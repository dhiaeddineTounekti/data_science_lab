Epoch: 1 | Iteration number: [10/4518] 0% | Training loss: 0.7592614471912384
Epoch: 1 | Iteration number: [20/4518] 0% | Training loss: 0.7254761010408401
Epoch: 1 | Iteration number: [30/4518] 0% | Training loss: 0.7140505194664002
Epoch: 1 | Iteration number: [40/4518] 0% | Training loss: 0.7081917628645897
Epoch: 1 | Iteration number: [50/4518] 1% | Training loss: 0.7047734606266022
Epoch: 1 | Iteration number: [60/4518] 1% | Training loss: 0.7025192836920421
Epoch: 1 | Iteration number: [70/4518] 1% | Training loss: 0.7007916688919067
Epoch: 1 | Iteration number: [80/4518] 1% | Training loss: 0.6995636068284512
Epoch: 1 | Iteration number: [90/4518] 1% | Training loss: 0.6986716250578563
Epoch: 1 | Iteration number: [100/4518] 2% | Training loss: 0.6979225927591324
Epoch: 1 | Iteration number: [110/4518] 2% | Training loss: 0.6973351483995264
Epoch: 1 | Iteration number: [120/4518] 2% | Training loss: 0.6968352794647217
Epoch: 1 | Iteration number: [130/4518] 2% | Training loss: 0.696495397732808
Epoch: 1 | Iteration number: [140/4518] 3% | Training loss: 0.6961949931723731
Epoch: 1 | Iteration number: [150/4518] 3% | Training loss: 0.6958954310417176
Epoch: 1 | Iteration number: [160/4518] 3% | Training loss: 0.6956376124173402
Epoch: 1 | Iteration number: [170/4518] 3% | Training loss: 0.6953796947703642
Epoch: 1 | Iteration number: [180/4518] 3% | Training loss: 0.6951243218448427
Epoch: 1 | Iteration number: [190/4518] 4% | Training loss: 0.6949022371517984
Epoch: 1 | Iteration number: [200/4518] 4% | Training loss: 0.6946942242980003
Epoch: 1 | Iteration number: [210/4518] 4% | Training loss: 0.6945033888022105
Epoch: 1 | Iteration number: [220/4518] 4% | Training loss: 0.6943315741690722
Epoch: 1 | Iteration number: [230/4518] 5% | Training loss: 0.6942183598228123
Epoch: 1 | Iteration number: [240/4518] 5% | Training loss: 0.6940665846069654
Epoch: 1 | Iteration number: [250/4518] 5% | Training loss: 0.6939497373104095
Epoch: 1 | Iteration number: [260/4518] 5% | Training loss: 0.6938110009982036
Epoch: 1 | Iteration number: [270/4518] 5% | Training loss: 0.6936620941868534
Epoch: 1 | Iteration number: [280/4518] 6% | Training loss: 0.6935616244162832
Epoch: 1 | Iteration number: [290/4518] 6% | Training loss: 0.6934655984927868
Epoch: 1 | Iteration number: [300/4518] 6% | Training loss: 0.6933384066820145
Epoch: 1 | Iteration number: [310/4518] 6% | Training loss: 0.6932749190638142
Epoch: 1 | Iteration number: [320/4518] 7% | Training loss: 0.6931941132992506
Epoch: 1 | Iteration number: [330/4518] 7% | Training loss: 0.693103784864599
Epoch: 1 | Iteration number: [340/4518] 7% | Training loss: 0.6930331370409797
Epoch: 1 | Iteration number: [350/4518] 7% | Training loss: 0.6929538939680372
Epoch: 1 | Iteration number: [360/4518] 7% | Training loss: 0.692874227795336
Epoch: 1 | Iteration number: [370/4518] 8% | Training loss: 0.6928025596850628
Epoch: 1 | Iteration number: [380/4518] 8% | Training loss: 0.6927344896291432
Epoch: 1 | Iteration number: [390/4518] 8% | Training loss: 0.6926841216209607
Epoch: 1 | Iteration number: [400/4518] 8% | Training loss: 0.6926256397366524
Epoch: 1 | Iteration number: [410/4518] 9% | Training loss: 0.6925477654468722
Epoch: 1 | Iteration number: [420/4518] 9% | Training loss: 0.6924944033225378
Epoch: 1 | Iteration number: [430/4518] 9% | Training loss: 0.6924214638942896
Epoch: 1 | Iteration number: [440/4518] 9% | Training loss: 0.6923688315532425
Epoch: 1 | Iteration number: [450/4518] 9% | Training loss: 0.6923351011011336
Epoch: 1 | Iteration number: [460/4518] 10% | Training loss: 0.6923059525697127
Epoch: 1 | Iteration number: [470/4518] 10% | Training loss: 0.6922543748896173
Epoch: 1 | Iteration number: [480/4518] 10% | Training loss: 0.6922010247906049
Epoch: 1 | Iteration number: [490/4518] 10% | Training loss: 0.6921757779559311
Epoch: 1 | Iteration number: [500/4518] 11% | Training loss: 0.6921295280456543
Epoch: 1 | Iteration number: [510/4518] 11% | Training loss: 0.6921007152865915
Epoch: 1 | Iteration number: [520/4518] 11% | Training loss: 0.6920709871328794
Epoch: 1 | Iteration number: [530/4518] 11% | Training loss: 0.692033717654786
Epoch: 1 | Iteration number: [540/4518] 11% | Training loss: 0.69200739717042
Epoch: 1 | Iteration number: [550/4518] 12% | Training loss: 0.6919862049276179
Epoch: 1 | Iteration number: [560/4518] 12% | Training loss: 0.6919461565358298
Epoch: 1 | Iteration number: [570/4518] 12% | Training loss: 0.6919123624500475
Epoch: 1 | Iteration number: [580/4518] 12% | Training loss: 0.6918919002187663
Epoch: 1 | Iteration number: [590/4518] 13% | Training loss: 0.6918741977820962
Epoch: 1 | Iteration number: [600/4518] 13% | Training loss: 0.6918357994159062
Epoch: 1 | Iteration number: [610/4518] 13% | Training loss: 0.691814521003942
Epoch: 1 | Iteration number: [620/4518] 13% | Training loss: 0.6917792768247666
Epoch: 1 | Iteration number: [630/4518] 13% | Training loss: 0.6917371934368497
Epoch: 1 | Iteration number: [640/4518] 14% | Training loss: 0.6917099348269403
Epoch: 1 | Iteration number: [650/4518] 14% | Training loss: 0.6916888050849621
Epoch: 1 | Iteration number: [660/4518] 14% | Training loss: 0.6916677156181047
Epoch: 1 | Iteration number: [670/4518] 14% | Training loss: 0.6916376610300434
Epoch: 1 | Iteration number: [680/4518] 15% | Training loss: 0.6916117582251043
Epoch: 1 | Iteration number: [690/4518] 15% | Training loss: 0.6915941465592039
Epoch: 1 | Iteration number: [700/4518] 15% | Training loss: 0.6915683501958847
Epoch: 1 | Iteration number: [710/4518] 15% | Training loss: 0.691544583481802
Epoch: 1 | Iteration number: [720/4518] 15% | Training loss: 0.6914929577873813
Epoch: 1 | Iteration number: [730/4518] 16% | Training loss: 0.6914770978770844
Epoch: 1 | Iteration number: [740/4518] 16% | Training loss: 0.6914640903472901
Epoch: 1 | Iteration number: [750/4518] 16% | Training loss: 0.6914554346402486
Epoch: 1 | Iteration number: [760/4518] 16% | Training loss: 0.6914343699028618
Epoch: 1 | Iteration number: [770/4518] 17% | Training loss: 0.6914116260293243
Epoch: 1 | Iteration number: [780/4518] 17% | Training loss: 0.6913890498570907
Epoch: 1 | Iteration number: [790/4518] 17% | Training loss: 0.6913741897178601
Epoch: 1 | Iteration number: [800/4518] 17% | Training loss: 0.6913562399148941
Epoch: 1 | Iteration number: [810/4518] 17% | Training loss: 0.6913244513081915
Epoch: 1 | Iteration number: [820/4518] 18% | Training loss: 0.6913034156328295
Epoch: 1 | Iteration number: [830/4518] 18% | Training loss: 0.6912982374788766
Epoch: 1 | Iteration number: [840/4518] 18% | Training loss: 0.6912758554021518
Epoch: 1 | Iteration number: [850/4518] 18% | Training loss: 0.6912586444265703
Epoch: 1 | Iteration number: [860/4518] 19% | Training loss: 0.6912527457919232
Epoch: 1 | Iteration number: [870/4518] 19% | Training loss: 0.6912266055742899
Epoch: 1 | Iteration number: [880/4518] 19% | Training loss: 0.6912181940268386
Epoch: 1 | Iteration number: [890/4518] 19% | Training loss: 0.6912138411168302
Epoch: 1 | Iteration number: [900/4518] 19% | Training loss: 0.6911994387706121
Epoch: 1 | Iteration number: [910/4518] 20% | Training loss: 0.6911743379556216
Epoch: 1 | Iteration number: [920/4518] 20% | Training loss: 0.6911534830927849
Epoch: 1 | Iteration number: [930/4518] 20% | Training loss: 0.6911342349744612
Epoch: 1 | Iteration number: [940/4518] 20% | Training loss: 0.6911158547122428
Epoch: 1 | Iteration number: [950/4518] 21% | Training loss: 0.6910921547287389
Epoch: 1 | Iteration number: [960/4518] 21% | Training loss: 0.6910810565575958
Epoch: 1 | Iteration number: [970/4518] 21% | Training loss: 0.6910576698706322
Epoch: 1 | Iteration number: [980/4518] 21% | Training loss: 0.6910485281019795
Epoch: 1 | Iteration number: [990/4518] 21% | Training loss: 0.691033008544132
Epoch: 1 | Iteration number: [1000/4518] 22% | Training loss: 0.6910223801136017
Epoch: 1 | Iteration number: [1010/4518] 22% | Training loss: 0.6910161763724714
Epoch: 1 | Iteration number: [1020/4518] 22% | Training loss: 0.6910026847147475
Epoch: 1 | Iteration number: [1030/4518] 22% | Training loss: 0.6909899875376988
Epoch: 1 | Iteration number: [1040/4518] 23% | Training loss: 0.6909763497801927
Epoch: 1 | Iteration number: [1050/4518] 23% | Training loss: 0.6909705510025933
Epoch: 1 | Iteration number: [1060/4518] 23% | Training loss: 0.6909487948102772
Epoch: 1 | Iteration number: [1070/4518] 23% | Training loss: 0.6909298072351473
Epoch: 1 | Iteration number: [1080/4518] 23% | Training loss: 0.69091354476081
Epoch: 1 | Iteration number: [1090/4518] 24% | Training loss: 0.6909032118976663
Epoch: 1 | Iteration number: [1100/4518] 24% | Training loss: 0.6908810049837286
Epoch: 1 | Iteration number: [1110/4518] 24% | Training loss: 0.6908715947254284
Epoch: 1 | Iteration number: [1120/4518] 24% | Training loss: 0.6908589799489294
Epoch: 1 | Iteration number: [1130/4518] 25% | Training loss: 0.6908474294485244
Epoch: 1 | Iteration number: [1140/4518] 25% | Training loss: 0.6908401610558493
Epoch: 1 | Iteration number: [1150/4518] 25% | Training loss: 0.6908313407068667
Epoch: 1 | Iteration number: [1160/4518] 25% | Training loss: 0.6908280666532187
Epoch: 1 | Iteration number: [1170/4518] 25% | Training loss: 0.6908160374714778
Epoch: 1 | Iteration number: [1180/4518] 26% | Training loss: 0.6908072246838424
Epoch: 1 | Iteration number: [1190/4518] 26% | Training loss: 0.6907915870682532
Epoch: 1 | Iteration number: [1200/4518] 26% | Training loss: 0.6907824244598547
Epoch: 1 | Iteration number: [1210/4518] 26% | Training loss: 0.6907680578468259
Epoch: 1 | Iteration number: [1220/4518] 27% | Training loss: 0.6907620245804552
Epoch: 1 | Iteration number: [1230/4518] 27% | Training loss: 0.6907481263808118
Epoch: 1 | Iteration number: [1240/4518] 27% | Training loss: 0.6907312016813986
Epoch: 1 | Iteration number: [1250/4518] 27% | Training loss: 0.690722928237915
Epoch: 1 | Iteration number: [1260/4518] 27% | Training loss: 0.6907132269844176
Epoch: 1 | Iteration number: [1270/4518] 28% | Training loss: 0.6907043881303682
Epoch: 1 | Iteration number: [1280/4518] 28% | Training loss: 0.6906919895671308
Epoch: 1 | Iteration number: [1290/4518] 28% | Training loss: 0.690686174695806
Epoch: 1 | Iteration number: [1300/4518] 28% | Training loss: 0.6906754767894745
Epoch: 1 | Iteration number: [1310/4518] 28% | Training loss: 0.690667520907089
Epoch: 1 | Iteration number: [1320/4518] 29% | Training loss: 0.6906470952160431
Epoch: 1 | Iteration number: [1330/4518] 29% | Training loss: 0.6906401524866433
Epoch: 1 | Iteration number: [1340/4518] 29% | Training loss: 0.6906280130592745
Epoch: 1 | Iteration number: [1350/4518] 29% | Training loss: 0.6906243534441348
Epoch: 1 | Iteration number: [1360/4518] 30% | Training loss: 0.6906069436055773
Epoch: 1 | Iteration number: [1370/4518] 30% | Training loss: 0.6905983661648131
Epoch: 1 | Iteration number: [1380/4518] 30% | Training loss: 0.6905840682810631
Epoch: 1 | Iteration number: [1390/4518] 30% | Training loss: 0.6905696246263792
Epoch: 1 | Iteration number: [1400/4518] 30% | Training loss: 0.6905642895613398
Epoch: 1 | Iteration number: [1410/4518] 31% | Training loss: 0.6905600431540334
Epoch: 1 | Iteration number: [1420/4518] 31% | Training loss: 0.6905490013075547
Epoch: 1 | Iteration number: [1430/4518] 31% | Training loss: 0.6905345710424277
Epoch: 1 | Iteration number: [1440/4518] 31% | Training loss: 0.6905361582421594
Epoch: 1 | Iteration number: [1450/4518] 32% | Training loss: 0.6905290373851513
Epoch: 1 | Iteration number: [1460/4518] 32% | Training loss: 0.6905205206511772
Epoch: 1 | Iteration number: [1470/4518] 32% | Training loss: 0.6905123963647959
Epoch: 1 | Iteration number: [1480/4518] 32% | Training loss: 0.6905075796955341
Epoch: 1 | Iteration number: [1490/4518] 32% | Training loss: 0.6905065243276174
Epoch: 1 | Iteration number: [1500/4518] 33% | Training loss: 0.6905000249147415
Epoch: 1 | Iteration number: [1510/4518] 33% | Training loss: 0.6904906920249888
Epoch: 1 | Iteration number: [1520/4518] 33% | Training loss: 0.6904900360656412
Epoch: 1 | Iteration number: [1530/4518] 33% | Training loss: 0.6904859647252202
Epoch: 1 | Iteration number: [1540/4518] 34% | Training loss: 0.690481059272568
Epoch: 1 | Iteration number: [1550/4518] 34% | Training loss: 0.6904736300437682
Epoch: 1 | Iteration number: [1560/4518] 34% | Training loss: 0.69046550626174
Epoch: 1 | Iteration number: [1570/4518] 34% | Training loss: 0.6904585899061458
Epoch: 1 | Iteration number: [1580/4518] 34% | Training loss: 0.6904498210058937
Epoch: 1 | Iteration number: [1590/4518] 35% | Training loss: 0.6904386427417492
Epoch: 1 | Iteration number: [1600/4518] 35% | Training loss: 0.690428587384522
Epoch: 1 | Iteration number: [1610/4518] 35% | Training loss: 0.6904184812714594
Epoch: 1 | Iteration number: [1620/4518] 35% | Training loss: 0.690405191315545
Epoch: 1 | Iteration number: [1630/4518] 36% | Training loss: 0.6903973039673881
Epoch: 1 | Iteration number: [1640/4518] 36% | Training loss: 0.6903943688404269
Epoch: 1 | Iteration number: [1650/4518] 36% | Training loss: 0.6903856030016234
Epoch: 1 | Iteration number: [1660/4518] 36% | Training loss: 0.6903826247855841
Epoch: 1 | Iteration number: [1670/4518] 36% | Training loss: 0.6903739679359391
Epoch: 1 | Iteration number: [1680/4518] 37% | Training loss: 0.6903623121480147
Epoch: 1 | Iteration number: [1690/4518] 37% | Training loss: 0.6903530381487671
Epoch: 1 | Iteration number: [1700/4518] 37% | Training loss: 0.6903366461571525
Epoch: 1 | Iteration number: [1710/4518] 37% | Training loss: 0.6903247148669951
Epoch: 1 | Iteration number: [1720/4518] 38% | Training loss: 0.6903183477909066
Epoch: 1 | Iteration number: [1730/4518] 38% | Training loss: 0.6903127798799834
Epoch: 1 | Iteration number: [1740/4518] 38% | Training loss: 0.6903090849004943
Epoch: 1 | Iteration number: [1750/4518] 38% | Training loss: 0.690299114397594
Epoch: 1 | Iteration number: [1760/4518] 38% | Training loss: 0.6902876500040293
Epoch: 1 | Iteration number: [1770/4518] 39% | Training loss: 0.6902762674005691
Epoch: 1 | Iteration number: [1780/4518] 39% | Training loss: 0.6902721324663483
Epoch: 1 | Iteration number: [1790/4518] 39% | Training loss: 0.6902655071719399
Epoch: 1 | Iteration number: [1800/4518] 39% | Training loss: 0.6902603387170367
Epoch: 1 | Iteration number: [1810/4518] 40% | Training loss: 0.690248572628801
Epoch: 1 | Iteration number: [1820/4518] 40% | Training loss: 0.6902426606023705
Epoch: 1 | Iteration number: [1830/4518] 40% | Training loss: 0.6902409376668148
Epoch: 1 | Iteration number: [1840/4518] 40% | Training loss: 0.6902387493006561
Epoch: 1 | Iteration number: [1850/4518] 40% | Training loss: 0.6902318503727785
Epoch: 1 | Iteration number: [1860/4518] 41% | Training loss: 0.6902284454594376
Epoch: 1 | Iteration number: [1870/4518] 41% | Training loss: 0.6902209022784616
Epoch: 1 | Iteration number: [1880/4518] 41% | Training loss: 0.6902163969709518
Epoch: 1 | Iteration number: [1890/4518] 41% | Training loss: 0.690209629705974
Epoch: 1 | Iteration number: [1900/4518] 42% | Training loss: 0.6901978301688244
Epoch: 1 | Iteration number: [1910/4518] 42% | Training loss: 0.6901881551555314
Epoch: 1 | Iteration number: [1920/4518] 42% | Training loss: 0.6901778104094167
Epoch: 1 | Iteration number: [1930/4518] 42% | Training loss: 0.6901712809201966
Epoch: 1 | Iteration number: [1940/4518] 42% | Training loss: 0.6901662652639998
Epoch: 1 | Iteration number: [1950/4518] 43% | Training loss: 0.6901629467499562
Epoch: 1 | Iteration number: [1960/4518] 43% | Training loss: 0.6901507405602202
Epoch: 1 | Iteration number: [1970/4518] 43% | Training loss: 0.6901471463859384
Epoch: 1 | Iteration number: [1980/4518] 43% | Training loss: 0.6901399200913882
Epoch: 1 | Iteration number: [1990/4518] 44% | Training loss: 0.6901390388383338
Epoch: 1 | Iteration number: [2000/4518] 44% | Training loss: 0.6901351155638695
Epoch: 1 | Iteration number: [2010/4518] 44% | Training loss: 0.6901292688811004
Epoch: 1 | Iteration number: [2020/4518] 44% | Training loss: 0.6901235519069256
Epoch: 1 | Iteration number: [2030/4518] 44% | Training loss: 0.6901184824006311
Epoch: 1 | Iteration number: [2040/4518] 45% | Training loss: 0.6901157184558756
Epoch: 1 | Iteration number: [2050/4518] 45% | Training loss: 0.6901112780338381
Epoch: 1 | Iteration number: [2060/4518] 45% | Training loss: 0.6901067236384142
Epoch: 1 | Iteration number: [2070/4518] 45% | Training loss: 0.6900944437669672
Epoch: 1 | Iteration number: [2080/4518] 46% | Training loss: 0.6900830907317308
Epoch: 1 | Iteration number: [2090/4518] 46% | Training loss: 0.690078990824485
Epoch: 1 | Iteration number: [2100/4518] 46% | Training loss: 0.6900757446459361
Epoch: 1 | Iteration number: [2110/4518] 46% | Training loss: 0.6900678352157087
Epoch: 1 | Iteration number: [2120/4518] 46% | Training loss: 0.690061538230698
Epoch: 1 | Iteration number: [2130/4518] 47% | Training loss: 0.6900559242622394
Epoch: 1 | Iteration number: [2140/4518] 47% | Training loss: 0.6900556430359868
Epoch: 1 | Iteration number: [2150/4518] 47% | Training loss: 0.6900466093906137
Epoch: 1 | Iteration number: [2160/4518] 47% | Training loss: 0.69004017037374
Epoch: 1 | Iteration number: [2170/4518] 48% | Training loss: 0.6900321769824226
Epoch: 1 | Iteration number: [2180/4518] 48% | Training loss: 0.6900237267717308
Epoch: 1 | Iteration number: [2190/4518] 48% | Training loss: 0.6900214874853282
Epoch: 1 | Iteration number: [2200/4518] 48% | Training loss: 0.6900151621482589
Epoch: 1 | Iteration number: [2210/4518] 48% | Training loss: 0.6900120528035574
Epoch: 1 | Iteration number: [2220/4518] 49% | Training loss: 0.6900084036696065
Epoch: 1 | Iteration number: [2230/4518] 49% | Training loss: 0.690001144804762
Epoch: 1 | Iteration number: [2240/4518] 49% | Training loss: 0.6899931422035609
Epoch: 1 | Iteration number: [2250/4518] 49% | Training loss: 0.6899895963139004
Epoch: 1 | Iteration number: [2260/4518] 50% | Training loss: 0.68998620401969
Epoch: 1 | Iteration number: [2270/4518] 50% | Training loss: 0.6899814520900995
Epoch: 1 | Iteration number: [2280/4518] 50% | Training loss: 0.689978172590858
Epoch: 1 | Iteration number: [2290/4518] 50% | Training loss: 0.6899707571387812
Epoch: 1 | Iteration number: [2300/4518] 50% | Training loss: 0.6899669347379519
Epoch: 1 | Iteration number: [2310/4518] 51% | Training loss: 0.6899548991934046
Epoch: 1 | Iteration number: [2320/4518] 51% | Training loss: 0.6899503865632518
Epoch: 1 | Iteration number: [2330/4518] 51% | Training loss: 0.6899486536887582
Epoch: 1 | Iteration number: [2340/4518] 51% | Training loss: 0.6899401338946106
Epoch: 1 | Iteration number: [2350/4518] 52% | Training loss: 0.6899354669134667
Epoch: 1 | Iteration number: [2360/4518] 52% | Training loss: 0.6899314552292986
Epoch: 1 | Iteration number: [2370/4518] 52% | Training loss: 0.6899313769260036
Epoch: 1 | Iteration number: [2380/4518] 52% | Training loss: 0.689924784167474
Epoch: 1 | Iteration number: [2390/4518] 52% | Training loss: 0.6899218576473172
Epoch: 1 | Iteration number: [2400/4518] 53% | Training loss: 0.6899179511020581
Epoch: 1 | Iteration number: [2410/4518] 53% | Training loss: 0.6899168605131727
Epoch: 1 | Iteration number: [2420/4518] 53% | Training loss: 0.6899138297916444
Epoch: 1 | Iteration number: [2430/4518] 53% | Training loss: 0.6899105206193257
Epoch: 1 | Iteration number: [2440/4518] 54% | Training loss: 0.6899069042479405
Epoch: 1 | Iteration number: [2450/4518] 54% | Training loss: 0.6899036016756175
Epoch: 1 | Iteration number: [2460/4518] 54% | Training loss: 0.6898998208889147
Epoch: 1 | Iteration number: [2470/4518] 54% | Training loss: 0.6898932138193957
Epoch: 1 | Iteration number: [2480/4518] 54% | Training loss: 0.6898868409856673
Epoch: 1 | Iteration number: [2490/4518] 55% | Training loss: 0.6898792826506986
Epoch: 1 | Iteration number: [2500/4518] 55% | Training loss: 0.6898765533924103
Epoch: 1 | Iteration number: [2510/4518] 55% | Training loss: 0.6898746450821241
Epoch: 1 | Iteration number: [2520/4518] 55% | Training loss: 0.689869082730914
Epoch: 1 | Iteration number: [2530/4518] 55% | Training loss: 0.6898618277589323
Epoch: 1 | Iteration number: [2540/4518] 56% | Training loss: 0.6898546346529262
Epoch: 1 | Iteration number: [2550/4518] 56% | Training loss: 0.6898511405785879
Epoch: 1 | Iteration number: [2560/4518] 56% | Training loss: 0.6898494090419263
Epoch: 1 | Iteration number: [2570/4518] 56% | Training loss: 0.689842736581884
Epoch: 1 | Iteration number: [2580/4518] 57% | Training loss: 0.689838923941287
Epoch: 1 | Iteration number: [2590/4518] 57% | Training loss: 0.6898337071236497
Epoch: 1 | Iteration number: [2600/4518] 57% | Training loss: 0.6898249898277796
Epoch: 1 | Iteration number: [2610/4518] 57% | Training loss: 0.6898227580890801
Epoch: 1 | Iteration number: [2620/4518] 57% | Training loss: 0.689817206800439
Epoch: 1 | Iteration number: [2630/4518] 58% | Training loss: 0.6898174412123604
Epoch: 1 | Iteration number: [2640/4518] 58% | Training loss: 0.6898141527040438
Epoch: 1 | Iteration number: [2650/4518] 58% | Training loss: 0.6898094037793717
Epoch: 1 | Iteration number: [2660/4518] 58% | Training loss: 0.6898106426896905
Epoch: 1 | Iteration number: [2670/4518] 59% | Training loss: 0.6898053525315688
Epoch: 1 | Iteration number: [2680/4518] 59% | Training loss: 0.6897975892050943
Epoch: 1 | Iteration number: [2690/4518] 59% | Training loss: 0.6897940047833113
Epoch: 1 | Iteration number: [2700/4518] 59% | Training loss: 0.6897895331956723
Epoch: 1 | Iteration number: [2710/4518] 59% | Training loss: 0.6897840886318376
Epoch: 1 | Iteration number: [2720/4518] 60% | Training loss: 0.6897802327923915
Epoch: 1 | Iteration number: [2730/4518] 60% | Training loss: 0.6897780271458539
Epoch: 1 | Iteration number: [2740/4518] 60% | Training loss: 0.6897740908130242
Epoch: 1 | Iteration number: [2750/4518] 60% | Training loss: 0.6897714295170524
Epoch: 1 | Iteration number: [2760/4518] 61% | Training loss: 0.6897676741299422
Epoch: 1 | Iteration number: [2770/4518] 61% | Training loss: 0.6897640242042955
Epoch: 1 | Iteration number: [2780/4518] 61% | Training loss: 0.6897578231507926
Epoch: 1 | Iteration number: [2790/4518] 61% | Training loss: 0.6897555001106741
Epoch: 1 | Iteration number: [2800/4518] 61% | Training loss: 0.6897527800500393
Epoch: 1 | Iteration number: [2810/4518] 62% | Training loss: 0.6897510988008085
Epoch: 1 | Iteration number: [2820/4518] 62% | Training loss: 0.689744521624653
Epoch: 1 | Iteration number: [2830/4518] 62% | Training loss: 0.6897409312295408
Epoch: 1 | Iteration number: [2840/4518] 62% | Training loss: 0.6897317616452634
Epoch: 1 | Iteration number: [2850/4518] 63% | Training loss: 0.6897289809427763
Epoch: 1 | Iteration number: [2860/4518] 63% | Training loss: 0.689728526781489
Epoch: 1 | Iteration number: [2870/4518] 63% | Training loss: 0.689722450726539
Epoch: 1 | Iteration number: [2880/4518] 63% | Training loss: 0.6897187876825531
Epoch: 1 | Iteration number: [2890/4518] 63% | Training loss: 0.6897136733812445
Epoch: 1 | Iteration number: [2900/4518] 64% | Training loss: 0.6897084485456861
Epoch: 1 | Iteration number: [2910/4518] 64% | Training loss: 0.6897069261655775
Epoch: 1 | Iteration number: [2920/4518] 64% | Training loss: 0.6897019484884118
Epoch: 1 | Iteration number: [2930/4518] 64% | Training loss: 0.6896981382736167
Epoch: 1 | Iteration number: [2940/4518] 65% | Training loss: 0.6896927002538629
Epoch: 1 | Iteration number: [2950/4518] 65% | Training loss: 0.689692402047626
Epoch: 1 | Iteration number: [2960/4518] 65% | Training loss: 0.6896884127243145
Epoch: 1 | Iteration number: [2970/4518] 65% | Training loss: 0.6896840492884319
Epoch: 1 | Iteration number: [2980/4518] 65% | Training loss: 0.6896817814183716
Epoch: 1 | Iteration number: [2990/4518] 66% | Training loss: 0.689679254935338
Epoch: 1 | Iteration number: [3000/4518] 66% | Training loss: 0.6896779669523239
Epoch: 1 | Iteration number: [3010/4518] 66% | Training loss: 0.6896751041626218
Epoch: 1 | Iteration number: [3020/4518] 66% | Training loss: 0.689671462379544
Epoch: 1 | Iteration number: [3030/4518] 67% | Training loss: 0.689666096271068
Epoch: 1 | Iteration number: [3040/4518] 67% | Training loss: 0.6896594817897207
Epoch: 1 | Iteration number: [3050/4518] 67% | Training loss: 0.6896568086694499
Epoch: 1 | Iteration number: [3060/4518] 67% | Training loss: 0.6896525590443143
Epoch: 1 | Iteration number: [3070/4518] 67% | Training loss: 0.6896460496447374
Epoch: 1 | Iteration number: [3080/4518] 68% | Training loss: 0.6896438104185191
Epoch: 1 | Iteration number: [3090/4518] 68% | Training loss: 0.6896398424523548
Epoch: 1 | Iteration number: [3100/4518] 68% | Training loss: 0.6896365509494659
Epoch: 1 | Iteration number: [3110/4518] 68% | Training loss: 0.689637449776628
Epoch: 1 | Iteration number: [3120/4518] 69% | Training loss: 0.6896346445267018
Epoch: 1 | Iteration number: [3130/4518] 69% | Training loss: 0.6896312204031898
Epoch: 1 | Iteration number: [3140/4518] 69% | Training loss: 0.689630421293769
Epoch: 1 | Iteration number: [3150/4518] 69% | Training loss: 0.6896259875335391
Epoch: 1 | Iteration number: [3160/4518] 69% | Training loss: 0.6896225627653206
Epoch: 1 | Iteration number: [3170/4518] 70% | Training loss: 0.6896226883874707
Epoch: 1 | Iteration number: [3180/4518] 70% | Training loss: 0.6896224386287185
Epoch: 1 | Iteration number: [3190/4518] 70% | Training loss: 0.68962005234811
Epoch: 1 | Iteration number: [3200/4518] 70% | Training loss: 0.6896179716289044
Epoch: 1 | Iteration number: [3210/4518] 71% | Training loss: 0.6896136769067461
Epoch: 1 | Iteration number: [3220/4518] 71% | Training loss: 0.6896090013270052
Epoch: 1 | Iteration number: [3230/4518] 71% | Training loss: 0.6896062662173351
Epoch: 1 | Iteration number: [3240/4518] 71% | Training loss: 0.6896039176870276
Epoch: 1 | Iteration number: [3250/4518] 71% | Training loss: 0.6896007230098431
Epoch: 1 | Iteration number: [3260/4518] 72% | Training loss: 0.6895956536560702
Epoch: 1 | Iteration number: [3270/4518] 72% | Training loss: 0.6895930829944961
Epoch: 1 | Iteration number: [3280/4518] 72% | Training loss: 0.689593872500629
Epoch: 1 | Iteration number: [3290/4518] 72% | Training loss: 0.6895887365094796
Epoch: 1 | Iteration number: [3300/4518] 73% | Training loss: 0.6895840252890731
Epoch: 1 | Iteration number: [3310/4518] 73% | Training loss: 0.6895809056895738
Epoch: 1 | Iteration number: [3320/4518] 73% | Training loss: 0.6895752884896404
Epoch: 1 | Iteration number: [3330/4518] 73% | Training loss: 0.6895701925138812
Epoch: 1 | Iteration number: [3340/4518] 73% | Training loss: 0.6895656478262233
Epoch: 1 | Iteration number: [3350/4518] 74% | Training loss: 0.6895630729198455
Epoch: 1 | Iteration number: [3360/4518] 74% | Training loss: 0.6895597935255084
Epoch: 1 | Iteration number: [3370/4518] 74% | Training loss: 0.6895583147641813
Epoch: 1 | Iteration number: [3380/4518] 74% | Training loss: 0.6895539672240703
Epoch: 1 | Iteration number: [3390/4518] 75% | Training loss: 0.6895500304600483
Epoch: 1 | Iteration number: [3400/4518] 75% | Training loss: 0.6895449810869554
Epoch: 1 | Iteration number: [3410/4518] 75% | Training loss: 0.6895390263575613
Epoch: 1 | Iteration number: [3420/4518] 75% | Training loss: 0.689533707290365
Epoch: 1 | Iteration number: [3430/4518] 75% | Training loss: 0.6895333453274329
Epoch: 1 | Iteration number: [3440/4518] 76% | Training loss: 0.6895333245050076
Epoch: 1 | Iteration number: [3450/4518] 76% | Training loss: 0.6895289043067158
Epoch: 1 | Iteration number: [3460/4518] 76% | Training loss: 0.6895278207139472
Epoch: 1 | Iteration number: [3470/4518] 76% | Training loss: 0.6895273252591619
Epoch: 1 | Iteration number: [3480/4518] 77% | Training loss: 0.6895229033183777
Epoch: 1 | Iteration number: [3490/4518] 77% | Training loss: 0.6895188746957861
Epoch: 1 | Iteration number: [3500/4518] 77% | Training loss: 0.6895163093805313
Epoch: 1 | Iteration number: [3510/4518] 77% | Training loss: 0.6895106194365738
Epoch: 1 | Iteration number: [3520/4518] 77% | Training loss: 0.6895058527588844
Epoch: 1 | Iteration number: [3530/4518] 78% | Training loss: 0.6894999465591172
Epoch: 1 | Iteration number: [3540/4518] 78% | Training loss: 0.6894959307491443
Epoch: 1 | Iteration number: [3550/4518] 78% | Training loss: 0.6894941573747447
Epoch: 1 | Iteration number: [3560/4518] 78% | Training loss: 0.6894910619499978
Epoch: 1 | Iteration number: [3570/4518] 79% | Training loss: 0.6894873751144783
Epoch: 1 | Iteration number: [3580/4518] 79% | Training loss: 0.689485766984231
Epoch: 1 | Iteration number: [3590/4518] 79% | Training loss: 0.6894819695803448
Epoch: 1 | Iteration number: [3600/4518] 79% | Training loss: 0.6894779724876086
Epoch: 1 | Iteration number: [3610/4518] 79% | Training loss: 0.6894735778302697
Epoch: 1 | Iteration number: [3620/4518] 80% | Training loss: 0.6894731548609655
Epoch: 1 | Iteration number: [3630/4518] 80% | Training loss: 0.6894692915201844
Epoch: 1 | Iteration number: [3640/4518] 80% | Training loss: 0.6894683747828662
Epoch: 1 | Iteration number: [3650/4518] 80% | Training loss: 0.6894645240045574
Epoch: 1 | Iteration number: [3660/4518] 81% | Training loss: 0.6894612316713958
Epoch: 1 | Iteration number: [3670/4518] 81% | Training loss: 0.6894594630201116
Epoch: 1 | Iteration number: [3680/4518] 81% | Training loss: 0.6894585236583067
Epoch: 1 | Iteration number: [3690/4518] 81% | Training loss: 0.6894534967456084
Epoch: 1 | Iteration number: [3700/4518] 81% | Training loss: 0.6894540242407773
Epoch: 1 | Iteration number: [3710/4518] 82% | Training loss: 0.6894484439789446
Epoch: 1 | Iteration number: [3720/4518] 82% | Training loss: 0.6894449091085824
Epoch: 1 | Iteration number: [3730/4518] 82% | Training loss: 0.6894435590297863
Epoch: 1 | Iteration number: [3740/4518] 82% | Training loss: 0.6894389550156772
Epoch: 1 | Iteration number: [3750/4518] 83% | Training loss: 0.6894353152751923
Epoch: 1 | Iteration number: [3760/4518] 83% | Training loss: 0.6894310578228311
Epoch: 1 | Iteration number: [3770/4518] 83% | Training loss: 0.6894263490283521
Epoch: 1 | Iteration number: [3780/4518] 83% | Training loss: 0.6894260402078982
Epoch: 1 | Iteration number: [3790/4518] 83% | Training loss: 0.689423255634182
Epoch: 1 | Iteration number: [3800/4518] 84% | Training loss: 0.689418648371571
Epoch: 1 | Iteration number: [3810/4518] 84% | Training loss: 0.6894166614909184
Epoch: 1 | Iteration number: [3820/4518] 84% | Training loss: 0.6894134249830746
Epoch: 1 | Iteration number: [3830/4518] 84% | Training loss: 0.6894088603186546
Epoch: 1 | Iteration number: [3840/4518] 84% | Training loss: 0.6894057749770581
Epoch: 1 | Iteration number: [3850/4518] 85% | Training loss: 0.6894018122282896
Epoch: 1 | Iteration number: [3860/4518] 85% | Training loss: 0.689399474195248
Epoch: 1 | Iteration number: [3870/4518] 85% | Training loss: 0.6893977034153557
Epoch: 1 | Iteration number: [3880/4518] 85% | Training loss: 0.6893988119419088
Epoch: 1 | Iteration number: [3890/4518] 86% | Training loss: 0.689396682067518
Epoch: 1 | Iteration number: [3900/4518] 86% | Training loss: 0.6893961745042068
Epoch: 1 | Iteration number: [3910/4518] 86% | Training loss: 0.6893953067110018
Epoch: 1 | Iteration number: [3920/4518] 86% | Training loss: 0.6893924663413544
Epoch: 1 | Iteration number: [3930/4518] 86% | Training loss: 0.6893886026080328
Epoch: 1 | Iteration number: [3940/4518] 87% | Training loss: 0.6893884746556355
Epoch: 1 | Iteration number: [3950/4518] 87% | Training loss: 0.6893836709668365
Epoch: 1 | Iteration number: [3960/4518] 87% | Training loss: 0.6893836275796698
Epoch: 1 | Iteration number: [3970/4518] 87% | Training loss: 0.6893827596749706
Epoch: 1 | Iteration number: [3980/4518] 88% | Training loss: 0.6893794612369346
Epoch: 1 | Iteration number: [3990/4518] 88% | Training loss: 0.6893795881952558
Epoch: 1 | Iteration number: [4000/4518] 88% | Training loss: 0.6893789499551057
Epoch: 1 | Iteration number: [4010/4518] 88% | Training loss: 0.6893764826722276
Epoch: 1 | Iteration number: [4020/4518] 88% | Training loss: 0.6893761313673276
Epoch: 1 | Iteration number: [4030/4518] 89% | Training loss: 0.6893761559396464
Epoch: 1 | Iteration number: [4040/4518] 89% | Training loss: 0.6893748990970083
Epoch: 1 | Iteration number: [4050/4518] 89% | Training loss: 0.6893747645690117
Epoch: 1 | Iteration number: [4060/4518] 89% | Training loss: 0.6893705388154889
Epoch: 1 | Iteration number: [4070/4518] 90% | Training loss: 0.6893681091817064
Epoch: 1 | Iteration number: [4080/4518] 90% | Training loss: 0.6893624442465165
Epoch: 1 | Iteration number: [4090/4518] 90% | Training loss: 0.6893598613645745
Epoch: 1 | Iteration number: [4100/4518] 90% | Training loss: 0.6893545308200324
Epoch: 1 | Iteration number: [4110/4518] 90% | Training loss: 0.689350906036196
Epoch: 1 | Iteration number: [4120/4518] 91% | Training loss: 0.6893486464341867
Epoch: 1 | Iteration number: [4130/4518] 91% | Training loss: 0.6893464917420764
Epoch: 1 | Iteration number: [4140/4518] 91% | Training loss: 0.6893455622420794
Epoch: 1 | Iteration number: [4150/4518] 91% | Training loss: 0.6893452364134501
Epoch: 1 | Iteration number: [4160/4518] 92% | Training loss: 0.6893434910246959
Epoch: 1 | Iteration number: [4170/4518] 92% | Training loss: 0.6893417717312738
Epoch: 1 | Iteration number: [4180/4518] 92% | Training loss: 0.6893406527607064
Epoch: 1 | Iteration number: [4190/4518] 92% | Training loss: 0.6893373217531491
Epoch: 1 | Iteration number: [4200/4518] 92% | Training loss: 0.6893356937311944
Epoch: 1 | Iteration number: [4210/4518] 93% | Training loss: 0.6893346193567308
Epoch: 1 | Iteration number: [4220/4518] 93% | Training loss: 0.6893322921759709
Epoch: 1 | Iteration number: [4230/4518] 93% | Training loss: 0.689330300921244
Epoch: 1 | Iteration number: [4240/4518] 93% | Training loss: 0.6893302637732254
Epoch: 1 | Iteration number: [4250/4518] 94% | Training loss: 0.68932977698831
Epoch: 1 | Iteration number: [4260/4518] 94% | Training loss: 0.6893295324744193
Epoch: 1 | Iteration number: [4270/4518] 94% | Training loss: 0.6893239819333481
Epoch: 1 | Iteration number: [4280/4518] 94% | Training loss: 0.6893234619331137
Epoch: 1 | Iteration number: [4290/4518] 94% | Training loss: 0.689322688182195
Epoch: 1 | Iteration number: [4300/4518] 95% | Training loss: 0.6893194698455721
Epoch: 1 | Iteration number: [4310/4518] 95% | Training loss: 0.689319969744804
Epoch: 1 | Iteration number: [4320/4518] 95% | Training loss: 0.6893164589725159
Epoch: 1 | Iteration number: [4330/4518] 95% | Training loss: 0.6893126126249723
Epoch: 1 | Iteration number: [4340/4518] 96% | Training loss: 0.6893104291593973
Epoch: 1 | Iteration number: [4350/4518] 96% | Training loss: 0.6893051998231603
Epoch: 1 | Iteration number: [4360/4518] 96% | Training loss: 0.6893021515476594
Epoch: 1 | Iteration number: [4370/4518] 96% | Training loss: 0.6892996328782708
Epoch: 1 | Iteration number: [4380/4518] 96% | Training loss: 0.6892965441561181
Epoch: 1 | Iteration number: [4390/4518] 97% | Training loss: 0.6892948036313329
Epoch: 1 | Iteration number: [4400/4518] 97% | Training loss: 0.6892922106927092
Epoch: 1 | Iteration number: [4410/4518] 97% | Training loss: 0.6892900737099636
Epoch: 1 | Iteration number: [4420/4518] 97% | Training loss: 0.6892857321516961
Epoch: 1 | Iteration number: [4430/4518] 98% | Training loss: 0.6892844300910528
Epoch: 1 | Iteration number: [4440/4518] 98% | Training loss: 0.6892794550136403
Epoch: 1 | Iteration number: [4450/4518] 98% | Training loss: 0.6892777314614714
Epoch: 1 | Iteration number: [4460/4518] 98% | Training loss: 0.6892756480138933
Epoch: 1 | Iteration number: [4470/4518] 98% | Training loss: 0.6892731721502556
Epoch: 1 | Iteration number: [4480/4518] 99% | Training loss: 0.68926752494382
Epoch: 1 | Iteration number: [4490/4518] 99% | Training loss: 0.6892669308690027
Epoch: 1 | Iteration number: [4500/4518] 99% | Training loss: 0.6892652714517381
Epoch: 1 | Iteration number: [4510/4518] 99% | Training loss: 0.6892626435027154

 End of epoch: 1 | Train Loss: 0.6891106850887727 | Training Time: 640 

 End of epoch: 1 | Eval Loss: 0.6908322706514475 | Evaluating Time: 17 
Epoch: 2 | Iteration number: [10/4518] 0% | Training loss: 0.75724276304245
Epoch: 2 | Iteration number: [20/4518] 0% | Training loss: 0.7229475438594818
Epoch: 2 | Iteration number: [30/4518] 0% | Training loss: 0.7116610527038574
Epoch: 2 | Iteration number: [40/4518] 0% | Training loss: 0.7058317005634308
Epoch: 2 | Iteration number: [50/4518] 1% | Training loss: 0.7023864448070526
Epoch: 2 | Iteration number: [60/4518] 1% | Training loss: 0.6999365170796712
Epoch: 2 | Iteration number: [70/4518] 1% | Training loss: 0.698136682169778
Epoch: 2 | Iteration number: [80/4518] 1% | Training loss: 0.6967674925923347
Epoch: 2 | Iteration number: [90/4518] 1% | Training loss: 0.6959928075472513
Epoch: 2 | Iteration number: [100/4518] 2% | Training loss: 0.6951635187864303
Epoch: 2 | Iteration number: [110/4518] 2% | Training loss: 0.6944273282181133
Epoch: 2 | Iteration number: [120/4518] 2% | Training loss: 0.693940457701683
Epoch: 2 | Iteration number: [130/4518] 2% | Training loss: 0.6934864420157213
Epoch: 2 | Iteration number: [140/4518] 3% | Training loss: 0.6931133342640741
Epoch: 2 | Iteration number: [150/4518] 3% | Training loss: 0.6927759647369385
Epoch: 2 | Iteration number: [160/4518] 3% | Training loss: 0.6924961876124144
Epoch: 2 | Iteration number: [170/4518] 3% | Training loss: 0.6923245924360611
Epoch: 2 | Iteration number: [180/4518] 3% | Training loss: 0.6920611941152148
Epoch: 2 | Iteration number: [190/4518] 4% | Training loss: 0.6919201251707578
Epoch: 2 | Iteration number: [200/4518] 4% | Training loss: 0.69170595318079
Epoch: 2 | Iteration number: [210/4518] 4% | Training loss: 0.6915059518246424
Epoch: 2 | Iteration number: [220/4518] 4% | Training loss: 0.6913133000785654
Epoch: 2 | Iteration number: [230/4518] 5% | Training loss: 0.6911857060764147
Epoch: 2 | Iteration number: [240/4518] 5% | Training loss: 0.690996627509594
Epoch: 2 | Iteration number: [250/4518] 5% | Training loss: 0.6908891980648041
Epoch: 2 | Iteration number: [260/4518] 5% | Training loss: 0.690791048682653
Epoch: 2 | Iteration number: [270/4518] 5% | Training loss: 0.6906963268915812
Epoch: 2 | Iteration number: [280/4518] 6% | Training loss: 0.6905651788626398
Epoch: 2 | Iteration number: [290/4518] 6% | Training loss: 0.6904763493044623
Epoch: 2 | Iteration number: [300/4518] 6% | Training loss: 0.69038689494133
Epoch: 2 | Iteration number: [310/4518] 6% | Training loss: 0.6903499697485278
Epoch: 2 | Iteration number: [320/4518] 7% | Training loss: 0.690296919643879
Epoch: 2 | Iteration number: [330/4518] 7% | Training loss: 0.6902367626175736
Epoch: 2 | Iteration number: [340/4518] 7% | Training loss: 0.6901970812503029
Epoch: 2 | Iteration number: [350/4518] 7% | Training loss: 0.6901558690411704
Epoch: 2 | Iteration number: [360/4518] 7% | Training loss: 0.6901318566666709
Epoch: 2 | Iteration number: [370/4518] 8% | Training loss: 0.6901094037133294
Epoch: 2 | Iteration number: [380/4518] 8% | Training loss: 0.6900760415353273
Epoch: 2 | Iteration number: [390/4518] 8% | Training loss: 0.6900081078211466
Epoch: 2 | Iteration number: [400/4518] 8% | Training loss: 0.6899570347368718
Epoch: 2 | Iteration number: [410/4518] 9% | Training loss: 0.6899248224932973
Epoch: 2 | Iteration number: [420/4518] 9% | Training loss: 0.6898713103362493
Epoch: 2 | Iteration number: [430/4518] 9% | Training loss: 0.6898712659991064
Epoch: 2 | Iteration number: [440/4518] 9% | Training loss: 0.6898279595104131
Epoch: 2 | Iteration number: [450/4518] 9% | Training loss: 0.68979582534896
Epoch: 2 | Iteration number: [460/4518] 10% | Training loss: 0.6897780214962752
Epoch: 2 | Iteration number: [470/4518] 10% | Training loss: 0.6897373767609292
Epoch: 2 | Iteration number: [480/4518] 10% | Training loss: 0.6896960638463497
Epoch: 2 | Iteration number: [490/4518] 10% | Training loss: 0.6896676429680415
Epoch: 2 | Iteration number: [500/4518] 11% | Training loss: 0.6896504200696946
Epoch: 2 | Iteration number: [510/4518] 11% | Training loss: 0.6896152482313268
Epoch: 2 | Iteration number: [520/4518] 11% | Training loss: 0.6895847777907665
Epoch: 2 | Iteration number: [530/4518] 11% | Training loss: 0.689554508339684
Epoch: 2 | Iteration number: [540/4518] 11% | Training loss: 0.6895415276288986
Epoch: 2 | Iteration number: [550/4518] 12% | Training loss: 0.6895137785781513
Epoch: 2 | Iteration number: [560/4518] 12% | Training loss: 0.6894947324480329
Epoch: 2 | Iteration number: [570/4518] 12% | Training loss: 0.6894574484281373
Epoch: 2 | Iteration number: [580/4518] 12% | Training loss: 0.6894610495402895
Epoch: 2 | Iteration number: [590/4518] 13% | Training loss: 0.6894437891952062
Epoch: 2 | Iteration number: [600/4518] 13% | Training loss: 0.6894249513745307
Epoch: 2 | Iteration number: [610/4518] 13% | Training loss: 0.6893953766979155
Epoch: 2 | Iteration number: [620/4518] 13% | Training loss: 0.6893859671969568
Epoch: 2 | Iteration number: [630/4518] 13% | Training loss: 0.6893513231996506
Epoch: 2 | Iteration number: [640/4518] 14% | Training loss: 0.6893170922994614
Epoch: 2 | Iteration number: [650/4518] 14% | Training loss: 0.6893082382128789
Epoch: 2 | Iteration number: [660/4518] 14% | Training loss: 0.6892887579672264
Epoch: 2 | Iteration number: [670/4518] 14% | Training loss: 0.6892673882085886
Epoch: 2 | Iteration number: [680/4518] 15% | Training loss: 0.6892338253995951
Epoch: 2 | Iteration number: [690/4518] 15% | Training loss: 0.6892103321310402
Epoch: 2 | Iteration number: [700/4518] 15% | Training loss: 0.6891979632207326
Epoch: 2 | Iteration number: [710/4518] 15% | Training loss: 0.6891993849210336
Epoch: 2 | Iteration number: [720/4518] 15% | Training loss: 0.6891788758337498
Epoch: 2 | Iteration number: [730/4518] 16% | Training loss: 0.689170466138892
Epoch: 2 | Iteration number: [740/4518] 16% | Training loss: 0.6891719176962569
Epoch: 2 | Iteration number: [750/4518] 16% | Training loss: 0.6891633931795756
Epoch: 2 | Iteration number: [760/4518] 16% | Training loss: 0.6891546496435216
Epoch: 2 | Iteration number: [770/4518] 17% | Training loss: 0.6891414663234314
Epoch: 2 | Iteration number: [780/4518] 17% | Training loss: 0.6891269002205286
Epoch: 2 | Iteration number: [790/4518] 17% | Training loss: 0.6891131165661389
Epoch: 2 | Iteration number: [800/4518] 17% | Training loss: 0.6891006293147802
Epoch: 2 | Iteration number: [810/4518] 17% | Training loss: 0.6890820670275041
Epoch: 2 | Iteration number: [820/4518] 18% | Training loss: 0.6890785851856557
Epoch: 2 | Iteration number: [830/4518] 18% | Training loss: 0.6890779418399535
Epoch: 2 | Iteration number: [840/4518] 18% | Training loss: 0.6890616377904302
Epoch: 2 | Iteration number: [850/4518] 18% | Training loss: 0.689048509387409
Epoch: 2 | Iteration number: [860/4518] 19% | Training loss: 0.6890428649824719
Epoch: 2 | Iteration number: [870/4518] 19% | Training loss: 0.6890322492040437
Epoch: 2 | Iteration number: [880/4518] 19% | Training loss: 0.6890140742740848
Epoch: 2 | Iteration number: [890/4518] 19% | Training loss: 0.689011421900117
Epoch: 2 | Iteration number: [900/4518] 19% | Training loss: 0.6890065016349157
Epoch: 2 | Iteration number: [910/4518] 20% | Training loss: 0.6889866604909792
Epoch: 2 | Iteration number: [920/4518] 20% | Training loss: 0.6889837445772212
Epoch: 2 | Iteration number: [930/4518] 20% | Training loss: 0.6889562038324213
Epoch: 2 | Iteration number: [940/4518] 20% | Training loss: 0.6889467476530278
Epoch: 2 | Iteration number: [950/4518] 21% | Training loss: 0.6889409675723628
Epoch: 2 | Iteration number: [960/4518] 21% | Training loss: 0.6889318265020847
Epoch: 2 | Iteration number: [970/4518] 21% | Training loss: 0.688919464214561
Epoch: 2 | Iteration number: [980/4518] 21% | Training loss: 0.6889100267570846
Epoch: 2 | Iteration number: [990/4518] 21% | Training loss: 0.688901587387528
Epoch: 2 | Iteration number: [1000/4518] 22% | Training loss: 0.6888905763030052
Epoch: 2 | Iteration number: [1010/4518] 22% | Training loss: 0.6888892360843054
Epoch: 2 | Iteration number: [1020/4518] 22% | Training loss: 0.6888827521427004
Epoch: 2 | Iteration number: [1030/4518] 22% | Training loss: 0.6888795999068659
Epoch: 2 | Iteration number: [1040/4518] 23% | Training loss: 0.6888665694456834
Epoch: 2 | Iteration number: [1050/4518] 23% | Training loss: 0.6888615818250747
Epoch: 2 | Iteration number: [1060/4518] 23% | Training loss: 0.6888473505681416
Epoch: 2 | Iteration number: [1070/4518] 23% | Training loss: 0.6888370327303343
Epoch: 2 | Iteration number: [1080/4518] 23% | Training loss: 0.688832185058682
Epoch: 2 | Iteration number: [1090/4518] 24% | Training loss: 0.6888318110496626
Epoch: 2 | Iteration number: [1100/4518] 24% | Training loss: 0.6888322985172272
Epoch: 2 | Iteration number: [1110/4518] 24% | Training loss: 0.6888277953272467
Epoch: 2 | Iteration number: [1120/4518] 24% | Training loss: 0.6888221641736371
Epoch: 2 | Iteration number: [1130/4518] 25% | Training loss: 0.6888180386703626
Epoch: 2 | Iteration number: [1140/4518] 25% | Training loss: 0.6888142256360305
Epoch: 2 | Iteration number: [1150/4518] 25% | Training loss: 0.6888013933015906
Epoch: 2 | Iteration number: [1160/4518] 25% | Training loss: 0.6887991641102166
Epoch: 2 | Iteration number: [1170/4518] 25% | Training loss: 0.6887939754714314
Epoch: 2 | Iteration number: [1180/4518] 26% | Training loss: 0.6887870330931777
Epoch: 2 | Iteration number: [1190/4518] 26% | Training loss: 0.6887732875948193
Epoch: 2 | Iteration number: [1200/4518] 26% | Training loss: 0.6887672518193722
Epoch: 2 | Iteration number: [1210/4518] 26% | Training loss: 0.6887546479701996
Epoch: 2 | Iteration number: [1220/4518] 27% | Training loss: 0.6887486630287327
Epoch: 2 | Iteration number: [1230/4518] 27% | Training loss: 0.6887475557443572
Epoch: 2 | Iteration number: [1240/4518] 27% | Training loss: 0.688732385106625
Epoch: 2 | Iteration number: [1250/4518] 27% | Training loss: 0.6887297930717469
Epoch: 2 | Iteration number: [1260/4518] 27% | Training loss: 0.688726732465956
Epoch: 2 | Iteration number: [1270/4518] 28% | Training loss: 0.6887238197439299
Epoch: 2 | Iteration number: [1280/4518] 28% | Training loss: 0.6887146103195846
Epoch: 2 | Iteration number: [1290/4518] 28% | Training loss: 0.6887042939200881
Epoch: 2 | Iteration number: [1300/4518] 28% | Training loss: 0.688700597011126
Epoch: 2 | Iteration number: [1310/4518] 28% | Training loss: 0.6886914030741189
Epoch: 2 | Iteration number: [1320/4518] 29% | Training loss: 0.6886844699581464
Epoch: 2 | Iteration number: [1330/4518] 29% | Training loss: 0.6886899235553311
Epoch: 2 | Iteration number: [1340/4518] 29% | Training loss: 0.6886762443763107
Epoch: 2 | Iteration number: [1350/4518] 29% | Training loss: 0.6886783950858646
Epoch: 2 | Iteration number: [1360/4518] 30% | Training loss: 0.6886734396219254
Epoch: 2 | Iteration number: [1370/4518] 30% | Training loss: 0.6886739741276651
Epoch: 2 | Iteration number: [1380/4518] 30% | Training loss: 0.688672634570495
Epoch: 2 | Iteration number: [1390/4518] 30% | Training loss: 0.6886746305355923
Epoch: 2 | Iteration number: [1400/4518] 30% | Training loss: 0.688666002878121
Epoch: 2 | Iteration number: [1410/4518] 31% | Training loss: 0.6886672860341715
Epoch: 2 | Iteration number: [1420/4518] 31% | Training loss: 0.6886705779273745
Epoch: 2 | Iteration number: [1430/4518] 31% | Training loss: 0.6886689539555904
Epoch: 2 | Iteration number: [1440/4518] 31% | Training loss: 0.6886696623845233
Epoch: 2 | Iteration number: [1450/4518] 32% | Training loss: 0.688666418585284
Epoch: 2 | Iteration number: [1460/4518] 32% | Training loss: 0.688670362389251
Epoch: 2 | Iteration number: [1470/4518] 32% | Training loss: 0.6886553369411806
Epoch: 2 | Iteration number: [1480/4518] 32% | Training loss: 0.6886496056173299
Epoch: 2 | Iteration number: [1490/4518] 32% | Training loss: 0.6886446270766674
Epoch: 2 | Iteration number: [1500/4518] 33% | Training loss: 0.6886386125882467
Epoch: 2 | Iteration number: [1510/4518] 33% | Training loss: 0.6886395489537953
Epoch: 2 | Iteration number: [1520/4518] 33% | Training loss: 0.6886375983294688
Epoch: 2 | Iteration number: [1530/4518] 33% | Training loss: 0.6886367458144045
Epoch: 2 | Iteration number: [1540/4518] 34% | Training loss: 0.6886297979525158
Epoch: 2 | Iteration number: [1550/4518] 34% | Training loss: 0.6886235053308548
Epoch: 2 | Iteration number: [1560/4518] 34% | Training loss: 0.6886172962112305
Epoch: 2 | Iteration number: [1570/4518] 34% | Training loss: 0.6886156152767741
Epoch: 2 | Iteration number: [1580/4518] 34% | Training loss: 0.6886142905754379
Epoch: 2 | Iteration number: [1590/4518] 35% | Training loss: 0.6886065756000063
Epoch: 2 | Iteration number: [1600/4518] 35% | Training loss: 0.6886047112196684
Epoch: 2 | Iteration number: [1610/4518] 35% | Training loss: 0.6886103170999088
Epoch: 2 | Iteration number: [1620/4518] 35% | Training loss: 0.6886047262100525
Epoch: 2 | Iteration number: [1630/4518] 36% | Training loss: 0.6886018269266819
Epoch: 2 | Iteration number: [1640/4518] 36% | Training loss: 0.6885997510901312
Epoch: 2 | Iteration number: [1650/4518] 36% | Training loss: 0.6885967537489804
Epoch: 2 | Iteration number: [1660/4518] 36% | Training loss: 0.6885838198733617
Epoch: 2 | Iteration number: [1670/4518] 36% | Training loss: 0.6885776609717729
Epoch: 2 | Iteration number: [1680/4518] 37% | Training loss: 0.6885772760425295
Epoch: 2 | Iteration number: [1690/4518] 37% | Training loss: 0.6885814366961373
Epoch: 2 | Iteration number: [1700/4518] 37% | Training loss: 0.6885705874246709
Epoch: 2 | Iteration number: [1710/4518] 37% | Training loss: 0.6885819249334391
Epoch: 2 | Iteration number: [1720/4518] 38% | Training loss: 0.6885823493433553
Epoch: 2 | Iteration number: [1730/4518] 38% | Training loss: 0.6885801941673191
Epoch: 2 | Iteration number: [1740/4518] 38% | Training loss: 0.6885731615211772
Epoch: 2 | Iteration number: [1750/4518] 38% | Training loss: 0.6885701951980591
Epoch: 2 | Iteration number: [1760/4518] 38% | Training loss: 0.6885755329646848
Epoch: 2 | Iteration number: [1770/4518] 39% | Training loss: 0.6885666592646453
Epoch: 2 | Iteration number: [1780/4518] 39% | Training loss: 0.6885639756583096
Epoch: 2 | Iteration number: [1790/4518] 39% | Training loss: 0.6885633149626534
Epoch: 2 | Iteration number: [1800/4518] 39% | Training loss: 0.6885729096333186
Epoch: 2 | Iteration number: [1810/4518] 40% | Training loss: 0.6885654432009597
Epoch: 2 | Iteration number: [1820/4518] 40% | Training loss: 0.6885637000366882
Epoch: 2 | Iteration number: [1830/4518] 40% | Training loss: 0.6885603922638085
Epoch: 2 | Iteration number: [1840/4518] 40% | Training loss: 0.6885591652730237
Epoch: 2 | Iteration number: [1850/4518] 40% | Training loss: 0.688559937928174
Epoch: 2 | Iteration number: [1860/4518] 41% | Training loss: 0.688551434714307
Epoch: 2 | Iteration number: [1870/4518] 41% | Training loss: 0.688540971438515
Epoch: 2 | Iteration number: [1880/4518] 41% | Training loss: 0.6885383880518853
Epoch: 2 | Iteration number: [1890/4518] 41% | Training loss: 0.688543156372807
Epoch: 2 | Iteration number: [1900/4518] 42% | Training loss: 0.6885362459483899
Epoch: 2 | Iteration number: [1910/4518] 42% | Training loss: 0.6885303653971687
Epoch: 2 | Iteration number: [1920/4518] 42% | Training loss: 0.6885293057809273
Epoch: 2 | Iteration number: [1930/4518] 42% | Training loss: 0.6885235912750423
Epoch: 2 | Iteration number: [1940/4518] 42% | Training loss: 0.68851856358887
Epoch: 2 | Iteration number: [1950/4518] 43% | Training loss: 0.6885164053317828
Epoch: 2 | Iteration number: [1960/4518] 43% | Training loss: 0.6885156424982207
Epoch: 2 | Iteration number: [1970/4518] 43% | Training loss: 0.6885053231328877
Epoch: 2 | Iteration number: [1980/4518] 43% | Training loss: 0.6885053253836102
Epoch: 2 | Iteration number: [1990/4518] 44% | Training loss: 0.6885056309963591
Epoch: 2 | Iteration number: [2000/4518] 44% | Training loss: 0.6885014244019986
Epoch: 2 | Iteration number: [2010/4518] 44% | Training loss: 0.6884964227379851
Epoch: 2 | Iteration number: [2020/4518] 44% | Training loss: 0.6884928817796235
Epoch: 2 | Iteration number: [2030/4518] 44% | Training loss: 0.6884838109239569
Epoch: 2 | Iteration number: [2040/4518] 45% | Training loss: 0.6884821887986333
Epoch: 2 | Iteration number: [2050/4518] 45% | Training loss: 0.6884819147644974
Epoch: 2 | Iteration number: [2060/4518] 45% | Training loss: 0.68848295784691
Epoch: 2 | Iteration number: [2070/4518] 45% | Training loss: 0.6884833504900264
Epoch: 2 | Iteration number: [2080/4518] 46% | Training loss: 0.6884832475047845
Epoch: 2 | Iteration number: [2090/4518] 46% | Training loss: 0.6884810648466412
Epoch: 2 | Iteration number: [2100/4518] 46% | Training loss: 0.6884838447968165
Epoch: 2 | Iteration number: [2110/4518] 46% | Training loss: 0.6884785363176987
Epoch: 2 | Iteration number: [2120/4518] 46% | Training loss: 0.6884729117717383
Epoch: 2 | Iteration number: [2130/4518] 47% | Training loss: 0.6884674998796042
Epoch: 2 | Iteration number: [2140/4518] 47% | Training loss: 0.6884658734375071
Epoch: 2 | Iteration number: [2150/4518] 47% | Training loss: 0.6884604562992274
Epoch: 2 | Iteration number: [2160/4518] 47% | Training loss: 0.6884550779506012
Epoch: 2 | Iteration number: [2170/4518] 48% | Training loss: 0.6884499399343393
Epoch: 2 | Iteration number: [2180/4518] 48% | Training loss: 0.6884446197966917
Epoch: 2 | Iteration number: [2190/4518] 48% | Training loss: 0.6884440398651716
Epoch: 2 | Iteration number: [2200/4518] 48% | Training loss: 0.6884408714012666
Epoch: 2 | Iteration number: [2210/4518] 48% | Training loss: 0.6884363324933462
Epoch: 2 | Iteration number: [2220/4518] 49% | Training loss: 0.6884290495434323
Epoch: 2 | Iteration number: [2230/4518] 49% | Training loss: 0.6884269564675644
Epoch: 2 | Iteration number: [2240/4518] 49% | Training loss: 0.6884257506313068
Epoch: 2 | Iteration number: [2250/4518] 49% | Training loss: 0.688423356877433
Epoch: 2 | Iteration number: [2260/4518] 50% | Training loss: 0.6884141772457983
Epoch: 2 | Iteration number: [2270/4518] 50% | Training loss: 0.6884091922890248
Epoch: 2 | Iteration number: [2280/4518] 50% | Training loss: 0.6884066015220525
Epoch: 2 | Iteration number: [2290/4518] 50% | Training loss: 0.6884040721899557
Epoch: 2 | Iteration number: [2300/4518] 50% | Training loss: 0.6883975261449814
Epoch: 2 | Iteration number: [2310/4518] 51% | Training loss: 0.6884014866310797
Epoch: 2 | Iteration number: [2320/4518] 51% | Training loss: 0.6883990881258044
Epoch: 2 | Iteration number: [2330/4518] 51% | Training loss: 0.6883996156663854
Epoch: 2 | Iteration number: [2340/4518] 51% | Training loss: 0.6883986235938521
Epoch: 2 | Iteration number: [2350/4518] 52% | Training loss: 0.6883978420622805
Epoch: 2 | Iteration number: [2360/4518] 52% | Training loss: 0.6883976794147896
Epoch: 2 | Iteration number: [2370/4518] 52% | Training loss: 0.6883946518354778
Epoch: 2 | Iteration number: [2380/4518] 52% | Training loss: 0.6883888421439323
Epoch: 2 | Iteration number: [2390/4518] 52% | Training loss: 0.6883834678009464
Epoch: 2 | Iteration number: [2400/4518] 53% | Training loss: 0.688383312796553
Epoch: 2 | Iteration number: [2410/4518] 53% | Training loss: 0.688379209739044
Epoch: 2 | Iteration number: [2420/4518] 53% | Training loss: 0.6883743406081002
Epoch: 2 | Iteration number: [2430/4518] 53% | Training loss: 0.6883710254366996
Epoch: 2 | Iteration number: [2440/4518] 54% | Training loss: 0.688371942741949
Epoch: 2 | Iteration number: [2450/4518] 54% | Training loss: 0.6883729781180012
Epoch: 2 | Iteration number: [2460/4518] 54% | Training loss: 0.6883660665372523
Epoch: 2 | Iteration number: [2470/4518] 54% | Training loss: 0.6883628564083625
Epoch: 2 | Iteration number: [2480/4518] 54% | Training loss: 0.6883617178566994
Epoch: 2 | Iteration number: [2490/4518] 55% | Training loss: 0.6883545793203943
Epoch: 2 | Iteration number: [2500/4518] 55% | Training loss: 0.6883516653060913
Epoch: 2 | Iteration number: [2510/4518] 55% | Training loss: 0.6883513781653933
Epoch: 2 | Iteration number: [2520/4518] 55% | Training loss: 0.6883494489722781
Epoch: 2 | Iteration number: [2530/4518] 55% | Training loss: 0.6883469562756686
Epoch: 2 | Iteration number: [2540/4518] 56% | Training loss: 0.6883489836154022
Epoch: 2 | Iteration number: [2550/4518] 56% | Training loss: 0.6883524933749554
Epoch: 2 | Iteration number: [2560/4518] 56% | Training loss: 0.6883469980908558
Epoch: 2 | Iteration number: [2570/4518] 56% | Training loss: 0.6883447382004808
Epoch: 2 | Iteration number: [2580/4518] 57% | Training loss: 0.6883451710144679
Epoch: 2 | Iteration number: [2590/4518] 57% | Training loss: 0.6883481621051847
Epoch: 2 | Iteration number: [2600/4518] 57% | Training loss: 0.6883464512916712
Epoch: 2 | Iteration number: [2610/4518] 57% | Training loss: 0.6883420913383879
Epoch: 2 | Iteration number: [2620/4518] 57% | Training loss: 0.6883393797255655
Epoch: 2 | Iteration number: [2630/4518] 58% | Training loss: 0.6883353433908165
Epoch: 2 | Iteration number: [2640/4518] 58% | Training loss: 0.6883366061205214
Epoch: 2 | Iteration number: [2650/4518] 58% | Training loss: 0.6883353463433823
Epoch: 2 | Iteration number: [2660/4518] 58% | Training loss: 0.688336733655822
Epoch: 2 | Iteration number: [2670/4518] 59% | Training loss: 0.6883302151487115
Epoch: 2 | Iteration number: [2680/4518] 59% | Training loss: 0.6883245929408429
Epoch: 2 | Iteration number: [2690/4518] 59% | Training loss: 0.6883263458549754
Epoch: 2 | Iteration number: [2700/4518] 59% | Training loss: 0.6883259274341442
Epoch: 2 | Iteration number: [2710/4518] 59% | Training loss: 0.6883258670458494
Epoch: 2 | Iteration number: [2720/4518] 60% | Training loss: 0.6883257390602546
Epoch: 2 | Iteration number: [2730/4518] 60% | Training loss: 0.688326660268036
Epoch: 2 | Iteration number: [2740/4518] 60% | Training loss: 0.6883247067023368
Epoch: 2 | Iteration number: [2750/4518] 60% | Training loss: 0.6883253188133239
Epoch: 2 | Iteration number: [2760/4518] 61% | Training loss: 0.6883213388099186
Epoch: 2 | Iteration number: [2770/4518] 61% | Training loss: 0.6883201906612203
Epoch: 2 | Iteration number: [2780/4518] 61% | Training loss: 0.6883205503225327
Epoch: 2 | Iteration number: [2790/4518] 61% | Training loss: 0.6883154012823618
Epoch: 2 | Iteration number: [2800/4518] 61% | Training loss: 0.6883113001925605
Epoch: 2 | Iteration number: [2810/4518] 62% | Training loss: 0.6883111739710133
Epoch: 2 | Iteration number: [2820/4518] 62% | Training loss: 0.6883131461997404
Epoch: 2 | Iteration number: [2830/4518] 62% | Training loss: 0.6883110249842856
Epoch: 2 | Iteration number: [2840/4518] 62% | Training loss: 0.6883103368567749
Epoch: 2 | Iteration number: [2850/4518] 63% | Training loss: 0.6883139661111329
Epoch: 2 | Iteration number: [2860/4518] 63% | Training loss: 0.6883136911408885
Epoch: 2 | Iteration number: [2870/4518] 63% | Training loss: 0.6883114061289133
Epoch: 2 | Iteration number: [2880/4518] 63% | Training loss: 0.6883116406699021
Epoch: 2 | Iteration number: [2890/4518] 63% | Training loss: 0.6883073891941651
Epoch: 2 | Iteration number: [2900/4518] 64% | Training loss: 0.688305695796835
Epoch: 2 | Iteration number: [2910/4518] 64% | Training loss: 0.6883077011894934
Epoch: 2 | Iteration number: [2920/4518] 64% | Training loss: 0.6883083925467648
Epoch: 2 | Iteration number: [2930/4518] 64% | Training loss: 0.6883074478688094
Epoch: 2 | Iteration number: [2940/4518] 65% | Training loss: 0.6883057676205019
Epoch: 2 | Iteration number: [2950/4518] 65% | Training loss: 0.6883029258857339
Epoch: 2 | Iteration number: [2960/4518] 65% | Training loss: 0.6883034270961542
Epoch: 2 | Iteration number: [2970/4518] 65% | Training loss: 0.6883011250784903
Epoch: 2 | Iteration number: [2980/4518] 65% | Training loss: 0.6883017234954258
Epoch: 2 | Iteration number: [2990/4518] 66% | Training loss: 0.6882960397862272
Epoch: 2 | Iteration number: [3000/4518] 66% | Training loss: 0.6882941331863404
Epoch: 2 | Iteration number: [3010/4518] 66% | Training loss: 0.6882904401253228
Epoch: 2 | Iteration number: [3020/4518] 66% | Training loss: 0.6882904428914682
Epoch: 2 | Iteration number: [3030/4518] 67% | Training loss: 0.6882888490217354
Epoch: 2 | Iteration number: [3040/4518] 67% | Training loss: 0.6882877710030267
Epoch: 2 | Iteration number: [3050/4518] 67% | Training loss: 0.6882849872503124
Epoch: 2 | Iteration number: [3060/4518] 67% | Training loss: 0.6882811327385746
Epoch: 2 | Iteration number: [3070/4518] 67% | Training loss: 0.6882813998464653
Epoch: 2 | Iteration number: [3080/4518] 68% | Training loss: 0.6882791874857692
Epoch: 2 | Iteration number: [3090/4518] 68% | Training loss: 0.6882819257314923
Epoch: 2 | Iteration number: [3100/4518] 68% | Training loss: 0.6882803841175572
Epoch: 2 | Iteration number: [3110/4518] 68% | Training loss: 0.6882796574060557
Epoch: 2 | Iteration number: [3120/4518] 69% | Training loss: 0.6882810056018523
Epoch: 2 | Iteration number: [3130/4518] 69% | Training loss: 0.6882803699269462
Epoch: 2 | Iteration number: [3140/4518] 69% | Training loss: 0.6882788504005237
Epoch: 2 | Iteration number: [3150/4518] 69% | Training loss: 0.6882779529359606
Epoch: 2 | Iteration number: [3160/4518] 69% | Training loss: 0.6882770740344555
Epoch: 2 | Iteration number: [3170/4518] 70% | Training loss: 0.6882772404500739
Epoch: 2 | Iteration number: [3180/4518] 70% | Training loss: 0.6882783013319819
Epoch: 2 | Iteration number: [3190/4518] 70% | Training loss: 0.6882750809566355
Epoch: 2 | Iteration number: [3200/4518] 70% | Training loss: 0.6882758906856179
Epoch: 2 | Iteration number: [3210/4518] 71% | Training loss: 0.6882744046943582
Epoch: 2 | Iteration number: [3220/4518] 71% | Training loss: 0.6882733861481921
Epoch: 2 | Iteration number: [3230/4518] 71% | Training loss: 0.6882725608422661
Epoch: 2 | Iteration number: [3240/4518] 71% | Training loss: 0.6882722697140258
Epoch: 2 | Iteration number: [3250/4518] 71% | Training loss: 0.6882743046283722
Epoch: 2 | Iteration number: [3260/4518] 72% | Training loss: 0.6882757705961999
Epoch: 2 | Iteration number: [3270/4518] 72% | Training loss: 0.6882749767113898
Epoch: 2 | Iteration number: [3280/4518] 72% | Training loss: 0.6882765793218846
Epoch: 2 | Iteration number: [3290/4518] 72% | Training loss: 0.6882782985917703
Epoch: 2 | Iteration number: [3300/4518] 73% | Training loss: 0.6882792949315273
Epoch: 2 | Iteration number: [3310/4518] 73% | Training loss: 0.688277643955006
Epoch: 2 | Iteration number: [3320/4518] 73% | Training loss: 0.6882760543600622
Epoch: 2 | Iteration number: [3330/4518] 73% | Training loss: 0.6882770771199876
Epoch: 2 | Iteration number: [3340/4518] 73% | Training loss: 0.6882779117829786
Epoch: 2 | Iteration number: [3350/4518] 74% | Training loss: 0.6882764572172022
Epoch: 2 | Iteration number: [3360/4518] 74% | Training loss: 0.6882738114822479
Epoch: 2 | Iteration number: [3370/4518] 74% | Training loss: 0.6882733089280058
Epoch: 2 | Iteration number: [3380/4518] 74% | Training loss: 0.6882727102062406
Epoch: 2 | Iteration number: [3390/4518] 75% | Training loss: 0.6882748601007602
Epoch: 2 | Iteration number: [3400/4518] 75% | Training loss: 0.6882730995206272
Epoch: 2 | Iteration number: [3410/4518] 75% | Training loss: 0.6882699164477262
Epoch: 2 | Iteration number: [3420/4518] 75% | Training loss: 0.6882691389113141
Epoch: 2 | Iteration number: [3430/4518] 75% | Training loss: 0.6882659489142304
Epoch: 2 | Iteration number: [3440/4518] 76% | Training loss: 0.6882660690954951
Epoch: 2 | Iteration number: [3450/4518] 76% | Training loss: 0.6882639301341513
Epoch: 2 | Iteration number: [3460/4518] 76% | Training loss: 0.688262531109628
Epoch: 2 | Iteration number: [3470/4518] 76% | Training loss: 0.6882577157501528
Epoch: 2 | Iteration number: [3480/4518] 77% | Training loss: 0.6882583642999331
Epoch: 2 | Iteration number: [3490/4518] 77% | Training loss: 0.6882540650217445
Epoch: 2 | Iteration number: [3500/4518] 77% | Training loss: 0.6882537408896855
Epoch: 2 | Iteration number: [3510/4518] 77% | Training loss: 0.6882538952888586
Epoch: 2 | Iteration number: [3520/4518] 77% | Training loss: 0.6882540002973242
Epoch: 2 | Iteration number: [3530/4518] 78% | Training loss: 0.6882543711419146
Epoch: 2 | Iteration number: [3540/4518] 78% | Training loss: 0.6882501871572376
Epoch: 2 | Iteration number: [3550/4518] 78% | Training loss: 0.6882488231088074
Epoch: 2 | Iteration number: [3560/4518] 78% | Training loss: 0.6882461566771014
Epoch: 2 | Iteration number: [3570/4518] 79% | Training loss: 0.6882468931147364
Epoch: 2 | Iteration number: [3580/4518] 79% | Training loss: 0.6882444872203486
Epoch: 2 | Iteration number: [3590/4518] 79% | Training loss: 0.6882442738186351
Epoch: 2 | Iteration number: [3600/4518] 79% | Training loss: 0.68824493550592
Epoch: 2 | Iteration number: [3610/4518] 79% | Training loss: 0.6882446713229626
Epoch: 2 | Iteration number: [3620/4518] 80% | Training loss: 0.6882423859274849
Epoch: 2 | Iteration number: [3630/4518] 80% | Training loss: 0.6882410666009939
Epoch: 2 | Iteration number: [3640/4518] 80% | Training loss: 0.6882369989385971
Epoch: 2 | Iteration number: [3650/4518] 80% | Training loss: 0.6882378669797558
Epoch: 2 | Iteration number: [3660/4518] 81% | Training loss: 0.6882346849135362
Epoch: 2 | Iteration number: [3670/4518] 81% | Training loss: 0.6882329267929296
Epoch: 2 | Iteration number: [3680/4518] 81% | Training loss: 0.6882309512923593
Epoch: 2 | Iteration number: [3690/4518] 81% | Training loss: 0.688229462124791
Epoch: 2 | Iteration number: [3700/4518] 81% | Training loss: 0.6882301369551066
Epoch: 2 | Iteration number: [3710/4518] 82% | Training loss: 0.6882292728379088
Epoch: 2 | Iteration number: [3720/4518] 82% | Training loss: 0.6882276583422897
Epoch: 2 | Iteration number: [3730/4518] 82% | Training loss: 0.6882275740838243
Epoch: 2 | Iteration number: [3740/4518] 82% | Training loss: 0.6882269875729148
Epoch: 2 | Iteration number: [3750/4518] 83% | Training loss: 0.6882275923411051
Epoch: 2 | Iteration number: [3760/4518] 83% | Training loss: 0.6882245870029673
Epoch: 2 | Iteration number: [3770/4518] 83% | Training loss: 0.6882252542820786
Epoch: 2 | Iteration number: [3780/4518] 83% | Training loss: 0.688220766959367
Epoch: 2 | Iteration number: [3790/4518] 83% | Training loss: 0.6882224137990645
Epoch: 2 | Iteration number: [3800/4518] 84% | Training loss: 0.6882229376937213
Epoch: 2 | Iteration number: [3810/4518] 84% | Training loss: 0.6882199293202929
Epoch: 2 | Iteration number: [3820/4518] 84% | Training loss: 0.688216481829813
Epoch: 2 | Iteration number: [3830/4518] 84% | Training loss: 0.6882163475449963
Epoch: 2 | Iteration number: [3840/4518] 84% | Training loss: 0.6882146809405337
Epoch: 2 | Iteration number: [3850/4518] 85% | Training loss: 0.6882129556637305
Epoch: 2 | Iteration number: [3860/4518] 85% | Training loss: 0.6882106948392996
Epoch: 2 | Iteration number: [3870/4518] 85% | Training loss: 0.6882144365045759
Epoch: 2 | Iteration number: [3880/4518] 85% | Training loss: 0.6882134346617865
Epoch: 2 | Iteration number: [3890/4518] 86% | Training loss: 0.6882155640879143
Epoch: 2 | Iteration number: [3900/4518] 86% | Training loss: 0.6882132660425626
Epoch: 2 | Iteration number: [3910/4518] 86% | Training loss: 0.6882128788534637
Epoch: 2 | Iteration number: [3920/4518] 86% | Training loss: 0.6882122909232061
Epoch: 2 | Iteration number: [3930/4518] 86% | Training loss: 0.6882096728447437
Epoch: 2 | Iteration number: [3940/4518] 87% | Training loss: 0.6882077797869135
Epoch: 2 | Iteration number: [3950/4518] 87% | Training loss: 0.6882044071939927
Epoch: 2 | Iteration number: [3960/4518] 87% | Training loss: 0.6882026761017664
Epoch: 2 | Iteration number: [3970/4518] 87% | Training loss: 0.688201192073918
Epoch: 2 | Iteration number: [3980/4518] 88% | Training loss: 0.688199727753898
Epoch: 2 | Iteration number: [3990/4518] 88% | Training loss: 0.688197649615749
Epoch: 2 | Iteration number: [4000/4518] 88% | Training loss: 0.6881980577409268
Epoch: 2 | Iteration number: [4010/4518] 88% | Training loss: 0.6881974019463223
Epoch: 2 | Iteration number: [4020/4518] 88% | Training loss: 0.6881968485033927
Epoch: 2 | Iteration number: [4030/4518] 89% | Training loss: 0.6881932164835871
Epoch: 2 | Iteration number: [4040/4518] 89% | Training loss: 0.6881907497744749
Epoch: 2 | Iteration number: [4050/4518] 89% | Training loss: 0.6881882516543071
Epoch: 2 | Iteration number: [4060/4518] 89% | Training loss: 0.6881866562395847
Epoch: 2 | Iteration number: [4070/4518] 90% | Training loss: 0.6881870651274407
Epoch: 2 | Iteration number: [4080/4518] 90% | Training loss: 0.688187735381664
Epoch: 2 | Iteration number: [4090/4518] 90% | Training loss: 0.6881876063521742
Epoch: 2 | Iteration number: [4100/4518] 90% | Training loss: 0.6881831303893066
Epoch: 2 | Iteration number: [4110/4518] 90% | Training loss: 0.6881827541801471
Epoch: 2 | Iteration number: [4120/4518] 91% | Training loss: 0.6881790492864488
Epoch: 2 | Iteration number: [4130/4518] 91% | Training loss: 0.6881755431252589
Epoch: 2 | Iteration number: [4140/4518] 91% | Training loss: 0.6881742755140083
Epoch: 2 | Iteration number: [4150/4518] 91% | Training loss: 0.6881739456825946
Epoch: 2 | Iteration number: [4160/4518] 92% | Training loss: 0.688173779200476
Epoch: 2 | Iteration number: [4170/4518] 92% | Training loss: 0.6881733583174735
Epoch: 2 | Iteration number: [4180/4518] 92% | Training loss: 0.6881722414607636
Epoch: 2 | Iteration number: [4190/4518] 92% | Training loss: 0.68816959490924
Epoch: 2 | Iteration number: [4200/4518] 92% | Training loss: 0.6881688292395501
Epoch: 2 | Iteration number: [4210/4518] 93% | Training loss: 0.688168522666016
Epoch: 2 | Iteration number: [4220/4518] 93% | Training loss: 0.688165479121615
Epoch: 2 | Iteration number: [4230/4518] 93% | Training loss: 0.6881628227712978
Epoch: 2 | Iteration number: [4240/4518] 93% | Training loss: 0.6881646827144443
Epoch: 2 | Iteration number: [4250/4518] 94% | Training loss: 0.6881619984121884
Epoch: 2 | Iteration number: [4260/4518] 94% | Training loss: 0.6881598525763677
Epoch: 2 | Iteration number: [4270/4518] 94% | Training loss: 0.6881577745952427
Epoch: 2 | Iteration number: [4280/4518] 94% | Training loss: 0.6881576074757308
Epoch: 2 | Iteration number: [4290/4518] 94% | Training loss: 0.6881553634896979
Epoch: 2 | Iteration number: [4300/4518] 95% | Training loss: 0.688156107400739
Epoch: 2 | Iteration number: [4310/4518] 95% | Training loss: 0.6881544955645249
Epoch: 2 | Iteration number: [4320/4518] 95% | Training loss: 0.6881511986117672
Epoch: 2 | Iteration number: [4330/4518] 95% | Training loss: 0.6881511309818638
Epoch: 2 | Iteration number: [4340/4518] 96% | Training loss: 0.6881518859605086
Epoch: 2 | Iteration number: [4350/4518] 96% | Training loss: 0.6881518874634271
Epoch: 2 | Iteration number: [4360/4518] 96% | Training loss: 0.688150640597584
Epoch: 2 | Iteration number: [4370/4518] 96% | Training loss: 0.6881507279807425
Epoch: 2 | Iteration number: [4380/4518] 96% | Training loss: 0.688149899189875
Epoch: 2 | Iteration number: [4390/4518] 97% | Training loss: 0.6881500584253689
Epoch: 2 | Iteration number: [4400/4518] 97% | Training loss: 0.688149771432985
Epoch: 2 | Iteration number: [4410/4518] 97% | Training loss: 0.6881486273406584
Epoch: 2 | Iteration number: [4420/4518] 97% | Training loss: 0.6881466175636015
Epoch: 2 | Iteration number: [4430/4518] 98% | Training loss: 0.6881445249101109
Epoch: 2 | Iteration number: [4440/4518] 98% | Training loss: 0.6881444373512053
Epoch: 2 | Iteration number: [4450/4518] 98% | Training loss: 0.6881420167376486
Epoch: 2 | Iteration number: [4460/4518] 98% | Training loss: 0.6881380506561476
Epoch: 2 | Iteration number: [4470/4518] 98% | Training loss: 0.6881380752295723
Epoch: 2 | Iteration number: [4480/4518] 99% | Training loss: 0.6881382227875292
Epoch: 2 | Iteration number: [4490/4518] 99% | Training loss: 0.6881386100183882
Epoch: 2 | Iteration number: [4500/4518] 99% | Training loss: 0.6881387945546045
Epoch: 2 | Iteration number: [4510/4518] 99% | Training loss: 0.6881394036989783

 End of epoch: 2 | Train Loss: 0.6879871758199888 | Training Time: 641 

 End of epoch: 2 | Eval Loss: 0.6906394350285433 | Evaluating Time: 17 
Epoch: 3 | Iteration number: [10/4518] 0% | Training loss: 0.7562837660312652
Epoch: 3 | Iteration number: [20/4518] 0% | Training loss: 0.7218858152627945
Epoch: 3 | Iteration number: [30/4518] 0% | Training loss: 0.7103760500748952
Epoch: 3 | Iteration number: [40/4518] 0% | Training loss: 0.7047847524285317
Epoch: 3 | Iteration number: [50/4518] 1% | Training loss: 0.701493068933487
Epoch: 3 | Iteration number: [60/4518] 1% | Training loss: 0.6992907146612803
Epoch: 3 | Iteration number: [70/4518] 1% | Training loss: 0.6976501226425171
Epoch: 3 | Iteration number: [80/4518] 1% | Training loss: 0.6965044125914573
Epoch: 3 | Iteration number: [90/4518] 1% | Training loss: 0.695461936129464
Epoch: 3 | Iteration number: [100/4518] 2% | Training loss: 0.6946129488945008
Epoch: 3 | Iteration number: [110/4518] 2% | Training loss: 0.6941188703883778
Epoch: 3 | Iteration number: [120/4518] 2% | Training loss: 0.6935505717992783
Epoch: 3 | Iteration number: [130/4518] 2% | Training loss: 0.6930961375053112
Epoch: 3 | Iteration number: [140/4518] 3% | Training loss: 0.6927293539047241
Epoch: 3 | Iteration number: [150/4518] 3% | Training loss: 0.6923620971043905
Epoch: 3 | Iteration number: [160/4518] 3% | Training loss: 0.6920527867972851
Epoch: 3 | Iteration number: [170/4518] 3% | Training loss: 0.6917556913460002
Epoch: 3 | Iteration number: [180/4518] 3% | Training loss: 0.6915368871556388
Epoch: 3 | Iteration number: [190/4518] 4% | Training loss: 0.6912877396533363
Epoch: 3 | Iteration number: [200/4518] 4% | Training loss: 0.6910850811004638
Epoch: 3 | Iteration number: [210/4518] 4% | Training loss: 0.6908818097341628
Epoch: 3 | Iteration number: [220/4518] 4% | Training loss: 0.6907115237279372
Epoch: 3 | Iteration number: [230/4518] 5% | Training loss: 0.6905299168565999
Epoch: 3 | Iteration number: [240/4518] 5% | Training loss: 0.690438774228096
Epoch: 3 | Iteration number: [250/4518] 5% | Training loss: 0.6903132038116455
Epoch: 3 | Iteration number: [260/4518] 5% | Training loss: 0.6902524086145254
Epoch: 3 | Iteration number: [270/4518] 5% | Training loss: 0.6901790687331447
Epoch: 3 | Iteration number: [280/4518] 6% | Training loss: 0.6900792756250926
Epoch: 3 | Iteration number: [290/4518] 6% | Training loss: 0.6900035171673216
Epoch: 3 | Iteration number: [300/4518] 6% | Training loss: 0.6899485182762146
Epoch: 3 | Iteration number: [310/4518] 6% | Training loss: 0.6898934802701396
Epoch: 3 | Iteration number: [320/4518] 7% | Training loss: 0.6898165995255112
Epoch: 3 | Iteration number: [330/4518] 7% | Training loss: 0.6897679811174219
Epoch: 3 | Iteration number: [340/4518] 7% | Training loss: 0.6896692658171935
Epoch: 3 | Iteration number: [350/4518] 7% | Training loss: 0.6896129141535078
Epoch: 3 | Iteration number: [360/4518] 7% | Training loss: 0.6895516258147028
Epoch: 3 | Iteration number: [370/4518] 8% | Training loss: 0.6895120010182664
Epoch: 3 | Iteration number: [380/4518] 8% | Training loss: 0.6894779512756749
Epoch: 3 | Iteration number: [390/4518] 8% | Training loss: 0.6894826985322512
Epoch: 3 | Iteration number: [400/4518] 8% | Training loss: 0.6894320532679558
Epoch: 3 | Iteration number: [410/4518] 9% | Training loss: 0.6893814177047916
Epoch: 3 | Iteration number: [420/4518] 9% | Training loss: 0.6893585566963468
Epoch: 3 | Iteration number: [430/4518] 9% | Training loss: 0.6893080794534018
Epoch: 3 | Iteration number: [440/4518] 9% | Training loss: 0.6892786501483483
Epoch: 3 | Iteration number: [450/4518] 9% | Training loss: 0.689250563648012
Epoch: 3 | Iteration number: [460/4518] 10% | Training loss: 0.6892152063224627
Epoch: 3 | Iteration number: [470/4518] 10% | Training loss: 0.6891302487951644
Epoch: 3 | Iteration number: [480/4518] 10% | Training loss: 0.6891127054889997
Epoch: 3 | Iteration number: [490/4518] 10% | Training loss: 0.6891057901236476
Epoch: 3 | Iteration number: [500/4518] 11% | Training loss: 0.6890918265581131
Epoch: 3 | Iteration number: [510/4518] 11% | Training loss: 0.6890846190499325
Epoch: 3 | Iteration number: [520/4518] 11% | Training loss: 0.6890657931566239
Epoch: 3 | Iteration number: [530/4518] 11% | Training loss: 0.6890526436409861
Epoch: 3 | Iteration number: [540/4518] 11% | Training loss: 0.689034218147949
Epoch: 3 | Iteration number: [550/4518] 12% | Training loss: 0.6890243189985101
Epoch: 3 | Iteration number: [560/4518] 12% | Training loss: 0.6890082361442702
Epoch: 3 | Iteration number: [570/4518] 12% | Training loss: 0.6889898640021943
Epoch: 3 | Iteration number: [580/4518] 12% | Training loss: 0.6889569884744183
Epoch: 3 | Iteration number: [590/4518] 13% | Training loss: 0.6889292294696227
Epoch: 3 | Iteration number: [600/4518] 13% | Training loss: 0.6888988803823789
Epoch: 3 | Iteration number: [610/4518] 13% | Training loss: 0.688862750960178
Epoch: 3 | Iteration number: [620/4518] 13% | Training loss: 0.6888466919622114
Epoch: 3 | Iteration number: [630/4518] 13% | Training loss: 0.6888265796123989
Epoch: 3 | Iteration number: [640/4518] 14% | Training loss: 0.6887916324660182
Epoch: 3 | Iteration number: [650/4518] 14% | Training loss: 0.6887776567385747
Epoch: 3 | Iteration number: [660/4518] 14% | Training loss: 0.6887547644701871
Epoch: 3 | Iteration number: [670/4518] 14% | Training loss: 0.6887386315794134
Epoch: 3 | Iteration number: [680/4518] 15% | Training loss: 0.6887281222378506
Epoch: 3 | Iteration number: [690/4518] 15% | Training loss: 0.6887022820935733
Epoch: 3 | Iteration number: [700/4518] 15% | Training loss: 0.6886827465466091
Epoch: 3 | Iteration number: [710/4518] 15% | Training loss: 0.6886777440427054
Epoch: 3 | Iteration number: [720/4518] 15% | Training loss: 0.6886556857162052
Epoch: 3 | Iteration number: [730/4518] 16% | Training loss: 0.688645773391201
Epoch: 3 | Iteration number: [740/4518] 16% | Training loss: 0.6886310489596548
Epoch: 3 | Iteration number: [750/4518] 16% | Training loss: 0.6886194607416789
Epoch: 3 | Iteration number: [760/4518] 16% | Training loss: 0.6886004444799925
Epoch: 3 | Iteration number: [770/4518] 17% | Training loss: 0.6885857057261776
Epoch: 3 | Iteration number: [780/4518] 17% | Training loss: 0.6885639590330613
Epoch: 3 | Iteration number: [790/4518] 17% | Training loss: 0.6885465429553502
Epoch: 3 | Iteration number: [800/4518] 17% | Training loss: 0.6885290368646383
Epoch: 3 | Iteration number: [810/4518] 17% | Training loss: 0.6885183933340473
Epoch: 3 | Iteration number: [820/4518] 18% | Training loss: 0.6885102493733894
Epoch: 3 | Iteration number: [830/4518] 18% | Training loss: 0.6885065199380898
Epoch: 3 | Iteration number: [840/4518] 18% | Training loss: 0.6884982981852122
Epoch: 3 | Iteration number: [850/4518] 18% | Training loss: 0.6884968253444222
Epoch: 3 | Iteration number: [860/4518] 19% | Training loss: 0.688484474739363
Epoch: 3 | Iteration number: [870/4518] 19% | Training loss: 0.6884717563788096
Epoch: 3 | Iteration number: [880/4518] 19% | Training loss: 0.6884718279269608
Epoch: 3 | Iteration number: [890/4518] 19% | Training loss: 0.688474397980765
Epoch: 3 | Iteration number: [900/4518] 19% | Training loss: 0.6884561134709253
Epoch: 3 | Iteration number: [910/4518] 20% | Training loss: 0.6884493519316662
Epoch: 3 | Iteration number: [920/4518] 20% | Training loss: 0.6884356834318327
Epoch: 3 | Iteration number: [930/4518] 20% | Training loss: 0.688431618803291
Epoch: 3 | Iteration number: [940/4518] 20% | Training loss: 0.6884178353116868
Epoch: 3 | Iteration number: [950/4518] 21% | Training loss: 0.6884201155210796
Epoch: 3 | Iteration number: [960/4518] 21% | Training loss: 0.6884072503695885
Epoch: 3 | Iteration number: [970/4518] 21% | Training loss: 0.6884048363597123
Epoch: 3 | Iteration number: [980/4518] 21% | Training loss: 0.6884024005155174
Epoch: 3 | Iteration number: [990/4518] 21% | Training loss: 0.6883989742910019
Epoch: 3 | Iteration number: [1000/4518] 22% | Training loss: 0.688397390961647
Epoch: 3 | Iteration number: [1010/4518] 22% | Training loss: 0.6883934387476137
Epoch: 3 | Iteration number: [1020/4518] 22% | Training loss: 0.6883826710429846
Epoch: 3 | Iteration number: [1030/4518] 22% | Training loss: 0.6883682748646412
Epoch: 3 | Iteration number: [1040/4518] 23% | Training loss: 0.6883645185484336
Epoch: 3 | Iteration number: [1050/4518] 23% | Training loss: 0.6883553239277431
Epoch: 3 | Iteration number: [1060/4518] 23% | Training loss: 0.6883395774746841
Epoch: 3 | Iteration number: [1070/4518] 23% | Training loss: 0.6883362347834578
Epoch: 3 | Iteration number: [1080/4518] 23% | Training loss: 0.6883423779849653
Epoch: 3 | Iteration number: [1090/4518] 24% | Training loss: 0.6883306619224199
Epoch: 3 | Iteration number: [1100/4518] 24% | Training loss: 0.6883126117424532
Epoch: 3 | Iteration number: [1110/4518] 24% | Training loss: 0.6883101360754924
Epoch: 3 | Iteration number: [1120/4518] 24% | Training loss: 0.6882984026734318
Epoch: 3 | Iteration number: [1130/4518] 25% | Training loss: 0.6882940098775172
Epoch: 3 | Iteration number: [1140/4518] 25% | Training loss: 0.68829176854669
Epoch: 3 | Iteration number: [1150/4518] 25% | Training loss: 0.688292872802071
Epoch: 3 | Iteration number: [1160/4518] 25% | Training loss: 0.6882930624587783
Epoch: 3 | Iteration number: [1170/4518] 25% | Training loss: 0.6882906391070439
Epoch: 3 | Iteration number: [1180/4518] 26% | Training loss: 0.6882843810622975
Epoch: 3 | Iteration number: [1190/4518] 26% | Training loss: 0.6882787234142047
Epoch: 3 | Iteration number: [1200/4518] 26% | Training loss: 0.6882778655489286
Epoch: 3 | Iteration number: [1210/4518] 26% | Training loss: 0.688270159792309
Epoch: 3 | Iteration number: [1220/4518] 27% | Training loss: 0.6882599558986602
Epoch: 3 | Iteration number: [1230/4518] 27% | Training loss: 0.688259679272892
Epoch: 3 | Iteration number: [1240/4518] 27% | Training loss: 0.6882569505322365
Epoch: 3 | Iteration number: [1250/4518] 27% | Training loss: 0.6882487470626831
Epoch: 3 | Iteration number: [1260/4518] 27% | Training loss: 0.6882428932757605
Epoch: 3 | Iteration number: [1270/4518] 28% | Training loss: 0.6882416376917381
Epoch: 3 | Iteration number: [1280/4518] 28% | Training loss: 0.688248126488179
Epoch: 3 | Iteration number: [1290/4518] 28% | Training loss: 0.6882503923981689
Epoch: 3 | Iteration number: [1300/4518] 28% | Training loss: 0.6882485736791905
Epoch: 3 | Iteration number: [1310/4518] 28% | Training loss: 0.6882464889806645
Epoch: 3 | Iteration number: [1320/4518] 29% | Training loss: 0.6882451647158825
Epoch: 3 | Iteration number: [1330/4518] 29% | Training loss: 0.6882521895985855
Epoch: 3 | Iteration number: [1340/4518] 29% | Training loss: 0.6882418910958874
Epoch: 3 | Iteration number: [1350/4518] 29% | Training loss: 0.6882443464685369
Epoch: 3 | Iteration number: [1360/4518] 30% | Training loss: 0.6882295816698495
Epoch: 3 | Iteration number: [1370/4518] 30% | Training loss: 0.6882159589850989
Epoch: 3 | Iteration number: [1380/4518] 30% | Training loss: 0.6882079996492552
Epoch: 3 | Iteration number: [1390/4518] 30% | Training loss: 0.6882049925464521
Epoch: 3 | Iteration number: [1400/4518] 30% | Training loss: 0.6882001560926437
Epoch: 3 | Iteration number: [1410/4518] 31% | Training loss: 0.6881936433890187
Epoch: 3 | Iteration number: [1420/4518] 31% | Training loss: 0.6881832580751097
Epoch: 3 | Iteration number: [1430/4518] 31% | Training loss: 0.6881778833749411
Epoch: 3 | Iteration number: [1440/4518] 31% | Training loss: 0.6881809419641892
Epoch: 3 | Iteration number: [1450/4518] 32% | Training loss: 0.6881815690007703
Epoch: 3 | Iteration number: [1460/4518] 32% | Training loss: 0.6881763107972603
Epoch: 3 | Iteration number: [1470/4518] 32% | Training loss: 0.688181626756175
Epoch: 3 | Iteration number: [1480/4518] 32% | Training loss: 0.6881769414286356
Epoch: 3 | Iteration number: [1490/4518] 32% | Training loss: 0.6881754571559445
Epoch: 3 | Iteration number: [1500/4518] 33% | Training loss: 0.6881734217007955
Epoch: 3 | Iteration number: [1510/4518] 33% | Training loss: 0.6881712775751455
Epoch: 3 | Iteration number: [1520/4518] 33% | Training loss: 0.6881638334769952
Epoch: 3 | Iteration number: [1530/4518] 33% | Training loss: 0.68816467807963
Epoch: 3 | Iteration number: [1540/4518] 34% | Training loss: 0.6881607894773607
Epoch: 3 | Iteration number: [1550/4518] 34% | Training loss: 0.6881588429020297
Epoch: 3 | Iteration number: [1560/4518] 34% | Training loss: 0.6881541366378466
Epoch: 3 | Iteration number: [1570/4518] 34% | Training loss: 0.6881548382294406
Epoch: 3 | Iteration number: [1580/4518] 34% | Training loss: 0.6881491140097002
Epoch: 3 | Iteration number: [1590/4518] 35% | Training loss: 0.6881420572973648
Epoch: 3 | Iteration number: [1600/4518] 35% | Training loss: 0.6881378925591707
Epoch: 3 | Iteration number: [1610/4518] 35% | Training loss: 0.6881336097021281
Epoch: 3 | Iteration number: [1620/4518] 35% | Training loss: 0.6881225763647645
Epoch: 3 | Iteration number: [1630/4518] 36% | Training loss: 0.6881160113709105
Epoch: 3 | Iteration number: [1640/4518] 36% | Training loss: 0.6881107957261364
Epoch: 3 | Iteration number: [1650/4518] 36% | Training loss: 0.6881065590453871
Epoch: 3 | Iteration number: [1660/4518] 36% | Training loss: 0.6881006825401123
Epoch: 3 | Iteration number: [1670/4518] 36% | Training loss: 0.6880984165711317
Epoch: 3 | Iteration number: [1680/4518] 37% | Training loss: 0.6880957296561627
Epoch: 3 | Iteration number: [1690/4518] 37% | Training loss: 0.6880921423082521
Epoch: 3 | Iteration number: [1700/4518] 37% | Training loss: 0.688096328588093
Epoch: 3 | Iteration number: [1710/4518] 37% | Training loss: 0.6880896301297417
Epoch: 3 | Iteration number: [1720/4518] 38% | Training loss: 0.6880872482477233
Epoch: 3 | Iteration number: [1730/4518] 38% | Training loss: 0.6880847115737165
Epoch: 3 | Iteration number: [1740/4518] 38% | Training loss: 0.6880870186391919
Epoch: 3 | Iteration number: [1750/4518] 38% | Training loss: 0.6880805634430477
Epoch: 3 | Iteration number: [1760/4518] 38% | Training loss: 0.6880782485685565
Epoch: 3 | Iteration number: [1770/4518] 39% | Training loss: 0.6880759247615512
Epoch: 3 | Iteration number: [1780/4518] 39% | Training loss: 0.6880668933806794
Epoch: 3 | Iteration number: [1790/4518] 39% | Training loss: 0.6880625096446309
Epoch: 3 | Iteration number: [1800/4518] 39% | Training loss: 0.6880617781149017
Epoch: 3 | Iteration number: [1810/4518] 40% | Training loss: 0.6880593489546802
Epoch: 3 | Iteration number: [1820/4518] 40% | Training loss: 0.6880536142613861
Epoch: 3 | Iteration number: [1830/4518] 40% | Training loss: 0.688058005362912
Epoch: 3 | Iteration number: [1840/4518] 40% | Training loss: 0.6880555801417516
Epoch: 3 | Iteration number: [1850/4518] 40% | Training loss: 0.6880452757912713
Epoch: 3 | Iteration number: [1860/4518] 41% | Training loss: 0.688043702834396
Epoch: 3 | Iteration number: [1870/4518] 41% | Training loss: 0.6880421749410782
Epoch: 3 | Iteration number: [1880/4518] 41% | Training loss: 0.6880392573298292
Epoch: 3 | Iteration number: [1890/4518] 41% | Training loss: 0.6880353596475389
Epoch: 3 | Iteration number: [1900/4518] 42% | Training loss: 0.6880352894569698
Epoch: 3 | Iteration number: [1910/4518] 42% | Training loss: 0.6880343253387831
Epoch: 3 | Iteration number: [1920/4518] 42% | Training loss: 0.6880325971171259
Epoch: 3 | Iteration number: [1930/4518] 42% | Training loss: 0.6880267033305193
Epoch: 3 | Iteration number: [1940/4518] 42% | Training loss: 0.6880201653721406
Epoch: 3 | Iteration number: [1950/4518] 43% | Training loss: 0.6880203849841386
Epoch: 3 | Iteration number: [1960/4518] 43% | Training loss: 0.6880184796999912
Epoch: 3 | Iteration number: [1970/4518] 43% | Training loss: 0.6880161922595223
Epoch: 3 | Iteration number: [1980/4518] 43% | Training loss: 0.6880109370055825
Epoch: 3 | Iteration number: [1990/4518] 44% | Training loss: 0.6880078669468961
Epoch: 3 | Iteration number: [2000/4518] 44% | Training loss: 0.6880055449604988
Epoch: 3 | Iteration number: [2010/4518] 44% | Training loss: 0.6880023937023694
Epoch: 3 | Iteration number: [2020/4518] 44% | Training loss: 0.6880005645574909
Epoch: 3 | Iteration number: [2030/4518] 44% | Training loss: 0.68799918775488
Epoch: 3 | Iteration number: [2040/4518] 45% | Training loss: 0.687995868073959
Epoch: 3 | Iteration number: [2050/4518] 45% | Training loss: 0.6879949318781131
Epoch: 3 | Iteration number: [2060/4518] 45% | Training loss: 0.6879877271872122
Epoch: 3 | Iteration number: [2070/4518] 45% | Training loss: 0.6879906772127474
Epoch: 3 | Iteration number: [2080/4518] 46% | Training loss: 0.6879809984507469
Epoch: 3 | Iteration number: [2090/4518] 46% | Training loss: 0.6879765075359618
Epoch: 3 | Iteration number: [2100/4518] 46% | Training loss: 0.6879695743890035
Epoch: 3 | Iteration number: [2110/4518] 46% | Training loss: 0.6879586856794583
Epoch: 3 | Iteration number: [2120/4518] 46% | Training loss: 0.6879565491428915
Epoch: 3 | Iteration number: [2130/4518] 47% | Training loss: 0.6879617698315723
Epoch: 3 | Iteration number: [2140/4518] 47% | Training loss: 0.6879603864155083
Epoch: 3 | Iteration number: [2150/4518] 47% | Training loss: 0.6879552903286247
Epoch: 3 | Iteration number: [2160/4518] 47% | Training loss: 0.6879505377124857
Epoch: 3 | Iteration number: [2170/4518] 48% | Training loss: 0.6879552434117014
Epoch: 3 | Iteration number: [2180/4518] 48% | Training loss: 0.6879542796983631
Epoch: 3 | Iteration number: [2190/4518] 48% | Training loss: 0.6879555759908946
Epoch: 3 | Iteration number: [2200/4518] 48% | Training loss: 0.6879545693776824
Epoch: 3 | Iteration number: [2210/4518] 48% | Training loss: 0.6879522385100973
Epoch: 3 | Iteration number: [2220/4518] 49% | Training loss: 0.6879499125588048
Epoch: 3 | Iteration number: [2230/4518] 49% | Training loss: 0.6879507416834211
Epoch: 3 | Iteration number: [2240/4518] 49% | Training loss: 0.6879471339551466
Epoch: 3 | Iteration number: [2250/4518] 49% | Training loss: 0.6879455284277598
Epoch: 3 | Iteration number: [2260/4518] 50% | Training loss: 0.6879444702536659
Epoch: 3 | Iteration number: [2270/4518] 50% | Training loss: 0.6879422783326472
Epoch: 3 | Iteration number: [2280/4518] 50% | Training loss: 0.6879381672070738
Epoch: 3 | Iteration number: [2290/4518] 50% | Training loss: 0.6879310908015639
Epoch: 3 | Iteration number: [2300/4518] 50% | Training loss: 0.6879222893714905
Epoch: 3 | Iteration number: [2310/4518] 51% | Training loss: 0.6879183662660194
Epoch: 3 | Iteration number: [2320/4518] 51% | Training loss: 0.6879200584672648
Epoch: 3 | Iteration number: [2330/4518] 51% | Training loss: 0.6879166391786076
Epoch: 3 | Iteration number: [2340/4518] 51% | Training loss: 0.6879096488412629
Epoch: 3 | Iteration number: [2350/4518] 52% | Training loss: 0.6879056785715387
Epoch: 3 | Iteration number: [2360/4518] 52% | Training loss: 0.6878990710539333
Epoch: 3 | Iteration number: [2370/4518] 52% | Training loss: 0.6878971898354559
Epoch: 3 | Iteration number: [2380/4518] 52% | Training loss: 0.6878935899303741
Epoch: 3 | Iteration number: [2390/4518] 52% | Training loss: 0.687891474977198
Epoch: 3 | Iteration number: [2400/4518] 53% | Training loss: 0.6878938166548808
Epoch: 3 | Iteration number: [2410/4518] 53% | Training loss: 0.6878929054094053
Epoch: 3 | Iteration number: [2420/4518] 53% | Training loss: 0.6878922965900958
Epoch: 3 | Iteration number: [2430/4518] 53% | Training loss: 0.6878894104388515
Epoch: 3 | Iteration number: [2440/4518] 54% | Training loss: 0.687893233265056
Epoch: 3 | Iteration number: [2450/4518] 54% | Training loss: 0.6878927695507906
Epoch: 3 | Iteration number: [2460/4518] 54% | Training loss: 0.6878904576466336
Epoch: 3 | Iteration number: [2470/4518] 54% | Training loss: 0.6878907070468795
Epoch: 3 | Iteration number: [2480/4518] 54% | Training loss: 0.6878957241292922
Epoch: 3 | Iteration number: [2490/4518] 55% | Training loss: 0.6878980633006039
Epoch: 3 | Iteration number: [2500/4518] 55% | Training loss: 0.687899888086319
Epoch: 3 | Iteration number: [2510/4518] 55% | Training loss: 0.6878981541114975
Epoch: 3 | Iteration number: [2520/4518] 55% | Training loss: 0.6878915828844857
Epoch: 3 | Iteration number: [2530/4518] 55% | Training loss: 0.6878919286219027
Epoch: 3 | Iteration number: [2540/4518] 56% | Training loss: 0.6878850779430135
Epoch: 3 | Iteration number: [2550/4518] 56% | Training loss: 0.6878843120733897
Epoch: 3 | Iteration number: [2560/4518] 56% | Training loss: 0.6878805492306128
Epoch: 3 | Iteration number: [2570/4518] 56% | Training loss: 0.6878797513501653
Epoch: 3 | Iteration number: [2580/4518] 57% | Training loss: 0.6878799970759902
Epoch: 3 | Iteration number: [2590/4518] 57% | Training loss: 0.6878796351692391
Epoch: 3 | Iteration number: [2600/4518] 57% | Training loss: 0.687880411858742
Epoch: 3 | Iteration number: [2610/4518] 57% | Training loss: 0.6878770297286154
Epoch: 3 | Iteration number: [2620/4518] 57% | Training loss: 0.6878740409175859
Epoch: 3 | Iteration number: [2630/4518] 58% | Training loss: 0.6878695497494687
Epoch: 3 | Iteration number: [2640/4518] 58% | Training loss: 0.6878662294059089
Epoch: 3 | Iteration number: [2650/4518] 58% | Training loss: 0.6878647290535693
Epoch: 3 | Iteration number: [2660/4518] 58% | Training loss: 0.6878611462232762
Epoch: 3 | Iteration number: [2670/4518] 59% | Training loss: 0.6878635039267023
Epoch: 3 | Iteration number: [2680/4518] 59% | Training loss: 0.6878628965189207
Epoch: 3 | Iteration number: [2690/4518] 59% | Training loss: 0.6878603587584868
Epoch: 3 | Iteration number: [2700/4518] 59% | Training loss: 0.6878565918074714
Epoch: 3 | Iteration number: [2710/4518] 59% | Training loss: 0.687856401200664
Epoch: 3 | Iteration number: [2720/4518] 60% | Training loss: 0.6878583006341668
Epoch: 3 | Iteration number: [2730/4518] 60% | Training loss: 0.6878580513891283
Epoch: 3 | Iteration number: [2740/4518] 60% | Training loss: 0.6878573552970468
Epoch: 3 | Iteration number: [2750/4518] 60% | Training loss: 0.6878561255064878
Epoch: 3 | Iteration number: [2760/4518] 61% | Training loss: 0.6878521908452545
Epoch: 3 | Iteration number: [2770/4518] 61% | Training loss: 0.6878506487026972
Epoch: 3 | Iteration number: [2780/4518] 61% | Training loss: 0.6878474672063649
Epoch: 3 | Iteration number: [2790/4518] 61% | Training loss: 0.6878451879520143
Epoch: 3 | Iteration number: [2800/4518] 61% | Training loss: 0.687848285479205
Epoch: 3 | Iteration number: [2810/4518] 62% | Training loss: 0.6878462805230422
Epoch: 3 | Iteration number: [2820/4518] 62% | Training loss: 0.6878393285663416
Epoch: 3 | Iteration number: [2830/4518] 62% | Training loss: 0.6878361582124191
Epoch: 3 | Iteration number: [2840/4518] 62% | Training loss: 0.6878356430732029
Epoch: 3 | Iteration number: [2850/4518] 63% | Training loss: 0.6878302087909297
Epoch: 3 | Iteration number: [2860/4518] 63% | Training loss: 0.6878262420425881
Epoch: 3 | Iteration number: [2870/4518] 63% | Training loss: 0.6878181508193864
Epoch: 3 | Iteration number: [2880/4518] 63% | Training loss: 0.6878162009434567
Epoch: 3 | Iteration number: [2890/4518] 63% | Training loss: 0.6878136536035571
Epoch: 3 | Iteration number: [2900/4518] 64% | Training loss: 0.6878144741263883
Epoch: 3 | Iteration number: [2910/4518] 64% | Training loss: 0.6878128481279944
Epoch: 3 | Iteration number: [2920/4518] 64% | Training loss: 0.6878110080140911
Epoch: 3 | Iteration number: [2930/4518] 64% | Training loss: 0.6878074559538845
Epoch: 3 | Iteration number: [2940/4518] 65% | Training loss: 0.6878017746266865
Epoch: 3 | Iteration number: [2950/4518] 65% | Training loss: 0.6878013662362503
Epoch: 3 | Iteration number: [2960/4518] 65% | Training loss: 0.6878003359243676
Epoch: 3 | Iteration number: [2970/4518] 65% | Training loss: 0.6877966701984406
Epoch: 3 | Iteration number: [2980/4518] 65% | Training loss: 0.6877968585331168
Epoch: 3 | Iteration number: [2990/4518] 66% | Training loss: 0.6877976995846101
Epoch: 3 | Iteration number: [3000/4518] 66% | Training loss: 0.687798078139623
Epoch: 3 | Iteration number: [3010/4518] 66% | Training loss: 0.6877975878525414
Epoch: 3 | Iteration number: [3020/4518] 66% | Training loss: 0.6877965917453072
Epoch: 3 | Iteration number: [3030/4518] 67% | Training loss: 0.6877962511561492
Epoch: 3 | Iteration number: [3040/4518] 67% | Training loss: 0.687792626356608
Epoch: 3 | Iteration number: [3050/4518] 67% | Training loss: 0.6877920585773031
Epoch: 3 | Iteration number: [3060/4518] 67% | Training loss: 0.6877913946224973
Epoch: 3 | Iteration number: [3070/4518] 67% | Training loss: 0.6877908179736681
Epoch: 3 | Iteration number: [3080/4518] 68% | Training loss: 0.6877871709404053
Epoch: 3 | Iteration number: [3090/4518] 68% | Training loss: 0.6877864133964464
Epoch: 3 | Iteration number: [3100/4518] 68% | Training loss: 0.6877855656223912
Epoch: 3 | Iteration number: [3110/4518] 68% | Training loss: 0.6877850955322241
Epoch: 3 | Iteration number: [3120/4518] 69% | Training loss: 0.6877841239174207
Epoch: 3 | Iteration number: [3130/4518] 69% | Training loss: 0.6877841942988264
Epoch: 3 | Iteration number: [3140/4518] 69% | Training loss: 0.6877861477766827
Epoch: 3 | Iteration number: [3150/4518] 69% | Training loss: 0.6877857278831422
Epoch: 3 | Iteration number: [3160/4518] 69% | Training loss: 0.6877818274724332
Epoch: 3 | Iteration number: [3170/4518] 70% | Training loss: 0.687782168708013
Epoch: 3 | Iteration number: [3180/4518] 70% | Training loss: 0.6877833109231865
Epoch: 3 | Iteration number: [3190/4518] 70% | Training loss: 0.6877790090806059
Epoch: 3 | Iteration number: [3200/4518] 70% | Training loss: 0.6877707496285439
Epoch: 3 | Iteration number: [3210/4518] 71% | Training loss: 0.6877712163226998
Epoch: 3 | Iteration number: [3220/4518] 71% | Training loss: 0.687770208142559
Epoch: 3 | Iteration number: [3230/4518] 71% | Training loss: 0.6877677008832571
Epoch: 3 | Iteration number: [3240/4518] 71% | Training loss: 0.6877689257632067
Epoch: 3 | Iteration number: [3250/4518] 71% | Training loss: 0.6877688923982473
Epoch: 3 | Iteration number: [3260/4518] 72% | Training loss: 0.6877672710484523
Epoch: 3 | Iteration number: [3270/4518] 72% | Training loss: 0.6877675982607978
Epoch: 3 | Iteration number: [3280/4518] 72% | Training loss: 0.687764884658703
Epoch: 3 | Iteration number: [3290/4518] 72% | Training loss: 0.687764559092855
Epoch: 3 | Iteration number: [3300/4518] 73% | Training loss: 0.6877659758835127
Epoch: 3 | Iteration number: [3310/4518] 73% | Training loss: 0.6877634284719599
Epoch: 3 | Iteration number: [3320/4518] 73% | Training loss: 0.6877640809459858
Epoch: 3 | Iteration number: [3330/4518] 73% | Training loss: 0.6877604195663521
Epoch: 3 | Iteration number: [3340/4518] 73% | Training loss: 0.6877594104962435
Epoch: 3 | Iteration number: [3350/4518] 74% | Training loss: 0.687757822737765
Epoch: 3 | Iteration number: [3360/4518] 74% | Training loss: 0.6877529489142554
Epoch: 3 | Iteration number: [3370/4518] 74% | Training loss: 0.6877545537686843
Epoch: 3 | Iteration number: [3380/4518] 74% | Training loss: 0.687751521055515
Epoch: 3 | Iteration number: [3390/4518] 75% | Training loss: 0.6877488394578298
Epoch: 3 | Iteration number: [3400/4518] 75% | Training loss: 0.6877506728908594
Epoch: 3 | Iteration number: [3410/4518] 75% | Training loss: 0.6877503570223833
Epoch: 3 | Iteration number: [3420/4518] 75% | Training loss: 0.6877532453564873
Epoch: 3 | Iteration number: [3430/4518] 75% | Training loss: 0.6877521616898195
Epoch: 3 | Iteration number: [3440/4518] 76% | Training loss: 0.6877557378695455
Epoch: 3 | Iteration number: [3450/4518] 76% | Training loss: 0.6877539310766303
Epoch: 3 | Iteration number: [3460/4518] 76% | Training loss: 0.6877513212620179
Epoch: 3 | Iteration number: [3470/4518] 76% | Training loss: 0.6877464536974685
Epoch: 3 | Iteration number: [3480/4518] 77% | Training loss: 0.6877436901817376
Epoch: 3 | Iteration number: [3490/4518] 77% | Training loss: 0.6877435596078036
Epoch: 3 | Iteration number: [3500/4518] 77% | Training loss: 0.6877429850782667
Epoch: 3 | Iteration number: [3510/4518] 77% | Training loss: 0.6877437687157906
Epoch: 3 | Iteration number: [3520/4518] 77% | Training loss: 0.6877404951067133
Epoch: 3 | Iteration number: [3530/4518] 78% | Training loss: 0.6877386902108071
Epoch: 3 | Iteration number: [3540/4518] 78% | Training loss: 0.6877390478795531
Epoch: 3 | Iteration number: [3550/4518] 78% | Training loss: 0.6877371590070321
Epoch: 3 | Iteration number: [3560/4518] 78% | Training loss: 0.6877357344279128
Epoch: 3 | Iteration number: [3570/4518] 79% | Training loss: 0.6877386801216114
Epoch: 3 | Iteration number: [3580/4518] 79% | Training loss: 0.6877391830003461
Epoch: 3 | Iteration number: [3590/4518] 79% | Training loss: 0.6877373520378283
Epoch: 3 | Iteration number: [3600/4518] 79% | Training loss: 0.6877387754287985
Epoch: 3 | Iteration number: [3610/4518] 79% | Training loss: 0.6877357014823818
Epoch: 3 | Iteration number: [3620/4518] 80% | Training loss: 0.6877348606099082
Epoch: 3 | Iteration number: [3630/4518] 80% | Training loss: 0.6877342076176782
Epoch: 3 | Iteration number: [3640/4518] 80% | Training loss: 0.6877340284513903
Epoch: 3 | Iteration number: [3650/4518] 80% | Training loss: 0.6877282378444933
Epoch: 3 | Iteration number: [3660/4518] 81% | Training loss: 0.687732615268947
Epoch: 3 | Iteration number: [3670/4518] 81% | Training loss: 0.6877336697454999
Epoch: 3 | Iteration number: [3680/4518] 81% | Training loss: 0.6877331918834344
Epoch: 3 | Iteration number: [3690/4518] 81% | Training loss: 0.6877298903336047
Epoch: 3 | Iteration number: [3700/4518] 81% | Training loss: 0.6877287400413203
Epoch: 3 | Iteration number: [3710/4518] 82% | Training loss: 0.687726820961163
Epoch: 3 | Iteration number: [3720/4518] 82% | Training loss: 0.6877264875558114
Epoch: 3 | Iteration number: [3730/4518] 82% | Training loss: 0.6877248400018299
Epoch: 3 | Iteration number: [3740/4518] 82% | Training loss: 0.687724387757281
Epoch: 3 | Iteration number: [3750/4518] 83% | Training loss: 0.6877227914174397
Epoch: 3 | Iteration number: [3760/4518] 83% | Training loss: 0.6877255724941163
Epoch: 3 | Iteration number: [3770/4518] 83% | Training loss: 0.6877240582233398
Epoch: 3 | Iteration number: [3780/4518] 83% | Training loss: 0.6877186934468608
Epoch: 3 | Iteration number: [3790/4518] 83% | Training loss: 0.6877184051007897
Epoch: 3 | Iteration number: [3800/4518] 84% | Training loss: 0.6877176703120533
Epoch: 3 | Iteration number: [3810/4518] 84% | Training loss: 0.6877168993311604
Epoch: 3 | Iteration number: [3820/4518] 84% | Training loss: 0.6877134588688456
Epoch: 3 | Iteration number: [3830/4518] 84% | Training loss: 0.687711410329485
Epoch: 3 | Iteration number: [3840/4518] 84% | Training loss: 0.6877113307050119
Epoch: 3 | Iteration number: [3850/4518] 85% | Training loss: 0.6877115653087567
Epoch: 3 | Iteration number: [3860/4518] 85% | Training loss: 0.6877134119290762
Epoch: 3 | Iteration number: [3870/4518] 85% | Training loss: 0.6877127050121318
Epoch: 3 | Iteration number: [3880/4518] 85% | Training loss: 0.6877108530285432
Epoch: 3 | Iteration number: [3890/4518] 86% | Training loss: 0.6877096225639235
Epoch: 3 | Iteration number: [3900/4518] 86% | Training loss: 0.6877099195351968
Epoch: 3 | Iteration number: [3910/4518] 86% | Training loss: 0.6877117675741006
Epoch: 3 | Iteration number: [3920/4518] 86% | Training loss: 0.6877130098945025
Epoch: 3 | Iteration number: [3930/4518] 86% | Training loss: 0.6877131122365859
Epoch: 3 | Iteration number: [3940/4518] 87% | Training loss: 0.687708893206519
Epoch: 3 | Iteration number: [3950/4518] 87% | Training loss: 0.6877097821990146
Epoch: 3 | Iteration number: [3960/4518] 87% | Training loss: 0.6877060407038891
Epoch: 3 | Iteration number: [3970/4518] 87% | Training loss: 0.6877050463889047
Epoch: 3 | Iteration number: [3980/4518] 88% | Training loss: 0.6877046869028752
Epoch: 3 | Iteration number: [3990/4518] 88% | Training loss: 0.6877043903620919
Epoch: 3 | Iteration number: [4000/4518] 88% | Training loss: 0.687703462049365
Epoch: 3 | Iteration number: [4010/4518] 88% | Training loss: 0.687704137450739
Epoch: 3 | Iteration number: [4020/4518] 88% | Training loss: 0.6877062057677786
Epoch: 3 | Iteration number: [4030/4518] 89% | Training loss: 0.6877061948734833
Epoch: 3 | Iteration number: [4040/4518] 89% | Training loss: 0.687708622349961
Epoch: 3 | Iteration number: [4050/4518] 89% | Training loss: 0.6877106187814548
Epoch: 3 | Iteration number: [4060/4518] 89% | Training loss: 0.6877083561250141
Epoch: 3 | Iteration number: [4070/4518] 90% | Training loss: 0.6877092788787673
Epoch: 3 | Iteration number: [4080/4518] 90% | Training loss: 0.6877095195154349
Epoch: 3 | Iteration number: [4090/4518] 90% | Training loss: 0.6877069394716715
Epoch: 3 | Iteration number: [4100/4518] 90% | Training loss: 0.68770469642267
Epoch: 3 | Iteration number: [4110/4518] 90% | Training loss: 0.6877049723970919
Epoch: 3 | Iteration number: [4120/4518] 91% | Training loss: 0.6877010457290029
Epoch: 3 | Iteration number: [4130/4518] 91% | Training loss: 0.687698847777041
Epoch: 3 | Iteration number: [4140/4518] 91% | Training loss: 0.6877000461310004
Epoch: 3 | Iteration number: [4150/4518] 91% | Training loss: 0.6877013182783701
Epoch: 3 | Iteration number: [4160/4518] 92% | Training loss: 0.68770266943253
Epoch: 3 | Iteration number: [4170/4518] 92% | Training loss: 0.68770094082224
Epoch: 3 | Iteration number: [4180/4518] 92% | Training loss: 0.6877010773100921
Epoch: 3 | Iteration number: [4190/4518] 92% | Training loss: 0.6876999065671161
Epoch: 3 | Iteration number: [4200/4518] 92% | Training loss: 0.6876979923674038
Epoch: 3 | Iteration number: [4210/4518] 93% | Training loss: 0.6876979593992799
Epoch: 3 | Iteration number: [4220/4518] 93% | Training loss: 0.6876949613269472
Epoch: 3 | Iteration number: [4230/4518] 93% | Training loss: 0.6876949519834902
Epoch: 3 | Iteration number: [4240/4518] 93% | Training loss: 0.687695028407956
Epoch: 3 | Iteration number: [4250/4518] 94% | Training loss: 0.6876937533967635
Epoch: 3 | Iteration number: [4260/4518] 94% | Training loss: 0.6876923161773055
Epoch: 3 | Iteration number: [4270/4518] 94% | Training loss: 0.6876893372250943
Epoch: 3 | Iteration number: [4280/4518] 94% | Training loss: 0.6876897356638284
Epoch: 3 | Iteration number: [4290/4518] 94% | Training loss: 0.687689361191574
Epoch: 3 | Iteration number: [4300/4518] 95% | Training loss: 0.6876867583463359
Epoch: 3 | Iteration number: [4310/4518] 95% | Training loss: 0.6876878798837728
Epoch: 3 | Iteration number: [4320/4518] 95% | Training loss: 0.6876857191186261
Epoch: 3 | Iteration number: [4330/4518] 95% | Training loss: 0.6876847076636263
Epoch: 3 | Iteration number: [4340/4518] 96% | Training loss: 0.6876855412111854
Epoch: 3 | Iteration number: [4350/4518] 96% | Training loss: 0.6876828847534355
Epoch: 3 | Iteration number: [4360/4518] 96% | Training loss: 0.6876821456015657
Epoch: 3 | Iteration number: [4370/4518] 96% | Training loss: 0.6876800612808638
Epoch: 3 | Iteration number: [4380/4518] 96% | Training loss: 0.6876785855315047
Epoch: 3 | Iteration number: [4390/4518] 97% | Training loss: 0.6876786131386333
Epoch: 3 | Iteration number: [4400/4518] 97% | Training loss: 0.687679301649332
Epoch: 3 | Iteration number: [4410/4518] 97% | Training loss: 0.6876819893210924
Epoch: 3 | Iteration number: [4420/4518] 97% | Training loss: 0.687682316354497
Epoch: 3 | Iteration number: [4430/4518] 98% | Training loss: 0.6876827442080926
Epoch: 3 | Iteration number: [4440/4518] 98% | Training loss: 0.6876798448261914
Epoch: 3 | Iteration number: [4450/4518] 98% | Training loss: 0.6876769563723146
Epoch: 3 | Iteration number: [4460/4518] 98% | Training loss: 0.6876789666211124
Epoch: 3 | Iteration number: [4470/4518] 98% | Training loss: 0.6876796419988542
Epoch: 3 | Iteration number: [4480/4518] 99% | Training loss: 0.6876800179880644
Epoch: 3 | Iteration number: [4490/4518] 99% | Training loss: 0.6876817798561402
Epoch: 3 | Iteration number: [4500/4518] 99% | Training loss: 0.6876826742225223
Epoch: 3 | Iteration number: [4510/4518] 99% | Training loss: 0.6876786033885177

 End of epoch: 3 | Train Loss: 0.6875267241211157 | Training Time: 643 

 End of epoch: 3 | Eval Loss: 0.6906288035061895 | Evaluating Time: 17 
Epoch: 4 | Iteration number: [10/4518] 0% | Training loss: 0.7573520183563233
Epoch: 4 | Iteration number: [20/4518] 0% | Training loss: 0.7226677477359772
Epoch: 4 | Iteration number: [30/4518] 0% | Training loss: 0.7107743601004283
Epoch: 4 | Iteration number: [40/4518] 0% | Training loss: 0.7048363789916039
Epoch: 4 | Iteration number: [50/4518] 1% | Training loss: 0.7012756562232971
Epoch: 4 | Iteration number: [60/4518] 1% | Training loss: 0.6990402529637019
Epoch: 4 | Iteration number: [70/4518] 1% | Training loss: 0.6972302062170846
Epoch: 4 | Iteration number: [80/4518] 1% | Training loss: 0.696018148213625
Epoch: 4 | Iteration number: [90/4518] 1% | Training loss: 0.6950825505786472
Epoch: 4 | Iteration number: [100/4518] 2% | Training loss: 0.6941425806283951
Epoch: 4 | Iteration number: [110/4518] 2% | Training loss: 0.6934106918898496
Epoch: 4 | Iteration number: [120/4518] 2% | Training loss: 0.6929558485746383
Epoch: 4 | Iteration number: [130/4518] 2% | Training loss: 0.6924993693828583
Epoch: 4 | Iteration number: [140/4518] 3% | Training loss: 0.6921565221888678
Epoch: 4 | Iteration number: [150/4518] 3% | Training loss: 0.6918367807070415
Epoch: 4 | Iteration number: [160/4518] 3% | Training loss: 0.69155189730227
Epoch: 4 | Iteration number: [170/4518] 3% | Training loss: 0.6913085029405706
Epoch: 4 | Iteration number: [180/4518] 3% | Training loss: 0.6910252468453513
Epoch: 4 | Iteration number: [190/4518] 4% | Training loss: 0.690873584621831
Epoch: 4 | Iteration number: [200/4518] 4% | Training loss: 0.6906786149740219
Epoch: 4 | Iteration number: [210/4518] 4% | Training loss: 0.6905276465983617
Epoch: 4 | Iteration number: [220/4518] 4% | Training loss: 0.6903946933421221
Epoch: 4 | Iteration number: [230/4518] 5% | Training loss: 0.6902331305586773
Epoch: 4 | Iteration number: [240/4518] 5% | Training loss: 0.6901082264880339
Epoch: 4 | Iteration number: [250/4518] 5% | Training loss: 0.6900059893131256
Epoch: 4 | Iteration number: [260/4518] 5% | Training loss: 0.689914025251682
Epoch: 4 | Iteration number: [270/4518] 5% | Training loss: 0.6898607300387488
Epoch: 4 | Iteration number: [280/4518] 6% | Training loss: 0.689759440932955
Epoch: 4 | Iteration number: [290/4518] 6% | Training loss: 0.6896834778374639
Epoch: 4 | Iteration number: [300/4518] 6% | Training loss: 0.689602014819781
Epoch: 4 | Iteration number: [310/4518] 6% | Training loss: 0.6895453260790917
Epoch: 4 | Iteration number: [320/4518] 7% | Training loss: 0.6895080564543605
Epoch: 4 | Iteration number: [330/4518] 7% | Training loss: 0.6894637662352938
Epoch: 4 | Iteration number: [340/4518] 7% | Training loss: 0.6893950064392651
Epoch: 4 | Iteration number: [350/4518] 7% | Training loss: 0.6893523444448199
Epoch: 4 | Iteration number: [360/4518] 7% | Training loss: 0.6892764887875981
Epoch: 4 | Iteration number: [370/4518] 8% | Training loss: 0.68925550370603
Epoch: 4 | Iteration number: [380/4518] 8% | Training loss: 0.6891815977661233
Epoch: 4 | Iteration number: [390/4518] 8% | Training loss: 0.6891279727984697
Epoch: 4 | Iteration number: [400/4518] 8% | Training loss: 0.6890865013003349
Epoch: 4 | Iteration number: [410/4518] 9% | Training loss: 0.6890287471980583
Epoch: 4 | Iteration number: [420/4518] 9% | Training loss: 0.6889898398092815
Epoch: 4 | Iteration number: [430/4518] 9% | Training loss: 0.6889716158079546
Epoch: 4 | Iteration number: [440/4518] 9% | Training loss: 0.6889071330428124
Epoch: 4 | Iteration number: [450/4518] 9% | Training loss: 0.68886959777938
Epoch: 4 | Iteration number: [460/4518] 10% | Training loss: 0.6888302847095158
Epoch: 4 | Iteration number: [470/4518] 10% | Training loss: 0.6888120898540984
Epoch: 4 | Iteration number: [480/4518] 10% | Training loss: 0.6887639082968235
Epoch: 4 | Iteration number: [490/4518] 10% | Training loss: 0.6887032743619412
Epoch: 4 | Iteration number: [500/4518] 11% | Training loss: 0.6886976872682571
Epoch: 4 | Iteration number: [510/4518] 11% | Training loss: 0.6886680985198301
Epoch: 4 | Iteration number: [520/4518] 11% | Training loss: 0.6886389304812138
Epoch: 4 | Iteration number: [530/4518] 11% | Training loss: 0.6885814982765126
Epoch: 4 | Iteration number: [540/4518] 11% | Training loss: 0.6885457388780735
Epoch: 4 | Iteration number: [550/4518] 12% | Training loss: 0.6885367907177318
Epoch: 4 | Iteration number: [560/4518] 12% | Training loss: 0.6885347718639033
Epoch: 4 | Iteration number: [570/4518] 12% | Training loss: 0.6885073558280342
Epoch: 4 | Iteration number: [580/4518] 12% | Training loss: 0.6884741312470929
Epoch: 4 | Iteration number: [590/4518] 13% | Training loss: 0.6884636500124204
Epoch: 4 | Iteration number: [600/4518] 13% | Training loss: 0.6884230403105418
Epoch: 4 | Iteration number: [610/4518] 13% | Training loss: 0.688397258813264
Epoch: 4 | Iteration number: [620/4518] 13% | Training loss: 0.6883670757855138
Epoch: 4 | Iteration number: [630/4518] 13% | Training loss: 0.6883478776803093
Epoch: 4 | Iteration number: [640/4518] 14% | Training loss: 0.6883463630452752
Epoch: 4 | Iteration number: [650/4518] 14% | Training loss: 0.688329000381323
Epoch: 4 | Iteration number: [660/4518] 14% | Training loss: 0.6883050308083043
Epoch: 4 | Iteration number: [670/4518] 14% | Training loss: 0.6882855204503928
Epoch: 4 | Iteration number: [680/4518] 15% | Training loss: 0.688289277343189
Epoch: 4 | Iteration number: [690/4518] 15% | Training loss: 0.688286585825077
Epoch: 4 | Iteration number: [700/4518] 15% | Training loss: 0.6882872214487621
Epoch: 4 | Iteration number: [710/4518] 15% | Training loss: 0.6882595458500822
Epoch: 4 | Iteration number: [720/4518] 15% | Training loss: 0.6882380613850223
Epoch: 4 | Iteration number: [730/4518] 16% | Training loss: 0.688246091669553
Epoch: 4 | Iteration number: [740/4518] 16% | Training loss: 0.688237272243242
Epoch: 4 | Iteration number: [750/4518] 16% | Training loss: 0.6882304573059081
Epoch: 4 | Iteration number: [760/4518] 16% | Training loss: 0.6882313483639767
Epoch: 4 | Iteration number: [770/4518] 17% | Training loss: 0.6882293914045606
Epoch: 4 | Iteration number: [780/4518] 17% | Training loss: 0.6882153856448638
Epoch: 4 | Iteration number: [790/4518] 17% | Training loss: 0.6882144418698323
Epoch: 4 | Iteration number: [800/4518] 17% | Training loss: 0.6882084503769874
Epoch: 4 | Iteration number: [810/4518] 17% | Training loss: 0.6881917621618435
Epoch: 4 | Iteration number: [820/4518] 18% | Training loss: 0.6881916920586331
Epoch: 4 | Iteration number: [830/4518] 18% | Training loss: 0.6881674491497407
Epoch: 4 | Iteration number: [840/4518] 18% | Training loss: 0.6881622423018728
Epoch: 4 | Iteration number: [850/4518] 18% | Training loss: 0.6881423736319823
Epoch: 4 | Iteration number: [860/4518] 19% | Training loss: 0.6881440916726755
Epoch: 4 | Iteration number: [870/4518] 19% | Training loss: 0.688134905935704
Epoch: 4 | Iteration number: [880/4518] 19% | Training loss: 0.6881222954527898
Epoch: 4 | Iteration number: [890/4518] 19% | Training loss: 0.6881155999858728
Epoch: 4 | Iteration number: [900/4518] 19% | Training loss: 0.6881015731228722
Epoch: 4 | Iteration number: [910/4518] 20% | Training loss: 0.6881017166179615
Epoch: 4 | Iteration number: [920/4518] 20% | Training loss: 0.688087897391423
Epoch: 4 | Iteration number: [930/4518] 20% | Training loss: 0.6880710787670586
Epoch: 4 | Iteration number: [940/4518] 20% | Training loss: 0.6880630122220263
Epoch: 4 | Iteration number: [950/4518] 21% | Training loss: 0.6880628444019117
Epoch: 4 | Iteration number: [960/4518] 21% | Training loss: 0.6880489045133193
Epoch: 4 | Iteration number: [970/4518] 21% | Training loss: 0.6880430313115268
Epoch: 4 | Iteration number: [980/4518] 21% | Training loss: 0.6880403762569233
Epoch: 4 | Iteration number: [990/4518] 21% | Training loss: 0.688032535772131
Epoch: 4 | Iteration number: [1000/4518] 22% | Training loss: 0.6880244475007057
Epoch: 4 | Iteration number: [1010/4518] 22% | Training loss: 0.6880112049013081
Epoch: 4 | Iteration number: [1020/4518] 22% | Training loss: 0.6880116292658974
Epoch: 4 | Iteration number: [1030/4518] 22% | Training loss: 0.6880088617500749
Epoch: 4 | Iteration number: [1040/4518] 23% | Training loss: 0.6879990958823607
Epoch: 4 | Iteration number: [1050/4518] 23% | Training loss: 0.6879833000614529
Epoch: 4 | Iteration number: [1060/4518] 23% | Training loss: 0.6879704090221873
Epoch: 4 | Iteration number: [1070/4518] 23% | Training loss: 0.6879641887740554
Epoch: 4 | Iteration number: [1080/4518] 23% | Training loss: 0.6879475150395322
Epoch: 4 | Iteration number: [1090/4518] 24% | Training loss: 0.687949461510422
Epoch: 4 | Iteration number: [1100/4518] 24% | Training loss: 0.6879432408376174
Epoch: 4 | Iteration number: [1110/4518] 24% | Training loss: 0.6879342478674811
Epoch: 4 | Iteration number: [1120/4518] 24% | Training loss: 0.6879312729729073
Epoch: 4 | Iteration number: [1130/4518] 25% | Training loss: 0.6879287469176064
Epoch: 4 | Iteration number: [1140/4518] 25% | Training loss: 0.6879257119538491
Epoch: 4 | Iteration number: [1150/4518] 25% | Training loss: 0.6879248718593431
Epoch: 4 | Iteration number: [1160/4518] 25% | Training loss: 0.6879279387922123
Epoch: 4 | Iteration number: [1170/4518] 25% | Training loss: 0.6879340387817122
Epoch: 4 | Iteration number: [1180/4518] 26% | Training loss: 0.6879171552294392
Epoch: 4 | Iteration number: [1190/4518] 26% | Training loss: 0.6879153492070046
Epoch: 4 | Iteration number: [1200/4518] 26% | Training loss: 0.6879150818288327
Epoch: 4 | Iteration number: [1210/4518] 26% | Training loss: 0.6879065160908975
Epoch: 4 | Iteration number: [1220/4518] 27% | Training loss: 0.6879016071557998
Epoch: 4 | Iteration number: [1230/4518] 27% | Training loss: 0.687896829746603
Epoch: 4 | Iteration number: [1240/4518] 27% | Training loss: 0.6878962679255394
Epoch: 4 | Iteration number: [1250/4518] 27% | Training loss: 0.6878885451316834
Epoch: 4 | Iteration number: [1260/4518] 27% | Training loss: 0.6878895337146426
Epoch: 4 | Iteration number: [1270/4518] 28% | Training loss: 0.6878855967615533
Epoch: 4 | Iteration number: [1280/4518] 28% | Training loss: 0.6878815346863121
Epoch: 4 | Iteration number: [1290/4518] 28% | Training loss: 0.687876494032468
Epoch: 4 | Iteration number: [1300/4518] 28% | Training loss: 0.6878721452217835
Epoch: 4 | Iteration number: [1310/4518] 28% | Training loss: 0.6878812584713215
Epoch: 4 | Iteration number: [1320/4518] 29% | Training loss: 0.6878775962825977
Epoch: 4 | Iteration number: [1330/4518] 29% | Training loss: 0.6878849074356538
Epoch: 4 | Iteration number: [1340/4518] 29% | Training loss: 0.6878808704329961
Epoch: 4 | Iteration number: [1350/4518] 29% | Training loss: 0.687874670735112
Epoch: 4 | Iteration number: [1360/4518] 30% | Training loss: 0.6878699283827754
Epoch: 4 | Iteration number: [1370/4518] 30% | Training loss: 0.687865212015862
Epoch: 4 | Iteration number: [1380/4518] 30% | Training loss: 0.687867018321286
Epoch: 4 | Iteration number: [1390/4518] 30% | Training loss: 0.6878663201555074
Epoch: 4 | Iteration number: [1400/4518] 30% | Training loss: 0.6878634283372335
Epoch: 4 | Iteration number: [1410/4518] 31% | Training loss: 0.6878561514489194
Epoch: 4 | Iteration number: [1420/4518] 31% | Training loss: 0.6878481634905641
Epoch: 4 | Iteration number: [1430/4518] 31% | Training loss: 0.6878460982879558
Epoch: 4 | Iteration number: [1440/4518] 31% | Training loss: 0.6878372349258927
Epoch: 4 | Iteration number: [1450/4518] 32% | Training loss: 0.6878335164744278
Epoch: 4 | Iteration number: [1460/4518] 32% | Training loss: 0.6878270534211642
Epoch: 4 | Iteration number: [1470/4518] 32% | Training loss: 0.6878163676683594
Epoch: 4 | Iteration number: [1480/4518] 32% | Training loss: 0.6878160378014719
Epoch: 4 | Iteration number: [1490/4518] 32% | Training loss: 0.6878050087282321
Epoch: 4 | Iteration number: [1500/4518] 33% | Training loss: 0.6878012005090713
Epoch: 4 | Iteration number: [1510/4518] 33% | Training loss: 0.6877912681229067
Epoch: 4 | Iteration number: [1520/4518] 33% | Training loss: 0.6877831814320464
Epoch: 4 | Iteration number: [1530/4518] 33% | Training loss: 0.6877894410900042
Epoch: 4 | Iteration number: [1540/4518] 34% | Training loss: 0.6877839473547873
Epoch: 4 | Iteration number: [1550/4518] 34% | Training loss: 0.687783901268436
Epoch: 4 | Iteration number: [1560/4518] 34% | Training loss: 0.687772270769645
Epoch: 4 | Iteration number: [1570/4518] 34% | Training loss: 0.6877687660372181
Epoch: 4 | Iteration number: [1580/4518] 34% | Training loss: 0.687763982784899
Epoch: 4 | Iteration number: [1590/4518] 35% | Training loss: 0.6877573506262318
Epoch: 4 | Iteration number: [1600/4518] 35% | Training loss: 0.6877454153820872
Epoch: 4 | Iteration number: [1610/4518] 35% | Training loss: 0.6877442755684349
Epoch: 4 | Iteration number: [1620/4518] 35% | Training loss: 0.6877434669821351
Epoch: 4 | Iteration number: [1630/4518] 36% | Training loss: 0.6877350967720243
Epoch: 4 | Iteration number: [1640/4518] 36% | Training loss: 0.6877396660607036
Epoch: 4 | Iteration number: [1650/4518] 36% | Training loss: 0.6877408262093861
Epoch: 4 | Iteration number: [1660/4518] 36% | Training loss: 0.6877376182251665
Epoch: 4 | Iteration number: [1670/4518] 36% | Training loss: 0.6877321863602736
Epoch: 4 | Iteration number: [1680/4518] 37% | Training loss: 0.6877375119853587
Epoch: 4 | Iteration number: [1690/4518] 37% | Training loss: 0.6877347133568759
Epoch: 4 | Iteration number: [1700/4518] 37% | Training loss: 0.6877302810374428
Epoch: 4 | Iteration number: [1710/4518] 37% | Training loss: 0.687726565794638
Epoch: 4 | Iteration number: [1720/4518] 38% | Training loss: 0.6877243517443191
Epoch: 4 | Iteration number: [1730/4518] 38% | Training loss: 0.6877200336470081
Epoch: 4 | Iteration number: [1740/4518] 38% | Training loss: 0.6877158421552044
Epoch: 4 | Iteration number: [1750/4518] 38% | Training loss: 0.6877178215299334
Epoch: 4 | Iteration number: [1760/4518] 38% | Training loss: 0.687714100222696
Epoch: 4 | Iteration number: [1770/4518] 39% | Training loss: 0.6877035890258638
Epoch: 4 | Iteration number: [1780/4518] 39% | Training loss: 0.6877061586366611
Epoch: 4 | Iteration number: [1790/4518] 39% | Training loss: 0.6877035494290251
Epoch: 4 | Iteration number: [1800/4518] 39% | Training loss: 0.6877054696281751
Epoch: 4 | Iteration number: [1810/4518] 40% | Training loss: 0.6877025033558272
Epoch: 4 | Iteration number: [1820/4518] 40% | Training loss: 0.6877020788716746
Epoch: 4 | Iteration number: [1830/4518] 40% | Training loss: 0.6876962992011524
Epoch: 4 | Iteration number: [1840/4518] 40% | Training loss: 0.6876929704585801
Epoch: 4 | Iteration number: [1850/4518] 40% | Training loss: 0.6876987902860384
Epoch: 4 | Iteration number: [1860/4518] 41% | Training loss: 0.6877005399234833
Epoch: 4 | Iteration number: [1870/4518] 41% | Training loss: 0.6876999932176927
Epoch: 4 | Iteration number: [1880/4518] 41% | Training loss: 0.6876977609510118
Epoch: 4 | Iteration number: [1890/4518] 41% | Training loss: 0.687693057457606
Epoch: 4 | Iteration number: [1900/4518] 42% | Training loss: 0.6876869487135033
Epoch: 4 | Iteration number: [1910/4518] 42% | Training loss: 0.6876828966652536
Epoch: 4 | Iteration number: [1920/4518] 42% | Training loss: 0.6876875016527871
Epoch: 4 | Iteration number: [1930/4518] 42% | Training loss: 0.6876843780742408
Epoch: 4 | Iteration number: [1940/4518] 42% | Training loss: 0.6876853189210301
Epoch: 4 | Iteration number: [1950/4518] 43% | Training loss: 0.687683328298422
Epoch: 4 | Iteration number: [1960/4518] 43% | Training loss: 0.6876804583230797
Epoch: 4 | Iteration number: [1970/4518] 43% | Training loss: 0.6876748524644049
Epoch: 4 | Iteration number: [1980/4518] 43% | Training loss: 0.6876708307350525
Epoch: 4 | Iteration number: [1990/4518] 44% | Training loss: 0.6876721180264075
Epoch: 4 | Iteration number: [2000/4518] 44% | Training loss: 0.6876716199815274
Epoch: 4 | Iteration number: [2010/4518] 44% | Training loss: 0.6876676906697192
Epoch: 4 | Iteration number: [2020/4518] 44% | Training loss: 0.6876665683961151
Epoch: 4 | Iteration number: [2030/4518] 44% | Training loss: 0.6876692206988781
Epoch: 4 | Iteration number: [2040/4518] 45% | Training loss: 0.6876687676883211
Epoch: 4 | Iteration number: [2050/4518] 45% | Training loss: 0.6876701929801848
Epoch: 4 | Iteration number: [2060/4518] 45% | Training loss: 0.6876732285740306
Epoch: 4 | Iteration number: [2070/4518] 45% | Training loss: 0.6876739925808377
Epoch: 4 | Iteration number: [2080/4518] 46% | Training loss: 0.6876755717855233
Epoch: 4 | Iteration number: [2090/4518] 46% | Training loss: 0.6876759518846941
Epoch: 4 | Iteration number: [2100/4518] 46% | Training loss: 0.687668812643914
Epoch: 4 | Iteration number: [2110/4518] 46% | Training loss: 0.6876703256961859
Epoch: 4 | Iteration number: [2120/4518] 46% | Training loss: 0.6876707207481816
Epoch: 4 | Iteration number: [2130/4518] 47% | Training loss: 0.6876693760565189
Epoch: 4 | Iteration number: [2140/4518] 47% | Training loss: 0.687670564595784
Epoch: 4 | Iteration number: [2150/4518] 47% | Training loss: 0.6876677359259405
Epoch: 4 | Iteration number: [2160/4518] 47% | Training loss: 0.6876670974272269
Epoch: 4 | Iteration number: [2170/4518] 48% | Training loss: 0.6876652076771732
Epoch: 4 | Iteration number: [2180/4518] 48% | Training loss: 0.687663356426659
Epoch: 4 | Iteration number: [2190/4518] 48% | Training loss: 0.687655627781942
Epoch: 4 | Iteration number: [2200/4518] 48% | Training loss: 0.6876505565372381
Epoch: 4 | Iteration number: [2210/4518] 48% | Training loss: 0.6876438243087061
Epoch: 4 | Iteration number: [2220/4518] 49% | Training loss: 0.6876368225963266
Epoch: 4 | Iteration number: [2230/4518] 49% | Training loss: 0.687636421881449
Epoch: 4 | Iteration number: [2240/4518] 49% | Training loss: 0.6876311741769314
Epoch: 4 | Iteration number: [2250/4518] 49% | Training loss: 0.6876336584885915
Epoch: 4 | Iteration number: [2260/4518] 50% | Training loss: 0.6876358729548159
Epoch: 4 | Iteration number: [2270/4518] 50% | Training loss: 0.6876390943443198
Epoch: 4 | Iteration number: [2280/4518] 50% | Training loss: 0.6876391627809457
Epoch: 4 | Iteration number: [2290/4518] 50% | Training loss: 0.6876382478980518
Epoch: 4 | Iteration number: [2300/4518] 50% | Training loss: 0.6876288804282312
Epoch: 4 | Iteration number: [2310/4518] 51% | Training loss: 0.6876284765216695
Epoch: 4 | Iteration number: [2320/4518] 51% | Training loss: 0.687625067912299
Epoch: 4 | Iteration number: [2330/4518] 51% | Training loss: 0.6876186351151937
Epoch: 4 | Iteration number: [2340/4518] 51% | Training loss: 0.6876173953215281
Epoch: 4 | Iteration number: [2350/4518] 52% | Training loss: 0.6876202984312747
Epoch: 4 | Iteration number: [2360/4518] 52% | Training loss: 0.6876246330849195
Epoch: 4 | Iteration number: [2370/4518] 52% | Training loss: 0.6876202940186368
Epoch: 4 | Iteration number: [2380/4518] 52% | Training loss: 0.6876183655332117
Epoch: 4 | Iteration number: [2390/4518] 52% | Training loss: 0.6876129674113445
Epoch: 4 | Iteration number: [2400/4518] 53% | Training loss: 0.6876137605806192
Epoch: 4 | Iteration number: [2410/4518] 53% | Training loss: 0.6876136076400884
Epoch: 4 | Iteration number: [2420/4518] 53% | Training loss: 0.6876134764557043
Epoch: 4 | Iteration number: [2430/4518] 53% | Training loss: 0.6876173306885079
Epoch: 4 | Iteration number: [2440/4518] 54% | Training loss: 0.6876159495994693
Epoch: 4 | Iteration number: [2450/4518] 54% | Training loss: 0.6876110371278257
Epoch: 4 | Iteration number: [2460/4518] 54% | Training loss: 0.6876094227883874
Epoch: 4 | Iteration number: [2470/4518] 54% | Training loss: 0.6876099182526593
Epoch: 4 | Iteration number: [2480/4518] 54% | Training loss: 0.6876121893765464
Epoch: 4 | Iteration number: [2490/4518] 55% | Training loss: 0.6876113122246831
Epoch: 4 | Iteration number: [2500/4518] 55% | Training loss: 0.6876109082221985
Epoch: 4 | Iteration number: [2510/4518] 55% | Training loss: 0.6876099406010601
Epoch: 4 | Iteration number: [2520/4518] 55% | Training loss: 0.6876064638769815
Epoch: 4 | Iteration number: [2530/4518] 55% | Training loss: 0.6876074582456129
Epoch: 4 | Iteration number: [2540/4518] 56% | Training loss: 0.6876090565535027
Epoch: 4 | Iteration number: [2550/4518] 56% | Training loss: 0.6876105683925106
Epoch: 4 | Iteration number: [2560/4518] 56% | Training loss: 0.6876095781568438
Epoch: 4 | Iteration number: [2570/4518] 56% | Training loss: 0.6876079559326171
Epoch: 4 | Iteration number: [2580/4518] 57% | Training loss: 0.6876088022261627
Epoch: 4 | Iteration number: [2590/4518] 57% | Training loss: 0.6876103314193519
Epoch: 4 | Iteration number: [2600/4518] 57% | Training loss: 0.6876073479652405
Epoch: 4 | Iteration number: [2610/4518] 57% | Training loss: 0.6876073225019536
Epoch: 4 | Iteration number: [2620/4518] 57% | Training loss: 0.687602202969653
Epoch: 4 | Iteration number: [2630/4518] 58% | Training loss: 0.6876044192241625
Epoch: 4 | Iteration number: [2640/4518] 58% | Training loss: 0.6876010414551604
Epoch: 4 | Iteration number: [2650/4518] 58% | Training loss: 0.687601189523373
Epoch: 4 | Iteration number: [2660/4518] 58% | Training loss: 0.6875988427857708
Epoch: 4 | Iteration number: [2670/4518] 59% | Training loss: 0.6876018770848321
Epoch: 4 | Iteration number: [2680/4518] 59% | Training loss: 0.6876009943325128
Epoch: 4 | Iteration number: [2690/4518] 59% | Training loss: 0.6875993006291443
Epoch: 4 | Iteration number: [2700/4518] 59% | Training loss: 0.687597530749109
Epoch: 4 | Iteration number: [2710/4518] 59% | Training loss: 0.6875973739747192
Epoch: 4 | Iteration number: [2720/4518] 60% | Training loss: 0.687595089831773
Epoch: 4 | Iteration number: [2730/4518] 60% | Training loss: 0.6875945136223958
Epoch: 4 | Iteration number: [2740/4518] 60% | Training loss: 0.6875938974157737
Epoch: 4 | Iteration number: [2750/4518] 60% | Training loss: 0.6875926541848616
Epoch: 4 | Iteration number: [2760/4518] 61% | Training loss: 0.6875879000278486
Epoch: 4 | Iteration number: [2770/4518] 61% | Training loss: 0.6875880351996163
Epoch: 4 | Iteration number: [2780/4518] 61% | Training loss: 0.6875836105012207
Epoch: 4 | Iteration number: [2790/4518] 61% | Training loss: 0.687584446087533
Epoch: 4 | Iteration number: [2800/4518] 61% | Training loss: 0.6875775026849338
Epoch: 4 | Iteration number: [2810/4518] 62% | Training loss: 0.6875764213422864
Epoch: 4 | Iteration number: [2820/4518] 62% | Training loss: 0.6875768299009783
Epoch: 4 | Iteration number: [2830/4518] 62% | Training loss: 0.6875749720490864
Epoch: 4 | Iteration number: [2840/4518] 62% | Training loss: 0.6875773549289771
Epoch: 4 | Iteration number: [2850/4518] 63% | Training loss: 0.6875754108136161
Epoch: 4 | Iteration number: [2860/4518] 63% | Training loss: 0.6875775259899927
Epoch: 4 | Iteration number: [2870/4518] 63% | Training loss: 0.6875780610257325
Epoch: 4 | Iteration number: [2880/4518] 63% | Training loss: 0.6875773238639037
Epoch: 4 | Iteration number: [2890/4518] 63% | Training loss: 0.6875743344580838
Epoch: 4 | Iteration number: [2900/4518] 64% | Training loss: 0.6875709813627704
Epoch: 4 | Iteration number: [2910/4518] 64% | Training loss: 0.6875683735940874
Epoch: 4 | Iteration number: [2920/4518] 64% | Training loss: 0.6875713590277385
Epoch: 4 | Iteration number: [2930/4518] 64% | Training loss: 0.6875725521365937
Epoch: 4 | Iteration number: [2940/4518] 65% | Training loss: 0.6875681964313092
Epoch: 4 | Iteration number: [2950/4518] 65% | Training loss: 0.6875701927330534
Epoch: 4 | Iteration number: [2960/4518] 65% | Training loss: 0.6875662631883814
Epoch: 4 | Iteration number: [2970/4518] 65% | Training loss: 0.6875660908342612
Epoch: 4 | Iteration number: [2980/4518] 65% | Training loss: 0.6875606440057691
Epoch: 4 | Iteration number: [2990/4518] 66% | Training loss: 0.687557329999962
Epoch: 4 | Iteration number: [3000/4518] 66% | Training loss: 0.687557120680809
Epoch: 4 | Iteration number: [3010/4518] 66% | Training loss: 0.6875550593252594
Epoch: 4 | Iteration number: [3020/4518] 66% | Training loss: 0.6875506178630109
Epoch: 4 | Iteration number: [3030/4518] 67% | Training loss: 0.6875499201489754
Epoch: 4 | Iteration number: [3040/4518] 67% | Training loss: 0.687549659668615
Epoch: 4 | Iteration number: [3050/4518] 67% | Training loss: 0.6875458516449224
Epoch: 4 | Iteration number: [3060/4518] 67% | Training loss: 0.6875439369405796
Epoch: 4 | Iteration number: [3070/4518] 67% | Training loss: 0.6875414968701838
Epoch: 4 | Iteration number: [3080/4518] 68% | Training loss: 0.687539769186602
Epoch: 4 | Iteration number: [3090/4518] 68% | Training loss: 0.6875406751162025
Epoch: 4 | Iteration number: [3100/4518] 68% | Training loss: 0.6875384839311722
Epoch: 4 | Iteration number: [3110/4518] 68% | Training loss: 0.6875406365685908
Epoch: 4 | Iteration number: [3120/4518] 69% | Training loss: 0.6875415141765888
Epoch: 4 | Iteration number: [3130/4518] 69% | Training loss: 0.6875362138016917
Epoch: 4 | Iteration number: [3140/4518] 69% | Training loss: 0.6875334631295721
Epoch: 4 | Iteration number: [3150/4518] 69% | Training loss: 0.687533602449629
Epoch: 4 | Iteration number: [3160/4518] 69% | Training loss: 0.6875354995267301
Epoch: 4 | Iteration number: [3170/4518] 70% | Training loss: 0.6875362174556082
Epoch: 4 | Iteration number: [3180/4518] 70% | Training loss: 0.687535970840814
Epoch: 4 | Iteration number: [3190/4518] 70% | Training loss: 0.6875421052629297
Epoch: 4 | Iteration number: [3200/4518] 70% | Training loss: 0.6875429214909673
Epoch: 4 | Iteration number: [3210/4518] 71% | Training loss: 0.6875427376815463
Epoch: 4 | Iteration number: [3220/4518] 71% | Training loss: 0.6875414728007702
Epoch: 4 | Iteration number: [3230/4518] 71% | Training loss: 0.6875359242176493
Epoch: 4 | Iteration number: [3240/4518] 71% | Training loss: 0.6875331527289049
Epoch: 4 | Iteration number: [3250/4518] 71% | Training loss: 0.6875315510126261
Epoch: 4 | Iteration number: [3260/4518] 72% | Training loss: 0.6875314282676194
Epoch: 4 | Iteration number: [3270/4518] 72% | Training loss: 0.6875290967091143
Epoch: 4 | Iteration number: [3280/4518] 72% | Training loss: 0.6875280908876803
Epoch: 4 | Iteration number: [3290/4518] 72% | Training loss: 0.6875279687277089
Epoch: 4 | Iteration number: [3300/4518] 73% | Training loss: 0.6875276018092127
Epoch: 4 | Iteration number: [3310/4518] 73% | Training loss: 0.6875323808085162
Epoch: 4 | Iteration number: [3320/4518] 73% | Training loss: 0.687536169337221
Epoch: 4 | Iteration number: [3330/4518] 73% | Training loss: 0.6875357366717971
Epoch: 4 | Iteration number: [3340/4518] 73% | Training loss: 0.6875361245192454
Epoch: 4 | Iteration number: [3350/4518] 74% | Training loss: 0.6875290961052055
Epoch: 4 | Iteration number: [3360/4518] 74% | Training loss: 0.687527037589323
Epoch: 4 | Iteration number: [3370/4518] 74% | Training loss: 0.6875220782502115
Epoch: 4 | Iteration number: [3380/4518] 74% | Training loss: 0.6875214236198798
Epoch: 4 | Iteration number: [3390/4518] 75% | Training loss: 0.6875202137284574
Epoch: 4 | Iteration number: [3400/4518] 75% | Training loss: 0.6875218827233595
Epoch: 4 | Iteration number: [3410/4518] 75% | Training loss: 0.6875205558940463
Epoch: 4 | Iteration number: [3420/4518] 75% | Training loss: 0.6875175821328023
Epoch: 4 | Iteration number: [3430/4518] 75% | Training loss: 0.6875157320117117
Epoch: 4 | Iteration number: [3440/4518] 76% | Training loss: 0.6875153116708578
Epoch: 4 | Iteration number: [3450/4518] 76% | Training loss: 0.6875176810872727
Epoch: 4 | Iteration number: [3460/4518] 76% | Training loss: 0.6875162434198953
Epoch: 4 | Iteration number: [3470/4518] 76% | Training loss: 0.6875132902554889
Epoch: 4 | Iteration number: [3480/4518] 77% | Training loss: 0.6875144527732641
Epoch: 4 | Iteration number: [3490/4518] 77% | Training loss: 0.6875114348009869
Epoch: 4 | Iteration number: [3500/4518] 77% | Training loss: 0.6875108281373977
Epoch: 4 | Iteration number: [3510/4518] 77% | Training loss: 0.6875089655914198
Epoch: 4 | Iteration number: [3520/4518] 77% | Training loss: 0.6875062460418452
Epoch: 4 | Iteration number: [3530/4518] 78% | Training loss: 0.687499293288158
Epoch: 4 | Iteration number: [3540/4518] 78% | Training loss: 0.6874986386905282
Epoch: 4 | Iteration number: [3550/4518] 78% | Training loss: 0.6874999881966013
Epoch: 4 | Iteration number: [3560/4518] 78% | Training loss: 0.6874998065360477
Epoch: 4 | Iteration number: [3570/4518] 79% | Training loss: 0.6874992690834345
Epoch: 4 | Iteration number: [3580/4518] 79% | Training loss: 0.687499245634958
Epoch: 4 | Iteration number: [3590/4518] 79% | Training loss: 0.687497067484683
Epoch: 4 | Iteration number: [3600/4518] 79% | Training loss: 0.6874976841111978
Epoch: 4 | Iteration number: [3610/4518] 79% | Training loss: 0.6874978098842907
Epoch: 4 | Iteration number: [3620/4518] 80% | Training loss: 0.687493513401042
Epoch: 4 | Iteration number: [3630/4518] 80% | Training loss: 0.6874924319177949
Epoch: 4 | Iteration number: [3640/4518] 80% | Training loss: 0.6874949031970004
Epoch: 4 | Iteration number: [3650/4518] 80% | Training loss: 0.6874963402421507
Epoch: 4 | Iteration number: [3660/4518] 81% | Training loss: 0.687497697225034
Epoch: 4 | Iteration number: [3670/4518] 81% | Training loss: 0.6874970058004602
Epoch: 4 | Iteration number: [3680/4518] 81% | Training loss: 0.6874978087194588
Epoch: 4 | Iteration number: [3690/4518] 81% | Training loss: 0.6874950973160545
Epoch: 4 | Iteration number: [3700/4518] 81% | Training loss: 0.6874943764789685
Epoch: 4 | Iteration number: [3710/4518] 82% | Training loss: 0.6874974958658862
Epoch: 4 | Iteration number: [3720/4518] 82% | Training loss: 0.687496681655607
Epoch: 4 | Iteration number: [3730/4518] 82% | Training loss: 0.6874978218257587
Epoch: 4 | Iteration number: [3740/4518] 82% | Training loss: 0.6874959489081632
Epoch: 4 | Iteration number: [3750/4518] 83% | Training loss: 0.6874959448019663
Epoch: 4 | Iteration number: [3760/4518] 83% | Training loss: 0.6874930365605557
Epoch: 4 | Iteration number: [3770/4518] 83% | Training loss: 0.6874919036180966
Epoch: 4 | Iteration number: [3780/4518] 83% | Training loss: 0.6874914361370934
Epoch: 4 | Iteration number: [3790/4518] 83% | Training loss: 0.6874921409939084
Epoch: 4 | Iteration number: [3800/4518] 84% | Training loss: 0.6874858536845759
Epoch: 4 | Iteration number: [3810/4518] 84% | Training loss: 0.687483593610328
Epoch: 4 | Iteration number: [3820/4518] 84% | Training loss: 0.6874802376275287
Epoch: 4 | Iteration number: [3830/4518] 84% | Training loss: 0.6874793127218052
Epoch: 4 | Iteration number: [3840/4518] 84% | Training loss: 0.687478756873558
Epoch: 4 | Iteration number: [3850/4518] 85% | Training loss: 0.6874749550262055
Epoch: 4 | Iteration number: [3860/4518] 85% | Training loss: 0.6874738093484869
Epoch: 4 | Iteration number: [3870/4518] 85% | Training loss: 0.6874709141192819
Epoch: 4 | Iteration number: [3880/4518] 85% | Training loss: 0.687467789388809
Epoch: 4 | Iteration number: [3890/4518] 86% | Training loss: 0.6874690714562767
Epoch: 4 | Iteration number: [3900/4518] 86% | Training loss: 0.6874648735156426
Epoch: 4 | Iteration number: [3910/4518] 86% | Training loss: 0.6874598074142281
Epoch: 4 | Iteration number: [3920/4518] 86% | Training loss: 0.6874611199206235
Epoch: 4 | Iteration number: [3930/4518] 86% | Training loss: 0.6874640968616379
Epoch: 4 | Iteration number: [3940/4518] 87% | Training loss: 0.6874635178728152
Epoch: 4 | Iteration number: [3950/4518] 87% | Training loss: 0.687463627434984
Epoch: 4 | Iteration number: [3960/4518] 87% | Training loss: 0.6874627761015988
Epoch: 4 | Iteration number: [3970/4518] 87% | Training loss: 0.6874638761771416
Epoch: 4 | Iteration number: [3980/4518] 88% | Training loss: 0.6874618333188732
Epoch: 4 | Iteration number: [3990/4518] 88% | Training loss: 0.6874610834103778
Epoch: 4 | Iteration number: [4000/4518] 88% | Training loss: 0.6874612376093865
Epoch: 4 | Iteration number: [4010/4518] 88% | Training loss: 0.6874630728564655
Epoch: 4 | Iteration number: [4020/4518] 88% | Training loss: 0.6874600084415122
Epoch: 4 | Iteration number: [4030/4518] 89% | Training loss: 0.6874588830003667
Epoch: 4 | Iteration number: [4040/4518] 89% | Training loss: 0.6874538680114368
Epoch: 4 | Iteration number: [4050/4518] 89% | Training loss: 0.6874518394028699
Epoch: 4 | Iteration number: [4060/4518] 89% | Training loss: 0.6874544044433556
Epoch: 4 | Iteration number: [4070/4518] 90% | Training loss: 0.6874515168496959
Epoch: 4 | Iteration number: [4080/4518] 90% | Training loss: 0.6874511906913683
Epoch: 4 | Iteration number: [4090/4518] 90% | Training loss: 0.6874510538752913
Epoch: 4 | Iteration number: [4100/4518] 90% | Training loss: 0.6874471273509467
Epoch: 4 | Iteration number: [4110/4518] 90% | Training loss: 0.6874476986499889
Epoch: 4 | Iteration number: [4120/4518] 91% | Training loss: 0.687447995583988
Epoch: 4 | Iteration number: [4130/4518] 91% | Training loss: 0.6874496649165996
Epoch: 4 | Iteration number: [4140/4518] 91% | Training loss: 0.6874483326638954
Epoch: 4 | Iteration number: [4150/4518] 91% | Training loss: 0.6874466906398176
Epoch: 4 | Iteration number: [4160/4518] 92% | Training loss: 0.6874456949245471
Epoch: 4 | Iteration number: [4170/4518] 92% | Training loss: 0.68744508644088
Epoch: 4 | Iteration number: [4180/4518] 92% | Training loss: 0.6874470303360926
Epoch: 4 | Iteration number: [4190/4518] 92% | Training loss: 0.687445491523902
Epoch: 4 | Iteration number: [4200/4518] 92% | Training loss: 0.6874426473180453
Epoch: 4 | Iteration number: [4210/4518] 93% | Training loss: 0.6874411117860654
Epoch: 4 | Iteration number: [4220/4518] 93% | Training loss: 0.6874409678140523
Epoch: 4 | Iteration number: [4230/4518] 93% | Training loss: 0.6874409867234827
Epoch: 4 | Iteration number: [4240/4518] 93% | Training loss: 0.6874424547378747
Epoch: 4 | Iteration number: [4250/4518] 94% | Training loss: 0.6874399998468511
Epoch: 4 | Iteration number: [4260/4518] 94% | Training loss: 0.6874390025933583
Epoch: 4 | Iteration number: [4270/4518] 94% | Training loss: 0.68743853225641
Epoch: 4 | Iteration number: [4280/4518] 94% | Training loss: 0.6874385453412466
Epoch: 4 | Iteration number: [4290/4518] 94% | Training loss: 0.6874407715313918
Epoch: 4 | Iteration number: [4300/4518] 95% | Training loss: 0.687438721421153
Epoch: 4 | Iteration number: [4310/4518] 95% | Training loss: 0.6874395975795533
Epoch: 4 | Iteration number: [4320/4518] 95% | Training loss: 0.6874392065047114
Epoch: 4 | Iteration number: [4330/4518] 95% | Training loss: 0.6874391401887766
Epoch: 4 | Iteration number: [4340/4518] 96% | Training loss: 0.6874380189290245
Epoch: 4 | Iteration number: [4350/4518] 96% | Training loss: 0.6874396881289866
Epoch: 4 | Iteration number: [4360/4518] 96% | Training loss: 0.6874409955712634
Epoch: 4 | Iteration number: [4370/4518] 96% | Training loss: 0.6874411172806807
Epoch: 4 | Iteration number: [4380/4518] 96% | Training loss: 0.6874404579809267
Epoch: 4 | Iteration number: [4390/4518] 97% | Training loss: 0.6874404119603454
Epoch: 4 | Iteration number: [4400/4518] 97% | Training loss: 0.6874382899701595
Epoch: 4 | Iteration number: [4410/4518] 97% | Training loss: 0.6874391375620619
Epoch: 4 | Iteration number: [4420/4518] 97% | Training loss: 0.6874415599517693
Epoch: 4 | Iteration number: [4430/4518] 98% | Training loss: 0.687441474441481
Epoch: 4 | Iteration number: [4440/4518] 98% | Training loss: 0.6874405507434596
Epoch: 4 | Iteration number: [4450/4518] 98% | Training loss: 0.6874386481354745
Epoch: 4 | Iteration number: [4460/4518] 98% | Training loss: 0.6874385753020043
Epoch: 4 | Iteration number: [4470/4518] 98% | Training loss: 0.6874375052233404
Epoch: 4 | Iteration number: [4480/4518] 99% | Training loss: 0.6874356985092163
Epoch: 4 | Iteration number: [4490/4518] 99% | Training loss: 0.6874349613099427
Epoch: 4 | Iteration number: [4500/4518] 99% | Training loss: 0.6874366952445772
Epoch: 4 | Iteration number: [4510/4518] 99% | Training loss: 0.6874354425925109

 End of epoch: 4 | Train Loss: 0.6872831756375225 | Training Time: 642 

 End of epoch: 4 | Eval Loss: 0.6908215235690681 | Evaluating Time: 17 
Epoch: 5 | Iteration number: [10/4518] 0% | Training loss: 0.7555733382701874
Epoch: 5 | Iteration number: [20/4518] 0% | Training loss: 0.7214810758829117
Epoch: 5 | Iteration number: [30/4518] 0% | Training loss: 0.7097251196702321
Epoch: 5 | Iteration number: [40/4518] 0% | Training loss: 0.704073679447174
Epoch: 5 | Iteration number: [50/4518] 1% | Training loss: 0.7004028296470642
Epoch: 5 | Iteration number: [60/4518] 1% | Training loss: 0.6980150212844213
Epoch: 5 | Iteration number: [70/4518] 1% | Training loss: 0.6965299418994358
Epoch: 5 | Iteration number: [80/4518] 1% | Training loss: 0.6955306485295296
Epoch: 5 | Iteration number: [90/4518] 1% | Training loss: 0.6946640961700016
Epoch: 5 | Iteration number: [100/4518] 2% | Training loss: 0.6939036166667938
Epoch: 5 | Iteration number: [110/4518] 2% | Training loss: 0.6932995601133867
Epoch: 5 | Iteration number: [120/4518] 2% | Training loss: 0.6927605325977008
Epoch: 5 | Iteration number: [130/4518] 2% | Training loss: 0.6923737466335297
Epoch: 5 | Iteration number: [140/4518] 3% | Training loss: 0.6919584431818553
Epoch: 5 | Iteration number: [150/4518] 3% | Training loss: 0.6917033569018046
Epoch: 5 | Iteration number: [160/4518] 3% | Training loss: 0.691291905194521
Epoch: 5 | Iteration number: [170/4518] 3% | Training loss: 0.6910381962271298
Epoch: 5 | Iteration number: [180/4518] 3% | Training loss: 0.6908766392204496
Epoch: 5 | Iteration number: [190/4518] 4% | Training loss: 0.6906968417920565
Epoch: 5 | Iteration number: [200/4518] 4% | Training loss: 0.6904967138171196
Epoch: 5 | Iteration number: [210/4518] 4% | Training loss: 0.6903641839822133
Epoch: 5 | Iteration number: [220/4518] 4% | Training loss: 0.6902064716274088
Epoch: 5 | Iteration number: [230/4518] 5% | Training loss: 0.690078945522723
Epoch: 5 | Iteration number: [240/4518] 5% | Training loss: 0.6899687146147092
Epoch: 5 | Iteration number: [250/4518] 5% | Training loss: 0.6899090392589569
Epoch: 5 | Iteration number: [260/4518] 5% | Training loss: 0.6897446414599052
Epoch: 5 | Iteration number: [270/4518] 5% | Training loss: 0.6896701728856122
Epoch: 5 | Iteration number: [280/4518] 6% | Training loss: 0.6895877452833312
Epoch: 5 | Iteration number: [290/4518] 6% | Training loss: 0.6894809155628598
Epoch: 5 | Iteration number: [300/4518] 6% | Training loss: 0.689416272242864
Epoch: 5 | Iteration number: [310/4518] 6% | Training loss: 0.6893117548957948
Epoch: 5 | Iteration number: [320/4518] 7% | Training loss: 0.6892365109175443
Epoch: 5 | Iteration number: [330/4518] 7% | Training loss: 0.6891702502062826
Epoch: 5 | Iteration number: [340/4518] 7% | Training loss: 0.6891353121575188
Epoch: 5 | Iteration number: [350/4518] 7% | Training loss: 0.6890440460613796
Epoch: 5 | Iteration number: [360/4518] 7% | Training loss: 0.6889749717381265
Epoch: 5 | Iteration number: [370/4518] 8% | Training loss: 0.6889108106896684
Epoch: 5 | Iteration number: [380/4518] 8% | Training loss: 0.6888395427088988
Epoch: 5 | Iteration number: [390/4518] 8% | Training loss: 0.6887625416119894
Epoch: 5 | Iteration number: [400/4518] 8% | Training loss: 0.6886617104709148
Epoch: 5 | Iteration number: [410/4518] 9% | Training loss: 0.6885971787499219
Epoch: 5 | Iteration number: [420/4518] 9% | Training loss: 0.6885296195745468
Epoch: 5 | Iteration number: [430/4518] 9% | Training loss: 0.6884871801664663
Epoch: 5 | Iteration number: [440/4518] 9% | Training loss: 0.688439571451057
Epoch: 5 | Iteration number: [450/4518] 9% | Training loss: 0.6883694008986155
Epoch: 5 | Iteration number: [460/4518] 10% | Training loss: 0.6883046468962793
Epoch: 5 | Iteration number: [470/4518] 10% | Training loss: 0.6882788328414268
Epoch: 5 | Iteration number: [480/4518] 10% | Training loss: 0.6882519653687874
Epoch: 5 | Iteration number: [490/4518] 10% | Training loss: 0.6882382210420103
Epoch: 5 | Iteration number: [500/4518] 11% | Training loss: 0.6882262250185013
Epoch: 5 | Iteration number: [510/4518] 11% | Training loss: 0.6881689930663389
Epoch: 5 | Iteration number: [520/4518] 11% | Training loss: 0.6881660680358227
Epoch: 5 | Iteration number: [530/4518] 11% | Training loss: 0.6881443867143595
Epoch: 5 | Iteration number: [540/4518] 11% | Training loss: 0.6881089009620526
Epoch: 5 | Iteration number: [550/4518] 12% | Training loss: 0.6880839782411402
Epoch: 5 | Iteration number: [560/4518] 12% | Training loss: 0.6880868795726981
Epoch: 5 | Iteration number: [570/4518] 12% | Training loss: 0.6880793681270198
Epoch: 5 | Iteration number: [580/4518] 12% | Training loss: 0.688074697811028
Epoch: 5 | Iteration number: [590/4518] 13% | Training loss: 0.6880674940044597
Epoch: 5 | Iteration number: [600/4518] 13% | Training loss: 0.6880615625778834
Epoch: 5 | Iteration number: [610/4518] 13% | Training loss: 0.6880469629999066
Epoch: 5 | Iteration number: [620/4518] 13% | Training loss: 0.68802798044297
Epoch: 5 | Iteration number: [630/4518] 13% | Training loss: 0.6880206434499649
Epoch: 5 | Iteration number: [640/4518] 14% | Training loss: 0.6879859996028245
Epoch: 5 | Iteration number: [650/4518] 14% | Training loss: 0.6879791781535516
Epoch: 5 | Iteration number: [660/4518] 14% | Training loss: 0.6879741455569411
Epoch: 5 | Iteration number: [670/4518] 14% | Training loss: 0.6879698866338873
Epoch: 5 | Iteration number: [680/4518] 15% | Training loss: 0.6879609821473851
Epoch: 5 | Iteration number: [690/4518] 15% | Training loss: 0.6879558757595394
Epoch: 5 | Iteration number: [700/4518] 15% | Training loss: 0.687934518456459
Epoch: 5 | Iteration number: [710/4518] 15% | Training loss: 0.6879141870518806
Epoch: 5 | Iteration number: [720/4518] 15% | Training loss: 0.6878941715591483
Epoch: 5 | Iteration number: [730/4518] 16% | Training loss: 0.6879059435570076
Epoch: 5 | Iteration number: [740/4518] 16% | Training loss: 0.6879001783358084
Epoch: 5 | Iteration number: [750/4518] 16% | Training loss: 0.6878821400006612
Epoch: 5 | Iteration number: [760/4518] 16% | Training loss: 0.6878719014556784
Epoch: 5 | Iteration number: [770/4518] 17% | Training loss: 0.6878612347237476
Epoch: 5 | Iteration number: [780/4518] 17% | Training loss: 0.6878556869733028
Epoch: 5 | Iteration number: [790/4518] 17% | Training loss: 0.6878505397446548
Epoch: 5 | Iteration number: [800/4518] 17% | Training loss: 0.6878375967592001
Epoch: 5 | Iteration number: [810/4518] 17% | Training loss: 0.6878358160272057
Epoch: 5 | Iteration number: [820/4518] 18% | Training loss: 0.6878332034843724
Epoch: 5 | Iteration number: [830/4518] 18% | Training loss: 0.6878314537456237
Epoch: 5 | Iteration number: [840/4518] 18% | Training loss: 0.6878308731885183
Epoch: 5 | Iteration number: [850/4518] 18% | Training loss: 0.6878268337249756
Epoch: 5 | Iteration number: [860/4518] 19% | Training loss: 0.6878255275792854
Epoch: 5 | Iteration number: [870/4518] 19% | Training loss: 0.687813681843637
Epoch: 5 | Iteration number: [880/4518] 19% | Training loss: 0.6877921205352653
Epoch: 5 | Iteration number: [890/4518] 19% | Training loss: 0.68778678346216
Epoch: 5 | Iteration number: [900/4518] 19% | Training loss: 0.6877797576453951
Epoch: 5 | Iteration number: [910/4518] 20% | Training loss: 0.6877865973409716
Epoch: 5 | Iteration number: [920/4518] 20% | Training loss: 0.6877828146452489
Epoch: 5 | Iteration number: [930/4518] 20% | Training loss: 0.6877863214221052
Epoch: 5 | Iteration number: [940/4518] 20% | Training loss: 0.6877778112888336
Epoch: 5 | Iteration number: [950/4518] 21% | Training loss: 0.6877773531487114
Epoch: 5 | Iteration number: [960/4518] 21% | Training loss: 0.6877756064757705
Epoch: 5 | Iteration number: [970/4518] 21% | Training loss: 0.6877739599070598
Epoch: 5 | Iteration number: [980/4518] 21% | Training loss: 0.6877710600896757
Epoch: 5 | Iteration number: [990/4518] 21% | Training loss: 0.6877655129842084
Epoch: 5 | Iteration number: [1000/4518] 22% | Training loss: 0.6877568463087081
Epoch: 5 | Iteration number: [1010/4518] 22% | Training loss: 0.6877523477124696
Epoch: 5 | Iteration number: [1020/4518] 22% | Training loss: 0.6877415223448884
Epoch: 5 | Iteration number: [1030/4518] 22% | Training loss: 0.6877402768551725
Epoch: 5 | Iteration number: [1040/4518] 23% | Training loss: 0.6877332077003442
Epoch: 5 | Iteration number: [1050/4518] 23% | Training loss: 0.687722514413652
Epoch: 5 | Iteration number: [1060/4518] 23% | Training loss: 0.6877166610281422
Epoch: 5 | Iteration number: [1070/4518] 23% | Training loss: 0.6877151533822032
Epoch: 5 | Iteration number: [1080/4518] 23% | Training loss: 0.6877040532452089
Epoch: 5 | Iteration number: [1090/4518] 24% | Training loss: 0.6876964628696441
Epoch: 5 | Iteration number: [1100/4518] 24% | Training loss: 0.6876967747644944
Epoch: 5 | Iteration number: [1110/4518] 24% | Training loss: 0.6876958473308666
Epoch: 5 | Iteration number: [1120/4518] 24% | Training loss: 0.687688920540469
Epoch: 5 | Iteration number: [1130/4518] 25% | Training loss: 0.6876825665478158
Epoch: 5 | Iteration number: [1140/4518] 25% | Training loss: 0.6876805415278987
Epoch: 5 | Iteration number: [1150/4518] 25% | Training loss: 0.6876753689931786
Epoch: 5 | Iteration number: [1160/4518] 25% | Training loss: 0.6876771220359309
Epoch: 5 | Iteration number: [1170/4518] 25% | Training loss: 0.6876783709750216
Epoch: 5 | Iteration number: [1180/4518] 26% | Training loss: 0.6876804234617847
Epoch: 5 | Iteration number: [1190/4518] 26% | Training loss: 0.687671191652282
Epoch: 5 | Iteration number: [1200/4518] 26% | Training loss: 0.6876703425248464
Epoch: 5 | Iteration number: [1210/4518] 26% | Training loss: 0.6876619093181673
Epoch: 5 | Iteration number: [1220/4518] 27% | Training loss: 0.6876551568019585
Epoch: 5 | Iteration number: [1230/4518] 27% | Training loss: 0.6876452540963646
Epoch: 5 | Iteration number: [1240/4518] 27% | Training loss: 0.687644684891547
Epoch: 5 | Iteration number: [1250/4518] 27% | Training loss: 0.6876461799621582
Epoch: 5 | Iteration number: [1260/4518] 27% | Training loss: 0.6876422050453368
Epoch: 5 | Iteration number: [1270/4518] 28% | Training loss: 0.6876309109954384
Epoch: 5 | Iteration number: [1280/4518] 28% | Training loss: 0.6876202749554068
Epoch: 5 | Iteration number: [1290/4518] 28% | Training loss: 0.6876121705354646
Epoch: 5 | Iteration number: [1300/4518] 28% | Training loss: 0.6876081412572127
Epoch: 5 | Iteration number: [1310/4518] 28% | Training loss: 0.6876028867623278
Epoch: 5 | Iteration number: [1320/4518] 29% | Training loss: 0.6875997692346573
Epoch: 5 | Iteration number: [1330/4518] 29% | Training loss: 0.6876047628714625
Epoch: 5 | Iteration number: [1340/4518] 29% | Training loss: 0.6875960518175097
Epoch: 5 | Iteration number: [1350/4518] 29% | Training loss: 0.6875917315924609
Epoch: 5 | Iteration number: [1360/4518] 30% | Training loss: 0.6875795516459381
Epoch: 5 | Iteration number: [1370/4518] 30% | Training loss: 0.6875763727365619
Epoch: 5 | Iteration number: [1380/4518] 30% | Training loss: 0.6875757177238879
Epoch: 5 | Iteration number: [1390/4518] 30% | Training loss: 0.6875714218444962
Epoch: 5 | Iteration number: [1400/4518] 30% | Training loss: 0.687556683591434
Epoch: 5 | Iteration number: [1410/4518] 31% | Training loss: 0.6875393318791762
Epoch: 5 | Iteration number: [1420/4518] 31% | Training loss: 0.6875399020356192
Epoch: 5 | Iteration number: [1430/4518] 31% | Training loss: 0.6875422643198
Epoch: 5 | Iteration number: [1440/4518] 31% | Training loss: 0.6875447338240014
Epoch: 5 | Iteration number: [1450/4518] 32% | Training loss: 0.6875468051022496
Epoch: 5 | Iteration number: [1460/4518] 32% | Training loss: 0.687540463511258
Epoch: 5 | Iteration number: [1470/4518] 32% | Training loss: 0.6875464119067808
Epoch: 5 | Iteration number: [1480/4518] 32% | Training loss: 0.6875527210734986
Epoch: 5 | Iteration number: [1490/4518] 32% | Training loss: 0.6875519984920553
Epoch: 5 | Iteration number: [1500/4518] 33% | Training loss: 0.687553586602211
Epoch: 5 | Iteration number: [1510/4518] 33% | Training loss: 0.687552161761467
Epoch: 5 | Iteration number: [1520/4518] 33% | Training loss: 0.6875454453261275
Epoch: 5 | Iteration number: [1530/4518] 33% | Training loss: 0.687545547765844
Epoch: 5 | Iteration number: [1540/4518] 34% | Training loss: 0.6875477137503686
Epoch: 5 | Iteration number: [1550/4518] 34% | Training loss: 0.68754566434891
Epoch: 5 | Iteration number: [1560/4518] 34% | Training loss: 0.687530238315081
Epoch: 5 | Iteration number: [1570/4518] 34% | Training loss: 0.6875236608420208
Epoch: 5 | Iteration number: [1580/4518] 34% | Training loss: 0.6875331865835793
Epoch: 5 | Iteration number: [1590/4518] 35% | Training loss: 0.6875349894634583
Epoch: 5 | Iteration number: [1600/4518] 35% | Training loss: 0.6875312142446637
Epoch: 5 | Iteration number: [1610/4518] 35% | Training loss: 0.6875362293320413
Epoch: 5 | Iteration number: [1620/4518] 35% | Training loss: 0.6875281506114536
Epoch: 5 | Iteration number: [1630/4518] 36% | Training loss: 0.6875288831310038
Epoch: 5 | Iteration number: [1640/4518] 36% | Training loss: 0.6875314881888831
Epoch: 5 | Iteration number: [1650/4518] 36% | Training loss: 0.687521374911973
Epoch: 5 | Iteration number: [1660/4518] 36% | Training loss: 0.6875161986753165
Epoch: 5 | Iteration number: [1670/4518] 36% | Training loss: 0.6875069740646613
Epoch: 5 | Iteration number: [1680/4518] 37% | Training loss: 0.687504428412233
Epoch: 5 | Iteration number: [1690/4518] 37% | Training loss: 0.6875080011652771
Epoch: 5 | Iteration number: [1700/4518] 37% | Training loss: 0.6875086457238477
Epoch: 5 | Iteration number: [1710/4518] 37% | Training loss: 0.6875118258752321
Epoch: 5 | Iteration number: [1720/4518] 38% | Training loss: 0.6875063039189161
Epoch: 5 | Iteration number: [1730/4518] 38% | Training loss: 0.6875060462882753
Epoch: 5 | Iteration number: [1740/4518] 38% | Training loss: 0.6875003339572885
Epoch: 5 | Iteration number: [1750/4518] 38% | Training loss: 0.6874999503748758
Epoch: 5 | Iteration number: [1760/4518] 38% | Training loss: 0.6874959231438962
Epoch: 5 | Iteration number: [1770/4518] 39% | Training loss: 0.6874970949302286
Epoch: 5 | Iteration number: [1780/4518] 39% | Training loss: 0.6875006064940035
Epoch: 5 | Iteration number: [1790/4518] 39% | Training loss: 0.6874993168108956
Epoch: 5 | Iteration number: [1800/4518] 39% | Training loss: 0.6874984983272022
Epoch: 5 | Iteration number: [1810/4518] 40% | Training loss: 0.6874963317786791
Epoch: 5 | Iteration number: [1820/4518] 40% | Training loss: 0.6874912719150166
Epoch: 5 | Iteration number: [1830/4518] 40% | Training loss: 0.6874864072421861
Epoch: 5 | Iteration number: [1840/4518] 40% | Training loss: 0.6874911467990149
Epoch: 5 | Iteration number: [1850/4518] 40% | Training loss: 0.6874874915947785
Epoch: 5 | Iteration number: [1860/4518] 41% | Training loss: 0.6874869938178729
Epoch: 5 | Iteration number: [1870/4518] 41% | Training loss: 0.687488393126962
Epoch: 5 | Iteration number: [1880/4518] 41% | Training loss: 0.6874835022269411
Epoch: 5 | Iteration number: [1890/4518] 41% | Training loss: 0.6874751484267926
Epoch: 5 | Iteration number: [1900/4518] 42% | Training loss: 0.6874797907628512
Epoch: 5 | Iteration number: [1910/4518] 42% | Training loss: 0.6874793896500353
Epoch: 5 | Iteration number: [1920/4518] 42% | Training loss: 0.6874760591425002
Epoch: 5 | Iteration number: [1930/4518] 42% | Training loss: 0.6874766745715561
Epoch: 5 | Iteration number: [1940/4518] 42% | Training loss: 0.6874769256901495
Epoch: 5 | Iteration number: [1950/4518] 43% | Training loss: 0.6874776946275662
Epoch: 5 | Iteration number: [1960/4518] 43% | Training loss: 0.6874806341772177
Epoch: 5 | Iteration number: [1970/4518] 43% | Training loss: 0.6874756882335934
Epoch: 5 | Iteration number: [1980/4518] 43% | Training loss: 0.6874742901686466
Epoch: 5 | Iteration number: [1990/4518] 44% | Training loss: 0.6874797132746059
Epoch: 5 | Iteration number: [2000/4518] 44% | Training loss: 0.6874747807383538
Epoch: 5 | Iteration number: [2010/4518] 44% | Training loss: 0.6874750677922472
Epoch: 5 | Iteration number: [2020/4518] 44% | Training loss: 0.6874735362163865
Epoch: 5 | Iteration number: [2030/4518] 44% | Training loss: 0.6874712853302509
Epoch: 5 | Iteration number: [2040/4518] 45% | Training loss: 0.687470555276263
Epoch: 5 | Iteration number: [2050/4518] 45% | Training loss: 0.6874716127209547
Epoch: 5 | Iteration number: [2060/4518] 45% | Training loss: 0.6874743564614972
Epoch: 5 | Iteration number: [2070/4518] 45% | Training loss: 0.6874740352377223
Epoch: 5 | Iteration number: [2080/4518] 46% | Training loss: 0.6874788299489479
Epoch: 5 | Iteration number: [2090/4518] 46% | Training loss: 0.6874732235402011
Epoch: 5 | Iteration number: [2100/4518] 46% | Training loss: 0.6874697863487971
Epoch: 5 | Iteration number: [2110/4518] 46% | Training loss: 0.6874698523661537
Epoch: 5 | Iteration number: [2120/4518] 46% | Training loss: 0.6874667988352056
Epoch: 5 | Iteration number: [2130/4518] 47% | Training loss: 0.6874693107716914
Epoch: 5 | Iteration number: [2140/4518] 47% | Training loss: 0.6874751627723747
Epoch: 5 | Iteration number: [2150/4518] 47% | Training loss: 0.6874728773361028
Epoch: 5 | Iteration number: [2160/4518] 47% | Training loss: 0.6874720147914357
Epoch: 5 | Iteration number: [2170/4518] 48% | Training loss: 0.6874699599731903
Epoch: 5 | Iteration number: [2180/4518] 48% | Training loss: 0.6874685409692449
Epoch: 5 | Iteration number: [2190/4518] 48% | Training loss: 0.6874711271562532
Epoch: 5 | Iteration number: [2200/4518] 48% | Training loss: 0.68746771723032
Epoch: 5 | Iteration number: [2210/4518] 48% | Training loss: 0.687466550817317
Epoch: 5 | Iteration number: [2220/4518] 49% | Training loss: 0.6874702218685064
Epoch: 5 | Iteration number: [2230/4518] 49% | Training loss: 0.6874687891904548
Epoch: 5 | Iteration number: [2240/4518] 49% | Training loss: 0.6874643916264176
Epoch: 5 | Iteration number: [2250/4518] 49% | Training loss: 0.6874633625878228
Epoch: 5 | Iteration number: [2260/4518] 50% | Training loss: 0.6874640020121515
Epoch: 5 | Iteration number: [2270/4518] 50% | Training loss: 0.6874632766330819
Epoch: 5 | Iteration number: [2280/4518] 50% | Training loss: 0.6874619359248563
Epoch: 5 | Iteration number: [2290/4518] 50% | Training loss: 0.68746416011752
Epoch: 5 | Iteration number: [2300/4518] 50% | Training loss: 0.6874639866403911
Epoch: 5 | Iteration number: [2310/4518] 51% | Training loss: 0.687467107215485
Epoch: 5 | Iteration number: [2320/4518] 51% | Training loss: 0.6874673272001333
Epoch: 5 | Iteration number: [2330/4518] 51% | Training loss: 0.6874605244065559
Epoch: 5 | Iteration number: [2340/4518] 51% | Training loss: 0.6874587012916549
Epoch: 5 | Iteration number: [2350/4518] 52% | Training loss: 0.6874634790420532
Epoch: 5 | Iteration number: [2360/4518] 52% | Training loss: 0.6874674886465073
Epoch: 5 | Iteration number: [2370/4518] 52% | Training loss: 0.6874610822915025
Epoch: 5 | Iteration number: [2380/4518] 52% | Training loss: 0.6874662952763694
Epoch: 5 | Iteration number: [2390/4518] 52% | Training loss: 0.6874683541234068
Epoch: 5 | Iteration number: [2400/4518] 53% | Training loss: 0.6874649091313283
Epoch: 5 | Iteration number: [2410/4518] 53% | Training loss: 0.6874596849269392
Epoch: 5 | Iteration number: [2420/4518] 53% | Training loss: 0.6874542831389372
Epoch: 5 | Iteration number: [2430/4518] 53% | Training loss: 0.6874554445714126
Epoch: 5 | Iteration number: [2440/4518] 54% | Training loss: 0.6874549324150945
Epoch: 5 | Iteration number: [2450/4518] 54% | Training loss: 0.687457123581244
Epoch: 5 | Iteration number: [2460/4518] 54% | Training loss: 0.6874529620980828
Epoch: 5 | Iteration number: [2470/4518] 54% | Training loss: 0.6874497935115567
Epoch: 5 | Iteration number: [2480/4518] 54% | Training loss: 0.6874543587526968
Epoch: 5 | Iteration number: [2490/4518] 55% | Training loss: 0.6874531948183435
Epoch: 5 | Iteration number: [2500/4518] 55% | Training loss: 0.6874524399280548
Epoch: 5 | Iteration number: [2510/4518] 55% | Training loss: 0.6874535928209464
Epoch: 5 | Iteration number: [2520/4518] 55% | Training loss: 0.6874471803033163
Epoch: 5 | Iteration number: [2530/4518] 55% | Training loss: 0.6874453352845233
Epoch: 5 | Iteration number: [2540/4518] 56% | Training loss: 0.6874398139752741
Epoch: 5 | Iteration number: [2550/4518] 56% | Training loss: 0.6874367540490394
Epoch: 5 | Iteration number: [2560/4518] 56% | Training loss: 0.687434736546129
Epoch: 5 | Iteration number: [2570/4518] 56% | Training loss: 0.6874325988589558
Epoch: 5 | Iteration number: [2580/4518] 57% | Training loss: 0.6874280131833498
Epoch: 5 | Iteration number: [2590/4518] 57% | Training loss: 0.6874295501405208
Epoch: 5 | Iteration number: [2600/4518] 57% | Training loss: 0.6874305570813326
Epoch: 5 | Iteration number: [2610/4518] 57% | Training loss: 0.6874286282564945
Epoch: 5 | Iteration number: [2620/4518] 57% | Training loss: 0.6874292006701913
Epoch: 5 | Iteration number: [2630/4518] 58% | Training loss: 0.6874246028892894
Epoch: 5 | Iteration number: [2640/4518] 58% | Training loss: 0.6874282403877288
Epoch: 5 | Iteration number: [2650/4518] 58% | Training loss: 0.687427583752938
Epoch: 5 | Iteration number: [2660/4518] 58% | Training loss: 0.6874214216506571
Epoch: 5 | Iteration number: [2670/4518] 59% | Training loss: 0.6874178358678068
Epoch: 5 | Iteration number: [2680/4518] 59% | Training loss: 0.6874191199220828
Epoch: 5 | Iteration number: [2690/4518] 59% | Training loss: 0.6874160583577634
Epoch: 5 | Iteration number: [2700/4518] 59% | Training loss: 0.6874107144276301
Epoch: 5 | Iteration number: [2710/4518] 59% | Training loss: 0.6874107268463642
Epoch: 5 | Iteration number: [2720/4518] 60% | Training loss: 0.6874125749530161
Epoch: 5 | Iteration number: [2730/4518] 60% | Training loss: 0.6874141529584542
Epoch: 5 | Iteration number: [2740/4518] 60% | Training loss: 0.6874172673173194
Epoch: 5 | Iteration number: [2750/4518] 60% | Training loss: 0.6874175236658616
Epoch: 5 | Iteration number: [2760/4518] 61% | Training loss: 0.687415723869766
Epoch: 5 | Iteration number: [2770/4518] 61% | Training loss: 0.6874170951679726
Epoch: 5 | Iteration number: [2780/4518] 61% | Training loss: 0.6874147081975457
Epoch: 5 | Iteration number: [2790/4518] 61% | Training loss: 0.6874119051682052
Epoch: 5 | Iteration number: [2800/4518] 61% | Training loss: 0.6874088560044765
Epoch: 5 | Iteration number: [2810/4518] 62% | Training loss: 0.6874057088458241
Epoch: 5 | Iteration number: [2820/4518] 62% | Training loss: 0.6874048749183087
Epoch: 5 | Iteration number: [2830/4518] 62% | Training loss: 0.6874030038872372
Epoch: 5 | Iteration number: [2840/4518] 62% | Training loss: 0.687404407392925
Epoch: 5 | Iteration number: [2850/4518] 63% | Training loss: 0.6873980755136724
Epoch: 5 | Iteration number: [2860/4518] 63% | Training loss: 0.6873956190122591
Epoch: 5 | Iteration number: [2870/4518] 63% | Training loss: 0.6873951140596476
Epoch: 5 | Iteration number: [2880/4518] 63% | Training loss: 0.6873970224211613
Epoch: 5 | Iteration number: [2890/4518] 63% | Training loss: 0.6873934372279883
Epoch: 5 | Iteration number: [2900/4518] 64% | Training loss: 0.6873906802720037
Epoch: 5 | Iteration number: [2910/4518] 64% | Training loss: 0.6873887841439329
Epoch: 5 | Iteration number: [2920/4518] 64% | Training loss: 0.6873860100564891
Epoch: 5 | Iteration number: [2930/4518] 64% | Training loss: 0.6873847939862326
Epoch: 5 | Iteration number: [2940/4518] 65% | Training loss: 0.6873839212720897
Epoch: 5 | Iteration number: [2950/4518] 65% | Training loss: 0.6873839355323275
Epoch: 5 | Iteration number: [2960/4518] 65% | Training loss: 0.6873853167166581
Epoch: 5 | Iteration number: [2970/4518] 65% | Training loss: 0.6873838731736848
Epoch: 5 | Iteration number: [2980/4518] 65% | Training loss: 0.6873778988450966
Epoch: 5 | Iteration number: [2990/4518] 66% | Training loss: 0.6873764143939002
Epoch: 5 | Iteration number: [3000/4518] 66% | Training loss: 0.6873767393628756
Epoch: 5 | Iteration number: [3010/4518] 66% | Training loss: 0.6873761367362203
Epoch: 5 | Iteration number: [3020/4518] 66% | Training loss: 0.6873757571771445
Epoch: 5 | Iteration number: [3030/4518] 67% | Training loss: 0.6873732079570443
Epoch: 5 | Iteration number: [3040/4518] 67% | Training loss: 0.6873723995528723
Epoch: 5 | Iteration number: [3050/4518] 67% | Training loss: 0.687376145417573
Epoch: 5 | Iteration number: [3060/4518] 67% | Training loss: 0.6873804172074872
Epoch: 5 | Iteration number: [3070/4518] 67% | Training loss: 0.6873740174871315
Epoch: 5 | Iteration number: [3080/4518] 68% | Training loss: 0.6873759005363885
Epoch: 5 | Iteration number: [3090/4518] 68% | Training loss: 0.6873733840328204
Epoch: 5 | Iteration number: [3100/4518] 68% | Training loss: 0.6873734468221664
Epoch: 5 | Iteration number: [3110/4518] 68% | Training loss: 0.6873741901955804
Epoch: 5 | Iteration number: [3120/4518] 69% | Training loss: 0.6873759189859415
Epoch: 5 | Iteration number: [3130/4518] 69% | Training loss: 0.6873754647974009
Epoch: 5 | Iteration number: [3140/4518] 69% | Training loss: 0.6873686115832846
Epoch: 5 | Iteration number: [3150/4518] 69% | Training loss: 0.6873672585827963
Epoch: 5 | Iteration number: [3160/4518] 69% | Training loss: 0.6873696714451042
Epoch: 5 | Iteration number: [3170/4518] 70% | Training loss: 0.6873692713701387
Epoch: 5 | Iteration number: [3180/4518] 70% | Training loss: 0.6873665400083709
Epoch: 5 | Iteration number: [3190/4518] 70% | Training loss: 0.6873653879733669
Epoch: 5 | Iteration number: [3200/4518] 70% | Training loss: 0.6873676009103655
Epoch: 5 | Iteration number: [3210/4518] 71% | Training loss: 0.6873685436642429
Epoch: 5 | Iteration number: [3220/4518] 71% | Training loss: 0.6873717611620885
Epoch: 5 | Iteration number: [3230/4518] 71% | Training loss: 0.6873719862371037
Epoch: 5 | Iteration number: [3240/4518] 71% | Training loss: 0.6873738498047546
Epoch: 5 | Iteration number: [3250/4518] 71% | Training loss: 0.6873725997668046
Epoch: 5 | Iteration number: [3260/4518] 72% | Training loss: 0.6873699844980532
Epoch: 5 | Iteration number: [3270/4518] 72% | Training loss: 0.6873730682451791
Epoch: 5 | Iteration number: [3280/4518] 72% | Training loss: 0.6873753531676967
Epoch: 5 | Iteration number: [3290/4518] 72% | Training loss: 0.6873747880697975
Epoch: 5 | Iteration number: [3300/4518] 73% | Training loss: 0.6873749477574319
Epoch: 5 | Iteration number: [3310/4518] 73% | Training loss: 0.6873729788644797
Epoch: 5 | Iteration number: [3320/4518] 73% | Training loss: 0.6873702415680311
Epoch: 5 | Iteration number: [3330/4518] 73% | Training loss: 0.6873683764590873
Epoch: 5 | Iteration number: [3340/4518] 73% | Training loss: 0.6873685255914391
Epoch: 5 | Iteration number: [3350/4518] 74% | Training loss: 0.6873670380506942
Epoch: 5 | Iteration number: [3360/4518] 74% | Training loss: 0.6873694764716285
Epoch: 5 | Iteration number: [3370/4518] 74% | Training loss: 0.6873673276660704
Epoch: 5 | Iteration number: [3380/4518] 74% | Training loss: 0.687366121319624
Epoch: 5 | Iteration number: [3390/4518] 75% | Training loss: 0.6873653764394181
Epoch: 5 | Iteration number: [3400/4518] 75% | Training loss: 0.6873652569861973
Epoch: 5 | Iteration number: [3410/4518] 75% | Training loss: 0.6873652194077668
Epoch: 5 | Iteration number: [3420/4518] 75% | Training loss: 0.6873661989879887
Epoch: 5 | Iteration number: [3430/4518] 75% | Training loss: 0.6873633333267345
Epoch: 5 | Iteration number: [3440/4518] 76% | Training loss: 0.6873655417804108
Epoch: 5 | Iteration number: [3450/4518] 76% | Training loss: 0.687364149508269
Epoch: 5 | Iteration number: [3460/4518] 76% | Training loss: 0.6873632444122623
Epoch: 5 | Iteration number: [3470/4518] 76% | Training loss: 0.6873625283969582
Epoch: 5 | Iteration number: [3480/4518] 77% | Training loss: 0.687361034339872
Epoch: 5 | Iteration number: [3490/4518] 77% | Training loss: 0.6873556832870986
Epoch: 5 | Iteration number: [3500/4518] 77% | Training loss: 0.6873554514135634
Epoch: 5 | Iteration number: [3510/4518] 77% | Training loss: 0.6873526511708555
Epoch: 5 | Iteration number: [3520/4518] 77% | Training loss: 0.6873513588512485
Epoch: 5 | Iteration number: [3530/4518] 78% | Training loss: 0.6873491506063228
Epoch: 5 | Iteration number: [3540/4518] 78% | Training loss: 0.6873443502995927
Epoch: 5 | Iteration number: [3550/4518] 78% | Training loss: 0.6873471861154261
Epoch: 5 | Iteration number: [3560/4518] 78% | Training loss: 0.6873486117365655
Epoch: 5 | Iteration number: [3570/4518] 79% | Training loss: 0.687348073720932
Epoch: 5 | Iteration number: [3580/4518] 79% | Training loss: 0.6873484213591954
Epoch: 5 | Iteration number: [3590/4518] 79% | Training loss: 0.6873493260493849
Epoch: 5 | Iteration number: [3600/4518] 79% | Training loss: 0.6873474556373226
Epoch: 5 | Iteration number: [3610/4518] 79% | Training loss: 0.6873443573630748
Epoch: 5 | Iteration number: [3620/4518] 80% | Training loss: 0.6873406918667957
Epoch: 5 | Iteration number: [3630/4518] 80% | Training loss: 0.6873414236816164
Epoch: 5 | Iteration number: [3640/4518] 80% | Training loss: 0.6873441930164348
Epoch: 5 | Iteration number: [3650/4518] 80% | Training loss: 0.6873433345637909
Epoch: 5 | Iteration number: [3660/4518] 81% | Training loss: 0.6873418132789799
Epoch: 5 | Iteration number: [3670/4518] 81% | Training loss: 0.6873430288292731
Epoch: 5 | Iteration number: [3680/4518] 81% | Training loss: 0.687343192473054
Epoch: 5 | Iteration number: [3690/4518] 81% | Training loss: 0.6873435666082998
Epoch: 5 | Iteration number: [3700/4518] 81% | Training loss: 0.6873459474621593
Epoch: 5 | Iteration number: [3710/4518] 82% | Training loss: 0.6873476535001534
Epoch: 5 | Iteration number: [3720/4518] 82% | Training loss: 0.6873466302790949
Epoch: 5 | Iteration number: [3730/4518] 82% | Training loss: 0.6873479830196012
Epoch: 5 | Iteration number: [3740/4518] 82% | Training loss: 0.6873475740140772
Epoch: 5 | Iteration number: [3750/4518] 83% | Training loss: 0.6873457110087077
Epoch: 5 | Iteration number: [3760/4518] 83% | Training loss: 0.6873444769293704
Epoch: 5 | Iteration number: [3770/4518] 83% | Training loss: 0.6873425433110811
Epoch: 5 | Iteration number: [3780/4518] 83% | Training loss: 0.6873425297005467
Epoch: 5 | Iteration number: [3790/4518] 83% | Training loss: 0.6873405448836827
Epoch: 5 | Iteration number: [3800/4518] 84% | Training loss: 0.6873382239278994
Epoch: 5 | Iteration number: [3810/4518] 84% | Training loss: 0.6873376208340402
Epoch: 5 | Iteration number: [3820/4518] 84% | Training loss: 0.6873362459593418
Epoch: 5 | Iteration number: [3830/4518] 84% | Training loss: 0.6873343303994162
Epoch: 5 | Iteration number: [3840/4518] 84% | Training loss: 0.6873356341539572
Epoch: 5 | Iteration number: [3850/4518] 85% | Training loss: 0.6873331522012686
Epoch: 5 | Iteration number: [3860/4518] 85% | Training loss: 0.6873324148241102
Epoch: 5 | Iteration number: [3870/4518] 85% | Training loss: 0.6873330926402287
Epoch: 5 | Iteration number: [3880/4518] 85% | Training loss: 0.6873348847185213
Epoch: 5 | Iteration number: [3890/4518] 86% | Training loss: 0.6873347203498634
Epoch: 5 | Iteration number: [3900/4518] 86% | Training loss: 0.6873322830903225
Epoch: 5 | Iteration number: [3910/4518] 86% | Training loss: 0.6873318098847518
Epoch: 5 | Iteration number: [3920/4518] 86% | Training loss: 0.6873332141461421
Epoch: 5 | Iteration number: [3930/4518] 86% | Training loss: 0.6873296575995196
Epoch: 5 | Iteration number: [3940/4518] 87% | Training loss: 0.6873298823077062
Epoch: 5 | Iteration number: [3950/4518] 87% | Training loss: 0.6873279827908625
Epoch: 5 | Iteration number: [3960/4518] 87% | Training loss: 0.687327343466306
Epoch: 5 | Iteration number: [3970/4518] 87% | Training loss: 0.6873258935714549
Epoch: 5 | Iteration number: [3980/4518] 88% | Training loss: 0.6873272838454749
Epoch: 5 | Iteration number: [3990/4518] 88% | Training loss: 0.6873253008626159
Epoch: 5 | Iteration number: [4000/4518] 88% | Training loss: 0.6873251275271177
Epoch: 5 | Iteration number: [4010/4518] 88% | Training loss: 0.687323734231126
Epoch: 5 | Iteration number: [4020/4518] 88% | Training loss: 0.6873210747295351
Epoch: 5 | Iteration number: [4030/4518] 89% | Training loss: 0.6873227355941649
Epoch: 5 | Iteration number: [4040/4518] 89% | Training loss: 0.6873220238797736
Epoch: 5 | Iteration number: [4050/4518] 89% | Training loss: 0.687323416442047
Epoch: 5 | Iteration number: [4060/4518] 89% | Training loss: 0.6873221150906802
Epoch: 5 | Iteration number: [4070/4518] 90% | Training loss: 0.6873208916157997
Epoch: 5 | Iteration number: [4080/4518] 90% | Training loss: 0.6873188412072612
Epoch: 5 | Iteration number: [4090/4518] 90% | Training loss: 0.6873161975795308
Epoch: 5 | Iteration number: [4100/4518] 90% | Training loss: 0.6873180840364317
Epoch: 5 | Iteration number: [4110/4518] 90% | Training loss: 0.6873115084467143
Epoch: 5 | Iteration number: [4120/4518] 91% | Training loss: 0.6873126247120135
Epoch: 5 | Iteration number: [4130/4518] 91% | Training loss: 0.6873138071116754
Epoch: 5 | Iteration number: [4140/4518] 91% | Training loss: 0.6873154587071875
Epoch: 5 | Iteration number: [4150/4518] 91% | Training loss: 0.6873130785844412
Epoch: 5 | Iteration number: [4160/4518] 92% | Training loss: 0.6873121426655696
Epoch: 5 | Iteration number: [4170/4518] 92% | Training loss: 0.6873151696700273
Epoch: 5 | Iteration number: [4180/4518] 92% | Training loss: 0.6873139550098392
Epoch: 5 | Iteration number: [4190/4518] 92% | Training loss: 0.6873159117232075
Epoch: 5 | Iteration number: [4200/4518] 92% | Training loss: 0.687317323017688
Epoch: 5 | Iteration number: [4210/4518] 93% | Training loss: 0.6873179258190255
Epoch: 5 | Iteration number: [4220/4518] 93% | Training loss: 0.6873192984769695
Epoch: 5 | Iteration number: [4230/4518] 93% | Training loss: 0.6873197194955027
Epoch: 5 | Iteration number: [4240/4518] 93% | Training loss: 0.6873219261191926
Epoch: 5 | Iteration number: [4250/4518] 94% | Training loss: 0.6873222266085007
Epoch: 5 | Iteration number: [4260/4518] 94% | Training loss: 0.6873233854630744
Epoch: 5 | Iteration number: [4270/4518] 94% | Training loss: 0.6873247379441451
Epoch: 5 | Iteration number: [4280/4518] 94% | Training loss: 0.6873256092316636
Epoch: 5 | Iteration number: [4290/4518] 94% | Training loss: 0.6873247931053589
Epoch: 5 | Iteration number: [4300/4518] 95% | Training loss: 0.6873250558903051
Epoch: 5 | Iteration number: [4310/4518] 95% | Training loss: 0.6873258802702698
Epoch: 5 | Iteration number: [4320/4518] 95% | Training loss: 0.6873258785379154
Epoch: 5 | Iteration number: [4330/4518] 95% | Training loss: 0.687327256833158
Epoch: 5 | Iteration number: [4340/4518] 96% | Training loss: 0.6873218636358938
Epoch: 5 | Iteration number: [4350/4518] 96% | Training loss: 0.6873255296274163
Epoch: 5 | Iteration number: [4360/4518] 96% | Training loss: 0.6873266989211424
Epoch: 5 | Iteration number: [4370/4518] 96% | Training loss: 0.6873242211696485
Epoch: 5 | Iteration number: [4380/4518] 96% | Training loss: 0.6873244485218231
Epoch: 5 | Iteration number: [4390/4518] 97% | Training loss: 0.6873246247513147
Epoch: 5 | Iteration number: [4400/4518] 97% | Training loss: 0.6873250145126473
Epoch: 5 | Iteration number: [4410/4518] 97% | Training loss: 0.687325779177975
Epoch: 5 | Iteration number: [4420/4518] 97% | Training loss: 0.6873245755876352
Epoch: 5 | Iteration number: [4430/4518] 98% | Training loss: 0.6873239369478505
Epoch: 5 | Iteration number: [4440/4518] 98% | Training loss: 0.687321875586703
Epoch: 5 | Iteration number: [4450/4518] 98% | Training loss: 0.6873240238495087
Epoch: 5 | Iteration number: [4460/4518] 98% | Training loss: 0.6873273453771266
Epoch: 5 | Iteration number: [4470/4518] 98% | Training loss: 0.6873293153658276
Epoch: 5 | Iteration number: [4480/4518] 99% | Training loss: 0.6873299824340003
Epoch: 5 | Iteration number: [4490/4518] 99% | Training loss: 0.6873310850298484
Epoch: 5 | Iteration number: [4500/4518] 99% | Training loss: 0.6873337319427066
Epoch: 5 | Iteration number: [4510/4518] 99% | Training loss: 0.6873308886709869

 End of epoch: 5 | Train Loss: 0.6871778487288461 | Training Time: 643 

 End of epoch: 5 | Eval Loss: 0.6905376412430588 | Evaluating Time: 23 
Epoch: 6 | Iteration number: [10/4518] 0% | Training loss: 0.753856360912323
Epoch: 6 | Iteration number: [20/4518] 0% | Training loss: 0.7203965544700622
Epoch: 6 | Iteration number: [30/4518] 0% | Training loss: 0.7093270619710287
Epoch: 6 | Iteration number: [40/4518] 0% | Training loss: 0.703753051161766
Epoch: 6 | Iteration number: [50/4518] 1% | Training loss: 0.7007399451732635
Epoch: 6 | Iteration number: [60/4518] 1% | Training loss: 0.6982240011294683
Epoch: 6 | Iteration number: [70/4518] 1% | Training loss: 0.6964934774807521
Epoch: 6 | Iteration number: [80/4518] 1% | Training loss: 0.695238483697176
Epoch: 6 | Iteration number: [90/4518] 1% | Training loss: 0.6943550560209486
Epoch: 6 | Iteration number: [100/4518] 2% | Training loss: 0.6936193126440048
Epoch: 6 | Iteration number: [110/4518] 2% | Training loss: 0.693136558749459
Epoch: 6 | Iteration number: [120/4518] 2% | Training loss: 0.6926430056492487
Epoch: 6 | Iteration number: [130/4518] 2% | Training loss: 0.6921698978314033
Epoch: 6 | Iteration number: [140/4518] 3% | Training loss: 0.6918084710836411
Epoch: 6 | Iteration number: [150/4518] 3% | Training loss: 0.6914916078249613
Epoch: 6 | Iteration number: [160/4518] 3% | Training loss: 0.6912382144480944
Epoch: 6 | Iteration number: [170/4518] 3% | Training loss: 0.6911151402136859
Epoch: 6 | Iteration number: [180/4518] 3% | Training loss: 0.6908151825269063
Epoch: 6 | Iteration number: [190/4518] 4% | Training loss: 0.6906359076499939
Epoch: 6 | Iteration number: [200/4518] 4% | Training loss: 0.6905082601308823
Epoch: 6 | Iteration number: [210/4518] 4% | Training loss: 0.6904079346429735
Epoch: 6 | Iteration number: [220/4518] 4% | Training loss: 0.6902037224986336
Epoch: 6 | Iteration number: [230/4518] 5% | Training loss: 0.6900098406750222
Epoch: 6 | Iteration number: [240/4518] 5% | Training loss: 0.68986658329765
Epoch: 6 | Iteration number: [250/4518] 5% | Training loss: 0.6897537834644317
Epoch: 6 | Iteration number: [260/4518] 5% | Training loss: 0.6896372114236539
Epoch: 6 | Iteration number: [270/4518] 5% | Training loss: 0.6895448205647645
Epoch: 6 | Iteration number: [280/4518] 6% | Training loss: 0.6894183131200927
Epoch: 6 | Iteration number: [290/4518] 6% | Training loss: 0.6893683678117292
Epoch: 6 | Iteration number: [300/4518] 6% | Training loss: 0.6892796003818512
Epoch: 6 | Iteration number: [310/4518] 6% | Training loss: 0.6892214180961732
Epoch: 6 | Iteration number: [320/4518] 7% | Training loss: 0.6891783110797405
Epoch: 6 | Iteration number: [330/4518] 7% | Training loss: 0.6890731204639782
Epoch: 6 | Iteration number: [340/4518] 7% | Training loss: 0.6889836477882721
Epoch: 6 | Iteration number: [350/4518] 7% | Training loss: 0.6889188402039664
Epoch: 6 | Iteration number: [360/4518] 7% | Training loss: 0.6888860591583782
Epoch: 6 | Iteration number: [370/4518] 8% | Training loss: 0.688769001896317
Epoch: 6 | Iteration number: [380/4518] 8% | Training loss: 0.6887011142153489
Epoch: 6 | Iteration number: [390/4518] 8% | Training loss: 0.6886528122119414
Epoch: 6 | Iteration number: [400/4518] 8% | Training loss: 0.6886428184807301
Epoch: 6 | Iteration number: [410/4518] 9% | Training loss: 0.6885998776773127
Epoch: 6 | Iteration number: [420/4518] 9% | Training loss: 0.688588118978909
Epoch: 6 | Iteration number: [430/4518] 9% | Training loss: 0.6885490481243577
Epoch: 6 | Iteration number: [440/4518] 9% | Training loss: 0.688534112545577
Epoch: 6 | Iteration number: [450/4518] 9% | Training loss: 0.6885169409381019
Epoch: 6 | Iteration number: [460/4518] 10% | Training loss: 0.6884618379499601
Epoch: 6 | Iteration number: [470/4518] 10% | Training loss: 0.6884471280777708
Epoch: 6 | Iteration number: [480/4518] 10% | Training loss: 0.688429365803798
Epoch: 6 | Iteration number: [490/4518] 10% | Training loss: 0.6883952257584552
Epoch: 6 | Iteration number: [500/4518] 11% | Training loss: 0.6883695719242096
Epoch: 6 | Iteration number: [510/4518] 11% | Training loss: 0.6883779613410725
Epoch: 6 | Iteration number: [520/4518] 11% | Training loss: 0.6883617428632883
Epoch: 6 | Iteration number: [530/4518] 11% | Training loss: 0.6883372223602151
Epoch: 6 | Iteration number: [540/4518] 11% | Training loss: 0.6883461068073908
Epoch: 6 | Iteration number: [550/4518] 12% | Training loss: 0.6883544773405248
Epoch: 6 | Iteration number: [560/4518] 12% | Training loss: 0.6883281610906125
Epoch: 6 | Iteration number: [570/4518] 12% | Training loss: 0.6883177830461871
Epoch: 6 | Iteration number: [580/4518] 12% | Training loss: 0.688285544822956
Epoch: 6 | Iteration number: [590/4518] 13% | Training loss: 0.6882634233620207
Epoch: 6 | Iteration number: [600/4518] 13% | Training loss: 0.688245660463969
Epoch: 6 | Iteration number: [610/4518] 13% | Training loss: 0.6882331646856714
Epoch: 6 | Iteration number: [620/4518] 13% | Training loss: 0.6882160328088268
Epoch: 6 | Iteration number: [630/4518] 13% | Training loss: 0.6881885049835084
Epoch: 6 | Iteration number: [640/4518] 14% | Training loss: 0.6881823467090726
Epoch: 6 | Iteration number: [650/4518] 14% | Training loss: 0.6881762798015888
Epoch: 6 | Iteration number: [660/4518] 14% | Training loss: 0.6881490956653248
Epoch: 6 | Iteration number: [670/4518] 14% | Training loss: 0.6881185763807439
Epoch: 6 | Iteration number: [680/4518] 15% | Training loss: 0.6881083198329981
Epoch: 6 | Iteration number: [690/4518] 15% | Training loss: 0.6880885334982388
Epoch: 6 | Iteration number: [700/4518] 15% | Training loss: 0.6880751318590982
Epoch: 6 | Iteration number: [710/4518] 15% | Training loss: 0.6880662886189742
Epoch: 6 | Iteration number: [720/4518] 15% | Training loss: 0.6880549877882004
Epoch: 6 | Iteration number: [730/4518] 16% | Training loss: 0.6880530946058769
Epoch: 6 | Iteration number: [740/4518] 16% | Training loss: 0.6880358763643213
Epoch: 6 | Iteration number: [750/4518] 16% | Training loss: 0.6880291255315145
Epoch: 6 | Iteration number: [760/4518] 16% | Training loss: 0.6880195540032888
Epoch: 6 | Iteration number: [770/4518] 17% | Training loss: 0.6879996431338322
Epoch: 6 | Iteration number: [780/4518] 17% | Training loss: 0.6879836187148706
Epoch: 6 | Iteration number: [790/4518] 17% | Training loss: 0.6879744180395634
Epoch: 6 | Iteration number: [800/4518] 17% | Training loss: 0.687957925722003
Epoch: 6 | Iteration number: [810/4518] 17% | Training loss: 0.6879455856335016
Epoch: 6 | Iteration number: [820/4518] 18% | Training loss: 0.687920336243583
Epoch: 6 | Iteration number: [830/4518] 18% | Training loss: 0.6879190099526601
Epoch: 6 | Iteration number: [840/4518] 18% | Training loss: 0.6879053465667225
Epoch: 6 | Iteration number: [850/4518] 18% | Training loss: 0.6879067069642684
Epoch: 6 | Iteration number: [860/4518] 19% | Training loss: 0.6879199068213618
Epoch: 6 | Iteration number: [870/4518] 19% | Training loss: 0.687903688077269
Epoch: 6 | Iteration number: [880/4518] 19% | Training loss: 0.6878976125608791
Epoch: 6 | Iteration number: [890/4518] 19% | Training loss: 0.6878873378373264
Epoch: 6 | Iteration number: [900/4518] 19% | Training loss: 0.6878716412517759
Epoch: 6 | Iteration number: [910/4518] 20% | Training loss: 0.6878571130417206
Epoch: 6 | Iteration number: [920/4518] 20% | Training loss: 0.6878591876315034
Epoch: 6 | Iteration number: [930/4518] 20% | Training loss: 0.68785164375459
Epoch: 6 | Iteration number: [940/4518] 20% | Training loss: 0.6878585336056161
Epoch: 6 | Iteration number: [950/4518] 21% | Training loss: 0.6878504524732891
Epoch: 6 | Iteration number: [960/4518] 21% | Training loss: 0.6878393745049834
Epoch: 6 | Iteration number: [970/4518] 21% | Training loss: 0.6878316079218363
Epoch: 6 | Iteration number: [980/4518] 21% | Training loss: 0.687830124460921
Epoch: 6 | Iteration number: [990/4518] 21% | Training loss: 0.687819040182865
Epoch: 6 | Iteration number: [1000/4518] 22% | Training loss: 0.6878035324215889
Epoch: 6 | Iteration number: [1010/4518] 22% | Training loss: 0.6877950375623042
Epoch: 6 | Iteration number: [1020/4518] 22% | Training loss: 0.6877855702358133
Epoch: 6 | Iteration number: [1030/4518] 22% | Training loss: 0.6877915823343889
Epoch: 6 | Iteration number: [1040/4518] 23% | Training loss: 0.6877979253347103
Epoch: 6 | Iteration number: [1050/4518] 23% | Training loss: 0.6877839483533587
Epoch: 6 | Iteration number: [1060/4518] 23% | Training loss: 0.6877784954489402
Epoch: 6 | Iteration number: [1070/4518] 23% | Training loss: 0.6877827358580081
Epoch: 6 | Iteration number: [1080/4518] 23% | Training loss: 0.6877883474583979
Epoch: 6 | Iteration number: [1090/4518] 24% | Training loss: 0.6877932121994299
Epoch: 6 | Iteration number: [1100/4518] 24% | Training loss: 0.6877938582138582
Epoch: 6 | Iteration number: [1110/4518] 24% | Training loss: 0.6877916833301922
Epoch: 6 | Iteration number: [1120/4518] 24% | Training loss: 0.6877800971269608
Epoch: 6 | Iteration number: [1130/4518] 25% | Training loss: 0.6877736230867099
Epoch: 6 | Iteration number: [1140/4518] 25% | Training loss: 0.6877654233522582
Epoch: 6 | Iteration number: [1150/4518] 25% | Training loss: 0.6877603635580644
Epoch: 6 | Iteration number: [1160/4518] 25% | Training loss: 0.6877558298665901
Epoch: 6 | Iteration number: [1170/4518] 25% | Training loss: 0.6877524955659851
Epoch: 6 | Iteration number: [1180/4518] 26% | Training loss: 0.6877468025280258
Epoch: 6 | Iteration number: [1190/4518] 26% | Training loss: 0.6877390590034613
Epoch: 6 | Iteration number: [1200/4518] 26% | Training loss: 0.6877364935477575
Epoch: 6 | Iteration number: [1210/4518] 26% | Training loss: 0.6877383453294266
Epoch: 6 | Iteration number: [1220/4518] 27% | Training loss: 0.687720656492671
Epoch: 6 | Iteration number: [1230/4518] 27% | Training loss: 0.6877171744176043
Epoch: 6 | Iteration number: [1240/4518] 27% | Training loss: 0.6877082077245559
Epoch: 6 | Iteration number: [1250/4518] 27% | Training loss: 0.6877115270137787
Epoch: 6 | Iteration number: [1260/4518] 27% | Training loss: 0.6877159316388387
Epoch: 6 | Iteration number: [1270/4518] 28% | Training loss: 0.6877114108697636
Epoch: 6 | Iteration number: [1280/4518] 28% | Training loss: 0.6877031501848251
Epoch: 6 | Iteration number: [1290/4518] 28% | Training loss: 0.6876947516156722
Epoch: 6 | Iteration number: [1300/4518] 28% | Training loss: 0.6876925517504032
Epoch: 6 | Iteration number: [1310/4518] 28% | Training loss: 0.68769023336527
Epoch: 6 | Iteration number: [1320/4518] 29% | Training loss: 0.6876853695873059
Epoch: 6 | Iteration number: [1330/4518] 29% | Training loss: 0.6876759822207286
Epoch: 6 | Iteration number: [1340/4518] 29% | Training loss: 0.6876650627424468
Epoch: 6 | Iteration number: [1350/4518] 29% | Training loss: 0.687665890234488
Epoch: 6 | Iteration number: [1360/4518] 30% | Training loss: 0.6876677750664599
Epoch: 6 | Iteration number: [1370/4518] 30% | Training loss: 0.6876708612389808
Epoch: 6 | Iteration number: [1380/4518] 30% | Training loss: 0.6876665583555249
Epoch: 6 | Iteration number: [1390/4518] 30% | Training loss: 0.687660922206563
Epoch: 6 | Iteration number: [1400/4518] 30% | Training loss: 0.6876534594808306
Epoch: 6 | Iteration number: [1410/4518] 31% | Training loss: 0.6876535481594979
Epoch: 6 | Iteration number: [1420/4518] 31% | Training loss: 0.6876512090505009
Epoch: 6 | Iteration number: [1430/4518] 31% | Training loss: 0.687650892826227
Epoch: 6 | Iteration number: [1440/4518] 31% | Training loss: 0.687645541338457
Epoch: 6 | Iteration number: [1450/4518] 32% | Training loss: 0.6876468398242161
Epoch: 6 | Iteration number: [1460/4518] 32% | Training loss: 0.6876470754816107
Epoch: 6 | Iteration number: [1470/4518] 32% | Training loss: 0.6876484010495296
Epoch: 6 | Iteration number: [1480/4518] 32% | Training loss: 0.6876455735515904
Epoch: 6 | Iteration number: [1490/4518] 32% | Training loss: 0.6876419030979976
Epoch: 6 | Iteration number: [1500/4518] 33% | Training loss: 0.6876382743914922
Epoch: 6 | Iteration number: [1510/4518] 33% | Training loss: 0.6876334554706978
Epoch: 6 | Iteration number: [1520/4518] 33% | Training loss: 0.6876322396491703
Epoch: 6 | Iteration number: [1530/4518] 33% | Training loss: 0.6876317072927562
Epoch: 6 | Iteration number: [1540/4518] 34% | Training loss: 0.6876253681136416
Epoch: 6 | Iteration number: [1550/4518] 34% | Training loss: 0.6876226842787958
Epoch: 6 | Iteration number: [1560/4518] 34% | Training loss: 0.687625440229208
Epoch: 6 | Iteration number: [1570/4518] 34% | Training loss: 0.6876228388327702
Epoch: 6 | Iteration number: [1580/4518] 34% | Training loss: 0.6876200867227361
Epoch: 6 | Iteration number: [1590/4518] 35% | Training loss: 0.6876222682823925
Epoch: 6 | Iteration number: [1600/4518] 35% | Training loss: 0.6876167374849319
Epoch: 6 | Iteration number: [1610/4518] 35% | Training loss: 0.6876107093340121
Epoch: 6 | Iteration number: [1620/4518] 35% | Training loss: 0.687599046178806
Epoch: 6 | Iteration number: [1630/4518] 36% | Training loss: 0.6875948556727427
Epoch: 6 | Iteration number: [1640/4518] 36% | Training loss: 0.6875913935827046
Epoch: 6 | Iteration number: [1650/4518] 36% | Training loss: 0.6875926552758073
Epoch: 6 | Iteration number: [1660/4518] 36% | Training loss: 0.6875886482646666
Epoch: 6 | Iteration number: [1670/4518] 36% | Training loss: 0.68757616245818
Epoch: 6 | Iteration number: [1680/4518] 37% | Training loss: 0.6875722267798015
Epoch: 6 | Iteration number: [1690/4518] 37% | Training loss: 0.6875659169530022
Epoch: 6 | Iteration number: [1700/4518] 37% | Training loss: 0.6875566067415125
Epoch: 6 | Iteration number: [1710/4518] 37% | Training loss: 0.6875562463238922
Epoch: 6 | Iteration number: [1720/4518] 38% | Training loss: 0.6875558159379072
Epoch: 6 | Iteration number: [1730/4518] 38% | Training loss: 0.6875404762739391
Epoch: 6 | Iteration number: [1740/4518] 38% | Training loss: 0.6875341319489753
Epoch: 6 | Iteration number: [1750/4518] 38% | Training loss: 0.687537914957319
Epoch: 6 | Iteration number: [1760/4518] 38% | Training loss: 0.687538616630164
Epoch: 6 | Iteration number: [1770/4518] 39% | Training loss: 0.6875393382573531
Epoch: 6 | Iteration number: [1780/4518] 39% | Training loss: 0.6875331368004338
Epoch: 6 | Iteration number: [1790/4518] 39% | Training loss: 0.6875364198365025
Epoch: 6 | Iteration number: [1800/4518] 39% | Training loss: 0.6875314342313342
Epoch: 6 | Iteration number: [1810/4518] 40% | Training loss: 0.6875302403012692
Epoch: 6 | Iteration number: [1820/4518] 40% | Training loss: 0.687525886624724
Epoch: 6 | Iteration number: [1830/4518] 40% | Training loss: 0.6875306600755681
Epoch: 6 | Iteration number: [1840/4518] 40% | Training loss: 0.687530294449433
Epoch: 6 | Iteration number: [1850/4518] 40% | Training loss: 0.6875309872627259
Epoch: 6 | Iteration number: [1860/4518] 41% | Training loss: 0.6875339415445123
Epoch: 6 | Iteration number: [1870/4518] 41% | Training loss: 0.6875362483575382
Epoch: 6 | Iteration number: [1880/4518] 41% | Training loss: 0.6875404988514616
Epoch: 6 | Iteration number: [1890/4518] 41% | Training loss: 0.6875392869351402
Epoch: 6 | Iteration number: [1900/4518] 42% | Training loss: 0.6875394020268791
Epoch: 6 | Iteration number: [1910/4518] 42% | Training loss: 0.6875387552208926
Epoch: 6 | Iteration number: [1920/4518] 42% | Training loss: 0.6875419426088532
Epoch: 6 | Iteration number: [1930/4518] 42% | Training loss: 0.6875437949914389
Epoch: 6 | Iteration number: [1940/4518] 42% | Training loss: 0.6875386893441997
Epoch: 6 | Iteration number: [1950/4518] 43% | Training loss: 0.6875397375913767
Epoch: 6 | Iteration number: [1960/4518] 43% | Training loss: 0.6875372414990347
Epoch: 6 | Iteration number: [1970/4518] 43% | Training loss: 0.6875391414927953
Epoch: 6 | Iteration number: [1980/4518] 43% | Training loss: 0.6875417714468156
Epoch: 6 | Iteration number: [1990/4518] 44% | Training loss: 0.6875438171714994
Epoch: 6 | Iteration number: [2000/4518] 44% | Training loss: 0.6875455372333527
Epoch: 6 | Iteration number: [2010/4518] 44% | Training loss: 0.6875461169439762
Epoch: 6 | Iteration number: [2020/4518] 44% | Training loss: 0.6875473660702752
Epoch: 6 | Iteration number: [2030/4518] 44% | Training loss: 0.6875473168095931
Epoch: 6 | Iteration number: [2040/4518] 45% | Training loss: 0.6875381484627724
Epoch: 6 | Iteration number: [2050/4518] 45% | Training loss: 0.6875335107198576
Epoch: 6 | Iteration number: [2060/4518] 45% | Training loss: 0.6875275133882911
Epoch: 6 | Iteration number: [2070/4518] 45% | Training loss: 0.6875213216756277
Epoch: 6 | Iteration number: [2080/4518] 46% | Training loss: 0.6875123482484083
Epoch: 6 | Iteration number: [2090/4518] 46% | Training loss: 0.6875112328232761
Epoch: 6 | Iteration number: [2100/4518] 46% | Training loss: 0.6875110370772225
Epoch: 6 | Iteration number: [2110/4518] 46% | Training loss: 0.6875048805187098
Epoch: 6 | Iteration number: [2120/4518] 46% | Training loss: 0.687497174627376
Epoch: 6 | Iteration number: [2130/4518] 47% | Training loss: 0.6874945219973443
Epoch: 6 | Iteration number: [2140/4518] 47% | Training loss: 0.6874904399163255
Epoch: 6 | Iteration number: [2150/4518] 47% | Training loss: 0.6874845806110736
Epoch: 6 | Iteration number: [2160/4518] 47% | Training loss: 0.6874798820802459
Epoch: 6 | Iteration number: [2170/4518] 48% | Training loss: 0.6874843701239555
Epoch: 6 | Iteration number: [2180/4518] 48% | Training loss: 0.687482217227647
Epoch: 6 | Iteration number: [2190/4518] 48% | Training loss: 0.6874824689947852
Epoch: 6 | Iteration number: [2200/4518] 48% | Training loss: 0.6874831620400602
Epoch: 6 | Iteration number: [2210/4518] 48% | Training loss: 0.6874858834894534
Epoch: 6 | Iteration number: [2220/4518] 49% | Training loss: 0.6874777029763471
Epoch: 6 | Iteration number: [2230/4518] 49% | Training loss: 0.6874776297887879
Epoch: 6 | Iteration number: [2240/4518] 49% | Training loss: 0.6874748468399048
Epoch: 6 | Iteration number: [2250/4518] 49% | Training loss: 0.6874719178676605
Epoch: 6 | Iteration number: [2260/4518] 50% | Training loss: 0.6874694033270389
Epoch: 6 | Iteration number: [2270/4518] 50% | Training loss: 0.6874702781832691
Epoch: 6 | Iteration number: [2280/4518] 50% | Training loss: 0.6874661463917348
Epoch: 6 | Iteration number: [2290/4518] 50% | Training loss: 0.6874664760572942
Epoch: 6 | Iteration number: [2300/4518] 50% | Training loss: 0.6874577668179637
Epoch: 6 | Iteration number: [2310/4518] 51% | Training loss: 0.6874576561120681
Epoch: 6 | Iteration number: [2320/4518] 51% | Training loss: 0.6874527064890698
Epoch: 6 | Iteration number: [2330/4518] 51% | Training loss: 0.6874540719351543
Epoch: 6 | Iteration number: [2340/4518] 51% | Training loss: 0.6874496867768785
Epoch: 6 | Iteration number: [2350/4518] 52% | Training loss: 0.6874493485815981
Epoch: 6 | Iteration number: [2360/4518] 52% | Training loss: 0.6874462635840399
Epoch: 6 | Iteration number: [2370/4518] 52% | Training loss: 0.6874462031362429
Epoch: 6 | Iteration number: [2380/4518] 52% | Training loss: 0.6874372954879489
Epoch: 6 | Iteration number: [2390/4518] 52% | Training loss: 0.6874327623694512
Epoch: 6 | Iteration number: [2400/4518] 53% | Training loss: 0.6874248214066029
Epoch: 6 | Iteration number: [2410/4518] 53% | Training loss: 0.6874243941297175
Epoch: 6 | Iteration number: [2420/4518] 53% | Training loss: 0.6874264359966783
Epoch: 6 | Iteration number: [2430/4518] 53% | Training loss: 0.6874291241414262
Epoch: 6 | Iteration number: [2440/4518] 54% | Training loss: 0.6874252164217293
Epoch: 6 | Iteration number: [2450/4518] 54% | Training loss: 0.687425399045555
Epoch: 6 | Iteration number: [2460/4518] 54% | Training loss: 0.6874299375264625
Epoch: 6 | Iteration number: [2470/4518] 54% | Training loss: 0.6874312581321006
Epoch: 6 | Iteration number: [2480/4518] 54% | Training loss: 0.6874298849653813
Epoch: 6 | Iteration number: [2490/4518] 55% | Training loss: 0.6874258315228076
Epoch: 6 | Iteration number: [2500/4518] 55% | Training loss: 0.6874275472164154
Epoch: 6 | Iteration number: [2510/4518] 55% | Training loss: 0.6874264701191648
Epoch: 6 | Iteration number: [2520/4518] 55% | Training loss: 0.6874294931926425
Epoch: 6 | Iteration number: [2530/4518] 55% | Training loss: 0.6874319564683635
Epoch: 6 | Iteration number: [2540/4518] 56% | Training loss: 0.687432310829951
Epoch: 6 | Iteration number: [2550/4518] 56% | Training loss: 0.6874305901106667
Epoch: 6 | Iteration number: [2560/4518] 56% | Training loss: 0.6874269035179168
Epoch: 6 | Iteration number: [2570/4518] 56% | Training loss: 0.6874258302760959
Epoch: 6 | Iteration number: [2580/4518] 57% | Training loss: 0.6874269255834032
Epoch: 6 | Iteration number: [2590/4518] 57% | Training loss: 0.6874255453757798
Epoch: 6 | Iteration number: [2600/4518] 57% | Training loss: 0.6874297266281568
Epoch: 6 | Iteration number: [2610/4518] 57% | Training loss: 0.6874282568578975
Epoch: 6 | Iteration number: [2620/4518] 57% | Training loss: 0.6874258702720395
Epoch: 6 | Iteration number: [2630/4518] 58% | Training loss: 0.6874250361221371
Epoch: 6 | Iteration number: [2640/4518] 58% | Training loss: 0.6874267208079498
Epoch: 6 | Iteration number: [2650/4518] 58% | Training loss: 0.6874224652209372
Epoch: 6 | Iteration number: [2660/4518] 58% | Training loss: 0.6874234250165466
Epoch: 6 | Iteration number: [2670/4518] 59% | Training loss: 0.6874216841624471
Epoch: 6 | Iteration number: [2680/4518] 59% | Training loss: 0.6874212840377395
Epoch: 6 | Iteration number: [2690/4518] 59% | Training loss: 0.6874187108752453
Epoch: 6 | Iteration number: [2700/4518] 59% | Training loss: 0.6874129319411737
Epoch: 6 | Iteration number: [2710/4518] 59% | Training loss: 0.6874045683009158
Epoch: 6 | Iteration number: [2720/4518] 60% | Training loss: 0.6874020451570259
Epoch: 6 | Iteration number: [2730/4518] 60% | Training loss: 0.6874057638557839
Epoch: 6 | Iteration number: [2740/4518] 60% | Training loss: 0.6874005383166083
Epoch: 6 | Iteration number: [2750/4518] 60% | Training loss: 0.687397299268029
Epoch: 6 | Iteration number: [2760/4518] 61% | Training loss: 0.6873953066874241
Epoch: 6 | Iteration number: [2770/4518] 61% | Training loss: 0.6873919272465826
Epoch: 6 | Iteration number: [2780/4518] 61% | Training loss: 0.6873860671365861
Epoch: 6 | Iteration number: [2790/4518] 61% | Training loss: 0.6873816947569557
Epoch: 6 | Iteration number: [2800/4518] 61% | Training loss: 0.6873794973322324
Epoch: 6 | Iteration number: [2810/4518] 62% | Training loss: 0.6873720984229837
Epoch: 6 | Iteration number: [2820/4518] 62% | Training loss: 0.6873692813917255
Epoch: 6 | Iteration number: [2830/4518] 62% | Training loss: 0.687373241076621
Epoch: 6 | Iteration number: [2840/4518] 62% | Training loss: 0.6873736174593509
Epoch: 6 | Iteration number: [2850/4518] 63% | Training loss: 0.6873732462891361
Epoch: 6 | Iteration number: [2860/4518] 63% | Training loss: 0.6873711220867984
Epoch: 6 | Iteration number: [2870/4518] 63% | Training loss: 0.6873715644514103
Epoch: 6 | Iteration number: [2880/4518] 63% | Training loss: 0.6873698500502441
Epoch: 6 | Iteration number: [2890/4518] 63% | Training loss: 0.6873688176841471
Epoch: 6 | Iteration number: [2900/4518] 64% | Training loss: 0.687366373477311
Epoch: 6 | Iteration number: [2910/4518] 64% | Training loss: 0.6873669019679434
Epoch: 6 | Iteration number: [2920/4518] 64% | Training loss: 0.6873615138538897
Epoch: 6 | Iteration number: [2930/4518] 64% | Training loss: 0.6873634782260596
Epoch: 6 | Iteration number: [2940/4518] 65% | Training loss: 0.6873651190274427
Epoch: 6 | Iteration number: [2950/4518] 65% | Training loss: 0.6873650817749863
Epoch: 6 | Iteration number: [2960/4518] 65% | Training loss: 0.6873661455069039
Epoch: 6 | Iteration number: [2970/4518] 65% | Training loss: 0.687360463820724
Epoch: 6 | Iteration number: [2980/4518] 65% | Training loss: 0.6873617263248303
Epoch: 6 | Iteration number: [2990/4518] 66% | Training loss: 0.6873606851069026
Epoch: 6 | Iteration number: [3000/4518] 66% | Training loss: 0.6873571404616038
Epoch: 6 | Iteration number: [3010/4518] 66% | Training loss: 0.6873545773599631
Epoch: 6 | Iteration number: [3020/4518] 66% | Training loss: 0.6873552582911309
Epoch: 6 | Iteration number: [3030/4518] 67% | Training loss: 0.6873542445327583
Epoch: 6 | Iteration number: [3040/4518] 67% | Training loss: 0.6873517460925015
Epoch: 6 | Iteration number: [3050/4518] 67% | Training loss: 0.6873538748944392
Epoch: 6 | Iteration number: [3060/4518] 67% | Training loss: 0.6873562271883286
Epoch: 6 | Iteration number: [3070/4518] 67% | Training loss: 0.6873526292437451
Epoch: 6 | Iteration number: [3080/4518] 68% | Training loss: 0.6873580754383818
Epoch: 6 | Iteration number: [3090/4518] 68% | Training loss: 0.6873584389493689
Epoch: 6 | Iteration number: [3100/4518] 68% | Training loss: 0.687356485339903
Epoch: 6 | Iteration number: [3110/4518] 68% | Training loss: 0.6873533059929728
Epoch: 6 | Iteration number: [3120/4518] 69% | Training loss: 0.687351509833183
Epoch: 6 | Iteration number: [3130/4518] 69% | Training loss: 0.6873449785831256
Epoch: 6 | Iteration number: [3140/4518] 69% | Training loss: 0.6873424703907814
Epoch: 6 | Iteration number: [3150/4518] 69% | Training loss: 0.687339757340295
Epoch: 6 | Iteration number: [3160/4518] 69% | Training loss: 0.6873403972085518
Epoch: 6 | Iteration number: [3170/4518] 70% | Training loss: 0.6873375921031278
Epoch: 6 | Iteration number: [3180/4518] 70% | Training loss: 0.6873354937857802
Epoch: 6 | Iteration number: [3190/4518] 70% | Training loss: 0.6873346577243745
Epoch: 6 | Iteration number: [3200/4518] 70% | Training loss: 0.6873338440991938
Epoch: 6 | Iteration number: [3210/4518] 71% | Training loss: 0.6873364794105755
Epoch: 6 | Iteration number: [3220/4518] 71% | Training loss: 0.6873340383819911
Epoch: 6 | Iteration number: [3230/4518] 71% | Training loss: 0.6873342532860606
Epoch: 6 | Iteration number: [3240/4518] 71% | Training loss: 0.6873314775250576
Epoch: 6 | Iteration number: [3250/4518] 71% | Training loss: 0.6873329844291394
Epoch: 6 | Iteration number: [3260/4518] 72% | Training loss: 0.6873354427105078
Epoch: 6 | Iteration number: [3270/4518] 72% | Training loss: 0.6873372839313764
Epoch: 6 | Iteration number: [3280/4518] 72% | Training loss: 0.6873360139022513
Epoch: 6 | Iteration number: [3290/4518] 72% | Training loss: 0.6873349637427228
Epoch: 6 | Iteration number: [3300/4518] 73% | Training loss: 0.68733672134804
Epoch: 6 | Iteration number: [3310/4518] 73% | Training loss: 0.687339586181583
Epoch: 6 | Iteration number: [3320/4518] 73% | Training loss: 0.6873368920870574
Epoch: 6 | Iteration number: [3330/4518] 73% | Training loss: 0.6873355563875433
Epoch: 6 | Iteration number: [3340/4518] 73% | Training loss: 0.6873368505053892
Epoch: 6 | Iteration number: [3350/4518] 74% | Training loss: 0.6873341138683148
Epoch: 6 | Iteration number: [3360/4518] 74% | Training loss: 0.6873346144776968
Epoch: 6 | Iteration number: [3370/4518] 74% | Training loss: 0.6873353422572421
Epoch: 6 | Iteration number: [3380/4518] 74% | Training loss: 0.6873401519814892
Epoch: 6 | Iteration number: [3390/4518] 75% | Training loss: 0.6873400279378469
Epoch: 6 | Iteration number: [3400/4518] 75% | Training loss: 0.6873395420873867
Epoch: 6 | Iteration number: [3410/4518] 75% | Training loss: 0.6873394795876444
Epoch: 6 | Iteration number: [3420/4518] 75% | Training loss: 0.6873366207058667
Epoch: 6 | Iteration number: [3430/4518] 75% | Training loss: 0.6873370328901808
Epoch: 6 | Iteration number: [3440/4518] 76% | Training loss: 0.6873333117816337
Epoch: 6 | Iteration number: [3450/4518] 76% | Training loss: 0.6873353291767231
Epoch: 6 | Iteration number: [3460/4518] 76% | Training loss: 0.6873350332065814
Epoch: 6 | Iteration number: [3470/4518] 76% | Training loss: 0.6873308280359428
Epoch: 6 | Iteration number: [3480/4518] 77% | Training loss: 0.6873269054053843
Epoch: 6 | Iteration number: [3490/4518] 77% | Training loss: 0.6873264730830588
Epoch: 6 | Iteration number: [3500/4518] 77% | Training loss: 0.6873243489435741
Epoch: 6 | Iteration number: [3510/4518] 77% | Training loss: 0.687325279478334
Epoch: 6 | Iteration number: [3520/4518] 77% | Training loss: 0.6873268270357089
Epoch: 6 | Iteration number: [3530/4518] 78% | Training loss: 0.687328505701789
Epoch: 6 | Iteration number: [3540/4518] 78% | Training loss: 0.687327473328612
Epoch: 6 | Iteration number: [3550/4518] 78% | Training loss: 0.6873275270092655
Epoch: 6 | Iteration number: [3560/4518] 78% | Training loss: 0.6873265844215168
Epoch: 6 | Iteration number: [3570/4518] 79% | Training loss: 0.6873273496033431
Epoch: 6 | Iteration number: [3580/4518] 79% | Training loss: 0.6873252487215916
Epoch: 6 | Iteration number: [3590/4518] 79% | Training loss: 0.6873247715091971
Epoch: 6 | Iteration number: [3600/4518] 79% | Training loss: 0.6873266182012028
Epoch: 6 | Iteration number: [3610/4518] 79% | Training loss: 0.6873282367667993
Epoch: 6 | Iteration number: [3620/4518] 80% | Training loss: 0.6873258545583124
Epoch: 6 | Iteration number: [3630/4518] 80% | Training loss: 0.687323089966104
Epoch: 6 | Iteration number: [3640/4518] 80% | Training loss: 0.6873235153300422
Epoch: 6 | Iteration number: [3650/4518] 80% | Training loss: 0.687317895807632
Epoch: 6 | Iteration number: [3660/4518] 81% | Training loss: 0.6873175868082567
Epoch: 6 | Iteration number: [3670/4518] 81% | Training loss: 0.6873160253591044
Epoch: 6 | Iteration number: [3680/4518] 81% | Training loss: 0.6873164638391007
Epoch: 6 | Iteration number: [3690/4518] 81% | Training loss: 0.6873180631376541
Epoch: 6 | Iteration number: [3700/4518] 81% | Training loss: 0.6873184198141098
Epoch: 6 | Iteration number: [3710/4518] 82% | Training loss: 0.687318162391128
Epoch: 6 | Iteration number: [3720/4518] 82% | Training loss: 0.6873166149021477
Epoch: 6 | Iteration number: [3730/4518] 82% | Training loss: 0.6873158188831391
Epoch: 6 | Iteration number: [3740/4518] 82% | Training loss: 0.6873152622883333
Epoch: 6 | Iteration number: [3750/4518] 83% | Training loss: 0.687315094947815
Epoch: 6 | Iteration number: [3760/4518] 83% | Training loss: 0.6873133604989407
Epoch: 6 | Iteration number: [3770/4518] 83% | Training loss: 0.6873154309605414
Epoch: 6 | Iteration number: [3780/4518] 83% | Training loss: 0.6873140255452463
Epoch: 6 | Iteration number: [3790/4518] 83% | Training loss: 0.6873131504474026
Epoch: 6 | Iteration number: [3800/4518] 84% | Training loss: 0.6873114059943902
Epoch: 6 | Iteration number: [3810/4518] 84% | Training loss: 0.6873111147580184
Epoch: 6 | Iteration number: [3820/4518] 84% | Training loss: 0.6873133356502543
Epoch: 6 | Iteration number: [3830/4518] 84% | Training loss: 0.6873146351728364
Epoch: 6 | Iteration number: [3840/4518] 84% | Training loss: 0.6873142686982949
Epoch: 6 | Iteration number: [3850/4518] 85% | Training loss: 0.6873170625544214
Epoch: 6 | Iteration number: [3860/4518] 85% | Training loss: 0.6873156903012428
Epoch: 6 | Iteration number: [3870/4518] 85% | Training loss: 0.6873154185385051
Epoch: 6 | Iteration number: [3880/4518] 85% | Training loss: 0.6873171268664684
Epoch: 6 | Iteration number: [3890/4518] 86% | Training loss: 0.6873165746734198
Epoch: 6 | Iteration number: [3900/4518] 86% | Training loss: 0.6873111001039163
Epoch: 6 | Iteration number: [3910/4518] 86% | Training loss: 0.6873113846687404
Epoch: 6 | Iteration number: [3920/4518] 86% | Training loss: 0.6873086840826638
Epoch: 6 | Iteration number: [3930/4518] 86% | Training loss: 0.6873091512205644
Epoch: 6 | Iteration number: [3940/4518] 87% | Training loss: 0.6873052664819708
Epoch: 6 | Iteration number: [3950/4518] 87% | Training loss: 0.6873008922232857
Epoch: 6 | Iteration number: [3960/4518] 87% | Training loss: 0.6873029969707884
Epoch: 6 | Iteration number: [3970/4518] 87% | Training loss: 0.6872999498015387
Epoch: 6 | Iteration number: [3980/4518] 88% | Training loss: 0.687300946125433
Epoch: 6 | Iteration number: [3990/4518] 88% | Training loss: 0.6873010962081135
Epoch: 6 | Iteration number: [4000/4518] 88% | Training loss: 0.6872978259176016
Epoch: 6 | Iteration number: [4010/4518] 88% | Training loss: 0.6872997088771211
Epoch: 6 | Iteration number: [4020/4518] 88% | Training loss: 0.6872968155649763
Epoch: 6 | Iteration number: [4030/4518] 89% | Training loss: 0.6872966281385635
Epoch: 6 | Iteration number: [4040/4518] 89% | Training loss: 0.6872973226969785
Epoch: 6 | Iteration number: [4050/4518] 89% | Training loss: 0.6872955088409377
Epoch: 6 | Iteration number: [4060/4518] 89% | Training loss: 0.6872979479029848
Epoch: 6 | Iteration number: [4070/4518] 90% | Training loss: 0.6872950572346587
Epoch: 6 | Iteration number: [4080/4518] 90% | Training loss: 0.6872942131085723
Epoch: 6 | Iteration number: [4090/4518] 90% | Training loss: 0.6872923138234901
Epoch: 6 | Iteration number: [4100/4518] 90% | Training loss: 0.6872931543210657
Epoch: 6 | Iteration number: [4110/4518] 90% | Training loss: 0.6872923347781754
Epoch: 6 | Iteration number: [4120/4518] 91% | Training loss: 0.6872905367207759
Epoch: 6 | Iteration number: [4130/4518] 91% | Training loss: 0.6872916661365269
Epoch: 6 | Iteration number: [4140/4518] 91% | Training loss: 0.6872884474226818
Epoch: 6 | Iteration number: [4150/4518] 91% | Training loss: 0.6872899911346205
Epoch: 6 | Iteration number: [4160/4518] 92% | Training loss: 0.6872928297576996
Epoch: 6 | Iteration number: [4170/4518] 92% | Training loss: 0.6872921962389271
Epoch: 6 | Iteration number: [4180/4518] 92% | Training loss: 0.6872928230243437
Epoch: 6 | Iteration number: [4190/4518] 92% | Training loss: 0.6872931017226991
Epoch: 6 | Iteration number: [4200/4518] 92% | Training loss: 0.6872923631327493
Epoch: 6 | Iteration number: [4210/4518] 93% | Training loss: 0.6872901432870969
Epoch: 6 | Iteration number: [4220/4518] 93% | Training loss: 0.6872899748561506
Epoch: 6 | Iteration number: [4230/4518] 93% | Training loss: 0.6872894295845753
Epoch: 6 | Iteration number: [4240/4518] 93% | Training loss: 0.6872899479180012
Epoch: 6 | Iteration number: [4250/4518] 94% | Training loss: 0.6872899084652171
Epoch: 6 | Iteration number: [4260/4518] 94% | Training loss: 0.6872882307555194
Epoch: 6 | Iteration number: [4270/4518] 94% | Training loss: 0.6872884395530129
Epoch: 6 | Iteration number: [4280/4518] 94% | Training loss: 0.6872863684859232
Epoch: 6 | Iteration number: [4290/4518] 94% | Training loss: 0.6872847033825232
Epoch: 6 | Iteration number: [4300/4518] 95% | Training loss: 0.6872855491277784
Epoch: 6 | Iteration number: [4310/4518] 95% | Training loss: 0.687285125518343
Epoch: 6 | Iteration number: [4320/4518] 95% | Training loss: 0.6872844851403325
Epoch: 6 | Iteration number: [4330/4518] 95% | Training loss: 0.6872845681930524
Epoch: 6 | Iteration number: [4340/4518] 96% | Training loss: 0.6872856845778804
Epoch: 6 | Iteration number: [4350/4518] 96% | Training loss: 0.6872849185987451
Epoch: 6 | Iteration number: [4360/4518] 96% | Training loss: 0.6872861239068006
Epoch: 6 | Iteration number: [4370/4518] 96% | Training loss: 0.6872869836520276
Epoch: 6 | Iteration number: [4380/4518] 96% | Training loss: 0.6872861209389282
Epoch: 6 | Iteration number: [4390/4518] 97% | Training loss: 0.687285146123999
Epoch: 6 | Iteration number: [4400/4518] 97% | Training loss: 0.6872865724157203
Epoch: 6 | Iteration number: [4410/4518] 97% | Training loss: 0.687287042673483
Epoch: 6 | Iteration number: [4420/4518] 97% | Training loss: 0.687285020421533
Epoch: 6 | Iteration number: [4430/4518] 98% | Training loss: 0.6872824214247495
Epoch: 6 | Iteration number: [4440/4518] 98% | Training loss: 0.6872821799940891
Epoch: 6 | Iteration number: [4450/4518] 98% | Training loss: 0.6872817113292351
Epoch: 6 | Iteration number: [4460/4518] 98% | Training loss: 0.6872808422876581
Epoch: 6 | Iteration number: [4470/4518] 98% | Training loss: 0.6872797648912041
Epoch: 6 | Iteration number: [4480/4518] 99% | Training loss: 0.687272655445018
Epoch: 6 | Iteration number: [4490/4518] 99% | Training loss: 0.6872705280117043
Epoch: 6 | Iteration number: [4500/4518] 99% | Training loss: 0.6872708152665032
Epoch: 6 | Iteration number: [4510/4518] 99% | Training loss: 0.6872714598004411

 End of epoch: 6 | Train Loss: 0.6871185190992157 | Training Time: 642 

 End of epoch: 6 | Eval Loss: 0.6904350725971923 | Evaluating Time: 17 
Epoch: 7 | Iteration number: [10/4518] 0% | Training loss: 0.7546304643154145
Epoch: 7 | Iteration number: [20/4518] 0% | Training loss: 0.7207169860601426
Epoch: 7 | Iteration number: [30/4518] 0% | Training loss: 0.7097994486490885
Epoch: 7 | Iteration number: [40/4518] 0% | Training loss: 0.7037439703941345
Epoch: 7 | Iteration number: [50/4518] 1% | Training loss: 0.7005757522583008
Epoch: 7 | Iteration number: [60/4518] 1% | Training loss: 0.6981502244869868
Epoch: 7 | Iteration number: [70/4518] 1% | Training loss: 0.6964916229248047
Epoch: 7 | Iteration number: [80/4518] 1% | Training loss: 0.6954787917435169
Epoch: 7 | Iteration number: [90/4518] 1% | Training loss: 0.6946391959985098
Epoch: 7 | Iteration number: [100/4518] 2% | Training loss: 0.6938312321901321
Epoch: 7 | Iteration number: [110/4518] 2% | Training loss: 0.6932964265346527
Epoch: 7 | Iteration number: [120/4518] 2% | Training loss: 0.6927580391367276
Epoch: 7 | Iteration number: [130/4518] 2% | Training loss: 0.6922167402047378
Epoch: 7 | Iteration number: [140/4518] 3% | Training loss: 0.6918575929743903
Epoch: 7 | Iteration number: [150/4518] 3% | Training loss: 0.6915004662672679
Epoch: 7 | Iteration number: [160/4518] 3% | Training loss: 0.6912685934454202
Epoch: 7 | Iteration number: [170/4518] 3% | Training loss: 0.6908875349689932
Epoch: 7 | Iteration number: [180/4518] 3% | Training loss: 0.6906679600477219
Epoch: 7 | Iteration number: [190/4518] 4% | Training loss: 0.6904579937458039
Epoch: 7 | Iteration number: [200/4518] 4% | Training loss: 0.6903015014529228
Epoch: 7 | Iteration number: [210/4518] 4% | Training loss: 0.6901835560798645
Epoch: 7 | Iteration number: [220/4518] 4% | Training loss: 0.6900915110653097
Epoch: 7 | Iteration number: [230/4518] 5% | Training loss: 0.689947904192883
Epoch: 7 | Iteration number: [240/4518] 5% | Training loss: 0.6898682653903961
Epoch: 7 | Iteration number: [250/4518] 5% | Training loss: 0.6897504892349243
Epoch: 7 | Iteration number: [260/4518] 5% | Training loss: 0.6896346335227673
Epoch: 7 | Iteration number: [270/4518] 5% | Training loss: 0.689591180395197
Epoch: 7 | Iteration number: [280/4518] 6% | Training loss: 0.6895289131573268
Epoch: 7 | Iteration number: [290/4518] 6% | Training loss: 0.6893611757919706
Epoch: 7 | Iteration number: [300/4518] 6% | Training loss: 0.689243592818578
Epoch: 7 | Iteration number: [310/4518] 6% | Training loss: 0.6891494585621741
Epoch: 7 | Iteration number: [320/4518] 7% | Training loss: 0.68909463416785
Epoch: 7 | Iteration number: [330/4518] 7% | Training loss: 0.6890172797622103
Epoch: 7 | Iteration number: [340/4518] 7% | Training loss: 0.6889396805973614
Epoch: 7 | Iteration number: [350/4518] 7% | Training loss: 0.6888784340449742
Epoch: 7 | Iteration number: [360/4518] 7% | Training loss: 0.6888239448269208
Epoch: 7 | Iteration number: [370/4518] 8% | Training loss: 0.6887971468873926
Epoch: 7 | Iteration number: [380/4518] 8% | Training loss: 0.6887433218328576
Epoch: 7 | Iteration number: [390/4518] 8% | Training loss: 0.6887186088623145
Epoch: 7 | Iteration number: [400/4518] 8% | Training loss: 0.688679367005825
Epoch: 7 | Iteration number: [410/4518] 9% | Training loss: 0.688654619019206
Epoch: 7 | Iteration number: [420/4518] 9% | Training loss: 0.6886234263579051
Epoch: 7 | Iteration number: [430/4518] 9% | Training loss: 0.688597811793172
Epoch: 7 | Iteration number: [440/4518] 9% | Training loss: 0.6885632621971044
Epoch: 7 | Iteration number: [450/4518] 9% | Training loss: 0.6885278287198808
Epoch: 7 | Iteration number: [460/4518] 10% | Training loss: 0.6885016401176868
Epoch: 7 | Iteration number: [470/4518] 10% | Training loss: 0.6884707195961729
Epoch: 7 | Iteration number: [480/4518] 10% | Training loss: 0.6884572230279445
Epoch: 7 | Iteration number: [490/4518] 10% | Training loss: 0.6884091761647438
Epoch: 7 | Iteration number: [500/4518] 11% | Training loss: 0.6883738514184952
Epoch: 7 | Iteration number: [510/4518] 11% | Training loss: 0.6883464543258443
Epoch: 7 | Iteration number: [520/4518] 11% | Training loss: 0.688335489653624
Epoch: 7 | Iteration number: [530/4518] 11% | Training loss: 0.6883389977913983
Epoch: 7 | Iteration number: [540/4518] 11% | Training loss: 0.6882840510871675
Epoch: 7 | Iteration number: [550/4518] 12% | Training loss: 0.6882632998986677
Epoch: 7 | Iteration number: [560/4518] 12% | Training loss: 0.688235005736351
Epoch: 7 | Iteration number: [570/4518] 12% | Training loss: 0.6881933693300214
Epoch: 7 | Iteration number: [580/4518] 12% | Training loss: 0.6881658002220351
Epoch: 7 | Iteration number: [590/4518] 13% | Training loss: 0.6881445412918673
Epoch: 7 | Iteration number: [600/4518] 13% | Training loss: 0.6881419907013575
Epoch: 7 | Iteration number: [610/4518] 13% | Training loss: 0.6881296820327883
Epoch: 7 | Iteration number: [620/4518] 13% | Training loss: 0.6880889797402966
Epoch: 7 | Iteration number: [630/4518] 13% | Training loss: 0.6880693485812536
Epoch: 7 | Iteration number: [640/4518] 14% | Training loss: 0.6880518101155758
Epoch: 7 | Iteration number: [650/4518] 14% | Training loss: 0.6880493098038893
Epoch: 7 | Iteration number: [660/4518] 14% | Training loss: 0.6880161922086369
Epoch: 7 | Iteration number: [670/4518] 14% | Training loss: 0.6880041827906423
Epoch: 7 | Iteration number: [680/4518] 15% | Training loss: 0.6879975829930867
Epoch: 7 | Iteration number: [690/4518] 15% | Training loss: 0.6879742553268654
Epoch: 7 | Iteration number: [700/4518] 15% | Training loss: 0.6879601266554424
Epoch: 7 | Iteration number: [710/4518] 15% | Training loss: 0.6879428209553302
Epoch: 7 | Iteration number: [720/4518] 15% | Training loss: 0.6879235971305105
Epoch: 7 | Iteration number: [730/4518] 16% | Training loss: 0.6879201155819304
Epoch: 7 | Iteration number: [740/4518] 16% | Training loss: 0.6879009817097638
Epoch: 7 | Iteration number: [750/4518] 16% | Training loss: 0.6879005857308705
Epoch: 7 | Iteration number: [760/4518] 16% | Training loss: 0.6878838700683494
Epoch: 7 | Iteration number: [770/4518] 17% | Training loss: 0.687874284038296
Epoch: 7 | Iteration number: [780/4518] 17% | Training loss: 0.6878695160150528
Epoch: 7 | Iteration number: [790/4518] 17% | Training loss: 0.6878458644770369
Epoch: 7 | Iteration number: [800/4518] 17% | Training loss: 0.6878413043171168
Epoch: 7 | Iteration number: [810/4518] 17% | Training loss: 0.687822871664424
Epoch: 7 | Iteration number: [820/4518] 18% | Training loss: 0.6878122733133595
Epoch: 7 | Iteration number: [830/4518] 18% | Training loss: 0.6878044954265456
Epoch: 7 | Iteration number: [840/4518] 18% | Training loss: 0.687789907909575
Epoch: 7 | Iteration number: [850/4518] 18% | Training loss: 0.6877788929378286
Epoch: 7 | Iteration number: [860/4518] 19% | Training loss: 0.6877731540175371
Epoch: 7 | Iteration number: [870/4518] 19% | Training loss: 0.6877630352973938
Epoch: 7 | Iteration number: [880/4518] 19% | Training loss: 0.6877585163170641
Epoch: 7 | Iteration number: [890/4518] 19% | Training loss: 0.6877419033077325
Epoch: 7 | Iteration number: [900/4518] 19% | Training loss: 0.687725710802608
Epoch: 7 | Iteration number: [910/4518] 20% | Training loss: 0.6877238243490785
Epoch: 7 | Iteration number: [920/4518] 20% | Training loss: 0.687712764416052
Epoch: 7 | Iteration number: [930/4518] 20% | Training loss: 0.6877047502225445
Epoch: 7 | Iteration number: [940/4518] 20% | Training loss: 0.6876856235747641
Epoch: 7 | Iteration number: [950/4518] 21% | Training loss: 0.6876912906295375
Epoch: 7 | Iteration number: [960/4518] 21% | Training loss: 0.6876844808459281
Epoch: 7 | Iteration number: [970/4518] 21% | Training loss: 0.6876906612484726
Epoch: 7 | Iteration number: [980/4518] 21% | Training loss: 0.687682984921397
Epoch: 7 | Iteration number: [990/4518] 21% | Training loss: 0.6876789200185526
Epoch: 7 | Iteration number: [1000/4518] 22% | Training loss: 0.687662584900856
Epoch: 7 | Iteration number: [1010/4518] 22% | Training loss: 0.6876640492146558
Epoch: 7 | Iteration number: [1020/4518] 22% | Training loss: 0.6876484575224858
Epoch: 7 | Iteration number: [1030/4518] 22% | Training loss: 0.6876371709467138
Epoch: 7 | Iteration number: [1040/4518] 23% | Training loss: 0.6876441967028838
Epoch: 7 | Iteration number: [1050/4518] 23% | Training loss: 0.6876442376772562
Epoch: 7 | Iteration number: [1060/4518] 23% | Training loss: 0.687645449447182
Epoch: 7 | Iteration number: [1070/4518] 23% | Training loss: 0.6876371419318369
Epoch: 7 | Iteration number: [1080/4518] 23% | Training loss: 0.6876308041590231
Epoch: 7 | Iteration number: [1090/4518] 24% | Training loss: 0.6876200171238785
Epoch: 7 | Iteration number: [1100/4518] 24% | Training loss: 0.6876157783378254
Epoch: 7 | Iteration number: [1110/4518] 24% | Training loss: 0.6876034509491276
Epoch: 7 | Iteration number: [1120/4518] 24% | Training loss: 0.687600021011063
Epoch: 7 | Iteration number: [1130/4518] 25% | Training loss: 0.6875870644518759
Epoch: 7 | Iteration number: [1140/4518] 25% | Training loss: 0.6875867193205315
Epoch: 7 | Iteration number: [1150/4518] 25% | Training loss: 0.6875840452442998
Epoch: 7 | Iteration number: [1160/4518] 25% | Training loss: 0.6875668280597391
Epoch: 7 | Iteration number: [1170/4518] 25% | Training loss: 0.6875701050982516
Epoch: 7 | Iteration number: [1180/4518] 26% | Training loss: 0.6875724365650597
Epoch: 7 | Iteration number: [1190/4518] 26% | Training loss: 0.687568831944666
Epoch: 7 | Iteration number: [1200/4518] 26% | Training loss: 0.6875673001011212
Epoch: 7 | Iteration number: [1210/4518] 26% | Training loss: 0.6875547863727759
Epoch: 7 | Iteration number: [1220/4518] 27% | Training loss: 0.6875464900595243
Epoch: 7 | Iteration number: [1230/4518] 27% | Training loss: 0.6875507233588676
Epoch: 7 | Iteration number: [1240/4518] 27% | Training loss: 0.6875360142319433
Epoch: 7 | Iteration number: [1250/4518] 27% | Training loss: 0.6875235476016999
Epoch: 7 | Iteration number: [1260/4518] 27% | Training loss: 0.6875203220617203
Epoch: 7 | Iteration number: [1270/4518] 28% | Training loss: 0.6875152885444521
Epoch: 7 | Iteration number: [1280/4518] 28% | Training loss: 0.6875103301834316
Epoch: 7 | Iteration number: [1290/4518] 28% | Training loss: 0.6875126693137856
Epoch: 7 | Iteration number: [1300/4518] 28% | Training loss: 0.6875121491230451
Epoch: 7 | Iteration number: [1310/4518] 28% | Training loss: 0.6875054320761266
Epoch: 7 | Iteration number: [1320/4518] 29% | Training loss: 0.6874978338678678
Epoch: 7 | Iteration number: [1330/4518] 29% | Training loss: 0.6874921904022532
Epoch: 7 | Iteration number: [1340/4518] 29% | Training loss: 0.687488904017121
Epoch: 7 | Iteration number: [1350/4518] 29% | Training loss: 0.6874715375017236
Epoch: 7 | Iteration number: [1360/4518] 30% | Training loss: 0.6874605252462275
Epoch: 7 | Iteration number: [1370/4518] 30% | Training loss: 0.6874613828902697
Epoch: 7 | Iteration number: [1380/4518] 30% | Training loss: 0.6874659909718278
Epoch: 7 | Iteration number: [1390/4518] 30% | Training loss: 0.6874585252013995
Epoch: 7 | Iteration number: [1400/4518] 30% | Training loss: 0.6874519378372601
Epoch: 7 | Iteration number: [1410/4518] 31% | Training loss: 0.6874496053296624
Epoch: 7 | Iteration number: [1420/4518] 31% | Training loss: 0.687452975167355
Epoch: 7 | Iteration number: [1430/4518] 31% | Training loss: 0.6874404474571868
Epoch: 7 | Iteration number: [1440/4518] 31% | Training loss: 0.6874334848175446
Epoch: 7 | Iteration number: [1450/4518] 32% | Training loss: 0.6874279889978212
Epoch: 7 | Iteration number: [1460/4518] 32% | Training loss: 0.6874315299808162
Epoch: 7 | Iteration number: [1470/4518] 32% | Training loss: 0.687423550758232
Epoch: 7 | Iteration number: [1480/4518] 32% | Training loss: 0.6874287035014178
Epoch: 7 | Iteration number: [1490/4518] 32% | Training loss: 0.6874329560955099
Epoch: 7 | Iteration number: [1500/4518] 33% | Training loss: 0.6874286018610001
Epoch: 7 | Iteration number: [1510/4518] 33% | Training loss: 0.6874230587719292
Epoch: 7 | Iteration number: [1520/4518] 33% | Training loss: 0.6874278199123709
Epoch: 7 | Iteration number: [1530/4518] 33% | Training loss: 0.687424366497526
Epoch: 7 | Iteration number: [1540/4518] 34% | Training loss: 0.6874291222203862
Epoch: 7 | Iteration number: [1550/4518] 34% | Training loss: 0.6874195558409537
Epoch: 7 | Iteration number: [1560/4518] 34% | Training loss: 0.6874193650407668
Epoch: 7 | Iteration number: [1570/4518] 34% | Training loss: 0.6874162003113206
Epoch: 7 | Iteration number: [1580/4518] 34% | Training loss: 0.6874099559044536
Epoch: 7 | Iteration number: [1590/4518] 35% | Training loss: 0.6874050788909384
Epoch: 7 | Iteration number: [1600/4518] 35% | Training loss: 0.6874053648486733
Epoch: 7 | Iteration number: [1610/4518] 35% | Training loss: 0.6874110362544563
Epoch: 7 | Iteration number: [1620/4518] 35% | Training loss: 0.687413169020488
Epoch: 7 | Iteration number: [1630/4518] 36% | Training loss: 0.6874113075206616
Epoch: 7 | Iteration number: [1640/4518] 36% | Training loss: 0.6874167034538781
Epoch: 7 | Iteration number: [1650/4518] 36% | Training loss: 0.6874133848060261
Epoch: 7 | Iteration number: [1660/4518] 36% | Training loss: 0.6874118991644985
Epoch: 7 | Iteration number: [1670/4518] 36% | Training loss: 0.687413193722685
Epoch: 7 | Iteration number: [1680/4518] 37% | Training loss: 0.6874051468712943
Epoch: 7 | Iteration number: [1690/4518] 37% | Training loss: 0.6874052360565704
Epoch: 7 | Iteration number: [1700/4518] 37% | Training loss: 0.6874041376394384
Epoch: 7 | Iteration number: [1710/4518] 37% | Training loss: 0.6873989012506273
Epoch: 7 | Iteration number: [1720/4518] 38% | Training loss: 0.6874020112808361
Epoch: 7 | Iteration number: [1730/4518] 38% | Training loss: 0.6873973793032542
Epoch: 7 | Iteration number: [1740/4518] 38% | Training loss: 0.6873966901124209
Epoch: 7 | Iteration number: [1750/4518] 38% | Training loss: 0.6873949972561427
Epoch: 7 | Iteration number: [1760/4518] 38% | Training loss: 0.6873982780359008
Epoch: 7 | Iteration number: [1770/4518] 39% | Training loss: 0.6873983316502329
Epoch: 7 | Iteration number: [1780/4518] 39% | Training loss: 0.6873895526936885
Epoch: 7 | Iteration number: [1790/4518] 39% | Training loss: 0.6873844394803713
Epoch: 7 | Iteration number: [1800/4518] 39% | Training loss: 0.687384901245435
Epoch: 7 | Iteration number: [1810/4518] 40% | Training loss: 0.6873824651728677
Epoch: 7 | Iteration number: [1820/4518] 40% | Training loss: 0.6873833571161543
Epoch: 7 | Iteration number: [1830/4518] 40% | Training loss: 0.6873890793714367
Epoch: 7 | Iteration number: [1840/4518] 40% | Training loss: 0.6873868153471013
Epoch: 7 | Iteration number: [1850/4518] 40% | Training loss: 0.6873856317674791
Epoch: 7 | Iteration number: [1860/4518] 41% | Training loss: 0.6873844229726381
Epoch: 7 | Iteration number: [1870/4518] 41% | Training loss: 0.6873804952052825
Epoch: 7 | Iteration number: [1880/4518] 41% | Training loss: 0.6873740100163095
Epoch: 7 | Iteration number: [1890/4518] 41% | Training loss: 0.6873723390871885
Epoch: 7 | Iteration number: [1900/4518] 42% | Training loss: 0.6873771516272896
Epoch: 7 | Iteration number: [1910/4518] 42% | Training loss: 0.6873742281766462
Epoch: 7 | Iteration number: [1920/4518] 42% | Training loss: 0.6873721869662404
Epoch: 7 | Iteration number: [1930/4518] 42% | Training loss: 0.6873722532870238
Epoch: 7 | Iteration number: [1940/4518] 42% | Training loss: 0.6873733250750709
Epoch: 7 | Iteration number: [1950/4518] 43% | Training loss: 0.6873669112951327
Epoch: 7 | Iteration number: [1960/4518] 43% | Training loss: 0.6873642941518706
Epoch: 7 | Iteration number: [1970/4518] 43% | Training loss: 0.6873598334450407
Epoch: 7 | Iteration number: [1980/4518] 43% | Training loss: 0.687362161218518
Epoch: 7 | Iteration number: [1990/4518] 44% | Training loss: 0.6873666750426268
Epoch: 7 | Iteration number: [2000/4518] 44% | Training loss: 0.6873668809533119
Epoch: 7 | Iteration number: [2010/4518] 44% | Training loss: 0.6873640009419835
Epoch: 7 | Iteration number: [2020/4518] 44% | Training loss: 0.6873633409785752
Epoch: 7 | Iteration number: [2030/4518] 44% | Training loss: 0.6873614725808205
Epoch: 7 | Iteration number: [2040/4518] 45% | Training loss: 0.6873609333938243
Epoch: 7 | Iteration number: [2050/4518] 45% | Training loss: 0.6873577670934724
Epoch: 7 | Iteration number: [2060/4518] 45% | Training loss: 0.6873600290238279
Epoch: 7 | Iteration number: [2070/4518] 45% | Training loss: 0.6873572013228412
Epoch: 7 | Iteration number: [2080/4518] 46% | Training loss: 0.6873541343384064
Epoch: 7 | Iteration number: [2090/4518] 46% | Training loss: 0.6873541038002123
Epoch: 7 | Iteration number: [2100/4518] 46% | Training loss: 0.6873585412615821
Epoch: 7 | Iteration number: [2110/4518] 46% | Training loss: 0.6873572438814064
Epoch: 7 | Iteration number: [2120/4518] 46% | Training loss: 0.6873595737904873
Epoch: 7 | Iteration number: [2130/4518] 47% | Training loss: 0.6873556118336082
Epoch: 7 | Iteration number: [2140/4518] 47% | Training loss: 0.6873586411231032
Epoch: 7 | Iteration number: [2150/4518] 47% | Training loss: 0.6873571865780409
Epoch: 7 | Iteration number: [2160/4518] 47% | Training loss: 0.6873563415750309
Epoch: 7 | Iteration number: [2170/4518] 48% | Training loss: 0.6873590093603881
Epoch: 7 | Iteration number: [2180/4518] 48% | Training loss: 0.6873633982664948
Epoch: 7 | Iteration number: [2190/4518] 48% | Training loss: 0.6873661555656015
Epoch: 7 | Iteration number: [2200/4518] 48% | Training loss: 0.6873691594058817
Epoch: 7 | Iteration number: [2210/4518] 48% | Training loss: 0.6873713664069974
Epoch: 7 | Iteration number: [2220/4518] 49% | Training loss: 0.6873723557403496
Epoch: 7 | Iteration number: [2230/4518] 49% | Training loss: 0.6873720634945839
Epoch: 7 | Iteration number: [2240/4518] 49% | Training loss: 0.6873750797339848
Epoch: 7 | Iteration number: [2250/4518] 49% | Training loss: 0.6873720606697931
Epoch: 7 | Iteration number: [2260/4518] 50% | Training loss: 0.687368134481717
Epoch: 7 | Iteration number: [2270/4518] 50% | Training loss: 0.6873663290481735
Epoch: 7 | Iteration number: [2280/4518] 50% | Training loss: 0.6873675843341309
Epoch: 7 | Iteration number: [2290/4518] 50% | Training loss: 0.6873637805599313
Epoch: 7 | Iteration number: [2300/4518] 50% | Training loss: 0.6873588654528493
Epoch: 7 | Iteration number: [2310/4518] 51% | Training loss: 0.6873601986732317
Epoch: 7 | Iteration number: [2320/4518] 51% | Training loss: 0.6873591690484819
Epoch: 7 | Iteration number: [2330/4518] 51% | Training loss: 0.6873632520309334
Epoch: 7 | Iteration number: [2340/4518] 51% | Training loss: 0.6873618179661596
Epoch: 7 | Iteration number: [2350/4518] 52% | Training loss: 0.6873639843818989
Epoch: 7 | Iteration number: [2360/4518] 52% | Training loss: 0.6873663704526627
Epoch: 7 | Iteration number: [2370/4518] 52% | Training loss: 0.6873660401452946
Epoch: 7 | Iteration number: [2380/4518] 52% | Training loss: 0.6873669786863968
Epoch: 7 | Iteration number: [2390/4518] 52% | Training loss: 0.6873655962145977
Epoch: 7 | Iteration number: [2400/4518] 53% | Training loss: 0.6873630044609308
Epoch: 7 | Iteration number: [2410/4518] 53% | Training loss: 0.6873612568586199
Epoch: 7 | Iteration number: [2420/4518] 53% | Training loss: 0.6873624967395767
Epoch: 7 | Iteration number: [2430/4518] 53% | Training loss: 0.6873604617736958
Epoch: 7 | Iteration number: [2440/4518] 54% | Training loss: 0.6873526891479727
Epoch: 7 | Iteration number: [2450/4518] 54% | Training loss: 0.687357639439252
Epoch: 7 | Iteration number: [2460/4518] 54% | Training loss: 0.6873599367897685
Epoch: 7 | Iteration number: [2470/4518] 54% | Training loss: 0.6873483012803653
Epoch: 7 | Iteration number: [2480/4518] 54% | Training loss: 0.687350119289852
Epoch: 7 | Iteration number: [2490/4518] 55% | Training loss: 0.6873477432622488
Epoch: 7 | Iteration number: [2500/4518] 55% | Training loss: 0.6873405291557312
Epoch: 7 | Iteration number: [2510/4518] 55% | Training loss: 0.6873364525249754
Epoch: 7 | Iteration number: [2520/4518] 55% | Training loss: 0.6873291220929888
Epoch: 7 | Iteration number: [2530/4518] 55% | Training loss: 0.6873274102512555
Epoch: 7 | Iteration number: [2540/4518] 56% | Training loss: 0.6873286653926053
Epoch: 7 | Iteration number: [2550/4518] 56% | Training loss: 0.6873309023473777
Epoch: 7 | Iteration number: [2560/4518] 56% | Training loss: 0.6873279998078943
Epoch: 7 | Iteration number: [2570/4518] 56% | Training loss: 0.6873275040420577
Epoch: 7 | Iteration number: [2580/4518] 57% | Training loss: 0.6873285522987677
Epoch: 7 | Iteration number: [2590/4518] 57% | Training loss: 0.687326326218351
Epoch: 7 | Iteration number: [2600/4518] 57% | Training loss: 0.6873232086117451
Epoch: 7 | Iteration number: [2610/4518] 57% | Training loss: 0.6873190447516825
Epoch: 7 | Iteration number: [2620/4518] 57% | Training loss: 0.6873206295129907
Epoch: 7 | Iteration number: [2630/4518] 58% | Training loss: 0.6873206216119542
Epoch: 7 | Iteration number: [2640/4518] 58% | Training loss: 0.6873209029436111
Epoch: 7 | Iteration number: [2650/4518] 58% | Training loss: 0.6873228041405948
Epoch: 7 | Iteration number: [2660/4518] 58% | Training loss: 0.6873183793143223
Epoch: 7 | Iteration number: [2670/4518] 59% | Training loss: 0.687315049108941
Epoch: 7 | Iteration number: [2680/4518] 59% | Training loss: 0.6873119815961638
Epoch: 7 | Iteration number: [2690/4518] 59% | Training loss: 0.6873166796000031
Epoch: 7 | Iteration number: [2700/4518] 59% | Training loss: 0.6873126775026321
Epoch: 7 | Iteration number: [2710/4518] 59% | Training loss: 0.6873122319304196
Epoch: 7 | Iteration number: [2720/4518] 60% | Training loss: 0.6873100095373743
Epoch: 7 | Iteration number: [2730/4518] 60% | Training loss: 0.6873059503324739
Epoch: 7 | Iteration number: [2740/4518] 60% | Training loss: 0.6873014804003013
Epoch: 7 | Iteration number: [2750/4518] 60% | Training loss: 0.6873005494421178
Epoch: 7 | Iteration number: [2760/4518] 61% | Training loss: 0.6872997202519058
Epoch: 7 | Iteration number: [2770/4518] 61% | Training loss: 0.6872954009887544
Epoch: 7 | Iteration number: [2780/4518] 61% | Training loss: 0.6872947098539888
Epoch: 7 | Iteration number: [2790/4518] 61% | Training loss: 0.6872936146874582
Epoch: 7 | Iteration number: [2800/4518] 61% | Training loss: 0.6872937683548246
Epoch: 7 | Iteration number: [2810/4518] 62% | Training loss: 0.6872931511588792
Epoch: 7 | Iteration number: [2820/4518] 62% | Training loss: 0.6872918697959143
Epoch: 7 | Iteration number: [2830/4518] 62% | Training loss: 0.6872894483193913
Epoch: 7 | Iteration number: [2840/4518] 62% | Training loss: 0.6872919684144813
Epoch: 7 | Iteration number: [2850/4518] 63% | Training loss: 0.6872924935817718
Epoch: 7 | Iteration number: [2860/4518] 63% | Training loss: 0.6872868696292798
Epoch: 7 | Iteration number: [2870/4518] 63% | Training loss: 0.6872866936053964
Epoch: 7 | Iteration number: [2880/4518] 63% | Training loss: 0.6872848695971899
Epoch: 7 | Iteration number: [2890/4518] 63% | Training loss: 0.6872847993893607
Epoch: 7 | Iteration number: [2900/4518] 64% | Training loss: 0.6872806638479233
Epoch: 7 | Iteration number: [2910/4518] 64% | Training loss: 0.6872803682928642
Epoch: 7 | Iteration number: [2920/4518] 64% | Training loss: 0.6872797274834489
Epoch: 7 | Iteration number: [2930/4518] 64% | Training loss: 0.6872851871996609
Epoch: 7 | Iteration number: [2940/4518] 65% | Training loss: 0.6872879266941628
Epoch: 7 | Iteration number: [2950/4518] 65% | Training loss: 0.6872880532984006
Epoch: 7 | Iteration number: [2960/4518] 65% | Training loss: 0.6872837404544289
Epoch: 7 | Iteration number: [2970/4518] 65% | Training loss: 0.6872831052200561
Epoch: 7 | Iteration number: [2980/4518] 65% | Training loss: 0.6872839307825037
Epoch: 7 | Iteration number: [2990/4518] 66% | Training loss: 0.687280656422261
Epoch: 7 | Iteration number: [3000/4518] 66% | Training loss: 0.6872754821181297
Epoch: 7 | Iteration number: [3010/4518] 66% | Training loss: 0.687279745193811
Epoch: 7 | Iteration number: [3020/4518] 66% | Training loss: 0.6872772758962303
Epoch: 7 | Iteration number: [3030/4518] 67% | Training loss: 0.687276810978112
Epoch: 7 | Iteration number: [3040/4518] 67% | Training loss: 0.6872737181814094
Epoch: 7 | Iteration number: [3050/4518] 67% | Training loss: 0.6872752918571722
Epoch: 7 | Iteration number: [3060/4518] 67% | Training loss: 0.6872734663922803
Epoch: 7 | Iteration number: [3070/4518] 67% | Training loss: 0.687275454353432
Epoch: 7 | Iteration number: [3080/4518] 68% | Training loss: 0.687272786203917
Epoch: 7 | Iteration number: [3090/4518] 68% | Training loss: 0.6872712882012612
Epoch: 7 | Iteration number: [3100/4518] 68% | Training loss: 0.6872711030514009
Epoch: 7 | Iteration number: [3110/4518] 68% | Training loss: 0.6872713923454284
Epoch: 7 | Iteration number: [3120/4518] 69% | Training loss: 0.687270334840585
Epoch: 7 | Iteration number: [3130/4518] 69% | Training loss: 0.6872739423959019
Epoch: 7 | Iteration number: [3140/4518] 69% | Training loss: 0.6872725884625867
Epoch: 7 | Iteration number: [3150/4518] 69% | Training loss: 0.6872763446020702
Epoch: 7 | Iteration number: [3160/4518] 69% | Training loss: 0.6872793799714197
Epoch: 7 | Iteration number: [3170/4518] 70% | Training loss: 0.6872790085216426
Epoch: 7 | Iteration number: [3180/4518] 70% | Training loss: 0.6872782131036123
Epoch: 7 | Iteration number: [3190/4518] 70% | Training loss: 0.6872815222015202
Epoch: 7 | Iteration number: [3200/4518] 70% | Training loss: 0.6872800043411553
Epoch: 7 | Iteration number: [3210/4518] 71% | Training loss: 0.68727811491378
Epoch: 7 | Iteration number: [3220/4518] 71% | Training loss: 0.6872799066653162
Epoch: 7 | Iteration number: [3230/4518] 71% | Training loss: 0.6872830883452766
Epoch: 7 | Iteration number: [3240/4518] 71% | Training loss: 0.6872788915479625
Epoch: 7 | Iteration number: [3250/4518] 71% | Training loss: 0.6872793716650742
Epoch: 7 | Iteration number: [3260/4518] 72% | Training loss: 0.6872810860353014
Epoch: 7 | Iteration number: [3270/4518] 72% | Training loss: 0.6872776958738263
Epoch: 7 | Iteration number: [3280/4518] 72% | Training loss: 0.6872800677287869
Epoch: 7 | Iteration number: [3290/4518] 72% | Training loss: 0.6872783520120256
Epoch: 7 | Iteration number: [3300/4518] 73% | Training loss: 0.6872797750523596
Epoch: 7 | Iteration number: [3310/4518] 73% | Training loss: 0.6872798980903049
Epoch: 7 | Iteration number: [3320/4518] 73% | Training loss: 0.6872781564133713
Epoch: 7 | Iteration number: [3330/4518] 73% | Training loss: 0.687280299176683
Epoch: 7 | Iteration number: [3340/4518] 73% | Training loss: 0.6872814718834654
Epoch: 7 | Iteration number: [3350/4518] 74% | Training loss: 0.6872817406903452
Epoch: 7 | Iteration number: [3360/4518] 74% | Training loss: 0.687282413936087
Epoch: 7 | Iteration number: [3370/4518] 74% | Training loss: 0.6872811968319494
Epoch: 7 | Iteration number: [3380/4518] 74% | Training loss: 0.687281473183773
Epoch: 7 | Iteration number: [3390/4518] 75% | Training loss: 0.6872817256985161
Epoch: 7 | Iteration number: [3400/4518] 75% | Training loss: 0.6872812520931749
Epoch: 7 | Iteration number: [3410/4518] 75% | Training loss: 0.6872806449439868
Epoch: 7 | Iteration number: [3420/4518] 75% | Training loss: 0.6872773010828341
Epoch: 7 | Iteration number: [3430/4518] 75% | Training loss: 0.6872762613845637
Epoch: 7 | Iteration number: [3440/4518] 76% | Training loss: 0.6872774110283962
Epoch: 7 | Iteration number: [3450/4518] 76% | Training loss: 0.6872759390395621
Epoch: 7 | Iteration number: [3460/4518] 76% | Training loss: 0.6872772764436083
Epoch: 7 | Iteration number: [3470/4518] 76% | Training loss: 0.6872751067454258
Epoch: 7 | Iteration number: [3480/4518] 77% | Training loss: 0.6872719254986993
Epoch: 7 | Iteration number: [3490/4518] 77% | Training loss: 0.6872719146460722
Epoch: 7 | Iteration number: [3500/4518] 77% | Training loss: 0.6872694338389805
Epoch: 7 | Iteration number: [3510/4518] 77% | Training loss: 0.6872719778973833
Epoch: 7 | Iteration number: [3520/4518] 77% | Training loss: 0.6872707079757344
Epoch: 7 | Iteration number: [3530/4518] 78% | Training loss: 0.6872691624900774
Epoch: 7 | Iteration number: [3540/4518] 78% | Training loss: 0.6872680628030313
Epoch: 7 | Iteration number: [3550/4518] 78% | Training loss: 0.6872670875300824
Epoch: 7 | Iteration number: [3560/4518] 78% | Training loss: 0.6872647320956327
Epoch: 7 | Iteration number: [3570/4518] 79% | Training loss: 0.6872608476326245
Epoch: 7 | Iteration number: [3580/4518] 79% | Training loss: 0.6872618168092973
Epoch: 7 | Iteration number: [3590/4518] 79% | Training loss: 0.6872608601548877
Epoch: 7 | Iteration number: [3600/4518] 79% | Training loss: 0.6872583327525191
Epoch: 7 | Iteration number: [3610/4518] 79% | Training loss: 0.6872565928918833
Epoch: 7 | Iteration number: [3620/4518] 80% | Training loss: 0.6872533540864018
Epoch: 7 | Iteration number: [3630/4518] 80% | Training loss: 0.6872558816569567
Epoch: 7 | Iteration number: [3640/4518] 80% | Training loss: 0.6872551497522291
Epoch: 7 | Iteration number: [3650/4518] 80% | Training loss: 0.6872578036948426
Epoch: 7 | Iteration number: [3660/4518] 81% | Training loss: 0.687251096214753
Epoch: 7 | Iteration number: [3670/4518] 81% | Training loss: 0.687250297417108
Epoch: 7 | Iteration number: [3680/4518] 81% | Training loss: 0.687256979521202
Epoch: 7 | Iteration number: [3690/4518] 81% | Training loss: 0.6872562848455538
Epoch: 7 | Iteration number: [3700/4518] 81% | Training loss: 0.6872570498408498
Epoch: 7 | Iteration number: [3710/4518] 82% | Training loss: 0.6872600174817756
Epoch: 7 | Iteration number: [3720/4518] 82% | Training loss: 0.6872614655603645
Epoch: 7 | Iteration number: [3730/4518] 82% | Training loss: 0.6872639340785489
Epoch: 7 | Iteration number: [3740/4518] 82% | Training loss: 0.687261740919103
Epoch: 7 | Iteration number: [3750/4518] 83% | Training loss: 0.6872599656263987
Epoch: 7 | Iteration number: [3760/4518] 83% | Training loss: 0.6872572141758939
Epoch: 7 | Iteration number: [3770/4518] 83% | Training loss: 0.687255656292331
Epoch: 7 | Iteration number: [3780/4518] 83% | Training loss: 0.6872538109462728
Epoch: 7 | Iteration number: [3790/4518] 83% | Training loss: 0.6872555069841622
Epoch: 7 | Iteration number: [3800/4518] 84% | Training loss: 0.6872613291363967
Epoch: 7 | Iteration number: [3810/4518] 84% | Training loss: 0.6872593558679415
Epoch: 7 | Iteration number: [3820/4518] 84% | Training loss: 0.6872584461229634
Epoch: 7 | Iteration number: [3830/4518] 84% | Training loss: 0.6872575023622488
Epoch: 7 | Iteration number: [3840/4518] 84% | Training loss: 0.687257603292043
Epoch: 7 | Iteration number: [3850/4518] 85% | Training loss: 0.6872563550843821
Epoch: 7 | Iteration number: [3860/4518] 85% | Training loss: 0.6872566687782812
Epoch: 7 | Iteration number: [3870/4518] 85% | Training loss: 0.6872571268593002
Epoch: 7 | Iteration number: [3880/4518] 85% | Training loss: 0.6872549283596658
Epoch: 7 | Iteration number: [3890/4518] 86% | Training loss: 0.6872502918415021
Epoch: 7 | Iteration number: [3900/4518] 86% | Training loss: 0.6872526639394271
Epoch: 7 | Iteration number: [3910/4518] 86% | Training loss: 0.6872528140349766
Epoch: 7 | Iteration number: [3920/4518] 86% | Training loss: 0.6872523732939545
Epoch: 7 | Iteration number: [3930/4518] 86% | Training loss: 0.6872539959942718
Epoch: 7 | Iteration number: [3940/4518] 87% | Training loss: 0.6872515019426491
Epoch: 7 | Iteration number: [3950/4518] 87% | Training loss: 0.6872491958020609
Epoch: 7 | Iteration number: [3960/4518] 87% | Training loss: 0.6872472946390961
Epoch: 7 | Iteration number: [3970/4518] 87% | Training loss: 0.6872440218324926
Epoch: 7 | Iteration number: [3980/4518] 88% | Training loss: 0.6872449107505568
Epoch: 7 | Iteration number: [3990/4518] 88% | Training loss: 0.6872443094886933
Epoch: 7 | Iteration number: [4000/4518] 88% | Training loss: 0.6872461649626493
Epoch: 7 | Iteration number: [4010/4518] 88% | Training loss: 0.6872454973676259
Epoch: 7 | Iteration number: [4020/4518] 88% | Training loss: 0.6872453859937725
Epoch: 7 | Iteration number: [4030/4518] 89% | Training loss: 0.6872447324449904
Epoch: 7 | Iteration number: [4040/4518] 89% | Training loss: 0.687245123235896
Epoch: 7 | Iteration number: [4050/4518] 89% | Training loss: 0.6872429522761592
Epoch: 7 | Iteration number: [4060/4518] 89% | Training loss: 0.6872417710391171
Epoch: 7 | Iteration number: [4070/4518] 90% | Training loss: 0.6872397516664182
Epoch: 7 | Iteration number: [4080/4518] 90% | Training loss: 0.6872388084291243
Epoch: 7 | Iteration number: [4090/4518] 90% | Training loss: 0.6872384921991446
Epoch: 7 | Iteration number: [4100/4518] 90% | Training loss: 0.6872331313098349
Epoch: 7 | Iteration number: [4110/4518] 90% | Training loss: 0.6872321915597521
Epoch: 7 | Iteration number: [4120/4518] 91% | Training loss: 0.6872342328278763
Epoch: 7 | Iteration number: [4130/4518] 91% | Training loss: 0.6872323688525553
Epoch: 7 | Iteration number: [4140/4518] 91% | Training loss: 0.6872318675696562
Epoch: 7 | Iteration number: [4150/4518] 91% | Training loss: 0.6872340771807246
Epoch: 7 | Iteration number: [4160/4518] 92% | Training loss: 0.687230052985251
Epoch: 7 | Iteration number: [4170/4518] 92% | Training loss: 0.6872273525745749
Epoch: 7 | Iteration number: [4180/4518] 92% | Training loss: 0.6872237153886037
Epoch: 7 | Iteration number: [4190/4518] 92% | Training loss: 0.6872248561399364
Epoch: 7 | Iteration number: [4200/4518] 92% | Training loss: 0.6872240074475606
Epoch: 7 | Iteration number: [4210/4518] 93% | Training loss: 0.6872190489197004
Epoch: 7 | Iteration number: [4220/4518] 93% | Training loss: 0.6872194123917846
Epoch: 7 | Iteration number: [4230/4518] 93% | Training loss: 0.6872185140495887
Epoch: 7 | Iteration number: [4240/4518] 93% | Training loss: 0.6872181267108557
Epoch: 7 | Iteration number: [4250/4518] 94% | Training loss: 0.6872176371882943
Epoch: 7 | Iteration number: [4260/4518] 94% | Training loss: 0.687216594591387
Epoch: 7 | Iteration number: [4270/4518] 94% | Training loss: 0.6872177462806747
Epoch: 7 | Iteration number: [4280/4518] 94% | Training loss: 0.6872174566454976
Epoch: 7 | Iteration number: [4290/4518] 94% | Training loss: 0.6872189874276693
Epoch: 7 | Iteration number: [4300/4518] 95% | Training loss: 0.6872168323466944
Epoch: 7 | Iteration number: [4310/4518] 95% | Training loss: 0.6872137476839212
Epoch: 7 | Iteration number: [4320/4518] 95% | Training loss: 0.6872159310099152
Epoch: 7 | Iteration number: [4330/4518] 95% | Training loss: 0.6872117002896844
Epoch: 7 | Iteration number: [4340/4518] 96% | Training loss: 0.687211133258134
Epoch: 7 | Iteration number: [4350/4518] 96% | Training loss: 0.6872120004823838
Epoch: 7 | Iteration number: [4360/4518] 96% | Training loss: 0.6872122299917247
Epoch: 7 | Iteration number: [4370/4518] 96% | Training loss: 0.6872103949296938
Epoch: 7 | Iteration number: [4380/4518] 96% | Training loss: 0.6872139339985913
Epoch: 7 | Iteration number: [4390/4518] 97% | Training loss: 0.687213872043853
Epoch: 7 | Iteration number: [4400/4518] 97% | Training loss: 0.6872137149084698
Epoch: 7 | Iteration number: [4410/4518] 97% | Training loss: 0.6872134812835122
Epoch: 7 | Iteration number: [4420/4518] 97% | Training loss: 0.6872106705450903
Epoch: 7 | Iteration number: [4430/4518] 98% | Training loss: 0.6872090640509371
Epoch: 7 | Iteration number: [4440/4518] 98% | Training loss: 0.6872082265379192
Epoch: 7 | Iteration number: [4450/4518] 98% | Training loss: 0.6872068388542433
Epoch: 7 | Iteration number: [4460/4518] 98% | Training loss: 0.6872076143865629
Epoch: 7 | Iteration number: [4470/4518] 98% | Training loss: 0.6872098543366596
Epoch: 7 | Iteration number: [4480/4518] 99% | Training loss: 0.6872123299964836
Epoch: 7 | Iteration number: [4490/4518] 99% | Training loss: 0.6872119751698721
Epoch: 7 | Iteration number: [4500/4518] 99% | Training loss: 0.6872149397134781
Epoch: 7 | Iteration number: [4510/4518] 99% | Training loss: 0.6872163054287566

 End of epoch: 7 | Train Loss: 0.6870641796501298 | Training Time: 642 

 End of epoch: 7 | Eval Loss: 0.6906057206951842 | Evaluating Time: 17 
Epoch: 8 | Iteration number: [10/4518] 0% | Training loss: 0.755708509683609
Epoch: 8 | Iteration number: [20/4518] 0% | Training loss: 0.720995831489563
Epoch: 8 | Iteration number: [30/4518] 0% | Training loss: 0.710019983847936
Epoch: 8 | Iteration number: [40/4518] 0% | Training loss: 0.704358084499836
Epoch: 8 | Iteration number: [50/4518] 1% | Training loss: 0.7010864448547364
Epoch: 8 | Iteration number: [60/4518] 1% | Training loss: 0.6986572613318761
Epoch: 8 | Iteration number: [70/4518] 1% | Training loss: 0.6971916896956307
Epoch: 8 | Iteration number: [80/4518] 1% | Training loss: 0.6959329597651959
Epoch: 8 | Iteration number: [90/4518] 1% | Training loss: 0.6949325899283091
Epoch: 8 | Iteration number: [100/4518] 2% | Training loss: 0.6941675674915314
Epoch: 8 | Iteration number: [110/4518] 2% | Training loss: 0.6934834946285594
Epoch: 8 | Iteration number: [120/4518] 2% | Training loss: 0.6928716152906418
Epoch: 8 | Iteration number: [130/4518] 2% | Training loss: 0.6923534301611093
Epoch: 8 | Iteration number: [140/4518] 3% | Training loss: 0.6919648677110672
Epoch: 8 | Iteration number: [150/4518] 3% | Training loss: 0.6916080232461294
Epoch: 8 | Iteration number: [160/4518] 3% | Training loss: 0.6914262276142835
Epoch: 8 | Iteration number: [170/4518] 3% | Training loss: 0.6911652687717886
Epoch: 8 | Iteration number: [180/4518] 3% | Training loss: 0.6909523215558794
Epoch: 8 | Iteration number: [190/4518] 4% | Training loss: 0.6907027407696372
Epoch: 8 | Iteration number: [200/4518] 4% | Training loss: 0.6905630537867546
Epoch: 8 | Iteration number: [210/4518] 4% | Training loss: 0.6904083200863429
Epoch: 8 | Iteration number: [220/4518] 4% | Training loss: 0.6902860535816713
Epoch: 8 | Iteration number: [230/4518] 5% | Training loss: 0.6901608518932176
Epoch: 8 | Iteration number: [240/4518] 5% | Training loss: 0.69007381995519
Epoch: 8 | Iteration number: [250/4518] 5% | Training loss: 0.6899664072990418
Epoch: 8 | Iteration number: [260/4518] 5% | Training loss: 0.6898656689203703
Epoch: 8 | Iteration number: [270/4518] 5% | Training loss: 0.6897983222096055
Epoch: 8 | Iteration number: [280/4518] 6% | Training loss: 0.6897319169981139
Epoch: 8 | Iteration number: [290/4518] 6% | Training loss: 0.689636406610752
Epoch: 8 | Iteration number: [300/4518] 6% | Training loss: 0.6895290994644165
Epoch: 8 | Iteration number: [310/4518] 6% | Training loss: 0.6894125640392303
Epoch: 8 | Iteration number: [320/4518] 7% | Training loss: 0.6893182877451182
Epoch: 8 | Iteration number: [330/4518] 7% | Training loss: 0.6892062080628945
Epoch: 8 | Iteration number: [340/4518] 7% | Training loss: 0.6891526173142826
Epoch: 8 | Iteration number: [350/4518] 7% | Training loss: 0.6891029940332685
Epoch: 8 | Iteration number: [360/4518] 7% | Training loss: 0.6890719246533182
Epoch: 8 | Iteration number: [370/4518] 8% | Training loss: 0.6890331922350703
Epoch: 8 | Iteration number: [380/4518] 8% | Training loss: 0.6889892860462791
Epoch: 8 | Iteration number: [390/4518] 8% | Training loss: 0.6889285295437544
Epoch: 8 | Iteration number: [400/4518] 8% | Training loss: 0.6888882820308209
Epoch: 8 | Iteration number: [410/4518] 9% | Training loss: 0.6888302701275523
Epoch: 8 | Iteration number: [420/4518] 9% | Training loss: 0.688785165264493
Epoch: 8 | Iteration number: [430/4518] 9% | Training loss: 0.6887351924596831
Epoch: 8 | Iteration number: [440/4518] 9% | Training loss: 0.6886540297757495
Epoch: 8 | Iteration number: [450/4518] 9% | Training loss: 0.6886246004369524
Epoch: 8 | Iteration number: [460/4518] 10% | Training loss: 0.6885757014803264
Epoch: 8 | Iteration number: [470/4518] 10% | Training loss: 0.6885485130421659
Epoch: 8 | Iteration number: [480/4518] 10% | Training loss: 0.6885322699944179
Epoch: 8 | Iteration number: [490/4518] 10% | Training loss: 0.6884993643176799
Epoch: 8 | Iteration number: [500/4518] 11% | Training loss: 0.6884772233963012
Epoch: 8 | Iteration number: [510/4518] 11% | Training loss: 0.6884638822546192
Epoch: 8 | Iteration number: [520/4518] 11% | Training loss: 0.6884011908219411
Epoch: 8 | Iteration number: [530/4518] 11% | Training loss: 0.6883838083384172
Epoch: 8 | Iteration number: [540/4518] 11% | Training loss: 0.6883622957600488
Epoch: 8 | Iteration number: [550/4518] 12% | Training loss: 0.6883271177248521
Epoch: 8 | Iteration number: [560/4518] 12% | Training loss: 0.6883051682795797
Epoch: 8 | Iteration number: [570/4518] 12% | Training loss: 0.6882735474067821
Epoch: 8 | Iteration number: [580/4518] 12% | Training loss: 0.6882573189406559
Epoch: 8 | Iteration number: [590/4518] 13% | Training loss: 0.6882472033217802
Epoch: 8 | Iteration number: [600/4518] 13% | Training loss: 0.6882371443510056
Epoch: 8 | Iteration number: [610/4518] 13% | Training loss: 0.6882421518935532
Epoch: 8 | Iteration number: [620/4518] 13% | Training loss: 0.6882192120436699
Epoch: 8 | Iteration number: [630/4518] 13% | Training loss: 0.6882105727044363
Epoch: 8 | Iteration number: [640/4518] 14% | Training loss: 0.6881761531345546
Epoch: 8 | Iteration number: [650/4518] 14% | Training loss: 0.6881483369607192
Epoch: 8 | Iteration number: [660/4518] 14% | Training loss: 0.6881432896310633
Epoch: 8 | Iteration number: [670/4518] 14% | Training loss: 0.6881393818712946
Epoch: 8 | Iteration number: [680/4518] 15% | Training loss: 0.6881327252177631
Epoch: 8 | Iteration number: [690/4518] 15% | Training loss: 0.6881249130636021
Epoch: 8 | Iteration number: [700/4518] 15% | Training loss: 0.6881000415767942
Epoch: 8 | Iteration number: [710/4518] 15% | Training loss: 0.6880907665675795
Epoch: 8 | Iteration number: [720/4518] 15% | Training loss: 0.6880721752014425
Epoch: 8 | Iteration number: [730/4518] 16% | Training loss: 0.6880596588735711
Epoch: 8 | Iteration number: [740/4518] 16% | Training loss: 0.688045863283647
Epoch: 8 | Iteration number: [750/4518] 16% | Training loss: 0.6880260564486186
Epoch: 8 | Iteration number: [760/4518] 16% | Training loss: 0.6880171202515301
Epoch: 8 | Iteration number: [770/4518] 17% | Training loss: 0.6880017652140036
Epoch: 8 | Iteration number: [780/4518] 17% | Training loss: 0.6879903994309596
Epoch: 8 | Iteration number: [790/4518] 17% | Training loss: 0.6879875662206094
Epoch: 8 | Iteration number: [800/4518] 17% | Training loss: 0.6879847354441881
Epoch: 8 | Iteration number: [810/4518] 17% | Training loss: 0.6879756685392356
Epoch: 8 | Iteration number: [820/4518] 18% | Training loss: 0.687966266855961
Epoch: 8 | Iteration number: [830/4518] 18% | Training loss: 0.6879424268940845
Epoch: 8 | Iteration number: [840/4518] 18% | Training loss: 0.6879401642651785
Epoch: 8 | Iteration number: [850/4518] 18% | Training loss: 0.6879062569141388
Epoch: 8 | Iteration number: [860/4518] 19% | Training loss: 0.6878864696552587
Epoch: 8 | Iteration number: [870/4518] 19% | Training loss: 0.6878717459481338
Epoch: 8 | Iteration number: [880/4518] 19% | Training loss: 0.6878566157411445
Epoch: 8 | Iteration number: [890/4518] 19% | Training loss: 0.6878320229857156
Epoch: 8 | Iteration number: [900/4518] 19% | Training loss: 0.687820074028439
Epoch: 8 | Iteration number: [910/4518] 20% | Training loss: 0.6878098014291826
Epoch: 8 | Iteration number: [920/4518] 20% | Training loss: 0.6878115560697473
Epoch: 8 | Iteration number: [930/4518] 20% | Training loss: 0.6878002323130126
Epoch: 8 | Iteration number: [940/4518] 20% | Training loss: 0.687795355535568
Epoch: 8 | Iteration number: [950/4518] 21% | Training loss: 0.6877859359665921
Epoch: 8 | Iteration number: [960/4518] 21% | Training loss: 0.6877871870373686
Epoch: 8 | Iteration number: [970/4518] 21% | Training loss: 0.6877809345722199
Epoch: 8 | Iteration number: [980/4518] 21% | Training loss: 0.6877821315308006
Epoch: 8 | Iteration number: [990/4518] 21% | Training loss: 0.6877631017656037
Epoch: 8 | Iteration number: [1000/4518] 22% | Training loss: 0.6877592207789421
Epoch: 8 | Iteration number: [1010/4518] 22% | Training loss: 0.6877487634668256
Epoch: 8 | Iteration number: [1020/4518] 22% | Training loss: 0.6877366946024053
Epoch: 8 | Iteration number: [1030/4518] 22% | Training loss: 0.6877384465874977
Epoch: 8 | Iteration number: [1040/4518] 23% | Training loss: 0.6877307738249119
Epoch: 8 | Iteration number: [1050/4518] 23% | Training loss: 0.6877293176310403
Epoch: 8 | Iteration number: [1060/4518] 23% | Training loss: 0.687737300710858
Epoch: 8 | Iteration number: [1070/4518] 23% | Training loss: 0.6877277135291946
Epoch: 8 | Iteration number: [1080/4518] 23% | Training loss: 0.6877232507423118
Epoch: 8 | Iteration number: [1090/4518] 24% | Training loss: 0.6877024113585096
Epoch: 8 | Iteration number: [1100/4518] 24% | Training loss: 0.6877087705243717
Epoch: 8 | Iteration number: [1110/4518] 24% | Training loss: 0.6877018014052967
Epoch: 8 | Iteration number: [1120/4518] 24% | Training loss: 0.6876902521720955
Epoch: 8 | Iteration number: [1130/4518] 25% | Training loss: 0.6876787514813179
Epoch: 8 | Iteration number: [1140/4518] 25% | Training loss: 0.6876529584851181
Epoch: 8 | Iteration number: [1150/4518] 25% | Training loss: 0.6876535636445751
Epoch: 8 | Iteration number: [1160/4518] 25% | Training loss: 0.6876465309796662
Epoch: 8 | Iteration number: [1170/4518] 25% | Training loss: 0.6876412611741286
Epoch: 8 | Iteration number: [1180/4518] 26% | Training loss: 0.6876470240495973
Epoch: 8 | Iteration number: [1190/4518] 26% | Training loss: 0.6876432581609037
Epoch: 8 | Iteration number: [1200/4518] 26% | Training loss: 0.6876319159070651
Epoch: 8 | Iteration number: [1210/4518] 26% | Training loss: 0.6876284390934243
Epoch: 8 | Iteration number: [1220/4518] 27% | Training loss: 0.6876119459750223
Epoch: 8 | Iteration number: [1230/4518] 27% | Training loss: 0.6876124542903125
Epoch: 8 | Iteration number: [1240/4518] 27% | Training loss: 0.687606236819298
Epoch: 8 | Iteration number: [1250/4518] 27% | Training loss: 0.6876112302303314
Epoch: 8 | Iteration number: [1260/4518] 27% | Training loss: 0.6876200746449214
Epoch: 8 | Iteration number: [1270/4518] 28% | Training loss: 0.6876077952347402
Epoch: 8 | Iteration number: [1280/4518] 28% | Training loss: 0.6875973255839198
Epoch: 8 | Iteration number: [1290/4518] 28% | Training loss: 0.6875916909801868
Epoch: 8 | Iteration number: [1300/4518] 28% | Training loss: 0.6875821290107874
Epoch: 8 | Iteration number: [1310/4518] 28% | Training loss: 0.687587810245179
Epoch: 8 | Iteration number: [1320/4518] 29% | Training loss: 0.6875765930974123
Epoch: 8 | Iteration number: [1330/4518] 29% | Training loss: 0.6875749754278283
Epoch: 8 | Iteration number: [1340/4518] 29% | Training loss: 0.6875743620876056
Epoch: 8 | Iteration number: [1350/4518] 29% | Training loss: 0.6875636540518867
Epoch: 8 | Iteration number: [1360/4518] 30% | Training loss: 0.6875550245975747
Epoch: 8 | Iteration number: [1370/4518] 30% | Training loss: 0.6875559040664756
Epoch: 8 | Iteration number: [1380/4518] 30% | Training loss: 0.6875611415375834
Epoch: 8 | Iteration number: [1390/4518] 30% | Training loss: 0.687559982898424
Epoch: 8 | Iteration number: [1400/4518] 30% | Training loss: 0.6875592139363289
Epoch: 8 | Iteration number: [1410/4518] 31% | Training loss: 0.6875577828140124
Epoch: 8 | Iteration number: [1420/4518] 31% | Training loss: 0.6875584189740704
Epoch: 8 | Iteration number: [1430/4518] 31% | Training loss: 0.6875618283982043
Epoch: 8 | Iteration number: [1440/4518] 31% | Training loss: 0.6875496349400945
Epoch: 8 | Iteration number: [1450/4518] 32% | Training loss: 0.68754820165963
Epoch: 8 | Iteration number: [1460/4518] 32% | Training loss: 0.6875447072803158
Epoch: 8 | Iteration number: [1470/4518] 32% | Training loss: 0.6875357261320361
Epoch: 8 | Iteration number: [1480/4518] 32% | Training loss: 0.6875266214883006
Epoch: 8 | Iteration number: [1490/4518] 32% | Training loss: 0.6875253721771625
Epoch: 8 | Iteration number: [1500/4518] 33% | Training loss: 0.6875196299950281
Epoch: 8 | Iteration number: [1510/4518] 33% | Training loss: 0.6875131921657663
Epoch: 8 | Iteration number: [1520/4518] 33% | Training loss: 0.6875181871025186
Epoch: 8 | Iteration number: [1530/4518] 33% | Training loss: 0.6875166536935794
Epoch: 8 | Iteration number: [1540/4518] 34% | Training loss: 0.6875161649344803
Epoch: 8 | Iteration number: [1550/4518] 34% | Training loss: 0.6875149322709729
Epoch: 8 | Iteration number: [1560/4518] 34% | Training loss: 0.6875143828682411
Epoch: 8 | Iteration number: [1570/4518] 34% | Training loss: 0.68750947041876
Epoch: 8 | Iteration number: [1580/4518] 34% | Training loss: 0.6875067377015005
Epoch: 8 | Iteration number: [1590/4518] 35% | Training loss: 0.6875034174454288
Epoch: 8 | Iteration number: [1600/4518] 35% | Training loss: 0.6875038554519415
Epoch: 8 | Iteration number: [1610/4518] 35% | Training loss: 0.687507117423952
Epoch: 8 | Iteration number: [1620/4518] 35% | Training loss: 0.6875042501055164
Epoch: 8 | Iteration number: [1630/4518] 36% | Training loss: 0.687499330709317
Epoch: 8 | Iteration number: [1640/4518] 36% | Training loss: 0.6875014100496362
Epoch: 8 | Iteration number: [1650/4518] 36% | Training loss: 0.6874968827493263
Epoch: 8 | Iteration number: [1660/4518] 36% | Training loss: 0.6874951305877731
Epoch: 8 | Iteration number: [1670/4518] 36% | Training loss: 0.6874901600583585
Epoch: 8 | Iteration number: [1680/4518] 37% | Training loss: 0.6874902023800782
Epoch: 8 | Iteration number: [1690/4518] 37% | Training loss: 0.6874922207474004
Epoch: 8 | Iteration number: [1700/4518] 37% | Training loss: 0.6874944372387494
Epoch: 8 | Iteration number: [1710/4518] 37% | Training loss: 0.6874887266702819
Epoch: 8 | Iteration number: [1720/4518] 38% | Training loss: 0.6874813843951669
Epoch: 8 | Iteration number: [1730/4518] 38% | Training loss: 0.6874753019024182
Epoch: 8 | Iteration number: [1740/4518] 38% | Training loss: 0.6874759592886629
Epoch: 8 | Iteration number: [1750/4518] 38% | Training loss: 0.687481202840805
Epoch: 8 | Iteration number: [1760/4518] 38% | Training loss: 0.6874754764478315
Epoch: 8 | Iteration number: [1770/4518] 39% | Training loss: 0.6874649696094168
Epoch: 8 | Iteration number: [1780/4518] 39% | Training loss: 0.6874640790933974
Epoch: 8 | Iteration number: [1790/4518] 39% | Training loss: 0.687457757522274
Epoch: 8 | Iteration number: [1800/4518] 39% | Training loss: 0.6874538097778956
Epoch: 8 | Iteration number: [1810/4518] 40% | Training loss: 0.6874544334016452
Epoch: 8 | Iteration number: [1820/4518] 40% | Training loss: 0.6874570708025943
Epoch: 8 | Iteration number: [1830/4518] 40% | Training loss: 0.6874561460291753
Epoch: 8 | Iteration number: [1840/4518] 40% | Training loss: 0.6874528395740882
Epoch: 8 | Iteration number: [1850/4518] 40% | Training loss: 0.6874477362954938
Epoch: 8 | Iteration number: [1860/4518] 41% | Training loss: 0.6874478913122608
Epoch: 8 | Iteration number: [1870/4518] 41% | Training loss: 0.6874425171212079
Epoch: 8 | Iteration number: [1880/4518] 41% | Training loss: 0.6874435390563721
Epoch: 8 | Iteration number: [1890/4518] 41% | Training loss: 0.6874426234651495
Epoch: 8 | Iteration number: [1900/4518] 42% | Training loss: 0.6874403383543617
Epoch: 8 | Iteration number: [1910/4518] 42% | Training loss: 0.6874374717005884
Epoch: 8 | Iteration number: [1920/4518] 42% | Training loss: 0.687435677057753
Epoch: 8 | Iteration number: [1930/4518] 42% | Training loss: 0.6874336539772508
Epoch: 8 | Iteration number: [1940/4518] 42% | Training loss: 0.6874350407996128
Epoch: 8 | Iteration number: [1950/4518] 43% | Training loss: 0.6874353799147483
Epoch: 8 | Iteration number: [1960/4518] 43% | Training loss: 0.6874352295787967
Epoch: 8 | Iteration number: [1970/4518] 43% | Training loss: 0.6874308891405309
Epoch: 8 | Iteration number: [1980/4518] 43% | Training loss: 0.6874290001813812
Epoch: 8 | Iteration number: [1990/4518] 44% | Training loss: 0.6874287351291982
Epoch: 8 | Iteration number: [2000/4518] 44% | Training loss: 0.6874213230609894
Epoch: 8 | Iteration number: [2010/4518] 44% | Training loss: 0.6874156244358613
Epoch: 8 | Iteration number: [2020/4518] 44% | Training loss: 0.6874105966622287
Epoch: 8 | Iteration number: [2030/4518] 44% | Training loss: 0.687411611596939
Epoch: 8 | Iteration number: [2040/4518] 45% | Training loss: 0.6874100865686641
Epoch: 8 | Iteration number: [2050/4518] 45% | Training loss: 0.687406782377057
Epoch: 8 | Iteration number: [2060/4518] 45% | Training loss: 0.6874082449859786
Epoch: 8 | Iteration number: [2070/4518] 45% | Training loss: 0.6874088615035089
Epoch: 8 | Iteration number: [2080/4518] 46% | Training loss: 0.687403257850271
Epoch: 8 | Iteration number: [2090/4518] 46% | Training loss: 0.6873998438627525
Epoch: 8 | Iteration number: [2100/4518] 46% | Training loss: 0.6873981121892021
Epoch: 8 | Iteration number: [2110/4518] 46% | Training loss: 0.6873907384431758
Epoch: 8 | Iteration number: [2120/4518] 46% | Training loss: 0.6873865557166765
Epoch: 8 | Iteration number: [2130/4518] 47% | Training loss: 0.687387208423704
Epoch: 8 | Iteration number: [2140/4518] 47% | Training loss: 0.6873830124039516
Epoch: 8 | Iteration number: [2150/4518] 47% | Training loss: 0.6873853536816531
Epoch: 8 | Iteration number: [2160/4518] 47% | Training loss: 0.6873858958206794
Epoch: 8 | Iteration number: [2170/4518] 48% | Training loss: 0.6873870742760496
Epoch: 8 | Iteration number: [2180/4518] 48% | Training loss: 0.6873864118385753
Epoch: 8 | Iteration number: [2190/4518] 48% | Training loss: 0.6873772050147732
Epoch: 8 | Iteration number: [2200/4518] 48% | Training loss: 0.6873716802759604
Epoch: 8 | Iteration number: [2210/4518] 48% | Training loss: 0.6873738983907312
Epoch: 8 | Iteration number: [2220/4518] 49% | Training loss: 0.6873689697400943
Epoch: 8 | Iteration number: [2230/4518] 49% | Training loss: 0.6873716284875913
Epoch: 8 | Iteration number: [2240/4518] 49% | Training loss: 0.6873661794034498
Epoch: 8 | Iteration number: [2250/4518] 49% | Training loss: 0.6873619518015119
Epoch: 8 | Iteration number: [2260/4518] 50% | Training loss: 0.6873595345600516
Epoch: 8 | Iteration number: [2270/4518] 50% | Training loss: 0.6873578256184835
Epoch: 8 | Iteration number: [2280/4518] 50% | Training loss: 0.6873524073968854
Epoch: 8 | Iteration number: [2290/4518] 50% | Training loss: 0.6873478584935051
Epoch: 8 | Iteration number: [2300/4518] 50% | Training loss: 0.6873483436263126
Epoch: 8 | Iteration number: [2310/4518] 51% | Training loss: 0.6873465474807855
Epoch: 8 | Iteration number: [2320/4518] 51% | Training loss: 0.6873471631572164
Epoch: 8 | Iteration number: [2330/4518] 51% | Training loss: 0.6873399004659939
Epoch: 8 | Iteration number: [2340/4518] 51% | Training loss: 0.6873417490567917
Epoch: 8 | Iteration number: [2350/4518] 52% | Training loss: 0.6873405827359951
Epoch: 8 | Iteration number: [2360/4518] 52% | Training loss: 0.6873341399734303
Epoch: 8 | Iteration number: [2370/4518] 52% | Training loss: 0.6873323343222655
Epoch: 8 | Iteration number: [2380/4518] 52% | Training loss: 0.6873291808517039
Epoch: 8 | Iteration number: [2390/4518] 52% | Training loss: 0.6873260937475261
Epoch: 8 | Iteration number: [2400/4518] 53% | Training loss: 0.6873270126680533
Epoch: 8 | Iteration number: [2410/4518] 53% | Training loss: 0.6873198993473132
Epoch: 8 | Iteration number: [2420/4518] 53% | Training loss: 0.6873188370269192
Epoch: 8 | Iteration number: [2430/4518] 53% | Training loss: 0.6873175685297805
Epoch: 8 | Iteration number: [2440/4518] 54% | Training loss: 0.6873205134370288
Epoch: 8 | Iteration number: [2450/4518] 54% | Training loss: 0.6873160851245024
Epoch: 8 | Iteration number: [2460/4518] 54% | Training loss: 0.6873117789020383
Epoch: 8 | Iteration number: [2470/4518] 54% | Training loss: 0.6873133057042172
Epoch: 8 | Iteration number: [2480/4518] 54% | Training loss: 0.6873133553852958
Epoch: 8 | Iteration number: [2490/4518] 55% | Training loss: 0.6873092326533843
Epoch: 8 | Iteration number: [2500/4518] 55% | Training loss: 0.68731296916008
Epoch: 8 | Iteration number: [2510/4518] 55% | Training loss: 0.687313473010918
Epoch: 8 | Iteration number: [2520/4518] 55% | Training loss: 0.6873189266711947
Epoch: 8 | Iteration number: [2530/4518] 55% | Training loss: 0.68732164332518
Epoch: 8 | Iteration number: [2540/4518] 56% | Training loss: 0.6873229420560552
Epoch: 8 | Iteration number: [2550/4518] 56% | Training loss: 0.6873245964097042
Epoch: 8 | Iteration number: [2560/4518] 56% | Training loss: 0.6873247051844373
Epoch: 8 | Iteration number: [2570/4518] 56% | Training loss: 0.687323498076502
Epoch: 8 | Iteration number: [2580/4518] 57% | Training loss: 0.6873229904461277
Epoch: 8 | Iteration number: [2590/4518] 57% | Training loss: 0.687319690909625
Epoch: 8 | Iteration number: [2600/4518] 57% | Training loss: 0.6873217497192896
Epoch: 8 | Iteration number: [2610/4518] 57% | Training loss: 0.687319167934615
Epoch: 8 | Iteration number: [2620/4518] 57% | Training loss: 0.6873191404206153
Epoch: 8 | Iteration number: [2630/4518] 58% | Training loss: 0.6873115002202443
Epoch: 8 | Iteration number: [2640/4518] 58% | Training loss: 0.6873115873923807
Epoch: 8 | Iteration number: [2650/4518] 58% | Training loss: 0.6873130476024916
Epoch: 8 | Iteration number: [2660/4518] 58% | Training loss: 0.6873112940026406
Epoch: 8 | Iteration number: [2670/4518] 59% | Training loss: 0.6873080742493104
Epoch: 8 | Iteration number: [2680/4518] 59% | Training loss: 0.6873036181526397
Epoch: 8 | Iteration number: [2690/4518] 59% | Training loss: 0.6873004179904895
Epoch: 8 | Iteration number: [2700/4518] 59% | Training loss: 0.6873059913626424
Epoch: 8 | Iteration number: [2710/4518] 59% | Training loss: 0.6873022811659147
Epoch: 8 | Iteration number: [2720/4518] 60% | Training loss: 0.6872985866359052
Epoch: 8 | Iteration number: [2730/4518] 60% | Training loss: 0.6872986276507814
Epoch: 8 | Iteration number: [2740/4518] 60% | Training loss: 0.687294496389201
Epoch: 8 | Iteration number: [2750/4518] 60% | Training loss: 0.6872948657165874
Epoch: 8 | Iteration number: [2760/4518] 61% | Training loss: 0.6872938989081244
Epoch: 8 | Iteration number: [2770/4518] 61% | Training loss: 0.6872926824359687
Epoch: 8 | Iteration number: [2780/4518] 61% | Training loss: 0.6872935535667611
Epoch: 8 | Iteration number: [2790/4518] 61% | Training loss: 0.6872968885420044
Epoch: 8 | Iteration number: [2800/4518] 61% | Training loss: 0.6872928275167942
Epoch: 8 | Iteration number: [2810/4518] 62% | Training loss: 0.6872897513184258
Epoch: 8 | Iteration number: [2820/4518] 62% | Training loss: 0.6872908852201827
Epoch: 8 | Iteration number: [2830/4518] 62% | Training loss: 0.6872868337184718
Epoch: 8 | Iteration number: [2840/4518] 62% | Training loss: 0.6872854466589404
Epoch: 8 | Iteration number: [2850/4518] 63% | Training loss: 0.6872833846744738
Epoch: 8 | Iteration number: [2860/4518] 63% | Training loss: 0.687278837048924
Epoch: 8 | Iteration number: [2870/4518] 63% | Training loss: 0.6872779003834475
Epoch: 8 | Iteration number: [2880/4518] 63% | Training loss: 0.6872733692949017
Epoch: 8 | Iteration number: [2890/4518] 63% | Training loss: 0.6872725342178014
Epoch: 8 | Iteration number: [2900/4518] 64% | Training loss: 0.6872721743789213
Epoch: 8 | Iteration number: [2910/4518] 64% | Training loss: 0.687274739832403
Epoch: 8 | Iteration number: [2920/4518] 64% | Training loss: 0.6872706308756789
Epoch: 8 | Iteration number: [2930/4518] 64% | Training loss: 0.6872699200496739
Epoch: 8 | Iteration number: [2940/4518] 65% | Training loss: 0.6872719321121163
Epoch: 8 | Iteration number: [2950/4518] 65% | Training loss: 0.6872764636904506
Epoch: 8 | Iteration number: [2960/4518] 65% | Training loss: 0.687269937307448
Epoch: 8 | Iteration number: [2970/4518] 65% | Training loss: 0.6872701376977594
Epoch: 8 | Iteration number: [2980/4518] 65% | Training loss: 0.6872704803343588
Epoch: 8 | Iteration number: [2990/4518] 66% | Training loss: 0.6872686914177643
Epoch: 8 | Iteration number: [3000/4518] 66% | Training loss: 0.6872724046905836
Epoch: 8 | Iteration number: [3010/4518] 66% | Training loss: 0.6872707867147122
Epoch: 8 | Iteration number: [3020/4518] 66% | Training loss: 0.6872661083147226
Epoch: 8 | Iteration number: [3030/4518] 67% | Training loss: 0.6872607436904026
Epoch: 8 | Iteration number: [3040/4518] 67% | Training loss: 0.6872589186618202
Epoch: 8 | Iteration number: [3050/4518] 67% | Training loss: 0.6872616988713625
Epoch: 8 | Iteration number: [3060/4518] 67% | Training loss: 0.687261454965554
Epoch: 8 | Iteration number: [3070/4518] 67% | Training loss: 0.6872608580107797
Epoch: 8 | Iteration number: [3080/4518] 68% | Training loss: 0.6872601065929834
Epoch: 8 | Iteration number: [3090/4518] 68% | Training loss: 0.6872578719865928
Epoch: 8 | Iteration number: [3100/4518] 68% | Training loss: 0.687259093619162
Epoch: 8 | Iteration number: [3110/4518] 68% | Training loss: 0.6872592491927254
Epoch: 8 | Iteration number: [3120/4518] 69% | Training loss: 0.6872620508647882
Epoch: 8 | Iteration number: [3130/4518] 69% | Training loss: 0.6872596848506135
Epoch: 8 | Iteration number: [3140/4518] 69% | Training loss: 0.687259690416087
Epoch: 8 | Iteration number: [3150/4518] 69% | Training loss: 0.687258131352682
Epoch: 8 | Iteration number: [3160/4518] 69% | Training loss: 0.6872605665763722
Epoch: 8 | Iteration number: [3170/4518] 70% | Training loss: 0.6872594290163239
Epoch: 8 | Iteration number: [3180/4518] 70% | Training loss: 0.6872606837524557
Epoch: 8 | Iteration number: [3190/4518] 70% | Training loss: 0.6872631797783053
Epoch: 8 | Iteration number: [3200/4518] 70% | Training loss: 0.6872612447477877
Epoch: 8 | Iteration number: [3210/4518] 71% | Training loss: 0.6872616046871352
Epoch: 8 | Iteration number: [3220/4518] 71% | Training loss: 0.6872599405531558
Epoch: 8 | Iteration number: [3230/4518] 71% | Training loss: 0.6872567066836284
Epoch: 8 | Iteration number: [3240/4518] 71% | Training loss: 0.6872577215418404
Epoch: 8 | Iteration number: [3250/4518] 71% | Training loss: 0.6872521745425004
Epoch: 8 | Iteration number: [3260/4518] 72% | Training loss: 0.6872490804985257
Epoch: 8 | Iteration number: [3270/4518] 72% | Training loss: 0.6872473971741644
Epoch: 8 | Iteration number: [3280/4518] 72% | Training loss: 0.687247402784301
Epoch: 8 | Iteration number: [3290/4518] 72% | Training loss: 0.6872443678350072
Epoch: 8 | Iteration number: [3300/4518] 73% | Training loss: 0.687244469685988
Epoch: 8 | Iteration number: [3310/4518] 73% | Training loss: 0.6872450778851696
Epoch: 8 | Iteration number: [3320/4518] 73% | Training loss: 0.6872470189469406
Epoch: 8 | Iteration number: [3330/4518] 73% | Training loss: 0.6872504285863927
Epoch: 8 | Iteration number: [3340/4518] 73% | Training loss: 0.6872487833756886
Epoch: 8 | Iteration number: [3350/4518] 74% | Training loss: 0.687252305354645
Epoch: 8 | Iteration number: [3360/4518] 74% | Training loss: 0.6872513057397944
Epoch: 8 | Iteration number: [3370/4518] 74% | Training loss: 0.6872541845375423
Epoch: 8 | Iteration number: [3380/4518] 74% | Training loss: 0.6872542730449924
Epoch: 8 | Iteration number: [3390/4518] 75% | Training loss: 0.6872493333345318
Epoch: 8 | Iteration number: [3400/4518] 75% | Training loss: 0.6872509415885981
Epoch: 8 | Iteration number: [3410/4518] 75% | Training loss: 0.6872515224291782
Epoch: 8 | Iteration number: [3420/4518] 75% | Training loss: 0.6872512158420351
Epoch: 8 | Iteration number: [3430/4518] 75% | Training loss: 0.6872517372880663
Epoch: 8 | Iteration number: [3440/4518] 76% | Training loss: 0.6872543141419112
Epoch: 8 | Iteration number: [3450/4518] 76% | Training loss: 0.6872544997153075
Epoch: 8 | Iteration number: [3460/4518] 76% | Training loss: 0.6872510526221611
Epoch: 8 | Iteration number: [3470/4518] 76% | Training loss: 0.6872490870677772
Epoch: 8 | Iteration number: [3480/4518] 77% | Training loss: 0.6872475642753744
Epoch: 8 | Iteration number: [3490/4518] 77% | Training loss: 0.6872452109625141
Epoch: 8 | Iteration number: [3500/4518] 77% | Training loss: 0.6872430406638554
Epoch: 8 | Iteration number: [3510/4518] 77% | Training loss: 0.6872419537981691
Epoch: 8 | Iteration number: [3520/4518] 77% | Training loss: 0.6872424013912678
Epoch: 8 | Iteration number: [3530/4518] 78% | Training loss: 0.6872429976213418
Epoch: 8 | Iteration number: [3540/4518] 78% | Training loss: 0.6872439339167654
Epoch: 8 | Iteration number: [3550/4518] 78% | Training loss: 0.6872451278021637
Epoch: 8 | Iteration number: [3560/4518] 78% | Training loss: 0.6872458127777228
Epoch: 8 | Iteration number: [3570/4518] 79% | Training loss: 0.6872383167763718
Epoch: 8 | Iteration number: [3580/4518] 79% | Training loss: 0.6872374581391585
Epoch: 8 | Iteration number: [3590/4518] 79% | Training loss: 0.6872376163855901
Epoch: 8 | Iteration number: [3600/4518] 79% | Training loss: 0.68723760937651
Epoch: 8 | Iteration number: [3610/4518] 79% | Training loss: 0.6872369495125028
Epoch: 8 | Iteration number: [3620/4518] 80% | Training loss: 0.6872359983993499
Epoch: 8 | Iteration number: [3630/4518] 80% | Training loss: 0.6872342044164327
Epoch: 8 | Iteration number: [3640/4518] 80% | Training loss: 0.6872359386348462
Epoch: 8 | Iteration number: [3650/4518] 80% | Training loss: 0.687235062971507
Epoch: 8 | Iteration number: [3660/4518] 81% | Training loss: 0.687236792956545
Epoch: 8 | Iteration number: [3670/4518] 81% | Training loss: 0.6872335690730924
Epoch: 8 | Iteration number: [3680/4518] 81% | Training loss: 0.6872352531746678
Epoch: 8 | Iteration number: [3690/4518] 81% | Training loss: 0.6872309257506032
Epoch: 8 | Iteration number: [3700/4518] 81% | Training loss: 0.687228551941949
Epoch: 8 | Iteration number: [3710/4518] 82% | Training loss: 0.687227049976025
Epoch: 8 | Iteration number: [3720/4518] 82% | Training loss: 0.6872244605934749
Epoch: 8 | Iteration number: [3730/4518] 82% | Training loss: 0.6872247044266708
Epoch: 8 | Iteration number: [3740/4518] 82% | Training loss: 0.687224773385308
Epoch: 8 | Iteration number: [3750/4518] 83% | Training loss: 0.6872202192942302
Epoch: 8 | Iteration number: [3760/4518] 83% | Training loss: 0.687224258466604
Epoch: 8 | Iteration number: [3770/4518] 83% | Training loss: 0.6872237677125147
Epoch: 8 | Iteration number: [3780/4518] 83% | Training loss: 0.6872235757333262
Epoch: 8 | Iteration number: [3790/4518] 83% | Training loss: 0.687226530980309
Epoch: 8 | Iteration number: [3800/4518] 84% | Training loss: 0.6872227695898006
Epoch: 8 | Iteration number: [3810/4518] 84% | Training loss: 0.6872215304161933
Epoch: 8 | Iteration number: [3820/4518] 84% | Training loss: 0.6872189486370037
Epoch: 8 | Iteration number: [3830/4518] 84% | Training loss: 0.6872188161465269
Epoch: 8 | Iteration number: [3840/4518] 84% | Training loss: 0.6872196638801445
Epoch: 8 | Iteration number: [3850/4518] 85% | Training loss: 0.6872202675373523
Epoch: 8 | Iteration number: [3860/4518] 85% | Training loss: 0.687221833337774
Epoch: 8 | Iteration number: [3870/4518] 85% | Training loss: 0.6872230661931888
Epoch: 8 | Iteration number: [3880/4518] 85% | Training loss: 0.6872210162355727
Epoch: 8 | Iteration number: [3890/4518] 86% | Training loss: 0.6872216640523896
Epoch: 8 | Iteration number: [3900/4518] 86% | Training loss: 0.6872179768482845
Epoch: 8 | Iteration number: [3910/4518] 86% | Training loss: 0.6872195209688543
Epoch: 8 | Iteration number: [3920/4518] 86% | Training loss: 0.6872184160564627
Epoch: 8 | Iteration number: [3930/4518] 86% | Training loss: 0.6872186285090507
Epoch: 8 | Iteration number: [3940/4518] 87% | Training loss: 0.6872179751620074
Epoch: 8 | Iteration number: [3950/4518] 87% | Training loss: 0.6872180269036112
Epoch: 8 | Iteration number: [3960/4518] 87% | Training loss: 0.6872160802134359
Epoch: 8 | Iteration number: [3970/4518] 87% | Training loss: 0.6872141286618163
Epoch: 8 | Iteration number: [3980/4518] 88% | Training loss: 0.6872121495517653
Epoch: 8 | Iteration number: [3990/4518] 88% | Training loss: 0.6872095737989087
Epoch: 8 | Iteration number: [4000/4518] 88% | Training loss: 0.6872082312852145
Epoch: 8 | Iteration number: [4010/4518] 88% | Training loss: 0.6872062023292456
Epoch: 8 | Iteration number: [4020/4518] 88% | Training loss: 0.6872024183694403
Epoch: 8 | Iteration number: [4030/4518] 89% | Training loss: 0.6872006764926626
Epoch: 8 | Iteration number: [4040/4518] 89% | Training loss: 0.6872036440095098
Epoch: 8 | Iteration number: [4050/4518] 89% | Training loss: 0.6872058723002304
Epoch: 8 | Iteration number: [4060/4518] 89% | Training loss: 0.6872075105829192
Epoch: 8 | Iteration number: [4070/4518] 90% | Training loss: 0.6872059800554552
Epoch: 8 | Iteration number: [4080/4518] 90% | Training loss: 0.6872049263587185
Epoch: 8 | Iteration number: [4090/4518] 90% | Training loss: 0.6872046842843221
Epoch: 8 | Iteration number: [4100/4518] 90% | Training loss: 0.6872045071822841
Epoch: 8 | Iteration number: [4110/4518] 90% | Training loss: 0.6872057673124792
Epoch: 8 | Iteration number: [4120/4518] 91% | Training loss: 0.6872076048868374
Epoch: 8 | Iteration number: [4130/4518] 91% | Training loss: 0.6872050571816886
Epoch: 8 | Iteration number: [4140/4518] 91% | Training loss: 0.6872029507649694
Epoch: 8 | Iteration number: [4150/4518] 91% | Training loss: 0.6872006484112108
Epoch: 8 | Iteration number: [4160/4518] 92% | Training loss: 0.6872016533063008
Epoch: 8 | Iteration number: [4170/4518] 92% | Training loss: 0.6872023829882093
Epoch: 8 | Iteration number: [4180/4518] 92% | Training loss: 0.6872016018229808
Epoch: 8 | Iteration number: [4190/4518] 92% | Training loss: 0.6872018217329193
Epoch: 8 | Iteration number: [4200/4518] 92% | Training loss: 0.6871996199233191
Epoch: 8 | Iteration number: [4210/4518] 93% | Training loss: 0.68720032068726
Epoch: 8 | Iteration number: [4220/4518] 93% | Training loss: 0.6872001577751331
Epoch: 8 | Iteration number: [4230/4518] 93% | Training loss: 0.6872005241700662
Epoch: 8 | Iteration number: [4240/4518] 93% | Training loss: 0.6872015495767009
Epoch: 8 | Iteration number: [4250/4518] 94% | Training loss: 0.6872000048861784
Epoch: 8 | Iteration number: [4260/4518] 94% | Training loss: 0.6872003958118913
Epoch: 8 | Iteration number: [4270/4518] 94% | Training loss: 0.6871996303911232
Epoch: 8 | Iteration number: [4280/4518] 94% | Training loss: 0.6871994313514121
Epoch: 8 | Iteration number: [4290/4518] 94% | Training loss: 0.6871995882971303
Epoch: 8 | Iteration number: [4300/4518] 95% | Training loss: 0.6872011385130328
Epoch: 8 | Iteration number: [4310/4518] 95% | Training loss: 0.6872027469898321
Epoch: 8 | Iteration number: [4320/4518] 95% | Training loss: 0.6872013387166791
Epoch: 8 | Iteration number: [4330/4518] 95% | Training loss: 0.6871954601576367
Epoch: 8 | Iteration number: [4340/4518] 96% | Training loss: 0.6871957521422118
Epoch: 8 | Iteration number: [4350/4518] 96% | Training loss: 0.6871973258599468
Epoch: 8 | Iteration number: [4360/4518] 96% | Training loss: 0.6871976051035278
Epoch: 8 | Iteration number: [4370/4518] 96% | Training loss: 0.6871967276528443
Epoch: 8 | Iteration number: [4380/4518] 96% | Training loss: 0.6871963274941597
Epoch: 8 | Iteration number: [4390/4518] 97% | Training loss: 0.6871957598487446
Epoch: 8 | Iteration number: [4400/4518] 97% | Training loss: 0.6871936996687542
Epoch: 8 | Iteration number: [4410/4518] 97% | Training loss: 0.6871933982620975
Epoch: 8 | Iteration number: [4420/4518] 97% | Training loss: 0.6871924232843235
Epoch: 8 | Iteration number: [4430/4518] 98% | Training loss: 0.6871927998001366
Epoch: 8 | Iteration number: [4440/4518] 98% | Training loss: 0.6871918986106778
Epoch: 8 | Iteration number: [4450/4518] 98% | Training loss: 0.6871937884641497
Epoch: 8 | Iteration number: [4460/4518] 98% | Training loss: 0.6871962700189497
Epoch: 8 | Iteration number: [4470/4518] 98% | Training loss: 0.6871932664573592
Epoch: 8 | Iteration number: [4480/4518] 99% | Training loss: 0.6871937109157443
Epoch: 8 | Iteration number: [4490/4518] 99% | Training loss: 0.6871932604530606
Epoch: 8 | Iteration number: [4500/4518] 99% | Training loss: 0.6871937556399239
Epoch: 8 | Iteration number: [4510/4518] 99% | Training loss: 0.687192820207507

 End of epoch: 8 | Train Loss: 0.68703956084739 | Training Time: 642 

 End of epoch: 8 | Eval Loss: 0.6904159358569554 | Evaluating Time: 17 
Epoch: 9 | Iteration number: [10/4518] 0% | Training loss: 0.7538262903690338
Epoch: 9 | Iteration number: [20/4518] 0% | Training loss: 0.721659642457962
Epoch: 9 | Iteration number: [30/4518] 0% | Training loss: 0.7100088000297546
Epoch: 9 | Iteration number: [40/4518] 0% | Training loss: 0.704473900794983
Epoch: 9 | Iteration number: [50/4518] 1% | Training loss: 0.701074811220169
Epoch: 9 | Iteration number: [60/4518] 1% | Training loss: 0.6990373839934667
Epoch: 9 | Iteration number: [70/4518] 1% | Training loss: 0.6972430390971047
Epoch: 9 | Iteration number: [80/4518] 1% | Training loss: 0.696074653416872
Epoch: 9 | Iteration number: [90/4518] 1% | Training loss: 0.695165772570504
Epoch: 9 | Iteration number: [100/4518] 2% | Training loss: 0.6943968558311462
Epoch: 9 | Iteration number: [110/4518] 2% | Training loss: 0.6937580450014634
Epoch: 9 | Iteration number: [120/4518] 2% | Training loss: 0.6932280942797661
Epoch: 9 | Iteration number: [130/4518] 2% | Training loss: 0.6927862181113317
Epoch: 9 | Iteration number: [140/4518] 3% | Training loss: 0.6922550729342869
Epoch: 9 | Iteration number: [150/4518] 3% | Training loss: 0.6918878694375356
Epoch: 9 | Iteration number: [160/4518] 3% | Training loss: 0.6916135359555483
Epoch: 9 | Iteration number: [170/4518] 3% | Training loss: 0.6913020652883193
Epoch: 9 | Iteration number: [180/4518] 3% | Training loss: 0.6909926818476783
Epoch: 9 | Iteration number: [190/4518] 4% | Training loss: 0.6908142456882879
Epoch: 9 | Iteration number: [200/4518] 4% | Training loss: 0.6905751237273217
Epoch: 9 | Iteration number: [210/4518] 4% | Training loss: 0.6903987015996661
Epoch: 9 | Iteration number: [220/4518] 4% | Training loss: 0.6901931069113991
Epoch: 9 | Iteration number: [230/4518] 5% | Training loss: 0.6900093133034914
Epoch: 9 | Iteration number: [240/4518] 5% | Training loss: 0.6898421759406725
Epoch: 9 | Iteration number: [250/4518] 5% | Training loss: 0.6897256836891175
Epoch: 9 | Iteration number: [260/4518] 5% | Training loss: 0.6896315354567307
Epoch: 9 | Iteration number: [270/4518] 5% | Training loss: 0.6895462078076822
Epoch: 9 | Iteration number: [280/4518] 6% | Training loss: 0.6894679740071297
Epoch: 9 | Iteration number: [290/4518] 6% | Training loss: 0.6894314942688777
Epoch: 9 | Iteration number: [300/4518] 6% | Training loss: 0.6893589760859807
Epoch: 9 | Iteration number: [310/4518] 6% | Training loss: 0.689317080666942
Epoch: 9 | Iteration number: [320/4518] 7% | Training loss: 0.6892597351223231
Epoch: 9 | Iteration number: [330/4518] 7% | Training loss: 0.6891756119150104
Epoch: 9 | Iteration number: [340/4518] 7% | Training loss: 0.6890971215332256
Epoch: 9 | Iteration number: [350/4518] 7% | Training loss: 0.6890344217845372
Epoch: 9 | Iteration number: [360/4518] 7% | Training loss: 0.688984896739324
Epoch: 9 | Iteration number: [370/4518] 8% | Training loss: 0.6889161330622595
Epoch: 9 | Iteration number: [380/4518] 8% | Training loss: 0.6888825574987814
Epoch: 9 | Iteration number: [390/4518] 8% | Training loss: 0.6888255764276553
Epoch: 9 | Iteration number: [400/4518] 8% | Training loss: 0.6888042767345905
Epoch: 9 | Iteration number: [410/4518] 9% | Training loss: 0.6887661846672616
Epoch: 9 | Iteration number: [420/4518] 9% | Training loss: 0.6887416958808898
Epoch: 9 | Iteration number: [430/4518] 9% | Training loss: 0.6886719529018845
Epoch: 9 | Iteration number: [440/4518] 9% | Training loss: 0.6886283909732646
Epoch: 9 | Iteration number: [450/4518] 9% | Training loss: 0.6885875194602542
Epoch: 9 | Iteration number: [460/4518] 10% | Training loss: 0.6885469132143518
Epoch: 9 | Iteration number: [470/4518] 10% | Training loss: 0.6885490558248886
Epoch: 9 | Iteration number: [480/4518] 10% | Training loss: 0.6885180330524842
Epoch: 9 | Iteration number: [490/4518] 10% | Training loss: 0.6885088763674911
Epoch: 9 | Iteration number: [500/4518] 11% | Training loss: 0.6884721038341522
Epoch: 9 | Iteration number: [510/4518] 11% | Training loss: 0.688448100230273
Epoch: 9 | Iteration number: [520/4518] 11% | Training loss: 0.6884251125730001
Epoch: 9 | Iteration number: [530/4518] 11% | Training loss: 0.6883789790126512
Epoch: 9 | Iteration number: [540/4518] 11% | Training loss: 0.6883415144902688
Epoch: 9 | Iteration number: [550/4518] 12% | Training loss: 0.6883138680458069
Epoch: 9 | Iteration number: [560/4518] 12% | Training loss: 0.6882739550301007
Epoch: 9 | Iteration number: [570/4518] 12% | Training loss: 0.688265369649519
Epoch: 9 | Iteration number: [580/4518] 12% | Training loss: 0.6882277068392983
Epoch: 9 | Iteration number: [590/4518] 13% | Training loss: 0.6882127109220473
Epoch: 9 | Iteration number: [600/4518] 13% | Training loss: 0.6881843834122022
Epoch: 9 | Iteration number: [610/4518] 13% | Training loss: 0.6881716130209751
Epoch: 9 | Iteration number: [620/4518] 13% | Training loss: 0.6881557618418047
Epoch: 9 | Iteration number: [630/4518] 13% | Training loss: 0.6881430529412769
Epoch: 9 | Iteration number: [640/4518] 14% | Training loss: 0.6881145064719021
Epoch: 9 | Iteration number: [650/4518] 14% | Training loss: 0.6881042895867274
Epoch: 9 | Iteration number: [660/4518] 14% | Training loss: 0.6880760344592007
Epoch: 9 | Iteration number: [670/4518] 14% | Training loss: 0.6880550842676589
Epoch: 9 | Iteration number: [680/4518] 15% | Training loss: 0.6880286970559288
Epoch: 9 | Iteration number: [690/4518] 15% | Training loss: 0.688008591575899
Epoch: 9 | Iteration number: [700/4518] 15% | Training loss: 0.6879951225008283
Epoch: 9 | Iteration number: [710/4518] 15% | Training loss: 0.6879892353440674
Epoch: 9 | Iteration number: [720/4518] 15% | Training loss: 0.6879721587730778
Epoch: 9 | Iteration number: [730/4518] 16% | Training loss: 0.6879454328589243
Epoch: 9 | Iteration number: [740/4518] 16% | Training loss: 0.6879183242449889
Epoch: 9 | Iteration number: [750/4518] 16% | Training loss: 0.6879168022473653
Epoch: 9 | Iteration number: [760/4518] 16% | Training loss: 0.6878981657718357
Epoch: 9 | Iteration number: [770/4518] 17% | Training loss: 0.6878959279555779
Epoch: 9 | Iteration number: [780/4518] 17% | Training loss: 0.6878947641604986
Epoch: 9 | Iteration number: [790/4518] 17% | Training loss: 0.6878847776334497
Epoch: 9 | Iteration number: [800/4518] 17% | Training loss: 0.687877150401473
Epoch: 9 | Iteration number: [810/4518] 17% | Training loss: 0.68784886745759
Epoch: 9 | Iteration number: [820/4518] 18% | Training loss: 0.6878300963378534
Epoch: 9 | Iteration number: [830/4518] 18% | Training loss: 0.6878112138753913
Epoch: 9 | Iteration number: [840/4518] 18% | Training loss: 0.6878057506822405
Epoch: 9 | Iteration number: [850/4518] 18% | Training loss: 0.6878000856848324
Epoch: 9 | Iteration number: [860/4518] 19% | Training loss: 0.6877866031125535
Epoch: 9 | Iteration number: [870/4518] 19% | Training loss: 0.687770997861336
Epoch: 9 | Iteration number: [880/4518] 19% | Training loss: 0.6877675857056271
Epoch: 9 | Iteration number: [890/4518] 19% | Training loss: 0.6877621639310644
Epoch: 9 | Iteration number: [900/4518] 19% | Training loss: 0.6877590319183138
Epoch: 9 | Iteration number: [910/4518] 20% | Training loss: 0.6877444648480677
Epoch: 9 | Iteration number: [920/4518] 20% | Training loss: 0.6877364457301471
Epoch: 9 | Iteration number: [930/4518] 20% | Training loss: 0.6877354074549932
Epoch: 9 | Iteration number: [940/4518] 20% | Training loss: 0.6877274314139752
Epoch: 9 | Iteration number: [950/4518] 21% | Training loss: 0.6877164249671133
Epoch: 9 | Iteration number: [960/4518] 21% | Training loss: 0.6877095807343722
Epoch: 9 | Iteration number: [970/4518] 21% | Training loss: 0.6877007260764997
Epoch: 9 | Iteration number: [980/4518] 21% | Training loss: 0.6876967450793908
Epoch: 9 | Iteration number: [990/4518] 21% | Training loss: 0.6876925043385438
Epoch: 9 | Iteration number: [1000/4518] 22% | Training loss: 0.6876921031475067
Epoch: 9 | Iteration number: [1010/4518] 22% | Training loss: 0.6876824459227004
Epoch: 9 | Iteration number: [1020/4518] 22% | Training loss: 0.6876843340256635
Epoch: 9 | Iteration number: [1030/4518] 22% | Training loss: 0.6876720010076912
Epoch: 9 | Iteration number: [1040/4518] 23% | Training loss: 0.6876738457725599
Epoch: 9 | Iteration number: [1050/4518] 23% | Training loss: 0.6876643686635153
Epoch: 9 | Iteration number: [1060/4518] 23% | Training loss: 0.687658435499893
Epoch: 9 | Iteration number: [1070/4518] 23% | Training loss: 0.687651576282822
Epoch: 9 | Iteration number: [1080/4518] 23% | Training loss: 0.6876456027781522
Epoch: 9 | Iteration number: [1090/4518] 24% | Training loss: 0.6876351488839596
Epoch: 9 | Iteration number: [1100/4518] 24% | Training loss: 0.6876382169940255
Epoch: 9 | Iteration number: [1110/4518] 24% | Training loss: 0.687630872307597
Epoch: 9 | Iteration number: [1120/4518] 24% | Training loss: 0.6876239587153707
Epoch: 9 | Iteration number: [1130/4518] 25% | Training loss: 0.6876130602528564
Epoch: 9 | Iteration number: [1140/4518] 25% | Training loss: 0.6875999931703534
Epoch: 9 | Iteration number: [1150/4518] 25% | Training loss: 0.6875919481464055
Epoch: 9 | Iteration number: [1160/4518] 25% | Training loss: 0.6875827144446044
Epoch: 9 | Iteration number: [1170/4518] 25% | Training loss: 0.6875833328463073
Epoch: 9 | Iteration number: [1180/4518] 26% | Training loss: 0.687576445735107
Epoch: 9 | Iteration number: [1190/4518] 26% | Training loss: 0.6875688936029162
Epoch: 9 | Iteration number: [1200/4518] 26% | Training loss: 0.6875635333359241
Epoch: 9 | Iteration number: [1210/4518] 26% | Training loss: 0.6875686042564959
Epoch: 9 | Iteration number: [1220/4518] 27% | Training loss: 0.6875610460023411
Epoch: 9 | Iteration number: [1230/4518] 27% | Training loss: 0.6875486357909877
Epoch: 9 | Iteration number: [1240/4518] 27% | Training loss: 0.6875436301673612
Epoch: 9 | Iteration number: [1250/4518] 27% | Training loss: 0.6875406870365143
Epoch: 9 | Iteration number: [1260/4518] 27% | Training loss: 0.6875520305028038
Epoch: 9 | Iteration number: [1270/4518] 28% | Training loss: 0.687551276374051
Epoch: 9 | Iteration number: [1280/4518] 28% | Training loss: 0.6875494912732393
Epoch: 9 | Iteration number: [1290/4518] 28% | Training loss: 0.687536670995313
Epoch: 9 | Iteration number: [1300/4518] 28% | Training loss: 0.6875453773828654
Epoch: 9 | Iteration number: [1310/4518] 28% | Training loss: 0.6875411623306856
Epoch: 9 | Iteration number: [1320/4518] 29% | Training loss: 0.6875462993979454
Epoch: 9 | Iteration number: [1330/4518] 29% | Training loss: 0.6875408523961117
Epoch: 9 | Iteration number: [1340/4518] 29% | Training loss: 0.6875434790084611
Epoch: 9 | Iteration number: [1350/4518] 29% | Training loss: 0.6875375675272059
Epoch: 9 | Iteration number: [1360/4518] 30% | Training loss: 0.6875299951171174
Epoch: 9 | Iteration number: [1370/4518] 30% | Training loss: 0.6875350182943971
Epoch: 9 | Iteration number: [1380/4518] 30% | Training loss: 0.6875228757443635
Epoch: 9 | Iteration number: [1390/4518] 30% | Training loss: 0.6875205661324288
Epoch: 9 | Iteration number: [1400/4518] 30% | Training loss: 0.6875313296488353
Epoch: 9 | Iteration number: [1410/4518] 31% | Training loss: 0.6875263938667081
Epoch: 9 | Iteration number: [1420/4518] 31% | Training loss: 0.687534616908557
Epoch: 9 | Iteration number: [1430/4518] 31% | Training loss: 0.6875351352291508
Epoch: 9 | Iteration number: [1440/4518] 31% | Training loss: 0.6875277362763882
Epoch: 9 | Iteration number: [1450/4518] 32% | Training loss: 0.6875268601549083
Epoch: 9 | Iteration number: [1460/4518] 32% | Training loss: 0.6875184651107005
Epoch: 9 | Iteration number: [1470/4518] 32% | Training loss: 0.6875154028944418
Epoch: 9 | Iteration number: [1480/4518] 32% | Training loss: 0.6875110187643283
Epoch: 9 | Iteration number: [1490/4518] 32% | Training loss: 0.6875083749726315
Epoch: 9 | Iteration number: [1500/4518] 33% | Training loss: 0.6875123487313588
Epoch: 9 | Iteration number: [1510/4518] 33% | Training loss: 0.6875087310936278
Epoch: 9 | Iteration number: [1520/4518] 33% | Training loss: 0.6874996027271999
Epoch: 9 | Iteration number: [1530/4518] 33% | Training loss: 0.6874972870147306
Epoch: 9 | Iteration number: [1540/4518] 34% | Training loss: 0.687494794540591
Epoch: 9 | Iteration number: [1550/4518] 34% | Training loss: 0.6874919540651383
Epoch: 9 | Iteration number: [1560/4518] 34% | Training loss: 0.6874991445969313
Epoch: 9 | Iteration number: [1570/4518] 34% | Training loss: 0.6874920154073436
Epoch: 9 | Iteration number: [1580/4518] 34% | Training loss: 0.6874866663655148
Epoch: 9 | Iteration number: [1590/4518] 35% | Training loss: 0.687491770772814
Epoch: 9 | Iteration number: [1600/4518] 35% | Training loss: 0.6874879353120923
Epoch: 9 | Iteration number: [1610/4518] 35% | Training loss: 0.6874872486413636
Epoch: 9 | Iteration number: [1620/4518] 35% | Training loss: 0.6874834016149427
Epoch: 9 | Iteration number: [1630/4518] 36% | Training loss: 0.6874801310293513
Epoch: 9 | Iteration number: [1640/4518] 36% | Training loss: 0.6874729109973442
Epoch: 9 | Iteration number: [1650/4518] 36% | Training loss: 0.6874684184247797
Epoch: 9 | Iteration number: [1660/4518] 36% | Training loss: 0.6874656714229699
Epoch: 9 | Iteration number: [1670/4518] 36% | Training loss: 0.6874649470437787
Epoch: 9 | Iteration number: [1680/4518] 37% | Training loss: 0.6874457471427463
Epoch: 9 | Iteration number: [1690/4518] 37% | Training loss: 0.687443782838844
Epoch: 9 | Iteration number: [1700/4518] 37% | Training loss: 0.6874426781780579
Epoch: 9 | Iteration number: [1710/4518] 37% | Training loss: 0.6874353974883319
Epoch: 9 | Iteration number: [1720/4518] 38% | Training loss: 0.6874320181649785
Epoch: 9 | Iteration number: [1730/4518] 38% | Training loss: 0.6874231990017643
Epoch: 9 | Iteration number: [1740/4518] 38% | Training loss: 0.687427715871526
Epoch: 9 | Iteration number: [1750/4518] 38% | Training loss: 0.6874362680912017
Epoch: 9 | Iteration number: [1760/4518] 38% | Training loss: 0.6874295037917115
Epoch: 9 | Iteration number: [1770/4518] 39% | Training loss: 0.6874264168874019
Epoch: 9 | Iteration number: [1780/4518] 39% | Training loss: 0.6874225492222925
Epoch: 9 | Iteration number: [1790/4518] 39% | Training loss: 0.687421353769036
Epoch: 9 | Iteration number: [1800/4518] 39% | Training loss: 0.6874232252107726
Epoch: 9 | Iteration number: [1810/4518] 40% | Training loss: 0.6874204975794692
Epoch: 9 | Iteration number: [1820/4518] 40% | Training loss: 0.6874196025041434
Epoch: 9 | Iteration number: [1830/4518] 40% | Training loss: 0.6874130520664278
Epoch: 9 | Iteration number: [1840/4518] 40% | Training loss: 0.6874114392568236
Epoch: 9 | Iteration number: [1850/4518] 40% | Training loss: 0.6874010224277909
Epoch: 9 | Iteration number: [1860/4518] 41% | Training loss: 0.6874021877845128
Epoch: 9 | Iteration number: [1870/4518] 41% | Training loss: 0.6873923637012747
Epoch: 9 | Iteration number: [1880/4518] 41% | Training loss: 0.6873954173732311
Epoch: 9 | Iteration number: [1890/4518] 41% | Training loss: 0.6873874931108384
Epoch: 9 | Iteration number: [1900/4518] 42% | Training loss: 0.6873898112460186
Epoch: 9 | Iteration number: [1910/4518] 42% | Training loss: 0.6873788465692111
Epoch: 9 | Iteration number: [1920/4518] 42% | Training loss: 0.687377162805448
Epoch: 9 | Iteration number: [1930/4518] 42% | Training loss: 0.6873885411363809
Epoch: 9 | Iteration number: [1940/4518] 42% | Training loss: 0.6873851642780697
Epoch: 9 | Iteration number: [1950/4518] 43% | Training loss: 0.6873820627041352
Epoch: 9 | Iteration number: [1960/4518] 43% | Training loss: 0.687377437006454
Epoch: 9 | Iteration number: [1970/4518] 43% | Training loss: 0.6873779268434205
Epoch: 9 | Iteration number: [1980/4518] 43% | Training loss: 0.6873783798530848
Epoch: 9 | Iteration number: [1990/4518] 44% | Training loss: 0.6873704065629586
Epoch: 9 | Iteration number: [2000/4518] 44% | Training loss: 0.6873710035383701
Epoch: 9 | Iteration number: [2010/4518] 44% | Training loss: 0.6873717217006493
Epoch: 9 | Iteration number: [2020/4518] 44% | Training loss: 0.6873747735330374
Epoch: 9 | Iteration number: [2030/4518] 44% | Training loss: 0.687367146708108
Epoch: 9 | Iteration number: [2040/4518] 45% | Training loss: 0.6873708886550922
Epoch: 9 | Iteration number: [2050/4518] 45% | Training loss: 0.6873732308062112
Epoch: 9 | Iteration number: [2060/4518] 45% | Training loss: 0.6873741060495376
Epoch: 9 | Iteration number: [2070/4518] 45% | Training loss: 0.6873786926269532
Epoch: 9 | Iteration number: [2080/4518] 46% | Training loss: 0.6873720547614189
Epoch: 9 | Iteration number: [2090/4518] 46% | Training loss: 0.6873685040257194
Epoch: 9 | Iteration number: [2100/4518] 46% | Training loss: 0.687369824222156
Epoch: 9 | Iteration number: [2110/4518] 46% | Training loss: 0.6873674328575767
Epoch: 9 | Iteration number: [2120/4518] 46% | Training loss: 0.6873709778740721
Epoch: 9 | Iteration number: [2130/4518] 47% | Training loss: 0.6873682029090576
Epoch: 9 | Iteration number: [2140/4518] 47% | Training loss: 0.6873659758645797
Epoch: 9 | Iteration number: [2150/4518] 47% | Training loss: 0.6873646750006565
Epoch: 9 | Iteration number: [2160/4518] 47% | Training loss: 0.6873616557706286
Epoch: 9 | Iteration number: [2170/4518] 48% | Training loss: 0.6873585249147107
Epoch: 9 | Iteration number: [2180/4518] 48% | Training loss: 0.6873626441583721
Epoch: 9 | Iteration number: [2190/4518] 48% | Training loss: 0.6873623025743929
Epoch: 9 | Iteration number: [2200/4518] 48% | Training loss: 0.6873599343679168
Epoch: 9 | Iteration number: [2210/4518] 48% | Training loss: 0.6873567499456362
Epoch: 9 | Iteration number: [2220/4518] 49% | Training loss: 0.6873557313068493
Epoch: 9 | Iteration number: [2230/4518] 49% | Training loss: 0.687350421048066
Epoch: 9 | Iteration number: [2240/4518] 49% | Training loss: 0.687344826411988
Epoch: 9 | Iteration number: [2250/4518] 49% | Training loss: 0.6873419693046146
Epoch: 9 | Iteration number: [2260/4518] 50% | Training loss: 0.6873374557336874
Epoch: 9 | Iteration number: [2270/4518] 50% | Training loss: 0.6873339164624656
Epoch: 9 | Iteration number: [2280/4518] 50% | Training loss: 0.6873354054333871
Epoch: 9 | Iteration number: [2290/4518] 50% | Training loss: 0.6873305977431968
Epoch: 9 | Iteration number: [2300/4518] 50% | Training loss: 0.6873271202522775
Epoch: 9 | Iteration number: [2310/4518] 51% | Training loss: 0.6873284368804007
Epoch: 9 | Iteration number: [2320/4518] 51% | Training loss: 0.6873255919279724
Epoch: 9 | Iteration number: [2330/4518] 51% | Training loss: 0.6873235914584394
Epoch: 9 | Iteration number: [2340/4518] 51% | Training loss: 0.6873236898937796
Epoch: 9 | Iteration number: [2350/4518] 52% | Training loss: 0.6873207788771771
Epoch: 9 | Iteration number: [2360/4518] 52% | Training loss: 0.6873195929294925
Epoch: 9 | Iteration number: [2370/4518] 52% | Training loss: 0.6873218641753941
Epoch: 9 | Iteration number: [2380/4518] 52% | Training loss: 0.6873246695815014
Epoch: 9 | Iteration number: [2390/4518] 52% | Training loss: 0.687321159630141
Epoch: 9 | Iteration number: [2400/4518] 53% | Training loss: 0.6873193759967884
Epoch: 9 | Iteration number: [2410/4518] 53% | Training loss: 0.6873145092077769
Epoch: 9 | Iteration number: [2420/4518] 53% | Training loss: 0.68730869448382
Epoch: 9 | Iteration number: [2430/4518] 53% | Training loss: 0.6873029492274233
Epoch: 9 | Iteration number: [2440/4518] 54% | Training loss: 0.6873044074070258
Epoch: 9 | Iteration number: [2450/4518] 54% | Training loss: 0.6872990603349647
Epoch: 9 | Iteration number: [2460/4518] 54% | Training loss: 0.6872952175818807
Epoch: 9 | Iteration number: [2470/4518] 54% | Training loss: 0.6872922630927824
Epoch: 9 | Iteration number: [2480/4518] 54% | Training loss: 0.6872952347801577
Epoch: 9 | Iteration number: [2490/4518] 55% | Training loss: 0.6873007655383114
Epoch: 9 | Iteration number: [2500/4518] 55% | Training loss: 0.6872965796709061
Epoch: 9 | Iteration number: [2510/4518] 55% | Training loss: 0.6873039474762769
Epoch: 9 | Iteration number: [2520/4518] 55% | Training loss: 0.687292446337995
Epoch: 9 | Iteration number: [2530/4518] 55% | Training loss: 0.6872916985406234
Epoch: 9 | Iteration number: [2540/4518] 56% | Training loss: 0.6872933906129026
Epoch: 9 | Iteration number: [2550/4518] 56% | Training loss: 0.687298749848908
Epoch: 9 | Iteration number: [2560/4518] 56% | Training loss: 0.6872998608741909
Epoch: 9 | Iteration number: [2570/4518] 56% | Training loss: 0.6872997588684586
Epoch: 9 | Iteration number: [2580/4518] 57% | Training loss: 0.6872994682354521
Epoch: 9 | Iteration number: [2590/4518] 57% | Training loss: 0.6872991508958883
Epoch: 9 | Iteration number: [2600/4518] 57% | Training loss: 0.6872977705643727
Epoch: 9 | Iteration number: [2610/4518] 57% | Training loss: 0.6873000866608602
Epoch: 9 | Iteration number: [2620/4518] 57% | Training loss: 0.6872996386680894
Epoch: 9 | Iteration number: [2630/4518] 58% | Training loss: 0.687301672479499
Epoch: 9 | Iteration number: [2640/4518] 58% | Training loss: 0.6872988927319195
Epoch: 9 | Iteration number: [2650/4518] 58% | Training loss: 0.6872980314380718
Epoch: 9 | Iteration number: [2660/4518] 58% | Training loss: 0.6872989975196079
Epoch: 9 | Iteration number: [2670/4518] 59% | Training loss: 0.6872993398471718
Epoch: 9 | Iteration number: [2680/4518] 59% | Training loss: 0.687294133074248
Epoch: 9 | Iteration number: [2690/4518] 59% | Training loss: 0.6872969725096536
Epoch: 9 | Iteration number: [2700/4518] 59% | Training loss: 0.6872974434826109
Epoch: 9 | Iteration number: [2710/4518] 59% | Training loss: 0.6872965683356422
Epoch: 9 | Iteration number: [2720/4518] 60% | Training loss: 0.6872980199315969
Epoch: 9 | Iteration number: [2730/4518] 60% | Training loss: 0.687298456565801
Epoch: 9 | Iteration number: [2740/4518] 60% | Training loss: 0.6872988980399432
Epoch: 9 | Iteration number: [2750/4518] 60% | Training loss: 0.6873001565499739
Epoch: 9 | Iteration number: [2760/4518] 61% | Training loss: 0.6872968422761861
Epoch: 9 | Iteration number: [2770/4518] 61% | Training loss: 0.687295074023925
Epoch: 9 | Iteration number: [2780/4518] 61% | Training loss: 0.687290966189165
Epoch: 9 | Iteration number: [2790/4518] 61% | Training loss: 0.687291914459625
Epoch: 9 | Iteration number: [2800/4518] 61% | Training loss: 0.6872942907895361
Epoch: 9 | Iteration number: [2810/4518] 62% | Training loss: 0.6872906279733597
Epoch: 9 | Iteration number: [2820/4518] 62% | Training loss: 0.6872891758773344
Epoch: 9 | Iteration number: [2830/4518] 62% | Training loss: 0.6872857333072083
Epoch: 9 | Iteration number: [2840/4518] 62% | Training loss: 0.6872879064838652
Epoch: 9 | Iteration number: [2850/4518] 63% | Training loss: 0.6872901732252356
Epoch: 9 | Iteration number: [2860/4518] 63% | Training loss: 0.6872886005189869
Epoch: 9 | Iteration number: [2870/4518] 63% | Training loss: 0.6872886224490841
Epoch: 9 | Iteration number: [2880/4518] 63% | Training loss: 0.6872877634647819
Epoch: 9 | Iteration number: [2890/4518] 63% | Training loss: 0.6872895829405339
Epoch: 9 | Iteration number: [2900/4518] 64% | Training loss: 0.6872881709501661
Epoch: 9 | Iteration number: [2910/4518] 64% | Training loss: 0.6872884994110291
Epoch: 9 | Iteration number: [2920/4518] 64% | Training loss: 0.6872899240418656
Epoch: 9 | Iteration number: [2930/4518] 64% | Training loss: 0.6872890408535459
Epoch: 9 | Iteration number: [2940/4518] 65% | Training loss: 0.6872875217880522
Epoch: 9 | Iteration number: [2950/4518] 65% | Training loss: 0.6872871353060512
Epoch: 9 | Iteration number: [2960/4518] 65% | Training loss: 0.6872871214674937
Epoch: 9 | Iteration number: [2970/4518] 65% | Training loss: 0.6872840754712872
Epoch: 9 | Iteration number: [2980/4518] 65% | Training loss: 0.6872837706700268
Epoch: 9 | Iteration number: [2990/4518] 66% | Training loss: 0.6872826872661361
Epoch: 9 | Iteration number: [3000/4518] 66% | Training loss: 0.6872758297522863
Epoch: 9 | Iteration number: [3010/4518] 66% | Training loss: 0.6872723804953882
Epoch: 9 | Iteration number: [3020/4518] 66% | Training loss: 0.687269139447749
Epoch: 9 | Iteration number: [3030/4518] 67% | Training loss: 0.6872659837648813
Epoch: 9 | Iteration number: [3040/4518] 67% | Training loss: 0.6872692900660791
Epoch: 9 | Iteration number: [3050/4518] 67% | Training loss: 0.6872699194853423
Epoch: 9 | Iteration number: [3060/4518] 67% | Training loss: 0.6872680591017593
Epoch: 9 | Iteration number: [3070/4518] 67% | Training loss: 0.6872684011436052
Epoch: 9 | Iteration number: [3080/4518] 68% | Training loss: 0.6872662606757957
Epoch: 9 | Iteration number: [3090/4518] 68% | Training loss: 0.6872634175140109
Epoch: 9 | Iteration number: [3100/4518] 68% | Training loss: 0.6872595962016813
Epoch: 9 | Iteration number: [3110/4518] 68% | Training loss: 0.6872530055199405
Epoch: 9 | Iteration number: [3120/4518] 69% | Training loss: 0.6872573859416522
Epoch: 9 | Iteration number: [3130/4518] 69% | Training loss: 0.6872551973444966
Epoch: 9 | Iteration number: [3140/4518] 69% | Training loss: 0.6872536395195943
Epoch: 9 | Iteration number: [3150/4518] 69% | Training loss: 0.6872528876955547
Epoch: 9 | Iteration number: [3160/4518] 69% | Training loss: 0.6872486546447005
Epoch: 9 | Iteration number: [3170/4518] 70% | Training loss: 0.6872483300485821
Epoch: 9 | Iteration number: [3180/4518] 70% | Training loss: 0.6872445267888735
Epoch: 9 | Iteration number: [3190/4518] 70% | Training loss: 0.687243952945482
Epoch: 9 | Iteration number: [3200/4518] 70% | Training loss: 0.6872408407367766
Epoch: 9 | Iteration number: [3210/4518] 71% | Training loss: 0.6872437530960249
Epoch: 9 | Iteration number: [3220/4518] 71% | Training loss: 0.6872493102683784
Epoch: 9 | Iteration number: [3230/4518] 71% | Training loss: 0.6872525290992607
Epoch: 9 | Iteration number: [3240/4518] 71% | Training loss: 0.6872527437997453
Epoch: 9 | Iteration number: [3250/4518] 71% | Training loss: 0.6872505404215593
Epoch: 9 | Iteration number: [3260/4518] 72% | Training loss: 0.6872533558336503
Epoch: 9 | Iteration number: [3270/4518] 72% | Training loss: 0.6872540602261138
Epoch: 9 | Iteration number: [3280/4518] 72% | Training loss: 0.687252224872752
Epoch: 9 | Iteration number: [3290/4518] 72% | Training loss: 0.6872546254320347
Epoch: 9 | Iteration number: [3300/4518] 73% | Training loss: 0.6872569712003073
Epoch: 9 | Iteration number: [3310/4518] 73% | Training loss: 0.6872550779959227
Epoch: 9 | Iteration number: [3320/4518] 73% | Training loss: 0.6872573092400309
Epoch: 9 | Iteration number: [3330/4518] 73% | Training loss: 0.6872552174347657
Epoch: 9 | Iteration number: [3340/4518] 73% | Training loss: 0.6872533173082831
Epoch: 9 | Iteration number: [3350/4518] 74% | Training loss: 0.6872537246390955
Epoch: 9 | Iteration number: [3360/4518] 74% | Training loss: 0.6872569385206415
Epoch: 9 | Iteration number: [3370/4518] 74% | Training loss: 0.6872578235868176
Epoch: 9 | Iteration number: [3380/4518] 74% | Training loss: 0.6872542750024231
Epoch: 9 | Iteration number: [3390/4518] 75% | Training loss: 0.6872545973213725
Epoch: 9 | Iteration number: [3400/4518] 75% | Training loss: 0.6872529873076607
Epoch: 9 | Iteration number: [3410/4518] 75% | Training loss: 0.6872473970536263
Epoch: 9 | Iteration number: [3420/4518] 75% | Training loss: 0.6872457783996013
Epoch: 9 | Iteration number: [3430/4518] 75% | Training loss: 0.6872449752714475
Epoch: 9 | Iteration number: [3440/4518] 76% | Training loss: 0.6872451918416245
Epoch: 9 | Iteration number: [3450/4518] 76% | Training loss: 0.6872451433582583
Epoch: 9 | Iteration number: [3460/4518] 76% | Training loss: 0.687241319063082
Epoch: 9 | Iteration number: [3470/4518] 76% | Training loss: 0.6872398560431917
Epoch: 9 | Iteration number: [3480/4518] 77% | Training loss: 0.6872371348498881
Epoch: 9 | Iteration number: [3490/4518] 77% | Training loss: 0.6872399262678316
Epoch: 9 | Iteration number: [3500/4518] 77% | Training loss: 0.6872378660270146
Epoch: 9 | Iteration number: [3510/4518] 77% | Training loss: 0.6872354102779997
Epoch: 9 | Iteration number: [3520/4518] 77% | Training loss: 0.6872368059036407
Epoch: 9 | Iteration number: [3530/4518] 78% | Training loss: 0.6872333612219133
Epoch: 9 | Iteration number: [3540/4518] 78% | Training loss: 0.6872330941217767
Epoch: 9 | Iteration number: [3550/4518] 78% | Training loss: 0.6872321704072012
Epoch: 9 | Iteration number: [3560/4518] 78% | Training loss: 0.6872281599078286
Epoch: 9 | Iteration number: [3570/4518] 79% | Training loss: 0.6872274821378938
Epoch: 9 | Iteration number: [3580/4518] 79% | Training loss: 0.6872239363593097
Epoch: 9 | Iteration number: [3590/4518] 79% | Training loss: 0.6872253554611153
Epoch: 9 | Iteration number: [3600/4518] 79% | Training loss: 0.6872212293909655
Epoch: 9 | Iteration number: [3610/4518] 79% | Training loss: 0.687222997716259
Epoch: 9 | Iteration number: [3620/4518] 80% | Training loss: 0.6872274249133484
Epoch: 9 | Iteration number: [3630/4518] 80% | Training loss: 0.6872268798265904
Epoch: 9 | Iteration number: [3640/4518] 80% | Training loss: 0.6872227284934495
Epoch: 9 | Iteration number: [3650/4518] 80% | Training loss: 0.6872239819944721
Epoch: 9 | Iteration number: [3660/4518] 81% | Training loss: 0.6872255003191734
Epoch: 9 | Iteration number: [3670/4518] 81% | Training loss: 0.6872257362107165
Epoch: 9 | Iteration number: [3680/4518] 81% | Training loss: 0.6872231893241405
Epoch: 9 | Iteration number: [3690/4518] 81% | Training loss: 0.6872221515915258
Epoch: 9 | Iteration number: [3700/4518] 81% | Training loss: 0.687217838957503
Epoch: 9 | Iteration number: [3710/4518] 82% | Training loss: 0.6872192195644276
Epoch: 9 | Iteration number: [3720/4518] 82% | Training loss: 0.6872173381428565
Epoch: 9 | Iteration number: [3730/4518] 82% | Training loss: 0.6872164877745804
Epoch: 9 | Iteration number: [3740/4518] 82% | Training loss: 0.687214796555871
Epoch: 9 | Iteration number: [3750/4518] 83% | Training loss: 0.6872153253237406
Epoch: 9 | Iteration number: [3760/4518] 83% | Training loss: 0.6872149105401749
Epoch: 9 | Iteration number: [3770/4518] 83% | Training loss: 0.6872132174216151
Epoch: 9 | Iteration number: [3780/4518] 83% | Training loss: 0.687212652551434
Epoch: 9 | Iteration number: [3790/4518] 83% | Training loss: 0.6872136715376912
Epoch: 9 | Iteration number: [3800/4518] 84% | Training loss: 0.6872146748712188
Epoch: 9 | Iteration number: [3810/4518] 84% | Training loss: 0.6872144897622386
Epoch: 9 | Iteration number: [3820/4518] 84% | Training loss: 0.6872114492492526
Epoch: 9 | Iteration number: [3830/4518] 84% | Training loss: 0.6872077787980709
Epoch: 9 | Iteration number: [3840/4518] 84% | Training loss: 0.6872064027469605
Epoch: 9 | Iteration number: [3850/4518] 85% | Training loss: 0.6872061325667741
Epoch: 9 | Iteration number: [3860/4518] 85% | Training loss: 0.6872059608216112
Epoch: 9 | Iteration number: [3870/4518] 85% | Training loss: 0.68720135206708
Epoch: 9 | Iteration number: [3880/4518] 85% | Training loss: 0.6871986043975525
Epoch: 9 | Iteration number: [3890/4518] 86% | Training loss: 0.6871999332868042
Epoch: 9 | Iteration number: [3900/4518] 86% | Training loss: 0.6871972466126467
Epoch: 9 | Iteration number: [3910/4518] 86% | Training loss: 0.6871961887230349
Epoch: 9 | Iteration number: [3920/4518] 86% | Training loss: 0.6871956597481456
Epoch: 9 | Iteration number: [3930/4518] 86% | Training loss: 0.687195781093214
Epoch: 9 | Iteration number: [3940/4518] 87% | Training loss: 0.6871940709310135
Epoch: 9 | Iteration number: [3950/4518] 87% | Training loss: 0.6871918930886667
Epoch: 9 | Iteration number: [3960/4518] 87% | Training loss: 0.6871893929110633
Epoch: 9 | Iteration number: [3970/4518] 87% | Training loss: 0.6871876580288788
Epoch: 9 | Iteration number: [3980/4518] 88% | Training loss: 0.6871895933870095
Epoch: 9 | Iteration number: [3990/4518] 88% | Training loss: 0.6871870792748636
Epoch: 9 | Iteration number: [4000/4518] 88% | Training loss: 0.6871866579353809
Epoch: 9 | Iteration number: [4010/4518] 88% | Training loss: 0.6871879256722933
Epoch: 9 | Iteration number: [4020/4518] 88% | Training loss: 0.6871865443329312
Epoch: 9 | Iteration number: [4030/4518] 89% | Training loss: 0.6871865035434515
Epoch: 9 | Iteration number: [4040/4518] 89% | Training loss: 0.6871869618054663
Epoch: 9 | Iteration number: [4050/4518] 89% | Training loss: 0.6871855145619239
Epoch: 9 | Iteration number: [4060/4518] 89% | Training loss: 0.6871867788542667
Epoch: 9 | Iteration number: [4070/4518] 90% | Training loss: 0.6871865458218999
Epoch: 9 | Iteration number: [4080/4518] 90% | Training loss: 0.6871861142562885
Epoch: 9 | Iteration number: [4090/4518] 90% | Training loss: 0.6871839633926494
Epoch: 9 | Iteration number: [4100/4518] 90% | Training loss: 0.6871807821204022
Epoch: 9 | Iteration number: [4110/4518] 90% | Training loss: 0.6871795262733515
Epoch: 9 | Iteration number: [4120/4518] 91% | Training loss: 0.6871767855674318
Epoch: 9 | Iteration number: [4130/4518] 91% | Training loss: 0.6871738384335728
Epoch: 9 | Iteration number: [4140/4518] 91% | Training loss: 0.6871750872780159
Epoch: 9 | Iteration number: [4150/4518] 91% | Training loss: 0.6871775962933
Epoch: 9 | Iteration number: [4160/4518] 92% | Training loss: 0.6871761774357695
Epoch: 9 | Iteration number: [4170/4518] 92% | Training loss: 0.6871752259685553
Epoch: 9 | Iteration number: [4180/4518] 92% | Training loss: 0.6871767816931437
Epoch: 9 | Iteration number: [4190/4518] 92% | Training loss: 0.6871811603447133
Epoch: 9 | Iteration number: [4200/4518] 92% | Training loss: 0.6871832114032337
Epoch: 9 | Iteration number: [4210/4518] 93% | Training loss: 0.6871844242700772
Epoch: 9 | Iteration number: [4220/4518] 93% | Training loss: 0.6871848806103259
Epoch: 9 | Iteration number: [4230/4518] 93% | Training loss: 0.6871839631392882
Epoch: 9 | Iteration number: [4240/4518] 93% | Training loss: 0.6871868159832819
Epoch: 9 | Iteration number: [4250/4518] 94% | Training loss: 0.6871877003136803
Epoch: 9 | Iteration number: [4260/4518] 94% | Training loss: 0.6871872770394518
Epoch: 9 | Iteration number: [4270/4518] 94% | Training loss: 0.6871875522845802
Epoch: 9 | Iteration number: [4280/4518] 94% | Training loss: 0.6871852225232347
Epoch: 9 | Iteration number: [4290/4518] 94% | Training loss: 0.6871855468183131
Epoch: 9 | Iteration number: [4300/4518] 95% | Training loss: 0.6871859027064123
Epoch: 9 | Iteration number: [4310/4518] 95% | Training loss: 0.6871858616716071
Epoch: 9 | Iteration number: [4320/4518] 95% | Training loss: 0.6871828418914918
Epoch: 9 | Iteration number: [4330/4518] 95% | Training loss: 0.687185155519437
Epoch: 9 | Iteration number: [4340/4518] 96% | Training loss: 0.6871842835218676
Epoch: 9 | Iteration number: [4350/4518] 96% | Training loss: 0.6871820746619126
Epoch: 9 | Iteration number: [4360/4518] 96% | Training loss: 0.6871834287402827
Epoch: 9 | Iteration number: [4370/4518] 96% | Training loss: 0.6871840992563104
Epoch: 9 | Iteration number: [4380/4518] 96% | Training loss: 0.6871844051499345
Epoch: 9 | Iteration number: [4390/4518] 97% | Training loss: 0.6871802362195452
Epoch: 9 | Iteration number: [4400/4518] 97% | Training loss: 0.6871774827756665
Epoch: 9 | Iteration number: [4410/4518] 97% | Training loss: 0.6871759928678439
Epoch: 9 | Iteration number: [4420/4518] 97% | Training loss: 0.6871764307782661
Epoch: 9 | Iteration number: [4430/4518] 98% | Training loss: 0.6871764329297817
Epoch: 9 | Iteration number: [4440/4518] 98% | Training loss: 0.6871748207925676
Epoch: 9 | Iteration number: [4450/4518] 98% | Training loss: 0.6871757065580132
Epoch: 9 | Iteration number: [4460/4518] 98% | Training loss: 0.687176001125387
Epoch: 9 | Iteration number: [4470/4518] 98% | Training loss: 0.6871754063589194
Epoch: 9 | Iteration number: [4480/4518] 99% | Training loss: 0.6871723096950778
Epoch: 9 | Iteration number: [4490/4518] 99% | Training loss: 0.6871718663415293
Epoch: 9 | Iteration number: [4500/4518] 99% | Training loss: 0.6871714891327751
Epoch: 9 | Iteration number: [4510/4518] 99% | Training loss: 0.6871709229412206

 End of epoch: 9 | Train Loss: 0.6870170807537647 | Training Time: 641 

 End of epoch: 9 | Eval Loss: 0.6904283336230687 | Evaluating Time: 17 
Epoch: 10 | Iteration number: [10/4518] 0% | Training loss: 0.7547625124454498
Epoch: 10 | Iteration number: [20/4518] 0% | Training loss: 0.721554833650589
Epoch: 10 | Iteration number: [30/4518] 0% | Training loss: 0.7100789805253347
Epoch: 10 | Iteration number: [40/4518] 0% | Training loss: 0.7042290002107621
Epoch: 10 | Iteration number: [50/4518] 1% | Training loss: 0.7007774972915649
Epoch: 10 | Iteration number: [60/4518] 1% | Training loss: 0.6984381715456645
Epoch: 10 | Iteration number: [70/4518] 1% | Training loss: 0.6967859310763223
Epoch: 10 | Iteration number: [80/4518] 1% | Training loss: 0.6956153362989426
Epoch: 10 | Iteration number: [90/4518] 1% | Training loss: 0.6947679943508572
Epoch: 10 | Iteration number: [100/4518] 2% | Training loss: 0.6939820581674576
Epoch: 10 | Iteration number: [110/4518] 2% | Training loss: 0.6933453711596402
Epoch: 10 | Iteration number: [120/4518] 2% | Training loss: 0.6928193499644597
Epoch: 10 | Iteration number: [130/4518] 2% | Training loss: 0.6924296943040994
Epoch: 10 | Iteration number: [140/4518] 3% | Training loss: 0.6920744470187596
Epoch: 10 | Iteration number: [150/4518] 3% | Training loss: 0.6917034276326497
Epoch: 10 | Iteration number: [160/4518] 3% | Training loss: 0.6914112608879804
Epoch: 10 | Iteration number: [170/4518] 3% | Training loss: 0.69113289994352
Epoch: 10 | Iteration number: [180/4518] 3% | Training loss: 0.6908583084742228
Epoch: 10 | Iteration number: [190/4518] 4% | Training loss: 0.6906908113705484
Epoch: 10 | Iteration number: [200/4518] 4% | Training loss: 0.6905088505148888
Epoch: 10 | Iteration number: [210/4518] 4% | Training loss: 0.6903055347147442
Epoch: 10 | Iteration number: [220/4518] 4% | Training loss: 0.6901872675527226
Epoch: 10 | Iteration number: [230/4518] 5% | Training loss: 0.6899770959563877
Epoch: 10 | Iteration number: [240/4518] 5% | Training loss: 0.6898147488633791
Epoch: 10 | Iteration number: [250/4518] 5% | Training loss: 0.6897115709781647
Epoch: 10 | Iteration number: [260/4518] 5% | Training loss: 0.6895847205932324
Epoch: 10 | Iteration number: [270/4518] 5% | Training loss: 0.6895008071705148
Epoch: 10 | Iteration number: [280/4518] 6% | Training loss: 0.6893983583365167
Epoch: 10 | Iteration number: [290/4518] 6% | Training loss: 0.6892918553845636
Epoch: 10 | Iteration number: [300/4518] 6% | Training loss: 0.6892656522989273
Epoch: 10 | Iteration number: [310/4518] 6% | Training loss: 0.6892411649227143
Epoch: 10 | Iteration number: [320/4518] 7% | Training loss: 0.6891964113339781
Epoch: 10 | Iteration number: [330/4518] 7% | Training loss: 0.6891157726446787
Epoch: 10 | Iteration number: [340/4518] 7% | Training loss: 0.689055932970608
Epoch: 10 | Iteration number: [350/4518] 7% | Training loss: 0.688936288356781
Epoch: 10 | Iteration number: [360/4518] 7% | Training loss: 0.6889071984423532
Epoch: 10 | Iteration number: [370/4518] 8% | Training loss: 0.6888212545497997
Epoch: 10 | Iteration number: [380/4518] 8% | Training loss: 0.6887140360317732
Epoch: 10 | Iteration number: [390/4518] 8% | Training loss: 0.6886877292241805
Epoch: 10 | Iteration number: [400/4518] 8% | Training loss: 0.688631865978241
Epoch: 10 | Iteration number: [410/4518] 9% | Training loss: 0.68857554836971
Epoch: 10 | Iteration number: [420/4518] 9% | Training loss: 0.6885507216056188
Epoch: 10 | Iteration number: [430/4518] 9% | Training loss: 0.6885032170040662
Epoch: 10 | Iteration number: [440/4518] 9% | Training loss: 0.6884841385212812
Epoch: 10 | Iteration number: [450/4518] 9% | Training loss: 0.6884573582808177
Epoch: 10 | Iteration number: [460/4518] 10% | Training loss: 0.6884110400210256
Epoch: 10 | Iteration number: [470/4518] 10% | Training loss: 0.6883872957939797
Epoch: 10 | Iteration number: [480/4518] 10% | Training loss: 0.6883678000420332
Epoch: 10 | Iteration number: [490/4518] 10% | Training loss: 0.6883399509653754
Epoch: 10 | Iteration number: [500/4518] 11% | Training loss: 0.688346363902092
Epoch: 10 | Iteration number: [510/4518] 11% | Training loss: 0.6882934286313899
Epoch: 10 | Iteration number: [520/4518] 11% | Training loss: 0.6882727259626755
Epoch: 10 | Iteration number: [530/4518] 11% | Training loss: 0.6882565136225718
Epoch: 10 | Iteration number: [540/4518] 11% | Training loss: 0.6882399940932239
Epoch: 10 | Iteration number: [550/4518] 12% | Training loss: 0.688202609907497
Epoch: 10 | Iteration number: [560/4518] 12% | Training loss: 0.6881821582359927
Epoch: 10 | Iteration number: [570/4518] 12% | Training loss: 0.6881609572653185
Epoch: 10 | Iteration number: [580/4518] 12% | Training loss: 0.6881468090517767
Epoch: 10 | Iteration number: [590/4518] 13% | Training loss: 0.6881403714923535
Epoch: 10 | Iteration number: [600/4518] 13% | Training loss: 0.6881302234530449
Epoch: 10 | Iteration number: [610/4518] 13% | Training loss: 0.6881352287824036
Epoch: 10 | Iteration number: [620/4518] 13% | Training loss: 0.6881117396777676
Epoch: 10 | Iteration number: [630/4518] 13% | Training loss: 0.688107478807843
Epoch: 10 | Iteration number: [640/4518] 14% | Training loss: 0.6881000132299959
Epoch: 10 | Iteration number: [650/4518] 14% | Training loss: 0.6880879964278295
Epoch: 10 | Iteration number: [660/4518] 14% | Training loss: 0.6880685718673648
Epoch: 10 | Iteration number: [670/4518] 14% | Training loss: 0.688046195524842
Epoch: 10 | Iteration number: [680/4518] 15% | Training loss: 0.6880358983488644
Epoch: 10 | Iteration number: [690/4518] 15% | Training loss: 0.6880104668762372
Epoch: 10 | Iteration number: [700/4518] 15% | Training loss: 0.6880122770581927
Epoch: 10 | Iteration number: [710/4518] 15% | Training loss: 0.6879986920826872
Epoch: 10 | Iteration number: [720/4518] 15% | Training loss: 0.687958176765177
Epoch: 10 | Iteration number: [730/4518] 16% | Training loss: 0.6879471664559351
Epoch: 10 | Iteration number: [740/4518] 16% | Training loss: 0.6879455932894268
Epoch: 10 | Iteration number: [750/4518] 16% | Training loss: 0.6879250762462616
Epoch: 10 | Iteration number: [760/4518] 16% | Training loss: 0.6878945078504713
Epoch: 10 | Iteration number: [770/4518] 17% | Training loss: 0.6878657977302353
Epoch: 10 | Iteration number: [780/4518] 17% | Training loss: 0.6878483805136802
Epoch: 10 | Iteration number: [790/4518] 17% | Training loss: 0.6878230135652084
Epoch: 10 | Iteration number: [800/4518] 17% | Training loss: 0.6878345653414726
Epoch: 10 | Iteration number: [810/4518] 17% | Training loss: 0.6878377583291796
Epoch: 10 | Iteration number: [820/4518] 18% | Training loss: 0.6878139780788887
Epoch: 10 | Iteration number: [830/4518] 18% | Training loss: 0.6877943366406912
Epoch: 10 | Iteration number: [840/4518] 18% | Training loss: 0.6877882224463281
Epoch: 10 | Iteration number: [850/4518] 18% | Training loss: 0.6877825333791621
Epoch: 10 | Iteration number: [860/4518] 19% | Training loss: 0.6877793190091155
Epoch: 10 | Iteration number: [870/4518] 19% | Training loss: 0.6877599899111123
Epoch: 10 | Iteration number: [880/4518] 19% | Training loss: 0.6877499637278643
Epoch: 10 | Iteration number: [890/4518] 19% | Training loss: 0.6877321885542923
Epoch: 10 | Iteration number: [900/4518] 19% | Training loss: 0.6877276051044464
Epoch: 10 | Iteration number: [910/4518] 20% | Training loss: 0.6877241300357567
Epoch: 10 | Iteration number: [920/4518] 20% | Training loss: 0.6877089011928309
Epoch: 10 | Iteration number: [930/4518] 20% | Training loss: 0.6876869448410567
Epoch: 10 | Iteration number: [940/4518] 20% | Training loss: 0.687685496756371
Epoch: 10 | Iteration number: [950/4518] 21% | Training loss: 0.6876728635712673
Epoch: 10 | Iteration number: [960/4518] 21% | Training loss: 0.6876733691742023
Epoch: 10 | Iteration number: [970/4518] 21% | Training loss: 0.6876544829496404
Epoch: 10 | Iteration number: [980/4518] 21% | Training loss: 0.6876448492614591
Epoch: 10 | Iteration number: [990/4518] 21% | Training loss: 0.6876384522577729
Epoch: 10 | Iteration number: [1000/4518] 22% | Training loss: 0.6876196537017822
Epoch: 10 | Iteration number: [1010/4518] 22% | Training loss: 0.6876070624530906
Epoch: 10 | Iteration number: [1020/4518] 22% | Training loss: 0.6875908759294772
Epoch: 10 | Iteration number: [1030/4518] 22% | Training loss: 0.6876017656141115
Epoch: 10 | Iteration number: [1040/4518] 23% | Training loss: 0.6875960711676341
Epoch: 10 | Iteration number: [1050/4518] 23% | Training loss: 0.6875996621449788
Epoch: 10 | Iteration number: [1060/4518] 23% | Training loss: 0.6875914849762647
Epoch: 10 | Iteration number: [1070/4518] 23% | Training loss: 0.6875893579465207
Epoch: 10 | Iteration number: [1080/4518] 23% | Training loss: 0.6875934000920366
Epoch: 10 | Iteration number: [1090/4518] 24% | Training loss: 0.6875901895378708
Epoch: 10 | Iteration number: [1100/4518] 24% | Training loss: 0.6875849156488072
Epoch: 10 | Iteration number: [1110/4518] 24% | Training loss: 0.6875839025587649
Epoch: 10 | Iteration number: [1120/4518] 24% | Training loss: 0.6875772075993675
Epoch: 10 | Iteration number: [1130/4518] 25% | Training loss: 0.6875636744815692
Epoch: 10 | Iteration number: [1140/4518] 25% | Training loss: 0.6875509537102883
Epoch: 10 | Iteration number: [1150/4518] 25% | Training loss: 0.6875432052301323
Epoch: 10 | Iteration number: [1160/4518] 25% | Training loss: 0.6875429671900025
Epoch: 10 | Iteration number: [1170/4518] 25% | Training loss: 0.6875377436478932
Epoch: 10 | Iteration number: [1180/4518] 26% | Training loss: 0.6875332262556432
Epoch: 10 | Iteration number: [1190/4518] 26% | Training loss: 0.6875189907911445
Epoch: 10 | Iteration number: [1200/4518] 26% | Training loss: 0.6875092393656572
Epoch: 10 | Iteration number: [1210/4518] 26% | Training loss: 0.6874992447943726
Epoch: 10 | Iteration number: [1220/4518] 27% | Training loss: 0.6875042636374958
Epoch: 10 | Iteration number: [1230/4518] 27% | Training loss: 0.6874975892586437
Epoch: 10 | Iteration number: [1240/4518] 27% | Training loss: 0.6874940978903924
Epoch: 10 | Iteration number: [1250/4518] 27% | Training loss: 0.6874970612049103
Epoch: 10 | Iteration number: [1260/4518] 27% | Training loss: 0.6874951122299073
Epoch: 10 | Iteration number: [1270/4518] 28% | Training loss: 0.6874884209294957
Epoch: 10 | Iteration number: [1280/4518] 28% | Training loss: 0.6874842041637749
Epoch: 10 | Iteration number: [1290/4518] 28% | Training loss: 0.6874765969524088
Epoch: 10 | Iteration number: [1300/4518] 28% | Training loss: 0.6874786381079601
Epoch: 10 | Iteration number: [1310/4518] 28% | Training loss: 0.6874765033030328
Epoch: 10 | Iteration number: [1320/4518] 29% | Training loss: 0.6874729027802294
Epoch: 10 | Iteration number: [1330/4518] 29% | Training loss: 0.6874736245413472
Epoch: 10 | Iteration number: [1340/4518] 29% | Training loss: 0.6874788743791296
Epoch: 10 | Iteration number: [1350/4518] 29% | Training loss: 0.6874795719870814
Epoch: 10 | Iteration number: [1360/4518] 30% | Training loss: 0.6874800531303181
Epoch: 10 | Iteration number: [1370/4518] 30% | Training loss: 0.6874764515970745
Epoch: 10 | Iteration number: [1380/4518] 30% | Training loss: 0.6874750445286433
Epoch: 10 | Iteration number: [1390/4518] 30% | Training loss: 0.6874694313934381
Epoch: 10 | Iteration number: [1400/4518] 30% | Training loss: 0.687468443938664
Epoch: 10 | Iteration number: [1410/4518] 31% | Training loss: 0.6874580799265111
Epoch: 10 | Iteration number: [1420/4518] 31% | Training loss: 0.6874572896621597
Epoch: 10 | Iteration number: [1430/4518] 31% | Training loss: 0.6874615643407915
Epoch: 10 | Iteration number: [1440/4518] 31% | Training loss: 0.6874681488921245
Epoch: 10 | Iteration number: [1450/4518] 32% | Training loss: 0.6874634782610268
Epoch: 10 | Iteration number: [1460/4518] 32% | Training loss: 0.6874594832528127
Epoch: 10 | Iteration number: [1470/4518] 32% | Training loss: 0.6874472434017934
Epoch: 10 | Iteration number: [1480/4518] 32% | Training loss: 0.6874373175002433
Epoch: 10 | Iteration number: [1490/4518] 32% | Training loss: 0.687434711072269
Epoch: 10 | Iteration number: [1500/4518] 33% | Training loss: 0.6874324882427851
Epoch: 10 | Iteration number: [1510/4518] 33% | Training loss: 0.6874213497765017
Epoch: 10 | Iteration number: [1520/4518] 33% | Training loss: 0.6874190113654263
Epoch: 10 | Iteration number: [1530/4518] 33% | Training loss: 0.6874135625518225
Epoch: 10 | Iteration number: [1540/4518] 34% | Training loss: 0.6874157486023841
Epoch: 10 | Iteration number: [1550/4518] 34% | Training loss: 0.6874165301553664
Epoch: 10 | Iteration number: [1560/4518] 34% | Training loss: 0.6874173487608249
Epoch: 10 | Iteration number: [1570/4518] 34% | Training loss: 0.6874211224021426
Epoch: 10 | Iteration number: [1580/4518] 34% | Training loss: 0.6874172376680978
Epoch: 10 | Iteration number: [1590/4518] 35% | Training loss: 0.6874147596224299
Epoch: 10 | Iteration number: [1600/4518] 35% | Training loss: 0.6874164077267051
Epoch: 10 | Iteration number: [1610/4518] 35% | Training loss: 0.6874113818503315
Epoch: 10 | Iteration number: [1620/4518] 35% | Training loss: 0.6874133691375638
Epoch: 10 | Iteration number: [1630/4518] 36% | Training loss: 0.6874086513109734
Epoch: 10 | Iteration number: [1640/4518] 36% | Training loss: 0.6874020112723839
Epoch: 10 | Iteration number: [1650/4518] 36% | Training loss: 0.6873942633831139
Epoch: 10 | Iteration number: [1660/4518] 36% | Training loss: 0.6873984344752438
Epoch: 10 | Iteration number: [1670/4518] 36% | Training loss: 0.6873935926103306
Epoch: 10 | Iteration number: [1680/4518] 37% | Training loss: 0.6873902432975315
Epoch: 10 | Iteration number: [1690/4518] 37% | Training loss: 0.6873926578541479
Epoch: 10 | Iteration number: [1700/4518] 37% | Training loss: 0.6873957630466012
Epoch: 10 | Iteration number: [1710/4518] 37% | Training loss: 0.6873963641492944
Epoch: 10 | Iteration number: [1720/4518] 38% | Training loss: 0.6873998623254687
Epoch: 10 | Iteration number: [1730/4518] 38% | Training loss: 0.6873975355845655
Epoch: 10 | Iteration number: [1740/4518] 38% | Training loss: 0.6873896944111791
Epoch: 10 | Iteration number: [1750/4518] 38% | Training loss: 0.6873891583851406
Epoch: 10 | Iteration number: [1760/4518] 38% | Training loss: 0.6873867006464438
Epoch: 10 | Iteration number: [1770/4518] 39% | Training loss: 0.6873875491026431
Epoch: 10 | Iteration number: [1780/4518] 39% | Training loss: 0.6873898279465986
Epoch: 10 | Iteration number: [1790/4518] 39% | Training loss: 0.6873849377285834
Epoch: 10 | Iteration number: [1800/4518] 39% | Training loss: 0.6873810600572162
Epoch: 10 | Iteration number: [1810/4518] 40% | Training loss: 0.6873752966770151
Epoch: 10 | Iteration number: [1820/4518] 40% | Training loss: 0.6873668572404883
Epoch: 10 | Iteration number: [1830/4518] 40% | Training loss: 0.6873652499881598
Epoch: 10 | Iteration number: [1840/4518] 40% | Training loss: 0.6873625674973364
Epoch: 10 | Iteration number: [1850/4518] 40% | Training loss: 0.6873580388120702
Epoch: 10 | Iteration number: [1860/4518] 41% | Training loss: 0.6873598562453382
Epoch: 10 | Iteration number: [1870/4518] 41% | Training loss: 0.6873542733052198
Epoch: 10 | Iteration number: [1880/4518] 41% | Training loss: 0.6873520994122992
Epoch: 10 | Iteration number: [1890/4518] 41% | Training loss: 0.6873462494403597
Epoch: 10 | Iteration number: [1900/4518] 42% | Training loss: 0.6873464370401282
Epoch: 10 | Iteration number: [1910/4518] 42% | Training loss: 0.6873513531310396
Epoch: 10 | Iteration number: [1920/4518] 42% | Training loss: 0.6873432443477213
Epoch: 10 | Iteration number: [1930/4518] 42% | Training loss: 0.6873403401881302
Epoch: 10 | Iteration number: [1940/4518] 42% | Training loss: 0.6873351106016906
Epoch: 10 | Iteration number: [1950/4518] 43% | Training loss: 0.687339212221977
Epoch: 10 | Iteration number: [1960/4518] 43% | Training loss: 0.687349699194334
Epoch: 10 | Iteration number: [1970/4518] 43% | Training loss: 0.6873483623042325
Epoch: 10 | Iteration number: [1980/4518] 43% | Training loss: 0.6873446141529564
Epoch: 10 | Iteration number: [1990/4518] 44% | Training loss: 0.687337517289061
Epoch: 10 | Iteration number: [2000/4518] 44% | Training loss: 0.6873371193408966
Epoch: 10 | Iteration number: [2010/4518] 44% | Training loss: 0.6873317862921093
Epoch: 10 | Iteration number: [2020/4518] 44% | Training loss: 0.6873324951618025
Epoch: 10 | Iteration number: [2030/4518] 44% | Training loss: 0.6873244631760226
Epoch: 10 | Iteration number: [2040/4518] 45% | Training loss: 0.6873229574046883
Epoch: 10 | Iteration number: [2050/4518] 45% | Training loss: 0.687321358337635
Epoch: 10 | Iteration number: [2060/4518] 45% | Training loss: 0.6873176414989731
Epoch: 10 | Iteration number: [2070/4518] 45% | Training loss: 0.6873148886765835
Epoch: 10 | Iteration number: [2080/4518] 46% | Training loss: 0.687311192544607
Epoch: 10 | Iteration number: [2090/4518] 46% | Training loss: 0.6873078430668589
Epoch: 10 | Iteration number: [2100/4518] 46% | Training loss: 0.687303167893773
Epoch: 10 | Iteration number: [2110/4518] 46% | Training loss: 0.6872960568604312
Epoch: 10 | Iteration number: [2120/4518] 46% | Training loss: 0.6872921353241183
Epoch: 10 | Iteration number: [2130/4518] 47% | Training loss: 0.6872864181167083
Epoch: 10 | Iteration number: [2140/4518] 47% | Training loss: 0.6872812212349099
Epoch: 10 | Iteration number: [2150/4518] 47% | Training loss: 0.6872798596703729
Epoch: 10 | Iteration number: [2160/4518] 47% | Training loss: 0.6872823507697494
Epoch: 10 | Iteration number: [2170/4518] 48% | Training loss: 0.6872789538401063
Epoch: 10 | Iteration number: [2180/4518] 48% | Training loss: 0.6872763125174636
Epoch: 10 | Iteration number: [2190/4518] 48% | Training loss: 0.6872798673094136
Epoch: 10 | Iteration number: [2200/4518] 48% | Training loss: 0.6872792360186577
Epoch: 10 | Iteration number: [2210/4518] 48% | Training loss: 0.6872784902876858
Epoch: 10 | Iteration number: [2220/4518] 49% | Training loss: 0.6872737827870223
Epoch: 10 | Iteration number: [2230/4518] 49% | Training loss: 0.6872669026456072
Epoch: 10 | Iteration number: [2240/4518] 49% | Training loss: 0.6872602707839438
Epoch: 10 | Iteration number: [2250/4518] 49% | Training loss: 0.6872580014864603
Epoch: 10 | Iteration number: [2260/4518] 50% | Training loss: 0.6872529651211426
Epoch: 10 | Iteration number: [2270/4518] 50% | Training loss: 0.6872452332847444
Epoch: 10 | Iteration number: [2280/4518] 50% | Training loss: 0.6872487499525672
Epoch: 10 | Iteration number: [2290/4518] 50% | Training loss: 0.6872519119077374
Epoch: 10 | Iteration number: [2300/4518] 50% | Training loss: 0.6872528561820155
Epoch: 10 | Iteration number: [2310/4518] 51% | Training loss: 0.687250651528825
Epoch: 10 | Iteration number: [2320/4518] 51% | Training loss: 0.6872464012226154
Epoch: 10 | Iteration number: [2330/4518] 51% | Training loss: 0.687240077139482
Epoch: 10 | Iteration number: [2340/4518] 51% | Training loss: 0.6872370914516286
Epoch: 10 | Iteration number: [2350/4518] 52% | Training loss: 0.6872326388764889
Epoch: 10 | Iteration number: [2360/4518] 52% | Training loss: 0.6872286001504477
Epoch: 10 | Iteration number: [2370/4518] 52% | Training loss: 0.6872309212946187
Epoch: 10 | Iteration number: [2380/4518] 52% | Training loss: 0.6872311772168184
Epoch: 10 | Iteration number: [2390/4518] 52% | Training loss: 0.6872301826666588
Epoch: 10 | Iteration number: [2400/4518] 53% | Training loss: 0.6872305727998416
Epoch: 10 | Iteration number: [2410/4518] 53% | Training loss: 0.6872322150780452
Epoch: 10 | Iteration number: [2420/4518] 53% | Training loss: 0.6872310078094813
Epoch: 10 | Iteration number: [2430/4518] 53% | Training loss: 0.6872311944824188
Epoch: 10 | Iteration number: [2440/4518] 54% | Training loss: 0.6872342649053355
Epoch: 10 | Iteration number: [2450/4518] 54% | Training loss: 0.6872340984490453
Epoch: 10 | Iteration number: [2460/4518] 54% | Training loss: 0.6872381277685243
Epoch: 10 | Iteration number: [2470/4518] 54% | Training loss: 0.6872354394752487
Epoch: 10 | Iteration number: [2480/4518] 54% | Training loss: 0.6872305031745665
Epoch: 10 | Iteration number: [2490/4518] 55% | Training loss: 0.6872263177810424
Epoch: 10 | Iteration number: [2500/4518] 55% | Training loss: 0.6872248296499253
Epoch: 10 | Iteration number: [2510/4518] 55% | Training loss: 0.6872221758166157
Epoch: 10 | Iteration number: [2520/4518] 55% | Training loss: 0.6872246072169335
Epoch: 10 | Iteration number: [2530/4518] 55% | Training loss: 0.6872217574609598
Epoch: 10 | Iteration number: [2540/4518] 56% | Training loss: 0.6872232073873985
Epoch: 10 | Iteration number: [2550/4518] 56% | Training loss: 0.6872240421351264
Epoch: 10 | Iteration number: [2560/4518] 56% | Training loss: 0.687220116937533
Epoch: 10 | Iteration number: [2570/4518] 56% | Training loss: 0.6872222449992881
Epoch: 10 | Iteration number: [2580/4518] 57% | Training loss: 0.6872225337250288
Epoch: 10 | Iteration number: [2590/4518] 57% | Training loss: 0.6872172905671551
Epoch: 10 | Iteration number: [2600/4518] 57% | Training loss: 0.6872191972915943
Epoch: 10 | Iteration number: [2610/4518] 57% | Training loss: 0.6872191788364644
Epoch: 10 | Iteration number: [2620/4518] 57% | Training loss: 0.6872105034480568
Epoch: 10 | Iteration number: [2630/4518] 58% | Training loss: 0.6872143783043546
Epoch: 10 | Iteration number: [2640/4518] 58% | Training loss: 0.6872175362074013
Epoch: 10 | Iteration number: [2650/4518] 58% | Training loss: 0.6872171060993987
Epoch: 10 | Iteration number: [2660/4518] 58% | Training loss: 0.6872167040754978
Epoch: 10 | Iteration number: [2670/4518] 59% | Training loss: 0.6872163309586629
Epoch: 10 | Iteration number: [2680/4518] 59% | Training loss: 0.687217815220356
Epoch: 10 | Iteration number: [2690/4518] 59% | Training loss: 0.6872158770224419
Epoch: 10 | Iteration number: [2700/4518] 59% | Training loss: 0.6872177665984189
Epoch: 10 | Iteration number: [2710/4518] 59% | Training loss: 0.6872200827317044
Epoch: 10 | Iteration number: [2720/4518] 60% | Training loss: 0.6872200290069861
Epoch: 10 | Iteration number: [2730/4518] 60% | Training loss: 0.6872224969304962
Epoch: 10 | Iteration number: [2740/4518] 60% | Training loss: 0.6872190764568148
Epoch: 10 | Iteration number: [2750/4518] 60% | Training loss: 0.687217820926146
Epoch: 10 | Iteration number: [2760/4518] 61% | Training loss: 0.6872198318441709
Epoch: 10 | Iteration number: [2770/4518] 61% | Training loss: 0.687217624264934
Epoch: 10 | Iteration number: [2780/4518] 61% | Training loss: 0.6872151507319306
Epoch: 10 | Iteration number: [2790/4518] 61% | Training loss: 0.6872146593413473
Epoch: 10 | Iteration number: [2800/4518] 61% | Training loss: 0.6872131363834654
Epoch: 10 | Iteration number: [2810/4518] 62% | Training loss: 0.6872107545039832
Epoch: 10 | Iteration number: [2820/4518] 62% | Training loss: 0.6872112996612035
Epoch: 10 | Iteration number: [2830/4518] 62% | Training loss: 0.6872099261401821
Epoch: 10 | Iteration number: [2840/4518] 62% | Training loss: 0.6872119811219228
Epoch: 10 | Iteration number: [2850/4518] 63% | Training loss: 0.6872014969482757
Epoch: 10 | Iteration number: [2860/4518] 63% | Training loss: 0.6872017983998452
Epoch: 10 | Iteration number: [2870/4518] 63% | Training loss: 0.6872064950366469
Epoch: 10 | Iteration number: [2880/4518] 63% | Training loss: 0.6872015055062042
Epoch: 10 | Iteration number: [2890/4518] 63% | Training loss: 0.6872018006433666
Epoch: 10 | Iteration number: [2900/4518] 64% | Training loss: 0.687198308356877
Epoch: 10 | Iteration number: [2910/4518] 64% | Training loss: 0.6871927331813013
Epoch: 10 | Iteration number: [2920/4518] 64% | Training loss: 0.6871945486085056
Epoch: 10 | Iteration number: [2930/4518] 64% | Training loss: 0.6871929609328
Epoch: 10 | Iteration number: [2940/4518] 65% | Training loss: 0.687191690757972
Epoch: 10 | Iteration number: [2950/4518] 65% | Training loss: 0.6871919269278898
Epoch: 10 | Iteration number: [2960/4518] 65% | Training loss: 0.6871915822697653
Epoch: 10 | Iteration number: [2970/4518] 65% | Training loss: 0.687191670591181
Epoch: 10 | Iteration number: [2980/4518] 65% | Training loss: 0.6871899252569915
Epoch: 10 | Iteration number: [2990/4518] 66% | Training loss: 0.6871852043281033
Epoch: 10 | Iteration number: [3000/4518] 66% | Training loss: 0.6871876146992048
Epoch: 10 | Iteration number: [3010/4518] 66% | Training loss: 0.6871876552255447
Epoch: 10 | Iteration number: [3020/4518] 66% | Training loss: 0.6871884177654785
Epoch: 10 | Iteration number: [3030/4518] 67% | Training loss: 0.6871811975740364
Epoch: 10 | Iteration number: [3040/4518] 67% | Training loss: 0.6871821905241201
Epoch: 10 | Iteration number: [3050/4518] 67% | Training loss: 0.6871853507151369
Epoch: 10 | Iteration number: [3060/4518] 67% | Training loss: 0.6871819944358339
Epoch: 10 | Iteration number: [3070/4518] 67% | Training loss: 0.687179490720022
Epoch: 10 | Iteration number: [3080/4518] 68% | Training loss: 0.6871807910985761
Epoch: 10 | Iteration number: [3090/4518] 68% | Training loss: 0.6871768820440113
Epoch: 10 | Iteration number: [3100/4518] 68% | Training loss: 0.6871793953449495
Epoch: 10 | Iteration number: [3110/4518] 68% | Training loss: 0.6871822342420314
Epoch: 10 | Iteration number: [3120/4518] 69% | Training loss: 0.687180898949886
Epoch: 10 | Iteration number: [3130/4518] 69% | Training loss: 0.6871769440059845
Epoch: 10 | Iteration number: [3140/4518] 69% | Training loss: 0.687175731237527
Epoch: 10 | Iteration number: [3150/4518] 69% | Training loss: 0.6871757269284082
Epoch: 10 | Iteration number: [3160/4518] 69% | Training loss: 0.6871774060816704
Epoch: 10 | Iteration number: [3170/4518] 70% | Training loss: 0.6871767413728996
Epoch: 10 | Iteration number: [3180/4518] 70% | Training loss: 0.6871804382253743
Epoch: 10 | Iteration number: [3190/4518] 70% | Training loss: 0.6871764407075684
Epoch: 10 | Iteration number: [3200/4518] 70% | Training loss: 0.6871772058680654
Epoch: 10 | Iteration number: [3210/4518] 71% | Training loss: 0.6871737419073456
Epoch: 10 | Iteration number: [3220/4518] 71% | Training loss: 0.6871722779473903
Epoch: 10 | Iteration number: [3230/4518] 71% | Training loss: 0.6871757695733948
Epoch: 10 | Iteration number: [3240/4518] 71% | Training loss: 0.6871758387044624
Epoch: 10 | Iteration number: [3250/4518] 71% | Training loss: 0.6871729929080376
Epoch: 10 | Iteration number: [3260/4518] 72% | Training loss: 0.6871771230105242
Epoch: 10 | Iteration number: [3270/4518] 72% | Training loss: 0.6871778341061479
Epoch: 10 | Iteration number: [3280/4518] 72% | Training loss: 0.6871796732268682
Epoch: 10 | Iteration number: [3290/4518] 72% | Training loss: 0.6871794345168719
Epoch: 10 | Iteration number: [3300/4518] 73% | Training loss: 0.6871817587722432
Epoch: 10 | Iteration number: [3310/4518] 73% | Training loss: 0.6871819933375564
Epoch: 10 | Iteration number: [3320/4518] 73% | Training loss: 0.6871815508568143
Epoch: 10 | Iteration number: [3330/4518] 73% | Training loss: 0.6871829730791372
Epoch: 10 | Iteration number: [3340/4518] 73% | Training loss: 0.6871825508371798
Epoch: 10 | Iteration number: [3350/4518] 74% | Training loss: 0.6871828496278222
Epoch: 10 | Iteration number: [3360/4518] 74% | Training loss: 0.6871857658738182
Epoch: 10 | Iteration number: [3370/4518] 74% | Training loss: 0.6871838064328145
Epoch: 10 | Iteration number: [3380/4518] 74% | Training loss: 0.6871859740576095
Epoch: 10 | Iteration number: [3390/4518] 75% | Training loss: 0.6871885490452645
Epoch: 10 | Iteration number: [3400/4518] 75% | Training loss: 0.6871877805625691
Epoch: 10 | Iteration number: [3410/4518] 75% | Training loss: 0.6871864953873095
Epoch: 10 | Iteration number: [3420/4518] 75% | Training loss: 0.687184763965551
Epoch: 10 | Iteration number: [3430/4518] 75% | Training loss: 0.6871873197159336
Epoch: 10 | Iteration number: [3440/4518] 76% | Training loss: 0.6871886022042396
Epoch: 10 | Iteration number: [3450/4518] 76% | Training loss: 0.687192174749098
Epoch: 10 | Iteration number: [3460/4518] 76% | Training loss: 0.6871889310765129
Epoch: 10 | Iteration number: [3470/4518] 76% | Training loss: 0.6871919628007268
Epoch: 10 | Iteration number: [3480/4518] 77% | Training loss: 0.6871908413610239
Epoch: 10 | Iteration number: [3490/4518] 77% | Training loss: 0.6871881207627348
Epoch: 10 | Iteration number: [3500/4518] 77% | Training loss: 0.6871845519372395
Epoch: 10 | Iteration number: [3510/4518] 77% | Training loss: 0.6871854346362274
Epoch: 10 | Iteration number: [3520/4518] 77% | Training loss: 0.6871892565692013
Epoch: 10 | Iteration number: [3530/4518] 78% | Training loss: 0.6871883600528111
Epoch: 10 | Iteration number: [3540/4518] 78% | Training loss: 0.6871864052647251
Epoch: 10 | Iteration number: [3550/4518] 78% | Training loss: 0.6871856519873714
Epoch: 10 | Iteration number: [3560/4518] 78% | Training loss: 0.6871838890936938
Epoch: 10 | Iteration number: [3570/4518] 79% | Training loss: 0.6871843824533521
Epoch: 10 | Iteration number: [3580/4518] 79% | Training loss: 0.6871822507687787
Epoch: 10 | Iteration number: [3590/4518] 79% | Training loss: 0.6871804951957341
Epoch: 10 | Iteration number: [3600/4518] 79% | Training loss: 0.6871794557571411
Epoch: 10 | Iteration number: [3610/4518] 79% | Training loss: 0.6871822202634944
Epoch: 10 | Iteration number: [3620/4518] 80% | Training loss: 0.6871874830670119
Epoch: 10 | Iteration number: [3630/4518] 80% | Training loss: 0.6871882767388315
Epoch: 10 | Iteration number: [3640/4518] 80% | Training loss: 0.6871850896503899
Epoch: 10 | Iteration number: [3650/4518] 80% | Training loss: 0.687185531250418
Epoch: 10 | Iteration number: [3660/4518] 81% | Training loss: 0.6871842687735792
Epoch: 10 | Iteration number: [3670/4518] 81% | Training loss: 0.6871830686074186
Epoch: 10 | Iteration number: [3680/4518] 81% | Training loss: 0.6871809427666923
Epoch: 10 | Iteration number: [3690/4518] 81% | Training loss: 0.6871813683651973
Epoch: 10 | Iteration number: [3700/4518] 81% | Training loss: 0.6871825467734723
Epoch: 10 | Iteration number: [3710/4518] 82% | Training loss: 0.687184686239839
Epoch: 10 | Iteration number: [3720/4518] 82% | Training loss: 0.6871849154592842
Epoch: 10 | Iteration number: [3730/4518] 82% | Training loss: 0.687185918853366
Epoch: 10 | Iteration number: [3740/4518] 82% | Training loss: 0.6871844117972941
Epoch: 10 | Iteration number: [3750/4518] 83% | Training loss: 0.6871848594665527
Epoch: 10 | Iteration number: [3760/4518] 83% | Training loss: 0.6871802495990662
Epoch: 10 | Iteration number: [3770/4518] 83% | Training loss: 0.6871809143444587
Epoch: 10 | Iteration number: [3780/4518] 83% | Training loss: 0.687180590345746
Epoch: 10 | Iteration number: [3790/4518] 83% | Training loss: 0.6871801447742533
Epoch: 10 | Iteration number: [3800/4518] 84% | Training loss: 0.6871782713814786
Epoch: 10 | Iteration number: [3810/4518] 84% | Training loss: 0.6871790308964847
Epoch: 10 | Iteration number: [3820/4518] 84% | Training loss: 0.687176912570499
Epoch: 10 | Iteration number: [3830/4518] 84% | Training loss: 0.6871770587197794
Epoch: 10 | Iteration number: [3840/4518] 84% | Training loss: 0.6871771260630339
Epoch: 10 | Iteration number: [3850/4518] 85% | Training loss: 0.687177673996269
Epoch: 10 | Iteration number: [3860/4518] 85% | Training loss: 0.6871762795460656
Epoch: 10 | Iteration number: [3870/4518] 85% | Training loss: 0.6871755582109594
Epoch: 10 | Iteration number: [3880/4518] 85% | Training loss: 0.6871789544359925
Epoch: 10 | Iteration number: [3890/4518] 86% | Training loss: 0.6871760963933939
Epoch: 10 | Iteration number: [3900/4518] 86% | Training loss: 0.687176667360159
Epoch: 10 | Iteration number: [3910/4518] 86% | Training loss: 0.6871754215958783
Epoch: 10 | Iteration number: [3920/4518] 86% | Training loss: 0.6871723703127735
Epoch: 10 | Iteration number: [3930/4518] 86% | Training loss: 0.6871737661555827
Epoch: 10 | Iteration number: [3940/4518] 87% | Training loss: 0.6871727782608894
Epoch: 10 | Iteration number: [3950/4518] 87% | Training loss: 0.687170892863334
Epoch: 10 | Iteration number: [3960/4518] 87% | Training loss: 0.6871711496903439
Epoch: 10 | Iteration number: [3970/4518] 87% | Training loss: 0.6871700205790906
Epoch: 10 | Iteration number: [3980/4518] 88% | Training loss: 0.6871669672092601
Epoch: 10 | Iteration number: [3990/4518] 88% | Training loss: 0.6871645725460578
Epoch: 10 | Iteration number: [4000/4518] 88% | Training loss: 0.6871628106683493
Epoch: 10 | Iteration number: [4010/4518] 88% | Training loss: 0.6871630385629554
Epoch: 10 | Iteration number: [4020/4518] 88% | Training loss: 0.6871615329785133
Epoch: 10 | Iteration number: [4030/4518] 89% | Training loss: 0.6871594215740933
Epoch: 10 | Iteration number: [4040/4518] 89% | Training loss: 0.6871573054554438
Epoch: 10 | Iteration number: [4050/4518] 89% | Training loss: 0.6871598840495686
Epoch: 10 | Iteration number: [4060/4518] 89% | Training loss: 0.6871593171593003
Epoch: 10 | Iteration number: [4070/4518] 90% | Training loss: 0.6871589884271786
Epoch: 10 | Iteration number: [4080/4518] 90% | Training loss: 0.6871584853705238
Epoch: 10 | Iteration number: [4090/4518] 90% | Training loss: 0.6871599689381047
Epoch: 10 | Iteration number: [4100/4518] 90% | Training loss: 0.6871590694857806
Epoch: 10 | Iteration number: [4110/4518] 90% | Training loss: 0.6871580647581105
Epoch: 10 | Iteration number: [4120/4518] 91% | Training loss: 0.6871569787414329
Epoch: 10 | Iteration number: [4130/4518] 91% | Training loss: 0.6871583981894985
Epoch: 10 | Iteration number: [4140/4518] 91% | Training loss: 0.6871589466425532
Epoch: 10 | Iteration number: [4150/4518] 91% | Training loss: 0.6871590121108365
Epoch: 10 | Iteration number: [4160/4518] 92% | Training loss: 0.687161946368332
Epoch: 10 | Iteration number: [4170/4518] 92% | Training loss: 0.6871641312857611
Epoch: 10 | Iteration number: [4180/4518] 92% | Training loss: 0.6871632690777619
Epoch: 10 | Iteration number: [4190/4518] 92% | Training loss: 0.6871640962888631
Epoch: 10 | Iteration number: [4200/4518] 92% | Training loss: 0.6871621678698631
Epoch: 10 | Iteration number: [4210/4518] 93% | Training loss: 0.6871638369956662
Epoch: 10 | Iteration number: [4220/4518] 93% | Training loss: 0.6871641376572197
Epoch: 10 | Iteration number: [4230/4518] 93% | Training loss: 0.6871659491079073
Epoch: 10 | Iteration number: [4240/4518] 93% | Training loss: 0.6871648366721171
Epoch: 10 | Iteration number: [4250/4518] 94% | Training loss: 0.6871607659003314
Epoch: 10 | Iteration number: [4260/4518] 94% | Training loss: 0.6871614373066056
Epoch: 10 | Iteration number: [4270/4518] 94% | Training loss: 0.6871608848454522
Epoch: 10 | Iteration number: [4280/4518] 94% | Training loss: 0.6871615591450272
Epoch: 10 | Iteration number: [4290/4518] 94% | Training loss: 0.6871635528850111
Epoch: 10 | Iteration number: [4300/4518] 95% | Training loss: 0.6871601004517356
Epoch: 10 | Iteration number: [4310/4518] 95% | Training loss: 0.6871587688712676
Epoch: 10 | Iteration number: [4320/4518] 95% | Training loss: 0.687158769617478
Epoch: 10 | Iteration number: [4330/4518] 95% | Training loss: 0.6871561688446283
Epoch: 10 | Iteration number: [4340/4518] 96% | Training loss: 0.6871547457671935
Epoch: 10 | Iteration number: [4350/4518] 96% | Training loss: 0.6871560418194738
Epoch: 10 | Iteration number: [4360/4518] 96% | Training loss: 0.6871577979637942
Epoch: 10 | Iteration number: [4370/4518] 96% | Training loss: 0.6871576141983748
Epoch: 10 | Iteration number: [4380/4518] 96% | Training loss: 0.6871573534322112
Epoch: 10 | Iteration number: [4390/4518] 97% | Training loss: 0.687160693173528
Epoch: 10 | Iteration number: [4400/4518] 97% | Training loss: 0.6871586687727408
Epoch: 10 | Iteration number: [4410/4518] 97% | Training loss: 0.6871597081490385
Epoch: 10 | Iteration number: [4420/4518] 97% | Training loss: 0.6871573861637806
Epoch: 10 | Iteration number: [4430/4518] 98% | Training loss: 0.6871570137096044
Epoch: 10 | Iteration number: [4440/4518] 98% | Training loss: 0.6871585215265686
Epoch: 10 | Iteration number: [4450/4518] 98% | Training loss: 0.6871582027097767
Epoch: 10 | Iteration number: [4460/4518] 98% | Training loss: 0.6871601710004123
Epoch: 10 | Iteration number: [4470/4518] 98% | Training loss: 0.6871583652176313
Epoch: 10 | Iteration number: [4480/4518] 99% | Training loss: 0.6871567094565503
Epoch: 10 | Iteration number: [4490/4518] 99% | Training loss: 0.687155861392584
Epoch: 10 | Iteration number: [4500/4518] 99% | Training loss: 0.6871563986142476
Epoch: 10 | Iteration number: [4510/4518] 99% | Training loss: 0.6871557100649155

 End of epoch: 10 | Train Loss: 0.6870032605633054 | Training Time: 643 

 End of epoch: 10 | Eval Loss: 0.6905971461412858 | Evaluating Time: 17 
Epoch: 11 | Iteration number: [10/4518] 0% | Training loss: 0.7552969574928283
Epoch: 11 | Iteration number: [20/4518] 0% | Training loss: 0.7211313247680664
Epoch: 11 | Iteration number: [30/4518] 0% | Training loss: 0.7102863192558289
Epoch: 11 | Iteration number: [40/4518] 0% | Training loss: 0.7044927477836609
Epoch: 11 | Iteration number: [50/4518] 1% | Training loss: 0.701084451675415
Epoch: 11 | Iteration number: [60/4518] 1% | Training loss: 0.6985514223575592
Epoch: 11 | Iteration number: [70/4518] 1% | Training loss: 0.6967830674988883
Epoch: 11 | Iteration number: [80/4518] 1% | Training loss: 0.695413789153099
Epoch: 11 | Iteration number: [90/4518] 1% | Training loss: 0.6944791634877523
Epoch: 11 | Iteration number: [100/4518] 2% | Training loss: 0.6936092776060104
Epoch: 11 | Iteration number: [110/4518] 2% | Training loss: 0.6929723457856611
Epoch: 11 | Iteration number: [120/4518] 2% | Training loss: 0.6925541698932648
Epoch: 11 | Iteration number: [130/4518] 2% | Training loss: 0.6921959661520445
Epoch: 11 | Iteration number: [140/4518] 3% | Training loss: 0.6918041999850955
Epoch: 11 | Iteration number: [150/4518] 3% | Training loss: 0.6914566953976949
Epoch: 11 | Iteration number: [160/4518] 3% | Training loss: 0.6911139268428087
Epoch: 11 | Iteration number: [170/4518] 3% | Training loss: 0.6908851563930511
Epoch: 11 | Iteration number: [180/4518] 3% | Training loss: 0.6906388898690542
Epoch: 11 | Iteration number: [190/4518] 4% | Training loss: 0.6904434724857933
Epoch: 11 | Iteration number: [200/4518] 4% | Training loss: 0.6902985873818398
Epoch: 11 | Iteration number: [210/4518] 4% | Training loss: 0.6901625843275161
Epoch: 11 | Iteration number: [220/4518] 4% | Training loss: 0.6900433136658235
Epoch: 11 | Iteration number: [230/4518] 5% | Training loss: 0.6899205197458682
Epoch: 11 | Iteration number: [240/4518] 5% | Training loss: 0.6898053082327048
Epoch: 11 | Iteration number: [250/4518] 5% | Training loss: 0.6896995792388916
Epoch: 11 | Iteration number: [260/4518] 5% | Training loss: 0.6896095126867294
Epoch: 11 | Iteration number: [270/4518] 5% | Training loss: 0.689533547560374
Epoch: 11 | Iteration number: [280/4518] 6% | Training loss: 0.6894555268543107
Epoch: 11 | Iteration number: [290/4518] 6% | Training loss: 0.689380212898912
Epoch: 11 | Iteration number: [300/4518] 6% | Training loss: 0.6892794209718704
Epoch: 11 | Iteration number: [310/4518] 6% | Training loss: 0.6892088886230222
Epoch: 11 | Iteration number: [320/4518] 7% | Training loss: 0.6891272569075226
Epoch: 11 | Iteration number: [330/4518] 7% | Training loss: 0.6890442976445863
Epoch: 11 | Iteration number: [340/4518] 7% | Training loss: 0.6889722647035823
Epoch: 11 | Iteration number: [350/4518] 7% | Training loss: 0.6889227783679962
Epoch: 11 | Iteration number: [360/4518] 7% | Training loss: 0.6888694011502796
Epoch: 11 | Iteration number: [370/4518] 8% | Training loss: 0.6887756747168463
Epoch: 11 | Iteration number: [380/4518] 8% | Training loss: 0.688723654339188
Epoch: 11 | Iteration number: [390/4518] 8% | Training loss: 0.6886849695291275
Epoch: 11 | Iteration number: [400/4518] 8% | Training loss: 0.6886339125037193
Epoch: 11 | Iteration number: [410/4518] 9% | Training loss: 0.6885983805830885
Epoch: 11 | Iteration number: [420/4518] 9% | Training loss: 0.6885568401643208
Epoch: 11 | Iteration number: [430/4518] 9% | Training loss: 0.6885156373644984
Epoch: 11 | Iteration number: [440/4518] 9% | Training loss: 0.6885041429237886
Epoch: 11 | Iteration number: [450/4518] 9% | Training loss: 0.6884844255447388
Epoch: 11 | Iteration number: [460/4518] 10% | Training loss: 0.6884271121543387
Epoch: 11 | Iteration number: [470/4518] 10% | Training loss: 0.6883802350531233
Epoch: 11 | Iteration number: [480/4518] 10% | Training loss: 0.6883113934348027
Epoch: 11 | Iteration number: [490/4518] 10% | Training loss: 0.688271999480773
Epoch: 11 | Iteration number: [500/4518] 11% | Training loss: 0.6882354499101638
Epoch: 11 | Iteration number: [510/4518] 11% | Training loss: 0.6882100503818661
Epoch: 11 | Iteration number: [520/4518] 11% | Training loss: 0.6881615185966858
Epoch: 11 | Iteration number: [530/4518] 11% | Training loss: 0.6881492090675067
Epoch: 11 | Iteration number: [540/4518] 11% | Training loss: 0.6881296543059525
Epoch: 11 | Iteration number: [550/4518] 12% | Training loss: 0.6880948127399792
Epoch: 11 | Iteration number: [560/4518] 12% | Training loss: 0.6881082580557891
Epoch: 11 | Iteration number: [570/4518] 12% | Training loss: 0.6881043765628547
Epoch: 11 | Iteration number: [580/4518] 12% | Training loss: 0.6880780472837645
Epoch: 11 | Iteration number: [590/4518] 13% | Training loss: 0.6880670288861808
Epoch: 11 | Iteration number: [600/4518] 13% | Training loss: 0.6880503211418788
Epoch: 11 | Iteration number: [610/4518] 13% | Training loss: 0.6880318356342003
Epoch: 11 | Iteration number: [620/4518] 13% | Training loss: 0.6880193286365078
Epoch: 11 | Iteration number: [630/4518] 13% | Training loss: 0.6879851859713357
Epoch: 11 | Iteration number: [640/4518] 14% | Training loss: 0.6879846799187362
Epoch: 11 | Iteration number: [650/4518] 14% | Training loss: 0.6879587158790001
Epoch: 11 | Iteration number: [660/4518] 14% | Training loss: 0.6879562298456828
Epoch: 11 | Iteration number: [670/4518] 14% | Training loss: 0.6879536326251813
Epoch: 11 | Iteration number: [680/4518] 15% | Training loss: 0.6879355414825328
Epoch: 11 | Iteration number: [690/4518] 15% | Training loss: 0.6879270172637442
Epoch: 11 | Iteration number: [700/4518] 15% | Training loss: 0.687928826894079
Epoch: 11 | Iteration number: [710/4518] 15% | Training loss: 0.6879324357274552
Epoch: 11 | Iteration number: [720/4518] 15% | Training loss: 0.6878972152041064
Epoch: 11 | Iteration number: [730/4518] 16% | Training loss: 0.6878893133712142
Epoch: 11 | Iteration number: [740/4518] 16% | Training loss: 0.6878911983322453
Epoch: 11 | Iteration number: [750/4518] 16% | Training loss: 0.6878800899982452
Epoch: 11 | Iteration number: [760/4518] 16% | Training loss: 0.6878714132465814
Epoch: 11 | Iteration number: [770/4518] 17% | Training loss: 0.6878459448164159
Epoch: 11 | Iteration number: [780/4518] 17% | Training loss: 0.6878291332568878
Epoch: 11 | Iteration number: [790/4518] 17% | Training loss: 0.6878253014027318
Epoch: 11 | Iteration number: [800/4518] 17% | Training loss: 0.687815578430891
Epoch: 11 | Iteration number: [810/4518] 17% | Training loss: 0.6878032998538312
Epoch: 11 | Iteration number: [820/4518] 18% | Training loss: 0.6877745385577039
Epoch: 11 | Iteration number: [830/4518] 18% | Training loss: 0.687761872863195
Epoch: 11 | Iteration number: [840/4518] 18% | Training loss: 0.687761194507281
Epoch: 11 | Iteration number: [850/4518] 18% | Training loss: 0.6877567524769727
Epoch: 11 | Iteration number: [860/4518] 19% | Training loss: 0.6877456477908201
Epoch: 11 | Iteration number: [870/4518] 19% | Training loss: 0.6877340454479743
Epoch: 11 | Iteration number: [880/4518] 19% | Training loss: 0.6877306403084235
Epoch: 11 | Iteration number: [890/4518] 19% | Training loss: 0.6877300499530321
Epoch: 11 | Iteration number: [900/4518] 19% | Training loss: 0.6877236684163411
Epoch: 11 | Iteration number: [910/4518] 20% | Training loss: 0.6877161066610734
Epoch: 11 | Iteration number: [920/4518] 20% | Training loss: 0.6877091979850893
Epoch: 11 | Iteration number: [930/4518] 20% | Training loss: 0.6876981831366016
Epoch: 11 | Iteration number: [940/4518] 20% | Training loss: 0.6876936809179631
Epoch: 11 | Iteration number: [950/4518] 21% | Training loss: 0.6876977596157475
Epoch: 11 | Iteration number: [960/4518] 21% | Training loss: 0.6876846957330902
Epoch: 11 | Iteration number: [970/4518] 21% | Training loss: 0.6876685125926106
Epoch: 11 | Iteration number: [980/4518] 21% | Training loss: 0.6876689819657072
Epoch: 11 | Iteration number: [990/4518] 21% | Training loss: 0.687655609665495
Epoch: 11 | Iteration number: [1000/4518] 22% | Training loss: 0.687632818698883
Epoch: 11 | Iteration number: [1010/4518] 22% | Training loss: 0.6876209329260458
Epoch: 11 | Iteration number: [1020/4518] 22% | Training loss: 0.6876346124153511
Epoch: 11 | Iteration number: [1030/4518] 22% | Training loss: 0.6876273388422809
Epoch: 11 | Iteration number: [1040/4518] 23% | Training loss: 0.6876216977834702
Epoch: 11 | Iteration number: [1050/4518] 23% | Training loss: 0.6876190649327778
Epoch: 11 | Iteration number: [1060/4518] 23% | Training loss: 0.6876167372712549
Epoch: 11 | Iteration number: [1070/4518] 23% | Training loss: 0.6876051468269847
Epoch: 11 | Iteration number: [1080/4518] 23% | Training loss: 0.687595139278306
Epoch: 11 | Iteration number: [1090/4518] 24% | Training loss: 0.6875790304547056
Epoch: 11 | Iteration number: [1100/4518] 24% | Training loss: 0.6875793660228903
Epoch: 11 | Iteration number: [1110/4518] 24% | Training loss: 0.6875560748684514
Epoch: 11 | Iteration number: [1120/4518] 24% | Training loss: 0.6875503967383079
Epoch: 11 | Iteration number: [1130/4518] 25% | Training loss: 0.6875491360120014
Epoch: 11 | Iteration number: [1140/4518] 25% | Training loss: 0.6875468513421845
Epoch: 11 | Iteration number: [1150/4518] 25% | Training loss: 0.6875432102576546
Epoch: 11 | Iteration number: [1160/4518] 25% | Training loss: 0.6875392798719735
Epoch: 11 | Iteration number: [1170/4518] 25% | Training loss: 0.6875421823599399
Epoch: 11 | Iteration number: [1180/4518] 26% | Training loss: 0.6875375957307169
Epoch: 11 | Iteration number: [1190/4518] 26% | Training loss: 0.6875479633066834
Epoch: 11 | Iteration number: [1200/4518] 26% | Training loss: 0.6875480774044991
Epoch: 11 | Iteration number: [1210/4518] 26% | Training loss: 0.6875492997898544
Epoch: 11 | Iteration number: [1220/4518] 27% | Training loss: 0.6875483035552697
Epoch: 11 | Iteration number: [1230/4518] 27% | Training loss: 0.6875430332935922
Epoch: 11 | Iteration number: [1240/4518] 27% | Training loss: 0.6875296286517574
Epoch: 11 | Iteration number: [1250/4518] 27% | Training loss: 0.6875255613327026
Epoch: 11 | Iteration number: [1260/4518] 27% | Training loss: 0.6875278660229274
Epoch: 11 | Iteration number: [1270/4518] 28% | Training loss: 0.6875250387379503
Epoch: 11 | Iteration number: [1280/4518] 28% | Training loss: 0.6875164666678757
Epoch: 11 | Iteration number: [1290/4518] 28% | Training loss: 0.6875214049520418
Epoch: 11 | Iteration number: [1300/4518] 28% | Training loss: 0.687520201252057
Epoch: 11 | Iteration number: [1310/4518] 28% | Training loss: 0.6875094613956131
Epoch: 11 | Iteration number: [1320/4518] 29% | Training loss: 0.6874906967986714
Epoch: 11 | Iteration number: [1330/4518] 29% | Training loss: 0.6874865119170426
Epoch: 11 | Iteration number: [1340/4518] 29% | Training loss: 0.6874812596769475
Epoch: 11 | Iteration number: [1350/4518] 29% | Training loss: 0.6874811673164367
Epoch: 11 | Iteration number: [1360/4518] 30% | Training loss: 0.6874773752163438
Epoch: 11 | Iteration number: [1370/4518] 30% | Training loss: 0.6874766082224184
Epoch: 11 | Iteration number: [1380/4518] 30% | Training loss: 0.687473653839982
Epoch: 11 | Iteration number: [1390/4518] 30% | Training loss: 0.6874755149693798
Epoch: 11 | Iteration number: [1400/4518] 30% | Training loss: 0.6874697686944689
Epoch: 11 | Iteration number: [1410/4518] 31% | Training loss: 0.6874733309796516
Epoch: 11 | Iteration number: [1420/4518] 31% | Training loss: 0.687452945868734
Epoch: 11 | Iteration number: [1430/4518] 31% | Training loss: 0.6874508946091978
Epoch: 11 | Iteration number: [1440/4518] 31% | Training loss: 0.6874515812016195
Epoch: 11 | Iteration number: [1450/4518] 32% | Training loss: 0.6874500415242951
Epoch: 11 | Iteration number: [1460/4518] 32% | Training loss: 0.6874479141953873
Epoch: 11 | Iteration number: [1470/4518] 32% | Training loss: 0.6874450694541542
Epoch: 11 | Iteration number: [1480/4518] 32% | Training loss: 0.6874476403400704
Epoch: 11 | Iteration number: [1490/4518] 32% | Training loss: 0.6874371252603979
Epoch: 11 | Iteration number: [1500/4518] 33% | Training loss: 0.6874299376408259
Epoch: 11 | Iteration number: [1510/4518] 33% | Training loss: 0.6874358001134253
Epoch: 11 | Iteration number: [1520/4518] 33% | Training loss: 0.687424220772166
Epoch: 11 | Iteration number: [1530/4518] 33% | Training loss: 0.6874188227980744
Epoch: 11 | Iteration number: [1540/4518] 34% | Training loss: 0.6874253222694645
Epoch: 11 | Iteration number: [1550/4518] 34% | Training loss: 0.687427400812026
Epoch: 11 | Iteration number: [1560/4518] 34% | Training loss: 0.6874303586972066
Epoch: 11 | Iteration number: [1570/4518] 34% | Training loss: 0.6874272314606199
Epoch: 11 | Iteration number: [1580/4518] 34% | Training loss: 0.6874272958010058
Epoch: 11 | Iteration number: [1590/4518] 35% | Training loss: 0.6874327372829869
Epoch: 11 | Iteration number: [1600/4518] 35% | Training loss: 0.6874300313740969
Epoch: 11 | Iteration number: [1610/4518] 35% | Training loss: 0.6874297153135264
Epoch: 11 | Iteration number: [1620/4518] 35% | Training loss: 0.6874257755868229
Epoch: 11 | Iteration number: [1630/4518] 36% | Training loss: 0.6874254223027844
Epoch: 11 | Iteration number: [1640/4518] 36% | Training loss: 0.6874336961565948
Epoch: 11 | Iteration number: [1650/4518] 36% | Training loss: 0.6874256744890502
Epoch: 11 | Iteration number: [1660/4518] 36% | Training loss: 0.6874274144330657
Epoch: 11 | Iteration number: [1670/4518] 36% | Training loss: 0.6874205394776282
Epoch: 11 | Iteration number: [1680/4518] 37% | Training loss: 0.6874201747987951
Epoch: 11 | Iteration number: [1690/4518] 37% | Training loss: 0.6874180542646781
Epoch: 11 | Iteration number: [1700/4518] 37% | Training loss: 0.6874076349244398
Epoch: 11 | Iteration number: [1710/4518] 37% | Training loss: 0.6874038444973571
Epoch: 11 | Iteration number: [1720/4518] 38% | Training loss: 0.6874080295826114
Epoch: 11 | Iteration number: [1730/4518] 38% | Training loss: 0.6874065146280851
Epoch: 11 | Iteration number: [1740/4518] 38% | Training loss: 0.6874046506895416
Epoch: 11 | Iteration number: [1750/4518] 38% | Training loss: 0.6873982939038958
Epoch: 11 | Iteration number: [1760/4518] 38% | Training loss: 0.6873948807066137
Epoch: 11 | Iteration number: [1770/4518] 39% | Training loss: 0.6873975823154557
Epoch: 11 | Iteration number: [1780/4518] 39% | Training loss: 0.6873950991737708
Epoch: 11 | Iteration number: [1790/4518] 39% | Training loss: 0.6873904029750291
Epoch: 11 | Iteration number: [1800/4518] 39% | Training loss: 0.6873827573988173
Epoch: 11 | Iteration number: [1810/4518] 40% | Training loss: 0.6873803400861624
Epoch: 11 | Iteration number: [1820/4518] 40% | Training loss: 0.6873752124689437
Epoch: 11 | Iteration number: [1830/4518] 40% | Training loss: 0.6873751932480296
Epoch: 11 | Iteration number: [1840/4518] 40% | Training loss: 0.6873753348446411
Epoch: 11 | Iteration number: [1850/4518] 40% | Training loss: 0.687374415880925
Epoch: 11 | Iteration number: [1860/4518] 41% | Training loss: 0.6873684292518965
Epoch: 11 | Iteration number: [1870/4518] 41% | Training loss: 0.6873598675039363
Epoch: 11 | Iteration number: [1880/4518] 41% | Training loss: 0.6873612209837487
Epoch: 11 | Iteration number: [1890/4518] 41% | Training loss: 0.6873610630552605
Epoch: 11 | Iteration number: [1900/4518] 42% | Training loss: 0.6873546860719982
Epoch: 11 | Iteration number: [1910/4518] 42% | Training loss: 0.6873552386673333
Epoch: 11 | Iteration number: [1920/4518] 42% | Training loss: 0.687349398030589
Epoch: 11 | Iteration number: [1930/4518] 42% | Training loss: 0.6873445530011864
Epoch: 11 | Iteration number: [1940/4518] 42% | Training loss: 0.68733605373766
Epoch: 11 | Iteration number: [1950/4518] 43% | Training loss: 0.6873284366803292
Epoch: 11 | Iteration number: [1960/4518] 43% | Training loss: 0.687326457001725
Epoch: 11 | Iteration number: [1970/4518] 43% | Training loss: 0.6873254128519048
Epoch: 11 | Iteration number: [1980/4518] 43% | Training loss: 0.6873211033115483
Epoch: 11 | Iteration number: [1990/4518] 44% | Training loss: 0.6873199137910526
Epoch: 11 | Iteration number: [2000/4518] 44% | Training loss: 0.6873174166679382
Epoch: 11 | Iteration number: [2010/4518] 44% | Training loss: 0.6873106799908538
Epoch: 11 | Iteration number: [2020/4518] 44% | Training loss: 0.6873105831960641
Epoch: 11 | Iteration number: [2030/4518] 44% | Training loss: 0.6873055713223706
Epoch: 11 | Iteration number: [2040/4518] 45% | Training loss: 0.687306040057949
Epoch: 11 | Iteration number: [2050/4518] 45% | Training loss: 0.687305785301255
Epoch: 11 | Iteration number: [2060/4518] 45% | Training loss: 0.6873063037985737
Epoch: 11 | Iteration number: [2070/4518] 45% | Training loss: 0.6873073379486655
Epoch: 11 | Iteration number: [2080/4518] 46% | Training loss: 0.687305263028695
Epoch: 11 | Iteration number: [2090/4518] 46% | Training loss: 0.6873034357739407
Epoch: 11 | Iteration number: [2100/4518] 46% | Training loss: 0.6873049137138185
Epoch: 11 | Iteration number: [2110/4518] 46% | Training loss: 0.6873049405796268
Epoch: 11 | Iteration number: [2120/4518] 46% | Training loss: 0.6873026143548624
Epoch: 11 | Iteration number: [2130/4518] 47% | Training loss: 0.6873014725429911
Epoch: 11 | Iteration number: [2140/4518] 47% | Training loss: 0.6873028429590653
Epoch: 11 | Iteration number: [2150/4518] 47% | Training loss: 0.6873002640868342
Epoch: 11 | Iteration number: [2160/4518] 47% | Training loss: 0.6873016413991098
Epoch: 11 | Iteration number: [2170/4518] 48% | Training loss: 0.6873058791534142
Epoch: 11 | Iteration number: [2180/4518] 48% | Training loss: 0.687300795781503
Epoch: 11 | Iteration number: [2190/4518] 48% | Training loss: 0.6872960291768863
Epoch: 11 | Iteration number: [2200/4518] 48% | Training loss: 0.687295462299477
Epoch: 11 | Iteration number: [2210/4518] 48% | Training loss: 0.6872985080356512
Epoch: 11 | Iteration number: [2220/4518] 49% | Training loss: 0.6873029700807622
Epoch: 11 | Iteration number: [2230/4518] 49% | Training loss: 0.6872905458570061
Epoch: 11 | Iteration number: [2240/4518] 49% | Training loss: 0.6872869834569948
Epoch: 11 | Iteration number: [2250/4518] 49% | Training loss: 0.6872832834720611
Epoch: 11 | Iteration number: [2260/4518] 50% | Training loss: 0.6872810968519312
Epoch: 11 | Iteration number: [2270/4518] 50% | Training loss: 0.68728435653947
Epoch: 11 | Iteration number: [2280/4518] 50% | Training loss: 0.68728005099192
Epoch: 11 | Iteration number: [2290/4518] 50% | Training loss: 0.6872748749745464
Epoch: 11 | Iteration number: [2300/4518] 50% | Training loss: 0.6872687351962794
Epoch: 11 | Iteration number: [2310/4518] 51% | Training loss: 0.6872649760473342
Epoch: 11 | Iteration number: [2320/4518] 51% | Training loss: 0.6872628425472769
Epoch: 11 | Iteration number: [2330/4518] 51% | Training loss: 0.6872612885395345
Epoch: 11 | Iteration number: [2340/4518] 51% | Training loss: 0.6872590372705052
Epoch: 11 | Iteration number: [2350/4518] 52% | Training loss: 0.6872589007083406
Epoch: 11 | Iteration number: [2360/4518] 52% | Training loss: 0.6872591127278441
Epoch: 11 | Iteration number: [2370/4518] 52% | Training loss: 0.6872610970388485
Epoch: 11 | Iteration number: [2380/4518] 52% | Training loss: 0.6872627194689102
Epoch: 11 | Iteration number: [2390/4518] 52% | Training loss: 0.6872647963058999
Epoch: 11 | Iteration number: [2400/4518] 53% | Training loss: 0.6872577275087436
Epoch: 11 | Iteration number: [2410/4518] 53% | Training loss: 0.6872564800547366
Epoch: 11 | Iteration number: [2420/4518] 53% | Training loss: 0.6872528372963598
Epoch: 11 | Iteration number: [2430/4518] 53% | Training loss: 0.687247347831726
Epoch: 11 | Iteration number: [2440/4518] 54% | Training loss: 0.6872423720408658
Epoch: 11 | Iteration number: [2450/4518] 54% | Training loss: 0.6872444653267763
Epoch: 11 | Iteration number: [2460/4518] 54% | Training loss: 0.6872425218907798
Epoch: 11 | Iteration number: [2470/4518] 54% | Training loss: 0.6872350527207378
Epoch: 11 | Iteration number: [2480/4518] 54% | Training loss: 0.6872374580512124
Epoch: 11 | Iteration number: [2490/4518] 55% | Training loss: 0.6872381485609644
Epoch: 11 | Iteration number: [2500/4518] 55% | Training loss: 0.6872388554573059
Epoch: 11 | Iteration number: [2510/4518] 55% | Training loss: 0.6872385373153534
Epoch: 11 | Iteration number: [2520/4518] 55% | Training loss: 0.687236227426264
Epoch: 11 | Iteration number: [2530/4518] 55% | Training loss: 0.6872321873549887
Epoch: 11 | Iteration number: [2540/4518] 56% | Training loss: 0.6872296179373433
Epoch: 11 | Iteration number: [2550/4518] 56% | Training loss: 0.6872324824566934
Epoch: 11 | Iteration number: [2560/4518] 56% | Training loss: 0.6872340241679922
Epoch: 11 | Iteration number: [2570/4518] 56% | Training loss: 0.687230479879602
Epoch: 11 | Iteration number: [2580/4518] 57% | Training loss: 0.6872342830942583
Epoch: 11 | Iteration number: [2590/4518] 57% | Training loss: 0.6872299467504714
Epoch: 11 | Iteration number: [2600/4518] 57% | Training loss: 0.6872344721968358
Epoch: 11 | Iteration number: [2610/4518] 57% | Training loss: 0.6872314709584831
Epoch: 11 | Iteration number: [2620/4518] 57% | Training loss: 0.6872313975832844
Epoch: 11 | Iteration number: [2630/4518] 58% | Training loss: 0.6872316569883107
Epoch: 11 | Iteration number: [2640/4518] 58% | Training loss: 0.6872299865113967
Epoch: 11 | Iteration number: [2650/4518] 58% | Training loss: 0.6872295262228768
Epoch: 11 | Iteration number: [2660/4518] 58% | Training loss: 0.687228194775438
Epoch: 11 | Iteration number: [2670/4518] 59% | Training loss: 0.6872224853056647
Epoch: 11 | Iteration number: [2680/4518] 59% | Training loss: 0.6872223197746633
Epoch: 11 | Iteration number: [2690/4518] 59% | Training loss: 0.6872214134741007
Epoch: 11 | Iteration number: [2700/4518] 59% | Training loss: 0.6872207500757994
Epoch: 11 | Iteration number: [2710/4518] 59% | Training loss: 0.6872214341075658
Epoch: 11 | Iteration number: [2720/4518] 60% | Training loss: 0.6872205231996144
Epoch: 11 | Iteration number: [2730/4518] 60% | Training loss: 0.6872223830048418
Epoch: 11 | Iteration number: [2740/4518] 60% | Training loss: 0.6872233018170308
Epoch: 11 | Iteration number: [2750/4518] 60% | Training loss: 0.6872255589528518
Epoch: 11 | Iteration number: [2760/4518] 61% | Training loss: 0.687227153821268
Epoch: 11 | Iteration number: [2770/4518] 61% | Training loss: 0.687226586651716
Epoch: 11 | Iteration number: [2780/4518] 61% | Training loss: 0.68722571824952
Epoch: 11 | Iteration number: [2790/4518] 61% | Training loss: 0.6872267275728206
Epoch: 11 | Iteration number: [2800/4518] 61% | Training loss: 0.68723014490945
Epoch: 11 | Iteration number: [2810/4518] 62% | Training loss: 0.687228585053169
Epoch: 11 | Iteration number: [2820/4518] 62% | Training loss: 0.6872259595715408
Epoch: 11 | Iteration number: [2830/4518] 62% | Training loss: 0.687225184529072
Epoch: 11 | Iteration number: [2840/4518] 62% | Training loss: 0.687220093209139
Epoch: 11 | Iteration number: [2850/4518] 63% | Training loss: 0.6872167693941217
Epoch: 11 | Iteration number: [2860/4518] 63% | Training loss: 0.6872184227188151
Epoch: 11 | Iteration number: [2870/4518] 63% | Training loss: 0.6872158088958222
Epoch: 11 | Iteration number: [2880/4518] 63% | Training loss: 0.6872180830480323
Epoch: 11 | Iteration number: [2890/4518] 63% | Training loss: 0.6872191976304698
Epoch: 11 | Iteration number: [2900/4518] 64% | Training loss: 0.6872182838670139
Epoch: 11 | Iteration number: [2910/4518] 64% | Training loss: 0.6872131700777926
Epoch: 11 | Iteration number: [2920/4518] 64% | Training loss: 0.6872162017511995
Epoch: 11 | Iteration number: [2930/4518] 64% | Training loss: 0.6872128500263032
Epoch: 11 | Iteration number: [2940/4518] 65% | Training loss: 0.6872071345444439
Epoch: 11 | Iteration number: [2950/4518] 65% | Training loss: 0.687203271712287
Epoch: 11 | Iteration number: [2960/4518] 65% | Training loss: 0.6872033554154473
Epoch: 11 | Iteration number: [2970/4518] 65% | Training loss: 0.6872033134855405
Epoch: 11 | Iteration number: [2980/4518] 65% | Training loss: 0.6872021851323595
Epoch: 11 | Iteration number: [2990/4518] 66% | Training loss: 0.6872034268435029
Epoch: 11 | Iteration number: [3000/4518] 66% | Training loss: 0.6872054982384046
Epoch: 11 | Iteration number: [3010/4518] 66% | Training loss: 0.6872023510972527
Epoch: 11 | Iteration number: [3020/4518] 66% | Training loss: 0.6872000180924965
Epoch: 11 | Iteration number: [3030/4518] 67% | Training loss: 0.6872007614118432
Epoch: 11 | Iteration number: [3040/4518] 67% | Training loss: 0.6871953777968883
Epoch: 11 | Iteration number: [3050/4518] 67% | Training loss: 0.6871955771719823
Epoch: 11 | Iteration number: [3060/4518] 67% | Training loss: 0.6871936703819076
Epoch: 11 | Iteration number: [3070/4518] 67% | Training loss: 0.6871919701076098
Epoch: 11 | Iteration number: [3080/4518] 68% | Training loss: 0.6871931509731652
Epoch: 11 | Iteration number: [3090/4518] 68% | Training loss: 0.6871926494015074
Epoch: 11 | Iteration number: [3100/4518] 68% | Training loss: 0.6871948942061393
Epoch: 11 | Iteration number: [3110/4518] 68% | Training loss: 0.6871927113203373
Epoch: 11 | Iteration number: [3120/4518] 69% | Training loss: 0.6871928170132331
Epoch: 11 | Iteration number: [3130/4518] 69% | Training loss: 0.6871930934750615
Epoch: 11 | Iteration number: [3140/4518] 69% | Training loss: 0.6871893784422783
Epoch: 11 | Iteration number: [3150/4518] 69% | Training loss: 0.6871876372231378
Epoch: 11 | Iteration number: [3160/4518] 69% | Training loss: 0.6871888975742497
Epoch: 11 | Iteration number: [3170/4518] 70% | Training loss: 0.6871883525457292
Epoch: 11 | Iteration number: [3180/4518] 70% | Training loss: 0.6871889030970867
Epoch: 11 | Iteration number: [3190/4518] 70% | Training loss: 0.68719070389353
Epoch: 11 | Iteration number: [3200/4518] 70% | Training loss: 0.6871942911855876
Epoch: 11 | Iteration number: [3210/4518] 71% | Training loss: 0.6871940532577372
Epoch: 11 | Iteration number: [3220/4518] 71% | Training loss: 0.6871950046986527
Epoch: 11 | Iteration number: [3230/4518] 71% | Training loss: 0.6871904129029797
Epoch: 11 | Iteration number: [3240/4518] 71% | Training loss: 0.6871857360189344
Epoch: 11 | Iteration number: [3250/4518] 71% | Training loss: 0.6871818144321442
Epoch: 11 | Iteration number: [3260/4518] 72% | Training loss: 0.6871801960687696
Epoch: 11 | Iteration number: [3270/4518] 72% | Training loss: 0.6871803128755786
Epoch: 11 | Iteration number: [3280/4518] 72% | Training loss: 0.6871822774955412
Epoch: 11 | Iteration number: [3290/4518] 72% | Training loss: 0.6871830013747635
Epoch: 11 | Iteration number: [3300/4518] 73% | Training loss: 0.6871815702590075
Epoch: 11 | Iteration number: [3310/4518] 73% | Training loss: 0.6871833657930264
Epoch: 11 | Iteration number: [3320/4518] 73% | Training loss: 0.6871830575616963
Epoch: 11 | Iteration number: [3330/4518] 73% | Training loss: 0.6871812066874347
Epoch: 11 | Iteration number: [3340/4518] 73% | Training loss: 0.6871836030554629
Epoch: 11 | Iteration number: [3350/4518] 74% | Training loss: 0.687181766424606
Epoch: 11 | Iteration number: [3360/4518] 74% | Training loss: 0.687180811078066
Epoch: 11 | Iteration number: [3370/4518] 74% | Training loss: 0.6871797252125839
Epoch: 11 | Iteration number: [3380/4518] 74% | Training loss: 0.6871787706070398
Epoch: 11 | Iteration number: [3390/4518] 75% | Training loss: 0.6871771789757551
Epoch: 11 | Iteration number: [3400/4518] 75% | Training loss: 0.687178658720325
Epoch: 11 | Iteration number: [3410/4518] 75% | Training loss: 0.6871799132865894
Epoch: 11 | Iteration number: [3420/4518] 75% | Training loss: 0.6871796633416449
Epoch: 11 | Iteration number: [3430/4518] 75% | Training loss: 0.6871756069861765
Epoch: 11 | Iteration number: [3440/4518] 76% | Training loss: 0.6871758190005325
Epoch: 11 | Iteration number: [3450/4518] 76% | Training loss: 0.6871747925834379
Epoch: 11 | Iteration number: [3460/4518] 76% | Training loss: 0.687172333250156
Epoch: 11 | Iteration number: [3470/4518] 76% | Training loss: 0.6871742185151543
Epoch: 11 | Iteration number: [3480/4518] 77% | Training loss: 0.6871762424022302
Epoch: 11 | Iteration number: [3490/4518] 77% | Training loss: 0.6871771227152095
Epoch: 11 | Iteration number: [3500/4518] 77% | Training loss: 0.6871801076275962
Epoch: 11 | Iteration number: [3510/4518] 77% | Training loss: 0.6871814650687736
Epoch: 11 | Iteration number: [3520/4518] 77% | Training loss: 0.6871821716427803
Epoch: 11 | Iteration number: [3530/4518] 78% | Training loss: 0.6871798454533218
Epoch: 11 | Iteration number: [3540/4518] 78% | Training loss: 0.6871792022117788
Epoch: 11 | Iteration number: [3550/4518] 78% | Training loss: 0.6871801686958527
Epoch: 11 | Iteration number: [3560/4518] 78% | Training loss: 0.6871787855296992
Epoch: 11 | Iteration number: [3570/4518] 79% | Training loss: 0.6871792387561638
Epoch: 11 | Iteration number: [3580/4518] 79% | Training loss: 0.6871845736350427
Epoch: 11 | Iteration number: [3590/4518] 79% | Training loss: 0.6871845068539749
Epoch: 11 | Iteration number: [3600/4518] 79% | Training loss: 0.6871829776134756
Epoch: 11 | Iteration number: [3610/4518] 79% | Training loss: 0.6871840798458564
Epoch: 11 | Iteration number: [3620/4518] 80% | Training loss: 0.6871820035889662
Epoch: 11 | Iteration number: [3630/4518] 80% | Training loss: 0.6871828426506894
Epoch: 11 | Iteration number: [3640/4518] 80% | Training loss: 0.6871834507355323
Epoch: 11 | Iteration number: [3650/4518] 80% | Training loss: 0.6871828771943915
Epoch: 11 | Iteration number: [3660/4518] 81% | Training loss: 0.6871794676194426
Epoch: 11 | Iteration number: [3670/4518] 81% | Training loss: 0.687179332695475
Epoch: 11 | Iteration number: [3680/4518] 81% | Training loss: 0.6871839479097853
Epoch: 11 | Iteration number: [3690/4518] 81% | Training loss: 0.6871811086407845
Epoch: 11 | Iteration number: [3700/4518] 81% | Training loss: 0.687183852517927
Epoch: 11 | Iteration number: [3710/4518] 82% | Training loss: 0.6871825425772654
Epoch: 11 | Iteration number: [3720/4518] 82% | Training loss: 0.6871820976336797
Epoch: 11 | Iteration number: [3730/4518] 82% | Training loss: 0.6871792648177364
Epoch: 11 | Iteration number: [3740/4518] 82% | Training loss: 0.6871815754130562
Epoch: 11 | Iteration number: [3750/4518] 83% | Training loss: 0.687181050825119
Epoch: 11 | Iteration number: [3760/4518] 83% | Training loss: 0.6871793389954466
Epoch: 11 | Iteration number: [3770/4518] 83% | Training loss: 0.6871796024414841
Epoch: 11 | Iteration number: [3780/4518] 83% | Training loss: 0.6871761963323311
Epoch: 11 | Iteration number: [3790/4518] 83% | Training loss: 0.6871748105045359
Epoch: 11 | Iteration number: [3800/4518] 84% | Training loss: 0.6871764624118805
Epoch: 11 | Iteration number: [3810/4518] 84% | Training loss: 0.6871746334034627
Epoch: 11 | Iteration number: [3820/4518] 84% | Training loss: 0.6871748146742426
Epoch: 11 | Iteration number: [3830/4518] 84% | Training loss: 0.6871752263982986
Epoch: 11 | Iteration number: [3840/4518] 84% | Training loss: 0.6871724533848464
Epoch: 11 | Iteration number: [3850/4518] 85% | Training loss: 0.6871709977032302
Epoch: 11 | Iteration number: [3860/4518] 85% | Training loss: 0.6871687381378727
Epoch: 11 | Iteration number: [3870/4518] 85% | Training loss: 0.6871681414217296
Epoch: 11 | Iteration number: [3880/4518] 85% | Training loss: 0.6871669646390934
Epoch: 11 | Iteration number: [3890/4518] 86% | Training loss: 0.6871683964845761
Epoch: 11 | Iteration number: [3900/4518] 86% | Training loss: 0.6871675816254738
Epoch: 11 | Iteration number: [3910/4518] 86% | Training loss: 0.6871685834949279
Epoch: 11 | Iteration number: [3920/4518] 86% | Training loss: 0.6871661086015556
Epoch: 11 | Iteration number: [3930/4518] 86% | Training loss: 0.6871660079058194
Epoch: 11 | Iteration number: [3940/4518] 87% | Training loss: 0.6871658670871996
Epoch: 11 | Iteration number: [3950/4518] 87% | Training loss: 0.6871663678145107
Epoch: 11 | Iteration number: [3960/4518] 87% | Training loss: 0.6871667914769867
Epoch: 11 | Iteration number: [3970/4518] 87% | Training loss: 0.6871654459751523
Epoch: 11 | Iteration number: [3980/4518] 88% | Training loss: 0.6871618637337756
Epoch: 11 | Iteration number: [3990/4518] 88% | Training loss: 0.6871597705628341
Epoch: 11 | Iteration number: [4000/4518] 88% | Training loss: 0.6871593293100595
Epoch: 11 | Iteration number: [4010/4518] 88% | Training loss: 0.6871587870721508
Epoch: 11 | Iteration number: [4020/4518] 88% | Training loss: 0.6871595178670551
Epoch: 11 | Iteration number: [4030/4518] 89% | Training loss: 0.6871565581255457
Epoch: 11 | Iteration number: [4040/4518] 89% | Training loss: 0.6871591671858683
Epoch: 11 | Iteration number: [4050/4518] 89% | Training loss: 0.6871602878158475
Epoch: 11 | Iteration number: [4060/4518] 89% | Training loss: 0.687160412857098
Epoch: 11 | Iteration number: [4070/4518] 90% | Training loss: 0.6871609706843514
Epoch: 11 | Iteration number: [4080/4518] 90% | Training loss: 0.6871578960734255
Epoch: 11 | Iteration number: [4090/4518] 90% | Training loss: 0.6871609573550795
Epoch: 11 | Iteration number: [4100/4518] 90% | Training loss: 0.6871592142669166
Epoch: 11 | Iteration number: [4110/4518] 90% | Training loss: 0.6871591024155165
Epoch: 11 | Iteration number: [4120/4518] 91% | Training loss: 0.6871588093273848
Epoch: 11 | Iteration number: [4130/4518] 91% | Training loss: 0.6871597617648127
Epoch: 11 | Iteration number: [4140/4518] 91% | Training loss: 0.6871607888579945
Epoch: 11 | Iteration number: [4150/4518] 91% | Training loss: 0.687161505768098
Epoch: 11 | Iteration number: [4160/4518] 92% | Training loss: 0.687161113651326
Epoch: 11 | Iteration number: [4170/4518] 92% | Training loss: 0.6871599197244759
Epoch: 11 | Iteration number: [4180/4518] 92% | Training loss: 0.6871585171758844
Epoch: 11 | Iteration number: [4190/4518] 92% | Training loss: 0.6871568229431754
Epoch: 11 | Iteration number: [4200/4518] 92% | Training loss: 0.6871547540170806
Epoch: 11 | Iteration number: [4210/4518] 93% | Training loss: 0.6871505642730097
Epoch: 11 | Iteration number: [4220/4518] 93% | Training loss: 0.6871496520901178
Epoch: 11 | Iteration number: [4230/4518] 93% | Training loss: 0.6871482037624287
Epoch: 11 | Iteration number: [4240/4518] 93% | Training loss: 0.6871499084357945
Epoch: 11 | Iteration number: [4250/4518] 94% | Training loss: 0.6871481428707347
Epoch: 11 | Iteration number: [4260/4518] 94% | Training loss: 0.6871471605530367
Epoch: 11 | Iteration number: [4270/4518] 94% | Training loss: 0.6871450392926326
Epoch: 11 | Iteration number: [4280/4518] 94% | Training loss: 0.6871474939111237
Epoch: 11 | Iteration number: [4290/4518] 94% | Training loss: 0.6871448337337076
Epoch: 11 | Iteration number: [4300/4518] 95% | Training loss: 0.6871431274469508
Epoch: 11 | Iteration number: [4310/4518] 95% | Training loss: 0.6871400688059646
Epoch: 11 | Iteration number: [4320/4518] 95% | Training loss: 0.6871424767706129
Epoch: 11 | Iteration number: [4330/4518] 95% | Training loss: 0.687142988371794
Epoch: 11 | Iteration number: [4340/4518] 96% | Training loss: 0.6871416389942169
Epoch: 11 | Iteration number: [4350/4518] 96% | Training loss: 0.6871400297236169
Epoch: 11 | Iteration number: [4360/4518] 96% | Training loss: 0.6871404321915513
Epoch: 11 | Iteration number: [4370/4518] 96% | Training loss: 0.6871392468429539
Epoch: 11 | Iteration number: [4380/4518] 96% | Training loss: 0.6871404878625043
Epoch: 11 | Iteration number: [4390/4518] 97% | Training loss: 0.687137712813184
Epoch: 11 | Iteration number: [4400/4518] 97% | Training loss: 0.6871364127641374
Epoch: 11 | Iteration number: [4410/4518] 97% | Training loss: 0.6871332940060536
Epoch: 11 | Iteration number: [4420/4518] 97% | Training loss: 0.687131000158474
Epoch: 11 | Iteration number: [4430/4518] 98% | Training loss: 0.68713134373822
Epoch: 11 | Iteration number: [4440/4518] 98% | Training loss: 0.68713217976394
Epoch: 11 | Iteration number: [4450/4518] 98% | Training loss: 0.68712991513563
Epoch: 11 | Iteration number: [4460/4518] 98% | Training loss: 0.6871292132032292
Epoch: 11 | Iteration number: [4470/4518] 98% | Training loss: 0.6871259087150796
Epoch: 11 | Iteration number: [4480/4518] 99% | Training loss: 0.6871247494726309
Epoch: 11 | Iteration number: [4490/4518] 99% | Training loss: 0.6871267353373275
Epoch: 11 | Iteration number: [4500/4518] 99% | Training loss: 0.6871278162664838
Epoch: 11 | Iteration number: [4510/4518] 99% | Training loss: 0.6871258830284068

 End of epoch: 11 | Train Loss: 0.6869707699632581 | Training Time: 643 

 End of epoch: 11 | Eval Loss: 0.6904181229824923 | Evaluating Time: 17 
Epoch: 12 | Iteration number: [10/4518] 0% | Training loss: 0.7547204375267029
Epoch: 12 | Iteration number: [20/4518] 0% | Training loss: 0.7211055308580399
Epoch: 12 | Iteration number: [30/4518] 0% | Training loss: 0.7099421381950378
Epoch: 12 | Iteration number: [40/4518] 0% | Training loss: 0.70395048558712
Epoch: 12 | Iteration number: [50/4518] 1% | Training loss: 0.7005615007877349
Epoch: 12 | Iteration number: [60/4518] 1% | Training loss: 0.6982329805692037
Epoch: 12 | Iteration number: [70/4518] 1% | Training loss: 0.6965693235397339
Epoch: 12 | Iteration number: [80/4518] 1% | Training loss: 0.6953459300100804
Epoch: 12 | Iteration number: [90/4518] 1% | Training loss: 0.6943929619259305
Epoch: 12 | Iteration number: [100/4518] 2% | Training loss: 0.6936939644813538
Epoch: 12 | Iteration number: [110/4518] 2% | Training loss: 0.6931569560007615
Epoch: 12 | Iteration number: [120/4518] 2% | Training loss: 0.6926359569032987
Epoch: 12 | Iteration number: [130/4518] 2% | Training loss: 0.692146686407236
Epoch: 12 | Iteration number: [140/4518] 3% | Training loss: 0.6917342816080366
Epoch: 12 | Iteration number: [150/4518] 3% | Training loss: 0.6913807654380798
Epoch: 12 | Iteration number: [160/4518] 3% | Training loss: 0.6911131605505944
Epoch: 12 | Iteration number: [170/4518] 3% | Training loss: 0.6907856488929075
Epoch: 12 | Iteration number: [180/4518] 3% | Training loss: 0.6905831373400159
Epoch: 12 | Iteration number: [190/4518] 4% | Training loss: 0.6903960739311419
Epoch: 12 | Iteration number: [200/4518] 4% | Training loss: 0.6902893528342247
Epoch: 12 | Iteration number: [210/4518] 4% | Training loss: 0.6901457846164704
Epoch: 12 | Iteration number: [220/4518] 4% | Training loss: 0.6899712175130844
Epoch: 12 | Iteration number: [230/4518] 5% | Training loss: 0.6898213044456813
Epoch: 12 | Iteration number: [240/4518] 5% | Training loss: 0.68974140137434
Epoch: 12 | Iteration number: [250/4518] 5% | Training loss: 0.689636029958725
Epoch: 12 | Iteration number: [260/4518] 5% | Training loss: 0.6895021477570901
Epoch: 12 | Iteration number: [270/4518] 5% | Training loss: 0.6893975911317048
Epoch: 12 | Iteration number: [280/4518] 6% | Training loss: 0.6893314301967621
Epoch: 12 | Iteration number: [290/4518] 6% | Training loss: 0.6892541484586123
Epoch: 12 | Iteration number: [300/4518] 6% | Training loss: 0.6891678396860759
Epoch: 12 | Iteration number: [310/4518] 6% | Training loss: 0.6890643915822429
Epoch: 12 | Iteration number: [320/4518] 7% | Training loss: 0.6889741463586688
Epoch: 12 | Iteration number: [330/4518] 7% | Training loss: 0.6888896458076709
Epoch: 12 | Iteration number: [340/4518] 7% | Training loss: 0.6888157774420346
Epoch: 12 | Iteration number: [350/4518] 7% | Training loss: 0.688757940701076
Epoch: 12 | Iteration number: [360/4518] 7% | Training loss: 0.6886871016687817
Epoch: 12 | Iteration number: [370/4518] 8% | Training loss: 0.6886329307749465
Epoch: 12 | Iteration number: [380/4518] 8% | Training loss: 0.6886343566994918
Epoch: 12 | Iteration number: [390/4518] 8% | Training loss: 0.6885704408853482
Epoch: 12 | Iteration number: [400/4518] 8% | Training loss: 0.6885235778987407
Epoch: 12 | Iteration number: [410/4518] 9% | Training loss: 0.688484157440139
Epoch: 12 | Iteration number: [420/4518] 9% | Training loss: 0.6884335627158483
Epoch: 12 | Iteration number: [430/4518] 9% | Training loss: 0.6883927817954574
Epoch: 12 | Iteration number: [440/4518] 9% | Training loss: 0.6883523145859892
Epoch: 12 | Iteration number: [450/4518] 9% | Training loss: 0.6883142615689172
Epoch: 12 | Iteration number: [460/4518] 10% | Training loss: 0.6882799143376558
Epoch: 12 | Iteration number: [470/4518] 10% | Training loss: 0.6882514655590057
Epoch: 12 | Iteration number: [480/4518] 10% | Training loss: 0.6882178840537866
Epoch: 12 | Iteration number: [490/4518] 10% | Training loss: 0.6881835617581192
Epoch: 12 | Iteration number: [500/4518] 11% | Training loss: 0.6881604073047638
Epoch: 12 | Iteration number: [510/4518] 11% | Training loss: 0.6881431047822915
Epoch: 12 | Iteration number: [520/4518] 11% | Training loss: 0.6880952909588813
Epoch: 12 | Iteration number: [530/4518] 11% | Training loss: 0.688071322441101
Epoch: 12 | Iteration number: [540/4518] 11% | Training loss: 0.688055110750375
Epoch: 12 | Iteration number: [550/4518] 12% | Training loss: 0.688047889362682
Epoch: 12 | Iteration number: [560/4518] 12% | Training loss: 0.6880250574222633
Epoch: 12 | Iteration number: [570/4518] 12% | Training loss: 0.6879780986852814
Epoch: 12 | Iteration number: [580/4518] 12% | Training loss: 0.6879604641733499
Epoch: 12 | Iteration number: [590/4518] 13% | Training loss: 0.687927947913186
Epoch: 12 | Iteration number: [600/4518] 13% | Training loss: 0.687906938890616
Epoch: 12 | Iteration number: [610/4518] 13% | Training loss: 0.6879036811531567
Epoch: 12 | Iteration number: [620/4518] 13% | Training loss: 0.6878916642358226
Epoch: 12 | Iteration number: [630/4518] 13% | Training loss: 0.687875399324629
Epoch: 12 | Iteration number: [640/4518] 14% | Training loss: 0.6878598542883992
Epoch: 12 | Iteration number: [650/4518] 14% | Training loss: 0.6878568630952101
Epoch: 12 | Iteration number: [660/4518] 14% | Training loss: 0.687846505280697
Epoch: 12 | Iteration number: [670/4518] 14% | Training loss: 0.6878360963579434
Epoch: 12 | Iteration number: [680/4518] 15% | Training loss: 0.6878150558646987
Epoch: 12 | Iteration number: [690/4518] 15% | Training loss: 0.6877915888592817
Epoch: 12 | Iteration number: [700/4518] 15% | Training loss: 0.6877581062487194
Epoch: 12 | Iteration number: [710/4518] 15% | Training loss: 0.6877406071609174
Epoch: 12 | Iteration number: [720/4518] 15% | Training loss: 0.6877325288123555
Epoch: 12 | Iteration number: [730/4518] 16% | Training loss: 0.6877213854495793
Epoch: 12 | Iteration number: [740/4518] 16% | Training loss: 0.6876992064553338
Epoch: 12 | Iteration number: [750/4518] 16% | Training loss: 0.6876812336444855
Epoch: 12 | Iteration number: [760/4518] 16% | Training loss: 0.6876702144742012
Epoch: 12 | Iteration number: [770/4518] 17% | Training loss: 0.6876473071513238
Epoch: 12 | Iteration number: [780/4518] 17% | Training loss: 0.6876313480047079
Epoch: 12 | Iteration number: [790/4518] 17% | Training loss: 0.6876247028761272
Epoch: 12 | Iteration number: [800/4518] 17% | Training loss: 0.6876185444742441
Epoch: 12 | Iteration number: [810/4518] 17% | Training loss: 0.6876229292816586
Epoch: 12 | Iteration number: [820/4518] 18% | Training loss: 0.6876309671779958
Epoch: 12 | Iteration number: [830/4518] 18% | Training loss: 0.6876242828656391
Epoch: 12 | Iteration number: [840/4518] 18% | Training loss: 0.6876191007239478
Epoch: 12 | Iteration number: [850/4518] 18% | Training loss: 0.687619718172971
Epoch: 12 | Iteration number: [860/4518] 19% | Training loss: 0.6876174777053123
Epoch: 12 | Iteration number: [870/4518] 19% | Training loss: 0.6876070296627351
Epoch: 12 | Iteration number: [880/4518] 19% | Training loss: 0.6875944182276725
Epoch: 12 | Iteration number: [890/4518] 19% | Training loss: 0.6875850778617216
Epoch: 12 | Iteration number: [900/4518] 19% | Training loss: 0.6875870605972079
Epoch: 12 | Iteration number: [910/4518] 20% | Training loss: 0.6875849172309205
Epoch: 12 | Iteration number: [920/4518] 20% | Training loss: 0.6875863042214643
Epoch: 12 | Iteration number: [930/4518] 20% | Training loss: 0.6875766986800779
Epoch: 12 | Iteration number: [940/4518] 20% | Training loss: 0.6875838714077117
Epoch: 12 | Iteration number: [950/4518] 21% | Training loss: 0.6875806977246937
Epoch: 12 | Iteration number: [960/4518] 21% | Training loss: 0.6875816142186523
Epoch: 12 | Iteration number: [970/4518] 21% | Training loss: 0.6875816167015391
Epoch: 12 | Iteration number: [980/4518] 21% | Training loss: 0.6875871167499192
Epoch: 12 | Iteration number: [990/4518] 21% | Training loss: 0.6875829156601068
Epoch: 12 | Iteration number: [1000/4518] 22% | Training loss: 0.6875696395635604
Epoch: 12 | Iteration number: [1010/4518] 22% | Training loss: 0.6875687790979254
Epoch: 12 | Iteration number: [1020/4518] 22% | Training loss: 0.6875794902736065
Epoch: 12 | Iteration number: [1030/4518] 22% | Training loss: 0.6875872248006099
Epoch: 12 | Iteration number: [1040/4518] 23% | Training loss: 0.6875894120106331
Epoch: 12 | Iteration number: [1050/4518] 23% | Training loss: 0.6875894749164582
Epoch: 12 | Iteration number: [1060/4518] 23% | Training loss: 0.6875781323549882
Epoch: 12 | Iteration number: [1070/4518] 23% | Training loss: 0.6875747191014691
Epoch: 12 | Iteration number: [1080/4518] 23% | Training loss: 0.6875658506044635
Epoch: 12 | Iteration number: [1090/4518] 24% | Training loss: 0.6875604023627185
Epoch: 12 | Iteration number: [1100/4518] 24% | Training loss: 0.6875499882481315
Epoch: 12 | Iteration number: [1110/4518] 24% | Training loss: 0.6875400250022475
Epoch: 12 | Iteration number: [1120/4518] 24% | Training loss: 0.6875369819147247
Epoch: 12 | Iteration number: [1130/4518] 25% | Training loss: 0.6875387023508022
Epoch: 12 | Iteration number: [1140/4518] 25% | Training loss: 0.687528871130525
Epoch: 12 | Iteration number: [1150/4518] 25% | Training loss: 0.6875233102881391
Epoch: 12 | Iteration number: [1160/4518] 25% | Training loss: 0.6875192428971159
Epoch: 12 | Iteration number: [1170/4518] 25% | Training loss: 0.6875021781676854
Epoch: 12 | Iteration number: [1180/4518] 26% | Training loss: 0.6875072221634752
Epoch: 12 | Iteration number: [1190/4518] 26% | Training loss: 0.6875083679912471
Epoch: 12 | Iteration number: [1200/4518] 26% | Training loss: 0.6875110172231992
Epoch: 12 | Iteration number: [1210/4518] 26% | Training loss: 0.6874955475822954
Epoch: 12 | Iteration number: [1220/4518] 27% | Training loss: 0.6874948755150936
Epoch: 12 | Iteration number: [1230/4518] 27% | Training loss: 0.6874858467074914
Epoch: 12 | Iteration number: [1240/4518] 27% | Training loss: 0.6874721710239687
Epoch: 12 | Iteration number: [1250/4518] 27% | Training loss: 0.687462166929245
Epoch: 12 | Iteration number: [1260/4518] 27% | Training loss: 0.6874570676258632
Epoch: 12 | Iteration number: [1270/4518] 28% | Training loss: 0.6874501180461072
Epoch: 12 | Iteration number: [1280/4518] 28% | Training loss: 0.6874422704335302
Epoch: 12 | Iteration number: [1290/4518] 28% | Training loss: 0.6874339395253233
Epoch: 12 | Iteration number: [1300/4518] 28% | Training loss: 0.6874262980314402
Epoch: 12 | Iteration number: [1310/4518] 28% | Training loss: 0.6874150863130584
Epoch: 12 | Iteration number: [1320/4518] 29% | Training loss: 0.6874158696243258
Epoch: 12 | Iteration number: [1330/4518] 29% | Training loss: 0.687405925989151
Epoch: 12 | Iteration number: [1340/4518] 29% | Training loss: 0.6874126384507364
Epoch: 12 | Iteration number: [1350/4518] 29% | Training loss: 0.6874167754473509
Epoch: 12 | Iteration number: [1360/4518] 30% | Training loss: 0.6874209644163356
Epoch: 12 | Iteration number: [1370/4518] 30% | Training loss: 0.6874206000871032
Epoch: 12 | Iteration number: [1380/4518] 30% | Training loss: 0.6874194817266602
Epoch: 12 | Iteration number: [1390/4518] 30% | Training loss: 0.6874126005515778
Epoch: 12 | Iteration number: [1400/4518] 30% | Training loss: 0.6874165792124612
Epoch: 12 | Iteration number: [1410/4518] 31% | Training loss: 0.6874127609509948
Epoch: 12 | Iteration number: [1420/4518] 31% | Training loss: 0.6874146317931967
Epoch: 12 | Iteration number: [1430/4518] 31% | Training loss: 0.6873997443205827
Epoch: 12 | Iteration number: [1440/4518] 31% | Training loss: 0.6873902195029788
Epoch: 12 | Iteration number: [1450/4518] 32% | Training loss: 0.6873955713058341
Epoch: 12 | Iteration number: [1460/4518] 32% | Training loss: 0.6873892707367466
Epoch: 12 | Iteration number: [1470/4518] 32% | Training loss: 0.6873742925066526
Epoch: 12 | Iteration number: [1480/4518] 32% | Training loss: 0.6873829780398188
Epoch: 12 | Iteration number: [1490/4518] 32% | Training loss: 0.6873850832049478
Epoch: 12 | Iteration number: [1500/4518] 33% | Training loss: 0.6873866577148438
Epoch: 12 | Iteration number: [1510/4518] 33% | Training loss: 0.6873980564392166
Epoch: 12 | Iteration number: [1520/4518] 33% | Training loss: 0.6873952174265133
Epoch: 12 | Iteration number: [1530/4518] 33% | Training loss: 0.6873978242375492
Epoch: 12 | Iteration number: [1540/4518] 34% | Training loss: 0.6873877288459184
Epoch: 12 | Iteration number: [1550/4518] 34% | Training loss: 0.6873878828940853
Epoch: 12 | Iteration number: [1560/4518] 34% | Training loss: 0.68738302000058
Epoch: 12 | Iteration number: [1570/4518] 34% | Training loss: 0.6873788362855364
Epoch: 12 | Iteration number: [1580/4518] 34% | Training loss: 0.6873724750702894
Epoch: 12 | Iteration number: [1590/4518] 35% | Training loss: 0.6873704833429565
Epoch: 12 | Iteration number: [1600/4518] 35% | Training loss: 0.6873591310158372
Epoch: 12 | Iteration number: [1610/4518] 35% | Training loss: 0.6873611345424415
Epoch: 12 | Iteration number: [1620/4518] 35% | Training loss: 0.6873622489564213
Epoch: 12 | Iteration number: [1630/4518] 36% | Training loss: 0.6873470761658955
Epoch: 12 | Iteration number: [1640/4518] 36% | Training loss: 0.6873469065965676
Epoch: 12 | Iteration number: [1650/4518] 36% | Training loss: 0.6873474178892194
Epoch: 12 | Iteration number: [1660/4518] 36% | Training loss: 0.6873385983777334
Epoch: 12 | Iteration number: [1670/4518] 36% | Training loss: 0.6873409567835802
Epoch: 12 | Iteration number: [1680/4518] 37% | Training loss: 0.6873400738196713
Epoch: 12 | Iteration number: [1690/4518] 37% | Training loss: 0.6873370211858015
Epoch: 12 | Iteration number: [1700/4518] 37% | Training loss: 0.6873389366444419
Epoch: 12 | Iteration number: [1710/4518] 37% | Training loss: 0.6873477089823338
Epoch: 12 | Iteration number: [1720/4518] 38% | Training loss: 0.6873460695147514
Epoch: 12 | Iteration number: [1730/4518] 38% | Training loss: 0.68734119510375
Epoch: 12 | Iteration number: [1740/4518] 38% | Training loss: 0.6873451260657146
Epoch: 12 | Iteration number: [1750/4518] 38% | Training loss: 0.6873377648762294
Epoch: 12 | Iteration number: [1760/4518] 38% | Training loss: 0.6873356276615099
Epoch: 12 | Iteration number: [1770/4518] 39% | Training loss: 0.6873352269668364
Epoch: 12 | Iteration number: [1780/4518] 39% | Training loss: 0.6873297858104277
Epoch: 12 | Iteration number: [1790/4518] 39% | Training loss: 0.6873210038885724
Epoch: 12 | Iteration number: [1800/4518] 39% | Training loss: 0.6873183175590303
Epoch: 12 | Iteration number: [1810/4518] 40% | Training loss: 0.6873176898086927
Epoch: 12 | Iteration number: [1820/4518] 40% | Training loss: 0.6873111640031521
Epoch: 12 | Iteration number: [1830/4518] 40% | Training loss: 0.687301996529428
Epoch: 12 | Iteration number: [1840/4518] 40% | Training loss: 0.6873007425147554
Epoch: 12 | Iteration number: [1850/4518] 40% | Training loss: 0.6872928262401271
Epoch: 12 | Iteration number: [1860/4518] 41% | Training loss: 0.6872887642473303
Epoch: 12 | Iteration number: [1870/4518] 41% | Training loss: 0.6872984743054538
Epoch: 12 | Iteration number: [1880/4518] 41% | Training loss: 0.6872981487753543
Epoch: 12 | Iteration number: [1890/4518] 41% | Training loss: 0.6872958074171076
Epoch: 12 | Iteration number: [1900/4518] 42% | Training loss: 0.6872931398216047
Epoch: 12 | Iteration number: [1910/4518] 42% | Training loss: 0.6872924856178424
Epoch: 12 | Iteration number: [1920/4518] 42% | Training loss: 0.6872963166795671
Epoch: 12 | Iteration number: [1930/4518] 42% | Training loss: 0.6873012543342274
Epoch: 12 | Iteration number: [1940/4518] 42% | Training loss: 0.6872953825697456
Epoch: 12 | Iteration number: [1950/4518] 43% | Training loss: 0.6872925586272509
Epoch: 12 | Iteration number: [1960/4518] 43% | Training loss: 0.6872936163629805
Epoch: 12 | Iteration number: [1970/4518] 43% | Training loss: 0.6872926062738834
Epoch: 12 | Iteration number: [1980/4518] 43% | Training loss: 0.6872855013368105
Epoch: 12 | Iteration number: [1990/4518] 44% | Training loss: 0.6872841643029122
Epoch: 12 | Iteration number: [2000/4518] 44% | Training loss: 0.6872848754227161
Epoch: 12 | Iteration number: [2010/4518] 44% | Training loss: 0.6872874026571341
Epoch: 12 | Iteration number: [2020/4518] 44% | Training loss: 0.6872817730549539
Epoch: 12 | Iteration number: [2030/4518] 44% | Training loss: 0.6872845708149408
Epoch: 12 | Iteration number: [2040/4518] 45% | Training loss: 0.6872826060828041
Epoch: 12 | Iteration number: [2050/4518] 45% | Training loss: 0.6872785745888221
Epoch: 12 | Iteration number: [2060/4518] 45% | Training loss: 0.6872732652043834
Epoch: 12 | Iteration number: [2070/4518] 45% | Training loss: 0.6872761738761036
Epoch: 12 | Iteration number: [2080/4518] 46% | Training loss: 0.6872725120817239
Epoch: 12 | Iteration number: [2090/4518] 46% | Training loss: 0.6872647718664562
Epoch: 12 | Iteration number: [2100/4518] 46% | Training loss: 0.687268194669769
Epoch: 12 | Iteration number: [2110/4518] 46% | Training loss: 0.6872696971723818
Epoch: 12 | Iteration number: [2120/4518] 46% | Training loss: 0.6872645624684838
Epoch: 12 | Iteration number: [2130/4518] 47% | Training loss: 0.687262821981045
Epoch: 12 | Iteration number: [2140/4518] 47% | Training loss: 0.6872550226539095
Epoch: 12 | Iteration number: [2150/4518] 47% | Training loss: 0.6872544300556183
Epoch: 12 | Iteration number: [2160/4518] 47% | Training loss: 0.6872576077779134
Epoch: 12 | Iteration number: [2170/4518] 48% | Training loss: 0.6872595155019364
Epoch: 12 | Iteration number: [2180/4518] 48% | Training loss: 0.6872597532534818
Epoch: 12 | Iteration number: [2190/4518] 48% | Training loss: 0.687253305002979
Epoch: 12 | Iteration number: [2200/4518] 48% | Training loss: 0.6872589545358311
Epoch: 12 | Iteration number: [2210/4518] 48% | Training loss: 0.6872568313082958
Epoch: 12 | Iteration number: [2220/4518] 49% | Training loss: 0.6872515089071549
Epoch: 12 | Iteration number: [2230/4518] 49% | Training loss: 0.6872523151171047
Epoch: 12 | Iteration number: [2240/4518] 49% | Training loss: 0.6872509721666574
Epoch: 12 | Iteration number: [2250/4518] 49% | Training loss: 0.6872478615972731
Epoch: 12 | Iteration number: [2260/4518] 50% | Training loss: 0.6872490175529918
Epoch: 12 | Iteration number: [2270/4518] 50% | Training loss: 0.6872455382137046
Epoch: 12 | Iteration number: [2280/4518] 50% | Training loss: 0.6872457939804646
Epoch: 12 | Iteration number: [2290/4518] 50% | Training loss: 0.687242789247671
Epoch: 12 | Iteration number: [2300/4518] 50% | Training loss: 0.6872429295208143
Epoch: 12 | Iteration number: [2310/4518] 51% | Training loss: 0.6872408293542408
Epoch: 12 | Iteration number: [2320/4518] 51% | Training loss: 0.687241228053282
Epoch: 12 | Iteration number: [2330/4518] 51% | Training loss: 0.6872438800948883
Epoch: 12 | Iteration number: [2340/4518] 51% | Training loss: 0.6872407049704821
Epoch: 12 | Iteration number: [2350/4518] 52% | Training loss: 0.6872367484518822
Epoch: 12 | Iteration number: [2360/4518] 52% | Training loss: 0.6872303318926843
Epoch: 12 | Iteration number: [2370/4518] 52% | Training loss: 0.6872279494875091
Epoch: 12 | Iteration number: [2380/4518] 52% | Training loss: 0.6872261192618297
Epoch: 12 | Iteration number: [2390/4518] 52% | Training loss: 0.6872304559003359
Epoch: 12 | Iteration number: [2400/4518] 53% | Training loss: 0.6872340712199608
Epoch: 12 | Iteration number: [2410/4518] 53% | Training loss: 0.6872295181038963
Epoch: 12 | Iteration number: [2420/4518] 53% | Training loss: 0.6872296417055052
Epoch: 12 | Iteration number: [2430/4518] 53% | Training loss: 0.6872321533568111
Epoch: 12 | Iteration number: [2440/4518] 54% | Training loss: 0.6872319274261349
Epoch: 12 | Iteration number: [2450/4518] 54% | Training loss: 0.6872338295226195
Epoch: 12 | Iteration number: [2460/4518] 54% | Training loss: 0.6872279752803042
Epoch: 12 | Iteration number: [2470/4518] 54% | Training loss: 0.6872247438923067
Epoch: 12 | Iteration number: [2480/4518] 54% | Training loss: 0.687224062075538
Epoch: 12 | Iteration number: [2490/4518] 55% | Training loss: 0.6872219611602615
Epoch: 12 | Iteration number: [2500/4518] 55% | Training loss: 0.6872244389295578
Epoch: 12 | Iteration number: [2510/4518] 55% | Training loss: 0.6872180638797729
Epoch: 12 | Iteration number: [2520/4518] 55% | Training loss: 0.6872183571259181
Epoch: 12 | Iteration number: [2530/4518] 55% | Training loss: 0.6872190500907747
Epoch: 12 | Iteration number: [2540/4518] 56% | Training loss: 0.6872171610359131
Epoch: 12 | Iteration number: [2550/4518] 56% | Training loss: 0.6872198491937974
Epoch: 12 | Iteration number: [2560/4518] 56% | Training loss: 0.6872202797560021
Epoch: 12 | Iteration number: [2570/4518] 56% | Training loss: 0.6872214866983287
Epoch: 12 | Iteration number: [2580/4518] 57% | Training loss: 0.6872205989536389
Epoch: 12 | Iteration number: [2590/4518] 57% | Training loss: 0.6872175837115432
Epoch: 12 | Iteration number: [2600/4518] 57% | Training loss: 0.6872148182071173
Epoch: 12 | Iteration number: [2610/4518] 57% | Training loss: 0.6872224558587275
Epoch: 12 | Iteration number: [2620/4518] 57% | Training loss: 0.6872252168546196
Epoch: 12 | Iteration number: [2630/4518] 58% | Training loss: 0.6872257118895934
Epoch: 12 | Iteration number: [2640/4518] 58% | Training loss: 0.6872245383985115
Epoch: 12 | Iteration number: [2650/4518] 58% | Training loss: 0.6872238084730112
Epoch: 12 | Iteration number: [2660/4518] 58% | Training loss: 0.6872212304880745
Epoch: 12 | Iteration number: [2670/4518] 59% | Training loss: 0.6872231506676263
Epoch: 12 | Iteration number: [2680/4518] 59% | Training loss: 0.687223104687769
Epoch: 12 | Iteration number: [2690/4518] 59% | Training loss: 0.6872171631532974
Epoch: 12 | Iteration number: [2700/4518] 59% | Training loss: 0.6872195009169755
Epoch: 12 | Iteration number: [2710/4518] 59% | Training loss: 0.6872178688040519
Epoch: 12 | Iteration number: [2720/4518] 60% | Training loss: 0.6872112912728506
Epoch: 12 | Iteration number: [2730/4518] 60% | Training loss: 0.6872119590912983
Epoch: 12 | Iteration number: [2740/4518] 60% | Training loss: 0.6872140807174418
Epoch: 12 | Iteration number: [2750/4518] 60% | Training loss: 0.6872164908105677
Epoch: 12 | Iteration number: [2760/4518] 61% | Training loss: 0.6872195780925129
Epoch: 12 | Iteration number: [2770/4518] 61% | Training loss: 0.6872206066059292
Epoch: 12 | Iteration number: [2780/4518] 61% | Training loss: 0.6872193764868401
Epoch: 12 | Iteration number: [2790/4518] 61% | Training loss: 0.6872191400938137
Epoch: 12 | Iteration number: [2800/4518] 61% | Training loss: 0.6872196136202131
Epoch: 12 | Iteration number: [2810/4518] 62% | Training loss: 0.6872139510522958
Epoch: 12 | Iteration number: [2820/4518] 62% | Training loss: 0.6872111293018287
Epoch: 12 | Iteration number: [2830/4518] 62% | Training loss: 0.6872066251591322
Epoch: 12 | Iteration number: [2840/4518] 62% | Training loss: 0.6872016525814231
Epoch: 12 | Iteration number: [2850/4518] 63% | Training loss: 0.6872031749758805
Epoch: 12 | Iteration number: [2860/4518] 63% | Training loss: 0.6872028913739678
Epoch: 12 | Iteration number: [2870/4518] 63% | Training loss: 0.6872005929930285
Epoch: 12 | Iteration number: [2880/4518] 63% | Training loss: 0.6872008085871736
Epoch: 12 | Iteration number: [2890/4518] 63% | Training loss: 0.6871993735381063
Epoch: 12 | Iteration number: [2900/4518] 64% | Training loss: 0.6871982171823239
Epoch: 12 | Iteration number: [2910/4518] 64% | Training loss: 0.6872006913026174
Epoch: 12 | Iteration number: [2920/4518] 64% | Training loss: 0.6872005783327638
Epoch: 12 | Iteration number: [2930/4518] 64% | Training loss: 0.68720158537907
Epoch: 12 | Iteration number: [2940/4518] 65% | Training loss: 0.6871982314959675
Epoch: 12 | Iteration number: [2950/4518] 65% | Training loss: 0.6871962884119002
Epoch: 12 | Iteration number: [2960/4518] 65% | Training loss: 0.6871956209878664
Epoch: 12 | Iteration number: [2970/4518] 65% | Training loss: 0.6871925584595613
Epoch: 12 | Iteration number: [2980/4518] 65% | Training loss: 0.6871935757214591
Epoch: 12 | Iteration number: [2990/4518] 66% | Training loss: 0.6871955221113951
Epoch: 12 | Iteration number: [3000/4518] 66% | Training loss: 0.6871940305233002
Epoch: 12 | Iteration number: [3010/4518] 66% | Training loss: 0.6871899699451915
Epoch: 12 | Iteration number: [3020/4518] 66% | Training loss: 0.6871912212363932
Epoch: 12 | Iteration number: [3030/4518] 67% | Training loss: 0.687191369352561
Epoch: 12 | Iteration number: [3040/4518] 67% | Training loss: 0.6871930420202644
Epoch: 12 | Iteration number: [3050/4518] 67% | Training loss: 0.6871954524712485
Epoch: 12 | Iteration number: [3060/4518] 67% | Training loss: 0.6871932847242729
Epoch: 12 | Iteration number: [3070/4518] 67% | Training loss: 0.6871927649073958
Epoch: 12 | Iteration number: [3080/4518] 68% | Training loss: 0.6871906712457732
Epoch: 12 | Iteration number: [3090/4518] 68% | Training loss: 0.6871886666345751
Epoch: 12 | Iteration number: [3100/4518] 68% | Training loss: 0.6871886191445012
Epoch: 12 | Iteration number: [3110/4518] 68% | Training loss: 0.687191776504854
Epoch: 12 | Iteration number: [3120/4518] 69% | Training loss: 0.687185630794519
Epoch: 12 | Iteration number: [3130/4518] 69% | Training loss: 0.6871825226770042
Epoch: 12 | Iteration number: [3140/4518] 69% | Training loss: 0.6871856552590231
Epoch: 12 | Iteration number: [3150/4518] 69% | Training loss: 0.6871856630226922
Epoch: 12 | Iteration number: [3160/4518] 69% | Training loss: 0.6871894247735603
Epoch: 12 | Iteration number: [3170/4518] 70% | Training loss: 0.6871839509213384
Epoch: 12 | Iteration number: [3180/4518] 70% | Training loss: 0.6871871880202923
Epoch: 12 | Iteration number: [3190/4518] 70% | Training loss: 0.6871909886131466
Epoch: 12 | Iteration number: [3200/4518] 70% | Training loss: 0.6871909673884511
Epoch: 12 | Iteration number: [3210/4518] 71% | Training loss: 0.6871916155948817
Epoch: 12 | Iteration number: [3220/4518] 71% | Training loss: 0.6871911303597208
Epoch: 12 | Iteration number: [3230/4518] 71% | Training loss: 0.6871905602537811
Epoch: 12 | Iteration number: [3240/4518] 71% | Training loss: 0.6871892468244941
Epoch: 12 | Iteration number: [3250/4518] 71% | Training loss: 0.6871863054862389
Epoch: 12 | Iteration number: [3260/4518] 72% | Training loss: 0.6871874811824845
Epoch: 12 | Iteration number: [3270/4518] 72% | Training loss: 0.687185613751776
Epoch: 12 | Iteration number: [3280/4518] 72% | Training loss: 0.6871829596779695
Epoch: 12 | Iteration number: [3290/4518] 72% | Training loss: 0.6871881308164278
Epoch: 12 | Iteration number: [3300/4518] 73% | Training loss: 0.6871881126815622
Epoch: 12 | Iteration number: [3310/4518] 73% | Training loss: 0.6871874273363557
Epoch: 12 | Iteration number: [3320/4518] 73% | Training loss: 0.6871879317853824
Epoch: 12 | Iteration number: [3330/4518] 73% | Training loss: 0.6871884573508311
Epoch: 12 | Iteration number: [3340/4518] 73% | Training loss: 0.6871925724837594
Epoch: 12 | Iteration number: [3350/4518] 74% | Training loss: 0.6871923254319091
Epoch: 12 | Iteration number: [3360/4518] 74% | Training loss: 0.6871895797373283
Epoch: 12 | Iteration number: [3370/4518] 74% | Training loss: 0.6871930919698155
Epoch: 12 | Iteration number: [3380/4518] 74% | Training loss: 0.6871903898095238
Epoch: 12 | Iteration number: [3390/4518] 75% | Training loss: 0.6871899856402811
Epoch: 12 | Iteration number: [3400/4518] 75% | Training loss: 0.6871885487261941
Epoch: 12 | Iteration number: [3410/4518] 75% | Training loss: 0.6871894970142947
Epoch: 12 | Iteration number: [3420/4518] 75% | Training loss: 0.6871911184655295
Epoch: 12 | Iteration number: [3430/4518] 75% | Training loss: 0.6871905096592082
Epoch: 12 | Iteration number: [3440/4518] 76% | Training loss: 0.6871874340398367
Epoch: 12 | Iteration number: [3450/4518] 76% | Training loss: 0.6871841538816259
Epoch: 12 | Iteration number: [3460/4518] 76% | Training loss: 0.6871806084248372
Epoch: 12 | Iteration number: [3470/4518] 76% | Training loss: 0.6871823916689463
Epoch: 12 | Iteration number: [3480/4518] 77% | Training loss: 0.6871781032318356
Epoch: 12 | Iteration number: [3490/4518] 77% | Training loss: 0.6871733832495943
Epoch: 12 | Iteration number: [3500/4518] 77% | Training loss: 0.6871738111632211
Epoch: 12 | Iteration number: [3510/4518] 77% | Training loss: 0.6871725755539375
Epoch: 12 | Iteration number: [3520/4518] 77% | Training loss: 0.6871692840856585
Epoch: 12 | Iteration number: [3530/4518] 78% | Training loss: 0.6871677114335403
Epoch: 12 | Iteration number: [3540/4518] 78% | Training loss: 0.6871639105222993
Epoch: 12 | Iteration number: [3550/4518] 78% | Training loss: 0.6871689731134495
Epoch: 12 | Iteration number: [3560/4518] 78% | Training loss: 0.687166299829992
Epoch: 12 | Iteration number: [3570/4518] 79% | Training loss: 0.6871670147617992
Epoch: 12 | Iteration number: [3580/4518] 79% | Training loss: 0.6871683535462652
Epoch: 12 | Iteration number: [3590/4518] 79% | Training loss: 0.6871645801412694
Epoch: 12 | Iteration number: [3600/4518] 79% | Training loss: 0.6871667679813173
Epoch: 12 | Iteration number: [3610/4518] 79% | Training loss: 0.6871635621274277
Epoch: 12 | Iteration number: [3620/4518] 80% | Training loss: 0.68716268463688
Epoch: 12 | Iteration number: [3630/4518] 80% | Training loss: 0.6871616312623352
Epoch: 12 | Iteration number: [3640/4518] 80% | Training loss: 0.6871603457318558
Epoch: 12 | Iteration number: [3650/4518] 80% | Training loss: 0.6871616769816777
Epoch: 12 | Iteration number: [3660/4518] 81% | Training loss: 0.6871595367056424
Epoch: 12 | Iteration number: [3670/4518] 81% | Training loss: 0.6871623888489986
Epoch: 12 | Iteration number: [3680/4518] 81% | Training loss: 0.6871600717954014
Epoch: 12 | Iteration number: [3690/4518] 81% | Training loss: 0.6871546744654172
Epoch: 12 | Iteration number: [3700/4518] 81% | Training loss: 0.6871516452769976
Epoch: 12 | Iteration number: [3710/4518] 82% | Training loss: 0.6871522812027173
Epoch: 12 | Iteration number: [3720/4518] 82% | Training loss: 0.687150446974462
Epoch: 12 | Iteration number: [3730/4518] 82% | Training loss: 0.687151587392945
Epoch: 12 | Iteration number: [3740/4518] 82% | Training loss: 0.6871476818214763
Epoch: 12 | Iteration number: [3750/4518] 83% | Training loss: 0.6871482568740844
Epoch: 12 | Iteration number: [3760/4518] 83% | Training loss: 0.6871492748564862
Epoch: 12 | Iteration number: [3770/4518] 83% | Training loss: 0.6871477769919985
Epoch: 12 | Iteration number: [3780/4518] 83% | Training loss: 0.6871445341085
Epoch: 12 | Iteration number: [3790/4518] 83% | Training loss: 0.6871432964122389
Epoch: 12 | Iteration number: [3800/4518] 84% | Training loss: 0.687145712705035
Epoch: 12 | Iteration number: [3810/4518] 84% | Training loss: 0.6871440431107999
Epoch: 12 | Iteration number: [3820/4518] 84% | Training loss: 0.6871452501775083
Epoch: 12 | Iteration number: [3830/4518] 84% | Training loss: 0.6871448010128409
Epoch: 12 | Iteration number: [3840/4518] 84% | Training loss: 0.6871475804752359
Epoch: 12 | Iteration number: [3850/4518] 85% | Training loss: 0.6871485948872257
Epoch: 12 | Iteration number: [3860/4518] 85% | Training loss: 0.687147344409493
Epoch: 12 | Iteration number: [3870/4518] 85% | Training loss: 0.6871469732864882
Epoch: 12 | Iteration number: [3880/4518] 85% | Training loss: 0.6871486172233661
Epoch: 12 | Iteration number: [3890/4518] 86% | Training loss: 0.6871483609731522
Epoch: 12 | Iteration number: [3900/4518] 86% | Training loss: 0.687147218126517
Epoch: 12 | Iteration number: [3910/4518] 86% | Training loss: 0.6871477482263999
Epoch: 12 | Iteration number: [3920/4518] 86% | Training loss: 0.6871468528953134
Epoch: 12 | Iteration number: [3930/4518] 86% | Training loss: 0.6871469279736963
Epoch: 12 | Iteration number: [3940/4518] 87% | Training loss: 0.6871443543488605
Epoch: 12 | Iteration number: [3950/4518] 87% | Training loss: 0.6871422664274143
Epoch: 12 | Iteration number: [3960/4518] 87% | Training loss: 0.687141218841678
Epoch: 12 | Iteration number: [3970/4518] 87% | Training loss: 0.6871376166565892
Epoch: 12 | Iteration number: [3980/4518] 88% | Training loss: 0.6871372753052256
Epoch: 12 | Iteration number: [3990/4518] 88% | Training loss: 0.6871361840040164
Epoch: 12 | Iteration number: [4000/4518] 88% | Training loss: 0.6871342429667712
Epoch: 12 | Iteration number: [4010/4518] 88% | Training loss: 0.687135885287996
Epoch: 12 | Iteration number: [4020/4518] 88% | Training loss: 0.68713526077828
Epoch: 12 | Iteration number: [4030/4518] 89% | Training loss: 0.6871365746404634
Epoch: 12 | Iteration number: [4040/4518] 89% | Training loss: 0.6871377127595467
Epoch: 12 | Iteration number: [4050/4518] 89% | Training loss: 0.6871386556124982
Epoch: 12 | Iteration number: [4060/4518] 89% | Training loss: 0.6871368933634218
Epoch: 12 | Iteration number: [4070/4518] 90% | Training loss: 0.6871373114480434
Epoch: 12 | Iteration number: [4080/4518] 90% | Training loss: 0.6871376871186144
Epoch: 12 | Iteration number: [4090/4518] 90% | Training loss: 0.6871395094616197
Epoch: 12 | Iteration number: [4100/4518] 90% | Training loss: 0.6871380759884671
Epoch: 12 | Iteration number: [4110/4518] 90% | Training loss: 0.6871359605568749
Epoch: 12 | Iteration number: [4120/4518] 91% | Training loss: 0.687137622726195
Epoch: 12 | Iteration number: [4130/4518] 91% | Training loss: 0.6871363588886169
Epoch: 12 | Iteration number: [4140/4518] 91% | Training loss: 0.6871353962859094
Epoch: 12 | Iteration number: [4150/4518] 91% | Training loss: 0.6871344339703939
Epoch: 12 | Iteration number: [4160/4518] 92% | Training loss: 0.6871347131350866
Epoch: 12 | Iteration number: [4170/4518] 92% | Training loss: 0.6871328110746342
Epoch: 12 | Iteration number: [4180/4518] 92% | Training loss: 0.6871306722386602
Epoch: 12 | Iteration number: [4190/4518] 92% | Training loss: 0.68712795513342
Epoch: 12 | Iteration number: [4200/4518] 92% | Training loss: 0.6871277207703818
Epoch: 12 | Iteration number: [4210/4518] 93% | Training loss: 0.6871268690057152
Epoch: 12 | Iteration number: [4220/4518] 93% | Training loss: 0.6871257077178684
Epoch: 12 | Iteration number: [4230/4518] 93% | Training loss: 0.6871234247306842
Epoch: 12 | Iteration number: [4240/4518] 93% | Training loss: 0.6871221442829888
Epoch: 12 | Iteration number: [4250/4518] 94% | Training loss: 0.6871236367506139
Epoch: 12 | Iteration number: [4260/4518] 94% | Training loss: 0.687126592851021
Epoch: 12 | Iteration number: [4270/4518] 94% | Training loss: 0.687129731410002
Epoch: 12 | Iteration number: [4280/4518] 94% | Training loss: 0.6871294195128378
Epoch: 12 | Iteration number: [4290/4518] 94% | Training loss: 0.6871295375284893
Epoch: 12 | Iteration number: [4300/4518] 95% | Training loss: 0.687125908954199
Epoch: 12 | Iteration number: [4310/4518] 95% | Training loss: 0.6871245068491473
Epoch: 12 | Iteration number: [4320/4518] 95% | Training loss: 0.6871233022461335
Epoch: 12 | Iteration number: [4330/4518] 95% | Training loss: 0.6871229796018666
Epoch: 12 | Iteration number: [4340/4518] 96% | Training loss: 0.6871222493835308
Epoch: 12 | Iteration number: [4350/4518] 96% | Training loss: 0.6871237175080968
Epoch: 12 | Iteration number: [4360/4518] 96% | Training loss: 0.6871256535069659
Epoch: 12 | Iteration number: [4370/4518] 96% | Training loss: 0.6871264830470358
Epoch: 12 | Iteration number: [4380/4518] 96% | Training loss: 0.6871268402223718
Epoch: 12 | Iteration number: [4390/4518] 97% | Training loss: 0.6871284544060605
Epoch: 12 | Iteration number: [4400/4518] 97% | Training loss: 0.6871292657337406
Epoch: 12 | Iteration number: [4410/4518] 97% | Training loss: 0.6871289260668549
Epoch: 12 | Iteration number: [4420/4518] 97% | Training loss: 0.6871298125966102
Epoch: 12 | Iteration number: [4430/4518] 98% | Training loss: 0.6871250441461869
Epoch: 12 | Iteration number: [4440/4518] 98% | Training loss: 0.6871246694310291
Epoch: 12 | Iteration number: [4450/4518] 98% | Training loss: 0.6871258165595237
Epoch: 12 | Iteration number: [4460/4518] 98% | Training loss: 0.6871251572808877
Epoch: 12 | Iteration number: [4470/4518] 98% | Training loss: 0.687123334287797
Epoch: 12 | Iteration number: [4480/4518] 99% | Training loss: 0.6871205144162689
Epoch: 12 | Iteration number: [4490/4518] 99% | Training loss: 0.6871188851002861
Epoch: 12 | Iteration number: [4500/4518] 99% | Training loss: 0.6871160648266474
Epoch: 12 | Iteration number: [4510/4518] 99% | Training loss: 0.6871183178377257

 End of epoch: 12 | Train Loss: 0.6869672412706614 | Training Time: 641 

 End of epoch: 12 | Eval Loss: 0.6904638494764056 | Evaluating Time: 17 
Epoch: 13 | Iteration number: [10/4518] 0% | Training loss: 0.7562061905860901
Epoch: 13 | Iteration number: [20/4518] 0% | Training loss: 0.7221061021089554
Epoch: 13 | Iteration number: [30/4518] 0% | Training loss: 0.7100362221399943
Epoch: 13 | Iteration number: [40/4518] 0% | Training loss: 0.704049926996231
Epoch: 13 | Iteration number: [50/4518] 1% | Training loss: 0.7006593632698059
Epoch: 13 | Iteration number: [60/4518] 1% | Training loss: 0.69850192964077
Epoch: 13 | Iteration number: [70/4518] 1% | Training loss: 0.697079508645194
Epoch: 13 | Iteration number: [80/4518] 1% | Training loss: 0.6956921495497227
Epoch: 13 | Iteration number: [90/4518] 1% | Training loss: 0.6948393980662028
Epoch: 13 | Iteration number: [100/4518] 2% | Training loss: 0.6940063178539276
Epoch: 13 | Iteration number: [110/4518] 2% | Training loss: 0.6933890483596108
Epoch: 13 | Iteration number: [120/4518] 2% | Training loss: 0.6929786165555318
Epoch: 13 | Iteration number: [130/4518] 2% | Training loss: 0.6925436056577242
Epoch: 13 | Iteration number: [140/4518] 3% | Training loss: 0.6922508295093264
Epoch: 13 | Iteration number: [150/4518] 3% | Training loss: 0.6919467206796011
Epoch: 13 | Iteration number: [160/4518] 3% | Training loss: 0.691623080521822
Epoch: 13 | Iteration number: [170/4518] 3% | Training loss: 0.691336794460521
Epoch: 13 | Iteration number: [180/4518] 3% | Training loss: 0.6911204881138272
Epoch: 13 | Iteration number: [190/4518] 4% | Training loss: 0.6908056917943453
Epoch: 13 | Iteration number: [200/4518] 4% | Training loss: 0.6906310454010963
Epoch: 13 | Iteration number: [210/4518] 4% | Training loss: 0.6904874421301342
Epoch: 13 | Iteration number: [220/4518] 4% | Training loss: 0.6902631361376156
Epoch: 13 | Iteration number: [230/4518] 5% | Training loss: 0.690063019161639
Epoch: 13 | Iteration number: [240/4518] 5% | Training loss: 0.6899348268906276
Epoch: 13 | Iteration number: [250/4518] 5% | Training loss: 0.6898289110660553
Epoch: 13 | Iteration number: [260/4518] 5% | Training loss: 0.6897260672771014
Epoch: 13 | Iteration number: [270/4518] 5% | Training loss: 0.6896319735933233
Epoch: 13 | Iteration number: [280/4518] 6% | Training loss: 0.6895412000162261
Epoch: 13 | Iteration number: [290/4518] 6% | Training loss: 0.6894942894064147
Epoch: 13 | Iteration number: [300/4518] 6% | Training loss: 0.6894390352567037
Epoch: 13 | Iteration number: [310/4518] 6% | Training loss: 0.6893438491129106
Epoch: 13 | Iteration number: [320/4518] 7% | Training loss: 0.6892841678112746
Epoch: 13 | Iteration number: [330/4518] 7% | Training loss: 0.6892016723300471
Epoch: 13 | Iteration number: [340/4518] 7% | Training loss: 0.6891248017549515
Epoch: 13 | Iteration number: [350/4518] 7% | Training loss: 0.6890259330613272
Epoch: 13 | Iteration number: [360/4518] 7% | Training loss: 0.6889709361725384
Epoch: 13 | Iteration number: [370/4518] 8% | Training loss: 0.6889492808161555
Epoch: 13 | Iteration number: [380/4518] 8% | Training loss: 0.6888928573382528
Epoch: 13 | Iteration number: [390/4518] 8% | Training loss: 0.6888495122775053
Epoch: 13 | Iteration number: [400/4518] 8% | Training loss: 0.6888067442178726
Epoch: 13 | Iteration number: [410/4518] 9% | Training loss: 0.6887578014920398
Epoch: 13 | Iteration number: [420/4518] 9% | Training loss: 0.6887496034304301
Epoch: 13 | Iteration number: [430/4518] 9% | Training loss: 0.6887105566124584
Epoch: 13 | Iteration number: [440/4518] 9% | Training loss: 0.6886750382455913
Epoch: 13 | Iteration number: [450/4518] 9% | Training loss: 0.6886248438888126
Epoch: 13 | Iteration number: [460/4518] 10% | Training loss: 0.6885737883008045
Epoch: 13 | Iteration number: [470/4518] 10% | Training loss: 0.6885064075601862
Epoch: 13 | Iteration number: [480/4518] 10% | Training loss: 0.6884847074747086
Epoch: 13 | Iteration number: [490/4518] 10% | Training loss: 0.6884456139438007
Epoch: 13 | Iteration number: [500/4518] 11% | Training loss: 0.6884321229457855
Epoch: 13 | Iteration number: [510/4518] 11% | Training loss: 0.688397662896736
Epoch: 13 | Iteration number: [520/4518] 11% | Training loss: 0.6883576872257086
Epoch: 13 | Iteration number: [530/4518] 11% | Training loss: 0.6883329534305717
Epoch: 13 | Iteration number: [540/4518] 11% | Training loss: 0.6883049559813958
Epoch: 13 | Iteration number: [550/4518] 12% | Training loss: 0.6882967135039243
Epoch: 13 | Iteration number: [560/4518] 12% | Training loss: 0.6882600554398128
Epoch: 13 | Iteration number: [570/4518] 12% | Training loss: 0.6882388893972363
Epoch: 13 | Iteration number: [580/4518] 12% | Training loss: 0.6882062022028298
Epoch: 13 | Iteration number: [590/4518] 13% | Training loss: 0.6881672484389806
Epoch: 13 | Iteration number: [600/4518] 13% | Training loss: 0.6881293873985609
Epoch: 13 | Iteration number: [610/4518] 13% | Training loss: 0.6880954151270819
Epoch: 13 | Iteration number: [620/4518] 13% | Training loss: 0.6880761253256952
Epoch: 13 | Iteration number: [630/4518] 13% | Training loss: 0.6880543637843359
Epoch: 13 | Iteration number: [640/4518] 14% | Training loss: 0.6880328686907887
Epoch: 13 | Iteration number: [650/4518] 14% | Training loss: 0.6880187993783217
Epoch: 13 | Iteration number: [660/4518] 14% | Training loss: 0.6879688234943332
Epoch: 13 | Iteration number: [670/4518] 14% | Training loss: 0.6879350074191591
Epoch: 13 | Iteration number: [680/4518] 15% | Training loss: 0.6879121056374382
Epoch: 13 | Iteration number: [690/4518] 15% | Training loss: 0.687898768376613
Epoch: 13 | Iteration number: [700/4518] 15% | Training loss: 0.6878783366509846
Epoch: 13 | Iteration number: [710/4518] 15% | Training loss: 0.6878696530637607
Epoch: 13 | Iteration number: [720/4518] 15% | Training loss: 0.687847572316726
Epoch: 13 | Iteration number: [730/4518] 16% | Training loss: 0.6878434705407652
Epoch: 13 | Iteration number: [740/4518] 16% | Training loss: 0.6878412663936615
Epoch: 13 | Iteration number: [750/4518] 16% | Training loss: 0.6878410587310791
Epoch: 13 | Iteration number: [760/4518] 16% | Training loss: 0.6878333671312583
Epoch: 13 | Iteration number: [770/4518] 17% | Training loss: 0.6878146589576424
Epoch: 13 | Iteration number: [780/4518] 17% | Training loss: 0.6877908644767908
Epoch: 13 | Iteration number: [790/4518] 17% | Training loss: 0.6877850030041948
Epoch: 13 | Iteration number: [800/4518] 17% | Training loss: 0.6877769012004137
Epoch: 13 | Iteration number: [810/4518] 17% | Training loss: 0.6877760774559445
Epoch: 13 | Iteration number: [820/4518] 18% | Training loss: 0.6877812088262744
Epoch: 13 | Iteration number: [830/4518] 18% | Training loss: 0.6877674147307155
Epoch: 13 | Iteration number: [840/4518] 18% | Training loss: 0.6877566805907658
Epoch: 13 | Iteration number: [850/4518] 18% | Training loss: 0.6877467853181503
Epoch: 13 | Iteration number: [860/4518] 19% | Training loss: 0.6877332223709239
Epoch: 13 | Iteration number: [870/4518] 19% | Training loss: 0.6877209101600209
Epoch: 13 | Iteration number: [880/4518] 19% | Training loss: 0.6877094581045887
Epoch: 13 | Iteration number: [890/4518] 19% | Training loss: 0.6876923284503851
Epoch: 13 | Iteration number: [900/4518] 19% | Training loss: 0.6876844910780588
Epoch: 13 | Iteration number: [910/4518] 20% | Training loss: 0.6876632501790811
Epoch: 13 | Iteration number: [920/4518] 20% | Training loss: 0.687641755523889
Epoch: 13 | Iteration number: [930/4518] 20% | Training loss: 0.6876476740965279
Epoch: 13 | Iteration number: [940/4518] 20% | Training loss: 0.687654106604292
Epoch: 13 | Iteration number: [950/4518] 21% | Training loss: 0.6876498940743898
Epoch: 13 | Iteration number: [960/4518] 21% | Training loss: 0.6876386174932122
Epoch: 13 | Iteration number: [970/4518] 21% | Training loss: 0.6876177619413002
Epoch: 13 | Iteration number: [980/4518] 21% | Training loss: 0.6876012290010647
Epoch: 13 | Iteration number: [990/4518] 21% | Training loss: 0.6875990761650933
Epoch: 13 | Iteration number: [1000/4518] 22% | Training loss: 0.6875978167057037
Epoch: 13 | Iteration number: [1010/4518] 22% | Training loss: 0.6875810465010086
Epoch: 13 | Iteration number: [1020/4518] 22% | Training loss: 0.6875752588113149
Epoch: 13 | Iteration number: [1030/4518] 22% | Training loss: 0.6875689940545165
Epoch: 13 | Iteration number: [1040/4518] 23% | Training loss: 0.6875694541403881
Epoch: 13 | Iteration number: [1050/4518] 23% | Training loss: 0.687564021121888
Epoch: 13 | Iteration number: [1060/4518] 23% | Training loss: 0.6875584713130627
Epoch: 13 | Iteration number: [1070/4518] 23% | Training loss: 0.6875513295146907
Epoch: 13 | Iteration number: [1080/4518] 23% | Training loss: 0.6875449632604916
Epoch: 13 | Iteration number: [1090/4518] 24% | Training loss: 0.6875241200311468
Epoch: 13 | Iteration number: [1100/4518] 24% | Training loss: 0.6875126453421333
Epoch: 13 | Iteration number: [1110/4518] 24% | Training loss: 0.6875021185960856
Epoch: 13 | Iteration number: [1120/4518] 24% | Training loss: 0.6874992805400065
Epoch: 13 | Iteration number: [1130/4518] 25% | Training loss: 0.6874908376584011
Epoch: 13 | Iteration number: [1140/4518] 25% | Training loss: 0.6874916260179721
Epoch: 13 | Iteration number: [1150/4518] 25% | Training loss: 0.6874816804865133
Epoch: 13 | Iteration number: [1160/4518] 25% | Training loss: 0.6874798240332768
Epoch: 13 | Iteration number: [1170/4518] 25% | Training loss: 0.6874761037846916
Epoch: 13 | Iteration number: [1180/4518] 26% | Training loss: 0.6874738945799359
Epoch: 13 | Iteration number: [1190/4518] 26% | Training loss: 0.6874745858316662
Epoch: 13 | Iteration number: [1200/4518] 26% | Training loss: 0.6874584745367368
Epoch: 13 | Iteration number: [1210/4518] 26% | Training loss: 0.6874477009635326
Epoch: 13 | Iteration number: [1220/4518] 27% | Training loss: 0.687434026892068
Epoch: 13 | Iteration number: [1230/4518] 27% | Training loss: 0.6874353689876029
Epoch: 13 | Iteration number: [1240/4518] 27% | Training loss: 0.687422442195877
Epoch: 13 | Iteration number: [1250/4518] 27% | Training loss: 0.6874221749782562
Epoch: 13 | Iteration number: [1260/4518] 27% | Training loss: 0.6874231052777123
Epoch: 13 | Iteration number: [1270/4518] 28% | Training loss: 0.6874093932898965
Epoch: 13 | Iteration number: [1280/4518] 28% | Training loss: 0.6874174402095378
Epoch: 13 | Iteration number: [1290/4518] 28% | Training loss: 0.6874199025390684
Epoch: 13 | Iteration number: [1300/4518] 28% | Training loss: 0.6874225175839204
Epoch: 13 | Iteration number: [1310/4518] 28% | Training loss: 0.6874129143835024
Epoch: 13 | Iteration number: [1320/4518] 29% | Training loss: 0.6874084664113593
Epoch: 13 | Iteration number: [1330/4518] 29% | Training loss: 0.687417459398284
Epoch: 13 | Iteration number: [1340/4518] 29% | Training loss: 0.6874060572528128
Epoch: 13 | Iteration number: [1350/4518] 29% | Training loss: 0.6873982584476471
Epoch: 13 | Iteration number: [1360/4518] 30% | Training loss: 0.6873944061205668
Epoch: 13 | Iteration number: [1370/4518] 30% | Training loss: 0.6873838560859652
Epoch: 13 | Iteration number: [1380/4518] 30% | Training loss: 0.6873815698900084
Epoch: 13 | Iteration number: [1390/4518] 30% | Training loss: 0.6873832987795631
Epoch: 13 | Iteration number: [1400/4518] 30% | Training loss: 0.68738077044487
Epoch: 13 | Iteration number: [1410/4518] 31% | Training loss: 0.6873788220662598
Epoch: 13 | Iteration number: [1420/4518] 31% | Training loss: 0.6873834773268498
Epoch: 13 | Iteration number: [1430/4518] 31% | Training loss: 0.6873852939872475
Epoch: 13 | Iteration number: [1440/4518] 31% | Training loss: 0.6873905261357626
Epoch: 13 | Iteration number: [1450/4518] 32% | Training loss: 0.6873946677816325
Epoch: 13 | Iteration number: [1460/4518] 32% | Training loss: 0.6873996401486332
Epoch: 13 | Iteration number: [1470/4518] 32% | Training loss: 0.6873997016423413
Epoch: 13 | Iteration number: [1480/4518] 32% | Training loss: 0.6873974225005588
Epoch: 13 | Iteration number: [1490/4518] 32% | Training loss: 0.6873927931257542
Epoch: 13 | Iteration number: [1500/4518] 33% | Training loss: 0.6873842670520147
Epoch: 13 | Iteration number: [1510/4518] 33% | Training loss: 0.6873826584279142
Epoch: 13 | Iteration number: [1520/4518] 33% | Training loss: 0.6873725005278462
Epoch: 13 | Iteration number: [1530/4518] 33% | Training loss: 0.6873621541690204
Epoch: 13 | Iteration number: [1540/4518] 34% | Training loss: 0.6873691704366114
Epoch: 13 | Iteration number: [1550/4518] 34% | Training loss: 0.6873679448327711
Epoch: 13 | Iteration number: [1560/4518] 34% | Training loss: 0.6873700372683696
Epoch: 13 | Iteration number: [1570/4518] 34% | Training loss: 0.687366990564735
Epoch: 13 | Iteration number: [1580/4518] 34% | Training loss: 0.6873606775380388
Epoch: 13 | Iteration number: [1590/4518] 35% | Training loss: 0.687363898979043
Epoch: 13 | Iteration number: [1600/4518] 35% | Training loss: 0.6873583712428808
Epoch: 13 | Iteration number: [1610/4518] 35% | Training loss: 0.6873489438006597
Epoch: 13 | Iteration number: [1620/4518] 35% | Training loss: 0.6873455462264426
Epoch: 13 | Iteration number: [1630/4518] 36% | Training loss: 0.6873369436322546
Epoch: 13 | Iteration number: [1640/4518] 36% | Training loss: 0.6873405511059412
Epoch: 13 | Iteration number: [1650/4518] 36% | Training loss: 0.6873325520212
Epoch: 13 | Iteration number: [1660/4518] 36% | Training loss: 0.6873305061136383
Epoch: 13 | Iteration number: [1670/4518] 36% | Training loss: 0.6873294286385268
Epoch: 13 | Iteration number: [1680/4518] 37% | Training loss: 0.6873215674289636
Epoch: 13 | Iteration number: [1690/4518] 37% | Training loss: 0.6873234373930643
Epoch: 13 | Iteration number: [1700/4518] 37% | Training loss: 0.6873205798163133
Epoch: 13 | Iteration number: [1710/4518] 37% | Training loss: 0.687318584898062
Epoch: 13 | Iteration number: [1720/4518] 38% | Training loss: 0.6873139839879302
Epoch: 13 | Iteration number: [1730/4518] 38% | Training loss: 0.6873146365832731
Epoch: 13 | Iteration number: [1740/4518] 38% | Training loss: 0.6873192389806112
Epoch: 13 | Iteration number: [1750/4518] 38% | Training loss: 0.6873180551188333
Epoch: 13 | Iteration number: [1760/4518] 38% | Training loss: 0.6873145047575235
Epoch: 13 | Iteration number: [1770/4518] 39% | Training loss: 0.6873039928870013
Epoch: 13 | Iteration number: [1780/4518] 39% | Training loss: 0.6873048049010587
Epoch: 13 | Iteration number: [1790/4518] 39% | Training loss: 0.6873028433522699
Epoch: 13 | Iteration number: [1800/4518] 39% | Training loss: 0.6872972989413473
Epoch: 13 | Iteration number: [1810/4518] 40% | Training loss: 0.6872879948075964
Epoch: 13 | Iteration number: [1820/4518] 40% | Training loss: 0.6872823739117319
Epoch: 13 | Iteration number: [1830/4518] 40% | Training loss: 0.6872900158655448
Epoch: 13 | Iteration number: [1840/4518] 40% | Training loss: 0.6872870609488176
Epoch: 13 | Iteration number: [1850/4518] 40% | Training loss: 0.6872888597282203
Epoch: 13 | Iteration number: [1860/4518] 41% | Training loss: 0.68728863427075
Epoch: 13 | Iteration number: [1870/4518] 41% | Training loss: 0.6872796709843498
Epoch: 13 | Iteration number: [1880/4518] 41% | Training loss: 0.6872787559286077
Epoch: 13 | Iteration number: [1890/4518] 41% | Training loss: 0.6872728704460084
Epoch: 13 | Iteration number: [1900/4518] 42% | Training loss: 0.6872694384110601
Epoch: 13 | Iteration number: [1910/4518] 42% | Training loss: 0.6872674206164495
Epoch: 13 | Iteration number: [1920/4518] 42% | Training loss: 0.687268075098594
Epoch: 13 | Iteration number: [1930/4518] 42% | Training loss: 0.6872736958024416
Epoch: 13 | Iteration number: [1940/4518] 42% | Training loss: 0.6872728423359468
Epoch: 13 | Iteration number: [1950/4518] 43% | Training loss: 0.6872726778800671
Epoch: 13 | Iteration number: [1960/4518] 43% | Training loss: 0.6872741276208235
Epoch: 13 | Iteration number: [1970/4518] 43% | Training loss: 0.687275996365523
Epoch: 13 | Iteration number: [1980/4518] 43% | Training loss: 0.6872691416680211
Epoch: 13 | Iteration number: [1990/4518] 44% | Training loss: 0.6872687802841915
Epoch: 13 | Iteration number: [2000/4518] 44% | Training loss: 0.6872716790139675
Epoch: 13 | Iteration number: [2010/4518] 44% | Training loss: 0.6872716692253131
Epoch: 13 | Iteration number: [2020/4518] 44% | Training loss: 0.6872742895737733
Epoch: 13 | Iteration number: [2030/4518] 44% | Training loss: 0.687274832649184
Epoch: 13 | Iteration number: [2040/4518] 45% | Training loss: 0.6872741882123199
Epoch: 13 | Iteration number: [2050/4518] 45% | Training loss: 0.6872697371680562
Epoch: 13 | Iteration number: [2060/4518] 45% | Training loss: 0.6872688586850768
Epoch: 13 | Iteration number: [2070/4518] 45% | Training loss: 0.6872645082681076
Epoch: 13 | Iteration number: [2080/4518] 46% | Training loss: 0.6872644458539211
Epoch: 13 | Iteration number: [2090/4518] 46% | Training loss: 0.6872629375549024
Epoch: 13 | Iteration number: [2100/4518] 46% | Training loss: 0.687260593686785
Epoch: 13 | Iteration number: [2110/4518] 46% | Training loss: 0.6872583026287115
Epoch: 13 | Iteration number: [2120/4518] 46% | Training loss: 0.6872570877929903
Epoch: 13 | Iteration number: [2130/4518] 47% | Training loss: 0.687252599084881
Epoch: 13 | Iteration number: [2140/4518] 47% | Training loss: 0.6872547665489054
Epoch: 13 | Iteration number: [2150/4518] 47% | Training loss: 0.6872522519355596
Epoch: 13 | Iteration number: [2160/4518] 47% | Training loss: 0.6872544056287518
Epoch: 13 | Iteration number: [2170/4518] 48% | Training loss: 0.6872547016989801
Epoch: 13 | Iteration number: [2180/4518] 48% | Training loss: 0.6872532603117304
Epoch: 13 | Iteration number: [2190/4518] 48% | Training loss: 0.6872523739185508
Epoch: 13 | Iteration number: [2200/4518] 48% | Training loss: 0.6872535354440863
Epoch: 13 | Iteration number: [2210/4518] 48% | Training loss: 0.6872583215592674
Epoch: 13 | Iteration number: [2220/4518] 49% | Training loss: 0.687259309839558
Epoch: 13 | Iteration number: [2230/4518] 49% | Training loss: 0.6872622967300929
Epoch: 13 | Iteration number: [2240/4518] 49% | Training loss: 0.6872573460319212
Epoch: 13 | Iteration number: [2250/4518] 49% | Training loss: 0.6872541037135654
Epoch: 13 | Iteration number: [2260/4518] 50% | Training loss: 0.6872468221504077
Epoch: 13 | Iteration number: [2270/4518] 50% | Training loss: 0.6872470071924941
Epoch: 13 | Iteration number: [2280/4518] 50% | Training loss: 0.6872520688071585
Epoch: 13 | Iteration number: [2290/4518] 50% | Training loss: 0.6872466905929115
Epoch: 13 | Iteration number: [2300/4518] 50% | Training loss: 0.687244238205578
Epoch: 13 | Iteration number: [2310/4518] 51% | Training loss: 0.6872437511945699
Epoch: 13 | Iteration number: [2320/4518] 51% | Training loss: 0.6872454926114658
Epoch: 13 | Iteration number: [2330/4518] 51% | Training loss: 0.687245197357538
Epoch: 13 | Iteration number: [2340/4518] 51% | Training loss: 0.6872429496966875
Epoch: 13 | Iteration number: [2350/4518] 52% | Training loss: 0.6872403186432858
Epoch: 13 | Iteration number: [2360/4518] 52% | Training loss: 0.6872378190442667
Epoch: 13 | Iteration number: [2370/4518] 52% | Training loss: 0.6872370331347744
Epoch: 13 | Iteration number: [2380/4518] 52% | Training loss: 0.6872364590648844
Epoch: 13 | Iteration number: [2390/4518] 52% | Training loss: 0.687231820547431
Epoch: 13 | Iteration number: [2400/4518] 53% | Training loss: 0.6872297505040964
Epoch: 13 | Iteration number: [2410/4518] 53% | Training loss: 0.6872250054634458
Epoch: 13 | Iteration number: [2420/4518] 53% | Training loss: 0.6872231881973172
Epoch: 13 | Iteration number: [2430/4518] 53% | Training loss: 0.6872243652373184
Epoch: 13 | Iteration number: [2440/4518] 54% | Training loss: 0.6872236483654038
Epoch: 13 | Iteration number: [2450/4518] 54% | Training loss: 0.6872260659811448
Epoch: 13 | Iteration number: [2460/4518] 54% | Training loss: 0.6872228493777717
Epoch: 13 | Iteration number: [2470/4518] 54% | Training loss: 0.6872243652942209
Epoch: 13 | Iteration number: [2480/4518] 54% | Training loss: 0.6872256348450337
Epoch: 13 | Iteration number: [2490/4518] 55% | Training loss: 0.6872244011685551
Epoch: 13 | Iteration number: [2500/4518] 55% | Training loss: 0.6872233492612839
Epoch: 13 | Iteration number: [2510/4518] 55% | Training loss: 0.6872203288800213
Epoch: 13 | Iteration number: [2520/4518] 55% | Training loss: 0.6872247846590148
Epoch: 13 | Iteration number: [2530/4518] 55% | Training loss: 0.687225372494445
Epoch: 13 | Iteration number: [2540/4518] 56% | Training loss: 0.6872285479166377
Epoch: 13 | Iteration number: [2550/4518] 56% | Training loss: 0.6872238486888362
Epoch: 13 | Iteration number: [2560/4518] 56% | Training loss: 0.6872212022775784
Epoch: 13 | Iteration number: [2570/4518] 56% | Training loss: 0.6872227845256894
Epoch: 13 | Iteration number: [2580/4518] 57% | Training loss: 0.6872161790844082
Epoch: 13 | Iteration number: [2590/4518] 57% | Training loss: 0.6872182829039437
Epoch: 13 | Iteration number: [2600/4518] 57% | Training loss: 0.6872157624593148
Epoch: 13 | Iteration number: [2610/4518] 57% | Training loss: 0.687211293393168
Epoch: 13 | Iteration number: [2620/4518] 57% | Training loss: 0.6872100659909139
Epoch: 13 | Iteration number: [2630/4518] 58% | Training loss: 0.687207627001824
Epoch: 13 | Iteration number: [2640/4518] 58% | Training loss: 0.6872083915228193
Epoch: 13 | Iteration number: [2650/4518] 58% | Training loss: 0.6872073909696543
Epoch: 13 | Iteration number: [2660/4518] 58% | Training loss: 0.6872086484405331
Epoch: 13 | Iteration number: [2670/4518] 59% | Training loss: 0.6872109462259414
Epoch: 13 | Iteration number: [2680/4518] 59% | Training loss: 0.6872069671750068
Epoch: 13 | Iteration number: [2690/4518] 59% | Training loss: 0.6872003818311656
Epoch: 13 | Iteration number: [2700/4518] 59% | Training loss: 0.6871977793508106
Epoch: 13 | Iteration number: [2710/4518] 59% | Training loss: 0.6872002995981942
Epoch: 13 | Iteration number: [2720/4518] 60% | Training loss: 0.6871997239396853
Epoch: 13 | Iteration number: [2730/4518] 60% | Training loss: 0.6871968463663654
Epoch: 13 | Iteration number: [2740/4518] 60% | Training loss: 0.6871941051126397
Epoch: 13 | Iteration number: [2750/4518] 60% | Training loss: 0.6871930559765209
Epoch: 13 | Iteration number: [2760/4518] 61% | Training loss: 0.6871926106188608
Epoch: 13 | Iteration number: [2770/4518] 61% | Training loss: 0.6871911251803168
Epoch: 13 | Iteration number: [2780/4518] 61% | Training loss: 0.6871911531086449
Epoch: 13 | Iteration number: [2790/4518] 61% | Training loss: 0.6871879848100806
Epoch: 13 | Iteration number: [2800/4518] 61% | Training loss: 0.687187430454152
Epoch: 13 | Iteration number: [2810/4518] 62% | Training loss: 0.6871879459700126
Epoch: 13 | Iteration number: [2820/4518] 62% | Training loss: 0.6871849240352076
Epoch: 13 | Iteration number: [2830/4518] 62% | Training loss: 0.6871839635363737
Epoch: 13 | Iteration number: [2840/4518] 62% | Training loss: 0.6871824325390266
Epoch: 13 | Iteration number: [2850/4518] 63% | Training loss: 0.6871803059494286
Epoch: 13 | Iteration number: [2860/4518] 63% | Training loss: 0.6871815228795671
Epoch: 13 | Iteration number: [2870/4518] 63% | Training loss: 0.6871827553581278
Epoch: 13 | Iteration number: [2880/4518] 63% | Training loss: 0.6871771851554513
Epoch: 13 | Iteration number: [2890/4518] 63% | Training loss: 0.6871751959967366
Epoch: 13 | Iteration number: [2900/4518] 64% | Training loss: 0.6871760368347168
Epoch: 13 | Iteration number: [2910/4518] 64% | Training loss: 0.6871721203999012
Epoch: 13 | Iteration number: [2920/4518] 64% | Training loss: 0.687171431967657
Epoch: 13 | Iteration number: [2930/4518] 64% | Training loss: 0.6871723579465325
Epoch: 13 | Iteration number: [2940/4518] 65% | Training loss: 0.6871748617311724
Epoch: 13 | Iteration number: [2950/4518] 65% | Training loss: 0.6871760583732087
Epoch: 13 | Iteration number: [2960/4518] 65% | Training loss: 0.6871753569994424
Epoch: 13 | Iteration number: [2970/4518] 65% | Training loss: 0.6871765379953866
Epoch: 13 | Iteration number: [2980/4518] 65% | Training loss: 0.6871746487265465
Epoch: 13 | Iteration number: [2990/4518] 66% | Training loss: 0.6871790531486971
Epoch: 13 | Iteration number: [3000/4518] 66% | Training loss: 0.6871781938473384
Epoch: 13 | Iteration number: [3010/4518] 66% | Training loss: 0.6871808208104384
Epoch: 13 | Iteration number: [3020/4518] 66% | Training loss: 0.6871773714458705
Epoch: 13 | Iteration number: [3030/4518] 67% | Training loss: 0.687176385236652
Epoch: 13 | Iteration number: [3040/4518] 67% | Training loss: 0.6871727932244539
Epoch: 13 | Iteration number: [3050/4518] 67% | Training loss: 0.6871678526284265
Epoch: 13 | Iteration number: [3060/4518] 67% | Training loss: 0.6871655272112952
Epoch: 13 | Iteration number: [3070/4518] 67% | Training loss: 0.6871650055487691
Epoch: 13 | Iteration number: [3080/4518] 68% | Training loss: 0.6871651847254147
Epoch: 13 | Iteration number: [3090/4518] 68% | Training loss: 0.6871655468030269
Epoch: 13 | Iteration number: [3100/4518] 68% | Training loss: 0.687164375532058
Epoch: 13 | Iteration number: [3110/4518] 68% | Training loss: 0.6871625829547932
Epoch: 13 | Iteration number: [3120/4518] 69% | Training loss: 0.6871631963894917
Epoch: 13 | Iteration number: [3130/4518] 69% | Training loss: 0.6871636033058166
Epoch: 13 | Iteration number: [3140/4518] 69% | Training loss: 0.6871609601245564
Epoch: 13 | Iteration number: [3150/4518] 69% | Training loss: 0.6871587965223525
Epoch: 13 | Iteration number: [3160/4518] 69% | Training loss: 0.6871587375485444
Epoch: 13 | Iteration number: [3170/4518] 70% | Training loss: 0.6871591537344719
Epoch: 13 | Iteration number: [3180/4518] 70% | Training loss: 0.687158501935455
Epoch: 13 | Iteration number: [3190/4518] 70% | Training loss: 0.6871584058555316
Epoch: 13 | Iteration number: [3200/4518] 70% | Training loss: 0.6871602452546358
Epoch: 13 | Iteration number: [3210/4518] 71% | Training loss: 0.6871621198186251
Epoch: 13 | Iteration number: [3220/4518] 71% | Training loss: 0.6871578797420359
Epoch: 13 | Iteration number: [3230/4518] 71% | Training loss: 0.6871596137067482
Epoch: 13 | Iteration number: [3240/4518] 71% | Training loss: 0.6871606685497142
Epoch: 13 | Iteration number: [3250/4518] 71% | Training loss: 0.6871613664260278
Epoch: 13 | Iteration number: [3260/4518] 72% | Training loss: 0.6871617935369351
Epoch: 13 | Iteration number: [3270/4518] 72% | Training loss: 0.6871632483391952
Epoch: 13 | Iteration number: [3280/4518] 72% | Training loss: 0.6871624241333182
Epoch: 13 | Iteration number: [3290/4518] 72% | Training loss: 0.6871628039332509
Epoch: 13 | Iteration number: [3300/4518] 73% | Training loss: 0.6871631403583469
Epoch: 13 | Iteration number: [3310/4518] 73% | Training loss: 0.6871620190467719
Epoch: 13 | Iteration number: [3320/4518] 73% | Training loss: 0.6871594893645091
Epoch: 13 | Iteration number: [3330/4518] 73% | Training loss: 0.6871598009053651
Epoch: 13 | Iteration number: [3340/4518] 73% | Training loss: 0.6871581041705822
Epoch: 13 | Iteration number: [3350/4518] 74% | Training loss: 0.6871566930635652
Epoch: 13 | Iteration number: [3360/4518] 74% | Training loss: 0.6871572288019316
Epoch: 13 | Iteration number: [3370/4518] 74% | Training loss: 0.6871583971496152
Epoch: 13 | Iteration number: [3380/4518] 74% | Training loss: 0.6871559721125654
Epoch: 13 | Iteration number: [3390/4518] 75% | Training loss: 0.6871543158823762
Epoch: 13 | Iteration number: [3400/4518] 75% | Training loss: 0.6871523853785851
Epoch: 13 | Iteration number: [3410/4518] 75% | Training loss: 0.6871540299958148
Epoch: 13 | Iteration number: [3420/4518] 75% | Training loss: 0.6871502518305305
Epoch: 13 | Iteration number: [3430/4518] 75% | Training loss: 0.687150900426481
Epoch: 13 | Iteration number: [3440/4518] 76% | Training loss: 0.6871520832527516
Epoch: 13 | Iteration number: [3450/4518] 76% | Training loss: 0.6871539639735568
Epoch: 13 | Iteration number: [3460/4518] 76% | Training loss: 0.6871525571869977
Epoch: 13 | Iteration number: [3470/4518] 76% | Training loss: 0.6871518080103981
Epoch: 13 | Iteration number: [3480/4518] 77% | Training loss: 0.6871487547953924
Epoch: 13 | Iteration number: [3490/4518] 77% | Training loss: 0.6871474557585566
Epoch: 13 | Iteration number: [3500/4518] 77% | Training loss: 0.687149700641632
Epoch: 13 | Iteration number: [3510/4518] 77% | Training loss: 0.6871489449274166
Epoch: 13 | Iteration number: [3520/4518] 77% | Training loss: 0.6871488162909042
Epoch: 13 | Iteration number: [3530/4518] 78% | Training loss: 0.6871503522477136
Epoch: 13 | Iteration number: [3540/4518] 78% | Training loss: 0.6871507941161172
Epoch: 13 | Iteration number: [3550/4518] 78% | Training loss: 0.6871497931446827
Epoch: 13 | Iteration number: [3560/4518] 78% | Training loss: 0.6871482803580466
Epoch: 13 | Iteration number: [3570/4518] 79% | Training loss: 0.6871490924632182
Epoch: 13 | Iteration number: [3580/4518] 79% | Training loss: 0.6871492604137133
Epoch: 13 | Iteration number: [3590/4518] 79% | Training loss: 0.6871509920919838
Epoch: 13 | Iteration number: [3600/4518] 79% | Training loss: 0.6871507625944084
Epoch: 13 | Iteration number: [3610/4518] 79% | Training loss: 0.6871509295751513
Epoch: 13 | Iteration number: [3620/4518] 80% | Training loss: 0.6871514973554822
Epoch: 13 | Iteration number: [3630/4518] 80% | Training loss: 0.6871504082003244
Epoch: 13 | Iteration number: [3640/4518] 80% | Training loss: 0.6871507658408238
Epoch: 13 | Iteration number: [3650/4518] 80% | Training loss: 0.6871510004344051
Epoch: 13 | Iteration number: [3660/4518] 81% | Training loss: 0.6871510930562932
Epoch: 13 | Iteration number: [3670/4518] 81% | Training loss: 0.6871468103549137
Epoch: 13 | Iteration number: [3680/4518] 81% | Training loss: 0.6871438843400582
Epoch: 13 | Iteration number: [3690/4518] 81% | Training loss: 0.6871402641783562
Epoch: 13 | Iteration number: [3700/4518] 81% | Training loss: 0.687137760681075
Epoch: 13 | Iteration number: [3710/4518] 82% | Training loss: 0.6871355190270674
Epoch: 13 | Iteration number: [3720/4518] 82% | Training loss: 0.6871349846964241
Epoch: 13 | Iteration number: [3730/4518] 82% | Training loss: 0.6871330823559544
Epoch: 13 | Iteration number: [3740/4518] 82% | Training loss: 0.6871313624044153
Epoch: 13 | Iteration number: [3750/4518] 83% | Training loss: 0.6871310949166616
Epoch: 13 | Iteration number: [3760/4518] 83% | Training loss: 0.6871296682731902
Epoch: 13 | Iteration number: [3770/4518] 83% | Training loss: 0.6871277381475788
Epoch: 13 | Iteration number: [3780/4518] 83% | Training loss: 0.6871262505729362
Epoch: 13 | Iteration number: [3790/4518] 83% | Training loss: 0.6871271631491216
Epoch: 13 | Iteration number: [3800/4518] 84% | Training loss: 0.6871261779258125
Epoch: 13 | Iteration number: [3810/4518] 84% | Training loss: 0.687124368650081
Epoch: 13 | Iteration number: [3820/4518] 84% | Training loss: 0.6871213332988829
Epoch: 13 | Iteration number: [3830/4518] 84% | Training loss: 0.6871191946084443
Epoch: 13 | Iteration number: [3840/4518] 84% | Training loss: 0.6871187967403481
Epoch: 13 | Iteration number: [3850/4518] 85% | Training loss: 0.6871194795199803
Epoch: 13 | Iteration number: [3860/4518] 85% | Training loss: 0.6871182071884679
Epoch: 13 | Iteration number: [3870/4518] 85% | Training loss: 0.6871207408510746
Epoch: 13 | Iteration number: [3880/4518] 85% | Training loss: 0.6871216277486271
Epoch: 13 | Iteration number: [3890/4518] 86% | Training loss: 0.6871205810869261
Epoch: 13 | Iteration number: [3900/4518] 86% | Training loss: 0.6871180323912547
Epoch: 13 | Iteration number: [3910/4518] 86% | Training loss: 0.6871149976692541
Epoch: 13 | Iteration number: [3920/4518] 86% | Training loss: 0.6871174969235245
Epoch: 13 | Iteration number: [3930/4518] 86% | Training loss: 0.6871202787673504
Epoch: 13 | Iteration number: [3940/4518] 87% | Training loss: 0.6871206652391986
Epoch: 13 | Iteration number: [3950/4518] 87% | Training loss: 0.6871191730831243
Epoch: 13 | Iteration number: [3960/4518] 87% | Training loss: 0.6871164558060241
Epoch: 13 | Iteration number: [3970/4518] 87% | Training loss: 0.6871160295057657
Epoch: 13 | Iteration number: [3980/4518] 88% | Training loss: 0.6871166296640233
Epoch: 13 | Iteration number: [3990/4518] 88% | Training loss: 0.6871190000596202
Epoch: 13 | Iteration number: [4000/4518] 88% | Training loss: 0.6871190907210112
Epoch: 13 | Iteration number: [4010/4518] 88% | Training loss: 0.6871199119269402
Epoch: 13 | Iteration number: [4020/4518] 88% | Training loss: 0.6871193551602055
Epoch: 13 | Iteration number: [4030/4518] 89% | Training loss: 0.6871193358679267
Epoch: 13 | Iteration number: [4040/4518] 89% | Training loss: 0.6871212921520271
Epoch: 13 | Iteration number: [4050/4518] 89% | Training loss: 0.6871222398752048
Epoch: 13 | Iteration number: [4060/4518] 89% | Training loss: 0.6871223488905159
Epoch: 13 | Iteration number: [4070/4518] 90% | Training loss: 0.6871234278274696
Epoch: 13 | Iteration number: [4080/4518] 90% | Training loss: 0.6871234220178688
Epoch: 13 | Iteration number: [4090/4518] 90% | Training loss: 0.6871221317201488
Epoch: 13 | Iteration number: [4100/4518] 90% | Training loss: 0.6871234483253665
Epoch: 13 | Iteration number: [4110/4518] 90% | Training loss: 0.6871251333223932
Epoch: 13 | Iteration number: [4120/4518] 91% | Training loss: 0.687121724344573
Epoch: 13 | Iteration number: [4130/4518] 91% | Training loss: 0.6871215207957759
Epoch: 13 | Iteration number: [4140/4518] 91% | Training loss: 0.6871217055597167
Epoch: 13 | Iteration number: [4150/4518] 91% | Training loss: 0.6871214511595577
Epoch: 13 | Iteration number: [4160/4518] 92% | Training loss: 0.6871208212410028
Epoch: 13 | Iteration number: [4170/4518] 92% | Training loss: 0.6871198407322955
Epoch: 13 | Iteration number: [4180/4518] 92% | Training loss: 0.6871167402518423
Epoch: 13 | Iteration number: [4190/4518] 92% | Training loss: 0.6871141746533515
Epoch: 13 | Iteration number: [4200/4518] 92% | Training loss: 0.687112103729021
Epoch: 13 | Iteration number: [4210/4518] 93% | Training loss: 0.6871139119753079
Epoch: 13 | Iteration number: [4220/4518] 93% | Training loss: 0.687112953397335
Epoch: 13 | Iteration number: [4230/4518] 93% | Training loss: 0.6871127804120382
Epoch: 13 | Iteration number: [4240/4518] 93% | Training loss: 0.6871108142131904
Epoch: 13 | Iteration number: [4250/4518] 94% | Training loss: 0.6871128076385049
Epoch: 13 | Iteration number: [4260/4518] 94% | Training loss: 0.6871109740974758
Epoch: 13 | Iteration number: [4270/4518] 94% | Training loss: 0.6871069190932102
Epoch: 13 | Iteration number: [4280/4518] 94% | Training loss: 0.6871058026903144
Epoch: 13 | Iteration number: [4290/4518] 94% | Training loss: 0.6871077629791829
Epoch: 13 | Iteration number: [4300/4518] 95% | Training loss: 0.6871084275356559
Epoch: 13 | Iteration number: [4310/4518] 95% | Training loss: 0.6871098970177555
Epoch: 13 | Iteration number: [4320/4518] 95% | Training loss: 0.6871088997909316
Epoch: 13 | Iteration number: [4330/4518] 95% | Training loss: 0.6871071065132943
Epoch: 13 | Iteration number: [4340/4518] 96% | Training loss: 0.6871079537176317
Epoch: 13 | Iteration number: [4350/4518] 96% | Training loss: 0.6871084772855386
Epoch: 13 | Iteration number: [4360/4518] 96% | Training loss: 0.687107225336613
Epoch: 13 | Iteration number: [4370/4518] 96% | Training loss: 0.6871098808074707
Epoch: 13 | Iteration number: [4380/4518] 96% | Training loss: 0.6871111567570194
Epoch: 13 | Iteration number: [4390/4518] 97% | Training loss: 0.6871110371549471
Epoch: 13 | Iteration number: [4400/4518] 97% | Training loss: 0.6871118737486276
Epoch: 13 | Iteration number: [4410/4518] 97% | Training loss: 0.6871156559779801
Epoch: 13 | Iteration number: [4420/4518] 97% | Training loss: 0.6871153707013411
Epoch: 13 | Iteration number: [4430/4518] 98% | Training loss: 0.6871146219174964
Epoch: 13 | Iteration number: [4440/4518] 98% | Training loss: 0.6871095745950132
Epoch: 13 | Iteration number: [4450/4518] 98% | Training loss: 0.6871090856027068
Epoch: 13 | Iteration number: [4460/4518] 98% | Training loss: 0.6871083786402048
Epoch: 13 | Iteration number: [4470/4518] 98% | Training loss: 0.6871055284202499
Epoch: 13 | Iteration number: [4480/4518] 99% | Training loss: 0.6871048533756818
Epoch: 13 | Iteration number: [4490/4518] 99% | Training loss: 0.6871057024246334
Epoch: 13 | Iteration number: [4500/4518] 99% | Training loss: 0.6871056139336692
Epoch: 13 | Iteration number: [4510/4518] 99% | Training loss: 0.68710638723458

 End of epoch: 13 | Train Loss: 0.6869537826263045 | Training Time: 641 

 End of epoch: 13 | Eval Loss: 0.6904585130360662 | Evaluating Time: 17 
Epoch: 14 | Iteration number: [10/4518] 0% | Training loss: 0.7563557982444763
Epoch: 14 | Iteration number: [20/4518] 0% | Training loss: 0.7212481796741486
Epoch: 14 | Iteration number: [30/4518] 0% | Training loss: 0.709805566072464
Epoch: 14 | Iteration number: [40/4518] 0% | Training loss: 0.7038155287504196
Epoch: 14 | Iteration number: [50/4518] 1% | Training loss: 0.7006432926654815
Epoch: 14 | Iteration number: [60/4518] 1% | Training loss: 0.6985138068596523
Epoch: 14 | Iteration number: [70/4518] 1% | Training loss: 0.6967778137751988
Epoch: 14 | Iteration number: [80/4518] 1% | Training loss: 0.69549310952425
Epoch: 14 | Iteration number: [90/4518] 1% | Training loss: 0.6946774661540985
Epoch: 14 | Iteration number: [100/4518] 2% | Training loss: 0.6938845312595368
Epoch: 14 | Iteration number: [110/4518] 2% | Training loss: 0.6932485168630427
Epoch: 14 | Iteration number: [120/4518] 2% | Training loss: 0.692668650050958
Epoch: 14 | Iteration number: [130/4518] 2% | Training loss: 0.692321933232821
Epoch: 14 | Iteration number: [140/4518] 3% | Training loss: 0.6918714489255633
Epoch: 14 | Iteration number: [150/4518] 3% | Training loss: 0.6915142210324605
Epoch: 14 | Iteration number: [160/4518] 3% | Training loss: 0.6911683797836303
Epoch: 14 | Iteration number: [170/4518] 3% | Training loss: 0.690905944740071
Epoch: 14 | Iteration number: [180/4518] 3% | Training loss: 0.6906820373402701
Epoch: 14 | Iteration number: [190/4518] 4% | Training loss: 0.6904785159387087
Epoch: 14 | Iteration number: [200/4518] 4% | Training loss: 0.6902866691350937
Epoch: 14 | Iteration number: [210/4518] 4% | Training loss: 0.6900988033839635
Epoch: 14 | Iteration number: [220/4518] 4% | Training loss: 0.6899513892152093
Epoch: 14 | Iteration number: [230/4518] 5% | Training loss: 0.6897829812505971
Epoch: 14 | Iteration number: [240/4518] 5% | Training loss: 0.6896826694409053
Epoch: 14 | Iteration number: [250/4518] 5% | Training loss: 0.6895833053588867
Epoch: 14 | Iteration number: [260/4518] 5% | Training loss: 0.6895000292704656
Epoch: 14 | Iteration number: [270/4518] 5% | Training loss: 0.6893903215726217
Epoch: 14 | Iteration number: [280/4518] 6% | Training loss: 0.6893491046769279
Epoch: 14 | Iteration number: [290/4518] 6% | Training loss: 0.6892575656545573
Epoch: 14 | Iteration number: [300/4518] 6% | Training loss: 0.6891654793421428
Epoch: 14 | Iteration number: [310/4518] 6% | Training loss: 0.6890721992138893
Epoch: 14 | Iteration number: [320/4518] 7% | Training loss: 0.6890080966055393
Epoch: 14 | Iteration number: [330/4518] 7% | Training loss: 0.6889076548995394
Epoch: 14 | Iteration number: [340/4518] 7% | Training loss: 0.6888580269673291
Epoch: 14 | Iteration number: [350/4518] 7% | Training loss: 0.6887796209539686
Epoch: 14 | Iteration number: [360/4518] 7% | Training loss: 0.6887524793545405
Epoch: 14 | Iteration number: [370/4518] 8% | Training loss: 0.6887031352197802
Epoch: 14 | Iteration number: [380/4518] 8% | Training loss: 0.6886715419982609
Epoch: 14 | Iteration number: [390/4518] 8% | Training loss: 0.6886204750109941
Epoch: 14 | Iteration number: [400/4518] 8% | Training loss: 0.6885724675655365
Epoch: 14 | Iteration number: [410/4518] 9% | Training loss: 0.6885290026664734
Epoch: 14 | Iteration number: [420/4518] 9% | Training loss: 0.6884852080118089
Epoch: 14 | Iteration number: [430/4518] 9% | Training loss: 0.6884526940279229
Epoch: 14 | Iteration number: [440/4518] 9% | Training loss: 0.688417473570867
Epoch: 14 | Iteration number: [450/4518] 9% | Training loss: 0.6883592977788713
Epoch: 14 | Iteration number: [460/4518] 10% | Training loss: 0.6883500421824662
Epoch: 14 | Iteration number: [470/4518] 10% | Training loss: 0.6883060823095606
Epoch: 14 | Iteration number: [480/4518] 10% | Training loss: 0.6882973875850439
Epoch: 14 | Iteration number: [490/4518] 10% | Training loss: 0.6882585165451984
Epoch: 14 | Iteration number: [500/4518] 11% | Training loss: 0.688228963971138
Epoch: 14 | Iteration number: [510/4518] 11% | Training loss: 0.6881854726987726
Epoch: 14 | Iteration number: [520/4518] 11% | Training loss: 0.6881739156750533
Epoch: 14 | Iteration number: [530/4518] 11% | Training loss: 0.6881561088112166
Epoch: 14 | Iteration number: [540/4518] 11% | Training loss: 0.6881400035487281
Epoch: 14 | Iteration number: [550/4518] 12% | Training loss: 0.6881203535470095
Epoch: 14 | Iteration number: [560/4518] 12% | Training loss: 0.6881307101675442
Epoch: 14 | Iteration number: [570/4518] 12% | Training loss: 0.6880893931054233
Epoch: 14 | Iteration number: [580/4518] 12% | Training loss: 0.6880813695233444
Epoch: 14 | Iteration number: [590/4518] 13% | Training loss: 0.6880728215484296
Epoch: 14 | Iteration number: [600/4518] 13% | Training loss: 0.6880512693524361
Epoch: 14 | Iteration number: [610/4518] 13% | Training loss: 0.688048201115405
Epoch: 14 | Iteration number: [620/4518] 13% | Training loss: 0.6880379447052556
Epoch: 14 | Iteration number: [630/4518] 13% | Training loss: 0.688002506135002
Epoch: 14 | Iteration number: [640/4518] 14% | Training loss: 0.6879761385731399
Epoch: 14 | Iteration number: [650/4518] 14% | Training loss: 0.6879279300799737
Epoch: 14 | Iteration number: [660/4518] 14% | Training loss: 0.6879230385476892
Epoch: 14 | Iteration number: [670/4518] 14% | Training loss: 0.6878961779288392
Epoch: 14 | Iteration number: [680/4518] 15% | Training loss: 0.6878913691815208
Epoch: 14 | Iteration number: [690/4518] 15% | Training loss: 0.6878920104192651
Epoch: 14 | Iteration number: [700/4518] 15% | Training loss: 0.6878972327709199
Epoch: 14 | Iteration number: [710/4518] 15% | Training loss: 0.6878747443917771
Epoch: 14 | Iteration number: [720/4518] 15% | Training loss: 0.6878568785058128
Epoch: 14 | Iteration number: [730/4518] 16% | Training loss: 0.6878479515036492
Epoch: 14 | Iteration number: [740/4518] 16% | Training loss: 0.6878372676469184
Epoch: 14 | Iteration number: [750/4518] 16% | Training loss: 0.6878405737876893
Epoch: 14 | Iteration number: [760/4518] 16% | Training loss: 0.687822898281248
Epoch: 14 | Iteration number: [770/4518] 17% | Training loss: 0.6878141805723116
Epoch: 14 | Iteration number: [780/4518] 17% | Training loss: 0.6878018849171125
Epoch: 14 | Iteration number: [790/4518] 17% | Training loss: 0.6877936427351795
Epoch: 14 | Iteration number: [800/4518] 17% | Training loss: 0.6877606827020645
Epoch: 14 | Iteration number: [810/4518] 17% | Training loss: 0.6877441034640794
Epoch: 14 | Iteration number: [820/4518] 18% | Training loss: 0.6877380418341335
Epoch: 14 | Iteration number: [830/4518] 18% | Training loss: 0.6877189932817436
Epoch: 14 | Iteration number: [840/4518] 18% | Training loss: 0.6877088502759026
Epoch: 14 | Iteration number: [850/4518] 18% | Training loss: 0.687698907291188
Epoch: 14 | Iteration number: [860/4518] 19% | Training loss: 0.6876918051131936
Epoch: 14 | Iteration number: [870/4518] 19% | Training loss: 0.6876773897943825
Epoch: 14 | Iteration number: [880/4518] 19% | Training loss: 0.6876692123033784
Epoch: 14 | Iteration number: [890/4518] 19% | Training loss: 0.6876533879992667
Epoch: 14 | Iteration number: [900/4518] 19% | Training loss: 0.6876468586921692
Epoch: 14 | Iteration number: [910/4518] 20% | Training loss: 0.687636103276368
Epoch: 14 | Iteration number: [920/4518] 20% | Training loss: 0.6876356651601584
Epoch: 14 | Iteration number: [930/4518] 20% | Training loss: 0.6876353611228286
Epoch: 14 | Iteration number: [940/4518] 20% | Training loss: 0.6876301566971109
Epoch: 14 | Iteration number: [950/4518] 21% | Training loss: 0.6876197050747118
Epoch: 14 | Iteration number: [960/4518] 21% | Training loss: 0.6876027482251327
Epoch: 14 | Iteration number: [970/4518] 21% | Training loss: 0.6875931285705763
Epoch: 14 | Iteration number: [980/4518] 21% | Training loss: 0.6875986279881731
Epoch: 14 | Iteration number: [990/4518] 21% | Training loss: 0.6875956409507328
Epoch: 14 | Iteration number: [1000/4518] 22% | Training loss: 0.6875818644165993
Epoch: 14 | Iteration number: [1010/4518] 22% | Training loss: 0.687585049277485
Epoch: 14 | Iteration number: [1020/4518] 22% | Training loss: 0.6875751778191211
Epoch: 14 | Iteration number: [1030/4518] 22% | Training loss: 0.6875657332753672
Epoch: 14 | Iteration number: [1040/4518] 23% | Training loss: 0.6875567275171096
Epoch: 14 | Iteration number: [1050/4518] 23% | Training loss: 0.6875463726407006
Epoch: 14 | Iteration number: [1060/4518] 23% | Training loss: 0.6875567266401255
Epoch: 14 | Iteration number: [1070/4518] 23% | Training loss: 0.6875544460020333
Epoch: 14 | Iteration number: [1080/4518] 23% | Training loss: 0.6875378772616386
Epoch: 14 | Iteration number: [1090/4518] 24% | Training loss: 0.687524477494966
Epoch: 14 | Iteration number: [1100/4518] 24% | Training loss: 0.6875145704096014
Epoch: 14 | Iteration number: [1110/4518] 24% | Training loss: 0.6875113513018634
Epoch: 14 | Iteration number: [1120/4518] 24% | Training loss: 0.687510662738766
Epoch: 14 | Iteration number: [1130/4518] 25% | Training loss: 0.6875004122215035
Epoch: 14 | Iteration number: [1140/4518] 25% | Training loss: 0.6874916590619505
Epoch: 14 | Iteration number: [1150/4518] 25% | Training loss: 0.6874972827019898
Epoch: 14 | Iteration number: [1160/4518] 25% | Training loss: 0.6874899523525403
Epoch: 14 | Iteration number: [1170/4518] 25% | Training loss: 0.6874954712696565
Epoch: 14 | Iteration number: [1180/4518] 26% | Training loss: 0.6874991430569504
Epoch: 14 | Iteration number: [1190/4518] 26% | Training loss: 0.6875039969672676
Epoch: 14 | Iteration number: [1200/4518] 26% | Training loss: 0.6874972646435101
Epoch: 14 | Iteration number: [1210/4518] 26% | Training loss: 0.6874901480418592
Epoch: 14 | Iteration number: [1220/4518] 27% | Training loss: 0.6874867709933734
Epoch: 14 | Iteration number: [1230/4518] 27% | Training loss: 0.6874822232781387
Epoch: 14 | Iteration number: [1240/4518] 27% | Training loss: 0.6874913987132811
Epoch: 14 | Iteration number: [1250/4518] 27% | Training loss: 0.6874948686599731
Epoch: 14 | Iteration number: [1260/4518] 27% | Training loss: 0.6874899935154688
Epoch: 14 | Iteration number: [1270/4518] 28% | Training loss: 0.6874845127890429
Epoch: 14 | Iteration number: [1280/4518] 28% | Training loss: 0.6874747638124973
Epoch: 14 | Iteration number: [1290/4518] 28% | Training loss: 0.6874670067960902
Epoch: 14 | Iteration number: [1300/4518] 28% | Training loss: 0.6874523551188982
Epoch: 14 | Iteration number: [1310/4518] 28% | Training loss: 0.6874496432206103
Epoch: 14 | Iteration number: [1320/4518] 29% | Training loss: 0.6874447236458461
Epoch: 14 | Iteration number: [1330/4518] 29% | Training loss: 0.6874391289133774
Epoch: 14 | Iteration number: [1340/4518] 29% | Training loss: 0.6874401889630218
Epoch: 14 | Iteration number: [1350/4518] 29% | Training loss: 0.6874352770381503
Epoch: 14 | Iteration number: [1360/4518] 30% | Training loss: 0.6874365638722392
Epoch: 14 | Iteration number: [1370/4518] 30% | Training loss: 0.6874360141527914
Epoch: 14 | Iteration number: [1380/4518] 30% | Training loss: 0.6874285380909408
Epoch: 14 | Iteration number: [1390/4518] 30% | Training loss: 0.6874322275892436
Epoch: 14 | Iteration number: [1400/4518] 30% | Training loss: 0.687427309198039
Epoch: 14 | Iteration number: [1410/4518] 31% | Training loss: 0.687428034239627
Epoch: 14 | Iteration number: [1420/4518] 31% | Training loss: 0.6874293444442078
Epoch: 14 | Iteration number: [1430/4518] 31% | Training loss: 0.6874312477928776
Epoch: 14 | Iteration number: [1440/4518] 31% | Training loss: 0.6874276753928926
Epoch: 14 | Iteration number: [1450/4518] 32% | Training loss: 0.6874203513408529
Epoch: 14 | Iteration number: [1460/4518] 32% | Training loss: 0.6874124199968494
Epoch: 14 | Iteration number: [1470/4518] 32% | Training loss: 0.6874067072154714
Epoch: 14 | Iteration number: [1480/4518] 32% | Training loss: 0.687403683525485
Epoch: 14 | Iteration number: [1490/4518] 32% | Training loss: 0.6874016403751886
Epoch: 14 | Iteration number: [1500/4518] 33% | Training loss: 0.6874023611942927
Epoch: 14 | Iteration number: [1510/4518] 33% | Training loss: 0.6874024819459347
Epoch: 14 | Iteration number: [1520/4518] 33% | Training loss: 0.6874029505409692
Epoch: 14 | Iteration number: [1530/4518] 33% | Training loss: 0.6874116928748835
Epoch: 14 | Iteration number: [1540/4518] 34% | Training loss: 0.6874035460221303
Epoch: 14 | Iteration number: [1550/4518] 34% | Training loss: 0.6874026915334887
Epoch: 14 | Iteration number: [1560/4518] 34% | Training loss: 0.687411076365373
Epoch: 14 | Iteration number: [1570/4518] 34% | Training loss: 0.68740596144822
Epoch: 14 | Iteration number: [1580/4518] 34% | Training loss: 0.6874112644150288
Epoch: 14 | Iteration number: [1590/4518] 35% | Training loss: 0.687411616883188
Epoch: 14 | Iteration number: [1600/4518] 35% | Training loss: 0.6874097433686256
Epoch: 14 | Iteration number: [1610/4518] 35% | Training loss: 0.6874071506239613
Epoch: 14 | Iteration number: [1620/4518] 35% | Training loss: 0.687395973632365
Epoch: 14 | Iteration number: [1630/4518] 36% | Training loss: 0.6874034233985503
Epoch: 14 | Iteration number: [1640/4518] 36% | Training loss: 0.6874009090952757
Epoch: 14 | Iteration number: [1650/4518] 36% | Training loss: 0.6874009280132525
Epoch: 14 | Iteration number: [1660/4518] 36% | Training loss: 0.687393952493208
Epoch: 14 | Iteration number: [1670/4518] 36% | Training loss: 0.6873988978163211
Epoch: 14 | Iteration number: [1680/4518] 37% | Training loss: 0.6873920255473682
Epoch: 14 | Iteration number: [1690/4518] 37% | Training loss: 0.6873864244427201
Epoch: 14 | Iteration number: [1700/4518] 37% | Training loss: 0.6873894501083038
Epoch: 14 | Iteration number: [1710/4518] 37% | Training loss: 0.6873825290746857
Epoch: 14 | Iteration number: [1720/4518] 38% | Training loss: 0.6873800137708354
Epoch: 14 | Iteration number: [1730/4518] 38% | Training loss: 0.6873776708379646
Epoch: 14 | Iteration number: [1740/4518] 38% | Training loss: 0.6873677236937928
Epoch: 14 | Iteration number: [1750/4518] 38% | Training loss: 0.6873652309349605
Epoch: 14 | Iteration number: [1760/4518] 38% | Training loss: 0.6873667519878257
Epoch: 14 | Iteration number: [1770/4518] 39% | Training loss: 0.6873692749247039
Epoch: 14 | Iteration number: [1780/4518] 39% | Training loss: 0.6873699600776929
Epoch: 14 | Iteration number: [1790/4518] 39% | Training loss: 0.687363065554443
Epoch: 14 | Iteration number: [1800/4518] 39% | Training loss: 0.6873512471715609
Epoch: 14 | Iteration number: [1810/4518] 40% | Training loss: 0.6873478746545908
Epoch: 14 | Iteration number: [1820/4518] 40% | Training loss: 0.687354938014523
Epoch: 14 | Iteration number: [1830/4518] 40% | Training loss: 0.6873516740369014
Epoch: 14 | Iteration number: [1840/4518] 40% | Training loss: 0.6873542830995891
Epoch: 14 | Iteration number: [1850/4518] 40% | Training loss: 0.68736036204003
Epoch: 14 | Iteration number: [1860/4518] 41% | Training loss: 0.6873541946052223
Epoch: 14 | Iteration number: [1870/4518] 41% | Training loss: 0.6873497606598757
Epoch: 14 | Iteration number: [1880/4518] 41% | Training loss: 0.6873548589488293
Epoch: 14 | Iteration number: [1890/4518] 41% | Training loss: 0.6873581868630868
Epoch: 14 | Iteration number: [1900/4518] 42% | Training loss: 0.6873593771771381
Epoch: 14 | Iteration number: [1910/4518] 42% | Training loss: 0.6873635549819906
Epoch: 14 | Iteration number: [1920/4518] 42% | Training loss: 0.6873576703791817
Epoch: 14 | Iteration number: [1930/4518] 42% | Training loss: 0.6873547131224618
Epoch: 14 | Iteration number: [1940/4518] 42% | Training loss: 0.6873513716090586
Epoch: 14 | Iteration number: [1950/4518] 43% | Training loss: 0.687344295275517
Epoch: 14 | Iteration number: [1960/4518] 43% | Training loss: 0.6873394500844333
Epoch: 14 | Iteration number: [1970/4518] 43% | Training loss: 0.6873368350079823
Epoch: 14 | Iteration number: [1980/4518] 43% | Training loss: 0.6873407554144811
Epoch: 14 | Iteration number: [1990/4518] 44% | Training loss: 0.687334864313279
Epoch: 14 | Iteration number: [2000/4518] 44% | Training loss: 0.6873359977006912
Epoch: 14 | Iteration number: [2010/4518] 44% | Training loss: 0.6873313625950125
Epoch: 14 | Iteration number: [2020/4518] 44% | Training loss: 0.6873312008853006
Epoch: 14 | Iteration number: [2030/4518] 44% | Training loss: 0.6873311370464381
Epoch: 14 | Iteration number: [2040/4518] 45% | Training loss: 0.6873301132636912
Epoch: 14 | Iteration number: [2050/4518] 45% | Training loss: 0.6873251892880695
Epoch: 14 | Iteration number: [2060/4518] 45% | Training loss: 0.6873261397903405
Epoch: 14 | Iteration number: [2070/4518] 45% | Training loss: 0.6873261963975602
Epoch: 14 | Iteration number: [2080/4518] 46% | Training loss: 0.6873283707178556
Epoch: 14 | Iteration number: [2090/4518] 46% | Training loss: 0.6873269395679948
Epoch: 14 | Iteration number: [2100/4518] 46% | Training loss: 0.6873249117249535
Epoch: 14 | Iteration number: [2110/4518] 46% | Training loss: 0.6873182214831854
Epoch: 14 | Iteration number: [2120/4518] 46% | Training loss: 0.6873165305774167
Epoch: 14 | Iteration number: [2130/4518] 47% | Training loss: 0.687311950647775
Epoch: 14 | Iteration number: [2140/4518] 47% | Training loss: 0.6873077889469182
Epoch: 14 | Iteration number: [2150/4518] 47% | Training loss: 0.6873062880926354
Epoch: 14 | Iteration number: [2160/4518] 47% | Training loss: 0.6873020433165409
Epoch: 14 | Iteration number: [2170/4518] 48% | Training loss: 0.6873063473932205
Epoch: 14 | Iteration number: [2180/4518] 48% | Training loss: 0.6872965339126937
Epoch: 14 | Iteration number: [2190/4518] 48% | Training loss: 0.6872934962788674
Epoch: 14 | Iteration number: [2200/4518] 48% | Training loss: 0.6872976145690137
Epoch: 14 | Iteration number: [2210/4518] 48% | Training loss: 0.68729417313278
Epoch: 14 | Iteration number: [2220/4518] 49% | Training loss: 0.6872917488083109
Epoch: 14 | Iteration number: [2230/4518] 49% | Training loss: 0.6872979110666455
Epoch: 14 | Iteration number: [2240/4518] 49% | Training loss: 0.6872937032952905
Epoch: 14 | Iteration number: [2250/4518] 49% | Training loss: 0.687297243197759
Epoch: 14 | Iteration number: [2260/4518] 50% | Training loss: 0.6872931336407113
Epoch: 14 | Iteration number: [2270/4518] 50% | Training loss: 0.6872938005934728
Epoch: 14 | Iteration number: [2280/4518] 50% | Training loss: 0.6872868742336307
Epoch: 14 | Iteration number: [2290/4518] 50% | Training loss: 0.6872873574625457
Epoch: 14 | Iteration number: [2300/4518] 50% | Training loss: 0.6872808750816014
Epoch: 14 | Iteration number: [2310/4518] 51% | Training loss: 0.6872797332800828
Epoch: 14 | Iteration number: [2320/4518] 51% | Training loss: 0.6872804497336519
Epoch: 14 | Iteration number: [2330/4518] 51% | Training loss: 0.6872801728770457
Epoch: 14 | Iteration number: [2340/4518] 51% | Training loss: 0.6872714173080575
Epoch: 14 | Iteration number: [2350/4518] 52% | Training loss: 0.687269657571265
Epoch: 14 | Iteration number: [2360/4518] 52% | Training loss: 0.6872710739909592
Epoch: 14 | Iteration number: [2370/4518] 52% | Training loss: 0.6872665069274259
Epoch: 14 | Iteration number: [2380/4518] 52% | Training loss: 0.6872635197990081
Epoch: 14 | Iteration number: [2390/4518] 52% | Training loss: 0.6872654844776855
Epoch: 14 | Iteration number: [2400/4518] 53% | Training loss: 0.687266007438302
Epoch: 14 | Iteration number: [2410/4518] 53% | Training loss: 0.6872641316340672
Epoch: 14 | Iteration number: [2420/4518] 53% | Training loss: 0.6872584784326474
Epoch: 14 | Iteration number: [2430/4518] 53% | Training loss: 0.6872612033606557
Epoch: 14 | Iteration number: [2440/4518] 54% | Training loss: 0.6872646958124442
Epoch: 14 | Iteration number: [2450/4518] 54% | Training loss: 0.6872628855948546
Epoch: 14 | Iteration number: [2460/4518] 54% | Training loss: 0.6872634900052373
Epoch: 14 | Iteration number: [2470/4518] 54% | Training loss: 0.6872586810395785
Epoch: 14 | Iteration number: [2480/4518] 54% | Training loss: 0.687253769559245
Epoch: 14 | Iteration number: [2490/4518] 55% | Training loss: 0.6872524026646671
Epoch: 14 | Iteration number: [2500/4518] 55% | Training loss: 0.6872537195205688
Epoch: 14 | Iteration number: [2510/4518] 55% | Training loss: 0.6872552271620685
Epoch: 14 | Iteration number: [2520/4518] 55% | Training loss: 0.6872580730962374
Epoch: 14 | Iteration number: [2530/4518] 55% | Training loss: 0.6872582544922358
Epoch: 14 | Iteration number: [2540/4518] 56% | Training loss: 0.6872535283171286
Epoch: 14 | Iteration number: [2550/4518] 56% | Training loss: 0.6872488055275936
Epoch: 14 | Iteration number: [2560/4518] 56% | Training loss: 0.6872461654944345
Epoch: 14 | Iteration number: [2570/4518] 56% | Training loss: 0.6872476467362638
Epoch: 14 | Iteration number: [2580/4518] 57% | Training loss: 0.6872464929209199
Epoch: 14 | Iteration number: [2590/4518] 57% | Training loss: 0.6872446758406503
Epoch: 14 | Iteration number: [2600/4518] 57% | Training loss: 0.6872408758676969
Epoch: 14 | Iteration number: [2610/4518] 57% | Training loss: 0.6872376822877204
Epoch: 14 | Iteration number: [2620/4518] 57% | Training loss: 0.6872377769410155
Epoch: 14 | Iteration number: [2630/4518] 58% | Training loss: 0.6872391983583399
Epoch: 14 | Iteration number: [2640/4518] 58% | Training loss: 0.6872404506260699
Epoch: 14 | Iteration number: [2650/4518] 58% | Training loss: 0.6872401988956164
Epoch: 14 | Iteration number: [2660/4518] 58% | Training loss: 0.6872345429838151
Epoch: 14 | Iteration number: [2670/4518] 59% | Training loss: 0.6872353712271215
Epoch: 14 | Iteration number: [2680/4518] 59% | Training loss: 0.6872329458816727
Epoch: 14 | Iteration number: [2690/4518] 59% | Training loss: 0.6872300839557081
Epoch: 14 | Iteration number: [2700/4518] 59% | Training loss: 0.6872309114094134
Epoch: 14 | Iteration number: [2710/4518] 59% | Training loss: 0.6872245745905211
Epoch: 14 | Iteration number: [2720/4518] 60% | Training loss: 0.6872239970547311
Epoch: 14 | Iteration number: [2730/4518] 60% | Training loss: 0.6872213213216691
Epoch: 14 | Iteration number: [2740/4518] 60% | Training loss: 0.687220030544448
Epoch: 14 | Iteration number: [2750/4518] 60% | Training loss: 0.6872211031263524
Epoch: 14 | Iteration number: [2760/4518] 61% | Training loss: 0.687220501381418
Epoch: 14 | Iteration number: [2770/4518] 61% | Training loss: 0.6872241064529556
Epoch: 14 | Iteration number: [2780/4518] 61% | Training loss: 0.6872265611621116
Epoch: 14 | Iteration number: [2790/4518] 61% | Training loss: 0.6872269706273164
Epoch: 14 | Iteration number: [2800/4518] 61% | Training loss: 0.6872263632076128
Epoch: 14 | Iteration number: [2810/4518] 62% | Training loss: 0.6872268459762967
Epoch: 14 | Iteration number: [2820/4518] 62% | Training loss: 0.6872274923197766
Epoch: 14 | Iteration number: [2830/4518] 62% | Training loss: 0.6872288399997953
Epoch: 14 | Iteration number: [2840/4518] 62% | Training loss: 0.6872290918105085
Epoch: 14 | Iteration number: [2850/4518] 63% | Training loss: 0.6872282045347649
Epoch: 14 | Iteration number: [2860/4518] 63% | Training loss: 0.687229383846263
Epoch: 14 | Iteration number: [2870/4518] 63% | Training loss: 0.687226157466709
Epoch: 14 | Iteration number: [2880/4518] 63% | Training loss: 0.6872249801539713
Epoch: 14 | Iteration number: [2890/4518] 63% | Training loss: 0.6872261972163375
Epoch: 14 | Iteration number: [2900/4518] 64% | Training loss: 0.687227967545904
Epoch: 14 | Iteration number: [2910/4518] 64% | Training loss: 0.6872292263401333
Epoch: 14 | Iteration number: [2920/4518] 64% | Training loss: 0.6872313519046731
Epoch: 14 | Iteration number: [2930/4518] 64% | Training loss: 0.6872304246490726
Epoch: 14 | Iteration number: [2940/4518] 65% | Training loss: 0.6872272026782134
Epoch: 14 | Iteration number: [2950/4518] 65% | Training loss: 0.6872207128395469
Epoch: 14 | Iteration number: [2960/4518] 65% | Training loss: 0.6872238826711435
Epoch: 14 | Iteration number: [2970/4518] 65% | Training loss: 0.6872211201423748
Epoch: 14 | Iteration number: [2980/4518] 65% | Training loss: 0.6872239349672459
Epoch: 14 | Iteration number: [2990/4518] 66% | Training loss: 0.6872178261296008
Epoch: 14 | Iteration number: [3000/4518] 66% | Training loss: 0.687220523973306
Epoch: 14 | Iteration number: [3010/4518] 66% | Training loss: 0.6872182488045423
Epoch: 14 | Iteration number: [3020/4518] 66% | Training loss: 0.687219820216002
Epoch: 14 | Iteration number: [3030/4518] 67% | Training loss: 0.6872219958124381
Epoch: 14 | Iteration number: [3040/4518] 67% | Training loss: 0.687220601384577
Epoch: 14 | Iteration number: [3050/4518] 67% | Training loss: 0.6872142405588119
Epoch: 14 | Iteration number: [3060/4518] 67% | Training loss: 0.6872133254225737
Epoch: 14 | Iteration number: [3070/4518] 67% | Training loss: 0.687209829115324
Epoch: 14 | Iteration number: [3080/4518] 68% | Training loss: 0.6872033153454978
Epoch: 14 | Iteration number: [3090/4518] 68% | Training loss: 0.6872026395450518
Epoch: 14 | Iteration number: [3100/4518] 68% | Training loss: 0.6872040201387097
Epoch: 14 | Iteration number: [3110/4518] 68% | Training loss: 0.6872065687677867
Epoch: 14 | Iteration number: [3120/4518] 69% | Training loss: 0.6872032121396981
Epoch: 14 | Iteration number: [3130/4518] 69% | Training loss: 0.6872044667077902
Epoch: 14 | Iteration number: [3140/4518] 69% | Training loss: 0.687200102988322
Epoch: 14 | Iteration number: [3150/4518] 69% | Training loss: 0.687195948646182
Epoch: 14 | Iteration number: [3160/4518] 69% | Training loss: 0.6871970807638349
Epoch: 14 | Iteration number: [3170/4518] 70% | Training loss: 0.6871996194782317
Epoch: 14 | Iteration number: [3180/4518] 70% | Training loss: 0.6872021335663285
Epoch: 14 | Iteration number: [3190/4518] 70% | Training loss: 0.6872023311715141
Epoch: 14 | Iteration number: [3200/4518] 70% | Training loss: 0.687199028711766
Epoch: 14 | Iteration number: [3210/4518] 71% | Training loss: 0.6871986451735749
Epoch: 14 | Iteration number: [3220/4518] 71% | Training loss: 0.6871966907696694
Epoch: 14 | Iteration number: [3230/4518] 71% | Training loss: 0.6871974833978588
Epoch: 14 | Iteration number: [3240/4518] 71% | Training loss: 0.6872014186080592
Epoch: 14 | Iteration number: [3250/4518] 71% | Training loss: 0.6871944092420431
Epoch: 14 | Iteration number: [3260/4518] 72% | Training loss: 0.6871924359557088
Epoch: 14 | Iteration number: [3270/4518] 72% | Training loss: 0.6871924849825168
Epoch: 14 | Iteration number: [3280/4518] 72% | Training loss: 0.6871937856441591
Epoch: 14 | Iteration number: [3290/4518] 72% | Training loss: 0.6871987500995126
Epoch: 14 | Iteration number: [3300/4518] 73% | Training loss: 0.6871968509392304
Epoch: 14 | Iteration number: [3310/4518] 73% | Training loss: 0.6871946647628197
Epoch: 14 | Iteration number: [3320/4518] 73% | Training loss: 0.6871916127492146
Epoch: 14 | Iteration number: [3330/4518] 73% | Training loss: 0.6871880689719776
Epoch: 14 | Iteration number: [3340/4518] 73% | Training loss: 0.6871892902130139
Epoch: 14 | Iteration number: [3350/4518] 74% | Training loss: 0.6871898521416223
Epoch: 14 | Iteration number: [3360/4518] 74% | Training loss: 0.6871908816730692
Epoch: 14 | Iteration number: [3370/4518] 74% | Training loss: 0.6871898053307915
Epoch: 14 | Iteration number: [3380/4518] 74% | Training loss: 0.6871864882799296
Epoch: 14 | Iteration number: [3390/4518] 75% | Training loss: 0.6871853449527493
Epoch: 14 | Iteration number: [3400/4518] 75% | Training loss: 0.687185119600857
Epoch: 14 | Iteration number: [3410/4518] 75% | Training loss: 0.687188283351859
Epoch: 14 | Iteration number: [3420/4518] 75% | Training loss: 0.6871914297690865
Epoch: 14 | Iteration number: [3430/4518] 75% | Training loss: 0.6871916374207934
Epoch: 14 | Iteration number: [3440/4518] 76% | Training loss: 0.6871913517283839
Epoch: 14 | Iteration number: [3450/4518] 76% | Training loss: 0.6871922567098037
Epoch: 14 | Iteration number: [3460/4518] 76% | Training loss: 0.6871889842383434
Epoch: 14 | Iteration number: [3470/4518] 76% | Training loss: 0.687190071186346
Epoch: 14 | Iteration number: [3480/4518] 77% | Training loss: 0.687189169296588
Epoch: 14 | Iteration number: [3490/4518] 77% | Training loss: 0.6871886814904418
Epoch: 14 | Iteration number: [3500/4518] 77% | Training loss: 0.6871913493531091
Epoch: 14 | Iteration number: [3510/4518] 77% | Training loss: 0.6871888534295932
Epoch: 14 | Iteration number: [3520/4518] 77% | Training loss: 0.6871861784295602
Epoch: 14 | Iteration number: [3530/4518] 78% | Training loss: 0.6871866423246206
Epoch: 14 | Iteration number: [3540/4518] 78% | Training loss: 0.6871832538290886
Epoch: 14 | Iteration number: [3550/4518] 78% | Training loss: 0.6871802237671866
Epoch: 14 | Iteration number: [3560/4518] 78% | Training loss: 0.6871777652857008
Epoch: 14 | Iteration number: [3570/4518] 79% | Training loss: 0.6871755944079712
Epoch: 14 | Iteration number: [3580/4518] 79% | Training loss: 0.6871741094236268
Epoch: 14 | Iteration number: [3590/4518] 79% | Training loss: 0.6871724867389063
Epoch: 14 | Iteration number: [3600/4518] 79% | Training loss: 0.6871762517591318
Epoch: 14 | Iteration number: [3610/4518] 79% | Training loss: 0.6871774696907509
Epoch: 14 | Iteration number: [3620/4518] 80% | Training loss: 0.6871749819642272
Epoch: 14 | Iteration number: [3630/4518] 80% | Training loss: 0.6871742539990375
Epoch: 14 | Iteration number: [3640/4518] 80% | Training loss: 0.6871748960935152
Epoch: 14 | Iteration number: [3650/4518] 80% | Training loss: 0.6871755267332678
Epoch: 14 | Iteration number: [3660/4518] 81% | Training loss: 0.6871748366642519
Epoch: 14 | Iteration number: [3670/4518] 81% | Training loss: 0.6871760224126665
Epoch: 14 | Iteration number: [3680/4518] 81% | Training loss: 0.6871711480228797
Epoch: 14 | Iteration number: [3690/4518] 81% | Training loss: 0.6871683968114982
Epoch: 14 | Iteration number: [3700/4518] 81% | Training loss: 0.6871685071893641
Epoch: 14 | Iteration number: [3710/4518] 82% | Training loss: 0.687168983645195
Epoch: 14 | Iteration number: [3720/4518] 82% | Training loss: 0.6871666477252079
Epoch: 14 | Iteration number: [3730/4518] 82% | Training loss: 0.6871670865820816
Epoch: 14 | Iteration number: [3740/4518] 82% | Training loss: 0.6871681273939775
Epoch: 14 | Iteration number: [3750/4518] 83% | Training loss: 0.6871641016801199
Epoch: 14 | Iteration number: [3760/4518] 83% | Training loss: 0.6871625395372827
Epoch: 14 | Iteration number: [3770/4518] 83% | Training loss: 0.6871641875736277
Epoch: 14 | Iteration number: [3780/4518] 83% | Training loss: 0.687163797793565
Epoch: 14 | Iteration number: [3790/4518] 83% | Training loss: 0.6871601329944379
Epoch: 14 | Iteration number: [3800/4518] 84% | Training loss: 0.6871589354308028
Epoch: 14 | Iteration number: [3810/4518] 84% | Training loss: 0.6871566803905907
Epoch: 14 | Iteration number: [3820/4518] 84% | Training loss: 0.6871550466689764
Epoch: 14 | Iteration number: [3830/4518] 84% | Training loss: 0.6871525924604182
Epoch: 14 | Iteration number: [3840/4518] 84% | Training loss: 0.6871513282724967
Epoch: 14 | Iteration number: [3850/4518] 85% | Training loss: 0.687151622307765
Epoch: 14 | Iteration number: [3860/4518] 85% | Training loss: 0.6871522064190454
Epoch: 14 | Iteration number: [3870/4518] 85% | Training loss: 0.6871536832139166
Epoch: 14 | Iteration number: [3880/4518] 85% | Training loss: 0.6871532537580766
Epoch: 14 | Iteration number: [3890/4518] 86% | Training loss: 0.6871487302154992
Epoch: 14 | Iteration number: [3900/4518] 86% | Training loss: 0.6871483646447842
Epoch: 14 | Iteration number: [3910/4518] 86% | Training loss: 0.6871482060236089
Epoch: 14 | Iteration number: [3920/4518] 86% | Training loss: 0.6871469537518462
Epoch: 14 | Iteration number: [3930/4518] 86% | Training loss: 0.687143586170279
Epoch: 14 | Iteration number: [3940/4518] 87% | Training loss: 0.6871427383822233
Epoch: 14 | Iteration number: [3950/4518] 87% | Training loss: 0.6871437457392487
Epoch: 14 | Iteration number: [3960/4518] 87% | Training loss: 0.6871445269145147
Epoch: 14 | Iteration number: [3970/4518] 87% | Training loss: 0.687146134580713
Epoch: 14 | Iteration number: [3980/4518] 88% | Training loss: 0.6871470252622911
Epoch: 14 | Iteration number: [3990/4518] 88% | Training loss: 0.6871450319624783
Epoch: 14 | Iteration number: [4000/4518] 88% | Training loss: 0.6871457591503859
Epoch: 14 | Iteration number: [4010/4518] 88% | Training loss: 0.6871456021085345
Epoch: 14 | Iteration number: [4020/4518] 88% | Training loss: 0.6871427954281147
Epoch: 14 | Iteration number: [4030/4518] 89% | Training loss: 0.6871431038190354
Epoch: 14 | Iteration number: [4040/4518] 89% | Training loss: 0.6871413079228732
Epoch: 14 | Iteration number: [4050/4518] 89% | Training loss: 0.6871391708615385
Epoch: 14 | Iteration number: [4060/4518] 89% | Training loss: 0.6871393358912962
Epoch: 14 | Iteration number: [4070/4518] 90% | Training loss: 0.6871406316610753
Epoch: 14 | Iteration number: [4080/4518] 90% | Training loss: 0.6871363620547687
Epoch: 14 | Iteration number: [4090/4518] 90% | Training loss: 0.6871329010990255
Epoch: 14 | Iteration number: [4100/4518] 90% | Training loss: 0.6871330529305993
Epoch: 14 | Iteration number: [4110/4518] 90% | Training loss: 0.6871312197252492
Epoch: 14 | Iteration number: [4120/4518] 91% | Training loss: 0.6871282824758187
Epoch: 14 | Iteration number: [4130/4518] 91% | Training loss: 0.6871272688339178
Epoch: 14 | Iteration number: [4140/4518] 91% | Training loss: 0.687127627381956
Epoch: 14 | Iteration number: [4150/4518] 91% | Training loss: 0.6871279535954257
Epoch: 14 | Iteration number: [4160/4518] 92% | Training loss: 0.6871301537666183
Epoch: 14 | Iteration number: [4170/4518] 92% | Training loss: 0.6871313643112457
Epoch: 14 | Iteration number: [4180/4518] 92% | Training loss: 0.6871260015445463
Epoch: 14 | Iteration number: [4190/4518] 92% | Training loss: 0.6871238357696442
Epoch: 14 | Iteration number: [4200/4518] 92% | Training loss: 0.6871204849651882
Epoch: 14 | Iteration number: [4210/4518] 93% | Training loss: 0.6871209289427325
Epoch: 14 | Iteration number: [4220/4518] 93% | Training loss: 0.6871167220069334
Epoch: 14 | Iteration number: [4230/4518] 93% | Training loss: 0.6871165801729152
Epoch: 14 | Iteration number: [4240/4518] 93% | Training loss: 0.6871157406776581
Epoch: 14 | Iteration number: [4250/4518] 94% | Training loss: 0.6871140849730548
Epoch: 14 | Iteration number: [4260/4518] 94% | Training loss: 0.6871117967535073
Epoch: 14 | Iteration number: [4270/4518] 94% | Training loss: 0.6871126647855414
Epoch: 14 | Iteration number: [4280/4518] 94% | Training loss: 0.6871095396230154
Epoch: 14 | Iteration number: [4290/4518] 94% | Training loss: 0.6871078339628962
Epoch: 14 | Iteration number: [4300/4518] 95% | Training loss: 0.6871102741014126
Epoch: 14 | Iteration number: [4310/4518] 95% | Training loss: 0.6871102848489987
Epoch: 14 | Iteration number: [4320/4518] 95% | Training loss: 0.6871119421113421
Epoch: 14 | Iteration number: [4330/4518] 95% | Training loss: 0.6871100488215616
Epoch: 14 | Iteration number: [4340/4518] 96% | Training loss: 0.6871068659328645
Epoch: 14 | Iteration number: [4350/4518] 96% | Training loss: 0.6871022432562949
Epoch: 14 | Iteration number: [4360/4518] 96% | Training loss: 0.6871025898724521
Epoch: 14 | Iteration number: [4370/4518] 96% | Training loss: 0.6871014884462073
Epoch: 14 | Iteration number: [4380/4518] 96% | Training loss: 0.6871008965930983
Epoch: 14 | Iteration number: [4390/4518] 97% | Training loss: 0.6871009469168061
Epoch: 14 | Iteration number: [4400/4518] 97% | Training loss: 0.6871001662449403
Epoch: 14 | Iteration number: [4410/4518] 97% | Training loss: 0.6870981795312056
Epoch: 14 | Iteration number: [4420/4518] 97% | Training loss: 0.6870992398774463
Epoch: 14 | Iteration number: [4430/4518] 98% | Training loss: 0.6870978086446801
Epoch: 14 | Iteration number: [4440/4518] 98% | Training loss: 0.6871001001950857
Epoch: 14 | Iteration number: [4450/4518] 98% | Training loss: 0.6871004351471247
Epoch: 14 | Iteration number: [4460/4518] 98% | Training loss: 0.687098380174872
Epoch: 14 | Iteration number: [4470/4518] 98% | Training loss: 0.6870966468614753
Epoch: 14 | Iteration number: [4480/4518] 99% | Training loss: 0.6870994505472481
Epoch: 14 | Iteration number: [4490/4518] 99% | Training loss: 0.6870972832486465
Epoch: 14 | Iteration number: [4500/4518] 99% | Training loss: 0.6870995733737946
Epoch: 14 | Iteration number: [4510/4518] 99% | Training loss: 0.6870988067660786

 End of epoch: 14 | Train Loss: 0.6869462265832174 | Training Time: 642 

 End of epoch: 14 | Eval Loss: 0.6904284358024597 | Evaluating Time: 17 
Epoch: 15 | Iteration number: [10/4518] 0% | Training loss: 0.7547033786773681
Epoch: 15 | Iteration number: [20/4518] 0% | Training loss: 0.720489639043808
Epoch: 15 | Iteration number: [30/4518] 0% | Training loss: 0.7096226354440053
Epoch: 15 | Iteration number: [40/4518] 0% | Training loss: 0.7040324121713638
Epoch: 15 | Iteration number: [50/4518] 1% | Training loss: 0.7008086287975311
Epoch: 15 | Iteration number: [60/4518] 1% | Training loss: 0.6985933681329092
Epoch: 15 | Iteration number: [70/4518] 1% | Training loss: 0.6970723407609122
Epoch: 15 | Iteration number: [80/4518] 1% | Training loss: 0.6959108754992485
Epoch: 15 | Iteration number: [90/4518] 1% | Training loss: 0.694839123222563
Epoch: 15 | Iteration number: [100/4518] 2% | Training loss: 0.6941030472517014
Epoch: 15 | Iteration number: [110/4518] 2% | Training loss: 0.6935156144879081
Epoch: 15 | Iteration number: [120/4518] 2% | Training loss: 0.6930170560876528
Epoch: 15 | Iteration number: [130/4518] 2% | Training loss: 0.6925563770991106
Epoch: 15 | Iteration number: [140/4518] 3% | Training loss: 0.6921322469200407
Epoch: 15 | Iteration number: [150/4518] 3% | Training loss: 0.6918025231361389
Epoch: 15 | Iteration number: [160/4518] 3% | Training loss: 0.6914859540760517
Epoch: 15 | Iteration number: [170/4518] 3% | Training loss: 0.6911878175595227
Epoch: 15 | Iteration number: [180/4518] 3% | Training loss: 0.6910387555758158
Epoch: 15 | Iteration number: [190/4518] 4% | Training loss: 0.6908026020777853
Epoch: 15 | Iteration number: [200/4518] 4% | Training loss: 0.6906867900490761
Epoch: 15 | Iteration number: [210/4518] 4% | Training loss: 0.6904789501712436
Epoch: 15 | Iteration number: [220/4518] 4% | Training loss: 0.6903689942576668
Epoch: 15 | Iteration number: [230/4518] 5% | Training loss: 0.6901852003906084
Epoch: 15 | Iteration number: [240/4518] 5% | Training loss: 0.6900196303923924
Epoch: 15 | Iteration number: [250/4518] 5% | Training loss: 0.6898525500297547
Epoch: 15 | Iteration number: [260/4518] 5% | Training loss: 0.6897080091329721
Epoch: 15 | Iteration number: [270/4518] 5% | Training loss: 0.6896287748107204
Epoch: 15 | Iteration number: [280/4518] 6% | Training loss: 0.6895390095455306
Epoch: 15 | Iteration number: [290/4518] 6% | Training loss: 0.6894148904701759
Epoch: 15 | Iteration number: [300/4518] 6% | Training loss: 0.6893163593610128
Epoch: 15 | Iteration number: [310/4518] 6% | Training loss: 0.6892118965425799
Epoch: 15 | Iteration number: [320/4518] 7% | Training loss: 0.6891128916293383
Epoch: 15 | Iteration number: [330/4518] 7% | Training loss: 0.6890616868481492
Epoch: 15 | Iteration number: [340/4518] 7% | Training loss: 0.6889815430430805
Epoch: 15 | Iteration number: [350/4518] 7% | Training loss: 0.6889327640192849
Epoch: 15 | Iteration number: [360/4518] 7% | Training loss: 0.6888605823119481
Epoch: 15 | Iteration number: [370/4518] 8% | Training loss: 0.6888221093126246
Epoch: 15 | Iteration number: [380/4518] 8% | Training loss: 0.6887735346430226
Epoch: 15 | Iteration number: [390/4518] 8% | Training loss: 0.6887489855289459
Epoch: 15 | Iteration number: [400/4518] 8% | Training loss: 0.6887068663537502
Epoch: 15 | Iteration number: [410/4518] 9% | Training loss: 0.6886524706352047
Epoch: 15 | Iteration number: [420/4518] 9% | Training loss: 0.688622582526434
Epoch: 15 | Iteration number: [430/4518] 9% | Training loss: 0.6885960907437081
Epoch: 15 | Iteration number: [440/4518] 9% | Training loss: 0.6885322205045007
Epoch: 15 | Iteration number: [450/4518] 9% | Training loss: 0.6884872870975071
Epoch: 15 | Iteration number: [460/4518] 10% | Training loss: 0.6884485861529475
Epoch: 15 | Iteration number: [470/4518] 10% | Training loss: 0.6883972501501124
Epoch: 15 | Iteration number: [480/4518] 10% | Training loss: 0.6883400453875462
Epoch: 15 | Iteration number: [490/4518] 10% | Training loss: 0.6883056012951598
Epoch: 15 | Iteration number: [500/4518] 11% | Training loss: 0.6882908483743667
Epoch: 15 | Iteration number: [510/4518] 11% | Training loss: 0.6882531568115833
Epoch: 15 | Iteration number: [520/4518] 11% | Training loss: 0.6882207326017893
Epoch: 15 | Iteration number: [530/4518] 11% | Training loss: 0.6881675004959107
Epoch: 15 | Iteration number: [540/4518] 11% | Training loss: 0.6881377945343653
Epoch: 15 | Iteration number: [550/4518] 12% | Training loss: 0.6881197602098639
Epoch: 15 | Iteration number: [560/4518] 12% | Training loss: 0.6880957202187606
Epoch: 15 | Iteration number: [570/4518] 12% | Training loss: 0.6880850377835726
Epoch: 15 | Iteration number: [580/4518] 12% | Training loss: 0.6880502068790896
Epoch: 15 | Iteration number: [590/4518] 13% | Training loss: 0.688013316110029
Epoch: 15 | Iteration number: [600/4518] 13% | Training loss: 0.688004352748394
Epoch: 15 | Iteration number: [610/4518] 13% | Training loss: 0.6879533579115008
Epoch: 15 | Iteration number: [620/4518] 13% | Training loss: 0.6879117931089094
Epoch: 15 | Iteration number: [630/4518] 13% | Training loss: 0.6878808850333804
Epoch: 15 | Iteration number: [640/4518] 14% | Training loss: 0.687863445840776
Epoch: 15 | Iteration number: [650/4518] 14% | Training loss: 0.6878388717541328
Epoch: 15 | Iteration number: [660/4518] 14% | Training loss: 0.6878220107519265
Epoch: 15 | Iteration number: [670/4518] 14% | Training loss: 0.6878030544786311
Epoch: 15 | Iteration number: [680/4518] 15% | Training loss: 0.6877906161196091
Epoch: 15 | Iteration number: [690/4518] 15% | Training loss: 0.6877979493659475
Epoch: 15 | Iteration number: [700/4518] 15% | Training loss: 0.6877802283423288
Epoch: 15 | Iteration number: [710/4518] 15% | Training loss: 0.6877774653300434
Epoch: 15 | Iteration number: [720/4518] 15% | Training loss: 0.6877641255656878
Epoch: 15 | Iteration number: [730/4518] 16% | Training loss: 0.6877482914761321
Epoch: 15 | Iteration number: [740/4518] 16% | Training loss: 0.6877419048869932
Epoch: 15 | Iteration number: [750/4518] 16% | Training loss: 0.6877341334819793
Epoch: 15 | Iteration number: [760/4518] 16% | Training loss: 0.6877302261559587
Epoch: 15 | Iteration number: [770/4518] 17% | Training loss: 0.6877196189645048
Epoch: 15 | Iteration number: [780/4518] 17% | Training loss: 0.6876906459148113
Epoch: 15 | Iteration number: [790/4518] 17% | Training loss: 0.6876684591739992
Epoch: 15 | Iteration number: [800/4518] 17% | Training loss: 0.6876534394919872
Epoch: 15 | Iteration number: [810/4518] 17% | Training loss: 0.6876415017210407
Epoch: 15 | Iteration number: [820/4518] 18% | Training loss: 0.6876350316332608
Epoch: 15 | Iteration number: [830/4518] 18% | Training loss: 0.6876377107867275
Epoch: 15 | Iteration number: [840/4518] 18% | Training loss: 0.6876287292156901
Epoch: 15 | Iteration number: [850/4518] 18% | Training loss: 0.6876360358210171
Epoch: 15 | Iteration number: [860/4518] 19% | Training loss: 0.6876287707062655
Epoch: 15 | Iteration number: [870/4518] 19% | Training loss: 0.6876327805820552
Epoch: 15 | Iteration number: [880/4518] 19% | Training loss: 0.6876355450261723
Epoch: 15 | Iteration number: [890/4518] 19% | Training loss: 0.6876233911916111
Epoch: 15 | Iteration number: [900/4518] 19% | Training loss: 0.6876220382584466
Epoch: 15 | Iteration number: [910/4518] 20% | Training loss: 0.6876045699957963
Epoch: 15 | Iteration number: [920/4518] 20% | Training loss: 0.6876006247556727
Epoch: 15 | Iteration number: [930/4518] 20% | Training loss: 0.6875761140418309
Epoch: 15 | Iteration number: [940/4518] 20% | Training loss: 0.6875705287811604
Epoch: 15 | Iteration number: [950/4518] 21% | Training loss: 0.6875658966365613
Epoch: 15 | Iteration number: [960/4518] 21% | Training loss: 0.6875690215577682
Epoch: 15 | Iteration number: [970/4518] 21% | Training loss: 0.6875625414946644
Epoch: 15 | Iteration number: [980/4518] 21% | Training loss: 0.6875587982790811
Epoch: 15 | Iteration number: [990/4518] 21% | Training loss: 0.687560812812863
Epoch: 15 | Iteration number: [1000/4518] 22% | Training loss: 0.687542258143425
Epoch: 15 | Iteration number: [1010/4518] 22% | Training loss: 0.6875475590771968
Epoch: 15 | Iteration number: [1020/4518] 22% | Training loss: 0.6875351413792254
Epoch: 15 | Iteration number: [1030/4518] 22% | Training loss: 0.6875291407686993
Epoch: 15 | Iteration number: [1040/4518] 23% | Training loss: 0.6875351743629345
Epoch: 15 | Iteration number: [1050/4518] 23% | Training loss: 0.6875285998980204
Epoch: 15 | Iteration number: [1060/4518] 23% | Training loss: 0.6875169777645255
Epoch: 15 | Iteration number: [1070/4518] 23% | Training loss: 0.6875049151549829
Epoch: 15 | Iteration number: [1080/4518] 23% | Training loss: 0.6875064526995023
Epoch: 15 | Iteration number: [1090/4518] 24% | Training loss: 0.6875063568080237
Epoch: 15 | Iteration number: [1100/4518] 24% | Training loss: 0.6875072499838742
Epoch: 15 | Iteration number: [1110/4518] 24% | Training loss: 0.6875112005182215
Epoch: 15 | Iteration number: [1120/4518] 24% | Training loss: 0.687517659259694
Epoch: 15 | Iteration number: [1130/4518] 25% | Training loss: 0.6875287900456285
Epoch: 15 | Iteration number: [1140/4518] 25% | Training loss: 0.687525548119294
Epoch: 15 | Iteration number: [1150/4518] 25% | Training loss: 0.6875254242316536
Epoch: 15 | Iteration number: [1160/4518] 25% | Training loss: 0.6875216436797175
Epoch: 15 | Iteration number: [1170/4518] 25% | Training loss: 0.687515925647866
Epoch: 15 | Iteration number: [1180/4518] 26% | Training loss: 0.687512470150398
Epoch: 15 | Iteration number: [1190/4518] 26% | Training loss: 0.6875161103340758
Epoch: 15 | Iteration number: [1200/4518] 26% | Training loss: 0.6875067526598772
Epoch: 15 | Iteration number: [1210/4518] 26% | Training loss: 0.6875081387925739
Epoch: 15 | Iteration number: [1220/4518] 27% | Training loss: 0.6874994415728772
Epoch: 15 | Iteration number: [1230/4518] 27% | Training loss: 0.687488464126742
Epoch: 15 | Iteration number: [1240/4518] 27% | Training loss: 0.6874770150069267
Epoch: 15 | Iteration number: [1250/4518] 27% | Training loss: 0.6874665330886841
Epoch: 15 | Iteration number: [1260/4518] 27% | Training loss: 0.6874612937843989
Epoch: 15 | Iteration number: [1270/4518] 28% | Training loss: 0.6874586950136921
Epoch: 15 | Iteration number: [1280/4518] 28% | Training loss: 0.687459320994094
Epoch: 15 | Iteration number: [1290/4518] 28% | Training loss: 0.6874598394068636
Epoch: 15 | Iteration number: [1300/4518] 28% | Training loss: 0.6874575645190019
Epoch: 15 | Iteration number: [1310/4518] 28% | Training loss: 0.6874591541654281
Epoch: 15 | Iteration number: [1320/4518] 29% | Training loss: 0.6874574934894389
Epoch: 15 | Iteration number: [1330/4518] 29% | Training loss: 0.6874451737654836
Epoch: 15 | Iteration number: [1340/4518] 29% | Training loss: 0.6874497406963093
Epoch: 15 | Iteration number: [1350/4518] 29% | Training loss: 0.6874503576314008
Epoch: 15 | Iteration number: [1360/4518] 30% | Training loss: 0.6874484664815314
Epoch: 15 | Iteration number: [1370/4518] 30% | Training loss: 0.6874418184269954
Epoch: 15 | Iteration number: [1380/4518] 30% | Training loss: 0.6874353001946988
Epoch: 15 | Iteration number: [1390/4518] 30% | Training loss: 0.6874265632183432
Epoch: 15 | Iteration number: [1400/4518] 30% | Training loss: 0.6874246415070125
Epoch: 15 | Iteration number: [1410/4518] 31% | Training loss: 0.6874257072066584
Epoch: 15 | Iteration number: [1420/4518] 31% | Training loss: 0.6874187639061834
Epoch: 15 | Iteration number: [1430/4518] 31% | Training loss: 0.6874238796584256
Epoch: 15 | Iteration number: [1440/4518] 31% | Training loss: 0.6874260170178281
Epoch: 15 | Iteration number: [1450/4518] 32% | Training loss: 0.6874329073675748
Epoch: 15 | Iteration number: [1460/4518] 32% | Training loss: 0.687424854097301
Epoch: 15 | Iteration number: [1470/4518] 32% | Training loss: 0.6874271718417706
Epoch: 15 | Iteration number: [1480/4518] 32% | Training loss: 0.6874219012018796
Epoch: 15 | Iteration number: [1490/4518] 32% | Training loss: 0.6874258353806182
Epoch: 15 | Iteration number: [1500/4518] 33% | Training loss: 0.6874315018256505
Epoch: 15 | Iteration number: [1510/4518] 33% | Training loss: 0.6874267743518021
Epoch: 15 | Iteration number: [1520/4518] 33% | Training loss: 0.6874224783950731
Epoch: 15 | Iteration number: [1530/4518] 33% | Training loss: 0.6874267823945464
Epoch: 15 | Iteration number: [1540/4518] 34% | Training loss: 0.6874201233123804
Epoch: 15 | Iteration number: [1550/4518] 34% | Training loss: 0.6874121374084103
Epoch: 15 | Iteration number: [1560/4518] 34% | Training loss: 0.6874109774445876
Epoch: 15 | Iteration number: [1570/4518] 34% | Training loss: 0.6874033592309162
Epoch: 15 | Iteration number: [1580/4518] 34% | Training loss: 0.6874068104013612
Epoch: 15 | Iteration number: [1590/4518] 35% | Training loss: 0.6874003017848392
Epoch: 15 | Iteration number: [1600/4518] 35% | Training loss: 0.687400345094502
Epoch: 15 | Iteration number: [1610/4518] 35% | Training loss: 0.6873979298964791
Epoch: 15 | Iteration number: [1620/4518] 35% | Training loss: 0.6873886546970885
Epoch: 15 | Iteration number: [1630/4518] 36% | Training loss: 0.6873847162796676
Epoch: 15 | Iteration number: [1640/4518] 36% | Training loss: 0.6873826092336236
Epoch: 15 | Iteration number: [1650/4518] 36% | Training loss: 0.6873780424305886
Epoch: 15 | Iteration number: [1660/4518] 36% | Training loss: 0.6873808266168617
Epoch: 15 | Iteration number: [1670/4518] 36% | Training loss: 0.6873793237223597
Epoch: 15 | Iteration number: [1680/4518] 37% | Training loss: 0.6873762561806611
Epoch: 15 | Iteration number: [1690/4518] 37% | Training loss: 0.6873705439313629
Epoch: 15 | Iteration number: [1700/4518] 37% | Training loss: 0.6873694871103062
Epoch: 15 | Iteration number: [1710/4518] 37% | Training loss: 0.6873678264213584
Epoch: 15 | Iteration number: [1720/4518] 38% | Training loss: 0.6873657194334407
Epoch: 15 | Iteration number: [1730/4518] 38% | Training loss: 0.687365045127152
Epoch: 15 | Iteration number: [1740/4518] 38% | Training loss: 0.687364323351575
Epoch: 15 | Iteration number: [1750/4518] 38% | Training loss: 0.6873585117885045
Epoch: 15 | Iteration number: [1760/4518] 38% | Training loss: 0.6873623644086447
Epoch: 15 | Iteration number: [1770/4518] 39% | Training loss: 0.687353264679343
Epoch: 15 | Iteration number: [1780/4518] 39% | Training loss: 0.6873490519403072
Epoch: 15 | Iteration number: [1790/4518] 39% | Training loss: 0.6873454118574132
Epoch: 15 | Iteration number: [1800/4518] 39% | Training loss: 0.6873400865329636
Epoch: 15 | Iteration number: [1810/4518] 40% | Training loss: 0.6873378040382216
Epoch: 15 | Iteration number: [1820/4518] 40% | Training loss: 0.6873335933292305
Epoch: 15 | Iteration number: [1830/4518] 40% | Training loss: 0.6873256203581075
Epoch: 15 | Iteration number: [1840/4518] 40% | Training loss: 0.6873203953647096
Epoch: 15 | Iteration number: [1850/4518] 40% | Training loss: 0.6873259591734087
Epoch: 15 | Iteration number: [1860/4518] 41% | Training loss: 0.687323744130391
Epoch: 15 | Iteration number: [1870/4518] 41% | Training loss: 0.6873185196024849
Epoch: 15 | Iteration number: [1880/4518] 41% | Training loss: 0.6873222531473383
Epoch: 15 | Iteration number: [1890/4518] 41% | Training loss: 0.6873202233402818
Epoch: 15 | Iteration number: [1900/4518] 42% | Training loss: 0.6873181995592619
Epoch: 15 | Iteration number: [1910/4518] 42% | Training loss: 0.6873125870190365
Epoch: 15 | Iteration number: [1920/4518] 42% | Training loss: 0.6873102836931745
Epoch: 15 | Iteration number: [1930/4518] 42% | Training loss: 0.6873107754504743
Epoch: 15 | Iteration number: [1940/4518] 42% | Training loss: 0.6873051004311473
Epoch: 15 | Iteration number: [1950/4518] 43% | Training loss: 0.6873018595805535
Epoch: 15 | Iteration number: [1960/4518] 43% | Training loss: 0.6872959229410911
Epoch: 15 | Iteration number: [1970/4518] 43% | Training loss: 0.6872999744669435
Epoch: 15 | Iteration number: [1980/4518] 43% | Training loss: 0.6873002358759293
Epoch: 15 | Iteration number: [1990/4518] 44% | Training loss: 0.6873045059304741
Epoch: 15 | Iteration number: [2000/4518] 44% | Training loss: 0.6872973295152187
Epoch: 15 | Iteration number: [2010/4518] 44% | Training loss: 0.6872976085736384
Epoch: 15 | Iteration number: [2020/4518] 44% | Training loss: 0.6872942482775981
Epoch: 15 | Iteration number: [2030/4518] 44% | Training loss: 0.687291233968265
Epoch: 15 | Iteration number: [2040/4518] 45% | Training loss: 0.6872863889909258
Epoch: 15 | Iteration number: [2050/4518] 45% | Training loss: 0.6872853570449643
Epoch: 15 | Iteration number: [2060/4518] 45% | Training loss: 0.6872804248795926
Epoch: 15 | Iteration number: [2070/4518] 45% | Training loss: 0.6872752192803627
Epoch: 15 | Iteration number: [2080/4518] 46% | Training loss: 0.6872718741114323
Epoch: 15 | Iteration number: [2090/4518] 46% | Training loss: 0.6872662435878407
Epoch: 15 | Iteration number: [2100/4518] 46% | Training loss: 0.6872659018777666
Epoch: 15 | Iteration number: [2110/4518] 46% | Training loss: 0.6872651243944303
Epoch: 15 | Iteration number: [2120/4518] 46% | Training loss: 0.6872642266019335
Epoch: 15 | Iteration number: [2130/4518] 47% | Training loss: 0.6872647936635174
Epoch: 15 | Iteration number: [2140/4518] 47% | Training loss: 0.6872603634250498
Epoch: 15 | Iteration number: [2150/4518] 47% | Training loss: 0.6872571236033772
Epoch: 15 | Iteration number: [2160/4518] 47% | Training loss: 0.687255915309544
Epoch: 15 | Iteration number: [2170/4518] 48% | Training loss: 0.687251960819218
Epoch: 15 | Iteration number: [2180/4518] 48% | Training loss: 0.6872564259472244
Epoch: 15 | Iteration number: [2190/4518] 48% | Training loss: 0.687256952017954
Epoch: 15 | Iteration number: [2200/4518] 48% | Training loss: 0.6872534617781639
Epoch: 15 | Iteration number: [2210/4518] 48% | Training loss: 0.6872539053135868
Epoch: 15 | Iteration number: [2220/4518] 49% | Training loss: 0.6872473403408721
Epoch: 15 | Iteration number: [2230/4518] 49% | Training loss: 0.6872459105044737
Epoch: 15 | Iteration number: [2240/4518] 49% | Training loss: 0.6872475348945175
Epoch: 15 | Iteration number: [2250/4518] 49% | Training loss: 0.6872430851989322
Epoch: 15 | Iteration number: [2260/4518] 50% | Training loss: 0.687243789434433
Epoch: 15 | Iteration number: [2270/4518] 50% | Training loss: 0.6872392248477179
Epoch: 15 | Iteration number: [2280/4518] 50% | Training loss: 0.6872413120510286
Epoch: 15 | Iteration number: [2290/4518] 50% | Training loss: 0.6872408116748759
Epoch: 15 | Iteration number: [2300/4518] 50% | Training loss: 0.687241651882296
Epoch: 15 | Iteration number: [2310/4518] 51% | Training loss: 0.6872418512513627
Epoch: 15 | Iteration number: [2320/4518] 51% | Training loss: 0.6872379673966046
Epoch: 15 | Iteration number: [2330/4518] 51% | Training loss: 0.6872348761353881
Epoch: 15 | Iteration number: [2340/4518] 51% | Training loss: 0.6872325377841281
Epoch: 15 | Iteration number: [2350/4518] 52% | Training loss: 0.6872307949116889
Epoch: 15 | Iteration number: [2360/4518] 52% | Training loss: 0.6872288319266449
Epoch: 15 | Iteration number: [2370/4518] 52% | Training loss: 0.6872262551060205
Epoch: 15 | Iteration number: [2380/4518] 52% | Training loss: 0.6872255972453526
Epoch: 15 | Iteration number: [2390/4518] 52% | Training loss: 0.6872253623966392
Epoch: 15 | Iteration number: [2400/4518] 53% | Training loss: 0.6872261542826891
Epoch: 15 | Iteration number: [2410/4518] 53% | Training loss: 0.6872229572895652
Epoch: 15 | Iteration number: [2420/4518] 53% | Training loss: 0.6872188371813986
Epoch: 15 | Iteration number: [2430/4518] 53% | Training loss: 0.6872153092313695
Epoch: 15 | Iteration number: [2440/4518] 54% | Training loss: 0.6872178143409432
Epoch: 15 | Iteration number: [2450/4518] 54% | Training loss: 0.6872133967097924
Epoch: 15 | Iteration number: [2460/4518] 54% | Training loss: 0.6872080012307904
Epoch: 15 | Iteration number: [2470/4518] 54% | Training loss: 0.6872094713241947
Epoch: 15 | Iteration number: [2480/4518] 54% | Training loss: 0.6872151496429597
Epoch: 15 | Iteration number: [2490/4518] 55% | Training loss: 0.687218392517672
Epoch: 15 | Iteration number: [2500/4518] 55% | Training loss: 0.6872196876287461
Epoch: 15 | Iteration number: [2510/4518] 55% | Training loss: 0.6872139412330917
Epoch: 15 | Iteration number: [2520/4518] 55% | Training loss: 0.6872098240823973
Epoch: 15 | Iteration number: [2530/4518] 55% | Training loss: 0.6872092810779692
Epoch: 15 | Iteration number: [2540/4518] 56% | Training loss: 0.6872100552236001
Epoch: 15 | Iteration number: [2550/4518] 56% | Training loss: 0.6872071648345274
Epoch: 15 | Iteration number: [2560/4518] 56% | Training loss: 0.6872043862240389
Epoch: 15 | Iteration number: [2570/4518] 56% | Training loss: 0.6872059539366325
Epoch: 15 | Iteration number: [2580/4518] 57% | Training loss: 0.6871991809024367
Epoch: 15 | Iteration number: [2590/4518] 57% | Training loss: 0.6871986223233713
Epoch: 15 | Iteration number: [2600/4518] 57% | Training loss: 0.687194045484066
Epoch: 15 | Iteration number: [2610/4518] 57% | Training loss: 0.6871952133160442
Epoch: 15 | Iteration number: [2620/4518] 57% | Training loss: 0.6871972917372944
Epoch: 15 | Iteration number: [2630/4518] 58% | Training loss: 0.6871972790235802
Epoch: 15 | Iteration number: [2640/4518] 58% | Training loss: 0.6871973353353413
Epoch: 15 | Iteration number: [2650/4518] 58% | Training loss: 0.6871926503361396
Epoch: 15 | Iteration number: [2660/4518] 58% | Training loss: 0.6871931124898724
Epoch: 15 | Iteration number: [2670/4518] 59% | Training loss: 0.6871917697820771
Epoch: 15 | Iteration number: [2680/4518] 59% | Training loss: 0.6871888807015633
Epoch: 15 | Iteration number: [2690/4518] 59% | Training loss: 0.6871880198278392
Epoch: 15 | Iteration number: [2700/4518] 59% | Training loss: 0.6871801922939442
Epoch: 15 | Iteration number: [2710/4518] 59% | Training loss: 0.6871809926200177
Epoch: 15 | Iteration number: [2720/4518] 60% | Training loss: 0.687181455225629
Epoch: 15 | Iteration number: [2730/4518] 60% | Training loss: 0.6871772529223026
Epoch: 15 | Iteration number: [2740/4518] 60% | Training loss: 0.6871786093407304
Epoch: 15 | Iteration number: [2750/4518] 60% | Training loss: 0.6871838787902486
Epoch: 15 | Iteration number: [2760/4518] 61% | Training loss: 0.6871852905637976
Epoch: 15 | Iteration number: [2770/4518] 61% | Training loss: 0.6871866040926978
Epoch: 15 | Iteration number: [2780/4518] 61% | Training loss: 0.6871885982348764
Epoch: 15 | Iteration number: [2790/4518] 61% | Training loss: 0.6871879014703962
Epoch: 15 | Iteration number: [2800/4518] 61% | Training loss: 0.6871864261371748
Epoch: 15 | Iteration number: [2810/4518] 62% | Training loss: 0.6871831961373842
Epoch: 15 | Iteration number: [2820/4518] 62% | Training loss: 0.6871839861497812
Epoch: 15 | Iteration number: [2830/4518] 62% | Training loss: 0.6871864521461325
Epoch: 15 | Iteration number: [2840/4518] 62% | Training loss: 0.6871824239551182
Epoch: 15 | Iteration number: [2850/4518] 63% | Training loss: 0.6871792172130785
Epoch: 15 | Iteration number: [2860/4518] 63% | Training loss: 0.6871784877318602
Epoch: 15 | Iteration number: [2870/4518] 63% | Training loss: 0.6871761246840713
Epoch: 15 | Iteration number: [2880/4518] 63% | Training loss: 0.6871772634486357
Epoch: 15 | Iteration number: [2890/4518] 63% | Training loss: 0.687176231694469
Epoch: 15 | Iteration number: [2900/4518] 64% | Training loss: 0.6871739201093542
Epoch: 15 | Iteration number: [2910/4518] 64% | Training loss: 0.6871727154631795
Epoch: 15 | Iteration number: [2920/4518] 64% | Training loss: 0.6871786717274417
Epoch: 15 | Iteration number: [2930/4518] 64% | Training loss: 0.6871789405573757
Epoch: 15 | Iteration number: [2940/4518] 65% | Training loss: 0.6871748611635091
Epoch: 15 | Iteration number: [2950/4518] 65% | Training loss: 0.6871745074805566
Epoch: 15 | Iteration number: [2960/4518] 65% | Training loss: 0.6871734717407743
Epoch: 15 | Iteration number: [2970/4518] 65% | Training loss: 0.6871725064536136
Epoch: 15 | Iteration number: [2980/4518] 65% | Training loss: 0.6871737028128349
Epoch: 15 | Iteration number: [2990/4518] 66% | Training loss: 0.6871744921773573
Epoch: 15 | Iteration number: [3000/4518] 66% | Training loss: 0.6871755099892616
Epoch: 15 | Iteration number: [3010/4518] 66% | Training loss: 0.6871747750776551
Epoch: 15 | Iteration number: [3020/4518] 66% | Training loss: 0.687177706988442
Epoch: 15 | Iteration number: [3030/4518] 67% | Training loss: 0.6871783452262186
Epoch: 15 | Iteration number: [3040/4518] 67% | Training loss: 0.6871812862589171
Epoch: 15 | Iteration number: [3050/4518] 67% | Training loss: 0.6871763484986102
Epoch: 15 | Iteration number: [3060/4518] 67% | Training loss: 0.6871731704356624
Epoch: 15 | Iteration number: [3070/4518] 67% | Training loss: 0.687167502459175
Epoch: 15 | Iteration number: [3080/4518] 68% | Training loss: 0.6871639994251264
Epoch: 15 | Iteration number: [3090/4518] 68% | Training loss: 0.687165425317573
Epoch: 15 | Iteration number: [3100/4518] 68% | Training loss: 0.6871644563636472
Epoch: 15 | Iteration number: [3110/4518] 68% | Training loss: 0.6871604990154218
Epoch: 15 | Iteration number: [3120/4518] 69% | Training loss: 0.6871624831969921
Epoch: 15 | Iteration number: [3130/4518] 69% | Training loss: 0.6871659452541948
Epoch: 15 | Iteration number: [3140/4518] 69% | Training loss: 0.6871639995628102
Epoch: 15 | Iteration number: [3150/4518] 69% | Training loss: 0.6871625107053726
Epoch: 15 | Iteration number: [3160/4518] 69% | Training loss: 0.6871609841720967
Epoch: 15 | Iteration number: [3170/4518] 70% | Training loss: 0.6871576382722764
Epoch: 15 | Iteration number: [3180/4518] 70% | Training loss: 0.6871571033443294
Epoch: 15 | Iteration number: [3190/4518] 70% | Training loss: 0.687153489967125
Epoch: 15 | Iteration number: [3200/4518] 70% | Training loss: 0.6871487848088145
Epoch: 15 | Iteration number: [3210/4518] 71% | Training loss: 0.6871453150410518
Epoch: 15 | Iteration number: [3220/4518] 71% | Training loss: 0.6871453070862693
Epoch: 15 | Iteration number: [3230/4518] 71% | Training loss: 0.6871431946754456
Epoch: 15 | Iteration number: [3240/4518] 71% | Training loss: 0.6871383003614567
Epoch: 15 | Iteration number: [3250/4518] 71% | Training loss: 0.687135855619724
Epoch: 15 | Iteration number: [3260/4518] 72% | Training loss: 0.6871293090786671
Epoch: 15 | Iteration number: [3270/4518] 72% | Training loss: 0.6871319889293169
Epoch: 15 | Iteration number: [3280/4518] 72% | Training loss: 0.687132103377726
Epoch: 15 | Iteration number: [3290/4518] 72% | Training loss: 0.687130545156705
Epoch: 15 | Iteration number: [3300/4518] 73% | Training loss: 0.6871297068306894
Epoch: 15 | Iteration number: [3310/4518] 73% | Training loss: 0.6871305242405917
Epoch: 15 | Iteration number: [3320/4518] 73% | Training loss: 0.6871295991432236
Epoch: 15 | Iteration number: [3330/4518] 73% | Training loss: 0.6871295693400385
Epoch: 15 | Iteration number: [3340/4518] 73% | Training loss: 0.687130902698654
Epoch: 15 | Iteration number: [3350/4518] 74% | Training loss: 0.68712910171765
Epoch: 15 | Iteration number: [3360/4518] 74% | Training loss: 0.6871252448608478
Epoch: 15 | Iteration number: [3370/4518] 74% | Training loss: 0.687123499956612
Epoch: 15 | Iteration number: [3380/4518] 74% | Training loss: 0.6871236429059294
Epoch: 15 | Iteration number: [3390/4518] 75% | Training loss: 0.6871251037866317
Epoch: 15 | Iteration number: [3400/4518] 75% | Training loss: 0.6871219428497203
Epoch: 15 | Iteration number: [3410/4518] 75% | Training loss: 0.6871196278204317
Epoch: 15 | Iteration number: [3420/4518] 75% | Training loss: 0.6871185223261516
Epoch: 15 | Iteration number: [3430/4518] 75% | Training loss: 0.6871148903237835
Epoch: 15 | Iteration number: [3440/4518] 76% | Training loss: 0.6871110541702703
Epoch: 15 | Iteration number: [3450/4518] 76% | Training loss: 0.6871107505542644
Epoch: 15 | Iteration number: [3460/4518] 76% | Training loss: 0.687111819393373
Epoch: 15 | Iteration number: [3470/4518] 76% | Training loss: 0.6871112660990668
Epoch: 15 | Iteration number: [3480/4518] 77% | Training loss: 0.6871099122296804
Epoch: 15 | Iteration number: [3490/4518] 77% | Training loss: 0.6871104923052911
Epoch: 15 | Iteration number: [3500/4518] 77% | Training loss: 0.6871055086169924
Epoch: 15 | Iteration number: [3510/4518] 77% | Training loss: 0.6871029350492689
Epoch: 15 | Iteration number: [3520/4518] 77% | Training loss: 0.6871027450500564
Epoch: 15 | Iteration number: [3530/4518] 78% | Training loss: 0.6871060629066597
Epoch: 15 | Iteration number: [3540/4518] 78% | Training loss: 0.6871068820104761
Epoch: 15 | Iteration number: [3550/4518] 78% | Training loss: 0.6871052334678005
Epoch: 15 | Iteration number: [3560/4518] 78% | Training loss: 0.6871068178100532
Epoch: 15 | Iteration number: [3570/4518] 79% | Training loss: 0.6871036324848314
Epoch: 15 | Iteration number: [3580/4518] 79% | Training loss: 0.6871066728617226
Epoch: 15 | Iteration number: [3590/4518] 79% | Training loss: 0.6871083056860315
Epoch: 15 | Iteration number: [3600/4518] 79% | Training loss: 0.6871090230180158
Epoch: 15 | Iteration number: [3610/4518] 79% | Training loss: 0.6871097630576084
Epoch: 15 | Iteration number: [3620/4518] 80% | Training loss: 0.6871099432858314
Epoch: 15 | Iteration number: [3630/4518] 80% | Training loss: 0.6871074193601109
Epoch: 15 | Iteration number: [3640/4518] 80% | Training loss: 0.6871057141285676
Epoch: 15 | Iteration number: [3650/4518] 80% | Training loss: 0.6871035796648836
Epoch: 15 | Iteration number: [3660/4518] 81% | Training loss: 0.6871071081669604
Epoch: 15 | Iteration number: [3670/4518] 81% | Training loss: 0.6871012715942528
Epoch: 15 | Iteration number: [3680/4518] 81% | Training loss: 0.6871005103963873
Epoch: 15 | Iteration number: [3690/4518] 81% | Training loss: 0.6871057049045718
Epoch: 15 | Iteration number: [3700/4518] 81% | Training loss: 0.6871096716861467
Epoch: 15 | Iteration number: [3710/4518] 82% | Training loss: 0.6871115524171176
Epoch: 15 | Iteration number: [3720/4518] 82% | Training loss: 0.6871117394617808
Epoch: 15 | Iteration number: [3730/4518] 82% | Training loss: 0.6871110613799926
Epoch: 15 | Iteration number: [3740/4518] 82% | Training loss: 0.6871086793627968
Epoch: 15 | Iteration number: [3750/4518] 83% | Training loss: 0.6871100424289703
Epoch: 15 | Iteration number: [3760/4518] 83% | Training loss: 0.6871131439475303
Epoch: 15 | Iteration number: [3770/4518] 83% | Training loss: 0.6871157609815622
Epoch: 15 | Iteration number: [3780/4518] 83% | Training loss: 0.6871173354368362
Epoch: 15 | Iteration number: [3790/4518] 83% | Training loss: 0.6871185121718686
Epoch: 15 | Iteration number: [3800/4518] 84% | Training loss: 0.6871185867253102
Epoch: 15 | Iteration number: [3810/4518] 84% | Training loss: 0.6871192122381816
Epoch: 15 | Iteration number: [3820/4518] 84% | Training loss: 0.6871163380707745
Epoch: 15 | Iteration number: [3830/4518] 84% | Training loss: 0.6871108535220044
Epoch: 15 | Iteration number: [3840/4518] 84% | Training loss: 0.6871133431792259
Epoch: 15 | Iteration number: [3850/4518] 85% | Training loss: 0.687114959475282
Epoch: 15 | Iteration number: [3860/4518] 85% | Training loss: 0.68711349545674
Epoch: 15 | Iteration number: [3870/4518] 85% | Training loss: 0.6871095249665183
Epoch: 15 | Iteration number: [3880/4518] 85% | Training loss: 0.6871086973351301
Epoch: 15 | Iteration number: [3890/4518] 86% | Training loss: 0.6871071748224813
Epoch: 15 | Iteration number: [3900/4518] 86% | Training loss: 0.6871057544763272
Epoch: 15 | Iteration number: [3910/4518] 86% | Training loss: 0.6871055167806728
Epoch: 15 | Iteration number: [3920/4518] 86% | Training loss: 0.6871021091177756
Epoch: 15 | Iteration number: [3930/4518] 86% | Training loss: 0.6871025692870598
Epoch: 15 | Iteration number: [3940/4518] 87% | Training loss: 0.6871030647742566
Epoch: 15 | Iteration number: [3950/4518] 87% | Training loss: 0.6871015418933917
Epoch: 15 | Iteration number: [3960/4518] 87% | Training loss: 0.6870999629449362
Epoch: 15 | Iteration number: [3970/4518] 87% | Training loss: 0.6870983405137242
Epoch: 15 | Iteration number: [3980/4518] 88% | Training loss: 0.6871003505872123
Epoch: 15 | Iteration number: [3990/4518] 88% | Training loss: 0.6871012062357184
Epoch: 15 | Iteration number: [4000/4518] 88% | Training loss: 0.6871025193333625
Epoch: 15 | Iteration number: [4010/4518] 88% | Training loss: 0.6871023469583649
Epoch: 15 | Iteration number: [4020/4518] 88% | Training loss: 0.6870989692300113
Epoch: 15 | Iteration number: [4030/4518] 89% | Training loss: 0.6870983083697761
Epoch: 15 | Iteration number: [4040/4518] 89% | Training loss: 0.6870945077868972
Epoch: 15 | Iteration number: [4050/4518] 89% | Training loss: 0.6870946150061525
Epoch: 15 | Iteration number: [4060/4518] 89% | Training loss: 0.6870911571045815
Epoch: 15 | Iteration number: [4070/4518] 90% | Training loss: 0.6870905895637353
Epoch: 15 | Iteration number: [4080/4518] 90% | Training loss: 0.6870917358965266
Epoch: 15 | Iteration number: [4090/4518] 90% | Training loss: 0.6870924330573793
Epoch: 15 | Iteration number: [4100/4518] 90% | Training loss: 0.6870915883343395
Epoch: 15 | Iteration number: [4110/4518] 90% | Training loss: 0.68709239089576
Epoch: 15 | Iteration number: [4120/4518] 91% | Training loss: 0.6870897179668389
Epoch: 15 | Iteration number: [4130/4518] 91% | Training loss: 0.6870901990889349
Epoch: 15 | Iteration number: [4140/4518] 91% | Training loss: 0.6870856835214412
Epoch: 15 | Iteration number: [4150/4518] 91% | Training loss: 0.6870834219742971
Epoch: 15 | Iteration number: [4160/4518] 92% | Training loss: 0.6870861530877077
Epoch: 15 | Iteration number: [4170/4518] 92% | Training loss: 0.6870835371154675
Epoch: 15 | Iteration number: [4180/4518] 92% | Training loss: 0.6870803779392152
Epoch: 15 | Iteration number: [4190/4518] 92% | Training loss: 0.6870828061940277
Epoch: 15 | Iteration number: [4200/4518] 92% | Training loss: 0.6870823400361198
Epoch: 15 | Iteration number: [4210/4518] 93% | Training loss: 0.6870808703599237
Epoch: 15 | Iteration number: [4220/4518] 93% | Training loss: 0.687079578299093
Epoch: 15 | Iteration number: [4230/4518] 93% | Training loss: 0.6870793071762608
Epoch: 15 | Iteration number: [4240/4518] 93% | Training loss: 0.6870792248339023
Epoch: 15 | Iteration number: [4250/4518] 94% | Training loss: 0.6870848181247711
Epoch: 15 | Iteration number: [4260/4518] 94% | Training loss: 0.6870859787077971
Epoch: 15 | Iteration number: [4270/4518] 94% | Training loss: 0.6870845068952797
Epoch: 15 | Iteration number: [4280/4518] 94% | Training loss: 0.6870846126959703
Epoch: 15 | Iteration number: [4290/4518] 94% | Training loss: 0.6870848513149715
Epoch: 15 | Iteration number: [4300/4518] 95% | Training loss: 0.687082224377366
Epoch: 15 | Iteration number: [4310/4518] 95% | Training loss: 0.6870825001645807
Epoch: 15 | Iteration number: [4320/4518] 95% | Training loss: 0.6870821740616251
Epoch: 15 | Iteration number: [4330/4518] 95% | Training loss: 0.6870828130641655
Epoch: 15 | Iteration number: [4340/4518] 96% | Training loss: 0.6870829783963718
Epoch: 15 | Iteration number: [4350/4518] 96% | Training loss: 0.687082289827281
Epoch: 15 | Iteration number: [4360/4518] 96% | Training loss: 0.6870843277885279
Epoch: 15 | Iteration number: [4370/4518] 96% | Training loss: 0.6870848566089124
Epoch: 15 | Iteration number: [4380/4518] 96% | Training loss: 0.6870833105012162
Epoch: 15 | Iteration number: [4390/4518] 97% | Training loss: 0.6870829032874053
Epoch: 15 | Iteration number: [4400/4518] 97% | Training loss: 0.6870835555141622
Epoch: 15 | Iteration number: [4410/4518] 97% | Training loss: 0.6870843279388756
Epoch: 15 | Iteration number: [4420/4518] 97% | Training loss: 0.6870868870710356
Epoch: 15 | Iteration number: [4430/4518] 98% | Training loss: 0.6870867438563913
Epoch: 15 | Iteration number: [4440/4518] 98% | Training loss: 0.6870854108585968
Epoch: 15 | Iteration number: [4450/4518] 98% | Training loss: 0.6870844025826186
Epoch: 15 | Iteration number: [4460/4518] 98% | Training loss: 0.6870862708898938
Epoch: 15 | Iteration number: [4470/4518] 98% | Training loss: 0.6870865581819675
Epoch: 15 | Iteration number: [4480/4518] 99% | Training loss: 0.6870865079308195
Epoch: 15 | Iteration number: [4490/4518] 99% | Training loss: 0.6870875858384411
Epoch: 15 | Iteration number: [4500/4518] 99% | Training loss: 0.6870876761807335
Epoch: 15 | Iteration number: [4510/4518] 99% | Training loss: 0.687089172461609

 End of epoch: 15 | Train Loss: 0.6869368790762252 | Training Time: 643 

 End of epoch: 15 | Eval Loss: 0.6903880007412969 | Evaluating Time: 17 
Epoch: 16 | Iteration number: [10/4518] 0% | Training loss: 0.7562990069389344
Epoch: 16 | Iteration number: [20/4518] 0% | Training loss: 0.7219146072864533
Epoch: 16 | Iteration number: [30/4518] 0% | Training loss: 0.7103217860062917
Epoch: 16 | Iteration number: [40/4518] 0% | Training loss: 0.7044785812497139
Epoch: 16 | Iteration number: [50/4518] 1% | Training loss: 0.7008409082889557
Epoch: 16 | Iteration number: [60/4518] 1% | Training loss: 0.6985399603843689
Epoch: 16 | Iteration number: [70/4518] 1% | Training loss: 0.6968795188835689
Epoch: 16 | Iteration number: [80/4518] 1% | Training loss: 0.695747722685337
Epoch: 16 | Iteration number: [90/4518] 1% | Training loss: 0.6948543051878612
Epoch: 16 | Iteration number: [100/4518] 2% | Training loss: 0.6939986598491669
Epoch: 16 | Iteration number: [110/4518] 2% | Training loss: 0.6932598520408977
Epoch: 16 | Iteration number: [120/4518] 2% | Training loss: 0.6927691062291463
Epoch: 16 | Iteration number: [130/4518] 2% | Training loss: 0.6922850572145902
Epoch: 16 | Iteration number: [140/4518] 3% | Training loss: 0.6917976200580597
Epoch: 16 | Iteration number: [150/4518] 3% | Training loss: 0.6915533296267191
Epoch: 16 | Iteration number: [160/4518] 3% | Training loss: 0.6912678744643926
Epoch: 16 | Iteration number: [170/4518] 3% | Training loss: 0.6910472291357377
Epoch: 16 | Iteration number: [180/4518] 3% | Training loss: 0.6907542520099216
Epoch: 16 | Iteration number: [190/4518] 4% | Training loss: 0.6905694374912663
Epoch: 16 | Iteration number: [200/4518] 4% | Training loss: 0.6903377637267113
Epoch: 16 | Iteration number: [210/4518] 4% | Training loss: 0.6901536436307998
Epoch: 16 | Iteration number: [220/4518] 4% | Training loss: 0.6899635897441344
Epoch: 16 | Iteration number: [230/4518] 5% | Training loss: 0.6898370592490487
Epoch: 16 | Iteration number: [240/4518] 5% | Training loss: 0.6897121417025726
Epoch: 16 | Iteration number: [250/4518] 5% | Training loss: 0.6896281168460846
Epoch: 16 | Iteration number: [260/4518] 5% | Training loss: 0.6894912100755252
Epoch: 16 | Iteration number: [270/4518] 5% | Training loss: 0.6894100540214114
Epoch: 16 | Iteration number: [280/4518] 6% | Training loss: 0.6893067074673517
Epoch: 16 | Iteration number: [290/4518] 6% | Training loss: 0.6892870142542082
Epoch: 16 | Iteration number: [300/4518] 6% | Training loss: 0.6892038023471833
Epoch: 16 | Iteration number: [310/4518] 6% | Training loss: 0.6891738582041955
Epoch: 16 | Iteration number: [320/4518] 7% | Training loss: 0.6891331501305104
Epoch: 16 | Iteration number: [330/4518] 7% | Training loss: 0.6890939457850023
Epoch: 16 | Iteration number: [340/4518] 7% | Training loss: 0.6890420228242874
Epoch: 16 | Iteration number: [350/4518] 7% | Training loss: 0.6889886782850538
Epoch: 16 | Iteration number: [360/4518] 7% | Training loss: 0.6889194606078995
Epoch: 16 | Iteration number: [370/4518] 8% | Training loss: 0.688875685350315
Epoch: 16 | Iteration number: [380/4518] 8% | Training loss: 0.6888464399074253
Epoch: 16 | Iteration number: [390/4518] 8% | Training loss: 0.688792095428858
Epoch: 16 | Iteration number: [400/4518] 8% | Training loss: 0.6887406627833843
Epoch: 16 | Iteration number: [410/4518] 9% | Training loss: 0.6886906971291797
Epoch: 16 | Iteration number: [420/4518] 9% | Training loss: 0.6886754769654501
Epoch: 16 | Iteration number: [430/4518] 9% | Training loss: 0.688644226623136
Epoch: 16 | Iteration number: [440/4518] 9% | Training loss: 0.6886250638149002
Epoch: 16 | Iteration number: [450/4518] 9% | Training loss: 0.6885856015152402
Epoch: 16 | Iteration number: [460/4518] 10% | Training loss: 0.6885473454776018
Epoch: 16 | Iteration number: [470/4518] 10% | Training loss: 0.6885365484876835
Epoch: 16 | Iteration number: [480/4518] 10% | Training loss: 0.6885106050719817
Epoch: 16 | Iteration number: [490/4518] 10% | Training loss: 0.6884774152113466
Epoch: 16 | Iteration number: [500/4518] 11% | Training loss: 0.6884559359550476
Epoch: 16 | Iteration number: [510/4518] 11% | Training loss: 0.6884118877205194
Epoch: 16 | Iteration number: [520/4518] 11% | Training loss: 0.6883700024623137
Epoch: 16 | Iteration number: [530/4518] 11% | Training loss: 0.6883245124007171
Epoch: 16 | Iteration number: [540/4518] 11% | Training loss: 0.6882954980488176
Epoch: 16 | Iteration number: [550/4518] 12% | Training loss: 0.6882398040728136
Epoch: 16 | Iteration number: [560/4518] 12% | Training loss: 0.6882151527064188
Epoch: 16 | Iteration number: [570/4518] 12% | Training loss: 0.6881996688089873
Epoch: 16 | Iteration number: [580/4518] 12% | Training loss: 0.6881659016526979
Epoch: 16 | Iteration number: [590/4518] 13% | Training loss: 0.6881317388203184
Epoch: 16 | Iteration number: [600/4518] 13% | Training loss: 0.6881114103396734
Epoch: 16 | Iteration number: [610/4518] 13% | Training loss: 0.6880859518637422
Epoch: 16 | Iteration number: [620/4518] 13% | Training loss: 0.6880567733318576
Epoch: 16 | Iteration number: [630/4518] 13% | Training loss: 0.6880512216734508
Epoch: 16 | Iteration number: [640/4518] 14% | Training loss: 0.6880348791368306
Epoch: 16 | Iteration number: [650/4518] 14% | Training loss: 0.688003940307177
Epoch: 16 | Iteration number: [660/4518] 14% | Training loss: 0.6879758263176138
Epoch: 16 | Iteration number: [670/4518] 14% | Training loss: 0.6879608857987533
Epoch: 16 | Iteration number: [680/4518] 15% | Training loss: 0.6879363551735878
Epoch: 16 | Iteration number: [690/4518] 15% | Training loss: 0.687913347672725
Epoch: 16 | Iteration number: [700/4518] 15% | Training loss: 0.6879041516780853
Epoch: 16 | Iteration number: [710/4518] 15% | Training loss: 0.6878876104321279
Epoch: 16 | Iteration number: [720/4518] 15% | Training loss: 0.6878822714090347
Epoch: 16 | Iteration number: [730/4518] 16% | Training loss: 0.6878626478044954
Epoch: 16 | Iteration number: [740/4518] 16% | Training loss: 0.6878412920075494
Epoch: 16 | Iteration number: [750/4518] 16% | Training loss: 0.6878240467707316
Epoch: 16 | Iteration number: [760/4518] 16% | Training loss: 0.687821288955839
Epoch: 16 | Iteration number: [770/4518] 17% | Training loss: 0.6878038013136232
Epoch: 16 | Iteration number: [780/4518] 17% | Training loss: 0.6877864057436968
Epoch: 16 | Iteration number: [790/4518] 17% | Training loss: 0.6877828906608533
Epoch: 16 | Iteration number: [800/4518] 17% | Training loss: 0.6877690126001835
Epoch: 16 | Iteration number: [810/4518] 17% | Training loss: 0.6877770069940591
Epoch: 16 | Iteration number: [820/4518] 18% | Training loss: 0.6877566960526675
Epoch: 16 | Iteration number: [830/4518] 18% | Training loss: 0.6877343954092049
Epoch: 16 | Iteration number: [840/4518] 18% | Training loss: 0.6877142644354275
Epoch: 16 | Iteration number: [850/4518] 18% | Training loss: 0.6877158840964822
Epoch: 16 | Iteration number: [860/4518] 19% | Training loss: 0.6877108618270519
Epoch: 16 | Iteration number: [870/4518] 19% | Training loss: 0.6876945429834826
Epoch: 16 | Iteration number: [880/4518] 19% | Training loss: 0.6876910269260407
Epoch: 16 | Iteration number: [890/4518] 19% | Training loss: 0.6876814585053519
Epoch: 16 | Iteration number: [900/4518] 19% | Training loss: 0.6876681541734272
Epoch: 16 | Iteration number: [910/4518] 20% | Training loss: 0.6876537307278141
Epoch: 16 | Iteration number: [920/4518] 20% | Training loss: 0.687647452691327
Epoch: 16 | Iteration number: [930/4518] 20% | Training loss: 0.6876430576847445
Epoch: 16 | Iteration number: [940/4518] 20% | Training loss: 0.6876311926765645
Epoch: 16 | Iteration number: [950/4518] 21% | Training loss: 0.6876140054276115
Epoch: 16 | Iteration number: [960/4518] 21% | Training loss: 0.6876048378025492
Epoch: 16 | Iteration number: [970/4518] 21% | Training loss: 0.6876168582857269
Epoch: 16 | Iteration number: [980/4518] 21% | Training loss: 0.6876128508728377
Epoch: 16 | Iteration number: [990/4518] 21% | Training loss: 0.6875997813663097
Epoch: 16 | Iteration number: [1000/4518] 22% | Training loss: 0.6875851687788963
Epoch: 16 | Iteration number: [1010/4518] 22% | Training loss: 0.6875875496628261
Epoch: 16 | Iteration number: [1020/4518] 22% | Training loss: 0.6875825299351823
Epoch: 16 | Iteration number: [1030/4518] 22% | Training loss: 0.6875758080806547
Epoch: 16 | Iteration number: [1040/4518] 23% | Training loss: 0.6875546922477392
Epoch: 16 | Iteration number: [1050/4518] 23% | Training loss: 0.6875467625118438
Epoch: 16 | Iteration number: [1060/4518] 23% | Training loss: 0.6875437963121342
Epoch: 16 | Iteration number: [1070/4518] 23% | Training loss: 0.6875426140901084
Epoch: 16 | Iteration number: [1080/4518] 23% | Training loss: 0.6875350169561527
Epoch: 16 | Iteration number: [1090/4518] 24% | Training loss: 0.687517900259123
Epoch: 16 | Iteration number: [1100/4518] 24% | Training loss: 0.6875066627697511
Epoch: 16 | Iteration number: [1110/4518] 24% | Training loss: 0.6875006409915718
Epoch: 16 | Iteration number: [1120/4518] 24% | Training loss: 0.687493116355368
Epoch: 16 | Iteration number: [1130/4518] 25% | Training loss: 0.6874918773110988
Epoch: 16 | Iteration number: [1140/4518] 25% | Training loss: 0.687492292544298
Epoch: 16 | Iteration number: [1150/4518] 25% | Training loss: 0.6874778529353763
Epoch: 16 | Iteration number: [1160/4518] 25% | Training loss: 0.6874839706667538
Epoch: 16 | Iteration number: [1170/4518] 25% | Training loss: 0.6874881314416217
Epoch: 16 | Iteration number: [1180/4518] 26% | Training loss: 0.687480802101604
Epoch: 16 | Iteration number: [1190/4518] 26% | Training loss: 0.6874886014381376
Epoch: 16 | Iteration number: [1200/4518] 26% | Training loss: 0.6874807551999886
Epoch: 16 | Iteration number: [1210/4518] 26% | Training loss: 0.687479028376666
Epoch: 16 | Iteration number: [1220/4518] 27% | Training loss: 0.6874813856648617
Epoch: 16 | Iteration number: [1230/4518] 27% | Training loss: 0.6874800090382739
Epoch: 16 | Iteration number: [1240/4518] 27% | Training loss: 0.6874753082952192
Epoch: 16 | Iteration number: [1250/4518] 27% | Training loss: 0.6874760490417481
Epoch: 16 | Iteration number: [1260/4518] 27% | Training loss: 0.6874655346548747
Epoch: 16 | Iteration number: [1270/4518] 28% | Training loss: 0.6874661394460934
Epoch: 16 | Iteration number: [1280/4518] 28% | Training loss: 0.6874674268532545
Epoch: 16 | Iteration number: [1290/4518] 28% | Training loss: 0.6874566202015839
Epoch: 16 | Iteration number: [1300/4518] 28% | Training loss: 0.6874498825806837
Epoch: 16 | Iteration number: [1310/4518] 28% | Training loss: 0.6874374338233744
Epoch: 16 | Iteration number: [1320/4518] 29% | Training loss: 0.6874356207070929
Epoch: 16 | Iteration number: [1330/4518] 29% | Training loss: 0.6874329284617775
Epoch: 16 | Iteration number: [1340/4518] 29% | Training loss: 0.6874306124537738
Epoch: 16 | Iteration number: [1350/4518] 29% | Training loss: 0.687420806619856
Epoch: 16 | Iteration number: [1360/4518] 30% | Training loss: 0.6874187547056114
Epoch: 16 | Iteration number: [1370/4518] 30% | Training loss: 0.6874264687517263
Epoch: 16 | Iteration number: [1380/4518] 30% | Training loss: 0.6874185986276986
Epoch: 16 | Iteration number: [1390/4518] 30% | Training loss: 0.687421987296866
Epoch: 16 | Iteration number: [1400/4518] 30% | Training loss: 0.6874185242397445
Epoch: 16 | Iteration number: [1410/4518] 31% | Training loss: 0.6874179664233052
Epoch: 16 | Iteration number: [1420/4518] 31% | Training loss: 0.6874149643199544
Epoch: 16 | Iteration number: [1430/4518] 31% | Training loss: 0.6874068678259015
Epoch: 16 | Iteration number: [1440/4518] 31% | Training loss: 0.687409238724245
Epoch: 16 | Iteration number: [1450/4518] 32% | Training loss: 0.6874141796703996
Epoch: 16 | Iteration number: [1460/4518] 32% | Training loss: 0.687411156255905
Epoch: 16 | Iteration number: [1470/4518] 32% | Training loss: 0.6874089887353028
Epoch: 16 | Iteration number: [1480/4518] 32% | Training loss: 0.6873975923737964
Epoch: 16 | Iteration number: [1490/4518] 32% | Training loss: 0.68738761408217
Epoch: 16 | Iteration number: [1500/4518] 33% | Training loss: 0.6873828413883845
Epoch: 16 | Iteration number: [1510/4518] 33% | Training loss: 0.6873796252225408
Epoch: 16 | Iteration number: [1520/4518] 33% | Training loss: 0.6873663209770855
Epoch: 16 | Iteration number: [1530/4518] 33% | Training loss: 0.6873629695060206
Epoch: 16 | Iteration number: [1540/4518] 34% | Training loss: 0.687360089552867
Epoch: 16 | Iteration number: [1550/4518] 34% | Training loss: 0.687354934869274
Epoch: 16 | Iteration number: [1560/4518] 34% | Training loss: 0.6873463222613702
Epoch: 16 | Iteration number: [1570/4518] 34% | Training loss: 0.6873422236579239
Epoch: 16 | Iteration number: [1580/4518] 34% | Training loss: 0.6873362054930457
Epoch: 16 | Iteration number: [1590/4518] 35% | Training loss: 0.6873271957133551
Epoch: 16 | Iteration number: [1600/4518] 35% | Training loss: 0.6873262009769678
Epoch: 16 | Iteration number: [1610/4518] 35% | Training loss: 0.6873215014890114
Epoch: 16 | Iteration number: [1620/4518] 35% | Training loss: 0.6873203758472278
Epoch: 16 | Iteration number: [1630/4518] 36% | Training loss: 0.687319166565234
Epoch: 16 | Iteration number: [1640/4518] 36% | Training loss: 0.6873192856224571
Epoch: 16 | Iteration number: [1650/4518] 36% | Training loss: 0.6873098016146457
Epoch: 16 | Iteration number: [1660/4518] 36% | Training loss: 0.6873096323156931
Epoch: 16 | Iteration number: [1670/4518] 36% | Training loss: 0.6873088269890425
Epoch: 16 | Iteration number: [1680/4518] 37% | Training loss: 0.6873114780301139
Epoch: 16 | Iteration number: [1690/4518] 37% | Training loss: 0.6873148450131953
Epoch: 16 | Iteration number: [1700/4518] 37% | Training loss: 0.6873163683624829
Epoch: 16 | Iteration number: [1710/4518] 37% | Training loss: 0.6873065292486671
Epoch: 16 | Iteration number: [1720/4518] 38% | Training loss: 0.6873013049017551
Epoch: 16 | Iteration number: [1730/4518] 38% | Training loss: 0.6872949727353334
Epoch: 16 | Iteration number: [1740/4518] 38% | Training loss: 0.6872892218074579
Epoch: 16 | Iteration number: [1750/4518] 38% | Training loss: 0.6872812101840973
Epoch: 16 | Iteration number: [1760/4518] 38% | Training loss: 0.6872743197124113
Epoch: 16 | Iteration number: [1770/4518] 39% | Training loss: 0.687267268276484
Epoch: 16 | Iteration number: [1780/4518] 39% | Training loss: 0.6872647638736146
Epoch: 16 | Iteration number: [1790/4518] 39% | Training loss: 0.6872622583498502
Epoch: 16 | Iteration number: [1800/4518] 39% | Training loss: 0.6872685264216529
Epoch: 16 | Iteration number: [1810/4518] 40% | Training loss: 0.687264608184277
Epoch: 16 | Iteration number: [1820/4518] 40% | Training loss: 0.6872571799781296
Epoch: 16 | Iteration number: [1830/4518] 40% | Training loss: 0.6872550338995261
Epoch: 16 | Iteration number: [1840/4518] 40% | Training loss: 0.6872504377494688
Epoch: 16 | Iteration number: [1850/4518] 40% | Training loss: 0.6872512399828112
Epoch: 16 | Iteration number: [1860/4518] 41% | Training loss: 0.6872460692480046
Epoch: 16 | Iteration number: [1870/4518] 41% | Training loss: 0.6872506759383462
Epoch: 16 | Iteration number: [1880/4518] 41% | Training loss: 0.6872508337206029
Epoch: 16 | Iteration number: [1890/4518] 41% | Training loss: 0.6872393425494906
Epoch: 16 | Iteration number: [1900/4518] 42% | Training loss: 0.68724020929713
Epoch: 16 | Iteration number: [1910/4518] 42% | Training loss: 0.6872417328869486
Epoch: 16 | Iteration number: [1920/4518] 42% | Training loss: 0.6872411410013834
Epoch: 16 | Iteration number: [1930/4518] 42% | Training loss: 0.6872371276734407
Epoch: 16 | Iteration number: [1940/4518] 42% | Training loss: 0.687238585119395
Epoch: 16 | Iteration number: [1950/4518] 43% | Training loss: 0.6872364035325172
Epoch: 16 | Iteration number: [1960/4518] 43% | Training loss: 0.687234890460968
Epoch: 16 | Iteration number: [1970/4518] 43% | Training loss: 0.6872288250378545
Epoch: 16 | Iteration number: [1980/4518] 43% | Training loss: 0.6872273850019532
Epoch: 16 | Iteration number: [1990/4518] 44% | Training loss: 0.6872318821336756
Epoch: 16 | Iteration number: [2000/4518] 44% | Training loss: 0.6872322053313256
Epoch: 16 | Iteration number: [2010/4518] 44% | Training loss: 0.6872208266708981
Epoch: 16 | Iteration number: [2020/4518] 44% | Training loss: 0.6872152686709224
Epoch: 16 | Iteration number: [2030/4518] 44% | Training loss: 0.6872140811581917
Epoch: 16 | Iteration number: [2040/4518] 45% | Training loss: 0.6872133641558535
Epoch: 16 | Iteration number: [2050/4518] 45% | Training loss: 0.6872126625223858
Epoch: 16 | Iteration number: [2060/4518] 45% | Training loss: 0.6872110289856068
Epoch: 16 | Iteration number: [2070/4518] 45% | Training loss: 0.6872112844877197
Epoch: 16 | Iteration number: [2080/4518] 46% | Training loss: 0.6872118324327927
Epoch: 16 | Iteration number: [2090/4518] 46% | Training loss: 0.6872114549698441
Epoch: 16 | Iteration number: [2100/4518] 46% | Training loss: 0.6872135185060047
Epoch: 16 | Iteration number: [2110/4518] 46% | Training loss: 0.687210668432769
Epoch: 16 | Iteration number: [2120/4518] 46% | Training loss: 0.6872103691663383
Epoch: 16 | Iteration number: [2130/4518] 47% | Training loss: 0.6872081971504319
Epoch: 16 | Iteration number: [2140/4518] 47% | Training loss: 0.6872086996230009
Epoch: 16 | Iteration number: [2150/4518] 47% | Training loss: 0.6872074683322463
Epoch: 16 | Iteration number: [2160/4518] 47% | Training loss: 0.6872047227841837
Epoch: 16 | Iteration number: [2170/4518] 48% | Training loss: 0.6872055536316287
Epoch: 16 | Iteration number: [2180/4518] 48% | Training loss: 0.6872076441662027
Epoch: 16 | Iteration number: [2190/4518] 48% | Training loss: 0.687206443776823
Epoch: 16 | Iteration number: [2200/4518] 48% | Training loss: 0.6872045173699206
Epoch: 16 | Iteration number: [2210/4518] 48% | Training loss: 0.6871983459362617
Epoch: 16 | Iteration number: [2220/4518] 49% | Training loss: 0.6871995309720168
Epoch: 16 | Iteration number: [2230/4518] 49% | Training loss: 0.687202458451147
Epoch: 16 | Iteration number: [2240/4518] 49% | Training loss: 0.6872078895302756
Epoch: 16 | Iteration number: [2250/4518] 49% | Training loss: 0.6872013216283587
Epoch: 16 | Iteration number: [2260/4518] 50% | Training loss: 0.6871986414215207
Epoch: 16 | Iteration number: [2270/4518] 50% | Training loss: 0.6871973705711869
Epoch: 16 | Iteration number: [2280/4518] 50% | Training loss: 0.6871936164404217
Epoch: 16 | Iteration number: [2290/4518] 50% | Training loss: 0.6871954241694321
Epoch: 16 | Iteration number: [2300/4518] 50% | Training loss: 0.6871904306826384
Epoch: 16 | Iteration number: [2310/4518] 51% | Training loss: 0.68719113497507
Epoch: 16 | Iteration number: [2320/4518] 51% | Training loss: 0.6871923988749241
Epoch: 16 | Iteration number: [2330/4518] 51% | Training loss: 0.6871961776023259
Epoch: 16 | Iteration number: [2340/4518] 51% | Training loss: 0.6871967293513127
Epoch: 16 | Iteration number: [2350/4518] 52% | Training loss: 0.6871931869172035
Epoch: 16 | Iteration number: [2360/4518] 52% | Training loss: 0.6871930435552436
Epoch: 16 | Iteration number: [2370/4518] 52% | Training loss: 0.6871866392686901
Epoch: 16 | Iteration number: [2380/4518] 52% | Training loss: 0.6871846658342025
Epoch: 16 | Iteration number: [2390/4518] 52% | Training loss: 0.6871810370908122
Epoch: 16 | Iteration number: [2400/4518] 53% | Training loss: 0.6871808814257383
Epoch: 16 | Iteration number: [2410/4518] 53% | Training loss: 0.687182339024247
Epoch: 16 | Iteration number: [2420/4518] 53% | Training loss: 0.6871791025331198
Epoch: 16 | Iteration number: [2430/4518] 53% | Training loss: 0.6871791272987554
Epoch: 16 | Iteration number: [2440/4518] 54% | Training loss: 0.6871839992824148
Epoch: 16 | Iteration number: [2450/4518] 54% | Training loss: 0.6871853511917347
Epoch: 16 | Iteration number: [2460/4518] 54% | Training loss: 0.6871837292260271
Epoch: 16 | Iteration number: [2470/4518] 54% | Training loss: 0.6871800313594371
Epoch: 16 | Iteration number: [2480/4518] 54% | Training loss: 0.6871795941745081
Epoch: 16 | Iteration number: [2490/4518] 55% | Training loss: 0.6871839391419208
Epoch: 16 | Iteration number: [2500/4518] 55% | Training loss: 0.6871830957174301
Epoch: 16 | Iteration number: [2510/4518] 55% | Training loss: 0.6871799971002982
Epoch: 16 | Iteration number: [2520/4518] 55% | Training loss: 0.6871792889067105
Epoch: 16 | Iteration number: [2530/4518] 55% | Training loss: 0.6871782611245695
Epoch: 16 | Iteration number: [2540/4518] 56% | Training loss: 0.687182762937283
Epoch: 16 | Iteration number: [2550/4518] 56% | Training loss: 0.687185389621585
Epoch: 16 | Iteration number: [2560/4518] 56% | Training loss: 0.6871870624832809
Epoch: 16 | Iteration number: [2570/4518] 56% | Training loss: 0.687185520699052
Epoch: 16 | Iteration number: [2580/4518] 57% | Training loss: 0.6871788208798845
Epoch: 16 | Iteration number: [2590/4518] 57% | Training loss: 0.6871750076074858
Epoch: 16 | Iteration number: [2600/4518] 57% | Training loss: 0.6871748360303732
Epoch: 16 | Iteration number: [2610/4518] 57% | Training loss: 0.687177006312257
Epoch: 16 | Iteration number: [2620/4518] 57% | Training loss: 0.6871779619964935
Epoch: 16 | Iteration number: [2630/4518] 58% | Training loss: 0.6871777811204526
Epoch: 16 | Iteration number: [2640/4518] 58% | Training loss: 0.6871809085435939
Epoch: 16 | Iteration number: [2650/4518] 58% | Training loss: 0.6871804827114321
Epoch: 16 | Iteration number: [2660/4518] 58% | Training loss: 0.6871847335333214
Epoch: 16 | Iteration number: [2670/4518] 59% | Training loss: 0.6871878113193012
Epoch: 16 | Iteration number: [2680/4518] 59% | Training loss: 0.6871861908418029
Epoch: 16 | Iteration number: [2690/4518] 59% | Training loss: 0.6871870130189732
Epoch: 16 | Iteration number: [2700/4518] 59% | Training loss: 0.6871856767601437
Epoch: 16 | Iteration number: [2710/4518] 59% | Training loss: 0.6871869603426254
Epoch: 16 | Iteration number: [2720/4518] 60% | Training loss: 0.6871867783367633
Epoch: 16 | Iteration number: [2730/4518] 60% | Training loss: 0.687186960095451
Epoch: 16 | Iteration number: [2740/4518] 60% | Training loss: 0.687184681509533
Epoch: 16 | Iteration number: [2750/4518] 60% | Training loss: 0.6871873241121119
Epoch: 16 | Iteration number: [2760/4518] 61% | Training loss: 0.687187166231266
Epoch: 16 | Iteration number: [2770/4518] 61% | Training loss: 0.6871835992439559
Epoch: 16 | Iteration number: [2780/4518] 61% | Training loss: 0.6871802598881207
Epoch: 16 | Iteration number: [2790/4518] 61% | Training loss: 0.6871780352139558
Epoch: 16 | Iteration number: [2800/4518] 61% | Training loss: 0.6871816128066608
Epoch: 16 | Iteration number: [2810/4518] 62% | Training loss: 0.6871860029858626
Epoch: 16 | Iteration number: [2820/4518] 62% | Training loss: 0.6871875548827733
Epoch: 16 | Iteration number: [2830/4518] 62% | Training loss: 0.6871824263052048
Epoch: 16 | Iteration number: [2840/4518] 62% | Training loss: 0.6871807232079371
Epoch: 16 | Iteration number: [2850/4518] 63% | Training loss: 0.6871806700396956
Epoch: 16 | Iteration number: [2860/4518] 63% | Training loss: 0.6871803051525063
Epoch: 16 | Iteration number: [2870/4518] 63% | Training loss: 0.6871803797495906
Epoch: 16 | Iteration number: [2880/4518] 63% | Training loss: 0.6871815610056122
Epoch: 16 | Iteration number: [2890/4518] 63% | Training loss: 0.687176693352036
Epoch: 16 | Iteration number: [2900/4518] 64% | Training loss: 0.6871777257631565
Epoch: 16 | Iteration number: [2910/4518] 64% | Training loss: 0.6871766052704906
Epoch: 16 | Iteration number: [2920/4518] 64% | Training loss: 0.6871784474955847
Epoch: 16 | Iteration number: [2930/4518] 64% | Training loss: 0.6871793409459827
Epoch: 16 | Iteration number: [2940/4518] 65% | Training loss: 0.6871759014470237
Epoch: 16 | Iteration number: [2950/4518] 65% | Training loss: 0.6871774855710693
Epoch: 16 | Iteration number: [2960/4518] 65% | Training loss: 0.6871758682099549
Epoch: 16 | Iteration number: [2970/4518] 65% | Training loss: 0.6871764555121913
Epoch: 16 | Iteration number: [2980/4518] 65% | Training loss: 0.6871741047041529
Epoch: 16 | Iteration number: [2990/4518] 66% | Training loss: 0.687174572892811
Epoch: 16 | Iteration number: [3000/4518] 66% | Training loss: 0.687176190038522
Epoch: 16 | Iteration number: [3010/4518] 66% | Training loss: 0.6871787455588876
Epoch: 16 | Iteration number: [3020/4518] 66% | Training loss: 0.6871749666945034
Epoch: 16 | Iteration number: [3030/4518] 67% | Training loss: 0.6871727476812431
Epoch: 16 | Iteration number: [3040/4518] 67% | Training loss: 0.6871721224565255
Epoch: 16 | Iteration number: [3050/4518] 67% | Training loss: 0.687169600881514
Epoch: 16 | Iteration number: [3060/4518] 67% | Training loss: 0.6871682503254585
Epoch: 16 | Iteration number: [3070/4518] 67% | Training loss: 0.6871640875013333
Epoch: 16 | Iteration number: [3080/4518] 68% | Training loss: 0.6871574897851263
Epoch: 16 | Iteration number: [3090/4518] 68% | Training loss: 0.6871541291185953
Epoch: 16 | Iteration number: [3100/4518] 68% | Training loss: 0.6871550562689381
Epoch: 16 | Iteration number: [3110/4518] 68% | Training loss: 0.687154597120653
Epoch: 16 | Iteration number: [3120/4518] 69% | Training loss: 0.687154556161318
Epoch: 16 | Iteration number: [3130/4518] 69% | Training loss: 0.6871541538558448
Epoch: 16 | Iteration number: [3140/4518] 69% | Training loss: 0.6871498418271921
Epoch: 16 | Iteration number: [3150/4518] 69% | Training loss: 0.6871486370714884
Epoch: 16 | Iteration number: [3160/4518] 69% | Training loss: 0.6871493624169616
Epoch: 16 | Iteration number: [3170/4518] 70% | Training loss: 0.6871452623925375
Epoch: 16 | Iteration number: [3180/4518] 70% | Training loss: 0.6871447418470803
Epoch: 16 | Iteration number: [3190/4518] 70% | Training loss: 0.687141612330948
Epoch: 16 | Iteration number: [3200/4518] 70% | Training loss: 0.6871368917450309
Epoch: 16 | Iteration number: [3210/4518] 71% | Training loss: 0.687134315811585
Epoch: 16 | Iteration number: [3220/4518] 71% | Training loss: 0.687134024871062
Epoch: 16 | Iteration number: [3230/4518] 71% | Training loss: 0.6871377807099015
Epoch: 16 | Iteration number: [3240/4518] 71% | Training loss: 0.6871361585494913
Epoch: 16 | Iteration number: [3250/4518] 71% | Training loss: 0.6871338133811951
Epoch: 16 | Iteration number: [3260/4518] 72% | Training loss: 0.6871364661155303
Epoch: 16 | Iteration number: [3270/4518] 72% | Training loss: 0.6871369075884513
Epoch: 16 | Iteration number: [3280/4518] 72% | Training loss: 0.6871341388400009
Epoch: 16 | Iteration number: [3290/4518] 72% | Training loss: 0.687131593147672
Epoch: 16 | Iteration number: [3300/4518] 73% | Training loss: 0.6871276368878104
Epoch: 16 | Iteration number: [3310/4518] 73% | Training loss: 0.6871311986374351
Epoch: 16 | Iteration number: [3320/4518] 73% | Training loss: 0.687132001731051
Epoch: 16 | Iteration number: [3330/4518] 73% | Training loss: 0.6871325564456058
Epoch: 16 | Iteration number: [3340/4518] 73% | Training loss: 0.6871309517921802
Epoch: 16 | Iteration number: [3350/4518] 74% | Training loss: 0.6871335958189039
Epoch: 16 | Iteration number: [3360/4518] 74% | Training loss: 0.687133863568306
Epoch: 16 | Iteration number: [3370/4518] 74% | Training loss: 0.6871339415407323
Epoch: 16 | Iteration number: [3380/4518] 74% | Training loss: 0.6871368880278965
Epoch: 16 | Iteration number: [3390/4518] 75% | Training loss: 0.6871363657941508
Epoch: 16 | Iteration number: [3400/4518] 75% | Training loss: 0.6871348703433485
Epoch: 16 | Iteration number: [3410/4518] 75% | Training loss: 0.6871363651018338
Epoch: 16 | Iteration number: [3420/4518] 75% | Training loss: 0.68713729834696
Epoch: 16 | Iteration number: [3430/4518] 75% | Training loss: 0.6871366553855707
Epoch: 16 | Iteration number: [3440/4518] 76% | Training loss: 0.6871384043159873
Epoch: 16 | Iteration number: [3450/4518] 76% | Training loss: 0.6871392700292062
Epoch: 16 | Iteration number: [3460/4518] 76% | Training loss: 0.6871396573981797
Epoch: 16 | Iteration number: [3470/4518] 76% | Training loss: 0.6871406441634945
Epoch: 16 | Iteration number: [3480/4518] 77% | Training loss: 0.6871395775127684
Epoch: 16 | Iteration number: [3490/4518] 77% | Training loss: 0.6871394213256999
Epoch: 16 | Iteration number: [3500/4518] 77% | Training loss: 0.6871392838954925
Epoch: 16 | Iteration number: [3510/4518] 77% | Training loss: 0.6871373282029078
Epoch: 16 | Iteration number: [3520/4518] 77% | Training loss: 0.6871381222693758
Epoch: 16 | Iteration number: [3530/4518] 78% | Training loss: 0.6871385060018588
Epoch: 16 | Iteration number: [3540/4518] 78% | Training loss: 0.6871350489262134
Epoch: 16 | Iteration number: [3550/4518] 78% | Training loss: 0.6871326973404683
Epoch: 16 | Iteration number: [3560/4518] 78% | Training loss: 0.6871290261323533
Epoch: 16 | Iteration number: [3570/4518] 79% | Training loss: 0.6871295212697582
Epoch: 16 | Iteration number: [3580/4518] 79% | Training loss: 0.6871265427859802
Epoch: 16 | Iteration number: [3590/4518] 79% | Training loss: 0.6871269852172034
Epoch: 16 | Iteration number: [3600/4518] 79% | Training loss: 0.6871265336043305
Epoch: 16 | Iteration number: [3610/4518] 79% | Training loss: 0.6871268166069179
Epoch: 16 | Iteration number: [3620/4518] 80% | Training loss: 0.6871255956137378
Epoch: 16 | Iteration number: [3630/4518] 80% | Training loss: 0.687123833083581
Epoch: 16 | Iteration number: [3640/4518] 80% | Training loss: 0.6871227911540441
Epoch: 16 | Iteration number: [3650/4518] 80% | Training loss: 0.6871217753625896
Epoch: 16 | Iteration number: [3660/4518] 81% | Training loss: 0.6871237187600526
Epoch: 16 | Iteration number: [3670/4518] 81% | Training loss: 0.6871229972923809
Epoch: 16 | Iteration number: [3680/4518] 81% | Training loss: 0.6871212507881548
Epoch: 16 | Iteration number: [3690/4518] 81% | Training loss: 0.6871198430940064
Epoch: 16 | Iteration number: [3700/4518] 81% | Training loss: 0.6871196306396176
Epoch: 16 | Iteration number: [3710/4518] 82% | Training loss: 0.6871154675586526
Epoch: 16 | Iteration number: [3720/4518] 82% | Training loss: 0.6871143503214723
Epoch: 16 | Iteration number: [3730/4518] 82% | Training loss: 0.6871114475637594
Epoch: 16 | Iteration number: [3740/4518] 82% | Training loss: 0.6871104943082932
Epoch: 16 | Iteration number: [3750/4518] 83% | Training loss: 0.6871099484125773
Epoch: 16 | Iteration number: [3760/4518] 83% | Training loss: 0.6871092444880211
Epoch: 16 | Iteration number: [3770/4518] 83% | Training loss: 0.6871089797911657
Epoch: 16 | Iteration number: [3780/4518] 83% | Training loss: 0.687105720036875
Epoch: 16 | Iteration number: [3790/4518] 83% | Training loss: 0.6871044171045197
Epoch: 16 | Iteration number: [3800/4518] 84% | Training loss: 0.6871046708916363
Epoch: 16 | Iteration number: [3810/4518] 84% | Training loss: 0.6871035942255356
Epoch: 16 | Iteration number: [3820/4518] 84% | Training loss: 0.6871045365227455
Epoch: 16 | Iteration number: [3830/4518] 84% | Training loss: 0.6871071071755481
Epoch: 16 | Iteration number: [3840/4518] 84% | Training loss: 0.6871049713498603
Epoch: 16 | Iteration number: [3850/4518] 85% | Training loss: 0.6871027375041664
Epoch: 16 | Iteration number: [3860/4518] 85% | Training loss: 0.6871039414498472
Epoch: 16 | Iteration number: [3870/4518] 85% | Training loss: 0.6871036020360252
Epoch: 16 | Iteration number: [3880/4518] 85% | Training loss: 0.6871018475324837
Epoch: 16 | Iteration number: [3890/4518] 86% | Training loss: 0.6870995833205686
Epoch: 16 | Iteration number: [3900/4518] 86% | Training loss: 0.6870970045756071
Epoch: 16 | Iteration number: [3910/4518] 86% | Training loss: 0.6870930114060717
Epoch: 16 | Iteration number: [3920/4518] 86% | Training loss: 0.6870964340409454
Epoch: 16 | Iteration number: [3930/4518] 86% | Training loss: 0.6871010756977945
Epoch: 16 | Iteration number: [3940/4518] 87% | Training loss: 0.6871024151441409
Epoch: 16 | Iteration number: [3950/4518] 87% | Training loss: 0.6870999143847937
Epoch: 16 | Iteration number: [3960/4518] 87% | Training loss: 0.6870994922940177
Epoch: 16 | Iteration number: [3970/4518] 87% | Training loss: 0.6871020230147941
Epoch: 16 | Iteration number: [3980/4518] 88% | Training loss: 0.6871015846279998
Epoch: 16 | Iteration number: [3990/4518] 88% | Training loss: 0.6870995761607225
Epoch: 16 | Iteration number: [4000/4518] 88% | Training loss: 0.687099697932601
Epoch: 16 | Iteration number: [4010/4518] 88% | Training loss: 0.6870989380631958
Epoch: 16 | Iteration number: [4020/4518] 88% | Training loss: 0.6870973944812272
Epoch: 16 | Iteration number: [4030/4518] 89% | Training loss: 0.687096132622759
Epoch: 16 | Iteration number: [4040/4518] 89% | Training loss: 0.6870960786496059
Epoch: 16 | Iteration number: [4050/4518] 89% | Training loss: 0.6870993797131527
Epoch: 16 | Iteration number: [4060/4518] 89% | Training loss: 0.6870986837471648
Epoch: 16 | Iteration number: [4070/4518] 90% | Training loss: 0.6871002603221584
Epoch: 16 | Iteration number: [4080/4518] 90% | Training loss: 0.6870972764258291
Epoch: 16 | Iteration number: [4090/4518] 90% | Training loss: 0.6870962291154419
Epoch: 16 | Iteration number: [4100/4518] 90% | Training loss: 0.6870973023408796
Epoch: 16 | Iteration number: [4110/4518] 90% | Training loss: 0.6871003833565399
Epoch: 16 | Iteration number: [4120/4518] 91% | Training loss: 0.6871013201990174
Epoch: 16 | Iteration number: [4130/4518] 91% | Training loss: 0.6870987652433409
Epoch: 16 | Iteration number: [4140/4518] 91% | Training loss: 0.6871025558687063
Epoch: 16 | Iteration number: [4150/4518] 91% | Training loss: 0.687104454514492
Epoch: 16 | Iteration number: [4160/4518] 92% | Training loss: 0.6871042569382833
Epoch: 16 | Iteration number: [4170/4518] 92% | Training loss: 0.687103950820095
Epoch: 16 | Iteration number: [4180/4518] 92% | Training loss: 0.6871032526333366
Epoch: 16 | Iteration number: [4190/4518] 92% | Training loss: 0.6871009880290111
Epoch: 16 | Iteration number: [4200/4518] 92% | Training loss: 0.6871012828037852
Epoch: 16 | Iteration number: [4210/4518] 93% | Training loss: 0.6871001478611998
Epoch: 16 | Iteration number: [4220/4518] 93% | Training loss: 0.687101136239784
Epoch: 16 | Iteration number: [4230/4518] 93% | Training loss: 0.6870990973556014
Epoch: 16 | Iteration number: [4240/4518] 93% | Training loss: 0.6870972116600792
Epoch: 16 | Iteration number: [4250/4518] 94% | Training loss: 0.6870965708003325
Epoch: 16 | Iteration number: [4260/4518] 94% | Training loss: 0.6871000443685782
Epoch: 16 | Iteration number: [4270/4518] 94% | Training loss: 0.6871009147837235
Epoch: 16 | Iteration number: [4280/4518] 94% | Training loss: 0.6871011811856912
Epoch: 16 | Iteration number: [4290/4518] 94% | Training loss: 0.6870980890202911
Epoch: 16 | Iteration number: [4300/4518] 95% | Training loss: 0.6870947754937549
Epoch: 16 | Iteration number: [4310/4518] 95% | Training loss: 0.6870976451378135
Epoch: 16 | Iteration number: [4320/4518] 95% | Training loss: 0.6870989471811939
Epoch: 16 | Iteration number: [4330/4518] 95% | Training loss: 0.6870965115192581
Epoch: 16 | Iteration number: [4340/4518] 96% | Training loss: 0.6870961258488316
Epoch: 16 | Iteration number: [4350/4518] 96% | Training loss: 0.6870943385294114
Epoch: 16 | Iteration number: [4360/4518] 96% | Training loss: 0.6870924980131858
Epoch: 16 | Iteration number: [4370/4518] 96% | Training loss: 0.6870900440407017
Epoch: 16 | Iteration number: [4380/4518] 96% | Training loss: 0.6870891385562888
Epoch: 16 | Iteration number: [4390/4518] 97% | Training loss: 0.6870881422912885
Epoch: 16 | Iteration number: [4400/4518] 97% | Training loss: 0.6870863370732828
Epoch: 16 | Iteration number: [4410/4518] 97% | Training loss: 0.6870858446811062
Epoch: 16 | Iteration number: [4420/4518] 97% | Training loss: 0.6870849201042728
Epoch: 16 | Iteration number: [4430/4518] 98% | Training loss: 0.6870852764250194
Epoch: 16 | Iteration number: [4440/4518] 98% | Training loss: 0.6870851075058585
Epoch: 16 | Iteration number: [4450/4518] 98% | Training loss: 0.6870831610781423
Epoch: 16 | Iteration number: [4460/4518] 98% | Training loss: 0.6870835656943343
Epoch: 16 | Iteration number: [4470/4518] 98% | Training loss: 0.6870832826467168
Epoch: 16 | Iteration number: [4480/4518] 99% | Training loss: 0.6870847584546677
Epoch: 16 | Iteration number: [4490/4518] 99% | Training loss: 0.6870828467249074
Epoch: 16 | Iteration number: [4500/4518] 99% | Training loss: 0.6870831998586655
Epoch: 16 | Iteration number: [4510/4518] 99% | Training loss: 0.6870797815714073

 End of epoch: 16 | Train Loss: 0.6869294669259803 | Training Time: 643 

 End of epoch: 16 | Eval Loss: 0.6904708366004788 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/4518] 0% | Training loss: 0.7554278254508973
Epoch: 17 | Iteration number: [20/4518] 0% | Training loss: 0.7208636701107025
Epoch: 17 | Iteration number: [30/4518] 0% | Training loss: 0.7096309999624888
Epoch: 17 | Iteration number: [40/4518] 0% | Training loss: 0.703901755809784
Epoch: 17 | Iteration number: [50/4518] 1% | Training loss: 0.7005655908584595
Epoch: 17 | Iteration number: [60/4518] 1% | Training loss: 0.6983930875857671
Epoch: 17 | Iteration number: [70/4518] 1% | Training loss: 0.6966812866074699
Epoch: 17 | Iteration number: [80/4518] 1% | Training loss: 0.69546252861619
Epoch: 17 | Iteration number: [90/4518] 1% | Training loss: 0.6944551520877414
Epoch: 17 | Iteration number: [100/4518] 2% | Training loss: 0.6937457948923111
Epoch: 17 | Iteration number: [110/4518] 2% | Training loss: 0.6931341230869293
Epoch: 17 | Iteration number: [120/4518] 2% | Training loss: 0.6925877769788106
Epoch: 17 | Iteration number: [130/4518] 2% | Training loss: 0.6921081721782685
Epoch: 17 | Iteration number: [140/4518] 3% | Training loss: 0.6917697808572224
Epoch: 17 | Iteration number: [150/4518] 3% | Training loss: 0.6914672275384267
Epoch: 17 | Iteration number: [160/4518] 3% | Training loss: 0.6912415944039821
Epoch: 17 | Iteration number: [170/4518] 3% | Training loss: 0.6910269341048072
Epoch: 17 | Iteration number: [180/4518] 3% | Training loss: 0.690737799803416
Epoch: 17 | Iteration number: [190/4518] 4% | Training loss: 0.6904985989394941
Epoch: 17 | Iteration number: [200/4518] 4% | Training loss: 0.6903363969922066
Epoch: 17 | Iteration number: [210/4518] 4% | Training loss: 0.6901357497487749
Epoch: 17 | Iteration number: [220/4518] 4% | Training loss: 0.6900087408044121
Epoch: 17 | Iteration number: [230/4518] 5% | Training loss: 0.6898679354916448
Epoch: 17 | Iteration number: [240/4518] 5% | Training loss: 0.6897363980611165
Epoch: 17 | Iteration number: [250/4518] 5% | Training loss: 0.6896225128173828
Epoch: 17 | Iteration number: [260/4518] 5% | Training loss: 0.6895632938696787
Epoch: 17 | Iteration number: [270/4518] 5% | Training loss: 0.6894177589151594
Epoch: 17 | Iteration number: [280/4518] 6% | Training loss: 0.689327618266855
Epoch: 17 | Iteration number: [290/4518] 6% | Training loss: 0.6892432837650694
Epoch: 17 | Iteration number: [300/4518] 6% | Training loss: 0.6891581519444784
Epoch: 17 | Iteration number: [310/4518] 6% | Training loss: 0.6891055078275742
Epoch: 17 | Iteration number: [320/4518] 7% | Training loss: 0.6890465430915356
Epoch: 17 | Iteration number: [330/4518] 7% | Training loss: 0.6890026235219204
Epoch: 17 | Iteration number: [340/4518] 7% | Training loss: 0.6889466404914856
Epoch: 17 | Iteration number: [350/4518] 7% | Training loss: 0.6889181140490941
Epoch: 17 | Iteration number: [360/4518] 7% | Training loss: 0.6888624009158876
Epoch: 17 | Iteration number: [370/4518] 8% | Training loss: 0.6888068985294651
Epoch: 17 | Iteration number: [380/4518] 8% | Training loss: 0.6887296968384793
Epoch: 17 | Iteration number: [390/4518] 8% | Training loss: 0.6886884030623314
Epoch: 17 | Iteration number: [400/4518] 8% | Training loss: 0.6886509074270726
Epoch: 17 | Iteration number: [410/4518] 9% | Training loss: 0.6886474173243453
Epoch: 17 | Iteration number: [420/4518] 9% | Training loss: 0.6886216937076478
Epoch: 17 | Iteration number: [430/4518] 9% | Training loss: 0.6885762116243673
Epoch: 17 | Iteration number: [440/4518] 9% | Training loss: 0.6885605864904144
Epoch: 17 | Iteration number: [450/4518] 9% | Training loss: 0.6885359623697069
Epoch: 17 | Iteration number: [460/4518] 10% | Training loss: 0.6885251369165337
Epoch: 17 | Iteration number: [470/4518] 10% | Training loss: 0.6885028454851597
Epoch: 17 | Iteration number: [480/4518] 10% | Training loss: 0.6884562244017919
Epoch: 17 | Iteration number: [490/4518] 10% | Training loss: 0.6884250182278302
Epoch: 17 | Iteration number: [500/4518] 11% | Training loss: 0.6883869466781616
Epoch: 17 | Iteration number: [510/4518] 11% | Training loss: 0.6883291135816013
Epoch: 17 | Iteration number: [520/4518] 11% | Training loss: 0.6882918072434572
Epoch: 17 | Iteration number: [530/4518] 11% | Training loss: 0.6882617659163925
Epoch: 17 | Iteration number: [540/4518] 11% | Training loss: 0.6882600157349198
Epoch: 17 | Iteration number: [550/4518] 12% | Training loss: 0.6882437184723941
Epoch: 17 | Iteration number: [560/4518] 12% | Training loss: 0.6882335365882941
Epoch: 17 | Iteration number: [570/4518] 12% | Training loss: 0.688206778701983
Epoch: 17 | Iteration number: [580/4518] 12% | Training loss: 0.6881866357449827
Epoch: 17 | Iteration number: [590/4518] 13% | Training loss: 0.688172508902469
Epoch: 17 | Iteration number: [600/4518] 13% | Training loss: 0.6881515310208003
Epoch: 17 | Iteration number: [610/4518] 13% | Training loss: 0.6881470455497992
Epoch: 17 | Iteration number: [620/4518] 13% | Training loss: 0.6881303755506393
Epoch: 17 | Iteration number: [630/4518] 13% | Training loss: 0.6881131582789951
Epoch: 17 | Iteration number: [640/4518] 14% | Training loss: 0.6881053098477423
Epoch: 17 | Iteration number: [650/4518] 14% | Training loss: 0.6880892452826867
Epoch: 17 | Iteration number: [660/4518] 14% | Training loss: 0.6880745478651741
Epoch: 17 | Iteration number: [670/4518] 14% | Training loss: 0.6880497985811376
Epoch: 17 | Iteration number: [680/4518] 15% | Training loss: 0.6880475961110171
Epoch: 17 | Iteration number: [690/4518] 15% | Training loss: 0.6880221478317095
Epoch: 17 | Iteration number: [700/4518] 15% | Training loss: 0.6880037978717259
Epoch: 17 | Iteration number: [710/4518] 15% | Training loss: 0.6879999373160618
Epoch: 17 | Iteration number: [720/4518] 15% | Training loss: 0.6879768152203825
Epoch: 17 | Iteration number: [730/4518] 16% | Training loss: 0.687972032942184
Epoch: 17 | Iteration number: [740/4518] 16% | Training loss: 0.6879461729043239
Epoch: 17 | Iteration number: [750/4518] 16% | Training loss: 0.687929924805959
Epoch: 17 | Iteration number: [760/4518] 16% | Training loss: 0.6879269407767998
Epoch: 17 | Iteration number: [770/4518] 17% | Training loss: 0.6879284975590644
Epoch: 17 | Iteration number: [780/4518] 17% | Training loss: 0.6878964397387627
Epoch: 17 | Iteration number: [790/4518] 17% | Training loss: 0.6878700785999057
Epoch: 17 | Iteration number: [800/4518] 17% | Training loss: 0.6878613290935754
Epoch: 17 | Iteration number: [810/4518] 17% | Training loss: 0.6878553534731453
Epoch: 17 | Iteration number: [820/4518] 18% | Training loss: 0.68783340483177
Epoch: 17 | Iteration number: [830/4518] 18% | Training loss: 0.6878247324242649
Epoch: 17 | Iteration number: [840/4518] 18% | Training loss: 0.6878032849658103
Epoch: 17 | Iteration number: [850/4518] 18% | Training loss: 0.6877953443807714
Epoch: 17 | Iteration number: [860/4518] 19% | Training loss: 0.6877867371536964
Epoch: 17 | Iteration number: [870/4518] 19% | Training loss: 0.6877755106180564
Epoch: 17 | Iteration number: [880/4518] 19% | Training loss: 0.6877663974057544
Epoch: 17 | Iteration number: [890/4518] 19% | Training loss: 0.6877622259466836
Epoch: 17 | Iteration number: [900/4518] 19% | Training loss: 0.6877646513117684
Epoch: 17 | Iteration number: [910/4518] 20% | Training loss: 0.6877552750346425
Epoch: 17 | Iteration number: [920/4518] 20% | Training loss: 0.6877539477270582
Epoch: 17 | Iteration number: [930/4518] 20% | Training loss: 0.6877486447493235
Epoch: 17 | Iteration number: [940/4518] 20% | Training loss: 0.687737677135366
Epoch: 17 | Iteration number: [950/4518] 21% | Training loss: 0.6877243911592584
Epoch: 17 | Iteration number: [960/4518] 21% | Training loss: 0.687725956303378
Epoch: 17 | Iteration number: [970/4518] 21% | Training loss: 0.6877209635124993
Epoch: 17 | Iteration number: [980/4518] 21% | Training loss: 0.6877018469328783
Epoch: 17 | Iteration number: [990/4518] 21% | Training loss: 0.6876937958929273
Epoch: 17 | Iteration number: [1000/4518] 22% | Training loss: 0.6876897547245026
Epoch: 17 | Iteration number: [1010/4518] 22% | Training loss: 0.6876958055071312
Epoch: 17 | Iteration number: [1020/4518] 22% | Training loss: 0.6876797417799632
Epoch: 17 | Iteration number: [1030/4518] 22% | Training loss: 0.6876771794939505
Epoch: 17 | Iteration number: [1040/4518] 23% | Training loss: 0.6876641895908576
Epoch: 17 | Iteration number: [1050/4518] 23% | Training loss: 0.6876577418191092
Epoch: 17 | Iteration number: [1060/4518] 23% | Training loss: 0.6876438970835703
Epoch: 17 | Iteration number: [1070/4518] 23% | Training loss: 0.6876303996995231
Epoch: 17 | Iteration number: [1080/4518] 23% | Training loss: 0.6876341141484402
Epoch: 17 | Iteration number: [1090/4518] 24% | Training loss: 0.6876224090199952
Epoch: 17 | Iteration number: [1100/4518] 24% | Training loss: 0.6876099946823987
Epoch: 17 | Iteration number: [1110/4518] 24% | Training loss: 0.6876026195448798
Epoch: 17 | Iteration number: [1120/4518] 24% | Training loss: 0.68760492131114
Epoch: 17 | Iteration number: [1130/4518] 25% | Training loss: 0.6875933928299794
Epoch: 17 | Iteration number: [1140/4518] 25% | Training loss: 0.6875932238603893
Epoch: 17 | Iteration number: [1150/4518] 25% | Training loss: 0.6875846190556236
Epoch: 17 | Iteration number: [1160/4518] 25% | Training loss: 0.6875844290030414
Epoch: 17 | Iteration number: [1170/4518] 25% | Training loss: 0.6875700251668946
Epoch: 17 | Iteration number: [1180/4518] 26% | Training loss: 0.6875715806322583
Epoch: 17 | Iteration number: [1190/4518] 26% | Training loss: 0.6875787478034235
Epoch: 17 | Iteration number: [1200/4518] 26% | Training loss: 0.6875708484649659
Epoch: 17 | Iteration number: [1210/4518] 26% | Training loss: 0.6875705154966717
Epoch: 17 | Iteration number: [1220/4518] 27% | Training loss: 0.6875731354854145
Epoch: 17 | Iteration number: [1230/4518] 27% | Training loss: 0.6875704183326504
Epoch: 17 | Iteration number: [1240/4518] 27% | Training loss: 0.6875585740131717
Epoch: 17 | Iteration number: [1250/4518] 27% | Training loss: 0.6875525183677673
Epoch: 17 | Iteration number: [1260/4518] 27% | Training loss: 0.6875423491001129
Epoch: 17 | Iteration number: [1270/4518] 28% | Training loss: 0.6875372329565483
Epoch: 17 | Iteration number: [1280/4518] 28% | Training loss: 0.6875350266229361
Epoch: 17 | Iteration number: [1290/4518] 28% | Training loss: 0.6875293830106425
Epoch: 17 | Iteration number: [1300/4518] 28% | Training loss: 0.6875293010473251
Epoch: 17 | Iteration number: [1310/4518] 28% | Training loss: 0.6875260603336888
Epoch: 17 | Iteration number: [1320/4518] 29% | Training loss: 0.6875198259498134
Epoch: 17 | Iteration number: [1330/4518] 29% | Training loss: 0.6875140287374195
Epoch: 17 | Iteration number: [1340/4518] 29% | Training loss: 0.6875085833357342
Epoch: 17 | Iteration number: [1350/4518] 29% | Training loss: 0.6875134597442768
Epoch: 17 | Iteration number: [1360/4518] 30% | Training loss: 0.6875162991092486
Epoch: 17 | Iteration number: [1370/4518] 30% | Training loss: 0.6875109095643036
Epoch: 17 | Iteration number: [1380/4518] 30% | Training loss: 0.6874998618295227
Epoch: 17 | Iteration number: [1390/4518] 30% | Training loss: 0.6875040294455109
Epoch: 17 | Iteration number: [1400/4518] 30% | Training loss: 0.687510213639055
Epoch: 17 | Iteration number: [1410/4518] 31% | Training loss: 0.6875058172442389
Epoch: 17 | Iteration number: [1420/4518] 31% | Training loss: 0.6875052494062505
Epoch: 17 | Iteration number: [1430/4518] 31% | Training loss: 0.6875008318807695
Epoch: 17 | Iteration number: [1440/4518] 31% | Training loss: 0.6874957448906369
Epoch: 17 | Iteration number: [1450/4518] 32% | Training loss: 0.6874896896707601
Epoch: 17 | Iteration number: [1460/4518] 32% | Training loss: 0.6874798205209105
Epoch: 17 | Iteration number: [1470/4518] 32% | Training loss: 0.6874746591055474
Epoch: 17 | Iteration number: [1480/4518] 32% | Training loss: 0.6874720107461955
Epoch: 17 | Iteration number: [1490/4518] 32% | Training loss: 0.6874726596294634
Epoch: 17 | Iteration number: [1500/4518] 33% | Training loss: 0.6874658931096395
Epoch: 17 | Iteration number: [1510/4518] 33% | Training loss: 0.6874655219892792
Epoch: 17 | Iteration number: [1520/4518] 33% | Training loss: 0.6874631144498524
Epoch: 17 | Iteration number: [1530/4518] 33% | Training loss: 0.687457316529517
Epoch: 17 | Iteration number: [1540/4518] 34% | Training loss: 0.687443768126624
Epoch: 17 | Iteration number: [1550/4518] 34% | Training loss: 0.6874476629687893
Epoch: 17 | Iteration number: [1560/4518] 34% | Training loss: 0.6874453741388443
Epoch: 17 | Iteration number: [1570/4518] 34% | Training loss: 0.6874367843008345
Epoch: 17 | Iteration number: [1580/4518] 34% | Training loss: 0.6874411011798472
Epoch: 17 | Iteration number: [1590/4518] 35% | Training loss: 0.6874451871937926
Epoch: 17 | Iteration number: [1600/4518] 35% | Training loss: 0.6874404967948794
Epoch: 17 | Iteration number: [1610/4518] 35% | Training loss: 0.6874347732304046
Epoch: 17 | Iteration number: [1620/4518] 35% | Training loss: 0.6874447752664119
Epoch: 17 | Iteration number: [1630/4518] 36% | Training loss: 0.6874402675526273
Epoch: 17 | Iteration number: [1640/4518] 36% | Training loss: 0.6874356916401444
Epoch: 17 | Iteration number: [1650/4518] 36% | Training loss: 0.6874312140363635
Epoch: 17 | Iteration number: [1660/4518] 36% | Training loss: 0.6874275138220155
Epoch: 17 | Iteration number: [1670/4518] 36% | Training loss: 0.687426483452677
Epoch: 17 | Iteration number: [1680/4518] 37% | Training loss: 0.687429972347759
Epoch: 17 | Iteration number: [1690/4518] 37% | Training loss: 0.6874306030880065
Epoch: 17 | Iteration number: [1700/4518] 37% | Training loss: 0.6874179751031539
Epoch: 17 | Iteration number: [1710/4518] 37% | Training loss: 0.6874222227355891
Epoch: 17 | Iteration number: [1720/4518] 38% | Training loss: 0.6874238930122797
Epoch: 17 | Iteration number: [1730/4518] 38% | Training loss: 0.6874201609220119
Epoch: 17 | Iteration number: [1740/4518] 38% | Training loss: 0.687416512082363
Epoch: 17 | Iteration number: [1750/4518] 38% | Training loss: 0.6874101373468127
Epoch: 17 | Iteration number: [1760/4518] 38% | Training loss: 0.6874082354998047
Epoch: 17 | Iteration number: [1770/4518] 39% | Training loss: 0.6874033870333333
Epoch: 17 | Iteration number: [1780/4518] 39% | Training loss: 0.6873987665337123
Epoch: 17 | Iteration number: [1790/4518] 39% | Training loss: 0.6873979540843538
Epoch: 17 | Iteration number: [1800/4518] 39% | Training loss: 0.6874019032716752
Epoch: 17 | Iteration number: [1810/4518] 40% | Training loss: 0.687400356610177
Epoch: 17 | Iteration number: [1820/4518] 40% | Training loss: 0.6874019498680974
Epoch: 17 | Iteration number: [1830/4518] 40% | Training loss: 0.6873928259956381
Epoch: 17 | Iteration number: [1840/4518] 40% | Training loss: 0.6873974597648435
Epoch: 17 | Iteration number: [1850/4518] 40% | Training loss: 0.6873962739351633
Epoch: 17 | Iteration number: [1860/4518] 41% | Training loss: 0.6873823759696817
Epoch: 17 | Iteration number: [1870/4518] 41% | Training loss: 0.6873845687205778
Epoch: 17 | Iteration number: [1880/4518] 41% | Training loss: 0.6873816382377705
Epoch: 17 | Iteration number: [1890/4518] 41% | Training loss: 0.6873769392096807
Epoch: 17 | Iteration number: [1900/4518] 42% | Training loss: 0.6873671881776107
Epoch: 17 | Iteration number: [1910/4518] 42% | Training loss: 0.6873669778177252
Epoch: 17 | Iteration number: [1920/4518] 42% | Training loss: 0.6873637054736416
Epoch: 17 | Iteration number: [1930/4518] 42% | Training loss: 0.6873629559507024
Epoch: 17 | Iteration number: [1940/4518] 42% | Training loss: 0.6873629266146533
Epoch: 17 | Iteration number: [1950/4518] 43% | Training loss: 0.68736251219725
Epoch: 17 | Iteration number: [1960/4518] 43% | Training loss: 0.6873580098152161
Epoch: 17 | Iteration number: [1970/4518] 43% | Training loss: 0.6873493205774859
Epoch: 17 | Iteration number: [1980/4518] 43% | Training loss: 0.6873514908431756
Epoch: 17 | Iteration number: [1990/4518] 44% | Training loss: 0.6873535804413072
Epoch: 17 | Iteration number: [2000/4518] 44% | Training loss: 0.6873523198366165
Epoch: 17 | Iteration number: [2010/4518] 44% | Training loss: 0.687352231663851
Epoch: 17 | Iteration number: [2020/4518] 44% | Training loss: 0.6873460169475858
Epoch: 17 | Iteration number: [2030/4518] 44% | Training loss: 0.687340321564322
Epoch: 17 | Iteration number: [2040/4518] 45% | Training loss: 0.6873353309198922
Epoch: 17 | Iteration number: [2050/4518] 45% | Training loss: 0.6873330514023943
Epoch: 17 | Iteration number: [2060/4518] 45% | Training loss: 0.687331358611005
Epoch: 17 | Iteration number: [2070/4518] 45% | Training loss: 0.6873299644765071
Epoch: 17 | Iteration number: [2080/4518] 46% | Training loss: 0.6873333751868743
Epoch: 17 | Iteration number: [2090/4518] 46% | Training loss: 0.6873314429983568
Epoch: 17 | Iteration number: [2100/4518] 46% | Training loss: 0.6873276868604479
Epoch: 17 | Iteration number: [2110/4518] 46% | Training loss: 0.687321382648007
Epoch: 17 | Iteration number: [2120/4518] 46% | Training loss: 0.6873209051084969
Epoch: 17 | Iteration number: [2130/4518] 47% | Training loss: 0.6873206946491636
Epoch: 17 | Iteration number: [2140/4518] 47% | Training loss: 0.687321074181628
Epoch: 17 | Iteration number: [2150/4518] 47% | Training loss: 0.6873249888142874
Epoch: 17 | Iteration number: [2160/4518] 47% | Training loss: 0.6873192996890457
Epoch: 17 | Iteration number: [2170/4518] 48% | Training loss: 0.6873209454496885
Epoch: 17 | Iteration number: [2180/4518] 48% | Training loss: 0.6873161344079797
Epoch: 17 | Iteration number: [2190/4518] 48% | Training loss: 0.6873105699885381
Epoch: 17 | Iteration number: [2200/4518] 48% | Training loss: 0.6873060744729909
Epoch: 17 | Iteration number: [2210/4518] 48% | Training loss: 0.687301680944624
Epoch: 17 | Iteration number: [2220/4518] 49% | Training loss: 0.6872982166908883
Epoch: 17 | Iteration number: [2230/4518] 49% | Training loss: 0.6872925141734393
Epoch: 17 | Iteration number: [2240/4518] 49% | Training loss: 0.6872856504150799
Epoch: 17 | Iteration number: [2250/4518] 49% | Training loss: 0.6872851538128323
Epoch: 17 | Iteration number: [2260/4518] 50% | Training loss: 0.6872817815668815
Epoch: 17 | Iteration number: [2270/4518] 50% | Training loss: 0.6872803636584514
Epoch: 17 | Iteration number: [2280/4518] 50% | Training loss: 0.6872799318349152
Epoch: 17 | Iteration number: [2290/4518] 50% | Training loss: 0.6872820768033573
Epoch: 17 | Iteration number: [2300/4518] 50% | Training loss: 0.6872806746804196
Epoch: 17 | Iteration number: [2310/4518] 51% | Training loss: 0.6872772179640733
Epoch: 17 | Iteration number: [2320/4518] 51% | Training loss: 0.6872772259445026
Epoch: 17 | Iteration number: [2330/4518] 51% | Training loss: 0.6872732850103419
Epoch: 17 | Iteration number: [2340/4518] 51% | Training loss: 0.687272514619379
Epoch: 17 | Iteration number: [2350/4518] 52% | Training loss: 0.687265260143483
Epoch: 17 | Iteration number: [2360/4518] 52% | Training loss: 0.6872593720838175
Epoch: 17 | Iteration number: [2370/4518] 52% | Training loss: 0.6872540414836337
Epoch: 17 | Iteration number: [2380/4518] 52% | Training loss: 0.6872549097828504
Epoch: 17 | Iteration number: [2390/4518] 52% | Training loss: 0.6872560712084111
Epoch: 17 | Iteration number: [2400/4518] 53% | Training loss: 0.6872537997861703
Epoch: 17 | Iteration number: [2410/4518] 53% | Training loss: 0.6872510135173797
Epoch: 17 | Iteration number: [2420/4518] 53% | Training loss: 0.6872502898135461
Epoch: 17 | Iteration number: [2430/4518] 53% | Training loss: 0.687247075318309
Epoch: 17 | Iteration number: [2440/4518] 54% | Training loss: 0.687247750114222
Epoch: 17 | Iteration number: [2450/4518] 54% | Training loss: 0.6872451002013926
Epoch: 17 | Iteration number: [2460/4518] 54% | Training loss: 0.6872411912292
Epoch: 17 | Iteration number: [2470/4518] 54% | Training loss: 0.6872359021472545
Epoch: 17 | Iteration number: [2480/4518] 54% | Training loss: 0.68723238201872
Epoch: 17 | Iteration number: [2490/4518] 55% | Training loss: 0.6872279602361012
Epoch: 17 | Iteration number: [2500/4518] 55% | Training loss: 0.6872274307250976
Epoch: 17 | Iteration number: [2510/4518] 55% | Training loss: 0.6872266333891576
Epoch: 17 | Iteration number: [2520/4518] 55% | Training loss: 0.6872269990661788
Epoch: 17 | Iteration number: [2530/4518] 55% | Training loss: 0.6872166756349118
Epoch: 17 | Iteration number: [2540/4518] 56% | Training loss: 0.6872153488435144
Epoch: 17 | Iteration number: [2550/4518] 56% | Training loss: 0.6872162319632138
Epoch: 17 | Iteration number: [2560/4518] 56% | Training loss: 0.6872130347415805
Epoch: 17 | Iteration number: [2570/4518] 56% | Training loss: 0.6872117043237278
Epoch: 17 | Iteration number: [2580/4518] 57% | Training loss: 0.6872069747411004
Epoch: 17 | Iteration number: [2590/4518] 57% | Training loss: 0.6872070518469718
Epoch: 17 | Iteration number: [2600/4518] 57% | Training loss: 0.6872055345544448
Epoch: 17 | Iteration number: [2610/4518] 57% | Training loss: 0.687201585372289
Epoch: 17 | Iteration number: [2620/4518] 57% | Training loss: 0.6872021288589667
Epoch: 17 | Iteration number: [2630/4518] 58% | Training loss: 0.6872043052553677
Epoch: 17 | Iteration number: [2640/4518] 58% | Training loss: 0.6871996288724018
Epoch: 17 | Iteration number: [2650/4518] 58% | Training loss: 0.6872018645619447
Epoch: 17 | Iteration number: [2660/4518] 58% | Training loss: 0.6872009935459696
Epoch: 17 | Iteration number: [2670/4518] 59% | Training loss: 0.6872055176268803
Epoch: 17 | Iteration number: [2680/4518] 59% | Training loss: 0.6872046341869369
Epoch: 17 | Iteration number: [2690/4518] 59% | Training loss: 0.6871991282058915
Epoch: 17 | Iteration number: [2700/4518] 59% | Training loss: 0.6871945643645746
Epoch: 17 | Iteration number: [2710/4518] 59% | Training loss: 0.6871906427659672
Epoch: 17 | Iteration number: [2720/4518] 60% | Training loss: 0.6871898069101221
Epoch: 17 | Iteration number: [2730/4518] 60% | Training loss: 0.6871909814876515
Epoch: 17 | Iteration number: [2740/4518] 60% | Training loss: 0.6871881557859644
Epoch: 17 | Iteration number: [2750/4518] 60% | Training loss: 0.6871910684542223
Epoch: 17 | Iteration number: [2760/4518] 61% | Training loss: 0.6871894548984542
Epoch: 17 | Iteration number: [2770/4518] 61% | Training loss: 0.6871861890119766
Epoch: 17 | Iteration number: [2780/4518] 61% | Training loss: 0.687188463352567
Epoch: 17 | Iteration number: [2790/4518] 61% | Training loss: 0.6871866369332891
Epoch: 17 | Iteration number: [2800/4518] 61% | Training loss: 0.6871864514691489
Epoch: 17 | Iteration number: [2810/4518] 62% | Training loss: 0.6871850320452897
Epoch: 17 | Iteration number: [2820/4518] 62% | Training loss: 0.6871871482395957
Epoch: 17 | Iteration number: [2830/4518] 62% | Training loss: 0.687184206546406
Epoch: 17 | Iteration number: [2840/4518] 62% | Training loss: 0.6871800644296996
Epoch: 17 | Iteration number: [2850/4518] 63% | Training loss: 0.6871819030820278
Epoch: 17 | Iteration number: [2860/4518] 63% | Training loss: 0.6871787266506182
Epoch: 17 | Iteration number: [2870/4518] 63% | Training loss: 0.6871767010422949
Epoch: 17 | Iteration number: [2880/4518] 63% | Training loss: 0.6871748250391748
Epoch: 17 | Iteration number: [2890/4518] 63% | Training loss: 0.687174119606975
Epoch: 17 | Iteration number: [2900/4518] 64% | Training loss: 0.6871731007921285
Epoch: 17 | Iteration number: [2910/4518] 64% | Training loss: 0.6871736730087254
Epoch: 17 | Iteration number: [2920/4518] 64% | Training loss: 0.6871770176577241
Epoch: 17 | Iteration number: [2930/4518] 64% | Training loss: 0.6871780028725647
Epoch: 17 | Iteration number: [2940/4518] 65% | Training loss: 0.6871811680445055
Epoch: 17 | Iteration number: [2950/4518] 65% | Training loss: 0.6871802554090144
Epoch: 17 | Iteration number: [2960/4518] 65% | Training loss: 0.6871838906729544
Epoch: 17 | Iteration number: [2970/4518] 65% | Training loss: 0.6871836341591395
Epoch: 17 | Iteration number: [2980/4518] 65% | Training loss: 0.6871852065492796
Epoch: 17 | Iteration number: [2990/4518] 66% | Training loss: 0.6871832304574973
Epoch: 17 | Iteration number: [3000/4518] 66% | Training loss: 0.6871809488336246
Epoch: 17 | Iteration number: [3010/4518] 66% | Training loss: 0.6871762845801357
Epoch: 17 | Iteration number: [3020/4518] 66% | Training loss: 0.6871766884003254
Epoch: 17 | Iteration number: [3030/4518] 67% | Training loss: 0.6871758733055379
Epoch: 17 | Iteration number: [3040/4518] 67% | Training loss: 0.687175503000617
Epoch: 17 | Iteration number: [3050/4518] 67% | Training loss: 0.6871740586640405
Epoch: 17 | Iteration number: [3060/4518] 67% | Training loss: 0.687174596428092
Epoch: 17 | Iteration number: [3070/4518] 67% | Training loss: 0.6871748737869511
Epoch: 17 | Iteration number: [3080/4518] 68% | Training loss: 0.6871776847289754
Epoch: 17 | Iteration number: [3090/4518] 68% | Training loss: 0.6871799660539164
Epoch: 17 | Iteration number: [3100/4518] 68% | Training loss: 0.6871804553654886
Epoch: 17 | Iteration number: [3110/4518] 68% | Training loss: 0.6871791340147184
Epoch: 17 | Iteration number: [3120/4518] 69% | Training loss: 0.687180822648299
Epoch: 17 | Iteration number: [3130/4518] 69% | Training loss: 0.6871802649368494
Epoch: 17 | Iteration number: [3140/4518] 69% | Training loss: 0.6871776853397393
Epoch: 17 | Iteration number: [3150/4518] 69% | Training loss: 0.6871743304956527
Epoch: 17 | Iteration number: [3160/4518] 69% | Training loss: 0.6871775122571595
Epoch: 17 | Iteration number: [3170/4518] 70% | Training loss: 0.6871754933794966
Epoch: 17 | Iteration number: [3180/4518] 70% | Training loss: 0.6871739861162953
Epoch: 17 | Iteration number: [3190/4518] 70% | Training loss: 0.6871738321168296
Epoch: 17 | Iteration number: [3200/4518] 70% | Training loss: 0.687171858586371
Epoch: 17 | Iteration number: [3210/4518] 71% | Training loss: 0.6871678846090382
Epoch: 17 | Iteration number: [3220/4518] 71% | Training loss: 0.6871664620519424
Epoch: 17 | Iteration number: [3230/4518] 71% | Training loss: 0.6871670898638274
Epoch: 17 | Iteration number: [3240/4518] 71% | Training loss: 0.687170684080065
Epoch: 17 | Iteration number: [3250/4518] 71% | Training loss: 0.6871725812875308
Epoch: 17 | Iteration number: [3260/4518] 72% | Training loss: 0.687169851975207
Epoch: 17 | Iteration number: [3270/4518] 72% | Training loss: 0.6871709867901759
Epoch: 17 | Iteration number: [3280/4518] 72% | Training loss: 0.6871725098025508
Epoch: 17 | Iteration number: [3290/4518] 72% | Training loss: 0.6871708075507433
Epoch: 17 | Iteration number: [3300/4518] 73% | Training loss: 0.6871683381362395
Epoch: 17 | Iteration number: [3310/4518] 73% | Training loss: 0.6871669225642328
Epoch: 17 | Iteration number: [3320/4518] 73% | Training loss: 0.6871631265404713
Epoch: 17 | Iteration number: [3330/4518] 73% | Training loss: 0.6871612987718783
Epoch: 17 | Iteration number: [3340/4518] 73% | Training loss: 0.6871624909296721
Epoch: 17 | Iteration number: [3350/4518] 74% | Training loss: 0.6871580759980785
Epoch: 17 | Iteration number: [3360/4518] 74% | Training loss: 0.6871591156259889
Epoch: 17 | Iteration number: [3370/4518] 74% | Training loss: 0.687159906898125
Epoch: 17 | Iteration number: [3380/4518] 74% | Training loss: 0.6871588908179977
Epoch: 17 | Iteration number: [3390/4518] 75% | Training loss: 0.687158729720608
Epoch: 17 | Iteration number: [3400/4518] 75% | Training loss: 0.6871604625968372
Epoch: 17 | Iteration number: [3410/4518] 75% | Training loss: 0.687157272034027
Epoch: 17 | Iteration number: [3420/4518] 75% | Training loss: 0.6871546791136613
Epoch: 17 | Iteration number: [3430/4518] 75% | Training loss: 0.6871552651720909
Epoch: 17 | Iteration number: [3440/4518] 76% | Training loss: 0.6871529699758042
Epoch: 17 | Iteration number: [3450/4518] 76% | Training loss: 0.6871561036420905
Epoch: 17 | Iteration number: [3460/4518] 76% | Training loss: 0.6871563860446731
Epoch: 17 | Iteration number: [3470/4518] 76% | Training loss: 0.6871572830319748
Epoch: 17 | Iteration number: [3480/4518] 77% | Training loss: 0.6871553058939418
Epoch: 17 | Iteration number: [3490/4518] 77% | Training loss: 0.6871546225254037
Epoch: 17 | Iteration number: [3500/4518] 77% | Training loss: 0.687154352750097
Epoch: 17 | Iteration number: [3510/4518] 77% | Training loss: 0.6871539578988002
Epoch: 17 | Iteration number: [3520/4518] 77% | Training loss: 0.6871503801677715
Epoch: 17 | Iteration number: [3530/4518] 78% | Training loss: 0.6871501390218059
Epoch: 17 | Iteration number: [3540/4518] 78% | Training loss: 0.6871493544955711
Epoch: 17 | Iteration number: [3550/4518] 78% | Training loss: 0.6871490330427465
Epoch: 17 | Iteration number: [3560/4518] 78% | Training loss: 0.68714760623956
Epoch: 17 | Iteration number: [3570/4518] 79% | Training loss: 0.6871469430061949
Epoch: 17 | Iteration number: [3580/4518] 79% | Training loss: 0.6871459260333184
Epoch: 17 | Iteration number: [3590/4518] 79% | Training loss: 0.6871462184904678
Epoch: 17 | Iteration number: [3600/4518] 79% | Training loss: 0.68714346225063
Epoch: 17 | Iteration number: [3610/4518] 79% | Training loss: 0.6871403854969796
Epoch: 17 | Iteration number: [3620/4518] 80% | Training loss: 0.687140955977677
Epoch: 17 | Iteration number: [3630/4518] 80% | Training loss: 0.6871407178643649
Epoch: 17 | Iteration number: [3640/4518] 80% | Training loss: 0.6871382130207596
Epoch: 17 | Iteration number: [3650/4518] 80% | Training loss: 0.687139405959273
Epoch: 17 | Iteration number: [3660/4518] 81% | Training loss: 0.6871424103695187
Epoch: 17 | Iteration number: [3670/4518] 81% | Training loss: 0.6871415260539717
Epoch: 17 | Iteration number: [3680/4518] 81% | Training loss: 0.6871418359486953
Epoch: 17 | Iteration number: [3690/4518] 81% | Training loss: 0.6871451101975066
Epoch: 17 | Iteration number: [3700/4518] 81% | Training loss: 0.6871432966799349
Epoch: 17 | Iteration number: [3710/4518] 82% | Training loss: 0.6871436661305131
Epoch: 17 | Iteration number: [3720/4518] 82% | Training loss: 0.6871473743390012
Epoch: 17 | Iteration number: [3730/4518] 82% | Training loss: 0.6871485163954564
Epoch: 17 | Iteration number: [3740/4518] 82% | Training loss: 0.6871470677661385
Epoch: 17 | Iteration number: [3750/4518] 83% | Training loss: 0.6871445122241974
Epoch: 17 | Iteration number: [3760/4518] 83% | Training loss: 0.6871442200814156
Epoch: 17 | Iteration number: [3770/4518] 83% | Training loss: 0.6871464069705426
Epoch: 17 | Iteration number: [3780/4518] 83% | Training loss: 0.6871416764757621
Epoch: 17 | Iteration number: [3790/4518] 83% | Training loss: 0.6871418493876043
Epoch: 17 | Iteration number: [3800/4518] 84% | Training loss: 0.6871404989299021
Epoch: 17 | Iteration number: [3810/4518] 84% | Training loss: 0.687138753785236
Epoch: 17 | Iteration number: [3820/4518] 84% | Training loss: 0.6871375544377022
Epoch: 17 | Iteration number: [3830/4518] 84% | Training loss: 0.6871370262639018
Epoch: 17 | Iteration number: [3840/4518] 84% | Training loss: 0.6871357385534793
Epoch: 17 | Iteration number: [3850/4518] 85% | Training loss: 0.6871325710377136
Epoch: 17 | Iteration number: [3860/4518] 85% | Training loss: 0.6871327941127392
Epoch: 17 | Iteration number: [3870/4518] 85% | Training loss: 0.6871317992838778
Epoch: 17 | Iteration number: [3880/4518] 85% | Training loss: 0.6871330389656971
Epoch: 17 | Iteration number: [3890/4518] 86% | Training loss: 0.6871322153772976
Epoch: 17 | Iteration number: [3900/4518] 86% | Training loss: 0.6871284704636305
Epoch: 17 | Iteration number: [3910/4518] 86% | Training loss: 0.6871268601368761
Epoch: 17 | Iteration number: [3920/4518] 86% | Training loss: 0.6871273083498284
Epoch: 17 | Iteration number: [3930/4518] 86% | Training loss: 0.6871305022682549
Epoch: 17 | Iteration number: [3940/4518] 87% | Training loss: 0.6871280353837812
Epoch: 17 | Iteration number: [3950/4518] 87% | Training loss: 0.6871241107168077
Epoch: 17 | Iteration number: [3960/4518] 87% | Training loss: 0.6871212078164323
Epoch: 17 | Iteration number: [3970/4518] 87% | Training loss: 0.687117289746138
Epoch: 17 | Iteration number: [3980/4518] 88% | Training loss: 0.6871160012693261
Epoch: 17 | Iteration number: [3990/4518] 88% | Training loss: 0.6871125912009026
Epoch: 17 | Iteration number: [4000/4518] 88% | Training loss: 0.6871110119819641
Epoch: 17 | Iteration number: [4010/4518] 88% | Training loss: 0.6871138980412423
Epoch: 17 | Iteration number: [4020/4518] 88% | Training loss: 0.6871107271209879
Epoch: 17 | Iteration number: [4030/4518] 89% | Training loss: 0.6871110702270905
Epoch: 17 | Iteration number: [4040/4518] 89% | Training loss: 0.6871089843387651
Epoch: 17 | Iteration number: [4050/4518] 89% | Training loss: 0.6871077669108355
Epoch: 17 | Iteration number: [4060/4518] 89% | Training loss: 0.6871045192621025
Epoch: 17 | Iteration number: [4070/4518] 90% | Training loss: 0.6871023462504076
Epoch: 17 | Iteration number: [4080/4518] 90% | Training loss: 0.6871005267781369
Epoch: 17 | Iteration number: [4090/4518] 90% | Training loss: 0.687099691912131
Epoch: 17 | Iteration number: [4100/4518] 90% | Training loss: 0.6870997640708598
Epoch: 17 | Iteration number: [4110/4518] 90% | Training loss: 0.6870994593975318
Epoch: 17 | Iteration number: [4120/4518] 91% | Training loss: 0.6870977883200043
Epoch: 17 | Iteration number: [4130/4518] 91% | Training loss: 0.6870981085820002
Epoch: 17 | Iteration number: [4140/4518] 91% | Training loss: 0.6870945073124292
Epoch: 17 | Iteration number: [4150/4518] 91% | Training loss: 0.6870923729115221
Epoch: 17 | Iteration number: [4160/4518] 92% | Training loss: 0.687091255460221
Epoch: 17 | Iteration number: [4170/4518] 92% | Training loss: 0.6870922761569492
Epoch: 17 | Iteration number: [4180/4518] 92% | Training loss: 0.6870931868062635
Epoch: 17 | Iteration number: [4190/4518] 92% | Training loss: 0.6870901361570153
Epoch: 17 | Iteration number: [4200/4518] 92% | Training loss: 0.687090892351809
Epoch: 17 | Iteration number: [4210/4518] 93% | Training loss: 0.6870920650749478
Epoch: 17 | Iteration number: [4220/4518] 93% | Training loss: 0.6870943309571506
Epoch: 17 | Iteration number: [4230/4518] 93% | Training loss: 0.6870957209849752
Epoch: 17 | Iteration number: [4240/4518] 93% | Training loss: 0.6870945167850774
Epoch: 17 | Iteration number: [4250/4518] 94% | Training loss: 0.6870894680864671
Epoch: 17 | Iteration number: [4260/4518] 94% | Training loss: 0.6870887711993965
Epoch: 17 | Iteration number: [4270/4518] 94% | Training loss: 0.6870862090475944
Epoch: 17 | Iteration number: [4280/4518] 94% | Training loss: 0.6870868875601581
Epoch: 17 | Iteration number: [4290/4518] 94% | Training loss: 0.6870886362515963
Epoch: 17 | Iteration number: [4300/4518] 95% | Training loss: 0.6870886817089347
Epoch: 17 | Iteration number: [4310/4518] 95% | Training loss: 0.6870885149647078
Epoch: 17 | Iteration number: [4320/4518] 95% | Training loss: 0.6870874003265743
Epoch: 17 | Iteration number: [4330/4518] 95% | Training loss: 0.6870884315659213
Epoch: 17 | Iteration number: [4340/4518] 96% | Training loss: 0.6870876695016562
Epoch: 17 | Iteration number: [4350/4518] 96% | Training loss: 0.6870881392352882
Epoch: 17 | Iteration number: [4360/4518] 96% | Training loss: 0.6870860971031932
Epoch: 17 | Iteration number: [4370/4518] 96% | Training loss: 0.6870862136716428
Epoch: 17 | Iteration number: [4380/4518] 96% | Training loss: 0.6870889069146762
Epoch: 17 | Iteration number: [4390/4518] 97% | Training loss: 0.6870889449716973
Epoch: 17 | Iteration number: [4400/4518] 97% | Training loss: 0.6870880830829794
Epoch: 17 | Iteration number: [4410/4518] 97% | Training loss: 0.6870867096377609
Epoch: 17 | Iteration number: [4420/4518] 97% | Training loss: 0.6870872196568623
Epoch: 17 | Iteration number: [4430/4518] 98% | Training loss: 0.6870846138043544
Epoch: 17 | Iteration number: [4440/4518] 98% | Training loss: 0.6870852939985894
Epoch: 17 | Iteration number: [4450/4518] 98% | Training loss: 0.6870847170808342
Epoch: 17 | Iteration number: [4460/4518] 98% | Training loss: 0.6870854337921057
Epoch: 17 | Iteration number: [4470/4518] 98% | Training loss: 0.6870873606311662
Epoch: 17 | Iteration number: [4480/4518] 99% | Training loss: 0.6870856424128371
Epoch: 17 | Iteration number: [4490/4518] 99% | Training loss: 0.6870853291853499
Epoch: 17 | Iteration number: [4500/4518] 99% | Training loss: 0.6870826370716095
Epoch: 17 | Iteration number: [4510/4518] 99% | Training loss: 0.6870789206477332

 End of epoch: 17 | Train Loss: 0.6869249669731904 | Training Time: 642 

 End of epoch: 17 | Eval Loss: 0.690424556634864 | Evaluating Time: 17 
Epoch: 18 | Iteration number: [10/4518] 0% | Training loss: 0.7561897933483124
Epoch: 18 | Iteration number: [20/4518] 0% | Training loss: 0.7210596621036529
Epoch: 18 | Iteration number: [30/4518] 0% | Training loss: 0.7096219797929127
Epoch: 18 | Iteration number: [40/4518] 0% | Training loss: 0.703735962510109
Epoch: 18 | Iteration number: [50/4518] 1% | Training loss: 0.7001701760292053
Epoch: 18 | Iteration number: [60/4518] 1% | Training loss: 0.6979625443617503
Epoch: 18 | Iteration number: [70/4518] 1% | Training loss: 0.6965528053896768
Epoch: 18 | Iteration number: [80/4518] 1% | Training loss: 0.695362976193428
Epoch: 18 | Iteration number: [90/4518] 1% | Training loss: 0.6944745282332102
Epoch: 18 | Iteration number: [100/4518] 2% | Training loss: 0.6936193299293518
Epoch: 18 | Iteration number: [110/4518] 2% | Training loss: 0.6930632217363878
Epoch: 18 | Iteration number: [120/4518] 2% | Training loss: 0.6926472008228302
Epoch: 18 | Iteration number: [130/4518] 2% | Training loss: 0.6921891120763926
Epoch: 18 | Iteration number: [140/4518] 3% | Training loss: 0.691838784302984
Epoch: 18 | Iteration number: [150/4518] 3% | Training loss: 0.6915256524085999
Epoch: 18 | Iteration number: [160/4518] 3% | Training loss: 0.6912819366902113
Epoch: 18 | Iteration number: [170/4518] 3% | Training loss: 0.6909990429878234
Epoch: 18 | Iteration number: [180/4518] 3% | Training loss: 0.6907719986306297
Epoch: 18 | Iteration number: [190/4518] 4% | Training loss: 0.6904839170606513
Epoch: 18 | Iteration number: [200/4518] 4% | Training loss: 0.6903470757603646
Epoch: 18 | Iteration number: [210/4518] 4% | Training loss: 0.6901816274438586
Epoch: 18 | Iteration number: [220/4518] 4% | Training loss: 0.6900846020741896
Epoch: 18 | Iteration number: [230/4518] 5% | Training loss: 0.6899903022724649
Epoch: 18 | Iteration number: [240/4518] 5% | Training loss: 0.6898085561891397
Epoch: 18 | Iteration number: [250/4518] 5% | Training loss: 0.6896636252403259
Epoch: 18 | Iteration number: [260/4518] 5% | Training loss: 0.6895219229734861
Epoch: 18 | Iteration number: [270/4518] 5% | Training loss: 0.6894407980971866
Epoch: 18 | Iteration number: [280/4518] 6% | Training loss: 0.689338917178767
Epoch: 18 | Iteration number: [290/4518] 6% | Training loss: 0.6892798888272252
Epoch: 18 | Iteration number: [300/4518] 6% | Training loss: 0.6892014267047246
Epoch: 18 | Iteration number: [310/4518] 6% | Training loss: 0.689147453154287
Epoch: 18 | Iteration number: [320/4518] 7% | Training loss: 0.689077696017921
Epoch: 18 | Iteration number: [330/4518] 7% | Training loss: 0.688965791463852
Epoch: 18 | Iteration number: [340/4518] 7% | Training loss: 0.6888948102207745
Epoch: 18 | Iteration number: [350/4518] 7% | Training loss: 0.6888193123681204
Epoch: 18 | Iteration number: [360/4518] 7% | Training loss: 0.6888094358974033
Epoch: 18 | Iteration number: [370/4518] 8% | Training loss: 0.6887960424294343
Epoch: 18 | Iteration number: [380/4518] 8% | Training loss: 0.6887401899224833
Epoch: 18 | Iteration number: [390/4518] 8% | Training loss: 0.6886766930421193
Epoch: 18 | Iteration number: [400/4518] 8% | Training loss: 0.6886341235041619
Epoch: 18 | Iteration number: [410/4518] 9% | Training loss: 0.6885872650437239
Epoch: 18 | Iteration number: [420/4518] 9% | Training loss: 0.6885717528206962
Epoch: 18 | Iteration number: [430/4518] 9% | Training loss: 0.6885250092938889
Epoch: 18 | Iteration number: [440/4518] 9% | Training loss: 0.6884640258821574
Epoch: 18 | Iteration number: [450/4518] 9% | Training loss: 0.6884591309229533
Epoch: 18 | Iteration number: [460/4518] 10% | Training loss: 0.6884213565484337
Epoch: 18 | Iteration number: [470/4518] 10% | Training loss: 0.6883817766575103
Epoch: 18 | Iteration number: [480/4518] 10% | Training loss: 0.6883411560207605
Epoch: 18 | Iteration number: [490/4518] 10% | Training loss: 0.6883101430474495
Epoch: 18 | Iteration number: [500/4518] 11% | Training loss: 0.68829416513443
Epoch: 18 | Iteration number: [510/4518] 11% | Training loss: 0.688239038808673
Epoch: 18 | Iteration number: [520/4518] 11% | Training loss: 0.6881998513753598
Epoch: 18 | Iteration number: [530/4518] 11% | Training loss: 0.6881706451469998
Epoch: 18 | Iteration number: [540/4518] 11% | Training loss: 0.6881570877852263
Epoch: 18 | Iteration number: [550/4518] 12% | Training loss: 0.6881147920001637
Epoch: 18 | Iteration number: [560/4518] 12% | Training loss: 0.6880758896470069
Epoch: 18 | Iteration number: [570/4518] 12% | Training loss: 0.6880656202634176
Epoch: 18 | Iteration number: [580/4518] 12% | Training loss: 0.6880421028054994
Epoch: 18 | Iteration number: [590/4518] 13% | Training loss: 0.6880178388902697
Epoch: 18 | Iteration number: [600/4518] 13% | Training loss: 0.6879945309956869
Epoch: 18 | Iteration number: [610/4518] 13% | Training loss: 0.6879748957078965
Epoch: 18 | Iteration number: [620/4518] 13% | Training loss: 0.6879647510667001
Epoch: 18 | Iteration number: [630/4518] 13% | Training loss: 0.6879308155604771
Epoch: 18 | Iteration number: [640/4518] 14% | Training loss: 0.6878954702988267
Epoch: 18 | Iteration number: [650/4518] 14% | Training loss: 0.6878955221176147
Epoch: 18 | Iteration number: [660/4518] 14% | Training loss: 0.6878846801591642
Epoch: 18 | Iteration number: [670/4518] 14% | Training loss: 0.6878662328221905
Epoch: 18 | Iteration number: [680/4518] 15% | Training loss: 0.6878539562225342
Epoch: 18 | Iteration number: [690/4518] 15% | Training loss: 0.6878175398577815
Epoch: 18 | Iteration number: [700/4518] 15% | Training loss: 0.6878000112090792
Epoch: 18 | Iteration number: [710/4518] 15% | Training loss: 0.6877801027935995
Epoch: 18 | Iteration number: [720/4518] 15% | Training loss: 0.6877602014276717
Epoch: 18 | Iteration number: [730/4518] 16% | Training loss: 0.6877405518538331
Epoch: 18 | Iteration number: [740/4518] 16% | Training loss: 0.687720451644949
Epoch: 18 | Iteration number: [750/4518] 16% | Training loss: 0.6877040215333303
Epoch: 18 | Iteration number: [760/4518] 16% | Training loss: 0.6877028157052241
Epoch: 18 | Iteration number: [770/4518] 17% | Training loss: 0.6876886987066888
Epoch: 18 | Iteration number: [780/4518] 17% | Training loss: 0.6876884284691933
Epoch: 18 | Iteration number: [790/4518] 17% | Training loss: 0.6876833567136451
Epoch: 18 | Iteration number: [800/4518] 17% | Training loss: 0.6876544149965048
Epoch: 18 | Iteration number: [810/4518] 17% | Training loss: 0.6876400921815707
Epoch: 18 | Iteration number: [820/4518] 18% | Training loss: 0.6876359204693538
Epoch: 18 | Iteration number: [830/4518] 18% | Training loss: 0.6876116595354425
Epoch: 18 | Iteration number: [840/4518] 18% | Training loss: 0.6876112145327387
Epoch: 18 | Iteration number: [850/4518] 18% | Training loss: 0.6875964485196506
Epoch: 18 | Iteration number: [860/4518] 19% | Training loss: 0.6875911919876586
Epoch: 18 | Iteration number: [870/4518] 19% | Training loss: 0.6875831712936533
Epoch: 18 | Iteration number: [880/4518] 19% | Training loss: 0.6875697172500871
Epoch: 18 | Iteration number: [890/4518] 19% | Training loss: 0.687566986378659
Epoch: 18 | Iteration number: [900/4518] 19% | Training loss: 0.687561465104421
Epoch: 18 | Iteration number: [910/4518] 20% | Training loss: 0.6875505681876298
Epoch: 18 | Iteration number: [920/4518] 20% | Training loss: 0.6875438373373902
Epoch: 18 | Iteration number: [930/4518] 20% | Training loss: 0.6875431528655431
Epoch: 18 | Iteration number: [940/4518] 20% | Training loss: 0.6875367797435599
Epoch: 18 | Iteration number: [950/4518] 21% | Training loss: 0.6875463629396338
Epoch: 18 | Iteration number: [960/4518] 21% | Training loss: 0.6875231808672349
Epoch: 18 | Iteration number: [970/4518] 21% | Training loss: 0.6875111174337643
Epoch: 18 | Iteration number: [980/4518] 21% | Training loss: 0.6875045553762086
Epoch: 18 | Iteration number: [990/4518] 21% | Training loss: 0.6874942621197363
Epoch: 18 | Iteration number: [1000/4518] 22% | Training loss: 0.6874850741028786
Epoch: 18 | Iteration number: [1010/4518] 22% | Training loss: 0.6874818620115224
Epoch: 18 | Iteration number: [1020/4518] 22% | Training loss: 0.6874759407020082
Epoch: 18 | Iteration number: [1030/4518] 22% | Training loss: 0.6874714185311956
Epoch: 18 | Iteration number: [1040/4518] 23% | Training loss: 0.6874682527895157
Epoch: 18 | Iteration number: [1050/4518] 23% | Training loss: 0.6874718160856338
Epoch: 18 | Iteration number: [1060/4518] 23% | Training loss: 0.6874811471070883
Epoch: 18 | Iteration number: [1070/4518] 23% | Training loss: 0.6874722808877999
Epoch: 18 | Iteration number: [1080/4518] 23% | Training loss: 0.687464651355037
Epoch: 18 | Iteration number: [1090/4518] 24% | Training loss: 0.6874743424424338
Epoch: 18 | Iteration number: [1100/4518] 24% | Training loss: 0.6874731503833424
Epoch: 18 | Iteration number: [1110/4518] 24% | Training loss: 0.6874563060365282
Epoch: 18 | Iteration number: [1120/4518] 24% | Training loss: 0.6874595226453883
Epoch: 18 | Iteration number: [1130/4518] 25% | Training loss: 0.6874565983768058
Epoch: 18 | Iteration number: [1140/4518] 25% | Training loss: 0.6874374385465656
Epoch: 18 | Iteration number: [1150/4518] 25% | Training loss: 0.6874287758184516
Epoch: 18 | Iteration number: [1160/4518] 25% | Training loss: 0.6874276492102392
Epoch: 18 | Iteration number: [1170/4518] 25% | Training loss: 0.6874170934542632
Epoch: 18 | Iteration number: [1180/4518] 26% | Training loss: 0.6874076871043545
Epoch: 18 | Iteration number: [1190/4518] 26% | Training loss: 0.6873986681469348
Epoch: 18 | Iteration number: [1200/4518] 26% | Training loss: 0.6874028526246547
Epoch: 18 | Iteration number: [1210/4518] 26% | Training loss: 0.6873989253497321
Epoch: 18 | Iteration number: [1220/4518] 27% | Training loss: 0.6873928730116516
Epoch: 18 | Iteration number: [1230/4518] 27% | Training loss: 0.6873867483643012
Epoch: 18 | Iteration number: [1240/4518] 27% | Training loss: 0.6873903787424488
Epoch: 18 | Iteration number: [1250/4518] 27% | Training loss: 0.6873837864398956
Epoch: 18 | Iteration number: [1260/4518] 27% | Training loss: 0.6873722642187088
Epoch: 18 | Iteration number: [1270/4518] 28% | Training loss: 0.6873698748472169
Epoch: 18 | Iteration number: [1280/4518] 28% | Training loss: 0.6873655531089753
Epoch: 18 | Iteration number: [1290/4518] 28% | Training loss: 0.6873704287432885
Epoch: 18 | Iteration number: [1300/4518] 28% | Training loss: 0.6873564235980694
Epoch: 18 | Iteration number: [1310/4518] 28% | Training loss: 0.6873486580739494
Epoch: 18 | Iteration number: [1320/4518] 29% | Training loss: 0.68732767719211
Epoch: 18 | Iteration number: [1330/4518] 29% | Training loss: 0.6873092629855737
Epoch: 18 | Iteration number: [1340/4518] 29% | Training loss: 0.6873039000069917
Epoch: 18 | Iteration number: [1350/4518] 29% | Training loss: 0.687292703655031
Epoch: 18 | Iteration number: [1360/4518] 30% | Training loss: 0.6872902482309762
Epoch: 18 | Iteration number: [1370/4518] 30% | Training loss: 0.6872961980583023
Epoch: 18 | Iteration number: [1380/4518] 30% | Training loss: 0.6872907027386237
Epoch: 18 | Iteration number: [1390/4518] 30% | Training loss: 0.6872849653950698
Epoch: 18 | Iteration number: [1400/4518] 30% | Training loss: 0.6872807205574853
Epoch: 18 | Iteration number: [1410/4518] 31% | Training loss: 0.687279960196069
Epoch: 18 | Iteration number: [1420/4518] 31% | Training loss: 0.6872793007484624
Epoch: 18 | Iteration number: [1430/4518] 31% | Training loss: 0.6872671771716404
Epoch: 18 | Iteration number: [1440/4518] 31% | Training loss: 0.687272885772917
Epoch: 18 | Iteration number: [1450/4518] 32% | Training loss: 0.6872692148438816
Epoch: 18 | Iteration number: [1460/4518] 32% | Training loss: 0.6872762363659193
Epoch: 18 | Iteration number: [1470/4518] 32% | Training loss: 0.6872731139465255
Epoch: 18 | Iteration number: [1480/4518] 32% | Training loss: 0.6872688035707216
Epoch: 18 | Iteration number: [1490/4518] 32% | Training loss: 0.687270081243259
Epoch: 18 | Iteration number: [1500/4518] 33% | Training loss: 0.6872688759565353
Epoch: 18 | Iteration number: [1510/4518] 33% | Training loss: 0.6872721541401566
Epoch: 18 | Iteration number: [1520/4518] 33% | Training loss: 0.6872689174194085
Epoch: 18 | Iteration number: [1530/4518] 33% | Training loss: 0.6872664481206657
Epoch: 18 | Iteration number: [1540/4518] 34% | Training loss: 0.6872634575738535
Epoch: 18 | Iteration number: [1550/4518] 34% | Training loss: 0.6872633983627442
Epoch: 18 | Iteration number: [1560/4518] 34% | Training loss: 0.6872592203128032
Epoch: 18 | Iteration number: [1570/4518] 34% | Training loss: 0.6872514539843152
Epoch: 18 | Iteration number: [1580/4518] 34% | Training loss: 0.6872505433197262
Epoch: 18 | Iteration number: [1590/4518] 35% | Training loss: 0.6872488501311848
Epoch: 18 | Iteration number: [1600/4518] 35% | Training loss: 0.6872500380873681
Epoch: 18 | Iteration number: [1610/4518] 35% | Training loss: 0.6872509505067553
Epoch: 18 | Iteration number: [1620/4518] 35% | Training loss: 0.6872520876519475
Epoch: 18 | Iteration number: [1630/4518] 36% | Training loss: 0.6872528949763878
Epoch: 18 | Iteration number: [1640/4518] 36% | Training loss: 0.6872499328924389
Epoch: 18 | Iteration number: [1650/4518] 36% | Training loss: 0.6872517907619476
Epoch: 18 | Iteration number: [1660/4518] 36% | Training loss: 0.6872513766389295
Epoch: 18 | Iteration number: [1670/4518] 36% | Training loss: 0.6872472326555652
Epoch: 18 | Iteration number: [1680/4518] 37% | Training loss: 0.687242967777309
Epoch: 18 | Iteration number: [1690/4518] 37% | Training loss: 0.6872450782349829
Epoch: 18 | Iteration number: [1700/4518] 37% | Training loss: 0.6872463653718724
Epoch: 18 | Iteration number: [1710/4518] 37% | Training loss: 0.687242381405412
Epoch: 18 | Iteration number: [1720/4518] 38% | Training loss: 0.6872288115495859
Epoch: 18 | Iteration number: [1730/4518] 38% | Training loss: 0.6872265990069836
Epoch: 18 | Iteration number: [1740/4518] 38% | Training loss: 0.6872289292428685
Epoch: 18 | Iteration number: [1750/4518] 38% | Training loss: 0.6872286025796618
Epoch: 18 | Iteration number: [1760/4518] 38% | Training loss: 0.6872287624600258
Epoch: 18 | Iteration number: [1770/4518] 39% | Training loss: 0.687227326025397
Epoch: 18 | Iteration number: [1780/4518] 39% | Training loss: 0.6872261896896898
Epoch: 18 | Iteration number: [1790/4518] 39% | Training loss: 0.68721952754692
Epoch: 18 | Iteration number: [1800/4518] 39% | Training loss: 0.6872154068284565
Epoch: 18 | Iteration number: [1810/4518] 40% | Training loss: 0.6872173999225237
Epoch: 18 | Iteration number: [1820/4518] 40% | Training loss: 0.6872170216762102
Epoch: 18 | Iteration number: [1830/4518] 40% | Training loss: 0.6872175469424555
Epoch: 18 | Iteration number: [1840/4518] 40% | Training loss: 0.687213289251794
Epoch: 18 | Iteration number: [1850/4518] 40% | Training loss: 0.6872090673124468
Epoch: 18 | Iteration number: [1860/4518] 41% | Training loss: 0.6872089169999605
Epoch: 18 | Iteration number: [1870/4518] 41% | Training loss: 0.6872091577014822
Epoch: 18 | Iteration number: [1880/4518] 41% | Training loss: 0.6872077810320448
Epoch: 18 | Iteration number: [1890/4518] 41% | Training loss: 0.6872074815331313
Epoch: 18 | Iteration number: [1900/4518] 42% | Training loss: 0.6871954478715595
Epoch: 18 | Iteration number: [1910/4518] 42% | Training loss: 0.6871905061274923
Epoch: 18 | Iteration number: [1920/4518] 42% | Training loss: 0.6871866021305323
Epoch: 18 | Iteration number: [1930/4518] 42% | Training loss: 0.6871882703946662
Epoch: 18 | Iteration number: [1940/4518] 42% | Training loss: 0.6871844120246848
Epoch: 18 | Iteration number: [1950/4518] 43% | Training loss: 0.6871888237427443
Epoch: 18 | Iteration number: [1960/4518] 43% | Training loss: 0.687191974843035
Epoch: 18 | Iteration number: [1970/4518] 43% | Training loss: 0.6871907249622539
Epoch: 18 | Iteration number: [1980/4518] 43% | Training loss: 0.687188057827227
Epoch: 18 | Iteration number: [1990/4518] 44% | Training loss: 0.6871807927462323
Epoch: 18 | Iteration number: [2000/4518] 44% | Training loss: 0.6871684032678604
Epoch: 18 | Iteration number: [2010/4518] 44% | Training loss: 0.687164850495941
Epoch: 18 | Iteration number: [2020/4518] 44% | Training loss: 0.6871614087336134
Epoch: 18 | Iteration number: [2030/4518] 44% | Training loss: 0.6871642366418698
Epoch: 18 | Iteration number: [2040/4518] 45% | Training loss: 0.6871629557480999
Epoch: 18 | Iteration number: [2050/4518] 45% | Training loss: 0.6871654721294961
Epoch: 18 | Iteration number: [2060/4518] 45% | Training loss: 0.687161244871547
Epoch: 18 | Iteration number: [2070/4518] 45% | Training loss: 0.687156667859082
Epoch: 18 | Iteration number: [2080/4518] 46% | Training loss: 0.6871621393813536
Epoch: 18 | Iteration number: [2090/4518] 46% | Training loss: 0.687159387517774
Epoch: 18 | Iteration number: [2100/4518] 46% | Training loss: 0.6871611409811746
Epoch: 18 | Iteration number: [2110/4518] 46% | Training loss: 0.6871658971806838
Epoch: 18 | Iteration number: [2120/4518] 46% | Training loss: 0.6871636600145754
Epoch: 18 | Iteration number: [2130/4518] 47% | Training loss: 0.6871628508601391
Epoch: 18 | Iteration number: [2140/4518] 47% | Training loss: 0.6871611566465592
Epoch: 18 | Iteration number: [2150/4518] 47% | Training loss: 0.6871595280392225
Epoch: 18 | Iteration number: [2160/4518] 47% | Training loss: 0.6871537754657092
Epoch: 18 | Iteration number: [2170/4518] 48% | Training loss: 0.6871531759538958
Epoch: 18 | Iteration number: [2180/4518] 48% | Training loss: 0.687154460937605
Epoch: 18 | Iteration number: [2190/4518] 48% | Training loss: 0.6871573026593961
Epoch: 18 | Iteration number: [2200/4518] 48% | Training loss: 0.6871571395343
Epoch: 18 | Iteration number: [2210/4518] 48% | Training loss: 0.6871591633531303
Epoch: 18 | Iteration number: [2220/4518] 49% | Training loss: 0.6871552787385545
Epoch: 18 | Iteration number: [2230/4518] 49% | Training loss: 0.6871557540423132
Epoch: 18 | Iteration number: [2240/4518] 49% | Training loss: 0.6871592710326825
Epoch: 18 | Iteration number: [2250/4518] 49% | Training loss: 0.6871580281787448
Epoch: 18 | Iteration number: [2260/4518] 50% | Training loss: 0.6871605857547406
Epoch: 18 | Iteration number: [2270/4518] 50% | Training loss: 0.6871619904618956
Epoch: 18 | Iteration number: [2280/4518] 50% | Training loss: 0.6871586230763218
Epoch: 18 | Iteration number: [2290/4518] 50% | Training loss: 0.6871630245681413
Epoch: 18 | Iteration number: [2300/4518] 50% | Training loss: 0.6871674563573754
Epoch: 18 | Iteration number: [2310/4518] 51% | Training loss: 0.6871681819230447
Epoch: 18 | Iteration number: [2320/4518] 51% | Training loss: 0.687169270422952
Epoch: 18 | Iteration number: [2330/4518] 51% | Training loss: 0.687168792286656
Epoch: 18 | Iteration number: [2340/4518] 51% | Training loss: 0.6871689012926868
Epoch: 18 | Iteration number: [2350/4518] 52% | Training loss: 0.6871681191058869
Epoch: 18 | Iteration number: [2360/4518] 52% | Training loss: 0.6871631101531498
Epoch: 18 | Iteration number: [2370/4518] 52% | Training loss: 0.6871606813201422
Epoch: 18 | Iteration number: [2380/4518] 52% | Training loss: 0.6871629405923251
Epoch: 18 | Iteration number: [2390/4518] 52% | Training loss: 0.6871599437053234
Epoch: 18 | Iteration number: [2400/4518] 53% | Training loss: 0.6871588813016812
Epoch: 18 | Iteration number: [2410/4518] 53% | Training loss: 0.6871608878814334
Epoch: 18 | Iteration number: [2420/4518] 53% | Training loss: 0.6871572012251074
Epoch: 18 | Iteration number: [2430/4518] 53% | Training loss: 0.6871562162789788
Epoch: 18 | Iteration number: [2440/4518] 54% | Training loss: 0.6871560155368243
Epoch: 18 | Iteration number: [2450/4518] 54% | Training loss: 0.6871598267068668
Epoch: 18 | Iteration number: [2460/4518] 54% | Training loss: 0.6871621302957457
Epoch: 18 | Iteration number: [2470/4518] 54% | Training loss: 0.68716530232777
Epoch: 18 | Iteration number: [2480/4518] 54% | Training loss: 0.687162486992536
Epoch: 18 | Iteration number: [2490/4518] 55% | Training loss: 0.6871577257372768
Epoch: 18 | Iteration number: [2500/4518] 55% | Training loss: 0.6871521390914918
Epoch: 18 | Iteration number: [2510/4518] 55% | Training loss: 0.6871491856546516
Epoch: 18 | Iteration number: [2520/4518] 55% | Training loss: 0.6871503356193739
Epoch: 18 | Iteration number: [2530/4518] 55% | Training loss: 0.6871436354671071
Epoch: 18 | Iteration number: [2540/4518] 56% | Training loss: 0.6871461089905792
Epoch: 18 | Iteration number: [2550/4518] 56% | Training loss: 0.6871471759618497
Epoch: 18 | Iteration number: [2560/4518] 56% | Training loss: 0.6871498520020396
Epoch: 18 | Iteration number: [2570/4518] 56% | Training loss: 0.6871493357396775
Epoch: 18 | Iteration number: [2580/4518] 57% | Training loss: 0.6871471835661304
Epoch: 18 | Iteration number: [2590/4518] 57% | Training loss: 0.687148585788992
Epoch: 18 | Iteration number: [2600/4518] 57% | Training loss: 0.6871517759103042
Epoch: 18 | Iteration number: [2610/4518] 57% | Training loss: 0.6871479092429881
Epoch: 18 | Iteration number: [2620/4518] 57% | Training loss: 0.6871489297570164
Epoch: 18 | Iteration number: [2630/4518] 58% | Training loss: 0.6871493054433467
Epoch: 18 | Iteration number: [2640/4518] 58% | Training loss: 0.6871489122509956
Epoch: 18 | Iteration number: [2650/4518] 58% | Training loss: 0.6871441992723717
Epoch: 18 | Iteration number: [2660/4518] 58% | Training loss: 0.68714024623982
Epoch: 18 | Iteration number: [2670/4518] 59% | Training loss: 0.6871402205599382
Epoch: 18 | Iteration number: [2680/4518] 59% | Training loss: 0.6871415649777028
Epoch: 18 | Iteration number: [2690/4518] 59% | Training loss: 0.6871437800861203
Epoch: 18 | Iteration number: [2700/4518] 59% | Training loss: 0.6871446549892426
Epoch: 18 | Iteration number: [2710/4518] 59% | Training loss: 0.6871445731263319
Epoch: 18 | Iteration number: [2720/4518] 60% | Training loss: 0.687146173220347
Epoch: 18 | Iteration number: [2730/4518] 60% | Training loss: 0.6871463955322028
Epoch: 18 | Iteration number: [2740/4518] 60% | Training loss: 0.6871480529978328
Epoch: 18 | Iteration number: [2750/4518] 60% | Training loss: 0.6871469661322507
Epoch: 18 | Iteration number: [2760/4518] 61% | Training loss: 0.6871417653301488
Epoch: 18 | Iteration number: [2770/4518] 61% | Training loss: 0.6871396940752917
Epoch: 18 | Iteration number: [2780/4518] 61% | Training loss: 0.6871398766263783
Epoch: 18 | Iteration number: [2790/4518] 61% | Training loss: 0.6871379811490308
Epoch: 18 | Iteration number: [2800/4518] 61% | Training loss: 0.6871402744948863
Epoch: 18 | Iteration number: [2810/4518] 62% | Training loss: 0.6871392198304689
Epoch: 18 | Iteration number: [2820/4518] 62% | Training loss: 0.6871398922822154
Epoch: 18 | Iteration number: [2830/4518] 62% | Training loss: 0.6871398476745552
Epoch: 18 | Iteration number: [2840/4518] 62% | Training loss: 0.6871393836719889
Epoch: 18 | Iteration number: [2850/4518] 63% | Training loss: 0.6871372647661912
Epoch: 18 | Iteration number: [2860/4518] 63% | Training loss: 0.6871378480554461
Epoch: 18 | Iteration number: [2870/4518] 63% | Training loss: 0.6871392505094149
Epoch: 18 | Iteration number: [2880/4518] 63% | Training loss: 0.6871383071359661
Epoch: 18 | Iteration number: [2890/4518] 63% | Training loss: 0.6871363938679744
Epoch: 18 | Iteration number: [2900/4518] 64% | Training loss: 0.6871329241374443
Epoch: 18 | Iteration number: [2910/4518] 64% | Training loss: 0.6871307599995145
Epoch: 18 | Iteration number: [2920/4518] 64% | Training loss: 0.6871303920059988
Epoch: 18 | Iteration number: [2930/4518] 64% | Training loss: 0.68713349417208
Epoch: 18 | Iteration number: [2940/4518] 65% | Training loss: 0.6871319789464782
Epoch: 18 | Iteration number: [2950/4518] 65% | Training loss: 0.6871272084672573
Epoch: 18 | Iteration number: [2960/4518] 65% | Training loss: 0.6871282989712986
Epoch: 18 | Iteration number: [2970/4518] 65% | Training loss: 0.6871344453156597
Epoch: 18 | Iteration number: [2980/4518] 65% | Training loss: 0.6871324911213561
Epoch: 18 | Iteration number: [2990/4518] 66% | Training loss: 0.6871296035406183
Epoch: 18 | Iteration number: [3000/4518] 66% | Training loss: 0.687131498714288
Epoch: 18 | Iteration number: [3010/4518] 66% | Training loss: 0.6871309872877558
Epoch: 18 | Iteration number: [3020/4518] 66% | Training loss: 0.6871258327503078
Epoch: 18 | Iteration number: [3030/4518] 67% | Training loss: 0.6871288443949356
Epoch: 18 | Iteration number: [3040/4518] 67% | Training loss: 0.6871337301244861
Epoch: 18 | Iteration number: [3050/4518] 67% | Training loss: 0.6871305433453107
Epoch: 18 | Iteration number: [3060/4518] 67% | Training loss: 0.6871307295911452
Epoch: 18 | Iteration number: [3070/4518] 67% | Training loss: 0.6871303958690904
Epoch: 18 | Iteration number: [3080/4518] 68% | Training loss: 0.6871293825762612
Epoch: 18 | Iteration number: [3090/4518] 68% | Training loss: 0.6871325107646992
Epoch: 18 | Iteration number: [3100/4518] 68% | Training loss: 0.6871303692363924
Epoch: 18 | Iteration number: [3110/4518] 68% | Training loss: 0.6871300289101923
Epoch: 18 | Iteration number: [3120/4518] 69% | Training loss: 0.6871275686682798
Epoch: 18 | Iteration number: [3130/4518] 69% | Training loss: 0.687128703986494
Epoch: 18 | Iteration number: [3140/4518] 69% | Training loss: 0.6871280662573067
Epoch: 18 | Iteration number: [3150/4518] 69% | Training loss: 0.6871260624272483
Epoch: 18 | Iteration number: [3160/4518] 69% | Training loss: 0.6871260598867754
Epoch: 18 | Iteration number: [3170/4518] 70% | Training loss: 0.6871272356916301
Epoch: 18 | Iteration number: [3180/4518] 70% | Training loss: 0.6871256069942091
Epoch: 18 | Iteration number: [3190/4518] 70% | Training loss: 0.6871249439574334
Epoch: 18 | Iteration number: [3200/4518] 70% | Training loss: 0.6871215280331672
Epoch: 18 | Iteration number: [3210/4518] 71% | Training loss: 0.6871231721569073
Epoch: 18 | Iteration number: [3220/4518] 71% | Training loss: 0.6871245493614896
Epoch: 18 | Iteration number: [3230/4518] 71% | Training loss: 0.687121086888269
Epoch: 18 | Iteration number: [3240/4518] 71% | Training loss: 0.6871222170782678
Epoch: 18 | Iteration number: [3250/4518] 71% | Training loss: 0.6871188999322745
Epoch: 18 | Iteration number: [3260/4518] 72% | Training loss: 0.6871173075920234
Epoch: 18 | Iteration number: [3270/4518] 72% | Training loss: 0.6871173656679439
Epoch: 18 | Iteration number: [3280/4518] 72% | Training loss: 0.68711477977837
Epoch: 18 | Iteration number: [3290/4518] 72% | Training loss: 0.6871127458510066
Epoch: 18 | Iteration number: [3300/4518] 73% | Training loss: 0.6871117096236258
Epoch: 18 | Iteration number: [3310/4518] 73% | Training loss: 0.6871125432119629
Epoch: 18 | Iteration number: [3320/4518] 73% | Training loss: 0.6871107283845005
Epoch: 18 | Iteration number: [3330/4518] 73% | Training loss: 0.6871096475167318
Epoch: 18 | Iteration number: [3340/4518] 73% | Training loss: 0.687107245829291
Epoch: 18 | Iteration number: [3350/4518] 74% | Training loss: 0.6871074133844518
Epoch: 18 | Iteration number: [3360/4518] 74% | Training loss: 0.687106266582296
Epoch: 18 | Iteration number: [3370/4518] 74% | Training loss: 0.687108404664682
Epoch: 18 | Iteration number: [3380/4518] 74% | Training loss: 0.6871080499252624
Epoch: 18 | Iteration number: [3390/4518] 75% | Training loss: 0.6871069509019542
Epoch: 18 | Iteration number: [3400/4518] 75% | Training loss: 0.6871062198281288
Epoch: 18 | Iteration number: [3410/4518] 75% | Training loss: 0.6871045086390811
Epoch: 18 | Iteration number: [3420/4518] 75% | Training loss: 0.6871061570463125
Epoch: 18 | Iteration number: [3430/4518] 75% | Training loss: 0.6871049387114389
Epoch: 18 | Iteration number: [3440/4518] 76% | Training loss: 0.6871035292571367
Epoch: 18 | Iteration number: [3450/4518] 76% | Training loss: 0.6871004171993421
Epoch: 18 | Iteration number: [3460/4518] 76% | Training loss: 0.6870979358350611
Epoch: 18 | Iteration number: [3470/4518] 76% | Training loss: 0.6870956950812931
Epoch: 18 | Iteration number: [3480/4518] 77% | Training loss: 0.6870954972916636
Epoch: 18 | Iteration number: [3490/4518] 77% | Training loss: 0.6870994892195508
Epoch: 18 | Iteration number: [3500/4518] 77% | Training loss: 0.6871008955751147
Epoch: 18 | Iteration number: [3510/4518] 77% | Training loss: 0.6871009131782075
Epoch: 18 | Iteration number: [3520/4518] 77% | Training loss: 0.6870979642495513
Epoch: 18 | Iteration number: [3530/4518] 78% | Training loss: 0.6870994214126814
Epoch: 18 | Iteration number: [3540/4518] 78% | Training loss: 0.6870992743026065
Epoch: 18 | Iteration number: [3550/4518] 78% | Training loss: 0.6871011462010128
Epoch: 18 | Iteration number: [3560/4518] 78% | Training loss: 0.6871032135205323
Epoch: 18 | Iteration number: [3570/4518] 79% | Training loss: 0.6871049751921529
Epoch: 18 | Iteration number: [3580/4518] 79% | Training loss: 0.6871023328943625
Epoch: 18 | Iteration number: [3590/4518] 79% | Training loss: 0.6870998717616196
Epoch: 18 | Iteration number: [3600/4518] 79% | Training loss: 0.6870985252989663
Epoch: 18 | Iteration number: [3610/4518] 79% | Training loss: 0.687098853905115
Epoch: 18 | Iteration number: [3620/4518] 80% | Training loss: 0.6871024454825491
Epoch: 18 | Iteration number: [3630/4518] 80% | Training loss: 0.687101085668753
Epoch: 18 | Iteration number: [3640/4518] 80% | Training loss: 0.6871007293954
Epoch: 18 | Iteration number: [3650/4518] 80% | Training loss: 0.687101575675076
Epoch: 18 | Iteration number: [3660/4518] 81% | Training loss: 0.6871029177324368
Epoch: 18 | Iteration number: [3670/4518] 81% | Training loss: 0.6871036556825976
Epoch: 18 | Iteration number: [3680/4518] 81% | Training loss: 0.6871026933517145
Epoch: 18 | Iteration number: [3690/4518] 81% | Training loss: 0.687102369128204
Epoch: 18 | Iteration number: [3700/4518] 81% | Training loss: 0.6871027917153126
Epoch: 18 | Iteration number: [3710/4518] 82% | Training loss: 0.6871010174969778
Epoch: 18 | Iteration number: [3720/4518] 82% | Training loss: 0.6871008477704499
Epoch: 18 | Iteration number: [3730/4518] 82% | Training loss: 0.6871016542329865
Epoch: 18 | Iteration number: [3740/4518] 82% | Training loss: 0.6871022444676588
Epoch: 18 | Iteration number: [3750/4518] 83% | Training loss: 0.6870980161190033
Epoch: 18 | Iteration number: [3760/4518] 83% | Training loss: 0.6870958824582556
Epoch: 18 | Iteration number: [3770/4518] 83% | Training loss: 0.6870963912111379
Epoch: 18 | Iteration number: [3780/4518] 83% | Training loss: 0.6870979563742088
Epoch: 18 | Iteration number: [3790/4518] 83% | Training loss: 0.6870992334820035
Epoch: 18 | Iteration number: [3800/4518] 84% | Training loss: 0.6871037770415607
Epoch: 18 | Iteration number: [3810/4518] 84% | Training loss: 0.6871037207406963
Epoch: 18 | Iteration number: [3820/4518] 84% | Training loss: 0.6871025743752874
Epoch: 18 | Iteration number: [3830/4518] 84% | Training loss: 0.6871051733238579
Epoch: 18 | Iteration number: [3840/4518] 84% | Training loss: 0.6871048315893858
Epoch: 18 | Iteration number: [3850/4518] 85% | Training loss: 0.6871051416923474
Epoch: 18 | Iteration number: [3860/4518] 85% | Training loss: 0.6871074201529508
Epoch: 18 | Iteration number: [3870/4518] 85% | Training loss: 0.6871069182875237
Epoch: 18 | Iteration number: [3880/4518] 85% | Training loss: 0.6871078161081088
Epoch: 18 | Iteration number: [3890/4518] 86% | Training loss: 0.6871084935714162
Epoch: 18 | Iteration number: [3900/4518] 86% | Training loss: 0.6871066063336837
Epoch: 18 | Iteration number: [3910/4518] 86% | Training loss: 0.6871026070678935
Epoch: 18 | Iteration number: [3920/4518] 86% | Training loss: 0.6871032964970384
Epoch: 18 | Iteration number: [3930/4518] 86% | Training loss: 0.687104263150965
Epoch: 18 | Iteration number: [3940/4518] 87% | Training loss: 0.6871031592491315
Epoch: 18 | Iteration number: [3950/4518] 87% | Training loss: 0.6871046830732611
Epoch: 18 | Iteration number: [3960/4518] 87% | Training loss: 0.6871018130971928
Epoch: 18 | Iteration number: [3970/4518] 87% | Training loss: 0.6870972927931874
Epoch: 18 | Iteration number: [3980/4518] 88% | Training loss: 0.687098095075569
Epoch: 18 | Iteration number: [3990/4518] 88% | Training loss: 0.6870975496028001
Epoch: 18 | Iteration number: [4000/4518] 88% | Training loss: 0.6870951806604862
Epoch: 18 | Iteration number: [4010/4518] 88% | Training loss: 0.6870926170575054
Epoch: 18 | Iteration number: [4020/4518] 88% | Training loss: 0.6870885716890222
Epoch: 18 | Iteration number: [4030/4518] 89% | Training loss: 0.6870892953044427
Epoch: 18 | Iteration number: [4040/4518] 89% | Training loss: 0.6870879592281757
Epoch: 18 | Iteration number: [4050/4518] 89% | Training loss: 0.6870893871489866
Epoch: 18 | Iteration number: [4060/4518] 89% | Training loss: 0.6870867914900991
Epoch: 18 | Iteration number: [4070/4518] 90% | Training loss: 0.6870868699117141
Epoch: 18 | Iteration number: [4080/4518] 90% | Training loss: 0.6870869366561665
Epoch: 18 | Iteration number: [4090/4518] 90% | Training loss: 0.6870857886113864
Epoch: 18 | Iteration number: [4100/4518] 90% | Training loss: 0.6870859501419998
Epoch: 18 | Iteration number: [4110/4518] 90% | Training loss: 0.6870853879881021
Epoch: 18 | Iteration number: [4120/4518] 91% | Training loss: 0.6870855807100685
Epoch: 18 | Iteration number: [4130/4518] 91% | Training loss: 0.6870850484682919
Epoch: 18 | Iteration number: [4140/4518] 91% | Training loss: 0.6870843204179248
Epoch: 18 | Iteration number: [4150/4518] 91% | Training loss: 0.6870864643533546
Epoch: 18 | Iteration number: [4160/4518] 92% | Training loss: 0.6870883622421669
Epoch: 18 | Iteration number: [4170/4518] 92% | Training loss: 0.6870891467844553
Epoch: 18 | Iteration number: [4180/4518] 92% | Training loss: 0.6870909769426693
Epoch: 18 | Iteration number: [4190/4518] 92% | Training loss: 0.6870919504996416
Epoch: 18 | Iteration number: [4200/4518] 92% | Training loss: 0.6870913785270282
Epoch: 18 | Iteration number: [4210/4518] 93% | Training loss: 0.6870908174124013
Epoch: 18 | Iteration number: [4220/4518] 93% | Training loss: 0.6870939121144642
Epoch: 18 | Iteration number: [4230/4518] 93% | Training loss: 0.6870935954946152
Epoch: 18 | Iteration number: [4240/4518] 93% | Training loss: 0.6870929678937174
Epoch: 18 | Iteration number: [4250/4518] 94% | Training loss: 0.6870914057703579
Epoch: 18 | Iteration number: [4260/4518] 94% | Training loss: 0.6870913086222931
Epoch: 18 | Iteration number: [4270/4518] 94% | Training loss: 0.6870928608421978
Epoch: 18 | Iteration number: [4280/4518] 94% | Training loss: 0.6870910364751504
Epoch: 18 | Iteration number: [4290/4518] 94% | Training loss: 0.6870874600115912
Epoch: 18 | Iteration number: [4300/4518] 95% | Training loss: 0.6870835784424183
Epoch: 18 | Iteration number: [4310/4518] 95% | Training loss: 0.6870852708401647
Epoch: 18 | Iteration number: [4320/4518] 95% | Training loss: 0.6870837116131077
Epoch: 18 | Iteration number: [4330/4518] 95% | Training loss: 0.687084086029414
Epoch: 18 | Iteration number: [4340/4518] 96% | Training loss: 0.6870845503384068
Epoch: 18 | Iteration number: [4350/4518] 96% | Training loss: 0.6870835313303717
Epoch: 18 | Iteration number: [4360/4518] 96% | Training loss: 0.6870838835972165
Epoch: 18 | Iteration number: [4370/4518] 96% | Training loss: 0.6870810229663717
Epoch: 18 | Iteration number: [4380/4518] 96% | Training loss: 0.6870787007079276
Epoch: 18 | Iteration number: [4390/4518] 97% | Training loss: 0.6870746766380406
Epoch: 18 | Iteration number: [4400/4518] 97% | Training loss: 0.6870728127116507
Epoch: 18 | Iteration number: [4410/4518] 97% | Training loss: 0.6870738473473763
Epoch: 18 | Iteration number: [4420/4518] 97% | Training loss: 0.6870778459903881
Epoch: 18 | Iteration number: [4430/4518] 98% | Training loss: 0.6870771702336942
Epoch: 18 | Iteration number: [4440/4518] 98% | Training loss: 0.6870773607680389
Epoch: 18 | Iteration number: [4450/4518] 98% | Training loss: 0.6870763607373398
Epoch: 18 | Iteration number: [4460/4518] 98% | Training loss: 0.6870725769633135
Epoch: 18 | Iteration number: [4470/4518] 98% | Training loss: 0.6870709250704021
Epoch: 18 | Iteration number: [4480/4518] 99% | Training loss: 0.68706911288734
Epoch: 18 | Iteration number: [4490/4518] 99% | Training loss: 0.6870662962939001
Epoch: 18 | Iteration number: [4500/4518] 99% | Training loss: 0.6870667796532313
Epoch: 18 | Iteration number: [4510/4518] 99% | Training loss: 0.6870677757025294

 End of epoch: 18 | Train Loss: 0.6869162013041018 | Training Time: 640 

 End of epoch: 18 | Eval Loss: 0.6903097799846104 | Evaluating Time: 17 
Epoch: 19 | Iteration number: [10/4518] 0% | Training loss: 0.7560931086540222
Epoch: 19 | Iteration number: [20/4518] 0% | Training loss: 0.7210696518421174
Epoch: 19 | Iteration number: [30/4518] 0% | Training loss: 0.7097359657287597
Epoch: 19 | Iteration number: [40/4518] 0% | Training loss: 0.704102349281311
Epoch: 19 | Iteration number: [50/4518] 1% | Training loss: 0.700705258846283
Epoch: 19 | Iteration number: [60/4518] 1% | Training loss: 0.6984895805517832
Epoch: 19 | Iteration number: [70/4518] 1% | Training loss: 0.696984647001539
Epoch: 19 | Iteration number: [80/4518] 1% | Training loss: 0.6958374872803688
Epoch: 19 | Iteration number: [90/4518] 1% | Training loss: 0.6947868863741556
Epoch: 19 | Iteration number: [100/4518] 2% | Training loss: 0.6940331852436066
Epoch: 19 | Iteration number: [110/4518] 2% | Training loss: 0.693357567353682
Epoch: 19 | Iteration number: [120/4518] 2% | Training loss: 0.692848319808642
Epoch: 19 | Iteration number: [130/4518] 2% | Training loss: 0.692365161730693
Epoch: 19 | Iteration number: [140/4518] 3% | Training loss: 0.691955703496933
Epoch: 19 | Iteration number: [150/4518] 3% | Training loss: 0.691535564661026
Epoch: 19 | Iteration number: [160/4518] 3% | Training loss: 0.6912859246134758
Epoch: 19 | Iteration number: [170/4518] 3% | Training loss: 0.6909716609646293
Epoch: 19 | Iteration number: [180/4518] 3% | Training loss: 0.6907370507717132
Epoch: 19 | Iteration number: [190/4518] 4% | Training loss: 0.6905122659708324
Epoch: 19 | Iteration number: [200/4518] 4% | Training loss: 0.6903819778561592
Epoch: 19 | Iteration number: [210/4518] 4% | Training loss: 0.6902458781287784
Epoch: 19 | Iteration number: [220/4518] 4% | Training loss: 0.6901679748838598
Epoch: 19 | Iteration number: [230/4518] 5% | Training loss: 0.6900466652020164
Epoch: 19 | Iteration number: [240/4518] 5% | Training loss: 0.6899687342345715
Epoch: 19 | Iteration number: [250/4518] 5% | Training loss: 0.6898404731750488
Epoch: 19 | Iteration number: [260/4518] 5% | Training loss: 0.6897370090851417
Epoch: 19 | Iteration number: [270/4518] 5% | Training loss: 0.6896352816511083
Epoch: 19 | Iteration number: [280/4518] 6% | Training loss: 0.6895541757345199
Epoch: 19 | Iteration number: [290/4518] 6% | Training loss: 0.6894670757754096
Epoch: 19 | Iteration number: [300/4518] 6% | Training loss: 0.6893462498982748
Epoch: 19 | Iteration number: [310/4518] 6% | Training loss: 0.6892957622005094
Epoch: 19 | Iteration number: [320/4518] 7% | Training loss: 0.6892187088727951
Epoch: 19 | Iteration number: [330/4518] 7% | Training loss: 0.6891193799900286
Epoch: 19 | Iteration number: [340/4518] 7% | Training loss: 0.6890722288804896
Epoch: 19 | Iteration number: [350/4518] 7% | Training loss: 0.6890434694290161
Epoch: 19 | Iteration number: [360/4518] 7% | Training loss: 0.6890241212315029
Epoch: 19 | Iteration number: [370/4518] 8% | Training loss: 0.6889891977245743
Epoch: 19 | Iteration number: [380/4518] 8% | Training loss: 0.6889430571543543
Epoch: 19 | Iteration number: [390/4518] 8% | Training loss: 0.6888780590815422
Epoch: 19 | Iteration number: [400/4518] 8% | Training loss: 0.6888278162479401
Epoch: 19 | Iteration number: [410/4518] 9% | Training loss: 0.6887558373009286
Epoch: 19 | Iteration number: [420/4518] 9% | Training loss: 0.6887158812511535
Epoch: 19 | Iteration number: [430/4518] 9% | Training loss: 0.688653901981753
Epoch: 19 | Iteration number: [440/4518] 9% | Training loss: 0.6885916765440594
Epoch: 19 | Iteration number: [450/4518] 9% | Training loss: 0.6885656898551517
Epoch: 19 | Iteration number: [460/4518] 10% | Training loss: 0.6885137234045111
Epoch: 19 | Iteration number: [470/4518] 10% | Training loss: 0.6884669401544206
Epoch: 19 | Iteration number: [480/4518] 10% | Training loss: 0.6884273909032345
Epoch: 19 | Iteration number: [490/4518] 10% | Training loss: 0.6884023818434502
Epoch: 19 | Iteration number: [500/4518] 11% | Training loss: 0.6883640856742859
Epoch: 19 | Iteration number: [510/4518] 11% | Training loss: 0.6883295128158494
Epoch: 19 | Iteration number: [520/4518] 11% | Training loss: 0.688288326217578
Epoch: 19 | Iteration number: [530/4518] 11% | Training loss: 0.688256153295625
Epoch: 19 | Iteration number: [540/4518] 11% | Training loss: 0.6882611655526691
Epoch: 19 | Iteration number: [550/4518] 12% | Training loss: 0.6882278965819966
Epoch: 19 | Iteration number: [560/4518] 12% | Training loss: 0.6881961147700038
Epoch: 19 | Iteration number: [570/4518] 12% | Training loss: 0.6881823846122674
Epoch: 19 | Iteration number: [580/4518] 12% | Training loss: 0.6881628973730679
Epoch: 19 | Iteration number: [590/4518] 13% | Training loss: 0.6881519169120466
Epoch: 19 | Iteration number: [600/4518] 13% | Training loss: 0.6881335418423017
Epoch: 19 | Iteration number: [610/4518] 13% | Training loss: 0.6881109082307972
Epoch: 19 | Iteration number: [620/4518] 13% | Training loss: 0.6881043805230048
Epoch: 19 | Iteration number: [630/4518] 13% | Training loss: 0.6880686405159179
Epoch: 19 | Iteration number: [640/4518] 14% | Training loss: 0.6880397961474956
Epoch: 19 | Iteration number: [650/4518] 14% | Training loss: 0.6880102833417746
Epoch: 19 | Iteration number: [660/4518] 14% | Training loss: 0.6879805753628413
Epoch: 19 | Iteration number: [670/4518] 14% | Training loss: 0.6879691536746808
Epoch: 19 | Iteration number: [680/4518] 15% | Training loss: 0.6879529639202006
Epoch: 19 | Iteration number: [690/4518] 15% | Training loss: 0.6879354611687039
Epoch: 19 | Iteration number: [700/4518] 15% | Training loss: 0.6879176212208612
Epoch: 19 | Iteration number: [710/4518] 15% | Training loss: 0.6879178897595741
Epoch: 19 | Iteration number: [720/4518] 15% | Training loss: 0.6879036870267656
Epoch: 19 | Iteration number: [730/4518] 16% | Training loss: 0.6878831739295019
Epoch: 19 | Iteration number: [740/4518] 16% | Training loss: 0.6878747384290438
Epoch: 19 | Iteration number: [750/4518] 16% | Training loss: 0.6878481539885203
Epoch: 19 | Iteration number: [760/4518] 16% | Training loss: 0.687830560066198
Epoch: 19 | Iteration number: [770/4518] 17% | Training loss: 0.6878235301414093
Epoch: 19 | Iteration number: [780/4518] 17% | Training loss: 0.6878088382574228
Epoch: 19 | Iteration number: [790/4518] 17% | Training loss: 0.6878019135209579
Epoch: 19 | Iteration number: [800/4518] 17% | Training loss: 0.6878050040453673
Epoch: 19 | Iteration number: [810/4518] 17% | Training loss: 0.6877910947358167
Epoch: 19 | Iteration number: [820/4518] 18% | Training loss: 0.6877693856634745
Epoch: 19 | Iteration number: [830/4518] 18% | Training loss: 0.6877590850893274
Epoch: 19 | Iteration number: [840/4518] 18% | Training loss: 0.6877372229383105
Epoch: 19 | Iteration number: [850/4518] 18% | Training loss: 0.6877311406416051
Epoch: 19 | Iteration number: [860/4518] 19% | Training loss: 0.6877229323913885
Epoch: 19 | Iteration number: [870/4518] 19% | Training loss: 0.6877095933618217
Epoch: 19 | Iteration number: [880/4518] 19% | Training loss: 0.687714915654876
Epoch: 19 | Iteration number: [890/4518] 19% | Training loss: 0.6877077982666787
Epoch: 19 | Iteration number: [900/4518] 19% | Training loss: 0.6876909210946824
Epoch: 19 | Iteration number: [910/4518] 20% | Training loss: 0.6876880007785755
Epoch: 19 | Iteration number: [920/4518] 20% | Training loss: 0.6876801216084024
Epoch: 19 | Iteration number: [930/4518] 20% | Training loss: 0.6876745074026046
Epoch: 19 | Iteration number: [940/4518] 20% | Training loss: 0.6876624670434506
Epoch: 19 | Iteration number: [950/4518] 21% | Training loss: 0.6876550436647315
Epoch: 19 | Iteration number: [960/4518] 21% | Training loss: 0.6876359532276789
Epoch: 19 | Iteration number: [970/4518] 21% | Training loss: 0.6876281386183709
Epoch: 19 | Iteration number: [980/4518] 21% | Training loss: 0.6876156560620483
Epoch: 19 | Iteration number: [990/4518] 21% | Training loss: 0.6876107211666878
Epoch: 19 | Iteration number: [1000/4518] 22% | Training loss: 0.6875959855318069
Epoch: 19 | Iteration number: [1010/4518] 22% | Training loss: 0.6875703290547475
Epoch: 19 | Iteration number: [1020/4518] 22% | Training loss: 0.6875680471167845
Epoch: 19 | Iteration number: [1030/4518] 22% | Training loss: 0.6875683588310353
Epoch: 19 | Iteration number: [1040/4518] 23% | Training loss: 0.6875674265508468
Epoch: 19 | Iteration number: [1050/4518] 23% | Training loss: 0.6875486355168479
Epoch: 19 | Iteration number: [1060/4518] 23% | Training loss: 0.687547648908957
Epoch: 19 | Iteration number: [1070/4518] 23% | Training loss: 0.6875425447370405
Epoch: 19 | Iteration number: [1080/4518] 23% | Training loss: 0.6875410555137529
Epoch: 19 | Iteration number: [1090/4518] 24% | Training loss: 0.6875392288243005
Epoch: 19 | Iteration number: [1100/4518] 24% | Training loss: 0.6875369677760385
Epoch: 19 | Iteration number: [1110/4518] 24% | Training loss: 0.6875333223793958
Epoch: 19 | Iteration number: [1120/4518] 24% | Training loss: 0.6875336884920086
Epoch: 19 | Iteration number: [1130/4518] 25% | Training loss: 0.6875265503351667
Epoch: 19 | Iteration number: [1140/4518] 25% | Training loss: 0.687524867580648
Epoch: 19 | Iteration number: [1150/4518] 25% | Training loss: 0.6875156460637631
Epoch: 19 | Iteration number: [1160/4518] 25% | Training loss: 0.6875069105933452
Epoch: 19 | Iteration number: [1170/4518] 25% | Training loss: 0.6875049088755224
Epoch: 19 | Iteration number: [1180/4518] 26% | Training loss: 0.6875096046318442
Epoch: 19 | Iteration number: [1190/4518] 26% | Training loss: 0.6875105939993338
Epoch: 19 | Iteration number: [1200/4518] 26% | Training loss: 0.6875018597145875
Epoch: 19 | Iteration number: [1210/4518] 26% | Training loss: 0.6874824488951154
Epoch: 19 | Iteration number: [1220/4518] 27% | Training loss: 0.6874803647154667
Epoch: 19 | Iteration number: [1230/4518] 27% | Training loss: 0.68747530371193
Epoch: 19 | Iteration number: [1240/4518] 27% | Training loss: 0.6874650194279609
Epoch: 19 | Iteration number: [1250/4518] 27% | Training loss: 0.6874519213199616
Epoch: 19 | Iteration number: [1260/4518] 27% | Training loss: 0.6874458215539417
Epoch: 19 | Iteration number: [1270/4518] 28% | Training loss: 0.6874414078363283
Epoch: 19 | Iteration number: [1280/4518] 28% | Training loss: 0.6874253102578223
Epoch: 19 | Iteration number: [1290/4518] 28% | Training loss: 0.687427191447842
Epoch: 19 | Iteration number: [1300/4518] 28% | Training loss: 0.6874207965227274
Epoch: 19 | Iteration number: [1310/4518] 28% | Training loss: 0.6874239184474217
Epoch: 19 | Iteration number: [1320/4518] 29% | Training loss: 0.6874319580468264
Epoch: 19 | Iteration number: [1330/4518] 29% | Training loss: 0.6874234493065597
Epoch: 19 | Iteration number: [1340/4518] 29% | Training loss: 0.6874219849483291
Epoch: 19 | Iteration number: [1350/4518] 29% | Training loss: 0.6874271627708718
Epoch: 19 | Iteration number: [1360/4518] 30% | Training loss: 0.6874275166760473
Epoch: 19 | Iteration number: [1370/4518] 30% | Training loss: 0.6874227143552182
Epoch: 19 | Iteration number: [1380/4518] 30% | Training loss: 0.6874189644620039
Epoch: 19 | Iteration number: [1390/4518] 30% | Training loss: 0.6874244915066863
Epoch: 19 | Iteration number: [1400/4518] 30% | Training loss: 0.6874080043605396
Epoch: 19 | Iteration number: [1410/4518] 31% | Training loss: 0.6874190584987613
Epoch: 19 | Iteration number: [1420/4518] 31% | Training loss: 0.6874116514770078
Epoch: 19 | Iteration number: [1430/4518] 31% | Training loss: 0.687411439001977
Epoch: 19 | Iteration number: [1440/4518] 31% | Training loss: 0.6874164946377277
Epoch: 19 | Iteration number: [1450/4518] 32% | Training loss: 0.687417543016631
Epoch: 19 | Iteration number: [1460/4518] 32% | Training loss: 0.6874161035638966
Epoch: 19 | Iteration number: [1470/4518] 32% | Training loss: 0.6874146094938525
Epoch: 19 | Iteration number: [1480/4518] 32% | Training loss: 0.6874118273322647
Epoch: 19 | Iteration number: [1490/4518] 32% | Training loss: 0.6874007654670101
Epoch: 19 | Iteration number: [1500/4518] 33% | Training loss: 0.6874024834632874
Epoch: 19 | Iteration number: [1510/4518] 33% | Training loss: 0.6873995103978163
Epoch: 19 | Iteration number: [1520/4518] 33% | Training loss: 0.6873940525086303
Epoch: 19 | Iteration number: [1530/4518] 33% | Training loss: 0.6873892562451706
Epoch: 19 | Iteration number: [1540/4518] 34% | Training loss: 0.6873884617895275
Epoch: 19 | Iteration number: [1550/4518] 34% | Training loss: 0.6873779669884712
Epoch: 19 | Iteration number: [1560/4518] 34% | Training loss: 0.687372979407127
Epoch: 19 | Iteration number: [1570/4518] 34% | Training loss: 0.6873715395380737
Epoch: 19 | Iteration number: [1580/4518] 34% | Training loss: 0.6873620729657668
Epoch: 19 | Iteration number: [1590/4518] 35% | Training loss: 0.687357037097403
Epoch: 19 | Iteration number: [1600/4518] 35% | Training loss: 0.6873513258621097
Epoch: 19 | Iteration number: [1610/4518] 35% | Training loss: 0.6873411872742339
Epoch: 19 | Iteration number: [1620/4518] 35% | Training loss: 0.6873436668036896
Epoch: 19 | Iteration number: [1630/4518] 36% | Training loss: 0.687342613716067
Epoch: 19 | Iteration number: [1640/4518] 36% | Training loss: 0.6873470198453926
Epoch: 19 | Iteration number: [1650/4518] 36% | Training loss: 0.6873491181026805
Epoch: 19 | Iteration number: [1660/4518] 36% | Training loss: 0.6873507421418845
Epoch: 19 | Iteration number: [1670/4518] 36% | Training loss: 0.6873489813533372
Epoch: 19 | Iteration number: [1680/4518] 37% | Training loss: 0.6873377256804989
Epoch: 19 | Iteration number: [1690/4518] 37% | Training loss: 0.6873326984735636
Epoch: 19 | Iteration number: [1700/4518] 37% | Training loss: 0.6873299733680838
Epoch: 19 | Iteration number: [1710/4518] 37% | Training loss: 0.6873392096736974
Epoch: 19 | Iteration number: [1720/4518] 38% | Training loss: 0.6873325917263363
Epoch: 19 | Iteration number: [1730/4518] 38% | Training loss: 0.6873154548551306
Epoch: 19 | Iteration number: [1740/4518] 38% | Training loss: 0.6873179125032206
Epoch: 19 | Iteration number: [1750/4518] 38% | Training loss: 0.6873103426183973
Epoch: 19 | Iteration number: [1760/4518] 38% | Training loss: 0.6873052498495037
Epoch: 19 | Iteration number: [1770/4518] 39% | Training loss: 0.6872992208111758
Epoch: 19 | Iteration number: [1780/4518] 39% | Training loss: 0.6872981656803174
Epoch: 19 | Iteration number: [1790/4518] 39% | Training loss: 0.6872987216078369
Epoch: 19 | Iteration number: [1800/4518] 39% | Training loss: 0.6872979794277085
Epoch: 19 | Iteration number: [1810/4518] 40% | Training loss: 0.6872983895612685
Epoch: 19 | Iteration number: [1820/4518] 40% | Training loss: 0.6872959762484163
Epoch: 19 | Iteration number: [1830/4518] 40% | Training loss: 0.6872967562063145
Epoch: 19 | Iteration number: [1840/4518] 40% | Training loss: 0.6872839162855044
Epoch: 19 | Iteration number: [1850/4518] 40% | Training loss: 0.6872809893053932
Epoch: 19 | Iteration number: [1860/4518] 41% | Training loss: 0.6872822658990019
Epoch: 19 | Iteration number: [1870/4518] 41% | Training loss: 0.6872787560052412
Epoch: 19 | Iteration number: [1880/4518] 41% | Training loss: 0.6872720403557128
Epoch: 19 | Iteration number: [1890/4518] 41% | Training loss: 0.6872698552078671
Epoch: 19 | Iteration number: [1900/4518] 42% | Training loss: 0.6872719406140478
Epoch: 19 | Iteration number: [1910/4518] 42% | Training loss: 0.6872767848494166
Epoch: 19 | Iteration number: [1920/4518] 42% | Training loss: 0.6872796358851095
Epoch: 19 | Iteration number: [1930/4518] 42% | Training loss: 0.6872821758139319
Epoch: 19 | Iteration number: [1940/4518] 42% | Training loss: 0.6872818037406685
Epoch: 19 | Iteration number: [1950/4518] 43% | Training loss: 0.6872840629479824
Epoch: 19 | Iteration number: [1960/4518] 43% | Training loss: 0.687284655230386
Epoch: 19 | Iteration number: [1970/4518] 43% | Training loss: 0.6872819179810848
Epoch: 19 | Iteration number: [1980/4518] 43% | Training loss: 0.6872784392099188
Epoch: 19 | Iteration number: [1990/4518] 44% | Training loss: 0.687276228169101
Epoch: 19 | Iteration number: [2000/4518] 44% | Training loss: 0.687270244717598
Epoch: 19 | Iteration number: [2010/4518] 44% | Training loss: 0.6872722504743889
Epoch: 19 | Iteration number: [2020/4518] 44% | Training loss: 0.687267338078801
Epoch: 19 | Iteration number: [2030/4518] 44% | Training loss: 0.6872680729539523
Epoch: 19 | Iteration number: [2040/4518] 45% | Training loss: 0.6872643971560048
Epoch: 19 | Iteration number: [2050/4518] 45% | Training loss: 0.6872600303917397
Epoch: 19 | Iteration number: [2060/4518] 45% | Training loss: 0.687260889804479
Epoch: 19 | Iteration number: [2070/4518] 45% | Training loss: 0.687259027261089
Epoch: 19 | Iteration number: [2080/4518] 46% | Training loss: 0.6872550688110866
Epoch: 19 | Iteration number: [2090/4518] 46% | Training loss: 0.6872542054459239
Epoch: 19 | Iteration number: [2100/4518] 46% | Training loss: 0.6872538122676668
Epoch: 19 | Iteration number: [2110/4518] 46% | Training loss: 0.6872509128109539
Epoch: 19 | Iteration number: [2120/4518] 46% | Training loss: 0.6872488248741851
Epoch: 19 | Iteration number: [2130/4518] 47% | Training loss: 0.6872466994843013
Epoch: 19 | Iteration number: [2140/4518] 47% | Training loss: 0.6872452268255091
Epoch: 19 | Iteration number: [2150/4518] 47% | Training loss: 0.6872472255174503
Epoch: 19 | Iteration number: [2160/4518] 47% | Training loss: 0.6872457472538507
Epoch: 19 | Iteration number: [2170/4518] 48% | Training loss: 0.6872471519054905
Epoch: 19 | Iteration number: [2180/4518] 48% | Training loss: 0.6872431123202
Epoch: 19 | Iteration number: [2190/4518] 48% | Training loss: 0.6872402625541164
Epoch: 19 | Iteration number: [2200/4518] 48% | Training loss: 0.6872408268939365
Epoch: 19 | Iteration number: [2210/4518] 48% | Training loss: 0.6872364822286287
Epoch: 19 | Iteration number: [2220/4518] 49% | Training loss: 0.6872405832415228
Epoch: 19 | Iteration number: [2230/4518] 49% | Training loss: 0.6872405522874653
Epoch: 19 | Iteration number: [2240/4518] 49% | Training loss: 0.687237150089017
Epoch: 19 | Iteration number: [2250/4518] 49% | Training loss: 0.6872397418816885
Epoch: 19 | Iteration number: [2260/4518] 50% | Training loss: 0.6872407394964083
Epoch: 19 | Iteration number: [2270/4518] 50% | Training loss: 0.687235048452663
Epoch: 19 | Iteration number: [2280/4518] 50% | Training loss: 0.6872334846279078
Epoch: 19 | Iteration number: [2290/4518] 50% | Training loss: 0.6872368726928161
Epoch: 19 | Iteration number: [2300/4518] 50% | Training loss: 0.6872338904764341
Epoch: 19 | Iteration number: [2310/4518] 51% | Training loss: 0.6872302056907059
Epoch: 19 | Iteration number: [2320/4518] 51% | Training loss: 0.6872322589159012
Epoch: 19 | Iteration number: [2330/4518] 51% | Training loss: 0.6872323994472814
Epoch: 19 | Iteration number: [2340/4518] 51% | Training loss: 0.6872271308532127
Epoch: 19 | Iteration number: [2350/4518] 52% | Training loss: 0.6872248963853146
Epoch: 19 | Iteration number: [2360/4518] 52% | Training loss: 0.687219966291371
Epoch: 19 | Iteration number: [2370/4518] 52% | Training loss: 0.6872144504438473
Epoch: 19 | Iteration number: [2380/4518] 52% | Training loss: 0.6872100873905069
Epoch: 19 | Iteration number: [2390/4518] 52% | Training loss: 0.6872092557502092
Epoch: 19 | Iteration number: [2400/4518] 53% | Training loss: 0.6872068185855945
Epoch: 19 | Iteration number: [2410/4518] 53% | Training loss: 0.6871953984019172
Epoch: 19 | Iteration number: [2420/4518] 53% | Training loss: 0.6871924088759855
Epoch: 19 | Iteration number: [2430/4518] 53% | Training loss: 0.6871884549105609
Epoch: 19 | Iteration number: [2440/4518] 54% | Training loss: 0.6871876223409762
Epoch: 19 | Iteration number: [2450/4518] 54% | Training loss: 0.6871843039259619
Epoch: 19 | Iteration number: [2460/4518] 54% | Training loss: 0.6871846200974007
Epoch: 19 | Iteration number: [2470/4518] 54% | Training loss: 0.6871812881728415
Epoch: 19 | Iteration number: [2480/4518] 54% | Training loss: 0.6871824932675208
Epoch: 19 | Iteration number: [2490/4518] 55% | Training loss: 0.6871827083658502
Epoch: 19 | Iteration number: [2500/4518] 55% | Training loss: 0.6871881259441376
Epoch: 19 | Iteration number: [2510/4518] 55% | Training loss: 0.6871906160358414
Epoch: 19 | Iteration number: [2520/4518] 55% | Training loss: 0.6871904087208566
Epoch: 19 | Iteration number: [2530/4518] 55% | Training loss: 0.6871837774284272
Epoch: 19 | Iteration number: [2540/4518] 56% | Training loss: 0.6871781625850932
Epoch: 19 | Iteration number: [2550/4518] 56% | Training loss: 0.6871812628297245
Epoch: 19 | Iteration number: [2560/4518] 56% | Training loss: 0.6871763116680085
Epoch: 19 | Iteration number: [2570/4518] 56% | Training loss: 0.6871707172941142
Epoch: 19 | Iteration number: [2580/4518] 57% | Training loss: 0.6871716664512028
Epoch: 19 | Iteration number: [2590/4518] 57% | Training loss: 0.6871724125271138
Epoch: 19 | Iteration number: [2600/4518] 57% | Training loss: 0.6871757803742702
Epoch: 19 | Iteration number: [2610/4518] 57% | Training loss: 0.6871766915494911
Epoch: 19 | Iteration number: [2620/4518] 57% | Training loss: 0.6871740646944702
Epoch: 19 | Iteration number: [2630/4518] 58% | Training loss: 0.6871767242825076
Epoch: 19 | Iteration number: [2640/4518] 58% | Training loss: 0.6871797569547639
Epoch: 19 | Iteration number: [2650/4518] 58% | Training loss: 0.6871803551574923
Epoch: 19 | Iteration number: [2660/4518] 58% | Training loss: 0.6871792633506588
Epoch: 19 | Iteration number: [2670/4518] 59% | Training loss: 0.6871732880113723
Epoch: 19 | Iteration number: [2680/4518] 59% | Training loss: 0.6871672993053252
Epoch: 19 | Iteration number: [2690/4518] 59% | Training loss: 0.6871619143007414
Epoch: 19 | Iteration number: [2700/4518] 59% | Training loss: 0.6871559670677891
Epoch: 19 | Iteration number: [2710/4518] 59% | Training loss: 0.6871551053770354
Epoch: 19 | Iteration number: [2720/4518] 60% | Training loss: 0.6871525494053083
Epoch: 19 | Iteration number: [2730/4518] 60% | Training loss: 0.6871505587092249
Epoch: 19 | Iteration number: [2740/4518] 60% | Training loss: 0.6871487422798672
Epoch: 19 | Iteration number: [2750/4518] 60% | Training loss: 0.6871496291160584
Epoch: 19 | Iteration number: [2760/4518] 61% | Training loss: 0.6871494057385817
Epoch: 19 | Iteration number: [2770/4518] 61% | Training loss: 0.6871531617125018
Epoch: 19 | Iteration number: [2780/4518] 61% | Training loss: 0.6871560557068681
Epoch: 19 | Iteration number: [2790/4518] 61% | Training loss: 0.687150132357006
Epoch: 19 | Iteration number: [2800/4518] 61% | Training loss: 0.6871442516786711
Epoch: 19 | Iteration number: [2810/4518] 62% | Training loss: 0.68714097515544
Epoch: 19 | Iteration number: [2820/4518] 62% | Training loss: 0.6871447710703451
Epoch: 19 | Iteration number: [2830/4518] 62% | Training loss: 0.6871449967365804
Epoch: 19 | Iteration number: [2840/4518] 62% | Training loss: 0.6871425346169673
Epoch: 19 | Iteration number: [2850/4518] 63% | Training loss: 0.6871429583064297
Epoch: 19 | Iteration number: [2860/4518] 63% | Training loss: 0.6871449701435917
Epoch: 19 | Iteration number: [2870/4518] 63% | Training loss: 0.6871393095948555
Epoch: 19 | Iteration number: [2880/4518] 63% | Training loss: 0.6871383345168498
Epoch: 19 | Iteration number: [2890/4518] 63% | Training loss: 0.6871401784123021
Epoch: 19 | Iteration number: [2900/4518] 64% | Training loss: 0.6871332741400291
Epoch: 19 | Iteration number: [2910/4518] 64% | Training loss: 0.6871312630954887
Epoch: 19 | Iteration number: [2920/4518] 64% | Training loss: 0.6871282938612651
Epoch: 19 | Iteration number: [2930/4518] 64% | Training loss: 0.6871285056905128
Epoch: 19 | Iteration number: [2940/4518] 65% | Training loss: 0.6871280178529064
Epoch: 19 | Iteration number: [2950/4518] 65% | Training loss: 0.6871248081579047
Epoch: 19 | Iteration number: [2960/4518] 65% | Training loss: 0.6871235481186493
Epoch: 19 | Iteration number: [2970/4518] 65% | Training loss: 0.6871231785727671
Epoch: 19 | Iteration number: [2980/4518] 65% | Training loss: 0.6871199193016795
Epoch: 19 | Iteration number: [2990/4518] 66% | Training loss: 0.6871235641348721
Epoch: 19 | Iteration number: [3000/4518] 66% | Training loss: 0.6871234065890313
Epoch: 19 | Iteration number: [3010/4518] 66% | Training loss: 0.6871227683815053
Epoch: 19 | Iteration number: [3020/4518] 66% | Training loss: 0.6871238185277838
Epoch: 19 | Iteration number: [3030/4518] 67% | Training loss: 0.6871261761330142
Epoch: 19 | Iteration number: [3040/4518] 67% | Training loss: 0.687124648003986
Epoch: 19 | Iteration number: [3050/4518] 67% | Training loss: 0.6871227823124557
Epoch: 19 | Iteration number: [3060/4518] 67% | Training loss: 0.6871204825008617
Epoch: 19 | Iteration number: [3070/4518] 67% | Training loss: 0.6871210369496858
Epoch: 19 | Iteration number: [3080/4518] 68% | Training loss: 0.6871232659011692
Epoch: 19 | Iteration number: [3090/4518] 68% | Training loss: 0.6871254728257078
Epoch: 19 | Iteration number: [3100/4518] 68% | Training loss: 0.6871245480929652
Epoch: 19 | Iteration number: [3110/4518] 68% | Training loss: 0.6871246922246129
Epoch: 19 | Iteration number: [3120/4518] 69% | Training loss: 0.687125362131076
Epoch: 19 | Iteration number: [3130/4518] 69% | Training loss: 0.6871305697832626
Epoch: 19 | Iteration number: [3140/4518] 69% | Training loss: 0.687132469882631
Epoch: 19 | Iteration number: [3150/4518] 69% | Training loss: 0.6871344120729537
Epoch: 19 | Iteration number: [3160/4518] 69% | Training loss: 0.6871346426538274
Epoch: 19 | Iteration number: [3170/4518] 70% | Training loss: 0.6871315287302722
Epoch: 19 | Iteration number: [3180/4518] 70% | Training loss: 0.6871288704234849
Epoch: 19 | Iteration number: [3190/4518] 70% | Training loss: 0.6871315395196778
Epoch: 19 | Iteration number: [3200/4518] 70% | Training loss: 0.6871276589669287
Epoch: 19 | Iteration number: [3210/4518] 71% | Training loss: 0.6871268782660226
Epoch: 19 | Iteration number: [3220/4518] 71% | Training loss: 0.6871297303193845
Epoch: 19 | Iteration number: [3230/4518] 71% | Training loss: 0.6871300695481315
Epoch: 19 | Iteration number: [3240/4518] 71% | Training loss: 0.6871305330851931
Epoch: 19 | Iteration number: [3250/4518] 71% | Training loss: 0.6871274005449736
Epoch: 19 | Iteration number: [3260/4518] 72% | Training loss: 0.6871267169348302
Epoch: 19 | Iteration number: [3270/4518] 72% | Training loss: 0.6871324149475915
Epoch: 19 | Iteration number: [3280/4518] 72% | Training loss: 0.6871329188528584
Epoch: 19 | Iteration number: [3290/4518] 72% | Training loss: 0.6871312110800873
Epoch: 19 | Iteration number: [3300/4518] 73% | Training loss: 0.6871317401618668
Epoch: 19 | Iteration number: [3310/4518] 73% | Training loss: 0.6871323201591515
Epoch: 19 | Iteration number: [3320/4518] 73% | Training loss: 0.6871292659676219
Epoch: 19 | Iteration number: [3330/4518] 73% | Training loss: 0.687126855109189
Epoch: 19 | Iteration number: [3340/4518] 73% | Training loss: 0.6871263643224796
Epoch: 19 | Iteration number: [3350/4518] 74% | Training loss: 0.6871254391812567
Epoch: 19 | Iteration number: [3360/4518] 74% | Training loss: 0.6871221739976179
Epoch: 19 | Iteration number: [3370/4518] 74% | Training loss: 0.6871223271600571
Epoch: 19 | Iteration number: [3380/4518] 74% | Training loss: 0.6871212657034045
Epoch: 19 | Iteration number: [3390/4518] 75% | Training loss: 0.6871201392647791
Epoch: 19 | Iteration number: [3400/4518] 75% | Training loss: 0.6871200815895024
Epoch: 19 | Iteration number: [3410/4518] 75% | Training loss: 0.6871197153221477
Epoch: 19 | Iteration number: [3420/4518] 75% | Training loss: 0.6871168252146035
Epoch: 19 | Iteration number: [3430/4518] 75% | Training loss: 0.6871152379769974
Epoch: 19 | Iteration number: [3440/4518] 76% | Training loss: 0.687117453473945
Epoch: 19 | Iteration number: [3450/4518] 76% | Training loss: 0.6871164058947908
Epoch: 19 | Iteration number: [3460/4518] 76% | Training loss: 0.6871178375158696
Epoch: 19 | Iteration number: [3470/4518] 76% | Training loss: 0.6871174638656099
Epoch: 19 | Iteration number: [3480/4518] 77% | Training loss: 0.6871180658710414
Epoch: 19 | Iteration number: [3490/4518] 77% | Training loss: 0.6871173192573482
Epoch: 19 | Iteration number: [3500/4518] 77% | Training loss: 0.6871178476980754
Epoch: 19 | Iteration number: [3510/4518] 77% | Training loss: 0.6871164580186208
Epoch: 19 | Iteration number: [3520/4518] 77% | Training loss: 0.6871161955493418
Epoch: 19 | Iteration number: [3530/4518] 78% | Training loss: 0.6871199274198192
Epoch: 19 | Iteration number: [3540/4518] 78% | Training loss: 0.6871181510262571
Epoch: 19 | Iteration number: [3550/4518] 78% | Training loss: 0.6871174196290298
Epoch: 19 | Iteration number: [3560/4518] 78% | Training loss: 0.687115558496352
Epoch: 19 | Iteration number: [3570/4518] 79% | Training loss: 0.6871153226252698
Epoch: 19 | Iteration number: [3580/4518] 79% | Training loss: 0.6871160702165945
Epoch: 19 | Iteration number: [3590/4518] 79% | Training loss: 0.6871176034461157
Epoch: 19 | Iteration number: [3600/4518] 79% | Training loss: 0.6871204071574741
Epoch: 19 | Iteration number: [3610/4518] 79% | Training loss: 0.6871224052027652
Epoch: 19 | Iteration number: [3620/4518] 80% | Training loss: 0.6871220100321164
Epoch: 19 | Iteration number: [3630/4518] 80% | Training loss: 0.6871176141188493
Epoch: 19 | Iteration number: [3640/4518] 80% | Training loss: 0.6871156452448813
Epoch: 19 | Iteration number: [3650/4518] 80% | Training loss: 0.6871163243953495
Epoch: 19 | Iteration number: [3660/4518] 81% | Training loss: 0.687117383128307
Epoch: 19 | Iteration number: [3670/4518] 81% | Training loss: 0.6871156571184257
Epoch: 19 | Iteration number: [3680/4518] 81% | Training loss: 0.6871122261428315
Epoch: 19 | Iteration number: [3690/4518] 81% | Training loss: 0.6871110551725558
Epoch: 19 | Iteration number: [3700/4518] 81% | Training loss: 0.6871101488616016
Epoch: 19 | Iteration number: [3710/4518] 82% | Training loss: 0.6871102053360798
Epoch: 19 | Iteration number: [3720/4518] 82% | Training loss: 0.6871139228824646
Epoch: 19 | Iteration number: [3730/4518] 82% | Training loss: 0.6871077791615402
Epoch: 19 | Iteration number: [3740/4518] 82% | Training loss: 0.6871065513813559
Epoch: 19 | Iteration number: [3750/4518] 83% | Training loss: 0.6871069519201914
Epoch: 19 | Iteration number: [3760/4518] 83% | Training loss: 0.6871073137096902
Epoch: 19 | Iteration number: [3770/4518] 83% | Training loss: 0.6871102411013383
Epoch: 19 | Iteration number: [3780/4518] 83% | Training loss: 0.687109505073734
Epoch: 19 | Iteration number: [3790/4518] 83% | Training loss: 0.6871077665710198
Epoch: 19 | Iteration number: [3800/4518] 84% | Training loss: 0.6871086564032655
Epoch: 19 | Iteration number: [3810/4518] 84% | Training loss: 0.6871074186066004
Epoch: 19 | Iteration number: [3820/4518] 84% | Training loss: 0.6871093585853177
Epoch: 19 | Iteration number: [3830/4518] 84% | Training loss: 0.687108612636362
Epoch: 19 | Iteration number: [3840/4518] 84% | Training loss: 0.6871069953621676
Epoch: 19 | Iteration number: [3850/4518] 85% | Training loss: 0.6871070387920776
Epoch: 19 | Iteration number: [3860/4518] 85% | Training loss: 0.6871068595450159
Epoch: 19 | Iteration number: [3870/4518] 85% | Training loss: 0.6871085021846979
Epoch: 19 | Iteration number: [3880/4518] 85% | Training loss: 0.6871055043696128
Epoch: 19 | Iteration number: [3890/4518] 86% | Training loss: 0.6871050498479436
Epoch: 19 | Iteration number: [3900/4518] 86% | Training loss: 0.6871037894028884
Epoch: 19 | Iteration number: [3910/4518] 86% | Training loss: 0.6871046739008726
Epoch: 19 | Iteration number: [3920/4518] 86% | Training loss: 0.6871030142568813
Epoch: 19 | Iteration number: [3930/4518] 86% | Training loss: 0.6870980391823912
Epoch: 19 | Iteration number: [3940/4518] 87% | Training loss: 0.6870918453193559
Epoch: 19 | Iteration number: [3950/4518] 87% | Training loss: 0.6870926910563361
Epoch: 19 | Iteration number: [3960/4518] 87% | Training loss: 0.6870929896530479
Epoch: 19 | Iteration number: [3970/4518] 87% | Training loss: 0.6870902631234762
Epoch: 19 | Iteration number: [3980/4518] 88% | Training loss: 0.6870928597959441
Epoch: 19 | Iteration number: [3990/4518] 88% | Training loss: 0.6870899120369053
Epoch: 19 | Iteration number: [4000/4518] 88% | Training loss: 0.6870903777778149
Epoch: 19 | Iteration number: [4010/4518] 88% | Training loss: 0.6870852410644664
Epoch: 19 | Iteration number: [4020/4518] 88% | Training loss: 0.6870856627747787
Epoch: 19 | Iteration number: [4030/4518] 89% | Training loss: 0.6870854375380144
Epoch: 19 | Iteration number: [4040/4518] 89% | Training loss: 0.6870860697166754
Epoch: 19 | Iteration number: [4050/4518] 89% | Training loss: 0.6870851671401366
Epoch: 19 | Iteration number: [4060/4518] 89% | Training loss: 0.687085659941429
Epoch: 19 | Iteration number: [4070/4518] 90% | Training loss: 0.6870856360809223
Epoch: 19 | Iteration number: [4080/4518] 90% | Training loss: 0.6870840427922268
Epoch: 19 | Iteration number: [4090/4518] 90% | Training loss: 0.6870830348039315
Epoch: 19 | Iteration number: [4100/4518] 90% | Training loss: 0.6870832346852233
Epoch: 19 | Iteration number: [4110/4518] 90% | Training loss: 0.687081304069273
Epoch: 19 | Iteration number: [4120/4518] 91% | Training loss: 0.6870812190967857
Epoch: 19 | Iteration number: [4130/4518] 91% | Training loss: 0.6870826635753271
Epoch: 19 | Iteration number: [4140/4518] 91% | Training loss: 0.6870788923208264
Epoch: 19 | Iteration number: [4150/4518] 91% | Training loss: 0.6870769262026591
Epoch: 19 | Iteration number: [4160/4518] 92% | Training loss: 0.6870747110161644
Epoch: 19 | Iteration number: [4170/4518] 92% | Training loss: 0.687074356842384
Epoch: 19 | Iteration number: [4180/4518] 92% | Training loss: 0.6870749341814142
Epoch: 19 | Iteration number: [4190/4518] 92% | Training loss: 0.687072982537718
Epoch: 19 | Iteration number: [4200/4518] 92% | Training loss: 0.6870742837729908
Epoch: 19 | Iteration number: [4210/4518] 93% | Training loss: 0.6870750893464848
Epoch: 19 | Iteration number: [4220/4518] 93% | Training loss: 0.687074973487176
Epoch: 19 | Iteration number: [4230/4518] 93% | Training loss: 0.6870712538701141
Epoch: 19 | Iteration number: [4240/4518] 93% | Training loss: 0.6870682077306621
Epoch: 19 | Iteration number: [4250/4518] 94% | Training loss: 0.6870676473449259
Epoch: 19 | Iteration number: [4260/4518] 94% | Training loss: 0.6870679615948682
Epoch: 19 | Iteration number: [4270/4518] 94% | Training loss: 0.6870682724605399
Epoch: 19 | Iteration number: [4280/4518] 94% | Training loss: 0.6870656513443617
Epoch: 19 | Iteration number: [4290/4518] 94% | Training loss: 0.6870650807043889
Epoch: 19 | Iteration number: [4300/4518] 95% | Training loss: 0.6870656910746596
Epoch: 19 | Iteration number: [4310/4518] 95% | Training loss: 0.687063839623657
Epoch: 19 | Iteration number: [4320/4518] 95% | Training loss: 0.6870625967504802
Epoch: 19 | Iteration number: [4330/4518] 95% | Training loss: 0.6870635383674234
Epoch: 19 | Iteration number: [4340/4518] 96% | Training loss: 0.6870623026300685
Epoch: 19 | Iteration number: [4350/4518] 96% | Training loss: 0.687060551985927
Epoch: 19 | Iteration number: [4360/4518] 96% | Training loss: 0.6870620052338741
Epoch: 19 | Iteration number: [4370/4518] 96% | Training loss: 0.68705953494635
Epoch: 19 | Iteration number: [4380/4518] 96% | Training loss: 0.6870579787857456
Epoch: 19 | Iteration number: [4390/4518] 97% | Training loss: 0.6870607315272025
Epoch: 19 | Iteration number: [4400/4518] 97% | Training loss: 0.6870589472217993
Epoch: 19 | Iteration number: [4410/4518] 97% | Training loss: 0.68706233692007
Epoch: 19 | Iteration number: [4420/4518] 97% | Training loss: 0.6870629214862892
Epoch: 19 | Iteration number: [4430/4518] 98% | Training loss: 0.6870642701067182
Epoch: 19 | Iteration number: [4440/4518] 98% | Training loss: 0.6870639205918656
Epoch: 19 | Iteration number: [4450/4518] 98% | Training loss: 0.6870612277073807
Epoch: 19 | Iteration number: [4460/4518] 98% | Training loss: 0.6870597493087229
Epoch: 19 | Iteration number: [4470/4518] 98% | Training loss: 0.6870615506865567
Epoch: 19 | Iteration number: [4480/4518] 99% | Training loss: 0.6870617450347969
Epoch: 19 | Iteration number: [4490/4518] 99% | Training loss: 0.687060766615687
Epoch: 19 | Iteration number: [4500/4518] 99% | Training loss: 0.6870600847138298
Epoch: 19 | Iteration number: [4510/4518] 99% | Training loss: 0.6870578798645087

 End of epoch: 19 | Train Loss: 0.686905367731151 | Training Time: 641 

 End of epoch: 19 | Eval Loss: 0.6903336632008455 | Evaluating Time: 17 
Epoch: 20 | Iteration number: [10/4518] 0% | Training loss: 0.7568434178829193
Epoch: 20 | Iteration number: [20/4518] 0% | Training loss: 0.7209065824747085
Epoch: 20 | Iteration number: [30/4518] 0% | Training loss: 0.7096921980381012
Epoch: 20 | Iteration number: [40/4518] 0% | Training loss: 0.7041834726929664
Epoch: 20 | Iteration number: [50/4518] 1% | Training loss: 0.7006767356395721
Epoch: 20 | Iteration number: [60/4518] 1% | Training loss: 0.6981945524613062
Epoch: 20 | Iteration number: [70/4518] 1% | Training loss: 0.6965273227010454
Epoch: 20 | Iteration number: [80/4518] 1% | Training loss: 0.6952958539128303
Epoch: 20 | Iteration number: [90/4518] 1% | Training loss: 0.6942802257008023
Epoch: 20 | Iteration number: [100/4518] 2% | Training loss: 0.6935582715272903
Epoch: 20 | Iteration number: [110/4518] 2% | Training loss: 0.6929950242692774
Epoch: 20 | Iteration number: [120/4518] 2% | Training loss: 0.6924964567025502
Epoch: 20 | Iteration number: [130/4518] 2% | Training loss: 0.6920702131894919
Epoch: 20 | Iteration number: [140/4518] 3% | Training loss: 0.6916947275400162
Epoch: 20 | Iteration number: [150/4518] 3% | Training loss: 0.6913390215237936
Epoch: 20 | Iteration number: [160/4518] 3% | Training loss: 0.6910570353269577
Epoch: 20 | Iteration number: [170/4518] 3% | Training loss: 0.690739774353364
Epoch: 20 | Iteration number: [180/4518] 3% | Training loss: 0.6905209822787179
Epoch: 20 | Iteration number: [190/4518] 4% | Training loss: 0.6903347282033218
Epoch: 20 | Iteration number: [200/4518] 4% | Training loss: 0.6901398673653603
Epoch: 20 | Iteration number: [210/4518] 4% | Training loss: 0.689920744725636
Epoch: 20 | Iteration number: [220/4518] 4% | Training loss: 0.6897569019686092
Epoch: 20 | Iteration number: [230/4518] 5% | Training loss: 0.689564999030984
Epoch: 20 | Iteration number: [240/4518] 5% | Training loss: 0.6895084597170353
Epoch: 20 | Iteration number: [250/4518] 5% | Training loss: 0.6893845889568329
Epoch: 20 | Iteration number: [260/4518] 5% | Training loss: 0.6892872530680436
Epoch: 20 | Iteration number: [270/4518] 5% | Training loss: 0.689208635798207
Epoch: 20 | Iteration number: [280/4518] 6% | Training loss: 0.6891550157751356
Epoch: 20 | Iteration number: [290/4518] 6% | Training loss: 0.6890798729041527
Epoch: 20 | Iteration number: [300/4518] 6% | Training loss: 0.6890319555997848
Epoch: 20 | Iteration number: [310/4518] 6% | Training loss: 0.688942135726252
Epoch: 20 | Iteration number: [320/4518] 7% | Training loss: 0.688854144141078
Epoch: 20 | Iteration number: [330/4518] 7% | Training loss: 0.688738690181212
Epoch: 20 | Iteration number: [340/4518] 7% | Training loss: 0.6886806759764167
Epoch: 20 | Iteration number: [350/4518] 7% | Training loss: 0.6886486557551793
Epoch: 20 | Iteration number: [360/4518] 7% | Training loss: 0.6885831993487146
Epoch: 20 | Iteration number: [370/4518] 8% | Training loss: 0.6885491947869997
Epoch: 20 | Iteration number: [380/4518] 8% | Training loss: 0.6885167391676652
Epoch: 20 | Iteration number: [390/4518] 8% | Training loss: 0.6884613275527954
Epoch: 20 | Iteration number: [400/4518] 8% | Training loss: 0.6884073129296303
Epoch: 20 | Iteration number: [410/4518] 9% | Training loss: 0.6883968550984453
Epoch: 20 | Iteration number: [420/4518] 9% | Training loss: 0.6883455212627139
Epoch: 20 | Iteration number: [430/4518] 9% | Training loss: 0.6883214308771977
Epoch: 20 | Iteration number: [440/4518] 9% | Training loss: 0.6882523723623969
Epoch: 20 | Iteration number: [450/4518] 9% | Training loss: 0.6882239588101705
Epoch: 20 | Iteration number: [460/4518] 10% | Training loss: 0.6881779261257337
Epoch: 20 | Iteration number: [470/4518] 10% | Training loss: 0.6881470469718284
Epoch: 20 | Iteration number: [480/4518] 10% | Training loss: 0.6881103629867236
Epoch: 20 | Iteration number: [490/4518] 10% | Training loss: 0.6881073966318247
Epoch: 20 | Iteration number: [500/4518] 11% | Training loss: 0.6880985634326935
Epoch: 20 | Iteration number: [510/4518] 11% | Training loss: 0.6880683984242234
Epoch: 20 | Iteration number: [520/4518] 11% | Training loss: 0.688061892757049
Epoch: 20 | Iteration number: [530/4518] 11% | Training loss: 0.6880551295460395
Epoch: 20 | Iteration number: [540/4518] 11% | Training loss: 0.6880232231484519
Epoch: 20 | Iteration number: [550/4518] 12% | Training loss: 0.6880035129460421
Epoch: 20 | Iteration number: [560/4518] 12% | Training loss: 0.6879792068685804
Epoch: 20 | Iteration number: [570/4518] 12% | Training loss: 0.6879596049325508
Epoch: 20 | Iteration number: [580/4518] 12% | Training loss: 0.687932064307147
Epoch: 20 | Iteration number: [590/4518] 13% | Training loss: 0.6879000910257889
Epoch: 20 | Iteration number: [600/4518] 13% | Training loss: 0.687875156501929
Epoch: 20 | Iteration number: [610/4518] 13% | Training loss: 0.6878579231559253
Epoch: 20 | Iteration number: [620/4518] 13% | Training loss: 0.6878538058650109
Epoch: 20 | Iteration number: [630/4518] 13% | Training loss: 0.6878393342570653
Epoch: 20 | Iteration number: [640/4518] 14% | Training loss: 0.6878339538350702
Epoch: 20 | Iteration number: [650/4518] 14% | Training loss: 0.6878150631831242
Epoch: 20 | Iteration number: [660/4518] 14% | Training loss: 0.6878083136045572
Epoch: 20 | Iteration number: [670/4518] 14% | Training loss: 0.6878024071899813
Epoch: 20 | Iteration number: [680/4518] 15% | Training loss: 0.6878063222941231
Epoch: 20 | Iteration number: [690/4518] 15% | Training loss: 0.6877866492755171
Epoch: 20 | Iteration number: [700/4518] 15% | Training loss: 0.6877761177505766
Epoch: 20 | Iteration number: [710/4518] 15% | Training loss: 0.6877793631083529
Epoch: 20 | Iteration number: [720/4518] 15% | Training loss: 0.6877745587792662
Epoch: 20 | Iteration number: [730/4518] 16% | Training loss: 0.6877610208237008
Epoch: 20 | Iteration number: [740/4518] 16% | Training loss: 0.6877409483935382
Epoch: 20 | Iteration number: [750/4518] 16% | Training loss: 0.6877320559024811
Epoch: 20 | Iteration number: [760/4518] 16% | Training loss: 0.6877250139650546
Epoch: 20 | Iteration number: [770/4518] 17% | Training loss: 0.6877211501071979
Epoch: 20 | Iteration number: [780/4518] 17% | Training loss: 0.68772583259986
Epoch: 20 | Iteration number: [790/4518] 17% | Training loss: 0.6877182211302504
Epoch: 20 | Iteration number: [800/4518] 17% | Training loss: 0.6877119465172291
Epoch: 20 | Iteration number: [810/4518] 17% | Training loss: 0.6877048697000668
Epoch: 20 | Iteration number: [820/4518] 18% | Training loss: 0.6877145656725255
Epoch: 20 | Iteration number: [830/4518] 18% | Training loss: 0.6877033011022821
Epoch: 20 | Iteration number: [840/4518] 18% | Training loss: 0.6876808271521614
Epoch: 20 | Iteration number: [850/4518] 18% | Training loss: 0.6876713061332702
Epoch: 20 | Iteration number: [860/4518] 19% | Training loss: 0.6876645542854487
Epoch: 20 | Iteration number: [870/4518] 19% | Training loss: 0.6876650397804962
Epoch: 20 | Iteration number: [880/4518] 19% | Training loss: 0.6876475638963959
Epoch: 20 | Iteration number: [890/4518] 19% | Training loss: 0.6876443428269933
Epoch: 20 | Iteration number: [900/4518] 19% | Training loss: 0.6876313327418433
Epoch: 20 | Iteration number: [910/4518] 20% | Training loss: 0.6876187608792231
Epoch: 20 | Iteration number: [920/4518] 20% | Training loss: 0.6876136925557386
Epoch: 20 | Iteration number: [930/4518] 20% | Training loss: 0.6876060304462269
Epoch: 20 | Iteration number: [940/4518] 20% | Training loss: 0.6875918123316258
Epoch: 20 | Iteration number: [950/4518] 21% | Training loss: 0.6875702810287475
Epoch: 20 | Iteration number: [960/4518] 21% | Training loss: 0.6875509983549516
Epoch: 20 | Iteration number: [970/4518] 21% | Training loss: 0.6875408194114252
Epoch: 20 | Iteration number: [980/4518] 21% | Training loss: 0.6875299347298486
Epoch: 20 | Iteration number: [990/4518] 21% | Training loss: 0.6875198724293949
Epoch: 20 | Iteration number: [1000/4518] 22% | Training loss: 0.6875245779752731
Epoch: 20 | Iteration number: [1010/4518] 22% | Training loss: 0.6875220877109187
Epoch: 20 | Iteration number: [1020/4518] 22% | Training loss: 0.6875088804492764
Epoch: 20 | Iteration number: [1030/4518] 22% | Training loss: 0.6874986737098508
Epoch: 20 | Iteration number: [1040/4518] 23% | Training loss: 0.6874939716206148
Epoch: 20 | Iteration number: [1050/4518] 23% | Training loss: 0.6874732353573754
Epoch: 20 | Iteration number: [1060/4518] 23% | Training loss: 0.6874672320653807
Epoch: 20 | Iteration number: [1070/4518] 23% | Training loss: 0.6874675324030012
Epoch: 20 | Iteration number: [1080/4518] 23% | Training loss: 0.6874680291723322
Epoch: 20 | Iteration number: [1090/4518] 24% | Training loss: 0.6874727217976107
Epoch: 20 | Iteration number: [1100/4518] 24% | Training loss: 0.6874605285579508
Epoch: 20 | Iteration number: [1110/4518] 24% | Training loss: 0.6874467979680311
Epoch: 20 | Iteration number: [1120/4518] 24% | Training loss: 0.6874337956309319
Epoch: 20 | Iteration number: [1130/4518] 25% | Training loss: 0.6874292602053785
Epoch: 20 | Iteration number: [1140/4518] 25% | Training loss: 0.6874304190016629
Epoch: 20 | Iteration number: [1150/4518] 25% | Training loss: 0.6874314960707789
Epoch: 20 | Iteration number: [1160/4518] 25% | Training loss: 0.6874222592033189
Epoch: 20 | Iteration number: [1170/4518] 25% | Training loss: 0.6874061504999797
Epoch: 20 | Iteration number: [1180/4518] 26% | Training loss: 0.687404235995422
Epoch: 20 | Iteration number: [1190/4518] 26% | Training loss: 0.6873932501849006
Epoch: 20 | Iteration number: [1200/4518] 26% | Training loss: 0.6873968417942524
Epoch: 20 | Iteration number: [1210/4518] 26% | Training loss: 0.6873917319557884
Epoch: 20 | Iteration number: [1220/4518] 27% | Training loss: 0.6873805956273783
Epoch: 20 | Iteration number: [1230/4518] 27% | Training loss: 0.687371780717276
Epoch: 20 | Iteration number: [1240/4518] 27% | Training loss: 0.6873651174287643
Epoch: 20 | Iteration number: [1250/4518] 27% | Training loss: 0.6873660142421723
Epoch: 20 | Iteration number: [1260/4518] 27% | Training loss: 0.6873607134535199
Epoch: 20 | Iteration number: [1270/4518] 28% | Training loss: 0.6873488131939895
Epoch: 20 | Iteration number: [1280/4518] 28% | Training loss: 0.6873512077145278
Epoch: 20 | Iteration number: [1290/4518] 28% | Training loss: 0.6873453954855601
Epoch: 20 | Iteration number: [1300/4518] 28% | Training loss: 0.6873470577368369
Epoch: 20 | Iteration number: [1310/4518] 28% | Training loss: 0.6873486462895196
Epoch: 20 | Iteration number: [1320/4518] 29% | Training loss: 0.6873497827938109
Epoch: 20 | Iteration number: [1330/4518] 29% | Training loss: 0.6873413344523064
Epoch: 20 | Iteration number: [1340/4518] 29% | Training loss: 0.6873357514836895
Epoch: 20 | Iteration number: [1350/4518] 29% | Training loss: 0.6873223777612051
Epoch: 20 | Iteration number: [1360/4518] 30% | Training loss: 0.6873193109298453
Epoch: 20 | Iteration number: [1370/4518] 30% | Training loss: 0.687319401711443
Epoch: 20 | Iteration number: [1380/4518] 30% | Training loss: 0.6873180881790493
Epoch: 20 | Iteration number: [1390/4518] 30% | Training loss: 0.6873182232860181
Epoch: 20 | Iteration number: [1400/4518] 30% | Training loss: 0.6873277894513947
Epoch: 20 | Iteration number: [1410/4518] 31% | Training loss: 0.6873267503072183
Epoch: 20 | Iteration number: [1420/4518] 31% | Training loss: 0.687324800919479
Epoch: 20 | Iteration number: [1430/4518] 31% | Training loss: 0.6873214915915803
Epoch: 20 | Iteration number: [1440/4518] 31% | Training loss: 0.6873087160703208
Epoch: 20 | Iteration number: [1450/4518] 32% | Training loss: 0.6873088448212065
Epoch: 20 | Iteration number: [1460/4518] 32% | Training loss: 0.6873014146334504
Epoch: 20 | Iteration number: [1470/4518] 32% | Training loss: 0.687295678075479
Epoch: 20 | Iteration number: [1480/4518] 32% | Training loss: 0.6873009471474467
Epoch: 20 | Iteration number: [1490/4518] 32% | Training loss: 0.6872991434679735
Epoch: 20 | Iteration number: [1500/4518] 33% | Training loss: 0.6872913601795833
Epoch: 20 | Iteration number: [1510/4518] 33% | Training loss: 0.687292809833754
Epoch: 20 | Iteration number: [1520/4518] 33% | Training loss: 0.6872949074365591
Epoch: 20 | Iteration number: [1530/4518] 33% | Training loss: 0.6872871275041618
Epoch: 20 | Iteration number: [1540/4518] 34% | Training loss: 0.687282572783433
Epoch: 20 | Iteration number: [1550/4518] 34% | Training loss: 0.6872618171476549
Epoch: 20 | Iteration number: [1560/4518] 34% | Training loss: 0.6872595116878167
Epoch: 20 | Iteration number: [1570/4518] 34% | Training loss: 0.6872583411681424
Epoch: 20 | Iteration number: [1580/4518] 34% | Training loss: 0.6872579415387745
Epoch: 20 | Iteration number: [1590/4518] 35% | Training loss: 0.6872587385042659
Epoch: 20 | Iteration number: [1600/4518] 35% | Training loss: 0.6872566543146967
Epoch: 20 | Iteration number: [1610/4518] 35% | Training loss: 0.6872631050785136
Epoch: 20 | Iteration number: [1620/4518] 35% | Training loss: 0.6872564723094304
Epoch: 20 | Iteration number: [1630/4518] 36% | Training loss: 0.6872495174042287
Epoch: 20 | Iteration number: [1640/4518] 36% | Training loss: 0.687248970677213
Epoch: 20 | Iteration number: [1650/4518] 36% | Training loss: 0.6872457687060038
Epoch: 20 | Iteration number: [1660/4518] 36% | Training loss: 0.6872402010552855
Epoch: 20 | Iteration number: [1670/4518] 36% | Training loss: 0.6872326356208253
Epoch: 20 | Iteration number: [1680/4518] 37% | Training loss: 0.6872278485624563
Epoch: 20 | Iteration number: [1690/4518] 37% | Training loss: 0.6872301499519122
Epoch: 20 | Iteration number: [1700/4518] 37% | Training loss: 0.6872339136460248
Epoch: 20 | Iteration number: [1710/4518] 37% | Training loss: 0.6872312013865911
Epoch: 20 | Iteration number: [1720/4518] 38% | Training loss: 0.6872340912735739
Epoch: 20 | Iteration number: [1730/4518] 38% | Training loss: 0.6872322754019258
Epoch: 20 | Iteration number: [1740/4518] 38% | Training loss: 0.6872331318499028
Epoch: 20 | Iteration number: [1750/4518] 38% | Training loss: 0.6872346572535378
Epoch: 20 | Iteration number: [1760/4518] 38% | Training loss: 0.6872367711229758
Epoch: 20 | Iteration number: [1770/4518] 39% | Training loss: 0.6872325756455545
Epoch: 20 | Iteration number: [1780/4518] 39% | Training loss: 0.6872349183546024
Epoch: 20 | Iteration number: [1790/4518] 39% | Training loss: 0.6872349226607957
Epoch: 20 | Iteration number: [1800/4518] 39% | Training loss: 0.6872320225172572
Epoch: 20 | Iteration number: [1810/4518] 40% | Training loss: 0.6872368992362892
Epoch: 20 | Iteration number: [1820/4518] 40% | Training loss: 0.6872369894942084
Epoch: 20 | Iteration number: [1830/4518] 40% | Training loss: 0.6872353400037589
Epoch: 20 | Iteration number: [1840/4518] 40% | Training loss: 0.6872294660819613
Epoch: 20 | Iteration number: [1850/4518] 40% | Training loss: 0.68722906312427
Epoch: 20 | Iteration number: [1860/4518] 41% | Training loss: 0.6872278416669497
Epoch: 20 | Iteration number: [1870/4518] 41% | Training loss: 0.6872221368838122
Epoch: 20 | Iteration number: [1880/4518] 41% | Training loss: 0.68721997424009
Epoch: 20 | Iteration number: [1890/4518] 41% | Training loss: 0.6872217955728056
Epoch: 20 | Iteration number: [1900/4518] 42% | Training loss: 0.687225132553201
Epoch: 20 | Iteration number: [1910/4518] 42% | Training loss: 0.6872234294551829
Epoch: 20 | Iteration number: [1920/4518] 42% | Training loss: 0.6872195530372361
Epoch: 20 | Iteration number: [1930/4518] 42% | Training loss: 0.6872130741418334
Epoch: 20 | Iteration number: [1940/4518] 42% | Training loss: 0.6872123287817866
Epoch: 20 | Iteration number: [1950/4518] 43% | Training loss: 0.6872124805205908
Epoch: 20 | Iteration number: [1960/4518] 43% | Training loss: 0.6872125420947464
Epoch: 20 | Iteration number: [1970/4518] 43% | Training loss: 0.6872110380739125
Epoch: 20 | Iteration number: [1980/4518] 43% | Training loss: 0.6872128385787059
Epoch: 20 | Iteration number: [1990/4518] 44% | Training loss: 0.6872142740230465
Epoch: 20 | Iteration number: [2000/4518] 44% | Training loss: 0.687208075761795
Epoch: 20 | Iteration number: [2010/4518] 44% | Training loss: 0.6872034710438097
Epoch: 20 | Iteration number: [2020/4518] 44% | Training loss: 0.6871984349914116
Epoch: 20 | Iteration number: [2030/4518] 44% | Training loss: 0.6871966355246276
Epoch: 20 | Iteration number: [2040/4518] 45% | Training loss: 0.6871951534467585
Epoch: 20 | Iteration number: [2050/4518] 45% | Training loss: 0.6871919854094343
Epoch: 20 | Iteration number: [2060/4518] 45% | Training loss: 0.6871949474209721
Epoch: 20 | Iteration number: [2070/4518] 45% | Training loss: 0.687193891391662
Epoch: 20 | Iteration number: [2080/4518] 46% | Training loss: 0.6871928580391865
Epoch: 20 | Iteration number: [2090/4518] 46% | Training loss: 0.6871967699539148
Epoch: 20 | Iteration number: [2100/4518] 46% | Training loss: 0.6871979392710186
Epoch: 20 | Iteration number: [2110/4518] 46% | Training loss: 0.6871931054580833
Epoch: 20 | Iteration number: [2120/4518] 46% | Training loss: 0.6871922512380582
Epoch: 20 | Iteration number: [2130/4518] 47% | Training loss: 0.6871923314013951
Epoch: 20 | Iteration number: [2140/4518] 47% | Training loss: 0.687187015119
Epoch: 20 | Iteration number: [2150/4518] 47% | Training loss: 0.6871844017782877
Epoch: 20 | Iteration number: [2160/4518] 47% | Training loss: 0.6871816070267448
Epoch: 20 | Iteration number: [2170/4518] 48% | Training loss: 0.6871787361835006
Epoch: 20 | Iteration number: [2180/4518] 48% | Training loss: 0.6871693245861509
Epoch: 20 | Iteration number: [2190/4518] 48% | Training loss: 0.6871659974529318
Epoch: 20 | Iteration number: [2200/4518] 48% | Training loss: 0.6871679912372068
Epoch: 20 | Iteration number: [2210/4518] 48% | Training loss: 0.6871646766209495
Epoch: 20 | Iteration number: [2220/4518] 49% | Training loss: 0.6871690651317974
Epoch: 20 | Iteration number: [2230/4518] 49% | Training loss: 0.6871685678648842
Epoch: 20 | Iteration number: [2240/4518] 49% | Training loss: 0.6871661653742194
Epoch: 20 | Iteration number: [2250/4518] 49% | Training loss: 0.687166746907764
Epoch: 20 | Iteration number: [2260/4518] 50% | Training loss: 0.6871669548011459
Epoch: 20 | Iteration number: [2270/4518] 50% | Training loss: 0.6871634629329396
Epoch: 20 | Iteration number: [2280/4518] 50% | Training loss: 0.6871632721601871
Epoch: 20 | Iteration number: [2290/4518] 50% | Training loss: 0.6871570351863011
Epoch: 20 | Iteration number: [2300/4518] 50% | Training loss: 0.6871580488785454
Epoch: 20 | Iteration number: [2310/4518] 51% | Training loss: 0.6871550318998692
Epoch: 20 | Iteration number: [2320/4518] 51% | Training loss: 0.6871475621030249
Epoch: 20 | Iteration number: [2330/4518] 51% | Training loss: 0.687149458765472
Epoch: 20 | Iteration number: [2340/4518] 51% | Training loss: 0.6871500209610686
Epoch: 20 | Iteration number: [2350/4518] 52% | Training loss: 0.6871459320250978
Epoch: 20 | Iteration number: [2360/4518] 52% | Training loss: 0.6871408283963042
Epoch: 20 | Iteration number: [2370/4518] 52% | Training loss: 0.6871409236630307
Epoch: 20 | Iteration number: [2380/4518] 52% | Training loss: 0.6871399209529412
Epoch: 20 | Iteration number: [2390/4518] 52% | Training loss: 0.6871368200210348
Epoch: 20 | Iteration number: [2400/4518] 53% | Training loss: 0.6871390745043755
Epoch: 20 | Iteration number: [2410/4518] 53% | Training loss: 0.6871384318438803
Epoch: 20 | Iteration number: [2420/4518] 53% | Training loss: 0.6871395014780612
Epoch: 20 | Iteration number: [2430/4518] 53% | Training loss: 0.6871449003984899
Epoch: 20 | Iteration number: [2440/4518] 54% | Training loss: 0.6871427108518413
Epoch: 20 | Iteration number: [2450/4518] 54% | Training loss: 0.6871420617249547
Epoch: 20 | Iteration number: [2460/4518] 54% | Training loss: 0.6871449794953431
Epoch: 20 | Iteration number: [2470/4518] 54% | Training loss: 0.6871470039431383
Epoch: 20 | Iteration number: [2480/4518] 54% | Training loss: 0.6871466349930533
Epoch: 20 | Iteration number: [2490/4518] 55% | Training loss: 0.6871499855594941
Epoch: 20 | Iteration number: [2500/4518] 55% | Training loss: 0.6871470721960068
Epoch: 20 | Iteration number: [2510/4518] 55% | Training loss: 0.68714826206762
Epoch: 20 | Iteration number: [2520/4518] 55% | Training loss: 0.6871499783226422
Epoch: 20 | Iteration number: [2530/4518] 55% | Training loss: 0.6871483382735799
Epoch: 20 | Iteration number: [2540/4518] 56% | Training loss: 0.6871462536139751
Epoch: 20 | Iteration number: [2550/4518] 56% | Training loss: 0.6871445560455323
Epoch: 20 | Iteration number: [2560/4518] 56% | Training loss: 0.6871367818908766
Epoch: 20 | Iteration number: [2570/4518] 56% | Training loss: 0.6871359705461139
Epoch: 20 | Iteration number: [2580/4518] 57% | Training loss: 0.6871365713518719
Epoch: 20 | Iteration number: [2590/4518] 57% | Training loss: 0.6871312827217072
Epoch: 20 | Iteration number: [2600/4518] 57% | Training loss: 0.6871307417979607
Epoch: 20 | Iteration number: [2610/4518] 57% | Training loss: 0.6871296298229831
Epoch: 20 | Iteration number: [2620/4518] 57% | Training loss: 0.6871303013945353
Epoch: 20 | Iteration number: [2630/4518] 58% | Training loss: 0.6871307294858272
Epoch: 20 | Iteration number: [2640/4518] 58% | Training loss: 0.6871302083134652
Epoch: 20 | Iteration number: [2650/4518] 58% | Training loss: 0.6871343356258465
Epoch: 20 | Iteration number: [2660/4518] 58% | Training loss: 0.6871281397970099
Epoch: 20 | Iteration number: [2670/4518] 59% | Training loss: 0.6871224001998758
Epoch: 20 | Iteration number: [2680/4518] 59% | Training loss: 0.687126025312872
Epoch: 20 | Iteration number: [2690/4518] 59% | Training loss: 0.6871243060964634
Epoch: 20 | Iteration number: [2700/4518] 59% | Training loss: 0.6871267047634831
Epoch: 20 | Iteration number: [2710/4518] 59% | Training loss: 0.6871268545129642
Epoch: 20 | Iteration number: [2720/4518] 60% | Training loss: 0.6871271985637791
Epoch: 20 | Iteration number: [2730/4518] 60% | Training loss: 0.6871275579973019
Epoch: 20 | Iteration number: [2740/4518] 60% | Training loss: 0.6871228629437677
Epoch: 20 | Iteration number: [2750/4518] 60% | Training loss: 0.6871183652227575
Epoch: 20 | Iteration number: [2760/4518] 61% | Training loss: 0.6871236557977787
Epoch: 20 | Iteration number: [2770/4518] 61% | Training loss: 0.6871249235494042
Epoch: 20 | Iteration number: [2780/4518] 61% | Training loss: 0.6871267399556346
Epoch: 20 | Iteration number: [2790/4518] 61% | Training loss: 0.6871236474710554
Epoch: 20 | Iteration number: [2800/4518] 61% | Training loss: 0.6871232152198042
Epoch: 20 | Iteration number: [2810/4518] 62% | Training loss: 0.6871228542828475
Epoch: 20 | Iteration number: [2820/4518] 62% | Training loss: 0.6871222559230548
Epoch: 20 | Iteration number: [2830/4518] 62% | Training loss: 0.6871201764357806
Epoch: 20 | Iteration number: [2840/4518] 62% | Training loss: 0.6871175218635881
Epoch: 20 | Iteration number: [2850/4518] 63% | Training loss: 0.6871186941757537
Epoch: 20 | Iteration number: [2860/4518] 63% | Training loss: 0.6871173736307171
Epoch: 20 | Iteration number: [2870/4518] 63% | Training loss: 0.6871188464895773
Epoch: 20 | Iteration number: [2880/4518] 63% | Training loss: 0.6871194702883562
Epoch: 20 | Iteration number: [2890/4518] 63% | Training loss: 0.6871185143307419
Epoch: 20 | Iteration number: [2900/4518] 64% | Training loss: 0.6871244624565388
Epoch: 20 | Iteration number: [2910/4518] 64% | Training loss: 0.6871224225386721
Epoch: 20 | Iteration number: [2920/4518] 64% | Training loss: 0.6871245426470286
Epoch: 20 | Iteration number: [2930/4518] 64% | Training loss: 0.6871237027767169
Epoch: 20 | Iteration number: [2940/4518] 65% | Training loss: 0.6871215481336425
Epoch: 20 | Iteration number: [2950/4518] 65% | Training loss: 0.6871244401244794
Epoch: 20 | Iteration number: [2960/4518] 65% | Training loss: 0.6871249837448468
Epoch: 20 | Iteration number: [2970/4518] 65% | Training loss: 0.6871275206206222
Epoch: 20 | Iteration number: [2980/4518] 65% | Training loss: 0.6871215927320838
Epoch: 20 | Iteration number: [2990/4518] 66% | Training loss: 0.6871213056969403
Epoch: 20 | Iteration number: [3000/4518] 66% | Training loss: 0.6871185923616091
Epoch: 20 | Iteration number: [3010/4518] 66% | Training loss: 0.6871204539390894
Epoch: 20 | Iteration number: [3020/4518] 66% | Training loss: 0.6871220297173949
Epoch: 20 | Iteration number: [3030/4518] 67% | Training loss: 0.6871230208047546
Epoch: 20 | Iteration number: [3040/4518] 67% | Training loss: 0.687119090027715
Epoch: 20 | Iteration number: [3050/4518] 67% | Training loss: 0.6871102100122171
Epoch: 20 | Iteration number: [3060/4518] 67% | Training loss: 0.6871105737156338
Epoch: 20 | Iteration number: [3070/4518] 67% | Training loss: 0.6871115644902283
Epoch: 20 | Iteration number: [3080/4518] 68% | Training loss: 0.6871081395582719
Epoch: 20 | Iteration number: [3090/4518] 68% | Training loss: 0.6871082940726604
Epoch: 20 | Iteration number: [3100/4518] 68% | Training loss: 0.6871099994067222
Epoch: 20 | Iteration number: [3110/4518] 68% | Training loss: 0.6871083565271936
Epoch: 20 | Iteration number: [3120/4518] 69% | Training loss: 0.6871052565865028
Epoch: 20 | Iteration number: [3130/4518] 69% | Training loss: 0.6870989034160638
Epoch: 20 | Iteration number: [3140/4518] 69% | Training loss: 0.6870940206916469
Epoch: 20 | Iteration number: [3150/4518] 69% | Training loss: 0.6870910387569004
Epoch: 20 | Iteration number: [3160/4518] 69% | Training loss: 0.6870910933311981
Epoch: 20 | Iteration number: [3170/4518] 70% | Training loss: 0.6870905248336612
Epoch: 20 | Iteration number: [3180/4518] 70% | Training loss: 0.687090647201868
Epoch: 20 | Iteration number: [3190/4518] 70% | Training loss: 0.6870883793853293
Epoch: 20 | Iteration number: [3200/4518] 70% | Training loss: 0.6870875330641866
Epoch: 20 | Iteration number: [3210/4518] 71% | Training loss: 0.6870841691055773
Epoch: 20 | Iteration number: [3220/4518] 71% | Training loss: 0.6870819935517282
Epoch: 20 | Iteration number: [3230/4518] 71% | Training loss: 0.6870782143929426
Epoch: 20 | Iteration number: [3240/4518] 71% | Training loss: 0.6870767584737436
Epoch: 20 | Iteration number: [3250/4518] 71% | Training loss: 0.6870789902393635
Epoch: 20 | Iteration number: [3260/4518] 72% | Training loss: 0.6870811481234486
Epoch: 20 | Iteration number: [3270/4518] 72% | Training loss: 0.687082655550143
Epoch: 20 | Iteration number: [3280/4518] 72% | Training loss: 0.6870836627737777
Epoch: 20 | Iteration number: [3290/4518] 72% | Training loss: 0.6870867165751008
Epoch: 20 | Iteration number: [3300/4518] 73% | Training loss: 0.687086445183465
Epoch: 20 | Iteration number: [3310/4518] 73% | Training loss: 0.6870881400439675
Epoch: 20 | Iteration number: [3320/4518] 73% | Training loss: 0.6870863271764962
Epoch: 20 | Iteration number: [3330/4518] 73% | Training loss: 0.6870876298294412
Epoch: 20 | Iteration number: [3340/4518] 73% | Training loss: 0.6870845646023036
Epoch: 20 | Iteration number: [3350/4518] 74% | Training loss: 0.6870817146550363
Epoch: 20 | Iteration number: [3360/4518] 74% | Training loss: 0.6870769390570266
Epoch: 20 | Iteration number: [3370/4518] 74% | Training loss: 0.6870781543877429
Epoch: 20 | Iteration number: [3380/4518] 74% | Training loss: 0.6870781820024965
Epoch: 20 | Iteration number: [3390/4518] 75% | Training loss: 0.6870764855965752
Epoch: 20 | Iteration number: [3400/4518] 75% | Training loss: 0.6870789567337316
Epoch: 20 | Iteration number: [3410/4518] 75% | Training loss: 0.6870830572595344
Epoch: 20 | Iteration number: [3420/4518] 75% | Training loss: 0.6870812068208616
Epoch: 20 | Iteration number: [3430/4518] 75% | Training loss: 0.6870817908392703
Epoch: 20 | Iteration number: [3440/4518] 76% | Training loss: 0.6870782620165237
Epoch: 20 | Iteration number: [3450/4518] 76% | Training loss: 0.6870754562944605
Epoch: 20 | Iteration number: [3460/4518] 76% | Training loss: 0.6870741187664815
Epoch: 20 | Iteration number: [3470/4518] 76% | Training loss: 0.6870703969118575
Epoch: 20 | Iteration number: [3480/4518] 77% | Training loss: 0.6870666056015026
Epoch: 20 | Iteration number: [3490/4518] 77% | Training loss: 0.6870686699121251
Epoch: 20 | Iteration number: [3500/4518] 77% | Training loss: 0.6870698047706059
Epoch: 20 | Iteration number: [3510/4518] 77% | Training loss: 0.6870664094078575
Epoch: 20 | Iteration number: [3520/4518] 77% | Training loss: 0.6870645900341598
Epoch: 20 | Iteration number: [3530/4518] 78% | Training loss: 0.6870652797708431
Epoch: 20 | Iteration number: [3540/4518] 78% | Training loss: 0.6870634129828652
Epoch: 20 | Iteration number: [3550/4518] 78% | Training loss: 0.6870620797553533
Epoch: 20 | Iteration number: [3560/4518] 78% | Training loss: 0.6870631560515822
Epoch: 20 | Iteration number: [3570/4518] 79% | Training loss: 0.687059400362127
Epoch: 20 | Iteration number: [3580/4518] 79% | Training loss: 0.6870591708568221
Epoch: 20 | Iteration number: [3590/4518] 79% | Training loss: 0.6870582757886073
Epoch: 20 | Iteration number: [3600/4518] 79% | Training loss: 0.6870537514322334
Epoch: 20 | Iteration number: [3610/4518] 79% | Training loss: 0.6870564353598122
Epoch: 20 | Iteration number: [3620/4518] 80% | Training loss: 0.6870585731379893
Epoch: 20 | Iteration number: [3630/4518] 80% | Training loss: 0.6870600708424224
Epoch: 20 | Iteration number: [3640/4518] 80% | Training loss: 0.687060897903783
Epoch: 20 | Iteration number: [3650/4518] 80% | Training loss: 0.6870603302080337
Epoch: 20 | Iteration number: [3660/4518] 81% | Training loss: 0.6870618568092096
Epoch: 20 | Iteration number: [3670/4518] 81% | Training loss: 0.6870609183727233
Epoch: 20 | Iteration number: [3680/4518] 81% | Training loss: 0.6870616009215946
Epoch: 20 | Iteration number: [3690/4518] 81% | Training loss: 0.6870621061583522
Epoch: 20 | Iteration number: [3700/4518] 81% | Training loss: 0.6870616044386013
Epoch: 20 | Iteration number: [3710/4518] 82% | Training loss: 0.6870585800823819
Epoch: 20 | Iteration number: [3720/4518] 82% | Training loss: 0.6870592271448464
Epoch: 20 | Iteration number: [3730/4518] 82% | Training loss: 0.6870582640810243
Epoch: 20 | Iteration number: [3740/4518] 82% | Training loss: 0.6870581833117786
Epoch: 20 | Iteration number: [3750/4518] 83% | Training loss: 0.6870613219896953
Epoch: 20 | Iteration number: [3760/4518] 83% | Training loss: 0.687063373546017
Epoch: 20 | Iteration number: [3770/4518] 83% | Training loss: 0.6870616151894435
Epoch: 20 | Iteration number: [3780/4518] 83% | Training loss: 0.6870631338900359
Epoch: 20 | Iteration number: [3790/4518] 83% | Training loss: 0.6870652039164289
Epoch: 20 | Iteration number: [3800/4518] 84% | Training loss: 0.687063665437071
Epoch: 20 | Iteration number: [3810/4518] 84% | Training loss: 0.6870667806447648
Epoch: 20 | Iteration number: [3820/4518] 84% | Training loss: 0.6870691535672592
Epoch: 20 | Iteration number: [3830/4518] 84% | Training loss: 0.6870683746611792
Epoch: 20 | Iteration number: [3840/4518] 84% | Training loss: 0.6870708426460623
Epoch: 20 | Iteration number: [3850/4518] 85% | Training loss: 0.6870693846646841
Epoch: 20 | Iteration number: [3860/4518] 85% | Training loss: 0.6870723782580134
Epoch: 20 | Iteration number: [3870/4518] 85% | Training loss: 0.6870758238380885
Epoch: 20 | Iteration number: [3880/4518] 85% | Training loss: 0.6870765673591919
Epoch: 20 | Iteration number: [3890/4518] 86% | Training loss: 0.6870772368497284
Epoch: 20 | Iteration number: [3900/4518] 86% | Training loss: 0.6870793318595642
Epoch: 20 | Iteration number: [3910/4518] 86% | Training loss: 0.6870770122846375
Epoch: 20 | Iteration number: [3920/4518] 86% | Training loss: 0.6870784928299942
Epoch: 20 | Iteration number: [3930/4518] 86% | Training loss: 0.6870810435776795
Epoch: 20 | Iteration number: [3940/4518] 87% | Training loss: 0.687081245450199
Epoch: 20 | Iteration number: [3950/4518] 87% | Training loss: 0.6870805471758299
Epoch: 20 | Iteration number: [3960/4518] 87% | Training loss: 0.6870793811450101
Epoch: 20 | Iteration number: [3970/4518] 87% | Training loss: 0.6870775500382824
Epoch: 20 | Iteration number: [3980/4518] 88% | Training loss: 0.6870778382423535
Epoch: 20 | Iteration number: [3990/4518] 88% | Training loss: 0.6870781796767299
Epoch: 20 | Iteration number: [4000/4518] 88% | Training loss: 0.6870750040709972
Epoch: 20 | Iteration number: [4010/4518] 88% | Training loss: 0.6870766640452672
Epoch: 20 | Iteration number: [4020/4518] 88% | Training loss: 0.6870783046999974
Epoch: 20 | Iteration number: [4030/4518] 89% | Training loss: 0.687077747754956
Epoch: 20 | Iteration number: [4040/4518] 89% | Training loss: 0.6870770677629083
Epoch: 20 | Iteration number: [4050/4518] 89% | Training loss: 0.687074362113152
Epoch: 20 | Iteration number: [4060/4518] 89% | Training loss: 0.6870769973899343
Epoch: 20 | Iteration number: [4070/4518] 90% | Training loss: 0.6870803644674709
Epoch: 20 | Iteration number: [4080/4518] 90% | Training loss: 0.6870801848085487
Epoch: 20 | Iteration number: [4090/4518] 90% | Training loss: 0.6870822274597467
Epoch: 20 | Iteration number: [4100/4518] 90% | Training loss: 0.6870790622437872
Epoch: 20 | Iteration number: [4110/4518] 90% | Training loss: 0.6870805417099138
Epoch: 20 | Iteration number: [4120/4518] 91% | Training loss: 0.6870807915781308
Epoch: 20 | Iteration number: [4130/4518] 91% | Training loss: 0.6870808051515722
Epoch: 20 | Iteration number: [4140/4518] 91% | Training loss: 0.6870784097823543
Epoch: 20 | Iteration number: [4150/4518] 91% | Training loss: 0.6870781302164836
Epoch: 20 | Iteration number: [4160/4518] 92% | Training loss: 0.6870766922401694
Epoch: 20 | Iteration number: [4170/4518] 92% | Training loss: 0.6870782467529928
Epoch: 20 | Iteration number: [4180/4518] 92% | Training loss: 0.6870793430713945
Epoch: 20 | Iteration number: [4190/4518] 92% | Training loss: 0.6870803609810467
Epoch: 20 | Iteration number: [4200/4518] 92% | Training loss: 0.6870779251058896
Epoch: 20 | Iteration number: [4210/4518] 93% | Training loss: 0.6870793749912334
Epoch: 20 | Iteration number: [4220/4518] 93% | Training loss: 0.6870776348486896
Epoch: 20 | Iteration number: [4230/4518] 93% | Training loss: 0.687077085529377
Epoch: 20 | Iteration number: [4240/4518] 93% | Training loss: 0.6870787830004152
Epoch: 20 | Iteration number: [4250/4518] 94% | Training loss: 0.6870769345479854
Epoch: 20 | Iteration number: [4260/4518] 94% | Training loss: 0.687076079397694
Epoch: 20 | Iteration number: [4270/4518] 94% | Training loss: 0.6870736231290205
Epoch: 20 | Iteration number: [4280/4518] 94% | Training loss: 0.6870726260069375
Epoch: 20 | Iteration number: [4290/4518] 94% | Training loss: 0.6870708205483177
Epoch: 20 | Iteration number: [4300/4518] 95% | Training loss: 0.6870700908261677
Epoch: 20 | Iteration number: [4310/4518] 95% | Training loss: 0.6870685718452294
Epoch: 20 | Iteration number: [4320/4518] 95% | Training loss: 0.6870663452065653
Epoch: 20 | Iteration number: [4330/4518] 95% | Training loss: 0.6870632278313538
Epoch: 20 | Iteration number: [4340/4518] 96% | Training loss: 0.6870637567361928
Epoch: 20 | Iteration number: [4350/4518] 96% | Training loss: 0.6870613821484577
Epoch: 20 | Iteration number: [4360/4518] 96% | Training loss: 0.6870611825257267
Epoch: 20 | Iteration number: [4370/4518] 96% | Training loss: 0.6870621295351731
Epoch: 20 | Iteration number: [4380/4518] 96% | Training loss: 0.6870582935744769
Epoch: 20 | Iteration number: [4390/4518] 97% | Training loss: 0.6870588185303846
Epoch: 20 | Iteration number: [4400/4518] 97% | Training loss: 0.6870547864382918
Epoch: 20 | Iteration number: [4410/4518] 97% | Training loss: 0.6870532769194536
Epoch: 20 | Iteration number: [4420/4518] 97% | Training loss: 0.6870545431095011
Epoch: 20 | Iteration number: [4430/4518] 98% | Training loss: 0.6870547443964681
Epoch: 20 | Iteration number: [4440/4518] 98% | Training loss: 0.687053096294403
Epoch: 20 | Iteration number: [4450/4518] 98% | Training loss: 0.6870540623450547
Epoch: 20 | Iteration number: [4460/4518] 98% | Training loss: 0.6870524378100853
Epoch: 20 | Iteration number: [4470/4518] 98% | Training loss: 0.6870514648472703
Epoch: 20 | Iteration number: [4480/4518] 99% | Training loss: 0.687048238036888
Epoch: 20 | Iteration number: [4490/4518] 99% | Training loss: 0.6870482362192829
Epoch: 20 | Iteration number: [4500/4518] 99% | Training loss: 0.6870471565061146
Epoch: 20 | Iteration number: [4510/4518] 99% | Training loss: 0.6870489568905925

 End of epoch: 20 | Train Loss: 0.6868973783208713 | Training Time: 641 

 End of epoch: 20 | Eval Loss: 0.6904715956473837 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/4518] 0% | Training loss: 0.7547136723995209
Epoch: 21 | Iteration number: [20/4518] 0% | Training loss: 0.7209123998880387
Epoch: 21 | Iteration number: [30/4518] 0% | Training loss: 0.7093928674856822
Epoch: 21 | Iteration number: [40/4518] 0% | Training loss: 0.7035901069641113
Epoch: 21 | Iteration number: [50/4518] 1% | Training loss: 0.7000016164779663
Epoch: 21 | Iteration number: [60/4518] 1% | Training loss: 0.6979421824216843
Epoch: 21 | Iteration number: [70/4518] 1% | Training loss: 0.6962953703744071
Epoch: 21 | Iteration number: [80/4518] 1% | Training loss: 0.6951514981687069
Epoch: 21 | Iteration number: [90/4518] 1% | Training loss: 0.6941837509473164
Epoch: 21 | Iteration number: [100/4518] 2% | Training loss: 0.6933777421712876
Epoch: 21 | Iteration number: [110/4518] 2% | Training loss: 0.6927092823115262
Epoch: 21 | Iteration number: [120/4518] 2% | Training loss: 0.6922294050455093
Epoch: 21 | Iteration number: [130/4518] 2% | Training loss: 0.6917127256210034
Epoch: 21 | Iteration number: [140/4518] 3% | Training loss: 0.6914921781846455
Epoch: 21 | Iteration number: [150/4518] 3% | Training loss: 0.6911943646272024
Epoch: 21 | Iteration number: [160/4518] 3% | Training loss: 0.6909143257886171
Epoch: 21 | Iteration number: [170/4518] 3% | Training loss: 0.6906801164150238
Epoch: 21 | Iteration number: [180/4518] 3% | Training loss: 0.690433320734236
Epoch: 21 | Iteration number: [190/4518] 4% | Training loss: 0.690284213894292
Epoch: 21 | Iteration number: [200/4518] 4% | Training loss: 0.6900720134377479
Epoch: 21 | Iteration number: [210/4518] 4% | Training loss: 0.6899231215318044
Epoch: 21 | Iteration number: [220/4518] 4% | Training loss: 0.6898470065810464
Epoch: 21 | Iteration number: [230/4518] 5% | Training loss: 0.6897454621999161
Epoch: 21 | Iteration number: [240/4518] 5% | Training loss: 0.689593585083882
Epoch: 21 | Iteration number: [250/4518] 5% | Training loss: 0.6894952220916748
Epoch: 21 | Iteration number: [260/4518] 5% | Training loss: 0.6893817372046984
Epoch: 21 | Iteration number: [270/4518] 5% | Training loss: 0.689297984264515
Epoch: 21 | Iteration number: [280/4518] 6% | Training loss: 0.6892232379743031
Epoch: 21 | Iteration number: [290/4518] 6% | Training loss: 0.6891748436566056
Epoch: 21 | Iteration number: [300/4518] 6% | Training loss: 0.6891147814194362
Epoch: 21 | Iteration number: [310/4518] 6% | Training loss: 0.6890839899739911
Epoch: 21 | Iteration number: [320/4518] 7% | Training loss: 0.6890588566660881
Epoch: 21 | Iteration number: [330/4518] 7% | Training loss: 0.6889965900869081
Epoch: 21 | Iteration number: [340/4518] 7% | Training loss: 0.6889307528734208
Epoch: 21 | Iteration number: [350/4518] 7% | Training loss: 0.6888629155499595
Epoch: 21 | Iteration number: [360/4518] 7% | Training loss: 0.6887728656331699
Epoch: 21 | Iteration number: [370/4518] 8% | Training loss: 0.6887092142491728
Epoch: 21 | Iteration number: [380/4518] 8% | Training loss: 0.6886601871565768
Epoch: 21 | Iteration number: [390/4518] 8% | Training loss: 0.6886177400747935
Epoch: 21 | Iteration number: [400/4518] 8% | Training loss: 0.688590911924839
Epoch: 21 | Iteration number: [410/4518] 9% | Training loss: 0.6885072552576298
Epoch: 21 | Iteration number: [420/4518] 9% | Training loss: 0.68848956823349
Epoch: 21 | Iteration number: [430/4518] 9% | Training loss: 0.6884374251199323
Epoch: 21 | Iteration number: [440/4518] 9% | Training loss: 0.6883776597001335
Epoch: 21 | Iteration number: [450/4518] 9% | Training loss: 0.6883477045430078
Epoch: 21 | Iteration number: [460/4518] 10% | Training loss: 0.6883225790832354
Epoch: 21 | Iteration number: [470/4518] 10% | Training loss: 0.6883030770940983
Epoch: 21 | Iteration number: [480/4518] 10% | Training loss: 0.68828152778248
Epoch: 21 | Iteration number: [490/4518] 10% | Training loss: 0.6882412422676476
Epoch: 21 | Iteration number: [500/4518] 11% | Training loss: 0.6882308576107025
Epoch: 21 | Iteration number: [510/4518] 11% | Training loss: 0.6881989537500868
Epoch: 21 | Iteration number: [520/4518] 11% | Training loss: 0.6881909509117786
Epoch: 21 | Iteration number: [530/4518] 11% | Training loss: 0.6881790142014341
Epoch: 21 | Iteration number: [540/4518] 11% | Training loss: 0.6881414070173546
Epoch: 21 | Iteration number: [550/4518] 12% | Training loss: 0.688121508359909
Epoch: 21 | Iteration number: [560/4518] 12% | Training loss: 0.6881262827132429
Epoch: 21 | Iteration number: [570/4518] 12% | Training loss: 0.6881226951615852
Epoch: 21 | Iteration number: [580/4518] 12% | Training loss: 0.68810142987761
Epoch: 21 | Iteration number: [590/4518] 13% | Training loss: 0.6880865687030857
Epoch: 21 | Iteration number: [600/4518] 13% | Training loss: 0.6880704808235169
Epoch: 21 | Iteration number: [610/4518] 13% | Training loss: 0.6880271031231177
Epoch: 21 | Iteration number: [620/4518] 13% | Training loss: 0.6880196812652772
Epoch: 21 | Iteration number: [630/4518] 13% | Training loss: 0.6880153874556224
Epoch: 21 | Iteration number: [640/4518] 14% | Training loss: 0.6880180417560041
Epoch: 21 | Iteration number: [650/4518] 14% | Training loss: 0.6879930090904236
Epoch: 21 | Iteration number: [660/4518] 14% | Training loss: 0.6879674502394416
Epoch: 21 | Iteration number: [670/4518] 14% | Training loss: 0.687963600389993
Epoch: 21 | Iteration number: [680/4518] 15% | Training loss: 0.6879586673834744
Epoch: 21 | Iteration number: [690/4518] 15% | Training loss: 0.6879440940808559
Epoch: 21 | Iteration number: [700/4518] 15% | Training loss: 0.6879207542112895
Epoch: 21 | Iteration number: [710/4518] 15% | Training loss: 0.6879224846900349
Epoch: 21 | Iteration number: [720/4518] 15% | Training loss: 0.6879075484971205
Epoch: 21 | Iteration number: [730/4518] 16% | Training loss: 0.6878861226447641
Epoch: 21 | Iteration number: [740/4518] 16% | Training loss: 0.6878923408083013
Epoch: 21 | Iteration number: [750/4518] 16% | Training loss: 0.6878733588854472
Epoch: 21 | Iteration number: [760/4518] 16% | Training loss: 0.6878356638707612
Epoch: 21 | Iteration number: [770/4518] 17% | Training loss: 0.6878306493356631
Epoch: 21 | Iteration number: [780/4518] 17% | Training loss: 0.6878294119468102
Epoch: 21 | Iteration number: [790/4518] 17% | Training loss: 0.687822129303896
Epoch: 21 | Iteration number: [800/4518] 17% | Training loss: 0.6878022666275502
Epoch: 21 | Iteration number: [810/4518] 17% | Training loss: 0.6878011233276791
Epoch: 21 | Iteration number: [820/4518] 18% | Training loss: 0.6877836319004617
Epoch: 21 | Iteration number: [830/4518] 18% | Training loss: 0.6877823944551399
Epoch: 21 | Iteration number: [840/4518] 18% | Training loss: 0.687767896269049
Epoch: 21 | Iteration number: [850/4518] 18% | Training loss: 0.6877410232319552
Epoch: 21 | Iteration number: [860/4518] 19% | Training loss: 0.6877305574888407
Epoch: 21 | Iteration number: [870/4518] 19% | Training loss: 0.6877295802379476
Epoch: 21 | Iteration number: [880/4518] 19% | Training loss: 0.687702743912285
Epoch: 21 | Iteration number: [890/4518] 19% | Training loss: 0.6876914992091361
Epoch: 21 | Iteration number: [900/4518] 19% | Training loss: 0.687681046658092
Epoch: 21 | Iteration number: [910/4518] 20% | Training loss: 0.6876767692330119
Epoch: 21 | Iteration number: [920/4518] 20% | Training loss: 0.6876690295079481
Epoch: 21 | Iteration number: [930/4518] 20% | Training loss: 0.6876441615243112
Epoch: 21 | Iteration number: [940/4518] 20% | Training loss: 0.6876242011151416
Epoch: 21 | Iteration number: [950/4518] 21% | Training loss: 0.6876133414946104
Epoch: 21 | Iteration number: [960/4518] 21% | Training loss: 0.6876082252711058
Epoch: 21 | Iteration number: [970/4518] 21% | Training loss: 0.6876063466686564
Epoch: 21 | Iteration number: [980/4518] 21% | Training loss: 0.6875978480796425
Epoch: 21 | Iteration number: [990/4518] 21% | Training loss: 0.687588427102927
Epoch: 21 | Iteration number: [1000/4518] 22% | Training loss: 0.6875763214826583
Epoch: 21 | Iteration number: [1010/4518] 22% | Training loss: 0.6875769397999981
Epoch: 21 | Iteration number: [1020/4518] 22% | Training loss: 0.6875837156001259
Epoch: 21 | Iteration number: [1030/4518] 22% | Training loss: 0.6875701567501697
Epoch: 21 | Iteration number: [1040/4518] 23% | Training loss: 0.6875693347018499
Epoch: 21 | Iteration number: [1050/4518] 23% | Training loss: 0.6875579772676741
Epoch: 21 | Iteration number: [1060/4518] 23% | Training loss: 0.6875511197548992
Epoch: 21 | Iteration number: [1070/4518] 23% | Training loss: 0.6875507377018438
Epoch: 21 | Iteration number: [1080/4518] 23% | Training loss: 0.6875427310113553
Epoch: 21 | Iteration number: [1090/4518] 24% | Training loss: 0.6875251120930418
Epoch: 21 | Iteration number: [1100/4518] 24% | Training loss: 0.6875217520106922
Epoch: 21 | Iteration number: [1110/4518] 24% | Training loss: 0.6875142462081737
Epoch: 21 | Iteration number: [1120/4518] 24% | Training loss: 0.687511156765478
Epoch: 21 | Iteration number: [1130/4518] 25% | Training loss: 0.6875015389075322
Epoch: 21 | Iteration number: [1140/4518] 25% | Training loss: 0.6874927827140741
Epoch: 21 | Iteration number: [1150/4518] 25% | Training loss: 0.687488062640895
Epoch: 21 | Iteration number: [1160/4518] 25% | Training loss: 0.6874659117953531
Epoch: 21 | Iteration number: [1170/4518] 25% | Training loss: 0.6874625755680932
Epoch: 21 | Iteration number: [1180/4518] 26% | Training loss: 0.6874572592266536
Epoch: 21 | Iteration number: [1190/4518] 26% | Training loss: 0.6874618906433843
Epoch: 21 | Iteration number: [1200/4518] 26% | Training loss: 0.6874481760462126
Epoch: 21 | Iteration number: [1210/4518] 26% | Training loss: 0.687438220721631
Epoch: 21 | Iteration number: [1220/4518] 27% | Training loss: 0.6874336482071486
Epoch: 21 | Iteration number: [1230/4518] 27% | Training loss: 0.6874300174112242
Epoch: 21 | Iteration number: [1240/4518] 27% | Training loss: 0.6874236752909999
Epoch: 21 | Iteration number: [1250/4518] 27% | Training loss: 0.6874207897663116
Epoch: 21 | Iteration number: [1260/4518] 27% | Training loss: 0.6874126264973293
Epoch: 21 | Iteration number: [1270/4518] 28% | Training loss: 0.6874168535855811
Epoch: 21 | Iteration number: [1280/4518] 28% | Training loss: 0.6874025834724307
Epoch: 21 | Iteration number: [1290/4518] 28% | Training loss: 0.6873977884303691
Epoch: 21 | Iteration number: [1300/4518] 28% | Training loss: 0.6873975529120518
Epoch: 21 | Iteration number: [1310/4518] 28% | Training loss: 0.6874017737748969
Epoch: 21 | Iteration number: [1320/4518] 29% | Training loss: 0.6874051014582316
Epoch: 21 | Iteration number: [1330/4518] 29% | Training loss: 0.6874080008582065
Epoch: 21 | Iteration number: [1340/4518] 29% | Training loss: 0.6874037283125208
Epoch: 21 | Iteration number: [1350/4518] 29% | Training loss: 0.6874097464702748
Epoch: 21 | Iteration number: [1360/4518] 30% | Training loss: 0.6874067921410588
Epoch: 21 | Iteration number: [1370/4518] 30% | Training loss: 0.6874008763445555
Epoch: 21 | Iteration number: [1380/4518] 30% | Training loss: 0.6874066765325657
Epoch: 21 | Iteration number: [1390/4518] 30% | Training loss: 0.6873957441436301
Epoch: 21 | Iteration number: [1400/4518] 30% | Training loss: 0.6873890565548624
Epoch: 21 | Iteration number: [1410/4518] 31% | Training loss: 0.6873942162128205
Epoch: 21 | Iteration number: [1420/4518] 31% | Training loss: 0.6873973678535139
Epoch: 21 | Iteration number: [1430/4518] 31% | Training loss: 0.6873901678132011
Epoch: 21 | Iteration number: [1440/4518] 31% | Training loss: 0.6873847720937596
Epoch: 21 | Iteration number: [1450/4518] 32% | Training loss: 0.6873731288416632
Epoch: 21 | Iteration number: [1460/4518] 32% | Training loss: 0.6873656793816448
Epoch: 21 | Iteration number: [1470/4518] 32% | Training loss: 0.6873628792714099
Epoch: 21 | Iteration number: [1480/4518] 32% | Training loss: 0.6873614379683056
Epoch: 21 | Iteration number: [1490/4518] 32% | Training loss: 0.6873554169731653
Epoch: 21 | Iteration number: [1500/4518] 33% | Training loss: 0.6873463519414266
Epoch: 21 | Iteration number: [1510/4518] 33% | Training loss: 0.6873371582552297
Epoch: 21 | Iteration number: [1520/4518] 33% | Training loss: 0.6873369512589355
Epoch: 21 | Iteration number: [1530/4518] 33% | Training loss: 0.6873358309268951
Epoch: 21 | Iteration number: [1540/4518] 34% | Training loss: 0.6873353605146532
Epoch: 21 | Iteration number: [1550/4518] 34% | Training loss: 0.6873382058835799
Epoch: 21 | Iteration number: [1560/4518] 34% | Training loss: 0.6873376148633468
Epoch: 21 | Iteration number: [1570/4518] 34% | Training loss: 0.6873351022316392
Epoch: 21 | Iteration number: [1580/4518] 34% | Training loss: 0.6873247532150414
Epoch: 21 | Iteration number: [1590/4518] 35% | Training loss: 0.6873177592109584
Epoch: 21 | Iteration number: [1600/4518] 35% | Training loss: 0.6873079363256693
Epoch: 21 | Iteration number: [1610/4518] 35% | Training loss: 0.6873035311328698
Epoch: 21 | Iteration number: [1620/4518] 35% | Training loss: 0.6872906786792072
Epoch: 21 | Iteration number: [1630/4518] 36% | Training loss: 0.6872870021071171
Epoch: 21 | Iteration number: [1640/4518] 36% | Training loss: 0.6872929810387333
Epoch: 21 | Iteration number: [1650/4518] 36% | Training loss: 0.6872885862986247
Epoch: 21 | Iteration number: [1660/4518] 36% | Training loss: 0.6872886642275087
Epoch: 21 | Iteration number: [1670/4518] 36% | Training loss: 0.6872900023788749
Epoch: 21 | Iteration number: [1680/4518] 37% | Training loss: 0.687295169773556
Epoch: 21 | Iteration number: [1690/4518] 37% | Training loss: 0.687296561447121
Epoch: 21 | Iteration number: [1700/4518] 37% | Training loss: 0.6872990068617989
Epoch: 21 | Iteration number: [1710/4518] 37% | Training loss: 0.6873034493267884
Epoch: 21 | Iteration number: [1720/4518] 38% | Training loss: 0.6873003424253574
Epoch: 21 | Iteration number: [1730/4518] 38% | Training loss: 0.6872995519224618
Epoch: 21 | Iteration number: [1740/4518] 38% | Training loss: 0.6872971482318023
Epoch: 21 | Iteration number: [1750/4518] 38% | Training loss: 0.6872949753148215
Epoch: 21 | Iteration number: [1760/4518] 38% | Training loss: 0.6872925343499943
Epoch: 21 | Iteration number: [1770/4518] 39% | Training loss: 0.6872863020937322
Epoch: 21 | Iteration number: [1780/4518] 39% | Training loss: 0.6872820795252083
Epoch: 21 | Iteration number: [1790/4518] 39% | Training loss: 0.6872734380833929
Epoch: 21 | Iteration number: [1800/4518] 39% | Training loss: 0.6872731137275696
Epoch: 21 | Iteration number: [1810/4518] 40% | Training loss: 0.6872743037853452
Epoch: 21 | Iteration number: [1820/4518] 40% | Training loss: 0.6872743123507762
Epoch: 21 | Iteration number: [1830/4518] 40% | Training loss: 0.6872702760123164
Epoch: 21 | Iteration number: [1840/4518] 40% | Training loss: 0.6872740029964758
Epoch: 21 | Iteration number: [1850/4518] 40% | Training loss: 0.6872648215616072
Epoch: 21 | Iteration number: [1860/4518] 41% | Training loss: 0.6872552529458077
Epoch: 21 | Iteration number: [1870/4518] 41% | Training loss: 0.6872524879195473
Epoch: 21 | Iteration number: [1880/4518] 41% | Training loss: 0.6872541538261353
Epoch: 21 | Iteration number: [1890/4518] 41% | Training loss: 0.6872533018626864
Epoch: 21 | Iteration number: [1900/4518] 42% | Training loss: 0.6872530968251981
Epoch: 21 | Iteration number: [1910/4518] 42% | Training loss: 0.6872407164873253
Epoch: 21 | Iteration number: [1920/4518] 42% | Training loss: 0.6872320227635403
Epoch: 21 | Iteration number: [1930/4518] 42% | Training loss: 0.6872316788206446
Epoch: 21 | Iteration number: [1940/4518] 42% | Training loss: 0.6872272469948247
Epoch: 21 | Iteration number: [1950/4518] 43% | Training loss: 0.6872306349032965
Epoch: 21 | Iteration number: [1960/4518] 43% | Training loss: 0.6872313876845398
Epoch: 21 | Iteration number: [1970/4518] 43% | Training loss: 0.6872309708050665
Epoch: 21 | Iteration number: [1980/4518] 43% | Training loss: 0.6872299522462517
Epoch: 21 | Iteration number: [1990/4518] 44% | Training loss: 0.6872297469095968
Epoch: 21 | Iteration number: [2000/4518] 44% | Training loss: 0.6872306811511517
Epoch: 21 | Iteration number: [2010/4518] 44% | Training loss: 0.6872293849193042
Epoch: 21 | Iteration number: [2020/4518] 44% | Training loss: 0.6872327315335226
Epoch: 21 | Iteration number: [2030/4518] 44% | Training loss: 0.6872283912644598
Epoch: 21 | Iteration number: [2040/4518] 45% | Training loss: 0.6872212942032253
Epoch: 21 | Iteration number: [2050/4518] 45% | Training loss: 0.6872168722676067
Epoch: 21 | Iteration number: [2060/4518] 45% | Training loss: 0.6872205146597427
Epoch: 21 | Iteration number: [2070/4518] 45% | Training loss: 0.6872116060072673
Epoch: 21 | Iteration number: [2080/4518] 46% | Training loss: 0.6872135606236183
Epoch: 21 | Iteration number: [2090/4518] 46% | Training loss: 0.6872064960630316
Epoch: 21 | Iteration number: [2100/4518] 46% | Training loss: 0.687202050742649
Epoch: 21 | Iteration number: [2110/4518] 46% | Training loss: 0.6872037679098228
Epoch: 21 | Iteration number: [2120/4518] 46% | Training loss: 0.6872007610944082
Epoch: 21 | Iteration number: [2130/4518] 47% | Training loss: 0.6872058812721235
Epoch: 21 | Iteration number: [2140/4518] 47% | Training loss: 0.6872041509530254
Epoch: 21 | Iteration number: [2150/4518] 47% | Training loss: 0.6872024334308713
Epoch: 21 | Iteration number: [2160/4518] 47% | Training loss: 0.6872031066152785
Epoch: 21 | Iteration number: [2170/4518] 48% | Training loss: 0.6872035700329987
Epoch: 21 | Iteration number: [2180/4518] 48% | Training loss: 0.6872030530774266
Epoch: 21 | Iteration number: [2190/4518] 48% | Training loss: 0.687201390745433
Epoch: 21 | Iteration number: [2200/4518] 48% | Training loss: 0.6871919098496437
Epoch: 21 | Iteration number: [2210/4518] 48% | Training loss: 0.6871895566245549
Epoch: 21 | Iteration number: [2220/4518] 49% | Training loss: 0.6871831730679349
Epoch: 21 | Iteration number: [2230/4518] 49% | Training loss: 0.6871763575504714
Epoch: 21 | Iteration number: [2240/4518] 49% | Training loss: 0.6871727795207074
Epoch: 21 | Iteration number: [2250/4518] 49% | Training loss: 0.6871660325262282
Epoch: 21 | Iteration number: [2260/4518] 50% | Training loss: 0.68716564497589
Epoch: 21 | Iteration number: [2270/4518] 50% | Training loss: 0.6871600575909216
Epoch: 21 | Iteration number: [2280/4518] 50% | Training loss: 0.6871605478096426
Epoch: 21 | Iteration number: [2290/4518] 50% | Training loss: 0.6871600026386794
Epoch: 21 | Iteration number: [2300/4518] 50% | Training loss: 0.6871598298912462
Epoch: 21 | Iteration number: [2310/4518] 51% | Training loss: 0.6871639008387859
Epoch: 21 | Iteration number: [2320/4518] 51% | Training loss: 0.687160595634888
Epoch: 21 | Iteration number: [2330/4518] 51% | Training loss: 0.6871623536803692
Epoch: 21 | Iteration number: [2340/4518] 51% | Training loss: 0.6871557504702837
Epoch: 21 | Iteration number: [2350/4518] 52% | Training loss: 0.6871558428317942
Epoch: 21 | Iteration number: [2360/4518] 52% | Training loss: 0.6871569725669037
Epoch: 21 | Iteration number: [2370/4518] 52% | Training loss: 0.6871579934776081
Epoch: 21 | Iteration number: [2380/4518] 52% | Training loss: 0.6871559665233147
Epoch: 21 | Iteration number: [2390/4518] 52% | Training loss: 0.6871586653228584
Epoch: 21 | Iteration number: [2400/4518] 53% | Training loss: 0.6871619060883919
Epoch: 21 | Iteration number: [2410/4518] 53% | Training loss: 0.6871629473826697
Epoch: 21 | Iteration number: [2420/4518] 53% | Training loss: 0.6871641608801755
Epoch: 21 | Iteration number: [2430/4518] 53% | Training loss: 0.6871601811161747
Epoch: 21 | Iteration number: [2440/4518] 54% | Training loss: 0.6871574680824749
Epoch: 21 | Iteration number: [2450/4518] 54% | Training loss: 0.6871566637438171
Epoch: 21 | Iteration number: [2460/4518] 54% | Training loss: 0.6871582555577038
Epoch: 21 | Iteration number: [2470/4518] 54% | Training loss: 0.6871517981594873
Epoch: 21 | Iteration number: [2480/4518] 54% | Training loss: 0.6871504679322242
Epoch: 21 | Iteration number: [2490/4518] 55% | Training loss: 0.6871459172193305
Epoch: 21 | Iteration number: [2500/4518] 55% | Training loss: 0.6871415937900544
Epoch: 21 | Iteration number: [2510/4518] 55% | Training loss: 0.687143238393434
Epoch: 21 | Iteration number: [2520/4518] 55% | Training loss: 0.6871461480855942
Epoch: 21 | Iteration number: [2530/4518] 55% | Training loss: 0.6871376009326678
Epoch: 21 | Iteration number: [2540/4518] 56% | Training loss: 0.687138832741835
Epoch: 21 | Iteration number: [2550/4518] 56% | Training loss: 0.6871338295469097
Epoch: 21 | Iteration number: [2560/4518] 56% | Training loss: 0.6871369038941338
Epoch: 21 | Iteration number: [2570/4518] 56% | Training loss: 0.6871346459778367
Epoch: 21 | Iteration number: [2580/4518] 57% | Training loss: 0.6871346924425096
Epoch: 21 | Iteration number: [2590/4518] 57% | Training loss: 0.6871367455679478
Epoch: 21 | Iteration number: [2600/4518] 57% | Training loss: 0.6871335254953458
Epoch: 21 | Iteration number: [2610/4518] 57% | Training loss: 0.6871326083881188
Epoch: 21 | Iteration number: [2620/4518] 57% | Training loss: 0.6871299181730692
Epoch: 21 | Iteration number: [2630/4518] 58% | Training loss: 0.6871261020350365
Epoch: 21 | Iteration number: [2640/4518] 58% | Training loss: 0.6871238499879837
Epoch: 21 | Iteration number: [2650/4518] 58% | Training loss: 0.6871158232329027
Epoch: 21 | Iteration number: [2660/4518] 58% | Training loss: 0.687113042343828
Epoch: 21 | Iteration number: [2670/4518] 59% | Training loss: 0.6871117371298401
Epoch: 21 | Iteration number: [2680/4518] 59% | Training loss: 0.6871139343772361
Epoch: 21 | Iteration number: [2690/4518] 59% | Training loss: 0.6871136087245657
Epoch: 21 | Iteration number: [2700/4518] 59% | Training loss: 0.6871098554134369
Epoch: 21 | Iteration number: [2710/4518] 59% | Training loss: 0.6871073070927299
Epoch: 21 | Iteration number: [2720/4518] 60% | Training loss: 0.6871107920785161
Epoch: 21 | Iteration number: [2730/4518] 60% | Training loss: 0.6871009755265581
Epoch: 21 | Iteration number: [2740/4518] 60% | Training loss: 0.6871000158090661
Epoch: 21 | Iteration number: [2750/4518] 60% | Training loss: 0.6870970601818779
Epoch: 21 | Iteration number: [2760/4518] 61% | Training loss: 0.6870983171290246
Epoch: 21 | Iteration number: [2770/4518] 61% | Training loss: 0.6870938882931045
Epoch: 21 | Iteration number: [2780/4518] 61% | Training loss: 0.6870897425378827
Epoch: 21 | Iteration number: [2790/4518] 61% | Training loss: 0.6870900796733023
Epoch: 21 | Iteration number: [2800/4518] 61% | Training loss: 0.6870863937905857
Epoch: 21 | Iteration number: [2810/4518] 62% | Training loss: 0.6870820753090746
Epoch: 21 | Iteration number: [2820/4518] 62% | Training loss: 0.6870754723007797
Epoch: 21 | Iteration number: [2830/4518] 62% | Training loss: 0.687075367959565
Epoch: 21 | Iteration number: [2840/4518] 62% | Training loss: 0.6870721719004739
Epoch: 21 | Iteration number: [2850/4518] 63% | Training loss: 0.6870703103458672
Epoch: 21 | Iteration number: [2860/4518] 63% | Training loss: 0.6870681736227515
Epoch: 21 | Iteration number: [2870/4518] 63% | Training loss: 0.6870688202073765
Epoch: 21 | Iteration number: [2880/4518] 63% | Training loss: 0.6870645965552993
Epoch: 21 | Iteration number: [2890/4518] 63% | Training loss: 0.6870656330692727
Epoch: 21 | Iteration number: [2900/4518] 64% | Training loss: 0.6870664455561802
Epoch: 21 | Iteration number: [2910/4518] 64% | Training loss: 0.6870700541025995
Epoch: 21 | Iteration number: [2920/4518] 64% | Training loss: 0.6870713202512427
Epoch: 21 | Iteration number: [2930/4518] 64% | Training loss: 0.6870692335908324
Epoch: 21 | Iteration number: [2940/4518] 65% | Training loss: 0.6870694640947848
Epoch: 21 | Iteration number: [2950/4518] 65% | Training loss: 0.6870643350835574
Epoch: 21 | Iteration number: [2960/4518] 65% | Training loss: 0.6870636955507704
Epoch: 21 | Iteration number: [2970/4518] 65% | Training loss: 0.6870640150625698
Epoch: 21 | Iteration number: [2980/4518] 65% | Training loss: 0.6870656956762276
Epoch: 21 | Iteration number: [2990/4518] 66% | Training loss: 0.687066132507994
Epoch: 21 | Iteration number: [3000/4518] 66% | Training loss: 0.6870625531474749
Epoch: 21 | Iteration number: [3010/4518] 66% | Training loss: 0.6870613679339324
Epoch: 21 | Iteration number: [3020/4518] 66% | Training loss: 0.6870606271636407
Epoch: 21 | Iteration number: [3030/4518] 67% | Training loss: 0.6870615287385758
Epoch: 21 | Iteration number: [3040/4518] 67% | Training loss: 0.6870609254429215
Epoch: 21 | Iteration number: [3050/4518] 67% | Training loss: 0.6870579418979708
Epoch: 21 | Iteration number: [3060/4518] 67% | Training loss: 0.6870614225373549
Epoch: 21 | Iteration number: [3070/4518] 67% | Training loss: 0.6870622574894747
Epoch: 21 | Iteration number: [3080/4518] 68% | Training loss: 0.6870624597583498
Epoch: 21 | Iteration number: [3090/4518] 68% | Training loss: 0.6870643350877422
Epoch: 21 | Iteration number: [3100/4518] 68% | Training loss: 0.6870674028704243
Epoch: 21 | Iteration number: [3110/4518] 68% | Training loss: 0.6870638321450285
Epoch: 21 | Iteration number: [3120/4518] 69% | Training loss: 0.6870650936586734
Epoch: 21 | Iteration number: [3130/4518] 69% | Training loss: 0.6870626928897712
Epoch: 21 | Iteration number: [3140/4518] 69% | Training loss: 0.6870620027659046
Epoch: 21 | Iteration number: [3150/4518] 69% | Training loss: 0.6870623532174126
Epoch: 21 | Iteration number: [3160/4518] 69% | Training loss: 0.6870648260169392
Epoch: 21 | Iteration number: [3170/4518] 70% | Training loss: 0.6870646735847185
Epoch: 21 | Iteration number: [3180/4518] 70% | Training loss: 0.6870648236582114
Epoch: 21 | Iteration number: [3190/4518] 70% | Training loss: 0.6870647728629994
Epoch: 21 | Iteration number: [3200/4518] 70% | Training loss: 0.6870673253946006
Epoch: 21 | Iteration number: [3210/4518] 71% | Training loss: 0.6870689499601026
Epoch: 21 | Iteration number: [3220/4518] 71% | Training loss: 0.6870711396384683
Epoch: 21 | Iteration number: [3230/4518] 71% | Training loss: 0.6870735265337646
Epoch: 21 | Iteration number: [3240/4518] 71% | Training loss: 0.6870779065806188
Epoch: 21 | Iteration number: [3250/4518] 71% | Training loss: 0.6870766068238479
Epoch: 21 | Iteration number: [3260/4518] 72% | Training loss: 0.6870735899436693
Epoch: 21 | Iteration number: [3270/4518] 72% | Training loss: 0.6870727116543948
Epoch: 21 | Iteration number: [3280/4518] 72% | Training loss: 0.6870737746176196
Epoch: 21 | Iteration number: [3290/4518] 72% | Training loss: 0.687071177825377
Epoch: 21 | Iteration number: [3300/4518] 73% | Training loss: 0.6870728900396462
Epoch: 21 | Iteration number: [3310/4518] 73% | Training loss: 0.687070104308719
Epoch: 21 | Iteration number: [3320/4518] 73% | Training loss: 0.6870677211737058
Epoch: 21 | Iteration number: [3330/4518] 73% | Training loss: 0.687065252939144
Epoch: 21 | Iteration number: [3340/4518] 73% | Training loss: 0.6870652382602235
Epoch: 21 | Iteration number: [3350/4518] 74% | Training loss: 0.6870632079821914
Epoch: 21 | Iteration number: [3360/4518] 74% | Training loss: 0.6870597651317006
Epoch: 21 | Iteration number: [3370/4518] 74% | Training loss: 0.6870593775273784
Epoch: 21 | Iteration number: [3380/4518] 74% | Training loss: 0.6870587207509216
Epoch: 21 | Iteration number: [3390/4518] 75% | Training loss: 0.6870593310105766
Epoch: 21 | Iteration number: [3400/4518] 75% | Training loss: 0.6870592265970566
Epoch: 21 | Iteration number: [3410/4518] 75% | Training loss: 0.6870598985302833
Epoch: 21 | Iteration number: [3420/4518] 75% | Training loss: 0.6870634256399166
Epoch: 21 | Iteration number: [3430/4518] 75% | Training loss: 0.6870652837412697
Epoch: 21 | Iteration number: [3440/4518] 76% | Training loss: 0.6870649181306362
Epoch: 21 | Iteration number: [3450/4518] 76% | Training loss: 0.687065247470054
Epoch: 21 | Iteration number: [3460/4518] 76% | Training loss: 0.6870670414212122
Epoch: 21 | Iteration number: [3470/4518] 76% | Training loss: 0.68706750204996
Epoch: 21 | Iteration number: [3480/4518] 77% | Training loss: 0.6870701707813932
Epoch: 21 | Iteration number: [3490/4518] 77% | Training loss: 0.6870714790499995
Epoch: 21 | Iteration number: [3500/4518] 77% | Training loss: 0.6870720041479383
Epoch: 21 | Iteration number: [3510/4518] 77% | Training loss: 0.6870750079297612
Epoch: 21 | Iteration number: [3520/4518] 77% | Training loss: 0.6870785892009735
Epoch: 21 | Iteration number: [3530/4518] 78% | Training loss: 0.6870775089723192
Epoch: 21 | Iteration number: [3540/4518] 78% | Training loss: 0.6870782704003113
Epoch: 21 | Iteration number: [3550/4518] 78% | Training loss: 0.687078926160302
Epoch: 21 | Iteration number: [3560/4518] 78% | Training loss: 0.6870808580953084
Epoch: 21 | Iteration number: [3570/4518] 79% | Training loss: 0.6870803688253675
Epoch: 21 | Iteration number: [3580/4518] 79% | Training loss: 0.687079392015601
Epoch: 21 | Iteration number: [3590/4518] 79% | Training loss: 0.6870829317397061
Epoch: 21 | Iteration number: [3600/4518] 79% | Training loss: 0.6870864570637544
Epoch: 21 | Iteration number: [3610/4518] 79% | Training loss: 0.6870893956386481
Epoch: 21 | Iteration number: [3620/4518] 80% | Training loss: 0.6870880360596746
Epoch: 21 | Iteration number: [3630/4518] 80% | Training loss: 0.6870887600029139
Epoch: 21 | Iteration number: [3640/4518] 80% | Training loss: 0.6870864708508764
Epoch: 21 | Iteration number: [3650/4518] 80% | Training loss: 0.6870837670972902
Epoch: 21 | Iteration number: [3660/4518] 81% | Training loss: 0.687081006820736
Epoch: 21 | Iteration number: [3670/4518] 81% | Training loss: 0.6870798662670302
Epoch: 21 | Iteration number: [3680/4518] 81% | Training loss: 0.6870796386314475
Epoch: 21 | Iteration number: [3690/4518] 81% | Training loss: 0.6870802593101977
Epoch: 21 | Iteration number: [3700/4518] 81% | Training loss: 0.6870813963703207
Epoch: 21 | Iteration number: [3710/4518] 82% | Training loss: 0.6870827576863476
Epoch: 21 | Iteration number: [3720/4518] 82% | Training loss: 0.6870839615983347
Epoch: 21 | Iteration number: [3730/4518] 82% | Training loss: 0.6870834084042915
Epoch: 21 | Iteration number: [3740/4518] 82% | Training loss: 0.6870817891257331
Epoch: 21 | Iteration number: [3750/4518] 83% | Training loss: 0.6870767965793609
Epoch: 21 | Iteration number: [3760/4518] 83% | Training loss: 0.6870775484816826
Epoch: 21 | Iteration number: [3770/4518] 83% | Training loss: 0.6870759708969916
Epoch: 21 | Iteration number: [3780/4518] 83% | Training loss: 0.6870764452786673
Epoch: 21 | Iteration number: [3790/4518] 83% | Training loss: 0.6870816485705665
Epoch: 21 | Iteration number: [3800/4518] 84% | Training loss: 0.6870783539822227
Epoch: 21 | Iteration number: [3810/4518] 84% | Training loss: 0.6870776245913167
Epoch: 21 | Iteration number: [3820/4518] 84% | Training loss: 0.6870778479033116
Epoch: 21 | Iteration number: [3830/4518] 84% | Training loss: 0.6870766482838763
Epoch: 21 | Iteration number: [3840/4518] 84% | Training loss: 0.6870756399196883
Epoch: 21 | Iteration number: [3850/4518] 85% | Training loss: 0.6870764699694398
Epoch: 21 | Iteration number: [3860/4518] 85% | Training loss: 0.6870795682767512
Epoch: 21 | Iteration number: [3870/4518] 85% | Training loss: 0.6870790491270464
Epoch: 21 | Iteration number: [3880/4518] 85% | Training loss: 0.6870830333417224
Epoch: 21 | Iteration number: [3890/4518] 86% | Training loss: 0.6870788946709474
Epoch: 21 | Iteration number: [3900/4518] 86% | Training loss: 0.687075086862613
Epoch: 21 | Iteration number: [3910/4518] 86% | Training loss: 0.68707423048556
Epoch: 21 | Iteration number: [3920/4518] 86% | Training loss: 0.687074941609587
Epoch: 21 | Iteration number: [3930/4518] 86% | Training loss: 0.6870741581188814
Epoch: 21 | Iteration number: [3940/4518] 87% | Training loss: 0.6870724032978116
Epoch: 21 | Iteration number: [3950/4518] 87% | Training loss: 0.687071827800968
Epoch: 21 | Iteration number: [3960/4518] 87% | Training loss: 0.6870717151146947
Epoch: 21 | Iteration number: [3970/4518] 87% | Training loss: 0.6870701819433073
Epoch: 21 | Iteration number: [3980/4518] 88% | Training loss: 0.6870708190765812
Epoch: 21 | Iteration number: [3990/4518] 88% | Training loss: 0.6870701519319586
Epoch: 21 | Iteration number: [4000/4518] 88% | Training loss: 0.6870719618797302
Epoch: 21 | Iteration number: [4010/4518] 88% | Training loss: 0.6870736766039879
Epoch: 21 | Iteration number: [4020/4518] 88% | Training loss: 0.6870728999524567
Epoch: 21 | Iteration number: [4030/4518] 89% | Training loss: 0.6870696636198768
Epoch: 21 | Iteration number: [4040/4518] 89% | Training loss: 0.687070122331676
Epoch: 21 | Iteration number: [4050/4518] 89% | Training loss: 0.6870721456592466
Epoch: 21 | Iteration number: [4060/4518] 89% | Training loss: 0.687070354481636
Epoch: 21 | Iteration number: [4070/4518] 90% | Training loss: 0.6870696870935051
Epoch: 21 | Iteration number: [4080/4518] 90% | Training loss: 0.687070520295232
Epoch: 21 | Iteration number: [4090/4518] 90% | Training loss: 0.6870705092594501
Epoch: 21 | Iteration number: [4100/4518] 90% | Training loss: 0.6870667728127503
Epoch: 21 | Iteration number: [4110/4518] 90% | Training loss: 0.6870686573268723
Epoch: 21 | Iteration number: [4120/4518] 91% | Training loss: 0.6870685094334547
Epoch: 21 | Iteration number: [4130/4518] 91% | Training loss: 0.6870651080879692
Epoch: 21 | Iteration number: [4140/4518] 91% | Training loss: 0.6870640657374248
Epoch: 21 | Iteration number: [4150/4518] 91% | Training loss: 0.6870622236757393
Epoch: 21 | Iteration number: [4160/4518] 92% | Training loss: 0.6870667046938951
Epoch: 21 | Iteration number: [4170/4518] 92% | Training loss: 0.6870674435326235
Epoch: 21 | Iteration number: [4180/4518] 92% | Training loss: 0.6870656615381606
Epoch: 21 | Iteration number: [4190/4518] 92% | Training loss: 0.6870633321189653
Epoch: 21 | Iteration number: [4200/4518] 92% | Training loss: 0.6870623533356758
Epoch: 21 | Iteration number: [4210/4518] 93% | Training loss: 0.6870629486307113
Epoch: 21 | Iteration number: [4220/4518] 93% | Training loss: 0.6870637113307889
Epoch: 21 | Iteration number: [4230/4518] 93% | Training loss: 0.6870649903237679
Epoch: 21 | Iteration number: [4240/4518] 93% | Training loss: 0.6870666083440465
Epoch: 21 | Iteration number: [4250/4518] 94% | Training loss: 0.6870673347501194
Epoch: 21 | Iteration number: [4260/4518] 94% | Training loss: 0.6870670073608838
Epoch: 21 | Iteration number: [4270/4518] 94% | Training loss: 0.6870641970941557
Epoch: 21 | Iteration number: [4280/4518] 94% | Training loss: 0.687062900186142
Epoch: 21 | Iteration number: [4290/4518] 94% | Training loss: 0.6870619890156325
Epoch: 21 | Iteration number: [4300/4518] 95% | Training loss: 0.6870632674389108
Epoch: 21 | Iteration number: [4310/4518] 95% | Training loss: 0.6870612929702635
Epoch: 21 | Iteration number: [4320/4518] 95% | Training loss: 0.6870584064059787
Epoch: 21 | Iteration number: [4330/4518] 95% | Training loss: 0.6870607991003825
Epoch: 21 | Iteration number: [4340/4518] 96% | Training loss: 0.6870590737750454
Epoch: 21 | Iteration number: [4350/4518] 96% | Training loss: 0.6870587661485562
Epoch: 21 | Iteration number: [4360/4518] 96% | Training loss: 0.6870580933509617
Epoch: 21 | Iteration number: [4370/4518] 96% | Training loss: 0.6870566080855014
Epoch: 21 | Iteration number: [4380/4518] 96% | Training loss: 0.6870596455248523
Epoch: 21 | Iteration number: [4390/4518] 97% | Training loss: 0.6870560822155589
Epoch: 21 | Iteration number: [4400/4518] 97% | Training loss: 0.6870548812503164
Epoch: 21 | Iteration number: [4410/4518] 97% | Training loss: 0.6870548832443566
Epoch: 21 | Iteration number: [4420/4518] 97% | Training loss: 0.6870553598954128
Epoch: 21 | Iteration number: [4430/4518] 98% | Training loss: 0.6870543251053743
Epoch: 21 | Iteration number: [4440/4518] 98% | Training loss: 0.6870529517934129
Epoch: 21 | Iteration number: [4450/4518] 98% | Training loss: 0.6870513297198864
Epoch: 21 | Iteration number: [4460/4518] 98% | Training loss: 0.6870509279014818
Epoch: 21 | Iteration number: [4470/4518] 98% | Training loss: 0.6870526463926772
Epoch: 21 | Iteration number: [4480/4518] 99% | Training loss: 0.6870533758375261
Epoch: 21 | Iteration number: [4490/4518] 99% | Training loss: 0.6870551085020757
Epoch: 21 | Iteration number: [4500/4518] 99% | Training loss: 0.6870538103845384
Epoch: 21 | Iteration number: [4510/4518] 99% | Training loss: 0.6870517446830902

 End of epoch: 21 | Train Loss: 0.6868996216613352 | Training Time: 642 

 End of epoch: 21 | Eval Loss: 0.6903325136826963 | Evaluating Time: 17 
Epoch: 22 | Iteration number: [10/4518] 0% | Training loss: 0.7558527648448944
Epoch: 22 | Iteration number: [20/4518] 0% | Training loss: 0.7213767319917679
Epoch: 22 | Iteration number: [30/4518] 0% | Training loss: 0.7097876052061717
Epoch: 22 | Iteration number: [40/4518] 0% | Training loss: 0.7041245147585868
Epoch: 22 | Iteration number: [50/4518] 1% | Training loss: 0.70079718708992
Epoch: 22 | Iteration number: [60/4518] 1% | Training loss: 0.6983446667591731
Epoch: 22 | Iteration number: [70/4518] 1% | Training loss: 0.6967378718512399
Epoch: 22 | Iteration number: [80/4518] 1% | Training loss: 0.6955789655447007
Epoch: 22 | Iteration number: [90/4518] 1% | Training loss: 0.6946351230144501
Epoch: 22 | Iteration number: [100/4518] 2% | Training loss: 0.6937901282310486
Epoch: 22 | Iteration number: [110/4518] 2% | Training loss: 0.6931546959010038
Epoch: 22 | Iteration number: [120/4518] 2% | Training loss: 0.6926554481188456
Epoch: 22 | Iteration number: [130/4518] 2% | Training loss: 0.6922631768079904
Epoch: 22 | Iteration number: [140/4518] 3% | Training loss: 0.6918188716684069
Epoch: 22 | Iteration number: [150/4518] 3% | Training loss: 0.6915136313438416
Epoch: 22 | Iteration number: [160/4518] 3% | Training loss: 0.6911765016615391
Epoch: 22 | Iteration number: [170/4518] 3% | Training loss: 0.6908744948751786
Epoch: 22 | Iteration number: [180/4518] 3% | Training loss: 0.6905706786447101
Epoch: 22 | Iteration number: [190/4518] 4% | Training loss: 0.6903829756535982
Epoch: 22 | Iteration number: [200/4518] 4% | Training loss: 0.6902247068285942
Epoch: 22 | Iteration number: [210/4518] 4% | Training loss: 0.6900838116804758
Epoch: 22 | Iteration number: [220/4518] 4% | Training loss: 0.6898788530718196
Epoch: 22 | Iteration number: [230/4518] 5% | Training loss: 0.6897582927475805
Epoch: 22 | Iteration number: [240/4518] 5% | Training loss: 0.6895959377288818
Epoch: 22 | Iteration number: [250/4518] 5% | Training loss: 0.6895230844020843
Epoch: 22 | Iteration number: [260/4518] 5% | Training loss: 0.6894356184280835
Epoch: 22 | Iteration number: [270/4518] 5% | Training loss: 0.6893543439882773
Epoch: 22 | Iteration number: [280/4518] 6% | Training loss: 0.689297405736787
Epoch: 22 | Iteration number: [290/4518] 6% | Training loss: 0.6892259914299538
Epoch: 22 | Iteration number: [300/4518] 6% | Training loss: 0.689139950076739
Epoch: 22 | Iteration number: [310/4518] 6% | Training loss: 0.6890760740926188
Epoch: 22 | Iteration number: [320/4518] 7% | Training loss: 0.6889980360865593
Epoch: 22 | Iteration number: [330/4518] 7% | Training loss: 0.6889532352938796
Epoch: 22 | Iteration number: [340/4518] 7% | Training loss: 0.6889300853013992
Epoch: 22 | Iteration number: [350/4518] 7% | Training loss: 0.6888824783052717
Epoch: 22 | Iteration number: [360/4518] 7% | Training loss: 0.6888673242595461
Epoch: 22 | Iteration number: [370/4518] 8% | Training loss: 0.6888161151795774
Epoch: 22 | Iteration number: [380/4518] 8% | Training loss: 0.6887741065339038
Epoch: 22 | Iteration number: [390/4518] 8% | Training loss: 0.6887230260249896
Epoch: 22 | Iteration number: [400/4518] 8% | Training loss: 0.6886534015834331
Epoch: 22 | Iteration number: [410/4518] 9% | Training loss: 0.6885996255932785
Epoch: 22 | Iteration number: [420/4518] 9% | Training loss: 0.6885711796226955
Epoch: 22 | Iteration number: [430/4518] 9% | Training loss: 0.6885244838027067
Epoch: 22 | Iteration number: [440/4518] 9% | Training loss: 0.6885088048198006
Epoch: 22 | Iteration number: [450/4518] 9% | Training loss: 0.688479314910041
Epoch: 22 | Iteration number: [460/4518] 10% | Training loss: 0.6884405093348545
Epoch: 22 | Iteration number: [470/4518] 10% | Training loss: 0.6884093313775164
Epoch: 22 | Iteration number: [480/4518] 10% | Training loss: 0.6883437648415566
Epoch: 22 | Iteration number: [490/4518] 10% | Training loss: 0.6883162688235848
Epoch: 22 | Iteration number: [500/4518] 11% | Training loss: 0.688304728269577
Epoch: 22 | Iteration number: [510/4518] 11% | Training loss: 0.6882888210754768
Epoch: 22 | Iteration number: [520/4518] 11% | Training loss: 0.688274795619341
Epoch: 22 | Iteration number: [530/4518] 11% | Training loss: 0.6882558920473423
Epoch: 22 | Iteration number: [540/4518] 11% | Training loss: 0.6882508207250524
Epoch: 22 | Iteration number: [550/4518] 12% | Training loss: 0.6882425433939153
Epoch: 22 | Iteration number: [560/4518] 12% | Training loss: 0.6882122015314442
Epoch: 22 | Iteration number: [570/4518] 12% | Training loss: 0.6881853122460214
Epoch: 22 | Iteration number: [580/4518] 12% | Training loss: 0.6881662655493309
Epoch: 22 | Iteration number: [590/4518] 13% | Training loss: 0.6881525065939306
Epoch: 22 | Iteration number: [600/4518] 13% | Training loss: 0.6881320457657178
Epoch: 22 | Iteration number: [610/4518] 13% | Training loss: 0.688125863524734
Epoch: 22 | Iteration number: [620/4518] 13% | Training loss: 0.6880891891256455
Epoch: 22 | Iteration number: [630/4518] 13% | Training loss: 0.6880661042909774
Epoch: 22 | Iteration number: [640/4518] 14% | Training loss: 0.6880488993600011
Epoch: 22 | Iteration number: [650/4518] 14% | Training loss: 0.6880421546789316
Epoch: 22 | Iteration number: [660/4518] 14% | Training loss: 0.6880385414217458
Epoch: 22 | Iteration number: [670/4518] 14% | Training loss: 0.6880246180206983
Epoch: 22 | Iteration number: [680/4518] 15% | Training loss: 0.6879921486272531
Epoch: 22 | Iteration number: [690/4518] 15% | Training loss: 0.6879891166652459
Epoch: 22 | Iteration number: [700/4518] 15% | Training loss: 0.6879647971902575
Epoch: 22 | Iteration number: [710/4518] 15% | Training loss: 0.6879585981369019
Epoch: 22 | Iteration number: [720/4518] 15% | Training loss: 0.6879469653798475
Epoch: 22 | Iteration number: [730/4518] 16% | Training loss: 0.6879288704427954
Epoch: 22 | Iteration number: [740/4518] 16% | Training loss: 0.6878965683885523
Epoch: 22 | Iteration number: [750/4518] 16% | Training loss: 0.6878762490749359
Epoch: 22 | Iteration number: [760/4518] 16% | Training loss: 0.6878551237677273
Epoch: 22 | Iteration number: [770/4518] 17% | Training loss: 0.6878216275147029
Epoch: 22 | Iteration number: [780/4518] 17% | Training loss: 0.6878202825784683
Epoch: 22 | Iteration number: [790/4518] 17% | Training loss: 0.687821967541417
Epoch: 22 | Iteration number: [800/4518] 17% | Training loss: 0.6878217104822397
Epoch: 22 | Iteration number: [810/4518] 17% | Training loss: 0.6878209053734202
Epoch: 22 | Iteration number: [820/4518] 18% | Training loss: 0.6878243394014312
Epoch: 22 | Iteration number: [830/4518] 18% | Training loss: 0.6878116015210209
Epoch: 22 | Iteration number: [840/4518] 18% | Training loss: 0.6878046645295053
Epoch: 22 | Iteration number: [850/4518] 18% | Training loss: 0.68779312154826
Epoch: 22 | Iteration number: [860/4518] 19% | Training loss: 0.6877933836260507
Epoch: 22 | Iteration number: [870/4518] 19% | Training loss: 0.6877798797755406
Epoch: 22 | Iteration number: [880/4518] 19% | Training loss: 0.6877711508084428
Epoch: 22 | Iteration number: [890/4518] 19% | Training loss: 0.6877534613180696
Epoch: 22 | Iteration number: [900/4518] 19% | Training loss: 0.687740793161922
Epoch: 22 | Iteration number: [910/4518] 20% | Training loss: 0.6877267078383938
Epoch: 22 | Iteration number: [920/4518] 20% | Training loss: 0.6877363412924434
Epoch: 22 | Iteration number: [930/4518] 20% | Training loss: 0.6877207845769903
Epoch: 22 | Iteration number: [940/4518] 20% | Training loss: 0.6877128788765441
Epoch: 22 | Iteration number: [950/4518] 21% | Training loss: 0.6877113502276572
Epoch: 22 | Iteration number: [960/4518] 21% | Training loss: 0.6876991125444571
Epoch: 22 | Iteration number: [970/4518] 21% | Training loss: 0.6876942517216673
Epoch: 22 | Iteration number: [980/4518] 21% | Training loss: 0.687685977317849
Epoch: 22 | Iteration number: [990/4518] 21% | Training loss: 0.687670992058937
Epoch: 22 | Iteration number: [1000/4518] 22% | Training loss: 0.6876620973944664
Epoch: 22 | Iteration number: [1010/4518] 22% | Training loss: 0.6876373759590754
Epoch: 22 | Iteration number: [1020/4518] 22% | Training loss: 0.6876153769446355
Epoch: 22 | Iteration number: [1030/4518] 22% | Training loss: 0.68760673646788
Epoch: 22 | Iteration number: [1040/4518] 23% | Training loss: 0.6876024101789181
Epoch: 22 | Iteration number: [1050/4518] 23% | Training loss: 0.687606110402516
Epoch: 22 | Iteration number: [1060/4518] 23% | Training loss: 0.6876066589130545
Epoch: 22 | Iteration number: [1070/4518] 23% | Training loss: 0.6876025290132683
Epoch: 22 | Iteration number: [1080/4518] 23% | Training loss: 0.6876012260715166
Epoch: 22 | Iteration number: [1090/4518] 24% | Training loss: 0.6875916728185951
Epoch: 22 | Iteration number: [1100/4518] 24% | Training loss: 0.6875787795673717
Epoch: 22 | Iteration number: [1110/4518] 24% | Training loss: 0.6875762927639592
Epoch: 22 | Iteration number: [1120/4518] 24% | Training loss: 0.6875768807849714
Epoch: 22 | Iteration number: [1130/4518] 25% | Training loss: 0.687566174237074
Epoch: 22 | Iteration number: [1140/4518] 25% | Training loss: 0.6875653705053162
Epoch: 22 | Iteration number: [1150/4518] 25% | Training loss: 0.6875609356424083
Epoch: 22 | Iteration number: [1160/4518] 25% | Training loss: 0.6875602051615715
Epoch: 22 | Iteration number: [1170/4518] 25% | Training loss: 0.6875466441496825
Epoch: 22 | Iteration number: [1180/4518] 26% | Training loss: 0.6875469966460083
Epoch: 22 | Iteration number: [1190/4518] 26% | Training loss: 0.6875513910746374
Epoch: 22 | Iteration number: [1200/4518] 26% | Training loss: 0.6875548582772414
Epoch: 22 | Iteration number: [1210/4518] 26% | Training loss: 0.6875381195348156
Epoch: 22 | Iteration number: [1220/4518] 27% | Training loss: 0.6875303200033844
Epoch: 22 | Iteration number: [1230/4518] 27% | Training loss: 0.6875243202457583
Epoch: 22 | Iteration number: [1240/4518] 27% | Training loss: 0.6875239419840997
Epoch: 22 | Iteration number: [1250/4518] 27% | Training loss: 0.6875217234611511
Epoch: 22 | Iteration number: [1260/4518] 27% | Training loss: 0.6875154967345889
Epoch: 22 | Iteration number: [1270/4518] 28% | Training loss: 0.6875133819467439
Epoch: 22 | Iteration number: [1280/4518] 28% | Training loss: 0.6875084476079791
Epoch: 22 | Iteration number: [1290/4518] 28% | Training loss: 0.6875041044497675
Epoch: 22 | Iteration number: [1300/4518] 28% | Training loss: 0.6875075808855203
Epoch: 22 | Iteration number: [1310/4518] 28% | Training loss: 0.6875038815363673
Epoch: 22 | Iteration number: [1320/4518] 29% | Training loss: 0.6875132033770734
Epoch: 22 | Iteration number: [1330/4518] 29% | Training loss: 0.6875089254146232
Epoch: 22 | Iteration number: [1340/4518] 29% | Training loss: 0.6875170575593834
Epoch: 22 | Iteration number: [1350/4518] 29% | Training loss: 0.6875201394822863
Epoch: 22 | Iteration number: [1360/4518] 30% | Training loss: 0.6875172728124787
Epoch: 22 | Iteration number: [1370/4518] 30% | Training loss: 0.6875147409247656
Epoch: 22 | Iteration number: [1380/4518] 30% | Training loss: 0.6875120221704677
Epoch: 22 | Iteration number: [1390/4518] 30% | Training loss: 0.6874985544801616
Epoch: 22 | Iteration number: [1400/4518] 30% | Training loss: 0.6874981783117566
Epoch: 22 | Iteration number: [1410/4518] 31% | Training loss: 0.6874941219674781
Epoch: 22 | Iteration number: [1420/4518] 31% | Training loss: 0.6874886305399344
Epoch: 22 | Iteration number: [1430/4518] 31% | Training loss: 0.6874771936373277
Epoch: 22 | Iteration number: [1440/4518] 31% | Training loss: 0.6874649102075232
Epoch: 22 | Iteration number: [1450/4518] 32% | Training loss: 0.6874710596840957
Epoch: 22 | Iteration number: [1460/4518] 32% | Training loss: 0.6874719684254633
Epoch: 22 | Iteration number: [1470/4518] 32% | Training loss: 0.6874797516939591
Epoch: 22 | Iteration number: [1480/4518] 32% | Training loss: 0.68747096303347
Epoch: 22 | Iteration number: [1490/4518] 32% | Training loss: 0.6874674057400466
Epoch: 22 | Iteration number: [1500/4518] 33% | Training loss: 0.6874638959169388
Epoch: 22 | Iteration number: [1510/4518] 33% | Training loss: 0.6874533596417762
Epoch: 22 | Iteration number: [1520/4518] 33% | Training loss: 0.6874550081005222
Epoch: 22 | Iteration number: [1530/4518] 33% | Training loss: 0.6874422427096398
Epoch: 22 | Iteration number: [1540/4518] 34% | Training loss: 0.6874366591890136
Epoch: 22 | Iteration number: [1550/4518] 34% | Training loss: 0.6874405643632335
Epoch: 22 | Iteration number: [1560/4518] 34% | Training loss: 0.6874417689366218
Epoch: 22 | Iteration number: [1570/4518] 34% | Training loss: 0.687445925755106
Epoch: 22 | Iteration number: [1580/4518] 34% | Training loss: 0.6874481797595567
Epoch: 22 | Iteration number: [1590/4518] 35% | Training loss: 0.6874412000179291
Epoch: 22 | Iteration number: [1600/4518] 35% | Training loss: 0.6874410163238645
Epoch: 22 | Iteration number: [1610/4518] 35% | Training loss: 0.6874382379262344
Epoch: 22 | Iteration number: [1620/4518] 35% | Training loss: 0.6874304250066663
Epoch: 22 | Iteration number: [1630/4518] 36% | Training loss: 0.687423681298648
Epoch: 22 | Iteration number: [1640/4518] 36% | Training loss: 0.6874205325434848
Epoch: 22 | Iteration number: [1650/4518] 36% | Training loss: 0.6874177771987338
Epoch: 22 | Iteration number: [1660/4518] 36% | Training loss: 0.6874149303838432
Epoch: 22 | Iteration number: [1670/4518] 36% | Training loss: 0.6874062026689153
Epoch: 22 | Iteration number: [1680/4518] 37% | Training loss: 0.6873996483782927
Epoch: 22 | Iteration number: [1690/4518] 37% | Training loss: 0.6873852148211214
Epoch: 22 | Iteration number: [1700/4518] 37% | Training loss: 0.6873840305033853
Epoch: 22 | Iteration number: [1710/4518] 37% | Training loss: 0.6873838226349033
Epoch: 22 | Iteration number: [1720/4518] 38% | Training loss: 0.6873806743081226
Epoch: 22 | Iteration number: [1730/4518] 38% | Training loss: 0.6873708691211106
Epoch: 22 | Iteration number: [1740/4518] 38% | Training loss: 0.6873658795808923
Epoch: 22 | Iteration number: [1750/4518] 38% | Training loss: 0.6873626187188284
Epoch: 22 | Iteration number: [1760/4518] 38% | Training loss: 0.6873584003949708
Epoch: 22 | Iteration number: [1770/4518] 39% | Training loss: 0.6873578650803216
Epoch: 22 | Iteration number: [1780/4518] 39% | Training loss: 0.6873597524474176
Epoch: 22 | Iteration number: [1790/4518] 39% | Training loss: 0.6873505713220415
Epoch: 22 | Iteration number: [1800/4518] 39% | Training loss: 0.6873503422405984
Epoch: 22 | Iteration number: [1810/4518] 40% | Training loss: 0.6873489386798268
Epoch: 22 | Iteration number: [1820/4518] 40% | Training loss: 0.6873472273349762
Epoch: 22 | Iteration number: [1830/4518] 40% | Training loss: 0.687343446413676
Epoch: 22 | Iteration number: [1840/4518] 40% | Training loss: 0.6873293218081412
Epoch: 22 | Iteration number: [1850/4518] 40% | Training loss: 0.6873318851638485
Epoch: 22 | Iteration number: [1860/4518] 41% | Training loss: 0.6873307753955165
Epoch: 22 | Iteration number: [1870/4518] 41% | Training loss: 0.6873260007185095
Epoch: 22 | Iteration number: [1880/4518] 41% | Training loss: 0.6873244248806162
Epoch: 22 | Iteration number: [1890/4518] 41% | Training loss: 0.6873239060558339
Epoch: 22 | Iteration number: [1900/4518] 42% | Training loss: 0.6873244389734771
Epoch: 22 | Iteration number: [1910/4518] 42% | Training loss: 0.6873196755404247
Epoch: 22 | Iteration number: [1920/4518] 42% | Training loss: 0.6873150246528288
Epoch: 22 | Iteration number: [1930/4518] 42% | Training loss: 0.6873144732855763
Epoch: 22 | Iteration number: [1940/4518] 42% | Training loss: 0.6873096519524289
Epoch: 22 | Iteration number: [1950/4518] 43% | Training loss: 0.6873110061425429
Epoch: 22 | Iteration number: [1960/4518] 43% | Training loss: 0.6873106128403119
Epoch: 22 | Iteration number: [1970/4518] 43% | Training loss: 0.6873076593512811
Epoch: 22 | Iteration number: [1980/4518] 43% | Training loss: 0.6873025342671558
Epoch: 22 | Iteration number: [1990/4518] 44% | Training loss: 0.6873002103525191
Epoch: 22 | Iteration number: [2000/4518] 44% | Training loss: 0.6872917466759682
Epoch: 22 | Iteration number: [2010/4518] 44% | Training loss: 0.6872902398678794
Epoch: 22 | Iteration number: [2020/4518] 44% | Training loss: 0.6872893791387577
Epoch: 22 | Iteration number: [2030/4518] 44% | Training loss: 0.6872822507261642
Epoch: 22 | Iteration number: [2040/4518] 45% | Training loss: 0.6872748167491427
Epoch: 22 | Iteration number: [2050/4518] 45% | Training loss: 0.6872793858807261
Epoch: 22 | Iteration number: [2060/4518] 45% | Training loss: 0.6872769044151584
Epoch: 22 | Iteration number: [2070/4518] 45% | Training loss: 0.6872729831559646
Epoch: 22 | Iteration number: [2080/4518] 46% | Training loss: 0.6872677149680945
Epoch: 22 | Iteration number: [2090/4518] 46% | Training loss: 0.687267168058733
Epoch: 22 | Iteration number: [2100/4518] 46% | Training loss: 0.687265730642137
Epoch: 22 | Iteration number: [2110/4518] 46% | Training loss: 0.6872710585029205
Epoch: 22 | Iteration number: [2120/4518] 46% | Training loss: 0.6872705590331329
Epoch: 22 | Iteration number: [2130/4518] 47% | Training loss: 0.6872678428468569
Epoch: 22 | Iteration number: [2140/4518] 47% | Training loss: 0.6872671372701075
Epoch: 22 | Iteration number: [2150/4518] 47% | Training loss: 0.687262404464012
Epoch: 22 | Iteration number: [2160/4518] 47% | Training loss: 0.6872621708170131
Epoch: 22 | Iteration number: [2170/4518] 48% | Training loss: 0.6872606726286049
Epoch: 22 | Iteration number: [2180/4518] 48% | Training loss: 0.6872615754057508
Epoch: 22 | Iteration number: [2190/4518] 48% | Training loss: 0.6872663628837289
Epoch: 22 | Iteration number: [2200/4518] 48% | Training loss: 0.6872638502717018
Epoch: 22 | Iteration number: [2210/4518] 48% | Training loss: 0.6872646473921262
Epoch: 22 | Iteration number: [2220/4518] 49% | Training loss: 0.6872589616088179
Epoch: 22 | Iteration number: [2230/4518] 49% | Training loss: 0.6872544376572152
Epoch: 22 | Iteration number: [2240/4518] 49% | Training loss: 0.6872499025559851
Epoch: 22 | Iteration number: [2250/4518] 49% | Training loss: 0.6872483481831021
Epoch: 22 | Iteration number: [2260/4518] 50% | Training loss: 0.6872422170586291
Epoch: 22 | Iteration number: [2270/4518] 50% | Training loss: 0.6872436915200187
Epoch: 22 | Iteration number: [2280/4518] 50% | Training loss: 0.6872428833654053
Epoch: 22 | Iteration number: [2290/4518] 50% | Training loss: 0.6872436154357211
Epoch: 22 | Iteration number: [2300/4518] 50% | Training loss: 0.6872429890477139
Epoch: 22 | Iteration number: [2310/4518] 51% | Training loss: 0.6872448076417436
Epoch: 22 | Iteration number: [2320/4518] 51% | Training loss: 0.6872431786152823
Epoch: 22 | Iteration number: [2330/4518] 51% | Training loss: 0.6872437985925716
Epoch: 22 | Iteration number: [2340/4518] 51% | Training loss: 0.6872450652285519
Epoch: 22 | Iteration number: [2350/4518] 52% | Training loss: 0.6872373399075041
Epoch: 22 | Iteration number: [2360/4518] 52% | Training loss: 0.6872332695429608
Epoch: 22 | Iteration number: [2370/4518] 52% | Training loss: 0.6872286643408522
Epoch: 22 | Iteration number: [2380/4518] 52% | Training loss: 0.6872295339568323
Epoch: 22 | Iteration number: [2390/4518] 52% | Training loss: 0.6872282745449114
Epoch: 22 | Iteration number: [2400/4518] 53% | Training loss: 0.6872291158139706
Epoch: 22 | Iteration number: [2410/4518] 53% | Training loss: 0.6872256834229987
Epoch: 22 | Iteration number: [2420/4518] 53% | Training loss: 0.6872240525385565
Epoch: 22 | Iteration number: [2430/4518] 53% | Training loss: 0.6872235905976943
Epoch: 22 | Iteration number: [2440/4518] 54% | Training loss: 0.687219515222995
Epoch: 22 | Iteration number: [2450/4518] 54% | Training loss: 0.6872210453967659
Epoch: 22 | Iteration number: [2460/4518] 54% | Training loss: 0.6872202529170649
Epoch: 22 | Iteration number: [2470/4518] 54% | Training loss: 0.6872239196590084
Epoch: 22 | Iteration number: [2480/4518] 54% | Training loss: 0.6872207306806118
Epoch: 22 | Iteration number: [2490/4518] 55% | Training loss: 0.6872204456463397
Epoch: 22 | Iteration number: [2500/4518] 55% | Training loss: 0.6872208269834519
Epoch: 22 | Iteration number: [2510/4518] 55% | Training loss: 0.687220547018773
Epoch: 22 | Iteration number: [2520/4518] 55% | Training loss: 0.6872205307795888
Epoch: 22 | Iteration number: [2530/4518] 55% | Training loss: 0.6872166362911345
Epoch: 22 | Iteration number: [2540/4518] 56% | Training loss: 0.6872103505951213
Epoch: 22 | Iteration number: [2550/4518] 56% | Training loss: 0.687202991808162
Epoch: 22 | Iteration number: [2560/4518] 56% | Training loss: 0.6872056931024417
Epoch: 22 | Iteration number: [2570/4518] 56% | Training loss: 0.6872058317355145
Epoch: 22 | Iteration number: [2580/4518] 57% | Training loss: 0.6872073904257412
Epoch: 22 | Iteration number: [2590/4518] 57% | Training loss: 0.6872060477503479
Epoch: 22 | Iteration number: [2600/4518] 57% | Training loss: 0.6872047577225245
Epoch: 22 | Iteration number: [2610/4518] 57% | Training loss: 0.6872039214632977
Epoch: 22 | Iteration number: [2620/4518] 57% | Training loss: 0.6871982556717996
Epoch: 22 | Iteration number: [2630/4518] 58% | Training loss: 0.6871953454987632
Epoch: 22 | Iteration number: [2640/4518] 58% | Training loss: 0.687193158946254
Epoch: 22 | Iteration number: [2650/4518] 58% | Training loss: 0.6871921045150396
Epoch: 22 | Iteration number: [2660/4518] 58% | Training loss: 0.6871887860441567
Epoch: 22 | Iteration number: [2670/4518] 59% | Training loss: 0.6871815423617202
Epoch: 22 | Iteration number: [2680/4518] 59% | Training loss: 0.6871826666726994
Epoch: 22 | Iteration number: [2690/4518] 59% | Training loss: 0.6871839222854841
Epoch: 22 | Iteration number: [2700/4518] 59% | Training loss: 0.6871818715996213
Epoch: 22 | Iteration number: [2710/4518] 59% | Training loss: 0.6871869494994188
Epoch: 22 | Iteration number: [2720/4518] 60% | Training loss: 0.6871907500002314
Epoch: 22 | Iteration number: [2730/4518] 60% | Training loss: 0.6871899945831997
Epoch: 22 | Iteration number: [2740/4518] 60% | Training loss: 0.6871901348341991
Epoch: 22 | Iteration number: [2750/4518] 60% | Training loss: 0.6871923102248799
Epoch: 22 | Iteration number: [2760/4518] 61% | Training loss: 0.6871894050335539
Epoch: 22 | Iteration number: [2770/4518] 61% | Training loss: 0.6871815648319919
Epoch: 22 | Iteration number: [2780/4518] 61% | Training loss: 0.6871864682264465
Epoch: 22 | Iteration number: [2790/4518] 61% | Training loss: 0.6871870113102766
Epoch: 22 | Iteration number: [2800/4518] 61% | Training loss: 0.6871832844614982
Epoch: 22 | Iteration number: [2810/4518] 62% | Training loss: 0.6871809775294783
Epoch: 22 | Iteration number: [2820/4518] 62% | Training loss: 0.6871791838542789
Epoch: 22 | Iteration number: [2830/4518] 62% | Training loss: 0.6871753815837968
Epoch: 22 | Iteration number: [2840/4518] 62% | Training loss: 0.687174839243083
Epoch: 22 | Iteration number: [2850/4518] 63% | Training loss: 0.6871699154586123
Epoch: 22 | Iteration number: [2860/4518] 63% | Training loss: 0.6871671207718082
Epoch: 22 | Iteration number: [2870/4518] 63% | Training loss: 0.6871658696737855
Epoch: 22 | Iteration number: [2880/4518] 63% | Training loss: 0.6871670801399483
Epoch: 22 | Iteration number: [2890/4518] 63% | Training loss: 0.6871700140637923
Epoch: 22 | Iteration number: [2900/4518] 64% | Training loss: 0.6871668282048455
Epoch: 22 | Iteration number: [2910/4518] 64% | Training loss: 0.6871676597193754
Epoch: 22 | Iteration number: [2920/4518] 64% | Training loss: 0.6871679237239982
Epoch: 22 | Iteration number: [2930/4518] 64% | Training loss: 0.6871680984521482
Epoch: 22 | Iteration number: [2940/4518] 65% | Training loss: 0.6871670128536873
Epoch: 22 | Iteration number: [2950/4518] 65% | Training loss: 0.6871680559344211
Epoch: 22 | Iteration number: [2960/4518] 65% | Training loss: 0.68716952053679
Epoch: 22 | Iteration number: [2970/4518] 65% | Training loss: 0.6871645255120916
Epoch: 22 | Iteration number: [2980/4518] 65% | Training loss: 0.6871572822732414
Epoch: 22 | Iteration number: [2990/4518] 66% | Training loss: 0.6871594421042247
Epoch: 22 | Iteration number: [3000/4518] 66% | Training loss: 0.6871578630805015
Epoch: 22 | Iteration number: [3010/4518] 66% | Training loss: 0.6871570798249735
Epoch: 22 | Iteration number: [3020/4518] 66% | Training loss: 0.6871610230562702
Epoch: 22 | Iteration number: [3030/4518] 67% | Training loss: 0.6871586159904405
Epoch: 22 | Iteration number: [3040/4518] 67% | Training loss: 0.6871533679726877
Epoch: 22 | Iteration number: [3050/4518] 67% | Training loss: 0.6871521460814555
Epoch: 22 | Iteration number: [3060/4518] 67% | Training loss: 0.6871505313449435
Epoch: 22 | Iteration number: [3070/4518] 67% | Training loss: 0.687149262467114
Epoch: 22 | Iteration number: [3080/4518] 68% | Training loss: 0.6871450032700192
Epoch: 22 | Iteration number: [3090/4518] 68% | Training loss: 0.6871463478768913
Epoch: 22 | Iteration number: [3100/4518] 68% | Training loss: 0.6871449740855925
Epoch: 22 | Iteration number: [3110/4518] 68% | Training loss: 0.6871448097121677
Epoch: 22 | Iteration number: [3120/4518] 69% | Training loss: 0.6871473198326734
Epoch: 22 | Iteration number: [3130/4518] 69% | Training loss: 0.6871450258139223
Epoch: 22 | Iteration number: [3140/4518] 69% | Training loss: 0.6871430632604915
Epoch: 22 | Iteration number: [3150/4518] 69% | Training loss: 0.6871417546461499
Epoch: 22 | Iteration number: [3160/4518] 69% | Training loss: 0.687144581181339
Epoch: 22 | Iteration number: [3170/4518] 70% | Training loss: 0.687145305206347
Epoch: 22 | Iteration number: [3180/4518] 70% | Training loss: 0.6871439153293394
Epoch: 22 | Iteration number: [3190/4518] 70% | Training loss: 0.6871402652099214
Epoch: 22 | Iteration number: [3200/4518] 70% | Training loss: 0.6871414184384048
Epoch: 22 | Iteration number: [3210/4518] 71% | Training loss: 0.6871392415877072
Epoch: 22 | Iteration number: [3220/4518] 71% | Training loss: 0.6871346437227652
Epoch: 22 | Iteration number: [3230/4518] 71% | Training loss: 0.68712665695155
Epoch: 22 | Iteration number: [3240/4518] 71% | Training loss: 0.6871261266094667
Epoch: 22 | Iteration number: [3250/4518] 71% | Training loss: 0.6871242222235753
Epoch: 22 | Iteration number: [3260/4518] 72% | Training loss: 0.687122815938815
Epoch: 22 | Iteration number: [3270/4518] 72% | Training loss: 0.6871236122164887
Epoch: 22 | Iteration number: [3280/4518] 72% | Training loss: 0.6871216092712995
Epoch: 22 | Iteration number: [3290/4518] 72% | Training loss: 0.687118814998847
Epoch: 22 | Iteration number: [3300/4518] 73% | Training loss: 0.6871184820839853
Epoch: 22 | Iteration number: [3310/4518] 73% | Training loss: 0.6871121706739293
Epoch: 22 | Iteration number: [3320/4518] 73% | Training loss: 0.6871133941663317
Epoch: 22 | Iteration number: [3330/4518] 73% | Training loss: 0.6871135848241525
Epoch: 22 | Iteration number: [3340/4518] 73% | Training loss: 0.6871100698759456
Epoch: 22 | Iteration number: [3350/4518] 74% | Training loss: 0.6871126519032379
Epoch: 22 | Iteration number: [3360/4518] 74% | Training loss: 0.6871151563312327
Epoch: 22 | Iteration number: [3370/4518] 74% | Training loss: 0.6871145933778067
Epoch: 22 | Iteration number: [3380/4518] 74% | Training loss: 0.6871138722057173
Epoch: 22 | Iteration number: [3390/4518] 75% | Training loss: 0.6871123901510661
Epoch: 22 | Iteration number: [3400/4518] 75% | Training loss: 0.6871103748679162
Epoch: 22 | Iteration number: [3410/4518] 75% | Training loss: 0.6871123581862519
Epoch: 22 | Iteration number: [3420/4518] 75% | Training loss: 0.6871118390595007
Epoch: 22 | Iteration number: [3430/4518] 75% | Training loss: 0.6871128328687596
Epoch: 22 | Iteration number: [3440/4518] 76% | Training loss: 0.6871106604677301
Epoch: 22 | Iteration number: [3450/4518] 76% | Training loss: 0.6871091628592947
Epoch: 22 | Iteration number: [3460/4518] 76% | Training loss: 0.6871055715173655
Epoch: 22 | Iteration number: [3470/4518] 76% | Training loss: 0.6871006333175241
Epoch: 22 | Iteration number: [3480/4518] 77% | Training loss: 0.6871019719147134
Epoch: 22 | Iteration number: [3490/4518] 77% | Training loss: 0.6871033590980792
Epoch: 22 | Iteration number: [3500/4518] 77% | Training loss: 0.6870985790661404
Epoch: 22 | Iteration number: [3510/4518] 77% | Training loss: 0.6871003747665645
Epoch: 22 | Iteration number: [3520/4518] 77% | Training loss: 0.6871025872162797
Epoch: 22 | Iteration number: [3530/4518] 78% | Training loss: 0.6871010241191042
Epoch: 22 | Iteration number: [3540/4518] 78% | Training loss: 0.6871002216965465
Epoch: 22 | Iteration number: [3550/4518] 78% | Training loss: 0.6870998509333167
Epoch: 22 | Iteration number: [3560/4518] 78% | Training loss: 0.687096617429444
Epoch: 22 | Iteration number: [3570/4518] 79% | Training loss: 0.6871005716444064
Epoch: 22 | Iteration number: [3580/4518] 79% | Training loss: 0.687097864377432
Epoch: 22 | Iteration number: [3590/4518] 79% | Training loss: 0.6871009524154131
Epoch: 22 | Iteration number: [3600/4518] 79% | Training loss: 0.6870984698500898
Epoch: 22 | Iteration number: [3610/4518] 79% | Training loss: 0.6870984050210494
Epoch: 22 | Iteration number: [3620/4518] 80% | Training loss: 0.6871016025707867
Epoch: 22 | Iteration number: [3630/4518] 80% | Training loss: 0.6871026350282768
Epoch: 22 | Iteration number: [3640/4518] 80% | Training loss: 0.6871017234011011
Epoch: 22 | Iteration number: [3650/4518] 80% | Training loss: 0.6870941368031175
Epoch: 22 | Iteration number: [3660/4518] 81% | Training loss: 0.6870954884206011
Epoch: 22 | Iteration number: [3670/4518] 81% | Training loss: 0.6870974630361032
Epoch: 22 | Iteration number: [3680/4518] 81% | Training loss: 0.6870990479769914
Epoch: 22 | Iteration number: [3690/4518] 81% | Training loss: 0.6871006932038924
Epoch: 22 | Iteration number: [3700/4518] 81% | Training loss: 0.6870983096393379
Epoch: 22 | Iteration number: [3710/4518] 82% | Training loss: 0.6870971885652877
Epoch: 22 | Iteration number: [3720/4518] 82% | Training loss: 0.6870968634723336
Epoch: 22 | Iteration number: [3730/4518] 82% | Training loss: 0.6870952163241184
Epoch: 22 | Iteration number: [3740/4518] 82% | Training loss: 0.6870939970972704
Epoch: 22 | Iteration number: [3750/4518] 83% | Training loss: 0.6870885328133901
Epoch: 22 | Iteration number: [3760/4518] 83% | Training loss: 0.6870876203984656
Epoch: 22 | Iteration number: [3770/4518] 83% | Training loss: 0.6870887823541222
Epoch: 22 | Iteration number: [3780/4518] 83% | Training loss: 0.6870861910165302
Epoch: 22 | Iteration number: [3790/4518] 83% | Training loss: 0.6870842437630907
Epoch: 22 | Iteration number: [3800/4518] 84% | Training loss: 0.6870840709303555
Epoch: 22 | Iteration number: [3810/4518] 84% | Training loss: 0.6870840901464927
Epoch: 22 | Iteration number: [3820/4518] 84% | Training loss: 0.6870834819465408
Epoch: 22 | Iteration number: [3830/4518] 84% | Training loss: 0.6870835028024629
Epoch: 22 | Iteration number: [3840/4518] 84% | Training loss: 0.6870840780436993
Epoch: 22 | Iteration number: [3850/4518] 85% | Training loss: 0.6870861329970421
Epoch: 22 | Iteration number: [3860/4518] 85% | Training loss: 0.6870826923167768
Epoch: 22 | Iteration number: [3870/4518] 85% | Training loss: 0.687083541823296
Epoch: 22 | Iteration number: [3880/4518] 85% | Training loss: 0.6870837308850485
Epoch: 22 | Iteration number: [3890/4518] 86% | Training loss: 0.6870835540380453
Epoch: 22 | Iteration number: [3900/4518] 86% | Training loss: 0.6870808427150433
Epoch: 22 | Iteration number: [3910/4518] 86% | Training loss: 0.6870813736068013
Epoch: 22 | Iteration number: [3920/4518] 86% | Training loss: 0.6870829154946366
Epoch: 22 | Iteration number: [3930/4518] 86% | Training loss: 0.6870811929532893
Epoch: 22 | Iteration number: [3940/4518] 87% | Training loss: 0.6870839518641457
Epoch: 22 | Iteration number: [3950/4518] 87% | Training loss: 0.6870827325235439
Epoch: 22 | Iteration number: [3960/4518] 87% | Training loss: 0.6870826040705045
Epoch: 22 | Iteration number: [3970/4518] 87% | Training loss: 0.6870832195660329
Epoch: 22 | Iteration number: [3980/4518] 88% | Training loss: 0.6870829679858146
Epoch: 22 | Iteration number: [3990/4518] 88% | Training loss: 0.6870831663297831
Epoch: 22 | Iteration number: [4000/4518] 88% | Training loss: 0.6870828859061002
Epoch: 22 | Iteration number: [4010/4518] 88% | Training loss: 0.6870817256241368
Epoch: 22 | Iteration number: [4020/4518] 88% | Training loss: 0.687081520859875
Epoch: 22 | Iteration number: [4030/4518] 89% | Training loss: 0.6870829711628906
Epoch: 22 | Iteration number: [4040/4518] 89% | Training loss: 0.6870822053734619
Epoch: 22 | Iteration number: [4050/4518] 89% | Training loss: 0.6870789581022145
Epoch: 22 | Iteration number: [4060/4518] 89% | Training loss: 0.6870773346112866
Epoch: 22 | Iteration number: [4070/4518] 90% | Training loss: 0.6870755296960217
Epoch: 22 | Iteration number: [4080/4518] 90% | Training loss: 0.6870727030377762
Epoch: 22 | Iteration number: [4090/4518] 90% | Training loss: 0.68707506532774
Epoch: 22 | Iteration number: [4100/4518] 90% | Training loss: 0.6870737539995008
Epoch: 22 | Iteration number: [4110/4518] 90% | Training loss: 0.6870739344987846
Epoch: 22 | Iteration number: [4120/4518] 91% | Training loss: 0.6870764934322209
Epoch: 22 | Iteration number: [4130/4518] 91% | Training loss: 0.6870736636492011
Epoch: 22 | Iteration number: [4140/4518] 91% | Training loss: 0.6870743177363262
Epoch: 22 | Iteration number: [4150/4518] 91% | Training loss: 0.6870770350565393
Epoch: 22 | Iteration number: [4160/4518] 92% | Training loss: 0.6870783176416388
Epoch: 22 | Iteration number: [4170/4518] 92% | Training loss: 0.687078181702456
Epoch: 22 | Iteration number: [4180/4518] 92% | Training loss: 0.687078066933098
Epoch: 22 | Iteration number: [4190/4518] 92% | Training loss: 0.6870763674413959
Epoch: 22 | Iteration number: [4200/4518] 92% | Training loss: 0.6870742738956497
Epoch: 22 | Iteration number: [4210/4518] 93% | Training loss: 0.6870750365376189
Epoch: 22 | Iteration number: [4220/4518] 93% | Training loss: 0.6870740490219605
Epoch: 22 | Iteration number: [4230/4518] 93% | Training loss: 0.6870755374290701
Epoch: 22 | Iteration number: [4240/4518] 93% | Training loss: 0.6870732568344979
Epoch: 22 | Iteration number: [4250/4518] 94% | Training loss: 0.68707272271549
Epoch: 22 | Iteration number: [4260/4518] 94% | Training loss: 0.6870691657626014
Epoch: 22 | Iteration number: [4270/4518] 94% | Training loss: 0.6870705648105094
Epoch: 22 | Iteration number: [4280/4518] 94% | Training loss: 0.6870653146198977
Epoch: 22 | Iteration number: [4290/4518] 94% | Training loss: 0.6870662517064101
Epoch: 22 | Iteration number: [4300/4518] 95% | Training loss: 0.6870636726396029
Epoch: 22 | Iteration number: [4310/4518] 95% | Training loss: 0.6870622668769686
Epoch: 22 | Iteration number: [4320/4518] 95% | Training loss: 0.6870610887391699
Epoch: 22 | Iteration number: [4330/4518] 95% | Training loss: 0.6870632127994203
Epoch: 22 | Iteration number: [4340/4518] 96% | Training loss: 0.6870613523205304
Epoch: 22 | Iteration number: [4350/4518] 96% | Training loss: 0.6870630069436698
Epoch: 22 | Iteration number: [4360/4518] 96% | Training loss: 0.6870613985378807
Epoch: 22 | Iteration number: [4370/4518] 96% | Training loss: 0.6870609346325393
Epoch: 22 | Iteration number: [4380/4518] 96% | Training loss: 0.6870601716923387
Epoch: 22 | Iteration number: [4390/4518] 97% | Training loss: 0.687056715110983
Epoch: 22 | Iteration number: [4400/4518] 97% | Training loss: 0.6870594940944151
Epoch: 22 | Iteration number: [4410/4518] 97% | Training loss: 0.6870533068299023
Epoch: 22 | Iteration number: [4420/4518] 97% | Training loss: 0.6870525406901113
Epoch: 22 | Iteration number: [4430/4518] 98% | Training loss: 0.6870493797093428
Epoch: 22 | Iteration number: [4440/4518] 98% | Training loss: 0.6870511071773263
Epoch: 22 | Iteration number: [4450/4518] 98% | Training loss: 0.6870499963171026
Epoch: 22 | Iteration number: [4460/4518] 98% | Training loss: 0.6870493033408049
Epoch: 22 | Iteration number: [4470/4518] 98% | Training loss: 0.6870480084712607
Epoch: 22 | Iteration number: [4480/4518] 99% | Training loss: 0.6870454216908132
Epoch: 22 | Iteration number: [4490/4518] 99% | Training loss: 0.6870435848666193
Epoch: 22 | Iteration number: [4500/4518] 99% | Training loss: 0.6870428061087926
Epoch: 22 | Iteration number: [4510/4518] 99% | Training loss: 0.6870433703097959

 End of epoch: 22 | Train Loss: 0.6868907749362623 | Training Time: 641 

 End of epoch: 22 | Eval Loss: 0.6912615761464956 | Evaluating Time: 17 
Epoch: 23 | Iteration number: [10/4518] 0% | Training loss: 0.7557000458240509
Epoch: 23 | Iteration number: [20/4518] 0% | Training loss: 0.72142653465271
Epoch: 23 | Iteration number: [30/4518] 0% | Training loss: 0.7095187425613403
Epoch: 23 | Iteration number: [40/4518] 0% | Training loss: 0.7039279460906982
Epoch: 23 | Iteration number: [50/4518] 1% | Training loss: 0.7003480124473572
Epoch: 23 | Iteration number: [60/4518] 1% | Training loss: 0.698186523715655
Epoch: 23 | Iteration number: [70/4518] 1% | Training loss: 0.6965899126870292
Epoch: 23 | Iteration number: [80/4518] 1% | Training loss: 0.6954311013221741
Epoch: 23 | Iteration number: [90/4518] 1% | Training loss: 0.694527965121799
Epoch: 23 | Iteration number: [100/4518] 2% | Training loss: 0.6938085800409317
Epoch: 23 | Iteration number: [110/4518] 2% | Training loss: 0.6932000507007946
Epoch: 23 | Iteration number: [120/4518] 2% | Training loss: 0.6925823042790095
Epoch: 23 | Iteration number: [130/4518] 2% | Training loss: 0.6921134118850415
Epoch: 23 | Iteration number: [140/4518] 3% | Training loss: 0.6917098334857396
Epoch: 23 | Iteration number: [150/4518] 3% | Training loss: 0.6913570606708527
Epoch: 23 | Iteration number: [160/4518] 3% | Training loss: 0.691048189997673
Epoch: 23 | Iteration number: [170/4518] 3% | Training loss: 0.6907375910702873
Epoch: 23 | Iteration number: [180/4518] 3% | Training loss: 0.6904648704661264
Epoch: 23 | Iteration number: [190/4518] 4% | Training loss: 0.6903255155212
Epoch: 23 | Iteration number: [200/4518] 4% | Training loss: 0.6900757074356079
Epoch: 23 | Iteration number: [210/4518] 4% | Training loss: 0.6898562346185957
Epoch: 23 | Iteration number: [220/4518] 4% | Training loss: 0.6897277141159232
Epoch: 23 | Iteration number: [230/4518] 5% | Training loss: 0.6896222809086675
Epoch: 23 | Iteration number: [240/4518] 5% | Training loss: 0.6895109333097935
Epoch: 23 | Iteration number: [250/4518] 5% | Training loss: 0.6894581778049469
Epoch: 23 | Iteration number: [260/4518] 5% | Training loss: 0.6893501050197162
Epoch: 23 | Iteration number: [270/4518] 5% | Training loss: 0.6892604375327075
Epoch: 23 | Iteration number: [280/4518] 6% | Training loss: 0.6891670356903757
Epoch: 23 | Iteration number: [290/4518] 6% | Training loss: 0.6891191069422097
Epoch: 23 | Iteration number: [300/4518] 6% | Training loss: 0.6890891538063685
Epoch: 23 | Iteration number: [310/4518] 6% | Training loss: 0.6890115557178375
Epoch: 23 | Iteration number: [320/4518] 7% | Training loss: 0.6889177298173308
Epoch: 23 | Iteration number: [330/4518] 7% | Training loss: 0.688872678713365
Epoch: 23 | Iteration number: [340/4518] 7% | Training loss: 0.688825527008842
Epoch: 23 | Iteration number: [350/4518] 7% | Training loss: 0.6887725508213043
Epoch: 23 | Iteration number: [360/4518] 7% | Training loss: 0.6887277869714631
Epoch: 23 | Iteration number: [370/4518] 8% | Training loss: 0.6886579052822009
Epoch: 23 | Iteration number: [380/4518] 8% | Training loss: 0.6886253626723039
Epoch: 23 | Iteration number: [390/4518] 8% | Training loss: 0.6885696278168605
Epoch: 23 | Iteration number: [400/4518] 8% | Training loss: 0.6885235014557839
Epoch: 23 | Iteration number: [410/4518] 9% | Training loss: 0.6884834719867241
Epoch: 23 | Iteration number: [420/4518] 9% | Training loss: 0.6884376507429849
Epoch: 23 | Iteration number: [430/4518] 9% | Training loss: 0.6884017478588016
Epoch: 23 | Iteration number: [440/4518] 9% | Training loss: 0.6883476480841637
Epoch: 23 | Iteration number: [450/4518] 9% | Training loss: 0.6883393726083967
Epoch: 23 | Iteration number: [460/4518] 10% | Training loss: 0.6883172282706136
Epoch: 23 | Iteration number: [470/4518] 10% | Training loss: 0.6882825287098581
Epoch: 23 | Iteration number: [480/4518] 10% | Training loss: 0.6882664953668912
Epoch: 23 | Iteration number: [490/4518] 10% | Training loss: 0.6882343069631226
Epoch: 23 | Iteration number: [500/4518] 11% | Training loss: 0.6882035808563233
Epoch: 23 | Iteration number: [510/4518] 11% | Training loss: 0.688188188566881
Epoch: 23 | Iteration number: [520/4518] 11% | Training loss: 0.6881686627864838
Epoch: 23 | Iteration number: [530/4518] 11% | Training loss: 0.6881489902172448
Epoch: 23 | Iteration number: [540/4518] 11% | Training loss: 0.688141851734232
Epoch: 23 | Iteration number: [550/4518] 12% | Training loss: 0.6881267204067923
Epoch: 23 | Iteration number: [560/4518] 12% | Training loss: 0.6881090388766357
Epoch: 23 | Iteration number: [570/4518] 12% | Training loss: 0.6880798772761696
Epoch: 23 | Iteration number: [580/4518] 12% | Training loss: 0.6880698747675994
Epoch: 23 | Iteration number: [590/4518] 13% | Training loss: 0.6880476664688627
Epoch: 23 | Iteration number: [600/4518] 13% | Training loss: 0.688028812011083
Epoch: 23 | Iteration number: [610/4518] 13% | Training loss: 0.6880348945250276
Epoch: 23 | Iteration number: [620/4518] 13% | Training loss: 0.6880212984738812
Epoch: 23 | Iteration number: [630/4518] 13% | Training loss: 0.6879975299040476
Epoch: 23 | Iteration number: [640/4518] 14% | Training loss: 0.6879957058466971
Epoch: 23 | Iteration number: [650/4518] 14% | Training loss: 0.6879697177043328
Epoch: 23 | Iteration number: [660/4518] 14% | Training loss: 0.6879489610592524
Epoch: 23 | Iteration number: [670/4518] 14% | Training loss: 0.6879355273140011
Epoch: 23 | Iteration number: [680/4518] 15% | Training loss: 0.687924991898677
Epoch: 23 | Iteration number: [690/4518] 15% | Training loss: 0.6879134814808334
Epoch: 23 | Iteration number: [700/4518] 15% | Training loss: 0.6879136673041752
Epoch: 23 | Iteration number: [710/4518] 15% | Training loss: 0.6879090504747042
Epoch: 23 | Iteration number: [720/4518] 15% | Training loss: 0.6878734396563636
Epoch: 23 | Iteration number: [730/4518] 16% | Training loss: 0.6878546948302282
Epoch: 23 | Iteration number: [740/4518] 16% | Training loss: 0.6878340556009396
Epoch: 23 | Iteration number: [750/4518] 16% | Training loss: 0.6878226603666941
Epoch: 23 | Iteration number: [760/4518] 16% | Training loss: 0.6878096164841401
Epoch: 23 | Iteration number: [770/4518] 17% | Training loss: 0.6877836962798973
Epoch: 23 | Iteration number: [780/4518] 17% | Training loss: 0.6877615185120167
Epoch: 23 | Iteration number: [790/4518] 17% | Training loss: 0.6877536544316931
Epoch: 23 | Iteration number: [800/4518] 17% | Training loss: 0.6877652966231108
Epoch: 23 | Iteration number: [810/4518] 17% | Training loss: 0.6877470090801333
Epoch: 23 | Iteration number: [820/4518] 18% | Training loss: 0.6877447112304408
Epoch: 23 | Iteration number: [830/4518] 18% | Training loss: 0.6877483079950494
Epoch: 23 | Iteration number: [840/4518] 18% | Training loss: 0.6877164223364421
Epoch: 23 | Iteration number: [850/4518] 18% | Training loss: 0.687696294223561
Epoch: 23 | Iteration number: [860/4518] 19% | Training loss: 0.6876767943071764
Epoch: 23 | Iteration number: [870/4518] 19% | Training loss: 0.6876606840511849
Epoch: 23 | Iteration number: [880/4518] 19% | Training loss: 0.6876496749845418
Epoch: 23 | Iteration number: [890/4518] 19% | Training loss: 0.6876331968253918
Epoch: 23 | Iteration number: [900/4518] 19% | Training loss: 0.6876157781812879
Epoch: 23 | Iteration number: [910/4518] 20% | Training loss: 0.6876024393589942
Epoch: 23 | Iteration number: [920/4518] 20% | Training loss: 0.6875914431136587
Epoch: 23 | Iteration number: [930/4518] 20% | Training loss: 0.687568957638997
Epoch: 23 | Iteration number: [940/4518] 20% | Training loss: 0.6875652868062891
Epoch: 23 | Iteration number: [950/4518] 21% | Training loss: 0.6875625851279811
Epoch: 23 | Iteration number: [960/4518] 21% | Training loss: 0.687553587804238
Epoch: 23 | Iteration number: [970/4518] 21% | Training loss: 0.6875473826201921
Epoch: 23 | Iteration number: [980/4518] 21% | Training loss: 0.6875500273339602
Epoch: 23 | Iteration number: [990/4518] 21% | Training loss: 0.6875273233110254
Epoch: 23 | Iteration number: [1000/4518] 22% | Training loss: 0.6875179333686828
Epoch: 23 | Iteration number: [1010/4518] 22% | Training loss: 0.687508761882782
Epoch: 23 | Iteration number: [1020/4518] 22% | Training loss: 0.6875080919733234
Epoch: 23 | Iteration number: [1030/4518] 22% | Training loss: 0.6874950145633475
Epoch: 23 | Iteration number: [1040/4518] 23% | Training loss: 0.6874846181044212
Epoch: 23 | Iteration number: [1050/4518] 23% | Training loss: 0.6874622985862551
Epoch: 23 | Iteration number: [1060/4518] 23% | Training loss: 0.6874564161278167
Epoch: 23 | Iteration number: [1070/4518] 23% | Training loss: 0.6874432519217518
Epoch: 23 | Iteration number: [1080/4518] 23% | Training loss: 0.6874327318535911
Epoch: 23 | Iteration number: [1090/4518] 24% | Training loss: 0.6874374127169268
Epoch: 23 | Iteration number: [1100/4518] 24% | Training loss: 0.6874246195229617
Epoch: 23 | Iteration number: [1110/4518] 24% | Training loss: 0.6874229314627948
Epoch: 23 | Iteration number: [1120/4518] 24% | Training loss: 0.6874165093792336
Epoch: 23 | Iteration number: [1130/4518] 25% | Training loss: 0.6874216358746048
Epoch: 23 | Iteration number: [1140/4518] 25% | Training loss: 0.6874145391740297
Epoch: 23 | Iteration number: [1150/4518] 25% | Training loss: 0.687408285866613
Epoch: 23 | Iteration number: [1160/4518] 25% | Training loss: 0.6874056714875945
Epoch: 23 | Iteration number: [1170/4518] 25% | Training loss: 0.6874053328974634
Epoch: 23 | Iteration number: [1180/4518] 26% | Training loss: 0.6873973254430092
Epoch: 23 | Iteration number: [1190/4518] 26% | Training loss: 0.6874035424545032
Epoch: 23 | Iteration number: [1200/4518] 26% | Training loss: 0.6873950560887655
Epoch: 23 | Iteration number: [1210/4518] 26% | Training loss: 0.6873908996089431
Epoch: 23 | Iteration number: [1220/4518] 27% | Training loss: 0.6873797016554192
Epoch: 23 | Iteration number: [1230/4518] 27% | Training loss: 0.6873827025657747
Epoch: 23 | Iteration number: [1240/4518] 27% | Training loss: 0.6873718079059354
Epoch: 23 | Iteration number: [1250/4518] 27% | Training loss: 0.6873623245239258
Epoch: 23 | Iteration number: [1260/4518] 27% | Training loss: 0.687353356064312
Epoch: 23 | Iteration number: [1270/4518] 28% | Training loss: 0.6873527334431025
Epoch: 23 | Iteration number: [1280/4518] 28% | Training loss: 0.6873468130361289
Epoch: 23 | Iteration number: [1290/4518] 28% | Training loss: 0.687350450236668
Epoch: 23 | Iteration number: [1300/4518] 28% | Training loss: 0.6873361335350917
Epoch: 23 | Iteration number: [1310/4518] 28% | Training loss: 0.6873398974651599
Epoch: 23 | Iteration number: [1320/4518] 29% | Training loss: 0.6873393556385329
Epoch: 23 | Iteration number: [1330/4518] 29% | Training loss: 0.6873391173835984
Epoch: 23 | Iteration number: [1340/4518] 29% | Training loss: 0.6873364717657886
Epoch: 23 | Iteration number: [1350/4518] 29% | Training loss: 0.6873314672929269
Epoch: 23 | Iteration number: [1360/4518] 30% | Training loss: 0.6873269332682386
Epoch: 23 | Iteration number: [1370/4518] 30% | Training loss: 0.6873275540605949
Epoch: 23 | Iteration number: [1380/4518] 30% | Training loss: 0.6873218605915705
Epoch: 23 | Iteration number: [1390/4518] 30% | Training loss: 0.6873202962841062
Epoch: 23 | Iteration number: [1400/4518] 30% | Training loss: 0.6873106836846896
Epoch: 23 | Iteration number: [1410/4518] 31% | Training loss: 0.6873045593711501
Epoch: 23 | Iteration number: [1420/4518] 31% | Training loss: 0.687303342491808
Epoch: 23 | Iteration number: [1430/4518] 31% | Training loss: 0.6873069405555725
Epoch: 23 | Iteration number: [1440/4518] 31% | Training loss: 0.6873088248901897
Epoch: 23 | Iteration number: [1450/4518] 32% | Training loss: 0.6873022644273166
Epoch: 23 | Iteration number: [1460/4518] 32% | Training loss: 0.6872987968056169
Epoch: 23 | Iteration number: [1470/4518] 32% | Training loss: 0.6872940416238746
Epoch: 23 | Iteration number: [1480/4518] 32% | Training loss: 0.6872914804800137
Epoch: 23 | Iteration number: [1490/4518] 32% | Training loss: 0.6872837371874175
Epoch: 23 | Iteration number: [1500/4518] 33% | Training loss: 0.6872789621750514
Epoch: 23 | Iteration number: [1510/4518] 33% | Training loss: 0.687281981485569
Epoch: 23 | Iteration number: [1520/4518] 33% | Training loss: 0.6872690181198873
Epoch: 23 | Iteration number: [1530/4518] 33% | Training loss: 0.6872655428312963
Epoch: 23 | Iteration number: [1540/4518] 34% | Training loss: 0.6872664553004426
Epoch: 23 | Iteration number: [1550/4518] 34% | Training loss: 0.68726245037971
Epoch: 23 | Iteration number: [1560/4518] 34% | Training loss: 0.6872673884798319
Epoch: 23 | Iteration number: [1570/4518] 34% | Training loss: 0.6872619111826466
Epoch: 23 | Iteration number: [1580/4518] 34% | Training loss: 0.6872639653426182
Epoch: 23 | Iteration number: [1590/4518] 35% | Training loss: 0.6872654652445571
Epoch: 23 | Iteration number: [1600/4518] 35% | Training loss: 0.687265061289072
Epoch: 23 | Iteration number: [1610/4518] 35% | Training loss: 0.6872640412416517
Epoch: 23 | Iteration number: [1620/4518] 35% | Training loss: 0.6872619183343134
Epoch: 23 | Iteration number: [1630/4518] 36% | Training loss: 0.6872588903260377
Epoch: 23 | Iteration number: [1640/4518] 36% | Training loss: 0.6872492532904555
Epoch: 23 | Iteration number: [1650/4518] 36% | Training loss: 0.687244464267384
Epoch: 23 | Iteration number: [1660/4518] 36% | Training loss: 0.6872431883610874
Epoch: 23 | Iteration number: [1670/4518] 36% | Training loss: 0.6872443430794927
Epoch: 23 | Iteration number: [1680/4518] 37% | Training loss: 0.6872294298240117
Epoch: 23 | Iteration number: [1690/4518] 37% | Training loss: 0.6872313275139713
Epoch: 23 | Iteration number: [1700/4518] 37% | Training loss: 0.6872322730106466
Epoch: 23 | Iteration number: [1710/4518] 37% | Training loss: 0.6872239821138437
Epoch: 23 | Iteration number: [1720/4518] 38% | Training loss: 0.6872152877754943
Epoch: 23 | Iteration number: [1730/4518] 38% | Training loss: 0.6872081669768846
Epoch: 23 | Iteration number: [1740/4518] 38% | Training loss: 0.6872055731970689
Epoch: 23 | Iteration number: [1750/4518] 38% | Training loss: 0.6872112921987261
Epoch: 23 | Iteration number: [1760/4518] 38% | Training loss: 0.6872214280407537
Epoch: 23 | Iteration number: [1770/4518] 39% | Training loss: 0.6872182149334816
Epoch: 23 | Iteration number: [1780/4518] 39% | Training loss: 0.6872216431947237
Epoch: 23 | Iteration number: [1790/4518] 39% | Training loss: 0.6872235819614133
Epoch: 23 | Iteration number: [1800/4518] 39% | Training loss: 0.6872168148226209
Epoch: 23 | Iteration number: [1810/4518] 40% | Training loss: 0.687213040978869
Epoch: 23 | Iteration number: [1820/4518] 40% | Training loss: 0.6872102173802617
Epoch: 23 | Iteration number: [1830/4518] 40% | Training loss: 0.6872026104418958
Epoch: 23 | Iteration number: [1840/4518] 40% | Training loss: 0.6872024043746616
Epoch: 23 | Iteration number: [1850/4518] 40% | Training loss: 0.6872003499237267
Epoch: 23 | Iteration number: [1860/4518] 41% | Training loss: 0.6872042002536918
Epoch: 23 | Iteration number: [1870/4518] 41% | Training loss: 0.6871983527499724
Epoch: 23 | Iteration number: [1880/4518] 41% | Training loss: 0.6871971880818936
Epoch: 23 | Iteration number: [1890/4518] 41% | Training loss: 0.6871939694124555
Epoch: 23 | Iteration number: [1900/4518] 42% | Training loss: 0.6871888667972464
Epoch: 23 | Iteration number: [1910/4518] 42% | Training loss: 0.6871834199466006
Epoch: 23 | Iteration number: [1920/4518] 42% | Training loss: 0.6871734643665453
Epoch: 23 | Iteration number: [1930/4518] 42% | Training loss: 0.6871612706641459
Epoch: 23 | Iteration number: [1940/4518] 42% | Training loss: 0.6871622629386862
Epoch: 23 | Iteration number: [1950/4518] 43% | Training loss: 0.6871579549557123
Epoch: 23 | Iteration number: [1960/4518] 43% | Training loss: 0.6871624531186357
Epoch: 23 | Iteration number: [1970/4518] 43% | Training loss: 0.6871641083114644
Epoch: 23 | Iteration number: [1980/4518] 43% | Training loss: 0.6871663182973862
Epoch: 23 | Iteration number: [1990/4518] 44% | Training loss: 0.6871651268185084
Epoch: 23 | Iteration number: [2000/4518] 44% | Training loss: 0.6871629833579064
Epoch: 23 | Iteration number: [2010/4518] 44% | Training loss: 0.6871618546953249
Epoch: 23 | Iteration number: [2020/4518] 44% | Training loss: 0.6871658254672985
Epoch: 23 | Iteration number: [2030/4518] 44% | Training loss: 0.6871603182383946
Epoch: 23 | Iteration number: [2040/4518] 45% | Training loss: 0.6871571049094201
Epoch: 23 | Iteration number: [2050/4518] 45% | Training loss: 0.6871494242912386
Epoch: 23 | Iteration number: [2060/4518] 45% | Training loss: 0.6871534879635839
Epoch: 23 | Iteration number: [2070/4518] 45% | Training loss: 0.6871515510738759
Epoch: 23 | Iteration number: [2080/4518] 46% | Training loss: 0.6871451375862727
Epoch: 23 | Iteration number: [2090/4518] 46% | Training loss: 0.687139655043634
Epoch: 23 | Iteration number: [2100/4518] 46% | Training loss: 0.6871421705824988
Epoch: 23 | Iteration number: [2110/4518] 46% | Training loss: 0.6871388283951022
Epoch: 23 | Iteration number: [2120/4518] 46% | Training loss: 0.6871395373119498
Epoch: 23 | Iteration number: [2130/4518] 47% | Training loss: 0.687136764425627
Epoch: 23 | Iteration number: [2140/4518] 47% | Training loss: 0.6871326905266146
Epoch: 23 | Iteration number: [2150/4518] 47% | Training loss: 0.687128078466238
Epoch: 23 | Iteration number: [2160/4518] 47% | Training loss: 0.6871322949727376
Epoch: 23 | Iteration number: [2170/4518] 48% | Training loss: 0.687133395507039
Epoch: 23 | Iteration number: [2180/4518] 48% | Training loss: 0.6871352176053809
Epoch: 23 | Iteration number: [2190/4518] 48% | Training loss: 0.6871318007985207
Epoch: 23 | Iteration number: [2200/4518] 48% | Training loss: 0.6871317303451625
Epoch: 23 | Iteration number: [2210/4518] 48% | Training loss: 0.6871278996381285
Epoch: 23 | Iteration number: [2220/4518] 49% | Training loss: 0.6871291455116358
Epoch: 23 | Iteration number: [2230/4518] 49% | Training loss: 0.6871308542153226
Epoch: 23 | Iteration number: [2240/4518] 49% | Training loss: 0.6871215062215924
Epoch: 23 | Iteration number: [2250/4518] 49% | Training loss: 0.6871145341661241
Epoch: 23 | Iteration number: [2260/4518] 50% | Training loss: 0.6871190440602007
Epoch: 23 | Iteration number: [2270/4518] 50% | Training loss: 0.6871149194398115
Epoch: 23 | Iteration number: [2280/4518] 50% | Training loss: 0.6871198372098437
Epoch: 23 | Iteration number: [2290/4518] 50% | Training loss: 0.6871209331995535
Epoch: 23 | Iteration number: [2300/4518] 50% | Training loss: 0.6871203962357147
Epoch: 23 | Iteration number: [2310/4518] 51% | Training loss: 0.6871196326755342
Epoch: 23 | Iteration number: [2320/4518] 51% | Training loss: 0.687122681068963
Epoch: 23 | Iteration number: [2330/4518] 51% | Training loss: 0.6871228086590255
Epoch: 23 | Iteration number: [2340/4518] 51% | Training loss: 0.6871272675247274
Epoch: 23 | Iteration number: [2350/4518] 52% | Training loss: 0.6871292601240442
Epoch: 23 | Iteration number: [2360/4518] 52% | Training loss: 0.6871266619381258
Epoch: 23 | Iteration number: [2370/4518] 52% | Training loss: 0.6871243091826701
Epoch: 23 | Iteration number: [2380/4518] 52% | Training loss: 0.6871244124504698
Epoch: 23 | Iteration number: [2390/4518] 52% | Training loss: 0.6871228979471837
Epoch: 23 | Iteration number: [2400/4518] 53% | Training loss: 0.6871231560160717
Epoch: 23 | Iteration number: [2410/4518] 53% | Training loss: 0.6871280802730703
Epoch: 23 | Iteration number: [2420/4518] 53% | Training loss: 0.6871303806866496
Epoch: 23 | Iteration number: [2430/4518] 53% | Training loss: 0.6871284216029163
Epoch: 23 | Iteration number: [2440/4518] 54% | Training loss: 0.687132272051006
Epoch: 23 | Iteration number: [2450/4518] 54% | Training loss: 0.6871350686647454
Epoch: 23 | Iteration number: [2460/4518] 54% | Training loss: 0.6871339706386008
Epoch: 23 | Iteration number: [2470/4518] 54% | Training loss: 0.6871332734219942
Epoch: 23 | Iteration number: [2480/4518] 54% | Training loss: 0.6871322321074624
Epoch: 23 | Iteration number: [2490/4518] 55% | Training loss: 0.6871273849383894
Epoch: 23 | Iteration number: [2500/4518] 55% | Training loss: 0.6871331146717071
Epoch: 23 | Iteration number: [2510/4518] 55% | Training loss: 0.6871359290592224
Epoch: 23 | Iteration number: [2520/4518] 55% | Training loss: 0.6871352515523396
Epoch: 23 | Iteration number: [2530/4518] 55% | Training loss: 0.6871320769014094
Epoch: 23 | Iteration number: [2540/4518] 56% | Training loss: 0.687131333750064
Epoch: 23 | Iteration number: [2550/4518] 56% | Training loss: 0.6871301523844401
Epoch: 23 | Iteration number: [2560/4518] 56% | Training loss: 0.6871337684802711
Epoch: 23 | Iteration number: [2570/4518] 56% | Training loss: 0.6871322088900244
Epoch: 23 | Iteration number: [2580/4518] 57% | Training loss: 0.6871308638374934
Epoch: 23 | Iteration number: [2590/4518] 57% | Training loss: 0.687124419741649
Epoch: 23 | Iteration number: [2600/4518] 57% | Training loss: 0.6871179191882794
Epoch: 23 | Iteration number: [2610/4518] 57% | Training loss: 0.6871193011373395
Epoch: 23 | Iteration number: [2620/4518] 57% | Training loss: 0.6871199053662423
Epoch: 23 | Iteration number: [2630/4518] 58% | Training loss: 0.6871174711011662
Epoch: 23 | Iteration number: [2640/4518] 58% | Training loss: 0.6871162704671874
Epoch: 23 | Iteration number: [2650/4518] 58% | Training loss: 0.6871196953305658
Epoch: 23 | Iteration number: [2660/4518] 58% | Training loss: 0.687118507888084
Epoch: 23 | Iteration number: [2670/4518] 59% | Training loss: 0.6871189420812586
Epoch: 23 | Iteration number: [2680/4518] 59% | Training loss: 0.687112046199948
Epoch: 23 | Iteration number: [2690/4518] 59% | Training loss: 0.6871122414959407
Epoch: 23 | Iteration number: [2700/4518] 59% | Training loss: 0.6871118435594771
Epoch: 23 | Iteration number: [2710/4518] 59% | Training loss: 0.6871104404275268
Epoch: 23 | Iteration number: [2720/4518] 60% | Training loss: 0.6871121449724716
Epoch: 23 | Iteration number: [2730/4518] 60% | Training loss: 0.6871124230243347
Epoch: 23 | Iteration number: [2740/4518] 60% | Training loss: 0.687117391520173
Epoch: 23 | Iteration number: [2750/4518] 60% | Training loss: 0.6871156708327206
Epoch: 23 | Iteration number: [2760/4518] 61% | Training loss: 0.6871151228961737
Epoch: 23 | Iteration number: [2770/4518] 61% | Training loss: 0.6871152048291712
Epoch: 23 | Iteration number: [2780/4518] 61% | Training loss: 0.6871111945497046
Epoch: 23 | Iteration number: [2790/4518] 61% | Training loss: 0.6871098828785736
Epoch: 23 | Iteration number: [2800/4518] 61% | Training loss: 0.6871054472454957
Epoch: 23 | Iteration number: [2810/4518] 62% | Training loss: 0.6871029116929214
Epoch: 23 | Iteration number: [2820/4518] 62% | Training loss: 0.6871027105454858
Epoch: 23 | Iteration number: [2830/4518] 62% | Training loss: 0.6870992130820406
Epoch: 23 | Iteration number: [2840/4518] 62% | Training loss: 0.6871020739557038
Epoch: 23 | Iteration number: [2850/4518] 63% | Training loss: 0.6871033616024151
Epoch: 23 | Iteration number: [2860/4518] 63% | Training loss: 0.6871040021831339
Epoch: 23 | Iteration number: [2870/4518] 63% | Training loss: 0.6871041525324048
Epoch: 23 | Iteration number: [2880/4518] 63% | Training loss: 0.6871043713349435
Epoch: 23 | Iteration number: [2890/4518] 63% | Training loss: 0.6871044601948616
Epoch: 23 | Iteration number: [2900/4518] 64% | Training loss: 0.6871041866623122
Epoch: 23 | Iteration number: [2910/4518] 64% | Training loss: 0.6871048272680171
Epoch: 23 | Iteration number: [2920/4518] 64% | Training loss: 0.6871025065240794
Epoch: 23 | Iteration number: [2930/4518] 64% | Training loss: 0.6871020368138271
Epoch: 23 | Iteration number: [2940/4518] 65% | Training loss: 0.6871026954683317
Epoch: 23 | Iteration number: [2950/4518] 65% | Training loss: 0.6871026333105766
Epoch: 23 | Iteration number: [2960/4518] 65% | Training loss: 0.6871040337995903
Epoch: 23 | Iteration number: [2970/4518] 65% | Training loss: 0.6871034496761733
Epoch: 23 | Iteration number: [2980/4518] 65% | Training loss: 0.6871028228494145
Epoch: 23 | Iteration number: [2990/4518] 66% | Training loss: 0.6871043223003082
Epoch: 23 | Iteration number: [3000/4518] 66% | Training loss: 0.6871053618590037
Epoch: 23 | Iteration number: [3010/4518] 66% | Training loss: 0.6871096997165996
Epoch: 23 | Iteration number: [3020/4518] 66% | Training loss: 0.6871083846550115
Epoch: 23 | Iteration number: [3030/4518] 67% | Training loss: 0.6871108663554238
Epoch: 23 | Iteration number: [3040/4518] 67% | Training loss: 0.6871123172538846
Epoch: 23 | Iteration number: [3050/4518] 67% | Training loss: 0.6871106868102902
Epoch: 23 | Iteration number: [3060/4518] 67% | Training loss: 0.6871124575730243
Epoch: 23 | Iteration number: [3070/4518] 67% | Training loss: 0.6871110810713194
Epoch: 23 | Iteration number: [3080/4518] 68% | Training loss: 0.6871102054591303
Epoch: 23 | Iteration number: [3090/4518] 68% | Training loss: 0.6871081569048193
Epoch: 23 | Iteration number: [3100/4518] 68% | Training loss: 0.6871093041089273
Epoch: 23 | Iteration number: [3110/4518] 68% | Training loss: 0.6871123839421288
Epoch: 23 | Iteration number: [3120/4518] 69% | Training loss: 0.6871119985786768
Epoch: 23 | Iteration number: [3130/4518] 69% | Training loss: 0.6871138522038445
Epoch: 23 | Iteration number: [3140/4518] 69% | Training loss: 0.6871138093577829
Epoch: 23 | Iteration number: [3150/4518] 69% | Training loss: 0.6871136158610147
Epoch: 23 | Iteration number: [3160/4518] 69% | Training loss: 0.6871141631769229
Epoch: 23 | Iteration number: [3170/4518] 70% | Training loss: 0.6871125740583762
Epoch: 23 | Iteration number: [3180/4518] 70% | Training loss: 0.6871092554158384
Epoch: 23 | Iteration number: [3190/4518] 70% | Training loss: 0.6871082857671577
Epoch: 23 | Iteration number: [3200/4518] 70% | Training loss: 0.6871051838621497
Epoch: 23 | Iteration number: [3210/4518] 71% | Training loss: 0.6871057274556976
Epoch: 23 | Iteration number: [3220/4518] 71% | Training loss: 0.6871058228038113
Epoch: 23 | Iteration number: [3230/4518] 71% | Training loss: 0.6870992799107873
Epoch: 23 | Iteration number: [3240/4518] 71% | Training loss: 0.6870986229107704
Epoch: 23 | Iteration number: [3250/4518] 71% | Training loss: 0.6870989226194528
Epoch: 23 | Iteration number: [3260/4518] 72% | Training loss: 0.6870963788837011
Epoch: 23 | Iteration number: [3270/4518] 72% | Training loss: 0.6870965133384098
Epoch: 23 | Iteration number: [3280/4518] 72% | Training loss: 0.6870949400816022
Epoch: 23 | Iteration number: [3290/4518] 72% | Training loss: 0.6870924102317961
Epoch: 23 | Iteration number: [3300/4518] 73% | Training loss: 0.6870909249601942
Epoch: 23 | Iteration number: [3310/4518] 73% | Training loss: 0.6870930021803184
Epoch: 23 | Iteration number: [3320/4518] 73% | Training loss: 0.6870881805757442
Epoch: 23 | Iteration number: [3330/4518] 73% | Training loss: 0.6870854547431877
Epoch: 23 | Iteration number: [3340/4518] 73% | Training loss: 0.6870838751692971
Epoch: 23 | Iteration number: [3350/4518] 74% | Training loss: 0.6870845141695506
Epoch: 23 | Iteration number: [3360/4518] 74% | Training loss: 0.687084205395409
Epoch: 23 | Iteration number: [3370/4518] 74% | Training loss: 0.6870872297343585
Epoch: 23 | Iteration number: [3380/4518] 74% | Training loss: 0.687087904683937
Epoch: 23 | Iteration number: [3390/4518] 75% | Training loss: 0.6870900925985128
Epoch: 23 | Iteration number: [3400/4518] 75% | Training loss: 0.6870895149427302
Epoch: 23 | Iteration number: [3410/4518] 75% | Training loss: 0.6870859184397979
Epoch: 23 | Iteration number: [3420/4518] 75% | Training loss: 0.6870863998668235
Epoch: 23 | Iteration number: [3430/4518] 75% | Training loss: 0.6870864307393834
Epoch: 23 | Iteration number: [3440/4518] 76% | Training loss: 0.6870864150136016
Epoch: 23 | Iteration number: [3450/4518] 76% | Training loss: 0.6870856405859408
Epoch: 23 | Iteration number: [3460/4518] 76% | Training loss: 0.6870830446309437
Epoch: 23 | Iteration number: [3470/4518] 76% | Training loss: 0.6870861396494105
Epoch: 23 | Iteration number: [3480/4518] 77% | Training loss: 0.6870875817605819
Epoch: 23 | Iteration number: [3490/4518] 77% | Training loss: 0.6870876616768987
Epoch: 23 | Iteration number: [3500/4518] 77% | Training loss: 0.6870858251707894
Epoch: 23 | Iteration number: [3510/4518] 77% | Training loss: 0.6870863883753447
Epoch: 23 | Iteration number: [3520/4518] 77% | Training loss: 0.6870856911282648
Epoch: 23 | Iteration number: [3530/4518] 78% | Training loss: 0.6870890493602321
Epoch: 23 | Iteration number: [3540/4518] 78% | Training loss: 0.6870869164918102
Epoch: 23 | Iteration number: [3550/4518] 78% | Training loss: 0.6870887062583171
Epoch: 23 | Iteration number: [3560/4518] 78% | Training loss: 0.6870880691522963
Epoch: 23 | Iteration number: [3570/4518] 79% | Training loss: 0.6870866894388066
Epoch: 23 | Iteration number: [3580/4518] 79% | Training loss: 0.6870863949120378
Epoch: 23 | Iteration number: [3590/4518] 79% | Training loss: 0.6870856765751056
Epoch: 23 | Iteration number: [3600/4518] 79% | Training loss: 0.6870849231713348
Epoch: 23 | Iteration number: [3610/4518] 79% | Training loss: 0.6870812909589911
Epoch: 23 | Iteration number: [3620/4518] 80% | Training loss: 0.6870823088601149
Epoch: 23 | Iteration number: [3630/4518] 80% | Training loss: 0.6870838378907563
Epoch: 23 | Iteration number: [3640/4518] 80% | Training loss: 0.6870830043822854
Epoch: 23 | Iteration number: [3650/4518] 80% | Training loss: 0.6870837834109998
Epoch: 23 | Iteration number: [3660/4518] 81% | Training loss: 0.687083877826649
Epoch: 23 | Iteration number: [3670/4518] 81% | Training loss: 0.6870866705026548
Epoch: 23 | Iteration number: [3680/4518] 81% | Training loss: 0.6870830393355826
Epoch: 23 | Iteration number: [3690/4518] 81% | Training loss: 0.6870767384686767
Epoch: 23 | Iteration number: [3700/4518] 81% | Training loss: 0.6870737048741934
Epoch: 23 | Iteration number: [3710/4518] 82% | Training loss: 0.6870739296118846
Epoch: 23 | Iteration number: [3720/4518] 82% | Training loss: 0.6870712227879032
Epoch: 23 | Iteration number: [3730/4518] 82% | Training loss: 0.6870725454178317
Epoch: 23 | Iteration number: [3740/4518] 82% | Training loss: 0.687071308668922
Epoch: 23 | Iteration number: [3750/4518] 83% | Training loss: 0.687070622253418
Epoch: 23 | Iteration number: [3760/4518] 83% | Training loss: 0.6870694722742476
Epoch: 23 | Iteration number: [3770/4518] 83% | Training loss: 0.6870654932067628
Epoch: 23 | Iteration number: [3780/4518] 83% | Training loss: 0.6870674162945419
Epoch: 23 | Iteration number: [3790/4518] 83% | Training loss: 0.6870662890984075
Epoch: 23 | Iteration number: [3800/4518] 84% | Training loss: 0.6870655672958023
Epoch: 23 | Iteration number: [3810/4518] 84% | Training loss: 0.6870689047290272
Epoch: 23 | Iteration number: [3820/4518] 84% | Training loss: 0.687067454928503
Epoch: 23 | Iteration number: [3830/4518] 84% | Training loss: 0.6870651659704063
Epoch: 23 | Iteration number: [3840/4518] 84% | Training loss: 0.6870625350003441
Epoch: 23 | Iteration number: [3850/4518] 85% | Training loss: 0.6870629482919519
Epoch: 23 | Iteration number: [3860/4518] 85% | Training loss: 0.6870624378864012
Epoch: 23 | Iteration number: [3870/4518] 85% | Training loss: 0.6870619938047049
Epoch: 23 | Iteration number: [3880/4518] 85% | Training loss: 0.6870623537099239
Epoch: 23 | Iteration number: [3890/4518] 86% | Training loss: 0.6870613105805796
Epoch: 23 | Iteration number: [3900/4518] 86% | Training loss: 0.687065241245123
Epoch: 23 | Iteration number: [3910/4518] 86% | Training loss: 0.6870638736830953
Epoch: 23 | Iteration number: [3920/4518] 86% | Training loss: 0.6870618501792148
Epoch: 23 | Iteration number: [3930/4518] 86% | Training loss: 0.6870595852078979
Epoch: 23 | Iteration number: [3940/4518] 87% | Training loss: 0.6870568324164086
Epoch: 23 | Iteration number: [3950/4518] 87% | Training loss: 0.6870577992215942
Epoch: 23 | Iteration number: [3960/4518] 87% | Training loss: 0.6870610666244921
Epoch: 23 | Iteration number: [3970/4518] 87% | Training loss: 0.687060954889062
Epoch: 23 | Iteration number: [3980/4518] 88% | Training loss: 0.6870636652462446
Epoch: 23 | Iteration number: [3990/4518] 88% | Training loss: 0.6870636751926632
Epoch: 23 | Iteration number: [4000/4518] 88% | Training loss: 0.6870636267960072
Epoch: 23 | Iteration number: [4010/4518] 88% | Training loss: 0.6870594269914223
Epoch: 23 | Iteration number: [4020/4518] 88% | Training loss: 0.6870613582098662
Epoch: 23 | Iteration number: [4030/4518] 89% | Training loss: 0.6870586975336667
Epoch: 23 | Iteration number: [4040/4518] 89% | Training loss: 0.6870611151993865
Epoch: 23 | Iteration number: [4050/4518] 89% | Training loss: 0.6870611274683917
Epoch: 23 | Iteration number: [4060/4518] 89% | Training loss: 0.6870606145541657
Epoch: 23 | Iteration number: [4070/4518] 90% | Training loss: 0.6870597541039347
Epoch: 23 | Iteration number: [4080/4518] 90% | Training loss: 0.6870609456563697
Epoch: 23 | Iteration number: [4090/4518] 90% | Training loss: 0.6870614235296226
Epoch: 23 | Iteration number: [4100/4518] 90% | Training loss: 0.6870594239380301
Epoch: 23 | Iteration number: [4110/4518] 90% | Training loss: 0.6870610578941893
Epoch: 23 | Iteration number: [4120/4518] 91% | Training loss: 0.6870579345133698
Epoch: 23 | Iteration number: [4130/4518] 91% | Training loss: 0.6870580190463447
Epoch: 23 | Iteration number: [4140/4518] 91% | Training loss: 0.6870550726202951
Epoch: 23 | Iteration number: [4150/4518] 91% | Training loss: 0.6870547666176255
Epoch: 23 | Iteration number: [4160/4518] 92% | Training loss: 0.6870511556330782
Epoch: 23 | Iteration number: [4170/4518] 92% | Training loss: 0.6870516837786713
Epoch: 23 | Iteration number: [4180/4518] 92% | Training loss: 0.6870513277618508
Epoch: 23 | Iteration number: [4190/4518] 92% | Training loss: 0.6870507596642988
Epoch: 23 | Iteration number: [4200/4518] 92% | Training loss: 0.6870542080487524
Epoch: 23 | Iteration number: [4210/4518] 93% | Training loss: 0.6870539782307776
Epoch: 23 | Iteration number: [4220/4518] 93% | Training loss: 0.687051085866458
Epoch: 23 | Iteration number: [4230/4518] 93% | Training loss: 0.6870514848694452
Epoch: 23 | Iteration number: [4240/4518] 93% | Training loss: 0.6870514615105008
Epoch: 23 | Iteration number: [4250/4518] 94% | Training loss: 0.6870488925260656
Epoch: 23 | Iteration number: [4260/4518] 94% | Training loss: 0.6870454074771192
Epoch: 23 | Iteration number: [4270/4518] 94% | Training loss: 0.6870437943544544
Epoch: 23 | Iteration number: [4280/4518] 94% | Training loss: 0.6870466491747125
Epoch: 23 | Iteration number: [4290/4518] 94% | Training loss: 0.6870478381504823
Epoch: 23 | Iteration number: [4300/4518] 95% | Training loss: 0.687048445745956
Epoch: 23 | Iteration number: [4310/4518] 95% | Training loss: 0.6870506469722137
Epoch: 23 | Iteration number: [4320/4518] 95% | Training loss: 0.6870519114727224
Epoch: 23 | Iteration number: [4330/4518] 95% | Training loss: 0.6870510382822975
Epoch: 23 | Iteration number: [4340/4518] 96% | Training loss: 0.6870497510455171
Epoch: 23 | Iteration number: [4350/4518] 96% | Training loss: 0.6870510843567464
Epoch: 23 | Iteration number: [4360/4518] 96% | Training loss: 0.6870510036382107
Epoch: 23 | Iteration number: [4370/4518] 96% | Training loss: 0.6870528894240032
Epoch: 23 | Iteration number: [4380/4518] 96% | Training loss: 0.6870531322749238
Epoch: 23 | Iteration number: [4390/4518] 97% | Training loss: 0.6870529153352446
Epoch: 23 | Iteration number: [4400/4518] 97% | Training loss: 0.6870550723238424
Epoch: 23 | Iteration number: [4410/4518] 97% | Training loss: 0.6870569675417444
Epoch: 23 | Iteration number: [4420/4518] 97% | Training loss: 0.6870555342996821
Epoch: 23 | Iteration number: [4430/4518] 98% | Training loss: 0.6870539950463357
Epoch: 23 | Iteration number: [4440/4518] 98% | Training loss: 0.6870519957026919
Epoch: 23 | Iteration number: [4450/4518] 98% | Training loss: 0.687051133265656
Epoch: 23 | Iteration number: [4460/4518] 98% | Training loss: 0.6870530572172773
Epoch: 23 | Iteration number: [4470/4518] 98% | Training loss: 0.6870516220195182
Epoch: 23 | Iteration number: [4480/4518] 99% | Training loss: 0.6870501817736242
Epoch: 23 | Iteration number: [4490/4518] 99% | Training loss: 0.6870513629143381
Epoch: 23 | Iteration number: [4500/4518] 99% | Training loss: 0.6870500680208206
Epoch: 23 | Iteration number: [4510/4518] 99% | Training loss: 0.6870464621520624

 End of epoch: 23 | Train Loss: 0.6868923354090817 | Training Time: 643 

 End of epoch: 23 | Eval Loss: 0.6903575427678167 | Evaluating Time: 17 
Epoch: 24 | Iteration number: [10/4518] 0% | Training loss: 0.7562315583229064
Epoch: 24 | Iteration number: [20/4518] 0% | Training loss: 0.7218759059906006
Epoch: 24 | Iteration number: [30/4518] 0% | Training loss: 0.7102012654145559
Epoch: 24 | Iteration number: [40/4518] 0% | Training loss: 0.7044526115059853
Epoch: 24 | Iteration number: [50/4518] 1% | Training loss: 0.7009008026123047
Epoch: 24 | Iteration number: [60/4518] 1% | Training loss: 0.6986904233694077
Epoch: 24 | Iteration number: [70/4518] 1% | Training loss: 0.6969192317553929
Epoch: 24 | Iteration number: [80/4518] 1% | Training loss: 0.6956273160874844
Epoch: 24 | Iteration number: [90/4518] 1% | Training loss: 0.6946614921092987
Epoch: 24 | Iteration number: [100/4518] 2% | Training loss: 0.6937820982933044
Epoch: 24 | Iteration number: [110/4518] 2% | Training loss: 0.6932169096036391
Epoch: 24 | Iteration number: [120/4518] 2% | Training loss: 0.6926882669329644
Epoch: 24 | Iteration number: [130/4518] 2% | Training loss: 0.6921531140804291
Epoch: 24 | Iteration number: [140/4518] 3% | Training loss: 0.6918294910873686
Epoch: 24 | Iteration number: [150/4518] 3% | Training loss: 0.6916064524650574
Epoch: 24 | Iteration number: [160/4518] 3% | Training loss: 0.6912730131298304
Epoch: 24 | Iteration number: [170/4518] 3% | Training loss: 0.6910597794196185
Epoch: 24 | Iteration number: [180/4518] 3% | Training loss: 0.6908463113837772
Epoch: 24 | Iteration number: [190/4518] 4% | Training loss: 0.6906260512377086
Epoch: 24 | Iteration number: [200/4518] 4% | Training loss: 0.6904654070734978
Epoch: 24 | Iteration number: [210/4518] 4% | Training loss: 0.6902547586531866
Epoch: 24 | Iteration number: [220/4518] 4% | Training loss: 0.6900596366687255
Epoch: 24 | Iteration number: [230/4518] 5% | Training loss: 0.6899412520553755
Epoch: 24 | Iteration number: [240/4518] 5% | Training loss: 0.6897875885168712
Epoch: 24 | Iteration number: [250/4518] 5% | Training loss: 0.6896351370811462
Epoch: 24 | Iteration number: [260/4518] 5% | Training loss: 0.6896112056878897
Epoch: 24 | Iteration number: [270/4518] 5% | Training loss: 0.6895084500312805
Epoch: 24 | Iteration number: [280/4518] 6% | Training loss: 0.6894458560006959
Epoch: 24 | Iteration number: [290/4518] 6% | Training loss: 0.68931482701466
Epoch: 24 | Iteration number: [300/4518] 6% | Training loss: 0.6892600603898367
Epoch: 24 | Iteration number: [310/4518] 6% | Training loss: 0.6891596957560508
Epoch: 24 | Iteration number: [320/4518] 7% | Training loss: 0.689084017649293
Epoch: 24 | Iteration number: [330/4518] 7% | Training loss: 0.6889727946483728
Epoch: 24 | Iteration number: [340/4518] 7% | Training loss: 0.688919027412639
Epoch: 24 | Iteration number: [350/4518] 7% | Training loss: 0.6888559596879141
Epoch: 24 | Iteration number: [360/4518] 7% | Training loss: 0.688826919429832
Epoch: 24 | Iteration number: [370/4518] 8% | Training loss: 0.6888035553532678
Epoch: 24 | Iteration number: [380/4518] 8% | Training loss: 0.6887489674906981
Epoch: 24 | Iteration number: [390/4518] 8% | Training loss: 0.688695361216863
Epoch: 24 | Iteration number: [400/4518] 8% | Training loss: 0.6886748406291008
Epoch: 24 | Iteration number: [410/4518] 9% | Training loss: 0.6886403537378079
Epoch: 24 | Iteration number: [420/4518] 9% | Training loss: 0.6885781430062794
Epoch: 24 | Iteration number: [430/4518] 9% | Training loss: 0.6885462885679201
Epoch: 24 | Iteration number: [440/4518] 9% | Training loss: 0.6885068901560524
Epoch: 24 | Iteration number: [450/4518] 9% | Training loss: 0.6884629774093628
Epoch: 24 | Iteration number: [460/4518] 10% | Training loss: 0.6884390789529552
Epoch: 24 | Iteration number: [470/4518] 10% | Training loss: 0.6883952379226684
Epoch: 24 | Iteration number: [480/4518] 10% | Training loss: 0.6883576452732086
Epoch: 24 | Iteration number: [490/4518] 10% | Training loss: 0.6883134015968868
Epoch: 24 | Iteration number: [500/4518] 11% | Training loss: 0.688279949426651
Epoch: 24 | Iteration number: [510/4518] 11% | Training loss: 0.6882588004364687
Epoch: 24 | Iteration number: [520/4518] 11% | Training loss: 0.6882110321751007
Epoch: 24 | Iteration number: [530/4518] 11% | Training loss: 0.6881385029486891
Epoch: 24 | Iteration number: [540/4518] 11% | Training loss: 0.688099256157875
Epoch: 24 | Iteration number: [550/4518] 12% | Training loss: 0.6880805879289453
Epoch: 24 | Iteration number: [560/4518] 12% | Training loss: 0.6880552162017141
Epoch: 24 | Iteration number: [570/4518] 12% | Training loss: 0.6880306883862144
Epoch: 24 | Iteration number: [580/4518] 12% | Training loss: 0.6880019344132522
Epoch: 24 | Iteration number: [590/4518] 13% | Training loss: 0.6879827690326561
Epoch: 24 | Iteration number: [600/4518] 13% | Training loss: 0.6879946708679199
Epoch: 24 | Iteration number: [610/4518] 13% | Training loss: 0.6879564380059476
Epoch: 24 | Iteration number: [620/4518] 13% | Training loss: 0.6879398573790827
Epoch: 24 | Iteration number: [630/4518] 13% | Training loss: 0.6879213358674731
Epoch: 24 | Iteration number: [640/4518] 14% | Training loss: 0.687899493984878
Epoch: 24 | Iteration number: [650/4518] 14% | Training loss: 0.6878891638609079
Epoch: 24 | Iteration number: [660/4518] 14% | Training loss: 0.6878693943673914
Epoch: 24 | Iteration number: [670/4518] 14% | Training loss: 0.6878828413450896
Epoch: 24 | Iteration number: [680/4518] 15% | Training loss: 0.6878709050662377
Epoch: 24 | Iteration number: [690/4518] 15% | Training loss: 0.6878493291744288
Epoch: 24 | Iteration number: [700/4518] 15% | Training loss: 0.6878292603152139
Epoch: 24 | Iteration number: [710/4518] 15% | Training loss: 0.6878020893520033
Epoch: 24 | Iteration number: [720/4518] 15% | Training loss: 0.6877817288041115
Epoch: 24 | Iteration number: [730/4518] 16% | Training loss: 0.687748469310264
Epoch: 24 | Iteration number: [740/4518] 16% | Training loss: 0.6877443398172791
Epoch: 24 | Iteration number: [750/4518] 16% | Training loss: 0.6877328654925029
Epoch: 24 | Iteration number: [760/4518] 16% | Training loss: 0.6877250683150793
Epoch: 24 | Iteration number: [770/4518] 17% | Training loss: 0.6877108088561467
Epoch: 24 | Iteration number: [780/4518] 17% | Training loss: 0.6876879813579413
Epoch: 24 | Iteration number: [790/4518] 17% | Training loss: 0.6876605529573899
Epoch: 24 | Iteration number: [800/4518] 17% | Training loss: 0.6876534194499254
Epoch: 24 | Iteration number: [810/4518] 17% | Training loss: 0.6876408211243006
Epoch: 24 | Iteration number: [820/4518] 18% | Training loss: 0.6876246103426306
Epoch: 24 | Iteration number: [830/4518] 18% | Training loss: 0.6876126900494817
Epoch: 24 | Iteration number: [840/4518] 18% | Training loss: 0.6876022240235692
Epoch: 24 | Iteration number: [850/4518] 18% | Training loss: 0.687588565489825
Epoch: 24 | Iteration number: [860/4518] 19% | Training loss: 0.6875789707483247
Epoch: 24 | Iteration number: [870/4518] 19% | Training loss: 0.6875820794324765
Epoch: 24 | Iteration number: [880/4518] 19% | Training loss: 0.6875799259678884
Epoch: 24 | Iteration number: [890/4518] 19% | Training loss: 0.6875626314891858
Epoch: 24 | Iteration number: [900/4518] 19% | Training loss: 0.6875585545433892
Epoch: 24 | Iteration number: [910/4518] 20% | Training loss: 0.6875379680932223
Epoch: 24 | Iteration number: [920/4518] 20% | Training loss: 0.6875436803568964
Epoch: 24 | Iteration number: [930/4518] 20% | Training loss: 0.6875347621338341
Epoch: 24 | Iteration number: [940/4518] 20% | Training loss: 0.6875243416491975
Epoch: 24 | Iteration number: [950/4518] 21% | Training loss: 0.6875261176887312
Epoch: 24 | Iteration number: [960/4518] 21% | Training loss: 0.6875030694529414
Epoch: 24 | Iteration number: [970/4518] 21% | Training loss: 0.6874903387015627
Epoch: 24 | Iteration number: [980/4518] 21% | Training loss: 0.6874877294107359
Epoch: 24 | Iteration number: [990/4518] 21% | Training loss: 0.6874872464724261
Epoch: 24 | Iteration number: [1000/4518] 22% | Training loss: 0.6874874605536461
Epoch: 24 | Iteration number: [1010/4518] 22% | Training loss: 0.6874932407152534
Epoch: 24 | Iteration number: [1020/4518] 22% | Training loss: 0.687487337402269
Epoch: 24 | Iteration number: [1030/4518] 22% | Training loss: 0.6874866871000493
Epoch: 24 | Iteration number: [1040/4518] 23% | Training loss: 0.6874760079269225
Epoch: 24 | Iteration number: [1050/4518] 23% | Training loss: 0.6874645357472556
Epoch: 24 | Iteration number: [1060/4518] 23% | Training loss: 0.687451775343913
Epoch: 24 | Iteration number: [1070/4518] 23% | Training loss: 0.6874402175996905
Epoch: 24 | Iteration number: [1080/4518] 23% | Training loss: 0.6874219907102761
Epoch: 24 | Iteration number: [1090/4518] 24% | Training loss: 0.6874196862955706
Epoch: 24 | Iteration number: [1100/4518] 24% | Training loss: 0.68741854169152
Epoch: 24 | Iteration number: [1110/4518] 24% | Training loss: 0.6874226540058582
Epoch: 24 | Iteration number: [1120/4518] 24% | Training loss: 0.6874193337879011
Epoch: 24 | Iteration number: [1130/4518] 25% | Training loss: 0.6874185992553171
Epoch: 24 | Iteration number: [1140/4518] 25% | Training loss: 0.6874087683464352
Epoch: 24 | Iteration number: [1150/4518] 25% | Training loss: 0.6874075490495433
Epoch: 24 | Iteration number: [1160/4518] 25% | Training loss: 0.6873999867459823
Epoch: 24 | Iteration number: [1170/4518] 25% | Training loss: 0.687386221304918
Epoch: 24 | Iteration number: [1180/4518] 26% | Training loss: 0.6873826654280646
Epoch: 24 | Iteration number: [1190/4518] 26% | Training loss: 0.6873754162247442
Epoch: 24 | Iteration number: [1200/4518] 26% | Training loss: 0.6873679578800996
Epoch: 24 | Iteration number: [1210/4518] 26% | Training loss: 0.6873688145117326
Epoch: 24 | Iteration number: [1220/4518] 27% | Training loss: 0.6873710402211205
Epoch: 24 | Iteration number: [1230/4518] 27% | Training loss: 0.6873679386891001
Epoch: 24 | Iteration number: [1240/4518] 27% | Training loss: 0.6873643326663201
Epoch: 24 | Iteration number: [1250/4518] 27% | Training loss: 0.6873577408790589
Epoch: 24 | Iteration number: [1260/4518] 27% | Training loss: 0.6873583505077968
Epoch: 24 | Iteration number: [1270/4518] 28% | Training loss: 0.6873596194222218
Epoch: 24 | Iteration number: [1280/4518] 28% | Training loss: 0.687365620676428
Epoch: 24 | Iteration number: [1290/4518] 28% | Training loss: 0.6873682372791823
Epoch: 24 | Iteration number: [1300/4518] 28% | Training loss: 0.687366461111949
Epoch: 24 | Iteration number: [1310/4518] 28% | Training loss: 0.6873564776573472
Epoch: 24 | Iteration number: [1320/4518] 29% | Training loss: 0.6873533889199748
Epoch: 24 | Iteration number: [1330/4518] 29% | Training loss: 0.6873573777819039
Epoch: 24 | Iteration number: [1340/4518] 29% | Training loss: 0.6873504305953411
Epoch: 24 | Iteration number: [1350/4518] 29% | Training loss: 0.6873529022711294
Epoch: 24 | Iteration number: [1360/4518] 30% | Training loss: 0.6873434410375707
Epoch: 24 | Iteration number: [1370/4518] 30% | Training loss: 0.6873438948262347
Epoch: 24 | Iteration number: [1380/4518] 30% | Training loss: 0.6873486963303193
Epoch: 24 | Iteration number: [1390/4518] 30% | Training loss: 0.6873494489587468
Epoch: 24 | Iteration number: [1400/4518] 30% | Training loss: 0.687345210313797
Epoch: 24 | Iteration number: [1410/4518] 31% | Training loss: 0.6873461789273201
Epoch: 24 | Iteration number: [1420/4518] 31% | Training loss: 0.6873468073321061
Epoch: 24 | Iteration number: [1430/4518] 31% | Training loss: 0.6873436065403732
Epoch: 24 | Iteration number: [1440/4518] 31% | Training loss: 0.6873344155235424
Epoch: 24 | Iteration number: [1450/4518] 32% | Training loss: 0.6873315021087384
Epoch: 24 | Iteration number: [1460/4518] 32% | Training loss: 0.6873342211932352
Epoch: 24 | Iteration number: [1470/4518] 32% | Training loss: 0.6873276012689888
Epoch: 24 | Iteration number: [1480/4518] 32% | Training loss: 0.6873258183534081
Epoch: 24 | Iteration number: [1490/4518] 32% | Training loss: 0.6873213163558268
Epoch: 24 | Iteration number: [1500/4518] 33% | Training loss: 0.6873183177312215
Epoch: 24 | Iteration number: [1510/4518] 33% | Training loss: 0.68731561800502
Epoch: 24 | Iteration number: [1520/4518] 33% | Training loss: 0.6873189590479198
Epoch: 24 | Iteration number: [1530/4518] 33% | Training loss: 0.6873150762000115
Epoch: 24 | Iteration number: [1540/4518] 34% | Training loss: 0.6873089303831001
Epoch: 24 | Iteration number: [1550/4518] 34% | Training loss: 0.6873086845105694
Epoch: 24 | Iteration number: [1560/4518] 34% | Training loss: 0.6873064770530432
Epoch: 24 | Iteration number: [1570/4518] 34% | Training loss: 0.6872969519940152
Epoch: 24 | Iteration number: [1580/4518] 34% | Training loss: 0.6872969610404365
Epoch: 24 | Iteration number: [1590/4518] 35% | Training loss: 0.6872894023199502
Epoch: 24 | Iteration number: [1600/4518] 35% | Training loss: 0.6872905232012272
Epoch: 24 | Iteration number: [1610/4518] 35% | Training loss: 0.6872836530208588
Epoch: 24 | Iteration number: [1620/4518] 35% | Training loss: 0.6872904734111126
Epoch: 24 | Iteration number: [1630/4518] 36% | Training loss: 0.6872934013422282
Epoch: 24 | Iteration number: [1640/4518] 36% | Training loss: 0.6872863461695067
Epoch: 24 | Iteration number: [1650/4518] 36% | Training loss: 0.6872919617277203
Epoch: 24 | Iteration number: [1660/4518] 36% | Training loss: 0.6872874928885195
Epoch: 24 | Iteration number: [1670/4518] 36% | Training loss: 0.6872833450040418
Epoch: 24 | Iteration number: [1680/4518] 37% | Training loss: 0.6872767370016802
Epoch: 24 | Iteration number: [1690/4518] 37% | Training loss: 0.6872751254301804
Epoch: 24 | Iteration number: [1700/4518] 37% | Training loss: 0.6872675461979474
Epoch: 24 | Iteration number: [1710/4518] 37% | Training loss: 0.6872673190825167
Epoch: 24 | Iteration number: [1720/4518] 38% | Training loss: 0.6872611450941064
Epoch: 24 | Iteration number: [1730/4518] 38% | Training loss: 0.6872615111701061
Epoch: 24 | Iteration number: [1740/4518] 38% | Training loss: 0.6872534499428739
Epoch: 24 | Iteration number: [1750/4518] 38% | Training loss: 0.6872492616857802
Epoch: 24 | Iteration number: [1760/4518] 38% | Training loss: 0.6872486405074596
Epoch: 24 | Iteration number: [1770/4518] 39% | Training loss: 0.6872454920057524
Epoch: 24 | Iteration number: [1780/4518] 39% | Training loss: 0.6872480235407862
Epoch: 24 | Iteration number: [1790/4518] 39% | Training loss: 0.6872462658242806
Epoch: 24 | Iteration number: [1800/4518] 39% | Training loss: 0.6872440518604385
Epoch: 24 | Iteration number: [1810/4518] 40% | Training loss: 0.6872391885486097
Epoch: 24 | Iteration number: [1820/4518] 40% | Training loss: 0.6872416956084115
Epoch: 24 | Iteration number: [1830/4518] 40% | Training loss: 0.6872391045419245
Epoch: 24 | Iteration number: [1840/4518] 40% | Training loss: 0.6872366264786409
Epoch: 24 | Iteration number: [1850/4518] 40% | Training loss: 0.6872332367059347
Epoch: 24 | Iteration number: [1860/4518] 41% | Training loss: 0.6872322969859647
Epoch: 24 | Iteration number: [1870/4518] 41% | Training loss: 0.6872206209815123
Epoch: 24 | Iteration number: [1880/4518] 41% | Training loss: 0.6872089680205
Epoch: 24 | Iteration number: [1890/4518] 41% | Training loss: 0.6872083109522623
Epoch: 24 | Iteration number: [1900/4518] 42% | Training loss: 0.6872028805080213
Epoch: 24 | Iteration number: [1910/4518] 42% | Training loss: 0.6871961485653023
Epoch: 24 | Iteration number: [1920/4518] 42% | Training loss: 0.6871935418186088
Epoch: 24 | Iteration number: [1930/4518] 42% | Training loss: 0.6871885963054518
Epoch: 24 | Iteration number: [1940/4518] 42% | Training loss: 0.687185778968113
Epoch: 24 | Iteration number: [1950/4518] 43% | Training loss: 0.6871799820203047
Epoch: 24 | Iteration number: [1960/4518] 43% | Training loss: 0.6871761321717379
Epoch: 24 | Iteration number: [1970/4518] 43% | Training loss: 0.6871692284109628
Epoch: 24 | Iteration number: [1980/4518] 43% | Training loss: 0.6871722918568235
Epoch: 24 | Iteration number: [1990/4518] 44% | Training loss: 0.6871704442117681
Epoch: 24 | Iteration number: [2000/4518] 44% | Training loss: 0.6871709041297436
Epoch: 24 | Iteration number: [2010/4518] 44% | Training loss: 0.6871706562552286
Epoch: 24 | Iteration number: [2020/4518] 44% | Training loss: 0.6871643856315329
Epoch: 24 | Iteration number: [2030/4518] 44% | Training loss: 0.6871623667590137
Epoch: 24 | Iteration number: [2040/4518] 45% | Training loss: 0.6871581783189493
Epoch: 24 | Iteration number: [2050/4518] 45% | Training loss: 0.6871592941807537
Epoch: 24 | Iteration number: [2060/4518] 45% | Training loss: 0.6871569458720753
Epoch: 24 | Iteration number: [2070/4518] 45% | Training loss: 0.6871523908370935
Epoch: 24 | Iteration number: [2080/4518] 46% | Training loss: 0.6871466276164239
Epoch: 24 | Iteration number: [2090/4518] 46% | Training loss: 0.6871418909878252
Epoch: 24 | Iteration number: [2100/4518] 46% | Training loss: 0.6871447962806339
Epoch: 24 | Iteration number: [2110/4518] 46% | Training loss: 0.6871450384928717
Epoch: 24 | Iteration number: [2120/4518] 46% | Training loss: 0.6871447463642876
Epoch: 24 | Iteration number: [2130/4518] 47% | Training loss: 0.6871385832907448
Epoch: 24 | Iteration number: [2140/4518] 47% | Training loss: 0.6871332375802727
Epoch: 24 | Iteration number: [2150/4518] 47% | Training loss: 0.6871325232539066
Epoch: 24 | Iteration number: [2160/4518] 47% | Training loss: 0.6871313380698363
Epoch: 24 | Iteration number: [2170/4518] 48% | Training loss: 0.6871340877449458
Epoch: 24 | Iteration number: [2180/4518] 48% | Training loss: 0.6871223719841844
Epoch: 24 | Iteration number: [2190/4518] 48% | Training loss: 0.6871307020590186
Epoch: 24 | Iteration number: [2200/4518] 48% | Training loss: 0.6871300888061523
Epoch: 24 | Iteration number: [2210/4518] 48% | Training loss: 0.6871357175829184
Epoch: 24 | Iteration number: [2220/4518] 49% | Training loss: 0.6871315244081858
Epoch: 24 | Iteration number: [2230/4518] 49% | Training loss: 0.6871339785143934
Epoch: 24 | Iteration number: [2240/4518] 49% | Training loss: 0.6871342258527875
Epoch: 24 | Iteration number: [2250/4518] 49% | Training loss: 0.6871314446396298
Epoch: 24 | Iteration number: [2260/4518] 50% | Training loss: 0.6871271232588101
Epoch: 24 | Iteration number: [2270/4518] 50% | Training loss: 0.6871269503091401
Epoch: 24 | Iteration number: [2280/4518] 50% | Training loss: 0.687131366551968
Epoch: 24 | Iteration number: [2290/4518] 50% | Training loss: 0.6871281729775225
Epoch: 24 | Iteration number: [2300/4518] 50% | Training loss: 0.6871314101633819
Epoch: 24 | Iteration number: [2310/4518] 51% | Training loss: 0.6871297050606121
Epoch: 24 | Iteration number: [2320/4518] 51% | Training loss: 0.687127505808041
Epoch: 24 | Iteration number: [2330/4518] 51% | Training loss: 0.6871292410746153
Epoch: 24 | Iteration number: [2340/4518] 51% | Training loss: 0.6871297693405396
Epoch: 24 | Iteration number: [2350/4518] 52% | Training loss: 0.6871296004285203
Epoch: 24 | Iteration number: [2360/4518] 52% | Training loss: 0.6871345243969206
Epoch: 24 | Iteration number: [2370/4518] 52% | Training loss: 0.6871344795709924
Epoch: 24 | Iteration number: [2380/4518] 52% | Training loss: 0.6871282682198436
Epoch: 24 | Iteration number: [2390/4518] 52% | Training loss: 0.6871311325907209
Epoch: 24 | Iteration number: [2400/4518] 53% | Training loss: 0.6871324624369541
Epoch: 24 | Iteration number: [2410/4518] 53% | Training loss: 0.6871310146023129
Epoch: 24 | Iteration number: [2420/4518] 53% | Training loss: 0.6871333665591626
Epoch: 24 | Iteration number: [2430/4518] 53% | Training loss: 0.687135473936183
Epoch: 24 | Iteration number: [2440/4518] 54% | Training loss: 0.6871374967401145
Epoch: 24 | Iteration number: [2450/4518] 54% | Training loss: 0.6871414610317775
Epoch: 24 | Iteration number: [2460/4518] 54% | Training loss: 0.6871397390840499
Epoch: 24 | Iteration number: [2470/4518] 54% | Training loss: 0.6871392850451141
Epoch: 24 | Iteration number: [2480/4518] 54% | Training loss: 0.687133341066299
Epoch: 24 | Iteration number: [2490/4518] 55% | Training loss: 0.6871311263147607
Epoch: 24 | Iteration number: [2500/4518] 55% | Training loss: 0.6871323239326477
Epoch: 24 | Iteration number: [2510/4518] 55% | Training loss: 0.6871299943600992
Epoch: 24 | Iteration number: [2520/4518] 55% | Training loss: 0.6871294401940845
Epoch: 24 | Iteration number: [2530/4518] 55% | Training loss: 0.6871285794045143
Epoch: 24 | Iteration number: [2540/4518] 56% | Training loss: 0.6871245436311707
Epoch: 24 | Iteration number: [2550/4518] 56% | Training loss: 0.6871225985358743
Epoch: 24 | Iteration number: [2560/4518] 56% | Training loss: 0.6871232624864205
Epoch: 24 | Iteration number: [2570/4518] 56% | Training loss: 0.6871231107396374
Epoch: 24 | Iteration number: [2580/4518] 57% | Training loss: 0.6871217130459556
Epoch: 24 | Iteration number: [2590/4518] 57% | Training loss: 0.6871212293512573
Epoch: 24 | Iteration number: [2600/4518] 57% | Training loss: 0.687120367701237
Epoch: 24 | Iteration number: [2610/4518] 57% | Training loss: 0.6871220779144901
Epoch: 24 | Iteration number: [2620/4518] 57% | Training loss: 0.6871263932180769
Epoch: 24 | Iteration number: [2630/4518] 58% | Training loss: 0.6871272971421594
Epoch: 24 | Iteration number: [2640/4518] 58% | Training loss: 0.6871249757932895
Epoch: 24 | Iteration number: [2650/4518] 58% | Training loss: 0.6871297498694006
Epoch: 24 | Iteration number: [2660/4518] 58% | Training loss: 0.6871369877704104
Epoch: 24 | Iteration number: [2670/4518] 59% | Training loss: 0.6871369895193907
Epoch: 24 | Iteration number: [2680/4518] 59% | Training loss: 0.687131927373694
Epoch: 24 | Iteration number: [2690/4518] 59% | Training loss: 0.6871338961735977
Epoch: 24 | Iteration number: [2700/4518] 59% | Training loss: 0.6871373306159619
Epoch: 24 | Iteration number: [2710/4518] 59% | Training loss: 0.6871408874258345
Epoch: 24 | Iteration number: [2720/4518] 60% | Training loss: 0.6871423893553369
Epoch: 24 | Iteration number: [2730/4518] 60% | Training loss: 0.6871398216857142
Epoch: 24 | Iteration number: [2740/4518] 60% | Training loss: 0.6871387246533902
Epoch: 24 | Iteration number: [2750/4518] 60% | Training loss: 0.6871351302320307
Epoch: 24 | Iteration number: [2760/4518] 61% | Training loss: 0.687134396036466
Epoch: 24 | Iteration number: [2770/4518] 61% | Training loss: 0.6871293499151292
Epoch: 24 | Iteration number: [2780/4518] 61% | Training loss: 0.687128836817021
Epoch: 24 | Iteration number: [2790/4518] 61% | Training loss: 0.6871258413492565
Epoch: 24 | Iteration number: [2800/4518] 61% | Training loss: 0.6871280489436218
Epoch: 24 | Iteration number: [2810/4518] 62% | Training loss: 0.6871324113043178
Epoch: 24 | Iteration number: [2820/4518] 62% | Training loss: 0.6871314118939934
Epoch: 24 | Iteration number: [2830/4518] 62% | Training loss: 0.6871304359747749
Epoch: 24 | Iteration number: [2840/4518] 62% | Training loss: 0.6871250204846893
Epoch: 24 | Iteration number: [2850/4518] 63% | Training loss: 0.687126447777999
Epoch: 24 | Iteration number: [2860/4518] 63% | Training loss: 0.6871255165005064
Epoch: 24 | Iteration number: [2870/4518] 63% | Training loss: 0.6871264083875597
Epoch: 24 | Iteration number: [2880/4518] 63% | Training loss: 0.6871271129904521
Epoch: 24 | Iteration number: [2890/4518] 63% | Training loss: 0.687125222307588
Epoch: 24 | Iteration number: [2900/4518] 64% | Training loss: 0.687126671712974
Epoch: 24 | Iteration number: [2910/4518] 64% | Training loss: 0.6871246578562301
Epoch: 24 | Iteration number: [2920/4518] 64% | Training loss: 0.6871270556360075
Epoch: 24 | Iteration number: [2930/4518] 64% | Training loss: 0.6871211664261672
Epoch: 24 | Iteration number: [2940/4518] 65% | Training loss: 0.6871249467337213
Epoch: 24 | Iteration number: [2950/4518] 65% | Training loss: 0.6871261433827675
Epoch: 24 | Iteration number: [2960/4518] 65% | Training loss: 0.6871277941038479
Epoch: 24 | Iteration number: [2970/4518] 65% | Training loss: 0.6871257468104763
Epoch: 24 | Iteration number: [2980/4518] 65% | Training loss: 0.6871240295019726
Epoch: 24 | Iteration number: [2990/4518] 66% | Training loss: 0.6871239400428274
Epoch: 24 | Iteration number: [3000/4518] 66% | Training loss: 0.6871232780019442
Epoch: 24 | Iteration number: [3010/4518] 66% | Training loss: 0.6871242662204856
Epoch: 24 | Iteration number: [3020/4518] 66% | Training loss: 0.6871218747453184
Epoch: 24 | Iteration number: [3030/4518] 67% | Training loss: 0.6871174571537736
Epoch: 24 | Iteration number: [3040/4518] 67% | Training loss: 0.6871186438947916
Epoch: 24 | Iteration number: [3050/4518] 67% | Training loss: 0.6871171201252546
Epoch: 24 | Iteration number: [3060/4518] 67% | Training loss: 0.6871224521811492
Epoch: 24 | Iteration number: [3070/4518] 67% | Training loss: 0.6871223221190201
Epoch: 24 | Iteration number: [3080/4518] 68% | Training loss: 0.6871255724074005
Epoch: 24 | Iteration number: [3090/4518] 68% | Training loss: 0.6871301110315478
Epoch: 24 | Iteration number: [3100/4518] 68% | Training loss: 0.6871251554066135
Epoch: 24 | Iteration number: [3110/4518] 68% | Training loss: 0.687123609451619
Epoch: 24 | Iteration number: [3120/4518] 69% | Training loss: 0.6871253439440177
Epoch: 24 | Iteration number: [3130/4518] 69% | Training loss: 0.6871185142011307
Epoch: 24 | Iteration number: [3140/4518] 69% | Training loss: 0.6871216143582277
Epoch: 24 | Iteration number: [3150/4518] 69% | Training loss: 0.6871197419507163
Epoch: 24 | Iteration number: [3160/4518] 69% | Training loss: 0.687119821713695
Epoch: 24 | Iteration number: [3170/4518] 70% | Training loss: 0.6871215031914154
Epoch: 24 | Iteration number: [3180/4518] 70% | Training loss: 0.6871213355529233
Epoch: 24 | Iteration number: [3190/4518] 70% | Training loss: 0.6871180353680374
Epoch: 24 | Iteration number: [3200/4518] 70% | Training loss: 0.6871192714199423
Epoch: 24 | Iteration number: [3210/4518] 71% | Training loss: 0.6871175111639908
Epoch: 24 | Iteration number: [3220/4518] 71% | Training loss: 0.6871125189228828
Epoch: 24 | Iteration number: [3230/4518] 71% | Training loss: 0.6871045531134118
Epoch: 24 | Iteration number: [3240/4518] 71% | Training loss: 0.6871016011377912
Epoch: 24 | Iteration number: [3250/4518] 71% | Training loss: 0.6871024432732509
Epoch: 24 | Iteration number: [3260/4518] 72% | Training loss: 0.6871013123930597
Epoch: 24 | Iteration number: [3270/4518] 72% | Training loss: 0.687100482023455
Epoch: 24 | Iteration number: [3280/4518] 72% | Training loss: 0.687096042458604
Epoch: 24 | Iteration number: [3290/4518] 72% | Training loss: 0.6870941209938026
Epoch: 24 | Iteration number: [3300/4518] 73% | Training loss: 0.687093113046704
Epoch: 24 | Iteration number: [3310/4518] 73% | Training loss: 0.6870918504781233
Epoch: 24 | Iteration number: [3320/4518] 73% | Training loss: 0.6870866799390459
Epoch: 24 | Iteration number: [3330/4518] 73% | Training loss: 0.6870832723540229
Epoch: 24 | Iteration number: [3340/4518] 73% | Training loss: 0.6870822054540325
Epoch: 24 | Iteration number: [3350/4518] 74% | Training loss: 0.6870851366911361
Epoch: 24 | Iteration number: [3360/4518] 74% | Training loss: 0.6870820668126856
Epoch: 24 | Iteration number: [3370/4518] 74% | Training loss: 0.687078566190397
Epoch: 24 | Iteration number: [3380/4518] 74% | Training loss: 0.6870769365475728
Epoch: 24 | Iteration number: [3390/4518] 75% | Training loss: 0.687080881781986
Epoch: 24 | Iteration number: [3400/4518] 75% | Training loss: 0.6870852092784994
Epoch: 24 | Iteration number: [3410/4518] 75% | Training loss: 0.6870823384554855
Epoch: 24 | Iteration number: [3420/4518] 75% | Training loss: 0.6870859381051091
Epoch: 24 | Iteration number: [3430/4518] 75% | Training loss: 0.6870874681034866
Epoch: 24 | Iteration number: [3440/4518] 76% | Training loss: 0.6870880902333315
Epoch: 24 | Iteration number: [3450/4518] 76% | Training loss: 0.687087176070697
Epoch: 24 | Iteration number: [3460/4518] 76% | Training loss: 0.6870864464885238
Epoch: 24 | Iteration number: [3470/4518] 76% | Training loss: 0.6870884663261666
Epoch: 24 | Iteration number: [3480/4518] 77% | Training loss: 0.6870832709402873
Epoch: 24 | Iteration number: [3490/4518] 77% | Training loss: 0.6870855065847195
Epoch: 24 | Iteration number: [3500/4518] 77% | Training loss: 0.687084956731115
Epoch: 24 | Iteration number: [3510/4518] 77% | Training loss: 0.687084971652751
Epoch: 24 | Iteration number: [3520/4518] 77% | Training loss: 0.6870850823480975
Epoch: 24 | Iteration number: [3530/4518] 78% | Training loss: 0.6870863173737405
Epoch: 24 | Iteration number: [3540/4518] 78% | Training loss: 0.6870842414723951
Epoch: 24 | Iteration number: [3550/4518] 78% | Training loss: 0.6870843440881917
Epoch: 24 | Iteration number: [3560/4518] 78% | Training loss: 0.687087079447307
Epoch: 24 | Iteration number: [3570/4518] 79% | Training loss: 0.6870840290013481
Epoch: 24 | Iteration number: [3580/4518] 79% | Training loss: 0.6870822289969002
Epoch: 24 | Iteration number: [3590/4518] 79% | Training loss: 0.6870834828419273
Epoch: 24 | Iteration number: [3600/4518] 79% | Training loss: 0.6870825975471073
Epoch: 24 | Iteration number: [3610/4518] 79% | Training loss: 0.6870863976571038
Epoch: 24 | Iteration number: [3620/4518] 80% | Training loss: 0.6870872857326961
Epoch: 24 | Iteration number: [3630/4518] 80% | Training loss: 0.6870828325426611
Epoch: 24 | Iteration number: [3640/4518] 80% | Training loss: 0.6870868754255902
Epoch: 24 | Iteration number: [3650/4518] 80% | Training loss: 0.6870876509196138
Epoch: 24 | Iteration number: [3660/4518] 81% | Training loss: 0.6870835475094331
Epoch: 24 | Iteration number: [3670/4518] 81% | Training loss: 0.6870812079399743
Epoch: 24 | Iteration number: [3680/4518] 81% | Training loss: 0.6870836503155854
Epoch: 24 | Iteration number: [3690/4518] 81% | Training loss: 0.6870829206010514
Epoch: 24 | Iteration number: [3700/4518] 81% | Training loss: 0.6870844414427474
Epoch: 24 | Iteration number: [3710/4518] 82% | Training loss: 0.687087676370883
Epoch: 24 | Iteration number: [3720/4518] 82% | Training loss: 0.6870862555599981
Epoch: 24 | Iteration number: [3730/4518] 82% | Training loss: 0.6870843272426492
Epoch: 24 | Iteration number: [3740/4518] 82% | Training loss: 0.6870855752956421
Epoch: 24 | Iteration number: [3750/4518] 83% | Training loss: 0.6870811008135478
Epoch: 24 | Iteration number: [3760/4518] 83% | Training loss: 0.6870792392562044
Epoch: 24 | Iteration number: [3770/4518] 83% | Training loss: 0.6870796618948565
Epoch: 24 | Iteration number: [3780/4518] 83% | Training loss: 0.687079170677397
Epoch: 24 | Iteration number: [3790/4518] 83% | Training loss: 0.6870789096034611
Epoch: 24 | Iteration number: [3800/4518] 84% | Training loss: 0.6870782159033575
Epoch: 24 | Iteration number: [3810/4518] 84% | Training loss: 0.6870770572051601
Epoch: 24 | Iteration number: [3820/4518] 84% | Training loss: 0.6870758541903571
Epoch: 24 | Iteration number: [3830/4518] 84% | Training loss: 0.6870732565772751
Epoch: 24 | Iteration number: [3840/4518] 84% | Training loss: 0.6870738415202747
Epoch: 24 | Iteration number: [3850/4518] 85% | Training loss: 0.6870745597721695
Epoch: 24 | Iteration number: [3860/4518] 85% | Training loss: 0.687075622047785
Epoch: 24 | Iteration number: [3870/4518] 85% | Training loss: 0.6870794193535196
Epoch: 24 | Iteration number: [3880/4518] 85% | Training loss: 0.6870775606368006
Epoch: 24 | Iteration number: [3890/4518] 86% | Training loss: 0.6870773785065256
Epoch: 24 | Iteration number: [3900/4518] 86% | Training loss: 0.6870758715042701
Epoch: 24 | Iteration number: [3910/4518] 86% | Training loss: 0.6870744760384035
Epoch: 24 | Iteration number: [3920/4518] 86% | Training loss: 0.687074797843792
Epoch: 24 | Iteration number: [3930/4518] 86% | Training loss: 0.6870736378446487
Epoch: 24 | Iteration number: [3940/4518] 87% | Training loss: 0.6870725589809079
Epoch: 24 | Iteration number: [3950/4518] 87% | Training loss: 0.6870703717575798
Epoch: 24 | Iteration number: [3960/4518] 87% | Training loss: 0.6870701989742241
Epoch: 24 | Iteration number: [3970/4518] 87% | Training loss: 0.6870656572751495
Epoch: 24 | Iteration number: [3980/4518] 88% | Training loss: 0.6870639638385581
Epoch: 24 | Iteration number: [3990/4518] 88% | Training loss: 0.6870640832529331
Epoch: 24 | Iteration number: [4000/4518] 88% | Training loss: 0.6870626443475485
Epoch: 24 | Iteration number: [4010/4518] 88% | Training loss: 0.6870637524900888
Epoch: 24 | Iteration number: [4020/4518] 88% | Training loss: 0.6870592880308332
Epoch: 24 | Iteration number: [4030/4518] 89% | Training loss: 0.6870571269882524
Epoch: 24 | Iteration number: [4040/4518] 89% | Training loss: 0.68705775731861
Epoch: 24 | Iteration number: [4050/4518] 89% | Training loss: 0.6870586079579812
Epoch: 24 | Iteration number: [4060/4518] 89% | Training loss: 0.6870610065207693
Epoch: 24 | Iteration number: [4070/4518] 90% | Training loss: 0.6870628163767681
Epoch: 24 | Iteration number: [4080/4518] 90% | Training loss: 0.6870625685243046
Epoch: 24 | Iteration number: [4090/4518] 90% | Training loss: 0.6870648196682079
Epoch: 24 | Iteration number: [4100/4518] 90% | Training loss: 0.6870639941023617
Epoch: 24 | Iteration number: [4110/4518] 90% | Training loss: 0.6870599300466895
Epoch: 24 | Iteration number: [4120/4518] 91% | Training loss: 0.6870607500371424
Epoch: 24 | Iteration number: [4130/4518] 91% | Training loss: 0.6870619959317454
Epoch: 24 | Iteration number: [4140/4518] 91% | Training loss: 0.6870628672377499
Epoch: 24 | Iteration number: [4150/4518] 91% | Training loss: 0.6870597433325756
Epoch: 24 | Iteration number: [4160/4518] 92% | Training loss: 0.6870591489598155
Epoch: 24 | Iteration number: [4170/4518] 92% | Training loss: 0.6870588572048169
Epoch: 24 | Iteration number: [4180/4518] 92% | Training loss: 0.6870559355573791
Epoch: 24 | Iteration number: [4190/4518] 92% | Training loss: 0.6870541363883417
Epoch: 24 | Iteration number: [4200/4518] 92% | Training loss: 0.687052569531259
Epoch: 24 | Iteration number: [4210/4518] 93% | Training loss: 0.6870522686251552
Epoch: 24 | Iteration number: [4220/4518] 93% | Training loss: 0.6870528527910675
Epoch: 24 | Iteration number: [4230/4518] 93% | Training loss: 0.6870549575375046
Epoch: 24 | Iteration number: [4240/4518] 93% | Training loss: 0.6870546965666537
Epoch: 24 | Iteration number: [4250/4518] 94% | Training loss: 0.6870540742733899
Epoch: 24 | Iteration number: [4260/4518] 94% | Training loss: 0.6870574060740046
Epoch: 24 | Iteration number: [4270/4518] 94% | Training loss: 0.6870546415203908
Epoch: 24 | Iteration number: [4280/4518] 94% | Training loss: 0.687053820003416
Epoch: 24 | Iteration number: [4290/4518] 94% | Training loss: 0.6870517290138698
Epoch: 24 | Iteration number: [4300/4518] 95% | Training loss: 0.6870505202371021
Epoch: 24 | Iteration number: [4310/4518] 95% | Training loss: 0.6870462891397233
Epoch: 24 | Iteration number: [4320/4518] 95% | Training loss: 0.6870434379963963
Epoch: 24 | Iteration number: [4330/4518] 95% | Training loss: 0.6870411481235099
Epoch: 24 | Iteration number: [4340/4518] 96% | Training loss: 0.6870413509794094
Epoch: 24 | Iteration number: [4350/4518] 96% | Training loss: 0.6870366422883395
Epoch: 24 | Iteration number: [4360/4518] 96% | Training loss: 0.687035629002873
Epoch: 24 | Iteration number: [4370/4518] 96% | Training loss: 0.6870363686941309
Epoch: 24 | Iteration number: [4380/4518] 96% | Training loss: 0.6870364267940391
Epoch: 24 | Iteration number: [4390/4518] 97% | Training loss: 0.6870353567844643
Epoch: 24 | Iteration number: [4400/4518] 97% | Training loss: 0.6870372629301115
Epoch: 24 | Iteration number: [4410/4518] 97% | Training loss: 0.6870363726367216
Epoch: 24 | Iteration number: [4420/4518] 97% | Training loss: 0.6870364717633476
Epoch: 24 | Iteration number: [4430/4518] 98% | Training loss: 0.6870349790926173
Epoch: 24 | Iteration number: [4440/4518] 98% | Training loss: 0.6870341837674648
Epoch: 24 | Iteration number: [4450/4518] 98% | Training loss: 0.6870327175869031
Epoch: 24 | Iteration number: [4460/4518] 98% | Training loss: 0.6870326375079262
Epoch: 24 | Iteration number: [4470/4518] 98% | Training loss: 0.6870318763741444
Epoch: 24 | Iteration number: [4480/4518] 99% | Training loss: 0.6870352252652603
Epoch: 24 | Iteration number: [4490/4518] 99% | Training loss: 0.6870348975095558
Epoch: 24 | Iteration number: [4500/4518] 99% | Training loss: 0.6870330886178546
Epoch: 24 | Iteration number: [4510/4518] 99% | Training loss: 0.6870349762841498

 End of epoch: 24 | Train Loss: 0.6868829061073136 | Training Time: 643 

 End of epoch: 24 | Eval Loss: 0.6902914290525475 | Evaluating Time: 17 
Epoch: 25 | Iteration number: [10/4518] 0% | Training loss: 0.7564546048641205
Epoch: 25 | Iteration number: [20/4518] 0% | Training loss: 0.7218772858381272
Epoch: 25 | Iteration number: [30/4518] 0% | Training loss: 0.7104613860448201
Epoch: 25 | Iteration number: [40/4518] 0% | Training loss: 0.7042215287685394
Epoch: 25 | Iteration number: [50/4518] 1% | Training loss: 0.7006188559532166
Epoch: 25 | Iteration number: [60/4518] 1% | Training loss: 0.6984260082244873
Epoch: 25 | Iteration number: [70/4518] 1% | Training loss: 0.6967516311577389
Epoch: 25 | Iteration number: [80/4518] 1% | Training loss: 0.6953974910080433
Epoch: 25 | Iteration number: [90/4518] 1% | Training loss: 0.6943646596537696
Epoch: 25 | Iteration number: [100/4518] 2% | Training loss: 0.693542926311493
Epoch: 25 | Iteration number: [110/4518] 2% | Training loss: 0.6928812558000738
Epoch: 25 | Iteration number: [120/4518] 2% | Training loss: 0.6925060962637265
Epoch: 25 | Iteration number: [130/4518] 2% | Training loss: 0.692006890131877
Epoch: 25 | Iteration number: [140/4518] 3% | Training loss: 0.6916757413319179
Epoch: 25 | Iteration number: [150/4518] 3% | Training loss: 0.691402621269226
Epoch: 25 | Iteration number: [160/4518] 3% | Training loss: 0.6911363959312439
Epoch: 25 | Iteration number: [170/4518] 3% | Training loss: 0.6909249070812674
Epoch: 25 | Iteration number: [180/4518] 3% | Training loss: 0.6907148900959227
Epoch: 25 | Iteration number: [190/4518] 4% | Training loss: 0.6905206043469279
Epoch: 25 | Iteration number: [200/4518] 4% | Training loss: 0.6903127807378769
Epoch: 25 | Iteration number: [210/4518] 4% | Training loss: 0.6901456171558017
Epoch: 25 | Iteration number: [220/4518] 4% | Training loss: 0.690021266991442
Epoch: 25 | Iteration number: [230/4518] 5% | Training loss: 0.6898931726165439
Epoch: 25 | Iteration number: [240/4518] 5% | Training loss: 0.6897934926052888
Epoch: 25 | Iteration number: [250/4518] 5% | Training loss: 0.6896538827419281
Epoch: 25 | Iteration number: [260/4518] 5% | Training loss: 0.6894705052559192
Epoch: 25 | Iteration number: [270/4518] 5% | Training loss: 0.6893823601581432
Epoch: 25 | Iteration number: [280/4518] 6% | Training loss: 0.6892955420272691
Epoch: 25 | Iteration number: [290/4518] 6% | Training loss: 0.689252317157285
Epoch: 25 | Iteration number: [300/4518] 6% | Training loss: 0.6891504953304927
Epoch: 25 | Iteration number: [310/4518] 6% | Training loss: 0.6890894626417468
Epoch: 25 | Iteration number: [320/4518] 7% | Training loss: 0.6890371149405837
Epoch: 25 | Iteration number: [330/4518] 7% | Training loss: 0.6889583464824792
Epoch: 25 | Iteration number: [340/4518] 7% | Training loss: 0.6888462731066872
Epoch: 25 | Iteration number: [350/4518] 7% | Training loss: 0.6887714009625571
Epoch: 25 | Iteration number: [360/4518] 7% | Training loss: 0.6887141411503156
Epoch: 25 | Iteration number: [370/4518] 8% | Training loss: 0.6886369260581764
Epoch: 25 | Iteration number: [380/4518] 8% | Training loss: 0.6886062915387906
Epoch: 25 | Iteration number: [390/4518] 8% | Training loss: 0.6885820789214893
Epoch: 25 | Iteration number: [400/4518] 8% | Training loss: 0.6885358710587025
Epoch: 25 | Iteration number: [410/4518] 9% | Training loss: 0.6885136695896706
Epoch: 25 | Iteration number: [420/4518] 9% | Training loss: 0.688458946063405
Epoch: 25 | Iteration number: [430/4518] 9% | Training loss: 0.6884150650612143
Epoch: 25 | Iteration number: [440/4518] 9% | Training loss: 0.688370606303215
Epoch: 25 | Iteration number: [450/4518] 9% | Training loss: 0.6883361048168606
Epoch: 25 | Iteration number: [460/4518] 10% | Training loss: 0.6883056369812592
Epoch: 25 | Iteration number: [470/4518] 10% | Training loss: 0.6882486168374407
Epoch: 25 | Iteration number: [480/4518] 10% | Training loss: 0.6882262596239647
Epoch: 25 | Iteration number: [490/4518] 10% | Training loss: 0.6882115553836433
Epoch: 25 | Iteration number: [500/4518] 11% | Training loss: 0.6881678366661071
Epoch: 25 | Iteration number: [510/4518] 11% | Training loss: 0.6881290237108867
Epoch: 25 | Iteration number: [520/4518] 11% | Training loss: 0.6881010124316582
Epoch: 25 | Iteration number: [530/4518] 11% | Training loss: 0.6880971360881374
Epoch: 25 | Iteration number: [540/4518] 11% | Training loss: 0.688071541984876
Epoch: 25 | Iteration number: [550/4518] 12% | Training loss: 0.688061844327233
Epoch: 25 | Iteration number: [560/4518] 12% | Training loss: 0.6880481859402997
Epoch: 25 | Iteration number: [570/4518] 12% | Training loss: 0.6880436518736053
Epoch: 25 | Iteration number: [580/4518] 12% | Training loss: 0.6880322542683831
Epoch: 25 | Iteration number: [590/4518] 13% | Training loss: 0.6880006392123336
Epoch: 25 | Iteration number: [600/4518] 13% | Training loss: 0.6879885557293892
Epoch: 25 | Iteration number: [610/4518] 13% | Training loss: 0.6879893270672345
Epoch: 25 | Iteration number: [620/4518] 13% | Training loss: 0.6879724906336877
Epoch: 25 | Iteration number: [630/4518] 13% | Training loss: 0.6879296124927581
Epoch: 25 | Iteration number: [640/4518] 14% | Training loss: 0.6879039981402457
Epoch: 25 | Iteration number: [650/4518] 14% | Training loss: 0.6878727736839881
Epoch: 25 | Iteration number: [660/4518] 14% | Training loss: 0.6878659025286183
Epoch: 25 | Iteration number: [670/4518] 14% | Training loss: 0.6878583301359148
Epoch: 25 | Iteration number: [680/4518] 15% | Training loss: 0.6878341210239074
Epoch: 25 | Iteration number: [690/4518] 15% | Training loss: 0.6878176923247351
Epoch: 25 | Iteration number: [700/4518] 15% | Training loss: 0.6878035617726189
Epoch: 25 | Iteration number: [710/4518] 15% | Training loss: 0.6877885685840123
Epoch: 25 | Iteration number: [720/4518] 15% | Training loss: 0.6877920706239011
Epoch: 25 | Iteration number: [730/4518] 16% | Training loss: 0.6877745689594582
Epoch: 25 | Iteration number: [740/4518] 16% | Training loss: 0.6877619102999971
Epoch: 25 | Iteration number: [750/4518] 16% | Training loss: 0.6877584974765778
Epoch: 25 | Iteration number: [760/4518] 16% | Training loss: 0.6877569116259876
Epoch: 25 | Iteration number: [770/4518] 17% | Training loss: 0.6877546872411455
Epoch: 25 | Iteration number: [780/4518] 17% | Training loss: 0.6877403996693783
Epoch: 25 | Iteration number: [790/4518] 17% | Training loss: 0.6877348691602296
Epoch: 25 | Iteration number: [800/4518] 17% | Training loss: 0.6877263650298119
Epoch: 25 | Iteration number: [810/4518] 17% | Training loss: 0.6877104495042636
Epoch: 25 | Iteration number: [820/4518] 18% | Training loss: 0.6877032307589926
Epoch: 25 | Iteration number: [830/4518] 18% | Training loss: 0.687694591786488
Epoch: 25 | Iteration number: [840/4518] 18% | Training loss: 0.687696167471863
Epoch: 25 | Iteration number: [850/4518] 18% | Training loss: 0.6876806230404797
Epoch: 25 | Iteration number: [860/4518] 19% | Training loss: 0.6876687889875368
Epoch: 25 | Iteration number: [870/4518] 19% | Training loss: 0.6876601656963085
Epoch: 25 | Iteration number: [880/4518] 19% | Training loss: 0.687644611299038
Epoch: 25 | Iteration number: [890/4518] 19% | Training loss: 0.687641734621498
Epoch: 25 | Iteration number: [900/4518] 19% | Training loss: 0.6876360223028395
Epoch: 25 | Iteration number: [910/4518] 20% | Training loss: 0.6876270852246127
Epoch: 25 | Iteration number: [920/4518] 20% | Training loss: 0.6876122991675916
Epoch: 25 | Iteration number: [930/4518] 20% | Training loss: 0.6876176013741442
Epoch: 25 | Iteration number: [940/4518] 20% | Training loss: 0.6876087535569009
Epoch: 25 | Iteration number: [950/4518] 21% | Training loss: 0.6876055445169148
Epoch: 25 | Iteration number: [960/4518] 21% | Training loss: 0.6875848640998204
Epoch: 25 | Iteration number: [970/4518] 21% | Training loss: 0.6875725971054785
Epoch: 25 | Iteration number: [980/4518] 21% | Training loss: 0.6875705110175269
Epoch: 25 | Iteration number: [990/4518] 21% | Training loss: 0.6875530518064595
Epoch: 25 | Iteration number: [1000/4518] 22% | Training loss: 0.6875373092889786
Epoch: 25 | Iteration number: [1010/4518] 22% | Training loss: 0.6875303420690027
Epoch: 25 | Iteration number: [1020/4518] 22% | Training loss: 0.6875281942241332
Epoch: 25 | Iteration number: [1030/4518] 22% | Training loss: 0.6875291364285553
Epoch: 25 | Iteration number: [1040/4518] 23% | Training loss: 0.6875300762171929
Epoch: 25 | Iteration number: [1050/4518] 23% | Training loss: 0.6875305413632166
Epoch: 25 | Iteration number: [1060/4518] 23% | Training loss: 0.6875226184444607
Epoch: 25 | Iteration number: [1070/4518] 23% | Training loss: 0.6875142099701356
Epoch: 25 | Iteration number: [1080/4518] 23% | Training loss: 0.6875035694903797
Epoch: 25 | Iteration number: [1090/4518] 24% | Training loss: 0.6874987188829195
Epoch: 25 | Iteration number: [1100/4518] 24% | Training loss: 0.6874928101084449
Epoch: 25 | Iteration number: [1110/4518] 24% | Training loss: 0.6874973675689182
Epoch: 25 | Iteration number: [1120/4518] 24% | Training loss: 0.6874976431684835
Epoch: 25 | Iteration number: [1130/4518] 25% | Training loss: 0.6874948501586914
Epoch: 25 | Iteration number: [1140/4518] 25% | Training loss: 0.6875008112505863
Epoch: 25 | Iteration number: [1150/4518] 25% | Training loss: 0.6875022740986036
Epoch: 25 | Iteration number: [1160/4518] 25% | Training loss: 0.6875099224263224
Epoch: 25 | Iteration number: [1170/4518] 25% | Training loss: 0.6875005396003397
Epoch: 25 | Iteration number: [1180/4518] 26% | Training loss: 0.6875000401573667
Epoch: 25 | Iteration number: [1190/4518] 26% | Training loss: 0.6875000741301465
Epoch: 25 | Iteration number: [1200/4518] 26% | Training loss: 0.6874922949075699
Epoch: 25 | Iteration number: [1210/4518] 26% | Training loss: 0.6874844840242843
Epoch: 25 | Iteration number: [1220/4518] 27% | Training loss: 0.6874800794437284
Epoch: 25 | Iteration number: [1230/4518] 27% | Training loss: 0.6874709016423884
Epoch: 25 | Iteration number: [1240/4518] 27% | Training loss: 0.6874507142651466
Epoch: 25 | Iteration number: [1250/4518] 27% | Training loss: 0.6874364027023315
Epoch: 25 | Iteration number: [1260/4518] 27% | Training loss: 0.6874223506639874
Epoch: 25 | Iteration number: [1270/4518] 28% | Training loss: 0.6874229807553329
Epoch: 25 | Iteration number: [1280/4518] 28% | Training loss: 0.6874157066456974
Epoch: 25 | Iteration number: [1290/4518] 28% | Training loss: 0.6874067591142284
Epoch: 25 | Iteration number: [1300/4518] 28% | Training loss: 0.6874018244101451
Epoch: 25 | Iteration number: [1310/4518] 28% | Training loss: 0.6873930608498231
Epoch: 25 | Iteration number: [1320/4518] 29% | Training loss: 0.687398121212468
Epoch: 25 | Iteration number: [1330/4518] 29% | Training loss: 0.6873922146800765
Epoch: 25 | Iteration number: [1340/4518] 29% | Training loss: 0.6873879117307379
Epoch: 25 | Iteration number: [1350/4518] 29% | Training loss: 0.6873771634808293
Epoch: 25 | Iteration number: [1360/4518] 30% | Training loss: 0.6873738146880094
Epoch: 25 | Iteration number: [1370/4518] 30% | Training loss: 0.6873661525928191
Epoch: 25 | Iteration number: [1380/4518] 30% | Training loss: 0.6873653391133184
Epoch: 25 | Iteration number: [1390/4518] 30% | Training loss: 0.6873564477447126
Epoch: 25 | Iteration number: [1400/4518] 30% | Training loss: 0.6873518397552626
Epoch: 25 | Iteration number: [1410/4518] 31% | Training loss: 0.6873522323919526
Epoch: 25 | Iteration number: [1420/4518] 31% | Training loss: 0.6873470635061533
Epoch: 25 | Iteration number: [1430/4518] 31% | Training loss: 0.6873380887758481
Epoch: 25 | Iteration number: [1440/4518] 31% | Training loss: 0.687338908844524
Epoch: 25 | Iteration number: [1450/4518] 32% | Training loss: 0.6873290202124366
Epoch: 25 | Iteration number: [1460/4518] 32% | Training loss: 0.6873312447985558
Epoch: 25 | Iteration number: [1470/4518] 32% | Training loss: 0.687318663410589
Epoch: 25 | Iteration number: [1480/4518] 32% | Training loss: 0.6873212370518091
Epoch: 25 | Iteration number: [1490/4518] 32% | Training loss: 0.6873141705989838
Epoch: 25 | Iteration number: [1500/4518] 33% | Training loss: 0.6873122700850169
Epoch: 25 | Iteration number: [1510/4518] 33% | Training loss: 0.6873121903037394
Epoch: 25 | Iteration number: [1520/4518] 33% | Training loss: 0.6873023744868605
Epoch: 25 | Iteration number: [1530/4518] 33% | Training loss: 0.6872991191405876
Epoch: 25 | Iteration number: [1540/4518] 34% | Training loss: 0.6873054279909505
Epoch: 25 | Iteration number: [1550/4518] 34% | Training loss: 0.6873090755170391
Epoch: 25 | Iteration number: [1560/4518] 34% | Training loss: 0.6873105888183301
Epoch: 25 | Iteration number: [1570/4518] 34% | Training loss: 0.6873097584885397
Epoch: 25 | Iteration number: [1580/4518] 34% | Training loss: 0.6872970685551438
Epoch: 25 | Iteration number: [1590/4518] 35% | Training loss: 0.6873035471769249
Epoch: 25 | Iteration number: [1600/4518] 35% | Training loss: 0.6873069015145302
Epoch: 25 | Iteration number: [1610/4518] 35% | Training loss: 0.6873108204107107
Epoch: 25 | Iteration number: [1620/4518] 35% | Training loss: 0.6873113188110752
Epoch: 25 | Iteration number: [1630/4518] 36% | Training loss: 0.6873101486384503
Epoch: 25 | Iteration number: [1640/4518] 36% | Training loss: 0.6873136348113781
Epoch: 25 | Iteration number: [1650/4518] 36% | Training loss: 0.6873059954787746
Epoch: 25 | Iteration number: [1660/4518] 36% | Training loss: 0.6873069163546505
Epoch: 25 | Iteration number: [1670/4518] 36% | Training loss: 0.6873025626836423
Epoch: 25 | Iteration number: [1680/4518] 37% | Training loss: 0.6873058153759866
Epoch: 25 | Iteration number: [1690/4518] 37% | Training loss: 0.6873042395481697
Epoch: 25 | Iteration number: [1700/4518] 37% | Training loss: 0.6872962952361388
Epoch: 25 | Iteration number: [1710/4518] 37% | Training loss: 0.6872941295305888
Epoch: 25 | Iteration number: [1720/4518] 38% | Training loss: 0.6872942644842835
Epoch: 25 | Iteration number: [1730/4518] 38% | Training loss: 0.6872865074976331
Epoch: 25 | Iteration number: [1740/4518] 38% | Training loss: 0.6872835493293302
Epoch: 25 | Iteration number: [1750/4518] 38% | Training loss: 0.6872811288833618
Epoch: 25 | Iteration number: [1760/4518] 38% | Training loss: 0.6872738640416752
Epoch: 25 | Iteration number: [1770/4518] 39% | Training loss: 0.6872723220431872
Epoch: 25 | Iteration number: [1780/4518] 39% | Training loss: 0.6872738766871141
Epoch: 25 | Iteration number: [1790/4518] 39% | Training loss: 0.6872713157584547
Epoch: 25 | Iteration number: [1800/4518] 39% | Training loss: 0.6872665310237143
Epoch: 25 | Iteration number: [1810/4518] 40% | Training loss: 0.6872654886206211
Epoch: 25 | Iteration number: [1820/4518] 40% | Training loss: 0.6872585663428673
Epoch: 25 | Iteration number: [1830/4518] 40% | Training loss: 0.6872571913596711
Epoch: 25 | Iteration number: [1840/4518] 40% | Training loss: 0.6872549877218578
Epoch: 25 | Iteration number: [1850/4518] 40% | Training loss: 0.6872561655495618
Epoch: 25 | Iteration number: [1860/4518] 41% | Training loss: 0.6872609542582625
Epoch: 25 | Iteration number: [1870/4518] 41% | Training loss: 0.6872608153896536
Epoch: 25 | Iteration number: [1880/4518] 41% | Training loss: 0.6872536554932595
Epoch: 25 | Iteration number: [1890/4518] 41% | Training loss: 0.6872590375640405
Epoch: 25 | Iteration number: [1900/4518] 42% | Training loss: 0.6872591114985316
Epoch: 25 | Iteration number: [1910/4518] 42% | Training loss: 0.6872598501088107
Epoch: 25 | Iteration number: [1920/4518] 42% | Training loss: 0.687261201068759
Epoch: 25 | Iteration number: [1930/4518] 42% | Training loss: 0.687258003968649
Epoch: 25 | Iteration number: [1940/4518] 42% | Training loss: 0.6872556750614619
Epoch: 25 | Iteration number: [1950/4518] 43% | Training loss: 0.6872507108786168
Epoch: 25 | Iteration number: [1960/4518] 43% | Training loss: 0.6872485512677504
Epoch: 25 | Iteration number: [1970/4518] 43% | Training loss: 0.6872476154777605
Epoch: 25 | Iteration number: [1980/4518] 43% | Training loss: 0.6872372971640692
Epoch: 25 | Iteration number: [1990/4518] 44% | Training loss: 0.6872356755649625
Epoch: 25 | Iteration number: [2000/4518] 44% | Training loss: 0.6872381523251534
Epoch: 25 | Iteration number: [2010/4518] 44% | Training loss: 0.6872406525101827
Epoch: 25 | Iteration number: [2020/4518] 44% | Training loss: 0.6872398159291485
Epoch: 25 | Iteration number: [2030/4518] 44% | Training loss: 0.6872385139242182
Epoch: 25 | Iteration number: [2040/4518] 45% | Training loss: 0.6872404850288933
Epoch: 25 | Iteration number: [2050/4518] 45% | Training loss: 0.6872356072577035
Epoch: 25 | Iteration number: [2060/4518] 45% | Training loss: 0.6872303453463953
Epoch: 25 | Iteration number: [2070/4518] 45% | Training loss: 0.687228520653674
Epoch: 25 | Iteration number: [2080/4518] 46% | Training loss: 0.6872193222435621
Epoch: 25 | Iteration number: [2090/4518] 46% | Training loss: 0.6872185801775261
Epoch: 25 | Iteration number: [2100/4518] 46% | Training loss: 0.6872172796726227
Epoch: 25 | Iteration number: [2110/4518] 46% | Training loss: 0.6872217013655115
Epoch: 25 | Iteration number: [2120/4518] 46% | Training loss: 0.6872253816082793
Epoch: 25 | Iteration number: [2130/4518] 47% | Training loss: 0.6872207448236259
Epoch: 25 | Iteration number: [2140/4518] 47% | Training loss: 0.6872158570267329
Epoch: 25 | Iteration number: [2150/4518] 47% | Training loss: 0.6872091809816139
Epoch: 25 | Iteration number: [2160/4518] 47% | Training loss: 0.6872046894497341
Epoch: 25 | Iteration number: [2170/4518] 48% | Training loss: 0.6872016761434793
Epoch: 25 | Iteration number: [2180/4518] 48% | Training loss: 0.6872020572150519
Epoch: 25 | Iteration number: [2190/4518] 48% | Training loss: 0.6871989356872698
Epoch: 25 | Iteration number: [2200/4518] 48% | Training loss: 0.6871943321011283
Epoch: 25 | Iteration number: [2210/4518] 48% | Training loss: 0.6871913979765517
Epoch: 25 | Iteration number: [2220/4518] 49% | Training loss: 0.6871916072594153
Epoch: 25 | Iteration number: [2230/4518] 49% | Training loss: 0.6871947466792547
Epoch: 25 | Iteration number: [2240/4518] 49% | Training loss: 0.6871914856401937
Epoch: 25 | Iteration number: [2250/4518] 49% | Training loss: 0.6871947338845995
Epoch: 25 | Iteration number: [2260/4518] 50% | Training loss: 0.687196938337478
Epoch: 25 | Iteration number: [2270/4518] 50% | Training loss: 0.6871996066118652
Epoch: 25 | Iteration number: [2280/4518] 50% | Training loss: 0.6872039766688096
Epoch: 25 | Iteration number: [2290/4518] 50% | Training loss: 0.6872063214341626
Epoch: 25 | Iteration number: [2300/4518] 50% | Training loss: 0.6871994935688766
Epoch: 25 | Iteration number: [2310/4518] 51% | Training loss: 0.687197423239291
Epoch: 25 | Iteration number: [2320/4518] 51% | Training loss: 0.687197715686313
Epoch: 25 | Iteration number: [2330/4518] 51% | Training loss: 0.687196027874435
Epoch: 25 | Iteration number: [2340/4518] 51% | Training loss: 0.6871989641943549
Epoch: 25 | Iteration number: [2350/4518] 52% | Training loss: 0.687192035786649
Epoch: 25 | Iteration number: [2360/4518] 52% | Training loss: 0.6871927419961509
Epoch: 25 | Iteration number: [2370/4518] 52% | Training loss: 0.6871899505204793
Epoch: 25 | Iteration number: [2380/4518] 52% | Training loss: 0.6871879574381002
Epoch: 25 | Iteration number: [2390/4518] 52% | Training loss: 0.6871831829079026
Epoch: 25 | Iteration number: [2400/4518] 53% | Training loss: 0.6871878258635601
Epoch: 25 | Iteration number: [2410/4518] 53% | Training loss: 0.6871893390580331
Epoch: 25 | Iteration number: [2420/4518] 53% | Training loss: 0.6871907905359899
Epoch: 25 | Iteration number: [2430/4518] 53% | Training loss: 0.6871849852579611
Epoch: 25 | Iteration number: [2440/4518] 54% | Training loss: 0.6871858412613634
Epoch: 25 | Iteration number: [2450/4518] 54% | Training loss: 0.6871834046743354
Epoch: 25 | Iteration number: [2460/4518] 54% | Training loss: 0.687181641876213
Epoch: 25 | Iteration number: [2470/4518] 54% | Training loss: 0.6871870431340175
Epoch: 25 | Iteration number: [2480/4518] 54% | Training loss: 0.687182210121424
Epoch: 25 | Iteration number: [2490/4518] 55% | Training loss: 0.6871865195442873
Epoch: 25 | Iteration number: [2500/4518] 55% | Training loss: 0.6871826521396637
Epoch: 25 | Iteration number: [2510/4518] 55% | Training loss: 0.6871830170135574
Epoch: 25 | Iteration number: [2520/4518] 55% | Training loss: 0.6871842221844764
Epoch: 25 | Iteration number: [2530/4518] 55% | Training loss: 0.6871803762177705
Epoch: 25 | Iteration number: [2540/4518] 56% | Training loss: 0.6871779273344776
Epoch: 25 | Iteration number: [2550/4518] 56% | Training loss: 0.6871799576983733
Epoch: 25 | Iteration number: [2560/4518] 56% | Training loss: 0.687177890772
Epoch: 25 | Iteration number: [2570/4518] 56% | Training loss: 0.687180486402623
Epoch: 25 | Iteration number: [2580/4518] 57% | Training loss: 0.6871841219968574
Epoch: 25 | Iteration number: [2590/4518] 57% | Training loss: 0.6871739375084984
Epoch: 25 | Iteration number: [2600/4518] 57% | Training loss: 0.6871706501337198
Epoch: 25 | Iteration number: [2610/4518] 57% | Training loss: 0.6871741245532857
Epoch: 25 | Iteration number: [2620/4518] 57% | Training loss: 0.687165379023734
Epoch: 25 | Iteration number: [2630/4518] 58% | Training loss: 0.6871660440366985
Epoch: 25 | Iteration number: [2640/4518] 58% | Training loss: 0.6871662553061139
Epoch: 25 | Iteration number: [2650/4518] 58% | Training loss: 0.6871669824168367
Epoch: 25 | Iteration number: [2660/4518] 58% | Training loss: 0.6871628844424298
Epoch: 25 | Iteration number: [2670/4518] 59% | Training loss: 0.6871606061297856
Epoch: 25 | Iteration number: [2680/4518] 59% | Training loss: 0.6871580220425307
Epoch: 25 | Iteration number: [2690/4518] 59% | Training loss: 0.6871546514193808
Epoch: 25 | Iteration number: [2700/4518] 59% | Training loss: 0.6871480460299386
Epoch: 25 | Iteration number: [2710/4518] 59% | Training loss: 0.6871476977293781
Epoch: 25 | Iteration number: [2720/4518] 60% | Training loss: 0.6871459179064807
Epoch: 25 | Iteration number: [2730/4518] 60% | Training loss: 0.6871435785468245
Epoch: 25 | Iteration number: [2740/4518] 60% | Training loss: 0.6871407343740881
Epoch: 25 | Iteration number: [2750/4518] 60% | Training loss: 0.6871376887451519
Epoch: 25 | Iteration number: [2760/4518] 61% | Training loss: 0.687139722402545
Epoch: 25 | Iteration number: [2770/4518] 61% | Training loss: 0.6871377586888062
Epoch: 25 | Iteration number: [2780/4518] 61% | Training loss: 0.6871386216055575
Epoch: 25 | Iteration number: [2790/4518] 61% | Training loss: 0.6871365473902781
Epoch: 25 | Iteration number: [2800/4518] 61% | Training loss: 0.6871342312438148
Epoch: 25 | Iteration number: [2810/4518] 62% | Training loss: 0.6871335436016639
Epoch: 25 | Iteration number: [2820/4518] 62% | Training loss: 0.6871300222391777
Epoch: 25 | Iteration number: [2830/4518] 62% | Training loss: 0.6871263270664552
Epoch: 25 | Iteration number: [2840/4518] 62% | Training loss: 0.6871203168387144
Epoch: 25 | Iteration number: [2850/4518] 63% | Training loss: 0.6871152507840541
Epoch: 25 | Iteration number: [2860/4518] 63% | Training loss: 0.6871150103482333
Epoch: 25 | Iteration number: [2870/4518] 63% | Training loss: 0.6871085838989098
Epoch: 25 | Iteration number: [2880/4518] 63% | Training loss: 0.6871067218068573
Epoch: 25 | Iteration number: [2890/4518] 63% | Training loss: 0.6871060888247507
Epoch: 25 | Iteration number: [2900/4518] 64% | Training loss: 0.6871072498272205
Epoch: 25 | Iteration number: [2910/4518] 64% | Training loss: 0.6871041732965056
Epoch: 25 | Iteration number: [2920/4518] 64% | Training loss: 0.6871063386536624
Epoch: 25 | Iteration number: [2930/4518] 64% | Training loss: 0.6871028596020395
Epoch: 25 | Iteration number: [2940/4518] 65% | Training loss: 0.6871067790352569
Epoch: 25 | Iteration number: [2950/4518] 65% | Training loss: 0.6871039441884574
Epoch: 25 | Iteration number: [2960/4518] 65% | Training loss: 0.6871054400463362
Epoch: 25 | Iteration number: [2970/4518] 65% | Training loss: 0.6870934133979206
Epoch: 25 | Iteration number: [2980/4518] 65% | Training loss: 0.6870928375512961
Epoch: 25 | Iteration number: [2990/4518] 66% | Training loss: 0.6870951706549795
Epoch: 25 | Iteration number: [3000/4518] 66% | Training loss: 0.687093356013298
Epoch: 25 | Iteration number: [3010/4518] 66% | Training loss: 0.6870880366163793
Epoch: 25 | Iteration number: [3020/4518] 66% | Training loss: 0.6870911670836392
Epoch: 25 | Iteration number: [3030/4518] 67% | Training loss: 0.6870901553347559
Epoch: 25 | Iteration number: [3040/4518] 67% | Training loss: 0.6870917889828745
Epoch: 25 | Iteration number: [3050/4518] 67% | Training loss: 0.6870885331708877
Epoch: 25 | Iteration number: [3060/4518] 67% | Training loss: 0.6870907239859401
Epoch: 25 | Iteration number: [3070/4518] 67% | Training loss: 0.6870893517806398
Epoch: 25 | Iteration number: [3080/4518] 68% | Training loss: 0.6870872642506253
Epoch: 25 | Iteration number: [3090/4518] 68% | Training loss: 0.6870870839623572
Epoch: 25 | Iteration number: [3100/4518] 68% | Training loss: 0.6870844771400575
Epoch: 25 | Iteration number: [3110/4518] 68% | Training loss: 0.6870831927877531
Epoch: 25 | Iteration number: [3120/4518] 69% | Training loss: 0.6870835718054038
Epoch: 25 | Iteration number: [3130/4518] 69% | Training loss: 0.6870838371899943
Epoch: 25 | Iteration number: [3140/4518] 69% | Training loss: 0.6870843771916286
Epoch: 25 | Iteration number: [3150/4518] 69% | Training loss: 0.6870844752447945
Epoch: 25 | Iteration number: [3160/4518] 69% | Training loss: 0.6870886894532396
Epoch: 25 | Iteration number: [3170/4518] 70% | Training loss: 0.6870890525801324
Epoch: 25 | Iteration number: [3180/4518] 70% | Training loss: 0.68708677306865
Epoch: 25 | Iteration number: [3190/4518] 70% | Training loss: 0.6870873025218521
Epoch: 25 | Iteration number: [3200/4518] 70% | Training loss: 0.6870856700837612
Epoch: 25 | Iteration number: [3210/4518] 71% | Training loss: 0.6870854544862408
Epoch: 25 | Iteration number: [3220/4518] 71% | Training loss: 0.687084449411179
Epoch: 25 | Iteration number: [3230/4518] 71% | Training loss: 0.6870869429303397
Epoch: 25 | Iteration number: [3240/4518] 71% | Training loss: 0.6870847247265003
Epoch: 25 | Iteration number: [3250/4518] 71% | Training loss: 0.6870822374087113
Epoch: 25 | Iteration number: [3260/4518] 72% | Training loss: 0.6870825573710576
Epoch: 25 | Iteration number: [3270/4518] 72% | Training loss: 0.6870792053343688
Epoch: 25 | Iteration number: [3280/4518] 72% | Training loss: 0.6870814952363328
Epoch: 25 | Iteration number: [3290/4518] 72% | Training loss: 0.6870779521016002
Epoch: 25 | Iteration number: [3300/4518] 73% | Training loss: 0.6870782245650436
Epoch: 25 | Iteration number: [3310/4518] 73% | Training loss: 0.6870767792185988
Epoch: 25 | Iteration number: [3320/4518] 73% | Training loss: 0.6870798832321742
Epoch: 25 | Iteration number: [3330/4518] 73% | Training loss: 0.6870816408513902
Epoch: 25 | Iteration number: [3340/4518] 73% | Training loss: 0.6870814940351212
Epoch: 25 | Iteration number: [3350/4518] 74% | Training loss: 0.6870785471040811
Epoch: 25 | Iteration number: [3360/4518] 74% | Training loss: 0.6870776466670491
Epoch: 25 | Iteration number: [3370/4518] 74% | Training loss: 0.6870777037271053
Epoch: 25 | Iteration number: [3380/4518] 74% | Training loss: 0.6870750115820642
Epoch: 25 | Iteration number: [3390/4518] 75% | Training loss: 0.687070074914831
Epoch: 25 | Iteration number: [3400/4518] 75% | Training loss: 0.6870707450193517
Epoch: 25 | Iteration number: [3410/4518] 75% | Training loss: 0.687072041849237
Epoch: 25 | Iteration number: [3420/4518] 75% | Training loss: 0.6870728960685563
Epoch: 25 | Iteration number: [3430/4518] 75% | Training loss: 0.6870715073698116
Epoch: 25 | Iteration number: [3440/4518] 76% | Training loss: 0.6870706544712533
Epoch: 25 | Iteration number: [3450/4518] 76% | Training loss: 0.6870676540637362
Epoch: 25 | Iteration number: [3460/4518] 76% | Training loss: 0.6870692055177138
Epoch: 25 | Iteration number: [3470/4518] 76% | Training loss: 0.687070537352081
Epoch: 25 | Iteration number: [3480/4518] 77% | Training loss: 0.6870706783286457
Epoch: 25 | Iteration number: [3490/4518] 77% | Training loss: 0.6870695239493362
Epoch: 25 | Iteration number: [3500/4518] 77% | Training loss: 0.6870663897139685
Epoch: 25 | Iteration number: [3510/4518] 77% | Training loss: 0.6870664680955078
Epoch: 25 | Iteration number: [3520/4518] 77% | Training loss: 0.6870653374459256
Epoch: 25 | Iteration number: [3530/4518] 78% | Training loss: 0.6870636910284544
Epoch: 25 | Iteration number: [3540/4518] 78% | Training loss: 0.6870691281085634
Epoch: 25 | Iteration number: [3550/4518] 78% | Training loss: 0.6870643013967594
Epoch: 25 | Iteration number: [3560/4518] 78% | Training loss: 0.6870635565244749
Epoch: 25 | Iteration number: [3570/4518] 79% | Training loss: 0.6870658331558483
Epoch: 25 | Iteration number: [3580/4518] 79% | Training loss: 0.6870641345085379
Epoch: 25 | Iteration number: [3590/4518] 79% | Training loss: 0.6870655858583105
Epoch: 25 | Iteration number: [3600/4518] 79% | Training loss: 0.6870646026730537
Epoch: 25 | Iteration number: [3610/4518] 79% | Training loss: 0.6870653516532972
Epoch: 25 | Iteration number: [3620/4518] 80% | Training loss: 0.6870633376237437
Epoch: 25 | Iteration number: [3630/4518] 80% | Training loss: 0.687061670381504
Epoch: 25 | Iteration number: [3640/4518] 80% | Training loss: 0.6870612417603587
Epoch: 25 | Iteration number: [3650/4518] 80% | Training loss: 0.6870655979522287
Epoch: 25 | Iteration number: [3660/4518] 81% | Training loss: 0.6870658886562931
Epoch: 25 | Iteration number: [3670/4518] 81% | Training loss: 0.687061581933206
Epoch: 25 | Iteration number: [3680/4518] 81% | Training loss: 0.6870582331781802
Epoch: 25 | Iteration number: [3690/4518] 81% | Training loss: 0.687060903194474
Epoch: 25 | Iteration number: [3700/4518] 81% | Training loss: 0.6870575905973847
Epoch: 25 | Iteration number: [3710/4518] 82% | Training loss: 0.6870591120739189
Epoch: 25 | Iteration number: [3720/4518] 82% | Training loss: 0.6870608899061398
Epoch: 25 | Iteration number: [3730/4518] 82% | Training loss: 0.6870600263011359
Epoch: 25 | Iteration number: [3740/4518] 82% | Training loss: 0.6870587434998171
Epoch: 25 | Iteration number: [3750/4518] 83% | Training loss: 0.687057890033722
Epoch: 25 | Iteration number: [3760/4518] 83% | Training loss: 0.6870537227772652
Epoch: 25 | Iteration number: [3770/4518] 83% | Training loss: 0.6870523990781617
Epoch: 25 | Iteration number: [3780/4518] 83% | Training loss: 0.6870504393621727
Epoch: 25 | Iteration number: [3790/4518] 83% | Training loss: 0.687048934647779
Epoch: 25 | Iteration number: [3800/4518] 84% | Training loss: 0.6870521583525758
Epoch: 25 | Iteration number: [3810/4518] 84% | Training loss: 0.6870518756507262
Epoch: 25 | Iteration number: [3820/4518] 84% | Training loss: 0.6870514176746938
Epoch: 25 | Iteration number: [3830/4518] 84% | Training loss: 0.6870510162479261
Epoch: 25 | Iteration number: [3840/4518] 84% | Training loss: 0.6870510921658327
Epoch: 25 | Iteration number: [3850/4518] 85% | Training loss: 0.6870487045622491
Epoch: 25 | Iteration number: [3860/4518] 85% | Training loss: 0.687048969738224
Epoch: 25 | Iteration number: [3870/4518] 85% | Training loss: 0.687050272543609
Epoch: 25 | Iteration number: [3880/4518] 85% | Training loss: 0.687047640963928
Epoch: 25 | Iteration number: [3890/4518] 86% | Training loss: 0.6870460656277625
Epoch: 25 | Iteration number: [3900/4518] 86% | Training loss: 0.6870436550103701
Epoch: 25 | Iteration number: [3910/4518] 86% | Training loss: 0.6870436582266523
Epoch: 25 | Iteration number: [3920/4518] 86% | Training loss: 0.6870432829978514
Epoch: 25 | Iteration number: [3930/4518] 86% | Training loss: 0.6870423998086507
Epoch: 25 | Iteration number: [3940/4518] 87% | Training loss: 0.6870411175459169
Epoch: 25 | Iteration number: [3950/4518] 87% | Training loss: 0.6870386338686642
Epoch: 25 | Iteration number: [3960/4518] 87% | Training loss: 0.6870407017192455
Epoch: 25 | Iteration number: [3970/4518] 87% | Training loss: 0.6870440992360151
Epoch: 25 | Iteration number: [3980/4518] 88% | Training loss: 0.6870467973863659
Epoch: 25 | Iteration number: [3990/4518] 88% | Training loss: 0.6870477014167565
Epoch: 25 | Iteration number: [4000/4518] 88% | Training loss: 0.6870475963652134
Epoch: 25 | Iteration number: [4010/4518] 88% | Training loss: 0.6870462168927799
Epoch: 25 | Iteration number: [4020/4518] 88% | Training loss: 0.6870493203401565
Epoch: 25 | Iteration number: [4030/4518] 89% | Training loss: 0.6870493163098177
Epoch: 25 | Iteration number: [4040/4518] 89% | Training loss: 0.6870499840614819
Epoch: 25 | Iteration number: [4050/4518] 89% | Training loss: 0.6870486192202863
Epoch: 25 | Iteration number: [4060/4518] 89% | Training loss: 0.6870432321073974
Epoch: 25 | Iteration number: [4070/4518] 90% | Training loss: 0.6870416901328347
Epoch: 25 | Iteration number: [4080/4518] 90% | Training loss: 0.6870387498070212
Epoch: 25 | Iteration number: [4090/4518] 90% | Training loss: 0.687039881143127
Epoch: 25 | Iteration number: [4100/4518] 90% | Training loss: 0.6870392942283212
Epoch: 25 | Iteration number: [4110/4518] 90% | Training loss: 0.6870386569894433
Epoch: 25 | Iteration number: [4120/4518] 91% | Training loss: 0.6870356797593311
Epoch: 25 | Iteration number: [4130/4518] 91% | Training loss: 0.6870349184508474
Epoch: 25 | Iteration number: [4140/4518] 91% | Training loss: 0.6870364451465976
Epoch: 25 | Iteration number: [4150/4518] 91% | Training loss: 0.6870347499560161
Epoch: 25 | Iteration number: [4160/4518] 92% | Training loss: 0.6870341830098858
Epoch: 25 | Iteration number: [4170/4518] 92% | Training loss: 0.6870321682174143
Epoch: 25 | Iteration number: [4180/4518] 92% | Training loss: 0.6870308950329511
Epoch: 25 | Iteration number: [4190/4518] 92% | Training loss: 0.6870320874068504
Epoch: 25 | Iteration number: [4200/4518] 92% | Training loss: 0.6870339914162954
Epoch: 25 | Iteration number: [4210/4518] 93% | Training loss: 0.6870313631808673
Epoch: 25 | Iteration number: [4220/4518] 93% | Training loss: 0.6870314591021335
Epoch: 25 | Iteration number: [4230/4518] 93% | Training loss: 0.6870313563809045
Epoch: 25 | Iteration number: [4240/4518] 93% | Training loss: 0.6870339286636632
Epoch: 25 | Iteration number: [4250/4518] 94% | Training loss: 0.6870326135579278
Epoch: 25 | Iteration number: [4260/4518] 94% | Training loss: 0.687032080648091
Epoch: 25 | Iteration number: [4270/4518] 94% | Training loss: 0.6870338251774987
Epoch: 25 | Iteration number: [4280/4518] 94% | Training loss: 0.6870340016539965
Epoch: 25 | Iteration number: [4290/4518] 94% | Training loss: 0.687033543622855
Epoch: 25 | Iteration number: [4300/4518] 95% | Training loss: 0.6870334299497827
Epoch: 25 | Iteration number: [4310/4518] 95% | Training loss: 0.6870352179434349
Epoch: 25 | Iteration number: [4320/4518] 95% | Training loss: 0.6870346553071781
Epoch: 25 | Iteration number: [4330/4518] 95% | Training loss: 0.6870317297499394
Epoch: 25 | Iteration number: [4340/4518] 96% | Training loss: 0.6870322534977565
Epoch: 25 | Iteration number: [4350/4518] 96% | Training loss: 0.687032700667436
Epoch: 25 | Iteration number: [4360/4518] 96% | Training loss: 0.6870304748689363
Epoch: 25 | Iteration number: [4370/4518] 96% | Training loss: 0.6870281635350984
Epoch: 25 | Iteration number: [4380/4518] 96% | Training loss: 0.6870292946900407
Epoch: 25 | Iteration number: [4390/4518] 97% | Training loss: 0.6870287077573546
Epoch: 25 | Iteration number: [4400/4518] 97% | Training loss: 0.6870275162024931
Epoch: 25 | Iteration number: [4410/4518] 97% | Training loss: 0.6870265573060431
Epoch: 25 | Iteration number: [4420/4518] 97% | Training loss: 0.6870312811832083
Epoch: 25 | Iteration number: [4430/4518] 98% | Training loss: 0.6870283587387938
Epoch: 25 | Iteration number: [4440/4518] 98% | Training loss: 0.6870256176268732
Epoch: 25 | Iteration number: [4450/4518] 98% | Training loss: 0.6870260365625446
Epoch: 25 | Iteration number: [4460/4518] 98% | Training loss: 0.687026002789292
Epoch: 25 | Iteration number: [4470/4518] 98% | Training loss: 0.6870266960104573
Epoch: 25 | Iteration number: [4480/4518] 99% | Training loss: 0.6870293023064733
Epoch: 25 | Iteration number: [4490/4518] 99% | Training loss: 0.6870278804100436
Epoch: 25 | Iteration number: [4500/4518] 99% | Training loss: 0.6870290903780195
Epoch: 25 | Iteration number: [4510/4518] 99% | Training loss: 0.6870288395564467

 End of epoch: 25 | Train Loss: 0.6868778227994589 | Training Time: 643 

 End of epoch: 25 | Eval Loss: 0.6902585491842154 | Evaluating Time: 17 
Epoch: 26 | Iteration number: [10/4518] 0% | Training loss: 0.7550758600234986
Epoch: 26 | Iteration number: [20/4518] 0% | Training loss: 0.7211096793413162
Epoch: 26 | Iteration number: [30/4518] 0% | Training loss: 0.7101551592350006
Epoch: 26 | Iteration number: [40/4518] 0% | Training loss: 0.7043628096580505
Epoch: 26 | Iteration number: [50/4518] 1% | Training loss: 0.7008110964298249
Epoch: 26 | Iteration number: [60/4518] 1% | Training loss: 0.6985001315673193
Epoch: 26 | Iteration number: [70/4518] 1% | Training loss: 0.6967087575367519
Epoch: 26 | Iteration number: [80/4518] 1% | Training loss: 0.6955957435071468
Epoch: 26 | Iteration number: [90/4518] 1% | Training loss: 0.6946447259849973
Epoch: 26 | Iteration number: [100/4518] 2% | Training loss: 0.6939116984605789
Epoch: 26 | Iteration number: [110/4518] 2% | Training loss: 0.6932086381045255
Epoch: 26 | Iteration number: [120/4518] 2% | Training loss: 0.6925492018461228
Epoch: 26 | Iteration number: [130/4518] 2% | Training loss: 0.6921615706040309
Epoch: 26 | Iteration number: [140/4518] 3% | Training loss: 0.6918863726513726
Epoch: 26 | Iteration number: [150/4518] 3% | Training loss: 0.6915593028068543
Epoch: 26 | Iteration number: [160/4518] 3% | Training loss: 0.6912799514830112
Epoch: 26 | Iteration number: [170/4518] 3% | Training loss: 0.691034460067749
Epoch: 26 | Iteration number: [180/4518] 3% | Training loss: 0.6909056269460254
Epoch: 26 | Iteration number: [190/4518] 4% | Training loss: 0.6906900757237484
Epoch: 26 | Iteration number: [200/4518] 4% | Training loss: 0.6903907510638237
Epoch: 26 | Iteration number: [210/4518] 4% | Training loss: 0.6902310266381219
Epoch: 26 | Iteration number: [220/4518] 4% | Training loss: 0.6900399912487377
Epoch: 26 | Iteration number: [230/4518] 5% | Training loss: 0.6898742844229159
Epoch: 26 | Iteration number: [240/4518] 5% | Training loss: 0.6897814964254697
Epoch: 26 | Iteration number: [250/4518] 5% | Training loss: 0.6896283283233643
Epoch: 26 | Iteration number: [260/4518] 5% | Training loss: 0.6895052327559544
Epoch: 26 | Iteration number: [270/4518] 5% | Training loss: 0.6894087369795199
Epoch: 26 | Iteration number: [280/4518] 6% | Training loss: 0.689311472432954
Epoch: 26 | Iteration number: [290/4518] 6% | Training loss: 0.689218374367418
Epoch: 26 | Iteration number: [300/4518] 6% | Training loss: 0.6890870183706284
Epoch: 26 | Iteration number: [310/4518] 6% | Training loss: 0.6890089244611801
Epoch: 26 | Iteration number: [320/4518] 7% | Training loss: 0.6889623558148742
Epoch: 26 | Iteration number: [330/4518] 7% | Training loss: 0.6889381583892937
Epoch: 26 | Iteration number: [340/4518] 7% | Training loss: 0.6888890217332279
Epoch: 26 | Iteration number: [350/4518] 7% | Training loss: 0.6888659766742161
Epoch: 26 | Iteration number: [360/4518] 7% | Training loss: 0.6888108847869767
Epoch: 26 | Iteration number: [370/4518] 8% | Training loss: 0.6887583368533367
Epoch: 26 | Iteration number: [380/4518] 8% | Training loss: 0.6887561980046724
Epoch: 26 | Iteration number: [390/4518] 8% | Training loss: 0.6887112420338851
Epoch: 26 | Iteration number: [400/4518] 8% | Training loss: 0.6886800380051136
Epoch: 26 | Iteration number: [410/4518] 9% | Training loss: 0.6886301295059484
Epoch: 26 | Iteration number: [420/4518] 9% | Training loss: 0.6885990127211525
Epoch: 26 | Iteration number: [430/4518] 9% | Training loss: 0.6885626503201419
Epoch: 26 | Iteration number: [440/4518] 9% | Training loss: 0.6885625837878747
Epoch: 26 | Iteration number: [450/4518] 9% | Training loss: 0.6885058379173279
Epoch: 26 | Iteration number: [460/4518] 10% | Training loss: 0.6884777551111968
Epoch: 26 | Iteration number: [470/4518] 10% | Training loss: 0.6884708421027407
Epoch: 26 | Iteration number: [480/4518] 10% | Training loss: 0.6884574605772893
Epoch: 26 | Iteration number: [490/4518] 10% | Training loss: 0.6884268209642294
Epoch: 26 | Iteration number: [500/4518] 11% | Training loss: 0.688407437801361
Epoch: 26 | Iteration number: [510/4518] 11% | Training loss: 0.6883799086598789
Epoch: 26 | Iteration number: [520/4518] 11% | Training loss: 0.6883485927031591
Epoch: 26 | Iteration number: [530/4518] 11% | Training loss: 0.6883279126770091
Epoch: 26 | Iteration number: [540/4518] 11% | Training loss: 0.6883031267810751
Epoch: 26 | Iteration number: [550/4518] 12% | Training loss: 0.688266648054123
Epoch: 26 | Iteration number: [560/4518] 12% | Training loss: 0.688235549309424
Epoch: 26 | Iteration number: [570/4518] 12% | Training loss: 0.6882080041525657
Epoch: 26 | Iteration number: [580/4518] 12% | Training loss: 0.6881804002770062
Epoch: 26 | Iteration number: [590/4518] 13% | Training loss: 0.6881445605876082
Epoch: 26 | Iteration number: [600/4518] 13% | Training loss: 0.6881064717968305
Epoch: 26 | Iteration number: [610/4518] 13% | Training loss: 0.6880874539007906
Epoch: 26 | Iteration number: [620/4518] 13% | Training loss: 0.6880403098560148
Epoch: 26 | Iteration number: [630/4518] 13% | Training loss: 0.6880415308097052
Epoch: 26 | Iteration number: [640/4518] 14% | Training loss: 0.6880218072794377
Epoch: 26 | Iteration number: [650/4518] 14% | Training loss: 0.6879933457191174
Epoch: 26 | Iteration number: [660/4518] 14% | Training loss: 0.6879785350777886
Epoch: 26 | Iteration number: [670/4518] 14% | Training loss: 0.68795814425198
Epoch: 26 | Iteration number: [680/4518] 15% | Training loss: 0.6879451428266132
Epoch: 26 | Iteration number: [690/4518] 15% | Training loss: 0.687927360120027
Epoch: 26 | Iteration number: [700/4518] 15% | Training loss: 0.6879077792167664
Epoch: 26 | Iteration number: [710/4518] 15% | Training loss: 0.6878880741730542
Epoch: 26 | Iteration number: [720/4518] 15% | Training loss: 0.6878630407982402
Epoch: 26 | Iteration number: [730/4518] 16% | Training loss: 0.6878703212084836
Epoch: 26 | Iteration number: [740/4518] 16% | Training loss: 0.6878610531220565
Epoch: 26 | Iteration number: [750/4518] 16% | Training loss: 0.6878409532705942
Epoch: 26 | Iteration number: [760/4518] 16% | Training loss: 0.6878446721716931
Epoch: 26 | Iteration number: [770/4518] 17% | Training loss: 0.6878371895133675
Epoch: 26 | Iteration number: [780/4518] 17% | Training loss: 0.6878450334836275
Epoch: 26 | Iteration number: [790/4518] 17% | Training loss: 0.6878250523458553
Epoch: 26 | Iteration number: [800/4518] 17% | Training loss: 0.6878025462478399
Epoch: 26 | Iteration number: [810/4518] 17% | Training loss: 0.6877660358393634
Epoch: 26 | Iteration number: [820/4518] 18% | Training loss: 0.6877455038268392
Epoch: 26 | Iteration number: [830/4518] 18% | Training loss: 0.6877295044531305
Epoch: 26 | Iteration number: [840/4518] 18% | Training loss: 0.6877272023331551
Epoch: 26 | Iteration number: [850/4518] 18% | Training loss: 0.6877152987788705
Epoch: 26 | Iteration number: [860/4518] 19% | Training loss: 0.6877059761867966
Epoch: 26 | Iteration number: [870/4518] 19% | Training loss: 0.6876911538770829
Epoch: 26 | Iteration number: [880/4518] 19% | Training loss: 0.6876896580511873
Epoch: 26 | Iteration number: [890/4518] 19% | Training loss: 0.6876808915915115
Epoch: 26 | Iteration number: [900/4518] 19% | Training loss: 0.6876673331525591
Epoch: 26 | Iteration number: [910/4518] 20% | Training loss: 0.6876624945100848
Epoch: 26 | Iteration number: [920/4518] 20% | Training loss: 0.6876522742535757
Epoch: 26 | Iteration number: [930/4518] 20% | Training loss: 0.6876533972960647
Epoch: 26 | Iteration number: [940/4518] 20% | Training loss: 0.6876399426384175
Epoch: 26 | Iteration number: [950/4518] 21% | Training loss: 0.6876324746483251
Epoch: 26 | Iteration number: [960/4518] 21% | Training loss: 0.6876223623131712
Epoch: 26 | Iteration number: [970/4518] 21% | Training loss: 0.6876158703233778
Epoch: 26 | Iteration number: [980/4518] 21% | Training loss: 0.6875862228018897
Epoch: 26 | Iteration number: [990/4518] 21% | Training loss: 0.6875687693706667
Epoch: 26 | Iteration number: [1000/4518] 22% | Training loss: 0.6875558784008026
Epoch: 26 | Iteration number: [1010/4518] 22% | Training loss: 0.6875492859594893
Epoch: 26 | Iteration number: [1020/4518] 22% | Training loss: 0.6875328739484151
Epoch: 26 | Iteration number: [1030/4518] 22% | Training loss: 0.6875254563336234
Epoch: 26 | Iteration number: [1040/4518] 23% | Training loss: 0.6875182146063218
Epoch: 26 | Iteration number: [1050/4518] 23% | Training loss: 0.6875096884795597
Epoch: 26 | Iteration number: [1060/4518] 23% | Training loss: 0.6874997558458796
Epoch: 26 | Iteration number: [1070/4518] 23% | Training loss: 0.6874879320091176
Epoch: 26 | Iteration number: [1080/4518] 23% | Training loss: 0.6874812753112228
Epoch: 26 | Iteration number: [1090/4518] 24% | Training loss: 0.6874750624556061
Epoch: 26 | Iteration number: [1100/4518] 24% | Training loss: 0.6874647282470356
Epoch: 26 | Iteration number: [1110/4518] 24% | Training loss: 0.6874652616075567
Epoch: 26 | Iteration number: [1120/4518] 24% | Training loss: 0.6874524425183024
Epoch: 26 | Iteration number: [1130/4518] 25% | Training loss: 0.6874579030328092
Epoch: 26 | Iteration number: [1140/4518] 25% | Training loss: 0.6874560180986137
Epoch: 26 | Iteration number: [1150/4518] 25% | Training loss: 0.6874452744359556
Epoch: 26 | Iteration number: [1160/4518] 25% | Training loss: 0.6874410954528841
Epoch: 26 | Iteration number: [1170/4518] 25% | Training loss: 0.6874332685755868
Epoch: 26 | Iteration number: [1180/4518] 26% | Training loss: 0.6874228417368259
Epoch: 26 | Iteration number: [1190/4518] 26% | Training loss: 0.6874096887953142
Epoch: 26 | Iteration number: [1200/4518] 26% | Training loss: 0.6874050824840864
Epoch: 26 | Iteration number: [1210/4518] 26% | Training loss: 0.6874022033588946
Epoch: 26 | Iteration number: [1220/4518] 27% | Training loss: 0.6873996535285575
Epoch: 26 | Iteration number: [1230/4518] 27% | Training loss: 0.687380004510647
Epoch: 26 | Iteration number: [1240/4518] 27% | Training loss: 0.687369188714412
Epoch: 26 | Iteration number: [1250/4518] 27% | Training loss: 0.687353615474701
Epoch: 26 | Iteration number: [1260/4518] 27% | Training loss: 0.6873540618116893
Epoch: 26 | Iteration number: [1270/4518] 28% | Training loss: 0.6873545862088992
Epoch: 26 | Iteration number: [1280/4518] 28% | Training loss: 0.6873490643687546
Epoch: 26 | Iteration number: [1290/4518] 28% | Training loss: 0.6873446524143219
Epoch: 26 | Iteration number: [1300/4518] 28% | Training loss: 0.6873421619030146
Epoch: 26 | Iteration number: [1310/4518] 28% | Training loss: 0.6873361056087581
Epoch: 26 | Iteration number: [1320/4518] 29% | Training loss: 0.6873279214808435
Epoch: 26 | Iteration number: [1330/4518] 29% | Training loss: 0.6873287661631304
Epoch: 26 | Iteration number: [1340/4518] 29% | Training loss: 0.6873330856881924
Epoch: 26 | Iteration number: [1350/4518] 29% | Training loss: 0.6873351240599597
Epoch: 26 | Iteration number: [1360/4518] 30% | Training loss: 0.6873255560503286
Epoch: 26 | Iteration number: [1370/4518] 30% | Training loss: 0.6873234090578817
Epoch: 26 | Iteration number: [1380/4518] 30% | Training loss: 0.6873256336519684
Epoch: 26 | Iteration number: [1390/4518] 30% | Training loss: 0.6873200275057512
Epoch: 26 | Iteration number: [1400/4518] 30% | Training loss: 0.6873147885714258
Epoch: 26 | Iteration number: [1410/4518] 31% | Training loss: 0.6873004385765563
Epoch: 26 | Iteration number: [1420/4518] 31% | Training loss: 0.6872932412674729
Epoch: 26 | Iteration number: [1430/4518] 31% | Training loss: 0.687299066365182
Epoch: 26 | Iteration number: [1440/4518] 31% | Training loss: 0.687297204343809
Epoch: 26 | Iteration number: [1450/4518] 32% | Training loss: 0.6872974777632747
Epoch: 26 | Iteration number: [1460/4518] 32% | Training loss: 0.6872924836531077
Epoch: 26 | Iteration number: [1470/4518] 32% | Training loss: 0.6872915703017696
Epoch: 26 | Iteration number: [1480/4518] 32% | Training loss: 0.6872878024304235
Epoch: 26 | Iteration number: [1490/4518] 32% | Training loss: 0.6872928592182646
Epoch: 26 | Iteration number: [1500/4518] 33% | Training loss: 0.6872888205448786
Epoch: 26 | Iteration number: [1510/4518] 33% | Training loss: 0.6872936651801431
Epoch: 26 | Iteration number: [1520/4518] 33% | Training loss: 0.6872874402294034
Epoch: 26 | Iteration number: [1530/4518] 33% | Training loss: 0.6872845507914724
Epoch: 26 | Iteration number: [1540/4518] 34% | Training loss: 0.6872841117443976
Epoch: 26 | Iteration number: [1550/4518] 34% | Training loss: 0.6872843763520641
Epoch: 26 | Iteration number: [1560/4518] 34% | Training loss: 0.6872827431330314
Epoch: 26 | Iteration number: [1570/4518] 34% | Training loss: 0.6872808457180193
Epoch: 26 | Iteration number: [1580/4518] 34% | Training loss: 0.6872880383760114
Epoch: 26 | Iteration number: [1590/4518] 35% | Training loss: 0.6872862742382025
Epoch: 26 | Iteration number: [1600/4518] 35% | Training loss: 0.6872796754166484
Epoch: 26 | Iteration number: [1610/4518] 35% | Training loss: 0.6872752420650506
Epoch: 26 | Iteration number: [1620/4518] 35% | Training loss: 0.6872675020753601
Epoch: 26 | Iteration number: [1630/4518] 36% | Training loss: 0.6872659813772681
Epoch: 26 | Iteration number: [1640/4518] 36% | Training loss: 0.6872644772980271
Epoch: 26 | Iteration number: [1650/4518] 36% | Training loss: 0.6872633147600925
Epoch: 26 | Iteration number: [1660/4518] 36% | Training loss: 0.6872529816555689
Epoch: 26 | Iteration number: [1670/4518] 36% | Training loss: 0.6872509777902843
Epoch: 26 | Iteration number: [1680/4518] 37% | Training loss: 0.6872517512667746
Epoch: 26 | Iteration number: [1690/4518] 37% | Training loss: 0.6872500431255476
Epoch: 26 | Iteration number: [1700/4518] 37% | Training loss: 0.687257074082599
Epoch: 26 | Iteration number: [1710/4518] 37% | Training loss: 0.6872558946497956
Epoch: 26 | Iteration number: [1720/4518] 38% | Training loss: 0.6872548526109651
Epoch: 26 | Iteration number: [1730/4518] 38% | Training loss: 0.6872551943180878
Epoch: 26 | Iteration number: [1740/4518] 38% | Training loss: 0.6872502185489939
Epoch: 26 | Iteration number: [1750/4518] 38% | Training loss: 0.687251724243164
Epoch: 26 | Iteration number: [1760/4518] 38% | Training loss: 0.6872529144991528
Epoch: 26 | Iteration number: [1770/4518] 39% | Training loss: 0.6872462865659746
Epoch: 26 | Iteration number: [1780/4518] 39% | Training loss: 0.6872432386607267
Epoch: 26 | Iteration number: [1790/4518] 39% | Training loss: 0.6872471908284299
Epoch: 26 | Iteration number: [1800/4518] 39% | Training loss: 0.6872507239381472
Epoch: 26 | Iteration number: [1810/4518] 40% | Training loss: 0.687249858735016
Epoch: 26 | Iteration number: [1820/4518] 40% | Training loss: 0.6872435383089296
Epoch: 26 | Iteration number: [1830/4518] 40% | Training loss: 0.6872329749044824
Epoch: 26 | Iteration number: [1840/4518] 40% | Training loss: 0.6872320790653643
Epoch: 26 | Iteration number: [1850/4518] 40% | Training loss: 0.687227996974378
Epoch: 26 | Iteration number: [1860/4518] 41% | Training loss: 0.6872246575611893
Epoch: 26 | Iteration number: [1870/4518] 41% | Training loss: 0.6872256104002662
Epoch: 26 | Iteration number: [1880/4518] 41% | Training loss: 0.6872277452907664
Epoch: 26 | Iteration number: [1890/4518] 41% | Training loss: 0.687220452197645
Epoch: 26 | Iteration number: [1900/4518] 42% | Training loss: 0.6872131875941628
Epoch: 26 | Iteration number: [1910/4518] 42% | Training loss: 0.6872112266680332
Epoch: 26 | Iteration number: [1920/4518] 42% | Training loss: 0.687205591890961
Epoch: 26 | Iteration number: [1930/4518] 42% | Training loss: 0.6872118607086222
Epoch: 26 | Iteration number: [1940/4518] 42% | Training loss: 0.6872162813378363
Epoch: 26 | Iteration number: [1950/4518] 43% | Training loss: 0.6872110170890123
Epoch: 26 | Iteration number: [1960/4518] 43% | Training loss: 0.6872180798528146
Epoch: 26 | Iteration number: [1970/4518] 43% | Training loss: 0.6872145199231084
Epoch: 26 | Iteration number: [1980/4518] 43% | Training loss: 0.687210618486308
Epoch: 26 | Iteration number: [1990/4518] 44% | Training loss: 0.6872084278557169
Epoch: 26 | Iteration number: [2000/4518] 44% | Training loss: 0.6872067831754685
Epoch: 26 | Iteration number: [2010/4518] 44% | Training loss: 0.6872031916729846
Epoch: 26 | Iteration number: [2020/4518] 44% | Training loss: 0.6871963111480864
Epoch: 26 | Iteration number: [2030/4518] 44% | Training loss: 0.6871900430453822
Epoch: 26 | Iteration number: [2040/4518] 45% | Training loss: 0.6871907328565915
Epoch: 26 | Iteration number: [2050/4518] 45% | Training loss: 0.687192494258648
Epoch: 26 | Iteration number: [2060/4518] 45% | Training loss: 0.6871859141345164
Epoch: 26 | Iteration number: [2070/4518] 45% | Training loss: 0.687183028574727
Epoch: 26 | Iteration number: [2080/4518] 46% | Training loss: 0.6871879310848621
Epoch: 26 | Iteration number: [2090/4518] 46% | Training loss: 0.687186979848232
Epoch: 26 | Iteration number: [2100/4518] 46% | Training loss: 0.6871782149303527
Epoch: 26 | Iteration number: [2110/4518] 46% | Training loss: 0.6871791009089393
Epoch: 26 | Iteration number: [2120/4518] 46% | Training loss: 0.6871800389211132
Epoch: 26 | Iteration number: [2130/4518] 47% | Training loss: 0.6871785293722377
Epoch: 26 | Iteration number: [2140/4518] 47% | Training loss: 0.6871722514105735
Epoch: 26 | Iteration number: [2150/4518] 47% | Training loss: 0.6871695978696957
Epoch: 26 | Iteration number: [2160/4518] 47% | Training loss: 0.6871667861662529
Epoch: 26 | Iteration number: [2170/4518] 48% | Training loss: 0.6871706376152654
Epoch: 26 | Iteration number: [2180/4518] 48% | Training loss: 0.6871625078927487
Epoch: 26 | Iteration number: [2190/4518] 48% | Training loss: 0.687166699481337
Epoch: 26 | Iteration number: [2200/4518] 48% | Training loss: 0.6871615233475512
Epoch: 26 | Iteration number: [2210/4518] 48% | Training loss: 0.687159628107537
Epoch: 26 | Iteration number: [2220/4518] 49% | Training loss: 0.6871651676055547
Epoch: 26 | Iteration number: [2230/4518] 49% | Training loss: 0.6871654998561192
Epoch: 26 | Iteration number: [2240/4518] 49% | Training loss: 0.6871642611122557
Epoch: 26 | Iteration number: [2250/4518] 49% | Training loss: 0.6871583225462172
Epoch: 26 | Iteration number: [2260/4518] 50% | Training loss: 0.6871571659514334
Epoch: 26 | Iteration number: [2270/4518] 50% | Training loss: 0.6871565477175859
Epoch: 26 | Iteration number: [2280/4518] 50% | Training loss: 0.6871554417829765
Epoch: 26 | Iteration number: [2290/4518] 50% | Training loss: 0.6871562902323544
Epoch: 26 | Iteration number: [2300/4518] 50% | Training loss: 0.6871584568075512
Epoch: 26 | Iteration number: [2310/4518] 51% | Training loss: 0.6871530555285417
Epoch: 26 | Iteration number: [2320/4518] 51% | Training loss: 0.6871507538032943
Epoch: 26 | Iteration number: [2330/4518] 51% | Training loss: 0.6871475886633468
Epoch: 26 | Iteration number: [2340/4518] 51% | Training loss: 0.6871473900528036
Epoch: 26 | Iteration number: [2350/4518] 52% | Training loss: 0.687142227051106
Epoch: 26 | Iteration number: [2360/4518] 52% | Training loss: 0.6871412478513637
Epoch: 26 | Iteration number: [2370/4518] 52% | Training loss: 0.6871428128033248
Epoch: 26 | Iteration number: [2380/4518] 52% | Training loss: 0.687139447321411
Epoch: 26 | Iteration number: [2390/4518] 52% | Training loss: 0.6871345508547507
Epoch: 26 | Iteration number: [2400/4518] 53% | Training loss: 0.687130918353796
Epoch: 26 | Iteration number: [2410/4518] 53% | Training loss: 0.6871288440534188
Epoch: 26 | Iteration number: [2420/4518] 53% | Training loss: 0.6871342028221809
Epoch: 26 | Iteration number: [2430/4518] 53% | Training loss: 0.6871340535795738
Epoch: 26 | Iteration number: [2440/4518] 54% | Training loss: 0.687131482875738
Epoch: 26 | Iteration number: [2450/4518] 54% | Training loss: 0.6871309286720899
Epoch: 26 | Iteration number: [2460/4518] 54% | Training loss: 0.6871282952345483
Epoch: 26 | Iteration number: [2470/4518] 54% | Training loss: 0.6871240778007971
Epoch: 26 | Iteration number: [2480/4518] 54% | Training loss: 0.6871233507510155
Epoch: 26 | Iteration number: [2490/4518] 55% | Training loss: 0.6871198393015497
Epoch: 26 | Iteration number: [2500/4518] 55% | Training loss: 0.6871227669239044
Epoch: 26 | Iteration number: [2510/4518] 55% | Training loss: 0.6871223149546589
Epoch: 26 | Iteration number: [2520/4518] 55% | Training loss: 0.6871238234733779
Epoch: 26 | Iteration number: [2530/4518] 55% | Training loss: 0.6871201656317051
Epoch: 26 | Iteration number: [2540/4518] 56% | Training loss: 0.6871215568518075
Epoch: 26 | Iteration number: [2550/4518] 56% | Training loss: 0.6871211072977852
Epoch: 26 | Iteration number: [2560/4518] 56% | Training loss: 0.6871212377212942
Epoch: 26 | Iteration number: [2570/4518] 56% | Training loss: 0.6871158218569329
Epoch: 26 | Iteration number: [2580/4518] 57% | Training loss: 0.6871168478052746
Epoch: 26 | Iteration number: [2590/4518] 57% | Training loss: 0.6871146388495751
Epoch: 26 | Iteration number: [2600/4518] 57% | Training loss: 0.6871140580910903
Epoch: 26 | Iteration number: [2610/4518] 57% | Training loss: 0.687110477457558
Epoch: 26 | Iteration number: [2620/4518] 57% | Training loss: 0.6871102630864573
Epoch: 26 | Iteration number: [2630/4518] 58% | Training loss: 0.6871055748526135
Epoch: 26 | Iteration number: [2640/4518] 58% | Training loss: 0.6871068999848583
Epoch: 26 | Iteration number: [2650/4518] 58% | Training loss: 0.6871076289662775
Epoch: 26 | Iteration number: [2660/4518] 58% | Training loss: 0.6871003777909099
Epoch: 26 | Iteration number: [2670/4518] 59% | Training loss: 0.6870996806951944
Epoch: 26 | Iteration number: [2680/4518] 59% | Training loss: 0.6870963145992649
Epoch: 26 | Iteration number: [2690/4518] 59% | Training loss: 0.6870970360408485
Epoch: 26 | Iteration number: [2700/4518] 59% | Training loss: 0.6870969127284156
Epoch: 26 | Iteration number: [2710/4518] 59% | Training loss: 0.6870892478971024
Epoch: 26 | Iteration number: [2720/4518] 60% | Training loss: 0.6870862329050021
Epoch: 26 | Iteration number: [2730/4518] 60% | Training loss: 0.6870841564931276
Epoch: 26 | Iteration number: [2740/4518] 60% | Training loss: 0.6870832096051126
Epoch: 26 | Iteration number: [2750/4518] 60% | Training loss: 0.6870806146535007
Epoch: 26 | Iteration number: [2760/4518] 61% | Training loss: 0.687082795518032
Epoch: 26 | Iteration number: [2770/4518] 61% | Training loss: 0.6870798294294612
Epoch: 26 | Iteration number: [2780/4518] 61% | Training loss: 0.6870774937190598
Epoch: 26 | Iteration number: [2790/4518] 61% | Training loss: 0.6870801099953259
Epoch: 26 | Iteration number: [2800/4518] 61% | Training loss: 0.6870785523951054
Epoch: 26 | Iteration number: [2810/4518] 62% | Training loss: 0.6870754829717276
Epoch: 26 | Iteration number: [2820/4518] 62% | Training loss: 0.6870758697496239
Epoch: 26 | Iteration number: [2830/4518] 62% | Training loss: 0.6870755589892923
Epoch: 26 | Iteration number: [2840/4518] 62% | Training loss: 0.6870749663509114
Epoch: 26 | Iteration number: [2850/4518] 63% | Training loss: 0.6870720017374607
Epoch: 26 | Iteration number: [2860/4518] 63% | Training loss: 0.6870780935237458
Epoch: 26 | Iteration number: [2870/4518] 63% | Training loss: 0.6870780916994872
Epoch: 26 | Iteration number: [2880/4518] 63% | Training loss: 0.6870795758441091
Epoch: 26 | Iteration number: [2890/4518] 63% | Training loss: 0.687076266001665
Epoch: 26 | Iteration number: [2900/4518] 64% | Training loss: 0.6870757577337068
Epoch: 26 | Iteration number: [2910/4518] 64% | Training loss: 0.6870818431025109
Epoch: 26 | Iteration number: [2920/4518] 64% | Training loss: 0.6870735996798293
Epoch: 26 | Iteration number: [2930/4518] 64% | Training loss: 0.6870718914901031
Epoch: 26 | Iteration number: [2940/4518] 65% | Training loss: 0.6870718249658339
Epoch: 26 | Iteration number: [2950/4518] 65% | Training loss: 0.6870705932681843
Epoch: 26 | Iteration number: [2960/4518] 65% | Training loss: 0.6870687353248531
Epoch: 26 | Iteration number: [2970/4518] 65% | Training loss: 0.6870689035264731
Epoch: 26 | Iteration number: [2980/4518] 65% | Training loss: 0.6870684391100135
Epoch: 26 | Iteration number: [2990/4518] 66% | Training loss: 0.6870700970142581
Epoch: 26 | Iteration number: [3000/4518] 66% | Training loss: 0.6870705992976824
Epoch: 26 | Iteration number: [3010/4518] 66% | Training loss: 0.6870698224864529
Epoch: 26 | Iteration number: [3020/4518] 66% | Training loss: 0.6870687386650123
Epoch: 26 | Iteration number: [3030/4518] 67% | Training loss: 0.6870695475697911
Epoch: 26 | Iteration number: [3040/4518] 67% | Training loss: 0.6870679702021574
Epoch: 26 | Iteration number: [3050/4518] 67% | Training loss: 0.6870687747978773
Epoch: 26 | Iteration number: [3060/4518] 67% | Training loss: 0.6870671667889052
Epoch: 26 | Iteration number: [3070/4518] 67% | Training loss: 0.687065483401575
Epoch: 26 | Iteration number: [3080/4518] 68% | Training loss: 0.6870620808044037
Epoch: 26 | Iteration number: [3090/4518] 68% | Training loss: 0.687058358516508
Epoch: 26 | Iteration number: [3100/4518] 68% | Training loss: 0.6870556048424014
Epoch: 26 | Iteration number: [3110/4518] 68% | Training loss: 0.6870578267949954
Epoch: 26 | Iteration number: [3120/4518] 69% | Training loss: 0.6870617638795804
Epoch: 26 | Iteration number: [3130/4518] 69% | Training loss: 0.6870626708760429
Epoch: 26 | Iteration number: [3140/4518] 69% | Training loss: 0.687065758503926
Epoch: 26 | Iteration number: [3150/4518] 69% | Training loss: 0.6870662655149188
Epoch: 26 | Iteration number: [3160/4518] 69% | Training loss: 0.6870653874889204
Epoch: 26 | Iteration number: [3170/4518] 70% | Training loss: 0.6870603411919687
Epoch: 26 | Iteration number: [3180/4518] 70% | Training loss: 0.6870594596525408
Epoch: 26 | Iteration number: [3190/4518] 70% | Training loss: 0.6870648512272252
Epoch: 26 | Iteration number: [3200/4518] 70% | Training loss: 0.6870637230016291
Epoch: 26 | Iteration number: [3210/4518] 71% | Training loss: 0.6870655797909353
Epoch: 26 | Iteration number: [3220/4518] 71% | Training loss: 0.6870659425206807
Epoch: 26 | Iteration number: [3230/4518] 71% | Training loss: 0.6870628977338596
Epoch: 26 | Iteration number: [3240/4518] 71% | Training loss: 0.6870628946909199
Epoch: 26 | Iteration number: [3250/4518] 71% | Training loss: 0.6870624198179979
Epoch: 26 | Iteration number: [3260/4518] 72% | Training loss: 0.687063756146314
Epoch: 26 | Iteration number: [3270/4518] 72% | Training loss: 0.6870651749295926
Epoch: 26 | Iteration number: [3280/4518] 72% | Training loss: 0.6870650353773338
Epoch: 26 | Iteration number: [3290/4518] 72% | Training loss: 0.6870623215534767
Epoch: 26 | Iteration number: [3300/4518] 73% | Training loss: 0.6870613856929721
Epoch: 26 | Iteration number: [3310/4518] 73% | Training loss: 0.6870570734728499
Epoch: 26 | Iteration number: [3320/4518] 73% | Training loss: 0.687056072882141
Epoch: 26 | Iteration number: [3330/4518] 73% | Training loss: 0.6870574932914596
Epoch: 26 | Iteration number: [3340/4518] 73% | Training loss: 0.6870602961071951
Epoch: 26 | Iteration number: [3350/4518] 74% | Training loss: 0.6870567773171325
Epoch: 26 | Iteration number: [3360/4518] 74% | Training loss: 0.6870544541449773
Epoch: 26 | Iteration number: [3370/4518] 74% | Training loss: 0.6870554904555708
Epoch: 26 | Iteration number: [3380/4518] 74% | Training loss: 0.687054557472291
Epoch: 26 | Iteration number: [3390/4518] 75% | Training loss: 0.6870520378284398
Epoch: 26 | Iteration number: [3400/4518] 75% | Training loss: 0.6870543033235214
Epoch: 26 | Iteration number: [3410/4518] 75% | Training loss: 0.6870483850104369
Epoch: 26 | Iteration number: [3420/4518] 75% | Training loss: 0.6870474530068057
Epoch: 26 | Iteration number: [3430/4518] 75% | Training loss: 0.6870480241476621
Epoch: 26 | Iteration number: [3440/4518] 76% | Training loss: 0.6870462103292
Epoch: 26 | Iteration number: [3450/4518] 76% | Training loss: 0.6870454907762832
Epoch: 26 | Iteration number: [3460/4518] 76% | Training loss: 0.6870452115990523
Epoch: 26 | Iteration number: [3470/4518] 76% | Training loss: 0.6870414992058999
Epoch: 26 | Iteration number: [3480/4518] 77% | Training loss: 0.6870407007891556
Epoch: 26 | Iteration number: [3490/4518] 77% | Training loss: 0.6870397955264608
Epoch: 26 | Iteration number: [3500/4518] 77% | Training loss: 0.6870376443352018
Epoch: 26 | Iteration number: [3510/4518] 77% | Training loss: 0.6870404313772153
Epoch: 26 | Iteration number: [3520/4518] 77% | Training loss: 0.6870411739938639
Epoch: 26 | Iteration number: [3530/4518] 78% | Training loss: 0.6870411088547693
Epoch: 26 | Iteration number: [3540/4518] 78% | Training loss: 0.6870413823653075
Epoch: 26 | Iteration number: [3550/4518] 78% | Training loss: 0.6870449027545016
Epoch: 26 | Iteration number: [3560/4518] 78% | Training loss: 0.6870487828770381
Epoch: 26 | Iteration number: [3570/4518] 79% | Training loss: 0.6870480585332011
Epoch: 26 | Iteration number: [3580/4518] 79% | Training loss: 0.6870494604943185
Epoch: 26 | Iteration number: [3590/4518] 79% | Training loss: 0.6870486529922751
Epoch: 26 | Iteration number: [3600/4518] 79% | Training loss: 0.6870494092173046
Epoch: 26 | Iteration number: [3610/4518] 79% | Training loss: 0.6870506753221444
Epoch: 26 | Iteration number: [3620/4518] 80% | Training loss: 0.6870507983212971
Epoch: 26 | Iteration number: [3630/4518] 80% | Training loss: 0.6870531151774173
Epoch: 26 | Iteration number: [3640/4518] 80% | Training loss: 0.68705189288645
Epoch: 26 | Iteration number: [3650/4518] 80% | Training loss: 0.6870499558481452
Epoch: 26 | Iteration number: [3660/4518] 81% | Training loss: 0.6870518493033497
Epoch: 26 | Iteration number: [3670/4518] 81% | Training loss: 0.6870501858986691
Epoch: 26 | Iteration number: [3680/4518] 81% | Training loss: 0.6870491221709096
Epoch: 26 | Iteration number: [3690/4518] 81% | Training loss: 0.6870473608253448
Epoch: 26 | Iteration number: [3700/4518] 81% | Training loss: 0.6870457821117865
Epoch: 26 | Iteration number: [3710/4518] 82% | Training loss: 0.6870490874080967
Epoch: 26 | Iteration number: [3720/4518] 82% | Training loss: 0.6870478966063068
Epoch: 26 | Iteration number: [3730/4518] 82% | Training loss: 0.6870439968224186
Epoch: 26 | Iteration number: [3740/4518] 82% | Training loss: 0.6870392548209205
Epoch: 26 | Iteration number: [3750/4518] 83% | Training loss: 0.6870417476336161
Epoch: 26 | Iteration number: [3760/4518] 83% | Training loss: 0.6870416345272926
Epoch: 26 | Iteration number: [3770/4518] 83% | Training loss: 0.6870445886088303
Epoch: 26 | Iteration number: [3780/4518] 83% | Training loss: 0.6870445542549961
Epoch: 26 | Iteration number: [3790/4518] 83% | Training loss: 0.6870460153569646
Epoch: 26 | Iteration number: [3800/4518] 84% | Training loss: 0.6870461477417695
Epoch: 26 | Iteration number: [3810/4518] 84% | Training loss: 0.6870470936060578
Epoch: 26 | Iteration number: [3820/4518] 84% | Training loss: 0.687045040336579
Epoch: 26 | Iteration number: [3830/4518] 84% | Training loss: 0.6870444276469806
Epoch: 26 | Iteration number: [3840/4518] 84% | Training loss: 0.6870426415620993
Epoch: 26 | Iteration number: [3850/4518] 85% | Training loss: 0.687041726607781
Epoch: 26 | Iteration number: [3860/4518] 85% | Training loss: 0.6870431490821541
Epoch: 26 | Iteration number: [3870/4518] 85% | Training loss: 0.6870412923260869
Epoch: 26 | Iteration number: [3880/4518] 85% | Training loss: 0.6870400854914459
Epoch: 26 | Iteration number: [3890/4518] 86% | Training loss: 0.6870391437817356
Epoch: 26 | Iteration number: [3900/4518] 86% | Training loss: 0.6870388211348117
Epoch: 26 | Iteration number: [3910/4518] 86% | Training loss: 0.6870362483784366
Epoch: 26 | Iteration number: [3920/4518] 86% | Training loss: 0.6870349419056153
Epoch: 26 | Iteration number: [3930/4518] 86% | Training loss: 0.6870371165014708
Epoch: 26 | Iteration number: [3940/4518] 87% | Training loss: 0.6870395679310494
Epoch: 26 | Iteration number: [3950/4518] 87% | Training loss: 0.6870347777801223
Epoch: 26 | Iteration number: [3960/4518] 87% | Training loss: 0.6870329185868754
Epoch: 26 | Iteration number: [3970/4518] 87% | Training loss: 0.6870302245809089
Epoch: 26 | Iteration number: [3980/4518] 88% | Training loss: 0.6870300205358908
Epoch: 26 | Iteration number: [3990/4518] 88% | Training loss: 0.6870320867625693
Epoch: 26 | Iteration number: [4000/4518] 88% | Training loss: 0.6870308083146811
Epoch: 26 | Iteration number: [4010/4518] 88% | Training loss: 0.6870322001099289
Epoch: 26 | Iteration number: [4020/4518] 88% | Training loss: 0.6870326164794799
Epoch: 26 | Iteration number: [4030/4518] 89% | Training loss: 0.6870317666465532
Epoch: 26 | Iteration number: [4040/4518] 89% | Training loss: 0.6870336497479146
Epoch: 26 | Iteration number: [4050/4518] 89% | Training loss: 0.6870337167198275
Epoch: 26 | Iteration number: [4060/4518] 89% | Training loss: 0.6870325098190402
Epoch: 26 | Iteration number: [4070/4518] 90% | Training loss: 0.6870327906467991
Epoch: 26 | Iteration number: [4080/4518] 90% | Training loss: 0.6870344263665816
Epoch: 26 | Iteration number: [4090/4518] 90% | Training loss: 0.6870340150113794
Epoch: 26 | Iteration number: [4100/4518] 90% | Training loss: 0.687034785078793
Epoch: 26 | Iteration number: [4110/4518] 90% | Training loss: 0.6870376192160187
Epoch: 26 | Iteration number: [4120/4518] 91% | Training loss: 0.6870397243395593
Epoch: 26 | Iteration number: [4130/4518] 91% | Training loss: 0.68703805997643
Epoch: 26 | Iteration number: [4140/4518] 91% | Training loss: 0.6870349486524933
Epoch: 26 | Iteration number: [4150/4518] 91% | Training loss: 0.6870342894490943
Epoch: 26 | Iteration number: [4160/4518] 92% | Training loss: 0.687034174785591
Epoch: 26 | Iteration number: [4170/4518] 92% | Training loss: 0.6870342764351294
Epoch: 26 | Iteration number: [4180/4518] 92% | Training loss: 0.6870346120242297
Epoch: 26 | Iteration number: [4190/4518] 92% | Training loss: 0.6870355813770704
Epoch: 26 | Iteration number: [4200/4518] 92% | Training loss: 0.6870348583090873
Epoch: 26 | Iteration number: [4210/4518] 93% | Training loss: 0.6870344126734201
Epoch: 26 | Iteration number: [4220/4518] 93% | Training loss: 0.6870351839828265
Epoch: 26 | Iteration number: [4230/4518] 93% | Training loss: 0.6870353100006744
Epoch: 26 | Iteration number: [4240/4518] 93% | Training loss: 0.6870356221103443
Epoch: 26 | Iteration number: [4250/4518] 94% | Training loss: 0.6870368111414068
Epoch: 26 | Iteration number: [4260/4518] 94% | Training loss: 0.6870342364053771
Epoch: 26 | Iteration number: [4270/4518] 94% | Training loss: 0.6870352838860183
Epoch: 26 | Iteration number: [4280/4518] 94% | Training loss: 0.6870367567672908
Epoch: 26 | Iteration number: [4290/4518] 94% | Training loss: 0.6870354062471634
Epoch: 26 | Iteration number: [4300/4518] 95% | Training loss: 0.6870366522184638
Epoch: 26 | Iteration number: [4310/4518] 95% | Training loss: 0.6870327716360513
Epoch: 26 | Iteration number: [4320/4518] 95% | Training loss: 0.687031332017095
Epoch: 26 | Iteration number: [4330/4518] 95% | Training loss: 0.6870321433070625
Epoch: 26 | Iteration number: [4340/4518] 96% | Training loss: 0.6870341903328346
Epoch: 26 | Iteration number: [4350/4518] 96% | Training loss: 0.6870360773870314
Epoch: 26 | Iteration number: [4360/4518] 96% | Training loss: 0.6870336518101736
Epoch: 26 | Iteration number: [4370/4518] 96% | Training loss: 0.6870320450250289
Epoch: 26 | Iteration number: [4380/4518] 96% | Training loss: 0.6870332386531787
Epoch: 26 | Iteration number: [4390/4518] 97% | Training loss: 0.6870329343648055
Epoch: 26 | Iteration number: [4400/4518] 97% | Training loss: 0.6870333579859951
Epoch: 26 | Iteration number: [4410/4518] 97% | Training loss: 0.6870362654700031
Epoch: 26 | Iteration number: [4420/4518] 97% | Training loss: 0.6870341960121603
Epoch: 26 | Iteration number: [4430/4518] 98% | Training loss: 0.6870319307792268
Epoch: 26 | Iteration number: [4440/4518] 98% | Training loss: 0.6870286220500061
Epoch: 26 | Iteration number: [4450/4518] 98% | Training loss: 0.6870276176795531
Epoch: 26 | Iteration number: [4460/4518] 98% | Training loss: 0.6870272786761613
Epoch: 26 | Iteration number: [4470/4518] 98% | Training loss: 0.6870283911158841
Epoch: 26 | Iteration number: [4480/4518] 99% | Training loss: 0.6870271567787443
Epoch: 26 | Iteration number: [4490/4518] 99% | Training loss: 0.6870268152922989
Epoch: 26 | Iteration number: [4500/4518] 99% | Training loss: 0.6870267685386869
Epoch: 26 | Iteration number: [4510/4518] 99% | Training loss: 0.6870269509350381

 End of epoch: 26 | Train Loss: 0.68687440935834 | Training Time: 643 

 End of epoch: 26 | Eval Loss: 0.6902829554616189 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/4518] 0% | Training loss: 0.7556916534900665
Epoch: 27 | Iteration number: [20/4518] 0% | Training loss: 0.721361830830574
Epoch: 27 | Iteration number: [30/4518] 0% | Training loss: 0.7097326755523682
Epoch: 27 | Iteration number: [40/4518] 0% | Training loss: 0.7038945525884628
Epoch: 27 | Iteration number: [50/4518] 1% | Training loss: 0.7007423996925354
Epoch: 27 | Iteration number: [60/4518] 1% | Training loss: 0.6987133373816808
Epoch: 27 | Iteration number: [70/4518] 1% | Training loss: 0.6972607518945422
Epoch: 27 | Iteration number: [80/4518] 1% | Training loss: 0.6960291393101216
Epoch: 27 | Iteration number: [90/4518] 1% | Training loss: 0.6949491904841529
Epoch: 27 | Iteration number: [100/4518] 2% | Training loss: 0.6942894393205643
Epoch: 27 | Iteration number: [110/4518] 2% | Training loss: 0.6935768723487854
Epoch: 27 | Iteration number: [120/4518] 2% | Training loss: 0.6930101484060287
Epoch: 27 | Iteration number: [130/4518] 2% | Training loss: 0.6925316168711736
Epoch: 27 | Iteration number: [140/4518] 3% | Training loss: 0.6921468768801008
Epoch: 27 | Iteration number: [150/4518] 3% | Training loss: 0.6918789263566335
Epoch: 27 | Iteration number: [160/4518] 3% | Training loss: 0.6915942694991827
Epoch: 27 | Iteration number: [170/4518] 3% | Training loss: 0.6912814774933983
Epoch: 27 | Iteration number: [180/4518] 3% | Training loss: 0.6910033480988609
Epoch: 27 | Iteration number: [190/4518] 4% | Training loss: 0.6908200354952562
Epoch: 27 | Iteration number: [200/4518] 4% | Training loss: 0.6905885478854179
Epoch: 27 | Iteration number: [210/4518] 4% | Training loss: 0.6903807449908483
Epoch: 27 | Iteration number: [220/4518] 4% | Training loss: 0.690203242410313
Epoch: 27 | Iteration number: [230/4518] 5% | Training loss: 0.6900577625502711
Epoch: 27 | Iteration number: [240/4518] 5% | Training loss: 0.6899294431010882
Epoch: 27 | Iteration number: [250/4518] 5% | Training loss: 0.6897317423820496
Epoch: 27 | Iteration number: [260/4518] 5% | Training loss: 0.6896221704207934
Epoch: 27 | Iteration number: [270/4518] 5% | Training loss: 0.6895383848084344
Epoch: 27 | Iteration number: [280/4518] 6% | Training loss: 0.6894403065953936
Epoch: 27 | Iteration number: [290/4518] 6% | Training loss: 0.6893777843179374
Epoch: 27 | Iteration number: [300/4518] 6% | Training loss: 0.6892384165525436
Epoch: 27 | Iteration number: [310/4518] 6% | Training loss: 0.6891508786909042
Epoch: 27 | Iteration number: [320/4518] 7% | Training loss: 0.6890600621700287
Epoch: 27 | Iteration number: [330/4518] 7% | Training loss: 0.689003485621828
Epoch: 27 | Iteration number: [340/4518] 7% | Training loss: 0.6889355901409598
Epoch: 27 | Iteration number: [350/4518] 7% | Training loss: 0.6889010054724557
Epoch: 27 | Iteration number: [360/4518] 7% | Training loss: 0.6888407389322917
Epoch: 27 | Iteration number: [370/4518] 8% | Training loss: 0.688792708918855
Epoch: 27 | Iteration number: [380/4518] 8% | Training loss: 0.6887441666502702
Epoch: 27 | Iteration number: [390/4518] 8% | Training loss: 0.6886819538397667
Epoch: 27 | Iteration number: [400/4518] 8% | Training loss: 0.6886353969573975
Epoch: 27 | Iteration number: [410/4518] 9% | Training loss: 0.6886258593419703
Epoch: 27 | Iteration number: [420/4518] 9% | Training loss: 0.6885437949782326
Epoch: 27 | Iteration number: [430/4518] 9% | Training loss: 0.6885044803453046
Epoch: 27 | Iteration number: [440/4518] 9% | Training loss: 0.6884723086248744
Epoch: 27 | Iteration number: [450/4518] 9% | Training loss: 0.6884394551648034
Epoch: 27 | Iteration number: [460/4518] 10% | Training loss: 0.6884151848761931
Epoch: 27 | Iteration number: [470/4518] 10% | Training loss: 0.688373406263108
Epoch: 27 | Iteration number: [480/4518] 10% | Training loss: 0.6883430495858193
Epoch: 27 | Iteration number: [490/4518] 10% | Training loss: 0.6883029362376856
Epoch: 27 | Iteration number: [500/4518] 11% | Training loss: 0.6882561393976212
Epoch: 27 | Iteration number: [510/4518] 11% | Training loss: 0.6882330854733785
Epoch: 27 | Iteration number: [520/4518] 11% | Training loss: 0.6881935944923988
Epoch: 27 | Iteration number: [530/4518] 11% | Training loss: 0.6881766195567149
Epoch: 27 | Iteration number: [540/4518] 11% | Training loss: 0.6881137077455167
Epoch: 27 | Iteration number: [550/4518] 12% | Training loss: 0.688108819289641
Epoch: 27 | Iteration number: [560/4518] 12% | Training loss: 0.6880892529019288
Epoch: 27 | Iteration number: [570/4518] 12% | Training loss: 0.6880884278238866
Epoch: 27 | Iteration number: [580/4518] 12% | Training loss: 0.6880721805424526
Epoch: 27 | Iteration number: [590/4518] 13% | Training loss: 0.6880307157160872
Epoch: 27 | Iteration number: [600/4518] 13% | Training loss: 0.6880105948448181
Epoch: 27 | Iteration number: [610/4518] 13% | Training loss: 0.6880099024928984
Epoch: 27 | Iteration number: [620/4518] 13% | Training loss: 0.6879808268239421
Epoch: 27 | Iteration number: [630/4518] 13% | Training loss: 0.687969088838214
Epoch: 27 | Iteration number: [640/4518] 14% | Training loss: 0.6879715641960502
Epoch: 27 | Iteration number: [650/4518] 14% | Training loss: 0.6879343653642215
Epoch: 27 | Iteration number: [660/4518] 14% | Training loss: 0.6879272928743652
Epoch: 27 | Iteration number: [670/4518] 14% | Training loss: 0.6879071713383518
Epoch: 27 | Iteration number: [680/4518] 15% | Training loss: 0.6878924017443376
Epoch: 27 | Iteration number: [690/4518] 15% | Training loss: 0.6878617151059966
Epoch: 27 | Iteration number: [700/4518] 15% | Training loss: 0.6878495453085218
Epoch: 27 | Iteration number: [710/4518] 15% | Training loss: 0.6878443532426592
Epoch: 27 | Iteration number: [720/4518] 15% | Training loss: 0.6878558490839269
Epoch: 27 | Iteration number: [730/4518] 16% | Training loss: 0.6878458280269414
Epoch: 27 | Iteration number: [740/4518] 16% | Training loss: 0.687832437737568
Epoch: 27 | Iteration number: [750/4518] 16% | Training loss: 0.6878231597741445
Epoch: 27 | Iteration number: [760/4518] 16% | Training loss: 0.6878177582433349
Epoch: 27 | Iteration number: [770/4518] 17% | Training loss: 0.6878032425007263
Epoch: 27 | Iteration number: [780/4518] 17% | Training loss: 0.6878019883082463
Epoch: 27 | Iteration number: [790/4518] 17% | Training loss: 0.6877976468092278
Epoch: 27 | Iteration number: [800/4518] 17% | Training loss: 0.6877942702919245
Epoch: 27 | Iteration number: [810/4518] 17% | Training loss: 0.6877800653746099
Epoch: 27 | Iteration number: [820/4518] 18% | Training loss: 0.6877753962830799
Epoch: 27 | Iteration number: [830/4518] 18% | Training loss: 0.687757234616452
Epoch: 27 | Iteration number: [840/4518] 18% | Training loss: 0.6877460183841841
Epoch: 27 | Iteration number: [850/4518] 18% | Training loss: 0.6877223400508656
Epoch: 27 | Iteration number: [860/4518] 19% | Training loss: 0.6877131739328074
Epoch: 27 | Iteration number: [870/4518] 19% | Training loss: 0.6877025819372857
Epoch: 27 | Iteration number: [880/4518] 19% | Training loss: 0.6876788556575775
Epoch: 27 | Iteration number: [890/4518] 19% | Training loss: 0.6876758835958631
Epoch: 27 | Iteration number: [900/4518] 19% | Training loss: 0.6876790225505829
Epoch: 27 | Iteration number: [910/4518] 20% | Training loss: 0.6876610137604096
Epoch: 27 | Iteration number: [920/4518] 20% | Training loss: 0.6876601745253024
Epoch: 27 | Iteration number: [930/4518] 20% | Training loss: 0.6876407088771943
Epoch: 27 | Iteration number: [940/4518] 20% | Training loss: 0.6876305999908041
Epoch: 27 | Iteration number: [950/4518] 21% | Training loss: 0.6876104154084858
Epoch: 27 | Iteration number: [960/4518] 21% | Training loss: 0.6875971642012397
Epoch: 27 | Iteration number: [970/4518] 21% | Training loss: 0.6875873351220003
Epoch: 27 | Iteration number: [980/4518] 21% | Training loss: 0.687584877744013
Epoch: 27 | Iteration number: [990/4518] 21% | Training loss: 0.6875763171248965
Epoch: 27 | Iteration number: [1000/4518] 22% | Training loss: 0.6875869232416153
Epoch: 27 | Iteration number: [1010/4518] 22% | Training loss: 0.6875807704311786
Epoch: 27 | Iteration number: [1020/4518] 22% | Training loss: 0.6875802882746154
Epoch: 27 | Iteration number: [1030/4518] 22% | Training loss: 0.6875699027649407
Epoch: 27 | Iteration number: [1040/4518] 23% | Training loss: 0.6875609859824181
Epoch: 27 | Iteration number: [1050/4518] 23% | Training loss: 0.6875578853062221
Epoch: 27 | Iteration number: [1060/4518] 23% | Training loss: 0.6875553280677436
Epoch: 27 | Iteration number: [1070/4518] 23% | Training loss: 0.6875543353156509
Epoch: 27 | Iteration number: [1080/4518] 23% | Training loss: 0.6875467515102139
Epoch: 27 | Iteration number: [1090/4518] 24% | Training loss: 0.6875392482368224
Epoch: 27 | Iteration number: [1100/4518] 24% | Training loss: 0.6875369622490622
Epoch: 27 | Iteration number: [1110/4518] 24% | Training loss: 0.6875322991126293
Epoch: 27 | Iteration number: [1120/4518] 24% | Training loss: 0.6875216993902411
Epoch: 27 | Iteration number: [1130/4518] 25% | Training loss: 0.6875180983965375
Epoch: 27 | Iteration number: [1140/4518] 25% | Training loss: 0.687504564042677
Epoch: 27 | Iteration number: [1150/4518] 25% | Training loss: 0.6875004667821137
Epoch: 27 | Iteration number: [1160/4518] 25% | Training loss: 0.687480562308739
Epoch: 27 | Iteration number: [1170/4518] 25% | Training loss: 0.6874795896884722
Epoch: 27 | Iteration number: [1180/4518] 26% | Training loss: 0.6874837382870206
Epoch: 27 | Iteration number: [1190/4518] 26% | Training loss: 0.6874752526022807
Epoch: 27 | Iteration number: [1200/4518] 26% | Training loss: 0.6874640554686388
Epoch: 27 | Iteration number: [1210/4518] 26% | Training loss: 0.6874580746839855
Epoch: 27 | Iteration number: [1220/4518] 27% | Training loss: 0.6874486867033067
Epoch: 27 | Iteration number: [1230/4518] 27% | Training loss: 0.6874420181037934
Epoch: 27 | Iteration number: [1240/4518] 27% | Training loss: 0.687427449899335
Epoch: 27 | Iteration number: [1250/4518] 27% | Training loss: 0.6874261061668396
Epoch: 27 | Iteration number: [1260/4518] 27% | Training loss: 0.6874200431127396
Epoch: 27 | Iteration number: [1270/4518] 28% | Training loss: 0.6874100120048824
Epoch: 27 | Iteration number: [1280/4518] 28% | Training loss: 0.6874054602812976
Epoch: 27 | Iteration number: [1290/4518] 28% | Training loss: 0.6873847662016402
Epoch: 27 | Iteration number: [1300/4518] 28% | Training loss: 0.6873755886921515
Epoch: 27 | Iteration number: [1310/4518] 28% | Training loss: 0.6873678606430083
Epoch: 27 | Iteration number: [1320/4518] 29% | Training loss: 0.6873613774324908
Epoch: 27 | Iteration number: [1330/4518] 29% | Training loss: 0.6873700900633533
Epoch: 27 | Iteration number: [1340/4518] 29% | Training loss: 0.6873684894237946
Epoch: 27 | Iteration number: [1350/4518] 29% | Training loss: 0.6873647240356163
Epoch: 27 | Iteration number: [1360/4518] 30% | Training loss: 0.6873601838069804
Epoch: 27 | Iteration number: [1370/4518] 30% | Training loss: 0.6873506701775711
Epoch: 27 | Iteration number: [1380/4518] 30% | Training loss: 0.6873444026363069
Epoch: 27 | Iteration number: [1390/4518] 30% | Training loss: 0.6873453136399496
Epoch: 27 | Iteration number: [1400/4518] 30% | Training loss: 0.6873420826026372
Epoch: 27 | Iteration number: [1410/4518] 31% | Training loss: 0.6873361944729555
Epoch: 27 | Iteration number: [1420/4518] 31% | Training loss: 0.6873341911695373
Epoch: 27 | Iteration number: [1430/4518] 31% | Training loss: 0.6873288490972319
Epoch: 27 | Iteration number: [1440/4518] 31% | Training loss: 0.6873349208384752
Epoch: 27 | Iteration number: [1450/4518] 32% | Training loss: 0.6873279558790141
Epoch: 27 | Iteration number: [1460/4518] 32% | Training loss: 0.687323284598246
Epoch: 27 | Iteration number: [1470/4518] 32% | Training loss: 0.6873180995993062
Epoch: 27 | Iteration number: [1480/4518] 32% | Training loss: 0.6873190769472638
Epoch: 27 | Iteration number: [1490/4518] 32% | Training loss: 0.687310208490231
Epoch: 27 | Iteration number: [1500/4518] 33% | Training loss: 0.6873121794064839
Epoch: 27 | Iteration number: [1510/4518] 33% | Training loss: 0.6873073243936956
Epoch: 27 | Iteration number: [1520/4518] 33% | Training loss: 0.6873023359399093
Epoch: 27 | Iteration number: [1530/4518] 33% | Training loss: 0.6872949283497006
Epoch: 27 | Iteration number: [1540/4518] 34% | Training loss: 0.6872989742012767
Epoch: 27 | Iteration number: [1550/4518] 34% | Training loss: 0.6872980463504791
Epoch: 27 | Iteration number: [1560/4518] 34% | Training loss: 0.6872967090744239
Epoch: 27 | Iteration number: [1570/4518] 34% | Training loss: 0.6872917972932195
Epoch: 27 | Iteration number: [1580/4518] 34% | Training loss: 0.6872943705773051
Epoch: 27 | Iteration number: [1590/4518] 35% | Training loss: 0.6872870832119348
Epoch: 27 | Iteration number: [1600/4518] 35% | Training loss: 0.6872815013304353
Epoch: 27 | Iteration number: [1610/4518] 35% | Training loss: 0.6872807014802969
Epoch: 27 | Iteration number: [1620/4518] 35% | Training loss: 0.6872813622524709
Epoch: 27 | Iteration number: [1630/4518] 36% | Training loss: 0.6872798438818177
Epoch: 27 | Iteration number: [1640/4518] 36% | Training loss: 0.6872770884778442
Epoch: 27 | Iteration number: [1650/4518] 36% | Training loss: 0.6872753692034519
Epoch: 27 | Iteration number: [1660/4518] 36% | Training loss: 0.6872712364397853
Epoch: 27 | Iteration number: [1670/4518] 36% | Training loss: 0.6872720836165422
Epoch: 27 | Iteration number: [1680/4518] 37% | Training loss: 0.6872631439495654
Epoch: 27 | Iteration number: [1690/4518] 37% | Training loss: 0.6872611181270442
Epoch: 27 | Iteration number: [1700/4518] 37% | Training loss: 0.6872643012159011
Epoch: 27 | Iteration number: [1710/4518] 37% | Training loss: 0.6872672898378985
Epoch: 27 | Iteration number: [1720/4518] 38% | Training loss: 0.6872731407021367
Epoch: 27 | Iteration number: [1730/4518] 38% | Training loss: 0.6872701415436805
Epoch: 27 | Iteration number: [1740/4518] 38% | Training loss: 0.6872639788978401
Epoch: 27 | Iteration number: [1750/4518] 38% | Training loss: 0.6872609446048736
Epoch: 27 | Iteration number: [1760/4518] 38% | Training loss: 0.6872604236684062
Epoch: 27 | Iteration number: [1770/4518] 39% | Training loss: 0.6872541565679561
Epoch: 27 | Iteration number: [1780/4518] 39% | Training loss: 0.6872529001048442
Epoch: 27 | Iteration number: [1790/4518] 39% | Training loss: 0.6872528557337862
Epoch: 27 | Iteration number: [1800/4518] 39% | Training loss: 0.6872451223929723
Epoch: 27 | Iteration number: [1810/4518] 40% | Training loss: 0.6872419364215261
Epoch: 27 | Iteration number: [1820/4518] 40% | Training loss: 0.6872443734617024
Epoch: 27 | Iteration number: [1830/4518] 40% | Training loss: 0.6872426165257647
Epoch: 27 | Iteration number: [1840/4518] 40% | Training loss: 0.6872427924495677
Epoch: 27 | Iteration number: [1850/4518] 40% | Training loss: 0.6872373055122994
Epoch: 27 | Iteration number: [1860/4518] 41% | Training loss: 0.6872300465260782
Epoch: 27 | Iteration number: [1870/4518] 41% | Training loss: 0.6872286429698454
Epoch: 27 | Iteration number: [1880/4518] 41% | Training loss: 0.687225496166564
Epoch: 27 | Iteration number: [1890/4518] 41% | Training loss: 0.6872332843838546
Epoch: 27 | Iteration number: [1900/4518] 42% | Training loss: 0.6872292709978003
Epoch: 27 | Iteration number: [1910/4518] 42% | Training loss: 0.687232507835508
Epoch: 27 | Iteration number: [1920/4518] 42% | Training loss: 0.6872234767613311
Epoch: 27 | Iteration number: [1930/4518] 42% | Training loss: 0.6872184748476651
Epoch: 27 | Iteration number: [1940/4518] 42% | Training loss: 0.6872180222543245
Epoch: 27 | Iteration number: [1950/4518] 43% | Training loss: 0.6872116200129191
Epoch: 27 | Iteration number: [1960/4518] 43% | Training loss: 0.687209603190422
Epoch: 27 | Iteration number: [1970/4518] 43% | Training loss: 0.6872079651670407
Epoch: 27 | Iteration number: [1980/4518] 43% | Training loss: 0.6872046784921126
Epoch: 27 | Iteration number: [1990/4518] 44% | Training loss: 0.6872062529451284
Epoch: 27 | Iteration number: [2000/4518] 44% | Training loss: 0.6872010976374149
Epoch: 27 | Iteration number: [2010/4518] 44% | Training loss: 0.6872047875057998
Epoch: 27 | Iteration number: [2020/4518] 44% | Training loss: 0.6872100472155184
Epoch: 27 | Iteration number: [2030/4518] 44% | Training loss: 0.6872076832895796
Epoch: 27 | Iteration number: [2040/4518] 45% | Training loss: 0.6872100649511113
Epoch: 27 | Iteration number: [2050/4518] 45% | Training loss: 0.6872134646846026
Epoch: 27 | Iteration number: [2060/4518] 45% | Training loss: 0.6872123393618945
Epoch: 27 | Iteration number: [2070/4518] 45% | Training loss: 0.6872128883997599
Epoch: 27 | Iteration number: [2080/4518] 46% | Training loss: 0.6872085180993264
Epoch: 27 | Iteration number: [2090/4518] 46% | Training loss: 0.6872019084161548
Epoch: 27 | Iteration number: [2100/4518] 46% | Training loss: 0.6872016752050036
Epoch: 27 | Iteration number: [2110/4518] 46% | Training loss: 0.6871975018514841
Epoch: 27 | Iteration number: [2120/4518] 46% | Training loss: 0.6871993477052113
Epoch: 27 | Iteration number: [2130/4518] 47% | Training loss: 0.6871990390506708
Epoch: 27 | Iteration number: [2140/4518] 47% | Training loss: 0.6871945123527652
Epoch: 27 | Iteration number: [2150/4518] 47% | Training loss: 0.6871884836984236
Epoch: 27 | Iteration number: [2160/4518] 47% | Training loss: 0.6871888107447712
Epoch: 27 | Iteration number: [2170/4518] 48% | Training loss: 0.6871908654815041
Epoch: 27 | Iteration number: [2180/4518] 48% | Training loss: 0.6871899343958688
Epoch: 27 | Iteration number: [2190/4518] 48% | Training loss: 0.6871816671057923
Epoch: 27 | Iteration number: [2200/4518] 48% | Training loss: 0.6871709411252629
Epoch: 27 | Iteration number: [2210/4518] 48% | Training loss: 0.6871687558171976
Epoch: 27 | Iteration number: [2220/4518] 49% | Training loss: 0.6871691418392164
Epoch: 27 | Iteration number: [2230/4518] 49% | Training loss: 0.6871674196869804
Epoch: 27 | Iteration number: [2240/4518] 49% | Training loss: 0.6871681989569749
Epoch: 27 | Iteration number: [2250/4518] 49% | Training loss: 0.6871640575461917
Epoch: 27 | Iteration number: [2260/4518] 50% | Training loss: 0.6871636721940168
Epoch: 27 | Iteration number: [2270/4518] 50% | Training loss: 0.6871633923526378
Epoch: 27 | Iteration number: [2280/4518] 50% | Training loss: 0.6871548240906313
Epoch: 27 | Iteration number: [2290/4518] 50% | Training loss: 0.6871471639803924
Epoch: 27 | Iteration number: [2300/4518] 50% | Training loss: 0.6871348695651345
Epoch: 27 | Iteration number: [2310/4518] 51% | Training loss: 0.6871319129611506
Epoch: 27 | Iteration number: [2320/4518] 51% | Training loss: 0.687127462183607
Epoch: 27 | Iteration number: [2330/4518] 51% | Training loss: 0.6871251664192379
Epoch: 27 | Iteration number: [2340/4518] 51% | Training loss: 0.6871221497527554
Epoch: 27 | Iteration number: [2350/4518] 52% | Training loss: 0.6871229545867189
Epoch: 27 | Iteration number: [2360/4518] 52% | Training loss: 0.6871197418388674
Epoch: 27 | Iteration number: [2370/4518] 52% | Training loss: 0.6871188509313366
Epoch: 27 | Iteration number: [2380/4518] 52% | Training loss: 0.6871269709673249
Epoch: 27 | Iteration number: [2390/4518] 52% | Training loss: 0.687126446917466
Epoch: 27 | Iteration number: [2400/4518] 53% | Training loss: 0.687128338466088
Epoch: 27 | Iteration number: [2410/4518] 53% | Training loss: 0.6871249747721486
Epoch: 27 | Iteration number: [2420/4518] 53% | Training loss: 0.6871264432580018
Epoch: 27 | Iteration number: [2430/4518] 53% | Training loss: 0.6871219106417134
Epoch: 27 | Iteration number: [2440/4518] 54% | Training loss: 0.6871238960838709
Epoch: 27 | Iteration number: [2450/4518] 54% | Training loss: 0.6871220187994899
Epoch: 27 | Iteration number: [2460/4518] 54% | Training loss: 0.6871165830914567
Epoch: 27 | Iteration number: [2470/4518] 54% | Training loss: 0.6871155950463252
Epoch: 27 | Iteration number: [2480/4518] 54% | Training loss: 0.6871151731860253
Epoch: 27 | Iteration number: [2490/4518] 55% | Training loss: 0.6871159007032234
Epoch: 27 | Iteration number: [2500/4518] 55% | Training loss: 0.6871083635568619
Epoch: 27 | Iteration number: [2510/4518] 55% | Training loss: 0.6871069862073161
Epoch: 27 | Iteration number: [2520/4518] 55% | Training loss: 0.6871056340753086
Epoch: 27 | Iteration number: [2530/4518] 55% | Training loss: 0.6871064694738199
Epoch: 27 | Iteration number: [2540/4518] 56% | Training loss: 0.6871006801372438
Epoch: 27 | Iteration number: [2550/4518] 56% | Training loss: 0.6871003964368034
Epoch: 27 | Iteration number: [2560/4518] 56% | Training loss: 0.6870933088241145
Epoch: 27 | Iteration number: [2570/4518] 56% | Training loss: 0.6870935546980758
Epoch: 27 | Iteration number: [2580/4518] 57% | Training loss: 0.687093320096186
Epoch: 27 | Iteration number: [2590/4518] 57% | Training loss: 0.6870906861822578
Epoch: 27 | Iteration number: [2600/4518] 57% | Training loss: 0.6870943276698773
Epoch: 27 | Iteration number: [2610/4518] 57% | Training loss: 0.6870914010024162
Epoch: 27 | Iteration number: [2620/4518] 57% | Training loss: 0.6870923827622683
Epoch: 27 | Iteration number: [2630/4518] 58% | Training loss: 0.6870978969584853
Epoch: 27 | Iteration number: [2640/4518] 58% | Training loss: 0.6871002832371177
Epoch: 27 | Iteration number: [2650/4518] 58% | Training loss: 0.6870991114400468
Epoch: 27 | Iteration number: [2660/4518] 58% | Training loss: 0.687100764840169
Epoch: 27 | Iteration number: [2670/4518] 59% | Training loss: 0.6871025567644098
Epoch: 27 | Iteration number: [2680/4518] 59% | Training loss: 0.6871055277203446
Epoch: 27 | Iteration number: [2690/4518] 59% | Training loss: 0.6871075307126382
Epoch: 27 | Iteration number: [2700/4518] 59% | Training loss: 0.687105047084667
Epoch: 27 | Iteration number: [2710/4518] 59% | Training loss: 0.6871015393426058
Epoch: 27 | Iteration number: [2720/4518] 60% | Training loss: 0.6871007225311855
Epoch: 27 | Iteration number: [2730/4518] 60% | Training loss: 0.6870989964995192
Epoch: 27 | Iteration number: [2740/4518] 60% | Training loss: 0.6870995793464411
Epoch: 27 | Iteration number: [2750/4518] 60% | Training loss: 0.6870984953316776
Epoch: 27 | Iteration number: [2760/4518] 61% | Training loss: 0.6870980446969254
Epoch: 27 | Iteration number: [2770/4518] 61% | Training loss: 0.6870965701578327
Epoch: 27 | Iteration number: [2780/4518] 61% | Training loss: 0.687095320310524
Epoch: 27 | Iteration number: [2790/4518] 61% | Training loss: 0.6870943745831862
Epoch: 27 | Iteration number: [2800/4518] 61% | Training loss: 0.6870953066434179
Epoch: 27 | Iteration number: [2810/4518] 62% | Training loss: 0.6870941964756976
Epoch: 27 | Iteration number: [2820/4518] 62% | Training loss: 0.6870921699079215
Epoch: 27 | Iteration number: [2830/4518] 62% | Training loss: 0.6870916893541181
Epoch: 27 | Iteration number: [2840/4518] 62% | Training loss: 0.6870926102282295
Epoch: 27 | Iteration number: [2850/4518] 63% | Training loss: 0.6870924812659883
Epoch: 27 | Iteration number: [2860/4518] 63% | Training loss: 0.6870948799631812
Epoch: 27 | Iteration number: [2870/4518] 63% | Training loss: 0.6870965014974415
Epoch: 27 | Iteration number: [2880/4518] 63% | Training loss: 0.6870964140113857
Epoch: 27 | Iteration number: [2890/4518] 63% | Training loss: 0.6870909743036778
Epoch: 27 | Iteration number: [2900/4518] 64% | Training loss: 0.6870898483333916
Epoch: 27 | Iteration number: [2910/4518] 64% | Training loss: 0.6870880334238006
Epoch: 27 | Iteration number: [2920/4518] 64% | Training loss: 0.6870908001310205
Epoch: 27 | Iteration number: [2930/4518] 64% | Training loss: 0.6870884456935596
Epoch: 27 | Iteration number: [2940/4518] 65% | Training loss: 0.6870919005805943
Epoch: 27 | Iteration number: [2950/4518] 65% | Training loss: 0.6870891874927585
Epoch: 27 | Iteration number: [2960/4518] 65% | Training loss: 0.6870882003693968
Epoch: 27 | Iteration number: [2970/4518] 65% | Training loss: 0.687088649561911
Epoch: 27 | Iteration number: [2980/4518] 65% | Training loss: 0.6870889004044884
Epoch: 27 | Iteration number: [2990/4518] 66% | Training loss: 0.6870908476835907
Epoch: 27 | Iteration number: [3000/4518] 66% | Training loss: 0.6870884829759598
Epoch: 27 | Iteration number: [3010/4518] 66% | Training loss: 0.6870920050381822
Epoch: 27 | Iteration number: [3020/4518] 66% | Training loss: 0.6870921223368865
Epoch: 27 | Iteration number: [3030/4518] 67% | Training loss: 0.6870928106134874
Epoch: 27 | Iteration number: [3040/4518] 67% | Training loss: 0.6870920053830273
Epoch: 27 | Iteration number: [3050/4518] 67% | Training loss: 0.687088508371447
Epoch: 27 | Iteration number: [3060/4518] 67% | Training loss: 0.687089630591324
Epoch: 27 | Iteration number: [3070/4518] 67% | Training loss: 0.687091757925015
Epoch: 27 | Iteration number: [3080/4518] 68% | Training loss: 0.687089078012225
Epoch: 27 | Iteration number: [3090/4518] 68% | Training loss: 0.6870896662901906
Epoch: 27 | Iteration number: [3100/4518] 68% | Training loss: 0.6870933304679009
Epoch: 27 | Iteration number: [3110/4518] 68% | Training loss: 0.6870932110444525
Epoch: 27 | Iteration number: [3120/4518] 69% | Training loss: 0.6870920029015113
Epoch: 27 | Iteration number: [3130/4518] 69% | Training loss: 0.6870904596659322
Epoch: 27 | Iteration number: [3140/4518] 69% | Training loss: 0.6870907748770562
Epoch: 27 | Iteration number: [3150/4518] 69% | Training loss: 0.6870911333485256
Epoch: 27 | Iteration number: [3160/4518] 69% | Training loss: 0.687087647918659
Epoch: 27 | Iteration number: [3170/4518] 70% | Training loss: 0.6870889731386106
Epoch: 27 | Iteration number: [3180/4518] 70% | Training loss: 0.6870861023102166
Epoch: 27 | Iteration number: [3190/4518] 70% | Training loss: 0.6870814391998662
Epoch: 27 | Iteration number: [3200/4518] 70% | Training loss: 0.6870821874216199
Epoch: 27 | Iteration number: [3210/4518] 71% | Training loss: 0.6870842510294691
Epoch: 27 | Iteration number: [3220/4518] 71% | Training loss: 0.687080875779531
Epoch: 27 | Iteration number: [3230/4518] 71% | Training loss: 0.6870809332320564
Epoch: 27 | Iteration number: [3240/4518] 71% | Training loss: 0.6870826236443756
Epoch: 27 | Iteration number: [3250/4518] 71% | Training loss: 0.6870796706309685
Epoch: 27 | Iteration number: [3260/4518] 72% | Training loss: 0.6870794340693878
Epoch: 27 | Iteration number: [3270/4518] 72% | Training loss: 0.6870763060696629
Epoch: 27 | Iteration number: [3280/4518] 72% | Training loss: 0.6870768245582174
Epoch: 27 | Iteration number: [3290/4518] 72% | Training loss: 0.6870757563860583
Epoch: 27 | Iteration number: [3300/4518] 73% | Training loss: 0.6870752425085415
Epoch: 27 | Iteration number: [3310/4518] 73% | Training loss: 0.6870708821223221
Epoch: 27 | Iteration number: [3320/4518] 73% | Training loss: 0.687068438942892
Epoch: 27 | Iteration number: [3330/4518] 73% | Training loss: 0.68706950241023
Epoch: 27 | Iteration number: [3340/4518] 73% | Training loss: 0.6870696458987847
Epoch: 27 | Iteration number: [3350/4518] 74% | Training loss: 0.6870688976458649
Epoch: 27 | Iteration number: [3360/4518] 74% | Training loss: 0.6870686140798387
Epoch: 27 | Iteration number: [3370/4518] 74% | Training loss: 0.6870655900116137
Epoch: 27 | Iteration number: [3380/4518] 74% | Training loss: 0.6870670813427874
Epoch: 27 | Iteration number: [3390/4518] 75% | Training loss: 0.687067068467098
Epoch: 27 | Iteration number: [3400/4518] 75% | Training loss: 0.6870686124002232
Epoch: 27 | Iteration number: [3410/4518] 75% | Training loss: 0.687069541897592
Epoch: 27 | Iteration number: [3420/4518] 75% | Training loss: 0.6870698894325056
Epoch: 27 | Iteration number: [3430/4518] 75% | Training loss: 0.6870692999995485
Epoch: 27 | Iteration number: [3440/4518] 76% | Training loss: 0.6870666224249574
Epoch: 27 | Iteration number: [3450/4518] 76% | Training loss: 0.6870690675922062
Epoch: 27 | Iteration number: [3460/4518] 76% | Training loss: 0.6870632263794111
Epoch: 27 | Iteration number: [3470/4518] 76% | Training loss: 0.687064904610087
Epoch: 27 | Iteration number: [3480/4518] 77% | Training loss: 0.6870628908447836
Epoch: 27 | Iteration number: [3490/4518] 77% | Training loss: 0.6870627327259086
Epoch: 27 | Iteration number: [3500/4518] 77% | Training loss: 0.6870630505255291
Epoch: 27 | Iteration number: [3510/4518] 77% | Training loss: 0.6870656717027355
Epoch: 27 | Iteration number: [3520/4518] 77% | Training loss: 0.6870654822242531
Epoch: 27 | Iteration number: [3530/4518] 78% | Training loss: 0.6870645211202226
Epoch: 27 | Iteration number: [3540/4518] 78% | Training loss: 0.6870627692863767
Epoch: 27 | Iteration number: [3550/4518] 78% | Training loss: 0.6870628012737757
Epoch: 27 | Iteration number: [3560/4518] 78% | Training loss: 0.6870663504587131
Epoch: 27 | Iteration number: [3570/4518] 79% | Training loss: 0.6870664029896092
Epoch: 27 | Iteration number: [3580/4518] 79% | Training loss: 0.68706358123425
Epoch: 27 | Iteration number: [3590/4518] 79% | Training loss: 0.6870646401202114
Epoch: 27 | Iteration number: [3600/4518] 79% | Training loss: 0.6870682274632983
Epoch: 27 | Iteration number: [3610/4518] 79% | Training loss: 0.6870657469922485
Epoch: 27 | Iteration number: [3620/4518] 80% | Training loss: 0.6870605934720013
Epoch: 27 | Iteration number: [3630/4518] 80% | Training loss: 0.6870586731709725
Epoch: 27 | Iteration number: [3640/4518] 80% | Training loss: 0.6870596507748404
Epoch: 27 | Iteration number: [3650/4518] 80% | Training loss: 0.68706362644287
Epoch: 27 | Iteration number: [3660/4518] 81% | Training loss: 0.6870603670676549
Epoch: 27 | Iteration number: [3670/4518] 81% | Training loss: 0.6870590532183323
Epoch: 27 | Iteration number: [3680/4518] 81% | Training loss: 0.6870618181546098
Epoch: 27 | Iteration number: [3690/4518] 81% | Training loss: 0.6870643380211621
Epoch: 27 | Iteration number: [3700/4518] 81% | Training loss: 0.6870675422372045
Epoch: 27 | Iteration number: [3710/4518] 82% | Training loss: 0.6870690202295299
Epoch: 27 | Iteration number: [3720/4518] 82% | Training loss: 0.687072524860982
Epoch: 27 | Iteration number: [3730/4518] 82% | Training loss: 0.6870722110086088
Epoch: 27 | Iteration number: [3740/4518] 82% | Training loss: 0.6870724942913667
Epoch: 27 | Iteration number: [3750/4518] 83% | Training loss: 0.6870709237416586
Epoch: 27 | Iteration number: [3760/4518] 83% | Training loss: 0.6870687154854865
Epoch: 27 | Iteration number: [3770/4518] 83% | Training loss: 0.6870697966621157
Epoch: 27 | Iteration number: [3780/4518] 83% | Training loss: 0.6870701299142585
Epoch: 27 | Iteration number: [3790/4518] 83% | Training loss: 0.6870696272887781
Epoch: 27 | Iteration number: [3800/4518] 84% | Training loss: 0.6870723207059659
Epoch: 27 | Iteration number: [3810/4518] 84% | Training loss: 0.687072635917213
Epoch: 27 | Iteration number: [3820/4518] 84% | Training loss: 0.6870704169048689
Epoch: 27 | Iteration number: [3830/4518] 84% | Training loss: 0.6870697066304577
Epoch: 27 | Iteration number: [3840/4518] 84% | Training loss: 0.6870661761146039
Epoch: 27 | Iteration number: [3850/4518] 85% | Training loss: 0.6870637268060213
Epoch: 27 | Iteration number: [3860/4518] 85% | Training loss: 0.6870619156663282
Epoch: 27 | Iteration number: [3870/4518] 85% | Training loss: 0.687063054597963
Epoch: 27 | Iteration number: [3880/4518] 85% | Training loss: 0.6870640781276005
Epoch: 27 | Iteration number: [3890/4518] 86% | Training loss: 0.6870648376586198
Epoch: 27 | Iteration number: [3900/4518] 86% | Training loss: 0.6870634733102261
Epoch: 27 | Iteration number: [3910/4518] 86% | Training loss: 0.687064874294164
Epoch: 27 | Iteration number: [3920/4518] 86% | Training loss: 0.6870658101475968
Epoch: 27 | Iteration number: [3930/4518] 86% | Training loss: 0.6870664361475685
Epoch: 27 | Iteration number: [3940/4518] 87% | Training loss: 0.6870647728594427
Epoch: 27 | Iteration number: [3950/4518] 87% | Training loss: 0.6870605141301699
Epoch: 27 | Iteration number: [3960/4518] 87% | Training loss: 0.6870611017701602
Epoch: 27 | Iteration number: [3970/4518] 87% | Training loss: 0.6870596719178504
Epoch: 27 | Iteration number: [3980/4518] 88% | Training loss: 0.6870592810850048
Epoch: 27 | Iteration number: [3990/4518] 88% | Training loss: 0.6870587993982741
Epoch: 27 | Iteration number: [4000/4518] 88% | Training loss: 0.6870593084543943
Epoch: 27 | Iteration number: [4010/4518] 88% | Training loss: 0.6870568038222201
Epoch: 27 | Iteration number: [4020/4518] 88% | Training loss: 0.6870553388672681
Epoch: 27 | Iteration number: [4030/4518] 89% | Training loss: 0.6870525245039398
Epoch: 27 | Iteration number: [4040/4518] 89% | Training loss: 0.6870513854197936
Epoch: 27 | Iteration number: [4050/4518] 89% | Training loss: 0.6870495724530867
Epoch: 27 | Iteration number: [4060/4518] 89% | Training loss: 0.687049511309915
Epoch: 27 | Iteration number: [4070/4518] 90% | Training loss: 0.6870445989566587
Epoch: 27 | Iteration number: [4080/4518] 90% | Training loss: 0.6870451865096887
Epoch: 27 | Iteration number: [4090/4518] 90% | Training loss: 0.6870408631187196
Epoch: 27 | Iteration number: [4100/4518] 90% | Training loss: 0.6870402379006875
Epoch: 27 | Iteration number: [4110/4518] 90% | Training loss: 0.6870392710042986
Epoch: 27 | Iteration number: [4120/4518] 91% | Training loss: 0.6870361929668963
Epoch: 27 | Iteration number: [4130/4518] 91% | Training loss: 0.6870365331738683
Epoch: 27 | Iteration number: [4140/4518] 91% | Training loss: 0.6870400714989445
Epoch: 27 | Iteration number: [4150/4518] 91% | Training loss: 0.6870387430507017
Epoch: 27 | Iteration number: [4160/4518] 92% | Training loss: 0.6870385525318292
Epoch: 27 | Iteration number: [4170/4518] 92% | Training loss: 0.687038328664766
Epoch: 27 | Iteration number: [4180/4518] 92% | Training loss: 0.6870419533486571
Epoch: 27 | Iteration number: [4190/4518] 92% | Training loss: 0.6870404145455873
Epoch: 27 | Iteration number: [4200/4518] 92% | Training loss: 0.6870413064956665
Epoch: 27 | Iteration number: [4210/4518] 93% | Training loss: 0.68704279325637
Epoch: 27 | Iteration number: [4220/4518] 93% | Training loss: 0.687038356319988
Epoch: 27 | Iteration number: [4230/4518] 93% | Training loss: 0.6870373641909155
Epoch: 27 | Iteration number: [4240/4518] 93% | Training loss: 0.6870391987264156
Epoch: 27 | Iteration number: [4250/4518] 94% | Training loss: 0.6870382640361786
Epoch: 27 | Iteration number: [4260/4518] 94% | Training loss: 0.6870381954410266
Epoch: 27 | Iteration number: [4270/4518] 94% | Training loss: 0.687038862440011
Epoch: 27 | Iteration number: [4280/4518] 94% | Training loss: 0.6870376045737311
Epoch: 27 | Iteration number: [4290/4518] 94% | Training loss: 0.6870341676793176
Epoch: 27 | Iteration number: [4300/4518] 95% | Training loss: 0.687034239949182
Epoch: 27 | Iteration number: [4310/4518] 95% | Training loss: 0.6870366853240472
Epoch: 27 | Iteration number: [4320/4518] 95% | Training loss: 0.6870354813282137
Epoch: 27 | Iteration number: [4330/4518] 95% | Training loss: 0.6870349896559814
Epoch: 27 | Iteration number: [4340/4518] 96% | Training loss: 0.687035623137852
Epoch: 27 | Iteration number: [4350/4518] 96% | Training loss: 0.687034966616795
Epoch: 27 | Iteration number: [4360/4518] 96% | Training loss: 0.6870324128264681
Epoch: 27 | Iteration number: [4370/4518] 96% | Training loss: 0.6870337161646828
Epoch: 27 | Iteration number: [4380/4518] 96% | Training loss: 0.6870356169873721
Epoch: 27 | Iteration number: [4390/4518] 97% | Training loss: 0.6870346695659916
Epoch: 27 | Iteration number: [4400/4518] 97% | Training loss: 0.6870350294221531
Epoch: 27 | Iteration number: [4410/4518] 97% | Training loss: 0.6870325334082925
Epoch: 27 | Iteration number: [4420/4518] 97% | Training loss: 0.6870321568051075
Epoch: 27 | Iteration number: [4430/4518] 98% | Training loss: 0.6870341996710672
Epoch: 27 | Iteration number: [4440/4518] 98% | Training loss: 0.6870350912079081
Epoch: 27 | Iteration number: [4450/4518] 98% | Training loss: 0.687031845390127
Epoch: 27 | Iteration number: [4460/4518] 98% | Training loss: 0.6870316661393161
Epoch: 27 | Iteration number: [4470/4518] 98% | Training loss: 0.6870311492774844
Epoch: 27 | Iteration number: [4480/4518] 99% | Training loss: 0.6870297642956887
Epoch: 27 | Iteration number: [4490/4518] 99% | Training loss: 0.6870312585729799
Epoch: 27 | Iteration number: [4500/4518] 99% | Training loss: 0.6870271095434825
Epoch: 27 | Iteration number: [4510/4518] 99% | Training loss: 0.6870271404408034

 End of epoch: 27 | Train Loss: 0.6868750658273802 | Training Time: 643 

 End of epoch: 27 | Eval Loss: 0.690269588207712 | Evaluating Time: 17 
Epoch: 28 | Iteration number: [10/4518] 0% | Training loss: 0.7546053171157837
Epoch: 28 | Iteration number: [20/4518] 0% | Training loss: 0.7206618905067443
Epoch: 28 | Iteration number: [30/4518] 0% | Training loss: 0.7091372231642405
Epoch: 28 | Iteration number: [40/4518] 0% | Training loss: 0.7037480786442757
Epoch: 28 | Iteration number: [50/4518] 1% | Training loss: 0.7000943529605865
Epoch: 28 | Iteration number: [60/4518] 1% | Training loss: 0.6979155540466309
Epoch: 28 | Iteration number: [70/4518] 1% | Training loss: 0.6963316142559052
Epoch: 28 | Iteration number: [80/4518] 1% | Training loss: 0.6951970979571342
Epoch: 28 | Iteration number: [90/4518] 1% | Training loss: 0.6942757341596816
Epoch: 28 | Iteration number: [100/4518] 2% | Training loss: 0.6936330574750901
Epoch: 28 | Iteration number: [110/4518] 2% | Training loss: 0.6931086318059401
Epoch: 28 | Iteration number: [120/4518] 2% | Training loss: 0.6925882811347643
Epoch: 28 | Iteration number: [130/4518] 2% | Training loss: 0.6921597379904527
Epoch: 28 | Iteration number: [140/4518] 3% | Training loss: 0.6917780556849071
Epoch: 28 | Iteration number: [150/4518] 3% | Training loss: 0.6913702988624573
Epoch: 28 | Iteration number: [160/4518] 3% | Training loss: 0.6911474443972111
Epoch: 28 | Iteration number: [170/4518] 3% | Training loss: 0.690922886834425
Epoch: 28 | Iteration number: [180/4518] 3% | Training loss: 0.6907026128636466
Epoch: 28 | Iteration number: [190/4518] 4% | Training loss: 0.6904890596866607
Epoch: 28 | Iteration number: [200/4518] 4% | Training loss: 0.6903755882382393
Epoch: 28 | Iteration number: [210/4518] 4% | Training loss: 0.6901872853438059
Epoch: 28 | Iteration number: [220/4518] 4% | Training loss: 0.6900198990648443
Epoch: 28 | Iteration number: [230/4518] 5% | Training loss: 0.6899188557396765
Epoch: 28 | Iteration number: [240/4518] 5% | Training loss: 0.6898118247588475
Epoch: 28 | Iteration number: [250/4518] 5% | Training loss: 0.6896762688159943
Epoch: 28 | Iteration number: [260/4518] 5% | Training loss: 0.689572571332638
Epoch: 28 | Iteration number: [270/4518] 5% | Training loss: 0.6894373825302831
Epoch: 28 | Iteration number: [280/4518] 6% | Training loss: 0.6893838737692152
Epoch: 28 | Iteration number: [290/4518] 6% | Training loss: 0.6893232033170503
Epoch: 28 | Iteration number: [300/4518] 6% | Training loss: 0.6892493685086568
Epoch: 28 | Iteration number: [310/4518] 6% | Training loss: 0.6891897876416483
Epoch: 28 | Iteration number: [320/4518] 7% | Training loss: 0.6890935290604829
Epoch: 28 | Iteration number: [330/4518] 7% | Training loss: 0.6890081364097017
Epoch: 28 | Iteration number: [340/4518] 7% | Training loss: 0.6889508881989648
Epoch: 28 | Iteration number: [350/4518] 7% | Training loss: 0.6888990827969143
Epoch: 28 | Iteration number: [360/4518] 7% | Training loss: 0.688822166952822
Epoch: 28 | Iteration number: [370/4518] 8% | Training loss: 0.6887736797332764
Epoch: 28 | Iteration number: [380/4518] 8% | Training loss: 0.6887212550953815
Epoch: 28 | Iteration number: [390/4518] 8% | Training loss: 0.6886771287673559
Epoch: 28 | Iteration number: [400/4518] 8% | Training loss: 0.6886166936159134
Epoch: 28 | Iteration number: [410/4518] 9% | Training loss: 0.688583570573388
Epoch: 28 | Iteration number: [420/4518] 9% | Training loss: 0.6885495905365263
Epoch: 28 | Iteration number: [430/4518] 9% | Training loss: 0.6885260856428812
Epoch: 28 | Iteration number: [440/4518] 9% | Training loss: 0.6884999286044727
Epoch: 28 | Iteration number: [450/4518] 9% | Training loss: 0.6884613909986284
Epoch: 28 | Iteration number: [460/4518] 10% | Training loss: 0.6884194935145586
Epoch: 28 | Iteration number: [470/4518] 10% | Training loss: 0.6883918867466298
Epoch: 28 | Iteration number: [480/4518] 10% | Training loss: 0.6883235121766726
Epoch: 28 | Iteration number: [490/4518] 10% | Training loss: 0.6883119664630112
Epoch: 28 | Iteration number: [500/4518] 11% | Training loss: 0.6882787277698517
Epoch: 28 | Iteration number: [510/4518] 11% | Training loss: 0.6882676408571355
Epoch: 28 | Iteration number: [520/4518] 11% | Training loss: 0.688237056021507
Epoch: 28 | Iteration number: [530/4518] 11% | Training loss: 0.6882161622902132
Epoch: 28 | Iteration number: [540/4518] 11% | Training loss: 0.6881773837186672
Epoch: 28 | Iteration number: [550/4518] 12% | Training loss: 0.6881599634343928
Epoch: 28 | Iteration number: [560/4518] 12% | Training loss: 0.6881482220121793
Epoch: 28 | Iteration number: [570/4518] 12% | Training loss: 0.6881201714800115
Epoch: 28 | Iteration number: [580/4518] 12% | Training loss: 0.6881113916635513
Epoch: 28 | Iteration number: [590/4518] 13% | Training loss: 0.6880890804832265
Epoch: 28 | Iteration number: [600/4518] 13% | Training loss: 0.6880521653095881
Epoch: 28 | Iteration number: [610/4518] 13% | Training loss: 0.6880410424021424
Epoch: 28 | Iteration number: [620/4518] 13% | Training loss: 0.6880104188957522
Epoch: 28 | Iteration number: [630/4518] 13% | Training loss: 0.687997340304511
Epoch: 28 | Iteration number: [640/4518] 14% | Training loss: 0.687965200189501
Epoch: 28 | Iteration number: [650/4518] 14% | Training loss: 0.6879529955753914
Epoch: 28 | Iteration number: [660/4518] 14% | Training loss: 0.6879365095586488
Epoch: 28 | Iteration number: [670/4518] 14% | Training loss: 0.6879288584438723
Epoch: 28 | Iteration number: [680/4518] 15% | Training loss: 0.6878951677504708
Epoch: 28 | Iteration number: [690/4518] 15% | Training loss: 0.6878818336604298
Epoch: 28 | Iteration number: [700/4518] 15% | Training loss: 0.6878531656946455
Epoch: 28 | Iteration number: [710/4518] 15% | Training loss: 0.6878435269208022
Epoch: 28 | Iteration number: [720/4518] 15% | Training loss: 0.6878329320086374
Epoch: 28 | Iteration number: [730/4518] 16% | Training loss: 0.6878130012179074
Epoch: 28 | Iteration number: [740/4518] 16% | Training loss: 0.6878049032108203
Epoch: 28 | Iteration number: [750/4518] 16% | Training loss: 0.687789309501648
Epoch: 28 | Iteration number: [760/4518] 16% | Training loss: 0.6877825306434381
Epoch: 28 | Iteration number: [770/4518] 17% | Training loss: 0.6877877329851125
Epoch: 28 | Iteration number: [780/4518] 17% | Training loss: 0.6877781087771441
Epoch: 28 | Iteration number: [790/4518] 17% | Training loss: 0.6877725859231587
Epoch: 28 | Iteration number: [800/4518] 17% | Training loss: 0.687753825634718
Epoch: 28 | Iteration number: [810/4518] 17% | Training loss: 0.687757533641509
Epoch: 28 | Iteration number: [820/4518] 18% | Training loss: 0.6877442367920061
Epoch: 28 | Iteration number: [830/4518] 18% | Training loss: 0.687738808307303
Epoch: 28 | Iteration number: [840/4518] 18% | Training loss: 0.6877294646842139
Epoch: 28 | Iteration number: [850/4518] 18% | Training loss: 0.6877343144837548
Epoch: 28 | Iteration number: [860/4518] 19% | Training loss: 0.6877361237309699
Epoch: 28 | Iteration number: [870/4518] 19% | Training loss: 0.687730343314423
Epoch: 28 | Iteration number: [880/4518] 19% | Training loss: 0.6877221254462546
Epoch: 28 | Iteration number: [890/4518] 19% | Training loss: 0.6877178265137619
Epoch: 28 | Iteration number: [900/4518] 19% | Training loss: 0.6877110001775953
Epoch: 28 | Iteration number: [910/4518] 20% | Training loss: 0.6876963722836841
Epoch: 28 | Iteration number: [920/4518] 20% | Training loss: 0.6876839534096096
Epoch: 28 | Iteration number: [930/4518] 20% | Training loss: 0.6876802689926599
Epoch: 28 | Iteration number: [940/4518] 20% | Training loss: 0.6876573214505581
Epoch: 28 | Iteration number: [950/4518] 21% | Training loss: 0.6876476980510511
Epoch: 28 | Iteration number: [960/4518] 21% | Training loss: 0.687630970031023
Epoch: 28 | Iteration number: [970/4518] 21% | Training loss: 0.6876202188816267
Epoch: 28 | Iteration number: [980/4518] 21% | Training loss: 0.6876101196420435
Epoch: 28 | Iteration number: [990/4518] 21% | Training loss: 0.6876115046366297
Epoch: 28 | Iteration number: [1000/4518] 22% | Training loss: 0.6876068850159645
Epoch: 28 | Iteration number: [1010/4518] 22% | Training loss: 0.6876029991277374
Epoch: 28 | Iteration number: [1020/4518] 22% | Training loss: 0.6875905871975656
Epoch: 28 | Iteration number: [1030/4518] 22% | Training loss: 0.6875824631996525
Epoch: 28 | Iteration number: [1040/4518] 23% | Training loss: 0.6875739220243234
Epoch: 28 | Iteration number: [1050/4518] 23% | Training loss: 0.6875697854019347
Epoch: 28 | Iteration number: [1060/4518] 23% | Training loss: 0.6875594492228526
Epoch: 28 | Iteration number: [1070/4518] 23% | Training loss: 0.6875403335161299
Epoch: 28 | Iteration number: [1080/4518] 23% | Training loss: 0.687540757490529
Epoch: 28 | Iteration number: [1090/4518] 24% | Training loss: 0.687520859110246
Epoch: 28 | Iteration number: [1100/4518] 24% | Training loss: 0.6875113384832036
Epoch: 28 | Iteration number: [1110/4518] 24% | Training loss: 0.6874926723875441
Epoch: 28 | Iteration number: [1120/4518] 24% | Training loss: 0.6874900218099356
Epoch: 28 | Iteration number: [1130/4518] 25% | Training loss: 0.6874803403310016
Epoch: 28 | Iteration number: [1140/4518] 25% | Training loss: 0.6874814335191459
Epoch: 28 | Iteration number: [1150/4518] 25% | Training loss: 0.6874722136103588
Epoch: 28 | Iteration number: [1160/4518] 25% | Training loss: 0.6874715931970498
Epoch: 28 | Iteration number: [1170/4518] 25% | Training loss: 0.687458739321456
Epoch: 28 | Iteration number: [1180/4518] 26% | Training loss: 0.6874570258088031
Epoch: 28 | Iteration number: [1190/4518] 26% | Training loss: 0.6874506695931699
Epoch: 28 | Iteration number: [1200/4518] 26% | Training loss: 0.68743978018562
Epoch: 28 | Iteration number: [1210/4518] 26% | Training loss: 0.6874226784903156
Epoch: 28 | Iteration number: [1220/4518] 27% | Training loss: 0.6874098161204917
Epoch: 28 | Iteration number: [1230/4518] 27% | Training loss: 0.6874120622631011
Epoch: 28 | Iteration number: [1240/4518] 27% | Training loss: 0.6874073975509213
Epoch: 28 | Iteration number: [1250/4518] 27% | Training loss: 0.6873940351486206
Epoch: 28 | Iteration number: [1260/4518] 27% | Training loss: 0.68738340479987
Epoch: 28 | Iteration number: [1270/4518] 28% | Training loss: 0.6873767384863275
Epoch: 28 | Iteration number: [1280/4518] 28% | Training loss: 0.6873708627186715
Epoch: 28 | Iteration number: [1290/4518] 28% | Training loss: 0.687369734834331
Epoch: 28 | Iteration number: [1300/4518] 28% | Training loss: 0.6873671332230935
Epoch: 28 | Iteration number: [1310/4518] 28% | Training loss: 0.6873553911693223
Epoch: 28 | Iteration number: [1320/4518] 29% | Training loss: 0.6873466374747681
Epoch: 28 | Iteration number: [1330/4518] 29% | Training loss: 0.6873464128128568
Epoch: 28 | Iteration number: [1340/4518] 29% | Training loss: 0.6873357552201
Epoch: 28 | Iteration number: [1350/4518] 29% | Training loss: 0.6873333039548662
Epoch: 28 | Iteration number: [1360/4518] 30% | Training loss: 0.6873330162728534
Epoch: 28 | Iteration number: [1370/4518] 30% | Training loss: 0.6873359495705932
Epoch: 28 | Iteration number: [1380/4518] 30% | Training loss: 0.68733737334825
Epoch: 28 | Iteration number: [1390/4518] 30% | Training loss: 0.6873347074865437
Epoch: 28 | Iteration number: [1400/4518] 30% | Training loss: 0.6873321256467274
Epoch: 28 | Iteration number: [1410/4518] 31% | Training loss: 0.6873277389834113
Epoch: 28 | Iteration number: [1420/4518] 31% | Training loss: 0.6873252456037091
Epoch: 28 | Iteration number: [1430/4518] 31% | Training loss: 0.6873196152540354
Epoch: 28 | Iteration number: [1440/4518] 31% | Training loss: 0.6873179313623243
Epoch: 28 | Iteration number: [1450/4518] 32% | Training loss: 0.6873125694537985
Epoch: 28 | Iteration number: [1460/4518] 32% | Training loss: 0.687313900214352
Epoch: 28 | Iteration number: [1470/4518] 32% | Training loss: 0.6873060546359238
Epoch: 28 | Iteration number: [1480/4518] 32% | Training loss: 0.6873062124123445
Epoch: 28 | Iteration number: [1490/4518] 32% | Training loss: 0.6873038767568217
Epoch: 28 | Iteration number: [1500/4518] 33% | Training loss: 0.687300682147344
Epoch: 28 | Iteration number: [1510/4518] 33% | Training loss: 0.6872956620541629
Epoch: 28 | Iteration number: [1520/4518] 33% | Training loss: 0.6872843400428169
Epoch: 28 | Iteration number: [1530/4518] 33% | Training loss: 0.6872785904438667
Epoch: 28 | Iteration number: [1540/4518] 34% | Training loss: 0.6872680110590799
Epoch: 28 | Iteration number: [1550/4518] 34% | Training loss: 0.6872660661128259
Epoch: 28 | Iteration number: [1560/4518] 34% | Training loss: 0.6872642189264297
Epoch: 28 | Iteration number: [1570/4518] 34% | Training loss: 0.6872552876259871
Epoch: 28 | Iteration number: [1580/4518] 34% | Training loss: 0.6872524053990087
Epoch: 28 | Iteration number: [1590/4518] 35% | Training loss: 0.6872459311155403
Epoch: 28 | Iteration number: [1600/4518] 35% | Training loss: 0.6872382587939501
Epoch: 28 | Iteration number: [1610/4518] 35% | Training loss: 0.6872316835459715
Epoch: 28 | Iteration number: [1620/4518] 35% | Training loss: 0.6872309589459572
Epoch: 28 | Iteration number: [1630/4518] 36% | Training loss: 0.6872229813066728
Epoch: 28 | Iteration number: [1640/4518] 36% | Training loss: 0.6872202277546976
Epoch: 28 | Iteration number: [1650/4518] 36% | Training loss: 0.6872172808647156
Epoch: 28 | Iteration number: [1660/4518] 36% | Training loss: 0.687220299064395
Epoch: 28 | Iteration number: [1670/4518] 36% | Training loss: 0.6872153745439952
Epoch: 28 | Iteration number: [1680/4518] 37% | Training loss: 0.6872067531659489
Epoch: 28 | Iteration number: [1690/4518] 37% | Training loss: 0.6872127877537315
Epoch: 28 | Iteration number: [1700/4518] 37% | Training loss: 0.6872041406701593
Epoch: 28 | Iteration number: [1710/4518] 37% | Training loss: 0.6872008834317413
Epoch: 28 | Iteration number: [1720/4518] 38% | Training loss: 0.6872020936636037
Epoch: 28 | Iteration number: [1730/4518] 38% | Training loss: 0.6871989727709334
Epoch: 28 | Iteration number: [1740/4518] 38% | Training loss: 0.6872031257755455
Epoch: 28 | Iteration number: [1750/4518] 38% | Training loss: 0.687202923468181
Epoch: 28 | Iteration number: [1760/4518] 38% | Training loss: 0.6872050113976002
Epoch: 28 | Iteration number: [1770/4518] 39% | Training loss: 0.6872055302905498
Epoch: 28 | Iteration number: [1780/4518] 39% | Training loss: 0.6872084467598562
Epoch: 28 | Iteration number: [1790/4518] 39% | Training loss: 0.6872030493600408
Epoch: 28 | Iteration number: [1800/4518] 39% | Training loss: 0.6872012362877528
Epoch: 28 | Iteration number: [1810/4518] 40% | Training loss: 0.6872030644456326
Epoch: 28 | Iteration number: [1820/4518] 40% | Training loss: 0.6872007749892853
Epoch: 28 | Iteration number: [1830/4518] 40% | Training loss: 0.6871979309561475
Epoch: 28 | Iteration number: [1840/4518] 40% | Training loss: 0.6872006427334703
Epoch: 28 | Iteration number: [1850/4518] 40% | Training loss: 0.687199312641814
Epoch: 28 | Iteration number: [1860/4518] 41% | Training loss: 0.687196645525194
Epoch: 28 | Iteration number: [1870/4518] 41% | Training loss: 0.6871957761399886
Epoch: 28 | Iteration number: [1880/4518] 41% | Training loss: 0.6871908995065283
Epoch: 28 | Iteration number: [1890/4518] 41% | Training loss: 0.6871926989189532
Epoch: 28 | Iteration number: [1900/4518] 42% | Training loss: 0.6871935117244721
Epoch: 28 | Iteration number: [1910/4518] 42% | Training loss: 0.6871841404138436
Epoch: 28 | Iteration number: [1920/4518] 42% | Training loss: 0.687183222702394
Epoch: 28 | Iteration number: [1930/4518] 42% | Training loss: 0.6871858523299657
Epoch: 28 | Iteration number: [1940/4518] 42% | Training loss: 0.6871791405468872
Epoch: 28 | Iteration number: [1950/4518] 43% | Training loss: 0.6871765254094051
Epoch: 28 | Iteration number: [1960/4518] 43% | Training loss: 0.687181460948623
Epoch: 28 | Iteration number: [1970/4518] 43% | Training loss: 0.687178631210085
Epoch: 28 | Iteration number: [1980/4518] 43% | Training loss: 0.6871781903986979
Epoch: 28 | Iteration number: [1990/4518] 44% | Training loss: 0.6871746025193277
Epoch: 28 | Iteration number: [2000/4518] 44% | Training loss: 0.687176379263401
Epoch: 28 | Iteration number: [2010/4518] 44% | Training loss: 0.687173017874286
Epoch: 28 | Iteration number: [2020/4518] 44% | Training loss: 0.6871726135806282
Epoch: 28 | Iteration number: [2030/4518] 44% | Training loss: 0.687169231217483
Epoch: 28 | Iteration number: [2040/4518] 45% | Training loss: 0.6871644073841618
Epoch: 28 | Iteration number: [2050/4518] 45% | Training loss: 0.6871649169921875
Epoch: 28 | Iteration number: [2060/4518] 45% | Training loss: 0.6871676781513159
Epoch: 28 | Iteration number: [2070/4518] 45% | Training loss: 0.6871633385114624
Epoch: 28 | Iteration number: [2080/4518] 46% | Training loss: 0.6871623103721783
Epoch: 28 | Iteration number: [2090/4518] 46% | Training loss: 0.6871662694586521
Epoch: 28 | Iteration number: [2100/4518] 46% | Training loss: 0.6871585741497221
Epoch: 28 | Iteration number: [2110/4518] 46% | Training loss: 0.6871596748230017
Epoch: 28 | Iteration number: [2120/4518] 46% | Training loss: 0.6871599318283909
Epoch: 28 | Iteration number: [2130/4518] 47% | Training loss: 0.6871508548797016
Epoch: 28 | Iteration number: [2140/4518] 47% | Training loss: 0.687150544568757
Epoch: 28 | Iteration number: [2150/4518] 47% | Training loss: 0.6871500201280727
Epoch: 28 | Iteration number: [2160/4518] 47% | Training loss: 0.687151101231575
Epoch: 28 | Iteration number: [2170/4518] 48% | Training loss: 0.6871496477984064
Epoch: 28 | Iteration number: [2180/4518] 48% | Training loss: 0.6871459499411626
Epoch: 28 | Iteration number: [2190/4518] 48% | Training loss: 0.6871462874216576
Epoch: 28 | Iteration number: [2200/4518] 48% | Training loss: 0.687141250507398
Epoch: 28 | Iteration number: [2210/4518] 48% | Training loss: 0.6871344720885765
Epoch: 28 | Iteration number: [2220/4518] 49% | Training loss: 0.6871388678346668
Epoch: 28 | Iteration number: [2230/4518] 49% | Training loss: 0.6871363748616702
Epoch: 28 | Iteration number: [2240/4518] 49% | Training loss: 0.6871332441855754
Epoch: 28 | Iteration number: [2250/4518] 49% | Training loss: 0.6871262107690176
Epoch: 28 | Iteration number: [2260/4518] 50% | Training loss: 0.6871223745356618
Epoch: 28 | Iteration number: [2270/4518] 50% | Training loss: 0.6871180993607391
Epoch: 28 | Iteration number: [2280/4518] 50% | Training loss: 0.6871189329707832
Epoch: 28 | Iteration number: [2290/4518] 50% | Training loss: 0.6871152036835533
Epoch: 28 | Iteration number: [2300/4518] 50% | Training loss: 0.6871113620892815
Epoch: 28 | Iteration number: [2310/4518] 51% | Training loss: 0.6871105734404032
Epoch: 28 | Iteration number: [2320/4518] 51% | Training loss: 0.6871126626329175
Epoch: 28 | Iteration number: [2330/4518] 51% | Training loss: 0.6871144097250419
Epoch: 28 | Iteration number: [2340/4518] 51% | Training loss: 0.6871138623127571
Epoch: 28 | Iteration number: [2350/4518] 52% | Training loss: 0.6871102611308402
Epoch: 28 | Iteration number: [2360/4518] 52% | Training loss: 0.6871087920362666
Epoch: 28 | Iteration number: [2370/4518] 52% | Training loss: 0.6871049439856775
Epoch: 28 | Iteration number: [2380/4518] 52% | Training loss: 0.6871002703404226
Epoch: 28 | Iteration number: [2390/4518] 52% | Training loss: 0.6870974226726149
Epoch: 28 | Iteration number: [2400/4518] 53% | Training loss: 0.6870964378615221
Epoch: 28 | Iteration number: [2410/4518] 53% | Training loss: 0.6870971934923987
Epoch: 28 | Iteration number: [2420/4518] 53% | Training loss: 0.6870982545959062
Epoch: 28 | Iteration number: [2430/4518] 53% | Training loss: 0.687100046480634
Epoch: 28 | Iteration number: [2440/4518] 54% | Training loss: 0.6870941806279245
Epoch: 28 | Iteration number: [2450/4518] 54% | Training loss: 0.6870868718137546
Epoch: 28 | Iteration number: [2460/4518] 54% | Training loss: 0.6870850507563692
Epoch: 28 | Iteration number: [2470/4518] 54% | Training loss: 0.6870874833722829
Epoch: 28 | Iteration number: [2480/4518] 54% | Training loss: 0.6870871026189097
Epoch: 28 | Iteration number: [2490/4518] 55% | Training loss: 0.6870838847983793
Epoch: 28 | Iteration number: [2500/4518] 55% | Training loss: 0.6870814835071564
Epoch: 28 | Iteration number: [2510/4518] 55% | Training loss: 0.6870799417989663
Epoch: 28 | Iteration number: [2520/4518] 55% | Training loss: 0.6870737240428016
Epoch: 28 | Iteration number: [2530/4518] 55% | Training loss: 0.6870742467316714
Epoch: 28 | Iteration number: [2540/4518] 56% | Training loss: 0.6870751128891321
Epoch: 28 | Iteration number: [2550/4518] 56% | Training loss: 0.6870769918198679
Epoch: 28 | Iteration number: [2560/4518] 56% | Training loss: 0.6870757772121578
Epoch: 28 | Iteration number: [2570/4518] 56% | Training loss: 0.6870716623295142
Epoch: 28 | Iteration number: [2580/4518] 57% | Training loss: 0.6870736158402391
Epoch: 28 | Iteration number: [2590/4518] 57% | Training loss: 0.6870755802710544
Epoch: 28 | Iteration number: [2600/4518] 57% | Training loss: 0.6870772144886164
Epoch: 28 | Iteration number: [2610/4518] 57% | Training loss: 0.6870721652589995
Epoch: 28 | Iteration number: [2620/4518] 57% | Training loss: 0.6870708727199613
Epoch: 28 | Iteration number: [2630/4518] 58% | Training loss: 0.6870714279635324
Epoch: 28 | Iteration number: [2640/4518] 58% | Training loss: 0.6870726487627535
Epoch: 28 | Iteration number: [2650/4518] 58% | Training loss: 0.6870717881985431
Epoch: 28 | Iteration number: [2660/4518] 58% | Training loss: 0.6870724614177431
Epoch: 28 | Iteration number: [2670/4518] 59% | Training loss: 0.6870755511946446
Epoch: 28 | Iteration number: [2680/4518] 59% | Training loss: 0.6870736602082181
Epoch: 28 | Iteration number: [2690/4518] 59% | Training loss: 0.6870713406779065
Epoch: 28 | Iteration number: [2700/4518] 59% | Training loss: 0.6870721538640835
Epoch: 28 | Iteration number: [2710/4518] 59% | Training loss: 0.6870690208959404
Epoch: 28 | Iteration number: [2720/4518] 60% | Training loss: 0.6870629246182302
Epoch: 28 | Iteration number: [2730/4518] 60% | Training loss: 0.6870646647699586
Epoch: 28 | Iteration number: [2740/4518] 60% | Training loss: 0.6870582569689646
Epoch: 28 | Iteration number: [2750/4518] 60% | Training loss: 0.6870586949261752
Epoch: 28 | Iteration number: [2760/4518] 61% | Training loss: 0.6870628905685051
Epoch: 28 | Iteration number: [2770/4518] 61% | Training loss: 0.6870645926532333
Epoch: 28 | Iteration number: [2780/4518] 61% | Training loss: 0.6870635492124146
Epoch: 28 | Iteration number: [2790/4518] 61% | Training loss: 0.6870638243613705
Epoch: 28 | Iteration number: [2800/4518] 61% | Training loss: 0.6870623335880892
Epoch: 28 | Iteration number: [2810/4518] 62% | Training loss: 0.6870566405223357
Epoch: 28 | Iteration number: [2820/4518] 62% | Training loss: 0.6870593263959208
Epoch: 28 | Iteration number: [2830/4518] 62% | Training loss: 0.6870597811975243
Epoch: 28 | Iteration number: [2840/4518] 62% | Training loss: 0.6870600317355613
Epoch: 28 | Iteration number: [2850/4518] 63% | Training loss: 0.6870645247425949
Epoch: 28 | Iteration number: [2860/4518] 63% | Training loss: 0.687060933825853
Epoch: 28 | Iteration number: [2870/4518] 63% | Training loss: 0.6870598533635356
Epoch: 28 | Iteration number: [2880/4518] 63% | Training loss: 0.6870584951920642
Epoch: 28 | Iteration number: [2890/4518] 63% | Training loss: 0.6870562439146339
Epoch: 28 | Iteration number: [2900/4518] 64% | Training loss: 0.6870604191360803
Epoch: 28 | Iteration number: [2910/4518] 64% | Training loss: 0.6870615397736789
Epoch: 28 | Iteration number: [2920/4518] 64% | Training loss: 0.6870629925433903
Epoch: 28 | Iteration number: [2930/4518] 64% | Training loss: 0.6870587899212951
Epoch: 28 | Iteration number: [2940/4518] 65% | Training loss: 0.6870598134540377
Epoch: 28 | Iteration number: [2950/4518] 65% | Training loss: 0.6870591265468274
Epoch: 28 | Iteration number: [2960/4518] 65% | Training loss: 0.6870587190462125
Epoch: 28 | Iteration number: [2970/4518] 65% | Training loss: 0.6870591966592101
Epoch: 28 | Iteration number: [2980/4518] 65% | Training loss: 0.6870563319265443
Epoch: 28 | Iteration number: [2990/4518] 66% | Training loss: 0.6870563290390282
Epoch: 28 | Iteration number: [3000/4518] 66% | Training loss: 0.6870516001184781
Epoch: 28 | Iteration number: [3010/4518] 66% | Training loss: 0.6870519033302105
Epoch: 28 | Iteration number: [3020/4518] 66% | Training loss: 0.6870548683089136
Epoch: 28 | Iteration number: [3030/4518] 67% | Training loss: 0.6870562771562696
Epoch: 28 | Iteration number: [3040/4518] 67% | Training loss: 0.6870598568924163
Epoch: 28 | Iteration number: [3050/4518] 67% | Training loss: 0.6870607462867362
Epoch: 28 | Iteration number: [3060/4518] 67% | Training loss: 0.6870608586306666
Epoch: 28 | Iteration number: [3070/4518] 67% | Training loss: 0.6870594757193463
Epoch: 28 | Iteration number: [3080/4518] 68% | Training loss: 0.6870585027453188
Epoch: 28 | Iteration number: [3090/4518] 68% | Training loss: 0.6870533507425808
Epoch: 28 | Iteration number: [3100/4518] 68% | Training loss: 0.6870524759446421
Epoch: 28 | Iteration number: [3110/4518] 68% | Training loss: 0.6870505466913487
Epoch: 28 | Iteration number: [3120/4518] 69% | Training loss: 0.6870527579616278
Epoch: 28 | Iteration number: [3130/4518] 69% | Training loss: 0.6870549936264086
Epoch: 28 | Iteration number: [3140/4518] 69% | Training loss: 0.687054114167098
Epoch: 28 | Iteration number: [3150/4518] 69% | Training loss: 0.6870559169186486
Epoch: 28 | Iteration number: [3160/4518] 69% | Training loss: 0.6870586709697035
Epoch: 28 | Iteration number: [3170/4518] 70% | Training loss: 0.6870579460817933
Epoch: 28 | Iteration number: [3180/4518] 70% | Training loss: 0.6870593754750378
Epoch: 28 | Iteration number: [3190/4518] 70% | Training loss: 0.6870589072988325
Epoch: 28 | Iteration number: [3200/4518] 70% | Training loss: 0.6870604512654245
Epoch: 28 | Iteration number: [3210/4518] 71% | Training loss: 0.6870579537944259
Epoch: 28 | Iteration number: [3220/4518] 71% | Training loss: 0.687057658233998
Epoch: 28 | Iteration number: [3230/4518] 71% | Training loss: 0.6870540406681804
Epoch: 28 | Iteration number: [3240/4518] 71% | Training loss: 0.687054640956131
Epoch: 28 | Iteration number: [3250/4518] 71% | Training loss: 0.6870520528096419
Epoch: 28 | Iteration number: [3260/4518] 72% | Training loss: 0.6870529915291839
Epoch: 28 | Iteration number: [3270/4518] 72% | Training loss: 0.6870497368709028
Epoch: 28 | Iteration number: [3280/4518] 72% | Training loss: 0.6870500406114066
Epoch: 28 | Iteration number: [3290/4518] 72% | Training loss: 0.6870501758660952
Epoch: 28 | Iteration number: [3300/4518] 73% | Training loss: 0.6870471730376735
Epoch: 28 | Iteration number: [3310/4518] 73% | Training loss: 0.6870455701365572
Epoch: 28 | Iteration number: [3320/4518] 73% | Training loss: 0.6870462022093405
Epoch: 28 | Iteration number: [3330/4518] 73% | Training loss: 0.6870510674811698
Epoch: 28 | Iteration number: [3340/4518] 73% | Training loss: 0.6870510493745347
Epoch: 28 | Iteration number: [3350/4518] 74% | Training loss: 0.6870522905463603
Epoch: 28 | Iteration number: [3360/4518] 74% | Training loss: 0.6870514232133116
Epoch: 28 | Iteration number: [3370/4518] 74% | Training loss: 0.6870494317053334
Epoch: 28 | Iteration number: [3380/4518] 74% | Training loss: 0.687048178629057
Epoch: 28 | Iteration number: [3390/4518] 75% | Training loss: 0.687045827587094
Epoch: 28 | Iteration number: [3400/4518] 75% | Training loss: 0.6870467756951556
Epoch: 28 | Iteration number: [3410/4518] 75% | Training loss: 0.6870452212448344
Epoch: 28 | Iteration number: [3420/4518] 75% | Training loss: 0.6870420403299276
Epoch: 28 | Iteration number: [3430/4518] 75% | Training loss: 0.6870431208923329
Epoch: 28 | Iteration number: [3440/4518] 76% | Training loss: 0.6870398815114831
Epoch: 28 | Iteration number: [3450/4518] 76% | Training loss: 0.6870418208923893
Epoch: 28 | Iteration number: [3460/4518] 76% | Training loss: 0.6870414439653385
Epoch: 28 | Iteration number: [3470/4518] 76% | Training loss: 0.6870425770365196
Epoch: 28 | Iteration number: [3480/4518] 77% | Training loss: 0.6870415324109724
Epoch: 28 | Iteration number: [3490/4518] 77% | Training loss: 0.6870445642396167
Epoch: 28 | Iteration number: [3500/4518] 77% | Training loss: 0.6870433980907713
Epoch: 28 | Iteration number: [3510/4518] 77% | Training loss: 0.687040475172195
Epoch: 28 | Iteration number: [3520/4518] 77% | Training loss: 0.6870393288745121
Epoch: 28 | Iteration number: [3530/4518] 78% | Training loss: 0.6870392905922854
Epoch: 28 | Iteration number: [3540/4518] 78% | Training loss: 0.6870402661083782
Epoch: 28 | Iteration number: [3550/4518] 78% | Training loss: 0.687038622809128
Epoch: 28 | Iteration number: [3560/4518] 78% | Training loss: 0.6870374011524608
Epoch: 28 | Iteration number: [3570/4518] 79% | Training loss: 0.687036857785297
Epoch: 28 | Iteration number: [3580/4518] 79% | Training loss: 0.68704252647621
Epoch: 28 | Iteration number: [3590/4518] 79% | Training loss: 0.6870436117011525
Epoch: 28 | Iteration number: [3600/4518] 79% | Training loss: 0.6870479752620061
Epoch: 28 | Iteration number: [3610/4518] 79% | Training loss: 0.6870460827760089
Epoch: 28 | Iteration number: [3620/4518] 80% | Training loss: 0.68704694410714
Epoch: 28 | Iteration number: [3630/4518] 80% | Training loss: 0.6870465779107464
Epoch: 28 | Iteration number: [3640/4518] 80% | Training loss: 0.6870450545143295
Epoch: 28 | Iteration number: [3650/4518] 80% | Training loss: 0.6870465564237882
Epoch: 28 | Iteration number: [3660/4518] 81% | Training loss: 0.687047036374853
Epoch: 28 | Iteration number: [3670/4518] 81% | Training loss: 0.6870457012906711
Epoch: 28 | Iteration number: [3680/4518] 81% | Training loss: 0.68704473151137
Epoch: 28 | Iteration number: [3690/4518] 81% | Training loss: 0.6870455120798695
Epoch: 28 | Iteration number: [3700/4518] 81% | Training loss: 0.6870489950115616
Epoch: 28 | Iteration number: [3710/4518] 82% | Training loss: 0.6870460513949073
Epoch: 28 | Iteration number: [3720/4518] 82% | Training loss: 0.6870410208900769
Epoch: 28 | Iteration number: [3730/4518] 82% | Training loss: 0.687038207070118
Epoch: 28 | Iteration number: [3740/4518] 82% | Training loss: 0.6870344928401039
Epoch: 28 | Iteration number: [3750/4518] 83% | Training loss: 0.68703411749204
Epoch: 28 | Iteration number: [3760/4518] 83% | Training loss: 0.6870337977688363
Epoch: 28 | Iteration number: [3770/4518] 83% | Training loss: 0.6870336772434275
Epoch: 28 | Iteration number: [3780/4518] 83% | Training loss: 0.6870345777462399
Epoch: 28 | Iteration number: [3790/4518] 83% | Training loss: 0.6870318448480641
Epoch: 28 | Iteration number: [3800/4518] 84% | Training loss: 0.6870293891900464
Epoch: 28 | Iteration number: [3810/4518] 84% | Training loss: 0.6870288790680292
Epoch: 28 | Iteration number: [3820/4518] 84% | Training loss: 0.6870277069157955
Epoch: 28 | Iteration number: [3830/4518] 84% | Training loss: 0.6870259528838624
Epoch: 28 | Iteration number: [3840/4518] 84% | Training loss: 0.6870246141838531
Epoch: 28 | Iteration number: [3850/4518] 85% | Training loss: 0.6870271119668886
Epoch: 28 | Iteration number: [3860/4518] 85% | Training loss: 0.6870213579482983
Epoch: 28 | Iteration number: [3870/4518] 85% | Training loss: 0.6870191387735904
Epoch: 28 | Iteration number: [3880/4518] 85% | Training loss: 0.6870185223897708
Epoch: 28 | Iteration number: [3890/4518] 86% | Training loss: 0.6870189380982847
Epoch: 28 | Iteration number: [3900/4518] 86% | Training loss: 0.6870213562402969
Epoch: 28 | Iteration number: [3910/4518] 86% | Training loss: 0.6870174745921893
Epoch: 28 | Iteration number: [3920/4518] 86% | Training loss: 0.6870174654284302
Epoch: 28 | Iteration number: [3930/4518] 86% | Training loss: 0.6870191314748225
Epoch: 28 | Iteration number: [3940/4518] 87% | Training loss: 0.6870203462046415
Epoch: 28 | Iteration number: [3950/4518] 87% | Training loss: 0.687013777735867
Epoch: 28 | Iteration number: [3960/4518] 87% | Training loss: 0.6870144921119767
Epoch: 28 | Iteration number: [3970/4518] 87% | Training loss: 0.6870144513602221
Epoch: 28 | Iteration number: [3980/4518] 88% | Training loss: 0.6870121063599035
Epoch: 28 | Iteration number: [3990/4518] 88% | Training loss: 0.6870112810816084
Epoch: 28 | Iteration number: [4000/4518] 88% | Training loss: 0.6870129157304764
Epoch: 28 | Iteration number: [4010/4518] 88% | Training loss: 0.6870132564011951
Epoch: 28 | Iteration number: [4020/4518] 88% | Training loss: 0.6870088871735246
Epoch: 28 | Iteration number: [4030/4518] 89% | Training loss: 0.6870059583678139
Epoch: 28 | Iteration number: [4040/4518] 89% | Training loss: 0.6870046124157339
Epoch: 28 | Iteration number: [4050/4518] 89% | Training loss: 0.6870050911697341
Epoch: 28 | Iteration number: [4060/4518] 89% | Training loss: 0.687009000000108
Epoch: 28 | Iteration number: [4070/4518] 90% | Training loss: 0.6870094284378633
Epoch: 28 | Iteration number: [4080/4518] 90% | Training loss: 0.6870117128625804
Epoch: 28 | Iteration number: [4090/4518] 90% | Training loss: 0.6870082928090924
Epoch: 28 | Iteration number: [4100/4518] 90% | Training loss: 0.68700916610113
Epoch: 28 | Iteration number: [4110/4518] 90% | Training loss: 0.687008503942304
Epoch: 28 | Iteration number: [4120/4518] 91% | Training loss: 0.687007996758211
Epoch: 28 | Iteration number: [4130/4518] 91% | Training loss: 0.6870070281530986
Epoch: 28 | Iteration number: [4140/4518] 91% | Training loss: 0.6870063071953502
Epoch: 28 | Iteration number: [4150/4518] 91% | Training loss: 0.6870041442204671
Epoch: 28 | Iteration number: [4160/4518] 92% | Training loss: 0.6870048843754025
Epoch: 28 | Iteration number: [4170/4518] 92% | Training loss: 0.6870059742916116
Epoch: 28 | Iteration number: [4180/4518] 92% | Training loss: 0.6870039379482634
Epoch: 28 | Iteration number: [4190/4518] 92% | Training loss: 0.6870045628069693
Epoch: 28 | Iteration number: [4200/4518] 92% | Training loss: 0.6870056104518119
Epoch: 28 | Iteration number: [4210/4518] 93% | Training loss: 0.6870087779049635
Epoch: 28 | Iteration number: [4220/4518] 93% | Training loss: 0.6870111213193686
Epoch: 28 | Iteration number: [4230/4518] 93% | Training loss: 0.6870103430381621
Epoch: 28 | Iteration number: [4240/4518] 93% | Training loss: 0.6870104192562823
Epoch: 28 | Iteration number: [4250/4518] 94% | Training loss: 0.6870116004663355
Epoch: 28 | Iteration number: [4260/4518] 94% | Training loss: 0.6870116238722779
Epoch: 28 | Iteration number: [4270/4518] 94% | Training loss: 0.68701408476126
Epoch: 28 | Iteration number: [4280/4518] 94% | Training loss: 0.6870112655040259
Epoch: 28 | Iteration number: [4290/4518] 94% | Training loss: 0.6870108899119851
Epoch: 28 | Iteration number: [4300/4518] 95% | Training loss: 0.687007869953333
Epoch: 28 | Iteration number: [4310/4518] 95% | Training loss: 0.6870085541305851
Epoch: 28 | Iteration number: [4320/4518] 95% | Training loss: 0.6870108379947918
Epoch: 28 | Iteration number: [4330/4518] 95% | Training loss: 0.6870101667716927
Epoch: 28 | Iteration number: [4340/4518] 96% | Training loss: 0.6870119579102038
Epoch: 28 | Iteration number: [4350/4518] 96% | Training loss: 0.6870133889680621
Epoch: 28 | Iteration number: [4360/4518] 96% | Training loss: 0.6870154867205052
Epoch: 28 | Iteration number: [4370/4518] 96% | Training loss: 0.687017069637639
Epoch: 28 | Iteration number: [4380/4518] 96% | Training loss: 0.6870156978091149
Epoch: 28 | Iteration number: [4390/4518] 97% | Training loss: 0.6870136970811118
Epoch: 28 | Iteration number: [4400/4518] 97% | Training loss: 0.6870122162455862
Epoch: 28 | Iteration number: [4410/4518] 97% | Training loss: 0.6870133645004697
Epoch: 28 | Iteration number: [4420/4518] 97% | Training loss: 0.6870130364306911
Epoch: 28 | Iteration number: [4430/4518] 98% | Training loss: 0.6870129875081925
Epoch: 28 | Iteration number: [4440/4518] 98% | Training loss: 0.6870130004109563
Epoch: 28 | Iteration number: [4450/4518] 98% | Training loss: 0.6870103021284167
Epoch: 28 | Iteration number: [4460/4518] 98% | Training loss: 0.6870093797220778
Epoch: 28 | Iteration number: [4470/4518] 98% | Training loss: 0.6870094957100998
Epoch: 28 | Iteration number: [4480/4518] 99% | Training loss: 0.6870108533384545
Epoch: 28 | Iteration number: [4490/4518] 99% | Training loss: 0.6870140563671733
Epoch: 28 | Iteration number: [4500/4518] 99% | Training loss: 0.6870158760680093
Epoch: 28 | Iteration number: [4510/4518] 99% | Training loss: 0.6870171934167985

 End of epoch: 28 | Train Loss: 0.6868653379746801 | Training Time: 644 

 End of epoch: 28 | Eval Loss: 0.6902615999688908 | Evaluating Time: 17 
Epoch: 29 | Iteration number: [10/4518] 0% | Training loss: 0.7558779239654541
Epoch: 29 | Iteration number: [20/4518] 0% | Training loss: 0.7217580825090408
Epoch: 29 | Iteration number: [30/4518] 0% | Training loss: 0.710215683778127
Epoch: 29 | Iteration number: [40/4518] 0% | Training loss: 0.704311092197895
Epoch: 29 | Iteration number: [50/4518] 1% | Training loss: 0.7008497488498687
Epoch: 29 | Iteration number: [60/4518] 1% | Training loss: 0.6985655625661215
Epoch: 29 | Iteration number: [70/4518] 1% | Training loss: 0.6968334189483097
Epoch: 29 | Iteration number: [80/4518] 1% | Training loss: 0.6956513017416001
Epoch: 29 | Iteration number: [90/4518] 1% | Training loss: 0.694696001874076
Epoch: 29 | Iteration number: [100/4518] 2% | Training loss: 0.693878891468048
Epoch: 29 | Iteration number: [110/4518] 2% | Training loss: 0.6933220332319087
Epoch: 29 | Iteration number: [120/4518] 2% | Training loss: 0.6927791640162468
Epoch: 29 | Iteration number: [130/4518] 2% | Training loss: 0.6923009954966032
Epoch: 29 | Iteration number: [140/4518] 3% | Training loss: 0.6919620807681764
Epoch: 29 | Iteration number: [150/4518] 3% | Training loss: 0.6916475240389506
Epoch: 29 | Iteration number: [160/4518] 3% | Training loss: 0.6913817461580039
Epoch: 29 | Iteration number: [170/4518] 3% | Training loss: 0.691153776996276
Epoch: 29 | Iteration number: [180/4518] 3% | Training loss: 0.6909662905666564
Epoch: 29 | Iteration number: [190/4518] 4% | Training loss: 0.6907834598892614
Epoch: 29 | Iteration number: [200/4518] 4% | Training loss: 0.690619165301323
Epoch: 29 | Iteration number: [210/4518] 4% | Training loss: 0.6904050248009818
Epoch: 29 | Iteration number: [220/4518] 4% | Training loss: 0.6902660567652096
Epoch: 29 | Iteration number: [230/4518] 5% | Training loss: 0.6901047061318937
Epoch: 29 | Iteration number: [240/4518] 5% | Training loss: 0.6899720186988513
Epoch: 29 | Iteration number: [250/4518] 5% | Training loss: 0.689839156627655
Epoch: 29 | Iteration number: [260/4518] 5% | Training loss: 0.6897298805988752
Epoch: 29 | Iteration number: [270/4518] 5% | Training loss: 0.6896102746327718
Epoch: 29 | Iteration number: [280/4518] 6% | Training loss: 0.6895183122583798
Epoch: 29 | Iteration number: [290/4518] 6% | Training loss: 0.6893923923887055
Epoch: 29 | Iteration number: [300/4518] 6% | Training loss: 0.6893004198869069
Epoch: 29 | Iteration number: [310/4518] 6% | Training loss: 0.6892137567843161
Epoch: 29 | Iteration number: [320/4518] 7% | Training loss: 0.6890908820554614
Epoch: 29 | Iteration number: [330/4518] 7% | Training loss: 0.6890603506203854
Epoch: 29 | Iteration number: [340/4518] 7% | Training loss: 0.6890273399212781
Epoch: 29 | Iteration number: [350/4518] 7% | Training loss: 0.6889816725254059
Epoch: 29 | Iteration number: [360/4518] 7% | Training loss: 0.6889162363277541
Epoch: 29 | Iteration number: [370/4518] 8% | Training loss: 0.6888386136776692
Epoch: 29 | Iteration number: [380/4518] 8% | Training loss: 0.6887865664143311
Epoch: 29 | Iteration number: [390/4518] 8% | Training loss: 0.688728129863739
Epoch: 29 | Iteration number: [400/4518] 8% | Training loss: 0.6886935959756374
Epoch: 29 | Iteration number: [410/4518] 9% | Training loss: 0.6886649075077801
Epoch: 29 | Iteration number: [420/4518] 9% | Training loss: 0.6886305881398065
Epoch: 29 | Iteration number: [430/4518] 9% | Training loss: 0.6885927345863608
Epoch: 29 | Iteration number: [440/4518] 9% | Training loss: 0.6885737866163254
Epoch: 29 | Iteration number: [450/4518] 9% | Training loss: 0.6885238866011302
Epoch: 29 | Iteration number: [460/4518] 10% | Training loss: 0.6884803822507028
Epoch: 29 | Iteration number: [470/4518] 10% | Training loss: 0.6884317920563069
Epoch: 29 | Iteration number: [480/4518] 10% | Training loss: 0.6884072681268056
Epoch: 29 | Iteration number: [490/4518] 10% | Training loss: 0.6883971805475196
Epoch: 29 | Iteration number: [500/4518] 11% | Training loss: 0.6883637059926987
Epoch: 29 | Iteration number: [510/4518] 11% | Training loss: 0.6883378494019602
Epoch: 29 | Iteration number: [520/4518] 11% | Training loss: 0.688308166884459
Epoch: 29 | Iteration number: [530/4518] 11% | Training loss: 0.6882822961177466
Epoch: 29 | Iteration number: [540/4518] 11% | Training loss: 0.6882688611745834
Epoch: 29 | Iteration number: [550/4518] 12% | Training loss: 0.6882621455192566
Epoch: 29 | Iteration number: [560/4518] 12% | Training loss: 0.6882315750632967
Epoch: 29 | Iteration number: [570/4518] 12% | Training loss: 0.6881964837249956
Epoch: 29 | Iteration number: [580/4518] 12% | Training loss: 0.6881666599676527
Epoch: 29 | Iteration number: [590/4518] 13% | Training loss: 0.6881526215601775
Epoch: 29 | Iteration number: [600/4518] 13% | Training loss: 0.6881308863560359
Epoch: 29 | Iteration number: [610/4518] 13% | Training loss: 0.6881078020471041
Epoch: 29 | Iteration number: [620/4518] 13% | Training loss: 0.6881055842484197
Epoch: 29 | Iteration number: [630/4518] 13% | Training loss: 0.6880734120096479
Epoch: 29 | Iteration number: [640/4518] 14% | Training loss: 0.6880645762197674
Epoch: 29 | Iteration number: [650/4518] 14% | Training loss: 0.6880462385140933
Epoch: 29 | Iteration number: [660/4518] 14% | Training loss: 0.6880162116253015
Epoch: 29 | Iteration number: [670/4518] 14% | Training loss: 0.68800246688857
Epoch: 29 | Iteration number: [680/4518] 15% | Training loss: 0.6879869538194993
Epoch: 29 | Iteration number: [690/4518] 15% | Training loss: 0.687992409001226
Epoch: 29 | Iteration number: [700/4518] 15% | Training loss: 0.6879790791443416
Epoch: 29 | Iteration number: [710/4518] 15% | Training loss: 0.687967685326724
Epoch: 29 | Iteration number: [720/4518] 15% | Training loss: 0.6879411742919022
Epoch: 29 | Iteration number: [730/4518] 16% | Training loss: 0.687938992454581
Epoch: 29 | Iteration number: [740/4518] 16% | Training loss: 0.6879217311337188
Epoch: 29 | Iteration number: [750/4518] 16% | Training loss: 0.6879206850528717
Epoch: 29 | Iteration number: [760/4518] 16% | Training loss: 0.6878940630900232
Epoch: 29 | Iteration number: [770/4518] 17% | Training loss: 0.6878838746578663
Epoch: 29 | Iteration number: [780/4518] 17% | Training loss: 0.6878627767929664
Epoch: 29 | Iteration number: [790/4518] 17% | Training loss: 0.6878508021559896
Epoch: 29 | Iteration number: [800/4518] 17% | Training loss: 0.6878177601099015
Epoch: 29 | Iteration number: [810/4518] 17% | Training loss: 0.6878230274459463
Epoch: 29 | Iteration number: [820/4518] 18% | Training loss: 0.6878169516964656
Epoch: 29 | Iteration number: [830/4518] 18% | Training loss: 0.6877966782414769
Epoch: 29 | Iteration number: [840/4518] 18% | Training loss: 0.6877871108906609
Epoch: 29 | Iteration number: [850/4518] 18% | Training loss: 0.6877661759011886
Epoch: 29 | Iteration number: [860/4518] 19% | Training loss: 0.6877626121044159
Epoch: 29 | Iteration number: [870/4518] 19% | Training loss: 0.6877518217454012
Epoch: 29 | Iteration number: [880/4518] 19% | Training loss: 0.6877487634393302
Epoch: 29 | Iteration number: [890/4518] 19% | Training loss: 0.687746948405598
Epoch: 29 | Iteration number: [900/4518] 19% | Training loss: 0.687732642226749
Epoch: 29 | Iteration number: [910/4518] 20% | Training loss: 0.6877158423046489
Epoch: 29 | Iteration number: [920/4518] 20% | Training loss: 0.6876960016463114
Epoch: 29 | Iteration number: [930/4518] 20% | Training loss: 0.6876958020271794
Epoch: 29 | Iteration number: [940/4518] 20% | Training loss: 0.6876843498742327
Epoch: 29 | Iteration number: [950/4518] 21% | Training loss: 0.6876706919544622
Epoch: 29 | Iteration number: [960/4518] 21% | Training loss: 0.6876695982490977
Epoch: 29 | Iteration number: [970/4518] 21% | Training loss: 0.6876635097965752
Epoch: 29 | Iteration number: [980/4518] 21% | Training loss: 0.6876543480522779
Epoch: 29 | Iteration number: [990/4518] 21% | Training loss: 0.6876394754708416
Epoch: 29 | Iteration number: [1000/4518] 22% | Training loss: 0.687639575958252
Epoch: 29 | Iteration number: [1010/4518] 22% | Training loss: 0.6876509433925742
Epoch: 29 | Iteration number: [1020/4518] 22% | Training loss: 0.6876558988702064
Epoch: 29 | Iteration number: [1030/4518] 22% | Training loss: 0.6876587184887488
Epoch: 29 | Iteration number: [1040/4518] 23% | Training loss: 0.6876463965727733
Epoch: 29 | Iteration number: [1050/4518] 23% | Training loss: 0.6876380141008468
Epoch: 29 | Iteration number: [1060/4518] 23% | Training loss: 0.6876366748562399
Epoch: 29 | Iteration number: [1070/4518] 23% | Training loss: 0.6876365950174421
Epoch: 29 | Iteration number: [1080/4518] 23% | Training loss: 0.6876360711676103
Epoch: 29 | Iteration number: [1090/4518] 24% | Training loss: 0.6876205401683072
Epoch: 29 | Iteration number: [1100/4518] 24% | Training loss: 0.6876290693066337
Epoch: 29 | Iteration number: [1110/4518] 24% | Training loss: 0.687626658849888
Epoch: 29 | Iteration number: [1120/4518] 24% | Training loss: 0.6876197950116225
Epoch: 29 | Iteration number: [1130/4518] 25% | Training loss: 0.6876017731902874
Epoch: 29 | Iteration number: [1140/4518] 25% | Training loss: 0.6875881625372067
Epoch: 29 | Iteration number: [1150/4518] 25% | Training loss: 0.6875780444041543
Epoch: 29 | Iteration number: [1160/4518] 25% | Training loss: 0.6875673001696323
Epoch: 29 | Iteration number: [1170/4518] 25% | Training loss: 0.6875659861116328
Epoch: 29 | Iteration number: [1180/4518] 26% | Training loss: 0.6875693785942207
Epoch: 29 | Iteration number: [1190/4518] 26% | Training loss: 0.6875619195589499
Epoch: 29 | Iteration number: [1200/4518] 26% | Training loss: 0.6875581469635169
Epoch: 29 | Iteration number: [1210/4518] 26% | Training loss: 0.6875543877112964
Epoch: 29 | Iteration number: [1220/4518] 27% | Training loss: 0.6875365954442102
Epoch: 29 | Iteration number: [1230/4518] 27% | Training loss: 0.6875350266452728
Epoch: 29 | Iteration number: [1240/4518] 27% | Training loss: 0.6875311861115118
Epoch: 29 | Iteration number: [1250/4518] 27% | Training loss: 0.6875208249092102
Epoch: 29 | Iteration number: [1260/4518] 27% | Training loss: 0.6875120486058887
Epoch: 29 | Iteration number: [1270/4518] 28% | Training loss: 0.6875026569122404
Epoch: 29 | Iteration number: [1280/4518] 28% | Training loss: 0.6875078001059591
Epoch: 29 | Iteration number: [1290/4518] 28% | Training loss: 0.6875064573084662
Epoch: 29 | Iteration number: [1300/4518] 28% | Training loss: 0.6875007238296362
Epoch: 29 | Iteration number: [1310/4518] 28% | Training loss: 0.6874770988489836
Epoch: 29 | Iteration number: [1320/4518] 29% | Training loss: 0.687467010319233
Epoch: 29 | Iteration number: [1330/4518] 29% | Training loss: 0.6874549863930035
Epoch: 29 | Iteration number: [1340/4518] 29% | Training loss: 0.687457554153542
Epoch: 29 | Iteration number: [1350/4518] 29% | Training loss: 0.6874481618404389
Epoch: 29 | Iteration number: [1360/4518] 30% | Training loss: 0.6874398815281251
Epoch: 29 | Iteration number: [1370/4518] 30% | Training loss: 0.6874336587686608
Epoch: 29 | Iteration number: [1380/4518] 30% | Training loss: 0.6874309680168179
Epoch: 29 | Iteration number: [1390/4518] 30% | Training loss: 0.6874338942037211
Epoch: 29 | Iteration number: [1400/4518] 30% | Training loss: 0.687430660043444
Epoch: 29 | Iteration number: [1410/4518] 31% | Training loss: 0.6874346163678676
Epoch: 29 | Iteration number: [1420/4518] 31% | Training loss: 0.6874308357776051
Epoch: 29 | Iteration number: [1430/4518] 31% | Training loss: 0.687432634622067
Epoch: 29 | Iteration number: [1440/4518] 31% | Training loss: 0.6874333669741949
Epoch: 29 | Iteration number: [1450/4518] 32% | Training loss: 0.6874311703237994
Epoch: 29 | Iteration number: [1460/4518] 32% | Training loss: 0.6874312967470247
Epoch: 29 | Iteration number: [1470/4518] 32% | Training loss: 0.6874224247575618
Epoch: 29 | Iteration number: [1480/4518] 32% | Training loss: 0.6874211607752619
Epoch: 29 | Iteration number: [1490/4518] 32% | Training loss: 0.6874258027780776
Epoch: 29 | Iteration number: [1500/4518] 33% | Training loss: 0.6874200463692347
Epoch: 29 | Iteration number: [1510/4518] 33% | Training loss: 0.6874184962140014
Epoch: 29 | Iteration number: [1520/4518] 33% | Training loss: 0.6874138953262254
Epoch: 29 | Iteration number: [1530/4518] 33% | Training loss: 0.6874085820188709
Epoch: 29 | Iteration number: [1540/4518] 34% | Training loss: 0.6874059771562552
Epoch: 29 | Iteration number: [1550/4518] 34% | Training loss: 0.687400726849033
Epoch: 29 | Iteration number: [1560/4518] 34% | Training loss: 0.6874012470627442
Epoch: 29 | Iteration number: [1570/4518] 34% | Training loss: 0.6874041022009151
Epoch: 29 | Iteration number: [1580/4518] 34% | Training loss: 0.6873994383253629
Epoch: 29 | Iteration number: [1590/4518] 35% | Training loss: 0.6873991594374554
Epoch: 29 | Iteration number: [1600/4518] 35% | Training loss: 0.6874022129550577
Epoch: 29 | Iteration number: [1610/4518] 35% | Training loss: 0.68739405611287
Epoch: 29 | Iteration number: [1620/4518] 35% | Training loss: 0.6873924136897664
Epoch: 29 | Iteration number: [1630/4518] 36% | Training loss: 0.687384336601737
Epoch: 29 | Iteration number: [1640/4518] 36% | Training loss: 0.6873824472834424
Epoch: 29 | Iteration number: [1650/4518] 36% | Training loss: 0.687371650428483
Epoch: 29 | Iteration number: [1660/4518] 36% | Training loss: 0.6873675489641098
Epoch: 29 | Iteration number: [1670/4518] 36% | Training loss: 0.6873640195338312
Epoch: 29 | Iteration number: [1680/4518] 37% | Training loss: 0.6873576792223113
Epoch: 29 | Iteration number: [1690/4518] 37% | Training loss: 0.6873524502536954
Epoch: 29 | Iteration number: [1700/4518] 37% | Training loss: 0.6873489816048566
Epoch: 29 | Iteration number: [1710/4518] 37% | Training loss: 0.6873476419881074
Epoch: 29 | Iteration number: [1720/4518] 38% | Training loss: 0.6873447609848754
Epoch: 29 | Iteration number: [1730/4518] 38% | Training loss: 0.6873344070305025
Epoch: 29 | Iteration number: [1740/4518] 38% | Training loss: 0.6873299688443371
Epoch: 29 | Iteration number: [1750/4518] 38% | Training loss: 0.6873305315971374
Epoch: 29 | Iteration number: [1760/4518] 38% | Training loss: 0.6873281075195833
Epoch: 29 | Iteration number: [1770/4518] 39% | Training loss: 0.6873322148107539
Epoch: 29 | Iteration number: [1780/4518] 39% | Training loss: 0.6873291873530055
Epoch: 29 | Iteration number: [1790/4518] 39% | Training loss: 0.6873297304747491
Epoch: 29 | Iteration number: [1800/4518] 39% | Training loss: 0.6873271659678883
Epoch: 29 | Iteration number: [1810/4518] 40% | Training loss: 0.6873213241442792
Epoch: 29 | Iteration number: [1820/4518] 40% | Training loss: 0.6873175695702269
Epoch: 29 | Iteration number: [1830/4518] 40% | Training loss: 0.6873154502097375
Epoch: 29 | Iteration number: [1840/4518] 40% | Training loss: 0.6873171077150365
Epoch: 29 | Iteration number: [1850/4518] 40% | Training loss: 0.6873129513134828
Epoch: 29 | Iteration number: [1860/4518] 41% | Training loss: 0.6873150501199948
Epoch: 29 | Iteration number: [1870/4518] 41% | Training loss: 0.6873139639270497
Epoch: 29 | Iteration number: [1880/4518] 41% | Training loss: 0.687310621174092
Epoch: 29 | Iteration number: [1890/4518] 41% | Training loss: 0.6873055723609117
Epoch: 29 | Iteration number: [1900/4518] 42% | Training loss: 0.6873036376739803
Epoch: 29 | Iteration number: [1910/4518] 42% | Training loss: 0.6872984510753791
Epoch: 29 | Iteration number: [1920/4518] 42% | Training loss: 0.6872904443182051
Epoch: 29 | Iteration number: [1930/4518] 42% | Training loss: 0.6872888146904466
Epoch: 29 | Iteration number: [1940/4518] 42% | Training loss: 0.6872955908480379
Epoch: 29 | Iteration number: [1950/4518] 43% | Training loss: 0.6872956190353785
Epoch: 29 | Iteration number: [1960/4518] 43% | Training loss: 0.6872921430030647
Epoch: 29 | Iteration number: [1970/4518] 43% | Training loss: 0.6872877607793372
Epoch: 29 | Iteration number: [1980/4518] 43% | Training loss: 0.6872802426718703
Epoch: 29 | Iteration number: [1990/4518] 44% | Training loss: 0.6872763203915639
Epoch: 29 | Iteration number: [2000/4518] 44% | Training loss: 0.6872698969244957
Epoch: 29 | Iteration number: [2010/4518] 44% | Training loss: 0.6872706859859068
Epoch: 29 | Iteration number: [2020/4518] 44% | Training loss: 0.6872649774693026
Epoch: 29 | Iteration number: [2030/4518] 44% | Training loss: 0.6872644979671891
Epoch: 29 | Iteration number: [2040/4518] 45% | Training loss: 0.6872560180577577
Epoch: 29 | Iteration number: [2050/4518] 45% | Training loss: 0.6872530156519355
Epoch: 29 | Iteration number: [2060/4518] 45% | Training loss: 0.6872540417226772
Epoch: 29 | Iteration number: [2070/4518] 45% | Training loss: 0.687256758051794
Epoch: 29 | Iteration number: [2080/4518] 46% | Training loss: 0.6872519907756494
Epoch: 29 | Iteration number: [2090/4518] 46% | Training loss: 0.6872536921615235
Epoch: 29 | Iteration number: [2100/4518] 46% | Training loss: 0.6872538713046482
Epoch: 29 | Iteration number: [2110/4518] 46% | Training loss: 0.6872543949651492
Epoch: 29 | Iteration number: [2120/4518] 46% | Training loss: 0.6872585182763495
Epoch: 29 | Iteration number: [2130/4518] 47% | Training loss: 0.6872571955544288
Epoch: 29 | Iteration number: [2140/4518] 47% | Training loss: 0.6872558311045727
Epoch: 29 | Iteration number: [2150/4518] 47% | Training loss: 0.6872499383327573
Epoch: 29 | Iteration number: [2160/4518] 47% | Training loss: 0.6872489527419762
Epoch: 29 | Iteration number: [2170/4518] 48% | Training loss: 0.6872467585697701
Epoch: 29 | Iteration number: [2180/4518] 48% | Training loss: 0.687248311567744
Epoch: 29 | Iteration number: [2190/4518] 48% | Training loss: 0.6872506983203975
Epoch: 29 | Iteration number: [2200/4518] 48% | Training loss: 0.6872498421235518
Epoch: 29 | Iteration number: [2210/4518] 48% | Training loss: 0.6872521233774418
Epoch: 29 | Iteration number: [2220/4518] 49% | Training loss: 0.6872456252037942
Epoch: 29 | Iteration number: [2230/4518] 49% | Training loss: 0.6872438233529505
Epoch: 29 | Iteration number: [2240/4518] 49% | Training loss: 0.687245048848646
Epoch: 29 | Iteration number: [2250/4518] 49% | Training loss: 0.6872388225131565
Epoch: 29 | Iteration number: [2260/4518] 50% | Training loss: 0.6872464025970054
Epoch: 29 | Iteration number: [2270/4518] 50% | Training loss: 0.6872466723299236
Epoch: 29 | Iteration number: [2280/4518] 50% | Training loss: 0.687251417730984
Epoch: 29 | Iteration number: [2290/4518] 50% | Training loss: 0.687248810071612
Epoch: 29 | Iteration number: [2300/4518] 50% | Training loss: 0.6872446881169858
Epoch: 29 | Iteration number: [2310/4518] 51% | Training loss: 0.6872427887988813
Epoch: 29 | Iteration number: [2320/4518] 51% | Training loss: 0.6872387771976405
Epoch: 29 | Iteration number: [2330/4518] 51% | Training loss: 0.6872306617032816
Epoch: 29 | Iteration number: [2340/4518] 51% | Training loss: 0.6872300165840703
Epoch: 29 | Iteration number: [2350/4518] 52% | Training loss: 0.6872280248428912
Epoch: 29 | Iteration number: [2360/4518] 52% | Training loss: 0.6872232977364023
Epoch: 29 | Iteration number: [2370/4518] 52% | Training loss: 0.6872238251227367
Epoch: 29 | Iteration number: [2380/4518] 52% | Training loss: 0.6872135521233582
Epoch: 29 | Iteration number: [2390/4518] 52% | Training loss: 0.6872102814987614
Epoch: 29 | Iteration number: [2400/4518] 53% | Training loss: 0.6872073988119761
Epoch: 29 | Iteration number: [2410/4518] 53% | Training loss: 0.6872051556328026
Epoch: 29 | Iteration number: [2420/4518] 53% | Training loss: 0.6872041762860354
Epoch: 29 | Iteration number: [2430/4518] 53% | Training loss: 0.6872004988998052
Epoch: 29 | Iteration number: [2440/4518] 54% | Training loss: 0.6871982465757698
Epoch: 29 | Iteration number: [2450/4518] 54% | Training loss: 0.6872003797852263
Epoch: 29 | Iteration number: [2460/4518] 54% | Training loss: 0.6871969170202085
Epoch: 29 | Iteration number: [2470/4518] 54% | Training loss: 0.6872013711494955
Epoch: 29 | Iteration number: [2480/4518] 54% | Training loss: 0.6871982884022497
Epoch: 29 | Iteration number: [2490/4518] 55% | Training loss: 0.6871939004425064
Epoch: 29 | Iteration number: [2500/4518] 55% | Training loss: 0.6871866056442261
Epoch: 29 | Iteration number: [2510/4518] 55% | Training loss: 0.6871848062452567
Epoch: 29 | Iteration number: [2520/4518] 55% | Training loss: 0.6871830171062833
Epoch: 29 | Iteration number: [2530/4518] 55% | Training loss: 0.6871787172296773
Epoch: 29 | Iteration number: [2540/4518] 56% | Training loss: 0.6871791371679682
Epoch: 29 | Iteration number: [2550/4518] 56% | Training loss: 0.6871743730236503
Epoch: 29 | Iteration number: [2560/4518] 56% | Training loss: 0.6871743773575872
Epoch: 29 | Iteration number: [2570/4518] 56% | Training loss: 0.6871743039862191
Epoch: 29 | Iteration number: [2580/4518] 57% | Training loss: 0.6871688258278278
Epoch: 29 | Iteration number: [2590/4518] 57% | Training loss: 0.6871697957451279
Epoch: 29 | Iteration number: [2600/4518] 57% | Training loss: 0.6871722151682927
Epoch: 29 | Iteration number: [2610/4518] 57% | Training loss: 0.6871766278570183
Epoch: 29 | Iteration number: [2620/4518] 57% | Training loss: 0.6871738793740746
Epoch: 29 | Iteration number: [2630/4518] 58% | Training loss: 0.6871706133786263
Epoch: 29 | Iteration number: [2640/4518] 58% | Training loss: 0.6871611301420313
Epoch: 29 | Iteration number: [2650/4518] 58% | Training loss: 0.6871574051425142
Epoch: 29 | Iteration number: [2660/4518] 58% | Training loss: 0.687157920316646
Epoch: 29 | Iteration number: [2670/4518] 59% | Training loss: 0.6871585018849105
Epoch: 29 | Iteration number: [2680/4518] 59% | Training loss: 0.6871627983984663
Epoch: 29 | Iteration number: [2690/4518] 59% | Training loss: 0.6871642470359802
Epoch: 29 | Iteration number: [2700/4518] 59% | Training loss: 0.6871666498758174
Epoch: 29 | Iteration number: [2710/4518] 59% | Training loss: 0.6871675111710805
Epoch: 29 | Iteration number: [2720/4518] 60% | Training loss: 0.6871595400659477
Epoch: 29 | Iteration number: [2730/4518] 60% | Training loss: 0.6871601486162389
Epoch: 29 | Iteration number: [2740/4518] 60% | Training loss: 0.687159760372482
Epoch: 29 | Iteration number: [2750/4518] 60% | Training loss: 0.6871575151573528
Epoch: 29 | Iteration number: [2760/4518] 61% | Training loss: 0.6871625619306081
Epoch: 29 | Iteration number: [2770/4518] 61% | Training loss: 0.6871605334729494
Epoch: 29 | Iteration number: [2780/4518] 61% | Training loss: 0.6871583857982279
Epoch: 29 | Iteration number: [2790/4518] 61% | Training loss: 0.687149633493902
Epoch: 29 | Iteration number: [2800/4518] 61% | Training loss: 0.6871486834755965
Epoch: 29 | Iteration number: [2810/4518] 62% | Training loss: 0.6871482394556134
Epoch: 29 | Iteration number: [2820/4518] 62% | Training loss: 0.6871509029510173
Epoch: 29 | Iteration number: [2830/4518] 62% | Training loss: 0.6871512645967436
Epoch: 29 | Iteration number: [2840/4518] 62% | Training loss: 0.6871495247936584
Epoch: 29 | Iteration number: [2850/4518] 63% | Training loss: 0.6871461699720015
Epoch: 29 | Iteration number: [2860/4518] 63% | Training loss: 0.6871434711909794
Epoch: 29 | Iteration number: [2870/4518] 63% | Training loss: 0.6871415045618595
Epoch: 29 | Iteration number: [2880/4518] 63% | Training loss: 0.6871382722424136
Epoch: 29 | Iteration number: [2890/4518] 63% | Training loss: 0.687132834480708
Epoch: 29 | Iteration number: [2900/4518] 64% | Training loss: 0.6871308579527099
Epoch: 29 | Iteration number: [2910/4518] 64% | Training loss: 0.6871239207454564
Epoch: 29 | Iteration number: [2920/4518] 64% | Training loss: 0.6871226684483763
Epoch: 29 | Iteration number: [2930/4518] 64% | Training loss: 0.6871151823029177
Epoch: 29 | Iteration number: [2940/4518] 65% | Training loss: 0.6871175404308605
Epoch: 29 | Iteration number: [2950/4518] 65% | Training loss: 0.6871141574342372
Epoch: 29 | Iteration number: [2960/4518] 65% | Training loss: 0.6871101610765263
Epoch: 29 | Iteration number: [2970/4518] 65% | Training loss: 0.6871098303232932
Epoch: 29 | Iteration number: [2980/4518] 65% | Training loss: 0.6871100862154225
Epoch: 29 | Iteration number: [2990/4518] 66% | Training loss: 0.687111636866694
Epoch: 29 | Iteration number: [3000/4518] 66% | Training loss: 0.6871059395273527
Epoch: 29 | Iteration number: [3010/4518] 66% | Training loss: 0.6871066435626971
Epoch: 29 | Iteration number: [3020/4518] 66% | Training loss: 0.6871041253899897
Epoch: 29 | Iteration number: [3030/4518] 67% | Training loss: 0.6871010657584313
Epoch: 29 | Iteration number: [3040/4518] 67% | Training loss: 0.6871002942911888
Epoch: 29 | Iteration number: [3050/4518] 67% | Training loss: 0.6870924187097394
Epoch: 29 | Iteration number: [3060/4518] 67% | Training loss: 0.6870923316361858
Epoch: 29 | Iteration number: [3070/4518] 67% | Training loss: 0.6870916190675493
Epoch: 29 | Iteration number: [3080/4518] 68% | Training loss: 0.6870891044085676
Epoch: 29 | Iteration number: [3090/4518] 68% | Training loss: 0.6870899288013915
Epoch: 29 | Iteration number: [3100/4518] 68% | Training loss: 0.6870884704205298
Epoch: 29 | Iteration number: [3110/4518] 68% | Training loss: 0.6870902149431959
Epoch: 29 | Iteration number: [3120/4518] 69% | Training loss: 0.6870846233688868
Epoch: 29 | Iteration number: [3130/4518] 69% | Training loss: 0.6870900934496627
Epoch: 29 | Iteration number: [3140/4518] 69% | Training loss: 0.6870899916264661
Epoch: 29 | Iteration number: [3150/4518] 69% | Training loss: 0.6870900714965094
Epoch: 29 | Iteration number: [3160/4518] 69% | Training loss: 0.6870908794712417
Epoch: 29 | Iteration number: [3170/4518] 70% | Training loss: 0.687089246116602
Epoch: 29 | Iteration number: [3180/4518] 70% | Training loss: 0.6870856393058346
Epoch: 29 | Iteration number: [3190/4518] 70% | Training loss: 0.6870837847454047
Epoch: 29 | Iteration number: [3200/4518] 70% | Training loss: 0.6870842351205647
Epoch: 29 | Iteration number: [3210/4518] 71% | Training loss: 0.6870850074142681
Epoch: 29 | Iteration number: [3220/4518] 71% | Training loss: 0.6870863495406156
Epoch: 29 | Iteration number: [3230/4518] 71% | Training loss: 0.6870830855502432
Epoch: 29 | Iteration number: [3240/4518] 71% | Training loss: 0.6870843030972246
Epoch: 29 | Iteration number: [3250/4518] 71% | Training loss: 0.6870854788009937
Epoch: 29 | Iteration number: [3260/4518] 72% | Training loss: 0.687084160041224
Epoch: 29 | Iteration number: [3270/4518] 72% | Training loss: 0.687083509938068
Epoch: 29 | Iteration number: [3280/4518] 72% | Training loss: 0.6870863054401991
Epoch: 29 | Iteration number: [3290/4518] 72% | Training loss: 0.6870827514893378
Epoch: 29 | Iteration number: [3300/4518] 73% | Training loss: 0.6870815593726707
Epoch: 29 | Iteration number: [3310/4518] 73% | Training loss: 0.6870812114091798
Epoch: 29 | Iteration number: [3320/4518] 73% | Training loss: 0.6870786300445177
Epoch: 29 | Iteration number: [3330/4518] 73% | Training loss: 0.687080591183167
Epoch: 29 | Iteration number: [3340/4518] 73% | Training loss: 0.6870807945371388
Epoch: 29 | Iteration number: [3350/4518] 74% | Training loss: 0.6870820278729965
Epoch: 29 | Iteration number: [3360/4518] 74% | Training loss: 0.6870812641368026
Epoch: 29 | Iteration number: [3370/4518] 74% | Training loss: 0.6870767279265543
Epoch: 29 | Iteration number: [3380/4518] 74% | Training loss: 0.6870740954692547
Epoch: 29 | Iteration number: [3390/4518] 75% | Training loss: 0.6870755136188856
Epoch: 29 | Iteration number: [3400/4518] 75% | Training loss: 0.6870732385621351
Epoch: 29 | Iteration number: [3410/4518] 75% | Training loss: 0.687074345804729
Epoch: 29 | Iteration number: [3420/4518] 75% | Training loss: 0.6870714519107551
Epoch: 29 | Iteration number: [3430/4518] 75% | Training loss: 0.6870728792845334
Epoch: 29 | Iteration number: [3440/4518] 76% | Training loss: 0.6870688004029352
Epoch: 29 | Iteration number: [3450/4518] 76% | Training loss: 0.687065751777179
Epoch: 29 | Iteration number: [3460/4518] 76% | Training loss: 0.6870702726648032
Epoch: 29 | Iteration number: [3470/4518] 76% | Training loss: 0.6870685152430356
Epoch: 29 | Iteration number: [3480/4518] 77% | Training loss: 0.6870629867089206
Epoch: 29 | Iteration number: [3490/4518] 77% | Training loss: 0.6870614204160805
Epoch: 29 | Iteration number: [3500/4518] 77% | Training loss: 0.6870643649782453
Epoch: 29 | Iteration number: [3510/4518] 77% | Training loss: 0.6870644632567707
Epoch: 29 | Iteration number: [3520/4518] 77% | Training loss: 0.6870590276508168
Epoch: 29 | Iteration number: [3530/4518] 78% | Training loss: 0.6870592304228386
Epoch: 29 | Iteration number: [3540/4518] 78% | Training loss: 0.6870557786549552
Epoch: 29 | Iteration number: [3550/4518] 78% | Training loss: 0.6870499188799254
Epoch: 29 | Iteration number: [3560/4518] 78% | Training loss: 0.6870473895849807
Epoch: 29 | Iteration number: [3570/4518] 79% | Training loss: 0.6870492021242778
Epoch: 29 | Iteration number: [3580/4518] 79% | Training loss: 0.68704447767921
Epoch: 29 | Iteration number: [3590/4518] 79% | Training loss: 0.6870463944079152
Epoch: 29 | Iteration number: [3600/4518] 79% | Training loss: 0.6870489247474405
Epoch: 29 | Iteration number: [3610/4518] 79% | Training loss: 0.6870490296395532
Epoch: 29 | Iteration number: [3620/4518] 80% | Training loss: 0.6870483758699828
Epoch: 29 | Iteration number: [3630/4518] 80% | Training loss: 0.687047485182108
Epoch: 29 | Iteration number: [3640/4518] 80% | Training loss: 0.6870455794445761
Epoch: 29 | Iteration number: [3650/4518] 80% | Training loss: 0.6870431366032117
Epoch: 29 | Iteration number: [3660/4518] 81% | Training loss: 0.6870424665388514
Epoch: 29 | Iteration number: [3670/4518] 81% | Training loss: 0.687039817337769
Epoch: 29 | Iteration number: [3680/4518] 81% | Training loss: 0.6870396517703067
Epoch: 29 | Iteration number: [3690/4518] 81% | Training loss: 0.6870416108347213
Epoch: 29 | Iteration number: [3700/4518] 81% | Training loss: 0.6870423332420555
Epoch: 29 | Iteration number: [3710/4518] 82% | Training loss: 0.6870414972305298
Epoch: 29 | Iteration number: [3720/4518] 82% | Training loss: 0.6870410920311046
Epoch: 29 | Iteration number: [3730/4518] 82% | Training loss: 0.687041571089154
Epoch: 29 | Iteration number: [3740/4518] 82% | Training loss: 0.6870410538293461
Epoch: 29 | Iteration number: [3750/4518] 83% | Training loss: 0.6870405706087748
Epoch: 29 | Iteration number: [3760/4518] 83% | Training loss: 0.6870379085870499
Epoch: 29 | Iteration number: [3770/4518] 83% | Training loss: 0.6870372214273053
Epoch: 29 | Iteration number: [3780/4518] 83% | Training loss: 0.6870364146888571
Epoch: 29 | Iteration number: [3790/4518] 83% | Training loss: 0.6870340110129606
Epoch: 29 | Iteration number: [3800/4518] 84% | Training loss: 0.68703404672836
Epoch: 29 | Iteration number: [3810/4518] 84% | Training loss: 0.6870310185775357
Epoch: 29 | Iteration number: [3820/4518] 84% | Training loss: 0.6870329568991487
Epoch: 29 | Iteration number: [3830/4518] 84% | Training loss: 0.687031574675682
Epoch: 29 | Iteration number: [3840/4518] 84% | Training loss: 0.6870343003266801
Epoch: 29 | Iteration number: [3850/4518] 85% | Training loss: 0.6870343859938832
Epoch: 29 | Iteration number: [3860/4518] 85% | Training loss: 0.6870356082144179
Epoch: 29 | Iteration number: [3870/4518] 85% | Training loss: 0.6870341212866534
Epoch: 29 | Iteration number: [3880/4518] 85% | Training loss: 0.6870359913897268
Epoch: 29 | Iteration number: [3890/4518] 86% | Training loss: 0.6870379445485407
Epoch: 29 | Iteration number: [3900/4518] 86% | Training loss: 0.6870340345150385
Epoch: 29 | Iteration number: [3910/4518] 86% | Training loss: 0.6870306646732418
Epoch: 29 | Iteration number: [3920/4518] 86% | Training loss: 0.687031274304098
Epoch: 29 | Iteration number: [3930/4518] 86% | Training loss: 0.6870297299238258
Epoch: 29 | Iteration number: [3940/4518] 87% | Training loss: 0.6870291510057933
Epoch: 29 | Iteration number: [3950/4518] 87% | Training loss: 0.6870287420478048
Epoch: 29 | Iteration number: [3960/4518] 87% | Training loss: 0.6870276844712219
Epoch: 29 | Iteration number: [3970/4518] 87% | Training loss: 0.6870240220044662
Epoch: 29 | Iteration number: [3980/4518] 88% | Training loss: 0.6870230985796032
Epoch: 29 | Iteration number: [3990/4518] 88% | Training loss: 0.6870226895301265
Epoch: 29 | Iteration number: [4000/4518] 88% | Training loss: 0.6870248587280512
Epoch: 29 | Iteration number: [4010/4518] 88% | Training loss: 0.6870243679852854
Epoch: 29 | Iteration number: [4020/4518] 88% | Training loss: 0.6870236922111084
Epoch: 29 | Iteration number: [4030/4518] 89% | Training loss: 0.6870225578472573
Epoch: 29 | Iteration number: [4040/4518] 89% | Training loss: 0.6870244687589089
Epoch: 29 | Iteration number: [4050/4518] 89% | Training loss: 0.6870260554772836
Epoch: 29 | Iteration number: [4060/4518] 89% | Training loss: 0.6870264760379133
Epoch: 29 | Iteration number: [4070/4518] 90% | Training loss: 0.6870281237788517
Epoch: 29 | Iteration number: [4080/4518] 90% | Training loss: 0.6870308835278539
Epoch: 29 | Iteration number: [4090/4518] 90% | Training loss: 0.6870320494279885
Epoch: 29 | Iteration number: [4100/4518] 90% | Training loss: 0.6870305084891436
Epoch: 29 | Iteration number: [4110/4518] 90% | Training loss: 0.6870319204173819
Epoch: 29 | Iteration number: [4120/4518] 91% | Training loss: 0.6870317544028597
Epoch: 29 | Iteration number: [4130/4518] 91% | Training loss: 0.6870337878965004
Epoch: 29 | Iteration number: [4140/4518] 91% | Training loss: 0.6870346736648808
Epoch: 29 | Iteration number: [4150/4518] 91% | Training loss: 0.6870344758751881
Epoch: 29 | Iteration number: [4160/4518] 92% | Training loss: 0.687033213245181
Epoch: 29 | Iteration number: [4170/4518] 92% | Training loss: 0.6870319769536849
Epoch: 29 | Iteration number: [4180/4518] 92% | Training loss: 0.6870315409590753
Epoch: 29 | Iteration number: [4190/4518] 92% | Training loss: 0.687030937407068
Epoch: 29 | Iteration number: [4200/4518] 92% | Training loss: 0.687031677535602
Epoch: 29 | Iteration number: [4210/4518] 93% | Training loss: 0.6870276536058078
Epoch: 29 | Iteration number: [4220/4518] 93% | Training loss: 0.6870297587737088
Epoch: 29 | Iteration number: [4230/4518] 93% | Training loss: 0.6870277539635381
Epoch: 29 | Iteration number: [4240/4518] 93% | Training loss: 0.6870263417233836
Epoch: 29 | Iteration number: [4250/4518] 94% | Training loss: 0.6870268077149111
Epoch: 29 | Iteration number: [4260/4518] 94% | Training loss: 0.6870232657507551
Epoch: 29 | Iteration number: [4270/4518] 94% | Training loss: 0.687018831817551
Epoch: 29 | Iteration number: [4280/4518] 94% | Training loss: 0.6870186360918473
Epoch: 29 | Iteration number: [4290/4518] 94% | Training loss: 0.6870169477168219
Epoch: 29 | Iteration number: [4300/4518] 95% | Training loss: 0.6870206253750379
Epoch: 29 | Iteration number: [4310/4518] 95% | Training loss: 0.6870197172093004
Epoch: 29 | Iteration number: [4320/4518] 95% | Training loss: 0.6870212473527149
Epoch: 29 | Iteration number: [4330/4518] 95% | Training loss: 0.6870173052607177
Epoch: 29 | Iteration number: [4340/4518] 96% | Training loss: 0.6870183874659824
Epoch: 29 | Iteration number: [4350/4518] 96% | Training loss: 0.687019128333563
Epoch: 29 | Iteration number: [4360/4518] 96% | Training loss: 0.6870168760008768
Epoch: 29 | Iteration number: [4370/4518] 96% | Training loss: 0.6870206743274182
Epoch: 29 | Iteration number: [4380/4518] 96% | Training loss: 0.6870214253664017
Epoch: 29 | Iteration number: [4390/4518] 97% | Training loss: 0.6870198441800875
Epoch: 29 | Iteration number: [4400/4518] 97% | Training loss: 0.6870184071632949
Epoch: 29 | Iteration number: [4410/4518] 97% | Training loss: 0.6870203586257234
Epoch: 29 | Iteration number: [4420/4518] 97% | Training loss: 0.6870190273582666
Epoch: 29 | Iteration number: [4430/4518] 98% | Training loss: 0.6870204394746311
Epoch: 29 | Iteration number: [4440/4518] 98% | Training loss: 0.6870203756534301
Epoch: 29 | Iteration number: [4450/4518] 98% | Training loss: 0.6870140572478263
Epoch: 29 | Iteration number: [4460/4518] 98% | Training loss: 0.6870129172577452
Epoch: 29 | Iteration number: [4470/4518] 98% | Training loss: 0.687016722886621
Epoch: 29 | Iteration number: [4480/4518] 99% | Training loss: 0.6870181583267237
Epoch: 29 | Iteration number: [4490/4518] 99% | Training loss: 0.6870179249210188
Epoch: 29 | Iteration number: [4500/4518] 99% | Training loss: 0.6870195602708392
Epoch: 29 | Iteration number: [4510/4518] 99% | Training loss: 0.6870179450829119

 End of epoch: 29 | Train Loss: 0.6868669013630874 | Training Time: 643 

 End of epoch: 29 | Eval Loss: 0.690267623687277 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/4518] 0% | Training loss: 0.7549416124820709
Epoch: 30 | Iteration number: [20/4518] 0% | Training loss: 0.7212239772081375
Epoch: 30 | Iteration number: [30/4518] 0% | Training loss: 0.7094526549180349
Epoch: 30 | Iteration number: [40/4518] 0% | Training loss: 0.7035615473985672
Epoch: 30 | Iteration number: [50/4518] 1% | Training loss: 0.700256267786026
Epoch: 30 | Iteration number: [60/4518] 1% | Training loss: 0.6978583017985026
Epoch: 30 | Iteration number: [70/4518] 1% | Training loss: 0.6962492661816734
Epoch: 30 | Iteration number: [80/4518] 1% | Training loss: 0.6950899660587311
Epoch: 30 | Iteration number: [90/4518] 1% | Training loss: 0.6941441595554352
Epoch: 30 | Iteration number: [100/4518] 2% | Training loss: 0.6936244624853134
Epoch: 30 | Iteration number: [110/4518] 2% | Training loss: 0.6929693552580747
Epoch: 30 | Iteration number: [120/4518] 2% | Training loss: 0.692313082019488
Epoch: 30 | Iteration number: [130/4518] 2% | Training loss: 0.6919180604127737
Epoch: 30 | Iteration number: [140/4518] 3% | Training loss: 0.6915901171309607
Epoch: 30 | Iteration number: [150/4518] 3% | Training loss: 0.691234571536382
Epoch: 30 | Iteration number: [160/4518] 3% | Training loss: 0.6910253599286079
Epoch: 30 | Iteration number: [170/4518] 3% | Training loss: 0.690714744609945
Epoch: 30 | Iteration number: [180/4518] 3% | Training loss: 0.6904629697402318
Epoch: 30 | Iteration number: [190/4518] 4% | Training loss: 0.6902512578587783
Epoch: 30 | Iteration number: [200/4518] 4% | Training loss: 0.6900635361671448
Epoch: 30 | Iteration number: [210/4518] 4% | Training loss: 0.689931450287501
Epoch: 30 | Iteration number: [220/4518] 4% | Training loss: 0.689834867011417
Epoch: 30 | Iteration number: [230/4518] 5% | Training loss: 0.6896873064663099
Epoch: 30 | Iteration number: [240/4518] 5% | Training loss: 0.6895655028522014
Epoch: 30 | Iteration number: [250/4518] 5% | Training loss: 0.6894573652744294
Epoch: 30 | Iteration number: [260/4518] 5% | Training loss: 0.6893138232139441
Epoch: 30 | Iteration number: [270/4518] 5% | Training loss: 0.6892195211516486
Epoch: 30 | Iteration number: [280/4518] 6% | Training loss: 0.6891383105090686
Epoch: 30 | Iteration number: [290/4518] 6% | Training loss: 0.6891317127079799
Epoch: 30 | Iteration number: [300/4518] 6% | Training loss: 0.6890454244613647
Epoch: 30 | Iteration number: [310/4518] 6% | Training loss: 0.6889912009239196
Epoch: 30 | Iteration number: [320/4518] 7% | Training loss: 0.6888916229829192
Epoch: 30 | Iteration number: [330/4518] 7% | Training loss: 0.6888549481377457
Epoch: 30 | Iteration number: [340/4518] 7% | Training loss: 0.688824746538611
Epoch: 30 | Iteration number: [350/4518] 7% | Training loss: 0.688751072372709
Epoch: 30 | Iteration number: [360/4518] 7% | Training loss: 0.6886992075377041
Epoch: 30 | Iteration number: [370/4518] 8% | Training loss: 0.6886774802530135
Epoch: 30 | Iteration number: [380/4518] 8% | Training loss: 0.6886274074253284
Epoch: 30 | Iteration number: [390/4518] 8% | Training loss: 0.6885646499120273
Epoch: 30 | Iteration number: [400/4518] 8% | Training loss: 0.688531759083271
Epoch: 30 | Iteration number: [410/4518] 9% | Training loss: 0.6884633969969866
Epoch: 30 | Iteration number: [420/4518] 9% | Training loss: 0.6884307878358024
Epoch: 30 | Iteration number: [430/4518] 9% | Training loss: 0.6883957398492236
Epoch: 30 | Iteration number: [440/4518] 9% | Training loss: 0.6883575072342699
Epoch: 30 | Iteration number: [450/4518] 9% | Training loss: 0.6883193650510576
Epoch: 30 | Iteration number: [460/4518] 10% | Training loss: 0.6882705694955328
Epoch: 30 | Iteration number: [470/4518] 10% | Training loss: 0.6882413853990271
Epoch: 30 | Iteration number: [480/4518] 10% | Training loss: 0.688231814528505
Epoch: 30 | Iteration number: [490/4518] 10% | Training loss: 0.6881724704285057
Epoch: 30 | Iteration number: [500/4518] 11% | Training loss: 0.6881607729196548
Epoch: 30 | Iteration number: [510/4518] 11% | Training loss: 0.6881255264375724
Epoch: 30 | Iteration number: [520/4518] 11% | Training loss: 0.6881040167350035
Epoch: 30 | Iteration number: [530/4518] 11% | Training loss: 0.6880734179379805
Epoch: 30 | Iteration number: [540/4518] 11% | Training loss: 0.6880583632875372
Epoch: 30 | Iteration number: [550/4518] 12% | Training loss: 0.688047549941323
Epoch: 30 | Iteration number: [560/4518] 12% | Training loss: 0.6880194206322943
Epoch: 30 | Iteration number: [570/4518] 12% | Training loss: 0.6880037065137896
Epoch: 30 | Iteration number: [580/4518] 12% | Training loss: 0.687972924010507
Epoch: 30 | Iteration number: [590/4518] 13% | Training loss: 0.6879593843120639
Epoch: 30 | Iteration number: [600/4518] 13% | Training loss: 0.6879366839925448
Epoch: 30 | Iteration number: [610/4518] 13% | Training loss: 0.6879166848346835
Epoch: 30 | Iteration number: [620/4518] 13% | Training loss: 0.6879347449348819
Epoch: 30 | Iteration number: [630/4518] 13% | Training loss: 0.6879149724566748
Epoch: 30 | Iteration number: [640/4518] 14% | Training loss: 0.6878949253819883
Epoch: 30 | Iteration number: [650/4518] 14% | Training loss: 0.687884043271725
Epoch: 30 | Iteration number: [660/4518] 14% | Training loss: 0.6878306979482824
Epoch: 30 | Iteration number: [670/4518] 14% | Training loss: 0.6878240789940108
Epoch: 30 | Iteration number: [680/4518] 15% | Training loss: 0.6878193311831531
Epoch: 30 | Iteration number: [690/4518] 15% | Training loss: 0.6877880400505618
Epoch: 30 | Iteration number: [700/4518] 15% | Training loss: 0.6877840938738414
Epoch: 30 | Iteration number: [710/4518] 15% | Training loss: 0.6877662731728084
Epoch: 30 | Iteration number: [720/4518] 15% | Training loss: 0.6877545193665557
Epoch: 30 | Iteration number: [730/4518] 16% | Training loss: 0.6877455726061782
Epoch: 30 | Iteration number: [740/4518] 16% | Training loss: 0.6877193292250504
Epoch: 30 | Iteration number: [750/4518] 16% | Training loss: 0.6876985399723053
Epoch: 30 | Iteration number: [760/4518] 16% | Training loss: 0.6876773830307158
Epoch: 30 | Iteration number: [770/4518] 17% | Training loss: 0.6876660519606107
Epoch: 30 | Iteration number: [780/4518] 17% | Training loss: 0.6876639100221488
Epoch: 30 | Iteration number: [790/4518] 17% | Training loss: 0.6876632722118233
Epoch: 30 | Iteration number: [800/4518] 17% | Training loss: 0.6876554988324642
Epoch: 30 | Iteration number: [810/4518] 17% | Training loss: 0.6876514122074033
Epoch: 30 | Iteration number: [820/4518] 18% | Training loss: 0.6876348403895773
Epoch: 30 | Iteration number: [830/4518] 18% | Training loss: 0.6876295991690762
Epoch: 30 | Iteration number: [840/4518] 18% | Training loss: 0.6876229423852194
Epoch: 30 | Iteration number: [850/4518] 18% | Training loss: 0.6876177789183224
Epoch: 30 | Iteration number: [860/4518] 19% | Training loss: 0.6876040242439092
Epoch: 30 | Iteration number: [870/4518] 19% | Training loss: 0.6875964296275172
Epoch: 30 | Iteration number: [880/4518] 19% | Training loss: 0.6875992644239556
Epoch: 30 | Iteration number: [890/4518] 19% | Training loss: 0.6875804697529654
Epoch: 30 | Iteration number: [900/4518] 19% | Training loss: 0.6875753770271937
Epoch: 30 | Iteration number: [910/4518] 20% | Training loss: 0.6875730597055876
Epoch: 30 | Iteration number: [920/4518] 20% | Training loss: 0.6875705487702204
Epoch: 30 | Iteration number: [930/4518] 20% | Training loss: 0.6875660948214992
Epoch: 30 | Iteration number: [940/4518] 20% | Training loss: 0.6875555473439237
Epoch: 30 | Iteration number: [950/4518] 21% | Training loss: 0.6875383904733156
Epoch: 30 | Iteration number: [960/4518] 21% | Training loss: 0.6875281283631921
Epoch: 30 | Iteration number: [970/4518] 21% | Training loss: 0.6875331317026591
Epoch: 30 | Iteration number: [980/4518] 21% | Training loss: 0.6875175005927378
Epoch: 30 | Iteration number: [990/4518] 21% | Training loss: 0.6875159506243889
Epoch: 30 | Iteration number: [1000/4518] 22% | Training loss: 0.6875225639343262
Epoch: 30 | Iteration number: [1010/4518] 22% | Training loss: 0.6875137036389644
Epoch: 30 | Iteration number: [1020/4518] 22% | Training loss: 0.6875126018828037
Epoch: 30 | Iteration number: [1030/4518] 22% | Training loss: 0.6875026367243053
Epoch: 30 | Iteration number: [1040/4518] 23% | Training loss: 0.687486136590059
Epoch: 30 | Iteration number: [1050/4518] 23% | Training loss: 0.6874733443487259
Epoch: 30 | Iteration number: [1060/4518] 23% | Training loss: 0.6874771838480571
Epoch: 30 | Iteration number: [1070/4518] 23% | Training loss: 0.6874715595044822
Epoch: 30 | Iteration number: [1080/4518] 23% | Training loss: 0.6874735565649138
Epoch: 30 | Iteration number: [1090/4518] 24% | Training loss: 0.6874523899970798
Epoch: 30 | Iteration number: [1100/4518] 24% | Training loss: 0.6874440627748316
Epoch: 30 | Iteration number: [1110/4518] 24% | Training loss: 0.6874488967495995
Epoch: 30 | Iteration number: [1120/4518] 24% | Training loss: 0.6874384995549917
Epoch: 30 | Iteration number: [1130/4518] 25% | Training loss: 0.6874364892465878
Epoch: 30 | Iteration number: [1140/4518] 25% | Training loss: 0.6874289129386868
Epoch: 30 | Iteration number: [1150/4518] 25% | Training loss: 0.6874179459136466
Epoch: 30 | Iteration number: [1160/4518] 25% | Training loss: 0.6874116784539716
Epoch: 30 | Iteration number: [1170/4518] 25% | Training loss: 0.6874046062302386
Epoch: 30 | Iteration number: [1180/4518] 26% | Training loss: 0.6874095177246352
Epoch: 30 | Iteration number: [1190/4518] 26% | Training loss: 0.6873993159843093
Epoch: 30 | Iteration number: [1200/4518] 26% | Training loss: 0.6873983635008335
Epoch: 30 | Iteration number: [1210/4518] 26% | Training loss: 0.6873928657740601
Epoch: 30 | Iteration number: [1220/4518] 27% | Training loss: 0.6873894834616145
Epoch: 30 | Iteration number: [1230/4518] 27% | Training loss: 0.6873739955871085
Epoch: 30 | Iteration number: [1240/4518] 27% | Training loss: 0.6873728963636583
Epoch: 30 | Iteration number: [1250/4518] 27% | Training loss: 0.6873697612762452
Epoch: 30 | Iteration number: [1260/4518] 27% | Training loss: 0.6873648068734578
Epoch: 30 | Iteration number: [1270/4518] 28% | Training loss: 0.6873637909494986
Epoch: 30 | Iteration number: [1280/4518] 28% | Training loss: 0.687366637820378
Epoch: 30 | Iteration number: [1290/4518] 28% | Training loss: 0.687364139945008
Epoch: 30 | Iteration number: [1300/4518] 28% | Training loss: 0.6873517709511977
Epoch: 30 | Iteration number: [1310/4518] 28% | Training loss: 0.6873474156583539
Epoch: 30 | Iteration number: [1320/4518] 29% | Training loss: 0.6873440731655468
Epoch: 30 | Iteration number: [1330/4518] 29% | Training loss: 0.6873399511315769
Epoch: 30 | Iteration number: [1340/4518] 29% | Training loss: 0.6873411932987953
Epoch: 30 | Iteration number: [1350/4518] 29% | Training loss: 0.6873355346255833
Epoch: 30 | Iteration number: [1360/4518] 30% | Training loss: 0.6873191497343428
Epoch: 30 | Iteration number: [1370/4518] 30% | Training loss: 0.6873185339635306
Epoch: 30 | Iteration number: [1380/4518] 30% | Training loss: 0.6873272311860237
Epoch: 30 | Iteration number: [1390/4518] 30% | Training loss: 0.6873307211793583
Epoch: 30 | Iteration number: [1400/4518] 30% | Training loss: 0.6873260947636196
Epoch: 30 | Iteration number: [1410/4518] 31% | Training loss: 0.6873281237926889
Epoch: 30 | Iteration number: [1420/4518] 31% | Training loss: 0.6873229320620148
Epoch: 30 | Iteration number: [1430/4518] 31% | Training loss: 0.6873288197117252
Epoch: 30 | Iteration number: [1440/4518] 31% | Training loss: 0.6873268918444713
Epoch: 30 | Iteration number: [1450/4518] 32% | Training loss: 0.6873227464741674
Epoch: 30 | Iteration number: [1460/4518] 32% | Training loss: 0.687312701303665
Epoch: 30 | Iteration number: [1470/4518] 32% | Training loss: 0.6873017476124017
Epoch: 30 | Iteration number: [1480/4518] 32% | Training loss: 0.6873042102601077
Epoch: 30 | Iteration number: [1490/4518] 32% | Training loss: 0.6872923206162933
Epoch: 30 | Iteration number: [1500/4518] 33% | Training loss: 0.687276916941007
Epoch: 30 | Iteration number: [1510/4518] 33% | Training loss: 0.6872864735047549
Epoch: 30 | Iteration number: [1520/4518] 33% | Training loss: 0.6872883603761071
Epoch: 30 | Iteration number: [1530/4518] 33% | Training loss: 0.6872833521147959
Epoch: 30 | Iteration number: [1540/4518] 34% | Training loss: 0.6872837361964312
Epoch: 30 | Iteration number: [1550/4518] 34% | Training loss: 0.6872792668496409
Epoch: 30 | Iteration number: [1560/4518] 34% | Training loss: 0.6872833626010479
Epoch: 30 | Iteration number: [1570/4518] 34% | Training loss: 0.6872819010619146
Epoch: 30 | Iteration number: [1580/4518] 34% | Training loss: 0.6872731096759627
Epoch: 30 | Iteration number: [1590/4518] 35% | Training loss: 0.6872715180774904
Epoch: 30 | Iteration number: [1600/4518] 35% | Training loss: 0.687266304641962
Epoch: 30 | Iteration number: [1610/4518] 35% | Training loss: 0.6872759793856129
Epoch: 30 | Iteration number: [1620/4518] 35% | Training loss: 0.6872707965565317
Epoch: 30 | Iteration number: [1630/4518] 36% | Training loss: 0.6872636461916145
Epoch: 30 | Iteration number: [1640/4518] 36% | Training loss: 0.6872596881738523
Epoch: 30 | Iteration number: [1650/4518] 36% | Training loss: 0.6872567689418793
Epoch: 30 | Iteration number: [1660/4518] 36% | Training loss: 0.6872585746538208
Epoch: 30 | Iteration number: [1670/4518] 36% | Training loss: 0.6872496251931447
Epoch: 30 | Iteration number: [1680/4518] 37% | Training loss: 0.6872523611854939
Epoch: 30 | Iteration number: [1690/4518] 37% | Training loss: 0.6872461655083493
Epoch: 30 | Iteration number: [1700/4518] 37% | Training loss: 0.6872430569634718
Epoch: 30 | Iteration number: [1710/4518] 37% | Training loss: 0.6872434418103849
Epoch: 30 | Iteration number: [1720/4518] 38% | Training loss: 0.6872505443040715
Epoch: 30 | Iteration number: [1730/4518] 38% | Training loss: 0.6872442613791868
Epoch: 30 | Iteration number: [1740/4518] 38% | Training loss: 0.6872468244412849
Epoch: 30 | Iteration number: [1750/4518] 38% | Training loss: 0.6872408407075065
Epoch: 30 | Iteration number: [1760/4518] 38% | Training loss: 0.6872450275854631
Epoch: 30 | Iteration number: [1770/4518] 39% | Training loss: 0.6872417381927792
Epoch: 30 | Iteration number: [1780/4518] 39% | Training loss: 0.6872422555189455
Epoch: 30 | Iteration number: [1790/4518] 39% | Training loss: 0.6872269889828879
Epoch: 30 | Iteration number: [1800/4518] 39% | Training loss: 0.6872208713822895
Epoch: 30 | Iteration number: [1810/4518] 40% | Training loss: 0.687218072763464
Epoch: 30 | Iteration number: [1820/4518] 40% | Training loss: 0.6872183630099663
Epoch: 30 | Iteration number: [1830/4518] 40% | Training loss: 0.6872114554129012
Epoch: 30 | Iteration number: [1840/4518] 40% | Training loss: 0.687213337486205
Epoch: 30 | Iteration number: [1850/4518] 40% | Training loss: 0.6872027507021621
Epoch: 30 | Iteration number: [1860/4518] 41% | Training loss: 0.6872011134060481
Epoch: 30 | Iteration number: [1870/4518] 41% | Training loss: 0.6872015812180259
Epoch: 30 | Iteration number: [1880/4518] 41% | Training loss: 0.6871960718581017
Epoch: 30 | Iteration number: [1890/4518] 41% | Training loss: 0.6871982322483466
Epoch: 30 | Iteration number: [1900/4518] 42% | Training loss: 0.6872010774988877
Epoch: 30 | Iteration number: [1910/4518] 42% | Training loss: 0.6871947231093002
Epoch: 30 | Iteration number: [1920/4518] 42% | Training loss: 0.6871930406428873
Epoch: 30 | Iteration number: [1930/4518] 42% | Training loss: 0.6871949766275178
Epoch: 30 | Iteration number: [1940/4518] 42% | Training loss: 0.6871934059661688
Epoch: 30 | Iteration number: [1950/4518] 43% | Training loss: 0.6871942560183696
Epoch: 30 | Iteration number: [1960/4518] 43% | Training loss: 0.6871840584034823
Epoch: 30 | Iteration number: [1970/4518] 43% | Training loss: 0.6871836445053217
Epoch: 30 | Iteration number: [1980/4518] 43% | Training loss: 0.6871801108121872
Epoch: 30 | Iteration number: [1990/4518] 44% | Training loss: 0.6871674921045351
Epoch: 30 | Iteration number: [2000/4518] 44% | Training loss: 0.6871677460372448
Epoch: 30 | Iteration number: [2010/4518] 44% | Training loss: 0.6871628762774207
Epoch: 30 | Iteration number: [2020/4518] 44% | Training loss: 0.6871603356434567
Epoch: 30 | Iteration number: [2030/4518] 44% | Training loss: 0.6871620328555553
Epoch: 30 | Iteration number: [2040/4518] 45% | Training loss: 0.6871574635014814
Epoch: 30 | Iteration number: [2050/4518] 45% | Training loss: 0.6871577545200906
Epoch: 30 | Iteration number: [2060/4518] 45% | Training loss: 0.6871498762114534
Epoch: 30 | Iteration number: [2070/4518] 45% | Training loss: 0.6871505976875047
Epoch: 30 | Iteration number: [2080/4518] 46% | Training loss: 0.6871451929498177
Epoch: 30 | Iteration number: [2090/4518] 46% | Training loss: 0.6871433773109217
Epoch: 30 | Iteration number: [2100/4518] 46% | Training loss: 0.687143394265856
Epoch: 30 | Iteration number: [2110/4518] 46% | Training loss: 0.6871446487462916
Epoch: 30 | Iteration number: [2120/4518] 46% | Training loss: 0.6871388411184527
Epoch: 30 | Iteration number: [2130/4518] 47% | Training loss: 0.6871366994201857
Epoch: 30 | Iteration number: [2140/4518] 47% | Training loss: 0.6871347731797495
Epoch: 30 | Iteration number: [2150/4518] 47% | Training loss: 0.687137162602225
Epoch: 30 | Iteration number: [2160/4518] 47% | Training loss: 0.6871377284880038
Epoch: 30 | Iteration number: [2170/4518] 48% | Training loss: 0.6871392745576147
Epoch: 30 | Iteration number: [2180/4518] 48% | Training loss: 0.687140430058908
Epoch: 30 | Iteration number: [2190/4518] 48% | Training loss: 0.6871407781289592
Epoch: 30 | Iteration number: [2200/4518] 48% | Training loss: 0.6871393153613264
Epoch: 30 | Iteration number: [2210/4518] 48% | Training loss: 0.6871374956622922
Epoch: 30 | Iteration number: [2220/4518] 49% | Training loss: 0.6871399581969321
Epoch: 30 | Iteration number: [2230/4518] 49% | Training loss: 0.6871427119045515
Epoch: 30 | Iteration number: [2240/4518] 49% | Training loss: 0.6871432976531131
Epoch: 30 | Iteration number: [2250/4518] 49% | Training loss: 0.6871470439434052
Epoch: 30 | Iteration number: [2260/4518] 50% | Training loss: 0.6871452660159727
Epoch: 30 | Iteration number: [2270/4518] 50% | Training loss: 0.6871496489919755
Epoch: 30 | Iteration number: [2280/4518] 50% | Training loss: 0.6871458257760918
Epoch: 30 | Iteration number: [2290/4518] 50% | Training loss: 0.6871435579514399
Epoch: 30 | Iteration number: [2300/4518] 50% | Training loss: 0.6871419839496198
Epoch: 30 | Iteration number: [2310/4518] 51% | Training loss: 0.6871388243906426
Epoch: 30 | Iteration number: [2320/4518] 51% | Training loss: 0.6871322067647144
Epoch: 30 | Iteration number: [2330/4518] 51% | Training loss: 0.6871305781116813
Epoch: 30 | Iteration number: [2340/4518] 51% | Training loss: 0.6871301569490351
Epoch: 30 | Iteration number: [2350/4518] 52% | Training loss: 0.6871266269937475
Epoch: 30 | Iteration number: [2360/4518] 52% | Training loss: 0.6871221319851228
Epoch: 30 | Iteration number: [2370/4518] 52% | Training loss: 0.6871198241720723
Epoch: 30 | Iteration number: [2380/4518] 52% | Training loss: 0.6871194857509196
Epoch: 30 | Iteration number: [2390/4518] 52% | Training loss: 0.6871259466873552
Epoch: 30 | Iteration number: [2400/4518] 53% | Training loss: 0.6871163975199064
Epoch: 30 | Iteration number: [2410/4518] 53% | Training loss: 0.6871167712191824
Epoch: 30 | Iteration number: [2420/4518] 53% | Training loss: 0.6871150531798355
Epoch: 30 | Iteration number: [2430/4518] 53% | Training loss: 0.6871129823810279
Epoch: 30 | Iteration number: [2440/4518] 54% | Training loss: 0.6871163978439863
Epoch: 30 | Iteration number: [2450/4518] 54% | Training loss: 0.6871149469395073
Epoch: 30 | Iteration number: [2460/4518] 54% | Training loss: 0.687115131742586
Epoch: 30 | Iteration number: [2470/4518] 54% | Training loss: 0.6871112354853858
Epoch: 30 | Iteration number: [2480/4518] 54% | Training loss: 0.687109835830427
Epoch: 30 | Iteration number: [2490/4518] 55% | Training loss: 0.687109237789629
Epoch: 30 | Iteration number: [2500/4518] 55% | Training loss: 0.6871036225795746
Epoch: 30 | Iteration number: [2510/4518] 55% | Training loss: 0.6871022866304177
Epoch: 30 | Iteration number: [2520/4518] 55% | Training loss: 0.68710468002255
Epoch: 30 | Iteration number: [2530/4518] 55% | Training loss: 0.6871070001436317
Epoch: 30 | Iteration number: [2540/4518] 56% | Training loss: 0.6871105918968756
Epoch: 30 | Iteration number: [2550/4518] 56% | Training loss: 0.6871083917103562
Epoch: 30 | Iteration number: [2560/4518] 56% | Training loss: 0.6871099455514923
Epoch: 30 | Iteration number: [2570/4518] 56% | Training loss: 0.6871090904516005
Epoch: 30 | Iteration number: [2580/4518] 57% | Training loss: 0.687109452116397
Epoch: 30 | Iteration number: [2590/4518] 57% | Training loss: 0.6871083339208802
Epoch: 30 | Iteration number: [2600/4518] 57% | Training loss: 0.687105102126415
Epoch: 30 | Iteration number: [2610/4518] 57% | Training loss: 0.6871028329905879
Epoch: 30 | Iteration number: [2620/4518] 57% | Training loss: 0.6870997845671559
Epoch: 30 | Iteration number: [2630/4518] 58% | Training loss: 0.6870995546475109
Epoch: 30 | Iteration number: [2640/4518] 58% | Training loss: 0.6871001647954638
Epoch: 30 | Iteration number: [2650/4518] 58% | Training loss: 0.6870947438815854
Epoch: 30 | Iteration number: [2660/4518] 58% | Training loss: 0.6870932706092533
Epoch: 30 | Iteration number: [2670/4518] 59% | Training loss: 0.6870904684066772
Epoch: 30 | Iteration number: [2680/4518] 59% | Training loss: 0.6870883072045312
Epoch: 30 | Iteration number: [2690/4518] 59% | Training loss: 0.6870835380483294
Epoch: 30 | Iteration number: [2700/4518] 59% | Training loss: 0.6870833785224844
Epoch: 30 | Iteration number: [2710/4518] 59% | Training loss: 0.6870837980090913
Epoch: 30 | Iteration number: [2720/4518] 60% | Training loss: 0.6870796519386417
Epoch: 30 | Iteration number: [2730/4518] 60% | Training loss: 0.687076557141084
Epoch: 30 | Iteration number: [2740/4518] 60% | Training loss: 0.6870723510093062
Epoch: 30 | Iteration number: [2750/4518] 60% | Training loss: 0.687069212176583
Epoch: 30 | Iteration number: [2760/4518] 61% | Training loss: 0.6870704054184582
Epoch: 30 | Iteration number: [2770/4518] 61% | Training loss: 0.6870596283824866
Epoch: 30 | Iteration number: [2780/4518] 61% | Training loss: 0.6870579430525251
Epoch: 30 | Iteration number: [2790/4518] 61% | Training loss: 0.6870541086760901
Epoch: 30 | Iteration number: [2800/4518] 61% | Training loss: 0.6870553903494563
Epoch: 30 | Iteration number: [2810/4518] 62% | Training loss: 0.687048558090081
Epoch: 30 | Iteration number: [2820/4518] 62% | Training loss: 0.6870476391932643
Epoch: 30 | Iteration number: [2830/4518] 62% | Training loss: 0.6870484909825948
Epoch: 30 | Iteration number: [2840/4518] 62% | Training loss: 0.6870482208443359
Epoch: 30 | Iteration number: [2850/4518] 63% | Training loss: 0.6870507776318935
Epoch: 30 | Iteration number: [2860/4518] 63% | Training loss: 0.6870512692036329
Epoch: 30 | Iteration number: [2870/4518] 63% | Training loss: 0.6870518845132835
Epoch: 30 | Iteration number: [2880/4518] 63% | Training loss: 0.6870467834174633
Epoch: 30 | Iteration number: [2890/4518] 63% | Training loss: 0.6870437748085668
Epoch: 30 | Iteration number: [2900/4518] 64% | Training loss: 0.6870449172422803
Epoch: 30 | Iteration number: [2910/4518] 64% | Training loss: 0.6870455172463381
Epoch: 30 | Iteration number: [2920/4518] 64% | Training loss: 0.687050367687663
Epoch: 30 | Iteration number: [2930/4518] 64% | Training loss: 0.6870538588880272
Epoch: 30 | Iteration number: [2940/4518] 65% | Training loss: 0.6870508271212481
Epoch: 30 | Iteration number: [2950/4518] 65% | Training loss: 0.687046946953919
Epoch: 30 | Iteration number: [2960/4518] 65% | Training loss: 0.6870501699882585
Epoch: 30 | Iteration number: [2970/4518] 65% | Training loss: 0.6870477241699142
Epoch: 30 | Iteration number: [2980/4518] 65% | Training loss: 0.6870483416238887
Epoch: 30 | Iteration number: [2990/4518] 66% | Training loss: 0.6870531023744756
Epoch: 30 | Iteration number: [3000/4518] 66% | Training loss: 0.6870544099410375
Epoch: 30 | Iteration number: [3010/4518] 66% | Training loss: 0.6870520175493436
Epoch: 30 | Iteration number: [3020/4518] 66% | Training loss: 0.6870510501972097
Epoch: 30 | Iteration number: [3030/4518] 67% | Training loss: 0.6870520719600589
Epoch: 30 | Iteration number: [3040/4518] 67% | Training loss: 0.687056852504611
Epoch: 30 | Iteration number: [3050/4518] 67% | Training loss: 0.6870590911341495
Epoch: 30 | Iteration number: [3060/4518] 67% | Training loss: 0.6870534217630336
Epoch: 30 | Iteration number: [3070/4518] 67% | Training loss: 0.6870534057337608
Epoch: 30 | Iteration number: [3080/4518] 68% | Training loss: 0.6870549207383936
Epoch: 30 | Iteration number: [3090/4518] 68% | Training loss: 0.6870559861551983
Epoch: 30 | Iteration number: [3100/4518] 68% | Training loss: 0.6870561584541874
Epoch: 30 | Iteration number: [3110/4518] 68% | Training loss: 0.6870520196160319
Epoch: 30 | Iteration number: [3120/4518] 69% | Training loss: 0.6870534562529662
Epoch: 30 | Iteration number: [3130/4518] 69% | Training loss: 0.6870500038416621
Epoch: 30 | Iteration number: [3140/4518] 69% | Training loss: 0.6870487369739325
Epoch: 30 | Iteration number: [3150/4518] 69% | Training loss: 0.6870469618978955
Epoch: 30 | Iteration number: [3160/4518] 69% | Training loss: 0.6870461386970327
Epoch: 30 | Iteration number: [3170/4518] 70% | Training loss: 0.6870446274333196
Epoch: 30 | Iteration number: [3180/4518] 70% | Training loss: 0.6870434941360786
Epoch: 30 | Iteration number: [3190/4518] 70% | Training loss: 0.6870416297060569
Epoch: 30 | Iteration number: [3200/4518] 70% | Training loss: 0.6870420393534005
Epoch: 30 | Iteration number: [3210/4518] 71% | Training loss: 0.6870391708111094
Epoch: 30 | Iteration number: [3220/4518] 71% | Training loss: 0.6870387977324658
Epoch: 30 | Iteration number: [3230/4518] 71% | Training loss: 0.6870345086874239
Epoch: 30 | Iteration number: [3240/4518] 71% | Training loss: 0.6870349513159858
Epoch: 30 | Iteration number: [3250/4518] 71% | Training loss: 0.6870377946266761
Epoch: 30 | Iteration number: [3260/4518] 72% | Training loss: 0.6870362160213155
Epoch: 30 | Iteration number: [3270/4518] 72% | Training loss: 0.6870360534672343
Epoch: 30 | Iteration number: [3280/4518] 72% | Training loss: 0.6870372628656829
Epoch: 30 | Iteration number: [3290/4518] 72% | Training loss: 0.6870378263996727
Epoch: 30 | Iteration number: [3300/4518] 73% | Training loss: 0.6870368421619588
Epoch: 30 | Iteration number: [3310/4518] 73% | Training loss: 0.6870355347852333
Epoch: 30 | Iteration number: [3320/4518] 73% | Training loss: 0.6870392033673195
Epoch: 30 | Iteration number: [3330/4518] 73% | Training loss: 0.687036467403979
Epoch: 30 | Iteration number: [3340/4518] 73% | Training loss: 0.6870332328323833
Epoch: 30 | Iteration number: [3350/4518] 74% | Training loss: 0.6870367263146301
Epoch: 30 | Iteration number: [3360/4518] 74% | Training loss: 0.6870369559242612
Epoch: 30 | Iteration number: [3370/4518] 74% | Training loss: 0.6870381173818685
Epoch: 30 | Iteration number: [3380/4518] 74% | Training loss: 0.6870386697307846
Epoch: 30 | Iteration number: [3390/4518] 75% | Training loss: 0.6870341059380928
Epoch: 30 | Iteration number: [3400/4518] 75% | Training loss: 0.6870320609036614
Epoch: 30 | Iteration number: [3410/4518] 75% | Training loss: 0.6870295028882293
Epoch: 30 | Iteration number: [3420/4518] 75% | Training loss: 0.6870295905578904
Epoch: 30 | Iteration number: [3430/4518] 75% | Training loss: 0.6870278121257315
Epoch: 30 | Iteration number: [3440/4518] 76% | Training loss: 0.6870311256064925
Epoch: 30 | Iteration number: [3450/4518] 76% | Training loss: 0.6870296089718307
Epoch: 30 | Iteration number: [3460/4518] 76% | Training loss: 0.6870303366742382
Epoch: 30 | Iteration number: [3470/4518] 76% | Training loss: 0.6870323081353212
Epoch: 30 | Iteration number: [3480/4518] 77% | Training loss: 0.6870313289007921
Epoch: 30 | Iteration number: [3490/4518] 77% | Training loss: 0.6870297915443649
Epoch: 30 | Iteration number: [3500/4518] 77% | Training loss: 0.6870270234176091
Epoch: 30 | Iteration number: [3510/4518] 77% | Training loss: 0.6870311541774674
Epoch: 30 | Iteration number: [3520/4518] 77% | Training loss: 0.6870304138822989
Epoch: 30 | Iteration number: [3530/4518] 78% | Training loss: 0.6870320382604518
Epoch: 30 | Iteration number: [3540/4518] 78% | Training loss: 0.6870301320222811
Epoch: 30 | Iteration number: [3550/4518] 78% | Training loss: 0.6870292232070171
Epoch: 30 | Iteration number: [3560/4518] 78% | Training loss: 0.6870273472218031
Epoch: 30 | Iteration number: [3570/4518] 79% | Training loss: 0.6870293770350662
Epoch: 30 | Iteration number: [3580/4518] 79% | Training loss: 0.6870317642915182
Epoch: 30 | Iteration number: [3590/4518] 79% | Training loss: 0.6870350440398564
Epoch: 30 | Iteration number: [3600/4518] 79% | Training loss: 0.6870351753466659
Epoch: 30 | Iteration number: [3610/4518] 79% | Training loss: 0.6870320370983218
Epoch: 30 | Iteration number: [3620/4518] 80% | Training loss: 0.6870341990863421
Epoch: 30 | Iteration number: [3630/4518] 80% | Training loss: 0.6870347145667746
Epoch: 30 | Iteration number: [3640/4518] 80% | Training loss: 0.6870316529994482
Epoch: 30 | Iteration number: [3650/4518] 80% | Training loss: 0.687031820636906
Epoch: 30 | Iteration number: [3660/4518] 81% | Training loss: 0.6870302283047327
Epoch: 30 | Iteration number: [3670/4518] 81% | Training loss: 0.6870317212567343
Epoch: 30 | Iteration number: [3680/4518] 81% | Training loss: 0.6870333874193223
Epoch: 30 | Iteration number: [3690/4518] 81% | Training loss: 0.6870313909964832
Epoch: 30 | Iteration number: [3700/4518] 81% | Training loss: 0.6870304657961871
Epoch: 30 | Iteration number: [3710/4518] 82% | Training loss: 0.6870332132452581
Epoch: 30 | Iteration number: [3720/4518] 82% | Training loss: 0.6870311591734168
Epoch: 30 | Iteration number: [3730/4518] 82% | Training loss: 0.6870288988700182
Epoch: 30 | Iteration number: [3740/4518] 82% | Training loss: 0.6870283838899378
Epoch: 30 | Iteration number: [3750/4518] 83% | Training loss: 0.6870268571694692
Epoch: 30 | Iteration number: [3760/4518] 83% | Training loss: 0.6870244278552684
Epoch: 30 | Iteration number: [3770/4518] 83% | Training loss: 0.6870243440098092
Epoch: 30 | Iteration number: [3780/4518] 83% | Training loss: 0.6870260375832754
Epoch: 30 | Iteration number: [3790/4518] 83% | Training loss: 0.6870246728366157
Epoch: 30 | Iteration number: [3800/4518] 84% | Training loss: 0.6870227010312834
Epoch: 30 | Iteration number: [3810/4518] 84% | Training loss: 0.6870242943131705
Epoch: 30 | Iteration number: [3820/4518] 84% | Training loss: 0.6870259226148665
Epoch: 30 | Iteration number: [3830/4518] 84% | Training loss: 0.6870283487727064
Epoch: 30 | Iteration number: [3840/4518] 84% | Training loss: 0.6870287890080362
Epoch: 30 | Iteration number: [3850/4518] 85% | Training loss: 0.68703214145326
Epoch: 30 | Iteration number: [3860/4518] 85% | Training loss: 0.6870284686897703
Epoch: 30 | Iteration number: [3870/4518] 85% | Training loss: 0.6870292932796231
Epoch: 30 | Iteration number: [3880/4518] 85% | Training loss: 0.6870281929515072
Epoch: 30 | Iteration number: [3890/4518] 86% | Training loss: 0.6870275146703794
Epoch: 30 | Iteration number: [3900/4518] 86% | Training loss: 0.6870274719519492
Epoch: 30 | Iteration number: [3910/4518] 86% | Training loss: 0.6870282538406685
Epoch: 30 | Iteration number: [3920/4518] 86% | Training loss: 0.6870280268088895
Epoch: 30 | Iteration number: [3930/4518] 86% | Training loss: 0.6870274633396672
Epoch: 30 | Iteration number: [3940/4518] 87% | Training loss: 0.6870290203899296
Epoch: 30 | Iteration number: [3950/4518] 87% | Training loss: 0.6870291011544722
Epoch: 30 | Iteration number: [3960/4518] 87% | Training loss: 0.6870273524613092
Epoch: 30 | Iteration number: [3970/4518] 87% | Training loss: 0.6870299826941502
Epoch: 30 | Iteration number: [3980/4518] 88% | Training loss: 0.6870272304544497
Epoch: 30 | Iteration number: [3990/4518] 88% | Training loss: 0.6870241362946972
Epoch: 30 | Iteration number: [4000/4518] 88% | Training loss: 0.6870231390595436
Epoch: 30 | Iteration number: [4010/4518] 88% | Training loss: 0.6870234928374873
Epoch: 30 | Iteration number: [4020/4518] 88% | Training loss: 0.6870266237810476
Epoch: 30 | Iteration number: [4030/4518] 89% | Training loss: 0.6870259669815044
Epoch: 30 | Iteration number: [4040/4518] 89% | Training loss: 0.6870245755308926
Epoch: 30 | Iteration number: [4050/4518] 89% | Training loss: 0.6870250434051325
Epoch: 30 | Iteration number: [4060/4518] 89% | Training loss: 0.6870251683766031
Epoch: 30 | Iteration number: [4070/4518] 90% | Training loss: 0.6870272972513475
Epoch: 30 | Iteration number: [4080/4518] 90% | Training loss: 0.6870243870160159
Epoch: 30 | Iteration number: [4090/4518] 90% | Training loss: 0.6870196152287182
Epoch: 30 | Iteration number: [4100/4518] 90% | Training loss: 0.6870190112619865
Epoch: 30 | Iteration number: [4110/4518] 90% | Training loss: 0.6870195636639049
Epoch: 30 | Iteration number: [4120/4518] 91% | Training loss: 0.687016569902596
Epoch: 30 | Iteration number: [4130/4518] 91% | Training loss: 0.6870143069770666
Epoch: 30 | Iteration number: [4140/4518] 91% | Training loss: 0.6870153848387769
Epoch: 30 | Iteration number: [4150/4518] 91% | Training loss: 0.6870149365247014
Epoch: 30 | Iteration number: [4160/4518] 92% | Training loss: 0.6870165667998103
Epoch: 30 | Iteration number: [4170/4518] 92% | Training loss: 0.6870163404541336
Epoch: 30 | Iteration number: [4180/4518] 92% | Training loss: 0.6870157290303536
Epoch: 30 | Iteration number: [4190/4518] 92% | Training loss: 0.6870178801205391
Epoch: 30 | Iteration number: [4200/4518] 92% | Training loss: 0.6870155563240959
Epoch: 30 | Iteration number: [4210/4518] 93% | Training loss: 0.6870126395355778
Epoch: 30 | Iteration number: [4220/4518] 93% | Training loss: 0.6870160578692693
Epoch: 30 | Iteration number: [4230/4518] 93% | Training loss: 0.6870142445496633
Epoch: 30 | Iteration number: [4240/4518] 93% | Training loss: 0.6870105840406328
Epoch: 30 | Iteration number: [4250/4518] 94% | Training loss: 0.6870115375238306
Epoch: 30 | Iteration number: [4260/4518] 94% | Training loss: 0.6870107956755329
Epoch: 30 | Iteration number: [4270/4518] 94% | Training loss: 0.6870100208551599
Epoch: 30 | Iteration number: [4280/4518] 94% | Training loss: 0.6870085443709498
Epoch: 30 | Iteration number: [4290/4518] 94% | Training loss: 0.6870102982837837
Epoch: 30 | Iteration number: [4300/4518] 95% | Training loss: 0.687009162902832
Epoch: 30 | Iteration number: [4310/4518] 95% | Training loss: 0.6870082838491055
Epoch: 30 | Iteration number: [4320/4518] 95% | Training loss: 0.6870073537169783
Epoch: 30 | Iteration number: [4330/4518] 95% | Training loss: 0.6870108319622815
Epoch: 30 | Iteration number: [4340/4518] 96% | Training loss: 0.6870066204653358
Epoch: 30 | Iteration number: [4350/4518] 96% | Training loss: 0.6870051971660264
Epoch: 30 | Iteration number: [4360/4518] 96% | Training loss: 0.6870066864091322
Epoch: 30 | Iteration number: [4370/4518] 96% | Training loss: 0.687007773195306
Epoch: 30 | Iteration number: [4380/4518] 96% | Training loss: 0.6870106021154961
Epoch: 30 | Iteration number: [4390/4518] 97% | Training loss: 0.6870091003003045
Epoch: 30 | Iteration number: [4400/4518] 97% | Training loss: 0.6870060853795572
Epoch: 30 | Iteration number: [4410/4518] 97% | Training loss: 0.6870058974711533
Epoch: 30 | Iteration number: [4420/4518] 97% | Training loss: 0.6870074165892277
Epoch: 30 | Iteration number: [4430/4518] 98% | Training loss: 0.68700879432816
Epoch: 30 | Iteration number: [4440/4518] 98% | Training loss: 0.6870076938792392
Epoch: 30 | Iteration number: [4450/4518] 98% | Training loss: 0.687008694142438
Epoch: 30 | Iteration number: [4460/4518] 98% | Training loss: 0.6870060640466588
Epoch: 30 | Iteration number: [4470/4518] 98% | Training loss: 0.6870069785672813
Epoch: 30 | Iteration number: [4480/4518] 99% | Training loss: 0.6870081736040967
Epoch: 30 | Iteration number: [4490/4518] 99% | Training loss: 0.6870096004354396
Epoch: 30 | Iteration number: [4500/4518] 99% | Training loss: 0.6870117492278417
Epoch: 30 | Iteration number: [4510/4518] 99% | Training loss: 0.6870110134327755

 End of epoch: 30 | Train Loss: 0.6868585803541476 | Training Time: 642 

 End of epoch: 30 | Eval Loss: 0.6902125027714944 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/4518] 0% | Training loss: 0.7572096765041352
Epoch: 31 | Iteration number: [20/4518] 0% | Training loss: 0.7226319670677185
Epoch: 31 | Iteration number: [30/4518] 0% | Training loss: 0.7105093717575073
Epoch: 31 | Iteration number: [40/4518] 0% | Training loss: 0.7046586483716964
Epoch: 31 | Iteration number: [50/4518] 1% | Training loss: 0.7008642554283142
Epoch: 31 | Iteration number: [60/4518] 1% | Training loss: 0.6984494080146154
Epoch: 31 | Iteration number: [70/4518] 1% | Training loss: 0.6968668026583535
Epoch: 31 | Iteration number: [80/4518] 1% | Training loss: 0.6956373922526836
Epoch: 31 | Iteration number: [90/4518] 1% | Training loss: 0.6946801861127218
Epoch: 31 | Iteration number: [100/4518] 2% | Training loss: 0.6938391774892807
Epoch: 31 | Iteration number: [110/4518] 2% | Training loss: 0.6932638450102373
Epoch: 31 | Iteration number: [120/4518] 2% | Training loss: 0.6927776699264844
Epoch: 31 | Iteration number: [130/4518] 2% | Training loss: 0.6921752769213456
Epoch: 31 | Iteration number: [140/4518] 3% | Training loss: 0.6918075991528375
Epoch: 31 | Iteration number: [150/4518] 3% | Training loss: 0.691417893966039
Epoch: 31 | Iteration number: [160/4518] 3% | Training loss: 0.691201814264059
Epoch: 31 | Iteration number: [170/4518] 3% | Training loss: 0.6909388903309317
Epoch: 31 | Iteration number: [180/4518] 3% | Training loss: 0.6907035516368019
Epoch: 31 | Iteration number: [190/4518] 4% | Training loss: 0.6904704828011362
Epoch: 31 | Iteration number: [200/4518] 4% | Training loss: 0.6902579861879349
Epoch: 31 | Iteration number: [210/4518] 4% | Training loss: 0.6900707074574062
Epoch: 31 | Iteration number: [220/4518] 4% | Training loss: 0.6899305346337232
Epoch: 31 | Iteration number: [230/4518] 5% | Training loss: 0.6897994300593501
Epoch: 31 | Iteration number: [240/4518] 5% | Training loss: 0.6896750353276729
Epoch: 31 | Iteration number: [250/4518] 5% | Training loss: 0.6895689852237702
Epoch: 31 | Iteration number: [260/4518] 5% | Training loss: 0.6894164275664549
Epoch: 31 | Iteration number: [270/4518] 5% | Training loss: 0.6893746669645663
Epoch: 31 | Iteration number: [280/4518] 6% | Training loss: 0.6893111343894686
Epoch: 31 | Iteration number: [290/4518] 6% | Training loss: 0.6892599253818906
Epoch: 31 | Iteration number: [300/4518] 6% | Training loss: 0.6891611842314402
Epoch: 31 | Iteration number: [310/4518] 6% | Training loss: 0.6890871474819799
Epoch: 31 | Iteration number: [320/4518] 7% | Training loss: 0.6889973351731896
Epoch: 31 | Iteration number: [330/4518] 7% | Training loss: 0.688946535912427
Epoch: 31 | Iteration number: [340/4518] 7% | Training loss: 0.6889207529671052
Epoch: 31 | Iteration number: [350/4518] 7% | Training loss: 0.6888756997244698
Epoch: 31 | Iteration number: [360/4518] 7% | Training loss: 0.6888062490357293
Epoch: 31 | Iteration number: [370/4518] 8% | Training loss: 0.6887497120612377
Epoch: 31 | Iteration number: [380/4518] 8% | Training loss: 0.6887248740384453
Epoch: 31 | Iteration number: [390/4518] 8% | Training loss: 0.6886800542855874
Epoch: 31 | Iteration number: [400/4518] 8% | Training loss: 0.6886710149049758
Epoch: 31 | Iteration number: [410/4518] 9% | Training loss: 0.6886227898481415
Epoch: 31 | Iteration number: [420/4518] 9% | Training loss: 0.6885533391010193
Epoch: 31 | Iteration number: [430/4518] 9% | Training loss: 0.6885053902171379
Epoch: 31 | Iteration number: [440/4518] 9% | Training loss: 0.6884877322749658
Epoch: 31 | Iteration number: [450/4518] 9% | Training loss: 0.6884499290254381
Epoch: 31 | Iteration number: [460/4518] 10% | Training loss: 0.6884427423062531
Epoch: 31 | Iteration number: [470/4518] 10% | Training loss: 0.6884236385213568
Epoch: 31 | Iteration number: [480/4518] 10% | Training loss: 0.6883856546133756
Epoch: 31 | Iteration number: [490/4518] 10% | Training loss: 0.6883577310309118
Epoch: 31 | Iteration number: [500/4518] 11% | Training loss: 0.68835025036335
Epoch: 31 | Iteration number: [510/4518] 11% | Training loss: 0.6883253981085384
Epoch: 31 | Iteration number: [520/4518] 11% | Training loss: 0.6882901747639363
Epoch: 31 | Iteration number: [530/4518] 11% | Training loss: 0.6882697826286532
Epoch: 31 | Iteration number: [540/4518] 11% | Training loss: 0.6882207164057978
Epoch: 31 | Iteration number: [550/4518] 12% | Training loss: 0.6882163028283552
Epoch: 31 | Iteration number: [560/4518] 12% | Training loss: 0.6881939511213984
Epoch: 31 | Iteration number: [570/4518] 12% | Training loss: 0.6881740867045888
Epoch: 31 | Iteration number: [580/4518] 12% | Training loss: 0.6881714923628446
Epoch: 31 | Iteration number: [590/4518] 13% | Training loss: 0.6881515712051068
Epoch: 31 | Iteration number: [600/4518] 13% | Training loss: 0.6881197266777357
Epoch: 31 | Iteration number: [610/4518] 13% | Training loss: 0.6881013902484393
Epoch: 31 | Iteration number: [620/4518] 13% | Training loss: 0.6880891399998819
Epoch: 31 | Iteration number: [630/4518] 13% | Training loss: 0.6880533565604497
Epoch: 31 | Iteration number: [640/4518] 14% | Training loss: 0.688038919121027
Epoch: 31 | Iteration number: [650/4518] 14% | Training loss: 0.6880204444665176
Epoch: 31 | Iteration number: [660/4518] 14% | Training loss: 0.6880009077715151
Epoch: 31 | Iteration number: [670/4518] 14% | Training loss: 0.687966111435819
Epoch: 31 | Iteration number: [680/4518] 15% | Training loss: 0.687954487257144
Epoch: 31 | Iteration number: [690/4518] 15% | Training loss: 0.687928060863329
Epoch: 31 | Iteration number: [700/4518] 15% | Training loss: 0.687914393544197
Epoch: 31 | Iteration number: [710/4518] 15% | Training loss: 0.6879162697724893
Epoch: 31 | Iteration number: [720/4518] 15% | Training loss: 0.6879163728819953
Epoch: 31 | Iteration number: [730/4518] 16% | Training loss: 0.6879003549275333
Epoch: 31 | Iteration number: [740/4518] 16% | Training loss: 0.6878759031360214
Epoch: 31 | Iteration number: [750/4518] 16% | Training loss: 0.6878564618428549
Epoch: 31 | Iteration number: [760/4518] 16% | Training loss: 0.6878372293553854
Epoch: 31 | Iteration number: [770/4518] 17% | Training loss: 0.687817684783564
Epoch: 31 | Iteration number: [780/4518] 17% | Training loss: 0.6878134615910358
Epoch: 31 | Iteration number: [790/4518] 17% | Training loss: 0.6878105898446675
Epoch: 31 | Iteration number: [800/4518] 17% | Training loss: 0.687799336835742
Epoch: 31 | Iteration number: [810/4518] 17% | Training loss: 0.6877895790853618
Epoch: 31 | Iteration number: [820/4518] 18% | Training loss: 0.687790254921448
Epoch: 31 | Iteration number: [830/4518] 18% | Training loss: 0.6877661699272064
Epoch: 31 | Iteration number: [840/4518] 18% | Training loss: 0.6877481826004528
Epoch: 31 | Iteration number: [850/4518] 18% | Training loss: 0.6877312012279735
Epoch: 31 | Iteration number: [860/4518] 19% | Training loss: 0.6876966553372006
Epoch: 31 | Iteration number: [870/4518] 19% | Training loss: 0.6876817299716774
Epoch: 31 | Iteration number: [880/4518] 19% | Training loss: 0.6876856735484167
Epoch: 31 | Iteration number: [890/4518] 19% | Training loss: 0.6876759277300888
Epoch: 31 | Iteration number: [900/4518] 19% | Training loss: 0.6876593500375747
Epoch: 31 | Iteration number: [910/4518] 20% | Training loss: 0.6876339241698548
Epoch: 31 | Iteration number: [920/4518] 20% | Training loss: 0.6876315203049909
Epoch: 31 | Iteration number: [930/4518] 20% | Training loss: 0.6876103181351898
Epoch: 31 | Iteration number: [940/4518] 20% | Training loss: 0.6875940428135243
Epoch: 31 | Iteration number: [950/4518] 21% | Training loss: 0.6876029792584871
Epoch: 31 | Iteration number: [960/4518] 21% | Training loss: 0.6875811882317067
Epoch: 31 | Iteration number: [970/4518] 21% | Training loss: 0.6875665313189792
Epoch: 31 | Iteration number: [980/4518] 21% | Training loss: 0.6875581904941676
Epoch: 31 | Iteration number: [990/4518] 21% | Training loss: 0.687552871366944
Epoch: 31 | Iteration number: [1000/4518] 22% | Training loss: 0.6875459491610527
Epoch: 31 | Iteration number: [1010/4518] 22% | Training loss: 0.6875407998514648
Epoch: 31 | Iteration number: [1020/4518] 22% | Training loss: 0.6875326712926229
Epoch: 31 | Iteration number: [1030/4518] 22% | Training loss: 0.6875358453074705
Epoch: 31 | Iteration number: [1040/4518] 23% | Training loss: 0.6875268540703333
Epoch: 31 | Iteration number: [1050/4518] 23% | Training loss: 0.6875030652114323
Epoch: 31 | Iteration number: [1060/4518] 23% | Training loss: 0.6874973248198347
Epoch: 31 | Iteration number: [1070/4518] 23% | Training loss: 0.6874965802531376
Epoch: 31 | Iteration number: [1080/4518] 23% | Training loss: 0.6874925379951795
Epoch: 31 | Iteration number: [1090/4518] 24% | Training loss: 0.6874792367493341
Epoch: 31 | Iteration number: [1100/4518] 24% | Training loss: 0.6874740155718543
Epoch: 31 | Iteration number: [1110/4518] 24% | Training loss: 0.6874716964390901
Epoch: 31 | Iteration number: [1120/4518] 24% | Training loss: 0.687456920051149
Epoch: 31 | Iteration number: [1130/4518] 25% | Training loss: 0.6874520370390563
Epoch: 31 | Iteration number: [1140/4518] 25% | Training loss: 0.6874542580361952
Epoch: 31 | Iteration number: [1150/4518] 25% | Training loss: 0.6874536502879599
Epoch: 31 | Iteration number: [1160/4518] 25% | Training loss: 0.6874491426451453
Epoch: 31 | Iteration number: [1170/4518] 25% | Training loss: 0.6874364064799414
Epoch: 31 | Iteration number: [1180/4518] 26% | Training loss: 0.6874230991985838
Epoch: 31 | Iteration number: [1190/4518] 26% | Training loss: 0.6874153292980515
Epoch: 31 | Iteration number: [1200/4518] 26% | Training loss: 0.6873989169796307
Epoch: 31 | Iteration number: [1210/4518] 26% | Training loss: 0.6873959495508967
Epoch: 31 | Iteration number: [1220/4518] 27% | Training loss: 0.6873937101149168
Epoch: 31 | Iteration number: [1230/4518] 27% | Training loss: 0.6874017256062205
Epoch: 31 | Iteration number: [1240/4518] 27% | Training loss: 0.68739583300006
Epoch: 31 | Iteration number: [1250/4518] 27% | Training loss: 0.6873957057476043
Epoch: 31 | Iteration number: [1260/4518] 27% | Training loss: 0.6873953342437744
Epoch: 31 | Iteration number: [1270/4518] 28% | Training loss: 0.6873912548924994
Epoch: 31 | Iteration number: [1280/4518] 28% | Training loss: 0.6873960430268198
Epoch: 31 | Iteration number: [1290/4518] 28% | Training loss: 0.6873855930890224
Epoch: 31 | Iteration number: [1300/4518] 28% | Training loss: 0.6873807201935694
Epoch: 31 | Iteration number: [1310/4518] 28% | Training loss: 0.6873826665732696
Epoch: 31 | Iteration number: [1320/4518] 29% | Training loss: 0.6873802700729081
Epoch: 31 | Iteration number: [1330/4518] 29% | Training loss: 0.6873850239846939
Epoch: 31 | Iteration number: [1340/4518] 29% | Training loss: 0.6873836809574668
Epoch: 31 | Iteration number: [1350/4518] 29% | Training loss: 0.68736972839744
Epoch: 31 | Iteration number: [1360/4518] 30% | Training loss: 0.6873694500940688
Epoch: 31 | Iteration number: [1370/4518] 30% | Training loss: 0.6873721246301693
Epoch: 31 | Iteration number: [1380/4518] 30% | Training loss: 0.6873696417912193
Epoch: 31 | Iteration number: [1390/4518] 30% | Training loss: 0.6873653872407598
Epoch: 31 | Iteration number: [1400/4518] 30% | Training loss: 0.6873725218432291
Epoch: 31 | Iteration number: [1410/4518] 31% | Training loss: 0.6873756348241306
Epoch: 31 | Iteration number: [1420/4518] 31% | Training loss: 0.6873742600142116
Epoch: 31 | Iteration number: [1430/4518] 31% | Training loss: 0.6873698620529441
Epoch: 31 | Iteration number: [1440/4518] 31% | Training loss: 0.6873644756774108
Epoch: 31 | Iteration number: [1450/4518] 32% | Training loss: 0.6873639456157027
Epoch: 31 | Iteration number: [1460/4518] 32% | Training loss: 0.6873623383780049
Epoch: 31 | Iteration number: [1470/4518] 32% | Training loss: 0.6873544668259264
Epoch: 31 | Iteration number: [1480/4518] 32% | Training loss: 0.6873603733810218
Epoch: 31 | Iteration number: [1490/4518] 32% | Training loss: 0.6873528081698705
Epoch: 31 | Iteration number: [1500/4518] 33% | Training loss: 0.6873551565408706
Epoch: 31 | Iteration number: [1510/4518] 33% | Training loss: 0.6873500430031328
Epoch: 31 | Iteration number: [1520/4518] 33% | Training loss: 0.6873493972577547
Epoch: 31 | Iteration number: [1530/4518] 33% | Training loss: 0.6873469855271134
Epoch: 31 | Iteration number: [1540/4518] 34% | Training loss: 0.6873421928325256
Epoch: 31 | Iteration number: [1550/4518] 34% | Training loss: 0.6873275503804607
Epoch: 31 | Iteration number: [1560/4518] 34% | Training loss: 0.6873227922962262
Epoch: 31 | Iteration number: [1570/4518] 34% | Training loss: 0.6873240264358035
Epoch: 31 | Iteration number: [1580/4518] 34% | Training loss: 0.687316300521923
Epoch: 31 | Iteration number: [1590/4518] 35% | Training loss: 0.6873100544296721
Epoch: 31 | Iteration number: [1600/4518] 35% | Training loss: 0.687317914403975
Epoch: 31 | Iteration number: [1610/4518] 35% | Training loss: 0.6873148466119114
Epoch: 31 | Iteration number: [1620/4518] 35% | Training loss: 0.687300870374397
Epoch: 31 | Iteration number: [1630/4518] 36% | Training loss: 0.6872912759429838
Epoch: 31 | Iteration number: [1640/4518] 36% | Training loss: 0.6872879561854572
Epoch: 31 | Iteration number: [1650/4518] 36% | Training loss: 0.6872777396259886
Epoch: 31 | Iteration number: [1660/4518] 36% | Training loss: 0.6872755179922265
Epoch: 31 | Iteration number: [1670/4518] 36% | Training loss: 0.6872658182047084
Epoch: 31 | Iteration number: [1680/4518] 37% | Training loss: 0.687261115830569
Epoch: 31 | Iteration number: [1690/4518] 37% | Training loss: 0.687259832465437
Epoch: 31 | Iteration number: [1700/4518] 37% | Training loss: 0.6872578370571136
Epoch: 31 | Iteration number: [1710/4518] 37% | Training loss: 0.687251308194378
Epoch: 31 | Iteration number: [1720/4518] 38% | Training loss: 0.6872461019213809
Epoch: 31 | Iteration number: [1730/4518] 38% | Training loss: 0.6872397847947358
Epoch: 31 | Iteration number: [1740/4518] 38% | Training loss: 0.6872398536095674
Epoch: 31 | Iteration number: [1750/4518] 38% | Training loss: 0.6872439489705222
Epoch: 31 | Iteration number: [1760/4518] 38% | Training loss: 0.6872378865087574
Epoch: 31 | Iteration number: [1770/4518] 39% | Training loss: 0.687236482780532
Epoch: 31 | Iteration number: [1780/4518] 39% | Training loss: 0.6872389795070284
Epoch: 31 | Iteration number: [1790/4518] 39% | Training loss: 0.6872309156303299
Epoch: 31 | Iteration number: [1800/4518] 39% | Training loss: 0.687230915096071
Epoch: 31 | Iteration number: [1810/4518] 40% | Training loss: 0.6872283259149414
Epoch: 31 | Iteration number: [1820/4518] 40% | Training loss: 0.6872328559448431
Epoch: 31 | Iteration number: [1830/4518] 40% | Training loss: 0.6872319759892636
Epoch: 31 | Iteration number: [1840/4518] 40% | Training loss: 0.6872335295638312
Epoch: 31 | Iteration number: [1850/4518] 40% | Training loss: 0.6872342787240002
Epoch: 31 | Iteration number: [1860/4518] 41% | Training loss: 0.6872317416052665
Epoch: 31 | Iteration number: [1870/4518] 41% | Training loss: 0.6872366077759686
Epoch: 31 | Iteration number: [1880/4518] 41% | Training loss: 0.6872338038809755
Epoch: 31 | Iteration number: [1890/4518] 41% | Training loss: 0.687239359800147
Epoch: 31 | Iteration number: [1900/4518] 42% | Training loss: 0.6872291250291623
Epoch: 31 | Iteration number: [1910/4518] 42% | Training loss: 0.6872321655612965
Epoch: 31 | Iteration number: [1920/4518] 42% | Training loss: 0.6872312145618101
Epoch: 31 | Iteration number: [1930/4518] 42% | Training loss: 0.6872236695623151
Epoch: 31 | Iteration number: [1940/4518] 42% | Training loss: 0.6872199021356622
Epoch: 31 | Iteration number: [1950/4518] 43% | Training loss: 0.6872201025791658
Epoch: 31 | Iteration number: [1960/4518] 43% | Training loss: 0.6872206743578522
Epoch: 31 | Iteration number: [1970/4518] 43% | Training loss: 0.6872162990461146
Epoch: 31 | Iteration number: [1980/4518] 43% | Training loss: 0.6872184340399925
Epoch: 31 | Iteration number: [1990/4518] 44% | Training loss: 0.6872177279175227
Epoch: 31 | Iteration number: [2000/4518] 44% | Training loss: 0.6872132029831409
Epoch: 31 | Iteration number: [2010/4518] 44% | Training loss: 0.6872100825036936
Epoch: 31 | Iteration number: [2020/4518] 44% | Training loss: 0.6872162808286082
Epoch: 31 | Iteration number: [2030/4518] 44% | Training loss: 0.6872143267704348
Epoch: 31 | Iteration number: [2040/4518] 45% | Training loss: 0.6872132989121419
Epoch: 31 | Iteration number: [2050/4518] 45% | Training loss: 0.6872147057114578
Epoch: 31 | Iteration number: [2060/4518] 45% | Training loss: 0.6872131772411679
Epoch: 31 | Iteration number: [2070/4518] 45% | Training loss: 0.6872095109184008
Epoch: 31 | Iteration number: [2080/4518] 46% | Training loss: 0.6872124345543292
Epoch: 31 | Iteration number: [2090/4518] 46% | Training loss: 0.6872121629532444
Epoch: 31 | Iteration number: [2100/4518] 46% | Training loss: 0.6872035471314476
Epoch: 31 | Iteration number: [2110/4518] 46% | Training loss: 0.6872044163010131
Epoch: 31 | Iteration number: [2120/4518] 46% | Training loss: 0.687194890542975
Epoch: 31 | Iteration number: [2130/4518] 47% | Training loss: 0.6871901730976194
Epoch: 31 | Iteration number: [2140/4518] 47% | Training loss: 0.6871956378500038
Epoch: 31 | Iteration number: [2150/4518] 47% | Training loss: 0.6871916864916335
Epoch: 31 | Iteration number: [2160/4518] 47% | Training loss: 0.6871916421309665
Epoch: 31 | Iteration number: [2170/4518] 48% | Training loss: 0.6871891338155017
Epoch: 31 | Iteration number: [2180/4518] 48% | Training loss: 0.6871880070058578
Epoch: 31 | Iteration number: [2190/4518] 48% | Training loss: 0.6871919722589728
Epoch: 31 | Iteration number: [2200/4518] 48% | Training loss: 0.6871885508027944
Epoch: 31 | Iteration number: [2210/4518] 48% | Training loss: 0.6871911393571224
Epoch: 31 | Iteration number: [2220/4518] 49% | Training loss: 0.6871912755139239
Epoch: 31 | Iteration number: [2230/4518] 49% | Training loss: 0.6871895690937213
Epoch: 31 | Iteration number: [2240/4518] 49% | Training loss: 0.6871856916695833
Epoch: 31 | Iteration number: [2250/4518] 49% | Training loss: 0.687183797650867
Epoch: 31 | Iteration number: [2260/4518] 50% | Training loss: 0.6871851016726114
Epoch: 31 | Iteration number: [2270/4518] 50% | Training loss: 0.6871828125699502
Epoch: 31 | Iteration number: [2280/4518] 50% | Training loss: 0.6871815110246341
Epoch: 31 | Iteration number: [2290/4518] 50% | Training loss: 0.6871835321838679
Epoch: 31 | Iteration number: [2300/4518] 50% | Training loss: 0.6871840843947037
Epoch: 31 | Iteration number: [2310/4518] 51% | Training loss: 0.6871881151870216
Epoch: 31 | Iteration number: [2320/4518] 51% | Training loss: 0.6871818952776235
Epoch: 31 | Iteration number: [2330/4518] 51% | Training loss: 0.687182935087466
Epoch: 31 | Iteration number: [2340/4518] 51% | Training loss: 0.6871836156417162
Epoch: 31 | Iteration number: [2350/4518] 52% | Training loss: 0.6871817998936836
Epoch: 31 | Iteration number: [2360/4518] 52% | Training loss: 0.6871835961432781
Epoch: 31 | Iteration number: [2370/4518] 52% | Training loss: 0.6871806561946869
Epoch: 31 | Iteration number: [2380/4518] 52% | Training loss: 0.6871825549281946
Epoch: 31 | Iteration number: [2390/4518] 52% | Training loss: 0.6871794583907187
Epoch: 31 | Iteration number: [2400/4518] 53% | Training loss: 0.6871789067735274
Epoch: 31 | Iteration number: [2410/4518] 53% | Training loss: 0.687175074256802
Epoch: 31 | Iteration number: [2420/4518] 53% | Training loss: 0.6871789621666443
Epoch: 31 | Iteration number: [2430/4518] 53% | Training loss: 0.687176385975669
Epoch: 31 | Iteration number: [2440/4518] 54% | Training loss: 0.6871746258413205
Epoch: 31 | Iteration number: [2450/4518] 54% | Training loss: 0.6871776780060359
Epoch: 31 | Iteration number: [2460/4518] 54% | Training loss: 0.6871742234724324
Epoch: 31 | Iteration number: [2470/4518] 54% | Training loss: 0.6871678706122796
Epoch: 31 | Iteration number: [2480/4518] 54% | Training loss: 0.6871665785870245
Epoch: 31 | Iteration number: [2490/4518] 55% | Training loss: 0.6871647236577
Epoch: 31 | Iteration number: [2500/4518] 55% | Training loss: 0.6871621551752091
Epoch: 31 | Iteration number: [2510/4518] 55% | Training loss: 0.6871560236134852
Epoch: 31 | Iteration number: [2520/4518] 55% | Training loss: 0.6871582800197222
Epoch: 31 | Iteration number: [2530/4518] 55% | Training loss: 0.6871540529925833
Epoch: 31 | Iteration number: [2540/4518] 56% | Training loss: 0.6871531229554199
Epoch: 31 | Iteration number: [2550/4518] 56% | Training loss: 0.6871510776818968
Epoch: 31 | Iteration number: [2560/4518] 56% | Training loss: 0.6871440400602296
Epoch: 31 | Iteration number: [2570/4518] 56% | Training loss: 0.6871409689406013
Epoch: 31 | Iteration number: [2580/4518] 57% | Training loss: 0.6871388544638951
Epoch: 31 | Iteration number: [2590/4518] 57% | Training loss: 0.6871405223851959
Epoch: 31 | Iteration number: [2600/4518] 57% | Training loss: 0.6871416386044943
Epoch: 31 | Iteration number: [2610/4518] 57% | Training loss: 0.6871352914421037
Epoch: 31 | Iteration number: [2620/4518] 57% | Training loss: 0.6871297407468767
Epoch: 31 | Iteration number: [2630/4518] 58% | Training loss: 0.6871237676859808
Epoch: 31 | Iteration number: [2640/4518] 58% | Training loss: 0.6871226678743507
Epoch: 31 | Iteration number: [2650/4518] 58% | Training loss: 0.6871255410617253
Epoch: 31 | Iteration number: [2660/4518] 58% | Training loss: 0.6871233987628965
Epoch: 31 | Iteration number: [2670/4518] 59% | Training loss: 0.6871174018481251
Epoch: 31 | Iteration number: [2680/4518] 59% | Training loss: 0.6871174858132405
Epoch: 31 | Iteration number: [2690/4518] 59% | Training loss: 0.6871179002146739
Epoch: 31 | Iteration number: [2700/4518] 59% | Training loss: 0.6871141094410861
Epoch: 31 | Iteration number: [2710/4518] 59% | Training loss: 0.6871157255339887
Epoch: 31 | Iteration number: [2720/4518] 60% | Training loss: 0.6871180183747235
Epoch: 31 | Iteration number: [2730/4518] 60% | Training loss: 0.687116386274715
Epoch: 31 | Iteration number: [2740/4518] 60% | Training loss: 0.6871160006436118
Epoch: 31 | Iteration number: [2750/4518] 60% | Training loss: 0.6871160777915608
Epoch: 31 | Iteration number: [2760/4518] 61% | Training loss: 0.6871158999161444
Epoch: 31 | Iteration number: [2770/4518] 61% | Training loss: 0.6871143609823303
Epoch: 31 | Iteration number: [2780/4518] 61% | Training loss: 0.687113019202253
Epoch: 31 | Iteration number: [2790/4518] 61% | Training loss: 0.6871113940806372
Epoch: 31 | Iteration number: [2800/4518] 61% | Training loss: 0.687109184222562
Epoch: 31 | Iteration number: [2810/4518] 62% | Training loss: 0.6871090410230847
Epoch: 31 | Iteration number: [2820/4518] 62% | Training loss: 0.6871096644841187
Epoch: 31 | Iteration number: [2830/4518] 62% | Training loss: 0.6871072406271742
Epoch: 31 | Iteration number: [2840/4518] 62% | Training loss: 0.6871076311653769
Epoch: 31 | Iteration number: [2850/4518] 63% | Training loss: 0.6871054413653257
Epoch: 31 | Iteration number: [2860/4518] 63% | Training loss: 0.687105582039673
Epoch: 31 | Iteration number: [2870/4518] 63% | Training loss: 0.6871043265696603
Epoch: 31 | Iteration number: [2880/4518] 63% | Training loss: 0.687105602129466
Epoch: 31 | Iteration number: [2890/4518] 63% | Training loss: 0.6871082498953004
Epoch: 31 | Iteration number: [2900/4518] 64% | Training loss: 0.6871019547561119
Epoch: 31 | Iteration number: [2910/4518] 64% | Training loss: 0.6870955345352081
Epoch: 31 | Iteration number: [2920/4518] 64% | Training loss: 0.6870953493126452
Epoch: 31 | Iteration number: [2930/4518] 64% | Training loss: 0.6870911091057513
Epoch: 31 | Iteration number: [2940/4518] 65% | Training loss: 0.6870923779043211
Epoch: 31 | Iteration number: [2950/4518] 65% | Training loss: 0.6870937485816115
Epoch: 31 | Iteration number: [2960/4518] 65% | Training loss: 0.6870932473524197
Epoch: 31 | Iteration number: [2970/4518] 65% | Training loss: 0.6870969324400931
Epoch: 31 | Iteration number: [2980/4518] 65% | Training loss: 0.6870954071515358
Epoch: 31 | Iteration number: [2990/4518] 66% | Training loss: 0.6870921753720695
Epoch: 31 | Iteration number: [3000/4518] 66% | Training loss: 0.6870931949218114
Epoch: 31 | Iteration number: [3010/4518] 66% | Training loss: 0.687090054441528
Epoch: 31 | Iteration number: [3020/4518] 66% | Training loss: 0.6870864323630238
Epoch: 31 | Iteration number: [3030/4518] 67% | Training loss: 0.6870856321880919
Epoch: 31 | Iteration number: [3040/4518] 67% | Training loss: 0.6870849130381095
Epoch: 31 | Iteration number: [3050/4518] 67% | Training loss: 0.6870845214851568
Epoch: 31 | Iteration number: [3060/4518] 67% | Training loss: 0.6870827991393657
Epoch: 31 | Iteration number: [3070/4518] 67% | Training loss: 0.687075843096556
Epoch: 31 | Iteration number: [3080/4518] 68% | Training loss: 0.6870715239218304
Epoch: 31 | Iteration number: [3090/4518] 68% | Training loss: 0.687072644418883
Epoch: 31 | Iteration number: [3100/4518] 68% | Training loss: 0.687071970662763
Epoch: 31 | Iteration number: [3110/4518] 68% | Training loss: 0.6870742401126113
Epoch: 31 | Iteration number: [3120/4518] 69% | Training loss: 0.6870725120680454
Epoch: 31 | Iteration number: [3130/4518] 69% | Training loss: 0.6870718074301942
Epoch: 31 | Iteration number: [3140/4518] 69% | Training loss: 0.6870725930876034
Epoch: 31 | Iteration number: [3150/4518] 69% | Training loss: 0.687073652365851
Epoch: 31 | Iteration number: [3160/4518] 69% | Training loss: 0.6870725774689566
Epoch: 31 | Iteration number: [3170/4518] 70% | Training loss: 0.6870724944098139
Epoch: 31 | Iteration number: [3180/4518] 70% | Training loss: 0.6870715133798947
Epoch: 31 | Iteration number: [3190/4518] 70% | Training loss: 0.6870705606421706
Epoch: 31 | Iteration number: [3200/4518] 70% | Training loss: 0.6870712726376951
Epoch: 31 | Iteration number: [3210/4518] 71% | Training loss: 0.6870687621590504
Epoch: 31 | Iteration number: [3220/4518] 71% | Training loss: 0.6870745505605426
Epoch: 31 | Iteration number: [3230/4518] 71% | Training loss: 0.6870702763644534
Epoch: 31 | Iteration number: [3240/4518] 71% | Training loss: 0.6870731632282705
Epoch: 31 | Iteration number: [3250/4518] 71% | Training loss: 0.687074100787823
Epoch: 31 | Iteration number: [3260/4518] 72% | Training loss: 0.6870677785639383
Epoch: 31 | Iteration number: [3270/4518] 72% | Training loss: 0.6870682537920249
Epoch: 31 | Iteration number: [3280/4518] 72% | Training loss: 0.6870708558254126
Epoch: 31 | Iteration number: [3290/4518] 72% | Training loss: 0.6870710119288018
Epoch: 31 | Iteration number: [3300/4518] 73% | Training loss: 0.6870718350916197
Epoch: 31 | Iteration number: [3310/4518] 73% | Training loss: 0.6870723306952646
Epoch: 31 | Iteration number: [3320/4518] 73% | Training loss: 0.6870739170406238
Epoch: 31 | Iteration number: [3330/4518] 73% | Training loss: 0.6870748150814044
Epoch: 31 | Iteration number: [3340/4518] 73% | Training loss: 0.6870714282025834
Epoch: 31 | Iteration number: [3350/4518] 74% | Training loss: 0.6870712650711857
Epoch: 31 | Iteration number: [3360/4518] 74% | Training loss: 0.6870741502514908
Epoch: 31 | Iteration number: [3370/4518] 74% | Training loss: 0.6870740071425452
Epoch: 31 | Iteration number: [3380/4518] 74% | Training loss: 0.6870748094376727
Epoch: 31 | Iteration number: [3390/4518] 75% | Training loss: 0.6870732281411995
Epoch: 31 | Iteration number: [3400/4518] 75% | Training loss: 0.687070767721709
Epoch: 31 | Iteration number: [3410/4518] 75% | Training loss: 0.687070719762282
Epoch: 31 | Iteration number: [3420/4518] 75% | Training loss: 0.6870706035379778
Epoch: 31 | Iteration number: [3430/4518] 75% | Training loss: 0.6870686708143084
Epoch: 31 | Iteration number: [3440/4518] 76% | Training loss: 0.6870660418341327
Epoch: 31 | Iteration number: [3450/4518] 76% | Training loss: 0.6870650153574737
Epoch: 31 | Iteration number: [3460/4518] 76% | Training loss: 0.68706480679829
Epoch: 31 | Iteration number: [3470/4518] 76% | Training loss: 0.6870629665659209
Epoch: 31 | Iteration number: [3480/4518] 77% | Training loss: 0.6870625042367255
Epoch: 31 | Iteration number: [3490/4518] 77% | Training loss: 0.6870590166922627
Epoch: 31 | Iteration number: [3500/4518] 77% | Training loss: 0.687059469972338
Epoch: 31 | Iteration number: [3510/4518] 77% | Training loss: 0.6870554688309672
Epoch: 31 | Iteration number: [3520/4518] 77% | Training loss: 0.6870546577328985
Epoch: 31 | Iteration number: [3530/4518] 78% | Training loss: 0.6870555675063525
Epoch: 31 | Iteration number: [3540/4518] 78% | Training loss: 0.6870512663812961
Epoch: 31 | Iteration number: [3550/4518] 78% | Training loss: 0.6870531874643245
Epoch: 31 | Iteration number: [3560/4518] 78% | Training loss: 0.687053322808796
Epoch: 31 | Iteration number: [3570/4518] 79% | Training loss: 0.6870525747788052
Epoch: 31 | Iteration number: [3580/4518] 79% | Training loss: 0.6870505718712034
Epoch: 31 | Iteration number: [3590/4518] 79% | Training loss: 0.6870482276409118
Epoch: 31 | Iteration number: [3600/4518] 79% | Training loss: 0.6870457860330741
Epoch: 31 | Iteration number: [3610/4518] 79% | Training loss: 0.6870465075540411
Epoch: 31 | Iteration number: [3620/4518] 80% | Training loss: 0.6870474911691076
Epoch: 31 | Iteration number: [3630/4518] 80% | Training loss: 0.6870473128212385
Epoch: 31 | Iteration number: [3640/4518] 80% | Training loss: 0.6870509707829454
Epoch: 31 | Iteration number: [3650/4518] 80% | Training loss: 0.6870473893211313
Epoch: 31 | Iteration number: [3660/4518] 81% | Training loss: 0.6870448410511016
Epoch: 31 | Iteration number: [3670/4518] 81% | Training loss: 0.687049291991408
Epoch: 31 | Iteration number: [3680/4518] 81% | Training loss: 0.6870478207812362
Epoch: 31 | Iteration number: [3690/4518] 81% | Training loss: 0.687047655101068
Epoch: 31 | Iteration number: [3700/4518] 81% | Training loss: 0.6870458739190488
Epoch: 31 | Iteration number: [3710/4518] 82% | Training loss: 0.6870425488588945
Epoch: 31 | Iteration number: [3720/4518] 82% | Training loss: 0.6870378713774424
Epoch: 31 | Iteration number: [3730/4518] 82% | Training loss: 0.6870384752111205
Epoch: 31 | Iteration number: [3740/4518] 82% | Training loss: 0.6870341372999915
Epoch: 31 | Iteration number: [3750/4518] 83% | Training loss: 0.6870359998861949
Epoch: 31 | Iteration number: [3760/4518] 83% | Training loss: 0.6870336989297512
Epoch: 31 | Iteration number: [3770/4518] 83% | Training loss: 0.6870283717185812
Epoch: 31 | Iteration number: [3780/4518] 83% | Training loss: 0.6870280593791336
Epoch: 31 | Iteration number: [3790/4518] 83% | Training loss: 0.687027342133912
Epoch: 31 | Iteration number: [3800/4518] 84% | Training loss: 0.6870274633953446
Epoch: 31 | Iteration number: [3810/4518] 84% | Training loss: 0.6870220002852713
Epoch: 31 | Iteration number: [3820/4518] 84% | Training loss: 0.6870219582662532
Epoch: 31 | Iteration number: [3830/4518] 84% | Training loss: 0.6870258805490349
Epoch: 31 | Iteration number: [3840/4518] 84% | Training loss: 0.6870250924956054
Epoch: 31 | Iteration number: [3850/4518] 85% | Training loss: 0.6870269490836503
Epoch: 31 | Iteration number: [3860/4518] 85% | Training loss: 0.6870223703162041
Epoch: 31 | Iteration number: [3870/4518] 85% | Training loss: 0.6870210955925382
Epoch: 31 | Iteration number: [3880/4518] 85% | Training loss: 0.6870209646286424
Epoch: 31 | Iteration number: [3890/4518] 86% | Training loss: 0.6870190642333582
Epoch: 31 | Iteration number: [3900/4518] 86% | Training loss: 0.6870166773673816
Epoch: 31 | Iteration number: [3910/4518] 86% | Training loss: 0.6870173178365468
Epoch: 31 | Iteration number: [3920/4518] 86% | Training loss: 0.6870180096097138
Epoch: 31 | Iteration number: [3930/4518] 86% | Training loss: 0.6870181382764083
Epoch: 31 | Iteration number: [3940/4518] 87% | Training loss: 0.6870172165674606
Epoch: 31 | Iteration number: [3950/4518] 87% | Training loss: 0.6870150257062309
Epoch: 31 | Iteration number: [3960/4518] 87% | Training loss: 0.6870144702268369
Epoch: 31 | Iteration number: [3970/4518] 87% | Training loss: 0.6870156705679762
Epoch: 31 | Iteration number: [3980/4518] 88% | Training loss: 0.6870141720352461
Epoch: 31 | Iteration number: [3990/4518] 88% | Training loss: 0.687014089013102
Epoch: 31 | Iteration number: [4000/4518] 88% | Training loss: 0.6870118967890739
Epoch: 31 | Iteration number: [4010/4518] 88% | Training loss: 0.6870108479127622
Epoch: 31 | Iteration number: [4020/4518] 88% | Training loss: 0.6870118737220764
Epoch: 31 | Iteration number: [4030/4518] 89% | Training loss: 0.6870121158086336
Epoch: 31 | Iteration number: [4040/4518] 89% | Training loss: 0.6870105907320976
Epoch: 31 | Iteration number: [4050/4518] 89% | Training loss: 0.6870105187245357
Epoch: 31 | Iteration number: [4060/4518] 89% | Training loss: 0.6870095536333
Epoch: 31 | Iteration number: [4070/4518] 90% | Training loss: 0.6870109575532871
Epoch: 31 | Iteration number: [4080/4518] 90% | Training loss: 0.6870098106709182
Epoch: 31 | Iteration number: [4090/4518] 90% | Training loss: 0.6870087082345212
Epoch: 31 | Iteration number: [4100/4518] 90% | Training loss: 0.6870084258695928
Epoch: 31 | Iteration number: [4110/4518] 90% | Training loss: 0.6870090052159163
Epoch: 31 | Iteration number: [4120/4518] 91% | Training loss: 0.6870095721726278
Epoch: 31 | Iteration number: [4130/4518] 91% | Training loss: 0.6870074565560708
Epoch: 31 | Iteration number: [4140/4518] 91% | Training loss: 0.6870058493193797
Epoch: 31 | Iteration number: [4150/4518] 91% | Training loss: 0.6870082091997904
Epoch: 31 | Iteration number: [4160/4518] 92% | Training loss: 0.6870075174678977
Epoch: 31 | Iteration number: [4170/4518] 92% | Training loss: 0.6870070016784348
Epoch: 31 | Iteration number: [4180/4518] 92% | Training loss: 0.6870072853764849
Epoch: 31 | Iteration number: [4190/4518] 92% | Training loss: 0.6870054374162223
Epoch: 31 | Iteration number: [4200/4518] 92% | Training loss: 0.6870042075997307
Epoch: 31 | Iteration number: [4210/4518] 93% | Training loss: 0.6870034544173442
Epoch: 31 | Iteration number: [4220/4518] 93% | Training loss: 0.6870015226975437
Epoch: 31 | Iteration number: [4230/4518] 93% | Training loss: 0.6870018013121106
Epoch: 31 | Iteration number: [4240/4518] 93% | Training loss: 0.6870055807930119
Epoch: 31 | Iteration number: [4250/4518] 94% | Training loss: 0.687005037910798
Epoch: 31 | Iteration number: [4260/4518] 94% | Training loss: 0.687005536153283
Epoch: 31 | Iteration number: [4270/4518] 94% | Training loss: 0.6870052104113532
Epoch: 31 | Iteration number: [4280/4518] 94% | Training loss: 0.6870067253708839
Epoch: 31 | Iteration number: [4290/4518] 94% | Training loss: 0.6870060296464355
Epoch: 31 | Iteration number: [4300/4518] 95% | Training loss: 0.6870033240179683
Epoch: 31 | Iteration number: [4310/4518] 95% | Training loss: 0.6870027447244684
Epoch: 31 | Iteration number: [4320/4518] 95% | Training loss: 0.6870027722583877
Epoch: 31 | Iteration number: [4330/4518] 95% | Training loss: 0.6870031807907184
Epoch: 31 | Iteration number: [4340/4518] 96% | Training loss: 0.6870013543537685
Epoch: 31 | Iteration number: [4350/4518] 96% | Training loss: 0.6870055766763359
Epoch: 31 | Iteration number: [4360/4518] 96% | Training loss: 0.6870052632388719
Epoch: 31 | Iteration number: [4370/4518] 96% | Training loss: 0.6870046365179241
Epoch: 31 | Iteration number: [4380/4518] 96% | Training loss: 0.6870059113524276
Epoch: 31 | Iteration number: [4390/4518] 97% | Training loss: 0.6870056196470196
Epoch: 31 | Iteration number: [4400/4518] 97% | Training loss: 0.6870027341354977
Epoch: 31 | Iteration number: [4410/4518] 97% | Training loss: 0.6870047317205373
Epoch: 31 | Iteration number: [4420/4518] 97% | Training loss: 0.6870065472649234
Epoch: 31 | Iteration number: [4430/4518] 98% | Training loss: 0.6870073559590979
Epoch: 31 | Iteration number: [4440/4518] 98% | Training loss: 0.6870084359167933
Epoch: 31 | Iteration number: [4450/4518] 98% | Training loss: 0.6870063402411644
Epoch: 31 | Iteration number: [4460/4518] 98% | Training loss: 0.6870070420439468
Epoch: 31 | Iteration number: [4470/4518] 98% | Training loss: 0.6870060473347137
Epoch: 31 | Iteration number: [4480/4518] 99% | Training loss: 0.6870052571275405
Epoch: 31 | Iteration number: [4490/4518] 99% | Training loss: 0.6870076324599889
Epoch: 31 | Iteration number: [4500/4518] 99% | Training loss: 0.6870092055930032
Epoch: 31 | Iteration number: [4510/4518] 99% | Training loss: 0.6870101720821566

 End of epoch: 31 | Train Loss: 0.6868577193058186 | Training Time: 642 

 End of epoch: 31 | Eval Loss: 0.6902344239001371 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/4518] 0% | Training loss: 0.7554928541183472
Epoch: 32 | Iteration number: [20/4518] 0% | Training loss: 0.7210180759429932
Epoch: 32 | Iteration number: [30/4518] 0% | Training loss: 0.7100275834401448
Epoch: 32 | Iteration number: [40/4518] 0% | Training loss: 0.704287301003933
Epoch: 32 | Iteration number: [50/4518] 1% | Training loss: 0.7007102608680725
Epoch: 32 | Iteration number: [60/4518] 1% | Training loss: 0.6983236531416576
Epoch: 32 | Iteration number: [70/4518] 1% | Training loss: 0.696730957712446
Epoch: 32 | Iteration number: [80/4518] 1% | Training loss: 0.6955544374883175
Epoch: 32 | Iteration number: [90/4518] 1% | Training loss: 0.6946407470438215
Epoch: 32 | Iteration number: [100/4518] 2% | Training loss: 0.6937915080785751
Epoch: 32 | Iteration number: [110/4518] 2% | Training loss: 0.6931928119876168
Epoch: 32 | Iteration number: [120/4518] 2% | Training loss: 0.692732893427213
Epoch: 32 | Iteration number: [130/4518] 2% | Training loss: 0.6922180212461031
Epoch: 32 | Iteration number: [140/4518] 3% | Training loss: 0.6917315257447106
Epoch: 32 | Iteration number: [150/4518] 3% | Training loss: 0.6914721763134003
Epoch: 32 | Iteration number: [160/4518] 3% | Training loss: 0.6911177821457386
Epoch: 32 | Iteration number: [170/4518] 3% | Training loss: 0.6909107909483068
Epoch: 32 | Iteration number: [180/4518] 3% | Training loss: 0.6906899617777931
Epoch: 32 | Iteration number: [190/4518] 4% | Training loss: 0.6905534753673955
Epoch: 32 | Iteration number: [200/4518] 4% | Training loss: 0.6903613290190697
Epoch: 32 | Iteration number: [210/4518] 4% | Training loss: 0.6902313221068609
Epoch: 32 | Iteration number: [220/4518] 4% | Training loss: 0.6900934387337078
Epoch: 32 | Iteration number: [230/4518] 5% | Training loss: 0.6899394188238227
Epoch: 32 | Iteration number: [240/4518] 5% | Training loss: 0.68982611844937
Epoch: 32 | Iteration number: [250/4518] 5% | Training loss: 0.6896517105102539
Epoch: 32 | Iteration number: [260/4518] 5% | Training loss: 0.689559408563834
Epoch: 32 | Iteration number: [270/4518] 5% | Training loss: 0.6894486142529381
Epoch: 32 | Iteration number: [280/4518] 6% | Training loss: 0.6893142902425358
Epoch: 32 | Iteration number: [290/4518] 6% | Training loss: 0.6892140536472715
Epoch: 32 | Iteration number: [300/4518] 6% | Training loss: 0.689142111937205
Epoch: 32 | Iteration number: [310/4518] 6% | Training loss: 0.6890624940395356
Epoch: 32 | Iteration number: [320/4518] 7% | Training loss: 0.6889847325161099
Epoch: 32 | Iteration number: [330/4518] 7% | Training loss: 0.6889306212916518
Epoch: 32 | Iteration number: [340/4518] 7% | Training loss: 0.6888565785744611
Epoch: 32 | Iteration number: [350/4518] 7% | Training loss: 0.6887586007799421
Epoch: 32 | Iteration number: [360/4518] 7% | Training loss: 0.6887074078122775
Epoch: 32 | Iteration number: [370/4518] 8% | Training loss: 0.6886958740852974
Epoch: 32 | Iteration number: [380/4518] 8% | Training loss: 0.6886712160549666
Epoch: 32 | Iteration number: [390/4518] 8% | Training loss: 0.6886257517032134
Epoch: 32 | Iteration number: [400/4518] 8% | Training loss: 0.6886032947897911
Epoch: 32 | Iteration number: [410/4518] 9% | Training loss: 0.6885492646112674
Epoch: 32 | Iteration number: [420/4518] 9% | Training loss: 0.6885182257209506
Epoch: 32 | Iteration number: [430/4518] 9% | Training loss: 0.6884612908197004
Epoch: 32 | Iteration number: [440/4518] 9% | Training loss: 0.6884280349720608
Epoch: 32 | Iteration number: [450/4518] 9% | Training loss: 0.6883991311656105
Epoch: 32 | Iteration number: [460/4518] 10% | Training loss: 0.6883375590262206
Epoch: 32 | Iteration number: [470/4518] 10% | Training loss: 0.6882884686297559
Epoch: 32 | Iteration number: [480/4518] 10% | Training loss: 0.6882570003469785
Epoch: 32 | Iteration number: [490/4518] 10% | Training loss: 0.6882383797849928
Epoch: 32 | Iteration number: [500/4518] 11% | Training loss: 0.6882120337486267
Epoch: 32 | Iteration number: [510/4518] 11% | Training loss: 0.6881764701768464
Epoch: 32 | Iteration number: [520/4518] 11% | Training loss: 0.6881631494714664
Epoch: 32 | Iteration number: [530/4518] 11% | Training loss: 0.6881447902265585
Epoch: 32 | Iteration number: [540/4518] 11% | Training loss: 0.6881221232590852
Epoch: 32 | Iteration number: [550/4518] 12% | Training loss: 0.6880897864428434
Epoch: 32 | Iteration number: [560/4518] 12% | Training loss: 0.6880577705800534
Epoch: 32 | Iteration number: [570/4518] 12% | Training loss: 0.6880259971869619
Epoch: 32 | Iteration number: [580/4518] 12% | Training loss: 0.6879929863173386
Epoch: 32 | Iteration number: [590/4518] 13% | Training loss: 0.6879796356467878
Epoch: 32 | Iteration number: [600/4518] 13% | Training loss: 0.6879788964986802
Epoch: 32 | Iteration number: [610/4518] 13% | Training loss: 0.6879354012794182
Epoch: 32 | Iteration number: [620/4518] 13% | Training loss: 0.6879255572634358
Epoch: 32 | Iteration number: [630/4518] 13% | Training loss: 0.6878972921106551
Epoch: 32 | Iteration number: [640/4518] 14% | Training loss: 0.6878838462755084
Epoch: 32 | Iteration number: [650/4518] 14% | Training loss: 0.6878711343728579
Epoch: 32 | Iteration number: [660/4518] 14% | Training loss: 0.6878395330725294
Epoch: 32 | Iteration number: [670/4518] 14% | Training loss: 0.6878347620145598
Epoch: 32 | Iteration number: [680/4518] 15% | Training loss: 0.6878058362533065
Epoch: 32 | Iteration number: [690/4518] 15% | Training loss: 0.6878029115822004
Epoch: 32 | Iteration number: [700/4518] 15% | Training loss: 0.6878271037340165
Epoch: 32 | Iteration number: [710/4518] 15% | Training loss: 0.6878411173820496
Epoch: 32 | Iteration number: [720/4518] 15% | Training loss: 0.6878077381187016
Epoch: 32 | Iteration number: [730/4518] 16% | Training loss: 0.6877822218692466
Epoch: 32 | Iteration number: [740/4518] 16% | Training loss: 0.6877706708134832
Epoch: 32 | Iteration number: [750/4518] 16% | Training loss: 0.6877786072889964
Epoch: 32 | Iteration number: [760/4518] 16% | Training loss: 0.6877648049279264
Epoch: 32 | Iteration number: [770/4518] 17% | Training loss: 0.6877344318024524
Epoch: 32 | Iteration number: [780/4518] 17% | Training loss: 0.6877224094592608
Epoch: 32 | Iteration number: [790/4518] 17% | Training loss: 0.6876944615871091
Epoch: 32 | Iteration number: [800/4518] 17% | Training loss: 0.6876887822896243
Epoch: 32 | Iteration number: [810/4518] 17% | Training loss: 0.6876767109205694
Epoch: 32 | Iteration number: [820/4518] 18% | Training loss: 0.68765880698111
Epoch: 32 | Iteration number: [830/4518] 18% | Training loss: 0.687647189074252
Epoch: 32 | Iteration number: [840/4518] 18% | Training loss: 0.6876545652747155
Epoch: 32 | Iteration number: [850/4518] 18% | Training loss: 0.6876448075210347
Epoch: 32 | Iteration number: [860/4518] 19% | Training loss: 0.6876319758420767
Epoch: 32 | Iteration number: [870/4518] 19% | Training loss: 0.687622714316708
Epoch: 32 | Iteration number: [880/4518] 19% | Training loss: 0.6876240652393211
Epoch: 32 | Iteration number: [890/4518] 19% | Training loss: 0.6876023219542557
Epoch: 32 | Iteration number: [900/4518] 19% | Training loss: 0.6875976478391224
Epoch: 32 | Iteration number: [910/4518] 20% | Training loss: 0.6875891567586543
Epoch: 32 | Iteration number: [920/4518] 20% | Training loss: 0.6875728546925213
Epoch: 32 | Iteration number: [930/4518] 20% | Training loss: 0.687571140578998
Epoch: 32 | Iteration number: [940/4518] 20% | Training loss: 0.6875598672222584
Epoch: 32 | Iteration number: [950/4518] 21% | Training loss: 0.6875512764328404
Epoch: 32 | Iteration number: [960/4518] 21% | Training loss: 0.6875517141694824
Epoch: 32 | Iteration number: [970/4518] 21% | Training loss: 0.6875517328989874
Epoch: 32 | Iteration number: [980/4518] 21% | Training loss: 0.6875338227773199
Epoch: 32 | Iteration number: [990/4518] 21% | Training loss: 0.687519662187557
Epoch: 32 | Iteration number: [1000/4518] 22% | Training loss: 0.6875239487886429
Epoch: 32 | Iteration number: [1010/4518] 22% | Training loss: 0.6875288406220993
Epoch: 32 | Iteration number: [1020/4518] 22% | Training loss: 0.6875299218822928
Epoch: 32 | Iteration number: [1030/4518] 22% | Training loss: 0.6875211866735255
Epoch: 32 | Iteration number: [1040/4518] 23% | Training loss: 0.6875010912234967
Epoch: 32 | Iteration number: [1050/4518] 23% | Training loss: 0.6874955849420457
Epoch: 32 | Iteration number: [1060/4518] 23% | Training loss: 0.6874945146857567
Epoch: 32 | Iteration number: [1070/4518] 23% | Training loss: 0.6874889232287897
Epoch: 32 | Iteration number: [1080/4518] 23% | Training loss: 0.6874758814220076
Epoch: 32 | Iteration number: [1090/4518] 24% | Training loss: 0.6874797911818968
Epoch: 32 | Iteration number: [1100/4518] 24% | Training loss: 0.6874659199064428
Epoch: 32 | Iteration number: [1110/4518] 24% | Training loss: 0.6874599216220615
Epoch: 32 | Iteration number: [1120/4518] 24% | Training loss: 0.687450654857925
Epoch: 32 | Iteration number: [1130/4518] 25% | Training loss: 0.6874505259294426
Epoch: 32 | Iteration number: [1140/4518] 25% | Training loss: 0.6874481534225899
Epoch: 32 | Iteration number: [1150/4518] 25% | Training loss: 0.687427119690439
Epoch: 32 | Iteration number: [1160/4518] 25% | Training loss: 0.6874210931103805
Epoch: 32 | Iteration number: [1170/4518] 25% | Training loss: 0.6874104548213829
Epoch: 32 | Iteration number: [1180/4518] 26% | Training loss: 0.6874025273121009
Epoch: 32 | Iteration number: [1190/4518] 26% | Training loss: 0.6873959094536405
Epoch: 32 | Iteration number: [1200/4518] 26% | Training loss: 0.6873793751498063
Epoch: 32 | Iteration number: [1210/4518] 26% | Training loss: 0.6873822124043772
Epoch: 32 | Iteration number: [1220/4518] 27% | Training loss: 0.6873685680940503
Epoch: 32 | Iteration number: [1230/4518] 27% | Training loss: 0.6873702025995022
Epoch: 32 | Iteration number: [1240/4518] 27% | Training loss: 0.6873609308273562
Epoch: 32 | Iteration number: [1250/4518] 27% | Training loss: 0.6873597595691681
Epoch: 32 | Iteration number: [1260/4518] 27% | Training loss: 0.6873533366691499
Epoch: 32 | Iteration number: [1270/4518] 28% | Training loss: 0.6873404079065548
Epoch: 32 | Iteration number: [1280/4518] 28% | Training loss: 0.6873445861507207
Epoch: 32 | Iteration number: [1290/4518] 28% | Training loss: 0.6873324621555417
Epoch: 32 | Iteration number: [1300/4518] 28% | Training loss: 0.6873288126633718
Epoch: 32 | Iteration number: [1310/4518] 28% | Training loss: 0.6873299499049441
Epoch: 32 | Iteration number: [1320/4518] 29% | Training loss: 0.6873296931837545
Epoch: 32 | Iteration number: [1330/4518] 29% | Training loss: 0.6873224489222792
Epoch: 32 | Iteration number: [1340/4518] 29% | Training loss: 0.6873241577130645
Epoch: 32 | Iteration number: [1350/4518] 29% | Training loss: 0.6873228184382121
Epoch: 32 | Iteration number: [1360/4518] 30% | Training loss: 0.6873158384771908
Epoch: 32 | Iteration number: [1370/4518] 30% | Training loss: 0.6873094789738202
Epoch: 32 | Iteration number: [1380/4518] 30% | Training loss: 0.6873092815927837
Epoch: 32 | Iteration number: [1390/4518] 30% | Training loss: 0.6873054982946931
Epoch: 32 | Iteration number: [1400/4518] 30% | Training loss: 0.6872971044267927
Epoch: 32 | Iteration number: [1410/4518] 31% | Training loss: 0.6872919758160909
Epoch: 32 | Iteration number: [1420/4518] 31% | Training loss: 0.6872831782404806
Epoch: 32 | Iteration number: [1430/4518] 31% | Training loss: 0.6872864050465031
Epoch: 32 | Iteration number: [1440/4518] 31% | Training loss: 0.6872857333885298
Epoch: 32 | Iteration number: [1450/4518] 32% | Training loss: 0.6872721156991761
Epoch: 32 | Iteration number: [1460/4518] 32% | Training loss: 0.6872723401001055
Epoch: 32 | Iteration number: [1470/4518] 32% | Training loss: 0.6872642697525673
Epoch: 32 | Iteration number: [1480/4518] 32% | Training loss: 0.6872691223347509
Epoch: 32 | Iteration number: [1490/4518] 32% | Training loss: 0.6872604746546521
Epoch: 32 | Iteration number: [1500/4518] 33% | Training loss: 0.6872661296526591
Epoch: 32 | Iteration number: [1510/4518] 33% | Training loss: 0.6872682018390555
Epoch: 32 | Iteration number: [1520/4518] 33% | Training loss: 0.6872641382248779
Epoch: 32 | Iteration number: [1530/4518] 33% | Training loss: 0.6872560062439613
Epoch: 32 | Iteration number: [1540/4518] 34% | Training loss: 0.6872566492526562
Epoch: 32 | Iteration number: [1550/4518] 34% | Training loss: 0.6872576032915423
Epoch: 32 | Iteration number: [1560/4518] 34% | Training loss: 0.6872543441561553
Epoch: 32 | Iteration number: [1570/4518] 34% | Training loss: 0.6872451179346462
Epoch: 32 | Iteration number: [1580/4518] 34% | Training loss: 0.6872364716062063
Epoch: 32 | Iteration number: [1590/4518] 35% | Training loss: 0.687229618973702
Epoch: 32 | Iteration number: [1600/4518] 35% | Training loss: 0.6872236884012818
Epoch: 32 | Iteration number: [1610/4518] 35% | Training loss: 0.6872161046318386
Epoch: 32 | Iteration number: [1620/4518] 35% | Training loss: 0.6872127480345008
Epoch: 32 | Iteration number: [1630/4518] 36% | Training loss: 0.6872091853179815
Epoch: 32 | Iteration number: [1640/4518] 36% | Training loss: 0.6872100436105961
Epoch: 32 | Iteration number: [1650/4518] 36% | Training loss: 0.6872098431081483
Epoch: 32 | Iteration number: [1660/4518] 36% | Training loss: 0.6872052833617451
Epoch: 32 | Iteration number: [1670/4518] 36% | Training loss: 0.6872050166130066
Epoch: 32 | Iteration number: [1680/4518] 37% | Training loss: 0.6872016019054822
Epoch: 32 | Iteration number: [1690/4518] 37% | Training loss: 0.6872062106809672
Epoch: 32 | Iteration number: [1700/4518] 37% | Training loss: 0.6872026444182676
Epoch: 32 | Iteration number: [1710/4518] 37% | Training loss: 0.6872042749708857
Epoch: 32 | Iteration number: [1720/4518] 38% | Training loss: 0.6872005227000214
Epoch: 32 | Iteration number: [1730/4518] 38% | Training loss: 0.68720049448096
Epoch: 32 | Iteration number: [1740/4518] 38% | Training loss: 0.6871977260057953
Epoch: 32 | Iteration number: [1750/4518] 38% | Training loss: 0.6871958260876792
Epoch: 32 | Iteration number: [1760/4518] 38% | Training loss: 0.687193550304933
Epoch: 32 | Iteration number: [1770/4518] 39% | Training loss: 0.6871957501112405
Epoch: 32 | Iteration number: [1780/4518] 39% | Training loss: 0.6871846563025806
Epoch: 32 | Iteration number: [1790/4518] 39% | Training loss: 0.6871809568818055
Epoch: 32 | Iteration number: [1800/4518] 39% | Training loss: 0.6871807776557075
Epoch: 32 | Iteration number: [1810/4518] 40% | Training loss: 0.6871821139069552
Epoch: 32 | Iteration number: [1820/4518] 40% | Training loss: 0.687179953285626
Epoch: 32 | Iteration number: [1830/4518] 40% | Training loss: 0.6871821035778588
Epoch: 32 | Iteration number: [1840/4518] 40% | Training loss: 0.6871780683812888
Epoch: 32 | Iteration number: [1850/4518] 40% | Training loss: 0.6871785813408929
Epoch: 32 | Iteration number: [1860/4518] 41% | Training loss: 0.6871810410932828
Epoch: 32 | Iteration number: [1870/4518] 41% | Training loss: 0.6871737887515104
Epoch: 32 | Iteration number: [1880/4518] 41% | Training loss: 0.6871711463687268
Epoch: 32 | Iteration number: [1890/4518] 41% | Training loss: 0.6871763072947346
Epoch: 32 | Iteration number: [1900/4518] 42% | Training loss: 0.6871747354457253
Epoch: 32 | Iteration number: [1910/4518] 42% | Training loss: 0.687174227537285
Epoch: 32 | Iteration number: [1920/4518] 42% | Training loss: 0.6871718267599741
Epoch: 32 | Iteration number: [1930/4518] 42% | Training loss: 0.6871665186832606
Epoch: 32 | Iteration number: [1940/4518] 42% | Training loss: 0.6871653775271681
Epoch: 32 | Iteration number: [1950/4518] 43% | Training loss: 0.6871629512921358
Epoch: 32 | Iteration number: [1960/4518] 43% | Training loss: 0.6871595064292149
Epoch: 32 | Iteration number: [1970/4518] 43% | Training loss: 0.687160519960568
Epoch: 32 | Iteration number: [1980/4518] 43% | Training loss: 0.6871543733158497
Epoch: 32 | Iteration number: [1990/4518] 44% | Training loss: 0.6871518499288127
Epoch: 32 | Iteration number: [2000/4518] 44% | Training loss: 0.6871463345587253
Epoch: 32 | Iteration number: [2010/4518] 44% | Training loss: 0.6871501418488536
Epoch: 32 | Iteration number: [2020/4518] 44% | Training loss: 0.6871490506547513
Epoch: 32 | Iteration number: [2030/4518] 44% | Training loss: 0.6871458920058359
Epoch: 32 | Iteration number: [2040/4518] 45% | Training loss: 0.6871468376003059
Epoch: 32 | Iteration number: [2050/4518] 45% | Training loss: 0.6871437740907437
Epoch: 32 | Iteration number: [2060/4518] 45% | Training loss: 0.68713316894272
Epoch: 32 | Iteration number: [2070/4518] 45% | Training loss: 0.687132437678351
Epoch: 32 | Iteration number: [2080/4518] 46% | Training loss: 0.6871270815913494
Epoch: 32 | Iteration number: [2090/4518] 46% | Training loss: 0.6871242301600972
Epoch: 32 | Iteration number: [2100/4518] 46% | Training loss: 0.6871186061700185
Epoch: 32 | Iteration number: [2110/4518] 46% | Training loss: 0.6871193157553108
Epoch: 32 | Iteration number: [2120/4518] 46% | Training loss: 0.6871125957875882
Epoch: 32 | Iteration number: [2130/4518] 47% | Training loss: 0.687120004215151
Epoch: 32 | Iteration number: [2140/4518] 47% | Training loss: 0.6871176134760135
Epoch: 32 | Iteration number: [2150/4518] 47% | Training loss: 0.6871161392400431
Epoch: 32 | Iteration number: [2160/4518] 47% | Training loss: 0.6871136078680004
Epoch: 32 | Iteration number: [2170/4518] 48% | Training loss: 0.6871181555882028
Epoch: 32 | Iteration number: [2180/4518] 48% | Training loss: 0.6871205902427708
Epoch: 32 | Iteration number: [2190/4518] 48% | Training loss: 0.6871203884142174
Epoch: 32 | Iteration number: [2200/4518] 48% | Training loss: 0.6871152860739015
Epoch: 32 | Iteration number: [2210/4518] 48% | Training loss: 0.6871183766229121
Epoch: 32 | Iteration number: [2220/4518] 49% | Training loss: 0.6871242961099556
Epoch: 32 | Iteration number: [2230/4518] 49% | Training loss: 0.6871195831373668
Epoch: 32 | Iteration number: [2240/4518] 49% | Training loss: 0.6871212634391018
Epoch: 32 | Iteration number: [2250/4518] 49% | Training loss: 0.6871144824292925
Epoch: 32 | Iteration number: [2260/4518] 50% | Training loss: 0.6871136058484558
Epoch: 32 | Iteration number: [2270/4518] 50% | Training loss: 0.6871107508432498
Epoch: 32 | Iteration number: [2280/4518] 50% | Training loss: 0.6871097477904538
Epoch: 32 | Iteration number: [2290/4518] 50% | Training loss: 0.6871148476434066
Epoch: 32 | Iteration number: [2300/4518] 50% | Training loss: 0.6871142819912537
Epoch: 32 | Iteration number: [2310/4518] 51% | Training loss: 0.6871122765334654
Epoch: 32 | Iteration number: [2320/4518] 51% | Training loss: 0.6871173694729805
Epoch: 32 | Iteration number: [2330/4518] 51% | Training loss: 0.6871199259430554
Epoch: 32 | Iteration number: [2340/4518] 51% | Training loss: 0.6871186866974219
Epoch: 32 | Iteration number: [2350/4518] 52% | Training loss: 0.6871168431068988
Epoch: 32 | Iteration number: [2360/4518] 52% | Training loss: 0.6871187605847746
Epoch: 32 | Iteration number: [2370/4518] 52% | Training loss: 0.6871186210133355
Epoch: 32 | Iteration number: [2380/4518] 52% | Training loss: 0.687118570243611
Epoch: 32 | Iteration number: [2390/4518] 52% | Training loss: 0.6871213982793577
Epoch: 32 | Iteration number: [2400/4518] 53% | Training loss: 0.6871224098404248
Epoch: 32 | Iteration number: [2410/4518] 53% | Training loss: 0.687121568057547
Epoch: 32 | Iteration number: [2420/4518] 53% | Training loss: 0.6871163280542232
Epoch: 32 | Iteration number: [2430/4518] 53% | Training loss: 0.6871185236261705
Epoch: 32 | Iteration number: [2440/4518] 54% | Training loss: 0.6871202880730395
Epoch: 32 | Iteration number: [2450/4518] 54% | Training loss: 0.6871199095735745
Epoch: 32 | Iteration number: [2460/4518] 54% | Training loss: 0.6871178294585003
Epoch: 32 | Iteration number: [2470/4518] 54% | Training loss: 0.6871187334118585
Epoch: 32 | Iteration number: [2480/4518] 54% | Training loss: 0.6871186804627218
Epoch: 32 | Iteration number: [2490/4518] 55% | Training loss: 0.6871171145314673
Epoch: 32 | Iteration number: [2500/4518] 55% | Training loss: 0.6871186798810959
Epoch: 32 | Iteration number: [2510/4518] 55% | Training loss: 0.6871151656031134
Epoch: 32 | Iteration number: [2520/4518] 55% | Training loss: 0.6871113086267123
Epoch: 32 | Iteration number: [2530/4518] 55% | Training loss: 0.6871131964823003
Epoch: 32 | Iteration number: [2540/4518] 56% | Training loss: 0.6871174072421442
Epoch: 32 | Iteration number: [2550/4518] 56% | Training loss: 0.6871181296133527
Epoch: 32 | Iteration number: [2560/4518] 56% | Training loss: 0.687117234035395
Epoch: 32 | Iteration number: [2570/4518] 56% | Training loss: 0.6871202393960396
Epoch: 32 | Iteration number: [2580/4518] 57% | Training loss: 0.6871225858612579
Epoch: 32 | Iteration number: [2590/4518] 57% | Training loss: 0.6871220285137648
Epoch: 32 | Iteration number: [2600/4518] 57% | Training loss: 0.6871243723768454
Epoch: 32 | Iteration number: [2610/4518] 57% | Training loss: 0.6871222187047717
Epoch: 32 | Iteration number: [2620/4518] 57% | Training loss: 0.6871197820164775
Epoch: 32 | Iteration number: [2630/4518] 58% | Training loss: 0.6871145237081404
Epoch: 32 | Iteration number: [2640/4518] 58% | Training loss: 0.6871073081186323
Epoch: 32 | Iteration number: [2650/4518] 58% | Training loss: 0.6871083489678941
Epoch: 32 | Iteration number: [2660/4518] 58% | Training loss: 0.6871061652898789
Epoch: 32 | Iteration number: [2670/4518] 59% | Training loss: 0.6871087253316958
Epoch: 32 | Iteration number: [2680/4518] 59% | Training loss: 0.6871039692590486
Epoch: 32 | Iteration number: [2690/4518] 59% | Training loss: 0.6871018738551654
Epoch: 32 | Iteration number: [2700/4518] 59% | Training loss: 0.687100275821156
Epoch: 32 | Iteration number: [2710/4518] 59% | Training loss: 0.6870966139974629
Epoch: 32 | Iteration number: [2720/4518] 60% | Training loss: 0.68709374458036
Epoch: 32 | Iteration number: [2730/4518] 60% | Training loss: 0.6870911218744494
Epoch: 32 | Iteration number: [2740/4518] 60% | Training loss: 0.6870888600601767
Epoch: 32 | Iteration number: [2750/4518] 60% | Training loss: 0.6870848062905398
Epoch: 32 | Iteration number: [2760/4518] 61% | Training loss: 0.687086822869985
Epoch: 32 | Iteration number: [2770/4518] 61% | Training loss: 0.6870830938704178
Epoch: 32 | Iteration number: [2780/4518] 61% | Training loss: 0.6870839112525363
Epoch: 32 | Iteration number: [2790/4518] 61% | Training loss: 0.6870858759649339
Epoch: 32 | Iteration number: [2800/4518] 61% | Training loss: 0.6870806776412896
Epoch: 32 | Iteration number: [2810/4518] 62% | Training loss: 0.6870822860040698
Epoch: 32 | Iteration number: [2820/4518] 62% | Training loss: 0.6870826752050548
Epoch: 32 | Iteration number: [2830/4518] 62% | Training loss: 0.6870785277428981
Epoch: 32 | Iteration number: [2840/4518] 62% | Training loss: 0.68707643762021
Epoch: 32 | Iteration number: [2850/4518] 63% | Training loss: 0.6870774355896733
Epoch: 32 | Iteration number: [2860/4518] 63% | Training loss: 0.6870760051728962
Epoch: 32 | Iteration number: [2870/4518] 63% | Training loss: 0.6870779835388635
Epoch: 32 | Iteration number: [2880/4518] 63% | Training loss: 0.6870794642716647
Epoch: 32 | Iteration number: [2890/4518] 63% | Training loss: 0.687080480297544
Epoch: 32 | Iteration number: [2900/4518] 64% | Training loss: 0.6870800587637671
Epoch: 32 | Iteration number: [2910/4518] 64% | Training loss: 0.6870802317902804
Epoch: 32 | Iteration number: [2920/4518] 64% | Training loss: 0.6870816143816465
Epoch: 32 | Iteration number: [2930/4518] 64% | Training loss: 0.6870823709020842
Epoch: 32 | Iteration number: [2940/4518] 65% | Training loss: 0.687077762399401
Epoch: 32 | Iteration number: [2950/4518] 65% | Training loss: 0.687082249350467
Epoch: 32 | Iteration number: [2960/4518] 65% | Training loss: 0.6870800421447367
Epoch: 32 | Iteration number: [2970/4518] 65% | Training loss: 0.6870814570473501
Epoch: 32 | Iteration number: [2980/4518] 65% | Training loss: 0.6870796801859901
Epoch: 32 | Iteration number: [2990/4518] 66% | Training loss: 0.6870762626462955
Epoch: 32 | Iteration number: [3000/4518] 66% | Training loss: 0.6870712418953577
Epoch: 32 | Iteration number: [3010/4518] 66% | Training loss: 0.6870705582968817
Epoch: 32 | Iteration number: [3020/4518] 66% | Training loss: 0.6870684536482324
Epoch: 32 | Iteration number: [3030/4518] 67% | Training loss: 0.6870720547811426
Epoch: 32 | Iteration number: [3040/4518] 67% | Training loss: 0.6870745539469154
Epoch: 32 | Iteration number: [3050/4518] 67% | Training loss: 0.6870722705809796
Epoch: 32 | Iteration number: [3060/4518] 67% | Training loss: 0.6870655976674136
Epoch: 32 | Iteration number: [3070/4518] 67% | Training loss: 0.6870622500340403
Epoch: 32 | Iteration number: [3080/4518] 68% | Training loss: 0.687061664887837
Epoch: 32 | Iteration number: [3090/4518] 68% | Training loss: 0.6870620742970686
Epoch: 32 | Iteration number: [3100/4518] 68% | Training loss: 0.6870613038924432
Epoch: 32 | Iteration number: [3110/4518] 68% | Training loss: 0.6870579496648918
Epoch: 32 | Iteration number: [3120/4518] 69% | Training loss: 0.6870542356601128
Epoch: 32 | Iteration number: [3130/4518] 69% | Training loss: 0.6870538468558949
Epoch: 32 | Iteration number: [3140/4518] 69% | Training loss: 0.6870536226565671
Epoch: 32 | Iteration number: [3150/4518] 69% | Training loss: 0.687051246298684
Epoch: 32 | Iteration number: [3160/4518] 69% | Training loss: 0.6870531825702402
Epoch: 32 | Iteration number: [3170/4518] 70% | Training loss: 0.6870523356112772
Epoch: 32 | Iteration number: [3180/4518] 70% | Training loss: 0.6870516353620673
Epoch: 32 | Iteration number: [3190/4518] 70% | Training loss: 0.6870501213499745
Epoch: 32 | Iteration number: [3200/4518] 70% | Training loss: 0.6870502057112753
Epoch: 32 | Iteration number: [3210/4518] 71% | Training loss: 0.6870506207519602
Epoch: 32 | Iteration number: [3220/4518] 71% | Training loss: 0.6870486635228862
Epoch: 32 | Iteration number: [3230/4518] 71% | Training loss: 0.687049561868142
Epoch: 32 | Iteration number: [3240/4518] 71% | Training loss: 0.6870547647093549
Epoch: 32 | Iteration number: [3250/4518] 71% | Training loss: 0.6870543168874887
Epoch: 32 | Iteration number: [3260/4518] 72% | Training loss: 0.6870490756320076
Epoch: 32 | Iteration number: [3270/4518] 72% | Training loss: 0.6870479983474137
Epoch: 32 | Iteration number: [3280/4518] 72% | Training loss: 0.6870474929853183
Epoch: 32 | Iteration number: [3290/4518] 72% | Training loss: 0.6870455858011738
Epoch: 32 | Iteration number: [3300/4518] 73% | Training loss: 0.6870414581443324
Epoch: 32 | Iteration number: [3310/4518] 73% | Training loss: 0.6870410705801223
Epoch: 32 | Iteration number: [3320/4518] 73% | Training loss: 0.6870384931205267
Epoch: 32 | Iteration number: [3330/4518] 73% | Training loss: 0.687043470645452
Epoch: 32 | Iteration number: [3340/4518] 73% | Training loss: 0.687046951162601
Epoch: 32 | Iteration number: [3350/4518] 74% | Training loss: 0.6870434150944895
Epoch: 32 | Iteration number: [3360/4518] 74% | Training loss: 0.68704587242433
Epoch: 32 | Iteration number: [3370/4518] 74% | Training loss: 0.6870452570278496
Epoch: 32 | Iteration number: [3380/4518] 74% | Training loss: 0.6870442570313899
Epoch: 32 | Iteration number: [3390/4518] 75% | Training loss: 0.6870436732220438
Epoch: 32 | Iteration number: [3400/4518] 75% | Training loss: 0.6870435168988565
Epoch: 32 | Iteration number: [3410/4518] 75% | Training loss: 0.687042739139624
Epoch: 32 | Iteration number: [3420/4518] 75% | Training loss: 0.6870430264382335
Epoch: 32 | Iteration number: [3430/4518] 75% | Training loss: 0.6870424213805629
Epoch: 32 | Iteration number: [3440/4518] 76% | Training loss: 0.687042691922465
Epoch: 32 | Iteration number: [3450/4518] 76% | Training loss: 0.6870407559042392
Epoch: 32 | Iteration number: [3460/4518] 76% | Training loss: 0.6870413629994916
Epoch: 32 | Iteration number: [3470/4518] 76% | Training loss: 0.6870418615746566
Epoch: 32 | Iteration number: [3480/4518] 77% | Training loss: 0.6870417035687929
Epoch: 32 | Iteration number: [3490/4518] 77% | Training loss: 0.6870402992454846
Epoch: 32 | Iteration number: [3500/4518] 77% | Training loss: 0.6870466868196214
Epoch: 32 | Iteration number: [3510/4518] 77% | Training loss: 0.6870483501684292
Epoch: 32 | Iteration number: [3520/4518] 77% | Training loss: 0.6870503599840132
Epoch: 32 | Iteration number: [3530/4518] 78% | Training loss: 0.6870504353607004
Epoch: 32 | Iteration number: [3540/4518] 78% | Training loss: 0.6870518293421147
Epoch: 32 | Iteration number: [3550/4518] 78% | Training loss: 0.6870539389193897
Epoch: 32 | Iteration number: [3560/4518] 78% | Training loss: 0.6870547557312451
Epoch: 32 | Iteration number: [3570/4518] 79% | Training loss: 0.6870550464682218
Epoch: 32 | Iteration number: [3580/4518] 79% | Training loss: 0.6870569337513194
Epoch: 32 | Iteration number: [3590/4518] 79% | Training loss: 0.6870554382754568
Epoch: 32 | Iteration number: [3600/4518] 79% | Training loss: 0.6870550313426389
Epoch: 32 | Iteration number: [3610/4518] 79% | Training loss: 0.6870570135083555
Epoch: 32 | Iteration number: [3620/4518] 80% | Training loss: 0.6870604653714112
Epoch: 32 | Iteration number: [3630/4518] 80% | Training loss: 0.6870587942028834
Epoch: 32 | Iteration number: [3640/4518] 80% | Training loss: 0.6870595607947517
Epoch: 32 | Iteration number: [3650/4518] 80% | Training loss: 0.6870538695544413
Epoch: 32 | Iteration number: [3660/4518] 81% | Training loss: 0.687050415697645
Epoch: 32 | Iteration number: [3670/4518] 81% | Training loss: 0.6870498678989566
Epoch: 32 | Iteration number: [3680/4518] 81% | Training loss: 0.6870502154140369
Epoch: 32 | Iteration number: [3690/4518] 81% | Training loss: 0.6870524235695681
Epoch: 32 | Iteration number: [3700/4518] 81% | Training loss: 0.6870527770390382
Epoch: 32 | Iteration number: [3710/4518] 82% | Training loss: 0.6870523385281833
Epoch: 32 | Iteration number: [3720/4518] 82% | Training loss: 0.6870549903922184
Epoch: 32 | Iteration number: [3730/4518] 82% | Training loss: 0.6870507308049751
Epoch: 32 | Iteration number: [3740/4518] 82% | Training loss: 0.6870509738431257
Epoch: 32 | Iteration number: [3750/4518] 83% | Training loss: 0.6870472553571065
Epoch: 32 | Iteration number: [3760/4518] 83% | Training loss: 0.6870442038520853
Epoch: 32 | Iteration number: [3770/4518] 83% | Training loss: 0.687044189494864
Epoch: 32 | Iteration number: [3780/4518] 83% | Training loss: 0.6870447067356614
Epoch: 32 | Iteration number: [3790/4518] 83% | Training loss: 0.687046335963901
Epoch: 32 | Iteration number: [3800/4518] 84% | Training loss: 0.6870406362728069
Epoch: 32 | Iteration number: [3810/4518] 84% | Training loss: 0.6870401121969298
Epoch: 32 | Iteration number: [3820/4518] 84% | Training loss: 0.6870393419140921
Epoch: 32 | Iteration number: [3830/4518] 84% | Training loss: 0.687038849181357
Epoch: 32 | Iteration number: [3840/4518] 84% | Training loss: 0.6870390075414131
Epoch: 32 | Iteration number: [3850/4518] 85% | Training loss: 0.687037937006393
Epoch: 32 | Iteration number: [3860/4518] 85% | Training loss: 0.6870377736542509
Epoch: 32 | Iteration number: [3870/4518] 85% | Training loss: 0.687036689338142
Epoch: 32 | Iteration number: [3880/4518] 85% | Training loss: 0.6870379484805864
Epoch: 32 | Iteration number: [3890/4518] 86% | Training loss: 0.6870379518420653
Epoch: 32 | Iteration number: [3900/4518] 86% | Training loss: 0.6870354235325105
Epoch: 32 | Iteration number: [3910/4518] 86% | Training loss: 0.6870331794404617
Epoch: 32 | Iteration number: [3920/4518] 86% | Training loss: 0.687035877850591
Epoch: 32 | Iteration number: [3930/4518] 86% | Training loss: 0.6870358852939751
Epoch: 32 | Iteration number: [3940/4518] 87% | Training loss: 0.6870361091673072
Epoch: 32 | Iteration number: [3950/4518] 87% | Training loss: 0.6870392518858366
Epoch: 32 | Iteration number: [3960/4518] 87% | Training loss: 0.6870357324529176
Epoch: 32 | Iteration number: [3970/4518] 87% | Training loss: 0.6870296808574302
Epoch: 32 | Iteration number: [3980/4518] 88% | Training loss: 0.6870264158326777
Epoch: 32 | Iteration number: [3990/4518] 88% | Training loss: 0.6870285848029574
Epoch: 32 | Iteration number: [4000/4518] 88% | Training loss: 0.687031575486064
Epoch: 32 | Iteration number: [4010/4518] 88% | Training loss: 0.6870319198491864
Epoch: 32 | Iteration number: [4020/4518] 88% | Training loss: 0.6870361488553423
Epoch: 32 | Iteration number: [4030/4518] 89% | Training loss: 0.6870376220412053
Epoch: 32 | Iteration number: [4040/4518] 89% | Training loss: 0.6870394134432962
Epoch: 32 | Iteration number: [4050/4518] 89% | Training loss: 0.6870401896959469
Epoch: 32 | Iteration number: [4060/4518] 89% | Training loss: 0.6870365566661205
Epoch: 32 | Iteration number: [4070/4518] 90% | Training loss: 0.6870374651740165
Epoch: 32 | Iteration number: [4080/4518] 90% | Training loss: 0.6870376623436516
Epoch: 32 | Iteration number: [4090/4518] 90% | Training loss: 0.6870403982607834
Epoch: 32 | Iteration number: [4100/4518] 90% | Training loss: 0.687038099329646
Epoch: 32 | Iteration number: [4110/4518] 90% | Training loss: 0.6870362071370266
Epoch: 32 | Iteration number: [4120/4518] 91% | Training loss: 0.6870348026596227
Epoch: 32 | Iteration number: [4130/4518] 91% | Training loss: 0.6870341914473665
Epoch: 32 | Iteration number: [4140/4518] 91% | Training loss: 0.687035002771783
Epoch: 32 | Iteration number: [4150/4518] 91% | Training loss: 0.687035824390779
Epoch: 32 | Iteration number: [4160/4518] 92% | Training loss: 0.6870342333013049
Epoch: 32 | Iteration number: [4170/4518] 92% | Training loss: 0.6870366736996374
Epoch: 32 | Iteration number: [4180/4518] 92% | Training loss: 0.6870340864624133
Epoch: 32 | Iteration number: [4190/4518] 92% | Training loss: 0.6870344673819075
Epoch: 32 | Iteration number: [4200/4518] 92% | Training loss: 0.6870323036114375
Epoch: 32 | Iteration number: [4210/4518] 93% | Training loss: 0.6870324282634853
Epoch: 32 | Iteration number: [4220/4518] 93% | Training loss: 0.6870335344172201
Epoch: 32 | Iteration number: [4230/4518] 93% | Training loss: 0.6870322746024345
Epoch: 32 | Iteration number: [4240/4518] 93% | Training loss: 0.6870286144175619
Epoch: 32 | Iteration number: [4250/4518] 94% | Training loss: 0.6870312155555276
Epoch: 32 | Iteration number: [4260/4518] 94% | Training loss: 0.6870332429946309
Epoch: 32 | Iteration number: [4270/4518] 94% | Training loss: 0.6870322333845098
Epoch: 32 | Iteration number: [4280/4518] 94% | Training loss: 0.6870321650510637
Epoch: 32 | Iteration number: [4290/4518] 94% | Training loss: 0.6870329790598863
Epoch: 32 | Iteration number: [4300/4518] 95% | Training loss: 0.6870303801325864
Epoch: 32 | Iteration number: [4310/4518] 95% | Training loss: 0.6870312637491736
Epoch: 32 | Iteration number: [4320/4518] 95% | Training loss: 0.6870316219688566
Epoch: 32 | Iteration number: [4330/4518] 95% | Training loss: 0.687032158091217
Epoch: 32 | Iteration number: [4340/4518] 96% | Training loss: 0.6870289041974028
Epoch: 32 | Iteration number: [4350/4518] 96% | Training loss: 0.6870291590279546
Epoch: 32 | Iteration number: [4360/4518] 96% | Training loss: 0.6870254118918279
Epoch: 32 | Iteration number: [4370/4518] 96% | Training loss: 0.6870230954899122
Epoch: 32 | Iteration number: [4380/4518] 96% | Training loss: 0.687021390352075
Epoch: 32 | Iteration number: [4390/4518] 97% | Training loss: 0.6870199333155074
Epoch: 32 | Iteration number: [4400/4518] 97% | Training loss: 0.6870183742317286
Epoch: 32 | Iteration number: [4410/4518] 97% | Training loss: 0.6870189295063754
Epoch: 32 | Iteration number: [4420/4518] 97% | Training loss: 0.6870184073620792
Epoch: 32 | Iteration number: [4430/4518] 98% | Training loss: 0.6870161201695556
Epoch: 32 | Iteration number: [4440/4518] 98% | Training loss: 0.687015566109
Epoch: 32 | Iteration number: [4450/4518] 98% | Training loss: 0.6870152397637956
Epoch: 32 | Iteration number: [4460/4518] 98% | Training loss: 0.6870146788289194
Epoch: 32 | Iteration number: [4470/4518] 98% | Training loss: 0.6870141420188366
Epoch: 32 | Iteration number: [4480/4518] 99% | Training loss: 0.6870145340450108
Epoch: 32 | Iteration number: [4490/4518] 99% | Training loss: 0.6870134155973294
Epoch: 32 | Iteration number: [4500/4518] 99% | Training loss: 0.6870135767857234
Epoch: 32 | Iteration number: [4510/4518] 99% | Training loss: 0.6870127973429644

 End of epoch: 32 | Train Loss: 0.6868599251526127 | Training Time: 642 

 End of epoch: 32 | Eval Loss: 0.6901941944141777 | Evaluating Time: 17 
Epoch: 33 | Iteration number: [10/4518] 0% | Training loss: 0.7564738154411316
Epoch: 33 | Iteration number: [20/4518] 0% | Training loss: 0.7217822521924973
Epoch: 33 | Iteration number: [30/4518] 0% | Training loss: 0.7098953028519949
Epoch: 33 | Iteration number: [40/4518] 0% | Training loss: 0.7039829447865487
Epoch: 33 | Iteration number: [50/4518] 1% | Training loss: 0.7008059442043304
Epoch: 33 | Iteration number: [60/4518] 1% | Training loss: 0.6984157721201579
Epoch: 33 | Iteration number: [70/4518] 1% | Training loss: 0.6970077352864402
Epoch: 33 | Iteration number: [80/4518] 1% | Training loss: 0.6958165086805821
Epoch: 33 | Iteration number: [90/4518] 1% | Training loss: 0.6948718342516157
Epoch: 33 | Iteration number: [100/4518] 2% | Training loss: 0.6941205334663391
Epoch: 33 | Iteration number: [110/4518] 2% | Training loss: 0.6934079311110757
Epoch: 33 | Iteration number: [120/4518] 2% | Training loss: 0.692762516438961
Epoch: 33 | Iteration number: [130/4518] 2% | Training loss: 0.6923546901116004
Epoch: 33 | Iteration number: [140/4518] 3% | Training loss: 0.6918144332511085
Epoch: 33 | Iteration number: [150/4518] 3% | Training loss: 0.6914988839626313
Epoch: 33 | Iteration number: [160/4518] 3% | Training loss: 0.6912030696868896
Epoch: 33 | Iteration number: [170/4518] 3% | Training loss: 0.6910265571930829
Epoch: 33 | Iteration number: [180/4518] 3% | Training loss: 0.6907074845499462
Epoch: 33 | Iteration number: [190/4518] 4% | Training loss: 0.6904196767430556
Epoch: 33 | Iteration number: [200/4518] 4% | Training loss: 0.6902364766597748
Epoch: 33 | Iteration number: [210/4518] 4% | Training loss: 0.6900375667072478
Epoch: 33 | Iteration number: [220/4518] 4% | Training loss: 0.6899714564735239
Epoch: 33 | Iteration number: [230/4518] 5% | Training loss: 0.6898544202680174
Epoch: 33 | Iteration number: [240/4518] 5% | Training loss: 0.6896958775818348
Epoch: 33 | Iteration number: [250/4518] 5% | Training loss: 0.689625498533249
Epoch: 33 | Iteration number: [260/4518] 5% | Training loss: 0.6895181098809608
Epoch: 33 | Iteration number: [270/4518] 5% | Training loss: 0.6894099467330509
Epoch: 33 | Iteration number: [280/4518] 6% | Training loss: 0.6892953593816076
Epoch: 33 | Iteration number: [290/4518] 6% | Training loss: 0.6892388273929727
Epoch: 33 | Iteration number: [300/4518] 6% | Training loss: 0.6891643671194713
Epoch: 33 | Iteration number: [310/4518] 6% | Training loss: 0.6890779170297807
Epoch: 33 | Iteration number: [320/4518] 7% | Training loss: 0.6889825830236077
Epoch: 33 | Iteration number: [330/4518] 7% | Training loss: 0.6889249539736545
Epoch: 33 | Iteration number: [340/4518] 7% | Training loss: 0.6888763459289775
Epoch: 33 | Iteration number: [350/4518] 7% | Training loss: 0.6888290449551173
Epoch: 33 | Iteration number: [360/4518] 7% | Training loss: 0.6887992304232385
Epoch: 33 | Iteration number: [370/4518] 8% | Training loss: 0.6887519844480463
Epoch: 33 | Iteration number: [380/4518] 8% | Training loss: 0.6887169773641385
Epoch: 33 | Iteration number: [390/4518] 8% | Training loss: 0.6886698800783891
Epoch: 33 | Iteration number: [400/4518] 8% | Training loss: 0.6886340491473675
Epoch: 33 | Iteration number: [410/4518] 9% | Training loss: 0.6885743036502745
Epoch: 33 | Iteration number: [420/4518] 9% | Training loss: 0.6885419666767121
Epoch: 33 | Iteration number: [430/4518] 9% | Training loss: 0.6884918430516886
Epoch: 33 | Iteration number: [440/4518] 9% | Training loss: 0.6884583381089298
Epoch: 33 | Iteration number: [450/4518] 9% | Training loss: 0.6884292974736955
Epoch: 33 | Iteration number: [460/4518] 10% | Training loss: 0.6883919271438018
Epoch: 33 | Iteration number: [470/4518] 10% | Training loss: 0.6883694283505704
Epoch: 33 | Iteration number: [480/4518] 10% | Training loss: 0.688348833595713
Epoch: 33 | Iteration number: [490/4518] 10% | Training loss: 0.6883280312528416
Epoch: 33 | Iteration number: [500/4518] 11% | Training loss: 0.6882712513208389
Epoch: 33 | Iteration number: [510/4518] 11% | Training loss: 0.6882597517733481
Epoch: 33 | Iteration number: [520/4518] 11% | Training loss: 0.6882484173545471
Epoch: 33 | Iteration number: [530/4518] 11% | Training loss: 0.6882055176878875
Epoch: 33 | Iteration number: [540/4518] 11% | Training loss: 0.6882049113512039
Epoch: 33 | Iteration number: [550/4518] 12% | Training loss: 0.68819145581939
Epoch: 33 | Iteration number: [560/4518] 12% | Training loss: 0.6881702448640551
Epoch: 33 | Iteration number: [570/4518] 12% | Training loss: 0.6881550428114439
Epoch: 33 | Iteration number: [580/4518] 12% | Training loss: 0.6881411856618421
Epoch: 33 | Iteration number: [590/4518] 13% | Training loss: 0.6881058008994086
Epoch: 33 | Iteration number: [600/4518] 13% | Training loss: 0.6880869369705518
Epoch: 33 | Iteration number: [610/4518] 13% | Training loss: 0.68807479309254
Epoch: 33 | Iteration number: [620/4518] 13% | Training loss: 0.6880443676825493
Epoch: 33 | Iteration number: [630/4518] 13% | Training loss: 0.68802842043695
Epoch: 33 | Iteration number: [640/4518] 14% | Training loss: 0.6880279640667141
Epoch: 33 | Iteration number: [650/4518] 14% | Training loss: 0.6880111384391785
Epoch: 33 | Iteration number: [660/4518] 14% | Training loss: 0.6879970282316208
Epoch: 33 | Iteration number: [670/4518] 14% | Training loss: 0.6879685954371495
Epoch: 33 | Iteration number: [680/4518] 15% | Training loss: 0.6879596774192417
Epoch: 33 | Iteration number: [690/4518] 15% | Training loss: 0.687937039827955
Epoch: 33 | Iteration number: [700/4518] 15% | Training loss: 0.6879080157620566
Epoch: 33 | Iteration number: [710/4518] 15% | Training loss: 0.6878858993590717
Epoch: 33 | Iteration number: [720/4518] 15% | Training loss: 0.687875285744667
Epoch: 33 | Iteration number: [730/4518] 16% | Training loss: 0.6878511819937457
Epoch: 33 | Iteration number: [740/4518] 16% | Training loss: 0.6878341798041318
Epoch: 33 | Iteration number: [750/4518] 16% | Training loss: 0.6878269185225169
Epoch: 33 | Iteration number: [760/4518] 16% | Training loss: 0.6878173717542698
Epoch: 33 | Iteration number: [770/4518] 17% | Training loss: 0.6878031505392743
Epoch: 33 | Iteration number: [780/4518] 17% | Training loss: 0.6877749089247142
Epoch: 33 | Iteration number: [790/4518] 17% | Training loss: 0.6877638996401919
Epoch: 33 | Iteration number: [800/4518] 17% | Training loss: 0.6877396288514137
Epoch: 33 | Iteration number: [810/4518] 17% | Training loss: 0.6877389255865121
Epoch: 33 | Iteration number: [820/4518] 18% | Training loss: 0.687732079043621
Epoch: 33 | Iteration number: [830/4518] 18% | Training loss: 0.6877344389277769
Epoch: 33 | Iteration number: [840/4518] 18% | Training loss: 0.6877288506144569
Epoch: 33 | Iteration number: [850/4518] 18% | Training loss: 0.6877210699109471
Epoch: 33 | Iteration number: [860/4518] 19% | Training loss: 0.6877167768949686
Epoch: 33 | Iteration number: [870/4518] 19% | Training loss: 0.6877206641367112
Epoch: 33 | Iteration number: [880/4518] 19% | Training loss: 0.6877148481255227
Epoch: 33 | Iteration number: [890/4518] 19% | Training loss: 0.6877087535483114
Epoch: 33 | Iteration number: [900/4518] 19% | Training loss: 0.6877026320166058
Epoch: 33 | Iteration number: [910/4518] 20% | Training loss: 0.6876937553122804
Epoch: 33 | Iteration number: [920/4518] 20% | Training loss: 0.6876902916509172
Epoch: 33 | Iteration number: [930/4518] 20% | Training loss: 0.6876808942646109
Epoch: 33 | Iteration number: [940/4518] 20% | Training loss: 0.6876768086818938
Epoch: 33 | Iteration number: [950/4518] 21% | Training loss: 0.6876680542920766
Epoch: 33 | Iteration number: [960/4518] 21% | Training loss: 0.6876631595815221
Epoch: 33 | Iteration number: [970/4518] 21% | Training loss: 0.6876640232567934
Epoch: 33 | Iteration number: [980/4518] 21% | Training loss: 0.6876493467360126
Epoch: 33 | Iteration number: [990/4518] 21% | Training loss: 0.6876518793178327
Epoch: 33 | Iteration number: [1000/4518] 22% | Training loss: 0.6876367379426956
Epoch: 33 | Iteration number: [1010/4518] 22% | Training loss: 0.6876412624769872
Epoch: 33 | Iteration number: [1020/4518] 22% | Training loss: 0.6876308854304108
Epoch: 33 | Iteration number: [1030/4518] 22% | Training loss: 0.6876092094819523
Epoch: 33 | Iteration number: [1040/4518] 23% | Training loss: 0.687602012948348
Epoch: 33 | Iteration number: [1050/4518] 23% | Training loss: 0.687588646638961
Epoch: 33 | Iteration number: [1060/4518] 23% | Training loss: 0.6875926352334473
Epoch: 33 | Iteration number: [1070/4518] 23% | Training loss: 0.6875999424502114
Epoch: 33 | Iteration number: [1080/4518] 23% | Training loss: 0.6876025484667884
Epoch: 33 | Iteration number: [1090/4518] 24% | Training loss: 0.6875843982630914
Epoch: 33 | Iteration number: [1100/4518] 24% | Training loss: 0.6875776946002787
Epoch: 33 | Iteration number: [1110/4518] 24% | Training loss: 0.6875600109229216
Epoch: 33 | Iteration number: [1120/4518] 24% | Training loss: 0.6875548268003123
Epoch: 33 | Iteration number: [1130/4518] 25% | Training loss: 0.6875417713570384
Epoch: 33 | Iteration number: [1140/4518] 25% | Training loss: 0.6875394353218246
Epoch: 33 | Iteration number: [1150/4518] 25% | Training loss: 0.6875379332252171
Epoch: 33 | Iteration number: [1160/4518] 25% | Training loss: 0.6875368005242841
Epoch: 33 | Iteration number: [1170/4518] 25% | Training loss: 0.6875252671221382
Epoch: 33 | Iteration number: [1180/4518] 26% | Training loss: 0.687528723579342
Epoch: 33 | Iteration number: [1190/4518] 26% | Training loss: 0.6875191174635367
Epoch: 33 | Iteration number: [1200/4518] 26% | Training loss: 0.6875158726672331
Epoch: 33 | Iteration number: [1210/4518] 26% | Training loss: 0.687501534942753
Epoch: 33 | Iteration number: [1220/4518] 27% | Training loss: 0.6874897163910944
Epoch: 33 | Iteration number: [1230/4518] 27% | Training loss: 0.6874815323488499
Epoch: 33 | Iteration number: [1240/4518] 27% | Training loss: 0.6874743697143371
Epoch: 33 | Iteration number: [1250/4518] 27% | Training loss: 0.6874750248908996
Epoch: 33 | Iteration number: [1260/4518] 27% | Training loss: 0.6874670356512069
Epoch: 33 | Iteration number: [1270/4518] 28% | Training loss: 0.6874691598528013
Epoch: 33 | Iteration number: [1280/4518] 28% | Training loss: 0.68746598479338
Epoch: 33 | Iteration number: [1290/4518] 28% | Training loss: 0.6874584788499877
Epoch: 33 | Iteration number: [1300/4518] 28% | Training loss: 0.6874545775010036
Epoch: 33 | Iteration number: [1310/4518] 28% | Training loss: 0.6874555499954078
Epoch: 33 | Iteration number: [1320/4518] 29% | Training loss: 0.6874469484343674
Epoch: 33 | Iteration number: [1330/4518] 29% | Training loss: 0.6874520924306453
Epoch: 33 | Iteration number: [1340/4518] 29% | Training loss: 0.6874509715767049
Epoch: 33 | Iteration number: [1350/4518] 29% | Training loss: 0.687447043215787
Epoch: 33 | Iteration number: [1360/4518] 30% | Training loss: 0.6874371969962821
Epoch: 33 | Iteration number: [1370/4518] 30% | Training loss: 0.6874306918060693
Epoch: 33 | Iteration number: [1380/4518] 30% | Training loss: 0.6874256025621857
Epoch: 33 | Iteration number: [1390/4518] 30% | Training loss: 0.6874261098799945
Epoch: 33 | Iteration number: [1400/4518] 30% | Training loss: 0.687423069519656
Epoch: 33 | Iteration number: [1410/4518] 31% | Training loss: 0.6874159513635838
Epoch: 33 | Iteration number: [1420/4518] 31% | Training loss: 0.6874089452582346
Epoch: 33 | Iteration number: [1430/4518] 31% | Training loss: 0.6874114998570688
Epoch: 33 | Iteration number: [1440/4518] 31% | Training loss: 0.6874223214056757
Epoch: 33 | Iteration number: [1450/4518] 32% | Training loss: 0.6874204349517822
Epoch: 33 | Iteration number: [1460/4518] 32% | Training loss: 0.6874206914068901
Epoch: 33 | Iteration number: [1470/4518] 32% | Training loss: 0.6874027797559492
Epoch: 33 | Iteration number: [1480/4518] 32% | Training loss: 0.6873967260927767
Epoch: 33 | Iteration number: [1490/4518] 32% | Training loss: 0.6873876762870174
Epoch: 33 | Iteration number: [1500/4518] 33% | Training loss: 0.6873799398740132
Epoch: 33 | Iteration number: [1510/4518] 33% | Training loss: 0.6873744430526203
Epoch: 33 | Iteration number: [1520/4518] 33% | Training loss: 0.6873648849757095
Epoch: 33 | Iteration number: [1530/4518] 33% | Training loss: 0.6873640130158344
Epoch: 33 | Iteration number: [1540/4518] 34% | Training loss: 0.68735626928218
Epoch: 33 | Iteration number: [1550/4518] 34% | Training loss: 0.6873558267085783
Epoch: 33 | Iteration number: [1560/4518] 34% | Training loss: 0.6873547354569802
Epoch: 33 | Iteration number: [1570/4518] 34% | Training loss: 0.68735408855092
Epoch: 33 | Iteration number: [1580/4518] 34% | Training loss: 0.687356316515162
Epoch: 33 | Iteration number: [1590/4518] 35% | Training loss: 0.6873470587925341
Epoch: 33 | Iteration number: [1600/4518] 35% | Training loss: 0.6873509529605508
Epoch: 33 | Iteration number: [1610/4518] 35% | Training loss: 0.6873493325636254
Epoch: 33 | Iteration number: [1620/4518] 35% | Training loss: 0.6873426310074182
Epoch: 33 | Iteration number: [1630/4518] 36% | Training loss: 0.6873418523490064
Epoch: 33 | Iteration number: [1640/4518] 36% | Training loss: 0.6873359660549861
Epoch: 33 | Iteration number: [1650/4518] 36% | Training loss: 0.6873366629716122
Epoch: 33 | Iteration number: [1660/4518] 36% | Training loss: 0.6873332030801887
Epoch: 33 | Iteration number: [1670/4518] 36% | Training loss: 0.6873270503418174
Epoch: 33 | Iteration number: [1680/4518] 37% | Training loss: 0.6873161411001569
Epoch: 33 | Iteration number: [1690/4518] 37% | Training loss: 0.687307459151251
Epoch: 33 | Iteration number: [1700/4518] 37% | Training loss: 0.6873016500122406
Epoch: 33 | Iteration number: [1710/4518] 37% | Training loss: 0.6873012216119041
Epoch: 33 | Iteration number: [1720/4518] 38% | Training loss: 0.6873083418191865
Epoch: 33 | Iteration number: [1730/4518] 38% | Training loss: 0.6873103333346416
Epoch: 33 | Iteration number: [1740/4518] 38% | Training loss: 0.6873080976050475
Epoch: 33 | Iteration number: [1750/4518] 38% | Training loss: 0.6873080211026328
Epoch: 33 | Iteration number: [1760/4518] 38% | Training loss: 0.6873141271146861
Epoch: 33 | Iteration number: [1770/4518] 39% | Training loss: 0.687309803733718
Epoch: 33 | Iteration number: [1780/4518] 39% | Training loss: 0.6873092266950714
Epoch: 33 | Iteration number: [1790/4518] 39% | Training loss: 0.6873133063316346
Epoch: 33 | Iteration number: [1800/4518] 39% | Training loss: 0.687314912047651
Epoch: 33 | Iteration number: [1810/4518] 40% | Training loss: 0.6873153550190162
Epoch: 33 | Iteration number: [1820/4518] 40% | Training loss: 0.6873168110192477
Epoch: 33 | Iteration number: [1830/4518] 40% | Training loss: 0.6873183471583277
Epoch: 33 | Iteration number: [1840/4518] 40% | Training loss: 0.6873179725978685
Epoch: 33 | Iteration number: [1850/4518] 40% | Training loss: 0.687314792549288
Epoch: 33 | Iteration number: [1860/4518] 41% | Training loss: 0.6873149517082399
Epoch: 33 | Iteration number: [1870/4518] 41% | Training loss: 0.6873207119696918
Epoch: 33 | Iteration number: [1880/4518] 41% | Training loss: 0.6873193482135205
Epoch: 33 | Iteration number: [1890/4518] 41% | Training loss: 0.6873195009887534
Epoch: 33 | Iteration number: [1900/4518] 42% | Training loss: 0.687318377243845
Epoch: 33 | Iteration number: [1910/4518] 42% | Training loss: 0.6873182855663499
Epoch: 33 | Iteration number: [1920/4518] 42% | Training loss: 0.6873173901811243
Epoch: 33 | Iteration number: [1930/4518] 42% | Training loss: 0.6873119361042359
Epoch: 33 | Iteration number: [1940/4518] 42% | Training loss: 0.687309494553153
Epoch: 33 | Iteration number: [1950/4518] 43% | Training loss: 0.6873031201423743
Epoch: 33 | Iteration number: [1960/4518] 43% | Training loss: 0.6872948971025797
Epoch: 33 | Iteration number: [1970/4518] 43% | Training loss: 0.6872893567012651
Epoch: 33 | Iteration number: [1980/4518] 43% | Training loss: 0.6872849695008211
Epoch: 33 | Iteration number: [1990/4518] 44% | Training loss: 0.687274300483004
Epoch: 33 | Iteration number: [2000/4518] 44% | Training loss: 0.6872740716040134
Epoch: 33 | Iteration number: [2010/4518] 44% | Training loss: 0.6872681854969234
Epoch: 33 | Iteration number: [2020/4518] 44% | Training loss: 0.6872681093688059
Epoch: 33 | Iteration number: [2030/4518] 44% | Training loss: 0.6872672753087405
Epoch: 33 | Iteration number: [2040/4518] 45% | Training loss: 0.6872601505880263
Epoch: 33 | Iteration number: [2050/4518] 45% | Training loss: 0.6872555705105386
Epoch: 33 | Iteration number: [2060/4518] 45% | Training loss: 0.6872602146806068
Epoch: 33 | Iteration number: [2070/4518] 45% | Training loss: 0.6872557046908687
Epoch: 33 | Iteration number: [2080/4518] 46% | Training loss: 0.6872514248180848
Epoch: 33 | Iteration number: [2090/4518] 46% | Training loss: 0.687240231892709
Epoch: 33 | Iteration number: [2100/4518] 46% | Training loss: 0.6872356692949931
Epoch: 33 | Iteration number: [2110/4518] 46% | Training loss: 0.6872292331609681
Epoch: 33 | Iteration number: [2120/4518] 46% | Training loss: 0.6872213613874507
Epoch: 33 | Iteration number: [2130/4518] 47% | Training loss: 0.6872223508190102
Epoch: 33 | Iteration number: [2140/4518] 47% | Training loss: 0.6872179399305415
Epoch: 33 | Iteration number: [2150/4518] 47% | Training loss: 0.6872162430785423
Epoch: 33 | Iteration number: [2160/4518] 47% | Training loss: 0.6872169263109013
Epoch: 33 | Iteration number: [2170/4518] 48% | Training loss: 0.6872221992037812
Epoch: 33 | Iteration number: [2180/4518] 48% | Training loss: 0.6872174680779833
Epoch: 33 | Iteration number: [2190/4518] 48% | Training loss: 0.687212603413351
Epoch: 33 | Iteration number: [2200/4518] 48% | Training loss: 0.6872045162861997
Epoch: 33 | Iteration number: [2210/4518] 48% | Training loss: 0.6872034040241759
Epoch: 33 | Iteration number: [2220/4518] 49% | Training loss: 0.6871997340036942
Epoch: 33 | Iteration number: [2230/4518] 49% | Training loss: 0.687201863233284
Epoch: 33 | Iteration number: [2240/4518] 49% | Training loss: 0.6872006209035005
Epoch: 33 | Iteration number: [2250/4518] 49% | Training loss: 0.6871996368832058
Epoch: 33 | Iteration number: [2260/4518] 50% | Training loss: 0.6871990268736814
Epoch: 33 | Iteration number: [2270/4518] 50% | Training loss: 0.6871950685977936
Epoch: 33 | Iteration number: [2280/4518] 50% | Training loss: 0.687191177041907
Epoch: 33 | Iteration number: [2290/4518] 50% | Training loss: 0.6871880308509394
Epoch: 33 | Iteration number: [2300/4518] 50% | Training loss: 0.6871860079402509
Epoch: 33 | Iteration number: [2310/4518] 51% | Training loss: 0.6871817692275687
Epoch: 33 | Iteration number: [2320/4518] 51% | Training loss: 0.6871775807748581
Epoch: 33 | Iteration number: [2330/4518] 51% | Training loss: 0.6871716211026319
Epoch: 33 | Iteration number: [2340/4518] 51% | Training loss: 0.6871693428000833
Epoch: 33 | Iteration number: [2350/4518] 52% | Training loss: 0.6871684170530198
Epoch: 33 | Iteration number: [2360/4518] 52% | Training loss: 0.6871690156348681
Epoch: 33 | Iteration number: [2370/4518] 52% | Training loss: 0.6871684206940454
Epoch: 33 | Iteration number: [2380/4518] 52% | Training loss: 0.6871624240354329
Epoch: 33 | Iteration number: [2390/4518] 52% | Training loss: 0.6871631560964065
Epoch: 33 | Iteration number: [2400/4518] 53% | Training loss: 0.6871621026843786
Epoch: 33 | Iteration number: [2410/4518] 53% | Training loss: 0.6871601473493695
Epoch: 33 | Iteration number: [2420/4518] 53% | Training loss: 0.6871586697160705
Epoch: 33 | Iteration number: [2430/4518] 53% | Training loss: 0.6871543920825047
Epoch: 33 | Iteration number: [2440/4518] 54% | Training loss: 0.6871489149625184
Epoch: 33 | Iteration number: [2450/4518] 54% | Training loss: 0.6871512907378527
Epoch: 33 | Iteration number: [2460/4518] 54% | Training loss: 0.6871513448352736
Epoch: 33 | Iteration number: [2470/4518] 54% | Training loss: 0.6871548812640341
Epoch: 33 | Iteration number: [2480/4518] 54% | Training loss: 0.6871504750703612
Epoch: 33 | Iteration number: [2490/4518] 55% | Training loss: 0.6871465835944716
Epoch: 33 | Iteration number: [2500/4518] 55% | Training loss: 0.6871476781368255
Epoch: 33 | Iteration number: [2510/4518] 55% | Training loss: 0.6871411841229139
Epoch: 33 | Iteration number: [2520/4518] 55% | Training loss: 0.6871404304863915
Epoch: 33 | Iteration number: [2530/4518] 55% | Training loss: 0.6871409312302887
Epoch: 33 | Iteration number: [2540/4518] 56% | Training loss: 0.6871362738017961
Epoch: 33 | Iteration number: [2550/4518] 56% | Training loss: 0.687132054941327
Epoch: 33 | Iteration number: [2560/4518] 56% | Training loss: 0.6871293263975531
Epoch: 33 | Iteration number: [2570/4518] 56% | Training loss: 0.6871258844893267
Epoch: 33 | Iteration number: [2580/4518] 57% | Training loss: 0.6871297538280488
Epoch: 33 | Iteration number: [2590/4518] 57% | Training loss: 0.6871316850875796
Epoch: 33 | Iteration number: [2600/4518] 57% | Training loss: 0.6871322597219394
Epoch: 33 | Iteration number: [2610/4518] 57% | Training loss: 0.6871272014475417
Epoch: 33 | Iteration number: [2620/4518] 57% | Training loss: 0.687129356114919
Epoch: 33 | Iteration number: [2630/4518] 58% | Training loss: 0.6871340500991154
Epoch: 33 | Iteration number: [2640/4518] 58% | Training loss: 0.6871277811626594
Epoch: 33 | Iteration number: [2650/4518] 58% | Training loss: 0.6871237959276955
Epoch: 33 | Iteration number: [2660/4518] 58% | Training loss: 0.6871225048948948
Epoch: 33 | Iteration number: [2670/4518] 59% | Training loss: 0.6871197186159284
Epoch: 33 | Iteration number: [2680/4518] 59% | Training loss: 0.687114517679855
Epoch: 33 | Iteration number: [2690/4518] 59% | Training loss: 0.6871104782841906
Epoch: 33 | Iteration number: [2700/4518] 59% | Training loss: 0.6871137931391045
Epoch: 33 | Iteration number: [2710/4518] 59% | Training loss: 0.6871118979040547
Epoch: 33 | Iteration number: [2720/4518] 60% | Training loss: 0.6871098083389156
Epoch: 33 | Iteration number: [2730/4518] 60% | Training loss: 0.6871111211322602
Epoch: 33 | Iteration number: [2740/4518] 60% | Training loss: 0.6871124856010841
Epoch: 33 | Iteration number: [2750/4518] 60% | Training loss: 0.6871141939379952
Epoch: 33 | Iteration number: [2760/4518] 61% | Training loss: 0.687114715921706
Epoch: 33 | Iteration number: [2770/4518] 61% | Training loss: 0.6871146768869476
Epoch: 33 | Iteration number: [2780/4518] 61% | Training loss: 0.6871135279429045
Epoch: 33 | Iteration number: [2790/4518] 61% | Training loss: 0.6871178320872741
Epoch: 33 | Iteration number: [2800/4518] 61% | Training loss: 0.6871159744262695
Epoch: 33 | Iteration number: [2810/4518] 62% | Training loss: 0.6871133799654733
Epoch: 33 | Iteration number: [2820/4518] 62% | Training loss: 0.6871163556761776
Epoch: 33 | Iteration number: [2830/4518] 62% | Training loss: 0.6871140414328962
Epoch: 33 | Iteration number: [2840/4518] 62% | Training loss: 0.687112316426257
Epoch: 33 | Iteration number: [2850/4518] 63% | Training loss: 0.6871115932757395
Epoch: 33 | Iteration number: [2860/4518] 63% | Training loss: 0.6871176062763987
Epoch: 33 | Iteration number: [2870/4518] 63% | Training loss: 0.6871180797703175
Epoch: 33 | Iteration number: [2880/4518] 63% | Training loss: 0.6871167610088984
Epoch: 33 | Iteration number: [2890/4518] 63% | Training loss: 0.6871197810222534
Epoch: 33 | Iteration number: [2900/4518] 64% | Training loss: 0.6871235448944157
Epoch: 33 | Iteration number: [2910/4518] 64% | Training loss: 0.6871179779575453
Epoch: 33 | Iteration number: [2920/4518] 64% | Training loss: 0.6871174795374478
Epoch: 33 | Iteration number: [2930/4518] 64% | Training loss: 0.6871151146424915
Epoch: 33 | Iteration number: [2940/4518] 65% | Training loss: 0.6871140693523445
Epoch: 33 | Iteration number: [2950/4518] 65% | Training loss: 0.6871137427071393
Epoch: 33 | Iteration number: [2960/4518] 65% | Training loss: 0.6871091245396718
Epoch: 33 | Iteration number: [2970/4518] 65% | Training loss: 0.6871061011596963
Epoch: 33 | Iteration number: [2980/4518] 65% | Training loss: 0.6871029831619071
Epoch: 33 | Iteration number: [2990/4518] 66% | Training loss: 0.6871034602457066
Epoch: 33 | Iteration number: [3000/4518] 66% | Training loss: 0.6871004249453545
Epoch: 33 | Iteration number: [3010/4518] 66% | Training loss: 0.6870990895749722
Epoch: 33 | Iteration number: [3020/4518] 66% | Training loss: 0.687097377986308
Epoch: 33 | Iteration number: [3030/4518] 67% | Training loss: 0.6870974616249009
Epoch: 33 | Iteration number: [3040/4518] 67% | Training loss: 0.68709866186898
Epoch: 33 | Iteration number: [3050/4518] 67% | Training loss: 0.68709631632586
Epoch: 33 | Iteration number: [3060/4518] 67% | Training loss: 0.6870943207561581
Epoch: 33 | Iteration number: [3070/4518] 67% | Training loss: 0.6870985284496208
Epoch: 33 | Iteration number: [3080/4518] 68% | Training loss: 0.6870949250150037
Epoch: 33 | Iteration number: [3090/4518] 68% | Training loss: 0.6870915904592928
Epoch: 33 | Iteration number: [3100/4518] 68% | Training loss: 0.6870896991606682
Epoch: 33 | Iteration number: [3110/4518] 68% | Training loss: 0.6870890784685252
Epoch: 33 | Iteration number: [3120/4518] 69% | Training loss: 0.6870909016292829
Epoch: 33 | Iteration number: [3130/4518] 69% | Training loss: 0.6870901857130824
Epoch: 33 | Iteration number: [3140/4518] 69% | Training loss: 0.687087326957162
Epoch: 33 | Iteration number: [3150/4518] 69% | Training loss: 0.6870879064098238
Epoch: 33 | Iteration number: [3160/4518] 69% | Training loss: 0.6870876024606861
Epoch: 33 | Iteration number: [3170/4518] 70% | Training loss: 0.6870854653206534
Epoch: 33 | Iteration number: [3180/4518] 70% | Training loss: 0.6870879531094113
Epoch: 33 | Iteration number: [3190/4518] 70% | Training loss: 0.6870852050549558
Epoch: 33 | Iteration number: [3200/4518] 70% | Training loss: 0.6870836558565497
Epoch: 33 | Iteration number: [3210/4518] 71% | Training loss: 0.6870785773728867
Epoch: 33 | Iteration number: [3220/4518] 71% | Training loss: 0.6870781473306395
Epoch: 33 | Iteration number: [3230/4518] 71% | Training loss: 0.6870769064123785
Epoch: 33 | Iteration number: [3240/4518] 71% | Training loss: 0.6870739419519165
Epoch: 33 | Iteration number: [3250/4518] 71% | Training loss: 0.6870686492553124
Epoch: 33 | Iteration number: [3260/4518] 72% | Training loss: 0.6870696875398145
Epoch: 33 | Iteration number: [3270/4518] 72% | Training loss: 0.6870705278823864
Epoch: 33 | Iteration number: [3280/4518] 72% | Training loss: 0.6870738285343821
Epoch: 33 | Iteration number: [3290/4518] 72% | Training loss: 0.6870753503316804
Epoch: 33 | Iteration number: [3300/4518] 73% | Training loss: 0.6870742540106629
Epoch: 33 | Iteration number: [3310/4518] 73% | Training loss: 0.6870656199865831
Epoch: 33 | Iteration number: [3320/4518] 73% | Training loss: 0.6870655772556742
Epoch: 33 | Iteration number: [3330/4518] 73% | Training loss: 0.6870635399768302
Epoch: 33 | Iteration number: [3340/4518] 73% | Training loss: 0.6870616380326048
Epoch: 33 | Iteration number: [3350/4518] 74% | Training loss: 0.6870587574546017
Epoch: 33 | Iteration number: [3360/4518] 74% | Training loss: 0.6870550441422633
Epoch: 33 | Iteration number: [3370/4518] 74% | Training loss: 0.6870527745000686
Epoch: 33 | Iteration number: [3380/4518] 74% | Training loss: 0.6870517296198557
Epoch: 33 | Iteration number: [3390/4518] 75% | Training loss: 0.6870522415040166
Epoch: 33 | Iteration number: [3400/4518] 75% | Training loss: 0.6870492454662043
Epoch: 33 | Iteration number: [3410/4518] 75% | Training loss: 0.6870470455839487
Epoch: 33 | Iteration number: [3420/4518] 75% | Training loss: 0.6870459301081318
Epoch: 33 | Iteration number: [3430/4518] 75% | Training loss: 0.6870452431652359
Epoch: 33 | Iteration number: [3440/4518] 76% | Training loss: 0.687044654474702
Epoch: 33 | Iteration number: [3450/4518] 76% | Training loss: 0.6870439573301785
Epoch: 33 | Iteration number: [3460/4518] 76% | Training loss: 0.6870444224404462
Epoch: 33 | Iteration number: [3470/4518] 76% | Training loss: 0.6870398973181887
Epoch: 33 | Iteration number: [3480/4518] 77% | Training loss: 0.6870397683018925
Epoch: 33 | Iteration number: [3490/4518] 77% | Training loss: 0.687038960446601
Epoch: 33 | Iteration number: [3500/4518] 77% | Training loss: 0.6870384634052004
Epoch: 33 | Iteration number: [3510/4518] 77% | Training loss: 0.6870383614658291
Epoch: 33 | Iteration number: [3520/4518] 77% | Training loss: 0.6870389666238969
Epoch: 33 | Iteration number: [3530/4518] 78% | Training loss: 0.6870396263876313
Epoch: 33 | Iteration number: [3540/4518] 78% | Training loss: 0.6870393587707799
Epoch: 33 | Iteration number: [3550/4518] 78% | Training loss: 0.687038176932805
Epoch: 33 | Iteration number: [3560/4518] 78% | Training loss: 0.687040692350168
Epoch: 33 | Iteration number: [3570/4518] 79% | Training loss: 0.6870372997612513
Epoch: 33 | Iteration number: [3580/4518] 79% | Training loss: 0.6870353265015107
Epoch: 33 | Iteration number: [3590/4518] 79% | Training loss: 0.6870351843017057
Epoch: 33 | Iteration number: [3600/4518] 79% | Training loss: 0.6870347543888622
Epoch: 33 | Iteration number: [3610/4518] 79% | Training loss: 0.6870356745997294
Epoch: 33 | Iteration number: [3620/4518] 80% | Training loss: 0.6870374499763573
Epoch: 33 | Iteration number: [3630/4518] 80% | Training loss: 0.6870374951809234
Epoch: 33 | Iteration number: [3640/4518] 80% | Training loss: 0.6870399703527544
Epoch: 33 | Iteration number: [3650/4518] 80% | Training loss: 0.6870395133756612
Epoch: 33 | Iteration number: [3660/4518] 81% | Training loss: 0.6870353496302672
Epoch: 33 | Iteration number: [3670/4518] 81% | Training loss: 0.6870331459539138
Epoch: 33 | Iteration number: [3680/4518] 81% | Training loss: 0.6870293159037828
Epoch: 33 | Iteration number: [3690/4518] 81% | Training loss: 0.687024077151203
Epoch: 33 | Iteration number: [3700/4518] 81% | Training loss: 0.6870242445855528
Epoch: 33 | Iteration number: [3710/4518] 82% | Training loss: 0.6870219713272753
Epoch: 33 | Iteration number: [3720/4518] 82% | Training loss: 0.6870204494525027
Epoch: 33 | Iteration number: [3730/4518] 82% | Training loss: 0.6870211955050042
Epoch: 33 | Iteration number: [3740/4518] 82% | Training loss: 0.6870203609135062
Epoch: 33 | Iteration number: [3750/4518] 83% | Training loss: 0.6870207688967387
Epoch: 33 | Iteration number: [3760/4518] 83% | Training loss: 0.6870189315936667
Epoch: 33 | Iteration number: [3770/4518] 83% | Training loss: 0.6870182653004674
Epoch: 33 | Iteration number: [3780/4518] 83% | Training loss: 0.68701570275284
Epoch: 33 | Iteration number: [3790/4518] 83% | Training loss: 0.6870116464695389
Epoch: 33 | Iteration number: [3800/4518] 84% | Training loss: 0.6870143739800704
Epoch: 33 | Iteration number: [3810/4518] 84% | Training loss: 0.687013519451687
Epoch: 33 | Iteration number: [3820/4518] 84% | Training loss: 0.6870119433128397
Epoch: 33 | Iteration number: [3830/4518] 84% | Training loss: 0.6870116892122413
Epoch: 33 | Iteration number: [3840/4518] 84% | Training loss: 0.6870121307205409
Epoch: 33 | Iteration number: [3850/4518] 85% | Training loss: 0.6870129759125896
Epoch: 33 | Iteration number: [3860/4518] 85% | Training loss: 0.6870128643790675
Epoch: 33 | Iteration number: [3870/4518] 85% | Training loss: 0.687013724484801
Epoch: 33 | Iteration number: [3880/4518] 85% | Training loss: 0.6870108365858953
Epoch: 33 | Iteration number: [3890/4518] 86% | Training loss: 0.6870130587053176
Epoch: 33 | Iteration number: [3900/4518] 86% | Training loss: 0.6870147028794655
Epoch: 33 | Iteration number: [3910/4518] 86% | Training loss: 0.6870131811827345
Epoch: 33 | Iteration number: [3920/4518] 86% | Training loss: 0.6870119229567294
Epoch: 33 | Iteration number: [3930/4518] 86% | Training loss: 0.6870125341203073
Epoch: 33 | Iteration number: [3940/4518] 87% | Training loss: 0.6870133377422536
Epoch: 33 | Iteration number: [3950/4518] 87% | Training loss: 0.6870125758346123
Epoch: 33 | Iteration number: [3960/4518] 87% | Training loss: 0.687013811881494
Epoch: 33 | Iteration number: [3970/4518] 87% | Training loss: 0.6870157298873594
Epoch: 33 | Iteration number: [3980/4518] 88% | Training loss: 0.6870182607491412
Epoch: 33 | Iteration number: [3990/4518] 88% | Training loss: 0.6870156950968549
Epoch: 33 | Iteration number: [4000/4518] 88% | Training loss: 0.6870132547914982
Epoch: 33 | Iteration number: [4010/4518] 88% | Training loss: 0.68701543724745
Epoch: 33 | Iteration number: [4020/4518] 88% | Training loss: 0.6870150443629839
Epoch: 33 | Iteration number: [4030/4518] 89% | Training loss: 0.6870168577944374
Epoch: 33 | Iteration number: [4040/4518] 89% | Training loss: 0.6870155574366598
Epoch: 33 | Iteration number: [4050/4518] 89% | Training loss: 0.6870165310524128
Epoch: 33 | Iteration number: [4060/4518] 89% | Training loss: 0.6870150807749462
Epoch: 33 | Iteration number: [4070/4518] 90% | Training loss: 0.6870102373768715
Epoch: 33 | Iteration number: [4080/4518] 90% | Training loss: 0.6870099944665151
Epoch: 33 | Iteration number: [4090/4518] 90% | Training loss: 0.6870060852220997
Epoch: 33 | Iteration number: [4100/4518] 90% | Training loss: 0.6870070264979107
Epoch: 33 | Iteration number: [4110/4518] 90% | Training loss: 0.6870043146349217
Epoch: 33 | Iteration number: [4120/4518] 91% | Training loss: 0.6870041091175912
Epoch: 33 | Iteration number: [4130/4518] 91% | Training loss: 0.6870035114357604
Epoch: 33 | Iteration number: [4140/4518] 91% | Training loss: 0.6870003312538211
Epoch: 33 | Iteration number: [4150/4518] 91% | Training loss: 0.6870006322286215
Epoch: 33 | Iteration number: [4160/4518] 92% | Training loss: 0.6869986877848323
Epoch: 33 | Iteration number: [4170/4518] 92% | Training loss: 0.6869968387863333
Epoch: 33 | Iteration number: [4180/4518] 92% | Training loss: 0.6869964619144868
Epoch: 33 | Iteration number: [4190/4518] 92% | Training loss: 0.686996933753849
Epoch: 33 | Iteration number: [4200/4518] 92% | Training loss: 0.6869978028535842
Epoch: 33 | Iteration number: [4210/4518] 93% | Training loss: 0.6869978473616892
Epoch: 33 | Iteration number: [4220/4518] 93% | Training loss: 0.6869951692661402
Epoch: 33 | Iteration number: [4230/4518] 93% | Training loss: 0.6869958449903673
Epoch: 33 | Iteration number: [4240/4518] 93% | Training loss: 0.686994585690071
Epoch: 33 | Iteration number: [4250/4518] 94% | Training loss: 0.6869963551549351
Epoch: 33 | Iteration number: [4260/4518] 94% | Training loss: 0.6869960579653861
Epoch: 33 | Iteration number: [4270/4518] 94% | Training loss: 0.6869977541634293
Epoch: 33 | Iteration number: [4280/4518] 94% | Training loss: 0.687000319946592
Epoch: 33 | Iteration number: [4290/4518] 94% | Training loss: 0.6869984136039005
Epoch: 33 | Iteration number: [4300/4518] 95% | Training loss: 0.6870004552464153
Epoch: 33 | Iteration number: [4310/4518] 95% | Training loss: 0.6869978039972744
Epoch: 33 | Iteration number: [4320/4518] 95% | Training loss: 0.6869965537692662
Epoch: 33 | Iteration number: [4330/4518] 95% | Training loss: 0.6869958478501432
Epoch: 33 | Iteration number: [4340/4518] 96% | Training loss: 0.6869984117246444
Epoch: 33 | Iteration number: [4350/4518] 96% | Training loss: 0.6870004924823498
Epoch: 33 | Iteration number: [4360/4518] 96% | Training loss: 0.6870020471855041
Epoch: 33 | Iteration number: [4370/4518] 96% | Training loss: 0.6870033434244807
Epoch: 33 | Iteration number: [4380/4518] 96% | Training loss: 0.6870043659999491
Epoch: 33 | Iteration number: [4390/4518] 97% | Training loss: 0.6870048121737999
Epoch: 33 | Iteration number: [4400/4518] 97% | Training loss: 0.6870023113624616
Epoch: 33 | Iteration number: [4410/4518] 97% | Training loss: 0.6870011394256367
Epoch: 33 | Iteration number: [4420/4518] 97% | Training loss: 0.6870010282524032
Epoch: 33 | Iteration number: [4430/4518] 98% | Training loss: 0.6870035791370185
Epoch: 33 | Iteration number: [4440/4518] 98% | Training loss: 0.6870021714686273
Epoch: 33 | Iteration number: [4450/4518] 98% | Training loss: 0.6870019899191482
Epoch: 33 | Iteration number: [4460/4518] 98% | Training loss: 0.6870007834092384
Epoch: 33 | Iteration number: [4470/4518] 98% | Training loss: 0.6870019729372105
Epoch: 33 | Iteration number: [4480/4518] 99% | Training loss: 0.6870024802429335
Epoch: 33 | Iteration number: [4490/4518] 99% | Training loss: 0.6870026597599675
Epoch: 33 | Iteration number: [4500/4518] 99% | Training loss: 0.6870058154794905
Epoch: 33 | Iteration number: [4510/4518] 99% | Training loss: 0.6870031884134212

 End of epoch: 33 | Train Loss: 0.6868518067308631 | Training Time: 642 

 End of epoch: 33 | Eval Loss: 0.6901901133206426 | Evaluating Time: 17 
Epoch: 34 | Iteration number: [10/4518] 0% | Training loss: 0.7559944212436676
Epoch: 34 | Iteration number: [20/4518] 0% | Training loss: 0.7211236476898193
Epoch: 34 | Iteration number: [30/4518] 0% | Training loss: 0.7096088210741679
Epoch: 34 | Iteration number: [40/4518] 0% | Training loss: 0.7037301555275917
Epoch: 34 | Iteration number: [50/4518] 1% | Training loss: 0.700336879491806
Epoch: 34 | Iteration number: [60/4518] 1% | Training loss: 0.6981711049874624
Epoch: 34 | Iteration number: [70/4518] 1% | Training loss: 0.6965509338038308
Epoch: 34 | Iteration number: [80/4518] 1% | Training loss: 0.6953053943812847
Epoch: 34 | Iteration number: [90/4518] 1% | Training loss: 0.6945118221971723
Epoch: 34 | Iteration number: [100/4518] 2% | Training loss: 0.693714570403099
Epoch: 34 | Iteration number: [110/4518] 2% | Training loss: 0.6931152717633681
Epoch: 34 | Iteration number: [120/4518] 2% | Training loss: 0.6925626243154208
Epoch: 34 | Iteration number: [130/4518] 2% | Training loss: 0.6920855077413413
Epoch: 34 | Iteration number: [140/4518] 3% | Training loss: 0.6917043460266931
Epoch: 34 | Iteration number: [150/4518] 3% | Training loss: 0.6912950646877288
Epoch: 34 | Iteration number: [160/4518] 3% | Training loss: 0.6909994974732399
Epoch: 34 | Iteration number: [170/4518] 3% | Training loss: 0.6907708322300631
Epoch: 34 | Iteration number: [180/4518] 3% | Training loss: 0.6905645887056987
Epoch: 34 | Iteration number: [190/4518] 4% | Training loss: 0.6903716369679099
Epoch: 34 | Iteration number: [200/4518] 4% | Training loss: 0.6901573818922043
Epoch: 34 | Iteration number: [210/4518] 4% | Training loss: 0.689967382805688
Epoch: 34 | Iteration number: [220/4518] 4% | Training loss: 0.6898109980604865
Epoch: 34 | Iteration number: [230/4518] 5% | Training loss: 0.6897113916666612
Epoch: 34 | Iteration number: [240/4518] 5% | Training loss: 0.6895454451441765
Epoch: 34 | Iteration number: [250/4518] 5% | Training loss: 0.6895015225410461
Epoch: 34 | Iteration number: [260/4518] 5% | Training loss: 0.6894385897196256
Epoch: 34 | Iteration number: [270/4518] 5% | Training loss: 0.6893691073965144
Epoch: 34 | Iteration number: [280/4518] 6% | Training loss: 0.6893127637250083
Epoch: 34 | Iteration number: [290/4518] 6% | Training loss: 0.6892104566097259
Epoch: 34 | Iteration number: [300/4518] 6% | Training loss: 0.689115560054779
Epoch: 34 | Iteration number: [310/4518] 6% | Training loss: 0.6890501481871452
Epoch: 34 | Iteration number: [320/4518] 7% | Training loss: 0.6889713058248162
Epoch: 34 | Iteration number: [330/4518] 7% | Training loss: 0.6888655521652916
Epoch: 34 | Iteration number: [340/4518] 7% | Training loss: 0.6887962600764106
Epoch: 34 | Iteration number: [350/4518] 7% | Training loss: 0.6887136920860836
Epoch: 34 | Iteration number: [360/4518] 7% | Training loss: 0.6886507870422469
Epoch: 34 | Iteration number: [370/4518] 8% | Training loss: 0.688589204485352
Epoch: 34 | Iteration number: [380/4518] 8% | Training loss: 0.6885315755480215
Epoch: 34 | Iteration number: [390/4518] 8% | Training loss: 0.6884812643894782
Epoch: 34 | Iteration number: [400/4518] 8% | Training loss: 0.6884844368696212
Epoch: 34 | Iteration number: [410/4518] 9% | Training loss: 0.6884259251559653
Epoch: 34 | Iteration number: [420/4518] 9% | Training loss: 0.6883781766607648
Epoch: 34 | Iteration number: [430/4518] 9% | Training loss: 0.6883228405963543
Epoch: 34 | Iteration number: [440/4518] 9% | Training loss: 0.6882704493674365
Epoch: 34 | Iteration number: [450/4518] 9% | Training loss: 0.6882618055078719
Epoch: 34 | Iteration number: [460/4518] 10% | Training loss: 0.6882409279761107
Epoch: 34 | Iteration number: [470/4518] 10% | Training loss: 0.6882060947570395
Epoch: 34 | Iteration number: [480/4518] 10% | Training loss: 0.6881579664846261
Epoch: 34 | Iteration number: [490/4518] 10% | Training loss: 0.6881422175436603
Epoch: 34 | Iteration number: [500/4518] 11% | Training loss: 0.6881201982498169
Epoch: 34 | Iteration number: [510/4518] 11% | Training loss: 0.6881180164860744
Epoch: 34 | Iteration number: [520/4518] 11% | Training loss: 0.6880929611050166
Epoch: 34 | Iteration number: [530/4518] 11% | Training loss: 0.6881040010812147
Epoch: 34 | Iteration number: [540/4518] 11% | Training loss: 0.6880897654427423
Epoch: 34 | Iteration number: [550/4518] 12% | Training loss: 0.6880657621947202
Epoch: 34 | Iteration number: [560/4518] 12% | Training loss: 0.6880483942372458
Epoch: 34 | Iteration number: [570/4518] 12% | Training loss: 0.6880114017871388
Epoch: 34 | Iteration number: [580/4518] 12% | Training loss: 0.6880177477310444
Epoch: 34 | Iteration number: [590/4518] 13% | Training loss: 0.6879870900663279
Epoch: 34 | Iteration number: [600/4518] 13% | Training loss: 0.6879597327113152
Epoch: 34 | Iteration number: [610/4518] 13% | Training loss: 0.6879607767355247
Epoch: 34 | Iteration number: [620/4518] 13% | Training loss: 0.6879525267308758
Epoch: 34 | Iteration number: [630/4518] 13% | Training loss: 0.687921125642837
Epoch: 34 | Iteration number: [640/4518] 14% | Training loss: 0.6879032470285893
Epoch: 34 | Iteration number: [650/4518] 14% | Training loss: 0.6878786982022799
Epoch: 34 | Iteration number: [660/4518] 14% | Training loss: 0.687866940371918
Epoch: 34 | Iteration number: [670/4518] 14% | Training loss: 0.6878563569552862
Epoch: 34 | Iteration number: [680/4518] 15% | Training loss: 0.6878504902124405
Epoch: 34 | Iteration number: [690/4518] 15% | Training loss: 0.687840821000113
Epoch: 34 | Iteration number: [700/4518] 15% | Training loss: 0.6878306295190538
Epoch: 34 | Iteration number: [710/4518] 15% | Training loss: 0.6878121762208536
Epoch: 34 | Iteration number: [720/4518] 15% | Training loss: 0.6877828813261456
Epoch: 34 | Iteration number: [730/4518] 16% | Training loss: 0.6877654033164455
Epoch: 34 | Iteration number: [740/4518] 16% | Training loss: 0.6877417652993589
Epoch: 34 | Iteration number: [750/4518] 16% | Training loss: 0.6877241458098093
Epoch: 34 | Iteration number: [760/4518] 16% | Training loss: 0.6876868988338269
Epoch: 34 | Iteration number: [770/4518] 17% | Training loss: 0.6876593835168071
Epoch: 34 | Iteration number: [780/4518] 17% | Training loss: 0.6876333089975211
Epoch: 34 | Iteration number: [790/4518] 17% | Training loss: 0.6876454708696921
Epoch: 34 | Iteration number: [800/4518] 17% | Training loss: 0.6876325634866953
Epoch: 34 | Iteration number: [810/4518] 17% | Training loss: 0.6876224233780378
Epoch: 34 | Iteration number: [820/4518] 18% | Training loss: 0.6876168445843022
Epoch: 34 | Iteration number: [830/4518] 18% | Training loss: 0.6875990380723792
Epoch: 34 | Iteration number: [840/4518] 18% | Training loss: 0.6875620702192897
Epoch: 34 | Iteration number: [850/4518] 18% | Training loss: 0.6875630203415366
Epoch: 34 | Iteration number: [860/4518] 19% | Training loss: 0.6875581698362218
Epoch: 34 | Iteration number: [870/4518] 19% | Training loss: 0.6875298728202951
Epoch: 34 | Iteration number: [880/4518] 19% | Training loss: 0.6875138517807831
Epoch: 34 | Iteration number: [890/4518] 19% | Training loss: 0.6875101869025927
Epoch: 34 | Iteration number: [900/4518] 19% | Training loss: 0.6874927235311932
Epoch: 34 | Iteration number: [910/4518] 20% | Training loss: 0.6874852105156406
Epoch: 34 | Iteration number: [920/4518] 20% | Training loss: 0.6874813985565434
Epoch: 34 | Iteration number: [930/4518] 20% | Training loss: 0.6874712654980281
Epoch: 34 | Iteration number: [940/4518] 20% | Training loss: 0.6874507832400343
Epoch: 34 | Iteration number: [950/4518] 21% | Training loss: 0.6874392073405416
Epoch: 34 | Iteration number: [960/4518] 21% | Training loss: 0.6874360753844182
Epoch: 34 | Iteration number: [970/4518] 21% | Training loss: 0.6874337340753103
Epoch: 34 | Iteration number: [980/4518] 21% | Training loss: 0.6874222098564615
Epoch: 34 | Iteration number: [990/4518] 21% | Training loss: 0.6874179679938037
Epoch: 34 | Iteration number: [1000/4518] 22% | Training loss: 0.6874121491312981
Epoch: 34 | Iteration number: [1010/4518] 22% | Training loss: 0.6874235426435377
Epoch: 34 | Iteration number: [1020/4518] 22% | Training loss: 0.6874139120181402
Epoch: 34 | Iteration number: [1030/4518] 22% | Training loss: 0.6874197538616588
Epoch: 34 | Iteration number: [1040/4518] 23% | Training loss: 0.687416388037113
Epoch: 34 | Iteration number: [1050/4518] 23% | Training loss: 0.6874111053489503
Epoch: 34 | Iteration number: [1060/4518] 23% | Training loss: 0.6874109426197016
Epoch: 34 | Iteration number: [1070/4518] 23% | Training loss: 0.6874175838777952
Epoch: 34 | Iteration number: [1080/4518] 23% | Training loss: 0.6874159258272913
Epoch: 34 | Iteration number: [1090/4518] 24% | Training loss: 0.6874109033597718
Epoch: 34 | Iteration number: [1100/4518] 24% | Training loss: 0.6874155985225331
Epoch: 34 | Iteration number: [1110/4518] 24% | Training loss: 0.6874074263078672
Epoch: 34 | Iteration number: [1120/4518] 24% | Training loss: 0.6874005750886032
Epoch: 34 | Iteration number: [1130/4518] 25% | Training loss: 0.6873957009442084
Epoch: 34 | Iteration number: [1140/4518] 25% | Training loss: 0.6873904126255136
Epoch: 34 | Iteration number: [1150/4518] 25% | Training loss: 0.6873913703794065
Epoch: 34 | Iteration number: [1160/4518] 25% | Training loss: 0.6873805350784598
Epoch: 34 | Iteration number: [1170/4518] 25% | Training loss: 0.6873788530500526
Epoch: 34 | Iteration number: [1180/4518] 26% | Training loss: 0.6873645787521944
Epoch: 34 | Iteration number: [1190/4518] 26% | Training loss: 0.6873438588210514
Epoch: 34 | Iteration number: [1200/4518] 26% | Training loss: 0.6873474030693372
Epoch: 34 | Iteration number: [1210/4518] 26% | Training loss: 0.6873521274771572
Epoch: 34 | Iteration number: [1220/4518] 27% | Training loss: 0.687354878128552
Epoch: 34 | Iteration number: [1230/4518] 27% | Training loss: 0.6873557230321372
Epoch: 34 | Iteration number: [1240/4518] 27% | Training loss: 0.6873550593372314
Epoch: 34 | Iteration number: [1250/4518] 27% | Training loss: 0.6873503829956055
Epoch: 34 | Iteration number: [1260/4518] 27% | Training loss: 0.6873501194847955
Epoch: 34 | Iteration number: [1270/4518] 28% | Training loss: 0.6873614935893712
Epoch: 34 | Iteration number: [1280/4518] 28% | Training loss: 0.6873658946249634
Epoch: 34 | Iteration number: [1290/4518] 28% | Training loss: 0.6873597665812619
Epoch: 34 | Iteration number: [1300/4518] 28% | Training loss: 0.6873542777850078
Epoch: 34 | Iteration number: [1310/4518] 28% | Training loss: 0.6873563217752763
Epoch: 34 | Iteration number: [1320/4518] 29% | Training loss: 0.6873528521169315
Epoch: 34 | Iteration number: [1330/4518] 29% | Training loss: 0.6873437753297332
Epoch: 34 | Iteration number: [1340/4518] 29% | Training loss: 0.6873417512694402
Epoch: 34 | Iteration number: [1350/4518] 29% | Training loss: 0.6873376845430444
Epoch: 34 | Iteration number: [1360/4518] 30% | Training loss: 0.6873415275093387
Epoch: 34 | Iteration number: [1370/4518] 30% | Training loss: 0.6873328388607415
Epoch: 34 | Iteration number: [1380/4518] 30% | Training loss: 0.6873229967079301
Epoch: 34 | Iteration number: [1390/4518] 30% | Training loss: 0.6873190346810457
Epoch: 34 | Iteration number: [1400/4518] 30% | Training loss: 0.6873217699357441
Epoch: 34 | Iteration number: [1410/4518] 31% | Training loss: 0.6873189470023974
Epoch: 34 | Iteration number: [1420/4518] 31% | Training loss: 0.6873244254521921
Epoch: 34 | Iteration number: [1430/4518] 31% | Training loss: 0.6873206973909498
Epoch: 34 | Iteration number: [1440/4518] 31% | Training loss: 0.6873111527413129
Epoch: 34 | Iteration number: [1450/4518] 32% | Training loss: 0.687313473800133
Epoch: 34 | Iteration number: [1460/4518] 32% | Training loss: 0.6873122727625991
Epoch: 34 | Iteration number: [1470/4518] 32% | Training loss: 0.6873119102854307
Epoch: 34 | Iteration number: [1480/4518] 32% | Training loss: 0.6873059958622262
Epoch: 34 | Iteration number: [1490/4518] 32% | Training loss: 0.6873062932651315
Epoch: 34 | Iteration number: [1500/4518] 33% | Training loss: 0.6873057765960693
Epoch: 34 | Iteration number: [1510/4518] 33% | Training loss: 0.6873100697599499
Epoch: 34 | Iteration number: [1520/4518] 33% | Training loss: 0.6873117551207543
Epoch: 34 | Iteration number: [1530/4518] 33% | Training loss: 0.6873084642139136
Epoch: 34 | Iteration number: [1540/4518] 34% | Training loss: 0.6873055037739989
Epoch: 34 | Iteration number: [1550/4518] 34% | Training loss: 0.6873028165294278
Epoch: 34 | Iteration number: [1560/4518] 34% | Training loss: 0.6873074383689807
Epoch: 34 | Iteration number: [1570/4518] 34% | Training loss: 0.6873040995400422
Epoch: 34 | Iteration number: [1580/4518] 34% | Training loss: 0.6872881597733196
Epoch: 34 | Iteration number: [1590/4518] 35% | Training loss: 0.6872790064076958
Epoch: 34 | Iteration number: [1600/4518] 35% | Training loss: 0.6872718822211027
Epoch: 34 | Iteration number: [1610/4518] 35% | Training loss: 0.6872704318221311
Epoch: 34 | Iteration number: [1620/4518] 35% | Training loss: 0.6872666938805286
Epoch: 34 | Iteration number: [1630/4518] 36% | Training loss: 0.6872661151037626
Epoch: 34 | Iteration number: [1640/4518] 36% | Training loss: 0.6872622732345651
Epoch: 34 | Iteration number: [1650/4518] 36% | Training loss: 0.6872574637152932
Epoch: 34 | Iteration number: [1660/4518] 36% | Training loss: 0.687250317974263
Epoch: 34 | Iteration number: [1670/4518] 36% | Training loss: 0.6872495615910628
Epoch: 34 | Iteration number: [1680/4518] 37% | Training loss: 0.6872424614926179
Epoch: 34 | Iteration number: [1690/4518] 37% | Training loss: 0.6872368420722217
Epoch: 34 | Iteration number: [1700/4518] 37% | Training loss: 0.6872327752674328
Epoch: 34 | Iteration number: [1710/4518] 37% | Training loss: 0.6872318369603296
Epoch: 34 | Iteration number: [1720/4518] 38% | Training loss: 0.6872345083674719
Epoch: 34 | Iteration number: [1730/4518] 38% | Training loss: 0.6872346947992468
Epoch: 34 | Iteration number: [1740/4518] 38% | Training loss: 0.687237222783867
Epoch: 34 | Iteration number: [1750/4518] 38% | Training loss: 0.6872325770173754
Epoch: 34 | Iteration number: [1760/4518] 38% | Training loss: 0.6872276230291887
Epoch: 34 | Iteration number: [1770/4518] 39% | Training loss: 0.6872198299162805
Epoch: 34 | Iteration number: [1780/4518] 39% | Training loss: 0.6872147200817472
Epoch: 34 | Iteration number: [1790/4518] 39% | Training loss: 0.6872080985727257
Epoch: 34 | Iteration number: [1800/4518] 39% | Training loss: 0.687199668917391
Epoch: 34 | Iteration number: [1810/4518] 40% | Training loss: 0.6871999448504896
Epoch: 34 | Iteration number: [1820/4518] 40% | Training loss: 0.6872017448420052
Epoch: 34 | Iteration number: [1830/4518] 40% | Training loss: 0.6872050139421974
Epoch: 34 | Iteration number: [1840/4518] 40% | Training loss: 0.6872018851663755
Epoch: 34 | Iteration number: [1850/4518] 40% | Training loss: 0.6872067383173349
Epoch: 34 | Iteration number: [1860/4518] 41% | Training loss: 0.6872049813949933
Epoch: 34 | Iteration number: [1870/4518] 41% | Training loss: 0.6872155038111988
Epoch: 34 | Iteration number: [1880/4518] 41% | Training loss: 0.6872098510569714
Epoch: 34 | Iteration number: [1890/4518] 41% | Training loss: 0.6872069450282546
Epoch: 34 | Iteration number: [1900/4518] 42% | Training loss: 0.6872055721910376
Epoch: 34 | Iteration number: [1910/4518] 42% | Training loss: 0.6872051187210683
Epoch: 34 | Iteration number: [1920/4518] 42% | Training loss: 0.6871965354929368
Epoch: 34 | Iteration number: [1930/4518] 42% | Training loss: 0.6871957808269737
Epoch: 34 | Iteration number: [1940/4518] 42% | Training loss: 0.6871917021643256
Epoch: 34 | Iteration number: [1950/4518] 43% | Training loss: 0.6871914835159595
Epoch: 34 | Iteration number: [1960/4518] 43% | Training loss: 0.6871885278699349
Epoch: 34 | Iteration number: [1970/4518] 43% | Training loss: 0.6871893437078156
Epoch: 34 | Iteration number: [1980/4518] 43% | Training loss: 0.6871816179065994
Epoch: 34 | Iteration number: [1990/4518] 44% | Training loss: 0.68718092645233
Epoch: 34 | Iteration number: [2000/4518] 44% | Training loss: 0.6871782237589359
Epoch: 34 | Iteration number: [2010/4518] 44% | Training loss: 0.6871817066005214
Epoch: 34 | Iteration number: [2020/4518] 44% | Training loss: 0.6871829526259168
Epoch: 34 | Iteration number: [2030/4518] 44% | Training loss: 0.6871807753452527
Epoch: 34 | Iteration number: [2040/4518] 45% | Training loss: 0.6871800510322347
Epoch: 34 | Iteration number: [2050/4518] 45% | Training loss: 0.6871806473848296
Epoch: 34 | Iteration number: [2060/4518] 45% | Training loss: 0.6871760372976655
Epoch: 34 | Iteration number: [2070/4518] 45% | Training loss: 0.6871801003741758
Epoch: 34 | Iteration number: [2080/4518] 46% | Training loss: 0.6871833872050047
Epoch: 34 | Iteration number: [2090/4518] 46% | Training loss: 0.6871873400142888
Epoch: 34 | Iteration number: [2100/4518] 46% | Training loss: 0.6871886797462191
Epoch: 34 | Iteration number: [2110/4518] 46% | Training loss: 0.6871860757258266
Epoch: 34 | Iteration number: [2120/4518] 46% | Training loss: 0.6871851428499761
Epoch: 34 | Iteration number: [2130/4518] 47% | Training loss: 0.687187953734062
Epoch: 34 | Iteration number: [2140/4518] 47% | Training loss: 0.6871887600031968
Epoch: 34 | Iteration number: [2150/4518] 47% | Training loss: 0.687185841715613
Epoch: 34 | Iteration number: [2160/4518] 47% | Training loss: 0.6871888603049295
Epoch: 34 | Iteration number: [2170/4518] 48% | Training loss: 0.6871852029029125
Epoch: 34 | Iteration number: [2180/4518] 48% | Training loss: 0.6871825888889646
Epoch: 34 | Iteration number: [2190/4518] 48% | Training loss: 0.6871849146335637
Epoch: 34 | Iteration number: [2200/4518] 48% | Training loss: 0.6871843031861565
Epoch: 34 | Iteration number: [2210/4518] 48% | Training loss: 0.6871833919939412
Epoch: 34 | Iteration number: [2220/4518] 49% | Training loss: 0.6871818007112623
Epoch: 34 | Iteration number: [2230/4518] 49% | Training loss: 0.6871826446377108
Epoch: 34 | Iteration number: [2240/4518] 49% | Training loss: 0.6871804884767958
Epoch: 34 | Iteration number: [2250/4518] 49% | Training loss: 0.6871804647710589
Epoch: 34 | Iteration number: [2260/4518] 50% | Training loss: 0.6871812985797899
Epoch: 34 | Iteration number: [2270/4518] 50% | Training loss: 0.6871839557975399
Epoch: 34 | Iteration number: [2280/4518] 50% | Training loss: 0.6871864179247305
Epoch: 34 | Iteration number: [2290/4518] 50% | Training loss: 0.68717574870222
Epoch: 34 | Iteration number: [2300/4518] 50% | Training loss: 0.6871732828668926
Epoch: 34 | Iteration number: [2310/4518] 51% | Training loss: 0.6871760510004961
Epoch: 34 | Iteration number: [2320/4518] 51% | Training loss: 0.6871738815359001
Epoch: 34 | Iteration number: [2330/4518] 51% | Training loss: 0.6871691633703371
Epoch: 34 | Iteration number: [2340/4518] 51% | Training loss: 0.6871641388306251
Epoch: 34 | Iteration number: [2350/4518] 52% | Training loss: 0.6871622886809897
Epoch: 34 | Iteration number: [2360/4518] 52% | Training loss: 0.6871598006305047
Epoch: 34 | Iteration number: [2370/4518] 52% | Training loss: 0.687157821755872
Epoch: 34 | Iteration number: [2380/4518] 52% | Training loss: 0.6871540128433404
Epoch: 34 | Iteration number: [2390/4518] 52% | Training loss: 0.6871506236836501
Epoch: 34 | Iteration number: [2400/4518] 53% | Training loss: 0.6871530476212502
Epoch: 34 | Iteration number: [2410/4518] 53% | Training loss: 0.6871498023325971
Epoch: 34 | Iteration number: [2420/4518] 53% | Training loss: 0.6871442630517581
Epoch: 34 | Iteration number: [2430/4518] 53% | Training loss: 0.687143290705151
Epoch: 34 | Iteration number: [2440/4518] 54% | Training loss: 0.687138275899848
Epoch: 34 | Iteration number: [2450/4518] 54% | Training loss: 0.6871408725028135
Epoch: 34 | Iteration number: [2460/4518] 54% | Training loss: 0.6871398407996185
Epoch: 34 | Iteration number: [2470/4518] 54% | Training loss: 0.6871348807927568
Epoch: 34 | Iteration number: [2480/4518] 54% | Training loss: 0.6871383042825806
Epoch: 34 | Iteration number: [2490/4518] 55% | Training loss: 0.6871374534076476
Epoch: 34 | Iteration number: [2500/4518] 55% | Training loss: 0.6871337369918823
Epoch: 34 | Iteration number: [2510/4518] 55% | Training loss: 0.687133617515108
Epoch: 34 | Iteration number: [2520/4518] 55% | Training loss: 0.6871332769829129
Epoch: 34 | Iteration number: [2530/4518] 55% | Training loss: 0.6871314472360573
Epoch: 34 | Iteration number: [2540/4518] 56% | Training loss: 0.6871312611919689
Epoch: 34 | Iteration number: [2550/4518] 56% | Training loss: 0.687129176644718
Epoch: 34 | Iteration number: [2560/4518] 56% | Training loss: 0.6871286316541955
Epoch: 34 | Iteration number: [2570/4518] 56% | Training loss: 0.6871346733449498
Epoch: 34 | Iteration number: [2580/4518] 57% | Training loss: 0.6871381237063297
Epoch: 34 | Iteration number: [2590/4518] 57% | Training loss: 0.6871328051486071
Epoch: 34 | Iteration number: [2600/4518] 57% | Training loss: 0.6871346555077112
Epoch: 34 | Iteration number: [2610/4518] 57% | Training loss: 0.6871319700018199
Epoch: 34 | Iteration number: [2620/4518] 57% | Training loss: 0.6871299589635762
Epoch: 34 | Iteration number: [2630/4518] 58% | Training loss: 0.6871337937764795
Epoch: 34 | Iteration number: [2640/4518] 58% | Training loss: 0.6871340719136325
Epoch: 34 | Iteration number: [2650/4518] 58% | Training loss: 0.687130320836913
Epoch: 34 | Iteration number: [2660/4518] 58% | Training loss: 0.6871309043993628
Epoch: 34 | Iteration number: [2670/4518] 59% | Training loss: 0.6871280203597823
Epoch: 34 | Iteration number: [2680/4518] 59% | Training loss: 0.6871299234121593
Epoch: 34 | Iteration number: [2690/4518] 59% | Training loss: 0.6871290773264095
Epoch: 34 | Iteration number: [2700/4518] 59% | Training loss: 0.6871313119155389
Epoch: 34 | Iteration number: [2710/4518] 59% | Training loss: 0.6871280469577691
Epoch: 34 | Iteration number: [2720/4518] 60% | Training loss: 0.687125516858171
Epoch: 34 | Iteration number: [2730/4518] 60% | Training loss: 0.6871282457432031
Epoch: 34 | Iteration number: [2740/4518] 60% | Training loss: 0.6871307180963293
Epoch: 34 | Iteration number: [2750/4518] 60% | Training loss: 0.6871366098143837
Epoch: 34 | Iteration number: [2760/4518] 61% | Training loss: 0.6871390788451485
Epoch: 34 | Iteration number: [2770/4518] 61% | Training loss: 0.6871390734338588
Epoch: 34 | Iteration number: [2780/4518] 61% | Training loss: 0.6871378362822018
Epoch: 34 | Iteration number: [2790/4518] 61% | Training loss: 0.6871349229393894
Epoch: 34 | Iteration number: [2800/4518] 61% | Training loss: 0.6871358954480716
Epoch: 34 | Iteration number: [2810/4518] 62% | Training loss: 0.6871271216784508
Epoch: 34 | Iteration number: [2820/4518] 62% | Training loss: 0.687124391798432
Epoch: 34 | Iteration number: [2830/4518] 62% | Training loss: 0.6871208653011929
Epoch: 34 | Iteration number: [2840/4518] 62% | Training loss: 0.6871215660807113
Epoch: 34 | Iteration number: [2850/4518] 63% | Training loss: 0.6871257153519413
Epoch: 34 | Iteration number: [2860/4518] 63% | Training loss: 0.6871209963635131
Epoch: 34 | Iteration number: [2870/4518] 63% | Training loss: 0.6871208912196475
Epoch: 34 | Iteration number: [2880/4518] 63% | Training loss: 0.6871186002468069
Epoch: 34 | Iteration number: [2890/4518] 63% | Training loss: 0.6871146881250362
Epoch: 34 | Iteration number: [2900/4518] 64% | Training loss: 0.6871150898522345
Epoch: 34 | Iteration number: [2910/4518] 64% | Training loss: 0.6871122966517288
Epoch: 34 | Iteration number: [2920/4518] 64% | Training loss: 0.6871116232177983
Epoch: 34 | Iteration number: [2930/4518] 64% | Training loss: 0.687107748769656
Epoch: 34 | Iteration number: [2940/4518] 65% | Training loss: 0.6871055506930059
Epoch: 34 | Iteration number: [2950/4518] 65% | Training loss: 0.6871052131814471
Epoch: 34 | Iteration number: [2960/4518] 65% | Training loss: 0.6871035739779472
Epoch: 34 | Iteration number: [2970/4518] 65% | Training loss: 0.6871029497597756
Epoch: 34 | Iteration number: [2980/4518] 65% | Training loss: 0.6871012476666661
Epoch: 34 | Iteration number: [2990/4518] 66% | Training loss: 0.6871014385319075
Epoch: 34 | Iteration number: [3000/4518] 66% | Training loss: 0.6871029094258945
Epoch: 34 | Iteration number: [3010/4518] 66% | Training loss: 0.6871005459085255
Epoch: 34 | Iteration number: [3020/4518] 66% | Training loss: 0.6871033683517911
Epoch: 34 | Iteration number: [3030/4518] 67% | Training loss: 0.6871026708938107
Epoch: 34 | Iteration number: [3040/4518] 67% | Training loss: 0.6871032219968344
Epoch: 34 | Iteration number: [3050/4518] 67% | Training loss: 0.6871017031591447
Epoch: 34 | Iteration number: [3060/4518] 67% | Training loss: 0.6870987878126257
Epoch: 34 | Iteration number: [3070/4518] 67% | Training loss: 0.6870995024710602
Epoch: 34 | Iteration number: [3080/4518] 68% | Training loss: 0.6870993372488331
Epoch: 34 | Iteration number: [3090/4518] 68% | Training loss: 0.687095958245225
Epoch: 34 | Iteration number: [3100/4518] 68% | Training loss: 0.6870976091392579
Epoch: 34 | Iteration number: [3110/4518] 68% | Training loss: 0.6870944905511053
Epoch: 34 | Iteration number: [3120/4518] 69% | Training loss: 0.6870913856877731
Epoch: 34 | Iteration number: [3130/4518] 69% | Training loss: 0.6870916656031014
Epoch: 34 | Iteration number: [3140/4518] 69% | Training loss: 0.6870825868123656
Epoch: 34 | Iteration number: [3150/4518] 69% | Training loss: 0.6870803685226138
Epoch: 34 | Iteration number: [3160/4518] 69% | Training loss: 0.6870791228134421
Epoch: 34 | Iteration number: [3170/4518] 70% | Training loss: 0.687078756564047
Epoch: 34 | Iteration number: [3180/4518] 70% | Training loss: 0.6870799098562145
Epoch: 34 | Iteration number: [3190/4518] 70% | Training loss: 0.6870756231505295
Epoch: 34 | Iteration number: [3200/4518] 70% | Training loss: 0.6870765249058605
Epoch: 34 | Iteration number: [3210/4518] 71% | Training loss: 0.6870743167920276
Epoch: 34 | Iteration number: [3220/4518] 71% | Training loss: 0.6870741592801135
Epoch: 34 | Iteration number: [3230/4518] 71% | Training loss: 0.6870727326109682
Epoch: 34 | Iteration number: [3240/4518] 71% | Training loss: 0.6870731378595034
Epoch: 34 | Iteration number: [3250/4518] 71% | Training loss: 0.6870759557393881
Epoch: 34 | Iteration number: [3260/4518] 72% | Training loss: 0.6870776497513239
Epoch: 34 | Iteration number: [3270/4518] 72% | Training loss: 0.6870793624755439
Epoch: 34 | Iteration number: [3280/4518] 72% | Training loss: 0.6870782666090058
Epoch: 34 | Iteration number: [3290/4518] 72% | Training loss: 0.6870720690688101
Epoch: 34 | Iteration number: [3300/4518] 73% | Training loss: 0.6870752593784621
Epoch: 34 | Iteration number: [3310/4518] 73% | Training loss: 0.6870762145231137
Epoch: 34 | Iteration number: [3320/4518] 73% | Training loss: 0.6870759419648044
Epoch: 34 | Iteration number: [3330/4518] 73% | Training loss: 0.6870715010452557
Epoch: 34 | Iteration number: [3340/4518] 73% | Training loss: 0.6870696657432054
Epoch: 34 | Iteration number: [3350/4518] 74% | Training loss: 0.6870686602414544
Epoch: 34 | Iteration number: [3360/4518] 74% | Training loss: 0.68706699863431
Epoch: 34 | Iteration number: [3370/4518] 74% | Training loss: 0.6870676480874817
Epoch: 34 | Iteration number: [3380/4518] 74% | Training loss: 0.6870705250804946
Epoch: 34 | Iteration number: [3390/4518] 75% | Training loss: 0.687069486165117
Epoch: 34 | Iteration number: [3400/4518] 75% | Training loss: 0.6870700876151814
Epoch: 34 | Iteration number: [3410/4518] 75% | Training loss: 0.687070423731706
Epoch: 34 | Iteration number: [3420/4518] 75% | Training loss: 0.687072398073492
Epoch: 34 | Iteration number: [3430/4518] 75% | Training loss: 0.6870718577512847
Epoch: 34 | Iteration number: [3440/4518] 76% | Training loss: 0.687072893526665
Epoch: 34 | Iteration number: [3450/4518] 76% | Training loss: 0.6870694207799607
Epoch: 34 | Iteration number: [3460/4518] 76% | Training loss: 0.6870693107388612
Epoch: 34 | Iteration number: [3470/4518] 76% | Training loss: 0.6870703005825065
Epoch: 34 | Iteration number: [3480/4518] 77% | Training loss: 0.6870691100756328
Epoch: 34 | Iteration number: [3490/4518] 77% | Training loss: 0.6870640311507578
Epoch: 34 | Iteration number: [3500/4518] 77% | Training loss: 0.6870669466427395
Epoch: 34 | Iteration number: [3510/4518] 77% | Training loss: 0.6870693706888759
Epoch: 34 | Iteration number: [3520/4518] 77% | Training loss: 0.6870685661888936
Epoch: 34 | Iteration number: [3530/4518] 78% | Training loss: 0.687068413252871
Epoch: 34 | Iteration number: [3540/4518] 78% | Training loss: 0.6870694009092568
Epoch: 34 | Iteration number: [3550/4518] 78% | Training loss: 0.6870691192485917
Epoch: 34 | Iteration number: [3560/4518] 78% | Training loss: 0.6870671128623941
Epoch: 34 | Iteration number: [3570/4518] 79% | Training loss: 0.6870634568171675
Epoch: 34 | Iteration number: [3580/4518] 79% | Training loss: 0.6870616873882336
Epoch: 34 | Iteration number: [3590/4518] 79% | Training loss: 0.6870611016630794
Epoch: 34 | Iteration number: [3600/4518] 79% | Training loss: 0.6870599450998837
Epoch: 34 | Iteration number: [3610/4518] 79% | Training loss: 0.6870575113970157
Epoch: 34 | Iteration number: [3620/4518] 80% | Training loss: 0.6870558071202336
Epoch: 34 | Iteration number: [3630/4518] 80% | Training loss: 0.6870582219161935
Epoch: 34 | Iteration number: [3640/4518] 80% | Training loss: 0.6870564852278311
Epoch: 34 | Iteration number: [3650/4518] 80% | Training loss: 0.687055509678305
Epoch: 34 | Iteration number: [3660/4518] 81% | Training loss: 0.6870529280822785
Epoch: 34 | Iteration number: [3670/4518] 81% | Training loss: 0.6870503222422639
Epoch: 34 | Iteration number: [3680/4518] 81% | Training loss: 0.6870510599697414
Epoch: 34 | Iteration number: [3690/4518] 81% | Training loss: 0.6870495209848978
Epoch: 34 | Iteration number: [3700/4518] 81% | Training loss: 0.6870518084152325
Epoch: 34 | Iteration number: [3710/4518] 82% | Training loss: 0.6870490065964084
Epoch: 34 | Iteration number: [3720/4518] 82% | Training loss: 0.6870468845931432
Epoch: 34 | Iteration number: [3730/4518] 82% | Training loss: 0.6870462076913256
Epoch: 34 | Iteration number: [3740/4518] 82% | Training loss: 0.6870452164169302
Epoch: 34 | Iteration number: [3750/4518] 83% | Training loss: 0.6870417103449503
Epoch: 34 | Iteration number: [3760/4518] 83% | Training loss: 0.6870425192916647
Epoch: 34 | Iteration number: [3770/4518] 83% | Training loss: 0.6870442792496567
Epoch: 34 | Iteration number: [3780/4518] 83% | Training loss: 0.6870454844658967
Epoch: 34 | Iteration number: [3790/4518] 83% | Training loss: 0.687048973272847
Epoch: 34 | Iteration number: [3800/4518] 84% | Training loss: 0.6870480248175169
Epoch: 34 | Iteration number: [3810/4518] 84% | Training loss: 0.6870465835248392
Epoch: 34 | Iteration number: [3820/4518] 84% | Training loss: 0.6870420432059553
Epoch: 34 | Iteration number: [3830/4518] 84% | Training loss: 0.6870426662752585
Epoch: 34 | Iteration number: [3840/4518] 84% | Training loss: 0.6870396988155941
Epoch: 34 | Iteration number: [3850/4518] 85% | Training loss: 0.6870330155515052
Epoch: 34 | Iteration number: [3860/4518] 85% | Training loss: 0.6870361388347309
Epoch: 34 | Iteration number: [3870/4518] 85% | Training loss: 0.6870356038867349
Epoch: 34 | Iteration number: [3880/4518] 85% | Training loss: 0.6870321332025774
Epoch: 34 | Iteration number: [3890/4518] 86% | Training loss: 0.6870310958675983
Epoch: 34 | Iteration number: [3900/4518] 86% | Training loss: 0.6870320124962391
Epoch: 34 | Iteration number: [3910/4518] 86% | Training loss: 0.6870309924987881
Epoch: 34 | Iteration number: [3920/4518] 86% | Training loss: 0.6870320351756349
Epoch: 34 | Iteration number: [3930/4518] 86% | Training loss: 0.687035272473294
Epoch: 34 | Iteration number: [3940/4518] 87% | Training loss: 0.6870352495291512
Epoch: 34 | Iteration number: [3950/4518] 87% | Training loss: 0.6870352294173422
Epoch: 34 | Iteration number: [3960/4518] 87% | Training loss: 0.6870339112450378
Epoch: 34 | Iteration number: [3970/4518] 87% | Training loss: 0.6870332433084396
Epoch: 34 | Iteration number: [3980/4518] 88% | Training loss: 0.6870294192178764
Epoch: 34 | Iteration number: [3990/4518] 88% | Training loss: 0.6870303038965192
Epoch: 34 | Iteration number: [4000/4518] 88% | Training loss: 0.6870290106683969
Epoch: 34 | Iteration number: [4010/4518] 88% | Training loss: 0.6870288234101863
Epoch: 34 | Iteration number: [4020/4518] 88% | Training loss: 0.6870255518018903
Epoch: 34 | Iteration number: [4030/4518] 89% | Training loss: 0.6870219725089393
Epoch: 34 | Iteration number: [4040/4518] 89% | Training loss: 0.6870233296020196
Epoch: 34 | Iteration number: [4050/4518] 89% | Training loss: 0.6870242078068816
Epoch: 34 | Iteration number: [4060/4518] 89% | Training loss: 0.6870230907730281
Epoch: 34 | Iteration number: [4070/4518] 90% | Training loss: 0.6870240907411318
Epoch: 34 | Iteration number: [4080/4518] 90% | Training loss: 0.6870246747399078
Epoch: 34 | Iteration number: [4090/4518] 90% | Training loss: 0.6870267019586633
Epoch: 34 | Iteration number: [4100/4518] 90% | Training loss: 0.6870266079030386
Epoch: 34 | Iteration number: [4110/4518] 90% | Training loss: 0.6870286651046317
Epoch: 34 | Iteration number: [4120/4518] 91% | Training loss: 0.6870272072050178
Epoch: 34 | Iteration number: [4130/4518] 91% | Training loss: 0.6870290472923122
Epoch: 34 | Iteration number: [4140/4518] 91% | Training loss: 0.6870284960465731
Epoch: 34 | Iteration number: [4150/4518] 91% | Training loss: 0.687026190642851
Epoch: 34 | Iteration number: [4160/4518] 92% | Training loss: 0.6870232647284865
Epoch: 34 | Iteration number: [4170/4518] 92% | Training loss: 0.6870244031901553
Epoch: 34 | Iteration number: [4180/4518] 92% | Training loss: 0.6870229625673385
Epoch: 34 | Iteration number: [4190/4518] 92% | Training loss: 0.6870242155963879
Epoch: 34 | Iteration number: [4200/4518] 92% | Training loss: 0.6870206222080049
Epoch: 34 | Iteration number: [4210/4518] 93% | Training loss: 0.6870185258977487
Epoch: 34 | Iteration number: [4220/4518] 93% | Training loss: 0.6870184629166861
Epoch: 34 | Iteration number: [4230/4518] 93% | Training loss: 0.687016690059193
Epoch: 34 | Iteration number: [4240/4518] 93% | Training loss: 0.6870174800449947
Epoch: 34 | Iteration number: [4250/4518] 94% | Training loss: 0.6870165041053996
Epoch: 34 | Iteration number: [4260/4518] 94% | Training loss: 0.6870179325901846
Epoch: 34 | Iteration number: [4270/4518] 94% | Training loss: 0.6870162916267225
Epoch: 34 | Iteration number: [4280/4518] 94% | Training loss: 0.6870133721522081
Epoch: 34 | Iteration number: [4290/4518] 94% | Training loss: 0.6870121515436328
Epoch: 34 | Iteration number: [4300/4518] 95% | Training loss: 0.687011735120485
Epoch: 34 | Iteration number: [4310/4518] 95% | Training loss: 0.6870099274990453
Epoch: 34 | Iteration number: [4320/4518] 95% | Training loss: 0.6870072959197893
Epoch: 34 | Iteration number: [4330/4518] 95% | Training loss: 0.6870088430805514
Epoch: 34 | Iteration number: [4340/4518] 96% | Training loss: 0.6870082461339537
Epoch: 34 | Iteration number: [4350/4518] 96% | Training loss: 0.6870106465378026
Epoch: 34 | Iteration number: [4360/4518] 96% | Training loss: 0.6870082264919893
Epoch: 34 | Iteration number: [4370/4518] 96% | Training loss: 0.6870097225808988
Epoch: 34 | Iteration number: [4380/4518] 96% | Training loss: 0.6870107099617997
Epoch: 34 | Iteration number: [4390/4518] 97% | Training loss: 0.6870119289412314
Epoch: 34 | Iteration number: [4400/4518] 97% | Training loss: 0.6870111459358172
Epoch: 34 | Iteration number: [4410/4518] 97% | Training loss: 0.6870109053020305
Epoch: 34 | Iteration number: [4420/4518] 97% | Training loss: 0.6870126447391726
Epoch: 34 | Iteration number: [4430/4518] 98% | Training loss: 0.6870107856076674
Epoch: 34 | Iteration number: [4440/4518] 98% | Training loss: 0.6870119528727489
Epoch: 34 | Iteration number: [4450/4518] 98% | Training loss: 0.6870086053114259
Epoch: 34 | Iteration number: [4460/4518] 98% | Training loss: 0.6870095323019498
Epoch: 34 | Iteration number: [4470/4518] 98% | Training loss: 0.6870099437450136
Epoch: 34 | Iteration number: [4480/4518] 99% | Training loss: 0.6870082421627428
Epoch: 34 | Iteration number: [4490/4518] 99% | Training loss: 0.6870067382177425
Epoch: 34 | Iteration number: [4500/4518] 99% | Training loss: 0.6870047544770771
Epoch: 34 | Iteration number: [4510/4518] 99% | Training loss: 0.6870041612246612

 End of epoch: 34 | Train Loss: 0.6868517697780941 | Training Time: 641 

 End of epoch: 34 | Eval Loss: 0.6901886049582033 | Evaluating Time: 17 
Epoch: 35 | Iteration number: [10/4518] 0% | Training loss: 0.7554553925991059
Epoch: 35 | Iteration number: [20/4518] 0% | Training loss: 0.7211913734674453
Epoch: 35 | Iteration number: [30/4518] 0% | Training loss: 0.7092303315798442
Epoch: 35 | Iteration number: [40/4518] 0% | Training loss: 0.7037071511149406
Epoch: 35 | Iteration number: [50/4518] 1% | Training loss: 0.7004457044601441
Epoch: 35 | Iteration number: [60/4518] 1% | Training loss: 0.6984061986207962
Epoch: 35 | Iteration number: [70/4518] 1% | Training loss: 0.6967490528311048
Epoch: 35 | Iteration number: [80/4518] 1% | Training loss: 0.6954786144196987
Epoch: 35 | Iteration number: [90/4518] 1% | Training loss: 0.6946186582247417
Epoch: 35 | Iteration number: [100/4518] 2% | Training loss: 0.6938359355926513
Epoch: 35 | Iteration number: [110/4518] 2% | Training loss: 0.6932385867292231
Epoch: 35 | Iteration number: [120/4518] 2% | Training loss: 0.6925605321923892
Epoch: 35 | Iteration number: [130/4518] 2% | Training loss: 0.6920439766003535
Epoch: 35 | Iteration number: [140/4518] 3% | Training loss: 0.6914851759161268
Epoch: 35 | Iteration number: [150/4518] 3% | Training loss: 0.6912122635046641
Epoch: 35 | Iteration number: [160/4518] 3% | Training loss: 0.6910301934927702
Epoch: 35 | Iteration number: [170/4518] 3% | Training loss: 0.6907721729839549
Epoch: 35 | Iteration number: [180/4518] 3% | Training loss: 0.6905903879139158
Epoch: 35 | Iteration number: [190/4518] 4% | Training loss: 0.6903661843977477
Epoch: 35 | Iteration number: [200/4518] 4% | Training loss: 0.6901578614115715
Epoch: 35 | Iteration number: [210/4518] 4% | Training loss: 0.6899067362149557
Epoch: 35 | Iteration number: [220/4518] 4% | Training loss: 0.6897444069385529
Epoch: 35 | Iteration number: [230/4518] 5% | Training loss: 0.6896600785462753
Epoch: 35 | Iteration number: [240/4518] 5% | Training loss: 0.6895755432546139
Epoch: 35 | Iteration number: [250/4518] 5% | Training loss: 0.6894557213783264
Epoch: 35 | Iteration number: [260/4518] 5% | Training loss: 0.6893592710678395
Epoch: 35 | Iteration number: [270/4518] 5% | Training loss: 0.6892176396316952
Epoch: 35 | Iteration number: [280/4518] 6% | Training loss: 0.6891200968197414
Epoch: 35 | Iteration number: [290/4518] 6% | Training loss: 0.6890559732913971
Epoch: 35 | Iteration number: [300/4518] 6% | Training loss: 0.6890260086456934
Epoch: 35 | Iteration number: [310/4518] 6% | Training loss: 0.6889497260893545
Epoch: 35 | Iteration number: [320/4518] 7% | Training loss: 0.6888590686023235
Epoch: 35 | Iteration number: [330/4518] 7% | Training loss: 0.6888147453467052
Epoch: 35 | Iteration number: [340/4518] 7% | Training loss: 0.6887820782030329
Epoch: 35 | Iteration number: [350/4518] 7% | Training loss: 0.6887362386499133
Epoch: 35 | Iteration number: [360/4518] 7% | Training loss: 0.6886896229452557
Epoch: 35 | Iteration number: [370/4518] 8% | Training loss: 0.6886611153950563
Epoch: 35 | Iteration number: [380/4518] 8% | Training loss: 0.6885760842185271
Epoch: 35 | Iteration number: [390/4518] 8% | Training loss: 0.6885236520033616
Epoch: 35 | Iteration number: [400/4518] 8% | Training loss: 0.6884862229228019
Epoch: 35 | Iteration number: [410/4518] 9% | Training loss: 0.6884822189807892
Epoch: 35 | Iteration number: [420/4518] 9% | Training loss: 0.6884591964029131
Epoch: 35 | Iteration number: [430/4518] 9% | Training loss: 0.6884336069572804
Epoch: 35 | Iteration number: [440/4518] 9% | Training loss: 0.6884014920754866
Epoch: 35 | Iteration number: [450/4518] 9% | Training loss: 0.6883811724185943
Epoch: 35 | Iteration number: [460/4518] 10% | Training loss: 0.6883662585331046
Epoch: 35 | Iteration number: [470/4518] 10% | Training loss: 0.6883409430371954
Epoch: 35 | Iteration number: [480/4518] 10% | Training loss: 0.6883092580984036
Epoch: 35 | Iteration number: [490/4518] 10% | Training loss: 0.6882718491310976
Epoch: 35 | Iteration number: [500/4518] 11% | Training loss: 0.6882418748140335
Epoch: 35 | Iteration number: [510/4518] 11% | Training loss: 0.6882033173944436
Epoch: 35 | Iteration number: [520/4518] 11% | Training loss: 0.6881627282271019
Epoch: 35 | Iteration number: [530/4518] 11% | Training loss: 0.6881387626225094
Epoch: 35 | Iteration number: [540/4518] 11% | Training loss: 0.6880932911678597
Epoch: 35 | Iteration number: [550/4518] 12% | Training loss: 0.6880608044971119
Epoch: 35 | Iteration number: [560/4518] 12% | Training loss: 0.6880669144647462
Epoch: 35 | Iteration number: [570/4518] 12% | Training loss: 0.6880488767958524
Epoch: 35 | Iteration number: [580/4518] 12% | Training loss: 0.6880160520816672
Epoch: 35 | Iteration number: [590/4518] 13% | Training loss: 0.6879995435981427
Epoch: 35 | Iteration number: [600/4518] 13% | Training loss: 0.6879556545615196
Epoch: 35 | Iteration number: [610/4518] 13% | Training loss: 0.6879118115198417
Epoch: 35 | Iteration number: [620/4518] 13% | Training loss: 0.6879052809169216
Epoch: 35 | Iteration number: [630/4518] 13% | Training loss: 0.6879068543986668
Epoch: 35 | Iteration number: [640/4518] 14% | Training loss: 0.6878813464194536
Epoch: 35 | Iteration number: [650/4518] 14% | Training loss: 0.687859314771799
Epoch: 35 | Iteration number: [660/4518] 14% | Training loss: 0.6878365242119991
Epoch: 35 | Iteration number: [670/4518] 14% | Training loss: 0.6878399292034889
Epoch: 35 | Iteration number: [680/4518] 15% | Training loss: 0.6878147761611377
Epoch: 35 | Iteration number: [690/4518] 15% | Training loss: 0.6877950121527133
Epoch: 35 | Iteration number: [700/4518] 15% | Training loss: 0.6877875733375549
Epoch: 35 | Iteration number: [710/4518] 15% | Training loss: 0.687761353606909
Epoch: 35 | Iteration number: [720/4518] 15% | Training loss: 0.6877370536327362
Epoch: 35 | Iteration number: [730/4518] 16% | Training loss: 0.6877180109285328
Epoch: 35 | Iteration number: [740/4518] 16% | Training loss: 0.687725646753569
Epoch: 35 | Iteration number: [750/4518] 16% | Training loss: 0.687708025376002
Epoch: 35 | Iteration number: [760/4518] 16% | Training loss: 0.6876865182267992
Epoch: 35 | Iteration number: [770/4518] 17% | Training loss: 0.6876617707215347
Epoch: 35 | Iteration number: [780/4518] 17% | Training loss: 0.6876432875792186
Epoch: 35 | Iteration number: [790/4518] 17% | Training loss: 0.6876423768604858
Epoch: 35 | Iteration number: [800/4518] 17% | Training loss: 0.6876217260211707
Epoch: 35 | Iteration number: [810/4518] 17% | Training loss: 0.6876092400079892
Epoch: 35 | Iteration number: [820/4518] 18% | Training loss: 0.6876070958085176
Epoch: 35 | Iteration number: [830/4518] 18% | Training loss: 0.687599613149482
Epoch: 35 | Iteration number: [840/4518] 18% | Training loss: 0.6875942688612711
Epoch: 35 | Iteration number: [850/4518] 18% | Training loss: 0.6875817131996155
Epoch: 35 | Iteration number: [860/4518] 19% | Training loss: 0.6875807136990303
Epoch: 35 | Iteration number: [870/4518] 19% | Training loss: 0.6875592126928527
Epoch: 35 | Iteration number: [880/4518] 19% | Training loss: 0.6875486961819909
Epoch: 35 | Iteration number: [890/4518] 19% | Training loss: 0.6875476004032607
Epoch: 35 | Iteration number: [900/4518] 19% | Training loss: 0.6875561585028966
Epoch: 35 | Iteration number: [910/4518] 20% | Training loss: 0.6875475384376861
Epoch: 35 | Iteration number: [920/4518] 20% | Training loss: 0.6875328845303992
Epoch: 35 | Iteration number: [930/4518] 20% | Training loss: 0.6875172108732244
Epoch: 35 | Iteration number: [940/4518] 20% | Training loss: 0.6875071899053898
Epoch: 35 | Iteration number: [950/4518] 21% | Training loss: 0.6874993739630046
Epoch: 35 | Iteration number: [960/4518] 21% | Training loss: 0.6874986863384644
Epoch: 35 | Iteration number: [970/4518] 21% | Training loss: 0.6874962727433628
Epoch: 35 | Iteration number: [980/4518] 21% | Training loss: 0.6874763511881536
Epoch: 35 | Iteration number: [990/4518] 21% | Training loss: 0.6874706081067673
Epoch: 35 | Iteration number: [1000/4518] 22% | Training loss: 0.6874614011645317
Epoch: 35 | Iteration number: [1010/4518] 22% | Training loss: 0.6874504205023888
Epoch: 35 | Iteration number: [1020/4518] 22% | Training loss: 0.6874494796874476
Epoch: 35 | Iteration number: [1030/4518] 22% | Training loss: 0.6874412945752005
Epoch: 35 | Iteration number: [1040/4518] 23% | Training loss: 0.6874403500213073
Epoch: 35 | Iteration number: [1050/4518] 23% | Training loss: 0.6874403058914911
Epoch: 35 | Iteration number: [1060/4518] 23% | Training loss: 0.687443157468202
Epoch: 35 | Iteration number: [1070/4518] 23% | Training loss: 0.687444101037266
Epoch: 35 | Iteration number: [1080/4518] 23% | Training loss: 0.6874397127716629
Epoch: 35 | Iteration number: [1090/4518] 24% | Training loss: 0.687434554920284
Epoch: 35 | Iteration number: [1100/4518] 24% | Training loss: 0.6874292851036246
Epoch: 35 | Iteration number: [1110/4518] 24% | Training loss: 0.6874203095564971
Epoch: 35 | Iteration number: [1120/4518] 24% | Training loss: 0.6874234528413841
Epoch: 35 | Iteration number: [1130/4518] 25% | Training loss: 0.687415722091641
Epoch: 35 | Iteration number: [1140/4518] 25% | Training loss: 0.6874189937846702
Epoch: 35 | Iteration number: [1150/4518] 25% | Training loss: 0.6874231565516928
Epoch: 35 | Iteration number: [1160/4518] 25% | Training loss: 0.6874144470383381
Epoch: 35 | Iteration number: [1170/4518] 25% | Training loss: 0.6874224974558903
Epoch: 35 | Iteration number: [1180/4518] 26% | Training loss: 0.6874183362823422
Epoch: 35 | Iteration number: [1190/4518] 26% | Training loss: 0.6874174817770469
Epoch: 35 | Iteration number: [1200/4518] 26% | Training loss: 0.6874208520849546
Epoch: 35 | Iteration number: [1210/4518] 26% | Training loss: 0.6874079446162074
Epoch: 35 | Iteration number: [1220/4518] 27% | Training loss: 0.6874045429171108
Epoch: 35 | Iteration number: [1230/4518] 27% | Training loss: 0.6873913250318388
Epoch: 35 | Iteration number: [1240/4518] 27% | Training loss: 0.6873834154778912
Epoch: 35 | Iteration number: [1250/4518] 27% | Training loss: 0.6873904274940491
Epoch: 35 | Iteration number: [1260/4518] 27% | Training loss: 0.687385698727199
Epoch: 35 | Iteration number: [1270/4518] 28% | Training loss: 0.6873882774292953
Epoch: 35 | Iteration number: [1280/4518] 28% | Training loss: 0.6873757016379386
Epoch: 35 | Iteration number: [1290/4518] 28% | Training loss: 0.6873697829800983
Epoch: 35 | Iteration number: [1300/4518] 28% | Training loss: 0.6873709720831651
Epoch: 35 | Iteration number: [1310/4518] 28% | Training loss: 0.6873742903916891
Epoch: 35 | Iteration number: [1320/4518] 29% | Training loss: 0.6873718090581171
Epoch: 35 | Iteration number: [1330/4518] 29% | Training loss: 0.6873741855746821
Epoch: 35 | Iteration number: [1340/4518] 29% | Training loss: 0.6873732494329339
Epoch: 35 | Iteration number: [1350/4518] 29% | Training loss: 0.687368824172903
Epoch: 35 | Iteration number: [1360/4518] 30% | Training loss: 0.6873614302891142
Epoch: 35 | Iteration number: [1370/4518] 30% | Training loss: 0.6873527264943088
Epoch: 35 | Iteration number: [1380/4518] 30% | Training loss: 0.6873521807832994
Epoch: 35 | Iteration number: [1390/4518] 30% | Training loss: 0.6873589862164834
Epoch: 35 | Iteration number: [1400/4518] 30% | Training loss: 0.687346295927252
Epoch: 35 | Iteration number: [1410/4518] 31% | Training loss: 0.6873398787163674
Epoch: 35 | Iteration number: [1420/4518] 31% | Training loss: 0.6873377862950446
Epoch: 35 | Iteration number: [1430/4518] 31% | Training loss: 0.6873326246138219
Epoch: 35 | Iteration number: [1440/4518] 31% | Training loss: 0.6873272842417161
Epoch: 35 | Iteration number: [1450/4518] 32% | Training loss: 0.6873237056156685
Epoch: 35 | Iteration number: [1460/4518] 32% | Training loss: 0.6873167674427163
Epoch: 35 | Iteration number: [1470/4518] 32% | Training loss: 0.6873226091569784
Epoch: 35 | Iteration number: [1480/4518] 32% | Training loss: 0.6873307134251336
Epoch: 35 | Iteration number: [1490/4518] 32% | Training loss: 0.6873303795420883
Epoch: 35 | Iteration number: [1500/4518] 33% | Training loss: 0.6873187146186829
Epoch: 35 | Iteration number: [1510/4518] 33% | Training loss: 0.6873058603299375
Epoch: 35 | Iteration number: [1520/4518] 33% | Training loss: 0.6873145099141096
Epoch: 35 | Iteration number: [1530/4518] 33% | Training loss: 0.6873125957507713
Epoch: 35 | Iteration number: [1540/4518] 34% | Training loss: 0.6873137952058346
Epoch: 35 | Iteration number: [1550/4518] 34% | Training loss: 0.6873044571184342
Epoch: 35 | Iteration number: [1560/4518] 34% | Training loss: 0.6873043017509656
Epoch: 35 | Iteration number: [1570/4518] 34% | Training loss: 0.6872976076451077
Epoch: 35 | Iteration number: [1580/4518] 34% | Training loss: 0.6872978708789318
Epoch: 35 | Iteration number: [1590/4518] 35% | Training loss: 0.6872867348808912
Epoch: 35 | Iteration number: [1600/4518] 35% | Training loss: 0.6872846427559852
Epoch: 35 | Iteration number: [1610/4518] 35% | Training loss: 0.6872822907400428
Epoch: 35 | Iteration number: [1620/4518] 35% | Training loss: 0.6872775144783068
Epoch: 35 | Iteration number: [1630/4518] 36% | Training loss: 0.6872839348082163
Epoch: 35 | Iteration number: [1640/4518] 36% | Training loss: 0.6872839771756312
Epoch: 35 | Iteration number: [1650/4518] 36% | Training loss: 0.6872884455232909
Epoch: 35 | Iteration number: [1660/4518] 36% | Training loss: 0.6872878955071231
Epoch: 35 | Iteration number: [1670/4518] 36% | Training loss: 0.6872910134092777
Epoch: 35 | Iteration number: [1680/4518] 37% | Training loss: 0.6872888495169934
Epoch: 35 | Iteration number: [1690/4518] 37% | Training loss: 0.6872848118550678
Epoch: 35 | Iteration number: [1700/4518] 37% | Training loss: 0.6872782278762144
Epoch: 35 | Iteration number: [1710/4518] 37% | Training loss: 0.687274191951194
Epoch: 35 | Iteration number: [1720/4518] 38% | Training loss: 0.6872769406022028
Epoch: 35 | Iteration number: [1730/4518] 38% | Training loss: 0.6872704945547732
Epoch: 35 | Iteration number: [1740/4518] 38% | Training loss: 0.6872717839890513
Epoch: 35 | Iteration number: [1750/4518] 38% | Training loss: 0.6872677151816232
Epoch: 35 | Iteration number: [1760/4518] 38% | Training loss: 0.6872661904516545
Epoch: 35 | Iteration number: [1770/4518] 39% | Training loss: 0.6872662257003246
Epoch: 35 | Iteration number: [1780/4518] 39% | Training loss: 0.6872618588503827
Epoch: 35 | Iteration number: [1790/4518] 39% | Training loss: 0.687251346504222
Epoch: 35 | Iteration number: [1800/4518] 39% | Training loss: 0.6872530649105708
Epoch: 35 | Iteration number: [1810/4518] 40% | Training loss: 0.6872496694161747
Epoch: 35 | Iteration number: [1820/4518] 40% | Training loss: 0.6872496898685183
Epoch: 35 | Iteration number: [1830/4518] 40% | Training loss: 0.6872465800392171
Epoch: 35 | Iteration number: [1840/4518] 40% | Training loss: 0.6872469735534295
Epoch: 35 | Iteration number: [1850/4518] 40% | Training loss: 0.6872487731559856
Epoch: 35 | Iteration number: [1860/4518] 41% | Training loss: 0.6872407732471343
Epoch: 35 | Iteration number: [1870/4518] 41% | Training loss: 0.6872325380855703
Epoch: 35 | Iteration number: [1880/4518] 41% | Training loss: 0.6872341403301726
Epoch: 35 | Iteration number: [1890/4518] 41% | Training loss: 0.6872232088336239
Epoch: 35 | Iteration number: [1900/4518] 42% | Training loss: 0.6872265139692708
Epoch: 35 | Iteration number: [1910/4518] 42% | Training loss: 0.687225665784007
Epoch: 35 | Iteration number: [1920/4518] 42% | Training loss: 0.68722425478821
Epoch: 35 | Iteration number: [1930/4518] 42% | Training loss: 0.6872228561905381
Epoch: 35 | Iteration number: [1940/4518] 42% | Training loss: 0.6872178163417836
Epoch: 35 | Iteration number: [1950/4518] 43% | Training loss: 0.6872160102159549
Epoch: 35 | Iteration number: [1960/4518] 43% | Training loss: 0.6872107140567838
Epoch: 35 | Iteration number: [1970/4518] 43% | Training loss: 0.687207345097198
Epoch: 35 | Iteration number: [1980/4518] 43% | Training loss: 0.6872053089165928
Epoch: 35 | Iteration number: [1990/4518] 44% | Training loss: 0.6871995710248324
Epoch: 35 | Iteration number: [2000/4518] 44% | Training loss: 0.6871959647238255
Epoch: 35 | Iteration number: [2010/4518] 44% | Training loss: 0.6871899551123529
Epoch: 35 | Iteration number: [2020/4518] 44% | Training loss: 0.6871886997529776
Epoch: 35 | Iteration number: [2030/4518] 44% | Training loss: 0.68718838530221
Epoch: 35 | Iteration number: [2040/4518] 45% | Training loss: 0.6871864131852692
Epoch: 35 | Iteration number: [2050/4518] 45% | Training loss: 0.6871829025047581
Epoch: 35 | Iteration number: [2060/4518] 45% | Training loss: 0.6871761530637741
Epoch: 35 | Iteration number: [2070/4518] 45% | Training loss: 0.6871808357572786
Epoch: 35 | Iteration number: [2080/4518] 46% | Training loss: 0.6871791791743957
Epoch: 35 | Iteration number: [2090/4518] 46% | Training loss: 0.6871798292586678
Epoch: 35 | Iteration number: [2100/4518] 46% | Training loss: 0.687175643046697
Epoch: 35 | Iteration number: [2110/4518] 46% | Training loss: 0.6871736860388263
Epoch: 35 | Iteration number: [2120/4518] 46% | Training loss: 0.6871713145442728
Epoch: 35 | Iteration number: [2130/4518] 47% | Training loss: 0.6871731352358357
Epoch: 35 | Iteration number: [2140/4518] 47% | Training loss: 0.6871739203963324
Epoch: 35 | Iteration number: [2150/4518] 47% | Training loss: 0.6871728590200114
Epoch: 35 | Iteration number: [2160/4518] 47% | Training loss: 0.6871710290235502
Epoch: 35 | Iteration number: [2170/4518] 48% | Training loss: 0.6871694447258101
Epoch: 35 | Iteration number: [2180/4518] 48% | Training loss: 0.6871733713860906
Epoch: 35 | Iteration number: [2190/4518] 48% | Training loss: 0.6871714277354549
Epoch: 35 | Iteration number: [2200/4518] 48% | Training loss: 0.6871734666553411
Epoch: 35 | Iteration number: [2210/4518] 48% | Training loss: 0.687167953986388
Epoch: 35 | Iteration number: [2220/4518] 49% | Training loss: 0.687161160777281
Epoch: 35 | Iteration number: [2230/4518] 49% | Training loss: 0.687165911074711
Epoch: 35 | Iteration number: [2240/4518] 49% | Training loss: 0.6871682735692177
Epoch: 35 | Iteration number: [2250/4518] 49% | Training loss: 0.687167076587677
Epoch: 35 | Iteration number: [2260/4518] 50% | Training loss: 0.6871624868791715
Epoch: 35 | Iteration number: [2270/4518] 50% | Training loss: 0.6871580587872325
Epoch: 35 | Iteration number: [2280/4518] 50% | Training loss: 0.6871595077347337
Epoch: 35 | Iteration number: [2290/4518] 50% | Training loss: 0.6871573945840894
Epoch: 35 | Iteration number: [2300/4518] 50% | Training loss: 0.6871577526952909
Epoch: 35 | Iteration number: [2310/4518] 51% | Training loss: 0.6871551585403872
Epoch: 35 | Iteration number: [2320/4518] 51% | Training loss: 0.687148274969438
Epoch: 35 | Iteration number: [2330/4518] 51% | Training loss: 0.6871477084865898
Epoch: 35 | Iteration number: [2340/4518] 51% | Training loss: 0.6871465428007973
Epoch: 35 | Iteration number: [2350/4518] 52% | Training loss: 0.6871474287104099
Epoch: 35 | Iteration number: [2360/4518] 52% | Training loss: 0.6871431655297845
Epoch: 35 | Iteration number: [2370/4518] 52% | Training loss: 0.6871420381692894
Epoch: 35 | Iteration number: [2380/4518] 52% | Training loss: 0.6871385811006322
Epoch: 35 | Iteration number: [2390/4518] 52% | Training loss: 0.6871362045469643
Epoch: 35 | Iteration number: [2400/4518] 53% | Training loss: 0.6871351246535778
Epoch: 35 | Iteration number: [2410/4518] 53% | Training loss: 0.6871379331434416
Epoch: 35 | Iteration number: [2420/4518] 53% | Training loss: 0.6871354109738483
Epoch: 35 | Iteration number: [2430/4518] 53% | Training loss: 0.6871392325364023
Epoch: 35 | Iteration number: [2440/4518] 54% | Training loss: 0.6871358022093773
Epoch: 35 | Iteration number: [2450/4518] 54% | Training loss: 0.6871358637177214
Epoch: 35 | Iteration number: [2460/4518] 54% | Training loss: 0.6871292262784834
Epoch: 35 | Iteration number: [2470/4518] 54% | Training loss: 0.6871298981822936
Epoch: 35 | Iteration number: [2480/4518] 54% | Training loss: 0.6871290526082439
Epoch: 35 | Iteration number: [2490/4518] 55% | Training loss: 0.6871225937063914
Epoch: 35 | Iteration number: [2500/4518] 55% | Training loss: 0.687120584511757
Epoch: 35 | Iteration number: [2510/4518] 55% | Training loss: 0.6871197827071308
Epoch: 35 | Iteration number: [2520/4518] 55% | Training loss: 0.6871197703102279
Epoch: 35 | Iteration number: [2530/4518] 55% | Training loss: 0.6871215351249861
Epoch: 35 | Iteration number: [2540/4518] 56% | Training loss: 0.6871213306357541
Epoch: 35 | Iteration number: [2550/4518] 56% | Training loss: 0.6871196634862937
Epoch: 35 | Iteration number: [2560/4518] 56% | Training loss: 0.687120164791122
Epoch: 35 | Iteration number: [2570/4518] 56% | Training loss: 0.6871199928600964
Epoch: 35 | Iteration number: [2580/4518] 57% | Training loss: 0.6871200707993766
Epoch: 35 | Iteration number: [2590/4518] 57% | Training loss: 0.6871223461213719
Epoch: 35 | Iteration number: [2600/4518] 57% | Training loss: 0.6871196542336391
Epoch: 35 | Iteration number: [2610/4518] 57% | Training loss: 0.6871146051363013
Epoch: 35 | Iteration number: [2620/4518] 57% | Training loss: 0.6871102292119091
Epoch: 35 | Iteration number: [2630/4518] 58% | Training loss: 0.6871049575479312
Epoch: 35 | Iteration number: [2640/4518] 58% | Training loss: 0.6871041248919386
Epoch: 35 | Iteration number: [2650/4518] 58% | Training loss: 0.6871065148317589
Epoch: 35 | Iteration number: [2660/4518] 58% | Training loss: 0.6871062803313248
Epoch: 35 | Iteration number: [2670/4518] 59% | Training loss: 0.6870987732758683
Epoch: 35 | Iteration number: [2680/4518] 59% | Training loss: 0.6871006646485471
Epoch: 35 | Iteration number: [2690/4518] 59% | Training loss: 0.6871009450419685
Epoch: 35 | Iteration number: [2700/4518] 59% | Training loss: 0.687102902840685
Epoch: 35 | Iteration number: [2710/4518] 59% | Training loss: 0.6870973834252445
Epoch: 35 | Iteration number: [2720/4518] 60% | Training loss: 0.6871008141733268
Epoch: 35 | Iteration number: [2730/4518] 60% | Training loss: 0.687095739247598
Epoch: 35 | Iteration number: [2740/4518] 60% | Training loss: 0.6870958586026282
Epoch: 35 | Iteration number: [2750/4518] 60% | Training loss: 0.687092933438041
Epoch: 35 | Iteration number: [2760/4518] 61% | Training loss: 0.68708996416434
Epoch: 35 | Iteration number: [2770/4518] 61% | Training loss: 0.6870873279950248
Epoch: 35 | Iteration number: [2780/4518] 61% | Training loss: 0.6870898012849067
Epoch: 35 | Iteration number: [2790/4518] 61% | Training loss: 0.687085734430607
Epoch: 35 | Iteration number: [2800/4518] 61% | Training loss: 0.6870859130152634
Epoch: 35 | Iteration number: [2810/4518] 62% | Training loss: 0.6870898281340073
Epoch: 35 | Iteration number: [2820/4518] 62% | Training loss: 0.6870908223990853
Epoch: 35 | Iteration number: [2830/4518] 62% | Training loss: 0.6870888721816532
Epoch: 35 | Iteration number: [2840/4518] 62% | Training loss: 0.6870876957413177
Epoch: 35 | Iteration number: [2850/4518] 63% | Training loss: 0.6870902680723291
Epoch: 35 | Iteration number: [2860/4518] 63% | Training loss: 0.6870889189360025
Epoch: 35 | Iteration number: [2870/4518] 63% | Training loss: 0.687089216958355
Epoch: 35 | Iteration number: [2880/4518] 63% | Training loss: 0.6870885138296419
Epoch: 35 | Iteration number: [2890/4518] 63% | Training loss: 0.687090131073262
Epoch: 35 | Iteration number: [2900/4518] 64% | Training loss: 0.6870882904118505
Epoch: 35 | Iteration number: [2910/4518] 64% | Training loss: 0.6870875839924894
Epoch: 35 | Iteration number: [2920/4518] 64% | Training loss: 0.6870917506209792
Epoch: 35 | Iteration number: [2930/4518] 64% | Training loss: 0.6870918940155173
Epoch: 35 | Iteration number: [2940/4518] 65% | Training loss: 0.6870940594040618
Epoch: 35 | Iteration number: [2950/4518] 65% | Training loss: 0.6870975096144919
Epoch: 35 | Iteration number: [2960/4518] 65% | Training loss: 0.6870931054692011
Epoch: 35 | Iteration number: [2970/4518] 65% | Training loss: 0.6870924014635761
Epoch: 35 | Iteration number: [2980/4518] 65% | Training loss: 0.6870900736359142
Epoch: 35 | Iteration number: [2990/4518] 66% | Training loss: 0.6870907354514336
Epoch: 35 | Iteration number: [3000/4518] 66% | Training loss: 0.6870873004396757
Epoch: 35 | Iteration number: [3010/4518] 66% | Training loss: 0.6870877546923501
Epoch: 35 | Iteration number: [3020/4518] 66% | Training loss: 0.6870855061226333
Epoch: 35 | Iteration number: [3030/4518] 67% | Training loss: 0.6870833825160174
Epoch: 35 | Iteration number: [3040/4518] 67% | Training loss: 0.6870790290793306
Epoch: 35 | Iteration number: [3050/4518] 67% | Training loss: 0.687076783610172
Epoch: 35 | Iteration number: [3060/4518] 67% | Training loss: 0.6870764658731573
Epoch: 35 | Iteration number: [3070/4518] 67% | Training loss: 0.6870783696345475
Epoch: 35 | Iteration number: [3080/4518] 68% | Training loss: 0.6870791590058959
Epoch: 35 | Iteration number: [3090/4518] 68% | Training loss: 0.6870761817134314
Epoch: 35 | Iteration number: [3100/4518] 68% | Training loss: 0.6870796827347048
Epoch: 35 | Iteration number: [3110/4518] 68% | Training loss: 0.6870804632208355
Epoch: 35 | Iteration number: [3120/4518] 69% | Training loss: 0.6870774392134104
Epoch: 35 | Iteration number: [3130/4518] 69% | Training loss: 0.6870749587068161
Epoch: 35 | Iteration number: [3140/4518] 69% | Training loss: 0.6870740935870796
Epoch: 35 | Iteration number: [3150/4518] 69% | Training loss: 0.6870729600437103
Epoch: 35 | Iteration number: [3160/4518] 69% | Training loss: 0.6870733169060719
Epoch: 35 | Iteration number: [3170/4518] 70% | Training loss: 0.6870733262800643
Epoch: 35 | Iteration number: [3180/4518] 70% | Training loss: 0.6870733568878293
Epoch: 35 | Iteration number: [3190/4518] 70% | Training loss: 0.6870687434852684
Epoch: 35 | Iteration number: [3200/4518] 70% | Training loss: 0.6870675675943494
Epoch: 35 | Iteration number: [3210/4518] 71% | Training loss: 0.6870670091325992
Epoch: 35 | Iteration number: [3220/4518] 71% | Training loss: 0.6870643544271126
Epoch: 35 | Iteration number: [3230/4518] 71% | Training loss: 0.6870649974412594
Epoch: 35 | Iteration number: [3240/4518] 71% | Training loss: 0.6870639104902009
Epoch: 35 | Iteration number: [3250/4518] 71% | Training loss: 0.6870616607115819
Epoch: 35 | Iteration number: [3260/4518] 72% | Training loss: 0.6870546835331829
Epoch: 35 | Iteration number: [3270/4518] 72% | Training loss: 0.6870562000559011
Epoch: 35 | Iteration number: [3280/4518] 72% | Training loss: 0.6870554673053869
Epoch: 35 | Iteration number: [3290/4518] 72% | Training loss: 0.687054811567521
Epoch: 35 | Iteration number: [3300/4518] 73% | Training loss: 0.6870528577674518
Epoch: 35 | Iteration number: [3310/4518] 73% | Training loss: 0.6870525202182124
Epoch: 35 | Iteration number: [3320/4518] 73% | Training loss: 0.6870525222226798
Epoch: 35 | Iteration number: [3330/4518] 73% | Training loss: 0.6870523536348486
Epoch: 35 | Iteration number: [3340/4518] 73% | Training loss: 0.687049298514863
Epoch: 35 | Iteration number: [3350/4518] 74% | Training loss: 0.6870491423357779
Epoch: 35 | Iteration number: [3360/4518] 74% | Training loss: 0.6870446231925771
Epoch: 35 | Iteration number: [3370/4518] 74% | Training loss: 0.6870418371538733
Epoch: 35 | Iteration number: [3380/4518] 74% | Training loss: 0.6870409951054838
Epoch: 35 | Iteration number: [3390/4518] 75% | Training loss: 0.6870388972020782
Epoch: 35 | Iteration number: [3400/4518] 75% | Training loss: 0.6870416745368172
Epoch: 35 | Iteration number: [3410/4518] 75% | Training loss: 0.6870364454309962
Epoch: 35 | Iteration number: [3420/4518] 75% | Training loss: 0.6870362347678134
Epoch: 35 | Iteration number: [3430/4518] 75% | Training loss: 0.687034627021923
Epoch: 35 | Iteration number: [3440/4518] 76% | Training loss: 0.6870351310732753
Epoch: 35 | Iteration number: [3450/4518] 76% | Training loss: 0.6870349940009739
Epoch: 35 | Iteration number: [3460/4518] 76% | Training loss: 0.6870328252542914
Epoch: 35 | Iteration number: [3470/4518] 76% | Training loss: 0.6870314540540107
Epoch: 35 | Iteration number: [3480/4518] 77% | Training loss: 0.6870298588412932
Epoch: 35 | Iteration number: [3490/4518] 77% | Training loss: 0.6870243894336558
Epoch: 35 | Iteration number: [3500/4518] 77% | Training loss: 0.6870242769036974
Epoch: 35 | Iteration number: [3510/4518] 77% | Training loss: 0.6870251920148518
Epoch: 35 | Iteration number: [3520/4518] 77% | Training loss: 0.6870255118405277
Epoch: 35 | Iteration number: [3530/4518] 78% | Training loss: 0.6870256346447272
Epoch: 35 | Iteration number: [3540/4518] 78% | Training loss: 0.6870223745787885
Epoch: 35 | Iteration number: [3550/4518] 78% | Training loss: 0.6870238303130781
Epoch: 35 | Iteration number: [3560/4518] 78% | Training loss: 0.6870242025912477
Epoch: 35 | Iteration number: [3570/4518] 79% | Training loss: 0.6870245732680088
Epoch: 35 | Iteration number: [3580/4518] 79% | Training loss: 0.6870227500546577
Epoch: 35 | Iteration number: [3590/4518] 79% | Training loss: 0.6870222901401414
Epoch: 35 | Iteration number: [3600/4518] 79% | Training loss: 0.6870226663019922
Epoch: 35 | Iteration number: [3610/4518] 79% | Training loss: 0.6870247497452924
Epoch: 35 | Iteration number: [3620/4518] 80% | Training loss: 0.6870232975120703
Epoch: 35 | Iteration number: [3630/4518] 80% | Training loss: 0.6870214622867994
Epoch: 35 | Iteration number: [3640/4518] 80% | Training loss: 0.6870223665139177
Epoch: 35 | Iteration number: [3650/4518] 80% | Training loss: 0.6870240471134447
Epoch: 35 | Iteration number: [3660/4518] 81% | Training loss: 0.6870263973871867
Epoch: 35 | Iteration number: [3670/4518] 81% | Training loss: 0.687027646459091
Epoch: 35 | Iteration number: [3680/4518] 81% | Training loss: 0.6870255071993755
Epoch: 35 | Iteration number: [3690/4518] 81% | Training loss: 0.6870247534135493
Epoch: 35 | Iteration number: [3700/4518] 81% | Training loss: 0.6870247207783364
Epoch: 35 | Iteration number: [3710/4518] 82% | Training loss: 0.6870245435488513
Epoch: 35 | Iteration number: [3720/4518] 82% | Training loss: 0.6870264979459906
Epoch: 35 | Iteration number: [3730/4518] 82% | Training loss: 0.6870253130673722
Epoch: 35 | Iteration number: [3740/4518] 82% | Training loss: 0.6870249345181461
Epoch: 35 | Iteration number: [3750/4518] 83% | Training loss: 0.6870232714494069
Epoch: 35 | Iteration number: [3760/4518] 83% | Training loss: 0.6870224281511408
Epoch: 35 | Iteration number: [3770/4518] 83% | Training loss: 0.6870220145274852
Epoch: 35 | Iteration number: [3780/4518] 83% | Training loss: 0.6870202809414535
Epoch: 35 | Iteration number: [3790/4518] 83% | Training loss: 0.6870213806471913
Epoch: 35 | Iteration number: [3800/4518] 84% | Training loss: 0.6870176345894211
Epoch: 35 | Iteration number: [3810/4518] 84% | Training loss: 0.6870199078180659
Epoch: 35 | Iteration number: [3820/4518] 84% | Training loss: 0.6870184579756872
Epoch: 35 | Iteration number: [3830/4518] 84% | Training loss: 0.6870148441654583
Epoch: 35 | Iteration number: [3840/4518] 84% | Training loss: 0.6870160993809501
Epoch: 35 | Iteration number: [3850/4518] 85% | Training loss: 0.6870158405737443
Epoch: 35 | Iteration number: [3860/4518] 85% | Training loss: 0.6870173228991464
Epoch: 35 | Iteration number: [3870/4518] 85% | Training loss: 0.687018361156301
Epoch: 35 | Iteration number: [3880/4518] 85% | Training loss: 0.6870185646660549
Epoch: 35 | Iteration number: [3890/4518] 86% | Training loss: 0.6870169965344407
Epoch: 35 | Iteration number: [3900/4518] 86% | Training loss: 0.6870123144602164
Epoch: 35 | Iteration number: [3910/4518] 86% | Training loss: 0.687011031116671
Epoch: 35 | Iteration number: [3920/4518] 86% | Training loss: 0.6870121722926898
Epoch: 35 | Iteration number: [3930/4518] 86% | Training loss: 0.6870110683313763
Epoch: 35 | Iteration number: [3940/4518] 87% | Training loss: 0.6870094998082533
Epoch: 35 | Iteration number: [3950/4518] 87% | Training loss: 0.6870070207571681
Epoch: 35 | Iteration number: [3960/4518] 87% | Training loss: 0.6870054395963447
Epoch: 35 | Iteration number: [3970/4518] 87% | Training loss: 0.687000913839196
Epoch: 35 | Iteration number: [3980/4518] 88% | Training loss: 0.687001381148046
Epoch: 35 | Iteration number: [3990/4518] 88% | Training loss: 0.6870037073330174
Epoch: 35 | Iteration number: [4000/4518] 88% | Training loss: 0.687003892019391
Epoch: 35 | Iteration number: [4010/4518] 88% | Training loss: 0.6870030024105177
Epoch: 35 | Iteration number: [4020/4518] 88% | Training loss: 0.687002388576963
Epoch: 35 | Iteration number: [4030/4518] 89% | Training loss: 0.6870018512971939
Epoch: 35 | Iteration number: [4040/4518] 89% | Training loss: 0.6870025646273452
Epoch: 35 | Iteration number: [4050/4518] 89% | Training loss: 0.6870011887432617
Epoch: 35 | Iteration number: [4060/4518] 89% | Training loss: 0.6870019113488972
Epoch: 35 | Iteration number: [4070/4518] 90% | Training loss: 0.6870018548256642
Epoch: 35 | Iteration number: [4080/4518] 90% | Training loss: 0.6870007722255062
Epoch: 35 | Iteration number: [4090/4518] 90% | Training loss: 0.6869976586118013
Epoch: 35 | Iteration number: [4100/4518] 90% | Training loss: 0.6870001295717751
Epoch: 35 | Iteration number: [4110/4518] 90% | Training loss: 0.6869988642759857
Epoch: 35 | Iteration number: [4120/4518] 91% | Training loss: 0.6869999600266947
Epoch: 35 | Iteration number: [4130/4518] 91% | Training loss: 0.6870019327064403
Epoch: 35 | Iteration number: [4140/4518] 91% | Training loss: 0.6870022072308305
Epoch: 35 | Iteration number: [4150/4518] 91% | Training loss: 0.6869985005367233
Epoch: 35 | Iteration number: [4160/4518] 92% | Training loss: 0.6869998111604498
Epoch: 35 | Iteration number: [4170/4518] 92% | Training loss: 0.6870006213799941
Epoch: 35 | Iteration number: [4180/4518] 92% | Training loss: 0.6869983117403596
Epoch: 35 | Iteration number: [4190/4518] 92% | Training loss: 0.6869986816636133
Epoch: 35 | Iteration number: [4200/4518] 92% | Training loss: 0.6869999212168512
Epoch: 35 | Iteration number: [4210/4518] 93% | Training loss: 0.6870003229082339
Epoch: 35 | Iteration number: [4220/4518] 93% | Training loss: 0.6869980083540153
Epoch: 35 | Iteration number: [4230/4518] 93% | Training loss: 0.6869936724644744
Epoch: 35 | Iteration number: [4240/4518] 93% | Training loss: 0.6869932999728986
Epoch: 35 | Iteration number: [4250/4518] 94% | Training loss: 0.6869950859827154
Epoch: 35 | Iteration number: [4260/4518] 94% | Training loss: 0.686995319889185
Epoch: 35 | Iteration number: [4270/4518] 94% | Training loss: 0.6869952037965386
Epoch: 35 | Iteration number: [4280/4518] 94% | Training loss: 0.686996158637176
Epoch: 35 | Iteration number: [4290/4518] 94% | Training loss: 0.6869965873537086
Epoch: 35 | Iteration number: [4300/4518] 95% | Training loss: 0.6869974335265714
Epoch: 35 | Iteration number: [4310/4518] 95% | Training loss: 0.6869993274560384
Epoch: 35 | Iteration number: [4320/4518] 95% | Training loss: 0.6869982944318542
Epoch: 35 | Iteration number: [4330/4518] 95% | Training loss: 0.6870032459979245
Epoch: 35 | Iteration number: [4340/4518] 96% | Training loss: 0.687004244203941
Epoch: 35 | Iteration number: [4350/4518] 96% | Training loss: 0.6870068174943157
Epoch: 35 | Iteration number: [4360/4518] 96% | Training loss: 0.687007630349846
Epoch: 35 | Iteration number: [4370/4518] 96% | Training loss: 0.6870084999491476
Epoch: 35 | Iteration number: [4380/4518] 96% | Training loss: 0.6870064415479904
Epoch: 35 | Iteration number: [4390/4518] 97% | Training loss: 0.6870053715477772
Epoch: 35 | Iteration number: [4400/4518] 97% | Training loss: 0.6870054460384629
Epoch: 35 | Iteration number: [4410/4518] 97% | Training loss: 0.687007184890933
Epoch: 35 | Iteration number: [4420/4518] 97% | Training loss: 0.6870101313380634
Epoch: 35 | Iteration number: [4430/4518] 98% | Training loss: 0.6870093104801651
Epoch: 35 | Iteration number: [4440/4518] 98% | Training loss: 0.6870102337486035
Epoch: 35 | Iteration number: [4450/4518] 98% | Training loss: 0.6870097126049942
Epoch: 35 | Iteration number: [4460/4518] 98% | Training loss: 0.6870080330981267
Epoch: 35 | Iteration number: [4470/4518] 98% | Training loss: 0.687008046103804
Epoch: 35 | Iteration number: [4480/4518] 99% | Training loss: 0.6870081813872925
Epoch: 35 | Iteration number: [4490/4518] 99% | Training loss: 0.6870063494866038
Epoch: 35 | Iteration number: [4500/4518] 99% | Training loss: 0.6870033681260215
Epoch: 35 | Iteration number: [4510/4518] 99% | Training loss: 0.6870026064949923

 End of epoch: 35 | Train Loss: 0.6868489245863919 | Training Time: 642 

 End of epoch: 35 | Eval Loss: 0.690308542884126 | Evaluating Time: 17 
Epoch: 36 | Iteration number: [10/4518] 0% | Training loss: 0.7554665565490722
Epoch: 36 | Iteration number: [20/4518] 0% | Training loss: 0.7208605140447617
Epoch: 36 | Iteration number: [30/4518] 0% | Training loss: 0.7092816034952799
Epoch: 36 | Iteration number: [40/4518] 0% | Training loss: 0.7031395196914673
Epoch: 36 | Iteration number: [50/4518] 1% | Training loss: 0.69973925948143
Epoch: 36 | Iteration number: [60/4518] 1% | Training loss: 0.6976623048384984
Epoch: 36 | Iteration number: [70/4518] 1% | Training loss: 0.6962077336651938
Epoch: 36 | Iteration number: [80/4518] 1% | Training loss: 0.6950492165982723
Epoch: 36 | Iteration number: [90/4518] 1% | Training loss: 0.6942448761728075
Epoch: 36 | Iteration number: [100/4518] 2% | Training loss: 0.6935191506147385
Epoch: 36 | Iteration number: [110/4518] 2% | Training loss: 0.6930033586241983
Epoch: 36 | Iteration number: [120/4518] 2% | Training loss: 0.6925184826056162
Epoch: 36 | Iteration number: [130/4518] 2% | Training loss: 0.6921632551229917
Epoch: 36 | Iteration number: [140/4518] 3% | Training loss: 0.6918591452496392
Epoch: 36 | Iteration number: [150/4518] 3% | Training loss: 0.6915129502614339
Epoch: 36 | Iteration number: [160/4518] 3% | Training loss: 0.6911475915461779
Epoch: 36 | Iteration number: [170/4518] 3% | Training loss: 0.690834077316172
Epoch: 36 | Iteration number: [180/4518] 3% | Training loss: 0.6905806157324049
Epoch: 36 | Iteration number: [190/4518] 4% | Training loss: 0.6903011667101007
Epoch: 36 | Iteration number: [200/4518] 4% | Training loss: 0.6900836700201034
Epoch: 36 | Iteration number: [210/4518] 4% | Training loss: 0.6898386722519284
Epoch: 36 | Iteration number: [220/4518] 4% | Training loss: 0.6897012388164346
Epoch: 36 | Iteration number: [230/4518] 5% | Training loss: 0.689626607687577
Epoch: 36 | Iteration number: [240/4518] 5% | Training loss: 0.6894957552353541
Epoch: 36 | Iteration number: [250/4518] 5% | Training loss: 0.6893708400726318
Epoch: 36 | Iteration number: [260/4518] 5% | Training loss: 0.6892884756510075
Epoch: 36 | Iteration number: [270/4518] 5% | Training loss: 0.6891771793365479
Epoch: 36 | Iteration number: [280/4518] 6% | Training loss: 0.6891184327857834
Epoch: 36 | Iteration number: [290/4518] 6% | Training loss: 0.6890300156741307
Epoch: 36 | Iteration number: [300/4518] 6% | Training loss: 0.6889940158526102
Epoch: 36 | Iteration number: [310/4518] 6% | Training loss: 0.6889449263772657
Epoch: 36 | Iteration number: [320/4518] 7% | Training loss: 0.68888682089746
Epoch: 36 | Iteration number: [330/4518] 7% | Training loss: 0.6888005431854364
Epoch: 36 | Iteration number: [340/4518] 7% | Training loss: 0.6886676914551679
Epoch: 36 | Iteration number: [350/4518] 7% | Training loss: 0.6885610934666225
Epoch: 36 | Iteration number: [360/4518] 7% | Training loss: 0.6885141031609641
Epoch: 36 | Iteration number: [370/4518] 8% | Training loss: 0.6884660835201676
Epoch: 36 | Iteration number: [380/4518] 8% | Training loss: 0.6884509748534152
Epoch: 36 | Iteration number: [390/4518] 8% | Training loss: 0.6884324321380029
Epoch: 36 | Iteration number: [400/4518] 8% | Training loss: 0.6883962306380272
Epoch: 36 | Iteration number: [410/4518] 9% | Training loss: 0.688374296484924
Epoch: 36 | Iteration number: [420/4518] 9% | Training loss: 0.6883411933978398
Epoch: 36 | Iteration number: [430/4518] 9% | Training loss: 0.6883107868737952
Epoch: 36 | Iteration number: [440/4518] 9% | Training loss: 0.6882897477258335
Epoch: 36 | Iteration number: [450/4518] 9% | Training loss: 0.6882772779464722
Epoch: 36 | Iteration number: [460/4518] 10% | Training loss: 0.688250396044358
Epoch: 36 | Iteration number: [470/4518] 10% | Training loss: 0.6882473371130355
Epoch: 36 | Iteration number: [480/4518] 10% | Training loss: 0.6882130357126395
Epoch: 36 | Iteration number: [490/4518] 10% | Training loss: 0.6881948578114412
Epoch: 36 | Iteration number: [500/4518] 11% | Training loss: 0.6881354538202286
Epoch: 36 | Iteration number: [510/4518] 11% | Training loss: 0.6880966395724053
Epoch: 36 | Iteration number: [520/4518] 11% | Training loss: 0.6880657113515414
Epoch: 36 | Iteration number: [530/4518] 11% | Training loss: 0.6880340654894991
Epoch: 36 | Iteration number: [540/4518] 11% | Training loss: 0.6880141813445975
Epoch: 36 | Iteration number: [550/4518] 12% | Training loss: 0.6880021418224681
Epoch: 36 | Iteration number: [560/4518] 12% | Training loss: 0.6879797086119652
Epoch: 36 | Iteration number: [570/4518] 12% | Training loss: 0.6879677139876181
Epoch: 36 | Iteration number: [580/4518] 12% | Training loss: 0.6879367279595342
Epoch: 36 | Iteration number: [590/4518] 13% | Training loss: 0.687928808947741
Epoch: 36 | Iteration number: [600/4518] 13% | Training loss: 0.6879230829079946
Epoch: 36 | Iteration number: [610/4518] 13% | Training loss: 0.6878977644638937
Epoch: 36 | Iteration number: [620/4518] 13% | Training loss: 0.6878716969682325
Epoch: 36 | Iteration number: [630/4518] 13% | Training loss: 0.6878353125519223
Epoch: 36 | Iteration number: [640/4518] 14% | Training loss: 0.6878205894492566
Epoch: 36 | Iteration number: [650/4518] 14% | Training loss: 0.6878129682174096
Epoch: 36 | Iteration number: [660/4518] 14% | Training loss: 0.6878099398179488
Epoch: 36 | Iteration number: [670/4518] 14% | Training loss: 0.6877930715902528
Epoch: 36 | Iteration number: [680/4518] 15% | Training loss: 0.6877781050170169
Epoch: 36 | Iteration number: [690/4518] 15% | Training loss: 0.6877580036287723
Epoch: 36 | Iteration number: [700/4518] 15% | Training loss: 0.6877295488119125
Epoch: 36 | Iteration number: [710/4518] 15% | Training loss: 0.6877301359680337
Epoch: 36 | Iteration number: [720/4518] 15% | Training loss: 0.6877211143573125
Epoch: 36 | Iteration number: [730/4518] 16% | Training loss: 0.6877250527682369
Epoch: 36 | Iteration number: [740/4518] 16% | Training loss: 0.687720663241438
Epoch: 36 | Iteration number: [750/4518] 16% | Training loss: 0.6877006748517355
Epoch: 36 | Iteration number: [760/4518] 16% | Training loss: 0.6876686099328493
Epoch: 36 | Iteration number: [770/4518] 17% | Training loss: 0.6876544062193338
Epoch: 36 | Iteration number: [780/4518] 17% | Training loss: 0.6876450025118315
Epoch: 36 | Iteration number: [790/4518] 17% | Training loss: 0.6876267769668676
Epoch: 36 | Iteration number: [800/4518] 17% | Training loss: 0.6876181671023369
Epoch: 36 | Iteration number: [810/4518] 17% | Training loss: 0.6876144668938201
Epoch: 36 | Iteration number: [820/4518] 18% | Training loss: 0.6876210680095161
Epoch: 36 | Iteration number: [830/4518] 18% | Training loss: 0.6876062792467784
Epoch: 36 | Iteration number: [840/4518] 18% | Training loss: 0.6875954813900448
Epoch: 36 | Iteration number: [850/4518] 18% | Training loss: 0.6875802120040445
Epoch: 36 | Iteration number: [860/4518] 19% | Training loss: 0.6875753393699956
Epoch: 36 | Iteration number: [870/4518] 19% | Training loss: 0.6875807276402397
Epoch: 36 | Iteration number: [880/4518] 19% | Training loss: 0.6875749189067971
Epoch: 36 | Iteration number: [890/4518] 19% | Training loss: 0.6875725132026029
Epoch: 36 | Iteration number: [900/4518] 19% | Training loss: 0.6875722924205991
Epoch: 36 | Iteration number: [910/4518] 20% | Training loss: 0.6875355772264711
Epoch: 36 | Iteration number: [920/4518] 20% | Training loss: 0.6875263497881268
Epoch: 36 | Iteration number: [930/4518] 20% | Training loss: 0.6875183369523735
Epoch: 36 | Iteration number: [940/4518] 20% | Training loss: 0.6875159590802294
Epoch: 36 | Iteration number: [950/4518] 21% | Training loss: 0.687509912064201
Epoch: 36 | Iteration number: [960/4518] 21% | Training loss: 0.6874843253443639
Epoch: 36 | Iteration number: [970/4518] 21% | Training loss: 0.6874809123806118
Epoch: 36 | Iteration number: [980/4518] 21% | Training loss: 0.6874781046594892
Epoch: 36 | Iteration number: [990/4518] 21% | Training loss: 0.6874584062532945
Epoch: 36 | Iteration number: [1000/4518] 22% | Training loss: 0.6874479541182518
Epoch: 36 | Iteration number: [1010/4518] 22% | Training loss: 0.6874385002225932
Epoch: 36 | Iteration number: [1020/4518] 22% | Training loss: 0.6874399043181363
Epoch: 36 | Iteration number: [1030/4518] 22% | Training loss: 0.6874228285933004
Epoch: 36 | Iteration number: [1040/4518] 23% | Training loss: 0.6874288983643055
Epoch: 36 | Iteration number: [1050/4518] 23% | Training loss: 0.6874235504581815
Epoch: 36 | Iteration number: [1060/4518] 23% | Training loss: 0.687425504371805
Epoch: 36 | Iteration number: [1070/4518] 23% | Training loss: 0.6874266863426316
Epoch: 36 | Iteration number: [1080/4518] 23% | Training loss: 0.6874297699442616
Epoch: 36 | Iteration number: [1090/4518] 24% | Training loss: 0.6874131264489725
Epoch: 36 | Iteration number: [1100/4518] 24% | Training loss: 0.6874031004580584
Epoch: 36 | Iteration number: [1110/4518] 24% | Training loss: 0.6873965487286852
Epoch: 36 | Iteration number: [1120/4518] 24% | Training loss: 0.6873758983931371
Epoch: 36 | Iteration number: [1130/4518] 25% | Training loss: 0.6873716482019002
Epoch: 36 | Iteration number: [1140/4518] 25% | Training loss: 0.6873733557107156
Epoch: 36 | Iteration number: [1150/4518] 25% | Training loss: 0.6873739910644033
Epoch: 36 | Iteration number: [1160/4518] 25% | Training loss: 0.6873566357740041
Epoch: 36 | Iteration number: [1170/4518] 25% | Training loss: 0.6873582297410721
Epoch: 36 | Iteration number: [1180/4518] 26% | Training loss: 0.6873560753414186
Epoch: 36 | Iteration number: [1190/4518] 26% | Training loss: 0.6873484051027218
Epoch: 36 | Iteration number: [1200/4518] 26% | Training loss: 0.6873345516125361
Epoch: 36 | Iteration number: [1210/4518] 26% | Training loss: 0.6873331930519135
Epoch: 36 | Iteration number: [1220/4518] 27% | Training loss: 0.6873273802096727
Epoch: 36 | Iteration number: [1230/4518] 27% | Training loss: 0.6873239198835884
Epoch: 36 | Iteration number: [1240/4518] 27% | Training loss: 0.6873252449016417
Epoch: 36 | Iteration number: [1250/4518] 27% | Training loss: 0.6873288278579712
Epoch: 36 | Iteration number: [1260/4518] 27% | Training loss: 0.6873280320375684
Epoch: 36 | Iteration number: [1270/4518] 28% | Training loss: 0.6873299657829165
Epoch: 36 | Iteration number: [1280/4518] 28% | Training loss: 0.6873253795783967
Epoch: 36 | Iteration number: [1290/4518] 28% | Training loss: 0.6873192404129709
Epoch: 36 | Iteration number: [1300/4518] 28% | Training loss: 0.6873169078276707
Epoch: 36 | Iteration number: [1310/4518] 28% | Training loss: 0.6873091626713295
Epoch: 36 | Iteration number: [1320/4518] 29% | Training loss: 0.687299712950533
Epoch: 36 | Iteration number: [1330/4518] 29% | Training loss: 0.6872946802386664
Epoch: 36 | Iteration number: [1340/4518] 29% | Training loss: 0.6872861484093452
Epoch: 36 | Iteration number: [1350/4518] 29% | Training loss: 0.6872949338842321
Epoch: 36 | Iteration number: [1360/4518] 30% | Training loss: 0.6872858480495565
Epoch: 36 | Iteration number: [1370/4518] 30% | Training loss: 0.687279199509725
Epoch: 36 | Iteration number: [1380/4518] 30% | Training loss: 0.6872742789379065
Epoch: 36 | Iteration number: [1390/4518] 30% | Training loss: 0.6872705213886371
Epoch: 36 | Iteration number: [1400/4518] 30% | Training loss: 0.6872716910498483
Epoch: 36 | Iteration number: [1410/4518] 31% | Training loss: 0.687267268549466
Epoch: 36 | Iteration number: [1420/4518] 31% | Training loss: 0.6872648402418888
Epoch: 36 | Iteration number: [1430/4518] 31% | Training loss: 0.6872600767162297
Epoch: 36 | Iteration number: [1440/4518] 31% | Training loss: 0.6872526466846466
Epoch: 36 | Iteration number: [1450/4518] 32% | Training loss: 0.6872408649839203
Epoch: 36 | Iteration number: [1460/4518] 32% | Training loss: 0.6872335883036051
Epoch: 36 | Iteration number: [1470/4518] 32% | Training loss: 0.6872298533413685
Epoch: 36 | Iteration number: [1480/4518] 32% | Training loss: 0.6872396057521974
Epoch: 36 | Iteration number: [1490/4518] 32% | Training loss: 0.6872344531068866
Epoch: 36 | Iteration number: [1500/4518] 33% | Training loss: 0.687224148273468
Epoch: 36 | Iteration number: [1510/4518] 33% | Training loss: 0.687223949179744
Epoch: 36 | Iteration number: [1520/4518] 33% | Training loss: 0.6872261301467293
Epoch: 36 | Iteration number: [1530/4518] 33% | Training loss: 0.6872237434963775
Epoch: 36 | Iteration number: [1540/4518] 34% | Training loss: 0.687229344906745
Epoch: 36 | Iteration number: [1550/4518] 34% | Training loss: 0.687222292346339
Epoch: 36 | Iteration number: [1560/4518] 34% | Training loss: 0.6872258553520227
Epoch: 36 | Iteration number: [1570/4518] 34% | Training loss: 0.6872196596898851
Epoch: 36 | Iteration number: [1580/4518] 34% | Training loss: 0.687214374844032
Epoch: 36 | Iteration number: [1590/4518] 35% | Training loss: 0.6872038639941306
Epoch: 36 | Iteration number: [1600/4518] 35% | Training loss: 0.6872018014267087
Epoch: 36 | Iteration number: [1610/4518] 35% | Training loss: 0.6872038428827842
Epoch: 36 | Iteration number: [1620/4518] 35% | Training loss: 0.6872038811445236
Epoch: 36 | Iteration number: [1630/4518] 36% | Training loss: 0.6871996020612541
Epoch: 36 | Iteration number: [1640/4518] 36% | Training loss: 0.6871932712996879
Epoch: 36 | Iteration number: [1650/4518] 36% | Training loss: 0.6871838985789905
Epoch: 36 | Iteration number: [1660/4518] 36% | Training loss: 0.6871881914066981
Epoch: 36 | Iteration number: [1670/4518] 36% | Training loss: 0.687179146162764
Epoch: 36 | Iteration number: [1680/4518] 37% | Training loss: 0.687179677543186
Epoch: 36 | Iteration number: [1690/4518] 37% | Training loss: 0.6871679332482039
Epoch: 36 | Iteration number: [1700/4518] 37% | Training loss: 0.6871725478943657
Epoch: 36 | Iteration number: [1710/4518] 37% | Training loss: 0.6871704648461259
Epoch: 36 | Iteration number: [1720/4518] 38% | Training loss: 0.6871706383519395
Epoch: 36 | Iteration number: [1730/4518] 38% | Training loss: 0.6871734098891992
Epoch: 36 | Iteration number: [1740/4518] 38% | Training loss: 0.6871695165319004
Epoch: 36 | Iteration number: [1750/4518] 38% | Training loss: 0.6871685492992401
Epoch: 36 | Iteration number: [1760/4518] 38% | Training loss: 0.6871703387322751
Epoch: 36 | Iteration number: [1770/4518] 39% | Training loss: 0.6871732201616643
Epoch: 36 | Iteration number: [1780/4518] 39% | Training loss: 0.6871650269192257
Epoch: 36 | Iteration number: [1790/4518] 39% | Training loss: 0.6871635521923364
Epoch: 36 | Iteration number: [1800/4518] 39% | Training loss: 0.6871610648433367
Epoch: 36 | Iteration number: [1810/4518] 40% | Training loss: 0.6871657531564407
Epoch: 36 | Iteration number: [1820/4518] 40% | Training loss: 0.6871568878928384
Epoch: 36 | Iteration number: [1830/4518] 40% | Training loss: 0.6871535175485037
Epoch: 36 | Iteration number: [1840/4518] 40% | Training loss: 0.6871537191388399
Epoch: 36 | Iteration number: [1850/4518] 40% | Training loss: 0.687152611629383
Epoch: 36 | Iteration number: [1860/4518] 41% | Training loss: 0.6871503696005832
Epoch: 36 | Iteration number: [1870/4518] 41% | Training loss: 0.6871517876571512
Epoch: 36 | Iteration number: [1880/4518] 41% | Training loss: 0.6871505931336829
Epoch: 36 | Iteration number: [1890/4518] 41% | Training loss: 0.6871499507830887
Epoch: 36 | Iteration number: [1900/4518] 42% | Training loss: 0.6871493335146653
Epoch: 36 | Iteration number: [1910/4518] 42% | Training loss: 0.6871409712349558
Epoch: 36 | Iteration number: [1920/4518] 42% | Training loss: 0.6871444844951232
Epoch: 36 | Iteration number: [1930/4518] 42% | Training loss: 0.6871429570598305
Epoch: 36 | Iteration number: [1940/4518] 42% | Training loss: 0.687146918521714
Epoch: 36 | Iteration number: [1950/4518] 43% | Training loss: 0.6871409756709368
Epoch: 36 | Iteration number: [1960/4518] 43% | Training loss: 0.6871360664160884
Epoch: 36 | Iteration number: [1970/4518] 43% | Training loss: 0.6871321697828128
Epoch: 36 | Iteration number: [1980/4518] 43% | Training loss: 0.6871376913605314
Epoch: 36 | Iteration number: [1990/4518] 44% | Training loss: 0.6871355028008695
Epoch: 36 | Iteration number: [2000/4518] 44% | Training loss: 0.6871326667666435
Epoch: 36 | Iteration number: [2010/4518] 44% | Training loss: 0.6871414415871919
Epoch: 36 | Iteration number: [2020/4518] 44% | Training loss: 0.6871378057073838
Epoch: 36 | Iteration number: [2030/4518] 44% | Training loss: 0.687132516518015
Epoch: 36 | Iteration number: [2040/4518] 45% | Training loss: 0.6871331117608968
Epoch: 36 | Iteration number: [2050/4518] 45% | Training loss: 0.6871298098564148
Epoch: 36 | Iteration number: [2060/4518] 45% | Training loss: 0.6871331213458071
Epoch: 36 | Iteration number: [2070/4518] 45% | Training loss: 0.6871323123070353
Epoch: 36 | Iteration number: [2080/4518] 46% | Training loss: 0.687130637294971
Epoch: 36 | Iteration number: [2090/4518] 46% | Training loss: 0.6871362995017659
Epoch: 36 | Iteration number: [2100/4518] 46% | Training loss: 0.6871429278737022
Epoch: 36 | Iteration number: [2110/4518] 46% | Training loss: 0.6871392083111533
Epoch: 36 | Iteration number: [2120/4518] 46% | Training loss: 0.6871397475588996
Epoch: 36 | Iteration number: [2130/4518] 47% | Training loss: 0.6871404833636933
Epoch: 36 | Iteration number: [2140/4518] 47% | Training loss: 0.6871349070395265
Epoch: 36 | Iteration number: [2150/4518] 47% | Training loss: 0.6871350621899893
Epoch: 36 | Iteration number: [2160/4518] 47% | Training loss: 0.687130272416053
Epoch: 36 | Iteration number: [2170/4518] 48% | Training loss: 0.6871312438617654
Epoch: 36 | Iteration number: [2180/4518] 48% | Training loss: 0.6871301098974473
Epoch: 36 | Iteration number: [2190/4518] 48% | Training loss: 0.6871255240211748
Epoch: 36 | Iteration number: [2200/4518] 48% | Training loss: 0.6871323683316057
Epoch: 36 | Iteration number: [2210/4518] 48% | Training loss: 0.6871323000791386
Epoch: 36 | Iteration number: [2220/4518] 49% | Training loss: 0.6871383349369238
Epoch: 36 | Iteration number: [2230/4518] 49% | Training loss: 0.687135305826974
Epoch: 36 | Iteration number: [2240/4518] 49% | Training loss: 0.6871294708922505
Epoch: 36 | Iteration number: [2250/4518] 49% | Training loss: 0.6871258252461752
Epoch: 36 | Iteration number: [2260/4518] 50% | Training loss: 0.6871226803918855
Epoch: 36 | Iteration number: [2270/4518] 50% | Training loss: 0.687123468531386
Epoch: 36 | Iteration number: [2280/4518] 50% | Training loss: 0.6871227616280841
Epoch: 36 | Iteration number: [2290/4518] 50% | Training loss: 0.6871199165369225
Epoch: 36 | Iteration number: [2300/4518] 50% | Training loss: 0.6871184093278387
Epoch: 36 | Iteration number: [2310/4518] 51% | Training loss: 0.6871140759228628
Epoch: 36 | Iteration number: [2320/4518] 51% | Training loss: 0.6871100169317476
Epoch: 36 | Iteration number: [2330/4518] 51% | Training loss: 0.6871139103762581
Epoch: 36 | Iteration number: [2340/4518] 51% | Training loss: 0.6871090909864148
Epoch: 36 | Iteration number: [2350/4518] 52% | Training loss: 0.6871157274094034
Epoch: 36 | Iteration number: [2360/4518] 52% | Training loss: 0.6871186186449002
Epoch: 36 | Iteration number: [2370/4518] 52% | Training loss: 0.6871188800797684
Epoch: 36 | Iteration number: [2380/4518] 52% | Training loss: 0.6871134926541512
Epoch: 36 | Iteration number: [2390/4518] 52% | Training loss: 0.6871145848948587
Epoch: 36 | Iteration number: [2400/4518] 53% | Training loss: 0.6871138619879882
Epoch: 36 | Iteration number: [2410/4518] 53% | Training loss: 0.687110801801642
Epoch: 36 | Iteration number: [2420/4518] 53% | Training loss: 0.68710719184442
Epoch: 36 | Iteration number: [2430/4518] 53% | Training loss: 0.6871037771427092
Epoch: 36 | Iteration number: [2440/4518] 54% | Training loss: 0.6871013837759612
Epoch: 36 | Iteration number: [2450/4518] 54% | Training loss: 0.6871054734015951
Epoch: 36 | Iteration number: [2460/4518] 54% | Training loss: 0.6871020358994724
Epoch: 36 | Iteration number: [2470/4518] 54% | Training loss: 0.6871001083841208
Epoch: 36 | Iteration number: [2480/4518] 54% | Training loss: 0.687100412720634
Epoch: 36 | Iteration number: [2490/4518] 55% | Training loss: 0.6870970521586008
Epoch: 36 | Iteration number: [2500/4518] 55% | Training loss: 0.6870944630622864
Epoch: 36 | Iteration number: [2510/4518] 55% | Training loss: 0.6870945795361264
Epoch: 36 | Iteration number: [2520/4518] 55% | Training loss: 0.687096050476271
Epoch: 36 | Iteration number: [2530/4518] 55% | Training loss: 0.6870919947096482
Epoch: 36 | Iteration number: [2540/4518] 56% | Training loss: 0.6870907039388897
Epoch: 36 | Iteration number: [2550/4518] 56% | Training loss: 0.6870833874216267
Epoch: 36 | Iteration number: [2560/4518] 56% | Training loss: 0.687083427561447
Epoch: 36 | Iteration number: [2570/4518] 56% | Training loss: 0.6870839311223086
Epoch: 36 | Iteration number: [2580/4518] 57% | Training loss: 0.6870821238950241
Epoch: 36 | Iteration number: [2590/4518] 57% | Training loss: 0.6870762051762761
Epoch: 36 | Iteration number: [2600/4518] 57% | Training loss: 0.6870774625127132
Epoch: 36 | Iteration number: [2610/4518] 57% | Training loss: 0.6870733159483621
Epoch: 36 | Iteration number: [2620/4518] 57% | Training loss: 0.6870731878371639
Epoch: 36 | Iteration number: [2630/4518] 58% | Training loss: 0.6870772718250071
Epoch: 36 | Iteration number: [2640/4518] 58% | Training loss: 0.6870799440326113
Epoch: 36 | Iteration number: [2650/4518] 58% | Training loss: 0.6870768333830923
Epoch: 36 | Iteration number: [2660/4518] 58% | Training loss: 0.6870750732887957
Epoch: 36 | Iteration number: [2670/4518] 59% | Training loss: 0.6870793934395251
Epoch: 36 | Iteration number: [2680/4518] 59% | Training loss: 0.6870738412906875
Epoch: 36 | Iteration number: [2690/4518] 59% | Training loss: 0.6870705860919669
Epoch: 36 | Iteration number: [2700/4518] 59% | Training loss: 0.6870705081136138
Epoch: 36 | Iteration number: [2710/4518] 59% | Training loss: 0.6870678702183756
Epoch: 36 | Iteration number: [2720/4518] 60% | Training loss: 0.6870684416197679
Epoch: 36 | Iteration number: [2730/4518] 60% | Training loss: 0.6870715214874281
Epoch: 36 | Iteration number: [2740/4518] 60% | Training loss: 0.6870708344191531
Epoch: 36 | Iteration number: [2750/4518] 60% | Training loss: 0.687069847128608
Epoch: 36 | Iteration number: [2760/4518] 61% | Training loss: 0.6870686623713245
Epoch: 36 | Iteration number: [2770/4518] 61% | Training loss: 0.6870675855164924
Epoch: 36 | Iteration number: [2780/4518] 61% | Training loss: 0.6870637511606696
Epoch: 36 | Iteration number: [2790/4518] 61% | Training loss: 0.6870611987233589
Epoch: 36 | Iteration number: [2800/4518] 61% | Training loss: 0.6870661577369486
Epoch: 36 | Iteration number: [2810/4518] 62% | Training loss: 0.6870659955031507
Epoch: 36 | Iteration number: [2820/4518] 62% | Training loss: 0.6870655236726112
Epoch: 36 | Iteration number: [2830/4518] 62% | Training loss: 0.687061144585323
Epoch: 36 | Iteration number: [2840/4518] 62% | Training loss: 0.687061955076708
Epoch: 36 | Iteration number: [2850/4518] 63% | Training loss: 0.6870601377989116
Epoch: 36 | Iteration number: [2860/4518] 63% | Training loss: 0.6870604226847629
Epoch: 36 | Iteration number: [2870/4518] 63% | Training loss: 0.6870584295186432
Epoch: 36 | Iteration number: [2880/4518] 63% | Training loss: 0.6870559272666772
Epoch: 36 | Iteration number: [2890/4518] 63% | Training loss: 0.6870572207502015
Epoch: 36 | Iteration number: [2900/4518] 64% | Training loss: 0.6870581008442517
Epoch: 36 | Iteration number: [2910/4518] 64% | Training loss: 0.6870562957939004
Epoch: 36 | Iteration number: [2920/4518] 64% | Training loss: 0.6870559409873126
Epoch: 36 | Iteration number: [2930/4518] 64% | Training loss: 0.6870510089926345
Epoch: 36 | Iteration number: [2940/4518] 65% | Training loss: 0.6870524979570285
Epoch: 36 | Iteration number: [2950/4518] 65% | Training loss: 0.687048864384829
Epoch: 36 | Iteration number: [2960/4518] 65% | Training loss: 0.6870478706988128
Epoch: 36 | Iteration number: [2970/4518] 65% | Training loss: 0.6870480206076947
Epoch: 36 | Iteration number: [2980/4518] 65% | Training loss: 0.6870467642209674
Epoch: 36 | Iteration number: [2990/4518] 66% | Training loss: 0.6870451559988552
Epoch: 36 | Iteration number: [3000/4518] 66% | Training loss: 0.6870412522951762
Epoch: 36 | Iteration number: [3010/4518] 66% | Training loss: 0.6870429546136001
Epoch: 36 | Iteration number: [3020/4518] 66% | Training loss: 0.6870430302343621
Epoch: 36 | Iteration number: [3030/4518] 67% | Training loss: 0.6870420211415873
Epoch: 36 | Iteration number: [3040/4518] 67% | Training loss: 0.6870387469663432
Epoch: 36 | Iteration number: [3050/4518] 67% | Training loss: 0.6870396767287957
Epoch: 36 | Iteration number: [3060/4518] 67% | Training loss: 0.6870433774648929
Epoch: 36 | Iteration number: [3070/4518] 67% | Training loss: 0.6870399191247524
Epoch: 36 | Iteration number: [3080/4518] 68% | Training loss: 0.6870421599451597
Epoch: 36 | Iteration number: [3090/4518] 68% | Training loss: 0.6870376921201601
Epoch: 36 | Iteration number: [3100/4518] 68% | Training loss: 0.6870396546394594
Epoch: 36 | Iteration number: [3110/4518] 68% | Training loss: 0.6870344549130013
Epoch: 36 | Iteration number: [3120/4518] 69% | Training loss: 0.6870315884359371
Epoch: 36 | Iteration number: [3130/4518] 69% | Training loss: 0.6870300791895808
Epoch: 36 | Iteration number: [3140/4518] 69% | Training loss: 0.6870302743403016
Epoch: 36 | Iteration number: [3150/4518] 69% | Training loss: 0.6870309317111969
Epoch: 36 | Iteration number: [3160/4518] 69% | Training loss: 0.6870314890259429
Epoch: 36 | Iteration number: [3170/4518] 70% | Training loss: 0.6870335516305376
Epoch: 36 | Iteration number: [3180/4518] 70% | Training loss: 0.6870288559288349
Epoch: 36 | Iteration number: [3190/4518] 70% | Training loss: 0.6870287251509842
Epoch: 36 | Iteration number: [3200/4518] 70% | Training loss: 0.6870298884063959
Epoch: 36 | Iteration number: [3210/4518] 71% | Training loss: 0.6870299687452406
Epoch: 36 | Iteration number: [3220/4518] 71% | Training loss: 0.6870320813256021
Epoch: 36 | Iteration number: [3230/4518] 71% | Training loss: 0.6870359889863076
Epoch: 36 | Iteration number: [3240/4518] 71% | Training loss: 0.6870397982038098
Epoch: 36 | Iteration number: [3250/4518] 71% | Training loss: 0.6870403849895184
Epoch: 36 | Iteration number: [3260/4518] 72% | Training loss: 0.6870385417177634
Epoch: 36 | Iteration number: [3270/4518] 72% | Training loss: 0.6870382141629491
Epoch: 36 | Iteration number: [3280/4518] 72% | Training loss: 0.6870413909234652
Epoch: 36 | Iteration number: [3290/4518] 72% | Training loss: 0.6870367322649275
Epoch: 36 | Iteration number: [3300/4518] 73% | Training loss: 0.6870393401745594
Epoch: 36 | Iteration number: [3310/4518] 73% | Training loss: 0.6870394853486755
Epoch: 36 | Iteration number: [3320/4518] 73% | Training loss: 0.6870400449238627
Epoch: 36 | Iteration number: [3330/4518] 73% | Training loss: 0.6870366250967478
Epoch: 36 | Iteration number: [3340/4518] 73% | Training loss: 0.6870353260440027
Epoch: 36 | Iteration number: [3350/4518] 74% | Training loss: 0.6870323402846037
Epoch: 36 | Iteration number: [3360/4518] 74% | Training loss: 0.6870326454795542
Epoch: 36 | Iteration number: [3370/4518] 74% | Training loss: 0.6870297512774651
Epoch: 36 | Iteration number: [3380/4518] 74% | Training loss: 0.687030763791863
Epoch: 36 | Iteration number: [3390/4518] 75% | Training loss: 0.687033153002241
Epoch: 36 | Iteration number: [3400/4518] 75% | Training loss: 0.687031362547594
Epoch: 36 | Iteration number: [3410/4518] 75% | Training loss: 0.6870326224135513
Epoch: 36 | Iteration number: [3420/4518] 75% | Training loss: 0.6870335341545574
Epoch: 36 | Iteration number: [3430/4518] 75% | Training loss: 0.6870329695088523
Epoch: 36 | Iteration number: [3440/4518] 76% | Training loss: 0.6870334828835587
Epoch: 36 | Iteration number: [3450/4518] 76% | Training loss: 0.6870298397368279
Epoch: 36 | Iteration number: [3460/4518] 76% | Training loss: 0.6870294045506186
Epoch: 36 | Iteration number: [3470/4518] 76% | Training loss: 0.6870304417713231
Epoch: 36 | Iteration number: [3480/4518] 77% | Training loss: 0.6870327858918015
Epoch: 36 | Iteration number: [3490/4518] 77% | Training loss: 0.6870322405779601
Epoch: 36 | Iteration number: [3500/4518] 77% | Training loss: 0.6870331502301352
Epoch: 36 | Iteration number: [3510/4518] 77% | Training loss: 0.6870358681067442
Epoch: 36 | Iteration number: [3520/4518] 77% | Training loss: 0.6870356299321759
Epoch: 36 | Iteration number: [3530/4518] 78% | Training loss: 0.6870342076331293
Epoch: 36 | Iteration number: [3540/4518] 78% | Training loss: 0.687036468720032
Epoch: 36 | Iteration number: [3550/4518] 78% | Training loss: 0.6870339421990892
Epoch: 36 | Iteration number: [3560/4518] 78% | Training loss: 0.6870357161492444
Epoch: 36 | Iteration number: [3570/4518] 79% | Training loss: 0.6870360527051931
Epoch: 36 | Iteration number: [3580/4518] 79% | Training loss: 0.6870371538500546
Epoch: 36 | Iteration number: [3590/4518] 79% | Training loss: 0.6870383890558418
Epoch: 36 | Iteration number: [3600/4518] 79% | Training loss: 0.6870388988157113
Epoch: 36 | Iteration number: [3610/4518] 79% | Training loss: 0.6870412222071037
Epoch: 36 | Iteration number: [3620/4518] 80% | Training loss: 0.6870399600728441
Epoch: 36 | Iteration number: [3630/4518] 80% | Training loss: 0.6870356867136049
Epoch: 36 | Iteration number: [3640/4518] 80% | Training loss: 0.6870319140153927
Epoch: 36 | Iteration number: [3650/4518] 80% | Training loss: 0.687031130202829
Epoch: 36 | Iteration number: [3660/4518] 81% | Training loss: 0.6870310599849524
Epoch: 36 | Iteration number: [3670/4518] 81% | Training loss: 0.6870311011248129
Epoch: 36 | Iteration number: [3680/4518] 81% | Training loss: 0.6870292365874933
Epoch: 36 | Iteration number: [3690/4518] 81% | Training loss: 0.6870287088682335
Epoch: 36 | Iteration number: [3700/4518] 81% | Training loss: 0.6870280910343737
Epoch: 36 | Iteration number: [3710/4518] 82% | Training loss: 0.6870271773993808
Epoch: 36 | Iteration number: [3720/4518] 82% | Training loss: 0.6870222262317135
Epoch: 36 | Iteration number: [3730/4518] 82% | Training loss: 0.6870215428259034
Epoch: 36 | Iteration number: [3740/4518] 82% | Training loss: 0.6870246267573719
Epoch: 36 | Iteration number: [3750/4518] 83% | Training loss: 0.6870262801011403
Epoch: 36 | Iteration number: [3760/4518] 83% | Training loss: 0.6870260097879044
Epoch: 36 | Iteration number: [3770/4518] 83% | Training loss: 0.6870267255710987
Epoch: 36 | Iteration number: [3780/4518] 83% | Training loss: 0.6870271077231755
Epoch: 36 | Iteration number: [3790/4518] 83% | Training loss: 0.6870275553738536
Epoch: 36 | Iteration number: [3800/4518] 84% | Training loss: 0.6870295851638443
Epoch: 36 | Iteration number: [3810/4518] 84% | Training loss: 0.6870341129033897
Epoch: 36 | Iteration number: [3820/4518] 84% | Training loss: 0.6870317281540775
Epoch: 36 | Iteration number: [3830/4518] 84% | Training loss: 0.6870318042391586
Epoch: 36 | Iteration number: [3840/4518] 84% | Training loss: 0.6870301359177877
Epoch: 36 | Iteration number: [3850/4518] 85% | Training loss: 0.6870317567788161
Epoch: 36 | Iteration number: [3860/4518] 85% | Training loss: 0.687030048892288
Epoch: 36 | Iteration number: [3870/4518] 85% | Training loss: 0.6870306045818082
Epoch: 36 | Iteration number: [3880/4518] 85% | Training loss: 0.687029978648289
Epoch: 36 | Iteration number: [3890/4518] 86% | Training loss: 0.6870307206188192
Epoch: 36 | Iteration number: [3900/4518] 86% | Training loss: 0.6870290443071952
Epoch: 36 | Iteration number: [3910/4518] 86% | Training loss: 0.687029409286616
Epoch: 36 | Iteration number: [3920/4518] 86% | Training loss: 0.6870276949539477
Epoch: 36 | Iteration number: [3930/4518] 86% | Training loss: 0.6870286609531966
Epoch: 36 | Iteration number: [3940/4518] 87% | Training loss: 0.6870287403691239
Epoch: 36 | Iteration number: [3950/4518] 87% | Training loss: 0.6870297917233238
Epoch: 36 | Iteration number: [3960/4518] 87% | Training loss: 0.6870293625526958
Epoch: 36 | Iteration number: [3970/4518] 87% | Training loss: 0.6870309527634973
Epoch: 36 | Iteration number: [3980/4518] 88% | Training loss: 0.6870297990701906
Epoch: 36 | Iteration number: [3990/4518] 88% | Training loss: 0.6870288754166816
Epoch: 36 | Iteration number: [4000/4518] 88% | Training loss: 0.6870298337340355
Epoch: 36 | Iteration number: [4010/4518] 88% | Training loss: 0.6870309393899399
Epoch: 36 | Iteration number: [4020/4518] 88% | Training loss: 0.6870307175377708
Epoch: 36 | Iteration number: [4030/4518] 89% | Training loss: 0.6870311050202059
Epoch: 36 | Iteration number: [4040/4518] 89% | Training loss: 0.6870315469137512
Epoch: 36 | Iteration number: [4050/4518] 89% | Training loss: 0.6870281151047459
Epoch: 36 | Iteration number: [4060/4518] 89% | Training loss: 0.6870297019264381
Epoch: 36 | Iteration number: [4070/4518] 90% | Training loss: 0.6870291747830131
Epoch: 36 | Iteration number: [4080/4518] 90% | Training loss: 0.6870284586122223
Epoch: 36 | Iteration number: [4090/4518] 90% | Training loss: 0.687024938273255
Epoch: 36 | Iteration number: [4100/4518] 90% | Training loss: 0.6870277179014392
Epoch: 36 | Iteration number: [4110/4518] 90% | Training loss: 0.6870263595070573
Epoch: 36 | Iteration number: [4120/4518] 91% | Training loss: 0.6870276454872298
Epoch: 36 | Iteration number: [4130/4518] 91% | Training loss: 0.6870326176105342
Epoch: 36 | Iteration number: [4140/4518] 91% | Training loss: 0.6870318743053841
Epoch: 36 | Iteration number: [4150/4518] 91% | Training loss: 0.6870294480151441
Epoch: 36 | Iteration number: [4160/4518] 92% | Training loss: 0.6870252245034163
Epoch: 36 | Iteration number: [4170/4518] 92% | Training loss: 0.6870218450931622
Epoch: 36 | Iteration number: [4180/4518] 92% | Training loss: 0.6870177603081653
Epoch: 36 | Iteration number: [4190/4518] 92% | Training loss: 0.6870183855224054
Epoch: 36 | Iteration number: [4200/4518] 92% | Training loss: 0.687015683225223
Epoch: 36 | Iteration number: [4210/4518] 93% | Training loss: 0.6870168830889705
Epoch: 36 | Iteration number: [4220/4518] 93% | Training loss: 0.6870109111776849
Epoch: 36 | Iteration number: [4230/4518] 93% | Training loss: 0.6870086303980356
Epoch: 36 | Iteration number: [4240/4518] 93% | Training loss: 0.6870084030167112
Epoch: 36 | Iteration number: [4250/4518] 94% | Training loss: 0.6870086460534264
Epoch: 36 | Iteration number: [4260/4518] 94% | Training loss: 0.6870098296045697
Epoch: 36 | Iteration number: [4270/4518] 94% | Training loss: 0.6870126552827465
Epoch: 36 | Iteration number: [4280/4518] 94% | Training loss: 0.6870092576491499
Epoch: 36 | Iteration number: [4290/4518] 94% | Training loss: 0.6870095053891758
Epoch: 36 | Iteration number: [4300/4518] 95% | Training loss: 0.6870040904089462
Epoch: 36 | Iteration number: [4310/4518] 95% | Training loss: 0.6870062338227185
Epoch: 36 | Iteration number: [4320/4518] 95% | Training loss: 0.6870019576753731
Epoch: 36 | Iteration number: [4330/4518] 95% | Training loss: 0.6870022389685034
Epoch: 36 | Iteration number: [4340/4518] 96% | Training loss: 0.6870029817528439
Epoch: 36 | Iteration number: [4350/4518] 96% | Training loss: 0.687003831082377
Epoch: 36 | Iteration number: [4360/4518] 96% | Training loss: 0.6870032588686418
Epoch: 36 | Iteration number: [4370/4518] 96% | Training loss: 0.6870044234551882
Epoch: 36 | Iteration number: [4380/4518] 96% | Training loss: 0.6870027935396047
Epoch: 36 | Iteration number: [4390/4518] 97% | Training loss: 0.6870006914426634
Epoch: 36 | Iteration number: [4400/4518] 97% | Training loss: 0.6869984851913019
Epoch: 36 | Iteration number: [4410/4518] 97% | Training loss: 0.6869988524454251
Epoch: 36 | Iteration number: [4420/4518] 97% | Training loss: 0.6870006770165258
Epoch: 36 | Iteration number: [4430/4518] 98% | Training loss: 0.6870033777325202
Epoch: 36 | Iteration number: [4440/4518] 98% | Training loss: 0.6870044178253896
Epoch: 36 | Iteration number: [4450/4518] 98% | Training loss: 0.6870040535524989
Epoch: 36 | Iteration number: [4460/4518] 98% | Training loss: 0.6870035613064274
Epoch: 36 | Iteration number: [4470/4518] 98% | Training loss: 0.6870025305406626
Epoch: 36 | Iteration number: [4480/4518] 99% | Training loss: 0.6870026887527534
Epoch: 36 | Iteration number: [4490/4518] 99% | Training loss: 0.68700136400278
Epoch: 36 | Iteration number: [4500/4518] 99% | Training loss: 0.6869980094167921
Epoch: 36 | Iteration number: [4510/4518] 99% | Training loss: 0.686995433981297

 End of epoch: 36 | Train Loss: 0.6868425234591554 | Training Time: 640 

 End of epoch: 36 | Eval Loss: 0.6901873483949778 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/4518] 0% | Training loss: 0.755967253446579
Epoch: 37 | Iteration number: [20/4518] 0% | Training loss: 0.7210354417562485
Epoch: 37 | Iteration number: [30/4518] 0% | Training loss: 0.7095538278420767
Epoch: 37 | Iteration number: [40/4518] 0% | Training loss: 0.7043052077293396
Epoch: 37 | Iteration number: [50/4518] 1% | Training loss: 0.7006627476215362
Epoch: 37 | Iteration number: [60/4518] 1% | Training loss: 0.6982662687699001
Epoch: 37 | Iteration number: [70/4518] 1% | Training loss: 0.6966855781418937
Epoch: 37 | Iteration number: [80/4518] 1% | Training loss: 0.6955054715275765
Epoch: 37 | Iteration number: [90/4518] 1% | Training loss: 0.694535470671124
Epoch: 37 | Iteration number: [100/4518] 2% | Training loss: 0.6937772566080094
Epoch: 37 | Iteration number: [110/4518] 2% | Training loss: 0.6930384413762526
Epoch: 37 | Iteration number: [120/4518] 2% | Training loss: 0.6925700962543487
Epoch: 37 | Iteration number: [130/4518] 2% | Training loss: 0.6921034698302929
Epoch: 37 | Iteration number: [140/4518] 3% | Training loss: 0.6917255137647901
Epoch: 37 | Iteration number: [150/4518] 3% | Training loss: 0.691476755142212
Epoch: 37 | Iteration number: [160/4518] 3% | Training loss: 0.6910356320440769
Epoch: 37 | Iteration number: [170/4518] 3% | Training loss: 0.6907475127893336
Epoch: 37 | Iteration number: [180/4518] 3% | Training loss: 0.6905312832858828
Epoch: 37 | Iteration number: [190/4518] 4% | Training loss: 0.6903085485885018
Epoch: 37 | Iteration number: [200/4518] 4% | Training loss: 0.6902024453878403
Epoch: 37 | Iteration number: [210/4518] 4% | Training loss: 0.6900654866581871
Epoch: 37 | Iteration number: [220/4518] 4% | Training loss: 0.6899132406169718
Epoch: 37 | Iteration number: [230/4518] 5% | Training loss: 0.6898299707018811
Epoch: 37 | Iteration number: [240/4518] 5% | Training loss: 0.6896706658105055
Epoch: 37 | Iteration number: [250/4518] 5% | Training loss: 0.6895505728721618
Epoch: 37 | Iteration number: [260/4518] 5% | Training loss: 0.6894280160848911
Epoch: 37 | Iteration number: [270/4518] 5% | Training loss: 0.6893331324612653
Epoch: 37 | Iteration number: [280/4518] 6% | Training loss: 0.689207369514874
Epoch: 37 | Iteration number: [290/4518] 6% | Training loss: 0.689106246520733
Epoch: 37 | Iteration number: [300/4518] 6% | Training loss: 0.6890467309951782
Epoch: 37 | Iteration number: [310/4518] 6% | Training loss: 0.6889467837349061
Epoch: 37 | Iteration number: [320/4518] 7% | Training loss: 0.6889032242819667
Epoch: 37 | Iteration number: [330/4518] 7% | Training loss: 0.6888363289110588
Epoch: 37 | Iteration number: [340/4518] 7% | Training loss: 0.6887915721710991
Epoch: 37 | Iteration number: [350/4518] 7% | Training loss: 0.6887456018584115
Epoch: 37 | Iteration number: [360/4518] 7% | Training loss: 0.688695186873277
Epoch: 37 | Iteration number: [370/4518] 8% | Training loss: 0.6886608813260052
Epoch: 37 | Iteration number: [380/4518] 8% | Training loss: 0.6886317488394286
Epoch: 37 | Iteration number: [390/4518] 8% | Training loss: 0.688557459299381
Epoch: 37 | Iteration number: [400/4518] 8% | Training loss: 0.6885193209350109
Epoch: 37 | Iteration number: [410/4518] 9% | Training loss: 0.6884821772575378
Epoch: 37 | Iteration number: [420/4518] 9% | Training loss: 0.6884416960534595
Epoch: 37 | Iteration number: [430/4518] 9% | Training loss: 0.6884157478809356
Epoch: 37 | Iteration number: [440/4518] 9% | Training loss: 0.6883426106788896
Epoch: 37 | Iteration number: [450/4518] 9% | Training loss: 0.6883357191085815
Epoch: 37 | Iteration number: [460/4518] 10% | Training loss: 0.6883066002441489
Epoch: 37 | Iteration number: [470/4518] 10% | Training loss: 0.6882725741000886
Epoch: 37 | Iteration number: [480/4518] 10% | Training loss: 0.6882221749673287
Epoch: 37 | Iteration number: [490/4518] 10% | Training loss: 0.688204858984266
Epoch: 37 | Iteration number: [500/4518] 11% | Training loss: 0.688159760594368
Epoch: 37 | Iteration number: [510/4518] 11% | Training loss: 0.688146577278773
Epoch: 37 | Iteration number: [520/4518] 11% | Training loss: 0.6881182625889778
Epoch: 37 | Iteration number: [530/4518] 11% | Training loss: 0.6880844476088038
Epoch: 37 | Iteration number: [540/4518] 11% | Training loss: 0.6880593666323909
Epoch: 37 | Iteration number: [550/4518] 12% | Training loss: 0.6880408706448294
Epoch: 37 | Iteration number: [560/4518] 12% | Training loss: 0.6879890764398234
Epoch: 37 | Iteration number: [570/4518] 12% | Training loss: 0.6879398946176496
Epoch: 37 | Iteration number: [580/4518] 12% | Training loss: 0.687906742712547
Epoch: 37 | Iteration number: [590/4518] 13% | Training loss: 0.6878728207895312
Epoch: 37 | Iteration number: [600/4518] 13% | Training loss: 0.6878427929679553
Epoch: 37 | Iteration number: [610/4518] 13% | Training loss: 0.6877998942234477
Epoch: 37 | Iteration number: [620/4518] 13% | Training loss: 0.6877881816317958
Epoch: 37 | Iteration number: [630/4518] 13% | Training loss: 0.6877636522527725
Epoch: 37 | Iteration number: [640/4518] 14% | Training loss: 0.6877588493749499
Epoch: 37 | Iteration number: [650/4518] 14% | Training loss: 0.6877531626591316
Epoch: 37 | Iteration number: [660/4518] 14% | Training loss: 0.6877365664099202
Epoch: 37 | Iteration number: [670/4518] 14% | Training loss: 0.68771202048259
Epoch: 37 | Iteration number: [680/4518] 15% | Training loss: 0.6876812628086876
Epoch: 37 | Iteration number: [690/4518] 15% | Training loss: 0.6876698837764021
Epoch: 37 | Iteration number: [700/4518] 15% | Training loss: 0.6876793528454644
Epoch: 37 | Iteration number: [710/4518] 15% | Training loss: 0.6876612560010292
Epoch: 37 | Iteration number: [720/4518] 15% | Training loss: 0.6876428949336211
Epoch: 37 | Iteration number: [730/4518] 16% | Training loss: 0.6876357574985452
Epoch: 37 | Iteration number: [740/4518] 16% | Training loss: 0.6876392247709068
Epoch: 37 | Iteration number: [750/4518] 16% | Training loss: 0.6876454006830851
Epoch: 37 | Iteration number: [760/4518] 16% | Training loss: 0.6876275940945275
Epoch: 37 | Iteration number: [770/4518] 17% | Training loss: 0.6876178465880357
Epoch: 37 | Iteration number: [780/4518] 17% | Training loss: 0.6875917161122347
Epoch: 37 | Iteration number: [790/4518] 17% | Training loss: 0.6876036288617532
Epoch: 37 | Iteration number: [800/4518] 17% | Training loss: 0.6875955829769373
Epoch: 37 | Iteration number: [810/4518] 17% | Training loss: 0.6875949103891114
Epoch: 37 | Iteration number: [820/4518] 18% | Training loss: 0.6875998838645656
Epoch: 37 | Iteration number: [830/4518] 18% | Training loss: 0.6875790500497243
Epoch: 37 | Iteration number: [840/4518] 18% | Training loss: 0.6875579721161298
Epoch: 37 | Iteration number: [850/4518] 18% | Training loss: 0.6875424474127152
Epoch: 37 | Iteration number: [860/4518] 19% | Training loss: 0.6875313741523166
Epoch: 37 | Iteration number: [870/4518] 19% | Training loss: 0.6875113017257602
Epoch: 37 | Iteration number: [880/4518] 19% | Training loss: 0.6875041826882146
Epoch: 37 | Iteration number: [890/4518] 19% | Training loss: 0.6874948277232352
Epoch: 37 | Iteration number: [900/4518] 19% | Training loss: 0.6874731836716333
Epoch: 37 | Iteration number: [910/4518] 20% | Training loss: 0.6874492059697161
Epoch: 37 | Iteration number: [920/4518] 20% | Training loss: 0.6874387162535087
Epoch: 37 | Iteration number: [930/4518] 20% | Training loss: 0.6874201684228836
Epoch: 37 | Iteration number: [940/4518] 20% | Training loss: 0.6874274587377589
Epoch: 37 | Iteration number: [950/4518] 21% | Training loss: 0.6874348683106272
Epoch: 37 | Iteration number: [960/4518] 21% | Training loss: 0.6874144482115905
Epoch: 37 | Iteration number: [970/4518] 21% | Training loss: 0.6874186660211111
Epoch: 37 | Iteration number: [980/4518] 21% | Training loss: 0.6874035395529805
Epoch: 37 | Iteration number: [990/4518] 21% | Training loss: 0.6873982851553445
Epoch: 37 | Iteration number: [1000/4518] 22% | Training loss: 0.6873982059955597
Epoch: 37 | Iteration number: [1010/4518] 22% | Training loss: 0.6874027891914444
Epoch: 37 | Iteration number: [1020/4518] 22% | Training loss: 0.6874080252998015
Epoch: 37 | Iteration number: [1030/4518] 22% | Training loss: 0.6874202028640266
Epoch: 37 | Iteration number: [1040/4518] 23% | Training loss: 0.6874069272898711
Epoch: 37 | Iteration number: [1050/4518] 23% | Training loss: 0.6873976248786563
Epoch: 37 | Iteration number: [1060/4518] 23% | Training loss: 0.6873796150931772
Epoch: 37 | Iteration number: [1070/4518] 23% | Training loss: 0.687378750616145
Epoch: 37 | Iteration number: [1080/4518] 23% | Training loss: 0.6873748076734719
Epoch: 37 | Iteration number: [1090/4518] 24% | Training loss: 0.6873599508486756
Epoch: 37 | Iteration number: [1100/4518] 24% | Training loss: 0.6873593281074004
Epoch: 37 | Iteration number: [1110/4518] 24% | Training loss: 0.687358977826866
Epoch: 37 | Iteration number: [1120/4518] 24% | Training loss: 0.6873619032225439
Epoch: 37 | Iteration number: [1130/4518] 25% | Training loss: 0.6873623070991145
Epoch: 37 | Iteration number: [1140/4518] 25% | Training loss: 0.6873546402705343
Epoch: 37 | Iteration number: [1150/4518] 25% | Training loss: 0.6873467202808546
Epoch: 37 | Iteration number: [1160/4518] 25% | Training loss: 0.687342797990503
Epoch: 37 | Iteration number: [1170/4518] 25% | Training loss: 0.68733010572246
Epoch: 37 | Iteration number: [1180/4518] 26% | Training loss: 0.6873221554998624
Epoch: 37 | Iteration number: [1190/4518] 26% | Training loss: 0.6873207177434649
Epoch: 37 | Iteration number: [1200/4518] 26% | Training loss: 0.6873202082018057
Epoch: 37 | Iteration number: [1210/4518] 26% | Training loss: 0.6873225834744036
Epoch: 37 | Iteration number: [1220/4518] 27% | Training loss: 0.6873106701940787
Epoch: 37 | Iteration number: [1230/4518] 27% | Training loss: 0.6873027980327606
Epoch: 37 | Iteration number: [1240/4518] 27% | Training loss: 0.6872787931753743
Epoch: 37 | Iteration number: [1250/4518] 27% | Training loss: 0.6872694033145904
Epoch: 37 | Iteration number: [1260/4518] 27% | Training loss: 0.6872656442816295
Epoch: 37 | Iteration number: [1270/4518] 28% | Training loss: 0.6872651067305737
Epoch: 37 | Iteration number: [1280/4518] 28% | Training loss: 0.6872690826654434
Epoch: 37 | Iteration number: [1290/4518] 28% | Training loss: 0.6872562825217727
Epoch: 37 | Iteration number: [1300/4518] 28% | Training loss: 0.6872530038998678
Epoch: 37 | Iteration number: [1310/4518] 28% | Training loss: 0.6872497205970851
Epoch: 37 | Iteration number: [1320/4518] 29% | Training loss: 0.6872450633030949
Epoch: 37 | Iteration number: [1330/4518] 29% | Training loss: 0.6872454003732007
Epoch: 37 | Iteration number: [1340/4518] 29% | Training loss: 0.6872431924983636
Epoch: 37 | Iteration number: [1350/4518] 29% | Training loss: 0.6872410639127096
Epoch: 37 | Iteration number: [1360/4518] 30% | Training loss: 0.6872358768301852
Epoch: 37 | Iteration number: [1370/4518] 30% | Training loss: 0.6872439179542291
Epoch: 37 | Iteration number: [1380/4518] 30% | Training loss: 0.68724597092124
Epoch: 37 | Iteration number: [1390/4518] 30% | Training loss: 0.6872406394361592
Epoch: 37 | Iteration number: [1400/4518] 30% | Training loss: 0.6872415738020624
Epoch: 37 | Iteration number: [1410/4518] 31% | Training loss: 0.6872359181972261
Epoch: 37 | Iteration number: [1420/4518] 31% | Training loss: 0.6872454607150924
Epoch: 37 | Iteration number: [1430/4518] 31% | Training loss: 0.6872424792576504
Epoch: 37 | Iteration number: [1440/4518] 31% | Training loss: 0.6872508650438653
Epoch: 37 | Iteration number: [1450/4518] 32% | Training loss: 0.6872429589567514
Epoch: 37 | Iteration number: [1460/4518] 32% | Training loss: 0.6872413421738638
Epoch: 37 | Iteration number: [1470/4518] 32% | Training loss: 0.6872358223207954
Epoch: 37 | Iteration number: [1480/4518] 32% | Training loss: 0.6872411633665497
Epoch: 37 | Iteration number: [1490/4518] 32% | Training loss: 0.6872351788834438
Epoch: 37 | Iteration number: [1500/4518] 33% | Training loss: 0.6872275178829829
Epoch: 37 | Iteration number: [1510/4518] 33% | Training loss: 0.6872279881641564
Epoch: 37 | Iteration number: [1520/4518] 33% | Training loss: 0.6872264311501854
Epoch: 37 | Iteration number: [1530/4518] 33% | Training loss: 0.6872246114646687
Epoch: 37 | Iteration number: [1540/4518] 34% | Training loss: 0.687221303891826
Epoch: 37 | Iteration number: [1550/4518] 34% | Training loss: 0.6872205928833254
Epoch: 37 | Iteration number: [1560/4518] 34% | Training loss: 0.6872194468210905
Epoch: 37 | Iteration number: [1570/4518] 34% | Training loss: 0.6872144233269296
Epoch: 37 | Iteration number: [1580/4518] 34% | Training loss: 0.6872029991844032
Epoch: 37 | Iteration number: [1590/4518] 35% | Training loss: 0.687198241326794
Epoch: 37 | Iteration number: [1600/4518] 35% | Training loss: 0.6871903775632382
Epoch: 37 | Iteration number: [1610/4518] 35% | Training loss: 0.6871982567058587
Epoch: 37 | Iteration number: [1620/4518] 35% | Training loss: 0.6871963304501992
Epoch: 37 | Iteration number: [1630/4518] 36% | Training loss: 0.6871992241385524
Epoch: 37 | Iteration number: [1640/4518] 36% | Training loss: 0.6871887588646354
Epoch: 37 | Iteration number: [1650/4518] 36% | Training loss: 0.6871944515271621
Epoch: 37 | Iteration number: [1660/4518] 36% | Training loss: 0.687194986120764
Epoch: 37 | Iteration number: [1670/4518] 36% | Training loss: 0.6871871189442937
Epoch: 37 | Iteration number: [1680/4518] 37% | Training loss: 0.6871782309597447
Epoch: 37 | Iteration number: [1690/4518] 37% | Training loss: 0.6871723814828862
Epoch: 37 | Iteration number: [1700/4518] 37% | Training loss: 0.6871682948224684
Epoch: 37 | Iteration number: [1710/4518] 37% | Training loss: 0.6871690329403906
Epoch: 37 | Iteration number: [1720/4518] 38% | Training loss: 0.6871654102622077
Epoch: 37 | Iteration number: [1730/4518] 38% | Training loss: 0.6871614505789873
Epoch: 37 | Iteration number: [1740/4518] 38% | Training loss: 0.6871566309325996
Epoch: 37 | Iteration number: [1750/4518] 38% | Training loss: 0.6871559697219304
Epoch: 37 | Iteration number: [1760/4518] 38% | Training loss: 0.6871614088727669
Epoch: 37 | Iteration number: [1770/4518] 39% | Training loss: 0.6871538199947379
Epoch: 37 | Iteration number: [1780/4518] 39% | Training loss: 0.6871438831425785
Epoch: 37 | Iteration number: [1790/4518] 39% | Training loss: 0.687141737058842
Epoch: 37 | Iteration number: [1800/4518] 39% | Training loss: 0.6871437333358659
Epoch: 37 | Iteration number: [1810/4518] 40% | Training loss: 0.6871316654906089
Epoch: 37 | Iteration number: [1820/4518] 40% | Training loss: 0.6871252856739275
Epoch: 37 | Iteration number: [1830/4518] 40% | Training loss: 0.6871315805638423
Epoch: 37 | Iteration number: [1840/4518] 40% | Training loss: 0.6871300684045191
Epoch: 37 | Iteration number: [1850/4518] 40% | Training loss: 0.6871281451147956
Epoch: 37 | Iteration number: [1860/4518] 41% | Training loss: 0.6871194422885936
Epoch: 37 | Iteration number: [1870/4518] 41% | Training loss: 0.6871201785171733
Epoch: 37 | Iteration number: [1880/4518] 41% | Training loss: 0.687122723967471
Epoch: 37 | Iteration number: [1890/4518] 41% | Training loss: 0.6871227439118441
Epoch: 37 | Iteration number: [1900/4518] 42% | Training loss: 0.6871194315584083
Epoch: 37 | Iteration number: [1910/4518] 42% | Training loss: 0.6871158220381013
Epoch: 37 | Iteration number: [1920/4518] 42% | Training loss: 0.6871163789493342
Epoch: 37 | Iteration number: [1930/4518] 42% | Training loss: 0.6871193101677869
Epoch: 37 | Iteration number: [1940/4518] 42% | Training loss: 0.6871103563259557
Epoch: 37 | Iteration number: [1950/4518] 43% | Training loss: 0.6871049383053413
Epoch: 37 | Iteration number: [1960/4518] 43% | Training loss: 0.6870982804772805
Epoch: 37 | Iteration number: [1970/4518] 43% | Training loss: 0.6871043785877035
Epoch: 37 | Iteration number: [1980/4518] 43% | Training loss: 0.6871006679354292
Epoch: 37 | Iteration number: [1990/4518] 44% | Training loss: 0.6870995434384849
Epoch: 37 | Iteration number: [2000/4518] 44% | Training loss: 0.6870967567265034
Epoch: 37 | Iteration number: [2010/4518] 44% | Training loss: 0.6871020206171482
Epoch: 37 | Iteration number: [2020/4518] 44% | Training loss: 0.6871010552833576
Epoch: 37 | Iteration number: [2030/4518] 44% | Training loss: 0.6871063378937726
Epoch: 37 | Iteration number: [2040/4518] 45% | Training loss: 0.6871063871710908
Epoch: 37 | Iteration number: [2050/4518] 45% | Training loss: 0.6871067652469728
Epoch: 37 | Iteration number: [2060/4518] 45% | Training loss: 0.6871068602626763
Epoch: 37 | Iteration number: [2070/4518] 45% | Training loss: 0.6871054400856368
Epoch: 37 | Iteration number: [2080/4518] 46% | Training loss: 0.6871051990355437
Epoch: 37 | Iteration number: [2090/4518] 46% | Training loss: 0.6870973838573438
Epoch: 37 | Iteration number: [2100/4518] 46% | Training loss: 0.6870936862911496
Epoch: 37 | Iteration number: [2110/4518] 46% | Training loss: 0.6870842084500461
Epoch: 37 | Iteration number: [2120/4518] 46% | Training loss: 0.6870825801817876
Epoch: 37 | Iteration number: [2130/4518] 47% | Training loss: 0.6870868825576675
Epoch: 37 | Iteration number: [2140/4518] 47% | Training loss: 0.687088346731997
Epoch: 37 | Iteration number: [2150/4518] 47% | Training loss: 0.6870863149055215
Epoch: 37 | Iteration number: [2160/4518] 47% | Training loss: 0.6870855250844249
Epoch: 37 | Iteration number: [2170/4518] 48% | Training loss: 0.6870824762478402
Epoch: 37 | Iteration number: [2180/4518] 48% | Training loss: 0.6870835321212033
Epoch: 37 | Iteration number: [2190/4518] 48% | Training loss: 0.6870904971475471
Epoch: 37 | Iteration number: [2200/4518] 48% | Training loss: 0.6870913410186767
Epoch: 37 | Iteration number: [2210/4518] 48% | Training loss: 0.6870926665774298
Epoch: 37 | Iteration number: [2220/4518] 49% | Training loss: 0.6870948263385275
Epoch: 37 | Iteration number: [2230/4518] 49% | Training loss: 0.6870911818983308
Epoch: 37 | Iteration number: [2240/4518] 49% | Training loss: 0.6870929900556803
Epoch: 37 | Iteration number: [2250/4518] 49% | Training loss: 0.6870915937953526
Epoch: 37 | Iteration number: [2260/4518] 50% | Training loss: 0.6870932097192359
Epoch: 37 | Iteration number: [2270/4518] 50% | Training loss: 0.6870919784260217
Epoch: 37 | Iteration number: [2280/4518] 50% | Training loss: 0.6870936065389399
Epoch: 37 | Iteration number: [2290/4518] 50% | Training loss: 0.687092420263582
Epoch: 37 | Iteration number: [2300/4518] 50% | Training loss: 0.6870901302151058
Epoch: 37 | Iteration number: [2310/4518] 51% | Training loss: 0.6870876924300091
Epoch: 37 | Iteration number: [2320/4518] 51% | Training loss: 0.6870867911597778
Epoch: 37 | Iteration number: [2330/4518] 51% | Training loss: 0.6870905386020185
Epoch: 37 | Iteration number: [2340/4518] 51% | Training loss: 0.6870848818976655
Epoch: 37 | Iteration number: [2350/4518] 52% | Training loss: 0.6870766396725432
Epoch: 37 | Iteration number: [2360/4518] 52% | Training loss: 0.6870775930457196
Epoch: 37 | Iteration number: [2370/4518] 52% | Training loss: 0.6870776578595367
Epoch: 37 | Iteration number: [2380/4518] 52% | Training loss: 0.6870752497630961
Epoch: 37 | Iteration number: [2390/4518] 52% | Training loss: 0.6870771971457175
Epoch: 37 | Iteration number: [2400/4518] 53% | Training loss: 0.687075366700689
Epoch: 37 | Iteration number: [2410/4518] 53% | Training loss: 0.6870726088517929
Epoch: 37 | Iteration number: [2420/4518] 53% | Training loss: 0.6870711686689992
Epoch: 37 | Iteration number: [2430/4518] 53% | Training loss: 0.6870726741881037
Epoch: 37 | Iteration number: [2440/4518] 54% | Training loss: 0.6870760463300298
Epoch: 37 | Iteration number: [2450/4518] 54% | Training loss: 0.6870774468110532
Epoch: 37 | Iteration number: [2460/4518] 54% | Training loss: 0.6870783007241846
Epoch: 37 | Iteration number: [2470/4518] 54% | Training loss: 0.6870748944369405
Epoch: 37 | Iteration number: [2480/4518] 54% | Training loss: 0.6870740214182485
Epoch: 37 | Iteration number: [2490/4518] 55% | Training loss: 0.6870741394868337
Epoch: 37 | Iteration number: [2500/4518] 55% | Training loss: 0.6870748926639557
Epoch: 37 | Iteration number: [2510/4518] 55% | Training loss: 0.687073231883258
Epoch: 37 | Iteration number: [2520/4518] 55% | Training loss: 0.6870730668306351
Epoch: 37 | Iteration number: [2530/4518] 55% | Training loss: 0.6870720237140128
Epoch: 37 | Iteration number: [2540/4518] 56% | Training loss: 0.6870729414027507
Epoch: 37 | Iteration number: [2550/4518] 56% | Training loss: 0.6870755566335192
Epoch: 37 | Iteration number: [2560/4518] 56% | Training loss: 0.6870706765446812
Epoch: 37 | Iteration number: [2570/4518] 56% | Training loss: 0.6870700733439004
Epoch: 37 | Iteration number: [2580/4518] 57% | Training loss: 0.6870668621257294
Epoch: 37 | Iteration number: [2590/4518] 57% | Training loss: 0.6870652513384359
Epoch: 37 | Iteration number: [2600/4518] 57% | Training loss: 0.6870679490382855
Epoch: 37 | Iteration number: [2610/4518] 57% | Training loss: 0.6870666144223049
Epoch: 37 | Iteration number: [2620/4518] 57% | Training loss: 0.6870698272499419
Epoch: 37 | Iteration number: [2630/4518] 58% | Training loss: 0.6870672995373324
Epoch: 37 | Iteration number: [2640/4518] 58% | Training loss: 0.6870656165887009
Epoch: 37 | Iteration number: [2650/4518] 58% | Training loss: 0.6870660768814807
Epoch: 37 | Iteration number: [2660/4518] 58% | Training loss: 0.6870658239475766
Epoch: 37 | Iteration number: [2670/4518] 59% | Training loss: 0.6870620138189766
Epoch: 37 | Iteration number: [2680/4518] 59% | Training loss: 0.6870634966377002
Epoch: 37 | Iteration number: [2690/4518] 59% | Training loss: 0.6870649054591097
Epoch: 37 | Iteration number: [2700/4518] 59% | Training loss: 0.6870645272731781
Epoch: 37 | Iteration number: [2710/4518] 59% | Training loss: 0.6870664915475458
Epoch: 37 | Iteration number: [2720/4518] 60% | Training loss: 0.687062333239352
Epoch: 37 | Iteration number: [2730/4518] 60% | Training loss: 0.687063354908765
Epoch: 37 | Iteration number: [2740/4518] 60% | Training loss: 0.6870630819867127
Epoch: 37 | Iteration number: [2750/4518] 60% | Training loss: 0.6870610553351315
Epoch: 37 | Iteration number: [2760/4518] 61% | Training loss: 0.6870607925282008
Epoch: 37 | Iteration number: [2770/4518] 61% | Training loss: 0.6870570716875124
Epoch: 37 | Iteration number: [2780/4518] 61% | Training loss: 0.6870588286960725
Epoch: 37 | Iteration number: [2790/4518] 61% | Training loss: 0.687059953904921
Epoch: 37 | Iteration number: [2800/4518] 61% | Training loss: 0.6870580403719629
Epoch: 37 | Iteration number: [2810/4518] 62% | Training loss: 0.6870580950877845
Epoch: 37 | Iteration number: [2820/4518] 62% | Training loss: 0.6870596297032444
Epoch: 37 | Iteration number: [2830/4518] 62% | Training loss: 0.6870592494314214
Epoch: 37 | Iteration number: [2840/4518] 62% | Training loss: 0.6870613279267096
Epoch: 37 | Iteration number: [2850/4518] 63% | Training loss: 0.6870614983324419
Epoch: 37 | Iteration number: [2860/4518] 63% | Training loss: 0.6870582629750659
Epoch: 37 | Iteration number: [2870/4518] 63% | Training loss: 0.6870590628647223
Epoch: 37 | Iteration number: [2880/4518] 63% | Training loss: 0.6870582993866668
Epoch: 37 | Iteration number: [2890/4518] 63% | Training loss: 0.68705492867318
Epoch: 37 | Iteration number: [2900/4518] 64% | Training loss: 0.6870563547364597
Epoch: 37 | Iteration number: [2910/4518] 64% | Training loss: 0.6870599124234976
Epoch: 37 | Iteration number: [2920/4518] 64% | Training loss: 0.6870584424636136
Epoch: 37 | Iteration number: [2930/4518] 64% | Training loss: 0.6870573789389874
Epoch: 37 | Iteration number: [2940/4518] 65% | Training loss: 0.6870505720579705
Epoch: 37 | Iteration number: [2950/4518] 65% | Training loss: 0.6870499436936136
Epoch: 37 | Iteration number: [2960/4518] 65% | Training loss: 0.6870494700766898
Epoch: 37 | Iteration number: [2970/4518] 65% | Training loss: 0.687053359397734
Epoch: 37 | Iteration number: [2980/4518] 65% | Training loss: 0.6870518570178307
Epoch: 37 | Iteration number: [2990/4518] 66% | Training loss: 0.6870517824605157
Epoch: 37 | Iteration number: [3000/4518] 66% | Training loss: 0.6870515367388725
Epoch: 37 | Iteration number: [3010/4518] 66% | Training loss: 0.6870474037537939
Epoch: 37 | Iteration number: [3020/4518] 66% | Training loss: 0.6870458034884851
Epoch: 37 | Iteration number: [3030/4518] 67% | Training loss: 0.6870477705111991
Epoch: 37 | Iteration number: [3040/4518] 67% | Training loss: 0.687044799641559
Epoch: 37 | Iteration number: [3050/4518] 67% | Training loss: 0.687046058138863
Epoch: 37 | Iteration number: [3060/4518] 67% | Training loss: 0.6870469762998469
Epoch: 37 | Iteration number: [3070/4518] 67% | Training loss: 0.6870448787942383
Epoch: 37 | Iteration number: [3080/4518] 68% | Training loss: 0.6870428141641927
Epoch: 37 | Iteration number: [3090/4518] 68% | Training loss: 0.6870408876428327
Epoch: 37 | Iteration number: [3100/4518] 68% | Training loss: 0.6870398885011673
Epoch: 37 | Iteration number: [3110/4518] 68% | Training loss: 0.6870412497275129
Epoch: 37 | Iteration number: [3120/4518] 69% | Training loss: 0.6870376003285249
Epoch: 37 | Iteration number: [3130/4518] 69% | Training loss: 0.6870374012488527
Epoch: 37 | Iteration number: [3140/4518] 69% | Training loss: 0.687036243707511
Epoch: 37 | Iteration number: [3150/4518] 69% | Training loss: 0.6870359197306255
Epoch: 37 | Iteration number: [3160/4518] 69% | Training loss: 0.6870374295907684
Epoch: 37 | Iteration number: [3170/4518] 70% | Training loss: 0.6870406377578759
Epoch: 37 | Iteration number: [3180/4518] 70% | Training loss: 0.6870386683153656
Epoch: 37 | Iteration number: [3190/4518] 70% | Training loss: 0.6870394770815081
Epoch: 37 | Iteration number: [3200/4518] 70% | Training loss: 0.6870405622757971
Epoch: 37 | Iteration number: [3210/4518] 71% | Training loss: 0.6870395943197506
Epoch: 37 | Iteration number: [3220/4518] 71% | Training loss: 0.6870368643762162
Epoch: 37 | Iteration number: [3230/4518] 71% | Training loss: 0.6870326939566586
Epoch: 37 | Iteration number: [3240/4518] 71% | Training loss: 0.6870347342189448
Epoch: 37 | Iteration number: [3250/4518] 71% | Training loss: 0.6870300940733689
Epoch: 37 | Iteration number: [3260/4518] 72% | Training loss: 0.687028774491117
Epoch: 37 | Iteration number: [3270/4518] 72% | Training loss: 0.6870274635083085
Epoch: 37 | Iteration number: [3280/4518] 72% | Training loss: 0.6870289260294379
Epoch: 37 | Iteration number: [3290/4518] 72% | Training loss: 0.6870340306526984
Epoch: 37 | Iteration number: [3300/4518] 73% | Training loss: 0.6870315506783399
Epoch: 37 | Iteration number: [3310/4518] 73% | Training loss: 0.687033030147639
Epoch: 37 | Iteration number: [3320/4518] 73% | Training loss: 0.6870341987494962
Epoch: 37 | Iteration number: [3330/4518] 73% | Training loss: 0.6870318835383062
Epoch: 37 | Iteration number: [3340/4518] 73% | Training loss: 0.687032676224937
Epoch: 37 | Iteration number: [3350/4518] 74% | Training loss: 0.6870315342696744
Epoch: 37 | Iteration number: [3360/4518] 74% | Training loss: 0.6870300153004272
Epoch: 37 | Iteration number: [3370/4518] 74% | Training loss: 0.6870296927340307
Epoch: 37 | Iteration number: [3380/4518] 74% | Training loss: 0.6870292034727582
Epoch: 37 | Iteration number: [3390/4518] 75% | Training loss: 0.6870292645288428
Epoch: 37 | Iteration number: [3400/4518] 75% | Training loss: 0.6870239422952428
Epoch: 37 | Iteration number: [3410/4518] 75% | Training loss: 0.6870238346088666
Epoch: 37 | Iteration number: [3420/4518] 75% | Training loss: 0.6870215111308627
Epoch: 37 | Iteration number: [3430/4518] 75% | Training loss: 0.6870189261158424
Epoch: 37 | Iteration number: [3440/4518] 76% | Training loss: 0.6870176147929458
Epoch: 37 | Iteration number: [3450/4518] 76% | Training loss: 0.6870183097797892
Epoch: 37 | Iteration number: [3460/4518] 76% | Training loss: 0.6870162493403936
Epoch: 37 | Iteration number: [3470/4518] 76% | Training loss: 0.687016541779213
Epoch: 37 | Iteration number: [3480/4518] 77% | Training loss: 0.6870149893664765
Epoch: 37 | Iteration number: [3490/4518] 77% | Training loss: 0.6870134466357081
Epoch: 37 | Iteration number: [3500/4518] 77% | Training loss: 0.6870126858949661
Epoch: 37 | Iteration number: [3510/4518] 77% | Training loss: 0.6870146178112411
Epoch: 37 | Iteration number: [3520/4518] 77% | Training loss: 0.687012889253145
Epoch: 37 | Iteration number: [3530/4518] 78% | Training loss: 0.6870098669704567
Epoch: 37 | Iteration number: [3540/4518] 78% | Training loss: 0.6870105128840538
Epoch: 37 | Iteration number: [3550/4518] 78% | Training loss: 0.6870083984019051
Epoch: 37 | Iteration number: [3560/4518] 78% | Training loss: 0.6870076431317276
Epoch: 37 | Iteration number: [3570/4518] 79% | Training loss: 0.6870054647869088
Epoch: 37 | Iteration number: [3580/4518] 79% | Training loss: 0.6870027144361475
Epoch: 37 | Iteration number: [3590/4518] 79% | Training loss: 0.6870017206104353
Epoch: 37 | Iteration number: [3600/4518] 79% | Training loss: 0.6870036642418967
Epoch: 37 | Iteration number: [3610/4518] 79% | Training loss: 0.6870035104969532
Epoch: 37 | Iteration number: [3620/4518] 80% | Training loss: 0.6869997347751375
Epoch: 37 | Iteration number: [3630/4518] 80% | Training loss: 0.687001636353406
Epoch: 37 | Iteration number: [3640/4518] 80% | Training loss: 0.68699929694553
Epoch: 37 | Iteration number: [3650/4518] 80% | Training loss: 0.6870017356741919
Epoch: 37 | Iteration number: [3660/4518] 81% | Training loss: 0.6869988727276443
Epoch: 37 | Iteration number: [3670/4518] 81% | Training loss: 0.6869970562997241
Epoch: 37 | Iteration number: [3680/4518] 81% | Training loss: 0.6869963876255181
Epoch: 37 | Iteration number: [3690/4518] 81% | Training loss: 0.6869953490046627
Epoch: 37 | Iteration number: [3700/4518] 81% | Training loss: 0.6869957972700531
Epoch: 37 | Iteration number: [3710/4518] 82% | Training loss: 0.6869906689439501
Epoch: 37 | Iteration number: [3720/4518] 82% | Training loss: 0.6869894562709716
Epoch: 37 | Iteration number: [3730/4518] 82% | Training loss: 0.6869861330966848
Epoch: 37 | Iteration number: [3740/4518] 82% | Training loss: 0.6869846365827927
Epoch: 37 | Iteration number: [3750/4518] 83% | Training loss: 0.6869854385534923
Epoch: 37 | Iteration number: [3760/4518] 83% | Training loss: 0.6869850602080213
Epoch: 37 | Iteration number: [3770/4518] 83% | Training loss: 0.6869838970725669
Epoch: 37 | Iteration number: [3780/4518] 83% | Training loss: 0.6869830603322024
Epoch: 37 | Iteration number: [3790/4518] 83% | Training loss: 0.6869834584736887
Epoch: 37 | Iteration number: [3800/4518] 84% | Training loss: 0.6869797214551976
Epoch: 37 | Iteration number: [3810/4518] 84% | Training loss: 0.6869811841039832
Epoch: 37 | Iteration number: [3820/4518] 84% | Training loss: 0.6869756473920732
Epoch: 37 | Iteration number: [3830/4518] 84% | Training loss: 0.6869723660049488
Epoch: 37 | Iteration number: [3840/4518] 84% | Training loss: 0.6869734075851739
Epoch: 37 | Iteration number: [3850/4518] 85% | Training loss: 0.6869692267535569
Epoch: 37 | Iteration number: [3860/4518] 85% | Training loss: 0.6869678494534962
Epoch: 37 | Iteration number: [3870/4518] 85% | Training loss: 0.6869722020872495
Epoch: 37 | Iteration number: [3880/4518] 85% | Training loss: 0.6869756225765365
Epoch: 37 | Iteration number: [3890/4518] 86% | Training loss: 0.6869781736543062
Epoch: 37 | Iteration number: [3900/4518] 86% | Training loss: 0.6869818491507799
Epoch: 37 | Iteration number: [3910/4518] 86% | Training loss: 0.6869806184793067
Epoch: 37 | Iteration number: [3920/4518] 86% | Training loss: 0.6869853616216961
Epoch: 37 | Iteration number: [3930/4518] 86% | Training loss: 0.686986811986103
Epoch: 37 | Iteration number: [3940/4518] 87% | Training loss: 0.6869858318325227
Epoch: 37 | Iteration number: [3950/4518] 87% | Training loss: 0.6869833193851422
Epoch: 37 | Iteration number: [3960/4518] 87% | Training loss: 0.6869868269171377
Epoch: 37 | Iteration number: [3970/4518] 87% | Training loss: 0.6869878189239453
Epoch: 37 | Iteration number: [3980/4518] 88% | Training loss: 0.6869869538587542
Epoch: 37 | Iteration number: [3990/4518] 88% | Training loss: 0.6869874343537448
Epoch: 37 | Iteration number: [4000/4518] 88% | Training loss: 0.6869887421876192
Epoch: 37 | Iteration number: [4010/4518] 88% | Training loss: 0.6869897909443872
Epoch: 37 | Iteration number: [4020/4518] 88% | Training loss: 0.6869855267343237
Epoch: 37 | Iteration number: [4030/4518] 89% | Training loss: 0.6869877719997473
Epoch: 37 | Iteration number: [4040/4518] 89% | Training loss: 0.6869898795343862
Epoch: 37 | Iteration number: [4050/4518] 89% | Training loss: 0.6869917673534817
Epoch: 37 | Iteration number: [4060/4518] 89% | Training loss: 0.68699317418883
Epoch: 37 | Iteration number: [4070/4518] 90% | Training loss: 0.6869935930361033
Epoch: 37 | Iteration number: [4080/4518] 90% | Training loss: 0.6869949177199719
Epoch: 37 | Iteration number: [4090/4518] 90% | Training loss: 0.6869939513194824
Epoch: 37 | Iteration number: [4100/4518] 90% | Training loss: 0.6869946712255478
Epoch: 37 | Iteration number: [4110/4518] 90% | Training loss: 0.6869943300302881
Epoch: 37 | Iteration number: [4120/4518] 91% | Training loss: 0.6869950570238447
Epoch: 37 | Iteration number: [4130/4518] 91% | Training loss: 0.6869967272437514
Epoch: 37 | Iteration number: [4140/4518] 91% | Training loss: 0.6869937735479235
Epoch: 37 | Iteration number: [4150/4518] 91% | Training loss: 0.6869946811141738
Epoch: 37 | Iteration number: [4160/4518] 92% | Training loss: 0.6869958778270162
Epoch: 37 | Iteration number: [4170/4518] 92% | Training loss: 0.6869963486131718
Epoch: 37 | Iteration number: [4180/4518] 92% | Training loss: 0.6869986835278963
Epoch: 37 | Iteration number: [4190/4518] 92% | Training loss: 0.6869964140980795
Epoch: 37 | Iteration number: [4200/4518] 92% | Training loss: 0.6869993831855911
Epoch: 37 | Iteration number: [4210/4518] 93% | Training loss: 0.6869985255804311
Epoch: 37 | Iteration number: [4220/4518] 93% | Training loss: 0.6869994234558531
Epoch: 37 | Iteration number: [4230/4518] 93% | Training loss: 0.6869985817031093
Epoch: 37 | Iteration number: [4240/4518] 93% | Training loss: 0.6870003953154357
Epoch: 37 | Iteration number: [4250/4518] 94% | Training loss: 0.6870005994263817
Epoch: 37 | Iteration number: [4260/4518] 94% | Training loss: 0.6870034865090545
Epoch: 37 | Iteration number: [4270/4518] 94% | Training loss: 0.6870031032405916
Epoch: 37 | Iteration number: [4280/4518] 94% | Training loss: 0.68700214794306
Epoch: 37 | Iteration number: [4290/4518] 94% | Training loss: 0.6870011987108173
Epoch: 37 | Iteration number: [4300/4518] 95% | Training loss: 0.6870005538158639
Epoch: 37 | Iteration number: [4310/4518] 95% | Training loss: 0.6870004196731231
Epoch: 37 | Iteration number: [4320/4518] 95% | Training loss: 0.6869980676996487
Epoch: 37 | Iteration number: [4330/4518] 95% | Training loss: 0.6869973526678239
Epoch: 37 | Iteration number: [4340/4518] 96% | Training loss: 0.6869966108540786
Epoch: 37 | Iteration number: [4350/4518] 96% | Training loss: 0.6870002539678551
Epoch: 37 | Iteration number: [4360/4518] 96% | Training loss: 0.6869974862544909
Epoch: 37 | Iteration number: [4370/4518] 96% | Training loss: 0.6869959939399082
Epoch: 37 | Iteration number: [4380/4518] 96% | Training loss: 0.6869980847726674
Epoch: 37 | Iteration number: [4390/4518] 97% | Training loss: 0.6869994775309378
Epoch: 37 | Iteration number: [4400/4518] 97% | Training loss: 0.6869996099038558
Epoch: 37 | Iteration number: [4410/4518] 97% | Training loss: 0.6869974863231858
Epoch: 37 | Iteration number: [4420/4518] 97% | Training loss: 0.686995403380955
Epoch: 37 | Iteration number: [4430/4518] 98% | Training loss: 0.6869954234455832
Epoch: 37 | Iteration number: [4440/4518] 98% | Training loss: 0.6869941166123829
Epoch: 37 | Iteration number: [4450/4518] 98% | Training loss: 0.6869928167911058
Epoch: 37 | Iteration number: [4460/4518] 98% | Training loss: 0.6869912903806019
Epoch: 37 | Iteration number: [4470/4518] 98% | Training loss: 0.6869927907950126
Epoch: 37 | Iteration number: [4480/4518] 99% | Training loss: 0.6869937232562474
Epoch: 37 | Iteration number: [4490/4518] 99% | Training loss: 0.6869932481998324
Epoch: 37 | Iteration number: [4500/4518] 99% | Training loss: 0.6869908429384232
Epoch: 37 | Iteration number: [4510/4518] 99% | Training loss: 0.6869921487477296

 End of epoch: 37 | Train Loss: 0.6868411396498594 | Training Time: 643 

 End of epoch: 37 | Eval Loss: 0.6902021631902578 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/4518] 0% | Training loss: 0.7548696577548981
Epoch: 38 | Iteration number: [20/4518] 0% | Training loss: 0.7206946343183518
Epoch: 38 | Iteration number: [30/4518] 0% | Training loss: 0.7096868952115377
Epoch: 38 | Iteration number: [40/4518] 0% | Training loss: 0.7039047077298164
Epoch: 38 | Iteration number: [50/4518] 1% | Training loss: 0.7006481969356537
Epoch: 38 | Iteration number: [60/4518] 1% | Training loss: 0.6981989711523056
Epoch: 38 | Iteration number: [70/4518] 1% | Training loss: 0.6964731769902366
Epoch: 38 | Iteration number: [80/4518] 1% | Training loss: 0.6952511683106423
Epoch: 38 | Iteration number: [90/4518] 1% | Training loss: 0.6941584037409888
Epoch: 38 | Iteration number: [100/4518] 2% | Training loss: 0.6934418016672135
Epoch: 38 | Iteration number: [110/4518] 2% | Training loss: 0.6928513429381631
Epoch: 38 | Iteration number: [120/4518] 2% | Training loss: 0.6923638244469961
Epoch: 38 | Iteration number: [130/4518] 2% | Training loss: 0.6920048351471241
Epoch: 38 | Iteration number: [140/4518] 3% | Training loss: 0.6915713893515724
Epoch: 38 | Iteration number: [150/4518] 3% | Training loss: 0.6912998223304748
Epoch: 38 | Iteration number: [160/4518] 3% | Training loss: 0.691035945340991
Epoch: 38 | Iteration number: [170/4518] 3% | Training loss: 0.6908171043676489
Epoch: 38 | Iteration number: [180/4518] 3% | Training loss: 0.6905640893512301
Epoch: 38 | Iteration number: [190/4518] 4% | Training loss: 0.6903105538142355
Epoch: 38 | Iteration number: [200/4518] 4% | Training loss: 0.6901547110080719
Epoch: 38 | Iteration number: [210/4518] 4% | Training loss: 0.6900179698353722
Epoch: 38 | Iteration number: [220/4518] 4% | Training loss: 0.6898775853893974
Epoch: 38 | Iteration number: [230/4518] 5% | Training loss: 0.6898083847502003
Epoch: 38 | Iteration number: [240/4518] 5% | Training loss: 0.6897132009267807
Epoch: 38 | Iteration number: [250/4518] 5% | Training loss: 0.6895871632099152
Epoch: 38 | Iteration number: [260/4518] 5% | Training loss: 0.6894884141591879
Epoch: 38 | Iteration number: [270/4518] 5% | Training loss: 0.6893518816541743
Epoch: 38 | Iteration number: [280/4518] 6% | Training loss: 0.6892627699034555
Epoch: 38 | Iteration number: [290/4518] 6% | Training loss: 0.6891846116246848
Epoch: 38 | Iteration number: [300/4518] 6% | Training loss: 0.6891133517026902
Epoch: 38 | Iteration number: [310/4518] 6% | Training loss: 0.6890560248205738
Epoch: 38 | Iteration number: [320/4518] 7% | Training loss: 0.6889685619622469
Epoch: 38 | Iteration number: [330/4518] 7% | Training loss: 0.6888933790452553
Epoch: 38 | Iteration number: [340/4518] 7% | Training loss: 0.6888127789777868
Epoch: 38 | Iteration number: [350/4518] 7% | Training loss: 0.6887794571263449
Epoch: 38 | Iteration number: [360/4518] 7% | Training loss: 0.6887585797243648
Epoch: 38 | Iteration number: [370/4518] 8% | Training loss: 0.6886853780295398
Epoch: 38 | Iteration number: [380/4518] 8% | Training loss: 0.6886717399484232
Epoch: 38 | Iteration number: [390/4518] 8% | Training loss: 0.6886536992513217
Epoch: 38 | Iteration number: [400/4518] 8% | Training loss: 0.6886285528540611
Epoch: 38 | Iteration number: [410/4518] 9% | Training loss: 0.6885657848381415
Epoch: 38 | Iteration number: [420/4518] 9% | Training loss: 0.6885173999127887
Epoch: 38 | Iteration number: [430/4518] 9% | Training loss: 0.688466087191604
Epoch: 38 | Iteration number: [440/4518] 9% | Training loss: 0.6884319921786135
Epoch: 38 | Iteration number: [450/4518] 9% | Training loss: 0.6883774047427708
Epoch: 38 | Iteration number: [460/4518] 10% | Training loss: 0.6883549263943797
Epoch: 38 | Iteration number: [470/4518] 10% | Training loss: 0.6883081012583794
Epoch: 38 | Iteration number: [480/4518] 10% | Training loss: 0.6882402713100115
Epoch: 38 | Iteration number: [490/4518] 10% | Training loss: 0.6881959712018773
Epoch: 38 | Iteration number: [500/4518] 11% | Training loss: 0.6881773685216903
Epoch: 38 | Iteration number: [510/4518] 11% | Training loss: 0.6881257813350827
Epoch: 38 | Iteration number: [520/4518] 11% | Training loss: 0.688100463610429
Epoch: 38 | Iteration number: [530/4518] 11% | Training loss: 0.6880736182320792
Epoch: 38 | Iteration number: [540/4518] 11% | Training loss: 0.688054586119122
Epoch: 38 | Iteration number: [550/4518] 12% | Training loss: 0.6880405859513716
Epoch: 38 | Iteration number: [560/4518] 12% | Training loss: 0.6880101699914251
Epoch: 38 | Iteration number: [570/4518] 12% | Training loss: 0.6879819445442735
Epoch: 38 | Iteration number: [580/4518] 12% | Training loss: 0.6879525228820998
Epoch: 38 | Iteration number: [590/4518] 13% | Training loss: 0.6878887581623206
Epoch: 38 | Iteration number: [600/4518] 13% | Training loss: 0.68785571316878
Epoch: 38 | Iteration number: [610/4518] 13% | Training loss: 0.6878301436783838
Epoch: 38 | Iteration number: [620/4518] 13% | Training loss: 0.6878028310114338
Epoch: 38 | Iteration number: [630/4518] 13% | Training loss: 0.6877826620662023
Epoch: 38 | Iteration number: [640/4518] 14% | Training loss: 0.6877664148807525
Epoch: 38 | Iteration number: [650/4518] 14% | Training loss: 0.6877449720639449
Epoch: 38 | Iteration number: [660/4518] 14% | Training loss: 0.6877389850038471
Epoch: 38 | Iteration number: [670/4518] 14% | Training loss: 0.6877122814975568
Epoch: 38 | Iteration number: [680/4518] 15% | Training loss: 0.6876835865132949
Epoch: 38 | Iteration number: [690/4518] 15% | Training loss: 0.6876817730889804
Epoch: 38 | Iteration number: [700/4518] 15% | Training loss: 0.6876745667627879
Epoch: 38 | Iteration number: [710/4518] 15% | Training loss: 0.6876777465074835
Epoch: 38 | Iteration number: [720/4518] 15% | Training loss: 0.6876757089462545
Epoch: 38 | Iteration number: [730/4518] 16% | Training loss: 0.6876495416033758
Epoch: 38 | Iteration number: [740/4518] 16% | Training loss: 0.6876362728106009
Epoch: 38 | Iteration number: [750/4518] 16% | Training loss: 0.6876270453929901
Epoch: 38 | Iteration number: [760/4518] 16% | Training loss: 0.6876276855406008
Epoch: 38 | Iteration number: [770/4518] 17% | Training loss: 0.6876308000707007
Epoch: 38 | Iteration number: [780/4518] 17% | Training loss: 0.6876237464256776
Epoch: 38 | Iteration number: [790/4518] 17% | Training loss: 0.6876054735123357
Epoch: 38 | Iteration number: [800/4518] 17% | Training loss: 0.6875837830454111
Epoch: 38 | Iteration number: [810/4518] 17% | Training loss: 0.6875883354816907
Epoch: 38 | Iteration number: [820/4518] 18% | Training loss: 0.68759486595305
Epoch: 38 | Iteration number: [830/4518] 18% | Training loss: 0.6875782063208431
Epoch: 38 | Iteration number: [840/4518] 18% | Training loss: 0.6875824207351321
Epoch: 38 | Iteration number: [850/4518] 18% | Training loss: 0.6875829105517444
Epoch: 38 | Iteration number: [860/4518] 19% | Training loss: 0.6875798246888227
Epoch: 38 | Iteration number: [870/4518] 19% | Training loss: 0.6875774667865928
Epoch: 38 | Iteration number: [880/4518] 19% | Training loss: 0.6875820065086539
Epoch: 38 | Iteration number: [890/4518] 19% | Training loss: 0.6875568032934425
Epoch: 38 | Iteration number: [900/4518] 19% | Training loss: 0.6875489477978812
Epoch: 38 | Iteration number: [910/4518] 20% | Training loss: 0.6875368208020598
Epoch: 38 | Iteration number: [920/4518] 20% | Training loss: 0.6875376633975817
Epoch: 38 | Iteration number: [930/4518] 20% | Training loss: 0.6875355234710119
Epoch: 38 | Iteration number: [940/4518] 20% | Training loss: 0.687526847580646
Epoch: 38 | Iteration number: [950/4518] 21% | Training loss: 0.6875214677735378
Epoch: 38 | Iteration number: [960/4518] 21% | Training loss: 0.6875067384292682
Epoch: 38 | Iteration number: [970/4518] 21% | Training loss: 0.6875085645115253
Epoch: 38 | Iteration number: [980/4518] 21% | Training loss: 0.6875075154158534
Epoch: 38 | Iteration number: [990/4518] 21% | Training loss: 0.6875053624312083
Epoch: 38 | Iteration number: [1000/4518] 22% | Training loss: 0.6875001949071884
Epoch: 38 | Iteration number: [1010/4518] 22% | Training loss: 0.6874953940363213
Epoch: 38 | Iteration number: [1020/4518] 22% | Training loss: 0.6874850081462486
Epoch: 38 | Iteration number: [1030/4518] 22% | Training loss: 0.6874818347032787
Epoch: 38 | Iteration number: [1040/4518] 23% | Training loss: 0.6874676680908753
Epoch: 38 | Iteration number: [1050/4518] 23% | Training loss: 0.6874617504505884
Epoch: 38 | Iteration number: [1060/4518] 23% | Training loss: 0.6874575386069856
Epoch: 38 | Iteration number: [1070/4518] 23% | Training loss: 0.6874497424776309
Epoch: 38 | Iteration number: [1080/4518] 23% | Training loss: 0.6874406656181371
Epoch: 38 | Iteration number: [1090/4518] 24% | Training loss: 0.6874429551833267
Epoch: 38 | Iteration number: [1100/4518] 24% | Training loss: 0.6874381234429099
Epoch: 38 | Iteration number: [1110/4518] 24% | Training loss: 0.6874214929503364
Epoch: 38 | Iteration number: [1120/4518] 24% | Training loss: 0.6874094238770859
Epoch: 38 | Iteration number: [1130/4518] 25% | Training loss: 0.6874008296865277
Epoch: 38 | Iteration number: [1140/4518] 25% | Training loss: 0.6874026437077606
Epoch: 38 | Iteration number: [1150/4518] 25% | Training loss: 0.687385868145072
Epoch: 38 | Iteration number: [1160/4518] 25% | Training loss: 0.687387088146703
Epoch: 38 | Iteration number: [1170/4518] 25% | Training loss: 0.6873765186366871
Epoch: 38 | Iteration number: [1180/4518] 26% | Training loss: 0.6873827950934233
Epoch: 38 | Iteration number: [1190/4518] 26% | Training loss: 0.6873680613621944
Epoch: 38 | Iteration number: [1200/4518] 26% | Training loss: 0.6873655615250269
Epoch: 38 | Iteration number: [1210/4518] 26% | Training loss: 0.6873675137019355
Epoch: 38 | Iteration number: [1220/4518] 27% | Training loss: 0.6873550177597608
Epoch: 38 | Iteration number: [1230/4518] 27% | Training loss: 0.6873527650910665
Epoch: 38 | Iteration number: [1240/4518] 27% | Training loss: 0.6873444858577944
Epoch: 38 | Iteration number: [1250/4518] 27% | Training loss: 0.6873432033061981
Epoch: 38 | Iteration number: [1260/4518] 27% | Training loss: 0.6873340790233915
Epoch: 38 | Iteration number: [1270/4518] 28% | Training loss: 0.6873220506146198
Epoch: 38 | Iteration number: [1280/4518] 28% | Training loss: 0.687312142457813
Epoch: 38 | Iteration number: [1290/4518] 28% | Training loss: 0.6873085648052453
Epoch: 38 | Iteration number: [1300/4518] 28% | Training loss: 0.6873011102584692
Epoch: 38 | Iteration number: [1310/4518] 28% | Training loss: 0.6872961376459544
Epoch: 38 | Iteration number: [1320/4518] 29% | Training loss: 0.687294192431551
Epoch: 38 | Iteration number: [1330/4518] 29% | Training loss: 0.6872857212124014
Epoch: 38 | Iteration number: [1340/4518] 29% | Training loss: 0.6872847783476559
Epoch: 38 | Iteration number: [1350/4518] 29% | Training loss: 0.6872903810165547
Epoch: 38 | Iteration number: [1360/4518] 30% | Training loss: 0.6872881675906041
Epoch: 38 | Iteration number: [1370/4518] 30% | Training loss: 0.6872816881559191
Epoch: 38 | Iteration number: [1380/4518] 30% | Training loss: 0.6872806105060854
Epoch: 38 | Iteration number: [1390/4518] 30% | Training loss: 0.6872619771271301
Epoch: 38 | Iteration number: [1400/4518] 30% | Training loss: 0.6872549352475575
Epoch: 38 | Iteration number: [1410/4518] 31% | Training loss: 0.6872408741332116
Epoch: 38 | Iteration number: [1420/4518] 31% | Training loss: 0.6872377699949372
Epoch: 38 | Iteration number: [1430/4518] 31% | Training loss: 0.6872385435587877
Epoch: 38 | Iteration number: [1440/4518] 31% | Training loss: 0.6872375283390284
Epoch: 38 | Iteration number: [1450/4518] 32% | Training loss: 0.6872392155795262
Epoch: 38 | Iteration number: [1460/4518] 32% | Training loss: 0.6872424763767686
Epoch: 38 | Iteration number: [1470/4518] 32% | Training loss: 0.6872276725412226
Epoch: 38 | Iteration number: [1480/4518] 32% | Training loss: 0.6872263857641736
Epoch: 38 | Iteration number: [1490/4518] 32% | Training loss: 0.6872252311882556
Epoch: 38 | Iteration number: [1500/4518] 33% | Training loss: 0.6872170731226603
Epoch: 38 | Iteration number: [1510/4518] 33% | Training loss: 0.687214043400935
Epoch: 38 | Iteration number: [1520/4518] 33% | Training loss: 0.6872183013903467
Epoch: 38 | Iteration number: [1530/4518] 33% | Training loss: 0.6872109575209275
Epoch: 38 | Iteration number: [1540/4518] 34% | Training loss: 0.687215202466234
Epoch: 38 | Iteration number: [1550/4518] 34% | Training loss: 0.687212977293999
Epoch: 38 | Iteration number: [1560/4518] 34% | Training loss: 0.6872154564811633
Epoch: 38 | Iteration number: [1570/4518] 34% | Training loss: 0.6872025484871712
Epoch: 38 | Iteration number: [1580/4518] 34% | Training loss: 0.687195975154261
Epoch: 38 | Iteration number: [1590/4518] 35% | Training loss: 0.687191212252251
Epoch: 38 | Iteration number: [1600/4518] 35% | Training loss: 0.6871939573809505
Epoch: 38 | Iteration number: [1610/4518] 35% | Training loss: 0.6871974294600279
Epoch: 38 | Iteration number: [1620/4518] 35% | Training loss: 0.687194146786207
Epoch: 38 | Iteration number: [1630/4518] 36% | Training loss: 0.687195248801284
Epoch: 38 | Iteration number: [1640/4518] 36% | Training loss: 0.6871982560652058
Epoch: 38 | Iteration number: [1650/4518] 36% | Training loss: 0.6872019435420181
Epoch: 38 | Iteration number: [1660/4518] 36% | Training loss: 0.6871907175305378
Epoch: 38 | Iteration number: [1670/4518] 36% | Training loss: 0.687188751183584
Epoch: 38 | Iteration number: [1680/4518] 37% | Training loss: 0.6871902536778223
Epoch: 38 | Iteration number: [1690/4518] 37% | Training loss: 0.6871887996351931
Epoch: 38 | Iteration number: [1700/4518] 37% | Training loss: 0.6871947068677229
Epoch: 38 | Iteration number: [1710/4518] 37% | Training loss: 0.6872008608098615
Epoch: 38 | Iteration number: [1720/4518] 38% | Training loss: 0.6872003879658012
Epoch: 38 | Iteration number: [1730/4518] 38% | Training loss: 0.6871881098416499
Epoch: 38 | Iteration number: [1740/4518] 38% | Training loss: 0.687183126944235
Epoch: 38 | Iteration number: [1750/4518] 38% | Training loss: 0.6871784719058446
Epoch: 38 | Iteration number: [1760/4518] 38% | Training loss: 0.687180490961129
Epoch: 38 | Iteration number: [1770/4518] 39% | Training loss: 0.687173244104547
Epoch: 38 | Iteration number: [1780/4518] 39% | Training loss: 0.6871668268790406
Epoch: 38 | Iteration number: [1790/4518] 39% | Training loss: 0.6871613554448389
Epoch: 38 | Iteration number: [1800/4518] 39% | Training loss: 0.6871553633941544
Epoch: 38 | Iteration number: [1810/4518] 40% | Training loss: 0.6871577753875796
Epoch: 38 | Iteration number: [1820/4518] 40% | Training loss: 0.6871511111875157
Epoch: 38 | Iteration number: [1830/4518] 40% | Training loss: 0.6871511432968203
Epoch: 38 | Iteration number: [1840/4518] 40% | Training loss: 0.6871500053807446
Epoch: 38 | Iteration number: [1850/4518] 40% | Training loss: 0.6871476714353304
Epoch: 38 | Iteration number: [1860/4518] 41% | Training loss: 0.6871426614381934
Epoch: 38 | Iteration number: [1870/4518] 41% | Training loss: 0.6871411648663608
Epoch: 38 | Iteration number: [1880/4518] 41% | Training loss: 0.687129985842299
Epoch: 38 | Iteration number: [1890/4518] 41% | Training loss: 0.6871252897239867
Epoch: 38 | Iteration number: [1900/4518] 42% | Training loss: 0.6871187901183179
Epoch: 38 | Iteration number: [1910/4518] 42% | Training loss: 0.687123429119899
Epoch: 38 | Iteration number: [1920/4518] 42% | Training loss: 0.6871207694212595
Epoch: 38 | Iteration number: [1930/4518] 42% | Training loss: 0.6871134653919101
Epoch: 38 | Iteration number: [1940/4518] 42% | Training loss: 0.6871180308233832
Epoch: 38 | Iteration number: [1950/4518] 43% | Training loss: 0.6871176183529389
Epoch: 38 | Iteration number: [1960/4518] 43% | Training loss: 0.6871158804212297
Epoch: 38 | Iteration number: [1970/4518] 43% | Training loss: 0.6871207780946935
Epoch: 38 | Iteration number: [1980/4518] 43% | Training loss: 0.6871203727493382
Epoch: 38 | Iteration number: [1990/4518] 44% | Training loss: 0.6871179995524823
Epoch: 38 | Iteration number: [2000/4518] 44% | Training loss: 0.6871223832070827
Epoch: 38 | Iteration number: [2010/4518] 44% | Training loss: 0.6871201471606297
Epoch: 38 | Iteration number: [2020/4518] 44% | Training loss: 0.6871210138101389
Epoch: 38 | Iteration number: [2030/4518] 44% | Training loss: 0.687122054493486
Epoch: 38 | Iteration number: [2040/4518] 45% | Training loss: 0.6871178285163991
Epoch: 38 | Iteration number: [2050/4518] 45% | Training loss: 0.6871212021025216
Epoch: 38 | Iteration number: [2060/4518] 45% | Training loss: 0.687120855375401
Epoch: 38 | Iteration number: [2070/4518] 45% | Training loss: 0.6871211080159542
Epoch: 38 | Iteration number: [2080/4518] 46% | Training loss: 0.6871180702860539
Epoch: 38 | Iteration number: [2090/4518] 46% | Training loss: 0.6871119352333853
Epoch: 38 | Iteration number: [2100/4518] 46% | Training loss: 0.6871080779177802
Epoch: 38 | Iteration number: [2110/4518] 46% | Training loss: 0.6871105434487781
Epoch: 38 | Iteration number: [2120/4518] 46% | Training loss: 0.6871091663837433
Epoch: 38 | Iteration number: [2130/4518] 47% | Training loss: 0.687104944136221
Epoch: 38 | Iteration number: [2140/4518] 47% | Training loss: 0.687108116367153
Epoch: 38 | Iteration number: [2150/4518] 47% | Training loss: 0.6871073074950729
Epoch: 38 | Iteration number: [2160/4518] 47% | Training loss: 0.6871074345376756
Epoch: 38 | Iteration number: [2170/4518] 48% | Training loss: 0.6871046092927731
Epoch: 38 | Iteration number: [2180/4518] 48% | Training loss: 0.6871093106926034
Epoch: 38 | Iteration number: [2190/4518] 48% | Training loss: 0.6871060344998695
Epoch: 38 | Iteration number: [2200/4518] 48% | Training loss: 0.687105241526257
Epoch: 38 | Iteration number: [2210/4518] 48% | Training loss: 0.6871007723775924
Epoch: 38 | Iteration number: [2220/4518] 49% | Training loss: 0.687095684725959
Epoch: 38 | Iteration number: [2230/4518] 49% | Training loss: 0.687093611950297
Epoch: 38 | Iteration number: [2240/4518] 49% | Training loss: 0.6870906655543617
Epoch: 38 | Iteration number: [2250/4518] 49% | Training loss: 0.6870922581884596
Epoch: 38 | Iteration number: [2260/4518] 50% | Training loss: 0.687086987732786
Epoch: 38 | Iteration number: [2270/4518] 50% | Training loss: 0.6870871893109729
Epoch: 38 | Iteration number: [2280/4518] 50% | Training loss: 0.6870878138824513
Epoch: 38 | Iteration number: [2290/4518] 50% | Training loss: 0.6870863508969935
Epoch: 38 | Iteration number: [2300/4518] 50% | Training loss: 0.6870833377475324
Epoch: 38 | Iteration number: [2310/4518] 51% | Training loss: 0.6870789747217517
Epoch: 38 | Iteration number: [2320/4518] 51% | Training loss: 0.6870768675516392
Epoch: 38 | Iteration number: [2330/4518] 51% | Training loss: 0.6870788124242054
Epoch: 38 | Iteration number: [2340/4518] 51% | Training loss: 0.6870811847540048
Epoch: 38 | Iteration number: [2350/4518] 52% | Training loss: 0.6870825061392277
Epoch: 38 | Iteration number: [2360/4518] 52% | Training loss: 0.68708238212739
Epoch: 38 | Iteration number: [2370/4518] 52% | Training loss: 0.6870845542426853
Epoch: 38 | Iteration number: [2380/4518] 52% | Training loss: 0.6870890335876401
Epoch: 38 | Iteration number: [2390/4518] 52% | Training loss: 0.687089052334989
Epoch: 38 | Iteration number: [2400/4518] 53% | Training loss: 0.6870905713488659
Epoch: 38 | Iteration number: [2410/4518] 53% | Training loss: 0.6870878376901397
Epoch: 38 | Iteration number: [2420/4518] 53% | Training loss: 0.6870828332487217
Epoch: 38 | Iteration number: [2430/4518] 53% | Training loss: 0.6870801753958556
Epoch: 38 | Iteration number: [2440/4518] 54% | Training loss: 0.6870780848088812
Epoch: 38 | Iteration number: [2450/4518] 54% | Training loss: 0.6870779504094805
Epoch: 38 | Iteration number: [2460/4518] 54% | Training loss: 0.6870810051032198
Epoch: 38 | Iteration number: [2470/4518] 54% | Training loss: 0.6870729460166051
Epoch: 38 | Iteration number: [2480/4518] 54% | Training loss: 0.6870734111435952
Epoch: 38 | Iteration number: [2490/4518] 55% | Training loss: 0.6870712250590804
Epoch: 38 | Iteration number: [2500/4518] 55% | Training loss: 0.6870744270801544
Epoch: 38 | Iteration number: [2510/4518] 55% | Training loss: 0.6870753801676381
Epoch: 38 | Iteration number: [2520/4518] 55% | Training loss: 0.6870695433919392
Epoch: 38 | Iteration number: [2530/4518] 55% | Training loss: 0.6870685354994219
Epoch: 38 | Iteration number: [2540/4518] 56% | Training loss: 0.6870680426518748
Epoch: 38 | Iteration number: [2550/4518] 56% | Training loss: 0.687059316588383
Epoch: 38 | Iteration number: [2560/4518] 56% | Training loss: 0.6870561972260475
Epoch: 38 | Iteration number: [2570/4518] 56% | Training loss: 0.6870571784704111
Epoch: 38 | Iteration number: [2580/4518] 57% | Training loss: 0.6870601038138072
Epoch: 38 | Iteration number: [2590/4518] 57% | Training loss: 0.687063294580084
Epoch: 38 | Iteration number: [2600/4518] 57% | Training loss: 0.6870712440518233
Epoch: 38 | Iteration number: [2610/4518] 57% | Training loss: 0.68707093884205
Epoch: 38 | Iteration number: [2620/4518] 57% | Training loss: 0.6870710871146836
Epoch: 38 | Iteration number: [2630/4518] 58% | Training loss: 0.6870741706157365
Epoch: 38 | Iteration number: [2640/4518] 58% | Training loss: 0.6870740190599904
Epoch: 38 | Iteration number: [2650/4518] 58% | Training loss: 0.6870719962524918
Epoch: 38 | Iteration number: [2660/4518] 58% | Training loss: 0.6870716525423796
Epoch: 38 | Iteration number: [2670/4518] 59% | Training loss: 0.6870692797814416
Epoch: 38 | Iteration number: [2680/4518] 59% | Training loss: 0.6870652575991048
Epoch: 38 | Iteration number: [2690/4518] 59% | Training loss: 0.6870692160049778
Epoch: 38 | Iteration number: [2700/4518] 59% | Training loss: 0.6870662921225583
Epoch: 38 | Iteration number: [2710/4518] 59% | Training loss: 0.6870622056656658
Epoch: 38 | Iteration number: [2720/4518] 60% | Training loss: 0.6870619711192215
Epoch: 38 | Iteration number: [2730/4518] 60% | Training loss: 0.6870600024204114
Epoch: 38 | Iteration number: [2740/4518] 60% | Training loss: 0.6870621202635939
Epoch: 38 | Iteration number: [2750/4518] 60% | Training loss: 0.6870604751110077
Epoch: 38 | Iteration number: [2760/4518] 61% | Training loss: 0.6870599746704101
Epoch: 38 | Iteration number: [2770/4518] 61% | Training loss: 0.6870573771344195
Epoch: 38 | Iteration number: [2780/4518] 61% | Training loss: 0.6870587296194309
Epoch: 38 | Iteration number: [2790/4518] 61% | Training loss: 0.6870594938809726
Epoch: 38 | Iteration number: [2800/4518] 61% | Training loss: 0.6870583858873163
Epoch: 38 | Iteration number: [2810/4518] 62% | Training loss: 0.6870593788997135
Epoch: 38 | Iteration number: [2820/4518] 62% | Training loss: 0.687059468686158
Epoch: 38 | Iteration number: [2830/4518] 62% | Training loss: 0.6870569183632679
Epoch: 38 | Iteration number: [2840/4518] 62% | Training loss: 0.6870574098657555
Epoch: 38 | Iteration number: [2850/4518] 63% | Training loss: 0.6870529877093801
Epoch: 38 | Iteration number: [2860/4518] 63% | Training loss: 0.6870536133334353
Epoch: 38 | Iteration number: [2870/4518] 63% | Training loss: 0.6870535090617602
Epoch: 38 | Iteration number: [2880/4518] 63% | Training loss: 0.687052265016569
Epoch: 38 | Iteration number: [2890/4518] 63% | Training loss: 0.6870542236265427
Epoch: 38 | Iteration number: [2900/4518] 64% | Training loss: 0.6870559755687056
Epoch: 38 | Iteration number: [2910/4518] 64% | Training loss: 0.6870559771446019
Epoch: 38 | Iteration number: [2920/4518] 64% | Training loss: 0.6870517835837521
Epoch: 38 | Iteration number: [2930/4518] 64% | Training loss: 0.6870515274309867
Epoch: 38 | Iteration number: [2940/4518] 65% | Training loss: 0.6870452160332479
Epoch: 38 | Iteration number: [2950/4518] 65% | Training loss: 0.6870421781580327
Epoch: 38 | Iteration number: [2960/4518] 65% | Training loss: 0.6870403688098933
Epoch: 38 | Iteration number: [2970/4518] 65% | Training loss: 0.6870400617821047
Epoch: 38 | Iteration number: [2980/4518] 65% | Training loss: 0.687041603038775
Epoch: 38 | Iteration number: [2990/4518] 66% | Training loss: 0.6870445566432531
Epoch: 38 | Iteration number: [3000/4518] 66% | Training loss: 0.6870369268457095
Epoch: 38 | Iteration number: [3010/4518] 66% | Training loss: 0.6870400797489078
Epoch: 38 | Iteration number: [3020/4518] 66% | Training loss: 0.6870389233361807
Epoch: 38 | Iteration number: [3030/4518] 67% | Training loss: 0.68703866479027
Epoch: 38 | Iteration number: [3040/4518] 67% | Training loss: 0.6870352265081907
Epoch: 38 | Iteration number: [3050/4518] 67% | Training loss: 0.6870343117049483
Epoch: 38 | Iteration number: [3060/4518] 67% | Training loss: 0.6870314381870569
Epoch: 38 | Iteration number: [3070/4518] 67% | Training loss: 0.6870323369673875
Epoch: 38 | Iteration number: [3080/4518] 68% | Training loss: 0.6870318115531624
Epoch: 38 | Iteration number: [3090/4518] 68% | Training loss: 0.6870304869795308
Epoch: 38 | Iteration number: [3100/4518] 68% | Training loss: 0.68702699353618
Epoch: 38 | Iteration number: [3110/4518] 68% | Training loss: 0.6870294378884736
Epoch: 38 | Iteration number: [3120/4518] 69% | Training loss: 0.6870298574177118
Epoch: 38 | Iteration number: [3130/4518] 69% | Training loss: 0.6870282884603872
Epoch: 38 | Iteration number: [3140/4518] 69% | Training loss: 0.6870258506316288
Epoch: 38 | Iteration number: [3150/4518] 69% | Training loss: 0.687028194003635
Epoch: 38 | Iteration number: [3160/4518] 69% | Training loss: 0.6870305608344983
Epoch: 38 | Iteration number: [3170/4518] 70% | Training loss: 0.6870304468302321
Epoch: 38 | Iteration number: [3180/4518] 70% | Training loss: 0.6870300423611635
Epoch: 38 | Iteration number: [3190/4518] 70% | Training loss: 0.6870286925272509
Epoch: 38 | Iteration number: [3200/4518] 70% | Training loss: 0.6870218808948994
Epoch: 38 | Iteration number: [3210/4518] 71% | Training loss: 0.687022372569622
Epoch: 38 | Iteration number: [3220/4518] 71% | Training loss: 0.6870241568880792
Epoch: 38 | Iteration number: [3230/4518] 71% | Training loss: 0.6870264174214826
Epoch: 38 | Iteration number: [3240/4518] 71% | Training loss: 0.6870278019779994
Epoch: 38 | Iteration number: [3250/4518] 71% | Training loss: 0.687027855689709
Epoch: 38 | Iteration number: [3260/4518] 72% | Training loss: 0.6870244919522408
Epoch: 38 | Iteration number: [3270/4518] 72% | Training loss: 0.6870222860702316
Epoch: 38 | Iteration number: [3280/4518] 72% | Training loss: 0.6870221751128754
Epoch: 38 | Iteration number: [3290/4518] 72% | Training loss: 0.6870222664169265
Epoch: 38 | Iteration number: [3300/4518] 73% | Training loss: 0.6870240272175182
Epoch: 38 | Iteration number: [3310/4518] 73% | Training loss: 0.6870230536626545
Epoch: 38 | Iteration number: [3320/4518] 73% | Training loss: 0.6870242482926472
Epoch: 38 | Iteration number: [3330/4518] 73% | Training loss: 0.6870220325730585
Epoch: 38 | Iteration number: [3340/4518] 73% | Training loss: 0.6870177011825367
Epoch: 38 | Iteration number: [3350/4518] 74% | Training loss: 0.6870204007269731
Epoch: 38 | Iteration number: [3360/4518] 74% | Training loss: 0.6870227715976182
Epoch: 38 | Iteration number: [3370/4518] 74% | Training loss: 0.6870223074001799
Epoch: 38 | Iteration number: [3380/4518] 74% | Training loss: 0.68702577435406
Epoch: 38 | Iteration number: [3390/4518] 75% | Training loss: 0.6870264788468678
Epoch: 38 | Iteration number: [3400/4518] 75% | Training loss: 0.6870257528739817
Epoch: 38 | Iteration number: [3410/4518] 75% | Training loss: 0.687023761422753
Epoch: 38 | Iteration number: [3420/4518] 75% | Training loss: 0.6870247079440724
Epoch: 38 | Iteration number: [3430/4518] 75% | Training loss: 0.6870232751001074
Epoch: 38 | Iteration number: [3440/4518] 76% | Training loss: 0.6870210056734639
Epoch: 38 | Iteration number: [3450/4518] 76% | Training loss: 0.6870188274418099
Epoch: 38 | Iteration number: [3460/4518] 76% | Training loss: 0.6870178136694638
Epoch: 38 | Iteration number: [3470/4518] 76% | Training loss: 0.6870133419888851
Epoch: 38 | Iteration number: [3480/4518] 77% | Training loss: 0.6870120612369186
Epoch: 38 | Iteration number: [3490/4518] 77% | Training loss: 0.6870105362040949
Epoch: 38 | Iteration number: [3500/4518] 77% | Training loss: 0.687009909272194
Epoch: 38 | Iteration number: [3510/4518] 77% | Training loss: 0.6870107708833156
Epoch: 38 | Iteration number: [3520/4518] 77% | Training loss: 0.6870092323049903
Epoch: 38 | Iteration number: [3530/4518] 78% | Training loss: 0.6870100095150491
Epoch: 38 | Iteration number: [3540/4518] 78% | Training loss: 0.6870113180013699
Epoch: 38 | Iteration number: [3550/4518] 78% | Training loss: 0.6870108214398505
Epoch: 38 | Iteration number: [3560/4518] 78% | Training loss: 0.6870135848609249
Epoch: 38 | Iteration number: [3570/4518] 79% | Training loss: 0.6870091711606632
Epoch: 38 | Iteration number: [3580/4518] 79% | Training loss: 0.687008964266191
Epoch: 38 | Iteration number: [3590/4518] 79% | Training loss: 0.6870075480187504
Epoch: 38 | Iteration number: [3600/4518] 79% | Training loss: 0.6870085423191389
Epoch: 38 | Iteration number: [3610/4518] 79% | Training loss: 0.6870098871537523
Epoch: 38 | Iteration number: [3620/4518] 80% | Training loss: 0.6870068759055428
Epoch: 38 | Iteration number: [3630/4518] 80% | Training loss: 0.6870084232535244
Epoch: 38 | Iteration number: [3640/4518] 80% | Training loss: 0.6870049175980327
Epoch: 38 | Iteration number: [3650/4518] 80% | Training loss: 0.6870059593083108
Epoch: 38 | Iteration number: [3660/4518] 81% | Training loss: 0.6870096898958331
Epoch: 38 | Iteration number: [3670/4518] 81% | Training loss: 0.6870130202425923
Epoch: 38 | Iteration number: [3680/4518] 81% | Training loss: 0.6870138674164595
Epoch: 38 | Iteration number: [3690/4518] 81% | Training loss: 0.6870125768307425
Epoch: 38 | Iteration number: [3700/4518] 81% | Training loss: 0.6870110419956413
Epoch: 38 | Iteration number: [3710/4518] 82% | Training loss: 0.6870111268806972
Epoch: 38 | Iteration number: [3720/4518] 82% | Training loss: 0.6870118061060546
Epoch: 38 | Iteration number: [3730/4518] 82% | Training loss: 0.6870041471224368
Epoch: 38 | Iteration number: [3740/4518] 82% | Training loss: 0.687001667414757
Epoch: 38 | Iteration number: [3750/4518] 83% | Training loss: 0.6870041628996532
Epoch: 38 | Iteration number: [3760/4518] 83% | Training loss: 0.6870055424406173
Epoch: 38 | Iteration number: [3770/4518] 83% | Training loss: 0.6870049219865065
Epoch: 38 | Iteration number: [3780/4518] 83% | Training loss: 0.6870047351670644
Epoch: 38 | Iteration number: [3790/4518] 83% | Training loss: 0.6870058206738142
Epoch: 38 | Iteration number: [3800/4518] 84% | Training loss: 0.6870095872722174
Epoch: 38 | Iteration number: [3810/4518] 84% | Training loss: 0.6870088151746535
Epoch: 38 | Iteration number: [3820/4518] 84% | Training loss: 0.687006435672026
Epoch: 38 | Iteration number: [3830/4518] 84% | Training loss: 0.6870089052240158
Epoch: 38 | Iteration number: [3840/4518] 84% | Training loss: 0.6870062416729827
Epoch: 38 | Iteration number: [3850/4518] 85% | Training loss: 0.687006380325788
Epoch: 38 | Iteration number: [3860/4518] 85% | Training loss: 0.687009535413332
Epoch: 38 | Iteration number: [3870/4518] 85% | Training loss: 0.6870108523572138
Epoch: 38 | Iteration number: [3880/4518] 85% | Training loss: 0.6870085270134444
Epoch: 38 | Iteration number: [3890/4518] 86% | Training loss: 0.6870073224707557
Epoch: 38 | Iteration number: [3900/4518] 86% | Training loss: 0.6870084413198324
Epoch: 38 | Iteration number: [3910/4518] 86% | Training loss: 0.6870087599662869
Epoch: 38 | Iteration number: [3920/4518] 86% | Training loss: 0.6870065929330125
Epoch: 38 | Iteration number: [3930/4518] 86% | Training loss: 0.6870095650658352
Epoch: 38 | Iteration number: [3940/4518] 87% | Training loss: 0.6870098161818412
Epoch: 38 | Iteration number: [3950/4518] 87% | Training loss: 0.6870075627218319
Epoch: 38 | Iteration number: [3960/4518] 87% | Training loss: 0.687008885572655
Epoch: 38 | Iteration number: [3970/4518] 87% | Training loss: 0.687004123436714
Epoch: 38 | Iteration number: [3980/4518] 88% | Training loss: 0.6870043168115856
Epoch: 38 | Iteration number: [3990/4518] 88% | Training loss: 0.687004685386978
Epoch: 38 | Iteration number: [4000/4518] 88% | Training loss: 0.687007459923625
Epoch: 38 | Iteration number: [4010/4518] 88% | Training loss: 0.6870081712331558
Epoch: 38 | Iteration number: [4020/4518] 88% | Training loss: 0.6870084503248556
Epoch: 38 | Iteration number: [4030/4518] 89% | Training loss: 0.6870059052708722
Epoch: 38 | Iteration number: [4040/4518] 89% | Training loss: 0.6870057539184494
Epoch: 38 | Iteration number: [4050/4518] 89% | Training loss: 0.6870042147754151
Epoch: 38 | Iteration number: [4060/4518] 89% | Training loss: 0.687001725840451
Epoch: 38 | Iteration number: [4070/4518] 90% | Training loss: 0.6870006099965708
Epoch: 38 | Iteration number: [4080/4518] 90% | Training loss: 0.6870024524044757
Epoch: 38 | Iteration number: [4090/4518] 90% | Training loss: 0.6869998809469359
Epoch: 38 | Iteration number: [4100/4518] 90% | Training loss: 0.6869955410463054
Epoch: 38 | Iteration number: [4110/4518] 90% | Training loss: 0.6869943654885258
Epoch: 38 | Iteration number: [4120/4518] 91% | Training loss: 0.6869921401866431
Epoch: 38 | Iteration number: [4130/4518] 91% | Training loss: 0.6869919478027353
Epoch: 38 | Iteration number: [4140/4518] 91% | Training loss: 0.686992461324314
Epoch: 38 | Iteration number: [4150/4518] 91% | Training loss: 0.686994187257376
Epoch: 38 | Iteration number: [4160/4518] 92% | Training loss: 0.6869935269109332
Epoch: 38 | Iteration number: [4170/4518] 92% | Training loss: 0.6869934809007805
Epoch: 38 | Iteration number: [4180/4518] 92% | Training loss: 0.6869963776409341
Epoch: 38 | Iteration number: [4190/4518] 92% | Training loss: 0.6869967203293894
Epoch: 38 | Iteration number: [4200/4518] 92% | Training loss: 0.6869976103589648
Epoch: 38 | Iteration number: [4210/4518] 93% | Training loss: 0.6869962935068262
Epoch: 38 | Iteration number: [4220/4518] 93% | Training loss: 0.6869967928288673
Epoch: 38 | Iteration number: [4230/4518] 93% | Training loss: 0.6869963362566405
Epoch: 38 | Iteration number: [4240/4518] 93% | Training loss: 0.6869948365215985
Epoch: 38 | Iteration number: [4250/4518] 94% | Training loss: 0.6869930697609397
Epoch: 38 | Iteration number: [4260/4518] 94% | Training loss: 0.6869947401430685
Epoch: 38 | Iteration number: [4270/4518] 94% | Training loss: 0.6869956595836255
Epoch: 38 | Iteration number: [4280/4518] 94% | Training loss: 0.6869963480072601
Epoch: 38 | Iteration number: [4290/4518] 94% | Training loss: 0.6869945792885094
Epoch: 38 | Iteration number: [4300/4518] 95% | Training loss: 0.6869925947244777
Epoch: 38 | Iteration number: [4310/4518] 95% | Training loss: 0.6869911967186806
Epoch: 38 | Iteration number: [4320/4518] 95% | Training loss: 0.6869935491156799
Epoch: 38 | Iteration number: [4330/4518] 95% | Training loss: 0.6869950800927627
Epoch: 38 | Iteration number: [4340/4518] 96% | Training loss: 0.6869966142188568
Epoch: 38 | Iteration number: [4350/4518] 96% | Training loss: 0.6869964334608495
Epoch: 38 | Iteration number: [4360/4518] 96% | Training loss: 0.6869956400689728
Epoch: 38 | Iteration number: [4370/4518] 96% | Training loss: 0.6869967777887253
Epoch: 38 | Iteration number: [4380/4518] 96% | Training loss: 0.6869942004413909
Epoch: 38 | Iteration number: [4390/4518] 97% | Training loss: 0.6869937302311352
Epoch: 38 | Iteration number: [4400/4518] 97% | Training loss: 0.6869947464222258
Epoch: 38 | Iteration number: [4410/4518] 97% | Training loss: 0.6869911777865049
Epoch: 38 | Iteration number: [4420/4518] 97% | Training loss: 0.6869904147553768
Epoch: 38 | Iteration number: [4430/4518] 98% | Training loss: 0.6869889100033866
Epoch: 38 | Iteration number: [4440/4518] 98% | Training loss: 0.6869865228195449
Epoch: 38 | Iteration number: [4450/4518] 98% | Training loss: 0.686987007588483
Epoch: 38 | Iteration number: [4460/4518] 98% | Training loss: 0.6869877560256308
Epoch: 38 | Iteration number: [4470/4518] 98% | Training loss: 0.6869902344758079
Epoch: 38 | Iteration number: [4480/4518] 99% | Training loss: 0.6869913741547082
Epoch: 38 | Iteration number: [4490/4518] 99% | Training loss: 0.6869915559987448
Epoch: 38 | Iteration number: [4500/4518] 99% | Training loss: 0.6869909211529626
Epoch: 38 | Iteration number: [4510/4518] 99% | Training loss: 0.6869924811724812

 End of epoch: 38 | Train Loss: 0.6868399873989354 | Training Time: 642 

 End of epoch: 38 | Eval Loss: 0.6901955239626826 | Evaluating Time: 17 
Epoch: 39 | Iteration number: [10/4518] 0% | Training loss: 0.7552170574665069
Epoch: 39 | Iteration number: [20/4518] 0% | Training loss: 0.7211334466934204
Epoch: 39 | Iteration number: [30/4518] 0% | Training loss: 0.7097808023293813
Epoch: 39 | Iteration number: [40/4518] 0% | Training loss: 0.7040798828005791
Epoch: 39 | Iteration number: [50/4518] 1% | Training loss: 0.7005120587348937
Epoch: 39 | Iteration number: [60/4518] 1% | Training loss: 0.698245299855868
Epoch: 39 | Iteration number: [70/4518] 1% | Training loss: 0.6965833800179618
Epoch: 39 | Iteration number: [80/4518] 1% | Training loss: 0.6954581424593925
Epoch: 39 | Iteration number: [90/4518] 1% | Training loss: 0.6943366097079383
Epoch: 39 | Iteration number: [100/4518] 2% | Training loss: 0.6937436920404434
Epoch: 39 | Iteration number: [110/4518] 2% | Training loss: 0.6930731209841642
Epoch: 39 | Iteration number: [120/4518] 2% | Training loss: 0.6925386155645052
Epoch: 39 | Iteration number: [130/4518] 2% | Training loss: 0.6921269779021924
Epoch: 39 | Iteration number: [140/4518] 3% | Training loss: 0.691785249539784
Epoch: 39 | Iteration number: [150/4518] 3% | Training loss: 0.6913652797540029
Epoch: 39 | Iteration number: [160/4518] 3% | Training loss: 0.6909974765032529
Epoch: 39 | Iteration number: [170/4518] 3% | Training loss: 0.6908845578922945
Epoch: 39 | Iteration number: [180/4518] 3% | Training loss: 0.6906438158618079
Epoch: 39 | Iteration number: [190/4518] 4% | Training loss: 0.6904479807928989
Epoch: 39 | Iteration number: [200/4518] 4% | Training loss: 0.6902867403626441
Epoch: 39 | Iteration number: [210/4518] 4% | Training loss: 0.6901076467264267
Epoch: 39 | Iteration number: [220/4518] 4% | Training loss: 0.6899569581855427
Epoch: 39 | Iteration number: [230/4518] 5% | Training loss: 0.6898344179858332
Epoch: 39 | Iteration number: [240/4518] 5% | Training loss: 0.6897366565962633
Epoch: 39 | Iteration number: [250/4518] 5% | Training loss: 0.6895956103801727
Epoch: 39 | Iteration number: [260/4518] 5% | Training loss: 0.6895264776853415
Epoch: 39 | Iteration number: [270/4518] 5% | Training loss: 0.6893933435281118
Epoch: 39 | Iteration number: [280/4518] 6% | Training loss: 0.6893204848681177
Epoch: 39 | Iteration number: [290/4518] 6% | Training loss: 0.6892563162178829
Epoch: 39 | Iteration number: [300/4518] 6% | Training loss: 0.6891826870044072
Epoch: 39 | Iteration number: [310/4518] 6% | Training loss: 0.6891384195896887
Epoch: 39 | Iteration number: [320/4518] 7% | Training loss: 0.6890515588223934
Epoch: 39 | Iteration number: [330/4518] 7% | Training loss: 0.68895382140622
Epoch: 39 | Iteration number: [340/4518] 7% | Training loss: 0.6889015969108133
Epoch: 39 | Iteration number: [350/4518] 7% | Training loss: 0.6888754597731999
Epoch: 39 | Iteration number: [360/4518] 7% | Training loss: 0.6887617473800977
Epoch: 39 | Iteration number: [370/4518] 8% | Training loss: 0.68870123640911
Epoch: 39 | Iteration number: [380/4518] 8% | Training loss: 0.6886395212851073
Epoch: 39 | Iteration number: [390/4518] 8% | Training loss: 0.6885502692980644
Epoch: 39 | Iteration number: [400/4518] 8% | Training loss: 0.688491083085537
Epoch: 39 | Iteration number: [410/4518] 9% | Training loss: 0.6884580663064631
Epoch: 39 | Iteration number: [420/4518] 9% | Training loss: 0.6884391184364046
Epoch: 39 | Iteration number: [430/4518] 9% | Training loss: 0.6884134346662566
Epoch: 39 | Iteration number: [440/4518] 9% | Training loss: 0.6883783345872706
Epoch: 39 | Iteration number: [450/4518] 9% | Training loss: 0.688346506887012
Epoch: 39 | Iteration number: [460/4518] 10% | Training loss: 0.6883132328157839
Epoch: 39 | Iteration number: [470/4518] 10% | Training loss: 0.6882785194731773
Epoch: 39 | Iteration number: [480/4518] 10% | Training loss: 0.6882558659960826
Epoch: 39 | Iteration number: [490/4518] 10% | Training loss: 0.688243972768589
Epoch: 39 | Iteration number: [500/4518] 11% | Training loss: 0.6882385121583938
Epoch: 39 | Iteration number: [510/4518] 11% | Training loss: 0.688214179464415
Epoch: 39 | Iteration number: [520/4518] 11% | Training loss: 0.6882036935824615
Epoch: 39 | Iteration number: [530/4518] 11% | Training loss: 0.6881928722813444
Epoch: 39 | Iteration number: [540/4518] 11% | Training loss: 0.688136163243541
Epoch: 39 | Iteration number: [550/4518] 12% | Training loss: 0.6881096995960583
Epoch: 39 | Iteration number: [560/4518] 12% | Training loss: 0.6880968900663512
Epoch: 39 | Iteration number: [570/4518] 12% | Training loss: 0.6880699356396993
Epoch: 39 | Iteration number: [580/4518] 12% | Training loss: 0.6880478803453774
Epoch: 39 | Iteration number: [590/4518] 13% | Training loss: 0.6880151043503971
Epoch: 39 | Iteration number: [600/4518] 13% | Training loss: 0.6879861644903819
Epoch: 39 | Iteration number: [610/4518] 13% | Training loss: 0.687977538929611
Epoch: 39 | Iteration number: [620/4518] 13% | Training loss: 0.687955111553592
Epoch: 39 | Iteration number: [630/4518] 13% | Training loss: 0.6879312449031406
Epoch: 39 | Iteration number: [640/4518] 14% | Training loss: 0.6879166847094893
Epoch: 39 | Iteration number: [650/4518] 14% | Training loss: 0.6879078533099248
Epoch: 39 | Iteration number: [660/4518] 14% | Training loss: 0.6878869253577609
Epoch: 39 | Iteration number: [670/4518] 14% | Training loss: 0.6878725806278969
Epoch: 39 | Iteration number: [680/4518] 15% | Training loss: 0.6878574236350901
Epoch: 39 | Iteration number: [690/4518] 15% | Training loss: 0.6878446475319241
Epoch: 39 | Iteration number: [700/4518] 15% | Training loss: 0.6878270070893424
Epoch: 39 | Iteration number: [710/4518] 15% | Training loss: 0.6877870056830662
Epoch: 39 | Iteration number: [720/4518] 15% | Training loss: 0.6877816487517622
Epoch: 39 | Iteration number: [730/4518] 16% | Training loss: 0.6877791589253569
Epoch: 39 | Iteration number: [740/4518] 16% | Training loss: 0.6877858149038779
Epoch: 39 | Iteration number: [750/4518] 16% | Training loss: 0.6877806843121846
Epoch: 39 | Iteration number: [760/4518] 16% | Training loss: 0.6877532299411925
Epoch: 39 | Iteration number: [770/4518] 17% | Training loss: 0.6877410542655301
Epoch: 39 | Iteration number: [780/4518] 17% | Training loss: 0.687737103456106
Epoch: 39 | Iteration number: [790/4518] 17% | Training loss: 0.6877278774599486
Epoch: 39 | Iteration number: [800/4518] 17% | Training loss: 0.6877148028463125
Epoch: 39 | Iteration number: [810/4518] 17% | Training loss: 0.6876953375928196
Epoch: 39 | Iteration number: [820/4518] 18% | Training loss: 0.6876799152391713
Epoch: 39 | Iteration number: [830/4518] 18% | Training loss: 0.687662300287959
Epoch: 39 | Iteration number: [840/4518] 18% | Training loss: 0.6876466763871056
Epoch: 39 | Iteration number: [850/4518] 18% | Training loss: 0.6876361853234908
Epoch: 39 | Iteration number: [860/4518] 19% | Training loss: 0.6876234412193298
Epoch: 39 | Iteration number: [870/4518] 19% | Training loss: 0.687597951121714
Epoch: 39 | Iteration number: [880/4518] 19% | Training loss: 0.687583344632929
Epoch: 39 | Iteration number: [890/4518] 19% | Training loss: 0.687576004360499
Epoch: 39 | Iteration number: [900/4518] 19% | Training loss: 0.6875880826181836
Epoch: 39 | Iteration number: [910/4518] 20% | Training loss: 0.6875835061728299
Epoch: 39 | Iteration number: [920/4518] 20% | Training loss: 0.6875795512743618
Epoch: 39 | Iteration number: [930/4518] 20% | Training loss: 0.6875790083280173
Epoch: 39 | Iteration number: [940/4518] 20% | Training loss: 0.6875574712423568
Epoch: 39 | Iteration number: [950/4518] 21% | Training loss: 0.6875536296869579
Epoch: 39 | Iteration number: [960/4518] 21% | Training loss: 0.6875404359772801
Epoch: 39 | Iteration number: [970/4518] 21% | Training loss: 0.6875286246083446
Epoch: 39 | Iteration number: [980/4518] 21% | Training loss: 0.6875073891513201
Epoch: 39 | Iteration number: [990/4518] 21% | Training loss: 0.6874878447465222
Epoch: 39 | Iteration number: [1000/4518] 22% | Training loss: 0.6874788075089454
Epoch: 39 | Iteration number: [1010/4518] 22% | Training loss: 0.687487528937878
Epoch: 39 | Iteration number: [1020/4518] 22% | Training loss: 0.6874812670198142
Epoch: 39 | Iteration number: [1030/4518] 22% | Training loss: 0.6874769920862994
Epoch: 39 | Iteration number: [1040/4518] 23% | Training loss: 0.6874644427345349
Epoch: 39 | Iteration number: [1050/4518] 23% | Training loss: 0.6874621939091455
Epoch: 39 | Iteration number: [1060/4518] 23% | Training loss: 0.6874450035252662
Epoch: 39 | Iteration number: [1070/4518] 23% | Training loss: 0.6874434249980428
Epoch: 39 | Iteration number: [1080/4518] 23% | Training loss: 0.6874389012102727
Epoch: 39 | Iteration number: [1090/4518] 24% | Training loss: 0.6874387133558956
Epoch: 39 | Iteration number: [1100/4518] 24% | Training loss: 0.6874363142251968
Epoch: 39 | Iteration number: [1110/4518] 24% | Training loss: 0.6874350763655998
Epoch: 39 | Iteration number: [1120/4518] 24% | Training loss: 0.6874368085925068
Epoch: 39 | Iteration number: [1130/4518] 25% | Training loss: 0.6874369541100697
Epoch: 39 | Iteration number: [1140/4518] 25% | Training loss: 0.6874308930154432
Epoch: 39 | Iteration number: [1150/4518] 25% | Training loss: 0.6874244743326436
Epoch: 39 | Iteration number: [1160/4518] 25% | Training loss: 0.6874146897217323
Epoch: 39 | Iteration number: [1170/4518] 25% | Training loss: 0.6874205061513134
Epoch: 39 | Iteration number: [1180/4518] 26% | Training loss: 0.6874145276970782
Epoch: 39 | Iteration number: [1190/4518] 26% | Training loss: 0.6874187580677642
Epoch: 39 | Iteration number: [1200/4518] 26% | Training loss: 0.6874162303904693
Epoch: 39 | Iteration number: [1210/4518] 26% | Training loss: 0.6873997593714186
Epoch: 39 | Iteration number: [1220/4518] 27% | Training loss: 0.6874037747500372
Epoch: 39 | Iteration number: [1230/4518] 27% | Training loss: 0.6873966944411518
Epoch: 39 | Iteration number: [1240/4518] 27% | Training loss: 0.6873950750597062
Epoch: 39 | Iteration number: [1250/4518] 27% | Training loss: 0.6873909932136536
Epoch: 39 | Iteration number: [1260/4518] 27% | Training loss: 0.6873874655791692
Epoch: 39 | Iteration number: [1270/4518] 28% | Training loss: 0.6873782857196538
Epoch: 39 | Iteration number: [1280/4518] 28% | Training loss: 0.6873795585241169
Epoch: 39 | Iteration number: [1290/4518] 28% | Training loss: 0.6873652373635492
Epoch: 39 | Iteration number: [1300/4518] 28% | Training loss: 0.6873654669064742
Epoch: 39 | Iteration number: [1310/4518] 28% | Training loss: 0.6873632311820984
Epoch: 39 | Iteration number: [1320/4518] 29% | Training loss: 0.6873617216493144
Epoch: 39 | Iteration number: [1330/4518] 29% | Training loss: 0.6873550740399755
Epoch: 39 | Iteration number: [1340/4518] 29% | Training loss: 0.6873575314212201
Epoch: 39 | Iteration number: [1350/4518] 29% | Training loss: 0.6873619640756536
Epoch: 39 | Iteration number: [1360/4518] 30% | Training loss: 0.6873544281896423
Epoch: 39 | Iteration number: [1370/4518] 30% | Training loss: 0.6873555034616567
Epoch: 39 | Iteration number: [1380/4518] 30% | Training loss: 0.6873494415179543
Epoch: 39 | Iteration number: [1390/4518] 30% | Training loss: 0.6873431771350421
Epoch: 39 | Iteration number: [1400/4518] 30% | Training loss: 0.6873430890696389
Epoch: 39 | Iteration number: [1410/4518] 31% | Training loss: 0.687338352245642
Epoch: 39 | Iteration number: [1420/4518] 31% | Training loss: 0.6873290190394495
Epoch: 39 | Iteration number: [1430/4518] 31% | Training loss: 0.6873143879683701
Epoch: 39 | Iteration number: [1440/4518] 31% | Training loss: 0.6873094184117184
Epoch: 39 | Iteration number: [1450/4518] 32% | Training loss: 0.6873056144960995
Epoch: 39 | Iteration number: [1460/4518] 32% | Training loss: 0.6872999729767237
Epoch: 39 | Iteration number: [1470/4518] 32% | Training loss: 0.6872947469455044
Epoch: 39 | Iteration number: [1480/4518] 32% | Training loss: 0.6872952774569795
Epoch: 39 | Iteration number: [1490/4518] 32% | Training loss: 0.6873040775724706
Epoch: 39 | Iteration number: [1500/4518] 33% | Training loss: 0.6873003203074137
Epoch: 39 | Iteration number: [1510/4518] 33% | Training loss: 0.6873031413713039
Epoch: 39 | Iteration number: [1520/4518] 33% | Training loss: 0.6873050259916406
Epoch: 39 | Iteration number: [1530/4518] 33% | Training loss: 0.6873071505742915
Epoch: 39 | Iteration number: [1540/4518] 34% | Training loss: 0.6873058965453854
Epoch: 39 | Iteration number: [1550/4518] 34% | Training loss: 0.6873003871210159
Epoch: 39 | Iteration number: [1560/4518] 34% | Training loss: 0.6872959978687457
Epoch: 39 | Iteration number: [1570/4518] 34% | Training loss: 0.6872911556511169
Epoch: 39 | Iteration number: [1580/4518] 34% | Training loss: 0.6872761321973198
Epoch: 39 | Iteration number: [1590/4518] 35% | Training loss: 0.6872725788902186
Epoch: 39 | Iteration number: [1600/4518] 35% | Training loss: 0.6872728775814175
Epoch: 39 | Iteration number: [1610/4518] 35% | Training loss: 0.6872705003119404
Epoch: 39 | Iteration number: [1620/4518] 35% | Training loss: 0.6872640502305678
Epoch: 39 | Iteration number: [1630/4518] 36% | Training loss: 0.6872588083422257
Epoch: 39 | Iteration number: [1640/4518] 36% | Training loss: 0.6872518080400257
Epoch: 39 | Iteration number: [1650/4518] 36% | Training loss: 0.6872565873102708
Epoch: 39 | Iteration number: [1660/4518] 36% | Training loss: 0.6872591146503586
Epoch: 39 | Iteration number: [1670/4518] 36% | Training loss: 0.6872467387936072
Epoch: 39 | Iteration number: [1680/4518] 37% | Training loss: 0.6872437991556667
Epoch: 39 | Iteration number: [1690/4518] 37% | Training loss: 0.6872488089919796
Epoch: 39 | Iteration number: [1700/4518] 37% | Training loss: 0.6872439410756616
Epoch: 39 | Iteration number: [1710/4518] 37% | Training loss: 0.6872433480812095
Epoch: 39 | Iteration number: [1720/4518] 38% | Training loss: 0.6872409259164056
Epoch: 39 | Iteration number: [1730/4518] 38% | Training loss: 0.6872358397252298
Epoch: 39 | Iteration number: [1740/4518] 38% | Training loss: 0.6872295053525903
Epoch: 39 | Iteration number: [1750/4518] 38% | Training loss: 0.6872282826219286
Epoch: 39 | Iteration number: [1760/4518] 38% | Training loss: 0.687225720117038
Epoch: 39 | Iteration number: [1770/4518] 39% | Training loss: 0.6872284751827434
Epoch: 39 | Iteration number: [1780/4518] 39% | Training loss: 0.6872301825981462
Epoch: 39 | Iteration number: [1790/4518] 39% | Training loss: 0.6872275395100343
Epoch: 39 | Iteration number: [1800/4518] 39% | Training loss: 0.6872277718120151
Epoch: 39 | Iteration number: [1810/4518] 40% | Training loss: 0.687225741411441
Epoch: 39 | Iteration number: [1820/4518] 40% | Training loss: 0.6872267674941283
Epoch: 39 | Iteration number: [1830/4518] 40% | Training loss: 0.687222010320653
Epoch: 39 | Iteration number: [1840/4518] 40% | Training loss: 0.6872219934735609
Epoch: 39 | Iteration number: [1850/4518] 40% | Training loss: 0.6872140487142512
Epoch: 39 | Iteration number: [1860/4518] 41% | Training loss: 0.6872124135173777
Epoch: 39 | Iteration number: [1870/4518] 41% | Training loss: 0.6872192781876753
Epoch: 39 | Iteration number: [1880/4518] 41% | Training loss: 0.6872141795272523
Epoch: 39 | Iteration number: [1890/4518] 41% | Training loss: 0.6872109286368839
Epoch: 39 | Iteration number: [1900/4518] 42% | Training loss: 0.6872091045191413
Epoch: 39 | Iteration number: [1910/4518] 42% | Training loss: 0.6872067133793656
Epoch: 39 | Iteration number: [1920/4518] 42% | Training loss: 0.6872005173626046
Epoch: 39 | Iteration number: [1930/4518] 42% | Training loss: 0.6872004104401781
Epoch: 39 | Iteration number: [1940/4518] 42% | Training loss: 0.6871956071595555
Epoch: 39 | Iteration number: [1950/4518] 43% | Training loss: 0.6871945429153932
Epoch: 39 | Iteration number: [1960/4518] 43% | Training loss: 0.6871956899762154
Epoch: 39 | Iteration number: [1970/4518] 43% | Training loss: 0.6871861574916065
Epoch: 39 | Iteration number: [1980/4518] 43% | Training loss: 0.6871875290015731
Epoch: 39 | Iteration number: [1990/4518] 44% | Training loss: 0.68718546110781
Epoch: 39 | Iteration number: [2000/4518] 44% | Training loss: 0.6871903519928455
Epoch: 39 | Iteration number: [2010/4518] 44% | Training loss: 0.6871860990773386
Epoch: 39 | Iteration number: [2020/4518] 44% | Training loss: 0.6871853845249308
Epoch: 39 | Iteration number: [2030/4518] 44% | Training loss: 0.6871790236733817
Epoch: 39 | Iteration number: [2040/4518] 45% | Training loss: 0.6871823701496218
Epoch: 39 | Iteration number: [2050/4518] 45% | Training loss: 0.687180420858104
Epoch: 39 | Iteration number: [2060/4518] 45% | Training loss: 0.6871752954513124
Epoch: 39 | Iteration number: [2070/4518] 45% | Training loss: 0.6871711696979504
Epoch: 39 | Iteration number: [2080/4518] 46% | Training loss: 0.6871705375898343
Epoch: 39 | Iteration number: [2090/4518] 46% | Training loss: 0.6871757227267945
Epoch: 39 | Iteration number: [2100/4518] 46% | Training loss: 0.6871703560863223
Epoch: 39 | Iteration number: [2110/4518] 46% | Training loss: 0.6871718509219834
Epoch: 39 | Iteration number: [2120/4518] 46% | Training loss: 0.6871682477166068
Epoch: 39 | Iteration number: [2130/4518] 47% | Training loss: 0.6871700011508566
Epoch: 39 | Iteration number: [2140/4518] 47% | Training loss: 0.6871724123988197
Epoch: 39 | Iteration number: [2150/4518] 47% | Training loss: 0.6871749856028446
Epoch: 39 | Iteration number: [2160/4518] 47% | Training loss: 0.6871770721894723
Epoch: 39 | Iteration number: [2170/4518] 48% | Training loss: 0.6871780606184138
Epoch: 39 | Iteration number: [2180/4518] 48% | Training loss: 0.6871788158876087
Epoch: 39 | Iteration number: [2190/4518] 48% | Training loss: 0.6871750606521624
Epoch: 39 | Iteration number: [2200/4518] 48% | Training loss: 0.6871659029884772
Epoch: 39 | Iteration number: [2210/4518] 48% | Training loss: 0.6871719757356255
Epoch: 39 | Iteration number: [2220/4518] 49% | Training loss: 0.6871710106327727
Epoch: 39 | Iteration number: [2230/4518] 49% | Training loss: 0.6871705754188144
Epoch: 39 | Iteration number: [2240/4518] 49% | Training loss: 0.6871746377487268
Epoch: 39 | Iteration number: [2250/4518] 49% | Training loss: 0.6871720017857021
Epoch: 39 | Iteration number: [2260/4518] 50% | Training loss: 0.6871708570855909
Epoch: 39 | Iteration number: [2270/4518] 50% | Training loss: 0.6871725947583824
Epoch: 39 | Iteration number: [2280/4518] 50% | Training loss: 0.687170300410505
Epoch: 39 | Iteration number: [2290/4518] 50% | Training loss: 0.6871689902382646
Epoch: 39 | Iteration number: [2300/4518] 50% | Training loss: 0.6871639677234318
Epoch: 39 | Iteration number: [2310/4518] 51% | Training loss: 0.6871607677761095
Epoch: 39 | Iteration number: [2320/4518] 51% | Training loss: 0.6871611212348115
Epoch: 39 | Iteration number: [2330/4518] 51% | Training loss: 0.6871586833133206
Epoch: 39 | Iteration number: [2340/4518] 51% | Training loss: 0.6871556407111323
Epoch: 39 | Iteration number: [2350/4518] 52% | Training loss: 0.6871527998751782
Epoch: 39 | Iteration number: [2360/4518] 52% | Training loss: 0.6871546900120832
Epoch: 39 | Iteration number: [2370/4518] 52% | Training loss: 0.6871531372834861
Epoch: 39 | Iteration number: [2380/4518] 52% | Training loss: 0.6871485788030784
Epoch: 39 | Iteration number: [2390/4518] 52% | Training loss: 0.6871415948768042
Epoch: 39 | Iteration number: [2400/4518] 53% | Training loss: 0.6871354909737905
Epoch: 39 | Iteration number: [2410/4518] 53% | Training loss: 0.6871408266645249
Epoch: 39 | Iteration number: [2420/4518] 53% | Training loss: 0.6871394491885319
Epoch: 39 | Iteration number: [2430/4518] 53% | Training loss: 0.6871404951246678
Epoch: 39 | Iteration number: [2440/4518] 54% | Training loss: 0.6871382273122912
Epoch: 39 | Iteration number: [2450/4518] 54% | Training loss: 0.6871331746237619
Epoch: 39 | Iteration number: [2460/4518] 54% | Training loss: 0.6871300859179923
Epoch: 39 | Iteration number: [2470/4518] 54% | Training loss: 0.6871307729468172
Epoch: 39 | Iteration number: [2480/4518] 54% | Training loss: 0.6871310064869542
Epoch: 39 | Iteration number: [2490/4518] 55% | Training loss: 0.6871344979747711
Epoch: 39 | Iteration number: [2500/4518] 55% | Training loss: 0.6871362736225128
Epoch: 39 | Iteration number: [2510/4518] 55% | Training loss: 0.6871349801105332
Epoch: 39 | Iteration number: [2520/4518] 55% | Training loss: 0.687135546216889
Epoch: 39 | Iteration number: [2530/4518] 55% | Training loss: 0.6871344896644471
Epoch: 39 | Iteration number: [2540/4518] 56% | Training loss: 0.687134069415528
Epoch: 39 | Iteration number: [2550/4518] 56% | Training loss: 0.6871309916645872
Epoch: 39 | Iteration number: [2560/4518] 56% | Training loss: 0.6871299770195037
Epoch: 39 | Iteration number: [2570/4518] 56% | Training loss: 0.6871280074119568
Epoch: 39 | Iteration number: [2580/4518] 57% | Training loss: 0.6871261775262596
Epoch: 39 | Iteration number: [2590/4518] 57% | Training loss: 0.6871276196825918
Epoch: 39 | Iteration number: [2600/4518] 57% | Training loss: 0.6871255771013407
Epoch: 39 | Iteration number: [2610/4518] 57% | Training loss: 0.6871227788514105
Epoch: 39 | Iteration number: [2620/4518] 57% | Training loss: 0.6871185410568732
Epoch: 39 | Iteration number: [2630/4518] 58% | Training loss: 0.6871185676906498
Epoch: 39 | Iteration number: [2640/4518] 58% | Training loss: 0.6871153449696121
Epoch: 39 | Iteration number: [2650/4518] 58% | Training loss: 0.6871068473581998
Epoch: 39 | Iteration number: [2660/4518] 58% | Training loss: 0.6871068749884913
Epoch: 39 | Iteration number: [2670/4518] 59% | Training loss: 0.6871017177453201
Epoch: 39 | Iteration number: [2680/4518] 59% | Training loss: 0.6870997862139745
Epoch: 39 | Iteration number: [2690/4518] 59% | Training loss: 0.6871003997591791
Epoch: 39 | Iteration number: [2700/4518] 59% | Training loss: 0.6871014529025113
Epoch: 39 | Iteration number: [2710/4518] 59% | Training loss: 0.6871014200233445
Epoch: 39 | Iteration number: [2720/4518] 60% | Training loss: 0.687104261600796
Epoch: 39 | Iteration number: [2730/4518] 60% | Training loss: 0.6871029131360107
Epoch: 39 | Iteration number: [2740/4518] 60% | Training loss: 0.687100466237451
Epoch: 39 | Iteration number: [2750/4518] 60% | Training loss: 0.6871023530093107
Epoch: 39 | Iteration number: [2760/4518] 61% | Training loss: 0.6871014368274938
Epoch: 39 | Iteration number: [2770/4518] 61% | Training loss: 0.6870993479279405
Epoch: 39 | Iteration number: [2780/4518] 61% | Training loss: 0.6870973197676296
Epoch: 39 | Iteration number: [2790/4518] 61% | Training loss: 0.6870958627765751
Epoch: 39 | Iteration number: [2800/4518] 61% | Training loss: 0.6870964032624449
Epoch: 39 | Iteration number: [2810/4518] 62% | Training loss: 0.68709547810283
Epoch: 39 | Iteration number: [2820/4518] 62% | Training loss: 0.6870929471778532
Epoch: 39 | Iteration number: [2830/4518] 62% | Training loss: 0.6870921595778987
Epoch: 39 | Iteration number: [2840/4518] 62% | Training loss: 0.6870877492805602
Epoch: 39 | Iteration number: [2850/4518] 63% | Training loss: 0.6870874383365899
Epoch: 39 | Iteration number: [2860/4518] 63% | Training loss: 0.6870833622200506
Epoch: 39 | Iteration number: [2870/4518] 63% | Training loss: 0.6870758946556663
Epoch: 39 | Iteration number: [2880/4518] 63% | Training loss: 0.6870732354621093
Epoch: 39 | Iteration number: [2890/4518] 63% | Training loss: 0.6870736688066106
Epoch: 39 | Iteration number: [2900/4518] 64% | Training loss: 0.6870725459888064
Epoch: 39 | Iteration number: [2910/4518] 64% | Training loss: 0.6870710788109049
Epoch: 39 | Iteration number: [2920/4518] 64% | Training loss: 0.6870728418026885
Epoch: 39 | Iteration number: [2930/4518] 64% | Training loss: 0.6870768014074592
Epoch: 39 | Iteration number: [2940/4518] 65% | Training loss: 0.6870740838196813
Epoch: 39 | Iteration number: [2950/4518] 65% | Training loss: 0.687071773985685
Epoch: 39 | Iteration number: [2960/4518] 65% | Training loss: 0.6870737584458815
Epoch: 39 | Iteration number: [2970/4518] 65% | Training loss: 0.6870696681115763
Epoch: 39 | Iteration number: [2980/4518] 65% | Training loss: 0.687069870621566
Epoch: 39 | Iteration number: [2990/4518] 66% | Training loss: 0.6870647427031029
Epoch: 39 | Iteration number: [3000/4518] 66% | Training loss: 0.6870644891262054
Epoch: 39 | Iteration number: [3010/4518] 66% | Training loss: 0.6870659620064834
Epoch: 39 | Iteration number: [3020/4518] 66% | Training loss: 0.687065663933754
Epoch: 39 | Iteration number: [3030/4518] 67% | Training loss: 0.6870612627405538
Epoch: 39 | Iteration number: [3040/4518] 67% | Training loss: 0.6870617364778331
Epoch: 39 | Iteration number: [3050/4518] 67% | Training loss: 0.6870593858351473
Epoch: 39 | Iteration number: [3060/4518] 67% | Training loss: 0.6870600612529743
Epoch: 39 | Iteration number: [3070/4518] 67% | Training loss: 0.68705824396121
Epoch: 39 | Iteration number: [3080/4518] 68% | Training loss: 0.6870594935177209
Epoch: 39 | Iteration number: [3090/4518] 68% | Training loss: 0.687059936380695
Epoch: 39 | Iteration number: [3100/4518] 68% | Training loss: 0.6870543866003713
Epoch: 39 | Iteration number: [3110/4518] 68% | Training loss: 0.6870523337190941
Epoch: 39 | Iteration number: [3120/4518] 69% | Training loss: 0.6870461497169275
Epoch: 39 | Iteration number: [3130/4518] 69% | Training loss: 0.6870488342385703
Epoch: 39 | Iteration number: [3140/4518] 69% | Training loss: 0.6870523839239862
Epoch: 39 | Iteration number: [3150/4518] 69% | Training loss: 0.6870490611167182
Epoch: 39 | Iteration number: [3160/4518] 69% | Training loss: 0.6870480601734753
Epoch: 39 | Iteration number: [3170/4518] 70% | Training loss: 0.6870446828825617
Epoch: 39 | Iteration number: [3180/4518] 70% | Training loss: 0.6870460881564602
Epoch: 39 | Iteration number: [3190/4518] 70% | Training loss: 0.687048877350589
Epoch: 39 | Iteration number: [3200/4518] 70% | Training loss: 0.687054649349302
Epoch: 39 | Iteration number: [3210/4518] 71% | Training loss: 0.6870475607869039
Epoch: 39 | Iteration number: [3220/4518] 71% | Training loss: 0.68704640160066
Epoch: 39 | Iteration number: [3230/4518] 71% | Training loss: 0.6870481699428322
Epoch: 39 | Iteration number: [3240/4518] 71% | Training loss: 0.6870499701043706
Epoch: 39 | Iteration number: [3250/4518] 71% | Training loss: 0.6870489417773027
Epoch: 39 | Iteration number: [3260/4518] 72% | Training loss: 0.6870410998357586
Epoch: 39 | Iteration number: [3270/4518] 72% | Training loss: 0.6870409756443187
Epoch: 39 | Iteration number: [3280/4518] 72% | Training loss: 0.6870401889630934
Epoch: 39 | Iteration number: [3290/4518] 72% | Training loss: 0.6870410109182259
Epoch: 39 | Iteration number: [3300/4518] 73% | Training loss: 0.6870424637288758
Epoch: 39 | Iteration number: [3310/4518] 73% | Training loss: 0.6870440659566228
Epoch: 39 | Iteration number: [3320/4518] 73% | Training loss: 0.6870436664805355
Epoch: 39 | Iteration number: [3330/4518] 73% | Training loss: 0.6870430302870524
Epoch: 39 | Iteration number: [3340/4518] 73% | Training loss: 0.6870443191000087
Epoch: 39 | Iteration number: [3350/4518] 74% | Training loss: 0.6870435051953615
Epoch: 39 | Iteration number: [3360/4518] 74% | Training loss: 0.6870433624479033
Epoch: 39 | Iteration number: [3370/4518] 74% | Training loss: 0.6870419468299571
Epoch: 39 | Iteration number: [3380/4518] 74% | Training loss: 0.6870390658018857
Epoch: 39 | Iteration number: [3390/4518] 75% | Training loss: 0.6870385187037926
Epoch: 39 | Iteration number: [3400/4518] 75% | Training loss: 0.6870373101269498
Epoch: 39 | Iteration number: [3410/4518] 75% | Training loss: 0.6870395522313384
Epoch: 39 | Iteration number: [3420/4518] 75% | Training loss: 0.6870391059165809
Epoch: 39 | Iteration number: [3430/4518] 75% | Training loss: 0.68703777814398
Epoch: 39 | Iteration number: [3440/4518] 76% | Training loss: 0.6870379240880179
Epoch: 39 | Iteration number: [3450/4518] 76% | Training loss: 0.6870386212286742
Epoch: 39 | Iteration number: [3460/4518] 76% | Training loss: 0.687037561756338
Epoch: 39 | Iteration number: [3470/4518] 76% | Training loss: 0.6870396246827645
Epoch: 39 | Iteration number: [3480/4518] 77% | Training loss: 0.687035475243097
Epoch: 39 | Iteration number: [3490/4518] 77% | Training loss: 0.6870379936387683
Epoch: 39 | Iteration number: [3500/4518] 77% | Training loss: 0.6870393051760537
Epoch: 39 | Iteration number: [3510/4518] 77% | Training loss: 0.6870384822204242
Epoch: 39 | Iteration number: [3520/4518] 77% | Training loss: 0.6870366551659324
Epoch: 39 | Iteration number: [3530/4518] 78% | Training loss: 0.6870380699127997
Epoch: 39 | Iteration number: [3540/4518] 78% | Training loss: 0.6870375522954316
Epoch: 39 | Iteration number: [3550/4518] 78% | Training loss: 0.687033029391732
Epoch: 39 | Iteration number: [3560/4518] 78% | Training loss: 0.6870291186015257
Epoch: 39 | Iteration number: [3570/4518] 79% | Training loss: 0.6870309554395222
Epoch: 39 | Iteration number: [3580/4518] 79% | Training loss: 0.687027133343606
Epoch: 39 | Iteration number: [3590/4518] 79% | Training loss: 0.6870270851096735
Epoch: 39 | Iteration number: [3600/4518] 79% | Training loss: 0.6870271399286059
Epoch: 39 | Iteration number: [3610/4518] 79% | Training loss: 0.6870289340243776
Epoch: 39 | Iteration number: [3620/4518] 80% | Training loss: 0.6870294512141475
Epoch: 39 | Iteration number: [3630/4518] 80% | Training loss: 0.6870287924430258
Epoch: 39 | Iteration number: [3640/4518] 80% | Training loss: 0.687022254214837
Epoch: 39 | Iteration number: [3650/4518] 80% | Training loss: 0.6870200044161653
Epoch: 39 | Iteration number: [3660/4518] 81% | Training loss: 0.6870196452394861
Epoch: 39 | Iteration number: [3670/4518] 81% | Training loss: 0.6870173481082397
Epoch: 39 | Iteration number: [3680/4518] 81% | Training loss: 0.6870187082206426
Epoch: 39 | Iteration number: [3690/4518] 81% | Training loss: 0.6870192029934912
Epoch: 39 | Iteration number: [3700/4518] 81% | Training loss: 0.6870155160652625
Epoch: 39 | Iteration number: [3710/4518] 82% | Training loss: 0.6870173042514575
Epoch: 39 | Iteration number: [3720/4518] 82% | Training loss: 0.6870159659013954
Epoch: 39 | Iteration number: [3730/4518] 82% | Training loss: 0.687013130053758
Epoch: 39 | Iteration number: [3740/4518] 82% | Training loss: 0.6870110708124497
Epoch: 39 | Iteration number: [3750/4518] 83% | Training loss: 0.6870119552135467
Epoch: 39 | Iteration number: [3760/4518] 83% | Training loss: 0.687008453033706
Epoch: 39 | Iteration number: [3770/4518] 83% | Training loss: 0.6870104707678686
Epoch: 39 | Iteration number: [3780/4518] 83% | Training loss: 0.6870090283571728
Epoch: 39 | Iteration number: [3790/4518] 83% | Training loss: 0.6870025416162838
Epoch: 39 | Iteration number: [3800/4518] 84% | Training loss: 0.6870043023009049
Epoch: 39 | Iteration number: [3810/4518] 84% | Training loss: 0.6870039280943984
Epoch: 39 | Iteration number: [3820/4518] 84% | Training loss: 0.6870020268631231
Epoch: 39 | Iteration number: [3830/4518] 84% | Training loss: 0.6870051453692484
Epoch: 39 | Iteration number: [3840/4518] 84% | Training loss: 0.6870031964499503
Epoch: 39 | Iteration number: [3850/4518] 85% | Training loss: 0.6870000450022808
Epoch: 39 | Iteration number: [3860/4518] 85% | Training loss: 0.6869980035513794
Epoch: 39 | Iteration number: [3870/4518] 85% | Training loss: 0.6869975247740437
Epoch: 39 | Iteration number: [3880/4518] 85% | Training loss: 0.6870005988890363
Epoch: 39 | Iteration number: [3890/4518] 86% | Training loss: 0.6870020735692856
Epoch: 39 | Iteration number: [3900/4518] 86% | Training loss: 0.6869999076464237
Epoch: 39 | Iteration number: [3910/4518] 86% | Training loss: 0.6870017403379426
Epoch: 39 | Iteration number: [3920/4518] 86% | Training loss: 0.6869990298030327
Epoch: 39 | Iteration number: [3930/4518] 86% | Training loss: 0.6869996404981492
Epoch: 39 | Iteration number: [3940/4518] 87% | Training loss: 0.6870007273811979
Epoch: 39 | Iteration number: [3950/4518] 87% | Training loss: 0.6870019089873833
Epoch: 39 | Iteration number: [3960/4518] 87% | Training loss: 0.6870016506374484
Epoch: 39 | Iteration number: [3970/4518] 87% | Training loss: 0.6869973311196046
Epoch: 39 | Iteration number: [3980/4518] 88% | Training loss: 0.6869978089877709
Epoch: 39 | Iteration number: [3990/4518] 88% | Training loss: 0.6869975740748241
Epoch: 39 | Iteration number: [4000/4518] 88% | Training loss: 0.6869991040080786
Epoch: 39 | Iteration number: [4010/4518] 88% | Training loss: 0.6869953827073152
Epoch: 39 | Iteration number: [4020/4518] 88% | Training loss: 0.6869981278086184
Epoch: 39 | Iteration number: [4030/4518] 89% | Training loss: 0.6869965990483021
Epoch: 39 | Iteration number: [4040/4518] 89% | Training loss: 0.6869941221900505
Epoch: 39 | Iteration number: [4050/4518] 89% | Training loss: 0.686994197839572
Epoch: 39 | Iteration number: [4060/4518] 89% | Training loss: 0.6869929964466048
Epoch: 39 | Iteration number: [4070/4518] 90% | Training loss: 0.6869928620224796
Epoch: 39 | Iteration number: [4080/4518] 90% | Training loss: 0.6869955654237785
Epoch: 39 | Iteration number: [4090/4518] 90% | Training loss: 0.6869940234279865
Epoch: 39 | Iteration number: [4100/4518] 90% | Training loss: 0.6869958723609041
Epoch: 39 | Iteration number: [4110/4518] 90% | Training loss: 0.6869975794405833
Epoch: 39 | Iteration number: [4120/4518] 91% | Training loss: 0.6869963811873232
Epoch: 39 | Iteration number: [4130/4518] 91% | Training loss: 0.6869949359870707
Epoch: 39 | Iteration number: [4140/4518] 91% | Training loss: 0.6869943712788503
Epoch: 39 | Iteration number: [4150/4518] 91% | Training loss: 0.6869952288162278
Epoch: 39 | Iteration number: [4160/4518] 92% | Training loss: 0.6869919622890078
Epoch: 39 | Iteration number: [4170/4518] 92% | Training loss: 0.6869942308186913
Epoch: 39 | Iteration number: [4180/4518] 92% | Training loss: 0.6869928575018376
Epoch: 39 | Iteration number: [4190/4518] 92% | Training loss: 0.6869955336137148
Epoch: 39 | Iteration number: [4200/4518] 92% | Training loss: 0.6869966781848953
Epoch: 39 | Iteration number: [4210/4518] 93% | Training loss: 0.6869948907447824
Epoch: 39 | Iteration number: [4220/4518] 93% | Training loss: 0.6869913203315148
Epoch: 39 | Iteration number: [4230/4518] 93% | Training loss: 0.6869933898003671
Epoch: 39 | Iteration number: [4240/4518] 93% | Training loss: 0.6869917110873843
Epoch: 39 | Iteration number: [4250/4518] 94% | Training loss: 0.6869900854194866
Epoch: 39 | Iteration number: [4260/4518] 94% | Training loss: 0.6869881029280138
Epoch: 39 | Iteration number: [4270/4518] 94% | Training loss: 0.6869874857488226
Epoch: 39 | Iteration number: [4280/4518] 94% | Training loss: 0.6869892042373943
Epoch: 39 | Iteration number: [4290/4518] 94% | Training loss: 0.686991838794766
Epoch: 39 | Iteration number: [4300/4518] 95% | Training loss: 0.6869907168593518
Epoch: 39 | Iteration number: [4310/4518] 95% | Training loss: 0.6869919184465696
Epoch: 39 | Iteration number: [4320/4518] 95% | Training loss: 0.68699083496575
Epoch: 39 | Iteration number: [4330/4518] 95% | Training loss: 0.6869899097683798
Epoch: 39 | Iteration number: [4340/4518] 96% | Training loss: 0.6869920817525705
Epoch: 39 | Iteration number: [4350/4518] 96% | Training loss: 0.6869924870715745
Epoch: 39 | Iteration number: [4360/4518] 96% | Training loss: 0.6869913476322769
Epoch: 39 | Iteration number: [4370/4518] 96% | Training loss: 0.6869913496196406
Epoch: 39 | Iteration number: [4380/4518] 96% | Training loss: 0.6869942567392027
Epoch: 39 | Iteration number: [4390/4518] 97% | Training loss: 0.6869936786507148
Epoch: 39 | Iteration number: [4400/4518] 97% | Training loss: 0.686993549913168
Epoch: 39 | Iteration number: [4410/4518] 97% | Training loss: 0.6869908682072784
Epoch: 39 | Iteration number: [4420/4518] 97% | Training loss: 0.6869905468565306
Epoch: 39 | Iteration number: [4430/4518] 98% | Training loss: 0.6869881723723616
Epoch: 39 | Iteration number: [4440/4518] 98% | Training loss: 0.6869853897943153
Epoch: 39 | Iteration number: [4450/4518] 98% | Training loss: 0.686982472224182
Epoch: 39 | Iteration number: [4460/4518] 98% | Training loss: 0.6869822881948787
Epoch: 39 | Iteration number: [4470/4518] 98% | Training loss: 0.6869832917881226
Epoch: 39 | Iteration number: [4480/4518] 99% | Training loss: 0.6869853030624135
Epoch: 39 | Iteration number: [4490/4518] 99% | Training loss: 0.6869853134277403
Epoch: 39 | Iteration number: [4500/4518] 99% | Training loss: 0.6869869533512327
Epoch: 39 | Iteration number: [4510/4518] 99% | Training loss: 0.6869866540849605

 End of epoch: 39 | Train Loss: 0.6868353768780782 | Training Time: 642 

 End of epoch: 39 | Eval Loss: 0.6902051835644002 | Evaluating Time: 17 
Epoch: 40 | Iteration number: [10/4518] 0% | Training loss: 0.7559169709682465
Epoch: 40 | Iteration number: [20/4518] 0% | Training loss: 0.7208777964115143
Epoch: 40 | Iteration number: [30/4518] 0% | Training loss: 0.7095742066701253
Epoch: 40 | Iteration number: [40/4518] 0% | Training loss: 0.704005540907383
Epoch: 40 | Iteration number: [50/4518] 1% | Training loss: 0.7006911039352417
Epoch: 40 | Iteration number: [60/4518] 1% | Training loss: 0.6984785308440526
Epoch: 40 | Iteration number: [70/4518] 1% | Training loss: 0.6965909438473837
Epoch: 40 | Iteration number: [80/4518] 1% | Training loss: 0.6953674636781215
Epoch: 40 | Iteration number: [90/4518] 1% | Training loss: 0.6943382508224911
Epoch: 40 | Iteration number: [100/4518] 2% | Training loss: 0.6934672713279724
Epoch: 40 | Iteration number: [110/4518] 2% | Training loss: 0.6928622798486189
Epoch: 40 | Iteration number: [120/4518] 2% | Training loss: 0.6923508991797765
Epoch: 40 | Iteration number: [130/4518] 2% | Training loss: 0.6919254784400647
Epoch: 40 | Iteration number: [140/4518] 3% | Training loss: 0.6916466896023069
Epoch: 40 | Iteration number: [150/4518] 3% | Training loss: 0.6913229378064474
Epoch: 40 | Iteration number: [160/4518] 3% | Training loss: 0.6911404319107533
Epoch: 40 | Iteration number: [170/4518] 3% | Training loss: 0.691010606990141
Epoch: 40 | Iteration number: [180/4518] 3% | Training loss: 0.6907782557937834
Epoch: 40 | Iteration number: [190/4518] 4% | Training loss: 0.6906034431959454
Epoch: 40 | Iteration number: [200/4518] 4% | Training loss: 0.6904001852869988
Epoch: 40 | Iteration number: [210/4518] 4% | Training loss: 0.6902315270333063
Epoch: 40 | Iteration number: [220/4518] 4% | Training loss: 0.6900536631995982
Epoch: 40 | Iteration number: [230/4518] 5% | Training loss: 0.6898845727029054
Epoch: 40 | Iteration number: [240/4518] 5% | Training loss: 0.6897459643582503
Epoch: 40 | Iteration number: [250/4518] 5% | Training loss: 0.6895666823387147
Epoch: 40 | Iteration number: [260/4518] 5% | Training loss: 0.6894649260319197
Epoch: 40 | Iteration number: [270/4518] 5% | Training loss: 0.6893314599990845
Epoch: 40 | Iteration number: [280/4518] 6% | Training loss: 0.6892667798059328
Epoch: 40 | Iteration number: [290/4518] 6% | Training loss: 0.6891926477695334
Epoch: 40 | Iteration number: [300/4518] 6% | Training loss: 0.6890862433115641
Epoch: 40 | Iteration number: [310/4518] 6% | Training loss: 0.6890602865526753
Epoch: 40 | Iteration number: [320/4518] 7% | Training loss: 0.6890023132786155
Epoch: 40 | Iteration number: [330/4518] 7% | Training loss: 0.6889375404878096
Epoch: 40 | Iteration number: [340/4518] 7% | Training loss: 0.6888550311326981
Epoch: 40 | Iteration number: [350/4518] 7% | Training loss: 0.6888424258572715
Epoch: 40 | Iteration number: [360/4518] 7% | Training loss: 0.6887769614656766
Epoch: 40 | Iteration number: [370/4518] 8% | Training loss: 0.6887134837137686
Epoch: 40 | Iteration number: [380/4518] 8% | Training loss: 0.6886634138069655
Epoch: 40 | Iteration number: [390/4518] 8% | Training loss: 0.6886091670928858
Epoch: 40 | Iteration number: [400/4518] 8% | Training loss: 0.6885523639619351
Epoch: 40 | Iteration number: [410/4518] 9% | Training loss: 0.6884910903325895
Epoch: 40 | Iteration number: [420/4518] 9% | Training loss: 0.6884229120754061
Epoch: 40 | Iteration number: [430/4518] 9% | Training loss: 0.6883818426797557
Epoch: 40 | Iteration number: [440/4518] 9% | Training loss: 0.6883385288444432
Epoch: 40 | Iteration number: [450/4518] 9% | Training loss: 0.6882834026548598
Epoch: 40 | Iteration number: [460/4518] 10% | Training loss: 0.6882268119117488
Epoch: 40 | Iteration number: [470/4518] 10% | Training loss: 0.6881748138590061
Epoch: 40 | Iteration number: [480/4518] 10% | Training loss: 0.6881512999534607
Epoch: 40 | Iteration number: [490/4518] 10% | Training loss: 0.6881441713595877
Epoch: 40 | Iteration number: [500/4518] 11% | Training loss: 0.6881355638504029
Epoch: 40 | Iteration number: [510/4518] 11% | Training loss: 0.6881070063394659
Epoch: 40 | Iteration number: [520/4518] 11% | Training loss: 0.6880707337306096
Epoch: 40 | Iteration number: [530/4518] 11% | Training loss: 0.6880481862796928
Epoch: 40 | Iteration number: [540/4518] 11% | Training loss: 0.6880196881515008
Epoch: 40 | Iteration number: [550/4518] 12% | Training loss: 0.688009977015582
Epoch: 40 | Iteration number: [560/4518] 12% | Training loss: 0.6879953561084611
Epoch: 40 | Iteration number: [570/4518] 12% | Training loss: 0.6879682699839275
Epoch: 40 | Iteration number: [580/4518] 12% | Training loss: 0.687973249164121
Epoch: 40 | Iteration number: [590/4518] 13% | Training loss: 0.6879560205896021
Epoch: 40 | Iteration number: [600/4518] 13% | Training loss: 0.687957348326842
Epoch: 40 | Iteration number: [610/4518] 13% | Training loss: 0.6879446939366762
Epoch: 40 | Iteration number: [620/4518] 13% | Training loss: 0.6879015769689314
Epoch: 40 | Iteration number: [630/4518] 13% | Training loss: 0.6878894425573803
Epoch: 40 | Iteration number: [640/4518] 14% | Training loss: 0.6878970461897552
Epoch: 40 | Iteration number: [650/4518] 14% | Training loss: 0.6878796494924105
Epoch: 40 | Iteration number: [660/4518] 14% | Training loss: 0.6878749577385006
Epoch: 40 | Iteration number: [670/4518] 14% | Training loss: 0.6878421550366416
Epoch: 40 | Iteration number: [680/4518] 15% | Training loss: 0.6878141484716359
Epoch: 40 | Iteration number: [690/4518] 15% | Training loss: 0.6877744678137959
Epoch: 40 | Iteration number: [700/4518] 15% | Training loss: 0.6877724509579795
Epoch: 40 | Iteration number: [710/4518] 15% | Training loss: 0.6877785116853848
Epoch: 40 | Iteration number: [720/4518] 15% | Training loss: 0.687761871682273
Epoch: 40 | Iteration number: [730/4518] 16% | Training loss: 0.6877612020871411
Epoch: 40 | Iteration number: [740/4518] 16% | Training loss: 0.6877410046957635
Epoch: 40 | Iteration number: [750/4518] 16% | Training loss: 0.6877271912097931
Epoch: 40 | Iteration number: [760/4518] 16% | Training loss: 0.687707449809501
Epoch: 40 | Iteration number: [770/4518] 17% | Training loss: 0.6876914005774957
Epoch: 40 | Iteration number: [780/4518] 17% | Training loss: 0.6876792558492758
Epoch: 40 | Iteration number: [790/4518] 17% | Training loss: 0.6876701376106166
Epoch: 40 | Iteration number: [800/4518] 17% | Training loss: 0.6876584073156118
Epoch: 40 | Iteration number: [810/4518] 17% | Training loss: 0.6876367775010473
Epoch: 40 | Iteration number: [820/4518] 18% | Training loss: 0.6876151268802038
Epoch: 40 | Iteration number: [830/4518] 18% | Training loss: 0.687608835567911
Epoch: 40 | Iteration number: [840/4518] 18% | Training loss: 0.6875981362802642
Epoch: 40 | Iteration number: [850/4518] 18% | Training loss: 0.6875769073822919
Epoch: 40 | Iteration number: [860/4518] 19% | Training loss: 0.6875677214112392
Epoch: 40 | Iteration number: [870/4518] 19% | Training loss: 0.6875660998382788
Epoch: 40 | Iteration number: [880/4518] 19% | Training loss: 0.6875572934069417
Epoch: 40 | Iteration number: [890/4518] 19% | Training loss: 0.6875402082218213
Epoch: 40 | Iteration number: [900/4518] 19% | Training loss: 0.6875446491109001
Epoch: 40 | Iteration number: [910/4518] 20% | Training loss: 0.6875313960588896
Epoch: 40 | Iteration number: [920/4518] 20% | Training loss: 0.6875179363333661
Epoch: 40 | Iteration number: [930/4518] 20% | Training loss: 0.6874933494675544
Epoch: 40 | Iteration number: [940/4518] 20% | Training loss: 0.687478752022094
Epoch: 40 | Iteration number: [950/4518] 21% | Training loss: 0.6874804861294596
Epoch: 40 | Iteration number: [960/4518] 21% | Training loss: 0.687471802594761
Epoch: 40 | Iteration number: [970/4518] 21% | Training loss: 0.6874733431437581
Epoch: 40 | Iteration number: [980/4518] 21% | Training loss: 0.6874779580198989
Epoch: 40 | Iteration number: [990/4518] 21% | Training loss: 0.6874754168168463
Epoch: 40 | Iteration number: [1000/4518] 22% | Training loss: 0.68747534263134
Epoch: 40 | Iteration number: [1010/4518] 22% | Training loss: 0.6874643938376171
Epoch: 40 | Iteration number: [1020/4518] 22% | Training loss: 0.687459959937077
Epoch: 40 | Iteration number: [1030/4518] 22% | Training loss: 0.6874569990102527
Epoch: 40 | Iteration number: [1040/4518] 23% | Training loss: 0.6874348937318875
Epoch: 40 | Iteration number: [1050/4518] 23% | Training loss: 0.687436781213397
Epoch: 40 | Iteration number: [1060/4518] 23% | Training loss: 0.6874337510117945
Epoch: 40 | Iteration number: [1070/4518] 23% | Training loss: 0.6874317426547826
Epoch: 40 | Iteration number: [1080/4518] 23% | Training loss: 0.6874290987849235
Epoch: 40 | Iteration number: [1090/4518] 24% | Training loss: 0.6874193200277626
Epoch: 40 | Iteration number: [1100/4518] 24% | Training loss: 0.6874149693142284
Epoch: 40 | Iteration number: [1110/4518] 24% | Training loss: 0.6874208073358278
Epoch: 40 | Iteration number: [1120/4518] 24% | Training loss: 0.6874145305582455
Epoch: 40 | Iteration number: [1130/4518] 25% | Training loss: 0.6874044008487094
Epoch: 40 | Iteration number: [1140/4518] 25% | Training loss: 0.6874001004716807
Epoch: 40 | Iteration number: [1150/4518] 25% | Training loss: 0.6873827991796576
Epoch: 40 | Iteration number: [1160/4518] 25% | Training loss: 0.6873852067466439
Epoch: 40 | Iteration number: [1170/4518] 25% | Training loss: 0.687384420225763
Epoch: 40 | Iteration number: [1180/4518] 26% | Training loss: 0.6873805346125264
Epoch: 40 | Iteration number: [1190/4518] 26% | Training loss: 0.6873839114894386
Epoch: 40 | Iteration number: [1200/4518] 26% | Training loss: 0.6873662596940995
Epoch: 40 | Iteration number: [1210/4518] 26% | Training loss: 0.6873612546723736
Epoch: 40 | Iteration number: [1220/4518] 27% | Training loss: 0.6873610663609426
Epoch: 40 | Iteration number: [1230/4518] 27% | Training loss: 0.687354433875743
Epoch: 40 | Iteration number: [1240/4518] 27% | Training loss: 0.6873617206369677
Epoch: 40 | Iteration number: [1250/4518] 27% | Training loss: 0.6873627348423004
Epoch: 40 | Iteration number: [1260/4518] 27% | Training loss: 0.6873594318590467
Epoch: 40 | Iteration number: [1270/4518] 28% | Training loss: 0.6873549771590496
Epoch: 40 | Iteration number: [1280/4518] 28% | Training loss: 0.6873564769513905
Epoch: 40 | Iteration number: [1290/4518] 28% | Training loss: 0.6873530258503995
Epoch: 40 | Iteration number: [1300/4518] 28% | Training loss: 0.6873452474979254
Epoch: 40 | Iteration number: [1310/4518] 28% | Training loss: 0.6873322462762586
Epoch: 40 | Iteration number: [1320/4518] 29% | Training loss: 0.6873254633311069
Epoch: 40 | Iteration number: [1330/4518] 29% | Training loss: 0.6873214462197813
Epoch: 40 | Iteration number: [1340/4518] 29% | Training loss: 0.687314824915644
Epoch: 40 | Iteration number: [1350/4518] 29% | Training loss: 0.6873081774623305
Epoch: 40 | Iteration number: [1360/4518] 30% | Training loss: 0.6873166572959984
Epoch: 40 | Iteration number: [1370/4518] 30% | Training loss: 0.6873072243519943
Epoch: 40 | Iteration number: [1380/4518] 30% | Training loss: 0.6873069375753402
Epoch: 40 | Iteration number: [1390/4518] 30% | Training loss: 0.6873135050423711
Epoch: 40 | Iteration number: [1400/4518] 30% | Training loss: 0.6873071931941168
Epoch: 40 | Iteration number: [1410/4518] 31% | Training loss: 0.687303956096054
Epoch: 40 | Iteration number: [1420/4518] 31% | Training loss: 0.687291824649757
Epoch: 40 | Iteration number: [1430/4518] 31% | Training loss: 0.6872956048775386
Epoch: 40 | Iteration number: [1440/4518] 31% | Training loss: 0.6872886628326442
Epoch: 40 | Iteration number: [1450/4518] 32% | Training loss: 0.6872911669879124
Epoch: 40 | Iteration number: [1460/4518] 32% | Training loss: 0.6872936103033693
Epoch: 40 | Iteration number: [1470/4518] 32% | Training loss: 0.6872901750259659
Epoch: 40 | Iteration number: [1480/4518] 32% | Training loss: 0.6872856964533394
Epoch: 40 | Iteration number: [1490/4518] 32% | Training loss: 0.6872846256566528
Epoch: 40 | Iteration number: [1500/4518] 33% | Training loss: 0.6872901542186737
Epoch: 40 | Iteration number: [1510/4518] 33% | Training loss: 0.6872903335568131
Epoch: 40 | Iteration number: [1520/4518] 33% | Training loss: 0.6872918462282733
Epoch: 40 | Iteration number: [1530/4518] 33% | Training loss: 0.6872886514352038
Epoch: 40 | Iteration number: [1540/4518] 34% | Training loss: 0.687282554476292
Epoch: 40 | Iteration number: [1550/4518] 34% | Training loss: 0.6872783152134188
Epoch: 40 | Iteration number: [1560/4518] 34% | Training loss: 0.6872781080695299
Epoch: 40 | Iteration number: [1570/4518] 34% | Training loss: 0.6872758271587882
Epoch: 40 | Iteration number: [1580/4518] 34% | Training loss: 0.6872701255581047
Epoch: 40 | Iteration number: [1590/4518] 35% | Training loss: 0.6872640768686931
Epoch: 40 | Iteration number: [1600/4518] 35% | Training loss: 0.6872563396394252
Epoch: 40 | Iteration number: [1610/4518] 35% | Training loss: 0.6872516469925827
Epoch: 40 | Iteration number: [1620/4518] 35% | Training loss: 0.6872486153870453
Epoch: 40 | Iteration number: [1630/4518] 36% | Training loss: 0.68725358554922
Epoch: 40 | Iteration number: [1640/4518] 36% | Training loss: 0.6872509637620391
Epoch: 40 | Iteration number: [1650/4518] 36% | Training loss: 0.6872406277150819
Epoch: 40 | Iteration number: [1660/4518] 36% | Training loss: 0.6872391906488373
Epoch: 40 | Iteration number: [1670/4518] 36% | Training loss: 0.6872291228014552
Epoch: 40 | Iteration number: [1680/4518] 37% | Training loss: 0.687227147569259
Epoch: 40 | Iteration number: [1690/4518] 37% | Training loss: 0.6872303514085578
Epoch: 40 | Iteration number: [1700/4518] 37% | Training loss: 0.687227928112535
Epoch: 40 | Iteration number: [1710/4518] 37% | Training loss: 0.6872281692878545
Epoch: 40 | Iteration number: [1720/4518] 38% | Training loss: 0.6872253214550573
Epoch: 40 | Iteration number: [1730/4518] 38% | Training loss: 0.6872214062710029
Epoch: 40 | Iteration number: [1740/4518] 38% | Training loss: 0.6872200356132683
Epoch: 40 | Iteration number: [1750/4518] 38% | Training loss: 0.6872205319404602
Epoch: 40 | Iteration number: [1760/4518] 38% | Training loss: 0.6872132531959902
Epoch: 40 | Iteration number: [1770/4518] 39% | Training loss: 0.6872144617940072
Epoch: 40 | Iteration number: [1780/4518] 39% | Training loss: 0.6872149970424309
Epoch: 40 | Iteration number: [1790/4518] 39% | Training loss: 0.6872195042045423
Epoch: 40 | Iteration number: [1800/4518] 39% | Training loss: 0.6872194837530454
Epoch: 40 | Iteration number: [1810/4518] 40% | Training loss: 0.6872211019637177
Epoch: 40 | Iteration number: [1820/4518] 40% | Training loss: 0.6872189089492127
Epoch: 40 | Iteration number: [1830/4518] 40% | Training loss: 0.6872213277009016
Epoch: 40 | Iteration number: [1840/4518] 40% | Training loss: 0.6872254375206388
Epoch: 40 | Iteration number: [1850/4518] 40% | Training loss: 0.6872242886311299
Epoch: 40 | Iteration number: [1860/4518] 41% | Training loss: 0.6872258133144789
Epoch: 40 | Iteration number: [1870/4518] 41% | Training loss: 0.687224611305298
Epoch: 40 | Iteration number: [1880/4518] 41% | Training loss: 0.6872212777429438
Epoch: 40 | Iteration number: [1890/4518] 41% | Training loss: 0.6872146778005771
Epoch: 40 | Iteration number: [1900/4518] 42% | Training loss: 0.687210336735374
Epoch: 40 | Iteration number: [1910/4518] 42% | Training loss: 0.687206449277738
Epoch: 40 | Iteration number: [1920/4518] 42% | Training loss: 0.6872013451841971
Epoch: 40 | Iteration number: [1930/4518] 42% | Training loss: 0.6872013500626223
Epoch: 40 | Iteration number: [1940/4518] 42% | Training loss: 0.6872037193209855
Epoch: 40 | Iteration number: [1950/4518] 43% | Training loss: 0.6872058819196163
Epoch: 40 | Iteration number: [1960/4518] 43% | Training loss: 0.6872033700346947
Epoch: 40 | Iteration number: [1970/4518] 43% | Training loss: 0.6872019237673223
Epoch: 40 | Iteration number: [1980/4518] 43% | Training loss: 0.6872014083344526
Epoch: 40 | Iteration number: [1990/4518] 44% | Training loss: 0.6872010910331304
Epoch: 40 | Iteration number: [2000/4518] 44% | Training loss: 0.6871951866447925
Epoch: 40 | Iteration number: [2010/4518] 44% | Training loss: 0.6871929263594139
Epoch: 40 | Iteration number: [2020/4518] 44% | Training loss: 0.6871958561758004
Epoch: 40 | Iteration number: [2030/4518] 44% | Training loss: 0.6871860885561394
Epoch: 40 | Iteration number: [2040/4518] 45% | Training loss: 0.6871830088835137
Epoch: 40 | Iteration number: [2050/4518] 45% | Training loss: 0.6871901531917293
Epoch: 40 | Iteration number: [2060/4518] 45% | Training loss: 0.6871873970170623
Epoch: 40 | Iteration number: [2070/4518] 45% | Training loss: 0.6871847646535882
Epoch: 40 | Iteration number: [2080/4518] 46% | Training loss: 0.6871796875332411
Epoch: 40 | Iteration number: [2090/4518] 46% | Training loss: 0.6871812129705146
Epoch: 40 | Iteration number: [2100/4518] 46% | Training loss: 0.6871768135683877
Epoch: 40 | Iteration number: [2110/4518] 46% | Training loss: 0.6871755010426327
Epoch: 40 | Iteration number: [2120/4518] 46% | Training loss: 0.6871720373068215
Epoch: 40 | Iteration number: [2130/4518] 47% | Training loss: 0.6871714390779325
Epoch: 40 | Iteration number: [2140/4518] 47% | Training loss: 0.6871702728984512
Epoch: 40 | Iteration number: [2150/4518] 47% | Training loss: 0.6871671908123549
Epoch: 40 | Iteration number: [2160/4518] 47% | Training loss: 0.6871660787474226
Epoch: 40 | Iteration number: [2170/4518] 48% | Training loss: 0.6871601546414986
Epoch: 40 | Iteration number: [2180/4518] 48% | Training loss: 0.6871614757754387
Epoch: 40 | Iteration number: [2190/4518] 48% | Training loss: 0.6871645930423039
Epoch: 40 | Iteration number: [2200/4518] 48% | Training loss: 0.6871653126857498
Epoch: 40 | Iteration number: [2210/4518] 48% | Training loss: 0.6871663319579077
Epoch: 40 | Iteration number: [2220/4518] 49% | Training loss: 0.6871625874225084
Epoch: 40 | Iteration number: [2230/4518] 49% | Training loss: 0.6871570354085332
Epoch: 40 | Iteration number: [2240/4518] 49% | Training loss: 0.6871565329709224
Epoch: 40 | Iteration number: [2250/4518] 49% | Training loss: 0.6871550555229187
Epoch: 40 | Iteration number: [2260/4518] 50% | Training loss: 0.687151188053916
Epoch: 40 | Iteration number: [2270/4518] 50% | Training loss: 0.6871423440095087
Epoch: 40 | Iteration number: [2280/4518] 50% | Training loss: 0.6871406331135516
Epoch: 40 | Iteration number: [2290/4518] 50% | Training loss: 0.6871397315414712
Epoch: 40 | Iteration number: [2300/4518] 50% | Training loss: 0.6871372459504915
Epoch: 40 | Iteration number: [2310/4518] 51% | Training loss: 0.6871365051764946
Epoch: 40 | Iteration number: [2320/4518] 51% | Training loss: 0.6871339385622535
Epoch: 40 | Iteration number: [2330/4518] 51% | Training loss: 0.6871319419324654
Epoch: 40 | Iteration number: [2340/4518] 51% | Training loss: 0.687131143711571
Epoch: 40 | Iteration number: [2350/4518] 52% | Training loss: 0.6871379631630918
Epoch: 40 | Iteration number: [2360/4518] 52% | Training loss: 0.6871405105217029
Epoch: 40 | Iteration number: [2370/4518] 52% | Training loss: 0.68713596493383
Epoch: 40 | Iteration number: [2380/4518] 52% | Training loss: 0.6871404022980137
Epoch: 40 | Iteration number: [2390/4518] 52% | Training loss: 0.6871414952946507
Epoch: 40 | Iteration number: [2400/4518] 53% | Training loss: 0.6871418561041355
Epoch: 40 | Iteration number: [2410/4518] 53% | Training loss: 0.6871400309548833
Epoch: 40 | Iteration number: [2420/4518] 53% | Training loss: 0.6871360145078218
Epoch: 40 | Iteration number: [2430/4518] 53% | Training loss: 0.6871347173741815
Epoch: 40 | Iteration number: [2440/4518] 54% | Training loss: 0.6871318235749104
Epoch: 40 | Iteration number: [2450/4518] 54% | Training loss: 0.6871318931238992
Epoch: 40 | Iteration number: [2460/4518] 54% | Training loss: 0.6871283310700238
Epoch: 40 | Iteration number: [2470/4518] 54% | Training loss: 0.6871282880364159
Epoch: 40 | Iteration number: [2480/4518] 54% | Training loss: 0.6871248656463238
Epoch: 40 | Iteration number: [2490/4518] 55% | Training loss: 0.68712184275968
Epoch: 40 | Iteration number: [2500/4518] 55% | Training loss: 0.6871171920776368
Epoch: 40 | Iteration number: [2510/4518] 55% | Training loss: 0.6871116633671689
Epoch: 40 | Iteration number: [2520/4518] 55% | Training loss: 0.687107880886585
Epoch: 40 | Iteration number: [2530/4518] 55% | Training loss: 0.6871088382519281
Epoch: 40 | Iteration number: [2540/4518] 56% | Training loss: 0.6871049178866889
Epoch: 40 | Iteration number: [2550/4518] 56% | Training loss: 0.6871044211060393
Epoch: 40 | Iteration number: [2560/4518] 56% | Training loss: 0.6871056878939271
Epoch: 40 | Iteration number: [2570/4518] 56% | Training loss: 0.6871025953543325
Epoch: 40 | Iteration number: [2580/4518] 57% | Training loss: 0.6871009104935698
Epoch: 40 | Iteration number: [2590/4518] 57% | Training loss: 0.6871011697417521
Epoch: 40 | Iteration number: [2600/4518] 57% | Training loss: 0.6871043205490479
Epoch: 40 | Iteration number: [2610/4518] 57% | Training loss: 0.6871056344317293
Epoch: 40 | Iteration number: [2620/4518] 57% | Training loss: 0.6871054733300027
Epoch: 40 | Iteration number: [2630/4518] 58% | Training loss: 0.6871048438911656
Epoch: 40 | Iteration number: [2640/4518] 58% | Training loss: 0.6871092900633812
Epoch: 40 | Iteration number: [2650/4518] 58% | Training loss: 0.6871140156152113
Epoch: 40 | Iteration number: [2660/4518] 58% | Training loss: 0.6871128946542739
Epoch: 40 | Iteration number: [2670/4518] 59% | Training loss: 0.6871117988106017
Epoch: 40 | Iteration number: [2680/4518] 59% | Training loss: 0.6871112031945542
Epoch: 40 | Iteration number: [2690/4518] 59% | Training loss: 0.6871110300370752
Epoch: 40 | Iteration number: [2700/4518] 59% | Training loss: 0.6871113895928418
Epoch: 40 | Iteration number: [2710/4518] 59% | Training loss: 0.687109262806903
Epoch: 40 | Iteration number: [2720/4518] 60% | Training loss: 0.6871110210743021
Epoch: 40 | Iteration number: [2730/4518] 60% | Training loss: 0.6871091287214678
Epoch: 40 | Iteration number: [2740/4518] 60% | Training loss: 0.6871158449319157
Epoch: 40 | Iteration number: [2750/4518] 60% | Training loss: 0.6871112817417492
Epoch: 40 | Iteration number: [2760/4518] 61% | Training loss: 0.68711257322111
Epoch: 40 | Iteration number: [2770/4518] 61% | Training loss: 0.6871095415702365
Epoch: 40 | Iteration number: [2780/4518] 61% | Training loss: 0.6871128851346833
Epoch: 40 | Iteration number: [2790/4518] 61% | Training loss: 0.6871078443783586
Epoch: 40 | Iteration number: [2800/4518] 61% | Training loss: 0.6870998490282467
Epoch: 40 | Iteration number: [2810/4518] 62% | Training loss: 0.6870970361809714
Epoch: 40 | Iteration number: [2820/4518] 62% | Training loss: 0.687098492143002
Epoch: 40 | Iteration number: [2830/4518] 62% | Training loss: 0.6871009828345093
Epoch: 40 | Iteration number: [2840/4518] 62% | Training loss: 0.6871007512153035
Epoch: 40 | Iteration number: [2850/4518] 63% | Training loss: 0.6871035037960922
Epoch: 40 | Iteration number: [2860/4518] 63% | Training loss: 0.6871011502050853
Epoch: 40 | Iteration number: [2870/4518] 63% | Training loss: 0.687101631775135
Epoch: 40 | Iteration number: [2880/4518] 63% | Training loss: 0.6871028134806288
Epoch: 40 | Iteration number: [2890/4518] 63% | Training loss: 0.687103590482659
Epoch: 40 | Iteration number: [2900/4518] 64% | Training loss: 0.6870986360722575
Epoch: 40 | Iteration number: [2910/4518] 64% | Training loss: 0.6870969679552256
Epoch: 40 | Iteration number: [2920/4518] 64% | Training loss: 0.6870903367457325
Epoch: 40 | Iteration number: [2930/4518] 64% | Training loss: 0.6870862563518941
Epoch: 40 | Iteration number: [2940/4518] 65% | Training loss: 0.6870829246076596
Epoch: 40 | Iteration number: [2950/4518] 65% | Training loss: 0.6870815973160631
Epoch: 40 | Iteration number: [2960/4518] 65% | Training loss: 0.687079099726838
Epoch: 40 | Iteration number: [2970/4518] 65% | Training loss: 0.6870785770191488
Epoch: 40 | Iteration number: [2980/4518] 65% | Training loss: 0.6870825763316762
Epoch: 40 | Iteration number: [2990/4518] 66% | Training loss: 0.6870868729109748
Epoch: 40 | Iteration number: [3000/4518] 66% | Training loss: 0.6870863554477692
Epoch: 40 | Iteration number: [3010/4518] 66% | Training loss: 0.6870834382071448
Epoch: 40 | Iteration number: [3020/4518] 66% | Training loss: 0.687082561021609
Epoch: 40 | Iteration number: [3030/4518] 67% | Training loss: 0.6870833097904823
Epoch: 40 | Iteration number: [3040/4518] 67% | Training loss: 0.6870805781334639
Epoch: 40 | Iteration number: [3050/4518] 67% | Training loss: 0.6870806408123892
Epoch: 40 | Iteration number: [3060/4518] 67% | Training loss: 0.6870792453390321
Epoch: 40 | Iteration number: [3070/4518] 67% | Training loss: 0.6870809832108525
Epoch: 40 | Iteration number: [3080/4518] 68% | Training loss: 0.6870809266319523
Epoch: 40 | Iteration number: [3090/4518] 68% | Training loss: 0.6870778073192029
Epoch: 40 | Iteration number: [3100/4518] 68% | Training loss: 0.6870816570328128
Epoch: 40 | Iteration number: [3110/4518] 68% | Training loss: 0.687081026398484
Epoch: 40 | Iteration number: [3120/4518] 69% | Training loss: 0.6870781781199651
Epoch: 40 | Iteration number: [3130/4518] 69% | Training loss: 0.6870754758389994
Epoch: 40 | Iteration number: [3140/4518] 69% | Training loss: 0.6870777077545785
Epoch: 40 | Iteration number: [3150/4518] 69% | Training loss: 0.6870752052466075
Epoch: 40 | Iteration number: [3160/4518] 69% | Training loss: 0.6870759586367426
Epoch: 40 | Iteration number: [3170/4518] 70% | Training loss: 0.6870740794044939
Epoch: 40 | Iteration number: [3180/4518] 70% | Training loss: 0.6870714989848107
Epoch: 40 | Iteration number: [3190/4518] 70% | Training loss: 0.6870728834856267
Epoch: 40 | Iteration number: [3200/4518] 70% | Training loss: 0.6870751850865782
Epoch: 40 | Iteration number: [3210/4518] 71% | Training loss: 0.6870758370075641
Epoch: 40 | Iteration number: [3220/4518] 71% | Training loss: 0.6870721377015854
Epoch: 40 | Iteration number: [3230/4518] 71% | Training loss: 0.6870701342359785
Epoch: 40 | Iteration number: [3240/4518] 71% | Training loss: 0.6870637428981287
Epoch: 40 | Iteration number: [3250/4518] 71% | Training loss: 0.6870610179350927
Epoch: 40 | Iteration number: [3260/4518] 72% | Training loss: 0.6870608478784561
Epoch: 40 | Iteration number: [3270/4518] 72% | Training loss: 0.68706420459514
Epoch: 40 | Iteration number: [3280/4518] 72% | Training loss: 0.6870617492715033
Epoch: 40 | Iteration number: [3290/4518] 72% | Training loss: 0.6870646725128486
Epoch: 40 | Iteration number: [3300/4518] 73% | Training loss: 0.6870660548137896
Epoch: 40 | Iteration number: [3310/4518] 73% | Training loss: 0.6870663230332723
Epoch: 40 | Iteration number: [3320/4518] 73% | Training loss: 0.6870631656014775
Epoch: 40 | Iteration number: [3330/4518] 73% | Training loss: 0.6870634179036539
Epoch: 40 | Iteration number: [3340/4518] 73% | Training loss: 0.6870647370815277
Epoch: 40 | Iteration number: [3350/4518] 74% | Training loss: 0.6870672617207713
Epoch: 40 | Iteration number: [3360/4518] 74% | Training loss: 0.6870694491302684
Epoch: 40 | Iteration number: [3370/4518] 74% | Training loss: 0.6870689116705773
Epoch: 40 | Iteration number: [3380/4518] 74% | Training loss: 0.6870664126774263
Epoch: 40 | Iteration number: [3390/4518] 75% | Training loss: 0.6870640894832161
Epoch: 40 | Iteration number: [3400/4518] 75% | Training loss: 0.6870648823941455
Epoch: 40 | Iteration number: [3410/4518] 75% | Training loss: 0.6870622429330328
Epoch: 40 | Iteration number: [3420/4518] 75% | Training loss: 0.687062277936796
Epoch: 40 | Iteration number: [3430/4518] 75% | Training loss: 0.6870619899677466
Epoch: 40 | Iteration number: [3440/4518] 76% | Training loss: 0.6870622895831285
Epoch: 40 | Iteration number: [3450/4518] 76% | Training loss: 0.6870601039865742
Epoch: 40 | Iteration number: [3460/4518] 76% | Training loss: 0.6870624137579361
Epoch: 40 | Iteration number: [3470/4518] 76% | Training loss: 0.6870598928213807
Epoch: 40 | Iteration number: [3480/4518] 77% | Training loss: 0.6870568500168022
Epoch: 40 | Iteration number: [3490/4518] 77% | Training loss: 0.6870550896684214
Epoch: 40 | Iteration number: [3500/4518] 77% | Training loss: 0.6870534427506583
Epoch: 40 | Iteration number: [3510/4518] 77% | Training loss: 0.68705356253518
Epoch: 40 | Iteration number: [3520/4518] 77% | Training loss: 0.6870521342381835
Epoch: 40 | Iteration number: [3530/4518] 78% | Training loss: 0.6870471666284729
Epoch: 40 | Iteration number: [3540/4518] 78% | Training loss: 0.6870412415535436
Epoch: 40 | Iteration number: [3550/4518] 78% | Training loss: 0.6870391418732388
Epoch: 40 | Iteration number: [3560/4518] 78% | Training loss: 0.6870378194565183
Epoch: 40 | Iteration number: [3570/4518] 79% | Training loss: 0.6870387608597592
Epoch: 40 | Iteration number: [3580/4518] 79% | Training loss: 0.6870357076715491
Epoch: 40 | Iteration number: [3590/4518] 79% | Training loss: 0.6870342777133984
Epoch: 40 | Iteration number: [3600/4518] 79% | Training loss: 0.6870333012276225
Epoch: 40 | Iteration number: [3610/4518] 79% | Training loss: 0.6870312943352886
Epoch: 40 | Iteration number: [3620/4518] 80% | Training loss: 0.6870307592561891
Epoch: 40 | Iteration number: [3630/4518] 80% | Training loss: 0.6870305395487583
Epoch: 40 | Iteration number: [3640/4518] 80% | Training loss: 0.6870318820679581
Epoch: 40 | Iteration number: [3650/4518] 80% | Training loss: 0.6870288316191059
Epoch: 40 | Iteration number: [3660/4518] 81% | Training loss: 0.6870297032138689
Epoch: 40 | Iteration number: [3670/4518] 81% | Training loss: 0.6870289021032058
Epoch: 40 | Iteration number: [3680/4518] 81% | Training loss: 0.6870266329497099
Epoch: 40 | Iteration number: [3690/4518] 81% | Training loss: 0.6870234741589565
Epoch: 40 | Iteration number: [3700/4518] 81% | Training loss: 0.687020590466422
Epoch: 40 | Iteration number: [3710/4518] 82% | Training loss: 0.6870168021265066
Epoch: 40 | Iteration number: [3720/4518] 82% | Training loss: 0.6870148321153016
Epoch: 40 | Iteration number: [3730/4518] 82% | Training loss: 0.6870136235258855
Epoch: 40 | Iteration number: [3740/4518] 82% | Training loss: 0.6870103787451505
Epoch: 40 | Iteration number: [3750/4518] 83% | Training loss: 0.687009193833669
Epoch: 40 | Iteration number: [3760/4518] 83% | Training loss: 0.6870097939321336
Epoch: 40 | Iteration number: [3770/4518] 83% | Training loss: 0.6870071586784696
Epoch: 40 | Iteration number: [3780/4518] 83% | Training loss: 0.6870052076994426
Epoch: 40 | Iteration number: [3790/4518] 83% | Training loss: 0.6870053900892313
Epoch: 40 | Iteration number: [3800/4518] 84% | Training loss: 0.6870052087150122
Epoch: 40 | Iteration number: [3810/4518] 84% | Training loss: 0.6870062503914821
Epoch: 40 | Iteration number: [3820/4518] 84% | Training loss: 0.6870079210291358
Epoch: 40 | Iteration number: [3830/4518] 84% | Training loss: 0.6870083080570629
Epoch: 40 | Iteration number: [3840/4518] 84% | Training loss: 0.6870081078261137
Epoch: 40 | Iteration number: [3850/4518] 85% | Training loss: 0.6870063992134936
Epoch: 40 | Iteration number: [3860/4518] 85% | Training loss: 0.6870066452983747
Epoch: 40 | Iteration number: [3870/4518] 85% | Training loss: 0.6870060183589156
Epoch: 40 | Iteration number: [3880/4518] 85% | Training loss: 0.6870102688977399
Epoch: 40 | Iteration number: [3890/4518] 86% | Training loss: 0.6870106107777986
Epoch: 40 | Iteration number: [3900/4518] 86% | Training loss: 0.687009641115482
Epoch: 40 | Iteration number: [3910/4518] 86% | Training loss: 0.6870081155806246
Epoch: 40 | Iteration number: [3920/4518] 86% | Training loss: 0.6870089434847539
Epoch: 40 | Iteration number: [3930/4518] 86% | Training loss: 0.6870108004138064
Epoch: 40 | Iteration number: [3940/4518] 87% | Training loss: 0.6870054381601701
Epoch: 40 | Iteration number: [3950/4518] 87% | Training loss: 0.6870075982431822
Epoch: 40 | Iteration number: [3960/4518] 87% | Training loss: 0.6870060191762568
Epoch: 40 | Iteration number: [3970/4518] 87% | Training loss: 0.6870051959599897
Epoch: 40 | Iteration number: [3980/4518] 88% | Training loss: 0.687004492795048
Epoch: 40 | Iteration number: [3990/4518] 88% | Training loss: 0.6870050705614544
Epoch: 40 | Iteration number: [4000/4518] 88% | Training loss: 0.6870056531727314
Epoch: 40 | Iteration number: [4010/4518] 88% | Training loss: 0.6870063255106719
Epoch: 40 | Iteration number: [4020/4518] 88% | Training loss: 0.687007050549806
Epoch: 40 | Iteration number: [4030/4518] 89% | Training loss: 0.6870069777255614
Epoch: 40 | Iteration number: [4040/4518] 89% | Training loss: 0.6870042650563882
Epoch: 40 | Iteration number: [4050/4518] 89% | Training loss: 0.6870027267638548
Epoch: 40 | Iteration number: [4060/4518] 89% | Training loss: 0.6869997007946663
Epoch: 40 | Iteration number: [4070/4518] 90% | Training loss: 0.6869974932301542
Epoch: 40 | Iteration number: [4080/4518] 90% | Training loss: 0.6869990126905487
Epoch: 40 | Iteration number: [4090/4518] 90% | Training loss: 0.6870010825270254
Epoch: 40 | Iteration number: [4100/4518] 90% | Training loss: 0.6870008051831548
Epoch: 40 | Iteration number: [4110/4518] 90% | Training loss: 0.6870006912961203
Epoch: 40 | Iteration number: [4120/4518] 91% | Training loss: 0.687001230242183
Epoch: 40 | Iteration number: [4130/4518] 91% | Training loss: 0.6869983404513998
Epoch: 40 | Iteration number: [4140/4518] 91% | Training loss: 0.6869970055881905
Epoch: 40 | Iteration number: [4150/4518] 91% | Training loss: 0.6869961226560983
Epoch: 40 | Iteration number: [4160/4518] 92% | Training loss: 0.6869985385009876
Epoch: 40 | Iteration number: [4170/4518] 92% | Training loss: 0.6870015791565965
Epoch: 40 | Iteration number: [4180/4518] 92% | Training loss: 0.6870027940524251
Epoch: 40 | Iteration number: [4190/4518] 92% | Training loss: 0.6870031793390652
Epoch: 40 | Iteration number: [4200/4518] 92% | Training loss: 0.6870052362056006
Epoch: 40 | Iteration number: [4210/4518] 93% | Training loss: 0.6870035850237214
Epoch: 40 | Iteration number: [4220/4518] 93% | Training loss: 0.6870019432492731
Epoch: 40 | Iteration number: [4230/4518] 93% | Training loss: 0.6870011569619461
Epoch: 40 | Iteration number: [4240/4518] 93% | Training loss: 0.686997261910506
Epoch: 40 | Iteration number: [4250/4518] 94% | Training loss: 0.6869959065493415
Epoch: 40 | Iteration number: [4260/4518] 94% | Training loss: 0.6869957154345624
Epoch: 40 | Iteration number: [4270/4518] 94% | Training loss: 0.6869962238176646
Epoch: 40 | Iteration number: [4280/4518] 94% | Training loss: 0.6869963053648717
Epoch: 40 | Iteration number: [4290/4518] 94% | Training loss: 0.6869957327842713
Epoch: 40 | Iteration number: [4300/4518] 95% | Training loss: 0.6869967234411904
Epoch: 40 | Iteration number: [4310/4518] 95% | Training loss: 0.6869944051080956
Epoch: 40 | Iteration number: [4320/4518] 95% | Training loss: 0.6869951739493344
Epoch: 40 | Iteration number: [4330/4518] 95% | Training loss: 0.686992558279434
Epoch: 40 | Iteration number: [4340/4518] 96% | Training loss: 0.6869951269456318
Epoch: 40 | Iteration number: [4350/4518] 96% | Training loss: 0.68699529146326
Epoch: 40 | Iteration number: [4360/4518] 96% | Training loss: 0.6869962322875994
Epoch: 40 | Iteration number: [4370/4518] 96% | Training loss: 0.6869956377714668
Epoch: 40 | Iteration number: [4380/4518] 96% | Training loss: 0.6869955046672255
Epoch: 40 | Iteration number: [4390/4518] 97% | Training loss: 0.6869930898410042
Epoch: 40 | Iteration number: [4400/4518] 97% | Training loss: 0.6869945136389949
Epoch: 40 | Iteration number: [4410/4518] 97% | Training loss: 0.6869937886591672
Epoch: 40 | Iteration number: [4420/4518] 97% | Training loss: 0.6869926125350581
Epoch: 40 | Iteration number: [4430/4518] 98% | Training loss: 0.6869910655118542
Epoch: 40 | Iteration number: [4440/4518] 98% | Training loss: 0.6869888790287413
Epoch: 40 | Iteration number: [4450/4518] 98% | Training loss: 0.6869888530152567
Epoch: 40 | Iteration number: [4460/4518] 98% | Training loss: 0.6869896772196474
Epoch: 40 | Iteration number: [4470/4518] 98% | Training loss: 0.6869887999373527
Epoch: 40 | Iteration number: [4480/4518] 99% | Training loss: 0.6869882784384702
Epoch: 40 | Iteration number: [4490/4518] 99% | Training loss: 0.6869905375956427
Epoch: 40 | Iteration number: [4500/4518] 99% | Training loss: 0.686989898191558
Epoch: 40 | Iteration number: [4510/4518] 99% | Training loss: 0.6869896777188963

 End of epoch: 40 | Train Loss: 0.6868371079589688 | Training Time: 654 

 End of epoch: 40 | Eval Loss: 0.690185222090507 | Evaluating Time: 19 
Epoch: 41 | Iteration number: [10/4518] 0% | Training loss: 0.7552576839923859
Epoch: 41 | Iteration number: [20/4518] 0% | Training loss: 0.720844230055809
Epoch: 41 | Iteration number: [30/4518] 0% | Training loss: 0.7096794068813324
Epoch: 41 | Iteration number: [40/4518] 0% | Training loss: 0.7039842814207077
Epoch: 41 | Iteration number: [50/4518] 1% | Training loss: 0.7003187024593354
Epoch: 41 | Iteration number: [60/4518] 1% | Training loss: 0.6979832619428634
Epoch: 41 | Iteration number: [70/4518] 1% | Training loss: 0.6964658209255763
Epoch: 41 | Iteration number: [80/4518] 1% | Training loss: 0.6952270671725274
Epoch: 41 | Iteration number: [90/4518] 1% | Training loss: 0.694288984934489
Epoch: 41 | Iteration number: [100/4518] 2% | Training loss: 0.6934982872009278
Epoch: 41 | Iteration number: [110/4518] 2% | Training loss: 0.6929691482673992
Epoch: 41 | Iteration number: [120/4518] 2% | Training loss: 0.6922992845376332
Epoch: 41 | Iteration number: [130/4518] 2% | Training loss: 0.6919310400119194
Epoch: 41 | Iteration number: [140/4518] 3% | Training loss: 0.6914923012256622
Epoch: 41 | Iteration number: [150/4518] 3% | Training loss: 0.6912340434392293
Epoch: 41 | Iteration number: [160/4518] 3% | Training loss: 0.6909292615950108
Epoch: 41 | Iteration number: [170/4518] 3% | Training loss: 0.6907071969088386
Epoch: 41 | Iteration number: [180/4518] 3% | Training loss: 0.6904947923289405
Epoch: 41 | Iteration number: [190/4518] 4% | Training loss: 0.6901755521171972
Epoch: 41 | Iteration number: [200/4518] 4% | Training loss: 0.6900255307555199
Epoch: 41 | Iteration number: [210/4518] 4% | Training loss: 0.6899403379077003
Epoch: 41 | Iteration number: [220/4518] 4% | Training loss: 0.6898013705557043
Epoch: 41 | Iteration number: [230/4518] 5% | Training loss: 0.689651144069174
Epoch: 41 | Iteration number: [240/4518] 5% | Training loss: 0.6895405774315199
Epoch: 41 | Iteration number: [250/4518] 5% | Training loss: 0.6894209191799164
Epoch: 41 | Iteration number: [260/4518] 5% | Training loss: 0.6893241018056869
Epoch: 41 | Iteration number: [270/4518] 5% | Training loss: 0.6892168453446141
Epoch: 41 | Iteration number: [280/4518] 6% | Training loss: 0.6891094258853367
Epoch: 41 | Iteration number: [290/4518] 6% | Training loss: 0.6890048240793163
Epoch: 41 | Iteration number: [300/4518] 6% | Training loss: 0.6889252583185832
Epoch: 41 | Iteration number: [310/4518] 6% | Training loss: 0.688846238390092
Epoch: 41 | Iteration number: [320/4518] 7% | Training loss: 0.6887654215097427
Epoch: 41 | Iteration number: [330/4518] 7% | Training loss: 0.6887469351291656
Epoch: 41 | Iteration number: [340/4518] 7% | Training loss: 0.6887081723002827
Epoch: 41 | Iteration number: [350/4518] 7% | Training loss: 0.6886609465735299
Epoch: 41 | Iteration number: [360/4518] 7% | Training loss: 0.6885691834820642
Epoch: 41 | Iteration number: [370/4518] 8% | Training loss: 0.688515314379254
Epoch: 41 | Iteration number: [380/4518] 8% | Training loss: 0.6884789783703653
Epoch: 41 | Iteration number: [390/4518] 8% | Training loss: 0.6884672129765536
Epoch: 41 | Iteration number: [400/4518] 8% | Training loss: 0.6884439001977444
Epoch: 41 | Iteration number: [410/4518] 9% | Training loss: 0.6883906352810744
Epoch: 41 | Iteration number: [420/4518] 9% | Training loss: 0.6883276989062627
Epoch: 41 | Iteration number: [430/4518] 9% | Training loss: 0.6882884354092355
Epoch: 41 | Iteration number: [440/4518] 9% | Training loss: 0.6882601975040002
Epoch: 41 | Iteration number: [450/4518] 9% | Training loss: 0.68823066022661
Epoch: 41 | Iteration number: [460/4518] 10% | Training loss: 0.6881983324237492
Epoch: 41 | Iteration number: [470/4518] 10% | Training loss: 0.6881473725146435
Epoch: 41 | Iteration number: [480/4518] 10% | Training loss: 0.688126960893472
Epoch: 41 | Iteration number: [490/4518] 10% | Training loss: 0.6880911169003467
Epoch: 41 | Iteration number: [500/4518] 11% | Training loss: 0.6880501639842987
Epoch: 41 | Iteration number: [510/4518] 11% | Training loss: 0.6880365503769295
Epoch: 41 | Iteration number: [520/4518] 11% | Training loss: 0.6880356073379517
Epoch: 41 | Iteration number: [530/4518] 11% | Training loss: 0.6880352087740628
Epoch: 41 | Iteration number: [540/4518] 11% | Training loss: 0.6880336110238676
Epoch: 41 | Iteration number: [550/4518] 12% | Training loss: 0.688016314831647
Epoch: 41 | Iteration number: [560/4518] 12% | Training loss: 0.6880034598921027
Epoch: 41 | Iteration number: [570/4518] 12% | Training loss: 0.6880169825595722
Epoch: 41 | Iteration number: [580/4518] 12% | Training loss: 0.6879795928453577
Epoch: 41 | Iteration number: [590/4518] 13% | Training loss: 0.6879662699618582
Epoch: 41 | Iteration number: [600/4518] 13% | Training loss: 0.6879473003745079
Epoch: 41 | Iteration number: [610/4518] 13% | Training loss: 0.6879438289853393
Epoch: 41 | Iteration number: [620/4518] 13% | Training loss: 0.6879226923950257
Epoch: 41 | Iteration number: [630/4518] 13% | Training loss: 0.687897955614423
Epoch: 41 | Iteration number: [640/4518] 14% | Training loss: 0.6878802713938057
Epoch: 41 | Iteration number: [650/4518] 14% | Training loss: 0.6878700013344105
Epoch: 41 | Iteration number: [660/4518] 14% | Training loss: 0.6878507209546638
Epoch: 41 | Iteration number: [670/4518] 14% | Training loss: 0.6878261712060045
Epoch: 41 | Iteration number: [680/4518] 15% | Training loss: 0.6878287718576543
Epoch: 41 | Iteration number: [690/4518] 15% | Training loss: 0.6878070875354435
Epoch: 41 | Iteration number: [700/4518] 15% | Training loss: 0.6877929440566471
Epoch: 41 | Iteration number: [710/4518] 15% | Training loss: 0.6877777084498339
Epoch: 41 | Iteration number: [720/4518] 15% | Training loss: 0.6877597585320473
Epoch: 41 | Iteration number: [730/4518] 16% | Training loss: 0.687750507625815
Epoch: 41 | Iteration number: [740/4518] 16% | Training loss: 0.6877564108049548
Epoch: 41 | Iteration number: [750/4518] 16% | Training loss: 0.6877506431738536
Epoch: 41 | Iteration number: [760/4518] 16% | Training loss: 0.687736282066295
Epoch: 41 | Iteration number: [770/4518] 17% | Training loss: 0.6877202575082902
Epoch: 41 | Iteration number: [780/4518] 17% | Training loss: 0.6876910179089277
Epoch: 41 | Iteration number: [790/4518] 17% | Training loss: 0.6877021308941177
Epoch: 41 | Iteration number: [800/4518] 17% | Training loss: 0.6876623885333538
Epoch: 41 | Iteration number: [810/4518] 17% | Training loss: 0.687653895807855
Epoch: 41 | Iteration number: [820/4518] 18% | Training loss: 0.6876420444831616
Epoch: 41 | Iteration number: [830/4518] 18% | Training loss: 0.6876257675239839
Epoch: 41 | Iteration number: [840/4518] 18% | Training loss: 0.687623390413466
Epoch: 41 | Iteration number: [850/4518] 18% | Training loss: 0.6876143381174873
Epoch: 41 | Iteration number: [860/4518] 19% | Training loss: 0.6875909541928491
Epoch: 41 | Iteration number: [870/4518] 19% | Training loss: 0.6875829363691396
Epoch: 41 | Iteration number: [880/4518] 19% | Training loss: 0.68756173056635
Epoch: 41 | Iteration number: [890/4518] 19% | Training loss: 0.6875638479597113
Epoch: 41 | Iteration number: [900/4518] 19% | Training loss: 0.6875481685002645
Epoch: 41 | Iteration number: [910/4518] 20% | Training loss: 0.6875463183764573
Epoch: 41 | Iteration number: [920/4518] 20% | Training loss: 0.6875420727159666
Epoch: 41 | Iteration number: [930/4518] 20% | Training loss: 0.6875476399416565
Epoch: 41 | Iteration number: [940/4518] 20% | Training loss: 0.6875422433969822
Epoch: 41 | Iteration number: [950/4518] 21% | Training loss: 0.6875208700330634
Epoch: 41 | Iteration number: [960/4518] 21% | Training loss: 0.6875101844469707
Epoch: 41 | Iteration number: [970/4518] 21% | Training loss: 0.687500085105601
Epoch: 41 | Iteration number: [980/4518] 21% | Training loss: 0.6874949875534797
Epoch: 41 | Iteration number: [990/4518] 21% | Training loss: 0.6874907585105511
Epoch: 41 | Iteration number: [1000/4518] 22% | Training loss: 0.6874750000238419
Epoch: 41 | Iteration number: [1010/4518] 22% | Training loss: 0.687467357191709
Epoch: 41 | Iteration number: [1020/4518] 22% | Training loss: 0.6874637388715557
Epoch: 41 | Iteration number: [1030/4518] 22% | Training loss: 0.6874572583193918
Epoch: 41 | Iteration number: [1040/4518] 23% | Training loss: 0.6874496687490207
Epoch: 41 | Iteration number: [1050/4518] 23% | Training loss: 0.6874320428144364
Epoch: 41 | Iteration number: [1060/4518] 23% | Training loss: 0.6874288038262781
Epoch: 41 | Iteration number: [1070/4518] 23% | Training loss: 0.6874239073735531
Epoch: 41 | Iteration number: [1080/4518] 23% | Training loss: 0.6874282357869325
Epoch: 41 | Iteration number: [1090/4518] 24% | Training loss: 0.6874109709481581
Epoch: 41 | Iteration number: [1100/4518] 24% | Training loss: 0.6874096091768959
Epoch: 41 | Iteration number: [1110/4518] 24% | Training loss: 0.6873983882568978
Epoch: 41 | Iteration number: [1120/4518] 24% | Training loss: 0.6873899290604251
Epoch: 41 | Iteration number: [1130/4518] 25% | Training loss: 0.6873935517484108
Epoch: 41 | Iteration number: [1140/4518] 25% | Training loss: 0.6873917780947267
Epoch: 41 | Iteration number: [1150/4518] 25% | Training loss: 0.6873872931107231
Epoch: 41 | Iteration number: [1160/4518] 25% | Training loss: 0.6873866604833767
Epoch: 41 | Iteration number: [1170/4518] 25% | Training loss: 0.6873724202824454
Epoch: 41 | Iteration number: [1180/4518] 26% | Training loss: 0.6873745945045504
Epoch: 41 | Iteration number: [1190/4518] 26% | Training loss: 0.6873703638545605
Epoch: 41 | Iteration number: [1200/4518] 26% | Training loss: 0.6873615264395873
Epoch: 41 | Iteration number: [1210/4518] 26% | Training loss: 0.6873494425095803
Epoch: 41 | Iteration number: [1220/4518] 27% | Training loss: 0.6873512784965703
Epoch: 41 | Iteration number: [1230/4518] 27% | Training loss: 0.6873362550405953
Epoch: 41 | Iteration number: [1240/4518] 27% | Training loss: 0.6873269742535006
Epoch: 41 | Iteration number: [1250/4518] 27% | Training loss: 0.6873332122802734
Epoch: 41 | Iteration number: [1260/4518] 27% | Training loss: 0.6873356663991534
Epoch: 41 | Iteration number: [1270/4518] 28% | Training loss: 0.6873321728912865
Epoch: 41 | Iteration number: [1280/4518] 28% | Training loss: 0.6873396107926965
Epoch: 41 | Iteration number: [1290/4518] 28% | Training loss: 0.6873401565145153
Epoch: 41 | Iteration number: [1300/4518] 28% | Training loss: 0.6873286946920248
Epoch: 41 | Iteration number: [1310/4518] 28% | Training loss: 0.6873354449981951
Epoch: 41 | Iteration number: [1320/4518] 29% | Training loss: 0.6873327087272297
Epoch: 41 | Iteration number: [1330/4518] 29% | Training loss: 0.6873304399332606
Epoch: 41 | Iteration number: [1340/4518] 29% | Training loss: 0.6873204861114274
Epoch: 41 | Iteration number: [1350/4518] 29% | Training loss: 0.6873235364754995
Epoch: 41 | Iteration number: [1360/4518] 30% | Training loss: 0.6873179351143978
Epoch: 41 | Iteration number: [1370/4518] 30% | Training loss: 0.6873069872386264
Epoch: 41 | Iteration number: [1380/4518] 30% | Training loss: 0.6873095296431279
Epoch: 41 | Iteration number: [1390/4518] 30% | Training loss: 0.6873132223276783
Epoch: 41 | Iteration number: [1400/4518] 30% | Training loss: 0.6873109823039599
Epoch: 41 | Iteration number: [1410/4518] 31% | Training loss: 0.6873025126068305
Epoch: 41 | Iteration number: [1420/4518] 31% | Training loss: 0.6873000097946382
Epoch: 41 | Iteration number: [1430/4518] 31% | Training loss: 0.687300717538887
Epoch: 41 | Iteration number: [1440/4518] 31% | Training loss: 0.6872935179620981
Epoch: 41 | Iteration number: [1450/4518] 32% | Training loss: 0.6872862647730729
Epoch: 41 | Iteration number: [1460/4518] 32% | Training loss: 0.6872796724920404
Epoch: 41 | Iteration number: [1470/4518] 32% | Training loss: 0.6872629708578798
Epoch: 41 | Iteration number: [1480/4518] 32% | Training loss: 0.6872577127572652
Epoch: 41 | Iteration number: [1490/4518] 32% | Training loss: 0.6872599123308323
Epoch: 41 | Iteration number: [1500/4518] 33% | Training loss: 0.6872541271050772
Epoch: 41 | Iteration number: [1510/4518] 33% | Training loss: 0.6872487964614338
Epoch: 41 | Iteration number: [1520/4518] 33% | Training loss: 0.6872419231816342
Epoch: 41 | Iteration number: [1530/4518] 33% | Training loss: 0.6872426338834701
Epoch: 41 | Iteration number: [1540/4518] 34% | Training loss: 0.687238716885641
Epoch: 41 | Iteration number: [1550/4518] 34% | Training loss: 0.6872369741239855
Epoch: 41 | Iteration number: [1560/4518] 34% | Training loss: 0.6872301055070681
Epoch: 41 | Iteration number: [1570/4518] 34% | Training loss: 0.6872242645473238
Epoch: 41 | Iteration number: [1580/4518] 34% | Training loss: 0.6872203734479373
Epoch: 41 | Iteration number: [1590/4518] 35% | Training loss: 0.6872163703606563
Epoch: 41 | Iteration number: [1600/4518] 35% | Training loss: 0.6872163981199264
Epoch: 41 | Iteration number: [1610/4518] 35% | Training loss: 0.687212022824317
Epoch: 41 | Iteration number: [1620/4518] 35% | Training loss: 0.687212046539342
Epoch: 41 | Iteration number: [1630/4518] 36% | Training loss: 0.6872136758514709
Epoch: 41 | Iteration number: [1640/4518] 36% | Training loss: 0.6872085252186148
Epoch: 41 | Iteration number: [1650/4518] 36% | Training loss: 0.6872083061030417
Epoch: 41 | Iteration number: [1660/4518] 36% | Training loss: 0.687209437625954
Epoch: 41 | Iteration number: [1670/4518] 36% | Training loss: 0.6872069751431128
Epoch: 41 | Iteration number: [1680/4518] 37% | Training loss: 0.6872074154870851
Epoch: 41 | Iteration number: [1690/4518] 37% | Training loss: 0.687209804453088
Epoch: 41 | Iteration number: [1700/4518] 37% | Training loss: 0.6872197973026949
Epoch: 41 | Iteration number: [1710/4518] 37% | Training loss: 0.6872166274235263
Epoch: 41 | Iteration number: [1720/4518] 38% | Training loss: 0.6872198063273762
Epoch: 41 | Iteration number: [1730/4518] 38% | Training loss: 0.6872197075041733
Epoch: 41 | Iteration number: [1740/4518] 38% | Training loss: 0.6872164242911613
Epoch: 41 | Iteration number: [1750/4518] 38% | Training loss: 0.687214828150613
Epoch: 41 | Iteration number: [1760/4518] 38% | Training loss: 0.6872020849450068
Epoch: 41 | Iteration number: [1770/4518] 39% | Training loss: 0.6872043703908974
Epoch: 41 | Iteration number: [1780/4518] 39% | Training loss: 0.6872009740116891
Epoch: 41 | Iteration number: [1790/4518] 39% | Training loss: 0.687198603652709
Epoch: 41 | Iteration number: [1800/4518] 39% | Training loss: 0.6871918056077427
Epoch: 41 | Iteration number: [1810/4518] 40% | Training loss: 0.687190393057976
Epoch: 41 | Iteration number: [1820/4518] 40% | Training loss: 0.6871880567663319
Epoch: 41 | Iteration number: [1830/4518] 40% | Training loss: 0.6871838113649296
Epoch: 41 | Iteration number: [1840/4518] 40% | Training loss: 0.6871794554850329
Epoch: 41 | Iteration number: [1850/4518] 40% | Training loss: 0.6871764501687643
Epoch: 41 | Iteration number: [1860/4518] 41% | Training loss: 0.6871749617720163
Epoch: 41 | Iteration number: [1870/4518] 41% | Training loss: 0.6871708773355433
Epoch: 41 | Iteration number: [1880/4518] 41% | Training loss: 0.6871681095754847
Epoch: 41 | Iteration number: [1890/4518] 41% | Training loss: 0.6871700212753639
Epoch: 41 | Iteration number: [1900/4518] 42% | Training loss: 0.6871711736917496
Epoch: 41 | Iteration number: [1910/4518] 42% | Training loss: 0.6871692944883676
Epoch: 41 | Iteration number: [1920/4518] 42% | Training loss: 0.687173772106568
Epoch: 41 | Iteration number: [1930/4518] 42% | Training loss: 0.6871657549717266
Epoch: 41 | Iteration number: [1940/4518] 42% | Training loss: 0.6871649419524006
Epoch: 41 | Iteration number: [1950/4518] 43% | Training loss: 0.687163939842811
Epoch: 41 | Iteration number: [1960/4518] 43% | Training loss: 0.687161245212263
Epoch: 41 | Iteration number: [1970/4518] 43% | Training loss: 0.687155145951334
Epoch: 41 | Iteration number: [1980/4518] 43% | Training loss: 0.6871506626557822
Epoch: 41 | Iteration number: [1990/4518] 44% | Training loss: 0.6871563277951437
Epoch: 41 | Iteration number: [2000/4518] 44% | Training loss: 0.687162149310112
Epoch: 41 | Iteration number: [2010/4518] 44% | Training loss: 0.6871527660545425
Epoch: 41 | Iteration number: [2020/4518] 44% | Training loss: 0.6871464979530562
Epoch: 41 | Iteration number: [2030/4518] 44% | Training loss: 0.6871502468445031
Epoch: 41 | Iteration number: [2040/4518] 45% | Training loss: 0.687153459238071
Epoch: 41 | Iteration number: [2050/4518] 45% | Training loss: 0.6871514190697089
Epoch: 41 | Iteration number: [2060/4518] 45% | Training loss: 0.6871537456234682
Epoch: 41 | Iteration number: [2070/4518] 45% | Training loss: 0.6871545110635712
Epoch: 41 | Iteration number: [2080/4518] 46% | Training loss: 0.6871540620349921
Epoch: 41 | Iteration number: [2090/4518] 46% | Training loss: 0.6871538883476166
Epoch: 41 | Iteration number: [2100/4518] 46% | Training loss: 0.687153406058039
Epoch: 41 | Iteration number: [2110/4518] 46% | Training loss: 0.6871548530049799
Epoch: 41 | Iteration number: [2120/4518] 46% | Training loss: 0.6871539461725164
Epoch: 41 | Iteration number: [2130/4518] 47% | Training loss: 0.6871576742387153
Epoch: 41 | Iteration number: [2140/4518] 47% | Training loss: 0.68715302771497
Epoch: 41 | Iteration number: [2150/4518] 47% | Training loss: 0.6871505198367807
Epoch: 41 | Iteration number: [2160/4518] 47% | Training loss: 0.6871448320371133
Epoch: 41 | Iteration number: [2170/4518] 48% | Training loss: 0.6871442458871323
Epoch: 41 | Iteration number: [2180/4518] 48% | Training loss: 0.6871428472733279
Epoch: 41 | Iteration number: [2190/4518] 48% | Training loss: 0.6871389828043986
Epoch: 41 | Iteration number: [2200/4518] 48% | Training loss: 0.6871388032219626
Epoch: 41 | Iteration number: [2210/4518] 48% | Training loss: 0.6871314007502336
Epoch: 41 | Iteration number: [2220/4518] 49% | Training loss: 0.6871278419150962
Epoch: 41 | Iteration number: [2230/4518] 49% | Training loss: 0.6871190248316179
Epoch: 41 | Iteration number: [2240/4518] 49% | Training loss: 0.6871216459465879
Epoch: 41 | Iteration number: [2250/4518] 49% | Training loss: 0.6871150756941902
Epoch: 41 | Iteration number: [2260/4518] 50% | Training loss: 0.6871117866408508
Epoch: 41 | Iteration number: [2270/4518] 50% | Training loss: 0.6871065731878323
Epoch: 41 | Iteration number: [2280/4518] 50% | Training loss: 0.6871058035576553
Epoch: 41 | Iteration number: [2290/4518] 50% | Training loss: 0.6871045544157903
Epoch: 41 | Iteration number: [2300/4518] 50% | Training loss: 0.6870961820560952
Epoch: 41 | Iteration number: [2310/4518] 51% | Training loss: 0.6871002277770599
Epoch: 41 | Iteration number: [2320/4518] 51% | Training loss: 0.6870979150821422
Epoch: 41 | Iteration number: [2330/4518] 51% | Training loss: 0.6870992464057366
Epoch: 41 | Iteration number: [2340/4518] 51% | Training loss: 0.6870986853654568
Epoch: 41 | Iteration number: [2350/4518] 52% | Training loss: 0.687100136660515
Epoch: 41 | Iteration number: [2360/4518] 52% | Training loss: 0.6871001254198915
Epoch: 41 | Iteration number: [2370/4518] 52% | Training loss: 0.6871004018099499
Epoch: 41 | Iteration number: [2380/4518] 52% | Training loss: 0.6871001610986325
Epoch: 41 | Iteration number: [2390/4518] 52% | Training loss: 0.6871008054731281
Epoch: 41 | Iteration number: [2400/4518] 53% | Training loss: 0.6871032691995302
Epoch: 41 | Iteration number: [2410/4518] 53% | Training loss: 0.687105213161326
Epoch: 41 | Iteration number: [2420/4518] 53% | Training loss: 0.6871085085159491
Epoch: 41 | Iteration number: [2430/4518] 53% | Training loss: 0.6871089060855992
Epoch: 41 | Iteration number: [2440/4518] 54% | Training loss: 0.6871040614901996
Epoch: 41 | Iteration number: [2450/4518] 54% | Training loss: 0.6871034180388159
Epoch: 41 | Iteration number: [2460/4518] 54% | Training loss: 0.687100845042283
Epoch: 41 | Iteration number: [2470/4518] 54% | Training loss: 0.6871001579259571
Epoch: 41 | Iteration number: [2480/4518] 54% | Training loss: 0.687096631526947
Epoch: 41 | Iteration number: [2490/4518] 55% | Training loss: 0.6870959356846101
Epoch: 41 | Iteration number: [2500/4518] 55% | Training loss: 0.687093557882309
Epoch: 41 | Iteration number: [2510/4518] 55% | Training loss: 0.687094628003489
Epoch: 41 | Iteration number: [2520/4518] 55% | Training loss: 0.6870911390062362
Epoch: 41 | Iteration number: [2530/4518] 55% | Training loss: 0.6870896886931106
Epoch: 41 | Iteration number: [2540/4518] 56% | Training loss: 0.6870859858557934
Epoch: 41 | Iteration number: [2550/4518] 56% | Training loss: 0.6870880513097726
Epoch: 41 | Iteration number: [2560/4518] 56% | Training loss: 0.687088938546367
Epoch: 41 | Iteration number: [2570/4518] 56% | Training loss: 0.6870908397876799
Epoch: 41 | Iteration number: [2580/4518] 57% | Training loss: 0.6870839257110921
Epoch: 41 | Iteration number: [2590/4518] 57% | Training loss: 0.6870839408926062
Epoch: 41 | Iteration number: [2600/4518] 57% | Training loss: 0.6870852177188946
Epoch: 41 | Iteration number: [2610/4518] 57% | Training loss: 0.6870901392109092
Epoch: 41 | Iteration number: [2620/4518] 57% | Training loss: 0.6870886661396682
Epoch: 41 | Iteration number: [2630/4518] 58% | Training loss: 0.6870898251524443
Epoch: 41 | Iteration number: [2640/4518] 58% | Training loss: 0.6870940544388511
Epoch: 41 | Iteration number: [2650/4518] 58% | Training loss: 0.6870918261330082
Epoch: 41 | Iteration number: [2660/4518] 58% | Training loss: 0.6870915661404904
Epoch: 41 | Iteration number: [2670/4518] 59% | Training loss: 0.6870876970809051
Epoch: 41 | Iteration number: [2680/4518] 59% | Training loss: 0.6870868692647165
Epoch: 41 | Iteration number: [2690/4518] 59% | Training loss: 0.6870893249059699
Epoch: 41 | Iteration number: [2700/4518] 59% | Training loss: 0.6870857472552193
Epoch: 41 | Iteration number: [2710/4518] 59% | Training loss: 0.687086017809231
Epoch: 41 | Iteration number: [2720/4518] 60% | Training loss: 0.6870846985017552
Epoch: 41 | Iteration number: [2730/4518] 60% | Training loss: 0.6870865065099555
Epoch: 41 | Iteration number: [2740/4518] 60% | Training loss: 0.6870787076706434
Epoch: 41 | Iteration number: [2750/4518] 60% | Training loss: 0.687074930711226
Epoch: 41 | Iteration number: [2760/4518] 61% | Training loss: 0.6870739381814348
Epoch: 41 | Iteration number: [2770/4518] 61% | Training loss: 0.6870703578856017
Epoch: 41 | Iteration number: [2780/4518] 61% | Training loss: 0.6870705448895049
Epoch: 41 | Iteration number: [2790/4518] 61% | Training loss: 0.6870688375179058
Epoch: 41 | Iteration number: [2800/4518] 61% | Training loss: 0.687061299937112
Epoch: 41 | Iteration number: [2810/4518] 62% | Training loss: 0.6870668853304989
Epoch: 41 | Iteration number: [2820/4518] 62% | Training loss: 0.6870670772613363
Epoch: 41 | Iteration number: [2830/4518] 62% | Training loss: 0.687061259961381
Epoch: 41 | Iteration number: [2840/4518] 62% | Training loss: 0.6870591165314258
Epoch: 41 | Iteration number: [2850/4518] 63% | Training loss: 0.6870619613245914
Epoch: 41 | Iteration number: [2860/4518] 63% | Training loss: 0.6870607816881233
Epoch: 41 | Iteration number: [2870/4518] 63% | Training loss: 0.6870565690645357
Epoch: 41 | Iteration number: [2880/4518] 63% | Training loss: 0.6870591804799107
Epoch: 41 | Iteration number: [2890/4518] 63% | Training loss: 0.6870574141249938
Epoch: 41 | Iteration number: [2900/4518] 64% | Training loss: 0.6870591250986888
Epoch: 41 | Iteration number: [2910/4518] 64% | Training loss: 0.6870576781915225
Epoch: 41 | Iteration number: [2920/4518] 64% | Training loss: 0.6870567801676385
Epoch: 41 | Iteration number: [2930/4518] 64% | Training loss: 0.6870575919696496
Epoch: 41 | Iteration number: [2940/4518] 65% | Training loss: 0.6870604350250594
Epoch: 41 | Iteration number: [2950/4518] 65% | Training loss: 0.687063861741858
Epoch: 41 | Iteration number: [2960/4518] 65% | Training loss: 0.6870616464800126
Epoch: 41 | Iteration number: [2970/4518] 65% | Training loss: 0.6870548116438316
Epoch: 41 | Iteration number: [2980/4518] 65% | Training loss: 0.6870536886405625
Epoch: 41 | Iteration number: [2990/4518] 66% | Training loss: 0.6870499933244393
Epoch: 41 | Iteration number: [3000/4518] 66% | Training loss: 0.687045026063919
Epoch: 41 | Iteration number: [3010/4518] 66% | Training loss: 0.6870465284962195
Epoch: 41 | Iteration number: [3020/4518] 66% | Training loss: 0.6870447135721611
Epoch: 41 | Iteration number: [3030/4518] 67% | Training loss: 0.6870459242819166
Epoch: 41 | Iteration number: [3040/4518] 67% | Training loss: 0.6870462941888131
Epoch: 41 | Iteration number: [3050/4518] 67% | Training loss: 0.6870484364619021
Epoch: 41 | Iteration number: [3060/4518] 67% | Training loss: 0.6870471373492596
Epoch: 41 | Iteration number: [3070/4518] 67% | Training loss: 0.687046586302282
Epoch: 41 | Iteration number: [3080/4518] 68% | Training loss: 0.6870460093601958
Epoch: 41 | Iteration number: [3090/4518] 68% | Training loss: 0.6870433648041537
Epoch: 41 | Iteration number: [3100/4518] 68% | Training loss: 0.687042920397174
Epoch: 41 | Iteration number: [3110/4518] 68% | Training loss: 0.6870412370399647
Epoch: 41 | Iteration number: [3120/4518] 69% | Training loss: 0.6870395262654011
Epoch: 41 | Iteration number: [3130/4518] 69% | Training loss: 0.6870404600144956
Epoch: 41 | Iteration number: [3140/4518] 69% | Training loss: 0.6870414674282074
Epoch: 41 | Iteration number: [3150/4518] 69% | Training loss: 0.6870425798211779
Epoch: 41 | Iteration number: [3160/4518] 69% | Training loss: 0.687038024882727
Epoch: 41 | Iteration number: [3170/4518] 70% | Training loss: 0.687039767266824
Epoch: 41 | Iteration number: [3180/4518] 70% | Training loss: 0.6870386014756916
Epoch: 41 | Iteration number: [3190/4518] 70% | Training loss: 0.6870383759464216
Epoch: 41 | Iteration number: [3200/4518] 70% | Training loss: 0.6870407862775028
Epoch: 41 | Iteration number: [3210/4518] 71% | Training loss: 0.6870392543504543
Epoch: 41 | Iteration number: [3220/4518] 71% | Training loss: 0.6870361855311423
Epoch: 41 | Iteration number: [3230/4518] 71% | Training loss: 0.6870357476889902
Epoch: 41 | Iteration number: [3240/4518] 71% | Training loss: 0.6870355884234111
Epoch: 41 | Iteration number: [3250/4518] 71% | Training loss: 0.6870326215303861
Epoch: 41 | Iteration number: [3260/4518] 72% | Training loss: 0.6870319952445527
Epoch: 41 | Iteration number: [3270/4518] 72% | Training loss: 0.6870360125460027
Epoch: 41 | Iteration number: [3280/4518] 72% | Training loss: 0.6870384030589243
Epoch: 41 | Iteration number: [3290/4518] 72% | Training loss: 0.687039556637361
Epoch: 41 | Iteration number: [3300/4518] 73% | Training loss: 0.6870391900250405
Epoch: 41 | Iteration number: [3310/4518] 73% | Training loss: 0.6870422254696353
Epoch: 41 | Iteration number: [3320/4518] 73% | Training loss: 0.687038629367409
Epoch: 41 | Iteration number: [3330/4518] 73% | Training loss: 0.6870387852549911
Epoch: 41 | Iteration number: [3340/4518] 73% | Training loss: 0.687041345577754
Epoch: 41 | Iteration number: [3350/4518] 74% | Training loss: 0.6870428298480475
Epoch: 41 | Iteration number: [3360/4518] 74% | Training loss: 0.6870414272128117
Epoch: 41 | Iteration number: [3370/4518] 74% | Training loss: 0.6870349194777118
Epoch: 41 | Iteration number: [3380/4518] 74% | Training loss: 0.6870325772719976
Epoch: 41 | Iteration number: [3390/4518] 75% | Training loss: 0.6870306394796456
Epoch: 41 | Iteration number: [3400/4518] 75% | Training loss: 0.6870301743640619
Epoch: 41 | Iteration number: [3410/4518] 75% | Training loss: 0.6870322762346687
Epoch: 41 | Iteration number: [3420/4518] 75% | Training loss: 0.6870335956240258
Epoch: 41 | Iteration number: [3430/4518] 75% | Training loss: 0.6870341541120679
Epoch: 41 | Iteration number: [3440/4518] 76% | Training loss: 0.6870312866949758
Epoch: 41 | Iteration number: [3450/4518] 76% | Training loss: 0.6870293512551681
Epoch: 41 | Iteration number: [3460/4518] 76% | Training loss: 0.6870310469169837
Epoch: 41 | Iteration number: [3470/4518] 76% | Training loss: 0.6870305340125169
Epoch: 41 | Iteration number: [3480/4518] 77% | Training loss: 0.6870303121962766
Epoch: 41 | Iteration number: [3490/4518] 77% | Training loss: 0.6870296391340928
Epoch: 41 | Iteration number: [3500/4518] 77% | Training loss: 0.6870269204889025
Epoch: 41 | Iteration number: [3510/4518] 77% | Training loss: 0.6870259895793394
Epoch: 41 | Iteration number: [3520/4518] 77% | Training loss: 0.6870239506052299
Epoch: 41 | Iteration number: [3530/4518] 78% | Training loss: 0.687023343445559
Epoch: 41 | Iteration number: [3540/4518] 78% | Training loss: 0.687022927656012
Epoch: 41 | Iteration number: [3550/4518] 78% | Training loss: 0.687021124950597
Epoch: 41 | Iteration number: [3560/4518] 78% | Training loss: 0.6870206949416171
Epoch: 41 | Iteration number: [3570/4518] 79% | Training loss: 0.6870209728302408
Epoch: 41 | Iteration number: [3580/4518] 79% | Training loss: 0.687022548930605
Epoch: 41 | Iteration number: [3590/4518] 79% | Training loss: 0.6870225995031904
Epoch: 41 | Iteration number: [3600/4518] 79% | Training loss: 0.6870239722728729
Epoch: 41 | Iteration number: [3610/4518] 79% | Training loss: 0.6870214907086126
Epoch: 41 | Iteration number: [3620/4518] 80% | Training loss: 0.6870237093604072
Epoch: 41 | Iteration number: [3630/4518] 80% | Training loss: 0.687021664203691
Epoch: 41 | Iteration number: [3640/4518] 80% | Training loss: 0.6870195713835758
Epoch: 41 | Iteration number: [3650/4518] 80% | Training loss: 0.6870242706553576
Epoch: 41 | Iteration number: [3660/4518] 81% | Training loss: 0.6870237395574487
Epoch: 41 | Iteration number: [3670/4518] 81% | Training loss: 0.687020470384681
Epoch: 41 | Iteration number: [3680/4518] 81% | Training loss: 0.6870215843715097
Epoch: 41 | Iteration number: [3690/4518] 81% | Training loss: 0.6870203628611112
Epoch: 41 | Iteration number: [3700/4518] 81% | Training loss: 0.6870178365063023
Epoch: 41 | Iteration number: [3710/4518] 82% | Training loss: 0.6870173608357052
Epoch: 41 | Iteration number: [3720/4518] 82% | Training loss: 0.6870199862346854
Epoch: 41 | Iteration number: [3730/4518] 82% | Training loss: 0.687018260128057
Epoch: 41 | Iteration number: [3740/4518] 82% | Training loss: 0.6870169971078475
Epoch: 41 | Iteration number: [3750/4518] 83% | Training loss: 0.6870153157711029
Epoch: 41 | Iteration number: [3760/4518] 83% | Training loss: 0.6870141420117084
Epoch: 41 | Iteration number: [3770/4518] 83% | Training loss: 0.6870122871443195
Epoch: 41 | Iteration number: [3780/4518] 83% | Training loss: 0.6870118210713069
Epoch: 41 | Iteration number: [3790/4518] 83% | Training loss: 0.6870104958168121
Epoch: 41 | Iteration number: [3800/4518] 84% | Training loss: 0.687010519645716
Epoch: 41 | Iteration number: [3810/4518] 84% | Training loss: 0.6870110179808508
Epoch: 41 | Iteration number: [3820/4518] 84% | Training loss: 0.687013819095976
Epoch: 41 | Iteration number: [3830/4518] 84% | Training loss: 0.687011935505481
Epoch: 41 | Iteration number: [3840/4518] 84% | Training loss: 0.6870101878264298
Epoch: 41 | Iteration number: [3850/4518] 85% | Training loss: 0.6870086593442148
Epoch: 41 | Iteration number: [3860/4518] 85% | Training loss: 0.6870114677001775
Epoch: 41 | Iteration number: [3870/4518] 85% | Training loss: 0.6870136907242373
Epoch: 41 | Iteration number: [3880/4518] 85% | Training loss: 0.6870102219667631
Epoch: 41 | Iteration number: [3890/4518] 86% | Training loss: 0.6870138228705732
Epoch: 41 | Iteration number: [3900/4518] 86% | Training loss: 0.6870180969819044
Epoch: 41 | Iteration number: [3910/4518] 86% | Training loss: 0.6870185544728623
Epoch: 41 | Iteration number: [3920/4518] 86% | Training loss: 0.6870200499131971
Epoch: 41 | Iteration number: [3930/4518] 86% | Training loss: 0.6870218976156706
Epoch: 41 | Iteration number: [3940/4518] 87% | Training loss: 0.68701934350021
Epoch: 41 | Iteration number: [3950/4518] 87% | Training loss: 0.6870201369931426
Epoch: 41 | Iteration number: [3960/4518] 87% | Training loss: 0.6870184413712435
Epoch: 41 | Iteration number: [3970/4518] 87% | Training loss: 0.6870196163654327
Epoch: 41 | Iteration number: [3980/4518] 88% | Training loss: 0.6870161218858843
Epoch: 41 | Iteration number: [3990/4518] 88% | Training loss: 0.6870128992057982
Epoch: 41 | Iteration number: [4000/4518] 88% | Training loss: 0.6870138804614544
Epoch: 41 | Iteration number: [4010/4518] 88% | Training loss: 0.6870133066266552
Epoch: 41 | Iteration number: [4020/4518] 88% | Training loss: 0.6870078754810551
Epoch: 41 | Iteration number: [4030/4518] 89% | Training loss: 0.6870077353701106
Epoch: 41 | Iteration number: [4040/4518] 89% | Training loss: 0.6870075119899051
Epoch: 41 | Iteration number: [4050/4518] 89% | Training loss: 0.6870100493931476
Epoch: 41 | Iteration number: [4060/4518] 89% | Training loss: 0.6870056973449115
Epoch: 41 | Iteration number: [4070/4518] 90% | Training loss: 0.687002590672097
Epoch: 41 | Iteration number: [4080/4518] 90% | Training loss: 0.6870018015013022
Epoch: 41 | Iteration number: [4090/4518] 90% | Training loss: 0.6870019859235852
Epoch: 41 | Iteration number: [4100/4518] 90% | Training loss: 0.687001193587373
Epoch: 41 | Iteration number: [4110/4518] 90% | Training loss: 0.6870009836054196
Epoch: 41 | Iteration number: [4120/4518] 91% | Training loss: 0.6870002359875198
Epoch: 41 | Iteration number: [4130/4518] 91% | Training loss: 0.6870014445689342
Epoch: 41 | Iteration number: [4140/4518] 91% | Training loss: 0.687003508930045
Epoch: 41 | Iteration number: [4150/4518] 91% | Training loss: 0.6870021212531859
Epoch: 41 | Iteration number: [4160/4518] 92% | Training loss: 0.6869993390085606
Epoch: 41 | Iteration number: [4170/4518] 92% | Training loss: 0.6869964292438197
Epoch: 41 | Iteration number: [4180/4518] 92% | Training loss: 0.6869971535707775
Epoch: 41 | Iteration number: [4190/4518] 92% | Training loss: 0.6869956351549927
Epoch: 41 | Iteration number: [4200/4518] 92% | Training loss: 0.6869954267995698
Epoch: 41 | Iteration number: [4210/4518] 93% | Training loss: 0.6869953916503245
Epoch: 41 | Iteration number: [4220/4518] 93% | Training loss: 0.6869947156917428
Epoch: 41 | Iteration number: [4230/4518] 93% | Training loss: 0.6869928614467594
Epoch: 41 | Iteration number: [4240/4518] 93% | Training loss: 0.6869942642045471
Epoch: 41 | Iteration number: [4250/4518] 94% | Training loss: 0.6869937893362607
Epoch: 41 | Iteration number: [4260/4518] 94% | Training loss: 0.686994258744616
Epoch: 41 | Iteration number: [4270/4518] 94% | Training loss: 0.6869914384301429
Epoch: 41 | Iteration number: [4280/4518] 94% | Training loss: 0.6869916610350119
Epoch: 41 | Iteration number: [4290/4518] 94% | Training loss: 0.6869917025377145
Epoch: 41 | Iteration number: [4300/4518] 95% | Training loss: 0.6869926144078721
Epoch: 41 | Iteration number: [4310/4518] 95% | Training loss: 0.6869901960244588
Epoch: 41 | Iteration number: [4320/4518] 95% | Training loss: 0.6869880682478349
Epoch: 41 | Iteration number: [4330/4518] 95% | Training loss: 0.6869886385788818
Epoch: 41 | Iteration number: [4340/4518] 96% | Training loss: 0.6869873472759801
Epoch: 41 | Iteration number: [4350/4518] 96% | Training loss: 0.686988717687541
Epoch: 41 | Iteration number: [4360/4518] 96% | Training loss: 0.6869886180539744
Epoch: 41 | Iteration number: [4370/4518] 96% | Training loss: 0.6869843290381356
Epoch: 41 | Iteration number: [4380/4518] 96% | Training loss: 0.68698409954979
Epoch: 41 | Iteration number: [4390/4518] 97% | Training loss: 0.6869857911775759
Epoch: 41 | Iteration number: [4400/4518] 97% | Training loss: 0.686982654102824
Epoch: 41 | Iteration number: [4410/4518] 97% | Training loss: 0.6869838234518661
Epoch: 41 | Iteration number: [4420/4518] 97% | Training loss: 0.686982905069088
Epoch: 41 | Iteration number: [4430/4518] 98% | Training loss: 0.686982257452291
Epoch: 41 | Iteration number: [4440/4518] 98% | Training loss: 0.6869854220801646
Epoch: 41 | Iteration number: [4450/4518] 98% | Training loss: 0.6869867944583464
Epoch: 41 | Iteration number: [4460/4518] 98% | Training loss: 0.6869874746141947
Epoch: 41 | Iteration number: [4470/4518] 98% | Training loss: 0.6869862450582602
Epoch: 41 | Iteration number: [4480/4518] 99% | Training loss: 0.6869841690574373
Epoch: 41 | Iteration number: [4490/4518] 99% | Training loss: 0.686985400299187
Epoch: 41 | Iteration number: [4500/4518] 99% | Training loss: 0.6869859340985616
Epoch: 41 | Iteration number: [4510/4518] 99% | Training loss: 0.6869876456102088

 End of epoch: 41 | Train Loss: 0.6868349639991577 | Training Time: 645 

 End of epoch: 41 | Eval Loss: 0.6901627499230054 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/4518] 0% | Training loss: 0.7554508864879608
Epoch: 42 | Iteration number: [20/4518] 0% | Training loss: 0.7208431154489517
Epoch: 42 | Iteration number: [30/4518] 0% | Training loss: 0.7094143470128377
Epoch: 42 | Iteration number: [40/4518] 0% | Training loss: 0.7037422388792038
Epoch: 42 | Iteration number: [50/4518] 1% | Training loss: 0.7001546514034271
Epoch: 42 | Iteration number: [60/4518] 1% | Training loss: 0.6978998641173045
Epoch: 42 | Iteration number: [70/4518] 1% | Training loss: 0.696411406993866
Epoch: 42 | Iteration number: [80/4518] 1% | Training loss: 0.6949737951159477
Epoch: 42 | Iteration number: [90/4518] 1% | Training loss: 0.6940355188316769
Epoch: 42 | Iteration number: [100/4518] 2% | Training loss: 0.6933082509040832
Epoch: 42 | Iteration number: [110/4518] 2% | Training loss: 0.6927565011111173
Epoch: 42 | Iteration number: [120/4518] 2% | Training loss: 0.6922653660178184
Epoch: 42 | Iteration number: [130/4518] 2% | Training loss: 0.691877195926813
Epoch: 42 | Iteration number: [140/4518] 3% | Training loss: 0.6915117830038071
Epoch: 42 | Iteration number: [150/4518] 3% | Training loss: 0.6911031075318654
Epoch: 42 | Iteration number: [160/4518] 3% | Training loss: 0.6907910838723182
Epoch: 42 | Iteration number: [170/4518] 3% | Training loss: 0.6905758079360513
Epoch: 42 | Iteration number: [180/4518] 3% | Training loss: 0.6904572827948464
Epoch: 42 | Iteration number: [190/4518] 4% | Training loss: 0.690202725247333
Epoch: 42 | Iteration number: [200/4518] 4% | Training loss: 0.690002798140049
Epoch: 42 | Iteration number: [210/4518] 4% | Training loss: 0.6898880564031147
Epoch: 42 | Iteration number: [220/4518] 4% | Training loss: 0.6897314868190072
Epoch: 42 | Iteration number: [230/4518] 5% | Training loss: 0.6896209833414658
Epoch: 42 | Iteration number: [240/4518] 5% | Training loss: 0.689508531242609
Epoch: 42 | Iteration number: [250/4518] 5% | Training loss: 0.6894432327747345
Epoch: 42 | Iteration number: [260/4518] 5% | Training loss: 0.689385324716568
Epoch: 42 | Iteration number: [270/4518] 5% | Training loss: 0.6893339572129427
Epoch: 42 | Iteration number: [280/4518] 6% | Training loss: 0.6892406046390533
Epoch: 42 | Iteration number: [290/4518] 6% | Training loss: 0.6891766622148711
Epoch: 42 | Iteration number: [300/4518] 6% | Training loss: 0.6890195371707281
Epoch: 42 | Iteration number: [310/4518] 6% | Training loss: 0.6889515832547218
Epoch: 42 | Iteration number: [320/4518] 7% | Training loss: 0.6889288274571299
Epoch: 42 | Iteration number: [330/4518] 7% | Training loss: 0.6888943074327527
Epoch: 42 | Iteration number: [340/4518] 7% | Training loss: 0.6888417254475986
Epoch: 42 | Iteration number: [350/4518] 7% | Training loss: 0.688813134431839
Epoch: 42 | Iteration number: [360/4518] 7% | Training loss: 0.6887545305821631
Epoch: 42 | Iteration number: [370/4518] 8% | Training loss: 0.6886755439075264
Epoch: 42 | Iteration number: [380/4518] 8% | Training loss: 0.6886435858513179
Epoch: 42 | Iteration number: [390/4518] 8% | Training loss: 0.6886315319782649
Epoch: 42 | Iteration number: [400/4518] 8% | Training loss: 0.6885774324834347
Epoch: 42 | Iteration number: [410/4518] 9% | Training loss: 0.6885409605212328
Epoch: 42 | Iteration number: [420/4518] 9% | Training loss: 0.6884931456475031
Epoch: 42 | Iteration number: [430/4518] 9% | Training loss: 0.6884611911551897
Epoch: 42 | Iteration number: [440/4518] 9% | Training loss: 0.6884200651537288
Epoch: 42 | Iteration number: [450/4518] 9% | Training loss: 0.6883925598197513
Epoch: 42 | Iteration number: [460/4518] 10% | Training loss: 0.6883600849172343
Epoch: 42 | Iteration number: [470/4518] 10% | Training loss: 0.6883378309138277
Epoch: 42 | Iteration number: [480/4518] 10% | Training loss: 0.688298366839687
Epoch: 42 | Iteration number: [490/4518] 10% | Training loss: 0.688278646858371
Epoch: 42 | Iteration number: [500/4518] 11% | Training loss: 0.6882347625494003
Epoch: 42 | Iteration number: [510/4518] 11% | Training loss: 0.6882061759630839
Epoch: 42 | Iteration number: [520/4518] 11% | Training loss: 0.6881921079296333
Epoch: 42 | Iteration number: [530/4518] 11% | Training loss: 0.6881805326578752
Epoch: 42 | Iteration number: [540/4518] 11% | Training loss: 0.6881649628833488
Epoch: 42 | Iteration number: [550/4518] 12% | Training loss: 0.6881445172700015
Epoch: 42 | Iteration number: [560/4518] 12% | Training loss: 0.688119790064437
Epoch: 42 | Iteration number: [570/4518] 12% | Training loss: 0.6881133198738099
Epoch: 42 | Iteration number: [580/4518] 12% | Training loss: 0.6881067559636872
Epoch: 42 | Iteration number: [590/4518] 13% | Training loss: 0.6881096648967873
Epoch: 42 | Iteration number: [600/4518] 13% | Training loss: 0.6880675600965818
Epoch: 42 | Iteration number: [610/4518] 13% | Training loss: 0.6880505762139305
Epoch: 42 | Iteration number: [620/4518] 13% | Training loss: 0.6880400972020242
Epoch: 42 | Iteration number: [630/4518] 13% | Training loss: 0.6880048022383736
Epoch: 42 | Iteration number: [640/4518] 14% | Training loss: 0.6879938961938024
Epoch: 42 | Iteration number: [650/4518] 14% | Training loss: 0.6879483377933502
Epoch: 42 | Iteration number: [660/4518] 14% | Training loss: 0.6879377313635566
Epoch: 42 | Iteration number: [670/4518] 14% | Training loss: 0.6879147246702394
Epoch: 42 | Iteration number: [680/4518] 15% | Training loss: 0.6879225151503787
Epoch: 42 | Iteration number: [690/4518] 15% | Training loss: 0.6878897477751192
Epoch: 42 | Iteration number: [700/4518] 15% | Training loss: 0.6878594209466662
Epoch: 42 | Iteration number: [710/4518] 15% | Training loss: 0.6878310626661274
Epoch: 42 | Iteration number: [720/4518] 15% | Training loss: 0.687830580274264
Epoch: 42 | Iteration number: [730/4518] 16% | Training loss: 0.6878121103325935
Epoch: 42 | Iteration number: [740/4518] 16% | Training loss: 0.6878014868175661
Epoch: 42 | Iteration number: [750/4518] 16% | Training loss: 0.6877939836978912
Epoch: 42 | Iteration number: [760/4518] 16% | Training loss: 0.6877684699861627
Epoch: 42 | Iteration number: [770/4518] 17% | Training loss: 0.6877621231141029
Epoch: 42 | Iteration number: [780/4518] 17% | Training loss: 0.687759091762396
Epoch: 42 | Iteration number: [790/4518] 17% | Training loss: 0.6877517550051967
Epoch: 42 | Iteration number: [800/4518] 17% | Training loss: 0.6877356351166963
Epoch: 42 | Iteration number: [810/4518] 17% | Training loss: 0.6877287358413507
Epoch: 42 | Iteration number: [820/4518] 18% | Training loss: 0.6877258516666366
Epoch: 42 | Iteration number: [830/4518] 18% | Training loss: 0.6877173844590244
Epoch: 42 | Iteration number: [840/4518] 18% | Training loss: 0.6877173989301636
Epoch: 42 | Iteration number: [850/4518] 18% | Training loss: 0.6877012058566598
Epoch: 42 | Iteration number: [860/4518] 19% | Training loss: 0.6876878114633782
Epoch: 42 | Iteration number: [870/4518] 19% | Training loss: 0.6876775353804402
Epoch: 42 | Iteration number: [880/4518] 19% | Training loss: 0.6876633510670879
Epoch: 42 | Iteration number: [890/4518] 19% | Training loss: 0.6876459520854307
Epoch: 42 | Iteration number: [900/4518] 19% | Training loss: 0.6876274130741755
Epoch: 42 | Iteration number: [910/4518] 20% | Training loss: 0.687629227913343
Epoch: 42 | Iteration number: [920/4518] 20% | Training loss: 0.6876148862683255
Epoch: 42 | Iteration number: [930/4518] 20% | Training loss: 0.6876145533336107
Epoch: 42 | Iteration number: [940/4518] 20% | Training loss: 0.6876002416331717
Epoch: 42 | Iteration number: [950/4518] 21% | Training loss: 0.6875969443195744
Epoch: 42 | Iteration number: [960/4518] 21% | Training loss: 0.6875916083653768
Epoch: 42 | Iteration number: [970/4518] 21% | Training loss: 0.6875839124635322
Epoch: 42 | Iteration number: [980/4518] 21% | Training loss: 0.6875749694449561
Epoch: 42 | Iteration number: [990/4518] 21% | Training loss: 0.6875647581586934
Epoch: 42 | Iteration number: [1000/4518] 22% | Training loss: 0.6875531571507454
Epoch: 42 | Iteration number: [1010/4518] 22% | Training loss: 0.6875521568968744
Epoch: 42 | Iteration number: [1020/4518] 22% | Training loss: 0.6875298546225417
Epoch: 42 | Iteration number: [1030/4518] 22% | Training loss: 0.6875341448969055
Epoch: 42 | Iteration number: [1040/4518] 23% | Training loss: 0.6875078256313617
Epoch: 42 | Iteration number: [1050/4518] 23% | Training loss: 0.6874963223934174
Epoch: 42 | Iteration number: [1060/4518] 23% | Training loss: 0.6874936375977858
Epoch: 42 | Iteration number: [1070/4518] 23% | Training loss: 0.6875026350266465
Epoch: 42 | Iteration number: [1080/4518] 23% | Training loss: 0.6874934960846548
Epoch: 42 | Iteration number: [1090/4518] 24% | Training loss: 0.6874817789694585
Epoch: 42 | Iteration number: [1100/4518] 24% | Training loss: 0.687476244893941
Epoch: 42 | Iteration number: [1110/4518] 24% | Training loss: 0.6874600877095988
Epoch: 42 | Iteration number: [1120/4518] 24% | Training loss: 0.6874510254178728
Epoch: 42 | Iteration number: [1130/4518] 25% | Training loss: 0.687444115950998
Epoch: 42 | Iteration number: [1140/4518] 25% | Training loss: 0.6874469627413833
Epoch: 42 | Iteration number: [1150/4518] 25% | Training loss: 0.6874325640305229
Epoch: 42 | Iteration number: [1160/4518] 25% | Training loss: 0.6874390294325763
Epoch: 42 | Iteration number: [1170/4518] 25% | Training loss: 0.6874427158608396
Epoch: 42 | Iteration number: [1180/4518] 26% | Training loss: 0.687438283431328
Epoch: 42 | Iteration number: [1190/4518] 26% | Training loss: 0.6874364484758938
Epoch: 42 | Iteration number: [1200/4518] 26% | Training loss: 0.6874202091991901
Epoch: 42 | Iteration number: [1210/4518] 26% | Training loss: 0.6874140884758028
Epoch: 42 | Iteration number: [1220/4518] 27% | Training loss: 0.6874030906157416
Epoch: 42 | Iteration number: [1230/4518] 27% | Training loss: 0.6873920902004087
Epoch: 42 | Iteration number: [1240/4518] 27% | Training loss: 0.6873900410629088
Epoch: 42 | Iteration number: [1250/4518] 27% | Training loss: 0.6873902862548829
Epoch: 42 | Iteration number: [1260/4518] 27% | Training loss: 0.6873849601499618
Epoch: 42 | Iteration number: [1270/4518] 28% | Training loss: 0.6873785643596348
Epoch: 42 | Iteration number: [1280/4518] 28% | Training loss: 0.6873793474398553
Epoch: 42 | Iteration number: [1290/4518] 28% | Training loss: 0.6873716227305952
Epoch: 42 | Iteration number: [1300/4518] 28% | Training loss: 0.687365328852947
Epoch: 42 | Iteration number: [1310/4518] 28% | Training loss: 0.687361279789728
Epoch: 42 | Iteration number: [1320/4518] 29% | Training loss: 0.6873537535920288
Epoch: 42 | Iteration number: [1330/4518] 29% | Training loss: 0.6873580329848411
Epoch: 42 | Iteration number: [1340/4518] 29% | Training loss: 0.6873409116446082
Epoch: 42 | Iteration number: [1350/4518] 29% | Training loss: 0.6873290258425253
Epoch: 42 | Iteration number: [1360/4518] 30% | Training loss: 0.6873235487762619
Epoch: 42 | Iteration number: [1370/4518] 30% | Training loss: 0.6873210478873149
Epoch: 42 | Iteration number: [1380/4518] 30% | Training loss: 0.6873251859260642
Epoch: 42 | Iteration number: [1390/4518] 30% | Training loss: 0.6873271120966767
Epoch: 42 | Iteration number: [1400/4518] 30% | Training loss: 0.6873257745589528
Epoch: 42 | Iteration number: [1410/4518] 31% | Training loss: 0.6873172626850453
Epoch: 42 | Iteration number: [1420/4518] 31% | Training loss: 0.6873047515120305
Epoch: 42 | Iteration number: [1430/4518] 31% | Training loss: 0.6873080992615306
Epoch: 42 | Iteration number: [1440/4518] 31% | Training loss: 0.687304910313752
Epoch: 42 | Iteration number: [1450/4518] 32% | Training loss: 0.6872948786308025
Epoch: 42 | Iteration number: [1460/4518] 32% | Training loss: 0.6872973340831391
Epoch: 42 | Iteration number: [1470/4518] 32% | Training loss: 0.6872868383417324
Epoch: 42 | Iteration number: [1480/4518] 32% | Training loss: 0.687279272200288
Epoch: 42 | Iteration number: [1490/4518] 32% | Training loss: 0.6872707746972974
Epoch: 42 | Iteration number: [1500/4518] 33% | Training loss: 0.6872647066911062
Epoch: 42 | Iteration number: [1510/4518] 33% | Training loss: 0.6872618306156816
Epoch: 42 | Iteration number: [1520/4518] 33% | Training loss: 0.6872587702384121
Epoch: 42 | Iteration number: [1530/4518] 33% | Training loss: 0.687261374479805
Epoch: 42 | Iteration number: [1540/4518] 34% | Training loss: 0.687256313066978
Epoch: 42 | Iteration number: [1550/4518] 34% | Training loss: 0.6872574298612533
Epoch: 42 | Iteration number: [1560/4518] 34% | Training loss: 0.6872570316378886
Epoch: 42 | Iteration number: [1570/4518] 34% | Training loss: 0.6872497680460572
Epoch: 42 | Iteration number: [1580/4518] 34% | Training loss: 0.6872486077154739
Epoch: 42 | Iteration number: [1590/4518] 35% | Training loss: 0.6872417338989066
Epoch: 42 | Iteration number: [1600/4518] 35% | Training loss: 0.6872411654889583
Epoch: 42 | Iteration number: [1610/4518] 35% | Training loss: 0.687247676990047
Epoch: 42 | Iteration number: [1620/4518] 35% | Training loss: 0.6872477051652508
Epoch: 42 | Iteration number: [1630/4518] 36% | Training loss: 0.6872404783415648
Epoch: 42 | Iteration number: [1640/4518] 36% | Training loss: 0.6872428946378755
Epoch: 42 | Iteration number: [1650/4518] 36% | Training loss: 0.6872422787998662
Epoch: 42 | Iteration number: [1660/4518] 36% | Training loss: 0.6872386623936964
Epoch: 42 | Iteration number: [1670/4518] 36% | Training loss: 0.687234494821754
Epoch: 42 | Iteration number: [1680/4518] 37% | Training loss: 0.6872351447741191
Epoch: 42 | Iteration number: [1690/4518] 37% | Training loss: 0.6872294015080266
Epoch: 42 | Iteration number: [1700/4518] 37% | Training loss: 0.6872324318394941
Epoch: 42 | Iteration number: [1710/4518] 37% | Training loss: 0.6872251783895214
Epoch: 42 | Iteration number: [1720/4518] 38% | Training loss: 0.6872199302842451
Epoch: 42 | Iteration number: [1730/4518] 38% | Training loss: 0.6872198941046103
Epoch: 42 | Iteration number: [1740/4518] 38% | Training loss: 0.6872201437580174
Epoch: 42 | Iteration number: [1750/4518] 38% | Training loss: 0.6872189531666892
Epoch: 42 | Iteration number: [1760/4518] 38% | Training loss: 0.6872100392864509
Epoch: 42 | Iteration number: [1770/4518] 39% | Training loss: 0.6872062077966787
Epoch: 42 | Iteration number: [1780/4518] 39% | Training loss: 0.6872030205271217
Epoch: 42 | Iteration number: [1790/4518] 39% | Training loss: 0.6872020721768534
Epoch: 42 | Iteration number: [1800/4518] 39% | Training loss: 0.6871956264972687
Epoch: 42 | Iteration number: [1810/4518] 40% | Training loss: 0.6871883735472326
Epoch: 42 | Iteration number: [1820/4518] 40% | Training loss: 0.6871876254186525
Epoch: 42 | Iteration number: [1830/4518] 40% | Training loss: 0.6871883525223028
Epoch: 42 | Iteration number: [1840/4518] 40% | Training loss: 0.687184011126342
Epoch: 42 | Iteration number: [1850/4518] 40% | Training loss: 0.6871768662736223
Epoch: 42 | Iteration number: [1860/4518] 41% | Training loss: 0.687182179541998
Epoch: 42 | Iteration number: [1870/4518] 41% | Training loss: 0.687181833115491
Epoch: 42 | Iteration number: [1880/4518] 41% | Training loss: 0.6871803956780028
Epoch: 42 | Iteration number: [1890/4518] 41% | Training loss: 0.6871785091344642
Epoch: 42 | Iteration number: [1900/4518] 42% | Training loss: 0.6871812408221395
Epoch: 42 | Iteration number: [1910/4518] 42% | Training loss: 0.6871805747766145
Epoch: 42 | Iteration number: [1920/4518] 42% | Training loss: 0.6871697408147156
Epoch: 42 | Iteration number: [1930/4518] 42% | Training loss: 0.6871709117617631
Epoch: 42 | Iteration number: [1940/4518] 42% | Training loss: 0.6871659987366077
Epoch: 42 | Iteration number: [1950/4518] 43% | Training loss: 0.6871614727912805
Epoch: 42 | Iteration number: [1960/4518] 43% | Training loss: 0.6871599595461573
Epoch: 42 | Iteration number: [1970/4518] 43% | Training loss: 0.6871600349542453
Epoch: 42 | Iteration number: [1980/4518] 43% | Training loss: 0.6871601249834504
Epoch: 42 | Iteration number: [1990/4518] 44% | Training loss: 0.6871615626704154
Epoch: 42 | Iteration number: [2000/4518] 44% | Training loss: 0.6871650987565517
Epoch: 42 | Iteration number: [2010/4518] 44% | Training loss: 0.6871593204303761
Epoch: 42 | Iteration number: [2020/4518] 44% | Training loss: 0.6871608431091403
Epoch: 42 | Iteration number: [2030/4518] 44% | Training loss: 0.6871556499615091
Epoch: 42 | Iteration number: [2040/4518] 45% | Training loss: 0.6871605851194438
Epoch: 42 | Iteration number: [2050/4518] 45% | Training loss: 0.6871590245642313
Epoch: 42 | Iteration number: [2060/4518] 45% | Training loss: 0.6871637839426115
Epoch: 42 | Iteration number: [2070/4518] 45% | Training loss: 0.6871645888556605
Epoch: 42 | Iteration number: [2080/4518] 46% | Training loss: 0.6871592365205288
Epoch: 42 | Iteration number: [2090/4518] 46% | Training loss: 0.6871560421571777
Epoch: 42 | Iteration number: [2100/4518] 46% | Training loss: 0.6871546678883689
Epoch: 42 | Iteration number: [2110/4518] 46% | Training loss: 0.6871469235250736
Epoch: 42 | Iteration number: [2120/4518] 46% | Training loss: 0.6871490165310086
Epoch: 42 | Iteration number: [2130/4518] 47% | Training loss: 0.6871453570927812
Epoch: 42 | Iteration number: [2140/4518] 47% | Training loss: 0.687144835028693
Epoch: 42 | Iteration number: [2150/4518] 47% | Training loss: 0.6871377000143362
Epoch: 42 | Iteration number: [2160/4518] 47% | Training loss: 0.6871401081758517
Epoch: 42 | Iteration number: [2170/4518] 48% | Training loss: 0.6871383142636119
Epoch: 42 | Iteration number: [2180/4518] 48% | Training loss: 0.6871392136593477
Epoch: 42 | Iteration number: [2190/4518] 48% | Training loss: 0.6871434965362287
Epoch: 42 | Iteration number: [2200/4518] 48% | Training loss: 0.6871384585987438
Epoch: 42 | Iteration number: [2210/4518] 48% | Training loss: 0.6871377616716187
Epoch: 42 | Iteration number: [2220/4518] 49% | Training loss: 0.6871302146900882
Epoch: 42 | Iteration number: [2230/4518] 49% | Training loss: 0.6871231225841249
Epoch: 42 | Iteration number: [2240/4518] 49% | Training loss: 0.687120545655489
Epoch: 42 | Iteration number: [2250/4518] 49% | Training loss: 0.6871183298958673
Epoch: 42 | Iteration number: [2260/4518] 50% | Training loss: 0.68711672092961
Epoch: 42 | Iteration number: [2270/4518] 50% | Training loss: 0.6871081312584982
Epoch: 42 | Iteration number: [2280/4518] 50% | Training loss: 0.6871078707408487
Epoch: 42 | Iteration number: [2290/4518] 50% | Training loss: 0.6871005205608351
Epoch: 42 | Iteration number: [2300/4518] 50% | Training loss: 0.6871002688615219
Epoch: 42 | Iteration number: [2310/4518] 51% | Training loss: 0.6870950571644358
Epoch: 42 | Iteration number: [2320/4518] 51% | Training loss: 0.6870954421573672
Epoch: 42 | Iteration number: [2330/4518] 51% | Training loss: 0.6870952003503562
Epoch: 42 | Iteration number: [2340/4518] 51% | Training loss: 0.6870932262167971
Epoch: 42 | Iteration number: [2350/4518] 52% | Training loss: 0.6870888440659706
Epoch: 42 | Iteration number: [2360/4518] 52% | Training loss: 0.6870915618740906
Epoch: 42 | Iteration number: [2370/4518] 52% | Training loss: 0.6870903175088424
Epoch: 42 | Iteration number: [2380/4518] 52% | Training loss: 0.6870907281627174
Epoch: 42 | Iteration number: [2390/4518] 52% | Training loss: 0.6870936918208789
Epoch: 42 | Iteration number: [2400/4518] 53% | Training loss: 0.6870911061018705
Epoch: 42 | Iteration number: [2410/4518] 53% | Training loss: 0.6870865987296916
Epoch: 42 | Iteration number: [2420/4518] 53% | Training loss: 0.6870891785326083
Epoch: 42 | Iteration number: [2430/4518] 53% | Training loss: 0.687093499560415
Epoch: 42 | Iteration number: [2440/4518] 54% | Training loss: 0.6870887538204428
Epoch: 42 | Iteration number: [2450/4518] 54% | Training loss: 0.6870844198976245
Epoch: 42 | Iteration number: [2460/4518] 54% | Training loss: 0.6870789695319122
Epoch: 42 | Iteration number: [2470/4518] 54% | Training loss: 0.687075511598394
Epoch: 42 | Iteration number: [2480/4518] 54% | Training loss: 0.68706862751034
Epoch: 42 | Iteration number: [2490/4518] 55% | Training loss: 0.6870674024145287
Epoch: 42 | Iteration number: [2500/4518] 55% | Training loss: 0.6870686767101288
Epoch: 42 | Iteration number: [2510/4518] 55% | Training loss: 0.6870657698566696
Epoch: 42 | Iteration number: [2520/4518] 55% | Training loss: 0.6870652876203023
Epoch: 42 | Iteration number: [2530/4518] 55% | Training loss: 0.6870646658386638
Epoch: 42 | Iteration number: [2540/4518] 56% | Training loss: 0.6870633099726805
Epoch: 42 | Iteration number: [2550/4518] 56% | Training loss: 0.6870702698417739
Epoch: 42 | Iteration number: [2560/4518] 56% | Training loss: 0.6870677990140394
Epoch: 42 | Iteration number: [2570/4518] 56% | Training loss: 0.6870672133646123
Epoch: 42 | Iteration number: [2580/4518] 57% | Training loss: 0.6870676182730253
Epoch: 42 | Iteration number: [2590/4518] 57% | Training loss: 0.6870694533278123
Epoch: 42 | Iteration number: [2600/4518] 57% | Training loss: 0.6870696774812846
Epoch: 42 | Iteration number: [2610/4518] 57% | Training loss: 0.6870636200311083
Epoch: 42 | Iteration number: [2620/4518] 57% | Training loss: 0.6870606912456396
Epoch: 42 | Iteration number: [2630/4518] 58% | Training loss: 0.6870544330022181
Epoch: 42 | Iteration number: [2640/4518] 58% | Training loss: 0.6870547323064371
Epoch: 42 | Iteration number: [2650/4518] 58% | Training loss: 0.6870561210389408
Epoch: 42 | Iteration number: [2660/4518] 58% | Training loss: 0.6870532033138705
Epoch: 42 | Iteration number: [2670/4518] 59% | Training loss: 0.6870514005087734
Epoch: 42 | Iteration number: [2680/4518] 59% | Training loss: 0.6870532632763706
Epoch: 42 | Iteration number: [2690/4518] 59% | Training loss: 0.6870519127322838
Epoch: 42 | Iteration number: [2700/4518] 59% | Training loss: 0.6870548844337463
Epoch: 42 | Iteration number: [2710/4518] 59% | Training loss: 0.687052143301911
Epoch: 42 | Iteration number: [2720/4518] 60% | Training loss: 0.6870531447231769
Epoch: 42 | Iteration number: [2730/4518] 60% | Training loss: 0.6870562356033605
Epoch: 42 | Iteration number: [2740/4518] 60% | Training loss: 0.6870557572502289
Epoch: 42 | Iteration number: [2750/4518] 60% | Training loss: 0.687056529565291
Epoch: 42 | Iteration number: [2760/4518] 61% | Training loss: 0.6870512673172398
Epoch: 42 | Iteration number: [2770/4518] 61% | Training loss: 0.6870499646835809
Epoch: 42 | Iteration number: [2780/4518] 61% | Training loss: 0.6870500818645354
Epoch: 42 | Iteration number: [2790/4518] 61% | Training loss: 0.6870544426116465
Epoch: 42 | Iteration number: [2800/4518] 61% | Training loss: 0.6870518894919327
Epoch: 42 | Iteration number: [2810/4518] 62% | Training loss: 0.6870508671019001
Epoch: 42 | Iteration number: [2820/4518] 62% | Training loss: 0.6870487553853515
Epoch: 42 | Iteration number: [2830/4518] 62% | Training loss: 0.6870426768338301
Epoch: 42 | Iteration number: [2840/4518] 62% | Training loss: 0.6870439134852987
Epoch: 42 | Iteration number: [2850/4518] 63% | Training loss: 0.6870422583086448
Epoch: 42 | Iteration number: [2860/4518] 63% | Training loss: 0.6870447264476256
Epoch: 42 | Iteration number: [2870/4518] 63% | Training loss: 0.6870451010478082
Epoch: 42 | Iteration number: [2880/4518] 63% | Training loss: 0.6870429272246029
Epoch: 42 | Iteration number: [2890/4518] 63% | Training loss: 0.6870372823365419
Epoch: 42 | Iteration number: [2900/4518] 64% | Training loss: 0.6870372734604211
Epoch: 42 | Iteration number: [2910/4518] 64% | Training loss: 0.6870315589241146
Epoch: 42 | Iteration number: [2920/4518] 64% | Training loss: 0.687032278657776
Epoch: 42 | Iteration number: [2930/4518] 64% | Training loss: 0.687034899199782
Epoch: 42 | Iteration number: [2940/4518] 65% | Training loss: 0.6870379856451839
Epoch: 42 | Iteration number: [2950/4518] 65% | Training loss: 0.6870372873847768
Epoch: 42 | Iteration number: [2960/4518] 65% | Training loss: 0.6870349347994135
Epoch: 42 | Iteration number: [2970/4518] 65% | Training loss: 0.6870340223464901
Epoch: 42 | Iteration number: [2980/4518] 65% | Training loss: 0.6870339443019573
Epoch: 42 | Iteration number: [2990/4518] 66% | Training loss: 0.6870331298746791
Epoch: 42 | Iteration number: [3000/4518] 66% | Training loss: 0.6870348416566848
Epoch: 42 | Iteration number: [3010/4518] 66% | Training loss: 0.6870374546890639
Epoch: 42 | Iteration number: [3020/4518] 66% | Training loss: 0.6870330255552632
Epoch: 42 | Iteration number: [3030/4518] 67% | Training loss: 0.6870336525511034
Epoch: 42 | Iteration number: [3040/4518] 67% | Training loss: 0.6870333151401657
Epoch: 42 | Iteration number: [3050/4518] 67% | Training loss: 0.6870309289557035
Epoch: 42 | Iteration number: [3060/4518] 67% | Training loss: 0.6870323809338551
Epoch: 42 | Iteration number: [3070/4518] 67% | Training loss: 0.6870318591400544
Epoch: 42 | Iteration number: [3080/4518] 68% | Training loss: 0.6870277255967066
Epoch: 42 | Iteration number: [3090/4518] 68% | Training loss: 0.6870229712003257
Epoch: 42 | Iteration number: [3100/4518] 68% | Training loss: 0.6870200155242797
Epoch: 42 | Iteration number: [3110/4518] 68% | Training loss: 0.6870206551536486
Epoch: 42 | Iteration number: [3120/4518] 69% | Training loss: 0.6870193695410703
Epoch: 42 | Iteration number: [3130/4518] 69% | Training loss: 0.6870204508114166
Epoch: 42 | Iteration number: [3140/4518] 69% | Training loss: 0.6870231074512384
Epoch: 42 | Iteration number: [3150/4518] 69% | Training loss: 0.687019243164668
Epoch: 42 | Iteration number: [3160/4518] 69% | Training loss: 0.6870166303047651
Epoch: 42 | Iteration number: [3170/4518] 70% | Training loss: 0.6870171583977408
Epoch: 42 | Iteration number: [3180/4518] 70% | Training loss: 0.6870184462400353
Epoch: 42 | Iteration number: [3190/4518] 70% | Training loss: 0.6870166300232508
Epoch: 42 | Iteration number: [3200/4518] 70% | Training loss: 0.6870153499953449
Epoch: 42 | Iteration number: [3210/4518] 71% | Training loss: 0.6870128134329371
Epoch: 42 | Iteration number: [3220/4518] 71% | Training loss: 0.6870092123191549
Epoch: 42 | Iteration number: [3230/4518] 71% | Training loss: 0.6870100485466583
Epoch: 42 | Iteration number: [3240/4518] 71% | Training loss: 0.687010575628575
Epoch: 42 | Iteration number: [3250/4518] 71% | Training loss: 0.6870064871311188
Epoch: 42 | Iteration number: [3260/4518] 72% | Training loss: 0.6870052397799639
Epoch: 42 | Iteration number: [3270/4518] 72% | Training loss: 0.6870021010393031
Epoch: 42 | Iteration number: [3280/4518] 72% | Training loss: 0.6870007997969302
Epoch: 42 | Iteration number: [3290/4518] 72% | Training loss: 0.6869992815796003
Epoch: 42 | Iteration number: [3300/4518] 73% | Training loss: 0.6869985326131185
Epoch: 42 | Iteration number: [3310/4518] 73% | Training loss: 0.6869944857326519
Epoch: 42 | Iteration number: [3320/4518] 73% | Training loss: 0.6869929053158645
Epoch: 42 | Iteration number: [3330/4518] 73% | Training loss: 0.6869916061023335
Epoch: 42 | Iteration number: [3340/4518] 73% | Training loss: 0.6869914656449221
Epoch: 42 | Iteration number: [3350/4518] 74% | Training loss: 0.6869904042713678
Epoch: 42 | Iteration number: [3360/4518] 74% | Training loss: 0.686987910809971
Epoch: 42 | Iteration number: [3370/4518] 74% | Training loss: 0.6869858049851143
Epoch: 42 | Iteration number: [3380/4518] 74% | Training loss: 0.6869888847396218
Epoch: 42 | Iteration number: [3390/4518] 75% | Training loss: 0.6869883604985071
Epoch: 42 | Iteration number: [3400/4518] 75% | Training loss: 0.6869874501578948
Epoch: 42 | Iteration number: [3410/4518] 75% | Training loss: 0.6869875231446408
Epoch: 42 | Iteration number: [3420/4518] 75% | Training loss: 0.6869862862846308
Epoch: 42 | Iteration number: [3430/4518] 75% | Training loss: 0.6869864805968092
Epoch: 42 | Iteration number: [3440/4518] 76% | Training loss: 0.6869860976761164
Epoch: 42 | Iteration number: [3450/4518] 76% | Training loss: 0.6869862561640532
Epoch: 42 | Iteration number: [3460/4518] 76% | Training loss: 0.686986809538279
Epoch: 42 | Iteration number: [3470/4518] 76% | Training loss: 0.6869851054822333
Epoch: 42 | Iteration number: [3480/4518] 77% | Training loss: 0.6869862714889405
Epoch: 42 | Iteration number: [3490/4518] 77% | Training loss: 0.6869829439160475
Epoch: 42 | Iteration number: [3500/4518] 77% | Training loss: 0.6869790775094714
Epoch: 42 | Iteration number: [3510/4518] 77% | Training loss: 0.6869769958689003
Epoch: 42 | Iteration number: [3520/4518] 77% | Training loss: 0.6869763269512491
Epoch: 42 | Iteration number: [3530/4518] 78% | Training loss: 0.6869769207141218
Epoch: 42 | Iteration number: [3540/4518] 78% | Training loss: 0.6869810076083167
Epoch: 42 | Iteration number: [3550/4518] 78% | Training loss: 0.686978718579655
Epoch: 42 | Iteration number: [3560/4518] 78% | Training loss: 0.6869801760389563
Epoch: 42 | Iteration number: [3570/4518] 79% | Training loss: 0.6869796777305817
Epoch: 42 | Iteration number: [3580/4518] 79% | Training loss: 0.6869848438647872
Epoch: 42 | Iteration number: [3590/4518] 79% | Training loss: 0.6869838758431437
Epoch: 42 | Iteration number: [3600/4518] 79% | Training loss: 0.6869863850043879
Epoch: 42 | Iteration number: [3610/4518] 79% | Training loss: 0.6869867470455963
Epoch: 42 | Iteration number: [3620/4518] 80% | Training loss: 0.6869887214668547
Epoch: 42 | Iteration number: [3630/4518] 80% | Training loss: 0.6869881670337078
Epoch: 42 | Iteration number: [3640/4518] 80% | Training loss: 0.6869942258347522
Epoch: 42 | Iteration number: [3650/4518] 80% | Training loss: 0.6869937662229146
Epoch: 42 | Iteration number: [3660/4518] 81% | Training loss: 0.6869935130323869
Epoch: 42 | Iteration number: [3670/4518] 81% | Training loss: 0.6869936044599445
Epoch: 42 | Iteration number: [3680/4518] 81% | Training loss: 0.6869917994931988
Epoch: 42 | Iteration number: [3690/4518] 81% | Training loss: 0.6869937152720402
Epoch: 42 | Iteration number: [3700/4518] 81% | Training loss: 0.6869912395928357
Epoch: 42 | Iteration number: [3710/4518] 82% | Training loss: 0.6869919803585968
Epoch: 42 | Iteration number: [3720/4518] 82% | Training loss: 0.6869903685745372
Epoch: 42 | Iteration number: [3730/4518] 82% | Training loss: 0.6869901182824102
Epoch: 42 | Iteration number: [3740/4518] 82% | Training loss: 0.6869907614381555
Epoch: 42 | Iteration number: [3750/4518] 83% | Training loss: 0.6869882166703543
Epoch: 42 | Iteration number: [3760/4518] 83% | Training loss: 0.6869860243924121
Epoch: 42 | Iteration number: [3770/4518] 83% | Training loss: 0.6869828157620974
Epoch: 42 | Iteration number: [3780/4518] 83% | Training loss: 0.6869835964113317
Epoch: 42 | Iteration number: [3790/4518] 83% | Training loss: 0.686987150643306
Epoch: 42 | Iteration number: [3800/4518] 84% | Training loss: 0.6869878882953995
Epoch: 42 | Iteration number: [3810/4518] 84% | Training loss: 0.6869843676021405
Epoch: 42 | Iteration number: [3820/4518] 84% | Training loss: 0.6869861283695511
Epoch: 42 | Iteration number: [3830/4518] 84% | Training loss: 0.6869906442439276
Epoch: 42 | Iteration number: [3840/4518] 84% | Training loss: 0.6869883384245138
Epoch: 42 | Iteration number: [3850/4518] 85% | Training loss: 0.6869879113079665
Epoch: 42 | Iteration number: [3860/4518] 85% | Training loss: 0.6869880362187025
Epoch: 42 | Iteration number: [3870/4518] 85% | Training loss: 0.6869869705010446
Epoch: 42 | Iteration number: [3880/4518] 85% | Training loss: 0.6869894382726286
Epoch: 42 | Iteration number: [3890/4518] 86% | Training loss: 0.6869888021277891
Epoch: 42 | Iteration number: [3900/4518] 86% | Training loss: 0.6869866854869402
Epoch: 42 | Iteration number: [3910/4518] 86% | Training loss: 0.6869859566926346
Epoch: 42 | Iteration number: [3920/4518] 86% | Training loss: 0.6869844368373861
Epoch: 42 | Iteration number: [3930/4518] 86% | Training loss: 0.6869846645354011
Epoch: 42 | Iteration number: [3940/4518] 87% | Training loss: 0.6869831725274246
Epoch: 42 | Iteration number: [3950/4518] 87% | Training loss: 0.6869818699510791
Epoch: 42 | Iteration number: [3960/4518] 87% | Training loss: 0.6869825648990544
Epoch: 42 | Iteration number: [3970/4518] 87% | Training loss: 0.686979071018978
Epoch: 42 | Iteration number: [3980/4518] 88% | Training loss: 0.6869788003027739
Epoch: 42 | Iteration number: [3990/4518] 88% | Training loss: 0.6869765746115443
Epoch: 42 | Iteration number: [4000/4518] 88% | Training loss: 0.6869766610264778
Epoch: 42 | Iteration number: [4010/4518] 88% | Training loss: 0.6869786999320746
Epoch: 42 | Iteration number: [4020/4518] 88% | Training loss: 0.686981860470416
Epoch: 42 | Iteration number: [4030/4518] 89% | Training loss: 0.6869828414828251
Epoch: 42 | Iteration number: [4040/4518] 89% | Training loss: 0.6869837239089579
Epoch: 42 | Iteration number: [4050/4518] 89% | Training loss: 0.686981043226925
Epoch: 42 | Iteration number: [4060/4518] 89% | Training loss: 0.6869831985587557
Epoch: 42 | Iteration number: [4070/4518] 90% | Training loss: 0.6869852380172626
Epoch: 42 | Iteration number: [4080/4518] 90% | Training loss: 0.6869832611697562
Epoch: 42 | Iteration number: [4090/4518] 90% | Training loss: 0.6869826878195578
Epoch: 42 | Iteration number: [4100/4518] 90% | Training loss: 0.686985480727219
Epoch: 42 | Iteration number: [4110/4518] 90% | Training loss: 0.6869886071577559
Epoch: 42 | Iteration number: [4120/4518] 91% | Training loss: 0.6869893507037348
Epoch: 42 | Iteration number: [4130/4518] 91% | Training loss: 0.6869899667925754
Epoch: 42 | Iteration number: [4140/4518] 91% | Training loss: 0.6869889969411104
Epoch: 42 | Iteration number: [4150/4518] 91% | Training loss: 0.6869862364717276
Epoch: 42 | Iteration number: [4160/4518] 92% | Training loss: 0.6869882177848082
Epoch: 42 | Iteration number: [4170/4518] 92% | Training loss: 0.6869889915132408
Epoch: 42 | Iteration number: [4180/4518] 92% | Training loss: 0.6869879065232984
Epoch: 42 | Iteration number: [4190/4518] 92% | Training loss: 0.6869878153101072
Epoch: 42 | Iteration number: [4200/4518] 92% | Training loss: 0.6869879193958782
Epoch: 42 | Iteration number: [4210/4518] 93% | Training loss: 0.6869882448552057
Epoch: 42 | Iteration number: [4220/4518] 93% | Training loss: 0.6869890826432061
Epoch: 42 | Iteration number: [4230/4518] 93% | Training loss: 0.6869855712350661
Epoch: 42 | Iteration number: [4240/4518] 93% | Training loss: 0.686986139304233
Epoch: 42 | Iteration number: [4250/4518] 94% | Training loss: 0.6869873812198639
Epoch: 42 | Iteration number: [4260/4518] 94% | Training loss: 0.6869895630319354
Epoch: 42 | Iteration number: [4270/4518] 94% | Training loss: 0.6869919523003509
Epoch: 42 | Iteration number: [4280/4518] 94% | Training loss: 0.6869915845098896
Epoch: 42 | Iteration number: [4290/4518] 94% | Training loss: 0.6869931283947471
Epoch: 42 | Iteration number: [4300/4518] 95% | Training loss: 0.686991135741389
Epoch: 42 | Iteration number: [4310/4518] 95% | Training loss: 0.6869865963741134
Epoch: 42 | Iteration number: [4320/4518] 95% | Training loss: 0.6869838498256825
Epoch: 42 | Iteration number: [4330/4518] 95% | Training loss: 0.6869841703779428
Epoch: 42 | Iteration number: [4340/4518] 96% | Training loss: 0.6869877865237575
Epoch: 42 | Iteration number: [4350/4518] 96% | Training loss: 0.6869865530797805
Epoch: 42 | Iteration number: [4360/4518] 96% | Training loss: 0.686988056758675
Epoch: 42 | Iteration number: [4370/4518] 96% | Training loss: 0.6869862185053749
Epoch: 42 | Iteration number: [4380/4518] 96% | Training loss: 0.6869888440250806
Epoch: 42 | Iteration number: [4390/4518] 97% | Training loss: 0.6869878855408732
Epoch: 42 | Iteration number: [4400/4518] 97% | Training loss: 0.6869854836843231
Epoch: 42 | Iteration number: [4410/4518] 97% | Training loss: 0.6869838837323005
Epoch: 42 | Iteration number: [4420/4518] 97% | Training loss: 0.6869844375692342
Epoch: 42 | Iteration number: [4430/4518] 98% | Training loss: 0.6869847012965459
Epoch: 42 | Iteration number: [4440/4518] 98% | Training loss: 0.6869859317535753
Epoch: 42 | Iteration number: [4450/4518] 98% | Training loss: 0.6869872560795773
Epoch: 42 | Iteration number: [4460/4518] 98% | Training loss: 0.6869874782626404
Epoch: 42 | Iteration number: [4470/4518] 98% | Training loss: 0.6869889491623147
Epoch: 42 | Iteration number: [4480/4518] 99% | Training loss: 0.6869891117459961
Epoch: 42 | Iteration number: [4490/4518] 99% | Training loss: 0.6869895879038193
Epoch: 42 | Iteration number: [4500/4518] 99% | Training loss: 0.6869878314733505
Epoch: 42 | Iteration number: [4510/4518] 99% | Training loss: 0.686984936982195

 End of epoch: 42 | Train Loss: 0.6868338928437961 | Training Time: 641 

 End of epoch: 42 | Eval Loss: 0.6901522327442559 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/4518] 0% | Training loss: 0.7552434861660003
Epoch: 43 | Iteration number: [20/4518] 0% | Training loss: 0.7208996593952179
Epoch: 43 | Iteration number: [30/4518] 0% | Training loss: 0.7094420512517293
Epoch: 43 | Iteration number: [40/4518] 0% | Training loss: 0.7032183095812797
Epoch: 43 | Iteration number: [50/4518] 1% | Training loss: 0.6999514007568359
Epoch: 43 | Iteration number: [60/4518] 1% | Training loss: 0.6979374210039775
Epoch: 43 | Iteration number: [70/4518] 1% | Training loss: 0.6961934864521027
Epoch: 43 | Iteration number: [80/4518] 1% | Training loss: 0.69487948641181
Epoch: 43 | Iteration number: [90/4518] 1% | Training loss: 0.6940581566757626
Epoch: 43 | Iteration number: [100/4518] 2% | Training loss: 0.6931658035516739
Epoch: 43 | Iteration number: [110/4518] 2% | Training loss: 0.6926227228208022
Epoch: 43 | Iteration number: [120/4518] 2% | Training loss: 0.6921538800001145
Epoch: 43 | Iteration number: [130/4518] 2% | Training loss: 0.6918048088367169
Epoch: 43 | Iteration number: [140/4518] 3% | Training loss: 0.691464507154056
Epoch: 43 | Iteration number: [150/4518] 3% | Training loss: 0.6911737223466238
Epoch: 43 | Iteration number: [160/4518] 3% | Training loss: 0.6908892005681991
Epoch: 43 | Iteration number: [170/4518] 3% | Training loss: 0.6905907595858854
Epoch: 43 | Iteration number: [180/4518] 3% | Training loss: 0.690370378891627
Epoch: 43 | Iteration number: [190/4518] 4% | Training loss: 0.690124258555864
Epoch: 43 | Iteration number: [200/4518] 4% | Training loss: 0.6899952074885368
Epoch: 43 | Iteration number: [210/4518] 4% | Training loss: 0.6897440944399152
Epoch: 43 | Iteration number: [220/4518] 4% | Training loss: 0.6896238454363562
Epoch: 43 | Iteration number: [230/4518] 5% | Training loss: 0.6894863367080688
Epoch: 43 | Iteration number: [240/4518] 5% | Training loss: 0.6893839500844479
Epoch: 43 | Iteration number: [250/4518] 5% | Training loss: 0.6892320461273194
Epoch: 43 | Iteration number: [260/4518] 5% | Training loss: 0.6891215920448304
Epoch: 43 | Iteration number: [270/4518] 5% | Training loss: 0.6890441841549344
Epoch: 43 | Iteration number: [280/4518] 6% | Training loss: 0.6889552016343389
Epoch: 43 | Iteration number: [290/4518] 6% | Training loss: 0.6888055104633858
Epoch: 43 | Iteration number: [300/4518] 6% | Training loss: 0.688754206697146
Epoch: 43 | Iteration number: [310/4518] 6% | Training loss: 0.6886845009942208
Epoch: 43 | Iteration number: [320/4518] 7% | Training loss: 0.6886025559157133
Epoch: 43 | Iteration number: [330/4518] 7% | Training loss: 0.6885656181609991
Epoch: 43 | Iteration number: [340/4518] 7% | Training loss: 0.6885451472857419
Epoch: 43 | Iteration number: [350/4518] 7% | Training loss: 0.6884518195901598
Epoch: 43 | Iteration number: [360/4518] 7% | Training loss: 0.6884232885307736
Epoch: 43 | Iteration number: [370/4518] 8% | Training loss: 0.6883406589160095
Epoch: 43 | Iteration number: [380/4518] 8% | Training loss: 0.6883017458413777
Epoch: 43 | Iteration number: [390/4518] 8% | Training loss: 0.6882442894654396
Epoch: 43 | Iteration number: [400/4518] 8% | Training loss: 0.6882134382426739
Epoch: 43 | Iteration number: [410/4518] 9% | Training loss: 0.6882048569074491
Epoch: 43 | Iteration number: [420/4518] 9% | Training loss: 0.6881936121554602
Epoch: 43 | Iteration number: [430/4518] 9% | Training loss: 0.6881633522898651
Epoch: 43 | Iteration number: [440/4518] 9% | Training loss: 0.688107977942987
Epoch: 43 | Iteration number: [450/4518] 9% | Training loss: 0.6880794299973382
Epoch: 43 | Iteration number: [460/4518] 10% | Training loss: 0.6880667144837587
Epoch: 43 | Iteration number: [470/4518] 10% | Training loss: 0.6880575299263001
Epoch: 43 | Iteration number: [480/4518] 10% | Training loss: 0.6880176608761152
Epoch: 43 | Iteration number: [490/4518] 10% | Training loss: 0.688002712264353
Epoch: 43 | Iteration number: [500/4518] 11% | Training loss: 0.6879892041683197
Epoch: 43 | Iteration number: [510/4518] 11% | Training loss: 0.6879737832966972
Epoch: 43 | Iteration number: [520/4518] 11% | Training loss: 0.6879547472183521
Epoch: 43 | Iteration number: [530/4518] 11% | Training loss: 0.6879259525604968
Epoch: 43 | Iteration number: [540/4518] 11% | Training loss: 0.6879069852608222
Epoch: 43 | Iteration number: [550/4518] 12% | Training loss: 0.6879135748473081
Epoch: 43 | Iteration number: [560/4518] 12% | Training loss: 0.6879023419959205
Epoch: 43 | Iteration number: [570/4518] 12% | Training loss: 0.6878802549420742
Epoch: 43 | Iteration number: [580/4518] 12% | Training loss: 0.6878601844968467
Epoch: 43 | Iteration number: [590/4518] 13% | Training loss: 0.6878464030007184
Epoch: 43 | Iteration number: [600/4518] 13% | Training loss: 0.6878273956974348
Epoch: 43 | Iteration number: [610/4518] 13% | Training loss: 0.6878281600162631
Epoch: 43 | Iteration number: [620/4518] 13% | Training loss: 0.6878294580405758
Epoch: 43 | Iteration number: [630/4518] 13% | Training loss: 0.6878025678415147
Epoch: 43 | Iteration number: [640/4518] 14% | Training loss: 0.6877815103158355
Epoch: 43 | Iteration number: [650/4518] 14% | Training loss: 0.6877726459503174
Epoch: 43 | Iteration number: [660/4518] 14% | Training loss: 0.6877736982974139
Epoch: 43 | Iteration number: [670/4518] 14% | Training loss: 0.6877560728521489
Epoch: 43 | Iteration number: [680/4518] 15% | Training loss: 0.6877412991488681
Epoch: 43 | Iteration number: [690/4518] 15% | Training loss: 0.6877197412477023
Epoch: 43 | Iteration number: [700/4518] 15% | Training loss: 0.6877187152419771
Epoch: 43 | Iteration number: [710/4518] 15% | Training loss: 0.6877089330008332
Epoch: 43 | Iteration number: [720/4518] 15% | Training loss: 0.6876805435452197
Epoch: 43 | Iteration number: [730/4518] 16% | Training loss: 0.6876681616861526
Epoch: 43 | Iteration number: [740/4518] 16% | Training loss: 0.6876509280623616
Epoch: 43 | Iteration number: [750/4518] 16% | Training loss: 0.6876397071679433
Epoch: 43 | Iteration number: [760/4518] 16% | Training loss: 0.6876267927257638
Epoch: 43 | Iteration number: [770/4518] 17% | Training loss: 0.6875959745475224
Epoch: 43 | Iteration number: [780/4518] 17% | Training loss: 0.6876071801552406
Epoch: 43 | Iteration number: [790/4518] 17% | Training loss: 0.6875910210458538
Epoch: 43 | Iteration number: [800/4518] 17% | Training loss: 0.6875860204547644
Epoch: 43 | Iteration number: [810/4518] 17% | Training loss: 0.6875897169849019
Epoch: 43 | Iteration number: [820/4518] 18% | Training loss: 0.6875587465559564
Epoch: 43 | Iteration number: [830/4518] 18% | Training loss: 0.6875658572438251
Epoch: 43 | Iteration number: [840/4518] 18% | Training loss: 0.6875570101397378
Epoch: 43 | Iteration number: [850/4518] 18% | Training loss: 0.6875474870906156
Epoch: 43 | Iteration number: [860/4518] 19% | Training loss: 0.6875192021907762
Epoch: 43 | Iteration number: [870/4518] 19% | Training loss: 0.687508974746726
Epoch: 43 | Iteration number: [880/4518] 19% | Training loss: 0.6874849484725432
Epoch: 43 | Iteration number: [890/4518] 19% | Training loss: 0.6874814859267031
Epoch: 43 | Iteration number: [900/4518] 19% | Training loss: 0.6874736830261019
Epoch: 43 | Iteration number: [910/4518] 20% | Training loss: 0.6874708406872801
Epoch: 43 | Iteration number: [920/4518] 20% | Training loss: 0.6874680532061536
Epoch: 43 | Iteration number: [930/4518] 20% | Training loss: 0.687453241309812
Epoch: 43 | Iteration number: [940/4518] 20% | Training loss: 0.6874465495982068
Epoch: 43 | Iteration number: [950/4518] 21% | Training loss: 0.6874446960499412
Epoch: 43 | Iteration number: [960/4518] 21% | Training loss: 0.6874376350392898
Epoch: 43 | Iteration number: [970/4518] 21% | Training loss: 0.6874357221052819
Epoch: 43 | Iteration number: [980/4518] 21% | Training loss: 0.687431285940871
Epoch: 43 | Iteration number: [990/4518] 21% | Training loss: 0.687426377908148
Epoch: 43 | Iteration number: [1000/4518] 22% | Training loss: 0.6874225896596908
Epoch: 43 | Iteration number: [1010/4518] 22% | Training loss: 0.6874185282995205
Epoch: 43 | Iteration number: [1020/4518] 22% | Training loss: 0.6874145779539557
Epoch: 43 | Iteration number: [1030/4518] 22% | Training loss: 0.6874043701343167
Epoch: 43 | Iteration number: [1040/4518] 23% | Training loss: 0.6873883973520536
Epoch: 43 | Iteration number: [1050/4518] 23% | Training loss: 0.6873886238960992
Epoch: 43 | Iteration number: [1060/4518] 23% | Training loss: 0.687372820950904
Epoch: 43 | Iteration number: [1070/4518] 23% | Training loss: 0.6873719034350921
Epoch: 43 | Iteration number: [1080/4518] 23% | Training loss: 0.6873695806772621
Epoch: 43 | Iteration number: [1090/4518] 24% | Training loss: 0.6873630086216358
Epoch: 43 | Iteration number: [1100/4518] 24% | Training loss: 0.6873618040843443
Epoch: 43 | Iteration number: [1110/4518] 24% | Training loss: 0.6873568864019067
Epoch: 43 | Iteration number: [1120/4518] 24% | Training loss: 0.6873483557254076
Epoch: 43 | Iteration number: [1130/4518] 25% | Training loss: 0.6873354054657759
Epoch: 43 | Iteration number: [1140/4518] 25% | Training loss: 0.6873256142202177
Epoch: 43 | Iteration number: [1150/4518] 25% | Training loss: 0.6873274595322816
Epoch: 43 | Iteration number: [1160/4518] 25% | Training loss: 0.6873314609301502
Epoch: 43 | Iteration number: [1170/4518] 25% | Training loss: 0.6873242568256509
Epoch: 43 | Iteration number: [1180/4518] 26% | Training loss: 0.6873260036868564
Epoch: 43 | Iteration number: [1190/4518] 26% | Training loss: 0.6873253246315387
Epoch: 43 | Iteration number: [1200/4518] 26% | Training loss: 0.6873247019946576
Epoch: 43 | Iteration number: [1210/4518] 26% | Training loss: 0.6873297097269169
Epoch: 43 | Iteration number: [1220/4518] 27% | Training loss: 0.6873217484501541
Epoch: 43 | Iteration number: [1230/4518] 27% | Training loss: 0.6873167389776649
Epoch: 43 | Iteration number: [1240/4518] 27% | Training loss: 0.6873110534683351
Epoch: 43 | Iteration number: [1250/4518] 27% | Training loss: 0.6873071467399597
Epoch: 43 | Iteration number: [1260/4518] 27% | Training loss: 0.6873059801166019
Epoch: 43 | Iteration number: [1270/4518] 28% | Training loss: 0.6872959199383503
Epoch: 43 | Iteration number: [1280/4518] 28% | Training loss: 0.6872938347514719
Epoch: 43 | Iteration number: [1290/4518] 28% | Training loss: 0.6872871683549512
Epoch: 43 | Iteration number: [1300/4518] 28% | Training loss: 0.6872917070755592
Epoch: 43 | Iteration number: [1310/4518] 28% | Training loss: 0.6872876789733654
Epoch: 43 | Iteration number: [1320/4518] 29% | Training loss: 0.6872907923929619
Epoch: 43 | Iteration number: [1330/4518] 29% | Training loss: 0.6872948928883201
Epoch: 43 | Iteration number: [1340/4518] 29% | Training loss: 0.6872882069491628
Epoch: 43 | Iteration number: [1350/4518] 29% | Training loss: 0.6872820271386041
Epoch: 43 | Iteration number: [1360/4518] 30% | Training loss: 0.6872906271149131
Epoch: 43 | Iteration number: [1370/4518] 30% | Training loss: 0.6872929223697551
Epoch: 43 | Iteration number: [1380/4518] 30% | Training loss: 0.6872904508874036
Epoch: 43 | Iteration number: [1390/4518] 30% | Training loss: 0.6872900077336126
Epoch: 43 | Iteration number: [1400/4518] 30% | Training loss: 0.6872850847244263
Epoch: 43 | Iteration number: [1410/4518] 31% | Training loss: 0.6872873873998088
Epoch: 43 | Iteration number: [1420/4518] 31% | Training loss: 0.6872734621377058
Epoch: 43 | Iteration number: [1430/4518] 31% | Training loss: 0.6872764457772662
Epoch: 43 | Iteration number: [1440/4518] 31% | Training loss: 0.6872673879481024
Epoch: 43 | Iteration number: [1450/4518] 32% | Training loss: 0.6872696909822267
Epoch: 43 | Iteration number: [1460/4518] 32% | Training loss: 0.6872661571388375
Epoch: 43 | Iteration number: [1470/4518] 32% | Training loss: 0.6872622753081679
Epoch: 43 | Iteration number: [1480/4518] 32% | Training loss: 0.687250441715524
Epoch: 43 | Iteration number: [1490/4518] 32% | Training loss: 0.6872493194253653
Epoch: 43 | Iteration number: [1500/4518] 33% | Training loss: 0.6872426317135493
Epoch: 43 | Iteration number: [1510/4518] 33% | Training loss: 0.6872431030731327
Epoch: 43 | Iteration number: [1520/4518] 33% | Training loss: 0.6872499856901796
Epoch: 43 | Iteration number: [1530/4518] 33% | Training loss: 0.687249813710942
Epoch: 43 | Iteration number: [1540/4518] 34% | Training loss: 0.687240084618717
Epoch: 43 | Iteration number: [1550/4518] 34% | Training loss: 0.6872368165369956
Epoch: 43 | Iteration number: [1560/4518] 34% | Training loss: 0.68723944322421
Epoch: 43 | Iteration number: [1570/4518] 34% | Training loss: 0.6872353963411538
Epoch: 43 | Iteration number: [1580/4518] 34% | Training loss: 0.6872303693732129
Epoch: 43 | Iteration number: [1590/4518] 35% | Training loss: 0.6872226765695608
Epoch: 43 | Iteration number: [1600/4518] 35% | Training loss: 0.6872143374383449
Epoch: 43 | Iteration number: [1610/4518] 35% | Training loss: 0.6872109588258755
Epoch: 43 | Iteration number: [1620/4518] 35% | Training loss: 0.6872100153455027
Epoch: 43 | Iteration number: [1630/4518] 36% | Training loss: 0.6872049688927235
Epoch: 43 | Iteration number: [1640/4518] 36% | Training loss: 0.6872074424857046
Epoch: 43 | Iteration number: [1650/4518] 36% | Training loss: 0.687211446762085
Epoch: 43 | Iteration number: [1660/4518] 36% | Training loss: 0.687205505047936
Epoch: 43 | Iteration number: [1670/4518] 36% | Training loss: 0.6871986814244778
Epoch: 43 | Iteration number: [1680/4518] 37% | Training loss: 0.6871967206753435
Epoch: 43 | Iteration number: [1690/4518] 37% | Training loss: 0.6871975235332398
Epoch: 43 | Iteration number: [1700/4518] 37% | Training loss: 0.6871990549213746
Epoch: 43 | Iteration number: [1710/4518] 37% | Training loss: 0.6871993055120547
Epoch: 43 | Iteration number: [1720/4518] 38% | Training loss: 0.687197008728981
Epoch: 43 | Iteration number: [1730/4518] 38% | Training loss: 0.6871965893431206
Epoch: 43 | Iteration number: [1740/4518] 38% | Training loss: 0.6871926949969653
Epoch: 43 | Iteration number: [1750/4518] 38% | Training loss: 0.6871904044832502
Epoch: 43 | Iteration number: [1760/4518] 38% | Training loss: 0.6871881776573983
Epoch: 43 | Iteration number: [1770/4518] 39% | Training loss: 0.6871904771543492
Epoch: 43 | Iteration number: [1780/4518] 39% | Training loss: 0.6871897434920408
Epoch: 43 | Iteration number: [1790/4518] 39% | Training loss: 0.6871832786325636
Epoch: 43 | Iteration number: [1800/4518] 39% | Training loss: 0.6871758942140473
Epoch: 43 | Iteration number: [1810/4518] 40% | Training loss: 0.6871757411825065
Epoch: 43 | Iteration number: [1820/4518] 40% | Training loss: 0.6871752129478769
Epoch: 43 | Iteration number: [1830/4518] 40% | Training loss: 0.6871744235356648
Epoch: 43 | Iteration number: [1840/4518] 40% | Training loss: 0.6871794310276923
Epoch: 43 | Iteration number: [1850/4518] 40% | Training loss: 0.6871705547538963
Epoch: 43 | Iteration number: [1860/4518] 41% | Training loss: 0.6871661989919601
Epoch: 43 | Iteration number: [1870/4518] 41% | Training loss: 0.6871674223698396
Epoch: 43 | Iteration number: [1880/4518] 41% | Training loss: 0.6871711692594468
Epoch: 43 | Iteration number: [1890/4518] 41% | Training loss: 0.6871730438931278
Epoch: 43 | Iteration number: [1900/4518] 42% | Training loss: 0.6871724003867099
Epoch: 43 | Iteration number: [1910/4518] 42% | Training loss: 0.6871690380011554
Epoch: 43 | Iteration number: [1920/4518] 42% | Training loss: 0.6871684586629272
Epoch: 43 | Iteration number: [1930/4518] 42% | Training loss: 0.6871622384212178
Epoch: 43 | Iteration number: [1940/4518] 42% | Training loss: 0.6871635612753249
Epoch: 43 | Iteration number: [1950/4518] 43% | Training loss: 0.6871575689315796
Epoch: 43 | Iteration number: [1960/4518] 43% | Training loss: 0.6871582954817889
Epoch: 43 | Iteration number: [1970/4518] 43% | Training loss: 0.6871637605773616
Epoch: 43 | Iteration number: [1980/4518] 43% | Training loss: 0.6871591200431187
Epoch: 43 | Iteration number: [1990/4518] 44% | Training loss: 0.6871551177309985
Epoch: 43 | Iteration number: [2000/4518] 44% | Training loss: 0.6871526916921139
Epoch: 43 | Iteration number: [2010/4518] 44% | Training loss: 0.6871468318635552
Epoch: 43 | Iteration number: [2020/4518] 44% | Training loss: 0.6871481884824168
Epoch: 43 | Iteration number: [2030/4518] 44% | Training loss: 0.6871463969716884
Epoch: 43 | Iteration number: [2040/4518] 45% | Training loss: 0.687144318661269
Epoch: 43 | Iteration number: [2050/4518] 45% | Training loss: 0.6871402876842313
Epoch: 43 | Iteration number: [2060/4518] 45% | Training loss: 0.6871421415828964
Epoch: 43 | Iteration number: [2070/4518] 45% | Training loss: 0.6871462833478255
Epoch: 43 | Iteration number: [2080/4518] 46% | Training loss: 0.6871486670122697
Epoch: 43 | Iteration number: [2090/4518] 46% | Training loss: 0.6871507814341185
Epoch: 43 | Iteration number: [2100/4518] 46% | Training loss: 0.6871471783093044
Epoch: 43 | Iteration number: [2110/4518] 46% | Training loss: 0.6871441303271253
Epoch: 43 | Iteration number: [2120/4518] 46% | Training loss: 0.687142777920894
Epoch: 43 | Iteration number: [2130/4518] 47% | Training loss: 0.6871408659527559
Epoch: 43 | Iteration number: [2140/4518] 47% | Training loss: 0.6871374736879473
Epoch: 43 | Iteration number: [2150/4518] 47% | Training loss: 0.6871382845002552
Epoch: 43 | Iteration number: [2160/4518] 47% | Training loss: 0.6871378278014837
Epoch: 43 | Iteration number: [2170/4518] 48% | Training loss: 0.6871394737799597
Epoch: 43 | Iteration number: [2180/4518] 48% | Training loss: 0.6871330012695505
Epoch: 43 | Iteration number: [2190/4518] 48% | Training loss: 0.6871313138095211
Epoch: 43 | Iteration number: [2200/4518] 48% | Training loss: 0.6871264297311956
Epoch: 43 | Iteration number: [2210/4518] 48% | Training loss: 0.6871231752283433
Epoch: 43 | Iteration number: [2220/4518] 49% | Training loss: 0.6871230234970918
Epoch: 43 | Iteration number: [2230/4518] 49% | Training loss: 0.6871155446954906
Epoch: 43 | Iteration number: [2240/4518] 49% | Training loss: 0.6871161031137619
Epoch: 43 | Iteration number: [2250/4518] 49% | Training loss: 0.6871121646563212
Epoch: 43 | Iteration number: [2260/4518] 50% | Training loss: 0.6871088021624405
Epoch: 43 | Iteration number: [2270/4518] 50% | Training loss: 0.6871020356463966
Epoch: 43 | Iteration number: [2280/4518] 50% | Training loss: 0.6871030830500419
Epoch: 43 | Iteration number: [2290/4518] 50% | Training loss: 0.6871009343836505
Epoch: 43 | Iteration number: [2300/4518] 50% | Training loss: 0.6871013929014621
Epoch: 43 | Iteration number: [2310/4518] 51% | Training loss: 0.6870998125829738
Epoch: 43 | Iteration number: [2320/4518] 51% | Training loss: 0.68709401873679
Epoch: 43 | Iteration number: [2330/4518] 51% | Training loss: 0.6870859752141355
Epoch: 43 | Iteration number: [2340/4518] 51% | Training loss: 0.6870817937147923
Epoch: 43 | Iteration number: [2350/4518] 52% | Training loss: 0.6870739574635283
Epoch: 43 | Iteration number: [2360/4518] 52% | Training loss: 0.6870765582232152
Epoch: 43 | Iteration number: [2370/4518] 52% | Training loss: 0.6870810888990572
Epoch: 43 | Iteration number: [2380/4518] 52% | Training loss: 0.6870809363717792
Epoch: 43 | Iteration number: [2390/4518] 52% | Training loss: 0.6870813256277699
Epoch: 43 | Iteration number: [2400/4518] 53% | Training loss: 0.6870783916115761
Epoch: 43 | Iteration number: [2410/4518] 53% | Training loss: 0.6870806600542979
Epoch: 43 | Iteration number: [2420/4518] 53% | Training loss: 0.6870841326053477
Epoch: 43 | Iteration number: [2430/4518] 53% | Training loss: 0.6870864786238337
Epoch: 43 | Iteration number: [2440/4518] 54% | Training loss: 0.6870821163791125
Epoch: 43 | Iteration number: [2450/4518] 54% | Training loss: 0.6870751084356892
Epoch: 43 | Iteration number: [2460/4518] 54% | Training loss: 0.6870705364438576
Epoch: 43 | Iteration number: [2470/4518] 54% | Training loss: 0.6870735882264882
Epoch: 43 | Iteration number: [2480/4518] 54% | Training loss: 0.687067636847496
Epoch: 43 | Iteration number: [2490/4518] 55% | Training loss: 0.6870669453019598
Epoch: 43 | Iteration number: [2500/4518] 55% | Training loss: 0.6870668416500092
Epoch: 43 | Iteration number: [2510/4518] 55% | Training loss: 0.6870652332723853
Epoch: 43 | Iteration number: [2520/4518] 55% | Training loss: 0.6870614534569165
Epoch: 43 | Iteration number: [2530/4518] 55% | Training loss: 0.6870653243404132
Epoch: 43 | Iteration number: [2540/4518] 56% | Training loss: 0.687063855167449
Epoch: 43 | Iteration number: [2550/4518] 56% | Training loss: 0.6870656414592967
Epoch: 43 | Iteration number: [2560/4518] 56% | Training loss: 0.6870615579653532
Epoch: 43 | Iteration number: [2570/4518] 56% | Training loss: 0.6870592335318777
Epoch: 43 | Iteration number: [2580/4518] 57% | Training loss: 0.6870615624180135
Epoch: 43 | Iteration number: [2590/4518] 57% | Training loss: 0.6870628326325803
Epoch: 43 | Iteration number: [2600/4518] 57% | Training loss: 0.6870626157292953
Epoch: 43 | Iteration number: [2610/4518] 57% | Training loss: 0.687062488639035
Epoch: 43 | Iteration number: [2620/4518] 57% | Training loss: 0.6870589830948196
Epoch: 43 | Iteration number: [2630/4518] 58% | Training loss: 0.6870549042415256
Epoch: 43 | Iteration number: [2640/4518] 58% | Training loss: 0.6870528769989809
Epoch: 43 | Iteration number: [2650/4518] 58% | Training loss: 0.6870566294553145
Epoch: 43 | Iteration number: [2660/4518] 58% | Training loss: 0.6870581923122693
Epoch: 43 | Iteration number: [2670/4518] 59% | Training loss: 0.6870587019438155
Epoch: 43 | Iteration number: [2680/4518] 59% | Training loss: 0.687057203009947
Epoch: 43 | Iteration number: [2690/4518] 59% | Training loss: 0.6870570373136314
Epoch: 43 | Iteration number: [2700/4518] 59% | Training loss: 0.6870529781889032
Epoch: 43 | Iteration number: [2710/4518] 59% | Training loss: 0.6870519346416656
Epoch: 43 | Iteration number: [2720/4518] 60% | Training loss: 0.6870492603410693
Epoch: 43 | Iteration number: [2730/4518] 60% | Training loss: 0.6870520162713397
Epoch: 43 | Iteration number: [2740/4518] 60% | Training loss: 0.687052115689229
Epoch: 43 | Iteration number: [2750/4518] 60% | Training loss: 0.6870488067323511
Epoch: 43 | Iteration number: [2760/4518] 61% | Training loss: 0.6870477866651356
Epoch: 43 | Iteration number: [2770/4518] 61% | Training loss: 0.6870453238702423
Epoch: 43 | Iteration number: [2780/4518] 61% | Training loss: 0.6870456702632012
Epoch: 43 | Iteration number: [2790/4518] 61% | Training loss: 0.6870476563985203
Epoch: 43 | Iteration number: [2800/4518] 61% | Training loss: 0.6870470892531532
Epoch: 43 | Iteration number: [2810/4518] 62% | Training loss: 0.6870474355076556
Epoch: 43 | Iteration number: [2820/4518] 62% | Training loss: 0.6870449954313589
Epoch: 43 | Iteration number: [2830/4518] 62% | Training loss: 0.6870439051739319
Epoch: 43 | Iteration number: [2840/4518] 62% | Training loss: 0.68704407047218
Epoch: 43 | Iteration number: [2850/4518] 63% | Training loss: 0.6870426873156898
Epoch: 43 | Iteration number: [2860/4518] 63% | Training loss: 0.6870427353190376
Epoch: 43 | Iteration number: [2870/4518] 63% | Training loss: 0.6870413810533929
Epoch: 43 | Iteration number: [2880/4518] 63% | Training loss: 0.6870389647781849
Epoch: 43 | Iteration number: [2890/4518] 63% | Training loss: 0.6870399433848767
Epoch: 43 | Iteration number: [2900/4518] 64% | Training loss: 0.6870386165380478
Epoch: 43 | Iteration number: [2910/4518] 64% | Training loss: 0.6870387758790832
Epoch: 43 | Iteration number: [2920/4518] 64% | Training loss: 0.6870437115634958
Epoch: 43 | Iteration number: [2930/4518] 64% | Training loss: 0.687040569005159
Epoch: 43 | Iteration number: [2940/4518] 65% | Training loss: 0.6870433951518974
Epoch: 43 | Iteration number: [2950/4518] 65% | Training loss: 0.6870450717513844
Epoch: 43 | Iteration number: [2960/4518] 65% | Training loss: 0.6870436484749253
Epoch: 43 | Iteration number: [2970/4518] 65% | Training loss: 0.6870452260328864
Epoch: 43 | Iteration number: [2980/4518] 65% | Training loss: 0.6870459432569926
Epoch: 43 | Iteration number: [2990/4518] 66% | Training loss: 0.6870440986443522
Epoch: 43 | Iteration number: [3000/4518] 66% | Training loss: 0.6870465683539708
Epoch: 43 | Iteration number: [3010/4518] 66% | Training loss: 0.6870435028179144
Epoch: 43 | Iteration number: [3020/4518] 66% | Training loss: 0.6870454626170215
Epoch: 43 | Iteration number: [3030/4518] 67% | Training loss: 0.6870441218807359
Epoch: 43 | Iteration number: [3040/4518] 67% | Training loss: 0.6870450180023908
Epoch: 43 | Iteration number: [3050/4518] 67% | Training loss: 0.6870448083760309
Epoch: 43 | Iteration number: [3060/4518] 67% | Training loss: 0.6870429749777115
Epoch: 43 | Iteration number: [3070/4518] 67% | Training loss: 0.6870450365232722
Epoch: 43 | Iteration number: [3080/4518] 68% | Training loss: 0.6870425062713685
Epoch: 43 | Iteration number: [3090/4518] 68% | Training loss: 0.6870426216557574
Epoch: 43 | Iteration number: [3100/4518] 68% | Training loss: 0.6870429779252698
Epoch: 43 | Iteration number: [3110/4518] 68% | Training loss: 0.687043950009576
Epoch: 43 | Iteration number: [3120/4518] 69% | Training loss: 0.6870444406874668
Epoch: 43 | Iteration number: [3130/4518] 69% | Training loss: 0.6870441420581013
Epoch: 43 | Iteration number: [3140/4518] 69% | Training loss: 0.6870397135330614
Epoch: 43 | Iteration number: [3150/4518] 69% | Training loss: 0.6870401289917174
Epoch: 43 | Iteration number: [3160/4518] 69% | Training loss: 0.6870403211893915
Epoch: 43 | Iteration number: [3170/4518] 70% | Training loss: 0.6870419884893797
Epoch: 43 | Iteration number: [3180/4518] 70% | Training loss: 0.6870389859256505
Epoch: 43 | Iteration number: [3190/4518] 70% | Training loss: 0.6870386426912206
Epoch: 43 | Iteration number: [3200/4518] 70% | Training loss: 0.6870417602360248
Epoch: 43 | Iteration number: [3210/4518] 71% | Training loss: 0.6870384348330096
Epoch: 43 | Iteration number: [3220/4518] 71% | Training loss: 0.6870392613159203
Epoch: 43 | Iteration number: [3230/4518] 71% | Training loss: 0.6870370552820317
Epoch: 43 | Iteration number: [3240/4518] 71% | Training loss: 0.6870376789827406
Epoch: 43 | Iteration number: [3250/4518] 71% | Training loss: 0.6870368072253007
Epoch: 43 | Iteration number: [3260/4518] 72% | Training loss: 0.6870366486120809
Epoch: 43 | Iteration number: [3270/4518] 72% | Training loss: 0.687038746248327
Epoch: 43 | Iteration number: [3280/4518] 72% | Training loss: 0.6870375826591398
Epoch: 43 | Iteration number: [3290/4518] 72% | Training loss: 0.6870394686253962
Epoch: 43 | Iteration number: [3300/4518] 73% | Training loss: 0.6870414486798373
Epoch: 43 | Iteration number: [3310/4518] 73% | Training loss: 0.6870410218519747
Epoch: 43 | Iteration number: [3320/4518] 73% | Training loss: 0.6870340402585914
Epoch: 43 | Iteration number: [3330/4518] 73% | Training loss: 0.6870330264618447
Epoch: 43 | Iteration number: [3340/4518] 73% | Training loss: 0.6870347713638922
Epoch: 43 | Iteration number: [3350/4518] 74% | Training loss: 0.687036317426767
Epoch: 43 | Iteration number: [3360/4518] 74% | Training loss: 0.6870363566492285
Epoch: 43 | Iteration number: [3370/4518] 74% | Training loss: 0.6870346549887332
Epoch: 43 | Iteration number: [3380/4518] 74% | Training loss: 0.6870360045919757
Epoch: 43 | Iteration number: [3390/4518] 75% | Training loss: 0.6870323194339212
Epoch: 43 | Iteration number: [3400/4518] 75% | Training loss: 0.6870306790576262
Epoch: 43 | Iteration number: [3410/4518] 75% | Training loss: 0.6870308516486998
Epoch: 43 | Iteration number: [3420/4518] 75% | Training loss: 0.6870296570815538
Epoch: 43 | Iteration number: [3430/4518] 75% | Training loss: 0.6870317469011591
Epoch: 43 | Iteration number: [3440/4518] 76% | Training loss: 0.6870293976955636
Epoch: 43 | Iteration number: [3450/4518] 76% | Training loss: 0.6870305090365203
Epoch: 43 | Iteration number: [3460/4518] 76% | Training loss: 0.6870294303046486
Epoch: 43 | Iteration number: [3470/4518] 76% | Training loss: 0.6870291906921595
Epoch: 43 | Iteration number: [3480/4518] 77% | Training loss: 0.6870308642586073
Epoch: 43 | Iteration number: [3490/4518] 77% | Training loss: 0.6870263801092404
Epoch: 43 | Iteration number: [3500/4518] 77% | Training loss: 0.6870272578341621
Epoch: 43 | Iteration number: [3510/4518] 77% | Training loss: 0.6870269917354964
Epoch: 43 | Iteration number: [3520/4518] 77% | Training loss: 0.6870272963053801
Epoch: 43 | Iteration number: [3530/4518] 78% | Training loss: 0.6870255039704083
Epoch: 43 | Iteration number: [3540/4518] 78% | Training loss: 0.6870211686791673
Epoch: 43 | Iteration number: [3550/4518] 78% | Training loss: 0.6870195394334658
Epoch: 43 | Iteration number: [3560/4518] 78% | Training loss: 0.687018744915389
Epoch: 43 | Iteration number: [3570/4518] 79% | Training loss: 0.6870156785520185
Epoch: 43 | Iteration number: [3580/4518] 79% | Training loss: 0.6870189097340547
Epoch: 43 | Iteration number: [3590/4518] 79% | Training loss: 0.6870153727803722
Epoch: 43 | Iteration number: [3600/4518] 79% | Training loss: 0.6870172259542677
Epoch: 43 | Iteration number: [3610/4518] 79% | Training loss: 0.6870181321107119
Epoch: 43 | Iteration number: [3620/4518] 80% | Training loss: 0.687016398784864
Epoch: 43 | Iteration number: [3630/4518] 80% | Training loss: 0.6870174990212622
Epoch: 43 | Iteration number: [3640/4518] 80% | Training loss: 0.687018828536128
Epoch: 43 | Iteration number: [3650/4518] 80% | Training loss: 0.6870188316090466
Epoch: 43 | Iteration number: [3660/4518] 81% | Training loss: 0.6870169085883052
Epoch: 43 | Iteration number: [3670/4518] 81% | Training loss: 0.6870168852383824
Epoch: 43 | Iteration number: [3680/4518] 81% | Training loss: 0.6870167714584133
Epoch: 43 | Iteration number: [3690/4518] 81% | Training loss: 0.6870175889352473
Epoch: 43 | Iteration number: [3700/4518] 81% | Training loss: 0.6870189467958502
Epoch: 43 | Iteration number: [3710/4518] 82% | Training loss: 0.687019715411965
Epoch: 43 | Iteration number: [3720/4518] 82% | Training loss: 0.6870204805686909
Epoch: 43 | Iteration number: [3730/4518] 82% | Training loss: 0.6870156322503538
Epoch: 43 | Iteration number: [3740/4518] 82% | Training loss: 0.6870139271499002
Epoch: 43 | Iteration number: [3750/4518] 83% | Training loss: 0.6870151059945424
Epoch: 43 | Iteration number: [3760/4518] 83% | Training loss: 0.6870182578233962
Epoch: 43 | Iteration number: [3770/4518] 83% | Training loss: 0.6870191746744616
Epoch: 43 | Iteration number: [3780/4518] 83% | Training loss: 0.6870166363381834
Epoch: 43 | Iteration number: [3790/4518] 83% | Training loss: 0.6870152686076303
Epoch: 43 | Iteration number: [3800/4518] 84% | Training loss: 0.6870116147242095
Epoch: 43 | Iteration number: [3810/4518] 84% | Training loss: 0.6870112378453332
Epoch: 43 | Iteration number: [3820/4518] 84% | Training loss: 0.6870123953875447
Epoch: 43 | Iteration number: [3830/4518] 84% | Training loss: 0.6870112136356513
Epoch: 43 | Iteration number: [3840/4518] 84% | Training loss: 0.6870092171709985
Epoch: 43 | Iteration number: [3850/4518] 85% | Training loss: 0.687007251497987
Epoch: 43 | Iteration number: [3860/4518] 85% | Training loss: 0.6870078832683167
Epoch: 43 | Iteration number: [3870/4518] 85% | Training loss: 0.6870074676912884
Epoch: 43 | Iteration number: [3880/4518] 85% | Training loss: 0.6870063045743815
Epoch: 43 | Iteration number: [3890/4518] 86% | Training loss: 0.687004770227447
Epoch: 43 | Iteration number: [3900/4518] 86% | Training loss: 0.6870057266950608
Epoch: 43 | Iteration number: [3910/4518] 86% | Training loss: 0.6870012639885973
Epoch: 43 | Iteration number: [3920/4518] 86% | Training loss: 0.6870006773848922
Epoch: 43 | Iteration number: [3930/4518] 86% | Training loss: 0.6870021350662824
Epoch: 43 | Iteration number: [3940/4518] 87% | Training loss: 0.6869988059634484
Epoch: 43 | Iteration number: [3950/4518] 87% | Training loss: 0.6869993341119983
Epoch: 43 | Iteration number: [3960/4518] 87% | Training loss: 0.6869983981203551
Epoch: 43 | Iteration number: [3970/4518] 87% | Training loss: 0.6869923061177472
Epoch: 43 | Iteration number: [3980/4518] 88% | Training loss: 0.68699601017051
Epoch: 43 | Iteration number: [3990/4518] 88% | Training loss: 0.6869959618214676
Epoch: 43 | Iteration number: [4000/4518] 88% | Training loss: 0.6869962479025126
Epoch: 43 | Iteration number: [4010/4518] 88% | Training loss: 0.6869954127771896
Epoch: 43 | Iteration number: [4020/4518] 88% | Training loss: 0.6869956637496379
Epoch: 43 | Iteration number: [4030/4518] 89% | Training loss: 0.686997538745847
Epoch: 43 | Iteration number: [4040/4518] 89% | Training loss: 0.6869966999434008
Epoch: 43 | Iteration number: [4050/4518] 89% | Training loss: 0.6869960758421156
Epoch: 43 | Iteration number: [4060/4518] 89% | Training loss: 0.6869953933460959
Epoch: 43 | Iteration number: [4070/4518] 90% | Training loss: 0.6869922608210355
Epoch: 43 | Iteration number: [4080/4518] 90% | Training loss: 0.6869921553514752
Epoch: 43 | Iteration number: [4090/4518] 90% | Training loss: 0.6869908601264207
Epoch: 43 | Iteration number: [4100/4518] 90% | Training loss: 0.6869903181675003
Epoch: 43 | Iteration number: [4110/4518] 90% | Training loss: 0.6869916378581611
Epoch: 43 | Iteration number: [4120/4518] 91% | Training loss: 0.6869921563464461
Epoch: 43 | Iteration number: [4130/4518] 91% | Training loss: 0.6869924588584438
Epoch: 43 | Iteration number: [4140/4518] 91% | Training loss: 0.6869909799761242
Epoch: 43 | Iteration number: [4150/4518] 91% | Training loss: 0.686990081488368
Epoch: 43 | Iteration number: [4160/4518] 92% | Training loss: 0.6869877791318756
Epoch: 43 | Iteration number: [4170/4518] 92% | Training loss: 0.6869896620154666
Epoch: 43 | Iteration number: [4180/4518] 92% | Training loss: 0.6869915202759099
Epoch: 43 | Iteration number: [4190/4518] 92% | Training loss: 0.6869910389682843
Epoch: 43 | Iteration number: [4200/4518] 92% | Training loss: 0.6869898367070016
Epoch: 43 | Iteration number: [4210/4518] 93% | Training loss: 0.6869851006181676
Epoch: 43 | Iteration number: [4220/4518] 93% | Training loss: 0.6869871913821777
Epoch: 43 | Iteration number: [4230/4518] 93% | Training loss: 0.6869856112392236
Epoch: 43 | Iteration number: [4240/4518] 93% | Training loss: 0.6869867824580309
Epoch: 43 | Iteration number: [4250/4518] 94% | Training loss: 0.6869871544136721
Epoch: 43 | Iteration number: [4260/4518] 94% | Training loss: 0.6869893440618201
Epoch: 43 | Iteration number: [4270/4518] 94% | Training loss: 0.6869905841015541
Epoch: 43 | Iteration number: [4280/4518] 94% | Training loss: 0.6869903075360806
Epoch: 43 | Iteration number: [4290/4518] 94% | Training loss: 0.6869886910165106
Epoch: 43 | Iteration number: [4300/4518] 95% | Training loss: 0.6869888328812843
Epoch: 43 | Iteration number: [4310/4518] 95% | Training loss: 0.6869895014159917
Epoch: 43 | Iteration number: [4320/4518] 95% | Training loss: 0.6869887897261867
Epoch: 43 | Iteration number: [4330/4518] 95% | Training loss: 0.6869874974596583
Epoch: 43 | Iteration number: [4340/4518] 96% | Training loss: 0.686985314510385
Epoch: 43 | Iteration number: [4350/4518] 96% | Training loss: 0.6869871500990856
Epoch: 43 | Iteration number: [4360/4518] 96% | Training loss: 0.6869895794522871
Epoch: 43 | Iteration number: [4370/4518] 96% | Training loss: 0.6869902565222856
Epoch: 43 | Iteration number: [4380/4518] 96% | Training loss: 0.6869904661559623
Epoch: 43 | Iteration number: [4390/4518] 97% | Training loss: 0.6869888205327315
Epoch: 43 | Iteration number: [4400/4518] 97% | Training loss: 0.6869878122887828
Epoch: 43 | Iteration number: [4410/4518] 97% | Training loss: 0.6869870114083193
Epoch: 43 | Iteration number: [4420/4518] 97% | Training loss: 0.6869893648775455
Epoch: 43 | Iteration number: [4430/4518] 98% | Training loss: 0.6869911722620239
Epoch: 43 | Iteration number: [4440/4518] 98% | Training loss: 0.6869894854120306
Epoch: 43 | Iteration number: [4450/4518] 98% | Training loss: 0.6869884409261553
Epoch: 43 | Iteration number: [4460/4518] 98% | Training loss: 0.6869917591724695
Epoch: 43 | Iteration number: [4470/4518] 98% | Training loss: 0.6869902609845403
Epoch: 43 | Iteration number: [4480/4518] 99% | Training loss: 0.6869900880647557
Epoch: 43 | Iteration number: [4490/4518] 99% | Training loss: 0.6869891069912433
Epoch: 43 | Iteration number: [4500/4518] 99% | Training loss: 0.6869854109552171
Epoch: 43 | Iteration number: [4510/4518] 99% | Training loss: 0.68698474652487

 End of epoch: 43 | Train Loss: 0.6868305732292008 | Training Time: 641 

 End of epoch: 43 | Eval Loss: 0.6901315061413512 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/4518] 0% | Training loss: 0.7561934232711792
Epoch: 44 | Iteration number: [20/4518] 0% | Training loss: 0.7216540932655334
Epoch: 44 | Iteration number: [30/4518] 0% | Training loss: 0.7100654006004333
Epoch: 44 | Iteration number: [40/4518] 0% | Training loss: 0.70407485216856
Epoch: 44 | Iteration number: [50/4518] 1% | Training loss: 0.7007227146625519
Epoch: 44 | Iteration number: [60/4518] 1% | Training loss: 0.6984089841445287
Epoch: 44 | Iteration number: [70/4518] 1% | Training loss: 0.6966006900582995
Epoch: 44 | Iteration number: [80/4518] 1% | Training loss: 0.6951325006783009
Epoch: 44 | Iteration number: [90/4518] 1% | Training loss: 0.6942255675792695
Epoch: 44 | Iteration number: [100/4518] 2% | Training loss: 0.6934239739179611
Epoch: 44 | Iteration number: [110/4518] 2% | Training loss: 0.6928333846005527
Epoch: 44 | Iteration number: [120/4518] 2% | Training loss: 0.6923503309488297
Epoch: 44 | Iteration number: [130/4518] 2% | Training loss: 0.6918830912846785
Epoch: 44 | Iteration number: [140/4518] 3% | Training loss: 0.6915915148598807
Epoch: 44 | Iteration number: [150/4518] 3% | Training loss: 0.6912872552871704
Epoch: 44 | Iteration number: [160/4518] 3% | Training loss: 0.691030440106988
Epoch: 44 | Iteration number: [170/4518] 3% | Training loss: 0.6907611352555892
Epoch: 44 | Iteration number: [180/4518] 3% | Training loss: 0.6905458195341958
Epoch: 44 | Iteration number: [190/4518] 4% | Training loss: 0.6903481342290577
Epoch: 44 | Iteration number: [200/4518] 4% | Training loss: 0.6901551315188408
Epoch: 44 | Iteration number: [210/4518] 4% | Training loss: 0.6899966203031086
Epoch: 44 | Iteration number: [220/4518] 4% | Training loss: 0.6899133484471928
Epoch: 44 | Iteration number: [230/4518] 5% | Training loss: 0.6898277510767398
Epoch: 44 | Iteration number: [240/4518] 5% | Training loss: 0.6897279175619284
Epoch: 44 | Iteration number: [250/4518] 5% | Training loss: 0.6895613360404969
Epoch: 44 | Iteration number: [260/4518] 5% | Training loss: 0.68947733434347
Epoch: 44 | Iteration number: [270/4518] 5% | Training loss: 0.6893825954861111
Epoch: 44 | Iteration number: [280/4518] 6% | Training loss: 0.6893050983548165
Epoch: 44 | Iteration number: [290/4518] 6% | Training loss: 0.6891906216226775
Epoch: 44 | Iteration number: [300/4518] 6% | Training loss: 0.6891171022256215
Epoch: 44 | Iteration number: [310/4518] 6% | Training loss: 0.689005474505886
Epoch: 44 | Iteration number: [320/4518] 7% | Training loss: 0.6889513615518809
Epoch: 44 | Iteration number: [330/4518] 7% | Training loss: 0.6888775119275757
Epoch: 44 | Iteration number: [340/4518] 7% | Training loss: 0.6888016837484696
Epoch: 44 | Iteration number: [350/4518] 7% | Training loss: 0.6887523475715093
Epoch: 44 | Iteration number: [360/4518] 7% | Training loss: 0.688703929218981
Epoch: 44 | Iteration number: [370/4518] 8% | Training loss: 0.6886945871082513
Epoch: 44 | Iteration number: [380/4518] 8% | Training loss: 0.6886350283497258
Epoch: 44 | Iteration number: [390/4518] 8% | Training loss: 0.6885870831134991
Epoch: 44 | Iteration number: [400/4518] 8% | Training loss: 0.6885416193306446
Epoch: 44 | Iteration number: [410/4518] 9% | Training loss: 0.6885035907349936
Epoch: 44 | Iteration number: [420/4518] 9% | Training loss: 0.6884959422406696
Epoch: 44 | Iteration number: [430/4518] 9% | Training loss: 0.6884598684865375
Epoch: 44 | Iteration number: [440/4518] 9% | Training loss: 0.6884099417112091
Epoch: 44 | Iteration number: [450/4518] 9% | Training loss: 0.6883632930119833
Epoch: 44 | Iteration number: [460/4518] 10% | Training loss: 0.6883067964211754
Epoch: 44 | Iteration number: [470/4518] 10% | Training loss: 0.6882672063847806
Epoch: 44 | Iteration number: [480/4518] 10% | Training loss: 0.6882484298199415
Epoch: 44 | Iteration number: [490/4518] 10% | Training loss: 0.6882085125057065
Epoch: 44 | Iteration number: [500/4518] 11% | Training loss: 0.6881971571445465
Epoch: 44 | Iteration number: [510/4518] 11% | Training loss: 0.6881827398842456
Epoch: 44 | Iteration number: [520/4518] 11% | Training loss: 0.6881631208153871
Epoch: 44 | Iteration number: [530/4518] 11% | Training loss: 0.6881257184271542
Epoch: 44 | Iteration number: [540/4518] 11% | Training loss: 0.6881250529377548
Epoch: 44 | Iteration number: [550/4518] 12% | Training loss: 0.6881061456420204
Epoch: 44 | Iteration number: [560/4518] 12% | Training loss: 0.6881204362426485
Epoch: 44 | Iteration number: [570/4518] 12% | Training loss: 0.6880977875307986
Epoch: 44 | Iteration number: [580/4518] 12% | Training loss: 0.6880821007079092
Epoch: 44 | Iteration number: [590/4518] 13% | Training loss: 0.6880810374930754
Epoch: 44 | Iteration number: [600/4518] 13% | Training loss: 0.6880462324619293
Epoch: 44 | Iteration number: [610/4518] 13% | Training loss: 0.6880160544739395
Epoch: 44 | Iteration number: [620/4518] 13% | Training loss: 0.6880070311407889
Epoch: 44 | Iteration number: [630/4518] 13% | Training loss: 0.6879954836671315
Epoch: 44 | Iteration number: [640/4518] 14% | Training loss: 0.687987654749304
Epoch: 44 | Iteration number: [650/4518] 14% | Training loss: 0.6879795435758738
Epoch: 44 | Iteration number: [660/4518] 14% | Training loss: 0.6879579760811546
Epoch: 44 | Iteration number: [670/4518] 14% | Training loss: 0.6879715405293365
Epoch: 44 | Iteration number: [680/4518] 15% | Training loss: 0.6879634425920599
Epoch: 44 | Iteration number: [690/4518] 15% | Training loss: 0.6879538855690887
Epoch: 44 | Iteration number: [700/4518] 15% | Training loss: 0.6879392042330333
Epoch: 44 | Iteration number: [710/4518] 15% | Training loss: 0.6879387343433542
Epoch: 44 | Iteration number: [720/4518] 15% | Training loss: 0.6879137262701989
Epoch: 44 | Iteration number: [730/4518] 16% | Training loss: 0.6878924612313101
Epoch: 44 | Iteration number: [740/4518] 16% | Training loss: 0.687887930950603
Epoch: 44 | Iteration number: [750/4518] 16% | Training loss: 0.6878701379299164
Epoch: 44 | Iteration number: [760/4518] 16% | Training loss: 0.6878416997821708
Epoch: 44 | Iteration number: [770/4518] 17% | Training loss: 0.6878327824078597
Epoch: 44 | Iteration number: [780/4518] 17% | Training loss: 0.6878312295063947
Epoch: 44 | Iteration number: [790/4518] 17% | Training loss: 0.6878319756139682
Epoch: 44 | Iteration number: [800/4518] 17% | Training loss: 0.687824070379138
Epoch: 44 | Iteration number: [810/4518] 17% | Training loss: 0.6877946950035331
Epoch: 44 | Iteration number: [820/4518] 18% | Training loss: 0.6877718916026557
Epoch: 44 | Iteration number: [830/4518] 18% | Training loss: 0.6877557479473482
Epoch: 44 | Iteration number: [840/4518] 18% | Training loss: 0.6877430419127146
Epoch: 44 | Iteration number: [850/4518] 18% | Training loss: 0.6877334441156948
Epoch: 44 | Iteration number: [860/4518] 19% | Training loss: 0.6877268513967825
Epoch: 44 | Iteration number: [870/4518] 19% | Training loss: 0.6877224539888316
Epoch: 44 | Iteration number: [880/4518] 19% | Training loss: 0.6877071630548347
Epoch: 44 | Iteration number: [890/4518] 19% | Training loss: 0.6876870035455468
Epoch: 44 | Iteration number: [900/4518] 19% | Training loss: 0.6876842005385293
Epoch: 44 | Iteration number: [910/4518] 20% | Training loss: 0.687656622994077
Epoch: 44 | Iteration number: [920/4518] 20% | Training loss: 0.6876512103754541
Epoch: 44 | Iteration number: [930/4518] 20% | Training loss: 0.6876522749341945
Epoch: 44 | Iteration number: [940/4518] 20% | Training loss: 0.687645396336596
Epoch: 44 | Iteration number: [950/4518] 21% | Training loss: 0.6876243876783471
Epoch: 44 | Iteration number: [960/4518] 21% | Training loss: 0.6876266350969672
Epoch: 44 | Iteration number: [970/4518] 21% | Training loss: 0.687605189846963
Epoch: 44 | Iteration number: [980/4518] 21% | Training loss: 0.6875900144479713
Epoch: 44 | Iteration number: [990/4518] 21% | Training loss: 0.6875796973103224
Epoch: 44 | Iteration number: [1000/4518] 22% | Training loss: 0.687586835026741
Epoch: 44 | Iteration number: [1010/4518] 22% | Training loss: 0.6875716870964164
Epoch: 44 | Iteration number: [1020/4518] 22% | Training loss: 0.6875618420979556
Epoch: 44 | Iteration number: [1030/4518] 22% | Training loss: 0.6875572372408747
Epoch: 44 | Iteration number: [1040/4518] 23% | Training loss: 0.6875375399222741
Epoch: 44 | Iteration number: [1050/4518] 23% | Training loss: 0.6875222020489828
Epoch: 44 | Iteration number: [1060/4518] 23% | Training loss: 0.6875125195057887
Epoch: 44 | Iteration number: [1070/4518] 23% | Training loss: 0.6875121707114104
Epoch: 44 | Iteration number: [1080/4518] 23% | Training loss: 0.6875042758606098
Epoch: 44 | Iteration number: [1090/4518] 24% | Training loss: 0.6874989529815289
Epoch: 44 | Iteration number: [1100/4518] 24% | Training loss: 0.6874960882013494
Epoch: 44 | Iteration number: [1110/4518] 24% | Training loss: 0.6874826448457735
Epoch: 44 | Iteration number: [1120/4518] 24% | Training loss: 0.6874774386308022
Epoch: 44 | Iteration number: [1130/4518] 25% | Training loss: 0.6874660370096696
Epoch: 44 | Iteration number: [1140/4518] 25% | Training loss: 0.6874556663266399
Epoch: 44 | Iteration number: [1150/4518] 25% | Training loss: 0.6874592471641043
Epoch: 44 | Iteration number: [1160/4518] 25% | Training loss: 0.6874537361079249
Epoch: 44 | Iteration number: [1170/4518] 25% | Training loss: 0.6874489465330401
Epoch: 44 | Iteration number: [1180/4518] 26% | Training loss: 0.687432323522487
Epoch: 44 | Iteration number: [1190/4518] 26% | Training loss: 0.6874213686009415
Epoch: 44 | Iteration number: [1200/4518] 26% | Training loss: 0.6874165365099907
Epoch: 44 | Iteration number: [1210/4518] 26% | Training loss: 0.6874081762861615
Epoch: 44 | Iteration number: [1220/4518] 27% | Training loss: 0.68740139823468
Epoch: 44 | Iteration number: [1230/4518] 27% | Training loss: 0.6873915559392635
Epoch: 44 | Iteration number: [1240/4518] 27% | Training loss: 0.6873898303797168
Epoch: 44 | Iteration number: [1250/4518] 27% | Training loss: 0.687386736536026
Epoch: 44 | Iteration number: [1260/4518] 27% | Training loss: 0.6873762664813844
Epoch: 44 | Iteration number: [1270/4518] 28% | Training loss: 0.6873650353255234
Epoch: 44 | Iteration number: [1280/4518] 28% | Training loss: 0.6873598408419639
Epoch: 44 | Iteration number: [1290/4518] 28% | Training loss: 0.6873542265374532
Epoch: 44 | Iteration number: [1300/4518] 28% | Training loss: 0.6873420328818834
Epoch: 44 | Iteration number: [1310/4518] 28% | Training loss: 0.687333493742324
Epoch: 44 | Iteration number: [1320/4518] 29% | Training loss: 0.6873330098209959
Epoch: 44 | Iteration number: [1330/4518] 29% | Training loss: 0.6873334008051937
Epoch: 44 | Iteration number: [1340/4518] 29% | Training loss: 0.6873277758484456
Epoch: 44 | Iteration number: [1350/4518] 29% | Training loss: 0.6873207057846917
Epoch: 44 | Iteration number: [1360/4518] 30% | Training loss: 0.6873185123590863
Epoch: 44 | Iteration number: [1370/4518] 30% | Training loss: 0.6873260287037731
Epoch: 44 | Iteration number: [1380/4518] 30% | Training loss: 0.6873274293066799
Epoch: 44 | Iteration number: [1390/4518] 30% | Training loss: 0.6873145474804391
Epoch: 44 | Iteration number: [1400/4518] 30% | Training loss: 0.6873087577734674
Epoch: 44 | Iteration number: [1410/4518] 31% | Training loss: 0.687306314157256
Epoch: 44 | Iteration number: [1420/4518] 31% | Training loss: 0.6873072989809681
Epoch: 44 | Iteration number: [1430/4518] 31% | Training loss: 0.6873036013199733
Epoch: 44 | Iteration number: [1440/4518] 31% | Training loss: 0.6872920068601768
Epoch: 44 | Iteration number: [1450/4518] 32% | Training loss: 0.6872856558191365
Epoch: 44 | Iteration number: [1460/4518] 32% | Training loss: 0.6872846859366927
Epoch: 44 | Iteration number: [1470/4518] 32% | Training loss: 0.6872797163165345
Epoch: 44 | Iteration number: [1480/4518] 32% | Training loss: 0.6872851307327683
Epoch: 44 | Iteration number: [1490/4518] 32% | Training loss: 0.6872796455485709
Epoch: 44 | Iteration number: [1500/4518] 33% | Training loss: 0.6872817477385204
Epoch: 44 | Iteration number: [1510/4518] 33% | Training loss: 0.6872803354894879
Epoch: 44 | Iteration number: [1520/4518] 33% | Training loss: 0.6872828425153306
Epoch: 44 | Iteration number: [1530/4518] 33% | Training loss: 0.6872785320079404
Epoch: 44 | Iteration number: [1540/4518] 34% | Training loss: 0.6872788047635711
Epoch: 44 | Iteration number: [1550/4518] 34% | Training loss: 0.6872788980699355
Epoch: 44 | Iteration number: [1560/4518] 34% | Training loss: 0.6872876312106083
Epoch: 44 | Iteration number: [1570/4518] 34% | Training loss: 0.6872790084902648
Epoch: 44 | Iteration number: [1580/4518] 34% | Training loss: 0.6872757336384133
Epoch: 44 | Iteration number: [1590/4518] 35% | Training loss: 0.6872783425094197
Epoch: 44 | Iteration number: [1600/4518] 35% | Training loss: 0.6872801963984966
Epoch: 44 | Iteration number: [1610/4518] 35% | Training loss: 0.6872740548589955
Epoch: 44 | Iteration number: [1620/4518] 35% | Training loss: 0.6872690067247108
Epoch: 44 | Iteration number: [1630/4518] 36% | Training loss: 0.6872540737953654
Epoch: 44 | Iteration number: [1640/4518] 36% | Training loss: 0.6872531409307224
Epoch: 44 | Iteration number: [1650/4518] 36% | Training loss: 0.687237105622436
Epoch: 44 | Iteration number: [1660/4518] 36% | Training loss: 0.687234233122274
Epoch: 44 | Iteration number: [1670/4518] 36% | Training loss: 0.6872312853793184
Epoch: 44 | Iteration number: [1680/4518] 37% | Training loss: 0.68721995140825
Epoch: 44 | Iteration number: [1690/4518] 37% | Training loss: 0.6872191584321874
Epoch: 44 | Iteration number: [1700/4518] 37% | Training loss: 0.6872164632993586
Epoch: 44 | Iteration number: [1710/4518] 37% | Training loss: 0.6872177132737567
Epoch: 44 | Iteration number: [1720/4518] 38% | Training loss: 0.6872150305398675
Epoch: 44 | Iteration number: [1730/4518] 38% | Training loss: 0.6872089789092886
Epoch: 44 | Iteration number: [1740/4518] 38% | Training loss: 0.6872097679938393
Epoch: 44 | Iteration number: [1750/4518] 38% | Training loss: 0.6872082891804832
Epoch: 44 | Iteration number: [1760/4518] 38% | Training loss: 0.6872067162259059
Epoch: 44 | Iteration number: [1770/4518] 39% | Training loss: 0.6872003668782402
Epoch: 44 | Iteration number: [1780/4518] 39% | Training loss: 0.6871953452236197
Epoch: 44 | Iteration number: [1790/4518] 39% | Training loss: 0.6871946443392578
Epoch: 44 | Iteration number: [1800/4518] 39% | Training loss: 0.6871940001514223
Epoch: 44 | Iteration number: [1810/4518] 40% | Training loss: 0.6871872171183318
Epoch: 44 | Iteration number: [1820/4518] 40% | Training loss: 0.6871885603928304
Epoch: 44 | Iteration number: [1830/4518] 40% | Training loss: 0.6871906868747023
Epoch: 44 | Iteration number: [1840/4518] 40% | Training loss: 0.6871865083018075
Epoch: 44 | Iteration number: [1850/4518] 40% | Training loss: 0.687185309416539
Epoch: 44 | Iteration number: [1860/4518] 41% | Training loss: 0.6871812755702644
Epoch: 44 | Iteration number: [1870/4518] 41% | Training loss: 0.6871822436225605
Epoch: 44 | Iteration number: [1880/4518] 41% | Training loss: 0.6871775758076222
Epoch: 44 | Iteration number: [1890/4518] 41% | Training loss: 0.6871752197780306
Epoch: 44 | Iteration number: [1900/4518] 42% | Training loss: 0.6871681287100441
Epoch: 44 | Iteration number: [1910/4518] 42% | Training loss: 0.6871678791121039
Epoch: 44 | Iteration number: [1920/4518] 42% | Training loss: 0.687161984325697
Epoch: 44 | Iteration number: [1930/4518] 42% | Training loss: 0.687161297285495
Epoch: 44 | Iteration number: [1940/4518] 42% | Training loss: 0.6871560595699192
Epoch: 44 | Iteration number: [1950/4518] 43% | Training loss: 0.6871553764587793
Epoch: 44 | Iteration number: [1960/4518] 43% | Training loss: 0.687156038807363
Epoch: 44 | Iteration number: [1970/4518] 43% | Training loss: 0.6871595969357467
Epoch: 44 | Iteration number: [1980/4518] 43% | Training loss: 0.6871579110321372
Epoch: 44 | Iteration number: [1990/4518] 44% | Training loss: 0.6871481748681572
Epoch: 44 | Iteration number: [2000/4518] 44% | Training loss: 0.6871504731178284
Epoch: 44 | Iteration number: [2010/4518] 44% | Training loss: 0.6871506768969161
Epoch: 44 | Iteration number: [2020/4518] 44% | Training loss: 0.6871485021149758
Epoch: 44 | Iteration number: [2030/4518] 44% | Training loss: 0.6871447108355649
Epoch: 44 | Iteration number: [2040/4518] 45% | Training loss: 0.6871426604834258
Epoch: 44 | Iteration number: [2050/4518] 45% | Training loss: 0.687139246289323
Epoch: 44 | Iteration number: [2060/4518] 45% | Training loss: 0.687137871778127
Epoch: 44 | Iteration number: [2070/4518] 45% | Training loss: 0.6871454217871606
Epoch: 44 | Iteration number: [2080/4518] 46% | Training loss: 0.6871422904615219
Epoch: 44 | Iteration number: [2090/4518] 46% | Training loss: 0.687143758951762
Epoch: 44 | Iteration number: [2100/4518] 46% | Training loss: 0.687138496069681
Epoch: 44 | Iteration number: [2110/4518] 46% | Training loss: 0.6871324224494645
Epoch: 44 | Iteration number: [2120/4518] 46% | Training loss: 0.6871364689941676
Epoch: 44 | Iteration number: [2130/4518] 47% | Training loss: 0.6871413533676398
Epoch: 44 | Iteration number: [2140/4518] 47% | Training loss: 0.6871414193483156
Epoch: 44 | Iteration number: [2150/4518] 47% | Training loss: 0.6871384963323903
Epoch: 44 | Iteration number: [2160/4518] 47% | Training loss: 0.6871368524101046
Epoch: 44 | Iteration number: [2170/4518] 48% | Training loss: 0.687138384003793
Epoch: 44 | Iteration number: [2180/4518] 48% | Training loss: 0.6871414658946728
Epoch: 44 | Iteration number: [2190/4518] 48% | Training loss: 0.6871336879795544
Epoch: 44 | Iteration number: [2200/4518] 48% | Training loss: 0.6871360083330761
Epoch: 44 | Iteration number: [2210/4518] 48% | Training loss: 0.6871365999204541
Epoch: 44 | Iteration number: [2220/4518] 49% | Training loss: 0.6871351091174392
Epoch: 44 | Iteration number: [2230/4518] 49% | Training loss: 0.6871342067226701
Epoch: 44 | Iteration number: [2240/4518] 49% | Training loss: 0.6871318507141301
Epoch: 44 | Iteration number: [2250/4518] 49% | Training loss: 0.6871276259687211
Epoch: 44 | Iteration number: [2260/4518] 50% | Training loss: 0.6871197548324028
Epoch: 44 | Iteration number: [2270/4518] 50% | Training loss: 0.6871168376853287
Epoch: 44 | Iteration number: [2280/4518] 50% | Training loss: 0.6871168026275802
Epoch: 44 | Iteration number: [2290/4518] 50% | Training loss: 0.6871153484005075
Epoch: 44 | Iteration number: [2300/4518] 50% | Training loss: 0.6871211918799773
Epoch: 44 | Iteration number: [2310/4518] 51% | Training loss: 0.6871173190090047
Epoch: 44 | Iteration number: [2320/4518] 51% | Training loss: 0.6871211848125376
Epoch: 44 | Iteration number: [2330/4518] 51% | Training loss: 0.6871243963425763
Epoch: 44 | Iteration number: [2340/4518] 51% | Training loss: 0.6871208137936062
Epoch: 44 | Iteration number: [2350/4518] 52% | Training loss: 0.6871131030549394
Epoch: 44 | Iteration number: [2360/4518] 52% | Training loss: 0.6871083291152776
Epoch: 44 | Iteration number: [2370/4518] 52% | Training loss: 0.6871066417875169
Epoch: 44 | Iteration number: [2380/4518] 52% | Training loss: 0.6871088224048374
Epoch: 44 | Iteration number: [2390/4518] 52% | Training loss: 0.687107359864223
Epoch: 44 | Iteration number: [2400/4518] 53% | Training loss: 0.687106018041571
Epoch: 44 | Iteration number: [2410/4518] 53% | Training loss: 0.6871067830388476
Epoch: 44 | Iteration number: [2420/4518] 53% | Training loss: 0.6871002634941054
Epoch: 44 | Iteration number: [2430/4518] 53% | Training loss: 0.6870987072157761
Epoch: 44 | Iteration number: [2440/4518] 54% | Training loss: 0.6871011339738721
Epoch: 44 | Iteration number: [2450/4518] 54% | Training loss: 0.6871034908781246
Epoch: 44 | Iteration number: [2460/4518] 54% | Training loss: 0.6871037717999482
Epoch: 44 | Iteration number: [2470/4518] 54% | Training loss: 0.6871041332179235
Epoch: 44 | Iteration number: [2480/4518] 54% | Training loss: 0.6871046038404588
Epoch: 44 | Iteration number: [2490/4518] 55% | Training loss: 0.6870980426489589
Epoch: 44 | Iteration number: [2500/4518] 55% | Training loss: 0.6871044833660126
Epoch: 44 | Iteration number: [2510/4518] 55% | Training loss: 0.6871067383374826
Epoch: 44 | Iteration number: [2520/4518] 55% | Training loss: 0.6871009951073026
Epoch: 44 | Iteration number: [2530/4518] 55% | Training loss: 0.6870977671956827
Epoch: 44 | Iteration number: [2540/4518] 56% | Training loss: 0.6870969867847098
Epoch: 44 | Iteration number: [2550/4518] 56% | Training loss: 0.6870971606291977
Epoch: 44 | Iteration number: [2560/4518] 56% | Training loss: 0.6870934606296941
Epoch: 44 | Iteration number: [2570/4518] 56% | Training loss: 0.6870957089769237
Epoch: 44 | Iteration number: [2580/4518] 57% | Training loss: 0.6870979675026827
Epoch: 44 | Iteration number: [2590/4518] 57% | Training loss: 0.6870965136064066
Epoch: 44 | Iteration number: [2600/4518] 57% | Training loss: 0.6870934280753136
Epoch: 44 | Iteration number: [2610/4518] 57% | Training loss: 0.6870959060630579
Epoch: 44 | Iteration number: [2620/4518] 57% | Training loss: 0.6870960174853565
Epoch: 44 | Iteration number: [2630/4518] 58% | Training loss: 0.6870982370222476
Epoch: 44 | Iteration number: [2640/4518] 58% | Training loss: 0.6870933817191558
Epoch: 44 | Iteration number: [2650/4518] 58% | Training loss: 0.687095617055893
Epoch: 44 | Iteration number: [2660/4518] 58% | Training loss: 0.6870944595874701
Epoch: 44 | Iteration number: [2670/4518] 59% | Training loss: 0.6870934218279878
Epoch: 44 | Iteration number: [2680/4518] 59% | Training loss: 0.6870934006215921
Epoch: 44 | Iteration number: [2690/4518] 59% | Training loss: 0.6870868669123454
Epoch: 44 | Iteration number: [2700/4518] 59% | Training loss: 0.6870809744905543
Epoch: 44 | Iteration number: [2710/4518] 59% | Training loss: 0.6870801185769788
Epoch: 44 | Iteration number: [2720/4518] 60% | Training loss: 0.687078765100416
Epoch: 44 | Iteration number: [2730/4518] 60% | Training loss: 0.6870779053195493
Epoch: 44 | Iteration number: [2740/4518] 60% | Training loss: 0.6870768145488126
Epoch: 44 | Iteration number: [2750/4518] 60% | Training loss: 0.6870779349370436
Epoch: 44 | Iteration number: [2760/4518] 61% | Training loss: 0.687077210476433
Epoch: 44 | Iteration number: [2770/4518] 61% | Training loss: 0.6870739285050746
Epoch: 44 | Iteration number: [2780/4518] 61% | Training loss: 0.6870708375525989
Epoch: 44 | Iteration number: [2790/4518] 61% | Training loss: 0.6870674912006625
Epoch: 44 | Iteration number: [2800/4518] 61% | Training loss: 0.6870662692614964
Epoch: 44 | Iteration number: [2810/4518] 62% | Training loss: 0.6870608937697903
Epoch: 44 | Iteration number: [2820/4518] 62% | Training loss: 0.6870559053640839
Epoch: 44 | Iteration number: [2830/4518] 62% | Training loss: 0.6870547413615372
Epoch: 44 | Iteration number: [2840/4518] 62% | Training loss: 0.6870534550346119
Epoch: 44 | Iteration number: [2850/4518] 63% | Training loss: 0.6870522108412626
Epoch: 44 | Iteration number: [2860/4518] 63% | Training loss: 0.6870537365858371
Epoch: 44 | Iteration number: [2870/4518] 63% | Training loss: 0.6870524996456784
Epoch: 44 | Iteration number: [2880/4518] 63% | Training loss: 0.6870520688593388
Epoch: 44 | Iteration number: [2890/4518] 63% | Training loss: 0.687055410934567
Epoch: 44 | Iteration number: [2900/4518] 64% | Training loss: 0.6870534187349779
Epoch: 44 | Iteration number: [2910/4518] 64% | Training loss: 0.6870511997196682
Epoch: 44 | Iteration number: [2920/4518] 64% | Training loss: 0.6870527724901291
Epoch: 44 | Iteration number: [2930/4518] 64% | Training loss: 0.6870476681828092
Epoch: 44 | Iteration number: [2940/4518] 65% | Training loss: 0.6870483099806065
Epoch: 44 | Iteration number: [2950/4518] 65% | Training loss: 0.6870459838438843
Epoch: 44 | Iteration number: [2960/4518] 65% | Training loss: 0.6870413797127234
Epoch: 44 | Iteration number: [2970/4518] 65% | Training loss: 0.6870337585808853
Epoch: 44 | Iteration number: [2980/4518] 65% | Training loss: 0.6870301138434635
Epoch: 44 | Iteration number: [2990/4518] 66% | Training loss: 0.687031968182146
Epoch: 44 | Iteration number: [3000/4518] 66% | Training loss: 0.6870344434579213
Epoch: 44 | Iteration number: [3010/4518] 66% | Training loss: 0.6870333167801663
Epoch: 44 | Iteration number: [3020/4518] 66% | Training loss: 0.6870302304132095
Epoch: 44 | Iteration number: [3030/4518] 67% | Training loss: 0.6870294506990476
Epoch: 44 | Iteration number: [3040/4518] 67% | Training loss: 0.6870275717228651
Epoch: 44 | Iteration number: [3050/4518] 67% | Training loss: 0.68702488283642
Epoch: 44 | Iteration number: [3060/4518] 67% | Training loss: 0.687024865762081
Epoch: 44 | Iteration number: [3070/4518] 67% | Training loss: 0.6870249425937764
Epoch: 44 | Iteration number: [3080/4518] 68% | Training loss: 0.6870264508700991
Epoch: 44 | Iteration number: [3090/4518] 68% | Training loss: 0.6870197280710955
Epoch: 44 | Iteration number: [3100/4518] 68% | Training loss: 0.6870198319804284
Epoch: 44 | Iteration number: [3110/4518] 68% | Training loss: 0.6870198814431954
Epoch: 44 | Iteration number: [3120/4518] 69% | Training loss: 0.6870214032057004
Epoch: 44 | Iteration number: [3130/4518] 69% | Training loss: 0.6870209076153204
Epoch: 44 | Iteration number: [3140/4518] 69% | Training loss: 0.6870206273095623
Epoch: 44 | Iteration number: [3150/4518] 69% | Training loss: 0.6870220740825411
Epoch: 44 | Iteration number: [3160/4518] 69% | Training loss: 0.6870208475408675
Epoch: 44 | Iteration number: [3170/4518] 70% | Training loss: 0.6870185233629088
Epoch: 44 | Iteration number: [3180/4518] 70% | Training loss: 0.6870188177569108
Epoch: 44 | Iteration number: [3190/4518] 70% | Training loss: 0.6870136485204428
Epoch: 44 | Iteration number: [3200/4518] 70% | Training loss: 0.6870150099880994
Epoch: 44 | Iteration number: [3210/4518] 71% | Training loss: 0.6870136076416182
Epoch: 44 | Iteration number: [3220/4518] 71% | Training loss: 0.687017294894094
Epoch: 44 | Iteration number: [3230/4518] 71% | Training loss: 0.6870153668495155
Epoch: 44 | Iteration number: [3240/4518] 71% | Training loss: 0.6870197637397566
Epoch: 44 | Iteration number: [3250/4518] 71% | Training loss: 0.6870186149890606
Epoch: 44 | Iteration number: [3260/4518] 72% | Training loss: 0.6870212325837715
Epoch: 44 | Iteration number: [3270/4518] 72% | Training loss: 0.6870241562525431
Epoch: 44 | Iteration number: [3280/4518] 72% | Training loss: 0.6870239189848667
Epoch: 44 | Iteration number: [3290/4518] 72% | Training loss: 0.6870205482632193
Epoch: 44 | Iteration number: [3300/4518] 73% | Training loss: 0.6870190406568123
Epoch: 44 | Iteration number: [3310/4518] 73% | Training loss: 0.6870172770722035
Epoch: 44 | Iteration number: [3320/4518] 73% | Training loss: 0.6870150415653206
Epoch: 44 | Iteration number: [3330/4518] 73% | Training loss: 0.6870116641571572
Epoch: 44 | Iteration number: [3340/4518] 73% | Training loss: 0.6870116981917512
Epoch: 44 | Iteration number: [3350/4518] 74% | Training loss: 0.6870118756614514
Epoch: 44 | Iteration number: [3360/4518] 74% | Training loss: 0.6870072227503572
Epoch: 44 | Iteration number: [3370/4518] 74% | Training loss: 0.6870072145490335
Epoch: 44 | Iteration number: [3380/4518] 74% | Training loss: 0.6870029857525459
Epoch: 44 | Iteration number: [3390/4518] 75% | Training loss: 0.687002873156978
Epoch: 44 | Iteration number: [3400/4518] 75% | Training loss: 0.6870023865033599
Epoch: 44 | Iteration number: [3410/4518] 75% | Training loss: 0.6870014331557533
Epoch: 44 | Iteration number: [3420/4518] 75% | Training loss: 0.6869997103486145
Epoch: 44 | Iteration number: [3430/4518] 75% | Training loss: 0.6869980062930994
Epoch: 44 | Iteration number: [3440/4518] 76% | Training loss: 0.6869994414233884
Epoch: 44 | Iteration number: [3450/4518] 76% | Training loss: 0.6869995609228162
Epoch: 44 | Iteration number: [3460/4518] 76% | Training loss: 0.6870000330526704
Epoch: 44 | Iteration number: [3470/4518] 76% | Training loss: 0.6869995695026189
Epoch: 44 | Iteration number: [3480/4518] 77% | Training loss: 0.6870003135896278
Epoch: 44 | Iteration number: [3490/4518] 77% | Training loss: 0.6869990393903672
Epoch: 44 | Iteration number: [3500/4518] 77% | Training loss: 0.6870017387696675
Epoch: 44 | Iteration number: [3510/4518] 77% | Training loss: 0.6869985086455984
Epoch: 44 | Iteration number: [3520/4518] 77% | Training loss: 0.6869971101426265
Epoch: 44 | Iteration number: [3530/4518] 78% | Training loss: 0.6869977689498544
Epoch: 44 | Iteration number: [3540/4518] 78% | Training loss: 0.6870018252376783
Epoch: 44 | Iteration number: [3550/4518] 78% | Training loss: 0.6870034758809587
Epoch: 44 | Iteration number: [3560/4518] 78% | Training loss: 0.6869993704423476
Epoch: 44 | Iteration number: [3570/4518] 79% | Training loss: 0.6870015342362454
Epoch: 44 | Iteration number: [3580/4518] 79% | Training loss: 0.6870042608769912
Epoch: 44 | Iteration number: [3590/4518] 79% | Training loss: 0.6870055650270085
Epoch: 44 | Iteration number: [3600/4518] 79% | Training loss: 0.6870023107694255
Epoch: 44 | Iteration number: [3610/4518] 79% | Training loss: 0.687004446438475
Epoch: 44 | Iteration number: [3620/4518] 80% | Training loss: 0.6870047892160838
Epoch: 44 | Iteration number: [3630/4518] 80% | Training loss: 0.6870040220005782
Epoch: 44 | Iteration number: [3640/4518] 80% | Training loss: 0.6869984849468692
Epoch: 44 | Iteration number: [3650/4518] 80% | Training loss: 0.6869957328822515
Epoch: 44 | Iteration number: [3660/4518] 81% | Training loss: 0.6869976208509643
Epoch: 44 | Iteration number: [3670/4518] 81% | Training loss: 0.6869965911886023
Epoch: 44 | Iteration number: [3680/4518] 81% | Training loss: 0.6869944752396449
Epoch: 44 | Iteration number: [3690/4518] 81% | Training loss: 0.6869935114855366
Epoch: 44 | Iteration number: [3700/4518] 81% | Training loss: 0.6869963979237789
Epoch: 44 | Iteration number: [3710/4518] 82% | Training loss: 0.6869953213354969
Epoch: 44 | Iteration number: [3720/4518] 82% | Training loss: 0.6869970708925237
Epoch: 44 | Iteration number: [3730/4518] 82% | Training loss: 0.6869979390509966
Epoch: 44 | Iteration number: [3740/4518] 82% | Training loss: 0.6869990264349443
Epoch: 44 | Iteration number: [3750/4518] 83% | Training loss: 0.6869993604024252
Epoch: 44 | Iteration number: [3760/4518] 83% | Training loss: 0.686995663192678
Epoch: 44 | Iteration number: [3770/4518] 83% | Training loss: 0.6869928531842776
Epoch: 44 | Iteration number: [3780/4518] 83% | Training loss: 0.6869933312689817
Epoch: 44 | Iteration number: [3790/4518] 83% | Training loss: 0.6869915986124003
Epoch: 44 | Iteration number: [3800/4518] 84% | Training loss: 0.6869907975667401
Epoch: 44 | Iteration number: [3810/4518] 84% | Training loss: 0.686991646424366
Epoch: 44 | Iteration number: [3820/4518] 84% | Training loss: 0.6869915465565877
Epoch: 44 | Iteration number: [3830/4518] 84% | Training loss: 0.6869932704899392
Epoch: 44 | Iteration number: [3840/4518] 84% | Training loss: 0.6869917541897546
Epoch: 44 | Iteration number: [3850/4518] 85% | Training loss: 0.6869907729501848
Epoch: 44 | Iteration number: [3860/4518] 85% | Training loss: 0.6869899996358496
Epoch: 44 | Iteration number: [3870/4518] 85% | Training loss: 0.686990681159712
Epoch: 44 | Iteration number: [3880/4518] 85% | Training loss: 0.6869887189920416
Epoch: 44 | Iteration number: [3890/4518] 86% | Training loss: 0.6869918664807219
Epoch: 44 | Iteration number: [3900/4518] 86% | Training loss: 0.6869907458928916
Epoch: 44 | Iteration number: [3910/4518] 86% | Training loss: 0.6869903192648192
Epoch: 44 | Iteration number: [3920/4518] 86% | Training loss: 0.6869921113763536
Epoch: 44 | Iteration number: [3930/4518] 86% | Training loss: 0.686994957499225
Epoch: 44 | Iteration number: [3940/4518] 87% | Training loss: 0.6869980605271867
Epoch: 44 | Iteration number: [3950/4518] 87% | Training loss: 0.6869987781892849
Epoch: 44 | Iteration number: [3960/4518] 87% | Training loss: 0.6869973068435987
Epoch: 44 | Iteration number: [3970/4518] 87% | Training loss: 0.6869960837310147
Epoch: 44 | Iteration number: [3980/4518] 88% | Training loss: 0.6869937789949341
Epoch: 44 | Iteration number: [3990/4518] 88% | Training loss: 0.686992739645162
Epoch: 44 | Iteration number: [4000/4518] 88% | Training loss: 0.6869913352578878
Epoch: 44 | Iteration number: [4010/4518] 88% | Training loss: 0.6869901677616814
Epoch: 44 | Iteration number: [4020/4518] 88% | Training loss: 0.6869939186828053
Epoch: 44 | Iteration number: [4030/4518] 89% | Training loss: 0.6869939165286923
Epoch: 44 | Iteration number: [4040/4518] 89% | Training loss: 0.686992678577357
Epoch: 44 | Iteration number: [4050/4518] 89% | Training loss: 0.6869919415609336
Epoch: 44 | Iteration number: [4060/4518] 89% | Training loss: 0.6869895238888087
Epoch: 44 | Iteration number: [4070/4518] 90% | Training loss: 0.6869911498753972
Epoch: 44 | Iteration number: [4080/4518] 90% | Training loss: 0.6869906852058336
Epoch: 44 | Iteration number: [4090/4518] 90% | Training loss: 0.6869884511223632
Epoch: 44 | Iteration number: [4100/4518] 90% | Training loss: 0.6869894390716785
Epoch: 44 | Iteration number: [4110/4518] 90% | Training loss: 0.6869870193973365
Epoch: 44 | Iteration number: [4120/4518] 91% | Training loss: 0.6869827452359848
Epoch: 44 | Iteration number: [4130/4518] 91% | Training loss: 0.6869826342234022
Epoch: 44 | Iteration number: [4140/4518] 91% | Training loss: 0.6869847217619707
Epoch: 44 | Iteration number: [4150/4518] 91% | Training loss: 0.6869858339321182
Epoch: 44 | Iteration number: [4160/4518] 92% | Training loss: 0.6869841569891343
Epoch: 44 | Iteration number: [4170/4518] 92% | Training loss: 0.6869828226183244
Epoch: 44 | Iteration number: [4180/4518] 92% | Training loss: 0.6869809659474204
Epoch: 44 | Iteration number: [4190/4518] 92% | Training loss: 0.6869799139249296
Epoch: 44 | Iteration number: [4200/4518] 92% | Training loss: 0.6869770565629005
Epoch: 44 | Iteration number: [4210/4518] 93% | Training loss: 0.6869765596265182
Epoch: 44 | Iteration number: [4220/4518] 93% | Training loss: 0.6869783697393833
Epoch: 44 | Iteration number: [4230/4518] 93% | Training loss: 0.6869788346561134
Epoch: 44 | Iteration number: [4240/4518] 93% | Training loss: 0.686978068765042
Epoch: 44 | Iteration number: [4250/4518] 94% | Training loss: 0.6869767229276544
Epoch: 44 | Iteration number: [4260/4518] 94% | Training loss: 0.6869782676159496
Epoch: 44 | Iteration number: [4270/4518] 94% | Training loss: 0.686978703304532
Epoch: 44 | Iteration number: [4280/4518] 94% | Training loss: 0.6869754357872723
Epoch: 44 | Iteration number: [4290/4518] 94% | Training loss: 0.6869766799858956
Epoch: 44 | Iteration number: [4300/4518] 95% | Training loss: 0.6869807938642281
Epoch: 44 | Iteration number: [4310/4518] 95% | Training loss: 0.6869782797006886
Epoch: 44 | Iteration number: [4320/4518] 95% | Training loss: 0.6869800732505542
Epoch: 44 | Iteration number: [4330/4518] 95% | Training loss: 0.6869802272072014
Epoch: 44 | Iteration number: [4340/4518] 96% | Training loss: 0.6869795667685671
Epoch: 44 | Iteration number: [4350/4518] 96% | Training loss: 0.686982009150516
Epoch: 44 | Iteration number: [4360/4518] 96% | Training loss: 0.6869823510083584
Epoch: 44 | Iteration number: [4370/4518] 96% | Training loss: 0.6869821408111388
Epoch: 44 | Iteration number: [4380/4518] 96% | Training loss: 0.6869826695418249
Epoch: 44 | Iteration number: [4390/4518] 97% | Training loss: 0.6869810631850858
Epoch: 44 | Iteration number: [4400/4518] 97% | Training loss: 0.6869811030680483
Epoch: 44 | Iteration number: [4410/4518] 97% | Training loss: 0.6869816080242598
Epoch: 44 | Iteration number: [4420/4518] 97% | Training loss: 0.6869794727720286
Epoch: 44 | Iteration number: [4430/4518] 98% | Training loss: 0.6869820673767115
Epoch: 44 | Iteration number: [4440/4518] 98% | Training loss: 0.6869824997073896
Epoch: 44 | Iteration number: [4450/4518] 98% | Training loss: 0.6869787109299992
Epoch: 44 | Iteration number: [4460/4518] 98% | Training loss: 0.6869790967403506
Epoch: 44 | Iteration number: [4470/4518] 98% | Training loss: 0.686980868665964
Epoch: 44 | Iteration number: [4480/4518] 99% | Training loss: 0.6869783503402557
Epoch: 44 | Iteration number: [4490/4518] 99% | Training loss: 0.6869785062321576
Epoch: 44 | Iteration number: [4500/4518] 99% | Training loss: 0.6869804408550263
Epoch: 44 | Iteration number: [4510/4518] 99% | Training loss: 0.6869785734925196

 End of epoch: 44 | Train Loss: 0.6868261240815209 | Training Time: 642 

 End of epoch: 44 | Eval Loss: 0.6901088770554991 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/4518] 0% | Training loss: 0.7552417993545533
Epoch: 45 | Iteration number: [20/4518] 0% | Training loss: 0.7218274116516114
Epoch: 45 | Iteration number: [30/4518] 0% | Training loss: 0.7105506757895151
Epoch: 45 | Iteration number: [40/4518] 0% | Training loss: 0.7044675275683403
Epoch: 45 | Iteration number: [50/4518] 1% | Training loss: 0.7006233906745911
Epoch: 45 | Iteration number: [60/4518] 1% | Training loss: 0.6983036190271378
Epoch: 45 | Iteration number: [70/4518] 1% | Training loss: 0.6967014951365335
Epoch: 45 | Iteration number: [80/4518] 1% | Training loss: 0.6953772068023681
Epoch: 45 | Iteration number: [90/4518] 1% | Training loss: 0.6944932891262903
Epoch: 45 | Iteration number: [100/4518] 2% | Training loss: 0.693778218626976
Epoch: 45 | Iteration number: [110/4518] 2% | Training loss: 0.693178927898407
Epoch: 45 | Iteration number: [120/4518] 2% | Training loss: 0.6925541574756304
Epoch: 45 | Iteration number: [130/4518] 2% | Training loss: 0.6921429106822381
Epoch: 45 | Iteration number: [140/4518] 3% | Training loss: 0.6917269400187901
Epoch: 45 | Iteration number: [150/4518] 3% | Training loss: 0.6914082137743632
Epoch: 45 | Iteration number: [160/4518] 3% | Training loss: 0.691074013337493
Epoch: 45 | Iteration number: [170/4518] 3% | Training loss: 0.6907966052784639
Epoch: 45 | Iteration number: [180/4518] 3% | Training loss: 0.6905958516730203
Epoch: 45 | Iteration number: [190/4518] 4% | Training loss: 0.6903816634102872
Epoch: 45 | Iteration number: [200/4518] 4% | Training loss: 0.6902279645204544
Epoch: 45 | Iteration number: [210/4518] 4% | Training loss: 0.6900524499870482
Epoch: 45 | Iteration number: [220/4518] 4% | Training loss: 0.6899273937398737
Epoch: 45 | Iteration number: [230/4518] 5% | Training loss: 0.6898866676765939
Epoch: 45 | Iteration number: [240/4518] 5% | Training loss: 0.6897899739444255
Epoch: 45 | Iteration number: [250/4518] 5% | Training loss: 0.6896327216625213
Epoch: 45 | Iteration number: [260/4518] 5% | Training loss: 0.6895045028283046
Epoch: 45 | Iteration number: [270/4518] 5% | Training loss: 0.6894117997752296
Epoch: 45 | Iteration number: [280/4518] 6% | Training loss: 0.6893062346747943
Epoch: 45 | Iteration number: [290/4518] 6% | Training loss: 0.689253830087596
Epoch: 45 | Iteration number: [300/4518] 6% | Training loss: 0.6892034357786179
Epoch: 45 | Iteration number: [310/4518] 6% | Training loss: 0.6891006854272658
Epoch: 45 | Iteration number: [320/4518] 7% | Training loss: 0.6889996998012066
Epoch: 45 | Iteration number: [330/4518] 7% | Training loss: 0.6889164613954949
Epoch: 45 | Iteration number: [340/4518] 7% | Training loss: 0.6888339778956245
Epoch: 45 | Iteration number: [350/4518] 7% | Training loss: 0.6887313352312361
Epoch: 45 | Iteration number: [360/4518] 7% | Training loss: 0.688667911125554
Epoch: 45 | Iteration number: [370/4518] 8% | Training loss: 0.6886374425243686
Epoch: 45 | Iteration number: [380/4518] 8% | Training loss: 0.6885837362000816
Epoch: 45 | Iteration number: [390/4518] 8% | Training loss: 0.6885608339921022
Epoch: 45 | Iteration number: [400/4518] 8% | Training loss: 0.6885570034384727
Epoch: 45 | Iteration number: [410/4518] 9% | Training loss: 0.688481730949588
Epoch: 45 | Iteration number: [420/4518] 9% | Training loss: 0.6884247180961427
Epoch: 45 | Iteration number: [430/4518] 9% | Training loss: 0.688384070923162
Epoch: 45 | Iteration number: [440/4518] 9% | Training loss: 0.6883731854232875
Epoch: 45 | Iteration number: [450/4518] 9% | Training loss: 0.6883255885707007
Epoch: 45 | Iteration number: [460/4518] 10% | Training loss: 0.6882928243149882
Epoch: 45 | Iteration number: [470/4518] 10% | Training loss: 0.6882487025666744
Epoch: 45 | Iteration number: [480/4518] 10% | Training loss: 0.6882652595639229
Epoch: 45 | Iteration number: [490/4518] 10% | Training loss: 0.6882445738023641
Epoch: 45 | Iteration number: [500/4518] 11% | Training loss: 0.6881909862756729
Epoch: 45 | Iteration number: [510/4518] 11% | Training loss: 0.6881663446332894
Epoch: 45 | Iteration number: [520/4518] 11% | Training loss: 0.6881318147365864
Epoch: 45 | Iteration number: [530/4518] 11% | Training loss: 0.688110976061731
Epoch: 45 | Iteration number: [540/4518] 11% | Training loss: 0.6880846395536705
Epoch: 45 | Iteration number: [550/4518] 12% | Training loss: 0.6880443641272458
Epoch: 45 | Iteration number: [560/4518] 12% | Training loss: 0.6880100712180137
Epoch: 45 | Iteration number: [570/4518] 12% | Training loss: 0.6879987853660918
Epoch: 45 | Iteration number: [580/4518] 12% | Training loss: 0.6879934466090696
Epoch: 45 | Iteration number: [590/4518] 13% | Training loss: 0.6879799457929903
Epoch: 45 | Iteration number: [600/4518] 13% | Training loss: 0.6879588482777278
Epoch: 45 | Iteration number: [610/4518] 13% | Training loss: 0.6879338119850784
Epoch: 45 | Iteration number: [620/4518] 13% | Training loss: 0.687906295349521
Epoch: 45 | Iteration number: [630/4518] 13% | Training loss: 0.6878917092368716
Epoch: 45 | Iteration number: [640/4518] 14% | Training loss: 0.6878822639584541
Epoch: 45 | Iteration number: [650/4518] 14% | Training loss: 0.6878734780274904
Epoch: 45 | Iteration number: [660/4518] 14% | Training loss: 0.6878652237581484
Epoch: 45 | Iteration number: [670/4518] 14% | Training loss: 0.687858735269575
Epoch: 45 | Iteration number: [680/4518] 15% | Training loss: 0.6878420493182014
Epoch: 45 | Iteration number: [690/4518] 15% | Training loss: 0.6878320014995077
Epoch: 45 | Iteration number: [700/4518] 15% | Training loss: 0.6878226034981864
Epoch: 45 | Iteration number: [710/4518] 15% | Training loss: 0.6878233677904371
Epoch: 45 | Iteration number: [720/4518] 15% | Training loss: 0.6878159918718868
Epoch: 45 | Iteration number: [730/4518] 16% | Training loss: 0.6878019534561732
Epoch: 45 | Iteration number: [740/4518] 16% | Training loss: 0.6877890228419691
Epoch: 45 | Iteration number: [750/4518] 16% | Training loss: 0.6877736516793569
Epoch: 45 | Iteration number: [760/4518] 16% | Training loss: 0.6877409269935206
Epoch: 45 | Iteration number: [770/4518] 17% | Training loss: 0.6877308313722734
Epoch: 45 | Iteration number: [780/4518] 17% | Training loss: 0.687702927681116
Epoch: 45 | Iteration number: [790/4518] 17% | Training loss: 0.6876962492737589
Epoch: 45 | Iteration number: [800/4518] 17% | Training loss: 0.6876927857846021
Epoch: 45 | Iteration number: [810/4518] 17% | Training loss: 0.6876767143055245
Epoch: 45 | Iteration number: [820/4518] 18% | Training loss: 0.6876709352179271
Epoch: 45 | Iteration number: [830/4518] 18% | Training loss: 0.6876531523394297
Epoch: 45 | Iteration number: [840/4518] 18% | Training loss: 0.6876325240447407
Epoch: 45 | Iteration number: [850/4518] 18% | Training loss: 0.687606270944371
Epoch: 45 | Iteration number: [860/4518] 19% | Training loss: 0.687592841511549
Epoch: 45 | Iteration number: [870/4518] 19% | Training loss: 0.6875909841608727
Epoch: 45 | Iteration number: [880/4518] 19% | Training loss: 0.6875768087126992
Epoch: 45 | Iteration number: [890/4518] 19% | Training loss: 0.6875541980346936
Epoch: 45 | Iteration number: [900/4518] 19% | Training loss: 0.6875505731503169
Epoch: 45 | Iteration number: [910/4518] 20% | Training loss: 0.687530453650506
Epoch: 45 | Iteration number: [920/4518] 20% | Training loss: 0.6875193522028301
Epoch: 45 | Iteration number: [930/4518] 20% | Training loss: 0.6875068934373958
Epoch: 45 | Iteration number: [940/4518] 20% | Training loss: 0.6875067494651105
Epoch: 45 | Iteration number: [950/4518] 21% | Training loss: 0.6875093244251452
Epoch: 45 | Iteration number: [960/4518] 21% | Training loss: 0.6875058996801575
Epoch: 45 | Iteration number: [970/4518] 21% | Training loss: 0.6875036538876209
Epoch: 45 | Iteration number: [980/4518] 21% | Training loss: 0.6874926130382382
Epoch: 45 | Iteration number: [990/4518] 21% | Training loss: 0.6874846195331727
Epoch: 45 | Iteration number: [1000/4518] 22% | Training loss: 0.6874810223579406
Epoch: 45 | Iteration number: [1010/4518] 22% | Training loss: 0.6874646086503964
Epoch: 45 | Iteration number: [1020/4518] 22% | Training loss: 0.6874606230095321
Epoch: 45 | Iteration number: [1030/4518] 22% | Training loss: 0.6874612525250148
Epoch: 45 | Iteration number: [1040/4518] 23% | Training loss: 0.6874611305502745
Epoch: 45 | Iteration number: [1050/4518] 23% | Training loss: 0.6874565126214709
Epoch: 45 | Iteration number: [1060/4518] 23% | Training loss: 0.6874477000731343
Epoch: 45 | Iteration number: [1070/4518] 23% | Training loss: 0.6874511387860663
Epoch: 45 | Iteration number: [1080/4518] 23% | Training loss: 0.6874393619321011
Epoch: 45 | Iteration number: [1090/4518] 24% | Training loss: 0.6874528355007872
Epoch: 45 | Iteration number: [1100/4518] 24% | Training loss: 0.6874533133073286
Epoch: 45 | Iteration number: [1110/4518] 24% | Training loss: 0.6874397669826542
Epoch: 45 | Iteration number: [1120/4518] 24% | Training loss: 0.6874335020248379
Epoch: 45 | Iteration number: [1130/4518] 25% | Training loss: 0.6874334136996649
Epoch: 45 | Iteration number: [1140/4518] 25% | Training loss: 0.6874265439677657
Epoch: 45 | Iteration number: [1150/4518] 25% | Training loss: 0.687413526047831
Epoch: 45 | Iteration number: [1160/4518] 25% | Training loss: 0.6874078042548278
Epoch: 45 | Iteration number: [1170/4518] 25% | Training loss: 0.6874003023673326
Epoch: 45 | Iteration number: [1180/4518] 26% | Training loss: 0.6874002216731088
Epoch: 45 | Iteration number: [1190/4518] 26% | Training loss: 0.6873877872939871
Epoch: 45 | Iteration number: [1200/4518] 26% | Training loss: 0.6873702701429526
Epoch: 45 | Iteration number: [1210/4518] 26% | Training loss: 0.6873712042146478
Epoch: 45 | Iteration number: [1220/4518] 27% | Training loss: 0.6873643993842797
Epoch: 45 | Iteration number: [1230/4518] 27% | Training loss: 0.687368776400884
Epoch: 45 | Iteration number: [1240/4518] 27% | Training loss: 0.6873632365176755
Epoch: 45 | Iteration number: [1250/4518] 27% | Training loss: 0.6873518095970154
Epoch: 45 | Iteration number: [1260/4518] 27% | Training loss: 0.6873578950999275
Epoch: 45 | Iteration number: [1270/4518] 28% | Training loss: 0.6873540696665996
Epoch: 45 | Iteration number: [1280/4518] 28% | Training loss: 0.6873498774133623
Epoch: 45 | Iteration number: [1290/4518] 28% | Training loss: 0.687353105877721
Epoch: 45 | Iteration number: [1300/4518] 28% | Training loss: 0.6873359068540427
Epoch: 45 | Iteration number: [1310/4518] 28% | Training loss: 0.6873329002438611
Epoch: 45 | Iteration number: [1320/4518] 29% | Training loss: 0.6873210670821595
Epoch: 45 | Iteration number: [1330/4518] 29% | Training loss: 0.6873246438521191
Epoch: 45 | Iteration number: [1340/4518] 29% | Training loss: 0.6873333110293346
Epoch: 45 | Iteration number: [1350/4518] 29% | Training loss: 0.687330787844128
Epoch: 45 | Iteration number: [1360/4518] 30% | Training loss: 0.68733546019477
Epoch: 45 | Iteration number: [1370/4518] 30% | Training loss: 0.6873439033101075
Epoch: 45 | Iteration number: [1380/4518] 30% | Training loss: 0.6873428179302077
Epoch: 45 | Iteration number: [1390/4518] 30% | Training loss: 0.6873435560319063
Epoch: 45 | Iteration number: [1400/4518] 30% | Training loss: 0.6873396277001926
Epoch: 45 | Iteration number: [1410/4518] 31% | Training loss: 0.6873332212580011
Epoch: 45 | Iteration number: [1420/4518] 31% | Training loss: 0.6873212125939383
Epoch: 45 | Iteration number: [1430/4518] 31% | Training loss: 0.6873165778346829
Epoch: 45 | Iteration number: [1440/4518] 31% | Training loss: 0.6873055354174641
Epoch: 45 | Iteration number: [1450/4518] 32% | Training loss: 0.6872983410440642
Epoch: 45 | Iteration number: [1460/4518] 32% | Training loss: 0.6872985167454366
Epoch: 45 | Iteration number: [1470/4518] 32% | Training loss: 0.6872917395465228
Epoch: 45 | Iteration number: [1480/4518] 32% | Training loss: 0.6872892718057375
Epoch: 45 | Iteration number: [1490/4518] 32% | Training loss: 0.6872830986176561
Epoch: 45 | Iteration number: [1500/4518] 33% | Training loss: 0.6872791750828425
Epoch: 45 | Iteration number: [1510/4518] 33% | Training loss: 0.6872799540592345
Epoch: 45 | Iteration number: [1520/4518] 33% | Training loss: 0.687273092724775
Epoch: 45 | Iteration number: [1530/4518] 33% | Training loss: 0.6872657410849153
Epoch: 45 | Iteration number: [1540/4518] 34% | Training loss: 0.6872653090334558
Epoch: 45 | Iteration number: [1550/4518] 34% | Training loss: 0.6872638829677336
Epoch: 45 | Iteration number: [1560/4518] 34% | Training loss: 0.6872650235509261
Epoch: 45 | Iteration number: [1570/4518] 34% | Training loss: 0.6872667119001886
Epoch: 45 | Iteration number: [1580/4518] 34% | Training loss: 0.6872714194693142
Epoch: 45 | Iteration number: [1590/4518] 35% | Training loss: 0.6872630153811953
Epoch: 45 | Iteration number: [1600/4518] 35% | Training loss: 0.6872565029188991
Epoch: 45 | Iteration number: [1610/4518] 35% | Training loss: 0.6872633330570245
Epoch: 45 | Iteration number: [1620/4518] 35% | Training loss: 0.6872543646229639
Epoch: 45 | Iteration number: [1630/4518] 36% | Training loss: 0.6872553298078432
Epoch: 45 | Iteration number: [1640/4518] 36% | Training loss: 0.6872542162493962
Epoch: 45 | Iteration number: [1650/4518] 36% | Training loss: 0.6872567693392436
Epoch: 45 | Iteration number: [1660/4518] 36% | Training loss: 0.6872518583593599
Epoch: 45 | Iteration number: [1670/4518] 36% | Training loss: 0.6872576562230458
Epoch: 45 | Iteration number: [1680/4518] 37% | Training loss: 0.6872567847725891
Epoch: 45 | Iteration number: [1690/4518] 37% | Training loss: 0.6872538249873551
Epoch: 45 | Iteration number: [1700/4518] 37% | Training loss: 0.6872531754129073
Epoch: 45 | Iteration number: [1710/4518] 37% | Training loss: 0.687249110212103
Epoch: 45 | Iteration number: [1720/4518] 38% | Training loss: 0.6872484433096508
Epoch: 45 | Iteration number: [1730/4518] 38% | Training loss: 0.6872386765962392
Epoch: 45 | Iteration number: [1740/4518] 38% | Training loss: 0.6872410760871295
Epoch: 45 | Iteration number: [1750/4518] 38% | Training loss: 0.687235844714301
Epoch: 45 | Iteration number: [1760/4518] 38% | Training loss: 0.6872366149655798
Epoch: 45 | Iteration number: [1770/4518] 39% | Training loss: 0.6872403854704172
Epoch: 45 | Iteration number: [1780/4518] 39% | Training loss: 0.6872387048233761
Epoch: 45 | Iteration number: [1790/4518] 39% | Training loss: 0.6872313051250394
Epoch: 45 | Iteration number: [1800/4518] 39% | Training loss: 0.6872269457909796
Epoch: 45 | Iteration number: [1810/4518] 40% | Training loss: 0.6872283353331339
Epoch: 45 | Iteration number: [1820/4518] 40% | Training loss: 0.6872256108692714
Epoch: 45 | Iteration number: [1830/4518] 40% | Training loss: 0.6872159399621474
Epoch: 45 | Iteration number: [1840/4518] 40% | Training loss: 0.6872099814855535
Epoch: 45 | Iteration number: [1850/4518] 40% | Training loss: 0.687209536835954
Epoch: 45 | Iteration number: [1860/4518] 41% | Training loss: 0.6872096661598451
Epoch: 45 | Iteration number: [1870/4518] 41% | Training loss: 0.6872091261142078
Epoch: 45 | Iteration number: [1880/4518] 41% | Training loss: 0.6872042676235767
Epoch: 45 | Iteration number: [1890/4518] 41% | Training loss: 0.6871989684760886
Epoch: 45 | Iteration number: [1900/4518] 42% | Training loss: 0.6872021822239224
Epoch: 45 | Iteration number: [1910/4518] 42% | Training loss: 0.6872019332428877
Epoch: 45 | Iteration number: [1920/4518] 42% | Training loss: 0.6871955377049744
Epoch: 45 | Iteration number: [1930/4518] 42% | Training loss: 0.6871930697112504
Epoch: 45 | Iteration number: [1940/4518] 42% | Training loss: 0.6871911869221127
Epoch: 45 | Iteration number: [1950/4518] 43% | Training loss: 0.6871952545031523
Epoch: 45 | Iteration number: [1960/4518] 43% | Training loss: 0.6871923214318801
Epoch: 45 | Iteration number: [1970/4518] 43% | Training loss: 0.6871873117037836
Epoch: 45 | Iteration number: [1980/4518] 43% | Training loss: 0.6871848607304121
Epoch: 45 | Iteration number: [1990/4518] 44% | Training loss: 0.6871793125742045
Epoch: 45 | Iteration number: [2000/4518] 44% | Training loss: 0.6871814516186714
Epoch: 45 | Iteration number: [2010/4518] 44% | Training loss: 0.6871805328634841
Epoch: 45 | Iteration number: [2020/4518] 44% | Training loss: 0.687178818984787
Epoch: 45 | Iteration number: [2030/4518] 44% | Training loss: 0.6871767312435094
Epoch: 45 | Iteration number: [2040/4518] 45% | Training loss: 0.6871729380944196
Epoch: 45 | Iteration number: [2050/4518] 45% | Training loss: 0.687172761166968
Epoch: 45 | Iteration number: [2060/4518] 45% | Training loss: 0.6871695695571529
Epoch: 45 | Iteration number: [2070/4518] 45% | Training loss: 0.6871697817159735
Epoch: 45 | Iteration number: [2080/4518] 46% | Training loss: 0.6871643017690915
Epoch: 45 | Iteration number: [2090/4518] 46% | Training loss: 0.6871597058179846
Epoch: 45 | Iteration number: [2100/4518] 46% | Training loss: 0.6871583464883623
Epoch: 45 | Iteration number: [2110/4518] 46% | Training loss: 0.6871583137184523
Epoch: 45 | Iteration number: [2120/4518] 46% | Training loss: 0.6871582807797306
Epoch: 45 | Iteration number: [2130/4518] 47% | Training loss: 0.6871501212108863
Epoch: 45 | Iteration number: [2140/4518] 47% | Training loss: 0.6871491441102785
Epoch: 45 | Iteration number: [2150/4518] 47% | Training loss: 0.6871455403261406
Epoch: 45 | Iteration number: [2160/4518] 47% | Training loss: 0.6871442684144885
Epoch: 45 | Iteration number: [2170/4518] 48% | Training loss: 0.6871418096777481
Epoch: 45 | Iteration number: [2180/4518] 48% | Training loss: 0.6871387238622806
Epoch: 45 | Iteration number: [2190/4518] 48% | Training loss: 0.6871349477604644
Epoch: 45 | Iteration number: [2200/4518] 48% | Training loss: 0.6871354337984865
Epoch: 45 | Iteration number: [2210/4518] 48% | Training loss: 0.6871358502774217
Epoch: 45 | Iteration number: [2220/4518] 49% | Training loss: 0.6871326298595549
Epoch: 45 | Iteration number: [2230/4518] 49% | Training loss: 0.6871301823132776
Epoch: 45 | Iteration number: [2240/4518] 49% | Training loss: 0.6871221738468324
Epoch: 45 | Iteration number: [2250/4518] 49% | Training loss: 0.6871152366002401
Epoch: 45 | Iteration number: [2260/4518] 50% | Training loss: 0.687111163165717
Epoch: 45 | Iteration number: [2270/4518] 50% | Training loss: 0.6871152030213814
Epoch: 45 | Iteration number: [2280/4518] 50% | Training loss: 0.6871187344193459
Epoch: 45 | Iteration number: [2290/4518] 50% | Training loss: 0.6871168402605182
Epoch: 45 | Iteration number: [2300/4518] 50% | Training loss: 0.6871091744692429
Epoch: 45 | Iteration number: [2310/4518] 51% | Training loss: 0.6871065869991914
Epoch: 45 | Iteration number: [2320/4518] 51% | Training loss: 0.6871026564774843
Epoch: 45 | Iteration number: [2330/4518] 51% | Training loss: 0.6870994818824555
Epoch: 45 | Iteration number: [2340/4518] 51% | Training loss: 0.6871005302565729
Epoch: 45 | Iteration number: [2350/4518] 52% | Training loss: 0.6870974805253617
Epoch: 45 | Iteration number: [2360/4518] 52% | Training loss: 0.6870960637927055
Epoch: 45 | Iteration number: [2370/4518] 52% | Training loss: 0.6870943291026329
Epoch: 45 | Iteration number: [2380/4518] 52% | Training loss: 0.6870955593946602
Epoch: 45 | Iteration number: [2390/4518] 52% | Training loss: 0.6870941220965844
Epoch: 45 | Iteration number: [2400/4518] 53% | Training loss: 0.687090161840121
Epoch: 45 | Iteration number: [2410/4518] 53% | Training loss: 0.6870897271821113
Epoch: 45 | Iteration number: [2420/4518] 53% | Training loss: 0.6870892032611469
Epoch: 45 | Iteration number: [2430/4518] 53% | Training loss: 0.687085652449494
Epoch: 45 | Iteration number: [2440/4518] 54% | Training loss: 0.6870874235864546
Epoch: 45 | Iteration number: [2450/4518] 54% | Training loss: 0.6870941013949258
Epoch: 45 | Iteration number: [2460/4518] 54% | Training loss: 0.6870961121427335
Epoch: 45 | Iteration number: [2470/4518] 54% | Training loss: 0.6870981406586373
Epoch: 45 | Iteration number: [2480/4518] 54% | Training loss: 0.687096024785311
Epoch: 45 | Iteration number: [2490/4518] 55% | Training loss: 0.6870893682341978
Epoch: 45 | Iteration number: [2500/4518] 55% | Training loss: 0.6870888595342636
Epoch: 45 | Iteration number: [2510/4518] 55% | Training loss: 0.6870939524762659
Epoch: 45 | Iteration number: [2520/4518] 55% | Training loss: 0.6870967088001115
Epoch: 45 | Iteration number: [2530/4518] 55% | Training loss: 0.687095571200367
Epoch: 45 | Iteration number: [2540/4518] 56% | Training loss: 0.6870982877147479
Epoch: 45 | Iteration number: [2550/4518] 56% | Training loss: 0.687100105753132
Epoch: 45 | Iteration number: [2560/4518] 56% | Training loss: 0.6870953221805394
Epoch: 45 | Iteration number: [2570/4518] 56% | Training loss: 0.6870956856221077
Epoch: 45 | Iteration number: [2580/4518] 57% | Training loss: 0.6870932342932206
Epoch: 45 | Iteration number: [2590/4518] 57% | Training loss: 0.6870919471541888
Epoch: 45 | Iteration number: [2600/4518] 57% | Training loss: 0.687092895255639
Epoch: 45 | Iteration number: [2610/4518] 57% | Training loss: 0.6870923689955496
Epoch: 45 | Iteration number: [2620/4518] 57% | Training loss: 0.6870922247417101
Epoch: 45 | Iteration number: [2630/4518] 58% | Training loss: 0.6870922031284739
Epoch: 45 | Iteration number: [2640/4518] 58% | Training loss: 0.6870904396203431
Epoch: 45 | Iteration number: [2650/4518] 58% | Training loss: 0.6870880933527677
Epoch: 45 | Iteration number: [2660/4518] 58% | Training loss: 0.6870847329609376
Epoch: 45 | Iteration number: [2670/4518] 59% | Training loss: 0.6870801076683659
Epoch: 45 | Iteration number: [2680/4518] 59% | Training loss: 0.6870757628955059
Epoch: 45 | Iteration number: [2690/4518] 59% | Training loss: 0.6870728966028717
Epoch: 45 | Iteration number: [2700/4518] 59% | Training loss: 0.6870729403804849
Epoch: 45 | Iteration number: [2710/4518] 59% | Training loss: 0.6870723590859628
Epoch: 45 | Iteration number: [2720/4518] 60% | Training loss: 0.6870711284744389
Epoch: 45 | Iteration number: [2730/4518] 60% | Training loss: 0.6870735483291822
Epoch: 45 | Iteration number: [2740/4518] 60% | Training loss: 0.6870751996545026
Epoch: 45 | Iteration number: [2750/4518] 60% | Training loss: 0.6870748480016535
Epoch: 45 | Iteration number: [2760/4518] 61% | Training loss: 0.6870703439781631
Epoch: 45 | Iteration number: [2770/4518] 61% | Training loss: 0.6870674926236218
Epoch: 45 | Iteration number: [2780/4518] 61% | Training loss: 0.6870701245481162
Epoch: 45 | Iteration number: [2790/4518] 61% | Training loss: 0.6870690857210467
Epoch: 45 | Iteration number: [2800/4518] 61% | Training loss: 0.6870714594849519
Epoch: 45 | Iteration number: [2810/4518] 62% | Training loss: 0.6870747226413034
Epoch: 45 | Iteration number: [2820/4518] 62% | Training loss: 0.687073838605103
Epoch: 45 | Iteration number: [2830/4518] 62% | Training loss: 0.6870713576621807
Epoch: 45 | Iteration number: [2840/4518] 62% | Training loss: 0.6870692220162338
Epoch: 45 | Iteration number: [2850/4518] 63% | Training loss: 0.6870736355530588
Epoch: 45 | Iteration number: [2860/4518] 63% | Training loss: 0.6870716932145032
Epoch: 45 | Iteration number: [2870/4518] 63% | Training loss: 0.6870703369898248
Epoch: 45 | Iteration number: [2880/4518] 63% | Training loss: 0.6870666707141532
Epoch: 45 | Iteration number: [2890/4518] 63% | Training loss: 0.6870640229807593
Epoch: 45 | Iteration number: [2900/4518] 64% | Training loss: 0.687063606998016
Epoch: 45 | Iteration number: [2910/4518] 64% | Training loss: 0.6870594935523685
Epoch: 45 | Iteration number: [2920/4518] 64% | Training loss: 0.6870595726860713
Epoch: 45 | Iteration number: [2930/4518] 64% | Training loss: 0.6870555153275513
Epoch: 45 | Iteration number: [2940/4518] 65% | Training loss: 0.6870539457416859
Epoch: 45 | Iteration number: [2950/4518] 65% | Training loss: 0.6870550184330698
Epoch: 45 | Iteration number: [2960/4518] 65% | Training loss: 0.6870517693862722
Epoch: 45 | Iteration number: [2970/4518] 65% | Training loss: 0.6870469686760244
Epoch: 45 | Iteration number: [2980/4518] 65% | Training loss: 0.6870479150506474
Epoch: 45 | Iteration number: [2990/4518] 66% | Training loss: 0.6870453384807675
Epoch: 45 | Iteration number: [3000/4518] 66% | Training loss: 0.6870452497402827
Epoch: 45 | Iteration number: [3010/4518] 66% | Training loss: 0.6870490564856419
Epoch: 45 | Iteration number: [3020/4518] 66% | Training loss: 0.6870478486383198
Epoch: 45 | Iteration number: [3030/4518] 67% | Training loss: 0.68705045161861
Epoch: 45 | Iteration number: [3040/4518] 67% | Training loss: 0.6870502495844113
Epoch: 45 | Iteration number: [3050/4518] 67% | Training loss: 0.6870517290615644
Epoch: 45 | Iteration number: [3060/4518] 67% | Training loss: 0.6870524539861804
Epoch: 45 | Iteration number: [3070/4518] 67% | Training loss: 0.6870522145922099
Epoch: 45 | Iteration number: [3080/4518] 68% | Training loss: 0.6870478214381577
Epoch: 45 | Iteration number: [3090/4518] 68% | Training loss: 0.6870439348676058
Epoch: 45 | Iteration number: [3100/4518] 68% | Training loss: 0.687043144741366
Epoch: 45 | Iteration number: [3110/4518] 68% | Training loss: 0.6870455477207037
Epoch: 45 | Iteration number: [3120/4518] 69% | Training loss: 0.6870421152657423
Epoch: 45 | Iteration number: [3130/4518] 69% | Training loss: 0.6870394075640475
Epoch: 45 | Iteration number: [3140/4518] 69% | Training loss: 0.6870397163993993
Epoch: 45 | Iteration number: [3150/4518] 69% | Training loss: 0.6870385511337764
Epoch: 45 | Iteration number: [3160/4518] 69% | Training loss: 0.6870384392104572
Epoch: 45 | Iteration number: [3170/4518] 70% | Training loss: 0.6870394225564289
Epoch: 45 | Iteration number: [3180/4518] 70% | Training loss: 0.6870441418586287
Epoch: 45 | Iteration number: [3190/4518] 70% | Training loss: 0.6870462315209607
Epoch: 45 | Iteration number: [3200/4518] 70% | Training loss: 0.6870405483990908
Epoch: 45 | Iteration number: [3210/4518] 71% | Training loss: 0.6870365468141074
Epoch: 45 | Iteration number: [3220/4518] 71% | Training loss: 0.6870410765920366
Epoch: 45 | Iteration number: [3230/4518] 71% | Training loss: 0.687038199137608
Epoch: 45 | Iteration number: [3240/4518] 71% | Training loss: 0.6870362623054305
Epoch: 45 | Iteration number: [3250/4518] 71% | Training loss: 0.6870328966287467
Epoch: 45 | Iteration number: [3260/4518] 72% | Training loss: 0.6870342613363558
Epoch: 45 | Iteration number: [3270/4518] 72% | Training loss: 0.6870336392968437
Epoch: 45 | Iteration number: [3280/4518] 72% | Training loss: 0.6870320639050589
Epoch: 45 | Iteration number: [3290/4518] 72% | Training loss: 0.6870302364275448
Epoch: 45 | Iteration number: [3300/4518] 73% | Training loss: 0.6870295389132066
Epoch: 45 | Iteration number: [3310/4518] 73% | Training loss: 0.6870284478289843
Epoch: 45 | Iteration number: [3320/4518] 73% | Training loss: 0.6870275489716645
Epoch: 45 | Iteration number: [3330/4518] 73% | Training loss: 0.6870260676822146
Epoch: 45 | Iteration number: [3340/4518] 73% | Training loss: 0.6870278319020471
Epoch: 45 | Iteration number: [3350/4518] 74% | Training loss: 0.6870300416092374
Epoch: 45 | Iteration number: [3360/4518] 74% | Training loss: 0.687030184215733
Epoch: 45 | Iteration number: [3370/4518] 74% | Training loss: 0.6870285559125046
Epoch: 45 | Iteration number: [3380/4518] 74% | Training loss: 0.6870256477030071
Epoch: 45 | Iteration number: [3390/4518] 75% | Training loss: 0.6870262339403496
Epoch: 45 | Iteration number: [3400/4518] 75% | Training loss: 0.6870269762242541
Epoch: 45 | Iteration number: [3410/4518] 75% | Training loss: 0.687024440898224
Epoch: 45 | Iteration number: [3420/4518] 75% | Training loss: 0.6870252654392119
Epoch: 45 | Iteration number: [3430/4518] 75% | Training loss: 0.6870285226895579
Epoch: 45 | Iteration number: [3440/4518] 76% | Training loss: 0.6870295718832071
Epoch: 45 | Iteration number: [3450/4518] 76% | Training loss: 0.6870281379810278
Epoch: 45 | Iteration number: [3460/4518] 76% | Training loss: 0.6870272494464941
Epoch: 45 | Iteration number: [3470/4518] 76% | Training loss: 0.6870256134687308
Epoch: 45 | Iteration number: [3480/4518] 77% | Training loss: 0.6870246998880102
Epoch: 45 | Iteration number: [3490/4518] 77% | Training loss: 0.6870241698187197
Epoch: 45 | Iteration number: [3500/4518] 77% | Training loss: 0.6870243980714253
Epoch: 45 | Iteration number: [3510/4518] 77% | Training loss: 0.6870218662624685
Epoch: 45 | Iteration number: [3520/4518] 77% | Training loss: 0.6870217065072872
Epoch: 45 | Iteration number: [3530/4518] 78% | Training loss: 0.6870218488886404
Epoch: 45 | Iteration number: [3540/4518] 78% | Training loss: 0.6870173007586582
Epoch: 45 | Iteration number: [3550/4518] 78% | Training loss: 0.6870153856445366
Epoch: 45 | Iteration number: [3560/4518] 78% | Training loss: 0.6870178911123382
Epoch: 45 | Iteration number: [3570/4518] 79% | Training loss: 0.6870141755466034
Epoch: 45 | Iteration number: [3580/4518] 79% | Training loss: 0.6870147360436744
Epoch: 45 | Iteration number: [3590/4518] 79% | Training loss: 0.6870129016946618
Epoch: 45 | Iteration number: [3600/4518] 79% | Training loss: 0.6870103546480337
Epoch: 45 | Iteration number: [3610/4518] 79% | Training loss: 0.687012638048452
Epoch: 45 | Iteration number: [3620/4518] 80% | Training loss: 0.6870104181503064
Epoch: 45 | Iteration number: [3630/4518] 80% | Training loss: 0.6870115712326091
Epoch: 45 | Iteration number: [3640/4518] 80% | Training loss: 0.687011849798344
Epoch: 45 | Iteration number: [3650/4518] 80% | Training loss: 0.6870130430182365
Epoch: 45 | Iteration number: [3660/4518] 81% | Training loss: 0.6870093254280872
Epoch: 45 | Iteration number: [3670/4518] 81% | Training loss: 0.6870112182333944
Epoch: 45 | Iteration number: [3680/4518] 81% | Training loss: 0.6870097157099972
Epoch: 45 | Iteration number: [3690/4518] 81% | Training loss: 0.6870085913798997
Epoch: 45 | Iteration number: [3700/4518] 81% | Training loss: 0.687007469534874
Epoch: 45 | Iteration number: [3710/4518] 82% | Training loss: 0.6870111790950086
Epoch: 45 | Iteration number: [3720/4518] 82% | Training loss: 0.6870080363686367
Epoch: 45 | Iteration number: [3730/4518] 82% | Training loss: 0.687005255976567
Epoch: 45 | Iteration number: [3740/4518] 82% | Training loss: 0.687001740565912
Epoch: 45 | Iteration number: [3750/4518] 83% | Training loss: 0.6869999682585398
Epoch: 45 | Iteration number: [3760/4518] 83% | Training loss: 0.6870006680171541
Epoch: 45 | Iteration number: [3770/4518] 83% | Training loss: 0.6869981706142425
Epoch: 45 | Iteration number: [3780/4518] 83% | Training loss: 0.686998084644792
Epoch: 45 | Iteration number: [3790/4518] 83% | Training loss: 0.6869998874324608
Epoch: 45 | Iteration number: [3800/4518] 84% | Training loss: 0.6869969071055714
Epoch: 45 | Iteration number: [3810/4518] 84% | Training loss: 0.6869968310741614
Epoch: 45 | Iteration number: [3820/4518] 84% | Training loss: 0.6869916054278769
Epoch: 45 | Iteration number: [3830/4518] 84% | Training loss: 0.6869918834602864
Epoch: 45 | Iteration number: [3840/4518] 84% | Training loss: 0.6869939081526051
Epoch: 45 | Iteration number: [3850/4518] 85% | Training loss: 0.6869957659461281
Epoch: 45 | Iteration number: [3860/4518] 85% | Training loss: 0.6869927538336867
Epoch: 45 | Iteration number: [3870/4518] 85% | Training loss: 0.6869928663399176
Epoch: 45 | Iteration number: [3880/4518] 85% | Training loss: 0.6869949801680968
Epoch: 45 | Iteration number: [3890/4518] 86% | Training loss: 0.6869937658616387
Epoch: 45 | Iteration number: [3900/4518] 86% | Training loss: 0.6869934639105431
Epoch: 45 | Iteration number: [3910/4518] 86% | Training loss: 0.6869898929467896
Epoch: 45 | Iteration number: [3920/4518] 86% | Training loss: 0.6869917911534407
Epoch: 45 | Iteration number: [3930/4518] 86% | Training loss: 0.6869912031194333
Epoch: 45 | Iteration number: [3940/4518] 87% | Training loss: 0.6869878155023313
Epoch: 45 | Iteration number: [3950/4518] 87% | Training loss: 0.6869872003718267
Epoch: 45 | Iteration number: [3960/4518] 87% | Training loss: 0.6869848098267208
Epoch: 45 | Iteration number: [3970/4518] 87% | Training loss: 0.686985658338148
Epoch: 45 | Iteration number: [3980/4518] 88% | Training loss: 0.6869868304262209
Epoch: 45 | Iteration number: [3990/4518] 88% | Training loss: 0.6869868305243346
Epoch: 45 | Iteration number: [4000/4518] 88% | Training loss: 0.6869885832220316
Epoch: 45 | Iteration number: [4010/4518] 88% | Training loss: 0.6869903043172603
Epoch: 45 | Iteration number: [4020/4518] 88% | Training loss: 0.6869910439152029
Epoch: 45 | Iteration number: [4030/4518] 89% | Training loss: 0.6869919871574004
Epoch: 45 | Iteration number: [4040/4518] 89% | Training loss: 0.6869900518862327
Epoch: 45 | Iteration number: [4050/4518] 89% | Training loss: 0.6869903759455975
Epoch: 45 | Iteration number: [4060/4518] 89% | Training loss: 0.6869912465217666
Epoch: 45 | Iteration number: [4070/4518] 90% | Training loss: 0.6869907201947393
Epoch: 45 | Iteration number: [4080/4518] 90% | Training loss: 0.6869920719049725
Epoch: 45 | Iteration number: [4090/4518] 90% | Training loss: 0.6869933771183555
Epoch: 45 | Iteration number: [4100/4518] 90% | Training loss: 0.6869957333512422
Epoch: 45 | Iteration number: [4110/4518] 90% | Training loss: 0.6869918549872953
Epoch: 45 | Iteration number: [4120/4518] 91% | Training loss: 0.6869888710888844
Epoch: 45 | Iteration number: [4130/4518] 91% | Training loss: 0.6869873965046308
Epoch: 45 | Iteration number: [4140/4518] 91% | Training loss: 0.686985718700045
Epoch: 45 | Iteration number: [4150/4518] 91% | Training loss: 0.686982907171709
Epoch: 45 | Iteration number: [4160/4518] 92% | Training loss: 0.6869775327495657
Epoch: 45 | Iteration number: [4170/4518] 92% | Training loss: 0.686977320423515
Epoch: 45 | Iteration number: [4180/4518] 92% | Training loss: 0.6869797776760667
Epoch: 45 | Iteration number: [4190/4518] 92% | Training loss: 0.6869777048686808
Epoch: 45 | Iteration number: [4200/4518] 92% | Training loss: 0.6869777374892008
Epoch: 45 | Iteration number: [4210/4518] 93% | Training loss: 0.6869757569600737
Epoch: 45 | Iteration number: [4220/4518] 93% | Training loss: 0.6869746519632249
Epoch: 45 | Iteration number: [4230/4518] 93% | Training loss: 0.6869742341075383
Epoch: 45 | Iteration number: [4240/4518] 93% | Training loss: 0.6869771180287847
Epoch: 45 | Iteration number: [4250/4518] 94% | Training loss: 0.6869782525651595
Epoch: 45 | Iteration number: [4260/4518] 94% | Training loss: 0.6869805737420427
Epoch: 45 | Iteration number: [4270/4518] 94% | Training loss: 0.6869796129244552
Epoch: 45 | Iteration number: [4280/4518] 94% | Training loss: 0.6869828695170234
Epoch: 45 | Iteration number: [4290/4518] 94% | Training loss: 0.6869823732159355
Epoch: 45 | Iteration number: [4300/4518] 95% | Training loss: 0.6869824498198753
Epoch: 45 | Iteration number: [4310/4518] 95% | Training loss: 0.6869819169254702
Epoch: 45 | Iteration number: [4320/4518] 95% | Training loss: 0.6869828734960821
Epoch: 45 | Iteration number: [4330/4518] 95% | Training loss: 0.6869812644656756
Epoch: 45 | Iteration number: [4340/4518] 96% | Training loss: 0.6869833711517571
Epoch: 45 | Iteration number: [4350/4518] 96% | Training loss: 0.6869816421092242
Epoch: 45 | Iteration number: [4360/4518] 96% | Training loss: 0.6869805209680435
Epoch: 45 | Iteration number: [4370/4518] 96% | Training loss: 0.6869821522683246
Epoch: 45 | Iteration number: [4380/4518] 96% | Training loss: 0.6869821558259938
Epoch: 45 | Iteration number: [4390/4518] 97% | Training loss: 0.6869817481497155
Epoch: 45 | Iteration number: [4400/4518] 97% | Training loss: 0.6869786702231927
Epoch: 45 | Iteration number: [4410/4518] 97% | Training loss: 0.6869766901815288
Epoch: 45 | Iteration number: [4420/4518] 97% | Training loss: 0.6869780726022849
Epoch: 45 | Iteration number: [4430/4518] 98% | Training loss: 0.6869774657366776
Epoch: 45 | Iteration number: [4440/4518] 98% | Training loss: 0.6869773105995075
Epoch: 45 | Iteration number: [4450/4518] 98% | Training loss: 0.686976926608032
Epoch: 45 | Iteration number: [4460/4518] 98% | Training loss: 0.6869764901463761
Epoch: 45 | Iteration number: [4470/4518] 98% | Training loss: 0.686978052513178
Epoch: 45 | Iteration number: [4480/4518] 99% | Training loss: 0.6869766590850693
Epoch: 45 | Iteration number: [4490/4518] 99% | Training loss: 0.6869757130177887
Epoch: 45 | Iteration number: [4500/4518] 99% | Training loss: 0.6869768822722965
Epoch: 45 | Iteration number: [4510/4518] 99% | Training loss: 0.6869793922700269

 End of epoch: 45 | Train Loss: 0.6868267724106617 | Training Time: 643 

 End of epoch: 45 | Eval Loss: 0.6901900001934597 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/4518] 0% | Training loss: 0.7552211821079254
Epoch: 46 | Iteration number: [20/4518] 0% | Training loss: 0.7211753129959106
Epoch: 46 | Iteration number: [30/4518] 0% | Training loss: 0.7097613195578257
Epoch: 46 | Iteration number: [40/4518] 0% | Training loss: 0.7040166780352592
Epoch: 46 | Iteration number: [50/4518] 1% | Training loss: 0.7007682275772095
Epoch: 46 | Iteration number: [60/4518] 1% | Training loss: 0.698375811179479
Epoch: 46 | Iteration number: [70/4518] 1% | Training loss: 0.6967525320393698
Epoch: 46 | Iteration number: [80/4518] 1% | Training loss: 0.6954830206930638
Epoch: 46 | Iteration number: [90/4518] 1% | Training loss: 0.6945455458429125
Epoch: 46 | Iteration number: [100/4518] 2% | Training loss: 0.6937807512283325
Epoch: 46 | Iteration number: [110/4518] 2% | Training loss: 0.6930493858727542
Epoch: 46 | Iteration number: [120/4518] 2% | Training loss: 0.6925164764126142
Epoch: 46 | Iteration number: [130/4518] 2% | Training loss: 0.6921392037318304
Epoch: 46 | Iteration number: [140/4518] 3% | Training loss: 0.6918276075805937
Epoch: 46 | Iteration number: [150/4518] 3% | Training loss: 0.6915001984437307
Epoch: 46 | Iteration number: [160/4518] 3% | Training loss: 0.6912299189716578
Epoch: 46 | Iteration number: [170/4518] 3% | Training loss: 0.6909490907893462
Epoch: 46 | Iteration number: [180/4518] 3% | Training loss: 0.690673076113065
Epoch: 46 | Iteration number: [190/4518] 4% | Training loss: 0.6904434938179819
Epoch: 46 | Iteration number: [200/4518] 4% | Training loss: 0.6903360530734062
Epoch: 46 | Iteration number: [210/4518] 4% | Training loss: 0.6900734311058407
Epoch: 46 | Iteration number: [220/4518] 4% | Training loss: 0.6899505815722725
Epoch: 46 | Iteration number: [230/4518] 5% | Training loss: 0.689804408342942
Epoch: 46 | Iteration number: [240/4518] 5% | Training loss: 0.6896706238389015
Epoch: 46 | Iteration number: [250/4518] 5% | Training loss: 0.6895056741237641
Epoch: 46 | Iteration number: [260/4518] 5% | Training loss: 0.6894402891397476
Epoch: 46 | Iteration number: [270/4518] 5% | Training loss: 0.6893437915378147
Epoch: 46 | Iteration number: [280/4518] 6% | Training loss: 0.6892475172877311
Epoch: 46 | Iteration number: [290/4518] 6% | Training loss: 0.6892130335857128
Epoch: 46 | Iteration number: [300/4518] 6% | Training loss: 0.6891430890560151
Epoch: 46 | Iteration number: [310/4518] 6% | Training loss: 0.6890951577694185
Epoch: 46 | Iteration number: [320/4518] 7% | Training loss: 0.6890453729778528
Epoch: 46 | Iteration number: [330/4518] 7% | Training loss: 0.6890000953818812
Epoch: 46 | Iteration number: [340/4518] 7% | Training loss: 0.6889795085963081
Epoch: 46 | Iteration number: [350/4518] 7% | Training loss: 0.6889040851593018
Epoch: 46 | Iteration number: [360/4518] 7% | Training loss: 0.6889089276393254
Epoch: 46 | Iteration number: [370/4518] 8% | Training loss: 0.6888188631147951
Epoch: 46 | Iteration number: [380/4518] 8% | Training loss: 0.6887308991269061
Epoch: 46 | Iteration number: [390/4518] 8% | Training loss: 0.6886587858200073
Epoch: 46 | Iteration number: [400/4518] 8% | Training loss: 0.688614751547575
Epoch: 46 | Iteration number: [410/4518] 9% | Training loss: 0.6885662451023009
Epoch: 46 | Iteration number: [420/4518] 9% | Training loss: 0.6885309586922328
Epoch: 46 | Iteration number: [430/4518] 9% | Training loss: 0.68850536790005
Epoch: 46 | Iteration number: [440/4518] 9% | Training loss: 0.6884602835232562
Epoch: 46 | Iteration number: [450/4518] 9% | Training loss: 0.688404526842965
Epoch: 46 | Iteration number: [460/4518] 10% | Training loss: 0.6883625395919966
Epoch: 46 | Iteration number: [470/4518] 10% | Training loss: 0.6883527420936747
Epoch: 46 | Iteration number: [480/4518] 10% | Training loss: 0.6883046522736549
Epoch: 46 | Iteration number: [490/4518] 10% | Training loss: 0.6882786671726071
Epoch: 46 | Iteration number: [500/4518] 11% | Training loss: 0.6882393540143966
Epoch: 46 | Iteration number: [510/4518] 11% | Training loss: 0.688212692971323
Epoch: 46 | Iteration number: [520/4518] 11% | Training loss: 0.6881712176478826
Epoch: 46 | Iteration number: [530/4518] 11% | Training loss: 0.6881340733114278
Epoch: 46 | Iteration number: [540/4518] 11% | Training loss: 0.6881162748292641
Epoch: 46 | Iteration number: [550/4518] 12% | Training loss: 0.6880728477781469
Epoch: 46 | Iteration number: [560/4518] 12% | Training loss: 0.6880322932132653
Epoch: 46 | Iteration number: [570/4518] 12% | Training loss: 0.6880045315675568
Epoch: 46 | Iteration number: [580/4518] 12% | Training loss: 0.6879810765899461
Epoch: 46 | Iteration number: [590/4518] 13% | Training loss: 0.6879481586359315
Epoch: 46 | Iteration number: [600/4518] 13% | Training loss: 0.6879266813397408
Epoch: 46 | Iteration number: [610/4518] 13% | Training loss: 0.6879175807608933
Epoch: 46 | Iteration number: [620/4518] 13% | Training loss: 0.6878964185714722
Epoch: 46 | Iteration number: [630/4518] 13% | Training loss: 0.6878980154082889
Epoch: 46 | Iteration number: [640/4518] 14% | Training loss: 0.6878668792545796
Epoch: 46 | Iteration number: [650/4518] 14% | Training loss: 0.6878486071183131
Epoch: 46 | Iteration number: [660/4518] 14% | Training loss: 0.6878427004272287
Epoch: 46 | Iteration number: [670/4518] 14% | Training loss: 0.6878438701380545
Epoch: 46 | Iteration number: [680/4518] 15% | Training loss: 0.6878281979876406
Epoch: 46 | Iteration number: [690/4518] 15% | Training loss: 0.6878070207609647
Epoch: 46 | Iteration number: [700/4518] 15% | Training loss: 0.6878015227828707
Epoch: 46 | Iteration number: [710/4518] 15% | Training loss: 0.6878036020507275
Epoch: 46 | Iteration number: [720/4518] 15% | Training loss: 0.6877941762407621
Epoch: 46 | Iteration number: [730/4518] 16% | Training loss: 0.6877867974647104
Epoch: 46 | Iteration number: [740/4518] 16% | Training loss: 0.6877711447509559
Epoch: 46 | Iteration number: [750/4518] 16% | Training loss: 0.687751380999883
Epoch: 46 | Iteration number: [760/4518] 16% | Training loss: 0.6877242743184692
Epoch: 46 | Iteration number: [770/4518] 17% | Training loss: 0.687720713754753
Epoch: 46 | Iteration number: [780/4518] 17% | Training loss: 0.6877146954719837
Epoch: 46 | Iteration number: [790/4518] 17% | Training loss: 0.6877083215532424
Epoch: 46 | Iteration number: [800/4518] 17% | Training loss: 0.6877089241147041
Epoch: 46 | Iteration number: [810/4518] 17% | Training loss: 0.687682095721916
Epoch: 46 | Iteration number: [820/4518] 18% | Training loss: 0.6876614995119048
Epoch: 46 | Iteration number: [830/4518] 18% | Training loss: 0.687650658854519
Epoch: 46 | Iteration number: [840/4518] 18% | Training loss: 0.6876367612963631
Epoch: 46 | Iteration number: [850/4518] 18% | Training loss: 0.6876316799135769
Epoch: 46 | Iteration number: [860/4518] 19% | Training loss: 0.6876206514447234
Epoch: 46 | Iteration number: [870/4518] 19% | Training loss: 0.687619423934783
Epoch: 46 | Iteration number: [880/4518] 19% | Training loss: 0.6876049432564866
Epoch: 46 | Iteration number: [890/4518] 19% | Training loss: 0.6876011473409246
Epoch: 46 | Iteration number: [900/4518] 19% | Training loss: 0.6875998179780113
Epoch: 46 | Iteration number: [910/4518] 20% | Training loss: 0.6875898938912611
Epoch: 46 | Iteration number: [920/4518] 20% | Training loss: 0.6875968966795051
Epoch: 46 | Iteration number: [930/4518] 20% | Training loss: 0.6875981635303907
Epoch: 46 | Iteration number: [940/4518] 20% | Training loss: 0.6876011763481383
Epoch: 46 | Iteration number: [950/4518] 21% | Training loss: 0.6875920795139514
Epoch: 46 | Iteration number: [960/4518] 21% | Training loss: 0.6875851739197969
Epoch: 46 | Iteration number: [970/4518] 21% | Training loss: 0.6875826913056914
Epoch: 46 | Iteration number: [980/4518] 21% | Training loss: 0.6875870075152845
Epoch: 46 | Iteration number: [990/4518] 21% | Training loss: 0.6875792543093363
Epoch: 46 | Iteration number: [1000/4518] 22% | Training loss: 0.6875526174902916
Epoch: 46 | Iteration number: [1010/4518] 22% | Training loss: 0.6875362690132443
Epoch: 46 | Iteration number: [1020/4518] 22% | Training loss: 0.6875299555413863
Epoch: 46 | Iteration number: [1030/4518] 22% | Training loss: 0.687527618246171
Epoch: 46 | Iteration number: [1040/4518] 23% | Training loss: 0.6875211751804902
Epoch: 46 | Iteration number: [1050/4518] 23% | Training loss: 0.6875238175619216
Epoch: 46 | Iteration number: [1060/4518] 23% | Training loss: 0.6875205204171955
Epoch: 46 | Iteration number: [1070/4518] 23% | Training loss: 0.6875093725240119
Epoch: 46 | Iteration number: [1080/4518] 23% | Training loss: 0.6875014976218895
Epoch: 46 | Iteration number: [1090/4518] 24% | Training loss: 0.6874892417444002
Epoch: 46 | Iteration number: [1100/4518] 24% | Training loss: 0.6874948696656661
Epoch: 46 | Iteration number: [1110/4518] 24% | Training loss: 0.6874917196260916
Epoch: 46 | Iteration number: [1120/4518] 24% | Training loss: 0.6874776182962316
Epoch: 46 | Iteration number: [1130/4518] 25% | Training loss: 0.6874738548181754
Epoch: 46 | Iteration number: [1140/4518] 25% | Training loss: 0.687456722845111
Epoch: 46 | Iteration number: [1150/4518] 25% | Training loss: 0.6874474054315816
Epoch: 46 | Iteration number: [1160/4518] 25% | Training loss: 0.6874405056238174
Epoch: 46 | Iteration number: [1170/4518] 25% | Training loss: 0.6874512451836187
Epoch: 46 | Iteration number: [1180/4518] 26% | Training loss: 0.6874442729404417
Epoch: 46 | Iteration number: [1190/4518] 26% | Training loss: 0.6874334444017971
Epoch: 46 | Iteration number: [1200/4518] 26% | Training loss: 0.6874369215468565
Epoch: 46 | Iteration number: [1210/4518] 26% | Training loss: 0.6874379745692261
Epoch: 46 | Iteration number: [1220/4518] 27% | Training loss: 0.6874164996088529
Epoch: 46 | Iteration number: [1230/4518] 27% | Training loss: 0.6874032396611159
Epoch: 46 | Iteration number: [1240/4518] 27% | Training loss: 0.6874043256525071
Epoch: 46 | Iteration number: [1250/4518] 27% | Training loss: 0.6874015974998474
Epoch: 46 | Iteration number: [1260/4518] 27% | Training loss: 0.6873903384284368
Epoch: 46 | Iteration number: [1270/4518] 28% | Training loss: 0.6873960495464445
Epoch: 46 | Iteration number: [1280/4518] 28% | Training loss: 0.6873914236202836
Epoch: 46 | Iteration number: [1290/4518] 28% | Training loss: 0.6873905778393264
Epoch: 46 | Iteration number: [1300/4518] 28% | Training loss: 0.6873738425970077
Epoch: 46 | Iteration number: [1310/4518] 28% | Training loss: 0.6873626575215173
Epoch: 46 | Iteration number: [1320/4518] 29% | Training loss: 0.6873576492974253
Epoch: 46 | Iteration number: [1330/4518] 29% | Training loss: 0.6873617455027157
Epoch: 46 | Iteration number: [1340/4518] 29% | Training loss: 0.6873488488926817
Epoch: 46 | Iteration number: [1350/4518] 29% | Training loss: 0.687340516646703
Epoch: 46 | Iteration number: [1360/4518] 30% | Training loss: 0.687338425219059
Epoch: 46 | Iteration number: [1370/4518] 30% | Training loss: 0.6873333429333067
Epoch: 46 | Iteration number: [1380/4518] 30% | Training loss: 0.6873178373644317
Epoch: 46 | Iteration number: [1390/4518] 30% | Training loss: 0.6873140518185046
Epoch: 46 | Iteration number: [1400/4518] 30% | Training loss: 0.6873135827694621
Epoch: 46 | Iteration number: [1410/4518] 31% | Training loss: 0.6873159450842133
Epoch: 46 | Iteration number: [1420/4518] 31% | Training loss: 0.6873132805169468
Epoch: 46 | Iteration number: [1430/4518] 31% | Training loss: 0.6873033654856515
Epoch: 46 | Iteration number: [1440/4518] 31% | Training loss: 0.687307482626703
Epoch: 46 | Iteration number: [1450/4518] 32% | Training loss: 0.6872986328190771
Epoch: 46 | Iteration number: [1460/4518] 32% | Training loss: 0.6872952950327363
Epoch: 46 | Iteration number: [1470/4518] 32% | Training loss: 0.6872919996174014
Epoch: 46 | Iteration number: [1480/4518] 32% | Training loss: 0.6872953221604631
Epoch: 46 | Iteration number: [1490/4518] 32% | Training loss: 0.6872946964814359
Epoch: 46 | Iteration number: [1500/4518] 33% | Training loss: 0.6872940790255865
Epoch: 46 | Iteration number: [1510/4518] 33% | Training loss: 0.6872933851962058
Epoch: 46 | Iteration number: [1520/4518] 33% | Training loss: 0.6872994817009098
Epoch: 46 | Iteration number: [1530/4518] 33% | Training loss: 0.6872974486911998
Epoch: 46 | Iteration number: [1540/4518] 34% | Training loss: 0.6872935288525247
Epoch: 46 | Iteration number: [1550/4518] 34% | Training loss: 0.6872978414643195
Epoch: 46 | Iteration number: [1560/4518] 34% | Training loss: 0.687302535925156
Epoch: 46 | Iteration number: [1570/4518] 34% | Training loss: 0.6872984624212715
Epoch: 46 | Iteration number: [1580/4518] 34% | Training loss: 0.68729612167123
Epoch: 46 | Iteration number: [1590/4518] 35% | Training loss: 0.6872921360363751
Epoch: 46 | Iteration number: [1600/4518] 35% | Training loss: 0.6872965260595083
Epoch: 46 | Iteration number: [1610/4518] 35% | Training loss: 0.6872954621078065
Epoch: 46 | Iteration number: [1620/4518] 35% | Training loss: 0.6873017485494967
Epoch: 46 | Iteration number: [1630/4518] 36% | Training loss: 0.6872980969815167
Epoch: 46 | Iteration number: [1640/4518] 36% | Training loss: 0.6872950979485745
Epoch: 46 | Iteration number: [1650/4518] 36% | Training loss: 0.6872972943927302
Epoch: 46 | Iteration number: [1660/4518] 36% | Training loss: 0.6873009880982249
Epoch: 46 | Iteration number: [1670/4518] 36% | Training loss: 0.6873072977551443
Epoch: 46 | Iteration number: [1680/4518] 37% | Training loss: 0.6873097056079478
Epoch: 46 | Iteration number: [1690/4518] 37% | Training loss: 0.687300731585576
Epoch: 46 | Iteration number: [1700/4518] 37% | Training loss: 0.6873013065843021
Epoch: 46 | Iteration number: [1710/4518] 37% | Training loss: 0.6873062109040935
Epoch: 46 | Iteration number: [1720/4518] 38% | Training loss: 0.6873037035035533
Epoch: 46 | Iteration number: [1730/4518] 38% | Training loss: 0.6873001682275982
Epoch: 46 | Iteration number: [1740/4518] 38% | Training loss: 0.6872965612630735
Epoch: 46 | Iteration number: [1750/4518] 38% | Training loss: 0.6872880611760276
Epoch: 46 | Iteration number: [1760/4518] 38% | Training loss: 0.6872880126603625
Epoch: 46 | Iteration number: [1770/4518] 39% | Training loss: 0.687282649676005
Epoch: 46 | Iteration number: [1780/4518] 39% | Training loss: 0.6872879838340737
Epoch: 46 | Iteration number: [1790/4518] 39% | Training loss: 0.6872840552689643
Epoch: 46 | Iteration number: [1800/4518] 39% | Training loss: 0.68727849761645
Epoch: 46 | Iteration number: [1810/4518] 40% | Training loss: 0.6872797688397255
Epoch: 46 | Iteration number: [1820/4518] 40% | Training loss: 0.687277545771756
Epoch: 46 | Iteration number: [1830/4518] 40% | Training loss: 0.6872744517248185
Epoch: 46 | Iteration number: [1840/4518] 40% | Training loss: 0.6872754636342111
Epoch: 46 | Iteration number: [1850/4518] 40% | Training loss: 0.6872704553926313
Epoch: 46 | Iteration number: [1860/4518] 41% | Training loss: 0.6872620422032572
Epoch: 46 | Iteration number: [1870/4518] 41% | Training loss: 0.6872586204725153
Epoch: 46 | Iteration number: [1880/4518] 41% | Training loss: 0.6872558876555017
Epoch: 46 | Iteration number: [1890/4518] 41% | Training loss: 0.6872580861603772
Epoch: 46 | Iteration number: [1900/4518] 42% | Training loss: 0.6872538511376632
Epoch: 46 | Iteration number: [1910/4518] 42% | Training loss: 0.6872536398041311
Epoch: 46 | Iteration number: [1920/4518] 42% | Training loss: 0.6872545779061814
Epoch: 46 | Iteration number: [1930/4518] 42% | Training loss: 0.6872523306564964
Epoch: 46 | Iteration number: [1940/4518] 42% | Training loss: 0.6872492904822851
Epoch: 46 | Iteration number: [1950/4518] 43% | Training loss: 0.6872525832286248
Epoch: 46 | Iteration number: [1960/4518] 43% | Training loss: 0.6872456656122694
Epoch: 46 | Iteration number: [1970/4518] 43% | Training loss: 0.6872422100626273
Epoch: 46 | Iteration number: [1980/4518] 43% | Training loss: 0.6872439864307943
Epoch: 46 | Iteration number: [1990/4518] 44% | Training loss: 0.6872424547995755
Epoch: 46 | Iteration number: [2000/4518] 44% | Training loss: 0.6872410520911216
Epoch: 46 | Iteration number: [2010/4518] 44% | Training loss: 0.6872387031417581
Epoch: 46 | Iteration number: [2020/4518] 44% | Training loss: 0.6872382402715116
Epoch: 46 | Iteration number: [2030/4518] 44% | Training loss: 0.6872321921909971
Epoch: 46 | Iteration number: [2040/4518] 45% | Training loss: 0.6872254213866066
Epoch: 46 | Iteration number: [2050/4518] 45% | Training loss: 0.6872221336132143
Epoch: 46 | Iteration number: [2060/4518] 45% | Training loss: 0.6872156043075821
Epoch: 46 | Iteration number: [2070/4518] 45% | Training loss: 0.6872177422910497
Epoch: 46 | Iteration number: [2080/4518] 46% | Training loss: 0.6872155242241346
Epoch: 46 | Iteration number: [2090/4518] 46% | Training loss: 0.687221857320749
Epoch: 46 | Iteration number: [2100/4518] 46% | Training loss: 0.6872184491157531
Epoch: 46 | Iteration number: [2110/4518] 46% | Training loss: 0.6872249149598216
Epoch: 46 | Iteration number: [2120/4518] 46% | Training loss: 0.6872194012943303
Epoch: 46 | Iteration number: [2130/4518] 47% | Training loss: 0.6872169949918846
Epoch: 46 | Iteration number: [2140/4518] 47% | Training loss: 0.6872111365895405
Epoch: 46 | Iteration number: [2150/4518] 47% | Training loss: 0.6872102580791296
Epoch: 46 | Iteration number: [2160/4518] 47% | Training loss: 0.6872120020566164
Epoch: 46 | Iteration number: [2170/4518] 48% | Training loss: 0.6872023256418343
Epoch: 46 | Iteration number: [2180/4518] 48% | Training loss: 0.6871957992194989
Epoch: 46 | Iteration number: [2190/4518] 48% | Training loss: 0.6871901822688917
Epoch: 46 | Iteration number: [2200/4518] 48% | Training loss: 0.6871913834051653
Epoch: 46 | Iteration number: [2210/4518] 48% | Training loss: 0.6871928315087141
Epoch: 46 | Iteration number: [2220/4518] 49% | Training loss: 0.687186482870901
Epoch: 46 | Iteration number: [2230/4518] 49% | Training loss: 0.6871798977723571
Epoch: 46 | Iteration number: [2240/4518] 49% | Training loss: 0.6871782189501183
Epoch: 46 | Iteration number: [2250/4518] 49% | Training loss: 0.6871814103126526
Epoch: 46 | Iteration number: [2260/4518] 50% | Training loss: 0.6871866103822151
Epoch: 46 | Iteration number: [2270/4518] 50% | Training loss: 0.6871844048279497
Epoch: 46 | Iteration number: [2280/4518] 50% | Training loss: 0.6871802502295428
Epoch: 46 | Iteration number: [2290/4518] 50% | Training loss: 0.6871748864390445
Epoch: 46 | Iteration number: [2300/4518] 50% | Training loss: 0.6871748139028964
Epoch: 46 | Iteration number: [2310/4518] 51% | Training loss: 0.6871732677990224
Epoch: 46 | Iteration number: [2320/4518] 51% | Training loss: 0.6871770691255044
Epoch: 46 | Iteration number: [2330/4518] 51% | Training loss: 0.6871768025881231
Epoch: 46 | Iteration number: [2340/4518] 51% | Training loss: 0.6871716806776503
Epoch: 46 | Iteration number: [2350/4518] 52% | Training loss: 0.6871743867498763
Epoch: 46 | Iteration number: [2360/4518] 52% | Training loss: 0.6871750027698985
Epoch: 46 | Iteration number: [2370/4518] 52% | Training loss: 0.6871732259098488
Epoch: 46 | Iteration number: [2380/4518] 52% | Training loss: 0.6871681020039471
Epoch: 46 | Iteration number: [2390/4518] 52% | Training loss: 0.6871693414125483
Epoch: 46 | Iteration number: [2400/4518] 53% | Training loss: 0.6871711327135563
Epoch: 46 | Iteration number: [2410/4518] 53% | Training loss: 0.6871644022059143
Epoch: 46 | Iteration number: [2420/4518] 53% | Training loss: 0.6871591319722578
Epoch: 46 | Iteration number: [2430/4518] 53% | Training loss: 0.6871570980597916
Epoch: 46 | Iteration number: [2440/4518] 54% | Training loss: 0.6871536822592625
Epoch: 46 | Iteration number: [2450/4518] 54% | Training loss: 0.6871514832730196
Epoch: 46 | Iteration number: [2460/4518] 54% | Training loss: 0.6871409934952977
Epoch: 46 | Iteration number: [2470/4518] 54% | Training loss: 0.687133912736105
Epoch: 46 | Iteration number: [2480/4518] 54% | Training loss: 0.6871287137029632
Epoch: 46 | Iteration number: [2490/4518] 55% | Training loss: 0.6871257339376043
Epoch: 46 | Iteration number: [2500/4518] 55% | Training loss: 0.6871248763561248
Epoch: 46 | Iteration number: [2510/4518] 55% | Training loss: 0.6871280714810132
Epoch: 46 | Iteration number: [2520/4518] 55% | Training loss: 0.6871308749393811
Epoch: 46 | Iteration number: [2530/4518] 55% | Training loss: 0.6871332870877307
Epoch: 46 | Iteration number: [2540/4518] 56% | Training loss: 0.6871293793747745
Epoch: 46 | Iteration number: [2550/4518] 56% | Training loss: 0.6871284853009617
Epoch: 46 | Iteration number: [2560/4518] 56% | Training loss: 0.687128767091781
Epoch: 46 | Iteration number: [2570/4518] 56% | Training loss: 0.6871328619667528
Epoch: 46 | Iteration number: [2580/4518] 57% | Training loss: 0.687133339809817
Epoch: 46 | Iteration number: [2590/4518] 57% | Training loss: 0.687134116381752
Epoch: 46 | Iteration number: [2600/4518] 57% | Training loss: 0.6871282837941096
Epoch: 46 | Iteration number: [2610/4518] 57% | Training loss: 0.6871308041486703
Epoch: 46 | Iteration number: [2620/4518] 57% | Training loss: 0.6871252288345162
Epoch: 46 | Iteration number: [2630/4518] 58% | Training loss: 0.6871281645370527
Epoch: 46 | Iteration number: [2640/4518] 58% | Training loss: 0.6871224482176882
Epoch: 46 | Iteration number: [2650/4518] 58% | Training loss: 0.6871258829449708
Epoch: 46 | Iteration number: [2660/4518] 58% | Training loss: 0.6871238418763741
Epoch: 46 | Iteration number: [2670/4518] 59% | Training loss: 0.6871187152710747
Epoch: 46 | Iteration number: [2680/4518] 59% | Training loss: 0.6871172069391208
Epoch: 46 | Iteration number: [2690/4518] 59% | Training loss: 0.6871182518820781
Epoch: 46 | Iteration number: [2700/4518] 59% | Training loss: 0.6871172400977876
Epoch: 46 | Iteration number: [2710/4518] 59% | Training loss: 0.6871161364761226
Epoch: 46 | Iteration number: [2720/4518] 60% | Training loss: 0.6871110485757098
Epoch: 46 | Iteration number: [2730/4518] 60% | Training loss: 0.6871135269984221
Epoch: 46 | Iteration number: [2740/4518] 60% | Training loss: 0.6871074934510419
Epoch: 46 | Iteration number: [2750/4518] 60% | Training loss: 0.6871057830073617
Epoch: 46 | Iteration number: [2760/4518] 61% | Training loss: 0.6870988074420155
Epoch: 46 | Iteration number: [2770/4518] 61% | Training loss: 0.6870984862642598
Epoch: 46 | Iteration number: [2780/4518] 61% | Training loss: 0.6870964545354569
Epoch: 46 | Iteration number: [2790/4518] 61% | Training loss: 0.687097477058356
Epoch: 46 | Iteration number: [2800/4518] 61% | Training loss: 0.6870970569550992
Epoch: 46 | Iteration number: [2810/4518] 62% | Training loss: 0.6870992664552669
Epoch: 46 | Iteration number: [2820/4518] 62% | Training loss: 0.687099071618513
Epoch: 46 | Iteration number: [2830/4518] 62% | Training loss: 0.6870938008118013
Epoch: 46 | Iteration number: [2840/4518] 62% | Training loss: 0.6870884442623233
Epoch: 46 | Iteration number: [2850/4518] 63% | Training loss: 0.6870858947226876
Epoch: 46 | Iteration number: [2860/4518] 63% | Training loss: 0.6870844222240514
Epoch: 46 | Iteration number: [2870/4518] 63% | Training loss: 0.6870819257526863
Epoch: 46 | Iteration number: [2880/4518] 63% | Training loss: 0.6870771389868524
Epoch: 46 | Iteration number: [2890/4518] 63% | Training loss: 0.6870792194221259
Epoch: 46 | Iteration number: [2900/4518] 64% | Training loss: 0.6870780251971607
Epoch: 46 | Iteration number: [2910/4518] 64% | Training loss: 0.6870781947247351
Epoch: 46 | Iteration number: [2920/4518] 64% | Training loss: 0.687078343821715
Epoch: 46 | Iteration number: [2930/4518] 64% | Training loss: 0.6870760123274026
Epoch: 46 | Iteration number: [2940/4518] 65% | Training loss: 0.6870759479448098
Epoch: 46 | Iteration number: [2950/4518] 65% | Training loss: 0.687074727466551
Epoch: 46 | Iteration number: [2960/4518] 65% | Training loss: 0.6870698855334038
Epoch: 46 | Iteration number: [2970/4518] 65% | Training loss: 0.6870680831698858
Epoch: 46 | Iteration number: [2980/4518] 65% | Training loss: 0.6870652523016769
Epoch: 46 | Iteration number: [2990/4518] 66% | Training loss: 0.6870638228180417
Epoch: 46 | Iteration number: [3000/4518] 66% | Training loss: 0.6870630945364634
Epoch: 46 | Iteration number: [3010/4518] 66% | Training loss: 0.687061198842882
Epoch: 46 | Iteration number: [3020/4518] 66% | Training loss: 0.6870595941677788
Epoch: 46 | Iteration number: [3030/4518] 67% | Training loss: 0.6870576644297873
Epoch: 46 | Iteration number: [3040/4518] 67% | Training loss: 0.6870560476262318
Epoch: 46 | Iteration number: [3050/4518] 67% | Training loss: 0.6870572653559388
Epoch: 46 | Iteration number: [3060/4518] 67% | Training loss: 0.6870578392658359
Epoch: 46 | Iteration number: [3070/4518] 67% | Training loss: 0.6870526830614195
Epoch: 46 | Iteration number: [3080/4518] 68% | Training loss: 0.6870525912224472
Epoch: 46 | Iteration number: [3090/4518] 68% | Training loss: 0.6870491148777378
Epoch: 46 | Iteration number: [3100/4518] 68% | Training loss: 0.6870474600215112
Epoch: 46 | Iteration number: [3110/4518] 68% | Training loss: 0.6870463117909201
Epoch: 46 | Iteration number: [3120/4518] 69% | Training loss: 0.6870454568893481
Epoch: 46 | Iteration number: [3130/4518] 69% | Training loss: 0.6870417179200596
Epoch: 46 | Iteration number: [3140/4518] 69% | Training loss: 0.6870428684790423
Epoch: 46 | Iteration number: [3150/4518] 69% | Training loss: 0.6870421762504275
Epoch: 46 | Iteration number: [3160/4518] 69% | Training loss: 0.6870426334535019
Epoch: 46 | Iteration number: [3170/4518] 70% | Training loss: 0.6870405012312748
Epoch: 46 | Iteration number: [3180/4518] 70% | Training loss: 0.6870395201369651
Epoch: 46 | Iteration number: [3190/4518] 70% | Training loss: 0.6870378065258732
Epoch: 46 | Iteration number: [3200/4518] 70% | Training loss: 0.6870386149547995
Epoch: 46 | Iteration number: [3210/4518] 71% | Training loss: 0.6870354158113308
Epoch: 46 | Iteration number: [3220/4518] 71% | Training loss: 0.6870365260735802
Epoch: 46 | Iteration number: [3230/4518] 71% | Training loss: 0.6870363546229737
Epoch: 46 | Iteration number: [3240/4518] 71% | Training loss: 0.6870341287718879
Epoch: 46 | Iteration number: [3250/4518] 71% | Training loss: 0.6870350758295792
Epoch: 46 | Iteration number: [3260/4518] 72% | Training loss: 0.6870367848251495
Epoch: 46 | Iteration number: [3270/4518] 72% | Training loss: 0.6870374084065813
Epoch: 46 | Iteration number: [3280/4518] 72% | Training loss: 0.6870380457763264
Epoch: 46 | Iteration number: [3290/4518] 72% | Training loss: 0.6870399625105699
Epoch: 46 | Iteration number: [3300/4518] 73% | Training loss: 0.6870394071846297
Epoch: 46 | Iteration number: [3310/4518] 73% | Training loss: 0.687040407419925
Epoch: 46 | Iteration number: [3320/4518] 73% | Training loss: 0.6870388818433486
Epoch: 46 | Iteration number: [3330/4518] 73% | Training loss: 0.6870431497648314
Epoch: 46 | Iteration number: [3340/4518] 73% | Training loss: 0.6870419627356672
Epoch: 46 | Iteration number: [3350/4518] 74% | Training loss: 0.6870372655854297
Epoch: 46 | Iteration number: [3360/4518] 74% | Training loss: 0.6870355923793146
Epoch: 46 | Iteration number: [3370/4518] 74% | Training loss: 0.6870380963168441
Epoch: 46 | Iteration number: [3380/4518] 74% | Training loss: 0.6870409384810713
Epoch: 46 | Iteration number: [3390/4518] 75% | Training loss: 0.6870388905207316
Epoch: 46 | Iteration number: [3400/4518] 75% | Training loss: 0.6870374974082498
Epoch: 46 | Iteration number: [3410/4518] 75% | Training loss: 0.6870380098519088
Epoch: 46 | Iteration number: [3420/4518] 75% | Training loss: 0.6870325144968534
Epoch: 46 | Iteration number: [3430/4518] 75% | Training loss: 0.6870320353667868
Epoch: 46 | Iteration number: [3440/4518] 76% | Training loss: 0.6870319666557534
Epoch: 46 | Iteration number: [3450/4518] 76% | Training loss: 0.6870319190750951
Epoch: 46 | Iteration number: [3460/4518] 76% | Training loss: 0.6870281762987203
Epoch: 46 | Iteration number: [3470/4518] 76% | Training loss: 0.6870271748355898
Epoch: 46 | Iteration number: [3480/4518] 77% | Training loss: 0.6870264341605121
Epoch: 46 | Iteration number: [3490/4518] 77% | Training loss: 0.6870263322035016
Epoch: 46 | Iteration number: [3500/4518] 77% | Training loss: 0.6870243738549097
Epoch: 46 | Iteration number: [3510/4518] 77% | Training loss: 0.6870284162695252
Epoch: 46 | Iteration number: [3520/4518] 77% | Training loss: 0.6870282507586208
Epoch: 46 | Iteration number: [3530/4518] 78% | Training loss: 0.6870263103385147
Epoch: 46 | Iteration number: [3540/4518] 78% | Training loss: 0.6870218427841273
Epoch: 46 | Iteration number: [3550/4518] 78% | Training loss: 0.6870181046573209
Epoch: 46 | Iteration number: [3560/4518] 78% | Training loss: 0.6870167951068181
Epoch: 46 | Iteration number: [3570/4518] 79% | Training loss: 0.687013133934566
Epoch: 46 | Iteration number: [3580/4518] 79% | Training loss: 0.68701417053212
Epoch: 46 | Iteration number: [3590/4518] 79% | Training loss: 0.6870130985892251
Epoch: 46 | Iteration number: [3600/4518] 79% | Training loss: 0.687012470761935
Epoch: 46 | Iteration number: [3610/4518] 79% | Training loss: 0.6870123290454252
Epoch: 46 | Iteration number: [3620/4518] 80% | Training loss: 0.6870095879827415
Epoch: 46 | Iteration number: [3630/4518] 80% | Training loss: 0.6870123489008134
Epoch: 46 | Iteration number: [3640/4518] 80% | Training loss: 0.6870119878715211
Epoch: 46 | Iteration number: [3650/4518] 80% | Training loss: 0.6870095559668867
Epoch: 46 | Iteration number: [3660/4518] 81% | Training loss: 0.6870114811782628
Epoch: 46 | Iteration number: [3670/4518] 81% | Training loss: 0.6870125786647485
Epoch: 46 | Iteration number: [3680/4518] 81% | Training loss: 0.6870075540536124
Epoch: 46 | Iteration number: [3690/4518] 81% | Training loss: 0.687008477727249
Epoch: 46 | Iteration number: [3700/4518] 81% | Training loss: 0.6870103404973005
Epoch: 46 | Iteration number: [3710/4518] 82% | Training loss: 0.6870084755825546
Epoch: 46 | Iteration number: [3720/4518] 82% | Training loss: 0.68700608082356
Epoch: 46 | Iteration number: [3730/4518] 82% | Training loss: 0.6870059081760233
Epoch: 46 | Iteration number: [3740/4518] 82% | Training loss: 0.6870091555590299
Epoch: 46 | Iteration number: [3750/4518] 83% | Training loss: 0.6870086439768474
Epoch: 46 | Iteration number: [3760/4518] 83% | Training loss: 0.6870062848513431
Epoch: 46 | Iteration number: [3770/4518] 83% | Training loss: 0.6870063957073961
Epoch: 46 | Iteration number: [3780/4518] 83% | Training loss: 0.687005887003172
Epoch: 46 | Iteration number: [3790/4518] 83% | Training loss: 0.6870043007239188
Epoch: 46 | Iteration number: [3800/4518] 84% | Training loss: 0.6870043270525179
Epoch: 46 | Iteration number: [3810/4518] 84% | Training loss: 0.6870062638299046
Epoch: 46 | Iteration number: [3820/4518] 84% | Training loss: 0.6870050954100974
Epoch: 46 | Iteration number: [3830/4518] 84% | Training loss: 0.6870039536965422
Epoch: 46 | Iteration number: [3840/4518] 84% | Training loss: 0.6870030162855982
Epoch: 46 | Iteration number: [3850/4518] 85% | Training loss: 0.6870022399394543
Epoch: 46 | Iteration number: [3860/4518] 85% | Training loss: 0.6869995815303042
Epoch: 46 | Iteration number: [3870/4518] 85% | Training loss: 0.687004051575057
Epoch: 46 | Iteration number: [3880/4518] 85% | Training loss: 0.6870027942909408
Epoch: 46 | Iteration number: [3890/4518] 86% | Training loss: 0.6870056387391372
Epoch: 46 | Iteration number: [3900/4518] 86% | Training loss: 0.6870083295840483
Epoch: 46 | Iteration number: [3910/4518] 86% | Training loss: 0.6870063166789082
Epoch: 46 | Iteration number: [3920/4518] 86% | Training loss: 0.6870064478595646
Epoch: 46 | Iteration number: [3930/4518] 86% | Training loss: 0.6870051997308513
Epoch: 46 | Iteration number: [3940/4518] 87% | Training loss: 0.6870020267170698
Epoch: 46 | Iteration number: [3950/4518] 87% | Training loss: 0.6870003836517092
Epoch: 46 | Iteration number: [3960/4518] 87% | Training loss: 0.687001158899129
Epoch: 46 | Iteration number: [3970/4518] 87% | Training loss: 0.6870001474315633
Epoch: 46 | Iteration number: [3980/4518] 88% | Training loss: 0.6870017573012779
Epoch: 46 | Iteration number: [3990/4518] 88% | Training loss: 0.6870014631359799
Epoch: 46 | Iteration number: [4000/4518] 88% | Training loss: 0.6870007028877735
Epoch: 46 | Iteration number: [4010/4518] 88% | Training loss: 0.6869989854885158
Epoch: 46 | Iteration number: [4020/4518] 88% | Training loss: 0.6870005260652571
Epoch: 46 | Iteration number: [4030/4518] 89% | Training loss: 0.6870001757854859
Epoch: 46 | Iteration number: [4040/4518] 89% | Training loss: 0.6870010257800027
Epoch: 46 | Iteration number: [4050/4518] 89% | Training loss: 0.6869962652818656
Epoch: 46 | Iteration number: [4060/4518] 89% | Training loss: 0.6869943549773964
Epoch: 46 | Iteration number: [4070/4518] 90% | Training loss: 0.6869947918509969
Epoch: 46 | Iteration number: [4080/4518] 90% | Training loss: 0.6869962736233777
Epoch: 46 | Iteration number: [4090/4518] 90% | Training loss: 0.6869988557324724
Epoch: 46 | Iteration number: [4100/4518] 90% | Training loss: 0.6869974740830863
Epoch: 46 | Iteration number: [4110/4518] 90% | Training loss: 0.6869989632980087
Epoch: 46 | Iteration number: [4120/4518] 91% | Training loss: 0.6869973261090159
Epoch: 46 | Iteration number: [4130/4518] 91% | Training loss: 0.6869991784522955
Epoch: 46 | Iteration number: [4140/4518] 91% | Training loss: 0.68699992529436
Epoch: 46 | Iteration number: [4150/4518] 91% | Training loss: 0.6869991391538137
Epoch: 46 | Iteration number: [4160/4518] 92% | Training loss: 0.6869976634016404
Epoch: 46 | Iteration number: [4170/4518] 92% | Training loss: 0.6869960753466013
Epoch: 46 | Iteration number: [4180/4518] 92% | Training loss: 0.6869969267308997
Epoch: 46 | Iteration number: [4190/4518] 92% | Training loss: 0.6869925400522273
Epoch: 46 | Iteration number: [4200/4518] 92% | Training loss: 0.686993185026305
Epoch: 46 | Iteration number: [4210/4518] 93% | Training loss: 0.6869938821945507
Epoch: 46 | Iteration number: [4220/4518] 93% | Training loss: 0.6869946368073965
Epoch: 46 | Iteration number: [4230/4518] 93% | Training loss: 0.6869934536604735
Epoch: 46 | Iteration number: [4240/4518] 93% | Training loss: 0.6869896304916661
Epoch: 46 | Iteration number: [4250/4518] 94% | Training loss: 0.6869894791350645
Epoch: 46 | Iteration number: [4260/4518] 94% | Training loss: 0.6869910962005177
Epoch: 46 | Iteration number: [4270/4518] 94% | Training loss: 0.6869899153011465
Epoch: 46 | Iteration number: [4280/4518] 94% | Training loss: 0.6869855215059263
Epoch: 46 | Iteration number: [4290/4518] 94% | Training loss: 0.6869859381155534
Epoch: 46 | Iteration number: [4300/4518] 95% | Training loss: 0.6869864742700443
Epoch: 46 | Iteration number: [4310/4518] 95% | Training loss: 0.6869865730439427
Epoch: 46 | Iteration number: [4320/4518] 95% | Training loss: 0.6869846168767523
Epoch: 46 | Iteration number: [4330/4518] 95% | Training loss: 0.6869851690241702
Epoch: 46 | Iteration number: [4340/4518] 96% | Training loss: 0.6869814206652927
Epoch: 46 | Iteration number: [4350/4518] 96% | Training loss: 0.6869812750268256
Epoch: 46 | Iteration number: [4360/4518] 96% | Training loss: 0.6869810812790459
Epoch: 46 | Iteration number: [4370/4518] 96% | Training loss: 0.6869819157047184
Epoch: 46 | Iteration number: [4380/4518] 96% | Training loss: 0.6869772562153263
Epoch: 46 | Iteration number: [4390/4518] 97% | Training loss: 0.6869783339576461
Epoch: 46 | Iteration number: [4400/4518] 97% | Training loss: 0.6869769758663394
Epoch: 46 | Iteration number: [4410/4518] 97% | Training loss: 0.6869764786728926
Epoch: 46 | Iteration number: [4420/4518] 97% | Training loss: 0.6869784111890318
Epoch: 46 | Iteration number: [4430/4518] 98% | Training loss: 0.6869787055536533
Epoch: 46 | Iteration number: [4440/4518] 98% | Training loss: 0.6869764747517603
Epoch: 46 | Iteration number: [4450/4518] 98% | Training loss: 0.6869734975059381
Epoch: 46 | Iteration number: [4460/4518] 98% | Training loss: 0.6869740235030384
Epoch: 46 | Iteration number: [4470/4518] 98% | Training loss: 0.6869744099893292
Epoch: 46 | Iteration number: [4480/4518] 99% | Training loss: 0.6869750931992062
Epoch: 46 | Iteration number: [4490/4518] 99% | Training loss: 0.6869752411454717
Epoch: 46 | Iteration number: [4500/4518] 99% | Training loss: 0.6869766465028126
Epoch: 46 | Iteration number: [4510/4518] 99% | Training loss: 0.6869749286618836

 End of epoch: 46 | Train Loss: 0.6868242230521941 | Training Time: 642 

 End of epoch: 46 | Eval Loss: 0.6901637546870173 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/4518] 0% | Training loss: 0.7547695517539978
Epoch: 47 | Iteration number: [20/4518] 0% | Training loss: 0.7205393195152283
Epoch: 47 | Iteration number: [30/4518] 0% | Training loss: 0.7094400087992351
Epoch: 47 | Iteration number: [40/4518] 0% | Training loss: 0.703599713742733
Epoch: 47 | Iteration number: [50/4518] 1% | Training loss: 0.7003503215312957
Epoch: 47 | Iteration number: [60/4518] 1% | Training loss: 0.6981290797392528
Epoch: 47 | Iteration number: [70/4518] 1% | Training loss: 0.6962424090930394
Epoch: 47 | Iteration number: [80/4518] 1% | Training loss: 0.6950638093054294
Epoch: 47 | Iteration number: [90/4518] 1% | Training loss: 0.6941307246685028
Epoch: 47 | Iteration number: [100/4518] 2% | Training loss: 0.6935242354869843
Epoch: 47 | Iteration number: [110/4518] 2% | Training loss: 0.6927824480967089
Epoch: 47 | Iteration number: [120/4518] 2% | Training loss: 0.6923816164334615
Epoch: 47 | Iteration number: [130/4518] 2% | Training loss: 0.6919819176197052
Epoch: 47 | Iteration number: [140/4518] 3% | Training loss: 0.6916520936148507
Epoch: 47 | Iteration number: [150/4518] 3% | Training loss: 0.6912789920965831
Epoch: 47 | Iteration number: [160/4518] 3% | Training loss: 0.6909474410116673
Epoch: 47 | Iteration number: [170/4518] 3% | Training loss: 0.6905936213100657
Epoch: 47 | Iteration number: [180/4518] 3% | Training loss: 0.6903117209672928
Epoch: 47 | Iteration number: [190/4518] 4% | Training loss: 0.6901931913275468
Epoch: 47 | Iteration number: [200/4518] 4% | Training loss: 0.6900110375881195
Epoch: 47 | Iteration number: [210/4518] 4% | Training loss: 0.6898426285811833
Epoch: 47 | Iteration number: [220/4518] 4% | Training loss: 0.6897049242799932
Epoch: 47 | Iteration number: [230/4518] 5% | Training loss: 0.6895693766034168
Epoch: 47 | Iteration number: [240/4518] 5% | Training loss: 0.689449047545592
Epoch: 47 | Iteration number: [250/4518] 5% | Training loss: 0.6892938401699066
Epoch: 47 | Iteration number: [260/4518] 5% | Training loss: 0.6892038856561368
Epoch: 47 | Iteration number: [270/4518] 5% | Training loss: 0.6890807158417172
Epoch: 47 | Iteration number: [280/4518] 6% | Training loss: 0.6889702245593071
Epoch: 47 | Iteration number: [290/4518] 6% | Training loss: 0.6888443017828053
Epoch: 47 | Iteration number: [300/4518] 6% | Training loss: 0.6888202226161957
Epoch: 47 | Iteration number: [310/4518] 6% | Training loss: 0.6887740792766694
Epoch: 47 | Iteration number: [320/4518] 7% | Training loss: 0.6887035513296723
Epoch: 47 | Iteration number: [330/4518] 7% | Training loss: 0.6886688115018786
Epoch: 47 | Iteration number: [340/4518] 7% | Training loss: 0.6886297941207886
Epoch: 47 | Iteration number: [350/4518] 7% | Training loss: 0.6885547622612544
Epoch: 47 | Iteration number: [360/4518] 7% | Training loss: 0.6884528633621004
Epoch: 47 | Iteration number: [370/4518] 8% | Training loss: 0.6883865799452807
Epoch: 47 | Iteration number: [380/4518] 8% | Training loss: 0.6883344283229427
Epoch: 47 | Iteration number: [390/4518] 8% | Training loss: 0.6883231103420258
Epoch: 47 | Iteration number: [400/4518] 8% | Training loss: 0.6882875688374043
Epoch: 47 | Iteration number: [410/4518] 9% | Training loss: 0.688251382112503
Epoch: 47 | Iteration number: [420/4518] 9% | Training loss: 0.6882428223178501
Epoch: 47 | Iteration number: [430/4518] 9% | Training loss: 0.6882356706053712
Epoch: 47 | Iteration number: [440/4518] 9% | Training loss: 0.6882042972878977
Epoch: 47 | Iteration number: [450/4518] 9% | Training loss: 0.6881694479783376
Epoch: 47 | Iteration number: [460/4518] 10% | Training loss: 0.6881404471138249
Epoch: 47 | Iteration number: [470/4518] 10% | Training loss: 0.6881201457470021
Epoch: 47 | Iteration number: [480/4518] 10% | Training loss: 0.6880786380420129
Epoch: 47 | Iteration number: [490/4518] 10% | Training loss: 0.6880431446493889
Epoch: 47 | Iteration number: [500/4518] 11% | Training loss: 0.6879996831417083
Epoch: 47 | Iteration number: [510/4518] 11% | Training loss: 0.6879856826043597
Epoch: 47 | Iteration number: [520/4518] 11% | Training loss: 0.687979129071419
Epoch: 47 | Iteration number: [530/4518] 11% | Training loss: 0.6879539281692145
Epoch: 47 | Iteration number: [540/4518] 11% | Training loss: 0.6879385938247045
Epoch: 47 | Iteration number: [550/4518] 12% | Training loss: 0.6879382468353619
Epoch: 47 | Iteration number: [560/4518] 12% | Training loss: 0.687905167894704
Epoch: 47 | Iteration number: [570/4518] 12% | Training loss: 0.6878966213318339
Epoch: 47 | Iteration number: [580/4518] 12% | Training loss: 0.6878994548115237
Epoch: 47 | Iteration number: [590/4518] 13% | Training loss: 0.6878753373178385
Epoch: 47 | Iteration number: [600/4518] 13% | Training loss: 0.6878647407889367
Epoch: 47 | Iteration number: [610/4518] 13% | Training loss: 0.6878429654191752
Epoch: 47 | Iteration number: [620/4518] 13% | Training loss: 0.6878311273551756
Epoch: 47 | Iteration number: [630/4518] 13% | Training loss: 0.6878146804514386
Epoch: 47 | Iteration number: [640/4518] 14% | Training loss: 0.6877792658284306
Epoch: 47 | Iteration number: [650/4518] 14% | Training loss: 0.6877470732652224
Epoch: 47 | Iteration number: [660/4518] 14% | Training loss: 0.6877368485385721
Epoch: 47 | Iteration number: [670/4518] 14% | Training loss: 0.6877258736695816
Epoch: 47 | Iteration number: [680/4518] 15% | Training loss: 0.6877110790680436
Epoch: 47 | Iteration number: [690/4518] 15% | Training loss: 0.6877063584500465
Epoch: 47 | Iteration number: [700/4518] 15% | Training loss: 0.6876928842067719
Epoch: 47 | Iteration number: [710/4518] 15% | Training loss: 0.6876909053661454
Epoch: 47 | Iteration number: [720/4518] 15% | Training loss: 0.6876939722233348
Epoch: 47 | Iteration number: [730/4518] 16% | Training loss: 0.6876801455674106
Epoch: 47 | Iteration number: [740/4518] 16% | Training loss: 0.6876759127990619
Epoch: 47 | Iteration number: [750/4518] 16% | Training loss: 0.6876732045809428
Epoch: 47 | Iteration number: [760/4518] 16% | Training loss: 0.6876813681502091
Epoch: 47 | Iteration number: [770/4518] 17% | Training loss: 0.6876739011182413
Epoch: 47 | Iteration number: [780/4518] 17% | Training loss: 0.6876712373433969
Epoch: 47 | Iteration number: [790/4518] 17% | Training loss: 0.6876658469061309
Epoch: 47 | Iteration number: [800/4518] 17% | Training loss: 0.6876473555713892
Epoch: 47 | Iteration number: [810/4518] 17% | Training loss: 0.6876317459859965
Epoch: 47 | Iteration number: [820/4518] 18% | Training loss: 0.687607225557653
Epoch: 47 | Iteration number: [830/4518] 18% | Training loss: 0.6875966282494097
Epoch: 47 | Iteration number: [840/4518] 18% | Training loss: 0.6875637380849747
Epoch: 47 | Iteration number: [850/4518] 18% | Training loss: 0.6875590551600737
Epoch: 47 | Iteration number: [860/4518] 19% | Training loss: 0.6875660212927086
Epoch: 47 | Iteration number: [870/4518] 19% | Training loss: 0.6875586872813345
Epoch: 47 | Iteration number: [880/4518] 19% | Training loss: 0.6875470290129835
Epoch: 47 | Iteration number: [890/4518] 19% | Training loss: 0.6875362719712632
Epoch: 47 | Iteration number: [900/4518] 19% | Training loss: 0.6875263046556049
Epoch: 47 | Iteration number: [910/4518] 20% | Training loss: 0.6875229263698662
Epoch: 47 | Iteration number: [920/4518] 20% | Training loss: 0.6875196862479914
Epoch: 47 | Iteration number: [930/4518] 20% | Training loss: 0.687493508861911
Epoch: 47 | Iteration number: [940/4518] 20% | Training loss: 0.6874865703126217
Epoch: 47 | Iteration number: [950/4518] 21% | Training loss: 0.6874818723452719
Epoch: 47 | Iteration number: [960/4518] 21% | Training loss: 0.6874785929918289
Epoch: 47 | Iteration number: [970/4518] 21% | Training loss: 0.687461522743874
Epoch: 47 | Iteration number: [980/4518] 21% | Training loss: 0.6874716644384423
Epoch: 47 | Iteration number: [990/4518] 21% | Training loss: 0.6874624548536359
Epoch: 47 | Iteration number: [1000/4518] 22% | Training loss: 0.6874554224014282
Epoch: 47 | Iteration number: [1010/4518] 22% | Training loss: 0.687458348628318
Epoch: 47 | Iteration number: [1020/4518] 22% | Training loss: 0.6874475910383112
Epoch: 47 | Iteration number: [1030/4518] 22% | Training loss: 0.6874557758419259
Epoch: 47 | Iteration number: [1040/4518] 23% | Training loss: 0.6874518671861062
Epoch: 47 | Iteration number: [1050/4518] 23% | Training loss: 0.6874460963408152
Epoch: 47 | Iteration number: [1060/4518] 23% | Training loss: 0.6874555320672269
Epoch: 47 | Iteration number: [1070/4518] 23% | Training loss: 0.6874548746046619
Epoch: 47 | Iteration number: [1080/4518] 23% | Training loss: 0.6874562979848297
Epoch: 47 | Iteration number: [1090/4518] 24% | Training loss: 0.6874530654981595
Epoch: 47 | Iteration number: [1100/4518] 24% | Training loss: 0.6874370819330216
Epoch: 47 | Iteration number: [1110/4518] 24% | Training loss: 0.6874324585403409
Epoch: 47 | Iteration number: [1120/4518] 24% | Training loss: 0.6874267764921699
Epoch: 47 | Iteration number: [1130/4518] 25% | Training loss: 0.6874219445528182
Epoch: 47 | Iteration number: [1140/4518] 25% | Training loss: 0.6874357284683931
Epoch: 47 | Iteration number: [1150/4518] 25% | Training loss: 0.6874301864271578
Epoch: 47 | Iteration number: [1160/4518] 25% | Training loss: 0.6874154385307739
Epoch: 47 | Iteration number: [1170/4518] 25% | Training loss: 0.6874171539249583
Epoch: 47 | Iteration number: [1180/4518] 26% | Training loss: 0.6873957782478656
Epoch: 47 | Iteration number: [1190/4518] 26% | Training loss: 0.6873898691489917
Epoch: 47 | Iteration number: [1200/4518] 26% | Training loss: 0.6873757631083329
Epoch: 47 | Iteration number: [1210/4518] 26% | Training loss: 0.6873858047910958
Epoch: 47 | Iteration number: [1220/4518] 27% | Training loss: 0.6873884320747657
Epoch: 47 | Iteration number: [1230/4518] 27% | Training loss: 0.6873775984698195
Epoch: 47 | Iteration number: [1240/4518] 27% | Training loss: 0.687379567277047
Epoch: 47 | Iteration number: [1250/4518] 27% | Training loss: 0.6873771406173707
Epoch: 47 | Iteration number: [1260/4518] 27% | Training loss: 0.6873737870227723
Epoch: 47 | Iteration number: [1270/4518] 28% | Training loss: 0.6873637633999502
Epoch: 47 | Iteration number: [1280/4518] 28% | Training loss: 0.6873736987821758
Epoch: 47 | Iteration number: [1290/4518] 28% | Training loss: 0.6873668422994688
Epoch: 47 | Iteration number: [1300/4518] 28% | Training loss: 0.6873629944141094
Epoch: 47 | Iteration number: [1310/4518] 28% | Training loss: 0.6873470724083995
Epoch: 47 | Iteration number: [1320/4518] 29% | Training loss: 0.6873472795341954
Epoch: 47 | Iteration number: [1330/4518] 29% | Training loss: 0.6873460224248413
Epoch: 47 | Iteration number: [1340/4518] 29% | Training loss: 0.6873536812725352
Epoch: 47 | Iteration number: [1350/4518] 29% | Training loss: 0.6873452551276595
Epoch: 47 | Iteration number: [1360/4518] 30% | Training loss: 0.6873353269170313
Epoch: 47 | Iteration number: [1370/4518] 30% | Training loss: 0.6873391463373699
Epoch: 47 | Iteration number: [1380/4518] 30% | Training loss: 0.6873433399891508
Epoch: 47 | Iteration number: [1390/4518] 30% | Training loss: 0.6873503488602398
Epoch: 47 | Iteration number: [1400/4518] 30% | Training loss: 0.6873540206466402
Epoch: 47 | Iteration number: [1410/4518] 31% | Training loss: 0.6873535231918307
Epoch: 47 | Iteration number: [1420/4518] 31% | Training loss: 0.6873517428905191
Epoch: 47 | Iteration number: [1430/4518] 31% | Training loss: 0.6873495097343738
Epoch: 47 | Iteration number: [1440/4518] 31% | Training loss: 0.6873463115758366
Epoch: 47 | Iteration number: [1450/4518] 32% | Training loss: 0.687335716157124
Epoch: 47 | Iteration number: [1460/4518] 32% | Training loss: 0.6873361292358947
Epoch: 47 | Iteration number: [1470/4518] 32% | Training loss: 0.687343087569386
Epoch: 47 | Iteration number: [1480/4518] 32% | Training loss: 0.6873227104544639
Epoch: 47 | Iteration number: [1490/4518] 32% | Training loss: 0.6873139325004296
Epoch: 47 | Iteration number: [1500/4518] 33% | Training loss: 0.6873111408551534
Epoch: 47 | Iteration number: [1510/4518] 33% | Training loss: 0.687305370663965
Epoch: 47 | Iteration number: [1520/4518] 33% | Training loss: 0.6872971899023181
Epoch: 47 | Iteration number: [1530/4518] 33% | Training loss: 0.6872988287919487
Epoch: 47 | Iteration number: [1540/4518] 34% | Training loss: 0.6873004975256982
Epoch: 47 | Iteration number: [1550/4518] 34% | Training loss: 0.687294904839608
Epoch: 47 | Iteration number: [1560/4518] 34% | Training loss: 0.6872923431870265
Epoch: 47 | Iteration number: [1570/4518] 34% | Training loss: 0.6872890631484377
Epoch: 47 | Iteration number: [1580/4518] 34% | Training loss: 0.6872942278656778
Epoch: 47 | Iteration number: [1590/4518] 35% | Training loss: 0.6872812494916736
Epoch: 47 | Iteration number: [1600/4518] 35% | Training loss: 0.6872822262719274
Epoch: 47 | Iteration number: [1610/4518] 35% | Training loss: 0.6872778209099858
Epoch: 47 | Iteration number: [1620/4518] 35% | Training loss: 0.6872727053032981
Epoch: 47 | Iteration number: [1630/4518] 36% | Training loss: 0.6872717755703839
Epoch: 47 | Iteration number: [1640/4518] 36% | Training loss: 0.6872728144250265
Epoch: 47 | Iteration number: [1650/4518] 36% | Training loss: 0.6872676722208659
Epoch: 47 | Iteration number: [1660/4518] 36% | Training loss: 0.6872704373425748
Epoch: 47 | Iteration number: [1670/4518] 36% | Training loss: 0.6872675535207737
Epoch: 47 | Iteration number: [1680/4518] 37% | Training loss: 0.6872625775990032
Epoch: 47 | Iteration number: [1690/4518] 37% | Training loss: 0.6872615126815773
Epoch: 47 | Iteration number: [1700/4518] 37% | Training loss: 0.6872593786435969
Epoch: 47 | Iteration number: [1710/4518] 37% | Training loss: 0.6872512585238406
Epoch: 47 | Iteration number: [1720/4518] 38% | Training loss: 0.6872463105376376
Epoch: 47 | Iteration number: [1730/4518] 38% | Training loss: 0.6872440886635311
Epoch: 47 | Iteration number: [1740/4518] 38% | Training loss: 0.6872398613855757
Epoch: 47 | Iteration number: [1750/4518] 38% | Training loss: 0.687236864396504
Epoch: 47 | Iteration number: [1760/4518] 38% | Training loss: 0.6872367370535027
Epoch: 47 | Iteration number: [1770/4518] 39% | Training loss: 0.6872349675765819
Epoch: 47 | Iteration number: [1780/4518] 39% | Training loss: 0.6872312029426018
Epoch: 47 | Iteration number: [1790/4518] 39% | Training loss: 0.6872235994099238
Epoch: 47 | Iteration number: [1800/4518] 39% | Training loss: 0.6872180948985948
Epoch: 47 | Iteration number: [1810/4518] 40% | Training loss: 0.687217288419028
Epoch: 47 | Iteration number: [1820/4518] 40% | Training loss: 0.6872148073636568
Epoch: 47 | Iteration number: [1830/4518] 40% | Training loss: 0.687205797270999
Epoch: 47 | Iteration number: [1840/4518] 40% | Training loss: 0.6872054584000422
Epoch: 47 | Iteration number: [1850/4518] 40% | Training loss: 0.6872036708690025
Epoch: 47 | Iteration number: [1860/4518] 41% | Training loss: 0.6872022359281458
Epoch: 47 | Iteration number: [1870/4518] 41% | Training loss: 0.6871946368625458
Epoch: 47 | Iteration number: [1880/4518] 41% | Training loss: 0.687191234719246
Epoch: 47 | Iteration number: [1890/4518] 41% | Training loss: 0.6871900530088515
Epoch: 47 | Iteration number: [1900/4518] 42% | Training loss: 0.6871879257653889
Epoch: 47 | Iteration number: [1910/4518] 42% | Training loss: 0.6871833252033014
Epoch: 47 | Iteration number: [1920/4518] 42% | Training loss: 0.6871801957177619
Epoch: 47 | Iteration number: [1930/4518] 42% | Training loss: 0.6871848019602386
Epoch: 47 | Iteration number: [1940/4518] 42% | Training loss: 0.6871838746918846
Epoch: 47 | Iteration number: [1950/4518] 43% | Training loss: 0.6871874901881585
Epoch: 47 | Iteration number: [1960/4518] 43% | Training loss: 0.6871815082065913
Epoch: 47 | Iteration number: [1970/4518] 43% | Training loss: 0.6871788345012568
Epoch: 47 | Iteration number: [1980/4518] 43% | Training loss: 0.687175550725725
Epoch: 47 | Iteration number: [1990/4518] 44% | Training loss: 0.687175432821015
Epoch: 47 | Iteration number: [2000/4518] 44% | Training loss: 0.6871707787513733
Epoch: 47 | Iteration number: [2010/4518] 44% | Training loss: 0.6871685881816333
Epoch: 47 | Iteration number: [2020/4518] 44% | Training loss: 0.687165985160535
Epoch: 47 | Iteration number: [2030/4518] 44% | Training loss: 0.6871687422832244
Epoch: 47 | Iteration number: [2040/4518] 45% | Training loss: 0.6871640993099587
Epoch: 47 | Iteration number: [2050/4518] 45% | Training loss: 0.6871595714150406
Epoch: 47 | Iteration number: [2060/4518] 45% | Training loss: 0.6871591899869511
Epoch: 47 | Iteration number: [2070/4518] 45% | Training loss: 0.6871589223543803
Epoch: 47 | Iteration number: [2080/4518] 46% | Training loss: 0.6871566139161587
Epoch: 47 | Iteration number: [2090/4518] 46% | Training loss: 0.687156982313503
Epoch: 47 | Iteration number: [2100/4518] 46% | Training loss: 0.6871566404047467
Epoch: 47 | Iteration number: [2110/4518] 46% | Training loss: 0.6871541335119455
Epoch: 47 | Iteration number: [2120/4518] 46% | Training loss: 0.6871469055144293
Epoch: 47 | Iteration number: [2130/4518] 47% | Training loss: 0.6871490888472455
Epoch: 47 | Iteration number: [2140/4518] 47% | Training loss: 0.687145388683426
Epoch: 47 | Iteration number: [2150/4518] 47% | Training loss: 0.687139705918556
Epoch: 47 | Iteration number: [2160/4518] 47% | Training loss: 0.6871351133894037
Epoch: 47 | Iteration number: [2170/4518] 48% | Training loss: 0.6871367496004852
Epoch: 47 | Iteration number: [2180/4518] 48% | Training loss: 0.6871394341145086
Epoch: 47 | Iteration number: [2190/4518] 48% | Training loss: 0.6871337090180889
Epoch: 47 | Iteration number: [2200/4518] 48% | Training loss: 0.6871352688019926
Epoch: 47 | Iteration number: [2210/4518] 48% | Training loss: 0.6871310612734627
Epoch: 47 | Iteration number: [2220/4518] 49% | Training loss: 0.6871336762701069
Epoch: 47 | Iteration number: [2230/4518] 49% | Training loss: 0.6871282712493777
Epoch: 47 | Iteration number: [2240/4518] 49% | Training loss: 0.6871222016268543
Epoch: 47 | Iteration number: [2250/4518] 49% | Training loss: 0.6871265111234452
Epoch: 47 | Iteration number: [2260/4518] 50% | Training loss: 0.687130723141991
Epoch: 47 | Iteration number: [2270/4518] 50% | Training loss: 0.6871286412167654
Epoch: 47 | Iteration number: [2280/4518] 50% | Training loss: 0.6871216680919915
Epoch: 47 | Iteration number: [2290/4518] 50% | Training loss: 0.6871222644393621
Epoch: 47 | Iteration number: [2300/4518] 50% | Training loss: 0.6871262550354004
Epoch: 47 | Iteration number: [2310/4518] 51% | Training loss: 0.6871301558884707
Epoch: 47 | Iteration number: [2320/4518] 51% | Training loss: 0.6871250365057896
Epoch: 47 | Iteration number: [2330/4518] 51% | Training loss: 0.6871192307175484
Epoch: 47 | Iteration number: [2340/4518] 51% | Training loss: 0.6871205618493578
Epoch: 47 | Iteration number: [2350/4518] 52% | Training loss: 0.687115877714563
Epoch: 47 | Iteration number: [2360/4518] 52% | Training loss: 0.6871177661216865
Epoch: 47 | Iteration number: [2370/4518] 52% | Training loss: 0.6871181941233607
Epoch: 47 | Iteration number: [2380/4518] 52% | Training loss: 0.6871139506332012
Epoch: 47 | Iteration number: [2390/4518] 52% | Training loss: 0.6871153688829813
Epoch: 47 | Iteration number: [2400/4518] 53% | Training loss: 0.6871060420076053
Epoch: 47 | Iteration number: [2410/4518] 53% | Training loss: 0.6871041655293144
Epoch: 47 | Iteration number: [2420/4518] 53% | Training loss: 0.6871011940900944
Epoch: 47 | Iteration number: [2430/4518] 53% | Training loss: 0.6871018488220717
Epoch: 47 | Iteration number: [2440/4518] 54% | Training loss: 0.6871049137877636
Epoch: 47 | Iteration number: [2450/4518] 54% | Training loss: 0.6871015091818207
Epoch: 47 | Iteration number: [2460/4518] 54% | Training loss: 0.6870997329068378
Epoch: 47 | Iteration number: [2470/4518] 54% | Training loss: 0.6871016323325122
Epoch: 47 | Iteration number: [2480/4518] 54% | Training loss: 0.6871030184290101
Epoch: 47 | Iteration number: [2490/4518] 55% | Training loss: 0.6871031047828705
Epoch: 47 | Iteration number: [2500/4518] 55% | Training loss: 0.6871025372982025
Epoch: 47 | Iteration number: [2510/4518] 55% | Training loss: 0.6871037324348769
Epoch: 47 | Iteration number: [2520/4518] 55% | Training loss: 0.6871028210435595
Epoch: 47 | Iteration number: [2530/4518] 55% | Training loss: 0.687095973896886
Epoch: 47 | Iteration number: [2540/4518] 56% | Training loss: 0.6870975412721709
Epoch: 47 | Iteration number: [2550/4518] 56% | Training loss: 0.6870945543635125
Epoch: 47 | Iteration number: [2560/4518] 56% | Training loss: 0.6870931120822206
Epoch: 47 | Iteration number: [2570/4518] 56% | Training loss: 0.6870889436873945
Epoch: 47 | Iteration number: [2580/4518] 57% | Training loss: 0.6870927130067072
Epoch: 47 | Iteration number: [2590/4518] 57% | Training loss: 0.6870936060734237
Epoch: 47 | Iteration number: [2600/4518] 57% | Training loss: 0.6870918035048705
Epoch: 47 | Iteration number: [2610/4518] 57% | Training loss: 0.6870946371463981
Epoch: 47 | Iteration number: [2620/4518] 57% | Training loss: 0.6870997494413652
Epoch: 47 | Iteration number: [2630/4518] 58% | Training loss: 0.6870978408893251
Epoch: 47 | Iteration number: [2640/4518] 58% | Training loss: 0.6870957438241352
Epoch: 47 | Iteration number: [2650/4518] 58% | Training loss: 0.6870911386777769
Epoch: 47 | Iteration number: [2660/4518] 58% | Training loss: 0.6870837394904373
Epoch: 47 | Iteration number: [2670/4518] 59% | Training loss: 0.6870823326405514
Epoch: 47 | Iteration number: [2680/4518] 59% | Training loss: 0.6870835939227645
Epoch: 47 | Iteration number: [2690/4518] 59% | Training loss: 0.6870816694537947
Epoch: 47 | Iteration number: [2700/4518] 59% | Training loss: 0.6870772567722533
Epoch: 47 | Iteration number: [2710/4518] 59% | Training loss: 0.6870752459742486
Epoch: 47 | Iteration number: [2720/4518] 60% | Training loss: 0.6870722104302224
Epoch: 47 | Iteration number: [2730/4518] 60% | Training loss: 0.6870741324328677
Epoch: 47 | Iteration number: [2740/4518] 60% | Training loss: 0.6870758608744962
Epoch: 47 | Iteration number: [2750/4518] 60% | Training loss: 0.6870746518265117
Epoch: 47 | Iteration number: [2760/4518] 61% | Training loss: 0.6870752698701361
Epoch: 47 | Iteration number: [2770/4518] 61% | Training loss: 0.6870716373197439
Epoch: 47 | Iteration number: [2780/4518] 61% | Training loss: 0.6870713396252488
Epoch: 47 | Iteration number: [2790/4518] 61% | Training loss: 0.6870701561264667
Epoch: 47 | Iteration number: [2800/4518] 61% | Training loss: 0.6870731601757663
Epoch: 47 | Iteration number: [2810/4518] 62% | Training loss: 0.6870717324820278
Epoch: 47 | Iteration number: [2820/4518] 62% | Training loss: 0.6870702397738788
Epoch: 47 | Iteration number: [2830/4518] 62% | Training loss: 0.6870659263100304
Epoch: 47 | Iteration number: [2840/4518] 62% | Training loss: 0.687063129099322
Epoch: 47 | Iteration number: [2850/4518] 63% | Training loss: 0.6870561545773556
Epoch: 47 | Iteration number: [2860/4518] 63% | Training loss: 0.6870546951994195
Epoch: 47 | Iteration number: [2870/4518] 63% | Training loss: 0.6870545552167328
Epoch: 47 | Iteration number: [2880/4518] 63% | Training loss: 0.6870569203048944
Epoch: 47 | Iteration number: [2890/4518] 63% | Training loss: 0.6870547712467946
Epoch: 47 | Iteration number: [2900/4518] 64% | Training loss: 0.6870540547781977
Epoch: 47 | Iteration number: [2910/4518] 64% | Training loss: 0.6870530652221536
Epoch: 47 | Iteration number: [2920/4518] 64% | Training loss: 0.6870517722751996
Epoch: 47 | Iteration number: [2930/4518] 64% | Training loss: 0.6870526890502447
Epoch: 47 | Iteration number: [2940/4518] 65% | Training loss: 0.6870475460477427
Epoch: 47 | Iteration number: [2950/4518] 65% | Training loss: 0.6870451840101662
Epoch: 47 | Iteration number: [2960/4518] 65% | Training loss: 0.6870441582557317
Epoch: 47 | Iteration number: [2970/4518] 65% | Training loss: 0.6870442974848378
Epoch: 47 | Iteration number: [2980/4518] 65% | Training loss: 0.6870422150864697
Epoch: 47 | Iteration number: [2990/4518] 66% | Training loss: 0.6870373593724293
Epoch: 47 | Iteration number: [3000/4518] 66% | Training loss: 0.6870371945699056
Epoch: 47 | Iteration number: [3010/4518] 66% | Training loss: 0.6870356398959493
Epoch: 47 | Iteration number: [3020/4518] 66% | Training loss: 0.6870382218566162
Epoch: 47 | Iteration number: [3030/4518] 67% | Training loss: 0.6870351506341802
Epoch: 47 | Iteration number: [3040/4518] 67% | Training loss: 0.6870358101631465
Epoch: 47 | Iteration number: [3050/4518] 67% | Training loss: 0.6870307746871573
Epoch: 47 | Iteration number: [3060/4518] 67% | Training loss: 0.6870317425213608
Epoch: 47 | Iteration number: [3070/4518] 67% | Training loss: 0.6870298298834201
Epoch: 47 | Iteration number: [3080/4518] 68% | Training loss: 0.68702790700383
Epoch: 47 | Iteration number: [3090/4518] 68% | Training loss: 0.6870292419561677
Epoch: 47 | Iteration number: [3100/4518] 68% | Training loss: 0.6870260267872964
Epoch: 47 | Iteration number: [3110/4518] 68% | Training loss: 0.687023884192157
Epoch: 47 | Iteration number: [3120/4518] 69% | Training loss: 0.687023563320056
Epoch: 47 | Iteration number: [3130/4518] 69% | Training loss: 0.6870247511056284
Epoch: 47 | Iteration number: [3140/4518] 69% | Training loss: 0.6870189006920833
Epoch: 47 | Iteration number: [3150/4518] 69% | Training loss: 0.6870158697309948
Epoch: 47 | Iteration number: [3160/4518] 69% | Training loss: 0.6870130038714107
Epoch: 47 | Iteration number: [3170/4518] 70% | Training loss: 0.6870075093834934
Epoch: 47 | Iteration number: [3180/4518] 70% | Training loss: 0.6870056723273775
Epoch: 47 | Iteration number: [3190/4518] 70% | Training loss: 0.6870077238934914
Epoch: 47 | Iteration number: [3200/4518] 70% | Training loss: 0.6870095171406865
Epoch: 47 | Iteration number: [3210/4518] 71% | Training loss: 0.6870107473242691
Epoch: 47 | Iteration number: [3220/4518] 71% | Training loss: 0.6870116303796353
Epoch: 47 | Iteration number: [3230/4518] 71% | Training loss: 0.6870144616893201
Epoch: 47 | Iteration number: [3240/4518] 71% | Training loss: 0.6870150734796936
Epoch: 47 | Iteration number: [3250/4518] 71% | Training loss: 0.6870134270374592
Epoch: 47 | Iteration number: [3260/4518] 72% | Training loss: 0.6870120002265356
Epoch: 47 | Iteration number: [3270/4518] 72% | Training loss: 0.6870107265240556
Epoch: 47 | Iteration number: [3280/4518] 72% | Training loss: 0.6870101523653763
Epoch: 47 | Iteration number: [3290/4518] 72% | Training loss: 0.6870128163813095
Epoch: 47 | Iteration number: [3300/4518] 73% | Training loss: 0.6870115371725776
Epoch: 47 | Iteration number: [3310/4518] 73% | Training loss: 0.6870086521180375
Epoch: 47 | Iteration number: [3320/4518] 73% | Training loss: 0.6870080737823463
Epoch: 47 | Iteration number: [3330/4518] 73% | Training loss: 0.6870079927616292
Epoch: 47 | Iteration number: [3340/4518] 73% | Training loss: 0.6870081696146263
Epoch: 47 | Iteration number: [3350/4518] 74% | Training loss: 0.6870069008798741
Epoch: 47 | Iteration number: [3360/4518] 74% | Training loss: 0.6870081913613137
Epoch: 47 | Iteration number: [3370/4518] 74% | Training loss: 0.6870087145344086
Epoch: 47 | Iteration number: [3380/4518] 74% | Training loss: 0.6870064536671666
Epoch: 47 | Iteration number: [3390/4518] 75% | Training loss: 0.6870052944769901
Epoch: 47 | Iteration number: [3400/4518] 75% | Training loss: 0.6870061300081365
Epoch: 47 | Iteration number: [3410/4518] 75% | Training loss: 0.6870035413073654
Epoch: 47 | Iteration number: [3420/4518] 75% | Training loss: 0.6870038218839823
Epoch: 47 | Iteration number: [3430/4518] 75% | Training loss: 0.6870087791462334
Epoch: 47 | Iteration number: [3440/4518] 76% | Training loss: 0.6870072361688281
Epoch: 47 | Iteration number: [3450/4518] 76% | Training loss: 0.6870061719417572
Epoch: 47 | Iteration number: [3460/4518] 76% | Training loss: 0.6870072895047292
Epoch: 47 | Iteration number: [3470/4518] 76% | Training loss: 0.6870070916774981
Epoch: 47 | Iteration number: [3480/4518] 77% | Training loss: 0.6870083372654586
Epoch: 47 | Iteration number: [3490/4518] 77% | Training loss: 0.6870058158236452
Epoch: 47 | Iteration number: [3500/4518] 77% | Training loss: 0.6870029211044312
Epoch: 47 | Iteration number: [3510/4518] 77% | Training loss: 0.6870021628178762
Epoch: 47 | Iteration number: [3520/4518] 77% | Training loss: 0.6870032252743841
Epoch: 47 | Iteration number: [3530/4518] 78% | Training loss: 0.6870057336669468
Epoch: 47 | Iteration number: [3540/4518] 78% | Training loss: 0.6870064782557515
Epoch: 47 | Iteration number: [3550/4518] 78% | Training loss: 0.6870025635773027
Epoch: 47 | Iteration number: [3560/4518] 78% | Training loss: 0.6870017467422431
Epoch: 47 | Iteration number: [3570/4518] 79% | Training loss: 0.6870025649958966
Epoch: 47 | Iteration number: [3580/4518] 79% | Training loss: 0.6870020017943569
Epoch: 47 | Iteration number: [3590/4518] 79% | Training loss: 0.6870015568055814
Epoch: 47 | Iteration number: [3600/4518] 79% | Training loss: 0.6870061182479064
Epoch: 47 | Iteration number: [3610/4518] 79% | Training loss: 0.6870059052827946
Epoch: 47 | Iteration number: [3620/4518] 80% | Training loss: 0.6870080589260186
Epoch: 47 | Iteration number: [3630/4518] 80% | Training loss: 0.6870103654946834
Epoch: 47 | Iteration number: [3640/4518] 80% | Training loss: 0.6870104005048563
Epoch: 47 | Iteration number: [3650/4518] 80% | Training loss: 0.6870114523580629
Epoch: 47 | Iteration number: [3660/4518] 81% | Training loss: 0.6870134387348519
Epoch: 47 | Iteration number: [3670/4518] 81% | Training loss: 0.6870148280336031
Epoch: 47 | Iteration number: [3680/4518] 81% | Training loss: 0.6870129584942175
Epoch: 47 | Iteration number: [3690/4518] 81% | Training loss: 0.687010322208327
Epoch: 47 | Iteration number: [3700/4518] 81% | Training loss: 0.687007776031623
Epoch: 47 | Iteration number: [3710/4518] 82% | Training loss: 0.6870074481976964
Epoch: 47 | Iteration number: [3720/4518] 82% | Training loss: 0.6870061337146708
Epoch: 47 | Iteration number: [3730/4518] 82% | Training loss: 0.6870059534627695
Epoch: 47 | Iteration number: [3740/4518] 82% | Training loss: 0.6870034811968472
Epoch: 47 | Iteration number: [3750/4518] 83% | Training loss: 0.6870041839758555
Epoch: 47 | Iteration number: [3760/4518] 83% | Training loss: 0.6870048976324974
Epoch: 47 | Iteration number: [3770/4518] 83% | Training loss: 0.6870070490976228
Epoch: 47 | Iteration number: [3780/4518] 83% | Training loss: 0.6870084038329503
Epoch: 47 | Iteration number: [3790/4518] 83% | Training loss: 0.6870084984321393
Epoch: 47 | Iteration number: [3800/4518] 84% | Training loss: 0.6870088202545518
Epoch: 47 | Iteration number: [3810/4518] 84% | Training loss: 0.687004933394785
Epoch: 47 | Iteration number: [3820/4518] 84% | Training loss: 0.6870047575984326
Epoch: 47 | Iteration number: [3830/4518] 84% | Training loss: 0.6870058540420184
Epoch: 47 | Iteration number: [3840/4518] 84% | Training loss: 0.687006998155266
Epoch: 47 | Iteration number: [3850/4518] 85% | Training loss: 0.6870081248995545
Epoch: 47 | Iteration number: [3860/4518] 85% | Training loss: 0.6870033318205818
Epoch: 47 | Iteration number: [3870/4518] 85% | Training loss: 0.6870047512442566
Epoch: 47 | Iteration number: [3880/4518] 85% | Training loss: 0.6870043141172104
Epoch: 47 | Iteration number: [3890/4518] 86% | Training loss: 0.6870038534191396
Epoch: 47 | Iteration number: [3900/4518] 86% | Training loss: 0.6870065959905967
Epoch: 47 | Iteration number: [3910/4518] 86% | Training loss: 0.6870068498279738
Epoch: 47 | Iteration number: [3920/4518] 86% | Training loss: 0.6870070576515733
Epoch: 47 | Iteration number: [3930/4518] 86% | Training loss: 0.6870058870649216
Epoch: 47 | Iteration number: [3940/4518] 87% | Training loss: 0.6870015164317214
Epoch: 47 | Iteration number: [3950/4518] 87% | Training loss: 0.6870027207724656
Epoch: 47 | Iteration number: [3960/4518] 87% | Training loss: 0.6870035659333672
Epoch: 47 | Iteration number: [3970/4518] 87% | Training loss: 0.6870034992244441
Epoch: 47 | Iteration number: [3980/4518] 88% | Training loss: 0.686999235695331
Epoch: 47 | Iteration number: [3990/4518] 88% | Training loss: 0.686998288733021
Epoch: 47 | Iteration number: [4000/4518] 88% | Training loss: 0.6869945727437735
Epoch: 47 | Iteration number: [4010/4518] 88% | Training loss: 0.6869950022632048
Epoch: 47 | Iteration number: [4020/4518] 88% | Training loss: 0.686992571988509
Epoch: 47 | Iteration number: [4030/4518] 89% | Training loss: 0.6869899406770322
Epoch: 47 | Iteration number: [4040/4518] 89% | Training loss: 0.6869930629092869
Epoch: 47 | Iteration number: [4050/4518] 89% | Training loss: 0.6869932979124563
Epoch: 47 | Iteration number: [4060/4518] 89% | Training loss: 0.6869897300533473
Epoch: 47 | Iteration number: [4070/4518] 90% | Training loss: 0.6869911127652817
Epoch: 47 | Iteration number: [4080/4518] 90% | Training loss: 0.6869922729683857
Epoch: 47 | Iteration number: [4090/4518] 90% | Training loss: 0.6869910576961443
Epoch: 47 | Iteration number: [4100/4518] 90% | Training loss: 0.6869889185632148
Epoch: 47 | Iteration number: [4110/4518] 90% | Training loss: 0.6869912573020823
Epoch: 47 | Iteration number: [4120/4518] 91% | Training loss: 0.6869928754359773
Epoch: 47 | Iteration number: [4130/4518] 91% | Training loss: 0.6869929780682986
Epoch: 47 | Iteration number: [4140/4518] 91% | Training loss: 0.6869928149641424
Epoch: 47 | Iteration number: [4150/4518] 91% | Training loss: 0.686993406881769
Epoch: 47 | Iteration number: [4160/4518] 92% | Training loss: 0.6869931295943948
Epoch: 47 | Iteration number: [4170/4518] 92% | Training loss: 0.6869947557826694
Epoch: 47 | Iteration number: [4180/4518] 92% | Training loss: 0.6869922937388625
Epoch: 47 | Iteration number: [4190/4518] 92% | Training loss: 0.6869928255428278
Epoch: 47 | Iteration number: [4200/4518] 92% | Training loss: 0.6869902439202581
Epoch: 47 | Iteration number: [4210/4518] 93% | Training loss: 0.686991186280715
Epoch: 47 | Iteration number: [4220/4518] 93% | Training loss: 0.6869932981605213
Epoch: 47 | Iteration number: [4230/4518] 93% | Training loss: 0.6869918987965189
Epoch: 47 | Iteration number: [4240/4518] 93% | Training loss: 0.6869938246765227
Epoch: 47 | Iteration number: [4250/4518] 94% | Training loss: 0.6869913035701303
Epoch: 47 | Iteration number: [4260/4518] 94% | Training loss: 0.6869940286091236
Epoch: 47 | Iteration number: [4270/4518] 94% | Training loss: 0.6869954698817233
Epoch: 47 | Iteration number: [4280/4518] 94% | Training loss: 0.68699183328965
Epoch: 47 | Iteration number: [4290/4518] 94% | Training loss: 0.6869922382848246
Epoch: 47 | Iteration number: [4300/4518] 95% | Training loss: 0.6869918933995934
Epoch: 47 | Iteration number: [4310/4518] 95% | Training loss: 0.6869922741659833
Epoch: 47 | Iteration number: [4320/4518] 95% | Training loss: 0.6869882098502583
Epoch: 47 | Iteration number: [4330/4518] 95% | Training loss: 0.6869896793888568
Epoch: 47 | Iteration number: [4340/4518] 96% | Training loss: 0.6869867891485241
Epoch: 47 | Iteration number: [4350/4518] 96% | Training loss: 0.6869884216648409
Epoch: 47 | Iteration number: [4360/4518] 96% | Training loss: 0.6869855137456448
Epoch: 47 | Iteration number: [4370/4518] 96% | Training loss: 0.6869820384602797
Epoch: 47 | Iteration number: [4380/4518] 96% | Training loss: 0.6869819465701439
Epoch: 47 | Iteration number: [4390/4518] 97% | Training loss: 0.686983817462769
Epoch: 47 | Iteration number: [4400/4518] 97% | Training loss: 0.6869817133518783
Epoch: 47 | Iteration number: [4410/4518] 97% | Training loss: 0.6869776333675903
Epoch: 47 | Iteration number: [4420/4518] 97% | Training loss: 0.6869762201249869
Epoch: 47 | Iteration number: [4430/4518] 98% | Training loss: 0.6869759360097063
Epoch: 47 | Iteration number: [4440/4518] 98% | Training loss: 0.6869774648198136
Epoch: 47 | Iteration number: [4450/4518] 98% | Training loss: 0.686977529445391
Epoch: 47 | Iteration number: [4460/4518] 98% | Training loss: 0.6869772868707041
Epoch: 47 | Iteration number: [4470/4518] 98% | Training loss: 0.6869767728134556
Epoch: 47 | Iteration number: [4480/4518] 99% | Training loss: 0.6869804985954293
Epoch: 47 | Iteration number: [4490/4518] 99% | Training loss: 0.6869804309046348
Epoch: 47 | Iteration number: [4500/4518] 99% | Training loss: 0.6869818480412165
Epoch: 47 | Iteration number: [4510/4518] 99% | Training loss: 0.6869805500539073

 End of epoch: 47 | Train Loss: 0.6868256573499752 | Training Time: 642 

 End of epoch: 47 | Eval Loss: 0.6902099470702969 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/4518] 0% | Training loss: 0.7562512397766114
Epoch: 48 | Iteration number: [20/4518] 0% | Training loss: 0.7215717643499374
Epoch: 48 | Iteration number: [30/4518] 0% | Training loss: 0.7098910232385
Epoch: 48 | Iteration number: [40/4518] 0% | Training loss: 0.704411692917347
Epoch: 48 | Iteration number: [50/4518] 1% | Training loss: 0.7007258856296539
Epoch: 48 | Iteration number: [60/4518] 1% | Training loss: 0.6982920457919438
Epoch: 48 | Iteration number: [70/4518] 1% | Training loss: 0.6965075850486755
Epoch: 48 | Iteration number: [80/4518] 1% | Training loss: 0.6952088005840779
Epoch: 48 | Iteration number: [90/4518] 1% | Training loss: 0.694199569357766
Epoch: 48 | Iteration number: [100/4518] 2% | Training loss: 0.693496897816658
Epoch: 48 | Iteration number: [110/4518] 2% | Training loss: 0.6929194022308697
Epoch: 48 | Iteration number: [120/4518] 2% | Training loss: 0.6923898686965306
Epoch: 48 | Iteration number: [130/4518] 2% | Training loss: 0.6919050597227536
Epoch: 48 | Iteration number: [140/4518] 3% | Training loss: 0.6915277429989406
Epoch: 48 | Iteration number: [150/4518] 3% | Training loss: 0.6911638855934144
Epoch: 48 | Iteration number: [160/4518] 3% | Training loss: 0.6908788170665503
Epoch: 48 | Iteration number: [170/4518] 3% | Training loss: 0.6907226222402909
Epoch: 48 | Iteration number: [180/4518] 3% | Training loss: 0.690500274962849
Epoch: 48 | Iteration number: [190/4518] 4% | Training loss: 0.6903299748897552
Epoch: 48 | Iteration number: [200/4518] 4% | Training loss: 0.6901485124230384
Epoch: 48 | Iteration number: [210/4518] 4% | Training loss: 0.6899772451037453
Epoch: 48 | Iteration number: [220/4518] 4% | Training loss: 0.6897364158521999
Epoch: 48 | Iteration number: [230/4518] 5% | Training loss: 0.6895857971647511
Epoch: 48 | Iteration number: [240/4518] 5% | Training loss: 0.689557816584905
Epoch: 48 | Iteration number: [250/4518] 5% | Training loss: 0.6894601128101349
Epoch: 48 | Iteration number: [260/4518] 5% | Training loss: 0.6893279623526793
Epoch: 48 | Iteration number: [270/4518] 5% | Training loss: 0.6892410218715668
Epoch: 48 | Iteration number: [280/4518] 6% | Training loss: 0.6891682426844324
Epoch: 48 | Iteration number: [290/4518] 6% | Training loss: 0.6891509446604499
Epoch: 48 | Iteration number: [300/4518] 6% | Training loss: 0.6890853834152222
Epoch: 48 | Iteration number: [310/4518] 6% | Training loss: 0.6890122913545178
Epoch: 48 | Iteration number: [320/4518] 7% | Training loss: 0.6889504041522742
Epoch: 48 | Iteration number: [330/4518] 7% | Training loss: 0.6888821791518819
Epoch: 48 | Iteration number: [340/4518] 7% | Training loss: 0.6888044213547426
Epoch: 48 | Iteration number: [350/4518] 7% | Training loss: 0.6887028987067086
Epoch: 48 | Iteration number: [360/4518] 7% | Training loss: 0.688661496506797
Epoch: 48 | Iteration number: [370/4518] 8% | Training loss: 0.6886380967256185
Epoch: 48 | Iteration number: [380/4518] 8% | Training loss: 0.6885801834495444
Epoch: 48 | Iteration number: [390/4518] 8% | Training loss: 0.6885275318072392
Epoch: 48 | Iteration number: [400/4518] 8% | Training loss: 0.6884611058235168
Epoch: 48 | Iteration number: [410/4518] 9% | Training loss: 0.6884272869040327
Epoch: 48 | Iteration number: [420/4518] 9% | Training loss: 0.6883844466436477
Epoch: 48 | Iteration number: [430/4518] 9% | Training loss: 0.6883345834044523
Epoch: 48 | Iteration number: [440/4518] 9% | Training loss: 0.6882883105765689
Epoch: 48 | Iteration number: [450/4518] 9% | Training loss: 0.6882399328549703
Epoch: 48 | Iteration number: [460/4518] 10% | Training loss: 0.6882165639296822
Epoch: 48 | Iteration number: [470/4518] 10% | Training loss: 0.6881838948168653
Epoch: 48 | Iteration number: [480/4518] 10% | Training loss: 0.6881863288581371
Epoch: 48 | Iteration number: [490/4518] 10% | Training loss: 0.6881494837147849
Epoch: 48 | Iteration number: [500/4518] 11% | Training loss: 0.6881086837053298
Epoch: 48 | Iteration number: [510/4518] 11% | Training loss: 0.6880922226344838
Epoch: 48 | Iteration number: [520/4518] 11% | Training loss: 0.6880780733548678
Epoch: 48 | Iteration number: [530/4518] 11% | Training loss: 0.6880313564021633
Epoch: 48 | Iteration number: [540/4518] 11% | Training loss: 0.6880031521673555
Epoch: 48 | Iteration number: [550/4518] 12% | Training loss: 0.6879788654500788
Epoch: 48 | Iteration number: [560/4518] 12% | Training loss: 0.6879532502165863
Epoch: 48 | Iteration number: [570/4518] 12% | Training loss: 0.6879355972273308
Epoch: 48 | Iteration number: [580/4518] 12% | Training loss: 0.6879160223336055
Epoch: 48 | Iteration number: [590/4518] 13% | Training loss: 0.6878889628386093
Epoch: 48 | Iteration number: [600/4518] 13% | Training loss: 0.6878815813859304
Epoch: 48 | Iteration number: [610/4518] 13% | Training loss: 0.6878451709864569
Epoch: 48 | Iteration number: [620/4518] 13% | Training loss: 0.6878287904685544
Epoch: 48 | Iteration number: [630/4518] 13% | Training loss: 0.6878147202824789
Epoch: 48 | Iteration number: [640/4518] 14% | Training loss: 0.6877972443588078
Epoch: 48 | Iteration number: [650/4518] 14% | Training loss: 0.6877722126703996
Epoch: 48 | Iteration number: [660/4518] 14% | Training loss: 0.6877645432949067
Epoch: 48 | Iteration number: [670/4518] 14% | Training loss: 0.6877547193819018
Epoch: 48 | Iteration number: [680/4518] 15% | Training loss: 0.6877328676335952
Epoch: 48 | Iteration number: [690/4518] 15% | Training loss: 0.6877227937829667
Epoch: 48 | Iteration number: [700/4518] 15% | Training loss: 0.6877178174257278
Epoch: 48 | Iteration number: [710/4518] 15% | Training loss: 0.6876954674720764
Epoch: 48 | Iteration number: [720/4518] 15% | Training loss: 0.6876734872659047
Epoch: 48 | Iteration number: [730/4518] 16% | Training loss: 0.6876591530564713
Epoch: 48 | Iteration number: [740/4518] 16% | Training loss: 0.6876596083512178
Epoch: 48 | Iteration number: [750/4518] 16% | Training loss: 0.6876423844496409
Epoch: 48 | Iteration number: [760/4518] 16% | Training loss: 0.6876454881931606
Epoch: 48 | Iteration number: [770/4518] 17% | Training loss: 0.6876371562480926
Epoch: 48 | Iteration number: [780/4518] 17% | Training loss: 0.6876220912505419
Epoch: 48 | Iteration number: [790/4518] 17% | Training loss: 0.6876159904878351
Epoch: 48 | Iteration number: [800/4518] 17% | Training loss: 0.6875977550446987
Epoch: 48 | Iteration number: [810/4518] 17% | Training loss: 0.687594246275631
Epoch: 48 | Iteration number: [820/4518] 18% | Training loss: 0.6875982871869716
Epoch: 48 | Iteration number: [830/4518] 18% | Training loss: 0.687578717340906
Epoch: 48 | Iteration number: [840/4518] 18% | Training loss: 0.6875714200593176
Epoch: 48 | Iteration number: [850/4518] 18% | Training loss: 0.687572431494208
Epoch: 48 | Iteration number: [860/4518] 19% | Training loss: 0.6875607285388681
Epoch: 48 | Iteration number: [870/4518] 19% | Training loss: 0.6875671307931002
Epoch: 48 | Iteration number: [880/4518] 19% | Training loss: 0.6875578544356606
Epoch: 48 | Iteration number: [890/4518] 19% | Training loss: 0.6875500268480751
Epoch: 48 | Iteration number: [900/4518] 19% | Training loss: 0.687539879017406
Epoch: 48 | Iteration number: [910/4518] 20% | Training loss: 0.6875119712326553
Epoch: 48 | Iteration number: [920/4518] 20% | Training loss: 0.687505795126376
Epoch: 48 | Iteration number: [930/4518] 20% | Training loss: 0.6874942871191169
Epoch: 48 | Iteration number: [940/4518] 20% | Training loss: 0.6874784524136401
Epoch: 48 | Iteration number: [950/4518] 21% | Training loss: 0.6874843624391054
Epoch: 48 | Iteration number: [960/4518] 21% | Training loss: 0.6874714259679119
Epoch: 48 | Iteration number: [970/4518] 21% | Training loss: 0.6874566484357892
Epoch: 48 | Iteration number: [980/4518] 21% | Training loss: 0.6874316450892662
Epoch: 48 | Iteration number: [990/4518] 21% | Training loss: 0.6874281233609325
Epoch: 48 | Iteration number: [1000/4518] 22% | Training loss: 0.6874161935448646
Epoch: 48 | Iteration number: [1010/4518] 22% | Training loss: 0.6874287739838704
Epoch: 48 | Iteration number: [1020/4518] 22% | Training loss: 0.6874261573249218
Epoch: 48 | Iteration number: [1030/4518] 22% | Training loss: 0.6874252127212228
Epoch: 48 | Iteration number: [1040/4518] 23% | Training loss: 0.687425946444273
Epoch: 48 | Iteration number: [1050/4518] 23% | Training loss: 0.6874248519397917
Epoch: 48 | Iteration number: [1060/4518] 23% | Training loss: 0.687414572936184
Epoch: 48 | Iteration number: [1070/4518] 23% | Training loss: 0.6874015106218998
Epoch: 48 | Iteration number: [1080/4518] 23% | Training loss: 0.6873957175899434
Epoch: 48 | Iteration number: [1090/4518] 24% | Training loss: 0.6873789274911268
Epoch: 48 | Iteration number: [1100/4518] 24% | Training loss: 0.6873759573698044
Epoch: 48 | Iteration number: [1110/4518] 24% | Training loss: 0.6873654975010468
Epoch: 48 | Iteration number: [1120/4518] 24% | Training loss: 0.687363068227257
Epoch: 48 | Iteration number: [1130/4518] 25% | Training loss: 0.6873628038748175
Epoch: 48 | Iteration number: [1140/4518] 25% | Training loss: 0.6873500244136442
Epoch: 48 | Iteration number: [1150/4518] 25% | Training loss: 0.6873455570573392
Epoch: 48 | Iteration number: [1160/4518] 25% | Training loss: 0.6873386710882187
Epoch: 48 | Iteration number: [1170/4518] 25% | Training loss: 0.6873471008916187
Epoch: 48 | Iteration number: [1180/4518] 26% | Training loss: 0.6873462188041817
Epoch: 48 | Iteration number: [1190/4518] 26% | Training loss: 0.6873365889577304
Epoch: 48 | Iteration number: [1200/4518] 26% | Training loss: 0.6873471484084924
Epoch: 48 | Iteration number: [1210/4518] 26% | Training loss: 0.6873469646311988
Epoch: 48 | Iteration number: [1220/4518] 27% | Training loss: 0.6873403400671286
Epoch: 48 | Iteration number: [1230/4518] 27% | Training loss: 0.687334702121533
Epoch: 48 | Iteration number: [1240/4518] 27% | Training loss: 0.6873385578393936
Epoch: 48 | Iteration number: [1250/4518] 27% | Training loss: 0.6873352890968323
Epoch: 48 | Iteration number: [1260/4518] 27% | Training loss: 0.6873303754935189
Epoch: 48 | Iteration number: [1270/4518] 28% | Training loss: 0.6873376285466622
Epoch: 48 | Iteration number: [1280/4518] 28% | Training loss: 0.6873311286326498
Epoch: 48 | Iteration number: [1290/4518] 28% | Training loss: 0.6873361639736235
Epoch: 48 | Iteration number: [1300/4518] 28% | Training loss: 0.6873255534355457
Epoch: 48 | Iteration number: [1310/4518] 28% | Training loss: 0.6873243464768388
Epoch: 48 | Iteration number: [1320/4518] 29% | Training loss: 0.6873180215557416
Epoch: 48 | Iteration number: [1330/4518] 29% | Training loss: 0.6873190969452823
Epoch: 48 | Iteration number: [1340/4518] 29% | Training loss: 0.6873231801968902
Epoch: 48 | Iteration number: [1350/4518] 29% | Training loss: 0.6873212790930713
Epoch: 48 | Iteration number: [1360/4518] 30% | Training loss: 0.6873173738227171
Epoch: 48 | Iteration number: [1370/4518] 30% | Training loss: 0.68732099798474
Epoch: 48 | Iteration number: [1380/4518] 30% | Training loss: 0.6873192911562712
Epoch: 48 | Iteration number: [1390/4518] 30% | Training loss: 0.6873188717759771
Epoch: 48 | Iteration number: [1400/4518] 30% | Training loss: 0.687321994474956
Epoch: 48 | Iteration number: [1410/4518] 31% | Training loss: 0.6873156949983421
Epoch: 48 | Iteration number: [1420/4518] 31% | Training loss: 0.6873151092462136
Epoch: 48 | Iteration number: [1430/4518] 31% | Training loss: 0.6873021256673586
Epoch: 48 | Iteration number: [1440/4518] 31% | Training loss: 0.6872949557171928
Epoch: 48 | Iteration number: [1450/4518] 32% | Training loss: 0.6872915841382126
Epoch: 48 | Iteration number: [1460/4518] 32% | Training loss: 0.6872858917059964
Epoch: 48 | Iteration number: [1470/4518] 32% | Training loss: 0.6872804571171196
Epoch: 48 | Iteration number: [1480/4518] 32% | Training loss: 0.6872755065963075
Epoch: 48 | Iteration number: [1490/4518] 32% | Training loss: 0.6872636917053453
Epoch: 48 | Iteration number: [1500/4518] 33% | Training loss: 0.6872547413508098
Epoch: 48 | Iteration number: [1510/4518] 33% | Training loss: 0.6872490264327321
Epoch: 48 | Iteration number: [1520/4518] 33% | Training loss: 0.687250908503407
Epoch: 48 | Iteration number: [1530/4518] 33% | Training loss: 0.6872511205719967
Epoch: 48 | Iteration number: [1540/4518] 34% | Training loss: 0.6872450369519073
Epoch: 48 | Iteration number: [1550/4518] 34% | Training loss: 0.6872459101676941
Epoch: 48 | Iteration number: [1560/4518] 34% | Training loss: 0.6872435568999021
Epoch: 48 | Iteration number: [1570/4518] 34% | Training loss: 0.6872359479308887
Epoch: 48 | Iteration number: [1580/4518] 34% | Training loss: 0.6872376647553866
Epoch: 48 | Iteration number: [1590/4518] 35% | Training loss: 0.6872326405543201
Epoch: 48 | Iteration number: [1600/4518] 35% | Training loss: 0.6872345673665404
Epoch: 48 | Iteration number: [1610/4518] 35% | Training loss: 0.687230051193178
Epoch: 48 | Iteration number: [1620/4518] 35% | Training loss: 0.6872314176441711
Epoch: 48 | Iteration number: [1630/4518] 36% | Training loss: 0.6872339029619299
Epoch: 48 | Iteration number: [1640/4518] 36% | Training loss: 0.6872349322569079
Epoch: 48 | Iteration number: [1650/4518] 36% | Training loss: 0.6872296518629247
Epoch: 48 | Iteration number: [1660/4518] 36% | Training loss: 0.6872254931783102
Epoch: 48 | Iteration number: [1670/4518] 36% | Training loss: 0.6872251234725564
Epoch: 48 | Iteration number: [1680/4518] 37% | Training loss: 0.6872171043994881
Epoch: 48 | Iteration number: [1690/4518] 37% | Training loss: 0.6872098481514045
Epoch: 48 | Iteration number: [1700/4518] 37% | Training loss: 0.6872059713041081
Epoch: 48 | Iteration number: [1710/4518] 37% | Training loss: 0.6872094980457373
Epoch: 48 | Iteration number: [1720/4518] 38% | Training loss: 0.6872071691377218
Epoch: 48 | Iteration number: [1730/4518] 38% | Training loss: 0.6872098044163919
Epoch: 48 | Iteration number: [1740/4518] 38% | Training loss: 0.6872061395439608
Epoch: 48 | Iteration number: [1750/4518] 38% | Training loss: 0.6872059655530112
Epoch: 48 | Iteration number: [1760/4518] 38% | Training loss: 0.6872055117718198
Epoch: 48 | Iteration number: [1770/4518] 39% | Training loss: 0.6872034170533304
Epoch: 48 | Iteration number: [1780/4518] 39% | Training loss: 0.6871973592913553
Epoch: 48 | Iteration number: [1790/4518] 39% | Training loss: 0.6871978941243454
Epoch: 48 | Iteration number: [1800/4518] 39% | Training loss: 0.687196535302533
Epoch: 48 | Iteration number: [1810/4518] 40% | Training loss: 0.6871946992795112
Epoch: 48 | Iteration number: [1820/4518] 40% | Training loss: 0.6871869643638422
Epoch: 48 | Iteration number: [1830/4518] 40% | Training loss: 0.6871891038665354
Epoch: 48 | Iteration number: [1840/4518] 40% | Training loss: 0.6871879546862582
Epoch: 48 | Iteration number: [1850/4518] 40% | Training loss: 0.6871911127502853
Epoch: 48 | Iteration number: [1860/4518] 41% | Training loss: 0.6871870003720766
Epoch: 48 | Iteration number: [1870/4518] 41% | Training loss: 0.6871848119452676
Epoch: 48 | Iteration number: [1880/4518] 41% | Training loss: 0.6871846404481441
Epoch: 48 | Iteration number: [1890/4518] 41% | Training loss: 0.6871903154585096
Epoch: 48 | Iteration number: [1900/4518] 42% | Training loss: 0.6871822196245193
Epoch: 48 | Iteration number: [1910/4518] 42% | Training loss: 0.6871812806079525
Epoch: 48 | Iteration number: [1920/4518] 42% | Training loss: 0.6871825002444287
Epoch: 48 | Iteration number: [1930/4518] 42% | Training loss: 0.6871831557911294
Epoch: 48 | Iteration number: [1940/4518] 42% | Training loss: 0.6871803572190177
Epoch: 48 | Iteration number: [1950/4518] 43% | Training loss: 0.6871826541423798
Epoch: 48 | Iteration number: [1960/4518] 43% | Training loss: 0.6871844402381352
Epoch: 48 | Iteration number: [1970/4518] 43% | Training loss: 0.6871834979747152
Epoch: 48 | Iteration number: [1980/4518] 43% | Training loss: 0.6871729566593363
Epoch: 48 | Iteration number: [1990/4518] 44% | Training loss: 0.687162984136361
Epoch: 48 | Iteration number: [2000/4518] 44% | Training loss: 0.6871582488119602
Epoch: 48 | Iteration number: [2010/4518] 44% | Training loss: 0.687155979397285
Epoch: 48 | Iteration number: [2020/4518] 44% | Training loss: 0.687152370603958
Epoch: 48 | Iteration number: [2030/4518] 44% | Training loss: 0.6871560225639437
Epoch: 48 | Iteration number: [2040/4518] 45% | Training loss: 0.6871561595330051
Epoch: 48 | Iteration number: [2050/4518] 45% | Training loss: 0.6871522740910693
Epoch: 48 | Iteration number: [2060/4518] 45% | Training loss: 0.6871461963190616
Epoch: 48 | Iteration number: [2070/4518] 45% | Training loss: 0.6871407223208515
Epoch: 48 | Iteration number: [2080/4518] 46% | Training loss: 0.6871372879697726
Epoch: 48 | Iteration number: [2090/4518] 46% | Training loss: 0.687134443373201
Epoch: 48 | Iteration number: [2100/4518] 46% | Training loss: 0.6871352406626656
Epoch: 48 | Iteration number: [2110/4518] 46% | Training loss: 0.6871363430791556
Epoch: 48 | Iteration number: [2120/4518] 46% | Training loss: 0.6871316862275015
Epoch: 48 | Iteration number: [2130/4518] 47% | Training loss: 0.6871298685040272
Epoch: 48 | Iteration number: [2140/4518] 47% | Training loss: 0.6871282135493287
Epoch: 48 | Iteration number: [2150/4518] 47% | Training loss: 0.687129100561142
Epoch: 48 | Iteration number: [2160/4518] 47% | Training loss: 0.6871275958087709
Epoch: 48 | Iteration number: [2170/4518] 48% | Training loss: 0.6871259822274134
Epoch: 48 | Iteration number: [2180/4518] 48% | Training loss: 0.6871235089291127
Epoch: 48 | Iteration number: [2190/4518] 48% | Training loss: 0.687123046618074
Epoch: 48 | Iteration number: [2200/4518] 48% | Training loss: 0.687116693989797
Epoch: 48 | Iteration number: [2210/4518] 48% | Training loss: 0.687123506991572
Epoch: 48 | Iteration number: [2220/4518] 49% | Training loss: 0.6871237534391987
Epoch: 48 | Iteration number: [2230/4518] 49% | Training loss: 0.6871214358795918
Epoch: 48 | Iteration number: [2240/4518] 49% | Training loss: 0.68711780687528
Epoch: 48 | Iteration number: [2250/4518] 49% | Training loss: 0.6871198939747281
Epoch: 48 | Iteration number: [2260/4518] 50% | Training loss: 0.6871186793377969
Epoch: 48 | Iteration number: [2270/4518] 50% | Training loss: 0.6871124425648593
Epoch: 48 | Iteration number: [2280/4518] 50% | Training loss: 0.6871145103322832
Epoch: 48 | Iteration number: [2290/4518] 50% | Training loss: 0.6871112521298588
Epoch: 48 | Iteration number: [2300/4518] 50% | Training loss: 0.6871148285399312
Epoch: 48 | Iteration number: [2310/4518] 51% | Training loss: 0.687111741639835
Epoch: 48 | Iteration number: [2320/4518] 51% | Training loss: 0.6871115569924486
Epoch: 48 | Iteration number: [2330/4518] 51% | Training loss: 0.6871107926184528
Epoch: 48 | Iteration number: [2340/4518] 51% | Training loss: 0.6871112732296316
Epoch: 48 | Iteration number: [2350/4518] 52% | Training loss: 0.687110122949519
Epoch: 48 | Iteration number: [2360/4518] 52% | Training loss: 0.6871035622843241
Epoch: 48 | Iteration number: [2370/4518] 52% | Training loss: 0.6871030299472406
Epoch: 48 | Iteration number: [2380/4518] 52% | Training loss: 0.6871047831883952
Epoch: 48 | Iteration number: [2390/4518] 52% | Training loss: 0.687108054669831
Epoch: 48 | Iteration number: [2400/4518] 53% | Training loss: 0.6871058427542448
Epoch: 48 | Iteration number: [2410/4518] 53% | Training loss: 0.6871065193934065
Epoch: 48 | Iteration number: [2420/4518] 53% | Training loss: 0.6871008507722666
Epoch: 48 | Iteration number: [2430/4518] 53% | Training loss: 0.6871022737811132
Epoch: 48 | Iteration number: [2440/4518] 54% | Training loss: 0.6871027037989897
Epoch: 48 | Iteration number: [2450/4518] 54% | Training loss: 0.6871027300065877
Epoch: 48 | Iteration number: [2460/4518] 54% | Training loss: 0.6871020990900877
Epoch: 48 | Iteration number: [2470/4518] 54% | Training loss: 0.6870984861242626
Epoch: 48 | Iteration number: [2480/4518] 54% | Training loss: 0.6870967952714813
Epoch: 48 | Iteration number: [2490/4518] 55% | Training loss: 0.6870927515278858
Epoch: 48 | Iteration number: [2500/4518] 55% | Training loss: 0.6870911999702454
Epoch: 48 | Iteration number: [2510/4518] 55% | Training loss: 0.687090737672441
Epoch: 48 | Iteration number: [2520/4518] 55% | Training loss: 0.6870862364532455
Epoch: 48 | Iteration number: [2530/4518] 55% | Training loss: 0.6870871436925745
Epoch: 48 | Iteration number: [2540/4518] 56% | Training loss: 0.6870826881936216
Epoch: 48 | Iteration number: [2550/4518] 56% | Training loss: 0.6870816588869282
Epoch: 48 | Iteration number: [2560/4518] 56% | Training loss: 0.6870772461639717
Epoch: 48 | Iteration number: [2570/4518] 56% | Training loss: 0.6870801349094405
Epoch: 48 | Iteration number: [2580/4518] 57% | Training loss: 0.6870782934880072
Epoch: 48 | Iteration number: [2590/4518] 57% | Training loss: 0.6870786967424812
Epoch: 48 | Iteration number: [2600/4518] 57% | Training loss: 0.6870746371837763
Epoch: 48 | Iteration number: [2610/4518] 57% | Training loss: 0.6870697317223896
Epoch: 48 | Iteration number: [2620/4518] 57% | Training loss: 0.6870746592301449
Epoch: 48 | Iteration number: [2630/4518] 58% | Training loss: 0.6870690115957659
Epoch: 48 | Iteration number: [2640/4518] 58% | Training loss: 0.6870645460757342
Epoch: 48 | Iteration number: [2650/4518] 58% | Training loss: 0.6870643584908179
Epoch: 48 | Iteration number: [2660/4518] 58% | Training loss: 0.6870596675496352
Epoch: 48 | Iteration number: [2670/4518] 59% | Training loss: 0.6870533401153507
Epoch: 48 | Iteration number: [2680/4518] 59% | Training loss: 0.6870567462115146
Epoch: 48 | Iteration number: [2690/4518] 59% | Training loss: 0.687056118759524
Epoch: 48 | Iteration number: [2700/4518] 59% | Training loss: 0.6870590523437218
Epoch: 48 | Iteration number: [2710/4518] 59% | Training loss: 0.6870550835044622
Epoch: 48 | Iteration number: [2720/4518] 60% | Training loss: 0.6870541542987613
Epoch: 48 | Iteration number: [2730/4518] 60% | Training loss: 0.6870510349343548
Epoch: 48 | Iteration number: [2740/4518] 60% | Training loss: 0.6870501267213891
Epoch: 48 | Iteration number: [2750/4518] 60% | Training loss: 0.6870508469885046
Epoch: 48 | Iteration number: [2760/4518] 61% | Training loss: 0.6870553671665813
Epoch: 48 | Iteration number: [2770/4518] 61% | Training loss: 0.6870587178946402
Epoch: 48 | Iteration number: [2780/4518] 61% | Training loss: 0.6870599692673992
Epoch: 48 | Iteration number: [2790/4518] 61% | Training loss: 0.6870559077322697
Epoch: 48 | Iteration number: [2800/4518] 61% | Training loss: 0.6870518469171865
Epoch: 48 | Iteration number: [2810/4518] 62% | Training loss: 0.6870482273585432
Epoch: 48 | Iteration number: [2820/4518] 62% | Training loss: 0.6870459096651551
Epoch: 48 | Iteration number: [2830/4518] 62% | Training loss: 0.6870462024590994
Epoch: 48 | Iteration number: [2840/4518] 62% | Training loss: 0.6870472773489817
Epoch: 48 | Iteration number: [2850/4518] 63% | Training loss: 0.6870501688279603
Epoch: 48 | Iteration number: [2860/4518] 63% | Training loss: 0.6870487220637448
Epoch: 48 | Iteration number: [2870/4518] 63% | Training loss: 0.6870494003495273
Epoch: 48 | Iteration number: [2880/4518] 63% | Training loss: 0.687045375092162
Epoch: 48 | Iteration number: [2890/4518] 63% | Training loss: 0.6870488973224864
Epoch: 48 | Iteration number: [2900/4518] 64% | Training loss: 0.6870432599659624
Epoch: 48 | Iteration number: [2910/4518] 64% | Training loss: 0.6870407637656759
Epoch: 48 | Iteration number: [2920/4518] 64% | Training loss: 0.6870383860517855
Epoch: 48 | Iteration number: [2930/4518] 64% | Training loss: 0.687034355678656
Epoch: 48 | Iteration number: [2940/4518] 65% | Training loss: 0.6870354658284155
Epoch: 48 | Iteration number: [2950/4518] 65% | Training loss: 0.6870354276794498
Epoch: 48 | Iteration number: [2960/4518] 65% | Training loss: 0.6870366451506679
Epoch: 48 | Iteration number: [2970/4518] 65% | Training loss: 0.687039852142334
Epoch: 48 | Iteration number: [2980/4518] 65% | Training loss: 0.6870402812557732
Epoch: 48 | Iteration number: [2990/4518] 66% | Training loss: 0.6870391969098694
Epoch: 48 | Iteration number: [3000/4518] 66% | Training loss: 0.6870414477785428
Epoch: 48 | Iteration number: [3010/4518] 66% | Training loss: 0.6870418967400674
Epoch: 48 | Iteration number: [3020/4518] 66% | Training loss: 0.687042142065945
Epoch: 48 | Iteration number: [3030/4518] 67% | Training loss: 0.6870442776593438
Epoch: 48 | Iteration number: [3040/4518] 67% | Training loss: 0.6870416747308091
Epoch: 48 | Iteration number: [3050/4518] 67% | Training loss: 0.687038117412661
Epoch: 48 | Iteration number: [3060/4518] 67% | Training loss: 0.687032426163262
Epoch: 48 | Iteration number: [3070/4518] 67% | Training loss: 0.6870346850409181
Epoch: 48 | Iteration number: [3080/4518] 68% | Training loss: 0.6870346584103324
Epoch: 48 | Iteration number: [3090/4518] 68% | Training loss: 0.6870324587937697
Epoch: 48 | Iteration number: [3100/4518] 68% | Training loss: 0.6870283358327804
Epoch: 48 | Iteration number: [3110/4518] 68% | Training loss: 0.687031408866502
Epoch: 48 | Iteration number: [3120/4518] 69% | Training loss: 0.6870320466275398
Epoch: 48 | Iteration number: [3130/4518] 69% | Training loss: 0.6870338930870398
Epoch: 48 | Iteration number: [3140/4518] 69% | Training loss: 0.6870329042339022
Epoch: 48 | Iteration number: [3150/4518] 69% | Training loss: 0.6870317302052937
Epoch: 48 | Iteration number: [3160/4518] 69% | Training loss: 0.6870326205522199
Epoch: 48 | Iteration number: [3170/4518] 70% | Training loss: 0.6870324194243278
Epoch: 48 | Iteration number: [3180/4518] 70% | Training loss: 0.6870312554468898
Epoch: 48 | Iteration number: [3190/4518] 70% | Training loss: 0.6870307144513325
Epoch: 48 | Iteration number: [3200/4518] 70% | Training loss: 0.6870316382683813
Epoch: 48 | Iteration number: [3210/4518] 71% | Training loss: 0.6870311652574213
Epoch: 48 | Iteration number: [3220/4518] 71% | Training loss: 0.687031138165397
Epoch: 48 | Iteration number: [3230/4518] 71% | Training loss: 0.6870295989993187
Epoch: 48 | Iteration number: [3240/4518] 71% | Training loss: 0.6870337668576358
Epoch: 48 | Iteration number: [3250/4518] 71% | Training loss: 0.6870355159135966
Epoch: 48 | Iteration number: [3260/4518] 72% | Training loss: 0.687032690955086
Epoch: 48 | Iteration number: [3270/4518] 72% | Training loss: 0.6870290707010742
Epoch: 48 | Iteration number: [3280/4518] 72% | Training loss: 0.6870257675829458
Epoch: 48 | Iteration number: [3290/4518] 72% | Training loss: 0.6870224950704893
Epoch: 48 | Iteration number: [3300/4518] 73% | Training loss: 0.6870221770532203
Epoch: 48 | Iteration number: [3310/4518] 73% | Training loss: 0.6870216140934348
Epoch: 48 | Iteration number: [3320/4518] 73% | Training loss: 0.6870230011372681
Epoch: 48 | Iteration number: [3330/4518] 73% | Training loss: 0.6870206772923112
Epoch: 48 | Iteration number: [3340/4518] 73% | Training loss: 0.6870188424687186
Epoch: 48 | Iteration number: [3350/4518] 74% | Training loss: 0.6870188220223384
Epoch: 48 | Iteration number: [3360/4518] 74% | Training loss: 0.6870209504273675
Epoch: 48 | Iteration number: [3370/4518] 74% | Training loss: 0.6870182792758376
Epoch: 48 | Iteration number: [3380/4518] 74% | Training loss: 0.687016461481004
Epoch: 48 | Iteration number: [3390/4518] 75% | Training loss: 0.6870193556522549
Epoch: 48 | Iteration number: [3400/4518] 75% | Training loss: 0.6870200054961092
Epoch: 48 | Iteration number: [3410/4518] 75% | Training loss: 0.6870206779398876
Epoch: 48 | Iteration number: [3420/4518] 75% | Training loss: 0.6870220306672548
Epoch: 48 | Iteration number: [3430/4518] 75% | Training loss: 0.6870241522789001
Epoch: 48 | Iteration number: [3440/4518] 76% | Training loss: 0.6870255823918553
Epoch: 48 | Iteration number: [3450/4518] 76% | Training loss: 0.6870247195423513
Epoch: 48 | Iteration number: [3460/4518] 76% | Training loss: 0.6870263500537487
Epoch: 48 | Iteration number: [3470/4518] 76% | Training loss: 0.6870218258598009
Epoch: 48 | Iteration number: [3480/4518] 77% | Training loss: 0.6870216289642214
Epoch: 48 | Iteration number: [3490/4518] 77% | Training loss: 0.6870212454167341
Epoch: 48 | Iteration number: [3500/4518] 77% | Training loss: 0.687018700173923
Epoch: 48 | Iteration number: [3510/4518] 77% | Training loss: 0.6870225895164359
Epoch: 48 | Iteration number: [3520/4518] 77% | Training loss: 0.6870215104215525
Epoch: 48 | Iteration number: [3530/4518] 78% | Training loss: 0.6870205446444557
Epoch: 48 | Iteration number: [3540/4518] 78% | Training loss: 0.6870210262341688
Epoch: 48 | Iteration number: [3550/4518] 78% | Training loss: 0.6870203712456663
Epoch: 48 | Iteration number: [3560/4518] 78% | Training loss: 0.6870195629556527
Epoch: 48 | Iteration number: [3570/4518] 79% | Training loss: 0.6870127138303441
Epoch: 48 | Iteration number: [3580/4518] 79% | Training loss: 0.6870134704106347
Epoch: 48 | Iteration number: [3590/4518] 79% | Training loss: 0.6870137376705584
Epoch: 48 | Iteration number: [3600/4518] 79% | Training loss: 0.687012697259585
Epoch: 48 | Iteration number: [3610/4518] 79% | Training loss: 0.6870105683968668
Epoch: 48 | Iteration number: [3620/4518] 80% | Training loss: 0.6870134098918399
Epoch: 48 | Iteration number: [3630/4518] 80% | Training loss: 0.6870146715772382
Epoch: 48 | Iteration number: [3640/4518] 80% | Training loss: 0.6870159134105012
Epoch: 48 | Iteration number: [3650/4518] 80% | Training loss: 0.6870180216064192
Epoch: 48 | Iteration number: [3660/4518] 81% | Training loss: 0.6870206871645047
Epoch: 48 | Iteration number: [3670/4518] 81% | Training loss: 0.6870163051893665
Epoch: 48 | Iteration number: [3680/4518] 81% | Training loss: 0.6870181999452736
Epoch: 48 | Iteration number: [3690/4518] 81% | Training loss: 0.687021157428178
Epoch: 48 | Iteration number: [3700/4518] 81% | Training loss: 0.6870216015867285
Epoch: 48 | Iteration number: [3710/4518] 82% | Training loss: 0.687024677121093
Epoch: 48 | Iteration number: [3720/4518] 82% | Training loss: 0.6870242457075786
Epoch: 48 | Iteration number: [3730/4518] 82% | Training loss: 0.6870216559948294
Epoch: 48 | Iteration number: [3740/4518] 82% | Training loss: 0.6870206996559459
Epoch: 48 | Iteration number: [3750/4518] 83% | Training loss: 0.6870209292093913
Epoch: 48 | Iteration number: [3760/4518] 83% | Training loss: 0.6870168202735009
Epoch: 48 | Iteration number: [3770/4518] 83% | Training loss: 0.6870145390299334
Epoch: 48 | Iteration number: [3780/4518] 83% | Training loss: 0.6870155619092719
Epoch: 48 | Iteration number: [3790/4518] 83% | Training loss: 0.6870147118939574
Epoch: 48 | Iteration number: [3800/4518] 84% | Training loss: 0.6870148204345452
Epoch: 48 | Iteration number: [3810/4518] 84% | Training loss: 0.6870134105519673
Epoch: 48 | Iteration number: [3820/4518] 84% | Training loss: 0.6870106730473603
Epoch: 48 | Iteration number: [3830/4518] 84% | Training loss: 0.6870120262041416
Epoch: 48 | Iteration number: [3840/4518] 84% | Training loss: 0.6870116879232228
Epoch: 48 | Iteration number: [3850/4518] 85% | Training loss: 0.6870109792498799
Epoch: 48 | Iteration number: [3860/4518] 85% | Training loss: 0.687010758914478
Epoch: 48 | Iteration number: [3870/4518] 85% | Training loss: 0.6870137192636189
Epoch: 48 | Iteration number: [3880/4518] 85% | Training loss: 0.6870143471151283
Epoch: 48 | Iteration number: [3890/4518] 86% | Training loss: 0.6870147945488633
Epoch: 48 | Iteration number: [3900/4518] 86% | Training loss: 0.687014027543557
Epoch: 48 | Iteration number: [3910/4518] 86% | Training loss: 0.6870166757832403
Epoch: 48 | Iteration number: [3920/4518] 86% | Training loss: 0.6870148357536111
Epoch: 48 | Iteration number: [3930/4518] 86% | Training loss: 0.6870134816824934
Epoch: 48 | Iteration number: [3940/4518] 87% | Training loss: 0.6870101291667386
Epoch: 48 | Iteration number: [3950/4518] 87% | Training loss: 0.6870096290866031
Epoch: 48 | Iteration number: [3960/4518] 87% | Training loss: 0.6870062792240971
Epoch: 48 | Iteration number: [3970/4518] 87% | Training loss: 0.6870047415984367
Epoch: 48 | Iteration number: [3980/4518] 88% | Training loss: 0.6870047870293334
Epoch: 48 | Iteration number: [3990/4518] 88% | Training loss: 0.6870055649662974
Epoch: 48 | Iteration number: [4000/4518] 88% | Training loss: 0.6870019367188215
Epoch: 48 | Iteration number: [4010/4518] 88% | Training loss: 0.6870010492510332
Epoch: 48 | Iteration number: [4020/4518] 88% | Training loss: 0.6869967274404877
Epoch: 48 | Iteration number: [4030/4518] 89% | Training loss: 0.6869949004046675
Epoch: 48 | Iteration number: [4040/4518] 89% | Training loss: 0.6869927825609056
Epoch: 48 | Iteration number: [4050/4518] 89% | Training loss: 0.6869936309037386
Epoch: 48 | Iteration number: [4060/4518] 89% | Training loss: 0.6869919560812964
Epoch: 48 | Iteration number: [4070/4518] 90% | Training loss: 0.6869892510061475
Epoch: 48 | Iteration number: [4080/4518] 90% | Training loss: 0.6869882407287756
Epoch: 48 | Iteration number: [4090/4518] 90% | Training loss: 0.6869868702002434
Epoch: 48 | Iteration number: [4100/4518] 90% | Training loss: 0.6869865534072969
Epoch: 48 | Iteration number: [4110/4518] 90% | Training loss: 0.6869857186528598
Epoch: 48 | Iteration number: [4120/4518] 91% | Training loss: 0.6869852125355341
Epoch: 48 | Iteration number: [4130/4518] 91% | Training loss: 0.6869826419734493
Epoch: 48 | Iteration number: [4140/4518] 91% | Training loss: 0.686978947310056
Epoch: 48 | Iteration number: [4150/4518] 91% | Training loss: 0.6869784233656274
Epoch: 48 | Iteration number: [4160/4518] 92% | Training loss: 0.6869780808543929
Epoch: 48 | Iteration number: [4170/4518] 92% | Training loss: 0.6869792811161608
Epoch: 48 | Iteration number: [4180/4518] 92% | Training loss: 0.6869799709348587
Epoch: 48 | Iteration number: [4190/4518] 92% | Training loss: 0.686979938093973
Epoch: 48 | Iteration number: [4200/4518] 92% | Training loss: 0.6869818647560619
Epoch: 48 | Iteration number: [4210/4518] 93% | Training loss: 0.6869798679816185
Epoch: 48 | Iteration number: [4220/4518] 93% | Training loss: 0.6869795358152752
Epoch: 48 | Iteration number: [4230/4518] 93% | Training loss: 0.6869771665574247
Epoch: 48 | Iteration number: [4240/4518] 93% | Training loss: 0.6869752815450137
Epoch: 48 | Iteration number: [4250/4518] 94% | Training loss: 0.6869759802958545
Epoch: 48 | Iteration number: [4260/4518] 94% | Training loss: 0.686979083402056
Epoch: 48 | Iteration number: [4270/4518] 94% | Training loss: 0.68697831732607
Epoch: 48 | Iteration number: [4280/4518] 94% | Training loss: 0.68697804527305
Epoch: 48 | Iteration number: [4290/4518] 94% | Training loss: 0.6869790048171313
Epoch: 48 | Iteration number: [4300/4518] 95% | Training loss: 0.6869806526150815
Epoch: 48 | Iteration number: [4310/4518] 95% | Training loss: 0.6869784763960164
Epoch: 48 | Iteration number: [4320/4518] 95% | Training loss: 0.686980994031937
Epoch: 48 | Iteration number: [4330/4518] 95% | Training loss: 0.6869759270693359
Epoch: 48 | Iteration number: [4340/4518] 96% | Training loss: 0.6869772516088002
Epoch: 48 | Iteration number: [4350/4518] 96% | Training loss: 0.6869780442906522
Epoch: 48 | Iteration number: [4360/4518] 96% | Training loss: 0.6869735265817117
Epoch: 48 | Iteration number: [4370/4518] 96% | Training loss: 0.6869722326096462
Epoch: 48 | Iteration number: [4380/4518] 96% | Training loss: 0.6869761389956627
Epoch: 48 | Iteration number: [4390/4518] 97% | Training loss: 0.6869737256632308
Epoch: 48 | Iteration number: [4400/4518] 97% | Training loss: 0.6869737927886572
Epoch: 48 | Iteration number: [4410/4518] 97% | Training loss: 0.6869738299695273
Epoch: 48 | Iteration number: [4420/4518] 97% | Training loss: 0.6869741507380257
Epoch: 48 | Iteration number: [4430/4518] 98% | Training loss: 0.6869730686361042
Epoch: 48 | Iteration number: [4440/4518] 98% | Training loss: 0.6869703511128554
Epoch: 48 | Iteration number: [4450/4518] 98% | Training loss: 0.6869690147410618
Epoch: 48 | Iteration number: [4460/4518] 98% | Training loss: 0.6869672907307544
Epoch: 48 | Iteration number: [4470/4518] 98% | Training loss: 0.686968140767458
Epoch: 48 | Iteration number: [4480/4518] 99% | Training loss: 0.6869665118599576
Epoch: 48 | Iteration number: [4490/4518] 99% | Training loss: 0.6869686332736621
Epoch: 48 | Iteration number: [4500/4518] 99% | Training loss: 0.6869677984449598
Epoch: 48 | Iteration number: [4510/4518] 99% | Training loss: 0.6869672051686669

 End of epoch: 48 | Train Loss: 0.686814629501239 | Training Time: 644 

 End of epoch: 48 | Eval Loss: 0.6901042643858462 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/4518] 0% | Training loss: 0.7552001416683197
Epoch: 49 | Iteration number: [20/4518] 0% | Training loss: 0.7204596668481826
Epoch: 49 | Iteration number: [30/4518] 0% | Training loss: 0.7089662929375966
Epoch: 49 | Iteration number: [40/4518] 0% | Training loss: 0.7031944945454598
Epoch: 49 | Iteration number: [50/4518] 1% | Training loss: 0.6999470245838165
Epoch: 49 | Iteration number: [60/4518] 1% | Training loss: 0.6977420339981715
Epoch: 49 | Iteration number: [70/4518] 1% | Training loss: 0.6961744385106223
Epoch: 49 | Iteration number: [80/4518] 1% | Training loss: 0.6949713796377182
Epoch: 49 | Iteration number: [90/4518] 1% | Training loss: 0.6940557685163286
Epoch: 49 | Iteration number: [100/4518] 2% | Training loss: 0.6932391202449799
Epoch: 49 | Iteration number: [110/4518] 2% | Training loss: 0.692718464677984
Epoch: 49 | Iteration number: [120/4518] 2% | Training loss: 0.692159196237723
Epoch: 49 | Iteration number: [130/4518] 2% | Training loss: 0.6917202055454255
Epoch: 49 | Iteration number: [140/4518] 3% | Training loss: 0.6913213844810213
Epoch: 49 | Iteration number: [150/4518] 3% | Training loss: 0.6911162360509236
Epoch: 49 | Iteration number: [160/4518] 3% | Training loss: 0.6909006990492343
Epoch: 49 | Iteration number: [170/4518] 3% | Training loss: 0.6906166399226469
Epoch: 49 | Iteration number: [180/4518] 3% | Training loss: 0.6904151254230075
Epoch: 49 | Iteration number: [190/4518] 4% | Training loss: 0.6901870987917248
Epoch: 49 | Iteration number: [200/4518] 4% | Training loss: 0.6899956902861595
Epoch: 49 | Iteration number: [210/4518] 4% | Training loss: 0.689848378158751
Epoch: 49 | Iteration number: [220/4518] 4% | Training loss: 0.6896943970160051
Epoch: 49 | Iteration number: [230/4518] 5% | Training loss: 0.6895795537077862
Epoch: 49 | Iteration number: [240/4518] 5% | Training loss: 0.6894355001548926
Epoch: 49 | Iteration number: [250/4518] 5% | Training loss: 0.6893595428466797
Epoch: 49 | Iteration number: [260/4518] 5% | Training loss: 0.6892499896196219
Epoch: 49 | Iteration number: [270/4518] 5% | Training loss: 0.6891843733964143
Epoch: 49 | Iteration number: [280/4518] 6% | Training loss: 0.6891276089208467
Epoch: 49 | Iteration number: [290/4518] 6% | Training loss: 0.689011935735571
Epoch: 49 | Iteration number: [300/4518] 6% | Training loss: 0.6889508181810379
Epoch: 49 | Iteration number: [310/4518] 6% | Training loss: 0.6889080136053024
Epoch: 49 | Iteration number: [320/4518] 7% | Training loss: 0.688854101113975
Epoch: 49 | Iteration number: [330/4518] 7% | Training loss: 0.688830983096903
Epoch: 49 | Iteration number: [340/4518] 7% | Training loss: 0.6888006590745028
Epoch: 49 | Iteration number: [350/4518] 7% | Training loss: 0.6887134960719518
Epoch: 49 | Iteration number: [360/4518] 7% | Training loss: 0.6887121410833464
Epoch: 49 | Iteration number: [370/4518] 8% | Training loss: 0.6886757372198878
Epoch: 49 | Iteration number: [380/4518] 8% | Training loss: 0.6886670661600013
Epoch: 49 | Iteration number: [390/4518] 8% | Training loss: 0.6885791245179299
Epoch: 49 | Iteration number: [400/4518] 8% | Training loss: 0.6885408498346806
Epoch: 49 | Iteration number: [410/4518] 9% | Training loss: 0.6884970150342802
Epoch: 49 | Iteration number: [420/4518] 9% | Training loss: 0.6884531536272593
Epoch: 49 | Iteration number: [430/4518] 9% | Training loss: 0.6884192326734232
Epoch: 49 | Iteration number: [440/4518] 9% | Training loss: 0.6883771568536758
Epoch: 49 | Iteration number: [450/4518] 9% | Training loss: 0.6883346529801687
Epoch: 49 | Iteration number: [460/4518] 10% | Training loss: 0.6883062906887221
Epoch: 49 | Iteration number: [470/4518] 10% | Training loss: 0.6882591491049909
Epoch: 49 | Iteration number: [480/4518] 10% | Training loss: 0.6882383156567812
Epoch: 49 | Iteration number: [490/4518] 10% | Training loss: 0.6882046908748393
Epoch: 49 | Iteration number: [500/4518] 11% | Training loss: 0.6881654435396194
Epoch: 49 | Iteration number: [510/4518] 11% | Training loss: 0.6881079957765691
Epoch: 49 | Iteration number: [520/4518] 11% | Training loss: 0.6881046907259868
Epoch: 49 | Iteration number: [530/4518] 11% | Training loss: 0.688067947356206
Epoch: 49 | Iteration number: [540/4518] 11% | Training loss: 0.6880490614308251
Epoch: 49 | Iteration number: [550/4518] 12% | Training loss: 0.6880014962499792
Epoch: 49 | Iteration number: [560/4518] 12% | Training loss: 0.6879807368985245
Epoch: 49 | Iteration number: [570/4518] 12% | Training loss: 0.6879572938408768
Epoch: 49 | Iteration number: [580/4518] 12% | Training loss: 0.6879304343256457
Epoch: 49 | Iteration number: [590/4518] 13% | Training loss: 0.6879143529019114
Epoch: 49 | Iteration number: [600/4518] 13% | Training loss: 0.6878887318571408
Epoch: 49 | Iteration number: [610/4518] 13% | Training loss: 0.6878726246904154
Epoch: 49 | Iteration number: [620/4518] 13% | Training loss: 0.6878648037872007
Epoch: 49 | Iteration number: [630/4518] 13% | Training loss: 0.6878584357481154
Epoch: 49 | Iteration number: [640/4518] 14% | Training loss: 0.6878381097689271
Epoch: 49 | Iteration number: [650/4518] 14% | Training loss: 0.687824301811365
Epoch: 49 | Iteration number: [660/4518] 14% | Training loss: 0.6878054328940132
Epoch: 49 | Iteration number: [670/4518] 14% | Training loss: 0.6877771294828671
Epoch: 49 | Iteration number: [680/4518] 15% | Training loss: 0.6877741865375463
Epoch: 49 | Iteration number: [690/4518] 15% | Training loss: 0.6877500004526498
Epoch: 49 | Iteration number: [700/4518] 15% | Training loss: 0.6877496858154024
Epoch: 49 | Iteration number: [710/4518] 15% | Training loss: 0.6877512899083151
Epoch: 49 | Iteration number: [720/4518] 15% | Training loss: 0.687737896376186
Epoch: 49 | Iteration number: [730/4518] 16% | Training loss: 0.6877438670968357
Epoch: 49 | Iteration number: [740/4518] 16% | Training loss: 0.6877302069921751
Epoch: 49 | Iteration number: [750/4518] 16% | Training loss: 0.6877220797538758
Epoch: 49 | Iteration number: [760/4518] 16% | Training loss: 0.6877239268861319
Epoch: 49 | Iteration number: [770/4518] 17% | Training loss: 0.6877095773622587
Epoch: 49 | Iteration number: [780/4518] 17% | Training loss: 0.6877013449485485
Epoch: 49 | Iteration number: [790/4518] 17% | Training loss: 0.6876780943780005
Epoch: 49 | Iteration number: [800/4518] 17% | Training loss: 0.6876763636618852
Epoch: 49 | Iteration number: [810/4518] 17% | Training loss: 0.6876657959855633
Epoch: 49 | Iteration number: [820/4518] 18% | Training loss: 0.6876576895393977
Epoch: 49 | Iteration number: [830/4518] 18% | Training loss: 0.687659191295325
Epoch: 49 | Iteration number: [840/4518] 18% | Training loss: 0.6876466456623305
Epoch: 49 | Iteration number: [850/4518] 18% | Training loss: 0.6876457875616411
Epoch: 49 | Iteration number: [860/4518] 19% | Training loss: 0.6876428773236829
Epoch: 49 | Iteration number: [870/4518] 19% | Training loss: 0.6876372161267817
Epoch: 49 | Iteration number: [880/4518] 19% | Training loss: 0.6876373449509794
Epoch: 49 | Iteration number: [890/4518] 19% | Training loss: 0.6876188421517275
Epoch: 49 | Iteration number: [900/4518] 19% | Training loss: 0.6876127535767026
Epoch: 49 | Iteration number: [910/4518] 20% | Training loss: 0.6876061079921303
Epoch: 49 | Iteration number: [920/4518] 20% | Training loss: 0.687599003120609
Epoch: 49 | Iteration number: [930/4518] 20% | Training loss: 0.6875958924011517
Epoch: 49 | Iteration number: [940/4518] 20% | Training loss: 0.6875935073228593
Epoch: 49 | Iteration number: [950/4518] 21% | Training loss: 0.6875853941315099
Epoch: 49 | Iteration number: [960/4518] 21% | Training loss: 0.687574028223753
Epoch: 49 | Iteration number: [970/4518] 21% | Training loss: 0.6875750625870891
Epoch: 49 | Iteration number: [980/4518] 21% | Training loss: 0.6875665679878118
Epoch: 49 | Iteration number: [990/4518] 21% | Training loss: 0.6875674955170564
Epoch: 49 | Iteration number: [1000/4518] 22% | Training loss: 0.6875555758476257
Epoch: 49 | Iteration number: [1010/4518] 22% | Training loss: 0.6875560108387825
Epoch: 49 | Iteration number: [1020/4518] 22% | Training loss: 0.687552569660486
Epoch: 49 | Iteration number: [1030/4518] 22% | Training loss: 0.6875508417203589
Epoch: 49 | Iteration number: [1040/4518] 23% | Training loss: 0.6875462979078293
Epoch: 49 | Iteration number: [1050/4518] 23% | Training loss: 0.6875282199609847
Epoch: 49 | Iteration number: [1060/4518] 23% | Training loss: 0.687510000366085
Epoch: 49 | Iteration number: [1070/4518] 23% | Training loss: 0.6874885547383923
Epoch: 49 | Iteration number: [1080/4518] 23% | Training loss: 0.6874730090852137
Epoch: 49 | Iteration number: [1090/4518] 24% | Training loss: 0.6874707696087864
Epoch: 49 | Iteration number: [1100/4518] 24% | Training loss: 0.6874585840918801
Epoch: 49 | Iteration number: [1110/4518] 24% | Training loss: 0.6874513377477457
Epoch: 49 | Iteration number: [1120/4518] 24% | Training loss: 0.6874521228351763
Epoch: 49 | Iteration number: [1130/4518] 25% | Training loss: 0.6874484915648942
Epoch: 49 | Iteration number: [1140/4518] 25% | Training loss: 0.6874427721165774
Epoch: 49 | Iteration number: [1150/4518] 25% | Training loss: 0.6874364028806271
Epoch: 49 | Iteration number: [1160/4518] 25% | Training loss: 0.6874360593742338
Epoch: 49 | Iteration number: [1170/4518] 25% | Training loss: 0.6874247074127198
Epoch: 49 | Iteration number: [1180/4518] 26% | Training loss: 0.6874094354904304
Epoch: 49 | Iteration number: [1190/4518] 26% | Training loss: 0.6874037971516617
Epoch: 49 | Iteration number: [1200/4518] 26% | Training loss: 0.6873920525113741
Epoch: 49 | Iteration number: [1210/4518] 26% | Training loss: 0.6873804073195812
Epoch: 49 | Iteration number: [1220/4518] 27% | Training loss: 0.6873816069032325
Epoch: 49 | Iteration number: [1230/4518] 27% | Training loss: 0.6873742735967403
Epoch: 49 | Iteration number: [1240/4518] 27% | Training loss: 0.687368411498685
Epoch: 49 | Iteration number: [1250/4518] 27% | Training loss: 0.6873669875144959
Epoch: 49 | Iteration number: [1260/4518] 27% | Training loss: 0.6873685769145451
Epoch: 49 | Iteration number: [1270/4518] 28% | Training loss: 0.6873616950249108
Epoch: 49 | Iteration number: [1280/4518] 28% | Training loss: 0.6873552442528308
Epoch: 49 | Iteration number: [1290/4518] 28% | Training loss: 0.6873512230178183
Epoch: 49 | Iteration number: [1300/4518] 28% | Training loss: 0.6873391206906392
Epoch: 49 | Iteration number: [1310/4518] 28% | Training loss: 0.6873274589767893
Epoch: 49 | Iteration number: [1320/4518] 29% | Training loss: 0.6873163778673519
Epoch: 49 | Iteration number: [1330/4518] 29% | Training loss: 0.6873126854573873
Epoch: 49 | Iteration number: [1340/4518] 29% | Training loss: 0.6873105560220889
Epoch: 49 | Iteration number: [1350/4518] 29% | Training loss: 0.6873077543135042
Epoch: 49 | Iteration number: [1360/4518] 30% | Training loss: 0.6873016359174953
Epoch: 49 | Iteration number: [1370/4518] 30% | Training loss: 0.6872808006993175
Epoch: 49 | Iteration number: [1380/4518] 30% | Training loss: 0.6872843886199205
Epoch: 49 | Iteration number: [1390/4518] 30% | Training loss: 0.6872727591356785
Epoch: 49 | Iteration number: [1400/4518] 30% | Training loss: 0.6872624523724828
Epoch: 49 | Iteration number: [1410/4518] 31% | Training loss: 0.6872582272012183
Epoch: 49 | Iteration number: [1420/4518] 31% | Training loss: 0.6872569139154864
Epoch: 49 | Iteration number: [1430/4518] 31% | Training loss: 0.6872543816799884
Epoch: 49 | Iteration number: [1440/4518] 31% | Training loss: 0.6872554262893067
Epoch: 49 | Iteration number: [1450/4518] 32% | Training loss: 0.687244409281632
Epoch: 49 | Iteration number: [1460/4518] 32% | Training loss: 0.6872387063421616
Epoch: 49 | Iteration number: [1470/4518] 32% | Training loss: 0.6872418040320987
Epoch: 49 | Iteration number: [1480/4518] 32% | Training loss: 0.6872374629249444
Epoch: 49 | Iteration number: [1490/4518] 32% | Training loss: 0.6872363208124301
Epoch: 49 | Iteration number: [1500/4518] 33% | Training loss: 0.687232679883639
Epoch: 49 | Iteration number: [1510/4518] 33% | Training loss: 0.6872301039711529
Epoch: 49 | Iteration number: [1520/4518] 33% | Training loss: 0.6872368411798226
Epoch: 49 | Iteration number: [1530/4518] 33% | Training loss: 0.6872265231765173
Epoch: 49 | Iteration number: [1540/4518] 34% | Training loss: 0.6872227607996433
Epoch: 49 | Iteration number: [1550/4518] 34% | Training loss: 0.6872292767801592
Epoch: 49 | Iteration number: [1560/4518] 34% | Training loss: 0.6872250466774672
Epoch: 49 | Iteration number: [1570/4518] 34% | Training loss: 0.6872247953323801
Epoch: 49 | Iteration number: [1580/4518] 34% | Training loss: 0.6872222108176992
Epoch: 49 | Iteration number: [1590/4518] 35% | Training loss: 0.6872263739318968
Epoch: 49 | Iteration number: [1600/4518] 35% | Training loss: 0.687229616753757
Epoch: 49 | Iteration number: [1610/4518] 35% | Training loss: 0.6872225842120484
Epoch: 49 | Iteration number: [1620/4518] 35% | Training loss: 0.6872225580392061
Epoch: 49 | Iteration number: [1630/4518] 36% | Training loss: 0.6872195791978778
Epoch: 49 | Iteration number: [1640/4518] 36% | Training loss: 0.6872215466164961
Epoch: 49 | Iteration number: [1650/4518] 36% | Training loss: 0.6872157893758831
Epoch: 49 | Iteration number: [1660/4518] 36% | Training loss: 0.6872036415769394
Epoch: 49 | Iteration number: [1670/4518] 36% | Training loss: 0.6871961130353506
Epoch: 49 | Iteration number: [1680/4518] 37% | Training loss: 0.6871908720760118
Epoch: 49 | Iteration number: [1690/4518] 37% | Training loss: 0.6871892476222924
Epoch: 49 | Iteration number: [1700/4518] 37% | Training loss: 0.6871918518753612
Epoch: 49 | Iteration number: [1710/4518] 37% | Training loss: 0.6871880918915508
Epoch: 49 | Iteration number: [1720/4518] 38% | Training loss: 0.6871860481971919
Epoch: 49 | Iteration number: [1730/4518] 38% | Training loss: 0.6871813988754515
Epoch: 49 | Iteration number: [1740/4518] 38% | Training loss: 0.6871785339267774
Epoch: 49 | Iteration number: [1750/4518] 38% | Training loss: 0.6871731986658913
Epoch: 49 | Iteration number: [1760/4518] 38% | Training loss: 0.6871698918667707
Epoch: 49 | Iteration number: [1770/4518] 39% | Training loss: 0.6871636650656576
Epoch: 49 | Iteration number: [1780/4518] 39% | Training loss: 0.6871703428498814
Epoch: 49 | Iteration number: [1790/4518] 39% | Training loss: 0.6871707337195647
Epoch: 49 | Iteration number: [1800/4518] 39% | Training loss: 0.687167217930158
Epoch: 49 | Iteration number: [1810/4518] 40% | Training loss: 0.6871694085677026
Epoch: 49 | Iteration number: [1820/4518] 40% | Training loss: 0.6871725784225778
Epoch: 49 | Iteration number: [1830/4518] 40% | Training loss: 0.6871676183789154
Epoch: 49 | Iteration number: [1840/4518] 40% | Training loss: 0.6871672379905763
Epoch: 49 | Iteration number: [1850/4518] 40% | Training loss: 0.6871708948225589
Epoch: 49 | Iteration number: [1860/4518] 41% | Training loss: 0.6871637578933469
Epoch: 49 | Iteration number: [1870/4518] 41% | Training loss: 0.6871642596262661
Epoch: 49 | Iteration number: [1880/4518] 41% | Training loss: 0.6871622669887035
Epoch: 49 | Iteration number: [1890/4518] 41% | Training loss: 0.6871624946594238
Epoch: 49 | Iteration number: [1900/4518] 42% | Training loss: 0.6871672339188425
Epoch: 49 | Iteration number: [1910/4518] 42% | Training loss: 0.6871634270196185
Epoch: 49 | Iteration number: [1920/4518] 42% | Training loss: 0.687165787195166
Epoch: 49 | Iteration number: [1930/4518] 42% | Training loss: 0.6871630710332505
Epoch: 49 | Iteration number: [1940/4518] 42% | Training loss: 0.6871643226171277
Epoch: 49 | Iteration number: [1950/4518] 43% | Training loss: 0.6871693440889701
Epoch: 49 | Iteration number: [1960/4518] 43% | Training loss: 0.6871656363411826
Epoch: 49 | Iteration number: [1970/4518] 43% | Training loss: 0.6871658021423417
Epoch: 49 | Iteration number: [1980/4518] 43% | Training loss: 0.6871648469657609
Epoch: 49 | Iteration number: [1990/4518] 44% | Training loss: 0.6871702241238637
Epoch: 49 | Iteration number: [2000/4518] 44% | Training loss: 0.6871740159094334
Epoch: 49 | Iteration number: [2010/4518] 44% | Training loss: 0.6871752679941073
Epoch: 49 | Iteration number: [2020/4518] 44% | Training loss: 0.6871714879380595
Epoch: 49 | Iteration number: [2030/4518] 44% | Training loss: 0.6871693878338254
Epoch: 49 | Iteration number: [2040/4518] 45% | Training loss: 0.6871615227238804
Epoch: 49 | Iteration number: [2050/4518] 45% | Training loss: 0.6871596951891736
Epoch: 49 | Iteration number: [2060/4518] 45% | Training loss: 0.6871638609367667
Epoch: 49 | Iteration number: [2070/4518] 45% | Training loss: 0.6871619551941969
Epoch: 49 | Iteration number: [2080/4518] 46% | Training loss: 0.6871681962735378
Epoch: 49 | Iteration number: [2090/4518] 46% | Training loss: 0.6871621419082988
Epoch: 49 | Iteration number: [2100/4518] 46% | Training loss: 0.6871586073580243
Epoch: 49 | Iteration number: [2110/4518] 46% | Training loss: 0.6871591000477849
Epoch: 49 | Iteration number: [2120/4518] 46% | Training loss: 0.6871554953309725
Epoch: 49 | Iteration number: [2130/4518] 47% | Training loss: 0.6871519693466419
Epoch: 49 | Iteration number: [2140/4518] 47% | Training loss: 0.687147782478377
Epoch: 49 | Iteration number: [2150/4518] 47% | Training loss: 0.6871440106768941
Epoch: 49 | Iteration number: [2160/4518] 47% | Training loss: 0.6871432838064653
Epoch: 49 | Iteration number: [2170/4518] 48% | Training loss: 0.6871409562600922
Epoch: 49 | Iteration number: [2180/4518] 48% | Training loss: 0.6871357238073962
Epoch: 49 | Iteration number: [2190/4518] 48% | Training loss: 0.6871312744269088
Epoch: 49 | Iteration number: [2200/4518] 48% | Training loss: 0.6871331612901254
Epoch: 49 | Iteration number: [2210/4518] 48% | Training loss: 0.6871379916484539
Epoch: 49 | Iteration number: [2220/4518] 49% | Training loss: 0.6871362468949309
Epoch: 49 | Iteration number: [2230/4518] 49% | Training loss: 0.6871360769453605
Epoch: 49 | Iteration number: [2240/4518] 49% | Training loss: 0.6871358076376575
Epoch: 49 | Iteration number: [2250/4518] 49% | Training loss: 0.6871341511143578
Epoch: 49 | Iteration number: [2260/4518] 50% | Training loss: 0.6871370697707202
Epoch: 49 | Iteration number: [2270/4518] 50% | Training loss: 0.6871359755814338
Epoch: 49 | Iteration number: [2280/4518] 50% | Training loss: 0.6871332415886092
Epoch: 49 | Iteration number: [2290/4518] 50% | Training loss: 0.6871311377750213
Epoch: 49 | Iteration number: [2300/4518] 50% | Training loss: 0.6871292637742084
Epoch: 49 | Iteration number: [2310/4518] 51% | Training loss: 0.6871292777391739
Epoch: 49 | Iteration number: [2320/4518] 51% | Training loss: 0.6871262149564151
Epoch: 49 | Iteration number: [2330/4518] 51% | Training loss: 0.6871238989123971
Epoch: 49 | Iteration number: [2340/4518] 51% | Training loss: 0.6871224715668931
Epoch: 49 | Iteration number: [2350/4518] 52% | Training loss: 0.6871168226130465
Epoch: 49 | Iteration number: [2360/4518] 52% | Training loss: 0.6871179946145769
Epoch: 49 | Iteration number: [2370/4518] 52% | Training loss: 0.6871193724091043
Epoch: 49 | Iteration number: [2380/4518] 52% | Training loss: 0.6871186212331307
Epoch: 49 | Iteration number: [2390/4518] 52% | Training loss: 0.687115476320977
Epoch: 49 | Iteration number: [2400/4518] 53% | Training loss: 0.6871142372488975
Epoch: 49 | Iteration number: [2410/4518] 53% | Training loss: 0.6871133626249322
Epoch: 49 | Iteration number: [2420/4518] 53% | Training loss: 0.6871151568475834
Epoch: 49 | Iteration number: [2430/4518] 53% | Training loss: 0.6871195660697089
Epoch: 49 | Iteration number: [2440/4518] 54% | Training loss: 0.6871212908234753
Epoch: 49 | Iteration number: [2450/4518] 54% | Training loss: 0.6871222280482857
Epoch: 49 | Iteration number: [2460/4518] 54% | Training loss: 0.6871216015117925
Epoch: 49 | Iteration number: [2470/4518] 54% | Training loss: 0.6871199267113257
Epoch: 49 | Iteration number: [2480/4518] 54% | Training loss: 0.687118750233804
Epoch: 49 | Iteration number: [2490/4518] 55% | Training loss: 0.6871168696976091
Epoch: 49 | Iteration number: [2500/4518] 55% | Training loss: 0.6871144651651383
Epoch: 49 | Iteration number: [2510/4518] 55% | Training loss: 0.6871158843496407
Epoch: 49 | Iteration number: [2520/4518] 55% | Training loss: 0.6871172227556743
Epoch: 49 | Iteration number: [2530/4518] 55% | Training loss: 0.6871156619235932
Epoch: 49 | Iteration number: [2540/4518] 56% | Training loss: 0.6871109141843526
Epoch: 49 | Iteration number: [2550/4518] 56% | Training loss: 0.6871044095824747
Epoch: 49 | Iteration number: [2560/4518] 56% | Training loss: 0.6871057279873639
Epoch: 49 | Iteration number: [2570/4518] 56% | Training loss: 0.6871052698170629
Epoch: 49 | Iteration number: [2580/4518] 57% | Training loss: 0.6871078575304312
Epoch: 49 | Iteration number: [2590/4518] 57% | Training loss: 0.6871064216243714
Epoch: 49 | Iteration number: [2600/4518] 57% | Training loss: 0.6871059046571071
Epoch: 49 | Iteration number: [2610/4518] 57% | Training loss: 0.6871074592473406
Epoch: 49 | Iteration number: [2620/4518] 57% | Training loss: 0.6871035073549693
Epoch: 49 | Iteration number: [2630/4518] 58% | Training loss: 0.6870992096884623
Epoch: 49 | Iteration number: [2640/4518] 58% | Training loss: 0.6870981891272646
Epoch: 49 | Iteration number: [2650/4518] 58% | Training loss: 0.68709824127971
Epoch: 49 | Iteration number: [2660/4518] 58% | Training loss: 0.6870991114162861
Epoch: 49 | Iteration number: [2670/4518] 59% | Training loss: 0.687097666058201
Epoch: 49 | Iteration number: [2680/4518] 59% | Training loss: 0.6870932325275976
Epoch: 49 | Iteration number: [2690/4518] 59% | Training loss: 0.6870927160778897
Epoch: 49 | Iteration number: [2700/4518] 59% | Training loss: 0.6870895913574431
Epoch: 49 | Iteration number: [2710/4518] 59% | Training loss: 0.6870830874601414
Epoch: 49 | Iteration number: [2720/4518] 60% | Training loss: 0.6870830265476423
Epoch: 49 | Iteration number: [2730/4518] 60% | Training loss: 0.6870869867530934
Epoch: 49 | Iteration number: [2740/4518] 60% | Training loss: 0.6870885665834385
Epoch: 49 | Iteration number: [2750/4518] 60% | Training loss: 0.6870865074287761
Epoch: 49 | Iteration number: [2760/4518] 61% | Training loss: 0.6870829247262167
Epoch: 49 | Iteration number: [2770/4518] 61% | Training loss: 0.6870787064090963
Epoch: 49 | Iteration number: [2780/4518] 61% | Training loss: 0.6870808554639062
Epoch: 49 | Iteration number: [2790/4518] 61% | Training loss: 0.6870789960507424
Epoch: 49 | Iteration number: [2800/4518] 61% | Training loss: 0.6870804065465927
Epoch: 49 | Iteration number: [2810/4518] 62% | Training loss: 0.6870823719111202
Epoch: 49 | Iteration number: [2820/4518] 62% | Training loss: 0.6870826541532016
Epoch: 49 | Iteration number: [2830/4518] 62% | Training loss: 0.6870799123398407
Epoch: 49 | Iteration number: [2840/4518] 62% | Training loss: 0.687080452391799
Epoch: 49 | Iteration number: [2850/4518] 63% | Training loss: 0.6870726202454484
Epoch: 49 | Iteration number: [2860/4518] 63% | Training loss: 0.6870723226062068
Epoch: 49 | Iteration number: [2870/4518] 63% | Training loss: 0.68706954163126
Epoch: 49 | Iteration number: [2880/4518] 63% | Training loss: 0.6870688012076749
Epoch: 49 | Iteration number: [2890/4518] 63% | Training loss: 0.6870679520611944
Epoch: 49 | Iteration number: [2900/4518] 64% | Training loss: 0.6870645771355465
Epoch: 49 | Iteration number: [2910/4518] 64% | Training loss: 0.6870634800380038
Epoch: 49 | Iteration number: [2920/4518] 64% | Training loss: 0.6870671327187591
Epoch: 49 | Iteration number: [2930/4518] 64% | Training loss: 0.6870673754516315
Epoch: 49 | Iteration number: [2940/4518] 65% | Training loss: 0.6870693367151987
Epoch: 49 | Iteration number: [2950/4518] 65% | Training loss: 0.6870713943748151
Epoch: 49 | Iteration number: [2960/4518] 65% | Training loss: 0.6870742962771171
Epoch: 49 | Iteration number: [2970/4518] 65% | Training loss: 0.6870683116744263
Epoch: 49 | Iteration number: [2980/4518] 65% | Training loss: 0.687065245141119
Epoch: 49 | Iteration number: [2990/4518] 66% | Training loss: 0.6870663438752344
Epoch: 49 | Iteration number: [3000/4518] 66% | Training loss: 0.6870635762810707
Epoch: 49 | Iteration number: [3010/4518] 66% | Training loss: 0.6870632082124881
Epoch: 49 | Iteration number: [3020/4518] 66% | Training loss: 0.6870628259039873
Epoch: 49 | Iteration number: [3030/4518] 67% | Training loss: 0.6870651154038143
Epoch: 49 | Iteration number: [3040/4518] 67% | Training loss: 0.6870639555744434
Epoch: 49 | Iteration number: [3050/4518] 67% | Training loss: 0.6870629113619445
Epoch: 49 | Iteration number: [3060/4518] 67% | Training loss: 0.6870613921117159
Epoch: 49 | Iteration number: [3070/4518] 67% | Training loss: 0.6870590747373501
Epoch: 49 | Iteration number: [3080/4518] 68% | Training loss: 0.6870605154858007
Epoch: 49 | Iteration number: [3090/4518] 68% | Training loss: 0.687059050393336
Epoch: 49 | Iteration number: [3100/4518] 68% | Training loss: 0.6870594782214011
Epoch: 49 | Iteration number: [3110/4518] 68% | Training loss: 0.6870578215436537
Epoch: 49 | Iteration number: [3120/4518] 69% | Training loss: 0.6870558544420279
Epoch: 49 | Iteration number: [3130/4518] 69% | Training loss: 0.6870589215724994
Epoch: 49 | Iteration number: [3140/4518] 69% | Training loss: 0.6870556896279572
Epoch: 49 | Iteration number: [3150/4518] 69% | Training loss: 0.6870583229783982
Epoch: 49 | Iteration number: [3160/4518] 69% | Training loss: 0.6870561834943445
Epoch: 49 | Iteration number: [3170/4518] 70% | Training loss: 0.6870546903708004
Epoch: 49 | Iteration number: [3180/4518] 70% | Training loss: 0.6870582957500182
Epoch: 49 | Iteration number: [3190/4518] 70% | Training loss: 0.6870586574077606
Epoch: 49 | Iteration number: [3200/4518] 70% | Training loss: 0.687056722342968
Epoch: 49 | Iteration number: [3210/4518] 71% | Training loss: 0.6870516066053575
Epoch: 49 | Iteration number: [3220/4518] 71% | Training loss: 0.6870496353377467
Epoch: 49 | Iteration number: [3230/4518] 71% | Training loss: 0.6870482628928618
Epoch: 49 | Iteration number: [3240/4518] 71% | Training loss: 0.687045973300198
Epoch: 49 | Iteration number: [3250/4518] 71% | Training loss: 0.6870410096095159
Epoch: 49 | Iteration number: [3260/4518] 72% | Training loss: 0.6870400037319382
Epoch: 49 | Iteration number: [3270/4518] 72% | Training loss: 0.6870402917767154
Epoch: 49 | Iteration number: [3280/4518] 72% | Training loss: 0.6870460813910496
Epoch: 49 | Iteration number: [3290/4518] 72% | Training loss: 0.6870429144079562
Epoch: 49 | Iteration number: [3300/4518] 73% | Training loss: 0.6870375986713352
Epoch: 49 | Iteration number: [3310/4518] 73% | Training loss: 0.6870404831052187
Epoch: 49 | Iteration number: [3320/4518] 73% | Training loss: 0.6870419986635805
Epoch: 49 | Iteration number: [3330/4518] 73% | Training loss: 0.6870403618962915
Epoch: 49 | Iteration number: [3340/4518] 73% | Training loss: 0.6870395918806156
Epoch: 49 | Iteration number: [3350/4518] 74% | Training loss: 0.6870392405453013
Epoch: 49 | Iteration number: [3360/4518] 74% | Training loss: 0.6870355614061866
Epoch: 49 | Iteration number: [3370/4518] 74% | Training loss: 0.6870365004157454
Epoch: 49 | Iteration number: [3380/4518] 74% | Training loss: 0.687035430835549
Epoch: 49 | Iteration number: [3390/4518] 75% | Training loss: 0.6870325713910185
Epoch: 49 | Iteration number: [3400/4518] 75% | Training loss: 0.6870338139288565
Epoch: 49 | Iteration number: [3410/4518] 75% | Training loss: 0.6870334678206625
Epoch: 49 | Iteration number: [3420/4518] 75% | Training loss: 0.6870298198789184
Epoch: 49 | Iteration number: [3430/4518] 75% | Training loss: 0.6870250263645072
Epoch: 49 | Iteration number: [3440/4518] 76% | Training loss: 0.6870234857464945
Epoch: 49 | Iteration number: [3450/4518] 76% | Training loss: 0.6870199880910957
Epoch: 49 | Iteration number: [3460/4518] 76% | Training loss: 0.6870187443977146
Epoch: 49 | Iteration number: [3470/4518] 76% | Training loss: 0.6870180483853783
Epoch: 49 | Iteration number: [3480/4518] 77% | Training loss: 0.6870208433475987
Epoch: 49 | Iteration number: [3490/4518] 77% | Training loss: 0.6870243565913258
Epoch: 49 | Iteration number: [3500/4518] 77% | Training loss: 0.6870233203342982
Epoch: 49 | Iteration number: [3510/4518] 77% | Training loss: 0.6870211508369174
Epoch: 49 | Iteration number: [3520/4518] 77% | Training loss: 0.6870209441774271
Epoch: 49 | Iteration number: [3530/4518] 78% | Training loss: 0.6870200307105824
Epoch: 49 | Iteration number: [3540/4518] 78% | Training loss: 0.6870220833242277
Epoch: 49 | Iteration number: [3550/4518] 78% | Training loss: 0.6870199941917204
Epoch: 49 | Iteration number: [3560/4518] 78% | Training loss: 0.6870211408211944
Epoch: 49 | Iteration number: [3570/4518] 79% | Training loss: 0.68701796408127
Epoch: 49 | Iteration number: [3580/4518] 79% | Training loss: 0.6870167434715025
Epoch: 49 | Iteration number: [3590/4518] 79% | Training loss: 0.6870182179308867
Epoch: 49 | Iteration number: [3600/4518] 79% | Training loss: 0.6870170310636361
Epoch: 49 | Iteration number: [3610/4518] 79% | Training loss: 0.6870162600130255
Epoch: 49 | Iteration number: [3620/4518] 80% | Training loss: 0.6870110470945664
Epoch: 49 | Iteration number: [3630/4518] 80% | Training loss: 0.68701163885022
Epoch: 49 | Iteration number: [3640/4518] 80% | Training loss: 0.6870111587610873
Epoch: 49 | Iteration number: [3650/4518] 80% | Training loss: 0.6870094908916787
Epoch: 49 | Iteration number: [3660/4518] 81% | Training loss: 0.6870087873088857
Epoch: 49 | Iteration number: [3670/4518] 81% | Training loss: 0.6870085315093682
Epoch: 49 | Iteration number: [3680/4518] 81% | Training loss: 0.68701221226998
Epoch: 49 | Iteration number: [3690/4518] 81% | Training loss: 0.6870134769254906
Epoch: 49 | Iteration number: [3700/4518] 81% | Training loss: 0.6870144575350994
Epoch: 49 | Iteration number: [3710/4518] 82% | Training loss: 0.687016134570551
Epoch: 49 | Iteration number: [3720/4518] 82% | Training loss: 0.6870163620639873
Epoch: 49 | Iteration number: [3730/4518] 82% | Training loss: 0.6870123933531324
Epoch: 49 | Iteration number: [3740/4518] 82% | Training loss: 0.6870113365631052
Epoch: 49 | Iteration number: [3750/4518] 83% | Training loss: 0.6870092069149017
Epoch: 49 | Iteration number: [3760/4518] 83% | Training loss: 0.6870090597170464
Epoch: 49 | Iteration number: [3770/4518] 83% | Training loss: 0.6870080846690373
Epoch: 49 | Iteration number: [3780/4518] 83% | Training loss: 0.6870066152520912
Epoch: 49 | Iteration number: [3790/4518] 83% | Training loss: 0.6870070342809984
Epoch: 49 | Iteration number: [3800/4518] 84% | Training loss: 0.6870023497468547
Epoch: 49 | Iteration number: [3810/4518] 84% | Training loss: 0.6870042641175388
Epoch: 49 | Iteration number: [3820/4518] 84% | Training loss: 0.6870043858963781
Epoch: 49 | Iteration number: [3830/4518] 84% | Training loss: 0.6870016340331683
Epoch: 49 | Iteration number: [3840/4518] 84% | Training loss: 0.6870022902265192
Epoch: 49 | Iteration number: [3850/4518] 85% | Training loss: 0.6870009218562733
Epoch: 49 | Iteration number: [3860/4518] 85% | Training loss: 0.6870004965233679
Epoch: 49 | Iteration number: [3870/4518] 85% | Training loss: 0.6869994152731982
Epoch: 49 | Iteration number: [3880/4518] 85% | Training loss: 0.6870007603285239
Epoch: 49 | Iteration number: [3890/4518] 86% | Training loss: 0.687002756325935
Epoch: 49 | Iteration number: [3900/4518] 86% | Training loss: 0.6870027444912837
Epoch: 49 | Iteration number: [3910/4518] 86% | Training loss: 0.6870022323125463
Epoch: 49 | Iteration number: [3920/4518] 86% | Training loss: 0.6870009942626466
Epoch: 49 | Iteration number: [3930/4518] 86% | Training loss: 0.6869990757858481
Epoch: 49 | Iteration number: [3940/4518] 87% | Training loss: 0.6869987622886745
Epoch: 49 | Iteration number: [3950/4518] 87% | Training loss: 0.6869956568072114
Epoch: 49 | Iteration number: [3960/4518] 87% | Training loss: 0.6869956945680609
Epoch: 49 | Iteration number: [3970/4518] 87% | Training loss: 0.686992482799727
Epoch: 49 | Iteration number: [3980/4518] 88% | Training loss: 0.6869915506947579
Epoch: 49 | Iteration number: [3990/4518] 88% | Training loss: 0.6869931018292754
Epoch: 49 | Iteration number: [4000/4518] 88% | Training loss: 0.6869955930262804
Epoch: 49 | Iteration number: [4010/4518] 88% | Training loss: 0.6869978326811754
Epoch: 49 | Iteration number: [4020/4518] 88% | Training loss: 0.6869986609143405
Epoch: 49 | Iteration number: [4030/4518] 89% | Training loss: 0.6869973333242809
Epoch: 49 | Iteration number: [4040/4518] 89% | Training loss: 0.6869968095185733
Epoch: 49 | Iteration number: [4050/4518] 89% | Training loss: 0.6869969083497554
Epoch: 49 | Iteration number: [4060/4518] 89% | Training loss: 0.6869991511840539
Epoch: 49 | Iteration number: [4070/4518] 90% | Training loss: 0.687001896490336
Epoch: 49 | Iteration number: [4080/4518] 90% | Training loss: 0.6869984444596019
Epoch: 49 | Iteration number: [4090/4518] 90% | Training loss: 0.6869978436193722
Epoch: 49 | Iteration number: [4100/4518] 90% | Training loss: 0.6869952823476093
Epoch: 49 | Iteration number: [4110/4518] 90% | Training loss: 0.6869952063055804
Epoch: 49 | Iteration number: [4120/4518] 91% | Training loss: 0.6869920125140727
Epoch: 49 | Iteration number: [4130/4518] 91% | Training loss: 0.6869963310676972
Epoch: 49 | Iteration number: [4140/4518] 91% | Training loss: 0.6869951466143419
Epoch: 49 | Iteration number: [4150/4518] 91% | Training loss: 0.6869966033136988
Epoch: 49 | Iteration number: [4160/4518] 92% | Training loss: 0.6869960165797517
Epoch: 49 | Iteration number: [4170/4518] 92% | Training loss: 0.6869947637585427
Epoch: 49 | Iteration number: [4180/4518] 92% | Training loss: 0.6869940064455333
Epoch: 49 | Iteration number: [4190/4518] 92% | Training loss: 0.6869938009109589
Epoch: 49 | Iteration number: [4200/4518] 92% | Training loss: 0.6869927694967815
Epoch: 49 | Iteration number: [4210/4518] 93% | Training loss: 0.6869928617517059
Epoch: 49 | Iteration number: [4220/4518] 93% | Training loss: 0.686993299671824
Epoch: 49 | Iteration number: [4230/4518] 93% | Training loss: 0.6869885023744957
Epoch: 49 | Iteration number: [4240/4518] 93% | Training loss: 0.6869885128202303
Epoch: 49 | Iteration number: [4250/4518] 94% | Training loss: 0.6869891102313995
Epoch: 49 | Iteration number: [4260/4518] 94% | Training loss: 0.6869896808560465
Epoch: 49 | Iteration number: [4270/4518] 94% | Training loss: 0.6869864409505902
Epoch: 49 | Iteration number: [4280/4518] 94% | Training loss: 0.6869857466248709
Epoch: 49 | Iteration number: [4290/4518] 94% | Training loss: 0.6869847965268266
Epoch: 49 | Iteration number: [4300/4518] 95% | Training loss: 0.6869862546199976
Epoch: 49 | Iteration number: [4310/4518] 95% | Training loss: 0.6869844673542854
Epoch: 49 | Iteration number: [4320/4518] 95% | Training loss: 0.6869840194505674
Epoch: 49 | Iteration number: [4330/4518] 95% | Training loss: 0.686982446399627
Epoch: 49 | Iteration number: [4340/4518] 96% | Training loss: 0.6869820519938447
Epoch: 49 | Iteration number: [4350/4518] 96% | Training loss: 0.6869815023603111
Epoch: 49 | Iteration number: [4360/4518] 96% | Training loss: 0.686980668831309
Epoch: 49 | Iteration number: [4370/4518] 96% | Training loss: 0.6869816570723902
Epoch: 49 | Iteration number: [4380/4518] 96% | Training loss: 0.6869771726463484
Epoch: 49 | Iteration number: [4390/4518] 97% | Training loss: 0.686974666045304
Epoch: 49 | Iteration number: [4400/4518] 97% | Training loss: 0.6869744449447501
Epoch: 49 | Iteration number: [4410/4518] 97% | Training loss: 0.6869731182954749
Epoch: 49 | Iteration number: [4420/4518] 97% | Training loss: 0.6869740140518991
Epoch: 49 | Iteration number: [4430/4518] 98% | Training loss: 0.6869743775164301
Epoch: 49 | Iteration number: [4440/4518] 98% | Training loss: 0.6869733665440534
Epoch: 49 | Iteration number: [4450/4518] 98% | Training loss: 0.6869722190331877
Epoch: 49 | Iteration number: [4460/4518] 98% | Training loss: 0.6869740465430401
Epoch: 49 | Iteration number: [4470/4518] 98% | Training loss: 0.6869750607867102
Epoch: 49 | Iteration number: [4480/4518] 99% | Training loss: 0.6869752373679407
Epoch: 49 | Iteration number: [4490/4518] 99% | Training loss: 0.6869742371589941
Epoch: 49 | Iteration number: [4500/4518] 99% | Training loss: 0.6869765985541874
Epoch: 49 | Iteration number: [4510/4518] 99% | Training loss: 0.6869771381439497

 End of epoch: 49 | Train Loss: 0.6868233595368292 | Training Time: 642 

 End of epoch: 49 | Eval Loss: 0.6902369370265883 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/4518] 0% | Training loss: 0.7556698143482208
Epoch: 50 | Iteration number: [20/4518] 0% | Training loss: 0.7213856905698777
Epoch: 50 | Iteration number: [30/4518] 0% | Training loss: 0.7103652973969777
Epoch: 50 | Iteration number: [40/4518] 0% | Training loss: 0.704933100938797
Epoch: 50 | Iteration number: [50/4518] 1% | Training loss: 0.7013815784454346
Epoch: 50 | Iteration number: [60/4518] 1% | Training loss: 0.6989758769671123
Epoch: 50 | Iteration number: [70/4518] 1% | Training loss: 0.6970873074872154
Epoch: 50 | Iteration number: [80/4518] 1% | Training loss: 0.695729199051857
Epoch: 50 | Iteration number: [90/4518] 1% | Training loss: 0.6946944210264417
Epoch: 50 | Iteration number: [100/4518] 2% | Training loss: 0.6938120889663696
Epoch: 50 | Iteration number: [110/4518] 2% | Training loss: 0.6931849376721816
Epoch: 50 | Iteration number: [120/4518] 2% | Training loss: 0.6925758788983027
Epoch: 50 | Iteration number: [130/4518] 2% | Training loss: 0.6920562881689806
Epoch: 50 | Iteration number: [140/4518] 3% | Training loss: 0.691707255584853
Epoch: 50 | Iteration number: [150/4518] 3% | Training loss: 0.6912789229551951
Epoch: 50 | Iteration number: [160/4518] 3% | Training loss: 0.6910025954246521
Epoch: 50 | Iteration number: [170/4518] 3% | Training loss: 0.6907991851077361
Epoch: 50 | Iteration number: [180/4518] 3% | Training loss: 0.6906024744113286
Epoch: 50 | Iteration number: [190/4518] 4% | Training loss: 0.6903864305270345
Epoch: 50 | Iteration number: [200/4518] 4% | Training loss: 0.6902125757932663
Epoch: 50 | Iteration number: [210/4518] 4% | Training loss: 0.6901051189218249
Epoch: 50 | Iteration number: [220/4518] 4% | Training loss: 0.6899320513010025
Epoch: 50 | Iteration number: [230/4518] 5% | Training loss: 0.689760193358297
Epoch: 50 | Iteration number: [240/4518] 5% | Training loss: 0.6896774426102639
Epoch: 50 | Iteration number: [250/4518] 5% | Training loss: 0.6896212027072907
Epoch: 50 | Iteration number: [260/4518] 5% | Training loss: 0.6895022905789889
Epoch: 50 | Iteration number: [270/4518] 5% | Training loss: 0.6893656571706136
Epoch: 50 | Iteration number: [280/4518] 6% | Training loss: 0.6893166026898793
Epoch: 50 | Iteration number: [290/4518] 6% | Training loss: 0.6892244232111964
Epoch: 50 | Iteration number: [300/4518] 6% | Training loss: 0.6891822799046834
Epoch: 50 | Iteration number: [310/4518] 6% | Training loss: 0.6890910929249179
Epoch: 50 | Iteration number: [320/4518] 7% | Training loss: 0.6890890289098024
Epoch: 50 | Iteration number: [330/4518] 7% | Training loss: 0.6890358854423869
Epoch: 50 | Iteration number: [340/4518] 7% | Training loss: 0.6890214152195875
Epoch: 50 | Iteration number: [350/4518] 7% | Training loss: 0.6889771051066262
Epoch: 50 | Iteration number: [360/4518] 7% | Training loss: 0.6889347044958009
Epoch: 50 | Iteration number: [370/4518] 8% | Training loss: 0.6888662583119161
Epoch: 50 | Iteration number: [380/4518] 8% | Training loss: 0.6888396823092511
Epoch: 50 | Iteration number: [390/4518] 8% | Training loss: 0.6888169391032977
Epoch: 50 | Iteration number: [400/4518] 8% | Training loss: 0.6887651211023331
Epoch: 50 | Iteration number: [410/4518] 9% | Training loss: 0.6887153978754834
Epoch: 50 | Iteration number: [420/4518] 9% | Training loss: 0.6886705737738382
Epoch: 50 | Iteration number: [430/4518] 9% | Training loss: 0.6886328214822813
Epoch: 50 | Iteration number: [440/4518] 9% | Training loss: 0.6885980998927896
Epoch: 50 | Iteration number: [450/4518] 9% | Training loss: 0.6885526802804735
Epoch: 50 | Iteration number: [460/4518] 10% | Training loss: 0.6885094993788263
Epoch: 50 | Iteration number: [470/4518] 10% | Training loss: 0.6884763413287224
Epoch: 50 | Iteration number: [480/4518] 10% | Training loss: 0.688413139184316
Epoch: 50 | Iteration number: [490/4518] 10% | Training loss: 0.6884020424619013
Epoch: 50 | Iteration number: [500/4518] 11% | Training loss: 0.688371487736702
Epoch: 50 | Iteration number: [510/4518] 11% | Training loss: 0.6883318345920713
Epoch: 50 | Iteration number: [520/4518] 11% | Training loss: 0.6883097303601412
Epoch: 50 | Iteration number: [530/4518] 11% | Training loss: 0.6882814165556206
Epoch: 50 | Iteration number: [540/4518] 11% | Training loss: 0.6882384383016162
Epoch: 50 | Iteration number: [550/4518] 12% | Training loss: 0.6882075884125449
Epoch: 50 | Iteration number: [560/4518] 12% | Training loss: 0.6881951789770807
Epoch: 50 | Iteration number: [570/4518] 12% | Training loss: 0.68817899070288
Epoch: 50 | Iteration number: [580/4518] 12% | Training loss: 0.688147894575678
Epoch: 50 | Iteration number: [590/4518] 13% | Training loss: 0.6881281371844017
Epoch: 50 | Iteration number: [600/4518] 13% | Training loss: 0.6880927218000094
Epoch: 50 | Iteration number: [610/4518] 13% | Training loss: 0.6880690909799982
Epoch: 50 | Iteration number: [620/4518] 13% | Training loss: 0.6880433627674657
Epoch: 50 | Iteration number: [630/4518] 13% | Training loss: 0.6880148815730261
Epoch: 50 | Iteration number: [640/4518] 14% | Training loss: 0.6879872578196228
Epoch: 50 | Iteration number: [650/4518] 14% | Training loss: 0.6879817796670473
Epoch: 50 | Iteration number: [660/4518] 14% | Training loss: 0.6879688793962652
Epoch: 50 | Iteration number: [670/4518] 14% | Training loss: 0.6879416471097006
Epoch: 50 | Iteration number: [680/4518] 15% | Training loss: 0.6879299358409994
Epoch: 50 | Iteration number: [690/4518] 15% | Training loss: 0.6879118411437325
Epoch: 50 | Iteration number: [700/4518] 15% | Training loss: 0.6878965076378414
Epoch: 50 | Iteration number: [710/4518] 15% | Training loss: 0.6878827248660612
Epoch: 50 | Iteration number: [720/4518] 15% | Training loss: 0.6878568817343976
Epoch: 50 | Iteration number: [730/4518] 16% | Training loss: 0.6878359610087251
Epoch: 50 | Iteration number: [740/4518] 16% | Training loss: 0.6878141507909105
Epoch: 50 | Iteration number: [750/4518] 16% | Training loss: 0.6878113581339518
Epoch: 50 | Iteration number: [760/4518] 16% | Training loss: 0.6877993990716181
Epoch: 50 | Iteration number: [770/4518] 17% | Training loss: 0.6877811835957812
Epoch: 50 | Iteration number: [780/4518] 17% | Training loss: 0.6877593832138257
Epoch: 50 | Iteration number: [790/4518] 17% | Training loss: 0.6877360159837747
Epoch: 50 | Iteration number: [800/4518] 17% | Training loss: 0.687740130648017
Epoch: 50 | Iteration number: [810/4518] 17% | Training loss: 0.6877303187493925
Epoch: 50 | Iteration number: [820/4518] 18% | Training loss: 0.6877154622136092
Epoch: 50 | Iteration number: [830/4518] 18% | Training loss: 0.6876889546233488
Epoch: 50 | Iteration number: [840/4518] 18% | Training loss: 0.6876738346758343
Epoch: 50 | Iteration number: [850/4518] 18% | Training loss: 0.6876667472895454
Epoch: 50 | Iteration number: [860/4518] 19% | Training loss: 0.6876506056203399
Epoch: 50 | Iteration number: [870/4518] 19% | Training loss: 0.6876248106189158
Epoch: 50 | Iteration number: [880/4518] 19% | Training loss: 0.6876165910877965
Epoch: 50 | Iteration number: [890/4518] 19% | Training loss: 0.6876027207696036
Epoch: 50 | Iteration number: [900/4518] 19% | Training loss: 0.6875819784402847
Epoch: 50 | Iteration number: [910/4518] 20% | Training loss: 0.6875807350153451
Epoch: 50 | Iteration number: [920/4518] 20% | Training loss: 0.6875624267303425
Epoch: 50 | Iteration number: [930/4518] 20% | Training loss: 0.6875589005408749
Epoch: 50 | Iteration number: [940/4518] 20% | Training loss: 0.6875403996477736
Epoch: 50 | Iteration number: [950/4518] 21% | Training loss: 0.6875335810058996
Epoch: 50 | Iteration number: [960/4518] 21% | Training loss: 0.6875314209610224
Epoch: 50 | Iteration number: [970/4518] 21% | Training loss: 0.6875370284331214
Epoch: 50 | Iteration number: [980/4518] 21% | Training loss: 0.6875304858903496
Epoch: 50 | Iteration number: [990/4518] 21% | Training loss: 0.6875013889086367
Epoch: 50 | Iteration number: [1000/4518] 22% | Training loss: 0.687490484714508
Epoch: 50 | Iteration number: [1010/4518] 22% | Training loss: 0.6874867922008627
Epoch: 50 | Iteration number: [1020/4518] 22% | Training loss: 0.6874659232649148
Epoch: 50 | Iteration number: [1030/4518] 22% | Training loss: 0.6874659285962003
Epoch: 50 | Iteration number: [1040/4518] 23% | Training loss: 0.6874639742649519
Epoch: 50 | Iteration number: [1050/4518] 23% | Training loss: 0.6874564003944397
Epoch: 50 | Iteration number: [1060/4518] 23% | Training loss: 0.6874494301260642
Epoch: 50 | Iteration number: [1070/4518] 23% | Training loss: 0.6874518016231395
Epoch: 50 | Iteration number: [1080/4518] 23% | Training loss: 0.687450046175056
Epoch: 50 | Iteration number: [1090/4518] 24% | Training loss: 0.6874525170260614
Epoch: 50 | Iteration number: [1100/4518] 24% | Training loss: 0.6874554241787304
Epoch: 50 | Iteration number: [1110/4518] 24% | Training loss: 0.6874462730712719
Epoch: 50 | Iteration number: [1120/4518] 24% | Training loss: 0.6874390095472336
Epoch: 50 | Iteration number: [1130/4518] 25% | Training loss: 0.6874366319812505
Epoch: 50 | Iteration number: [1140/4518] 25% | Training loss: 0.6874229412852673
Epoch: 50 | Iteration number: [1150/4518] 25% | Training loss: 0.687413980598035
Epoch: 50 | Iteration number: [1160/4518] 25% | Training loss: 0.6874085835855582
Epoch: 50 | Iteration number: [1170/4518] 25% | Training loss: 0.6874069747761783
Epoch: 50 | Iteration number: [1180/4518] 26% | Training loss: 0.6874017517950575
Epoch: 50 | Iteration number: [1190/4518] 26% | Training loss: 0.6873788202009281
Epoch: 50 | Iteration number: [1200/4518] 26% | Training loss: 0.6873779932657877
Epoch: 50 | Iteration number: [1210/4518] 26% | Training loss: 0.6873697836537006
Epoch: 50 | Iteration number: [1220/4518] 27% | Training loss: 0.6873675594075781
Epoch: 50 | Iteration number: [1230/4518] 27% | Training loss: 0.6873590258078847
Epoch: 50 | Iteration number: [1240/4518] 27% | Training loss: 0.6873588903296378
Epoch: 50 | Iteration number: [1250/4518] 27% | Training loss: 0.6873568623065949
Epoch: 50 | Iteration number: [1260/4518] 27% | Training loss: 0.6873525670123479
Epoch: 50 | Iteration number: [1270/4518] 28% | Training loss: 0.6873513435284923
Epoch: 50 | Iteration number: [1280/4518] 28% | Training loss: 0.6873495324514807
Epoch: 50 | Iteration number: [1290/4518] 28% | Training loss: 0.687337698215662
Epoch: 50 | Iteration number: [1300/4518] 28% | Training loss: 0.6873313860251353
Epoch: 50 | Iteration number: [1310/4518] 28% | Training loss: 0.6873196677852222
Epoch: 50 | Iteration number: [1320/4518] 29% | Training loss: 0.6873098813223116
Epoch: 50 | Iteration number: [1330/4518] 29% | Training loss: 0.6873032822196645
Epoch: 50 | Iteration number: [1340/4518] 29% | Training loss: 0.6872949077122247
Epoch: 50 | Iteration number: [1350/4518] 29% | Training loss: 0.6872970582379235
Epoch: 50 | Iteration number: [1360/4518] 30% | Training loss: 0.6872952706235297
Epoch: 50 | Iteration number: [1370/4518] 30% | Training loss: 0.6872871240560156
Epoch: 50 | Iteration number: [1380/4518] 30% | Training loss: 0.6872800281082374
Epoch: 50 | Iteration number: [1390/4518] 30% | Training loss: 0.6872812792980414
Epoch: 50 | Iteration number: [1400/4518] 30% | Training loss: 0.687275388794286
Epoch: 50 | Iteration number: [1410/4518] 31% | Training loss: 0.6872785749164879
Epoch: 50 | Iteration number: [1420/4518] 31% | Training loss: 0.6872737914743557
Epoch: 50 | Iteration number: [1430/4518] 31% | Training loss: 0.6872724360519356
Epoch: 50 | Iteration number: [1440/4518] 31% | Training loss: 0.6872781398809619
Epoch: 50 | Iteration number: [1450/4518] 32% | Training loss: 0.6872721515441763
Epoch: 50 | Iteration number: [1460/4518] 32% | Training loss: 0.6872631136685201
Epoch: 50 | Iteration number: [1470/4518] 32% | Training loss: 0.6872649809535669
Epoch: 50 | Iteration number: [1480/4518] 32% | Training loss: 0.6872536908130388
Epoch: 50 | Iteration number: [1490/4518] 32% | Training loss: 0.6872568909353858
Epoch: 50 | Iteration number: [1500/4518] 33% | Training loss: 0.6872557052373887
Epoch: 50 | Iteration number: [1510/4518] 33% | Training loss: 0.687257605080573
Epoch: 50 | Iteration number: [1520/4518] 33% | Training loss: 0.6872485261998679
Epoch: 50 | Iteration number: [1530/4518] 33% | Training loss: 0.6872510164002188
Epoch: 50 | Iteration number: [1540/4518] 34% | Training loss: 0.687248975967432
Epoch: 50 | Iteration number: [1550/4518] 34% | Training loss: 0.6872492852903181
Epoch: 50 | Iteration number: [1560/4518] 34% | Training loss: 0.6872454188190974
Epoch: 50 | Iteration number: [1570/4518] 34% | Training loss: 0.6872447978159425
Epoch: 50 | Iteration number: [1580/4518] 34% | Training loss: 0.6872472915845581
Epoch: 50 | Iteration number: [1590/4518] 35% | Training loss: 0.6872393389542898
Epoch: 50 | Iteration number: [1600/4518] 35% | Training loss: 0.6872332832217216
Epoch: 50 | Iteration number: [1610/4518] 35% | Training loss: 0.6872301450057059
Epoch: 50 | Iteration number: [1620/4518] 35% | Training loss: 0.6872255322741874
Epoch: 50 | Iteration number: [1630/4518] 36% | Training loss: 0.687224619593357
Epoch: 50 | Iteration number: [1640/4518] 36% | Training loss: 0.6872189240848146
Epoch: 50 | Iteration number: [1650/4518] 36% | Training loss: 0.6872203344287294
Epoch: 50 | Iteration number: [1660/4518] 36% | Training loss: 0.6872204915945789
Epoch: 50 | Iteration number: [1670/4518] 36% | Training loss: 0.6872136642119128
Epoch: 50 | Iteration number: [1680/4518] 37% | Training loss: 0.6872096645335356
Epoch: 50 | Iteration number: [1690/4518] 37% | Training loss: 0.687207132366282
Epoch: 50 | Iteration number: [1700/4518] 37% | Training loss: 0.68719837150153
Epoch: 50 | Iteration number: [1710/4518] 37% | Training loss: 0.6871857619425009
Epoch: 50 | Iteration number: [1720/4518] 38% | Training loss: 0.6871805842186129
Epoch: 50 | Iteration number: [1730/4518] 38% | Training loss: 0.687174149021248
Epoch: 50 | Iteration number: [1740/4518] 38% | Training loss: 0.6871745699781111
Epoch: 50 | Iteration number: [1750/4518] 38% | Training loss: 0.6871766668047223
Epoch: 50 | Iteration number: [1760/4518] 38% | Training loss: 0.6871696834875779
Epoch: 50 | Iteration number: [1770/4518] 39% | Training loss: 0.6871637161168676
Epoch: 50 | Iteration number: [1780/4518] 39% | Training loss: 0.687155887551522
Epoch: 50 | Iteration number: [1790/4518] 39% | Training loss: 0.6871488808586611
Epoch: 50 | Iteration number: [1800/4518] 39% | Training loss: 0.68714785973231
Epoch: 50 | Iteration number: [1810/4518] 40% | Training loss: 0.6871483228483253
Epoch: 50 | Iteration number: [1820/4518] 40% | Training loss: 0.6871491440377393
Epoch: 50 | Iteration number: [1830/4518] 40% | Training loss: 0.6871522364394912
Epoch: 50 | Iteration number: [1840/4518] 40% | Training loss: 0.6871561830458434
Epoch: 50 | Iteration number: [1850/4518] 40% | Training loss: 0.6871544415241964
Epoch: 50 | Iteration number: [1860/4518] 41% | Training loss: 0.6871558132351085
Epoch: 50 | Iteration number: [1870/4518] 41% | Training loss: 0.6871550685900418
Epoch: 50 | Iteration number: [1880/4518] 41% | Training loss: 0.6871554530681447
Epoch: 50 | Iteration number: [1890/4518] 41% | Training loss: 0.6871557940250982
Epoch: 50 | Iteration number: [1900/4518] 42% | Training loss: 0.6871526195187317
Epoch: 50 | Iteration number: [1910/4518] 42% | Training loss: 0.6871495409785765
Epoch: 50 | Iteration number: [1920/4518] 42% | Training loss: 0.6871494573851427
Epoch: 50 | Iteration number: [1930/4518] 42% | Training loss: 0.6871449044022535
Epoch: 50 | Iteration number: [1940/4518] 42% | Training loss: 0.6871481153768363
Epoch: 50 | Iteration number: [1950/4518] 43% | Training loss: 0.687149094312619
Epoch: 50 | Iteration number: [1960/4518] 43% | Training loss: 0.6871461871935397
Epoch: 50 | Iteration number: [1970/4518] 43% | Training loss: 0.6871408970827984
Epoch: 50 | Iteration number: [1980/4518] 43% | Training loss: 0.6871378003647833
Epoch: 50 | Iteration number: [1990/4518] 44% | Training loss: 0.6871363847698998
Epoch: 50 | Iteration number: [2000/4518] 44% | Training loss: 0.6871360402405262
Epoch: 50 | Iteration number: [2010/4518] 44% | Training loss: 0.6871382187848067
Epoch: 50 | Iteration number: [2020/4518] 44% | Training loss: 0.6871389335039819
Epoch: 50 | Iteration number: [2030/4518] 44% | Training loss: 0.6871384794782536
Epoch: 50 | Iteration number: [2040/4518] 45% | Training loss: 0.6871343750579685
Epoch: 50 | Iteration number: [2050/4518] 45% | Training loss: 0.6871313143357998
Epoch: 50 | Iteration number: [2060/4518] 45% | Training loss: 0.6871322611871274
Epoch: 50 | Iteration number: [2070/4518] 45% | Training loss: 0.6871361028169088
Epoch: 50 | Iteration number: [2080/4518] 46% | Training loss: 0.6871313177622281
Epoch: 50 | Iteration number: [2090/4518] 46% | Training loss: 0.6871246826135371
Epoch: 50 | Iteration number: [2100/4518] 46% | Training loss: 0.6871240228130704
Epoch: 50 | Iteration number: [2110/4518] 46% | Training loss: 0.6871286511421204
Epoch: 50 | Iteration number: [2120/4518] 46% | Training loss: 0.6871247817604047
Epoch: 50 | Iteration number: [2130/4518] 47% | Training loss: 0.6871229623405026
Epoch: 50 | Iteration number: [2140/4518] 47% | Training loss: 0.687125161735811
Epoch: 50 | Iteration number: [2150/4518] 47% | Training loss: 0.6871211686799693
Epoch: 50 | Iteration number: [2160/4518] 47% | Training loss: 0.6871236605500733
Epoch: 50 | Iteration number: [2170/4518] 48% | Training loss: 0.6871224033393069
Epoch: 50 | Iteration number: [2180/4518] 48% | Training loss: 0.687118393866294
Epoch: 50 | Iteration number: [2190/4518] 48% | Training loss: 0.6871203687365197
Epoch: 50 | Iteration number: [2200/4518] 48% | Training loss: 0.687125229510394
Epoch: 50 | Iteration number: [2210/4518] 48% | Training loss: 0.6871239633851461
Epoch: 50 | Iteration number: [2220/4518] 49% | Training loss: 0.6871232383691512
Epoch: 50 | Iteration number: [2230/4518] 49% | Training loss: 0.6871257241531338
Epoch: 50 | Iteration number: [2240/4518] 49% | Training loss: 0.6871251574850508
Epoch: 50 | Iteration number: [2250/4518] 49% | Training loss: 0.6871222705576155
Epoch: 50 | Iteration number: [2260/4518] 50% | Training loss: 0.6871171478940322
Epoch: 50 | Iteration number: [2270/4518] 50% | Training loss: 0.6871139790518168
Epoch: 50 | Iteration number: [2280/4518] 50% | Training loss: 0.6871087232179809
Epoch: 50 | Iteration number: [2290/4518] 50% | Training loss: 0.6871094420226901
Epoch: 50 | Iteration number: [2300/4518] 50% | Training loss: 0.6871080339473227
Epoch: 50 | Iteration number: [2310/4518] 51% | Training loss: 0.6871014255981941
Epoch: 50 | Iteration number: [2320/4518] 51% | Training loss: 0.687101515485295
Epoch: 50 | Iteration number: [2330/4518] 51% | Training loss: 0.6870921080460364
Epoch: 50 | Iteration number: [2340/4518] 51% | Training loss: 0.6870948676115427
Epoch: 50 | Iteration number: [2350/4518] 52% | Training loss: 0.6870930077420905
Epoch: 50 | Iteration number: [2360/4518] 52% | Training loss: 0.6870912104339922
Epoch: 50 | Iteration number: [2370/4518] 52% | Training loss: 0.6870888851362945
Epoch: 50 | Iteration number: [2380/4518] 52% | Training loss: 0.6870911574914675
Epoch: 50 | Iteration number: [2390/4518] 52% | Training loss: 0.6870918194369791
Epoch: 50 | Iteration number: [2400/4518] 53% | Training loss: 0.6870877075443665
Epoch: 50 | Iteration number: [2410/4518] 53% | Training loss: 0.6870869643460665
Epoch: 50 | Iteration number: [2420/4518] 53% | Training loss: 0.6870810263905643
Epoch: 50 | Iteration number: [2430/4518] 53% | Training loss: 0.6870786944289267
Epoch: 50 | Iteration number: [2440/4518] 54% | Training loss: 0.6870812832820611
Epoch: 50 | Iteration number: [2450/4518] 54% | Training loss: 0.6870847501803418
Epoch: 50 | Iteration number: [2460/4518] 54% | Training loss: 0.6870831622825405
Epoch: 50 | Iteration number: [2470/4518] 54% | Training loss: 0.6870806055754303
Epoch: 50 | Iteration number: [2480/4518] 54% | Training loss: 0.6870824978716912
Epoch: 50 | Iteration number: [2490/4518] 55% | Training loss: 0.687084410013444
Epoch: 50 | Iteration number: [2500/4518] 55% | Training loss: 0.6870828596591949
Epoch: 50 | Iteration number: [2510/4518] 55% | Training loss: 0.6870833071579496
Epoch: 50 | Iteration number: [2520/4518] 55% | Training loss: 0.6870852341254552
Epoch: 50 | Iteration number: [2530/4518] 55% | Training loss: 0.6870866488091089
Epoch: 50 | Iteration number: [2540/4518] 56% | Training loss: 0.6870797135229186
Epoch: 50 | Iteration number: [2550/4518] 56% | Training loss: 0.6870751435850181
Epoch: 50 | Iteration number: [2560/4518] 56% | Training loss: 0.6870701585197821
Epoch: 50 | Iteration number: [2570/4518] 56% | Training loss: 0.6870704228312124
Epoch: 50 | Iteration number: [2580/4518] 57% | Training loss: 0.6870719798775606
Epoch: 50 | Iteration number: [2590/4518] 57% | Training loss: 0.6870688941257801
Epoch: 50 | Iteration number: [2600/4518] 57% | Training loss: 0.6870696742947285
Epoch: 50 | Iteration number: [2610/4518] 57% | Training loss: 0.6870678713038507
Epoch: 50 | Iteration number: [2620/4518] 57% | Training loss: 0.6870682655854989
Epoch: 50 | Iteration number: [2630/4518] 58% | Training loss: 0.6870657200822359
Epoch: 50 | Iteration number: [2640/4518] 58% | Training loss: 0.6870641342618249
Epoch: 50 | Iteration number: [2650/4518] 58% | Training loss: 0.6870619479440293
Epoch: 50 | Iteration number: [2660/4518] 58% | Training loss: 0.6870617686581791
Epoch: 50 | Iteration number: [2670/4518] 59% | Training loss: 0.6870609218708138
Epoch: 50 | Iteration number: [2680/4518] 59% | Training loss: 0.6870652496147511
Epoch: 50 | Iteration number: [2690/4518] 59% | Training loss: 0.6870703418458705
Epoch: 50 | Iteration number: [2700/4518] 59% | Training loss: 0.6870708190511774
Epoch: 50 | Iteration number: [2710/4518] 59% | Training loss: 0.687070742524418
Epoch: 50 | Iteration number: [2720/4518] 60% | Training loss: 0.687069328523734
Epoch: 50 | Iteration number: [2730/4518] 60% | Training loss: 0.6870697875599284
Epoch: 50 | Iteration number: [2740/4518] 60% | Training loss: 0.6870647781086664
Epoch: 50 | Iteration number: [2750/4518] 60% | Training loss: 0.6870650398297743
Epoch: 50 | Iteration number: [2760/4518] 61% | Training loss: 0.6870631406056709
Epoch: 50 | Iteration number: [2770/4518] 61% | Training loss: 0.6870618627174666
Epoch: 50 | Iteration number: [2780/4518] 61% | Training loss: 0.6870576914051454
Epoch: 50 | Iteration number: [2790/4518] 61% | Training loss: 0.6870529731114705
Epoch: 50 | Iteration number: [2800/4518] 61% | Training loss: 0.6870533835036414
Epoch: 50 | Iteration number: [2810/4518] 62% | Training loss: 0.6870564899198526
Epoch: 50 | Iteration number: [2820/4518] 62% | Training loss: 0.6870579415390677
Epoch: 50 | Iteration number: [2830/4518] 62% | Training loss: 0.6870532294254842
Epoch: 50 | Iteration number: [2840/4518] 62% | Training loss: 0.6870488936842327
Epoch: 50 | Iteration number: [2850/4518] 63% | Training loss: 0.6870509961404299
Epoch: 50 | Iteration number: [2860/4518] 63% | Training loss: 0.6870462846922708
Epoch: 50 | Iteration number: [2870/4518] 63% | Training loss: 0.6870446673046006
Epoch: 50 | Iteration number: [2880/4518] 63% | Training loss: 0.6870437871457802
Epoch: 50 | Iteration number: [2890/4518] 63% | Training loss: 0.6870394264744227
Epoch: 50 | Iteration number: [2900/4518] 64% | Training loss: 0.6870378668143832
Epoch: 50 | Iteration number: [2910/4518] 64% | Training loss: 0.6870415301052566
Epoch: 50 | Iteration number: [2920/4518] 64% | Training loss: 0.6870417999486401
Epoch: 50 | Iteration number: [2930/4518] 64% | Training loss: 0.6870373740741418
Epoch: 50 | Iteration number: [2940/4518] 65% | Training loss: 0.6870335502081177
Epoch: 50 | Iteration number: [2950/4518] 65% | Training loss: 0.687033309633449
Epoch: 50 | Iteration number: [2960/4518] 65% | Training loss: 0.6870347788406385
Epoch: 50 | Iteration number: [2970/4518] 65% | Training loss: 0.6870341901425963
Epoch: 50 | Iteration number: [2980/4518] 65% | Training loss: 0.6870327118459164
Epoch: 50 | Iteration number: [2990/4518] 66% | Training loss: 0.687028797215044
Epoch: 50 | Iteration number: [3000/4518] 66% | Training loss: 0.687028162141641
Epoch: 50 | Iteration number: [3010/4518] 66% | Training loss: 0.6870277606767673
Epoch: 50 | Iteration number: [3020/4518] 66% | Training loss: 0.6870297207934967
Epoch: 50 | Iteration number: [3030/4518] 67% | Training loss: 0.6870290599837161
Epoch: 50 | Iteration number: [3040/4518] 67% | Training loss: 0.6870275617430085
Epoch: 50 | Iteration number: [3050/4518] 67% | Training loss: 0.6870222713712786
Epoch: 50 | Iteration number: [3060/4518] 67% | Training loss: 0.6870236843045241
Epoch: 50 | Iteration number: [3070/4518] 67% | Training loss: 0.6870244396625979
Epoch: 50 | Iteration number: [3080/4518] 68% | Training loss: 0.6870231936504314
Epoch: 50 | Iteration number: [3090/4518] 68% | Training loss: 0.687022936170541
Epoch: 50 | Iteration number: [3100/4518] 68% | Training loss: 0.6870195221516394
Epoch: 50 | Iteration number: [3110/4518] 68% | Training loss: 0.6870160821549762
Epoch: 50 | Iteration number: [3120/4518] 69% | Training loss: 0.6870167015836789
Epoch: 50 | Iteration number: [3130/4518] 69% | Training loss: 0.6870137397473612
Epoch: 50 | Iteration number: [3140/4518] 69% | Training loss: 0.6870101619867762
Epoch: 50 | Iteration number: [3150/4518] 69% | Training loss: 0.6870095500113472
Epoch: 50 | Iteration number: [3160/4518] 69% | Training loss: 0.687013775713836
Epoch: 50 | Iteration number: [3170/4518] 70% | Training loss: 0.6870115024434279
Epoch: 50 | Iteration number: [3180/4518] 70% | Training loss: 0.6870163973959736
Epoch: 50 | Iteration number: [3190/4518] 70% | Training loss: 0.6870148909129319
Epoch: 50 | Iteration number: [3200/4518] 70% | Training loss: 0.6870140488259494
Epoch: 50 | Iteration number: [3210/4518] 71% | Training loss: 0.687011734254635
Epoch: 50 | Iteration number: [3220/4518] 71% | Training loss: 0.6870097046313078
Epoch: 50 | Iteration number: [3230/4518] 71% | Training loss: 0.6870091068670846
Epoch: 50 | Iteration number: [3240/4518] 71% | Training loss: 0.6870059653932665
Epoch: 50 | Iteration number: [3250/4518] 71% | Training loss: 0.687005123413526
Epoch: 50 | Iteration number: [3260/4518] 72% | Training loss: 0.6870036006156652
Epoch: 50 | Iteration number: [3270/4518] 72% | Training loss: 0.6870023616410177
Epoch: 50 | Iteration number: [3280/4518] 72% | Training loss: 0.6870011697273429
Epoch: 50 | Iteration number: [3290/4518] 72% | Training loss: 0.6870012699833032
Epoch: 50 | Iteration number: [3300/4518] 73% | Training loss: 0.6870033941305045
Epoch: 50 | Iteration number: [3310/4518] 73% | Training loss: 0.6870053444744237
Epoch: 50 | Iteration number: [3320/4518] 73% | Training loss: 0.6870081117354243
Epoch: 50 | Iteration number: [3330/4518] 73% | Training loss: 0.6870067750906443
Epoch: 50 | Iteration number: [3340/4518] 73% | Training loss: 0.6870047498070552
Epoch: 50 | Iteration number: [3350/4518] 74% | Training loss: 0.687001773207935
Epoch: 50 | Iteration number: [3360/4518] 74% | Training loss: 0.687003153793159
Epoch: 50 | Iteration number: [3370/4518] 74% | Training loss: 0.6870028899755959
Epoch: 50 | Iteration number: [3380/4518] 74% | Training loss: 0.6870039849062644
Epoch: 50 | Iteration number: [3390/4518] 75% | Training loss: 0.6870022847589138
Epoch: 50 | Iteration number: [3400/4518] 75% | Training loss: 0.6869996778228704
Epoch: 50 | Iteration number: [3410/4518] 75% | Training loss: 0.6869975480341142
Epoch: 50 | Iteration number: [3420/4518] 75% | Training loss: 0.6869966758622064
Epoch: 50 | Iteration number: [3430/4518] 75% | Training loss: 0.6869956606852418
Epoch: 50 | Iteration number: [3440/4518] 76% | Training loss: 0.6869944393634796
Epoch: 50 | Iteration number: [3450/4518] 76% | Training loss: 0.6869979029116423
Epoch: 50 | Iteration number: [3460/4518] 76% | Training loss: 0.6869996200579439
Epoch: 50 | Iteration number: [3470/4518] 76% | Training loss: 0.6869979270597013
Epoch: 50 | Iteration number: [3480/4518] 77% | Training loss: 0.6869999860723813
Epoch: 50 | Iteration number: [3490/4518] 77% | Training loss: 0.687000933759192
Epoch: 50 | Iteration number: [3500/4518] 77% | Training loss: 0.686998525432178
Epoch: 50 | Iteration number: [3510/4518] 77% | Training loss: 0.6870000169317947
Epoch: 50 | Iteration number: [3520/4518] 77% | Training loss: 0.6870029182765972
Epoch: 50 | Iteration number: [3530/4518] 78% | Training loss: 0.6870034308676679
Epoch: 50 | Iteration number: [3540/4518] 78% | Training loss: 0.6870014303821629
Epoch: 50 | Iteration number: [3550/4518] 78% | Training loss: 0.687000814743445
Epoch: 50 | Iteration number: [3560/4518] 78% | Training loss: 0.6870016251387221
Epoch: 50 | Iteration number: [3570/4518] 79% | Training loss: 0.6870062977826896
Epoch: 50 | Iteration number: [3580/4518] 79% | Training loss: 0.6870052273380024
Epoch: 50 | Iteration number: [3590/4518] 79% | Training loss: 0.687004571389355
Epoch: 50 | Iteration number: [3600/4518] 79% | Training loss: 0.687002784775363
Epoch: 50 | Iteration number: [3610/4518] 79% | Training loss: 0.6869991013052721
Epoch: 50 | Iteration number: [3620/4518] 80% | Training loss: 0.6869997529529076
Epoch: 50 | Iteration number: [3630/4518] 80% | Training loss: 0.6869983119577088
Epoch: 50 | Iteration number: [3640/4518] 80% | Training loss: 0.6869975567191512
Epoch: 50 | Iteration number: [3650/4518] 80% | Training loss: 0.6869965497924857
Epoch: 50 | Iteration number: [3660/4518] 81% | Training loss: 0.6869982791402952
Epoch: 50 | Iteration number: [3670/4518] 81% | Training loss: 0.6869944877455605
Epoch: 50 | Iteration number: [3680/4518] 81% | Training loss: 0.6869927356424539
Epoch: 50 | Iteration number: [3690/4518] 81% | Training loss: 0.6869936016355427
Epoch: 50 | Iteration number: [3700/4518] 81% | Training loss: 0.6869948327219164
Epoch: 50 | Iteration number: [3710/4518] 82% | Training loss: 0.6869927903391281
Epoch: 50 | Iteration number: [3720/4518] 82% | Training loss: 0.6869924600085905
Epoch: 50 | Iteration number: [3730/4518] 82% | Training loss: 0.6869917173967285
Epoch: 50 | Iteration number: [3740/4518] 82% | Training loss: 0.6869926960869907
Epoch: 50 | Iteration number: [3750/4518] 83% | Training loss: 0.6869929550329844
Epoch: 50 | Iteration number: [3760/4518] 83% | Training loss: 0.6869938637664977
Epoch: 50 | Iteration number: [3770/4518] 83% | Training loss: 0.6869942759803499
Epoch: 50 | Iteration number: [3780/4518] 83% | Training loss: 0.6869930390012328
Epoch: 50 | Iteration number: [3790/4518] 83% | Training loss: 0.6869933979177852
Epoch: 50 | Iteration number: [3800/4518] 84% | Training loss: 0.686994927839229
Epoch: 50 | Iteration number: [3810/4518] 84% | Training loss: 0.6869969298051098
Epoch: 50 | Iteration number: [3820/4518] 84% | Training loss: 0.6869965192223094
Epoch: 50 | Iteration number: [3830/4518] 84% | Training loss: 0.6869994599732033
Epoch: 50 | Iteration number: [3840/4518] 84% | Training loss: 0.6869986943590144
Epoch: 50 | Iteration number: [3850/4518] 85% | Training loss: 0.6869958702465156
Epoch: 50 | Iteration number: [3860/4518] 85% | Training loss: 0.6869989856691558
Epoch: 50 | Iteration number: [3870/4518] 85% | Training loss: 0.6869922324206478
Epoch: 50 | Iteration number: [3880/4518] 85% | Training loss: 0.6869929339928725
Epoch: 50 | Iteration number: [3890/4518] 86% | Training loss: 0.6869946817965618
Epoch: 50 | Iteration number: [3900/4518] 86% | Training loss: 0.6869926868952237
Epoch: 50 | Iteration number: [3910/4518] 86% | Training loss: 0.6869902710323139
Epoch: 50 | Iteration number: [3920/4518] 86% | Training loss: 0.6869926747314784
Epoch: 50 | Iteration number: [3930/4518] 86% | Training loss: 0.6869912347569114
Epoch: 50 | Iteration number: [3940/4518] 87% | Training loss: 0.686989798975475
Epoch: 50 | Iteration number: [3950/4518] 87% | Training loss: 0.6869868269600445
Epoch: 50 | Iteration number: [3960/4518] 87% | Training loss: 0.6869815643237095
Epoch: 50 | Iteration number: [3970/4518] 87% | Training loss: 0.6869772122248594
Epoch: 50 | Iteration number: [3980/4518] 88% | Training loss: 0.6869748279527204
Epoch: 50 | Iteration number: [3990/4518] 88% | Training loss: 0.6869757293160995
Epoch: 50 | Iteration number: [4000/4518] 88% | Training loss: 0.6869772682338953
Epoch: 50 | Iteration number: [4010/4518] 88% | Training loss: 0.6869750385272533
Epoch: 50 | Iteration number: [4020/4518] 88% | Training loss: 0.6869753265410513
Epoch: 50 | Iteration number: [4030/4518] 89% | Training loss: 0.6869748373777044
Epoch: 50 | Iteration number: [4040/4518] 89% | Training loss: 0.6869742550767294
Epoch: 50 | Iteration number: [4050/4518] 89% | Training loss: 0.6869747903906269
Epoch: 50 | Iteration number: [4060/4518] 89% | Training loss: 0.6869765346420222
Epoch: 50 | Iteration number: [4070/4518] 90% | Training loss: 0.6869727150081709
Epoch: 50 | Iteration number: [4080/4518] 90% | Training loss: 0.6869704724526873
Epoch: 50 | Iteration number: [4090/4518] 90% | Training loss: 0.6869714766959398
Epoch: 50 | Iteration number: [4100/4518] 90% | Training loss: 0.6869729415963336
Epoch: 50 | Iteration number: [4110/4518] 90% | Training loss: 0.686976195686925
Epoch: 50 | Iteration number: [4120/4518] 91% | Training loss: 0.6869753592945997
Epoch: 50 | Iteration number: [4130/4518] 91% | Training loss: 0.6869744139491213
Epoch: 50 | Iteration number: [4140/4518] 91% | Training loss: 0.6869753520413874
Epoch: 50 | Iteration number: [4150/4518] 91% | Training loss: 0.686975110697459
Epoch: 50 | Iteration number: [4160/4518] 92% | Training loss: 0.6869788782097972
Epoch: 50 | Iteration number: [4170/4518] 92% | Training loss: 0.6869792677372766
Epoch: 50 | Iteration number: [4180/4518] 92% | Training loss: 0.6869808146828099
Epoch: 50 | Iteration number: [4190/4518] 92% | Training loss: 0.6869769523564841
Epoch: 50 | Iteration number: [4200/4518] 92% | Training loss: 0.6869729317511831
Epoch: 50 | Iteration number: [4210/4518] 93% | Training loss: 0.6869723204903818
Epoch: 50 | Iteration number: [4220/4518] 93% | Training loss: 0.6869717528328512
Epoch: 50 | Iteration number: [4230/4518] 93% | Training loss: 0.6869723631839662
Epoch: 50 | Iteration number: [4240/4518] 93% | Training loss: 0.6869729416831485
Epoch: 50 | Iteration number: [4250/4518] 94% | Training loss: 0.6869712319093592
Epoch: 50 | Iteration number: [4260/4518] 94% | Training loss: 0.6869690656801904
Epoch: 50 | Iteration number: [4270/4518] 94% | Training loss: 0.6869660677759094
Epoch: 50 | Iteration number: [4280/4518] 94% | Training loss: 0.6869698456096872
Epoch: 50 | Iteration number: [4290/4518] 94% | Training loss: 0.6869686457243833
Epoch: 50 | Iteration number: [4300/4518] 95% | Training loss: 0.6869676213902096
Epoch: 50 | Iteration number: [4310/4518] 95% | Training loss: 0.686965860346907
Epoch: 50 | Iteration number: [4320/4518] 95% | Training loss: 0.6869671828630898
Epoch: 50 | Iteration number: [4330/4518] 95% | Training loss: 0.6869711699992349
Epoch: 50 | Iteration number: [4340/4518] 96% | Training loss: 0.6869687248347541
Epoch: 50 | Iteration number: [4350/4518] 96% | Training loss: 0.6869676598050128
Epoch: 50 | Iteration number: [4360/4518] 96% | Training loss: 0.6869662191752993
Epoch: 50 | Iteration number: [4370/4518] 96% | Training loss: 0.686967719037691
Epoch: 50 | Iteration number: [4380/4518] 96% | Training loss: 0.6869683290045011
Epoch: 50 | Iteration number: [4390/4518] 97% | Training loss: 0.6869662820070914
Epoch: 50 | Iteration number: [4400/4518] 97% | Training loss: 0.6869636525213718
Epoch: 50 | Iteration number: [4410/4518] 97% | Training loss: 0.6869624663642745
Epoch: 50 | Iteration number: [4420/4518] 97% | Training loss: 0.686964307030941
Epoch: 50 | Iteration number: [4430/4518] 98% | Training loss: 0.686964561142717
Epoch: 50 | Iteration number: [4440/4518] 98% | Training loss: 0.6869681737175933
Epoch: 50 | Iteration number: [4450/4518] 98% | Training loss: 0.6869672719146428
Epoch: 50 | Iteration number: [4460/4518] 98% | Training loss: 0.6869668622321612
Epoch: 50 | Iteration number: [4470/4518] 98% | Training loss: 0.6869666207156725
Epoch: 50 | Iteration number: [4480/4518] 99% | Training loss: 0.6869674060227615
Epoch: 50 | Iteration number: [4490/4518] 99% | Training loss: 0.6869678043177505
Epoch: 50 | Iteration number: [4500/4518] 99% | Training loss: 0.686965783516566
Epoch: 50 | Iteration number: [4510/4518] 99% | Training loss: 0.6869655365293676

 End of epoch: 50 | Train Loss: 0.6868143215966784 | Training Time: 644 

 End of epoch: 50 | Eval Loss: 0.6901552287899718 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/4518] 0% | Training loss: 0.7552853941917419
Epoch: 51 | Iteration number: [20/4518] 0% | Training loss: 0.721271088719368
Epoch: 51 | Iteration number: [30/4518] 0% | Training loss: 0.7097814321517945
Epoch: 51 | Iteration number: [40/4518] 0% | Training loss: 0.7042660251259804
Epoch: 51 | Iteration number: [50/4518] 1% | Training loss: 0.7003551042079925
Epoch: 51 | Iteration number: [60/4518] 1% | Training loss: 0.6981353342533112
Epoch: 51 | Iteration number: [70/4518] 1% | Training loss: 0.6964292628424508
Epoch: 51 | Iteration number: [80/4518] 1% | Training loss: 0.6952004164457322
Epoch: 51 | Iteration number: [90/4518] 1% | Training loss: 0.6942699902587467
Epoch: 51 | Iteration number: [100/4518] 2% | Training loss: 0.6934347033500672
Epoch: 51 | Iteration number: [110/4518] 2% | Training loss: 0.6928696366873655
Epoch: 51 | Iteration number: [120/4518] 2% | Training loss: 0.6923006316026051
Epoch: 51 | Iteration number: [130/4518] 2% | Training loss: 0.6918510693770189
Epoch: 51 | Iteration number: [140/4518] 3% | Training loss: 0.6914678760937282
Epoch: 51 | Iteration number: [150/4518] 3% | Training loss: 0.6912033009529114
Epoch: 51 | Iteration number: [160/4518] 3% | Training loss: 0.6909601964056492
Epoch: 51 | Iteration number: [170/4518] 3% | Training loss: 0.6907558886443868
Epoch: 51 | Iteration number: [180/4518] 3% | Training loss: 0.6904620415634579
Epoch: 51 | Iteration number: [190/4518] 4% | Training loss: 0.6902500532175365
Epoch: 51 | Iteration number: [200/4518] 4% | Training loss: 0.6900855380296708
Epoch: 51 | Iteration number: [210/4518] 4% | Training loss: 0.6899239636602856
Epoch: 51 | Iteration number: [220/4518] 4% | Training loss: 0.6897899603301828
Epoch: 51 | Iteration number: [230/4518] 5% | Training loss: 0.689675979251447
Epoch: 51 | Iteration number: [240/4518] 5% | Training loss: 0.6895653014381726
Epoch: 51 | Iteration number: [250/4518] 5% | Training loss: 0.6894172556400299
Epoch: 51 | Iteration number: [260/4518] 5% | Training loss: 0.689375364780426
Epoch: 51 | Iteration number: [270/4518] 5% | Training loss: 0.6892850674964763
Epoch: 51 | Iteration number: [280/4518] 6% | Training loss: 0.6892388128808566
Epoch: 51 | Iteration number: [290/4518] 6% | Training loss: 0.6891662225641053
Epoch: 51 | Iteration number: [300/4518] 6% | Training loss: 0.6891228437423706
Epoch: 51 | Iteration number: [310/4518] 6% | Training loss: 0.6890317949556535
Epoch: 51 | Iteration number: [320/4518] 7% | Training loss: 0.6890011040493846
Epoch: 51 | Iteration number: [330/4518] 7% | Training loss: 0.6889505570585077
Epoch: 51 | Iteration number: [340/4518] 7% | Training loss: 0.6888668896520839
Epoch: 51 | Iteration number: [350/4518] 7% | Training loss: 0.6888013163634709
Epoch: 51 | Iteration number: [360/4518] 7% | Training loss: 0.6887083187699318
Epoch: 51 | Iteration number: [370/4518] 8% | Training loss: 0.6886659842890662
Epoch: 51 | Iteration number: [380/4518] 8% | Training loss: 0.6886170983314515
Epoch: 51 | Iteration number: [390/4518] 8% | Training loss: 0.6885586844040797
Epoch: 51 | Iteration number: [400/4518] 8% | Training loss: 0.6885096764564514
Epoch: 51 | Iteration number: [410/4518] 9% | Training loss: 0.6884702069003408
Epoch: 51 | Iteration number: [420/4518] 9% | Training loss: 0.6884454077198392
Epoch: 51 | Iteration number: [430/4518] 9% | Training loss: 0.6884103420168854
Epoch: 51 | Iteration number: [440/4518] 9% | Training loss: 0.6883500024676323
Epoch: 51 | Iteration number: [450/4518] 9% | Training loss: 0.6883020599683126
Epoch: 51 | Iteration number: [460/4518] 10% | Training loss: 0.6882508504649867
Epoch: 51 | Iteration number: [470/4518] 10% | Training loss: 0.6882132389443986
Epoch: 51 | Iteration number: [480/4518] 10% | Training loss: 0.6882194876670837
Epoch: 51 | Iteration number: [490/4518] 10% | Training loss: 0.6881920063982204
Epoch: 51 | Iteration number: [500/4518] 11% | Training loss: 0.6881510753631592
Epoch: 51 | Iteration number: [510/4518] 11% | Training loss: 0.6881254525745616
Epoch: 51 | Iteration number: [520/4518] 11% | Training loss: 0.6880965039134026
Epoch: 51 | Iteration number: [530/4518] 11% | Training loss: 0.6880822279543247
Epoch: 51 | Iteration number: [540/4518] 11% | Training loss: 0.6880617823865679
Epoch: 51 | Iteration number: [550/4518] 12% | Training loss: 0.6880201914093711
Epoch: 51 | Iteration number: [560/4518] 12% | Training loss: 0.688003451696464
Epoch: 51 | Iteration number: [570/4518] 12% | Training loss: 0.6879846112769946
Epoch: 51 | Iteration number: [580/4518] 12% | Training loss: 0.687981442747445
Epoch: 51 | Iteration number: [590/4518] 13% | Training loss: 0.6879419621774706
Epoch: 51 | Iteration number: [600/4518] 13% | Training loss: 0.68790393948555
Epoch: 51 | Iteration number: [610/4518] 13% | Training loss: 0.6878920225823512
Epoch: 51 | Iteration number: [620/4518] 13% | Training loss: 0.6878812619755345
Epoch: 51 | Iteration number: [630/4518] 13% | Training loss: 0.6878470051856268
Epoch: 51 | Iteration number: [640/4518] 14% | Training loss: 0.6878467213362456
Epoch: 51 | Iteration number: [650/4518] 14% | Training loss: 0.6878314279592954
Epoch: 51 | Iteration number: [660/4518] 14% | Training loss: 0.6878282043066892
Epoch: 51 | Iteration number: [670/4518] 14% | Training loss: 0.6878265768734377
Epoch: 51 | Iteration number: [680/4518] 15% | Training loss: 0.6878273597534965
Epoch: 51 | Iteration number: [690/4518] 15% | Training loss: 0.6877996710763461
Epoch: 51 | Iteration number: [700/4518] 15% | Training loss: 0.6878046007667269
Epoch: 51 | Iteration number: [710/4518] 15% | Training loss: 0.6878059634020631
Epoch: 51 | Iteration number: [720/4518] 15% | Training loss: 0.6877847385075357
Epoch: 51 | Iteration number: [730/4518] 16% | Training loss: 0.6877485655758478
Epoch: 51 | Iteration number: [740/4518] 16% | Training loss: 0.6877394142988565
Epoch: 51 | Iteration number: [750/4518] 16% | Training loss: 0.6877226028442383
Epoch: 51 | Iteration number: [760/4518] 16% | Training loss: 0.6877050344881258
Epoch: 51 | Iteration number: [770/4518] 17% | Training loss: 0.6877105532528518
Epoch: 51 | Iteration number: [780/4518] 17% | Training loss: 0.6876908297722156
Epoch: 51 | Iteration number: [790/4518] 17% | Training loss: 0.6876783303822143
Epoch: 51 | Iteration number: [800/4518] 17% | Training loss: 0.6876735939830542
Epoch: 51 | Iteration number: [810/4518] 17% | Training loss: 0.6876515956572544
Epoch: 51 | Iteration number: [820/4518] 18% | Training loss: 0.6876354769235704
Epoch: 51 | Iteration number: [830/4518] 18% | Training loss: 0.6876253010278724
Epoch: 51 | Iteration number: [840/4518] 18% | Training loss: 0.6876030135012808
Epoch: 51 | Iteration number: [850/4518] 18% | Training loss: 0.6875833915261661
Epoch: 51 | Iteration number: [860/4518] 19% | Training loss: 0.6875834893348605
Epoch: 51 | Iteration number: [870/4518] 19% | Training loss: 0.6875680360300788
Epoch: 51 | Iteration number: [880/4518] 19% | Training loss: 0.6875356602397832
Epoch: 51 | Iteration number: [890/4518] 19% | Training loss: 0.6875115971216995
Epoch: 51 | Iteration number: [900/4518] 19% | Training loss: 0.6874941013918983
Epoch: 51 | Iteration number: [910/4518] 20% | Training loss: 0.6874756872653961
Epoch: 51 | Iteration number: [920/4518] 20% | Training loss: 0.6874754708098328
Epoch: 51 | Iteration number: [930/4518] 20% | Training loss: 0.6874575325237807
Epoch: 51 | Iteration number: [940/4518] 20% | Training loss: 0.6874490247127858
Epoch: 51 | Iteration number: [950/4518] 21% | Training loss: 0.6874359995440433
Epoch: 51 | Iteration number: [960/4518] 21% | Training loss: 0.6874319108823935
Epoch: 51 | Iteration number: [970/4518] 21% | Training loss: 0.6874226775980488
Epoch: 51 | Iteration number: [980/4518] 21% | Training loss: 0.6874184978859765
Epoch: 51 | Iteration number: [990/4518] 21% | Training loss: 0.6874119514166707
Epoch: 51 | Iteration number: [1000/4518] 22% | Training loss: 0.6873960124254227
Epoch: 51 | Iteration number: [1010/4518] 22% | Training loss: 0.6873826944001831
Epoch: 51 | Iteration number: [1020/4518] 22% | Training loss: 0.6873784200233571
Epoch: 51 | Iteration number: [1030/4518] 22% | Training loss: 0.6873752187177973
Epoch: 51 | Iteration number: [1040/4518] 23% | Training loss: 0.6873627443153124
Epoch: 51 | Iteration number: [1050/4518] 23% | Training loss: 0.687357353199096
Epoch: 51 | Iteration number: [1060/4518] 23% | Training loss: 0.6873536874100847
Epoch: 51 | Iteration number: [1070/4518] 23% | Training loss: 0.687345450336688
Epoch: 51 | Iteration number: [1080/4518] 23% | Training loss: 0.6873369013821637
Epoch: 51 | Iteration number: [1090/4518] 24% | Training loss: 0.6873237963663329
Epoch: 51 | Iteration number: [1100/4518] 24% | Training loss: 0.6873184500499205
Epoch: 51 | Iteration number: [1110/4518] 24% | Training loss: 0.6873121209509738
Epoch: 51 | Iteration number: [1120/4518] 24% | Training loss: 0.6873058889593396
Epoch: 51 | Iteration number: [1130/4518] 25% | Training loss: 0.6873070277998933
Epoch: 51 | Iteration number: [1140/4518] 25% | Training loss: 0.6873093529228579
Epoch: 51 | Iteration number: [1150/4518] 25% | Training loss: 0.6873053796913313
Epoch: 51 | Iteration number: [1160/4518] 25% | Training loss: 0.6872967814063203
Epoch: 51 | Iteration number: [1170/4518] 25% | Training loss: 0.6872962587409549
Epoch: 51 | Iteration number: [1180/4518] 26% | Training loss: 0.6872942676988699
Epoch: 51 | Iteration number: [1190/4518] 26% | Training loss: 0.6872933352193913
Epoch: 51 | Iteration number: [1200/4518] 26% | Training loss: 0.687300916860501
Epoch: 51 | Iteration number: [1210/4518] 26% | Training loss: 0.6873074951250691
Epoch: 51 | Iteration number: [1220/4518] 27% | Training loss: 0.6873071095493973
Epoch: 51 | Iteration number: [1230/4518] 27% | Training loss: 0.6873086681210898
Epoch: 51 | Iteration number: [1240/4518] 27% | Training loss: 0.6873065596145969
Epoch: 51 | Iteration number: [1250/4518] 27% | Training loss: 0.6873070905208588
Epoch: 51 | Iteration number: [1260/4518] 27% | Training loss: 0.6873075494217494
Epoch: 51 | Iteration number: [1270/4518] 28% | Training loss: 0.6873047264072839
Epoch: 51 | Iteration number: [1280/4518] 28% | Training loss: 0.6872973172459751
Epoch: 51 | Iteration number: [1290/4518] 28% | Training loss: 0.6872918046722116
Epoch: 51 | Iteration number: [1300/4518] 28% | Training loss: 0.6872937483512438
Epoch: 51 | Iteration number: [1310/4518] 28% | Training loss: 0.6872905458657796
Epoch: 51 | Iteration number: [1320/4518] 29% | Training loss: 0.687285849858414
Epoch: 51 | Iteration number: [1330/4518] 29% | Training loss: 0.6872696659618751
Epoch: 51 | Iteration number: [1340/4518] 29% | Training loss: 0.6872665756229145
Epoch: 51 | Iteration number: [1350/4518] 29% | Training loss: 0.6872637713396991
Epoch: 51 | Iteration number: [1360/4518] 30% | Training loss: 0.6872671143097036
Epoch: 51 | Iteration number: [1370/4518] 30% | Training loss: 0.6872642481414071
Epoch: 51 | Iteration number: [1380/4518] 30% | Training loss: 0.6872628214566604
Epoch: 51 | Iteration number: [1390/4518] 30% | Training loss: 0.6872457714818364
Epoch: 51 | Iteration number: [1400/4518] 30% | Training loss: 0.6872517541902405
Epoch: 51 | Iteration number: [1410/4518] 31% | Training loss: 0.6872516677311972
Epoch: 51 | Iteration number: [1420/4518] 31% | Training loss: 0.6872493050467801
Epoch: 51 | Iteration number: [1430/4518] 31% | Training loss: 0.6872417194859964
Epoch: 51 | Iteration number: [1440/4518] 31% | Training loss: 0.6872372419055965
Epoch: 51 | Iteration number: [1450/4518] 32% | Training loss: 0.6872441949104441
Epoch: 51 | Iteration number: [1460/4518] 32% | Training loss: 0.6872559959349567
Epoch: 51 | Iteration number: [1470/4518] 32% | Training loss: 0.6872633407310563
Epoch: 51 | Iteration number: [1480/4518] 32% | Training loss: 0.6872477852814907
Epoch: 51 | Iteration number: [1490/4518] 32% | Training loss: 0.6872375595089574
Epoch: 51 | Iteration number: [1500/4518] 33% | Training loss: 0.6872376812696457
Epoch: 51 | Iteration number: [1510/4518] 33% | Training loss: 0.6872342330335781
Epoch: 51 | Iteration number: [1520/4518] 33% | Training loss: 0.6872315915399476
Epoch: 51 | Iteration number: [1530/4518] 33% | Training loss: 0.6872328296985502
Epoch: 51 | Iteration number: [1540/4518] 34% | Training loss: 0.6872264021015787
Epoch: 51 | Iteration number: [1550/4518] 34% | Training loss: 0.687219666088781
Epoch: 51 | Iteration number: [1560/4518] 34% | Training loss: 0.6872262232578717
Epoch: 51 | Iteration number: [1570/4518] 34% | Training loss: 0.6872184828208511
Epoch: 51 | Iteration number: [1580/4518] 34% | Training loss: 0.6872047917375081
Epoch: 51 | Iteration number: [1590/4518] 35% | Training loss: 0.687190938633193
Epoch: 51 | Iteration number: [1600/4518] 35% | Training loss: 0.687182626388967
Epoch: 51 | Iteration number: [1610/4518] 35% | Training loss: 0.6871802378145064
Epoch: 51 | Iteration number: [1620/4518] 35% | Training loss: 0.6871729232278871
Epoch: 51 | Iteration number: [1630/4518] 36% | Training loss: 0.6871672553884471
Epoch: 51 | Iteration number: [1640/4518] 36% | Training loss: 0.6871684500356999
Epoch: 51 | Iteration number: [1650/4518] 36% | Training loss: 0.6871641886956764
Epoch: 51 | Iteration number: [1660/4518] 36% | Training loss: 0.6871631672224366
Epoch: 51 | Iteration number: [1670/4518] 36% | Training loss: 0.687162832014575
Epoch: 51 | Iteration number: [1680/4518] 37% | Training loss: 0.6871600643864699
Epoch: 51 | Iteration number: [1690/4518] 37% | Training loss: 0.687158484289632
Epoch: 51 | Iteration number: [1700/4518] 37% | Training loss: 0.6871599647578072
Epoch: 51 | Iteration number: [1710/4518] 37% | Training loss: 0.687158008033072
Epoch: 51 | Iteration number: [1720/4518] 38% | Training loss: 0.6871623768709426
Epoch: 51 | Iteration number: [1730/4518] 38% | Training loss: 0.6871653809368266
Epoch: 51 | Iteration number: [1740/4518] 38% | Training loss: 0.6871605368866318
Epoch: 51 | Iteration number: [1750/4518] 38% | Training loss: 0.6871525406496866
Epoch: 51 | Iteration number: [1760/4518] 38% | Training loss: 0.6871499102901328
Epoch: 51 | Iteration number: [1770/4518] 39% | Training loss: 0.6871493664501751
Epoch: 51 | Iteration number: [1780/4518] 39% | Training loss: 0.6871474587850357
Epoch: 51 | Iteration number: [1790/4518] 39% | Training loss: 0.6871467058219057
Epoch: 51 | Iteration number: [1800/4518] 39% | Training loss: 0.6871468591690063
Epoch: 51 | Iteration number: [1810/4518] 40% | Training loss: 0.6871352336683326
Epoch: 51 | Iteration number: [1820/4518] 40% | Training loss: 0.6871368054177734
Epoch: 51 | Iteration number: [1830/4518] 40% | Training loss: 0.6871331481008581
Epoch: 51 | Iteration number: [1840/4518] 40% | Training loss: 0.6871317447851534
Epoch: 51 | Iteration number: [1850/4518] 40% | Training loss: 0.6871311439050211
Epoch: 51 | Iteration number: [1860/4518] 41% | Training loss: 0.6871283253033956
Epoch: 51 | Iteration number: [1870/4518] 41% | Training loss: 0.6871273603350083
Epoch: 51 | Iteration number: [1880/4518] 41% | Training loss: 0.6871287923226965
Epoch: 51 | Iteration number: [1890/4518] 41% | Training loss: 0.6871289461378067
Epoch: 51 | Iteration number: [1900/4518] 42% | Training loss: 0.687125521364965
Epoch: 51 | Iteration number: [1910/4518] 42% | Training loss: 0.6871257271130048
Epoch: 51 | Iteration number: [1920/4518] 42% | Training loss: 0.6871267875035604
Epoch: 51 | Iteration number: [1930/4518] 42% | Training loss: 0.6871215273370397
Epoch: 51 | Iteration number: [1940/4518] 42% | Training loss: 0.687123753176522
Epoch: 51 | Iteration number: [1950/4518] 43% | Training loss: 0.6871192763096247
Epoch: 51 | Iteration number: [1960/4518] 43% | Training loss: 0.6871222961313871
Epoch: 51 | Iteration number: [1970/4518] 43% | Training loss: 0.6871191839276232
Epoch: 51 | Iteration number: [1980/4518] 43% | Training loss: 0.6871168289220695
Epoch: 51 | Iteration number: [1990/4518] 44% | Training loss: 0.6871119011586635
Epoch: 51 | Iteration number: [2000/4518] 44% | Training loss: 0.687111403644085
Epoch: 51 | Iteration number: [2010/4518] 44% | Training loss: 0.6871134494371082
Epoch: 51 | Iteration number: [2020/4518] 44% | Training loss: 0.687111576506407
Epoch: 51 | Iteration number: [2030/4518] 44% | Training loss: 0.6871156082951964
Epoch: 51 | Iteration number: [2040/4518] 45% | Training loss: 0.6871118473948217
Epoch: 51 | Iteration number: [2050/4518] 45% | Training loss: 0.6871162290689422
Epoch: 51 | Iteration number: [2060/4518] 45% | Training loss: 0.6871131505781007
Epoch: 51 | Iteration number: [2070/4518] 45% | Training loss: 0.6871191341519932
Epoch: 51 | Iteration number: [2080/4518] 46% | Training loss: 0.687122382567479
Epoch: 51 | Iteration number: [2090/4518] 46% | Training loss: 0.6871156633470618
Epoch: 51 | Iteration number: [2100/4518] 46% | Training loss: 0.6871143586862655
Epoch: 51 | Iteration number: [2110/4518] 46% | Training loss: 0.6871157530359747
Epoch: 51 | Iteration number: [2120/4518] 46% | Training loss: 0.6871167364547838
Epoch: 51 | Iteration number: [2130/4518] 47% | Training loss: 0.6871152506467882
Epoch: 51 | Iteration number: [2140/4518] 47% | Training loss: 0.6871179943608346
Epoch: 51 | Iteration number: [2150/4518] 47% | Training loss: 0.6871144790982091
Epoch: 51 | Iteration number: [2160/4518] 47% | Training loss: 0.6871102464695772
Epoch: 51 | Iteration number: [2170/4518] 48% | Training loss: 0.6871044589627173
Epoch: 51 | Iteration number: [2180/4518] 48% | Training loss: 0.6871054713879157
Epoch: 51 | Iteration number: [2190/4518] 48% | Training loss: 0.6871018746944323
Epoch: 51 | Iteration number: [2200/4518] 48% | Training loss: 0.6870992483334107
Epoch: 51 | Iteration number: [2210/4518] 48% | Training loss: 0.6870987636740931
Epoch: 51 | Iteration number: [2220/4518] 49% | Training loss: 0.6870990955614829
Epoch: 51 | Iteration number: [2230/4518] 49% | Training loss: 0.687105014639585
Epoch: 51 | Iteration number: [2240/4518] 49% | Training loss: 0.6871022304786103
Epoch: 51 | Iteration number: [2250/4518] 49% | Training loss: 0.6870996145672268
Epoch: 51 | Iteration number: [2260/4518] 50% | Training loss: 0.6870936261077898
Epoch: 51 | Iteration number: [2270/4518] 50% | Training loss: 0.6870940240469273
Epoch: 51 | Iteration number: [2280/4518] 50% | Training loss: 0.6870947055387915
Epoch: 51 | Iteration number: [2290/4518] 50% | Training loss: 0.6870909184087312
Epoch: 51 | Iteration number: [2300/4518] 50% | Training loss: 0.6870889198261758
Epoch: 51 | Iteration number: [2310/4518] 51% | Training loss: 0.6870900563347391
Epoch: 51 | Iteration number: [2320/4518] 51% | Training loss: 0.6870888210062323
Epoch: 51 | Iteration number: [2330/4518] 51% | Training loss: 0.6870932756575392
Epoch: 51 | Iteration number: [2340/4518] 51% | Training loss: 0.687100340362288
Epoch: 51 | Iteration number: [2350/4518] 52% | Training loss: 0.6871037188489386
Epoch: 51 | Iteration number: [2360/4518] 52% | Training loss: 0.6871032361256875
Epoch: 51 | Iteration number: [2370/4518] 52% | Training loss: 0.6871032989980802
Epoch: 51 | Iteration number: [2380/4518] 52% | Training loss: 0.6871070111999993
Epoch: 51 | Iteration number: [2390/4518] 52% | Training loss: 0.6871039487078598
Epoch: 51 | Iteration number: [2400/4518] 53% | Training loss: 0.6871083583434423
Epoch: 51 | Iteration number: [2410/4518] 53% | Training loss: 0.687106636549922
Epoch: 51 | Iteration number: [2420/4518] 53% | Training loss: 0.6871035941622474
Epoch: 51 | Iteration number: [2430/4518] 53% | Training loss: 0.6871022500128412
Epoch: 51 | Iteration number: [2440/4518] 54% | Training loss: 0.6871037536957225
Epoch: 51 | Iteration number: [2450/4518] 54% | Training loss: 0.687100993127239
Epoch: 51 | Iteration number: [2460/4518] 54% | Training loss: 0.6870945987420354
Epoch: 51 | Iteration number: [2470/4518] 54% | Training loss: 0.6870963243096464
Epoch: 51 | Iteration number: [2480/4518] 54% | Training loss: 0.6870943303550443
Epoch: 51 | Iteration number: [2490/4518] 55% | Training loss: 0.6870913534997457
Epoch: 51 | Iteration number: [2500/4518] 55% | Training loss: 0.687091823720932
Epoch: 51 | Iteration number: [2510/4518] 55% | Training loss: 0.6870947157956689
Epoch: 51 | Iteration number: [2520/4518] 55% | Training loss: 0.6870845825899214
Epoch: 51 | Iteration number: [2530/4518] 55% | Training loss: 0.6870885220205359
Epoch: 51 | Iteration number: [2540/4518] 56% | Training loss: 0.6870893928244358
Epoch: 51 | Iteration number: [2550/4518] 56% | Training loss: 0.6870890718347886
Epoch: 51 | Iteration number: [2560/4518] 56% | Training loss: 0.6870898545719684
Epoch: 51 | Iteration number: [2570/4518] 56% | Training loss: 0.6870865435219924
Epoch: 51 | Iteration number: [2580/4518] 57% | Training loss: 0.687080024448476
Epoch: 51 | Iteration number: [2590/4518] 57% | Training loss: 0.687084268695139
Epoch: 51 | Iteration number: [2600/4518] 57% | Training loss: 0.6870804289212593
Epoch: 51 | Iteration number: [2610/4518] 57% | Training loss: 0.6870713968386595
Epoch: 51 | Iteration number: [2620/4518] 57% | Training loss: 0.6870694168651377
Epoch: 51 | Iteration number: [2630/4518] 58% | Training loss: 0.6870644763848628
Epoch: 51 | Iteration number: [2640/4518] 58% | Training loss: 0.6870630416003141
Epoch: 51 | Iteration number: [2650/4518] 58% | Training loss: 0.6870566421184899
Epoch: 51 | Iteration number: [2660/4518] 58% | Training loss: 0.6870568674085732
Epoch: 51 | Iteration number: [2670/4518] 59% | Training loss: 0.6870579473311536
Epoch: 51 | Iteration number: [2680/4518] 59% | Training loss: 0.6870538747355119
Epoch: 51 | Iteration number: [2690/4518] 59% | Training loss: 0.6870521480044468
Epoch: 51 | Iteration number: [2700/4518] 59% | Training loss: 0.687057385996536
Epoch: 51 | Iteration number: [2710/4518] 59% | Training loss: 0.6870582325432133
Epoch: 51 | Iteration number: [2720/4518] 60% | Training loss: 0.6870565230355543
Epoch: 51 | Iteration number: [2730/4518] 60% | Training loss: 0.6870569134588207
Epoch: 51 | Iteration number: [2740/4518] 60% | Training loss: 0.687058057771982
Epoch: 51 | Iteration number: [2750/4518] 60% | Training loss: 0.6870564953197132
Epoch: 51 | Iteration number: [2760/4518] 61% | Training loss: 0.687052499168161
Epoch: 51 | Iteration number: [2770/4518] 61% | Training loss: 0.6870568304500855
Epoch: 51 | Iteration number: [2780/4518] 61% | Training loss: 0.6870497832195365
Epoch: 51 | Iteration number: [2790/4518] 61% | Training loss: 0.6870494049509793
Epoch: 51 | Iteration number: [2800/4518] 61% | Training loss: 0.6870528270304203
Epoch: 51 | Iteration number: [2810/4518] 62% | Training loss: 0.6870521435958211
Epoch: 51 | Iteration number: [2820/4518] 62% | Training loss: 0.6870538225199314
Epoch: 51 | Iteration number: [2830/4518] 62% | Training loss: 0.6870510536453328
Epoch: 51 | Iteration number: [2840/4518] 62% | Training loss: 0.6870504736060827
Epoch: 51 | Iteration number: [2850/4518] 63% | Training loss: 0.6870537724202139
Epoch: 51 | Iteration number: [2860/4518] 63% | Training loss: 0.6870570225107087
Epoch: 51 | Iteration number: [2870/4518] 63% | Training loss: 0.6870577496310976
Epoch: 51 | Iteration number: [2880/4518] 63% | Training loss: 0.6870576993458801
Epoch: 51 | Iteration number: [2890/4518] 63% | Training loss: 0.6870591650990879
Epoch: 51 | Iteration number: [2900/4518] 64% | Training loss: 0.6870604346538413
Epoch: 51 | Iteration number: [2910/4518] 64% | Training loss: 0.6870594979971135
Epoch: 51 | Iteration number: [2920/4518] 64% | Training loss: 0.6870603079256946
Epoch: 51 | Iteration number: [2930/4518] 64% | Training loss: 0.687057717241118
Epoch: 51 | Iteration number: [2940/4518] 65% | Training loss: 0.6870561499376686
Epoch: 51 | Iteration number: [2950/4518] 65% | Training loss: 0.6870520345235275
Epoch: 51 | Iteration number: [2960/4518] 65% | Training loss: 0.6870529851196585
Epoch: 51 | Iteration number: [2970/4518] 65% | Training loss: 0.687048766568855
Epoch: 51 | Iteration number: [2980/4518] 65% | Training loss: 0.6870514682875384
Epoch: 51 | Iteration number: [2990/4518] 66% | Training loss: 0.6870504368308396
Epoch: 51 | Iteration number: [3000/4518] 66% | Training loss: 0.6870469650824864
Epoch: 51 | Iteration number: [3010/4518] 66% | Training loss: 0.6870445143146768
Epoch: 51 | Iteration number: [3020/4518] 66% | Training loss: 0.6870414312904244
Epoch: 51 | Iteration number: [3030/4518] 67% | Training loss: 0.6870364717721152
Epoch: 51 | Iteration number: [3040/4518] 67% | Training loss: 0.6870387945324182
Epoch: 51 | Iteration number: [3050/4518] 67% | Training loss: 0.6870379913439516
Epoch: 51 | Iteration number: [3060/4518] 67% | Training loss: 0.6870363813404944
Epoch: 51 | Iteration number: [3070/4518] 67% | Training loss: 0.6870384915643872
Epoch: 51 | Iteration number: [3080/4518] 68% | Training loss: 0.6870393252604967
Epoch: 51 | Iteration number: [3090/4518] 68% | Training loss: 0.6870363149635228
Epoch: 51 | Iteration number: [3100/4518] 68% | Training loss: 0.6870356069649419
Epoch: 51 | Iteration number: [3110/4518] 68% | Training loss: 0.6870351848878278
Epoch: 51 | Iteration number: [3120/4518] 69% | Training loss: 0.6870352223897591
Epoch: 51 | Iteration number: [3130/4518] 69% | Training loss: 0.6870321972682453
Epoch: 51 | Iteration number: [3140/4518] 69% | Training loss: 0.6870298818418175
Epoch: 51 | Iteration number: [3150/4518] 69% | Training loss: 0.6870287210033054
Epoch: 51 | Iteration number: [3160/4518] 69% | Training loss: 0.687026901429967
Epoch: 51 | Iteration number: [3170/4518] 70% | Training loss: 0.6870236544578986
Epoch: 51 | Iteration number: [3180/4518] 70% | Training loss: 0.6870242025117455
Epoch: 51 | Iteration number: [3190/4518] 70% | Training loss: 0.6870206331010896
Epoch: 51 | Iteration number: [3200/4518] 70% | Training loss: 0.6870176575705409
Epoch: 51 | Iteration number: [3210/4518] 71% | Training loss: 0.6870154491837522
Epoch: 51 | Iteration number: [3220/4518] 71% | Training loss: 0.6870157287357757
Epoch: 51 | Iteration number: [3230/4518] 71% | Training loss: 0.6870189532222394
Epoch: 51 | Iteration number: [3240/4518] 71% | Training loss: 0.6870224672519131
Epoch: 51 | Iteration number: [3250/4518] 71% | Training loss: 0.6870183850251711
Epoch: 51 | Iteration number: [3260/4518] 72% | Training loss: 0.6870220021967508
Epoch: 51 | Iteration number: [3270/4518] 72% | Training loss: 0.6870160279653124
Epoch: 51 | Iteration number: [3280/4518] 72% | Training loss: 0.6870163518299417
Epoch: 51 | Iteration number: [3290/4518] 72% | Training loss: 0.6870161172104462
Epoch: 51 | Iteration number: [3300/4518] 73% | Training loss: 0.6870173507386987
Epoch: 51 | Iteration number: [3310/4518] 73% | Training loss: 0.6870171463021338
Epoch: 51 | Iteration number: [3320/4518] 73% | Training loss: 0.6870142398110355
Epoch: 51 | Iteration number: [3330/4518] 73% | Training loss: 0.6870103165910051
Epoch: 51 | Iteration number: [3340/4518] 73% | Training loss: 0.6870115977918316
Epoch: 51 | Iteration number: [3350/4518] 74% | Training loss: 0.6870112158291376
Epoch: 51 | Iteration number: [3360/4518] 74% | Training loss: 0.6870088818172614
Epoch: 51 | Iteration number: [3370/4518] 74% | Training loss: 0.6870077846312027
Epoch: 51 | Iteration number: [3380/4518] 74% | Training loss: 0.6870092189876286
Epoch: 51 | Iteration number: [3390/4518] 75% | Training loss: 0.6870072652632508
Epoch: 51 | Iteration number: [3400/4518] 75% | Training loss: 0.6870050084590912
Epoch: 51 | Iteration number: [3410/4518] 75% | Training loss: 0.6870009607233959
Epoch: 51 | Iteration number: [3420/4518] 75% | Training loss: 0.6870014472140207
Epoch: 51 | Iteration number: [3430/4518] 75% | Training loss: 0.6870019982055742
Epoch: 51 | Iteration number: [3440/4518] 76% | Training loss: 0.687004664748214
Epoch: 51 | Iteration number: [3450/4518] 76% | Training loss: 0.6870081295656121
Epoch: 51 | Iteration number: [3460/4518] 76% | Training loss: 0.6870056461908913
Epoch: 51 | Iteration number: [3470/4518] 76% | Training loss: 0.6870104807082789
Epoch: 51 | Iteration number: [3480/4518] 77% | Training loss: 0.6870114488163214
Epoch: 51 | Iteration number: [3490/4518] 77% | Training loss: 0.6870134684622801
Epoch: 51 | Iteration number: [3500/4518] 77% | Training loss: 0.6870125105551311
Epoch: 51 | Iteration number: [3510/4518] 77% | Training loss: 0.6870132939258532
Epoch: 51 | Iteration number: [3520/4518] 77% | Training loss: 0.6870142834091728
Epoch: 51 | Iteration number: [3530/4518] 78% | Training loss: 0.6870136065118374
Epoch: 51 | Iteration number: [3540/4518] 78% | Training loss: 0.6870113985855028
Epoch: 51 | Iteration number: [3550/4518] 78% | Training loss: 0.6870108938888765
Epoch: 51 | Iteration number: [3560/4518] 78% | Training loss: 0.6870120167899667
Epoch: 51 | Iteration number: [3570/4518] 79% | Training loss: 0.6870088960777144
Epoch: 51 | Iteration number: [3580/4518] 79% | Training loss: 0.6870109311528712
Epoch: 51 | Iteration number: [3590/4518] 79% | Training loss: 0.6870098128126192
Epoch: 51 | Iteration number: [3600/4518] 79% | Training loss: 0.687013395064407
Epoch: 51 | Iteration number: [3610/4518] 79% | Training loss: 0.6870128192399677
Epoch: 51 | Iteration number: [3620/4518] 80% | Training loss: 0.6870130616492329
Epoch: 51 | Iteration number: [3630/4518] 80% | Training loss: 0.687010319617169
Epoch: 51 | Iteration number: [3640/4518] 80% | Training loss: 0.6870110766900764
Epoch: 51 | Iteration number: [3650/4518] 80% | Training loss: 0.6870071717974258
Epoch: 51 | Iteration number: [3660/4518] 81% | Training loss: 0.6870060144063553
Epoch: 51 | Iteration number: [3670/4518] 81% | Training loss: 0.6870054808234649
Epoch: 51 | Iteration number: [3680/4518] 81% | Training loss: 0.687006495812017
Epoch: 51 | Iteration number: [3690/4518] 81% | Training loss: 0.6870039645249282
Epoch: 51 | Iteration number: [3700/4518] 81% | Training loss: 0.6870014570693712
Epoch: 51 | Iteration number: [3710/4518] 82% | Training loss: 0.6870027812343402
Epoch: 51 | Iteration number: [3720/4518] 82% | Training loss: 0.687001132115882
Epoch: 51 | Iteration number: [3730/4518] 82% | Training loss: 0.6870006504071622
Epoch: 51 | Iteration number: [3740/4518] 82% | Training loss: 0.6869982317010349
Epoch: 51 | Iteration number: [3750/4518] 83% | Training loss: 0.68699483183225
Epoch: 51 | Iteration number: [3760/4518] 83% | Training loss: 0.6869962911180993
Epoch: 51 | Iteration number: [3770/4518] 83% | Training loss: 0.686993295966156
Epoch: 51 | Iteration number: [3780/4518] 83% | Training loss: 0.6869918991491277
Epoch: 51 | Iteration number: [3790/4518] 83% | Training loss: 0.6869924949152802
Epoch: 51 | Iteration number: [3800/4518] 84% | Training loss: 0.6869943764178377
Epoch: 51 | Iteration number: [3810/4518] 84% | Training loss: 0.6869933966733026
Epoch: 51 | Iteration number: [3820/4518] 84% | Training loss: 0.6869910593120215
Epoch: 51 | Iteration number: [3830/4518] 84% | Training loss: 0.6869871913452995
Epoch: 51 | Iteration number: [3840/4518] 84% | Training loss: 0.6869866435105602
Epoch: 51 | Iteration number: [3850/4518] 85% | Training loss: 0.6869885217679012
Epoch: 51 | Iteration number: [3860/4518] 85% | Training loss: 0.6869882173488795
Epoch: 51 | Iteration number: [3870/4518] 85% | Training loss: 0.6869861311074683
Epoch: 51 | Iteration number: [3880/4518] 85% | Training loss: 0.6869864113244813
Epoch: 51 | Iteration number: [3890/4518] 86% | Training loss: 0.686984203637106
Epoch: 51 | Iteration number: [3900/4518] 86% | Training loss: 0.6869847082938904
Epoch: 51 | Iteration number: [3910/4518] 86% | Training loss: 0.6869845801302235
Epoch: 51 | Iteration number: [3920/4518] 86% | Training loss: 0.6869880798063717
Epoch: 51 | Iteration number: [3930/4518] 86% | Training loss: 0.6869881103056987
Epoch: 51 | Iteration number: [3940/4518] 87% | Training loss: 0.6869903551291693
Epoch: 51 | Iteration number: [3950/4518] 87% | Training loss: 0.6869854702074316
Epoch: 51 | Iteration number: [3960/4518] 87% | Training loss: 0.6869872736057849
Epoch: 51 | Iteration number: [3970/4518] 87% | Training loss: 0.6869871256183316
Epoch: 51 | Iteration number: [3980/4518] 88% | Training loss: 0.686985869698189
Epoch: 51 | Iteration number: [3990/4518] 88% | Training loss: 0.6869839069538547
Epoch: 51 | Iteration number: [4000/4518] 88% | Training loss: 0.6869850498735904
Epoch: 51 | Iteration number: [4010/4518] 88% | Training loss: 0.6869848783919936
Epoch: 51 | Iteration number: [4020/4518] 88% | Training loss: 0.6869850293617343
Epoch: 51 | Iteration number: [4030/4518] 89% | Training loss: 0.6869819282597999
Epoch: 51 | Iteration number: [4040/4518] 89% | Training loss: 0.6869801509793442
Epoch: 51 | Iteration number: [4050/4518] 89% | Training loss: 0.6869821320345373
Epoch: 51 | Iteration number: [4060/4518] 89% | Training loss: 0.6869826216269009
Epoch: 51 | Iteration number: [4070/4518] 90% | Training loss: 0.6869813946013954
Epoch: 51 | Iteration number: [4080/4518] 90% | Training loss: 0.6869827945150581
Epoch: 51 | Iteration number: [4090/4518] 90% | Training loss: 0.6869803656721465
Epoch: 51 | Iteration number: [4100/4518] 90% | Training loss: 0.6869825250927994
Epoch: 51 | Iteration number: [4110/4518] 90% | Training loss: 0.686981794636905
Epoch: 51 | Iteration number: [4120/4518] 91% | Training loss: 0.6869812010850721
Epoch: 51 | Iteration number: [4130/4518] 91% | Training loss: 0.6869808277985663
Epoch: 51 | Iteration number: [4140/4518] 91% | Training loss: 0.6869806880824232
Epoch: 51 | Iteration number: [4150/4518] 91% | Training loss: 0.686980316193707
Epoch: 51 | Iteration number: [4160/4518] 92% | Training loss: 0.6869788750433005
Epoch: 51 | Iteration number: [4170/4518] 92% | Training loss: 0.6869803838449702
Epoch: 51 | Iteration number: [4180/4518] 92% | Training loss: 0.6869801930548471
Epoch: 51 | Iteration number: [4190/4518] 92% | Training loss: 0.6869778691868793
Epoch: 51 | Iteration number: [4200/4518] 92% | Training loss: 0.6869773633565222
Epoch: 51 | Iteration number: [4210/4518] 93% | Training loss: 0.6869771132418209
Epoch: 51 | Iteration number: [4220/4518] 93% | Training loss: 0.6869740802671107
Epoch: 51 | Iteration number: [4230/4518] 93% | Training loss: 0.6869749127973056
Epoch: 51 | Iteration number: [4240/4518] 93% | Training loss: 0.6869759713141423
Epoch: 51 | Iteration number: [4250/4518] 94% | Training loss: 0.6869723835271948
Epoch: 51 | Iteration number: [4260/4518] 94% | Training loss: 0.6869720057422566
Epoch: 51 | Iteration number: [4270/4518] 94% | Training loss: 0.6869739605475924
Epoch: 51 | Iteration number: [4280/4518] 94% | Training loss: 0.6869747107134802
Epoch: 51 | Iteration number: [4290/4518] 94% | Training loss: 0.6869748251143591
Epoch: 51 | Iteration number: [4300/4518] 95% | Training loss: 0.6869757419270138
Epoch: 51 | Iteration number: [4310/4518] 95% | Training loss: 0.6869774129025621
Epoch: 51 | Iteration number: [4320/4518] 95% | Training loss: 0.6869783215086769
Epoch: 51 | Iteration number: [4330/4518] 95% | Training loss: 0.6869793727546586
Epoch: 51 | Iteration number: [4340/4518] 96% | Training loss: 0.6869782445205521
Epoch: 51 | Iteration number: [4350/4518] 96% | Training loss: 0.6869773492319831
Epoch: 51 | Iteration number: [4360/4518] 96% | Training loss: 0.6869801255951234
Epoch: 51 | Iteration number: [4370/4518] 96% | Training loss: 0.686978017233602
Epoch: 51 | Iteration number: [4380/4518] 96% | Training loss: 0.6869771270583209
Epoch: 51 | Iteration number: [4390/4518] 97% | Training loss: 0.6869769643813982
Epoch: 51 | Iteration number: [4400/4518] 97% | Training loss: 0.6869780598174442
Epoch: 51 | Iteration number: [4410/4518] 97% | Training loss: 0.6869788035513863
Epoch: 51 | Iteration number: [4420/4518] 97% | Training loss: 0.6869781396237973
Epoch: 51 | Iteration number: [4430/4518] 98% | Training loss: 0.6869789407565416
Epoch: 51 | Iteration number: [4440/4518] 98% | Training loss: 0.6869794242016904
Epoch: 51 | Iteration number: [4450/4518] 98% | Training loss: 0.6869805788993836
Epoch: 51 | Iteration number: [4460/4518] 98% | Training loss: 0.68697618914292
Epoch: 51 | Iteration number: [4470/4518] 98% | Training loss: 0.6869752970717897
Epoch: 51 | Iteration number: [4480/4518] 99% | Training loss: 0.686974279595805
Epoch: 51 | Iteration number: [4490/4518] 99% | Training loss: 0.6869717775182362
Epoch: 51 | Iteration number: [4500/4518] 99% | Training loss: 0.6869703050057093
Epoch: 51 | Iteration number: [4510/4518] 99% | Training loss: 0.6869724192270419

 End of epoch: 51 | Train Loss: 0.6868219560835941 | Training Time: 643 

 End of epoch: 51 | Eval Loss: 0.6901114595179655 | Evaluating Time: 17 
Epoch: 52 | Iteration number: [10/4518] 0% | Training loss: 0.754164069890976
Epoch: 52 | Iteration number: [20/4518] 0% | Training loss: 0.7211746722459793
Epoch: 52 | Iteration number: [30/4518] 0% | Training loss: 0.7097389062245687
Epoch: 52 | Iteration number: [40/4518] 0% | Training loss: 0.7040494427084922
Epoch: 52 | Iteration number: [50/4518] 1% | Training loss: 0.7007287037372589
Epoch: 52 | Iteration number: [60/4518] 1% | Training loss: 0.6983637611071268
Epoch: 52 | Iteration number: [70/4518] 1% | Training loss: 0.6965689650603704
Epoch: 52 | Iteration number: [80/4518] 1% | Training loss: 0.6954162955284119
Epoch: 52 | Iteration number: [90/4518] 1% | Training loss: 0.694420666164822
Epoch: 52 | Iteration number: [100/4518] 2% | Training loss: 0.6937477576732636
Epoch: 52 | Iteration number: [110/4518] 2% | Training loss: 0.6931487435644323
Epoch: 52 | Iteration number: [120/4518] 2% | Training loss: 0.6926364590724309
Epoch: 52 | Iteration number: [130/4518] 2% | Training loss: 0.6923127729159135
Epoch: 52 | Iteration number: [140/4518] 3% | Training loss: 0.691915939961161
Epoch: 52 | Iteration number: [150/4518] 3% | Training loss: 0.6916315786043803
Epoch: 52 | Iteration number: [160/4518] 3% | Training loss: 0.6913687393069268
Epoch: 52 | Iteration number: [170/4518] 3% | Training loss: 0.691039542240255
Epoch: 52 | Iteration number: [180/4518] 3% | Training loss: 0.6907895174291399
Epoch: 52 | Iteration number: [190/4518] 4% | Training loss: 0.6906120623412885
Epoch: 52 | Iteration number: [200/4518] 4% | Training loss: 0.6904458668828011
Epoch: 52 | Iteration number: [210/4518] 4% | Training loss: 0.6903123373077029
Epoch: 52 | Iteration number: [220/4518] 4% | Training loss: 0.690137256546454
Epoch: 52 | Iteration number: [230/4518] 5% | Training loss: 0.6900040507316589
Epoch: 52 | Iteration number: [240/4518] 5% | Training loss: 0.6898301819960276
Epoch: 52 | Iteration number: [250/4518] 5% | Training loss: 0.6896811130046845
Epoch: 52 | Iteration number: [260/4518] 5% | Training loss: 0.689548357633444
Epoch: 52 | Iteration number: [270/4518] 5% | Training loss: 0.6894176790007839
Epoch: 52 | Iteration number: [280/4518] 6% | Training loss: 0.6893253183790615
Epoch: 52 | Iteration number: [290/4518] 6% | Training loss: 0.689291773582327
Epoch: 52 | Iteration number: [300/4518] 6% | Training loss: 0.6891955331961314
Epoch: 52 | Iteration number: [310/4518] 6% | Training loss: 0.6891077712658913
Epoch: 52 | Iteration number: [320/4518] 7% | Training loss: 0.6890347503125668
Epoch: 52 | Iteration number: [330/4518] 7% | Training loss: 0.6889551027254625
Epoch: 52 | Iteration number: [340/4518] 7% | Training loss: 0.6888785917969311
Epoch: 52 | Iteration number: [350/4518] 7% | Training loss: 0.6888290013585772
Epoch: 52 | Iteration number: [360/4518] 7% | Training loss: 0.6887649792763922
Epoch: 52 | Iteration number: [370/4518] 8% | Training loss: 0.6887355760948078
Epoch: 52 | Iteration number: [380/4518] 8% | Training loss: 0.6886524671002439
Epoch: 52 | Iteration number: [390/4518] 8% | Training loss: 0.6886425511959272
Epoch: 52 | Iteration number: [400/4518] 8% | Training loss: 0.6885654550790786
Epoch: 52 | Iteration number: [410/4518] 9% | Training loss: 0.6885205636664135
Epoch: 52 | Iteration number: [420/4518] 9% | Training loss: 0.6884813112871987
Epoch: 52 | Iteration number: [430/4518] 9% | Training loss: 0.688423857439396
Epoch: 52 | Iteration number: [440/4518] 9% | Training loss: 0.6883719331838868
Epoch: 52 | Iteration number: [450/4518] 9% | Training loss: 0.6883542709880405
Epoch: 52 | Iteration number: [460/4518] 10% | Training loss: 0.6883234866287398
Epoch: 52 | Iteration number: [470/4518] 10% | Training loss: 0.6882603223019458
Epoch: 52 | Iteration number: [480/4518] 10% | Training loss: 0.6882411807775497
Epoch: 52 | Iteration number: [490/4518] 10% | Training loss: 0.688221134093343
Epoch: 52 | Iteration number: [500/4518] 11% | Training loss: 0.6881961728334427
Epoch: 52 | Iteration number: [510/4518] 11% | Training loss: 0.6881535187655804
Epoch: 52 | Iteration number: [520/4518] 11% | Training loss: 0.6881277132492799
Epoch: 52 | Iteration number: [530/4518] 11% | Training loss: 0.6880947158021747
Epoch: 52 | Iteration number: [540/4518] 11% | Training loss: 0.6880629483196471
Epoch: 52 | Iteration number: [550/4518] 12% | Training loss: 0.6879940058968284
Epoch: 52 | Iteration number: [560/4518] 12% | Training loss: 0.687980182575328
Epoch: 52 | Iteration number: [570/4518] 12% | Training loss: 0.6879793865638867
Epoch: 52 | Iteration number: [580/4518] 12% | Training loss: 0.6879709346541043
Epoch: 52 | Iteration number: [590/4518] 13% | Training loss: 0.6879589461674125
Epoch: 52 | Iteration number: [600/4518] 13% | Training loss: 0.6879543422659238
Epoch: 52 | Iteration number: [610/4518] 13% | Training loss: 0.6879258404989712
Epoch: 52 | Iteration number: [620/4518] 13% | Training loss: 0.6879236751025722
Epoch: 52 | Iteration number: [630/4518] 13% | Training loss: 0.6879286600483788
Epoch: 52 | Iteration number: [640/4518] 14% | Training loss: 0.6879345778375864
Epoch: 52 | Iteration number: [650/4518] 14% | Training loss: 0.6879194481556232
Epoch: 52 | Iteration number: [660/4518] 14% | Training loss: 0.6879152230241082
Epoch: 52 | Iteration number: [670/4518] 14% | Training loss: 0.6879071983828473
Epoch: 52 | Iteration number: [680/4518] 15% | Training loss: 0.6878796148826094
Epoch: 52 | Iteration number: [690/4518] 15% | Training loss: 0.6878670118857121
Epoch: 52 | Iteration number: [700/4518] 15% | Training loss: 0.6878514528274536
Epoch: 52 | Iteration number: [710/4518] 15% | Training loss: 0.6878320440440111
Epoch: 52 | Iteration number: [720/4518] 15% | Training loss: 0.6878257151279185
Epoch: 52 | Iteration number: [730/4518] 16% | Training loss: 0.6878260544718129
Epoch: 52 | Iteration number: [740/4518] 16% | Training loss: 0.6878193402612531
Epoch: 52 | Iteration number: [750/4518] 16% | Training loss: 0.6878021105130514
Epoch: 52 | Iteration number: [760/4518] 16% | Training loss: 0.6877873873240069
Epoch: 52 | Iteration number: [770/4518] 17% | Training loss: 0.6877914230544846
Epoch: 52 | Iteration number: [780/4518] 17% | Training loss: 0.6877820668312219
Epoch: 52 | Iteration number: [790/4518] 17% | Training loss: 0.6877670352972006
Epoch: 52 | Iteration number: [800/4518] 17% | Training loss: 0.6877269621938467
Epoch: 52 | Iteration number: [810/4518] 17% | Training loss: 0.6877337872982026
Epoch: 52 | Iteration number: [820/4518] 18% | Training loss: 0.6877190220646742
Epoch: 52 | Iteration number: [830/4518] 18% | Training loss: 0.6877046210938189
Epoch: 52 | Iteration number: [840/4518] 18% | Training loss: 0.6877055827350843
Epoch: 52 | Iteration number: [850/4518] 18% | Training loss: 0.6876847107270184
Epoch: 52 | Iteration number: [860/4518] 19% | Training loss: 0.6876751618329868
Epoch: 52 | Iteration number: [870/4518] 19% | Training loss: 0.6876773315599595
Epoch: 52 | Iteration number: [880/4518] 19% | Training loss: 0.6876674377782779
Epoch: 52 | Iteration number: [890/4518] 19% | Training loss: 0.6876621901319268
Epoch: 52 | Iteration number: [900/4518] 19% | Training loss: 0.6876498901844025
Epoch: 52 | Iteration number: [910/4518] 20% | Training loss: 0.6876366771839477
Epoch: 52 | Iteration number: [920/4518] 20% | Training loss: 0.687628080793049
Epoch: 52 | Iteration number: [930/4518] 20% | Training loss: 0.6876262850658867
Epoch: 52 | Iteration number: [940/4518] 20% | Training loss: 0.6876145196721909
Epoch: 52 | Iteration number: [950/4518] 21% | Training loss: 0.6876073896257501
Epoch: 52 | Iteration number: [960/4518] 21% | Training loss: 0.6875993755956491
Epoch: 52 | Iteration number: [970/4518] 21% | Training loss: 0.6875928656956585
Epoch: 52 | Iteration number: [980/4518] 21% | Training loss: 0.6875944563928915
Epoch: 52 | Iteration number: [990/4518] 21% | Training loss: 0.6875886969494097
Epoch: 52 | Iteration number: [1000/4518] 22% | Training loss: 0.6875710608363151
Epoch: 52 | Iteration number: [1010/4518] 22% | Training loss: 0.6875664899844934
Epoch: 52 | Iteration number: [1020/4518] 22% | Training loss: 0.6875605752070745
Epoch: 52 | Iteration number: [1030/4518] 22% | Training loss: 0.6875629302367423
Epoch: 52 | Iteration number: [1040/4518] 23% | Training loss: 0.6875448243549237
Epoch: 52 | Iteration number: [1050/4518] 23% | Training loss: 0.6875316240106311
Epoch: 52 | Iteration number: [1060/4518] 23% | Training loss: 0.6875222032924868
Epoch: 52 | Iteration number: [1070/4518] 23% | Training loss: 0.6875211798699102
Epoch: 52 | Iteration number: [1080/4518] 23% | Training loss: 0.6874958297168767
Epoch: 52 | Iteration number: [1090/4518] 24% | Training loss: 0.6874797720427906
Epoch: 52 | Iteration number: [1100/4518] 24% | Training loss: 0.6874776002493772
Epoch: 52 | Iteration number: [1110/4518] 24% | Training loss: 0.6874803912532222
Epoch: 52 | Iteration number: [1120/4518] 24% | Training loss: 0.687460371958358
Epoch: 52 | Iteration number: [1130/4518] 25% | Training loss: 0.6874494690810684
Epoch: 52 | Iteration number: [1140/4518] 25% | Training loss: 0.687442127654427
Epoch: 52 | Iteration number: [1150/4518] 25% | Training loss: 0.6874308617736983
Epoch: 52 | Iteration number: [1160/4518] 25% | Training loss: 0.6874274415188822
Epoch: 52 | Iteration number: [1170/4518] 25% | Training loss: 0.6874259638480651
Epoch: 52 | Iteration number: [1180/4518] 26% | Training loss: 0.6874247929807437
Epoch: 52 | Iteration number: [1190/4518] 26% | Training loss: 0.6874184116595934
Epoch: 52 | Iteration number: [1200/4518] 26% | Training loss: 0.6874047802388668
Epoch: 52 | Iteration number: [1210/4518] 26% | Training loss: 0.6874026067985975
Epoch: 52 | Iteration number: [1220/4518] 27% | Training loss: 0.6874007059413879
Epoch: 52 | Iteration number: [1230/4518] 27% | Training loss: 0.6874040082702791
Epoch: 52 | Iteration number: [1240/4518] 27% | Training loss: 0.6874101205218223
Epoch: 52 | Iteration number: [1250/4518] 27% | Training loss: 0.6874142200946808
Epoch: 52 | Iteration number: [1260/4518] 27% | Training loss: 0.6874126573403676
Epoch: 52 | Iteration number: [1270/4518] 28% | Training loss: 0.6874057291530249
Epoch: 52 | Iteration number: [1280/4518] 28% | Training loss: 0.6874104141257703
Epoch: 52 | Iteration number: [1290/4518] 28% | Training loss: 0.6874180157979329
Epoch: 52 | Iteration number: [1300/4518] 28% | Training loss: 0.6874196393673236
Epoch: 52 | Iteration number: [1310/4518] 28% | Training loss: 0.687413135603184
Epoch: 52 | Iteration number: [1320/4518] 29% | Training loss: 0.6874204804048394
Epoch: 52 | Iteration number: [1330/4518] 29% | Training loss: 0.6874258592164606
Epoch: 52 | Iteration number: [1340/4518] 29% | Training loss: 0.6874281926831203
Epoch: 52 | Iteration number: [1350/4518] 29% | Training loss: 0.6874221764228962
Epoch: 52 | Iteration number: [1360/4518] 30% | Training loss: 0.6874093569815158
Epoch: 52 | Iteration number: [1370/4518] 30% | Training loss: 0.6874015964730813
Epoch: 52 | Iteration number: [1380/4518] 30% | Training loss: 0.6873990112456723
Epoch: 52 | Iteration number: [1390/4518] 30% | Training loss: 0.6873967334520903
Epoch: 52 | Iteration number: [1400/4518] 30% | Training loss: 0.6873970566902842
Epoch: 52 | Iteration number: [1410/4518] 31% | Training loss: 0.6873965880549546
Epoch: 52 | Iteration number: [1420/4518] 31% | Training loss: 0.6873825698671207
Epoch: 52 | Iteration number: [1430/4518] 31% | Training loss: 0.6873761637644334
Epoch: 52 | Iteration number: [1440/4518] 31% | Training loss: 0.6873706206679344
Epoch: 52 | Iteration number: [1450/4518] 32% | Training loss: 0.6873604781463228
Epoch: 52 | Iteration number: [1460/4518] 32% | Training loss: 0.6873643527700476
Epoch: 52 | Iteration number: [1470/4518] 32% | Training loss: 0.6873547120159175
Epoch: 52 | Iteration number: [1480/4518] 32% | Training loss: 0.6873458080195092
Epoch: 52 | Iteration number: [1490/4518] 32% | Training loss: 0.6873376026249572
Epoch: 52 | Iteration number: [1500/4518] 33% | Training loss: 0.6873315046628317
Epoch: 52 | Iteration number: [1510/4518] 33% | Training loss: 0.6873273068311199
Epoch: 52 | Iteration number: [1520/4518] 33% | Training loss: 0.6873260148261723
Epoch: 52 | Iteration number: [1530/4518] 33% | Training loss: 0.6873193828888189
Epoch: 52 | Iteration number: [1540/4518] 34% | Training loss: 0.6873034925042809
Epoch: 52 | Iteration number: [1550/4518] 34% | Training loss: 0.6872999916922662
Epoch: 52 | Iteration number: [1560/4518] 34% | Training loss: 0.687296859232279
Epoch: 52 | Iteration number: [1570/4518] 34% | Training loss: 0.6872985916152882
Epoch: 52 | Iteration number: [1580/4518] 34% | Training loss: 0.6872878417184082
Epoch: 52 | Iteration number: [1590/4518] 35% | Training loss: 0.6872841030546705
Epoch: 52 | Iteration number: [1600/4518] 35% | Training loss: 0.6872819169610739
Epoch: 52 | Iteration number: [1610/4518] 35% | Training loss: 0.6872864558459809
Epoch: 52 | Iteration number: [1620/4518] 35% | Training loss: 0.6872875327313388
Epoch: 52 | Iteration number: [1630/4518] 36% | Training loss: 0.6872788119169831
Epoch: 52 | Iteration number: [1640/4518] 36% | Training loss: 0.6872753996311165
Epoch: 52 | Iteration number: [1650/4518] 36% | Training loss: 0.687274977871866
Epoch: 52 | Iteration number: [1660/4518] 36% | Training loss: 0.687277176724859
Epoch: 52 | Iteration number: [1670/4518] 36% | Training loss: 0.6872674967714413
Epoch: 52 | Iteration number: [1680/4518] 37% | Training loss: 0.6872645757737614
Epoch: 52 | Iteration number: [1690/4518] 37% | Training loss: 0.6872531512079859
Epoch: 52 | Iteration number: [1700/4518] 37% | Training loss: 0.6872522293469485
Epoch: 52 | Iteration number: [1710/4518] 37% | Training loss: 0.6872433976471772
Epoch: 52 | Iteration number: [1720/4518] 38% | Training loss: 0.6872423262790192
Epoch: 52 | Iteration number: [1730/4518] 38% | Training loss: 0.687250048025495
Epoch: 52 | Iteration number: [1740/4518] 38% | Training loss: 0.6872491763583545
Epoch: 52 | Iteration number: [1750/4518] 38% | Training loss: 0.6872579853194101
Epoch: 52 | Iteration number: [1760/4518] 38% | Training loss: 0.6872471968897365
Epoch: 52 | Iteration number: [1770/4518] 39% | Training loss: 0.6872456480217519
Epoch: 52 | Iteration number: [1780/4518] 39% | Training loss: 0.687235071786334
Epoch: 52 | Iteration number: [1790/4518] 39% | Training loss: 0.6872312323674143
Epoch: 52 | Iteration number: [1800/4518] 39% | Training loss: 0.6872331134809389
Epoch: 52 | Iteration number: [1810/4518] 40% | Training loss: 0.6872364902364615
Epoch: 52 | Iteration number: [1820/4518] 40% | Training loss: 0.6872401899361349
Epoch: 52 | Iteration number: [1830/4518] 40% | Training loss: 0.6872419988522764
Epoch: 52 | Iteration number: [1840/4518] 40% | Training loss: 0.6872379694943843
Epoch: 52 | Iteration number: [1850/4518] 40% | Training loss: 0.6872332173102611
Epoch: 52 | Iteration number: [1860/4518] 41% | Training loss: 0.6872346126905051
Epoch: 52 | Iteration number: [1870/4518] 41% | Training loss: 0.6872334476779489
Epoch: 52 | Iteration number: [1880/4518] 41% | Training loss: 0.6872349491461794
Epoch: 52 | Iteration number: [1890/4518] 41% | Training loss: 0.6872346593904748
Epoch: 52 | Iteration number: [1900/4518] 42% | Training loss: 0.6872312319278717
Epoch: 52 | Iteration number: [1910/4518] 42% | Training loss: 0.6872275452651279
Epoch: 52 | Iteration number: [1920/4518] 42% | Training loss: 0.6872232560689251
Epoch: 52 | Iteration number: [1930/4518] 42% | Training loss: 0.6872245396665958
Epoch: 52 | Iteration number: [1940/4518] 42% | Training loss: 0.6872245935435147
Epoch: 52 | Iteration number: [1950/4518] 43% | Training loss: 0.6872230351276887
Epoch: 52 | Iteration number: [1960/4518] 43% | Training loss: 0.6872216902825297
Epoch: 52 | Iteration number: [1970/4518] 43% | Training loss: 0.6872214754825922
Epoch: 52 | Iteration number: [1980/4518] 43% | Training loss: 0.6872190526639572
Epoch: 52 | Iteration number: [1990/4518] 44% | Training loss: 0.6872111528063539
Epoch: 52 | Iteration number: [2000/4518] 44% | Training loss: 0.6872019084095955
Epoch: 52 | Iteration number: [2010/4518] 44% | Training loss: 0.687192562919351
Epoch: 52 | Iteration number: [2020/4518] 44% | Training loss: 0.68719490179331
Epoch: 52 | Iteration number: [2030/4518] 44% | Training loss: 0.6871864661500959
Epoch: 52 | Iteration number: [2040/4518] 45% | Training loss: 0.6871835412640198
Epoch: 52 | Iteration number: [2050/4518] 45% | Training loss: 0.687176438860777
Epoch: 52 | Iteration number: [2060/4518] 45% | Training loss: 0.6871696405908436
Epoch: 52 | Iteration number: [2070/4518] 45% | Training loss: 0.6871731636028935
Epoch: 52 | Iteration number: [2080/4518] 46% | Training loss: 0.687171643284651
Epoch: 52 | Iteration number: [2090/4518] 46% | Training loss: 0.687168726852636
Epoch: 52 | Iteration number: [2100/4518] 46% | Training loss: 0.687170093456904
Epoch: 52 | Iteration number: [2110/4518] 46% | Training loss: 0.6871686714802873
Epoch: 52 | Iteration number: [2120/4518] 46% | Training loss: 0.687165635008857
Epoch: 52 | Iteration number: [2130/4518] 47% | Training loss: 0.6871702425636596
Epoch: 52 | Iteration number: [2140/4518] 47% | Training loss: 0.6871710888693265
Epoch: 52 | Iteration number: [2150/4518] 47% | Training loss: 0.6871671014053877
Epoch: 52 | Iteration number: [2160/4518] 47% | Training loss: 0.687164374164961
Epoch: 52 | Iteration number: [2170/4518] 48% | Training loss: 0.6871633161597538
Epoch: 52 | Iteration number: [2180/4518] 48% | Training loss: 0.6871571007671706
Epoch: 52 | Iteration number: [2190/4518] 48% | Training loss: 0.6871604156276406
Epoch: 52 | Iteration number: [2200/4518] 48% | Training loss: 0.6871597181125121
Epoch: 52 | Iteration number: [2210/4518] 48% | Training loss: 0.6871536421829759
Epoch: 52 | Iteration number: [2220/4518] 49% | Training loss: 0.6871491011735555
Epoch: 52 | Iteration number: [2230/4518] 49% | Training loss: 0.6871459833442363
Epoch: 52 | Iteration number: [2240/4518] 49% | Training loss: 0.6871427301317453
Epoch: 52 | Iteration number: [2250/4518] 49% | Training loss: 0.6871441739135319
Epoch: 52 | Iteration number: [2260/4518] 50% | Training loss: 0.6871431152377508
Epoch: 52 | Iteration number: [2270/4518] 50% | Training loss: 0.6871419546625163
Epoch: 52 | Iteration number: [2280/4518] 50% | Training loss: 0.687135099554271
Epoch: 52 | Iteration number: [2290/4518] 50% | Training loss: 0.6871261545664359
Epoch: 52 | Iteration number: [2300/4518] 50% | Training loss: 0.6871265093917432
Epoch: 52 | Iteration number: [2310/4518] 51% | Training loss: 0.6871263669166731
Epoch: 52 | Iteration number: [2320/4518] 51% | Training loss: 0.6871299780391413
Epoch: 52 | Iteration number: [2330/4518] 51% | Training loss: 0.6871281278747345
Epoch: 52 | Iteration number: [2340/4518] 51% | Training loss: 0.6871227153091349
Epoch: 52 | Iteration number: [2350/4518] 52% | Training loss: 0.6871211373806
Epoch: 52 | Iteration number: [2360/4518] 52% | Training loss: 0.6871235676236072
Epoch: 52 | Iteration number: [2370/4518] 52% | Training loss: 0.6871211180707071
Epoch: 52 | Iteration number: [2380/4518] 52% | Training loss: 0.6871219862659438
Epoch: 52 | Iteration number: [2390/4518] 52% | Training loss: 0.687125705525466
Epoch: 52 | Iteration number: [2400/4518] 53% | Training loss: 0.6871249284098546
Epoch: 52 | Iteration number: [2410/4518] 53% | Training loss: 0.687129096000521
Epoch: 52 | Iteration number: [2420/4518] 53% | Training loss: 0.6871306603358797
Epoch: 52 | Iteration number: [2430/4518] 53% | Training loss: 0.6871240358048506
Epoch: 52 | Iteration number: [2440/4518] 54% | Training loss: 0.6871212431641875
Epoch: 52 | Iteration number: [2450/4518] 54% | Training loss: 0.6871209568393474
Epoch: 52 | Iteration number: [2460/4518] 54% | Training loss: 0.6871172857720678
Epoch: 52 | Iteration number: [2470/4518] 54% | Training loss: 0.6871143615921499
Epoch: 52 | Iteration number: [2480/4518] 54% | Training loss: 0.6871138135031346
Epoch: 52 | Iteration number: [2490/4518] 55% | Training loss: 0.6871159594221766
Epoch: 52 | Iteration number: [2500/4518] 55% | Training loss: 0.6871147706985473
Epoch: 52 | Iteration number: [2510/4518] 55% | Training loss: 0.6871116971352186
Epoch: 52 | Iteration number: [2520/4518] 55% | Training loss: 0.6871105379764996
Epoch: 52 | Iteration number: [2530/4518] 55% | Training loss: 0.6871065665846285
Epoch: 52 | Iteration number: [2540/4518] 56% | Training loss: 0.6871070810190336
Epoch: 52 | Iteration number: [2550/4518] 56% | Training loss: 0.6871036804423613
Epoch: 52 | Iteration number: [2560/4518] 56% | Training loss: 0.6871021903585642
Epoch: 52 | Iteration number: [2570/4518] 56% | Training loss: 0.6870959704720093
Epoch: 52 | Iteration number: [2580/4518] 57% | Training loss: 0.6870935879936514
Epoch: 52 | Iteration number: [2590/4518] 57% | Training loss: 0.6870915855219926
Epoch: 52 | Iteration number: [2600/4518] 57% | Training loss: 0.6870887284783217
Epoch: 52 | Iteration number: [2610/4518] 57% | Training loss: 0.6870914703584722
Epoch: 52 | Iteration number: [2620/4518] 57% | Training loss: 0.6870902005270237
Epoch: 52 | Iteration number: [2630/4518] 58% | Training loss: 0.6870932374163725
Epoch: 52 | Iteration number: [2640/4518] 58% | Training loss: 0.6870959480829311
Epoch: 52 | Iteration number: [2650/4518] 58% | Training loss: 0.6870954983639267
Epoch: 52 | Iteration number: [2660/4518] 58% | Training loss: 0.6870987944360962
Epoch: 52 | Iteration number: [2670/4518] 59% | Training loss: 0.6870973686153969
Epoch: 52 | Iteration number: [2680/4518] 59% | Training loss: 0.6870964297385358
Epoch: 52 | Iteration number: [2690/4518] 59% | Training loss: 0.6870963646798329
Epoch: 52 | Iteration number: [2700/4518] 59% | Training loss: 0.6870899884789078
Epoch: 52 | Iteration number: [2710/4518] 59% | Training loss: 0.6870876540776988
Epoch: 52 | Iteration number: [2720/4518] 60% | Training loss: 0.6870826063348966
Epoch: 52 | Iteration number: [2730/4518] 60% | Training loss: 0.6870803768381532
Epoch: 52 | Iteration number: [2740/4518] 60% | Training loss: 0.6870799481433674
Epoch: 52 | Iteration number: [2750/4518] 60% | Training loss: 0.6870762860341506
Epoch: 52 | Iteration number: [2760/4518] 61% | Training loss: 0.6870715055776679
Epoch: 52 | Iteration number: [2770/4518] 61% | Training loss: 0.6870662019571242
Epoch: 52 | Iteration number: [2780/4518] 61% | Training loss: 0.6870664902942644
Epoch: 52 | Iteration number: [2790/4518] 61% | Training loss: 0.6870667010652549
Epoch: 52 | Iteration number: [2800/4518] 61% | Training loss: 0.6870639926195145
Epoch: 52 | Iteration number: [2810/4518] 62% | Training loss: 0.6870592520966649
Epoch: 52 | Iteration number: [2820/4518] 62% | Training loss: 0.6870606404458377
Epoch: 52 | Iteration number: [2830/4518] 62% | Training loss: 0.6870540300864634
Epoch: 52 | Iteration number: [2840/4518] 62% | Training loss: 0.6870503493387934
Epoch: 52 | Iteration number: [2850/4518] 63% | Training loss: 0.687052102611776
Epoch: 52 | Iteration number: [2860/4518] 63% | Training loss: 0.6870538423319796
Epoch: 52 | Iteration number: [2870/4518] 63% | Training loss: 0.6870564057851918
Epoch: 52 | Iteration number: [2880/4518] 63% | Training loss: 0.6870526475210984
Epoch: 52 | Iteration number: [2890/4518] 63% | Training loss: 0.6870505052041842
Epoch: 52 | Iteration number: [2900/4518] 64% | Training loss: 0.6870551285867034
Epoch: 52 | Iteration number: [2910/4518] 64% | Training loss: 0.6870531082562974
Epoch: 52 | Iteration number: [2920/4518] 64% | Training loss: 0.6870502915896781
Epoch: 52 | Iteration number: [2930/4518] 64% | Training loss: 0.687044110497517
Epoch: 52 | Iteration number: [2940/4518] 65% | Training loss: 0.6870418695973701
Epoch: 52 | Iteration number: [2950/4518] 65% | Training loss: 0.6870432899159901
Epoch: 52 | Iteration number: [2960/4518] 65% | Training loss: 0.6870455269072507
Epoch: 52 | Iteration number: [2970/4518] 65% | Training loss: 0.6870442643510773
Epoch: 52 | Iteration number: [2980/4518] 65% | Training loss: 0.6870418544983704
Epoch: 52 | Iteration number: [2990/4518] 66% | Training loss: 0.687043313776769
Epoch: 52 | Iteration number: [3000/4518] 66% | Training loss: 0.6870384718974432
Epoch: 52 | Iteration number: [3010/4518] 66% | Training loss: 0.6870377171079186
Epoch: 52 | Iteration number: [3020/4518] 66% | Training loss: 0.6870387680088448
Epoch: 52 | Iteration number: [3030/4518] 67% | Training loss: 0.6870379923790595
Epoch: 52 | Iteration number: [3040/4518] 67% | Training loss: 0.6870323808961794
Epoch: 52 | Iteration number: [3050/4518] 67% | Training loss: 0.6870320045557179
Epoch: 52 | Iteration number: [3060/4518] 67% | Training loss: 0.6870327390876471
Epoch: 52 | Iteration number: [3070/4518] 67% | Training loss: 0.6870357179680554
Epoch: 52 | Iteration number: [3080/4518] 68% | Training loss: 0.6870354333287709
Epoch: 52 | Iteration number: [3090/4518] 68% | Training loss: 0.6870331597366766
Epoch: 52 | Iteration number: [3100/4518] 68% | Training loss: 0.6870309808754151
Epoch: 52 | Iteration number: [3110/4518] 68% | Training loss: 0.6870297023337754
Epoch: 52 | Iteration number: [3120/4518] 69% | Training loss: 0.6870295569491692
Epoch: 52 | Iteration number: [3130/4518] 69% | Training loss: 0.6870304996784503
Epoch: 52 | Iteration number: [3140/4518] 69% | Training loss: 0.6870306221353021
Epoch: 52 | Iteration number: [3150/4518] 69% | Training loss: 0.687029300625362
Epoch: 52 | Iteration number: [3160/4518] 69% | Training loss: 0.6870313783801054
Epoch: 52 | Iteration number: [3170/4518] 70% | Training loss: 0.6870331369739978
Epoch: 52 | Iteration number: [3180/4518] 70% | Training loss: 0.687032159263233
Epoch: 52 | Iteration number: [3190/4518] 70% | Training loss: 0.6870303831877753
Epoch: 52 | Iteration number: [3200/4518] 70% | Training loss: 0.6870298804715276
Epoch: 52 | Iteration number: [3210/4518] 71% | Training loss: 0.6870330694494218
Epoch: 52 | Iteration number: [3220/4518] 71% | Training loss: 0.6870354303291866
Epoch: 52 | Iteration number: [3230/4518] 71% | Training loss: 0.687037957858744
Epoch: 52 | Iteration number: [3240/4518] 71% | Training loss: 0.6870368871239968
Epoch: 52 | Iteration number: [3250/4518] 71% | Training loss: 0.6870419675386868
Epoch: 52 | Iteration number: [3260/4518] 72% | Training loss: 0.6870399783359715
Epoch: 52 | Iteration number: [3270/4518] 72% | Training loss: 0.6870383173318448
Epoch: 52 | Iteration number: [3280/4518] 72% | Training loss: 0.6870346406247557
Epoch: 52 | Iteration number: [3290/4518] 72% | Training loss: 0.6870315497225904
Epoch: 52 | Iteration number: [3300/4518] 73% | Training loss: 0.6870281507210299
Epoch: 52 | Iteration number: [3310/4518] 73% | Training loss: 0.6870277156102333
Epoch: 52 | Iteration number: [3320/4518] 73% | Training loss: 0.6870283798640033
Epoch: 52 | Iteration number: [3330/4518] 73% | Training loss: 0.6870253371225821
Epoch: 52 | Iteration number: [3340/4518] 73% | Training loss: 0.6870263583288935
Epoch: 52 | Iteration number: [3350/4518] 74% | Training loss: 0.6870220135219062
Epoch: 52 | Iteration number: [3360/4518] 74% | Training loss: 0.6870206053767886
Epoch: 52 | Iteration number: [3370/4518] 74% | Training loss: 0.6870216157740584
Epoch: 52 | Iteration number: [3380/4518] 74% | Training loss: 0.687021827080546
Epoch: 52 | Iteration number: [3390/4518] 75% | Training loss: 0.6870211300772552
Epoch: 52 | Iteration number: [3400/4518] 75% | Training loss: 0.6870246016979218
Epoch: 52 | Iteration number: [3410/4518] 75% | Training loss: 0.6870233944609019
Epoch: 52 | Iteration number: [3420/4518] 75% | Training loss: 0.6870218873023987
Epoch: 52 | Iteration number: [3430/4518] 75% | Training loss: 0.6870190207534211
Epoch: 52 | Iteration number: [3440/4518] 76% | Training loss: 0.6870176645558934
Epoch: 52 | Iteration number: [3450/4518] 76% | Training loss: 0.6870154381316641
Epoch: 52 | Iteration number: [3460/4518] 76% | Training loss: 0.6870169776368004
Epoch: 52 | Iteration number: [3470/4518] 76% | Training loss: 0.6870141634680008
Epoch: 52 | Iteration number: [3480/4518] 77% | Training loss: 0.6870133032058847
Epoch: 52 | Iteration number: [3490/4518] 77% | Training loss: 0.6870139883719064
Epoch: 52 | Iteration number: [3500/4518] 77% | Training loss: 0.6870150260925293
Epoch: 52 | Iteration number: [3510/4518] 77% | Training loss: 0.6870095163159221
Epoch: 52 | Iteration number: [3520/4518] 77% | Training loss: 0.6870104757052931
Epoch: 52 | Iteration number: [3530/4518] 78% | Training loss: 0.6870039764443471
Epoch: 52 | Iteration number: [3540/4518] 78% | Training loss: 0.6870012390411506
Epoch: 52 | Iteration number: [3550/4518] 78% | Training loss: 0.6869977510647035
Epoch: 52 | Iteration number: [3560/4518] 78% | Training loss: 0.6870008864094702
Epoch: 52 | Iteration number: [3570/4518] 79% | Training loss: 0.6869987481448496
Epoch: 52 | Iteration number: [3580/4518] 79% | Training loss: 0.6869963020918756
Epoch: 52 | Iteration number: [3590/4518] 79% | Training loss: 0.6869970224361898
Epoch: 52 | Iteration number: [3600/4518] 79% | Training loss: 0.6869957932002014
Epoch: 52 | Iteration number: [3610/4518] 79% | Training loss: 0.6869960389308982
Epoch: 52 | Iteration number: [3620/4518] 80% | Training loss: 0.6869930886431952
Epoch: 52 | Iteration number: [3630/4518] 80% | Training loss: 0.6869911980858847
Epoch: 52 | Iteration number: [3640/4518] 80% | Training loss: 0.6869939417629451
Epoch: 52 | Iteration number: [3650/4518] 80% | Training loss: 0.6869920918549577
Epoch: 52 | Iteration number: [3660/4518] 81% | Training loss: 0.6869910000289072
Epoch: 52 | Iteration number: [3670/4518] 81% | Training loss: 0.686989184816137
Epoch: 52 | Iteration number: [3680/4518] 81% | Training loss: 0.6869889493059853
Epoch: 52 | Iteration number: [3690/4518] 81% | Training loss: 0.6869890570155973
Epoch: 52 | Iteration number: [3700/4518] 81% | Training loss: 0.6869878934847342
Epoch: 52 | Iteration number: [3710/4518] 82% | Training loss: 0.6869890002870174
Epoch: 52 | Iteration number: [3720/4518] 82% | Training loss: 0.6869907643365604
Epoch: 52 | Iteration number: [3730/4518] 82% | Training loss: 0.6869894858499634
Epoch: 52 | Iteration number: [3740/4518] 82% | Training loss: 0.6869863697073676
Epoch: 52 | Iteration number: [3750/4518] 83% | Training loss: 0.6869846348921458
Epoch: 52 | Iteration number: [3760/4518] 83% | Training loss: 0.686984771965666
Epoch: 52 | Iteration number: [3770/4518] 83% | Training loss: 0.6869854510462885
Epoch: 52 | Iteration number: [3780/4518] 83% | Training loss: 0.6869851756978917
Epoch: 52 | Iteration number: [3790/4518] 83% | Training loss: 0.6869861448345839
Epoch: 52 | Iteration number: [3800/4518] 84% | Training loss: 0.6869878582891665
Epoch: 52 | Iteration number: [3810/4518] 84% | Training loss: 0.6869850694507439
Epoch: 52 | Iteration number: [3820/4518] 84% | Training loss: 0.6869833741044499
Epoch: 52 | Iteration number: [3830/4518] 84% | Training loss: 0.6869846922299258
Epoch: 52 | Iteration number: [3840/4518] 84% | Training loss: 0.6869840594163785
Epoch: 52 | Iteration number: [3850/4518] 85% | Training loss: 0.6869857543165033
Epoch: 52 | Iteration number: [3860/4518] 85% | Training loss: 0.6869857018630121
Epoch: 52 | Iteration number: [3870/4518] 85% | Training loss: 0.6869835041444123
Epoch: 52 | Iteration number: [3880/4518] 85% | Training loss: 0.6869827019799616
Epoch: 52 | Iteration number: [3890/4518] 86% | Training loss: 0.6869849992135496
Epoch: 52 | Iteration number: [3900/4518] 86% | Training loss: 0.6869808961947759
Epoch: 52 | Iteration number: [3910/4518] 86% | Training loss: 0.6869808305254983
Epoch: 52 | Iteration number: [3920/4518] 86% | Training loss: 0.6869829658799026
Epoch: 52 | Iteration number: [3930/4518] 86% | Training loss: 0.6869831076408464
Epoch: 52 | Iteration number: [3940/4518] 87% | Training loss: 0.6869851304794932
Epoch: 52 | Iteration number: [3950/4518] 87% | Training loss: 0.6869850256322305
Epoch: 52 | Iteration number: [3960/4518] 87% | Training loss: 0.6869830263533978
Epoch: 52 | Iteration number: [3970/4518] 87% | Training loss: 0.6869808300316184
Epoch: 52 | Iteration number: [3980/4518] 88% | Training loss: 0.686978088132101
Epoch: 52 | Iteration number: [3990/4518] 88% | Training loss: 0.6869769888862333
Epoch: 52 | Iteration number: [4000/4518] 88% | Training loss: 0.6869746428132057
Epoch: 52 | Iteration number: [4010/4518] 88% | Training loss: 0.6869745698058397
Epoch: 52 | Iteration number: [4020/4518] 88% | Training loss: 0.6869749940746459
Epoch: 52 | Iteration number: [4030/4518] 89% | Training loss: 0.686975814405801
Epoch: 52 | Iteration number: [4040/4518] 89% | Training loss: 0.6869758139299874
Epoch: 52 | Iteration number: [4050/4518] 89% | Training loss: 0.6869769216761177
Epoch: 52 | Iteration number: [4060/4518] 89% | Training loss: 0.6869775213631503
Epoch: 52 | Iteration number: [4070/4518] 90% | Training loss: 0.686977885323016
Epoch: 52 | Iteration number: [4080/4518] 90% | Training loss: 0.6869783901262517
Epoch: 52 | Iteration number: [4090/4518] 90% | Training loss: 0.6869766546490723
Epoch: 52 | Iteration number: [4100/4518] 90% | Training loss: 0.6869771183263965
Epoch: 52 | Iteration number: [4110/4518] 90% | Training loss: 0.6869787712311802
Epoch: 52 | Iteration number: [4120/4518] 91% | Training loss: 0.6869765692978229
Epoch: 52 | Iteration number: [4130/4518] 91% | Training loss: 0.6869794353157209
Epoch: 52 | Iteration number: [4140/4518] 91% | Training loss: 0.6869770760985389
Epoch: 52 | Iteration number: [4150/4518] 91% | Training loss: 0.6869742973884905
Epoch: 52 | Iteration number: [4160/4518] 92% | Training loss: 0.6869757064259969
Epoch: 52 | Iteration number: [4170/4518] 92% | Training loss: 0.6869746884567847
Epoch: 52 | Iteration number: [4180/4518] 92% | Training loss: 0.6869734389359872
Epoch: 52 | Iteration number: [4190/4518] 92% | Training loss: 0.6869724826198205
Epoch: 52 | Iteration number: [4200/4518] 92% | Training loss: 0.6869720868411519
Epoch: 52 | Iteration number: [4210/4518] 93% | Training loss: 0.6869723097587142
Epoch: 52 | Iteration number: [4220/4518] 93% | Training loss: 0.6869695593677991
Epoch: 52 | Iteration number: [4230/4518] 93% | Training loss: 0.6869678749542146
Epoch: 52 | Iteration number: [4240/4518] 93% | Training loss: 0.6869665636065996
Epoch: 52 | Iteration number: [4250/4518] 94% | Training loss: 0.6869691473315744
Epoch: 52 | Iteration number: [4260/4518] 94% | Training loss: 0.6869672672709389
Epoch: 52 | Iteration number: [4270/4518] 94% | Training loss: 0.6869680325795113
Epoch: 52 | Iteration number: [4280/4518] 94% | Training loss: 0.6869652306643602
Epoch: 52 | Iteration number: [4290/4518] 94% | Training loss: 0.6869675346326717
Epoch: 52 | Iteration number: [4300/4518] 95% | Training loss: 0.6869671687968941
Epoch: 52 | Iteration number: [4310/4518] 95% | Training loss: 0.6869698898006757
Epoch: 52 | Iteration number: [4320/4518] 95% | Training loss: 0.6869666518436538
Epoch: 52 | Iteration number: [4330/4518] 95% | Training loss: 0.6869646355819482
Epoch: 52 | Iteration number: [4340/4518] 96% | Training loss: 0.686965569510438
Epoch: 52 | Iteration number: [4350/4518] 96% | Training loss: 0.6869641513660036
Epoch: 52 | Iteration number: [4360/4518] 96% | Training loss: 0.6869637052400397
Epoch: 52 | Iteration number: [4370/4518] 96% | Training loss: 0.6869648115722211
Epoch: 52 | Iteration number: [4380/4518] 96% | Training loss: 0.6869645885953076
Epoch: 52 | Iteration number: [4390/4518] 97% | Training loss: 0.686966250466866
Epoch: 52 | Iteration number: [4400/4518] 97% | Training loss: 0.686966128742153
Epoch: 52 | Iteration number: [4410/4518] 97% | Training loss: 0.6869630216065448
Epoch: 52 | Iteration number: [4420/4518] 97% | Training loss: 0.6869611566018196
Epoch: 52 | Iteration number: [4430/4518] 98% | Training loss: 0.6869604443454312
Epoch: 52 | Iteration number: [4440/4518] 98% | Training loss: 0.6869591889483435
Epoch: 52 | Iteration number: [4450/4518] 98% | Training loss: 0.6869620126017024
Epoch: 52 | Iteration number: [4460/4518] 98% | Training loss: 0.686959486291013
Epoch: 52 | Iteration number: [4470/4518] 98% | Training loss: 0.6869576600173976
Epoch: 52 | Iteration number: [4480/4518] 99% | Training loss: 0.6869573135727218
Epoch: 52 | Iteration number: [4490/4518] 99% | Training loss: 0.6869591415061186
Epoch: 52 | Iteration number: [4500/4518] 99% | Training loss: 0.6869572647677528
Epoch: 52 | Iteration number: [4510/4518] 99% | Training loss: 0.6869589544584904

 End of epoch: 52 | Train Loss: 0.6868074973793672 | Training Time: 642 

 End of epoch: 52 | Eval Loss: 0.6901037741680535 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/4518] 0% | Training loss: 0.7562054514884948
Epoch: 53 | Iteration number: [20/4518] 0% | Training loss: 0.7213282644748688
Epoch: 53 | Iteration number: [30/4518] 0% | Training loss: 0.7097348173459371
Epoch: 53 | Iteration number: [40/4518] 0% | Training loss: 0.7041463807225228
Epoch: 53 | Iteration number: [50/4518] 1% | Training loss: 0.7010444629192353
Epoch: 53 | Iteration number: [60/4518] 1% | Training loss: 0.6987883865833282
Epoch: 53 | Iteration number: [70/4518] 1% | Training loss: 0.697185184274401
Epoch: 53 | Iteration number: [80/4518] 1% | Training loss: 0.6959307380020618
Epoch: 53 | Iteration number: [90/4518] 1% | Training loss: 0.6948344522052341
Epoch: 53 | Iteration number: [100/4518] 2% | Training loss: 0.6941977155208587
Epoch: 53 | Iteration number: [110/4518] 2% | Training loss: 0.6935543911023574
Epoch: 53 | Iteration number: [120/4518] 2% | Training loss: 0.6929518570502599
Epoch: 53 | Iteration number: [130/4518] 2% | Training loss: 0.6924979278674492
Epoch: 53 | Iteration number: [140/4518] 3% | Training loss: 0.6919903274093355
Epoch: 53 | Iteration number: [150/4518] 3% | Training loss: 0.6916582385698954
Epoch: 53 | Iteration number: [160/4518] 3% | Training loss: 0.6914721459150315
Epoch: 53 | Iteration number: [170/4518] 3% | Training loss: 0.691247903248843
Epoch: 53 | Iteration number: [180/4518] 3% | Training loss: 0.6910530659887526
Epoch: 53 | Iteration number: [190/4518] 4% | Training loss: 0.6908626656783254
Epoch: 53 | Iteration number: [200/4518] 4% | Training loss: 0.6905976402759552
Epoch: 53 | Iteration number: [210/4518] 4% | Training loss: 0.6904242637611571
Epoch: 53 | Iteration number: [220/4518] 4% | Training loss: 0.6902385551821102
Epoch: 53 | Iteration number: [230/4518] 5% | Training loss: 0.6900895559269449
Epoch: 53 | Iteration number: [240/4518] 5% | Training loss: 0.6899445508917172
Epoch: 53 | Iteration number: [250/4518] 5% | Training loss: 0.6898329360485077
Epoch: 53 | Iteration number: [260/4518] 5% | Training loss: 0.6896719072873776
Epoch: 53 | Iteration number: [270/4518] 5% | Training loss: 0.689560118648741
Epoch: 53 | Iteration number: [280/4518] 6% | Training loss: 0.6894671133586339
Epoch: 53 | Iteration number: [290/4518] 6% | Training loss: 0.6893681063734252
Epoch: 53 | Iteration number: [300/4518] 6% | Training loss: 0.6893013745546341
Epoch: 53 | Iteration number: [310/4518] 6% | Training loss: 0.6892525380657565
Epoch: 53 | Iteration number: [320/4518] 7% | Training loss: 0.6891828294843435
Epoch: 53 | Iteration number: [330/4518] 7% | Training loss: 0.6891079187393189
Epoch: 53 | Iteration number: [340/4518] 7% | Training loss: 0.6890317303292891
Epoch: 53 | Iteration number: [350/4518] 7% | Training loss: 0.6889785979475294
Epoch: 53 | Iteration number: [360/4518] 7% | Training loss: 0.6888977767692672
Epoch: 53 | Iteration number: [370/4518] 8% | Training loss: 0.6888502631638501
Epoch: 53 | Iteration number: [380/4518] 8% | Training loss: 0.6888079476983924
Epoch: 53 | Iteration number: [390/4518] 8% | Training loss: 0.6887337327003479
Epoch: 53 | Iteration number: [400/4518] 8% | Training loss: 0.688681970089674
Epoch: 53 | Iteration number: [410/4518] 9% | Training loss: 0.6886400106476575
Epoch: 53 | Iteration number: [420/4518] 9% | Training loss: 0.6885882628815515
Epoch: 53 | Iteration number: [430/4518] 9% | Training loss: 0.6885594427585602
Epoch: 53 | Iteration number: [440/4518] 9% | Training loss: 0.6885393173857168
Epoch: 53 | Iteration number: [450/4518] 9% | Training loss: 0.6884868343671163
Epoch: 53 | Iteration number: [460/4518] 10% | Training loss: 0.6884355169275532
Epoch: 53 | Iteration number: [470/4518] 10% | Training loss: 0.6883826484071448
Epoch: 53 | Iteration number: [480/4518] 10% | Training loss: 0.6883785713464021
Epoch: 53 | Iteration number: [490/4518] 10% | Training loss: 0.6883376057050666
Epoch: 53 | Iteration number: [500/4518] 11% | Training loss: 0.6882989952564239
Epoch: 53 | Iteration number: [510/4518] 11% | Training loss: 0.688247785614986
Epoch: 53 | Iteration number: [520/4518] 11% | Training loss: 0.6882160167281445
Epoch: 53 | Iteration number: [530/4518] 11% | Training loss: 0.6881759278054508
Epoch: 53 | Iteration number: [540/4518] 11% | Training loss: 0.6881517307625876
Epoch: 53 | Iteration number: [550/4518] 12% | Training loss: 0.6881430940194564
Epoch: 53 | Iteration number: [560/4518] 12% | Training loss: 0.6881151918854033
Epoch: 53 | Iteration number: [570/4518] 12% | Training loss: 0.6880867921469505
Epoch: 53 | Iteration number: [580/4518] 12% | Training loss: 0.6880466344027684
Epoch: 53 | Iteration number: [590/4518] 13% | Training loss: 0.6880233185776209
Epoch: 53 | Iteration number: [600/4518] 13% | Training loss: 0.6880096050103506
Epoch: 53 | Iteration number: [610/4518] 13% | Training loss: 0.6880120587153513
Epoch: 53 | Iteration number: [620/4518] 13% | Training loss: 0.687986213834055
Epoch: 53 | Iteration number: [630/4518] 13% | Training loss: 0.6879704491486625
Epoch: 53 | Iteration number: [640/4518] 14% | Training loss: 0.6879565765149891
Epoch: 53 | Iteration number: [650/4518] 14% | Training loss: 0.6879322637044466
Epoch: 53 | Iteration number: [660/4518] 14% | Training loss: 0.6879071510199345
Epoch: 53 | Iteration number: [670/4518] 14% | Training loss: 0.6878754917365402
Epoch: 53 | Iteration number: [680/4518] 15% | Training loss: 0.6878499927766183
Epoch: 53 | Iteration number: [690/4518] 15% | Training loss: 0.6878332752248515
Epoch: 53 | Iteration number: [700/4518] 15% | Training loss: 0.6878465740169798
Epoch: 53 | Iteration number: [710/4518] 15% | Training loss: 0.6878268624695254
Epoch: 53 | Iteration number: [720/4518] 15% | Training loss: 0.6878089559574921
Epoch: 53 | Iteration number: [730/4518] 16% | Training loss: 0.687805042364826
Epoch: 53 | Iteration number: [740/4518] 16% | Training loss: 0.6877956074637336
Epoch: 53 | Iteration number: [750/4518] 16% | Training loss: 0.6877978984514872
Epoch: 53 | Iteration number: [760/4518] 16% | Training loss: 0.6877745533460065
Epoch: 53 | Iteration number: [770/4518] 17% | Training loss: 0.6877718088688789
Epoch: 53 | Iteration number: [780/4518] 17% | Training loss: 0.6877559997332402
Epoch: 53 | Iteration number: [790/4518] 17% | Training loss: 0.6877510874331751
Epoch: 53 | Iteration number: [800/4518] 17% | Training loss: 0.6877452886104584
Epoch: 53 | Iteration number: [810/4518] 17% | Training loss: 0.6877378926600939
Epoch: 53 | Iteration number: [820/4518] 18% | Training loss: 0.6877389894026081
Epoch: 53 | Iteration number: [830/4518] 18% | Training loss: 0.6877287489822111
Epoch: 53 | Iteration number: [840/4518] 18% | Training loss: 0.6877191549965314
Epoch: 53 | Iteration number: [850/4518] 18% | Training loss: 0.6876996256323422
Epoch: 53 | Iteration number: [860/4518] 19% | Training loss: 0.687684267274169
Epoch: 53 | Iteration number: [870/4518] 19% | Training loss: 0.6876702306599453
Epoch: 53 | Iteration number: [880/4518] 19% | Training loss: 0.6876549378037453
Epoch: 53 | Iteration number: [890/4518] 19% | Training loss: 0.6876505076885223
Epoch: 53 | Iteration number: [900/4518] 19% | Training loss: 0.6876299226284027
Epoch: 53 | Iteration number: [910/4518] 20% | Training loss: 0.6876245069634783
Epoch: 53 | Iteration number: [920/4518] 20% | Training loss: 0.6876130905488264
Epoch: 53 | Iteration number: [930/4518] 20% | Training loss: 0.68759078652628
Epoch: 53 | Iteration number: [940/4518] 20% | Training loss: 0.6875821251184382
Epoch: 53 | Iteration number: [950/4518] 21% | Training loss: 0.6875874500525625
Epoch: 53 | Iteration number: [960/4518] 21% | Training loss: 0.6875879447907209
Epoch: 53 | Iteration number: [970/4518] 21% | Training loss: 0.687575098349876
Epoch: 53 | Iteration number: [980/4518] 21% | Training loss: 0.6875673132283348
Epoch: 53 | Iteration number: [990/4518] 21% | Training loss: 0.6875526409558576
Epoch: 53 | Iteration number: [1000/4518] 22% | Training loss: 0.6875381782054901
Epoch: 53 | Iteration number: [1010/4518] 22% | Training loss: 0.6875212033786396
Epoch: 53 | Iteration number: [1020/4518] 22% | Training loss: 0.6875118517992543
Epoch: 53 | Iteration number: [1030/4518] 22% | Training loss: 0.6875184512254103
Epoch: 53 | Iteration number: [1040/4518] 23% | Training loss: 0.6874930641972101
Epoch: 53 | Iteration number: [1050/4518] 23% | Training loss: 0.6874777561142331
Epoch: 53 | Iteration number: [1060/4518] 23% | Training loss: 0.687469612033862
Epoch: 53 | Iteration number: [1070/4518] 23% | Training loss: 0.6874638189222211
Epoch: 53 | Iteration number: [1080/4518] 23% | Training loss: 0.6874644363367999
Epoch: 53 | Iteration number: [1090/4518] 24% | Training loss: 0.6874579315338659
Epoch: 53 | Iteration number: [1100/4518] 24% | Training loss: 0.6874451684409921
Epoch: 53 | Iteration number: [1110/4518] 24% | Training loss: 0.6874414048753343
Epoch: 53 | Iteration number: [1120/4518] 24% | Training loss: 0.6874235187258039
Epoch: 53 | Iteration number: [1130/4518] 25% | Training loss: 0.6874237840682005
Epoch: 53 | Iteration number: [1140/4518] 25% | Training loss: 0.6874217410882314
Epoch: 53 | Iteration number: [1150/4518] 25% | Training loss: 0.6874101088358008
Epoch: 53 | Iteration number: [1160/4518] 25% | Training loss: 0.6874050275005144
Epoch: 53 | Iteration number: [1170/4518] 25% | Training loss: 0.6873977787474281
Epoch: 53 | Iteration number: [1180/4518] 26% | Training loss: 0.6873972293684039
Epoch: 53 | Iteration number: [1190/4518] 26% | Training loss: 0.6873950642697951
Epoch: 53 | Iteration number: [1200/4518] 26% | Training loss: 0.6873877413570881
Epoch: 53 | Iteration number: [1210/4518] 26% | Training loss: 0.6873858198154071
Epoch: 53 | Iteration number: [1220/4518] 27% | Training loss: 0.6873787886295162
Epoch: 53 | Iteration number: [1230/4518] 27% | Training loss: 0.6873713078053016
Epoch: 53 | Iteration number: [1240/4518] 27% | Training loss: 0.6873623457166457
Epoch: 53 | Iteration number: [1250/4518] 27% | Training loss: 0.6873515866756439
Epoch: 53 | Iteration number: [1260/4518] 27% | Training loss: 0.6873530535470872
Epoch: 53 | Iteration number: [1270/4518] 28% | Training loss: 0.687341395794876
Epoch: 53 | Iteration number: [1280/4518] 28% | Training loss: 0.6873435517307371
Epoch: 53 | Iteration number: [1290/4518] 28% | Training loss: 0.6873359022214431
Epoch: 53 | Iteration number: [1300/4518] 28% | Training loss: 0.6873307195535073
Epoch: 53 | Iteration number: [1310/4518] 28% | Training loss: 0.6873227813771663
Epoch: 53 | Iteration number: [1320/4518] 29% | Training loss: 0.6873079614657345
Epoch: 53 | Iteration number: [1330/4518] 29% | Training loss: 0.6873057544231415
Epoch: 53 | Iteration number: [1340/4518] 29% | Training loss: 0.6873080690850073
Epoch: 53 | Iteration number: [1350/4518] 29% | Training loss: 0.6872958140461534
Epoch: 53 | Iteration number: [1360/4518] 30% | Training loss: 0.6872923228232299
Epoch: 53 | Iteration number: [1370/4518] 30% | Training loss: 0.6872951945249182
Epoch: 53 | Iteration number: [1380/4518] 30% | Training loss: 0.6872882094072259
Epoch: 53 | Iteration number: [1390/4518] 30% | Training loss: 0.6872750671218625
Epoch: 53 | Iteration number: [1400/4518] 30% | Training loss: 0.6872719901374408
Epoch: 53 | Iteration number: [1410/4518] 31% | Training loss: 0.6872741549150319
Epoch: 53 | Iteration number: [1420/4518] 31% | Training loss: 0.6872736007394925
Epoch: 53 | Iteration number: [1430/4518] 31% | Training loss: 0.687281843415507
Epoch: 53 | Iteration number: [1440/4518] 31% | Training loss: 0.6872752369278007
Epoch: 53 | Iteration number: [1450/4518] 32% | Training loss: 0.6872759094731561
Epoch: 53 | Iteration number: [1460/4518] 32% | Training loss: 0.6872686872743581
Epoch: 53 | Iteration number: [1470/4518] 32% | Training loss: 0.6872661581655749
Epoch: 53 | Iteration number: [1480/4518] 32% | Training loss: 0.6872513013111579
Epoch: 53 | Iteration number: [1490/4518] 32% | Training loss: 0.6872432593931288
Epoch: 53 | Iteration number: [1500/4518] 33% | Training loss: 0.6872486213048299
Epoch: 53 | Iteration number: [1510/4518] 33% | Training loss: 0.6872355819932673
Epoch: 53 | Iteration number: [1520/4518] 33% | Training loss: 0.687237998098135
Epoch: 53 | Iteration number: [1530/4518] 33% | Training loss: 0.6872340263104906
Epoch: 53 | Iteration number: [1540/4518] 34% | Training loss: 0.6872378819948667
Epoch: 53 | Iteration number: [1550/4518] 34% | Training loss: 0.6872328480212919
Epoch: 53 | Iteration number: [1560/4518] 34% | Training loss: 0.687233295196142
Epoch: 53 | Iteration number: [1570/4518] 34% | Training loss: 0.6872315837699137
Epoch: 53 | Iteration number: [1580/4518] 34% | Training loss: 0.6872214739458471
Epoch: 53 | Iteration number: [1590/4518] 35% | Training loss: 0.6872259120521306
Epoch: 53 | Iteration number: [1600/4518] 35% | Training loss: 0.6872248556092382
Epoch: 53 | Iteration number: [1610/4518] 35% | Training loss: 0.6872221592790592
Epoch: 53 | Iteration number: [1620/4518] 35% | Training loss: 0.687213808261318
Epoch: 53 | Iteration number: [1630/4518] 36% | Training loss: 0.687214362438471
Epoch: 53 | Iteration number: [1640/4518] 36% | Training loss: 0.6872107473088473
Epoch: 53 | Iteration number: [1650/4518] 36% | Training loss: 0.6872153543703484
Epoch: 53 | Iteration number: [1660/4518] 36% | Training loss: 0.687203581577324
Epoch: 53 | Iteration number: [1670/4518] 36% | Training loss: 0.6872062401143376
Epoch: 53 | Iteration number: [1680/4518] 37% | Training loss: 0.6872068047523499
Epoch: 53 | Iteration number: [1690/4518] 37% | Training loss: 0.6872031316602019
Epoch: 53 | Iteration number: [1700/4518] 37% | Training loss: 0.6871980100168902
Epoch: 53 | Iteration number: [1710/4518] 37% | Training loss: 0.6871946939250879
Epoch: 53 | Iteration number: [1720/4518] 38% | Training loss: 0.6871903091322544
Epoch: 53 | Iteration number: [1730/4518] 38% | Training loss: 0.6871884003884531
Epoch: 53 | Iteration number: [1740/4518] 38% | Training loss: 0.687179675424236
Epoch: 53 | Iteration number: [1750/4518] 38% | Training loss: 0.687171998500824
Epoch: 53 | Iteration number: [1760/4518] 38% | Training loss: 0.687167247317054
Epoch: 53 | Iteration number: [1770/4518] 39% | Training loss: 0.6871680162720761
Epoch: 53 | Iteration number: [1780/4518] 39% | Training loss: 0.6871674662225702
Epoch: 53 | Iteration number: [1790/4518] 39% | Training loss: 0.6871674017533244
Epoch: 53 | Iteration number: [1800/4518] 39% | Training loss: 0.6871661265691121
Epoch: 53 | Iteration number: [1810/4518] 40% | Training loss: 0.6871703434385648
Epoch: 53 | Iteration number: [1820/4518] 40% | Training loss: 0.6871637528414255
Epoch: 53 | Iteration number: [1830/4518] 40% | Training loss: 0.687165402714672
Epoch: 53 | Iteration number: [1840/4518] 40% | Training loss: 0.6871673833740795
Epoch: 53 | Iteration number: [1850/4518] 40% | Training loss: 0.6871645131626645
Epoch: 53 | Iteration number: [1860/4518] 41% | Training loss: 0.6871636582318172
Epoch: 53 | Iteration number: [1870/4518] 41% | Training loss: 0.6871629604362549
Epoch: 53 | Iteration number: [1880/4518] 41% | Training loss: 0.6871679432214575
Epoch: 53 | Iteration number: [1890/4518] 41% | Training loss: 0.6871591132784647
Epoch: 53 | Iteration number: [1900/4518] 42% | Training loss: 0.6871534053902877
Epoch: 53 | Iteration number: [1910/4518] 42% | Training loss: 0.6871523329724816
Epoch: 53 | Iteration number: [1920/4518] 42% | Training loss: 0.6871506991796196
Epoch: 53 | Iteration number: [1930/4518] 42% | Training loss: 0.6871463977919959
Epoch: 53 | Iteration number: [1940/4518] 42% | Training loss: 0.6871437423008004
Epoch: 53 | Iteration number: [1950/4518] 43% | Training loss: 0.6871379177998274
Epoch: 53 | Iteration number: [1960/4518] 43% | Training loss: 0.6871388206676561
Epoch: 53 | Iteration number: [1970/4518] 43% | Training loss: 0.687136839246992
Epoch: 53 | Iteration number: [1980/4518] 43% | Training loss: 0.6871323130046478
Epoch: 53 | Iteration number: [1990/4518] 44% | Training loss: 0.6871302474383733
Epoch: 53 | Iteration number: [2000/4518] 44% | Training loss: 0.6871267627477646
Epoch: 53 | Iteration number: [2010/4518] 44% | Training loss: 0.6871276862882263
Epoch: 53 | Iteration number: [2020/4518] 44% | Training loss: 0.6871281908290221
Epoch: 53 | Iteration number: [2030/4518] 44% | Training loss: 0.6871204043844064
Epoch: 53 | Iteration number: [2040/4518] 45% | Training loss: 0.6871160306474742
Epoch: 53 | Iteration number: [2050/4518] 45% | Training loss: 0.6871208426719758
Epoch: 53 | Iteration number: [2060/4518] 45% | Training loss: 0.6871196603601418
Epoch: 53 | Iteration number: [2070/4518] 45% | Training loss: 0.6871198337147202
Epoch: 53 | Iteration number: [2080/4518] 46% | Training loss: 0.6871156579599931
Epoch: 53 | Iteration number: [2090/4518] 46% | Training loss: 0.6871106837639969
Epoch: 53 | Iteration number: [2100/4518] 46% | Training loss: 0.6871082727114359
Epoch: 53 | Iteration number: [2110/4518] 46% | Training loss: 0.6871090869485484
Epoch: 53 | Iteration number: [2120/4518] 46% | Training loss: 0.6871117020834167
Epoch: 53 | Iteration number: [2130/4518] 47% | Training loss: 0.6871061968971306
Epoch: 53 | Iteration number: [2140/4518] 47% | Training loss: 0.6871088146606338
Epoch: 53 | Iteration number: [2150/4518] 47% | Training loss: 0.6871105698929276
Epoch: 53 | Iteration number: [2160/4518] 47% | Training loss: 0.6871128981036169
Epoch: 53 | Iteration number: [2170/4518] 48% | Training loss: 0.6871080607862516
Epoch: 53 | Iteration number: [2180/4518] 48% | Training loss: 0.6871070574182983
Epoch: 53 | Iteration number: [2190/4518] 48% | Training loss: 0.6871003607636718
Epoch: 53 | Iteration number: [2200/4518] 48% | Training loss: 0.6870981129462068
Epoch: 53 | Iteration number: [2210/4518] 48% | Training loss: 0.6870924091446993
Epoch: 53 | Iteration number: [2220/4518] 49% | Training loss: 0.6870933506134395
Epoch: 53 | Iteration number: [2230/4518] 49% | Training loss: 0.6870898691528047
Epoch: 53 | Iteration number: [2240/4518] 49% | Training loss: 0.6870833699724503
Epoch: 53 | Iteration number: [2250/4518] 49% | Training loss: 0.6870838139851888
Epoch: 53 | Iteration number: [2260/4518] 50% | Training loss: 0.6870846653670336
Epoch: 53 | Iteration number: [2270/4518] 50% | Training loss: 0.6870869835567894
Epoch: 53 | Iteration number: [2280/4518] 50% | Training loss: 0.6870843972030439
Epoch: 53 | Iteration number: [2290/4518] 50% | Training loss: 0.6870793635147627
Epoch: 53 | Iteration number: [2300/4518] 50% | Training loss: 0.6870799431075221
Epoch: 53 | Iteration number: [2310/4518] 51% | Training loss: 0.6870874204160847
Epoch: 53 | Iteration number: [2320/4518] 51% | Training loss: 0.6870929013038504
Epoch: 53 | Iteration number: [2330/4518] 51% | Training loss: 0.6870906946740949
Epoch: 53 | Iteration number: [2340/4518] 51% | Training loss: 0.6870833171483798
Epoch: 53 | Iteration number: [2350/4518] 52% | Training loss: 0.6870813204887065
Epoch: 53 | Iteration number: [2360/4518] 52% | Training loss: 0.6870855057896194
Epoch: 53 | Iteration number: [2370/4518] 52% | Training loss: 0.6870840153362178
Epoch: 53 | Iteration number: [2380/4518] 52% | Training loss: 0.687085842835803
Epoch: 53 | Iteration number: [2390/4518] 52% | Training loss: 0.687086394516494
Epoch: 53 | Iteration number: [2400/4518] 53% | Training loss: 0.6870864287515481
Epoch: 53 | Iteration number: [2410/4518] 53% | Training loss: 0.6870846457995814
Epoch: 53 | Iteration number: [2420/4518] 53% | Training loss: 0.6870828920652059
Epoch: 53 | Iteration number: [2430/4518] 53% | Training loss: 0.687081575663492
Epoch: 53 | Iteration number: [2440/4518] 54% | Training loss: 0.687073472581926
Epoch: 53 | Iteration number: [2450/4518] 54% | Training loss: 0.6870713663101197
Epoch: 53 | Iteration number: [2460/4518] 54% | Training loss: 0.6870708468726011
Epoch: 53 | Iteration number: [2470/4518] 54% | Training loss: 0.6870657653219787
Epoch: 53 | Iteration number: [2480/4518] 54% | Training loss: 0.6870641486298653
Epoch: 53 | Iteration number: [2490/4518] 55% | Training loss: 0.6870625674006451
Epoch: 53 | Iteration number: [2500/4518] 55% | Training loss: 0.6870573537588119
Epoch: 53 | Iteration number: [2510/4518] 55% | Training loss: 0.6870594146954586
Epoch: 53 | Iteration number: [2520/4518] 55% | Training loss: 0.687058443185829
Epoch: 53 | Iteration number: [2530/4518] 55% | Training loss: 0.6870584589454968
Epoch: 53 | Iteration number: [2540/4518] 56% | Training loss: 0.6870588298388354
Epoch: 53 | Iteration number: [2550/4518] 56% | Training loss: 0.687054850470786
Epoch: 53 | Iteration number: [2560/4518] 56% | Training loss: 0.6870532667730004
Epoch: 53 | Iteration number: [2570/4518] 56% | Training loss: 0.6870545534540243
Epoch: 53 | Iteration number: [2580/4518] 57% | Training loss: 0.6870578670917555
Epoch: 53 | Iteration number: [2590/4518] 57% | Training loss: 0.6870569141214878
Epoch: 53 | Iteration number: [2600/4518] 57% | Training loss: 0.687057373730036
Epoch: 53 | Iteration number: [2610/4518] 57% | Training loss: 0.6870584745516722
Epoch: 53 | Iteration number: [2620/4518] 57% | Training loss: 0.6870574782367881
Epoch: 53 | Iteration number: [2630/4518] 58% | Training loss: 0.6870518840084511
Epoch: 53 | Iteration number: [2640/4518] 58% | Training loss: 0.6870406379753893
Epoch: 53 | Iteration number: [2650/4518] 58% | Training loss: 0.6870402877735642
Epoch: 53 | Iteration number: [2660/4518] 58% | Training loss: 0.6870398386080462
Epoch: 53 | Iteration number: [2670/4518] 59% | Training loss: 0.6870387494787294
Epoch: 53 | Iteration number: [2680/4518] 59% | Training loss: 0.6870379051165795
Epoch: 53 | Iteration number: [2690/4518] 59% | Training loss: 0.6870368856036531
Epoch: 53 | Iteration number: [2700/4518] 59% | Training loss: 0.6870333189434475
Epoch: 53 | Iteration number: [2710/4518] 59% | Training loss: 0.6870338446539707
Epoch: 53 | Iteration number: [2720/4518] 60% | Training loss: 0.6870347649735563
Epoch: 53 | Iteration number: [2730/4518] 60% | Training loss: 0.6870355716991774
Epoch: 53 | Iteration number: [2740/4518] 60% | Training loss: 0.6870309836020435
Epoch: 53 | Iteration number: [2750/4518] 60% | Training loss: 0.6870290490280498
Epoch: 53 | Iteration number: [2760/4518] 61% | Training loss: 0.6870248012352681
Epoch: 53 | Iteration number: [2770/4518] 61% | Training loss: 0.6870269323514256
Epoch: 53 | Iteration number: [2780/4518] 61% | Training loss: 0.6870263193151076
Epoch: 53 | Iteration number: [2790/4518] 61% | Training loss: 0.687023877328442
Epoch: 53 | Iteration number: [2800/4518] 61% | Training loss: 0.6870261663624219
Epoch: 53 | Iteration number: [2810/4518] 62% | Training loss: 0.6870285856341977
Epoch: 53 | Iteration number: [2820/4518] 62% | Training loss: 0.6870274389255131
Epoch: 53 | Iteration number: [2830/4518] 62% | Training loss: 0.6870231002042656
Epoch: 53 | Iteration number: [2840/4518] 62% | Training loss: 0.6870250221499254
Epoch: 53 | Iteration number: [2850/4518] 63% | Training loss: 0.6870250585622955
Epoch: 53 | Iteration number: [2860/4518] 63% | Training loss: 0.6870251250642163
Epoch: 53 | Iteration number: [2870/4518] 63% | Training loss: 0.6870287367691147
Epoch: 53 | Iteration number: [2880/4518] 63% | Training loss: 0.6870259480136964
Epoch: 53 | Iteration number: [2890/4518] 63% | Training loss: 0.6870214836201454
Epoch: 53 | Iteration number: [2900/4518] 64% | Training loss: 0.6870207537659283
Epoch: 53 | Iteration number: [2910/4518] 64% | Training loss: 0.6870205846848766
Epoch: 53 | Iteration number: [2920/4518] 64% | Training loss: 0.6870233173239721
Epoch: 53 | Iteration number: [2930/4518] 64% | Training loss: 0.6870293296034425
Epoch: 53 | Iteration number: [2940/4518] 65% | Training loss: 0.6870273249084446
Epoch: 53 | Iteration number: [2950/4518] 65% | Training loss: 0.6870231101876598
Epoch: 53 | Iteration number: [2960/4518] 65% | Training loss: 0.687021812776456
Epoch: 53 | Iteration number: [2970/4518] 65% | Training loss: 0.6870268320997155
Epoch: 53 | Iteration number: [2980/4518] 65% | Training loss: 0.6870243014705261
Epoch: 53 | Iteration number: [2990/4518] 66% | Training loss: 0.6870232443745719
Epoch: 53 | Iteration number: [3000/4518] 66% | Training loss: 0.6870241655508678
Epoch: 53 | Iteration number: [3010/4518] 66% | Training loss: 0.6870176198672615
Epoch: 53 | Iteration number: [3020/4518] 66% | Training loss: 0.6870173208366167
Epoch: 53 | Iteration number: [3030/4518] 67% | Training loss: 0.6870215122849241
Epoch: 53 | Iteration number: [3040/4518] 67% | Training loss: 0.6870200125010391
Epoch: 53 | Iteration number: [3050/4518] 67% | Training loss: 0.6870175385475159
Epoch: 53 | Iteration number: [3060/4518] 67% | Training loss: 0.6870176498796425
Epoch: 53 | Iteration number: [3070/4518] 67% | Training loss: 0.6870129799027397
Epoch: 53 | Iteration number: [3080/4518] 68% | Training loss: 0.6870130095776026
Epoch: 53 | Iteration number: [3090/4518] 68% | Training loss: 0.6870119247621703
Epoch: 53 | Iteration number: [3100/4518] 68% | Training loss: 0.6870147382059405
Epoch: 53 | Iteration number: [3110/4518] 68% | Training loss: 0.6870098840385388
Epoch: 53 | Iteration number: [3120/4518] 69% | Training loss: 0.6870144510116333
Epoch: 53 | Iteration number: [3130/4518] 69% | Training loss: 0.6870099552904074
Epoch: 53 | Iteration number: [3140/4518] 69% | Training loss: 0.6870113726064657
Epoch: 53 | Iteration number: [3150/4518] 69% | Training loss: 0.6870097604252043
Epoch: 53 | Iteration number: [3160/4518] 69% | Training loss: 0.6870107399700563
Epoch: 53 | Iteration number: [3170/4518] 70% | Training loss: 0.6870054226568445
Epoch: 53 | Iteration number: [3180/4518] 70% | Training loss: 0.6870057666826548
Epoch: 53 | Iteration number: [3190/4518] 70% | Training loss: 0.687004357725849
Epoch: 53 | Iteration number: [3200/4518] 70% | Training loss: 0.6870057001709938
Epoch: 53 | Iteration number: [3210/4518] 71% | Training loss: 0.6870093450553691
Epoch: 53 | Iteration number: [3220/4518] 71% | Training loss: 0.6870081445630293
Epoch: 53 | Iteration number: [3230/4518] 71% | Training loss: 0.6870104044399026
Epoch: 53 | Iteration number: [3240/4518] 71% | Training loss: 0.6870126774281631
Epoch: 53 | Iteration number: [3250/4518] 71% | Training loss: 0.6870157898572775
Epoch: 53 | Iteration number: [3260/4518] 72% | Training loss: 0.6870157240541435
Epoch: 53 | Iteration number: [3270/4518] 72% | Training loss: 0.6870171686742649
Epoch: 53 | Iteration number: [3280/4518] 72% | Training loss: 0.6870143747729499
Epoch: 53 | Iteration number: [3290/4518] 72% | Training loss: 0.6870187120597051
Epoch: 53 | Iteration number: [3300/4518] 73% | Training loss: 0.687015617887179
Epoch: 53 | Iteration number: [3310/4518] 73% | Training loss: 0.6870157916920423
Epoch: 53 | Iteration number: [3320/4518] 73% | Training loss: 0.6870083492383899
Epoch: 53 | Iteration number: [3330/4518] 73% | Training loss: 0.6870038528879125
Epoch: 53 | Iteration number: [3340/4518] 73% | Training loss: 0.6870066689695427
Epoch: 53 | Iteration number: [3350/4518] 74% | Training loss: 0.687007245643815
Epoch: 53 | Iteration number: [3360/4518] 74% | Training loss: 0.6870070412400223
Epoch: 53 | Iteration number: [3370/4518] 74% | Training loss: 0.6870082246797374
Epoch: 53 | Iteration number: [3380/4518] 74% | Training loss: 0.6870064208669775
Epoch: 53 | Iteration number: [3390/4518] 75% | Training loss: 0.687002433278216
Epoch: 53 | Iteration number: [3400/4518] 75% | Training loss: 0.6870043543682379
Epoch: 53 | Iteration number: [3410/4518] 75% | Training loss: 0.6870084979492199
Epoch: 53 | Iteration number: [3420/4518] 75% | Training loss: 0.6870089364330672
Epoch: 53 | Iteration number: [3430/4518] 75% | Training loss: 0.6870081843335843
Epoch: 53 | Iteration number: [3440/4518] 76% | Training loss: 0.6870095700891905
Epoch: 53 | Iteration number: [3450/4518] 76% | Training loss: 0.6870119402201279
Epoch: 53 | Iteration number: [3460/4518] 76% | Training loss: 0.6870121762759424
Epoch: 53 | Iteration number: [3470/4518] 76% | Training loss: 0.6870100892929935
Epoch: 53 | Iteration number: [3480/4518] 77% | Training loss: 0.6870105409074103
Epoch: 53 | Iteration number: [3490/4518] 77% | Training loss: 0.6870133463666911
Epoch: 53 | Iteration number: [3500/4518] 77% | Training loss: 0.687014196736472
Epoch: 53 | Iteration number: [3510/4518] 77% | Training loss: 0.6870149606992716
Epoch: 53 | Iteration number: [3520/4518] 77% | Training loss: 0.6870134640993042
Epoch: 53 | Iteration number: [3530/4518] 78% | Training loss: 0.6870115734868955
Epoch: 53 | Iteration number: [3540/4518] 78% | Training loss: 0.6870097346561777
Epoch: 53 | Iteration number: [3550/4518] 78% | Training loss: 0.6870074986068295
Epoch: 53 | Iteration number: [3560/4518] 78% | Training loss: 0.6870041565781229
Epoch: 53 | Iteration number: [3570/4518] 79% | Training loss: 0.6870040967016995
Epoch: 53 | Iteration number: [3580/4518] 79% | Training loss: 0.6870046712499757
Epoch: 53 | Iteration number: [3590/4518] 79% | Training loss: 0.6870027809421996
Epoch: 53 | Iteration number: [3600/4518] 79% | Training loss: 0.6870017147560914
Epoch: 53 | Iteration number: [3610/4518] 79% | Training loss: 0.6869999428535102
Epoch: 53 | Iteration number: [3620/4518] 80% | Training loss: 0.6869943777171288
Epoch: 53 | Iteration number: [3630/4518] 80% | Training loss: 0.6869939463854493
Epoch: 53 | Iteration number: [3640/4518] 80% | Training loss: 0.6869945011951111
Epoch: 53 | Iteration number: [3650/4518] 80% | Training loss: 0.6869902404040507
Epoch: 53 | Iteration number: [3660/4518] 81% | Training loss: 0.6869941328881217
Epoch: 53 | Iteration number: [3670/4518] 81% | Training loss: 0.6869938464028309
Epoch: 53 | Iteration number: [3680/4518] 81% | Training loss: 0.6869923476615678
Epoch: 53 | Iteration number: [3690/4518] 81% | Training loss: 0.6869925878073788
Epoch: 53 | Iteration number: [3700/4518] 81% | Training loss: 0.6869949166678093
Epoch: 53 | Iteration number: [3710/4518] 82% | Training loss: 0.686991175776222
Epoch: 53 | Iteration number: [3720/4518] 82% | Training loss: 0.6869922093486274
Epoch: 53 | Iteration number: [3730/4518] 82% | Training loss: 0.6869894041292789
Epoch: 53 | Iteration number: [3740/4518] 82% | Training loss: 0.6869927398979983
Epoch: 53 | Iteration number: [3750/4518] 83% | Training loss: 0.6869897209962209
Epoch: 53 | Iteration number: [3760/4518] 83% | Training loss: 0.6869889230011625
Epoch: 53 | Iteration number: [3770/4518] 83% | Training loss: 0.6869920990353238
Epoch: 53 | Iteration number: [3780/4518] 83% | Training loss: 0.6869926292902578
Epoch: 53 | Iteration number: [3790/4518] 83% | Training loss: 0.6869946336211504
Epoch: 53 | Iteration number: [3800/4518] 84% | Training loss: 0.6869937225705699
Epoch: 53 | Iteration number: [3810/4518] 84% | Training loss: 0.6869959599546247
Epoch: 53 | Iteration number: [3820/4518] 84% | Training loss: 0.6869959920800793
Epoch: 53 | Iteration number: [3830/4518] 84% | Training loss: 0.6869958701862057
Epoch: 53 | Iteration number: [3840/4518] 84% | Training loss: 0.6869938142287234
Epoch: 53 | Iteration number: [3850/4518] 85% | Training loss: 0.6869950900294564
Epoch: 53 | Iteration number: [3860/4518] 85% | Training loss: 0.686996121804949
Epoch: 53 | Iteration number: [3870/4518] 85% | Training loss: 0.6869948608314652
Epoch: 53 | Iteration number: [3880/4518] 85% | Training loss: 0.6869936771306795
Epoch: 53 | Iteration number: [3890/4518] 86% | Training loss: 0.6869911804144058
Epoch: 53 | Iteration number: [3900/4518] 86% | Training loss: 0.6869927718853339
Epoch: 53 | Iteration number: [3910/4518] 86% | Training loss: 0.6869921442340402
Epoch: 53 | Iteration number: [3920/4518] 86% | Training loss: 0.6869897986857258
Epoch: 53 | Iteration number: [3930/4518] 86% | Training loss: 0.6869879563194499
Epoch: 53 | Iteration number: [3940/4518] 87% | Training loss: 0.6869852883259052
Epoch: 53 | Iteration number: [3950/4518] 87% | Training loss: 0.6869831877569609
Epoch: 53 | Iteration number: [3960/4518] 87% | Training loss: 0.6869818901473825
Epoch: 53 | Iteration number: [3970/4518] 87% | Training loss: 0.6869815927158375
Epoch: 53 | Iteration number: [3980/4518] 88% | Training loss: 0.6869835705912892
Epoch: 53 | Iteration number: [3990/4518] 88% | Training loss: 0.6869853366437114
Epoch: 53 | Iteration number: [4000/4518] 88% | Training loss: 0.68698743262887
Epoch: 53 | Iteration number: [4010/4518] 88% | Training loss: 0.6869837700131528
Epoch: 53 | Iteration number: [4020/4518] 88% | Training loss: 0.6869812943152527
Epoch: 53 | Iteration number: [4030/4518] 89% | Training loss: 0.6869822090524006
Epoch: 53 | Iteration number: [4040/4518] 89% | Training loss: 0.6869815779647025
Epoch: 53 | Iteration number: [4050/4518] 89% | Training loss: 0.6869808651046988
Epoch: 53 | Iteration number: [4060/4518] 89% | Training loss: 0.6869804938144872
Epoch: 53 | Iteration number: [4070/4518] 90% | Training loss: 0.6869833569415371
Epoch: 53 | Iteration number: [4080/4518] 90% | Training loss: 0.6869841510612591
Epoch: 53 | Iteration number: [4090/4518] 90% | Training loss: 0.6869804289346803
Epoch: 53 | Iteration number: [4100/4518] 90% | Training loss: 0.6869754726712297
Epoch: 53 | Iteration number: [4110/4518] 90% | Training loss: 0.6869734974673195
Epoch: 53 | Iteration number: [4120/4518] 91% | Training loss: 0.6869734236048263
Epoch: 53 | Iteration number: [4130/4518] 91% | Training loss: 0.6869720617160382
Epoch: 53 | Iteration number: [4140/4518] 91% | Training loss: 0.6869724734969761
Epoch: 53 | Iteration number: [4150/4518] 91% | Training loss: 0.6869755322531045
Epoch: 53 | Iteration number: [4160/4518] 92% | Training loss: 0.6869747252561725
Epoch: 53 | Iteration number: [4170/4518] 92% | Training loss: 0.6869759310063698
Epoch: 53 | Iteration number: [4180/4518] 92% | Training loss: 0.6869762963798057
Epoch: 53 | Iteration number: [4190/4518] 92% | Training loss: 0.6869760533079042
Epoch: 53 | Iteration number: [4200/4518] 92% | Training loss: 0.6869755220413208
Epoch: 53 | Iteration number: [4210/4518] 93% | Training loss: 0.6869764544476806
Epoch: 53 | Iteration number: [4220/4518] 93% | Training loss: 0.6869782471826291
Epoch: 53 | Iteration number: [4230/4518] 93% | Training loss: 0.6869777396074705
Epoch: 53 | Iteration number: [4240/4518] 93% | Training loss: 0.6869764939934577
Epoch: 53 | Iteration number: [4250/4518] 94% | Training loss: 0.6869745648468242
Epoch: 53 | Iteration number: [4260/4518] 94% | Training loss: 0.686976734979052
Epoch: 53 | Iteration number: [4270/4518] 94% | Training loss: 0.6869755177224268
Epoch: 53 | Iteration number: [4280/4518] 94% | Training loss: 0.6869756161191753
Epoch: 53 | Iteration number: [4290/4518] 94% | Training loss: 0.6869766283841122
Epoch: 53 | Iteration number: [4300/4518] 95% | Training loss: 0.6869783748443736
Epoch: 53 | Iteration number: [4310/4518] 95% | Training loss: 0.6869793173885124
Epoch: 53 | Iteration number: [4320/4518] 95% | Training loss: 0.686978016724741
Epoch: 53 | Iteration number: [4330/4518] 95% | Training loss: 0.6869794445555425
Epoch: 53 | Iteration number: [4340/4518] 96% | Training loss: 0.6869791752045056
Epoch: 53 | Iteration number: [4350/4518] 96% | Training loss: 0.6869798883898505
Epoch: 53 | Iteration number: [4360/4518] 96% | Training loss: 0.6869763989514167
Epoch: 53 | Iteration number: [4370/4518] 96% | Training loss: 0.6869708586339274
Epoch: 53 | Iteration number: [4380/4518] 96% | Training loss: 0.6869705801549023
Epoch: 53 | Iteration number: [4390/4518] 97% | Training loss: 0.6869690838462943
Epoch: 53 | Iteration number: [4400/4518] 97% | Training loss: 0.68696931688623
Epoch: 53 | Iteration number: [4410/4518] 97% | Training loss: 0.6869677533638451
Epoch: 53 | Iteration number: [4420/4518] 97% | Training loss: 0.6869675368475159
Epoch: 53 | Iteration number: [4430/4518] 98% | Training loss: 0.6869680275093621
Epoch: 53 | Iteration number: [4440/4518] 98% | Training loss: 0.6869667962998958
Epoch: 53 | Iteration number: [4450/4518] 98% | Training loss: 0.686965538973219
Epoch: 53 | Iteration number: [4460/4518] 98% | Training loss: 0.6869647302301475
Epoch: 53 | Iteration number: [4470/4518] 98% | Training loss: 0.6869643014016034
Epoch: 53 | Iteration number: [4480/4518] 99% | Training loss: 0.6869677045648651
Epoch: 53 | Iteration number: [4490/4518] 99% | Training loss: 0.6869656760204077
Epoch: 53 | Iteration number: [4500/4518] 99% | Training loss: 0.6869644972483318
Epoch: 53 | Iteration number: [4510/4518] 99% | Training loss: 0.6869634491377025

 End of epoch: 53 | Train Loss: 0.6868073724180579 | Training Time: 642 

 End of epoch: 53 | Eval Loss: 0.6900710414867012 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/4518] 0% | Training loss: 0.7565192103385925
Epoch: 54 | Iteration number: [20/4518] 0% | Training loss: 0.7222908347845077
Epoch: 54 | Iteration number: [30/4518] 0% | Training loss: 0.7101474980513255
Epoch: 54 | Iteration number: [40/4518] 0% | Training loss: 0.7040580376982689
Epoch: 54 | Iteration number: [50/4518] 1% | Training loss: 0.7005649495124817
Epoch: 54 | Iteration number: [60/4518] 1% | Training loss: 0.6981300791104634
Epoch: 54 | Iteration number: [70/4518] 1% | Training loss: 0.6964645215443203
Epoch: 54 | Iteration number: [80/4518] 1% | Training loss: 0.695228996872902
Epoch: 54 | Iteration number: [90/4518] 1% | Training loss: 0.6943792952431573
Epoch: 54 | Iteration number: [100/4518] 2% | Training loss: 0.6936467027664185
Epoch: 54 | Iteration number: [110/4518] 2% | Training loss: 0.6930467909032648
Epoch: 54 | Iteration number: [120/4518] 2% | Training loss: 0.6924819727738698
Epoch: 54 | Iteration number: [130/4518] 2% | Training loss: 0.6920587438803453
Epoch: 54 | Iteration number: [140/4518] 3% | Training loss: 0.6916166305541992
Epoch: 54 | Iteration number: [150/4518] 3% | Training loss: 0.6913665084044138
Epoch: 54 | Iteration number: [160/4518] 3% | Training loss: 0.6911545816808939
Epoch: 54 | Iteration number: [170/4518] 3% | Training loss: 0.6908557534217834
Epoch: 54 | Iteration number: [180/4518] 3% | Training loss: 0.6905935360325708
Epoch: 54 | Iteration number: [190/4518] 4% | Training loss: 0.6903946456156279
Epoch: 54 | Iteration number: [200/4518] 4% | Training loss: 0.6902317371964455
Epoch: 54 | Iteration number: [210/4518] 4% | Training loss: 0.6900653782345
Epoch: 54 | Iteration number: [220/4518] 4% | Training loss: 0.6899026667529886
Epoch: 54 | Iteration number: [230/4518] 5% | Training loss: 0.689757183842037
Epoch: 54 | Iteration number: [240/4518] 5% | Training loss: 0.6896342533330123
Epoch: 54 | Iteration number: [250/4518] 5% | Training loss: 0.689430801153183
Epoch: 54 | Iteration number: [260/4518] 5% | Training loss: 0.6893169029400898
Epoch: 54 | Iteration number: [270/4518] 5% | Training loss: 0.6892514019100754
Epoch: 54 | Iteration number: [280/4518] 6% | Training loss: 0.6891742991549629
Epoch: 54 | Iteration number: [290/4518] 6% | Training loss: 0.6891436091784773
Epoch: 54 | Iteration number: [300/4518] 6% | Training loss: 0.6890707109371821
Epoch: 54 | Iteration number: [310/4518] 6% | Training loss: 0.6890311381509228
Epoch: 54 | Iteration number: [320/4518] 7% | Training loss: 0.6889723993837833
Epoch: 54 | Iteration number: [330/4518] 7% | Training loss: 0.6889035351348646
Epoch: 54 | Iteration number: [340/4518] 7% | Training loss: 0.6888596301569658
Epoch: 54 | Iteration number: [350/4518] 7% | Training loss: 0.688789073739733
Epoch: 54 | Iteration number: [360/4518] 7% | Training loss: 0.6887324573265181
Epoch: 54 | Iteration number: [370/4518] 8% | Training loss: 0.6886731821137506
Epoch: 54 | Iteration number: [380/4518] 8% | Training loss: 0.6886106042485488
Epoch: 54 | Iteration number: [390/4518] 8% | Training loss: 0.6886067610520583
Epoch: 54 | Iteration number: [400/4518] 8% | Training loss: 0.6885489381849765
Epoch: 54 | Iteration number: [410/4518] 9% | Training loss: 0.6884872923536999
Epoch: 54 | Iteration number: [420/4518] 9% | Training loss: 0.6884736682687487
Epoch: 54 | Iteration number: [430/4518] 9% | Training loss: 0.6884417356446731
Epoch: 54 | Iteration number: [440/4518] 9% | Training loss: 0.6883734541860493
Epoch: 54 | Iteration number: [450/4518] 9% | Training loss: 0.6883246378103892
Epoch: 54 | Iteration number: [460/4518] 10% | Training loss: 0.6882787337769632
Epoch: 54 | Iteration number: [470/4518] 10% | Training loss: 0.6882401314187557
Epoch: 54 | Iteration number: [480/4518] 10% | Training loss: 0.6881983454028765
Epoch: 54 | Iteration number: [490/4518] 10% | Training loss: 0.6881359292536365
Epoch: 54 | Iteration number: [500/4518] 11% | Training loss: 0.6881174013614655
Epoch: 54 | Iteration number: [510/4518] 11% | Training loss: 0.6881205464110655
Epoch: 54 | Iteration number: [520/4518] 11% | Training loss: 0.6881231976243166
Epoch: 54 | Iteration number: [530/4518] 11% | Training loss: 0.6881100740072862
Epoch: 54 | Iteration number: [540/4518] 11% | Training loss: 0.6880610134866503
Epoch: 54 | Iteration number: [550/4518] 12% | Training loss: 0.6880278610099446
Epoch: 54 | Iteration number: [560/4518] 12% | Training loss: 0.6880155632538455
Epoch: 54 | Iteration number: [570/4518] 12% | Training loss: 0.6879923614493587
Epoch: 54 | Iteration number: [580/4518] 12% | Training loss: 0.6879776939235884
Epoch: 54 | Iteration number: [590/4518] 13% | Training loss: 0.6879552488609896
Epoch: 54 | Iteration number: [600/4518] 13% | Training loss: 0.6879293851057688
Epoch: 54 | Iteration number: [610/4518] 13% | Training loss: 0.6879111965171626
Epoch: 54 | Iteration number: [620/4518] 13% | Training loss: 0.6878886071905013
Epoch: 54 | Iteration number: [630/4518] 13% | Training loss: 0.6878782379248786
Epoch: 54 | Iteration number: [640/4518] 14% | Training loss: 0.6878667584620416
Epoch: 54 | Iteration number: [650/4518] 14% | Training loss: 0.6878662324868716
Epoch: 54 | Iteration number: [660/4518] 14% | Training loss: 0.687832711501555
Epoch: 54 | Iteration number: [670/4518] 14% | Training loss: 0.6878146524749585
Epoch: 54 | Iteration number: [680/4518] 15% | Training loss: 0.6878182985326823
Epoch: 54 | Iteration number: [690/4518] 15% | Training loss: 0.6878083318039991
Epoch: 54 | Iteration number: [700/4518] 15% | Training loss: 0.6877819841248648
Epoch: 54 | Iteration number: [710/4518] 15% | Training loss: 0.6877760785566249
Epoch: 54 | Iteration number: [720/4518] 15% | Training loss: 0.6877729302479161
Epoch: 54 | Iteration number: [730/4518] 16% | Training loss: 0.687758567153591
Epoch: 54 | Iteration number: [740/4518] 16% | Training loss: 0.6877487515275543
Epoch: 54 | Iteration number: [750/4518] 16% | Training loss: 0.6877160079479218
Epoch: 54 | Iteration number: [760/4518] 16% | Training loss: 0.6877080732270291
Epoch: 54 | Iteration number: [770/4518] 17% | Training loss: 0.6876852375346345
Epoch: 54 | Iteration number: [780/4518] 17% | Training loss: 0.6876779212401464
Epoch: 54 | Iteration number: [790/4518] 17% | Training loss: 0.6876534763770767
Epoch: 54 | Iteration number: [800/4518] 17% | Training loss: 0.6876554704457521
Epoch: 54 | Iteration number: [810/4518] 17% | Training loss: 0.6876389722765228
Epoch: 54 | Iteration number: [820/4518] 18% | Training loss: 0.6876358996804167
Epoch: 54 | Iteration number: [830/4518] 18% | Training loss: 0.6876270211604705
Epoch: 54 | Iteration number: [840/4518] 18% | Training loss: 0.687613751419953
Epoch: 54 | Iteration number: [850/4518] 18% | Training loss: 0.6875855776842903
Epoch: 54 | Iteration number: [860/4518] 19% | Training loss: 0.6875764154417571
Epoch: 54 | Iteration number: [870/4518] 19% | Training loss: 0.687566030642082
Epoch: 54 | Iteration number: [880/4518] 19% | Training loss: 0.6875542990863324
Epoch: 54 | Iteration number: [890/4518] 19% | Training loss: 0.6875458918260724
Epoch: 54 | Iteration number: [900/4518] 19% | Training loss: 0.6875375763575235
Epoch: 54 | Iteration number: [910/4518] 20% | Training loss: 0.6875461510249546
Epoch: 54 | Iteration number: [920/4518] 20% | Training loss: 0.6875324651598931
Epoch: 54 | Iteration number: [930/4518] 20% | Training loss: 0.6875202575678466
Epoch: 54 | Iteration number: [940/4518] 20% | Training loss: 0.6875203457284481
Epoch: 54 | Iteration number: [950/4518] 21% | Training loss: 0.6875098371505737
Epoch: 54 | Iteration number: [960/4518] 21% | Training loss: 0.6874965767065684
Epoch: 54 | Iteration number: [970/4518] 21% | Training loss: 0.6874945982829812
Epoch: 54 | Iteration number: [980/4518] 21% | Training loss: 0.687482254480829
Epoch: 54 | Iteration number: [990/4518] 21% | Training loss: 0.6874574241614101
Epoch: 54 | Iteration number: [1000/4518] 22% | Training loss: 0.6874473903179169
Epoch: 54 | Iteration number: [1010/4518] 22% | Training loss: 0.6874425880389639
Epoch: 54 | Iteration number: [1020/4518] 22% | Training loss: 0.6874357457838807
Epoch: 54 | Iteration number: [1030/4518] 22% | Training loss: 0.6874342685764275
Epoch: 54 | Iteration number: [1040/4518] 23% | Training loss: 0.6874248683452606
Epoch: 54 | Iteration number: [1050/4518] 23% | Training loss: 0.687419673204422
Epoch: 54 | Iteration number: [1060/4518] 23% | Training loss: 0.6874118823487804
Epoch: 54 | Iteration number: [1070/4518] 23% | Training loss: 0.6874109942779363
Epoch: 54 | Iteration number: [1080/4518] 23% | Training loss: 0.687397428629575
Epoch: 54 | Iteration number: [1090/4518] 24% | Training loss: 0.687391197681427
Epoch: 54 | Iteration number: [1100/4518] 24% | Training loss: 0.6873820851607756
Epoch: 54 | Iteration number: [1110/4518] 24% | Training loss: 0.6873837636934744
Epoch: 54 | Iteration number: [1120/4518] 24% | Training loss: 0.6873715244765792
Epoch: 54 | Iteration number: [1130/4518] 25% | Training loss: 0.6873708732887707
Epoch: 54 | Iteration number: [1140/4518] 25% | Training loss: 0.6873683804482744
Epoch: 54 | Iteration number: [1150/4518] 25% | Training loss: 0.6873627688573755
Epoch: 54 | Iteration number: [1160/4518] 25% | Training loss: 0.6873619584173992
Epoch: 54 | Iteration number: [1170/4518] 25% | Training loss: 0.6873492509890825
Epoch: 54 | Iteration number: [1180/4518] 26% | Training loss: 0.6873438782611135
Epoch: 54 | Iteration number: [1190/4518] 26% | Training loss: 0.6873417308350571
Epoch: 54 | Iteration number: [1200/4518] 26% | Training loss: 0.6873221828540166
Epoch: 54 | Iteration number: [1210/4518] 26% | Training loss: 0.6873317197827268
Epoch: 54 | Iteration number: [1220/4518] 27% | Training loss: 0.6873332040720299
Epoch: 54 | Iteration number: [1230/4518] 27% | Training loss: 0.6873177004538901
Epoch: 54 | Iteration number: [1240/4518] 27% | Training loss: 0.6873066859379892
Epoch: 54 | Iteration number: [1250/4518] 27% | Training loss: 0.6873048268795013
Epoch: 54 | Iteration number: [1260/4518] 27% | Training loss: 0.6873080435726378
Epoch: 54 | Iteration number: [1270/4518] 28% | Training loss: 0.6873093815769736
Epoch: 54 | Iteration number: [1280/4518] 28% | Training loss: 0.6873175346292555
Epoch: 54 | Iteration number: [1290/4518] 28% | Training loss: 0.6873064658438512
Epoch: 54 | Iteration number: [1300/4518] 28% | Training loss: 0.6873069944748512
Epoch: 54 | Iteration number: [1310/4518] 28% | Training loss: 0.6873060807471967
Epoch: 54 | Iteration number: [1320/4518] 29% | Training loss: 0.6873096740155509
Epoch: 54 | Iteration number: [1330/4518] 29% | Training loss: 0.6873078296955367
Epoch: 54 | Iteration number: [1340/4518] 29% | Training loss: 0.6873044486366101
Epoch: 54 | Iteration number: [1350/4518] 29% | Training loss: 0.6872949862038648
Epoch: 54 | Iteration number: [1360/4518] 30% | Training loss: 0.6872948946321712
Epoch: 54 | Iteration number: [1370/4518] 30% | Training loss: 0.6872989154645126
Epoch: 54 | Iteration number: [1380/4518] 30% | Training loss: 0.6873066646033439
Epoch: 54 | Iteration number: [1390/4518] 30% | Training loss: 0.6873031846482119
Epoch: 54 | Iteration number: [1400/4518] 30% | Training loss: 0.6873014188238553
Epoch: 54 | Iteration number: [1410/4518] 31% | Training loss: 0.687297426893356
Epoch: 54 | Iteration number: [1420/4518] 31% | Training loss: 0.6873011395964824
Epoch: 54 | Iteration number: [1430/4518] 31% | Training loss: 0.6873080054363171
Epoch: 54 | Iteration number: [1440/4518] 31% | Training loss: 0.6873000070452691
Epoch: 54 | Iteration number: [1450/4518] 32% | Training loss: 0.687292600335746
Epoch: 54 | Iteration number: [1460/4518] 32% | Training loss: 0.6872887366438565
Epoch: 54 | Iteration number: [1470/4518] 32% | Training loss: 0.6872864974193833
Epoch: 54 | Iteration number: [1480/4518] 32% | Training loss: 0.6872677567842844
Epoch: 54 | Iteration number: [1490/4518] 32% | Training loss: 0.6872640790955332
Epoch: 54 | Iteration number: [1500/4518] 33% | Training loss: 0.6872561883131663
Epoch: 54 | Iteration number: [1510/4518] 33% | Training loss: 0.6872583266520342
Epoch: 54 | Iteration number: [1520/4518] 33% | Training loss: 0.6872533775866032
Epoch: 54 | Iteration number: [1530/4518] 33% | Training loss: 0.6872520308089413
Epoch: 54 | Iteration number: [1540/4518] 34% | Training loss: 0.6872477618904856
Epoch: 54 | Iteration number: [1550/4518] 34% | Training loss: 0.6872405117173349
Epoch: 54 | Iteration number: [1560/4518] 34% | Training loss: 0.6872416450427129
Epoch: 54 | Iteration number: [1570/4518] 34% | Training loss: 0.6872430189399962
Epoch: 54 | Iteration number: [1580/4518] 34% | Training loss: 0.6872298971384386
Epoch: 54 | Iteration number: [1590/4518] 35% | Training loss: 0.6872303746031515
Epoch: 54 | Iteration number: [1600/4518] 35% | Training loss: 0.6872272940725088
Epoch: 54 | Iteration number: [1610/4518] 35% | Training loss: 0.687228867133952
Epoch: 54 | Iteration number: [1620/4518] 35% | Training loss: 0.6872136349295392
Epoch: 54 | Iteration number: [1630/4518] 36% | Training loss: 0.6872190029343213
Epoch: 54 | Iteration number: [1640/4518] 36% | Training loss: 0.6872186205372578
Epoch: 54 | Iteration number: [1650/4518] 36% | Training loss: 0.6872124022426027
Epoch: 54 | Iteration number: [1660/4518] 36% | Training loss: 0.6872154041227088
Epoch: 54 | Iteration number: [1670/4518] 36% | Training loss: 0.6872054912372978
Epoch: 54 | Iteration number: [1680/4518] 37% | Training loss: 0.6872012955092248
Epoch: 54 | Iteration number: [1690/4518] 37% | Training loss: 0.6871930282496842
Epoch: 54 | Iteration number: [1700/4518] 37% | Training loss: 0.6871914898297365
Epoch: 54 | Iteration number: [1710/4518] 37% | Training loss: 0.6871953982358787
Epoch: 54 | Iteration number: [1720/4518] 38% | Training loss: 0.6871983501107194
Epoch: 54 | Iteration number: [1730/4518] 38% | Training loss: 0.6871945842842146
Epoch: 54 | Iteration number: [1740/4518] 38% | Training loss: 0.687197508894164
Epoch: 54 | Iteration number: [1750/4518] 38% | Training loss: 0.6871932347502028
Epoch: 54 | Iteration number: [1760/4518] 38% | Training loss: 0.6871901686218652
Epoch: 54 | Iteration number: [1770/4518] 39% | Training loss: 0.6871860179523964
Epoch: 54 | Iteration number: [1780/4518] 39% | Training loss: 0.6871863858083661
Epoch: 54 | Iteration number: [1790/4518] 39% | Training loss: 0.6871836078233559
Epoch: 54 | Iteration number: [1800/4518] 39% | Training loss: 0.6871803440319167
Epoch: 54 | Iteration number: [1810/4518] 40% | Training loss: 0.6871748439514834
Epoch: 54 | Iteration number: [1820/4518] 40% | Training loss: 0.687167670405828
Epoch: 54 | Iteration number: [1830/4518] 40% | Training loss: 0.6871643597636717
Epoch: 54 | Iteration number: [1840/4518] 40% | Training loss: 0.6871606521632361
Epoch: 54 | Iteration number: [1850/4518] 40% | Training loss: 0.6871631621670079
Epoch: 54 | Iteration number: [1860/4518] 41% | Training loss: 0.6871663065046393
Epoch: 54 | Iteration number: [1870/4518] 41% | Training loss: 0.6871639348287634
Epoch: 54 | Iteration number: [1880/4518] 41% | Training loss: 0.6871600634240089
Epoch: 54 | Iteration number: [1890/4518] 41% | Training loss: 0.6871504250342253
Epoch: 54 | Iteration number: [1900/4518] 42% | Training loss: 0.6871471902571227
Epoch: 54 | Iteration number: [1910/4518] 42% | Training loss: 0.6871452552797906
Epoch: 54 | Iteration number: [1920/4518] 42% | Training loss: 0.6871366937023898
Epoch: 54 | Iteration number: [1930/4518] 42% | Training loss: 0.6871392842710327
Epoch: 54 | Iteration number: [1940/4518] 42% | Training loss: 0.6871455273062912
Epoch: 54 | Iteration number: [1950/4518] 43% | Training loss: 0.6871429026126862
Epoch: 54 | Iteration number: [1960/4518] 43% | Training loss: 0.6871413330642544
Epoch: 54 | Iteration number: [1970/4518] 43% | Training loss: 0.6871438770124755
Epoch: 54 | Iteration number: [1980/4518] 43% | Training loss: 0.6871428812092001
Epoch: 54 | Iteration number: [1990/4518] 44% | Training loss: 0.6871377404610716
Epoch: 54 | Iteration number: [2000/4518] 44% | Training loss: 0.6871425625085831
Epoch: 54 | Iteration number: [2010/4518] 44% | Training loss: 0.687140947847224
Epoch: 54 | Iteration number: [2020/4518] 44% | Training loss: 0.6871423999861915
Epoch: 54 | Iteration number: [2030/4518] 44% | Training loss: 0.6871407508556479
Epoch: 54 | Iteration number: [2040/4518] 45% | Training loss: 0.6871378806876202
Epoch: 54 | Iteration number: [2050/4518] 45% | Training loss: 0.6871328952254319
Epoch: 54 | Iteration number: [2060/4518] 45% | Training loss: 0.6871325020940559
Epoch: 54 | Iteration number: [2070/4518] 45% | Training loss: 0.6871299586434295
Epoch: 54 | Iteration number: [2080/4518] 46% | Training loss: 0.6871283830931554
Epoch: 54 | Iteration number: [2090/4518] 46% | Training loss: 0.6871268855042435
Epoch: 54 | Iteration number: [2100/4518] 46% | Training loss: 0.6871297241676422
Epoch: 54 | Iteration number: [2110/4518] 46% | Training loss: 0.6871233053117002
Epoch: 54 | Iteration number: [2120/4518] 46% | Training loss: 0.6871213687759525
Epoch: 54 | Iteration number: [2130/4518] 47% | Training loss: 0.6871224295085585
Epoch: 54 | Iteration number: [2140/4518] 47% | Training loss: 0.6871258262997476
Epoch: 54 | Iteration number: [2150/4518] 47% | Training loss: 0.6871291339120199
Epoch: 54 | Iteration number: [2160/4518] 47% | Training loss: 0.6871233139049124
Epoch: 54 | Iteration number: [2170/4518] 48% | Training loss: 0.687130405194199
Epoch: 54 | Iteration number: [2180/4518] 48% | Training loss: 0.6871275986006501
Epoch: 54 | Iteration number: [2190/4518] 48% | Training loss: 0.6871235026616485
Epoch: 54 | Iteration number: [2200/4518] 48% | Training loss: 0.6871223244883797
Epoch: 54 | Iteration number: [2210/4518] 48% | Training loss: 0.6871224772336796
Epoch: 54 | Iteration number: [2220/4518] 49% | Training loss: 0.687124158374898
Epoch: 54 | Iteration number: [2230/4518] 49% | Training loss: 0.6871252238750458
Epoch: 54 | Iteration number: [2240/4518] 49% | Training loss: 0.6871241223067045
Epoch: 54 | Iteration number: [2250/4518] 49% | Training loss: 0.687121885644065
Epoch: 54 | Iteration number: [2260/4518] 50% | Training loss: 0.687118282175697
Epoch: 54 | Iteration number: [2270/4518] 50% | Training loss: 0.6871146768462816
Epoch: 54 | Iteration number: [2280/4518] 50% | Training loss: 0.6871151419846635
Epoch: 54 | Iteration number: [2290/4518] 50% | Training loss: 0.6871131353503231
Epoch: 54 | Iteration number: [2300/4518] 50% | Training loss: 0.687109067051307
Epoch: 54 | Iteration number: [2310/4518] 51% | Training loss: 0.6871098234797969
Epoch: 54 | Iteration number: [2320/4518] 51% | Training loss: 0.6871093312471077
Epoch: 54 | Iteration number: [2330/4518] 51% | Training loss: 0.6871101805324719
Epoch: 54 | Iteration number: [2340/4518] 51% | Training loss: 0.687106158845445
Epoch: 54 | Iteration number: [2350/4518] 52% | Training loss: 0.6871099844638338
Epoch: 54 | Iteration number: [2360/4518] 52% | Training loss: 0.6871064468460568
Epoch: 54 | Iteration number: [2370/4518] 52% | Training loss: 0.6871057809405186
Epoch: 54 | Iteration number: [2380/4518] 52% | Training loss: 0.6871051877737046
Epoch: 54 | Iteration number: [2390/4518] 52% | Training loss: 0.6870976281964131
Epoch: 54 | Iteration number: [2400/4518] 53% | Training loss: 0.6870881549765666
Epoch: 54 | Iteration number: [2410/4518] 53% | Training loss: 0.6870872282635622
Epoch: 54 | Iteration number: [2420/4518] 53% | Training loss: 0.6870845523993832
Epoch: 54 | Iteration number: [2430/4518] 53% | Training loss: 0.6870827419522368
Epoch: 54 | Iteration number: [2440/4518] 54% | Training loss: 0.6870785400271415
Epoch: 54 | Iteration number: [2450/4518] 54% | Training loss: 0.6870787623707129
Epoch: 54 | Iteration number: [2460/4518] 54% | Training loss: 0.6870775806710003
Epoch: 54 | Iteration number: [2470/4518] 54% | Training loss: 0.6870747717044614
Epoch: 54 | Iteration number: [2480/4518] 54% | Training loss: 0.6870757023172994
Epoch: 54 | Iteration number: [2490/4518] 55% | Training loss: 0.6870794231154354
Epoch: 54 | Iteration number: [2500/4518] 55% | Training loss: 0.6870773201227188
Epoch: 54 | Iteration number: [2510/4518] 55% | Training loss: 0.6870734950935699
Epoch: 54 | Iteration number: [2520/4518] 55% | Training loss: 0.6870693432196738
Epoch: 54 | Iteration number: [2530/4518] 55% | Training loss: 0.687066389402382
Epoch: 54 | Iteration number: [2540/4518] 56% | Training loss: 0.6870612434045537
Epoch: 54 | Iteration number: [2550/4518] 56% | Training loss: 0.6870566480300005
Epoch: 54 | Iteration number: [2560/4518] 56% | Training loss: 0.6870531196473166
Epoch: 54 | Iteration number: [2570/4518] 56% | Training loss: 0.6870519979686589
Epoch: 54 | Iteration number: [2580/4518] 57% | Training loss: 0.6870496546113214
Epoch: 54 | Iteration number: [2590/4518] 57% | Training loss: 0.6870473013651417
Epoch: 54 | Iteration number: [2600/4518] 57% | Training loss: 0.687047081383375
Epoch: 54 | Iteration number: [2610/4518] 57% | Training loss: 0.6870454326214919
Epoch: 54 | Iteration number: [2620/4518] 57% | Training loss: 0.6870411189685341
Epoch: 54 | Iteration number: [2630/4518] 58% | Training loss: 0.6870416676816832
Epoch: 54 | Iteration number: [2640/4518] 58% | Training loss: 0.6870333055880937
Epoch: 54 | Iteration number: [2650/4518] 58% | Training loss: 0.6870379934445867
Epoch: 54 | Iteration number: [2660/4518] 58% | Training loss: 0.6870375943811317
Epoch: 54 | Iteration number: [2670/4518] 59% | Training loss: 0.6870303906751483
Epoch: 54 | Iteration number: [2680/4518] 59% | Training loss: 0.6870293564538458
Epoch: 54 | Iteration number: [2690/4518] 59% | Training loss: 0.6870260413916137
Epoch: 54 | Iteration number: [2700/4518] 59% | Training loss: 0.6870219866876249
Epoch: 54 | Iteration number: [2710/4518] 59% | Training loss: 0.6870219540991906
Epoch: 54 | Iteration number: [2720/4518] 60% | Training loss: 0.6870209981194314
Epoch: 54 | Iteration number: [2730/4518] 60% | Training loss: 0.6870205180548923
Epoch: 54 | Iteration number: [2740/4518] 60% | Training loss: 0.6870182411296524
Epoch: 54 | Iteration number: [2750/4518] 60% | Training loss: 0.6870191738172011
Epoch: 54 | Iteration number: [2760/4518] 61% | Training loss: 0.6870150363099747
Epoch: 54 | Iteration number: [2770/4518] 61% | Training loss: 0.6870145979340756
Epoch: 54 | Iteration number: [2780/4518] 61% | Training loss: 0.6870151897342942
Epoch: 54 | Iteration number: [2790/4518] 61% | Training loss: 0.6870133465122579
Epoch: 54 | Iteration number: [2800/4518] 61% | Training loss: 0.6870127986158644
Epoch: 54 | Iteration number: [2810/4518] 62% | Training loss: 0.6870129278121894
Epoch: 54 | Iteration number: [2820/4518] 62% | Training loss: 0.6870111021166998
Epoch: 54 | Iteration number: [2830/4518] 62% | Training loss: 0.6870084171160371
Epoch: 54 | Iteration number: [2840/4518] 62% | Training loss: 0.6870095445866317
Epoch: 54 | Iteration number: [2850/4518] 63% | Training loss: 0.6870141695465958
Epoch: 54 | Iteration number: [2860/4518] 63% | Training loss: 0.687014289335771
Epoch: 54 | Iteration number: [2870/4518] 63% | Training loss: 0.6870153508950609
Epoch: 54 | Iteration number: [2880/4518] 63% | Training loss: 0.6870166198247009
Epoch: 54 | Iteration number: [2890/4518] 63% | Training loss: 0.68701652674114
Epoch: 54 | Iteration number: [2900/4518] 64% | Training loss: 0.6870153568530905
Epoch: 54 | Iteration number: [2910/4518] 64% | Training loss: 0.6870140652681135
Epoch: 54 | Iteration number: [2920/4518] 64% | Training loss: 0.6870096129709727
Epoch: 54 | Iteration number: [2930/4518] 64% | Training loss: 0.6870079757207083
Epoch: 54 | Iteration number: [2940/4518] 65% | Training loss: 0.6870017348300843
Epoch: 54 | Iteration number: [2950/4518] 65% | Training loss: 0.6870020984795134
Epoch: 54 | Iteration number: [2960/4518] 65% | Training loss: 0.6869989224583716
Epoch: 54 | Iteration number: [2970/4518] 65% | Training loss: 0.6869952770997378
Epoch: 54 | Iteration number: [2980/4518] 65% | Training loss: 0.6869928095164715
Epoch: 54 | Iteration number: [2990/4518] 66% | Training loss: 0.6869928873900985
Epoch: 54 | Iteration number: [3000/4518] 66% | Training loss: 0.6869964097936948
Epoch: 54 | Iteration number: [3010/4518] 66% | Training loss: 0.6869973649020211
Epoch: 54 | Iteration number: [3020/4518] 66% | Training loss: 0.6869958141781637
Epoch: 54 | Iteration number: [3030/4518] 67% | Training loss: 0.6869960930481209
Epoch: 54 | Iteration number: [3040/4518] 67% | Training loss: 0.6869944471669824
Epoch: 54 | Iteration number: [3050/4518] 67% | Training loss: 0.6869940405595498
Epoch: 54 | Iteration number: [3060/4518] 67% | Training loss: 0.6869957608140372
Epoch: 54 | Iteration number: [3070/4518] 67% | Training loss: 0.6869975495998557
Epoch: 54 | Iteration number: [3080/4518] 68% | Training loss: 0.6869990478862416
Epoch: 54 | Iteration number: [3090/4518] 68% | Training loss: 0.6870013234106083
Epoch: 54 | Iteration number: [3100/4518] 68% | Training loss: 0.6869999934780983
Epoch: 54 | Iteration number: [3110/4518] 68% | Training loss: 0.6869997564811032
Epoch: 54 | Iteration number: [3120/4518] 69% | Training loss: 0.6870018695409481
Epoch: 54 | Iteration number: [3130/4518] 69% | Training loss: 0.6870024269571701
Epoch: 54 | Iteration number: [3140/4518] 69% | Training loss: 0.6870021521285841
Epoch: 54 | Iteration number: [3150/4518] 69% | Training loss: 0.687003002318125
Epoch: 54 | Iteration number: [3160/4518] 69% | Training loss: 0.6870029946105389
Epoch: 54 | Iteration number: [3170/4518] 70% | Training loss: 0.6870006955384456
Epoch: 54 | Iteration number: [3180/4518] 70% | Training loss: 0.6870036308308067
Epoch: 54 | Iteration number: [3190/4518] 70% | Training loss: 0.6870035228310708
Epoch: 54 | Iteration number: [3200/4518] 70% | Training loss: 0.6870013876445591
Epoch: 54 | Iteration number: [3210/4518] 71% | Training loss: 0.6870015484521693
Epoch: 54 | Iteration number: [3220/4518] 71% | Training loss: 0.686998608375188
Epoch: 54 | Iteration number: [3230/4518] 71% | Training loss: 0.6869970875812389
Epoch: 54 | Iteration number: [3240/4518] 71% | Training loss: 0.6869943408686437
Epoch: 54 | Iteration number: [3250/4518] 71% | Training loss: 0.6869938483788417
Epoch: 54 | Iteration number: [3260/4518] 72% | Training loss: 0.6869941462402694
Epoch: 54 | Iteration number: [3270/4518] 72% | Training loss: 0.6869950564811719
Epoch: 54 | Iteration number: [3280/4518] 72% | Training loss: 0.6869911698669922
Epoch: 54 | Iteration number: [3290/4518] 72% | Training loss: 0.6869905701705388
Epoch: 54 | Iteration number: [3300/4518] 73% | Training loss: 0.6869938334371104
Epoch: 54 | Iteration number: [3310/4518] 73% | Training loss: 0.6869910442396954
Epoch: 54 | Iteration number: [3320/4518] 73% | Training loss: 0.6869911839085889
Epoch: 54 | Iteration number: [3330/4518] 73% | Training loss: 0.6869926005154401
Epoch: 54 | Iteration number: [3340/4518] 73% | Training loss: 0.6869935306424866
Epoch: 54 | Iteration number: [3350/4518] 74% | Training loss: 0.6869944562840817
Epoch: 54 | Iteration number: [3360/4518] 74% | Training loss: 0.6869943561298507
Epoch: 54 | Iteration number: [3370/4518] 74% | Training loss: 0.6869928245551509
Epoch: 54 | Iteration number: [3380/4518] 74% | Training loss: 0.6869953048828791
Epoch: 54 | Iteration number: [3390/4518] 75% | Training loss: 0.6870010448240601
Epoch: 54 | Iteration number: [3400/4518] 75% | Training loss: 0.687003012667684
Epoch: 54 | Iteration number: [3410/4518] 75% | Training loss: 0.6870026563094858
Epoch: 54 | Iteration number: [3420/4518] 75% | Training loss: 0.6870032227353046
Epoch: 54 | Iteration number: [3430/4518] 75% | Training loss: 0.6870032919565373
Epoch: 54 | Iteration number: [3440/4518] 76% | Training loss: 0.686999934651824
Epoch: 54 | Iteration number: [3450/4518] 76% | Training loss: 0.6869974384964376
Epoch: 54 | Iteration number: [3460/4518] 76% | Training loss: 0.6869968161073035
Epoch: 54 | Iteration number: [3470/4518] 76% | Training loss: 0.6869974510298682
Epoch: 54 | Iteration number: [3480/4518] 77% | Training loss: 0.6869975147233612
Epoch: 54 | Iteration number: [3490/4518] 77% | Training loss: 0.6869963973675212
Epoch: 54 | Iteration number: [3500/4518] 77% | Training loss: 0.6869951571907316
Epoch: 54 | Iteration number: [3510/4518] 77% | Training loss: 0.6869990448326806
Epoch: 54 | Iteration number: [3520/4518] 77% | Training loss: 0.6869988508861173
Epoch: 54 | Iteration number: [3530/4518] 78% | Training loss: 0.6869970723015728
Epoch: 54 | Iteration number: [3540/4518] 78% | Training loss: 0.6869986840560611
Epoch: 54 | Iteration number: [3550/4518] 78% | Training loss: 0.6869972480015016
Epoch: 54 | Iteration number: [3560/4518] 78% | Training loss: 0.6869984442598365
Epoch: 54 | Iteration number: [3570/4518] 79% | Training loss: 0.6869992353836027
Epoch: 54 | Iteration number: [3580/4518] 79% | Training loss: 0.6869963611637414
Epoch: 54 | Iteration number: [3590/4518] 79% | Training loss: 0.6869967542484943
Epoch: 54 | Iteration number: [3600/4518] 79% | Training loss: 0.6869952817426788
Epoch: 54 | Iteration number: [3610/4518] 79% | Training loss: 0.6869950935616057
Epoch: 54 | Iteration number: [3620/4518] 80% | Training loss: 0.68699112932985
Epoch: 54 | Iteration number: [3630/4518] 80% | Training loss: 0.6869845684730645
Epoch: 54 | Iteration number: [3640/4518] 80% | Training loss: 0.6869822185445618
Epoch: 54 | Iteration number: [3650/4518] 80% | Training loss: 0.6869834437925522
Epoch: 54 | Iteration number: [3660/4518] 81% | Training loss: 0.6869856622049717
Epoch: 54 | Iteration number: [3670/4518] 81% | Training loss: 0.6869856887195026
Epoch: 54 | Iteration number: [3680/4518] 81% | Training loss: 0.6869832819084758
Epoch: 54 | Iteration number: [3690/4518] 81% | Training loss: 0.6869841782219688
Epoch: 54 | Iteration number: [3700/4518] 81% | Training loss: 0.6869863698450295
Epoch: 54 | Iteration number: [3710/4518] 82% | Training loss: 0.6869881969577861
Epoch: 54 | Iteration number: [3720/4518] 82% | Training loss: 0.6869882946052859
Epoch: 54 | Iteration number: [3730/4518] 82% | Training loss: 0.6869899321816881
Epoch: 54 | Iteration number: [3740/4518] 82% | Training loss: 0.6869875069289284
Epoch: 54 | Iteration number: [3750/4518] 83% | Training loss: 0.6869878021717072
Epoch: 54 | Iteration number: [3760/4518] 83% | Training loss: 0.6869890110765365
Epoch: 54 | Iteration number: [3770/4518] 83% | Training loss: 0.686986879913497
Epoch: 54 | Iteration number: [3780/4518] 83% | Training loss: 0.6869900676623854
Epoch: 54 | Iteration number: [3790/4518] 83% | Training loss: 0.6869875494282605
Epoch: 54 | Iteration number: [3800/4518] 84% | Training loss: 0.6869860472804622
Epoch: 54 | Iteration number: [3810/4518] 84% | Training loss: 0.6869822976157421
Epoch: 54 | Iteration number: [3820/4518] 84% | Training loss: 0.6869813310850353
Epoch: 54 | Iteration number: [3830/4518] 84% | Training loss: 0.6869807880790053
Epoch: 54 | Iteration number: [3840/4518] 84% | Training loss: 0.686980719693626
Epoch: 54 | Iteration number: [3850/4518] 85% | Training loss: 0.6869826345165054
Epoch: 54 | Iteration number: [3860/4518] 85% | Training loss: 0.6869807939146467
Epoch: 54 | Iteration number: [3870/4518] 85% | Training loss: 0.6869792124405696
Epoch: 54 | Iteration number: [3880/4518] 85% | Training loss: 0.6869775586828744
Epoch: 54 | Iteration number: [3890/4518] 86% | Training loss: 0.6869748669449038
Epoch: 54 | Iteration number: [3900/4518] 86% | Training loss: 0.6869755180065449
Epoch: 54 | Iteration number: [3910/4518] 86% | Training loss: 0.6869724650822028
Epoch: 54 | Iteration number: [3920/4518] 86% | Training loss: 0.6869701422446844
Epoch: 54 | Iteration number: [3930/4518] 86% | Training loss: 0.6869679776615162
Epoch: 54 | Iteration number: [3940/4518] 87% | Training loss: 0.6869657934619691
Epoch: 54 | Iteration number: [3950/4518] 87% | Training loss: 0.6869669407077983
Epoch: 54 | Iteration number: [3960/4518] 87% | Training loss: 0.6869635578658846
Epoch: 54 | Iteration number: [3970/4518] 87% | Training loss: 0.6869637968257933
Epoch: 54 | Iteration number: [3980/4518] 88% | Training loss: 0.6869675397723164
Epoch: 54 | Iteration number: [3990/4518] 88% | Training loss: 0.6869648121652149
Epoch: 54 | Iteration number: [4000/4518] 88% | Training loss: 0.6869663165062666
Epoch: 54 | Iteration number: [4010/4518] 88% | Training loss: 0.6869667200822188
Epoch: 54 | Iteration number: [4020/4518] 88% | Training loss: 0.6869665608922048
Epoch: 54 | Iteration number: [4030/4518] 89% | Training loss: 0.6869682830853143
Epoch: 54 | Iteration number: [4040/4518] 89% | Training loss: 0.6869666120498488
Epoch: 54 | Iteration number: [4050/4518] 89% | Training loss: 0.6869641193195626
Epoch: 54 | Iteration number: [4060/4518] 89% | Training loss: 0.6869610631700807
Epoch: 54 | Iteration number: [4070/4518] 90% | Training loss: 0.6869621964285942
Epoch: 54 | Iteration number: [4080/4518] 90% | Training loss: 0.6869641998819277
Epoch: 54 | Iteration number: [4090/4518] 90% | Training loss: 0.6869657048094826
Epoch: 54 | Iteration number: [4100/4518] 90% | Training loss: 0.6869679818647664
Epoch: 54 | Iteration number: [4110/4518] 90% | Training loss: 0.6869675606126623
Epoch: 54 | Iteration number: [4120/4518] 91% | Training loss: 0.6869671082033695
Epoch: 54 | Iteration number: [4130/4518] 91% | Training loss: 0.6869672980204622
Epoch: 54 | Iteration number: [4140/4518] 91% | Training loss: 0.6869651607701168
Epoch: 54 | Iteration number: [4150/4518] 91% | Training loss: 0.6869686169078552
Epoch: 54 | Iteration number: [4160/4518] 92% | Training loss: 0.6869703964975018
Epoch: 54 | Iteration number: [4170/4518] 92% | Training loss: 0.6869683265114288
Epoch: 54 | Iteration number: [4180/4518] 92% | Training loss: 0.6869630237658058
Epoch: 54 | Iteration number: [4190/4518] 92% | Training loss: 0.6869634458586253
Epoch: 54 | Iteration number: [4200/4518] 92% | Training loss: 0.6869583718691553
Epoch: 54 | Iteration number: [4210/4518] 93% | Training loss: 0.686959538465441
Epoch: 54 | Iteration number: [4220/4518] 93% | Training loss: 0.6869609184315985
Epoch: 54 | Iteration number: [4230/4518] 93% | Training loss: 0.6869583111282781
Epoch: 54 | Iteration number: [4240/4518] 93% | Training loss: 0.6869584722198405
Epoch: 54 | Iteration number: [4250/4518] 94% | Training loss: 0.6869550792329452
Epoch: 54 | Iteration number: [4260/4518] 94% | Training loss: 0.6869558439987926
Epoch: 54 | Iteration number: [4270/4518] 94% | Training loss: 0.6869574161407819
Epoch: 54 | Iteration number: [4280/4518] 94% | Training loss: 0.6869580837053674
Epoch: 54 | Iteration number: [4290/4518] 94% | Training loss: 0.6869558925534184
Epoch: 54 | Iteration number: [4300/4518] 95% | Training loss: 0.686955445963283
Epoch: 54 | Iteration number: [4310/4518] 95% | Training loss: 0.6869515605426443
Epoch: 54 | Iteration number: [4320/4518] 95% | Training loss: 0.6869496277085057
Epoch: 54 | Iteration number: [4330/4518] 95% | Training loss: 0.6869488052077437
Epoch: 54 | Iteration number: [4340/4518] 96% | Training loss: 0.6869500501501945
Epoch: 54 | Iteration number: [4350/4518] 96% | Training loss: 0.686946871266968
Epoch: 54 | Iteration number: [4360/4518] 96% | Training loss: 0.6869454143107484
Epoch: 54 | Iteration number: [4370/4518] 96% | Training loss: 0.6869422256946563
Epoch: 54 | Iteration number: [4380/4518] 96% | Training loss: 0.6869437470828017
Epoch: 54 | Iteration number: [4390/4518] 97% | Training loss: 0.6869438127939141
Epoch: 54 | Iteration number: [4400/4518] 97% | Training loss: 0.6869446028633551
Epoch: 54 | Iteration number: [4410/4518] 97% | Training loss: 0.6869438624706398
Epoch: 54 | Iteration number: [4420/4518] 97% | Training loss: 0.6869439011380684
Epoch: 54 | Iteration number: [4430/4518] 98% | Training loss: 0.68694621839857
Epoch: 54 | Iteration number: [4440/4518] 98% | Training loss: 0.6869491985655046
Epoch: 54 | Iteration number: [4450/4518] 98% | Training loss: 0.6869522717293729
Epoch: 54 | Iteration number: [4460/4518] 98% | Training loss: 0.686953342161371
Epoch: 54 | Iteration number: [4470/4518] 98% | Training loss: 0.6869550711889928
Epoch: 54 | Iteration number: [4480/4518] 99% | Training loss: 0.6869558001203196
Epoch: 54 | Iteration number: [4490/4518] 99% | Training loss: 0.6869559217136527
Epoch: 54 | Iteration number: [4500/4518] 99% | Training loss: 0.6869581806792153
Epoch: 54 | Iteration number: [4510/4518] 99% | Training loss: 0.6869589730403376

 End of epoch: 54 | Train Loss: 0.6868090055167226 | Training Time: 642 

 End of epoch: 54 | Eval Loss: 0.690094704530677 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/4518] 0% | Training loss: 0.7555296182632446
Epoch: 55 | Iteration number: [20/4518] 0% | Training loss: 0.7209156662225723
Epoch: 55 | Iteration number: [30/4518] 0% | Training loss: 0.7100126624107361
Epoch: 55 | Iteration number: [40/4518] 0% | Training loss: 0.7045353665947914
Epoch: 55 | Iteration number: [50/4518] 1% | Training loss: 0.7008496952056885
Epoch: 55 | Iteration number: [60/4518] 1% | Training loss: 0.6982466399669647
Epoch: 55 | Iteration number: [70/4518] 1% | Training loss: 0.6966354216848101
Epoch: 55 | Iteration number: [80/4518] 1% | Training loss: 0.6954261265695095
Epoch: 55 | Iteration number: [90/4518] 1% | Training loss: 0.6945978323618571
Epoch: 55 | Iteration number: [100/4518] 2% | Training loss: 0.693791783452034
Epoch: 55 | Iteration number: [110/4518] 2% | Training loss: 0.6931889105926861
Epoch: 55 | Iteration number: [120/4518] 2% | Training loss: 0.6925894285241763
Epoch: 55 | Iteration number: [130/4518] 2% | Training loss: 0.6921536133839534
Epoch: 55 | Iteration number: [140/4518] 3% | Training loss: 0.6917579501867295
Epoch: 55 | Iteration number: [150/4518] 3% | Training loss: 0.6914057286580404
Epoch: 55 | Iteration number: [160/4518] 3% | Training loss: 0.691126586124301
Epoch: 55 | Iteration number: [170/4518] 3% | Training loss: 0.6908508837223053
Epoch: 55 | Iteration number: [180/4518] 3% | Training loss: 0.6906949844625261
Epoch: 55 | Iteration number: [190/4518] 4% | Training loss: 0.6904807661709033
Epoch: 55 | Iteration number: [200/4518] 4% | Training loss: 0.6901842564344406
Epoch: 55 | Iteration number: [210/4518] 4% | Training loss: 0.6900533832254864
Epoch: 55 | Iteration number: [220/4518] 4% | Training loss: 0.6898777999661185
Epoch: 55 | Iteration number: [230/4518] 5% | Training loss: 0.6897624868413677
Epoch: 55 | Iteration number: [240/4518] 5% | Training loss: 0.6895885561903318
Epoch: 55 | Iteration number: [250/4518] 5% | Training loss: 0.6894425377845764
Epoch: 55 | Iteration number: [260/4518] 5% | Training loss: 0.6893483331570258
Epoch: 55 | Iteration number: [270/4518] 5% | Training loss: 0.6892794688542684
Epoch: 55 | Iteration number: [280/4518] 6% | Training loss: 0.6891802379063198
Epoch: 55 | Iteration number: [290/4518] 6% | Training loss: 0.6890741422258574
Epoch: 55 | Iteration number: [300/4518] 6% | Training loss: 0.6890134759744009
Epoch: 55 | Iteration number: [310/4518] 6% | Training loss: 0.6889128792670465
Epoch: 55 | Iteration number: [320/4518] 7% | Training loss: 0.6888214586302638
Epoch: 55 | Iteration number: [330/4518] 7% | Training loss: 0.6887329636198102
Epoch: 55 | Iteration number: [340/4518] 7% | Training loss: 0.6887260931379655
Epoch: 55 | Iteration number: [350/4518] 7% | Training loss: 0.6887004358427865
Epoch: 55 | Iteration number: [360/4518] 7% | Training loss: 0.6886115599009726
Epoch: 55 | Iteration number: [370/4518] 8% | Training loss: 0.6886120578727206
Epoch: 55 | Iteration number: [380/4518] 8% | Training loss: 0.6885894631084643
Epoch: 55 | Iteration number: [390/4518] 8% | Training loss: 0.6885521767995296
Epoch: 55 | Iteration number: [400/4518] 8% | Training loss: 0.6885384419560432
Epoch: 55 | Iteration number: [410/4518] 9% | Training loss: 0.688523506245962
Epoch: 55 | Iteration number: [420/4518] 9% | Training loss: 0.6884716400078364
Epoch: 55 | Iteration number: [430/4518] 9% | Training loss: 0.6884553755438605
Epoch: 55 | Iteration number: [440/4518] 9% | Training loss: 0.6884281387383288
Epoch: 55 | Iteration number: [450/4518] 9% | Training loss: 0.688388792011473
Epoch: 55 | Iteration number: [460/4518] 10% | Training loss: 0.6883406988952471
Epoch: 55 | Iteration number: [470/4518] 10% | Training loss: 0.6883035709249212
Epoch: 55 | Iteration number: [480/4518] 10% | Training loss: 0.6882884456465642
Epoch: 55 | Iteration number: [490/4518] 10% | Training loss: 0.6882728247009978
Epoch: 55 | Iteration number: [500/4518] 11% | Training loss: 0.6882333211898803
Epoch: 55 | Iteration number: [510/4518] 11% | Training loss: 0.688208048250161
Epoch: 55 | Iteration number: [520/4518] 11% | Training loss: 0.6881650631244366
Epoch: 55 | Iteration number: [530/4518] 11% | Training loss: 0.6881229417504005
Epoch: 55 | Iteration number: [540/4518] 11% | Training loss: 0.6881128037417377
Epoch: 55 | Iteration number: [550/4518] 12% | Training loss: 0.6880848576805808
Epoch: 55 | Iteration number: [560/4518] 12% | Training loss: 0.6880605973303318
Epoch: 55 | Iteration number: [570/4518] 12% | Training loss: 0.6880407723418454
Epoch: 55 | Iteration number: [580/4518] 12% | Training loss: 0.6880230209950743
Epoch: 55 | Iteration number: [590/4518] 13% | Training loss: 0.6879871778568979
Epoch: 55 | Iteration number: [600/4518] 13% | Training loss: 0.6879773032665253
Epoch: 55 | Iteration number: [610/4518] 13% | Training loss: 0.6879754956628455
Epoch: 55 | Iteration number: [620/4518] 13% | Training loss: 0.6879581960939591
Epoch: 55 | Iteration number: [630/4518] 13% | Training loss: 0.6879402259985606
Epoch: 55 | Iteration number: [640/4518] 14% | Training loss: 0.6879068490117788
Epoch: 55 | Iteration number: [650/4518] 14% | Training loss: 0.687883123434507
Epoch: 55 | Iteration number: [660/4518] 14% | Training loss: 0.6878844867149989
Epoch: 55 | Iteration number: [670/4518] 14% | Training loss: 0.6878645386268843
Epoch: 55 | Iteration number: [680/4518] 15% | Training loss: 0.6878627494854086
Epoch: 55 | Iteration number: [690/4518] 15% | Training loss: 0.687865368179653
Epoch: 55 | Iteration number: [700/4518] 15% | Training loss: 0.6878517672845296
Epoch: 55 | Iteration number: [710/4518] 15% | Training loss: 0.6878361599546083
Epoch: 55 | Iteration number: [720/4518] 15% | Training loss: 0.6878024045791891
Epoch: 55 | Iteration number: [730/4518] 16% | Training loss: 0.6877763145590482
Epoch: 55 | Iteration number: [740/4518] 16% | Training loss: 0.687773217703845
Epoch: 55 | Iteration number: [750/4518] 16% | Training loss: 0.6877691884040833
Epoch: 55 | Iteration number: [760/4518] 16% | Training loss: 0.6877402122867735
Epoch: 55 | Iteration number: [770/4518] 17% | Training loss: 0.6877580651989231
Epoch: 55 | Iteration number: [780/4518] 17% | Training loss: 0.6877648420822926
Epoch: 55 | Iteration number: [790/4518] 17% | Training loss: 0.6877561781225325
Epoch: 55 | Iteration number: [800/4518] 17% | Training loss: 0.6877418005466461
Epoch: 55 | Iteration number: [810/4518] 17% | Training loss: 0.6877358192279015
Epoch: 55 | Iteration number: [820/4518] 18% | Training loss: 0.6877314247736117
Epoch: 55 | Iteration number: [830/4518] 18% | Training loss: 0.6877036654087434
Epoch: 55 | Iteration number: [840/4518] 18% | Training loss: 0.6876918965861911
Epoch: 55 | Iteration number: [850/4518] 18% | Training loss: 0.6876748856376199
Epoch: 55 | Iteration number: [860/4518] 19% | Training loss: 0.6876678208972132
Epoch: 55 | Iteration number: [870/4518] 19% | Training loss: 0.6876585650032965
Epoch: 55 | Iteration number: [880/4518] 19% | Training loss: 0.6876471776176583
Epoch: 55 | Iteration number: [890/4518] 19% | Training loss: 0.6876463043555785
Epoch: 55 | Iteration number: [900/4518] 19% | Training loss: 0.6876455444097519
Epoch: 55 | Iteration number: [910/4518] 20% | Training loss: 0.687630936732659
Epoch: 55 | Iteration number: [920/4518] 20% | Training loss: 0.687604665302712
Epoch: 55 | Iteration number: [930/4518] 20% | Training loss: 0.6875801069762117
Epoch: 55 | Iteration number: [940/4518] 20% | Training loss: 0.6875615807923865
Epoch: 55 | Iteration number: [950/4518] 21% | Training loss: 0.6875623539247011
Epoch: 55 | Iteration number: [960/4518] 21% | Training loss: 0.6875485213473439
Epoch: 55 | Iteration number: [970/4518] 21% | Training loss: 0.6875427172356046
Epoch: 55 | Iteration number: [980/4518] 21% | Training loss: 0.6875196187471857
Epoch: 55 | Iteration number: [990/4518] 21% | Training loss: 0.6875150982779686
Epoch: 55 | Iteration number: [1000/4518] 22% | Training loss: 0.6874907157421112
Epoch: 55 | Iteration number: [1010/4518] 22% | Training loss: 0.6874778993649058
Epoch: 55 | Iteration number: [1020/4518] 22% | Training loss: 0.6874749980720819
Epoch: 55 | Iteration number: [1030/4518] 22% | Training loss: 0.6874714329404739
Epoch: 55 | Iteration number: [1040/4518] 23% | Training loss: 0.6874761215196206
Epoch: 55 | Iteration number: [1050/4518] 23% | Training loss: 0.6874707350844429
Epoch: 55 | Iteration number: [1060/4518] 23% | Training loss: 0.6874599863335772
Epoch: 55 | Iteration number: [1070/4518] 23% | Training loss: 0.6874510094384166
Epoch: 55 | Iteration number: [1080/4518] 23% | Training loss: 0.6874417558312416
Epoch: 55 | Iteration number: [1090/4518] 24% | Training loss: 0.6874433274115991
Epoch: 55 | Iteration number: [1100/4518] 24% | Training loss: 0.6874353979934346
Epoch: 55 | Iteration number: [1110/4518] 24% | Training loss: 0.6874248835417601
Epoch: 55 | Iteration number: [1120/4518] 24% | Training loss: 0.6874160345643758
Epoch: 55 | Iteration number: [1130/4518] 25% | Training loss: 0.6874128641280453
Epoch: 55 | Iteration number: [1140/4518] 25% | Training loss: 0.6873898874772223
Epoch: 55 | Iteration number: [1150/4518] 25% | Training loss: 0.6873838282668072
Epoch: 55 | Iteration number: [1160/4518] 25% | Training loss: 0.6873775785853122
Epoch: 55 | Iteration number: [1170/4518] 25% | Training loss: 0.6873620088793274
Epoch: 55 | Iteration number: [1180/4518] 26% | Training loss: 0.6873643316959931
Epoch: 55 | Iteration number: [1190/4518] 26% | Training loss: 0.6873633568026438
Epoch: 55 | Iteration number: [1200/4518] 26% | Training loss: 0.6873662506540617
Epoch: 55 | Iteration number: [1210/4518] 26% | Training loss: 0.6873634930484551
Epoch: 55 | Iteration number: [1220/4518] 27% | Training loss: 0.6873637240929682
Epoch: 55 | Iteration number: [1230/4518] 27% | Training loss: 0.6873653353714362
Epoch: 55 | Iteration number: [1240/4518] 27% | Training loss: 0.6873677119132011
Epoch: 55 | Iteration number: [1250/4518] 27% | Training loss: 0.6873649914264679
Epoch: 55 | Iteration number: [1260/4518] 27% | Training loss: 0.6873512644143331
Epoch: 55 | Iteration number: [1270/4518] 28% | Training loss: 0.6873429618013187
Epoch: 55 | Iteration number: [1280/4518] 28% | Training loss: 0.6873311828356237
Epoch: 55 | Iteration number: [1290/4518] 28% | Training loss: 0.6873357259487921
Epoch: 55 | Iteration number: [1300/4518] 28% | Training loss: 0.6873333773246179
Epoch: 55 | Iteration number: [1310/4518] 28% | Training loss: 0.6873213998688996
Epoch: 55 | Iteration number: [1320/4518] 29% | Training loss: 0.6873177506255381
Epoch: 55 | Iteration number: [1330/4518] 29% | Training loss: 0.6873171826502434
Epoch: 55 | Iteration number: [1340/4518] 29% | Training loss: 0.6873009079427862
Epoch: 55 | Iteration number: [1350/4518] 29% | Training loss: 0.6872993736796909
Epoch: 55 | Iteration number: [1360/4518] 30% | Training loss: 0.687294937582577
Epoch: 55 | Iteration number: [1370/4518] 30% | Training loss: 0.687291427119805
Epoch: 55 | Iteration number: [1380/4518] 30% | Training loss: 0.6872814732185308
Epoch: 55 | Iteration number: [1390/4518] 30% | Training loss: 0.6872823546258666
Epoch: 55 | Iteration number: [1400/4518] 30% | Training loss: 0.6872787601607186
Epoch: 55 | Iteration number: [1410/4518] 31% | Training loss: 0.6872664497676471
Epoch: 55 | Iteration number: [1420/4518] 31% | Training loss: 0.6872701958031722
Epoch: 55 | Iteration number: [1430/4518] 31% | Training loss: 0.6872708857059479
Epoch: 55 | Iteration number: [1440/4518] 31% | Training loss: 0.687269559999307
Epoch: 55 | Iteration number: [1450/4518] 32% | Training loss: 0.6872669772855167
Epoch: 55 | Iteration number: [1460/4518] 32% | Training loss: 0.6872593549832906
Epoch: 55 | Iteration number: [1470/4518] 32% | Training loss: 0.6872588497846305
Epoch: 55 | Iteration number: [1480/4518] 32% | Training loss: 0.6872606990305153
Epoch: 55 | Iteration number: [1490/4518] 32% | Training loss: 0.6872533126165403
Epoch: 55 | Iteration number: [1500/4518] 33% | Training loss: 0.6872510066429774
Epoch: 55 | Iteration number: [1510/4518] 33% | Training loss: 0.6872470053615949
Epoch: 55 | Iteration number: [1520/4518] 33% | Training loss: 0.6872443274839928
Epoch: 55 | Iteration number: [1530/4518] 33% | Training loss: 0.6872456206994898
Epoch: 55 | Iteration number: [1540/4518] 34% | Training loss: 0.6872460168290447
Epoch: 55 | Iteration number: [1550/4518] 34% | Training loss: 0.6872378254321314
Epoch: 55 | Iteration number: [1560/4518] 34% | Training loss: 0.6872406106346692
Epoch: 55 | Iteration number: [1570/4518] 34% | Training loss: 0.6872417601430492
Epoch: 55 | Iteration number: [1580/4518] 34% | Training loss: 0.6872430859864512
Epoch: 55 | Iteration number: [1590/4518] 35% | Training loss: 0.6872365779471847
Epoch: 55 | Iteration number: [1600/4518] 35% | Training loss: 0.6872288185358048
Epoch: 55 | Iteration number: [1610/4518] 35% | Training loss: 0.6872233895411403
Epoch: 55 | Iteration number: [1620/4518] 35% | Training loss: 0.6872134836735548
Epoch: 55 | Iteration number: [1630/4518] 36% | Training loss: 0.687210258823231
Epoch: 55 | Iteration number: [1640/4518] 36% | Training loss: 0.6872027844190598
Epoch: 55 | Iteration number: [1650/4518] 36% | Training loss: 0.6871995686762261
Epoch: 55 | Iteration number: [1660/4518] 36% | Training loss: 0.6871988032955721
Epoch: 55 | Iteration number: [1670/4518] 36% | Training loss: 0.687196052931026
Epoch: 55 | Iteration number: [1680/4518] 37% | Training loss: 0.6871919672404017
Epoch: 55 | Iteration number: [1690/4518] 37% | Training loss: 0.6871906815548621
Epoch: 55 | Iteration number: [1700/4518] 37% | Training loss: 0.687188765616978
Epoch: 55 | Iteration number: [1710/4518] 37% | Training loss: 0.6871915662497805
Epoch: 55 | Iteration number: [1720/4518] 38% | Training loss: 0.6871811131405275
Epoch: 55 | Iteration number: [1730/4518] 38% | Training loss: 0.6871788745326114
Epoch: 55 | Iteration number: [1740/4518] 38% | Training loss: 0.6871753370624849
Epoch: 55 | Iteration number: [1750/4518] 38% | Training loss: 0.6871760615280696
Epoch: 55 | Iteration number: [1760/4518] 38% | Training loss: 0.687175281684507
Epoch: 55 | Iteration number: [1770/4518] 39% | Training loss: 0.6871775363798195
Epoch: 55 | Iteration number: [1780/4518] 39% | Training loss: 0.6871767767024843
Epoch: 55 | Iteration number: [1790/4518] 39% | Training loss: 0.6871779929326233
Epoch: 55 | Iteration number: [1800/4518] 39% | Training loss: 0.6871777521570523
Epoch: 55 | Iteration number: [1810/4518] 40% | Training loss: 0.6871741146672496
Epoch: 55 | Iteration number: [1820/4518] 40% | Training loss: 0.687172826731598
Epoch: 55 | Iteration number: [1830/4518] 40% | Training loss: 0.6871690645895369
Epoch: 55 | Iteration number: [1840/4518] 40% | Training loss: 0.6871682641298874
Epoch: 55 | Iteration number: [1850/4518] 40% | Training loss: 0.6871661719438192
Epoch: 55 | Iteration number: [1860/4518] 41% | Training loss: 0.6871660047320909
Epoch: 55 | Iteration number: [1870/4518] 41% | Training loss: 0.6871688168316601
Epoch: 55 | Iteration number: [1880/4518] 41% | Training loss: 0.6871659115590948
Epoch: 55 | Iteration number: [1890/4518] 41% | Training loss: 0.6871652920410116
Epoch: 55 | Iteration number: [1900/4518] 42% | Training loss: 0.6871665113223226
Epoch: 55 | Iteration number: [1910/4518] 42% | Training loss: 0.6871605482401024
Epoch: 55 | Iteration number: [1920/4518] 42% | Training loss: 0.6871567068931957
Epoch: 55 | Iteration number: [1930/4518] 42% | Training loss: 0.6871572699262688
Epoch: 55 | Iteration number: [1940/4518] 42% | Training loss: 0.6871579533385247
Epoch: 55 | Iteration number: [1950/4518] 43% | Training loss: 0.6871598669504508
Epoch: 55 | Iteration number: [1960/4518] 43% | Training loss: 0.6871624004780029
Epoch: 55 | Iteration number: [1970/4518] 43% | Training loss: 0.6871602140404851
Epoch: 55 | Iteration number: [1980/4518] 43% | Training loss: 0.6871626313888666
Epoch: 55 | Iteration number: [1990/4518] 44% | Training loss: 0.6871637735534553
Epoch: 55 | Iteration number: [2000/4518] 44% | Training loss: 0.6871671638190746
Epoch: 55 | Iteration number: [2010/4518] 44% | Training loss: 0.6871680609918945
Epoch: 55 | Iteration number: [2020/4518] 44% | Training loss: 0.6871638816772121
Epoch: 55 | Iteration number: [2030/4518] 44% | Training loss: 0.6871596881615117
Epoch: 55 | Iteration number: [2040/4518] 45% | Training loss: 0.6871473100255517
Epoch: 55 | Iteration number: [2050/4518] 45% | Training loss: 0.6871443831339115
Epoch: 55 | Iteration number: [2060/4518] 45% | Training loss: 0.6871407519266444
Epoch: 55 | Iteration number: [2070/4518] 45% | Training loss: 0.6871400480972972
Epoch: 55 | Iteration number: [2080/4518] 46% | Training loss: 0.6871356452600315
Epoch: 55 | Iteration number: [2090/4518] 46% | Training loss: 0.6871380345958271
Epoch: 55 | Iteration number: [2100/4518] 46% | Training loss: 0.6871345212629864
Epoch: 55 | Iteration number: [2110/4518] 46% | Training loss: 0.6871322478728272
Epoch: 55 | Iteration number: [2120/4518] 46% | Training loss: 0.68713304645048
Epoch: 55 | Iteration number: [2130/4518] 47% | Training loss: 0.6871324211219108
Epoch: 55 | Iteration number: [2140/4518] 47% | Training loss: 0.687137929273543
Epoch: 55 | Iteration number: [2150/4518] 47% | Training loss: 0.6871335938642191
Epoch: 55 | Iteration number: [2160/4518] 47% | Training loss: 0.6871298847099145
Epoch: 55 | Iteration number: [2170/4518] 48% | Training loss: 0.6871269752627693
Epoch: 55 | Iteration number: [2180/4518] 48% | Training loss: 0.687123553906012
Epoch: 55 | Iteration number: [2190/4518] 48% | Training loss: 0.6871183431856164
Epoch: 55 | Iteration number: [2200/4518] 48% | Training loss: 0.6871262166174975
Epoch: 55 | Iteration number: [2210/4518] 48% | Training loss: 0.6871226882772747
Epoch: 55 | Iteration number: [2220/4518] 49% | Training loss: 0.687122044880111
Epoch: 55 | Iteration number: [2230/4518] 49% | Training loss: 0.687124198942441
Epoch: 55 | Iteration number: [2240/4518] 49% | Training loss: 0.6871193591771382
Epoch: 55 | Iteration number: [2250/4518] 49% | Training loss: 0.6871179467837015
Epoch: 55 | Iteration number: [2260/4518] 50% | Training loss: 0.6871186862213422
Epoch: 55 | Iteration number: [2270/4518] 50% | Training loss: 0.6871181936516111
Epoch: 55 | Iteration number: [2280/4518] 50% | Training loss: 0.687116056393113
Epoch: 55 | Iteration number: [2290/4518] 50% | Training loss: 0.6871140171346706
Epoch: 55 | Iteration number: [2300/4518] 50% | Training loss: 0.6871120232861975
Epoch: 55 | Iteration number: [2310/4518] 51% | Training loss: 0.68711038665338
Epoch: 55 | Iteration number: [2320/4518] 51% | Training loss: 0.6871066204432783
Epoch: 55 | Iteration number: [2330/4518] 51% | Training loss: 0.6871045220051712
Epoch: 55 | Iteration number: [2340/4518] 51% | Training loss: 0.687104459425323
Epoch: 55 | Iteration number: [2350/4518] 52% | Training loss: 0.6870964837581554
Epoch: 55 | Iteration number: [2360/4518] 52% | Training loss: 0.6870962451827728
Epoch: 55 | Iteration number: [2370/4518] 52% | Training loss: 0.6870938390870638
Epoch: 55 | Iteration number: [2380/4518] 52% | Training loss: 0.6870914694892258
Epoch: 55 | Iteration number: [2390/4518] 52% | Training loss: 0.6870890508136989
Epoch: 55 | Iteration number: [2400/4518] 53% | Training loss: 0.6870825981597105
Epoch: 55 | Iteration number: [2410/4518] 53% | Training loss: 0.6870845992535476
Epoch: 55 | Iteration number: [2420/4518] 53% | Training loss: 0.6870833191250967
Epoch: 55 | Iteration number: [2430/4518] 53% | Training loss: 0.6870862135671294
Epoch: 55 | Iteration number: [2440/4518] 54% | Training loss: 0.6870834532819811
Epoch: 55 | Iteration number: [2450/4518] 54% | Training loss: 0.6870788440655689
Epoch: 55 | Iteration number: [2460/4518] 54% | Training loss: 0.6870748559391595
Epoch: 55 | Iteration number: [2470/4518] 54% | Training loss: 0.6870696702708117
Epoch: 55 | Iteration number: [2480/4518] 54% | Training loss: 0.6870675689991443
Epoch: 55 | Iteration number: [2490/4518] 55% | Training loss: 0.6870660985330023
Epoch: 55 | Iteration number: [2500/4518] 55% | Training loss: 0.6870641324281692
Epoch: 55 | Iteration number: [2510/4518] 55% | Training loss: 0.6870575048059107
Epoch: 55 | Iteration number: [2520/4518] 55% | Training loss: 0.6870568478154757
Epoch: 55 | Iteration number: [2530/4518] 55% | Training loss: 0.68705505248115
Epoch: 55 | Iteration number: [2540/4518] 56% | Training loss: 0.6870553337448225
Epoch: 55 | Iteration number: [2550/4518] 56% | Training loss: 0.6870483598054624
Epoch: 55 | Iteration number: [2560/4518] 56% | Training loss: 0.687048186105676
Epoch: 55 | Iteration number: [2570/4518] 56% | Training loss: 0.6870481943342008
Epoch: 55 | Iteration number: [2580/4518] 57% | Training loss: 0.6870474143776782
Epoch: 55 | Iteration number: [2590/4518] 57% | Training loss: 0.6870506161658461
Epoch: 55 | Iteration number: [2600/4518] 57% | Training loss: 0.6870465948948493
Epoch: 55 | Iteration number: [2610/4518] 57% | Training loss: 0.6870439426423947
Epoch: 55 | Iteration number: [2620/4518] 57% | Training loss: 0.6870458989880467
Epoch: 55 | Iteration number: [2630/4518] 58% | Training loss: 0.6870437450055387
Epoch: 55 | Iteration number: [2640/4518] 58% | Training loss: 0.6870395558350014
Epoch: 55 | Iteration number: [2650/4518] 58% | Training loss: 0.6870411482622039
Epoch: 55 | Iteration number: [2660/4518] 58% | Training loss: 0.6870402753801275
Epoch: 55 | Iteration number: [2670/4518] 59% | Training loss: 0.6870371442162588
Epoch: 55 | Iteration number: [2680/4518] 59% | Training loss: 0.6870328242654231
Epoch: 55 | Iteration number: [2690/4518] 59% | Training loss: 0.6870326486883553
Epoch: 55 | Iteration number: [2700/4518] 59% | Training loss: 0.6870367839822062
Epoch: 55 | Iteration number: [2710/4518] 59% | Training loss: 0.6870364105349537
Epoch: 55 | Iteration number: [2720/4518] 60% | Training loss: 0.6870323486626149
Epoch: 55 | Iteration number: [2730/4518] 60% | Training loss: 0.6870324310365614
Epoch: 55 | Iteration number: [2740/4518] 60% | Training loss: 0.6870296661653658
Epoch: 55 | Iteration number: [2750/4518] 60% | Training loss: 0.68702860511433
Epoch: 55 | Iteration number: [2760/4518] 61% | Training loss: 0.6870259939760401
Epoch: 55 | Iteration number: [2770/4518] 61% | Training loss: 0.687025304133281
Epoch: 55 | Iteration number: [2780/4518] 61% | Training loss: 0.6870223220089356
Epoch: 55 | Iteration number: [2790/4518] 61% | Training loss: 0.6870197246365223
Epoch: 55 | Iteration number: [2800/4518] 61% | Training loss: 0.6870215531545026
Epoch: 55 | Iteration number: [2810/4518] 62% | Training loss: 0.6870222863989792
Epoch: 55 | Iteration number: [2820/4518] 62% | Training loss: 0.6870204595175196
Epoch: 55 | Iteration number: [2830/4518] 62% | Training loss: 0.6870227627324552
Epoch: 55 | Iteration number: [2840/4518] 62% | Training loss: 0.687025415540581
Epoch: 55 | Iteration number: [2850/4518] 63% | Training loss: 0.6870271424452464
Epoch: 55 | Iteration number: [2860/4518] 63% | Training loss: 0.6870269970460372
Epoch: 55 | Iteration number: [2870/4518] 63% | Training loss: 0.6870230303408792
Epoch: 55 | Iteration number: [2880/4518] 63% | Training loss: 0.6870200206836065
Epoch: 55 | Iteration number: [2890/4518] 63% | Training loss: 0.6870146725623253
Epoch: 55 | Iteration number: [2900/4518] 64% | Training loss: 0.6870174308686421
Epoch: 55 | Iteration number: [2910/4518] 64% | Training loss: 0.6870164156369737
Epoch: 55 | Iteration number: [2920/4518] 64% | Training loss: 0.6870153093174712
Epoch: 55 | Iteration number: [2930/4518] 64% | Training loss: 0.6870138942178199
Epoch: 55 | Iteration number: [2940/4518] 65% | Training loss: 0.687013563959777
Epoch: 55 | Iteration number: [2950/4518] 65% | Training loss: 0.687009659156961
Epoch: 55 | Iteration number: [2960/4518] 65% | Training loss: 0.6870144563148151
Epoch: 55 | Iteration number: [2970/4518] 65% | Training loss: 0.6870116923593913
Epoch: 55 | Iteration number: [2980/4518] 65% | Training loss: 0.6870099945956428
Epoch: 55 | Iteration number: [2990/4518] 66% | Training loss: 0.6870102175103382
Epoch: 55 | Iteration number: [3000/4518] 66% | Training loss: 0.6870055286685626
Epoch: 55 | Iteration number: [3010/4518] 66% | Training loss: 0.6870067682971194
Epoch: 55 | Iteration number: [3020/4518] 66% | Training loss: 0.6870101686542397
Epoch: 55 | Iteration number: [3030/4518] 67% | Training loss: 0.6870110566466555
Epoch: 55 | Iteration number: [3040/4518] 67% | Training loss: 0.6870094607143026
Epoch: 55 | Iteration number: [3050/4518] 67% | Training loss: 0.6870110923344972
Epoch: 55 | Iteration number: [3060/4518] 67% | Training loss: 0.6870124443878536
Epoch: 55 | Iteration number: [3070/4518] 67% | Training loss: 0.6870122801014965
Epoch: 55 | Iteration number: [3080/4518] 68% | Training loss: 0.687014782254572
Epoch: 55 | Iteration number: [3090/4518] 68% | Training loss: 0.6870171545778664
Epoch: 55 | Iteration number: [3100/4518] 68% | Training loss: 0.6870170400411852
Epoch: 55 | Iteration number: [3110/4518] 68% | Training loss: 0.6870150699684474
Epoch: 55 | Iteration number: [3120/4518] 69% | Training loss: 0.6870155765269047
Epoch: 55 | Iteration number: [3130/4518] 69% | Training loss: 0.6870129083673032
Epoch: 55 | Iteration number: [3140/4518] 69% | Training loss: 0.687012129718331
Epoch: 55 | Iteration number: [3150/4518] 69% | Training loss: 0.6870115693977901
Epoch: 55 | Iteration number: [3160/4518] 69% | Training loss: 0.6870124601865116
Epoch: 55 | Iteration number: [3170/4518] 70% | Training loss: 0.687008113364692
Epoch: 55 | Iteration number: [3180/4518] 70% | Training loss: 0.687001013587106
Epoch: 55 | Iteration number: [3190/4518] 70% | Training loss: 0.6870046664928567
Epoch: 55 | Iteration number: [3200/4518] 70% | Training loss: 0.6870006842166185
Epoch: 55 | Iteration number: [3210/4518] 71% | Training loss: 0.687001519002647
Epoch: 55 | Iteration number: [3220/4518] 71% | Training loss: 0.6870004890683274
Epoch: 55 | Iteration number: [3230/4518] 71% | Training loss: 0.687001688672293
Epoch: 55 | Iteration number: [3240/4518] 71% | Training loss: 0.6870058687196837
Epoch: 55 | Iteration number: [3250/4518] 71% | Training loss: 0.6870050645057971
Epoch: 55 | Iteration number: [3260/4518] 72% | Training loss: 0.6870051815100243
Epoch: 55 | Iteration number: [3270/4518] 72% | Training loss: 0.6870038490412067
Epoch: 55 | Iteration number: [3280/4518] 72% | Training loss: 0.6870037720697683
Epoch: 55 | Iteration number: [3290/4518] 72% | Training loss: 0.6870060424130738
Epoch: 55 | Iteration number: [3300/4518] 73% | Training loss: 0.687008735501405
Epoch: 55 | Iteration number: [3310/4518] 73% | Training loss: 0.687008533196867
Epoch: 55 | Iteration number: [3320/4518] 73% | Training loss: 0.6870042670742575
Epoch: 55 | Iteration number: [3330/4518] 73% | Training loss: 0.6869999105507905
Epoch: 55 | Iteration number: [3340/4518] 73% | Training loss: 0.6869971164329324
Epoch: 55 | Iteration number: [3350/4518] 74% | Training loss: 0.6869970040712784
Epoch: 55 | Iteration number: [3360/4518] 74% | Training loss: 0.6869958177918479
Epoch: 55 | Iteration number: [3370/4518] 74% | Training loss: 0.6869961134757769
Epoch: 55 | Iteration number: [3380/4518] 74% | Training loss: 0.6869978348531667
Epoch: 55 | Iteration number: [3390/4518] 75% | Training loss: 0.6869965994076743
Epoch: 55 | Iteration number: [3400/4518] 75% | Training loss: 0.6869979318099864
Epoch: 55 | Iteration number: [3410/4518] 75% | Training loss: 0.6869965416595034
Epoch: 55 | Iteration number: [3420/4518] 75% | Training loss: 0.6869935126506794
Epoch: 55 | Iteration number: [3430/4518] 75% | Training loss: 0.686993153050064
Epoch: 55 | Iteration number: [3440/4518] 76% | Training loss: 0.6869911442662394
Epoch: 55 | Iteration number: [3450/4518] 76% | Training loss: 0.6869923926781917
Epoch: 55 | Iteration number: [3460/4518] 76% | Training loss: 0.6869916479022516
Epoch: 55 | Iteration number: [3470/4518] 76% | Training loss: 0.6869886932352435
Epoch: 55 | Iteration number: [3480/4518] 77% | Training loss: 0.6869930048098509
Epoch: 55 | Iteration number: [3490/4518] 77% | Training loss: 0.686995696543281
Epoch: 55 | Iteration number: [3500/4518] 77% | Training loss: 0.6869966855900628
Epoch: 55 | Iteration number: [3510/4518] 77% | Training loss: 0.6869972834729741
Epoch: 55 | Iteration number: [3520/4518] 77% | Training loss: 0.6869956270029599
Epoch: 55 | Iteration number: [3530/4518] 78% | Training loss: 0.6869978353085666
Epoch: 55 | Iteration number: [3540/4518] 78% | Training loss: 0.6869957176978979
Epoch: 55 | Iteration number: [3550/4518] 78% | Training loss: 0.6869912133754139
Epoch: 55 | Iteration number: [3560/4518] 78% | Training loss: 0.6869899145003115
Epoch: 55 | Iteration number: [3570/4518] 79% | Training loss: 0.6869886471443818
Epoch: 55 | Iteration number: [3580/4518] 79% | Training loss: 0.686991242140365
Epoch: 55 | Iteration number: [3590/4518] 79% | Training loss: 0.6869918981634475
Epoch: 55 | Iteration number: [3600/4518] 79% | Training loss: 0.6869955156246821
Epoch: 55 | Iteration number: [3610/4518] 79% | Training loss: 0.6869972953836013
Epoch: 55 | Iteration number: [3620/4518] 80% | Training loss: 0.6869912721010861
Epoch: 55 | Iteration number: [3630/4518] 80% | Training loss: 0.6869903290731519
Epoch: 55 | Iteration number: [3640/4518] 80% | Training loss: 0.6869899065776186
Epoch: 55 | Iteration number: [3650/4518] 80% | Training loss: 0.6869883554928923
Epoch: 55 | Iteration number: [3660/4518] 81% | Training loss: 0.6869895108573424
Epoch: 55 | Iteration number: [3670/4518] 81% | Training loss: 0.686990067078567
Epoch: 55 | Iteration number: [3680/4518] 81% | Training loss: 0.686989410351152
Epoch: 55 | Iteration number: [3690/4518] 81% | Training loss: 0.6869875559800362
Epoch: 55 | Iteration number: [3700/4518] 81% | Training loss: 0.6869842964088595
Epoch: 55 | Iteration number: [3710/4518] 82% | Training loss: 0.6869837332285961
Epoch: 55 | Iteration number: [3720/4518] 82% | Training loss: 0.6869845556155327
Epoch: 55 | Iteration number: [3730/4518] 82% | Training loss: 0.6869804452315732
Epoch: 55 | Iteration number: [3740/4518] 82% | Training loss: 0.6869848001608874
Epoch: 55 | Iteration number: [3750/4518] 83% | Training loss: 0.6869854945182801
Epoch: 55 | Iteration number: [3760/4518] 83% | Training loss: 0.686985391235732
Epoch: 55 | Iteration number: [3770/4518] 83% | Training loss: 0.6869826942128907
Epoch: 55 | Iteration number: [3780/4518] 83% | Training loss: 0.6869809764245199
Epoch: 55 | Iteration number: [3790/4518] 83% | Training loss: 0.6869801964168498
Epoch: 55 | Iteration number: [3800/4518] 84% | Training loss: 0.6869822530997427
Epoch: 55 | Iteration number: [3810/4518] 84% | Training loss: 0.6869793767691285
Epoch: 55 | Iteration number: [3820/4518] 84% | Training loss: 0.6869766395597557
Epoch: 55 | Iteration number: [3830/4518] 84% | Training loss: 0.6869787134483029
Epoch: 55 | Iteration number: [3840/4518] 84% | Training loss: 0.6869800851059457
Epoch: 55 | Iteration number: [3850/4518] 85% | Training loss: 0.6869798501435812
Epoch: 55 | Iteration number: [3860/4518] 85% | Training loss: 0.6869817775920265
Epoch: 55 | Iteration number: [3870/4518] 85% | Training loss: 0.6869821903471491
Epoch: 55 | Iteration number: [3880/4518] 85% | Training loss: 0.6869840874346261
Epoch: 55 | Iteration number: [3890/4518] 86% | Training loss: 0.6869861615194454
Epoch: 55 | Iteration number: [3900/4518] 86% | Training loss: 0.6869860290564024
Epoch: 55 | Iteration number: [3910/4518] 86% | Training loss: 0.6869859860528765
Epoch: 55 | Iteration number: [3920/4518] 86% | Training loss: 0.6869840749216323
Epoch: 55 | Iteration number: [3930/4518] 86% | Training loss: 0.6869833228242306
Epoch: 55 | Iteration number: [3940/4518] 87% | Training loss: 0.6869824916426905
Epoch: 55 | Iteration number: [3950/4518] 87% | Training loss: 0.6869828028316739
Epoch: 55 | Iteration number: [3960/4518] 87% | Training loss: 0.6869827358108578
Epoch: 55 | Iteration number: [3970/4518] 87% | Training loss: 0.686981287531048
Epoch: 55 | Iteration number: [3980/4518] 88% | Training loss: 0.6869840674064867
Epoch: 55 | Iteration number: [3990/4518] 88% | Training loss: 0.6869846498010153
Epoch: 55 | Iteration number: [4000/4518] 88% | Training loss: 0.6869832719862461
Epoch: 55 | Iteration number: [4010/4518] 88% | Training loss: 0.6869820811504735
Epoch: 55 | Iteration number: [4020/4518] 88% | Training loss: 0.6869779773612521
Epoch: 55 | Iteration number: [4030/4518] 89% | Training loss: 0.6869745758271987
Epoch: 55 | Iteration number: [4040/4518] 89% | Training loss: 0.6869732843619762
Epoch: 55 | Iteration number: [4050/4518] 89% | Training loss: 0.6869753640669364
Epoch: 55 | Iteration number: [4060/4518] 89% | Training loss: 0.6869775428560567
Epoch: 55 | Iteration number: [4070/4518] 90% | Training loss: 0.6869729298484999
Epoch: 55 | Iteration number: [4080/4518] 90% | Training loss: 0.6869704213650788
Epoch: 55 | Iteration number: [4090/4518] 90% | Training loss: 0.686970379474985
Epoch: 55 | Iteration number: [4100/4518] 90% | Training loss: 0.6869728741994718
Epoch: 55 | Iteration number: [4110/4518] 90% | Training loss: 0.6869737052859471
Epoch: 55 | Iteration number: [4120/4518] 91% | Training loss: 0.6869726766949719
Epoch: 55 | Iteration number: [4130/4518] 91% | Training loss: 0.6869716866541717
Epoch: 55 | Iteration number: [4140/4518] 91% | Training loss: 0.6869744235766683
Epoch: 55 | Iteration number: [4150/4518] 91% | Training loss: 0.6869748968675912
Epoch: 55 | Iteration number: [4160/4518] 92% | Training loss: 0.6869746201886581
Epoch: 55 | Iteration number: [4170/4518] 92% | Training loss: 0.6869763338880287
Epoch: 55 | Iteration number: [4180/4518] 92% | Training loss: 0.6869790092894905
Epoch: 55 | Iteration number: [4190/4518] 92% | Training loss: 0.6869773541970583
Epoch: 55 | Iteration number: [4200/4518] 92% | Training loss: 0.6869752593125615
Epoch: 55 | Iteration number: [4210/4518] 93% | Training loss: 0.6869728532794536
Epoch: 55 | Iteration number: [4220/4518] 93% | Training loss: 0.6869732944321293
Epoch: 55 | Iteration number: [4230/4518] 93% | Training loss: 0.6869767724340408
Epoch: 55 | Iteration number: [4240/4518] 93% | Training loss: 0.6869753638247273
Epoch: 55 | Iteration number: [4250/4518] 94% | Training loss: 0.6869723246939042
Epoch: 55 | Iteration number: [4260/4518] 94% | Training loss: 0.6869692725474845
Epoch: 55 | Iteration number: [4270/4518] 94% | Training loss: 0.6869684155149259
Epoch: 55 | Iteration number: [4280/4518] 94% | Training loss: 0.6869680773153484
Epoch: 55 | Iteration number: [4290/4518] 94% | Training loss: 0.6869680007437726
Epoch: 55 | Iteration number: [4300/4518] 95% | Training loss: 0.6869698420236277
Epoch: 55 | Iteration number: [4310/4518] 95% | Training loss: 0.6869699751832922
Epoch: 55 | Iteration number: [4320/4518] 95% | Training loss: 0.6869696690804429
Epoch: 55 | Iteration number: [4330/4518] 95% | Training loss: 0.6869690260353044
Epoch: 55 | Iteration number: [4340/4518] 96% | Training loss: 0.6869704445386262
Epoch: 55 | Iteration number: [4350/4518] 96% | Training loss: 0.6869722048989658
Epoch: 55 | Iteration number: [4360/4518] 96% | Training loss: 0.6869700584389747
Epoch: 55 | Iteration number: [4370/4518] 96% | Training loss: 0.68696935242319
Epoch: 55 | Iteration number: [4380/4518] 96% | Training loss: 0.6869682777553933
Epoch: 55 | Iteration number: [4390/4518] 97% | Training loss: 0.6869690828958785
Epoch: 55 | Iteration number: [4400/4518] 97% | Training loss: 0.6869709603488445
Epoch: 55 | Iteration number: [4410/4518] 97% | Training loss: 0.6869693435103444
Epoch: 55 | Iteration number: [4420/4518] 97% | Training loss: 0.6869720067104064
Epoch: 55 | Iteration number: [4430/4518] 98% | Training loss: 0.6869692044521831
Epoch: 55 | Iteration number: [4440/4518] 98% | Training loss: 0.6869676312884769
Epoch: 55 | Iteration number: [4450/4518] 98% | Training loss: 0.6869670328933202
Epoch: 55 | Iteration number: [4460/4518] 98% | Training loss: 0.6869651431192731
Epoch: 55 | Iteration number: [4470/4518] 98% | Training loss: 0.6869616878246034
Epoch: 55 | Iteration number: [4480/4518] 99% | Training loss: 0.6869594288989902
Epoch: 55 | Iteration number: [4490/4518] 99% | Training loss: 0.6869566799404891
Epoch: 55 | Iteration number: [4500/4518] 99% | Training loss: 0.6869556759728326
Epoch: 55 | Iteration number: [4510/4518] 99% | Training loss: 0.6869552701513413

 End of epoch: 55 | Train Loss: 0.6868025660778686 | Training Time: 643 

 End of epoch: 55 | Eval Loss: 0.6901110544496653 | Evaluating Time: 17 
Epoch: 56 | Iteration number: [10/4518] 0% | Training loss: 0.7553859531879425
Epoch: 56 | Iteration number: [20/4518] 0% | Training loss: 0.7209750145673752
Epoch: 56 | Iteration number: [30/4518] 0% | Training loss: 0.7091582675774892
Epoch: 56 | Iteration number: [40/4518] 0% | Training loss: 0.703867281973362
Epoch: 56 | Iteration number: [50/4518] 1% | Training loss: 0.7006137692928314
Epoch: 56 | Iteration number: [60/4518] 1% | Training loss: 0.6983461081981659
Epoch: 56 | Iteration number: [70/4518] 1% | Training loss: 0.6966766502176013
Epoch: 56 | Iteration number: [80/4518] 1% | Training loss: 0.6954011119902134
Epoch: 56 | Iteration number: [90/4518] 1% | Training loss: 0.6944023383988275
Epoch: 56 | Iteration number: [100/4518] 2% | Training loss: 0.6937159532308579
Epoch: 56 | Iteration number: [110/4518] 2% | Training loss: 0.6930581596764651
Epoch: 56 | Iteration number: [120/4518] 2% | Training loss: 0.6924993072946867
Epoch: 56 | Iteration number: [130/4518] 2% | Training loss: 0.6921054638349093
Epoch: 56 | Iteration number: [140/4518] 3% | Training loss: 0.6917190015316009
Epoch: 56 | Iteration number: [150/4518] 3% | Training loss: 0.6914099780718486
Epoch: 56 | Iteration number: [160/4518] 3% | Training loss: 0.6911741510033608
Epoch: 56 | Iteration number: [170/4518] 3% | Training loss: 0.6909361516728121
Epoch: 56 | Iteration number: [180/4518] 3% | Training loss: 0.6906516962581211
Epoch: 56 | Iteration number: [190/4518] 4% | Training loss: 0.6904397192754244
Epoch: 56 | Iteration number: [200/4518] 4% | Training loss: 0.6902896648645401
Epoch: 56 | Iteration number: [210/4518] 4% | Training loss: 0.690143176487514
Epoch: 56 | Iteration number: [220/4518] 4% | Training loss: 0.6900374352931976
Epoch: 56 | Iteration number: [230/4518] 5% | Training loss: 0.689918431510096
Epoch: 56 | Iteration number: [240/4518] 5% | Training loss: 0.6898483085135619
Epoch: 56 | Iteration number: [250/4518] 5% | Training loss: 0.6897938270568847
Epoch: 56 | Iteration number: [260/4518] 5% | Training loss: 0.6896923732299071
Epoch: 56 | Iteration number: [270/4518] 5% | Training loss: 0.6895759812107792
Epoch: 56 | Iteration number: [280/4518] 6% | Training loss: 0.6894362215484892
Epoch: 56 | Iteration number: [290/4518] 6% | Training loss: 0.6893236970079356
Epoch: 56 | Iteration number: [300/4518] 6% | Training loss: 0.6892825615406036
Epoch: 56 | Iteration number: [310/4518] 6% | Training loss: 0.6892341675296907
Epoch: 56 | Iteration number: [320/4518] 7% | Training loss: 0.6891663342714309
Epoch: 56 | Iteration number: [330/4518] 7% | Training loss: 0.6890770677364234
Epoch: 56 | Iteration number: [340/4518] 7% | Training loss: 0.6890169469749227
Epoch: 56 | Iteration number: [350/4518] 7% | Training loss: 0.6889617879050118
Epoch: 56 | Iteration number: [360/4518] 7% | Training loss: 0.6889044697086016
Epoch: 56 | Iteration number: [370/4518] 8% | Training loss: 0.6888367205052762
Epoch: 56 | Iteration number: [380/4518] 8% | Training loss: 0.6888250702305844
Epoch: 56 | Iteration number: [390/4518] 8% | Training loss: 0.6887715981556819
Epoch: 56 | Iteration number: [400/4518] 8% | Training loss: 0.6886999528110027
Epoch: 56 | Iteration number: [410/4518] 9% | Training loss: 0.6886666588666962
Epoch: 56 | Iteration number: [420/4518] 9% | Training loss: 0.6885901175794147
Epoch: 56 | Iteration number: [430/4518] 9% | Training loss: 0.6885884804781093
Epoch: 56 | Iteration number: [440/4518] 9% | Training loss: 0.688572437654842
Epoch: 56 | Iteration number: [450/4518] 9% | Training loss: 0.6885208960374196
Epoch: 56 | Iteration number: [460/4518] 10% | Training loss: 0.6884849962980851
Epoch: 56 | Iteration number: [470/4518] 10% | Training loss: 0.6884022103979233
Epoch: 56 | Iteration number: [480/4518] 10% | Training loss: 0.688375125452876
Epoch: 56 | Iteration number: [490/4518] 10% | Training loss: 0.6883188046971146
Epoch: 56 | Iteration number: [500/4518] 11% | Training loss: 0.6882917333841324
Epoch: 56 | Iteration number: [510/4518] 11% | Training loss: 0.6882516212323133
Epoch: 56 | Iteration number: [520/4518] 11% | Training loss: 0.6882312641693995
Epoch: 56 | Iteration number: [530/4518] 11% | Training loss: 0.6882024760516184
Epoch: 56 | Iteration number: [540/4518] 11% | Training loss: 0.6881703607462071
Epoch: 56 | Iteration number: [550/4518] 12% | Training loss: 0.6881585142829202
Epoch: 56 | Iteration number: [560/4518] 12% | Training loss: 0.68814512565732
Epoch: 56 | Iteration number: [570/4518] 12% | Training loss: 0.6881136993567148
Epoch: 56 | Iteration number: [580/4518] 12% | Training loss: 0.6881101203375849
Epoch: 56 | Iteration number: [590/4518] 13% | Training loss: 0.6880900980052301
Epoch: 56 | Iteration number: [600/4518] 13% | Training loss: 0.6880851678053538
Epoch: 56 | Iteration number: [610/4518] 13% | Training loss: 0.6880647690569768
Epoch: 56 | Iteration number: [620/4518] 13% | Training loss: 0.688051567539092
Epoch: 56 | Iteration number: [630/4518] 13% | Training loss: 0.6880403260389963
Epoch: 56 | Iteration number: [640/4518] 14% | Training loss: 0.6880487112328411
Epoch: 56 | Iteration number: [650/4518] 14% | Training loss: 0.6880165371528039
Epoch: 56 | Iteration number: [660/4518] 14% | Training loss: 0.6880012945695357
Epoch: 56 | Iteration number: [670/4518] 14% | Training loss: 0.6879924175454609
Epoch: 56 | Iteration number: [680/4518] 15% | Training loss: 0.687970150568906
Epoch: 56 | Iteration number: [690/4518] 15% | Training loss: 0.6879356662432353
Epoch: 56 | Iteration number: [700/4518] 15% | Training loss: 0.6879048728091376
Epoch: 56 | Iteration number: [710/4518] 15% | Training loss: 0.6879015616128142
Epoch: 56 | Iteration number: [720/4518] 15% | Training loss: 0.6878903720941808
Epoch: 56 | Iteration number: [730/4518] 16% | Training loss: 0.6878724934303597
Epoch: 56 | Iteration number: [740/4518] 16% | Training loss: 0.6878707362187876
Epoch: 56 | Iteration number: [750/4518] 16% | Training loss: 0.6878408850034078
Epoch: 56 | Iteration number: [760/4518] 16% | Training loss: 0.687841372191906
Epoch: 56 | Iteration number: [770/4518] 17% | Training loss: 0.6878066921388948
Epoch: 56 | Iteration number: [780/4518] 17% | Training loss: 0.6878073124549328
Epoch: 56 | Iteration number: [790/4518] 17% | Training loss: 0.6877915581570396
Epoch: 56 | Iteration number: [800/4518] 17% | Training loss: 0.6877832620590926
Epoch: 56 | Iteration number: [810/4518] 17% | Training loss: 0.6877626882659065
Epoch: 56 | Iteration number: [820/4518] 18% | Training loss: 0.6877456070446386
Epoch: 56 | Iteration number: [830/4518] 18% | Training loss: 0.6877382886697011
Epoch: 56 | Iteration number: [840/4518] 18% | Training loss: 0.6877256833371662
Epoch: 56 | Iteration number: [850/4518] 18% | Training loss: 0.6877062777911915
Epoch: 56 | Iteration number: [860/4518] 19% | Training loss: 0.6877169177975766
Epoch: 56 | Iteration number: [870/4518] 19% | Training loss: 0.687717488236811
Epoch: 56 | Iteration number: [880/4518] 19% | Training loss: 0.6877259695394473
Epoch: 56 | Iteration number: [890/4518] 19% | Training loss: 0.6877219600623913
Epoch: 56 | Iteration number: [900/4518] 19% | Training loss: 0.6877074033021927
Epoch: 56 | Iteration number: [910/4518] 20% | Training loss: 0.6876940315241342
Epoch: 56 | Iteration number: [920/4518] 20% | Training loss: 0.6876913741878842
Epoch: 56 | Iteration number: [930/4518] 20% | Training loss: 0.6877072820099451
Epoch: 56 | Iteration number: [940/4518] 20% | Training loss: 0.6877013731510081
Epoch: 56 | Iteration number: [950/4518] 21% | Training loss: 0.6876882987273367
Epoch: 56 | Iteration number: [960/4518] 21% | Training loss: 0.6876886839047074
Epoch: 56 | Iteration number: [970/4518] 21% | Training loss: 0.6876753751764593
Epoch: 56 | Iteration number: [980/4518] 21% | Training loss: 0.6876833564772897
Epoch: 56 | Iteration number: [990/4518] 21% | Training loss: 0.6876624227774264
Epoch: 56 | Iteration number: [1000/4518] 22% | Training loss: 0.6876418135166168
Epoch: 56 | Iteration number: [1010/4518] 22% | Training loss: 0.6876316972888342
Epoch: 56 | Iteration number: [1020/4518] 22% | Training loss: 0.6876109054859947
Epoch: 56 | Iteration number: [1030/4518] 22% | Training loss: 0.6876063757151076
Epoch: 56 | Iteration number: [1040/4518] 23% | Training loss: 0.6876041183678003
Epoch: 56 | Iteration number: [1050/4518] 23% | Training loss: 0.6875983227434612
Epoch: 56 | Iteration number: [1060/4518] 23% | Training loss: 0.6875835336604208
Epoch: 56 | Iteration number: [1070/4518] 23% | Training loss: 0.6875674500086597
Epoch: 56 | Iteration number: [1080/4518] 23% | Training loss: 0.6875507399991706
Epoch: 56 | Iteration number: [1090/4518] 24% | Training loss: 0.6875434831741754
Epoch: 56 | Iteration number: [1100/4518] 24% | Training loss: 0.6875456664778969
Epoch: 56 | Iteration number: [1110/4518] 24% | Training loss: 0.687526617984514
Epoch: 56 | Iteration number: [1120/4518] 24% | Training loss: 0.6875279810811792
Epoch: 56 | Iteration number: [1130/4518] 25% | Training loss: 0.6875333803944883
Epoch: 56 | Iteration number: [1140/4518] 25% | Training loss: 0.6875312350298229
Epoch: 56 | Iteration number: [1150/4518] 25% | Training loss: 0.6875134047736292
Epoch: 56 | Iteration number: [1160/4518] 25% | Training loss: 0.6875191970631994
Epoch: 56 | Iteration number: [1170/4518] 25% | Training loss: 0.6875108065258744
Epoch: 56 | Iteration number: [1180/4518] 26% | Training loss: 0.6875048351489892
Epoch: 56 | Iteration number: [1190/4518] 26% | Training loss: 0.6875003220654335
Epoch: 56 | Iteration number: [1200/4518] 26% | Training loss: 0.6875012115637461
Epoch: 56 | Iteration number: [1210/4518] 26% | Training loss: 0.6874973309926751
Epoch: 56 | Iteration number: [1220/4518] 27% | Training loss: 0.6874933507110251
Epoch: 56 | Iteration number: [1230/4518] 27% | Training loss: 0.6874806288296614
Epoch: 56 | Iteration number: [1240/4518] 27% | Training loss: 0.6874659256108345
Epoch: 56 | Iteration number: [1250/4518] 27% | Training loss: 0.6874450619220733
Epoch: 56 | Iteration number: [1260/4518] 27% | Training loss: 0.6874241455679848
Epoch: 56 | Iteration number: [1270/4518] 28% | Training loss: 0.6874121046441747
Epoch: 56 | Iteration number: [1280/4518] 28% | Training loss: 0.687413807073608
Epoch: 56 | Iteration number: [1290/4518] 28% | Training loss: 0.6874155353206073
Epoch: 56 | Iteration number: [1300/4518] 28% | Training loss: 0.6874064125464513
Epoch: 56 | Iteration number: [1310/4518] 28% | Training loss: 0.6874016237622909
Epoch: 56 | Iteration number: [1320/4518] 29% | Training loss: 0.6873957095272614
Epoch: 56 | Iteration number: [1330/4518] 29% | Training loss: 0.6873917103261876
Epoch: 56 | Iteration number: [1340/4518] 29% | Training loss: 0.687381365139093
Epoch: 56 | Iteration number: [1350/4518] 29% | Training loss: 0.6873770880257641
Epoch: 56 | Iteration number: [1360/4518] 30% | Training loss: 0.687372859392096
Epoch: 56 | Iteration number: [1370/4518] 30% | Training loss: 0.6873637388222409
Epoch: 56 | Iteration number: [1380/4518] 30% | Training loss: 0.6873647715302481
Epoch: 56 | Iteration number: [1390/4518] 30% | Training loss: 0.6873568521986763
Epoch: 56 | Iteration number: [1400/4518] 30% | Training loss: 0.6873617290599006
Epoch: 56 | Iteration number: [1410/4518] 31% | Training loss: 0.6873603614086801
Epoch: 56 | Iteration number: [1420/4518] 31% | Training loss: 0.6873474312500215
Epoch: 56 | Iteration number: [1430/4518] 31% | Training loss: 0.687341910433936
Epoch: 56 | Iteration number: [1440/4518] 31% | Training loss: 0.68733917147749
Epoch: 56 | Iteration number: [1450/4518] 32% | Training loss: 0.6873289169936344
Epoch: 56 | Iteration number: [1460/4518] 32% | Training loss: 0.6873196114415991
Epoch: 56 | Iteration number: [1470/4518] 32% | Training loss: 0.687320108032551
Epoch: 56 | Iteration number: [1480/4518] 32% | Training loss: 0.687313999920278
Epoch: 56 | Iteration number: [1490/4518] 32% | Training loss: 0.6873074680766803
Epoch: 56 | Iteration number: [1500/4518] 33% | Training loss: 0.6872982910076777
Epoch: 56 | Iteration number: [1510/4518] 33% | Training loss: 0.6872940924388683
Epoch: 56 | Iteration number: [1520/4518] 33% | Training loss: 0.6872884051580178
Epoch: 56 | Iteration number: [1530/4518] 33% | Training loss: 0.6872838990361083
Epoch: 56 | Iteration number: [1540/4518] 34% | Training loss: 0.6872754093114432
Epoch: 56 | Iteration number: [1550/4518] 34% | Training loss: 0.6872741313134471
Epoch: 56 | Iteration number: [1560/4518] 34% | Training loss: 0.687272917613005
Epoch: 56 | Iteration number: [1570/4518] 34% | Training loss: 0.6872780431607727
Epoch: 56 | Iteration number: [1580/4518] 34% | Training loss: 0.6872821010743515
Epoch: 56 | Iteration number: [1590/4518] 35% | Training loss: 0.6872770601473515
Epoch: 56 | Iteration number: [1600/4518] 35% | Training loss: 0.6872798680886626
Epoch: 56 | Iteration number: [1610/4518] 35% | Training loss: 0.6872767140036043
Epoch: 56 | Iteration number: [1620/4518] 35% | Training loss: 0.6872690165852323
Epoch: 56 | Iteration number: [1630/4518] 36% | Training loss: 0.687270218901839
Epoch: 56 | Iteration number: [1640/4518] 36% | Training loss: 0.6872660425014612
Epoch: 56 | Iteration number: [1650/4518] 36% | Training loss: 0.6872600402254047
Epoch: 56 | Iteration number: [1660/4518] 36% | Training loss: 0.6872562744172223
Epoch: 56 | Iteration number: [1670/4518] 36% | Training loss: 0.6872521192370774
Epoch: 56 | Iteration number: [1680/4518] 37% | Training loss: 0.6872495560064202
Epoch: 56 | Iteration number: [1690/4518] 37% | Training loss: 0.6872505723372013
Epoch: 56 | Iteration number: [1700/4518] 37% | Training loss: 0.6872515673146529
Epoch: 56 | Iteration number: [1710/4518] 37% | Training loss: 0.687251429390489
Epoch: 56 | Iteration number: [1720/4518] 38% | Training loss: 0.6872606404992037
Epoch: 56 | Iteration number: [1730/4518] 38% | Training loss: 0.6872636304769902
Epoch: 56 | Iteration number: [1740/4518] 38% | Training loss: 0.6872522634678874
Epoch: 56 | Iteration number: [1750/4518] 38% | Training loss: 0.6872542620045798
Epoch: 56 | Iteration number: [1760/4518] 38% | Training loss: 0.6872543173080141
Epoch: 56 | Iteration number: [1770/4518] 39% | Training loss: 0.6872478796600622
Epoch: 56 | Iteration number: [1780/4518] 39% | Training loss: 0.6872463448328918
Epoch: 56 | Iteration number: [1790/4518] 39% | Training loss: 0.6872483462594741
Epoch: 56 | Iteration number: [1800/4518] 39% | Training loss: 0.6872445721427599
Epoch: 56 | Iteration number: [1810/4518] 40% | Training loss: 0.6872459978029872
Epoch: 56 | Iteration number: [1820/4518] 40% | Training loss: 0.6872424022836999
Epoch: 56 | Iteration number: [1830/4518] 40% | Training loss: 0.6872350087257031
Epoch: 56 | Iteration number: [1840/4518] 40% | Training loss: 0.6872268457451592
Epoch: 56 | Iteration number: [1850/4518] 40% | Training loss: 0.687222906415527
Epoch: 56 | Iteration number: [1860/4518] 41% | Training loss: 0.687220543014106
Epoch: 56 | Iteration number: [1870/4518] 41% | Training loss: 0.6872192303764629
Epoch: 56 | Iteration number: [1880/4518] 41% | Training loss: 0.6872176675086326
Epoch: 56 | Iteration number: [1890/4518] 41% | Training loss: 0.6872174193304051
Epoch: 56 | Iteration number: [1900/4518] 42% | Training loss: 0.6872184476099517
Epoch: 56 | Iteration number: [1910/4518] 42% | Training loss: 0.6872193828303153
Epoch: 56 | Iteration number: [1920/4518] 42% | Training loss: 0.6872169529087842
Epoch: 56 | Iteration number: [1930/4518] 42% | Training loss: 0.6872074867468424
Epoch: 56 | Iteration number: [1940/4518] 42% | Training loss: 0.6872106510339324
Epoch: 56 | Iteration number: [1950/4518] 43% | Training loss: 0.6872095311910679
Epoch: 56 | Iteration number: [1960/4518] 43% | Training loss: 0.6872066425729771
Epoch: 56 | Iteration number: [1970/4518] 43% | Training loss: 0.6872051148245177
Epoch: 56 | Iteration number: [1980/4518] 43% | Training loss: 0.6872080362505383
Epoch: 56 | Iteration number: [1990/4518] 44% | Training loss: 0.6872014534533324
Epoch: 56 | Iteration number: [2000/4518] 44% | Training loss: 0.687191225618124
Epoch: 56 | Iteration number: [2010/4518] 44% | Training loss: 0.687185041139375
Epoch: 56 | Iteration number: [2020/4518] 44% | Training loss: 0.6871839089263784
Epoch: 56 | Iteration number: [2030/4518] 44% | Training loss: 0.687186004757294
Epoch: 56 | Iteration number: [2040/4518] 45% | Training loss: 0.6871827609398786
Epoch: 56 | Iteration number: [2050/4518] 45% | Training loss: 0.6871800317996886
Epoch: 56 | Iteration number: [2060/4518] 45% | Training loss: 0.6871710259937546
Epoch: 56 | Iteration number: [2070/4518] 45% | Training loss: 0.6871657685381203
Epoch: 56 | Iteration number: [2080/4518] 46% | Training loss: 0.6871690224569578
Epoch: 56 | Iteration number: [2090/4518] 46% | Training loss: 0.6871661368454473
Epoch: 56 | Iteration number: [2100/4518] 46% | Training loss: 0.687169001187597
Epoch: 56 | Iteration number: [2110/4518] 46% | Training loss: 0.6871632410169213
Epoch: 56 | Iteration number: [2120/4518] 46% | Training loss: 0.6871600048440807
Epoch: 56 | Iteration number: [2130/4518] 47% | Training loss: 0.6871577338713436
Epoch: 56 | Iteration number: [2140/4518] 47% | Training loss: 0.6871611382638183
Epoch: 56 | Iteration number: [2150/4518] 47% | Training loss: 0.687165080863376
Epoch: 56 | Iteration number: [2160/4518] 47% | Training loss: 0.6871561194459598
Epoch: 56 | Iteration number: [2170/4518] 48% | Training loss: 0.6871545356814213
Epoch: 56 | Iteration number: [2180/4518] 48% | Training loss: 0.6871512660192787
Epoch: 56 | Iteration number: [2190/4518] 48% | Training loss: 0.6871488746442751
Epoch: 56 | Iteration number: [2200/4518] 48% | Training loss: 0.6871499472043731
Epoch: 56 | Iteration number: [2210/4518] 48% | Training loss: 0.6871528563995707
Epoch: 56 | Iteration number: [2220/4518] 49% | Training loss: 0.6871529653802648
Epoch: 56 | Iteration number: [2230/4518] 49% | Training loss: 0.6871521662436259
Epoch: 56 | Iteration number: [2240/4518] 49% | Training loss: 0.6871468178661806
Epoch: 56 | Iteration number: [2250/4518] 49% | Training loss: 0.6871513425509135
Epoch: 56 | Iteration number: [2260/4518] 50% | Training loss: 0.6871498248218435
Epoch: 56 | Iteration number: [2270/4518] 50% | Training loss: 0.6871460011614576
Epoch: 56 | Iteration number: [2280/4518] 50% | Training loss: 0.6871440677004949
Epoch: 56 | Iteration number: [2290/4518] 50% | Training loss: 0.6871466493762737
Epoch: 56 | Iteration number: [2300/4518] 50% | Training loss: 0.6871391088029613
Epoch: 56 | Iteration number: [2310/4518] 51% | Training loss: 0.6871380320617131
Epoch: 56 | Iteration number: [2320/4518] 51% | Training loss: 0.6871370445294627
Epoch: 56 | Iteration number: [2330/4518] 51% | Training loss: 0.6871339122369055
Epoch: 56 | Iteration number: [2340/4518] 51% | Training loss: 0.6871342865320352
Epoch: 56 | Iteration number: [2350/4518] 52% | Training loss: 0.6871315678129805
Epoch: 56 | Iteration number: [2360/4518] 52% | Training loss: 0.6871295600371846
Epoch: 56 | Iteration number: [2370/4518] 52% | Training loss: 0.6871292118784748
Epoch: 56 | Iteration number: [2380/4518] 52% | Training loss: 0.6871306343739774
Epoch: 56 | Iteration number: [2390/4518] 52% | Training loss: 0.6871340387286502
Epoch: 56 | Iteration number: [2400/4518] 53% | Training loss: 0.6871299830079078
Epoch: 56 | Iteration number: [2410/4518] 53% | Training loss: 0.6871275037898068
Epoch: 56 | Iteration number: [2420/4518] 53% | Training loss: 0.6871263056747184
Epoch: 56 | Iteration number: [2430/4518] 53% | Training loss: 0.6871233095848021
Epoch: 56 | Iteration number: [2440/4518] 54% | Training loss: 0.6871255718538019
Epoch: 56 | Iteration number: [2450/4518] 54% | Training loss: 0.68712071452822
Epoch: 56 | Iteration number: [2460/4518] 54% | Training loss: 0.6871213898668445
Epoch: 56 | Iteration number: [2470/4518] 54% | Training loss: 0.6871177578503304
Epoch: 56 | Iteration number: [2480/4518] 54% | Training loss: 0.6871174641674564
Epoch: 56 | Iteration number: [2490/4518] 55% | Training loss: 0.6871145166307089
Epoch: 56 | Iteration number: [2500/4518] 55% | Training loss: 0.6871146866083145
Epoch: 56 | Iteration number: [2510/4518] 55% | Training loss: 0.6871127881139398
Epoch: 56 | Iteration number: [2520/4518] 55% | Training loss: 0.6871140589789738
Epoch: 56 | Iteration number: [2530/4518] 55% | Training loss: 0.6871108403790138
Epoch: 56 | Iteration number: [2540/4518] 56% | Training loss: 0.6871062257158475
Epoch: 56 | Iteration number: [2550/4518] 56% | Training loss: 0.687106593356413
Epoch: 56 | Iteration number: [2560/4518] 56% | Training loss: 0.6871015332639218
Epoch: 56 | Iteration number: [2570/4518] 56% | Training loss: 0.6871005325465814
Epoch: 56 | Iteration number: [2580/4518] 57% | Training loss: 0.6871017783880233
Epoch: 56 | Iteration number: [2590/4518] 57% | Training loss: 0.6870999653597136
Epoch: 56 | Iteration number: [2600/4518] 57% | Training loss: 0.6870975272930585
Epoch: 56 | Iteration number: [2610/4518] 57% | Training loss: 0.6870965607549953
Epoch: 56 | Iteration number: [2620/4518] 57% | Training loss: 0.687094263288811
Epoch: 56 | Iteration number: [2630/4518] 58% | Training loss: 0.6870877636929429
Epoch: 56 | Iteration number: [2640/4518] 58% | Training loss: 0.6870831928244143
Epoch: 56 | Iteration number: [2650/4518] 58% | Training loss: 0.6870801341308738
Epoch: 56 | Iteration number: [2660/4518] 58% | Training loss: 0.68708025149833
Epoch: 56 | Iteration number: [2670/4518] 59% | Training loss: 0.6870764415362355
Epoch: 56 | Iteration number: [2680/4518] 59% | Training loss: 0.6870720056233122
Epoch: 56 | Iteration number: [2690/4518] 59% | Training loss: 0.6870791391812293
Epoch: 56 | Iteration number: [2700/4518] 59% | Training loss: 0.6870791762184214
Epoch: 56 | Iteration number: [2710/4518] 59% | Training loss: 0.6870782035303292
Epoch: 56 | Iteration number: [2720/4518] 60% | Training loss: 0.6870756508892073
Epoch: 56 | Iteration number: [2730/4518] 60% | Training loss: 0.6870731405286126
Epoch: 56 | Iteration number: [2740/4518] 60% | Training loss: 0.6870734756445362
Epoch: 56 | Iteration number: [2750/4518] 60% | Training loss: 0.6870705180168152
Epoch: 56 | Iteration number: [2760/4518] 61% | Training loss: 0.6870660418401594
Epoch: 56 | Iteration number: [2770/4518] 61% | Training loss: 0.6870593854236259
Epoch: 56 | Iteration number: [2780/4518] 61% | Training loss: 0.6870568754004059
Epoch: 56 | Iteration number: [2790/4518] 61% | Training loss: 0.6870592958610973
Epoch: 56 | Iteration number: [2800/4518] 61% | Training loss: 0.6870586504467896
Epoch: 56 | Iteration number: [2810/4518] 62% | Training loss: 0.6870592208519525
Epoch: 56 | Iteration number: [2820/4518] 62% | Training loss: 0.6870627429468412
Epoch: 56 | Iteration number: [2830/4518] 62% | Training loss: 0.687064840663027
Epoch: 56 | Iteration number: [2840/4518] 62% | Training loss: 0.6870655747576498
Epoch: 56 | Iteration number: [2850/4518] 63% | Training loss: 0.6870651095373589
Epoch: 56 | Iteration number: [2860/4518] 63% | Training loss: 0.6870638246302838
Epoch: 56 | Iteration number: [2870/4518] 63% | Training loss: 0.6870643354043728
Epoch: 56 | Iteration number: [2880/4518] 63% | Training loss: 0.6870618805703189
Epoch: 56 | Iteration number: [2890/4518] 63% | Training loss: 0.6870652911572308
Epoch: 56 | Iteration number: [2900/4518] 64% | Training loss: 0.6870652677683995
Epoch: 56 | Iteration number: [2910/4518] 64% | Training loss: 0.6870652638350155
Epoch: 56 | Iteration number: [2920/4518] 64% | Training loss: 0.6870662650629266
Epoch: 56 | Iteration number: [2930/4518] 64% | Training loss: 0.6870630069600844
Epoch: 56 | Iteration number: [2940/4518] 65% | Training loss: 0.6870634551559176
Epoch: 56 | Iteration number: [2950/4518] 65% | Training loss: 0.6870603288230249
Epoch: 56 | Iteration number: [2960/4518] 65% | Training loss: 0.68705956633832
Epoch: 56 | Iteration number: [2970/4518] 65% | Training loss: 0.687060606640196
Epoch: 56 | Iteration number: [2980/4518] 65% | Training loss: 0.6870554875607459
Epoch: 56 | Iteration number: [2990/4518] 66% | Training loss: 0.6870510470308986
Epoch: 56 | Iteration number: [3000/4518] 66% | Training loss: 0.6870463691155115
Epoch: 56 | Iteration number: [3010/4518] 66% | Training loss: 0.687045218580189
Epoch: 56 | Iteration number: [3020/4518] 66% | Training loss: 0.6870426057585027
Epoch: 56 | Iteration number: [3030/4518] 67% | Training loss: 0.6870380788156302
Epoch: 56 | Iteration number: [3040/4518] 67% | Training loss: 0.687038951347533
Epoch: 56 | Iteration number: [3050/4518] 67% | Training loss: 0.687039055179377
Epoch: 56 | Iteration number: [3060/4518] 67% | Training loss: 0.6870389711233525
Epoch: 56 | Iteration number: [3070/4518] 67% | Training loss: 0.6870376097845332
Epoch: 56 | Iteration number: [3080/4518] 68% | Training loss: 0.6870379110628908
Epoch: 56 | Iteration number: [3090/4518] 68% | Training loss: 0.6870373451401115
Epoch: 56 | Iteration number: [3100/4518] 68% | Training loss: 0.6870349702335173
Epoch: 56 | Iteration number: [3110/4518] 68% | Training loss: 0.6870286141752814
Epoch: 56 | Iteration number: [3120/4518] 69% | Training loss: 0.687026460086688
Epoch: 56 | Iteration number: [3130/4518] 69% | Training loss: 0.6870215333307894
Epoch: 56 | Iteration number: [3140/4518] 69% | Training loss: 0.6870221768974498
Epoch: 56 | Iteration number: [3150/4518] 69% | Training loss: 0.6870157306156461
Epoch: 56 | Iteration number: [3160/4518] 69% | Training loss: 0.6870164888191826
Epoch: 56 | Iteration number: [3170/4518] 70% | Training loss: 0.6870182822931452
Epoch: 56 | Iteration number: [3180/4518] 70% | Training loss: 0.6870151581629267
Epoch: 56 | Iteration number: [3190/4518] 70% | Training loss: 0.687014560677041
Epoch: 56 | Iteration number: [3200/4518] 70% | Training loss: 0.6870139868371189
Epoch: 56 | Iteration number: [3210/4518] 71% | Training loss: 0.6870129414622286
Epoch: 56 | Iteration number: [3220/4518] 71% | Training loss: 0.6870128781714054
Epoch: 56 | Iteration number: [3230/4518] 71% | Training loss: 0.6870134584121291
Epoch: 56 | Iteration number: [3240/4518] 71% | Training loss: 0.6870120075933728
Epoch: 56 | Iteration number: [3250/4518] 71% | Training loss: 0.6870113471287947
Epoch: 56 | Iteration number: [3260/4518] 72% | Training loss: 0.6870080558434586
Epoch: 56 | Iteration number: [3270/4518] 72% | Training loss: 0.6870077743442781
Epoch: 56 | Iteration number: [3280/4518] 72% | Training loss: 0.6870075990514057
Epoch: 56 | Iteration number: [3290/4518] 72% | Training loss: 0.687005944165053
Epoch: 56 | Iteration number: [3300/4518] 73% | Training loss: 0.6870081499670491
Epoch: 56 | Iteration number: [3310/4518] 73% | Training loss: 0.6870079377266576
Epoch: 56 | Iteration number: [3320/4518] 73% | Training loss: 0.6870103269994977
Epoch: 56 | Iteration number: [3330/4518] 73% | Training loss: 0.6870099186181307
Epoch: 56 | Iteration number: [3340/4518] 73% | Training loss: 0.6870098544987376
Epoch: 56 | Iteration number: [3350/4518] 74% | Training loss: 0.6870128661127233
Epoch: 56 | Iteration number: [3360/4518] 74% | Training loss: 0.687015829483668
Epoch: 56 | Iteration number: [3370/4518] 74% | Training loss: 0.6870131588654278
Epoch: 56 | Iteration number: [3380/4518] 74% | Training loss: 0.687011874744878
Epoch: 56 | Iteration number: [3390/4518] 75% | Training loss: 0.6870059555610725
Epoch: 56 | Iteration number: [3400/4518] 75% | Training loss: 0.6870056549766484
Epoch: 56 | Iteration number: [3410/4518] 75% | Training loss: 0.6870047383294428
Epoch: 56 | Iteration number: [3420/4518] 75% | Training loss: 0.6870051031921343
Epoch: 56 | Iteration number: [3430/4518] 75% | Training loss: 0.6870018076271079
Epoch: 56 | Iteration number: [3440/4518] 76% | Training loss: 0.6870023153202478
Epoch: 56 | Iteration number: [3450/4518] 76% | Training loss: 0.687005884785583
Epoch: 56 | Iteration number: [3460/4518] 76% | Training loss: 0.6870048979114246
Epoch: 56 | Iteration number: [3470/4518] 76% | Training loss: 0.6870045459751437
Epoch: 56 | Iteration number: [3480/4518] 77% | Training loss: 0.6870054919144203
Epoch: 56 | Iteration number: [3490/4518] 77% | Training loss: 0.6870029145291336
Epoch: 56 | Iteration number: [3500/4518] 77% | Training loss: 0.6870034819160189
Epoch: 56 | Iteration number: [3510/4518] 77% | Training loss: 0.6870034782465367
Epoch: 56 | Iteration number: [3520/4518] 77% | Training loss: 0.6869996609504927
Epoch: 56 | Iteration number: [3530/4518] 78% | Training loss: 0.6869962017191706
Epoch: 56 | Iteration number: [3540/4518] 78% | Training loss: 0.6869924003626667
Epoch: 56 | Iteration number: [3550/4518] 78% | Training loss: 0.6869885788165347
Epoch: 56 | Iteration number: [3560/4518] 78% | Training loss: 0.6869894868872138
Epoch: 56 | Iteration number: [3570/4518] 79% | Training loss: 0.68698785617238
Epoch: 56 | Iteration number: [3580/4518] 79% | Training loss: 0.6869865786762877
Epoch: 56 | Iteration number: [3590/4518] 79% | Training loss: 0.6869871984783321
Epoch: 56 | Iteration number: [3600/4518] 79% | Training loss: 0.6869870012336307
Epoch: 56 | Iteration number: [3610/4518] 79% | Training loss: 0.6869843610105753
Epoch: 56 | Iteration number: [3620/4518] 80% | Training loss: 0.6869848883942345
Epoch: 56 | Iteration number: [3630/4518] 80% | Training loss: 0.6869820693143471
Epoch: 56 | Iteration number: [3640/4518] 80% | Training loss: 0.6869783882420142
Epoch: 56 | Iteration number: [3650/4518] 80% | Training loss: 0.6869730220102284
Epoch: 56 | Iteration number: [3660/4518] 81% | Training loss: 0.6869715164430806
Epoch: 56 | Iteration number: [3670/4518] 81% | Training loss: 0.6869682919426899
Epoch: 56 | Iteration number: [3680/4518] 81% | Training loss: 0.6869686093019403
Epoch: 56 | Iteration number: [3690/4518] 81% | Training loss: 0.6869686997033716
Epoch: 56 | Iteration number: [3700/4518] 81% | Training loss: 0.6869658936358787
Epoch: 56 | Iteration number: [3710/4518] 82% | Training loss: 0.686963071463243
Epoch: 56 | Iteration number: [3720/4518] 82% | Training loss: 0.6869633399510896
Epoch: 56 | Iteration number: [3730/4518] 82% | Training loss: 0.6869656414352857
Epoch: 56 | Iteration number: [3740/4518] 82% | Training loss: 0.6869677765962274
Epoch: 56 | Iteration number: [3750/4518] 83% | Training loss: 0.686969687350591
Epoch: 56 | Iteration number: [3760/4518] 83% | Training loss: 0.6869678826091138
Epoch: 56 | Iteration number: [3770/4518] 83% | Training loss: 0.6869697787559317
Epoch: 56 | Iteration number: [3780/4518] 83% | Training loss: 0.6869700985295432
Epoch: 56 | Iteration number: [3790/4518] 83% | Training loss: 0.6869677401941495
Epoch: 56 | Iteration number: [3800/4518] 84% | Training loss: 0.686964997366855
Epoch: 56 | Iteration number: [3810/4518] 84% | Training loss: 0.6869626504542634
Epoch: 56 | Iteration number: [3820/4518] 84% | Training loss: 0.6869625345730657
Epoch: 56 | Iteration number: [3830/4518] 84% | Training loss: 0.6869643182729617
Epoch: 56 | Iteration number: [3840/4518] 84% | Training loss: 0.6869641098969926
Epoch: 56 | Iteration number: [3850/4518] 85% | Training loss: 0.6869652006842873
Epoch: 56 | Iteration number: [3860/4518] 85% | Training loss: 0.6869657597702402
Epoch: 56 | Iteration number: [3870/4518] 85% | Training loss: 0.6869640896486682
Epoch: 56 | Iteration number: [3880/4518] 85% | Training loss: 0.6869600693282393
Epoch: 56 | Iteration number: [3890/4518] 86% | Training loss: 0.6869586684403506
Epoch: 56 | Iteration number: [3900/4518] 86% | Training loss: 0.6869588490174366
Epoch: 56 | Iteration number: [3910/4518] 86% | Training loss: 0.6869599710187644
Epoch: 56 | Iteration number: [3920/4518] 86% | Training loss: 0.6869597916852455
Epoch: 56 | Iteration number: [3930/4518] 86% | Training loss: 0.6869591527767763
Epoch: 56 | Iteration number: [3940/4518] 87% | Training loss: 0.6869606467975578
Epoch: 56 | Iteration number: [3950/4518] 87% | Training loss: 0.6869594755052011
Epoch: 56 | Iteration number: [3960/4518] 87% | Training loss: 0.6869600442774368
Epoch: 56 | Iteration number: [3970/4518] 87% | Training loss: 0.6869569385081755
Epoch: 56 | Iteration number: [3980/4518] 88% | Training loss: 0.6869581400150031
Epoch: 56 | Iteration number: [3990/4518] 88% | Training loss: 0.6869587517322454
Epoch: 56 | Iteration number: [4000/4518] 88% | Training loss: 0.6869579002410173
Epoch: 56 | Iteration number: [4010/4518] 88% | Training loss: 0.6869582200882738
Epoch: 56 | Iteration number: [4020/4518] 88% | Training loss: 0.6869579583258179
Epoch: 56 | Iteration number: [4030/4518] 89% | Training loss: 0.6869582405605033
Epoch: 56 | Iteration number: [4040/4518] 89% | Training loss: 0.6869597742905711
Epoch: 56 | Iteration number: [4050/4518] 89% | Training loss: 0.6869577565752429
Epoch: 56 | Iteration number: [4060/4518] 89% | Training loss: 0.6869584622347883
Epoch: 56 | Iteration number: [4070/4518] 90% | Training loss: 0.6869571648153685
Epoch: 56 | Iteration number: [4080/4518] 90% | Training loss: 0.6869570092535486
Epoch: 56 | Iteration number: [4090/4518] 90% | Training loss: 0.6869591393942938
Epoch: 56 | Iteration number: [4100/4518] 90% | Training loss: 0.6869601089489169
Epoch: 56 | Iteration number: [4110/4518] 90% | Training loss: 0.6869566407226878
Epoch: 56 | Iteration number: [4120/4518] 91% | Training loss: 0.6869566618672852
Epoch: 56 | Iteration number: [4130/4518] 91% | Training loss: 0.6869578882510667
Epoch: 56 | Iteration number: [4140/4518] 91% | Training loss: 0.6869560407699594
Epoch: 56 | Iteration number: [4150/4518] 91% | Training loss: 0.6869566229165318
Epoch: 56 | Iteration number: [4160/4518] 92% | Training loss: 0.6869586434501868
Epoch: 56 | Iteration number: [4170/4518] 92% | Training loss: 0.6869571368900135
Epoch: 56 | Iteration number: [4180/4518] 92% | Training loss: 0.6869598427600268
Epoch: 56 | Iteration number: [4190/4518] 92% | Training loss: 0.6869585975400019
Epoch: 56 | Iteration number: [4200/4518] 92% | Training loss: 0.6869577517679759
Epoch: 56 | Iteration number: [4210/4518] 93% | Training loss: 0.6869572251681194
Epoch: 56 | Iteration number: [4220/4518] 93% | Training loss: 0.6869579744282492
Epoch: 56 | Iteration number: [4230/4518] 93% | Training loss: 0.6869545373933535
Epoch: 56 | Iteration number: [4240/4518] 93% | Training loss: 0.6869553882980122
Epoch: 56 | Iteration number: [4250/4518] 94% | Training loss: 0.6869534912109375
Epoch: 56 | Iteration number: [4260/4518] 94% | Training loss: 0.6869558076483543
Epoch: 56 | Iteration number: [4270/4518] 94% | Training loss: 0.6869558093838167
Epoch: 56 | Iteration number: [4280/4518] 94% | Training loss: 0.6869534156868391
Epoch: 56 | Iteration number: [4290/4518] 94% | Training loss: 0.6869532039393356
Epoch: 56 | Iteration number: [4300/4518] 95% | Training loss: 0.6869552151131075
Epoch: 56 | Iteration number: [4310/4518] 95% | Training loss: 0.6869554010178816
Epoch: 56 | Iteration number: [4320/4518] 95% | Training loss: 0.6869556818295408
Epoch: 56 | Iteration number: [4330/4518] 95% | Training loss: 0.6869516088285292
Epoch: 56 | Iteration number: [4340/4518] 96% | Training loss: 0.6869502666771137
Epoch: 56 | Iteration number: [4350/4518] 96% | Training loss: 0.6869480514389344
Epoch: 56 | Iteration number: [4360/4518] 96% | Training loss: 0.6869469645373318
Epoch: 56 | Iteration number: [4370/4518] 96% | Training loss: 0.6869467066545508
Epoch: 56 | Iteration number: [4380/4518] 96% | Training loss: 0.6869505626153728
Epoch: 56 | Iteration number: [4390/4518] 97% | Training loss: 0.6869504401922769
Epoch: 56 | Iteration number: [4400/4518] 97% | Training loss: 0.6869495548849756
Epoch: 56 | Iteration number: [4410/4518] 97% | Training loss: 0.6869481208102773
Epoch: 56 | Iteration number: [4420/4518] 97% | Training loss: 0.6869477335953604
Epoch: 56 | Iteration number: [4430/4518] 98% | Training loss: 0.6869507366459203
Epoch: 56 | Iteration number: [4440/4518] 98% | Training loss: 0.6869523739895305
Epoch: 56 | Iteration number: [4450/4518] 98% | Training loss: 0.6869534722606787
Epoch: 56 | Iteration number: [4460/4518] 98% | Training loss: 0.6869529011671853
Epoch: 56 | Iteration number: [4470/4518] 98% | Training loss: 0.6869514089436073
Epoch: 56 | Iteration number: [4480/4518] 99% | Training loss: 0.6869545835735542
Epoch: 56 | Iteration number: [4490/4518] 99% | Training loss: 0.6869517380782384
Epoch: 56 | Iteration number: [4500/4518] 99% | Training loss: 0.6869515280061298
Epoch: 56 | Iteration number: [4510/4518] 99% | Training loss: 0.6869555888709895

 End of epoch: 56 | Train Loss: 0.6868038942931024 | Training Time: 643 

 End of epoch: 56 | Eval Loss: 0.6900644241547098 | Evaluating Time: 17 
Epoch: 57 | Iteration number: [10/4518] 0% | Training loss: 0.7541435658931732
Epoch: 57 | Iteration number: [20/4518] 0% | Training loss: 0.7203304827213287
Epoch: 57 | Iteration number: [30/4518] 0% | Training loss: 0.7087343613306681
Epoch: 57 | Iteration number: [40/4518] 0% | Training loss: 0.7030665025115013
Epoch: 57 | Iteration number: [50/4518] 1% | Training loss: 0.6996159398555756
Epoch: 57 | Iteration number: [60/4518] 1% | Training loss: 0.6975027283032735
Epoch: 57 | Iteration number: [70/4518] 1% | Training loss: 0.6961626035826547
Epoch: 57 | Iteration number: [80/4518] 1% | Training loss: 0.6950182311236859
Epoch: 57 | Iteration number: [90/4518] 1% | Training loss: 0.6941473027070363
Epoch: 57 | Iteration number: [100/4518] 2% | Training loss: 0.6934503400325776
Epoch: 57 | Iteration number: [110/4518] 2% | Training loss: 0.6927952462976629
Epoch: 57 | Iteration number: [120/4518] 2% | Training loss: 0.6922613173723221
Epoch: 57 | Iteration number: [130/4518] 2% | Training loss: 0.6917980189506824
Epoch: 57 | Iteration number: [140/4518] 3% | Training loss: 0.6914667929921832
Epoch: 57 | Iteration number: [150/4518] 3% | Training loss: 0.6911537416776021
Epoch: 57 | Iteration number: [160/4518] 3% | Training loss: 0.6909828938543796
Epoch: 57 | Iteration number: [170/4518] 3% | Training loss: 0.6907197128323947
Epoch: 57 | Iteration number: [180/4518] 3% | Training loss: 0.6904826154311497
Epoch: 57 | Iteration number: [190/4518] 4% | Training loss: 0.6902712351397464
Epoch: 57 | Iteration number: [200/4518] 4% | Training loss: 0.6900732883810997
Epoch: 57 | Iteration number: [210/4518] 4% | Training loss: 0.6899188856283823
Epoch: 57 | Iteration number: [220/4518] 4% | Training loss: 0.689727892387997
Epoch: 57 | Iteration number: [230/4518] 5% | Training loss: 0.6896002341871676
Epoch: 57 | Iteration number: [240/4518] 5% | Training loss: 0.6894405456880729
Epoch: 57 | Iteration number: [250/4518] 5% | Training loss: 0.6893278374671936
Epoch: 57 | Iteration number: [260/4518] 5% | Training loss: 0.6892147958278656
Epoch: 57 | Iteration number: [270/4518] 5% | Training loss: 0.6891709217318782
Epoch: 57 | Iteration number: [280/4518] 6% | Training loss: 0.6890345149806567
Epoch: 57 | Iteration number: [290/4518] 6% | Training loss: 0.6889837906278413
Epoch: 57 | Iteration number: [300/4518] 6% | Training loss: 0.6889397394657135
Epoch: 57 | Iteration number: [310/4518] 6% | Training loss: 0.6888790145997078
Epoch: 57 | Iteration number: [320/4518] 7% | Training loss: 0.688819762505591
Epoch: 57 | Iteration number: [330/4518] 7% | Training loss: 0.688751062299266
Epoch: 57 | Iteration number: [340/4518] 7% | Training loss: 0.6886402031954597
Epoch: 57 | Iteration number: [350/4518] 7% | Training loss: 0.6885542607307434
Epoch: 57 | Iteration number: [360/4518] 7% | Training loss: 0.6885043695569039
Epoch: 57 | Iteration number: [370/4518] 8% | Training loss: 0.6884715953388729
Epoch: 57 | Iteration number: [380/4518] 8% | Training loss: 0.6883750007340782
Epoch: 57 | Iteration number: [390/4518] 8% | Training loss: 0.6883263083604666
Epoch: 57 | Iteration number: [400/4518] 8% | Training loss: 0.6882986398041249
Epoch: 57 | Iteration number: [410/4518] 9% | Training loss: 0.6882602863195466
Epoch: 57 | Iteration number: [420/4518] 9% | Training loss: 0.6882210978439876
Epoch: 57 | Iteration number: [430/4518] 9% | Training loss: 0.6882055035857267
Epoch: 57 | Iteration number: [440/4518] 9% | Training loss: 0.6881804219701073
Epoch: 57 | Iteration number: [450/4518] 9% | Training loss: 0.6881572351190779
Epoch: 57 | Iteration number: [460/4518] 10% | Training loss: 0.6881455747977547
Epoch: 57 | Iteration number: [470/4518] 10% | Training loss: 0.688116082485686
Epoch: 57 | Iteration number: [480/4518] 10% | Training loss: 0.6880824616799752
Epoch: 57 | Iteration number: [490/4518] 10% | Training loss: 0.6880780968130852
Epoch: 57 | Iteration number: [500/4518] 11% | Training loss: 0.6880662264823914
Epoch: 57 | Iteration number: [510/4518] 11% | Training loss: 0.6880326534018797
Epoch: 57 | Iteration number: [520/4518] 11% | Training loss: 0.6880009536559765
Epoch: 57 | Iteration number: [530/4518] 11% | Training loss: 0.6879811285801654
Epoch: 57 | Iteration number: [540/4518] 11% | Training loss: 0.6879940578231105
Epoch: 57 | Iteration number: [550/4518] 12% | Training loss: 0.6879973648894917
Epoch: 57 | Iteration number: [560/4518] 12% | Training loss: 0.6879788944763797
Epoch: 57 | Iteration number: [570/4518] 12% | Training loss: 0.6879581416908064
Epoch: 57 | Iteration number: [580/4518] 12% | Training loss: 0.6879410217548239
Epoch: 57 | Iteration number: [590/4518] 13% | Training loss: 0.6879085287199183
Epoch: 57 | Iteration number: [600/4518] 13% | Training loss: 0.6878713731964429
Epoch: 57 | Iteration number: [610/4518] 13% | Training loss: 0.6878667378034748
Epoch: 57 | Iteration number: [620/4518] 13% | Training loss: 0.6878467954935567
Epoch: 57 | Iteration number: [630/4518] 13% | Training loss: 0.6878393670869252
Epoch: 57 | Iteration number: [640/4518] 14% | Training loss: 0.6878258652985096
Epoch: 57 | Iteration number: [650/4518] 14% | Training loss: 0.6877925499585958
Epoch: 57 | Iteration number: [660/4518] 14% | Training loss: 0.6877791758739586
Epoch: 57 | Iteration number: [670/4518] 14% | Training loss: 0.6877636007408597
Epoch: 57 | Iteration number: [680/4518] 15% | Training loss: 0.6877528138020459
Epoch: 57 | Iteration number: [690/4518] 15% | Training loss: 0.6877382475396862
Epoch: 57 | Iteration number: [700/4518] 15% | Training loss: 0.6877225681713649
Epoch: 57 | Iteration number: [710/4518] 15% | Training loss: 0.6877263004511175
Epoch: 57 | Iteration number: [720/4518] 15% | Training loss: 0.687715551091565
Epoch: 57 | Iteration number: [730/4518] 16% | Training loss: 0.6876872977981828
Epoch: 57 | Iteration number: [740/4518] 16% | Training loss: 0.6876811659013903
Epoch: 57 | Iteration number: [750/4518] 16% | Training loss: 0.6876830359299978
Epoch: 57 | Iteration number: [760/4518] 16% | Training loss: 0.6876784436796841
Epoch: 57 | Iteration number: [770/4518] 17% | Training loss: 0.6876470133855745
Epoch: 57 | Iteration number: [780/4518] 17% | Training loss: 0.6876402993232776
Epoch: 57 | Iteration number: [790/4518] 17% | Training loss: 0.6876109366175495
Epoch: 57 | Iteration number: [800/4518] 17% | Training loss: 0.6876002152264118
Epoch: 57 | Iteration number: [810/4518] 17% | Training loss: 0.687600917507101
Epoch: 57 | Iteration number: [820/4518] 18% | Training loss: 0.6876038600758808
Epoch: 57 | Iteration number: [830/4518] 18% | Training loss: 0.6875868141651154
Epoch: 57 | Iteration number: [840/4518] 18% | Training loss: 0.6875821481148402
Epoch: 57 | Iteration number: [850/4518] 18% | Training loss: 0.6875648832321167
Epoch: 57 | Iteration number: [860/4518] 19% | Training loss: 0.687558628653371
Epoch: 57 | Iteration number: [870/4518] 19% | Training loss: 0.6875557780950919
Epoch: 57 | Iteration number: [880/4518] 19% | Training loss: 0.6875445908443494
Epoch: 57 | Iteration number: [890/4518] 19% | Training loss: 0.6875312793790624
Epoch: 57 | Iteration number: [900/4518] 19% | Training loss: 0.6875166810221143
Epoch: 57 | Iteration number: [910/4518] 20% | Training loss: 0.6875063399037162
Epoch: 57 | Iteration number: [920/4518] 20% | Training loss: 0.687483261136905
Epoch: 57 | Iteration number: [930/4518] 20% | Training loss: 0.6874713203599376
Epoch: 57 | Iteration number: [940/4518] 20% | Training loss: 0.687473675291589
Epoch: 57 | Iteration number: [950/4518] 21% | Training loss: 0.6874674298261342
Epoch: 57 | Iteration number: [960/4518] 21% | Training loss: 0.6874572162205974
Epoch: 57 | Iteration number: [970/4518] 21% | Training loss: 0.6874531516094797
Epoch: 57 | Iteration number: [980/4518] 21% | Training loss: 0.6874628136352617
Epoch: 57 | Iteration number: [990/4518] 21% | Training loss: 0.687449981768926
Epoch: 57 | Iteration number: [1000/4518] 22% | Training loss: 0.6874380602240563
Epoch: 57 | Iteration number: [1010/4518] 22% | Training loss: 0.687429134562464
Epoch: 57 | Iteration number: [1020/4518] 22% | Training loss: 0.687429229126257
Epoch: 57 | Iteration number: [1030/4518] 22% | Training loss: 0.6874369092936655
Epoch: 57 | Iteration number: [1040/4518] 23% | Training loss: 0.6874324387082686
Epoch: 57 | Iteration number: [1050/4518] 23% | Training loss: 0.6874265400000981
Epoch: 57 | Iteration number: [1060/4518] 23% | Training loss: 0.6874168592241575
Epoch: 57 | Iteration number: [1070/4518] 23% | Training loss: 0.6874097582335784
Epoch: 57 | Iteration number: [1080/4518] 23% | Training loss: 0.6873963375334387
Epoch: 57 | Iteration number: [1090/4518] 24% | Training loss: 0.6873812076148637
Epoch: 57 | Iteration number: [1100/4518] 24% | Training loss: 0.6873770211501555
Epoch: 57 | Iteration number: [1110/4518] 24% | Training loss: 0.6873710059904837
Epoch: 57 | Iteration number: [1120/4518] 24% | Training loss: 0.6873713345932109
Epoch: 57 | Iteration number: [1130/4518] 25% | Training loss: 0.6873719558779118
Epoch: 57 | Iteration number: [1140/4518] 25% | Training loss: 0.6873557838954424
Epoch: 57 | Iteration number: [1150/4518] 25% | Training loss: 0.6873475715388423
Epoch: 57 | Iteration number: [1160/4518] 25% | Training loss: 0.6873400982083946
Epoch: 57 | Iteration number: [1170/4518] 25% | Training loss: 0.6873415434971833
Epoch: 57 | Iteration number: [1180/4518] 26% | Training loss: 0.687336947453224
Epoch: 57 | Iteration number: [1190/4518] 26% | Training loss: 0.6873297500009297
Epoch: 57 | Iteration number: [1200/4518] 26% | Training loss: 0.6873213086028894
Epoch: 57 | Iteration number: [1210/4518] 26% | Training loss: 0.6873251000711741
Epoch: 57 | Iteration number: [1220/4518] 27% | Training loss: 0.6873161189868802
Epoch: 57 | Iteration number: [1230/4518] 27% | Training loss: 0.6873160002192831
Epoch: 57 | Iteration number: [1240/4518] 27% | Training loss: 0.6873070316449288
Epoch: 57 | Iteration number: [1250/4518] 27% | Training loss: 0.6873088018894196
Epoch: 57 | Iteration number: [1260/4518] 27% | Training loss: 0.6873027210197752
Epoch: 57 | Iteration number: [1270/4518] 28% | Training loss: 0.6873097987156215
Epoch: 57 | Iteration number: [1280/4518] 28% | Training loss: 0.6873143107164651
Epoch: 57 | Iteration number: [1290/4518] 28% | Training loss: 0.687313489165417
Epoch: 57 | Iteration number: [1300/4518] 28% | Training loss: 0.6873006747777646
Epoch: 57 | Iteration number: [1310/4518] 28% | Training loss: 0.6872868383203754
Epoch: 57 | Iteration number: [1320/4518] 29% | Training loss: 0.6872801460551493
Epoch: 57 | Iteration number: [1330/4518] 29% | Training loss: 0.6872721672058105
Epoch: 57 | Iteration number: [1340/4518] 29% | Training loss: 0.6872623159814236
Epoch: 57 | Iteration number: [1350/4518] 29% | Training loss: 0.6872536463649185
Epoch: 57 | Iteration number: [1360/4518] 30% | Training loss: 0.6872543688206112
Epoch: 57 | Iteration number: [1370/4518] 30% | Training loss: 0.6872489008155183
Epoch: 57 | Iteration number: [1380/4518] 30% | Training loss: 0.6872544995684554
Epoch: 57 | Iteration number: [1390/4518] 30% | Training loss: 0.687253872396277
Epoch: 57 | Iteration number: [1400/4518] 30% | Training loss: 0.6872554680705071
Epoch: 57 | Iteration number: [1410/4518] 31% | Training loss: 0.6872511586398943
Epoch: 57 | Iteration number: [1420/4518] 31% | Training loss: 0.687250612613181
Epoch: 57 | Iteration number: [1430/4518] 31% | Training loss: 0.6872568676104912
Epoch: 57 | Iteration number: [1440/4518] 31% | Training loss: 0.687248368271523
Epoch: 57 | Iteration number: [1450/4518] 32% | Training loss: 0.6872482295282956
Epoch: 57 | Iteration number: [1460/4518] 32% | Training loss: 0.687244732208448
Epoch: 57 | Iteration number: [1470/4518] 32% | Training loss: 0.6872452728602351
Epoch: 57 | Iteration number: [1480/4518] 32% | Training loss: 0.6872369314367707
Epoch: 57 | Iteration number: [1490/4518] 32% | Training loss: 0.6872304753569148
Epoch: 57 | Iteration number: [1500/4518] 33% | Training loss: 0.6872194780906041
Epoch: 57 | Iteration number: [1510/4518] 33% | Training loss: 0.687219291293858
Epoch: 57 | Iteration number: [1520/4518] 33% | Training loss: 0.6872233570014176
Epoch: 57 | Iteration number: [1530/4518] 33% | Training loss: 0.6872156346155927
Epoch: 57 | Iteration number: [1540/4518] 34% | Training loss: 0.6872097361397433
Epoch: 57 | Iteration number: [1550/4518] 34% | Training loss: 0.6872074385996788
Epoch: 57 | Iteration number: [1560/4518] 34% | Training loss: 0.6872101238522774
Epoch: 57 | Iteration number: [1570/4518] 34% | Training loss: 0.6871996070928634
Epoch: 57 | Iteration number: [1580/4518] 34% | Training loss: 0.6871940243847763
Epoch: 57 | Iteration number: [1590/4518] 35% | Training loss: 0.6871946449924565
Epoch: 57 | Iteration number: [1600/4518] 35% | Training loss: 0.6871944848075509
Epoch: 57 | Iteration number: [1610/4518] 35% | Training loss: 0.6871936453425366
Epoch: 57 | Iteration number: [1620/4518] 35% | Training loss: 0.6871895986206737
Epoch: 57 | Iteration number: [1630/4518] 36% | Training loss: 0.6871805240771521
Epoch: 57 | Iteration number: [1640/4518] 36% | Training loss: 0.6871754142569333
Epoch: 57 | Iteration number: [1650/4518] 36% | Training loss: 0.6871753711050207
Epoch: 57 | Iteration number: [1660/4518] 36% | Training loss: 0.6871780338416617
Epoch: 57 | Iteration number: [1670/4518] 36% | Training loss: 0.6871720577785355
Epoch: 57 | Iteration number: [1680/4518] 37% | Training loss: 0.6871616836105074
Epoch: 57 | Iteration number: [1690/4518] 37% | Training loss: 0.6871679671064637
Epoch: 57 | Iteration number: [1700/4518] 37% | Training loss: 0.68716012032593
Epoch: 57 | Iteration number: [1710/4518] 37% | Training loss: 0.687163409782432
Epoch: 57 | Iteration number: [1720/4518] 38% | Training loss: 0.687165152194888
Epoch: 57 | Iteration number: [1730/4518] 38% | Training loss: 0.6871594274319666
Epoch: 57 | Iteration number: [1740/4518] 38% | Training loss: 0.6871527314871207
Epoch: 57 | Iteration number: [1750/4518] 38% | Training loss: 0.6871504759447915
Epoch: 57 | Iteration number: [1760/4518] 38% | Training loss: 0.6871535940942439
Epoch: 57 | Iteration number: [1770/4518] 39% | Training loss: 0.6871484898577975
Epoch: 57 | Iteration number: [1780/4518] 39% | Training loss: 0.6871459559108434
Epoch: 57 | Iteration number: [1790/4518] 39% | Training loss: 0.6871357648399289
Epoch: 57 | Iteration number: [1800/4518] 39% | Training loss: 0.687136146624883
Epoch: 57 | Iteration number: [1810/4518] 40% | Training loss: 0.6871368267588852
Epoch: 57 | Iteration number: [1820/4518] 40% | Training loss: 0.6871321458737929
Epoch: 57 | Iteration number: [1830/4518] 40% | Training loss: 0.6871364208844191
Epoch: 57 | Iteration number: [1840/4518] 40% | Training loss: 0.6871341655111831
Epoch: 57 | Iteration number: [1850/4518] 40% | Training loss: 0.6871256124006735
Epoch: 57 | Iteration number: [1860/4518] 41% | Training loss: 0.6871185416816383
Epoch: 57 | Iteration number: [1870/4518] 41% | Training loss: 0.6871189177355027
Epoch: 57 | Iteration number: [1880/4518] 41% | Training loss: 0.6871216838981243
Epoch: 57 | Iteration number: [1890/4518] 41% | Training loss: 0.6871225017719168
Epoch: 57 | Iteration number: [1900/4518] 42% | Training loss: 0.6871169268143804
Epoch: 57 | Iteration number: [1910/4518] 42% | Training loss: 0.68711877318577
Epoch: 57 | Iteration number: [1920/4518] 42% | Training loss: 0.6871147301668922
Epoch: 57 | Iteration number: [1930/4518] 42% | Training loss: 0.6871118920454707
Epoch: 57 | Iteration number: [1940/4518] 42% | Training loss: 0.6871129350563915
Epoch: 57 | Iteration number: [1950/4518] 43% | Training loss: 0.6871133033740214
Epoch: 57 | Iteration number: [1960/4518] 43% | Training loss: 0.6871124244162015
Epoch: 57 | Iteration number: [1970/4518] 43% | Training loss: 0.6871085801100368
Epoch: 57 | Iteration number: [1980/4518] 43% | Training loss: 0.6871112035380469
Epoch: 57 | Iteration number: [1990/4518] 44% | Training loss: 0.6871130327183996
Epoch: 57 | Iteration number: [2000/4518] 44% | Training loss: 0.6871107721030713
Epoch: 57 | Iteration number: [2010/4518] 44% | Training loss: 0.6871086998068872
Epoch: 57 | Iteration number: [2020/4518] 44% | Training loss: 0.6871074611597722
Epoch: 57 | Iteration number: [2030/4518] 44% | Training loss: 0.6871095004927349
Epoch: 57 | Iteration number: [2040/4518] 45% | Training loss: 0.687104200937
Epoch: 57 | Iteration number: [2050/4518] 45% | Training loss: 0.6871082334402131
Epoch: 57 | Iteration number: [2060/4518] 45% | Training loss: 0.6871105075750537
Epoch: 57 | Iteration number: [2070/4518] 45% | Training loss: 0.6871091124804124
Epoch: 57 | Iteration number: [2080/4518] 46% | Training loss: 0.6871096899876228
Epoch: 57 | Iteration number: [2090/4518] 46% | Training loss: 0.6871007454737522
Epoch: 57 | Iteration number: [2100/4518] 46% | Training loss: 0.6871044834454855
Epoch: 57 | Iteration number: [2110/4518] 46% | Training loss: 0.6870998287087933
Epoch: 57 | Iteration number: [2120/4518] 46% | Training loss: 0.6870956860342116
Epoch: 57 | Iteration number: [2130/4518] 47% | Training loss: 0.6870889413524681
Epoch: 57 | Iteration number: [2140/4518] 47% | Training loss: 0.6870847157785825
Epoch: 57 | Iteration number: [2150/4518] 47% | Training loss: 0.6870835497767426
Epoch: 57 | Iteration number: [2160/4518] 47% | Training loss: 0.6870851837098598
Epoch: 57 | Iteration number: [2170/4518] 48% | Training loss: 0.6870823233083646
Epoch: 57 | Iteration number: [2180/4518] 48% | Training loss: 0.6870793771853141
Epoch: 57 | Iteration number: [2190/4518] 48% | Training loss: 0.6870786268689316
Epoch: 57 | Iteration number: [2200/4518] 48% | Training loss: 0.6870775511860847
Epoch: 57 | Iteration number: [2210/4518] 48% | Training loss: 0.6870832147911123
Epoch: 57 | Iteration number: [2220/4518] 49% | Training loss: 0.6870836611266609
Epoch: 57 | Iteration number: [2230/4518] 49% | Training loss: 0.6870836169195816
Epoch: 57 | Iteration number: [2240/4518] 49% | Training loss: 0.6870788659368242
Epoch: 57 | Iteration number: [2250/4518] 49% | Training loss: 0.6870774083137512
Epoch: 57 | Iteration number: [2260/4518] 50% | Training loss: 0.6870777573205729
Epoch: 57 | Iteration number: [2270/4518] 50% | Training loss: 0.6870775472487647
Epoch: 57 | Iteration number: [2280/4518] 50% | Training loss: 0.6870763762739667
Epoch: 57 | Iteration number: [2290/4518] 50% | Training loss: 0.687077839848256
Epoch: 57 | Iteration number: [2300/4518] 50% | Training loss: 0.6870828377423079
Epoch: 57 | Iteration number: [2310/4518] 51% | Training loss: 0.6870759339559646
Epoch: 57 | Iteration number: [2320/4518] 51% | Training loss: 0.6870773397386074
Epoch: 57 | Iteration number: [2330/4518] 51% | Training loss: 0.6870758339826641
Epoch: 57 | Iteration number: [2340/4518] 51% | Training loss: 0.6870735354912587
Epoch: 57 | Iteration number: [2350/4518] 52% | Training loss: 0.6870737860557881
Epoch: 57 | Iteration number: [2360/4518] 52% | Training loss: 0.6870720528445001
Epoch: 57 | Iteration number: [2370/4518] 52% | Training loss: 0.6870706650275218
Epoch: 57 | Iteration number: [2380/4518] 52% | Training loss: 0.6870691712163076
Epoch: 57 | Iteration number: [2390/4518] 52% | Training loss: 0.6870736099686084
Epoch: 57 | Iteration number: [2400/4518] 53% | Training loss: 0.6870724097887675
Epoch: 57 | Iteration number: [2410/4518] 53% | Training loss: 0.687071693388753
Epoch: 57 | Iteration number: [2420/4518] 53% | Training loss: 0.6870755738463283
Epoch: 57 | Iteration number: [2430/4518] 53% | Training loss: 0.6870773414525475
Epoch: 57 | Iteration number: [2440/4518] 54% | Training loss: 0.6870757418089226
Epoch: 57 | Iteration number: [2450/4518] 54% | Training loss: 0.6870754557969618
Epoch: 57 | Iteration number: [2460/4518] 54% | Training loss: 0.687071738398172
Epoch: 57 | Iteration number: [2470/4518] 54% | Training loss: 0.6870693799455156
Epoch: 57 | Iteration number: [2480/4518] 54% | Training loss: 0.687073331470451
Epoch: 57 | Iteration number: [2490/4518] 55% | Training loss: 0.6870708718357316
Epoch: 57 | Iteration number: [2500/4518] 55% | Training loss: 0.6870707185983658
Epoch: 57 | Iteration number: [2510/4518] 55% | Training loss: 0.687072013668805
Epoch: 57 | Iteration number: [2520/4518] 55% | Training loss: 0.6870680657171068
Epoch: 57 | Iteration number: [2530/4518] 55% | Training loss: 0.6870676712320727
Epoch: 57 | Iteration number: [2540/4518] 56% | Training loss: 0.6870705296439449
Epoch: 57 | Iteration number: [2550/4518] 56% | Training loss: 0.6870723091387281
Epoch: 57 | Iteration number: [2560/4518] 56% | Training loss: 0.6870710424613208
Epoch: 57 | Iteration number: [2570/4518] 56% | Training loss: 0.6870672487331272
Epoch: 57 | Iteration number: [2580/4518] 57% | Training loss: 0.6870657121719316
Epoch: 57 | Iteration number: [2590/4518] 57% | Training loss: 0.6870671531178316
Epoch: 57 | Iteration number: [2600/4518] 57% | Training loss: 0.6870680174231529
Epoch: 57 | Iteration number: [2610/4518] 57% | Training loss: 0.6870683063949204
Epoch: 57 | Iteration number: [2620/4518] 57% | Training loss: 0.6870618250078827
Epoch: 57 | Iteration number: [2630/4518] 58% | Training loss: 0.6870588634403939
Epoch: 57 | Iteration number: [2640/4518] 58% | Training loss: 0.6870565193620595
Epoch: 57 | Iteration number: [2650/4518] 58% | Training loss: 0.6870510020346011
Epoch: 57 | Iteration number: [2660/4518] 58% | Training loss: 0.6870451620646886
Epoch: 57 | Iteration number: [2670/4518] 59% | Training loss: 0.687046392535449
Epoch: 57 | Iteration number: [2680/4518] 59% | Training loss: 0.6870473458695767
Epoch: 57 | Iteration number: [2690/4518] 59% | Training loss: 0.6870448096534133
Epoch: 57 | Iteration number: [2700/4518] 59% | Training loss: 0.6870488690005409
Epoch: 57 | Iteration number: [2710/4518] 59% | Training loss: 0.6870489470853137
Epoch: 57 | Iteration number: [2720/4518] 60% | Training loss: 0.687046304673833
Epoch: 57 | Iteration number: [2730/4518] 60% | Training loss: 0.6870437682548285
Epoch: 57 | Iteration number: [2740/4518] 60% | Training loss: 0.6870431763629844
Epoch: 57 | Iteration number: [2750/4518] 60% | Training loss: 0.68703880685026
Epoch: 57 | Iteration number: [2760/4518] 61% | Training loss: 0.6870382601584213
Epoch: 57 | Iteration number: [2770/4518] 61% | Training loss: 0.6870348463850331
Epoch: 57 | Iteration number: [2780/4518] 61% | Training loss: 0.6870345856431577
Epoch: 57 | Iteration number: [2790/4518] 61% | Training loss: 0.6870357085727021
Epoch: 57 | Iteration number: [2800/4518] 61% | Training loss: 0.6870374165475368
Epoch: 57 | Iteration number: [2810/4518] 62% | Training loss: 0.6870321048748451
Epoch: 57 | Iteration number: [2820/4518] 62% | Training loss: 0.6870295130614693
Epoch: 57 | Iteration number: [2830/4518] 62% | Training loss: 0.6870294997422518
Epoch: 57 | Iteration number: [2840/4518] 62% | Training loss: 0.6870277429970217
Epoch: 57 | Iteration number: [2850/4518] 63% | Training loss: 0.6870279138339194
Epoch: 57 | Iteration number: [2860/4518] 63% | Training loss: 0.6870253997666019
Epoch: 57 | Iteration number: [2870/4518] 63% | Training loss: 0.6870251357555389
Epoch: 57 | Iteration number: [2880/4518] 63% | Training loss: 0.6870227190976341
Epoch: 57 | Iteration number: [2890/4518] 63% | Training loss: 0.6870214531990896
Epoch: 57 | Iteration number: [2900/4518] 64% | Training loss: 0.6870184371389192
Epoch: 57 | Iteration number: [2910/4518] 64% | Training loss: 0.6870158871629394
Epoch: 57 | Iteration number: [2920/4518] 64% | Training loss: 0.6870150711846679
Epoch: 57 | Iteration number: [2930/4518] 64% | Training loss: 0.6870154405413227
Epoch: 57 | Iteration number: [2940/4518] 65% | Training loss: 0.6870172775318834
Epoch: 57 | Iteration number: [2950/4518] 65% | Training loss: 0.6870149073964459
Epoch: 57 | Iteration number: [2960/4518] 65% | Training loss: 0.6870139547699207
Epoch: 57 | Iteration number: [2970/4518] 65% | Training loss: 0.6870150821578221
Epoch: 57 | Iteration number: [2980/4518] 65% | Training loss: 0.6870137659295293
Epoch: 57 | Iteration number: [2990/4518] 66% | Training loss: 0.6870132486955777
Epoch: 57 | Iteration number: [3000/4518] 66% | Training loss: 0.68701280717055
Epoch: 57 | Iteration number: [3010/4518] 66% | Training loss: 0.6870151849482147
Epoch: 57 | Iteration number: [3020/4518] 66% | Training loss: 0.6870142668485641
Epoch: 57 | Iteration number: [3030/4518] 67% | Training loss: 0.6870118816300194
Epoch: 57 | Iteration number: [3040/4518] 67% | Training loss: 0.6870099885879378
Epoch: 57 | Iteration number: [3050/4518] 67% | Training loss: 0.6870089066810295
Epoch: 57 | Iteration number: [3060/4518] 67% | Training loss: 0.6870046972449309
Epoch: 57 | Iteration number: [3070/4518] 67% | Training loss: 0.6870080158065895
Epoch: 57 | Iteration number: [3080/4518] 68% | Training loss: 0.687009287964214
Epoch: 57 | Iteration number: [3090/4518] 68% | Training loss: 0.6870070512819445
Epoch: 57 | Iteration number: [3100/4518] 68% | Training loss: 0.6870068738921996
Epoch: 57 | Iteration number: [3110/4518] 68% | Training loss: 0.6870046824121016
Epoch: 57 | Iteration number: [3120/4518] 69% | Training loss: 0.6870070179876608
Epoch: 57 | Iteration number: [3130/4518] 69% | Training loss: 0.6870088040828705
Epoch: 57 | Iteration number: [3140/4518] 69% | Training loss: 0.6870081313286617
Epoch: 57 | Iteration number: [3150/4518] 69% | Training loss: 0.6870080318715838
Epoch: 57 | Iteration number: [3160/4518] 69% | Training loss: 0.6870063658379302
Epoch: 57 | Iteration number: [3170/4518] 70% | Training loss: 0.6870074358460279
Epoch: 57 | Iteration number: [3180/4518] 70% | Training loss: 0.6870020560685943
Epoch: 57 | Iteration number: [3190/4518] 70% | Training loss: 0.6869997481754208
Epoch: 57 | Iteration number: [3200/4518] 70% | Training loss: 0.6869988109730184
Epoch: 57 | Iteration number: [3210/4518] 71% | Training loss: 0.6870022640235699
Epoch: 57 | Iteration number: [3220/4518] 71% | Training loss: 0.6870021447631883
Epoch: 57 | Iteration number: [3230/4518] 71% | Training loss: 0.6870020136375545
Epoch: 57 | Iteration number: [3240/4518] 71% | Training loss: 0.6869977153745699
Epoch: 57 | Iteration number: [3250/4518] 71% | Training loss: 0.6869976968031664
Epoch: 57 | Iteration number: [3260/4518] 72% | Training loss: 0.686998422233605
Epoch: 57 | Iteration number: [3270/4518] 72% | Training loss: 0.6869977573371444
Epoch: 57 | Iteration number: [3280/4518] 72% | Training loss: 0.6869981130267062
Epoch: 57 | Iteration number: [3290/4518] 72% | Training loss: 0.6869988305228097
Epoch: 57 | Iteration number: [3300/4518] 73% | Training loss: 0.6869980245648009
Epoch: 57 | Iteration number: [3310/4518] 73% | Training loss: 0.6869975538592324
Epoch: 57 | Iteration number: [3320/4518] 73% | Training loss: 0.6869955310081861
Epoch: 57 | Iteration number: [3330/4518] 73% | Training loss: 0.6869941036622446
Epoch: 57 | Iteration number: [3340/4518] 73% | Training loss: 0.6869948570599813
Epoch: 57 | Iteration number: [3350/4518] 74% | Training loss: 0.6869975319727143
Epoch: 57 | Iteration number: [3360/4518] 74% | Training loss: 0.686998587403269
Epoch: 57 | Iteration number: [3370/4518] 74% | Training loss: 0.6869941144385748
Epoch: 57 | Iteration number: [3380/4518] 74% | Training loss: 0.6869944660621282
Epoch: 57 | Iteration number: [3390/4518] 75% | Training loss: 0.6869947941781497
Epoch: 57 | Iteration number: [3400/4518] 75% | Training loss: 0.6869942770985996
Epoch: 57 | Iteration number: [3410/4518] 75% | Training loss: 0.6869974052626366
Epoch: 57 | Iteration number: [3420/4518] 75% | Training loss: 0.6869939510236707
Epoch: 57 | Iteration number: [3430/4518] 75% | Training loss: 0.6869984336566647
Epoch: 57 | Iteration number: [3440/4518] 76% | Training loss: 0.6869938304084678
Epoch: 57 | Iteration number: [3450/4518] 76% | Training loss: 0.6869969226830247
Epoch: 57 | Iteration number: [3460/4518] 76% | Training loss: 0.6869989530544061
Epoch: 57 | Iteration number: [3470/4518] 76% | Training loss: 0.6870035261345184
Epoch: 57 | Iteration number: [3480/4518] 77% | Training loss: 0.6870033825779783
Epoch: 57 | Iteration number: [3490/4518] 77% | Training loss: 0.6870035991798499
Epoch: 57 | Iteration number: [3500/4518] 77% | Training loss: 0.6870061788218362
Epoch: 57 | Iteration number: [3510/4518] 77% | Training loss: 0.6870051783204418
Epoch: 57 | Iteration number: [3520/4518] 77% | Training loss: 0.6870029744776812
Epoch: 57 | Iteration number: [3530/4518] 78% | Training loss: 0.687004902511413
Epoch: 57 | Iteration number: [3540/4518] 78% | Training loss: 0.6870080097920477
Epoch: 57 | Iteration number: [3550/4518] 78% | Training loss: 0.6870061708839846
Epoch: 57 | Iteration number: [3560/4518] 78% | Training loss: 0.6870051052128331
Epoch: 57 | Iteration number: [3570/4518] 79% | Training loss: 0.6870051498840503
Epoch: 57 | Iteration number: [3580/4518] 79% | Training loss: 0.6870043086439538
Epoch: 57 | Iteration number: [3590/4518] 79% | Training loss: 0.6870046709075279
Epoch: 57 | Iteration number: [3600/4518] 79% | Training loss: 0.6870043190154764
Epoch: 57 | Iteration number: [3610/4518] 79% | Training loss: 0.6869999803829722
Epoch: 57 | Iteration number: [3620/4518] 80% | Training loss: 0.6870006949203449
Epoch: 57 | Iteration number: [3630/4518] 80% | Training loss: 0.686996774716154
Epoch: 57 | Iteration number: [3640/4518] 80% | Training loss: 0.6869948891492991
Epoch: 57 | Iteration number: [3650/4518] 80% | Training loss: 0.6869959475079628
Epoch: 57 | Iteration number: [3660/4518] 81% | Training loss: 0.686996010467003
Epoch: 57 | Iteration number: [3670/4518] 81% | Training loss: 0.6869913197343291
Epoch: 57 | Iteration number: [3680/4518] 81% | Training loss: 0.6869929848157841
Epoch: 57 | Iteration number: [3690/4518] 81% | Training loss: 0.6869934795671685
Epoch: 57 | Iteration number: [3700/4518] 81% | Training loss: 0.6869931846695977
Epoch: 57 | Iteration number: [3710/4518] 82% | Training loss: 0.6869909818603022
Epoch: 57 | Iteration number: [3720/4518] 82% | Training loss: 0.6869892084470359
Epoch: 57 | Iteration number: [3730/4518] 82% | Training loss: 0.6869911618271078
Epoch: 57 | Iteration number: [3740/4518] 82% | Training loss: 0.6869917878811372
Epoch: 57 | Iteration number: [3750/4518] 83% | Training loss: 0.6869920752207438
Epoch: 57 | Iteration number: [3760/4518] 83% | Training loss: 0.6869916154032057
Epoch: 57 | Iteration number: [3770/4518] 83% | Training loss: 0.6869888200367793
Epoch: 57 | Iteration number: [3780/4518] 83% | Training loss: 0.686989662240422
Epoch: 57 | Iteration number: [3790/4518] 83% | Training loss: 0.6869931363336015
Epoch: 57 | Iteration number: [3800/4518] 84% | Training loss: 0.6869928445627815
Epoch: 57 | Iteration number: [3810/4518] 84% | Training loss: 0.6869879589149646
Epoch: 57 | Iteration number: [3820/4518] 84% | Training loss: 0.6869872492489391
Epoch: 57 | Iteration number: [3830/4518] 84% | Training loss: 0.6869873361083297
Epoch: 57 | Iteration number: [3840/4518] 84% | Training loss: 0.6869868287350982
Epoch: 57 | Iteration number: [3850/4518] 85% | Training loss: 0.6869855905043615
Epoch: 57 | Iteration number: [3860/4518] 85% | Training loss: 0.6869858119154223
Epoch: 57 | Iteration number: [3870/4518] 85% | Training loss: 0.6869856771110564
Epoch: 57 | Iteration number: [3880/4518] 85% | Training loss: 0.6869870467591531
Epoch: 57 | Iteration number: [3890/4518] 86% | Training loss: 0.6869824115598723
Epoch: 57 | Iteration number: [3900/4518] 86% | Training loss: 0.6869813556548877
Epoch: 57 | Iteration number: [3910/4518] 86% | Training loss: 0.6869798678571306
Epoch: 57 | Iteration number: [3920/4518] 86% | Training loss: 0.6869790456580872
Epoch: 57 | Iteration number: [3930/4518] 86% | Training loss: 0.6869775609812361
Epoch: 57 | Iteration number: [3940/4518] 87% | Training loss: 0.6869763935731752
Epoch: 57 | Iteration number: [3950/4518] 87% | Training loss: 0.6869786171219017
Epoch: 57 | Iteration number: [3960/4518] 87% | Training loss: 0.6869771393712121
Epoch: 57 | Iteration number: [3970/4518] 87% | Training loss: 0.6869794737331814
Epoch: 57 | Iteration number: [3980/4518] 88% | Training loss: 0.6869798539721187
Epoch: 57 | Iteration number: [3990/4518] 88% | Training loss: 0.6869813917424147
Epoch: 57 | Iteration number: [4000/4518] 88% | Training loss: 0.6869826125055551
Epoch: 57 | Iteration number: [4010/4518] 88% | Training loss: 0.6869870533669679
Epoch: 57 | Iteration number: [4020/4518] 88% | Training loss: 0.6869854208100494
Epoch: 57 | Iteration number: [4030/4518] 89% | Training loss: 0.6869830733641206
Epoch: 57 | Iteration number: [4040/4518] 89% | Training loss: 0.6869858547897623
Epoch: 57 | Iteration number: [4050/4518] 89% | Training loss: 0.6869862836525764
Epoch: 57 | Iteration number: [4060/4518] 89% | Training loss: 0.6869853742604185
Epoch: 57 | Iteration number: [4070/4518] 90% | Training loss: 0.6869843490293629
Epoch: 57 | Iteration number: [4080/4518] 90% | Training loss: 0.6869852561868873
Epoch: 57 | Iteration number: [4090/4518] 90% | Training loss: 0.6869840826702585
Epoch: 57 | Iteration number: [4100/4518] 90% | Training loss: 0.686982189489574
Epoch: 57 | Iteration number: [4110/4518] 90% | Training loss: 0.6869809031341487
Epoch: 57 | Iteration number: [4120/4518] 91% | Training loss: 0.6869775093296199
Epoch: 57 | Iteration number: [4130/4518] 91% | Training loss: 0.6869793033484397
Epoch: 57 | Iteration number: [4140/4518] 91% | Training loss: 0.6869790633231545
Epoch: 57 | Iteration number: [4150/4518] 91% | Training loss: 0.6869787060639945
Epoch: 57 | Iteration number: [4160/4518] 92% | Training loss: 0.6869791618763255
Epoch: 57 | Iteration number: [4170/4518] 92% | Training loss: 0.6869782211540414
Epoch: 57 | Iteration number: [4180/4518] 92% | Training loss: 0.6869778093538786
Epoch: 57 | Iteration number: [4190/4518] 92% | Training loss: 0.6869759423778279
Epoch: 57 | Iteration number: [4200/4518] 92% | Training loss: 0.6869769958938872
Epoch: 57 | Iteration number: [4210/4518] 93% | Training loss: 0.6869762557560928
Epoch: 57 | Iteration number: [4220/4518] 93% | Training loss: 0.6869797164936201
Epoch: 57 | Iteration number: [4230/4518] 93% | Training loss: 0.686979202542181
Epoch: 57 | Iteration number: [4240/4518] 93% | Training loss: 0.6869751590040495
Epoch: 57 | Iteration number: [4250/4518] 94% | Training loss: 0.6869733023503247
Epoch: 57 | Iteration number: [4260/4518] 94% | Training loss: 0.6869728201571764
Epoch: 57 | Iteration number: [4270/4518] 94% | Training loss: 0.6869732697060292
Epoch: 57 | Iteration number: [4280/4518] 94% | Training loss: 0.6869718441339296
Epoch: 57 | Iteration number: [4290/4518] 94% | Training loss: 0.6869724680215884
Epoch: 57 | Iteration number: [4300/4518] 95% | Training loss: 0.6869723957222561
Epoch: 57 | Iteration number: [4310/4518] 95% | Training loss: 0.6869726907902693
Epoch: 57 | Iteration number: [4320/4518] 95% | Training loss: 0.6869688785186521
Epoch: 57 | Iteration number: [4330/4518] 95% | Training loss: 0.686965078679849
Epoch: 57 | Iteration number: [4340/4518] 96% | Training loss: 0.686967640373564
Epoch: 57 | Iteration number: [4350/4518] 96% | Training loss: 0.6869688884554238
Epoch: 57 | Iteration number: [4360/4518] 96% | Training loss: 0.6869657985250884
Epoch: 57 | Iteration number: [4370/4518] 96% | Training loss: 0.6869678880175409
Epoch: 57 | Iteration number: [4380/4518] 96% | Training loss: 0.6869675405085359
Epoch: 57 | Iteration number: [4390/4518] 97% | Training loss: 0.6869679394235372
Epoch: 57 | Iteration number: [4400/4518] 97% | Training loss: 0.6869679747250947
Epoch: 57 | Iteration number: [4410/4518] 97% | Training loss: 0.6869675849030077
Epoch: 57 | Iteration number: [4420/4518] 97% | Training loss: 0.6869662634657518
Epoch: 57 | Iteration number: [4430/4518] 98% | Training loss: 0.6869632545362477
Epoch: 57 | Iteration number: [4440/4518] 98% | Training loss: 0.6869639989089321
Epoch: 57 | Iteration number: [4450/4518] 98% | Training loss: 0.6869648154531972
Epoch: 57 | Iteration number: [4460/4518] 98% | Training loss: 0.6869628028217453
Epoch: 57 | Iteration number: [4470/4518] 98% | Training loss: 0.6869637657331941
Epoch: 57 | Iteration number: [4480/4518] 99% | Training loss: 0.686963341624609
Epoch: 57 | Iteration number: [4490/4518] 99% | Training loss: 0.6869605697741221
Epoch: 57 | Iteration number: [4500/4518] 99% | Training loss: 0.6869620425833596
Epoch: 57 | Iteration number: [4510/4518] 99% | Training loss: 0.6869598997670108

 End of epoch: 57 | Train Loss: 0.6868070842102071 | Training Time: 643 

 End of epoch: 57 | Eval Loss: 0.6901094682362615 | Evaluating Time: 17 
Epoch: 58 | Iteration number: [10/4518] 0% | Training loss: 0.7573616206645966
Epoch: 58 | Iteration number: [20/4518] 0% | Training loss: 0.7214899808168411
Epoch: 58 | Iteration number: [30/4518] 0% | Training loss: 0.7097585221131643
Epoch: 58 | Iteration number: [40/4518] 0% | Training loss: 0.7039772897958756
Epoch: 58 | Iteration number: [50/4518] 1% | Training loss: 0.7004274499416351
Epoch: 58 | Iteration number: [60/4518] 1% | Training loss: 0.6980438341697057
Epoch: 58 | Iteration number: [70/4518] 1% | Training loss: 0.6963719104017531
Epoch: 58 | Iteration number: [80/4518] 1% | Training loss: 0.6951957792043686
Epoch: 58 | Iteration number: [90/4518] 1% | Training loss: 0.6943008866575029
Epoch: 58 | Iteration number: [100/4518] 2% | Training loss: 0.6935986787080765
Epoch: 58 | Iteration number: [110/4518] 2% | Training loss: 0.6928964934565804
Epoch: 58 | Iteration number: [120/4518] 2% | Training loss: 0.6924143001437187
Epoch: 58 | Iteration number: [130/4518] 2% | Training loss: 0.691909698339609
Epoch: 58 | Iteration number: [140/4518] 3% | Training loss: 0.6915595361164638
Epoch: 58 | Iteration number: [150/4518] 3% | Training loss: 0.6912830015023549
Epoch: 58 | Iteration number: [160/4518] 3% | Training loss: 0.6910364747047424
Epoch: 58 | Iteration number: [170/4518] 3% | Training loss: 0.6908103189047645
Epoch: 58 | Iteration number: [180/4518] 3% | Training loss: 0.6905707859330708
Epoch: 58 | Iteration number: [190/4518] 4% | Training loss: 0.690396638606724
Epoch: 58 | Iteration number: [200/4518] 4% | Training loss: 0.69021443516016
Epoch: 58 | Iteration number: [210/4518] 4% | Training loss: 0.6900723823479243
Epoch: 58 | Iteration number: [220/4518] 4% | Training loss: 0.6899978458881378
Epoch: 58 | Iteration number: [230/4518] 5% | Training loss: 0.6898576231106468
Epoch: 58 | Iteration number: [240/4518] 5% | Training loss: 0.689753812054793
Epoch: 58 | Iteration number: [250/4518] 5% | Training loss: 0.6896040275096893
Epoch: 58 | Iteration number: [260/4518] 5% | Training loss: 0.6895000166617907
Epoch: 58 | Iteration number: [270/4518] 5% | Training loss: 0.6893914494249556
Epoch: 58 | Iteration number: [280/4518] 6% | Training loss: 0.6893049782940319
Epoch: 58 | Iteration number: [290/4518] 6% | Training loss: 0.6892212395010323
Epoch: 58 | Iteration number: [300/4518] 6% | Training loss: 0.6891107855240504
Epoch: 58 | Iteration number: [310/4518] 6% | Training loss: 0.6890725783763393
Epoch: 58 | Iteration number: [320/4518] 7% | Training loss: 0.689007717743516
Epoch: 58 | Iteration number: [330/4518] 7% | Training loss: 0.6889699766130158
Epoch: 58 | Iteration number: [340/4518] 7% | Training loss: 0.6889159965164521
Epoch: 58 | Iteration number: [350/4518] 7% | Training loss: 0.6888636173520769
Epoch: 58 | Iteration number: [360/4518] 7% | Training loss: 0.688804509739081
Epoch: 58 | Iteration number: [370/4518] 8% | Training loss: 0.6887761177243413
Epoch: 58 | Iteration number: [380/4518] 8% | Training loss: 0.6887115353032163
Epoch: 58 | Iteration number: [390/4518] 8% | Training loss: 0.6886632578495221
Epoch: 58 | Iteration number: [400/4518] 8% | Training loss: 0.6886140130460262
Epoch: 58 | Iteration number: [410/4518] 9% | Training loss: 0.6885476001879064
Epoch: 58 | Iteration number: [420/4518] 9% | Training loss: 0.688529482341948
Epoch: 58 | Iteration number: [430/4518] 9% | Training loss: 0.6884895102922306
Epoch: 58 | Iteration number: [440/4518] 9% | Training loss: 0.6884526148438453
Epoch: 58 | Iteration number: [450/4518] 9% | Training loss: 0.6884016455544366
Epoch: 58 | Iteration number: [460/4518] 10% | Training loss: 0.6883493857539218
Epoch: 58 | Iteration number: [470/4518] 10% | Training loss: 0.6883312958352109
Epoch: 58 | Iteration number: [480/4518] 10% | Training loss: 0.6883190793295701
Epoch: 58 | Iteration number: [490/4518] 10% | Training loss: 0.6883270859718322
Epoch: 58 | Iteration number: [500/4518] 11% | Training loss: 0.6882798639535904
Epoch: 58 | Iteration number: [510/4518] 11% | Training loss: 0.6882554325402952
Epoch: 58 | Iteration number: [520/4518] 11% | Training loss: 0.6882052982082734
Epoch: 58 | Iteration number: [530/4518] 11% | Training loss: 0.6881849114624959
Epoch: 58 | Iteration number: [540/4518] 11% | Training loss: 0.6881538417604235
Epoch: 58 | Iteration number: [550/4518] 12% | Training loss: 0.6881314351341942
Epoch: 58 | Iteration number: [560/4518] 12% | Training loss: 0.6880979388952255
Epoch: 58 | Iteration number: [570/4518] 12% | Training loss: 0.6880857341122208
Epoch: 58 | Iteration number: [580/4518] 12% | Training loss: 0.6880751612885245
Epoch: 58 | Iteration number: [590/4518] 13% | Training loss: 0.688058138903925
Epoch: 58 | Iteration number: [600/4518] 13% | Training loss: 0.6880266637603442
Epoch: 58 | Iteration number: [610/4518] 13% | Training loss: 0.6880010834482849
Epoch: 58 | Iteration number: [620/4518] 13% | Training loss: 0.6879810746639006
Epoch: 58 | Iteration number: [630/4518] 13% | Training loss: 0.6879720349160452
Epoch: 58 | Iteration number: [640/4518] 14% | Training loss: 0.6879578686319292
Epoch: 58 | Iteration number: [650/4518] 14% | Training loss: 0.6879291080511534
Epoch: 58 | Iteration number: [660/4518] 14% | Training loss: 0.6879070322621953
Epoch: 58 | Iteration number: [670/4518] 14% | Training loss: 0.6878899175729325
Epoch: 58 | Iteration number: [680/4518] 15% | Training loss: 0.6878754138069995
Epoch: 58 | Iteration number: [690/4518] 15% | Training loss: 0.687860979118209
Epoch: 58 | Iteration number: [700/4518] 15% | Training loss: 0.6878389321906226
Epoch: 58 | Iteration number: [710/4518] 15% | Training loss: 0.6878137669932675
Epoch: 58 | Iteration number: [720/4518] 15% | Training loss: 0.6877976732121573
Epoch: 58 | Iteration number: [730/4518] 16% | Training loss: 0.6877764109879324
Epoch: 58 | Iteration number: [740/4518] 16% | Training loss: 0.6877600350895443
Epoch: 58 | Iteration number: [750/4518] 16% | Training loss: 0.6877505996227264
Epoch: 58 | Iteration number: [760/4518] 16% | Training loss: 0.6877536200379071
Epoch: 58 | Iteration number: [770/4518] 17% | Training loss: 0.6877465323968367
Epoch: 58 | Iteration number: [780/4518] 17% | Training loss: 0.6877342463303835
Epoch: 58 | Iteration number: [790/4518] 17% | Training loss: 0.6877456230453298
Epoch: 58 | Iteration number: [800/4518] 17% | Training loss: 0.6877301236987114
Epoch: 58 | Iteration number: [810/4518] 17% | Training loss: 0.6877139413062437
Epoch: 58 | Iteration number: [820/4518] 18% | Training loss: 0.6877150646070155
Epoch: 58 | Iteration number: [830/4518] 18% | Training loss: 0.6877034155001124
Epoch: 58 | Iteration number: [840/4518] 18% | Training loss: 0.6877099419633548
Epoch: 58 | Iteration number: [850/4518] 18% | Training loss: 0.6876890538019292
Epoch: 58 | Iteration number: [860/4518] 19% | Training loss: 0.6876959911612577
Epoch: 58 | Iteration number: [870/4518] 19% | Training loss: 0.6876813641224785
Epoch: 58 | Iteration number: [880/4518] 19% | Training loss: 0.6876599710773338
Epoch: 58 | Iteration number: [890/4518] 19% | Training loss: 0.6876347343573409
Epoch: 58 | Iteration number: [900/4518] 19% | Training loss: 0.6876400385300319
Epoch: 58 | Iteration number: [910/4518] 20% | Training loss: 0.6876399984071543
Epoch: 58 | Iteration number: [920/4518] 20% | Training loss: 0.6876277021091918
Epoch: 58 | Iteration number: [930/4518] 20% | Training loss: 0.6876081763416209
Epoch: 58 | Iteration number: [940/4518] 20% | Training loss: 0.6876039764982589
Epoch: 58 | Iteration number: [950/4518] 21% | Training loss: 0.687596958436464
Epoch: 58 | Iteration number: [960/4518] 21% | Training loss: 0.6875876634071271
Epoch: 58 | Iteration number: [970/4518] 21% | Training loss: 0.6875848321570563
Epoch: 58 | Iteration number: [980/4518] 21% | Training loss: 0.6875960881004528
Epoch: 58 | Iteration number: [990/4518] 21% | Training loss: 0.6875883479913075
Epoch: 58 | Iteration number: [1000/4518] 22% | Training loss: 0.6875875819325447
Epoch: 58 | Iteration number: [1010/4518] 22% | Training loss: 0.6875908318132458
Epoch: 58 | Iteration number: [1020/4518] 22% | Training loss: 0.6875728646329805
Epoch: 58 | Iteration number: [1030/4518] 22% | Training loss: 0.6875563129638005
Epoch: 58 | Iteration number: [1040/4518] 23% | Training loss: 0.6875422764856082
Epoch: 58 | Iteration number: [1050/4518] 23% | Training loss: 0.6875339816865467
Epoch: 58 | Iteration number: [1060/4518] 23% | Training loss: 0.6875307467186226
Epoch: 58 | Iteration number: [1070/4518] 23% | Training loss: 0.6875108358458938
Epoch: 58 | Iteration number: [1080/4518] 23% | Training loss: 0.6875034671690728
Epoch: 58 | Iteration number: [1090/4518] 24% | Training loss: 0.687498672019451
Epoch: 58 | Iteration number: [1100/4518] 24% | Training loss: 0.6874928087537939
Epoch: 58 | Iteration number: [1110/4518] 24% | Training loss: 0.6874892323403745
Epoch: 58 | Iteration number: [1120/4518] 24% | Training loss: 0.6874962961035115
Epoch: 58 | Iteration number: [1130/4518] 25% | Training loss: 0.6874871656430506
Epoch: 58 | Iteration number: [1140/4518] 25% | Training loss: 0.6874787524081113
Epoch: 58 | Iteration number: [1150/4518] 25% | Training loss: 0.6874703967571258
Epoch: 58 | Iteration number: [1160/4518] 25% | Training loss: 0.6874658960206755
Epoch: 58 | Iteration number: [1170/4518] 25% | Training loss: 0.6874563650188283
Epoch: 58 | Iteration number: [1180/4518] 26% | Training loss: 0.6874575384087481
Epoch: 58 | Iteration number: [1190/4518] 26% | Training loss: 0.6874524693028266
Epoch: 58 | Iteration number: [1200/4518] 26% | Training loss: 0.6874395074446996
Epoch: 58 | Iteration number: [1210/4518] 26% | Training loss: 0.6874392605517521
Epoch: 58 | Iteration number: [1220/4518] 27% | Training loss: 0.6874345228320262
Epoch: 58 | Iteration number: [1230/4518] 27% | Training loss: 0.6874150522840702
Epoch: 58 | Iteration number: [1240/4518] 27% | Training loss: 0.6874144988675271
Epoch: 58 | Iteration number: [1250/4518] 27% | Training loss: 0.6874155468463897
Epoch: 58 | Iteration number: [1260/4518] 27% | Training loss: 0.6874024166001214
Epoch: 58 | Iteration number: [1270/4518] 28% | Training loss: 0.687397420312476
Epoch: 58 | Iteration number: [1280/4518] 28% | Training loss: 0.6873882738407702
Epoch: 58 | Iteration number: [1290/4518] 28% | Training loss: 0.6873890435048776
Epoch: 58 | Iteration number: [1300/4518] 28% | Training loss: 0.6873878760979726
Epoch: 58 | Iteration number: [1310/4518] 28% | Training loss: 0.6873840127737467
Epoch: 58 | Iteration number: [1320/4518] 29% | Training loss: 0.6873709248322429
Epoch: 58 | Iteration number: [1330/4518] 29% | Training loss: 0.6873559746527134
Epoch: 58 | Iteration number: [1340/4518] 29% | Training loss: 0.6873492048747504
Epoch: 58 | Iteration number: [1350/4518] 29% | Training loss: 0.6873383867299115
Epoch: 58 | Iteration number: [1360/4518] 30% | Training loss: 0.6873336262124426
Epoch: 58 | Iteration number: [1370/4518] 30% | Training loss: 0.6873278933284926
Epoch: 58 | Iteration number: [1380/4518] 30% | Training loss: 0.6873260292454042
Epoch: 58 | Iteration number: [1390/4518] 30% | Training loss: 0.6873195726665662
Epoch: 58 | Iteration number: [1400/4518] 30% | Training loss: 0.6873203216706003
Epoch: 58 | Iteration number: [1410/4518] 31% | Training loss: 0.6873265640532716
Epoch: 58 | Iteration number: [1420/4518] 31% | Training loss: 0.6873197709590616
Epoch: 58 | Iteration number: [1430/4518] 31% | Training loss: 0.6873196218814049
Epoch: 58 | Iteration number: [1440/4518] 31% | Training loss: 0.6873090848740604
Epoch: 58 | Iteration number: [1450/4518] 32% | Training loss: 0.6873043297077047
Epoch: 58 | Iteration number: [1460/4518] 32% | Training loss: 0.6872888062098255
Epoch: 58 | Iteration number: [1470/4518] 32% | Training loss: 0.6872876364357617
Epoch: 58 | Iteration number: [1480/4518] 32% | Training loss: 0.6872823580696776
Epoch: 58 | Iteration number: [1490/4518] 32% | Training loss: 0.6872779330551224
Epoch: 58 | Iteration number: [1500/4518] 33% | Training loss: 0.6872787013848622
Epoch: 58 | Iteration number: [1510/4518] 33% | Training loss: 0.6872730157627964
Epoch: 58 | Iteration number: [1520/4518] 33% | Training loss: 0.6872774575493837
Epoch: 58 | Iteration number: [1530/4518] 33% | Training loss: 0.6872756745301041
Epoch: 58 | Iteration number: [1540/4518] 34% | Training loss: 0.6872785637130985
Epoch: 58 | Iteration number: [1550/4518] 34% | Training loss: 0.6872721399030378
Epoch: 58 | Iteration number: [1560/4518] 34% | Training loss: 0.6872723357035564
Epoch: 58 | Iteration number: [1570/4518] 34% | Training loss: 0.6872742332470645
Epoch: 58 | Iteration number: [1580/4518] 34% | Training loss: 0.6872800538811502
Epoch: 58 | Iteration number: [1590/4518] 35% | Training loss: 0.6872644421439501
Epoch: 58 | Iteration number: [1600/4518] 35% | Training loss: 0.6872596895322204
Epoch: 58 | Iteration number: [1610/4518] 35% | Training loss: 0.6872526502757339
Epoch: 58 | Iteration number: [1620/4518] 35% | Training loss: 0.687242767472326
Epoch: 58 | Iteration number: [1630/4518] 36% | Training loss: 0.6872402841328112
Epoch: 58 | Iteration number: [1640/4518] 36% | Training loss: 0.6872384252708132
Epoch: 58 | Iteration number: [1650/4518] 36% | Training loss: 0.6872426428578117
Epoch: 58 | Iteration number: [1660/4518] 36% | Training loss: 0.6872435173715453
Epoch: 58 | Iteration number: [1670/4518] 36% | Training loss: 0.6872377659032445
Epoch: 58 | Iteration number: [1680/4518] 37% | Training loss: 0.6872342919664723
Epoch: 58 | Iteration number: [1690/4518] 37% | Training loss: 0.6872310504052765
Epoch: 58 | Iteration number: [1700/4518] 37% | Training loss: 0.6872319257609985
Epoch: 58 | Iteration number: [1710/4518] 37% | Training loss: 0.6872245765917483
Epoch: 58 | Iteration number: [1720/4518] 38% | Training loss: 0.6872132967377818
Epoch: 58 | Iteration number: [1730/4518] 38% | Training loss: 0.6872055096433342
Epoch: 58 | Iteration number: [1740/4518] 38% | Training loss: 0.6871927866647983
Epoch: 58 | Iteration number: [1750/4518] 38% | Training loss: 0.6871854553903852
Epoch: 58 | Iteration number: [1760/4518] 38% | Training loss: 0.6871845274147662
Epoch: 58 | Iteration number: [1770/4518] 39% | Training loss: 0.6871785578081163
Epoch: 58 | Iteration number: [1780/4518] 39% | Training loss: 0.6871690048260635
Epoch: 58 | Iteration number: [1790/4518] 39% | Training loss: 0.6871696541429232
Epoch: 58 | Iteration number: [1800/4518] 39% | Training loss: 0.6871670717994373
Epoch: 58 | Iteration number: [1810/4518] 40% | Training loss: 0.6871696332870926
Epoch: 58 | Iteration number: [1820/4518] 40% | Training loss: 0.6871733202384068
Epoch: 58 | Iteration number: [1830/4518] 40% | Training loss: 0.6871627265638341
Epoch: 58 | Iteration number: [1840/4518] 40% | Training loss: 0.6871583040641702
Epoch: 58 | Iteration number: [1850/4518] 40% | Training loss: 0.6871555220436405
Epoch: 58 | Iteration number: [1860/4518] 41% | Training loss: 0.6871569812297821
Epoch: 58 | Iteration number: [1870/4518] 41% | Training loss: 0.6871445632873372
Epoch: 58 | Iteration number: [1880/4518] 41% | Training loss: 0.6871474763497393
Epoch: 58 | Iteration number: [1890/4518] 41% | Training loss: 0.6871419911662107
Epoch: 58 | Iteration number: [1900/4518] 42% | Training loss: 0.6871382108801289
Epoch: 58 | Iteration number: [1910/4518] 42% | Training loss: 0.6871365811812316
Epoch: 58 | Iteration number: [1920/4518] 42% | Training loss: 0.6871374749888977
Epoch: 58 | Iteration number: [1930/4518] 42% | Training loss: 0.6871354791166869
Epoch: 58 | Iteration number: [1940/4518] 42% | Training loss: 0.6871337040797951
Epoch: 58 | Iteration number: [1950/4518] 43% | Training loss: 0.6871336756608425
Epoch: 58 | Iteration number: [1960/4518] 43% | Training loss: 0.6871278052123225
Epoch: 58 | Iteration number: [1970/4518] 43% | Training loss: 0.687116523866121
Epoch: 58 | Iteration number: [1980/4518] 43% | Training loss: 0.6871196210083336
Epoch: 58 | Iteration number: [1990/4518] 44% | Training loss: 0.6871180109043217
Epoch: 58 | Iteration number: [2000/4518] 44% | Training loss: 0.6871161960065365
Epoch: 58 | Iteration number: [2010/4518] 44% | Training loss: 0.6871201140963616
Epoch: 58 | Iteration number: [2020/4518] 44% | Training loss: 0.6871190745051544
Epoch: 58 | Iteration number: [2030/4518] 44% | Training loss: 0.6871124427600447
Epoch: 58 | Iteration number: [2040/4518] 45% | Training loss: 0.6871054875207883
Epoch: 58 | Iteration number: [2050/4518] 45% | Training loss: 0.6871051401336019
Epoch: 58 | Iteration number: [2060/4518] 45% | Training loss: 0.6871042383816636
Epoch: 58 | Iteration number: [2070/4518] 45% | Training loss: 0.6870971703299001
Epoch: 58 | Iteration number: [2080/4518] 46% | Training loss: 0.6870949252580221
Epoch: 58 | Iteration number: [2090/4518] 46% | Training loss: 0.6870926174535705
Epoch: 58 | Iteration number: [2100/4518] 46% | Training loss: 0.6870918969313303
Epoch: 58 | Iteration number: [2110/4518] 46% | Training loss: 0.6870922556985611
Epoch: 58 | Iteration number: [2120/4518] 46% | Training loss: 0.6870916233872467
Epoch: 58 | Iteration number: [2130/4518] 47% | Training loss: 0.6870948123260283
Epoch: 58 | Iteration number: [2140/4518] 47% | Training loss: 0.6870925802493764
Epoch: 58 | Iteration number: [2150/4518] 47% | Training loss: 0.6870894279313642
Epoch: 58 | Iteration number: [2160/4518] 47% | Training loss: 0.6870854491436923
Epoch: 58 | Iteration number: [2170/4518] 48% | Training loss: 0.6870818368026188
Epoch: 58 | Iteration number: [2180/4518] 48% | Training loss: 0.6870810757262991
Epoch: 58 | Iteration number: [2190/4518] 48% | Training loss: 0.6870883145833124
Epoch: 58 | Iteration number: [2200/4518] 48% | Training loss: 0.687086044522849
Epoch: 58 | Iteration number: [2210/4518] 48% | Training loss: 0.6870865880903615
Epoch: 58 | Iteration number: [2220/4518] 49% | Training loss: 0.6870837267186191
Epoch: 58 | Iteration number: [2230/4518] 49% | Training loss: 0.6870842741743866
Epoch: 58 | Iteration number: [2240/4518] 49% | Training loss: 0.6870791379362344
Epoch: 58 | Iteration number: [2250/4518] 49% | Training loss: 0.6870742158889771
Epoch: 58 | Iteration number: [2260/4518] 50% | Training loss: 0.6870750460477002
Epoch: 58 | Iteration number: [2270/4518] 50% | Training loss: 0.6870674119121702
Epoch: 58 | Iteration number: [2280/4518] 50% | Training loss: 0.6870672975454414
Epoch: 58 | Iteration number: [2290/4518] 50% | Training loss: 0.6870697016539011
Epoch: 58 | Iteration number: [2300/4518] 50% | Training loss: 0.6870673973145692
Epoch: 58 | Iteration number: [2310/4518] 51% | Training loss: 0.6870676957941675
Epoch: 58 | Iteration number: [2320/4518] 51% | Training loss: 0.6870632248705831
Epoch: 58 | Iteration number: [2330/4518] 51% | Training loss: 0.687060570588951
Epoch: 58 | Iteration number: [2340/4518] 51% | Training loss: 0.6870608603088265
Epoch: 58 | Iteration number: [2350/4518] 52% | Training loss: 0.6870627265534502
Epoch: 58 | Iteration number: [2360/4518] 52% | Training loss: 0.6870613773748026
Epoch: 58 | Iteration number: [2370/4518] 52% | Training loss: 0.6870584310610083
Epoch: 58 | Iteration number: [2380/4518] 52% | Training loss: 0.687056805431342
Epoch: 58 | Iteration number: [2390/4518] 52% | Training loss: 0.6870511177444059
Epoch: 58 | Iteration number: [2400/4518] 53% | Training loss: 0.6870506104578574
Epoch: 58 | Iteration number: [2410/4518] 53% | Training loss: 0.6870535713013771
Epoch: 58 | Iteration number: [2420/4518] 53% | Training loss: 0.6870550540853138
Epoch: 58 | Iteration number: [2430/4518] 53% | Training loss: 0.6870485498336117
Epoch: 58 | Iteration number: [2440/4518] 54% | Training loss: 0.6870517969620032
Epoch: 58 | Iteration number: [2450/4518] 54% | Training loss: 0.6870560662843743
Epoch: 58 | Iteration number: [2460/4518] 54% | Training loss: 0.6870577708007843
Epoch: 58 | Iteration number: [2470/4518] 54% | Training loss: 0.6870510656341368
Epoch: 58 | Iteration number: [2480/4518] 54% | Training loss: 0.6870486450531791
Epoch: 58 | Iteration number: [2490/4518] 55% | Training loss: 0.6870511150503733
Epoch: 58 | Iteration number: [2500/4518] 55% | Training loss: 0.6870501986026764
Epoch: 58 | Iteration number: [2510/4518] 55% | Training loss: 0.6870474145231968
Epoch: 58 | Iteration number: [2520/4518] 55% | Training loss: 0.6870493422661509
Epoch: 58 | Iteration number: [2530/4518] 55% | Training loss: 0.687049067138212
Epoch: 58 | Iteration number: [2540/4518] 56% | Training loss: 0.6870455431187247
Epoch: 58 | Iteration number: [2550/4518] 56% | Training loss: 0.6870436892088722
Epoch: 58 | Iteration number: [2560/4518] 56% | Training loss: 0.6870443156687542
Epoch: 58 | Iteration number: [2570/4518] 56% | Training loss: 0.6870496472727927
Epoch: 58 | Iteration number: [2580/4518] 57% | Training loss: 0.6870483485996262
Epoch: 58 | Iteration number: [2590/4518] 57% | Training loss: 0.6870491688085799
Epoch: 58 | Iteration number: [2600/4518] 57% | Training loss: 0.687048298578996
Epoch: 58 | Iteration number: [2610/4518] 57% | Training loss: 0.6870387053352663
Epoch: 58 | Iteration number: [2620/4518] 57% | Training loss: 0.6870401487550662
Epoch: 58 | Iteration number: [2630/4518] 58% | Training loss: 0.6870365909523837
Epoch: 58 | Iteration number: [2640/4518] 58% | Training loss: 0.6870335239804153
Epoch: 58 | Iteration number: [2650/4518] 58% | Training loss: 0.6870363723781874
Epoch: 58 | Iteration number: [2660/4518] 58% | Training loss: 0.6870353957091956
Epoch: 58 | Iteration number: [2670/4518] 59% | Training loss: 0.6870292904225181
Epoch: 58 | Iteration number: [2680/4518] 59% | Training loss: 0.6870301735712521
Epoch: 58 | Iteration number: [2690/4518] 59% | Training loss: 0.6870322766800352
Epoch: 58 | Iteration number: [2700/4518] 59% | Training loss: 0.6870259033088331
Epoch: 58 | Iteration number: [2710/4518] 59% | Training loss: 0.6870267995169242
Epoch: 58 | Iteration number: [2720/4518] 60% | Training loss: 0.6870269247714211
Epoch: 58 | Iteration number: [2730/4518] 60% | Training loss: 0.6870211341660538
Epoch: 58 | Iteration number: [2740/4518] 60% | Training loss: 0.6870229853330737
Epoch: 58 | Iteration number: [2750/4518] 60% | Training loss: 0.6870243911092931
Epoch: 58 | Iteration number: [2760/4518] 61% | Training loss: 0.6870248495020728
Epoch: 58 | Iteration number: [2770/4518] 61% | Training loss: 0.6870234708923726
Epoch: 58 | Iteration number: [2780/4518] 61% | Training loss: 0.687023947564818
Epoch: 58 | Iteration number: [2790/4518] 61% | Training loss: 0.6870267834073753
Epoch: 58 | Iteration number: [2800/4518] 61% | Training loss: 0.6870240034801619
Epoch: 58 | Iteration number: [2810/4518] 62% | Training loss: 0.6870179132422518
Epoch: 58 | Iteration number: [2820/4518] 62% | Training loss: 0.6870218435289166
Epoch: 58 | Iteration number: [2830/4518] 62% | Training loss: 0.6870230766572717
Epoch: 58 | Iteration number: [2840/4518] 62% | Training loss: 0.6870239163578397
Epoch: 58 | Iteration number: [2850/4518] 63% | Training loss: 0.6870243919523139
Epoch: 58 | Iteration number: [2860/4518] 63% | Training loss: 0.6870281673811532
Epoch: 58 | Iteration number: [2870/4518] 63% | Training loss: 0.6870301743209986
Epoch: 58 | Iteration number: [2880/4518] 63% | Training loss: 0.687031639388038
Epoch: 58 | Iteration number: [2890/4518] 63% | Training loss: 0.6870260683929219
Epoch: 58 | Iteration number: [2900/4518] 64% | Training loss: 0.6870267964231557
Epoch: 58 | Iteration number: [2910/4518] 64% | Training loss: 0.6870280244301274
Epoch: 58 | Iteration number: [2920/4518] 64% | Training loss: 0.687028041155371
Epoch: 58 | Iteration number: [2930/4518] 64% | Training loss: 0.6870279803210965
Epoch: 58 | Iteration number: [2940/4518] 65% | Training loss: 0.6870233027910699
Epoch: 58 | Iteration number: [2950/4518] 65% | Training loss: 0.68702408439022
Epoch: 58 | Iteration number: [2960/4518] 65% | Training loss: 0.6870271200263822
Epoch: 58 | Iteration number: [2970/4518] 65% | Training loss: 0.6870265615508211
Epoch: 58 | Iteration number: [2980/4518] 65% | Training loss: 0.6870300925818066
Epoch: 58 | Iteration number: [2990/4518] 66% | Training loss: 0.6870304890500263
Epoch: 58 | Iteration number: [3000/4518] 66% | Training loss: 0.6870324164231618
Epoch: 58 | Iteration number: [3010/4518] 66% | Training loss: 0.6870315874731818
Epoch: 58 | Iteration number: [3020/4518] 66% | Training loss: 0.6870272870687459
Epoch: 58 | Iteration number: [3030/4518] 67% | Training loss: 0.687028037616522
Epoch: 58 | Iteration number: [3040/4518] 67% | Training loss: 0.687021432934623
Epoch: 58 | Iteration number: [3050/4518] 67% | Training loss: 0.6870198504260329
Epoch: 58 | Iteration number: [3060/4518] 67% | Training loss: 0.6870166677665087
Epoch: 58 | Iteration number: [3070/4518] 67% | Training loss: 0.6870167666421263
Epoch: 58 | Iteration number: [3080/4518] 68% | Training loss: 0.6870089466115097
Epoch: 58 | Iteration number: [3090/4518] 68% | Training loss: 0.6870070372005882
Epoch: 58 | Iteration number: [3100/4518] 68% | Training loss: 0.6870093548297882
Epoch: 58 | Iteration number: [3110/4518] 68% | Training loss: 0.6870057451763337
Epoch: 58 | Iteration number: [3120/4518] 69% | Training loss: 0.6870067030764543
Epoch: 58 | Iteration number: [3130/4518] 69% | Training loss: 0.6870058394849491
Epoch: 58 | Iteration number: [3140/4518] 69% | Training loss: 0.6870073145172398
Epoch: 58 | Iteration number: [3150/4518] 69% | Training loss: 0.6870070522550552
Epoch: 58 | Iteration number: [3160/4518] 69% | Training loss: 0.6870064541320258
Epoch: 58 | Iteration number: [3170/4518] 70% | Training loss: 0.6870024573163656
Epoch: 58 | Iteration number: [3180/4518] 70% | Training loss: 0.6870016523877029
Epoch: 58 | Iteration number: [3190/4518] 70% | Training loss: 0.6870004517718169
Epoch: 58 | Iteration number: [3200/4518] 70% | Training loss: 0.6869979107566178
Epoch: 58 | Iteration number: [3210/4518] 71% | Training loss: 0.6869959265272194
Epoch: 58 | Iteration number: [3220/4518] 71% | Training loss: 0.6869976890568408
Epoch: 58 | Iteration number: [3230/4518] 71% | Training loss: 0.6870006144046783
Epoch: 58 | Iteration number: [3240/4518] 71% | Training loss: 0.6869984166121778
Epoch: 58 | Iteration number: [3250/4518] 71% | Training loss: 0.686991942185622
Epoch: 58 | Iteration number: [3260/4518] 72% | Training loss: 0.6869917920030699
Epoch: 58 | Iteration number: [3270/4518] 72% | Training loss: 0.686989755368014
Epoch: 58 | Iteration number: [3280/4518] 72% | Training loss: 0.6869900345620585
Epoch: 58 | Iteration number: [3290/4518] 72% | Training loss: 0.6869884279723588
Epoch: 58 | Iteration number: [3300/4518] 73% | Training loss: 0.6869938595728441
Epoch: 58 | Iteration number: [3310/4518] 73% | Training loss: 0.6869879980821985
Epoch: 58 | Iteration number: [3320/4518] 73% | Training loss: 0.6869891118392887
Epoch: 58 | Iteration number: [3330/4518] 73% | Training loss: 0.6869871815582653
Epoch: 58 | Iteration number: [3340/4518] 73% | Training loss: 0.6869844126130292
Epoch: 58 | Iteration number: [3350/4518] 74% | Training loss: 0.6869841646970208
Epoch: 58 | Iteration number: [3360/4518] 74% | Training loss: 0.6869840633301508
Epoch: 58 | Iteration number: [3370/4518] 74% | Training loss: 0.6869860544225936
Epoch: 58 | Iteration number: [3380/4518] 74% | Training loss: 0.6869846748000772
Epoch: 58 | Iteration number: [3390/4518] 75% | Training loss: 0.6869840099572432
Epoch: 58 | Iteration number: [3400/4518] 75% | Training loss: 0.6869840619143318
Epoch: 58 | Iteration number: [3410/4518] 75% | Training loss: 0.6869859088376121
Epoch: 58 | Iteration number: [3420/4518] 75% | Training loss: 0.6869878235616182
Epoch: 58 | Iteration number: [3430/4518] 75% | Training loss: 0.6869864477708111
Epoch: 58 | Iteration number: [3440/4518] 76% | Training loss: 0.6869864251724509
Epoch: 58 | Iteration number: [3450/4518] 76% | Training loss: 0.6869851500227832
Epoch: 58 | Iteration number: [3460/4518] 76% | Training loss: 0.6869804876732688
Epoch: 58 | Iteration number: [3470/4518] 76% | Training loss: 0.6869780765143183
Epoch: 58 | Iteration number: [3480/4518] 77% | Training loss: 0.6869776334399464
Epoch: 58 | Iteration number: [3490/4518] 77% | Training loss: 0.6869782161746804
Epoch: 58 | Iteration number: [3500/4518] 77% | Training loss: 0.6869762329714639
Epoch: 58 | Iteration number: [3510/4518] 77% | Training loss: 0.6869759872258558
Epoch: 58 | Iteration number: [3520/4518] 77% | Training loss: 0.6869763674383814
Epoch: 58 | Iteration number: [3530/4518] 78% | Training loss: 0.6869751378767214
Epoch: 58 | Iteration number: [3540/4518] 78% | Training loss: 0.6869774323903908
Epoch: 58 | Iteration number: [3550/4518] 78% | Training loss: 0.6869789297647879
Epoch: 58 | Iteration number: [3560/4518] 78% | Training loss: 0.686976754899775
Epoch: 58 | Iteration number: [3570/4518] 79% | Training loss: 0.6869738777979415
Epoch: 58 | Iteration number: [3580/4518] 79% | Training loss: 0.6869757983771116
Epoch: 58 | Iteration number: [3590/4518] 79% | Training loss: 0.6869739594399763
Epoch: 58 | Iteration number: [3600/4518] 79% | Training loss: 0.6869763207601176
Epoch: 58 | Iteration number: [3610/4518] 79% | Training loss: 0.6869787729512952
Epoch: 58 | Iteration number: [3620/4518] 80% | Training loss: 0.6869779400568641
Epoch: 58 | Iteration number: [3630/4518] 80% | Training loss: 0.6869745184567349
Epoch: 58 | Iteration number: [3640/4518] 80% | Training loss: 0.6869695406202432
Epoch: 58 | Iteration number: [3650/4518] 80% | Training loss: 0.6869702978330116
Epoch: 58 | Iteration number: [3660/4518] 81% | Training loss: 0.686971445389784
Epoch: 58 | Iteration number: [3670/4518] 81% | Training loss: 0.6869703988125928
Epoch: 58 | Iteration number: [3680/4518] 81% | Training loss: 0.6869711210222348
Epoch: 58 | Iteration number: [3690/4518] 81% | Training loss: 0.6869698323693055
Epoch: 58 | Iteration number: [3700/4518] 81% | Training loss: 0.6869689418979593
Epoch: 58 | Iteration number: [3710/4518] 82% | Training loss: 0.6869700205936586
Epoch: 58 | Iteration number: [3720/4518] 82% | Training loss: 0.6869692340493202
Epoch: 58 | Iteration number: [3730/4518] 82% | Training loss: 0.6869737717005906
Epoch: 58 | Iteration number: [3740/4518] 82% | Training loss: 0.6869704986797934
Epoch: 58 | Iteration number: [3750/4518] 83% | Training loss: 0.6869735619068146
Epoch: 58 | Iteration number: [3760/4518] 83% | Training loss: 0.6869738990639118
Epoch: 58 | Iteration number: [3770/4518] 83% | Training loss: 0.686970704667448
Epoch: 58 | Iteration number: [3780/4518] 83% | Training loss: 0.6869692439597751
Epoch: 58 | Iteration number: [3790/4518] 83% | Training loss: 0.6869699332833604
Epoch: 58 | Iteration number: [3800/4518] 84% | Training loss: 0.6869680816248843
Epoch: 58 | Iteration number: [3810/4518] 84% | Training loss: 0.6869699783525441
Epoch: 58 | Iteration number: [3820/4518] 84% | Training loss: 0.6869705622576918
Epoch: 58 | Iteration number: [3830/4518] 84% | Training loss: 0.686969324876372
Epoch: 58 | Iteration number: [3840/4518] 84% | Training loss: 0.6869696756824851
Epoch: 58 | Iteration number: [3850/4518] 85% | Training loss: 0.6869683937283305
Epoch: 58 | Iteration number: [3860/4518] 85% | Training loss: 0.6869662808939583
Epoch: 58 | Iteration number: [3870/4518] 85% | Training loss: 0.6869640978269799
Epoch: 58 | Iteration number: [3880/4518] 85% | Training loss: 0.6869649450035439
Epoch: 58 | Iteration number: [3890/4518] 86% | Training loss: 0.68696413844594
Epoch: 58 | Iteration number: [3900/4518] 86% | Training loss: 0.6869635219451709
Epoch: 58 | Iteration number: [3910/4518] 86% | Training loss: 0.686961409213293
Epoch: 58 | Iteration number: [3920/4518] 86% | Training loss: 0.6869610400072166
Epoch: 58 | Iteration number: [3930/4518] 86% | Training loss: 0.6869584157721687
Epoch: 58 | Iteration number: [3940/4518] 87% | Training loss: 0.6869579540896537
Epoch: 58 | Iteration number: [3950/4518] 87% | Training loss: 0.68695847894572
Epoch: 58 | Iteration number: [3960/4518] 87% | Training loss: 0.6869582707081178
Epoch: 58 | Iteration number: [3970/4518] 87% | Training loss: 0.686958723764876
Epoch: 58 | Iteration number: [3980/4518] 88% | Training loss: 0.6869597342295862
Epoch: 58 | Iteration number: [3990/4518] 88% | Training loss: 0.6869570425578526
Epoch: 58 | Iteration number: [4000/4518] 88% | Training loss: 0.6869548496752977
Epoch: 58 | Iteration number: [4010/4518] 88% | Training loss: 0.6869568945463757
Epoch: 58 | Iteration number: [4020/4518] 88% | Training loss: 0.6869577646255494
Epoch: 58 | Iteration number: [4030/4518] 89% | Training loss: 0.6869561326119208
Epoch: 58 | Iteration number: [4040/4518] 89% | Training loss: 0.686954222368722
Epoch: 58 | Iteration number: [4050/4518] 89% | Training loss: 0.6869522135346025
Epoch: 58 | Iteration number: [4060/4518] 89% | Training loss: 0.6869509875774383
Epoch: 58 | Iteration number: [4070/4518] 90% | Training loss: 0.6869512217782932
Epoch: 58 | Iteration number: [4080/4518] 90% | Training loss: 0.6869546529855214
Epoch: 58 | Iteration number: [4090/4518] 90% | Training loss: 0.686951192477513
Epoch: 58 | Iteration number: [4100/4518] 90% | Training loss: 0.6869495157497685
Epoch: 58 | Iteration number: [4110/4518] 90% | Training loss: 0.6869476268616326
Epoch: 58 | Iteration number: [4120/4518] 91% | Training loss: 0.68694716295571
Epoch: 58 | Iteration number: [4130/4518] 91% | Training loss: 0.6869482635730115
Epoch: 58 | Iteration number: [4140/4518] 91% | Training loss: 0.6869479676951533
Epoch: 58 | Iteration number: [4150/4518] 91% | Training loss: 0.6869480115390686
Epoch: 58 | Iteration number: [4160/4518] 92% | Training loss: 0.686947391483073
Epoch: 58 | Iteration number: [4170/4518] 92% | Training loss: 0.6869441953351457
Epoch: 58 | Iteration number: [4180/4518] 92% | Training loss: 0.6869423711841757
Epoch: 58 | Iteration number: [4190/4518] 92% | Training loss: 0.6869407016081571
Epoch: 58 | Iteration number: [4200/4518] 92% | Training loss: 0.6869405212288812
Epoch: 58 | Iteration number: [4210/4518] 93% | Training loss: 0.6869369368796677
Epoch: 58 | Iteration number: [4220/4518] 93% | Training loss: 0.6869390570580677
Epoch: 58 | Iteration number: [4230/4518] 93% | Training loss: 0.686939043708445
Epoch: 58 | Iteration number: [4240/4518] 93% | Training loss: 0.6869386876950849
Epoch: 58 | Iteration number: [4250/4518] 94% | Training loss: 0.6869397589739631
Epoch: 58 | Iteration number: [4260/4518] 94% | Training loss: 0.686942261233576
Epoch: 58 | Iteration number: [4270/4518] 94% | Training loss: 0.6869439491622621
Epoch: 58 | Iteration number: [4280/4518] 94% | Training loss: 0.6869435767843345
Epoch: 58 | Iteration number: [4290/4518] 94% | Training loss: 0.6869425345273007
Epoch: 58 | Iteration number: [4300/4518] 95% | Training loss: 0.6869401769444
Epoch: 58 | Iteration number: [4310/4518] 95% | Training loss: 0.6869415923918483
Epoch: 58 | Iteration number: [4320/4518] 95% | Training loss: 0.6869439965734879
Epoch: 58 | Iteration number: [4330/4518] 95% | Training loss: 0.6869443343087652
Epoch: 58 | Iteration number: [4340/4518] 96% | Training loss: 0.686943704329328
Epoch: 58 | Iteration number: [4350/4518] 96% | Training loss: 0.6869455059232383
Epoch: 58 | Iteration number: [4360/4518] 96% | Training loss: 0.6869470496653417
Epoch: 58 | Iteration number: [4370/4518] 96% | Training loss: 0.6869452463134749
Epoch: 58 | Iteration number: [4380/4518] 96% | Training loss: 0.6869449232675169
Epoch: 58 | Iteration number: [4390/4518] 97% | Training loss: 0.6869456227928197
Epoch: 58 | Iteration number: [4400/4518] 97% | Training loss: 0.6869460437243635
Epoch: 58 | Iteration number: [4410/4518] 97% | Training loss: 0.6869481566000958
Epoch: 58 | Iteration number: [4420/4518] 97% | Training loss: 0.6869464022946034
Epoch: 58 | Iteration number: [4430/4518] 98% | Training loss: 0.6869447235598252
Epoch: 58 | Iteration number: [4440/4518] 98% | Training loss: 0.6869471590395446
Epoch: 58 | Iteration number: [4450/4518] 98% | Training loss: 0.6869474449586332
Epoch: 58 | Iteration number: [4460/4518] 98% | Training loss: 0.686948881862944
Epoch: 58 | Iteration number: [4470/4518] 98% | Training loss: 0.6869489354308553
Epoch: 58 | Iteration number: [4480/4518] 99% | Training loss: 0.6869489728872266
Epoch: 58 | Iteration number: [4490/4518] 99% | Training loss: 0.6869497563764619
Epoch: 58 | Iteration number: [4500/4518] 99% | Training loss: 0.6869503084950976
Epoch: 58 | Iteration number: [4510/4518] 99% | Training loss: 0.6869519619878274

 End of epoch: 58 | Train Loss: 0.686800219359362 | Training Time: 642 

 End of epoch: 58 | Eval Loss: 0.6900811511643079 | Evaluating Time: 17 
Epoch: 59 | Iteration number: [10/4518] 0% | Training loss: 0.7545578181743622
Epoch: 59 | Iteration number: [20/4518] 0% | Training loss: 0.7207522183656693
Epoch: 59 | Iteration number: [30/4518] 0% | Training loss: 0.7094857434431712
Epoch: 59 | Iteration number: [40/4518] 0% | Training loss: 0.703657579421997
Epoch: 59 | Iteration number: [50/4518] 1% | Training loss: 0.700302722454071
Epoch: 59 | Iteration number: [60/4518] 1% | Training loss: 0.6981006731589635
Epoch: 59 | Iteration number: [70/4518] 1% | Training loss: 0.696482538325446
Epoch: 59 | Iteration number: [80/4518] 1% | Training loss: 0.6951699256896973
Epoch: 59 | Iteration number: [90/4518] 1% | Training loss: 0.694123262166977
Epoch: 59 | Iteration number: [100/4518] 2% | Training loss: 0.693362877368927
Epoch: 59 | Iteration number: [110/4518] 2% | Training loss: 0.6927622963081707
Epoch: 59 | Iteration number: [120/4518] 2% | Training loss: 0.6923158407211304
Epoch: 59 | Iteration number: [130/4518] 2% | Training loss: 0.6919631123542785
Epoch: 59 | Iteration number: [140/4518] 3% | Training loss: 0.6915727581296648
Epoch: 59 | Iteration number: [150/4518] 3% | Training loss: 0.6912551947434743
Epoch: 59 | Iteration number: [160/4518] 3% | Training loss: 0.691013291850686
Epoch: 59 | Iteration number: [170/4518] 3% | Training loss: 0.6907917180482079
Epoch: 59 | Iteration number: [180/4518] 3% | Training loss: 0.6905830952856276
Epoch: 59 | Iteration number: [190/4518] 4% | Training loss: 0.6904060652381495
Epoch: 59 | Iteration number: [200/4518] 4% | Training loss: 0.6902057400345802
Epoch: 59 | Iteration number: [210/4518] 4% | Training loss: 0.690034518355415
Epoch: 59 | Iteration number: [220/4518] 4% | Training loss: 0.6899445520205931
Epoch: 59 | Iteration number: [230/4518] 5% | Training loss: 0.6898668423942897
Epoch: 59 | Iteration number: [240/4518] 5% | Training loss: 0.689668727417787
Epoch: 59 | Iteration number: [250/4518] 5% | Training loss: 0.6895790646076202
Epoch: 59 | Iteration number: [260/4518] 5% | Training loss: 0.6894522192386481
Epoch: 59 | Iteration number: [270/4518] 5% | Training loss: 0.6893579529391395
Epoch: 59 | Iteration number: [280/4518] 6% | Training loss: 0.6892760161842618
Epoch: 59 | Iteration number: [290/4518] 6% | Training loss: 0.6891782343387604
Epoch: 59 | Iteration number: [300/4518] 6% | Training loss: 0.6890535128116607
Epoch: 59 | Iteration number: [310/4518] 6% | Training loss: 0.6889791504029305
Epoch: 59 | Iteration number: [320/4518] 7% | Training loss: 0.6889170153066516
Epoch: 59 | Iteration number: [330/4518] 7% | Training loss: 0.688867794564276
Epoch: 59 | Iteration number: [340/4518] 7% | Training loss: 0.6887761549038045
Epoch: 59 | Iteration number: [350/4518] 7% | Training loss: 0.6887427754061562
Epoch: 59 | Iteration number: [360/4518] 7% | Training loss: 0.6886829394433234
Epoch: 59 | Iteration number: [370/4518] 8% | Training loss: 0.6885865654494311
Epoch: 59 | Iteration number: [380/4518] 8% | Training loss: 0.6885510132500999
Epoch: 59 | Iteration number: [390/4518] 8% | Training loss: 0.688534537034157
Epoch: 59 | Iteration number: [400/4518] 8% | Training loss: 0.6884653948247432
Epoch: 59 | Iteration number: [410/4518] 9% | Training loss: 0.6884236927439527
Epoch: 59 | Iteration number: [420/4518] 9% | Training loss: 0.6883625863563447
Epoch: 59 | Iteration number: [430/4518] 9% | Training loss: 0.6883319637110067
Epoch: 59 | Iteration number: [440/4518] 9% | Training loss: 0.6882847628810189
Epoch: 59 | Iteration number: [450/4518] 9% | Training loss: 0.6882546099026998
Epoch: 59 | Iteration number: [460/4518] 10% | Training loss: 0.6882162962270819
Epoch: 59 | Iteration number: [470/4518] 10% | Training loss: 0.6881919290157075
Epoch: 59 | Iteration number: [480/4518] 10% | Training loss: 0.6881414959828059
Epoch: 59 | Iteration number: [490/4518] 10% | Training loss: 0.6881276580752159
Epoch: 59 | Iteration number: [500/4518] 11% | Training loss: 0.6880515801906586
Epoch: 59 | Iteration number: [510/4518] 11% | Training loss: 0.6880276767646565
Epoch: 59 | Iteration number: [520/4518] 11% | Training loss: 0.687985987846668
Epoch: 59 | Iteration number: [530/4518] 11% | Training loss: 0.6879652207752444
Epoch: 59 | Iteration number: [540/4518] 11% | Training loss: 0.6879459024579436
Epoch: 59 | Iteration number: [550/4518] 12% | Training loss: 0.6879087467627092
Epoch: 59 | Iteration number: [560/4518] 12% | Training loss: 0.6878776574773448
Epoch: 59 | Iteration number: [570/4518] 12% | Training loss: 0.6878717522872122
Epoch: 59 | Iteration number: [580/4518] 12% | Training loss: 0.6878266926469474
Epoch: 59 | Iteration number: [590/4518] 13% | Training loss: 0.6877849253557496
Epoch: 59 | Iteration number: [600/4518] 13% | Training loss: 0.6877854797244072
Epoch: 59 | Iteration number: [610/4518] 13% | Training loss: 0.6878006434831463
Epoch: 59 | Iteration number: [620/4518] 13% | Training loss: 0.6877975010102795
Epoch: 59 | Iteration number: [630/4518] 13% | Training loss: 0.6877690487437778
Epoch: 59 | Iteration number: [640/4518] 14% | Training loss: 0.687761057447642
Epoch: 59 | Iteration number: [650/4518] 14% | Training loss: 0.687750439277062
Epoch: 59 | Iteration number: [660/4518] 14% | Training loss: 0.6877316663662593
Epoch: 59 | Iteration number: [670/4518] 14% | Training loss: 0.6876982199611948
Epoch: 59 | Iteration number: [680/4518] 15% | Training loss: 0.6876817375421524
Epoch: 59 | Iteration number: [690/4518] 15% | Training loss: 0.6876606597416642
Epoch: 59 | Iteration number: [700/4518] 15% | Training loss: 0.6876541010822569
Epoch: 59 | Iteration number: [710/4518] 15% | Training loss: 0.6876331765047261
Epoch: 59 | Iteration number: [720/4518] 15% | Training loss: 0.6876215504275428
Epoch: 59 | Iteration number: [730/4518] 16% | Training loss: 0.6875919404911668
Epoch: 59 | Iteration number: [740/4518] 16% | Training loss: 0.6875714125665459
Epoch: 59 | Iteration number: [750/4518] 16% | Training loss: 0.6875398016770681
Epoch: 59 | Iteration number: [760/4518] 16% | Training loss: 0.6875355870315903
Epoch: 59 | Iteration number: [770/4518] 17% | Training loss: 0.6875251184810292
Epoch: 59 | Iteration number: [780/4518] 17% | Training loss: 0.6875205595523883
Epoch: 59 | Iteration number: [790/4518] 17% | Training loss: 0.6875263902205455
Epoch: 59 | Iteration number: [800/4518] 17% | Training loss: 0.6875139021128416
Epoch: 59 | Iteration number: [810/4518] 17% | Training loss: 0.6875092134799486
Epoch: 59 | Iteration number: [820/4518] 18% | Training loss: 0.6874919588972882
Epoch: 59 | Iteration number: [830/4518] 18% | Training loss: 0.6874600592866001
Epoch: 59 | Iteration number: [840/4518] 18% | Training loss: 0.687459528800987
Epoch: 59 | Iteration number: [850/4518] 18% | Training loss: 0.6874527823223787
Epoch: 59 | Iteration number: [860/4518] 19% | Training loss: 0.6874567078296528
Epoch: 59 | Iteration number: [870/4518] 19% | Training loss: 0.6874577063938667
Epoch: 59 | Iteration number: [880/4518] 19% | Training loss: 0.6874527342617511
Epoch: 59 | Iteration number: [890/4518] 19% | Training loss: 0.6874600017338657
Epoch: 59 | Iteration number: [900/4518] 19% | Training loss: 0.6874409580230713
Epoch: 59 | Iteration number: [910/4518] 20% | Training loss: 0.6874244180354443
Epoch: 59 | Iteration number: [920/4518] 20% | Training loss: 0.6874136852829352
Epoch: 59 | Iteration number: [930/4518] 20% | Training loss: 0.6873984315062082
Epoch: 59 | Iteration number: [940/4518] 20% | Training loss: 0.6873866832636772
Epoch: 59 | Iteration number: [950/4518] 21% | Training loss: 0.6873769901928148
Epoch: 59 | Iteration number: [960/4518] 21% | Training loss: 0.6873753544564049
Epoch: 59 | Iteration number: [970/4518] 21% | Training loss: 0.6873748779911356
Epoch: 59 | Iteration number: [980/4518] 21% | Training loss: 0.6873724226440702
Epoch: 59 | Iteration number: [990/4518] 21% | Training loss: 0.6873543177590226
Epoch: 59 | Iteration number: [1000/4518] 22% | Training loss: 0.6873500269055367
Epoch: 59 | Iteration number: [1010/4518] 22% | Training loss: 0.6873452672863951
Epoch: 59 | Iteration number: [1020/4518] 22% | Training loss: 0.687335241542143
Epoch: 59 | Iteration number: [1030/4518] 22% | Training loss: 0.6873286588678083
Epoch: 59 | Iteration number: [1040/4518] 23% | Training loss: 0.6873190373755418
Epoch: 59 | Iteration number: [1050/4518] 23% | Training loss: 0.6873065805435181
Epoch: 59 | Iteration number: [1060/4518] 23% | Training loss: 0.6873068474936035
Epoch: 59 | Iteration number: [1070/4518] 23% | Training loss: 0.687308887065014
Epoch: 59 | Iteration number: [1080/4518] 23% | Training loss: 0.6873194345169598
Epoch: 59 | Iteration number: [1090/4518] 24% | Training loss: 0.6873198131355671
Epoch: 59 | Iteration number: [1100/4518] 24% | Training loss: 0.687306999835101
Epoch: 59 | Iteration number: [1110/4518] 24% | Training loss: 0.6873037666350872
Epoch: 59 | Iteration number: [1120/4518] 24% | Training loss: 0.6872850344649383
Epoch: 59 | Iteration number: [1130/4518] 25% | Training loss: 0.6872923808815204
Epoch: 59 | Iteration number: [1140/4518] 25% | Training loss: 0.6872928191172449
Epoch: 59 | Iteration number: [1150/4518] 25% | Training loss: 0.6872876216017682
Epoch: 59 | Iteration number: [1160/4518] 25% | Training loss: 0.6872945381135777
Epoch: 59 | Iteration number: [1170/4518] 25% | Training loss: 0.6872870445251464
Epoch: 59 | Iteration number: [1180/4518] 26% | Training loss: 0.6872845477471917
Epoch: 59 | Iteration number: [1190/4518] 26% | Training loss: 0.6872689819135586
Epoch: 59 | Iteration number: [1200/4518] 26% | Training loss: 0.6872727271914482
Epoch: 59 | Iteration number: [1210/4518] 26% | Training loss: 0.6872592528004292
Epoch: 59 | Iteration number: [1220/4518] 27% | Training loss: 0.6872644512379755
Epoch: 59 | Iteration number: [1230/4518] 27% | Training loss: 0.6872731453519526
Epoch: 59 | Iteration number: [1240/4518] 27% | Training loss: 0.6872684261971904
Epoch: 59 | Iteration number: [1250/4518] 27% | Training loss: 0.6872687322616577
Epoch: 59 | Iteration number: [1260/4518] 27% | Training loss: 0.6872668825444721
Epoch: 59 | Iteration number: [1270/4518] 28% | Training loss: 0.687265297043042
Epoch: 59 | Iteration number: [1280/4518] 28% | Training loss: 0.6872595535125583
Epoch: 59 | Iteration number: [1290/4518] 28% | Training loss: 0.6872603824434355
Epoch: 59 | Iteration number: [1300/4518] 28% | Training loss: 0.6872517730639531
Epoch: 59 | Iteration number: [1310/4518] 28% | Training loss: 0.6872527158442344
Epoch: 59 | Iteration number: [1320/4518] 29% | Training loss: 0.6872466627847065
Epoch: 59 | Iteration number: [1330/4518] 29% | Training loss: 0.6872420145156688
Epoch: 59 | Iteration number: [1340/4518] 29% | Training loss: 0.6872401072018182
Epoch: 59 | Iteration number: [1350/4518] 29% | Training loss: 0.6872482208852415
Epoch: 59 | Iteration number: [1360/4518] 30% | Training loss: 0.6872342359055491
Epoch: 59 | Iteration number: [1370/4518] 30% | Training loss: 0.6872311792669505
Epoch: 59 | Iteration number: [1380/4518] 30% | Training loss: 0.6872326827999474
Epoch: 59 | Iteration number: [1390/4518] 30% | Training loss: 0.6872375101494275
Epoch: 59 | Iteration number: [1400/4518] 30% | Training loss: 0.6872368050473077
Epoch: 59 | Iteration number: [1410/4518] 31% | Training loss: 0.6872346389800944
Epoch: 59 | Iteration number: [1420/4518] 31% | Training loss: 0.687229176390339
Epoch: 59 | Iteration number: [1430/4518] 31% | Training loss: 0.687231575525724
Epoch: 59 | Iteration number: [1440/4518] 31% | Training loss: 0.687229219575723
Epoch: 59 | Iteration number: [1450/4518] 32% | Training loss: 0.6872201171414606
Epoch: 59 | Iteration number: [1460/4518] 32% | Training loss: 0.6872210566311666
Epoch: 59 | Iteration number: [1470/4518] 32% | Training loss: 0.6872179866242571
Epoch: 59 | Iteration number: [1480/4518] 32% | Training loss: 0.6872219930629473
Epoch: 59 | Iteration number: [1490/4518] 32% | Training loss: 0.6872190679479765
Epoch: 59 | Iteration number: [1500/4518] 33% | Training loss: 0.6872148778438568
Epoch: 59 | Iteration number: [1510/4518] 33% | Training loss: 0.6872156574631368
Epoch: 59 | Iteration number: [1520/4518] 33% | Training loss: 0.6872166383423304
Epoch: 59 | Iteration number: [1530/4518] 33% | Training loss: 0.6872057916292178
Epoch: 59 | Iteration number: [1540/4518] 34% | Training loss: 0.6872018377889286
Epoch: 59 | Iteration number: [1550/4518] 34% | Training loss: 0.6871978960498687
Epoch: 59 | Iteration number: [1560/4518] 34% | Training loss: 0.6871902730984566
Epoch: 59 | Iteration number: [1570/4518] 34% | Training loss: 0.6871889388485319
Epoch: 59 | Iteration number: [1580/4518] 34% | Training loss: 0.6871867585408536
Epoch: 59 | Iteration number: [1590/4518] 35% | Training loss: 0.6871797159407873
Epoch: 59 | Iteration number: [1600/4518] 35% | Training loss: 0.6871764713898301
Epoch: 59 | Iteration number: [1610/4518] 35% | Training loss: 0.6871641943913809
Epoch: 59 | Iteration number: [1620/4518] 35% | Training loss: 0.6871574998269846
Epoch: 59 | Iteration number: [1630/4518] 36% | Training loss: 0.68715506905427
Epoch: 59 | Iteration number: [1640/4518] 36% | Training loss: 0.6871528837012082
Epoch: 59 | Iteration number: [1650/4518] 36% | Training loss: 0.6871545641350024
Epoch: 59 | Iteration number: [1660/4518] 36% | Training loss: 0.6871469379548567
Epoch: 59 | Iteration number: [1670/4518] 36% | Training loss: 0.6871485862546338
Epoch: 59 | Iteration number: [1680/4518] 37% | Training loss: 0.6871406864197481
Epoch: 59 | Iteration number: [1690/4518] 37% | Training loss: 0.6871355402399097
Epoch: 59 | Iteration number: [1700/4518] 37% | Training loss: 0.6871408744419323
Epoch: 59 | Iteration number: [1710/4518] 37% | Training loss: 0.6871395145591936
Epoch: 59 | Iteration number: [1720/4518] 38% | Training loss: 0.6871403734351313
Epoch: 59 | Iteration number: [1730/4518] 38% | Training loss: 0.6871324209119544
Epoch: 59 | Iteration number: [1740/4518] 38% | Training loss: 0.6871276430014907
Epoch: 59 | Iteration number: [1750/4518] 38% | Training loss: 0.6871280810151781
Epoch: 59 | Iteration number: [1760/4518] 38% | Training loss: 0.6871243567967956
Epoch: 59 | Iteration number: [1770/4518] 39% | Training loss: 0.6871231353552328
Epoch: 59 | Iteration number: [1780/4518] 39% | Training loss: 0.6871135025211934
Epoch: 59 | Iteration number: [1790/4518] 39% | Training loss: 0.6871202081275386
Epoch: 59 | Iteration number: [1800/4518] 39% | Training loss: 0.6871099655826887
Epoch: 59 | Iteration number: [1810/4518] 40% | Training loss: 0.6871081186592249
Epoch: 59 | Iteration number: [1820/4518] 40% | Training loss: 0.6871116601176315
Epoch: 59 | Iteration number: [1830/4518] 40% | Training loss: 0.6871077436241296
Epoch: 59 | Iteration number: [1840/4518] 40% | Training loss: 0.6871107412745123
Epoch: 59 | Iteration number: [1850/4518] 40% | Training loss: 0.6871061623740841
Epoch: 59 | Iteration number: [1860/4518] 41% | Training loss: 0.6871061876896889
Epoch: 59 | Iteration number: [1870/4518] 41% | Training loss: 0.6871118665378999
Epoch: 59 | Iteration number: [1880/4518] 41% | Training loss: 0.6871115169943647
Epoch: 59 | Iteration number: [1890/4518] 41% | Training loss: 0.6871124155937679
Epoch: 59 | Iteration number: [1900/4518] 42% | Training loss: 0.687109507886987
Epoch: 59 | Iteration number: [1910/4518] 42% | Training loss: 0.6870984225372994
Epoch: 59 | Iteration number: [1920/4518] 42% | Training loss: 0.6870932354902227
Epoch: 59 | Iteration number: [1930/4518] 42% | Training loss: 0.687087152195718
Epoch: 59 | Iteration number: [1940/4518] 42% | Training loss: 0.6870870141638923
Epoch: 59 | Iteration number: [1950/4518] 43% | Training loss: 0.6870812207613236
Epoch: 59 | Iteration number: [1960/4518] 43% | Training loss: 0.6870756802510242
Epoch: 59 | Iteration number: [1970/4518] 43% | Training loss: 0.6870766221569274
Epoch: 59 | Iteration number: [1980/4518] 43% | Training loss: 0.6870714933282197
Epoch: 59 | Iteration number: [1990/4518] 44% | Training loss: 0.6870695721863502
Epoch: 59 | Iteration number: [2000/4518] 44% | Training loss: 0.6870685210824012
Epoch: 59 | Iteration number: [2010/4518] 44% | Training loss: 0.68706974336757
Epoch: 59 | Iteration number: [2020/4518] 44% | Training loss: 0.687066500080694
Epoch: 59 | Iteration number: [2030/4518] 44% | Training loss: 0.6870701377027728
Epoch: 59 | Iteration number: [2040/4518] 45% | Training loss: 0.687072162797638
Epoch: 59 | Iteration number: [2050/4518] 45% | Training loss: 0.6870773482322693
Epoch: 59 | Iteration number: [2060/4518] 45% | Training loss: 0.6870795305782151
Epoch: 59 | Iteration number: [2070/4518] 45% | Training loss: 0.6870865008393348
Epoch: 59 | Iteration number: [2080/4518] 46% | Training loss: 0.6870803076773881
Epoch: 59 | Iteration number: [2090/4518] 46% | Training loss: 0.6870747188631998
Epoch: 59 | Iteration number: [2100/4518] 46% | Training loss: 0.6870781222979228
Epoch: 59 | Iteration number: [2110/4518] 46% | Training loss: 0.6870734174952123
Epoch: 59 | Iteration number: [2120/4518] 46% | Training loss: 0.687072159040649
Epoch: 59 | Iteration number: [2130/4518] 47% | Training loss: 0.6870733397667397
Epoch: 59 | Iteration number: [2140/4518] 47% | Training loss: 0.6870700562668738
Epoch: 59 | Iteration number: [2150/4518] 47% | Training loss: 0.6870643173262131
Epoch: 59 | Iteration number: [2160/4518] 47% | Training loss: 0.6870618579564272
Epoch: 59 | Iteration number: [2170/4518] 48% | Training loss: 0.6870562295485202
Epoch: 59 | Iteration number: [2180/4518] 48% | Training loss: 0.6870622518412564
Epoch: 59 | Iteration number: [2190/4518] 48% | Training loss: 0.6870588173877159
Epoch: 59 | Iteration number: [2200/4518] 48% | Training loss: 0.6870564210414887
Epoch: 59 | Iteration number: [2210/4518] 48% | Training loss: 0.6870527798234067
Epoch: 59 | Iteration number: [2220/4518] 49% | Training loss: 0.6870511087748381
Epoch: 59 | Iteration number: [2230/4518] 49% | Training loss: 0.6870525256935256
Epoch: 59 | Iteration number: [2240/4518] 49% | Training loss: 0.6870548051116722
Epoch: 59 | Iteration number: [2250/4518] 49% | Training loss: 0.6870542346901364
Epoch: 59 | Iteration number: [2260/4518] 50% | Training loss: 0.6870520123338277
Epoch: 59 | Iteration number: [2270/4518] 50% | Training loss: 0.6870499094677391
Epoch: 59 | Iteration number: [2280/4518] 50% | Training loss: 0.687042443689547
Epoch: 59 | Iteration number: [2290/4518] 50% | Training loss: 0.6870386832666189
Epoch: 59 | Iteration number: [2300/4518] 50% | Training loss: 0.6870416693583778
Epoch: 59 | Iteration number: [2310/4518] 51% | Training loss: 0.6870452694304577
Epoch: 59 | Iteration number: [2320/4518] 51% | Training loss: 0.6870401294323905
Epoch: 59 | Iteration number: [2330/4518] 51% | Training loss: 0.6870401686097419
Epoch: 59 | Iteration number: [2340/4518] 51% | Training loss: 0.6870440469338344
Epoch: 59 | Iteration number: [2350/4518] 52% | Training loss: 0.6870472685073284
Epoch: 59 | Iteration number: [2360/4518] 52% | Training loss: 0.6870449278819359
Epoch: 59 | Iteration number: [2370/4518] 52% | Training loss: 0.6870429184114882
Epoch: 59 | Iteration number: [2380/4518] 52% | Training loss: 0.6870421559870744
Epoch: 59 | Iteration number: [2390/4518] 52% | Training loss: 0.6870380665966657
Epoch: 59 | Iteration number: [2400/4518] 53% | Training loss: 0.6870343936483065
Epoch: 59 | Iteration number: [2410/4518] 53% | Training loss: 0.6870354413491562
Epoch: 59 | Iteration number: [2420/4518] 53% | Training loss: 0.6870332912226353
Epoch: 59 | Iteration number: [2430/4518] 53% | Training loss: 0.6870334894814119
Epoch: 59 | Iteration number: [2440/4518] 54% | Training loss: 0.6870347151502234
Epoch: 59 | Iteration number: [2450/4518] 54% | Training loss: 0.6870342908343491
Epoch: 59 | Iteration number: [2460/4518] 54% | Training loss: 0.6870388738023556
Epoch: 59 | Iteration number: [2470/4518] 54% | Training loss: 0.6870407648414736
Epoch: 59 | Iteration number: [2480/4518] 54% | Training loss: 0.6870372395361624
Epoch: 59 | Iteration number: [2490/4518] 55% | Training loss: 0.6870342036088307
Epoch: 59 | Iteration number: [2500/4518] 55% | Training loss: 0.6870380171775818
Epoch: 59 | Iteration number: [2510/4518] 55% | Training loss: 0.6870428811506446
Epoch: 59 | Iteration number: [2520/4518] 55% | Training loss: 0.6870399645633167
Epoch: 59 | Iteration number: [2530/4518] 55% | Training loss: 0.6870406972089775
Epoch: 59 | Iteration number: [2540/4518] 56% | Training loss: 0.6870416993231285
Epoch: 59 | Iteration number: [2550/4518] 56% | Training loss: 0.6870407657529793
Epoch: 59 | Iteration number: [2560/4518] 56% | Training loss: 0.6870379716390744
Epoch: 59 | Iteration number: [2570/4518] 56% | Training loss: 0.6870320734578812
Epoch: 59 | Iteration number: [2580/4518] 57% | Training loss: 0.687032369888106
Epoch: 59 | Iteration number: [2590/4518] 57% | Training loss: 0.687029452190436
Epoch: 59 | Iteration number: [2600/4518] 57% | Training loss: 0.6870302828917136
Epoch: 59 | Iteration number: [2610/4518] 57% | Training loss: 0.6870288124029664
Epoch: 59 | Iteration number: [2620/4518] 57% | Training loss: 0.6870233017524691
Epoch: 59 | Iteration number: [2630/4518] 58% | Training loss: 0.687019460872099
Epoch: 59 | Iteration number: [2640/4518] 58% | Training loss: 0.687020650347977
Epoch: 59 | Iteration number: [2650/4518] 58% | Training loss: 0.6870230646628254
Epoch: 59 | Iteration number: [2660/4518] 58% | Training loss: 0.6870232885045217
Epoch: 59 | Iteration number: [2670/4518] 59% | Training loss: 0.6870258077476802
Epoch: 59 | Iteration number: [2680/4518] 59% | Training loss: 0.6870252392407673
Epoch: 59 | Iteration number: [2690/4518] 59% | Training loss: 0.6870277745129894
Epoch: 59 | Iteration number: [2700/4518] 59% | Training loss: 0.6870152606566747
Epoch: 59 | Iteration number: [2710/4518] 59% | Training loss: 0.6870147547158808
Epoch: 59 | Iteration number: [2720/4518] 60% | Training loss: 0.6870116029153852
Epoch: 59 | Iteration number: [2730/4518] 60% | Training loss: 0.6870155151073749
Epoch: 59 | Iteration number: [2740/4518] 60% | Training loss: 0.6870147040725625
Epoch: 59 | Iteration number: [2750/4518] 60% | Training loss: 0.6870112046328458
Epoch: 59 | Iteration number: [2760/4518] 61% | Training loss: 0.6870141692999481
Epoch: 59 | Iteration number: [2770/4518] 61% | Training loss: 0.6870107216740343
Epoch: 59 | Iteration number: [2780/4518] 61% | Training loss: 0.6870105282437029
Epoch: 59 | Iteration number: [2790/4518] 61% | Training loss: 0.6870063908424856
Epoch: 59 | Iteration number: [2800/4518] 61% | Training loss: 0.6870109109367644
Epoch: 59 | Iteration number: [2810/4518] 62% | Training loss: 0.687013285164307
Epoch: 59 | Iteration number: [2820/4518] 62% | Training loss: 0.6870092495958856
Epoch: 59 | Iteration number: [2830/4518] 62% | Training loss: 0.6870069060856377
Epoch: 59 | Iteration number: [2840/4518] 62% | Training loss: 0.6870072558522224
Epoch: 59 | Iteration number: [2850/4518] 63% | Training loss: 0.6870057033237658
Epoch: 59 | Iteration number: [2860/4518] 63% | Training loss: 0.687006892045061
Epoch: 59 | Iteration number: [2870/4518] 63% | Training loss: 0.687003929793627
Epoch: 59 | Iteration number: [2880/4518] 63% | Training loss: 0.6870007819185654
Epoch: 59 | Iteration number: [2890/4518] 63% | Training loss: 0.6869997641207025
Epoch: 59 | Iteration number: [2900/4518] 64% | Training loss: 0.6869941556864771
Epoch: 59 | Iteration number: [2910/4518] 64% | Training loss: 0.686994062338498
Epoch: 59 | Iteration number: [2920/4518] 64% | Training loss: 0.6869951477810128
Epoch: 59 | Iteration number: [2930/4518] 64% | Training loss: 0.6869922625326866
Epoch: 59 | Iteration number: [2940/4518] 65% | Training loss: 0.6869926376002176
Epoch: 59 | Iteration number: [2950/4518] 65% | Training loss: 0.686992175619481
Epoch: 59 | Iteration number: [2960/4518] 65% | Training loss: 0.6869921933356169
Epoch: 59 | Iteration number: [2970/4518] 65% | Training loss: 0.6869926429557479
Epoch: 59 | Iteration number: [2980/4518] 65% | Training loss: 0.686991204931432
Epoch: 59 | Iteration number: [2990/4518] 66% | Training loss: 0.6869906959525718
Epoch: 59 | Iteration number: [3000/4518] 66% | Training loss: 0.6869895383119583
Epoch: 59 | Iteration number: [3010/4518] 66% | Training loss: 0.6869891509859268
Epoch: 59 | Iteration number: [3020/4518] 66% | Training loss: 0.6869868414883582
Epoch: 59 | Iteration number: [3030/4518] 67% | Training loss: 0.6869871278997302
Epoch: 59 | Iteration number: [3040/4518] 67% | Training loss: 0.6869841150351261
Epoch: 59 | Iteration number: [3050/4518] 67% | Training loss: 0.686980928299857
Epoch: 59 | Iteration number: [3060/4518] 67% | Training loss: 0.6869794635406506
Epoch: 59 | Iteration number: [3070/4518] 67% | Training loss: 0.6869770354673218
Epoch: 59 | Iteration number: [3080/4518] 68% | Training loss: 0.6869777640545524
Epoch: 59 | Iteration number: [3090/4518] 68% | Training loss: 0.6869773947498173
Epoch: 59 | Iteration number: [3100/4518] 68% | Training loss: 0.6869756245805371
Epoch: 59 | Iteration number: [3110/4518] 68% | Training loss: 0.6869775567982358
Epoch: 59 | Iteration number: [3120/4518] 69% | Training loss: 0.6869746790673488
Epoch: 59 | Iteration number: [3130/4518] 69% | Training loss: 0.6869777411127242
Epoch: 59 | Iteration number: [3140/4518] 69% | Training loss: 0.6869776097072917
Epoch: 59 | Iteration number: [3150/4518] 69% | Training loss: 0.6869780185298314
Epoch: 59 | Iteration number: [3160/4518] 69% | Training loss: 0.6869690861505798
Epoch: 59 | Iteration number: [3170/4518] 70% | Training loss: 0.6869705048269278
Epoch: 59 | Iteration number: [3180/4518] 70% | Training loss: 0.6869690825916687
Epoch: 59 | Iteration number: [3190/4518] 70% | Training loss: 0.686965227967893
Epoch: 59 | Iteration number: [3200/4518] 70% | Training loss: 0.6869682304561138
Epoch: 59 | Iteration number: [3210/4518] 71% | Training loss: 0.6869654179919175
Epoch: 59 | Iteration number: [3220/4518] 71% | Training loss: 0.6869641571681692
Epoch: 59 | Iteration number: [3230/4518] 71% | Training loss: 0.6869629787217721
Epoch: 59 | Iteration number: [3240/4518] 71% | Training loss: 0.6869644461774532
Epoch: 59 | Iteration number: [3250/4518] 71% | Training loss: 0.6869655745946444
Epoch: 59 | Iteration number: [3260/4518] 72% | Training loss: 0.6869629365169198
Epoch: 59 | Iteration number: [3270/4518] 72% | Training loss: 0.686963539404242
Epoch: 59 | Iteration number: [3280/4518] 72% | Training loss: 0.6869639091193676
Epoch: 59 | Iteration number: [3290/4518] 72% | Training loss: 0.6869651014862814
Epoch: 59 | Iteration number: [3300/4518] 73% | Training loss: 0.6869647773829374
Epoch: 59 | Iteration number: [3310/4518] 73% | Training loss: 0.6869605066552983
Epoch: 59 | Iteration number: [3320/4518] 73% | Training loss: 0.6869589963950307
Epoch: 59 | Iteration number: [3330/4518] 73% | Training loss: 0.6869590336675042
Epoch: 59 | Iteration number: [3340/4518] 73% | Training loss: 0.6869563901852704
Epoch: 59 | Iteration number: [3350/4518] 74% | Training loss: 0.6869595278199039
Epoch: 59 | Iteration number: [3360/4518] 74% | Training loss: 0.686960599926256
Epoch: 59 | Iteration number: [3370/4518] 74% | Training loss: 0.6869641186044902
Epoch: 59 | Iteration number: [3380/4518] 74% | Training loss: 0.686962021666871
Epoch: 59 | Iteration number: [3390/4518] 75% | Training loss: 0.686957827342295
Epoch: 59 | Iteration number: [3400/4518] 75% | Training loss: 0.6869596403661896
Epoch: 59 | Iteration number: [3410/4518] 75% | Training loss: 0.6869608552399968
Epoch: 59 | Iteration number: [3420/4518] 75% | Training loss: 0.686956609393421
Epoch: 59 | Iteration number: [3430/4518] 75% | Training loss: 0.6869609389464987
Epoch: 59 | Iteration number: [3440/4518] 76% | Training loss: 0.6869597211480141
Epoch: 59 | Iteration number: [3450/4518] 76% | Training loss: 0.6869573520577472
Epoch: 59 | Iteration number: [3460/4518] 76% | Training loss: 0.6869566337393888
Epoch: 59 | Iteration number: [3470/4518] 76% | Training loss: 0.6869562187524625
Epoch: 59 | Iteration number: [3480/4518] 77% | Training loss: 0.6869562481669174
Epoch: 59 | Iteration number: [3490/4518] 77% | Training loss: 0.6869569492374246
Epoch: 59 | Iteration number: [3500/4518] 77% | Training loss: 0.6869613196849823
Epoch: 59 | Iteration number: [3510/4518] 77% | Training loss: 0.686960003620539
Epoch: 59 | Iteration number: [3520/4518] 77% | Training loss: 0.6869574979116971
Epoch: 59 | Iteration number: [3530/4518] 78% | Training loss: 0.6869591339451733
Epoch: 59 | Iteration number: [3540/4518] 78% | Training loss: 0.6869610979227023
Epoch: 59 | Iteration number: [3550/4518] 78% | Training loss: 0.6869606929933522
Epoch: 59 | Iteration number: [3560/4518] 78% | Training loss: 0.6869613589865438
Epoch: 59 | Iteration number: [3570/4518] 79% | Training loss: 0.6869620001950518
Epoch: 59 | Iteration number: [3580/4518] 79% | Training loss: 0.6869655376206563
Epoch: 59 | Iteration number: [3590/4518] 79% | Training loss: 0.6869629445348278
Epoch: 59 | Iteration number: [3600/4518] 79% | Training loss: 0.6869594195981821
Epoch: 59 | Iteration number: [3610/4518] 79% | Training loss: 0.6869588500079686
Epoch: 59 | Iteration number: [3620/4518] 80% | Training loss: 0.68695679530913
Epoch: 59 | Iteration number: [3630/4518] 80% | Training loss: 0.6869584357442935
Epoch: 59 | Iteration number: [3640/4518] 80% | Training loss: 0.6869551645202951
Epoch: 59 | Iteration number: [3650/4518] 80% | Training loss: 0.6869572510294718
Epoch: 59 | Iteration number: [3660/4518] 81% | Training loss: 0.6869562301153693
Epoch: 59 | Iteration number: [3670/4518] 81% | Training loss: 0.6869538078840812
Epoch: 59 | Iteration number: [3680/4518] 81% | Training loss: 0.6869529969180408
Epoch: 59 | Iteration number: [3690/4518] 81% | Training loss: 0.6869532888982354
Epoch: 59 | Iteration number: [3700/4518] 81% | Training loss: 0.6869554994396261
Epoch: 59 | Iteration number: [3710/4518] 82% | Training loss: 0.6869557199613103
Epoch: 59 | Iteration number: [3720/4518] 82% | Training loss: 0.686957092871589
Epoch: 59 | Iteration number: [3730/4518] 82% | Training loss: 0.6869573043115017
Epoch: 59 | Iteration number: [3740/4518] 82% | Training loss: 0.6869567639368741
Epoch: 59 | Iteration number: [3750/4518] 83% | Training loss: 0.6869573278745016
Epoch: 59 | Iteration number: [3760/4518] 83% | Training loss: 0.686959456129277
Epoch: 59 | Iteration number: [3770/4518] 83% | Training loss: 0.6869549945905923
Epoch: 59 | Iteration number: [3780/4518] 83% | Training loss: 0.6869536641886625
Epoch: 59 | Iteration number: [3790/4518] 83% | Training loss: 0.6869553968113771
Epoch: 59 | Iteration number: [3800/4518] 84% | Training loss: 0.6869559045371256
Epoch: 59 | Iteration number: [3810/4518] 84% | Training loss: 0.6869585145802636
Epoch: 59 | Iteration number: [3820/4518] 84% | Training loss: 0.6869600904237537
Epoch: 59 | Iteration number: [3830/4518] 84% | Training loss: 0.6869587763793786
Epoch: 59 | Iteration number: [3840/4518] 84% | Training loss: 0.686956525935481
Epoch: 59 | Iteration number: [3850/4518] 85% | Training loss: 0.6869590205031556
Epoch: 59 | Iteration number: [3860/4518] 85% | Training loss: 0.6869582536770272
Epoch: 59 | Iteration number: [3870/4518] 85% | Training loss: 0.6869604926238688
Epoch: 59 | Iteration number: [3880/4518] 85% | Training loss: 0.6869595566053981
Epoch: 59 | Iteration number: [3890/4518] 86% | Training loss: 0.6869593378357531
Epoch: 59 | Iteration number: [3900/4518] 86% | Training loss: 0.6869586399273995
Epoch: 59 | Iteration number: [3910/4518] 86% | Training loss: 0.6869587242603302
Epoch: 59 | Iteration number: [3920/4518] 86% | Training loss: 0.6869551187267109
Epoch: 59 | Iteration number: [3930/4518] 86% | Training loss: 0.6869559959752566
Epoch: 59 | Iteration number: [3940/4518] 87% | Training loss: 0.6869576580935929
Epoch: 59 | Iteration number: [3950/4518] 87% | Training loss: 0.6869584100306788
Epoch: 59 | Iteration number: [3960/4518] 87% | Training loss: 0.6869586610884377
Epoch: 59 | Iteration number: [3970/4518] 87% | Training loss: 0.6869594039784871
Epoch: 59 | Iteration number: [3980/4518] 88% | Training loss: 0.6869585416424814
Epoch: 59 | Iteration number: [3990/4518] 88% | Training loss: 0.686960802669812
Epoch: 59 | Iteration number: [4000/4518] 88% | Training loss: 0.6869593535065651
Epoch: 59 | Iteration number: [4010/4518] 88% | Training loss: 0.6869569527538043
Epoch: 59 | Iteration number: [4020/4518] 88% | Training loss: 0.6869569133318478
Epoch: 59 | Iteration number: [4030/4518] 89% | Training loss: 0.6869563791355483
Epoch: 59 | Iteration number: [4040/4518] 89% | Training loss: 0.686956089897321
Epoch: 59 | Iteration number: [4050/4518] 89% | Training loss: 0.6869564014893991
Epoch: 59 | Iteration number: [4060/4518] 89% | Training loss: 0.6869591405973059
Epoch: 59 | Iteration number: [4070/4518] 90% | Training loss: 0.6869585369816577
Epoch: 59 | Iteration number: [4080/4518] 90% | Training loss: 0.6869587198191998
Epoch: 59 | Iteration number: [4090/4518] 90% | Training loss: 0.686958011059423
Epoch: 59 | Iteration number: [4100/4518] 90% | Training loss: 0.6869577212449981
Epoch: 59 | Iteration number: [4110/4518] 90% | Training loss: 0.6869598963834943
Epoch: 59 | Iteration number: [4120/4518] 91% | Training loss: 0.68696010028853
Epoch: 59 | Iteration number: [4130/4518] 91% | Training loss: 0.6869620154902664
Epoch: 59 | Iteration number: [4140/4518] 91% | Training loss: 0.6869616563913327
Epoch: 59 | Iteration number: [4150/4518] 91% | Training loss: 0.6869616768159063
Epoch: 59 | Iteration number: [4160/4518] 92% | Training loss: 0.6869601383661994
Epoch: 59 | Iteration number: [4170/4518] 92% | Training loss: 0.6869598868224832
Epoch: 59 | Iteration number: [4180/4518] 92% | Training loss: 0.6869616222010845
Epoch: 59 | Iteration number: [4190/4518] 92% | Training loss: 0.6869595190647962
Epoch: 59 | Iteration number: [4200/4518] 92% | Training loss: 0.6869614758236068
Epoch: 59 | Iteration number: [4210/4518] 93% | Training loss: 0.6869599320259909
Epoch: 59 | Iteration number: [4220/4518] 93% | Training loss: 0.6869579599366934
Epoch: 59 | Iteration number: [4230/4518] 93% | Training loss: 0.6869547689778304
Epoch: 59 | Iteration number: [4240/4518] 93% | Training loss: 0.6869525671005249
Epoch: 59 | Iteration number: [4250/4518] 94% | Training loss: 0.6869513029210708
Epoch: 59 | Iteration number: [4260/4518] 94% | Training loss: 0.6869496574004491
Epoch: 59 | Iteration number: [4270/4518] 94% | Training loss: 0.6869494469997754
Epoch: 59 | Iteration number: [4280/4518] 94% | Training loss: 0.6869531276209332
Epoch: 59 | Iteration number: [4290/4518] 94% | Training loss: 0.6869534688534993
Epoch: 59 | Iteration number: [4300/4518] 95% | Training loss: 0.6869571191072464
Epoch: 59 | Iteration number: [4310/4518] 95% | Training loss: 0.68695394417526
Epoch: 59 | Iteration number: [4320/4518] 95% | Training loss: 0.6869566758611688
Epoch: 59 | Iteration number: [4330/4518] 95% | Training loss: 0.6869554969785395
Epoch: 59 | Iteration number: [4340/4518] 96% | Training loss: 0.6869548266247121
Epoch: 59 | Iteration number: [4350/4518] 96% | Training loss: 0.6869538371864407
Epoch: 59 | Iteration number: [4360/4518] 96% | Training loss: 0.6869555972448183
Epoch: 59 | Iteration number: [4370/4518] 96% | Training loss: 0.6869550013023874
Epoch: 59 | Iteration number: [4380/4518] 96% | Training loss: 0.6869549345616336
Epoch: 59 | Iteration number: [4390/4518] 97% | Training loss: 0.6869531618571227
Epoch: 59 | Iteration number: [4400/4518] 97% | Training loss: 0.686952691796151
Epoch: 59 | Iteration number: [4410/4518] 97% | Training loss: 0.6869523632012797
Epoch: 59 | Iteration number: [4420/4518] 97% | Training loss: 0.6869534236138762
Epoch: 59 | Iteration number: [4430/4518] 98% | Training loss: 0.6869513298399561
Epoch: 59 | Iteration number: [4440/4518] 98% | Training loss: 0.6869501784041121
Epoch: 59 | Iteration number: [4450/4518] 98% | Training loss: 0.6869498270013359
Epoch: 59 | Iteration number: [4460/4518] 98% | Training loss: 0.6869475259641895
Epoch: 59 | Iteration number: [4470/4518] 98% | Training loss: 0.6869476646918312
Epoch: 59 | Iteration number: [4480/4518] 99% | Training loss: 0.6869477462023497
Epoch: 59 | Iteration number: [4490/4518] 99% | Training loss: 0.6869509251053987
Epoch: 59 | Iteration number: [4500/4518] 99% | Training loss: 0.6869521226618025
Epoch: 59 | Iteration number: [4510/4518] 99% | Training loss: 0.6869478633821408

 End of epoch: 59 | Train Loss: 0.6867968916312527 | Training Time: 643 

 End of epoch: 59 | Eval Loss: 0.6900547755007841 | Evaluating Time: 17 
Epoch: 60 | Iteration number: [10/4518] 0% | Training loss: 0.7544050216674805
Epoch: 60 | Iteration number: [20/4518] 0% | Training loss: 0.720756185054779
Epoch: 60 | Iteration number: [30/4518] 0% | Training loss: 0.7095388631025951
Epoch: 60 | Iteration number: [40/4518] 0% | Training loss: 0.7036277458071709
Epoch: 60 | Iteration number: [50/4518] 1% | Training loss: 0.7003906214237213
Epoch: 60 | Iteration number: [60/4518] 1% | Training loss: 0.6979377160469691
Epoch: 60 | Iteration number: [70/4518] 1% | Training loss: 0.6962789586612157
Epoch: 60 | Iteration number: [80/4518] 1% | Training loss: 0.6952193915843964
Epoch: 60 | Iteration number: [90/4518] 1% | Training loss: 0.6942171924644046
Epoch: 60 | Iteration number: [100/4518] 2% | Training loss: 0.6934022688865662
Epoch: 60 | Iteration number: [110/4518] 2% | Training loss: 0.6927709194746885
Epoch: 60 | Iteration number: [120/4518] 2% | Training loss: 0.6922361006339391
Epoch: 60 | Iteration number: [130/4518] 2% | Training loss: 0.6917166338517116
Epoch: 60 | Iteration number: [140/4518] 3% | Training loss: 0.6913346282073429
Epoch: 60 | Iteration number: [150/4518] 3% | Training loss: 0.6911054702599844
Epoch: 60 | Iteration number: [160/4518] 3% | Training loss: 0.6907180655747652
Epoch: 60 | Iteration number: [170/4518] 3% | Training loss: 0.6904838046606849
Epoch: 60 | Iteration number: [180/4518] 3% | Training loss: 0.6902361114819845
Epoch: 60 | Iteration number: [190/4518] 4% | Training loss: 0.6901107101063979
Epoch: 60 | Iteration number: [200/4518] 4% | Training loss: 0.6899916356801987
Epoch: 60 | Iteration number: [210/4518] 4% | Training loss: 0.6898295953160241
Epoch: 60 | Iteration number: [220/4518] 4% | Training loss: 0.6897121667861938
Epoch: 60 | Iteration number: [230/4518] 5% | Training loss: 0.6895841655523881
Epoch: 60 | Iteration number: [240/4518] 5% | Training loss: 0.6894454141457875
Epoch: 60 | Iteration number: [250/4518] 5% | Training loss: 0.6893467319011688
Epoch: 60 | Iteration number: [260/4518] 5% | Training loss: 0.6892558306455612
Epoch: 60 | Iteration number: [270/4518] 5% | Training loss: 0.6891355587376489
Epoch: 60 | Iteration number: [280/4518] 6% | Training loss: 0.6890618126307215
Epoch: 60 | Iteration number: [290/4518] 6% | Training loss: 0.689001640985752
Epoch: 60 | Iteration number: [300/4518] 6% | Training loss: 0.688952908317248
Epoch: 60 | Iteration number: [310/4518] 6% | Training loss: 0.6888687749062815
Epoch: 60 | Iteration number: [320/4518] 7% | Training loss: 0.6887866785749793
Epoch: 60 | Iteration number: [330/4518] 7% | Training loss: 0.6887484888235728
Epoch: 60 | Iteration number: [340/4518] 7% | Training loss: 0.6887196395327063
Epoch: 60 | Iteration number: [350/4518] 7% | Training loss: 0.6886784393446787
Epoch: 60 | Iteration number: [360/4518] 7% | Training loss: 0.6886402659946018
Epoch: 60 | Iteration number: [370/4518] 8% | Training loss: 0.68859632579056
Epoch: 60 | Iteration number: [380/4518] 8% | Training loss: 0.6885270855928722
Epoch: 60 | Iteration number: [390/4518] 8% | Training loss: 0.68847932326488
Epoch: 60 | Iteration number: [400/4518] 8% | Training loss: 0.6884287293255329
Epoch: 60 | Iteration number: [410/4518] 9% | Training loss: 0.6883751172844956
Epoch: 60 | Iteration number: [420/4518] 9% | Training loss: 0.6883558927547364
Epoch: 60 | Iteration number: [430/4518] 9% | Training loss: 0.6883200311383536
Epoch: 60 | Iteration number: [440/4518] 9% | Training loss: 0.6883086761290377
Epoch: 60 | Iteration number: [450/4518] 9% | Training loss: 0.6882873190773858
Epoch: 60 | Iteration number: [460/4518] 10% | Training loss: 0.6882792291433915
Epoch: 60 | Iteration number: [470/4518] 10% | Training loss: 0.6882838189601899
Epoch: 60 | Iteration number: [480/4518] 10% | Training loss: 0.6882397023340067
Epoch: 60 | Iteration number: [490/4518] 10% | Training loss: 0.6882363995727228
Epoch: 60 | Iteration number: [500/4518] 11% | Training loss: 0.6881915583610535
Epoch: 60 | Iteration number: [510/4518] 11% | Training loss: 0.6881694357769162
Epoch: 60 | Iteration number: [520/4518] 11% | Training loss: 0.6881520921221146
Epoch: 60 | Iteration number: [530/4518] 11% | Training loss: 0.6881208635726065
Epoch: 60 | Iteration number: [540/4518] 11% | Training loss: 0.6880757963215863
Epoch: 60 | Iteration number: [550/4518] 12% | Training loss: 0.6880400083281777
Epoch: 60 | Iteration number: [560/4518] 12% | Training loss: 0.6880129917391709
Epoch: 60 | Iteration number: [570/4518] 12% | Training loss: 0.6880059588373753
Epoch: 60 | Iteration number: [580/4518] 12% | Training loss: 0.6879919863980392
Epoch: 60 | Iteration number: [590/4518] 13% | Training loss: 0.6879625551781412
Epoch: 60 | Iteration number: [600/4518] 13% | Training loss: 0.6879392336805662
Epoch: 60 | Iteration number: [610/4518] 13% | Training loss: 0.6879373952013548
Epoch: 60 | Iteration number: [620/4518] 13% | Training loss: 0.6879071868235065
Epoch: 60 | Iteration number: [630/4518] 13% | Training loss: 0.6878912410092732
Epoch: 60 | Iteration number: [640/4518] 14% | Training loss: 0.6878779558464885
Epoch: 60 | Iteration number: [650/4518] 14% | Training loss: 0.6878584693945371
Epoch: 60 | Iteration number: [660/4518] 14% | Training loss: 0.6878409619584228
Epoch: 60 | Iteration number: [670/4518] 14% | Training loss: 0.6878313117952489
Epoch: 60 | Iteration number: [680/4518] 15% | Training loss: 0.6878148928284645
Epoch: 60 | Iteration number: [690/4518] 15% | Training loss: 0.6878046008123868
Epoch: 60 | Iteration number: [700/4518] 15% | Training loss: 0.6877898366110665
Epoch: 60 | Iteration number: [710/4518] 15% | Training loss: 0.687756283014593
Epoch: 60 | Iteration number: [720/4518] 15% | Training loss: 0.6877411389516459
Epoch: 60 | Iteration number: [730/4518] 16% | Training loss: 0.6877276768423106
Epoch: 60 | Iteration number: [740/4518] 16% | Training loss: 0.6877133644915916
Epoch: 60 | Iteration number: [750/4518] 16% | Training loss: 0.6877097611427307
Epoch: 60 | Iteration number: [760/4518] 16% | Training loss: 0.6877096690629658
Epoch: 60 | Iteration number: [770/4518] 17% | Training loss: 0.6876967555516726
Epoch: 60 | Iteration number: [780/4518] 17% | Training loss: 0.6876735542065058
Epoch: 60 | Iteration number: [790/4518] 17% | Training loss: 0.6876481488535676
Epoch: 60 | Iteration number: [800/4518] 17% | Training loss: 0.6876510224491358
Epoch: 60 | Iteration number: [810/4518] 17% | Training loss: 0.6876335228666847
Epoch: 60 | Iteration number: [820/4518] 18% | Training loss: 0.6876181235400641
Epoch: 60 | Iteration number: [830/4518] 18% | Training loss: 0.687607518879764
Epoch: 60 | Iteration number: [840/4518] 18% | Training loss: 0.6875930567582448
Epoch: 60 | Iteration number: [850/4518] 18% | Training loss: 0.6875866161374484
Epoch: 60 | Iteration number: [860/4518] 19% | Training loss: 0.687565969519837
Epoch: 60 | Iteration number: [870/4518] 19% | Training loss: 0.6875597221412878
Epoch: 60 | Iteration number: [880/4518] 19% | Training loss: 0.6875455344265158
Epoch: 60 | Iteration number: [890/4518] 19% | Training loss: 0.6875364836682094
Epoch: 60 | Iteration number: [900/4518] 19% | Training loss: 0.6875269997119904
Epoch: 60 | Iteration number: [910/4518] 20% | Training loss: 0.6875222987526066
Epoch: 60 | Iteration number: [920/4518] 20% | Training loss: 0.6875118228404419
Epoch: 60 | Iteration number: [930/4518] 20% | Training loss: 0.6874908694656946
Epoch: 60 | Iteration number: [940/4518] 20% | Training loss: 0.687487707810199
Epoch: 60 | Iteration number: [950/4518] 21% | Training loss: 0.6874713386359967
Epoch: 60 | Iteration number: [960/4518] 21% | Training loss: 0.6874662172670166
Epoch: 60 | Iteration number: [970/4518] 21% | Training loss: 0.6874693251762194
Epoch: 60 | Iteration number: [980/4518] 21% | Training loss: 0.6874640863768908
Epoch: 60 | Iteration number: [990/4518] 21% | Training loss: 0.6874644316206074
Epoch: 60 | Iteration number: [1000/4518] 22% | Training loss: 0.6874582681059838
Epoch: 60 | Iteration number: [1010/4518] 22% | Training loss: 0.6874635928338116
Epoch: 60 | Iteration number: [1020/4518] 22% | Training loss: 0.687472367403554
Epoch: 60 | Iteration number: [1030/4518] 22% | Training loss: 0.6874693433636601
Epoch: 60 | Iteration number: [1040/4518] 23% | Training loss: 0.6874728062978157
Epoch: 60 | Iteration number: [1050/4518] 23% | Training loss: 0.6874668347267877
Epoch: 60 | Iteration number: [1060/4518] 23% | Training loss: 0.6874667862113917
Epoch: 60 | Iteration number: [1070/4518] 23% | Training loss: 0.6874619410973843
Epoch: 60 | Iteration number: [1080/4518] 23% | Training loss: 0.6874500531841208
Epoch: 60 | Iteration number: [1090/4518] 24% | Training loss: 0.6874448519781096
Epoch: 60 | Iteration number: [1100/4518] 24% | Training loss: 0.6874455247683958
Epoch: 60 | Iteration number: [1110/4518] 24% | Training loss: 0.6874443316244864
Epoch: 60 | Iteration number: [1120/4518] 24% | Training loss: 0.6874339605548552
Epoch: 60 | Iteration number: [1130/4518] 25% | Training loss: 0.6874347983735852
Epoch: 60 | Iteration number: [1140/4518] 25% | Training loss: 0.6874248433008529
Epoch: 60 | Iteration number: [1150/4518] 25% | Training loss: 0.6874186663523965
Epoch: 60 | Iteration number: [1160/4518] 25% | Training loss: 0.6874154631433815
Epoch: 60 | Iteration number: [1170/4518] 25% | Training loss: 0.6874128020726717
Epoch: 60 | Iteration number: [1180/4518] 26% | Training loss: 0.6874196394520291
Epoch: 60 | Iteration number: [1190/4518] 26% | Training loss: 0.6874096213268632
Epoch: 60 | Iteration number: [1200/4518] 26% | Training loss: 0.687391149799029
Epoch: 60 | Iteration number: [1210/4518] 26% | Training loss: 0.687388588426527
Epoch: 60 | Iteration number: [1220/4518] 27% | Training loss: 0.6873912266043366
Epoch: 60 | Iteration number: [1230/4518] 27% | Training loss: 0.6873815747780528
Epoch: 60 | Iteration number: [1240/4518] 27% | Training loss: 0.6873800910288288
Epoch: 60 | Iteration number: [1250/4518] 27% | Training loss: 0.6873827944278718
Epoch: 60 | Iteration number: [1260/4518] 27% | Training loss: 0.6873829327405445
Epoch: 60 | Iteration number: [1270/4518] 28% | Training loss: 0.6873705603944974
Epoch: 60 | Iteration number: [1280/4518] 28% | Training loss: 0.6873570147436112
Epoch: 60 | Iteration number: [1290/4518] 28% | Training loss: 0.6873549705789995
Epoch: 60 | Iteration number: [1300/4518] 28% | Training loss: 0.6873533189296722
Epoch: 60 | Iteration number: [1310/4518] 28% | Training loss: 0.6873650201404368
Epoch: 60 | Iteration number: [1320/4518] 29% | Training loss: 0.6873563729452364
Epoch: 60 | Iteration number: [1330/4518] 29% | Training loss: 0.6873463679077034
Epoch: 60 | Iteration number: [1340/4518] 29% | Training loss: 0.6873480505018091
Epoch: 60 | Iteration number: [1350/4518] 29% | Training loss: 0.6873369632385395
Epoch: 60 | Iteration number: [1360/4518] 30% | Training loss: 0.6873335209839484
Epoch: 60 | Iteration number: [1370/4518] 30% | Training loss: 0.6873307433441608
Epoch: 60 | Iteration number: [1380/4518] 30% | Training loss: 0.6873285897400068
Epoch: 60 | Iteration number: [1390/4518] 30% | Training loss: 0.6873257893881352
Epoch: 60 | Iteration number: [1400/4518] 30% | Training loss: 0.6873248301659312
Epoch: 60 | Iteration number: [1410/4518] 31% | Training loss: 0.6873098965232254
Epoch: 60 | Iteration number: [1420/4518] 31% | Training loss: 0.6873048514967234
Epoch: 60 | Iteration number: [1430/4518] 31% | Training loss: 0.6873014638473938
Epoch: 60 | Iteration number: [1440/4518] 31% | Training loss: 0.6872988620979918
Epoch: 60 | Iteration number: [1450/4518] 32% | Training loss: 0.6872890831684244
Epoch: 60 | Iteration number: [1460/4518] 32% | Training loss: 0.6872849593832068
Epoch: 60 | Iteration number: [1470/4518] 32% | Training loss: 0.6872781094645156
Epoch: 60 | Iteration number: [1480/4518] 32% | Training loss: 0.6872760882651484
Epoch: 60 | Iteration number: [1490/4518] 32% | Training loss: 0.6872707293337623
Epoch: 60 | Iteration number: [1500/4518] 33% | Training loss: 0.6872715144952138
Epoch: 60 | Iteration number: [1510/4518] 33% | Training loss: 0.6872669163918653
Epoch: 60 | Iteration number: [1520/4518] 33% | Training loss: 0.6872667389872827
Epoch: 60 | Iteration number: [1530/4518] 33% | Training loss: 0.6872646888876273
Epoch: 60 | Iteration number: [1540/4518] 34% | Training loss: 0.6872588859750078
Epoch: 60 | Iteration number: [1550/4518] 34% | Training loss: 0.687258024830972
Epoch: 60 | Iteration number: [1560/4518] 34% | Training loss: 0.6872589908731289
Epoch: 60 | Iteration number: [1570/4518] 34% | Training loss: 0.6872613300943071
Epoch: 60 | Iteration number: [1580/4518] 34% | Training loss: 0.6872551709413528
Epoch: 60 | Iteration number: [1590/4518] 35% | Training loss: 0.6872557071769763
Epoch: 60 | Iteration number: [1600/4518] 35% | Training loss: 0.6872530615702271
Epoch: 60 | Iteration number: [1610/4518] 35% | Training loss: 0.687258516816619
Epoch: 60 | Iteration number: [1620/4518] 35% | Training loss: 0.6872513410117891
Epoch: 60 | Iteration number: [1630/4518] 36% | Training loss: 0.6872519869745874
Epoch: 60 | Iteration number: [1640/4518] 36% | Training loss: 0.6872527043266994
Epoch: 60 | Iteration number: [1650/4518] 36% | Training loss: 0.6872517355644342
Epoch: 60 | Iteration number: [1660/4518] 36% | Training loss: 0.6872491788074194
Epoch: 60 | Iteration number: [1670/4518] 36% | Training loss: 0.6872457431105082
Epoch: 60 | Iteration number: [1680/4518] 37% | Training loss: 0.68724097098623
Epoch: 60 | Iteration number: [1690/4518] 37% | Training loss: 0.687236127980362
Epoch: 60 | Iteration number: [1700/4518] 37% | Training loss: 0.6872333360068938
Epoch: 60 | Iteration number: [1710/4518] 37% | Training loss: 0.6872388378918519
Epoch: 60 | Iteration number: [1720/4518] 38% | Training loss: 0.687230181901954
Epoch: 60 | Iteration number: [1730/4518] 38% | Training loss: 0.6872280637652888
Epoch: 60 | Iteration number: [1740/4518] 38% | Training loss: 0.6872208000599653
Epoch: 60 | Iteration number: [1750/4518] 38% | Training loss: 0.6872145560468946
Epoch: 60 | Iteration number: [1760/4518] 38% | Training loss: 0.6872148051857948
Epoch: 60 | Iteration number: [1770/4518] 39% | Training loss: 0.6872184932231903
Epoch: 60 | Iteration number: [1780/4518] 39% | Training loss: 0.6872159476695435
Epoch: 60 | Iteration number: [1790/4518] 39% | Training loss: 0.687212607813947
Epoch: 60 | Iteration number: [1800/4518] 39% | Training loss: 0.687203233341376
Epoch: 60 | Iteration number: [1810/4518] 40% | Training loss: 0.6872066397034661
Epoch: 60 | Iteration number: [1820/4518] 40% | Training loss: 0.687205001122349
Epoch: 60 | Iteration number: [1830/4518] 40% | Training loss: 0.6872011779110289
Epoch: 60 | Iteration number: [1840/4518] 40% | Training loss: 0.6872014720154845
Epoch: 60 | Iteration number: [1850/4518] 40% | Training loss: 0.6871996302862425
Epoch: 60 | Iteration number: [1860/4518] 41% | Training loss: 0.6871923805885417
Epoch: 60 | Iteration number: [1870/4518] 41% | Training loss: 0.6871887313172141
Epoch: 60 | Iteration number: [1880/4518] 41% | Training loss: 0.6871836885492852
Epoch: 60 | Iteration number: [1890/4518] 41% | Training loss: 0.6871818311630733
Epoch: 60 | Iteration number: [1900/4518] 42% | Training loss: 0.6871769484720732
Epoch: 60 | Iteration number: [1910/4518] 42% | Training loss: 0.6871763923093287
Epoch: 60 | Iteration number: [1920/4518] 42% | Training loss: 0.6871666683194538
Epoch: 60 | Iteration number: [1930/4518] 42% | Training loss: 0.6871601940127852
Epoch: 60 | Iteration number: [1940/4518] 42% | Training loss: 0.687161675648591
Epoch: 60 | Iteration number: [1950/4518] 43% | Training loss: 0.6871585781146319
Epoch: 60 | Iteration number: [1960/4518] 43% | Training loss: 0.6871595854966008
Epoch: 60 | Iteration number: [1970/4518] 43% | Training loss: 0.6871569345747759
Epoch: 60 | Iteration number: [1980/4518] 43% | Training loss: 0.687159606693971
Epoch: 60 | Iteration number: [1990/4518] 44% | Training loss: 0.6871560334859781
Epoch: 60 | Iteration number: [2000/4518] 44% | Training loss: 0.6871484322249889
Epoch: 60 | Iteration number: [2010/4518] 44% | Training loss: 0.6871428910179518
Epoch: 60 | Iteration number: [2020/4518] 44% | Training loss: 0.6871419176016703
Epoch: 60 | Iteration number: [2030/4518] 44% | Training loss: 0.6871417166857884
Epoch: 60 | Iteration number: [2040/4518] 45% | Training loss: 0.6871405275721176
Epoch: 60 | Iteration number: [2050/4518] 45% | Training loss: 0.6871386180272916
Epoch: 60 | Iteration number: [2060/4518] 45% | Training loss: 0.6871388562964004
Epoch: 60 | Iteration number: [2070/4518] 45% | Training loss: 0.687136564594536
Epoch: 60 | Iteration number: [2080/4518] 46% | Training loss: 0.6871383605668178
Epoch: 60 | Iteration number: [2090/4518] 46% | Training loss: 0.6871310169616954
Epoch: 60 | Iteration number: [2100/4518] 46% | Training loss: 0.6871238124086744
Epoch: 60 | Iteration number: [2110/4518] 46% | Training loss: 0.6871190159241735
Epoch: 60 | Iteration number: [2120/4518] 46% | Training loss: 0.6871225351432584
Epoch: 60 | Iteration number: [2130/4518] 47% | Training loss: 0.6871246070649143
Epoch: 60 | Iteration number: [2140/4518] 47% | Training loss: 0.6871224659904142
Epoch: 60 | Iteration number: [2150/4518] 47% | Training loss: 0.6871198322052179
Epoch: 60 | Iteration number: [2160/4518] 47% | Training loss: 0.6871254030753065
Epoch: 60 | Iteration number: [2170/4518] 48% | Training loss: 0.6871290332710688
Epoch: 60 | Iteration number: [2180/4518] 48% | Training loss: 0.6871251771482852
Epoch: 60 | Iteration number: [2190/4518] 48% | Training loss: 0.6871229031314589
Epoch: 60 | Iteration number: [2200/4518] 48% | Training loss: 0.6871271266720512
Epoch: 60 | Iteration number: [2210/4518] 48% | Training loss: 0.6871254686047049
Epoch: 60 | Iteration number: [2220/4518] 49% | Training loss: 0.6871253456349845
Epoch: 60 | Iteration number: [2230/4518] 49% | Training loss: 0.6871226633343461
Epoch: 60 | Iteration number: [2240/4518] 49% | Training loss: 0.6871248596480914
Epoch: 60 | Iteration number: [2250/4518] 49% | Training loss: 0.6871211238702138
Epoch: 60 | Iteration number: [2260/4518] 50% | Training loss: 0.6871205186949367
Epoch: 60 | Iteration number: [2270/4518] 50% | Training loss: 0.6871218267778993
Epoch: 60 | Iteration number: [2280/4518] 50% | Training loss: 0.6871182769798396
Epoch: 60 | Iteration number: [2290/4518] 50% | Training loss: 0.6871096984528038
Epoch: 60 | Iteration number: [2300/4518] 50% | Training loss: 0.6871071618795395
Epoch: 60 | Iteration number: [2310/4518] 51% | Training loss: 0.6871071835358937
Epoch: 60 | Iteration number: [2320/4518] 51% | Training loss: 0.687109853198816
Epoch: 60 | Iteration number: [2330/4518] 51% | Training loss: 0.6871126809601108
Epoch: 60 | Iteration number: [2340/4518] 51% | Training loss: 0.687108965893077
Epoch: 60 | Iteration number: [2350/4518] 52% | Training loss: 0.6871037724170279
Epoch: 60 | Iteration number: [2360/4518] 52% | Training loss: 0.6871050073181169
Epoch: 60 | Iteration number: [2370/4518] 52% | Training loss: 0.6871085424211961
Epoch: 60 | Iteration number: [2380/4518] 52% | Training loss: 0.6871105917862483
Epoch: 60 | Iteration number: [2390/4518] 52% | Training loss: 0.6871096749435409
Epoch: 60 | Iteration number: [2400/4518] 53% | Training loss: 0.6871036259581645
Epoch: 60 | Iteration number: [2410/4518] 53% | Training loss: 0.6871037345704202
Epoch: 60 | Iteration number: [2420/4518] 53% | Training loss: 0.6871021035042676
Epoch: 60 | Iteration number: [2430/4518] 53% | Training loss: 0.6870999786834168
Epoch: 60 | Iteration number: [2440/4518] 54% | Training loss: 0.687098822632774
Epoch: 60 | Iteration number: [2450/4518] 54% | Training loss: 0.6870990902793651
Epoch: 60 | Iteration number: [2460/4518] 54% | Training loss: 0.6870982706304488
Epoch: 60 | Iteration number: [2470/4518] 54% | Training loss: 0.6870950841228006
Epoch: 60 | Iteration number: [2480/4518] 54% | Training loss: 0.6870935776300968
Epoch: 60 | Iteration number: [2490/4518] 55% | Training loss: 0.687083592663807
Epoch: 60 | Iteration number: [2500/4518] 55% | Training loss: 0.6870849855899811
Epoch: 60 | Iteration number: [2510/4518] 55% | Training loss: 0.687092194139245
Epoch: 60 | Iteration number: [2520/4518] 55% | Training loss: 0.687089882554516
Epoch: 60 | Iteration number: [2530/4518] 55% | Training loss: 0.6870891735016593
Epoch: 60 | Iteration number: [2540/4518] 56% | Training loss: 0.6870913855672821
Epoch: 60 | Iteration number: [2550/4518] 56% | Training loss: 0.6870914201175465
Epoch: 60 | Iteration number: [2560/4518] 56% | Training loss: 0.687087522028014
Epoch: 60 | Iteration number: [2570/4518] 56% | Training loss: 0.6870883488005701
Epoch: 60 | Iteration number: [2580/4518] 57% | Training loss: 0.6870846410130346
Epoch: 60 | Iteration number: [2590/4518] 57% | Training loss: 0.6870845735303224
Epoch: 60 | Iteration number: [2600/4518] 57% | Training loss: 0.6870826700100532
Epoch: 60 | Iteration number: [2610/4518] 57% | Training loss: 0.6870779684905348
Epoch: 60 | Iteration number: [2620/4518] 57% | Training loss: 0.6870738065879763
Epoch: 60 | Iteration number: [2630/4518] 58% | Training loss: 0.6870748082947822
Epoch: 60 | Iteration number: [2640/4518] 58% | Training loss: 0.6870735706479261
Epoch: 60 | Iteration number: [2650/4518] 58% | Training loss: 0.6870669157774943
Epoch: 60 | Iteration number: [2660/4518] 58% | Training loss: 0.6870648448852669
Epoch: 60 | Iteration number: [2670/4518] 59% | Training loss: 0.6870642186997089
Epoch: 60 | Iteration number: [2680/4518] 59% | Training loss: 0.6870660447362643
Epoch: 60 | Iteration number: [2690/4518] 59% | Training loss: 0.6870701887128965
Epoch: 60 | Iteration number: [2700/4518] 59% | Training loss: 0.6870734475718604
Epoch: 60 | Iteration number: [2710/4518] 59% | Training loss: 0.6870732232653347
Epoch: 60 | Iteration number: [2720/4518] 60% | Training loss: 0.6870730025584206
Epoch: 60 | Iteration number: [2730/4518] 60% | Training loss: 0.6870704397613749
Epoch: 60 | Iteration number: [2740/4518] 60% | Training loss: 0.6870695620122618
Epoch: 60 | Iteration number: [2750/4518] 60% | Training loss: 0.6870672735300931
Epoch: 60 | Iteration number: [2760/4518] 61% | Training loss: 0.6870656363774037
Epoch: 60 | Iteration number: [2770/4518] 61% | Training loss: 0.687063251484172
Epoch: 60 | Iteration number: [2780/4518] 61% | Training loss: 0.6870605060522504
Epoch: 60 | Iteration number: [2790/4518] 61% | Training loss: 0.6870618396121542
Epoch: 60 | Iteration number: [2800/4518] 61% | Training loss: 0.6870644816117627
Epoch: 60 | Iteration number: [2810/4518] 62% | Training loss: 0.6870656190817891
Epoch: 60 | Iteration number: [2820/4518] 62% | Training loss: 0.6870641271273296
Epoch: 60 | Iteration number: [2830/4518] 62% | Training loss: 0.6870656326044574
Epoch: 60 | Iteration number: [2840/4518] 62% | Training loss: 0.6870642285951426
Epoch: 60 | Iteration number: [2850/4518] 63% | Training loss: 0.6870624845069752
Epoch: 60 | Iteration number: [2860/4518] 63% | Training loss: 0.6870576807877401
Epoch: 60 | Iteration number: [2870/4518] 63% | Training loss: 0.687058628934601
Epoch: 60 | Iteration number: [2880/4518] 63% | Training loss: 0.687058719019923
Epoch: 60 | Iteration number: [2890/4518] 63% | Training loss: 0.6870575123592232
Epoch: 60 | Iteration number: [2900/4518] 64% | Training loss: 0.6870530498438868
Epoch: 60 | Iteration number: [2910/4518] 64% | Training loss: 0.6870529770646309
Epoch: 60 | Iteration number: [2920/4518] 64% | Training loss: 0.6870510237878316
Epoch: 60 | Iteration number: [2930/4518] 64% | Training loss: 0.6870511809917034
Epoch: 60 | Iteration number: [2940/4518] 65% | Training loss: 0.6870494215869579
Epoch: 60 | Iteration number: [2950/4518] 65% | Training loss: 0.687053395408695
Epoch: 60 | Iteration number: [2960/4518] 65% | Training loss: 0.6870564448471005
Epoch: 60 | Iteration number: [2970/4518] 65% | Training loss: 0.6870569084629868
Epoch: 60 | Iteration number: [2980/4518] 65% | Training loss: 0.6870579370716274
Epoch: 60 | Iteration number: [2990/4518] 66% | Training loss: 0.6870573068741572
Epoch: 60 | Iteration number: [3000/4518] 66% | Training loss: 0.6870548678239187
Epoch: 60 | Iteration number: [3010/4518] 66% | Training loss: 0.6870543975568689
Epoch: 60 | Iteration number: [3020/4518] 66% | Training loss: 0.6870482879561304
Epoch: 60 | Iteration number: [3030/4518] 67% | Training loss: 0.6870522258502029
Epoch: 60 | Iteration number: [3040/4518] 67% | Training loss: 0.6870493023999428
Epoch: 60 | Iteration number: [3050/4518] 67% | Training loss: 0.6870510630920285
Epoch: 60 | Iteration number: [3060/4518] 67% | Training loss: 0.6870522607385723
Epoch: 60 | Iteration number: [3070/4518] 67% | Training loss: 0.6870482170232344
Epoch: 60 | Iteration number: [3080/4518] 68% | Training loss: 0.6870476846184049
Epoch: 60 | Iteration number: [3090/4518] 68% | Training loss: 0.6870456458295433
Epoch: 60 | Iteration number: [3100/4518] 68% | Training loss: 0.6870493957111913
Epoch: 60 | Iteration number: [3110/4518] 68% | Training loss: 0.687046957648452
Epoch: 60 | Iteration number: [3120/4518] 69% | Training loss: 0.6870453588855572
Epoch: 60 | Iteration number: [3130/4518] 69% | Training loss: 0.6870450312527605
Epoch: 60 | Iteration number: [3140/4518] 69% | Training loss: 0.6870458679594053
Epoch: 60 | Iteration number: [3150/4518] 69% | Training loss: 0.6870460548098125
Epoch: 60 | Iteration number: [3160/4518] 69% | Training loss: 0.6870450974453853
Epoch: 60 | Iteration number: [3170/4518] 70% | Training loss: 0.6870372110172777
Epoch: 60 | Iteration number: [3180/4518] 70% | Training loss: 0.6870380940864671
Epoch: 60 | Iteration number: [3190/4518] 70% | Training loss: 0.687040504673058
Epoch: 60 | Iteration number: [3200/4518] 70% | Training loss: 0.6870422700233757
Epoch: 60 | Iteration number: [3210/4518] 71% | Training loss: 0.6870356120424479
Epoch: 60 | Iteration number: [3220/4518] 71% | Training loss: 0.687035800581393
Epoch: 60 | Iteration number: [3230/4518] 71% | Training loss: 0.6870317956057864
Epoch: 60 | Iteration number: [3240/4518] 71% | Training loss: 0.6870307878027727
Epoch: 60 | Iteration number: [3250/4518] 71% | Training loss: 0.6870275524396163
Epoch: 60 | Iteration number: [3260/4518] 72% | Training loss: 0.6870331268551891
Epoch: 60 | Iteration number: [3270/4518] 72% | Training loss: 0.6870290944335657
Epoch: 60 | Iteration number: [3280/4518] 72% | Training loss: 0.687029936346339
Epoch: 60 | Iteration number: [3290/4518] 72% | Training loss: 0.6870299065547874
Epoch: 60 | Iteration number: [3300/4518] 73% | Training loss: 0.6870301615650004
Epoch: 60 | Iteration number: [3310/4518] 73% | Training loss: 0.6870266010754058
Epoch: 60 | Iteration number: [3320/4518] 73% | Training loss: 0.6870255380868912
Epoch: 60 | Iteration number: [3330/4518] 73% | Training loss: 0.6870249113879047
Epoch: 60 | Iteration number: [3340/4518] 73% | Training loss: 0.6870261746966196
Epoch: 60 | Iteration number: [3350/4518] 74% | Training loss: 0.6870229252772545
Epoch: 60 | Iteration number: [3360/4518] 74% | Training loss: 0.6870213635975406
Epoch: 60 | Iteration number: [3370/4518] 74% | Training loss: 0.6870226889937143
Epoch: 60 | Iteration number: [3380/4518] 74% | Training loss: 0.687018495075096
Epoch: 60 | Iteration number: [3390/4518] 75% | Training loss: 0.6870143243345187
Epoch: 60 | Iteration number: [3400/4518] 75% | Training loss: 0.6870152143871083
Epoch: 60 | Iteration number: [3410/4518] 75% | Training loss: 0.6870128991666777
Epoch: 60 | Iteration number: [3420/4518] 75% | Training loss: 0.6870109881399667
Epoch: 60 | Iteration number: [3430/4518] 75% | Training loss: 0.6870082078278934
Epoch: 60 | Iteration number: [3440/4518] 76% | Training loss: 0.6870066704618376
Epoch: 60 | Iteration number: [3450/4518] 76% | Training loss: 0.6870052243833956
Epoch: 60 | Iteration number: [3460/4518] 76% | Training loss: 0.6870032965275593
Epoch: 60 | Iteration number: [3470/4518] 76% | Training loss: 0.6870023705945578
Epoch: 60 | Iteration number: [3480/4518] 77% | Training loss: 0.6870022326022729
Epoch: 60 | Iteration number: [3490/4518] 77% | Training loss: 0.687001432764496
Epoch: 60 | Iteration number: [3500/4518] 77% | Training loss: 0.6869997559445244
Epoch: 60 | Iteration number: [3510/4518] 77% | Training loss: 0.6869976448707091
Epoch: 60 | Iteration number: [3520/4518] 77% | Training loss: 0.6869966549460184
Epoch: 60 | Iteration number: [3530/4518] 78% | Training loss: 0.6869965193460751
Epoch: 60 | Iteration number: [3540/4518] 78% | Training loss: 0.6869933630450297
Epoch: 60 | Iteration number: [3550/4518] 78% | Training loss: 0.6869909989330131
Epoch: 60 | Iteration number: [3560/4518] 78% | Training loss: 0.6869917333460925
Epoch: 60 | Iteration number: [3570/4518] 79% | Training loss: 0.6869915301559352
Epoch: 60 | Iteration number: [3580/4518] 79% | Training loss: 0.6869957154689554
Epoch: 60 | Iteration number: [3590/4518] 79% | Training loss: 0.6869910942644794
Epoch: 60 | Iteration number: [3600/4518] 79% | Training loss: 0.6869909948110581
Epoch: 60 | Iteration number: [3610/4518] 79% | Training loss: 0.6869899288273914
Epoch: 60 | Iteration number: [3620/4518] 80% | Training loss: 0.686989315092893
Epoch: 60 | Iteration number: [3630/4518] 80% | Training loss: 0.6869881373463255
Epoch: 60 | Iteration number: [3640/4518] 80% | Training loss: 0.686988405588564
Epoch: 60 | Iteration number: [3650/4518] 80% | Training loss: 0.6869860915778434
Epoch: 60 | Iteration number: [3660/4518] 81% | Training loss: 0.6869838717205277
Epoch: 60 | Iteration number: [3670/4518] 81% | Training loss: 0.6869790291916122
Epoch: 60 | Iteration number: [3680/4518] 81% | Training loss: 0.6869775650617869
Epoch: 60 | Iteration number: [3690/4518] 81% | Training loss: 0.686973709885667
Epoch: 60 | Iteration number: [3700/4518] 81% | Training loss: 0.6869726777076721
Epoch: 60 | Iteration number: [3710/4518] 82% | Training loss: 0.6869732605157837
Epoch: 60 | Iteration number: [3720/4518] 82% | Training loss: 0.6869710345422068
Epoch: 60 | Iteration number: [3730/4518] 82% | Training loss: 0.686970379317414
Epoch: 60 | Iteration number: [3740/4518] 82% | Training loss: 0.6869723702815764
Epoch: 60 | Iteration number: [3750/4518] 83% | Training loss: 0.6869710298220316
Epoch: 60 | Iteration number: [3760/4518] 83% | Training loss: 0.6869718530235138
Epoch: 60 | Iteration number: [3770/4518] 83% | Training loss: 0.6869749579884962
Epoch: 60 | Iteration number: [3780/4518] 83% | Training loss: 0.6869753528682012
Epoch: 60 | Iteration number: [3790/4518] 83% | Training loss: 0.6869755247809327
Epoch: 60 | Iteration number: [3800/4518] 84% | Training loss: 0.686971911615447
Epoch: 60 | Iteration number: [3810/4518] 84% | Training loss: 0.6869706558743174
Epoch: 60 | Iteration number: [3820/4518] 84% | Training loss: 0.6869691187954698
Epoch: 60 | Iteration number: [3830/4518] 84% | Training loss: 0.6869691635858919
Epoch: 60 | Iteration number: [3840/4518] 84% | Training loss: 0.6869680353285124
Epoch: 60 | Iteration number: [3850/4518] 85% | Training loss: 0.6869673557405348
Epoch: 60 | Iteration number: [3860/4518] 85% | Training loss: 0.6869674991140712
Epoch: 60 | Iteration number: [3870/4518] 85% | Training loss: 0.6869690590280587
Epoch: 60 | Iteration number: [3880/4518] 85% | Training loss: 0.6869670903406192
Epoch: 60 | Iteration number: [3890/4518] 86% | Training loss: 0.6869673024872581
Epoch: 60 | Iteration number: [3900/4518] 86% | Training loss: 0.6869691339670083
Epoch: 60 | Iteration number: [3910/4518] 86% | Training loss: 0.6869696113307153
Epoch: 60 | Iteration number: [3920/4518] 86% | Training loss: 0.6869721833236363
Epoch: 60 | Iteration number: [3930/4518] 86% | Training loss: 0.6869711452768049
Epoch: 60 | Iteration number: [3940/4518] 87% | Training loss: 0.6869693948532725
Epoch: 60 | Iteration number: [3950/4518] 87% | Training loss: 0.6869679141346412
Epoch: 60 | Iteration number: [3960/4518] 87% | Training loss: 0.6869663213539605
Epoch: 60 | Iteration number: [3970/4518] 87% | Training loss: 0.6869630572627714
Epoch: 60 | Iteration number: [3980/4518] 88% | Training loss: 0.6869626467551418
Epoch: 60 | Iteration number: [3990/4518] 88% | Training loss: 0.6869642440388376
Epoch: 60 | Iteration number: [4000/4518] 88% | Training loss: 0.6869659511446953
Epoch: 60 | Iteration number: [4010/4518] 88% | Training loss: 0.6869642592427736
Epoch: 60 | Iteration number: [4020/4518] 88% | Training loss: 0.6869631328541248
Epoch: 60 | Iteration number: [4030/4518] 89% | Training loss: 0.6869617533447133
Epoch: 60 | Iteration number: [4040/4518] 89% | Training loss: 0.6869593091677911
Epoch: 60 | Iteration number: [4050/4518] 89% | Training loss: 0.6869592943897954
Epoch: 60 | Iteration number: [4060/4518] 89% | Training loss: 0.6869586098810722
Epoch: 60 | Iteration number: [4070/4518] 90% | Training loss: 0.6869561607773239
Epoch: 60 | Iteration number: [4080/4518] 90% | Training loss: 0.6869594000133814
Epoch: 60 | Iteration number: [4090/4518] 90% | Training loss: 0.6869596585959269
Epoch: 60 | Iteration number: [4100/4518] 90% | Training loss: 0.6869565723000504
Epoch: 60 | Iteration number: [4110/4518] 90% | Training loss: 0.6869561787649373
Epoch: 60 | Iteration number: [4120/4518] 91% | Training loss: 0.6869569567800725
Epoch: 60 | Iteration number: [4130/4518] 91% | Training loss: 0.6869545981035394
Epoch: 60 | Iteration number: [4140/4518] 91% | Training loss: 0.6869572329348412
Epoch: 60 | Iteration number: [4150/4518] 91% | Training loss: 0.6869565945361034
Epoch: 60 | Iteration number: [4160/4518] 92% | Training loss: 0.686956909012336
Epoch: 60 | Iteration number: [4170/4518] 92% | Training loss: 0.6869579574615835
Epoch: 60 | Iteration number: [4180/4518] 92% | Training loss: 0.6869580260161577
Epoch: 60 | Iteration number: [4190/4518] 92% | Training loss: 0.6869594658331541
Epoch: 60 | Iteration number: [4200/4518] 92% | Training loss: 0.686959660464809
Epoch: 60 | Iteration number: [4210/4518] 93% | Training loss: 0.6869551040072905
Epoch: 60 | Iteration number: [4220/4518] 93% | Training loss: 0.6869533867773852
Epoch: 60 | Iteration number: [4230/4518] 93% | Training loss: 0.6869531917374748
Epoch: 60 | Iteration number: [4240/4518] 93% | Training loss: 0.6869548946056726
Epoch: 60 | Iteration number: [4250/4518] 94% | Training loss: 0.6869553795842563
Epoch: 60 | Iteration number: [4260/4518] 94% | Training loss: 0.686957356081882
Epoch: 60 | Iteration number: [4270/4518] 94% | Training loss: 0.686956150163253
Epoch: 60 | Iteration number: [4280/4518] 94% | Training loss: 0.6869537723259391
Epoch: 60 | Iteration number: [4290/4518] 94% | Training loss: 0.6869514666792952
Epoch: 60 | Iteration number: [4300/4518] 95% | Training loss: 0.6869531579211701
Epoch: 60 | Iteration number: [4310/4518] 95% | Training loss: 0.6869494968251673
Epoch: 60 | Iteration number: [4320/4518] 95% | Training loss: 0.6869515373888943
Epoch: 60 | Iteration number: [4330/4518] 95% | Training loss: 0.6869515128141187
Epoch: 60 | Iteration number: [4340/4518] 96% | Training loss: 0.6869492576556272
Epoch: 60 | Iteration number: [4350/4518] 96% | Training loss: 0.686947550047403
Epoch: 60 | Iteration number: [4360/4518] 96% | Training loss: 0.6869471063444373
Epoch: 60 | Iteration number: [4370/4518] 96% | Training loss: 0.6869465143920628
Epoch: 60 | Iteration number: [4380/4518] 96% | Training loss: 0.6869455284315702
Epoch: 60 | Iteration number: [4390/4518] 97% | Training loss: 0.6869450642606392
Epoch: 60 | Iteration number: [4400/4518] 97% | Training loss: 0.6869417372887785
Epoch: 60 | Iteration number: [4410/4518] 97% | Training loss: 0.6869417666577968
Epoch: 60 | Iteration number: [4420/4518] 97% | Training loss: 0.6869424503718027
Epoch: 60 | Iteration number: [4430/4518] 98% | Training loss: 0.6869455582132189
Epoch: 60 | Iteration number: [4440/4518] 98% | Training loss: 0.6869442416472478
Epoch: 60 | Iteration number: [4450/4518] 98% | Training loss: 0.6869445248266285
Epoch: 60 | Iteration number: [4460/4518] 98% | Training loss: 0.6869467088593496
Epoch: 60 | Iteration number: [4470/4518] 98% | Training loss: 0.6869497737761845
Epoch: 60 | Iteration number: [4480/4518] 99% | Training loss: 0.6869489218108356
Epoch: 60 | Iteration number: [4490/4518] 99% | Training loss: 0.6869504606405186
Epoch: 60 | Iteration number: [4500/4518] 99% | Training loss: 0.6869501869016224
Epoch: 60 | Iteration number: [4510/4518] 99% | Training loss: 0.686951531235236

 End of epoch: 60 | Train Loss: 0.6867975259629326 | Training Time: 643 

 End of epoch: 60 | Eval Loss: 0.6900677449849187 | Evaluating Time: 17 
Epoch: 61 | Iteration number: [10/4518] 0% | Training loss: 0.7549222230911254
Epoch: 61 | Iteration number: [20/4518] 0% | Training loss: 0.7210664510726928
Epoch: 61 | Iteration number: [30/4518] 0% | Training loss: 0.7099835952123006
Epoch: 61 | Iteration number: [40/4518] 0% | Training loss: 0.7044215932488441
Epoch: 61 | Iteration number: [50/4518] 1% | Training loss: 0.7010381996631623
Epoch: 61 | Iteration number: [60/4518] 1% | Training loss: 0.6986085106929143
Epoch: 61 | Iteration number: [70/4518] 1% | Training loss: 0.6969468380723681
Epoch: 61 | Iteration number: [80/4518] 1% | Training loss: 0.6956058524549007
Epoch: 61 | Iteration number: [90/4518] 1% | Training loss: 0.694624721341663
Epoch: 61 | Iteration number: [100/4518] 2% | Training loss: 0.6938577252626419
Epoch: 61 | Iteration number: [110/4518] 2% | Training loss: 0.6932214785705914
Epoch: 61 | Iteration number: [120/4518] 2% | Training loss: 0.6926725010077158
Epoch: 61 | Iteration number: [130/4518] 2% | Training loss: 0.6922203747125772
Epoch: 61 | Iteration number: [140/4518] 3% | Training loss: 0.6918197078364235
Epoch: 61 | Iteration number: [150/4518] 3% | Training loss: 0.6915063881874084
Epoch: 61 | Iteration number: [160/4518] 3% | Training loss: 0.6911321107298136
Epoch: 61 | Iteration number: [170/4518] 3% | Training loss: 0.6909752305816201
Epoch: 61 | Iteration number: [180/4518] 3% | Training loss: 0.6907363153166242
Epoch: 61 | Iteration number: [190/4518] 4% | Training loss: 0.6904746388134203
Epoch: 61 | Iteration number: [200/4518] 4% | Training loss: 0.6902692806720734
Epoch: 61 | Iteration number: [210/4518] 4% | Training loss: 0.6901076509839013
Epoch: 61 | Iteration number: [220/4518] 4% | Training loss: 0.6900148047642274
Epoch: 61 | Iteration number: [230/4518] 5% | Training loss: 0.6898913331653761
Epoch: 61 | Iteration number: [240/4518] 5% | Training loss: 0.6897629722952843
Epoch: 61 | Iteration number: [250/4518] 5% | Training loss: 0.6896187307834625
Epoch: 61 | Iteration number: [260/4518] 5% | Training loss: 0.6895293639256403
Epoch: 61 | Iteration number: [270/4518] 5% | Training loss: 0.6894693067780248
Epoch: 61 | Iteration number: [280/4518] 6% | Training loss: 0.6894186219998768
Epoch: 61 | Iteration number: [290/4518] 6% | Training loss: 0.6893536203894122
Epoch: 61 | Iteration number: [300/4518] 6% | Training loss: 0.68931077003479
Epoch: 61 | Iteration number: [310/4518] 6% | Training loss: 0.6892302184335647
Epoch: 61 | Iteration number: [320/4518] 7% | Training loss: 0.6891158072277903
Epoch: 61 | Iteration number: [330/4518] 7% | Training loss: 0.6890475193659464
Epoch: 61 | Iteration number: [340/4518] 7% | Training loss: 0.6889210928888881
Epoch: 61 | Iteration number: [350/4518] 7% | Training loss: 0.6888411922114236
Epoch: 61 | Iteration number: [360/4518] 7% | Training loss: 0.6887615801559555
Epoch: 61 | Iteration number: [370/4518] 8% | Training loss: 0.688646263367421
Epoch: 61 | Iteration number: [380/4518] 8% | Training loss: 0.6886178727212705
Epoch: 61 | Iteration number: [390/4518] 8% | Training loss: 0.6885459335950704
Epoch: 61 | Iteration number: [400/4518] 8% | Training loss: 0.6884911459684372
Epoch: 61 | Iteration number: [410/4518] 9% | Training loss: 0.6884756672673109
Epoch: 61 | Iteration number: [420/4518] 9% | Training loss: 0.688421439131101
Epoch: 61 | Iteration number: [430/4518] 9% | Training loss: 0.6883582357750383
Epoch: 61 | Iteration number: [440/4518] 9% | Training loss: 0.688315892896869
Epoch: 61 | Iteration number: [450/4518] 9% | Training loss: 0.688302835226059
Epoch: 61 | Iteration number: [460/4518] 10% | Training loss: 0.6882619656946348
Epoch: 61 | Iteration number: [470/4518] 10% | Training loss: 0.6882188203486991
Epoch: 61 | Iteration number: [480/4518] 10% | Training loss: 0.6882153384387493
Epoch: 61 | Iteration number: [490/4518] 10% | Training loss: 0.688185453414917
Epoch: 61 | Iteration number: [500/4518] 11% | Training loss: 0.6881831214427948
Epoch: 61 | Iteration number: [510/4518] 11% | Training loss: 0.6881793501330357
Epoch: 61 | Iteration number: [520/4518] 11% | Training loss: 0.6881497166477717
Epoch: 61 | Iteration number: [530/4518] 11% | Training loss: 0.6881072395252732
Epoch: 61 | Iteration number: [540/4518] 11% | Training loss: 0.6880764374026546
Epoch: 61 | Iteration number: [550/4518] 12% | Training loss: 0.6880628751624714
Epoch: 61 | Iteration number: [560/4518] 12% | Training loss: 0.6880512231162617
Epoch: 61 | Iteration number: [570/4518] 12% | Training loss: 0.6880406709093797
Epoch: 61 | Iteration number: [580/4518] 12% | Training loss: 0.6880354696306689
Epoch: 61 | Iteration number: [590/4518] 13% | Training loss: 0.6880238072346833
Epoch: 61 | Iteration number: [600/4518] 13% | Training loss: 0.6880082608262698
Epoch: 61 | Iteration number: [610/4518] 13% | Training loss: 0.6879781695662952
Epoch: 61 | Iteration number: [620/4518] 13% | Training loss: 0.6879514466370306
Epoch: 61 | Iteration number: [630/4518] 13% | Training loss: 0.6879175868299272
Epoch: 61 | Iteration number: [640/4518] 14% | Training loss: 0.6878687267191708
Epoch: 61 | Iteration number: [650/4518] 14% | Training loss: 0.6878427675137153
Epoch: 61 | Iteration number: [660/4518] 14% | Training loss: 0.6878368890646732
Epoch: 61 | Iteration number: [670/4518] 14% | Training loss: 0.6878312315513838
Epoch: 61 | Iteration number: [680/4518] 15% | Training loss: 0.6878189985366429
Epoch: 61 | Iteration number: [690/4518] 15% | Training loss: 0.6878194380497586
Epoch: 61 | Iteration number: [700/4518] 15% | Training loss: 0.6877872797421046
Epoch: 61 | Iteration number: [710/4518] 15% | Training loss: 0.6877688611896945
Epoch: 61 | Iteration number: [720/4518] 15% | Training loss: 0.6877510441674126
Epoch: 61 | Iteration number: [730/4518] 16% | Training loss: 0.6877264511095335
Epoch: 61 | Iteration number: [740/4518] 16% | Training loss: 0.6877218177189698
Epoch: 61 | Iteration number: [750/4518] 16% | Training loss: 0.687708464940389
Epoch: 61 | Iteration number: [760/4518] 16% | Training loss: 0.6877092157539568
Epoch: 61 | Iteration number: [770/4518] 17% | Training loss: 0.6877096212529517
Epoch: 61 | Iteration number: [780/4518] 17% | Training loss: 0.6877064698781723
Epoch: 61 | Iteration number: [790/4518] 17% | Training loss: 0.6876998113680489
Epoch: 61 | Iteration number: [800/4518] 17% | Training loss: 0.6876837046444416
Epoch: 61 | Iteration number: [810/4518] 17% | Training loss: 0.6876847871291785
Epoch: 61 | Iteration number: [820/4518] 18% | Training loss: 0.687674292558577
Epoch: 61 | Iteration number: [830/4518] 18% | Training loss: 0.6876753733100661
Epoch: 61 | Iteration number: [840/4518] 18% | Training loss: 0.6876728181328092
Epoch: 61 | Iteration number: [850/4518] 18% | Training loss: 0.6876670851426966
Epoch: 61 | Iteration number: [860/4518] 19% | Training loss: 0.6876485010219174
Epoch: 61 | Iteration number: [870/4518] 19% | Training loss: 0.6876322449623853
Epoch: 61 | Iteration number: [880/4518] 19% | Training loss: 0.687620036168532
Epoch: 61 | Iteration number: [890/4518] 19% | Training loss: 0.6876171359185422
Epoch: 61 | Iteration number: [900/4518] 19% | Training loss: 0.6876089329189724
Epoch: 61 | Iteration number: [910/4518] 20% | Training loss: 0.6876039499109918
Epoch: 61 | Iteration number: [920/4518] 20% | Training loss: 0.6875908645598785
Epoch: 61 | Iteration number: [930/4518] 20% | Training loss: 0.6875905609899952
Epoch: 61 | Iteration number: [940/4518] 20% | Training loss: 0.6875770918866422
Epoch: 61 | Iteration number: [950/4518] 21% | Training loss: 0.6875801085170946
Epoch: 61 | Iteration number: [960/4518] 21% | Training loss: 0.6875815924877922
Epoch: 61 | Iteration number: [970/4518] 21% | Training loss: 0.6875710792762717
Epoch: 61 | Iteration number: [980/4518] 21% | Training loss: 0.6875590921056514
Epoch: 61 | Iteration number: [990/4518] 21% | Training loss: 0.6875548897367535
Epoch: 61 | Iteration number: [1000/4518] 22% | Training loss: 0.6875450505614281
Epoch: 61 | Iteration number: [1010/4518] 22% | Training loss: 0.6875455576594514
Epoch: 61 | Iteration number: [1020/4518] 22% | Training loss: 0.6875347037525738
Epoch: 61 | Iteration number: [1030/4518] 22% | Training loss: 0.6875205491931693
Epoch: 61 | Iteration number: [1040/4518] 23% | Training loss: 0.6875156724682221
Epoch: 61 | Iteration number: [1050/4518] 23% | Training loss: 0.687517242147809
Epoch: 61 | Iteration number: [1060/4518] 23% | Training loss: 0.6875115627387784
Epoch: 61 | Iteration number: [1070/4518] 23% | Training loss: 0.6875084723267599
Epoch: 61 | Iteration number: [1080/4518] 23% | Training loss: 0.6875034121451554
Epoch: 61 | Iteration number: [1090/4518] 24% | Training loss: 0.6874857168678844
Epoch: 61 | Iteration number: [1100/4518] 24% | Training loss: 0.687471958507191
Epoch: 61 | Iteration number: [1110/4518] 24% | Training loss: 0.6874614909425512
Epoch: 61 | Iteration number: [1120/4518] 24% | Training loss: 0.687446298875979
Epoch: 61 | Iteration number: [1130/4518] 25% | Training loss: 0.6874442511955193
Epoch: 61 | Iteration number: [1140/4518] 25% | Training loss: 0.6874359432542533
Epoch: 61 | Iteration number: [1150/4518] 25% | Training loss: 0.6874268878024558
Epoch: 61 | Iteration number: [1160/4518] 25% | Training loss: 0.6874213111811671
Epoch: 61 | Iteration number: [1170/4518] 25% | Training loss: 0.6874241541084062
Epoch: 61 | Iteration number: [1180/4518] 26% | Training loss: 0.6874157880322408
Epoch: 61 | Iteration number: [1190/4518] 26% | Training loss: 0.6874095061746965
Epoch: 61 | Iteration number: [1200/4518] 26% | Training loss: 0.6873967761298021
Epoch: 61 | Iteration number: [1210/4518] 26% | Training loss: 0.6873847822512477
Epoch: 61 | Iteration number: [1220/4518] 27% | Training loss: 0.6873830800173713
Epoch: 61 | Iteration number: [1230/4518] 27% | Training loss: 0.6873815847121603
Epoch: 61 | Iteration number: [1240/4518] 27% | Training loss: 0.6873824160425893
Epoch: 61 | Iteration number: [1250/4518] 27% | Training loss: 0.6873783141136169
Epoch: 61 | Iteration number: [1260/4518] 27% | Training loss: 0.6873814717171685
Epoch: 61 | Iteration number: [1270/4518] 28% | Training loss: 0.6873754503220085
Epoch: 61 | Iteration number: [1280/4518] 28% | Training loss: 0.6873823060654104
Epoch: 61 | Iteration number: [1290/4518] 28% | Training loss: 0.68738210071889
Epoch: 61 | Iteration number: [1300/4518] 28% | Training loss: 0.6873741228305377
Epoch: 61 | Iteration number: [1310/4518] 28% | Training loss: 0.687359917982844
Epoch: 61 | Iteration number: [1320/4518] 29% | Training loss: 0.6873528880603386
Epoch: 61 | Iteration number: [1330/4518] 29% | Training loss: 0.6873419525479911
Epoch: 61 | Iteration number: [1340/4518] 29% | Training loss: 0.6873370879621649
Epoch: 61 | Iteration number: [1350/4518] 29% | Training loss: 0.6873361923076489
Epoch: 61 | Iteration number: [1360/4518] 30% | Training loss: 0.6873266938416397
Epoch: 61 | Iteration number: [1370/4518] 30% | Training loss: 0.6873223607122463
Epoch: 61 | Iteration number: [1380/4518] 30% | Training loss: 0.6873149029586626
Epoch: 61 | Iteration number: [1390/4518] 30% | Training loss: 0.6873136989504314
Epoch: 61 | Iteration number: [1400/4518] 30% | Training loss: 0.687309138902596
Epoch: 61 | Iteration number: [1410/4518] 31% | Training loss: 0.687301895381711
Epoch: 61 | Iteration number: [1420/4518] 31% | Training loss: 0.6872995985225893
Epoch: 61 | Iteration number: [1430/4518] 31% | Training loss: 0.6872958881454868
Epoch: 61 | Iteration number: [1440/4518] 31% | Training loss: 0.6872916037009822
Epoch: 61 | Iteration number: [1450/4518] 32% | Training loss: 0.6872786650575441
Epoch: 61 | Iteration number: [1460/4518] 32% | Training loss: 0.6872716102698078
Epoch: 61 | Iteration number: [1470/4518] 32% | Training loss: 0.6872649655861108
Epoch: 61 | Iteration number: [1480/4518] 32% | Training loss: 0.6872579840389458
Epoch: 61 | Iteration number: [1490/4518] 32% | Training loss: 0.6872502297363026
Epoch: 61 | Iteration number: [1500/4518] 33% | Training loss: 0.6872402707735698
Epoch: 61 | Iteration number: [1510/4518] 33% | Training loss: 0.6872410230289232
Epoch: 61 | Iteration number: [1520/4518] 33% | Training loss: 0.6872399506208143
Epoch: 61 | Iteration number: [1530/4518] 33% | Training loss: 0.6872401750165653
Epoch: 61 | Iteration number: [1540/4518] 34% | Training loss: 0.6872422632845965
Epoch: 61 | Iteration number: [1550/4518] 34% | Training loss: 0.6872366073054652
Epoch: 61 | Iteration number: [1560/4518] 34% | Training loss: 0.6872165187047078
Epoch: 61 | Iteration number: [1570/4518] 34% | Training loss: 0.6872059974700782
Epoch: 61 | Iteration number: [1580/4518] 34% | Training loss: 0.6872001909379718
Epoch: 61 | Iteration number: [1590/4518] 35% | Training loss: 0.6871980341350508
Epoch: 61 | Iteration number: [1600/4518] 35% | Training loss: 0.6871902565658092
Epoch: 61 | Iteration number: [1610/4518] 35% | Training loss: 0.6871947212989286
Epoch: 61 | Iteration number: [1620/4518] 35% | Training loss: 0.6871873677512745
Epoch: 61 | Iteration number: [1630/4518] 36% | Training loss: 0.6871809273409697
Epoch: 61 | Iteration number: [1640/4518] 36% | Training loss: 0.6871719353809589
Epoch: 61 | Iteration number: [1650/4518] 36% | Training loss: 0.6871715668114748
Epoch: 61 | Iteration number: [1660/4518] 36% | Training loss: 0.6871689362698291
Epoch: 61 | Iteration number: [1670/4518] 36% | Training loss: 0.6871672416875463
Epoch: 61 | Iteration number: [1680/4518] 37% | Training loss: 0.6871645524388268
Epoch: 61 | Iteration number: [1690/4518] 37% | Training loss: 0.6871682027035211
Epoch: 61 | Iteration number: [1700/4518] 37% | Training loss: 0.6871682085009182
Epoch: 61 | Iteration number: [1710/4518] 37% | Training loss: 0.687170128829298
Epoch: 61 | Iteration number: [1720/4518] 38% | Training loss: 0.6871627465583557
Epoch: 61 | Iteration number: [1730/4518] 38% | Training loss: 0.6871560205269411
Epoch: 61 | Iteration number: [1740/4518] 38% | Training loss: 0.6871578644404466
Epoch: 61 | Iteration number: [1750/4518] 38% | Training loss: 0.6871520406859262
Epoch: 61 | Iteration number: [1760/4518] 38% | Training loss: 0.6871486044065519
Epoch: 61 | Iteration number: [1770/4518] 39% | Training loss: 0.6871499234673667
Epoch: 61 | Iteration number: [1780/4518] 39% | Training loss: 0.6871494428160485
Epoch: 61 | Iteration number: [1790/4518] 39% | Training loss: 0.6871363221267082
Epoch: 61 | Iteration number: [1800/4518] 39% | Training loss: 0.687132897178332
Epoch: 61 | Iteration number: [1810/4518] 40% | Training loss: 0.6871241885983483
Epoch: 61 | Iteration number: [1820/4518] 40% | Training loss: 0.687117770248717
Epoch: 61 | Iteration number: [1830/4518] 40% | Training loss: 0.6871196581040575
Epoch: 61 | Iteration number: [1840/4518] 40% | Training loss: 0.687123460970495
Epoch: 61 | Iteration number: [1850/4518] 40% | Training loss: 0.6871238520660916
Epoch: 61 | Iteration number: [1860/4518] 41% | Training loss: 0.6871305132745414
Epoch: 61 | Iteration number: [1870/4518] 41% | Training loss: 0.6871319417966241
Epoch: 61 | Iteration number: [1880/4518] 41% | Training loss: 0.6871361278790109
Epoch: 61 | Iteration number: [1890/4518] 41% | Training loss: 0.6871338879305219
Epoch: 61 | Iteration number: [1900/4518] 42% | Training loss: 0.6871352672263196
Epoch: 61 | Iteration number: [1910/4518] 42% | Training loss: 0.6871378615264493
Epoch: 61 | Iteration number: [1920/4518] 42% | Training loss: 0.6871333466842771
Epoch: 61 | Iteration number: [1930/4518] 42% | Training loss: 0.6871393386255275
Epoch: 61 | Iteration number: [1940/4518] 42% | Training loss: 0.6871355792296302
Epoch: 61 | Iteration number: [1950/4518] 43% | Training loss: 0.6871355074491257
Epoch: 61 | Iteration number: [1960/4518] 43% | Training loss: 0.6871332220885218
Epoch: 61 | Iteration number: [1970/4518] 43% | Training loss: 0.6871363780220148
Epoch: 61 | Iteration number: [1980/4518] 43% | Training loss: 0.6871386456670183
Epoch: 61 | Iteration number: [1990/4518] 44% | Training loss: 0.6871390526618191
Epoch: 61 | Iteration number: [2000/4518] 44% | Training loss: 0.6871336920559407
Epoch: 61 | Iteration number: [2010/4518] 44% | Training loss: 0.6871353531654795
Epoch: 61 | Iteration number: [2020/4518] 44% | Training loss: 0.6871334505553293
Epoch: 61 | Iteration number: [2030/4518] 44% | Training loss: 0.6871386982830875
Epoch: 61 | Iteration number: [2040/4518] 45% | Training loss: 0.687133829500161
Epoch: 61 | Iteration number: [2050/4518] 45% | Training loss: 0.6871230410657277
Epoch: 61 | Iteration number: [2060/4518] 45% | Training loss: 0.6871186927684303
Epoch: 61 | Iteration number: [2070/4518] 45% | Training loss: 0.6871198640353438
Epoch: 61 | Iteration number: [2080/4518] 46% | Training loss: 0.6871168522307506
Epoch: 61 | Iteration number: [2090/4518] 46% | Training loss: 0.6871152097528631
Epoch: 61 | Iteration number: [2100/4518] 46% | Training loss: 0.6871138504005614
Epoch: 61 | Iteration number: [2110/4518] 46% | Training loss: 0.6871073493460343
Epoch: 61 | Iteration number: [2120/4518] 46% | Training loss: 0.6871091861488684
Epoch: 61 | Iteration number: [2130/4518] 47% | Training loss: 0.687102113671146
Epoch: 61 | Iteration number: [2140/4518] 47% | Training loss: 0.6871071761456605
Epoch: 61 | Iteration number: [2150/4518] 47% | Training loss: 0.6871094794051592
Epoch: 61 | Iteration number: [2160/4518] 47% | Training loss: 0.6871067143148846
Epoch: 61 | Iteration number: [2170/4518] 48% | Training loss: 0.687102133612479
Epoch: 61 | Iteration number: [2180/4518] 48% | Training loss: 0.6870958806177891
Epoch: 61 | Iteration number: [2190/4518] 48% | Training loss: 0.6870924180773296
Epoch: 61 | Iteration number: [2200/4518] 48% | Training loss: 0.6870902241630987
Epoch: 61 | Iteration number: [2210/4518] 48% | Training loss: 0.687086401697737
Epoch: 61 | Iteration number: [2220/4518] 49% | Training loss: 0.687084509123553
Epoch: 61 | Iteration number: [2230/4518] 49% | Training loss: 0.6870795500385387
Epoch: 61 | Iteration number: [2240/4518] 49% | Training loss: 0.6870866358546274
Epoch: 61 | Iteration number: [2250/4518] 49% | Training loss: 0.6870875310897827
Epoch: 61 | Iteration number: [2260/4518] 50% | Training loss: 0.6870809211931398
Epoch: 61 | Iteration number: [2270/4518] 50% | Training loss: 0.6870856025670593
Epoch: 61 | Iteration number: [2280/4518] 50% | Training loss: 0.687077202216575
Epoch: 61 | Iteration number: [2290/4518] 50% | Training loss: 0.6870768097550588
Epoch: 61 | Iteration number: [2300/4518] 50% | Training loss: 0.6870727702586548
Epoch: 61 | Iteration number: [2310/4518] 51% | Training loss: 0.6870708815463178
Epoch: 61 | Iteration number: [2320/4518] 51% | Training loss: 0.6870643844635322
Epoch: 61 | Iteration number: [2330/4518] 51% | Training loss: 0.6870651873907818
Epoch: 61 | Iteration number: [2340/4518] 51% | Training loss: 0.6870605957304311
Epoch: 61 | Iteration number: [2350/4518] 52% | Training loss: 0.6870616846896233
Epoch: 61 | Iteration number: [2360/4518] 52% | Training loss: 0.6870532510391737
Epoch: 61 | Iteration number: [2370/4518] 52% | Training loss: 0.68705746566696
Epoch: 61 | Iteration number: [2380/4518] 52% | Training loss: 0.6870559177729262
Epoch: 61 | Iteration number: [2390/4518] 52% | Training loss: 0.6870549125402043
Epoch: 61 | Iteration number: [2400/4518] 53% | Training loss: 0.6870601219435533
Epoch: 61 | Iteration number: [2410/4518] 53% | Training loss: 0.6870616217371833
Epoch: 61 | Iteration number: [2420/4518] 53% | Training loss: 0.6870606856897843
Epoch: 61 | Iteration number: [2430/4518] 53% | Training loss: 0.6870578732264876
Epoch: 61 | Iteration number: [2440/4518] 54% | Training loss: 0.6870572738960141
Epoch: 61 | Iteration number: [2450/4518] 54% | Training loss: 0.6870584318832476
Epoch: 61 | Iteration number: [2460/4518] 54% | Training loss: 0.6870528468513877
Epoch: 61 | Iteration number: [2470/4518] 54% | Training loss: 0.6870538297935054
Epoch: 61 | Iteration number: [2480/4518] 54% | Training loss: 0.687051689552684
Epoch: 61 | Iteration number: [2490/4518] 55% | Training loss: 0.6870482612087065
Epoch: 61 | Iteration number: [2500/4518] 55% | Training loss: 0.687048706793785
Epoch: 61 | Iteration number: [2510/4518] 55% | Training loss: 0.6870418814073995
Epoch: 61 | Iteration number: [2520/4518] 55% | Training loss: 0.6870393279999022
Epoch: 61 | Iteration number: [2530/4518] 55% | Training loss: 0.6870369656990639
Epoch: 61 | Iteration number: [2540/4518] 56% | Training loss: 0.6870323118497067
Epoch: 61 | Iteration number: [2550/4518] 56% | Training loss: 0.6870322250151166
Epoch: 61 | Iteration number: [2560/4518] 56% | Training loss: 0.6870315986219794
Epoch: 61 | Iteration number: [2570/4518] 56% | Training loss: 0.6870376937120342
Epoch: 61 | Iteration number: [2580/4518] 57% | Training loss: 0.6870389305112898
Epoch: 61 | Iteration number: [2590/4518] 57% | Training loss: 0.687042793067726
Epoch: 61 | Iteration number: [2600/4518] 57% | Training loss: 0.6870441180926102
Epoch: 61 | Iteration number: [2610/4518] 57% | Training loss: 0.6870408678876943
Epoch: 61 | Iteration number: [2620/4518] 57% | Training loss: 0.6870380946470581
Epoch: 61 | Iteration number: [2630/4518] 58% | Training loss: 0.6870379330994059
Epoch: 61 | Iteration number: [2640/4518] 58% | Training loss: 0.6870339370586656
Epoch: 61 | Iteration number: [2650/4518] 58% | Training loss: 0.6870311354916051
Epoch: 61 | Iteration number: [2660/4518] 58% | Training loss: 0.6870303990697502
Epoch: 61 | Iteration number: [2670/4518] 59% | Training loss: 0.687026329009274
Epoch: 61 | Iteration number: [2680/4518] 59% | Training loss: 0.6870277044266018
Epoch: 61 | Iteration number: [2690/4518] 59% | Training loss: 0.6870279243222843
Epoch: 61 | Iteration number: [2700/4518] 59% | Training loss: 0.6870325126029827
Epoch: 61 | Iteration number: [2710/4518] 59% | Training loss: 0.6870263667344167
Epoch: 61 | Iteration number: [2720/4518] 60% | Training loss: 0.6870286908219843
Epoch: 61 | Iteration number: [2730/4518] 60% | Training loss: 0.6870273526116605
Epoch: 61 | Iteration number: [2740/4518] 60% | Training loss: 0.6870282482926863
Epoch: 61 | Iteration number: [2750/4518] 60% | Training loss: 0.6870316745801406
Epoch: 61 | Iteration number: [2760/4518] 61% | Training loss: 0.6870312677345414
Epoch: 61 | Iteration number: [2770/4518] 61% | Training loss: 0.6870339911767291
Epoch: 61 | Iteration number: [2780/4518] 61% | Training loss: 0.6870329793194215
Epoch: 61 | Iteration number: [2790/4518] 61% | Training loss: 0.6870313521781702
Epoch: 61 | Iteration number: [2800/4518] 61% | Training loss: 0.6870306870341301
Epoch: 61 | Iteration number: [2810/4518] 62% | Training loss: 0.687031214708111
Epoch: 61 | Iteration number: [2820/4518] 62% | Training loss: 0.6870303788929121
Epoch: 61 | Iteration number: [2830/4518] 62% | Training loss: 0.6870307906145763
Epoch: 61 | Iteration number: [2840/4518] 62% | Training loss: 0.6870296340593149
Epoch: 61 | Iteration number: [2850/4518] 63% | Training loss: 0.6870315218808358
Epoch: 61 | Iteration number: [2860/4518] 63% | Training loss: 0.6870329435055073
Epoch: 61 | Iteration number: [2870/4518] 63% | Training loss: 0.6870303187013088
Epoch: 61 | Iteration number: [2880/4518] 63% | Training loss: 0.6870286014758878
Epoch: 61 | Iteration number: [2890/4518] 63% | Training loss: 0.6870272863901198
Epoch: 61 | Iteration number: [2900/4518] 64% | Training loss: 0.6870229650571429
Epoch: 61 | Iteration number: [2910/4518] 64% | Training loss: 0.687014440142412
Epoch: 61 | Iteration number: [2920/4518] 64% | Training loss: 0.6870126427444693
Epoch: 61 | Iteration number: [2930/4518] 64% | Training loss: 0.6870136296382943
Epoch: 61 | Iteration number: [2940/4518] 65% | Training loss: 0.6870175823670667
Epoch: 61 | Iteration number: [2950/4518] 65% | Training loss: 0.6870177124112339
Epoch: 61 | Iteration number: [2960/4518] 65% | Training loss: 0.6870137091826748
Epoch: 61 | Iteration number: [2970/4518] 65% | Training loss: 0.6870148392438086
Epoch: 61 | Iteration number: [2980/4518] 65% | Training loss: 0.6870125443143332
Epoch: 61 | Iteration number: [2990/4518] 66% | Training loss: 0.6870151807831283
Epoch: 61 | Iteration number: [3000/4518] 66% | Training loss: 0.6870205401976903
Epoch: 61 | Iteration number: [3010/4518] 66% | Training loss: 0.6870205374849199
Epoch: 61 | Iteration number: [3020/4518] 66% | Training loss: 0.6870190701539943
Epoch: 61 | Iteration number: [3030/4518] 67% | Training loss: 0.6870183822345419
Epoch: 61 | Iteration number: [3040/4518] 67% | Training loss: 0.6870188444852829
Epoch: 61 | Iteration number: [3050/4518] 67% | Training loss: 0.6870201414530395
Epoch: 61 | Iteration number: [3060/4518] 67% | Training loss: 0.6870220300613665
Epoch: 61 | Iteration number: [3070/4518] 67% | Training loss: 0.6870250931391887
Epoch: 61 | Iteration number: [3080/4518] 68% | Training loss: 0.6870247747023385
Epoch: 61 | Iteration number: [3090/4518] 68% | Training loss: 0.6870267410301468
Epoch: 61 | Iteration number: [3100/4518] 68% | Training loss: 0.6870234747471348
Epoch: 61 | Iteration number: [3110/4518] 68% | Training loss: 0.6870203129539919
Epoch: 61 | Iteration number: [3120/4518] 69% | Training loss: 0.687016690789889
Epoch: 61 | Iteration number: [3130/4518] 69% | Training loss: 0.6870093114269428
Epoch: 61 | Iteration number: [3140/4518] 69% | Training loss: 0.6870109694398893
Epoch: 61 | Iteration number: [3150/4518] 69% | Training loss: 0.6870141235419682
Epoch: 61 | Iteration number: [3160/4518] 69% | Training loss: 0.6870138866048825
Epoch: 61 | Iteration number: [3170/4518] 70% | Training loss: 0.6870151086748586
Epoch: 61 | Iteration number: [3180/4518] 70% | Training loss: 0.6870123794993515
Epoch: 61 | Iteration number: [3190/4518] 70% | Training loss: 0.687014264204659
Epoch: 61 | Iteration number: [3200/4518] 70% | Training loss: 0.6870171159133315
Epoch: 61 | Iteration number: [3210/4518] 71% | Training loss: 0.6870163597978907
Epoch: 61 | Iteration number: [3220/4518] 71% | Training loss: 0.687015332975743
Epoch: 61 | Iteration number: [3230/4518] 71% | Training loss: 0.6870186000785592
Epoch: 61 | Iteration number: [3240/4518] 71% | Training loss: 0.68701943917039
Epoch: 61 | Iteration number: [3250/4518] 71% | Training loss: 0.687019056228491
Epoch: 61 | Iteration number: [3260/4518] 72% | Training loss: 0.6870207347204349
Epoch: 61 | Iteration number: [3270/4518] 72% | Training loss: 0.687016810408426
Epoch: 61 | Iteration number: [3280/4518] 72% | Training loss: 0.6870153745318331
Epoch: 61 | Iteration number: [3290/4518] 72% | Training loss: 0.6870142650640482
Epoch: 61 | Iteration number: [3300/4518] 73% | Training loss: 0.6870111494714564
Epoch: 61 | Iteration number: [3310/4518] 73% | Training loss: 0.6870155619350445
Epoch: 61 | Iteration number: [3320/4518] 73% | Training loss: 0.6870141753410719
Epoch: 61 | Iteration number: [3330/4518] 73% | Training loss: 0.6870158761829227
Epoch: 61 | Iteration number: [3340/4518] 73% | Training loss: 0.6870151671820772
Epoch: 61 | Iteration number: [3350/4518] 74% | Training loss: 0.6870124794653992
Epoch: 61 | Iteration number: [3360/4518] 74% | Training loss: 0.687008100073962
Epoch: 61 | Iteration number: [3370/4518] 74% | Training loss: 0.6870069125108974
Epoch: 61 | Iteration number: [3380/4518] 74% | Training loss: 0.6870075020917069
Epoch: 61 | Iteration number: [3390/4518] 75% | Training loss: 0.6870070999350871
Epoch: 61 | Iteration number: [3400/4518] 75% | Training loss: 0.6870059617477304
Epoch: 61 | Iteration number: [3410/4518] 75% | Training loss: 0.6870069158391868
Epoch: 61 | Iteration number: [3420/4518] 75% | Training loss: 0.6870079562852257
Epoch: 61 | Iteration number: [3430/4518] 75% | Training loss: 0.687009966894767
Epoch: 61 | Iteration number: [3440/4518] 76% | Training loss: 0.6870143826097943
Epoch: 61 | Iteration number: [3450/4518] 76% | Training loss: 0.6870112869359445
Epoch: 61 | Iteration number: [3460/4518] 76% | Training loss: 0.687012868826789
Epoch: 61 | Iteration number: [3470/4518] 76% | Training loss: 0.6870147716930346
Epoch: 61 | Iteration number: [3480/4518] 77% | Training loss: 0.6870116925787652
Epoch: 61 | Iteration number: [3490/4518] 77% | Training loss: 0.6870093081776255
Epoch: 61 | Iteration number: [3500/4518] 77% | Training loss: 0.687009869490351
Epoch: 61 | Iteration number: [3510/4518] 77% | Training loss: 0.6870046627147924
Epoch: 61 | Iteration number: [3520/4518] 77% | Training loss: 0.6870029906488277
Epoch: 61 | Iteration number: [3530/4518] 78% | Training loss: 0.6870027439790137
Epoch: 61 | Iteration number: [3540/4518] 78% | Training loss: 0.6870033023889456
Epoch: 61 | Iteration number: [3550/4518] 78% | Training loss: 0.6870045021050413
Epoch: 61 | Iteration number: [3560/4518] 78% | Training loss: 0.6870021032650819
Epoch: 61 | Iteration number: [3570/4518] 79% | Training loss: 0.6870010799219628
Epoch: 61 | Iteration number: [3580/4518] 79% | Training loss: 0.6870017801583146
Epoch: 61 | Iteration number: [3590/4518] 79% | Training loss: 0.6870010131912975
Epoch: 61 | Iteration number: [3600/4518] 79% | Training loss: 0.6870000424318844
Epoch: 61 | Iteration number: [3610/4518] 79% | Training loss: 0.6869952381482746
Epoch: 61 | Iteration number: [3620/4518] 80% | Training loss: 0.686993166820779
Epoch: 61 | Iteration number: [3630/4518] 80% | Training loss: 0.6869929166700558
Epoch: 61 | Iteration number: [3640/4518] 80% | Training loss: 0.686991713826473
Epoch: 61 | Iteration number: [3650/4518] 80% | Training loss: 0.6869922169920516
Epoch: 61 | Iteration number: [3660/4518] 81% | Training loss: 0.686993853202283
Epoch: 61 | Iteration number: [3670/4518] 81% | Training loss: 0.6869947480570717
Epoch: 61 | Iteration number: [3680/4518] 81% | Training loss: 0.6869974057311597
Epoch: 61 | Iteration number: [3690/4518] 81% | Training loss: 0.6869953200261444
Epoch: 61 | Iteration number: [3700/4518] 81% | Training loss: 0.6869927338329521
Epoch: 61 | Iteration number: [3710/4518] 82% | Training loss: 0.686992755459968
Epoch: 61 | Iteration number: [3720/4518] 82% | Training loss: 0.6869924051146353
Epoch: 61 | Iteration number: [3730/4518] 82% | Training loss: 0.6869895407885074
Epoch: 61 | Iteration number: [3740/4518] 82% | Training loss: 0.6869893846505466
Epoch: 61 | Iteration number: [3750/4518] 83% | Training loss: 0.6869934262275695
Epoch: 61 | Iteration number: [3760/4518] 83% | Training loss: 0.6869942175898146
Epoch: 61 | Iteration number: [3770/4518] 83% | Training loss: 0.6869941564074246
Epoch: 61 | Iteration number: [3780/4518] 83% | Training loss: 0.6869908486093793
Epoch: 61 | Iteration number: [3790/4518] 83% | Training loss: 0.6869916838674872
Epoch: 61 | Iteration number: [3800/4518] 84% | Training loss: 0.686994582775392
Epoch: 61 | Iteration number: [3810/4518] 84% | Training loss: 0.686996534615364
Epoch: 61 | Iteration number: [3820/4518] 84% | Training loss: 0.6869971121480952
Epoch: 61 | Iteration number: [3830/4518] 84% | Training loss: 0.6869982807972412
Epoch: 61 | Iteration number: [3840/4518] 84% | Training loss: 0.6869962906309713
Epoch: 61 | Iteration number: [3850/4518] 85% | Training loss: 0.6869951645430032
Epoch: 61 | Iteration number: [3860/4518] 85% | Training loss: 0.6869966756494552
Epoch: 61 | Iteration number: [3870/4518] 85% | Training loss: 0.6869954805041468
Epoch: 61 | Iteration number: [3880/4518] 85% | Training loss: 0.6869945526430288
Epoch: 61 | Iteration number: [3890/4518] 86% | Training loss: 0.6869938337864178
Epoch: 61 | Iteration number: [3900/4518] 86% | Training loss: 0.6869951023046788
Epoch: 61 | Iteration number: [3910/4518] 86% | Training loss: 0.6869925974732469
Epoch: 61 | Iteration number: [3920/4518] 86% | Training loss: 0.6869917859076237
Epoch: 61 | Iteration number: [3930/4518] 86% | Training loss: 0.6869909054298741
Epoch: 61 | Iteration number: [3940/4518] 87% | Training loss: 0.686989748160246
Epoch: 61 | Iteration number: [3950/4518] 87% | Training loss: 0.6869908513449415
Epoch: 61 | Iteration number: [3960/4518] 87% | Training loss: 0.6869881575005223
Epoch: 61 | Iteration number: [3970/4518] 87% | Training loss: 0.6869881808757782
Epoch: 61 | Iteration number: [3980/4518] 88% | Training loss: 0.686987408501419
Epoch: 61 | Iteration number: [3990/4518] 88% | Training loss: 0.6869846393888756
Epoch: 61 | Iteration number: [4000/4518] 88% | Training loss: 0.6869841486364603
Epoch: 61 | Iteration number: [4010/4518] 88% | Training loss: 0.6869803795939372
Epoch: 61 | Iteration number: [4020/4518] 88% | Training loss: 0.6869797856801778
Epoch: 61 | Iteration number: [4030/4518] 89% | Training loss: 0.6869755653826238
Epoch: 61 | Iteration number: [4040/4518] 89% | Training loss: 0.68697374461606
Epoch: 61 | Iteration number: [4050/4518] 89% | Training loss: 0.6869742017174945
Epoch: 61 | Iteration number: [4060/4518] 89% | Training loss: 0.6869764774303718
Epoch: 61 | Iteration number: [4070/4518] 90% | Training loss: 0.6869757588577505
Epoch: 61 | Iteration number: [4080/4518] 90% | Training loss: 0.6869743241398942
Epoch: 61 | Iteration number: [4090/4518] 90% | Training loss: 0.6869698513253686
Epoch: 61 | Iteration number: [4100/4518] 90% | Training loss: 0.6869692263806738
Epoch: 61 | Iteration number: [4110/4518] 90% | Training loss: 0.6869695956109504
Epoch: 61 | Iteration number: [4120/4518] 91% | Training loss: 0.6869675000894417
Epoch: 61 | Iteration number: [4130/4518] 91% | Training loss: 0.6869684086151908
Epoch: 61 | Iteration number: [4140/4518] 91% | Training loss: 0.6869700813638991
Epoch: 61 | Iteration number: [4150/4518] 91% | Training loss: 0.6869652655900242
Epoch: 61 | Iteration number: [4160/4518] 92% | Training loss: 0.6869623767355314
Epoch: 61 | Iteration number: [4170/4518] 92% | Training loss: 0.6869603681335632
Epoch: 61 | Iteration number: [4180/4518] 92% | Training loss: 0.6869565772382836
Epoch: 61 | Iteration number: [4190/4518] 92% | Training loss: 0.6869562759177497
Epoch: 61 | Iteration number: [4200/4518] 92% | Training loss: 0.6869555283160437
Epoch: 61 | Iteration number: [4210/4518] 93% | Training loss: 0.6869522015725632
Epoch: 61 | Iteration number: [4220/4518] 93% | Training loss: 0.6869533384157018
Epoch: 61 | Iteration number: [4230/4518] 93% | Training loss: 0.686949382535673
Epoch: 61 | Iteration number: [4240/4518] 93% | Training loss: 0.6869456211069844
Epoch: 61 | Iteration number: [4250/4518] 94% | Training loss: 0.6869446559934055
Epoch: 61 | Iteration number: [4260/4518] 94% | Training loss: 0.6869451723048384
Epoch: 61 | Iteration number: [4270/4518] 94% | Training loss: 0.6869459184885583
Epoch: 61 | Iteration number: [4280/4518] 94% | Training loss: 0.6869483067610553
Epoch: 61 | Iteration number: [4290/4518] 94% | Training loss: 0.686949459378258
Epoch: 61 | Iteration number: [4300/4518] 95% | Training loss: 0.6869497815952744
Epoch: 61 | Iteration number: [4310/4518] 95% | Training loss: 0.6869521823532343
Epoch: 61 | Iteration number: [4320/4518] 95% | Training loss: 0.686953216942924
Epoch: 61 | Iteration number: [4330/4518] 95% | Training loss: 0.6869530288919841
Epoch: 61 | Iteration number: [4340/4518] 96% | Training loss: 0.6869567772210469
Epoch: 61 | Iteration number: [4350/4518] 96% | Training loss: 0.6869574520779752
Epoch: 61 | Iteration number: [4360/4518] 96% | Training loss: 0.6869563793643899
Epoch: 61 | Iteration number: [4370/4518] 96% | Training loss: 0.6869568975757406
Epoch: 61 | Iteration number: [4380/4518] 96% | Training loss: 0.6869568629079758
Epoch: 61 | Iteration number: [4390/4518] 97% | Training loss: 0.6869555782620076
Epoch: 61 | Iteration number: [4400/4518] 97% | Training loss: 0.6869551435925744
Epoch: 61 | Iteration number: [4410/4518] 97% | Training loss: 0.6869563594156382
Epoch: 61 | Iteration number: [4420/4518] 97% | Training loss: 0.6869546230292428
Epoch: 61 | Iteration number: [4430/4518] 98% | Training loss: 0.6869540250866462
Epoch: 61 | Iteration number: [4440/4518] 98% | Training loss: 0.68695489879664
Epoch: 61 | Iteration number: [4450/4518] 98% | Training loss: 0.6869541959548264
Epoch: 61 | Iteration number: [4460/4518] 98% | Training loss: 0.6869500604846552
Epoch: 61 | Iteration number: [4470/4518] 98% | Training loss: 0.6869495736272543
Epoch: 61 | Iteration number: [4480/4518] 99% | Training loss: 0.686948290307607
Epoch: 61 | Iteration number: [4490/4518] 99% | Training loss: 0.6869495523002471
Epoch: 61 | Iteration number: [4500/4518] 99% | Training loss: 0.6869508854680592
Epoch: 61 | Iteration number: [4510/4518] 99% | Training loss: 0.6869492031518213

 End of epoch: 61 | Train Loss: 0.6867952912373055 | Training Time: 641 

 End of epoch: 61 | Eval Loss: 0.6900699844165724 | Evaluating Time: 17 
Epoch: 62 | Iteration number: [10/4518] 0% | Training loss: 0.7559246718883514
Epoch: 62 | Iteration number: [20/4518] 0% | Training loss: 0.7207999616861344
Epoch: 62 | Iteration number: [30/4518] 0% | Training loss: 0.7098375141620636
Epoch: 62 | Iteration number: [40/4518] 0% | Training loss: 0.7041175082325936
Epoch: 62 | Iteration number: [50/4518] 1% | Training loss: 0.7010470342636108
Epoch: 62 | Iteration number: [60/4518] 1% | Training loss: 0.6984544227520625
Epoch: 62 | Iteration number: [70/4518] 1% | Training loss: 0.696736090523856
Epoch: 62 | Iteration number: [80/4518] 1% | Training loss: 0.6955261692404747
Epoch: 62 | Iteration number: [90/4518] 1% | Training loss: 0.6945902340941958
Epoch: 62 | Iteration number: [100/4518] 2% | Training loss: 0.6937793636322022
Epoch: 62 | Iteration number: [110/4518] 2% | Training loss: 0.693190948529677
Epoch: 62 | Iteration number: [120/4518] 2% | Training loss: 0.6926498462756475
Epoch: 62 | Iteration number: [130/4518] 2% | Training loss: 0.6922488794876979
Epoch: 62 | Iteration number: [140/4518] 3% | Training loss: 0.691863306931087
Epoch: 62 | Iteration number: [150/4518] 3% | Training loss: 0.6914306577046713
Epoch: 62 | Iteration number: [160/4518] 3% | Training loss: 0.6911131009459496
Epoch: 62 | Iteration number: [170/4518] 3% | Training loss: 0.6908915305838865
Epoch: 62 | Iteration number: [180/4518] 3% | Training loss: 0.690703061885304
Epoch: 62 | Iteration number: [190/4518] 4% | Training loss: 0.690506101595728
Epoch: 62 | Iteration number: [200/4518] 4% | Training loss: 0.6903235578536987
Epoch: 62 | Iteration number: [210/4518] 4% | Training loss: 0.6901933147793724
Epoch: 62 | Iteration number: [220/4518] 4% | Training loss: 0.690032129667022
Epoch: 62 | Iteration number: [230/4518] 5% | Training loss: 0.6898622188879096
Epoch: 62 | Iteration number: [240/4518] 5% | Training loss: 0.6897499702870846
Epoch: 62 | Iteration number: [250/4518] 5% | Training loss: 0.6896129512786865
Epoch: 62 | Iteration number: [260/4518] 5% | Training loss: 0.689479602758701
Epoch: 62 | Iteration number: [270/4518] 5% | Training loss: 0.6893659558561113
Epoch: 62 | Iteration number: [280/4518] 6% | Training loss: 0.689302929171494
Epoch: 62 | Iteration number: [290/4518] 6% | Training loss: 0.6892031741553339
Epoch: 62 | Iteration number: [300/4518] 6% | Training loss: 0.6890768142541249
Epoch: 62 | Iteration number: [310/4518] 6% | Training loss: 0.6890551345963631
Epoch: 62 | Iteration number: [320/4518] 7% | Training loss: 0.6889931537210942
Epoch: 62 | Iteration number: [330/4518] 7% | Training loss: 0.6888921186779484
Epoch: 62 | Iteration number: [340/4518] 7% | Training loss: 0.6887792480342528
Epoch: 62 | Iteration number: [350/4518] 7% | Training loss: 0.6887041773114886
Epoch: 62 | Iteration number: [360/4518] 7% | Training loss: 0.6886330188976394
Epoch: 62 | Iteration number: [370/4518] 8% | Training loss: 0.6885493431542371
Epoch: 62 | Iteration number: [380/4518] 8% | Training loss: 0.6884601064418492
Epoch: 62 | Iteration number: [390/4518] 8% | Training loss: 0.6884401251108219
Epoch: 62 | Iteration number: [400/4518] 8% | Training loss: 0.6884055933356286
Epoch: 62 | Iteration number: [410/4518] 9% | Training loss: 0.6884040182683526
Epoch: 62 | Iteration number: [420/4518] 9% | Training loss: 0.6883567787352063
Epoch: 62 | Iteration number: [430/4518] 9% | Training loss: 0.6883020567339521
Epoch: 62 | Iteration number: [440/4518] 9% | Training loss: 0.6882846331054514
Epoch: 62 | Iteration number: [450/4518] 9% | Training loss: 0.6882406859927708
Epoch: 62 | Iteration number: [460/4518] 10% | Training loss: 0.6882270942563596
Epoch: 62 | Iteration number: [470/4518] 10% | Training loss: 0.6881989073246083
Epoch: 62 | Iteration number: [480/4518] 10% | Training loss: 0.688165873537461
Epoch: 62 | Iteration number: [490/4518] 10% | Training loss: 0.6881581155621276
Epoch: 62 | Iteration number: [500/4518] 11% | Training loss: 0.6881504528522492
Epoch: 62 | Iteration number: [510/4518] 11% | Training loss: 0.6881162447087905
Epoch: 62 | Iteration number: [520/4518] 11% | Training loss: 0.6880701455932398
Epoch: 62 | Iteration number: [530/4518] 11% | Training loss: 0.688061504319029
Epoch: 62 | Iteration number: [540/4518] 11% | Training loss: 0.6880322477331868
Epoch: 62 | Iteration number: [550/4518] 12% | Training loss: 0.6880179228565909
Epoch: 62 | Iteration number: [560/4518] 12% | Training loss: 0.6879971617034504
Epoch: 62 | Iteration number: [570/4518] 12% | Training loss: 0.6879786050110532
Epoch: 62 | Iteration number: [580/4518] 12% | Training loss: 0.68794309270793
Epoch: 62 | Iteration number: [590/4518] 13% | Training loss: 0.6879150167360144
Epoch: 62 | Iteration number: [600/4518] 13% | Training loss: 0.6878808807333311
Epoch: 62 | Iteration number: [610/4518] 13% | Training loss: 0.6878618039068628
Epoch: 62 | Iteration number: [620/4518] 13% | Training loss: 0.6878360212810578
Epoch: 62 | Iteration number: [630/4518] 13% | Training loss: 0.687827931226246
Epoch: 62 | Iteration number: [640/4518] 14% | Training loss: 0.6878276398405433
Epoch: 62 | Iteration number: [650/4518] 14% | Training loss: 0.6878030824661255
Epoch: 62 | Iteration number: [660/4518] 14% | Training loss: 0.6877897049441483
Epoch: 62 | Iteration number: [670/4518] 14% | Training loss: 0.687791461197298
Epoch: 62 | Iteration number: [680/4518] 15% | Training loss: 0.6877469319631072
Epoch: 62 | Iteration number: [690/4518] 15% | Training loss: 0.687739581387976
Epoch: 62 | Iteration number: [700/4518] 15% | Training loss: 0.6877069942440306
Epoch: 62 | Iteration number: [710/4518] 15% | Training loss: 0.6876938332134569
Epoch: 62 | Iteration number: [720/4518] 15% | Training loss: 0.6876906261675888
Epoch: 62 | Iteration number: [730/4518] 16% | Training loss: 0.6876763813299676
Epoch: 62 | Iteration number: [740/4518] 16% | Training loss: 0.6876549777952401
Epoch: 62 | Iteration number: [750/4518] 16% | Training loss: 0.6876351380348206
Epoch: 62 | Iteration number: [760/4518] 16% | Training loss: 0.6876310664572214
Epoch: 62 | Iteration number: [770/4518] 17% | Training loss: 0.6876229598924711
Epoch: 62 | Iteration number: [780/4518] 17% | Training loss: 0.6876111175005253
Epoch: 62 | Iteration number: [790/4518] 17% | Training loss: 0.6875944401644454
Epoch: 62 | Iteration number: [800/4518] 17% | Training loss: 0.6875991552323103
Epoch: 62 | Iteration number: [810/4518] 17% | Training loss: 0.6875929382112291
Epoch: 62 | Iteration number: [820/4518] 18% | Training loss: 0.6875767311671885
Epoch: 62 | Iteration number: [830/4518] 18% | Training loss: 0.6875756528004107
Epoch: 62 | Iteration number: [840/4518] 18% | Training loss: 0.6875766407166208
Epoch: 62 | Iteration number: [850/4518] 18% | Training loss: 0.6875792788757997
Epoch: 62 | Iteration number: [860/4518] 19% | Training loss: 0.6875730591457944
Epoch: 62 | Iteration number: [870/4518] 19% | Training loss: 0.6875575149196318
Epoch: 62 | Iteration number: [880/4518] 19% | Training loss: 0.6875514205206524
Epoch: 62 | Iteration number: [890/4518] 19% | Training loss: 0.6875463823923904
Epoch: 62 | Iteration number: [900/4518] 19% | Training loss: 0.6875568861431546
Epoch: 62 | Iteration number: [910/4518] 20% | Training loss: 0.6875481519725296
Epoch: 62 | Iteration number: [920/4518] 20% | Training loss: 0.6875458154341448
Epoch: 62 | Iteration number: [930/4518] 20% | Training loss: 0.6875379984737724
Epoch: 62 | Iteration number: [940/4518] 20% | Training loss: 0.6875283881704858
Epoch: 62 | Iteration number: [950/4518] 21% | Training loss: 0.6875106994729293
Epoch: 62 | Iteration number: [960/4518] 21% | Training loss: 0.687523090839386
Epoch: 62 | Iteration number: [970/4518] 21% | Training loss: 0.687520785430043
Epoch: 62 | Iteration number: [980/4518] 21% | Training loss: 0.6875110323331795
Epoch: 62 | Iteration number: [990/4518] 21% | Training loss: 0.6875003493193425
Epoch: 62 | Iteration number: [1000/4518] 22% | Training loss: 0.6874945287108422
Epoch: 62 | Iteration number: [1010/4518] 22% | Training loss: 0.6874906017638669
Epoch: 62 | Iteration number: [1020/4518] 22% | Training loss: 0.6874756279529309
Epoch: 62 | Iteration number: [1030/4518] 22% | Training loss: 0.6874734821828824
Epoch: 62 | Iteration number: [1040/4518] 23% | Training loss: 0.687464098059214
Epoch: 62 | Iteration number: [1050/4518] 23% | Training loss: 0.6874569529578799
Epoch: 62 | Iteration number: [1060/4518] 23% | Training loss: 0.6874513246540753
Epoch: 62 | Iteration number: [1070/4518] 23% | Training loss: 0.6874389121465594
Epoch: 62 | Iteration number: [1080/4518] 23% | Training loss: 0.6874395750187061
Epoch: 62 | Iteration number: [1090/4518] 24% | Training loss: 0.6874329416030044
Epoch: 62 | Iteration number: [1100/4518] 24% | Training loss: 0.687438224662434
Epoch: 62 | Iteration number: [1110/4518] 24% | Training loss: 0.6874133468748213
Epoch: 62 | Iteration number: [1120/4518] 24% | Training loss: 0.6874201723507473
Epoch: 62 | Iteration number: [1130/4518] 25% | Training loss: 0.687420720494954
Epoch: 62 | Iteration number: [1140/4518] 25% | Training loss: 0.6874195114562386
Epoch: 62 | Iteration number: [1150/4518] 25% | Training loss: 0.6874082136672476
Epoch: 62 | Iteration number: [1160/4518] 25% | Training loss: 0.6874115337071748
Epoch: 62 | Iteration number: [1170/4518] 25% | Training loss: 0.6874105976178095
Epoch: 62 | Iteration number: [1180/4518] 26% | Training loss: 0.6873983538251812
Epoch: 62 | Iteration number: [1190/4518] 26% | Training loss: 0.6873956905693567
Epoch: 62 | Iteration number: [1200/4518] 26% | Training loss: 0.6873941606779893
Epoch: 62 | Iteration number: [1210/4518] 26% | Training loss: 0.6873818517223863
Epoch: 62 | Iteration number: [1220/4518] 27% | Training loss: 0.6873699910328036
Epoch: 62 | Iteration number: [1230/4518] 27% | Training loss: 0.6873680001351892
Epoch: 62 | Iteration number: [1240/4518] 27% | Training loss: 0.6873674840215713
Epoch: 62 | Iteration number: [1250/4518] 27% | Training loss: 0.6873654491901398
Epoch: 62 | Iteration number: [1260/4518] 27% | Training loss: 0.6873615679759828
Epoch: 62 | Iteration number: [1270/4518] 28% | Training loss: 0.6873497516620817
Epoch: 62 | Iteration number: [1280/4518] 28% | Training loss: 0.6873380635865033
Epoch: 62 | Iteration number: [1290/4518] 28% | Training loss: 0.6873317148334296
Epoch: 62 | Iteration number: [1300/4518] 28% | Training loss: 0.6873320730832907
Epoch: 62 | Iteration number: [1310/4518] 28% | Training loss: 0.687314597932437
Epoch: 62 | Iteration number: [1320/4518] 29% | Training loss: 0.6873182407382763
Epoch: 62 | Iteration number: [1330/4518] 29% | Training loss: 0.6873155531578494
Epoch: 62 | Iteration number: [1340/4518] 29% | Training loss: 0.6873201579300325
Epoch: 62 | Iteration number: [1350/4518] 29% | Training loss: 0.6873188714627866
Epoch: 62 | Iteration number: [1360/4518] 30% | Training loss: 0.6873212240636348
Epoch: 62 | Iteration number: [1370/4518] 30% | Training loss: 0.687324601977411
Epoch: 62 | Iteration number: [1380/4518] 30% | Training loss: 0.6873202413752459
Epoch: 62 | Iteration number: [1390/4518] 30% | Training loss: 0.6873169194022528
Epoch: 62 | Iteration number: [1400/4518] 30% | Training loss: 0.6873190750394549
Epoch: 62 | Iteration number: [1410/4518] 31% | Training loss: 0.6873072775120431
Epoch: 62 | Iteration number: [1420/4518] 31% | Training loss: 0.6872862121168997
Epoch: 62 | Iteration number: [1430/4518] 31% | Training loss: 0.6872774367565875
Epoch: 62 | Iteration number: [1440/4518] 31% | Training loss: 0.6872795528007878
Epoch: 62 | Iteration number: [1450/4518] 32% | Training loss: 0.6872758081863667
Epoch: 62 | Iteration number: [1460/4518] 32% | Training loss: 0.6872622306216253
Epoch: 62 | Iteration number: [1470/4518] 32% | Training loss: 0.6872555707993151
Epoch: 62 | Iteration number: [1480/4518] 32% | Training loss: 0.6872533064436268
Epoch: 62 | Iteration number: [1490/4518] 32% | Training loss: 0.6872510370792159
Epoch: 62 | Iteration number: [1500/4518] 33% | Training loss: 0.6872489860057831
Epoch: 62 | Iteration number: [1510/4518] 33% | Training loss: 0.6872507855986917
Epoch: 62 | Iteration number: [1520/4518] 33% | Training loss: 0.6872418064035868
Epoch: 62 | Iteration number: [1530/4518] 33% | Training loss: 0.6872371647872176
Epoch: 62 | Iteration number: [1540/4518] 34% | Training loss: 0.6872266557696578
Epoch: 62 | Iteration number: [1550/4518] 34% | Training loss: 0.6872140494469673
Epoch: 62 | Iteration number: [1560/4518] 34% | Training loss: 0.6872155672082534
Epoch: 62 | Iteration number: [1570/4518] 34% | Training loss: 0.6872169905027766
Epoch: 62 | Iteration number: [1580/4518] 34% | Training loss: 0.6872137001798123
Epoch: 62 | Iteration number: [1590/4518] 35% | Training loss: 0.6872052720507735
Epoch: 62 | Iteration number: [1600/4518] 35% | Training loss: 0.6871991847082972
Epoch: 62 | Iteration number: [1610/4518] 35% | Training loss: 0.6872035606677488
Epoch: 62 | Iteration number: [1620/4518] 35% | Training loss: 0.6872098519846245
Epoch: 62 | Iteration number: [1630/4518] 36% | Training loss: 0.6872072885372887
Epoch: 62 | Iteration number: [1640/4518] 36% | Training loss: 0.687212304334815
Epoch: 62 | Iteration number: [1650/4518] 36% | Training loss: 0.687204101410779
Epoch: 62 | Iteration number: [1660/4518] 36% | Training loss: 0.6871994704367167
Epoch: 62 | Iteration number: [1670/4518] 36% | Training loss: 0.6871953250762232
Epoch: 62 | Iteration number: [1680/4518] 37% | Training loss: 0.6871909263942922
Epoch: 62 | Iteration number: [1690/4518] 37% | Training loss: 0.6871953010206392
Epoch: 62 | Iteration number: [1700/4518] 37% | Training loss: 0.6871898606244256
Epoch: 62 | Iteration number: [1710/4518] 37% | Training loss: 0.6871900745999744
Epoch: 62 | Iteration number: [1720/4518] 38% | Training loss: 0.6871881237210229
Epoch: 62 | Iteration number: [1730/4518] 38% | Training loss: 0.6871860982710226
Epoch: 62 | Iteration number: [1740/4518] 38% | Training loss: 0.6871878120748476
Epoch: 62 | Iteration number: [1750/4518] 38% | Training loss: 0.6871807139941625
Epoch: 62 | Iteration number: [1760/4518] 38% | Training loss: 0.6871772300113331
Epoch: 62 | Iteration number: [1770/4518] 39% | Training loss: 0.6871702184111385
Epoch: 62 | Iteration number: [1780/4518] 39% | Training loss: 0.6871690339586708
Epoch: 62 | Iteration number: [1790/4518] 39% | Training loss: 0.6871561370748381
Epoch: 62 | Iteration number: [1800/4518] 39% | Training loss: 0.6871506402889888
Epoch: 62 | Iteration number: [1810/4518] 40% | Training loss: 0.6871548296996902
Epoch: 62 | Iteration number: [1820/4518] 40% | Training loss: 0.6871497483371378
Epoch: 62 | Iteration number: [1830/4518] 40% | Training loss: 0.6871495984942535
Epoch: 62 | Iteration number: [1840/4518] 40% | Training loss: 0.6871497040209563
Epoch: 62 | Iteration number: [1850/4518] 40% | Training loss: 0.6871394775687037
Epoch: 62 | Iteration number: [1860/4518] 41% | Training loss: 0.6871406566071254
Epoch: 62 | Iteration number: [1870/4518] 41% | Training loss: 0.6871360294640383
Epoch: 62 | Iteration number: [1880/4518] 41% | Training loss: 0.6871364578604698
Epoch: 62 | Iteration number: [1890/4518] 41% | Training loss: 0.6871357792584354
Epoch: 62 | Iteration number: [1900/4518] 42% | Training loss: 0.6871332241673218
Epoch: 62 | Iteration number: [1910/4518] 42% | Training loss: 0.6871309592461711
Epoch: 62 | Iteration number: [1920/4518] 42% | Training loss: 0.6871294879975418
Epoch: 62 | Iteration number: [1930/4518] 42% | Training loss: 0.6871253768397119
Epoch: 62 | Iteration number: [1940/4518] 42% | Training loss: 0.6871332980922817
Epoch: 62 | Iteration number: [1950/4518] 43% | Training loss: 0.6871345590628111
Epoch: 62 | Iteration number: [1960/4518] 43% | Training loss: 0.6871355598070183
Epoch: 62 | Iteration number: [1970/4518] 43% | Training loss: 0.6871318015047742
Epoch: 62 | Iteration number: [1980/4518] 43% | Training loss: 0.6871336510687164
Epoch: 62 | Iteration number: [1990/4518] 44% | Training loss: 0.687133606774124
Epoch: 62 | Iteration number: [2000/4518] 44% | Training loss: 0.6871400916576386
Epoch: 62 | Iteration number: [2010/4518] 44% | Training loss: 0.6871379080993026
Epoch: 62 | Iteration number: [2020/4518] 44% | Training loss: 0.6871352890045336
Epoch: 62 | Iteration number: [2030/4518] 44% | Training loss: 0.6871363697087236
Epoch: 62 | Iteration number: [2040/4518] 45% | Training loss: 0.6871418990048708
Epoch: 62 | Iteration number: [2050/4518] 45% | Training loss: 0.6871404674285796
Epoch: 62 | Iteration number: [2060/4518] 45% | Training loss: 0.6871397304303438
Epoch: 62 | Iteration number: [2070/4518] 45% | Training loss: 0.6871395112811656
Epoch: 62 | Iteration number: [2080/4518] 46% | Training loss: 0.687134206495606
Epoch: 62 | Iteration number: [2090/4518] 46% | Training loss: 0.687128403825623
Epoch: 62 | Iteration number: [2100/4518] 46% | Training loss: 0.6871268603631429
Epoch: 62 | Iteration number: [2110/4518] 46% | Training loss: 0.6871239948329202
Epoch: 62 | Iteration number: [2120/4518] 46% | Training loss: 0.6871197689816637
Epoch: 62 | Iteration number: [2130/4518] 47% | Training loss: 0.687123660022664
Epoch: 62 | Iteration number: [2140/4518] 47% | Training loss: 0.6871233397833655
Epoch: 62 | Iteration number: [2150/4518] 47% | Training loss: 0.6871226907053659
Epoch: 62 | Iteration number: [2160/4518] 47% | Training loss: 0.6871250009647122
Epoch: 62 | Iteration number: [2170/4518] 48% | Training loss: 0.6871168667270291
Epoch: 62 | Iteration number: [2180/4518] 48% | Training loss: 0.6871164078285935
Epoch: 62 | Iteration number: [2190/4518] 48% | Training loss: 0.6871142365888918
Epoch: 62 | Iteration number: [2200/4518] 48% | Training loss: 0.6871186489408666
Epoch: 62 | Iteration number: [2210/4518] 48% | Training loss: 0.6871185129044822
Epoch: 62 | Iteration number: [2220/4518] 49% | Training loss: 0.6871149822935327
Epoch: 62 | Iteration number: [2230/4518] 49% | Training loss: 0.6871140821097678
Epoch: 62 | Iteration number: [2240/4518] 49% | Training loss: 0.6871073921610202
Epoch: 62 | Iteration number: [2250/4518] 49% | Training loss: 0.6871089894771576
Epoch: 62 | Iteration number: [2260/4518] 50% | Training loss: 0.6871095049697741
Epoch: 62 | Iteration number: [2270/4518] 50% | Training loss: 0.6871130225941998
Epoch: 62 | Iteration number: [2280/4518] 50% | Training loss: 0.6871115050294943
Epoch: 62 | Iteration number: [2290/4518] 50% | Training loss: 0.6871096395769494
Epoch: 62 | Iteration number: [2300/4518] 50% | Training loss: 0.6871068280935287
Epoch: 62 | Iteration number: [2310/4518] 51% | Training loss: 0.6871027590908529
Epoch: 62 | Iteration number: [2320/4518] 51% | Training loss: 0.6871028733664546
Epoch: 62 | Iteration number: [2330/4518] 51% | Training loss: 0.687100523070716
Epoch: 62 | Iteration number: [2340/4518] 51% | Training loss: 0.6871019530245381
Epoch: 62 | Iteration number: [2350/4518] 52% | Training loss: 0.6870985007539708
Epoch: 62 | Iteration number: [2360/4518] 52% | Training loss: 0.6871032149862435
Epoch: 62 | Iteration number: [2370/4518] 52% | Training loss: 0.6870999705690874
Epoch: 62 | Iteration number: [2380/4518] 52% | Training loss: 0.6871028145571717
Epoch: 62 | Iteration number: [2390/4518] 52% | Training loss: 0.6870980894465826
Epoch: 62 | Iteration number: [2400/4518] 53% | Training loss: 0.687100815474987
Epoch: 62 | Iteration number: [2410/4518] 53% | Training loss: 0.6870984191469137
Epoch: 62 | Iteration number: [2420/4518] 53% | Training loss: 0.6870936997419547
Epoch: 62 | Iteration number: [2430/4518] 53% | Training loss: 0.6870929193104246
Epoch: 62 | Iteration number: [2440/4518] 54% | Training loss: 0.6870961136749534
Epoch: 62 | Iteration number: [2450/4518] 54% | Training loss: 0.6870972894892401
Epoch: 62 | Iteration number: [2460/4518] 54% | Training loss: 0.6870910119719622
Epoch: 62 | Iteration number: [2470/4518] 54% | Training loss: 0.687088060306634
Epoch: 62 | Iteration number: [2480/4518] 54% | Training loss: 0.687081579094933
Epoch: 62 | Iteration number: [2490/4518] 55% | Training loss: 0.687081566273448
Epoch: 62 | Iteration number: [2500/4518] 55% | Training loss: 0.6870810120582581
Epoch: 62 | Iteration number: [2510/4518] 55% | Training loss: 0.6870780530678798
Epoch: 62 | Iteration number: [2520/4518] 55% | Training loss: 0.6870830302673673
Epoch: 62 | Iteration number: [2530/4518] 55% | Training loss: 0.6870789516820267
Epoch: 62 | Iteration number: [2540/4518] 56% | Training loss: 0.6870785197404425
Epoch: 62 | Iteration number: [2550/4518] 56% | Training loss: 0.6870728442715663
Epoch: 62 | Iteration number: [2560/4518] 56% | Training loss: 0.6870731910923495
Epoch: 62 | Iteration number: [2570/4518] 56% | Training loss: 0.6870710463375433
Epoch: 62 | Iteration number: [2580/4518] 57% | Training loss: 0.6870707505895186
Epoch: 62 | Iteration number: [2590/4518] 57% | Training loss: 0.6870699319139871
Epoch: 62 | Iteration number: [2600/4518] 57% | Training loss: 0.6870663227484777
Epoch: 62 | Iteration number: [2610/4518] 57% | Training loss: 0.6870675229478156
Epoch: 62 | Iteration number: [2620/4518] 57% | Training loss: 0.6870631485039951
Epoch: 62 | Iteration number: [2630/4518] 58% | Training loss: 0.6870635557537297
Epoch: 62 | Iteration number: [2640/4518] 58% | Training loss: 0.6870633475934014
Epoch: 62 | Iteration number: [2650/4518] 58% | Training loss: 0.6870675637362138
Epoch: 62 | Iteration number: [2660/4518] 58% | Training loss: 0.687070209079219
Epoch: 62 | Iteration number: [2670/4518] 59% | Training loss: 0.6870694241050478
Epoch: 62 | Iteration number: [2680/4518] 59% | Training loss: 0.6870679388072953
Epoch: 62 | Iteration number: [2690/4518] 59% | Training loss: 0.6870692087593575
Epoch: 62 | Iteration number: [2700/4518] 59% | Training loss: 0.6870672589098966
Epoch: 62 | Iteration number: [2710/4518] 59% | Training loss: 0.6870642439025795
Epoch: 62 | Iteration number: [2720/4518] 60% | Training loss: 0.6870629062547403
Epoch: 62 | Iteration number: [2730/4518] 60% | Training loss: 0.6870587982537546
Epoch: 62 | Iteration number: [2740/4518] 60% | Training loss: 0.6870583627998393
Epoch: 62 | Iteration number: [2750/4518] 60% | Training loss: 0.6870574057752435
Epoch: 62 | Iteration number: [2760/4518] 61% | Training loss: 0.6870579747834067
Epoch: 62 | Iteration number: [2770/4518] 61% | Training loss: 0.6870537735925254
Epoch: 62 | Iteration number: [2780/4518] 61% | Training loss: 0.6870544375918752
Epoch: 62 | Iteration number: [2790/4518] 61% | Training loss: 0.6870479776654193
Epoch: 62 | Iteration number: [2800/4518] 61% | Training loss: 0.687049366171871
Epoch: 62 | Iteration number: [2810/4518] 62% | Training loss: 0.6870449122797128
Epoch: 62 | Iteration number: [2820/4518] 62% | Training loss: 0.6870428327973007
Epoch: 62 | Iteration number: [2830/4518] 62% | Training loss: 0.6870416211787045
Epoch: 62 | Iteration number: [2840/4518] 62% | Training loss: 0.6870360642671585
Epoch: 62 | Iteration number: [2850/4518] 63% | Training loss: 0.6870340518156688
Epoch: 62 | Iteration number: [2860/4518] 63% | Training loss: 0.6870351073416796
Epoch: 62 | Iteration number: [2870/4518] 63% | Training loss: 0.6870343392526647
Epoch: 62 | Iteration number: [2880/4518] 63% | Training loss: 0.6870336687606242
Epoch: 62 | Iteration number: [2890/4518] 63% | Training loss: 0.6870266407212584
Epoch: 62 | Iteration number: [2900/4518] 64% | Training loss: 0.6870221348261011
Epoch: 62 | Iteration number: [2910/4518] 64% | Training loss: 0.6870272398199823
Epoch: 62 | Iteration number: [2920/4518] 64% | Training loss: 0.687028198454478
Epoch: 62 | Iteration number: [2930/4518] 64% | Training loss: 0.6870336567175673
Epoch: 62 | Iteration number: [2940/4518] 65% | Training loss: 0.6870382360049656
Epoch: 62 | Iteration number: [2950/4518] 65% | Training loss: 0.687033609838809
Epoch: 62 | Iteration number: [2960/4518] 65% | Training loss: 0.6870358866815631
Epoch: 62 | Iteration number: [2970/4518] 65% | Training loss: 0.6870327185701441
Epoch: 62 | Iteration number: [2980/4518] 65% | Training loss: 0.6870292256542501
Epoch: 62 | Iteration number: [2990/4518] 66% | Training loss: 0.6870284508502603
Epoch: 62 | Iteration number: [3000/4518] 66% | Training loss: 0.687026651819547
Epoch: 62 | Iteration number: [3010/4518] 66% | Training loss: 0.6870236174806804
Epoch: 62 | Iteration number: [3020/4518] 66% | Training loss: 0.687022911456247
Epoch: 62 | Iteration number: [3030/4518] 67% | Training loss: 0.6870251802328002
Epoch: 62 | Iteration number: [3040/4518] 67% | Training loss: 0.6870223096522846
Epoch: 62 | Iteration number: [3050/4518] 67% | Training loss: 0.6870195753457117
Epoch: 62 | Iteration number: [3060/4518] 67% | Training loss: 0.6870176851944206
Epoch: 62 | Iteration number: [3070/4518] 67% | Training loss: 0.6870145657551794
Epoch: 62 | Iteration number: [3080/4518] 68% | Training loss: 0.6870145437972887
Epoch: 62 | Iteration number: [3090/4518] 68% | Training loss: 0.6870162377465504
Epoch: 62 | Iteration number: [3100/4518] 68% | Training loss: 0.6870210407818518
Epoch: 62 | Iteration number: [3110/4518] 68% | Training loss: 0.6870241935613455
Epoch: 62 | Iteration number: [3120/4518] 69% | Training loss: 0.6870202812246787
Epoch: 62 | Iteration number: [3130/4518] 69% | Training loss: 0.6870181780463209
Epoch: 62 | Iteration number: [3140/4518] 69% | Training loss: 0.6870166868540891
Epoch: 62 | Iteration number: [3150/4518] 69% | Training loss: 0.6870188280892751
Epoch: 62 | Iteration number: [3160/4518] 69% | Training loss: 0.687017785012722
Epoch: 62 | Iteration number: [3170/4518] 70% | Training loss: 0.6870179458183445
Epoch: 62 | Iteration number: [3180/4518] 70% | Training loss: 0.6870164957623812
Epoch: 62 | Iteration number: [3190/4518] 70% | Training loss: 0.6870170106708443
Epoch: 62 | Iteration number: [3200/4518] 70% | Training loss: 0.6870168669521809
Epoch: 62 | Iteration number: [3210/4518] 71% | Training loss: 0.6870167226249184
Epoch: 62 | Iteration number: [3220/4518] 71% | Training loss: 0.6870181943318858
Epoch: 62 | Iteration number: [3230/4518] 71% | Training loss: 0.6870208496095226
Epoch: 62 | Iteration number: [3240/4518] 71% | Training loss: 0.6870215053543632
Epoch: 62 | Iteration number: [3250/4518] 71% | Training loss: 0.6870192560416002
Epoch: 62 | Iteration number: [3260/4518] 72% | Training loss: 0.6870194976498013
Epoch: 62 | Iteration number: [3270/4518] 72% | Training loss: 0.6870182222000321
Epoch: 62 | Iteration number: [3280/4518] 72% | Training loss: 0.6870191442712051
Epoch: 62 | Iteration number: [3290/4518] 72% | Training loss: 0.6870196002957306
Epoch: 62 | Iteration number: [3300/4518] 73% | Training loss: 0.6870210103555159
Epoch: 62 | Iteration number: [3310/4518] 73% | Training loss: 0.6870163116210177
Epoch: 62 | Iteration number: [3320/4518] 73% | Training loss: 0.6870166931884835
Epoch: 62 | Iteration number: [3330/4518] 73% | Training loss: 0.6870173162347204
Epoch: 62 | Iteration number: [3340/4518] 73% | Training loss: 0.6870189962272872
Epoch: 62 | Iteration number: [3350/4518] 74% | Training loss: 0.6870191653984696
Epoch: 62 | Iteration number: [3360/4518] 74% | Training loss: 0.6870210513472557
Epoch: 62 | Iteration number: [3370/4518] 74% | Training loss: 0.6870184245024661
Epoch: 62 | Iteration number: [3380/4518] 74% | Training loss: 0.6870163419719278
Epoch: 62 | Iteration number: [3390/4518] 75% | Training loss: 0.6870169682312856
Epoch: 62 | Iteration number: [3400/4518] 75% | Training loss: 0.6870138946175576
Epoch: 62 | Iteration number: [3410/4518] 75% | Training loss: 0.6870136350131105
Epoch: 62 | Iteration number: [3420/4518] 75% | Training loss: 0.6870103477734572
Epoch: 62 | Iteration number: [3430/4518] 75% | Training loss: 0.6870164777377604
Epoch: 62 | Iteration number: [3440/4518] 76% | Training loss: 0.6870113932462626
Epoch: 62 | Iteration number: [3450/4518] 76% | Training loss: 0.6870117436975672
Epoch: 62 | Iteration number: [3460/4518] 76% | Training loss: 0.6870124281314067
Epoch: 62 | Iteration number: [3470/4518] 76% | Training loss: 0.687017632750338
Epoch: 62 | Iteration number: [3480/4518] 77% | Training loss: 0.6870190580857212
Epoch: 62 | Iteration number: [3490/4518] 77% | Training loss: 0.6870193112203932
Epoch: 62 | Iteration number: [3500/4518] 77% | Training loss: 0.6870159473589489
Epoch: 62 | Iteration number: [3510/4518] 77% | Training loss: 0.6870143964419677
Epoch: 62 | Iteration number: [3520/4518] 77% | Training loss: 0.687011329237033
Epoch: 62 | Iteration number: [3530/4518] 78% | Training loss: 0.6870103351792938
Epoch: 62 | Iteration number: [3540/4518] 78% | Training loss: 0.6870111895651467
Epoch: 62 | Iteration number: [3550/4518] 78% | Training loss: 0.6870118129085487
Epoch: 62 | Iteration number: [3560/4518] 78% | Training loss: 0.687010394572542
Epoch: 62 | Iteration number: [3570/4518] 79% | Training loss: 0.6870095095881561
Epoch: 62 | Iteration number: [3580/4518] 79% | Training loss: 0.687014233699724
Epoch: 62 | Iteration number: [3590/4518] 79% | Training loss: 0.6870138549705069
Epoch: 62 | Iteration number: [3600/4518] 79% | Training loss: 0.6870140877034929
Epoch: 62 | Iteration number: [3610/4518] 79% | Training loss: 0.6870111566996641
Epoch: 62 | Iteration number: [3620/4518] 80% | Training loss: 0.6870141418599292
Epoch: 62 | Iteration number: [3630/4518] 80% | Training loss: 0.6870128560821543
Epoch: 62 | Iteration number: [3640/4518] 80% | Training loss: 0.6870134968187783
Epoch: 62 | Iteration number: [3650/4518] 80% | Training loss: 0.6870145429650398
Epoch: 62 | Iteration number: [3660/4518] 81% | Training loss: 0.6870137360578026
Epoch: 62 | Iteration number: [3670/4518] 81% | Training loss: 0.687011184354569
Epoch: 62 | Iteration number: [3680/4518] 81% | Training loss: 0.6870144158601761
Epoch: 62 | Iteration number: [3690/4518] 81% | Training loss: 0.6870147289945504
Epoch: 62 | Iteration number: [3700/4518] 81% | Training loss: 0.6870134609454387
Epoch: 62 | Iteration number: [3710/4518] 82% | Training loss: 0.6870118972265495
Epoch: 62 | Iteration number: [3720/4518] 82% | Training loss: 0.6870106959054547
Epoch: 62 | Iteration number: [3730/4518] 82% | Training loss: 0.6870110279113933
Epoch: 62 | Iteration number: [3740/4518] 82% | Training loss: 0.687011602600628
Epoch: 62 | Iteration number: [3750/4518] 83% | Training loss: 0.6870093916893005
Epoch: 62 | Iteration number: [3760/4518] 83% | Training loss: 0.6870067160497321
Epoch: 62 | Iteration number: [3770/4518] 83% | Training loss: 0.6870071052398227
Epoch: 62 | Iteration number: [3780/4518] 83% | Training loss: 0.6870063072947598
Epoch: 62 | Iteration number: [3790/4518] 83% | Training loss: 0.6870048227914091
Epoch: 62 | Iteration number: [3800/4518] 84% | Training loss: 0.6870029651491265
Epoch: 62 | Iteration number: [3810/4518] 84% | Training loss: 0.6870017055920729
Epoch: 62 | Iteration number: [3820/4518] 84% | Training loss: 0.6869999019731402
Epoch: 62 | Iteration number: [3830/4518] 84% | Training loss: 0.6870008942819451
Epoch: 62 | Iteration number: [3840/4518] 84% | Training loss: 0.6869992163963616
Epoch: 62 | Iteration number: [3850/4518] 85% | Training loss: 0.6869982215491208
Epoch: 62 | Iteration number: [3860/4518] 85% | Training loss: 0.6869984949499832
Epoch: 62 | Iteration number: [3870/4518] 85% | Training loss: 0.6869972692749605
Epoch: 62 | Iteration number: [3880/4518] 85% | Training loss: 0.6869972692168865
Epoch: 62 | Iteration number: [3890/4518] 86% | Training loss: 0.6869954929560194
Epoch: 62 | Iteration number: [3900/4518] 86% | Training loss: 0.6869938565064699
Epoch: 62 | Iteration number: [3910/4518] 86% | Training loss: 0.686991105040016
Epoch: 62 | Iteration number: [3920/4518] 86% | Training loss: 0.6869862876376327
Epoch: 62 | Iteration number: [3930/4518] 86% | Training loss: 0.6869848875599053
Epoch: 62 | Iteration number: [3940/4518] 87% | Training loss: 0.6869844566141894
Epoch: 62 | Iteration number: [3950/4518] 87% | Training loss: 0.6869807148281531
Epoch: 62 | Iteration number: [3960/4518] 87% | Training loss: 0.686983261024109
Epoch: 62 | Iteration number: [3970/4518] 87% | Training loss: 0.6869801575801234
Epoch: 62 | Iteration number: [3980/4518] 88% | Training loss: 0.6869792618943219
Epoch: 62 | Iteration number: [3990/4518] 88% | Training loss: 0.6869808307715825
Epoch: 62 | Iteration number: [4000/4518] 88% | Training loss: 0.6869816264808178
Epoch: 62 | Iteration number: [4010/4518] 88% | Training loss: 0.6869786471054143
Epoch: 62 | Iteration number: [4020/4518] 88% | Training loss: 0.6869763714757132
Epoch: 62 | Iteration number: [4030/4518] 89% | Training loss: 0.6869746148882078
Epoch: 62 | Iteration number: [4040/4518] 89% | Training loss: 0.6869706697688245
Epoch: 62 | Iteration number: [4050/4518] 89% | Training loss: 0.6869676410563198
Epoch: 62 | Iteration number: [4060/4518] 89% | Training loss: 0.686968548559203
Epoch: 62 | Iteration number: [4070/4518] 90% | Training loss: 0.6869694099086509
Epoch: 62 | Iteration number: [4080/4518] 90% | Training loss: 0.6869699888807885
Epoch: 62 | Iteration number: [4090/4518] 90% | Training loss: 0.686968933807317
Epoch: 62 | Iteration number: [4100/4518] 90% | Training loss: 0.6869677763305059
Epoch: 62 | Iteration number: [4110/4518] 90% | Training loss: 0.6869661537545151
Epoch: 62 | Iteration number: [4120/4518] 91% | Training loss: 0.6869655140539975
Epoch: 62 | Iteration number: [4130/4518] 91% | Training loss: 0.686965986588388
Epoch: 62 | Iteration number: [4140/4518] 91% | Training loss: 0.686967814674124
Epoch: 62 | Iteration number: [4150/4518] 91% | Training loss: 0.6869677277645433
Epoch: 62 | Iteration number: [4160/4518] 92% | Training loss: 0.686966107499141
Epoch: 62 | Iteration number: [4170/4518] 92% | Training loss: 0.6869613980646614
Epoch: 62 | Iteration number: [4180/4518] 92% | Training loss: 0.6869616863687643
Epoch: 62 | Iteration number: [4190/4518] 92% | Training loss: 0.6869605818625566
Epoch: 62 | Iteration number: [4200/4518] 92% | Training loss: 0.6869600797125271
Epoch: 62 | Iteration number: [4210/4518] 93% | Training loss: 0.6869620753155752
Epoch: 62 | Iteration number: [4220/4518] 93% | Training loss: 0.6869644948232796
Epoch: 62 | Iteration number: [4230/4518] 93% | Training loss: 0.6869613775265696
Epoch: 62 | Iteration number: [4240/4518] 93% | Training loss: 0.6869620428754474
Epoch: 62 | Iteration number: [4250/4518] 94% | Training loss: 0.686960836873335
Epoch: 62 | Iteration number: [4260/4518] 94% | Training loss: 0.6869574654689977
Epoch: 62 | Iteration number: [4270/4518] 94% | Training loss: 0.686955160251546
Epoch: 62 | Iteration number: [4280/4518] 94% | Training loss: 0.6869552796828412
Epoch: 62 | Iteration number: [4290/4518] 94% | Training loss: 0.6869542539953352
Epoch: 62 | Iteration number: [4300/4518] 95% | Training loss: 0.6869559941458148
Epoch: 62 | Iteration number: [4310/4518] 95% | Training loss: 0.6869582190591056
Epoch: 62 | Iteration number: [4320/4518] 95% | Training loss: 0.6869582490926539
Epoch: 62 | Iteration number: [4330/4518] 95% | Training loss: 0.686958358524578
Epoch: 62 | Iteration number: [4340/4518] 96% | Training loss: 0.6869568869952233
Epoch: 62 | Iteration number: [4350/4518] 96% | Training loss: 0.6869553698342422
Epoch: 62 | Iteration number: [4360/4518] 96% | Training loss: 0.6869552885310366
Epoch: 62 | Iteration number: [4370/4518] 96% | Training loss: 0.6869535478083438
Epoch: 62 | Iteration number: [4380/4518] 96% | Training loss: 0.6869502553656766
Epoch: 62 | Iteration number: [4390/4518] 97% | Training loss: 0.6869516561813398
Epoch: 62 | Iteration number: [4400/4518] 97% | Training loss: 0.6869505914232947
Epoch: 62 | Iteration number: [4410/4518] 97% | Training loss: 0.6869523515371508
Epoch: 62 | Iteration number: [4420/4518] 97% | Training loss: 0.6869516237693675
Epoch: 62 | Iteration number: [4430/4518] 98% | Training loss: 0.6869503196017737
Epoch: 62 | Iteration number: [4440/4518] 98% | Training loss: 0.6869519338682966
Epoch: 62 | Iteration number: [4450/4518] 98% | Training loss: 0.6869512928335855
Epoch: 62 | Iteration number: [4460/4518] 98% | Training loss: 0.6869492002666798
Epoch: 62 | Iteration number: [4470/4518] 98% | Training loss: 0.6869468983521131
Epoch: 62 | Iteration number: [4480/4518] 99% | Training loss: 0.6869478160249335
Epoch: 62 | Iteration number: [4490/4518] 99% | Training loss: 0.6869500670241885
Epoch: 62 | Iteration number: [4500/4518] 99% | Training loss: 0.6869500090546078
Epoch: 62 | Iteration number: [4510/4518] 99% | Training loss: 0.6869489663323912

 End of epoch: 62 | Train Loss: 0.6867982200707625 | Training Time: 641 

 End of epoch: 62 | Eval Loss: 0.6900734402695481 | Evaluating Time: 23 
Epoch: 63 | Iteration number: [10/4518] 0% | Training loss: 0.756009715795517
Epoch: 63 | Iteration number: [20/4518] 0% | Training loss: 0.7217085152864456
Epoch: 63 | Iteration number: [30/4518] 0% | Training loss: 0.7103350142637889
Epoch: 63 | Iteration number: [40/4518] 0% | Training loss: 0.7045339435338974
Epoch: 63 | Iteration number: [50/4518] 1% | Training loss: 0.7010603809356689
Epoch: 63 | Iteration number: [60/4518] 1% | Training loss: 0.6982534646987915
Epoch: 63 | Iteration number: [70/4518] 1% | Training loss: 0.6965608877795083
Epoch: 63 | Iteration number: [80/4518] 1% | Training loss: 0.6952138699591159
Epoch: 63 | Iteration number: [90/4518] 1% | Training loss: 0.6944354236125946
Epoch: 63 | Iteration number: [100/4518] 2% | Training loss: 0.6936694371700287
Epoch: 63 | Iteration number: [110/4518] 2% | Training loss: 0.6930466841567646
Epoch: 63 | Iteration number: [120/4518] 2% | Training loss: 0.6925887073079745
Epoch: 63 | Iteration number: [130/4518] 2% | Training loss: 0.6921336939701668
Epoch: 63 | Iteration number: [140/4518] 3% | Training loss: 0.6917910618441445
Epoch: 63 | Iteration number: [150/4518] 3% | Training loss: 0.691609765291214
Epoch: 63 | Iteration number: [160/4518] 3% | Training loss: 0.691332221776247
Epoch: 63 | Iteration number: [170/4518] 3% | Training loss: 0.6910733941723318
Epoch: 63 | Iteration number: [180/4518] 3% | Training loss: 0.6908188932471805
Epoch: 63 | Iteration number: [190/4518] 4% | Training loss: 0.69057432224876
Epoch: 63 | Iteration number: [200/4518] 4% | Training loss: 0.6903267779946327
Epoch: 63 | Iteration number: [210/4518] 4% | Training loss: 0.6901975231511253
Epoch: 63 | Iteration number: [220/4518] 4% | Training loss: 0.6900832390243357
Epoch: 63 | Iteration number: [230/4518] 5% | Training loss: 0.6899142475231834
Epoch: 63 | Iteration number: [240/4518] 5% | Training loss: 0.6898448963960012
Epoch: 63 | Iteration number: [250/4518] 5% | Training loss: 0.6897097001075745
Epoch: 63 | Iteration number: [260/4518] 5% | Training loss: 0.6895262186343853
Epoch: 63 | Iteration number: [270/4518] 5% | Training loss: 0.6894040909078386
Epoch: 63 | Iteration number: [280/4518] 6% | Training loss: 0.6892666769879204
Epoch: 63 | Iteration number: [290/4518] 6% | Training loss: 0.6891751287312343
Epoch: 63 | Iteration number: [300/4518] 6% | Training loss: 0.6890608904759089
Epoch: 63 | Iteration number: [310/4518] 6% | Training loss: 0.6889989724082332
Epoch: 63 | Iteration number: [320/4518] 7% | Training loss: 0.688951344974339
Epoch: 63 | Iteration number: [330/4518] 7% | Training loss: 0.6888787659731779
Epoch: 63 | Iteration number: [340/4518] 7% | Training loss: 0.6888078300391927
Epoch: 63 | Iteration number: [350/4518] 7% | Training loss: 0.6887112920624869
Epoch: 63 | Iteration number: [360/4518] 7% | Training loss: 0.6886849815646807
Epoch: 63 | Iteration number: [370/4518] 8% | Training loss: 0.688650844387106
Epoch: 63 | Iteration number: [380/4518] 8% | Training loss: 0.6886362129136135
Epoch: 63 | Iteration number: [390/4518] 8% | Training loss: 0.6885553422646645
Epoch: 63 | Iteration number: [400/4518] 8% | Training loss: 0.6885182715952396
Epoch: 63 | Iteration number: [410/4518] 9% | Training loss: 0.6884466999914588
Epoch: 63 | Iteration number: [420/4518] 9% | Training loss: 0.6884028548286074
Epoch: 63 | Iteration number: [430/4518] 9% | Training loss: 0.6883642661017041
Epoch: 63 | Iteration number: [440/4518] 9% | Training loss: 0.6883239221843807
Epoch: 63 | Iteration number: [450/4518] 9% | Training loss: 0.688262190553877
Epoch: 63 | Iteration number: [460/4518] 10% | Training loss: 0.6882233329441236
Epoch: 63 | Iteration number: [470/4518] 10% | Training loss: 0.688206285238266
Epoch: 63 | Iteration number: [480/4518] 10% | Training loss: 0.6881903088341157
Epoch: 63 | Iteration number: [490/4518] 10% | Training loss: 0.6881832608154842
Epoch: 63 | Iteration number: [500/4518] 11% | Training loss: 0.6881606976985931
Epoch: 63 | Iteration number: [510/4518] 11% | Training loss: 0.6881269202512853
Epoch: 63 | Iteration number: [520/4518] 11% | Training loss: 0.6881172253535344
Epoch: 63 | Iteration number: [530/4518] 11% | Training loss: 0.6881268441677093
Epoch: 63 | Iteration number: [540/4518] 11% | Training loss: 0.6880812994859836
Epoch: 63 | Iteration number: [550/4518] 12% | Training loss: 0.6880511566725644
Epoch: 63 | Iteration number: [560/4518] 12% | Training loss: 0.6880385945950236
Epoch: 63 | Iteration number: [570/4518] 12% | Training loss: 0.6880402280573259
Epoch: 63 | Iteration number: [580/4518] 12% | Training loss: 0.6880178222368504
Epoch: 63 | Iteration number: [590/4518] 13% | Training loss: 0.6879926834066036
Epoch: 63 | Iteration number: [600/4518] 13% | Training loss: 0.6879593369364738
Epoch: 63 | Iteration number: [610/4518] 13% | Training loss: 0.687926671837197
Epoch: 63 | Iteration number: [620/4518] 13% | Training loss: 0.6879384726285934
Epoch: 63 | Iteration number: [630/4518] 13% | Training loss: 0.687928773486425
Epoch: 63 | Iteration number: [640/4518] 14% | Training loss: 0.6879001244902611
Epoch: 63 | Iteration number: [650/4518] 14% | Training loss: 0.6878933954238892
Epoch: 63 | Iteration number: [660/4518] 14% | Training loss: 0.6878903325760003
Epoch: 63 | Iteration number: [670/4518] 14% | Training loss: 0.6878870050408947
Epoch: 63 | Iteration number: [680/4518] 15% | Training loss: 0.6878651606685975
Epoch: 63 | Iteration number: [690/4518] 15% | Training loss: 0.6878495815007583
Epoch: 63 | Iteration number: [700/4518] 15% | Training loss: 0.687845242193767
Epoch: 63 | Iteration number: [710/4518] 15% | Training loss: 0.6878330329774132
Epoch: 63 | Iteration number: [720/4518] 15% | Training loss: 0.6878304501374563
Epoch: 63 | Iteration number: [730/4518] 16% | Training loss: 0.6878278500413242
Epoch: 63 | Iteration number: [740/4518] 16% | Training loss: 0.6878145950066077
Epoch: 63 | Iteration number: [750/4518] 16% | Training loss: 0.6878180828094482
Epoch: 63 | Iteration number: [760/4518] 16% | Training loss: 0.687820576680334
Epoch: 63 | Iteration number: [770/4518] 17% | Training loss: 0.6877979086591052
Epoch: 63 | Iteration number: [780/4518] 17% | Training loss: 0.687789849898754
Epoch: 63 | Iteration number: [790/4518] 17% | Training loss: 0.6877782783176326
Epoch: 63 | Iteration number: [800/4518] 17% | Training loss: 0.6877712208032608
Epoch: 63 | Iteration number: [810/4518] 17% | Training loss: 0.687769748840803
Epoch: 63 | Iteration number: [820/4518] 18% | Training loss: 0.6877565338117321
Epoch: 63 | Iteration number: [830/4518] 18% | Training loss: 0.6877431173640561
Epoch: 63 | Iteration number: [840/4518] 18% | Training loss: 0.6877485156059265
Epoch: 63 | Iteration number: [850/4518] 18% | Training loss: 0.6877395836044761
Epoch: 63 | Iteration number: [860/4518] 19% | Training loss: 0.6877339084481084
Epoch: 63 | Iteration number: [870/4518] 19% | Training loss: 0.6877134691024649
Epoch: 63 | Iteration number: [880/4518] 19% | Training loss: 0.6877030759372494
Epoch: 63 | Iteration number: [890/4518] 19% | Training loss: 0.6876893896735117
Epoch: 63 | Iteration number: [900/4518] 19% | Training loss: 0.6876679530408647
Epoch: 63 | Iteration number: [910/4518] 20% | Training loss: 0.6876599364228301
Epoch: 63 | Iteration number: [920/4518] 20% | Training loss: 0.6876567479061044
Epoch: 63 | Iteration number: [930/4518] 20% | Training loss: 0.6876435410591863
Epoch: 63 | Iteration number: [940/4518] 20% | Training loss: 0.6876369547970751
Epoch: 63 | Iteration number: [950/4518] 21% | Training loss: 0.6876313673822503
Epoch: 63 | Iteration number: [960/4518] 21% | Training loss: 0.6876339876403411
Epoch: 63 | Iteration number: [970/4518] 21% | Training loss: 0.6876198398698237
Epoch: 63 | Iteration number: [980/4518] 21% | Training loss: 0.6876071774837922
Epoch: 63 | Iteration number: [990/4518] 21% | Training loss: 0.6876054997998055
Epoch: 63 | Iteration number: [1000/4518] 22% | Training loss: 0.6875972656011582
Epoch: 63 | Iteration number: [1010/4518] 22% | Training loss: 0.687588353912429
Epoch: 63 | Iteration number: [1020/4518] 22% | Training loss: 0.6875887472255557
Epoch: 63 | Iteration number: [1030/4518] 22% | Training loss: 0.6875878177800225
Epoch: 63 | Iteration number: [1040/4518] 23% | Training loss: 0.6875527053498305
Epoch: 63 | Iteration number: [1050/4518] 23% | Training loss: 0.687534035330727
Epoch: 63 | Iteration number: [1060/4518] 23% | Training loss: 0.6875320232701752
Epoch: 63 | Iteration number: [1070/4518] 23% | Training loss: 0.6875275648642923
Epoch: 63 | Iteration number: [1080/4518] 23% | Training loss: 0.6875101705392201
Epoch: 63 | Iteration number: [1090/4518] 24% | Training loss: 0.6874953414868871
Epoch: 63 | Iteration number: [1100/4518] 24% | Training loss: 0.6874988547780297
Epoch: 63 | Iteration number: [1110/4518] 24% | Training loss: 0.6874803008796933
Epoch: 63 | Iteration number: [1120/4518] 24% | Training loss: 0.6874626844057015
Epoch: 63 | Iteration number: [1130/4518] 25% | Training loss: 0.6874483768918873
Epoch: 63 | Iteration number: [1140/4518] 25% | Training loss: 0.6874402475984474
Epoch: 63 | Iteration number: [1150/4518] 25% | Training loss: 0.6874361361627993
Epoch: 63 | Iteration number: [1160/4518] 25% | Training loss: 0.6874252910244054
Epoch: 63 | Iteration number: [1170/4518] 25% | Training loss: 0.687422237946437
Epoch: 63 | Iteration number: [1180/4518] 26% | Training loss: 0.6874197272931115
Epoch: 63 | Iteration number: [1190/4518] 26% | Training loss: 0.687410172193992
Epoch: 63 | Iteration number: [1200/4518] 26% | Training loss: 0.6874073602755865
Epoch: 63 | Iteration number: [1210/4518] 26% | Training loss: 0.6873961970333226
Epoch: 63 | Iteration number: [1220/4518] 27% | Training loss: 0.6873881666386714
Epoch: 63 | Iteration number: [1230/4518] 27% | Training loss: 0.6873813977086447
Epoch: 63 | Iteration number: [1240/4518] 27% | Training loss: 0.6873831877785345
Epoch: 63 | Iteration number: [1250/4518] 27% | Training loss: 0.6873819211483002
Epoch: 63 | Iteration number: [1260/4518] 27% | Training loss: 0.6873809683890569
Epoch: 63 | Iteration number: [1270/4518] 28% | Training loss: 0.6873763306403723
Epoch: 63 | Iteration number: [1280/4518] 28% | Training loss: 0.6873783269431442
Epoch: 63 | Iteration number: [1290/4518] 28% | Training loss: 0.687380518284879
Epoch: 63 | Iteration number: [1300/4518] 28% | Training loss: 0.6873729952940574
Epoch: 63 | Iteration number: [1310/4518] 28% | Training loss: 0.6873710758813465
Epoch: 63 | Iteration number: [1320/4518] 29% | Training loss: 0.6873741193702727
Epoch: 63 | Iteration number: [1330/4518] 29% | Training loss: 0.6873803969612695
Epoch: 63 | Iteration number: [1340/4518] 29% | Training loss: 0.6873775993710134
Epoch: 63 | Iteration number: [1350/4518] 29% | Training loss: 0.6873721660949565
Epoch: 63 | Iteration number: [1360/4518] 30% | Training loss: 0.6873653318952112
Epoch: 63 | Iteration number: [1370/4518] 30% | Training loss: 0.687370109036021
Epoch: 63 | Iteration number: [1380/4518] 30% | Training loss: 0.687376109154328
Epoch: 63 | Iteration number: [1390/4518] 30% | Training loss: 0.6873777528889745
Epoch: 63 | Iteration number: [1400/4518] 30% | Training loss: 0.6873745616844722
Epoch: 63 | Iteration number: [1410/4518] 31% | Training loss: 0.6873757304029262
Epoch: 63 | Iteration number: [1420/4518] 31% | Training loss: 0.6873745912817163
Epoch: 63 | Iteration number: [1430/4518] 31% | Training loss: 0.6873674422294109
Epoch: 63 | Iteration number: [1440/4518] 31% | Training loss: 0.6873684264719486
Epoch: 63 | Iteration number: [1450/4518] 32% | Training loss: 0.6873662113321238
Epoch: 63 | Iteration number: [1460/4518] 32% | Training loss: 0.6873576922367697
Epoch: 63 | Iteration number: [1470/4518] 32% | Training loss: 0.6873638905230023
Epoch: 63 | Iteration number: [1480/4518] 32% | Training loss: 0.6873612464682476
Epoch: 63 | Iteration number: [1490/4518] 32% | Training loss: 0.6873571071848773
Epoch: 63 | Iteration number: [1500/4518] 33% | Training loss: 0.6873576486905416
Epoch: 63 | Iteration number: [1510/4518] 33% | Training loss: 0.6873667996056032
Epoch: 63 | Iteration number: [1520/4518] 33% | Training loss: 0.6873609782833802
Epoch: 63 | Iteration number: [1530/4518] 33% | Training loss: 0.6873514331633749
Epoch: 63 | Iteration number: [1540/4518] 34% | Training loss: 0.6873452315856884
Epoch: 63 | Iteration number: [1550/4518] 34% | Training loss: 0.687337439560121
Epoch: 63 | Iteration number: [1560/4518] 34% | Training loss: 0.6873302680559648
Epoch: 63 | Iteration number: [1570/4518] 34% | Training loss: 0.6873244753309117
Epoch: 63 | Iteration number: [1580/4518] 34% | Training loss: 0.6873208188180682
Epoch: 63 | Iteration number: [1590/4518] 35% | Training loss: 0.6873167321367084
Epoch: 63 | Iteration number: [1600/4518] 35% | Training loss: 0.6873058057948946
Epoch: 63 | Iteration number: [1610/4518] 35% | Training loss: 0.6872914276878286
Epoch: 63 | Iteration number: [1620/4518] 35% | Training loss: 0.6872840482511638
Epoch: 63 | Iteration number: [1630/4518] 36% | Training loss: 0.687281862760614
Epoch: 63 | Iteration number: [1640/4518] 36% | Training loss: 0.687274247262536
Epoch: 63 | Iteration number: [1650/4518] 36% | Training loss: 0.687268376603271
Epoch: 63 | Iteration number: [1660/4518] 36% | Training loss: 0.6872652807867671
Epoch: 63 | Iteration number: [1670/4518] 36% | Training loss: 0.6872518670773078
Epoch: 63 | Iteration number: [1680/4518] 37% | Training loss: 0.687248393006268
Epoch: 63 | Iteration number: [1690/4518] 37% | Training loss: 0.6872516413412151
Epoch: 63 | Iteration number: [1700/4518] 37% | Training loss: 0.6872457247621873
Epoch: 63 | Iteration number: [1710/4518] 37% | Training loss: 0.6872455652694256
Epoch: 63 | Iteration number: [1720/4518] 38% | Training loss: 0.6872445552848107
Epoch: 63 | Iteration number: [1730/4518] 38% | Training loss: 0.6872478768315619
Epoch: 63 | Iteration number: [1740/4518] 38% | Training loss: 0.6872476625373993
Epoch: 63 | Iteration number: [1750/4518] 38% | Training loss: 0.6872445167132787
Epoch: 63 | Iteration number: [1760/4518] 38% | Training loss: 0.6872480202804913
Epoch: 63 | Iteration number: [1770/4518] 39% | Training loss: 0.6872503003831637
Epoch: 63 | Iteration number: [1780/4518] 39% | Training loss: 0.687248379494367
Epoch: 63 | Iteration number: [1790/4518] 39% | Training loss: 0.6872521513001213
Epoch: 63 | Iteration number: [1800/4518] 39% | Training loss: 0.6872490913338132
Epoch: 63 | Iteration number: [1810/4518] 40% | Training loss: 0.6872452592981454
Epoch: 63 | Iteration number: [1820/4518] 40% | Training loss: 0.6872455930644339
Epoch: 63 | Iteration number: [1830/4518] 40% | Training loss: 0.6872436539722923
Epoch: 63 | Iteration number: [1840/4518] 40% | Training loss: 0.6872348574516566
Epoch: 63 | Iteration number: [1850/4518] 40% | Training loss: 0.6872311797335341
Epoch: 63 | Iteration number: [1860/4518] 41% | Training loss: 0.6872329568991097
Epoch: 63 | Iteration number: [1870/4518] 41% | Training loss: 0.6872349522649286
Epoch: 63 | Iteration number: [1880/4518] 41% | Training loss: 0.6872382008331888
Epoch: 63 | Iteration number: [1890/4518] 41% | Training loss: 0.6872318204117831
Epoch: 63 | Iteration number: [1900/4518] 42% | Training loss: 0.6872291082143783
Epoch: 63 | Iteration number: [1910/4518] 42% | Training loss: 0.687221314925798
Epoch: 63 | Iteration number: [1920/4518] 42% | Training loss: 0.6872127269084255
Epoch: 63 | Iteration number: [1930/4518] 42% | Training loss: 0.6872154137631155
Epoch: 63 | Iteration number: [1940/4518] 42% | Training loss: 0.6872141006066627
Epoch: 63 | Iteration number: [1950/4518] 43% | Training loss: 0.6872062911437108
Epoch: 63 | Iteration number: [1960/4518] 43% | Training loss: 0.687199389265508
Epoch: 63 | Iteration number: [1970/4518] 43% | Training loss: 0.6871984284541328
Epoch: 63 | Iteration number: [1980/4518] 43% | Training loss: 0.6871954118663615
Epoch: 63 | Iteration number: [1990/4518] 44% | Training loss: 0.6871910532515253
Epoch: 63 | Iteration number: [2000/4518] 44% | Training loss: 0.6871899105310441
Epoch: 63 | Iteration number: [2010/4518] 44% | Training loss: 0.6871810412822078
Epoch: 63 | Iteration number: [2020/4518] 44% | Training loss: 0.6871844534826751
Epoch: 63 | Iteration number: [2030/4518] 44% | Training loss: 0.6871829655370102
Epoch: 63 | Iteration number: [2040/4518] 45% | Training loss: 0.6871777928343006
Epoch: 63 | Iteration number: [2050/4518] 45% | Training loss: 0.6871687151455298
Epoch: 63 | Iteration number: [2060/4518] 45% | Training loss: 0.6871640508036012
Epoch: 63 | Iteration number: [2070/4518] 45% | Training loss: 0.6871637686439183
Epoch: 63 | Iteration number: [2080/4518] 46% | Training loss: 0.6871613474132923
Epoch: 63 | Iteration number: [2090/4518] 46% | Training loss: 0.687155855443489
Epoch: 63 | Iteration number: [2100/4518] 46% | Training loss: 0.6871560299680346
Epoch: 63 | Iteration number: [2110/4518] 46% | Training loss: 0.6871550298697575
Epoch: 63 | Iteration number: [2120/4518] 46% | Training loss: 0.6871489318755438
Epoch: 63 | Iteration number: [2130/4518] 47% | Training loss: 0.6871380923499524
Epoch: 63 | Iteration number: [2140/4518] 47% | Training loss: 0.6871365528797435
Epoch: 63 | Iteration number: [2150/4518] 47% | Training loss: 0.6871365709914717
Epoch: 63 | Iteration number: [2160/4518] 47% | Training loss: 0.6871346501012643
Epoch: 63 | Iteration number: [2170/4518] 48% | Training loss: 0.6871332916521257
Epoch: 63 | Iteration number: [2180/4518] 48% | Training loss: 0.687133777606378
Epoch: 63 | Iteration number: [2190/4518] 48% | Training loss: 0.6871269143607518
Epoch: 63 | Iteration number: [2200/4518] 48% | Training loss: 0.6871274291385304
Epoch: 63 | Iteration number: [2210/4518] 48% | Training loss: 0.6871335006407483
Epoch: 63 | Iteration number: [2220/4518] 49% | Training loss: 0.68713032498553
Epoch: 63 | Iteration number: [2230/4518] 49% | Training loss: 0.6871266193454041
Epoch: 63 | Iteration number: [2240/4518] 49% | Training loss: 0.6871249823697976
Epoch: 63 | Iteration number: [2250/4518] 49% | Training loss: 0.6871225714418623
Epoch: 63 | Iteration number: [2260/4518] 50% | Training loss: 0.687119117933037
Epoch: 63 | Iteration number: [2270/4518] 50% | Training loss: 0.6871169172719712
Epoch: 63 | Iteration number: [2280/4518] 50% | Training loss: 0.6871107250452042
Epoch: 63 | Iteration number: [2290/4518] 50% | Training loss: 0.6871034809075068
Epoch: 63 | Iteration number: [2300/4518] 50% | Training loss: 0.6871045224303785
Epoch: 63 | Iteration number: [2310/4518] 51% | Training loss: 0.6870981842666477
Epoch: 63 | Iteration number: [2320/4518] 51% | Training loss: 0.6870929270982742
Epoch: 63 | Iteration number: [2330/4518] 51% | Training loss: 0.6870943111411492
Epoch: 63 | Iteration number: [2340/4518] 51% | Training loss: 0.6870957714115452
Epoch: 63 | Iteration number: [2350/4518] 52% | Training loss: 0.6870926956673886
Epoch: 63 | Iteration number: [2360/4518] 52% | Training loss: 0.6870946527285091
Epoch: 63 | Iteration number: [2370/4518] 52% | Training loss: 0.6870922923842563
Epoch: 63 | Iteration number: [2380/4518] 52% | Training loss: 0.6870912899490164
Epoch: 63 | Iteration number: [2390/4518] 52% | Training loss: 0.6870886765015175
Epoch: 63 | Iteration number: [2400/4518] 53% | Training loss: 0.6870850709080696
Epoch: 63 | Iteration number: [2410/4518] 53% | Training loss: 0.6870870634233308
Epoch: 63 | Iteration number: [2420/4518] 53% | Training loss: 0.6870851338155999
Epoch: 63 | Iteration number: [2430/4518] 53% | Training loss: 0.6870801625673663
Epoch: 63 | Iteration number: [2440/4518] 54% | Training loss: 0.6870815374079298
Epoch: 63 | Iteration number: [2450/4518] 54% | Training loss: 0.687075077100676
Epoch: 63 | Iteration number: [2460/4518] 54% | Training loss: 0.6870756588088788
Epoch: 63 | Iteration number: [2470/4518] 54% | Training loss: 0.6870795749700986
Epoch: 63 | Iteration number: [2480/4518] 54% | Training loss: 0.6870768746781734
Epoch: 63 | Iteration number: [2490/4518] 55% | Training loss: 0.6870762284740387
Epoch: 63 | Iteration number: [2500/4518] 55% | Training loss: 0.6870751349925995
Epoch: 63 | Iteration number: [2510/4518] 55% | Training loss: 0.6870741040820619
Epoch: 63 | Iteration number: [2520/4518] 55% | Training loss: 0.687072945185124
Epoch: 63 | Iteration number: [2530/4518] 55% | Training loss: 0.6870758844929722
Epoch: 63 | Iteration number: [2540/4518] 56% | Training loss: 0.687078896868886
Epoch: 63 | Iteration number: [2550/4518] 56% | Training loss: 0.6870791302942763
Epoch: 63 | Iteration number: [2560/4518] 56% | Training loss: 0.68708049824927
Epoch: 63 | Iteration number: [2570/4518] 56% | Training loss: 0.6870823754874649
Epoch: 63 | Iteration number: [2580/4518] 57% | Training loss: 0.6870826310889665
Epoch: 63 | Iteration number: [2590/4518] 57% | Training loss: 0.6870845122917278
Epoch: 63 | Iteration number: [2600/4518] 57% | Training loss: 0.6870857209884204
Epoch: 63 | Iteration number: [2610/4518] 57% | Training loss: 0.6870856228002643
Epoch: 63 | Iteration number: [2620/4518] 57% | Training loss: 0.6870846785889327
Epoch: 63 | Iteration number: [2630/4518] 58% | Training loss: 0.6870852881964622
Epoch: 63 | Iteration number: [2640/4518] 58% | Training loss: 0.6870840600494182
Epoch: 63 | Iteration number: [2650/4518] 58% | Training loss: 0.6870823774922569
Epoch: 63 | Iteration number: [2660/4518] 58% | Training loss: 0.6870776917701377
Epoch: 63 | Iteration number: [2670/4518] 59% | Training loss: 0.6870756883969468
Epoch: 63 | Iteration number: [2680/4518] 59% | Training loss: 0.6870745945777466
Epoch: 63 | Iteration number: [2690/4518] 59% | Training loss: 0.6870732896833172
Epoch: 63 | Iteration number: [2700/4518] 59% | Training loss: 0.6870713225117436
Epoch: 63 | Iteration number: [2710/4518] 59% | Training loss: 0.6870724422685335
Epoch: 63 | Iteration number: [2720/4518] 60% | Training loss: 0.6870724157813717
Epoch: 63 | Iteration number: [2730/4518] 60% | Training loss: 0.6870752877804822
Epoch: 63 | Iteration number: [2740/4518] 60% | Training loss: 0.6870744509853586
Epoch: 63 | Iteration number: [2750/4518] 60% | Training loss: 0.6870693404457786
Epoch: 63 | Iteration number: [2760/4518] 61% | Training loss: 0.687067073950733
Epoch: 63 | Iteration number: [2770/4518] 61% | Training loss: 0.6870606002824832
Epoch: 63 | Iteration number: [2780/4518] 61% | Training loss: 0.6870644915232555
Epoch: 63 | Iteration number: [2790/4518] 61% | Training loss: 0.6870660670769257
Epoch: 63 | Iteration number: [2800/4518] 61% | Training loss: 0.6870656898404871
Epoch: 63 | Iteration number: [2810/4518] 62% | Training loss: 0.6870647701504392
Epoch: 63 | Iteration number: [2820/4518] 62% | Training loss: 0.6870650729811784
Epoch: 63 | Iteration number: [2830/4518] 62% | Training loss: 0.6870658115237004
Epoch: 63 | Iteration number: [2840/4518] 62% | Training loss: 0.6870630508787196
Epoch: 63 | Iteration number: [2850/4518] 63% | Training loss: 0.687061643119444
Epoch: 63 | Iteration number: [2860/4518] 63% | Training loss: 0.6870584835539331
Epoch: 63 | Iteration number: [2870/4518] 63% | Training loss: 0.6870543262061342
Epoch: 63 | Iteration number: [2880/4518] 63% | Training loss: 0.687049427214596
Epoch: 63 | Iteration number: [2890/4518] 63% | Training loss: 0.6870484087706438
Epoch: 63 | Iteration number: [2900/4518] 64% | Training loss: 0.6870454196683292
Epoch: 63 | Iteration number: [2910/4518] 64% | Training loss: 0.6870447371423859
Epoch: 63 | Iteration number: [2920/4518] 64% | Training loss: 0.6870429185563571
Epoch: 63 | Iteration number: [2930/4518] 64% | Training loss: 0.6870416976689478
Epoch: 63 | Iteration number: [2940/4518] 65% | Training loss: 0.6870391383665759
Epoch: 63 | Iteration number: [2950/4518] 65% | Training loss: 0.687038233744896
Epoch: 63 | Iteration number: [2960/4518] 65% | Training loss: 0.6870346076987885
Epoch: 63 | Iteration number: [2970/4518] 65% | Training loss: 0.6870306325079215
Epoch: 63 | Iteration number: [2980/4518] 65% | Training loss: 0.6870310336351395
Epoch: 63 | Iteration number: [2990/4518] 66% | Training loss: 0.6870281819715149
Epoch: 63 | Iteration number: [3000/4518] 66% | Training loss: 0.6870299982627233
Epoch: 63 | Iteration number: [3010/4518] 66% | Training loss: 0.6870276464576341
Epoch: 63 | Iteration number: [3020/4518] 66% | Training loss: 0.6870285769172062
Epoch: 63 | Iteration number: [3030/4518] 67% | Training loss: 0.6870252120809587
Epoch: 63 | Iteration number: [3040/4518] 67% | Training loss: 0.6870247693242211
Epoch: 63 | Iteration number: [3050/4518] 67% | Training loss: 0.6870258823183716
Epoch: 63 | Iteration number: [3060/4518] 67% | Training loss: 0.6870268280404845
Epoch: 63 | Iteration number: [3070/4518] 67% | Training loss: 0.687028854794145
Epoch: 63 | Iteration number: [3080/4518] 68% | Training loss: 0.6870246755031796
Epoch: 63 | Iteration number: [3090/4518] 68% | Training loss: 0.6870282032150281
Epoch: 63 | Iteration number: [3100/4518] 68% | Training loss: 0.687024158643138
Epoch: 63 | Iteration number: [3110/4518] 68% | Training loss: 0.6870201463101377
Epoch: 63 | Iteration number: [3120/4518] 69% | Training loss: 0.687017484773428
Epoch: 63 | Iteration number: [3130/4518] 69% | Training loss: 0.6870139769471872
Epoch: 63 | Iteration number: [3140/4518] 69% | Training loss: 0.6870118302334646
Epoch: 63 | Iteration number: [3150/4518] 69% | Training loss: 0.6870099634972829
Epoch: 63 | Iteration number: [3160/4518] 69% | Training loss: 0.6870106298712235
Epoch: 63 | Iteration number: [3170/4518] 70% | Training loss: 0.6870114425943477
Epoch: 63 | Iteration number: [3180/4518] 70% | Training loss: 0.6870111606405966
Epoch: 63 | Iteration number: [3190/4518] 70% | Training loss: 0.6870102830067697
Epoch: 63 | Iteration number: [3200/4518] 70% | Training loss: 0.6870106514357031
Epoch: 63 | Iteration number: [3210/4518] 71% | Training loss: 0.6870096716925362
Epoch: 63 | Iteration number: [3220/4518] 71% | Training loss: 0.6870068675242595
Epoch: 63 | Iteration number: [3230/4518] 71% | Training loss: 0.6870041501780413
Epoch: 63 | Iteration number: [3240/4518] 71% | Training loss: 0.6870006306855767
Epoch: 63 | Iteration number: [3250/4518] 71% | Training loss: 0.6870013058919173
Epoch: 63 | Iteration number: [3260/4518] 72% | Training loss: 0.6870014976687226
Epoch: 63 | Iteration number: [3270/4518] 72% | Training loss: 0.686997352280748
Epoch: 63 | Iteration number: [3280/4518] 72% | Training loss: 0.6870007931459241
Epoch: 63 | Iteration number: [3290/4518] 72% | Training loss: 0.686998763164126
Epoch: 63 | Iteration number: [3300/4518] 73% | Training loss: 0.6869975395094264
Epoch: 63 | Iteration number: [3310/4518] 73% | Training loss: 0.6869984745078936
Epoch: 63 | Iteration number: [3320/4518] 73% | Training loss: 0.6869976294327931
Epoch: 63 | Iteration number: [3330/4518] 73% | Training loss: 0.6869972471360329
Epoch: 63 | Iteration number: [3340/4518] 73% | Training loss: 0.6869972823979612
Epoch: 63 | Iteration number: [3350/4518] 74% | Training loss: 0.6870000163654782
Epoch: 63 | Iteration number: [3360/4518] 74% | Training loss: 0.6869965365777413
Epoch: 63 | Iteration number: [3370/4518] 74% | Training loss: 0.6869957982432595
Epoch: 63 | Iteration number: [3380/4518] 74% | Training loss: 0.6869945660498016
Epoch: 63 | Iteration number: [3390/4518] 75% | Training loss: 0.6869909837182644
Epoch: 63 | Iteration number: [3400/4518] 75% | Training loss: 0.6869894440033857
Epoch: 63 | Iteration number: [3410/4518] 75% | Training loss: 0.6869890365782372
Epoch: 63 | Iteration number: [3420/4518] 75% | Training loss: 0.6869896001285977
Epoch: 63 | Iteration number: [3430/4518] 75% | Training loss: 0.6869881475632115
Epoch: 63 | Iteration number: [3440/4518] 76% | Training loss: 0.6869889816052692
Epoch: 63 | Iteration number: [3450/4518] 76% | Training loss: 0.6869901875309322
Epoch: 63 | Iteration number: [3460/4518] 76% | Training loss: 0.6869876855542894
Epoch: 63 | Iteration number: [3470/4518] 76% | Training loss: 0.6869871500074348
Epoch: 63 | Iteration number: [3480/4518] 77% | Training loss: 0.6869887363807908
Epoch: 63 | Iteration number: [3490/4518] 77% | Training loss: 0.68698387251884
Epoch: 63 | Iteration number: [3500/4518] 77% | Training loss: 0.6869829860244479
Epoch: 63 | Iteration number: [3510/4518] 77% | Training loss: 0.6869831457946375
Epoch: 63 | Iteration number: [3520/4518] 77% | Training loss: 0.6869830087504604
Epoch: 63 | Iteration number: [3530/4518] 78% | Training loss: 0.6869824040206228
Epoch: 63 | Iteration number: [3540/4518] 78% | Training loss: 0.686981649755758
Epoch: 63 | Iteration number: [3550/4518] 78% | Training loss: 0.6869829836697645
Epoch: 63 | Iteration number: [3560/4518] 78% | Training loss: 0.6869855124796375
Epoch: 63 | Iteration number: [3570/4518] 79% | Training loss: 0.686986241337298
Epoch: 63 | Iteration number: [3580/4518] 79% | Training loss: 0.6869837421611701
Epoch: 63 | Iteration number: [3590/4518] 79% | Training loss: 0.6869831806935972
Epoch: 63 | Iteration number: [3600/4518] 79% | Training loss: 0.686984458350473
Epoch: 63 | Iteration number: [3610/4518] 79% | Training loss: 0.6869834189269681
Epoch: 63 | Iteration number: [3620/4518] 80% | Training loss: 0.6869866739649799
Epoch: 63 | Iteration number: [3630/4518] 80% | Training loss: 0.6869881870332828
Epoch: 63 | Iteration number: [3640/4518] 80% | Training loss: 0.6869885363421597
Epoch: 63 | Iteration number: [3650/4518] 80% | Training loss: 0.6869864763135779
Epoch: 63 | Iteration number: [3660/4518] 81% | Training loss: 0.6869899920589937
Epoch: 63 | Iteration number: [3670/4518] 81% | Training loss: 0.6869897710205098
Epoch: 63 | Iteration number: [3680/4518] 81% | Training loss: 0.6869877496167369
Epoch: 63 | Iteration number: [3690/4518] 81% | Training loss: 0.6869887657281829
Epoch: 63 | Iteration number: [3700/4518] 81% | Training loss: 0.6869880957539017
Epoch: 63 | Iteration number: [3710/4518] 82% | Training loss: 0.6869885886293858
Epoch: 63 | Iteration number: [3720/4518] 82% | Training loss: 0.6869883547547043
Epoch: 63 | Iteration number: [3730/4518] 82% | Training loss: 0.686990152622995
Epoch: 63 | Iteration number: [3740/4518] 82% | Training loss: 0.6869906311047906
Epoch: 63 | Iteration number: [3750/4518] 83% | Training loss: 0.6869907877922058
Epoch: 63 | Iteration number: [3760/4518] 83% | Training loss: 0.6869897945764217
Epoch: 63 | Iteration number: [3770/4518] 83% | Training loss: 0.686989458849955
Epoch: 63 | Iteration number: [3780/4518] 83% | Training loss: 0.6869888249370787
Epoch: 63 | Iteration number: [3790/4518] 83% | Training loss: 0.6869893046199175
Epoch: 63 | Iteration number: [3800/4518] 84% | Training loss: 0.6869936059336913
Epoch: 63 | Iteration number: [3810/4518] 84% | Training loss: 0.6869914073800164
Epoch: 63 | Iteration number: [3820/4518] 84% | Training loss: 0.6869907249486883
Epoch: 63 | Iteration number: [3830/4518] 84% | Training loss: 0.6869907396580469
Epoch: 63 | Iteration number: [3840/4518] 84% | Training loss: 0.6869903182610869
Epoch: 63 | Iteration number: [3850/4518] 85% | Training loss: 0.6869889789432674
Epoch: 63 | Iteration number: [3860/4518] 85% | Training loss: 0.6869857831013635
Epoch: 63 | Iteration number: [3870/4518] 85% | Training loss: 0.686985607526099
Epoch: 63 | Iteration number: [3880/4518] 85% | Training loss: 0.6869856831800077
Epoch: 63 | Iteration number: [3890/4518] 86% | Training loss: 0.6869867699158528
Epoch: 63 | Iteration number: [3900/4518] 86% | Training loss: 0.6869827974606783
Epoch: 63 | Iteration number: [3910/4518] 86% | Training loss: 0.6869819957581932
Epoch: 63 | Iteration number: [3920/4518] 86% | Training loss: 0.6869794962357502
Epoch: 63 | Iteration number: [3930/4518] 86% | Training loss: 0.6869831385048291
Epoch: 63 | Iteration number: [3940/4518] 87% | Training loss: 0.6869826312900195
Epoch: 63 | Iteration number: [3950/4518] 87% | Training loss: 0.6869817396507988
Epoch: 63 | Iteration number: [3960/4518] 87% | Training loss: 0.6869780452112959
Epoch: 63 | Iteration number: [3970/4518] 87% | Training loss: 0.6869758176713506
Epoch: 63 | Iteration number: [3980/4518] 88% | Training loss: 0.6869761697611018
Epoch: 63 | Iteration number: [3990/4518] 88% | Training loss: 0.68697862075385
Epoch: 63 | Iteration number: [4000/4518] 88% | Training loss: 0.6869768629223109
Epoch: 63 | Iteration number: [4010/4518] 88% | Training loss: 0.6869750825841527
Epoch: 63 | Iteration number: [4020/4518] 88% | Training loss: 0.6869737075039404
Epoch: 63 | Iteration number: [4030/4518] 89% | Training loss: 0.6869738513275648
Epoch: 63 | Iteration number: [4040/4518] 89% | Training loss: 0.6869732186198234
Epoch: 63 | Iteration number: [4050/4518] 89% | Training loss: 0.6869700678631111
Epoch: 63 | Iteration number: [4060/4518] 89% | Training loss: 0.6869696221328134
Epoch: 63 | Iteration number: [4070/4518] 90% | Training loss: 0.6869665847217129
Epoch: 63 | Iteration number: [4080/4518] 90% | Training loss: 0.6869670074944403
Epoch: 63 | Iteration number: [4090/4518] 90% | Training loss: 0.6869647866356343
Epoch: 63 | Iteration number: [4100/4518] 90% | Training loss: 0.6869635491981739
Epoch: 63 | Iteration number: [4110/4518] 90% | Training loss: 0.6869603634460709
Epoch: 63 | Iteration number: [4120/4518] 91% | Training loss: 0.6869627933623721
Epoch: 63 | Iteration number: [4130/4518] 91% | Training loss: 0.686964130964464
Epoch: 63 | Iteration number: [4140/4518] 91% | Training loss: 0.6869645211575688
Epoch: 63 | Iteration number: [4150/4518] 91% | Training loss: 0.6869615398401238
Epoch: 63 | Iteration number: [4160/4518] 92% | Training loss: 0.6869621802121401
Epoch: 63 | Iteration number: [4170/4518] 92% | Training loss: 0.686963153242779
Epoch: 63 | Iteration number: [4180/4518] 92% | Training loss: 0.6869618059488004
Epoch: 63 | Iteration number: [4190/4518] 92% | Training loss: 0.6869619844779195
Epoch: 63 | Iteration number: [4200/4518] 92% | Training loss: 0.6869609330665497
Epoch: 63 | Iteration number: [4210/4518] 93% | Training loss: 0.6869640961254011
Epoch: 63 | Iteration number: [4220/4518] 93% | Training loss: 0.6869639339887701
Epoch: 63 | Iteration number: [4230/4518] 93% | Training loss: 0.6869620594572514
Epoch: 63 | Iteration number: [4240/4518] 93% | Training loss: 0.6869590246874206
Epoch: 63 | Iteration number: [4250/4518] 94% | Training loss: 0.6869613980405471
Epoch: 63 | Iteration number: [4260/4518] 94% | Training loss: 0.6869586917576096
Epoch: 63 | Iteration number: [4270/4518] 94% | Training loss: 0.6869567904036832
Epoch: 63 | Iteration number: [4280/4518] 94% | Training loss: 0.6869560783015234
Epoch: 63 | Iteration number: [4290/4518] 94% | Training loss: 0.6869540916039394
Epoch: 63 | Iteration number: [4300/4518] 95% | Training loss: 0.6869570134961328
Epoch: 63 | Iteration number: [4310/4518] 95% | Training loss: 0.6869552981825826
Epoch: 63 | Iteration number: [4320/4518] 95% | Training loss: 0.6869549989286396
Epoch: 63 | Iteration number: [4330/4518] 95% | Training loss: 0.6869540974669864
Epoch: 63 | Iteration number: [4340/4518] 96% | Training loss: 0.6869551619901085
Epoch: 63 | Iteration number: [4350/4518] 96% | Training loss: 0.6869527712224544
Epoch: 63 | Iteration number: [4360/4518] 96% | Training loss: 0.6869503019189616
Epoch: 63 | Iteration number: [4370/4518] 96% | Training loss: 0.6869522067311153
Epoch: 63 | Iteration number: [4380/4518] 96% | Training loss: 0.6869538409116606
Epoch: 63 | Iteration number: [4390/4518] 97% | Training loss: 0.6869551899221329
Epoch: 63 | Iteration number: [4400/4518] 97% | Training loss: 0.6869522006945177
Epoch: 63 | Iteration number: [4410/4518] 97% | Training loss: 0.686952111537224
Epoch: 63 | Iteration number: [4420/4518] 97% | Training loss: 0.6869514848042397
Epoch: 63 | Iteration number: [4430/4518] 98% | Training loss: 0.6869475285436445
Epoch: 63 | Iteration number: [4440/4518] 98% | Training loss: 0.6869482274125288
Epoch: 63 | Iteration number: [4450/4518] 98% | Training loss: 0.686952589535981
Epoch: 63 | Iteration number: [4460/4518] 98% | Training loss: 0.6869514973174297
Epoch: 63 | Iteration number: [4470/4518] 98% | Training loss: 0.6869501714071705
Epoch: 63 | Iteration number: [4480/4518] 99% | Training loss: 0.6869516019443316
Epoch: 63 | Iteration number: [4490/4518] 99% | Training loss: 0.6869495425033144
Epoch: 63 | Iteration number: [4500/4518] 99% | Training loss: 0.6869477825694614
Epoch: 63 | Iteration number: [4510/4518] 99% | Training loss: 0.6869455179724091

 End of epoch: 63 | Train Loss: 0.6867934189284993 | Training Time: 643 

 End of epoch: 63 | Eval Loss: 0.6900487177226008 | Evaluating Time: 17 
Epoch: 64 | Iteration number: [10/4518] 0% | Training loss: 0.7558197379112244
Epoch: 64 | Iteration number: [20/4518] 0% | Training loss: 0.7207690000534057
Epoch: 64 | Iteration number: [30/4518] 0% | Training loss: 0.7098590036233267
Epoch: 64 | Iteration number: [40/4518] 0% | Training loss: 0.7042411178350448
Epoch: 64 | Iteration number: [50/4518] 1% | Training loss: 0.7008000349998474
Epoch: 64 | Iteration number: [60/4518] 1% | Training loss: 0.6986711432536443
Epoch: 64 | Iteration number: [70/4518] 1% | Training loss: 0.6968773066997528
Epoch: 64 | Iteration number: [80/4518] 1% | Training loss: 0.695520906150341
Epoch: 64 | Iteration number: [90/4518] 1% | Training loss: 0.6945835842026604
Epoch: 64 | Iteration number: [100/4518] 2% | Training loss: 0.6937676638364791
Epoch: 64 | Iteration number: [110/4518] 2% | Training loss: 0.6931554696776651
Epoch: 64 | Iteration number: [120/4518] 2% | Training loss: 0.6926524211963018
Epoch: 64 | Iteration number: [130/4518] 2% | Training loss: 0.6922613107241117
Epoch: 64 | Iteration number: [140/4518] 3% | Training loss: 0.6918690621852874
Epoch: 64 | Iteration number: [150/4518] 3% | Training loss: 0.6915662781397501
Epoch: 64 | Iteration number: [160/4518] 3% | Training loss: 0.6912325773388147
Epoch: 64 | Iteration number: [170/4518] 3% | Training loss: 0.6910049718969008
Epoch: 64 | Iteration number: [180/4518] 3% | Training loss: 0.6907512062125736
Epoch: 64 | Iteration number: [190/4518] 4% | Training loss: 0.6905350095347355
Epoch: 64 | Iteration number: [200/4518] 4% | Training loss: 0.6903981637954711
Epoch: 64 | Iteration number: [210/4518] 4% | Training loss: 0.6902845391205379
Epoch: 64 | Iteration number: [220/4518] 4% | Training loss: 0.6901547017422589
Epoch: 64 | Iteration number: [230/4518] 5% | Training loss: 0.6899929393892703
Epoch: 64 | Iteration number: [240/4518] 5% | Training loss: 0.6898760378360749
Epoch: 64 | Iteration number: [250/4518] 5% | Training loss: 0.6897006514072418
Epoch: 64 | Iteration number: [260/4518] 5% | Training loss: 0.6896124956699518
Epoch: 64 | Iteration number: [270/4518] 5% | Training loss: 0.6895053795090428
Epoch: 64 | Iteration number: [280/4518] 6% | Training loss: 0.6894280529447965
Epoch: 64 | Iteration number: [290/4518] 6% | Training loss: 0.6893292178367746
Epoch: 64 | Iteration number: [300/4518] 6% | Training loss: 0.6892323291301727
Epoch: 64 | Iteration number: [310/4518] 6% | Training loss: 0.6891341786230764
Epoch: 64 | Iteration number: [320/4518] 7% | Training loss: 0.6890542024746538
Epoch: 64 | Iteration number: [330/4518] 7% | Training loss: 0.6889977901270895
Epoch: 64 | Iteration number: [340/4518] 7% | Training loss: 0.6889190445928013
Epoch: 64 | Iteration number: [350/4518] 7% | Training loss: 0.6888425130503518
Epoch: 64 | Iteration number: [360/4518] 7% | Training loss: 0.6887924503948953
Epoch: 64 | Iteration number: [370/4518] 8% | Training loss: 0.6887429155207969
Epoch: 64 | Iteration number: [380/4518] 8% | Training loss: 0.688667356497363
Epoch: 64 | Iteration number: [390/4518] 8% | Training loss: 0.6886471583293035
Epoch: 64 | Iteration number: [400/4518] 8% | Training loss: 0.6885902126133442
Epoch: 64 | Iteration number: [410/4518] 9% | Training loss: 0.6885312933747362
Epoch: 64 | Iteration number: [420/4518] 9% | Training loss: 0.6885257116385869
Epoch: 64 | Iteration number: [430/4518] 9% | Training loss: 0.6884681655917056
Epoch: 64 | Iteration number: [440/4518] 9% | Training loss: 0.6884221013296734
Epoch: 64 | Iteration number: [450/4518] 9% | Training loss: 0.6883575456672245
Epoch: 64 | Iteration number: [460/4518] 10% | Training loss: 0.6883202802875767
Epoch: 64 | Iteration number: [470/4518] 10% | Training loss: 0.6882812075158383
Epoch: 64 | Iteration number: [480/4518] 10% | Training loss: 0.6882535833865404
Epoch: 64 | Iteration number: [490/4518] 10% | Training loss: 0.6882379436979489
Epoch: 64 | Iteration number: [500/4518] 11% | Training loss: 0.6882023273706436
Epoch: 64 | Iteration number: [510/4518] 11% | Training loss: 0.6881777071485332
Epoch: 64 | Iteration number: [520/4518] 11% | Training loss: 0.6881591334939003
Epoch: 64 | Iteration number: [530/4518] 11% | Training loss: 0.6881121479115396
Epoch: 64 | Iteration number: [540/4518] 11% | Training loss: 0.6880877491500642
Epoch: 64 | Iteration number: [550/4518] 12% | Training loss: 0.6880681092088873
Epoch: 64 | Iteration number: [560/4518] 12% | Training loss: 0.6880484541612012
Epoch: 64 | Iteration number: [570/4518] 12% | Training loss: 0.6880321627123314
Epoch: 64 | Iteration number: [580/4518] 12% | Training loss: 0.6880286795311961
Epoch: 64 | Iteration number: [590/4518] 13% | Training loss: 0.6880082689099393
Epoch: 64 | Iteration number: [600/4518] 13% | Training loss: 0.6880098836620648
Epoch: 64 | Iteration number: [610/4518] 13% | Training loss: 0.6880089961114477
Epoch: 64 | Iteration number: [620/4518] 13% | Training loss: 0.6880073817506913
Epoch: 64 | Iteration number: [630/4518] 13% | Training loss: 0.6879905502001444
Epoch: 64 | Iteration number: [640/4518] 14% | Training loss: 0.6879808714613318
Epoch: 64 | Iteration number: [650/4518] 14% | Training loss: 0.6879595243930816
Epoch: 64 | Iteration number: [660/4518] 14% | Training loss: 0.687937168912454
Epoch: 64 | Iteration number: [670/4518] 14% | Training loss: 0.6879181663491832
Epoch: 64 | Iteration number: [680/4518] 15% | Training loss: 0.6878959990599576
Epoch: 64 | Iteration number: [690/4518] 15% | Training loss: 0.6878777787305307
Epoch: 64 | Iteration number: [700/4518] 15% | Training loss: 0.687877584866115
Epoch: 64 | Iteration number: [710/4518] 15% | Training loss: 0.6878725802394706
Epoch: 64 | Iteration number: [720/4518] 15% | Training loss: 0.6878501809305615
Epoch: 64 | Iteration number: [730/4518] 16% | Training loss: 0.6878208731135277
Epoch: 64 | Iteration number: [740/4518] 16% | Training loss: 0.6878198542304941
Epoch: 64 | Iteration number: [750/4518] 16% | Training loss: 0.6878049373626709
Epoch: 64 | Iteration number: [760/4518] 16% | Training loss: 0.6877805552984538
Epoch: 64 | Iteration number: [770/4518] 17% | Training loss: 0.6877371226812338
Epoch: 64 | Iteration number: [780/4518] 17% | Training loss: 0.6877176209902152
Epoch: 64 | Iteration number: [790/4518] 17% | Training loss: 0.6876958177814001
Epoch: 64 | Iteration number: [800/4518] 17% | Training loss: 0.6876815935224294
Epoch: 64 | Iteration number: [810/4518] 17% | Training loss: 0.6876781404018402
Epoch: 64 | Iteration number: [820/4518] 18% | Training loss: 0.6876645156523077
Epoch: 64 | Iteration number: [830/4518] 18% | Training loss: 0.6876495993280985
Epoch: 64 | Iteration number: [840/4518] 18% | Training loss: 0.6876445289169039
Epoch: 64 | Iteration number: [850/4518] 18% | Training loss: 0.6876290380253511
Epoch: 64 | Iteration number: [860/4518] 19% | Training loss: 0.6876169371050458
Epoch: 64 | Iteration number: [870/4518] 19% | Training loss: 0.6876097093368398
Epoch: 64 | Iteration number: [880/4518] 19% | Training loss: 0.6876024706797166
Epoch: 64 | Iteration number: [890/4518] 19% | Training loss: 0.687575568308991
Epoch: 64 | Iteration number: [900/4518] 19% | Training loss: 0.6875706326961517
Epoch: 64 | Iteration number: [910/4518] 20% | Training loss: 0.6875552855350159
Epoch: 64 | Iteration number: [920/4518] 20% | Training loss: 0.6875255939753159
Epoch: 64 | Iteration number: [930/4518] 20% | Training loss: 0.6875108781681266
Epoch: 64 | Iteration number: [940/4518] 20% | Training loss: 0.6874953847616276
Epoch: 64 | Iteration number: [950/4518] 21% | Training loss: 0.6874866173769298
Epoch: 64 | Iteration number: [960/4518] 21% | Training loss: 0.687460936109225
Epoch: 64 | Iteration number: [970/4518] 21% | Training loss: 0.6874529447137695
Epoch: 64 | Iteration number: [980/4518] 21% | Training loss: 0.6874487783835859
Epoch: 64 | Iteration number: [990/4518] 21% | Training loss: 0.6874493213012965
Epoch: 64 | Iteration number: [1000/4518] 22% | Training loss: 0.687432946562767
Epoch: 64 | Iteration number: [1010/4518] 22% | Training loss: 0.687424261204087
Epoch: 64 | Iteration number: [1020/4518] 22% | Training loss: 0.6874122479967043
Epoch: 64 | Iteration number: [1030/4518] 22% | Training loss: 0.6874213854086052
Epoch: 64 | Iteration number: [1040/4518] 23% | Training loss: 0.6874063523342976
Epoch: 64 | Iteration number: [1050/4518] 23% | Training loss: 0.6874122953414917
Epoch: 64 | Iteration number: [1060/4518] 23% | Training loss: 0.6874081112303824
Epoch: 64 | Iteration number: [1070/4518] 23% | Training loss: 0.6874078473755132
Epoch: 64 | Iteration number: [1080/4518] 23% | Training loss: 0.6873928498890665
Epoch: 64 | Iteration number: [1090/4518] 24% | Training loss: 0.6873917538091677
Epoch: 64 | Iteration number: [1100/4518] 24% | Training loss: 0.6873856406320226
Epoch: 64 | Iteration number: [1110/4518] 24% | Training loss: 0.6873768853711653
Epoch: 64 | Iteration number: [1120/4518] 24% | Training loss: 0.6873799179813691
Epoch: 64 | Iteration number: [1130/4518] 25% | Training loss: 0.6873757022671995
Epoch: 64 | Iteration number: [1140/4518] 25% | Training loss: 0.6873701073621449
Epoch: 64 | Iteration number: [1150/4518] 25% | Training loss: 0.687363254920296
Epoch: 64 | Iteration number: [1160/4518] 25% | Training loss: 0.6873578508352411
Epoch: 64 | Iteration number: [1170/4518] 25% | Training loss: 0.6873506917403295
Epoch: 64 | Iteration number: [1180/4518] 26% | Training loss: 0.6873496717820733
Epoch: 64 | Iteration number: [1190/4518] 26% | Training loss: 0.6873475798538753
Epoch: 64 | Iteration number: [1200/4518] 26% | Training loss: 0.6873420922954877
Epoch: 64 | Iteration number: [1210/4518] 26% | Training loss: 0.6873450453123771
Epoch: 64 | Iteration number: [1220/4518] 27% | Training loss: 0.6873436137789586
Epoch: 64 | Iteration number: [1230/4518] 27% | Training loss: 0.6873310634760352
Epoch: 64 | Iteration number: [1240/4518] 27% | Training loss: 0.6873178982926953
Epoch: 64 | Iteration number: [1250/4518] 27% | Training loss: 0.6873152687549591
Epoch: 64 | Iteration number: [1260/4518] 27% | Training loss: 0.6873182394201793
Epoch: 64 | Iteration number: [1270/4518] 28% | Training loss: 0.6873119577648132
Epoch: 64 | Iteration number: [1280/4518] 28% | Training loss: 0.6873135960660874
Epoch: 64 | Iteration number: [1290/4518] 28% | Training loss: 0.6873076967490735
Epoch: 64 | Iteration number: [1300/4518] 28% | Training loss: 0.6873083533232028
Epoch: 64 | Iteration number: [1310/4518] 28% | Training loss: 0.6873053461085749
Epoch: 64 | Iteration number: [1320/4518] 29% | Training loss: 0.6873036263115478
Epoch: 64 | Iteration number: [1330/4518] 29% | Training loss: 0.6873041575564478
Epoch: 64 | Iteration number: [1340/4518] 29% | Training loss: 0.6873009159048992
Epoch: 64 | Iteration number: [1350/4518] 29% | Training loss: 0.6873008814564457
Epoch: 64 | Iteration number: [1360/4518] 30% | Training loss: 0.6873051802463391
Epoch: 64 | Iteration number: [1370/4518] 30% | Training loss: 0.6873015262349679
Epoch: 64 | Iteration number: [1380/4518] 30% | Training loss: 0.6872961512942245
Epoch: 64 | Iteration number: [1390/4518] 30% | Training loss: 0.6872867166996002
Epoch: 64 | Iteration number: [1400/4518] 30% | Training loss: 0.6872863854254995
Epoch: 64 | Iteration number: [1410/4518] 31% | Training loss: 0.6872778855317028
Epoch: 64 | Iteration number: [1420/4518] 31% | Training loss: 0.6872769858215896
Epoch: 64 | Iteration number: [1430/4518] 31% | Training loss: 0.687274112859806
Epoch: 64 | Iteration number: [1440/4518] 31% | Training loss: 0.6872680386735334
Epoch: 64 | Iteration number: [1450/4518] 32% | Training loss: 0.6872626000437243
Epoch: 64 | Iteration number: [1460/4518] 32% | Training loss: 0.6872548101291265
Epoch: 64 | Iteration number: [1470/4518] 32% | Training loss: 0.6872534656605753
Epoch: 64 | Iteration number: [1480/4518] 32% | Training loss: 0.6872513079562703
Epoch: 64 | Iteration number: [1490/4518] 32% | Training loss: 0.6872527166100957
Epoch: 64 | Iteration number: [1500/4518] 33% | Training loss: 0.6872453441619873
Epoch: 64 | Iteration number: [1510/4518] 33% | Training loss: 0.6872506639815325
Epoch: 64 | Iteration number: [1520/4518] 33% | Training loss: 0.6872514535329843
Epoch: 64 | Iteration number: [1530/4518] 33% | Training loss: 0.6872520878034479
Epoch: 64 | Iteration number: [1540/4518] 34% | Training loss: 0.6872594396789352
Epoch: 64 | Iteration number: [1550/4518] 34% | Training loss: 0.6872530083887038
Epoch: 64 | Iteration number: [1560/4518] 34% | Training loss: 0.6872506929131654
Epoch: 64 | Iteration number: [1570/4518] 34% | Training loss: 0.687244084496407
Epoch: 64 | Iteration number: [1580/4518] 34% | Training loss: 0.6872419027210791
Epoch: 64 | Iteration number: [1590/4518] 35% | Training loss: 0.6872397255222752
Epoch: 64 | Iteration number: [1600/4518] 35% | Training loss: 0.6872362663969398
Epoch: 64 | Iteration number: [1610/4518] 35% | Training loss: 0.6872288955664783
Epoch: 64 | Iteration number: [1620/4518] 35% | Training loss: 0.6872334856310008
Epoch: 64 | Iteration number: [1630/4518] 36% | Training loss: 0.6872241046531069
Epoch: 64 | Iteration number: [1640/4518] 36% | Training loss: 0.6872231949756785
Epoch: 64 | Iteration number: [1650/4518] 36% | Training loss: 0.6872181496114442
Epoch: 64 | Iteration number: [1660/4518] 36% | Training loss: 0.6872172457985131
Epoch: 64 | Iteration number: [1670/4518] 36% | Training loss: 0.6872070896411371
Epoch: 64 | Iteration number: [1680/4518] 37% | Training loss: 0.6872099483651775
Epoch: 64 | Iteration number: [1690/4518] 37% | Training loss: 0.6872053288143768
Epoch: 64 | Iteration number: [1700/4518] 37% | Training loss: 0.6872040779099745
Epoch: 64 | Iteration number: [1710/4518] 37% | Training loss: 0.6871977351562322
Epoch: 64 | Iteration number: [1720/4518] 38% | Training loss: 0.6871934531733047
Epoch: 64 | Iteration number: [1730/4518] 38% | Training loss: 0.6871881421935352
Epoch: 64 | Iteration number: [1740/4518] 38% | Training loss: 0.6871824996224765
Epoch: 64 | Iteration number: [1750/4518] 38% | Training loss: 0.6871824902806963
Epoch: 64 | Iteration number: [1760/4518] 38% | Training loss: 0.6871817608448592
Epoch: 64 | Iteration number: [1770/4518] 39% | Training loss: 0.6871760880206265
Epoch: 64 | Iteration number: [1780/4518] 39% | Training loss: 0.6871712000517363
Epoch: 64 | Iteration number: [1790/4518] 39% | Training loss: 0.6871720681310366
Epoch: 64 | Iteration number: [1800/4518] 39% | Training loss: 0.6871721958451801
Epoch: 64 | Iteration number: [1810/4518] 40% | Training loss: 0.6871661649224508
Epoch: 64 | Iteration number: [1820/4518] 40% | Training loss: 0.6871642356390482
Epoch: 64 | Iteration number: [1830/4518] 40% | Training loss: 0.6871630113632953
Epoch: 64 | Iteration number: [1840/4518] 40% | Training loss: 0.6871619316546813
Epoch: 64 | Iteration number: [1850/4518] 40% | Training loss: 0.6871588290059889
Epoch: 64 | Iteration number: [1860/4518] 41% | Training loss: 0.6871539311062905
Epoch: 64 | Iteration number: [1870/4518] 41% | Training loss: 0.6871495387770913
Epoch: 64 | Iteration number: [1880/4518] 41% | Training loss: 0.6871448196312214
Epoch: 64 | Iteration number: [1890/4518] 41% | Training loss: 0.6871443542223128
Epoch: 64 | Iteration number: [1900/4518] 42% | Training loss: 0.6871421942899102
Epoch: 64 | Iteration number: [1910/4518] 42% | Training loss: 0.6871372654487949
Epoch: 64 | Iteration number: [1920/4518] 42% | Training loss: 0.6871389925479889
Epoch: 64 | Iteration number: [1930/4518] 42% | Training loss: 0.6871386814302731
Epoch: 64 | Iteration number: [1940/4518] 42% | Training loss: 0.6871296733310542
Epoch: 64 | Iteration number: [1950/4518] 43% | Training loss: 0.6871310830727602
Epoch: 64 | Iteration number: [1960/4518] 43% | Training loss: 0.687132400517561
Epoch: 64 | Iteration number: [1970/4518] 43% | Training loss: 0.6871290286180332
Epoch: 64 | Iteration number: [1980/4518] 43% | Training loss: 0.6871261978691274
Epoch: 64 | Iteration number: [1990/4518] 44% | Training loss: 0.6871267451712834
Epoch: 64 | Iteration number: [2000/4518] 44% | Training loss: 0.6871269866526127
Epoch: 64 | Iteration number: [2010/4518] 44% | Training loss: 0.6871310483163862
Epoch: 64 | Iteration number: [2020/4518] 44% | Training loss: 0.6871341005410299
Epoch: 64 | Iteration number: [2030/4518] 44% | Training loss: 0.6871278690587124
Epoch: 64 | Iteration number: [2040/4518] 45% | Training loss: 0.6871248032824666
Epoch: 64 | Iteration number: [2050/4518] 45% | Training loss: 0.6871263450529517
Epoch: 64 | Iteration number: [2060/4518] 45% | Training loss: 0.6871248732492762
Epoch: 64 | Iteration number: [2070/4518] 45% | Training loss: 0.6871186554431915
Epoch: 64 | Iteration number: [2080/4518] 46% | Training loss: 0.6871092129785281
Epoch: 64 | Iteration number: [2090/4518] 46% | Training loss: 0.687102629066084
Epoch: 64 | Iteration number: [2100/4518] 46% | Training loss: 0.6871029024180911
Epoch: 64 | Iteration number: [2110/4518] 46% | Training loss: 0.6870999893870964
Epoch: 64 | Iteration number: [2120/4518] 46% | Training loss: 0.6871021924997276
Epoch: 64 | Iteration number: [2130/4518] 47% | Training loss: 0.6870987525008654
Epoch: 64 | Iteration number: [2140/4518] 47% | Training loss: 0.6871019519378092
Epoch: 64 | Iteration number: [2150/4518] 47% | Training loss: 0.6871040988245676
Epoch: 64 | Iteration number: [2160/4518] 47% | Training loss: 0.6871022665114315
Epoch: 64 | Iteration number: [2170/4518] 48% | Training loss: 0.6871027519351326
Epoch: 64 | Iteration number: [2180/4518] 48% | Training loss: 0.6871030824720312
Epoch: 64 | Iteration number: [2190/4518] 48% | Training loss: 0.6870964486577195
Epoch: 64 | Iteration number: [2200/4518] 48% | Training loss: 0.6870932292667302
Epoch: 64 | Iteration number: [2210/4518] 48% | Training loss: 0.6870915409936085
Epoch: 64 | Iteration number: [2220/4518] 49% | Training loss: 0.6870883825662973
Epoch: 64 | Iteration number: [2230/4518] 49% | Training loss: 0.6870879651452394
Epoch: 64 | Iteration number: [2240/4518] 49% | Training loss: 0.6870820723740118
Epoch: 64 | Iteration number: [2250/4518] 49% | Training loss: 0.6870794409116109
Epoch: 64 | Iteration number: [2260/4518] 50% | Training loss: 0.6870761918810616
Epoch: 64 | Iteration number: [2270/4518] 50% | Training loss: 0.6870766706928808
Epoch: 64 | Iteration number: [2280/4518] 50% | Training loss: 0.6870780566021015
Epoch: 64 | Iteration number: [2290/4518] 50% | Training loss: 0.6870839575752942
Epoch: 64 | Iteration number: [2300/4518] 50% | Training loss: 0.6870796996873358
Epoch: 64 | Iteration number: [2310/4518] 51% | Training loss: 0.6870800679122214
Epoch: 64 | Iteration number: [2320/4518] 51% | Training loss: 0.6870763551058441
Epoch: 64 | Iteration number: [2330/4518] 51% | Training loss: 0.6870757868105761
Epoch: 64 | Iteration number: [2340/4518] 51% | Training loss: 0.6870705457324655
Epoch: 64 | Iteration number: [2350/4518] 52% | Training loss: 0.6870714266756748
Epoch: 64 | Iteration number: [2360/4518] 52% | Training loss: 0.6870687053365222
Epoch: 64 | Iteration number: [2370/4518] 52% | Training loss: 0.6870704329215022
Epoch: 64 | Iteration number: [2380/4518] 52% | Training loss: 0.6870677767180595
Epoch: 64 | Iteration number: [2390/4518] 52% | Training loss: 0.687073104451391
Epoch: 64 | Iteration number: [2400/4518] 53% | Training loss: 0.6870737592379252
Epoch: 64 | Iteration number: [2410/4518] 53% | Training loss: 0.6870702718303411
Epoch: 64 | Iteration number: [2420/4518] 53% | Training loss: 0.6870691296729174
Epoch: 64 | Iteration number: [2430/4518] 53% | Training loss: 0.6870738338541101
Epoch: 64 | Iteration number: [2440/4518] 54% | Training loss: 0.6870748004463852
Epoch: 64 | Iteration number: [2450/4518] 54% | Training loss: 0.6870727843167831
Epoch: 64 | Iteration number: [2460/4518] 54% | Training loss: 0.6870712679576099
Epoch: 64 | Iteration number: [2470/4518] 54% | Training loss: 0.6870686670305275
Epoch: 64 | Iteration number: [2480/4518] 54% | Training loss: 0.6870664796521587
Epoch: 64 | Iteration number: [2490/4518] 55% | Training loss: 0.6870672022243102
Epoch: 64 | Iteration number: [2500/4518] 55% | Training loss: 0.6870642884969711
Epoch: 64 | Iteration number: [2510/4518] 55% | Training loss: 0.6870595172344451
Epoch: 64 | Iteration number: [2520/4518] 55% | Training loss: 0.6870586708188057
Epoch: 64 | Iteration number: [2530/4518] 55% | Training loss: 0.6870575837231436
Epoch: 64 | Iteration number: [2540/4518] 56% | Training loss: 0.6870613106827098
Epoch: 64 | Iteration number: [2550/4518] 56% | Training loss: 0.6870589361705032
Epoch: 64 | Iteration number: [2560/4518] 56% | Training loss: 0.6870540233328939
Epoch: 64 | Iteration number: [2570/4518] 56% | Training loss: 0.6870588155108204
Epoch: 64 | Iteration number: [2580/4518] 57% | Training loss: 0.6870559397593949
Epoch: 64 | Iteration number: [2590/4518] 57% | Training loss: 0.6870491679570849
Epoch: 64 | Iteration number: [2600/4518] 57% | Training loss: 0.6870520084867111
Epoch: 64 | Iteration number: [2610/4518] 57% | Training loss: 0.6870479646313693
Epoch: 64 | Iteration number: [2620/4518] 57% | Training loss: 0.6870418730355401
Epoch: 64 | Iteration number: [2630/4518] 58% | Training loss: 0.6870374993453008
Epoch: 64 | Iteration number: [2640/4518] 58% | Training loss: 0.6870362112467939
Epoch: 64 | Iteration number: [2650/4518] 58% | Training loss: 0.6870291108680221
Epoch: 64 | Iteration number: [2660/4518] 58% | Training loss: 0.6870247037114954
Epoch: 64 | Iteration number: [2670/4518] 59% | Training loss: 0.6870239745811577
Epoch: 64 | Iteration number: [2680/4518] 59% | Training loss: 0.687028912599407
Epoch: 64 | Iteration number: [2690/4518] 59% | Training loss: 0.6870313200587234
Epoch: 64 | Iteration number: [2700/4518] 59% | Training loss: 0.687026760644383
Epoch: 64 | Iteration number: [2710/4518] 59% | Training loss: 0.6870238091672919
Epoch: 64 | Iteration number: [2720/4518] 60% | Training loss: 0.6870210318661788
Epoch: 64 | Iteration number: [2730/4518] 60% | Training loss: 0.6870209110307169
Epoch: 64 | Iteration number: [2740/4518] 60% | Training loss: 0.687020484983486
Epoch: 64 | Iteration number: [2750/4518] 60% | Training loss: 0.6870186409733512
Epoch: 64 | Iteration number: [2760/4518] 61% | Training loss: 0.6870179470034613
Epoch: 64 | Iteration number: [2770/4518] 61% | Training loss: 0.6870182111590347
Epoch: 64 | Iteration number: [2780/4518] 61% | Training loss: 0.6870229629089506
Epoch: 64 | Iteration number: [2790/4518] 61% | Training loss: 0.687022311905379
Epoch: 64 | Iteration number: [2800/4518] 61% | Training loss: 0.687019519848483
Epoch: 64 | Iteration number: [2810/4518] 62% | Training loss: 0.6870184063911438
Epoch: 64 | Iteration number: [2820/4518] 62% | Training loss: 0.6870200029924406
Epoch: 64 | Iteration number: [2830/4518] 62% | Training loss: 0.6870173125932579
Epoch: 64 | Iteration number: [2840/4518] 62% | Training loss: 0.6870160772137239
Epoch: 64 | Iteration number: [2850/4518] 63% | Training loss: 0.6870088189735747
Epoch: 64 | Iteration number: [2860/4518] 63% | Training loss: 0.6870121114320689
Epoch: 64 | Iteration number: [2870/4518] 63% | Training loss: 0.6870122768737713
Epoch: 64 | Iteration number: [2880/4518] 63% | Training loss: 0.6870088587825497
Epoch: 64 | Iteration number: [2890/4518] 63% | Training loss: 0.6870106308105495
Epoch: 64 | Iteration number: [2900/4518] 64% | Training loss: 0.6870098668953468
Epoch: 64 | Iteration number: [2910/4518] 64% | Training loss: 0.6870084653400473
Epoch: 64 | Iteration number: [2920/4518] 64% | Training loss: 0.6870039374656873
Epoch: 64 | Iteration number: [2930/4518] 64% | Training loss: 0.6869977121060212
Epoch: 64 | Iteration number: [2940/4518] 65% | Training loss: 0.6869929421718429
Epoch: 64 | Iteration number: [2950/4518] 65% | Training loss: 0.6869916409961248
Epoch: 64 | Iteration number: [2960/4518] 65% | Training loss: 0.6869893585910668
Epoch: 64 | Iteration number: [2970/4518] 65% | Training loss: 0.6869924623958189
Epoch: 64 | Iteration number: [2980/4518] 65% | Training loss: 0.6869879846204847
Epoch: 64 | Iteration number: [2990/4518] 66% | Training loss: 0.6869883465727037
Epoch: 64 | Iteration number: [3000/4518] 66% | Training loss: 0.6869897370934487
Epoch: 64 | Iteration number: [3010/4518] 66% | Training loss: 0.6869940770028834
Epoch: 64 | Iteration number: [3020/4518] 66% | Training loss: 0.6869931281797144
Epoch: 64 | Iteration number: [3030/4518] 67% | Training loss: 0.6869935888465089
Epoch: 64 | Iteration number: [3040/4518] 67% | Training loss: 0.6869920703925585
Epoch: 64 | Iteration number: [3050/4518] 67% | Training loss: 0.686987762842022
Epoch: 64 | Iteration number: [3060/4518] 67% | Training loss: 0.6869860229538937
Epoch: 64 | Iteration number: [3070/4518] 67% | Training loss: 0.6869873381204636
Epoch: 64 | Iteration number: [3080/4518] 68% | Training loss: 0.6869870271969151
Epoch: 64 | Iteration number: [3090/4518] 68% | Training loss: 0.6869902703947234
Epoch: 64 | Iteration number: [3100/4518] 68% | Training loss: 0.6869900490007093
Epoch: 64 | Iteration number: [3110/4518] 68% | Training loss: 0.6869932573899579
Epoch: 64 | Iteration number: [3120/4518] 69% | Training loss: 0.6869946514375699
Epoch: 64 | Iteration number: [3130/4518] 69% | Training loss: 0.6869943884043648
Epoch: 64 | Iteration number: [3140/4518] 69% | Training loss: 0.6869959622052065
Epoch: 64 | Iteration number: [3150/4518] 69% | Training loss: 0.6869983984364404
Epoch: 64 | Iteration number: [3160/4518] 69% | Training loss: 0.687002406278743
Epoch: 64 | Iteration number: [3170/4518] 70% | Training loss: 0.6870040964252941
Epoch: 64 | Iteration number: [3180/4518] 70% | Training loss: 0.6870053272577202
Epoch: 64 | Iteration number: [3190/4518] 70% | Training loss: 0.6870034105912272
Epoch: 64 | Iteration number: [3200/4518] 70% | Training loss: 0.6870010557770729
Epoch: 64 | Iteration number: [3210/4518] 71% | Training loss: 0.6869991938087427
Epoch: 64 | Iteration number: [3220/4518] 71% | Training loss: 0.686994923641963
Epoch: 64 | Iteration number: [3230/4518] 71% | Training loss: 0.6869953671291517
Epoch: 64 | Iteration number: [3240/4518] 71% | Training loss: 0.6869948195086585
Epoch: 64 | Iteration number: [3250/4518] 71% | Training loss: 0.6869944112667671
Epoch: 64 | Iteration number: [3260/4518] 72% | Training loss: 0.6869881804552547
Epoch: 64 | Iteration number: [3270/4518] 72% | Training loss: 0.6869869380186822
Epoch: 64 | Iteration number: [3280/4518] 72% | Training loss: 0.6869866387327996
Epoch: 64 | Iteration number: [3290/4518] 72% | Training loss: 0.6869822706313844
Epoch: 64 | Iteration number: [3300/4518] 73% | Training loss: 0.686983569408908
Epoch: 64 | Iteration number: [3310/4518] 73% | Training loss: 0.6869840469785328
Epoch: 64 | Iteration number: [3320/4518] 73% | Training loss: 0.6869879816490484
Epoch: 64 | Iteration number: [3330/4518] 73% | Training loss: 0.6869853711164033
Epoch: 64 | Iteration number: [3340/4518] 73% | Training loss: 0.6869858436955664
Epoch: 64 | Iteration number: [3350/4518] 74% | Training loss: 0.6869862893446168
Epoch: 64 | Iteration number: [3360/4518] 74% | Training loss: 0.6869852686566966
Epoch: 64 | Iteration number: [3370/4518] 74% | Training loss: 0.6869840864081057
Epoch: 64 | Iteration number: [3380/4518] 74% | Training loss: 0.6869850937784071
Epoch: 64 | Iteration number: [3390/4518] 75% | Training loss: 0.6869855382801158
Epoch: 64 | Iteration number: [3400/4518] 75% | Training loss: 0.6869840850549586
Epoch: 64 | Iteration number: [3410/4518] 75% | Training loss: 0.6869841474417018
Epoch: 64 | Iteration number: [3420/4518] 75% | Training loss: 0.6869865526581368
Epoch: 64 | Iteration number: [3430/4518] 75% | Training loss: 0.6869857512132072
Epoch: 64 | Iteration number: [3440/4518] 76% | Training loss: 0.6869799960837808
Epoch: 64 | Iteration number: [3450/4518] 76% | Training loss: 0.6869739044921985
Epoch: 64 | Iteration number: [3460/4518] 76% | Training loss: 0.6869732658298029
Epoch: 64 | Iteration number: [3470/4518] 76% | Training loss: 0.686972148858161
Epoch: 64 | Iteration number: [3480/4518] 77% | Training loss: 0.6869699162313307
Epoch: 64 | Iteration number: [3490/4518] 77% | Training loss: 0.6869717943121847
Epoch: 64 | Iteration number: [3500/4518] 77% | Training loss: 0.6869701699018479
Epoch: 64 | Iteration number: [3510/4518] 77% | Training loss: 0.6869713979399102
Epoch: 64 | Iteration number: [3520/4518] 77% | Training loss: 0.6869702588258819
Epoch: 64 | Iteration number: [3530/4518] 78% | Training loss: 0.6869654744947936
Epoch: 64 | Iteration number: [3540/4518] 78% | Training loss: 0.6869620775940728
Epoch: 64 | Iteration number: [3550/4518] 78% | Training loss: 0.6869665999143896
Epoch: 64 | Iteration number: [3560/4518] 78% | Training loss: 0.686967983440067
Epoch: 64 | Iteration number: [3570/4518] 79% | Training loss: 0.6869732748727505
Epoch: 64 | Iteration number: [3580/4518] 79% | Training loss: 0.6869762594473429
Epoch: 64 | Iteration number: [3590/4518] 79% | Training loss: 0.6869773414971768
Epoch: 64 | Iteration number: [3600/4518] 79% | Training loss: 0.6869748899009492
Epoch: 64 | Iteration number: [3610/4518] 79% | Training loss: 0.6869736718834272
Epoch: 64 | Iteration number: [3620/4518] 80% | Training loss: 0.6869762821256785
Epoch: 64 | Iteration number: [3630/4518] 80% | Training loss: 0.686975438453606
Epoch: 64 | Iteration number: [3640/4518] 80% | Training loss: 0.6869747668177217
Epoch: 64 | Iteration number: [3650/4518] 80% | Training loss: 0.6869708526297791
Epoch: 64 | Iteration number: [3660/4518] 81% | Training loss: 0.6869668157211418
Epoch: 64 | Iteration number: [3670/4518] 81% | Training loss: 0.686970384861533
Epoch: 64 | Iteration number: [3680/4518] 81% | Training loss: 0.6869657363904559
Epoch: 64 | Iteration number: [3690/4518] 81% | Training loss: 0.6869680584769262
Epoch: 64 | Iteration number: [3700/4518] 81% | Training loss: 0.6869688220604045
Epoch: 64 | Iteration number: [3710/4518] 82% | Training loss: 0.686971796522886
Epoch: 64 | Iteration number: [3720/4518] 82% | Training loss: 0.6869698728604984
Epoch: 64 | Iteration number: [3730/4518] 82% | Training loss: 0.6869728791969392
Epoch: 64 | Iteration number: [3740/4518] 82% | Training loss: 0.6869738738645207
Epoch: 64 | Iteration number: [3750/4518] 83% | Training loss: 0.6869719790617624
Epoch: 64 | Iteration number: [3760/4518] 83% | Training loss: 0.6869708503338885
Epoch: 64 | Iteration number: [3770/4518] 83% | Training loss: 0.6869727300396016
Epoch: 64 | Iteration number: [3780/4518] 83% | Training loss: 0.6869710332975185
Epoch: 64 | Iteration number: [3790/4518] 83% | Training loss: 0.686972523584844
Epoch: 64 | Iteration number: [3800/4518] 84% | Training loss: 0.6869724301601711
Epoch: 64 | Iteration number: [3810/4518] 84% | Training loss: 0.686974603923287
Epoch: 64 | Iteration number: [3820/4518] 84% | Training loss: 0.6869739483164243
Epoch: 64 | Iteration number: [3830/4518] 84% | Training loss: 0.6869743370511825
Epoch: 64 | Iteration number: [3840/4518] 84% | Training loss: 0.6869732367030035
Epoch: 64 | Iteration number: [3850/4518] 85% | Training loss: 0.6869682682024968
Epoch: 64 | Iteration number: [3860/4518] 85% | Training loss: 0.6869665489604436
Epoch: 64 | Iteration number: [3870/4518] 85% | Training loss: 0.6869690670523533
Epoch: 64 | Iteration number: [3880/4518] 85% | Training loss: 0.6869684421678179
Epoch: 64 | Iteration number: [3890/4518] 86% | Training loss: 0.6869680446187144
Epoch: 64 | Iteration number: [3900/4518] 86% | Training loss: 0.6869684360119013
Epoch: 64 | Iteration number: [3910/4518] 86% | Training loss: 0.6869683759444205
Epoch: 64 | Iteration number: [3920/4518] 86% | Training loss: 0.6869686352203087
Epoch: 64 | Iteration number: [3930/4518] 86% | Training loss: 0.6869690179521497
Epoch: 64 | Iteration number: [3940/4518] 87% | Training loss: 0.6869686566784903
Epoch: 64 | Iteration number: [3950/4518] 87% | Training loss: 0.6869684143307843
Epoch: 64 | Iteration number: [3960/4518] 87% | Training loss: 0.6869663755249495
Epoch: 64 | Iteration number: [3970/4518] 87% | Training loss: 0.6869661558184876
Epoch: 64 | Iteration number: [3980/4518] 88% | Training loss: 0.6869649131393912
Epoch: 64 | Iteration number: [3990/4518] 88% | Training loss: 0.6869685680495766
Epoch: 64 | Iteration number: [4000/4518] 88% | Training loss: 0.6869642343968153
Epoch: 64 | Iteration number: [4010/4518] 88% | Training loss: 0.6869656669974624
Epoch: 64 | Iteration number: [4020/4518] 88% | Training loss: 0.6869643054643081
Epoch: 64 | Iteration number: [4030/4518] 89% | Training loss: 0.6869639966683115
Epoch: 64 | Iteration number: [4040/4518] 89% | Training loss: 0.6869610327010107
Epoch: 64 | Iteration number: [4050/4518] 89% | Training loss: 0.6869619114016309
Epoch: 64 | Iteration number: [4060/4518] 89% | Training loss: 0.6869609068033143
Epoch: 64 | Iteration number: [4070/4518] 90% | Training loss: 0.6869611873673572
Epoch: 64 | Iteration number: [4080/4518] 90% | Training loss: 0.6869596476940548
Epoch: 64 | Iteration number: [4090/4518] 90% | Training loss: 0.6869577558670183
Epoch: 64 | Iteration number: [4100/4518] 90% | Training loss: 0.6869592502931269
Epoch: 64 | Iteration number: [4110/4518] 90% | Training loss: 0.6869590915467617
Epoch: 64 | Iteration number: [4120/4518] 91% | Training loss: 0.6869615585045907
Epoch: 64 | Iteration number: [4130/4518] 91% | Training loss: 0.6869619828015205
Epoch: 64 | Iteration number: [4140/4518] 91% | Training loss: 0.6869605797788371
Epoch: 64 | Iteration number: [4150/4518] 91% | Training loss: 0.6869566114264798
Epoch: 64 | Iteration number: [4160/4518] 92% | Training loss: 0.6869579143249072
Epoch: 64 | Iteration number: [4170/4518] 92% | Training loss: 0.6869586431008163
Epoch: 64 | Iteration number: [4180/4518] 92% | Training loss: 0.6869558571058026
Epoch: 64 | Iteration number: [4190/4518] 92% | Training loss: 0.6869538728121073
Epoch: 64 | Iteration number: [4200/4518] 92% | Training loss: 0.6869510206863993
Epoch: 64 | Iteration number: [4210/4518] 93% | Training loss: 0.6869509966101612
Epoch: 64 | Iteration number: [4220/4518] 93% | Training loss: 0.6869506568846544
Epoch: 64 | Iteration number: [4230/4518] 93% | Training loss: 0.6869508246298941
Epoch: 64 | Iteration number: [4240/4518] 93% | Training loss: 0.6869493678915051
Epoch: 64 | Iteration number: [4250/4518] 94% | Training loss: 0.6869508793915019
Epoch: 64 | Iteration number: [4260/4518] 94% | Training loss: 0.6869513241338058
Epoch: 64 | Iteration number: [4270/4518] 94% | Training loss: 0.6869531535571856
Epoch: 64 | Iteration number: [4280/4518] 94% | Training loss: 0.686951844784144
Epoch: 64 | Iteration number: [4290/4518] 94% | Training loss: 0.6869531021112607
Epoch: 64 | Iteration number: [4300/4518] 95% | Training loss: 0.6869514722463697
Epoch: 64 | Iteration number: [4310/4518] 95% | Training loss: 0.686949229005318
Epoch: 64 | Iteration number: [4320/4518] 95% | Training loss: 0.6869522270643049
Epoch: 64 | Iteration number: [4330/4518] 95% | Training loss: 0.6869503789217863
Epoch: 64 | Iteration number: [4340/4518] 96% | Training loss: 0.6869494724658227
Epoch: 64 | Iteration number: [4350/4518] 96% | Training loss: 0.6869484232760024
Epoch: 64 | Iteration number: [4360/4518] 96% | Training loss: 0.6869482478554095
Epoch: 64 | Iteration number: [4370/4518] 96% | Training loss: 0.6869481920104823
Epoch: 64 | Iteration number: [4380/4518] 96% | Training loss: 0.6869472341178214
Epoch: 64 | Iteration number: [4390/4518] 97% | Training loss: 0.6869450906414649
Epoch: 64 | Iteration number: [4400/4518] 97% | Training loss: 0.6869427594542503
Epoch: 64 | Iteration number: [4410/4518] 97% | Training loss: 0.6869440217948014
Epoch: 64 | Iteration number: [4420/4518] 97% | Training loss: 0.6869432043166183
Epoch: 64 | Iteration number: [4430/4518] 98% | Training loss: 0.6869446362383479
Epoch: 64 | Iteration number: [4440/4518] 98% | Training loss: 0.6869468593516865
Epoch: 64 | Iteration number: [4450/4518] 98% | Training loss: 0.6869469642907046
Epoch: 64 | Iteration number: [4460/4518] 98% | Training loss: 0.6869474158158752
Epoch: 64 | Iteration number: [4470/4518] 98% | Training loss: 0.6869493101800581
Epoch: 64 | Iteration number: [4480/4518] 99% | Training loss: 0.6869475648073213
Epoch: 64 | Iteration number: [4490/4518] 99% | Training loss: 0.6869470420154538
Epoch: 64 | Iteration number: [4500/4518] 99% | Training loss: 0.6869451315402985
Epoch: 64 | Iteration number: [4510/4518] 99% | Training loss: 0.686943750027278

 End of epoch: 64 | Train Loss: 0.6867911710497445 | Training Time: 643 

 End of epoch: 64 | Eval Loss: 0.6900514412899407 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/4518] 0% | Training loss: 0.7552661716938018
Epoch: 65 | Iteration number: [20/4518] 0% | Training loss: 0.7209327936172485
Epoch: 65 | Iteration number: [30/4518] 0% | Training loss: 0.7100147167841594
Epoch: 65 | Iteration number: [40/4518] 0% | Training loss: 0.7043096125125885
Epoch: 65 | Iteration number: [50/4518] 1% | Training loss: 0.7007775640487671
Epoch: 65 | Iteration number: [60/4518] 1% | Training loss: 0.6985306998093923
Epoch: 65 | Iteration number: [70/4518] 1% | Training loss: 0.6969539821147919
Epoch: 65 | Iteration number: [80/4518] 1% | Training loss: 0.6956832893192768
Epoch: 65 | Iteration number: [90/4518] 1% | Training loss: 0.6945555773046281
Epoch: 65 | Iteration number: [100/4518] 2% | Training loss: 0.6939687412977219
Epoch: 65 | Iteration number: [110/4518] 2% | Training loss: 0.6933133818886497
Epoch: 65 | Iteration number: [120/4518] 2% | Training loss: 0.6927871207396189
Epoch: 65 | Iteration number: [130/4518] 2% | Training loss: 0.6922864959790156
Epoch: 65 | Iteration number: [140/4518] 3% | Training loss: 0.6920325568744115
Epoch: 65 | Iteration number: [150/4518] 3% | Training loss: 0.6917376176516215
Epoch: 65 | Iteration number: [160/4518] 3% | Training loss: 0.691433360427618
Epoch: 65 | Iteration number: [170/4518] 3% | Training loss: 0.6910641884102541
Epoch: 65 | Iteration number: [180/4518] 3% | Training loss: 0.6908753199709786
Epoch: 65 | Iteration number: [190/4518] 4% | Training loss: 0.6906783674892626
Epoch: 65 | Iteration number: [200/4518] 4% | Training loss: 0.6905313247442245
Epoch: 65 | Iteration number: [210/4518] 4% | Training loss: 0.6903016953241258
Epoch: 65 | Iteration number: [220/4518] 4% | Training loss: 0.6901272329417142
Epoch: 65 | Iteration number: [230/4518] 5% | Training loss: 0.6900288514468981
Epoch: 65 | Iteration number: [240/4518] 5% | Training loss: 0.6898461997509002
Epoch: 65 | Iteration number: [250/4518] 5% | Training loss: 0.6897401070594787
Epoch: 65 | Iteration number: [260/4518] 5% | Training loss: 0.6896310593073185
Epoch: 65 | Iteration number: [270/4518] 5% | Training loss: 0.6895179170149344
Epoch: 65 | Iteration number: [280/4518] 6% | Training loss: 0.6893878968698638
Epoch: 65 | Iteration number: [290/4518] 6% | Training loss: 0.6893121187029214
Epoch: 65 | Iteration number: [300/4518] 6% | Training loss: 0.6891866228977839
Epoch: 65 | Iteration number: [310/4518] 6% | Training loss: 0.6890665037016714
Epoch: 65 | Iteration number: [320/4518] 7% | Training loss: 0.6890107179060578
Epoch: 65 | Iteration number: [330/4518] 7% | Training loss: 0.6889719153895523
Epoch: 65 | Iteration number: [340/4518] 7% | Training loss: 0.6888977184015161
Epoch: 65 | Iteration number: [350/4518] 7% | Training loss: 0.688850314787456
Epoch: 65 | Iteration number: [360/4518] 7% | Training loss: 0.6887668997049332
Epoch: 65 | Iteration number: [370/4518] 8% | Training loss: 0.6887131942285074
Epoch: 65 | Iteration number: [380/4518] 8% | Training loss: 0.6886702496754495
Epoch: 65 | Iteration number: [390/4518] 8% | Training loss: 0.6886095025600532
Epoch: 65 | Iteration number: [400/4518] 8% | Training loss: 0.6885862585902214
Epoch: 65 | Iteration number: [410/4518] 9% | Training loss: 0.6885431007641117
Epoch: 65 | Iteration number: [420/4518] 9% | Training loss: 0.6884775028342293
Epoch: 65 | Iteration number: [430/4518] 9% | Training loss: 0.6884411551231562
Epoch: 65 | Iteration number: [440/4518] 9% | Training loss: 0.6884232751347802
Epoch: 65 | Iteration number: [450/4518] 9% | Training loss: 0.6884151958094703
Epoch: 65 | Iteration number: [460/4518] 10% | Training loss: 0.6883969042612159
Epoch: 65 | Iteration number: [470/4518] 10% | Training loss: 0.6883522632274222
Epoch: 65 | Iteration number: [480/4518] 10% | Training loss: 0.688340758283933
Epoch: 65 | Iteration number: [490/4518] 10% | Training loss: 0.6882978249569328
Epoch: 65 | Iteration number: [500/4518] 11% | Training loss: 0.6882739171981812
Epoch: 65 | Iteration number: [510/4518] 11% | Training loss: 0.6882491630666396
Epoch: 65 | Iteration number: [520/4518] 11% | Training loss: 0.6881991588152372
Epoch: 65 | Iteration number: [530/4518] 11% | Training loss: 0.6882025460027299
Epoch: 65 | Iteration number: [540/4518] 11% | Training loss: 0.6881748660846992
Epoch: 65 | Iteration number: [550/4518] 12% | Training loss: 0.6881305288184772
Epoch: 65 | Iteration number: [560/4518] 12% | Training loss: 0.6880932606756687
Epoch: 65 | Iteration number: [570/4518] 12% | Training loss: 0.6880498623638822
Epoch: 65 | Iteration number: [580/4518] 12% | Training loss: 0.6880285979344927
Epoch: 65 | Iteration number: [590/4518] 13% | Training loss: 0.688031699192726
Epoch: 65 | Iteration number: [600/4518] 13% | Training loss: 0.6880089554190636
Epoch: 65 | Iteration number: [610/4518] 13% | Training loss: 0.6879865189067653
Epoch: 65 | Iteration number: [620/4518] 13% | Training loss: 0.6879842204432334
Epoch: 65 | Iteration number: [630/4518] 13% | Training loss: 0.6879724335102808
Epoch: 65 | Iteration number: [640/4518] 14% | Training loss: 0.6879550330340862
Epoch: 65 | Iteration number: [650/4518] 14% | Training loss: 0.6879470540010012
Epoch: 65 | Iteration number: [660/4518] 14% | Training loss: 0.6879225208000703
Epoch: 65 | Iteration number: [670/4518] 14% | Training loss: 0.6879065588339052
Epoch: 65 | Iteration number: [680/4518] 15% | Training loss: 0.6878883318866
Epoch: 65 | Iteration number: [690/4518] 15% | Training loss: 0.6878838527893675
Epoch: 65 | Iteration number: [700/4518] 15% | Training loss: 0.6878645625284739
Epoch: 65 | Iteration number: [710/4518] 15% | Training loss: 0.6878627755272556
Epoch: 65 | Iteration number: [720/4518] 15% | Training loss: 0.6878531721731027
Epoch: 65 | Iteration number: [730/4518] 16% | Training loss: 0.6878296941110532
Epoch: 65 | Iteration number: [740/4518] 16% | Training loss: 0.6878201279285792
Epoch: 65 | Iteration number: [750/4518] 16% | Training loss: 0.6878216633001963
Epoch: 65 | Iteration number: [760/4518] 16% | Training loss: 0.6878074117397007
Epoch: 65 | Iteration number: [770/4518] 17% | Training loss: 0.6877912440083244
Epoch: 65 | Iteration number: [780/4518] 17% | Training loss: 0.6877623833906956
Epoch: 65 | Iteration number: [790/4518] 17% | Training loss: 0.6877570580078076
Epoch: 65 | Iteration number: [800/4518] 17% | Training loss: 0.6877474787086248
Epoch: 65 | Iteration number: [810/4518] 17% | Training loss: 0.6877295294661581
Epoch: 65 | Iteration number: [820/4518] 18% | Training loss: 0.6877225177317131
Epoch: 65 | Iteration number: [830/4518] 18% | Training loss: 0.6877237579908716
Epoch: 65 | Iteration number: [840/4518] 18% | Training loss: 0.6877141072636559
Epoch: 65 | Iteration number: [850/4518] 18% | Training loss: 0.6877045022038852
Epoch: 65 | Iteration number: [860/4518] 19% | Training loss: 0.6877010601897572
Epoch: 65 | Iteration number: [870/4518] 19% | Training loss: 0.6876870458153472
Epoch: 65 | Iteration number: [880/4518] 19% | Training loss: 0.6876678154549816
Epoch: 65 | Iteration number: [890/4518] 19% | Training loss: 0.6876563208156757
Epoch: 65 | Iteration number: [900/4518] 19% | Training loss: 0.6876437046792772
Epoch: 65 | Iteration number: [910/4518] 20% | Training loss: 0.6876457279855078
Epoch: 65 | Iteration number: [920/4518] 20% | Training loss: 0.6876229098309641
Epoch: 65 | Iteration number: [930/4518] 20% | Training loss: 0.6876002398229415
Epoch: 65 | Iteration number: [940/4518] 20% | Training loss: 0.6875894547776973
Epoch: 65 | Iteration number: [950/4518] 21% | Training loss: 0.6875754614252794
Epoch: 65 | Iteration number: [960/4518] 21% | Training loss: 0.6875666627039512
Epoch: 65 | Iteration number: [970/4518] 21% | Training loss: 0.6875402106452234
Epoch: 65 | Iteration number: [980/4518] 21% | Training loss: 0.6875351065883831
Epoch: 65 | Iteration number: [990/4518] 21% | Training loss: 0.6875339441829258
Epoch: 65 | Iteration number: [1000/4518] 22% | Training loss: 0.6875231628417968
Epoch: 65 | Iteration number: [1010/4518] 22% | Training loss: 0.6875185107240582
Epoch: 65 | Iteration number: [1020/4518] 22% | Training loss: 0.6875124539230384
Epoch: 65 | Iteration number: [1030/4518] 22% | Training loss: 0.6875136969737636
Epoch: 65 | Iteration number: [1040/4518] 23% | Training loss: 0.6875121856538149
Epoch: 65 | Iteration number: [1050/4518] 23% | Training loss: 0.6875067137536548
Epoch: 65 | Iteration number: [1060/4518] 23% | Training loss: 0.6875031411647796
Epoch: 65 | Iteration number: [1070/4518] 23% | Training loss: 0.6874946219341778
Epoch: 65 | Iteration number: [1080/4518] 23% | Training loss: 0.6874975958356151
Epoch: 65 | Iteration number: [1090/4518] 24% | Training loss: 0.6874892960447784
Epoch: 65 | Iteration number: [1100/4518] 24% | Training loss: 0.6874769055843353
Epoch: 65 | Iteration number: [1110/4518] 24% | Training loss: 0.687472007188711
Epoch: 65 | Iteration number: [1120/4518] 24% | Training loss: 0.6874546140964543
Epoch: 65 | Iteration number: [1130/4518] 25% | Training loss: 0.6874468555492638
Epoch: 65 | Iteration number: [1140/4518] 25% | Training loss: 0.6874406420347984
Epoch: 65 | Iteration number: [1150/4518] 25% | Training loss: 0.6874371566979781
Epoch: 65 | Iteration number: [1160/4518] 25% | Training loss: 0.6874365275276119
Epoch: 65 | Iteration number: [1170/4518] 25% | Training loss: 0.6874334135116675
Epoch: 65 | Iteration number: [1180/4518] 26% | Training loss: 0.6874130647566359
Epoch: 65 | Iteration number: [1190/4518] 26% | Training loss: 0.6874075836494189
Epoch: 65 | Iteration number: [1200/4518] 26% | Training loss: 0.6874063503245512
Epoch: 65 | Iteration number: [1210/4518] 26% | Training loss: 0.6873915393983037
Epoch: 65 | Iteration number: [1220/4518] 27% | Training loss: 0.6873925950194969
Epoch: 65 | Iteration number: [1230/4518] 27% | Training loss: 0.6873945642292985
Epoch: 65 | Iteration number: [1240/4518] 27% | Training loss: 0.6873811653544826
Epoch: 65 | Iteration number: [1250/4518] 27% | Training loss: 0.687377825498581
Epoch: 65 | Iteration number: [1260/4518] 27% | Training loss: 0.687373859399841
Epoch: 65 | Iteration number: [1270/4518] 28% | Training loss: 0.6873652284070263
Epoch: 65 | Iteration number: [1280/4518] 28% | Training loss: 0.6873600903898478
Epoch: 65 | Iteration number: [1290/4518] 28% | Training loss: 0.6873460292816163
Epoch: 65 | Iteration number: [1300/4518] 28% | Training loss: 0.6873463997474083
Epoch: 65 | Iteration number: [1310/4518] 28% | Training loss: 0.6873386377141676
Epoch: 65 | Iteration number: [1320/4518] 29% | Training loss: 0.6873393454786503
Epoch: 65 | Iteration number: [1330/4518] 29% | Training loss: 0.6873353750185859
Epoch: 65 | Iteration number: [1340/4518] 29% | Training loss: 0.6873424752879499
Epoch: 65 | Iteration number: [1350/4518] 29% | Training loss: 0.687335803243849
Epoch: 65 | Iteration number: [1360/4518] 30% | Training loss: 0.6873272369013114
Epoch: 65 | Iteration number: [1370/4518] 30% | Training loss: 0.6873329312696944
Epoch: 65 | Iteration number: [1380/4518] 30% | Training loss: 0.6873221954573756
Epoch: 65 | Iteration number: [1390/4518] 30% | Training loss: 0.6873193456972245
Epoch: 65 | Iteration number: [1400/4518] 30% | Training loss: 0.6873227308051927
Epoch: 65 | Iteration number: [1410/4518] 31% | Training loss: 0.6873193016711702
Epoch: 65 | Iteration number: [1420/4518] 31% | Training loss: 0.6873167165987928
Epoch: 65 | Iteration number: [1430/4518] 31% | Training loss: 0.6873167322648989
Epoch: 65 | Iteration number: [1440/4518] 31% | Training loss: 0.6873120988822645
Epoch: 65 | Iteration number: [1450/4518] 32% | Training loss: 0.6873101397629442
Epoch: 65 | Iteration number: [1460/4518] 32% | Training loss: 0.6873053401300352
Epoch: 65 | Iteration number: [1470/4518] 32% | Training loss: 0.6873086433426864
Epoch: 65 | Iteration number: [1480/4518] 32% | Training loss: 0.6873102663336573
Epoch: 65 | Iteration number: [1490/4518] 32% | Training loss: 0.6873163410881221
Epoch: 65 | Iteration number: [1500/4518] 33% | Training loss: 0.6873121869564056
Epoch: 65 | Iteration number: [1510/4518] 33% | Training loss: 0.6873042423993546
Epoch: 65 | Iteration number: [1520/4518] 33% | Training loss: 0.6872888957591433
Epoch: 65 | Iteration number: [1530/4518] 33% | Training loss: 0.6872840875504064
Epoch: 65 | Iteration number: [1540/4518] 34% | Training loss: 0.6872907298725921
Epoch: 65 | Iteration number: [1550/4518] 34% | Training loss: 0.6872866664778802
Epoch: 65 | Iteration number: [1560/4518] 34% | Training loss: 0.6872789095991697
Epoch: 65 | Iteration number: [1570/4518] 34% | Training loss: 0.6872873306274414
Epoch: 65 | Iteration number: [1580/4518] 34% | Training loss: 0.6872895718752583
Epoch: 65 | Iteration number: [1590/4518] 35% | Training loss: 0.6872947476569962
Epoch: 65 | Iteration number: [1600/4518] 35% | Training loss: 0.6872926822677254
Epoch: 65 | Iteration number: [1610/4518] 35% | Training loss: 0.6872932559584979
Epoch: 65 | Iteration number: [1620/4518] 35% | Training loss: 0.6872948464788037
Epoch: 65 | Iteration number: [1630/4518] 36% | Training loss: 0.6872907645497586
Epoch: 65 | Iteration number: [1640/4518] 36% | Training loss: 0.6872888222336769
Epoch: 65 | Iteration number: [1650/4518] 36% | Training loss: 0.6872804020029126
Epoch: 65 | Iteration number: [1660/4518] 36% | Training loss: 0.6872719133474741
Epoch: 65 | Iteration number: [1670/4518] 36% | Training loss: 0.6872715282582951
Epoch: 65 | Iteration number: [1680/4518] 37% | Training loss: 0.6872728929633186
Epoch: 65 | Iteration number: [1690/4518] 37% | Training loss: 0.687277870241707
Epoch: 65 | Iteration number: [1700/4518] 37% | Training loss: 0.6872708626354442
Epoch: 65 | Iteration number: [1710/4518] 37% | Training loss: 0.6872716830139272
Epoch: 65 | Iteration number: [1720/4518] 38% | Training loss: 0.6872747404977333
Epoch: 65 | Iteration number: [1730/4518] 38% | Training loss: 0.6872742532994706
Epoch: 65 | Iteration number: [1740/4518] 38% | Training loss: 0.6872731263267583
Epoch: 65 | Iteration number: [1750/4518] 38% | Training loss: 0.6872694885049547
Epoch: 65 | Iteration number: [1760/4518] 38% | Training loss: 0.6872624526647004
Epoch: 65 | Iteration number: [1770/4518] 39% | Training loss: 0.6872621345991469
Epoch: 65 | Iteration number: [1780/4518] 39% | Training loss: 0.6872578201334129
Epoch: 65 | Iteration number: [1790/4518] 39% | Training loss: 0.6872554451726668
Epoch: 65 | Iteration number: [1800/4518] 39% | Training loss: 0.6872440940141678
Epoch: 65 | Iteration number: [1810/4518] 40% | Training loss: 0.6872440600592787
Epoch: 65 | Iteration number: [1820/4518] 40% | Training loss: 0.6872406844254378
Epoch: 65 | Iteration number: [1830/4518] 40% | Training loss: 0.6872393260888063
Epoch: 65 | Iteration number: [1840/4518] 40% | Training loss: 0.6872388032791408
Epoch: 65 | Iteration number: [1850/4518] 40% | Training loss: 0.6872389434479378
Epoch: 65 | Iteration number: [1860/4518] 41% | Training loss: 0.687236029839003
Epoch: 65 | Iteration number: [1870/4518] 41% | Training loss: 0.6872307626321355
Epoch: 65 | Iteration number: [1880/4518] 41% | Training loss: 0.6872314807265363
Epoch: 65 | Iteration number: [1890/4518] 41% | Training loss: 0.6872300799876925
Epoch: 65 | Iteration number: [1900/4518] 42% | Training loss: 0.6872250976374275
Epoch: 65 | Iteration number: [1910/4518] 42% | Training loss: 0.6872224691026498
Epoch: 65 | Iteration number: [1920/4518] 42% | Training loss: 0.6872238653091093
Epoch: 65 | Iteration number: [1930/4518] 42% | Training loss: 0.6872140905091182
Epoch: 65 | Iteration number: [1940/4518] 42% | Training loss: 0.6872066562323226
Epoch: 65 | Iteration number: [1950/4518] 43% | Training loss: 0.6872058450870024
Epoch: 65 | Iteration number: [1960/4518] 43% | Training loss: 0.6872033423611096
Epoch: 65 | Iteration number: [1970/4518] 43% | Training loss: 0.6872008315802831
Epoch: 65 | Iteration number: [1980/4518] 43% | Training loss: 0.6871947027818122
Epoch: 65 | Iteration number: [1990/4518] 44% | Training loss: 0.6871859878750902
Epoch: 65 | Iteration number: [2000/4518] 44% | Training loss: 0.6871877163350583
Epoch: 65 | Iteration number: [2010/4518] 44% | Training loss: 0.6871885270621646
Epoch: 65 | Iteration number: [2020/4518] 44% | Training loss: 0.6871833499410365
Epoch: 65 | Iteration number: [2030/4518] 44% | Training loss: 0.6871781447544474
Epoch: 65 | Iteration number: [2040/4518] 45% | Training loss: 0.6871748502347984
Epoch: 65 | Iteration number: [2050/4518] 45% | Training loss: 0.6871783688300993
Epoch: 65 | Iteration number: [2060/4518] 45% | Training loss: 0.6871733535551331
Epoch: 65 | Iteration number: [2070/4518] 45% | Training loss: 0.6871705242689105
Epoch: 65 | Iteration number: [2080/4518] 46% | Training loss: 0.6871687487627451
Epoch: 65 | Iteration number: [2090/4518] 46% | Training loss: 0.6871674010628148
Epoch: 65 | Iteration number: [2100/4518] 46% | Training loss: 0.6871767653737749
Epoch: 65 | Iteration number: [2110/4518] 46% | Training loss: 0.6871696228664633
Epoch: 65 | Iteration number: [2120/4518] 46% | Training loss: 0.6871707444483379
Epoch: 65 | Iteration number: [2130/4518] 47% | Training loss: 0.687167339397708
Epoch: 65 | Iteration number: [2140/4518] 47% | Training loss: 0.6871610320338579
Epoch: 65 | Iteration number: [2150/4518] 47% | Training loss: 0.6871573523310728
Epoch: 65 | Iteration number: [2160/4518] 47% | Training loss: 0.6871597876703298
Epoch: 65 | Iteration number: [2170/4518] 48% | Training loss: 0.687149985045332
Epoch: 65 | Iteration number: [2180/4518] 48% | Training loss: 0.6871542364905734
Epoch: 65 | Iteration number: [2190/4518] 48% | Training loss: 0.6871515270509676
Epoch: 65 | Iteration number: [2200/4518] 48% | Training loss: 0.6871467540209943
Epoch: 65 | Iteration number: [2210/4518] 48% | Training loss: 0.6871496970027821
Epoch: 65 | Iteration number: [2220/4518] 49% | Training loss: 0.6871480799741573
Epoch: 65 | Iteration number: [2230/4518] 49% | Training loss: 0.6871495252232915
Epoch: 65 | Iteration number: [2240/4518] 49% | Training loss: 0.6871462200369154
Epoch: 65 | Iteration number: [2250/4518] 49% | Training loss: 0.6871463482379914
Epoch: 65 | Iteration number: [2260/4518] 50% | Training loss: 0.6871392502457695
Epoch: 65 | Iteration number: [2270/4518] 50% | Training loss: 0.6871394821988328
Epoch: 65 | Iteration number: [2280/4518] 50% | Training loss: 0.6871341444421233
Epoch: 65 | Iteration number: [2290/4518] 50% | Training loss: 0.6871332257855928
Epoch: 65 | Iteration number: [2300/4518] 50% | Training loss: 0.6871300301603649
Epoch: 65 | Iteration number: [2310/4518] 51% | Training loss: 0.6871232656689433
Epoch: 65 | Iteration number: [2320/4518] 51% | Training loss: 0.6871217881811076
Epoch: 65 | Iteration number: [2330/4518] 51% | Training loss: 0.6871199625244468
Epoch: 65 | Iteration number: [2340/4518] 51% | Training loss: 0.6871246979532079
Epoch: 65 | Iteration number: [2350/4518] 52% | Training loss: 0.6871227225344232
Epoch: 65 | Iteration number: [2360/4518] 52% | Training loss: 0.68711715375973
Epoch: 65 | Iteration number: [2370/4518] 52% | Training loss: 0.6871146462134671
Epoch: 65 | Iteration number: [2380/4518] 52% | Training loss: 0.6871128615962357
Epoch: 65 | Iteration number: [2390/4518] 52% | Training loss: 0.6871096873383143
Epoch: 65 | Iteration number: [2400/4518] 53% | Training loss: 0.687106771916151
Epoch: 65 | Iteration number: [2410/4518] 53% | Training loss: 0.6871091281230024
Epoch: 65 | Iteration number: [2420/4518] 53% | Training loss: 0.6871112802550813
Epoch: 65 | Iteration number: [2430/4518] 53% | Training loss: 0.6871084643980112
Epoch: 65 | Iteration number: [2440/4518] 54% | Training loss: 0.6871076370848984
Epoch: 65 | Iteration number: [2450/4518] 54% | Training loss: 0.6871072843610024
Epoch: 65 | Iteration number: [2460/4518] 54% | Training loss: 0.6871081062206408
Epoch: 65 | Iteration number: [2470/4518] 54% | Training loss: 0.6870994536741543
Epoch: 65 | Iteration number: [2480/4518] 54% | Training loss: 0.6870955824611649
Epoch: 65 | Iteration number: [2490/4518] 55% | Training loss: 0.6870950946846162
Epoch: 65 | Iteration number: [2500/4518] 55% | Training loss: 0.6870916649103165
Epoch: 65 | Iteration number: [2510/4518] 55% | Training loss: 0.687085002921967
Epoch: 65 | Iteration number: [2520/4518] 55% | Training loss: 0.6870838754706913
Epoch: 65 | Iteration number: [2530/4518] 55% | Training loss: 0.6870785556527466
Epoch: 65 | Iteration number: [2540/4518] 56% | Training loss: 0.6870807300167759
Epoch: 65 | Iteration number: [2550/4518] 56% | Training loss: 0.6870760313436097
Epoch: 65 | Iteration number: [2560/4518] 56% | Training loss: 0.6870798491640017
Epoch: 65 | Iteration number: [2570/4518] 56% | Training loss: 0.6870794947973021
Epoch: 65 | Iteration number: [2580/4518] 57% | Training loss: 0.6870860896138258
Epoch: 65 | Iteration number: [2590/4518] 57% | Training loss: 0.6870837785562494
Epoch: 65 | Iteration number: [2600/4518] 57% | Training loss: 0.6870817272938214
Epoch: 65 | Iteration number: [2610/4518] 57% | Training loss: 0.6870837337440915
Epoch: 65 | Iteration number: [2620/4518] 57% | Training loss: 0.6870829617249147
Epoch: 65 | Iteration number: [2630/4518] 58% | Training loss: 0.6870818903690962
Epoch: 65 | Iteration number: [2640/4518] 58% | Training loss: 0.6870826589564483
Epoch: 65 | Iteration number: [2650/4518] 58% | Training loss: 0.6870816328165666
Epoch: 65 | Iteration number: [2660/4518] 58% | Training loss: 0.6870775119478542
Epoch: 65 | Iteration number: [2670/4518] 59% | Training loss: 0.687082064821479
Epoch: 65 | Iteration number: [2680/4518] 59% | Training loss: 0.6870807673281698
Epoch: 65 | Iteration number: [2690/4518] 59% | Training loss: 0.6870751495254971
Epoch: 65 | Iteration number: [2700/4518] 59% | Training loss: 0.6870736854164688
Epoch: 65 | Iteration number: [2710/4518] 59% | Training loss: 0.6870727169777634
Epoch: 65 | Iteration number: [2720/4518] 60% | Training loss: 0.6870694162433638
Epoch: 65 | Iteration number: [2730/4518] 60% | Training loss: 0.6870692594365759
Epoch: 65 | Iteration number: [2740/4518] 60% | Training loss: 0.6870687154740313
Epoch: 65 | Iteration number: [2750/4518] 60% | Training loss: 0.687068519635634
Epoch: 65 | Iteration number: [2760/4518] 61% | Training loss: 0.6870668000501136
Epoch: 65 | Iteration number: [2770/4518] 61% | Training loss: 0.6870648364082571
Epoch: 65 | Iteration number: [2780/4518] 61% | Training loss: 0.687068084010975
Epoch: 65 | Iteration number: [2790/4518] 61% | Training loss: 0.6870679768610172
Epoch: 65 | Iteration number: [2800/4518] 61% | Training loss: 0.6870715036562511
Epoch: 65 | Iteration number: [2810/4518] 62% | Training loss: 0.6870720460321555
Epoch: 65 | Iteration number: [2820/4518] 62% | Training loss: 0.6870749305960134
Epoch: 65 | Iteration number: [2830/4518] 62% | Training loss: 0.6870742676746718
Epoch: 65 | Iteration number: [2840/4518] 62% | Training loss: 0.6870732397470676
Epoch: 65 | Iteration number: [2850/4518] 63% | Training loss: 0.687073884700474
Epoch: 65 | Iteration number: [2860/4518] 63% | Training loss: 0.6870726397404304
Epoch: 65 | Iteration number: [2870/4518] 63% | Training loss: 0.6870716142322129
Epoch: 65 | Iteration number: [2880/4518] 63% | Training loss: 0.6870703965218531
Epoch: 65 | Iteration number: [2890/4518] 63% | Training loss: 0.6870641140789309
Epoch: 65 | Iteration number: [2900/4518] 64% | Training loss: 0.6870578041158873
Epoch: 65 | Iteration number: [2910/4518] 64% | Training loss: 0.6870583994077243
Epoch: 65 | Iteration number: [2920/4518] 64% | Training loss: 0.687058079344769
Epoch: 65 | Iteration number: [2930/4518] 64% | Training loss: 0.6870576296650102
Epoch: 65 | Iteration number: [2940/4518] 65% | Training loss: 0.6870560738707886
Epoch: 65 | Iteration number: [2950/4518] 65% | Training loss: 0.6870515850034811
Epoch: 65 | Iteration number: [2960/4518] 65% | Training loss: 0.6870516627221495
Epoch: 65 | Iteration number: [2970/4518] 65% | Training loss: 0.6870531659134309
Epoch: 65 | Iteration number: [2980/4518] 65% | Training loss: 0.6870482408960393
Epoch: 65 | Iteration number: [2990/4518] 66% | Training loss: 0.6870472330911502
Epoch: 65 | Iteration number: [3000/4518] 66% | Training loss: 0.6870461499889692
Epoch: 65 | Iteration number: [3010/4518] 66% | Training loss: 0.687046604200059
Epoch: 65 | Iteration number: [3020/4518] 66% | Training loss: 0.6870431919958417
Epoch: 65 | Iteration number: [3030/4518] 67% | Training loss: 0.6870415476682556
Epoch: 65 | Iteration number: [3040/4518] 67% | Training loss: 0.6870415076613426
Epoch: 65 | Iteration number: [3050/4518] 67% | Training loss: 0.6870471562518448
Epoch: 65 | Iteration number: [3060/4518] 67% | Training loss: 0.6870466464680005
Epoch: 65 | Iteration number: [3070/4518] 67% | Training loss: 0.6870445376692843
Epoch: 65 | Iteration number: [3080/4518] 68% | Training loss: 0.6870407652932328
Epoch: 65 | Iteration number: [3090/4518] 68% | Training loss: 0.6870424149877431
Epoch: 65 | Iteration number: [3100/4518] 68% | Training loss: 0.6870380280094762
Epoch: 65 | Iteration number: [3110/4518] 68% | Training loss: 0.6870336227286666
Epoch: 65 | Iteration number: [3120/4518] 69% | Training loss: 0.6870332114780561
Epoch: 65 | Iteration number: [3130/4518] 69% | Training loss: 0.6870353839458369
Epoch: 65 | Iteration number: [3140/4518] 69% | Training loss: 0.6870322745696754
Epoch: 65 | Iteration number: [3150/4518] 69% | Training loss: 0.6870336096816593
Epoch: 65 | Iteration number: [3160/4518] 69% | Training loss: 0.6870342787873895
Epoch: 65 | Iteration number: [3170/4518] 70% | Training loss: 0.6870363654586419
Epoch: 65 | Iteration number: [3180/4518] 70% | Training loss: 0.6870349759013398
Epoch: 65 | Iteration number: [3190/4518] 70% | Training loss: 0.6870342400567285
Epoch: 65 | Iteration number: [3200/4518] 70% | Training loss: 0.6870350884832441
Epoch: 65 | Iteration number: [3210/4518] 71% | Training loss: 0.6870326560977092
Epoch: 65 | Iteration number: [3220/4518] 71% | Training loss: 0.687034382249998
Epoch: 65 | Iteration number: [3230/4518] 71% | Training loss: 0.6870347264381385
Epoch: 65 | Iteration number: [3240/4518] 71% | Training loss: 0.6870311349998286
Epoch: 65 | Iteration number: [3250/4518] 71% | Training loss: 0.6870276082662435
Epoch: 65 | Iteration number: [3260/4518] 72% | Training loss: 0.6870288850339644
Epoch: 65 | Iteration number: [3270/4518] 72% | Training loss: 0.6870315851056977
Epoch: 65 | Iteration number: [3280/4518] 72% | Training loss: 0.6870327386732509
Epoch: 65 | Iteration number: [3290/4518] 72% | Training loss: 0.6870330788806579
Epoch: 65 | Iteration number: [3300/4518] 73% | Training loss: 0.6870284640608412
Epoch: 65 | Iteration number: [3310/4518] 73% | Training loss: 0.6870244390294631
Epoch: 65 | Iteration number: [3320/4518] 73% | Training loss: 0.6870220002460192
Epoch: 65 | Iteration number: [3330/4518] 73% | Training loss: 0.6870213913487958
Epoch: 65 | Iteration number: [3340/4518] 73% | Training loss: 0.6870186036396884
Epoch: 65 | Iteration number: [3350/4518] 74% | Training loss: 0.6870162112499351
Epoch: 65 | Iteration number: [3360/4518] 74% | Training loss: 0.687017594472993
Epoch: 65 | Iteration number: [3370/4518] 74% | Training loss: 0.6870139530044634
Epoch: 65 | Iteration number: [3380/4518] 74% | Training loss: 0.6870133097707872
Epoch: 65 | Iteration number: [3390/4518] 75% | Training loss: 0.687012072843788
Epoch: 65 | Iteration number: [3400/4518] 75% | Training loss: 0.6870086302301462
Epoch: 65 | Iteration number: [3410/4518] 75% | Training loss: 0.6870084457907858
Epoch: 65 | Iteration number: [3420/4518] 75% | Training loss: 0.6870095525045841
Epoch: 65 | Iteration number: [3430/4518] 75% | Training loss: 0.6870096791242372
Epoch: 65 | Iteration number: [3440/4518] 76% | Training loss: 0.6870080462721891
Epoch: 65 | Iteration number: [3450/4518] 76% | Training loss: 0.6870055286435114
Epoch: 65 | Iteration number: [3460/4518] 76% | Training loss: 0.6870022576323823
Epoch: 65 | Iteration number: [3470/4518] 76% | Training loss: 0.6870024883266141
Epoch: 65 | Iteration number: [3480/4518] 77% | Training loss: 0.6870012689938491
Epoch: 65 | Iteration number: [3490/4518] 77% | Training loss: 0.6870020861953582
Epoch: 65 | Iteration number: [3500/4518] 77% | Training loss: 0.6870015253850392
Epoch: 65 | Iteration number: [3510/4518] 77% | Training loss: 0.6870050093217454
Epoch: 65 | Iteration number: [3520/4518] 77% | Training loss: 0.6870039821856401
Epoch: 65 | Iteration number: [3530/4518] 78% | Training loss: 0.6870009689087908
Epoch: 65 | Iteration number: [3540/4518] 78% | Training loss: 0.686998796294638
Epoch: 65 | Iteration number: [3550/4518] 78% | Training loss: 0.6869985310124679
Epoch: 65 | Iteration number: [3560/4518] 78% | Training loss: 0.6869951401868563
Epoch: 65 | Iteration number: [3570/4518] 79% | Training loss: 0.6869957499310416
Epoch: 65 | Iteration number: [3580/4518] 79% | Training loss: 0.6869923012716144
Epoch: 65 | Iteration number: [3590/4518] 79% | Training loss: 0.6869973315003854
Epoch: 65 | Iteration number: [3600/4518] 79% | Training loss: 0.6869982984993193
Epoch: 65 | Iteration number: [3610/4518] 79% | Training loss: 0.6869984638823037
Epoch: 65 | Iteration number: [3620/4518] 80% | Training loss: 0.6869988042511334
Epoch: 65 | Iteration number: [3630/4518] 80% | Training loss: 0.6869952829416133
Epoch: 65 | Iteration number: [3640/4518] 80% | Training loss: 0.6869951334137183
Epoch: 65 | Iteration number: [3650/4518] 80% | Training loss: 0.6869939899934481
Epoch: 65 | Iteration number: [3660/4518] 81% | Training loss: 0.6869940745700253
Epoch: 65 | Iteration number: [3670/4518] 81% | Training loss: 0.6869932273915418
Epoch: 65 | Iteration number: [3680/4518] 81% | Training loss: 0.6869945897194354
Epoch: 65 | Iteration number: [3690/4518] 81% | Training loss: 0.6869968228385377
Epoch: 65 | Iteration number: [3700/4518] 81% | Training loss: 0.6869972300690573
Epoch: 65 | Iteration number: [3710/4518] 82% | Training loss: 0.6869969546312913
Epoch: 65 | Iteration number: [3720/4518] 82% | Training loss: 0.6869961844496829
Epoch: 65 | Iteration number: [3730/4518] 82% | Training loss: 0.6869963994933836
Epoch: 65 | Iteration number: [3740/4518] 82% | Training loss: 0.6869979199559931
Epoch: 65 | Iteration number: [3750/4518] 83% | Training loss: 0.6869967273712159
Epoch: 65 | Iteration number: [3760/4518] 83% | Training loss: 0.6869946368989792
Epoch: 65 | Iteration number: [3770/4518] 83% | Training loss: 0.6869923447740489
Epoch: 65 | Iteration number: [3780/4518] 83% | Training loss: 0.6869924363635835
Epoch: 65 | Iteration number: [3790/4518] 83% | Training loss: 0.6869916619285744
Epoch: 65 | Iteration number: [3800/4518] 84% | Training loss: 0.6869909571817047
Epoch: 65 | Iteration number: [3810/4518] 84% | Training loss: 0.6869919254867424
Epoch: 65 | Iteration number: [3820/4518] 84% | Training loss: 0.6869936713373473
Epoch: 65 | Iteration number: [3830/4518] 84% | Training loss: 0.6869947205635648
Epoch: 65 | Iteration number: [3840/4518] 84% | Training loss: 0.686993319246297
Epoch: 65 | Iteration number: [3850/4518] 85% | Training loss: 0.6869907840815458
Epoch: 65 | Iteration number: [3860/4518] 85% | Training loss: 0.6869892747136596
Epoch: 65 | Iteration number: [3870/4518] 85% | Training loss: 0.6869890890226191
Epoch: 65 | Iteration number: [3880/4518] 85% | Training loss: 0.6869883118523765
Epoch: 65 | Iteration number: [3890/4518] 86% | Training loss: 0.6869860527907669
Epoch: 65 | Iteration number: [3900/4518] 86% | Training loss: 0.6869868987187361
Epoch: 65 | Iteration number: [3910/4518] 86% | Training loss: 0.6869887241469624
Epoch: 65 | Iteration number: [3920/4518] 86% | Training loss: 0.6869887809212111
Epoch: 65 | Iteration number: [3930/4518] 86% | Training loss: 0.6869859178557651
Epoch: 65 | Iteration number: [3940/4518] 87% | Training loss: 0.6869854196376607
Epoch: 65 | Iteration number: [3950/4518] 87% | Training loss: 0.6869841681854635
Epoch: 65 | Iteration number: [3960/4518] 87% | Training loss: 0.6869829577026945
Epoch: 65 | Iteration number: [3970/4518] 87% | Training loss: 0.6869844775055758
Epoch: 65 | Iteration number: [3980/4518] 88% | Training loss: 0.6869849941688566
Epoch: 65 | Iteration number: [3990/4518] 88% | Training loss: 0.6869815153735025
Epoch: 65 | Iteration number: [4000/4518] 88% | Training loss: 0.6869786484986544
Epoch: 65 | Iteration number: [4010/4518] 88% | Training loss: 0.6869808227789966
Epoch: 65 | Iteration number: [4020/4518] 88% | Training loss: 0.6869820810669097
Epoch: 65 | Iteration number: [4030/4518] 89% | Training loss: 0.6869833221802345
Epoch: 65 | Iteration number: [4040/4518] 89% | Training loss: 0.686982546820499
Epoch: 65 | Iteration number: [4050/4518] 89% | Training loss: 0.6869824122352365
Epoch: 65 | Iteration number: [4060/4518] 89% | Training loss: 0.686979083929743
Epoch: 65 | Iteration number: [4070/4518] 90% | Training loss: 0.6869793105769801
Epoch: 65 | Iteration number: [4080/4518] 90% | Training loss: 0.6869773579724864
Epoch: 65 | Iteration number: [4090/4518] 90% | Training loss: 0.6869804784400539
Epoch: 65 | Iteration number: [4100/4518] 90% | Training loss: 0.6869773331357212
Epoch: 65 | Iteration number: [4110/4518] 90% | Training loss: 0.6869752973245589
Epoch: 65 | Iteration number: [4120/4518] 91% | Training loss: 0.6869696394621747
Epoch: 65 | Iteration number: [4130/4518] 91% | Training loss: 0.6869685674695069
Epoch: 65 | Iteration number: [4140/4518] 91% | Training loss: 0.6869687585871
Epoch: 65 | Iteration number: [4150/4518] 91% | Training loss: 0.6869678805678724
Epoch: 65 | Iteration number: [4160/4518] 92% | Training loss: 0.6869674492340822
Epoch: 65 | Iteration number: [4170/4518] 92% | Training loss: 0.6869691212829069
Epoch: 65 | Iteration number: [4180/4518] 92% | Training loss: 0.686966757996801
Epoch: 65 | Iteration number: [4190/4518] 92% | Training loss: 0.6869688037044962
Epoch: 65 | Iteration number: [4200/4518] 92% | Training loss: 0.6869680005453882
Epoch: 65 | Iteration number: [4210/4518] 93% | Training loss: 0.6869684031202221
Epoch: 65 | Iteration number: [4220/4518] 93% | Training loss: 0.6869629550742877
Epoch: 65 | Iteration number: [4230/4518] 93% | Training loss: 0.6869628575676722
Epoch: 65 | Iteration number: [4240/4518] 93% | Training loss: 0.6869640086900514
Epoch: 65 | Iteration number: [4250/4518] 94% | Training loss: 0.686965487872853
Epoch: 65 | Iteration number: [4260/4518] 94% | Training loss: 0.6869664433556544
Epoch: 65 | Iteration number: [4270/4518] 94% | Training loss: 0.68696461927137
Epoch: 65 | Iteration number: [4280/4518] 94% | Training loss: 0.6869648590962464
Epoch: 65 | Iteration number: [4290/4518] 94% | Training loss: 0.6869620861568095
Epoch: 65 | Iteration number: [4300/4518] 95% | Training loss: 0.6869591933488846
Epoch: 65 | Iteration number: [4310/4518] 95% | Training loss: 0.6869595872000586
Epoch: 65 | Iteration number: [4320/4518] 95% | Training loss: 0.6869592167850997
Epoch: 65 | Iteration number: [4330/4518] 95% | Training loss: 0.6869594392269919
Epoch: 65 | Iteration number: [4340/4518] 96% | Training loss: 0.686957501733358
Epoch: 65 | Iteration number: [4350/4518] 96% | Training loss: 0.6869577404274337
Epoch: 65 | Iteration number: [4360/4518] 96% | Training loss: 0.686957577540787
Epoch: 65 | Iteration number: [4370/4518] 96% | Training loss: 0.6869576233338982
Epoch: 65 | Iteration number: [4380/4518] 96% | Training loss: 0.6869599132777349
Epoch: 65 | Iteration number: [4390/4518] 97% | Training loss: 0.6869570132811683
Epoch: 65 | Iteration number: [4400/4518] 97% | Training loss: 0.686953886368058
Epoch: 65 | Iteration number: [4410/4518] 97% | Training loss: 0.6869504235769346
Epoch: 65 | Iteration number: [4420/4518] 97% | Training loss: 0.6869528893431927
Epoch: 65 | Iteration number: [4430/4518] 98% | Training loss: 0.6869497290448734
Epoch: 65 | Iteration number: [4440/4518] 98% | Training loss: 0.6869479252679928
Epoch: 65 | Iteration number: [4450/4518] 98% | Training loss: 0.6869480059521922
Epoch: 65 | Iteration number: [4460/4518] 98% | Training loss: 0.686946876500754
Epoch: 65 | Iteration number: [4470/4518] 98% | Training loss: 0.6869472004689893
Epoch: 65 | Iteration number: [4480/4518] 99% | Training loss: 0.686948978608208
Epoch: 65 | Iteration number: [4490/4518] 99% | Training loss: 0.6869506583845695
Epoch: 65 | Iteration number: [4500/4518] 99% | Training loss: 0.6869492338630888
Epoch: 65 | Iteration number: [4510/4518] 99% | Training loss: 0.6869497418535787

 End of epoch: 65 | Train Loss: 0.6867960747652953 | Training Time: 642 

 End of epoch: 65 | Eval Loss: 0.6900820123906038 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/4518] 0% | Training loss: 0.7541884481906891
Epoch: 66 | Iteration number: [20/4518] 0% | Training loss: 0.7203693509101867
Epoch: 66 | Iteration number: [30/4518] 0% | Training loss: 0.7090497076511383
Epoch: 66 | Iteration number: [40/4518] 0% | Training loss: 0.7035169810056686
Epoch: 66 | Iteration number: [50/4518] 1% | Training loss: 0.7001906430721283
Epoch: 66 | Iteration number: [60/4518] 1% | Training loss: 0.6980559070905049
Epoch: 66 | Iteration number: [70/4518] 1% | Training loss: 0.6965000893388476
Epoch: 66 | Iteration number: [80/4518] 1% | Training loss: 0.6952073104679585
Epoch: 66 | Iteration number: [90/4518] 1% | Training loss: 0.6942622522513072
Epoch: 66 | Iteration number: [100/4518] 2% | Training loss: 0.6933812320232391
Epoch: 66 | Iteration number: [110/4518] 2% | Training loss: 0.6927116296508096
Epoch: 66 | Iteration number: [120/4518] 2% | Training loss: 0.6922412092487017
Epoch: 66 | Iteration number: [130/4518] 2% | Training loss: 0.6918710488539476
Epoch: 66 | Iteration number: [140/4518] 3% | Training loss: 0.6915170733417784
Epoch: 66 | Iteration number: [150/4518] 3% | Training loss: 0.6911492768923442
Epoch: 66 | Iteration number: [160/4518] 3% | Training loss: 0.6908185232430697
Epoch: 66 | Iteration number: [170/4518] 3% | Training loss: 0.6905399687149946
Epoch: 66 | Iteration number: [180/4518] 3% | Training loss: 0.6903420663542218
Epoch: 66 | Iteration number: [190/4518] 4% | Training loss: 0.6901679051549812
Epoch: 66 | Iteration number: [200/4518] 4% | Training loss: 0.6899648600816727
Epoch: 66 | Iteration number: [210/4518] 4% | Training loss: 0.6898350187710354
Epoch: 66 | Iteration number: [220/4518] 4% | Training loss: 0.689689854871143
Epoch: 66 | Iteration number: [230/4518] 5% | Training loss: 0.6895501800205397
Epoch: 66 | Iteration number: [240/4518] 5% | Training loss: 0.689392105738322
Epoch: 66 | Iteration number: [250/4518] 5% | Training loss: 0.6893069705963135
Epoch: 66 | Iteration number: [260/4518] 5% | Training loss: 0.6892222787325198
Epoch: 66 | Iteration number: [270/4518] 5% | Training loss: 0.6891390105088552
Epoch: 66 | Iteration number: [280/4518] 6% | Training loss: 0.6890237146190235
Epoch: 66 | Iteration number: [290/4518] 6% | Training loss: 0.6889416394562556
Epoch: 66 | Iteration number: [300/4518] 6% | Training loss: 0.6888668658336004
Epoch: 66 | Iteration number: [310/4518] 6% | Training loss: 0.6887760362317485
Epoch: 66 | Iteration number: [320/4518] 7% | Training loss: 0.6886655125766993
Epoch: 66 | Iteration number: [330/4518] 7% | Training loss: 0.6885968844095866
Epoch: 66 | Iteration number: [340/4518] 7% | Training loss: 0.6885506989324794
Epoch: 66 | Iteration number: [350/4518] 7% | Training loss: 0.6885176190308162
Epoch: 66 | Iteration number: [360/4518] 7% | Training loss: 0.6884663356675043
Epoch: 66 | Iteration number: [370/4518] 8% | Training loss: 0.6883910557708225
Epoch: 66 | Iteration number: [380/4518] 8% | Training loss: 0.6883587087455548
Epoch: 66 | Iteration number: [390/4518] 8% | Training loss: 0.6883326911009275
Epoch: 66 | Iteration number: [400/4518] 8% | Training loss: 0.6883012460172176
Epoch: 66 | Iteration number: [410/4518] 9% | Training loss: 0.6882841733897604
Epoch: 66 | Iteration number: [420/4518] 9% | Training loss: 0.6882599541119166
Epoch: 66 | Iteration number: [430/4518] 9% | Training loss: 0.6882310030072234
Epoch: 66 | Iteration number: [440/4518] 9% | Training loss: 0.6881898629394445
Epoch: 66 | Iteration number: [450/4518] 9% | Training loss: 0.6881535952621036
Epoch: 66 | Iteration number: [460/4518] 10% | Training loss: 0.688117579014405
Epoch: 66 | Iteration number: [470/4518] 10% | Training loss: 0.6880845479508664
Epoch: 66 | Iteration number: [480/4518] 10% | Training loss: 0.688084552437067
Epoch: 66 | Iteration number: [490/4518] 10% | Training loss: 0.6880351573837047
Epoch: 66 | Iteration number: [500/4518] 11% | Training loss: 0.6880083657503128
Epoch: 66 | Iteration number: [510/4518] 11% | Training loss: 0.6879629623656179
Epoch: 66 | Iteration number: [520/4518] 11% | Training loss: 0.687920592381404
Epoch: 66 | Iteration number: [530/4518] 11% | Training loss: 0.6879030914801472
Epoch: 66 | Iteration number: [540/4518] 11% | Training loss: 0.6878721677594715
Epoch: 66 | Iteration number: [550/4518] 12% | Training loss: 0.6878366035764868
Epoch: 66 | Iteration number: [560/4518] 12% | Training loss: 0.6878116721553462
Epoch: 66 | Iteration number: [570/4518] 12% | Training loss: 0.6878012955188751
Epoch: 66 | Iteration number: [580/4518] 12% | Training loss: 0.6877943046134094
Epoch: 66 | Iteration number: [590/4518] 13% | Training loss: 0.6877831717668954
Epoch: 66 | Iteration number: [600/4518] 13% | Training loss: 0.687756032248338
Epoch: 66 | Iteration number: [610/4518] 13% | Training loss: 0.6877299055701397
Epoch: 66 | Iteration number: [620/4518] 13% | Training loss: 0.6877165514615274
Epoch: 66 | Iteration number: [630/4518] 13% | Training loss: 0.6876894603645991
Epoch: 66 | Iteration number: [640/4518] 14% | Training loss: 0.6876852977089584
Epoch: 66 | Iteration number: [650/4518] 14% | Training loss: 0.6876595741051894
Epoch: 66 | Iteration number: [660/4518] 14% | Training loss: 0.6876432976036361
Epoch: 66 | Iteration number: [670/4518] 14% | Training loss: 0.6876207026083078
Epoch: 66 | Iteration number: [680/4518] 15% | Training loss: 0.6876093963489813
Epoch: 66 | Iteration number: [690/4518] 15% | Training loss: 0.6875516685022824
Epoch: 66 | Iteration number: [700/4518] 15% | Training loss: 0.687532554268837
Epoch: 66 | Iteration number: [710/4518] 15% | Training loss: 0.6875397541153598
Epoch: 66 | Iteration number: [720/4518] 15% | Training loss: 0.68753861784935
Epoch: 66 | Iteration number: [730/4518] 16% | Training loss: 0.6875278192023708
Epoch: 66 | Iteration number: [740/4518] 16% | Training loss: 0.6875165170914418
Epoch: 66 | Iteration number: [750/4518] 16% | Training loss: 0.6875098141829172
Epoch: 66 | Iteration number: [760/4518] 16% | Training loss: 0.6875035015375991
Epoch: 66 | Iteration number: [770/4518] 17% | Training loss: 0.6874892893549683
Epoch: 66 | Iteration number: [780/4518] 17% | Training loss: 0.6874897227837489
Epoch: 66 | Iteration number: [790/4518] 17% | Training loss: 0.6874863669087615
Epoch: 66 | Iteration number: [800/4518] 17% | Training loss: 0.687477031648159
Epoch: 66 | Iteration number: [810/4518] 17% | Training loss: 0.6874700090031565
Epoch: 66 | Iteration number: [820/4518] 18% | Training loss: 0.6874541674445315
Epoch: 66 | Iteration number: [830/4518] 18% | Training loss: 0.6874447694743973
Epoch: 66 | Iteration number: [840/4518] 18% | Training loss: 0.6874412162672906
Epoch: 66 | Iteration number: [850/4518] 18% | Training loss: 0.6874368420769187
Epoch: 66 | Iteration number: [860/4518] 19% | Training loss: 0.6874405148417451
Epoch: 66 | Iteration number: [870/4518] 19% | Training loss: 0.6874361584241363
Epoch: 66 | Iteration number: [880/4518] 19% | Training loss: 0.6874344686892899
Epoch: 66 | Iteration number: [890/4518] 19% | Training loss: 0.6874233653706111
Epoch: 66 | Iteration number: [900/4518] 19% | Training loss: 0.687421887119611
Epoch: 66 | Iteration number: [910/4518] 20% | Training loss: 0.6874184460430355
Epoch: 66 | Iteration number: [920/4518] 20% | Training loss: 0.6874074424738469
Epoch: 66 | Iteration number: [930/4518] 20% | Training loss: 0.6873980978483795
Epoch: 66 | Iteration number: [940/4518] 20% | Training loss: 0.6873915839068433
Epoch: 66 | Iteration number: [950/4518] 21% | Training loss: 0.6873680681303928
Epoch: 66 | Iteration number: [960/4518] 21% | Training loss: 0.687363108061254
Epoch: 66 | Iteration number: [970/4518] 21% | Training loss: 0.6873552786935236
Epoch: 66 | Iteration number: [980/4518] 21% | Training loss: 0.6873340161479249
Epoch: 66 | Iteration number: [990/4518] 21% | Training loss: 0.6873226712448428
Epoch: 66 | Iteration number: [1000/4518] 22% | Training loss: 0.6873313313722611
Epoch: 66 | Iteration number: [1010/4518] 22% | Training loss: 0.6873129510643459
Epoch: 66 | Iteration number: [1020/4518] 22% | Training loss: 0.6873124304939718
Epoch: 66 | Iteration number: [1030/4518] 22% | Training loss: 0.6872976155535688
Epoch: 66 | Iteration number: [1040/4518] 23% | Training loss: 0.6872995010935343
Epoch: 66 | Iteration number: [1050/4518] 23% | Training loss: 0.6872946702866327
Epoch: 66 | Iteration number: [1060/4518] 23% | Training loss: 0.6872872101810743
Epoch: 66 | Iteration number: [1070/4518] 23% | Training loss: 0.6872817548635964
Epoch: 66 | Iteration number: [1080/4518] 23% | Training loss: 0.6872719625631968
Epoch: 66 | Iteration number: [1090/4518] 24% | Training loss: 0.687265173065553
Epoch: 66 | Iteration number: [1100/4518] 24% | Training loss: 0.6872538919882341
Epoch: 66 | Iteration number: [1110/4518] 24% | Training loss: 0.687252065136626
Epoch: 66 | Iteration number: [1120/4518] 24% | Training loss: 0.687248274151768
Epoch: 66 | Iteration number: [1130/4518] 25% | Training loss: 0.6872298191606471
Epoch: 66 | Iteration number: [1140/4518] 25% | Training loss: 0.6872247128110183
Epoch: 66 | Iteration number: [1150/4518] 25% | Training loss: 0.6872206806099933
Epoch: 66 | Iteration number: [1160/4518] 25% | Training loss: 0.6872179306786635
Epoch: 66 | Iteration number: [1170/4518] 25% | Training loss: 0.687212947749684
Epoch: 66 | Iteration number: [1180/4518] 26% | Training loss: 0.6872042032116551
Epoch: 66 | Iteration number: [1190/4518] 26% | Training loss: 0.6872055897191793
Epoch: 66 | Iteration number: [1200/4518] 26% | Training loss: 0.6872052526970704
Epoch: 66 | Iteration number: [1210/4518] 26% | Training loss: 0.6872191026683682
Epoch: 66 | Iteration number: [1220/4518] 27% | Training loss: 0.6872191158963031
Epoch: 66 | Iteration number: [1230/4518] 27% | Training loss: 0.6872287570461025
Epoch: 66 | Iteration number: [1240/4518] 27% | Training loss: 0.6872340645520918
Epoch: 66 | Iteration number: [1250/4518] 27% | Training loss: 0.6872337332248688
Epoch: 66 | Iteration number: [1260/4518] 27% | Training loss: 0.6872302035490672
Epoch: 66 | Iteration number: [1270/4518] 28% | Training loss: 0.6872291929609193
Epoch: 66 | Iteration number: [1280/4518] 28% | Training loss: 0.6872354618273675
Epoch: 66 | Iteration number: [1290/4518] 28% | Training loss: 0.6872368007667304
Epoch: 66 | Iteration number: [1300/4518] 28% | Training loss: 0.6872334350072421
Epoch: 66 | Iteration number: [1310/4518] 28% | Training loss: 0.6872355416075874
Epoch: 66 | Iteration number: [1320/4518] 29% | Training loss: 0.687229782704151
Epoch: 66 | Iteration number: [1330/4518] 29% | Training loss: 0.6872284022488988
Epoch: 66 | Iteration number: [1340/4518] 29% | Training loss: 0.687228236803368
Epoch: 66 | Iteration number: [1350/4518] 29% | Training loss: 0.6872193362536254
Epoch: 66 | Iteration number: [1360/4518] 30% | Training loss: 0.6872209193513674
Epoch: 66 | Iteration number: [1370/4518] 30% | Training loss: 0.6872174791175953
Epoch: 66 | Iteration number: [1380/4518] 30% | Training loss: 0.6872110847113789
Epoch: 66 | Iteration number: [1390/4518] 30% | Training loss: 0.6871978161146315
Epoch: 66 | Iteration number: [1400/4518] 30% | Training loss: 0.6871983635851315
Epoch: 66 | Iteration number: [1410/4518] 31% | Training loss: 0.6871842413506609
Epoch: 66 | Iteration number: [1420/4518] 31% | Training loss: 0.687190451084728
Epoch: 66 | Iteration number: [1430/4518] 31% | Training loss: 0.6871851384222925
Epoch: 66 | Iteration number: [1440/4518] 31% | Training loss: 0.6871787497980727
Epoch: 66 | Iteration number: [1450/4518] 32% | Training loss: 0.6871802135582628
Epoch: 66 | Iteration number: [1460/4518] 32% | Training loss: 0.6871827277826936
Epoch: 66 | Iteration number: [1470/4518] 32% | Training loss: 0.6871764843561211
Epoch: 66 | Iteration number: [1480/4518] 32% | Training loss: 0.6871680896024446
Epoch: 66 | Iteration number: [1490/4518] 32% | Training loss: 0.6871686992629262
Epoch: 66 | Iteration number: [1500/4518] 33% | Training loss: 0.6871617862780889
Epoch: 66 | Iteration number: [1510/4518] 33% | Training loss: 0.6871590227480756
Epoch: 66 | Iteration number: [1520/4518] 33% | Training loss: 0.6871664112335757
Epoch: 66 | Iteration number: [1530/4518] 33% | Training loss: 0.6871596451288734
Epoch: 66 | Iteration number: [1540/4518] 34% | Training loss: 0.6871548555501096
Epoch: 66 | Iteration number: [1550/4518] 34% | Training loss: 0.6871522741548477
Epoch: 66 | Iteration number: [1560/4518] 34% | Training loss: 0.6871418531124408
Epoch: 66 | Iteration number: [1570/4518] 34% | Training loss: 0.6871377459756888
Epoch: 66 | Iteration number: [1580/4518] 34% | Training loss: 0.6871429535407054
Epoch: 66 | Iteration number: [1590/4518] 35% | Training loss: 0.6871411643688033
Epoch: 66 | Iteration number: [1600/4518] 35% | Training loss: 0.687137163951993
Epoch: 66 | Iteration number: [1610/4518] 35% | Training loss: 0.6871368654026008
Epoch: 66 | Iteration number: [1620/4518] 35% | Training loss: 0.6871309104525013
Epoch: 66 | Iteration number: [1630/4518] 36% | Training loss: 0.6871336783002491
Epoch: 66 | Iteration number: [1640/4518] 36% | Training loss: 0.6871375128990267
Epoch: 66 | Iteration number: [1650/4518] 36% | Training loss: 0.6871346193010157
Epoch: 66 | Iteration number: [1660/4518] 36% | Training loss: 0.6871367072125515
Epoch: 66 | Iteration number: [1670/4518] 36% | Training loss: 0.6871315668086092
Epoch: 66 | Iteration number: [1680/4518] 37% | Training loss: 0.6871298762304442
Epoch: 66 | Iteration number: [1690/4518] 37% | Training loss: 0.6871237033217616
Epoch: 66 | Iteration number: [1700/4518] 37% | Training loss: 0.6871186210478053
Epoch: 66 | Iteration number: [1710/4518] 37% | Training loss: 0.6871175236172147
Epoch: 66 | Iteration number: [1720/4518] 38% | Training loss: 0.687122701039148
Epoch: 66 | Iteration number: [1730/4518] 38% | Training loss: 0.6871174427815255
Epoch: 66 | Iteration number: [1740/4518] 38% | Training loss: 0.6871223224648114
Epoch: 66 | Iteration number: [1750/4518] 38% | Training loss: 0.6871200890541077
Epoch: 66 | Iteration number: [1760/4518] 38% | Training loss: 0.6871187601915815
Epoch: 66 | Iteration number: [1770/4518] 39% | Training loss: 0.6871189281091852
Epoch: 66 | Iteration number: [1780/4518] 39% | Training loss: 0.687119209063187
Epoch: 66 | Iteration number: [1790/4518] 39% | Training loss: 0.6871228960972259
Epoch: 66 | Iteration number: [1800/4518] 39% | Training loss: 0.687120227350129
Epoch: 66 | Iteration number: [1810/4518] 40% | Training loss: 0.6871231003360854
Epoch: 66 | Iteration number: [1820/4518] 40% | Training loss: 0.6871225563379434
Epoch: 66 | Iteration number: [1830/4518] 40% | Training loss: 0.6871246354827464
Epoch: 66 | Iteration number: [1840/4518] 40% | Training loss: 0.6871204730285251
Epoch: 66 | Iteration number: [1850/4518] 40% | Training loss: 0.6871207406714156
Epoch: 66 | Iteration number: [1860/4518] 41% | Training loss: 0.6871187639172359
Epoch: 66 | Iteration number: [1870/4518] 41% | Training loss: 0.6871201850194982
Epoch: 66 | Iteration number: [1880/4518] 41% | Training loss: 0.687116224968687
Epoch: 66 | Iteration number: [1890/4518] 41% | Training loss: 0.6871139611201311
Epoch: 66 | Iteration number: [1900/4518] 42% | Training loss: 0.687115301709426
Epoch: 66 | Iteration number: [1910/4518] 42% | Training loss: 0.6871123382246307
Epoch: 66 | Iteration number: [1920/4518] 42% | Training loss: 0.6871119142820438
Epoch: 66 | Iteration number: [1930/4518] 42% | Training loss: 0.6871144108512859
Epoch: 66 | Iteration number: [1940/4518] 42% | Training loss: 0.6871154641060485
Epoch: 66 | Iteration number: [1950/4518] 43% | Training loss: 0.6871109797710028
Epoch: 66 | Iteration number: [1960/4518] 43% | Training loss: 0.6871087573316632
Epoch: 66 | Iteration number: [1970/4518] 43% | Training loss: 0.6871081944952157
Epoch: 66 | Iteration number: [1980/4518] 43% | Training loss: 0.6871044335943279
Epoch: 66 | Iteration number: [1990/4518] 44% | Training loss: 0.6871042792222009
Epoch: 66 | Iteration number: [2000/4518] 44% | Training loss: 0.6870949083864689
Epoch: 66 | Iteration number: [2010/4518] 44% | Training loss: 0.687097017207549
Epoch: 66 | Iteration number: [2020/4518] 44% | Training loss: 0.6870972451597157
Epoch: 66 | Iteration number: [2030/4518] 44% | Training loss: 0.6870928776381638
Epoch: 66 | Iteration number: [2040/4518] 45% | Training loss: 0.6870949901786505
Epoch: 66 | Iteration number: [2050/4518] 45% | Training loss: 0.687098155923006
Epoch: 66 | Iteration number: [2060/4518] 45% | Training loss: 0.6870980829868502
Epoch: 66 | Iteration number: [2070/4518] 45% | Training loss: 0.6871003471710831
Epoch: 66 | Iteration number: [2080/4518] 46% | Training loss: 0.6871006165559476
Epoch: 66 | Iteration number: [2090/4518] 46% | Training loss: 0.687100718238137
Epoch: 66 | Iteration number: [2100/4518] 46% | Training loss: 0.6870991029342015
Epoch: 66 | Iteration number: [2110/4518] 46% | Training loss: 0.6870894527265811
Epoch: 66 | Iteration number: [2120/4518] 46% | Training loss: 0.6870896855896373
Epoch: 66 | Iteration number: [2130/4518] 47% | Training loss: 0.6870873325307604
Epoch: 66 | Iteration number: [2140/4518] 47% | Training loss: 0.6870926732214812
Epoch: 66 | Iteration number: [2150/4518] 47% | Training loss: 0.68708766920622
Epoch: 66 | Iteration number: [2160/4518] 47% | Training loss: 0.6870903617254009
Epoch: 66 | Iteration number: [2170/4518] 48% | Training loss: 0.6870905401794591
Epoch: 66 | Iteration number: [2180/4518] 48% | Training loss: 0.6870915178312074
Epoch: 66 | Iteration number: [2190/4518] 48% | Training loss: 0.6870889515637263
Epoch: 66 | Iteration number: [2200/4518] 48% | Training loss: 0.6870930254730311
Epoch: 66 | Iteration number: [2210/4518] 48% | Training loss: 0.6870859280161189
Epoch: 66 | Iteration number: [2220/4518] 49% | Training loss: 0.6870875841593957
Epoch: 66 | Iteration number: [2230/4518] 49% | Training loss: 0.6870853845046775
Epoch: 66 | Iteration number: [2240/4518] 49% | Training loss: 0.6870882167081748
Epoch: 66 | Iteration number: [2250/4518] 49% | Training loss: 0.6870892237027486
Epoch: 66 | Iteration number: [2260/4518] 50% | Training loss: 0.6870927599151577
Epoch: 66 | Iteration number: [2270/4518] 50% | Training loss: 0.6870884845172781
Epoch: 66 | Iteration number: [2280/4518] 50% | Training loss: 0.6870937673407689
Epoch: 66 | Iteration number: [2290/4518] 50% | Training loss: 0.6870911826212854
Epoch: 66 | Iteration number: [2300/4518] 50% | Training loss: 0.6870854985454808
Epoch: 66 | Iteration number: [2310/4518] 51% | Training loss: 0.6870827415546814
Epoch: 66 | Iteration number: [2320/4518] 51% | Training loss: 0.6870809468729743
Epoch: 66 | Iteration number: [2330/4518] 51% | Training loss: 0.6870772590197207
Epoch: 66 | Iteration number: [2340/4518] 51% | Training loss: 0.6870737164193749
Epoch: 66 | Iteration number: [2350/4518] 52% | Training loss: 0.6870714373537835
Epoch: 66 | Iteration number: [2360/4518] 52% | Training loss: 0.6870703671190699
Epoch: 66 | Iteration number: [2370/4518] 52% | Training loss: 0.6870726972189634
Epoch: 66 | Iteration number: [2380/4518] 52% | Training loss: 0.6870630084716973
Epoch: 66 | Iteration number: [2390/4518] 52% | Training loss: 0.687063304774432
Epoch: 66 | Iteration number: [2400/4518] 53% | Training loss: 0.6870670352131129
Epoch: 66 | Iteration number: [2410/4518] 53% | Training loss: 0.6870646074847067
Epoch: 66 | Iteration number: [2420/4518] 53% | Training loss: 0.6870662738961621
Epoch: 66 | Iteration number: [2430/4518] 53% | Training loss: 0.6870635975780801
Epoch: 66 | Iteration number: [2440/4518] 54% | Training loss: 0.687064240335441
Epoch: 66 | Iteration number: [2450/4518] 54% | Training loss: 0.6870637229267432
Epoch: 66 | Iteration number: [2460/4518] 54% | Training loss: 0.6870637706382487
Epoch: 66 | Iteration number: [2470/4518] 54% | Training loss: 0.6870597295191606
Epoch: 66 | Iteration number: [2480/4518] 54% | Training loss: 0.6870640545362426
Epoch: 66 | Iteration number: [2490/4518] 55% | Training loss: 0.6870648444656388
Epoch: 66 | Iteration number: [2500/4518] 55% | Training loss: 0.6870633522987366
Epoch: 66 | Iteration number: [2510/4518] 55% | Training loss: 0.6870644350925764
Epoch: 66 | Iteration number: [2520/4518] 55% | Training loss: 0.6870672891064296
Epoch: 66 | Iteration number: [2530/4518] 55% | Training loss: 0.6870650380732043
Epoch: 66 | Iteration number: [2540/4518] 56% | Training loss: 0.6870570650720221
Epoch: 66 | Iteration number: [2550/4518] 56% | Training loss: 0.6870570382417417
Epoch: 66 | Iteration number: [2560/4518] 56% | Training loss: 0.6870555510511622
Epoch: 66 | Iteration number: [2570/4518] 56% | Training loss: 0.6870608585817805
Epoch: 66 | Iteration number: [2580/4518] 57% | Training loss: 0.6870606089747229
Epoch: 66 | Iteration number: [2590/4518] 57% | Training loss: 0.6870588514565501
Epoch: 66 | Iteration number: [2600/4518] 57% | Training loss: 0.6870567968258491
Epoch: 66 | Iteration number: [2610/4518] 57% | Training loss: 0.6870564660350025
Epoch: 66 | Iteration number: [2620/4518] 57% | Training loss: 0.6870546082048926
Epoch: 66 | Iteration number: [2630/4518] 58% | Training loss: 0.6870549643447644
Epoch: 66 | Iteration number: [2640/4518] 58% | Training loss: 0.6870517272163521
Epoch: 66 | Iteration number: [2650/4518] 58% | Training loss: 0.6870527130477834
Epoch: 66 | Iteration number: [2660/4518] 58% | Training loss: 0.687053287903169
Epoch: 66 | Iteration number: [2670/4518] 59% | Training loss: 0.687048941471157
Epoch: 66 | Iteration number: [2680/4518] 59% | Training loss: 0.687047224836563
Epoch: 66 | Iteration number: [2690/4518] 59% | Training loss: 0.687046328308857
Epoch: 66 | Iteration number: [2700/4518] 59% | Training loss: 0.6870452030279018
Epoch: 66 | Iteration number: [2710/4518] 59% | Training loss: 0.6870383334115863
Epoch: 66 | Iteration number: [2720/4518] 60% | Training loss: 0.6870407734504518
Epoch: 66 | Iteration number: [2730/4518] 60% | Training loss: 0.6870401236163828
Epoch: 66 | Iteration number: [2740/4518] 60% | Training loss: 0.68704202364396
Epoch: 66 | Iteration number: [2750/4518] 60% | Training loss: 0.6870436928055503
Epoch: 66 | Iteration number: [2760/4518] 61% | Training loss: 0.6870399611583654
Epoch: 66 | Iteration number: [2770/4518] 61% | Training loss: 0.6870410084939605
Epoch: 66 | Iteration number: [2780/4518] 61% | Training loss: 0.6870399934353588
Epoch: 66 | Iteration number: [2790/4518] 61% | Training loss: 0.6870377416465445
Epoch: 66 | Iteration number: [2800/4518] 61% | Training loss: 0.6870363396831921
Epoch: 66 | Iteration number: [2810/4518] 62% | Training loss: 0.6870359174297374
Epoch: 66 | Iteration number: [2820/4518] 62% | Training loss: 0.6870349201750248
Epoch: 66 | Iteration number: [2830/4518] 62% | Training loss: 0.6870341442920294
Epoch: 66 | Iteration number: [2840/4518] 62% | Training loss: 0.6870304708749475
Epoch: 66 | Iteration number: [2850/4518] 63% | Training loss: 0.6870299468960679
Epoch: 66 | Iteration number: [2860/4518] 63% | Training loss: 0.6870334546674381
Epoch: 66 | Iteration number: [2870/4518] 63% | Training loss: 0.6870288518040022
Epoch: 66 | Iteration number: [2880/4518] 63% | Training loss: 0.6870294288421671
Epoch: 66 | Iteration number: [2890/4518] 63% | Training loss: 0.6870256020742305
Epoch: 66 | Iteration number: [2900/4518] 64% | Training loss: 0.6870255841057876
Epoch: 66 | Iteration number: [2910/4518] 64% | Training loss: 0.6870279709088434
Epoch: 66 | Iteration number: [2920/4518] 64% | Training loss: 0.6870254934038201
Epoch: 66 | Iteration number: [2930/4518] 64% | Training loss: 0.6870230586658973
Epoch: 66 | Iteration number: [2940/4518] 65% | Training loss: 0.6870210143781844
Epoch: 66 | Iteration number: [2950/4518] 65% | Training loss: 0.6870230855376034
Epoch: 66 | Iteration number: [2960/4518] 65% | Training loss: 0.6870210721484713
Epoch: 66 | Iteration number: [2970/4518] 65% | Training loss: 0.6870243758063526
Epoch: 66 | Iteration number: [2980/4518] 65% | Training loss: 0.687020245834485
Epoch: 66 | Iteration number: [2990/4518] 66% | Training loss: 0.6870231737659926
Epoch: 66 | Iteration number: [3000/4518] 66% | Training loss: 0.6870215641856193
Epoch: 66 | Iteration number: [3010/4518] 66% | Training loss: 0.6870208502013818
Epoch: 66 | Iteration number: [3020/4518] 66% | Training loss: 0.687020941641157
Epoch: 66 | Iteration number: [3030/4518] 67% | Training loss: 0.687020477957458
Epoch: 66 | Iteration number: [3040/4518] 67% | Training loss: 0.6870202891136471
Epoch: 66 | Iteration number: [3050/4518] 67% | Training loss: 0.6870183386177313
Epoch: 66 | Iteration number: [3060/4518] 67% | Training loss: 0.6870211964728785
Epoch: 66 | Iteration number: [3070/4518] 67% | Training loss: 0.6870224791745798
Epoch: 66 | Iteration number: [3080/4518] 68% | Training loss: 0.6870205884242987
Epoch: 66 | Iteration number: [3090/4518] 68% | Training loss: 0.6870174860491336
Epoch: 66 | Iteration number: [3100/4518] 68% | Training loss: 0.6870154666708361
Epoch: 66 | Iteration number: [3110/4518] 68% | Training loss: 0.6870102408806228
Epoch: 66 | Iteration number: [3120/4518] 69% | Training loss: 0.6870068086645542
Epoch: 66 | Iteration number: [3130/4518] 69% | Training loss: 0.68700188068917
Epoch: 66 | Iteration number: [3140/4518] 69% | Training loss: 0.6870024377563198
Epoch: 66 | Iteration number: [3150/4518] 69% | Training loss: 0.6869958490038675
Epoch: 66 | Iteration number: [3160/4518] 69% | Training loss: 0.6869953534271144
Epoch: 66 | Iteration number: [3170/4518] 70% | Training loss: 0.6869956533615521
Epoch: 66 | Iteration number: [3180/4518] 70% | Training loss: 0.686992792775796
Epoch: 66 | Iteration number: [3190/4518] 70% | Training loss: 0.6869926386679228
Epoch: 66 | Iteration number: [3200/4518] 70% | Training loss: 0.6869918905198574
Epoch: 66 | Iteration number: [3210/4518] 71% | Training loss: 0.6869927161393508
Epoch: 66 | Iteration number: [3220/4518] 71% | Training loss: 0.6869890149891006
Epoch: 66 | Iteration number: [3230/4518] 71% | Training loss: 0.6869871278480849
Epoch: 66 | Iteration number: [3240/4518] 71% | Training loss: 0.6869853199816044
Epoch: 66 | Iteration number: [3250/4518] 71% | Training loss: 0.6869854297454541
Epoch: 66 | Iteration number: [3260/4518] 72% | Training loss: 0.6869860640332742
Epoch: 66 | Iteration number: [3270/4518] 72% | Training loss: 0.6869845154635403
Epoch: 66 | Iteration number: [3280/4518] 72% | Training loss: 0.686984239336921
Epoch: 66 | Iteration number: [3290/4518] 72% | Training loss: 0.6869836179318761
Epoch: 66 | Iteration number: [3300/4518] 73% | Training loss: 0.6869867933338338
Epoch: 66 | Iteration number: [3310/4518] 73% | Training loss: 0.6869825874750708
Epoch: 66 | Iteration number: [3320/4518] 73% | Training loss: 0.6869813800217157
Epoch: 66 | Iteration number: [3330/4518] 73% | Training loss: 0.686981019565651
Epoch: 66 | Iteration number: [3340/4518] 73% | Training loss: 0.686980565490123
Epoch: 66 | Iteration number: [3350/4518] 74% | Training loss: 0.6869808609094192
Epoch: 66 | Iteration number: [3360/4518] 74% | Training loss: 0.6869727849073354
Epoch: 66 | Iteration number: [3370/4518] 74% | Training loss: 0.6869721782844215
Epoch: 66 | Iteration number: [3380/4518] 74% | Training loss: 0.6869715064411333
Epoch: 66 | Iteration number: [3390/4518] 75% | Training loss: 0.686968810579418
Epoch: 66 | Iteration number: [3400/4518] 75% | Training loss: 0.6869700911465814
Epoch: 66 | Iteration number: [3410/4518] 75% | Training loss: 0.6869708186370537
Epoch: 66 | Iteration number: [3420/4518] 75% | Training loss: 0.686970272433688
Epoch: 66 | Iteration number: [3430/4518] 75% | Training loss: 0.6869665921603277
Epoch: 66 | Iteration number: [3440/4518] 76% | Training loss: 0.6869701208763345
Epoch: 66 | Iteration number: [3450/4518] 76% | Training loss: 0.6869701279591823
Epoch: 66 | Iteration number: [3460/4518] 76% | Training loss: 0.6869716024123176
Epoch: 66 | Iteration number: [3470/4518] 76% | Training loss: 0.6869698699510063
Epoch: 66 | Iteration number: [3480/4518] 77% | Training loss: 0.6869690340825881
Epoch: 66 | Iteration number: [3490/4518] 77% | Training loss: 0.6869689293782144
Epoch: 66 | Iteration number: [3500/4518] 77% | Training loss: 0.6869649197033474
Epoch: 66 | Iteration number: [3510/4518] 77% | Training loss: 0.6869676861837719
Epoch: 66 | Iteration number: [3520/4518] 77% | Training loss: 0.6869687152010473
Epoch: 66 | Iteration number: [3530/4518] 78% | Training loss: 0.686966210603714
Epoch: 66 | Iteration number: [3540/4518] 78% | Training loss: 0.6869635699327382
Epoch: 66 | Iteration number: [3550/4518] 78% | Training loss: 0.6869674927248082
Epoch: 66 | Iteration number: [3560/4518] 78% | Training loss: 0.686969439651859
Epoch: 66 | Iteration number: [3570/4518] 79% | Training loss: 0.6869688449620532
Epoch: 66 | Iteration number: [3580/4518] 79% | Training loss: 0.6869706506003215
Epoch: 66 | Iteration number: [3590/4518] 79% | Training loss: 0.6869736166717614
Epoch: 66 | Iteration number: [3600/4518] 79% | Training loss: 0.6869704912602902
Epoch: 66 | Iteration number: [3610/4518] 79% | Training loss: 0.6869675875700741
Epoch: 66 | Iteration number: [3620/4518] 80% | Training loss: 0.6869648464641518
Epoch: 66 | Iteration number: [3630/4518] 80% | Training loss: 0.6869651208895954
Epoch: 66 | Iteration number: [3640/4518] 80% | Training loss: 0.6869635037177212
Epoch: 66 | Iteration number: [3650/4518] 80% | Training loss: 0.6869656442289483
Epoch: 66 | Iteration number: [3660/4518] 81% | Training loss: 0.6869629271043455
Epoch: 66 | Iteration number: [3670/4518] 81% | Training loss: 0.6869622954880509
Epoch: 66 | Iteration number: [3680/4518] 81% | Training loss: 0.6869581331215475
Epoch: 66 | Iteration number: [3690/4518] 81% | Training loss: 0.686957857683099
Epoch: 66 | Iteration number: [3700/4518] 81% | Training loss: 0.6869594961888081
Epoch: 66 | Iteration number: [3710/4518] 82% | Training loss: 0.6869591587315994
Epoch: 66 | Iteration number: [3720/4518] 82% | Training loss: 0.6869609401270907
Epoch: 66 | Iteration number: [3730/4518] 82% | Training loss: 0.6869615550814621
Epoch: 66 | Iteration number: [3740/4518] 82% | Training loss: 0.6869607937686584
Epoch: 66 | Iteration number: [3750/4518] 83% | Training loss: 0.686959446366628
Epoch: 66 | Iteration number: [3760/4518] 83% | Training loss: 0.6869606991873143
Epoch: 66 | Iteration number: [3770/4518] 83% | Training loss: 0.6869589018252548
Epoch: 66 | Iteration number: [3780/4518] 83% | Training loss: 0.6869571543086773
Epoch: 66 | Iteration number: [3790/4518] 83% | Training loss: 0.6869573533377735
Epoch: 66 | Iteration number: [3800/4518] 84% | Training loss: 0.6869567238029681
Epoch: 66 | Iteration number: [3810/4518] 84% | Training loss: 0.6869540925883245
Epoch: 66 | Iteration number: [3820/4518] 84% | Training loss: 0.6869524435535151
Epoch: 66 | Iteration number: [3830/4518] 84% | Training loss: 0.6869517675890312
Epoch: 66 | Iteration number: [3840/4518] 84% | Training loss: 0.6869549106030415
Epoch: 66 | Iteration number: [3850/4518] 85% | Training loss: 0.6869574563069777
Epoch: 66 | Iteration number: [3860/4518] 85% | Training loss: 0.6869582148259168
Epoch: 66 | Iteration number: [3870/4518] 85% | Training loss: 0.6869547918477416
Epoch: 66 | Iteration number: [3880/4518] 85% | Training loss: 0.6869522583853338
Epoch: 66 | Iteration number: [3890/4518] 86% | Training loss: 0.6869545528545478
Epoch: 66 | Iteration number: [3900/4518] 86% | Training loss: 0.6869545223926886
Epoch: 66 | Iteration number: [3910/4518] 86% | Training loss: 0.6869538092094919
Epoch: 66 | Iteration number: [3920/4518] 86% | Training loss: 0.6869533315757099
Epoch: 66 | Iteration number: [3930/4518] 86% | Training loss: 0.6869549690767099
Epoch: 66 | Iteration number: [3940/4518] 87% | Training loss: 0.6869572592568276
Epoch: 66 | Iteration number: [3950/4518] 87% | Training loss: 0.6869569254072406
Epoch: 66 | Iteration number: [3960/4518] 87% | Training loss: 0.6869580719808135
Epoch: 66 | Iteration number: [3970/4518] 87% | Training loss: 0.6869582520323977
Epoch: 66 | Iteration number: [3980/4518] 88% | Training loss: 0.6869593324822996
Epoch: 66 | Iteration number: [3990/4518] 88% | Training loss: 0.6869575527377595
Epoch: 66 | Iteration number: [4000/4518] 88% | Training loss: 0.6869559589475394
Epoch: 66 | Iteration number: [4010/4518] 88% | Training loss: 0.6869580003834722
Epoch: 66 | Iteration number: [4020/4518] 88% | Training loss: 0.6869582652007763
Epoch: 66 | Iteration number: [4030/4518] 89% | Training loss: 0.6869585330817599
Epoch: 66 | Iteration number: [4040/4518] 89% | Training loss: 0.6869530542504669
Epoch: 66 | Iteration number: [4050/4518] 89% | Training loss: 0.6869476761641325
Epoch: 66 | Iteration number: [4060/4518] 89% | Training loss: 0.686948730587372
Epoch: 66 | Iteration number: [4070/4518] 90% | Training loss: 0.6869544927991872
Epoch: 66 | Iteration number: [4080/4518] 90% | Training loss: 0.686955898006757
Epoch: 66 | Iteration number: [4090/4518] 90% | Training loss: 0.6869575858844813
Epoch: 66 | Iteration number: [4100/4518] 90% | Training loss: 0.6869571424693596
Epoch: 66 | Iteration number: [4110/4518] 90% | Training loss: 0.6869573557173829
Epoch: 66 | Iteration number: [4120/4518] 91% | Training loss: 0.6869568918081164
Epoch: 66 | Iteration number: [4130/4518] 91% | Training loss: 0.686955104367785
Epoch: 66 | Iteration number: [4140/4518] 91% | Training loss: 0.6869558916287721
Epoch: 66 | Iteration number: [4150/4518] 91% | Training loss: 0.6869563874853662
Epoch: 66 | Iteration number: [4160/4518] 92% | Training loss: 0.6869551743738926
Epoch: 66 | Iteration number: [4170/4518] 92% | Training loss: 0.6869560099191231
Epoch: 66 | Iteration number: [4180/4518] 92% | Training loss: 0.6869571753808756
Epoch: 66 | Iteration number: [4190/4518] 92% | Training loss: 0.6869539961752288
Epoch: 66 | Iteration number: [4200/4518] 92% | Training loss: 0.6869550698853675
Epoch: 66 | Iteration number: [4210/4518] 93% | Training loss: 0.6869497741769441
Epoch: 66 | Iteration number: [4220/4518] 93% | Training loss: 0.6869450257287771
Epoch: 66 | Iteration number: [4230/4518] 93% | Training loss: 0.6869472448284745
Epoch: 66 | Iteration number: [4240/4518] 93% | Training loss: 0.6869468658037905
Epoch: 66 | Iteration number: [4250/4518] 94% | Training loss: 0.686945096618989
Epoch: 66 | Iteration number: [4260/4518] 94% | Training loss: 0.6869465385384403
Epoch: 66 | Iteration number: [4270/4518] 94% | Training loss: 0.6869467963239907
Epoch: 66 | Iteration number: [4280/4518] 94% | Training loss: 0.6869471070643898
Epoch: 66 | Iteration number: [4290/4518] 94% | Training loss: 0.6869435756356566
Epoch: 66 | Iteration number: [4300/4518] 95% | Training loss: 0.6869429223204768
Epoch: 66 | Iteration number: [4310/4518] 95% | Training loss: 0.6869438163918852
Epoch: 66 | Iteration number: [4320/4518] 95% | Training loss: 0.6869417978519643
Epoch: 66 | Iteration number: [4330/4518] 95% | Training loss: 0.6869430208866921
Epoch: 66 | Iteration number: [4340/4518] 96% | Training loss: 0.6869444204777616
Epoch: 66 | Iteration number: [4350/4518] 96% | Training loss: 0.6869430930861111
Epoch: 66 | Iteration number: [4360/4518] 96% | Training loss: 0.6869423241653574
Epoch: 66 | Iteration number: [4370/4518] 96% | Training loss: 0.686941154952453
Epoch: 66 | Iteration number: [4380/4518] 96% | Training loss: 0.6869381742390324
Epoch: 66 | Iteration number: [4390/4518] 97% | Training loss: 0.6869394634606355
Epoch: 66 | Iteration number: [4400/4518] 97% | Training loss: 0.686941206170754
Epoch: 66 | Iteration number: [4410/4518] 97% | Training loss: 0.6869413493306729
Epoch: 66 | Iteration number: [4420/4518] 97% | Training loss: 0.6869423317288921
Epoch: 66 | Iteration number: [4430/4518] 98% | Training loss: 0.6869407468132726
Epoch: 66 | Iteration number: [4440/4518] 98% | Training loss: 0.6869405925273895
Epoch: 66 | Iteration number: [4450/4518] 98% | Training loss: 0.6869399697325203
Epoch: 66 | Iteration number: [4460/4518] 98% | Training loss: 0.6869399190750892
Epoch: 66 | Iteration number: [4470/4518] 98% | Training loss: 0.6869393201882407
Epoch: 66 | Iteration number: [4480/4518] 99% | Training loss: 0.6869394561408886
Epoch: 66 | Iteration number: [4490/4518] 99% | Training loss: 0.6869420840108315
Epoch: 66 | Iteration number: [4500/4518] 99% | Training loss: 0.6869445442623562
Epoch: 66 | Iteration number: [4510/4518] 99% | Training loss: 0.6869440505351301

 End of epoch: 66 | Train Loss: 0.6867899346161649 | Training Time: 644 

 End of epoch: 66 | Eval Loss: 0.690036729890473 | Evaluating Time: 17 
Epoch: 67 | Iteration number: [10/4518] 0% | Training loss: 0.7563507199287415
Epoch: 67 | Iteration number: [20/4518] 0% | Training loss: 0.7211226433515548
Epoch: 67 | Iteration number: [30/4518] 0% | Training loss: 0.7098848899205525
Epoch: 67 | Iteration number: [40/4518] 0% | Training loss: 0.7045833066105842
Epoch: 67 | Iteration number: [50/4518] 1% | Training loss: 0.7008678364753723
Epoch: 67 | Iteration number: [60/4518] 1% | Training loss: 0.6985792626937231
Epoch: 67 | Iteration number: [70/4518] 1% | Training loss: 0.6967951706477574
Epoch: 67 | Iteration number: [80/4518] 1% | Training loss: 0.6953919097781182
Epoch: 67 | Iteration number: [90/4518] 1% | Training loss: 0.6944920208719042
Epoch: 67 | Iteration number: [100/4518] 2% | Training loss: 0.6937369155883789
Epoch: 67 | Iteration number: [110/4518] 2% | Training loss: 0.6931256478483027
Epoch: 67 | Iteration number: [120/4518] 2% | Training loss: 0.692658220231533
Epoch: 67 | Iteration number: [130/4518] 2% | Training loss: 0.6923187086215385
Epoch: 67 | Iteration number: [140/4518] 3% | Training loss: 0.691927524123873
Epoch: 67 | Iteration number: [150/4518] 3% | Training loss: 0.6915563869476319
Epoch: 67 | Iteration number: [160/4518] 3% | Training loss: 0.6912263210862875
Epoch: 67 | Iteration number: [170/4518] 3% | Training loss: 0.6908908861524918
Epoch: 67 | Iteration number: [180/4518] 3% | Training loss: 0.6906708813375897
Epoch: 67 | Iteration number: [190/4518] 4% | Training loss: 0.6904381168516058
Epoch: 67 | Iteration number: [200/4518] 4% | Training loss: 0.6902730175852776
Epoch: 67 | Iteration number: [210/4518] 4% | Training loss: 0.6901612662133716
Epoch: 67 | Iteration number: [220/4518] 4% | Training loss: 0.6899693816900253
Epoch: 67 | Iteration number: [230/4518] 5% | Training loss: 0.6898098748663197
Epoch: 67 | Iteration number: [240/4518] 5% | Training loss: 0.6896733338634173
Epoch: 67 | Iteration number: [250/4518] 5% | Training loss: 0.6895296838283539
Epoch: 67 | Iteration number: [260/4518] 5% | Training loss: 0.6893921939226297
Epoch: 67 | Iteration number: [270/4518] 5% | Training loss: 0.689312172377551
Epoch: 67 | Iteration number: [280/4518] 6% | Training loss: 0.689236487022468
Epoch: 67 | Iteration number: [290/4518] 6% | Training loss: 0.6891429658593803
Epoch: 67 | Iteration number: [300/4518] 6% | Training loss: 0.6890455971161524
Epoch: 67 | Iteration number: [310/4518] 6% | Training loss: 0.6889987670606182
Epoch: 67 | Iteration number: [320/4518] 7% | Training loss: 0.6889308478683234
Epoch: 67 | Iteration number: [330/4518] 7% | Training loss: 0.6888997312748071
Epoch: 67 | Iteration number: [340/4518] 7% | Training loss: 0.6888349263107075
Epoch: 67 | Iteration number: [350/4518] 7% | Training loss: 0.6887558761664799
Epoch: 67 | Iteration number: [360/4518] 7% | Training loss: 0.6886856264538235
Epoch: 67 | Iteration number: [370/4518] 8% | Training loss: 0.6885944572654931
Epoch: 67 | Iteration number: [380/4518] 8% | Training loss: 0.6885224235685248
Epoch: 67 | Iteration number: [390/4518] 8% | Training loss: 0.6884996001537029
Epoch: 67 | Iteration number: [400/4518] 8% | Training loss: 0.6884738087654114
Epoch: 67 | Iteration number: [410/4518] 9% | Training loss: 0.6884476491590825
Epoch: 67 | Iteration number: [420/4518] 9% | Training loss: 0.6884291194734119
Epoch: 67 | Iteration number: [430/4518] 9% | Training loss: 0.6883639264938444
Epoch: 67 | Iteration number: [440/4518] 9% | Training loss: 0.6883147113702514
Epoch: 67 | Iteration number: [450/4518] 9% | Training loss: 0.6882614681455824
Epoch: 67 | Iteration number: [460/4518] 10% | Training loss: 0.6882168969382411
Epoch: 67 | Iteration number: [470/4518] 10% | Training loss: 0.6881960735676137
Epoch: 67 | Iteration number: [480/4518] 10% | Training loss: 0.6881653516242902
Epoch: 67 | Iteration number: [490/4518] 10% | Training loss: 0.6881286219674714
Epoch: 67 | Iteration number: [500/4518] 11% | Training loss: 0.6880986514091492
Epoch: 67 | Iteration number: [510/4518] 11% | Training loss: 0.688090034793405
Epoch: 67 | Iteration number: [520/4518] 11% | Training loss: 0.6880574715825227
Epoch: 67 | Iteration number: [530/4518] 11% | Training loss: 0.6880424109269988
Epoch: 67 | Iteration number: [540/4518] 11% | Training loss: 0.6879746803530941
Epoch: 67 | Iteration number: [550/4518] 12% | Training loss: 0.6879582257704301
Epoch: 67 | Iteration number: [560/4518] 12% | Training loss: 0.6879678730453763
Epoch: 67 | Iteration number: [570/4518] 12% | Training loss: 0.6879645698948911
Epoch: 67 | Iteration number: [580/4518] 12% | Training loss: 0.6879326730966568
Epoch: 67 | Iteration number: [590/4518] 13% | Training loss: 0.6879261514898074
Epoch: 67 | Iteration number: [600/4518] 13% | Training loss: 0.6879158957799276
Epoch: 67 | Iteration number: [610/4518] 13% | Training loss: 0.6879053189129126
Epoch: 67 | Iteration number: [620/4518] 13% | Training loss: 0.6878901299930388
Epoch: 67 | Iteration number: [630/4518] 13% | Training loss: 0.6878709770384289
Epoch: 67 | Iteration number: [640/4518] 14% | Training loss: 0.6878484204411507
Epoch: 67 | Iteration number: [650/4518] 14% | Training loss: 0.6878543238456433
Epoch: 67 | Iteration number: [660/4518] 14% | Training loss: 0.6878316550543814
Epoch: 67 | Iteration number: [670/4518] 14% | Training loss: 0.6877904627750169
Epoch: 67 | Iteration number: [680/4518] 15% | Training loss: 0.6877902066006379
Epoch: 67 | Iteration number: [690/4518] 15% | Training loss: 0.6877731014852938
Epoch: 67 | Iteration number: [700/4518] 15% | Training loss: 0.6877392292022705
Epoch: 67 | Iteration number: [710/4518] 15% | Training loss: 0.6877358919298145
Epoch: 67 | Iteration number: [720/4518] 15% | Training loss: 0.6877100898159875
Epoch: 67 | Iteration number: [730/4518] 16% | Training loss: 0.6877247061631451
Epoch: 67 | Iteration number: [740/4518] 16% | Training loss: 0.6877101177299345
Epoch: 67 | Iteration number: [750/4518] 16% | Training loss: 0.6876955199241638
Epoch: 67 | Iteration number: [760/4518] 16% | Training loss: 0.6876750020604384
Epoch: 67 | Iteration number: [770/4518] 17% | Training loss: 0.6876555148657266
Epoch: 67 | Iteration number: [780/4518] 17% | Training loss: 0.68762198419143
Epoch: 67 | Iteration number: [790/4518] 17% | Training loss: 0.6876005365878721
Epoch: 67 | Iteration number: [800/4518] 17% | Training loss: 0.6875725377351045
Epoch: 67 | Iteration number: [810/4518] 17% | Training loss: 0.6875524229473537
Epoch: 67 | Iteration number: [820/4518] 18% | Training loss: 0.687542171812639
Epoch: 67 | Iteration number: [830/4518] 18% | Training loss: 0.6875418033226427
Epoch: 67 | Iteration number: [840/4518] 18% | Training loss: 0.6875328606792859
Epoch: 67 | Iteration number: [850/4518] 18% | Training loss: 0.6875276910557466
Epoch: 67 | Iteration number: [860/4518] 19% | Training loss: 0.68752412872259
Epoch: 67 | Iteration number: [870/4518] 19% | Training loss: 0.68751971899778
Epoch: 67 | Iteration number: [880/4518] 19% | Training loss: 0.6874923853711649
Epoch: 67 | Iteration number: [890/4518] 19% | Training loss: 0.6874811860282769
Epoch: 67 | Iteration number: [900/4518] 19% | Training loss: 0.6874588218662474
Epoch: 67 | Iteration number: [910/4518] 20% | Training loss: 0.6874506823964172
Epoch: 67 | Iteration number: [920/4518] 20% | Training loss: 0.6874341021413388
Epoch: 67 | Iteration number: [930/4518] 20% | Training loss: 0.6874390757212074
Epoch: 67 | Iteration number: [940/4518] 20% | Training loss: 0.6874203888659781
Epoch: 67 | Iteration number: [950/4518] 21% | Training loss: 0.6874208388830486
Epoch: 67 | Iteration number: [960/4518] 21% | Training loss: 0.6874146942670146
Epoch: 67 | Iteration number: [970/4518] 21% | Training loss: 0.6874035529869119
Epoch: 67 | Iteration number: [980/4518] 21% | Training loss: 0.6873879091472042
Epoch: 67 | Iteration number: [990/4518] 21% | Training loss: 0.6873691015171283
Epoch: 67 | Iteration number: [1000/4518] 22% | Training loss: 0.6873567807078361
Epoch: 67 | Iteration number: [1010/4518] 22% | Training loss: 0.687353251476099
Epoch: 67 | Iteration number: [1020/4518] 22% | Training loss: 0.6873560939933739
Epoch: 67 | Iteration number: [1030/4518] 22% | Training loss: 0.6873434005431759
Epoch: 67 | Iteration number: [1040/4518] 23% | Training loss: 0.6873391211605989
Epoch: 67 | Iteration number: [1050/4518] 23% | Training loss: 0.6873415717056819
Epoch: 67 | Iteration number: [1060/4518] 23% | Training loss: 0.6873270043786966
Epoch: 67 | Iteration number: [1070/4518] 23% | Training loss: 0.6873257081085277
Epoch: 67 | Iteration number: [1080/4518] 23% | Training loss: 0.687320803547347
Epoch: 67 | Iteration number: [1090/4518] 24% | Training loss: 0.6873179658290443
Epoch: 67 | Iteration number: [1100/4518] 24% | Training loss: 0.6873210024291819
Epoch: 67 | Iteration number: [1110/4518] 24% | Training loss: 0.6873152007390787
Epoch: 67 | Iteration number: [1120/4518] 24% | Training loss: 0.6873065483357225
Epoch: 67 | Iteration number: [1130/4518] 25% | Training loss: 0.6872807365075677
Epoch: 67 | Iteration number: [1140/4518] 25% | Training loss: 0.6872786466489759
Epoch: 67 | Iteration number: [1150/4518] 25% | Training loss: 0.6872731804329416
Epoch: 67 | Iteration number: [1160/4518] 25% | Training loss: 0.687271013496251
Epoch: 67 | Iteration number: [1170/4518] 25% | Training loss: 0.6872758015608176
Epoch: 67 | Iteration number: [1180/4518] 26% | Training loss: 0.6872693043644146
Epoch: 67 | Iteration number: [1190/4518] 26% | Training loss: 0.6872581132820674
Epoch: 67 | Iteration number: [1200/4518] 26% | Training loss: 0.6872583302358787
Epoch: 67 | Iteration number: [1210/4518] 26% | Training loss: 0.6872584793685882
Epoch: 67 | Iteration number: [1220/4518] 27% | Training loss: 0.687253650094642
Epoch: 67 | Iteration number: [1230/4518] 27% | Training loss: 0.6872574539688544
Epoch: 67 | Iteration number: [1240/4518] 27% | Training loss: 0.6872695707505749
Epoch: 67 | Iteration number: [1250/4518] 27% | Training loss: 0.6872585806846618
Epoch: 67 | Iteration number: [1260/4518] 27% | Training loss: 0.6872519032349662
Epoch: 67 | Iteration number: [1270/4518] 28% | Training loss: 0.6872542227347066
Epoch: 67 | Iteration number: [1280/4518] 28% | Training loss: 0.6872607101686299
Epoch: 67 | Iteration number: [1290/4518] 28% | Training loss: 0.6872595937677132
Epoch: 67 | Iteration number: [1300/4518] 28% | Training loss: 0.6872540517953726
Epoch: 67 | Iteration number: [1310/4518] 28% | Training loss: 0.6872551635021472
Epoch: 67 | Iteration number: [1320/4518] 29% | Training loss: 0.687250358859698
Epoch: 67 | Iteration number: [1330/4518] 29% | Training loss: 0.6872452589802276
Epoch: 67 | Iteration number: [1340/4518] 29% | Training loss: 0.6872408146288858
Epoch: 67 | Iteration number: [1350/4518] 29% | Training loss: 0.687242981813572
Epoch: 67 | Iteration number: [1360/4518] 30% | Training loss: 0.687241103368647
Epoch: 67 | Iteration number: [1370/4518] 30% | Training loss: 0.6872424119580401
Epoch: 67 | Iteration number: [1380/4518] 30% | Training loss: 0.6872327155393103
Epoch: 67 | Iteration number: [1390/4518] 30% | Training loss: 0.6872197185060103
Epoch: 67 | Iteration number: [1400/4518] 30% | Training loss: 0.6872172417810986
Epoch: 67 | Iteration number: [1410/4518] 31% | Training loss: 0.6872120804397772
Epoch: 67 | Iteration number: [1420/4518] 31% | Training loss: 0.6872139044630695
Epoch: 67 | Iteration number: [1430/4518] 31% | Training loss: 0.6872112723497245
Epoch: 67 | Iteration number: [1440/4518] 31% | Training loss: 0.6872182609306441
Epoch: 67 | Iteration number: [1450/4518] 32% | Training loss: 0.6872126953355198
Epoch: 67 | Iteration number: [1460/4518] 32% | Training loss: 0.6872056137617321
Epoch: 67 | Iteration number: [1470/4518] 32% | Training loss: 0.687195165870952
Epoch: 67 | Iteration number: [1480/4518] 32% | Training loss: 0.6871893147761757
Epoch: 67 | Iteration number: [1490/4518] 32% | Training loss: 0.6871912190178097
Epoch: 67 | Iteration number: [1500/4518] 33% | Training loss: 0.6871881598631541
Epoch: 67 | Iteration number: [1510/4518] 33% | Training loss: 0.6871872303896392
Epoch: 67 | Iteration number: [1520/4518] 33% | Training loss: 0.6871785530918523
Epoch: 67 | Iteration number: [1530/4518] 33% | Training loss: 0.6871703648099712
Epoch: 67 | Iteration number: [1540/4518] 34% | Training loss: 0.6871654865803657
Epoch: 67 | Iteration number: [1550/4518] 34% | Training loss: 0.687160201649512
Epoch: 67 | Iteration number: [1560/4518] 34% | Training loss: 0.6871571841530311
Epoch: 67 | Iteration number: [1570/4518] 34% | Training loss: 0.68715572023088
Epoch: 67 | Iteration number: [1580/4518] 34% | Training loss: 0.6871526443882834
Epoch: 67 | Iteration number: [1590/4518] 35% | Training loss: 0.6871467698295162
Epoch: 67 | Iteration number: [1600/4518] 35% | Training loss: 0.6871502815932036
Epoch: 67 | Iteration number: [1610/4518] 35% | Training loss: 0.6871531094453349
Epoch: 67 | Iteration number: [1620/4518] 35% | Training loss: 0.6871423683416696
Epoch: 67 | Iteration number: [1630/4518] 36% | Training loss: 0.6871451661264969
Epoch: 67 | Iteration number: [1640/4518] 36% | Training loss: 0.6871428365751011
Epoch: 67 | Iteration number: [1650/4518] 36% | Training loss: 0.68714616392598
Epoch: 67 | Iteration number: [1660/4518] 36% | Training loss: 0.6871430178363639
Epoch: 67 | Iteration number: [1670/4518] 36% | Training loss: 0.6871439360215992
Epoch: 67 | Iteration number: [1680/4518] 37% | Training loss: 0.6871433701543581
Epoch: 67 | Iteration number: [1690/4518] 37% | Training loss: 0.6871477706192514
Epoch: 67 | Iteration number: [1700/4518] 37% | Training loss: 0.6871496697383769
Epoch: 67 | Iteration number: [1710/4518] 37% | Training loss: 0.6871552246704437
Epoch: 67 | Iteration number: [1720/4518] 38% | Training loss: 0.6871525563819464
Epoch: 67 | Iteration number: [1730/4518] 38% | Training loss: 0.6871509611606598
Epoch: 67 | Iteration number: [1740/4518] 38% | Training loss: 0.6871526004939243
Epoch: 67 | Iteration number: [1750/4518] 38% | Training loss: 0.6871528785569327
Epoch: 67 | Iteration number: [1760/4518] 38% | Training loss: 0.6871525559235703
Epoch: 67 | Iteration number: [1770/4518] 39% | Training loss: 0.6871501225872901
Epoch: 67 | Iteration number: [1780/4518] 39% | Training loss: 0.6871485250049763
Epoch: 67 | Iteration number: [1790/4518] 39% | Training loss: 0.6871416303032604
Epoch: 67 | Iteration number: [1800/4518] 39% | Training loss: 0.6871336385276583
Epoch: 67 | Iteration number: [1810/4518] 40% | Training loss: 0.6871293676162952
Epoch: 67 | Iteration number: [1820/4518] 40% | Training loss: 0.6871271505788132
Epoch: 67 | Iteration number: [1830/4518] 40% | Training loss: 0.6871258347412276
Epoch: 67 | Iteration number: [1840/4518] 40% | Training loss: 0.687127548844918
Epoch: 67 | Iteration number: [1850/4518] 40% | Training loss: 0.6871325522822302
Epoch: 67 | Iteration number: [1860/4518] 41% | Training loss: 0.6871290379954923
Epoch: 67 | Iteration number: [1870/4518] 41% | Training loss: 0.6871254733220779
Epoch: 67 | Iteration number: [1880/4518] 41% | Training loss: 0.6871240842532604
Epoch: 67 | Iteration number: [1890/4518] 41% | Training loss: 0.6871263293362169
Epoch: 67 | Iteration number: [1900/4518] 42% | Training loss: 0.6871242606012444
Epoch: 67 | Iteration number: [1910/4518] 42% | Training loss: 0.687111533749166
Epoch: 67 | Iteration number: [1920/4518] 42% | Training loss: 0.6871080795923868
Epoch: 67 | Iteration number: [1930/4518] 42% | Training loss: 0.6871107241650319
Epoch: 67 | Iteration number: [1940/4518] 42% | Training loss: 0.6871070077738811
Epoch: 67 | Iteration number: [1950/4518] 43% | Training loss: 0.687101388099866
Epoch: 67 | Iteration number: [1960/4518] 43% | Training loss: 0.6871018845207837
Epoch: 67 | Iteration number: [1970/4518] 43% | Training loss: 0.6871092035685699
Epoch: 67 | Iteration number: [1980/4518] 43% | Training loss: 0.6871080010828345
Epoch: 67 | Iteration number: [1990/4518] 44% | Training loss: 0.6871067632083318
Epoch: 67 | Iteration number: [2000/4518] 44% | Training loss: 0.6871024593710899
Epoch: 67 | Iteration number: [2010/4518] 44% | Training loss: 0.6871048930865615
Epoch: 67 | Iteration number: [2020/4518] 44% | Training loss: 0.6871028713955738
Epoch: 67 | Iteration number: [2030/4518] 44% | Training loss: 0.6871013034447073
Epoch: 67 | Iteration number: [2040/4518] 45% | Training loss: 0.687104811066506
Epoch: 67 | Iteration number: [2050/4518] 45% | Training loss: 0.687109552796294
Epoch: 67 | Iteration number: [2060/4518] 45% | Training loss: 0.6871097371126842
Epoch: 67 | Iteration number: [2070/4518] 45% | Training loss: 0.6871153094054421
Epoch: 67 | Iteration number: [2080/4518] 46% | Training loss: 0.6871134925347108
Epoch: 67 | Iteration number: [2090/4518] 46% | Training loss: 0.6871149739865481
Epoch: 67 | Iteration number: [2100/4518] 46% | Training loss: 0.6871078971737907
Epoch: 67 | Iteration number: [2110/4518] 46% | Training loss: 0.6871038124177128
Epoch: 67 | Iteration number: [2120/4518] 46% | Training loss: 0.6870960431278876
Epoch: 67 | Iteration number: [2130/4518] 47% | Training loss: 0.6870966040752303
Epoch: 67 | Iteration number: [2140/4518] 47% | Training loss: 0.6870959051301546
Epoch: 67 | Iteration number: [2150/4518] 47% | Training loss: 0.6870950578257095
Epoch: 67 | Iteration number: [2160/4518] 47% | Training loss: 0.687096736304186
Epoch: 67 | Iteration number: [2170/4518] 48% | Training loss: 0.6870926477392698
Epoch: 67 | Iteration number: [2180/4518] 48% | Training loss: 0.6870946796935633
Epoch: 67 | Iteration number: [2190/4518] 48% | Training loss: 0.6870959934034304
Epoch: 67 | Iteration number: [2200/4518] 48% | Training loss: 0.6870959571545774
Epoch: 67 | Iteration number: [2210/4518] 48% | Training loss: 0.6870948004776536
Epoch: 67 | Iteration number: [2220/4518] 49% | Training loss: 0.6870943870093371
Epoch: 67 | Iteration number: [2230/4518] 49% | Training loss: 0.687099818076788
Epoch: 67 | Iteration number: [2240/4518] 49% | Training loss: 0.6870942126959563
Epoch: 67 | Iteration number: [2250/4518] 49% | Training loss: 0.6870926124519772
Epoch: 67 | Iteration number: [2260/4518] 50% | Training loss: 0.6870950494192343
Epoch: 67 | Iteration number: [2270/4518] 50% | Training loss: 0.6870891054033708
Epoch: 67 | Iteration number: [2280/4518] 50% | Training loss: 0.6870926925749109
Epoch: 67 | Iteration number: [2290/4518] 50% | Training loss: 0.6870881131903053
Epoch: 67 | Iteration number: [2300/4518] 50% | Training loss: 0.6870850036714388
Epoch: 67 | Iteration number: [2310/4518] 51% | Training loss: 0.6870848906246615
Epoch: 67 | Iteration number: [2320/4518] 51% | Training loss: 0.687084588947995
Epoch: 67 | Iteration number: [2330/4518] 51% | Training loss: 0.6870823331401071
Epoch: 67 | Iteration number: [2340/4518] 51% | Training loss: 0.6870811132029591
Epoch: 67 | Iteration number: [2350/4518] 52% | Training loss: 0.6870804209151167
Epoch: 67 | Iteration number: [2360/4518] 52% | Training loss: 0.6870753017522521
Epoch: 67 | Iteration number: [2370/4518] 52% | Training loss: 0.6870739432326852
Epoch: 67 | Iteration number: [2380/4518] 52% | Training loss: 0.6870690886212998
Epoch: 67 | Iteration number: [2390/4518] 52% | Training loss: 0.6870712389257663
Epoch: 67 | Iteration number: [2400/4518] 53% | Training loss: 0.6870626006275415
Epoch: 67 | Iteration number: [2410/4518] 53% | Training loss: 0.687059805304183
Epoch: 67 | Iteration number: [2420/4518] 53% | Training loss: 0.6870608804886006
Epoch: 67 | Iteration number: [2430/4518] 53% | Training loss: 0.6870561998567464
Epoch: 67 | Iteration number: [2440/4518] 54% | Training loss: 0.6870526736388441
Epoch: 67 | Iteration number: [2450/4518] 54% | Training loss: 0.6870547879715355
Epoch: 67 | Iteration number: [2460/4518] 54% | Training loss: 0.6870532055453556
Epoch: 67 | Iteration number: [2470/4518] 54% | Training loss: 0.6870541903171462
Epoch: 67 | Iteration number: [2480/4518] 54% | Training loss: 0.6870537067132612
Epoch: 67 | Iteration number: [2490/4518] 55% | Training loss: 0.6870520560138197
Epoch: 67 | Iteration number: [2500/4518] 55% | Training loss: 0.6870490056276322
Epoch: 67 | Iteration number: [2510/4518] 55% | Training loss: 0.6870505597011977
Epoch: 67 | Iteration number: [2520/4518] 55% | Training loss: 0.6870485807222033
Epoch: 67 | Iteration number: [2530/4518] 55% | Training loss: 0.6870407588161499
Epoch: 67 | Iteration number: [2540/4518] 56% | Training loss: 0.6870378235663016
Epoch: 67 | Iteration number: [2550/4518] 56% | Training loss: 0.6870377346581104
Epoch: 67 | Iteration number: [2560/4518] 56% | Training loss: 0.6870384434703738
Epoch: 67 | Iteration number: [2570/4518] 56% | Training loss: 0.6870320252407386
Epoch: 67 | Iteration number: [2580/4518] 57% | Training loss: 0.6870341535224471
Epoch: 67 | Iteration number: [2590/4518] 57% | Training loss: 0.6870356394977644
Epoch: 67 | Iteration number: [2600/4518] 57% | Training loss: 0.6870358551465549
Epoch: 67 | Iteration number: [2610/4518] 57% | Training loss: 0.6870370390314708
Epoch: 67 | Iteration number: [2620/4518] 57% | Training loss: 0.6870385931420873
Epoch: 67 | Iteration number: [2630/4518] 58% | Training loss: 0.6870398112123004
Epoch: 67 | Iteration number: [2640/4518] 58% | Training loss: 0.6870403936415007
Epoch: 67 | Iteration number: [2650/4518] 58% | Training loss: 0.6870389183737197
Epoch: 67 | Iteration number: [2660/4518] 58% | Training loss: 0.6870396646117806
Epoch: 67 | Iteration number: [2670/4518] 59% | Training loss: 0.6870394938001025
Epoch: 67 | Iteration number: [2680/4518] 59% | Training loss: 0.6870379931446332
Epoch: 67 | Iteration number: [2690/4518] 59% | Training loss: 0.6870361058020681
Epoch: 67 | Iteration number: [2700/4518] 59% | Training loss: 0.6870384165755025
Epoch: 67 | Iteration number: [2710/4518] 59% | Training loss: 0.6870371826900328
Epoch: 67 | Iteration number: [2720/4518] 60% | Training loss: 0.6870340684100109
Epoch: 67 | Iteration number: [2730/4518] 60% | Training loss: 0.6870329464748229
Epoch: 67 | Iteration number: [2740/4518] 60% | Training loss: 0.6870304540125993
Epoch: 67 | Iteration number: [2750/4518] 60% | Training loss: 0.687025540525263
Epoch: 67 | Iteration number: [2760/4518] 61% | Training loss: 0.6870212078094482
Epoch: 67 | Iteration number: [2770/4518] 61% | Training loss: 0.6870170514936481
Epoch: 67 | Iteration number: [2780/4518] 61% | Training loss: 0.6870088289538734
Epoch: 67 | Iteration number: [2790/4518] 61% | Training loss: 0.687013758937945
Epoch: 67 | Iteration number: [2800/4518] 61% | Training loss: 0.6870102273353509
Epoch: 67 | Iteration number: [2810/4518] 62% | Training loss: 0.6870125571603877
Epoch: 67 | Iteration number: [2820/4518] 62% | Training loss: 0.6870099870448417
Epoch: 67 | Iteration number: [2830/4518] 62% | Training loss: 0.6870058991041285
Epoch: 67 | Iteration number: [2840/4518] 62% | Training loss: 0.6870073321419703
Epoch: 67 | Iteration number: [2850/4518] 63% | Training loss: 0.6870044450592576
Epoch: 67 | Iteration number: [2860/4518] 63% | Training loss: 0.6870035617918401
Epoch: 67 | Iteration number: [2870/4518] 63% | Training loss: 0.6870004685498281
Epoch: 67 | Iteration number: [2880/4518] 63% | Training loss: 0.6870024997534023
Epoch: 67 | Iteration number: [2890/4518] 63% | Training loss: 0.6870007919398972
Epoch: 67 | Iteration number: [2900/4518] 64% | Training loss: 0.6869996145675922
Epoch: 67 | Iteration number: [2910/4518] 64% | Training loss: 0.6869990981116737
Epoch: 67 | Iteration number: [2920/4518] 64% | Training loss: 0.686996297517868
Epoch: 67 | Iteration number: [2930/4518] 64% | Training loss: 0.6869904177180736
Epoch: 67 | Iteration number: [2940/4518] 65% | Training loss: 0.6869921407529286
Epoch: 67 | Iteration number: [2950/4518] 65% | Training loss: 0.686992448649164
Epoch: 67 | Iteration number: [2960/4518] 65% | Training loss: 0.6869902322018469
Epoch: 67 | Iteration number: [2970/4518] 65% | Training loss: 0.6869874787451041
Epoch: 67 | Iteration number: [2980/4518] 65% | Training loss: 0.6869855090875754
Epoch: 67 | Iteration number: [2990/4518] 66% | Training loss: 0.6869896013999862
Epoch: 67 | Iteration number: [3000/4518] 66% | Training loss: 0.6869887305100759
Epoch: 67 | Iteration number: [3010/4518] 66% | Training loss: 0.6869837508447146
Epoch: 67 | Iteration number: [3020/4518] 66% | Training loss: 0.6869799901910175
Epoch: 67 | Iteration number: [3030/4518] 67% | Training loss: 0.6869802786965574
Epoch: 67 | Iteration number: [3040/4518] 67% | Training loss: 0.6869817917088145
Epoch: 67 | Iteration number: [3050/4518] 67% | Training loss: 0.6869776916894756
Epoch: 67 | Iteration number: [3060/4518] 67% | Training loss: 0.6869768902172451
Epoch: 67 | Iteration number: [3070/4518] 67% | Training loss: 0.6869811831739904
Epoch: 67 | Iteration number: [3080/4518] 68% | Training loss: 0.6869789796796713
Epoch: 67 | Iteration number: [3090/4518] 68% | Training loss: 0.6869808159599798
Epoch: 67 | Iteration number: [3100/4518] 68% | Training loss: 0.686982802364134
Epoch: 67 | Iteration number: [3110/4518] 68% | Training loss: 0.6869839045970769
Epoch: 67 | Iteration number: [3120/4518] 69% | Training loss: 0.6869852954760576
Epoch: 67 | Iteration number: [3130/4518] 69% | Training loss: 0.6869875214160822
Epoch: 67 | Iteration number: [3140/4518] 69% | Training loss: 0.6869861330006533
Epoch: 67 | Iteration number: [3150/4518] 69% | Training loss: 0.6869896196372925
Epoch: 67 | Iteration number: [3160/4518] 69% | Training loss: 0.6869918142127085
Epoch: 67 | Iteration number: [3170/4518] 70% | Training loss: 0.6869914692095026
Epoch: 67 | Iteration number: [3180/4518] 70% | Training loss: 0.6869936019744514
Epoch: 67 | Iteration number: [3190/4518] 70% | Training loss: 0.6869912737962968
Epoch: 67 | Iteration number: [3200/4518] 70% | Training loss: 0.6869882547855377
Epoch: 67 | Iteration number: [3210/4518] 71% | Training loss: 0.6869905751442241
Epoch: 67 | Iteration number: [3220/4518] 71% | Training loss: 0.6869911175892219
Epoch: 67 | Iteration number: [3230/4518] 71% | Training loss: 0.686992044050258
Epoch: 67 | Iteration number: [3240/4518] 71% | Training loss: 0.6869895996870818
Epoch: 67 | Iteration number: [3250/4518] 71% | Training loss: 0.6869906600071833
Epoch: 67 | Iteration number: [3260/4518] 72% | Training loss: 0.6869894987783549
Epoch: 67 | Iteration number: [3270/4518] 72% | Training loss: 0.6869851088122855
Epoch: 67 | Iteration number: [3280/4518] 72% | Training loss: 0.6869823338600194
Epoch: 67 | Iteration number: [3290/4518] 72% | Training loss: 0.6869816262490119
Epoch: 67 | Iteration number: [3300/4518] 73% | Training loss: 0.6869845406214397
Epoch: 67 | Iteration number: [3310/4518] 73% | Training loss: 0.6869819187505728
Epoch: 67 | Iteration number: [3320/4518] 73% | Training loss: 0.6869823181126491
Epoch: 67 | Iteration number: [3330/4518] 73% | Training loss: 0.6869835621959812
Epoch: 67 | Iteration number: [3340/4518] 73% | Training loss: 0.6869844233204505
Epoch: 67 | Iteration number: [3350/4518] 74% | Training loss: 0.6869817170456274
Epoch: 67 | Iteration number: [3360/4518] 74% | Training loss: 0.686978559887835
Epoch: 67 | Iteration number: [3370/4518] 74% | Training loss: 0.6869774186823417
Epoch: 67 | Iteration number: [3380/4518] 74% | Training loss: 0.6869759007847521
Epoch: 67 | Iteration number: [3390/4518] 75% | Training loss: 0.6869759063277624
Epoch: 67 | Iteration number: [3400/4518] 75% | Training loss: 0.6869718616850236
Epoch: 67 | Iteration number: [3410/4518] 75% | Training loss: 0.6869757972504736
Epoch: 67 | Iteration number: [3420/4518] 75% | Training loss: 0.6869761297751589
Epoch: 67 | Iteration number: [3430/4518] 75% | Training loss: 0.6869757566611899
Epoch: 67 | Iteration number: [3440/4518] 76% | Training loss: 0.6869739601085353
Epoch: 67 | Iteration number: [3450/4518] 76% | Training loss: 0.6869777571118396
Epoch: 67 | Iteration number: [3460/4518] 76% | Training loss: 0.6869741429311003
Epoch: 67 | Iteration number: [3470/4518] 76% | Training loss: 0.6869759761119095
Epoch: 67 | Iteration number: [3480/4518] 77% | Training loss: 0.6869699599414036
Epoch: 67 | Iteration number: [3490/4518] 77% | Training loss: 0.6869679912284316
Epoch: 67 | Iteration number: [3500/4518] 77% | Training loss: 0.6869675067833492
Epoch: 67 | Iteration number: [3510/4518] 77% | Training loss: 0.6869673314597192
Epoch: 67 | Iteration number: [3520/4518] 77% | Training loss: 0.6869660742919553
Epoch: 67 | Iteration number: [3530/4518] 78% | Training loss: 0.6869625938850489
Epoch: 67 | Iteration number: [3540/4518] 78% | Training loss: 0.6869595161770696
Epoch: 67 | Iteration number: [3550/4518] 78% | Training loss: 0.6869597249131807
Epoch: 67 | Iteration number: [3560/4518] 78% | Training loss: 0.6869559195436789
Epoch: 67 | Iteration number: [3570/4518] 79% | Training loss: 0.686955005965647
Epoch: 67 | Iteration number: [3580/4518] 79% | Training loss: 0.6869539790979311
Epoch: 67 | Iteration number: [3590/4518] 79% | Training loss: 0.6869532933640281
Epoch: 67 | Iteration number: [3600/4518] 79% | Training loss: 0.6869508012632529
Epoch: 67 | Iteration number: [3610/4518] 79% | Training loss: 0.6869519835859125
Epoch: 67 | Iteration number: [3620/4518] 80% | Training loss: 0.6869544170344073
Epoch: 67 | Iteration number: [3630/4518] 80% | Training loss: 0.6869547287787288
Epoch: 67 | Iteration number: [3640/4518] 80% | Training loss: 0.6869512752680988
Epoch: 67 | Iteration number: [3650/4518] 80% | Training loss: 0.6869510647368757
Epoch: 67 | Iteration number: [3660/4518] 81% | Training loss: 0.6869477888111208
Epoch: 67 | Iteration number: [3670/4518] 81% | Training loss: 0.6869469764609428
Epoch: 67 | Iteration number: [3680/4518] 81% | Training loss: 0.6869448238578828
Epoch: 67 | Iteration number: [3690/4518] 81% | Training loss: 0.6869448654535341
Epoch: 67 | Iteration number: [3700/4518] 81% | Training loss: 0.6869454837328679
Epoch: 67 | Iteration number: [3710/4518] 82% | Training loss: 0.6869445999195634
Epoch: 67 | Iteration number: [3720/4518] 82% | Training loss: 0.6869432411847576
Epoch: 67 | Iteration number: [3730/4518] 82% | Training loss: 0.6869455554210468
Epoch: 67 | Iteration number: [3740/4518] 82% | Training loss: 0.6869472402142969
Epoch: 67 | Iteration number: [3750/4518] 83% | Training loss: 0.6869451159954071
Epoch: 67 | Iteration number: [3760/4518] 83% | Training loss: 0.6869464302792194
Epoch: 67 | Iteration number: [3770/4518] 83% | Training loss: 0.6869501761321364
Epoch: 67 | Iteration number: [3780/4518] 83% | Training loss: 0.6869532873706212
Epoch: 67 | Iteration number: [3790/4518] 83% | Training loss: 0.6869573475503041
Epoch: 67 | Iteration number: [3800/4518] 84% | Training loss: 0.6869605441783604
Epoch: 67 | Iteration number: [3810/4518] 84% | Training loss: 0.6869608146937813
Epoch: 67 | Iteration number: [3820/4518] 84% | Training loss: 0.6869602134246476
Epoch: 67 | Iteration number: [3830/4518] 84% | Training loss: 0.6869604835311053
Epoch: 67 | Iteration number: [3840/4518] 84% | Training loss: 0.6869611757186552
Epoch: 67 | Iteration number: [3850/4518] 85% | Training loss: 0.6869601691233648
Epoch: 67 | Iteration number: [3860/4518] 85% | Training loss: 0.6869610930971531
Epoch: 67 | Iteration number: [3870/4518] 85% | Training loss: 0.6869613735250725
Epoch: 67 | Iteration number: [3880/4518] 85% | Training loss: 0.6869609076030475
Epoch: 67 | Iteration number: [3890/4518] 86% | Training loss: 0.6869586015268586
Epoch: 67 | Iteration number: [3900/4518] 86% | Training loss: 0.6869600047820653
Epoch: 67 | Iteration number: [3910/4518] 86% | Training loss: 0.6869616216405883
Epoch: 67 | Iteration number: [3920/4518] 86% | Training loss: 0.6869616446750505
Epoch: 67 | Iteration number: [3930/4518] 86% | Training loss: 0.6869598151011624
Epoch: 67 | Iteration number: [3940/4518] 87% | Training loss: 0.6869596148959272
Epoch: 67 | Iteration number: [3950/4518] 87% | Training loss: 0.6869613694993756
Epoch: 67 | Iteration number: [3960/4518] 87% | Training loss: 0.6869609464298595
Epoch: 67 | Iteration number: [3970/4518] 87% | Training loss: 0.6869593363564921
Epoch: 67 | Iteration number: [3980/4518] 88% | Training loss: 0.6869574175408139
Epoch: 67 | Iteration number: [3990/4518] 88% | Training loss: 0.686960708616969
Epoch: 67 | Iteration number: [4000/4518] 88% | Training loss: 0.6869586270600557
Epoch: 67 | Iteration number: [4010/4518] 88% | Training loss: 0.6869602680949499
Epoch: 67 | Iteration number: [4020/4518] 88% | Training loss: 0.686956161898167
Epoch: 67 | Iteration number: [4030/4518] 89% | Training loss: 0.6869557289272621
Epoch: 67 | Iteration number: [4040/4518] 89% | Training loss: 0.6869543371961848
Epoch: 67 | Iteration number: [4050/4518] 89% | Training loss: 0.6869558353482941
Epoch: 67 | Iteration number: [4060/4518] 89% | Training loss: 0.686953247797313
Epoch: 67 | Iteration number: [4070/4518] 90% | Training loss: 0.686949998857934
Epoch: 67 | Iteration number: [4080/4518] 90% | Training loss: 0.6869495482713568
Epoch: 67 | Iteration number: [4090/4518] 90% | Training loss: 0.6869499391331941
Epoch: 67 | Iteration number: [4100/4518] 90% | Training loss: 0.6869484849383192
Epoch: 67 | Iteration number: [4110/4518] 90% | Training loss: 0.6869470809497973
Epoch: 67 | Iteration number: [4120/4518] 91% | Training loss: 0.6869486058076608
Epoch: 67 | Iteration number: [4130/4518] 91% | Training loss: 0.6869485181555621
Epoch: 67 | Iteration number: [4140/4518] 91% | Training loss: 0.68694571527306
Epoch: 67 | Iteration number: [4150/4518] 91% | Training loss: 0.6869445992665119
Epoch: 67 | Iteration number: [4160/4518] 92% | Training loss: 0.6869444587482856
Epoch: 67 | Iteration number: [4170/4518] 92% | Training loss: 0.6869453696181163
Epoch: 67 | Iteration number: [4180/4518] 92% | Training loss: 0.6869457961982517
Epoch: 67 | Iteration number: [4190/4518] 92% | Training loss: 0.6869448148407629
Epoch: 67 | Iteration number: [4200/4518] 92% | Training loss: 0.6869459906788099
Epoch: 67 | Iteration number: [4210/4518] 93% | Training loss: 0.6869417708871484
Epoch: 67 | Iteration number: [4220/4518] 93% | Training loss: 0.6869411814128054
Epoch: 67 | Iteration number: [4230/4518] 93% | Training loss: 0.6869409445752489
Epoch: 67 | Iteration number: [4240/4518] 93% | Training loss: 0.6869388092941833
Epoch: 67 | Iteration number: [4250/4518] 94% | Training loss: 0.6869407863336451
Epoch: 67 | Iteration number: [4260/4518] 94% | Training loss: 0.6869399200162977
Epoch: 67 | Iteration number: [4270/4518] 94% | Training loss: 0.6869387381249904
Epoch: 67 | Iteration number: [4280/4518] 94% | Training loss: 0.6869375801810594
Epoch: 67 | Iteration number: [4290/4518] 94% | Training loss: 0.6869405382163041
Epoch: 67 | Iteration number: [4300/4518] 95% | Training loss: 0.6869390934705735
Epoch: 67 | Iteration number: [4310/4518] 95% | Training loss: 0.6869390848756113
Epoch: 67 | Iteration number: [4320/4518] 95% | Training loss: 0.6869397480316736
Epoch: 67 | Iteration number: [4330/4518] 95% | Training loss: 0.6869392588700213
Epoch: 67 | Iteration number: [4340/4518] 96% | Training loss: 0.6869403869737678
Epoch: 67 | Iteration number: [4350/4518] 96% | Training loss: 0.6869377967132919
Epoch: 67 | Iteration number: [4360/4518] 96% | Training loss: 0.6869384111340987
Epoch: 67 | Iteration number: [4370/4518] 96% | Training loss: 0.6869419733092222
Epoch: 67 | Iteration number: [4380/4518] 96% | Training loss: 0.6869419463965446
Epoch: 67 | Iteration number: [4390/4518] 97% | Training loss: 0.6869422553612051
Epoch: 67 | Iteration number: [4400/4518] 97% | Training loss: 0.6869429821046916
Epoch: 67 | Iteration number: [4410/4518] 97% | Training loss: 0.6869428879684872
Epoch: 67 | Iteration number: [4420/4518] 97% | Training loss: 0.6869443811037961
Epoch: 67 | Iteration number: [4430/4518] 98% | Training loss: 0.6869478096407639
Epoch: 67 | Iteration number: [4440/4518] 98% | Training loss: 0.6869457854880943
Epoch: 67 | Iteration number: [4450/4518] 98% | Training loss: 0.6869476167271646
Epoch: 67 | Iteration number: [4460/4518] 98% | Training loss: 0.6869444273245174
Epoch: 67 | Iteration number: [4470/4518] 98% | Training loss: 0.6869443917567831
Epoch: 67 | Iteration number: [4480/4518] 99% | Training loss: 0.6869463724217244
Epoch: 67 | Iteration number: [4490/4518] 99% | Training loss: 0.6869444215483549
Epoch: 67 | Iteration number: [4500/4518] 99% | Training loss: 0.6869432314104504
Epoch: 67 | Iteration number: [4510/4518] 99% | Training loss: 0.6869421719843956

 End of epoch: 67 | Train Loss: 0.6867895479379581 | Training Time: 642 

 End of epoch: 67 | Eval Loss: 0.6900373563474539 | Evaluating Time: 17 
Epoch: 68 | Iteration number: [10/4518] 0% | Training loss: 0.755014032125473
Epoch: 68 | Iteration number: [20/4518] 0% | Training loss: 0.7210174053907394
Epoch: 68 | Iteration number: [30/4518] 0% | Training loss: 0.7094149430592854
Epoch: 68 | Iteration number: [40/4518] 0% | Training loss: 0.7037833362817765
Epoch: 68 | Iteration number: [50/4518] 1% | Training loss: 0.7003806221485138
Epoch: 68 | Iteration number: [60/4518] 1% | Training loss: 0.6982680877049764
Epoch: 68 | Iteration number: [70/4518] 1% | Training loss: 0.6967765952859606
Epoch: 68 | Iteration number: [80/4518] 1% | Training loss: 0.6954977102577686
Epoch: 68 | Iteration number: [90/4518] 1% | Training loss: 0.6944783091545105
Epoch: 68 | Iteration number: [100/4518] 2% | Training loss: 0.6936640220880509
Epoch: 68 | Iteration number: [110/4518] 2% | Training loss: 0.6930339916185899
Epoch: 68 | Iteration number: [120/4518] 2% | Training loss: 0.6925759648283323
Epoch: 68 | Iteration number: [130/4518] 2% | Training loss: 0.6921284863582025
Epoch: 68 | Iteration number: [140/4518] 3% | Training loss: 0.6917642985071455
Epoch: 68 | Iteration number: [150/4518] 3% | Training loss: 0.6914508366584777
Epoch: 68 | Iteration number: [160/4518] 3% | Training loss: 0.691183191537857
Epoch: 68 | Iteration number: [170/4518] 3% | Training loss: 0.6909930316840901
Epoch: 68 | Iteration number: [180/4518] 3% | Training loss: 0.6907898621426688
Epoch: 68 | Iteration number: [190/4518] 4% | Training loss: 0.6906527854894337
Epoch: 68 | Iteration number: [200/4518] 4% | Training loss: 0.6905119577050209
Epoch: 68 | Iteration number: [210/4518] 4% | Training loss: 0.6903174916903178
Epoch: 68 | Iteration number: [220/4518] 4% | Training loss: 0.6901460867036473
Epoch: 68 | Iteration number: [230/4518] 5% | Training loss: 0.6899708164774854
Epoch: 68 | Iteration number: [240/4518] 5% | Training loss: 0.689829558134079
Epoch: 68 | Iteration number: [250/4518] 5% | Training loss: 0.6897031881809235
Epoch: 68 | Iteration number: [260/4518] 5% | Training loss: 0.689577405498578
Epoch: 68 | Iteration number: [270/4518] 5% | Training loss: 0.6894948407455727
Epoch: 68 | Iteration number: [280/4518] 6% | Training loss: 0.6893921654139247
Epoch: 68 | Iteration number: [290/4518] 6% | Training loss: 0.6893398274635446
Epoch: 68 | Iteration number: [300/4518] 6% | Training loss: 0.6892361698547999
Epoch: 68 | Iteration number: [310/4518] 6% | Training loss: 0.6891205528090077
Epoch: 68 | Iteration number: [320/4518] 7% | Training loss: 0.6890539072453976
Epoch: 68 | Iteration number: [330/4518] 7% | Training loss: 0.6889288187026977
Epoch: 68 | Iteration number: [340/4518] 7% | Training loss: 0.688895960239803
Epoch: 68 | Iteration number: [350/4518] 7% | Training loss: 0.6888079178333283
Epoch: 68 | Iteration number: [360/4518] 7% | Training loss: 0.6887382353345554
Epoch: 68 | Iteration number: [370/4518] 8% | Training loss: 0.6886650805537765
Epoch: 68 | Iteration number: [380/4518] 8% | Training loss: 0.6886313689382453
Epoch: 68 | Iteration number: [390/4518] 8% | Training loss: 0.6885972240032294
Epoch: 68 | Iteration number: [400/4518] 8% | Training loss: 0.6885735078155995
Epoch: 68 | Iteration number: [410/4518] 9% | Training loss: 0.6885443819732201
Epoch: 68 | Iteration number: [420/4518] 9% | Training loss: 0.6885277600515456
Epoch: 68 | Iteration number: [430/4518] 9% | Training loss: 0.6884704200334327
Epoch: 68 | Iteration number: [440/4518] 9% | Training loss: 0.6884580574252389
Epoch: 68 | Iteration number: [450/4518] 9% | Training loss: 0.6884281060430739
Epoch: 68 | Iteration number: [460/4518] 10% | Training loss: 0.6883576483830162
Epoch: 68 | Iteration number: [470/4518] 10% | Training loss: 0.6883227164440967
Epoch: 68 | Iteration number: [480/4518] 10% | Training loss: 0.6882608387619257
Epoch: 68 | Iteration number: [490/4518] 10% | Training loss: 0.6882160642925574
Epoch: 68 | Iteration number: [500/4518] 11% | Training loss: 0.6881969697475433
Epoch: 68 | Iteration number: [510/4518] 11% | Training loss: 0.6881786754318312
Epoch: 68 | Iteration number: [520/4518] 11% | Training loss: 0.6881512550207285
Epoch: 68 | Iteration number: [530/4518] 11% | Training loss: 0.6881280441329164
Epoch: 68 | Iteration number: [540/4518] 11% | Training loss: 0.6880809522337383
Epoch: 68 | Iteration number: [550/4518] 12% | Training loss: 0.688063305941495
Epoch: 68 | Iteration number: [560/4518] 12% | Training loss: 0.6880617151302951
Epoch: 68 | Iteration number: [570/4518] 12% | Training loss: 0.6880172479570957
Epoch: 68 | Iteration number: [580/4518] 12% | Training loss: 0.688001491386315
Epoch: 68 | Iteration number: [590/4518] 13% | Training loss: 0.6879835863234633
Epoch: 68 | Iteration number: [600/4518] 13% | Training loss: 0.6879796200990677
Epoch: 68 | Iteration number: [610/4518] 13% | Training loss: 0.6879542086945205
Epoch: 68 | Iteration number: [620/4518] 13% | Training loss: 0.6879346457219893
Epoch: 68 | Iteration number: [630/4518] 13% | Training loss: 0.6879373571229359
Epoch: 68 | Iteration number: [640/4518] 14% | Training loss: 0.6879270839504897
Epoch: 68 | Iteration number: [650/4518] 14% | Training loss: 0.687910852432251
Epoch: 68 | Iteration number: [660/4518] 14% | Training loss: 0.6879022953185168
Epoch: 68 | Iteration number: [670/4518] 14% | Training loss: 0.6878938875981231
Epoch: 68 | Iteration number: [680/4518] 15% | Training loss: 0.6878607135485201
Epoch: 68 | Iteration number: [690/4518] 15% | Training loss: 0.687820153305496
Epoch: 68 | Iteration number: [700/4518] 15% | Training loss: 0.6878071815626962
Epoch: 68 | Iteration number: [710/4518] 15% | Training loss: 0.6878044588465086
Epoch: 68 | Iteration number: [720/4518] 15% | Training loss: 0.6877956546015209
Epoch: 68 | Iteration number: [730/4518] 16% | Training loss: 0.6877937685136926
Epoch: 68 | Iteration number: [740/4518] 16% | Training loss: 0.6877902476368724
Epoch: 68 | Iteration number: [750/4518] 16% | Training loss: 0.68778559867541
Epoch: 68 | Iteration number: [760/4518] 16% | Training loss: 0.6877650913439299
Epoch: 68 | Iteration number: [770/4518] 17% | Training loss: 0.6877445621923967
Epoch: 68 | Iteration number: [780/4518] 17% | Training loss: 0.6877284194414433
Epoch: 68 | Iteration number: [790/4518] 17% | Training loss: 0.6877062297320065
Epoch: 68 | Iteration number: [800/4518] 17% | Training loss: 0.6876919662952423
Epoch: 68 | Iteration number: [810/4518] 17% | Training loss: 0.6876781387093627
Epoch: 68 | Iteration number: [820/4518] 18% | Training loss: 0.6876527568915995
Epoch: 68 | Iteration number: [830/4518] 18% | Training loss: 0.6876526164003165
Epoch: 68 | Iteration number: [840/4518] 18% | Training loss: 0.6876511956964221
Epoch: 68 | Iteration number: [850/4518] 18% | Training loss: 0.6876507104845608
Epoch: 68 | Iteration number: [860/4518] 19% | Training loss: 0.6876403593739798
Epoch: 68 | Iteration number: [870/4518] 19% | Training loss: 0.6876249492168427
Epoch: 68 | Iteration number: [880/4518] 19% | Training loss: 0.6876181680370461
Epoch: 68 | Iteration number: [890/4518] 19% | Training loss: 0.6876204246215606
Epoch: 68 | Iteration number: [900/4518] 19% | Training loss: 0.6876000408993826
Epoch: 68 | Iteration number: [910/4518] 20% | Training loss: 0.6875964232853481
Epoch: 68 | Iteration number: [920/4518] 20% | Training loss: 0.6875731567325799
Epoch: 68 | Iteration number: [930/4518] 20% | Training loss: 0.6875659792013066
Epoch: 68 | Iteration number: [940/4518] 20% | Training loss: 0.6875670805890509
Epoch: 68 | Iteration number: [950/4518] 21% | Training loss: 0.6875620868958925
Epoch: 68 | Iteration number: [960/4518] 21% | Training loss: 0.6875463472058375
Epoch: 68 | Iteration number: [970/4518] 21% | Training loss: 0.6875454119800293
Epoch: 68 | Iteration number: [980/4518] 21% | Training loss: 0.6875317673293911
Epoch: 68 | Iteration number: [990/4518] 21% | Training loss: 0.6875331081525244
Epoch: 68 | Iteration number: [1000/4518] 22% | Training loss: 0.6875172970294953
Epoch: 68 | Iteration number: [1010/4518] 22% | Training loss: 0.687509013992725
Epoch: 68 | Iteration number: [1020/4518] 22% | Training loss: 0.6875074208951464
Epoch: 68 | Iteration number: [1030/4518] 22% | Training loss: 0.6874882872822216
Epoch: 68 | Iteration number: [1040/4518] 23% | Training loss: 0.6874824102681417
Epoch: 68 | Iteration number: [1050/4518] 23% | Training loss: 0.6874743663697016
Epoch: 68 | Iteration number: [1060/4518] 23% | Training loss: 0.6874864829598732
Epoch: 68 | Iteration number: [1070/4518] 23% | Training loss: 0.6874807693690898
Epoch: 68 | Iteration number: [1080/4518] 23% | Training loss: 0.6874772019960262
Epoch: 68 | Iteration number: [1090/4518] 24% | Training loss: 0.687450969984772
Epoch: 68 | Iteration number: [1100/4518] 24% | Training loss: 0.6874591118639166
Epoch: 68 | Iteration number: [1110/4518] 24% | Training loss: 0.6874529297824379
Epoch: 68 | Iteration number: [1120/4518] 24% | Training loss: 0.6874449828373534
Epoch: 68 | Iteration number: [1130/4518] 25% | Training loss: 0.6874314699552756
Epoch: 68 | Iteration number: [1140/4518] 25% | Training loss: 0.6874229029082415
Epoch: 68 | Iteration number: [1150/4518] 25% | Training loss: 0.6874139419327612
Epoch: 68 | Iteration number: [1160/4518] 25% | Training loss: 0.6874011334160278
Epoch: 68 | Iteration number: [1170/4518] 25% | Training loss: 0.6873933590884902
Epoch: 68 | Iteration number: [1180/4518] 26% | Training loss: 0.6873732672909559
Epoch: 68 | Iteration number: [1190/4518] 26% | Training loss: 0.6873758698210997
Epoch: 68 | Iteration number: [1200/4518] 26% | Training loss: 0.6873731852074464
Epoch: 68 | Iteration number: [1210/4518] 26% | Training loss: 0.6873727372855194
Epoch: 68 | Iteration number: [1220/4518] 27% | Training loss: 0.6873635223165887
Epoch: 68 | Iteration number: [1230/4518] 27% | Training loss: 0.6873563070607379
Epoch: 68 | Iteration number: [1240/4518] 27% | Training loss: 0.6873497704344411
Epoch: 68 | Iteration number: [1250/4518] 27% | Training loss: 0.687337117099762
Epoch: 68 | Iteration number: [1260/4518] 27% | Training loss: 0.6873404251204597
Epoch: 68 | Iteration number: [1270/4518] 28% | Training loss: 0.6873405642866149
Epoch: 68 | Iteration number: [1280/4518] 28% | Training loss: 0.6873325867578387
Epoch: 68 | Iteration number: [1290/4518] 28% | Training loss: 0.6873309111410333
Epoch: 68 | Iteration number: [1300/4518] 28% | Training loss: 0.6873304851697042
Epoch: 68 | Iteration number: [1310/4518] 28% | Training loss: 0.6873305596013105
Epoch: 68 | Iteration number: [1320/4518] 29% | Training loss: 0.6873083372459267
Epoch: 68 | Iteration number: [1330/4518] 29% | Training loss: 0.6872982834962974
Epoch: 68 | Iteration number: [1340/4518] 29% | Training loss: 0.6872905491003349
Epoch: 68 | Iteration number: [1350/4518] 29% | Training loss: 0.687283136844635
Epoch: 68 | Iteration number: [1360/4518] 30% | Training loss: 0.6872735752340625
Epoch: 68 | Iteration number: [1370/4518] 30% | Training loss: 0.6872646862137927
Epoch: 68 | Iteration number: [1380/4518] 30% | Training loss: 0.6872601004614346
Epoch: 68 | Iteration number: [1390/4518] 30% | Training loss: 0.6872627733851508
Epoch: 68 | Iteration number: [1400/4518] 30% | Training loss: 0.6872571903467178
Epoch: 68 | Iteration number: [1410/4518] 31% | Training loss: 0.6872602776432714
Epoch: 68 | Iteration number: [1420/4518] 31% | Training loss: 0.6872606080602592
Epoch: 68 | Iteration number: [1430/4518] 31% | Training loss: 0.6872607716313609
Epoch: 68 | Iteration number: [1440/4518] 31% | Training loss: 0.6872595398376385
Epoch: 68 | Iteration number: [1450/4518] 32% | Training loss: 0.687260064996522
Epoch: 68 | Iteration number: [1460/4518] 32% | Training loss: 0.687259353105336
Epoch: 68 | Iteration number: [1470/4518] 32% | Training loss: 0.6872535592439223
Epoch: 68 | Iteration number: [1480/4518] 32% | Training loss: 0.68724502691546
Epoch: 68 | Iteration number: [1490/4518] 32% | Training loss: 0.6872407855603518
Epoch: 68 | Iteration number: [1500/4518] 33% | Training loss: 0.6872334025303523
Epoch: 68 | Iteration number: [1510/4518] 33% | Training loss: 0.6872336593290038
Epoch: 68 | Iteration number: [1520/4518] 33% | Training loss: 0.6872385135606716
Epoch: 68 | Iteration number: [1530/4518] 33% | Training loss: 0.6872384946720272
Epoch: 68 | Iteration number: [1540/4518] 34% | Training loss: 0.6872325145191961
Epoch: 68 | Iteration number: [1550/4518] 34% | Training loss: 0.6872208981360158
Epoch: 68 | Iteration number: [1560/4518] 34% | Training loss: 0.6872244155177704
Epoch: 68 | Iteration number: [1570/4518] 34% | Training loss: 0.6872263379537376
Epoch: 68 | Iteration number: [1580/4518] 34% | Training loss: 0.6872236741494528
Epoch: 68 | Iteration number: [1590/4518] 35% | Training loss: 0.6872242283521208
Epoch: 68 | Iteration number: [1600/4518] 35% | Training loss: 0.687214659973979
Epoch: 68 | Iteration number: [1610/4518] 35% | Training loss: 0.6872080987654858
Epoch: 68 | Iteration number: [1620/4518] 35% | Training loss: 0.6872019405718203
Epoch: 68 | Iteration number: [1630/4518] 36% | Training loss: 0.6872015578615154
Epoch: 68 | Iteration number: [1640/4518] 36% | Training loss: 0.6872032756122147
Epoch: 68 | Iteration number: [1650/4518] 36% | Training loss: 0.6872077165589188
Epoch: 68 | Iteration number: [1660/4518] 36% | Training loss: 0.6872119079512286
Epoch: 68 | Iteration number: [1670/4518] 36% | Training loss: 0.6872032832956599
Epoch: 68 | Iteration number: [1680/4518] 37% | Training loss: 0.6871983761943522
Epoch: 68 | Iteration number: [1690/4518] 37% | Training loss: 0.6871900860374496
Epoch: 68 | Iteration number: [1700/4518] 37% | Training loss: 0.6871816049603855
Epoch: 68 | Iteration number: [1710/4518] 37% | Training loss: 0.6871842299985607
Epoch: 68 | Iteration number: [1720/4518] 38% | Training loss: 0.6871754809174426
Epoch: 68 | Iteration number: [1730/4518] 38% | Training loss: 0.6871759856022851
Epoch: 68 | Iteration number: [1740/4518] 38% | Training loss: 0.6871786450175034
Epoch: 68 | Iteration number: [1750/4518] 38% | Training loss: 0.687168911252703
Epoch: 68 | Iteration number: [1760/4518] 38% | Training loss: 0.6871674409305507
Epoch: 68 | Iteration number: [1770/4518] 39% | Training loss: 0.6871703458707885
Epoch: 68 | Iteration number: [1780/4518] 39% | Training loss: 0.687176652805189
Epoch: 68 | Iteration number: [1790/4518] 39% | Training loss: 0.6871683201310355
Epoch: 68 | Iteration number: [1800/4518] 39% | Training loss: 0.6871626838048299
Epoch: 68 | Iteration number: [1810/4518] 40% | Training loss: 0.6871679810529255
Epoch: 68 | Iteration number: [1820/4518] 40% | Training loss: 0.6871634750903308
Epoch: 68 | Iteration number: [1830/4518] 40% | Training loss: 0.6871549248369665
Epoch: 68 | Iteration number: [1840/4518] 40% | Training loss: 0.6871503759337508
Epoch: 68 | Iteration number: [1850/4518] 40% | Training loss: 0.6871517726537344
Epoch: 68 | Iteration number: [1860/4518] 41% | Training loss: 0.6871395450125458
Epoch: 68 | Iteration number: [1870/4518] 41% | Training loss: 0.6871417656939297
Epoch: 68 | Iteration number: [1880/4518] 41% | Training loss: 0.6871392264328104
Epoch: 68 | Iteration number: [1890/4518] 41% | Training loss: 0.6871403318864328
Epoch: 68 | Iteration number: [1900/4518] 42% | Training loss: 0.6871453169772499
Epoch: 68 | Iteration number: [1910/4518] 42% | Training loss: 0.6871460040826448
Epoch: 68 | Iteration number: [1920/4518] 42% | Training loss: 0.6871446039838095
Epoch: 68 | Iteration number: [1930/4518] 42% | Training loss: 0.6871390609543558
Epoch: 68 | Iteration number: [1940/4518] 42% | Training loss: 0.6871388502034944
Epoch: 68 | Iteration number: [1950/4518] 43% | Training loss: 0.6871372985839844
Epoch: 68 | Iteration number: [1960/4518] 43% | Training loss: 0.687132191141041
Epoch: 68 | Iteration number: [1970/4518] 43% | Training loss: 0.6871356248855591
Epoch: 68 | Iteration number: [1980/4518] 43% | Training loss: 0.6871326469411754
Epoch: 68 | Iteration number: [1990/4518] 44% | Training loss: 0.6871332066442499
Epoch: 68 | Iteration number: [2000/4518] 44% | Training loss: 0.6871278082430363
Epoch: 68 | Iteration number: [2010/4518] 44% | Training loss: 0.6871218994185699
Epoch: 68 | Iteration number: [2020/4518] 44% | Training loss: 0.6871237717642642
Epoch: 68 | Iteration number: [2030/4518] 44% | Training loss: 0.6871210850224706
Epoch: 68 | Iteration number: [2040/4518] 45% | Training loss: 0.6871086695907163
Epoch: 68 | Iteration number: [2050/4518] 45% | Training loss: 0.6871077320633865
Epoch: 68 | Iteration number: [2060/4518] 45% | Training loss: 0.6870995879751964
Epoch: 68 | Iteration number: [2070/4518] 45% | Training loss: 0.6871011252852454
Epoch: 68 | Iteration number: [2080/4518] 46% | Training loss: 0.6871026790485932
Epoch: 68 | Iteration number: [2090/4518] 46% | Training loss: 0.6870970943327726
Epoch: 68 | Iteration number: [2100/4518] 46% | Training loss: 0.6870948352416356
Epoch: 68 | Iteration number: [2110/4518] 46% | Training loss: 0.6870941381036387
Epoch: 68 | Iteration number: [2120/4518] 46% | Training loss: 0.6871010929627238
Epoch: 68 | Iteration number: [2130/4518] 47% | Training loss: 0.6871027591362805
Epoch: 68 | Iteration number: [2140/4518] 47% | Training loss: 0.6870976252255039
Epoch: 68 | Iteration number: [2150/4518] 47% | Training loss: 0.6870955392649007
Epoch: 68 | Iteration number: [2160/4518] 47% | Training loss: 0.6870911057624552
Epoch: 68 | Iteration number: [2170/4518] 48% | Training loss: 0.6870856827579885
Epoch: 68 | Iteration number: [2180/4518] 48% | Training loss: 0.6870871108606321
Epoch: 68 | Iteration number: [2190/4518] 48% | Training loss: 0.687087624802437
Epoch: 68 | Iteration number: [2200/4518] 48% | Training loss: 0.6870857502113689
Epoch: 68 | Iteration number: [2210/4518] 48% | Training loss: 0.6870834350585937
Epoch: 68 | Iteration number: [2220/4518] 49% | Training loss: 0.6870742875981976
Epoch: 68 | Iteration number: [2230/4518] 49% | Training loss: 0.6870669761046165
Epoch: 68 | Iteration number: [2240/4518] 49% | Training loss: 0.6870685869295682
Epoch: 68 | Iteration number: [2250/4518] 49% | Training loss: 0.6870701983504826
Epoch: 68 | Iteration number: [2260/4518] 50% | Training loss: 0.6870699750374903
Epoch: 68 | Iteration number: [2270/4518] 50% | Training loss: 0.6870698863189126
Epoch: 68 | Iteration number: [2280/4518] 50% | Training loss: 0.6870655702132927
Epoch: 68 | Iteration number: [2290/4518] 50% | Training loss: 0.6870630234610046
Epoch: 68 | Iteration number: [2300/4518] 50% | Training loss: 0.6870613785412001
Epoch: 68 | Iteration number: [2310/4518] 51% | Training loss: 0.6870602626047093
Epoch: 68 | Iteration number: [2320/4518] 51% | Training loss: 0.6870632853487443
Epoch: 68 | Iteration number: [2330/4518] 51% | Training loss: 0.6870617233120833
Epoch: 68 | Iteration number: [2340/4518] 51% | Training loss: 0.6870602214693005
Epoch: 68 | Iteration number: [2350/4518] 52% | Training loss: 0.68705597991639
Epoch: 68 | Iteration number: [2360/4518] 52% | Training loss: 0.6870513411649203
Epoch: 68 | Iteration number: [2370/4518] 52% | Training loss: 0.6870473405731379
Epoch: 68 | Iteration number: [2380/4518] 52% | Training loss: 0.6870447017815935
Epoch: 68 | Iteration number: [2390/4518] 52% | Training loss: 0.6870454298651867
Epoch: 68 | Iteration number: [2400/4518] 53% | Training loss: 0.6870477964977423
Epoch: 68 | Iteration number: [2410/4518] 53% | Training loss: 0.6870457243869909
Epoch: 68 | Iteration number: [2420/4518] 53% | Training loss: 0.6870432309375322
Epoch: 68 | Iteration number: [2430/4518] 53% | Training loss: 0.6870375388934289
Epoch: 68 | Iteration number: [2440/4518] 54% | Training loss: 0.6870368849302901
Epoch: 68 | Iteration number: [2450/4518] 54% | Training loss: 0.6870305655440506
Epoch: 68 | Iteration number: [2460/4518] 54% | Training loss: 0.6870280071002681
Epoch: 68 | Iteration number: [2470/4518] 54% | Training loss: 0.6870267008721587
Epoch: 68 | Iteration number: [2480/4518] 54% | Training loss: 0.6870276749374405
Epoch: 68 | Iteration number: [2490/4518] 55% | Training loss: 0.6870238537529865
Epoch: 68 | Iteration number: [2500/4518] 55% | Training loss: 0.6870188735961914
Epoch: 68 | Iteration number: [2510/4518] 55% | Training loss: 0.6870209960111109
Epoch: 68 | Iteration number: [2520/4518] 55% | Training loss: 0.6870204154934202
Epoch: 68 | Iteration number: [2530/4518] 55% | Training loss: 0.6870177183933409
Epoch: 68 | Iteration number: [2540/4518] 56% | Training loss: 0.6870182690188641
Epoch: 68 | Iteration number: [2550/4518] 56% | Training loss: 0.6870204672860164
Epoch: 68 | Iteration number: [2560/4518] 56% | Training loss: 0.6870182386599482
Epoch: 68 | Iteration number: [2570/4518] 56% | Training loss: 0.6870186055448733
Epoch: 68 | Iteration number: [2580/4518] 57% | Training loss: 0.6870212840017422
Epoch: 68 | Iteration number: [2590/4518] 57% | Training loss: 0.6870191401726491
Epoch: 68 | Iteration number: [2600/4518] 57% | Training loss: 0.6870203512677779
Epoch: 68 | Iteration number: [2610/4518] 57% | Training loss: 0.6870241808251859
Epoch: 68 | Iteration number: [2620/4518] 57% | Training loss: 0.6870223909616471
Epoch: 68 | Iteration number: [2630/4518] 58% | Training loss: 0.6870205120895299
Epoch: 68 | Iteration number: [2640/4518] 58% | Training loss: 0.6870204840871421
Epoch: 68 | Iteration number: [2650/4518] 58% | Training loss: 0.6870197314586279
Epoch: 68 | Iteration number: [2660/4518] 58% | Training loss: 0.6870203460293605
Epoch: 68 | Iteration number: [2670/4518] 59% | Training loss: 0.687020413929157
Epoch: 68 | Iteration number: [2680/4518] 59% | Training loss: 0.6870262799867943
Epoch: 68 | Iteration number: [2690/4518] 59% | Training loss: 0.687022908668979
Epoch: 68 | Iteration number: [2700/4518] 59% | Training loss: 0.6870237649811639
Epoch: 68 | Iteration number: [2710/4518] 59% | Training loss: 0.687021182955851
Epoch: 68 | Iteration number: [2720/4518] 60% | Training loss: 0.6870247312985799
Epoch: 68 | Iteration number: [2730/4518] 60% | Training loss: 0.6870252662962609
Epoch: 68 | Iteration number: [2740/4518] 60% | Training loss: 0.6870292702295484
Epoch: 68 | Iteration number: [2750/4518] 60% | Training loss: 0.6870293848731301
Epoch: 68 | Iteration number: [2760/4518] 61% | Training loss: 0.6870279781844305
Epoch: 68 | Iteration number: [2770/4518] 61% | Training loss: 0.6870308568546488
Epoch: 68 | Iteration number: [2780/4518] 61% | Training loss: 0.6870363606180219
Epoch: 68 | Iteration number: [2790/4518] 61% | Training loss: 0.6870371012704775
Epoch: 68 | Iteration number: [2800/4518] 61% | Training loss: 0.6870372771152429
Epoch: 68 | Iteration number: [2810/4518] 62% | Training loss: 0.6870341264480374
Epoch: 68 | Iteration number: [2820/4518] 62% | Training loss: 0.6870337401721495
Epoch: 68 | Iteration number: [2830/4518] 62% | Training loss: 0.6870342494110336
Epoch: 68 | Iteration number: [2840/4518] 62% | Training loss: 0.6870316993602564
Epoch: 68 | Iteration number: [2850/4518] 63% | Training loss: 0.6870273990170997
Epoch: 68 | Iteration number: [2860/4518] 63% | Training loss: 0.6870228910571212
Epoch: 68 | Iteration number: [2870/4518] 63% | Training loss: 0.687022588061954
Epoch: 68 | Iteration number: [2880/4518] 63% | Training loss: 0.6870196754526761
Epoch: 68 | Iteration number: [2890/4518] 63% | Training loss: 0.6870211250023034
Epoch: 68 | Iteration number: [2900/4518] 64% | Training loss: 0.6870188961357906
Epoch: 68 | Iteration number: [2910/4518] 64% | Training loss: 0.6870207489970623
Epoch: 68 | Iteration number: [2920/4518] 64% | Training loss: 0.6870170378317572
Epoch: 68 | Iteration number: [2930/4518] 64% | Training loss: 0.6870139334795825
Epoch: 68 | Iteration number: [2940/4518] 65% | Training loss: 0.6870119338538371
Epoch: 68 | Iteration number: [2950/4518] 65% | Training loss: 0.687011815653009
Epoch: 68 | Iteration number: [2960/4518] 65% | Training loss: 0.6870067064625186
Epoch: 68 | Iteration number: [2970/4518] 65% | Training loss: 0.6870035833381242
Epoch: 68 | Iteration number: [2980/4518] 65% | Training loss: 0.6869988124642596
Epoch: 68 | Iteration number: [2990/4518] 66% | Training loss: 0.6869981661887472
Epoch: 68 | Iteration number: [3000/4518] 66% | Training loss: 0.6869976952075958
Epoch: 68 | Iteration number: [3010/4518] 66% | Training loss: 0.6869925527873625
Epoch: 68 | Iteration number: [3020/4518] 66% | Training loss: 0.6869930313517716
Epoch: 68 | Iteration number: [3030/4518] 67% | Training loss: 0.6869916516758822
Epoch: 68 | Iteration number: [3040/4518] 67% | Training loss: 0.6869916560030297
Epoch: 68 | Iteration number: [3050/4518] 67% | Training loss: 0.686993025326338
Epoch: 68 | Iteration number: [3060/4518] 67% | Training loss: 0.6869941137584985
Epoch: 68 | Iteration number: [3070/4518] 67% | Training loss: 0.6869900800311992
Epoch: 68 | Iteration number: [3080/4518] 68% | Training loss: 0.6869906885476855
Epoch: 68 | Iteration number: [3090/4518] 68% | Training loss: 0.68698813000929
Epoch: 68 | Iteration number: [3100/4518] 68% | Training loss: 0.6869882108319191
Epoch: 68 | Iteration number: [3110/4518] 68% | Training loss: 0.6869867456112644
Epoch: 68 | Iteration number: [3120/4518] 69% | Training loss: 0.6869896661012601
Epoch: 68 | Iteration number: [3130/4518] 69% | Training loss: 0.6869887999452341
Epoch: 68 | Iteration number: [3140/4518] 69% | Training loss: 0.6869888850837756
Epoch: 68 | Iteration number: [3150/4518] 69% | Training loss: 0.6869873163624415
Epoch: 68 | Iteration number: [3160/4518] 69% | Training loss: 0.6869905335805084
Epoch: 68 | Iteration number: [3170/4518] 70% | Training loss: 0.6869898724255126
Epoch: 68 | Iteration number: [3180/4518] 70% | Training loss: 0.6869905291863208
Epoch: 68 | Iteration number: [3190/4518] 70% | Training loss: 0.6869878525831109
Epoch: 68 | Iteration number: [3200/4518] 70% | Training loss: 0.6869888549484312
Epoch: 68 | Iteration number: [3210/4518] 71% | Training loss: 0.6869857054261775
Epoch: 68 | Iteration number: [3220/4518] 71% | Training loss: 0.6869840345027284
Epoch: 68 | Iteration number: [3230/4518] 71% | Training loss: 0.6869834563311409
Epoch: 68 | Iteration number: [3240/4518] 71% | Training loss: 0.686983211301727
Epoch: 68 | Iteration number: [3250/4518] 71% | Training loss: 0.686983285665512
Epoch: 68 | Iteration number: [3260/4518] 72% | Training loss: 0.6869809084874721
Epoch: 68 | Iteration number: [3270/4518] 72% | Training loss: 0.6869787569257462
Epoch: 68 | Iteration number: [3280/4518] 72% | Training loss: 0.6869783141990987
Epoch: 68 | Iteration number: [3290/4518] 72% | Training loss: 0.6869797380861903
Epoch: 68 | Iteration number: [3300/4518] 73% | Training loss: 0.6869767525882432
Epoch: 68 | Iteration number: [3310/4518] 73% | Training loss: 0.6869756601008044
Epoch: 68 | Iteration number: [3320/4518] 73% | Training loss: 0.686976222586201
Epoch: 68 | Iteration number: [3330/4518] 73% | Training loss: 0.6869746006286896
Epoch: 68 | Iteration number: [3340/4518] 73% | Training loss: 0.6869781010165186
Epoch: 68 | Iteration number: [3350/4518] 74% | Training loss: 0.6869782564177442
Epoch: 68 | Iteration number: [3360/4518] 74% | Training loss: 0.6869747351145461
Epoch: 68 | Iteration number: [3370/4518] 74% | Training loss: 0.6869762279513328
Epoch: 68 | Iteration number: [3380/4518] 74% | Training loss: 0.6869757079513821
Epoch: 68 | Iteration number: [3390/4518] 75% | Training loss: 0.6869779025383052
Epoch: 68 | Iteration number: [3400/4518] 75% | Training loss: 0.6869738242556067
Epoch: 68 | Iteration number: [3410/4518] 75% | Training loss: 0.6869748039154713
Epoch: 68 | Iteration number: [3420/4518] 75% | Training loss: 0.6869701073357933
Epoch: 68 | Iteration number: [3430/4518] 75% | Training loss: 0.6869712109120872
Epoch: 68 | Iteration number: [3440/4518] 76% | Training loss: 0.6869706472338633
Epoch: 68 | Iteration number: [3450/4518] 76% | Training loss: 0.6869673798913541
Epoch: 68 | Iteration number: [3460/4518] 76% | Training loss: 0.6869702344512664
Epoch: 68 | Iteration number: [3470/4518] 76% | Training loss: 0.6869672234532469
Epoch: 68 | Iteration number: [3480/4518] 77% | Training loss: 0.6869691854749603
Epoch: 68 | Iteration number: [3490/4518] 77% | Training loss: 0.6869656247532471
Epoch: 68 | Iteration number: [3500/4518] 77% | Training loss: 0.6869624381746564
Epoch: 68 | Iteration number: [3510/4518] 77% | Training loss: 0.6869626942013743
Epoch: 68 | Iteration number: [3520/4518] 77% | Training loss: 0.6869614421813326
Epoch: 68 | Iteration number: [3530/4518] 78% | Training loss: 0.6869646997357225
Epoch: 68 | Iteration number: [3540/4518] 78% | Training loss: 0.6869612411758994
Epoch: 68 | Iteration number: [3550/4518] 78% | Training loss: 0.6869601514809568
Epoch: 68 | Iteration number: [3560/4518] 78% | Training loss: 0.6869626860940055
Epoch: 68 | Iteration number: [3570/4518] 79% | Training loss: 0.686962045207411
Epoch: 68 | Iteration number: [3580/4518] 79% | Training loss: 0.6869611684503502
Epoch: 68 | Iteration number: [3590/4518] 79% | Training loss: 0.6869597568319369
Epoch: 68 | Iteration number: [3600/4518] 79% | Training loss: 0.6869631482164065
Epoch: 68 | Iteration number: [3610/4518] 79% | Training loss: 0.6869649420319501
Epoch: 68 | Iteration number: [3620/4518] 80% | Training loss: 0.6869613445101522
Epoch: 68 | Iteration number: [3630/4518] 80% | Training loss: 0.6869646245126225
Epoch: 68 | Iteration number: [3640/4518] 80% | Training loss: 0.6869660820934799
Epoch: 68 | Iteration number: [3650/4518] 80% | Training loss: 0.6869652882830738
Epoch: 68 | Iteration number: [3660/4518] 81% | Training loss: 0.6869626573851851
Epoch: 68 | Iteration number: [3670/4518] 81% | Training loss: 0.6869598847806291
Epoch: 68 | Iteration number: [3680/4518] 81% | Training loss: 0.6869573577590611
Epoch: 68 | Iteration number: [3690/4518] 81% | Training loss: 0.6869558554031662
Epoch: 68 | Iteration number: [3700/4518] 81% | Training loss: 0.6869511164040178
Epoch: 68 | Iteration number: [3710/4518] 82% | Training loss: 0.6869520460016966
Epoch: 68 | Iteration number: [3720/4518] 82% | Training loss: 0.6869527583801618
Epoch: 68 | Iteration number: [3730/4518] 82% | Training loss: 0.6869538947660226
Epoch: 68 | Iteration number: [3740/4518] 82% | Training loss: 0.686955664677416
Epoch: 68 | Iteration number: [3750/4518] 83% | Training loss: 0.6869539900461833
Epoch: 68 | Iteration number: [3760/4518] 83% | Training loss: 0.6869522486595397
Epoch: 68 | Iteration number: [3770/4518] 83% | Training loss: 0.6869552450882029
Epoch: 68 | Iteration number: [3780/4518] 83% | Training loss: 0.6869574112393869
Epoch: 68 | Iteration number: [3790/4518] 83% | Training loss: 0.6869595915629555
Epoch: 68 | Iteration number: [3800/4518] 84% | Training loss: 0.686956587653411
Epoch: 68 | Iteration number: [3810/4518] 84% | Training loss: 0.6869564065783043
Epoch: 68 | Iteration number: [3820/4518] 84% | Training loss: 0.6869561890501003
Epoch: 68 | Iteration number: [3830/4518] 84% | Training loss: 0.6869572333816448
Epoch: 68 | Iteration number: [3840/4518] 84% | Training loss: 0.6869581200027217
Epoch: 68 | Iteration number: [3850/4518] 85% | Training loss: 0.6869545732999777
Epoch: 68 | Iteration number: [3860/4518] 85% | Training loss: 0.6869496593357985
Epoch: 68 | Iteration number: [3870/4518] 85% | Training loss: 0.686946544828957
Epoch: 68 | Iteration number: [3880/4518] 85% | Training loss: 0.6869481916740997
Epoch: 68 | Iteration number: [3890/4518] 86% | Training loss: 0.6869468561634613
Epoch: 68 | Iteration number: [3900/4518] 86% | Training loss: 0.686946560495939
Epoch: 68 | Iteration number: [3910/4518] 86% | Training loss: 0.686950517432464
Epoch: 68 | Iteration number: [3920/4518] 86% | Training loss: 0.6869489236297656
Epoch: 68 | Iteration number: [3930/4518] 86% | Training loss: 0.6869491119117834
Epoch: 68 | Iteration number: [3940/4518] 87% | Training loss: 0.6869461111005792
Epoch: 68 | Iteration number: [3950/4518] 87% | Training loss: 0.686947513456586
Epoch: 68 | Iteration number: [3960/4518] 87% | Training loss: 0.6869474932551384
Epoch: 68 | Iteration number: [3970/4518] 87% | Training loss: 0.6869438687860215
Epoch: 68 | Iteration number: [3980/4518] 88% | Training loss: 0.6869430695646372
Epoch: 68 | Iteration number: [3990/4518] 88% | Training loss: 0.6869442126207185
Epoch: 68 | Iteration number: [4000/4518] 88% | Training loss: 0.6869427748769522
Epoch: 68 | Iteration number: [4010/4518] 88% | Training loss: 0.6869425490907303
Epoch: 68 | Iteration number: [4020/4518] 88% | Training loss: 0.6869392382268289
Epoch: 68 | Iteration number: [4030/4518] 89% | Training loss: 0.686937420643293
Epoch: 68 | Iteration number: [4040/4518] 89% | Training loss: 0.686936547467024
Epoch: 68 | Iteration number: [4050/4518] 89% | Training loss: 0.6869350714595229
Epoch: 68 | Iteration number: [4060/4518] 89% | Training loss: 0.6869356340815869
Epoch: 68 | Iteration number: [4070/4518] 90% | Training loss: 0.6869369914988628
Epoch: 68 | Iteration number: [4080/4518] 90% | Training loss: 0.6869372228343112
Epoch: 68 | Iteration number: [4090/4518] 90% | Training loss: 0.686937915943654
Epoch: 68 | Iteration number: [4100/4518] 90% | Training loss: 0.6869370014783813
Epoch: 68 | Iteration number: [4110/4518] 90% | Training loss: 0.6869363946201157
Epoch: 68 | Iteration number: [4120/4518] 91% | Training loss: 0.6869398131098562
Epoch: 68 | Iteration number: [4130/4518] 91% | Training loss: 0.6869417497378574
Epoch: 68 | Iteration number: [4140/4518] 91% | Training loss: 0.6869390042795651
Epoch: 68 | Iteration number: [4150/4518] 91% | Training loss: 0.6869418914490435
Epoch: 68 | Iteration number: [4160/4518] 92% | Training loss: 0.6869438219815492
Epoch: 68 | Iteration number: [4170/4518] 92% | Training loss: 0.6869451077864897
Epoch: 68 | Iteration number: [4180/4518] 92% | Training loss: 0.6869433689915962
Epoch: 68 | Iteration number: [4190/4518] 92% | Training loss: 0.6869445968641587
Epoch: 68 | Iteration number: [4200/4518] 92% | Training loss: 0.686946338954426
Epoch: 68 | Iteration number: [4210/4518] 93% | Training loss: 0.6869467221359742
Epoch: 68 | Iteration number: [4220/4518] 93% | Training loss: 0.6869470003656867
Epoch: 68 | Iteration number: [4230/4518] 93% | Training loss: 0.6869471895215641
Epoch: 68 | Iteration number: [4240/4518] 93% | Training loss: 0.6869497632783539
Epoch: 68 | Iteration number: [4250/4518] 94% | Training loss: 0.6869499441595639
Epoch: 68 | Iteration number: [4260/4518] 94% | Training loss: 0.6869481275059248
Epoch: 68 | Iteration number: [4270/4518] 94% | Training loss: 0.6869451014163622
Epoch: 68 | Iteration number: [4280/4518] 94% | Training loss: 0.6869471711811618
Epoch: 68 | Iteration number: [4290/4518] 94% | Training loss: 0.686948720850311
Epoch: 68 | Iteration number: [4300/4518] 95% | Training loss: 0.6869492647536966
Epoch: 68 | Iteration number: [4310/4518] 95% | Training loss: 0.686948882427127
Epoch: 68 | Iteration number: [4320/4518] 95% | Training loss: 0.6869493990170735
Epoch: 68 | Iteration number: [4330/4518] 95% | Training loss: 0.686949873672622
Epoch: 68 | Iteration number: [4340/4518] 96% | Training loss: 0.6869488446668546
Epoch: 68 | Iteration number: [4350/4518] 96% | Training loss: 0.6869509780406952
Epoch: 68 | Iteration number: [4360/4518] 96% | Training loss: 0.6869532432988149
Epoch: 68 | Iteration number: [4370/4518] 96% | Training loss: 0.6869548568600102
Epoch: 68 | Iteration number: [4380/4518] 96% | Training loss: 0.6869538307053857
Epoch: 68 | Iteration number: [4390/4518] 97% | Training loss: 0.68695438483853
Epoch: 68 | Iteration number: [4400/4518] 97% | Training loss: 0.6869515949894082
Epoch: 68 | Iteration number: [4410/4518] 97% | Training loss: 0.6869463500252116
Epoch: 68 | Iteration number: [4420/4518] 97% | Training loss: 0.6869476227064478
Epoch: 68 | Iteration number: [4430/4518] 98% | Training loss: 0.6869491222076975
Epoch: 68 | Iteration number: [4440/4518] 98% | Training loss: 0.6869462489544809
Epoch: 68 | Iteration number: [4450/4518] 98% | Training loss: 0.6869450586431481
Epoch: 68 | Iteration number: [4460/4518] 98% | Training loss: 0.6869455347948544
Epoch: 68 | Iteration number: [4470/4518] 98% | Training loss: 0.6869445059523487
Epoch: 68 | Iteration number: [4480/4518] 99% | Training loss: 0.6869429280582283
Epoch: 68 | Iteration number: [4490/4518] 99% | Training loss: 0.6869441566329225
Epoch: 68 | Iteration number: [4500/4518] 99% | Training loss: 0.6869406247006522
Epoch: 68 | Iteration number: [4510/4518] 99% | Training loss: 0.6869399641807751

 End of epoch: 68 | Train Loss: 0.6867880872547653 | Training Time: 642 

 End of epoch: 68 | Eval Loss: 0.6900923142627794 | Evaluating Time: 17 
Epoch: 69 | Iteration number: [10/4518] 0% | Training loss: 0.7549995124340058
Epoch: 69 | Iteration number: [20/4518] 0% | Training loss: 0.7206823498010635
Epoch: 69 | Iteration number: [30/4518] 0% | Training loss: 0.7091457724571228
Epoch: 69 | Iteration number: [40/4518] 0% | Training loss: 0.7035988703370094
Epoch: 69 | Iteration number: [50/4518] 1% | Training loss: 0.7000511813163758
Epoch: 69 | Iteration number: [60/4518] 1% | Training loss: 0.697717335820198
Epoch: 69 | Iteration number: [70/4518] 1% | Training loss: 0.6963368254048484
Epoch: 69 | Iteration number: [80/4518] 1% | Training loss: 0.6951695904135704
Epoch: 69 | Iteration number: [90/4518] 1% | Training loss: 0.6943605131573147
Epoch: 69 | Iteration number: [100/4518] 2% | Training loss: 0.6935691493749618
Epoch: 69 | Iteration number: [110/4518] 2% | Training loss: 0.692852870984511
Epoch: 69 | Iteration number: [120/4518] 2% | Training loss: 0.6922951713204384
Epoch: 69 | Iteration number: [130/4518] 2% | Training loss: 0.6918345772303067
Epoch: 69 | Iteration number: [140/4518] 3% | Training loss: 0.6914610913821629
Epoch: 69 | Iteration number: [150/4518] 3% | Training loss: 0.6911089670658112
Epoch: 69 | Iteration number: [160/4518] 3% | Training loss: 0.6908544208854437
Epoch: 69 | Iteration number: [170/4518] 3% | Training loss: 0.6906020227600547
Epoch: 69 | Iteration number: [180/4518] 3% | Training loss: 0.6903331882423824
Epoch: 69 | Iteration number: [190/4518] 4% | Training loss: 0.6901619399848737
Epoch: 69 | Iteration number: [200/4518] 4% | Training loss: 0.6900093361735344
Epoch: 69 | Iteration number: [210/4518] 4% | Training loss: 0.6898245465187799
Epoch: 69 | Iteration number: [220/4518] 4% | Training loss: 0.689629204435782
Epoch: 69 | Iteration number: [230/4518] 5% | Training loss: 0.6894767183324565
Epoch: 69 | Iteration number: [240/4518] 5% | Training loss: 0.689342825114727
Epoch: 69 | Iteration number: [250/4518] 5% | Training loss: 0.6892233858108521
Epoch: 69 | Iteration number: [260/4518] 5% | Training loss: 0.6891207568920575
Epoch: 69 | Iteration number: [270/4518] 5% | Training loss: 0.6890384610052462
Epoch: 69 | Iteration number: [280/4518] 6% | Training loss: 0.6889647398676191
Epoch: 69 | Iteration number: [290/4518] 6% | Training loss: 0.6888504015988317
Epoch: 69 | Iteration number: [300/4518] 6% | Training loss: 0.6888253883520762
Epoch: 69 | Iteration number: [310/4518] 6% | Training loss: 0.6887717366218566
Epoch: 69 | Iteration number: [320/4518] 7% | Training loss: 0.6887509673833847
Epoch: 69 | Iteration number: [330/4518] 7% | Training loss: 0.68870821649378
Epoch: 69 | Iteration number: [340/4518] 7% | Training loss: 0.6886355915490319
Epoch: 69 | Iteration number: [350/4518] 7% | Training loss: 0.6885779253074101
Epoch: 69 | Iteration number: [360/4518] 7% | Training loss: 0.6885333052939839
Epoch: 69 | Iteration number: [370/4518] 8% | Training loss: 0.6885129089291031
Epoch: 69 | Iteration number: [380/4518] 8% | Training loss: 0.6884973394243341
Epoch: 69 | Iteration number: [390/4518] 8% | Training loss: 0.6884370485941569
Epoch: 69 | Iteration number: [400/4518] 8% | Training loss: 0.6884011280536652
Epoch: 69 | Iteration number: [410/4518] 9% | Training loss: 0.6883446830074962
Epoch: 69 | Iteration number: [420/4518] 9% | Training loss: 0.6882577914567221
Epoch: 69 | Iteration number: [430/4518] 9% | Training loss: 0.688230572606242
Epoch: 69 | Iteration number: [440/4518] 9% | Training loss: 0.6881946024569598
Epoch: 69 | Iteration number: [450/4518] 9% | Training loss: 0.6881436236699422
Epoch: 69 | Iteration number: [460/4518] 10% | Training loss: 0.6881148413471554
Epoch: 69 | Iteration number: [470/4518] 10% | Training loss: 0.6880709559359449
Epoch: 69 | Iteration number: [480/4518] 10% | Training loss: 0.6880368759234746
Epoch: 69 | Iteration number: [490/4518] 10% | Training loss: 0.6880000916062569
Epoch: 69 | Iteration number: [500/4518] 11% | Training loss: 0.6879776953458786
Epoch: 69 | Iteration number: [510/4518] 11% | Training loss: 0.6879502166719997
Epoch: 69 | Iteration number: [520/4518] 11% | Training loss: 0.6879039631440089
Epoch: 69 | Iteration number: [530/4518] 11% | Training loss: 0.687875549410874
Epoch: 69 | Iteration number: [540/4518] 11% | Training loss: 0.6878585418065389
Epoch: 69 | Iteration number: [550/4518] 12% | Training loss: 0.6878486939993772
Epoch: 69 | Iteration number: [560/4518] 12% | Training loss: 0.6878282187240464
Epoch: 69 | Iteration number: [570/4518] 12% | Training loss: 0.6878227146048295
Epoch: 69 | Iteration number: [580/4518] 12% | Training loss: 0.687799634193552
Epoch: 69 | Iteration number: [590/4518] 13% | Training loss: 0.6877967116186174
Epoch: 69 | Iteration number: [600/4518] 13% | Training loss: 0.6877901765704155
Epoch: 69 | Iteration number: [610/4518] 13% | Training loss: 0.6877485348552954
Epoch: 69 | Iteration number: [620/4518] 13% | Training loss: 0.687755038372932
Epoch: 69 | Iteration number: [630/4518] 13% | Training loss: 0.6877179597105298
Epoch: 69 | Iteration number: [640/4518] 14% | Training loss: 0.6877033045515418
Epoch: 69 | Iteration number: [650/4518] 14% | Training loss: 0.687687174998797
Epoch: 69 | Iteration number: [660/4518] 14% | Training loss: 0.6876759042342504
Epoch: 69 | Iteration number: [670/4518] 14% | Training loss: 0.6876723501219678
Epoch: 69 | Iteration number: [680/4518] 15% | Training loss: 0.6876487161306774
Epoch: 69 | Iteration number: [690/4518] 15% | Training loss: 0.6876319913760476
Epoch: 69 | Iteration number: [700/4518] 15% | Training loss: 0.6876263367278236
Epoch: 69 | Iteration number: [710/4518] 15% | Training loss: 0.6876271371270569
Epoch: 69 | Iteration number: [720/4518] 15% | Training loss: 0.687629864199294
Epoch: 69 | Iteration number: [730/4518] 16% | Training loss: 0.6876216807594038
Epoch: 69 | Iteration number: [740/4518] 16% | Training loss: 0.6876265982518325
Epoch: 69 | Iteration number: [750/4518] 16% | Training loss: 0.6876264760494232
Epoch: 69 | Iteration number: [760/4518] 16% | Training loss: 0.6876253858992928
Epoch: 69 | Iteration number: [770/4518] 17% | Training loss: 0.6876217118331365
Epoch: 69 | Iteration number: [780/4518] 17% | Training loss: 0.6875952834502245
Epoch: 69 | Iteration number: [790/4518] 17% | Training loss: 0.6875988100902943
Epoch: 69 | Iteration number: [800/4518] 17% | Training loss: 0.6875789181888103
Epoch: 69 | Iteration number: [810/4518] 17% | Training loss: 0.6875667551417409
Epoch: 69 | Iteration number: [820/4518] 18% | Training loss: 0.6875540944134316
Epoch: 69 | Iteration number: [830/4518] 18% | Training loss: 0.687547338655196
Epoch: 69 | Iteration number: [840/4518] 18% | Training loss: 0.6875439127995855
Epoch: 69 | Iteration number: [850/4518] 18% | Training loss: 0.6875364957837498
Epoch: 69 | Iteration number: [860/4518] 19% | Training loss: 0.687525244715602
Epoch: 69 | Iteration number: [870/4518] 19% | Training loss: 0.6875162331537269
Epoch: 69 | Iteration number: [880/4518] 19% | Training loss: 0.6875131983648647
Epoch: 69 | Iteration number: [890/4518] 19% | Training loss: 0.6875032373358695
Epoch: 69 | Iteration number: [900/4518] 19% | Training loss: 0.6874854360686408
Epoch: 69 | Iteration number: [910/4518] 20% | Training loss: 0.6874865520786453
Epoch: 69 | Iteration number: [920/4518] 20% | Training loss: 0.6874689611403838
Epoch: 69 | Iteration number: [930/4518] 20% | Training loss: 0.6874501036700382
Epoch: 69 | Iteration number: [940/4518] 20% | Training loss: 0.6874465513102552
Epoch: 69 | Iteration number: [950/4518] 21% | Training loss: 0.6874376948256241
Epoch: 69 | Iteration number: [960/4518] 21% | Training loss: 0.6874329714104533
Epoch: 69 | Iteration number: [970/4518] 21% | Training loss: 0.6874268531184835
Epoch: 69 | Iteration number: [980/4518] 21% | Training loss: 0.6874252444627333
Epoch: 69 | Iteration number: [990/4518] 21% | Training loss: 0.6874143108575032
Epoch: 69 | Iteration number: [1000/4518] 22% | Training loss: 0.6874163508415222
Epoch: 69 | Iteration number: [1010/4518] 22% | Training loss: 0.6874088621965729
Epoch: 69 | Iteration number: [1020/4518] 22% | Training loss: 0.6874054346598831
Epoch: 69 | Iteration number: [1030/4518] 22% | Training loss: 0.6873942041281358
Epoch: 69 | Iteration number: [1040/4518] 23% | Training loss: 0.6873913575250369
Epoch: 69 | Iteration number: [1050/4518] 23% | Training loss: 0.6873963296413421
Epoch: 69 | Iteration number: [1060/4518] 23% | Training loss: 0.6873770932543952
Epoch: 69 | Iteration number: [1070/4518] 23% | Training loss: 0.6873655734218169
Epoch: 69 | Iteration number: [1080/4518] 23% | Training loss: 0.6873591957268892
Epoch: 69 | Iteration number: [1090/4518] 24% | Training loss: 0.6873458898942405
Epoch: 69 | Iteration number: [1100/4518] 24% | Training loss: 0.6873379344289953
Epoch: 69 | Iteration number: [1110/4518] 24% | Training loss: 0.6873308323525094
Epoch: 69 | Iteration number: [1120/4518] 24% | Training loss: 0.6873282083443233
Epoch: 69 | Iteration number: [1130/4518] 25% | Training loss: 0.6873099249548617
Epoch: 69 | Iteration number: [1140/4518] 25% | Training loss: 0.6873060805232901
Epoch: 69 | Iteration number: [1150/4518] 25% | Training loss: 0.6873069563119307
Epoch: 69 | Iteration number: [1160/4518] 25% | Training loss: 0.6872970822042432
Epoch: 69 | Iteration number: [1170/4518] 25% | Training loss: 0.6872965243127611
Epoch: 69 | Iteration number: [1180/4518] 26% | Training loss: 0.6872867149316658
Epoch: 69 | Iteration number: [1190/4518] 26% | Training loss: 0.6872760939998787
Epoch: 69 | Iteration number: [1200/4518] 26% | Training loss: 0.687276969452699
Epoch: 69 | Iteration number: [1210/4518] 26% | Training loss: 0.6872708762972808
Epoch: 69 | Iteration number: [1220/4518] 27% | Training loss: 0.6872724353778558
Epoch: 69 | Iteration number: [1230/4518] 27% | Training loss: 0.6872652100353707
Epoch: 69 | Iteration number: [1240/4518] 27% | Training loss: 0.6872508728696454
Epoch: 69 | Iteration number: [1250/4518] 27% | Training loss: 0.6872470298767089
Epoch: 69 | Iteration number: [1260/4518] 27% | Training loss: 0.6872490199785384
Epoch: 69 | Iteration number: [1270/4518] 28% | Training loss: 0.6872435145490752
Epoch: 69 | Iteration number: [1280/4518] 28% | Training loss: 0.6872413279954344
Epoch: 69 | Iteration number: [1290/4518] 28% | Training loss: 0.6872376252514447
Epoch: 69 | Iteration number: [1300/4518] 28% | Training loss: 0.6872342885457552
Epoch: 69 | Iteration number: [1310/4518] 28% | Training loss: 0.6872255683400249
Epoch: 69 | Iteration number: [1320/4518] 29% | Training loss: 0.6872254084908601
Epoch: 69 | Iteration number: [1330/4518] 29% | Training loss: 0.6872159289686304
Epoch: 69 | Iteration number: [1340/4518] 29% | Training loss: 0.6872113698454045
Epoch: 69 | Iteration number: [1350/4518] 29% | Training loss: 0.6872157817858237
Epoch: 69 | Iteration number: [1360/4518] 30% | Training loss: 0.6872195752666277
Epoch: 69 | Iteration number: [1370/4518] 30% | Training loss: 0.6872214971232589
Epoch: 69 | Iteration number: [1380/4518] 30% | Training loss: 0.6872118926134663
Epoch: 69 | Iteration number: [1390/4518] 30% | Training loss: 0.6872134425228448
Epoch: 69 | Iteration number: [1400/4518] 30% | Training loss: 0.687207444012165
Epoch: 69 | Iteration number: [1410/4518] 31% | Training loss: 0.6872002230045643
Epoch: 69 | Iteration number: [1420/4518] 31% | Training loss: 0.6872085276623847
Epoch: 69 | Iteration number: [1430/4518] 31% | Training loss: 0.6872088927489061
Epoch: 69 | Iteration number: [1440/4518] 31% | Training loss: 0.6872102302395635
Epoch: 69 | Iteration number: [1450/4518] 32% | Training loss: 0.6872044898723734
Epoch: 69 | Iteration number: [1460/4518] 32% | Training loss: 0.6872078103561924
Epoch: 69 | Iteration number: [1470/4518] 32% | Training loss: 0.687202209477522
Epoch: 69 | Iteration number: [1480/4518] 32% | Training loss: 0.6871959435778695
Epoch: 69 | Iteration number: [1490/4518] 32% | Training loss: 0.687193426989869
Epoch: 69 | Iteration number: [1500/4518] 33% | Training loss: 0.6871934030056
Epoch: 69 | Iteration number: [1510/4518] 33% | Training loss: 0.6871919590905802
Epoch: 69 | Iteration number: [1520/4518] 33% | Training loss: 0.6871846121392752
Epoch: 69 | Iteration number: [1530/4518] 33% | Training loss: 0.6871841423651751
Epoch: 69 | Iteration number: [1540/4518] 34% | Training loss: 0.6871844975592254
Epoch: 69 | Iteration number: [1550/4518] 34% | Training loss: 0.6871775696739074
Epoch: 69 | Iteration number: [1560/4518] 34% | Training loss: 0.6871739216721975
Epoch: 69 | Iteration number: [1570/4518] 34% | Training loss: 0.6871721384251953
Epoch: 69 | Iteration number: [1580/4518] 34% | Training loss: 0.687169659816766
Epoch: 69 | Iteration number: [1590/4518] 35% | Training loss: 0.6871598784278774
Epoch: 69 | Iteration number: [1600/4518] 35% | Training loss: 0.6871613270044327
Epoch: 69 | Iteration number: [1610/4518] 35% | Training loss: 0.687161466127597
Epoch: 69 | Iteration number: [1620/4518] 35% | Training loss: 0.6871596650944816
Epoch: 69 | Iteration number: [1630/4518] 36% | Training loss: 0.6871465294273353
Epoch: 69 | Iteration number: [1640/4518] 36% | Training loss: 0.6871416843155536
Epoch: 69 | Iteration number: [1650/4518] 36% | Training loss: 0.6871365942377032
Epoch: 69 | Iteration number: [1660/4518] 36% | Training loss: 0.6871411685124937
Epoch: 69 | Iteration number: [1670/4518] 36% | Training loss: 0.6871482469364555
Epoch: 69 | Iteration number: [1680/4518] 37% | Training loss: 0.6871456337117013
Epoch: 69 | Iteration number: [1690/4518] 37% | Training loss: 0.6871422301382708
Epoch: 69 | Iteration number: [1700/4518] 37% | Training loss: 0.687150757523144
Epoch: 69 | Iteration number: [1710/4518] 37% | Training loss: 0.6871511647227215
Epoch: 69 | Iteration number: [1720/4518] 38% | Training loss: 0.687137958407402
Epoch: 69 | Iteration number: [1730/4518] 38% | Training loss: 0.687140636843753
Epoch: 69 | Iteration number: [1740/4518] 38% | Training loss: 0.6871419794600585
Epoch: 69 | Iteration number: [1750/4518] 38% | Training loss: 0.6871384746006557
Epoch: 69 | Iteration number: [1760/4518] 38% | Training loss: 0.6871355615217577
Epoch: 69 | Iteration number: [1770/4518] 39% | Training loss: 0.6871349098655464
Epoch: 69 | Iteration number: [1780/4518] 39% | Training loss: 0.6871286996294943
Epoch: 69 | Iteration number: [1790/4518] 39% | Training loss: 0.6871315343086946
Epoch: 69 | Iteration number: [1800/4518] 39% | Training loss: 0.6871287288930681
Epoch: 69 | Iteration number: [1810/4518] 40% | Training loss: 0.6871253273763709
Epoch: 69 | Iteration number: [1820/4518] 40% | Training loss: 0.6871202744297928
Epoch: 69 | Iteration number: [1830/4518] 40% | Training loss: 0.6871150291682593
Epoch: 69 | Iteration number: [1840/4518] 40% | Training loss: 0.6871167076022728
Epoch: 69 | Iteration number: [1850/4518] 40% | Training loss: 0.6871137745960338
Epoch: 69 | Iteration number: [1860/4518] 41% | Training loss: 0.6871121307214101
Epoch: 69 | Iteration number: [1870/4518] 41% | Training loss: 0.6871022253112997
Epoch: 69 | Iteration number: [1880/4518] 41% | Training loss: 0.6871003741913654
Epoch: 69 | Iteration number: [1890/4518] 41% | Training loss: 0.6871021683569307
Epoch: 69 | Iteration number: [1900/4518] 42% | Training loss: 0.687101736884368
Epoch: 69 | Iteration number: [1910/4518] 42% | Training loss: 0.6870942242170504
Epoch: 69 | Iteration number: [1920/4518] 42% | Training loss: 0.6870888884800176
Epoch: 69 | Iteration number: [1930/4518] 42% | Training loss: 0.6870841033718129
Epoch: 69 | Iteration number: [1940/4518] 42% | Training loss: 0.68708514374556
Epoch: 69 | Iteration number: [1950/4518] 43% | Training loss: 0.6870906824637683
Epoch: 69 | Iteration number: [1960/4518] 43% | Training loss: 0.6870891880015938
Epoch: 69 | Iteration number: [1970/4518] 43% | Training loss: 0.6870928521083697
Epoch: 69 | Iteration number: [1980/4518] 43% | Training loss: 0.6870897571847896
Epoch: 69 | Iteration number: [1990/4518] 44% | Training loss: 0.6870829751144103
Epoch: 69 | Iteration number: [2000/4518] 44% | Training loss: 0.6870826923847199
Epoch: 69 | Iteration number: [2010/4518] 44% | Training loss: 0.6870846916193986
Epoch: 69 | Iteration number: [2020/4518] 44% | Training loss: 0.6870838747461243
Epoch: 69 | Iteration number: [2030/4518] 44% | Training loss: 0.687078647484333
Epoch: 69 | Iteration number: [2040/4518] 45% | Training loss: 0.6870727361125104
Epoch: 69 | Iteration number: [2050/4518] 45% | Training loss: 0.6870682864945109
Epoch: 69 | Iteration number: [2060/4518] 45% | Training loss: 0.6870623287066673
Epoch: 69 | Iteration number: [2070/4518] 45% | Training loss: 0.6870622556854561
Epoch: 69 | Iteration number: [2080/4518] 46% | Training loss: 0.687059294919555
Epoch: 69 | Iteration number: [2090/4518] 46% | Training loss: 0.6870592431303417
Epoch: 69 | Iteration number: [2100/4518] 46% | Training loss: 0.687057433837936
Epoch: 69 | Iteration number: [2110/4518] 46% | Training loss: 0.6870528880736274
Epoch: 69 | Iteration number: [2120/4518] 46% | Training loss: 0.6870554063117729
Epoch: 69 | Iteration number: [2130/4518] 47% | Training loss: 0.6870588910971449
Epoch: 69 | Iteration number: [2140/4518] 47% | Training loss: 0.6870625279774175
Epoch: 69 | Iteration number: [2150/4518] 47% | Training loss: 0.6870614789253058
Epoch: 69 | Iteration number: [2160/4518] 47% | Training loss: 0.6870610944374844
Epoch: 69 | Iteration number: [2170/4518] 48% | Training loss: 0.6870584957061275
Epoch: 69 | Iteration number: [2180/4518] 48% | Training loss: 0.6870594923102528
Epoch: 69 | Iteration number: [2190/4518] 48% | Training loss: 0.687057123418268
Epoch: 69 | Iteration number: [2200/4518] 48% | Training loss: 0.6870488067919558
Epoch: 69 | Iteration number: [2210/4518] 48% | Training loss: 0.6870500098795912
Epoch: 69 | Iteration number: [2220/4518] 49% | Training loss: 0.6870446158422007
Epoch: 69 | Iteration number: [2230/4518] 49% | Training loss: 0.6870468169317118
Epoch: 69 | Iteration number: [2240/4518] 49% | Training loss: 0.6870459306985139
Epoch: 69 | Iteration number: [2250/4518] 49% | Training loss: 0.6870474995242225
Epoch: 69 | Iteration number: [2260/4518] 50% | Training loss: 0.6870424130057866
Epoch: 69 | Iteration number: [2270/4518] 50% | Training loss: 0.6870395670640836
Epoch: 69 | Iteration number: [2280/4518] 50% | Training loss: 0.6870455299814542
Epoch: 69 | Iteration number: [2290/4518] 50% | Training loss: 0.6870489297215074
Epoch: 69 | Iteration number: [2300/4518] 50% | Training loss: 0.6870423205520796
Epoch: 69 | Iteration number: [2310/4518] 51% | Training loss: 0.6870396973250749
Epoch: 69 | Iteration number: [2320/4518] 51% | Training loss: 0.6870426017919491
Epoch: 69 | Iteration number: [2330/4518] 51% | Training loss: 0.6870453808952299
Epoch: 69 | Iteration number: [2340/4518] 51% | Training loss: 0.6870450340529792
Epoch: 69 | Iteration number: [2350/4518] 52% | Training loss: 0.6870453506834964
Epoch: 69 | Iteration number: [2360/4518] 52% | Training loss: 0.6870461752101527
Epoch: 69 | Iteration number: [2370/4518] 52% | Training loss: 0.6870498303119643
Epoch: 69 | Iteration number: [2380/4518] 52% | Training loss: 0.6870539305841221
Epoch: 69 | Iteration number: [2390/4518] 52% | Training loss: 0.6870499795450825
Epoch: 69 | Iteration number: [2400/4518] 53% | Training loss: 0.6870514732847611
Epoch: 69 | Iteration number: [2410/4518] 53% | Training loss: 0.6870498404710619
Epoch: 69 | Iteration number: [2420/4518] 53% | Training loss: 0.6870450321554152
Epoch: 69 | Iteration number: [2430/4518] 53% | Training loss: 0.6870439900047004
Epoch: 69 | Iteration number: [2440/4518] 54% | Training loss: 0.687043256544676
Epoch: 69 | Iteration number: [2450/4518] 54% | Training loss: 0.687039447657916
Epoch: 69 | Iteration number: [2460/4518] 54% | Training loss: 0.687044029797965
Epoch: 69 | Iteration number: [2470/4518] 54% | Training loss: 0.6870462866688547
Epoch: 69 | Iteration number: [2480/4518] 54% | Training loss: 0.687043283158733
Epoch: 69 | Iteration number: [2490/4518] 55% | Training loss: 0.687047578915056
Epoch: 69 | Iteration number: [2500/4518] 55% | Training loss: 0.6870454273700715
Epoch: 69 | Iteration number: [2510/4518] 55% | Training loss: 0.6870498343530405
Epoch: 69 | Iteration number: [2520/4518] 55% | Training loss: 0.6870498072769907
Epoch: 69 | Iteration number: [2530/4518] 55% | Training loss: 0.6870485037683027
Epoch: 69 | Iteration number: [2540/4518] 56% | Training loss: 0.6870483431994445
Epoch: 69 | Iteration number: [2550/4518] 56% | Training loss: 0.6870473276633843
Epoch: 69 | Iteration number: [2560/4518] 56% | Training loss: 0.6870422422420234
Epoch: 69 | Iteration number: [2570/4518] 56% | Training loss: 0.6870411871472222
Epoch: 69 | Iteration number: [2580/4518] 57% | Training loss: 0.6870432187651478
Epoch: 69 | Iteration number: [2590/4518] 57% | Training loss: 0.6870426705905369
Epoch: 69 | Iteration number: [2600/4518] 57% | Training loss: 0.6870421367425185
Epoch: 69 | Iteration number: [2610/4518] 57% | Training loss: 0.6870370642663876
Epoch: 69 | Iteration number: [2620/4518] 57% | Training loss: 0.6870360124202175
Epoch: 69 | Iteration number: [2630/4518] 58% | Training loss: 0.6870342163531953
Epoch: 69 | Iteration number: [2640/4518] 58% | Training loss: 0.6870355168075273
Epoch: 69 | Iteration number: [2650/4518] 58% | Training loss: 0.6870332644345626
Epoch: 69 | Iteration number: [2660/4518] 58% | Training loss: 0.6870345030736206
Epoch: 69 | Iteration number: [2670/4518] 59% | Training loss: 0.6870410300819169
Epoch: 69 | Iteration number: [2680/4518] 59% | Training loss: 0.6870425152022447
Epoch: 69 | Iteration number: [2690/4518] 59% | Training loss: 0.6870438169812624
Epoch: 69 | Iteration number: [2700/4518] 59% | Training loss: 0.6870413600956952
Epoch: 69 | Iteration number: [2710/4518] 59% | Training loss: 0.6870441107072514
Epoch: 69 | Iteration number: [2720/4518] 60% | Training loss: 0.6870476729291327
Epoch: 69 | Iteration number: [2730/4518] 60% | Training loss: 0.6870453788902297
Epoch: 69 | Iteration number: [2740/4518] 60% | Training loss: 0.6870466884035263
Epoch: 69 | Iteration number: [2750/4518] 60% | Training loss: 0.6870485193079168
Epoch: 69 | Iteration number: [2760/4518] 61% | Training loss: 0.6870515721863595
Epoch: 69 | Iteration number: [2770/4518] 61% | Training loss: 0.6870519402440274
Epoch: 69 | Iteration number: [2780/4518] 61% | Training loss: 0.6870498959752296
Epoch: 69 | Iteration number: [2790/4518] 61% | Training loss: 0.6870485066085733
Epoch: 69 | Iteration number: [2800/4518] 61% | Training loss: 0.6870536873170308
Epoch: 69 | Iteration number: [2810/4518] 62% | Training loss: 0.6870523667632473
Epoch: 69 | Iteration number: [2820/4518] 62% | Training loss: 0.6870515735436838
Epoch: 69 | Iteration number: [2830/4518] 62% | Training loss: 0.6870508781170255
Epoch: 69 | Iteration number: [2840/4518] 62% | Training loss: 0.6870457649440832
Epoch: 69 | Iteration number: [2850/4518] 63% | Training loss: 0.6870418948457953
Epoch: 69 | Iteration number: [2860/4518] 63% | Training loss: 0.6870424809155764
Epoch: 69 | Iteration number: [2870/4518] 63% | Training loss: 0.6870428496952257
Epoch: 69 | Iteration number: [2880/4518] 63% | Training loss: 0.6870402265547051
Epoch: 69 | Iteration number: [2890/4518] 63% | Training loss: 0.6870424336628106
Epoch: 69 | Iteration number: [2900/4518] 64% | Training loss: 0.687040774185082
Epoch: 69 | Iteration number: [2910/4518] 64% | Training loss: 0.6870400114772246
Epoch: 69 | Iteration number: [2920/4518] 64% | Training loss: 0.6870383849086826
Epoch: 69 | Iteration number: [2930/4518] 64% | Training loss: 0.6870352574175942
Epoch: 69 | Iteration number: [2940/4518] 65% | Training loss: 0.6870327835180321
Epoch: 69 | Iteration number: [2950/4518] 65% | Training loss: 0.6870328194003994
Epoch: 69 | Iteration number: [2960/4518] 65% | Training loss: 0.6870293578586063
Epoch: 69 | Iteration number: [2970/4518] 65% | Training loss: 0.6870326839713536
Epoch: 69 | Iteration number: [2980/4518] 65% | Training loss: 0.6870318337374886
Epoch: 69 | Iteration number: [2990/4518] 66% | Training loss: 0.6870282716974366
Epoch: 69 | Iteration number: [3000/4518] 66% | Training loss: 0.6870268653035164
Epoch: 69 | Iteration number: [3010/4518] 66% | Training loss: 0.6870234086465994
Epoch: 69 | Iteration number: [3020/4518] 66% | Training loss: 0.6870223480344608
Epoch: 69 | Iteration number: [3030/4518] 67% | Training loss: 0.6870190007458425
Epoch: 69 | Iteration number: [3040/4518] 67% | Training loss: 0.6870202433906103
Epoch: 69 | Iteration number: [3050/4518] 67% | Training loss: 0.6870173093334573
Epoch: 69 | Iteration number: [3060/4518] 67% | Training loss: 0.6870181106858784
Epoch: 69 | Iteration number: [3070/4518] 67% | Training loss: 0.6870183855198105
Epoch: 69 | Iteration number: [3080/4518] 68% | Training loss: 0.687019054862586
Epoch: 69 | Iteration number: [3090/4518] 68% | Training loss: 0.6870200772308609
Epoch: 69 | Iteration number: [3100/4518] 68% | Training loss: 0.6870142097626963
Epoch: 69 | Iteration number: [3110/4518] 68% | Training loss: 0.6870104976980632
Epoch: 69 | Iteration number: [3120/4518] 69% | Training loss: 0.6870126475317356
Epoch: 69 | Iteration number: [3130/4518] 69% | Training loss: 0.6870116201071693
Epoch: 69 | Iteration number: [3140/4518] 69% | Training loss: 0.6870097630722507
Epoch: 69 | Iteration number: [3150/4518] 69% | Training loss: 0.6870121052719298
Epoch: 69 | Iteration number: [3160/4518] 69% | Training loss: 0.6870102557011798
Epoch: 69 | Iteration number: [3170/4518] 70% | Training loss: 0.6870120021070968
Epoch: 69 | Iteration number: [3180/4518] 70% | Training loss: 0.6870111525995927
Epoch: 69 | Iteration number: [3190/4518] 70% | Training loss: 0.6870106674287013
Epoch: 69 | Iteration number: [3200/4518] 70% | Training loss: 0.6870103612169624
Epoch: 69 | Iteration number: [3210/4518] 71% | Training loss: 0.6870067821856228
Epoch: 69 | Iteration number: [3220/4518] 71% | Training loss: 0.6870065547109391
Epoch: 69 | Iteration number: [3230/4518] 71% | Training loss: 0.6870061850953767
Epoch: 69 | Iteration number: [3240/4518] 71% | Training loss: 0.6870069398372262
Epoch: 69 | Iteration number: [3250/4518] 71% | Training loss: 0.6870040820745321
Epoch: 69 | Iteration number: [3260/4518] 72% | Training loss: 0.6870032067496352
Epoch: 69 | Iteration number: [3270/4518] 72% | Training loss: 0.6870074558695521
Epoch: 69 | Iteration number: [3280/4518] 72% | Training loss: 0.6870040590079819
Epoch: 69 | Iteration number: [3290/4518] 72% | Training loss: 0.6870053464699661
Epoch: 69 | Iteration number: [3300/4518] 73% | Training loss: 0.6870003794540058
Epoch: 69 | Iteration number: [3310/4518] 73% | Training loss: 0.6870014610427384
Epoch: 69 | Iteration number: [3320/4518] 73% | Training loss: 0.6870010079928192
Epoch: 69 | Iteration number: [3330/4518] 73% | Training loss: 0.6869951393511202
Epoch: 69 | Iteration number: [3340/4518] 73% | Training loss: 0.686993265901497
Epoch: 69 | Iteration number: [3350/4518] 74% | Training loss: 0.6869901683259366
Epoch: 69 | Iteration number: [3360/4518] 74% | Training loss: 0.6869873578704538
Epoch: 69 | Iteration number: [3370/4518] 74% | Training loss: 0.6869876982196502
Epoch: 69 | Iteration number: [3380/4518] 74% | Training loss: 0.6869866393021578
Epoch: 69 | Iteration number: [3390/4518] 75% | Training loss: 0.6869852878702777
Epoch: 69 | Iteration number: [3400/4518] 75% | Training loss: 0.6869873112440109
Epoch: 69 | Iteration number: [3410/4518] 75% | Training loss: 0.6869923337813346
Epoch: 69 | Iteration number: [3420/4518] 75% | Training loss: 0.6869919498761495
Epoch: 69 | Iteration number: [3430/4518] 75% | Training loss: 0.6869917419839531
Epoch: 69 | Iteration number: [3440/4518] 76% | Training loss: 0.686990954085838
Epoch: 69 | Iteration number: [3450/4518] 76% | Training loss: 0.6869915292228478
Epoch: 69 | Iteration number: [3460/4518] 76% | Training loss: 0.686987355816571
Epoch: 69 | Iteration number: [3470/4518] 76% | Training loss: 0.6869910012576353
Epoch: 69 | Iteration number: [3480/4518] 77% | Training loss: 0.6869883417055525
Epoch: 69 | Iteration number: [3490/4518] 77% | Training loss: 0.6869893929507466
Epoch: 69 | Iteration number: [3500/4518] 77% | Training loss: 0.6869899368456431
Epoch: 69 | Iteration number: [3510/4518] 77% | Training loss: 0.6869881184692057
Epoch: 69 | Iteration number: [3520/4518] 77% | Training loss: 0.6869850412857803
Epoch: 69 | Iteration number: [3530/4518] 78% | Training loss: 0.6869868509323671
Epoch: 69 | Iteration number: [3540/4518] 78% | Training loss: 0.6869848065457101
Epoch: 69 | Iteration number: [3550/4518] 78% | Training loss: 0.6869858654284141
Epoch: 69 | Iteration number: [3560/4518] 78% | Training loss: 0.6869854997717932
Epoch: 69 | Iteration number: [3570/4518] 79% | Training loss: 0.6869890941291296
Epoch: 69 | Iteration number: [3580/4518] 79% | Training loss: 0.6869883609883612
Epoch: 69 | Iteration number: [3590/4518] 79% | Training loss: 0.6869857857652362
Epoch: 69 | Iteration number: [3600/4518] 79% | Training loss: 0.6869819271067779
Epoch: 69 | Iteration number: [3610/4518] 79% | Training loss: 0.6869789783809324
Epoch: 69 | Iteration number: [3620/4518] 80% | Training loss: 0.6869794749587939
Epoch: 69 | Iteration number: [3630/4518] 80% | Training loss: 0.6869787353457827
Epoch: 69 | Iteration number: [3640/4518] 80% | Training loss: 0.6869815325507751
Epoch: 69 | Iteration number: [3650/4518] 80% | Training loss: 0.6869799277063918
Epoch: 69 | Iteration number: [3660/4518] 81% | Training loss: 0.6869818762514761
Epoch: 69 | Iteration number: [3670/4518] 81% | Training loss: 0.6869793814274531
Epoch: 69 | Iteration number: [3680/4518] 81% | Training loss: 0.6869801511745091
Epoch: 69 | Iteration number: [3690/4518] 81% | Training loss: 0.6869821452836035
Epoch: 69 | Iteration number: [3700/4518] 81% | Training loss: 0.6869806187861675
Epoch: 69 | Iteration number: [3710/4518] 82% | Training loss: 0.6869789697089286
Epoch: 69 | Iteration number: [3720/4518] 82% | Training loss: 0.686979430529379
Epoch: 69 | Iteration number: [3730/4518] 82% | Training loss: 0.6869800799334017
Epoch: 69 | Iteration number: [3740/4518] 82% | Training loss: 0.6869795871290931
Epoch: 69 | Iteration number: [3750/4518] 83% | Training loss: 0.6869786588827769
Epoch: 69 | Iteration number: [3760/4518] 83% | Training loss: 0.68697540427142
Epoch: 69 | Iteration number: [3770/4518] 83% | Training loss: 0.6869777327190976
Epoch: 69 | Iteration number: [3780/4518] 83% | Training loss: 0.6869771916241872
Epoch: 69 | Iteration number: [3790/4518] 83% | Training loss: 0.6869729938481918
Epoch: 69 | Iteration number: [3800/4518] 84% | Training loss: 0.6869743835769202
Epoch: 69 | Iteration number: [3810/4518] 84% | Training loss: 0.6869758503017775
Epoch: 69 | Iteration number: [3820/4518] 84% | Training loss: 0.6869781999219775
Epoch: 69 | Iteration number: [3830/4518] 84% | Training loss: 0.6869802367282598
Epoch: 69 | Iteration number: [3840/4518] 84% | Training loss: 0.6869782967803378
Epoch: 69 | Iteration number: [3850/4518] 85% | Training loss: 0.686975750737376
Epoch: 69 | Iteration number: [3860/4518] 85% | Training loss: 0.6869763927292948
Epoch: 69 | Iteration number: [3870/4518] 85% | Training loss: 0.6869774616195866
Epoch: 69 | Iteration number: [3880/4518] 85% | Training loss: 0.686976315372998
Epoch: 69 | Iteration number: [3890/4518] 86% | Training loss: 0.6869757013792857
Epoch: 69 | Iteration number: [3900/4518] 86% | Training loss: 0.6869743085518861
Epoch: 69 | Iteration number: [3910/4518] 86% | Training loss: 0.6869717132100059
Epoch: 69 | Iteration number: [3920/4518] 86% | Training loss: 0.6869677910543218
Epoch: 69 | Iteration number: [3930/4518] 86% | Training loss: 0.6869665258258354
Epoch: 69 | Iteration number: [3940/4518] 87% | Training loss: 0.6869621210745749
Epoch: 69 | Iteration number: [3950/4518] 87% | Training loss: 0.6869648721097391
Epoch: 69 | Iteration number: [3960/4518] 87% | Training loss: 0.6869665120436688
Epoch: 69 | Iteration number: [3970/4518] 87% | Training loss: 0.6869640711572969
Epoch: 69 | Iteration number: [3980/4518] 88% | Training loss: 0.6869623008535136
Epoch: 69 | Iteration number: [3990/4518] 88% | Training loss: 0.6869616541497988
Epoch: 69 | Iteration number: [4000/4518] 88% | Training loss: 0.6869600155949592
Epoch: 69 | Iteration number: [4010/4518] 88% | Training loss: 0.686959558101069
Epoch: 69 | Iteration number: [4020/4518] 88% | Training loss: 0.6869598704487531
Epoch: 69 | Iteration number: [4030/4518] 89% | Training loss: 0.6869599019623276
Epoch: 69 | Iteration number: [4040/4518] 89% | Training loss: 0.6869604932494683
Epoch: 69 | Iteration number: [4050/4518] 89% | Training loss: 0.6869627247180468
Epoch: 69 | Iteration number: [4060/4518] 89% | Training loss: 0.6869628310350362
Epoch: 69 | Iteration number: [4070/4518] 90% | Training loss: 0.6869600958408243
Epoch: 69 | Iteration number: [4080/4518] 90% | Training loss: 0.6869591704040181
Epoch: 69 | Iteration number: [4090/4518] 90% | Training loss: 0.6869555101709436
Epoch: 69 | Iteration number: [4100/4518] 90% | Training loss: 0.6869564030664723
Epoch: 69 | Iteration number: [4110/4518] 90% | Training loss: 0.6869593108222433
Epoch: 69 | Iteration number: [4120/4518] 91% | Training loss: 0.6869599880234709
Epoch: 69 | Iteration number: [4130/4518] 91% | Training loss: 0.6869606696520244
Epoch: 69 | Iteration number: [4140/4518] 91% | Training loss: 0.6869599773400071
Epoch: 69 | Iteration number: [4150/4518] 91% | Training loss: 0.6869584603912859
Epoch: 69 | Iteration number: [4160/4518] 92% | Training loss: 0.6869542149826884
Epoch: 69 | Iteration number: [4170/4518] 92% | Training loss: 0.6869534246212573
Epoch: 69 | Iteration number: [4180/4518] 92% | Training loss: 0.6869529410269842
Epoch: 69 | Iteration number: [4190/4518] 92% | Training loss: 0.6869516023872576
Epoch: 69 | Iteration number: [4200/4518] 92% | Training loss: 0.6869499418990953
Epoch: 69 | Iteration number: [4210/4518] 93% | Training loss: 0.6869466790394092
Epoch: 69 | Iteration number: [4220/4518] 93% | Training loss: 0.6869487207930235
Epoch: 69 | Iteration number: [4230/4518] 93% | Training loss: 0.6869472185066124
Epoch: 69 | Iteration number: [4240/4518] 93% | Training loss: 0.6869459789878917
Epoch: 69 | Iteration number: [4250/4518] 94% | Training loss: 0.686945564845029
Epoch: 69 | Iteration number: [4260/4518] 94% | Training loss: 0.6869403105246629
Epoch: 69 | Iteration number: [4270/4518] 94% | Training loss: 0.6869421786670105
Epoch: 69 | Iteration number: [4280/4518] 94% | Training loss: 0.6869395873953249
Epoch: 69 | Iteration number: [4290/4518] 94% | Training loss: 0.6869406538409787
Epoch: 69 | Iteration number: [4300/4518] 95% | Training loss: 0.686940378602161
Epoch: 69 | Iteration number: [4310/4518] 95% | Training loss: 0.6869363844947859
Epoch: 69 | Iteration number: [4320/4518] 95% | Training loss: 0.6869357234211984
Epoch: 69 | Iteration number: [4330/4518] 95% | Training loss: 0.6869364052116183
Epoch: 69 | Iteration number: [4340/4518] 96% | Training loss: 0.6869374373404111
Epoch: 69 | Iteration number: [4350/4518] 96% | Training loss: 0.6869354386028202
Epoch: 69 | Iteration number: [4360/4518] 96% | Training loss: 0.6869294839304522
Epoch: 69 | Iteration number: [4370/4518] 96% | Training loss: 0.6869273159132943
Epoch: 69 | Iteration number: [4380/4518] 96% | Training loss: 0.6869287085995827
Epoch: 69 | Iteration number: [4390/4518] 97% | Training loss: 0.686932125110561
Epoch: 69 | Iteration number: [4400/4518] 97% | Training loss: 0.6869308086687869
Epoch: 69 | Iteration number: [4410/4518] 97% | Training loss: 0.6869333187063265
Epoch: 69 | Iteration number: [4420/4518] 97% | Training loss: 0.6869331604080502
Epoch: 69 | Iteration number: [4430/4518] 98% | Training loss: 0.6869380781128498
Epoch: 69 | Iteration number: [4440/4518] 98% | Training loss: 0.6869358796525646
Epoch: 69 | Iteration number: [4450/4518] 98% | Training loss: 0.6869370674551203
Epoch: 69 | Iteration number: [4460/4518] 98% | Training loss: 0.686937030401465
Epoch: 69 | Iteration number: [4470/4518] 98% | Training loss: 0.6869359081623538
Epoch: 69 | Iteration number: [4480/4518] 99% | Training loss: 0.6869357084988483
Epoch: 69 | Iteration number: [4490/4518] 99% | Training loss: 0.6869349737209838
Epoch: 69 | Iteration number: [4500/4518] 99% | Training loss: 0.6869365469879575
Epoch: 69 | Iteration number: [4510/4518] 99% | Training loss: 0.6869382536860633

 End of epoch: 69 | Train Loss: 0.6867868786841802 | Training Time: 642 

 End of epoch: 69 | Eval Loss: 0.6900442558891919 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/4518] 0% | Training loss: 0.7563556432723999
Epoch: 70 | Iteration number: [20/4518] 0% | Training loss: 0.7213425546884537
Epoch: 70 | Iteration number: [30/4518] 0% | Training loss: 0.7102689981460572
Epoch: 70 | Iteration number: [40/4518] 0% | Training loss: 0.704192565381527
Epoch: 70 | Iteration number: [50/4518] 1% | Training loss: 0.7004852163791656
Epoch: 70 | Iteration number: [60/4518] 1% | Training loss: 0.6978904912869136
Epoch: 70 | Iteration number: [70/4518] 1% | Training loss: 0.6963434168270656
Epoch: 70 | Iteration number: [80/4518] 1% | Training loss: 0.6952461317181587
Epoch: 70 | Iteration number: [90/4518] 1% | Training loss: 0.694357223643197
Epoch: 70 | Iteration number: [100/4518] 2% | Training loss: 0.6935918372869492
Epoch: 70 | Iteration number: [110/4518] 2% | Training loss: 0.6929890984838659
Epoch: 70 | Iteration number: [120/4518] 2% | Training loss: 0.6924158165852229
Epoch: 70 | Iteration number: [130/4518] 2% | Training loss: 0.6918943735269399
Epoch: 70 | Iteration number: [140/4518] 3% | Training loss: 0.6913950920104981
Epoch: 70 | Iteration number: [150/4518] 3% | Training loss: 0.6910120538870493
Epoch: 70 | Iteration number: [160/4518] 3% | Training loss: 0.6907833397388459
Epoch: 70 | Iteration number: [170/4518] 3% | Training loss: 0.6906022327787736
Epoch: 70 | Iteration number: [180/4518] 3% | Training loss: 0.6903664671712452
Epoch: 70 | Iteration number: [190/4518] 4% | Training loss: 0.6901607256186636
Epoch: 70 | Iteration number: [200/4518] 4% | Training loss: 0.6900356933474541
Epoch: 70 | Iteration number: [210/4518] 4% | Training loss: 0.689923799321765
Epoch: 70 | Iteration number: [220/4518] 4% | Training loss: 0.6897585690021515
Epoch: 70 | Iteration number: [230/4518] 5% | Training loss: 0.6896021490511687
Epoch: 70 | Iteration number: [240/4518] 5% | Training loss: 0.6894929486016432
Epoch: 70 | Iteration number: [250/4518] 5% | Training loss: 0.6893537707328796
Epoch: 70 | Iteration number: [260/4518] 5% | Training loss: 0.6892339708713385
Epoch: 70 | Iteration number: [270/4518] 5% | Training loss: 0.6890851778012735
Epoch: 70 | Iteration number: [280/4518] 6% | Training loss: 0.6890002982957023
Epoch: 70 | Iteration number: [290/4518] 6% | Training loss: 0.6889016400123464
Epoch: 70 | Iteration number: [300/4518] 6% | Training loss: 0.6888307368755341
Epoch: 70 | Iteration number: [310/4518] 6% | Training loss: 0.6887906666724912
Epoch: 70 | Iteration number: [320/4518] 7% | Training loss: 0.6887248208746314
Epoch: 70 | Iteration number: [330/4518] 7% | Training loss: 0.6886892670934851
Epoch: 70 | Iteration number: [340/4518] 7% | Training loss: 0.6886830720831366
Epoch: 70 | Iteration number: [350/4518] 7% | Training loss: 0.6886435799939292
Epoch: 70 | Iteration number: [360/4518] 7% | Training loss: 0.6885742616322306
Epoch: 70 | Iteration number: [370/4518] 8% | Training loss: 0.6885377527894201
Epoch: 70 | Iteration number: [380/4518] 8% | Training loss: 0.6884895522343485
Epoch: 70 | Iteration number: [390/4518] 8% | Training loss: 0.6884167429728386
Epoch: 70 | Iteration number: [400/4518] 8% | Training loss: 0.6884182259440422
Epoch: 70 | Iteration number: [410/4518] 9% | Training loss: 0.6883540755364953
Epoch: 70 | Iteration number: [420/4518] 9% | Training loss: 0.688293231952758
Epoch: 70 | Iteration number: [430/4518] 9% | Training loss: 0.688259485433268
Epoch: 70 | Iteration number: [440/4518] 9% | Training loss: 0.6882434286854484
Epoch: 70 | Iteration number: [450/4518] 9% | Training loss: 0.688208839363522
Epoch: 70 | Iteration number: [460/4518] 10% | Training loss: 0.688184345934702
Epoch: 70 | Iteration number: [470/4518] 10% | Training loss: 0.6881653577723401
Epoch: 70 | Iteration number: [480/4518] 10% | Training loss: 0.6881305485963821
Epoch: 70 | Iteration number: [490/4518] 10% | Training loss: 0.6881150448808865
Epoch: 70 | Iteration number: [500/4518] 11% | Training loss: 0.6881005169153214
Epoch: 70 | Iteration number: [510/4518] 11% | Training loss: 0.6880735487330194
Epoch: 70 | Iteration number: [520/4518] 11% | Training loss: 0.6880571847924819
Epoch: 70 | Iteration number: [530/4518] 11% | Training loss: 0.6880420570103627
Epoch: 70 | Iteration number: [540/4518] 11% | Training loss: 0.6880398403715204
Epoch: 70 | Iteration number: [550/4518] 12% | Training loss: 0.6880232360146262
Epoch: 70 | Iteration number: [560/4518] 12% | Training loss: 0.6879667141607829
Epoch: 70 | Iteration number: [570/4518] 12% | Training loss: 0.6879471091847671
Epoch: 70 | Iteration number: [580/4518] 12% | Training loss: 0.6879345751014249
Epoch: 70 | Iteration number: [590/4518] 13% | Training loss: 0.6879270151510077
Epoch: 70 | Iteration number: [600/4518] 13% | Training loss: 0.6879054240385691
Epoch: 70 | Iteration number: [610/4518] 13% | Training loss: 0.6878818060530991
Epoch: 70 | Iteration number: [620/4518] 13% | Training loss: 0.6878523491082653
Epoch: 70 | Iteration number: [630/4518] 13% | Training loss: 0.6878283659617106
Epoch: 70 | Iteration number: [640/4518] 14% | Training loss: 0.6878025872632861
Epoch: 70 | Iteration number: [650/4518] 14% | Training loss: 0.6877878543046805
Epoch: 70 | Iteration number: [660/4518] 14% | Training loss: 0.6877712298523296
Epoch: 70 | Iteration number: [670/4518] 14% | Training loss: 0.68777177342728
Epoch: 70 | Iteration number: [680/4518] 15% | Training loss: 0.6877519209595288
Epoch: 70 | Iteration number: [690/4518] 15% | Training loss: 0.6877318022043809
Epoch: 70 | Iteration number: [700/4518] 15% | Training loss: 0.6877095727409636
Epoch: 70 | Iteration number: [710/4518] 15% | Training loss: 0.6877121758293098
Epoch: 70 | Iteration number: [720/4518] 15% | Training loss: 0.6876963557468521
Epoch: 70 | Iteration number: [730/4518] 16% | Training loss: 0.6877109650063188
Epoch: 70 | Iteration number: [740/4518] 16% | Training loss: 0.6877177596897692
Epoch: 70 | Iteration number: [750/4518] 16% | Training loss: 0.6877014589309692
Epoch: 70 | Iteration number: [760/4518] 16% | Training loss: 0.6876957872980519
Epoch: 70 | Iteration number: [770/4518] 17% | Training loss: 0.687686094835207
Epoch: 70 | Iteration number: [780/4518] 17% | Training loss: 0.687674378278928
Epoch: 70 | Iteration number: [790/4518] 17% | Training loss: 0.6876575764221481
Epoch: 70 | Iteration number: [800/4518] 17% | Training loss: 0.687633120417595
Epoch: 70 | Iteration number: [810/4518] 17% | Training loss: 0.6876364036106769
Epoch: 70 | Iteration number: [820/4518] 18% | Training loss: 0.6876185793702195
Epoch: 70 | Iteration number: [830/4518] 18% | Training loss: 0.687617198099573
Epoch: 70 | Iteration number: [840/4518] 18% | Training loss: 0.6876079645185244
Epoch: 70 | Iteration number: [850/4518] 18% | Training loss: 0.6875937853841221
Epoch: 70 | Iteration number: [860/4518] 19% | Training loss: 0.68759745657444
Epoch: 70 | Iteration number: [870/4518] 19% | Training loss: 0.6875868340333303
Epoch: 70 | Iteration number: [880/4518] 19% | Training loss: 0.6875903512943875
Epoch: 70 | Iteration number: [890/4518] 19% | Training loss: 0.6875765643762739
Epoch: 70 | Iteration number: [900/4518] 19% | Training loss: 0.6875764979918798
Epoch: 70 | Iteration number: [910/4518] 20% | Training loss: 0.6875692721906599
Epoch: 70 | Iteration number: [920/4518] 20% | Training loss: 0.6875358582190846
Epoch: 70 | Iteration number: [930/4518] 20% | Training loss: 0.687528520694343
Epoch: 70 | Iteration number: [940/4518] 20% | Training loss: 0.6875138905454189
Epoch: 70 | Iteration number: [950/4518] 21% | Training loss: 0.6875081884233575
Epoch: 70 | Iteration number: [960/4518] 21% | Training loss: 0.6875095997626582
Epoch: 70 | Iteration number: [970/4518] 21% | Training loss: 0.6875087959864705
Epoch: 70 | Iteration number: [980/4518] 21% | Training loss: 0.6875115135494544
Epoch: 70 | Iteration number: [990/4518] 21% | Training loss: 0.6875040004951786
Epoch: 70 | Iteration number: [1000/4518] 22% | Training loss: 0.6875093443989754
Epoch: 70 | Iteration number: [1010/4518] 22% | Training loss: 0.687486339618664
Epoch: 70 | Iteration number: [1020/4518] 22% | Training loss: 0.6874838637370689
Epoch: 70 | Iteration number: [1030/4518] 22% | Training loss: 0.687474452928432
Epoch: 70 | Iteration number: [1040/4518] 23% | Training loss: 0.687479299822679
Epoch: 70 | Iteration number: [1050/4518] 23% | Training loss: 0.687466280346825
Epoch: 70 | Iteration number: [1060/4518] 23% | Training loss: 0.6874679975352197
Epoch: 70 | Iteration number: [1070/4518] 23% | Training loss: 0.6874658028656078
Epoch: 70 | Iteration number: [1080/4518] 23% | Training loss: 0.687463966343138
Epoch: 70 | Iteration number: [1090/4518] 24% | Training loss: 0.6874607814561337
Epoch: 70 | Iteration number: [1100/4518] 24% | Training loss: 0.6874501403895291
Epoch: 70 | Iteration number: [1110/4518] 24% | Training loss: 0.6874389497546463
Epoch: 70 | Iteration number: [1120/4518] 24% | Training loss: 0.6874371649431331
Epoch: 70 | Iteration number: [1130/4518] 25% | Training loss: 0.6874302380380377
Epoch: 70 | Iteration number: [1140/4518] 25% | Training loss: 0.6874136590121085
Epoch: 70 | Iteration number: [1150/4518] 25% | Training loss: 0.6874171017563862
Epoch: 70 | Iteration number: [1160/4518] 25% | Training loss: 0.6874083122302745
Epoch: 70 | Iteration number: [1170/4518] 25% | Training loss: 0.6874051911199195
Epoch: 70 | Iteration number: [1180/4518] 26% | Training loss: 0.6874097114397307
Epoch: 70 | Iteration number: [1190/4518] 26% | Training loss: 0.6874196582481641
Epoch: 70 | Iteration number: [1200/4518] 26% | Training loss: 0.687407237191995
Epoch: 70 | Iteration number: [1210/4518] 26% | Training loss: 0.6874111812961988
Epoch: 70 | Iteration number: [1220/4518] 27% | Training loss: 0.687396711159925
Epoch: 70 | Iteration number: [1230/4518] 27% | Training loss: 0.6873958034728601
Epoch: 70 | Iteration number: [1240/4518] 27% | Training loss: 0.6873986575872667
Epoch: 70 | Iteration number: [1250/4518] 27% | Training loss: 0.6873747214794159
Epoch: 70 | Iteration number: [1260/4518] 27% | Training loss: 0.6873648937732454
Epoch: 70 | Iteration number: [1270/4518] 28% | Training loss: 0.6873567492004454
Epoch: 70 | Iteration number: [1280/4518] 28% | Training loss: 0.6873449281789362
Epoch: 70 | Iteration number: [1290/4518] 28% | Training loss: 0.6873466745365497
Epoch: 70 | Iteration number: [1300/4518] 28% | Training loss: 0.6873449271000348
Epoch: 70 | Iteration number: [1310/4518] 28% | Training loss: 0.6873460672738898
Epoch: 70 | Iteration number: [1320/4518] 29% | Training loss: 0.6873445182587161
Epoch: 70 | Iteration number: [1330/4518] 29% | Training loss: 0.6873380515360294
Epoch: 70 | Iteration number: [1340/4518] 29% | Training loss: 0.6873405373363353
Epoch: 70 | Iteration number: [1350/4518] 29% | Training loss: 0.6873433380215256
Epoch: 70 | Iteration number: [1360/4518] 30% | Training loss: 0.6873455707641208
Epoch: 70 | Iteration number: [1370/4518] 30% | Training loss: 0.6873397675308868
Epoch: 70 | Iteration number: [1380/4518] 30% | Training loss: 0.6873432982658995
Epoch: 70 | Iteration number: [1390/4518] 30% | Training loss: 0.6873369481066148
Epoch: 70 | Iteration number: [1400/4518] 30% | Training loss: 0.6873376057829176
Epoch: 70 | Iteration number: [1410/4518] 31% | Training loss: 0.6873299971539923
Epoch: 70 | Iteration number: [1420/4518] 31% | Training loss: 0.6873172438900236
Epoch: 70 | Iteration number: [1430/4518] 31% | Training loss: 0.6873214521191336
Epoch: 70 | Iteration number: [1440/4518] 31% | Training loss: 0.6873164864050018
Epoch: 70 | Iteration number: [1450/4518] 32% | Training loss: 0.6873114876500491
Epoch: 70 | Iteration number: [1460/4518] 32% | Training loss: 0.6873112343353768
Epoch: 70 | Iteration number: [1470/4518] 32% | Training loss: 0.6873022506431657
Epoch: 70 | Iteration number: [1480/4518] 32% | Training loss: 0.68729818020318
Epoch: 70 | Iteration number: [1490/4518] 32% | Training loss: 0.6872907977376208
Epoch: 70 | Iteration number: [1500/4518] 33% | Training loss: 0.687282591064771
Epoch: 70 | Iteration number: [1510/4518] 33% | Training loss: 0.6872714776471751
Epoch: 70 | Iteration number: [1520/4518] 33% | Training loss: 0.6872707019511022
Epoch: 70 | Iteration number: [1530/4518] 33% | Training loss: 0.6872614514593984
Epoch: 70 | Iteration number: [1540/4518] 34% | Training loss: 0.6872614992903424
Epoch: 70 | Iteration number: [1550/4518] 34% | Training loss: 0.6872576503599843
Epoch: 70 | Iteration number: [1560/4518] 34% | Training loss: 0.6872577596933414
Epoch: 70 | Iteration number: [1570/4518] 34% | Training loss: 0.6872504976524669
Epoch: 70 | Iteration number: [1580/4518] 34% | Training loss: 0.6872441955005066
Epoch: 70 | Iteration number: [1590/4518] 35% | Training loss: 0.6872385578710328
Epoch: 70 | Iteration number: [1600/4518] 35% | Training loss: 0.6872327355667949
Epoch: 70 | Iteration number: [1610/4518] 35% | Training loss: 0.6872284573427638
Epoch: 70 | Iteration number: [1620/4518] 35% | Training loss: 0.6872238574572551
Epoch: 70 | Iteration number: [1630/4518] 36% | Training loss: 0.6872220872735685
Epoch: 70 | Iteration number: [1640/4518] 36% | Training loss: 0.6872189743489754
Epoch: 70 | Iteration number: [1650/4518] 36% | Training loss: 0.6872185748634916
Epoch: 70 | Iteration number: [1660/4518] 36% | Training loss: 0.6872157844075237
Epoch: 70 | Iteration number: [1670/4518] 36% | Training loss: 0.6872110560982527
Epoch: 70 | Iteration number: [1680/4518] 37% | Training loss: 0.6872029109724931
Epoch: 70 | Iteration number: [1690/4518] 37% | Training loss: 0.6872042883782697
Epoch: 70 | Iteration number: [1700/4518] 37% | Training loss: 0.6871977567322114
Epoch: 70 | Iteration number: [1710/4518] 37% | Training loss: 0.6871974796928161
Epoch: 70 | Iteration number: [1720/4518] 38% | Training loss: 0.6871994829801626
Epoch: 70 | Iteration number: [1730/4518] 38% | Training loss: 0.6871948244943784
Epoch: 70 | Iteration number: [1740/4518] 38% | Training loss: 0.6871892759169655
Epoch: 70 | Iteration number: [1750/4518] 38% | Training loss: 0.6871879818098886
Epoch: 70 | Iteration number: [1760/4518] 38% | Training loss: 0.6871848377991806
Epoch: 70 | Iteration number: [1770/4518] 39% | Training loss: 0.6871817025424397
Epoch: 70 | Iteration number: [1780/4518] 39% | Training loss: 0.6871799793805969
Epoch: 70 | Iteration number: [1790/4518] 39% | Training loss: 0.6871802324356313
Epoch: 70 | Iteration number: [1800/4518] 39% | Training loss: 0.6871849826309416
Epoch: 70 | Iteration number: [1810/4518] 40% | Training loss: 0.6871881674995739
Epoch: 70 | Iteration number: [1820/4518] 40% | Training loss: 0.6871860463213134
Epoch: 70 | Iteration number: [1830/4518] 40% | Training loss: 0.6871820298700385
Epoch: 70 | Iteration number: [1840/4518] 40% | Training loss: 0.6871776325223239
Epoch: 70 | Iteration number: [1850/4518] 40% | Training loss: 0.6871741554221591
Epoch: 70 | Iteration number: [1860/4518] 41% | Training loss: 0.6871747733764751
Epoch: 70 | Iteration number: [1870/4518] 41% | Training loss: 0.6871629231435092
Epoch: 70 | Iteration number: [1880/4518] 41% | Training loss: 0.687163785987712
Epoch: 70 | Iteration number: [1890/4518] 41% | Training loss: 0.6871622697070793
Epoch: 70 | Iteration number: [1900/4518] 42% | Training loss: 0.6871653053948754
Epoch: 70 | Iteration number: [1910/4518] 42% | Training loss: 0.6871620803603327
Epoch: 70 | Iteration number: [1920/4518] 42% | Training loss: 0.6871637283824384
Epoch: 70 | Iteration number: [1930/4518] 42% | Training loss: 0.6871607537405479
Epoch: 70 | Iteration number: [1940/4518] 42% | Training loss: 0.6871631017972514
Epoch: 70 | Iteration number: [1950/4518] 43% | Training loss: 0.6871613139678271
Epoch: 70 | Iteration number: [1960/4518] 43% | Training loss: 0.6871577948027727
Epoch: 70 | Iteration number: [1970/4518] 43% | Training loss: 0.6871614508217362
Epoch: 70 | Iteration number: [1980/4518] 43% | Training loss: 0.6871582462932124
Epoch: 70 | Iteration number: [1990/4518] 44% | Training loss: 0.6871542019460668
Epoch: 70 | Iteration number: [2000/4518] 44% | Training loss: 0.6871475954651832
Epoch: 70 | Iteration number: [2010/4518] 44% | Training loss: 0.6871444550616231
Epoch: 70 | Iteration number: [2020/4518] 44% | Training loss: 0.6871547397115443
Epoch: 70 | Iteration number: [2030/4518] 44% | Training loss: 0.6871522213437874
Epoch: 70 | Iteration number: [2040/4518] 45% | Training loss: 0.6871518389851439
Epoch: 70 | Iteration number: [2050/4518] 45% | Training loss: 0.6871501480951542
Epoch: 70 | Iteration number: [2060/4518] 45% | Training loss: 0.6871523051875309
Epoch: 70 | Iteration number: [2070/4518] 45% | Training loss: 0.6871530518151712
Epoch: 70 | Iteration number: [2080/4518] 46% | Training loss: 0.6871438244787547
Epoch: 70 | Iteration number: [2090/4518] 46% | Training loss: 0.6871398945744528
Epoch: 70 | Iteration number: [2100/4518] 46% | Training loss: 0.687140594295093
Epoch: 70 | Iteration number: [2110/4518] 46% | Training loss: 0.6871357699423605
Epoch: 70 | Iteration number: [2120/4518] 46% | Training loss: 0.6871340645090589
Epoch: 70 | Iteration number: [2130/4518] 47% | Training loss: 0.6871348070986394
Epoch: 70 | Iteration number: [2140/4518] 47% | Training loss: 0.6871357803311303
Epoch: 70 | Iteration number: [2150/4518] 47% | Training loss: 0.6871343953110451
Epoch: 70 | Iteration number: [2160/4518] 47% | Training loss: 0.6871389060936592
Epoch: 70 | Iteration number: [2170/4518] 48% | Training loss: 0.6871358732474016
Epoch: 70 | Iteration number: [2180/4518] 48% | Training loss: 0.6871382810653897
Epoch: 70 | Iteration number: [2190/4518] 48% | Training loss: 0.6871359417971955
Epoch: 70 | Iteration number: [2200/4518] 48% | Training loss: 0.6871320023319938
Epoch: 70 | Iteration number: [2210/4518] 48% | Training loss: 0.6871325517941385
Epoch: 70 | Iteration number: [2220/4518] 49% | Training loss: 0.6871348062614063
Epoch: 70 | Iteration number: [2230/4518] 49% | Training loss: 0.6871320737317004
Epoch: 70 | Iteration number: [2240/4518] 49% | Training loss: 0.687129016513271
Epoch: 70 | Iteration number: [2250/4518] 49% | Training loss: 0.6871333994335599
Epoch: 70 | Iteration number: [2260/4518] 50% | Training loss: 0.687138007488926
Epoch: 70 | Iteration number: [2270/4518] 50% | Training loss: 0.6871324572006511
Epoch: 70 | Iteration number: [2280/4518] 50% | Training loss: 0.6871289093243448
Epoch: 70 | Iteration number: [2290/4518] 50% | Training loss: 0.687128370323556
Epoch: 70 | Iteration number: [2300/4518] 50% | Training loss: 0.6871253272243169
Epoch: 70 | Iteration number: [2310/4518] 51% | Training loss: 0.6871179249895599
Epoch: 70 | Iteration number: [2320/4518] 51% | Training loss: 0.6871176559606503
Epoch: 70 | Iteration number: [2330/4518] 51% | Training loss: 0.6871208388662133
Epoch: 70 | Iteration number: [2340/4518] 51% | Training loss: 0.6871304955492672
Epoch: 70 | Iteration number: [2350/4518] 52% | Training loss: 0.6871289679851937
Epoch: 70 | Iteration number: [2360/4518] 52% | Training loss: 0.687124292400934
Epoch: 70 | Iteration number: [2370/4518] 52% | Training loss: 0.6871173650655062
Epoch: 70 | Iteration number: [2380/4518] 52% | Training loss: 0.6871202146806636
Epoch: 70 | Iteration number: [2390/4518] 52% | Training loss: 0.6871178486606566
Epoch: 70 | Iteration number: [2400/4518] 53% | Training loss: 0.6871204043428103
Epoch: 70 | Iteration number: [2410/4518] 53% | Training loss: 0.6871154853417171
Epoch: 70 | Iteration number: [2420/4518] 53% | Training loss: 0.6871068342658114
Epoch: 70 | Iteration number: [2430/4518] 53% | Training loss: 0.6871052214147623
Epoch: 70 | Iteration number: [2440/4518] 54% | Training loss: 0.6871035754436352
Epoch: 70 | Iteration number: [2450/4518] 54% | Training loss: 0.6871029088935073
Epoch: 70 | Iteration number: [2460/4518] 54% | Training loss: 0.6871022645777803
Epoch: 70 | Iteration number: [2470/4518] 54% | Training loss: 0.6871032932750609
Epoch: 70 | Iteration number: [2480/4518] 54% | Training loss: 0.6871014950736877
Epoch: 70 | Iteration number: [2490/4518] 55% | Training loss: 0.6871024915970951
Epoch: 70 | Iteration number: [2500/4518] 55% | Training loss: 0.6871051941394806
Epoch: 70 | Iteration number: [2510/4518] 55% | Training loss: 0.6871069925477306
Epoch: 70 | Iteration number: [2520/4518] 55% | Training loss: 0.687110558980041
Epoch: 70 | Iteration number: [2530/4518] 55% | Training loss: 0.6871119606636259
Epoch: 70 | Iteration number: [2540/4518] 56% | Training loss: 0.6871140947726768
Epoch: 70 | Iteration number: [2550/4518] 56% | Training loss: 0.6871122591869504
Epoch: 70 | Iteration number: [2560/4518] 56% | Training loss: 0.6871138147544116
Epoch: 70 | Iteration number: [2570/4518] 56% | Training loss: 0.6871144580006135
Epoch: 70 | Iteration number: [2580/4518] 57% | Training loss: 0.6871121317148209
Epoch: 70 | Iteration number: [2590/4518] 57% | Training loss: 0.6871097591853049
Epoch: 70 | Iteration number: [2600/4518] 57% | Training loss: 0.6871056070923806
Epoch: 70 | Iteration number: [2610/4518] 57% | Training loss: 0.6871055657151102
Epoch: 70 | Iteration number: [2620/4518] 57% | Training loss: 0.6871005238694999
Epoch: 70 | Iteration number: [2630/4518] 58% | Training loss: 0.6871023365073331
Epoch: 70 | Iteration number: [2640/4518] 58% | Training loss: 0.6871042067580151
Epoch: 70 | Iteration number: [2650/4518] 58% | Training loss: 0.6871007592947977
Epoch: 70 | Iteration number: [2660/4518] 58% | Training loss: 0.6871039882414323
Epoch: 70 | Iteration number: [2670/4518] 59% | Training loss: 0.6871024355682988
Epoch: 70 | Iteration number: [2680/4518] 59% | Training loss: 0.6870990135109246
Epoch: 70 | Iteration number: [2690/4518] 59% | Training loss: 0.6870943388088042
Epoch: 70 | Iteration number: [2700/4518] 59% | Training loss: 0.6870958065765875
Epoch: 70 | Iteration number: [2710/4518] 59% | Training loss: 0.68709379238836
Epoch: 70 | Iteration number: [2720/4518] 60% | Training loss: 0.6870909725918489
Epoch: 70 | Iteration number: [2730/4518] 60% | Training loss: 0.6870907406448882
Epoch: 70 | Iteration number: [2740/4518] 60% | Training loss: 0.6870919354858189
Epoch: 70 | Iteration number: [2750/4518] 60% | Training loss: 0.6870899154706435
Epoch: 70 | Iteration number: [2760/4518] 61% | Training loss: 0.6870873948370201
Epoch: 70 | Iteration number: [2770/4518] 61% | Training loss: 0.6870828162892201
Epoch: 70 | Iteration number: [2780/4518] 61% | Training loss: 0.6870839284907142
Epoch: 70 | Iteration number: [2790/4518] 61% | Training loss: 0.6870792697621075
Epoch: 70 | Iteration number: [2800/4518] 61% | Training loss: 0.6870812162969794
Epoch: 70 | Iteration number: [2810/4518] 62% | Training loss: 0.6870788205985072
Epoch: 70 | Iteration number: [2820/4518] 62% | Training loss: 0.6870805079421253
Epoch: 70 | Iteration number: [2830/4518] 62% | Training loss: 0.687079194556698
Epoch: 70 | Iteration number: [2840/4518] 62% | Training loss: 0.6870773052455674
Epoch: 70 | Iteration number: [2850/4518] 63% | Training loss: 0.6870776089659908
Epoch: 70 | Iteration number: [2860/4518] 63% | Training loss: 0.6870820143631288
Epoch: 70 | Iteration number: [2870/4518] 63% | Training loss: 0.6870792271783543
Epoch: 70 | Iteration number: [2880/4518] 63% | Training loss: 0.687075204298728
Epoch: 70 | Iteration number: [2890/4518] 63% | Training loss: 0.6870775372924277
Epoch: 70 | Iteration number: [2900/4518] 64% | Training loss: 0.687078674271189
Epoch: 70 | Iteration number: [2910/4518] 64% | Training loss: 0.6870770967088614
Epoch: 70 | Iteration number: [2920/4518] 64% | Training loss: 0.687077560980026
Epoch: 70 | Iteration number: [2930/4518] 64% | Training loss: 0.6870738438982199
Epoch: 70 | Iteration number: [2940/4518] 65% | Training loss: 0.6870747918377117
Epoch: 70 | Iteration number: [2950/4518] 65% | Training loss: 0.687071330991842
Epoch: 70 | Iteration number: [2960/4518] 65% | Training loss: 0.6870715867224577
Epoch: 70 | Iteration number: [2970/4518] 65% | Training loss: 0.6870662743395025
Epoch: 70 | Iteration number: [2980/4518] 65% | Training loss: 0.6870675218185323
Epoch: 70 | Iteration number: [2990/4518] 66% | Training loss: 0.6870644743027894
Epoch: 70 | Iteration number: [3000/4518] 66% | Training loss: 0.6870658438404401
Epoch: 70 | Iteration number: [3010/4518] 66% | Training loss: 0.6870645824460888
Epoch: 70 | Iteration number: [3020/4518] 66% | Training loss: 0.6870619352684905
Epoch: 70 | Iteration number: [3030/4518] 67% | Training loss: 0.6870595538576837
Epoch: 70 | Iteration number: [3040/4518] 67% | Training loss: 0.6870599289865871
Epoch: 70 | Iteration number: [3050/4518] 67% | Training loss: 0.6870589143721784
Epoch: 70 | Iteration number: [3060/4518] 67% | Training loss: 0.6870549823918374
Epoch: 70 | Iteration number: [3070/4518] 67% | Training loss: 0.6870530515423815
Epoch: 70 | Iteration number: [3080/4518] 68% | Training loss: 0.6870457481641274
Epoch: 70 | Iteration number: [3090/4518] 68% | Training loss: 0.6870476308571096
Epoch: 70 | Iteration number: [3100/4518] 68% | Training loss: 0.6870489222964933
Epoch: 70 | Iteration number: [3110/4518] 68% | Training loss: 0.6870461602494647
Epoch: 70 | Iteration number: [3120/4518] 69% | Training loss: 0.6870499046185078
Epoch: 70 | Iteration number: [3130/4518] 69% | Training loss: 0.6870469126267175
Epoch: 70 | Iteration number: [3140/4518] 69% | Training loss: 0.6870457630058763
Epoch: 70 | Iteration number: [3150/4518] 69% | Training loss: 0.6870450351541004
Epoch: 70 | Iteration number: [3160/4518] 69% | Training loss: 0.687045018469231
Epoch: 70 | Iteration number: [3170/4518] 70% | Training loss: 0.6870488561478323
Epoch: 70 | Iteration number: [3180/4518] 70% | Training loss: 0.6870497974209816
Epoch: 70 | Iteration number: [3190/4518] 70% | Training loss: 0.6870454383120641
Epoch: 70 | Iteration number: [3200/4518] 70% | Training loss: 0.6870440049469471
Epoch: 70 | Iteration number: [3210/4518] 71% | Training loss: 0.6870439397026074
Epoch: 70 | Iteration number: [3220/4518] 71% | Training loss: 0.6870456317011614
Epoch: 70 | Iteration number: [3230/4518] 71% | Training loss: 0.6870413858085963
Epoch: 70 | Iteration number: [3240/4518] 71% | Training loss: 0.6870409340218261
Epoch: 70 | Iteration number: [3250/4518] 71% | Training loss: 0.6870394937625298
Epoch: 70 | Iteration number: [3260/4518] 72% | Training loss: 0.6870406659285715
Epoch: 70 | Iteration number: [3270/4518] 72% | Training loss: 0.6870386330177295
Epoch: 70 | Iteration number: [3280/4518] 72% | Training loss: 0.6870395030917191
Epoch: 70 | Iteration number: [3290/4518] 72% | Training loss: 0.6870372089571504
Epoch: 70 | Iteration number: [3300/4518] 73% | Training loss: 0.6870400341713068
Epoch: 70 | Iteration number: [3310/4518] 73% | Training loss: 0.6870402325676287
Epoch: 70 | Iteration number: [3320/4518] 73% | Training loss: 0.687034590075533
Epoch: 70 | Iteration number: [3330/4518] 73% | Training loss: 0.6870324047657105
Epoch: 70 | Iteration number: [3340/4518] 73% | Training loss: 0.687033449229366
Epoch: 70 | Iteration number: [3350/4518] 74% | Training loss: 0.6870304446078058
Epoch: 70 | Iteration number: [3360/4518] 74% | Training loss: 0.6870253823874962
Epoch: 70 | Iteration number: [3370/4518] 74% | Training loss: 0.6870234760933884
Epoch: 70 | Iteration number: [3380/4518] 74% | Training loss: 0.6870191929961097
Epoch: 70 | Iteration number: [3390/4518] 75% | Training loss: 0.6870204876306134
Epoch: 70 | Iteration number: [3400/4518] 75% | Training loss: 0.6870197451114655
Epoch: 70 | Iteration number: [3410/4518] 75% | Training loss: 0.6870191256496564
Epoch: 70 | Iteration number: [3420/4518] 75% | Training loss: 0.6870143508527711
Epoch: 70 | Iteration number: [3430/4518] 75% | Training loss: 0.6870107771182546
Epoch: 70 | Iteration number: [3440/4518] 76% | Training loss: 0.6870108145094195
Epoch: 70 | Iteration number: [3450/4518] 76% | Training loss: 0.6870114952584971
Epoch: 70 | Iteration number: [3460/4518] 76% | Training loss: 0.6870103670337986
Epoch: 70 | Iteration number: [3470/4518] 76% | Training loss: 0.6870079338378796
Epoch: 70 | Iteration number: [3480/4518] 77% | Training loss: 0.6870089748981355
Epoch: 70 | Iteration number: [3490/4518] 77% | Training loss: 0.6870059365017025
Epoch: 70 | Iteration number: [3500/4518] 77% | Training loss: 0.6870077720710209
Epoch: 70 | Iteration number: [3510/4518] 77% | Training loss: 0.6870106460192265
Epoch: 70 | Iteration number: [3520/4518] 77% | Training loss: 0.6870104484768076
Epoch: 70 | Iteration number: [3530/4518] 78% | Training loss: 0.6870081078736032
Epoch: 70 | Iteration number: [3540/4518] 78% | Training loss: 0.6870051254828771
Epoch: 70 | Iteration number: [3550/4518] 78% | Training loss: 0.6870051881628977
Epoch: 70 | Iteration number: [3560/4518] 78% | Training loss: 0.6870024312245712
Epoch: 70 | Iteration number: [3570/4518] 79% | Training loss: 0.6869999089995686
Epoch: 70 | Iteration number: [3580/4518] 79% | Training loss: 0.687001188007813
Epoch: 70 | Iteration number: [3590/4518] 79% | Training loss: 0.6869966579014877
Epoch: 70 | Iteration number: [3600/4518] 79% | Training loss: 0.686994082381328
Epoch: 70 | Iteration number: [3610/4518] 79% | Training loss: 0.6869912500361657
Epoch: 70 | Iteration number: [3620/4518] 80% | Training loss: 0.6869886774878475
Epoch: 70 | Iteration number: [3630/4518] 80% | Training loss: 0.686989419929909
Epoch: 70 | Iteration number: [3640/4518] 80% | Training loss: 0.6869851605741533
Epoch: 70 | Iteration number: [3650/4518] 80% | Training loss: 0.6869879833312884
Epoch: 70 | Iteration number: [3660/4518] 81% | Training loss: 0.6869864389707482
Epoch: 70 | Iteration number: [3670/4518] 81% | Training loss: 0.6869855223624518
Epoch: 70 | Iteration number: [3680/4518] 81% | Training loss: 0.6869824073722829
Epoch: 70 | Iteration number: [3690/4518] 81% | Training loss: 0.6869824986793808
Epoch: 70 | Iteration number: [3700/4518] 81% | Training loss: 0.6869785597517684
Epoch: 70 | Iteration number: [3710/4518] 82% | Training loss: 0.6869783496760293
Epoch: 70 | Iteration number: [3720/4518] 82% | Training loss: 0.6869789706763401
Epoch: 70 | Iteration number: [3730/4518] 82% | Training loss: 0.6869772900205515
Epoch: 70 | Iteration number: [3740/4518] 82% | Training loss: 0.6869748567514878
Epoch: 70 | Iteration number: [3750/4518] 83% | Training loss: 0.6869762127717336
Epoch: 70 | Iteration number: [3760/4518] 83% | Training loss: 0.6869702307309242
Epoch: 70 | Iteration number: [3770/4518] 83% | Training loss: 0.6869713503738929
Epoch: 70 | Iteration number: [3780/4518] 83% | Training loss: 0.6869759465809222
Epoch: 70 | Iteration number: [3790/4518] 83% | Training loss: 0.6869771591906183
Epoch: 70 | Iteration number: [3800/4518] 84% | Training loss: 0.6869744223669956
Epoch: 70 | Iteration number: [3810/4518] 84% | Training loss: 0.6869722468959378
Epoch: 70 | Iteration number: [3820/4518] 84% | Training loss: 0.6869711606446361
Epoch: 70 | Iteration number: [3830/4518] 84% | Training loss: 0.6869697961576925
Epoch: 70 | Iteration number: [3840/4518] 84% | Training loss: 0.6869691171683371
Epoch: 70 | Iteration number: [3850/4518] 85% | Training loss: 0.6869665338157059
Epoch: 70 | Iteration number: [3860/4518] 85% | Training loss: 0.6869654799681253
Epoch: 70 | Iteration number: [3870/4518] 85% | Training loss: 0.6869693586684629
Epoch: 70 | Iteration number: [3880/4518] 85% | Training loss: 0.686969162861711
Epoch: 70 | Iteration number: [3890/4518] 86% | Training loss: 0.6869679762802271
Epoch: 70 | Iteration number: [3900/4518] 86% | Training loss: 0.6869667457770079
Epoch: 70 | Iteration number: [3910/4518] 86% | Training loss: 0.6869704297131589
Epoch: 70 | Iteration number: [3920/4518] 86% | Training loss: 0.6869664504363828
Epoch: 70 | Iteration number: [3930/4518] 86% | Training loss: 0.6869653527821596
Epoch: 70 | Iteration number: [3940/4518] 87% | Training loss: 0.6869659651354485
Epoch: 70 | Iteration number: [3950/4518] 87% | Training loss: 0.6869636494751218
Epoch: 70 | Iteration number: [3960/4518] 87% | Training loss: 0.6869642965269811
Epoch: 70 | Iteration number: [3970/4518] 87% | Training loss: 0.6869632632816468
Epoch: 70 | Iteration number: [3980/4518] 88% | Training loss: 0.6869616794526278
Epoch: 70 | Iteration number: [3990/4518] 88% | Training loss: 0.6869618794374298
Epoch: 70 | Iteration number: [4000/4518] 88% | Training loss: 0.686959986552596
Epoch: 70 | Iteration number: [4010/4518] 88% | Training loss: 0.6869572549240844
Epoch: 70 | Iteration number: [4020/4518] 88% | Training loss: 0.6869556724135556
Epoch: 70 | Iteration number: [4030/4518] 89% | Training loss: 0.6869583264769751
Epoch: 70 | Iteration number: [4040/4518] 89% | Training loss: 0.686957332403353
Epoch: 70 | Iteration number: [4050/4518] 89% | Training loss: 0.686957193215688
Epoch: 70 | Iteration number: [4060/4518] 89% | Training loss: 0.6869565880357338
Epoch: 70 | Iteration number: [4070/4518] 90% | Training loss: 0.6869584251680304
Epoch: 70 | Iteration number: [4080/4518] 90% | Training loss: 0.6869558878535149
Epoch: 70 | Iteration number: [4090/4518] 90% | Training loss: 0.6869566952540996
Epoch: 70 | Iteration number: [4100/4518] 90% | Training loss: 0.6869556491840176
Epoch: 70 | Iteration number: [4110/4518] 90% | Training loss: 0.6869532290456358
Epoch: 70 | Iteration number: [4120/4518] 91% | Training loss: 0.6869516609941871
Epoch: 70 | Iteration number: [4130/4518] 91% | Training loss: 0.6869526918228833
Epoch: 70 | Iteration number: [4140/4518] 91% | Training loss: 0.6869515124438466
Epoch: 70 | Iteration number: [4150/4518] 91% | Training loss: 0.6869500531058713
Epoch: 70 | Iteration number: [4160/4518] 92% | Training loss: 0.6869513615249441
Epoch: 70 | Iteration number: [4170/4518] 92% | Training loss: 0.6869515567088871
Epoch: 70 | Iteration number: [4180/4518] 92% | Training loss: 0.6869497123232299
Epoch: 70 | Iteration number: [4190/4518] 92% | Training loss: 0.6869497439457295
Epoch: 70 | Iteration number: [4200/4518] 92% | Training loss: 0.6869495707182657
Epoch: 70 | Iteration number: [4210/4518] 93% | Training loss: 0.6869497238032325
Epoch: 70 | Iteration number: [4220/4518] 93% | Training loss: 0.6869509739050933
Epoch: 70 | Iteration number: [4230/4518] 93% | Training loss: 0.6869497744045078
Epoch: 70 | Iteration number: [4240/4518] 93% | Training loss: 0.6869469414482702
Epoch: 70 | Iteration number: [4250/4518] 94% | Training loss: 0.6869495842877557
Epoch: 70 | Iteration number: [4260/4518] 94% | Training loss: 0.6869498761606888
Epoch: 70 | Iteration number: [4270/4518] 94% | Training loss: 0.6869528955542231
Epoch: 70 | Iteration number: [4280/4518] 94% | Training loss: 0.6869537143367473
Epoch: 70 | Iteration number: [4290/4518] 94% | Training loss: 0.6869504355884098
Epoch: 70 | Iteration number: [4300/4518] 95% | Training loss: 0.6869494146663089
Epoch: 70 | Iteration number: [4310/4518] 95% | Training loss: 0.6869465503919429
Epoch: 70 | Iteration number: [4320/4518] 95% | Training loss: 0.6869463810766184
Epoch: 70 | Iteration number: [4330/4518] 95% | Training loss: 0.6869445550524335
Epoch: 70 | Iteration number: [4340/4518] 96% | Training loss: 0.686940621409548
Epoch: 70 | Iteration number: [4350/4518] 96% | Training loss: 0.6869383655608385
Epoch: 70 | Iteration number: [4360/4518] 96% | Training loss: 0.6869385176022118
Epoch: 70 | Iteration number: [4370/4518] 96% | Training loss: 0.686940838679569
Epoch: 70 | Iteration number: [4380/4518] 96% | Training loss: 0.6869395656128452
Epoch: 70 | Iteration number: [4390/4518] 97% | Training loss: 0.6869375683044789
Epoch: 70 | Iteration number: [4400/4518] 97% | Training loss: 0.6869372404028069
Epoch: 70 | Iteration number: [4410/4518] 97% | Training loss: 0.6869360191346296
Epoch: 70 | Iteration number: [4420/4518] 97% | Training loss: 0.686935437453818
Epoch: 70 | Iteration number: [4430/4518] 98% | Training loss: 0.6869345085615498
Epoch: 70 | Iteration number: [4440/4518] 98% | Training loss: 0.6869363621951223
Epoch: 70 | Iteration number: [4450/4518] 98% | Training loss: 0.6869347227021549
Epoch: 70 | Iteration number: [4460/4518] 98% | Training loss: 0.6869340489931706
Epoch: 70 | Iteration number: [4470/4518] 98% | Training loss: 0.6869360576006657
Epoch: 70 | Iteration number: [4480/4518] 99% | Training loss: 0.6869335570239595
Epoch: 70 | Iteration number: [4490/4518] 99% | Training loss: 0.6869322583643525
Epoch: 70 | Iteration number: [4500/4518] 99% | Training loss: 0.6869328146908018
Epoch: 70 | Iteration number: [4510/4518] 99% | Training loss: 0.6869337782759359

 End of epoch: 70 | Train Loss: 0.6867807783770213 | Training Time: 641 

 End of epoch: 70 | Eval Loss: 0.6900529119433189 | Evaluating Time: 17 
Epoch: 71 | Iteration number: [10/4518] 0% | Training loss: 0.7565692603588104
Epoch: 71 | Iteration number: [20/4518] 0% | Training loss: 0.7215257257223129
Epoch: 71 | Iteration number: [30/4518] 0% | Training loss: 0.7101744671662649
Epoch: 71 | Iteration number: [40/4518] 0% | Training loss: 0.7045167356729507
Epoch: 71 | Iteration number: [50/4518] 1% | Training loss: 0.7006870079040527
Epoch: 71 | Iteration number: [60/4518] 1% | Training loss: 0.6981800357500713
Epoch: 71 | Iteration number: [70/4518] 1% | Training loss: 0.6965328139918191
Epoch: 71 | Iteration number: [80/4518] 1% | Training loss: 0.6954084351658821
Epoch: 71 | Iteration number: [90/4518] 1% | Training loss: 0.6945255590809716
Epoch: 71 | Iteration number: [100/4518] 2% | Training loss: 0.6937679201364517
Epoch: 71 | Iteration number: [110/4518] 2% | Training loss: 0.692959894917228
Epoch: 71 | Iteration number: [120/4518] 2% | Training loss: 0.6926003624995549
Epoch: 71 | Iteration number: [130/4518] 2% | Training loss: 0.6920914993836329
Epoch: 71 | Iteration number: [140/4518] 3% | Training loss: 0.6917136183806828
Epoch: 71 | Iteration number: [150/4518] 3% | Training loss: 0.6913584776719411
Epoch: 71 | Iteration number: [160/4518] 3% | Training loss: 0.6910188540816307
Epoch: 71 | Iteration number: [170/4518] 3% | Training loss: 0.6907773806768305
Epoch: 71 | Iteration number: [180/4518] 3% | Training loss: 0.6905625697639254
Epoch: 71 | Iteration number: [190/4518] 4% | Training loss: 0.6904171294287631
Epoch: 71 | Iteration number: [200/4518] 4% | Training loss: 0.6902347826957702
Epoch: 71 | Iteration number: [210/4518] 4% | Training loss: 0.6900290736130306
Epoch: 71 | Iteration number: [220/4518] 4% | Training loss: 0.6899156258864836
Epoch: 71 | Iteration number: [230/4518] 5% | Training loss: 0.6898036381472712
Epoch: 71 | Iteration number: [240/4518] 5% | Training loss: 0.6897056919833024
Epoch: 71 | Iteration number: [250/4518] 5% | Training loss: 0.6896294293403625
Epoch: 71 | Iteration number: [260/4518] 5% | Training loss: 0.6895368312413875
Epoch: 71 | Iteration number: [270/4518] 5% | Training loss: 0.6894842437020055
Epoch: 71 | Iteration number: [280/4518] 6% | Training loss: 0.6894026402916227
Epoch: 71 | Iteration number: [290/4518] 6% | Training loss: 0.6893154417646342
Epoch: 71 | Iteration number: [300/4518] 6% | Training loss: 0.6892437394460043
Epoch: 71 | Iteration number: [310/4518] 6% | Training loss: 0.689184921210812
Epoch: 71 | Iteration number: [320/4518] 7% | Training loss: 0.6890708873048424
Epoch: 71 | Iteration number: [330/4518] 7% | Training loss: 0.6890044223178516
Epoch: 71 | Iteration number: [340/4518] 7% | Training loss: 0.6889775078086292
Epoch: 71 | Iteration number: [350/4518] 7% | Training loss: 0.688888053383146
Epoch: 71 | Iteration number: [360/4518] 7% | Training loss: 0.6888457144300143
Epoch: 71 | Iteration number: [370/4518] 8% | Training loss: 0.6888159798609244
Epoch: 71 | Iteration number: [380/4518] 8% | Training loss: 0.6887603082154926
Epoch: 71 | Iteration number: [390/4518] 8% | Training loss: 0.688690587801811
Epoch: 71 | Iteration number: [400/4518] 8% | Training loss: 0.6886394807696342
Epoch: 71 | Iteration number: [410/4518] 9% | Training loss: 0.6885774807232182
Epoch: 71 | Iteration number: [420/4518] 9% | Training loss: 0.6885539521773656
Epoch: 71 | Iteration number: [430/4518] 9% | Training loss: 0.6885382192079411
Epoch: 71 | Iteration number: [440/4518] 9% | Training loss: 0.6884877221150831
Epoch: 71 | Iteration number: [450/4518] 9% | Training loss: 0.6884397553073035
Epoch: 71 | Iteration number: [460/4518] 10% | Training loss: 0.6884050456078156
Epoch: 71 | Iteration number: [470/4518] 10% | Training loss: 0.688389161672998
Epoch: 71 | Iteration number: [480/4518] 10% | Training loss: 0.6883770667016507
Epoch: 71 | Iteration number: [490/4518] 10% | Training loss: 0.6883593562914401
Epoch: 71 | Iteration number: [500/4518] 11% | Training loss: 0.6883454271554947
Epoch: 71 | Iteration number: [510/4518] 11% | Training loss: 0.6883179242704429
Epoch: 71 | Iteration number: [520/4518] 11% | Training loss: 0.688296570456945
Epoch: 71 | Iteration number: [530/4518] 11% | Training loss: 0.6882868079644329
Epoch: 71 | Iteration number: [540/4518] 11% | Training loss: 0.6882529371314579
Epoch: 71 | Iteration number: [550/4518] 12% | Training loss: 0.6882075772502205
Epoch: 71 | Iteration number: [560/4518] 12% | Training loss: 0.6881581046751567
Epoch: 71 | Iteration number: [570/4518] 12% | Training loss: 0.6881444828552112
Epoch: 71 | Iteration number: [580/4518] 12% | Training loss: 0.6881273880087097
Epoch: 71 | Iteration number: [590/4518] 13% | Training loss: 0.68808190438707
Epoch: 71 | Iteration number: [600/4518] 13% | Training loss: 0.6880459411938985
Epoch: 71 | Iteration number: [610/4518] 13% | Training loss: 0.6880157874255884
Epoch: 71 | Iteration number: [620/4518] 13% | Training loss: 0.6880013824470581
Epoch: 71 | Iteration number: [630/4518] 13% | Training loss: 0.6879857111544836
Epoch: 71 | Iteration number: [640/4518] 14% | Training loss: 0.6879673065617681
Epoch: 71 | Iteration number: [650/4518] 14% | Training loss: 0.6879505267510048
Epoch: 71 | Iteration number: [660/4518] 14% | Training loss: 0.6879293203353882
Epoch: 71 | Iteration number: [670/4518] 14% | Training loss: 0.6879241021711435
Epoch: 71 | Iteration number: [680/4518] 15% | Training loss: 0.6879223592141095
Epoch: 71 | Iteration number: [690/4518] 15% | Training loss: 0.687889713221702
Epoch: 71 | Iteration number: [700/4518] 15% | Training loss: 0.687877180831773
Epoch: 71 | Iteration number: [710/4518] 15% | Training loss: 0.6878259309580629
Epoch: 71 | Iteration number: [720/4518] 15% | Training loss: 0.6877907504638036
Epoch: 71 | Iteration number: [730/4518] 16% | Training loss: 0.6877860877611865
Epoch: 71 | Iteration number: [740/4518] 16% | Training loss: 0.6877783303325241
Epoch: 71 | Iteration number: [750/4518] 16% | Training loss: 0.6877672993342082
Epoch: 71 | Iteration number: [760/4518] 16% | Training loss: 0.687770109584457
Epoch: 71 | Iteration number: [770/4518] 17% | Training loss: 0.6877738721184916
Epoch: 71 | Iteration number: [780/4518] 17% | Training loss: 0.6877746097552471
Epoch: 71 | Iteration number: [790/4518] 17% | Training loss: 0.6877548312084585
Epoch: 71 | Iteration number: [800/4518] 17% | Training loss: 0.6877319823205471
Epoch: 71 | Iteration number: [810/4518] 17% | Training loss: 0.6877255263151946
Epoch: 71 | Iteration number: [820/4518] 18% | Training loss: 0.687719690290893
Epoch: 71 | Iteration number: [830/4518] 18% | Training loss: 0.687700236418161
Epoch: 71 | Iteration number: [840/4518] 18% | Training loss: 0.6876930908787818
Epoch: 71 | Iteration number: [850/4518] 18% | Training loss: 0.6876786561573253
Epoch: 71 | Iteration number: [860/4518] 19% | Training loss: 0.6876595631588337
Epoch: 71 | Iteration number: [870/4518] 19% | Training loss: 0.6876430173029845
Epoch: 71 | Iteration number: [880/4518] 19% | Training loss: 0.6876392512836239
Epoch: 71 | Iteration number: [890/4518] 19% | Training loss: 0.6876352196329095
Epoch: 71 | Iteration number: [900/4518] 19% | Training loss: 0.6876096824142668
Epoch: 71 | Iteration number: [910/4518] 20% | Training loss: 0.6876107361945477
Epoch: 71 | Iteration number: [920/4518] 20% | Training loss: 0.6876056016139362
Epoch: 71 | Iteration number: [930/4518] 20% | Training loss: 0.6875980523324782
Epoch: 71 | Iteration number: [940/4518] 20% | Training loss: 0.6875965697334168
Epoch: 71 | Iteration number: [950/4518] 21% | Training loss: 0.6875802649949726
Epoch: 71 | Iteration number: [960/4518] 21% | Training loss: 0.6875564302007358
Epoch: 71 | Iteration number: [970/4518] 21% | Training loss: 0.6875553193780565
Epoch: 71 | Iteration number: [980/4518] 21% | Training loss: 0.6875522214539197
Epoch: 71 | Iteration number: [990/4518] 21% | Training loss: 0.6875514668647689
Epoch: 71 | Iteration number: [1000/4518] 22% | Training loss: 0.6875403160452843
Epoch: 71 | Iteration number: [1010/4518] 22% | Training loss: 0.6875285162784085
Epoch: 71 | Iteration number: [1020/4518] 22% | Training loss: 0.6875268579698076
Epoch: 71 | Iteration number: [1030/4518] 22% | Training loss: 0.6875205163238118
Epoch: 71 | Iteration number: [1040/4518] 23% | Training loss: 0.6875202958400433
Epoch: 71 | Iteration number: [1050/4518] 23% | Training loss: 0.6875091618015653
Epoch: 71 | Iteration number: [1060/4518] 23% | Training loss: 0.6875069677829743
Epoch: 71 | Iteration number: [1070/4518] 23% | Training loss: 0.6875047592916221
Epoch: 71 | Iteration number: [1080/4518] 23% | Training loss: 0.6875000800247546
Epoch: 71 | Iteration number: [1090/4518] 24% | Training loss: 0.6874914998308235
Epoch: 71 | Iteration number: [1100/4518] 24% | Training loss: 0.6874805754423141
Epoch: 71 | Iteration number: [1110/4518] 24% | Training loss: 0.6874760003777237
Epoch: 71 | Iteration number: [1120/4518] 24% | Training loss: 0.687481411706124
Epoch: 71 | Iteration number: [1130/4518] 25% | Training loss: 0.6874671266669721
Epoch: 71 | Iteration number: [1140/4518] 25% | Training loss: 0.6874498092814496
Epoch: 71 | Iteration number: [1150/4518] 25% | Training loss: 0.6874410956320556
Epoch: 71 | Iteration number: [1160/4518] 25% | Training loss: 0.6874281373517267
Epoch: 71 | Iteration number: [1170/4518] 25% | Training loss: 0.6874188627442743
Epoch: 71 | Iteration number: [1180/4518] 26% | Training loss: 0.6874183050656723
Epoch: 71 | Iteration number: [1190/4518] 26% | Training loss: 0.6874117559244652
Epoch: 71 | Iteration number: [1200/4518] 26% | Training loss: 0.6874169434110323
Epoch: 71 | Iteration number: [1210/4518] 26% | Training loss: 0.6874121807823497
Epoch: 71 | Iteration number: [1220/4518] 27% | Training loss: 0.6874108901277918
Epoch: 71 | Iteration number: [1230/4518] 27% | Training loss: 0.6874059390730974
Epoch: 71 | Iteration number: [1240/4518] 27% | Training loss: 0.6874065364560773
Epoch: 71 | Iteration number: [1250/4518] 27% | Training loss: 0.6874037296772003
Epoch: 71 | Iteration number: [1260/4518] 27% | Training loss: 0.6874054382244746
Epoch: 71 | Iteration number: [1270/4518] 28% | Training loss: 0.6874095105749416
Epoch: 71 | Iteration number: [1280/4518] 28% | Training loss: 0.687395789893344
Epoch: 71 | Iteration number: [1290/4518] 28% | Training loss: 0.6873887623927389
Epoch: 71 | Iteration number: [1300/4518] 28% | Training loss: 0.6873856166692881
Epoch: 71 | Iteration number: [1310/4518] 28% | Training loss: 0.6873812039389865
Epoch: 71 | Iteration number: [1320/4518] 29% | Training loss: 0.6873775189573115
Epoch: 71 | Iteration number: [1330/4518] 29% | Training loss: 0.6873707117442798
Epoch: 71 | Iteration number: [1340/4518] 29% | Training loss: 0.6873677016638998
Epoch: 71 | Iteration number: [1350/4518] 29% | Training loss: 0.6873563234011332
Epoch: 71 | Iteration number: [1360/4518] 30% | Training loss: 0.6873610693742247
Epoch: 71 | Iteration number: [1370/4518] 30% | Training loss: 0.6873646338055603
Epoch: 71 | Iteration number: [1380/4518] 30% | Training loss: 0.6873555305643358
Epoch: 71 | Iteration number: [1390/4518] 30% | Training loss: 0.6873456888919254
Epoch: 71 | Iteration number: [1400/4518] 30% | Training loss: 0.687353707424232
Epoch: 71 | Iteration number: [1410/4518] 31% | Training loss: 0.6873420840459512
Epoch: 71 | Iteration number: [1420/4518] 31% | Training loss: 0.6873400769183333
Epoch: 71 | Iteration number: [1430/4518] 31% | Training loss: 0.6873450705638299
Epoch: 71 | Iteration number: [1440/4518] 31% | Training loss: 0.6873307096047534
Epoch: 71 | Iteration number: [1450/4518] 32% | Training loss: 0.6873308716149166
Epoch: 71 | Iteration number: [1460/4518] 32% | Training loss: 0.687337919865569
Epoch: 71 | Iteration number: [1470/4518] 32% | Training loss: 0.6873258278483436
Epoch: 71 | Iteration number: [1480/4518] 32% | Training loss: 0.6873261468233289
Epoch: 71 | Iteration number: [1490/4518] 32% | Training loss: 0.6873272512183093
Epoch: 71 | Iteration number: [1500/4518] 33% | Training loss: 0.6873271829287211
Epoch: 71 | Iteration number: [1510/4518] 33% | Training loss: 0.6873285102528452
Epoch: 71 | Iteration number: [1520/4518] 33% | Training loss: 0.6873225019950616
Epoch: 71 | Iteration number: [1530/4518] 33% | Training loss: 0.6873206409363964
Epoch: 71 | Iteration number: [1540/4518] 34% | Training loss: 0.6873177892975993
Epoch: 71 | Iteration number: [1550/4518] 34% | Training loss: 0.6873118835495364
Epoch: 71 | Iteration number: [1560/4518] 34% | Training loss: 0.6873150300521117
Epoch: 71 | Iteration number: [1570/4518] 34% | Training loss: 0.687311472938319
Epoch: 71 | Iteration number: [1580/4518] 34% | Training loss: 0.6873097366547283
Epoch: 71 | Iteration number: [1590/4518] 35% | Training loss: 0.687309752957626
Epoch: 71 | Iteration number: [1600/4518] 35% | Training loss: 0.6873049105331301
Epoch: 71 | Iteration number: [1610/4518] 35% | Training loss: 0.6873025151513378
Epoch: 71 | Iteration number: [1620/4518] 35% | Training loss: 0.68729224142469
Epoch: 71 | Iteration number: [1630/4518] 36% | Training loss: 0.6872924428044652
Epoch: 71 | Iteration number: [1640/4518] 36% | Training loss: 0.6872885884308233
Epoch: 71 | Iteration number: [1650/4518] 36% | Training loss: 0.6872872273127238
Epoch: 71 | Iteration number: [1660/4518] 36% | Training loss: 0.6872739996895733
Epoch: 71 | Iteration number: [1670/4518] 36% | Training loss: 0.6872641382460108
Epoch: 71 | Iteration number: [1680/4518] 37% | Training loss: 0.6872588772504102
Epoch: 71 | Iteration number: [1690/4518] 37% | Training loss: 0.687262939807226
Epoch: 71 | Iteration number: [1700/4518] 37% | Training loss: 0.6872597838850583
Epoch: 71 | Iteration number: [1710/4518] 37% | Training loss: 0.6872593467347106
Epoch: 71 | Iteration number: [1720/4518] 38% | Training loss: 0.6872533122120902
Epoch: 71 | Iteration number: [1730/4518] 38% | Training loss: 0.6872466603455516
Epoch: 71 | Iteration number: [1740/4518] 38% | Training loss: 0.6872433065340436
Epoch: 71 | Iteration number: [1750/4518] 38% | Training loss: 0.6872403317178999
Epoch: 71 | Iteration number: [1760/4518] 38% | Training loss: 0.6872407107867978
Epoch: 71 | Iteration number: [1770/4518] 39% | Training loss: 0.6872332029423471
Epoch: 71 | Iteration number: [1780/4518] 39% | Training loss: 0.6872286309352081
Epoch: 71 | Iteration number: [1790/4518] 39% | Training loss: 0.6872296912710094
Epoch: 71 | Iteration number: [1800/4518] 39% | Training loss: 0.6872368607918421
Epoch: 71 | Iteration number: [1810/4518] 40% | Training loss: 0.6872363885133964
Epoch: 71 | Iteration number: [1820/4518] 40% | Training loss: 0.6872356429204836
Epoch: 71 | Iteration number: [1830/4518] 40% | Training loss: 0.6872358087633477
Epoch: 71 | Iteration number: [1840/4518] 40% | Training loss: 0.6872268256285916
Epoch: 71 | Iteration number: [1850/4518] 40% | Training loss: 0.6872157402940698
Epoch: 71 | Iteration number: [1860/4518] 41% | Training loss: 0.687212531957575
Epoch: 71 | Iteration number: [1870/4518] 41% | Training loss: 0.6872073906946947
Epoch: 71 | Iteration number: [1880/4518] 41% | Training loss: 0.6871994066745677
Epoch: 71 | Iteration number: [1890/4518] 41% | Training loss: 0.6871972153426478
Epoch: 71 | Iteration number: [1900/4518] 42% | Training loss: 0.6871934340188378
Epoch: 71 | Iteration number: [1910/4518] 42% | Training loss: 0.6871883234740552
Epoch: 71 | Iteration number: [1920/4518] 42% | Training loss: 0.6871863626254101
Epoch: 71 | Iteration number: [1930/4518] 42% | Training loss: 0.6871788819527996
Epoch: 71 | Iteration number: [1940/4518] 42% | Training loss: 0.6871722402031889
Epoch: 71 | Iteration number: [1950/4518] 43% | Training loss: 0.6871750335509961
Epoch: 71 | Iteration number: [1960/4518] 43% | Training loss: 0.6871702258075987
Epoch: 71 | Iteration number: [1970/4518] 43% | Training loss: 0.6871614347557126
Epoch: 71 | Iteration number: [1980/4518] 43% | Training loss: 0.6871559417006945
Epoch: 71 | Iteration number: [1990/4518] 44% | Training loss: 0.6871570807006491
Epoch: 71 | Iteration number: [2000/4518] 44% | Training loss: 0.6871579891443252
Epoch: 71 | Iteration number: [2010/4518] 44% | Training loss: 0.6871595534815718
Epoch: 71 | Iteration number: [2020/4518] 44% | Training loss: 0.6871525487097183
Epoch: 71 | Iteration number: [2030/4518] 44% | Training loss: 0.6871578362481348
Epoch: 71 | Iteration number: [2040/4518] 45% | Training loss: 0.6871518814680623
Epoch: 71 | Iteration number: [2050/4518] 45% | Training loss: 0.68714962089934
Epoch: 71 | Iteration number: [2060/4518] 45% | Training loss: 0.6871487523456221
Epoch: 71 | Iteration number: [2070/4518] 45% | Training loss: 0.6871436867161074
Epoch: 71 | Iteration number: [2080/4518] 46% | Training loss: 0.6871419480213752
Epoch: 71 | Iteration number: [2090/4518] 46% | Training loss: 0.6871387099250081
Epoch: 71 | Iteration number: [2100/4518] 46% | Training loss: 0.6871351332607724
Epoch: 71 | Iteration number: [2110/4518] 46% | Training loss: 0.6871421618201722
Epoch: 71 | Iteration number: [2120/4518] 46% | Training loss: 0.6871402129812061
Epoch: 71 | Iteration number: [2130/4518] 47% | Training loss: 0.6871404686444242
Epoch: 71 | Iteration number: [2140/4518] 47% | Training loss: 0.687144342872584
Epoch: 71 | Iteration number: [2150/4518] 47% | Training loss: 0.6871447592557862
Epoch: 71 | Iteration number: [2160/4518] 47% | Training loss: 0.6871502100593514
Epoch: 71 | Iteration number: [2170/4518] 48% | Training loss: 0.6871512163344616
Epoch: 71 | Iteration number: [2180/4518] 48% | Training loss: 0.6871510401504849
Epoch: 71 | Iteration number: [2190/4518] 48% | Training loss: 0.687152262773688
Epoch: 71 | Iteration number: [2200/4518] 48% | Training loss: 0.6871433348005468
Epoch: 71 | Iteration number: [2210/4518] 48% | Training loss: 0.6871393160043259
Epoch: 71 | Iteration number: [2220/4518] 49% | Training loss: 0.6871357993499653
Epoch: 71 | Iteration number: [2230/4518] 49% | Training loss: 0.6871379572714391
Epoch: 71 | Iteration number: [2240/4518] 49% | Training loss: 0.6871362136144723
Epoch: 71 | Iteration number: [2250/4518] 49% | Training loss: 0.6871321642663744
Epoch: 71 | Iteration number: [2260/4518] 50% | Training loss: 0.6871313636809324
Epoch: 71 | Iteration number: [2270/4518] 50% | Training loss: 0.6871350654421399
Epoch: 71 | Iteration number: [2280/4518] 50% | Training loss: 0.687133148939986
Epoch: 71 | Iteration number: [2290/4518] 50% | Training loss: 0.6871295179342078
Epoch: 71 | Iteration number: [2300/4518] 50% | Training loss: 0.68712625487991
Epoch: 71 | Iteration number: [2310/4518] 51% | Training loss: 0.6871289837411988
Epoch: 71 | Iteration number: [2320/4518] 51% | Training loss: 0.6871266201395413
Epoch: 71 | Iteration number: [2330/4518] 51% | Training loss: 0.6871288700932597
Epoch: 71 | Iteration number: [2340/4518] 51% | Training loss: 0.6871274285846286
Epoch: 71 | Iteration number: [2350/4518] 52% | Training loss: 0.6871279296215544
Epoch: 71 | Iteration number: [2360/4518] 52% | Training loss: 0.687124893776441
Epoch: 71 | Iteration number: [2370/4518] 52% | Training loss: 0.6871225318828212
Epoch: 71 | Iteration number: [2380/4518] 52% | Training loss: 0.6871195000510256
Epoch: 71 | Iteration number: [2390/4518] 52% | Training loss: 0.6871198597812254
Epoch: 71 | Iteration number: [2400/4518] 53% | Training loss: 0.6871197935690483
Epoch: 71 | Iteration number: [2410/4518] 53% | Training loss: 0.6871200944872813
Epoch: 71 | Iteration number: [2420/4518] 53% | Training loss: 0.6871174981278821
Epoch: 71 | Iteration number: [2430/4518] 53% | Training loss: 0.6871169396388678
Epoch: 71 | Iteration number: [2440/4518] 54% | Training loss: 0.6871187552076872
Epoch: 71 | Iteration number: [2450/4518] 54% | Training loss: 0.6871186747113053
Epoch: 71 | Iteration number: [2460/4518] 54% | Training loss: 0.6871187428633372
Epoch: 71 | Iteration number: [2470/4518] 54% | Training loss: 0.6871159156083095
Epoch: 71 | Iteration number: [2480/4518] 54% | Training loss: 0.6871116840791318
Epoch: 71 | Iteration number: [2490/4518] 55% | Training loss: 0.6871064482204406
Epoch: 71 | Iteration number: [2500/4518] 55% | Training loss: 0.6871013840913772
Epoch: 71 | Iteration number: [2510/4518] 55% | Training loss: 0.6870996490180254
Epoch: 71 | Iteration number: [2520/4518] 55% | Training loss: 0.6870973226569947
Epoch: 71 | Iteration number: [2530/4518] 55% | Training loss: 0.6870937152813545
Epoch: 71 | Iteration number: [2540/4518] 56% | Training loss: 0.6870959948367021
Epoch: 71 | Iteration number: [2550/4518] 56% | Training loss: 0.6870920128448337
Epoch: 71 | Iteration number: [2560/4518] 56% | Training loss: 0.6870897366432474
Epoch: 71 | Iteration number: [2570/4518] 56% | Training loss: 0.6870864889037285
Epoch: 71 | Iteration number: [2580/4518] 57% | Training loss: 0.6870828802733459
Epoch: 71 | Iteration number: [2590/4518] 57% | Training loss: 0.6870811914845323
Epoch: 71 | Iteration number: [2600/4518] 57% | Training loss: 0.6870807933348876
Epoch: 71 | Iteration number: [2610/4518] 57% | Training loss: 0.6870827565476355
Epoch: 71 | Iteration number: [2620/4518] 57% | Training loss: 0.6870802887750946
Epoch: 71 | Iteration number: [2630/4518] 58% | Training loss: 0.6870808195705196
Epoch: 71 | Iteration number: [2640/4518] 58% | Training loss: 0.687078318315925
Epoch: 71 | Iteration number: [2650/4518] 58% | Training loss: 0.6870754338885253
Epoch: 71 | Iteration number: [2660/4518] 58% | Training loss: 0.6870750273752929
Epoch: 71 | Iteration number: [2670/4518] 59% | Training loss: 0.6870785273416212
Epoch: 71 | Iteration number: [2680/4518] 59% | Training loss: 0.687073400127354
Epoch: 71 | Iteration number: [2690/4518] 59% | Training loss: 0.6870754480805096
Epoch: 71 | Iteration number: [2700/4518] 59% | Training loss: 0.6870728458298577
Epoch: 71 | Iteration number: [2710/4518] 59% | Training loss: 0.6870704796261453
Epoch: 71 | Iteration number: [2720/4518] 60% | Training loss: 0.6870705381035804
Epoch: 71 | Iteration number: [2730/4518] 60% | Training loss: 0.6870701939631731
Epoch: 71 | Iteration number: [2740/4518] 60% | Training loss: 0.6870730946968941
Epoch: 71 | Iteration number: [2750/4518] 60% | Training loss: 0.6870703573877162
Epoch: 71 | Iteration number: [2760/4518] 61% | Training loss: 0.6870631025321242
Epoch: 71 | Iteration number: [2770/4518] 61% | Training loss: 0.687067633243244
Epoch: 71 | Iteration number: [2780/4518] 61% | Training loss: 0.6870688524606416
Epoch: 71 | Iteration number: [2790/4518] 61% | Training loss: 0.6870713992358108
Epoch: 71 | Iteration number: [2800/4518] 61% | Training loss: 0.6870730760054929
Epoch: 71 | Iteration number: [2810/4518] 62% | Training loss: 0.6870707736320767
Epoch: 71 | Iteration number: [2820/4518] 62% | Training loss: 0.6870673277065263
Epoch: 71 | Iteration number: [2830/4518] 62% | Training loss: 0.6870637067004565
Epoch: 71 | Iteration number: [2840/4518] 62% | Training loss: 0.6870661474449534
Epoch: 71 | Iteration number: [2850/4518] 63% | Training loss: 0.6870687378080268
Epoch: 71 | Iteration number: [2860/4518] 63% | Training loss: 0.6870681685376001
Epoch: 71 | Iteration number: [2870/4518] 63% | Training loss: 0.6870698673176848
Epoch: 71 | Iteration number: [2880/4518] 63% | Training loss: 0.687065562295417
Epoch: 71 | Iteration number: [2890/4518] 63% | Training loss: 0.6870651006286119
Epoch: 71 | Iteration number: [2900/4518] 64% | Training loss: 0.6870641523599624
Epoch: 71 | Iteration number: [2910/4518] 64% | Training loss: 0.687062549754926
Epoch: 71 | Iteration number: [2920/4518] 64% | Training loss: 0.687062925079914
Epoch: 71 | Iteration number: [2930/4518] 64% | Training loss: 0.6870643740424524
Epoch: 71 | Iteration number: [2940/4518] 65% | Training loss: 0.687064139798385
Epoch: 71 | Iteration number: [2950/4518] 65% | Training loss: 0.6870606041156639
Epoch: 71 | Iteration number: [2960/4518] 65% | Training loss: 0.687057323190006
Epoch: 71 | Iteration number: [2970/4518] 65% | Training loss: 0.6870584072087349
Epoch: 71 | Iteration number: [2980/4518] 65% | Training loss: 0.687063377315566
Epoch: 71 | Iteration number: [2990/4518] 66% | Training loss: 0.6870628095789498
Epoch: 71 | Iteration number: [3000/4518] 66% | Training loss: 0.687061139245828
Epoch: 71 | Iteration number: [3010/4518] 66% | Training loss: 0.6870628158317452
Epoch: 71 | Iteration number: [3020/4518] 66% | Training loss: 0.6870614385960118
Epoch: 71 | Iteration number: [3030/4518] 67% | Training loss: 0.6870606173973273
Epoch: 71 | Iteration number: [3040/4518] 67% | Training loss: 0.6870569584401031
Epoch: 71 | Iteration number: [3050/4518] 67% | Training loss: 0.687055858529982
Epoch: 71 | Iteration number: [3060/4518] 67% | Training loss: 0.6870550511319653
Epoch: 71 | Iteration number: [3070/4518] 67% | Training loss: 0.6870495023867207
Epoch: 71 | Iteration number: [3080/4518] 68% | Training loss: 0.6870491831140084
Epoch: 71 | Iteration number: [3090/4518] 68% | Training loss: 0.6870500337923229
Epoch: 71 | Iteration number: [3100/4518] 68% | Training loss: 0.687048253032469
Epoch: 71 | Iteration number: [3110/4518] 68% | Training loss: 0.6870455904788909
Epoch: 71 | Iteration number: [3120/4518] 69% | Training loss: 0.6870407373668291
Epoch: 71 | Iteration number: [3130/4518] 69% | Training loss: 0.687040403970895
Epoch: 71 | Iteration number: [3140/4518] 69% | Training loss: 0.6870380946025727
Epoch: 71 | Iteration number: [3150/4518] 69% | Training loss: 0.6870357460256606
Epoch: 71 | Iteration number: [3160/4518] 69% | Training loss: 0.6870345809791661
Epoch: 71 | Iteration number: [3170/4518] 70% | Training loss: 0.6870355398496995
Epoch: 71 | Iteration number: [3180/4518] 70% | Training loss: 0.6870369943057966
Epoch: 71 | Iteration number: [3190/4518] 70% | Training loss: 0.6870337326511694
Epoch: 71 | Iteration number: [3200/4518] 70% | Training loss: 0.6870322941243648
Epoch: 71 | Iteration number: [3210/4518] 71% | Training loss: 0.6870320416499521
Epoch: 71 | Iteration number: [3220/4518] 71% | Training loss: 0.6870316491919275
Epoch: 71 | Iteration number: [3230/4518] 71% | Training loss: 0.6870334548293252
Epoch: 71 | Iteration number: [3240/4518] 71% | Training loss: 0.687029863121333
Epoch: 71 | Iteration number: [3250/4518] 71% | Training loss: 0.687029629450578
Epoch: 71 | Iteration number: [3260/4518] 72% | Training loss: 0.6870283536750115
Epoch: 71 | Iteration number: [3270/4518] 72% | Training loss: 0.6870251407317065
Epoch: 71 | Iteration number: [3280/4518] 72% | Training loss: 0.6870280434445637
Epoch: 71 | Iteration number: [3290/4518] 72% | Training loss: 0.687029932117752
Epoch: 71 | Iteration number: [3300/4518] 73% | Training loss: 0.6870318090554439
Epoch: 71 | Iteration number: [3310/4518] 73% | Training loss: 0.6870287266382638
Epoch: 71 | Iteration number: [3320/4518] 73% | Training loss: 0.6870309307812208
Epoch: 71 | Iteration number: [3330/4518] 73% | Training loss: 0.6870314465091751
Epoch: 71 | Iteration number: [3340/4518] 73% | Training loss: 0.68702995748577
Epoch: 71 | Iteration number: [3350/4518] 74% | Training loss: 0.687032402504736
Epoch: 71 | Iteration number: [3360/4518] 74% | Training loss: 0.6870275503645341
Epoch: 71 | Iteration number: [3370/4518] 74% | Training loss: 0.6870270380811097
Epoch: 71 | Iteration number: [3380/4518] 74% | Training loss: 0.6870272192376605
Epoch: 71 | Iteration number: [3390/4518] 75% | Training loss: 0.6870231444153462
Epoch: 71 | Iteration number: [3400/4518] 75% | Training loss: 0.6870240500394036
Epoch: 71 | Iteration number: [3410/4518] 75% | Training loss: 0.6870233471442527
Epoch: 71 | Iteration number: [3420/4518] 75% | Training loss: 0.6870210967565837
Epoch: 71 | Iteration number: [3430/4518] 75% | Training loss: 0.6870205494127191
Epoch: 71 | Iteration number: [3440/4518] 76% | Training loss: 0.6870234078619369
Epoch: 71 | Iteration number: [3450/4518] 76% | Training loss: 0.6870224331772846
Epoch: 71 | Iteration number: [3460/4518] 76% | Training loss: 0.6870196371581513
Epoch: 71 | Iteration number: [3470/4518] 76% | Training loss: 0.6870201821629527
Epoch: 71 | Iteration number: [3480/4518] 77% | Training loss: 0.6870185395938226
Epoch: 71 | Iteration number: [3490/4518] 77% | Training loss: 0.6870186571746979
Epoch: 71 | Iteration number: [3500/4518] 77% | Training loss: 0.6870192596060889
Epoch: 71 | Iteration number: [3510/4518] 77% | Training loss: 0.6870171284743524
Epoch: 71 | Iteration number: [3520/4518] 77% | Training loss: 0.6870179003273899
Epoch: 71 | Iteration number: [3530/4518] 78% | Training loss: 0.687017525238626
Epoch: 71 | Iteration number: [3540/4518] 78% | Training loss: 0.6870145610160073
Epoch: 71 | Iteration number: [3550/4518] 78% | Training loss: 0.6870161148024277
Epoch: 71 | Iteration number: [3560/4518] 78% | Training loss: 0.6870157981354199
Epoch: 71 | Iteration number: [3570/4518] 79% | Training loss: 0.6870168065991389
Epoch: 71 | Iteration number: [3580/4518] 79% | Training loss: 0.6870134293533571
Epoch: 71 | Iteration number: [3590/4518] 79% | Training loss: 0.6870130535121748
Epoch: 71 | Iteration number: [3600/4518] 79% | Training loss: 0.6870146694117122
Epoch: 71 | Iteration number: [3610/4518] 79% | Training loss: 0.6870168766486677
Epoch: 71 | Iteration number: [3620/4518] 80% | Training loss: 0.6870181827584683
Epoch: 71 | Iteration number: [3630/4518] 80% | Training loss: 0.6870167005653224
Epoch: 71 | Iteration number: [3640/4518] 80% | Training loss: 0.6870169347786641
Epoch: 71 | Iteration number: [3650/4518] 80% | Training loss: 0.6870164679664456
Epoch: 71 | Iteration number: [3660/4518] 81% | Training loss: 0.6870155517195092
Epoch: 71 | Iteration number: [3670/4518] 81% | Training loss: 0.6870144317195591
Epoch: 71 | Iteration number: [3680/4518] 81% | Training loss: 0.687012753246919
Epoch: 71 | Iteration number: [3690/4518] 81% | Training loss: 0.6870123120342813
Epoch: 71 | Iteration number: [3700/4518] 81% | Training loss: 0.687008386447623
Epoch: 71 | Iteration number: [3710/4518] 82% | Training loss: 0.6870083808095628
Epoch: 71 | Iteration number: [3720/4518] 82% | Training loss: 0.6870058030691198
Epoch: 71 | Iteration number: [3730/4518] 82% | Training loss: 0.6870069883783765
Epoch: 71 | Iteration number: [3740/4518] 82% | Training loss: 0.687008508848634
Epoch: 71 | Iteration number: [3750/4518] 83% | Training loss: 0.6870069862842559
Epoch: 71 | Iteration number: [3760/4518] 83% | Training loss: 0.6870035433705817
Epoch: 71 | Iteration number: [3770/4518] 83% | Training loss: 0.686999381442285
Epoch: 71 | Iteration number: [3780/4518] 83% | Training loss: 0.6869968195283224
Epoch: 71 | Iteration number: [3790/4518] 83% | Training loss: 0.6869936949187658
Epoch: 71 | Iteration number: [3800/4518] 84% | Training loss: 0.6869893314336476
Epoch: 71 | Iteration number: [3810/4518] 84% | Training loss: 0.6869894803508999
Epoch: 71 | Iteration number: [3820/4518] 84% | Training loss: 0.6869912530115138
Epoch: 71 | Iteration number: [3830/4518] 84% | Training loss: 0.6869944679674841
Epoch: 71 | Iteration number: [3840/4518] 84% | Training loss: 0.6869949345011264
Epoch: 71 | Iteration number: [3850/4518] 85% | Training loss: 0.6869970338065903
Epoch: 71 | Iteration number: [3860/4518] 85% | Training loss: 0.6869963550969109
Epoch: 71 | Iteration number: [3870/4518] 85% | Training loss: 0.686999376584085
Epoch: 71 | Iteration number: [3880/4518] 85% | Training loss: 0.6870020577741652
Epoch: 71 | Iteration number: [3890/4518] 86% | Training loss: 0.6870032442259605
Epoch: 71 | Iteration number: [3900/4518] 86% | Training loss: 0.6870015726334009
Epoch: 71 | Iteration number: [3910/4518] 86% | Training loss: 0.6870013006965218
Epoch: 71 | Iteration number: [3920/4518] 86% | Training loss: 0.6870001641919419
Epoch: 71 | Iteration number: [3930/4518] 86% | Training loss: 0.6869976025804612
Epoch: 71 | Iteration number: [3940/4518] 87% | Training loss: 0.6869958762438769
Epoch: 71 | Iteration number: [3950/4518] 87% | Training loss: 0.6869953665250464
Epoch: 71 | Iteration number: [3960/4518] 87% | Training loss: 0.6869960880490265
Epoch: 71 | Iteration number: [3970/4518] 87% | Training loss: 0.6869929755815031
Epoch: 71 | Iteration number: [3980/4518] 88% | Training loss: 0.6869917695995551
Epoch: 71 | Iteration number: [3990/4518] 88% | Training loss: 0.6869906937717495
Epoch: 71 | Iteration number: [4000/4518] 88% | Training loss: 0.6869932736158371
Epoch: 71 | Iteration number: [4010/4518] 88% | Training loss: 0.6869922816902028
Epoch: 71 | Iteration number: [4020/4518] 88% | Training loss: 0.686995072166125
Epoch: 71 | Iteration number: [4030/4518] 89% | Training loss: 0.6869905970084756
Epoch: 71 | Iteration number: [4040/4518] 89% | Training loss: 0.6869908904232601
Epoch: 71 | Iteration number: [4050/4518] 89% | Training loss: 0.6869925571665352
Epoch: 71 | Iteration number: [4060/4518] 89% | Training loss: 0.6869898605963279
Epoch: 71 | Iteration number: [4070/4518] 90% | Training loss: 0.6869885412715284
Epoch: 71 | Iteration number: [4080/4518] 90% | Training loss: 0.6869856367946839
Epoch: 71 | Iteration number: [4090/4518] 90% | Training loss: 0.6869852917992981
Epoch: 71 | Iteration number: [4100/4518] 90% | Training loss: 0.686982848673332
Epoch: 71 | Iteration number: [4110/4518] 90% | Training loss: 0.6869808564365926
Epoch: 71 | Iteration number: [4120/4518] 91% | Training loss: 0.6869797315991041
Epoch: 71 | Iteration number: [4130/4518] 91% | Training loss: 0.6869784137671565
Epoch: 71 | Iteration number: [4140/4518] 91% | Training loss: 0.6869797369852159
Epoch: 71 | Iteration number: [4150/4518] 91% | Training loss: 0.6869765594924789
Epoch: 71 | Iteration number: [4160/4518] 92% | Training loss: 0.6869742099338999
Epoch: 71 | Iteration number: [4170/4518] 92% | Training loss: 0.686972889311308
Epoch: 71 | Iteration number: [4180/4518] 92% | Training loss: 0.6869741969844371
Epoch: 71 | Iteration number: [4190/4518] 92% | Training loss: 0.6869710992088182
Epoch: 71 | Iteration number: [4200/4518] 92% | Training loss: 0.6869726198627836
Epoch: 71 | Iteration number: [4210/4518] 93% | Training loss: 0.6869696137457733
Epoch: 71 | Iteration number: [4220/4518] 93% | Training loss: 0.6869678990959556
Epoch: 71 | Iteration number: [4230/4518] 93% | Training loss: 0.68696545097563
Epoch: 71 | Iteration number: [4240/4518] 93% | Training loss: 0.686963575698857
Epoch: 71 | Iteration number: [4250/4518] 94% | Training loss: 0.6869633694536545
Epoch: 71 | Iteration number: [4260/4518] 94% | Training loss: 0.686962350209554
Epoch: 71 | Iteration number: [4270/4518] 94% | Training loss: 0.6869616741458482
Epoch: 71 | Iteration number: [4280/4518] 94% | Training loss: 0.686963310809893
Epoch: 71 | Iteration number: [4290/4518] 94% | Training loss: 0.6869601183421128
Epoch: 71 | Iteration number: [4300/4518] 95% | Training loss: 0.6869618718984515
Epoch: 71 | Iteration number: [4310/4518] 95% | Training loss: 0.6869657418705748
Epoch: 71 | Iteration number: [4320/4518] 95% | Training loss: 0.6869657372986829
Epoch: 71 | Iteration number: [4330/4518] 95% | Training loss: 0.6869647676482211
Epoch: 71 | Iteration number: [4340/4518] 96% | Training loss: 0.6869647500701763
Epoch: 71 | Iteration number: [4350/4518] 96% | Training loss: 0.6869634139263767
Epoch: 71 | Iteration number: [4360/4518] 96% | Training loss: 0.6869621047186195
Epoch: 71 | Iteration number: [4370/4518] 96% | Training loss: 0.6869599204177987
Epoch: 71 | Iteration number: [4380/4518] 96% | Training loss: 0.6869585373902429
Epoch: 71 | Iteration number: [4390/4518] 97% | Training loss: 0.6869585425544166
Epoch: 71 | Iteration number: [4400/4518] 97% | Training loss: 0.686955897835168
Epoch: 71 | Iteration number: [4410/4518] 97% | Training loss: 0.686952767945201
Epoch: 71 | Iteration number: [4420/4518] 97% | Training loss: 0.6869507881176418
Epoch: 71 | Iteration number: [4430/4518] 98% | Training loss: 0.6869495131630392
Epoch: 71 | Iteration number: [4440/4518] 98% | Training loss: 0.6869485074603879
Epoch: 71 | Iteration number: [4450/4518] 98% | Training loss: 0.6869477551170949
Epoch: 71 | Iteration number: [4460/4518] 98% | Training loss: 0.6869448238156836
Epoch: 71 | Iteration number: [4470/4518] 98% | Training loss: 0.6869448102027245
Epoch: 71 | Iteration number: [4480/4518] 99% | Training loss: 0.6869424213788339
Epoch: 71 | Iteration number: [4490/4518] 99% | Training loss: 0.6869432770462504
Epoch: 71 | Iteration number: [4500/4518] 99% | Training loss: 0.6869415172073576
Epoch: 71 | Iteration number: [4510/4518] 99% | Training loss: 0.6869383212071565

 End of epoch: 71 | Train Loss: 0.6867877120146344 | Training Time: 642 

 End of epoch: 71 | Eval Loss: 0.6900188691762029 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/4518] 0% | Training loss: 0.7555021524429322
Epoch: 72 | Iteration number: [20/4518] 0% | Training loss: 0.720565888285637
Epoch: 72 | Iteration number: [30/4518] 0% | Training loss: 0.7094886978467305
Epoch: 72 | Iteration number: [40/4518] 0% | Training loss: 0.7037572339177132
Epoch: 72 | Iteration number: [50/4518] 1% | Training loss: 0.7003202784061432
Epoch: 72 | Iteration number: [60/4518] 1% | Training loss: 0.6981460283199946
Epoch: 72 | Iteration number: [70/4518] 1% | Training loss: 0.6965660606111799
Epoch: 72 | Iteration number: [80/4518] 1% | Training loss: 0.6952905520796776
Epoch: 72 | Iteration number: [90/4518] 1% | Training loss: 0.6942990667290158
Epoch: 72 | Iteration number: [100/4518] 2% | Training loss: 0.693516137599945
Epoch: 72 | Iteration number: [110/4518] 2% | Training loss: 0.6929319316690619
Epoch: 72 | Iteration number: [120/4518] 2% | Training loss: 0.6924441094199817
Epoch: 72 | Iteration number: [130/4518] 2% | Training loss: 0.692040112385383
Epoch: 72 | Iteration number: [140/4518] 3% | Training loss: 0.6916883570807321
Epoch: 72 | Iteration number: [150/4518] 3% | Training loss: 0.6913620507717133
Epoch: 72 | Iteration number: [160/4518] 3% | Training loss: 0.6910366274416446
Epoch: 72 | Iteration number: [170/4518] 3% | Training loss: 0.6908215161632089
Epoch: 72 | Iteration number: [180/4518] 3% | Training loss: 0.6906080202923881
Epoch: 72 | Iteration number: [190/4518] 4% | Training loss: 0.6904036575242093
Epoch: 72 | Iteration number: [200/4518] 4% | Training loss: 0.6902208283543587
Epoch: 72 | Iteration number: [210/4518] 4% | Training loss: 0.6899450077897027
Epoch: 72 | Iteration number: [220/4518] 4% | Training loss: 0.6897972052747553
Epoch: 72 | Iteration number: [230/4518] 5% | Training loss: 0.6897541377855384
Epoch: 72 | Iteration number: [240/4518] 5% | Training loss: 0.6896293267607689
Epoch: 72 | Iteration number: [250/4518] 5% | Training loss: 0.6895137057304382
Epoch: 72 | Iteration number: [260/4518] 5% | Training loss: 0.6894235537602351
Epoch: 72 | Iteration number: [270/4518] 5% | Training loss: 0.6892525655251962
Epoch: 72 | Iteration number: [280/4518] 6% | Training loss: 0.6891675991671425
Epoch: 72 | Iteration number: [290/4518] 6% | Training loss: 0.6891022036815512
Epoch: 72 | Iteration number: [300/4518] 6% | Training loss: 0.6890104979276657
Epoch: 72 | Iteration number: [310/4518] 6% | Training loss: 0.6889542593109992
Epoch: 72 | Iteration number: [320/4518] 7% | Training loss: 0.6888675525784492
Epoch: 72 | Iteration number: [330/4518] 7% | Training loss: 0.6887931224071618
Epoch: 72 | Iteration number: [340/4518] 7% | Training loss: 0.6886998707757277
Epoch: 72 | Iteration number: [350/4518] 7% | Training loss: 0.6886396602221898
Epoch: 72 | Iteration number: [360/4518] 7% | Training loss: 0.6885843106442028
Epoch: 72 | Iteration number: [370/4518] 8% | Training loss: 0.6885645117308642
Epoch: 72 | Iteration number: [380/4518] 8% | Training loss: 0.6884966221294905
Epoch: 72 | Iteration number: [390/4518] 8% | Training loss: 0.6884371927151314
Epoch: 72 | Iteration number: [400/4518] 8% | Training loss: 0.6884219181537629
Epoch: 72 | Iteration number: [410/4518] 9% | Training loss: 0.6884035021793552
Epoch: 72 | Iteration number: [420/4518] 9% | Training loss: 0.6884068689176015
Epoch: 72 | Iteration number: [430/4518] 9% | Training loss: 0.6884041041828866
Epoch: 72 | Iteration number: [440/4518] 9% | Training loss: 0.6883798299865289
Epoch: 72 | Iteration number: [450/4518] 9% | Training loss: 0.6883116217454275
Epoch: 72 | Iteration number: [460/4518] 10% | Training loss: 0.6882996144502059
Epoch: 72 | Iteration number: [470/4518] 10% | Training loss: 0.6882638638323926
Epoch: 72 | Iteration number: [480/4518] 10% | Training loss: 0.6882098592817784
Epoch: 72 | Iteration number: [490/4518] 10% | Training loss: 0.6881814071110317
Epoch: 72 | Iteration number: [500/4518] 11% | Training loss: 0.6881450984477997
Epoch: 72 | Iteration number: [510/4518] 11% | Training loss: 0.6881187673877267
Epoch: 72 | Iteration number: [520/4518] 11% | Training loss: 0.6880969961102192
Epoch: 72 | Iteration number: [530/4518] 11% | Training loss: 0.6880685151747937
Epoch: 72 | Iteration number: [540/4518] 11% | Training loss: 0.6880505781482767
Epoch: 72 | Iteration number: [550/4518] 12% | Training loss: 0.6880254328250885
Epoch: 72 | Iteration number: [560/4518] 12% | Training loss: 0.688001646740096
Epoch: 72 | Iteration number: [570/4518] 12% | Training loss: 0.6879920107230806
Epoch: 72 | Iteration number: [580/4518] 12% | Training loss: 0.6879856636811947
Epoch: 72 | Iteration number: [590/4518] 13% | Training loss: 0.6879662945108899
Epoch: 72 | Iteration number: [600/4518] 13% | Training loss: 0.6879428016146024
Epoch: 72 | Iteration number: [610/4518] 13% | Training loss: 0.6879279069236067
Epoch: 72 | Iteration number: [620/4518] 13% | Training loss: 0.6878971637256683
Epoch: 72 | Iteration number: [630/4518] 13% | Training loss: 0.687895385235075
Epoch: 72 | Iteration number: [640/4518] 14% | Training loss: 0.6878688902594149
Epoch: 72 | Iteration number: [650/4518] 14% | Training loss: 0.6878382889124063
Epoch: 72 | Iteration number: [660/4518] 14% | Training loss: 0.6878204097350439
Epoch: 72 | Iteration number: [670/4518] 14% | Training loss: 0.6878159023932556
Epoch: 72 | Iteration number: [680/4518] 15% | Training loss: 0.6878124658675755
Epoch: 72 | Iteration number: [690/4518] 15% | Training loss: 0.6877918562163478
Epoch: 72 | Iteration number: [700/4518] 15% | Training loss: 0.6877642931256975
Epoch: 72 | Iteration number: [710/4518] 15% | Training loss: 0.6877470816524935
Epoch: 72 | Iteration number: [720/4518] 15% | Training loss: 0.6877255679004722
Epoch: 72 | Iteration number: [730/4518] 16% | Training loss: 0.6877214435028703
Epoch: 72 | Iteration number: [740/4518] 16% | Training loss: 0.687715369462967
Epoch: 72 | Iteration number: [750/4518] 16% | Training loss: 0.6877166210810344
Epoch: 72 | Iteration number: [760/4518] 16% | Training loss: 0.6877088980455147
Epoch: 72 | Iteration number: [770/4518] 17% | Training loss: 0.687673368933913
Epoch: 72 | Iteration number: [780/4518] 17% | Training loss: 0.687673881649971
Epoch: 72 | Iteration number: [790/4518] 17% | Training loss: 0.687673316499855
Epoch: 72 | Iteration number: [800/4518] 17% | Training loss: 0.6876645550131798
Epoch: 72 | Iteration number: [810/4518] 17% | Training loss: 0.6876635696417019
Epoch: 72 | Iteration number: [820/4518] 18% | Training loss: 0.6876494078374491
Epoch: 72 | Iteration number: [830/4518] 18% | Training loss: 0.6876190997031798
Epoch: 72 | Iteration number: [840/4518] 18% | Training loss: 0.6876136700312296
Epoch: 72 | Iteration number: [850/4518] 18% | Training loss: 0.6876096933028277
Epoch: 72 | Iteration number: [860/4518] 19% | Training loss: 0.6876290839078815
Epoch: 72 | Iteration number: [870/4518] 19% | Training loss: 0.6876085866456745
Epoch: 72 | Iteration number: [880/4518] 19% | Training loss: 0.6875952670520002
Epoch: 72 | Iteration number: [890/4518] 19% | Training loss: 0.6875907198096929
Epoch: 72 | Iteration number: [900/4518] 19% | Training loss: 0.6875922122266558
Epoch: 72 | Iteration number: [910/4518] 20% | Training loss: 0.6875827425128811
Epoch: 72 | Iteration number: [920/4518] 20% | Training loss: 0.6875801771231319
Epoch: 72 | Iteration number: [930/4518] 20% | Training loss: 0.6875851574123547
Epoch: 72 | Iteration number: [940/4518] 20% | Training loss: 0.6875795140545419
Epoch: 72 | Iteration number: [950/4518] 21% | Training loss: 0.6875794926442598
Epoch: 72 | Iteration number: [960/4518] 21% | Training loss: 0.6875735349332293
Epoch: 72 | Iteration number: [970/4518] 21% | Training loss: 0.6875683807835137
Epoch: 72 | Iteration number: [980/4518] 21% | Training loss: 0.6875698616310042
Epoch: 72 | Iteration number: [990/4518] 21% | Training loss: 0.6875655818467188
Epoch: 72 | Iteration number: [1000/4518] 22% | Training loss: 0.6875599518418312
Epoch: 72 | Iteration number: [1010/4518] 22% | Training loss: 0.6875424042786702
Epoch: 72 | Iteration number: [1020/4518] 22% | Training loss: 0.6875342508741453
Epoch: 72 | Iteration number: [1030/4518] 22% | Training loss: 0.6875400156072042
Epoch: 72 | Iteration number: [1040/4518] 23% | Training loss: 0.6875423591297406
Epoch: 72 | Iteration number: [1050/4518] 23% | Training loss: 0.6875324661958785
Epoch: 72 | Iteration number: [1060/4518] 23% | Training loss: 0.6875296119249092
Epoch: 72 | Iteration number: [1070/4518] 23% | Training loss: 0.6875284225027137
Epoch: 72 | Iteration number: [1080/4518] 23% | Training loss: 0.6875209717286958
Epoch: 72 | Iteration number: [1090/4518] 24% | Training loss: 0.6875150851700285
Epoch: 72 | Iteration number: [1100/4518] 24% | Training loss: 0.6875088413195176
Epoch: 72 | Iteration number: [1110/4518] 24% | Training loss: 0.6875022082715421
Epoch: 72 | Iteration number: [1120/4518] 24% | Training loss: 0.6875043446464199
Epoch: 72 | Iteration number: [1130/4518] 25% | Training loss: 0.6874990674774204
Epoch: 72 | Iteration number: [1140/4518] 25% | Training loss: 0.6874972613757117
Epoch: 72 | Iteration number: [1150/4518] 25% | Training loss: 0.6874884325525035
Epoch: 72 | Iteration number: [1160/4518] 25% | Training loss: 0.687478683529229
Epoch: 72 | Iteration number: [1170/4518] 25% | Training loss: 0.6874747990543006
Epoch: 72 | Iteration number: [1180/4518] 26% | Training loss: 0.6874581349098077
Epoch: 72 | Iteration number: [1190/4518] 26% | Training loss: 0.6874679701167996
Epoch: 72 | Iteration number: [1200/4518] 26% | Training loss: 0.6874681503574054
Epoch: 72 | Iteration number: [1210/4518] 26% | Training loss: 0.6874647715367561
Epoch: 72 | Iteration number: [1220/4518] 27% | Training loss: 0.6874696029014274
Epoch: 72 | Iteration number: [1230/4518] 27% | Training loss: 0.6874598416371074
Epoch: 72 | Iteration number: [1240/4518] 27% | Training loss: 0.6874506028909837
Epoch: 72 | Iteration number: [1250/4518] 27% | Training loss: 0.6874434909820557
Epoch: 72 | Iteration number: [1260/4518] 27% | Training loss: 0.6874445662612007
Epoch: 72 | Iteration number: [1270/4518] 28% | Training loss: 0.6874439695219355
Epoch: 72 | Iteration number: [1280/4518] 28% | Training loss: 0.6874353528954089
Epoch: 72 | Iteration number: [1290/4518] 28% | Training loss: 0.6874282415061034
Epoch: 72 | Iteration number: [1300/4518] 28% | Training loss: 0.68742613696135
Epoch: 72 | Iteration number: [1310/4518] 28% | Training loss: 0.6874204277082254
Epoch: 72 | Iteration number: [1320/4518] 29% | Training loss: 0.6874185272690022
Epoch: 72 | Iteration number: [1330/4518] 29% | Training loss: 0.6874174154790721
Epoch: 72 | Iteration number: [1340/4518] 29% | Training loss: 0.6874015631515589
Epoch: 72 | Iteration number: [1350/4518] 29% | Training loss: 0.6873941354398374
Epoch: 72 | Iteration number: [1360/4518] 30% | Training loss: 0.6873853886828704
Epoch: 72 | Iteration number: [1370/4518] 30% | Training loss: 0.6873896606212114
Epoch: 72 | Iteration number: [1380/4518] 30% | Training loss: 0.6873868353124978
Epoch: 72 | Iteration number: [1390/4518] 30% | Training loss: 0.6873846385547583
Epoch: 72 | Iteration number: [1400/4518] 30% | Training loss: 0.6873775865350451
Epoch: 72 | Iteration number: [1410/4518] 31% | Training loss: 0.6873650721624388
Epoch: 72 | Iteration number: [1420/4518] 31% | Training loss: 0.6873525006250596
Epoch: 72 | Iteration number: [1430/4518] 31% | Training loss: 0.6873553617434068
Epoch: 72 | Iteration number: [1440/4518] 31% | Training loss: 0.6873511673261722
Epoch: 72 | Iteration number: [1450/4518] 32% | Training loss: 0.6873487163823226
Epoch: 72 | Iteration number: [1460/4518] 32% | Training loss: 0.6873436504439132
Epoch: 72 | Iteration number: [1470/4518] 32% | Training loss: 0.6873320388956135
Epoch: 72 | Iteration number: [1480/4518] 32% | Training loss: 0.6873359580700462
Epoch: 72 | Iteration number: [1490/4518] 32% | Training loss: 0.6873312544902699
Epoch: 72 | Iteration number: [1500/4518] 33% | Training loss: 0.6873353719711304
Epoch: 72 | Iteration number: [1510/4518] 33% | Training loss: 0.6873302130509686
Epoch: 72 | Iteration number: [1520/4518] 33% | Training loss: 0.6873226174790609
Epoch: 72 | Iteration number: [1530/4518] 33% | Training loss: 0.687325571681939
Epoch: 72 | Iteration number: [1540/4518] 34% | Training loss: 0.687323800077686
Epoch: 72 | Iteration number: [1550/4518] 34% | Training loss: 0.6873146875058451
Epoch: 72 | Iteration number: [1560/4518] 34% | Training loss: 0.687309162509747
Epoch: 72 | Iteration number: [1570/4518] 34% | Training loss: 0.6873023834957439
Epoch: 72 | Iteration number: [1580/4518] 34% | Training loss: 0.6872956202754491
Epoch: 72 | Iteration number: [1590/4518] 35% | Training loss: 0.687292508321738
Epoch: 72 | Iteration number: [1600/4518] 35% | Training loss: 0.6872867280617356
Epoch: 72 | Iteration number: [1610/4518] 35% | Training loss: 0.6872781576947395
Epoch: 72 | Iteration number: [1620/4518] 35% | Training loss: 0.6872763105748613
Epoch: 72 | Iteration number: [1630/4518] 36% | Training loss: 0.6872816131158841
Epoch: 72 | Iteration number: [1640/4518] 36% | Training loss: 0.6872781481684708
Epoch: 72 | Iteration number: [1650/4518] 36% | Training loss: 0.6872746294556242
Epoch: 72 | Iteration number: [1660/4518] 36% | Training loss: 0.6872645913477403
Epoch: 72 | Iteration number: [1670/4518] 36% | Training loss: 0.6872658570369561
Epoch: 72 | Iteration number: [1680/4518] 37% | Training loss: 0.6872658563156923
Epoch: 72 | Iteration number: [1690/4518] 37% | Training loss: 0.6872647113701296
Epoch: 72 | Iteration number: [1700/4518] 37% | Training loss: 0.6872621026810478
Epoch: 72 | Iteration number: [1710/4518] 37% | Training loss: 0.6872534088223998
Epoch: 72 | Iteration number: [1720/4518] 38% | Training loss: 0.6872479700071867
Epoch: 72 | Iteration number: [1730/4518] 38% | Training loss: 0.6872410286368662
Epoch: 72 | Iteration number: [1740/4518] 38% | Training loss: 0.6872332561632682
Epoch: 72 | Iteration number: [1750/4518] 38% | Training loss: 0.6872367685522351
Epoch: 72 | Iteration number: [1760/4518] 38% | Training loss: 0.6872341792353175
Epoch: 72 | Iteration number: [1770/4518] 39% | Training loss: 0.6872324060922289
Epoch: 72 | Iteration number: [1780/4518] 39% | Training loss: 0.6872323767522748
Epoch: 72 | Iteration number: [1790/4518] 39% | Training loss: 0.6872259836956109
Epoch: 72 | Iteration number: [1800/4518] 39% | Training loss: 0.6872207034627597
Epoch: 72 | Iteration number: [1810/4518] 40% | Training loss: 0.687209039663083
Epoch: 72 | Iteration number: [1820/4518] 40% | Training loss: 0.68720055943007
Epoch: 72 | Iteration number: [1830/4518] 40% | Training loss: 0.6871936218986094
Epoch: 72 | Iteration number: [1840/4518] 40% | Training loss: 0.6871903510521288
Epoch: 72 | Iteration number: [1850/4518] 40% | Training loss: 0.6871945535492253
Epoch: 72 | Iteration number: [1860/4518] 41% | Training loss: 0.6871925470008645
Epoch: 72 | Iteration number: [1870/4518] 41% | Training loss: 0.6871934426659568
Epoch: 72 | Iteration number: [1880/4518] 41% | Training loss: 0.6871920905848767
Epoch: 72 | Iteration number: [1890/4518] 41% | Training loss: 0.6871902740821636
Epoch: 72 | Iteration number: [1900/4518] 42% | Training loss: 0.6871870137515821
Epoch: 72 | Iteration number: [1910/4518] 42% | Training loss: 0.6871814690647325
Epoch: 72 | Iteration number: [1920/4518] 42% | Training loss: 0.6871793299913407
Epoch: 72 | Iteration number: [1930/4518] 42% | Training loss: 0.687179288808546
Epoch: 72 | Iteration number: [1940/4518] 42% | Training loss: 0.6871766376433913
Epoch: 72 | Iteration number: [1950/4518] 43% | Training loss: 0.6871764814242338
Epoch: 72 | Iteration number: [1960/4518] 43% | Training loss: 0.6871653676945336
Epoch: 72 | Iteration number: [1970/4518] 43% | Training loss: 0.687159459724039
Epoch: 72 | Iteration number: [1980/4518] 43% | Training loss: 0.6871558139420519
Epoch: 72 | Iteration number: [1990/4518] 44% | Training loss: 0.6871536766763907
Epoch: 72 | Iteration number: [2000/4518] 44% | Training loss: 0.6871553567945957
Epoch: 72 | Iteration number: [2010/4518] 44% | Training loss: 0.6871535689083498
Epoch: 72 | Iteration number: [2020/4518] 44% | Training loss: 0.6871521051862453
Epoch: 72 | Iteration number: [2030/4518] 44% | Training loss: 0.6871548191373571
Epoch: 72 | Iteration number: [2040/4518] 45% | Training loss: 0.6871488087609703
Epoch: 72 | Iteration number: [2050/4518] 45% | Training loss: 0.6871496334599285
Epoch: 72 | Iteration number: [2060/4518] 45% | Training loss: 0.6871478709491711
Epoch: 72 | Iteration number: [2070/4518] 45% | Training loss: 0.6871465882529383
Epoch: 72 | Iteration number: [2080/4518] 46% | Training loss: 0.6871424013605485
Epoch: 72 | Iteration number: [2090/4518] 46% | Training loss: 0.687138827080932
Epoch: 72 | Iteration number: [2100/4518] 46% | Training loss: 0.6871377039523352
Epoch: 72 | Iteration number: [2110/4518] 46% | Training loss: 0.6871373494936956
Epoch: 72 | Iteration number: [2120/4518] 46% | Training loss: 0.6871269959604965
Epoch: 72 | Iteration number: [2130/4518] 47% | Training loss: 0.687131329713293
Epoch: 72 | Iteration number: [2140/4518] 47% | Training loss: 0.687129142936145
Epoch: 72 | Iteration number: [2150/4518] 47% | Training loss: 0.6871256819159486
Epoch: 72 | Iteration number: [2160/4518] 47% | Training loss: 0.6871184201704131
Epoch: 72 | Iteration number: [2170/4518] 48% | Training loss: 0.6871221809617934
Epoch: 72 | Iteration number: [2180/4518] 48% | Training loss: 0.6871270983590992
Epoch: 72 | Iteration number: [2190/4518] 48% | Training loss: 0.6871241918981892
Epoch: 72 | Iteration number: [2200/4518] 48% | Training loss: 0.6871178996562958
Epoch: 72 | Iteration number: [2210/4518] 48% | Training loss: 0.6871208827959466
Epoch: 72 | Iteration number: [2220/4518] 49% | Training loss: 0.6871271630128225
Epoch: 72 | Iteration number: [2230/4518] 49% | Training loss: 0.6871319633695577
Epoch: 72 | Iteration number: [2240/4518] 49% | Training loss: 0.6871330251385058
Epoch: 72 | Iteration number: [2250/4518] 49% | Training loss: 0.6871355867385864
Epoch: 72 | Iteration number: [2260/4518] 50% | Training loss: 0.6871396438474149
Epoch: 72 | Iteration number: [2270/4518] 50% | Training loss: 0.6871339692155695
Epoch: 72 | Iteration number: [2280/4518] 50% | Training loss: 0.6871272505375376
Epoch: 72 | Iteration number: [2290/4518] 50% | Training loss: 0.6871293470328552
Epoch: 72 | Iteration number: [2300/4518] 50% | Training loss: 0.6871257417875788
Epoch: 72 | Iteration number: [2310/4518] 51% | Training loss: 0.6871281391356414
Epoch: 72 | Iteration number: [2320/4518] 51% | Training loss: 0.6871232870323905
Epoch: 72 | Iteration number: [2330/4518] 51% | Training loss: 0.6871251118029648
Epoch: 72 | Iteration number: [2340/4518] 51% | Training loss: 0.6871271995652435
Epoch: 72 | Iteration number: [2350/4518] 52% | Training loss: 0.6871228939167997
Epoch: 72 | Iteration number: [2360/4518] 52% | Training loss: 0.6871193585759502
Epoch: 72 | Iteration number: [2370/4518] 52% | Training loss: 0.6871140381454919
Epoch: 72 | Iteration number: [2380/4518] 52% | Training loss: 0.6871148326316802
Epoch: 72 | Iteration number: [2390/4518] 52% | Training loss: 0.6871153578598629
Epoch: 72 | Iteration number: [2400/4518] 53% | Training loss: 0.6871105147153139
Epoch: 72 | Iteration number: [2410/4518] 53% | Training loss: 0.6871069172605934
Epoch: 72 | Iteration number: [2420/4518] 53% | Training loss: 0.6871032962129136
Epoch: 72 | Iteration number: [2430/4518] 53% | Training loss: 0.6871031167821139
Epoch: 72 | Iteration number: [2440/4518] 54% | Training loss: 0.6871011411557432
Epoch: 72 | Iteration number: [2450/4518] 54% | Training loss: 0.6871012231281826
Epoch: 72 | Iteration number: [2460/4518] 54% | Training loss: 0.6870985309525234
Epoch: 72 | Iteration number: [2470/4518] 54% | Training loss: 0.6870984856657654
Epoch: 72 | Iteration number: [2480/4518] 54% | Training loss: 0.6870969015504084
Epoch: 72 | Iteration number: [2490/4518] 55% | Training loss: 0.6870947755005465
Epoch: 72 | Iteration number: [2500/4518] 55% | Training loss: 0.6871001197814941
Epoch: 72 | Iteration number: [2510/4518] 55% | Training loss: 0.6870992711340763
Epoch: 72 | Iteration number: [2520/4518] 55% | Training loss: 0.6870944118452451
Epoch: 72 | Iteration number: [2530/4518] 55% | Training loss: 0.6870937412435358
Epoch: 72 | Iteration number: [2540/4518] 56% | Training loss: 0.6870911582013753
Epoch: 72 | Iteration number: [2550/4518] 56% | Training loss: 0.6870946124254489
Epoch: 72 | Iteration number: [2560/4518] 56% | Training loss: 0.6870896404376253
Epoch: 72 | Iteration number: [2570/4518] 56% | Training loss: 0.6870820058922823
Epoch: 72 | Iteration number: [2580/4518] 57% | Training loss: 0.6870804954637852
Epoch: 72 | Iteration number: [2590/4518] 57% | Training loss: 0.6870810128316917
Epoch: 72 | Iteration number: [2600/4518] 57% | Training loss: 0.6870762587052125
Epoch: 72 | Iteration number: [2610/4518] 57% | Training loss: 0.6870791495074714
Epoch: 72 | Iteration number: [2620/4518] 57% | Training loss: 0.6870819491056995
Epoch: 72 | Iteration number: [2630/4518] 58% | Training loss: 0.687076652843236
Epoch: 72 | Iteration number: [2640/4518] 58% | Training loss: 0.6870717196753531
Epoch: 72 | Iteration number: [2650/4518] 58% | Training loss: 0.6870770192371225
Epoch: 72 | Iteration number: [2660/4518] 58% | Training loss: 0.6870799441310697
Epoch: 72 | Iteration number: [2670/4518] 59% | Training loss: 0.6870778668016083
Epoch: 72 | Iteration number: [2680/4518] 59% | Training loss: 0.6870748469189032
Epoch: 72 | Iteration number: [2690/4518] 59% | Training loss: 0.6870751291402654
Epoch: 72 | Iteration number: [2700/4518] 59% | Training loss: 0.6870710051721997
Epoch: 72 | Iteration number: [2710/4518] 59% | Training loss: 0.6870680354618058
Epoch: 72 | Iteration number: [2720/4518] 60% | Training loss: 0.6870658650336897
Epoch: 72 | Iteration number: [2730/4518] 60% | Training loss: 0.6870649178386171
Epoch: 72 | Iteration number: [2740/4518] 60% | Training loss: 0.6870644967051318
Epoch: 72 | Iteration number: [2750/4518] 60% | Training loss: 0.6870632948225195
Epoch: 72 | Iteration number: [2760/4518] 61% | Training loss: 0.6870655367987744
Epoch: 72 | Iteration number: [2770/4518] 61% | Training loss: 0.6870667710846512
Epoch: 72 | Iteration number: [2780/4518] 61% | Training loss: 0.6870617251173198
Epoch: 72 | Iteration number: [2790/4518] 61% | Training loss: 0.687062156456773
Epoch: 72 | Iteration number: [2800/4518] 61% | Training loss: 0.6870576808069433
Epoch: 72 | Iteration number: [2810/4518] 62% | Training loss: 0.6870582427842761
Epoch: 72 | Iteration number: [2820/4518] 62% | Training loss: 0.6870623248900082
Epoch: 72 | Iteration number: [2830/4518] 62% | Training loss: 0.6870629852736375
Epoch: 72 | Iteration number: [2840/4518] 62% | Training loss: 0.6870541656101253
Epoch: 72 | Iteration number: [2850/4518] 63% | Training loss: 0.687048924847653
Epoch: 72 | Iteration number: [2860/4518] 63% | Training loss: 0.6870472448480712
Epoch: 72 | Iteration number: [2870/4518] 63% | Training loss: 0.6870446057269798
Epoch: 72 | Iteration number: [2880/4518] 63% | Training loss: 0.6870415814427866
Epoch: 72 | Iteration number: [2890/4518] 63% | Training loss: 0.6870413283369533
Epoch: 72 | Iteration number: [2900/4518] 64% | Training loss: 0.6870413126411109
Epoch: 72 | Iteration number: [2910/4518] 64% | Training loss: 0.687042578245766
Epoch: 72 | Iteration number: [2920/4518] 64% | Training loss: 0.6870426720544084
Epoch: 72 | Iteration number: [2930/4518] 64% | Training loss: 0.68703899214699
Epoch: 72 | Iteration number: [2940/4518] 65% | Training loss: 0.6870377176472929
Epoch: 72 | Iteration number: [2950/4518] 65% | Training loss: 0.687036499290143
Epoch: 72 | Iteration number: [2960/4518] 65% | Training loss: 0.6870342660795998
Epoch: 72 | Iteration number: [2970/4518] 65% | Training loss: 0.6870319277148456
Epoch: 72 | Iteration number: [2980/4518] 65% | Training loss: 0.6870328456163406
Epoch: 72 | Iteration number: [2990/4518] 66% | Training loss: 0.6870323419371577
Epoch: 72 | Iteration number: [3000/4518] 66% | Training loss: 0.6870331802765528
Epoch: 72 | Iteration number: [3010/4518] 66% | Training loss: 0.6870309308121767
Epoch: 72 | Iteration number: [3020/4518] 66% | Training loss: 0.6870339885847458
Epoch: 72 | Iteration number: [3030/4518] 67% | Training loss: 0.6870290887237775
Epoch: 72 | Iteration number: [3040/4518] 67% | Training loss: 0.6870311969008885
Epoch: 72 | Iteration number: [3050/4518] 67% | Training loss: 0.687032043992496
Epoch: 72 | Iteration number: [3060/4518] 67% | Training loss: 0.68703608002538
Epoch: 72 | Iteration number: [3070/4518] 67% | Training loss: 0.6870372183159819
Epoch: 72 | Iteration number: [3080/4518] 68% | Training loss: 0.6870347210919702
Epoch: 72 | Iteration number: [3090/4518] 68% | Training loss: 0.6870304878475597
Epoch: 72 | Iteration number: [3100/4518] 68% | Training loss: 0.687030596271638
Epoch: 72 | Iteration number: [3110/4518] 68% | Training loss: 0.6870283045186107
Epoch: 72 | Iteration number: [3120/4518] 69% | Training loss: 0.6870296832460624
Epoch: 72 | Iteration number: [3130/4518] 69% | Training loss: 0.6870346222251368
Epoch: 72 | Iteration number: [3140/4518] 69% | Training loss: 0.6870323851230038
Epoch: 72 | Iteration number: [3150/4518] 69% | Training loss: 0.6870311969802493
Epoch: 72 | Iteration number: [3160/4518] 69% | Training loss: 0.6870284599971168
Epoch: 72 | Iteration number: [3170/4518] 70% | Training loss: 0.6870259333672207
Epoch: 72 | Iteration number: [3180/4518] 70% | Training loss: 0.6870223471765998
Epoch: 72 | Iteration number: [3190/4518] 70% | Training loss: 0.6870179419046659
Epoch: 72 | Iteration number: [3200/4518] 70% | Training loss: 0.6870197725482285
Epoch: 72 | Iteration number: [3210/4518] 71% | Training loss: 0.6870207537743162
Epoch: 72 | Iteration number: [3220/4518] 71% | Training loss: 0.6870232985441729
Epoch: 72 | Iteration number: [3230/4518] 71% | Training loss: 0.6870209106350831
Epoch: 72 | Iteration number: [3240/4518] 71% | Training loss: 0.6870190572591476
Epoch: 72 | Iteration number: [3250/4518] 71% | Training loss: 0.6870196991700392
Epoch: 72 | Iteration number: [3260/4518] 72% | Training loss: 0.6870153807423598
Epoch: 72 | Iteration number: [3270/4518] 72% | Training loss: 0.6870136881822475
Epoch: 72 | Iteration number: [3280/4518] 72% | Training loss: 0.687012389465803
Epoch: 72 | Iteration number: [3290/4518] 72% | Training loss: 0.6870101675617659
Epoch: 72 | Iteration number: [3300/4518] 73% | Training loss: 0.6870125941977356
Epoch: 72 | Iteration number: [3310/4518] 73% | Training loss: 0.6870113727729487
Epoch: 72 | Iteration number: [3320/4518] 73% | Training loss: 0.687008066008608
Epoch: 72 | Iteration number: [3330/4518] 73% | Training loss: 0.6870075947171574
Epoch: 72 | Iteration number: [3340/4518] 73% | Training loss: 0.6870068739988133
Epoch: 72 | Iteration number: [3350/4518] 74% | Training loss: 0.6870053795736227
Epoch: 72 | Iteration number: [3360/4518] 74% | Training loss: 0.6870044830299559
Epoch: 72 | Iteration number: [3370/4518] 74% | Training loss: 0.6870063688882381
Epoch: 72 | Iteration number: [3380/4518] 74% | Training loss: 0.6870050222034285
Epoch: 72 | Iteration number: [3390/4518] 75% | Training loss: 0.6870060733461802
Epoch: 72 | Iteration number: [3400/4518] 75% | Training loss: 0.6870059354690945
Epoch: 72 | Iteration number: [3410/4518] 75% | Training loss: 0.6870028921411184
Epoch: 72 | Iteration number: [3420/4518] 75% | Training loss: 0.6870041618047402
Epoch: 72 | Iteration number: [3430/4518] 75% | Training loss: 0.6870036448229854
Epoch: 72 | Iteration number: [3440/4518] 76% | Training loss: 0.6870066957418308
Epoch: 72 | Iteration number: [3450/4518] 76% | Training loss: 0.6870065773915554
Epoch: 72 | Iteration number: [3460/4518] 76% | Training loss: 0.6870043129762473
Epoch: 72 | Iteration number: [3470/4518] 76% | Training loss: 0.6870013234422943
Epoch: 72 | Iteration number: [3480/4518] 77% | Training loss: 0.6869969642196578
Epoch: 72 | Iteration number: [3490/4518] 77% | Training loss: 0.6869917150213247
Epoch: 72 | Iteration number: [3500/4518] 77% | Training loss: 0.686989031621388
Epoch: 72 | Iteration number: [3510/4518] 77% | Training loss: 0.6869894998365658
Epoch: 72 | Iteration number: [3520/4518] 77% | Training loss: 0.6869903636249629
Epoch: 72 | Iteration number: [3530/4518] 78% | Training loss: 0.6869909672325123
Epoch: 72 | Iteration number: [3540/4518] 78% | Training loss: 0.6869852298397129
Epoch: 72 | Iteration number: [3550/4518] 78% | Training loss: 0.6869871154301603
Epoch: 72 | Iteration number: [3560/4518] 78% | Training loss: 0.6869908353418447
Epoch: 72 | Iteration number: [3570/4518] 79% | Training loss: 0.6869879557471983
Epoch: 72 | Iteration number: [3580/4518] 79% | Training loss: 0.6869876949147805
Epoch: 72 | Iteration number: [3590/4518] 79% | Training loss: 0.6869850181603498
Epoch: 72 | Iteration number: [3600/4518] 79% | Training loss: 0.6869844260646237
Epoch: 72 | Iteration number: [3610/4518] 79% | Training loss: 0.68698502376139
Epoch: 72 | Iteration number: [3620/4518] 80% | Training loss: 0.6869850628283801
Epoch: 72 | Iteration number: [3630/4518] 80% | Training loss: 0.6869853511329524
Epoch: 72 | Iteration number: [3640/4518] 80% | Training loss: 0.6869840977119875
Epoch: 72 | Iteration number: [3650/4518] 80% | Training loss: 0.6869846794866535
Epoch: 72 | Iteration number: [3660/4518] 81% | Training loss: 0.6869839786668944
Epoch: 72 | Iteration number: [3670/4518] 81% | Training loss: 0.686981011882465
Epoch: 72 | Iteration number: [3680/4518] 81% | Training loss: 0.6869811755483565
Epoch: 72 | Iteration number: [3690/4518] 81% | Training loss: 0.686979117496873
Epoch: 72 | Iteration number: [3700/4518] 81% | Training loss: 0.6869790863185316
Epoch: 72 | Iteration number: [3710/4518] 82% | Training loss: 0.6869770912629254
Epoch: 72 | Iteration number: [3720/4518] 82% | Training loss: 0.6869745671108205
Epoch: 72 | Iteration number: [3730/4518] 82% | Training loss: 0.6869731444455983
Epoch: 72 | Iteration number: [3740/4518] 82% | Training loss: 0.6869721600397385
Epoch: 72 | Iteration number: [3750/4518] 83% | Training loss: 0.6869720505396525
Epoch: 72 | Iteration number: [3760/4518] 83% | Training loss: 0.6869706864211154
Epoch: 72 | Iteration number: [3770/4518] 83% | Training loss: 0.6869714928400611
Epoch: 72 | Iteration number: [3780/4518] 83% | Training loss: 0.6869678368959478
Epoch: 72 | Iteration number: [3790/4518] 83% | Training loss: 0.6869628638736806
Epoch: 72 | Iteration number: [3800/4518] 84% | Training loss: 0.6869612466190991
Epoch: 72 | Iteration number: [3810/4518] 84% | Training loss: 0.686963029139311
Epoch: 72 | Iteration number: [3820/4518] 84% | Training loss: 0.6869629879896554
Epoch: 72 | Iteration number: [3830/4518] 84% | Training loss: 0.6869607445465367
Epoch: 72 | Iteration number: [3840/4518] 84% | Training loss: 0.6869599062949419
Epoch: 72 | Iteration number: [3850/4518] 85% | Training loss: 0.6869605698059131
Epoch: 72 | Iteration number: [3860/4518] 85% | Training loss: 0.6869622280251795
Epoch: 72 | Iteration number: [3870/4518] 85% | Training loss: 0.6869644575648838
Epoch: 72 | Iteration number: [3880/4518] 85% | Training loss: 0.6869617914416126
Epoch: 72 | Iteration number: [3890/4518] 86% | Training loss: 0.6869590967204087
Epoch: 72 | Iteration number: [3900/4518] 86% | Training loss: 0.6869583838413923
Epoch: 72 | Iteration number: [3910/4518] 86% | Training loss: 0.6869609004396307
Epoch: 72 | Iteration number: [3920/4518] 86% | Training loss: 0.6869624193225589
Epoch: 72 | Iteration number: [3930/4518] 86% | Training loss: 0.6869626084205152
Epoch: 72 | Iteration number: [3940/4518] 87% | Training loss: 0.686963421197107
Epoch: 72 | Iteration number: [3950/4518] 87% | Training loss: 0.6869602107850811
Epoch: 72 | Iteration number: [3960/4518] 87% | Training loss: 0.6869536486538974
Epoch: 72 | Iteration number: [3970/4518] 87% | Training loss: 0.6869489627160714
Epoch: 72 | Iteration number: [3980/4518] 88% | Training loss: 0.6869519459542318
Epoch: 72 | Iteration number: [3990/4518] 88% | Training loss: 0.6869504696892617
Epoch: 72 | Iteration number: [4000/4518] 88% | Training loss: 0.686949275881052
Epoch: 72 | Iteration number: [4010/4518] 88% | Training loss: 0.6869528783378458
Epoch: 72 | Iteration number: [4020/4518] 88% | Training loss: 0.6869497000429761
Epoch: 72 | Iteration number: [4030/4518] 89% | Training loss: 0.686948500658679
Epoch: 72 | Iteration number: [4040/4518] 89% | Training loss: 0.6869498580841735
Epoch: 72 | Iteration number: [4050/4518] 89% | Training loss: 0.6869459532219686
Epoch: 72 | Iteration number: [4060/4518] 89% | Training loss: 0.6869446779266367
Epoch: 72 | Iteration number: [4070/4518] 90% | Training loss: 0.6869467436535059
Epoch: 72 | Iteration number: [4080/4518] 90% | Training loss: 0.6869460476087589
Epoch: 72 | Iteration number: [4090/4518] 90% | Training loss: 0.6869477937886068
Epoch: 72 | Iteration number: [4100/4518] 90% | Training loss: 0.6869511193327787
Epoch: 72 | Iteration number: [4110/4518] 90% | Training loss: 0.6869471827562708
Epoch: 72 | Iteration number: [4120/4518] 91% | Training loss: 0.6869428256182994
Epoch: 72 | Iteration number: [4130/4518] 91% | Training loss: 0.6869406357082847
Epoch: 72 | Iteration number: [4140/4518] 91% | Training loss: 0.6869407133203773
Epoch: 72 | Iteration number: [4150/4518] 91% | Training loss: 0.686940160472709
Epoch: 72 | Iteration number: [4160/4518] 92% | Training loss: 0.6869374561195191
Epoch: 72 | Iteration number: [4170/4518] 92% | Training loss: 0.6869373476619629
Epoch: 72 | Iteration number: [4180/4518] 92% | Training loss: 0.6869397327375184
Epoch: 72 | Iteration number: [4190/4518] 92% | Training loss: 0.6869386627736694
Epoch: 72 | Iteration number: [4200/4518] 92% | Training loss: 0.6869414017030171
Epoch: 72 | Iteration number: [4210/4518] 93% | Training loss: 0.6869405504218756
Epoch: 72 | Iteration number: [4220/4518] 93% | Training loss: 0.6869430741992607
Epoch: 72 | Iteration number: [4230/4518] 93% | Training loss: 0.686945029592965
Epoch: 72 | Iteration number: [4240/4518] 93% | Training loss: 0.686945883718864
Epoch: 72 | Iteration number: [4250/4518] 94% | Training loss: 0.6869428414176492
Epoch: 72 | Iteration number: [4260/4518] 94% | Training loss: 0.6869396649895699
Epoch: 72 | Iteration number: [4270/4518] 94% | Training loss: 0.6869398223292912
Epoch: 72 | Iteration number: [4280/4518] 94% | Training loss: 0.6869417709724925
Epoch: 72 | Iteration number: [4290/4518] 94% | Training loss: 0.6869426319788108
Epoch: 72 | Iteration number: [4300/4518] 95% | Training loss: 0.6869412007719972
Epoch: 72 | Iteration number: [4310/4518] 95% | Training loss: 0.6869394945572811
Epoch: 72 | Iteration number: [4320/4518] 95% | Training loss: 0.6869383342978027
Epoch: 72 | Iteration number: [4330/4518] 95% | Training loss: 0.686940472340749
Epoch: 72 | Iteration number: [4340/4518] 96% | Training loss: 0.68693998708703
Epoch: 72 | Iteration number: [4350/4518] 96% | Training loss: 0.6869390410938482
Epoch: 72 | Iteration number: [4360/4518] 96% | Training loss: 0.6869384024941593
Epoch: 72 | Iteration number: [4370/4518] 96% | Training loss: 0.6869404893717995
Epoch: 72 | Iteration number: [4380/4518] 96% | Training loss: 0.6869413453830432
Epoch: 72 | Iteration number: [4390/4518] 97% | Training loss: 0.6869382122654578
Epoch: 72 | Iteration number: [4400/4518] 97% | Training loss: 0.6869367674534971
Epoch: 72 | Iteration number: [4410/4518] 97% | Training loss: 0.6869393319770052
Epoch: 72 | Iteration number: [4420/4518] 97% | Training loss: 0.6869402842688884
Epoch: 72 | Iteration number: [4430/4518] 98% | Training loss: 0.6869422212545813
Epoch: 72 | Iteration number: [4440/4518] 98% | Training loss: 0.686939324156658
Epoch: 72 | Iteration number: [4450/4518] 98% | Training loss: 0.6869381552331904
Epoch: 72 | Iteration number: [4460/4518] 98% | Training loss: 0.6869393559715673
Epoch: 72 | Iteration number: [4470/4518] 98% | Training loss: 0.6869356552226431
Epoch: 72 | Iteration number: [4480/4518] 99% | Training loss: 0.6869360386926149
Epoch: 72 | Iteration number: [4490/4518] 99% | Training loss: 0.6869377324071387
Epoch: 72 | Iteration number: [4500/4518] 99% | Training loss: 0.6869361721674602
Epoch: 72 | Iteration number: [4510/4518] 99% | Training loss: 0.6869371869215151

 End of epoch: 72 | Train Loss: 0.686782713219253 | Training Time: 640 

 End of epoch: 72 | Eval Loss: 0.6900958929743085 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/4518] 0% | Training loss: 0.7540324032306671
Epoch: 73 | Iteration number: [20/4518] 0% | Training loss: 0.7207742094993591
Epoch: 73 | Iteration number: [30/4518] 0% | Training loss: 0.7091513514518738
Epoch: 73 | Iteration number: [40/4518] 0% | Training loss: 0.7029952615499496
Epoch: 73 | Iteration number: [50/4518] 1% | Training loss: 0.6998376846313477
Epoch: 73 | Iteration number: [60/4518] 1% | Training loss: 0.6978563765684763
Epoch: 73 | Iteration number: [70/4518] 1% | Training loss: 0.6961309100900378
Epoch: 73 | Iteration number: [80/4518] 1% | Training loss: 0.6949635915458202
Epoch: 73 | Iteration number: [90/4518] 1% | Training loss: 0.693984740310245
Epoch: 73 | Iteration number: [100/4518] 2% | Training loss: 0.6931620228290558
Epoch: 73 | Iteration number: [110/4518] 2% | Training loss: 0.6925807649439032
Epoch: 73 | Iteration number: [120/4518] 2% | Training loss: 0.692194822927316
Epoch: 73 | Iteration number: [130/4518] 2% | Training loss: 0.691798834158824
Epoch: 73 | Iteration number: [140/4518] 3% | Training loss: 0.6913812769310815
Epoch: 73 | Iteration number: [150/4518] 3% | Training loss: 0.6911313688755035
Epoch: 73 | Iteration number: [160/4518] 3% | Training loss: 0.690798981115222
Epoch: 73 | Iteration number: [170/4518] 3% | Training loss: 0.6906239004696116
Epoch: 73 | Iteration number: [180/4518] 3% | Training loss: 0.6903911428319083
Epoch: 73 | Iteration number: [190/4518] 4% | Training loss: 0.6902120674911298
Epoch: 73 | Iteration number: [200/4518] 4% | Training loss: 0.6900934809446335
Epoch: 73 | Iteration number: [210/4518] 4% | Training loss: 0.6899385574318114
Epoch: 73 | Iteration number: [220/4518] 4% | Training loss: 0.689751210808754
Epoch: 73 | Iteration number: [230/4518] 5% | Training loss: 0.689673185866812
Epoch: 73 | Iteration number: [240/4518] 5% | Training loss: 0.689496806015571
Epoch: 73 | Iteration number: [250/4518] 5% | Training loss: 0.6893735826015472
Epoch: 73 | Iteration number: [260/4518] 5% | Training loss: 0.6892483163338441
Epoch: 73 | Iteration number: [270/4518] 5% | Training loss: 0.6891386890852893
Epoch: 73 | Iteration number: [280/4518] 6% | Training loss: 0.6890790798834392
Epoch: 73 | Iteration number: [290/4518] 6% | Training loss: 0.6889796976385445
Epoch: 73 | Iteration number: [300/4518] 6% | Training loss: 0.6889125080903371
Epoch: 73 | Iteration number: [310/4518] 6% | Training loss: 0.6888308575076442
Epoch: 73 | Iteration number: [320/4518] 7% | Training loss: 0.6888259505853057
Epoch: 73 | Iteration number: [330/4518] 7% | Training loss: 0.6887213166916009
Epoch: 73 | Iteration number: [340/4518] 7% | Training loss: 0.688661414384842
Epoch: 73 | Iteration number: [350/4518] 7% | Training loss: 0.6885926604270936
Epoch: 73 | Iteration number: [360/4518] 7% | Training loss: 0.6885272204875946
Epoch: 73 | Iteration number: [370/4518] 8% | Training loss: 0.688449388259166
Epoch: 73 | Iteration number: [380/4518] 8% | Training loss: 0.6884067772250426
Epoch: 73 | Iteration number: [390/4518] 8% | Training loss: 0.6883876985464341
Epoch: 73 | Iteration number: [400/4518] 8% | Training loss: 0.6883141238987446
Epoch: 73 | Iteration number: [410/4518] 9% | Training loss: 0.6882631765633095
Epoch: 73 | Iteration number: [420/4518] 9% | Training loss: 0.6882542764856702
Epoch: 73 | Iteration number: [430/4518] 9% | Training loss: 0.6882160584593928
Epoch: 73 | Iteration number: [440/4518] 9% | Training loss: 0.6881754741072654
Epoch: 73 | Iteration number: [450/4518] 9% | Training loss: 0.6881439136134253
Epoch: 73 | Iteration number: [460/4518] 10% | Training loss: 0.6881210321965425
Epoch: 73 | Iteration number: [470/4518] 10% | Training loss: 0.6880912664088797
Epoch: 73 | Iteration number: [480/4518] 10% | Training loss: 0.6880312565714121
Epoch: 73 | Iteration number: [490/4518] 10% | Training loss: 0.6880349363599505
Epoch: 73 | Iteration number: [500/4518] 11% | Training loss: 0.6879991555213928
Epoch: 73 | Iteration number: [510/4518] 11% | Training loss: 0.6879681076489242
Epoch: 73 | Iteration number: [520/4518] 11% | Training loss: 0.6879119126842572
Epoch: 73 | Iteration number: [530/4518] 11% | Training loss: 0.6878821218913456
Epoch: 73 | Iteration number: [540/4518] 11% | Training loss: 0.6878737054489277
Epoch: 73 | Iteration number: [550/4518] 12% | Training loss: 0.68786348472942
Epoch: 73 | Iteration number: [560/4518] 12% | Training loss: 0.6878485175115722
Epoch: 73 | Iteration number: [570/4518] 12% | Training loss: 0.6878300593610396
Epoch: 73 | Iteration number: [580/4518] 12% | Training loss: 0.6877942629929247
Epoch: 73 | Iteration number: [590/4518] 13% | Training loss: 0.6877923675512864
Epoch: 73 | Iteration number: [600/4518] 13% | Training loss: 0.6877864315112432
Epoch: 73 | Iteration number: [610/4518] 13% | Training loss: 0.6877530074510418
Epoch: 73 | Iteration number: [620/4518] 13% | Training loss: 0.6877503986320188
Epoch: 73 | Iteration number: [630/4518] 13% | Training loss: 0.6877197638390556
Epoch: 73 | Iteration number: [640/4518] 14% | Training loss: 0.687701812852174
Epoch: 73 | Iteration number: [650/4518] 14% | Training loss: 0.6876797462426699
Epoch: 73 | Iteration number: [660/4518] 14% | Training loss: 0.687650085308335
Epoch: 73 | Iteration number: [670/4518] 14% | Training loss: 0.6876319953754767
Epoch: 73 | Iteration number: [680/4518] 15% | Training loss: 0.6876350011895684
Epoch: 73 | Iteration number: [690/4518] 15% | Training loss: 0.6876195176787998
Epoch: 73 | Iteration number: [700/4518] 15% | Training loss: 0.6876040487630026
Epoch: 73 | Iteration number: [710/4518] 15% | Training loss: 0.6875911296253473
Epoch: 73 | Iteration number: [720/4518] 15% | Training loss: 0.6875588063564565
Epoch: 73 | Iteration number: [730/4518] 16% | Training loss: 0.6875492758946876
Epoch: 73 | Iteration number: [740/4518] 16% | Training loss: 0.6875328676926123
Epoch: 73 | Iteration number: [750/4518] 16% | Training loss: 0.6875209152698517
Epoch: 73 | Iteration number: [760/4518] 16% | Training loss: 0.687499909730334
Epoch: 73 | Iteration number: [770/4518] 17% | Training loss: 0.6874903336747901
Epoch: 73 | Iteration number: [780/4518] 17% | Training loss: 0.6874778183606954
Epoch: 73 | Iteration number: [790/4518] 17% | Training loss: 0.6874414516400688
Epoch: 73 | Iteration number: [800/4518] 17% | Training loss: 0.6874465558677911
Epoch: 73 | Iteration number: [810/4518] 17% | Training loss: 0.6874490317003227
Epoch: 73 | Iteration number: [820/4518] 18% | Training loss: 0.6874480462655789
Epoch: 73 | Iteration number: [830/4518] 18% | Training loss: 0.687448934618249
Epoch: 73 | Iteration number: [840/4518] 18% | Training loss: 0.687442656429041
Epoch: 73 | Iteration number: [850/4518] 18% | Training loss: 0.6874492908926572
Epoch: 73 | Iteration number: [860/4518] 19% | Training loss: 0.6874572597963865
Epoch: 73 | Iteration number: [870/4518] 19% | Training loss: 0.687442693765136
Epoch: 73 | Iteration number: [880/4518] 19% | Training loss: 0.6874376227909869
Epoch: 73 | Iteration number: [890/4518] 19% | Training loss: 0.6874224694257371
Epoch: 73 | Iteration number: [900/4518] 19% | Training loss: 0.6874111338456472
Epoch: 73 | Iteration number: [910/4518] 20% | Training loss: 0.6873961364174938
Epoch: 73 | Iteration number: [920/4518] 20% | Training loss: 0.6873986294736033
Epoch: 73 | Iteration number: [930/4518] 20% | Training loss: 0.687395994188965
Epoch: 73 | Iteration number: [940/4518] 20% | Training loss: 0.687398994412828
Epoch: 73 | Iteration number: [950/4518] 21% | Training loss: 0.6873792522831967
Epoch: 73 | Iteration number: [960/4518] 21% | Training loss: 0.6873629756892721
Epoch: 73 | Iteration number: [970/4518] 21% | Training loss: 0.6873520773096183
Epoch: 73 | Iteration number: [980/4518] 21% | Training loss: 0.6873374387925985
Epoch: 73 | Iteration number: [990/4518] 21% | Training loss: 0.6873179438138249
Epoch: 73 | Iteration number: [1000/4518] 22% | Training loss: 0.6873061919808388
Epoch: 73 | Iteration number: [1010/4518] 22% | Training loss: 0.687287011772099
Epoch: 73 | Iteration number: [1020/4518] 22% | Training loss: 0.6872821137601254
Epoch: 73 | Iteration number: [1030/4518] 22% | Training loss: 0.6872740536638834
Epoch: 73 | Iteration number: [1040/4518] 23% | Training loss: 0.687260766613942
Epoch: 73 | Iteration number: [1050/4518] 23% | Training loss: 0.6872571790218354
Epoch: 73 | Iteration number: [1060/4518] 23% | Training loss: 0.6872424050322119
Epoch: 73 | Iteration number: [1070/4518] 23% | Training loss: 0.6872449954536474
Epoch: 73 | Iteration number: [1080/4518] 23% | Training loss: 0.6872457415417389
Epoch: 73 | Iteration number: [1090/4518] 24% | Training loss: 0.6872420797107417
Epoch: 73 | Iteration number: [1100/4518] 24% | Training loss: 0.6872357786785472
Epoch: 73 | Iteration number: [1110/4518] 24% | Training loss: 0.6872380150868012
Epoch: 73 | Iteration number: [1120/4518] 24% | Training loss: 0.6872390976441758
Epoch: 73 | Iteration number: [1130/4518] 25% | Training loss: 0.6872270896371487
Epoch: 73 | Iteration number: [1140/4518] 25% | Training loss: 0.6872186050603264
Epoch: 73 | Iteration number: [1150/4518] 25% | Training loss: 0.6872131283386894
Epoch: 73 | Iteration number: [1160/4518] 25% | Training loss: 0.6872090428553779
Epoch: 73 | Iteration number: [1170/4518] 25% | Training loss: 0.6872007097953405
Epoch: 73 | Iteration number: [1180/4518] 26% | Training loss: 0.6871891332884966
Epoch: 73 | Iteration number: [1190/4518] 26% | Training loss: 0.687192093023733
Epoch: 73 | Iteration number: [1200/4518] 26% | Training loss: 0.6871796323855718
Epoch: 73 | Iteration number: [1210/4518] 26% | Training loss: 0.68717560181933
Epoch: 73 | Iteration number: [1220/4518] 27% | Training loss: 0.6871665898893701
Epoch: 73 | Iteration number: [1230/4518] 27% | Training loss: 0.6871588032420088
Epoch: 73 | Iteration number: [1240/4518] 27% | Training loss: 0.6871712029460938
Epoch: 73 | Iteration number: [1250/4518] 27% | Training loss: 0.6871680972099304
Epoch: 73 | Iteration number: [1260/4518] 27% | Training loss: 0.6871611892703979
Epoch: 73 | Iteration number: [1270/4518] 28% | Training loss: 0.6871511893948232
Epoch: 73 | Iteration number: [1280/4518] 28% | Training loss: 0.6871437747497111
Epoch: 73 | Iteration number: [1290/4518] 28% | Training loss: 0.687147762424262
Epoch: 73 | Iteration number: [1300/4518] 28% | Training loss: 0.6871329875175769
Epoch: 73 | Iteration number: [1310/4518] 28% | Training loss: 0.6871245990727693
Epoch: 73 | Iteration number: [1320/4518] 29% | Training loss: 0.6871283463456413
Epoch: 73 | Iteration number: [1330/4518] 29% | Training loss: 0.6871267248365216
Epoch: 73 | Iteration number: [1340/4518] 29% | Training loss: 0.687124777996718
Epoch: 73 | Iteration number: [1350/4518] 29% | Training loss: 0.6871240091765368
Epoch: 73 | Iteration number: [1360/4518] 30% | Training loss: 0.6871145518825335
Epoch: 73 | Iteration number: [1370/4518] 30% | Training loss: 0.6871105895860352
Epoch: 73 | Iteration number: [1380/4518] 30% | Training loss: 0.6871026862358701
Epoch: 73 | Iteration number: [1390/4518] 30% | Training loss: 0.6870923586886564
Epoch: 73 | Iteration number: [1400/4518] 30% | Training loss: 0.687092000075749
Epoch: 73 | Iteration number: [1410/4518] 31% | Training loss: 0.6871002051001744
Epoch: 73 | Iteration number: [1420/4518] 31% | Training loss: 0.6870973975305826
Epoch: 73 | Iteration number: [1430/4518] 31% | Training loss: 0.6870967048448282
Epoch: 73 | Iteration number: [1440/4518] 31% | Training loss: 0.6870894738783438
Epoch: 73 | Iteration number: [1450/4518] 32% | Training loss: 0.6870908808297125
Epoch: 73 | Iteration number: [1460/4518] 32% | Training loss: 0.6870804178388151
Epoch: 73 | Iteration number: [1470/4518] 32% | Training loss: 0.6870829203907325
Epoch: 73 | Iteration number: [1480/4518] 32% | Training loss: 0.6870897497679737
Epoch: 73 | Iteration number: [1490/4518] 32% | Training loss: 0.687093662135553
Epoch: 73 | Iteration number: [1500/4518] 33% | Training loss: 0.6870942972103755
Epoch: 73 | Iteration number: [1510/4518] 33% | Training loss: 0.6871008265886875
Epoch: 73 | Iteration number: [1520/4518] 33% | Training loss: 0.6871010679947702
Epoch: 73 | Iteration number: [1530/4518] 33% | Training loss: 0.6870970235151403
Epoch: 73 | Iteration number: [1540/4518] 34% | Training loss: 0.6870913292293425
Epoch: 73 | Iteration number: [1550/4518] 34% | Training loss: 0.6870937745801864
Epoch: 73 | Iteration number: [1560/4518] 34% | Training loss: 0.6870834999359571
Epoch: 73 | Iteration number: [1570/4518] 34% | Training loss: 0.6870811903552645
Epoch: 73 | Iteration number: [1580/4518] 34% | Training loss: 0.6870760392916353
Epoch: 73 | Iteration number: [1590/4518] 35% | Training loss: 0.687069484685202
Epoch: 73 | Iteration number: [1600/4518] 35% | Training loss: 0.6870654331892729
Epoch: 73 | Iteration number: [1610/4518] 35% | Training loss: 0.6870635157046111
Epoch: 73 | Iteration number: [1620/4518] 35% | Training loss: 0.6870544713956338
Epoch: 73 | Iteration number: [1630/4518] 36% | Training loss: 0.6870545582537271
Epoch: 73 | Iteration number: [1640/4518] 36% | Training loss: 0.6870574009127733
Epoch: 73 | Iteration number: [1650/4518] 36% | Training loss: 0.6870527924190868
Epoch: 73 | Iteration number: [1660/4518] 36% | Training loss: 0.6870469449514366
Epoch: 73 | Iteration number: [1670/4518] 36% | Training loss: 0.6870472621774959
Epoch: 73 | Iteration number: [1680/4518] 37% | Training loss: 0.6870385818893001
Epoch: 73 | Iteration number: [1690/4518] 37% | Training loss: 0.6870369814909422
Epoch: 73 | Iteration number: [1700/4518] 37% | Training loss: 0.6870342727268444
Epoch: 73 | Iteration number: [1710/4518] 37% | Training loss: 0.6870325351319118
Epoch: 73 | Iteration number: [1720/4518] 38% | Training loss: 0.6870351858956869
Epoch: 73 | Iteration number: [1730/4518] 38% | Training loss: 0.6870355936488665
Epoch: 73 | Iteration number: [1740/4518] 38% | Training loss: 0.6870332490781258
Epoch: 73 | Iteration number: [1750/4518] 38% | Training loss: 0.6870321872574943
Epoch: 73 | Iteration number: [1760/4518] 38% | Training loss: 0.6870273132893172
Epoch: 73 | Iteration number: [1770/4518] 39% | Training loss: 0.687036186052581
Epoch: 73 | Iteration number: [1780/4518] 39% | Training loss: 0.6870326018400407
Epoch: 73 | Iteration number: [1790/4518] 39% | Training loss: 0.6870292765468192
Epoch: 73 | Iteration number: [1800/4518] 39% | Training loss: 0.6870382878184319
Epoch: 73 | Iteration number: [1810/4518] 40% | Training loss: 0.6870379115336508
Epoch: 73 | Iteration number: [1820/4518] 40% | Training loss: 0.6870384546099129
Epoch: 73 | Iteration number: [1830/4518] 40% | Training loss: 0.6870417254544346
Epoch: 73 | Iteration number: [1840/4518] 40% | Training loss: 0.6870417939580005
Epoch: 73 | Iteration number: [1850/4518] 40% | Training loss: 0.6870388647350105
Epoch: 73 | Iteration number: [1860/4518] 41% | Training loss: 0.6870339345867916
Epoch: 73 | Iteration number: [1870/4518] 41% | Training loss: 0.6870364893247737
Epoch: 73 | Iteration number: [1880/4518] 41% | Training loss: 0.6870326234305159
Epoch: 73 | Iteration number: [1890/4518] 41% | Training loss: 0.6870329579032918
Epoch: 73 | Iteration number: [1900/4518] 42% | Training loss: 0.6870323484508615
Epoch: 73 | Iteration number: [1910/4518] 42% | Training loss: 0.6870332009505227
Epoch: 73 | Iteration number: [1920/4518] 42% | Training loss: 0.6870358163180451
Epoch: 73 | Iteration number: [1930/4518] 42% | Training loss: 0.6870355644374314
Epoch: 73 | Iteration number: [1940/4518] 42% | Training loss: 0.6870392363096021
Epoch: 73 | Iteration number: [1950/4518] 43% | Training loss: 0.6870389748842288
Epoch: 73 | Iteration number: [1960/4518] 43% | Training loss: 0.6870334813181235
Epoch: 73 | Iteration number: [1970/4518] 43% | Training loss: 0.6870300497500424
Epoch: 73 | Iteration number: [1980/4518] 43% | Training loss: 0.6870282862222556
Epoch: 73 | Iteration number: [1990/4518] 44% | Training loss: 0.6870247741440433
Epoch: 73 | Iteration number: [2000/4518] 44% | Training loss: 0.6870271980166435
Epoch: 73 | Iteration number: [2010/4518] 44% | Training loss: 0.6870199668466749
Epoch: 73 | Iteration number: [2020/4518] 44% | Training loss: 0.687016091193303
Epoch: 73 | Iteration number: [2030/4518] 44% | Training loss: 0.6870187897987554
Epoch: 73 | Iteration number: [2040/4518] 45% | Training loss: 0.687017325414162
Epoch: 73 | Iteration number: [2050/4518] 45% | Training loss: 0.6870223754499016
Epoch: 73 | Iteration number: [2060/4518] 45% | Training loss: 0.6870266977155093
Epoch: 73 | Iteration number: [2070/4518] 45% | Training loss: 0.6870224128598752
Epoch: 73 | Iteration number: [2080/4518] 46% | Training loss: 0.6870181519251604
Epoch: 73 | Iteration number: [2090/4518] 46% | Training loss: 0.6870120356813002
Epoch: 73 | Iteration number: [2100/4518] 46% | Training loss: 0.6870089822156089
Epoch: 73 | Iteration number: [2110/4518] 46% | Training loss: 0.6870008388119286
Epoch: 73 | Iteration number: [2120/4518] 46% | Training loss: 0.6870005546875719
Epoch: 73 | Iteration number: [2130/4518] 47% | Training loss: 0.6870021191281332
Epoch: 73 | Iteration number: [2140/4518] 47% | Training loss: 0.6870072548077485
Epoch: 73 | Iteration number: [2150/4518] 47% | Training loss: 0.6870032783718997
Epoch: 73 | Iteration number: [2160/4518] 47% | Training loss: 0.6870042538753263
Epoch: 73 | Iteration number: [2170/4518] 48% | Training loss: 0.6870067793378083
Epoch: 73 | Iteration number: [2180/4518] 48% | Training loss: 0.6870072898241358
Epoch: 73 | Iteration number: [2190/4518] 48% | Training loss: 0.6870072776596295
Epoch: 73 | Iteration number: [2200/4518] 48% | Training loss: 0.6870076007734646
Epoch: 73 | Iteration number: [2210/4518] 48% | Training loss: 0.6870056914797735
Epoch: 73 | Iteration number: [2220/4518] 49% | Training loss: 0.6869962400681263
Epoch: 73 | Iteration number: [2230/4518] 49% | Training loss: 0.6869985342560327
Epoch: 73 | Iteration number: [2240/4518] 49% | Training loss: 0.6869979351758957
Epoch: 73 | Iteration number: [2250/4518] 49% | Training loss: 0.6869926087061564
Epoch: 73 | Iteration number: [2260/4518] 50% | Training loss: 0.6869839969989473
Epoch: 73 | Iteration number: [2270/4518] 50% | Training loss: 0.6869799636796707
Epoch: 73 | Iteration number: [2280/4518] 50% | Training loss: 0.6869820907189135
Epoch: 73 | Iteration number: [2290/4518] 50% | Training loss: 0.6869812657218833
Epoch: 73 | Iteration number: [2300/4518] 50% | Training loss: 0.6869831912413887
Epoch: 73 | Iteration number: [2310/4518] 51% | Training loss: 0.6869804802395049
Epoch: 73 | Iteration number: [2320/4518] 51% | Training loss: 0.6869806143487321
Epoch: 73 | Iteration number: [2330/4518] 51% | Training loss: 0.6869775014629691
Epoch: 73 | Iteration number: [2340/4518] 51% | Training loss: 0.6869672078607428
Epoch: 73 | Iteration number: [2350/4518] 52% | Training loss: 0.6869657275778182
Epoch: 73 | Iteration number: [2360/4518] 52% | Training loss: 0.6869639351711435
Epoch: 73 | Iteration number: [2370/4518] 52% | Training loss: 0.6869586357336004
Epoch: 73 | Iteration number: [2380/4518] 52% | Training loss: 0.6869581265359366
Epoch: 73 | Iteration number: [2390/4518] 52% | Training loss: 0.6869611256042784
Epoch: 73 | Iteration number: [2400/4518] 53% | Training loss: 0.6869612868626912
Epoch: 73 | Iteration number: [2410/4518] 53% | Training loss: 0.6869660988635542
Epoch: 73 | Iteration number: [2420/4518] 53% | Training loss: 0.6869640312411568
Epoch: 73 | Iteration number: [2430/4518] 53% | Training loss: 0.6869637196201356
Epoch: 73 | Iteration number: [2440/4518] 54% | Training loss: 0.6869626562859191
Epoch: 73 | Iteration number: [2450/4518] 54% | Training loss: 0.6869651778133548
Epoch: 73 | Iteration number: [2460/4518] 54% | Training loss: 0.6869650703862431
Epoch: 73 | Iteration number: [2470/4518] 54% | Training loss: 0.6869652976632601
Epoch: 73 | Iteration number: [2480/4518] 54% | Training loss: 0.6869675342354082
Epoch: 73 | Iteration number: [2490/4518] 55% | Training loss: 0.6869680115736153
Epoch: 73 | Iteration number: [2500/4518] 55% | Training loss: 0.6869653856039047
Epoch: 73 | Iteration number: [2510/4518] 55% | Training loss: 0.6869661162336509
Epoch: 73 | Iteration number: [2520/4518] 55% | Training loss: 0.6869646058432639
Epoch: 73 | Iteration number: [2530/4518] 55% | Training loss: 0.6869617228215862
Epoch: 73 | Iteration number: [2540/4518] 56% | Training loss: 0.6869601291699672
Epoch: 73 | Iteration number: [2550/4518] 56% | Training loss: 0.6869575286379047
Epoch: 73 | Iteration number: [2560/4518] 56% | Training loss: 0.6869565167697147
Epoch: 73 | Iteration number: [2570/4518] 56% | Training loss: 0.6869554842028637
Epoch: 73 | Iteration number: [2580/4518] 57% | Training loss: 0.686955958096556
Epoch: 73 | Iteration number: [2590/4518] 57% | Training loss: 0.6869531918906797
Epoch: 73 | Iteration number: [2600/4518] 57% | Training loss: 0.6869514722090501
Epoch: 73 | Iteration number: [2610/4518] 57% | Training loss: 0.6869589338129051
Epoch: 73 | Iteration number: [2620/4518] 57% | Training loss: 0.6869588347564217
Epoch: 73 | Iteration number: [2630/4518] 58% | Training loss: 0.6869570290634387
Epoch: 73 | Iteration number: [2640/4518] 58% | Training loss: 0.6869592229751024
Epoch: 73 | Iteration number: [2650/4518] 58% | Training loss: 0.6869593289438284
Epoch: 73 | Iteration number: [2660/4518] 58% | Training loss: 0.6869600503964531
Epoch: 73 | Iteration number: [2670/4518] 59% | Training loss: 0.6869611989246326
Epoch: 73 | Iteration number: [2680/4518] 59% | Training loss: 0.6869651152571635
Epoch: 73 | Iteration number: [2690/4518] 59% | Training loss: 0.6869642608892519
Epoch: 73 | Iteration number: [2700/4518] 59% | Training loss: 0.6869624134567048
Epoch: 73 | Iteration number: [2710/4518] 59% | Training loss: 0.686959157526713
Epoch: 73 | Iteration number: [2720/4518] 60% | Training loss: 0.6869565437383511
Epoch: 73 | Iteration number: [2730/4518] 60% | Training loss: 0.6869573750338711
Epoch: 73 | Iteration number: [2740/4518] 60% | Training loss: 0.6869599318199784
Epoch: 73 | Iteration number: [2750/4518] 60% | Training loss: 0.6869580012885007
Epoch: 73 | Iteration number: [2760/4518] 61% | Training loss: 0.6869619480941607
Epoch: 73 | Iteration number: [2770/4518] 61% | Training loss: 0.6869634301653837
Epoch: 73 | Iteration number: [2780/4518] 61% | Training loss: 0.6869632972015751
Epoch: 73 | Iteration number: [2790/4518] 61% | Training loss: 0.6869616020537619
Epoch: 73 | Iteration number: [2800/4518] 61% | Training loss: 0.686959958417075
Epoch: 73 | Iteration number: [2810/4518] 62% | Training loss: 0.6869603888207907
Epoch: 73 | Iteration number: [2820/4518] 62% | Training loss: 0.6869613777661154
Epoch: 73 | Iteration number: [2830/4518] 62% | Training loss: 0.6869643842584253
Epoch: 73 | Iteration number: [2840/4518] 62% | Training loss: 0.6869624974652075
Epoch: 73 | Iteration number: [2850/4518] 63% | Training loss: 0.6869590909020943
Epoch: 73 | Iteration number: [2860/4518] 63% | Training loss: 0.6869660530890618
Epoch: 73 | Iteration number: [2870/4518] 63% | Training loss: 0.6869716965570682
Epoch: 73 | Iteration number: [2880/4518] 63% | Training loss: 0.6869724969483084
Epoch: 73 | Iteration number: [2890/4518] 63% | Training loss: 0.6869754171288962
Epoch: 73 | Iteration number: [2900/4518] 64% | Training loss: 0.686977222417963
Epoch: 73 | Iteration number: [2910/4518] 64% | Training loss: 0.6869724716927178
Epoch: 73 | Iteration number: [2920/4518] 64% | Training loss: 0.6869726231449271
Epoch: 73 | Iteration number: [2930/4518] 64% | Training loss: 0.6869759391192283
Epoch: 73 | Iteration number: [2940/4518] 65% | Training loss: 0.6869711017527548
Epoch: 73 | Iteration number: [2950/4518] 65% | Training loss: 0.6869729446960707
Epoch: 73 | Iteration number: [2960/4518] 65% | Training loss: 0.686973746584074
Epoch: 73 | Iteration number: [2970/4518] 65% | Training loss: 0.686971843082094
Epoch: 73 | Iteration number: [2980/4518] 65% | Training loss: 0.6869675228459723
Epoch: 73 | Iteration number: [2990/4518] 66% | Training loss: 0.6869631068562982
Epoch: 73 | Iteration number: [3000/4518] 66% | Training loss: 0.6869651170770327
Epoch: 73 | Iteration number: [3010/4518] 66% | Training loss: 0.6869658518075151
Epoch: 73 | Iteration number: [3020/4518] 66% | Training loss: 0.6869658079960488
Epoch: 73 | Iteration number: [3030/4518] 67% | Training loss: 0.6869659878239773
Epoch: 73 | Iteration number: [3040/4518] 67% | Training loss: 0.6869626925964104
Epoch: 73 | Iteration number: [3050/4518] 67% | Training loss: 0.6869574387737962
Epoch: 73 | Iteration number: [3060/4518] 67% | Training loss: 0.6869575047804639
Epoch: 73 | Iteration number: [3070/4518] 67% | Training loss: 0.6869556698814665
Epoch: 73 | Iteration number: [3080/4518] 68% | Training loss: 0.6869556592656421
Epoch: 73 | Iteration number: [3090/4518] 68% | Training loss: 0.6869565336256737
Epoch: 73 | Iteration number: [3100/4518] 68% | Training loss: 0.6869553900149561
Epoch: 73 | Iteration number: [3110/4518] 68% | Training loss: 0.6869541128540346
Epoch: 73 | Iteration number: [3120/4518] 69% | Training loss: 0.6869532869985471
Epoch: 73 | Iteration number: [3130/4518] 69% | Training loss: 0.6869548780659136
Epoch: 73 | Iteration number: [3140/4518] 69% | Training loss: 0.6869571401245275
Epoch: 73 | Iteration number: [3150/4518] 69% | Training loss: 0.6869549869544922
Epoch: 73 | Iteration number: [3160/4518] 69% | Training loss: 0.6869581288929227
Epoch: 73 | Iteration number: [3170/4518] 70% | Training loss: 0.6869611511283117
Epoch: 73 | Iteration number: [3180/4518] 70% | Training loss: 0.6869616390586649
Epoch: 73 | Iteration number: [3190/4518] 70% | Training loss: 0.6869628075895639
Epoch: 73 | Iteration number: [3200/4518] 70% | Training loss: 0.6869634383544326
Epoch: 73 | Iteration number: [3210/4518] 71% | Training loss: 0.6869629967249814
Epoch: 73 | Iteration number: [3220/4518] 71% | Training loss: 0.6869629080436245
Epoch: 73 | Iteration number: [3230/4518] 71% | Training loss: 0.6869624162975111
Epoch: 73 | Iteration number: [3240/4518] 71% | Training loss: 0.6869621628044564
Epoch: 73 | Iteration number: [3250/4518] 71% | Training loss: 0.6869604687874133
Epoch: 73 | Iteration number: [3260/4518] 72% | Training loss: 0.6869606302559741
Epoch: 73 | Iteration number: [3270/4518] 72% | Training loss: 0.6869610266036579
Epoch: 73 | Iteration number: [3280/4518] 72% | Training loss: 0.6869619729497084
Epoch: 73 | Iteration number: [3290/4518] 72% | Training loss: 0.6869633148687588
Epoch: 73 | Iteration number: [3300/4518] 73% | Training loss: 0.6869559568708593
Epoch: 73 | Iteration number: [3310/4518] 73% | Training loss: 0.6869605127238075
Epoch: 73 | Iteration number: [3320/4518] 73% | Training loss: 0.6869605307837566
Epoch: 73 | Iteration number: [3330/4518] 73% | Training loss: 0.6869615025706477
Epoch: 73 | Iteration number: [3340/4518] 73% | Training loss: 0.6869577303974929
Epoch: 73 | Iteration number: [3350/4518] 74% | Training loss: 0.6869599113713449
Epoch: 73 | Iteration number: [3360/4518] 74% | Training loss: 0.6869564350517023
Epoch: 73 | Iteration number: [3370/4518] 74% | Training loss: 0.6869555063877332
Epoch: 73 | Iteration number: [3380/4518] 74% | Training loss: 0.6869583953238098
Epoch: 73 | Iteration number: [3390/4518] 75% | Training loss: 0.6869539153611062
Epoch: 73 | Iteration number: [3400/4518] 75% | Training loss: 0.686955134535537
Epoch: 73 | Iteration number: [3410/4518] 75% | Training loss: 0.6869564478523221
Epoch: 73 | Iteration number: [3420/4518] 75% | Training loss: 0.6869528061813779
Epoch: 73 | Iteration number: [3430/4518] 75% | Training loss: 0.6869536669365519
Epoch: 73 | Iteration number: [3440/4518] 76% | Training loss: 0.686956411825363
Epoch: 73 | Iteration number: [3450/4518] 76% | Training loss: 0.6869574478225432
Epoch: 73 | Iteration number: [3460/4518] 76% | Training loss: 0.6869563978531457
Epoch: 73 | Iteration number: [3470/4518] 76% | Training loss: 0.6869555443095886
Epoch: 73 | Iteration number: [3480/4518] 77% | Training loss: 0.6869563371456903
Epoch: 73 | Iteration number: [3490/4518] 77% | Training loss: 0.686951014852114
Epoch: 73 | Iteration number: [3500/4518] 77% | Training loss: 0.6869540773630142
Epoch: 73 | Iteration number: [3510/4518] 77% | Training loss: 0.6869543316017869
Epoch: 73 | Iteration number: [3520/4518] 77% | Training loss: 0.6869531968100504
Epoch: 73 | Iteration number: [3530/4518] 78% | Training loss: 0.6869548939949393
Epoch: 73 | Iteration number: [3540/4518] 78% | Training loss: 0.6869535340259304
Epoch: 73 | Iteration number: [3550/4518] 78% | Training loss: 0.6869514452067899
Epoch: 73 | Iteration number: [3560/4518] 78% | Training loss: 0.6869492945878694
Epoch: 73 | Iteration number: [3570/4518] 79% | Training loss: 0.6869481943568596
Epoch: 73 | Iteration number: [3580/4518] 79% | Training loss: 0.6869483581634873
Epoch: 73 | Iteration number: [3590/4518] 79% | Training loss: 0.6869487625974798
Epoch: 73 | Iteration number: [3600/4518] 79% | Training loss: 0.686951177302334
Epoch: 73 | Iteration number: [3610/4518] 79% | Training loss: 0.6869500505957247
Epoch: 73 | Iteration number: [3620/4518] 80% | Training loss: 0.6869490331049124
Epoch: 73 | Iteration number: [3630/4518] 80% | Training loss: 0.6869482230384816
Epoch: 73 | Iteration number: [3640/4518] 80% | Training loss: 0.6869474802043412
Epoch: 73 | Iteration number: [3650/4518] 80% | Training loss: 0.6869465313382345
Epoch: 73 | Iteration number: [3660/4518] 81% | Training loss: 0.6869488145158591
Epoch: 73 | Iteration number: [3670/4518] 81% | Training loss: 0.6869487392967338
Epoch: 73 | Iteration number: [3680/4518] 81% | Training loss: 0.6869469174224397
Epoch: 73 | Iteration number: [3690/4518] 81% | Training loss: 0.6869430374162308
Epoch: 73 | Iteration number: [3700/4518] 81% | Training loss: 0.6869397874941697
Epoch: 73 | Iteration number: [3710/4518] 82% | Training loss: 0.6869429057659807
Epoch: 73 | Iteration number: [3720/4518] 82% | Training loss: 0.6869417443871498
Epoch: 73 | Iteration number: [3730/4518] 82% | Training loss: 0.6869411832046253
Epoch: 73 | Iteration number: [3740/4518] 82% | Training loss: 0.6869394431617808
Epoch: 73 | Iteration number: [3750/4518] 83% | Training loss: 0.6869394114812215
Epoch: 73 | Iteration number: [3760/4518] 83% | Training loss: 0.6869377028751881
Epoch: 73 | Iteration number: [3770/4518] 83% | Training loss: 0.6869379221602523
Epoch: 73 | Iteration number: [3780/4518] 83% | Training loss: 0.6869394631928237
Epoch: 73 | Iteration number: [3790/4518] 83% | Training loss: 0.6869382937539535
Epoch: 73 | Iteration number: [3800/4518] 84% | Training loss: 0.6869363548253712
Epoch: 73 | Iteration number: [3810/4518] 84% | Training loss: 0.6869363129138947
Epoch: 73 | Iteration number: [3820/4518] 84% | Training loss: 0.6869388018915167
Epoch: 73 | Iteration number: [3830/4518] 84% | Training loss: 0.686939484487937
Epoch: 73 | Iteration number: [3840/4518] 84% | Training loss: 0.6869390069041401
Epoch: 73 | Iteration number: [3850/4518] 85% | Training loss: 0.6869372316459557
Epoch: 73 | Iteration number: [3860/4518] 85% | Training loss: 0.6869358461601129
Epoch: 73 | Iteration number: [3870/4518] 85% | Training loss: 0.6869363487690918
Epoch: 73 | Iteration number: [3880/4518] 85% | Training loss: 0.6869367305611827
Epoch: 73 | Iteration number: [3890/4518] 86% | Training loss: 0.6869344686174761
Epoch: 73 | Iteration number: [3900/4518] 86% | Training loss: 0.6869346391390532
Epoch: 73 | Iteration number: [3910/4518] 86% | Training loss: 0.6869380688118508
Epoch: 73 | Iteration number: [3920/4518] 86% | Training loss: 0.6869377598926729
Epoch: 73 | Iteration number: [3930/4518] 86% | Training loss: 0.6869385803625481
Epoch: 73 | Iteration number: [3940/4518] 87% | Training loss: 0.6869376766651415
Epoch: 73 | Iteration number: [3950/4518] 87% | Training loss: 0.6869394385512871
Epoch: 73 | Iteration number: [3960/4518] 87% | Training loss: 0.6869374932664813
Epoch: 73 | Iteration number: [3970/4518] 87% | Training loss: 0.6869385916129768
Epoch: 73 | Iteration number: [3980/4518] 88% | Training loss: 0.6869354356323655
Epoch: 73 | Iteration number: [3990/4518] 88% | Training loss: 0.6869363751327783
Epoch: 73 | Iteration number: [4000/4518] 88% | Training loss: 0.686934825733304
Epoch: 73 | Iteration number: [4010/4518] 88% | Training loss: 0.6869330372744962
Epoch: 73 | Iteration number: [4020/4518] 88% | Training loss: 0.6869344375323301
Epoch: 73 | Iteration number: [4030/4518] 89% | Training loss: 0.6869336654471404
Epoch: 73 | Iteration number: [4040/4518] 89% | Training loss: 0.6869345974509079
Epoch: 73 | Iteration number: [4050/4518] 89% | Training loss: 0.6869333722561966
Epoch: 73 | Iteration number: [4060/4518] 89% | Training loss: 0.6869327472348519
Epoch: 73 | Iteration number: [4070/4518] 90% | Training loss: 0.6869354334598091
Epoch: 73 | Iteration number: [4080/4518] 90% | Training loss: 0.6869367395107653
Epoch: 73 | Iteration number: [4090/4518] 90% | Training loss: 0.6869375178312614
Epoch: 73 | Iteration number: [4100/4518] 90% | Training loss: 0.6869412355742803
Epoch: 73 | Iteration number: [4110/4518] 90% | Training loss: 0.6869435751815202
Epoch: 73 | Iteration number: [4120/4518] 91% | Training loss: 0.6869409308705515
Epoch: 73 | Iteration number: [4130/4518] 91% | Training loss: 0.6869376244614257
Epoch: 73 | Iteration number: [4140/4518] 91% | Training loss: 0.6869394545537838
Epoch: 73 | Iteration number: [4150/4518] 91% | Training loss: 0.686940866493317
Epoch: 73 | Iteration number: [4160/4518] 92% | Training loss: 0.6869409496394487
Epoch: 73 | Iteration number: [4170/4518] 92% | Training loss: 0.6869412844558414
Epoch: 73 | Iteration number: [4180/4518] 92% | Training loss: 0.686939744145106
Epoch: 73 | Iteration number: [4190/4518] 92% | Training loss: 0.6869417989595409
Epoch: 73 | Iteration number: [4200/4518] 92% | Training loss: 0.6869429439590091
Epoch: 73 | Iteration number: [4210/4518] 93% | Training loss: 0.6869427766058054
Epoch: 73 | Iteration number: [4220/4518] 93% | Training loss: 0.686939454982631
Epoch: 73 | Iteration number: [4230/4518] 93% | Training loss: 0.6869379785748521
Epoch: 73 | Iteration number: [4240/4518] 93% | Training loss: 0.6869389018922482
Epoch: 73 | Iteration number: [4250/4518] 94% | Training loss: 0.6869420480167164
Epoch: 73 | Iteration number: [4260/4518] 94% | Training loss: 0.6869422478295268
Epoch: 73 | Iteration number: [4270/4518] 94% | Training loss: 0.6869411599859421
Epoch: 73 | Iteration number: [4280/4518] 94% | Training loss: 0.6869419679463467
Epoch: 73 | Iteration number: [4290/4518] 94% | Training loss: 0.6869410385618676
Epoch: 73 | Iteration number: [4300/4518] 95% | Training loss: 0.686942405991776
Epoch: 73 | Iteration number: [4310/4518] 95% | Training loss: 0.6869432520977029
Epoch: 73 | Iteration number: [4320/4518] 95% | Training loss: 0.6869432689966979
Epoch: 73 | Iteration number: [4330/4518] 95% | Training loss: 0.6869417576536571
Epoch: 73 | Iteration number: [4340/4518] 96% | Training loss: 0.6869422287023562
Epoch: 73 | Iteration number: [4350/4518] 96% | Training loss: 0.686941605573413
Epoch: 73 | Iteration number: [4360/4518] 96% | Training loss: 0.6869415971664113
Epoch: 73 | Iteration number: [4370/4518] 96% | Training loss: 0.6869435244484952
Epoch: 73 | Iteration number: [4380/4518] 96% | Training loss: 0.6869434342945003
Epoch: 73 | Iteration number: [4390/4518] 97% | Training loss: 0.686943787390659
Epoch: 73 | Iteration number: [4400/4518] 97% | Training loss: 0.6869439738311551
Epoch: 73 | Iteration number: [4410/4518] 97% | Training loss: 0.6869427826128849
Epoch: 73 | Iteration number: [4420/4518] 97% | Training loss: 0.6869408929779519
Epoch: 73 | Iteration number: [4430/4518] 98% | Training loss: 0.686941233418596
Epoch: 73 | Iteration number: [4440/4518] 98% | Training loss: 0.6869396182330879
Epoch: 73 | Iteration number: [4450/4518] 98% | Training loss: 0.6869408326336507
Epoch: 73 | Iteration number: [4460/4518] 98% | Training loss: 0.6869383093754807
Epoch: 73 | Iteration number: [4470/4518] 98% | Training loss: 0.6869388145755068
Epoch: 73 | Iteration number: [4480/4518] 99% | Training loss: 0.6869404012869511
Epoch: 73 | Iteration number: [4490/4518] 99% | Training loss: 0.6869418187635248
Epoch: 73 | Iteration number: [4500/4518] 99% | Training loss: 0.6869365727769003
Epoch: 73 | Iteration number: [4510/4518] 99% | Training loss: 0.6869346481865631

 End of epoch: 73 | Train Loss: 0.6867812872328765 | Training Time: 642 

 End of epoch: 73 | Eval Loss: 0.6899946672575814 | Evaluating Time: 17 
Epoch: 74 | Iteration number: [10/4518] 0% | Training loss: 0.75489501953125
Epoch: 74 | Iteration number: [20/4518] 0% | Training loss: 0.7210670977830886
Epoch: 74 | Iteration number: [30/4518] 0% | Training loss: 0.7097825447718302
Epoch: 74 | Iteration number: [40/4518] 0% | Training loss: 0.7041379421949386
Epoch: 74 | Iteration number: [50/4518] 1% | Training loss: 0.7007494950294495
Epoch: 74 | Iteration number: [60/4518] 1% | Training loss: 0.6983516345421473
Epoch: 74 | Iteration number: [70/4518] 1% | Training loss: 0.6965392453329904
Epoch: 74 | Iteration number: [80/4518] 1% | Training loss: 0.6954092539846897
Epoch: 74 | Iteration number: [90/4518] 1% | Training loss: 0.69434491859542
Epoch: 74 | Iteration number: [100/4518] 2% | Training loss: 0.6935353147983551
Epoch: 74 | Iteration number: [110/4518] 2% | Training loss: 0.6928918394175443
Epoch: 74 | Iteration number: [120/4518] 2% | Training loss: 0.6924861028790474
Epoch: 74 | Iteration number: [130/4518] 2% | Training loss: 0.6919582380698277
Epoch: 74 | Iteration number: [140/4518] 3% | Training loss: 0.6915339972291674
Epoch: 74 | Iteration number: [150/4518] 3% | Training loss: 0.6911755029360453
Epoch: 74 | Iteration number: [160/4518] 3% | Training loss: 0.690819488838315
Epoch: 74 | Iteration number: [170/4518] 3% | Training loss: 0.690588144344442
Epoch: 74 | Iteration number: [180/4518] 3% | Training loss: 0.6903696454233593
Epoch: 74 | Iteration number: [190/4518] 4% | Training loss: 0.6901850584306215
Epoch: 74 | Iteration number: [200/4518] 4% | Training loss: 0.6900180554389954
Epoch: 74 | Iteration number: [210/4518] 4% | Training loss: 0.6898201854456039
Epoch: 74 | Iteration number: [220/4518] 4% | Training loss: 0.6896406227892096
Epoch: 74 | Iteration number: [230/4518] 5% | Training loss: 0.6894799315411112
Epoch: 74 | Iteration number: [240/4518] 5% | Training loss: 0.6894213693837324
Epoch: 74 | Iteration number: [250/4518] 5% | Training loss: 0.68931170129776
Epoch: 74 | Iteration number: [260/4518] 5% | Training loss: 0.6892105503724172
Epoch: 74 | Iteration number: [270/4518] 5% | Training loss: 0.6891002067813167
Epoch: 74 | Iteration number: [280/4518] 6% | Training loss: 0.6890192930187498
Epoch: 74 | Iteration number: [290/4518] 6% | Training loss: 0.6889588621155969
Epoch: 74 | Iteration number: [300/4518] 6% | Training loss: 0.6888632615407307
Epoch: 74 | Iteration number: [310/4518] 6% | Training loss: 0.6887947292097153
Epoch: 74 | Iteration number: [320/4518] 7% | Training loss: 0.6887307530269027
Epoch: 74 | Iteration number: [330/4518] 7% | Training loss: 0.6886845778335224
Epoch: 74 | Iteration number: [340/4518] 7% | Training loss: 0.6886599027058657
Epoch: 74 | Iteration number: [350/4518] 7% | Training loss: 0.6886103073188237
Epoch: 74 | Iteration number: [360/4518] 7% | Training loss: 0.688576830095715
Epoch: 74 | Iteration number: [370/4518] 8% | Training loss: 0.6884864913450705
Epoch: 74 | Iteration number: [380/4518] 8% | Training loss: 0.6884460391182649
Epoch: 74 | Iteration number: [390/4518] 8% | Training loss: 0.6883967093932323
Epoch: 74 | Iteration number: [400/4518] 8% | Training loss: 0.6883673147857189
Epoch: 74 | Iteration number: [410/4518] 9% | Training loss: 0.6883037379602107
Epoch: 74 | Iteration number: [420/4518] 9% | Training loss: 0.6882534414529801
Epoch: 74 | Iteration number: [430/4518] 9% | Training loss: 0.6882520621599153
Epoch: 74 | Iteration number: [440/4518] 9% | Training loss: 0.6882501407103105
Epoch: 74 | Iteration number: [450/4518] 9% | Training loss: 0.688198324309455
Epoch: 74 | Iteration number: [460/4518] 10% | Training loss: 0.688152723727019
Epoch: 74 | Iteration number: [470/4518] 10% | Training loss: 0.6881647525949681
Epoch: 74 | Iteration number: [480/4518] 10% | Training loss: 0.6881129963944356
Epoch: 74 | Iteration number: [490/4518] 10% | Training loss: 0.688130007349715
Epoch: 74 | Iteration number: [500/4518] 11% | Training loss: 0.6880686939954758
Epoch: 74 | Iteration number: [510/4518] 11% | Training loss: 0.6880139291286469
Epoch: 74 | Iteration number: [520/4518] 11% | Training loss: 0.6880077715103443
Epoch: 74 | Iteration number: [530/4518] 11% | Training loss: 0.6879859937811797
Epoch: 74 | Iteration number: [540/4518] 11% | Training loss: 0.6879778940368582
Epoch: 74 | Iteration number: [550/4518] 12% | Training loss: 0.6879394798929042
Epoch: 74 | Iteration number: [560/4518] 12% | Training loss: 0.687921891361475
Epoch: 74 | Iteration number: [570/4518] 12% | Training loss: 0.6879032525054195
Epoch: 74 | Iteration number: [580/4518] 12% | Training loss: 0.6878731525149838
Epoch: 74 | Iteration number: [590/4518] 13% | Training loss: 0.6878817907834457
Epoch: 74 | Iteration number: [600/4518] 13% | Training loss: 0.6878531784812609
Epoch: 74 | Iteration number: [610/4518] 13% | Training loss: 0.687834786000799
Epoch: 74 | Iteration number: [620/4518] 13% | Training loss: 0.6878194697441593
Epoch: 74 | Iteration number: [630/4518] 13% | Training loss: 0.6878027353967939
Epoch: 74 | Iteration number: [640/4518] 14% | Training loss: 0.6877945956774056
Epoch: 74 | Iteration number: [650/4518] 14% | Training loss: 0.687780316059406
Epoch: 74 | Iteration number: [660/4518] 14% | Training loss: 0.6877765346657146
Epoch: 74 | Iteration number: [670/4518] 14% | Training loss: 0.6877556373823934
Epoch: 74 | Iteration number: [680/4518] 15% | Training loss: 0.6877200576312402
Epoch: 74 | Iteration number: [690/4518] 15% | Training loss: 0.6877077088839766
Epoch: 74 | Iteration number: [700/4518] 15% | Training loss: 0.6876991787978581
Epoch: 74 | Iteration number: [710/4518] 15% | Training loss: 0.68767538188209
Epoch: 74 | Iteration number: [720/4518] 15% | Training loss: 0.6876545089814398
Epoch: 74 | Iteration number: [730/4518] 16% | Training loss: 0.6876493622178901
Epoch: 74 | Iteration number: [740/4518] 16% | Training loss: 0.6876238533773937
Epoch: 74 | Iteration number: [750/4518] 16% | Training loss: 0.6876143759886424
Epoch: 74 | Iteration number: [760/4518] 16% | Training loss: 0.6876239421336274
Epoch: 74 | Iteration number: [770/4518] 17% | Training loss: 0.6876090988710329
Epoch: 74 | Iteration number: [780/4518] 17% | Training loss: 0.6876037298104702
Epoch: 74 | Iteration number: [790/4518] 17% | Training loss: 0.6875894993920869
Epoch: 74 | Iteration number: [800/4518] 17% | Training loss: 0.6875747641921044
Epoch: 74 | Iteration number: [810/4518] 17% | Training loss: 0.6875766241991962
Epoch: 74 | Iteration number: [820/4518] 18% | Training loss: 0.687560784816742
Epoch: 74 | Iteration number: [830/4518] 18% | Training loss: 0.6875526711165186
Epoch: 74 | Iteration number: [840/4518] 18% | Training loss: 0.687536793024767
Epoch: 74 | Iteration number: [850/4518] 18% | Training loss: 0.6875287785950829
Epoch: 74 | Iteration number: [860/4518] 19% | Training loss: 0.687520943824635
Epoch: 74 | Iteration number: [870/4518] 19% | Training loss: 0.6875120950841356
Epoch: 74 | Iteration number: [880/4518] 19% | Training loss: 0.6875077628276565
Epoch: 74 | Iteration number: [890/4518] 19% | Training loss: 0.6874880518806115
Epoch: 74 | Iteration number: [900/4518] 19% | Training loss: 0.6874840962224537
Epoch: 74 | Iteration number: [910/4518] 20% | Training loss: 0.6874878390804752
Epoch: 74 | Iteration number: [920/4518] 20% | Training loss: 0.6874701326308044
Epoch: 74 | Iteration number: [930/4518] 20% | Training loss: 0.687466360035763
Epoch: 74 | Iteration number: [940/4518] 20% | Training loss: 0.6874544851957484
Epoch: 74 | Iteration number: [950/4518] 21% | Training loss: 0.6874454106782613
Epoch: 74 | Iteration number: [960/4518] 21% | Training loss: 0.6874262612313032
Epoch: 74 | Iteration number: [970/4518] 21% | Training loss: 0.6874201426800993
Epoch: 74 | Iteration number: [980/4518] 21% | Training loss: 0.6874075035051423
Epoch: 74 | Iteration number: [990/4518] 21% | Training loss: 0.6873960753883979
Epoch: 74 | Iteration number: [1000/4518] 22% | Training loss: 0.6873896582126617
Epoch: 74 | Iteration number: [1010/4518] 22% | Training loss: 0.6873906461909266
Epoch: 74 | Iteration number: [1020/4518] 22% | Training loss: 0.6873805228985992
Epoch: 74 | Iteration number: [1030/4518] 22% | Training loss: 0.6873825623572452
Epoch: 74 | Iteration number: [1040/4518] 23% | Training loss: 0.6873697964044717
Epoch: 74 | Iteration number: [1050/4518] 23% | Training loss: 0.6873630237011682
Epoch: 74 | Iteration number: [1060/4518] 23% | Training loss: 0.6873539270657414
Epoch: 74 | Iteration number: [1070/4518] 23% | Training loss: 0.6873507188859387
Epoch: 74 | Iteration number: [1080/4518] 23% | Training loss: 0.6873468214163074
Epoch: 74 | Iteration number: [1090/4518] 24% | Training loss: 0.6873226085387238
Epoch: 74 | Iteration number: [1100/4518] 24% | Training loss: 0.687304260188883
Epoch: 74 | Iteration number: [1110/4518] 24% | Training loss: 0.6872945414470123
Epoch: 74 | Iteration number: [1120/4518] 24% | Training loss: 0.6872888485768012
Epoch: 74 | Iteration number: [1130/4518] 25% | Training loss: 0.6872795357640865
Epoch: 74 | Iteration number: [1140/4518] 25% | Training loss: 0.687277229051841
Epoch: 74 | Iteration number: [1150/4518] 25% | Training loss: 0.6872692250168841
Epoch: 74 | Iteration number: [1160/4518] 25% | Training loss: 0.6872676166480985
Epoch: 74 | Iteration number: [1170/4518] 25% | Training loss: 0.6872705886506627
Epoch: 74 | Iteration number: [1180/4518] 26% | Training loss: 0.6872562595343186
Epoch: 74 | Iteration number: [1190/4518] 26% | Training loss: 0.6872454356746514
Epoch: 74 | Iteration number: [1200/4518] 26% | Training loss: 0.6872444506486257
Epoch: 74 | Iteration number: [1210/4518] 26% | Training loss: 0.6872380766494215
Epoch: 74 | Iteration number: [1220/4518] 27% | Training loss: 0.6872382458116187
Epoch: 74 | Iteration number: [1230/4518] 27% | Training loss: 0.6872301856192147
Epoch: 74 | Iteration number: [1240/4518] 27% | Training loss: 0.6872165440551696
Epoch: 74 | Iteration number: [1250/4518] 27% | Training loss: 0.6872173893451691
Epoch: 74 | Iteration number: [1260/4518] 27% | Training loss: 0.6872079083370783
Epoch: 74 | Iteration number: [1270/4518] 28% | Training loss: 0.6872103995225561
Epoch: 74 | Iteration number: [1280/4518] 28% | Training loss: 0.6872127206064761
Epoch: 74 | Iteration number: [1290/4518] 28% | Training loss: 0.687215113778447
Epoch: 74 | Iteration number: [1300/4518] 28% | Training loss: 0.687217362844027
Epoch: 74 | Iteration number: [1310/4518] 28% | Training loss: 0.6872167085418265
Epoch: 74 | Iteration number: [1320/4518] 29% | Training loss: 0.6872183555906469
Epoch: 74 | Iteration number: [1330/4518] 29% | Training loss: 0.6872092644074805
Epoch: 74 | Iteration number: [1340/4518] 29% | Training loss: 0.6872061384702797
Epoch: 74 | Iteration number: [1350/4518] 29% | Training loss: 0.6871976944693813
Epoch: 74 | Iteration number: [1360/4518] 30% | Training loss: 0.6871938076965949
Epoch: 74 | Iteration number: [1370/4518] 30% | Training loss: 0.6871959275137769
Epoch: 74 | Iteration number: [1380/4518] 30% | Training loss: 0.6871903254070144
Epoch: 74 | Iteration number: [1390/4518] 30% | Training loss: 0.6871929517324022
Epoch: 74 | Iteration number: [1400/4518] 30% | Training loss: 0.6871911905493056
Epoch: 74 | Iteration number: [1410/4518] 31% | Training loss: 0.6871938731230742
Epoch: 74 | Iteration number: [1420/4518] 31% | Training loss: 0.6871843835837405
Epoch: 74 | Iteration number: [1430/4518] 31% | Training loss: 0.6871749594911829
Epoch: 74 | Iteration number: [1440/4518] 31% | Training loss: 0.6871699540565411
Epoch: 74 | Iteration number: [1450/4518] 32% | Training loss: 0.687160149853805
Epoch: 74 | Iteration number: [1460/4518] 32% | Training loss: 0.6871580656260661
Epoch: 74 | Iteration number: [1470/4518] 32% | Training loss: 0.6871507409478531
Epoch: 74 | Iteration number: [1480/4518] 32% | Training loss: 0.6871512860059739
Epoch: 74 | Iteration number: [1490/4518] 32% | Training loss: 0.6871529467553901
Epoch: 74 | Iteration number: [1500/4518] 33% | Training loss: 0.6871537939310074
Epoch: 74 | Iteration number: [1510/4518] 33% | Training loss: 0.6871471195426209
Epoch: 74 | Iteration number: [1520/4518] 33% | Training loss: 0.6871398899116015
Epoch: 74 | Iteration number: [1530/4518] 33% | Training loss: 0.6871344862810147
Epoch: 74 | Iteration number: [1540/4518] 34% | Training loss: 0.6871295634415242
Epoch: 74 | Iteration number: [1550/4518] 34% | Training loss: 0.6871316262214414
Epoch: 74 | Iteration number: [1560/4518] 34% | Training loss: 0.6871331498026848
Epoch: 74 | Iteration number: [1570/4518] 34% | Training loss: 0.6871306479736499
Epoch: 74 | Iteration number: [1580/4518] 34% | Training loss: 0.6871222438314293
Epoch: 74 | Iteration number: [1590/4518] 35% | Training loss: 0.6871192755939076
Epoch: 74 | Iteration number: [1600/4518] 35% | Training loss: 0.6871191394329071
Epoch: 74 | Iteration number: [1610/4518] 35% | Training loss: 0.6871190220302676
Epoch: 74 | Iteration number: [1620/4518] 35% | Training loss: 0.6871156499341682
Epoch: 74 | Iteration number: [1630/4518] 36% | Training loss: 0.6871160864464344
Epoch: 74 | Iteration number: [1640/4518] 36% | Training loss: 0.6871164314993998
Epoch: 74 | Iteration number: [1650/4518] 36% | Training loss: 0.6871184638774757
Epoch: 74 | Iteration number: [1660/4518] 36% | Training loss: 0.6871162816343537
Epoch: 74 | Iteration number: [1670/4518] 36% | Training loss: 0.6871056294726754
Epoch: 74 | Iteration number: [1680/4518] 37% | Training loss: 0.6870960124191784
Epoch: 74 | Iteration number: [1690/4518] 37% | Training loss: 0.6870942513265553
Epoch: 74 | Iteration number: [1700/4518] 37% | Training loss: 0.687091231065638
Epoch: 74 | Iteration number: [1710/4518] 37% | Training loss: 0.6870947239691751
Epoch: 74 | Iteration number: [1720/4518] 38% | Training loss: 0.6870931567147721
Epoch: 74 | Iteration number: [1730/4518] 38% | Training loss: 0.6870871000551764
Epoch: 74 | Iteration number: [1740/4518] 38% | Training loss: 0.6870875637079107
Epoch: 74 | Iteration number: [1750/4518] 38% | Training loss: 0.687087901864733
Epoch: 74 | Iteration number: [1760/4518] 38% | Training loss: 0.6870796957476573
Epoch: 74 | Iteration number: [1770/4518] 39% | Training loss: 0.6870789704013005
Epoch: 74 | Iteration number: [1780/4518] 39% | Training loss: 0.6870796620510937
Epoch: 74 | Iteration number: [1790/4518] 39% | Training loss: 0.6870785633611945
Epoch: 74 | Iteration number: [1800/4518] 39% | Training loss: 0.6870739365617434
Epoch: 74 | Iteration number: [1810/4518] 40% | Training loss: 0.6870715753478899
Epoch: 74 | Iteration number: [1820/4518] 40% | Training loss: 0.6870717278221151
Epoch: 74 | Iteration number: [1830/4518] 40% | Training loss: 0.6870726598090813
Epoch: 74 | Iteration number: [1840/4518] 40% | Training loss: 0.6870741289270961
Epoch: 74 | Iteration number: [1850/4518] 40% | Training loss: 0.6870695442766757
Epoch: 74 | Iteration number: [1860/4518] 41% | Training loss: 0.6870690133943352
Epoch: 74 | Iteration number: [1870/4518] 41% | Training loss: 0.6870652254889993
Epoch: 74 | Iteration number: [1880/4518] 41% | Training loss: 0.6870649918913841
Epoch: 74 | Iteration number: [1890/4518] 41% | Training loss: 0.6870640925629429
Epoch: 74 | Iteration number: [1900/4518] 42% | Training loss: 0.6870711989465512
Epoch: 74 | Iteration number: [1910/4518] 42% | Training loss: 0.6870655159987704
Epoch: 74 | Iteration number: [1920/4518] 42% | Training loss: 0.6870612131121258
Epoch: 74 | Iteration number: [1930/4518] 42% | Training loss: 0.6870582381060704
Epoch: 74 | Iteration number: [1940/4518] 42% | Training loss: 0.6870510063835026
Epoch: 74 | Iteration number: [1950/4518] 43% | Training loss: 0.6870496093921172
Epoch: 74 | Iteration number: [1960/4518] 43% | Training loss: 0.6870414386598431
Epoch: 74 | Iteration number: [1970/4518] 43% | Training loss: 0.6870431207158239
Epoch: 74 | Iteration number: [1980/4518] 43% | Training loss: 0.687045725367286
Epoch: 74 | Iteration number: [1990/4518] 44% | Training loss: 0.687038115850046
Epoch: 74 | Iteration number: [2000/4518] 44% | Training loss: 0.6870408334434033
Epoch: 74 | Iteration number: [2010/4518] 44% | Training loss: 0.6870392686692043
Epoch: 74 | Iteration number: [2020/4518] 44% | Training loss: 0.6870407820633142
Epoch: 74 | Iteration number: [2030/4518] 44% | Training loss: 0.6870413450771952
Epoch: 74 | Iteration number: [2040/4518] 45% | Training loss: 0.6870389690293985
Epoch: 74 | Iteration number: [2050/4518] 45% | Training loss: 0.6870415933829982
Epoch: 74 | Iteration number: [2060/4518] 45% | Training loss: 0.6870368431783417
Epoch: 74 | Iteration number: [2070/4518] 45% | Training loss: 0.6870395843533502
Epoch: 74 | Iteration number: [2080/4518] 46% | Training loss: 0.6870411946223333
Epoch: 74 | Iteration number: [2090/4518] 46% | Training loss: 0.6870456922282443
Epoch: 74 | Iteration number: [2100/4518] 46% | Training loss: 0.6870436098178228
Epoch: 74 | Iteration number: [2110/4518] 46% | Training loss: 0.6870466670436317
Epoch: 74 | Iteration number: [2120/4518] 46% | Training loss: 0.6870464581082452
Epoch: 74 | Iteration number: [2130/4518] 47% | Training loss: 0.6870447715962996
Epoch: 74 | Iteration number: [2140/4518] 47% | Training loss: 0.6870442698770595
Epoch: 74 | Iteration number: [2150/4518] 47% | Training loss: 0.6870375788766284
Epoch: 74 | Iteration number: [2160/4518] 47% | Training loss: 0.6870375637930852
Epoch: 74 | Iteration number: [2170/4518] 48% | Training loss: 0.687040965787826
Epoch: 74 | Iteration number: [2180/4518] 48% | Training loss: 0.6870384154243206
Epoch: 74 | Iteration number: [2190/4518] 48% | Training loss: 0.687033995400825
Epoch: 74 | Iteration number: [2200/4518] 48% | Training loss: 0.6870313886349851
Epoch: 74 | Iteration number: [2210/4518] 48% | Training loss: 0.6870273685563204
Epoch: 74 | Iteration number: [2220/4518] 49% | Training loss: 0.6870244861454577
Epoch: 74 | Iteration number: [2230/4518] 49% | Training loss: 0.6870259914964838
Epoch: 74 | Iteration number: [2240/4518] 49% | Training loss: 0.6870276380330325
Epoch: 74 | Iteration number: [2250/4518] 49% | Training loss: 0.6870299413734012
Epoch: 74 | Iteration number: [2260/4518] 50% | Training loss: 0.6870317631590683
Epoch: 74 | Iteration number: [2270/4518] 50% | Training loss: 0.6870356504087406
Epoch: 74 | Iteration number: [2280/4518] 50% | Training loss: 0.6870369956158755
Epoch: 74 | Iteration number: [2290/4518] 50% | Training loss: 0.6870360999128183
Epoch: 74 | Iteration number: [2300/4518] 50% | Training loss: 0.687030105072519
Epoch: 74 | Iteration number: [2310/4518] 51% | Training loss: 0.6870332795562166
Epoch: 74 | Iteration number: [2320/4518] 51% | Training loss: 0.6870315409169114
Epoch: 74 | Iteration number: [2330/4518] 51% | Training loss: 0.6870363102706205
Epoch: 74 | Iteration number: [2340/4518] 51% | Training loss: 0.6870414051999394
Epoch: 74 | Iteration number: [2350/4518] 52% | Training loss: 0.6870414334916054
Epoch: 74 | Iteration number: [2360/4518] 52% | Training loss: 0.6870416460906045
Epoch: 74 | Iteration number: [2370/4518] 52% | Training loss: 0.6870382571522193
Epoch: 74 | Iteration number: [2380/4518] 52% | Training loss: 0.6870385910783495
Epoch: 74 | Iteration number: [2390/4518] 52% | Training loss: 0.6870396581154987
Epoch: 74 | Iteration number: [2400/4518] 53% | Training loss: 0.6870353059719007
Epoch: 74 | Iteration number: [2410/4518] 53% | Training loss: 0.6870410862799997
Epoch: 74 | Iteration number: [2420/4518] 53% | Training loss: 0.6870362891638575
Epoch: 74 | Iteration number: [2430/4518] 53% | Training loss: 0.6870376829747801
Epoch: 74 | Iteration number: [2440/4518] 54% | Training loss: 0.6870346406932737
Epoch: 74 | Iteration number: [2450/4518] 54% | Training loss: 0.6870327850507231
Epoch: 74 | Iteration number: [2460/4518] 54% | Training loss: 0.6870310957111964
Epoch: 74 | Iteration number: [2470/4518] 54% | Training loss: 0.6870352424832008
Epoch: 74 | Iteration number: [2480/4518] 54% | Training loss: 0.6870312371561604
Epoch: 74 | Iteration number: [2490/4518] 55% | Training loss: 0.687038384551504
Epoch: 74 | Iteration number: [2500/4518] 55% | Training loss: 0.6870427226781846
Epoch: 74 | Iteration number: [2510/4518] 55% | Training loss: 0.6870396753943774
Epoch: 74 | Iteration number: [2520/4518] 55% | Training loss: 0.687035544926212
Epoch: 74 | Iteration number: [2530/4518] 55% | Training loss: 0.6870361560418201
Epoch: 74 | Iteration number: [2540/4518] 56% | Training loss: 0.6870371240799821
Epoch: 74 | Iteration number: [2550/4518] 56% | Training loss: 0.6870360596974691
Epoch: 74 | Iteration number: [2560/4518] 56% | Training loss: 0.6870378267951309
Epoch: 74 | Iteration number: [2570/4518] 56% | Training loss: 0.6870375298572422
Epoch: 74 | Iteration number: [2580/4518] 57% | Training loss: 0.6870394185762997
Epoch: 74 | Iteration number: [2590/4518] 57% | Training loss: 0.6870414168678195
Epoch: 74 | Iteration number: [2600/4518] 57% | Training loss: 0.6870408257383567
Epoch: 74 | Iteration number: [2610/4518] 57% | Training loss: 0.6870385892546497
Epoch: 74 | Iteration number: [2620/4518] 57% | Training loss: 0.6870396139740034
Epoch: 74 | Iteration number: [2630/4518] 58% | Training loss: 0.687039819303121
Epoch: 74 | Iteration number: [2640/4518] 58% | Training loss: 0.6870400661546172
Epoch: 74 | Iteration number: [2650/4518] 58% | Training loss: 0.687038115240493
Epoch: 74 | Iteration number: [2660/4518] 58% | Training loss: 0.6870378994179848
Epoch: 74 | Iteration number: [2670/4518] 59% | Training loss: 0.6870391774266846
Epoch: 74 | Iteration number: [2680/4518] 59% | Training loss: 0.6870343672250634
Epoch: 74 | Iteration number: [2690/4518] 59% | Training loss: 0.6870317946800956
Epoch: 74 | Iteration number: [2700/4518] 59% | Training loss: 0.6870296891530355
Epoch: 74 | Iteration number: [2710/4518] 59% | Training loss: 0.687029923570112
Epoch: 74 | Iteration number: [2720/4518] 60% | Training loss: 0.6870311915874481
Epoch: 74 | Iteration number: [2730/4518] 60% | Training loss: 0.6870309708100972
Epoch: 74 | Iteration number: [2740/4518] 60% | Training loss: 0.6870289711186486
Epoch: 74 | Iteration number: [2750/4518] 60% | Training loss: 0.687028197331862
Epoch: 74 | Iteration number: [2760/4518] 61% | Training loss: 0.6870294319330782
Epoch: 74 | Iteration number: [2770/4518] 61% | Training loss: 0.6870255777551809
Epoch: 74 | Iteration number: [2780/4518] 61% | Training loss: 0.6870243919195889
Epoch: 74 | Iteration number: [2790/4518] 61% | Training loss: 0.6870253865436841
Epoch: 74 | Iteration number: [2800/4518] 61% | Training loss: 0.6870304823986122
Epoch: 74 | Iteration number: [2810/4518] 62% | Training loss: 0.6870299391475012
Epoch: 74 | Iteration number: [2820/4518] 62% | Training loss: 0.6870283037424088
Epoch: 74 | Iteration number: [2830/4518] 62% | Training loss: 0.6870250692426526
Epoch: 74 | Iteration number: [2840/4518] 62% | Training loss: 0.6870239406614237
Epoch: 74 | Iteration number: [2850/4518] 63% | Training loss: 0.6870184485745011
Epoch: 74 | Iteration number: [2860/4518] 63% | Training loss: 0.6870211794659808
Epoch: 74 | Iteration number: [2870/4518] 63% | Training loss: 0.6870190468607048
Epoch: 74 | Iteration number: [2880/4518] 63% | Training loss: 0.6870213398916853
Epoch: 74 | Iteration number: [2890/4518] 63% | Training loss: 0.687019689169722
Epoch: 74 | Iteration number: [2900/4518] 64% | Training loss: 0.687016935677364
Epoch: 74 | Iteration number: [2910/4518] 64% | Training loss: 0.687014733311237
Epoch: 74 | Iteration number: [2920/4518] 64% | Training loss: 0.6870212116470076
Epoch: 74 | Iteration number: [2930/4518] 64% | Training loss: 0.6870167391292065
Epoch: 74 | Iteration number: [2940/4518] 65% | Training loss: 0.6870123997837507
Epoch: 74 | Iteration number: [2950/4518] 65% | Training loss: 0.6870146649772838
Epoch: 74 | Iteration number: [2960/4518] 65% | Training loss: 0.6870095744326308
Epoch: 74 | Iteration number: [2970/4518] 65% | Training loss: 0.6870045307308736
Epoch: 74 | Iteration number: [2980/4518] 65% | Training loss: 0.6870070526263858
Epoch: 74 | Iteration number: [2990/4518] 66% | Training loss: 0.6870048170305016
Epoch: 74 | Iteration number: [3000/4518] 66% | Training loss: 0.6870046853025754
Epoch: 74 | Iteration number: [3010/4518] 66% | Training loss: 0.6870016529116519
Epoch: 74 | Iteration number: [3020/4518] 66% | Training loss: 0.687001065584208
Epoch: 74 | Iteration number: [3030/4518] 67% | Training loss: 0.6870026136979018
Epoch: 74 | Iteration number: [3040/4518] 67% | Training loss: 0.6870030783508954
Epoch: 74 | Iteration number: [3050/4518] 67% | Training loss: 0.687003745036047
Epoch: 74 | Iteration number: [3060/4518] 67% | Training loss: 0.6870043916055579
Epoch: 74 | Iteration number: [3070/4518] 67% | Training loss: 0.6870072601478341
Epoch: 74 | Iteration number: [3080/4518] 68% | Training loss: 0.6870069872442778
Epoch: 74 | Iteration number: [3090/4518] 68% | Training loss: 0.687007165495246
Epoch: 74 | Iteration number: [3100/4518] 68% | Training loss: 0.68700931772109
Epoch: 74 | Iteration number: [3110/4518] 68% | Training loss: 0.6870071892186377
Epoch: 74 | Iteration number: [3120/4518] 69% | Training loss: 0.6870069415141374
Epoch: 74 | Iteration number: [3130/4518] 69% | Training loss: 0.6870072896488177
Epoch: 74 | Iteration number: [3140/4518] 69% | Training loss: 0.687009481127095
Epoch: 74 | Iteration number: [3150/4518] 69% | Training loss: 0.6870064707407876
Epoch: 74 | Iteration number: [3160/4518] 69% | Training loss: 0.6870069654682015
Epoch: 74 | Iteration number: [3170/4518] 70% | Training loss: 0.6870069125097257
Epoch: 74 | Iteration number: [3180/4518] 70% | Training loss: 0.6870074939990194
Epoch: 74 | Iteration number: [3190/4518] 70% | Training loss: 0.6870055967363818
Epoch: 74 | Iteration number: [3200/4518] 70% | Training loss: 0.6870042212307453
Epoch: 74 | Iteration number: [3210/4518] 71% | Training loss: 0.6870006117308252
Epoch: 74 | Iteration number: [3220/4518] 71% | Training loss: 0.6870006504266158
Epoch: 74 | Iteration number: [3230/4518] 71% | Training loss: 0.6870030939948079
Epoch: 74 | Iteration number: [3240/4518] 71% | Training loss: 0.6870064813965633
Epoch: 74 | Iteration number: [3250/4518] 71% | Training loss: 0.6870036932321695
Epoch: 74 | Iteration number: [3260/4518] 72% | Training loss: 0.6870075949496287
Epoch: 74 | Iteration number: [3270/4518] 72% | Training loss: 0.6870064976929889
Epoch: 74 | Iteration number: [3280/4518] 72% | Training loss: 0.6870054122696563
Epoch: 74 | Iteration number: [3290/4518] 72% | Training loss: 0.6870071128508964
Epoch: 74 | Iteration number: [3300/4518] 73% | Training loss: 0.687005175821709
Epoch: 74 | Iteration number: [3310/4518] 73% | Training loss: 0.6870065408350838
Epoch: 74 | Iteration number: [3320/4518] 73% | Training loss: 0.6870063893048161
Epoch: 74 | Iteration number: [3330/4518] 73% | Training loss: 0.6870036869077711
Epoch: 74 | Iteration number: [3340/4518] 73% | Training loss: 0.687003939969097
Epoch: 74 | Iteration number: [3350/4518] 74% | Training loss: 0.6870040978602509
Epoch: 74 | Iteration number: [3360/4518] 74% | Training loss: 0.6870011218424354
Epoch: 74 | Iteration number: [3370/4518] 74% | Training loss: 0.6870024712573881
Epoch: 74 | Iteration number: [3380/4518] 74% | Training loss: 0.6869991504934413
Epoch: 74 | Iteration number: [3390/4518] 75% | Training loss: 0.6869989041030231
Epoch: 74 | Iteration number: [3400/4518] 75% | Training loss: 0.6869991625757779
Epoch: 74 | Iteration number: [3410/4518] 75% | Training loss: 0.6869958839458454
Epoch: 74 | Iteration number: [3420/4518] 75% | Training loss: 0.6869957475111499
Epoch: 74 | Iteration number: [3430/4518] 75% | Training loss: 0.6869951837959511
Epoch: 74 | Iteration number: [3440/4518] 76% | Training loss: 0.6869875192295674
Epoch: 74 | Iteration number: [3450/4518] 76% | Training loss: 0.686987574480582
Epoch: 74 | Iteration number: [3460/4518] 76% | Training loss: 0.6869873733017486
Epoch: 74 | Iteration number: [3470/4518] 76% | Training loss: 0.6869891814093081
Epoch: 74 | Iteration number: [3480/4518] 77% | Training loss: 0.6869905818296576
Epoch: 74 | Iteration number: [3490/4518] 77% | Training loss: 0.6869930811973561
Epoch: 74 | Iteration number: [3500/4518] 77% | Training loss: 0.686996683222907
Epoch: 74 | Iteration number: [3510/4518] 77% | Training loss: 0.686995464529407
Epoch: 74 | Iteration number: [3520/4518] 77% | Training loss: 0.6869953432035717
Epoch: 74 | Iteration number: [3530/4518] 78% | Training loss: 0.6869922481920496
Epoch: 74 | Iteration number: [3540/4518] 78% | Training loss: 0.6869912394190912
Epoch: 74 | Iteration number: [3550/4518] 78% | Training loss: 0.6869885357332901
Epoch: 74 | Iteration number: [3560/4518] 78% | Training loss: 0.68699136091752
Epoch: 74 | Iteration number: [3570/4518] 79% | Training loss: 0.6869887803615976
Epoch: 74 | Iteration number: [3580/4518] 79% | Training loss: 0.6869894390166139
Epoch: 74 | Iteration number: [3590/4518] 79% | Training loss: 0.6869890885100723
Epoch: 74 | Iteration number: [3600/4518] 79% | Training loss: 0.6869902550843027
Epoch: 74 | Iteration number: [3610/4518] 79% | Training loss: 0.6869883970045317
Epoch: 74 | Iteration number: [3620/4518] 80% | Training loss: 0.686989603813182
Epoch: 74 | Iteration number: [3630/4518] 80% | Training loss: 0.686991662952854
Epoch: 74 | Iteration number: [3640/4518] 80% | Training loss: 0.6869920944447045
Epoch: 74 | Iteration number: [3650/4518] 80% | Training loss: 0.6869916381574657
Epoch: 74 | Iteration number: [3660/4518] 81% | Training loss: 0.6869908572871828
Epoch: 74 | Iteration number: [3670/4518] 81% | Training loss: 0.6869916734643463
Epoch: 74 | Iteration number: [3680/4518] 81% | Training loss: 0.6869899058471556
Epoch: 74 | Iteration number: [3690/4518] 81% | Training loss: 0.6869924680165805
Epoch: 74 | Iteration number: [3700/4518] 81% | Training loss: 0.6869907028932829
Epoch: 74 | Iteration number: [3710/4518] 82% | Training loss: 0.6869885992329076
Epoch: 74 | Iteration number: [3720/4518] 82% | Training loss: 0.6869882467453198
Epoch: 74 | Iteration number: [3730/4518] 82% | Training loss: 0.6869895646143854
Epoch: 74 | Iteration number: [3740/4518] 82% | Training loss: 0.68698793657642
Epoch: 74 | Iteration number: [3750/4518] 83% | Training loss: 0.6869852212111155
Epoch: 74 | Iteration number: [3760/4518] 83% | Training loss: 0.6869885705887003
Epoch: 74 | Iteration number: [3770/4518] 83% | Training loss: 0.6869893251742861
Epoch: 74 | Iteration number: [3780/4518] 83% | Training loss: 0.6869878369191337
Epoch: 74 | Iteration number: [3790/4518] 83% | Training loss: 0.6869877769796074
Epoch: 74 | Iteration number: [3800/4518] 84% | Training loss: 0.6869853939037573
Epoch: 74 | Iteration number: [3810/4518] 84% | Training loss: 0.6869841495993256
Epoch: 74 | Iteration number: [3820/4518] 84% | Training loss: 0.6869832929984437
Epoch: 74 | Iteration number: [3830/4518] 84% | Training loss: 0.6869796083739159
Epoch: 74 | Iteration number: [3840/4518] 84% | Training loss: 0.686978547523419
Epoch: 74 | Iteration number: [3850/4518] 85% | Training loss: 0.6869799346428412
Epoch: 74 | Iteration number: [3860/4518] 85% | Training loss: 0.6869790618747009
Epoch: 74 | Iteration number: [3870/4518] 85% | Training loss: 0.6869808214733459
Epoch: 74 | Iteration number: [3880/4518] 85% | Training loss: 0.6869793644117326
Epoch: 74 | Iteration number: [3890/4518] 86% | Training loss: 0.6869771932574961
Epoch: 74 | Iteration number: [3900/4518] 86% | Training loss: 0.6869777809809415
Epoch: 74 | Iteration number: [3910/4518] 86% | Training loss: 0.6869768468010456
Epoch: 74 | Iteration number: [3920/4518] 86% | Training loss: 0.6869759103017193
Epoch: 74 | Iteration number: [3930/4518] 86% | Training loss: 0.6869761603327501
Epoch: 74 | Iteration number: [3940/4518] 87% | Training loss: 0.6869768387170008
Epoch: 74 | Iteration number: [3950/4518] 87% | Training loss: 0.6869777226297161
Epoch: 74 | Iteration number: [3960/4518] 87% | Training loss: 0.6869752146228395
Epoch: 74 | Iteration number: [3970/4518] 87% | Training loss: 0.686976004577704
Epoch: 74 | Iteration number: [3980/4518] 88% | Training loss: 0.6869782049901522
Epoch: 74 | Iteration number: [3990/4518] 88% | Training loss: 0.6869810845469473
Epoch: 74 | Iteration number: [4000/4518] 88% | Training loss: 0.6869827027916908
Epoch: 74 | Iteration number: [4010/4518] 88% | Training loss: 0.6869801912819061
Epoch: 74 | Iteration number: [4020/4518] 88% | Training loss: 0.6869791866238437
Epoch: 74 | Iteration number: [4030/4518] 89% | Training loss: 0.6869729833478667
Epoch: 74 | Iteration number: [4040/4518] 89% | Training loss: 0.6869710226312722
Epoch: 74 | Iteration number: [4050/4518] 89% | Training loss: 0.6869691394729379
Epoch: 74 | Iteration number: [4060/4518] 89% | Training loss: 0.6869717032157728
Epoch: 74 | Iteration number: [4070/4518] 90% | Training loss: 0.6869726257476525
Epoch: 74 | Iteration number: [4080/4518] 90% | Training loss: 0.6869745293522582
Epoch: 74 | Iteration number: [4090/4518] 90% | Training loss: 0.6869719309736873
Epoch: 74 | Iteration number: [4100/4518] 90% | Training loss: 0.6869706891368075
Epoch: 74 | Iteration number: [4110/4518] 90% | Training loss: 0.686966415130309
Epoch: 74 | Iteration number: [4120/4518] 91% | Training loss: 0.6869665181897219
Epoch: 74 | Iteration number: [4130/4518] 91% | Training loss: 0.686963085862684
Epoch: 74 | Iteration number: [4140/4518] 91% | Training loss: 0.6869605212683839
Epoch: 74 | Iteration number: [4150/4518] 91% | Training loss: 0.686959625784173
Epoch: 74 | Iteration number: [4160/4518] 92% | Training loss: 0.6869582114168085
Epoch: 74 | Iteration number: [4170/4518] 92% | Training loss: 0.6869590300879033
Epoch: 74 | Iteration number: [4180/4518] 92% | Training loss: 0.6869574753006109
Epoch: 74 | Iteration number: [4190/4518] 92% | Training loss: 0.686956817750999
Epoch: 74 | Iteration number: [4200/4518] 92% | Training loss: 0.6869530306543623
Epoch: 74 | Iteration number: [4210/4518] 93% | Training loss: 0.6869516296086572
Epoch: 74 | Iteration number: [4220/4518] 93% | Training loss: 0.6869526023830848
Epoch: 74 | Iteration number: [4230/4518] 93% | Training loss: 0.6869539395291755
Epoch: 74 | Iteration number: [4240/4518] 93% | Training loss: 0.686952224444106
Epoch: 74 | Iteration number: [4250/4518] 94% | Training loss: 0.6869501725084641
Epoch: 74 | Iteration number: [4260/4518] 94% | Training loss: 0.6869465302133784
Epoch: 74 | Iteration number: [4270/4518] 94% | Training loss: 0.6869473596925758
Epoch: 74 | Iteration number: [4280/4518] 94% | Training loss: 0.6869460328856362
Epoch: 74 | Iteration number: [4290/4518] 94% | Training loss: 0.6869408588587265
Epoch: 74 | Iteration number: [4300/4518] 95% | Training loss: 0.6869392939639646
Epoch: 74 | Iteration number: [4310/4518] 95% | Training loss: 0.6869401113478047
Epoch: 74 | Iteration number: [4320/4518] 95% | Training loss: 0.686940978674425
Epoch: 74 | Iteration number: [4330/4518] 95% | Training loss: 0.6869394733641494
Epoch: 74 | Iteration number: [4340/4518] 96% | Training loss: 0.6869369368674019
Epoch: 74 | Iteration number: [4350/4518] 96% | Training loss: 0.6869389110324027
Epoch: 74 | Iteration number: [4360/4518] 96% | Training loss: 0.6869364367302405
Epoch: 74 | Iteration number: [4370/4518] 96% | Training loss: 0.68693760484798
Epoch: 74 | Iteration number: [4380/4518] 96% | Training loss: 0.6869396530193825
Epoch: 74 | Iteration number: [4390/4518] 97% | Training loss: 0.6869395324743962
Epoch: 74 | Iteration number: [4400/4518] 97% | Training loss: 0.6869343755461953
Epoch: 74 | Iteration number: [4410/4518] 97% | Training loss: 0.6869354461596396
Epoch: 74 | Iteration number: [4420/4518] 97% | Training loss: 0.6869354876322984
Epoch: 74 | Iteration number: [4430/4518] 98% | Training loss: 0.6869330771486054
Epoch: 74 | Iteration number: [4440/4518] 98% | Training loss: 0.6869326016521669
Epoch: 74 | Iteration number: [4450/4518] 98% | Training loss: 0.6869311998399455
Epoch: 74 | Iteration number: [4460/4518] 98% | Training loss: 0.6869307901960852
Epoch: 74 | Iteration number: [4470/4518] 98% | Training loss: 0.6869285367212573
Epoch: 74 | Iteration number: [4480/4518] 99% | Training loss: 0.6869280801021627
Epoch: 74 | Iteration number: [4490/4518] 99% | Training loss: 0.6869316070541772
Epoch: 74 | Iteration number: [4500/4518] 99% | Training loss: 0.686930938217375
Epoch: 74 | Iteration number: [4510/4518] 99% | Training loss: 0.686932343416362

 End of epoch: 74 | Train Loss: 0.6867775101348224 | Training Time: 643 

 End of epoch: 74 | Eval Loss: 0.6900379572595868 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/4518] 0% | Training loss: 0.7544720053672791
Epoch: 75 | Iteration number: [20/4518] 0% | Training loss: 0.7208479106426239
Epoch: 75 | Iteration number: [30/4518] 0% | Training loss: 0.7092972616354625
Epoch: 75 | Iteration number: [40/4518] 0% | Training loss: 0.7037639528512954
Epoch: 75 | Iteration number: [50/4518] 1% | Training loss: 0.7004573047161102
Epoch: 75 | Iteration number: [60/4518] 1% | Training loss: 0.698180936773618
Epoch: 75 | Iteration number: [70/4518] 1% | Training loss: 0.6964207453387125
Epoch: 75 | Iteration number: [80/4518] 1% | Training loss: 0.6952435873448849
Epoch: 75 | Iteration number: [90/4518] 1% | Training loss: 0.6943033456802368
Epoch: 75 | Iteration number: [100/4518] 2% | Training loss: 0.6934617352485657
Epoch: 75 | Iteration number: [110/4518] 2% | Training loss: 0.6929204480214552
Epoch: 75 | Iteration number: [120/4518] 2% | Training loss: 0.692516082028548
Epoch: 75 | Iteration number: [130/4518] 2% | Training loss: 0.6921457217289851
Epoch: 75 | Iteration number: [140/4518] 3% | Training loss: 0.6918244383164814
Epoch: 75 | Iteration number: [150/4518] 3% | Training loss: 0.6915396718184154
Epoch: 75 | Iteration number: [160/4518] 3% | Training loss: 0.6912655647844076
Epoch: 75 | Iteration number: [170/4518] 3% | Training loss: 0.6910155674990486
Epoch: 75 | Iteration number: [180/4518] 3% | Training loss: 0.690820935368538
Epoch: 75 | Iteration number: [190/4518] 4% | Training loss: 0.6906539553090145
Epoch: 75 | Iteration number: [200/4518] 4% | Training loss: 0.6904300671815872
Epoch: 75 | Iteration number: [210/4518] 4% | Training loss: 0.6903167574178605
Epoch: 75 | Iteration number: [220/4518] 4% | Training loss: 0.6901126753200184
Epoch: 75 | Iteration number: [230/4518] 5% | Training loss: 0.6900208815284398
Epoch: 75 | Iteration number: [240/4518] 5% | Training loss: 0.6898802367349466
Epoch: 75 | Iteration number: [250/4518] 5% | Training loss: 0.6897640523910522
Epoch: 75 | Iteration number: [260/4518] 5% | Training loss: 0.689638312963339
Epoch: 75 | Iteration number: [270/4518] 5% | Training loss: 0.6895324801957166
Epoch: 75 | Iteration number: [280/4518] 6% | Training loss: 0.6893993852393968
Epoch: 75 | Iteration number: [290/4518] 6% | Training loss: 0.6892914328081855
Epoch: 75 | Iteration number: [300/4518] 6% | Training loss: 0.6892270970344544
Epoch: 75 | Iteration number: [310/4518] 6% | Training loss: 0.6891206149132021
Epoch: 75 | Iteration number: [320/4518] 7% | Training loss: 0.6890980180352926
Epoch: 75 | Iteration number: [330/4518] 7% | Training loss: 0.6889783964012608
Epoch: 75 | Iteration number: [340/4518] 7% | Training loss: 0.6889597824391197
Epoch: 75 | Iteration number: [350/4518] 7% | Training loss: 0.6888992861339024
Epoch: 75 | Iteration number: [360/4518] 7% | Training loss: 0.688851059642103
Epoch: 75 | Iteration number: [370/4518] 8% | Training loss: 0.6888235221037994
Epoch: 75 | Iteration number: [380/4518] 8% | Training loss: 0.6887501065668307
Epoch: 75 | Iteration number: [390/4518] 8% | Training loss: 0.6887080340813367
Epoch: 75 | Iteration number: [400/4518] 8% | Training loss: 0.6886451163887978
Epoch: 75 | Iteration number: [410/4518] 9% | Training loss: 0.6885613796187611
Epoch: 75 | Iteration number: [420/4518] 9% | Training loss: 0.688519727616083
Epoch: 75 | Iteration number: [430/4518] 9% | Training loss: 0.68847784316817
Epoch: 75 | Iteration number: [440/4518] 9% | Training loss: 0.6884597885337743
Epoch: 75 | Iteration number: [450/4518] 9% | Training loss: 0.688399330245124
Epoch: 75 | Iteration number: [460/4518] 10% | Training loss: 0.6883538388687631
Epoch: 75 | Iteration number: [470/4518] 10% | Training loss: 0.6883216386145734
Epoch: 75 | Iteration number: [480/4518] 10% | Training loss: 0.6882681347429752
Epoch: 75 | Iteration number: [490/4518] 10% | Training loss: 0.6882608384502177
Epoch: 75 | Iteration number: [500/4518] 11% | Training loss: 0.6882084984779357
Epoch: 75 | Iteration number: [510/4518] 11% | Training loss: 0.6881845374902089
Epoch: 75 | Iteration number: [520/4518] 11% | Training loss: 0.6881729339177792
Epoch: 75 | Iteration number: [530/4518] 11% | Training loss: 0.6881627904918959
Epoch: 75 | Iteration number: [540/4518] 11% | Training loss: 0.6881287122214282
Epoch: 75 | Iteration number: [550/4518] 12% | Training loss: 0.6880897393009879
Epoch: 75 | Iteration number: [560/4518] 12% | Training loss: 0.6880738506359714
Epoch: 75 | Iteration number: [570/4518] 12% | Training loss: 0.6880442764675408
Epoch: 75 | Iteration number: [580/4518] 12% | Training loss: 0.6880382862584344
Epoch: 75 | Iteration number: [590/4518] 13% | Training loss: 0.6879912410752248
Epoch: 75 | Iteration number: [600/4518] 13% | Training loss: 0.6879689196745554
Epoch: 75 | Iteration number: [610/4518] 13% | Training loss: 0.6879494223438325
Epoch: 75 | Iteration number: [620/4518] 13% | Training loss: 0.6879408820982902
Epoch: 75 | Iteration number: [630/4518] 13% | Training loss: 0.6879139606914823
Epoch: 75 | Iteration number: [640/4518] 14% | Training loss: 0.6878918216563761
Epoch: 75 | Iteration number: [650/4518] 14% | Training loss: 0.6878772024924938
Epoch: 75 | Iteration number: [660/4518] 14% | Training loss: 0.6878657846739797
Epoch: 75 | Iteration number: [670/4518] 14% | Training loss: 0.6878508856047445
Epoch: 75 | Iteration number: [680/4518] 15% | Training loss: 0.6878233281128546
Epoch: 75 | Iteration number: [690/4518] 15% | Training loss: 0.6877933840820755
Epoch: 75 | Iteration number: [700/4518] 15% | Training loss: 0.687776922413281
Epoch: 75 | Iteration number: [710/4518] 15% | Training loss: 0.6877659161325912
Epoch: 75 | Iteration number: [720/4518] 15% | Training loss: 0.687763625714514
Epoch: 75 | Iteration number: [730/4518] 16% | Training loss: 0.6877525086272253
Epoch: 75 | Iteration number: [740/4518] 16% | Training loss: 0.6877367426414748
Epoch: 75 | Iteration number: [750/4518] 16% | Training loss: 0.6877336383660634
Epoch: 75 | Iteration number: [760/4518] 16% | Training loss: 0.6877373768310798
Epoch: 75 | Iteration number: [770/4518] 17% | Training loss: 0.6877167391312586
Epoch: 75 | Iteration number: [780/4518] 17% | Training loss: 0.6877057577554996
Epoch: 75 | Iteration number: [790/4518] 17% | Training loss: 0.6877145830589004
Epoch: 75 | Iteration number: [800/4518] 17% | Training loss: 0.6877066692709923
Epoch: 75 | Iteration number: [810/4518] 17% | Training loss: 0.6876796142554578
Epoch: 75 | Iteration number: [820/4518] 18% | Training loss: 0.6876779394905742
Epoch: 75 | Iteration number: [830/4518] 18% | Training loss: 0.6876820903226554
Epoch: 75 | Iteration number: [840/4518] 18% | Training loss: 0.6876738360949926
Epoch: 75 | Iteration number: [850/4518] 18% | Training loss: 0.6876636957421022
Epoch: 75 | Iteration number: [860/4518] 19% | Training loss: 0.6876418363909389
Epoch: 75 | Iteration number: [870/4518] 19% | Training loss: 0.6876414151712396
Epoch: 75 | Iteration number: [880/4518] 19% | Training loss: 0.6876265594227747
Epoch: 75 | Iteration number: [890/4518] 19% | Training loss: 0.6876098903377404
Epoch: 75 | Iteration number: [900/4518] 19% | Training loss: 0.6876013934612274
Epoch: 75 | Iteration number: [910/4518] 20% | Training loss: 0.6875852704703153
Epoch: 75 | Iteration number: [920/4518] 20% | Training loss: 0.6875729346404905
Epoch: 75 | Iteration number: [930/4518] 20% | Training loss: 0.6875727343302901
Epoch: 75 | Iteration number: [940/4518] 20% | Training loss: 0.6875736168090333
Epoch: 75 | Iteration number: [950/4518] 21% | Training loss: 0.6875577515049984
Epoch: 75 | Iteration number: [960/4518] 21% | Training loss: 0.6875449409708381
Epoch: 75 | Iteration number: [970/4518] 21% | Training loss: 0.6875356510127942
Epoch: 75 | Iteration number: [980/4518] 21% | Training loss: 0.68754092381925
Epoch: 75 | Iteration number: [990/4518] 21% | Training loss: 0.687523954745495
Epoch: 75 | Iteration number: [1000/4518] 22% | Training loss: 0.6875200907588005
Epoch: 75 | Iteration number: [1010/4518] 22% | Training loss: 0.6874992446144028
Epoch: 75 | Iteration number: [1020/4518] 22% | Training loss: 0.6874863203249726
Epoch: 75 | Iteration number: [1030/4518] 22% | Training loss: 0.6874736403955997
Epoch: 75 | Iteration number: [1040/4518] 23% | Training loss: 0.6874713995708869
Epoch: 75 | Iteration number: [1050/4518] 23% | Training loss: 0.6874659095491682
Epoch: 75 | Iteration number: [1060/4518] 23% | Training loss: 0.6874564897901607
Epoch: 75 | Iteration number: [1070/4518] 23% | Training loss: 0.687449702258422
Epoch: 75 | Iteration number: [1080/4518] 23% | Training loss: 0.6874471265960622
Epoch: 75 | Iteration number: [1090/4518] 24% | Training loss: 0.6874398901375062
Epoch: 75 | Iteration number: [1100/4518] 24% | Training loss: 0.6874360639940609
Epoch: 75 | Iteration number: [1110/4518] 24% | Training loss: 0.6874357381919483
Epoch: 75 | Iteration number: [1120/4518] 24% | Training loss: 0.6874273148498364
Epoch: 75 | Iteration number: [1130/4518] 25% | Training loss: 0.6874255437766557
Epoch: 75 | Iteration number: [1140/4518] 25% | Training loss: 0.6874239834254248
Epoch: 75 | Iteration number: [1150/4518] 25% | Training loss: 0.6874069170329882
Epoch: 75 | Iteration number: [1160/4518] 25% | Training loss: 0.6874033591870604
Epoch: 75 | Iteration number: [1170/4518] 25% | Training loss: 0.687400216781176
Epoch: 75 | Iteration number: [1180/4518] 26% | Training loss: 0.687398484248226
Epoch: 75 | Iteration number: [1190/4518] 26% | Training loss: 0.687384102875445
Epoch: 75 | Iteration number: [1200/4518] 26% | Training loss: 0.6873789560298125
Epoch: 75 | Iteration number: [1210/4518] 26% | Training loss: 0.687367832611415
Epoch: 75 | Iteration number: [1220/4518] 27% | Training loss: 0.687367650231377
Epoch: 75 | Iteration number: [1230/4518] 27% | Training loss: 0.6873579597570063
Epoch: 75 | Iteration number: [1240/4518] 27% | Training loss: 0.6873484958083399
Epoch: 75 | Iteration number: [1250/4518] 27% | Training loss: 0.6873471864700318
Epoch: 75 | Iteration number: [1260/4518] 27% | Training loss: 0.6873478892776701
Epoch: 75 | Iteration number: [1270/4518] 28% | Training loss: 0.6873411951102609
Epoch: 75 | Iteration number: [1280/4518] 28% | Training loss: 0.6873400031588972
Epoch: 75 | Iteration number: [1290/4518] 28% | Training loss: 0.6873318759969963
Epoch: 75 | Iteration number: [1300/4518] 28% | Training loss: 0.6873274124585665
Epoch: 75 | Iteration number: [1310/4518] 28% | Training loss: 0.6873197274808666
Epoch: 75 | Iteration number: [1320/4518] 29% | Training loss: 0.6873157159397096
Epoch: 75 | Iteration number: [1330/4518] 29% | Training loss: 0.6873076875406997
Epoch: 75 | Iteration number: [1340/4518] 29% | Training loss: 0.6872925075577266
Epoch: 75 | Iteration number: [1350/4518] 29% | Training loss: 0.6872843560907576
Epoch: 75 | Iteration number: [1360/4518] 30% | Training loss: 0.6872696589897661
Epoch: 75 | Iteration number: [1370/4518] 30% | Training loss: 0.6872728604034786
Epoch: 75 | Iteration number: [1380/4518] 30% | Training loss: 0.6872672889111698
Epoch: 75 | Iteration number: [1390/4518] 30% | Training loss: 0.6872638321608948
Epoch: 75 | Iteration number: [1400/4518] 30% | Training loss: 0.6872621234825679
Epoch: 75 | Iteration number: [1410/4518] 31% | Training loss: 0.687251537573253
Epoch: 75 | Iteration number: [1420/4518] 31% | Training loss: 0.6872446856028597
Epoch: 75 | Iteration number: [1430/4518] 31% | Training loss: 0.6872422117453355
Epoch: 75 | Iteration number: [1440/4518] 31% | Training loss: 0.6872273966256115
Epoch: 75 | Iteration number: [1450/4518] 32% | Training loss: 0.6872231379459645
Epoch: 75 | Iteration number: [1460/4518] 32% | Training loss: 0.6872163788913047
Epoch: 75 | Iteration number: [1470/4518] 32% | Training loss: 0.6872103790847622
Epoch: 75 | Iteration number: [1480/4518] 32% | Training loss: 0.6872102967790655
Epoch: 75 | Iteration number: [1490/4518] 32% | Training loss: 0.6872137831761533
Epoch: 75 | Iteration number: [1500/4518] 33% | Training loss: 0.6872110758622487
Epoch: 75 | Iteration number: [1510/4518] 33% | Training loss: 0.6872079486878503
Epoch: 75 | Iteration number: [1520/4518] 33% | Training loss: 0.6871952130214164
Epoch: 75 | Iteration number: [1530/4518] 33% | Training loss: 0.6871908348759794
Epoch: 75 | Iteration number: [1540/4518] 34% | Training loss: 0.6871827530396449
Epoch: 75 | Iteration number: [1550/4518] 34% | Training loss: 0.6871727949573148
Epoch: 75 | Iteration number: [1560/4518] 34% | Training loss: 0.6871687449323826
Epoch: 75 | Iteration number: [1570/4518] 34% | Training loss: 0.6871648922467687
Epoch: 75 | Iteration number: [1580/4518] 34% | Training loss: 0.6871572779326499
Epoch: 75 | Iteration number: [1590/4518] 35% | Training loss: 0.6871540140805754
Epoch: 75 | Iteration number: [1600/4518] 35% | Training loss: 0.6871621109172702
Epoch: 75 | Iteration number: [1610/4518] 35% | Training loss: 0.6871605157852173
Epoch: 75 | Iteration number: [1620/4518] 35% | Training loss: 0.6871525308600178
Epoch: 75 | Iteration number: [1630/4518] 36% | Training loss: 0.6871510178399233
Epoch: 75 | Iteration number: [1640/4518] 36% | Training loss: 0.6871476335496437
Epoch: 75 | Iteration number: [1650/4518] 36% | Training loss: 0.6871485429821592
Epoch: 75 | Iteration number: [1660/4518] 36% | Training loss: 0.6871468531439103
Epoch: 75 | Iteration number: [1670/4518] 36% | Training loss: 0.6871485846128292
Epoch: 75 | Iteration number: [1680/4518] 37% | Training loss: 0.6871446587854908
Epoch: 75 | Iteration number: [1690/4518] 37% | Training loss: 0.6871429196828921
Epoch: 75 | Iteration number: [1700/4518] 37% | Training loss: 0.6871392401877572
Epoch: 75 | Iteration number: [1710/4518] 37% | Training loss: 0.6871428801999455
Epoch: 75 | Iteration number: [1720/4518] 38% | Training loss: 0.687147189850031
Epoch: 75 | Iteration number: [1730/4518] 38% | Training loss: 0.6871400599190265
Epoch: 75 | Iteration number: [1740/4518] 38% | Training loss: 0.687137125757919
Epoch: 75 | Iteration number: [1750/4518] 38% | Training loss: 0.6871371661594936
Epoch: 75 | Iteration number: [1760/4518] 38% | Training loss: 0.6871344189074906
Epoch: 75 | Iteration number: [1770/4518] 39% | Training loss: 0.687138399431261
Epoch: 75 | Iteration number: [1780/4518] 39% | Training loss: 0.687141454789076
Epoch: 75 | Iteration number: [1790/4518] 39% | Training loss: 0.6871419154065947
Epoch: 75 | Iteration number: [1800/4518] 39% | Training loss: 0.6871435572372543
Epoch: 75 | Iteration number: [1810/4518] 40% | Training loss: 0.6871448452301447
Epoch: 75 | Iteration number: [1820/4518] 40% | Training loss: 0.6871443735374199
Epoch: 75 | Iteration number: [1830/4518] 40% | Training loss: 0.6871392203810437
Epoch: 75 | Iteration number: [1840/4518] 40% | Training loss: 0.6871432271016681
Epoch: 75 | Iteration number: [1850/4518] 40% | Training loss: 0.687142795388763
Epoch: 75 | Iteration number: [1860/4518] 41% | Training loss: 0.6871446665897164
Epoch: 75 | Iteration number: [1870/4518] 41% | Training loss: 0.6871512192455842
Epoch: 75 | Iteration number: [1880/4518] 41% | Training loss: 0.6871425233305769
Epoch: 75 | Iteration number: [1890/4518] 41% | Training loss: 0.6871363151956488
Epoch: 75 | Iteration number: [1900/4518] 42% | Training loss: 0.6871283400686163
Epoch: 75 | Iteration number: [1910/4518] 42% | Training loss: 0.6871302340979352
Epoch: 75 | Iteration number: [1920/4518] 42% | Training loss: 0.6871353537154694
Epoch: 75 | Iteration number: [1930/4518] 42% | Training loss: 0.6871287142983372
Epoch: 75 | Iteration number: [1940/4518] 42% | Training loss: 0.6871217241299521
Epoch: 75 | Iteration number: [1950/4518] 43% | Training loss: 0.6871263195918157
Epoch: 75 | Iteration number: [1960/4518] 43% | Training loss: 0.6871200481543736
Epoch: 75 | Iteration number: [1970/4518] 43% | Training loss: 0.6871197163756123
Epoch: 75 | Iteration number: [1980/4518] 43% | Training loss: 0.6871179721271149
Epoch: 75 | Iteration number: [1990/4518] 44% | Training loss: 0.6871195263299511
Epoch: 75 | Iteration number: [2000/4518] 44% | Training loss: 0.6871156857609749
Epoch: 75 | Iteration number: [2010/4518] 44% | Training loss: 0.687110450700741
Epoch: 75 | Iteration number: [2020/4518] 44% | Training loss: 0.6871119453765379
Epoch: 75 | Iteration number: [2030/4518] 44% | Training loss: 0.6871056164133138
Epoch: 75 | Iteration number: [2040/4518] 45% | Training loss: 0.6871047979768585
Epoch: 75 | Iteration number: [2050/4518] 45% | Training loss: 0.6871050707886859
Epoch: 75 | Iteration number: [2060/4518] 45% | Training loss: 0.6870989995674022
Epoch: 75 | Iteration number: [2070/4518] 45% | Training loss: 0.687096304162113
Epoch: 75 | Iteration number: [2080/4518] 46% | Training loss: 0.687098558447682
Epoch: 75 | Iteration number: [2090/4518] 46% | Training loss: 0.6870978352270628
Epoch: 75 | Iteration number: [2100/4518] 46% | Training loss: 0.6870914432548342
Epoch: 75 | Iteration number: [2110/4518] 46% | Training loss: 0.6870906576443623
Epoch: 75 | Iteration number: [2120/4518] 46% | Training loss: 0.6870962090649695
Epoch: 75 | Iteration number: [2130/4518] 47% | Training loss: 0.6870925506795516
Epoch: 75 | Iteration number: [2140/4518] 47% | Training loss: 0.6870899596225436
Epoch: 75 | Iteration number: [2150/4518] 47% | Training loss: 0.6870822424112364
Epoch: 75 | Iteration number: [2160/4518] 47% | Training loss: 0.6870753567251894
Epoch: 75 | Iteration number: [2170/4518] 48% | Training loss: 0.6870751140579101
Epoch: 75 | Iteration number: [2180/4518] 48% | Training loss: 0.6870711566111364
Epoch: 75 | Iteration number: [2190/4518] 48% | Training loss: 0.6870670920365477
Epoch: 75 | Iteration number: [2200/4518] 48% | Training loss: 0.6870641934329813
Epoch: 75 | Iteration number: [2210/4518] 48% | Training loss: 0.687060247260521
Epoch: 75 | Iteration number: [2220/4518] 49% | Training loss: 0.6870611769927515
Epoch: 75 | Iteration number: [2230/4518] 49% | Training loss: 0.6870614350911213
Epoch: 75 | Iteration number: [2240/4518] 49% | Training loss: 0.6870594194158912
Epoch: 75 | Iteration number: [2250/4518] 49% | Training loss: 0.6870500774118635
Epoch: 75 | Iteration number: [2260/4518] 50% | Training loss: 0.6870537608334448
Epoch: 75 | Iteration number: [2270/4518] 50% | Training loss: 0.6870512091903435
Epoch: 75 | Iteration number: [2280/4518] 50% | Training loss: 0.6870482031190605
Epoch: 75 | Iteration number: [2290/4518] 50% | Training loss: 0.6870426592608206
Epoch: 75 | Iteration number: [2300/4518] 50% | Training loss: 0.6870394555382107
Epoch: 75 | Iteration number: [2310/4518] 51% | Training loss: 0.6870341309221276
Epoch: 75 | Iteration number: [2320/4518] 51% | Training loss: 0.6870334973879929
Epoch: 75 | Iteration number: [2330/4518] 51% | Training loss: 0.6870297484131842
Epoch: 75 | Iteration number: [2340/4518] 51% | Training loss: 0.687033469401873
Epoch: 75 | Iteration number: [2350/4518] 52% | Training loss: 0.6870349073663671
Epoch: 75 | Iteration number: [2360/4518] 52% | Training loss: 0.68703916262267
Epoch: 75 | Iteration number: [2370/4518] 52% | Training loss: 0.6870381267261908
Epoch: 75 | Iteration number: [2380/4518] 52% | Training loss: 0.6870375378542588
Epoch: 75 | Iteration number: [2390/4518] 52% | Training loss: 0.6870348292913397
Epoch: 75 | Iteration number: [2400/4518] 53% | Training loss: 0.6870362213005622
Epoch: 75 | Iteration number: [2410/4518] 53% | Training loss: 0.6870319194318842
Epoch: 75 | Iteration number: [2420/4518] 53% | Training loss: 0.6870315367771574
Epoch: 75 | Iteration number: [2430/4518] 53% | Training loss: 0.6870267643114176
Epoch: 75 | Iteration number: [2440/4518] 54% | Training loss: 0.6870269255804233
Epoch: 75 | Iteration number: [2450/4518] 54% | Training loss: 0.6870257237736059
Epoch: 75 | Iteration number: [2460/4518] 54% | Training loss: 0.6870252481563305
Epoch: 75 | Iteration number: [2470/4518] 54% | Training loss: 0.6870228346784105
Epoch: 75 | Iteration number: [2480/4518] 54% | Training loss: 0.6870218418778912
Epoch: 75 | Iteration number: [2490/4518] 55% | Training loss: 0.6870236839395929
Epoch: 75 | Iteration number: [2500/4518] 55% | Training loss: 0.6870235137224198
Epoch: 75 | Iteration number: [2510/4518] 55% | Training loss: 0.6870207935927873
Epoch: 75 | Iteration number: [2520/4518] 55% | Training loss: 0.6870177945920399
Epoch: 75 | Iteration number: [2530/4518] 55% | Training loss: 0.6870194226621168
Epoch: 75 | Iteration number: [2540/4518] 56% | Training loss: 0.6870190039629073
Epoch: 75 | Iteration number: [2550/4518] 56% | Training loss: 0.6870195742681915
Epoch: 75 | Iteration number: [2560/4518] 56% | Training loss: 0.6870201469399035
Epoch: 75 | Iteration number: [2570/4518] 56% | Training loss: 0.6870222670326901
Epoch: 75 | Iteration number: [2580/4518] 57% | Training loss: 0.6870185435742371
Epoch: 75 | Iteration number: [2590/4518] 57% | Training loss: 0.6870141839658892
Epoch: 75 | Iteration number: [2600/4518] 57% | Training loss: 0.6870095291045996
Epoch: 75 | Iteration number: [2610/4518] 57% | Training loss: 0.6870115725473426
Epoch: 75 | Iteration number: [2620/4518] 57% | Training loss: 0.6870123121347136
Epoch: 75 | Iteration number: [2630/4518] 58% | Training loss: 0.6870101506719117
Epoch: 75 | Iteration number: [2640/4518] 58% | Training loss: 0.6870122956281358
Epoch: 75 | Iteration number: [2650/4518] 58% | Training loss: 0.6870115884744896
Epoch: 75 | Iteration number: [2660/4518] 58% | Training loss: 0.6870067925829636
Epoch: 75 | Iteration number: [2670/4518] 59% | Training loss: 0.6870056619581658
Epoch: 75 | Iteration number: [2680/4518] 59% | Training loss: 0.6870102007664851
Epoch: 75 | Iteration number: [2690/4518] 59% | Training loss: 0.6870105078450809
Epoch: 75 | Iteration number: [2700/4518] 59% | Training loss: 0.6870061739065029
Epoch: 75 | Iteration number: [2710/4518] 59% | Training loss: 0.687001355569741
Epoch: 75 | Iteration number: [2720/4518] 60% | Training loss: 0.6870081220260438
Epoch: 75 | Iteration number: [2730/4518] 60% | Training loss: 0.6870081414451529
Epoch: 75 | Iteration number: [2740/4518] 60% | Training loss: 0.6870088832656832
Epoch: 75 | Iteration number: [2750/4518] 60% | Training loss: 0.687003559329293
Epoch: 75 | Iteration number: [2760/4518] 61% | Training loss: 0.6870049806392711
Epoch: 75 | Iteration number: [2770/4518] 61% | Training loss: 0.6870009527740065
Epoch: 75 | Iteration number: [2780/4518] 61% | Training loss: 0.6870012812691627
Epoch: 75 | Iteration number: [2790/4518] 61% | Training loss: 0.6869994928546277
Epoch: 75 | Iteration number: [2800/4518] 61% | Training loss: 0.6869927828226771
Epoch: 75 | Iteration number: [2810/4518] 62% | Training loss: 0.6869908295492261
Epoch: 75 | Iteration number: [2820/4518] 62% | Training loss: 0.6869849037194083
Epoch: 75 | Iteration number: [2830/4518] 62% | Training loss: 0.686987049145749
Epoch: 75 | Iteration number: [2840/4518] 62% | Training loss: 0.6869860486665242
Epoch: 75 | Iteration number: [2850/4518] 63% | Training loss: 0.6869850316173152
Epoch: 75 | Iteration number: [2860/4518] 63% | Training loss: 0.6869846406724903
Epoch: 75 | Iteration number: [2870/4518] 63% | Training loss: 0.686979133347601
Epoch: 75 | Iteration number: [2880/4518] 63% | Training loss: 0.6869794750793112
Epoch: 75 | Iteration number: [2890/4518] 63% | Training loss: 0.6869776293068196
Epoch: 75 | Iteration number: [2900/4518] 64% | Training loss: 0.6869756533154125
Epoch: 75 | Iteration number: [2910/4518] 64% | Training loss: 0.6869782622327509
Epoch: 75 | Iteration number: [2920/4518] 64% | Training loss: 0.6869796481851029
Epoch: 75 | Iteration number: [2930/4518] 64% | Training loss: 0.6869793910215333
Epoch: 75 | Iteration number: [2940/4518] 65% | Training loss: 0.6869771010413461
Epoch: 75 | Iteration number: [2950/4518] 65% | Training loss: 0.686976137646174
Epoch: 75 | Iteration number: [2960/4518] 65% | Training loss: 0.6869781538441374
Epoch: 75 | Iteration number: [2970/4518] 65% | Training loss: 0.6869732001413801
Epoch: 75 | Iteration number: [2980/4518] 65% | Training loss: 0.6869718901262988
Epoch: 75 | Iteration number: [2990/4518] 66% | Training loss: 0.6869716071364872
Epoch: 75 | Iteration number: [3000/4518] 66% | Training loss: 0.6869703191916148
Epoch: 75 | Iteration number: [3010/4518] 66% | Training loss: 0.6869699724488876
Epoch: 75 | Iteration number: [3020/4518] 66% | Training loss: 0.6869731264003854
Epoch: 75 | Iteration number: [3030/4518] 67% | Training loss: 0.6869727532265604
Epoch: 75 | Iteration number: [3040/4518] 67% | Training loss: 0.6869716858393268
Epoch: 75 | Iteration number: [3050/4518] 67% | Training loss: 0.6869657366197617
Epoch: 75 | Iteration number: [3060/4518] 67% | Training loss: 0.6869663029714348
Epoch: 75 | Iteration number: [3070/4518] 67% | Training loss: 0.6869649197845583
Epoch: 75 | Iteration number: [3080/4518] 68% | Training loss: 0.6869667711776573
Epoch: 75 | Iteration number: [3090/4518] 68% | Training loss: 0.6869668407733387
Epoch: 75 | Iteration number: [3100/4518] 68% | Training loss: 0.6869666841530031
Epoch: 75 | Iteration number: [3110/4518] 68% | Training loss: 0.68696408469194
Epoch: 75 | Iteration number: [3120/4518] 69% | Training loss: 0.6869662371965555
Epoch: 75 | Iteration number: [3130/4518] 69% | Training loss: 0.6869687434964287
Epoch: 75 | Iteration number: [3140/4518] 69% | Training loss: 0.6869699606090595
Epoch: 75 | Iteration number: [3150/4518] 69% | Training loss: 0.6869697583289374
Epoch: 75 | Iteration number: [3160/4518] 69% | Training loss: 0.6869649498523036
Epoch: 75 | Iteration number: [3170/4518] 70% | Training loss: 0.6869652611412085
Epoch: 75 | Iteration number: [3180/4518] 70% | Training loss: 0.6869622302692642
Epoch: 75 | Iteration number: [3190/4518] 70% | Training loss: 0.6869637068349366
Epoch: 75 | Iteration number: [3200/4518] 70% | Training loss: 0.6869656568206847
Epoch: 75 | Iteration number: [3210/4518] 71% | Training loss: 0.6869693419643652
Epoch: 75 | Iteration number: [3220/4518] 71% | Training loss: 0.6869700447557876
Epoch: 75 | Iteration number: [3230/4518] 71% | Training loss: 0.6869701485146679
Epoch: 75 | Iteration number: [3240/4518] 71% | Training loss: 0.6869680205061112
Epoch: 75 | Iteration number: [3250/4518] 71% | Training loss: 0.6869692291113046
Epoch: 75 | Iteration number: [3260/4518] 72% | Training loss: 0.6869726855330672
Epoch: 75 | Iteration number: [3270/4518] 72% | Training loss: 0.6869762220331653
Epoch: 75 | Iteration number: [3280/4518] 72% | Training loss: 0.6869784938852962
Epoch: 75 | Iteration number: [3290/4518] 72% | Training loss: 0.6869775679698469
Epoch: 75 | Iteration number: [3300/4518] 73% | Training loss: 0.6869804324164535
Epoch: 75 | Iteration number: [3310/4518] 73% | Training loss: 0.6869833795145559
Epoch: 75 | Iteration number: [3320/4518] 73% | Training loss: 0.686982459637774
Epoch: 75 | Iteration number: [3330/4518] 73% | Training loss: 0.68698481367873
Epoch: 75 | Iteration number: [3340/4518] 73% | Training loss: 0.6869833934449864
Epoch: 75 | Iteration number: [3350/4518] 74% | Training loss: 0.6869831317752155
Epoch: 75 | Iteration number: [3360/4518] 74% | Training loss: 0.6869826306189809
Epoch: 75 | Iteration number: [3370/4518] 74% | Training loss: 0.6869815474624804
Epoch: 75 | Iteration number: [3380/4518] 74% | Training loss: 0.6869790998965325
Epoch: 75 | Iteration number: [3390/4518] 75% | Training loss: 0.6869810336810649
Epoch: 75 | Iteration number: [3400/4518] 75% | Training loss: 0.6869810999316328
Epoch: 75 | Iteration number: [3410/4518] 75% | Training loss: 0.686977781438408
Epoch: 75 | Iteration number: [3420/4518] 75% | Training loss: 0.6869770817240777
Epoch: 75 | Iteration number: [3430/4518] 75% | Training loss: 0.6869752180993384
Epoch: 75 | Iteration number: [3440/4518] 76% | Training loss: 0.6869759623047917
Epoch: 75 | Iteration number: [3450/4518] 76% | Training loss: 0.6869756800886514
Epoch: 75 | Iteration number: [3460/4518] 76% | Training loss: 0.6869746651263595
Epoch: 75 | Iteration number: [3470/4518] 76% | Training loss: 0.6869726188931754
Epoch: 75 | Iteration number: [3480/4518] 77% | Training loss: 0.6869733716907173
Epoch: 75 | Iteration number: [3490/4518] 77% | Training loss: 0.6869723392762564
Epoch: 75 | Iteration number: [3500/4518] 77% | Training loss: 0.6869720695189068
Epoch: 75 | Iteration number: [3510/4518] 77% | Training loss: 0.6869721107503288
Epoch: 75 | Iteration number: [3520/4518] 77% | Training loss: 0.6869715950536457
Epoch: 75 | Iteration number: [3530/4518] 78% | Training loss: 0.686972990758696
Epoch: 75 | Iteration number: [3540/4518] 78% | Training loss: 0.6869688529079243
Epoch: 75 | Iteration number: [3550/4518] 78% | Training loss: 0.6869652450588387
Epoch: 75 | Iteration number: [3560/4518] 78% | Training loss: 0.686966188268715
Epoch: 75 | Iteration number: [3570/4518] 79% | Training loss: 0.6869659822194182
Epoch: 75 | Iteration number: [3580/4518] 79% | Training loss: 0.6869672814561002
Epoch: 75 | Iteration number: [3590/4518] 79% | Training loss: 0.6869671317860276
Epoch: 75 | Iteration number: [3600/4518] 79% | Training loss: 0.6869698899653223
Epoch: 75 | Iteration number: [3610/4518] 79% | Training loss: 0.6869686603876363
Epoch: 75 | Iteration number: [3620/4518] 80% | Training loss: 0.6869639706216465
Epoch: 75 | Iteration number: [3630/4518] 80% | Training loss: 0.6869649035378921
Epoch: 75 | Iteration number: [3640/4518] 80% | Training loss: 0.6869677956123929
Epoch: 75 | Iteration number: [3650/4518] 80% | Training loss: 0.6869653619642127
Epoch: 75 | Iteration number: [3660/4518] 81% | Training loss: 0.6869654364924613
Epoch: 75 | Iteration number: [3670/4518] 81% | Training loss: 0.6869637272338451
Epoch: 75 | Iteration number: [3680/4518] 81% | Training loss: 0.6869617452278085
Epoch: 75 | Iteration number: [3690/4518] 81% | Training loss: 0.6869591605372545
Epoch: 75 | Iteration number: [3700/4518] 81% | Training loss: 0.6869606354591009
Epoch: 75 | Iteration number: [3710/4518] 82% | Training loss: 0.6869601181253912
Epoch: 75 | Iteration number: [3720/4518] 82% | Training loss: 0.6869621161812095
Epoch: 75 | Iteration number: [3730/4518] 82% | Training loss: 0.6869626906538138
Epoch: 75 | Iteration number: [3740/4518] 82% | Training loss: 0.6869603293146042
Epoch: 75 | Iteration number: [3750/4518] 83% | Training loss: 0.6869610426108043
Epoch: 75 | Iteration number: [3760/4518] 83% | Training loss: 0.6869601715118328
Epoch: 75 | Iteration number: [3770/4518] 83% | Training loss: 0.6869606439409585
Epoch: 75 | Iteration number: [3780/4518] 83% | Training loss: 0.6869630568084263
Epoch: 75 | Iteration number: [3790/4518] 83% | Training loss: 0.6869620931494519
Epoch: 75 | Iteration number: [3800/4518] 84% | Training loss: 0.6869619533419609
Epoch: 75 | Iteration number: [3810/4518] 84% | Training loss: 0.6869634349045791
Epoch: 75 | Iteration number: [3820/4518] 84% | Training loss: 0.6869654975324401
Epoch: 75 | Iteration number: [3830/4518] 84% | Training loss: 0.6869648810155087
Epoch: 75 | Iteration number: [3840/4518] 84% | Training loss: 0.6869635832185547
Epoch: 75 | Iteration number: [3850/4518] 85% | Training loss: 0.6869598163722398
Epoch: 75 | Iteration number: [3860/4518] 85% | Training loss: 0.6869588124628512
Epoch: 75 | Iteration number: [3870/4518] 85% | Training loss: 0.6869584391129417
Epoch: 75 | Iteration number: [3880/4518] 85% | Training loss: 0.6869575941992789
Epoch: 75 | Iteration number: [3890/4518] 86% | Training loss: 0.6869538381963892
Epoch: 75 | Iteration number: [3900/4518] 86% | Training loss: 0.686951686510673
Epoch: 75 | Iteration number: [3910/4518] 86% | Training loss: 0.686948388891147
Epoch: 75 | Iteration number: [3920/4518] 86% | Training loss: 0.6869462323432066
Epoch: 75 | Iteration number: [3930/4518] 86% | Training loss: 0.6869474924702681
Epoch: 75 | Iteration number: [3940/4518] 87% | Training loss: 0.6869467219725478
Epoch: 75 | Iteration number: [3950/4518] 87% | Training loss: 0.6869446081753019
Epoch: 75 | Iteration number: [3960/4518] 87% | Training loss: 0.6869447973189932
Epoch: 75 | Iteration number: [3970/4518] 87% | Training loss: 0.6869417519503337
Epoch: 75 | Iteration number: [3980/4518] 88% | Training loss: 0.6869443757749683
Epoch: 75 | Iteration number: [3990/4518] 88% | Training loss: 0.6869437907871447
Epoch: 75 | Iteration number: [4000/4518] 88% | Training loss: 0.6869437732696533
Epoch: 75 | Iteration number: [4010/4518] 88% | Training loss: 0.686943407665167
Epoch: 75 | Iteration number: [4020/4518] 88% | Training loss: 0.686940850487989
Epoch: 75 | Iteration number: [4030/4518] 89% | Training loss: 0.6869401314714114
Epoch: 75 | Iteration number: [4040/4518] 89% | Training loss: 0.6869379475122631
Epoch: 75 | Iteration number: [4050/4518] 89% | Training loss: 0.6869346959502609
Epoch: 75 | Iteration number: [4060/4518] 89% | Training loss: 0.68693245807892
Epoch: 75 | Iteration number: [4070/4518] 90% | Training loss: 0.686936667275956
Epoch: 75 | Iteration number: [4080/4518] 90% | Training loss: 0.6869361118796994
Epoch: 75 | Iteration number: [4090/4518] 90% | Training loss: 0.6869344766536377
Epoch: 75 | Iteration number: [4100/4518] 90% | Training loss: 0.6869332585683683
Epoch: 75 | Iteration number: [4110/4518] 90% | Training loss: 0.6869316024791875
Epoch: 75 | Iteration number: [4120/4518] 91% | Training loss: 0.6869315829381202
Epoch: 75 | Iteration number: [4130/4518] 91% | Training loss: 0.6869338063437482
Epoch: 75 | Iteration number: [4140/4518] 91% | Training loss: 0.6869347059928277
Epoch: 75 | Iteration number: [4150/4518] 91% | Training loss: 0.6869332473105695
Epoch: 75 | Iteration number: [4160/4518] 92% | Training loss: 0.68693619184196
Epoch: 75 | Iteration number: [4170/4518] 92% | Training loss: 0.6869384575233185
Epoch: 75 | Iteration number: [4180/4518] 92% | Training loss: 0.6869396289427314
Epoch: 75 | Iteration number: [4190/4518] 92% | Training loss: 0.6869374960874316
Epoch: 75 | Iteration number: [4200/4518] 92% | Training loss: 0.6869369986937159
Epoch: 75 | Iteration number: [4210/4518] 93% | Training loss: 0.6869359834743509
Epoch: 75 | Iteration number: [4220/4518] 93% | Training loss: 0.686936369707799
Epoch: 75 | Iteration number: [4230/4518] 93% | Training loss: 0.6869357796989153
Epoch: 75 | Iteration number: [4240/4518] 93% | Training loss: 0.6869368877472742
Epoch: 75 | Iteration number: [4250/4518] 94% | Training loss: 0.6869354238790625
Epoch: 75 | Iteration number: [4260/4518] 94% | Training loss: 0.6869347429891147
Epoch: 75 | Iteration number: [4270/4518] 94% | Training loss: 0.6869321212835557
Epoch: 75 | Iteration number: [4280/4518] 94% | Training loss: 0.6869292247518201
Epoch: 75 | Iteration number: [4290/4518] 94% | Training loss: 0.6869294144751587
Epoch: 75 | Iteration number: [4300/4518] 95% | Training loss: 0.6869308293836062
Epoch: 75 | Iteration number: [4310/4518] 95% | Training loss: 0.6869314904694214
Epoch: 75 | Iteration number: [4320/4518] 95% | Training loss: 0.6869297539470373
Epoch: 75 | Iteration number: [4330/4518] 95% | Training loss: 0.6869267005430358
Epoch: 75 | Iteration number: [4340/4518] 96% | Training loss: 0.6869279662035578
Epoch: 75 | Iteration number: [4350/4518] 96% | Training loss: 0.6869303887739949
Epoch: 75 | Iteration number: [4360/4518] 96% | Training loss: 0.6869299084084843
Epoch: 75 | Iteration number: [4370/4518] 96% | Training loss: 0.6869265503277767
Epoch: 75 | Iteration number: [4380/4518] 96% | Training loss: 0.6869252383164619
Epoch: 75 | Iteration number: [4390/4518] 97% | Training loss: 0.6869250628155293
Epoch: 75 | Iteration number: [4400/4518] 97% | Training loss: 0.6869251673465425
Epoch: 75 | Iteration number: [4410/4518] 97% | Training loss: 0.6869252370328319
Epoch: 75 | Iteration number: [4420/4518] 97% | Training loss: 0.6869243031308662
Epoch: 75 | Iteration number: [4430/4518] 98% | Training loss: 0.6869225938352451
Epoch: 75 | Iteration number: [4440/4518] 98% | Training loss: 0.6869248518401438
Epoch: 75 | Iteration number: [4450/4518] 98% | Training loss: 0.6869265026456854
Epoch: 75 | Iteration number: [4460/4518] 98% | Training loss: 0.686926371300167
Epoch: 75 | Iteration number: [4470/4518] 98% | Training loss: 0.686924346528064
Epoch: 75 | Iteration number: [4480/4518] 99% | Training loss: 0.6869259781603302
Epoch: 75 | Iteration number: [4490/4518] 99% | Training loss: 0.6869293129789271
Epoch: 75 | Iteration number: [4500/4518] 99% | Training loss: 0.6869312465985616
Epoch: 75 | Iteration number: [4510/4518] 99% | Training loss: 0.6869298280871364

 End of epoch: 75 | Train Loss: 0.6867784818303748 | Training Time: 642 

 End of epoch: 75 | Eval Loss: 0.6899931151039747 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/4518] 0% | Training loss: 0.7547845482826233
Epoch: 76 | Iteration number: [20/4518] 0% | Training loss: 0.7211627066135406
Epoch: 76 | Iteration number: [30/4518] 0% | Training loss: 0.709992790222168
Epoch: 76 | Iteration number: [40/4518] 0% | Training loss: 0.7041378915309906
Epoch: 76 | Iteration number: [50/4518] 1% | Training loss: 0.7005212426185607
Epoch: 76 | Iteration number: [60/4518] 1% | Training loss: 0.6979324688514074
Epoch: 76 | Iteration number: [70/4518] 1% | Training loss: 0.6963899544307164
Epoch: 76 | Iteration number: [80/4518] 1% | Training loss: 0.6953367181122303
Epoch: 76 | Iteration number: [90/4518] 1% | Training loss: 0.6942890067895253
Epoch: 76 | Iteration number: [100/4518] 2% | Training loss: 0.6934878635406494
Epoch: 76 | Iteration number: [110/4518] 2% | Training loss: 0.6929673124443401
Epoch: 76 | Iteration number: [120/4518] 2% | Training loss: 0.6924601708849271
Epoch: 76 | Iteration number: [130/4518] 2% | Training loss: 0.6920421086824857
Epoch: 76 | Iteration number: [140/4518] 3% | Training loss: 0.6916445808751243
Epoch: 76 | Iteration number: [150/4518] 3% | Training loss: 0.6913163888454438
Epoch: 76 | Iteration number: [160/4518] 3% | Training loss: 0.6910032667219639
Epoch: 76 | Iteration number: [170/4518] 3% | Training loss: 0.6908521795974059
Epoch: 76 | Iteration number: [180/4518] 3% | Training loss: 0.6906176086929109
Epoch: 76 | Iteration number: [190/4518] 4% | Training loss: 0.6904665583058407
Epoch: 76 | Iteration number: [200/4518] 4% | Training loss: 0.6903544732928276
Epoch: 76 | Iteration number: [210/4518] 4% | Training loss: 0.690133008218947
Epoch: 76 | Iteration number: [220/4518] 4% | Training loss: 0.690011577443643
Epoch: 76 | Iteration number: [230/4518] 5% | Training loss: 0.6898729039275128
Epoch: 76 | Iteration number: [240/4518] 5% | Training loss: 0.689681667337815
Epoch: 76 | Iteration number: [250/4518] 5% | Training loss: 0.6895627105236053
Epoch: 76 | Iteration number: [260/4518] 5% | Training loss: 0.6894475666376261
Epoch: 76 | Iteration number: [270/4518] 5% | Training loss: 0.6893997742070093
Epoch: 76 | Iteration number: [280/4518] 6% | Training loss: 0.6893020614981651
Epoch: 76 | Iteration number: [290/4518] 6% | Training loss: 0.6892006941910448
Epoch: 76 | Iteration number: [300/4518] 6% | Training loss: 0.6891240135828653
Epoch: 76 | Iteration number: [310/4518] 6% | Training loss: 0.689020892689305
Epoch: 76 | Iteration number: [320/4518] 7% | Training loss: 0.6889588084071875
Epoch: 76 | Iteration number: [330/4518] 7% | Training loss: 0.6889013160358776
Epoch: 76 | Iteration number: [340/4518] 7% | Training loss: 0.6888057796394124
Epoch: 76 | Iteration number: [350/4518] 7% | Training loss: 0.688760118995394
Epoch: 76 | Iteration number: [360/4518] 7% | Training loss: 0.688692640264829
Epoch: 76 | Iteration number: [370/4518] 8% | Training loss: 0.6886630904030155
Epoch: 76 | Iteration number: [380/4518] 8% | Training loss: 0.6885886617397007
Epoch: 76 | Iteration number: [390/4518] 8% | Training loss: 0.6885278568818018
Epoch: 76 | Iteration number: [400/4518] 8% | Training loss: 0.6884622529149056
Epoch: 76 | Iteration number: [410/4518] 9% | Training loss: 0.6884266786459016
Epoch: 76 | Iteration number: [420/4518] 9% | Training loss: 0.6883907106660662
Epoch: 76 | Iteration number: [430/4518] 9% | Training loss: 0.6883548778156902
Epoch: 76 | Iteration number: [440/4518] 9% | Training loss: 0.6883181636983698
Epoch: 76 | Iteration number: [450/4518] 9% | Training loss: 0.6882596573564741
Epoch: 76 | Iteration number: [460/4518] 10% | Training loss: 0.6882365231928618
Epoch: 76 | Iteration number: [470/4518] 10% | Training loss: 0.6882243521670077
Epoch: 76 | Iteration number: [480/4518] 10% | Training loss: 0.6881928586711487
Epoch: 76 | Iteration number: [490/4518] 10% | Training loss: 0.6881530430852151
Epoch: 76 | Iteration number: [500/4518] 11% | Training loss: 0.6881273462772369
Epoch: 76 | Iteration number: [510/4518] 11% | Training loss: 0.6880946097420712
Epoch: 76 | Iteration number: [520/4518] 11% | Training loss: 0.6880994766950608
Epoch: 76 | Iteration number: [530/4518] 11% | Training loss: 0.6880803066604543
Epoch: 76 | Iteration number: [540/4518] 11% | Training loss: 0.6880462061475825
Epoch: 76 | Iteration number: [550/4518] 12% | Training loss: 0.6880485343933106
Epoch: 76 | Iteration number: [560/4518] 12% | Training loss: 0.6880433886178903
Epoch: 76 | Iteration number: [570/4518] 12% | Training loss: 0.6880343840833296
Epoch: 76 | Iteration number: [580/4518] 12% | Training loss: 0.6879962709443322
Epoch: 76 | Iteration number: [590/4518] 13% | Training loss: 0.6879457876843921
Epoch: 76 | Iteration number: [600/4518] 13% | Training loss: 0.6879195121924082
Epoch: 76 | Iteration number: [610/4518] 13% | Training loss: 0.6878975562384871
Epoch: 76 | Iteration number: [620/4518] 13% | Training loss: 0.6878695435100987
Epoch: 76 | Iteration number: [630/4518] 13% | Training loss: 0.6878520812307085
Epoch: 76 | Iteration number: [640/4518] 14% | Training loss: 0.6878308183513582
Epoch: 76 | Iteration number: [650/4518] 14% | Training loss: 0.6877968726708339
Epoch: 76 | Iteration number: [660/4518] 14% | Training loss: 0.687769601019946
Epoch: 76 | Iteration number: [670/4518] 14% | Training loss: 0.687747132956092
Epoch: 76 | Iteration number: [680/4518] 15% | Training loss: 0.6877217686351608
Epoch: 76 | Iteration number: [690/4518] 15% | Training loss: 0.6877207617828811
Epoch: 76 | Iteration number: [700/4518] 15% | Training loss: 0.6877141734531947
Epoch: 76 | Iteration number: [710/4518] 15% | Training loss: 0.6877002957001538
Epoch: 76 | Iteration number: [720/4518] 15% | Training loss: 0.6876994125545025
Epoch: 76 | Iteration number: [730/4518] 16% | Training loss: 0.6876647605471415
Epoch: 76 | Iteration number: [740/4518] 16% | Training loss: 0.6876473650739
Epoch: 76 | Iteration number: [750/4518] 16% | Training loss: 0.6876362925370534
Epoch: 76 | Iteration number: [760/4518] 16% | Training loss: 0.6876102047531228
Epoch: 76 | Iteration number: [770/4518] 17% | Training loss: 0.6875974095486975
Epoch: 76 | Iteration number: [780/4518] 17% | Training loss: 0.6875885185522911
Epoch: 76 | Iteration number: [790/4518] 17% | Training loss: 0.6875850289682799
Epoch: 76 | Iteration number: [800/4518] 17% | Training loss: 0.6875744473934173
Epoch: 76 | Iteration number: [810/4518] 17% | Training loss: 0.687565051994206
Epoch: 76 | Iteration number: [820/4518] 18% | Training loss: 0.6875526955214942
Epoch: 76 | Iteration number: [830/4518] 18% | Training loss: 0.6875356132007507
Epoch: 76 | Iteration number: [840/4518] 18% | Training loss: 0.6875256238948732
Epoch: 76 | Iteration number: [850/4518] 18% | Training loss: 0.6875294801768135
Epoch: 76 | Iteration number: [860/4518] 19% | Training loss: 0.687510085868281
Epoch: 76 | Iteration number: [870/4518] 19% | Training loss: 0.6874968883634984
Epoch: 76 | Iteration number: [880/4518] 19% | Training loss: 0.6874920976432887
Epoch: 76 | Iteration number: [890/4518] 19% | Training loss: 0.6874835779157917
Epoch: 76 | Iteration number: [900/4518] 19% | Training loss: 0.6874673951996697
Epoch: 76 | Iteration number: [910/4518] 20% | Training loss: 0.6874433769629552
Epoch: 76 | Iteration number: [920/4518] 20% | Training loss: 0.6874381742399672
Epoch: 76 | Iteration number: [930/4518] 20% | Training loss: 0.6874298689185933
Epoch: 76 | Iteration number: [940/4518] 20% | Training loss: 0.687420164651059
Epoch: 76 | Iteration number: [950/4518] 21% | Training loss: 0.6874244604612652
Epoch: 76 | Iteration number: [960/4518] 21% | Training loss: 0.6874183272942901
Epoch: 76 | Iteration number: [970/4518] 21% | Training loss: 0.6874119335843115
Epoch: 76 | Iteration number: [980/4518] 21% | Training loss: 0.6874054362579268
Epoch: 76 | Iteration number: [990/4518] 21% | Training loss: 0.6874108154364307
Epoch: 76 | Iteration number: [1000/4518] 22% | Training loss: 0.6874025315642357
Epoch: 76 | Iteration number: [1010/4518] 22% | Training loss: 0.6873993710126027
Epoch: 76 | Iteration number: [1020/4518] 22% | Training loss: 0.687393964622535
Epoch: 76 | Iteration number: [1030/4518] 22% | Training loss: 0.6873949925876358
Epoch: 76 | Iteration number: [1040/4518] 23% | Training loss: 0.6873862698101081
Epoch: 76 | Iteration number: [1050/4518] 23% | Training loss: 0.6873902820405506
Epoch: 76 | Iteration number: [1060/4518] 23% | Training loss: 0.6873794716484142
Epoch: 76 | Iteration number: [1070/4518] 23% | Training loss: 0.6873746913170146
Epoch: 76 | Iteration number: [1080/4518] 23% | Training loss: 0.6873824955136688
Epoch: 76 | Iteration number: [1090/4518] 24% | Training loss: 0.6873798873993235
Epoch: 76 | Iteration number: [1100/4518] 24% | Training loss: 0.6873877140608701
Epoch: 76 | Iteration number: [1110/4518] 24% | Training loss: 0.6873796891521763
Epoch: 76 | Iteration number: [1120/4518] 24% | Training loss: 0.6873788165726832
Epoch: 76 | Iteration number: [1130/4518] 25% | Training loss: 0.6873797168246413
Epoch: 76 | Iteration number: [1140/4518] 25% | Training loss: 0.6873792555771376
Epoch: 76 | Iteration number: [1150/4518] 25% | Training loss: 0.6873678722070611
Epoch: 76 | Iteration number: [1160/4518] 25% | Training loss: 0.6873653998662685
Epoch: 76 | Iteration number: [1170/4518] 25% | Training loss: 0.6873684934061817
Epoch: 76 | Iteration number: [1180/4518] 26% | Training loss: 0.6873629765490354
Epoch: 76 | Iteration number: [1190/4518] 26% | Training loss: 0.6873615698654111
Epoch: 76 | Iteration number: [1200/4518] 26% | Training loss: 0.6873594464361668
Epoch: 76 | Iteration number: [1210/4518] 26% | Training loss: 0.6873449092068948
Epoch: 76 | Iteration number: [1220/4518] 27% | Training loss: 0.6873489702334169
Epoch: 76 | Iteration number: [1230/4518] 27% | Training loss: 0.6873389257163536
Epoch: 76 | Iteration number: [1240/4518] 27% | Training loss: 0.6873344589625635
Epoch: 76 | Iteration number: [1250/4518] 27% | Training loss: 0.6873254878997803
Epoch: 76 | Iteration number: [1260/4518] 27% | Training loss: 0.6873242453450248
Epoch: 76 | Iteration number: [1270/4518] 28% | Training loss: 0.6873127311702788
Epoch: 76 | Iteration number: [1280/4518] 28% | Training loss: 0.6873056123498827
Epoch: 76 | Iteration number: [1290/4518] 28% | Training loss: 0.687303094069163
Epoch: 76 | Iteration number: [1300/4518] 28% | Training loss: 0.6873013767829308
Epoch: 76 | Iteration number: [1310/4518] 28% | Training loss: 0.6873013731177526
Epoch: 76 | Iteration number: [1320/4518] 29% | Training loss: 0.6873001319892479
Epoch: 76 | Iteration number: [1330/4518] 29% | Training loss: 0.6872951691760156
Epoch: 76 | Iteration number: [1340/4518] 29% | Training loss: 0.6872885478966272
Epoch: 76 | Iteration number: [1350/4518] 29% | Training loss: 0.6872839255244644
Epoch: 76 | Iteration number: [1360/4518] 30% | Training loss: 0.6872803306316628
Epoch: 76 | Iteration number: [1370/4518] 30% | Training loss: 0.6872725784343524
Epoch: 76 | Iteration number: [1380/4518] 30% | Training loss: 0.6872709788705992
Epoch: 76 | Iteration number: [1390/4518] 30% | Training loss: 0.6872781925921817
Epoch: 76 | Iteration number: [1400/4518] 30% | Training loss: 0.6872753013031824
Epoch: 76 | Iteration number: [1410/4518] 31% | Training loss: 0.6872698175568953
Epoch: 76 | Iteration number: [1420/4518] 31% | Training loss: 0.687258655252591
Epoch: 76 | Iteration number: [1430/4518] 31% | Training loss: 0.6872540063374526
Epoch: 76 | Iteration number: [1440/4518] 31% | Training loss: 0.6872469744334618
Epoch: 76 | Iteration number: [1450/4518] 32% | Training loss: 0.6872418265096073
Epoch: 76 | Iteration number: [1460/4518] 32% | Training loss: 0.6872403028076642
Epoch: 76 | Iteration number: [1470/4518] 32% | Training loss: 0.6872369995328034
Epoch: 76 | Iteration number: [1480/4518] 32% | Training loss: 0.6872287936710023
Epoch: 76 | Iteration number: [1490/4518] 32% | Training loss: 0.6872335983602793
Epoch: 76 | Iteration number: [1500/4518] 33% | Training loss: 0.6872327824831009
Epoch: 76 | Iteration number: [1510/4518] 33% | Training loss: 0.6872231158594422
Epoch: 76 | Iteration number: [1520/4518] 33% | Training loss: 0.687231051686563
Epoch: 76 | Iteration number: [1530/4518] 33% | Training loss: 0.6872371176099465
Epoch: 76 | Iteration number: [1540/4518] 34% | Training loss: 0.6872298470565251
Epoch: 76 | Iteration number: [1550/4518] 34% | Training loss: 0.6872386210964572
Epoch: 76 | Iteration number: [1560/4518] 34% | Training loss: 0.6872352616145061
Epoch: 76 | Iteration number: [1570/4518] 34% | Training loss: 0.687233193778688
Epoch: 76 | Iteration number: [1580/4518] 34% | Training loss: 0.6872177046311052
Epoch: 76 | Iteration number: [1590/4518] 35% | Training loss: 0.6872126492689241
Epoch: 76 | Iteration number: [1600/4518] 35% | Training loss: 0.687203810326755
Epoch: 76 | Iteration number: [1610/4518] 35% | Training loss: 0.6872008038233526
Epoch: 76 | Iteration number: [1620/4518] 35% | Training loss: 0.687197975759153
Epoch: 76 | Iteration number: [1630/4518] 36% | Training loss: 0.6871867137452576
Epoch: 76 | Iteration number: [1640/4518] 36% | Training loss: 0.6871920214920509
Epoch: 76 | Iteration number: [1650/4518] 36% | Training loss: 0.6871895950852018
Epoch: 76 | Iteration number: [1660/4518] 36% | Training loss: 0.68718436152102
Epoch: 76 | Iteration number: [1670/4518] 36% | Training loss: 0.6871862322627428
Epoch: 76 | Iteration number: [1680/4518] 37% | Training loss: 0.6871893518737384
Epoch: 76 | Iteration number: [1690/4518] 37% | Training loss: 0.6871885763117548
Epoch: 76 | Iteration number: [1700/4518] 37% | Training loss: 0.6871835283321492
Epoch: 76 | Iteration number: [1710/4518] 37% | Training loss: 0.6871825013941492
Epoch: 76 | Iteration number: [1720/4518] 38% | Training loss: 0.687178688305755
Epoch: 76 | Iteration number: [1730/4518] 38% | Training loss: 0.6871750807831053
Epoch: 76 | Iteration number: [1740/4518] 38% | Training loss: 0.6871685750525574
Epoch: 76 | Iteration number: [1750/4518] 38% | Training loss: 0.6871583490371704
Epoch: 76 | Iteration number: [1760/4518] 38% | Training loss: 0.6871572915125977
Epoch: 76 | Iteration number: [1770/4518] 39% | Training loss: 0.6871542355435043
Epoch: 76 | Iteration number: [1780/4518] 39% | Training loss: 0.6871512573421671
Epoch: 76 | Iteration number: [1790/4518] 39% | Training loss: 0.687143376419664
Epoch: 76 | Iteration number: [1800/4518] 39% | Training loss: 0.6871458382738961
Epoch: 76 | Iteration number: [1810/4518] 40% | Training loss: 0.6871368804030655
Epoch: 76 | Iteration number: [1820/4518] 40% | Training loss: 0.6871255409914059
Epoch: 76 | Iteration number: [1830/4518] 40% | Training loss: 0.6871274486265547
Epoch: 76 | Iteration number: [1840/4518] 40% | Training loss: 0.6871252145132293
Epoch: 76 | Iteration number: [1850/4518] 40% | Training loss: 0.6871264368134576
Epoch: 76 | Iteration number: [1860/4518] 41% | Training loss: 0.6871242737577807
Epoch: 76 | Iteration number: [1870/4518] 41% | Training loss: 0.6871281904332778
Epoch: 76 | Iteration number: [1880/4518] 41% | Training loss: 0.6871221999538706
Epoch: 76 | Iteration number: [1890/4518] 41% | Training loss: 0.6871109708276375
Epoch: 76 | Iteration number: [1900/4518] 42% | Training loss: 0.687113537568795
Epoch: 76 | Iteration number: [1910/4518] 42% | Training loss: 0.6871050186806325
Epoch: 76 | Iteration number: [1920/4518] 42% | Training loss: 0.687098193479081
Epoch: 76 | Iteration number: [1930/4518] 42% | Training loss: 0.6870976251950536
Epoch: 76 | Iteration number: [1940/4518] 42% | Training loss: 0.687099113353749
Epoch: 76 | Iteration number: [1950/4518] 43% | Training loss: 0.6871002708948576
Epoch: 76 | Iteration number: [1960/4518] 43% | Training loss: 0.6871002668932993
Epoch: 76 | Iteration number: [1970/4518] 43% | Training loss: 0.6871051454907141
Epoch: 76 | Iteration number: [1980/4518] 43% | Training loss: 0.6871054784517096
Epoch: 76 | Iteration number: [1990/4518] 44% | Training loss: 0.6871038407237087
Epoch: 76 | Iteration number: [2000/4518] 44% | Training loss: 0.6871057814955711
Epoch: 76 | Iteration number: [2010/4518] 44% | Training loss: 0.6871067561616945
Epoch: 76 | Iteration number: [2020/4518] 44% | Training loss: 0.6870978915160245
Epoch: 76 | Iteration number: [2030/4518] 44% | Training loss: 0.6870905479774099
Epoch: 76 | Iteration number: [2040/4518] 45% | Training loss: 0.6870901627867829
Epoch: 76 | Iteration number: [2050/4518] 45% | Training loss: 0.6870866494643979
Epoch: 76 | Iteration number: [2060/4518] 45% | Training loss: 0.6870855615555661
Epoch: 76 | Iteration number: [2070/4518] 45% | Training loss: 0.6870829591140655
Epoch: 76 | Iteration number: [2080/4518] 46% | Training loss: 0.6870782707459652
Epoch: 76 | Iteration number: [2090/4518] 46% | Training loss: 0.6870774704873847
Epoch: 76 | Iteration number: [2100/4518] 46% | Training loss: 0.6870762234926224
Epoch: 76 | Iteration number: [2110/4518] 46% | Training loss: 0.6870735381734314
Epoch: 76 | Iteration number: [2120/4518] 46% | Training loss: 0.6870743498487293
Epoch: 76 | Iteration number: [2130/4518] 47% | Training loss: 0.6870749399695598
Epoch: 76 | Iteration number: [2140/4518] 47% | Training loss: 0.6870727666906107
Epoch: 76 | Iteration number: [2150/4518] 47% | Training loss: 0.6870796609756559
Epoch: 76 | Iteration number: [2160/4518] 47% | Training loss: 0.6870755272331062
Epoch: 76 | Iteration number: [2170/4518] 48% | Training loss: 0.6870725439715495
Epoch: 76 | Iteration number: [2180/4518] 48% | Training loss: 0.687068860437892
Epoch: 76 | Iteration number: [2190/4518] 48% | Training loss: 0.6870661682462039
Epoch: 76 | Iteration number: [2200/4518] 48% | Training loss: 0.6870656015656211
Epoch: 76 | Iteration number: [2210/4518] 48% | Training loss: 0.6870675349127653
Epoch: 76 | Iteration number: [2220/4518] 49% | Training loss: 0.6870715779495669
Epoch: 76 | Iteration number: [2230/4518] 49% | Training loss: 0.68706850807763
Epoch: 76 | Iteration number: [2240/4518] 49% | Training loss: 0.6870648441037961
Epoch: 76 | Iteration number: [2250/4518] 49% | Training loss: 0.6870660931004419
Epoch: 76 | Iteration number: [2260/4518] 50% | Training loss: 0.6870604070678221
Epoch: 76 | Iteration number: [2270/4518] 50% | Training loss: 0.6870582457155908
Epoch: 76 | Iteration number: [2280/4518] 50% | Training loss: 0.6870556703262162
Epoch: 76 | Iteration number: [2290/4518] 50% | Training loss: 0.6870564572936062
Epoch: 76 | Iteration number: [2300/4518] 50% | Training loss: 0.6870571567442106
Epoch: 76 | Iteration number: [2310/4518] 51% | Training loss: 0.6870508067019574
Epoch: 76 | Iteration number: [2320/4518] 51% | Training loss: 0.6870550071627929
Epoch: 76 | Iteration number: [2330/4518] 51% | Training loss: 0.6870542416500943
Epoch: 76 | Iteration number: [2340/4518] 51% | Training loss: 0.6870565883624248
Epoch: 76 | Iteration number: [2350/4518] 52% | Training loss: 0.6870604915568169
Epoch: 76 | Iteration number: [2360/4518] 52% | Training loss: 0.6870591460395667
Epoch: 76 | Iteration number: [2370/4518] 52% | Training loss: 0.6870600274595027
Epoch: 76 | Iteration number: [2380/4518] 52% | Training loss: 0.6870633913939741
Epoch: 76 | Iteration number: [2390/4518] 52% | Training loss: 0.6870621821620974
Epoch: 76 | Iteration number: [2400/4518] 53% | Training loss: 0.6870559987177451
Epoch: 76 | Iteration number: [2410/4518] 53% | Training loss: 0.6870510030336895
Epoch: 76 | Iteration number: [2420/4518] 53% | Training loss: 0.6870481127796094
Epoch: 76 | Iteration number: [2430/4518] 53% | Training loss: 0.6870463973700754
Epoch: 76 | Iteration number: [2440/4518] 54% | Training loss: 0.6870446604783418
Epoch: 76 | Iteration number: [2450/4518] 54% | Training loss: 0.6870469781573938
Epoch: 76 | Iteration number: [2460/4518] 54% | Training loss: 0.6870452373008418
Epoch: 76 | Iteration number: [2470/4518] 54% | Training loss: 0.6870440999747288
Epoch: 76 | Iteration number: [2480/4518] 54% | Training loss: 0.6870474966783677
Epoch: 76 | Iteration number: [2490/4518] 55% | Training loss: 0.6870454053562808
Epoch: 76 | Iteration number: [2500/4518] 55% | Training loss: 0.687041834640503
Epoch: 76 | Iteration number: [2510/4518] 55% | Training loss: 0.6870486466533159
Epoch: 76 | Iteration number: [2520/4518] 55% | Training loss: 0.6870443648525647
Epoch: 76 | Iteration number: [2530/4518] 55% | Training loss: 0.6870395378397387
Epoch: 76 | Iteration number: [2540/4518] 56% | Training loss: 0.6870372990219612
Epoch: 76 | Iteration number: [2550/4518] 56% | Training loss: 0.6870337262808108
Epoch: 76 | Iteration number: [2560/4518] 56% | Training loss: 0.6870347936172039
Epoch: 76 | Iteration number: [2570/4518] 56% | Training loss: 0.6870321854775054
Epoch: 76 | Iteration number: [2580/4518] 57% | Training loss: 0.6870332607696222
Epoch: 76 | Iteration number: [2590/4518] 57% | Training loss: 0.6870305286641286
Epoch: 76 | Iteration number: [2600/4518] 57% | Training loss: 0.6870244586238494
Epoch: 76 | Iteration number: [2610/4518] 57% | Training loss: 0.6870234728087867
Epoch: 76 | Iteration number: [2620/4518] 57% | Training loss: 0.6870181381019927
Epoch: 76 | Iteration number: [2630/4518] 58% | Training loss: 0.6870203489813062
Epoch: 76 | Iteration number: [2640/4518] 58% | Training loss: 0.687016738680276
Epoch: 76 | Iteration number: [2650/4518] 58% | Training loss: 0.6870154571083357
Epoch: 76 | Iteration number: [2660/4518] 58% | Training loss: 0.6870200741784017
Epoch: 76 | Iteration number: [2670/4518] 59% | Training loss: 0.687015383565024
Epoch: 76 | Iteration number: [2680/4518] 59% | Training loss: 0.6870168787997161
Epoch: 76 | Iteration number: [2690/4518] 59% | Training loss: 0.68701519567284
Epoch: 76 | Iteration number: [2700/4518] 59% | Training loss: 0.6870177963265667
Epoch: 76 | Iteration number: [2710/4518] 59% | Training loss: 0.6870156076341537
Epoch: 76 | Iteration number: [2720/4518] 60% | Training loss: 0.68701039353276
Epoch: 76 | Iteration number: [2730/4518] 60% | Training loss: 0.6870090564528665
Epoch: 76 | Iteration number: [2740/4518] 60% | Training loss: 0.6870075845152792
Epoch: 76 | Iteration number: [2750/4518] 60% | Training loss: 0.6870059163570404
Epoch: 76 | Iteration number: [2760/4518] 61% | Training loss: 0.687008718908697
Epoch: 76 | Iteration number: [2770/4518] 61% | Training loss: 0.6870111739377253
Epoch: 76 | Iteration number: [2780/4518] 61% | Training loss: 0.6870080395996999
Epoch: 76 | Iteration number: [2790/4518] 61% | Training loss: 0.6870114331817969
Epoch: 76 | Iteration number: [2800/4518] 61% | Training loss: 0.6870095887141568
Epoch: 76 | Iteration number: [2810/4518] 62% | Training loss: 0.6870072985034821
Epoch: 76 | Iteration number: [2820/4518] 62% | Training loss: 0.6870094262750436
Epoch: 76 | Iteration number: [2830/4518] 62% | Training loss: 0.6870084351238008
Epoch: 76 | Iteration number: [2840/4518] 62% | Training loss: 0.6870129901968257
Epoch: 76 | Iteration number: [2850/4518] 63% | Training loss: 0.6870153406628391
Epoch: 76 | Iteration number: [2860/4518] 63% | Training loss: 0.6870103596598952
Epoch: 76 | Iteration number: [2870/4518] 63% | Training loss: 0.687010288674657
Epoch: 76 | Iteration number: [2880/4518] 63% | Training loss: 0.6870093354541394
Epoch: 76 | Iteration number: [2890/4518] 63% | Training loss: 0.687010706502261
Epoch: 76 | Iteration number: [2900/4518] 64% | Training loss: 0.6870131796598434
Epoch: 76 | Iteration number: [2910/4518] 64% | Training loss: 0.6870101061268771
Epoch: 76 | Iteration number: [2920/4518] 64% | Training loss: 0.6870080346726392
Epoch: 76 | Iteration number: [2930/4518] 64% | Training loss: 0.6870140748626136
Epoch: 76 | Iteration number: [2940/4518] 65% | Training loss: 0.6870163716223775
Epoch: 76 | Iteration number: [2950/4518] 65% | Training loss: 0.6870183753361137
Epoch: 76 | Iteration number: [2960/4518] 65% | Training loss: 0.6870186346406872
Epoch: 76 | Iteration number: [2970/4518] 65% | Training loss: 0.6870168852886367
Epoch: 76 | Iteration number: [2980/4518] 65% | Training loss: 0.6870137636893547
Epoch: 76 | Iteration number: [2990/4518] 66% | Training loss: 0.6870125505039126
Epoch: 76 | Iteration number: [3000/4518] 66% | Training loss: 0.6870139846801758
Epoch: 76 | Iteration number: [3010/4518] 66% | Training loss: 0.6870148300134462
Epoch: 76 | Iteration number: [3020/4518] 66% | Training loss: 0.6870140309957479
Epoch: 76 | Iteration number: [3030/4518] 67% | Training loss: 0.6870138577698874
Epoch: 76 | Iteration number: [3040/4518] 67% | Training loss: 0.6870155493875868
Epoch: 76 | Iteration number: [3050/4518] 67% | Training loss: 0.6870136000680142
Epoch: 76 | Iteration number: [3060/4518] 67% | Training loss: 0.687009417991233
Epoch: 76 | Iteration number: [3070/4518] 67% | Training loss: 0.6870129230356372
Epoch: 76 | Iteration number: [3080/4518] 68% | Training loss: 0.687008879401467
Epoch: 76 | Iteration number: [3090/4518] 68% | Training loss: 0.6870068586374178
Epoch: 76 | Iteration number: [3100/4518] 68% | Training loss: 0.6870065269354851
Epoch: 76 | Iteration number: [3110/4518] 68% | Training loss: 0.6870066090220424
Epoch: 76 | Iteration number: [3120/4518] 69% | Training loss: 0.6870078539236998
Epoch: 76 | Iteration number: [3130/4518] 69% | Training loss: 0.6870102056680015
Epoch: 76 | Iteration number: [3140/4518] 69% | Training loss: 0.6870143980167474
Epoch: 76 | Iteration number: [3150/4518] 69% | Training loss: 0.6870102861949375
Epoch: 76 | Iteration number: [3160/4518] 69% | Training loss: 0.6870018962629234
Epoch: 76 | Iteration number: [3170/4518] 70% | Training loss: 0.6870013290775311
Epoch: 76 | Iteration number: [3180/4518] 70% | Training loss: 0.687001569653457
Epoch: 76 | Iteration number: [3190/4518] 70% | Training loss: 0.687004433343403
Epoch: 76 | Iteration number: [3200/4518] 70% | Training loss: 0.6869983864203095
Epoch: 76 | Iteration number: [3210/4518] 71% | Training loss: 0.6869959639240277
Epoch: 76 | Iteration number: [3220/4518] 71% | Training loss: 0.6869982223147931
Epoch: 76 | Iteration number: [3230/4518] 71% | Training loss: 0.6869994730772249
Epoch: 76 | Iteration number: [3240/4518] 71% | Training loss: 0.6869984499098342
Epoch: 76 | Iteration number: [3250/4518] 71% | Training loss: 0.6869973880327664
Epoch: 76 | Iteration number: [3260/4518] 72% | Training loss: 0.6869999084553104
Epoch: 76 | Iteration number: [3270/4518] 72% | Training loss: 0.686998656419439
Epoch: 76 | Iteration number: [3280/4518] 72% | Training loss: 0.68699958008237
Epoch: 76 | Iteration number: [3290/4518] 72% | Training loss: 0.6870036225913143
Epoch: 76 | Iteration number: [3300/4518] 73% | Training loss: 0.6870036322781534
Epoch: 76 | Iteration number: [3310/4518] 73% | Training loss: 0.6870006533187681
Epoch: 76 | Iteration number: [3320/4518] 73% | Training loss: 0.6870020415589034
Epoch: 76 | Iteration number: [3330/4518] 73% | Training loss: 0.6869962435405892
Epoch: 76 | Iteration number: [3340/4518] 73% | Training loss: 0.6869965858802111
Epoch: 76 | Iteration number: [3350/4518] 74% | Training loss: 0.6869976183371758
Epoch: 76 | Iteration number: [3360/4518] 74% | Training loss: 0.6870001172912973
Epoch: 76 | Iteration number: [3370/4518] 74% | Training loss: 0.686993506595006
Epoch: 76 | Iteration number: [3380/4518] 74% | Training loss: 0.6869933625297433
Epoch: 76 | Iteration number: [3390/4518] 75% | Training loss: 0.6869928348732557
Epoch: 76 | Iteration number: [3400/4518] 75% | Training loss: 0.6869969627962393
Epoch: 76 | Iteration number: [3410/4518] 75% | Training loss: 0.686997775178501
Epoch: 76 | Iteration number: [3420/4518] 75% | Training loss: 0.6869975896083821
Epoch: 76 | Iteration number: [3430/4518] 75% | Training loss: 0.6869945971507025
Epoch: 76 | Iteration number: [3440/4518] 76% | Training loss: 0.6869919512854066
Epoch: 76 | Iteration number: [3450/4518] 76% | Training loss: 0.6869929122060969
Epoch: 76 | Iteration number: [3460/4518] 76% | Training loss: 0.6869912150967328
Epoch: 76 | Iteration number: [3470/4518] 76% | Training loss: 0.6869895100937109
Epoch: 76 | Iteration number: [3480/4518] 77% | Training loss: 0.6869883884643686
Epoch: 76 | Iteration number: [3490/4518] 77% | Training loss: 0.6869905486489435
Epoch: 76 | Iteration number: [3500/4518] 77% | Training loss: 0.6869873038700649
Epoch: 76 | Iteration number: [3510/4518] 77% | Training loss: 0.6869888216851444
Epoch: 76 | Iteration number: [3520/4518] 77% | Training loss: 0.6869908455759287
Epoch: 76 | Iteration number: [3530/4518] 78% | Training loss: 0.6869921120807064
Epoch: 76 | Iteration number: [3540/4518] 78% | Training loss: 0.6869939623747842
Epoch: 76 | Iteration number: [3550/4518] 78% | Training loss: 0.6869969796126997
Epoch: 76 | Iteration number: [3560/4518] 78% | Training loss: 0.6869973115874141
Epoch: 76 | Iteration number: [3570/4518] 79% | Training loss: 0.6869951771587884
Epoch: 76 | Iteration number: [3580/4518] 79% | Training loss: 0.6869941085077531
Epoch: 76 | Iteration number: [3590/4518] 79% | Training loss: 0.6869882411611445
Epoch: 76 | Iteration number: [3600/4518] 79% | Training loss: 0.6869885718160206
Epoch: 76 | Iteration number: [3610/4518] 79% | Training loss: 0.6869841041327184
Epoch: 76 | Iteration number: [3620/4518] 80% | Training loss: 0.6869842117662588
Epoch: 76 | Iteration number: [3630/4518] 80% | Training loss: 0.6869829335652764
Epoch: 76 | Iteration number: [3640/4518] 80% | Training loss: 0.6869815309951594
Epoch: 76 | Iteration number: [3650/4518] 80% | Training loss: 0.6869847427165672
Epoch: 76 | Iteration number: [3660/4518] 81% | Training loss: 0.6869826466333671
Epoch: 76 | Iteration number: [3670/4518] 81% | Training loss: 0.6869844861348903
Epoch: 76 | Iteration number: [3680/4518] 81% | Training loss: 0.6869849746965844
Epoch: 76 | Iteration number: [3690/4518] 81% | Training loss: 0.686985135724551
Epoch: 76 | Iteration number: [3700/4518] 81% | Training loss: 0.6869831115168494
Epoch: 76 | Iteration number: [3710/4518] 82% | Training loss: 0.6869827015701973
Epoch: 76 | Iteration number: [3720/4518] 82% | Training loss: 0.6869810695930194
Epoch: 76 | Iteration number: [3730/4518] 82% | Training loss: 0.6869760926703026
Epoch: 76 | Iteration number: [3740/4518] 82% | Training loss: 0.6869774616816464
Epoch: 76 | Iteration number: [3750/4518] 83% | Training loss: 0.6869775924841562
Epoch: 76 | Iteration number: [3760/4518] 83% | Training loss: 0.6869762914136369
Epoch: 76 | Iteration number: [3770/4518] 83% | Training loss: 0.6869742421319693
Epoch: 76 | Iteration number: [3780/4518] 83% | Training loss: 0.6869740497025233
Epoch: 76 | Iteration number: [3790/4518] 83% | Training loss: 0.6869696431549999
Epoch: 76 | Iteration number: [3800/4518] 84% | Training loss: 0.6869672242120692
Epoch: 76 | Iteration number: [3810/4518] 84% | Training loss: 0.6869656098326986
Epoch: 76 | Iteration number: [3820/4518] 84% | Training loss: 0.6869676862243582
Epoch: 76 | Iteration number: [3830/4518] 84% | Training loss: 0.6869628121273947
Epoch: 76 | Iteration number: [3840/4518] 84% | Training loss: 0.6869624618596087
Epoch: 76 | Iteration number: [3850/4518] 85% | Training loss: 0.6869634477658705
Epoch: 76 | Iteration number: [3860/4518] 85% | Training loss: 0.6869599671252651
Epoch: 76 | Iteration number: [3870/4518] 85% | Training loss: 0.6869625648632838
Epoch: 76 | Iteration number: [3880/4518] 85% | Training loss: 0.6869635291628002
Epoch: 76 | Iteration number: [3890/4518] 86% | Training loss: 0.6869615409705204
Epoch: 76 | Iteration number: [3900/4518] 86% | Training loss: 0.6869625749954811
Epoch: 76 | Iteration number: [3910/4518] 86% | Training loss: 0.6869611514651257
Epoch: 76 | Iteration number: [3920/4518] 86% | Training loss: 0.6869615866213429
Epoch: 76 | Iteration number: [3930/4518] 86% | Training loss: 0.6869613131645679
Epoch: 76 | Iteration number: [3940/4518] 87% | Training loss: 0.6869650404314099
Epoch: 76 | Iteration number: [3950/4518] 87% | Training loss: 0.6869660080837298
Epoch: 76 | Iteration number: [3960/4518] 87% | Training loss: 0.6869661705511989
Epoch: 76 | Iteration number: [3970/4518] 87% | Training loss: 0.6869662689472026
Epoch: 76 | Iteration number: [3980/4518] 88% | Training loss: 0.6869668274518832
Epoch: 76 | Iteration number: [3990/4518] 88% | Training loss: 0.6869625682968244
Epoch: 76 | Iteration number: [4000/4518] 88% | Training loss: 0.68695927926898
Epoch: 76 | Iteration number: [4010/4518] 88% | Training loss: 0.6869597521208766
Epoch: 76 | Iteration number: [4020/4518] 88% | Training loss: 0.6869583085994815
Epoch: 76 | Iteration number: [4030/4518] 89% | Training loss: 0.6869585046549292
Epoch: 76 | Iteration number: [4040/4518] 89% | Training loss: 0.6869590797046624
Epoch: 76 | Iteration number: [4050/4518] 89% | Training loss: 0.686957139659811
Epoch: 76 | Iteration number: [4060/4518] 89% | Training loss: 0.6869561597631483
Epoch: 76 | Iteration number: [4070/4518] 90% | Training loss: 0.6869539200234471
Epoch: 76 | Iteration number: [4080/4518] 90% | Training loss: 0.6869537513191794
Epoch: 76 | Iteration number: [4090/4518] 90% | Training loss: 0.6869556496516417
Epoch: 76 | Iteration number: [4100/4518] 90% | Training loss: 0.6869540018860887
Epoch: 76 | Iteration number: [4110/4518] 90% | Training loss: 0.6869526007314668
Epoch: 76 | Iteration number: [4120/4518] 91% | Training loss: 0.6869520281269712
Epoch: 76 | Iteration number: [4130/4518] 91% | Training loss: 0.6869508726833519
Epoch: 76 | Iteration number: [4140/4518] 91% | Training loss: 0.6869497276014752
Epoch: 76 | Iteration number: [4150/4518] 91% | Training loss: 0.6869504868409719
Epoch: 76 | Iteration number: [4160/4518] 92% | Training loss: 0.6869505566616471
Epoch: 76 | Iteration number: [4170/4518] 92% | Training loss: 0.6869505596961335
Epoch: 76 | Iteration number: [4180/4518] 92% | Training loss: 0.6869499700919293
Epoch: 76 | Iteration number: [4190/4518] 92% | Training loss: 0.6869452106924216
Epoch: 76 | Iteration number: [4200/4518] 92% | Training loss: 0.6869447547906921
Epoch: 76 | Iteration number: [4210/4518] 93% | Training loss: 0.6869468532095613
Epoch: 76 | Iteration number: [4220/4518] 93% | Training loss: 0.6869456649250328
Epoch: 76 | Iteration number: [4230/4518] 93% | Training loss: 0.6869460403355583
Epoch: 76 | Iteration number: [4240/4518] 93% | Training loss: 0.6869466276663654
Epoch: 76 | Iteration number: [4250/4518] 94% | Training loss: 0.6869427342414856
Epoch: 76 | Iteration number: [4260/4518] 94% | Training loss: 0.6869418167872048
Epoch: 76 | Iteration number: [4270/4518] 94% | Training loss: 0.6869386572888082
Epoch: 76 | Iteration number: [4280/4518] 94% | Training loss: 0.686937122158358
Epoch: 76 | Iteration number: [4290/4518] 94% | Training loss: 0.6869377321574516
Epoch: 76 | Iteration number: [4300/4518] 95% | Training loss: 0.6869368316822274
Epoch: 76 | Iteration number: [4310/4518] 95% | Training loss: 0.6869325753984208
Epoch: 76 | Iteration number: [4320/4518] 95% | Training loss: 0.686932047718653
Epoch: 76 | Iteration number: [4330/4518] 95% | Training loss: 0.6869342682818618
Epoch: 76 | Iteration number: [4340/4518] 96% | Training loss: 0.6869313660854568
Epoch: 76 | Iteration number: [4350/4518] 96% | Training loss: 0.6869298068819375
Epoch: 76 | Iteration number: [4360/4518] 96% | Training loss: 0.6869316815646417
Epoch: 76 | Iteration number: [4370/4518] 96% | Training loss: 0.6869314202864055
Epoch: 76 | Iteration number: [4380/4518] 96% | Training loss: 0.6869298783475406
Epoch: 76 | Iteration number: [4390/4518] 97% | Training loss: 0.6869283091370229
Epoch: 76 | Iteration number: [4400/4518] 97% | Training loss: 0.6869286012920466
Epoch: 76 | Iteration number: [4410/4518] 97% | Training loss: 0.6869289033402121
Epoch: 76 | Iteration number: [4420/4518] 97% | Training loss: 0.6869263142347336
Epoch: 76 | Iteration number: [4430/4518] 98% | Training loss: 0.6869291324916865
Epoch: 76 | Iteration number: [4440/4518] 98% | Training loss: 0.6869253755823986
Epoch: 76 | Iteration number: [4450/4518] 98% | Training loss: 0.6869276713923123
Epoch: 76 | Iteration number: [4460/4518] 98% | Training loss: 0.6869280129002884
Epoch: 76 | Iteration number: [4470/4518] 98% | Training loss: 0.6869298896933562
Epoch: 76 | Iteration number: [4480/4518] 99% | Training loss: 0.6869322614212121
Epoch: 76 | Iteration number: [4490/4518] 99% | Training loss: 0.686931245244691
Epoch: 76 | Iteration number: [4500/4518] 99% | Training loss: 0.6869334698915481
Epoch: 76 | Iteration number: [4510/4518] 99% | Training loss: 0.6869317875733132

 End of epoch: 76 | Train Loss: 0.6867797025250565 | Training Time: 641 

 End of epoch: 76 | Eval Loss: 0.6899963824116454 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/4518] 0% | Training loss: 0.7577903389930725
Epoch: 77 | Iteration number: [20/4518] 0% | Training loss: 0.7221734613180161
Epoch: 77 | Iteration number: [30/4518] 0% | Training loss: 0.7103812376658122
Epoch: 77 | Iteration number: [40/4518] 0% | Training loss: 0.7047139465808868
Epoch: 77 | Iteration number: [50/4518] 1% | Training loss: 0.7014800238609314
Epoch: 77 | Iteration number: [60/4518] 1% | Training loss: 0.6990031083424886
Epoch: 77 | Iteration number: [70/4518] 1% | Training loss: 0.6973867007664272
Epoch: 77 | Iteration number: [80/4518] 1% | Training loss: 0.6958974249660969
Epoch: 77 | Iteration number: [90/4518] 1% | Training loss: 0.6947820074028439
Epoch: 77 | Iteration number: [100/4518] 2% | Training loss: 0.6940872913599014
Epoch: 77 | Iteration number: [110/4518] 2% | Training loss: 0.6936442012136633
Epoch: 77 | Iteration number: [120/4518] 2% | Training loss: 0.6930794586737951
Epoch: 77 | Iteration number: [130/4518] 2% | Training loss: 0.6926192861336928
Epoch: 77 | Iteration number: [140/4518] 3% | Training loss: 0.6923043847084045
Epoch: 77 | Iteration number: [150/4518] 3% | Training loss: 0.6918766562143962
Epoch: 77 | Iteration number: [160/4518] 3% | Training loss: 0.6915340516716242
Epoch: 77 | Iteration number: [170/4518] 3% | Training loss: 0.6912409512435689
Epoch: 77 | Iteration number: [180/4518] 3% | Training loss: 0.6909466604391734
Epoch: 77 | Iteration number: [190/4518] 4% | Training loss: 0.6906858205795288
Epoch: 77 | Iteration number: [200/4518] 4% | Training loss: 0.6904988101124764
Epoch: 77 | Iteration number: [210/4518] 4% | Training loss: 0.6903030367124648
Epoch: 77 | Iteration number: [220/4518] 4% | Training loss: 0.6901377244429154
Epoch: 77 | Iteration number: [230/4518] 5% | Training loss: 0.6899544493011807
Epoch: 77 | Iteration number: [240/4518] 5% | Training loss: 0.689803550640742
Epoch: 77 | Iteration number: [250/4518] 5% | Training loss: 0.6897048907279968
Epoch: 77 | Iteration number: [260/4518] 5% | Training loss: 0.6895642110934624
Epoch: 77 | Iteration number: [270/4518] 5% | Training loss: 0.6894707955695965
Epoch: 77 | Iteration number: [280/4518] 6% | Training loss: 0.6894174976008279
Epoch: 77 | Iteration number: [290/4518] 6% | Training loss: 0.6893603302281478
Epoch: 77 | Iteration number: [300/4518] 6% | Training loss: 0.6892858374118805
Epoch: 77 | Iteration number: [310/4518] 6% | Training loss: 0.6892034471035003
Epoch: 77 | Iteration number: [320/4518] 7% | Training loss: 0.6891336997970938
Epoch: 77 | Iteration number: [330/4518] 7% | Training loss: 0.6890682057900862
Epoch: 77 | Iteration number: [340/4518] 7% | Training loss: 0.6890203567112193
Epoch: 77 | Iteration number: [350/4518] 7% | Training loss: 0.6889924468312945
Epoch: 77 | Iteration number: [360/4518] 7% | Training loss: 0.6889374554157257
Epoch: 77 | Iteration number: [370/4518] 8% | Training loss: 0.6888814832713153
Epoch: 77 | Iteration number: [380/4518] 8% | Training loss: 0.6888171355975302
Epoch: 77 | Iteration number: [390/4518] 8% | Training loss: 0.6887370117199727
Epoch: 77 | Iteration number: [400/4518] 8% | Training loss: 0.6887023133039475
Epoch: 77 | Iteration number: [410/4518] 9% | Training loss: 0.6886536082116569
Epoch: 77 | Iteration number: [420/4518] 9% | Training loss: 0.6885882915485473
Epoch: 77 | Iteration number: [430/4518] 9% | Training loss: 0.6885295590689016
Epoch: 77 | Iteration number: [440/4518] 9% | Training loss: 0.6885066877711903
Epoch: 77 | Iteration number: [450/4518] 9% | Training loss: 0.6884507114357419
Epoch: 77 | Iteration number: [460/4518] 10% | Training loss: 0.6884013232977494
Epoch: 77 | Iteration number: [470/4518] 10% | Training loss: 0.6883635236861858
Epoch: 77 | Iteration number: [480/4518] 10% | Training loss: 0.6883844950546821
Epoch: 77 | Iteration number: [490/4518] 10% | Training loss: 0.6883543222534413
Epoch: 77 | Iteration number: [500/4518] 11% | Training loss: 0.6883093523979187
Epoch: 77 | Iteration number: [510/4518] 11% | Training loss: 0.6882774882456836
Epoch: 77 | Iteration number: [520/4518] 11% | Training loss: 0.6882446141197132
Epoch: 77 | Iteration number: [530/4518] 11% | Training loss: 0.6882448132308024
Epoch: 77 | Iteration number: [540/4518] 11% | Training loss: 0.6882116558375182
Epoch: 77 | Iteration number: [550/4518] 12% | Training loss: 0.6881752800941467
Epoch: 77 | Iteration number: [560/4518] 12% | Training loss: 0.6881541239363806
Epoch: 77 | Iteration number: [570/4518] 12% | Training loss: 0.6881462291667336
Epoch: 77 | Iteration number: [580/4518] 12% | Training loss: 0.6881330944340804
Epoch: 77 | Iteration number: [590/4518] 13% | Training loss: 0.6881090998649597
Epoch: 77 | Iteration number: [600/4518] 13% | Training loss: 0.6880778839190801
Epoch: 77 | Iteration number: [610/4518] 13% | Training loss: 0.6880649425944344
Epoch: 77 | Iteration number: [620/4518] 13% | Training loss: 0.6880520091902825
Epoch: 77 | Iteration number: [630/4518] 13% | Training loss: 0.6880248222086165
Epoch: 77 | Iteration number: [640/4518] 14% | Training loss: 0.6879898902028799
Epoch: 77 | Iteration number: [650/4518] 14% | Training loss: 0.6879676004556509
Epoch: 77 | Iteration number: [660/4518] 14% | Training loss: 0.6879664887081492
Epoch: 77 | Iteration number: [670/4518] 14% | Training loss: 0.6879466243644259
Epoch: 77 | Iteration number: [680/4518] 15% | Training loss: 0.6879268985460786
Epoch: 77 | Iteration number: [690/4518] 15% | Training loss: 0.6879048226536184
Epoch: 77 | Iteration number: [700/4518] 15% | Training loss: 0.6878820415905543
Epoch: 77 | Iteration number: [710/4518] 15% | Training loss: 0.6878624901805126
Epoch: 77 | Iteration number: [720/4518] 15% | Training loss: 0.6878407210111618
Epoch: 77 | Iteration number: [730/4518] 16% | Training loss: 0.6878095518236291
Epoch: 77 | Iteration number: [740/4518] 16% | Training loss: 0.6877920328765302
Epoch: 77 | Iteration number: [750/4518] 16% | Training loss: 0.6877868208090464
Epoch: 77 | Iteration number: [760/4518] 16% | Training loss: 0.6877887957190213
Epoch: 77 | Iteration number: [770/4518] 17% | Training loss: 0.6877840595585959
Epoch: 77 | Iteration number: [780/4518] 17% | Training loss: 0.6877720320836092
Epoch: 77 | Iteration number: [790/4518] 17% | Training loss: 0.6877460244335706
Epoch: 77 | Iteration number: [800/4518] 17% | Training loss: 0.6877337641268969
Epoch: 77 | Iteration number: [810/4518] 17% | Training loss: 0.6877349233921664
Epoch: 77 | Iteration number: [820/4518] 18% | Training loss: 0.6877265161857372
Epoch: 77 | Iteration number: [830/4518] 18% | Training loss: 0.6877021087939481
Epoch: 77 | Iteration number: [840/4518] 18% | Training loss: 0.6876823603397324
Epoch: 77 | Iteration number: [850/4518] 18% | Training loss: 0.6876589149587294
Epoch: 77 | Iteration number: [860/4518] 19% | Training loss: 0.6876408448052961
Epoch: 77 | Iteration number: [870/4518] 19% | Training loss: 0.6876158172371744
Epoch: 77 | Iteration number: [880/4518] 19% | Training loss: 0.6876188858666203
Epoch: 77 | Iteration number: [890/4518] 19% | Training loss: 0.6875971892576539
Epoch: 77 | Iteration number: [900/4518] 19% | Training loss: 0.6875733372900221
Epoch: 77 | Iteration number: [910/4518] 20% | Training loss: 0.6875526911609775
Epoch: 77 | Iteration number: [920/4518] 20% | Training loss: 0.6875273221212884
Epoch: 77 | Iteration number: [930/4518] 20% | Training loss: 0.68752405066644
Epoch: 77 | Iteration number: [940/4518] 20% | Training loss: 0.6875206414689409
Epoch: 77 | Iteration number: [950/4518] 21% | Training loss: 0.6875038736744931
Epoch: 77 | Iteration number: [960/4518] 21% | Training loss: 0.6875054140885671
Epoch: 77 | Iteration number: [970/4518] 21% | Training loss: 0.6875116483452394
Epoch: 77 | Iteration number: [980/4518] 21% | Training loss: 0.6875050410324214
Epoch: 77 | Iteration number: [990/4518] 21% | Training loss: 0.6875020971201887
Epoch: 77 | Iteration number: [1000/4518] 22% | Training loss: 0.6875002683401108
Epoch: 77 | Iteration number: [1010/4518] 22% | Training loss: 0.6874964118003846
Epoch: 77 | Iteration number: [1020/4518] 22% | Training loss: 0.6874994785762301
Epoch: 77 | Iteration number: [1030/4518] 22% | Training loss: 0.6874984822226959
Epoch: 77 | Iteration number: [1040/4518] 23% | Training loss: 0.687494826144897
Epoch: 77 | Iteration number: [1050/4518] 23% | Training loss: 0.6874778825896127
Epoch: 77 | Iteration number: [1060/4518] 23% | Training loss: 0.687459093219829
Epoch: 77 | Iteration number: [1070/4518] 23% | Training loss: 0.6874630594364951
Epoch: 77 | Iteration number: [1080/4518] 23% | Training loss: 0.6874651707984784
Epoch: 77 | Iteration number: [1090/4518] 24% | Training loss: 0.6874527926291895
Epoch: 77 | Iteration number: [1100/4518] 24% | Training loss: 0.6874357641826977
Epoch: 77 | Iteration number: [1110/4518] 24% | Training loss: 0.6874244600802929
Epoch: 77 | Iteration number: [1120/4518] 24% | Training loss: 0.6874273428427321
Epoch: 77 | Iteration number: [1130/4518] 25% | Training loss: 0.6874223308225649
Epoch: 77 | Iteration number: [1140/4518] 25% | Training loss: 0.6874243560590242
Epoch: 77 | Iteration number: [1150/4518] 25% | Training loss: 0.6874163033651269
Epoch: 77 | Iteration number: [1160/4518] 25% | Training loss: 0.6874147585239904
Epoch: 77 | Iteration number: [1170/4518] 25% | Training loss: 0.6874100346850534
Epoch: 77 | Iteration number: [1180/4518] 26% | Training loss: 0.6873916141057419
Epoch: 77 | Iteration number: [1190/4518] 26% | Training loss: 0.6873857516701481
Epoch: 77 | Iteration number: [1200/4518] 26% | Training loss: 0.6873789700369041
Epoch: 77 | Iteration number: [1210/4518] 26% | Training loss: 0.6873786052889075
Epoch: 77 | Iteration number: [1220/4518] 27% | Training loss: 0.6873756135584879
Epoch: 77 | Iteration number: [1230/4518] 27% | Training loss: 0.687369078543128
Epoch: 77 | Iteration number: [1240/4518] 27% | Training loss: 0.687356430195993
Epoch: 77 | Iteration number: [1250/4518] 27% | Training loss: 0.6873522005558014
Epoch: 77 | Iteration number: [1260/4518] 27% | Training loss: 0.6873439683800652
Epoch: 77 | Iteration number: [1270/4518] 28% | Training loss: 0.68734126184869
Epoch: 77 | Iteration number: [1280/4518] 28% | Training loss: 0.6873317333869636
Epoch: 77 | Iteration number: [1290/4518] 28% | Training loss: 0.6873258909975836
Epoch: 77 | Iteration number: [1300/4518] 28% | Training loss: 0.6873221148435886
Epoch: 77 | Iteration number: [1310/4518] 28% | Training loss: 0.6873136726954511
Epoch: 77 | Iteration number: [1320/4518] 29% | Training loss: 0.6873040143287543
Epoch: 77 | Iteration number: [1330/4518] 29% | Training loss: 0.6872955593399536
Epoch: 77 | Iteration number: [1340/4518] 29% | Training loss: 0.6872873656340499
Epoch: 77 | Iteration number: [1350/4518] 29% | Training loss: 0.6872745617230733
Epoch: 77 | Iteration number: [1360/4518] 30% | Training loss: 0.6872791623806253
Epoch: 77 | Iteration number: [1370/4518] 30% | Training loss: 0.6872767123862775
Epoch: 77 | Iteration number: [1380/4518] 30% | Training loss: 0.6872773074153541
Epoch: 77 | Iteration number: [1390/4518] 30% | Training loss: 0.6872622418746673
Epoch: 77 | Iteration number: [1400/4518] 30% | Training loss: 0.6872590137805258
Epoch: 77 | Iteration number: [1410/4518] 31% | Training loss: 0.6872544486471948
Epoch: 77 | Iteration number: [1420/4518] 31% | Training loss: 0.6872487780073999
Epoch: 77 | Iteration number: [1430/4518] 31% | Training loss: 0.687256101294831
Epoch: 77 | Iteration number: [1440/4518] 31% | Training loss: 0.6872472956776619
Epoch: 77 | Iteration number: [1450/4518] 32% | Training loss: 0.6872418936778759
Epoch: 77 | Iteration number: [1460/4518] 32% | Training loss: 0.6872398029451501
Epoch: 77 | Iteration number: [1470/4518] 32% | Training loss: 0.6872320557938141
Epoch: 77 | Iteration number: [1480/4518] 32% | Training loss: 0.6872338455673811
Epoch: 77 | Iteration number: [1490/4518] 32% | Training loss: 0.6872364437020065
Epoch: 77 | Iteration number: [1500/4518] 33% | Training loss: 0.6872406146526336
Epoch: 77 | Iteration number: [1510/4518] 33% | Training loss: 0.6872315879294414
Epoch: 77 | Iteration number: [1520/4518] 33% | Training loss: 0.6872328117881951
Epoch: 77 | Iteration number: [1530/4518] 33% | Training loss: 0.6872369858174542
Epoch: 77 | Iteration number: [1540/4518] 34% | Training loss: 0.6872359958949027
Epoch: 77 | Iteration number: [1550/4518] 34% | Training loss: 0.6872349969802364
Epoch: 77 | Iteration number: [1560/4518] 34% | Training loss: 0.6872341304253309
Epoch: 77 | Iteration number: [1570/4518] 34% | Training loss: 0.6872332847042448
Epoch: 77 | Iteration number: [1580/4518] 34% | Training loss: 0.6872272900388211
Epoch: 77 | Iteration number: [1590/4518] 35% | Training loss: 0.6872247816256757
Epoch: 77 | Iteration number: [1600/4518] 35% | Training loss: 0.6872330829501152
Epoch: 77 | Iteration number: [1610/4518] 35% | Training loss: 0.6872217370486408
Epoch: 77 | Iteration number: [1620/4518] 35% | Training loss: 0.6872087715216625
Epoch: 77 | Iteration number: [1630/4518] 36% | Training loss: 0.6871966733888615
Epoch: 77 | Iteration number: [1640/4518] 36% | Training loss: 0.6871930062770844
Epoch: 77 | Iteration number: [1650/4518] 36% | Training loss: 0.6871896819634871
Epoch: 77 | Iteration number: [1660/4518] 36% | Training loss: 0.68718064915703
Epoch: 77 | Iteration number: [1670/4518] 36% | Training loss: 0.6871838286608279
Epoch: 77 | Iteration number: [1680/4518] 37% | Training loss: 0.6871692618089063
Epoch: 77 | Iteration number: [1690/4518] 37% | Training loss: 0.6871649214854607
Epoch: 77 | Iteration number: [1700/4518] 37% | Training loss: 0.6871636220637489
Epoch: 77 | Iteration number: [1710/4518] 37% | Training loss: 0.6871604922919246
Epoch: 77 | Iteration number: [1720/4518] 38% | Training loss: 0.6871590024163556
Epoch: 77 | Iteration number: [1730/4518] 38% | Training loss: 0.6871536615266965
Epoch: 77 | Iteration number: [1740/4518] 38% | Training loss: 0.687150634876613
Epoch: 77 | Iteration number: [1750/4518] 38% | Training loss: 0.687147015775953
Epoch: 77 | Iteration number: [1760/4518] 38% | Training loss: 0.6871455350721424
Epoch: 77 | Iteration number: [1770/4518] 39% | Training loss: 0.6871468275280322
Epoch: 77 | Iteration number: [1780/4518] 39% | Training loss: 0.6871408822496285
Epoch: 77 | Iteration number: [1790/4518] 39% | Training loss: 0.6871224058073993
Epoch: 77 | Iteration number: [1800/4518] 39% | Training loss: 0.6871213947402106
Epoch: 77 | Iteration number: [1810/4518] 40% | Training loss: 0.687126321324986
Epoch: 77 | Iteration number: [1820/4518] 40% | Training loss: 0.6871322648865836
Epoch: 77 | Iteration number: [1830/4518] 40% | Training loss: 0.6871337949903936
Epoch: 77 | Iteration number: [1840/4518] 40% | Training loss: 0.687131137109321
Epoch: 77 | Iteration number: [1850/4518] 40% | Training loss: 0.6871270601169484
Epoch: 77 | Iteration number: [1860/4518] 41% | Training loss: 0.6871179031748925
Epoch: 77 | Iteration number: [1870/4518] 41% | Training loss: 0.6871157247433688
Epoch: 77 | Iteration number: [1880/4518] 41% | Training loss: 0.6871176417203659
Epoch: 77 | Iteration number: [1890/4518] 41% | Training loss: 0.6871144094795146
Epoch: 77 | Iteration number: [1900/4518] 42% | Training loss: 0.6871086657047272
Epoch: 77 | Iteration number: [1910/4518] 42% | Training loss: 0.6871067095177336
Epoch: 77 | Iteration number: [1920/4518] 42% | Training loss: 0.6871136957158644
Epoch: 77 | Iteration number: [1930/4518] 42% | Training loss: 0.6871150359588584
Epoch: 77 | Iteration number: [1940/4518] 42% | Training loss: 0.6871129556722247
Epoch: 77 | Iteration number: [1950/4518] 43% | Training loss: 0.6871088524048145
Epoch: 77 | Iteration number: [1960/4518] 43% | Training loss: 0.6871073474385301
Epoch: 77 | Iteration number: [1970/4518] 43% | Training loss: 0.687113509656209
Epoch: 77 | Iteration number: [1980/4518] 43% | Training loss: 0.6871084932426009
Epoch: 77 | Iteration number: [1990/4518] 44% | Training loss: 0.6871041113108247
Epoch: 77 | Iteration number: [2000/4518] 44% | Training loss: 0.6871036475598812
Epoch: 77 | Iteration number: [2010/4518] 44% | Training loss: 0.68710953768213
Epoch: 77 | Iteration number: [2020/4518] 44% | Training loss: 0.687103343629601
Epoch: 77 | Iteration number: [2030/4518] 44% | Training loss: 0.687108011345558
Epoch: 77 | Iteration number: [2040/4518] 45% | Training loss: 0.6871050058042302
Epoch: 77 | Iteration number: [2050/4518] 45% | Training loss: 0.6871073928402691
Epoch: 77 | Iteration number: [2060/4518] 45% | Training loss: 0.6871000490142304
Epoch: 77 | Iteration number: [2070/4518] 45% | Training loss: 0.6870964858554988
Epoch: 77 | Iteration number: [2080/4518] 46% | Training loss: 0.6870983892335342
Epoch: 77 | Iteration number: [2090/4518] 46% | Training loss: 0.6870938232070521
Epoch: 77 | Iteration number: [2100/4518] 46% | Training loss: 0.6870925917228063
Epoch: 77 | Iteration number: [2110/4518] 46% | Training loss: 0.6870849357679557
Epoch: 77 | Iteration number: [2120/4518] 46% | Training loss: 0.6870855889792712
Epoch: 77 | Iteration number: [2130/4518] 47% | Training loss: 0.6870893755709062
Epoch: 77 | Iteration number: [2140/4518] 47% | Training loss: 0.6870932128663375
Epoch: 77 | Iteration number: [2150/4518] 47% | Training loss: 0.6870949256974598
Epoch: 77 | Iteration number: [2160/4518] 47% | Training loss: 0.6870897169466372
Epoch: 77 | Iteration number: [2170/4518] 48% | Training loss: 0.6870834746943092
Epoch: 77 | Iteration number: [2180/4518] 48% | Training loss: 0.6870732725760259
Epoch: 77 | Iteration number: [2190/4518] 48% | Training loss: 0.6870699212159196
Epoch: 77 | Iteration number: [2200/4518] 48% | Training loss: 0.6870718804001809
Epoch: 77 | Iteration number: [2210/4518] 48% | Training loss: 0.6870722965687108
Epoch: 77 | Iteration number: [2220/4518] 49% | Training loss: 0.687069932458637
Epoch: 77 | Iteration number: [2230/4518] 49% | Training loss: 0.6870627732554894
Epoch: 77 | Iteration number: [2240/4518] 49% | Training loss: 0.6870651435639177
Epoch: 77 | Iteration number: [2250/4518] 49% | Training loss: 0.6870610883765751
Epoch: 77 | Iteration number: [2260/4518] 50% | Training loss: 0.6870615247076591
Epoch: 77 | Iteration number: [2270/4518] 50% | Training loss: 0.6870670287357028
Epoch: 77 | Iteration number: [2280/4518] 50% | Training loss: 0.6870640238126119
Epoch: 77 | Iteration number: [2290/4518] 50% | Training loss: 0.6870652354700597
Epoch: 77 | Iteration number: [2300/4518] 50% | Training loss: 0.6870638601157977
Epoch: 77 | Iteration number: [2310/4518] 51% | Training loss: 0.6870662201276589
Epoch: 77 | Iteration number: [2320/4518] 51% | Training loss: 0.6870610149256114
Epoch: 77 | Iteration number: [2330/4518] 51% | Training loss: 0.6870573493032497
Epoch: 77 | Iteration number: [2340/4518] 51% | Training loss: 0.6870561593872869
Epoch: 77 | Iteration number: [2350/4518] 52% | Training loss: 0.6870562000731204
Epoch: 77 | Iteration number: [2360/4518] 52% | Training loss: 0.6870494054283126
Epoch: 77 | Iteration number: [2370/4518] 52% | Training loss: 0.6870455944588416
Epoch: 77 | Iteration number: [2380/4518] 52% | Training loss: 0.6870450406014419
Epoch: 77 | Iteration number: [2390/4518] 52% | Training loss: 0.6870442900448165
Epoch: 77 | Iteration number: [2400/4518] 53% | Training loss: 0.6870420337716738
Epoch: 77 | Iteration number: [2410/4518] 53% | Training loss: 0.6870451037567186
Epoch: 77 | Iteration number: [2420/4518] 53% | Training loss: 0.6870468178071266
Epoch: 77 | Iteration number: [2430/4518] 53% | Training loss: 0.6870445471732214
Epoch: 77 | Iteration number: [2440/4518] 54% | Training loss: 0.6870379472120863
Epoch: 77 | Iteration number: [2450/4518] 54% | Training loss: 0.6870401269805675
Epoch: 77 | Iteration number: [2460/4518] 54% | Training loss: 0.6870385021455889
Epoch: 77 | Iteration number: [2470/4518] 54% | Training loss: 0.6870368263740771
Epoch: 77 | Iteration number: [2480/4518] 54% | Training loss: 0.687034345995034
Epoch: 77 | Iteration number: [2490/4518] 55% | Training loss: 0.6870286300239793
Epoch: 77 | Iteration number: [2500/4518] 55% | Training loss: 0.6870312017202377
Epoch: 77 | Iteration number: [2510/4518] 55% | Training loss: 0.6870283439577338
Epoch: 77 | Iteration number: [2520/4518] 55% | Training loss: 0.6870281719262638
Epoch: 77 | Iteration number: [2530/4518] 55% | Training loss: 0.6870307109101488
Epoch: 77 | Iteration number: [2540/4518] 56% | Training loss: 0.6870298473149773
Epoch: 77 | Iteration number: [2550/4518] 56% | Training loss: 0.6870313247278624
Epoch: 77 | Iteration number: [2560/4518] 56% | Training loss: 0.6870305904885754
Epoch: 77 | Iteration number: [2570/4518] 56% | Training loss: 0.6870306619874235
Epoch: 77 | Iteration number: [2580/4518] 57% | Training loss: 0.6870284718598506
Epoch: 77 | Iteration number: [2590/4518] 57% | Training loss: 0.6870278983272641
Epoch: 77 | Iteration number: [2600/4518] 57% | Training loss: 0.6870276049008737
Epoch: 77 | Iteration number: [2610/4518] 57% | Training loss: 0.6870271967745375
Epoch: 77 | Iteration number: [2620/4518] 57% | Training loss: 0.6870307724439461
Epoch: 77 | Iteration number: [2630/4518] 58% | Training loss: 0.6870289018398908
Epoch: 77 | Iteration number: [2640/4518] 58% | Training loss: 0.687025803395293
Epoch: 77 | Iteration number: [2650/4518] 58% | Training loss: 0.6870244127174593
Epoch: 77 | Iteration number: [2660/4518] 58% | Training loss: 0.6870280743093419
Epoch: 77 | Iteration number: [2670/4518] 59% | Training loss: 0.6870248207885228
Epoch: 77 | Iteration number: [2680/4518] 59% | Training loss: 0.6870255375531182
Epoch: 77 | Iteration number: [2690/4518] 59% | Training loss: 0.6870241581064175
Epoch: 77 | Iteration number: [2700/4518] 59% | Training loss: 0.6870241371349052
Epoch: 77 | Iteration number: [2710/4518] 59% | Training loss: 0.687030633657181
Epoch: 77 | Iteration number: [2720/4518] 60% | Training loss: 0.6870292012086686
Epoch: 77 | Iteration number: [2730/4518] 60% | Training loss: 0.687029816357644
Epoch: 77 | Iteration number: [2740/4518] 60% | Training loss: 0.6870316778438805
Epoch: 77 | Iteration number: [2750/4518] 60% | Training loss: 0.6870303170681
Epoch: 77 | Iteration number: [2760/4518] 61% | Training loss: 0.6870313823007155
Epoch: 77 | Iteration number: [2770/4518] 61% | Training loss: 0.6870328473915692
Epoch: 77 | Iteration number: [2780/4518] 61% | Training loss: 0.687038164430385
Epoch: 77 | Iteration number: [2790/4518] 61% | Training loss: 0.6870361496043461
Epoch: 77 | Iteration number: [2800/4518] 61% | Training loss: 0.6870396505721977
Epoch: 77 | Iteration number: [2810/4518] 62% | Training loss: 0.6870359952127382
Epoch: 77 | Iteration number: [2820/4518] 62% | Training loss: 0.6870415883706816
Epoch: 77 | Iteration number: [2830/4518] 62% | Training loss: 0.6870398851670984
Epoch: 77 | Iteration number: [2840/4518] 62% | Training loss: 0.6870406217768159
Epoch: 77 | Iteration number: [2850/4518] 63% | Training loss: 0.68703672459251
Epoch: 77 | Iteration number: [2860/4518] 63% | Training loss: 0.6870324563938421
Epoch: 77 | Iteration number: [2870/4518] 63% | Training loss: 0.6870344487424511
Epoch: 77 | Iteration number: [2880/4518] 63% | Training loss: 0.6870339985315999
Epoch: 77 | Iteration number: [2890/4518] 63% | Training loss: 0.6870291322779079
Epoch: 77 | Iteration number: [2900/4518] 64% | Training loss: 0.6870239025148852
Epoch: 77 | Iteration number: [2910/4518] 64% | Training loss: 0.6870261146440538
Epoch: 77 | Iteration number: [2920/4518] 64% | Training loss: 0.6870296432547374
Epoch: 77 | Iteration number: [2930/4518] 64% | Training loss: 0.6870266421663069
Epoch: 77 | Iteration number: [2940/4518] 65% | Training loss: 0.6870246761915635
Epoch: 77 | Iteration number: [2950/4518] 65% | Training loss: 0.6870183076292782
Epoch: 77 | Iteration number: [2960/4518] 65% | Training loss: 0.6870132641010993
Epoch: 77 | Iteration number: [2970/4518] 65% | Training loss: 0.6870152362468668
Epoch: 77 | Iteration number: [2980/4518] 65% | Training loss: 0.6870098856671545
Epoch: 77 | Iteration number: [2990/4518] 66% | Training loss: 0.6870099459404132
Epoch: 77 | Iteration number: [3000/4518] 66% | Training loss: 0.6870120095411937
Epoch: 77 | Iteration number: [3010/4518] 66% | Training loss: 0.6870115455202882
Epoch: 77 | Iteration number: [3020/4518] 66% | Training loss: 0.6870111939133398
Epoch: 77 | Iteration number: [3030/4518] 67% | Training loss: 0.6870117579159564
Epoch: 77 | Iteration number: [3040/4518] 67% | Training loss: 0.6870140853092859
Epoch: 77 | Iteration number: [3050/4518] 67% | Training loss: 0.687010880806407
Epoch: 77 | Iteration number: [3060/4518] 67% | Training loss: 0.6870085663850012
Epoch: 77 | Iteration number: [3070/4518] 67% | Training loss: 0.6870093286231597
Epoch: 77 | Iteration number: [3080/4518] 68% | Training loss: 0.6870094324474211
Epoch: 77 | Iteration number: [3090/4518] 68% | Training loss: 0.6870122676142597
Epoch: 77 | Iteration number: [3100/4518] 68% | Training loss: 0.6870100281892284
Epoch: 77 | Iteration number: [3110/4518] 68% | Training loss: 0.6870106380468779
Epoch: 77 | Iteration number: [3120/4518] 69% | Training loss: 0.6870086429592891
Epoch: 77 | Iteration number: [3130/4518] 69% | Training loss: 0.6870039269756585
Epoch: 77 | Iteration number: [3140/4518] 69% | Training loss: 0.6870012003714872
Epoch: 77 | Iteration number: [3150/4518] 69% | Training loss: 0.6870029826391311
Epoch: 77 | Iteration number: [3160/4518] 69% | Training loss: 0.6870035518007942
Epoch: 77 | Iteration number: [3170/4518] 70% | Training loss: 0.6870013815371396
Epoch: 77 | Iteration number: [3180/4518] 70% | Training loss: 0.6869968133714964
Epoch: 77 | Iteration number: [3190/4518] 70% | Training loss: 0.6869954763908745
Epoch: 77 | Iteration number: [3200/4518] 70% | Training loss: 0.6869959931075573
Epoch: 77 | Iteration number: [3210/4518] 71% | Training loss: 0.6869943366429516
Epoch: 77 | Iteration number: [3220/4518] 71% | Training loss: 0.6869898372185156
Epoch: 77 | Iteration number: [3230/4518] 71% | Training loss: 0.6869891559560971
Epoch: 77 | Iteration number: [3240/4518] 71% | Training loss: 0.6869899266663893
Epoch: 77 | Iteration number: [3250/4518] 71% | Training loss: 0.6869906364954435
Epoch: 77 | Iteration number: [3260/4518] 72% | Training loss: 0.6869909544846763
Epoch: 77 | Iteration number: [3270/4518] 72% | Training loss: 0.6869889984619362
Epoch: 77 | Iteration number: [3280/4518] 72% | Training loss: 0.6869886065038239
Epoch: 77 | Iteration number: [3290/4518] 72% | Training loss: 0.6869854950614975
Epoch: 77 | Iteration number: [3300/4518] 73% | Training loss: 0.6869807903875004
Epoch: 77 | Iteration number: [3310/4518] 73% | Training loss: 0.6869794575109223
Epoch: 77 | Iteration number: [3320/4518] 73% | Training loss: 0.6869785817272692
Epoch: 77 | Iteration number: [3330/4518] 73% | Training loss: 0.6869778310751414
Epoch: 77 | Iteration number: [3340/4518] 73% | Training loss: 0.686978005167253
Epoch: 77 | Iteration number: [3350/4518] 74% | Training loss: 0.686978695410401
Epoch: 77 | Iteration number: [3360/4518] 74% | Training loss: 0.6869775068192255
Epoch: 77 | Iteration number: [3370/4518] 74% | Training loss: 0.6869790159453271
Epoch: 77 | Iteration number: [3380/4518] 74% | Training loss: 0.6869778453069326
Epoch: 77 | Iteration number: [3390/4518] 75% | Training loss: 0.6869795789760826
Epoch: 77 | Iteration number: [3400/4518] 75% | Training loss: 0.6869784450005082
Epoch: 77 | Iteration number: [3410/4518] 75% | Training loss: 0.6869819399024035
Epoch: 77 | Iteration number: [3420/4518] 75% | Training loss: 0.6869836471931279
Epoch: 77 | Iteration number: [3430/4518] 75% | Training loss: 0.6869804227491162
Epoch: 77 | Iteration number: [3440/4518] 76% | Training loss: 0.6869813404804053
Epoch: 77 | Iteration number: [3450/4518] 76% | Training loss: 0.6869788207178531
Epoch: 77 | Iteration number: [3460/4518] 76% | Training loss: 0.6869771263675194
Epoch: 77 | Iteration number: [3470/4518] 76% | Training loss: 0.6869774370097289
Epoch: 77 | Iteration number: [3480/4518] 77% | Training loss: 0.6869753050735627
Epoch: 77 | Iteration number: [3490/4518] 77% | Training loss: 0.6869786316139309
Epoch: 77 | Iteration number: [3500/4518] 77% | Training loss: 0.6869733634676252
Epoch: 77 | Iteration number: [3510/4518] 77% | Training loss: 0.6869709484937184
Epoch: 77 | Iteration number: [3520/4518] 77% | Training loss: 0.6869760155000469
Epoch: 77 | Iteration number: [3530/4518] 78% | Training loss: 0.6869739103418572
Epoch: 77 | Iteration number: [3540/4518] 78% | Training loss: 0.6869748786681116
Epoch: 77 | Iteration number: [3550/4518] 78% | Training loss: 0.6869767488896007
Epoch: 77 | Iteration number: [3560/4518] 78% | Training loss: 0.6869758905821972
Epoch: 77 | Iteration number: [3570/4518] 79% | Training loss: 0.6869754279861932
Epoch: 77 | Iteration number: [3580/4518] 79% | Training loss: 0.6869734290591831
Epoch: 77 | Iteration number: [3590/4518] 79% | Training loss: 0.6869716473774657
Epoch: 77 | Iteration number: [3600/4518] 79% | Training loss: 0.6869709660775132
Epoch: 77 | Iteration number: [3610/4518] 79% | Training loss: 0.686969885155765
Epoch: 77 | Iteration number: [3620/4518] 80% | Training loss: 0.6869669617539611
Epoch: 77 | Iteration number: [3630/4518] 80% | Training loss: 0.6869659399690707
Epoch: 77 | Iteration number: [3640/4518] 80% | Training loss: 0.6869657870341134
Epoch: 77 | Iteration number: [3650/4518] 80% | Training loss: 0.6869672906235473
Epoch: 77 | Iteration number: [3660/4518] 81% | Training loss: 0.6869660634649256
Epoch: 77 | Iteration number: [3670/4518] 81% | Training loss: 0.6869602065482646
Epoch: 77 | Iteration number: [3680/4518] 81% | Training loss: 0.6869613768775826
Epoch: 77 | Iteration number: [3690/4518] 81% | Training loss: 0.6869645668723718
Epoch: 77 | Iteration number: [3700/4518] 81% | Training loss: 0.6869631486808931
Epoch: 77 | Iteration number: [3710/4518] 82% | Training loss: 0.6869627792237583
Epoch: 77 | Iteration number: [3720/4518] 82% | Training loss: 0.6869646099946832
Epoch: 77 | Iteration number: [3730/4518] 82% | Training loss: 0.6869646892311106
Epoch: 77 | Iteration number: [3740/4518] 82% | Training loss: 0.6869637510833894
Epoch: 77 | Iteration number: [3750/4518] 83% | Training loss: 0.6869634246190389
Epoch: 77 | Iteration number: [3760/4518] 83% | Training loss: 0.6869604183796872
Epoch: 77 | Iteration number: [3770/4518] 83% | Training loss: 0.6869575459539732
Epoch: 77 | Iteration number: [3780/4518] 83% | Training loss: 0.6869568523591157
Epoch: 77 | Iteration number: [3790/4518] 83% | Training loss: 0.6869549150674513
Epoch: 77 | Iteration number: [3800/4518] 84% | Training loss: 0.6869550200512534
Epoch: 77 | Iteration number: [3810/4518] 84% | Training loss: 0.6869524257076693
Epoch: 77 | Iteration number: [3820/4518] 84% | Training loss: 0.68695277900908
Epoch: 77 | Iteration number: [3830/4518] 84% | Training loss: 0.6869534679554773
Epoch: 77 | Iteration number: [3840/4518] 84% | Training loss: 0.6869551447064927
Epoch: 77 | Iteration number: [3850/4518] 85% | Training loss: 0.6869563911642347
Epoch: 77 | Iteration number: [3860/4518] 85% | Training loss: 0.6869584393315983
Epoch: 77 | Iteration number: [3870/4518] 85% | Training loss: 0.6869611430229758
Epoch: 77 | Iteration number: [3880/4518] 85% | Training loss: 0.6869611957945775
Epoch: 77 | Iteration number: [3890/4518] 86% | Training loss: 0.6869630887606456
Epoch: 77 | Iteration number: [3900/4518] 86% | Training loss: 0.6869596073872004
Epoch: 77 | Iteration number: [3910/4518] 86% | Training loss: 0.6869601664335832
Epoch: 77 | Iteration number: [3920/4518] 86% | Training loss: 0.6869595978180973
Epoch: 77 | Iteration number: [3930/4518] 86% | Training loss: 0.6869583097729671
Epoch: 77 | Iteration number: [3940/4518] 87% | Training loss: 0.6869558716032106
Epoch: 77 | Iteration number: [3950/4518] 87% | Training loss: 0.6869563978080508
Epoch: 77 | Iteration number: [3960/4518] 87% | Training loss: 0.6869569086667263
Epoch: 77 | Iteration number: [3970/4518] 87% | Training loss: 0.6869580891480674
Epoch: 77 | Iteration number: [3980/4518] 88% | Training loss: 0.6869560116799034
Epoch: 77 | Iteration number: [3990/4518] 88% | Training loss: 0.6869537759394873
Epoch: 77 | Iteration number: [4000/4518] 88% | Training loss: 0.6869513595104217
Epoch: 77 | Iteration number: [4010/4518] 88% | Training loss: 0.6869510403892346
Epoch: 77 | Iteration number: [4020/4518] 88% | Training loss: 0.6869505712790276
Epoch: 77 | Iteration number: [4030/4518] 89% | Training loss: 0.6869482059336773
Epoch: 77 | Iteration number: [4040/4518] 89% | Training loss: 0.6869482292839796
Epoch: 77 | Iteration number: [4050/4518] 89% | Training loss: 0.6869461955847563
Epoch: 77 | Iteration number: [4060/4518] 89% | Training loss: 0.6869467123975894
Epoch: 77 | Iteration number: [4070/4518] 90% | Training loss: 0.6869461518247825
Epoch: 77 | Iteration number: [4080/4518] 90% | Training loss: 0.6869484130512266
Epoch: 77 | Iteration number: [4090/4518] 90% | Training loss: 0.6869459178745018
Epoch: 77 | Iteration number: [4100/4518] 90% | Training loss: 0.6869474566709705
Epoch: 77 | Iteration number: [4110/4518] 90% | Training loss: 0.6869492390585061
Epoch: 77 | Iteration number: [4120/4518] 91% | Training loss: 0.6869501000179827
Epoch: 77 | Iteration number: [4130/4518] 91% | Training loss: 0.6869457467993582
Epoch: 77 | Iteration number: [4140/4518] 91% | Training loss: 0.6869434827479763
Epoch: 77 | Iteration number: [4150/4518] 91% | Training loss: 0.686945034768208
Epoch: 77 | Iteration number: [4160/4518] 92% | Training loss: 0.6869420963124587
Epoch: 77 | Iteration number: [4170/4518] 92% | Training loss: 0.6869420630897549
Epoch: 77 | Iteration number: [4180/4518] 92% | Training loss: 0.6869452441850917
Epoch: 77 | Iteration number: [4190/4518] 92% | Training loss: 0.6869443986040311
Epoch: 77 | Iteration number: [4200/4518] 92% | Training loss: 0.6869430485509691
Epoch: 77 | Iteration number: [4210/4518] 93% | Training loss: 0.6869446978716273
Epoch: 77 | Iteration number: [4220/4518] 93% | Training loss: 0.6869461264937975
Epoch: 77 | Iteration number: [4230/4518] 93% | Training loss: 0.6869455875516219
Epoch: 77 | Iteration number: [4240/4518] 93% | Training loss: 0.6869461142370161
Epoch: 77 | Iteration number: [4250/4518] 94% | Training loss: 0.6869440524297602
Epoch: 77 | Iteration number: [4260/4518] 94% | Training loss: 0.6869439520886247
Epoch: 77 | Iteration number: [4270/4518] 94% | Training loss: 0.6869412796698353
Epoch: 77 | Iteration number: [4280/4518] 94% | Training loss: 0.6869397099608573
Epoch: 77 | Iteration number: [4290/4518] 94% | Training loss: 0.6869406913266037
Epoch: 77 | Iteration number: [4300/4518] 95% | Training loss: 0.6869396228152652
Epoch: 77 | Iteration number: [4310/4518] 95% | Training loss: 0.6869404559622231
Epoch: 77 | Iteration number: [4320/4518] 95% | Training loss: 0.6869400752087435
Epoch: 77 | Iteration number: [4330/4518] 95% | Training loss: 0.6869380069384674
Epoch: 77 | Iteration number: [4340/4518] 96% | Training loss: 0.6869379777375454
Epoch: 77 | Iteration number: [4350/4518] 96% | Training loss: 0.6869391604949688
Epoch: 77 | Iteration number: [4360/4518] 96% | Training loss: 0.6869368093002827
Epoch: 77 | Iteration number: [4370/4518] 96% | Training loss: 0.6869360645930336
Epoch: 77 | Iteration number: [4380/4518] 96% | Training loss: 0.6869344728450253
Epoch: 77 | Iteration number: [4390/4518] 97% | Training loss: 0.6869354598614512
Epoch: 77 | Iteration number: [4400/4518] 97% | Training loss: 0.6869335556843064
Epoch: 77 | Iteration number: [4410/4518] 97% | Training loss: 0.6869309227077328
Epoch: 77 | Iteration number: [4420/4518] 97% | Training loss: 0.6869285057842461
Epoch: 77 | Iteration number: [4430/4518] 98% | Training loss: 0.686927344607984
Epoch: 77 | Iteration number: [4440/4518] 98% | Training loss: 0.6869236908785932
Epoch: 77 | Iteration number: [4450/4518] 98% | Training loss: 0.6869254278868772
Epoch: 77 | Iteration number: [4460/4518] 98% | Training loss: 0.6869246491936825
Epoch: 77 | Iteration number: [4470/4518] 98% | Training loss: 0.6869243812507698
Epoch: 77 | Iteration number: [4480/4518] 99% | Training loss: 0.686923760481711
Epoch: 77 | Iteration number: [4490/4518] 99% | Training loss: 0.6869258753839208
Epoch: 77 | Iteration number: [4500/4518] 99% | Training loss: 0.6869276413122813
Epoch: 77 | Iteration number: [4510/4518] 99% | Training loss: 0.6869272295625141

 End of epoch: 77 | Train Loss: 0.6867726078308911 | Training Time: 640 

 End of epoch: 77 | Eval Loss: 0.689976189817701 | Evaluating Time: 16 
Epoch: 78 | Iteration number: [10/4518] 0% | Training loss: 0.7552969813346863
Epoch: 78 | Iteration number: [20/4518] 0% | Training loss: 0.7212209969758987
Epoch: 78 | Iteration number: [30/4518] 0% | Training loss: 0.7096984545389812
Epoch: 78 | Iteration number: [40/4518] 0% | Training loss: 0.7039835885167122
Epoch: 78 | Iteration number: [50/4518] 1% | Training loss: 0.7005572056770325
Epoch: 78 | Iteration number: [60/4518] 1% | Training loss: 0.6982196609179179
Epoch: 78 | Iteration number: [70/4518] 1% | Training loss: 0.6962162205151149
Epoch: 78 | Iteration number: [80/4518] 1% | Training loss: 0.6950727544724942
Epoch: 78 | Iteration number: [90/4518] 1% | Training loss: 0.6941499835915036
Epoch: 78 | Iteration number: [100/4518] 2% | Training loss: 0.6934424275159836
Epoch: 78 | Iteration number: [110/4518] 2% | Training loss: 0.6928312729705464
Epoch: 78 | Iteration number: [120/4518] 2% | Training loss: 0.6923066402475039
Epoch: 78 | Iteration number: [130/4518] 2% | Training loss: 0.691801852446336
Epoch: 78 | Iteration number: [140/4518] 3% | Training loss: 0.6913611216204507
Epoch: 78 | Iteration number: [150/4518] 3% | Training loss: 0.691096289952596
Epoch: 78 | Iteration number: [160/4518] 3% | Training loss: 0.6908057417720557
Epoch: 78 | Iteration number: [170/4518] 3% | Training loss: 0.6905097561724046
Epoch: 78 | Iteration number: [180/4518] 3% | Training loss: 0.6903546300199297
Epoch: 78 | Iteration number: [190/4518] 4% | Training loss: 0.6901923377262918
Epoch: 78 | Iteration number: [200/4518] 4% | Training loss: 0.6899882656335831
Epoch: 78 | Iteration number: [210/4518] 4% | Training loss: 0.6898521542549133
Epoch: 78 | Iteration number: [220/4518] 4% | Training loss: 0.6896711178801277
Epoch: 78 | Iteration number: [230/4518] 5% | Training loss: 0.6895519609036653
Epoch: 78 | Iteration number: [240/4518] 5% | Training loss: 0.6895176820456982
Epoch: 78 | Iteration number: [250/4518] 5% | Training loss: 0.6893626267910004
Epoch: 78 | Iteration number: [260/4518] 5% | Training loss: 0.689272202207492
Epoch: 78 | Iteration number: [270/4518] 5% | Training loss: 0.689236585299174
Epoch: 78 | Iteration number: [280/4518] 6% | Training loss: 0.6891057636056628
Epoch: 78 | Iteration number: [290/4518] 6% | Training loss: 0.689026500644355
Epoch: 78 | Iteration number: [300/4518] 6% | Training loss: 0.6889254605770111
Epoch: 78 | Iteration number: [310/4518] 6% | Training loss: 0.688878119953217
Epoch: 78 | Iteration number: [320/4518] 7% | Training loss: 0.6888145308941602
Epoch: 78 | Iteration number: [330/4518] 7% | Training loss: 0.6887343375971823
Epoch: 78 | Iteration number: [340/4518] 7% | Training loss: 0.6887190201703239
Epoch: 78 | Iteration number: [350/4518] 7% | Training loss: 0.6886475554534367
Epoch: 78 | Iteration number: [360/4518] 7% | Training loss: 0.6886014027727975
Epoch: 78 | Iteration number: [370/4518] 8% | Training loss: 0.6885596603960604
Epoch: 78 | Iteration number: [380/4518] 8% | Training loss: 0.6884874114864751
Epoch: 78 | Iteration number: [390/4518] 8% | Training loss: 0.6884511888027192
Epoch: 78 | Iteration number: [400/4518] 8% | Training loss: 0.6883896797895431
Epoch: 78 | Iteration number: [410/4518] 9% | Training loss: 0.6883379955117296
Epoch: 78 | Iteration number: [420/4518] 9% | Training loss: 0.6883122315009434
Epoch: 78 | Iteration number: [430/4518] 9% | Training loss: 0.68823066533998
Epoch: 78 | Iteration number: [440/4518] 9% | Training loss: 0.6882110939784484
Epoch: 78 | Iteration number: [450/4518] 9% | Training loss: 0.6881765834490459
Epoch: 78 | Iteration number: [460/4518] 10% | Training loss: 0.6881489123987115
Epoch: 78 | Iteration number: [470/4518] 10% | Training loss: 0.688104496103652
Epoch: 78 | Iteration number: [480/4518] 10% | Training loss: 0.6880747233827909
Epoch: 78 | Iteration number: [490/4518] 10% | Training loss: 0.6880181314993877
Epoch: 78 | Iteration number: [500/4518] 11% | Training loss: 0.688018424630165
Epoch: 78 | Iteration number: [510/4518] 11% | Training loss: 0.6880046355958078
Epoch: 78 | Iteration number: [520/4518] 11% | Training loss: 0.6879877437765781
Epoch: 78 | Iteration number: [530/4518] 11% | Training loss: 0.6879655703058782
Epoch: 78 | Iteration number: [540/4518] 11% | Training loss: 0.6879273337346536
Epoch: 78 | Iteration number: [550/4518] 12% | Training loss: 0.6878949668190696
Epoch: 78 | Iteration number: [560/4518] 12% | Training loss: 0.6878759082938943
Epoch: 78 | Iteration number: [570/4518] 12% | Training loss: 0.6878879146617756
Epoch: 78 | Iteration number: [580/4518] 12% | Training loss: 0.6878498754624662
Epoch: 78 | Iteration number: [590/4518] 13% | Training loss: 0.6878338317749864
Epoch: 78 | Iteration number: [600/4518] 13% | Training loss: 0.6878178221980731
Epoch: 78 | Iteration number: [610/4518] 13% | Training loss: 0.6878078660026925
Epoch: 78 | Iteration number: [620/4518] 13% | Training loss: 0.6877734244831146
Epoch: 78 | Iteration number: [630/4518] 13% | Training loss: 0.6877562741438548
Epoch: 78 | Iteration number: [640/4518] 14% | Training loss: 0.6877254259772598
Epoch: 78 | Iteration number: [650/4518] 14% | Training loss: 0.6877230403056511
Epoch: 78 | Iteration number: [660/4518] 14% | Training loss: 0.6877143932111336
Epoch: 78 | Iteration number: [670/4518] 14% | Training loss: 0.6877044769365396
Epoch: 78 | Iteration number: [680/4518] 15% | Training loss: 0.6877018532332252
Epoch: 78 | Iteration number: [690/4518] 15% | Training loss: 0.6876994101033694
Epoch: 78 | Iteration number: [700/4518] 15% | Training loss: 0.6876818411690848
Epoch: 78 | Iteration number: [710/4518] 15% | Training loss: 0.6876747138903174
Epoch: 78 | Iteration number: [720/4518] 15% | Training loss: 0.6876862421631813
Epoch: 78 | Iteration number: [730/4518] 16% | Training loss: 0.6876691623093331
Epoch: 78 | Iteration number: [740/4518] 16% | Training loss: 0.6876445030038422
Epoch: 78 | Iteration number: [750/4518] 16% | Training loss: 0.6876131389141082
Epoch: 78 | Iteration number: [760/4518] 16% | Training loss: 0.6876007943561203
Epoch: 78 | Iteration number: [770/4518] 17% | Training loss: 0.6876185040195267
Epoch: 78 | Iteration number: [780/4518] 17% | Training loss: 0.6876072244766431
Epoch: 78 | Iteration number: [790/4518] 17% | Training loss: 0.6876085417934611
Epoch: 78 | Iteration number: [800/4518] 17% | Training loss: 0.6875957669317723
Epoch: 78 | Iteration number: [810/4518] 17% | Training loss: 0.6875747634304894
Epoch: 78 | Iteration number: [820/4518] 18% | Training loss: 0.6875728728567682
Epoch: 78 | Iteration number: [830/4518] 18% | Training loss: 0.6875738312681037
Epoch: 78 | Iteration number: [840/4518] 18% | Training loss: 0.687577772850082
Epoch: 78 | Iteration number: [850/4518] 18% | Training loss: 0.6875570549684412
Epoch: 78 | Iteration number: [860/4518] 19% | Training loss: 0.6875672194846841
Epoch: 78 | Iteration number: [870/4518] 19% | Training loss: 0.6875535266152744
Epoch: 78 | Iteration number: [880/4518] 19% | Training loss: 0.6875478459352796
Epoch: 78 | Iteration number: [890/4518] 19% | Training loss: 0.6875386675422112
Epoch: 78 | Iteration number: [900/4518] 19% | Training loss: 0.6875258841117223
Epoch: 78 | Iteration number: [910/4518] 20% | Training loss: 0.6874909674073314
Epoch: 78 | Iteration number: [920/4518] 20% | Training loss: 0.6874899439837622
Epoch: 78 | Iteration number: [930/4518] 20% | Training loss: 0.6874853994256707
Epoch: 78 | Iteration number: [940/4518] 20% | Training loss: 0.6874734418823364
Epoch: 78 | Iteration number: [950/4518] 21% | Training loss: 0.6874532535829042
Epoch: 78 | Iteration number: [960/4518] 21% | Training loss: 0.6874522579212984
Epoch: 78 | Iteration number: [970/4518] 21% | Training loss: 0.6874335347377147
Epoch: 78 | Iteration number: [980/4518] 21% | Training loss: 0.6874203527460293
Epoch: 78 | Iteration number: [990/4518] 21% | Training loss: 0.6874153077000319
Epoch: 78 | Iteration number: [1000/4518] 22% | Training loss: 0.6874151291847229
Epoch: 78 | Iteration number: [1010/4518] 22% | Training loss: 0.6874031508913134
Epoch: 78 | Iteration number: [1020/4518] 22% | Training loss: 0.6874004878834182
Epoch: 78 | Iteration number: [1030/4518] 22% | Training loss: 0.6874039137826382
Epoch: 78 | Iteration number: [1040/4518] 23% | Training loss: 0.6874017228300755
Epoch: 78 | Iteration number: [1050/4518] 23% | Training loss: 0.6874021862802051
Epoch: 78 | Iteration number: [1060/4518] 23% | Training loss: 0.6873928491237029
Epoch: 78 | Iteration number: [1070/4518] 23% | Training loss: 0.6873731156375921
Epoch: 78 | Iteration number: [1080/4518] 23% | Training loss: 0.6873716745663572
Epoch: 78 | Iteration number: [1090/4518] 24% | Training loss: 0.6873694954115317
Epoch: 78 | Iteration number: [1100/4518] 24% | Training loss: 0.687370663935488
Epoch: 78 | Iteration number: [1110/4518] 24% | Training loss: 0.6873654962122977
Epoch: 78 | Iteration number: [1120/4518] 24% | Training loss: 0.6873552650745426
Epoch: 78 | Iteration number: [1130/4518] 25% | Training loss: 0.6873431339728093
Epoch: 78 | Iteration number: [1140/4518] 25% | Training loss: 0.687336009845399
Epoch: 78 | Iteration number: [1150/4518] 25% | Training loss: 0.687331890852555
Epoch: 78 | Iteration number: [1160/4518] 25% | Training loss: 0.6873331049392963
Epoch: 78 | Iteration number: [1170/4518] 25% | Training loss: 0.6873298030123751
Epoch: 78 | Iteration number: [1180/4518] 26% | Training loss: 0.6873325344869646
Epoch: 78 | Iteration number: [1190/4518] 26% | Training loss: 0.6873185295517705
Epoch: 78 | Iteration number: [1200/4518] 26% | Training loss: 0.6873102334638437
Epoch: 78 | Iteration number: [1210/4518] 26% | Training loss: 0.6873022532167513
Epoch: 78 | Iteration number: [1220/4518] 27% | Training loss: 0.6873037902058148
Epoch: 78 | Iteration number: [1230/4518] 27% | Training loss: 0.6872904836646909
Epoch: 78 | Iteration number: [1240/4518] 27% | Training loss: 0.6872924864772827
Epoch: 78 | Iteration number: [1250/4518] 27% | Training loss: 0.6872857567310333
Epoch: 78 | Iteration number: [1260/4518] 27% | Training loss: 0.6872728464149294
Epoch: 78 | Iteration number: [1270/4518] 28% | Training loss: 0.6872791466750497
Epoch: 78 | Iteration number: [1280/4518] 28% | Training loss: 0.6872788161505013
Epoch: 78 | Iteration number: [1290/4518] 28% | Training loss: 0.6872767017793285
Epoch: 78 | Iteration number: [1300/4518] 28% | Training loss: 0.6872733877255366
Epoch: 78 | Iteration number: [1310/4518] 28% | Training loss: 0.6872714979502991
Epoch: 78 | Iteration number: [1320/4518] 29% | Training loss: 0.6872678594607295
Epoch: 78 | Iteration number: [1330/4518] 29% | Training loss: 0.6872628007616316
Epoch: 78 | Iteration number: [1340/4518] 29% | Training loss: 0.6872604262472978
Epoch: 78 | Iteration number: [1350/4518] 29% | Training loss: 0.6872524401876662
Epoch: 78 | Iteration number: [1360/4518] 30% | Training loss: 0.687251125013127
Epoch: 78 | Iteration number: [1370/4518] 30% | Training loss: 0.6872451476372071
Epoch: 78 | Iteration number: [1380/4518] 30% | Training loss: 0.6872402316850165
Epoch: 78 | Iteration number: [1390/4518] 30% | Training loss: 0.6872374682546519
Epoch: 78 | Iteration number: [1400/4518] 30% | Training loss: 0.6872314514006888
Epoch: 78 | Iteration number: [1410/4518] 31% | Training loss: 0.687221929240734
Epoch: 78 | Iteration number: [1420/4518] 31% | Training loss: 0.6872139267098736
Epoch: 78 | Iteration number: [1430/4518] 31% | Training loss: 0.687207097815467
Epoch: 78 | Iteration number: [1440/4518] 31% | Training loss: 0.6872030924591753
Epoch: 78 | Iteration number: [1450/4518] 32% | Training loss: 0.6872032291313698
Epoch: 78 | Iteration number: [1460/4518] 32% | Training loss: 0.6872007580244378
Epoch: 78 | Iteration number: [1470/4518] 32% | Training loss: 0.6871883111746133
Epoch: 78 | Iteration number: [1480/4518] 32% | Training loss: 0.6871755102196255
Epoch: 78 | Iteration number: [1490/4518] 32% | Training loss: 0.6871763493790722
Epoch: 78 | Iteration number: [1500/4518] 33% | Training loss: 0.6871686826944351
Epoch: 78 | Iteration number: [1510/4518] 33% | Training loss: 0.687170753021114
Epoch: 78 | Iteration number: [1520/4518] 33% | Training loss: 0.6871707466872115
Epoch: 78 | Iteration number: [1530/4518] 33% | Training loss: 0.6871687541600147
Epoch: 78 | Iteration number: [1540/4518] 34% | Training loss: 0.687161383187616
Epoch: 78 | Iteration number: [1550/4518] 34% | Training loss: 0.6871621879839128
Epoch: 78 | Iteration number: [1560/4518] 34% | Training loss: 0.687165111876451
Epoch: 78 | Iteration number: [1570/4518] 34% | Training loss: 0.6871661907548358
Epoch: 78 | Iteration number: [1580/4518] 34% | Training loss: 0.6871669470132151
Epoch: 78 | Iteration number: [1590/4518] 35% | Training loss: 0.6871682767598134
Epoch: 78 | Iteration number: [1600/4518] 35% | Training loss: 0.6871652331203222
Epoch: 78 | Iteration number: [1610/4518] 35% | Training loss: 0.6871637479488895
Epoch: 78 | Iteration number: [1620/4518] 35% | Training loss: 0.6871539232171612
Epoch: 78 | Iteration number: [1630/4518] 36% | Training loss: 0.6871504687092787
Epoch: 78 | Iteration number: [1640/4518] 36% | Training loss: 0.6871488529371053
Epoch: 78 | Iteration number: [1650/4518] 36% | Training loss: 0.6871533520293959
Epoch: 78 | Iteration number: [1660/4518] 36% | Training loss: 0.6871518866843488
Epoch: 78 | Iteration number: [1670/4518] 36% | Training loss: 0.6871455450971683
Epoch: 78 | Iteration number: [1680/4518] 37% | Training loss: 0.6871492507911864
Epoch: 78 | Iteration number: [1690/4518] 37% | Training loss: 0.6871491589137083
Epoch: 78 | Iteration number: [1700/4518] 37% | Training loss: 0.6871432239869062
Epoch: 78 | Iteration number: [1710/4518] 37% | Training loss: 0.6871389203949978
Epoch: 78 | Iteration number: [1720/4518] 38% | Training loss: 0.6871425213162289
Epoch: 78 | Iteration number: [1730/4518] 38% | Training loss: 0.6871337125756148
Epoch: 78 | Iteration number: [1740/4518] 38% | Training loss: 0.6871290549122054
Epoch: 78 | Iteration number: [1750/4518] 38% | Training loss: 0.6871195811544146
Epoch: 78 | Iteration number: [1760/4518] 38% | Training loss: 0.6871114057234743
Epoch: 78 | Iteration number: [1770/4518] 39% | Training loss: 0.6871059892204522
Epoch: 78 | Iteration number: [1780/4518] 39% | Training loss: 0.6871037985166807
Epoch: 78 | Iteration number: [1790/4518] 39% | Training loss: 0.687106455637756
Epoch: 78 | Iteration number: [1800/4518] 39% | Training loss: 0.6871027062336604
Epoch: 78 | Iteration number: [1810/4518] 40% | Training loss: 0.6871011858486997
Epoch: 78 | Iteration number: [1820/4518] 40% | Training loss: 0.6870970174833968
Epoch: 78 | Iteration number: [1830/4518] 40% | Training loss: 0.6870832813242094
Epoch: 78 | Iteration number: [1840/4518] 40% | Training loss: 0.6870784008308597
Epoch: 78 | Iteration number: [1850/4518] 40% | Training loss: 0.6870760886733597
Epoch: 78 | Iteration number: [1860/4518] 41% | Training loss: 0.6870767795911399
Epoch: 78 | Iteration number: [1870/4518] 41% | Training loss: 0.6870727809673962
Epoch: 78 | Iteration number: [1880/4518] 41% | Training loss: 0.6870824944782764
Epoch: 78 | Iteration number: [1890/4518] 41% | Training loss: 0.6870746315787079
Epoch: 78 | Iteration number: [1900/4518] 42% | Training loss: 0.6870817006889143
Epoch: 78 | Iteration number: [1910/4518] 42% | Training loss: 0.6870819807676745
Epoch: 78 | Iteration number: [1920/4518] 42% | Training loss: 0.687076669652015
Epoch: 78 | Iteration number: [1930/4518] 42% | Training loss: 0.6870756473874798
Epoch: 78 | Iteration number: [1940/4518] 42% | Training loss: 0.6870705516989698
Epoch: 78 | Iteration number: [1950/4518] 43% | Training loss: 0.6870777956644694
Epoch: 78 | Iteration number: [1960/4518] 43% | Training loss: 0.6870755649038723
Epoch: 78 | Iteration number: [1970/4518] 43% | Training loss: 0.6870732320444233
Epoch: 78 | Iteration number: [1980/4518] 43% | Training loss: 0.6870658866684847
Epoch: 78 | Iteration number: [1990/4518] 44% | Training loss: 0.6870626877001182
Epoch: 78 | Iteration number: [2000/4518] 44% | Training loss: 0.6870641197860241
Epoch: 78 | Iteration number: [2010/4518] 44% | Training loss: 0.6870653692169569
Epoch: 78 | Iteration number: [2020/4518] 44% | Training loss: 0.6870657971589872
Epoch: 78 | Iteration number: [2030/4518] 44% | Training loss: 0.6870629674401777
Epoch: 78 | Iteration number: [2040/4518] 45% | Training loss: 0.687060628509989
Epoch: 78 | Iteration number: [2050/4518] 45% | Training loss: 0.687059186551629
Epoch: 78 | Iteration number: [2060/4518] 45% | Training loss: 0.6870583999504163
Epoch: 78 | Iteration number: [2070/4518] 45% | Training loss: 0.6870572446625014
Epoch: 78 | Iteration number: [2080/4518] 46% | Training loss: 0.6870562291202637
Epoch: 78 | Iteration number: [2090/4518] 46% | Training loss: 0.6870561034200294
Epoch: 78 | Iteration number: [2100/4518] 46% | Training loss: 0.6870558071420306
Epoch: 78 | Iteration number: [2110/4518] 46% | Training loss: 0.6870521616879233
Epoch: 78 | Iteration number: [2120/4518] 46% | Training loss: 0.6870594584998094
Epoch: 78 | Iteration number: [2130/4518] 47% | Training loss: 0.6870602770310612
Epoch: 78 | Iteration number: [2140/4518] 47% | Training loss: 0.6870574163777806
Epoch: 78 | Iteration number: [2150/4518] 47% | Training loss: 0.6870631039142608
Epoch: 78 | Iteration number: [2160/4518] 47% | Training loss: 0.6870608232915402
Epoch: 78 | Iteration number: [2170/4518] 48% | Training loss: 0.687057555326119
Epoch: 78 | Iteration number: [2180/4518] 48% | Training loss: 0.6870605928908794
Epoch: 78 | Iteration number: [2190/4518] 48% | Training loss: 0.6870595354739933
Epoch: 78 | Iteration number: [2200/4518] 48% | Training loss: 0.6870587360587987
Epoch: 78 | Iteration number: [2210/4518] 48% | Training loss: 0.6870593688606677
Epoch: 78 | Iteration number: [2220/4518] 49% | Training loss: 0.6870538055359781
Epoch: 78 | Iteration number: [2230/4518] 49% | Training loss: 0.6870528442977255
Epoch: 78 | Iteration number: [2240/4518] 49% | Training loss: 0.6870512534997293
Epoch: 78 | Iteration number: [2250/4518] 49% | Training loss: 0.6870514430999756
Epoch: 78 | Iteration number: [2260/4518] 50% | Training loss: 0.6870543779525081
Epoch: 78 | Iteration number: [2270/4518] 50% | Training loss: 0.6870540684540366
Epoch: 78 | Iteration number: [2280/4518] 50% | Training loss: 0.6870551523670816
Epoch: 78 | Iteration number: [2290/4518] 50% | Training loss: 0.6870523624284819
Epoch: 78 | Iteration number: [2300/4518] 50% | Training loss: 0.6870441093392994
Epoch: 78 | Iteration number: [2310/4518] 51% | Training loss: 0.6870372500254478
Epoch: 78 | Iteration number: [2320/4518] 51% | Training loss: 0.6870363319999185
Epoch: 78 | Iteration number: [2330/4518] 51% | Training loss: 0.6870399959609232
Epoch: 78 | Iteration number: [2340/4518] 51% | Training loss: 0.6870406565248457
Epoch: 78 | Iteration number: [2350/4518] 52% | Training loss: 0.6870389943680865
Epoch: 78 | Iteration number: [2360/4518] 52% | Training loss: 0.6870349795889046
Epoch: 78 | Iteration number: [2370/4518] 52% | Training loss: 0.6870346058521593
Epoch: 78 | Iteration number: [2380/4518] 52% | Training loss: 0.6870341254382574
Epoch: 78 | Iteration number: [2390/4518] 52% | Training loss: 0.6870343847005437
Epoch: 78 | Iteration number: [2400/4518] 53% | Training loss: 0.6870385528852542
Epoch: 78 | Iteration number: [2410/4518] 53% | Training loss: 0.6870346995062848
Epoch: 78 | Iteration number: [2420/4518] 53% | Training loss: 0.6870344943005191
Epoch: 78 | Iteration number: [2430/4518] 53% | Training loss: 0.687035934547338
Epoch: 78 | Iteration number: [2440/4518] 54% | Training loss: 0.6870361667431769
Epoch: 78 | Iteration number: [2450/4518] 54% | Training loss: 0.6870306347097669
Epoch: 78 | Iteration number: [2460/4518] 54% | Training loss: 0.6870340522227248
Epoch: 78 | Iteration number: [2470/4518] 54% | Training loss: 0.6870385813085657
Epoch: 78 | Iteration number: [2480/4518] 54% | Training loss: 0.6870315822382127
Epoch: 78 | Iteration number: [2490/4518] 55% | Training loss: 0.6870360532438898
Epoch: 78 | Iteration number: [2500/4518] 55% | Training loss: 0.687033747291565
Epoch: 78 | Iteration number: [2510/4518] 55% | Training loss: 0.6870358750877152
Epoch: 78 | Iteration number: [2520/4518] 55% | Training loss: 0.6870345560094667
Epoch: 78 | Iteration number: [2530/4518] 55% | Training loss: 0.6870318089549249
Epoch: 78 | Iteration number: [2540/4518] 56% | Training loss: 0.6870253225480477
Epoch: 78 | Iteration number: [2550/4518] 56% | Training loss: 0.6870233896199395
Epoch: 78 | Iteration number: [2560/4518] 56% | Training loss: 0.6870243493467569
Epoch: 78 | Iteration number: [2570/4518] 56% | Training loss: 0.687024834763679
Epoch: 78 | Iteration number: [2580/4518] 57% | Training loss: 0.6870235303113627
Epoch: 78 | Iteration number: [2590/4518] 57% | Training loss: 0.687023254504075
Epoch: 78 | Iteration number: [2600/4518] 57% | Training loss: 0.6870202947809146
Epoch: 78 | Iteration number: [2610/4518] 57% | Training loss: 0.6870174427142088
Epoch: 78 | Iteration number: [2620/4518] 57% | Training loss: 0.687017481131408
Epoch: 78 | Iteration number: [2630/4518] 58% | Training loss: 0.68702096238789
Epoch: 78 | Iteration number: [2640/4518] 58% | Training loss: 0.6870238498304829
Epoch: 78 | Iteration number: [2650/4518] 58% | Training loss: 0.6870288303888069
Epoch: 78 | Iteration number: [2660/4518] 58% | Training loss: 0.6870287230812517
Epoch: 78 | Iteration number: [2670/4518] 59% | Training loss: 0.6870233516568102
Epoch: 78 | Iteration number: [2680/4518] 59% | Training loss: 0.6870228848795392
Epoch: 78 | Iteration number: [2690/4518] 59% | Training loss: 0.6870236163688859
Epoch: 78 | Iteration number: [2700/4518] 59% | Training loss: 0.6870210042264726
Epoch: 78 | Iteration number: [2710/4518] 59% | Training loss: 0.6870233383565811
Epoch: 78 | Iteration number: [2720/4518] 60% | Training loss: 0.6870249678764273
Epoch: 78 | Iteration number: [2730/4518] 60% | Training loss: 0.6870251152978275
Epoch: 78 | Iteration number: [2740/4518] 60% | Training loss: 0.6870279051744155
Epoch: 78 | Iteration number: [2750/4518] 60% | Training loss: 0.6870242237177762
Epoch: 78 | Iteration number: [2760/4518] 61% | Training loss: 0.6870234788975854
Epoch: 78 | Iteration number: [2770/4518] 61% | Training loss: 0.6870229401743368
Epoch: 78 | Iteration number: [2780/4518] 61% | Training loss: 0.6870205201476598
Epoch: 78 | Iteration number: [2790/4518] 61% | Training loss: 0.6870200164215539
Epoch: 78 | Iteration number: [2800/4518] 61% | Training loss: 0.6870180512113231
Epoch: 78 | Iteration number: [2810/4518] 62% | Training loss: 0.6870177574429224
Epoch: 78 | Iteration number: [2820/4518] 62% | Training loss: 0.6870192962123992
Epoch: 78 | Iteration number: [2830/4518] 62% | Training loss: 0.6870139228160306
Epoch: 78 | Iteration number: [2840/4518] 62% | Training loss: 0.6870130828568634
Epoch: 78 | Iteration number: [2850/4518] 63% | Training loss: 0.6870119871382128
Epoch: 78 | Iteration number: [2860/4518] 63% | Training loss: 0.6870095011862841
Epoch: 78 | Iteration number: [2870/4518] 63% | Training loss: 0.6870096942896627
Epoch: 78 | Iteration number: [2880/4518] 63% | Training loss: 0.687010588310659
Epoch: 78 | Iteration number: [2890/4518] 63% | Training loss: 0.6870123305741478
Epoch: 78 | Iteration number: [2900/4518] 64% | Training loss: 0.6870084601846235
Epoch: 78 | Iteration number: [2910/4518] 64% | Training loss: 0.6870096773216405
Epoch: 78 | Iteration number: [2920/4518] 64% | Training loss: 0.6870084744406073
Epoch: 78 | Iteration number: [2930/4518] 64% | Training loss: 0.687005633542969
Epoch: 78 | Iteration number: [2940/4518] 65% | Training loss: 0.6870057524264265
Epoch: 78 | Iteration number: [2950/4518] 65% | Training loss: 0.6870086634159088
Epoch: 78 | Iteration number: [2960/4518] 65% | Training loss: 0.687006464197829
Epoch: 78 | Iteration number: [2970/4518] 65% | Training loss: 0.687006968962223
Epoch: 78 | Iteration number: [2980/4518] 65% | Training loss: 0.6870063426910631
Epoch: 78 | Iteration number: [2990/4518] 66% | Training loss: 0.6870025207366433
Epoch: 78 | Iteration number: [3000/4518] 66% | Training loss: 0.686997006992499
Epoch: 78 | Iteration number: [3010/4518] 66% | Training loss: 0.686997237910464
Epoch: 78 | Iteration number: [3020/4518] 66% | Training loss: 0.6869961460694572
Epoch: 78 | Iteration number: [3030/4518] 67% | Training loss: 0.686992365141513
Epoch: 78 | Iteration number: [3040/4518] 67% | Training loss: 0.6869922571472431
Epoch: 78 | Iteration number: [3050/4518] 67% | Training loss: 0.6869894599132851
Epoch: 78 | Iteration number: [3060/4518] 67% | Training loss: 0.6869890881519691
Epoch: 78 | Iteration number: [3070/4518] 67% | Training loss: 0.6869859505165672
Epoch: 78 | Iteration number: [3080/4518] 68% | Training loss: 0.6869889990462885
Epoch: 78 | Iteration number: [3090/4518] 68% | Training loss: 0.6869910946362998
Epoch: 78 | Iteration number: [3100/4518] 68% | Training loss: 0.6869849256738539
Epoch: 78 | Iteration number: [3110/4518] 68% | Training loss: 0.6869833664687117
Epoch: 78 | Iteration number: [3120/4518] 69% | Training loss: 0.6869764050612083
Epoch: 78 | Iteration number: [3130/4518] 69% | Training loss: 0.6869737839927308
Epoch: 78 | Iteration number: [3140/4518] 69% | Training loss: 0.686973970426116
Epoch: 78 | Iteration number: [3150/4518] 69% | Training loss: 0.6869746292961968
Epoch: 78 | Iteration number: [3160/4518] 69% | Training loss: 0.686970072871522
Epoch: 78 | Iteration number: [3170/4518] 70% | Training loss: 0.6869710439951262
Epoch: 78 | Iteration number: [3180/4518] 70% | Training loss: 0.6869662006133758
Epoch: 78 | Iteration number: [3190/4518] 70% | Training loss: 0.6869663635391426
Epoch: 78 | Iteration number: [3200/4518] 70% | Training loss: 0.6869644915126264
Epoch: 78 | Iteration number: [3210/4518] 71% | Training loss: 0.6869667774234606
Epoch: 78 | Iteration number: [3220/4518] 71% | Training loss: 0.6869654755969966
Epoch: 78 | Iteration number: [3230/4518] 71% | Training loss: 0.6869640985325025
Epoch: 78 | Iteration number: [3240/4518] 71% | Training loss: 0.6869644052636477
Epoch: 78 | Iteration number: [3250/4518] 71% | Training loss: 0.6869669393209311
Epoch: 78 | Iteration number: [3260/4518] 72% | Training loss: 0.6869661471046553
Epoch: 78 | Iteration number: [3270/4518] 72% | Training loss: 0.6869646796392739
Epoch: 78 | Iteration number: [3280/4518] 72% | Training loss: 0.686966085561165
Epoch: 78 | Iteration number: [3290/4518] 72% | Training loss: 0.6869697865381792
Epoch: 78 | Iteration number: [3300/4518] 73% | Training loss: 0.686964718428525
Epoch: 78 | Iteration number: [3310/4518] 73% | Training loss: 0.6869651437886172
Epoch: 78 | Iteration number: [3320/4518] 73% | Training loss: 0.6869657393679561
Epoch: 78 | Iteration number: [3330/4518] 73% | Training loss: 0.6869638769834249
Epoch: 78 | Iteration number: [3340/4518] 73% | Training loss: 0.6869627348141756
Epoch: 78 | Iteration number: [3350/4518] 74% | Training loss: 0.6869620947161718
Epoch: 78 | Iteration number: [3360/4518] 74% | Training loss: 0.6869591664700281
Epoch: 78 | Iteration number: [3370/4518] 74% | Training loss: 0.686957728473652
Epoch: 78 | Iteration number: [3380/4518] 74% | Training loss: 0.6869548741706024
Epoch: 78 | Iteration number: [3390/4518] 75% | Training loss: 0.6869519506232226
Epoch: 78 | Iteration number: [3400/4518] 75% | Training loss: 0.6869493155794986
Epoch: 78 | Iteration number: [3410/4518] 75% | Training loss: 0.6869506848697439
Epoch: 78 | Iteration number: [3420/4518] 75% | Training loss: 0.6869498004341683
Epoch: 78 | Iteration number: [3430/4518] 75% | Training loss: 0.6869494502120393
Epoch: 78 | Iteration number: [3440/4518] 76% | Training loss: 0.686949534211741
Epoch: 78 | Iteration number: [3450/4518] 76% | Training loss: 0.6869493541337441
Epoch: 78 | Iteration number: [3460/4518] 76% | Training loss: 0.6869426976394102
Epoch: 78 | Iteration number: [3470/4518] 76% | Training loss: 0.686939319839395
Epoch: 78 | Iteration number: [3480/4518] 77% | Training loss: 0.6869373263812614
Epoch: 78 | Iteration number: [3490/4518] 77% | Training loss: 0.6869391617768132
Epoch: 78 | Iteration number: [3500/4518] 77% | Training loss: 0.6869381162779672
Epoch: 78 | Iteration number: [3510/4518] 77% | Training loss: 0.6869377391970056
Epoch: 78 | Iteration number: [3520/4518] 77% | Training loss: 0.6869402563030069
Epoch: 78 | Iteration number: [3530/4518] 78% | Training loss: 0.6869386149871113
Epoch: 78 | Iteration number: [3540/4518] 78% | Training loss: 0.6869372486899802
Epoch: 78 | Iteration number: [3550/4518] 78% | Training loss: 0.686934045788268
Epoch: 78 | Iteration number: [3560/4518] 78% | Training loss: 0.6869379173001546
Epoch: 78 | Iteration number: [3570/4518] 79% | Training loss: 0.6869365937736522
Epoch: 78 | Iteration number: [3580/4518] 79% | Training loss: 0.6869381337358965
Epoch: 78 | Iteration number: [3590/4518] 79% | Training loss: 0.6869399498598158
Epoch: 78 | Iteration number: [3600/4518] 79% | Training loss: 0.686939620723327
Epoch: 78 | Iteration number: [3610/4518] 79% | Training loss: 0.6869340970575645
Epoch: 78 | Iteration number: [3620/4518] 80% | Training loss: 0.6869329125512371
Epoch: 78 | Iteration number: [3630/4518] 80% | Training loss: 0.6869301225856644
Epoch: 78 | Iteration number: [3640/4518] 80% | Training loss: 0.6869289415550756
Epoch: 78 | Iteration number: [3650/4518] 80% | Training loss: 0.686928946857583
Epoch: 78 | Iteration number: [3660/4518] 81% | Training loss: 0.6869287309750833
Epoch: 78 | Iteration number: [3670/4518] 81% | Training loss: 0.6869269971626656
Epoch: 78 | Iteration number: [3680/4518] 81% | Training loss: 0.6869243152115656
Epoch: 78 | Iteration number: [3690/4518] 81% | Training loss: 0.6869250971934983
Epoch: 78 | Iteration number: [3700/4518] 81% | Training loss: 0.6869252745847444
Epoch: 78 | Iteration number: [3710/4518] 82% | Training loss: 0.6869227281156576
Epoch: 78 | Iteration number: [3720/4518] 82% | Training loss: 0.6869248108037056
Epoch: 78 | Iteration number: [3730/4518] 82% | Training loss: 0.6869220337663196
Epoch: 78 | Iteration number: [3740/4518] 82% | Training loss: 0.6869200234585268
Epoch: 78 | Iteration number: [3750/4518] 83% | Training loss: 0.6869192900180817
Epoch: 78 | Iteration number: [3760/4518] 83% | Training loss: 0.6869233981408971
Epoch: 78 | Iteration number: [3770/4518] 83% | Training loss: 0.6869221051428616
Epoch: 78 | Iteration number: [3780/4518] 83% | Training loss: 0.6869234223214407
Epoch: 78 | Iteration number: [3790/4518] 83% | Training loss: 0.6869247308664398
Epoch: 78 | Iteration number: [3800/4518] 84% | Training loss: 0.6869280120887254
Epoch: 78 | Iteration number: [3810/4518] 84% | Training loss: 0.6869306164150789
Epoch: 78 | Iteration number: [3820/4518] 84% | Training loss: 0.6869326262729955
Epoch: 78 | Iteration number: [3830/4518] 84% | Training loss: 0.6869293263935856
Epoch: 78 | Iteration number: [3840/4518] 84% | Training loss: 0.6869292548391968
Epoch: 78 | Iteration number: [3850/4518] 85% | Training loss: 0.6869281071037441
Epoch: 78 | Iteration number: [3860/4518] 85% | Training loss: 0.6869303600775764
Epoch: 78 | Iteration number: [3870/4518] 85% | Training loss: 0.686930356207436
Epoch: 78 | Iteration number: [3880/4518] 85% | Training loss: 0.686925622667234
Epoch: 78 | Iteration number: [3890/4518] 86% | Training loss: 0.6869267398563326
Epoch: 78 | Iteration number: [3900/4518] 86% | Training loss: 0.6869285091681359
Epoch: 78 | Iteration number: [3910/4518] 86% | Training loss: 0.6869283477058801
Epoch: 78 | Iteration number: [3920/4518] 86% | Training loss: 0.6869270928508165
Epoch: 78 | Iteration number: [3930/4518] 86% | Training loss: 0.6869254241462882
Epoch: 78 | Iteration number: [3940/4518] 87% | Training loss: 0.6869249417394551
Epoch: 78 | Iteration number: [3950/4518] 87% | Training loss: 0.6869239965571633
Epoch: 78 | Iteration number: [3960/4518] 87% | Training loss: 0.6869230309219071
Epoch: 78 | Iteration number: [3970/4518] 87% | Training loss: 0.6869242865582857
Epoch: 78 | Iteration number: [3980/4518] 88% | Training loss: 0.6869229992580175
Epoch: 78 | Iteration number: [3990/4518] 88% | Training loss: 0.6869224694289061
Epoch: 78 | Iteration number: [4000/4518] 88% | Training loss: 0.6869218378812074
Epoch: 78 | Iteration number: [4010/4518] 88% | Training loss: 0.68692257395409
Epoch: 78 | Iteration number: [4020/4518] 88% | Training loss: 0.6869219973016141
Epoch: 78 | Iteration number: [4030/4518] 89% | Training loss: 0.6869202934778653
Epoch: 78 | Iteration number: [4040/4518] 89% | Training loss: 0.6869253561933442
Epoch: 78 | Iteration number: [4050/4518] 89% | Training loss: 0.6869207227965932
Epoch: 78 | Iteration number: [4060/4518] 89% | Training loss: 0.6869233326518477
Epoch: 78 | Iteration number: [4070/4518] 90% | Training loss: 0.6869207534362408
Epoch: 78 | Iteration number: [4080/4518] 90% | Training loss: 0.6869182498723853
Epoch: 78 | Iteration number: [4090/4518] 90% | Training loss: 0.6869180925172232
Epoch: 78 | Iteration number: [4100/4518] 90% | Training loss: 0.6869189797378168
Epoch: 78 | Iteration number: [4110/4518] 90% | Training loss: 0.6869164412329086
Epoch: 78 | Iteration number: [4120/4518] 91% | Training loss: 0.6869177411771515
Epoch: 78 | Iteration number: [4130/4518] 91% | Training loss: 0.686920694101232
Epoch: 78 | Iteration number: [4140/4518] 91% | Training loss: 0.6869212871300425
Epoch: 78 | Iteration number: [4150/4518] 91% | Training loss: 0.6869189938579697
Epoch: 78 | Iteration number: [4160/4518] 92% | Training loss: 0.6869210261851549
Epoch: 78 | Iteration number: [4170/4518] 92% | Training loss: 0.6869211781225044
Epoch: 78 | Iteration number: [4180/4518] 92% | Training loss: 0.6869201744857587
Epoch: 78 | Iteration number: [4190/4518] 92% | Training loss: 0.6869224065243487
Epoch: 78 | Iteration number: [4200/4518] 92% | Training loss: 0.6869212932813735
Epoch: 78 | Iteration number: [4210/4518] 93% | Training loss: 0.6869218278809002
Epoch: 78 | Iteration number: [4220/4518] 93% | Training loss: 0.6869224123621439
Epoch: 78 | Iteration number: [4230/4518] 93% | Training loss: 0.6869254959249609
Epoch: 78 | Iteration number: [4240/4518] 93% | Training loss: 0.6869271398434099
Epoch: 78 | Iteration number: [4250/4518] 94% | Training loss: 0.6869265689148623
Epoch: 78 | Iteration number: [4260/4518] 94% | Training loss: 0.6869261098159871
Epoch: 78 | Iteration number: [4270/4518] 94% | Training loss: 0.6869256859082528
Epoch: 78 | Iteration number: [4280/4518] 94% | Training loss: 0.6869232671840169
Epoch: 78 | Iteration number: [4290/4518] 94% | Training loss: 0.686923848526739
Epoch: 78 | Iteration number: [4300/4518] 95% | Training loss: 0.686926170213278
Epoch: 78 | Iteration number: [4310/4518] 95% | Training loss: 0.6869246603026468
Epoch: 78 | Iteration number: [4320/4518] 95% | Training loss: 0.6869274143405535
Epoch: 78 | Iteration number: [4330/4518] 95% | Training loss: 0.686927359415257
Epoch: 78 | Iteration number: [4340/4518] 96% | Training loss: 0.6869248768288968
Epoch: 78 | Iteration number: [4350/4518] 96% | Training loss: 0.6869233688951909
Epoch: 78 | Iteration number: [4360/4518] 96% | Training loss: 0.68692430149798
Epoch: 78 | Iteration number: [4370/4518] 96% | Training loss: 0.6869244312258007
Epoch: 78 | Iteration number: [4380/4518] 96% | Training loss: 0.6869238467249151
Epoch: 78 | Iteration number: [4390/4518] 97% | Training loss: 0.6869242080387602
Epoch: 78 | Iteration number: [4400/4518] 97% | Training loss: 0.6869227918711576
Epoch: 78 | Iteration number: [4410/4518] 97% | Training loss: 0.6869230847645238
Epoch: 78 | Iteration number: [4420/4518] 97% | Training loss: 0.6869214753624541
Epoch: 78 | Iteration number: [4430/4518] 98% | Training loss: 0.6869208792396916
Epoch: 78 | Iteration number: [4440/4518] 98% | Training loss: 0.6869194763469266
Epoch: 78 | Iteration number: [4450/4518] 98% | Training loss: 0.6869203391235866
Epoch: 78 | Iteration number: [4460/4518] 98% | Training loss: 0.6869198648117049
Epoch: 78 | Iteration number: [4470/4518] 98% | Training loss: 0.6869206805490541
Epoch: 78 | Iteration number: [4480/4518] 99% | Training loss: 0.6869227118257966
Epoch: 78 | Iteration number: [4490/4518] 99% | Training loss: 0.6869232179725622
Epoch: 78 | Iteration number: [4500/4518] 99% | Training loss: 0.686923659351137
Epoch: 78 | Iteration number: [4510/4518] 99% | Training loss: 0.6869238265866451

 End of epoch: 78 | Train Loss: 0.6867731124782731 | Training Time: 641 

 End of epoch: 78 | Eval Loss: 0.6899836464804046 | Evaluating Time: 16 
Epoch: 79 | Iteration number: [10/4518] 0% | Training loss: 0.7561033487319946
Epoch: 79 | Iteration number: [20/4518] 0% | Training loss: 0.7211089193820953
Epoch: 79 | Iteration number: [30/4518] 0% | Training loss: 0.7098770181337992
Epoch: 79 | Iteration number: [40/4518] 0% | Training loss: 0.7041933596134186
Epoch: 79 | Iteration number: [50/4518] 1% | Training loss: 0.7009201109409332
Epoch: 79 | Iteration number: [60/4518] 1% | Training loss: 0.698550495505333
Epoch: 79 | Iteration number: [70/4518] 1% | Training loss: 0.6969568925244468
Epoch: 79 | Iteration number: [80/4518] 1% | Training loss: 0.6954652048647404
Epoch: 79 | Iteration number: [90/4518] 1% | Training loss: 0.6944774501853519
Epoch: 79 | Iteration number: [100/4518] 2% | Training loss: 0.6936422008275985
Epoch: 79 | Iteration number: [110/4518] 2% | Training loss: 0.6930936206470836
Epoch: 79 | Iteration number: [120/4518] 2% | Training loss: 0.6925716216365496
Epoch: 79 | Iteration number: [130/4518] 2% | Training loss: 0.6921621460181017
Epoch: 79 | Iteration number: [140/4518] 3% | Training loss: 0.6917028780494417
Epoch: 79 | Iteration number: [150/4518] 3% | Training loss: 0.6914243384202321
Epoch: 79 | Iteration number: [160/4518] 3% | Training loss: 0.6910449437797069
Epoch: 79 | Iteration number: [170/4518] 3% | Training loss: 0.690860305814182
Epoch: 79 | Iteration number: [180/4518] 3% | Training loss: 0.6906576772530874
Epoch: 79 | Iteration number: [190/4518] 4% | Training loss: 0.6904721934544412
Epoch: 79 | Iteration number: [200/4518] 4% | Training loss: 0.6902667745947838
Epoch: 79 | Iteration number: [210/4518] 4% | Training loss: 0.6901136020819346
Epoch: 79 | Iteration number: [220/4518] 4% | Training loss: 0.6899405931884592
Epoch: 79 | Iteration number: [230/4518] 5% | Training loss: 0.6897673697575278
Epoch: 79 | Iteration number: [240/4518] 5% | Training loss: 0.6896479114890098
Epoch: 79 | Iteration number: [250/4518] 5% | Training loss: 0.689566550731659
Epoch: 79 | Iteration number: [260/4518] 5% | Training loss: 0.6894682428011527
Epoch: 79 | Iteration number: [270/4518] 5% | Training loss: 0.6893668282915044
Epoch: 79 | Iteration number: [280/4518] 6% | Training loss: 0.6892705023288727
Epoch: 79 | Iteration number: [290/4518] 6% | Training loss: 0.6891489302289897
Epoch: 79 | Iteration number: [300/4518] 6% | Training loss: 0.6891002096732457
Epoch: 79 | Iteration number: [310/4518] 6% | Training loss: 0.6890313427294454
Epoch: 79 | Iteration number: [320/4518] 7% | Training loss: 0.6889210164546966
Epoch: 79 | Iteration number: [330/4518] 7% | Training loss: 0.6888586557272709
Epoch: 79 | Iteration number: [340/4518] 7% | Training loss: 0.6888201802968978
Epoch: 79 | Iteration number: [350/4518] 7% | Training loss: 0.6887490539891379
Epoch: 79 | Iteration number: [360/4518] 7% | Training loss: 0.6886923384335306
Epoch: 79 | Iteration number: [370/4518] 8% | Training loss: 0.6886231992695783
Epoch: 79 | Iteration number: [380/4518] 8% | Training loss: 0.6885747915820072
Epoch: 79 | Iteration number: [390/4518] 8% | Training loss: 0.6885305146376292
Epoch: 79 | Iteration number: [400/4518] 8% | Training loss: 0.6884377974271775
Epoch: 79 | Iteration number: [410/4518] 9% | Training loss: 0.6883678504606573
Epoch: 79 | Iteration number: [420/4518] 9% | Training loss: 0.6883453804822195
Epoch: 79 | Iteration number: [430/4518] 9% | Training loss: 0.6883166670799256
Epoch: 79 | Iteration number: [440/4518] 9% | Training loss: 0.6882901270281184
Epoch: 79 | Iteration number: [450/4518] 9% | Training loss: 0.688250168826845
Epoch: 79 | Iteration number: [460/4518] 10% | Training loss: 0.688198087785555
Epoch: 79 | Iteration number: [470/4518] 10% | Training loss: 0.6881857348249314
Epoch: 79 | Iteration number: [480/4518] 10% | Training loss: 0.688125412290295
Epoch: 79 | Iteration number: [490/4518] 10% | Training loss: 0.6881121066151833
Epoch: 79 | Iteration number: [500/4518] 11% | Training loss: 0.6880812603235245
Epoch: 79 | Iteration number: [510/4518] 11% | Training loss: 0.6880606511059929
Epoch: 79 | Iteration number: [520/4518] 11% | Training loss: 0.6880399188170067
Epoch: 79 | Iteration number: [530/4518] 11% | Training loss: 0.6880065364657708
Epoch: 79 | Iteration number: [540/4518] 11% | Training loss: 0.6879945986800724
Epoch: 79 | Iteration number: [550/4518] 12% | Training loss: 0.6879726349223744
Epoch: 79 | Iteration number: [560/4518] 12% | Training loss: 0.6879536508449486
Epoch: 79 | Iteration number: [570/4518] 12% | Training loss: 0.6879528039380124
Epoch: 79 | Iteration number: [580/4518] 12% | Training loss: 0.6879357694551862
Epoch: 79 | Iteration number: [590/4518] 13% | Training loss: 0.6878993039414034
Epoch: 79 | Iteration number: [600/4518] 13% | Training loss: 0.6878973804910977
Epoch: 79 | Iteration number: [610/4518] 13% | Training loss: 0.6878925529659772
Epoch: 79 | Iteration number: [620/4518] 13% | Training loss: 0.6878908278480653
Epoch: 79 | Iteration number: [630/4518] 13% | Training loss: 0.6878572219894046
Epoch: 79 | Iteration number: [640/4518] 14% | Training loss: 0.6878483472391963
Epoch: 79 | Iteration number: [650/4518] 14% | Training loss: 0.6878171631923089
Epoch: 79 | Iteration number: [660/4518] 14% | Training loss: 0.6877942644285433
Epoch: 79 | Iteration number: [670/4518] 14% | Training loss: 0.6877802799886732
Epoch: 79 | Iteration number: [680/4518] 15% | Training loss: 0.6877346442026251
Epoch: 79 | Iteration number: [690/4518] 15% | Training loss: 0.6876993558545044
Epoch: 79 | Iteration number: [700/4518] 15% | Training loss: 0.6876949790545872
Epoch: 79 | Iteration number: [710/4518] 15% | Training loss: 0.6876871213946544
Epoch: 79 | Iteration number: [720/4518] 15% | Training loss: 0.6876766302519375
Epoch: 79 | Iteration number: [730/4518] 16% | Training loss: 0.6876718058978042
Epoch: 79 | Iteration number: [740/4518] 16% | Training loss: 0.6876729890301421
Epoch: 79 | Iteration number: [750/4518] 16% | Training loss: 0.687648473183314
Epoch: 79 | Iteration number: [760/4518] 16% | Training loss: 0.6876417487075455
Epoch: 79 | Iteration number: [770/4518] 17% | Training loss: 0.6876320841250482
Epoch: 79 | Iteration number: [780/4518] 17% | Training loss: 0.6876148198659603
Epoch: 79 | Iteration number: [790/4518] 17% | Training loss: 0.6876134859610208
Epoch: 79 | Iteration number: [800/4518] 17% | Training loss: 0.687592232376337
Epoch: 79 | Iteration number: [810/4518] 17% | Training loss: 0.6875830709198375
Epoch: 79 | Iteration number: [820/4518] 18% | Training loss: 0.6875859388491002
Epoch: 79 | Iteration number: [830/4518] 18% | Training loss: 0.6875737015023289
Epoch: 79 | Iteration number: [840/4518] 18% | Training loss: 0.6875683387830144
Epoch: 79 | Iteration number: [850/4518] 18% | Training loss: 0.6875580798177158
Epoch: 79 | Iteration number: [860/4518] 19% | Training loss: 0.6875482523857162
Epoch: 79 | Iteration number: [870/4518] 19% | Training loss: 0.687541051500145
Epoch: 79 | Iteration number: [880/4518] 19% | Training loss: 0.6875349132852121
Epoch: 79 | Iteration number: [890/4518] 19% | Training loss: 0.6875383738721355
Epoch: 79 | Iteration number: [900/4518] 19% | Training loss: 0.6875258895423677
Epoch: 79 | Iteration number: [910/4518] 20% | Training loss: 0.6875229840750222
Epoch: 79 | Iteration number: [920/4518] 20% | Training loss: 0.6875181250598119
Epoch: 79 | Iteration number: [930/4518] 20% | Training loss: 0.6875223726354619
Epoch: 79 | Iteration number: [940/4518] 20% | Training loss: 0.6875003938345199
Epoch: 79 | Iteration number: [950/4518] 21% | Training loss: 0.6874962121561954
Epoch: 79 | Iteration number: [960/4518] 21% | Training loss: 0.6874863479286433
Epoch: 79 | Iteration number: [970/4518] 21% | Training loss: 0.6874816234578791
Epoch: 79 | Iteration number: [980/4518] 21% | Training loss: 0.6874740554361928
Epoch: 79 | Iteration number: [990/4518] 21% | Training loss: 0.6874681036881726
Epoch: 79 | Iteration number: [1000/4518] 22% | Training loss: 0.6874568666815758
Epoch: 79 | Iteration number: [1010/4518] 22% | Training loss: 0.6874476083434454
Epoch: 79 | Iteration number: [1020/4518] 22% | Training loss: 0.6874473899018531
Epoch: 79 | Iteration number: [1030/4518] 22% | Training loss: 0.6874492701974887
Epoch: 79 | Iteration number: [1040/4518] 23% | Training loss: 0.687444137609922
Epoch: 79 | Iteration number: [1050/4518] 23% | Training loss: 0.6874219301201049
Epoch: 79 | Iteration number: [1060/4518] 23% | Training loss: 0.6874185358015996
Epoch: 79 | Iteration number: [1070/4518] 23% | Training loss: 0.687411781003542
Epoch: 79 | Iteration number: [1080/4518] 23% | Training loss: 0.6873995445944645
Epoch: 79 | Iteration number: [1090/4518] 24% | Training loss: 0.6873930291298332
Epoch: 79 | Iteration number: [1100/4518] 24% | Training loss: 0.6873859989643097
Epoch: 79 | Iteration number: [1110/4518] 24% | Training loss: 0.6873869198399621
Epoch: 79 | Iteration number: [1120/4518] 24% | Training loss: 0.687379406605448
Epoch: 79 | Iteration number: [1130/4518] 25% | Training loss: 0.6873804954300939
Epoch: 79 | Iteration number: [1140/4518] 25% | Training loss: 0.687376951857617
Epoch: 79 | Iteration number: [1150/4518] 25% | Training loss: 0.6873644239487855
Epoch: 79 | Iteration number: [1160/4518] 25% | Training loss: 0.6873593386904947
Epoch: 79 | Iteration number: [1170/4518] 25% | Training loss: 0.6873555717305241
Epoch: 79 | Iteration number: [1180/4518] 26% | Training loss: 0.687349536863424
Epoch: 79 | Iteration number: [1190/4518] 26% | Training loss: 0.6873362913352101
Epoch: 79 | Iteration number: [1200/4518] 26% | Training loss: 0.6873127259810765
Epoch: 79 | Iteration number: [1210/4518] 26% | Training loss: 0.6873121061108329
Epoch: 79 | Iteration number: [1220/4518] 27% | Training loss: 0.6873119494954093
Epoch: 79 | Iteration number: [1230/4518] 27% | Training loss: 0.6873166393942949
Epoch: 79 | Iteration number: [1240/4518] 27% | Training loss: 0.6873161741802769
Epoch: 79 | Iteration number: [1250/4518] 27% | Training loss: 0.6873098466396331
Epoch: 79 | Iteration number: [1260/4518] 27% | Training loss: 0.6873183413157388
Epoch: 79 | Iteration number: [1270/4518] 28% | Training loss: 0.6873164307883405
Epoch: 79 | Iteration number: [1280/4518] 28% | Training loss: 0.6873138144146651
Epoch: 79 | Iteration number: [1290/4518] 28% | Training loss: 0.687308394908905
Epoch: 79 | Iteration number: [1300/4518] 28% | Training loss: 0.6872962615123162
Epoch: 79 | Iteration number: [1310/4518] 28% | Training loss: 0.6872875101238717
Epoch: 79 | Iteration number: [1320/4518] 29% | Training loss: 0.6872826587070119
Epoch: 79 | Iteration number: [1330/4518] 29% | Training loss: 0.687284673515119
Epoch: 79 | Iteration number: [1340/4518] 29% | Training loss: 0.6872831724028089
Epoch: 79 | Iteration number: [1350/4518] 29% | Training loss: 0.687280997214494
Epoch: 79 | Iteration number: [1360/4518] 30% | Training loss: 0.6872817881405353
Epoch: 79 | Iteration number: [1370/4518] 30% | Training loss: 0.687276745625656
Epoch: 79 | Iteration number: [1380/4518] 30% | Training loss: 0.6872818841018539
Epoch: 79 | Iteration number: [1390/4518] 30% | Training loss: 0.6872842407055039
Epoch: 79 | Iteration number: [1400/4518] 30% | Training loss: 0.6872792805092676
Epoch: 79 | Iteration number: [1410/4518] 31% | Training loss: 0.6872817338358426
Epoch: 79 | Iteration number: [1420/4518] 31% | Training loss: 0.6872704640660487
Epoch: 79 | Iteration number: [1430/4518] 31% | Training loss: 0.6872714456144746
Epoch: 79 | Iteration number: [1440/4518] 31% | Training loss: 0.6872697109149561
Epoch: 79 | Iteration number: [1450/4518] 32% | Training loss: 0.6872736967021021
Epoch: 79 | Iteration number: [1460/4518] 32% | Training loss: 0.6872694245348238
Epoch: 79 | Iteration number: [1470/4518] 32% | Training loss: 0.6872613688309988
Epoch: 79 | Iteration number: [1480/4518] 32% | Training loss: 0.6872678575886263
Epoch: 79 | Iteration number: [1490/4518] 32% | Training loss: 0.687265934600126
Epoch: 79 | Iteration number: [1500/4518] 33% | Training loss: 0.6872622538805008
Epoch: 79 | Iteration number: [1510/4518] 33% | Training loss: 0.6872646856781662
Epoch: 79 | Iteration number: [1520/4518] 33% | Training loss: 0.6872538062694825
Epoch: 79 | Iteration number: [1530/4518] 33% | Training loss: 0.6872525989619735
Epoch: 79 | Iteration number: [1540/4518] 34% | Training loss: 0.6872375102399232
Epoch: 79 | Iteration number: [1550/4518] 34% | Training loss: 0.6872259740675649
Epoch: 79 | Iteration number: [1560/4518] 34% | Training loss: 0.6872305982387983
Epoch: 79 | Iteration number: [1570/4518] 34% | Training loss: 0.6872271778856873
Epoch: 79 | Iteration number: [1580/4518] 34% | Training loss: 0.6872201359724697
Epoch: 79 | Iteration number: [1590/4518] 35% | Training loss: 0.6872178456318453
Epoch: 79 | Iteration number: [1600/4518] 35% | Training loss: 0.6872159938141703
Epoch: 79 | Iteration number: [1610/4518] 35% | Training loss: 0.6872153064108784
Epoch: 79 | Iteration number: [1620/4518] 35% | Training loss: 0.6872131058463344
Epoch: 79 | Iteration number: [1630/4518] 36% | Training loss: 0.6872098324123336
Epoch: 79 | Iteration number: [1640/4518] 36% | Training loss: 0.6872016079542114
Epoch: 79 | Iteration number: [1650/4518] 36% | Training loss: 0.6872007174925371
Epoch: 79 | Iteration number: [1660/4518] 36% | Training loss: 0.6871971126780453
Epoch: 79 | Iteration number: [1670/4518] 36% | Training loss: 0.6871904617655064
Epoch: 79 | Iteration number: [1680/4518] 37% | Training loss: 0.6871891840228013
Epoch: 79 | Iteration number: [1690/4518] 37% | Training loss: 0.6871765906641469
Epoch: 79 | Iteration number: [1700/4518] 37% | Training loss: 0.6871713511733448
Epoch: 79 | Iteration number: [1710/4518] 37% | Training loss: 0.6871678897163325
Epoch: 79 | Iteration number: [1720/4518] 38% | Training loss: 0.6871581658027893
Epoch: 79 | Iteration number: [1730/4518] 38% | Training loss: 0.6871598638206549
Epoch: 79 | Iteration number: [1740/4518] 38% | Training loss: 0.687157905855398
Epoch: 79 | Iteration number: [1750/4518] 38% | Training loss: 0.6871561488424028
Epoch: 79 | Iteration number: [1760/4518] 38% | Training loss: 0.6871526068245822
Epoch: 79 | Iteration number: [1770/4518] 39% | Training loss: 0.6871474345525106
Epoch: 79 | Iteration number: [1780/4518] 39% | Training loss: 0.687145191498017
Epoch: 79 | Iteration number: [1790/4518] 39% | Training loss: 0.687138870108727
Epoch: 79 | Iteration number: [1800/4518] 39% | Training loss: 0.6871320055590735
Epoch: 79 | Iteration number: [1810/4518] 40% | Training loss: 0.6871274461074429
Epoch: 79 | Iteration number: [1820/4518] 40% | Training loss: 0.6871261938587649
Epoch: 79 | Iteration number: [1830/4518] 40% | Training loss: 0.6871229350566864
Epoch: 79 | Iteration number: [1840/4518] 40% | Training loss: 0.6871228931714659
Epoch: 79 | Iteration number: [1850/4518] 40% | Training loss: 0.687115357115462
Epoch: 79 | Iteration number: [1860/4518] 41% | Training loss: 0.6871122489693344
Epoch: 79 | Iteration number: [1870/4518] 41% | Training loss: 0.687111195937835
Epoch: 79 | Iteration number: [1880/4518] 41% | Training loss: 0.6871119912951551
Epoch: 79 | Iteration number: [1890/4518] 41% | Training loss: 0.6871115986001555
Epoch: 79 | Iteration number: [1900/4518] 42% | Training loss: 0.6871086395414252
Epoch: 79 | Iteration number: [1910/4518] 42% | Training loss: 0.6871131661362673
Epoch: 79 | Iteration number: [1920/4518] 42% | Training loss: 0.6871101084786156
Epoch: 79 | Iteration number: [1930/4518] 42% | Training loss: 0.6871051763623489
Epoch: 79 | Iteration number: [1940/4518] 42% | Training loss: 0.687109002378798
Epoch: 79 | Iteration number: [1950/4518] 43% | Training loss: 0.6871090502311021
Epoch: 79 | Iteration number: [1960/4518] 43% | Training loss: 0.6871012302685757
Epoch: 79 | Iteration number: [1970/4518] 43% | Training loss: 0.687101912468218
Epoch: 79 | Iteration number: [1980/4518] 43% | Training loss: 0.6870991376313296
Epoch: 79 | Iteration number: [1990/4518] 44% | Training loss: 0.687095826654578
Epoch: 79 | Iteration number: [2000/4518] 44% | Training loss: 0.6870889946818352
Epoch: 79 | Iteration number: [2010/4518] 44% | Training loss: 0.6870862501474162
Epoch: 79 | Iteration number: [2020/4518] 44% | Training loss: 0.6870780375334296
Epoch: 79 | Iteration number: [2030/4518] 44% | Training loss: 0.6870727774838509
Epoch: 79 | Iteration number: [2040/4518] 45% | Training loss: 0.6870682989849763
Epoch: 79 | Iteration number: [2050/4518] 45% | Training loss: 0.6870715875160404
Epoch: 79 | Iteration number: [2060/4518] 45% | Training loss: 0.6870723793228853
Epoch: 79 | Iteration number: [2070/4518] 45% | Training loss: 0.6870706586446164
Epoch: 79 | Iteration number: [2080/4518] 46% | Training loss: 0.6870667009112926
Epoch: 79 | Iteration number: [2090/4518] 46% | Training loss: 0.6870656927236529
Epoch: 79 | Iteration number: [2100/4518] 46% | Training loss: 0.6870652753398532
Epoch: 79 | Iteration number: [2110/4518] 46% | Training loss: 0.6870606796718887
Epoch: 79 | Iteration number: [2120/4518] 46% | Training loss: 0.6870642860543054
Epoch: 79 | Iteration number: [2130/4518] 47% | Training loss: 0.687063665820959
Epoch: 79 | Iteration number: [2140/4518] 47% | Training loss: 0.6870602216676017
Epoch: 79 | Iteration number: [2150/4518] 47% | Training loss: 0.6870562228213909
Epoch: 79 | Iteration number: [2160/4518] 47% | Training loss: 0.6870551482946784
Epoch: 79 | Iteration number: [2170/4518] 48% | Training loss: 0.6870546661763697
Epoch: 79 | Iteration number: [2180/4518] 48% | Training loss: 0.6870571293141864
Epoch: 79 | Iteration number: [2190/4518] 48% | Training loss: 0.6870554634153027
Epoch: 79 | Iteration number: [2200/4518] 48% | Training loss: 0.6870491840622642
Epoch: 79 | Iteration number: [2210/4518] 48% | Training loss: 0.6870435628416312
Epoch: 79 | Iteration number: [2220/4518] 49% | Training loss: 0.6870421205554996
Epoch: 79 | Iteration number: [2230/4518] 49% | Training loss: 0.687034824584097
Epoch: 79 | Iteration number: [2240/4518] 49% | Training loss: 0.6870339220389724
Epoch: 79 | Iteration number: [2250/4518] 49% | Training loss: 0.6870296074549357
Epoch: 79 | Iteration number: [2260/4518] 50% | Training loss: 0.6870279232221367
Epoch: 79 | Iteration number: [2270/4518] 50% | Training loss: 0.6870206882775093
Epoch: 79 | Iteration number: [2280/4518] 50% | Training loss: 0.687019095295354
Epoch: 79 | Iteration number: [2290/4518] 50% | Training loss: 0.6870219535182137
Epoch: 79 | Iteration number: [2300/4518] 50% | Training loss: 0.6870250990079797
Epoch: 79 | Iteration number: [2310/4518] 51% | Training loss: 0.6870288075048686
Epoch: 79 | Iteration number: [2320/4518] 51% | Training loss: 0.6870221552920752
Epoch: 79 | Iteration number: [2330/4518] 51% | Training loss: 0.687020924290874
Epoch: 79 | Iteration number: [2340/4518] 51% | Training loss: 0.6870268121234372
Epoch: 79 | Iteration number: [2350/4518] 52% | Training loss: 0.6870243897336594
Epoch: 79 | Iteration number: [2360/4518] 52% | Training loss: 0.6870222557399233
Epoch: 79 | Iteration number: [2370/4518] 52% | Training loss: 0.687016770784362
Epoch: 79 | Iteration number: [2380/4518] 52% | Training loss: 0.6870128980454276
Epoch: 79 | Iteration number: [2390/4518] 52% | Training loss: 0.6870107143743268
Epoch: 79 | Iteration number: [2400/4518] 53% | Training loss: 0.6870107156038284
Epoch: 79 | Iteration number: [2410/4518] 53% | Training loss: 0.6870099793083935
Epoch: 79 | Iteration number: [2420/4518] 53% | Training loss: 0.6870093659428526
Epoch: 79 | Iteration number: [2430/4518] 53% | Training loss: 0.6870126331294024
Epoch: 79 | Iteration number: [2440/4518] 54% | Training loss: 0.6870150111737798
Epoch: 79 | Iteration number: [2450/4518] 54% | Training loss: 0.6870143295064265
Epoch: 79 | Iteration number: [2460/4518] 54% | Training loss: 0.6870140737149774
Epoch: 79 | Iteration number: [2470/4518] 54% | Training loss: 0.6870072631700801
Epoch: 79 | Iteration number: [2480/4518] 54% | Training loss: 0.6870053146635332
Epoch: 79 | Iteration number: [2490/4518] 55% | Training loss: 0.68700744629385
Epoch: 79 | Iteration number: [2500/4518] 55% | Training loss: 0.6870017303705216
Epoch: 79 | Iteration number: [2510/4518] 55% | Training loss: 0.6869958801336022
Epoch: 79 | Iteration number: [2520/4518] 55% | Training loss: 0.6870006771314712
Epoch: 79 | Iteration number: [2530/4518] 55% | Training loss: 0.6870001943215079
Epoch: 79 | Iteration number: [2540/4518] 56% | Training loss: 0.6870014379812976
Epoch: 79 | Iteration number: [2550/4518] 56% | Training loss: 0.6870029626640619
Epoch: 79 | Iteration number: [2560/4518] 56% | Training loss: 0.6870003252755851
Epoch: 79 | Iteration number: [2570/4518] 56% | Training loss: 0.6870046333580165
Epoch: 79 | Iteration number: [2580/4518] 57% | Training loss: 0.6870059768358866
Epoch: 79 | Iteration number: [2590/4518] 57% | Training loss: 0.6870042173098413
Epoch: 79 | Iteration number: [2600/4518] 57% | Training loss: 0.687001845905414
Epoch: 79 | Iteration number: [2610/4518] 57% | Training loss: 0.6870011768121829
Epoch: 79 | Iteration number: [2620/4518] 57% | Training loss: 0.687000994668662
Epoch: 79 | Iteration number: [2630/4518] 58% | Training loss: 0.6869995011802862
Epoch: 79 | Iteration number: [2640/4518] 58% | Training loss: 0.6870024001733823
Epoch: 79 | Iteration number: [2650/4518] 58% | Training loss: 0.6870044267852351
Epoch: 79 | Iteration number: [2660/4518] 58% | Training loss: 0.6870066262053368
Epoch: 79 | Iteration number: [2670/4518] 59% | Training loss: 0.6870021045431216
Epoch: 79 | Iteration number: [2680/4518] 59% | Training loss: 0.6869987433970864
Epoch: 79 | Iteration number: [2690/4518] 59% | Training loss: 0.6869953373994083
Epoch: 79 | Iteration number: [2700/4518] 59% | Training loss: 0.6869993961519665
Epoch: 79 | Iteration number: [2710/4518] 59% | Training loss: 0.6870017023104144
Epoch: 79 | Iteration number: [2720/4518] 60% | Training loss: 0.6870040846878991
Epoch: 79 | Iteration number: [2730/4518] 60% | Training loss: 0.6870025594155867
Epoch: 79 | Iteration number: [2740/4518] 60% | Training loss: 0.687000840880575
Epoch: 79 | Iteration number: [2750/4518] 60% | Training loss: 0.6870027667825872
Epoch: 79 | Iteration number: [2760/4518] 61% | Training loss: 0.6869992994095968
Epoch: 79 | Iteration number: [2770/4518] 61% | Training loss: 0.6870023479530527
Epoch: 79 | Iteration number: [2780/4518] 61% | Training loss: 0.6870019768639434
Epoch: 79 | Iteration number: [2790/4518] 61% | Training loss: 0.6870050146801925
Epoch: 79 | Iteration number: [2800/4518] 61% | Training loss: 0.6870034894985813
Epoch: 79 | Iteration number: [2810/4518] 62% | Training loss: 0.6870016134294327
Epoch: 79 | Iteration number: [2820/4518] 62% | Training loss: 0.6870014352790007
Epoch: 79 | Iteration number: [2830/4518] 62% | Training loss: 0.6869970840826473
Epoch: 79 | Iteration number: [2840/4518] 62% | Training loss: 0.6870014142612336
Epoch: 79 | Iteration number: [2850/4518] 63% | Training loss: 0.6870025096650709
Epoch: 79 | Iteration number: [2860/4518] 63% | Training loss: 0.6870033027200432
Epoch: 79 | Iteration number: [2870/4518] 63% | Training loss: 0.6870000211411652
Epoch: 79 | Iteration number: [2880/4518] 63% | Training loss: 0.6870028242675794
Epoch: 79 | Iteration number: [2890/4518] 63% | Training loss: 0.6869988790639131
Epoch: 79 | Iteration number: [2900/4518] 64% | Training loss: 0.6869955041901818
Epoch: 79 | Iteration number: [2910/4518] 64% | Training loss: 0.6869920116109947
Epoch: 79 | Iteration number: [2920/4518] 64% | Training loss: 0.6869906183179111
Epoch: 79 | Iteration number: [2930/4518] 64% | Training loss: 0.6869860058758446
Epoch: 79 | Iteration number: [2940/4518] 65% | Training loss: 0.686986397946773
Epoch: 79 | Iteration number: [2950/4518] 65% | Training loss: 0.6869860031443127
Epoch: 79 | Iteration number: [2960/4518] 65% | Training loss: 0.6869798737603265
Epoch: 79 | Iteration number: [2970/4518] 65% | Training loss: 0.6869750210131058
Epoch: 79 | Iteration number: [2980/4518] 65% | Training loss: 0.6869721730683473
Epoch: 79 | Iteration number: [2990/4518] 66% | Training loss: 0.6869737527442218
Epoch: 79 | Iteration number: [3000/4518] 66% | Training loss: 0.6869705135027567
Epoch: 79 | Iteration number: [3010/4518] 66% | Training loss: 0.6869700516775201
Epoch: 79 | Iteration number: [3020/4518] 66% | Training loss: 0.6869702441013412
Epoch: 79 | Iteration number: [3030/4518] 67% | Training loss: 0.6869712323048721
Epoch: 79 | Iteration number: [3040/4518] 67% | Training loss: 0.6869717917356052
Epoch: 79 | Iteration number: [3050/4518] 67% | Training loss: 0.6869658169003784
Epoch: 79 | Iteration number: [3060/4518] 67% | Training loss: 0.6869675415403703
Epoch: 79 | Iteration number: [3070/4518] 67% | Training loss: 0.6869715128542935
Epoch: 79 | Iteration number: [3080/4518] 68% | Training loss: 0.6869711898944595
Epoch: 79 | Iteration number: [3090/4518] 68% | Training loss: 0.6869716585454045
Epoch: 79 | Iteration number: [3100/4518] 68% | Training loss: 0.6869697993609213
Epoch: 79 | Iteration number: [3110/4518] 68% | Training loss: 0.686972169573284
Epoch: 79 | Iteration number: [3120/4518] 69% | Training loss: 0.6869698649033522
Epoch: 79 | Iteration number: [3130/4518] 69% | Training loss: 0.6869712932231709
Epoch: 79 | Iteration number: [3140/4518] 69% | Training loss: 0.6869662794907382
Epoch: 79 | Iteration number: [3150/4518] 69% | Training loss: 0.6869682158931854
Epoch: 79 | Iteration number: [3160/4518] 69% | Training loss: 0.686967040145699
Epoch: 79 | Iteration number: [3170/4518] 70% | Training loss: 0.6869670533419407
Epoch: 79 | Iteration number: [3180/4518] 70% | Training loss: 0.6869639624214772
Epoch: 79 | Iteration number: [3190/4518] 70% | Training loss: 0.6869627026554933
Epoch: 79 | Iteration number: [3200/4518] 70% | Training loss: 0.6869624905847013
Epoch: 79 | Iteration number: [3210/4518] 71% | Training loss: 0.6869619992291816
Epoch: 79 | Iteration number: [3220/4518] 71% | Training loss: 0.6869631989031845
Epoch: 79 | Iteration number: [3230/4518] 71% | Training loss: 0.686960888296458
Epoch: 79 | Iteration number: [3240/4518] 71% | Training loss: 0.6869586987259947
Epoch: 79 | Iteration number: [3250/4518] 71% | Training loss: 0.6869549298286438
Epoch: 79 | Iteration number: [3260/4518] 72% | Training loss: 0.6869574261954957
Epoch: 79 | Iteration number: [3270/4518] 72% | Training loss: 0.68695995189728
Epoch: 79 | Iteration number: [3280/4518] 72% | Training loss: 0.6869555395732566
Epoch: 79 | Iteration number: [3290/4518] 72% | Training loss: 0.6869567991752392
Epoch: 79 | Iteration number: [3300/4518] 73% | Training loss: 0.686956997423461
Epoch: 79 | Iteration number: [3310/4518] 73% | Training loss: 0.6869561863989988
Epoch: 79 | Iteration number: [3320/4518] 73% | Training loss: 0.6869573163878486
Epoch: 79 | Iteration number: [3330/4518] 73% | Training loss: 0.6869571494268584
Epoch: 79 | Iteration number: [3340/4518] 73% | Training loss: 0.6869576316036864
Epoch: 79 | Iteration number: [3350/4518] 74% | Training loss: 0.6869601398261626
Epoch: 79 | Iteration number: [3360/4518] 74% | Training loss: 0.6869623306961287
Epoch: 79 | Iteration number: [3370/4518] 74% | Training loss: 0.6869590115653301
Epoch: 79 | Iteration number: [3380/4518] 74% | Training loss: 0.6869619572656395
Epoch: 79 | Iteration number: [3390/4518] 75% | Training loss: 0.6869604872391287
Epoch: 79 | Iteration number: [3400/4518] 75% | Training loss: 0.6869593234973795
Epoch: 79 | Iteration number: [3410/4518] 75% | Training loss: 0.686958160306002
Epoch: 79 | Iteration number: [3420/4518] 75% | Training loss: 0.6869561974068135
Epoch: 79 | Iteration number: [3430/4518] 75% | Training loss: 0.6869558282739567
Epoch: 79 | Iteration number: [3440/4518] 76% | Training loss: 0.6869565668840741
Epoch: 79 | Iteration number: [3450/4518] 76% | Training loss: 0.6869588769864345
Epoch: 79 | Iteration number: [3460/4518] 76% | Training loss: 0.686956612119785
Epoch: 79 | Iteration number: [3470/4518] 76% | Training loss: 0.6869583501939471
Epoch: 79 | Iteration number: [3480/4518] 77% | Training loss: 0.6869513872882416
Epoch: 79 | Iteration number: [3490/4518] 77% | Training loss: 0.6869499154282163
Epoch: 79 | Iteration number: [3500/4518] 77% | Training loss: 0.6869488207101822
Epoch: 79 | Iteration number: [3510/4518] 77% | Training loss: 0.6869511111849054
Epoch: 79 | Iteration number: [3520/4518] 77% | Training loss: 0.6869511862370101
Epoch: 79 | Iteration number: [3530/4518] 78% | Training loss: 0.6869518555426395
Epoch: 79 | Iteration number: [3540/4518] 78% | Training loss: 0.6869549833953718
Epoch: 79 | Iteration number: [3550/4518] 78% | Training loss: 0.686955104058897
Epoch: 79 | Iteration number: [3560/4518] 78% | Training loss: 0.6869551669345813
Epoch: 79 | Iteration number: [3570/4518] 79% | Training loss: 0.6869544399886572
Epoch: 79 | Iteration number: [3580/4518] 79% | Training loss: 0.6869543458163405
Epoch: 79 | Iteration number: [3590/4518] 79% | Training loss: 0.68695221817261
Epoch: 79 | Iteration number: [3600/4518] 79% | Training loss: 0.6869515161878533
Epoch: 79 | Iteration number: [3610/4518] 79% | Training loss: 0.6869509155400242
Epoch: 79 | Iteration number: [3620/4518] 80% | Training loss: 0.6869499321965223
Epoch: 79 | Iteration number: [3630/4518] 80% | Training loss: 0.6869492385669845
Epoch: 79 | Iteration number: [3640/4518] 80% | Training loss: 0.6869513231155636
Epoch: 79 | Iteration number: [3650/4518] 80% | Training loss: 0.6869511461911136
Epoch: 79 | Iteration number: [3660/4518] 81% | Training loss: 0.6869506711516875
Epoch: 79 | Iteration number: [3670/4518] 81% | Training loss: 0.6869470920322377
Epoch: 79 | Iteration number: [3680/4518] 81% | Training loss: 0.6869457599909409
Epoch: 79 | Iteration number: [3690/4518] 81% | Training loss: 0.6869441354823952
Epoch: 79 | Iteration number: [3700/4518] 81% | Training loss: 0.686942225984625
Epoch: 79 | Iteration number: [3710/4518] 82% | Training loss: 0.6869437460629445
Epoch: 79 | Iteration number: [3720/4518] 82% | Training loss: 0.6869431669673612
Epoch: 79 | Iteration number: [3730/4518] 82% | Training loss: 0.6869447837086848
Epoch: 79 | Iteration number: [3740/4518] 82% | Training loss: 0.6869450383167216
Epoch: 79 | Iteration number: [3750/4518] 83% | Training loss: 0.6869428557713827
Epoch: 79 | Iteration number: [3760/4518] 83% | Training loss: 0.6869404967002413
Epoch: 79 | Iteration number: [3770/4518] 83% | Training loss: 0.6869416186284639
Epoch: 79 | Iteration number: [3780/4518] 83% | Training loss: 0.6869436233289659
Epoch: 79 | Iteration number: [3790/4518] 83% | Training loss: 0.6869444243354345
Epoch: 79 | Iteration number: [3800/4518] 84% | Training loss: 0.6869426937950285
Epoch: 79 | Iteration number: [3810/4518] 84% | Training loss: 0.6869424482186636
Epoch: 79 | Iteration number: [3820/4518] 84% | Training loss: 0.6869400448980132
Epoch: 79 | Iteration number: [3830/4518] 84% | Training loss: 0.6869390408924292
Epoch: 79 | Iteration number: [3840/4518] 84% | Training loss: 0.6869404942728579
Epoch: 79 | Iteration number: [3850/4518] 85% | Training loss: 0.6869423494865368
Epoch: 79 | Iteration number: [3860/4518] 85% | Training loss: 0.6869404134509477
Epoch: 79 | Iteration number: [3870/4518] 85% | Training loss: 0.6869381899365467
Epoch: 79 | Iteration number: [3880/4518] 85% | Training loss: 0.6869375036856563
Epoch: 79 | Iteration number: [3890/4518] 86% | Training loss: 0.686937372788672
Epoch: 79 | Iteration number: [3900/4518] 86% | Training loss: 0.6869379414503392
Epoch: 79 | Iteration number: [3910/4518] 86% | Training loss: 0.6869357623407603
Epoch: 79 | Iteration number: [3920/4518] 86% | Training loss: 0.686938059694913
Epoch: 79 | Iteration number: [3930/4518] 86% | Training loss: 0.6869371709022813
Epoch: 79 | Iteration number: [3940/4518] 87% | Training loss: 0.6869364446794927
Epoch: 79 | Iteration number: [3950/4518] 87% | Training loss: 0.6869337894644918
Epoch: 79 | Iteration number: [3960/4518] 87% | Training loss: 0.6869327355063323
Epoch: 79 | Iteration number: [3970/4518] 87% | Training loss: 0.6869328338493328
Epoch: 79 | Iteration number: [3980/4518] 88% | Training loss: 0.6869353087253905
Epoch: 79 | Iteration number: [3990/4518] 88% | Training loss: 0.6869357324184332
Epoch: 79 | Iteration number: [4000/4518] 88% | Training loss: 0.6869352188557386
Epoch: 79 | Iteration number: [4010/4518] 88% | Training loss: 0.6869330779424034
Epoch: 79 | Iteration number: [4020/4518] 88% | Training loss: 0.6869352933334474
Epoch: 79 | Iteration number: [4030/4518] 89% | Training loss: 0.686936516900808
Epoch: 79 | Iteration number: [4040/4518] 89% | Training loss: 0.6869360385702388
Epoch: 79 | Iteration number: [4050/4518] 89% | Training loss: 0.686937367827804
Epoch: 79 | Iteration number: [4060/4518] 89% | Training loss: 0.6869365232184602
Epoch: 79 | Iteration number: [4070/4518] 90% | Training loss: 0.6869346286506559
Epoch: 79 | Iteration number: [4080/4518] 90% | Training loss: 0.6869343468663739
Epoch: 79 | Iteration number: [4090/4518] 90% | Training loss: 0.6869365721722396
Epoch: 79 | Iteration number: [4100/4518] 90% | Training loss: 0.6869347657226935
Epoch: 79 | Iteration number: [4110/4518] 90% | Training loss: 0.6869368080095073
Epoch: 79 | Iteration number: [4120/4518] 91% | Training loss: 0.6869353120766797
Epoch: 79 | Iteration number: [4130/4518] 91% | Training loss: 0.6869368120486742
Epoch: 79 | Iteration number: [4140/4518] 91% | Training loss: 0.6869374948135321
Epoch: 79 | Iteration number: [4150/4518] 91% | Training loss: 0.686937000435519
Epoch: 79 | Iteration number: [4160/4518] 92% | Training loss: 0.6869371701175204
Epoch: 79 | Iteration number: [4170/4518] 92% | Training loss: 0.6869371715209467
Epoch: 79 | Iteration number: [4180/4518] 92% | Training loss: 0.6869390492946907
Epoch: 79 | Iteration number: [4190/4518] 92% | Training loss: 0.6869391142895227
Epoch: 79 | Iteration number: [4200/4518] 92% | Training loss: 0.6869410213260424
Epoch: 79 | Iteration number: [4210/4518] 93% | Training loss: 0.6869400715742995
Epoch: 79 | Iteration number: [4220/4518] 93% | Training loss: 0.6869399638537547
Epoch: 79 | Iteration number: [4230/4518] 93% | Training loss: 0.6869398691270932
Epoch: 79 | Iteration number: [4240/4518] 93% | Training loss: 0.686940438356602
Epoch: 79 | Iteration number: [4250/4518] 94% | Training loss: 0.6869418090371524
Epoch: 79 | Iteration number: [4260/4518] 94% | Training loss: 0.6869416260523415
Epoch: 79 | Iteration number: [4270/4518] 94% | Training loss: 0.6869457087416281
Epoch: 79 | Iteration number: [4280/4518] 94% | Training loss: 0.6869463895804414
Epoch: 79 | Iteration number: [4290/4518] 94% | Training loss: 0.6869463043751972
Epoch: 79 | Iteration number: [4300/4518] 95% | Training loss: 0.6869464059624562
Epoch: 79 | Iteration number: [4310/4518] 95% | Training loss: 0.6869454695426118
Epoch: 79 | Iteration number: [4320/4518] 95% | Training loss: 0.6869450986799267
Epoch: 79 | Iteration number: [4330/4518] 95% | Training loss: 0.6869421004010128
Epoch: 79 | Iteration number: [4340/4518] 96% | Training loss: 0.6869433231068097
Epoch: 79 | Iteration number: [4350/4518] 96% | Training loss: 0.686941272404002
Epoch: 79 | Iteration number: [4360/4518] 96% | Training loss: 0.6869411911302751
Epoch: 79 | Iteration number: [4370/4518] 96% | Training loss: 0.6869437049673678
Epoch: 79 | Iteration number: [4380/4518] 96% | Training loss: 0.6869452352937498
Epoch: 79 | Iteration number: [4390/4518] 97% | Training loss: 0.6869446710872216
Epoch: 79 | Iteration number: [4400/4518] 97% | Training loss: 0.6869432812522758
Epoch: 79 | Iteration number: [4410/4518] 97% | Training loss: 0.6869413418429239
Epoch: 79 | Iteration number: [4420/4518] 97% | Training loss: 0.6869398612512183
Epoch: 79 | Iteration number: [4430/4518] 98% | Training loss: 0.6869366524047292
Epoch: 79 | Iteration number: [4440/4518] 98% | Training loss: 0.6869342515865962
Epoch: 79 | Iteration number: [4450/4518] 98% | Training loss: 0.6869333824013056
Epoch: 79 | Iteration number: [4460/4518] 98% | Training loss: 0.6869305241936525
Epoch: 79 | Iteration number: [4470/4518] 98% | Training loss: 0.6869325801296788
Epoch: 79 | Iteration number: [4480/4518] 99% | Training loss: 0.6869295096157917
Epoch: 79 | Iteration number: [4490/4518] 99% | Training loss: 0.6869306630705938
Epoch: 79 | Iteration number: [4500/4518] 99% | Training loss: 0.686930162469546
Epoch: 79 | Iteration number: [4510/4518] 99% | Training loss: 0.6869285530499503

 End of epoch: 79 | Train Loss: 0.6867773665586052 | Training Time: 640 

 End of epoch: 79 | Eval Loss: 0.6899951526096889 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/4518] 0% | Training loss: 0.7561009168624878
Epoch: 80 | Iteration number: [20/4518] 0% | Training loss: 0.7214419990777969
Epoch: 80 | Iteration number: [30/4518] 0% | Training loss: 0.7102912763754526
Epoch: 80 | Iteration number: [40/4518] 0% | Training loss: 0.7045973405241966
Epoch: 80 | Iteration number: [50/4518] 1% | Training loss: 0.7010714840888977
Epoch: 80 | Iteration number: [60/4518] 1% | Training loss: 0.6985279053449631
Epoch: 80 | Iteration number: [70/4518] 1% | Training loss: 0.6969029639448439
Epoch: 80 | Iteration number: [80/4518] 1% | Training loss: 0.6956191942095756
Epoch: 80 | Iteration number: [90/4518] 1% | Training loss: 0.6945511135790083
Epoch: 80 | Iteration number: [100/4518] 2% | Training loss: 0.6935887503623962
Epoch: 80 | Iteration number: [110/4518] 2% | Training loss: 0.6929394933310422
Epoch: 80 | Iteration number: [120/4518] 2% | Training loss: 0.6924044668674469
Epoch: 80 | Iteration number: [130/4518] 2% | Training loss: 0.6920050038741186
Epoch: 80 | Iteration number: [140/4518] 3% | Training loss: 0.6918300526482718
Epoch: 80 | Iteration number: [150/4518] 3% | Training loss: 0.6914359899361928
Epoch: 80 | Iteration number: [160/4518] 3% | Training loss: 0.6910759069025516
Epoch: 80 | Iteration number: [170/4518] 3% | Training loss: 0.6908651807728936
Epoch: 80 | Iteration number: [180/4518] 3% | Training loss: 0.690646450387107
Epoch: 80 | Iteration number: [190/4518] 4% | Training loss: 0.6904192610790855
Epoch: 80 | Iteration number: [200/4518] 4% | Training loss: 0.6902412807941437
Epoch: 80 | Iteration number: [210/4518] 4% | Training loss: 0.6901124590919131
Epoch: 80 | Iteration number: [220/4518] 4% | Training loss: 0.6900108965960416
Epoch: 80 | Iteration number: [230/4518] 5% | Training loss: 0.6898627104966537
Epoch: 80 | Iteration number: [240/4518] 5% | Training loss: 0.6897245061894258
Epoch: 80 | Iteration number: [250/4518] 5% | Training loss: 0.6896247308254242
Epoch: 80 | Iteration number: [260/4518] 5% | Training loss: 0.6895394261066731
Epoch: 80 | Iteration number: [270/4518] 5% | Training loss: 0.6894688370051207
Epoch: 80 | Iteration number: [280/4518] 6% | Training loss: 0.6893503123096058
Epoch: 80 | Iteration number: [290/4518] 6% | Training loss: 0.6892558138946007
Epoch: 80 | Iteration number: [300/4518] 6% | Training loss: 0.6891827954848607
Epoch: 80 | Iteration number: [310/4518] 6% | Training loss: 0.6891318630787634
Epoch: 80 | Iteration number: [320/4518] 7% | Training loss: 0.6890318633988499
Epoch: 80 | Iteration number: [330/4518] 7% | Training loss: 0.6889565276377129
Epoch: 80 | Iteration number: [340/4518] 7% | Training loss: 0.688894996748251
Epoch: 80 | Iteration number: [350/4518] 7% | Training loss: 0.6888181725570134
Epoch: 80 | Iteration number: [360/4518] 7% | Training loss: 0.6887996819284227
Epoch: 80 | Iteration number: [370/4518] 8% | Training loss: 0.6887533679201796
Epoch: 80 | Iteration number: [380/4518] 8% | Training loss: 0.6887178703358299
Epoch: 80 | Iteration number: [390/4518] 8% | Training loss: 0.6886988043785095
Epoch: 80 | Iteration number: [400/4518] 8% | Training loss: 0.6886314597725868
Epoch: 80 | Iteration number: [410/4518] 9% | Training loss: 0.6886072228594524
Epoch: 80 | Iteration number: [420/4518] 9% | Training loss: 0.6885943439744767
Epoch: 80 | Iteration number: [430/4518] 9% | Training loss: 0.6885537893273109
Epoch: 80 | Iteration number: [440/4518] 9% | Training loss: 0.6885414122180505
Epoch: 80 | Iteration number: [450/4518] 9% | Training loss: 0.6885249596171908
Epoch: 80 | Iteration number: [460/4518] 10% | Training loss: 0.6884929803402527
Epoch: 80 | Iteration number: [470/4518] 10% | Training loss: 0.6884847487540955
Epoch: 80 | Iteration number: [480/4518] 10% | Training loss: 0.6884257857998212
Epoch: 80 | Iteration number: [490/4518] 10% | Training loss: 0.6884079601083483
Epoch: 80 | Iteration number: [500/4518] 11% | Training loss: 0.6884185893535614
Epoch: 80 | Iteration number: [510/4518] 11% | Training loss: 0.6883862372706918
Epoch: 80 | Iteration number: [520/4518] 11% | Training loss: 0.6883598045660899
Epoch: 80 | Iteration number: [530/4518] 11% | Training loss: 0.6883223032051662
Epoch: 80 | Iteration number: [540/4518] 11% | Training loss: 0.688282268135636
Epoch: 80 | Iteration number: [550/4518] 12% | Training loss: 0.6882231083783237
Epoch: 80 | Iteration number: [560/4518] 12% | Training loss: 0.6881781870765346
Epoch: 80 | Iteration number: [570/4518] 12% | Training loss: 0.688115350928223
Epoch: 80 | Iteration number: [580/4518] 12% | Training loss: 0.6880890546173885
Epoch: 80 | Iteration number: [590/4518] 13% | Training loss: 0.6880489687798387
Epoch: 80 | Iteration number: [600/4518] 13% | Training loss: 0.6880476455887159
Epoch: 80 | Iteration number: [610/4518] 13% | Training loss: 0.6880360718633308
Epoch: 80 | Iteration number: [620/4518] 13% | Training loss: 0.6880177689175452
Epoch: 80 | Iteration number: [630/4518] 13% | Training loss: 0.6880142349099356
Epoch: 80 | Iteration number: [640/4518] 14% | Training loss: 0.6879988812841475
Epoch: 80 | Iteration number: [650/4518] 14% | Training loss: 0.6879973952586834
Epoch: 80 | Iteration number: [660/4518] 14% | Training loss: 0.6879641683715763
Epoch: 80 | Iteration number: [670/4518] 14% | Training loss: 0.6879497438224393
Epoch: 80 | Iteration number: [680/4518] 15% | Training loss: 0.6879333853721619
Epoch: 80 | Iteration number: [690/4518] 15% | Training loss: 0.6879085167594577
Epoch: 80 | Iteration number: [700/4518] 15% | Training loss: 0.6878934400422233
Epoch: 80 | Iteration number: [710/4518] 15% | Training loss: 0.6878931962268453
Epoch: 80 | Iteration number: [720/4518] 15% | Training loss: 0.6878818762799104
Epoch: 80 | Iteration number: [730/4518] 16% | Training loss: 0.6878805636543117
Epoch: 80 | Iteration number: [740/4518] 16% | Training loss: 0.6878853262276263
Epoch: 80 | Iteration number: [750/4518] 16% | Training loss: 0.6878620977401734
Epoch: 80 | Iteration number: [760/4518] 16% | Training loss: 0.6878407276774707
Epoch: 80 | Iteration number: [770/4518] 17% | Training loss: 0.6878375721442235
Epoch: 80 | Iteration number: [780/4518] 17% | Training loss: 0.6878136028081943
Epoch: 80 | Iteration number: [790/4518] 17% | Training loss: 0.6877964418900164
Epoch: 80 | Iteration number: [800/4518] 17% | Training loss: 0.6877815124392509
Epoch: 80 | Iteration number: [810/4518] 17% | Training loss: 0.6877579276944384
Epoch: 80 | Iteration number: [820/4518] 18% | Training loss: 0.6877345530725107
Epoch: 80 | Iteration number: [830/4518] 18% | Training loss: 0.6877206224993051
Epoch: 80 | Iteration number: [840/4518] 18% | Training loss: 0.6877073588825408
Epoch: 80 | Iteration number: [850/4518] 18% | Training loss: 0.6877013284318587
Epoch: 80 | Iteration number: [860/4518] 19% | Training loss: 0.6876891445974971
Epoch: 80 | Iteration number: [870/4518] 19% | Training loss: 0.687695535709118
Epoch: 80 | Iteration number: [880/4518] 19% | Training loss: 0.6876930250362916
Epoch: 80 | Iteration number: [890/4518] 19% | Training loss: 0.6876782574680415
Epoch: 80 | Iteration number: [900/4518] 19% | Training loss: 0.6876605910725063
Epoch: 80 | Iteration number: [910/4518] 20% | Training loss: 0.6876590534225925
Epoch: 80 | Iteration number: [920/4518] 20% | Training loss: 0.6876413686119992
Epoch: 80 | Iteration number: [930/4518] 20% | Training loss: 0.687633127550925
Epoch: 80 | Iteration number: [940/4518] 20% | Training loss: 0.6876177969131064
Epoch: 80 | Iteration number: [950/4518] 21% | Training loss: 0.6875943872175718
Epoch: 80 | Iteration number: [960/4518] 21% | Training loss: 0.6875905993704995
Epoch: 80 | Iteration number: [970/4518] 21% | Training loss: 0.6875869273524924
Epoch: 80 | Iteration number: [980/4518] 21% | Training loss: 0.6875823346327762
Epoch: 80 | Iteration number: [990/4518] 21% | Training loss: 0.6875559847764294
Epoch: 80 | Iteration number: [1000/4518] 22% | Training loss: 0.6875256596207618
Epoch: 80 | Iteration number: [1010/4518] 22% | Training loss: 0.6875192774994539
Epoch: 80 | Iteration number: [1020/4518] 22% | Training loss: 0.6874901132840736
Epoch: 80 | Iteration number: [1030/4518] 22% | Training loss: 0.6874808224080836
Epoch: 80 | Iteration number: [1040/4518] 23% | Training loss: 0.6874714056459758
Epoch: 80 | Iteration number: [1050/4518] 23% | Training loss: 0.6874661618187314
Epoch: 80 | Iteration number: [1060/4518] 23% | Training loss: 0.6874522389668338
Epoch: 80 | Iteration number: [1070/4518] 23% | Training loss: 0.6874264270345741
Epoch: 80 | Iteration number: [1080/4518] 23% | Training loss: 0.6874192962491954
Epoch: 80 | Iteration number: [1090/4518] 24% | Training loss: 0.6873984855249388
Epoch: 80 | Iteration number: [1100/4518] 24% | Training loss: 0.6873948787017302
Epoch: 80 | Iteration number: [1110/4518] 24% | Training loss: 0.6873827961651054
Epoch: 80 | Iteration number: [1120/4518] 24% | Training loss: 0.6873834705246347
Epoch: 80 | Iteration number: [1130/4518] 25% | Training loss: 0.6873841891774034
Epoch: 80 | Iteration number: [1140/4518] 25% | Training loss: 0.6873864896987614
Epoch: 80 | Iteration number: [1150/4518] 25% | Training loss: 0.6873785578167957
Epoch: 80 | Iteration number: [1160/4518] 25% | Training loss: 0.6873683524029008
Epoch: 80 | Iteration number: [1170/4518] 25% | Training loss: 0.6873644557773557
Epoch: 80 | Iteration number: [1180/4518] 26% | Training loss: 0.6873474419116974
Epoch: 80 | Iteration number: [1190/4518] 26% | Training loss: 0.6873461758389192
Epoch: 80 | Iteration number: [1200/4518] 26% | Training loss: 0.6873419731358688
Epoch: 80 | Iteration number: [1210/4518] 26% | Training loss: 0.6873369783409371
Epoch: 80 | Iteration number: [1220/4518] 27% | Training loss: 0.6873304166266175
Epoch: 80 | Iteration number: [1230/4518] 27% | Training loss: 0.6873344022084058
Epoch: 80 | Iteration number: [1240/4518] 27% | Training loss: 0.687336502776992
Epoch: 80 | Iteration number: [1250/4518] 27% | Training loss: 0.6873351711750031
Epoch: 80 | Iteration number: [1260/4518] 27% | Training loss: 0.6873300545745425
Epoch: 80 | Iteration number: [1270/4518] 28% | Training loss: 0.6873295210008546
Epoch: 80 | Iteration number: [1280/4518] 28% | Training loss: 0.6873245855793357
Epoch: 80 | Iteration number: [1290/4518] 28% | Training loss: 0.6873251269030016
Epoch: 80 | Iteration number: [1300/4518] 28% | Training loss: 0.6873162729465044
Epoch: 80 | Iteration number: [1310/4518] 28% | Training loss: 0.6873124265943775
Epoch: 80 | Iteration number: [1320/4518] 29% | Training loss: 0.6873015191067349
Epoch: 80 | Iteration number: [1330/4518] 29% | Training loss: 0.6873015258545266
Epoch: 80 | Iteration number: [1340/4518] 29% | Training loss: 0.6872955638526091
Epoch: 80 | Iteration number: [1350/4518] 29% | Training loss: 0.6872937813953117
Epoch: 80 | Iteration number: [1360/4518] 30% | Training loss: 0.6872991174021188
Epoch: 80 | Iteration number: [1370/4518] 30% | Training loss: 0.6872999221304037
Epoch: 80 | Iteration number: [1380/4518] 30% | Training loss: 0.6872935713201329
Epoch: 80 | Iteration number: [1390/4518] 30% | Training loss: 0.6872964670761026
Epoch: 80 | Iteration number: [1400/4518] 30% | Training loss: 0.6872975785817419
Epoch: 80 | Iteration number: [1410/4518] 31% | Training loss: 0.6872878014618623
Epoch: 80 | Iteration number: [1420/4518] 31% | Training loss: 0.6872869646885026
Epoch: 80 | Iteration number: [1430/4518] 31% | Training loss: 0.6872811709250604
Epoch: 80 | Iteration number: [1440/4518] 31% | Training loss: 0.6872821069426007
Epoch: 80 | Iteration number: [1450/4518] 32% | Training loss: 0.68728312327944
Epoch: 80 | Iteration number: [1460/4518] 32% | Training loss: 0.6872692775236418
Epoch: 80 | Iteration number: [1470/4518] 32% | Training loss: 0.6872671774860953
Epoch: 80 | Iteration number: [1480/4518] 32% | Training loss: 0.6872586332060195
Epoch: 80 | Iteration number: [1490/4518] 32% | Training loss: 0.6872453785182646
Epoch: 80 | Iteration number: [1500/4518] 33% | Training loss: 0.6872421102126439
Epoch: 80 | Iteration number: [1510/4518] 33% | Training loss: 0.6872459191360221
Epoch: 80 | Iteration number: [1520/4518] 33% | Training loss: 0.6872376253730372
Epoch: 80 | Iteration number: [1530/4518] 33% | Training loss: 0.6872452109078176
Epoch: 80 | Iteration number: [1540/4518] 34% | Training loss: 0.6872495296326551
Epoch: 80 | Iteration number: [1550/4518] 34% | Training loss: 0.687256787477001
Epoch: 80 | Iteration number: [1560/4518] 34% | Training loss: 0.6872540661921868
Epoch: 80 | Iteration number: [1570/4518] 34% | Training loss: 0.6872461939313609
Epoch: 80 | Iteration number: [1580/4518] 34% | Training loss: 0.6872477457115922
Epoch: 80 | Iteration number: [1590/4518] 35% | Training loss: 0.6872418920573948
Epoch: 80 | Iteration number: [1600/4518] 35% | Training loss: 0.687237816862762
Epoch: 80 | Iteration number: [1610/4518] 35% | Training loss: 0.6872322076596088
Epoch: 80 | Iteration number: [1620/4518] 35% | Training loss: 0.6872290994282122
Epoch: 80 | Iteration number: [1630/4518] 36% | Training loss: 0.6872323977800966
Epoch: 80 | Iteration number: [1640/4518] 36% | Training loss: 0.6872343436610407
Epoch: 80 | Iteration number: [1650/4518] 36% | Training loss: 0.6872331379399155
Epoch: 80 | Iteration number: [1660/4518] 36% | Training loss: 0.6872375204979655
Epoch: 80 | Iteration number: [1670/4518] 36% | Training loss: 0.6872243184172465
Epoch: 80 | Iteration number: [1680/4518] 37% | Training loss: 0.6872194036131813
Epoch: 80 | Iteration number: [1690/4518] 37% | Training loss: 0.6872198358089966
Epoch: 80 | Iteration number: [1700/4518] 37% | Training loss: 0.6872262431944118
Epoch: 80 | Iteration number: [1710/4518] 37% | Training loss: 0.6872261161344093
Epoch: 80 | Iteration number: [1720/4518] 38% | Training loss: 0.6872191013984902
Epoch: 80 | Iteration number: [1730/4518] 38% | Training loss: 0.6872133854841221
Epoch: 80 | Iteration number: [1740/4518] 38% | Training loss: 0.6872070571471904
Epoch: 80 | Iteration number: [1750/4518] 38% | Training loss: 0.6872021831103734
Epoch: 80 | Iteration number: [1760/4518] 38% | Training loss: 0.6872009129348127
Epoch: 80 | Iteration number: [1770/4518] 39% | Training loss: 0.6872014081747518
Epoch: 80 | Iteration number: [1780/4518] 39% | Training loss: 0.6872008922059885
Epoch: 80 | Iteration number: [1790/4518] 39% | Training loss: 0.6872044222980904
Epoch: 80 | Iteration number: [1800/4518] 39% | Training loss: 0.687210098306338
Epoch: 80 | Iteration number: [1810/4518] 40% | Training loss: 0.687205279334474
Epoch: 80 | Iteration number: [1820/4518] 40% | Training loss: 0.6872052119328426
Epoch: 80 | Iteration number: [1830/4518] 40% | Training loss: 0.6872094211356887
Epoch: 80 | Iteration number: [1840/4518] 40% | Training loss: 0.6872071158950743
Epoch: 80 | Iteration number: [1850/4518] 40% | Training loss: 0.687202277860126
Epoch: 80 | Iteration number: [1860/4518] 41% | Training loss: 0.6872011454836014
Epoch: 80 | Iteration number: [1870/4518] 41% | Training loss: 0.6872020806220763
Epoch: 80 | Iteration number: [1880/4518] 41% | Training loss: 0.6871969071474481
Epoch: 80 | Iteration number: [1890/4518] 41% | Training loss: 0.6871950199048986
Epoch: 80 | Iteration number: [1900/4518] 42% | Training loss: 0.6871933049277256
Epoch: 80 | Iteration number: [1910/4518] 42% | Training loss: 0.6871914554328818
Epoch: 80 | Iteration number: [1920/4518] 42% | Training loss: 0.6871965507976711
Epoch: 80 | Iteration number: [1930/4518] 42% | Training loss: 0.68719775349365
Epoch: 80 | Iteration number: [1940/4518] 42% | Training loss: 0.6871938959532178
Epoch: 80 | Iteration number: [1950/4518] 43% | Training loss: 0.687183552797024
Epoch: 80 | Iteration number: [1960/4518] 43% | Training loss: 0.687171349142279
Epoch: 80 | Iteration number: [1970/4518] 43% | Training loss: 0.6871650178420362
Epoch: 80 | Iteration number: [1980/4518] 43% | Training loss: 0.6871576115338489
Epoch: 80 | Iteration number: [1990/4518] 44% | Training loss: 0.6871558818086307
Epoch: 80 | Iteration number: [2000/4518] 44% | Training loss: 0.68715466979146
Epoch: 80 | Iteration number: [2010/4518] 44% | Training loss: 0.6871536817123641
Epoch: 80 | Iteration number: [2020/4518] 44% | Training loss: 0.687154090109438
Epoch: 80 | Iteration number: [2030/4518] 44% | Training loss: 0.6871579762750071
Epoch: 80 | Iteration number: [2040/4518] 45% | Training loss: 0.6871600666759061
Epoch: 80 | Iteration number: [2050/4518] 45% | Training loss: 0.687158510684967
Epoch: 80 | Iteration number: [2060/4518] 45% | Training loss: 0.6871613497583612
Epoch: 80 | Iteration number: [2070/4518] 45% | Training loss: 0.6871603293407367
Epoch: 80 | Iteration number: [2080/4518] 46% | Training loss: 0.6871576780310044
Epoch: 80 | Iteration number: [2090/4518] 46% | Training loss: 0.6871583775184942
Epoch: 80 | Iteration number: [2100/4518] 46% | Training loss: 0.6871537316129321
Epoch: 80 | Iteration number: [2110/4518] 46% | Training loss: 0.6871550567342207
Epoch: 80 | Iteration number: [2120/4518] 46% | Training loss: 0.6871526477471838
Epoch: 80 | Iteration number: [2130/4518] 47% | Training loss: 0.6871523942466073
Epoch: 80 | Iteration number: [2140/4518] 47% | Training loss: 0.6871505044609587
Epoch: 80 | Iteration number: [2150/4518] 47% | Training loss: 0.6871448239060335
Epoch: 80 | Iteration number: [2160/4518] 47% | Training loss: 0.6871385733562487
Epoch: 80 | Iteration number: [2170/4518] 48% | Training loss: 0.6871397039857329
Epoch: 80 | Iteration number: [2180/4518] 48% | Training loss: 0.6871386315571059
Epoch: 80 | Iteration number: [2190/4518] 48% | Training loss: 0.6871343866330848
Epoch: 80 | Iteration number: [2200/4518] 48% | Training loss: 0.6871383511207321
Epoch: 80 | Iteration number: [2210/4518] 48% | Training loss: 0.687134325693096
Epoch: 80 | Iteration number: [2220/4518] 49% | Training loss: 0.6871350114946967
Epoch: 80 | Iteration number: [2230/4518] 49% | Training loss: 0.6871347873200215
Epoch: 80 | Iteration number: [2240/4518] 49% | Training loss: 0.6871369809444462
Epoch: 80 | Iteration number: [2250/4518] 49% | Training loss: 0.6871406556500329
Epoch: 80 | Iteration number: [2260/4518] 50% | Training loss: 0.6871400124995054
Epoch: 80 | Iteration number: [2270/4518] 50% | Training loss: 0.6871348090896522
Epoch: 80 | Iteration number: [2280/4518] 50% | Training loss: 0.6871392071508524
Epoch: 80 | Iteration number: [2290/4518] 50% | Training loss: 0.6871332692787637
Epoch: 80 | Iteration number: [2300/4518] 50% | Training loss: 0.687131463781647
Epoch: 80 | Iteration number: [2310/4518] 51% | Training loss: 0.6871307047414573
Epoch: 80 | Iteration number: [2320/4518] 51% | Training loss: 0.6871317311607558
Epoch: 80 | Iteration number: [2330/4518] 51% | Training loss: 0.68712801830963
Epoch: 80 | Iteration number: [2340/4518] 51% | Training loss: 0.687125523808675
Epoch: 80 | Iteration number: [2350/4518] 52% | Training loss: 0.6871247049849084
Epoch: 80 | Iteration number: [2360/4518] 52% | Training loss: 0.6871217329370773
Epoch: 80 | Iteration number: [2370/4518] 52% | Training loss: 0.6871204771321534
Epoch: 80 | Iteration number: [2380/4518] 52% | Training loss: 0.6871153139767526
Epoch: 80 | Iteration number: [2390/4518] 52% | Training loss: 0.687113193039116
Epoch: 80 | Iteration number: [2400/4518] 53% | Training loss: 0.6871134334802628
Epoch: 80 | Iteration number: [2410/4518] 53% | Training loss: 0.6871090023102108
Epoch: 80 | Iteration number: [2420/4518] 53% | Training loss: 0.6871009052292375
Epoch: 80 | Iteration number: [2430/4518] 53% | Training loss: 0.687100016800955
Epoch: 80 | Iteration number: [2440/4518] 54% | Training loss: 0.6871026841099145
Epoch: 80 | Iteration number: [2450/4518] 54% | Training loss: 0.6871028251064067
Epoch: 80 | Iteration number: [2460/4518] 54% | Training loss: 0.6871022538925574
Epoch: 80 | Iteration number: [2470/4518] 54% | Training loss: 0.6870982034968943
Epoch: 80 | Iteration number: [2480/4518] 54% | Training loss: 0.6870968918406194
Epoch: 80 | Iteration number: [2490/4518] 55% | Training loss: 0.6870957214430155
Epoch: 80 | Iteration number: [2500/4518] 55% | Training loss: 0.6870902097940444
Epoch: 80 | Iteration number: [2510/4518] 55% | Training loss: 0.6870890497211442
Epoch: 80 | Iteration number: [2520/4518] 55% | Training loss: 0.6870872216092215
Epoch: 80 | Iteration number: [2530/4518] 55% | Training loss: 0.6870853942844708
Epoch: 80 | Iteration number: [2540/4518] 56% | Training loss: 0.6870838526196367
Epoch: 80 | Iteration number: [2550/4518] 56% | Training loss: 0.6870813376529544
Epoch: 80 | Iteration number: [2560/4518] 56% | Training loss: 0.6870759200770408
Epoch: 80 | Iteration number: [2570/4518] 56% | Training loss: 0.687079187659438
Epoch: 80 | Iteration number: [2580/4518] 57% | Training loss: 0.6870812358089196
Epoch: 80 | Iteration number: [2590/4518] 57% | Training loss: 0.6870759264152483
Epoch: 80 | Iteration number: [2600/4518] 57% | Training loss: 0.6870759994479326
Epoch: 80 | Iteration number: [2610/4518] 57% | Training loss: 0.6870706895987193
Epoch: 80 | Iteration number: [2620/4518] 57% | Training loss: 0.687071437735594
Epoch: 80 | Iteration number: [2630/4518] 58% | Training loss: 0.6870683926366581
Epoch: 80 | Iteration number: [2640/4518] 58% | Training loss: 0.6870659404631817
Epoch: 80 | Iteration number: [2650/4518] 58% | Training loss: 0.6870647379587281
Epoch: 80 | Iteration number: [2660/4518] 58% | Training loss: 0.6870673303093229
Epoch: 80 | Iteration number: [2670/4518] 59% | Training loss: 0.6870632956983445
Epoch: 80 | Iteration number: [2680/4518] 59% | Training loss: 0.6870611075589906
Epoch: 80 | Iteration number: [2690/4518] 59% | Training loss: 0.6870572208028743
Epoch: 80 | Iteration number: [2700/4518] 59% | Training loss: 0.6870582472615772
Epoch: 80 | Iteration number: [2710/4518] 59% | Training loss: 0.6870568769444398
Epoch: 80 | Iteration number: [2720/4518] 60% | Training loss: 0.6870561496080722
Epoch: 80 | Iteration number: [2730/4518] 60% | Training loss: 0.6870600092760373
Epoch: 80 | Iteration number: [2740/4518] 60% | Training loss: 0.6870591213885885
Epoch: 80 | Iteration number: [2750/4518] 60% | Training loss: 0.687063117872585
Epoch: 80 | Iteration number: [2760/4518] 61% | Training loss: 0.6870601296424865
Epoch: 80 | Iteration number: [2770/4518] 61% | Training loss: 0.6870604813529266
Epoch: 80 | Iteration number: [2780/4518] 61% | Training loss: 0.687058819390887
Epoch: 80 | Iteration number: [2790/4518] 61% | Training loss: 0.687056510572365
Epoch: 80 | Iteration number: [2800/4518] 61% | Training loss: 0.6870600394904613
Epoch: 80 | Iteration number: [2810/4518] 62% | Training loss: 0.6870605257058059
Epoch: 80 | Iteration number: [2820/4518] 62% | Training loss: 0.6870565981095564
Epoch: 80 | Iteration number: [2830/4518] 62% | Training loss: 0.6870541059086264
Epoch: 80 | Iteration number: [2840/4518] 62% | Training loss: 0.687051706750628
Epoch: 80 | Iteration number: [2850/4518] 63% | Training loss: 0.6870507805598409
Epoch: 80 | Iteration number: [2860/4518] 63% | Training loss: 0.6870496821153415
Epoch: 80 | Iteration number: [2870/4518] 63% | Training loss: 0.6870503392161392
Epoch: 80 | Iteration number: [2880/4518] 63% | Training loss: 0.6870444427761767
Epoch: 80 | Iteration number: [2890/4518] 63% | Training loss: 0.6870434523041273
Epoch: 80 | Iteration number: [2900/4518] 64% | Training loss: 0.6870443102614633
Epoch: 80 | Iteration number: [2910/4518] 64% | Training loss: 0.6870414918435808
Epoch: 80 | Iteration number: [2920/4518] 64% | Training loss: 0.6870356705499022
Epoch: 80 | Iteration number: [2930/4518] 64% | Training loss: 0.6870332113915336
Epoch: 80 | Iteration number: [2940/4518] 65% | Training loss: 0.6870359340695297
Epoch: 80 | Iteration number: [2950/4518] 65% | Training loss: 0.6870323278742322
Epoch: 80 | Iteration number: [2960/4518] 65% | Training loss: 0.6870351812324008
Epoch: 80 | Iteration number: [2970/4518] 65% | Training loss: 0.6870330048530592
Epoch: 80 | Iteration number: [2980/4518] 65% | Training loss: 0.6870335352900844
Epoch: 80 | Iteration number: [2990/4518] 66% | Training loss: 0.6870356698099985
Epoch: 80 | Iteration number: [3000/4518] 66% | Training loss: 0.6870304730931918
Epoch: 80 | Iteration number: [3010/4518] 66% | Training loss: 0.6870324574435668
Epoch: 80 | Iteration number: [3020/4518] 66% | Training loss: 0.6870356905934037
Epoch: 80 | Iteration number: [3030/4518] 67% | Training loss: 0.6870389912388112
Epoch: 80 | Iteration number: [3040/4518] 67% | Training loss: 0.6870376729847569
Epoch: 80 | Iteration number: [3050/4518] 67% | Training loss: 0.6870371931889018
Epoch: 80 | Iteration number: [3060/4518] 67% | Training loss: 0.6870416909651039
Epoch: 80 | Iteration number: [3070/4518] 67% | Training loss: 0.6870375193485608
Epoch: 80 | Iteration number: [3080/4518] 68% | Training loss: 0.6870354823671379
Epoch: 80 | Iteration number: [3090/4518] 68% | Training loss: 0.687035380308682
Epoch: 80 | Iteration number: [3100/4518] 68% | Training loss: 0.6870323926979496
Epoch: 80 | Iteration number: [3110/4518] 68% | Training loss: 0.687034786859126
Epoch: 80 | Iteration number: [3120/4518] 69% | Training loss: 0.6870319248965153
Epoch: 80 | Iteration number: [3130/4518] 69% | Training loss: 0.6870307240051964
Epoch: 80 | Iteration number: [3140/4518] 69% | Training loss: 0.6870274848998732
Epoch: 80 | Iteration number: [3150/4518] 69% | Training loss: 0.6870283446047041
Epoch: 80 | Iteration number: [3160/4518] 69% | Training loss: 0.6870298654595508
Epoch: 80 | Iteration number: [3170/4518] 70% | Training loss: 0.6870274122393094
Epoch: 80 | Iteration number: [3180/4518] 70% | Training loss: 0.6870253658519601
Epoch: 80 | Iteration number: [3190/4518] 70% | Training loss: 0.6870208666242402
Epoch: 80 | Iteration number: [3200/4518] 70% | Training loss: 0.6870191737078131
Epoch: 80 | Iteration number: [3210/4518] 71% | Training loss: 0.687017223452482
Epoch: 80 | Iteration number: [3220/4518] 71% | Training loss: 0.6870124346721246
Epoch: 80 | Iteration number: [3230/4518] 71% | Training loss: 0.687013158783455
Epoch: 80 | Iteration number: [3240/4518] 71% | Training loss: 0.6870135462946362
Epoch: 80 | Iteration number: [3250/4518] 71% | Training loss: 0.687015162064479
Epoch: 80 | Iteration number: [3260/4518] 72% | Training loss: 0.6870095025359487
Epoch: 80 | Iteration number: [3270/4518] 72% | Training loss: 0.6870093135111922
Epoch: 80 | Iteration number: [3280/4518] 72% | Training loss: 0.6870050597845054
Epoch: 80 | Iteration number: [3290/4518] 72% | Training loss: 0.6870036224826128
Epoch: 80 | Iteration number: [3300/4518] 73% | Training loss: 0.6870056015072447
Epoch: 80 | Iteration number: [3310/4518] 73% | Training loss: 0.6870044469833374
Epoch: 80 | Iteration number: [3320/4518] 73% | Training loss: 0.6870001951075462
Epoch: 80 | Iteration number: [3330/4518] 73% | Training loss: 0.6869962604733201
Epoch: 80 | Iteration number: [3340/4518] 73% | Training loss: 0.6869997416427749
Epoch: 80 | Iteration number: [3350/4518] 74% | Training loss: 0.687000532168061
Epoch: 80 | Iteration number: [3360/4518] 74% | Training loss: 0.6869981545067969
Epoch: 80 | Iteration number: [3370/4518] 74% | Training loss: 0.6870023986175435
Epoch: 80 | Iteration number: [3380/4518] 74% | Training loss: 0.6870027431193189
Epoch: 80 | Iteration number: [3390/4518] 75% | Training loss: 0.6870022591236419
Epoch: 80 | Iteration number: [3400/4518] 75% | Training loss: 0.6869987477274502
Epoch: 80 | Iteration number: [3410/4518] 75% | Training loss: 0.6869980444831233
Epoch: 80 | Iteration number: [3420/4518] 75% | Training loss: 0.686998028835358
Epoch: 80 | Iteration number: [3430/4518] 75% | Training loss: 0.6869955509292837
Epoch: 80 | Iteration number: [3440/4518] 76% | Training loss: 0.6869949824588243
Epoch: 80 | Iteration number: [3450/4518] 76% | Training loss: 0.6869941799191461
Epoch: 80 | Iteration number: [3460/4518] 76% | Training loss: 0.6869932974005021
Epoch: 80 | Iteration number: [3470/4518] 76% | Training loss: 0.686987944415392
Epoch: 80 | Iteration number: [3480/4518] 77% | Training loss: 0.6869877720701283
Epoch: 80 | Iteration number: [3490/4518] 77% | Training loss: 0.686985806937204
Epoch: 80 | Iteration number: [3500/4518] 77% | Training loss: 0.6869802414349148
Epoch: 80 | Iteration number: [3510/4518] 77% | Training loss: 0.686980098859537
Epoch: 80 | Iteration number: [3520/4518] 77% | Training loss: 0.6869771001183174
Epoch: 80 | Iteration number: [3530/4518] 78% | Training loss: 0.6869768966358715
Epoch: 80 | Iteration number: [3540/4518] 78% | Training loss: 0.6869763342337419
Epoch: 80 | Iteration number: [3550/4518] 78% | Training loss: 0.6869805269509973
Epoch: 80 | Iteration number: [3560/4518] 78% | Training loss: 0.6869783159052388
Epoch: 80 | Iteration number: [3570/4518] 79% | Training loss: 0.6869799676228638
Epoch: 80 | Iteration number: [3580/4518] 79% | Training loss: 0.6869773140666205
Epoch: 80 | Iteration number: [3590/4518] 79% | Training loss: 0.6869774335108095
Epoch: 80 | Iteration number: [3600/4518] 79% | Training loss: 0.6869751915832361
Epoch: 80 | Iteration number: [3610/4518] 79% | Training loss: 0.6869746224206571
Epoch: 80 | Iteration number: [3620/4518] 80% | Training loss: 0.6869750806475212
Epoch: 80 | Iteration number: [3630/4518] 80% | Training loss: 0.6869696088566267
Epoch: 80 | Iteration number: [3640/4518] 80% | Training loss: 0.6869646507305104
Epoch: 80 | Iteration number: [3650/4518] 80% | Training loss: 0.6869680867946312
Epoch: 80 | Iteration number: [3660/4518] 81% | Training loss: 0.6869675168737036
Epoch: 80 | Iteration number: [3670/4518] 81% | Training loss: 0.6869696861067001
Epoch: 80 | Iteration number: [3680/4518] 81% | Training loss: 0.6869658265100873
Epoch: 80 | Iteration number: [3690/4518] 81% | Training loss: 0.6869666576062438
Epoch: 80 | Iteration number: [3700/4518] 81% | Training loss: 0.6869615138704712
Epoch: 80 | Iteration number: [3710/4518] 82% | Training loss: 0.6869619266684808
Epoch: 80 | Iteration number: [3720/4518] 82% | Training loss: 0.6869629890207322
Epoch: 80 | Iteration number: [3730/4518] 82% | Training loss: 0.6869624102403268
Epoch: 80 | Iteration number: [3740/4518] 82% | Training loss: 0.6869581190181926
Epoch: 80 | Iteration number: [3750/4518] 83% | Training loss: 0.6869591213862101
Epoch: 80 | Iteration number: [3760/4518] 83% | Training loss: 0.6869570890481168
Epoch: 80 | Iteration number: [3770/4518] 83% | Training loss: 0.68695761830168
Epoch: 80 | Iteration number: [3780/4518] 83% | Training loss: 0.6869593699300099
Epoch: 80 | Iteration number: [3790/4518] 83% | Training loss: 0.6869577378742299
Epoch: 80 | Iteration number: [3800/4518] 84% | Training loss: 0.6869547787151838
Epoch: 80 | Iteration number: [3810/4518] 84% | Training loss: 0.6869505020577138
Epoch: 80 | Iteration number: [3820/4518] 84% | Training loss: 0.686948517901111
Epoch: 80 | Iteration number: [3830/4518] 84% | Training loss: 0.686945038411387
Epoch: 80 | Iteration number: [3840/4518] 84% | Training loss: 0.6869462501878539
Epoch: 80 | Iteration number: [3850/4518] 85% | Training loss: 0.6869462245315701
Epoch: 80 | Iteration number: [3860/4518] 85% | Training loss: 0.6869461529921991
Epoch: 80 | Iteration number: [3870/4518] 85% | Training loss: 0.6869428385443773
Epoch: 80 | Iteration number: [3880/4518] 85% | Training loss: 0.6869460688731105
Epoch: 80 | Iteration number: [3890/4518] 86% | Training loss: 0.6869490347821792
Epoch: 80 | Iteration number: [3900/4518] 86% | Training loss: 0.6869492655075513
Epoch: 80 | Iteration number: [3910/4518] 86% | Training loss: 0.6869474289209946
Epoch: 80 | Iteration number: [3920/4518] 86% | Training loss: 0.6869462452068621
Epoch: 80 | Iteration number: [3930/4518] 86% | Training loss: 0.686944300527791
Epoch: 80 | Iteration number: [3940/4518] 87% | Training loss: 0.6869442874102423
Epoch: 80 | Iteration number: [3950/4518] 87% | Training loss: 0.6869435441041295
Epoch: 80 | Iteration number: [3960/4518] 87% | Training loss: 0.6869453931547175
Epoch: 80 | Iteration number: [3970/4518] 87% | Training loss: 0.6869462297755465
Epoch: 80 | Iteration number: [3980/4518] 88% | Training loss: 0.6869451469662201
Epoch: 80 | Iteration number: [3990/4518] 88% | Training loss: 0.6869462320081572
Epoch: 80 | Iteration number: [4000/4518] 88% | Training loss: 0.6869446981996298
Epoch: 80 | Iteration number: [4010/4518] 88% | Training loss: 0.6869433463808902
Epoch: 80 | Iteration number: [4020/4518] 88% | Training loss: 0.6869440852706112
Epoch: 80 | Iteration number: [4030/4518] 89% | Training loss: 0.6869457643617767
Epoch: 80 | Iteration number: [4040/4518] 89% | Training loss: 0.6869449948172758
Epoch: 80 | Iteration number: [4050/4518] 89% | Training loss: 0.6869468425085515
Epoch: 80 | Iteration number: [4060/4518] 89% | Training loss: 0.6869464550259078
Epoch: 80 | Iteration number: [4070/4518] 90% | Training loss: 0.6869471127336676
Epoch: 80 | Iteration number: [4080/4518] 90% | Training loss: 0.6869448544201897
Epoch: 80 | Iteration number: [4090/4518] 90% | Training loss: 0.6869429132757676
Epoch: 80 | Iteration number: [4100/4518] 90% | Training loss: 0.6869421173595801
Epoch: 80 | Iteration number: [4110/4518] 90% | Training loss: 0.6869432889777088
Epoch: 80 | Iteration number: [4120/4518] 91% | Training loss: 0.686942568045218
Epoch: 80 | Iteration number: [4130/4518] 91% | Training loss: 0.68694093415004
Epoch: 80 | Iteration number: [4140/4518] 91% | Training loss: 0.6869382135534056
Epoch: 80 | Iteration number: [4150/4518] 91% | Training loss: 0.6869391164722213
Epoch: 80 | Iteration number: [4160/4518] 92% | Training loss: 0.686938702673293
Epoch: 80 | Iteration number: [4170/4518] 92% | Training loss: 0.6869410287276161
Epoch: 80 | Iteration number: [4180/4518] 92% | Training loss: 0.6869387574030452
Epoch: 80 | Iteration number: [4190/4518] 92% | Training loss: 0.6869397064239712
Epoch: 80 | Iteration number: [4200/4518] 92% | Training loss: 0.686940085646652
Epoch: 80 | Iteration number: [4210/4518] 93% | Training loss: 0.6869409124528427
Epoch: 80 | Iteration number: [4220/4518] 93% | Training loss: 0.6869419409906695
Epoch: 80 | Iteration number: [4230/4518] 93% | Training loss: 0.6869422402928625
Epoch: 80 | Iteration number: [4240/4518] 93% | Training loss: 0.6869410238176022
Epoch: 80 | Iteration number: [4250/4518] 94% | Training loss: 0.6869408387436586
Epoch: 80 | Iteration number: [4260/4518] 94% | Training loss: 0.686943697803457
Epoch: 80 | Iteration number: [4270/4518] 94% | Training loss: 0.6869445010147274
Epoch: 80 | Iteration number: [4280/4518] 94% | Training loss: 0.6869415551006237
Epoch: 80 | Iteration number: [4290/4518] 94% | Training loss: 0.6869404199240091
Epoch: 80 | Iteration number: [4300/4518] 95% | Training loss: 0.6869423304602157
Epoch: 80 | Iteration number: [4310/4518] 95% | Training loss: 0.6869404939515408
Epoch: 80 | Iteration number: [4320/4518] 95% | Training loss: 0.6869387100554175
Epoch: 80 | Iteration number: [4330/4518] 95% | Training loss: 0.6869372892737664
Epoch: 80 | Iteration number: [4340/4518] 96% | Training loss: 0.6869381005038864
Epoch: 80 | Iteration number: [4350/4518] 96% | Training loss: 0.6869342373705458
Epoch: 80 | Iteration number: [4360/4518] 96% | Training loss: 0.686933292229788
Epoch: 80 | Iteration number: [4370/4518] 96% | Training loss: 0.6869327559896683
Epoch: 80 | Iteration number: [4380/4518] 96% | Training loss: 0.6869299254869217
Epoch: 80 | Iteration number: [4390/4518] 97% | Training loss: 0.6869299745098062
Epoch: 80 | Iteration number: [4400/4518] 97% | Training loss: 0.6869325039332563
Epoch: 80 | Iteration number: [4410/4518] 97% | Training loss: 0.6869324552904722
Epoch: 80 | Iteration number: [4420/4518] 97% | Training loss: 0.6869333201134367
Epoch: 80 | Iteration number: [4430/4518] 98% | Training loss: 0.686932375065091
Epoch: 80 | Iteration number: [4440/4518] 98% | Training loss: 0.68693135416991
Epoch: 80 | Iteration number: [4450/4518] 98% | Training loss: 0.6869286448500129
Epoch: 80 | Iteration number: [4460/4518] 98% | Training loss: 0.6869245373881986
Epoch: 80 | Iteration number: [4470/4518] 98% | Training loss: 0.6869221335556149
Epoch: 80 | Iteration number: [4480/4518] 99% | Training loss: 0.6869230776359992
Epoch: 80 | Iteration number: [4490/4518] 99% | Training loss: 0.6869197403136765
Epoch: 80 | Iteration number: [4500/4518] 99% | Training loss: 0.6869208550188276
Epoch: 80 | Iteration number: [4510/4518] 99% | Training loss: 0.6869211395933993

 End of epoch: 80 | Train Loss: 0.68676992939499 | Training Time: 640 

 End of epoch: 80 | Eval Loss: 0.6899697452175374 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/4518] 0% | Training loss: 0.7556652367115021
Epoch: 81 | Iteration number: [20/4518] 0% | Training loss: 0.7211863219738006
Epoch: 81 | Iteration number: [30/4518] 0% | Training loss: 0.7096692502498627
Epoch: 81 | Iteration number: [40/4518] 0% | Training loss: 0.7041684150695801
Epoch: 81 | Iteration number: [50/4518] 1% | Training loss: 0.7006092941761017
Epoch: 81 | Iteration number: [60/4518] 1% | Training loss: 0.6985078463951747
Epoch: 81 | Iteration number: [70/4518] 1% | Training loss: 0.6966856036867414
Epoch: 81 | Iteration number: [80/4518] 1% | Training loss: 0.6954721823334694
Epoch: 81 | Iteration number: [90/4518] 1% | Training loss: 0.6944711446762085
Epoch: 81 | Iteration number: [100/4518] 2% | Training loss: 0.693654528260231
Epoch: 81 | Iteration number: [110/4518] 2% | Training loss: 0.6928604852069508
Epoch: 81 | Iteration number: [120/4518] 2% | Training loss: 0.6923472786943118
Epoch: 81 | Iteration number: [130/4518] 2% | Training loss: 0.6919449847478133
Epoch: 81 | Iteration number: [140/4518] 3% | Training loss: 0.6916077188083104
Epoch: 81 | Iteration number: [150/4518] 3% | Training loss: 0.6913601211706797
Epoch: 81 | Iteration number: [160/4518] 3% | Training loss: 0.69105384349823
Epoch: 81 | Iteration number: [170/4518] 3% | Training loss: 0.690817898161271
Epoch: 81 | Iteration number: [180/4518] 3% | Training loss: 0.6905062748326196
Epoch: 81 | Iteration number: [190/4518] 4% | Training loss: 0.6903179259676683
Epoch: 81 | Iteration number: [200/4518] 4% | Training loss: 0.6901442050933838
Epoch: 81 | Iteration number: [210/4518] 4% | Training loss: 0.6900185409046354
Epoch: 81 | Iteration number: [220/4518] 4% | Training loss: 0.6898361322554675
Epoch: 81 | Iteration number: [230/4518] 5% | Training loss: 0.6896865515605263
Epoch: 81 | Iteration number: [240/4518] 5% | Training loss: 0.6896113959451516
Epoch: 81 | Iteration number: [250/4518] 5% | Training loss: 0.6894583332538605
Epoch: 81 | Iteration number: [260/4518] 5% | Training loss: 0.6893427287156765
Epoch: 81 | Iteration number: [270/4518] 5% | Training loss: 0.6892341514428456
Epoch: 81 | Iteration number: [280/4518] 6% | Training loss: 0.6891403181212289
Epoch: 81 | Iteration number: [290/4518] 6% | Training loss: 0.6890930697835725
Epoch: 81 | Iteration number: [300/4518] 6% | Training loss: 0.6890329913298289
Epoch: 81 | Iteration number: [310/4518] 6% | Training loss: 0.6889331075452989
Epoch: 81 | Iteration number: [320/4518] 7% | Training loss: 0.6888663431629538
Epoch: 81 | Iteration number: [330/4518] 7% | Training loss: 0.6888088526147784
Epoch: 81 | Iteration number: [340/4518] 7% | Training loss: 0.688776225026916
Epoch: 81 | Iteration number: [350/4518] 7% | Training loss: 0.688683225767953
Epoch: 81 | Iteration number: [360/4518] 7% | Training loss: 0.6886520655618773
Epoch: 81 | Iteration number: [370/4518] 8% | Training loss: 0.6886171158906575
Epoch: 81 | Iteration number: [380/4518] 8% | Training loss: 0.6885579278594569
Epoch: 81 | Iteration number: [390/4518] 8% | Training loss: 0.6885055072796651
Epoch: 81 | Iteration number: [400/4518] 8% | Training loss: 0.6884661282598973
Epoch: 81 | Iteration number: [410/4518] 9% | Training loss: 0.6884638678736803
Epoch: 81 | Iteration number: [420/4518] 9% | Training loss: 0.6884331521533784
Epoch: 81 | Iteration number: [430/4518] 9% | Training loss: 0.6883944573790528
Epoch: 81 | Iteration number: [440/4518] 9% | Training loss: 0.6883520765738054
Epoch: 81 | Iteration number: [450/4518] 9% | Training loss: 0.6883212224642435
Epoch: 81 | Iteration number: [460/4518] 10% | Training loss: 0.6882751017808915
Epoch: 81 | Iteration number: [470/4518] 10% | Training loss: 0.6882546873802834
Epoch: 81 | Iteration number: [480/4518] 10% | Training loss: 0.6882514754931132
Epoch: 81 | Iteration number: [490/4518] 10% | Training loss: 0.6882392374836669
Epoch: 81 | Iteration number: [500/4518] 11% | Training loss: 0.6882068053483963
Epoch: 81 | Iteration number: [510/4518] 11% | Training loss: 0.6882010785972371
Epoch: 81 | Iteration number: [520/4518] 11% | Training loss: 0.6881642965170053
Epoch: 81 | Iteration number: [530/4518] 11% | Training loss: 0.6881163567866919
Epoch: 81 | Iteration number: [540/4518] 11% | Training loss: 0.6880961365169949
Epoch: 81 | Iteration number: [550/4518] 12% | Training loss: 0.6880678369782188
Epoch: 81 | Iteration number: [560/4518] 12% | Training loss: 0.6880473377449172
Epoch: 81 | Iteration number: [570/4518] 12% | Training loss: 0.6880047231389765
Epoch: 81 | Iteration number: [580/4518] 12% | Training loss: 0.6880043848835189
Epoch: 81 | Iteration number: [590/4518] 13% | Training loss: 0.6879737982305429
Epoch: 81 | Iteration number: [600/4518] 13% | Training loss: 0.6879658591747284
Epoch: 81 | Iteration number: [610/4518] 13% | Training loss: 0.6879427511183942
Epoch: 81 | Iteration number: [620/4518] 13% | Training loss: 0.6879270357470358
Epoch: 81 | Iteration number: [630/4518] 13% | Training loss: 0.6878972113132477
Epoch: 81 | Iteration number: [640/4518] 14% | Training loss: 0.6878951037302613
Epoch: 81 | Iteration number: [650/4518] 14% | Training loss: 0.687892302274704
Epoch: 81 | Iteration number: [660/4518] 14% | Training loss: 0.6878844672983343
Epoch: 81 | Iteration number: [670/4518] 14% | Training loss: 0.6878716907394467
Epoch: 81 | Iteration number: [680/4518] 15% | Training loss: 0.6878534365226241
Epoch: 81 | Iteration number: [690/4518] 15% | Training loss: 0.687827978272369
Epoch: 81 | Iteration number: [700/4518] 15% | Training loss: 0.6878023626974651
Epoch: 81 | Iteration number: [710/4518] 15% | Training loss: 0.687795000093084
Epoch: 81 | Iteration number: [720/4518] 15% | Training loss: 0.6877783985601531
Epoch: 81 | Iteration number: [730/4518] 16% | Training loss: 0.6877646558088799
Epoch: 81 | Iteration number: [740/4518] 16% | Training loss: 0.6877485139949902
Epoch: 81 | Iteration number: [750/4518] 16% | Training loss: 0.6877319413026174
Epoch: 81 | Iteration number: [760/4518] 16% | Training loss: 0.6877141153341846
Epoch: 81 | Iteration number: [770/4518] 17% | Training loss: 0.6877017634255546
Epoch: 81 | Iteration number: [780/4518] 17% | Training loss: 0.6876993021139732
Epoch: 81 | Iteration number: [790/4518] 17% | Training loss: 0.6876805749120591
Epoch: 81 | Iteration number: [800/4518] 17% | Training loss: 0.6876560567319393
Epoch: 81 | Iteration number: [810/4518] 17% | Training loss: 0.6876480183483642
Epoch: 81 | Iteration number: [820/4518] 18% | Training loss: 0.6876338574217586
Epoch: 81 | Iteration number: [830/4518] 18% | Training loss: 0.6876214237816363
Epoch: 81 | Iteration number: [840/4518] 18% | Training loss: 0.6876119290079389
Epoch: 81 | Iteration number: [850/4518] 18% | Training loss: 0.6875873257833368
Epoch: 81 | Iteration number: [860/4518] 19% | Training loss: 0.6875642751538477
Epoch: 81 | Iteration number: [870/4518] 19% | Training loss: 0.6875505492605012
Epoch: 81 | Iteration number: [880/4518] 19% | Training loss: 0.6875444275411693
Epoch: 81 | Iteration number: [890/4518] 19% | Training loss: 0.6875290375747037
Epoch: 81 | Iteration number: [900/4518] 19% | Training loss: 0.6875242222017712
Epoch: 81 | Iteration number: [910/4518] 20% | Training loss: 0.6875237214696276
Epoch: 81 | Iteration number: [920/4518] 20% | Training loss: 0.687522614909255
Epoch: 81 | Iteration number: [930/4518] 20% | Training loss: 0.6875160107689519
Epoch: 81 | Iteration number: [940/4518] 20% | Training loss: 0.6875168039443645
Epoch: 81 | Iteration number: [950/4518] 21% | Training loss: 0.6875075062952544
Epoch: 81 | Iteration number: [960/4518] 21% | Training loss: 0.6874911978219946
Epoch: 81 | Iteration number: [970/4518] 21% | Training loss: 0.6874951648957951
Epoch: 81 | Iteration number: [980/4518] 21% | Training loss: 0.6874782624901558
Epoch: 81 | Iteration number: [990/4518] 21% | Training loss: 0.687469619512558
Epoch: 81 | Iteration number: [1000/4518] 22% | Training loss: 0.6874574826359748
Epoch: 81 | Iteration number: [1010/4518] 22% | Training loss: 0.6874308296949556
Epoch: 81 | Iteration number: [1020/4518] 22% | Training loss: 0.6874142960006115
Epoch: 81 | Iteration number: [1030/4518] 22% | Training loss: 0.6874041595505279
Epoch: 81 | Iteration number: [1040/4518] 23% | Training loss: 0.6873918591783597
Epoch: 81 | Iteration number: [1050/4518] 23% | Training loss: 0.6873958980469477
Epoch: 81 | Iteration number: [1060/4518] 23% | Training loss: 0.6873981991466486
Epoch: 81 | Iteration number: [1070/4518] 23% | Training loss: 0.6873962218516341
Epoch: 81 | Iteration number: [1080/4518] 23% | Training loss: 0.687402057868463
Epoch: 81 | Iteration number: [1090/4518] 24% | Training loss: 0.6873906742542162
Epoch: 81 | Iteration number: [1100/4518] 24% | Training loss: 0.6873840151591735
Epoch: 81 | Iteration number: [1110/4518] 24% | Training loss: 0.6873730741642617
Epoch: 81 | Iteration number: [1120/4518] 24% | Training loss: 0.6873714430523771
Epoch: 81 | Iteration number: [1130/4518] 25% | Training loss: 0.6873693841748533
Epoch: 81 | Iteration number: [1140/4518] 25% | Training loss: 0.6873577779845188
Epoch: 81 | Iteration number: [1150/4518] 25% | Training loss: 0.687344379062238
Epoch: 81 | Iteration number: [1160/4518] 25% | Training loss: 0.6873347079445575
Epoch: 81 | Iteration number: [1170/4518] 25% | Training loss: 0.6873327242003546
Epoch: 81 | Iteration number: [1180/4518] 26% | Training loss: 0.6873230358301583
Epoch: 81 | Iteration number: [1190/4518] 26% | Training loss: 0.6873085846420096
Epoch: 81 | Iteration number: [1200/4518] 26% | Training loss: 0.6872943384448688
Epoch: 81 | Iteration number: [1210/4518] 26% | Training loss: 0.6872859012982077
Epoch: 81 | Iteration number: [1220/4518] 27% | Training loss: 0.6872818494429354
Epoch: 81 | Iteration number: [1230/4518] 27% | Training loss: 0.6872881877228496
Epoch: 81 | Iteration number: [1240/4518] 27% | Training loss: 0.687279306256002
Epoch: 81 | Iteration number: [1250/4518] 27% | Training loss: 0.6872705301761627
Epoch: 81 | Iteration number: [1260/4518] 27% | Training loss: 0.6872581887339789
Epoch: 81 | Iteration number: [1270/4518] 28% | Training loss: 0.6872607386487676
Epoch: 81 | Iteration number: [1280/4518] 28% | Training loss: 0.6872565216384828
Epoch: 81 | Iteration number: [1290/4518] 28% | Training loss: 0.6872446621573248
Epoch: 81 | Iteration number: [1300/4518] 28% | Training loss: 0.6872404891711015
Epoch: 81 | Iteration number: [1310/4518] 28% | Training loss: 0.6872397994722119
Epoch: 81 | Iteration number: [1320/4518] 29% | Training loss: 0.6872409408291181
Epoch: 81 | Iteration number: [1330/4518] 29% | Training loss: 0.6872333243825381
Epoch: 81 | Iteration number: [1340/4518] 29% | Training loss: 0.6872334661323632
Epoch: 81 | Iteration number: [1350/4518] 29% | Training loss: 0.6872310532905437
Epoch: 81 | Iteration number: [1360/4518] 30% | Training loss: 0.6872275704846663
Epoch: 81 | Iteration number: [1370/4518] 30% | Training loss: 0.6872269429429604
Epoch: 81 | Iteration number: [1380/4518] 30% | Training loss: 0.6872237789458123
Epoch: 81 | Iteration number: [1390/4518] 30% | Training loss: 0.687215258835031
Epoch: 81 | Iteration number: [1400/4518] 30% | Training loss: 0.687206232036863
Epoch: 81 | Iteration number: [1410/4518] 31% | Training loss: 0.6871926514814931
Epoch: 81 | Iteration number: [1420/4518] 31% | Training loss: 0.6871821657033034
Epoch: 81 | Iteration number: [1430/4518] 31% | Training loss: 0.6871723881551436
Epoch: 81 | Iteration number: [1440/4518] 31% | Training loss: 0.6871704327563445
Epoch: 81 | Iteration number: [1450/4518] 32% | Training loss: 0.6871735729842351
Epoch: 81 | Iteration number: [1460/4518] 32% | Training loss: 0.6871661723068315
Epoch: 81 | Iteration number: [1470/4518] 32% | Training loss: 0.6871598379952567
Epoch: 81 | Iteration number: [1480/4518] 32% | Training loss: 0.687164208574875
Epoch: 81 | Iteration number: [1490/4518] 32% | Training loss: 0.687153444674191
Epoch: 81 | Iteration number: [1500/4518] 33% | Training loss: 0.6871464562416076
Epoch: 81 | Iteration number: [1510/4518] 33% | Training loss: 0.687146291827524
Epoch: 81 | Iteration number: [1520/4518] 33% | Training loss: 0.6871375510174977
Epoch: 81 | Iteration number: [1530/4518] 33% | Training loss: 0.6871417955635419
Epoch: 81 | Iteration number: [1540/4518] 34% | Training loss: 0.6871280742156041
Epoch: 81 | Iteration number: [1550/4518] 34% | Training loss: 0.6871239494892859
Epoch: 81 | Iteration number: [1560/4518] 34% | Training loss: 0.6871186235776314
Epoch: 81 | Iteration number: [1570/4518] 34% | Training loss: 0.6871163034135369
Epoch: 81 | Iteration number: [1580/4518] 34% | Training loss: 0.6871106550663333
Epoch: 81 | Iteration number: [1590/4518] 35% | Training loss: 0.6871046720060913
Epoch: 81 | Iteration number: [1600/4518] 35% | Training loss: 0.6871043014526367
Epoch: 81 | Iteration number: [1610/4518] 35% | Training loss: 0.6870971340570391
Epoch: 81 | Iteration number: [1620/4518] 35% | Training loss: 0.6870988377818354
Epoch: 81 | Iteration number: [1630/4518] 36% | Training loss: 0.6870905844711819
Epoch: 81 | Iteration number: [1640/4518] 36% | Training loss: 0.6870847147048973
Epoch: 81 | Iteration number: [1650/4518] 36% | Training loss: 0.687083344929146
Epoch: 81 | Iteration number: [1660/4518] 36% | Training loss: 0.6870829099991236
Epoch: 81 | Iteration number: [1670/4518] 36% | Training loss: 0.6870813205213604
Epoch: 81 | Iteration number: [1680/4518] 37% | Training loss: 0.6870837350686391
Epoch: 81 | Iteration number: [1690/4518] 37% | Training loss: 0.6870875380448336
Epoch: 81 | Iteration number: [1700/4518] 37% | Training loss: 0.6870939850456574
Epoch: 81 | Iteration number: [1710/4518] 37% | Training loss: 0.6870924811962752
Epoch: 81 | Iteration number: [1720/4518] 38% | Training loss: 0.6870891354804816
Epoch: 81 | Iteration number: [1730/4518] 38% | Training loss: 0.6870855176379915
Epoch: 81 | Iteration number: [1740/4518] 38% | Training loss: 0.6870800671221196
Epoch: 81 | Iteration number: [1750/4518] 38% | Training loss: 0.6870889363629478
Epoch: 81 | Iteration number: [1760/4518] 38% | Training loss: 0.6870798032053492
Epoch: 81 | Iteration number: [1770/4518] 39% | Training loss: 0.6870826656198771
Epoch: 81 | Iteration number: [1780/4518] 39% | Training loss: 0.6870795688937219
Epoch: 81 | Iteration number: [1790/4518] 39% | Training loss: 0.6870755707751439
Epoch: 81 | Iteration number: [1800/4518] 39% | Training loss: 0.6870726130737199
Epoch: 81 | Iteration number: [1810/4518] 40% | Training loss: 0.6870681205507141
Epoch: 81 | Iteration number: [1820/4518] 40% | Training loss: 0.6870690839958715
Epoch: 81 | Iteration number: [1830/4518] 40% | Training loss: 0.6870658652378562
Epoch: 81 | Iteration number: [1840/4518] 40% | Training loss: 0.6870684522649516
Epoch: 81 | Iteration number: [1850/4518] 40% | Training loss: 0.6870689984270044
Epoch: 81 | Iteration number: [1860/4518] 41% | Training loss: 0.6870700968209134
Epoch: 81 | Iteration number: [1870/4518] 41% | Training loss: 0.6870707640992129
Epoch: 81 | Iteration number: [1880/4518] 41% | Training loss: 0.6870672778880342
Epoch: 81 | Iteration number: [1890/4518] 41% | Training loss: 0.6870673478280426
Epoch: 81 | Iteration number: [1900/4518] 42% | Training loss: 0.6870694393546958
Epoch: 81 | Iteration number: [1910/4518] 42% | Training loss: 0.6870695809107177
Epoch: 81 | Iteration number: [1920/4518] 42% | Training loss: 0.6870721808324257
Epoch: 81 | Iteration number: [1930/4518] 42% | Training loss: 0.6870767996101181
Epoch: 81 | Iteration number: [1940/4518] 42% | Training loss: 0.687080467484661
Epoch: 81 | Iteration number: [1950/4518] 43% | Training loss: 0.6870802923043569
Epoch: 81 | Iteration number: [1960/4518] 43% | Training loss: 0.6870758274380042
Epoch: 81 | Iteration number: [1970/4518] 43% | Training loss: 0.6870831970030886
Epoch: 81 | Iteration number: [1980/4518] 43% | Training loss: 0.687078449702022
Epoch: 81 | Iteration number: [1990/4518] 44% | Training loss: 0.6870843151705948
Epoch: 81 | Iteration number: [2000/4518] 44% | Training loss: 0.6870812473595143
Epoch: 81 | Iteration number: [2010/4518] 44% | Training loss: 0.6870826912163502
Epoch: 81 | Iteration number: [2020/4518] 44% | Training loss: 0.6870836908274358
Epoch: 81 | Iteration number: [2030/4518] 44% | Training loss: 0.6870804225576335
Epoch: 81 | Iteration number: [2040/4518] 45% | Training loss: 0.6870792649832427
Epoch: 81 | Iteration number: [2050/4518] 45% | Training loss: 0.6870790752550451
Epoch: 81 | Iteration number: [2060/4518] 45% | Training loss: 0.6870824165135911
Epoch: 81 | Iteration number: [2070/4518] 45% | Training loss: 0.6870763824181856
Epoch: 81 | Iteration number: [2080/4518] 46% | Training loss: 0.6870771976331106
Epoch: 81 | Iteration number: [2090/4518] 46% | Training loss: 0.6870789292611574
Epoch: 81 | Iteration number: [2100/4518] 46% | Training loss: 0.6870740344694682
Epoch: 81 | Iteration number: [2110/4518] 46% | Training loss: 0.6870747896732312
Epoch: 81 | Iteration number: [2120/4518] 46% | Training loss: 0.6870753924520511
Epoch: 81 | Iteration number: [2130/4518] 47% | Training loss: 0.6870735658726222
Epoch: 81 | Iteration number: [2140/4518] 47% | Training loss: 0.6870769255907736
Epoch: 81 | Iteration number: [2150/4518] 47% | Training loss: 0.6870803245278292
Epoch: 81 | Iteration number: [2160/4518] 47% | Training loss: 0.6870793922631829
Epoch: 81 | Iteration number: [2170/4518] 48% | Training loss: 0.6870712034713288
Epoch: 81 | Iteration number: [2180/4518] 48% | Training loss: 0.6870671273644912
Epoch: 81 | Iteration number: [2190/4518] 48% | Training loss: 0.6870682392490509
Epoch: 81 | Iteration number: [2200/4518] 48% | Training loss: 0.6870706286755475
Epoch: 81 | Iteration number: [2210/4518] 48% | Training loss: 0.6870705796582667
Epoch: 81 | Iteration number: [2220/4518] 49% | Training loss: 0.6870766785230723
Epoch: 81 | Iteration number: [2230/4518] 49% | Training loss: 0.6870762794274385
Epoch: 81 | Iteration number: [2240/4518] 49% | Training loss: 0.6870692040771246
Epoch: 81 | Iteration number: [2250/4518] 49% | Training loss: 0.6870687919987573
Epoch: 81 | Iteration number: [2260/4518] 50% | Training loss: 0.6870678475736517
Epoch: 81 | Iteration number: [2270/4518] 50% | Training loss: 0.687069053770687
Epoch: 81 | Iteration number: [2280/4518] 50% | Training loss: 0.6870702751111566
Epoch: 81 | Iteration number: [2290/4518] 50% | Training loss: 0.6870742966254205
Epoch: 81 | Iteration number: [2300/4518] 50% | Training loss: 0.6870748269298802
Epoch: 81 | Iteration number: [2310/4518] 51% | Training loss: 0.6870725883291914
Epoch: 81 | Iteration number: [2320/4518] 51% | Training loss: 0.6870699194741661
Epoch: 81 | Iteration number: [2330/4518] 51% | Training loss: 0.6870702046948953
Epoch: 81 | Iteration number: [2340/4518] 51% | Training loss: 0.6870648569021469
Epoch: 81 | Iteration number: [2350/4518] 52% | Training loss: 0.6870616987411012
Epoch: 81 | Iteration number: [2360/4518] 52% | Training loss: 0.6870607456413366
Epoch: 81 | Iteration number: [2370/4518] 52% | Training loss: 0.6870635387515217
Epoch: 81 | Iteration number: [2380/4518] 52% | Training loss: 0.687062204435092
Epoch: 81 | Iteration number: [2390/4518] 52% | Training loss: 0.6870619140160134
Epoch: 81 | Iteration number: [2400/4518] 53% | Training loss: 0.6870647330582141
Epoch: 81 | Iteration number: [2410/4518] 53% | Training loss: 0.6870657943343721
Epoch: 81 | Iteration number: [2420/4518] 53% | Training loss: 0.6870663538205722
Epoch: 81 | Iteration number: [2430/4518] 53% | Training loss: 0.6870626932799571
Epoch: 81 | Iteration number: [2440/4518] 54% | Training loss: 0.6870585941144678
Epoch: 81 | Iteration number: [2450/4518] 54% | Training loss: 0.6870510401287857
Epoch: 81 | Iteration number: [2460/4518] 54% | Training loss: 0.6870519701785188
Epoch: 81 | Iteration number: [2470/4518] 54% | Training loss: 0.6870492549077702
Epoch: 81 | Iteration number: [2480/4518] 54% | Training loss: 0.6870523166512289
Epoch: 81 | Iteration number: [2490/4518] 55% | Training loss: 0.6870539959894126
Epoch: 81 | Iteration number: [2500/4518] 55% | Training loss: 0.6870527629375458
Epoch: 81 | Iteration number: [2510/4518] 55% | Training loss: 0.6870556520988267
Epoch: 81 | Iteration number: [2520/4518] 55% | Training loss: 0.6870558395272209
Epoch: 81 | Iteration number: [2530/4518] 55% | Training loss: 0.6870536329482384
Epoch: 81 | Iteration number: [2540/4518] 56% | Training loss: 0.6870500255288101
Epoch: 81 | Iteration number: [2550/4518] 56% | Training loss: 0.6870454410711925
Epoch: 81 | Iteration number: [2560/4518] 56% | Training loss: 0.6870483837788924
Epoch: 81 | Iteration number: [2570/4518] 56% | Training loss: 0.6870446611935063
Epoch: 81 | Iteration number: [2580/4518] 57% | Training loss: 0.6870479115913081
Epoch: 81 | Iteration number: [2590/4518] 57% | Training loss: 0.6870502225220434
Epoch: 81 | Iteration number: [2600/4518] 57% | Training loss: 0.6870505142670411
Epoch: 81 | Iteration number: [2610/4518] 57% | Training loss: 0.6870470516069639
Epoch: 81 | Iteration number: [2620/4518] 57% | Training loss: 0.6870423216856163
Epoch: 81 | Iteration number: [2630/4518] 58% | Training loss: 0.6870355420239525
Epoch: 81 | Iteration number: [2640/4518] 58% | Training loss: 0.6870326874608343
Epoch: 81 | Iteration number: [2650/4518] 58% | Training loss: 0.6870363612444895
Epoch: 81 | Iteration number: [2660/4518] 58% | Training loss: 0.6870297230948182
Epoch: 81 | Iteration number: [2670/4518] 59% | Training loss: 0.6870301272761956
Epoch: 81 | Iteration number: [2680/4518] 59% | Training loss: 0.6870306934216129
Epoch: 81 | Iteration number: [2690/4518] 59% | Training loss: 0.6870293212424423
Epoch: 81 | Iteration number: [2700/4518] 59% | Training loss: 0.6870251361087516
Epoch: 81 | Iteration number: [2710/4518] 59% | Training loss: 0.6870250708502597
Epoch: 81 | Iteration number: [2720/4518] 60% | Training loss: 0.6870256221031441
Epoch: 81 | Iteration number: [2730/4518] 60% | Training loss: 0.6870217608444856
Epoch: 81 | Iteration number: [2740/4518] 60% | Training loss: 0.6870216160360044
Epoch: 81 | Iteration number: [2750/4518] 60% | Training loss: 0.687024835434827
Epoch: 81 | Iteration number: [2760/4518] 61% | Training loss: 0.6870226087129634
Epoch: 81 | Iteration number: [2770/4518] 61% | Training loss: 0.6870255331054922
Epoch: 81 | Iteration number: [2780/4518] 61% | Training loss: 0.6870249843211482
Epoch: 81 | Iteration number: [2790/4518] 61% | Training loss: 0.687025871413583
Epoch: 81 | Iteration number: [2800/4518] 61% | Training loss: 0.6870245517790318
Epoch: 81 | Iteration number: [2810/4518] 62% | Training loss: 0.6870209508307039
Epoch: 81 | Iteration number: [2820/4518] 62% | Training loss: 0.6870227595593067
Epoch: 81 | Iteration number: [2830/4518] 62% | Training loss: 0.6870269574883128
Epoch: 81 | Iteration number: [2840/4518] 62% | Training loss: 0.6870248138065069
Epoch: 81 | Iteration number: [2850/4518] 63% | Training loss: 0.687023214185447
Epoch: 81 | Iteration number: [2860/4518] 63% | Training loss: 0.6870250135243355
Epoch: 81 | Iteration number: [2870/4518] 63% | Training loss: 0.6870257778865535
Epoch: 81 | Iteration number: [2880/4518] 63% | Training loss: 0.6870233397516939
Epoch: 81 | Iteration number: [2890/4518] 63% | Training loss: 0.6870232008732726
Epoch: 81 | Iteration number: [2900/4518] 64% | Training loss: 0.6870218906936975
Epoch: 81 | Iteration number: [2910/4518] 64% | Training loss: 0.6870238593149022
Epoch: 81 | Iteration number: [2920/4518] 64% | Training loss: 0.6870260844491932
Epoch: 81 | Iteration number: [2930/4518] 64% | Training loss: 0.6870234659710842
Epoch: 81 | Iteration number: [2940/4518] 65% | Training loss: 0.6870244229934653
Epoch: 81 | Iteration number: [2950/4518] 65% | Training loss: 0.6870255133055024
Epoch: 81 | Iteration number: [2960/4518] 65% | Training loss: 0.6870232392203164
Epoch: 81 | Iteration number: [2970/4518] 65% | Training loss: 0.6870244056688816
Epoch: 81 | Iteration number: [2980/4518] 65% | Training loss: 0.68702343044265
Epoch: 81 | Iteration number: [2990/4518] 66% | Training loss: 0.6870237112045288
Epoch: 81 | Iteration number: [3000/4518] 66% | Training loss: 0.6870233884255091
Epoch: 81 | Iteration number: [3010/4518] 66% | Training loss: 0.6870185355213393
Epoch: 81 | Iteration number: [3020/4518] 66% | Training loss: 0.6870194541894837
Epoch: 81 | Iteration number: [3030/4518] 67% | Training loss: 0.6870201516662887
Epoch: 81 | Iteration number: [3040/4518] 67% | Training loss: 0.6870215788875755
Epoch: 81 | Iteration number: [3050/4518] 67% | Training loss: 0.6870213313767167
Epoch: 81 | Iteration number: [3060/4518] 67% | Training loss: 0.6870235139637991
Epoch: 81 | Iteration number: [3070/4518] 67% | Training loss: 0.6870250237687014
Epoch: 81 | Iteration number: [3080/4518] 68% | Training loss: 0.6870241737017384
Epoch: 81 | Iteration number: [3090/4518] 68% | Training loss: 0.687020557636582
Epoch: 81 | Iteration number: [3100/4518] 68% | Training loss: 0.6870220318148214
Epoch: 81 | Iteration number: [3110/4518] 68% | Training loss: 0.6870205219343928
Epoch: 81 | Iteration number: [3120/4518] 69% | Training loss: 0.6870211530381288
Epoch: 81 | Iteration number: [3130/4518] 69% | Training loss: 0.6870232126012016
Epoch: 81 | Iteration number: [3140/4518] 69% | Training loss: 0.6870243345855908
Epoch: 81 | Iteration number: [3150/4518] 69% | Training loss: 0.6870198576223283
Epoch: 81 | Iteration number: [3160/4518] 69% | Training loss: 0.6870224507549141
Epoch: 81 | Iteration number: [3170/4518] 70% | Training loss: 0.6870208175964536
Epoch: 81 | Iteration number: [3180/4518] 70% | Training loss: 0.6870214132018059
Epoch: 81 | Iteration number: [3190/4518] 70% | Training loss: 0.6870213431437561
Epoch: 81 | Iteration number: [3200/4518] 70% | Training loss: 0.6870212142542005
Epoch: 81 | Iteration number: [3210/4518] 71% | Training loss: 0.6870187064197576
Epoch: 81 | Iteration number: [3220/4518] 71% | Training loss: 0.687016757841436
Epoch: 81 | Iteration number: [3230/4518] 71% | Training loss: 0.6870190238066871
Epoch: 81 | Iteration number: [3240/4518] 71% | Training loss: 0.6870169171580562
Epoch: 81 | Iteration number: [3250/4518] 71% | Training loss: 0.687017449103869
Epoch: 81 | Iteration number: [3260/4518] 72% | Training loss: 0.6870156120120382
Epoch: 81 | Iteration number: [3270/4518] 72% | Training loss: 0.6870153977965725
Epoch: 81 | Iteration number: [3280/4518] 72% | Training loss: 0.6870151345322771
Epoch: 81 | Iteration number: [3290/4518] 72% | Training loss: 0.6870143583661517
Epoch: 81 | Iteration number: [3300/4518] 73% | Training loss: 0.6870143717346769
Epoch: 81 | Iteration number: [3310/4518] 73% | Training loss: 0.6870151464852682
Epoch: 81 | Iteration number: [3320/4518] 73% | Training loss: 0.6870104579501841
Epoch: 81 | Iteration number: [3330/4518] 73% | Training loss: 0.6870093335976472
Epoch: 81 | Iteration number: [3340/4518] 73% | Training loss: 0.6870031750844624
Epoch: 81 | Iteration number: [3350/4518] 74% | Training loss: 0.6870047012371804
Epoch: 81 | Iteration number: [3360/4518] 74% | Training loss: 0.6870022336109763
Epoch: 81 | Iteration number: [3370/4518] 74% | Training loss: 0.68699885666901
Epoch: 81 | Iteration number: [3380/4518] 74% | Training loss: 0.6869955365121717
Epoch: 81 | Iteration number: [3390/4518] 75% | Training loss: 0.686992360919626
Epoch: 81 | Iteration number: [3400/4518] 75% | Training loss: 0.6869948903427404
Epoch: 81 | Iteration number: [3410/4518] 75% | Training loss: 0.6869935509571232
Epoch: 81 | Iteration number: [3420/4518] 75% | Training loss: 0.6869919999475368
Epoch: 81 | Iteration number: [3430/4518] 75% | Training loss: 0.6869878413899647
Epoch: 81 | Iteration number: [3440/4518] 76% | Training loss: 0.6869889551470446
Epoch: 81 | Iteration number: [3450/4518] 76% | Training loss: 0.6869882291987323
Epoch: 81 | Iteration number: [3460/4518] 76% | Training loss: 0.686988115379576
Epoch: 81 | Iteration number: [3470/4518] 76% | Training loss: 0.6869860061822776
Epoch: 81 | Iteration number: [3480/4518] 77% | Training loss: 0.6869862437762063
Epoch: 81 | Iteration number: [3490/4518] 77% | Training loss: 0.6869836509398539
Epoch: 81 | Iteration number: [3500/4518] 77% | Training loss: 0.6869875637463161
Epoch: 81 | Iteration number: [3510/4518] 77% | Training loss: 0.686985208573844
Epoch: 81 | Iteration number: [3520/4518] 77% | Training loss: 0.6869873637502844
Epoch: 81 | Iteration number: [3530/4518] 78% | Training loss: 0.6869846880267092
Epoch: 81 | Iteration number: [3540/4518] 78% | Training loss: 0.6869850326560984
Epoch: 81 | Iteration number: [3550/4518] 78% | Training loss: 0.6869815252700322
Epoch: 81 | Iteration number: [3560/4518] 78% | Training loss: 0.6869791346821892
Epoch: 81 | Iteration number: [3570/4518] 79% | Training loss: 0.6869783752939614
Epoch: 81 | Iteration number: [3580/4518] 79% | Training loss: 0.6869783256806474
Epoch: 81 | Iteration number: [3590/4518] 79% | Training loss: 0.6869777078416022
Epoch: 81 | Iteration number: [3600/4518] 79% | Training loss: 0.6869784673220581
Epoch: 81 | Iteration number: [3610/4518] 79% | Training loss: 0.6869750266425168
Epoch: 81 | Iteration number: [3620/4518] 80% | Training loss: 0.686977321436392
Epoch: 81 | Iteration number: [3630/4518] 80% | Training loss: 0.6869767086893402
Epoch: 81 | Iteration number: [3640/4518] 80% | Training loss: 0.6869773004081223
Epoch: 81 | Iteration number: [3650/4518] 80% | Training loss: 0.6869766274380358
Epoch: 81 | Iteration number: [3660/4518] 81% | Training loss: 0.6869756759027315
Epoch: 81 | Iteration number: [3670/4518] 81% | Training loss: 0.6869718333518473
Epoch: 81 | Iteration number: [3680/4518] 81% | Training loss: 0.6869692955166101
Epoch: 81 | Iteration number: [3690/4518] 81% | Training loss: 0.6869675091288601
Epoch: 81 | Iteration number: [3700/4518] 81% | Training loss: 0.6869670367402
Epoch: 81 | Iteration number: [3710/4518] 82% | Training loss: 0.6869649660394519
Epoch: 81 | Iteration number: [3720/4518] 82% | Training loss: 0.686967637510069
Epoch: 81 | Iteration number: [3730/4518] 82% | Training loss: 0.6869685093774872
Epoch: 81 | Iteration number: [3740/4518] 82% | Training loss: 0.6869703476919847
Epoch: 81 | Iteration number: [3750/4518] 83% | Training loss: 0.6869726533730824
Epoch: 81 | Iteration number: [3760/4518] 83% | Training loss: 0.6869730632989964
Epoch: 81 | Iteration number: [3770/4518] 83% | Training loss: 0.6869755405962309
Epoch: 81 | Iteration number: [3780/4518] 83% | Training loss: 0.6869717973565298
Epoch: 81 | Iteration number: [3790/4518] 83% | Training loss: 0.6869685286739571
Epoch: 81 | Iteration number: [3800/4518] 84% | Training loss: 0.6869709112926533
Epoch: 81 | Iteration number: [3810/4518] 84% | Training loss: 0.6869706768689193
Epoch: 81 | Iteration number: [3820/4518] 84% | Training loss: 0.6869672307637349
Epoch: 81 | Iteration number: [3830/4518] 84% | Training loss: 0.6869674216206951
Epoch: 81 | Iteration number: [3840/4518] 84% | Training loss: 0.6869654229221245
Epoch: 81 | Iteration number: [3850/4518] 85% | Training loss: 0.6869619801601806
Epoch: 81 | Iteration number: [3860/4518] 85% | Training loss: 0.6869630126292223
Epoch: 81 | Iteration number: [3870/4518] 85% | Training loss: 0.6869631192172837
Epoch: 81 | Iteration number: [3880/4518] 85% | Training loss: 0.6869649718870822
Epoch: 81 | Iteration number: [3890/4518] 86% | Training loss: 0.6869650235366086
Epoch: 81 | Iteration number: [3900/4518] 86% | Training loss: 0.6869643406073253
Epoch: 81 | Iteration number: [3910/4518] 86% | Training loss: 0.6869674459900088
Epoch: 81 | Iteration number: [3920/4518] 86% | Training loss: 0.6869657619875305
Epoch: 81 | Iteration number: [3930/4518] 86% | Training loss: 0.6869650712905039
Epoch: 81 | Iteration number: [3940/4518] 87% | Training loss: 0.6869643439042387
Epoch: 81 | Iteration number: [3950/4518] 87% | Training loss: 0.6869645575028431
Epoch: 81 | Iteration number: [3960/4518] 87% | Training loss: 0.6869620141507399
Epoch: 81 | Iteration number: [3970/4518] 87% | Training loss: 0.6869570194623933
Epoch: 81 | Iteration number: [3980/4518] 88% | Training loss: 0.6869537682389494
Epoch: 81 | Iteration number: [3990/4518] 88% | Training loss: 0.6869543978743685
Epoch: 81 | Iteration number: [4000/4518] 88% | Training loss: 0.6869559809267521
Epoch: 81 | Iteration number: [4010/4518] 88% | Training loss: 0.6869525120294004
Epoch: 81 | Iteration number: [4020/4518] 88% | Training loss: 0.6869516431543957
Epoch: 81 | Iteration number: [4030/4518] 89% | Training loss: 0.6869518952689159
Epoch: 81 | Iteration number: [4040/4518] 89% | Training loss: 0.6869513728831074
Epoch: 81 | Iteration number: [4050/4518] 89% | Training loss: 0.6869518540376498
Epoch: 81 | Iteration number: [4060/4518] 89% | Training loss: 0.6869517908748147
Epoch: 81 | Iteration number: [4070/4518] 90% | Training loss: 0.6869515736507257
Epoch: 81 | Iteration number: [4080/4518] 90% | Training loss: 0.686950730327882
Epoch: 81 | Iteration number: [4090/4518] 90% | Training loss: 0.6869514860267453
Epoch: 81 | Iteration number: [4100/4518] 90% | Training loss: 0.6869530820555804
Epoch: 81 | Iteration number: [4110/4518] 90% | Training loss: 0.6869531463387529
Epoch: 81 | Iteration number: [4120/4518] 91% | Training loss: 0.6869514844081934
Epoch: 81 | Iteration number: [4130/4518] 91% | Training loss: 0.686953569310052
Epoch: 81 | Iteration number: [4140/4518] 91% | Training loss: 0.6869522594167414
Epoch: 81 | Iteration number: [4150/4518] 91% | Training loss: 0.6869485112701554
Epoch: 81 | Iteration number: [4160/4518] 92% | Training loss: 0.6869467362474937
Epoch: 81 | Iteration number: [4170/4518] 92% | Training loss: 0.6869465307080203
Epoch: 81 | Iteration number: [4180/4518] 92% | Training loss: 0.6869478142147429
Epoch: 81 | Iteration number: [4190/4518] 92% | Training loss: 0.6869483652291264
Epoch: 81 | Iteration number: [4200/4518] 92% | Training loss: 0.6869519962725186
Epoch: 81 | Iteration number: [4210/4518] 93% | Training loss: 0.686949757484812
Epoch: 81 | Iteration number: [4220/4518] 93% | Training loss: 0.6869522066477916
Epoch: 81 | Iteration number: [4230/4518] 93% | Training loss: 0.6869535981058793
Epoch: 81 | Iteration number: [4240/4518] 93% | Training loss: 0.6869497094373658
Epoch: 81 | Iteration number: [4250/4518] 94% | Training loss: 0.6869483403458315
Epoch: 81 | Iteration number: [4260/4518] 94% | Training loss: 0.6869492479333296
Epoch: 81 | Iteration number: [4270/4518] 94% | Training loss: 0.6869460348641845
Epoch: 81 | Iteration number: [4280/4518] 94% | Training loss: 0.6869425219353115
Epoch: 81 | Iteration number: [4290/4518] 94% | Training loss: 0.6869419952233632
Epoch: 81 | Iteration number: [4300/4518] 95% | Training loss: 0.6869428746228994
Epoch: 81 | Iteration number: [4310/4518] 95% | Training loss: 0.6869440564838197
Epoch: 81 | Iteration number: [4320/4518] 95% | Training loss: 0.6869437363550619
Epoch: 81 | Iteration number: [4330/4518] 95% | Training loss: 0.6869426507184467
Epoch: 81 | Iteration number: [4340/4518] 96% | Training loss: 0.6869450511745594
Epoch: 81 | Iteration number: [4350/4518] 96% | Training loss: 0.6869447563160425
Epoch: 81 | Iteration number: [4360/4518] 96% | Training loss: 0.686942704391042
Epoch: 81 | Iteration number: [4370/4518] 96% | Training loss: 0.6869365090090841
Epoch: 81 | Iteration number: [4380/4518] 96% | Training loss: 0.6869359953898817
Epoch: 81 | Iteration number: [4390/4518] 97% | Training loss: 0.6869352856773994
Epoch: 81 | Iteration number: [4400/4518] 97% | Training loss: 0.6869369494237683
Epoch: 81 | Iteration number: [4410/4518] 97% | Training loss: 0.6869348208785327
Epoch: 81 | Iteration number: [4420/4518] 97% | Training loss: 0.6869343535393072
Epoch: 81 | Iteration number: [4430/4518] 98% | Training loss: 0.6869354531000753
Epoch: 81 | Iteration number: [4440/4518] 98% | Training loss: 0.6869354501098126
Epoch: 81 | Iteration number: [4450/4518] 98% | Training loss: 0.6869319903984499
Epoch: 81 | Iteration number: [4460/4518] 98% | Training loss: 0.6869313311683758
Epoch: 81 | Iteration number: [4470/4518] 98% | Training loss: 0.686930215998784
Epoch: 81 | Iteration number: [4480/4518] 99% | Training loss: 0.6869310536022697
Epoch: 81 | Iteration number: [4490/4518] 99% | Training loss: 0.6869300810823462
Epoch: 81 | Iteration number: [4500/4518] 99% | Training loss: 0.6869297656085757
Epoch: 81 | Iteration number: [4510/4518] 99% | Training loss: 0.6869301687190909

 End of epoch: 81 | Train Loss: 0.6867786104328709 | Training Time: 639 

 End of epoch: 81 | Eval Loss: 0.6899556858198983 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/4518] 0% | Training loss: 0.7565700531005859
Epoch: 82 | Iteration number: [20/4518] 0% | Training loss: 0.7222719430923462
Epoch: 82 | Iteration number: [30/4518] 0% | Training loss: 0.7102775494257609
Epoch: 82 | Iteration number: [40/4518] 0% | Training loss: 0.7044575929641723
Epoch: 82 | Iteration number: [50/4518] 1% | Training loss: 0.7008847272396088
Epoch: 82 | Iteration number: [60/4518] 1% | Training loss: 0.6983851174513499
Epoch: 82 | Iteration number: [70/4518] 1% | Training loss: 0.696909225838525
Epoch: 82 | Iteration number: [80/4518] 1% | Training loss: 0.6956624001264572
Epoch: 82 | Iteration number: [90/4518] 1% | Training loss: 0.6947881466812558
Epoch: 82 | Iteration number: [100/4518] 2% | Training loss: 0.693912068605423
Epoch: 82 | Iteration number: [110/4518] 2% | Training loss: 0.6933596443046223
Epoch: 82 | Iteration number: [120/4518] 2% | Training loss: 0.6926984791954358
Epoch: 82 | Iteration number: [130/4518] 2% | Training loss: 0.692303415445181
Epoch: 82 | Iteration number: [140/4518] 3% | Training loss: 0.6918792358466557
Epoch: 82 | Iteration number: [150/4518] 3% | Training loss: 0.6914750862121583
Epoch: 82 | Iteration number: [160/4518] 3% | Training loss: 0.6911195360124112
Epoch: 82 | Iteration number: [170/4518] 3% | Training loss: 0.6908413925591637
Epoch: 82 | Iteration number: [180/4518] 3% | Training loss: 0.6906155642535952
Epoch: 82 | Iteration number: [190/4518] 4% | Training loss: 0.6903471661241432
Epoch: 82 | Iteration number: [200/4518] 4% | Training loss: 0.6902584946155548
Epoch: 82 | Iteration number: [210/4518] 4% | Training loss: 0.6901034795102619
Epoch: 82 | Iteration number: [220/4518] 4% | Training loss: 0.6899700357155366
Epoch: 82 | Iteration number: [230/4518] 5% | Training loss: 0.6898167047811591
Epoch: 82 | Iteration number: [240/4518] 5% | Training loss: 0.689682099223137
Epoch: 82 | Iteration number: [250/4518] 5% | Training loss: 0.689544907093048
Epoch: 82 | Iteration number: [260/4518] 5% | Training loss: 0.6894310641747254
Epoch: 82 | Iteration number: [270/4518] 5% | Training loss: 0.6893802640614686
Epoch: 82 | Iteration number: [280/4518] 6% | Training loss: 0.6892722870622362
Epoch: 82 | Iteration number: [290/4518] 6% | Training loss: 0.6891723686251147
Epoch: 82 | Iteration number: [300/4518] 6% | Training loss: 0.6890660017728806
Epoch: 82 | Iteration number: [310/4518] 6% | Training loss: 0.6890085401073579
Epoch: 82 | Iteration number: [320/4518] 7% | Training loss: 0.6889335785061121
Epoch: 82 | Iteration number: [330/4518] 7% | Training loss: 0.6888804092551722
Epoch: 82 | Iteration number: [340/4518] 7% | Training loss: 0.688833834844477
Epoch: 82 | Iteration number: [350/4518] 7% | Training loss: 0.6887569534778595
Epoch: 82 | Iteration number: [360/4518] 7% | Training loss: 0.6886799022555351
Epoch: 82 | Iteration number: [370/4518] 8% | Training loss: 0.6886499290530746
Epoch: 82 | Iteration number: [380/4518] 8% | Training loss: 0.6886139017970938
Epoch: 82 | Iteration number: [390/4518] 8% | Training loss: 0.6885768078840696
Epoch: 82 | Iteration number: [400/4518] 8% | Training loss: 0.6885234926640987
Epoch: 82 | Iteration number: [410/4518] 9% | Training loss: 0.6884899662762154
Epoch: 82 | Iteration number: [420/4518] 9% | Training loss: 0.6884339000497546
Epoch: 82 | Iteration number: [430/4518] 9% | Training loss: 0.6883880942366843
Epoch: 82 | Iteration number: [440/4518] 9% | Training loss: 0.6883317176591266
Epoch: 82 | Iteration number: [450/4518] 9% | Training loss: 0.6883230194780562
Epoch: 82 | Iteration number: [460/4518] 10% | Training loss: 0.6882586726675863
Epoch: 82 | Iteration number: [470/4518] 10% | Training loss: 0.6882257499593369
Epoch: 82 | Iteration number: [480/4518] 10% | Training loss: 0.6882198080420494
Epoch: 82 | Iteration number: [490/4518] 10% | Training loss: 0.6881832754125401
Epoch: 82 | Iteration number: [500/4518] 11% | Training loss: 0.6881343626976013
Epoch: 82 | Iteration number: [510/4518] 11% | Training loss: 0.6881088810808519
Epoch: 82 | Iteration number: [520/4518] 11% | Training loss: 0.6881181950752552
Epoch: 82 | Iteration number: [530/4518] 11% | Training loss: 0.6880974820200002
Epoch: 82 | Iteration number: [540/4518] 11% | Training loss: 0.688061777750651
Epoch: 82 | Iteration number: [550/4518] 12% | Training loss: 0.6880498502471231
Epoch: 82 | Iteration number: [560/4518] 12% | Training loss: 0.6880225747823715
Epoch: 82 | Iteration number: [570/4518] 12% | Training loss: 0.6880079674093347
Epoch: 82 | Iteration number: [580/4518] 12% | Training loss: 0.6880014362006351
Epoch: 82 | Iteration number: [590/4518] 13% | Training loss: 0.6879863761239132
Epoch: 82 | Iteration number: [600/4518] 13% | Training loss: 0.6879625990986824
Epoch: 82 | Iteration number: [610/4518] 13% | Training loss: 0.6879504465665973
Epoch: 82 | Iteration number: [620/4518] 13% | Training loss: 0.6879398501688434
Epoch: 82 | Iteration number: [630/4518] 13% | Training loss: 0.6879157863912129
Epoch: 82 | Iteration number: [640/4518] 14% | Training loss: 0.6879048054106534
Epoch: 82 | Iteration number: [650/4518] 14% | Training loss: 0.6878820826457097
Epoch: 82 | Iteration number: [660/4518] 14% | Training loss: 0.687871320048968
Epoch: 82 | Iteration number: [670/4518] 14% | Training loss: 0.6878615091985731
Epoch: 82 | Iteration number: [680/4518] 15% | Training loss: 0.6878418057280429
Epoch: 82 | Iteration number: [690/4518] 15% | Training loss: 0.6878249380899513
Epoch: 82 | Iteration number: [700/4518] 15% | Training loss: 0.6878080086197171
Epoch: 82 | Iteration number: [710/4518] 15% | Training loss: 0.6877911328429908
Epoch: 82 | Iteration number: [720/4518] 15% | Training loss: 0.6877783784435855
Epoch: 82 | Iteration number: [730/4518] 16% | Training loss: 0.6877517111497382
Epoch: 82 | Iteration number: [740/4518] 16% | Training loss: 0.6877402475556812
Epoch: 82 | Iteration number: [750/4518] 16% | Training loss: 0.6877248064676921
Epoch: 82 | Iteration number: [760/4518] 16% | Training loss: 0.6877071150039372
Epoch: 82 | Iteration number: [770/4518] 17% | Training loss: 0.6876930904852879
Epoch: 82 | Iteration number: [780/4518] 17% | Training loss: 0.6876877532555506
Epoch: 82 | Iteration number: [790/4518] 17% | Training loss: 0.6876801038090187
Epoch: 82 | Iteration number: [800/4518] 17% | Training loss: 0.6876779524981975
Epoch: 82 | Iteration number: [810/4518] 17% | Training loss: 0.6876699442480817
Epoch: 82 | Iteration number: [820/4518] 18% | Training loss: 0.6876467452543538
Epoch: 82 | Iteration number: [830/4518] 18% | Training loss: 0.687629752345832
Epoch: 82 | Iteration number: [840/4518] 18% | Training loss: 0.6876212065418561
Epoch: 82 | Iteration number: [850/4518] 18% | Training loss: 0.6875975563245661
Epoch: 82 | Iteration number: [860/4518] 19% | Training loss: 0.6875829864379972
Epoch: 82 | Iteration number: [870/4518] 19% | Training loss: 0.6875667310309136
Epoch: 82 | Iteration number: [880/4518] 19% | Training loss: 0.6875629048455846
Epoch: 82 | Iteration number: [890/4518] 19% | Training loss: 0.6875553141818957
Epoch: 82 | Iteration number: [900/4518] 19% | Training loss: 0.6875426369243198
Epoch: 82 | Iteration number: [910/4518] 20% | Training loss: 0.6875246370231712
Epoch: 82 | Iteration number: [920/4518] 20% | Training loss: 0.6875113779435987
Epoch: 82 | Iteration number: [930/4518] 20% | Training loss: 0.6875042048833704
Epoch: 82 | Iteration number: [940/4518] 20% | Training loss: 0.6874843514346062
Epoch: 82 | Iteration number: [950/4518] 21% | Training loss: 0.687472018630881
Epoch: 82 | Iteration number: [960/4518] 21% | Training loss: 0.6874601487070322
Epoch: 82 | Iteration number: [970/4518] 21% | Training loss: 0.687447418134237
Epoch: 82 | Iteration number: [980/4518] 21% | Training loss: 0.6874518089756674
Epoch: 82 | Iteration number: [990/4518] 21% | Training loss: 0.6874348613950941
Epoch: 82 | Iteration number: [1000/4518] 22% | Training loss: 0.6874276015758515
Epoch: 82 | Iteration number: [1010/4518] 22% | Training loss: 0.6874009640500097
Epoch: 82 | Iteration number: [1020/4518] 22% | Training loss: 0.6873861461877823
Epoch: 82 | Iteration number: [1030/4518] 22% | Training loss: 0.6873764529968929
Epoch: 82 | Iteration number: [1040/4518] 23% | Training loss: 0.6873663729199997
Epoch: 82 | Iteration number: [1050/4518] 23% | Training loss: 0.6873720569837661
Epoch: 82 | Iteration number: [1060/4518] 23% | Training loss: 0.6873693332919535
Epoch: 82 | Iteration number: [1070/4518] 23% | Training loss: 0.6873607455012954
Epoch: 82 | Iteration number: [1080/4518] 23% | Training loss: 0.6873516830581206
Epoch: 82 | Iteration number: [1090/4518] 24% | Training loss: 0.68732908893069
Epoch: 82 | Iteration number: [1100/4518] 24% | Training loss: 0.6873355477506464
Epoch: 82 | Iteration number: [1110/4518] 24% | Training loss: 0.6873377946583
Epoch: 82 | Iteration number: [1120/4518] 24% | Training loss: 0.6873377317828792
Epoch: 82 | Iteration number: [1130/4518] 25% | Training loss: 0.6873406159139313
Epoch: 82 | Iteration number: [1140/4518] 25% | Training loss: 0.6873469026988013
Epoch: 82 | Iteration number: [1150/4518] 25% | Training loss: 0.6873433661979178
Epoch: 82 | Iteration number: [1160/4518] 25% | Training loss: 0.6873330655282941
Epoch: 82 | Iteration number: [1170/4518] 25% | Training loss: 0.6873281959794525
Epoch: 82 | Iteration number: [1180/4518] 26% | Training loss: 0.687318311808473
Epoch: 82 | Iteration number: [1190/4518] 26% | Training loss: 0.6873182582755049
Epoch: 82 | Iteration number: [1200/4518] 26% | Training loss: 0.6873150013387204
Epoch: 82 | Iteration number: [1210/4518] 26% | Training loss: 0.6873125595494736
Epoch: 82 | Iteration number: [1220/4518] 27% | Training loss: 0.687310171078463
Epoch: 82 | Iteration number: [1230/4518] 27% | Training loss: 0.6873070830736703
Epoch: 82 | Iteration number: [1240/4518] 27% | Training loss: 0.6873018953108019
Epoch: 82 | Iteration number: [1250/4518] 27% | Training loss: 0.6872933692932129
Epoch: 82 | Iteration number: [1260/4518] 27% | Training loss: 0.6872747597713319
Epoch: 82 | Iteration number: [1270/4518] 28% | Training loss: 0.6872616594701302
Epoch: 82 | Iteration number: [1280/4518] 28% | Training loss: 0.6872525933198631
Epoch: 82 | Iteration number: [1290/4518] 28% | Training loss: 0.6872564611508865
Epoch: 82 | Iteration number: [1300/4518] 28% | Training loss: 0.6872563478121391
Epoch: 82 | Iteration number: [1310/4518] 28% | Training loss: 0.6872499287583446
Epoch: 82 | Iteration number: [1320/4518] 29% | Training loss: 0.6872462776574222
Epoch: 82 | Iteration number: [1330/4518] 29% | Training loss: 0.6872473207631505
Epoch: 82 | Iteration number: [1340/4518] 29% | Training loss: 0.6872588916945813
Epoch: 82 | Iteration number: [1350/4518] 29% | Training loss: 0.687261871540988
Epoch: 82 | Iteration number: [1360/4518] 30% | Training loss: 0.6872604247840012
Epoch: 82 | Iteration number: [1370/4518] 30% | Training loss: 0.6872556080783371
Epoch: 82 | Iteration number: [1380/4518] 30% | Training loss: 0.6872510638789854
Epoch: 82 | Iteration number: [1390/4518] 30% | Training loss: 0.6872457825451446
Epoch: 82 | Iteration number: [1400/4518] 30% | Training loss: 0.6872464895248414
Epoch: 82 | Iteration number: [1410/4518] 31% | Training loss: 0.6872379311433076
Epoch: 82 | Iteration number: [1420/4518] 31% | Training loss: 0.6872280183392512
Epoch: 82 | Iteration number: [1430/4518] 31% | Training loss: 0.6872246391706534
Epoch: 82 | Iteration number: [1440/4518] 31% | Training loss: 0.6872259880105654
Epoch: 82 | Iteration number: [1450/4518] 32% | Training loss: 0.6872230424141061
Epoch: 82 | Iteration number: [1460/4518] 32% | Training loss: 0.6872137456315838
Epoch: 82 | Iteration number: [1470/4518] 32% | Training loss: 0.6872139834222339
Epoch: 82 | Iteration number: [1480/4518] 32% | Training loss: 0.6872130385121784
Epoch: 82 | Iteration number: [1490/4518] 32% | Training loss: 0.6872046371434359
Epoch: 82 | Iteration number: [1500/4518] 33% | Training loss: 0.6871984962224961
Epoch: 82 | Iteration number: [1510/4518] 33% | Training loss: 0.68718850198171
Epoch: 82 | Iteration number: [1520/4518] 33% | Training loss: 0.6871795143736036
Epoch: 82 | Iteration number: [1530/4518] 33% | Training loss: 0.6871759136517842
Epoch: 82 | Iteration number: [1540/4518] 34% | Training loss: 0.6871753791709999
Epoch: 82 | Iteration number: [1550/4518] 34% | Training loss: 0.6871786968169674
Epoch: 82 | Iteration number: [1560/4518] 34% | Training loss: 0.6871717087351359
Epoch: 82 | Iteration number: [1570/4518] 34% | Training loss: 0.6871716076401388
Epoch: 82 | Iteration number: [1580/4518] 34% | Training loss: 0.6871735315534133
Epoch: 82 | Iteration number: [1590/4518] 35% | Training loss: 0.6871790307497828
Epoch: 82 | Iteration number: [1600/4518] 35% | Training loss: 0.6871816208958625
Epoch: 82 | Iteration number: [1610/4518] 35% | Training loss: 0.6871853005071604
Epoch: 82 | Iteration number: [1620/4518] 35% | Training loss: 0.6871769361657861
Epoch: 82 | Iteration number: [1630/4518] 36% | Training loss: 0.6871805506981223
Epoch: 82 | Iteration number: [1640/4518] 36% | Training loss: 0.6871770750095204
Epoch: 82 | Iteration number: [1650/4518] 36% | Training loss: 0.6871699737418782
Epoch: 82 | Iteration number: [1660/4518] 36% | Training loss: 0.6871712853391486
Epoch: 82 | Iteration number: [1670/4518] 36% | Training loss: 0.6871732065420665
Epoch: 82 | Iteration number: [1680/4518] 37% | Training loss: 0.6871689121283237
Epoch: 82 | Iteration number: [1690/4518] 37% | Training loss: 0.6871716272548811
Epoch: 82 | Iteration number: [1700/4518] 37% | Training loss: 0.6871629851004657
Epoch: 82 | Iteration number: [1710/4518] 37% | Training loss: 0.6871594140404149
Epoch: 82 | Iteration number: [1720/4518] 38% | Training loss: 0.6871508171392041
Epoch: 82 | Iteration number: [1730/4518] 38% | Training loss: 0.6871512840593481
Epoch: 82 | Iteration number: [1740/4518] 38% | Training loss: 0.6871395757828636
Epoch: 82 | Iteration number: [1750/4518] 38% | Training loss: 0.6871289851665496
Epoch: 82 | Iteration number: [1760/4518] 38% | Training loss: 0.6871335326270623
Epoch: 82 | Iteration number: [1770/4518] 39% | Training loss: 0.6871271456365532
Epoch: 82 | Iteration number: [1780/4518] 39% | Training loss: 0.687124852015731
Epoch: 82 | Iteration number: [1790/4518] 39% | Training loss: 0.6871170474164313
Epoch: 82 | Iteration number: [1800/4518] 39% | Training loss: 0.6871110551555951
Epoch: 82 | Iteration number: [1810/4518] 40% | Training loss: 0.6871124745403205
Epoch: 82 | Iteration number: [1820/4518] 40% | Training loss: 0.6871041200973176
Epoch: 82 | Iteration number: [1830/4518] 40% | Training loss: 0.6871056042408031
Epoch: 82 | Iteration number: [1840/4518] 40% | Training loss: 0.6871025036858476
Epoch: 82 | Iteration number: [1850/4518] 40% | Training loss: 0.6870985004708574
Epoch: 82 | Iteration number: [1860/4518] 41% | Training loss: 0.6871006405481728
Epoch: 82 | Iteration number: [1870/4518] 41% | Training loss: 0.687093993431744
Epoch: 82 | Iteration number: [1880/4518] 41% | Training loss: 0.6870926083085385
Epoch: 82 | Iteration number: [1890/4518] 41% | Training loss: 0.687099502641688
Epoch: 82 | Iteration number: [1900/4518] 42% | Training loss: 0.6871065138829382
Epoch: 82 | Iteration number: [1910/4518] 42% | Training loss: 0.6871064378328973
Epoch: 82 | Iteration number: [1920/4518] 42% | Training loss: 0.6871088009017209
Epoch: 82 | Iteration number: [1930/4518] 42% | Training loss: 0.6871003292693993
Epoch: 82 | Iteration number: [1940/4518] 42% | Training loss: 0.6870961185275893
Epoch: 82 | Iteration number: [1950/4518] 43% | Training loss: 0.6870860497462444
Epoch: 82 | Iteration number: [1960/4518] 43% | Training loss: 0.6870826792352054
Epoch: 82 | Iteration number: [1970/4518] 43% | Training loss: 0.6870749519863709
Epoch: 82 | Iteration number: [1980/4518] 43% | Training loss: 0.6870707024227489
Epoch: 82 | Iteration number: [1990/4518] 44% | Training loss: 0.6870745378223496
Epoch: 82 | Iteration number: [2000/4518] 44% | Training loss: 0.687079147875309
Epoch: 82 | Iteration number: [2010/4518] 44% | Training loss: 0.6870805124738323
Epoch: 82 | Iteration number: [2020/4518] 44% | Training loss: 0.6870779344055912
Epoch: 82 | Iteration number: [2030/4518] 44% | Training loss: 0.6870782111665885
Epoch: 82 | Iteration number: [2040/4518] 45% | Training loss: 0.6870716589630819
Epoch: 82 | Iteration number: [2050/4518] 45% | Training loss: 0.687074147404694
Epoch: 82 | Iteration number: [2060/4518] 45% | Training loss: 0.6870680000018148
Epoch: 82 | Iteration number: [2070/4518] 45% | Training loss: 0.6870679457118546
Epoch: 82 | Iteration number: [2080/4518] 46% | Training loss: 0.6870713377801272
Epoch: 82 | Iteration number: [2090/4518] 46% | Training loss: 0.6870713244499772
Epoch: 82 | Iteration number: [2100/4518] 46% | Training loss: 0.6870747688554583
Epoch: 82 | Iteration number: [2110/4518] 46% | Training loss: 0.6870726082844757
Epoch: 82 | Iteration number: [2120/4518] 46% | Training loss: 0.6870750104200165
Epoch: 82 | Iteration number: [2130/4518] 47% | Training loss: 0.6870685346249683
Epoch: 82 | Iteration number: [2140/4518] 47% | Training loss: 0.6870723322730198
Epoch: 82 | Iteration number: [2150/4518] 47% | Training loss: 0.6870722799245701
Epoch: 82 | Iteration number: [2160/4518] 47% | Training loss: 0.6870718240737915
Epoch: 82 | Iteration number: [2170/4518] 48% | Training loss: 0.6870744518420663
Epoch: 82 | Iteration number: [2180/4518] 48% | Training loss: 0.6870749050597532
Epoch: 82 | Iteration number: [2190/4518] 48% | Training loss: 0.6870746017046715
Epoch: 82 | Iteration number: [2200/4518] 48% | Training loss: 0.687073492732915
Epoch: 82 | Iteration number: [2210/4518] 48% | Training loss: 0.6870708267882938
Epoch: 82 | Iteration number: [2220/4518] 49% | Training loss: 0.6870684934360487
Epoch: 82 | Iteration number: [2230/4518] 49% | Training loss: 0.6870705054212579
Epoch: 82 | Iteration number: [2240/4518] 49% | Training loss: 0.6870674126382385
Epoch: 82 | Iteration number: [2250/4518] 49% | Training loss: 0.6870653304788802
Epoch: 82 | Iteration number: [2260/4518] 50% | Training loss: 0.6870685320776121
Epoch: 82 | Iteration number: [2270/4518] 50% | Training loss: 0.6870716153787622
Epoch: 82 | Iteration number: [2280/4518] 50% | Training loss: 0.6870706821219963
Epoch: 82 | Iteration number: [2290/4518] 50% | Training loss: 0.6870687722378943
Epoch: 82 | Iteration number: [2300/4518] 50% | Training loss: 0.6870714143825614
Epoch: 82 | Iteration number: [2310/4518] 51% | Training loss: 0.6870743221792824
Epoch: 82 | Iteration number: [2320/4518] 51% | Training loss: 0.6870698929089925
Epoch: 82 | Iteration number: [2330/4518] 51% | Training loss: 0.6870694807159031
Epoch: 82 | Iteration number: [2340/4518] 51% | Training loss: 0.6870716791122388
Epoch: 82 | Iteration number: [2350/4518] 52% | Training loss: 0.6870733451843262
Epoch: 82 | Iteration number: [2360/4518] 52% | Training loss: 0.6870713758014017
Epoch: 82 | Iteration number: [2370/4518] 52% | Training loss: 0.6870744208494822
Epoch: 82 | Iteration number: [2380/4518] 52% | Training loss: 0.6870716985534219
Epoch: 82 | Iteration number: [2390/4518] 52% | Training loss: 0.687069897846198
Epoch: 82 | Iteration number: [2400/4518] 53% | Training loss: 0.6870689025024573
Epoch: 82 | Iteration number: [2410/4518] 53% | Training loss: 0.6870655634343872
Epoch: 82 | Iteration number: [2420/4518] 53% | Training loss: 0.6870637242212768
Epoch: 82 | Iteration number: [2430/4518] 53% | Training loss: 0.6870631796097069
Epoch: 82 | Iteration number: [2440/4518] 54% | Training loss: 0.6870576276153815
Epoch: 82 | Iteration number: [2450/4518] 54% | Training loss: 0.6870560582073367
Epoch: 82 | Iteration number: [2460/4518] 54% | Training loss: 0.6870559274181118
Epoch: 82 | Iteration number: [2470/4518] 54% | Training loss: 0.6870631022974547
Epoch: 82 | Iteration number: [2480/4518] 54% | Training loss: 0.6870595240304547
Epoch: 82 | Iteration number: [2490/4518] 55% | Training loss: 0.6870635453716339
Epoch: 82 | Iteration number: [2500/4518] 55% | Training loss: 0.6870639250516891
Epoch: 82 | Iteration number: [2510/4518] 55% | Training loss: 0.6870632793086459
Epoch: 82 | Iteration number: [2520/4518] 55% | Training loss: 0.6870617036072034
Epoch: 82 | Iteration number: [2530/4518] 55% | Training loss: 0.6870593064622916
Epoch: 82 | Iteration number: [2540/4518] 56% | Training loss: 0.6870566369980339
Epoch: 82 | Iteration number: [2550/4518] 56% | Training loss: 0.6870587328368543
Epoch: 82 | Iteration number: [2560/4518] 56% | Training loss: 0.6870587589917705
Epoch: 82 | Iteration number: [2570/4518] 56% | Training loss: 0.6870612547091473
Epoch: 82 | Iteration number: [2580/4518] 57% | Training loss: 0.6870666947244674
Epoch: 82 | Iteration number: [2590/4518] 57% | Training loss: 0.6870671302195221
Epoch: 82 | Iteration number: [2600/4518] 57% | Training loss: 0.6870634768788632
Epoch: 82 | Iteration number: [2610/4518] 57% | Training loss: 0.6870644719436251
Epoch: 82 | Iteration number: [2620/4518] 57% | Training loss: 0.687063288961658
Epoch: 82 | Iteration number: [2630/4518] 58% | Training loss: 0.6870607374285563
Epoch: 82 | Iteration number: [2640/4518] 58% | Training loss: 0.6870603455061263
Epoch: 82 | Iteration number: [2650/4518] 58% | Training loss: 0.6870588275621522
Epoch: 82 | Iteration number: [2660/4518] 58% | Training loss: 0.6870589177187224
Epoch: 82 | Iteration number: [2670/4518] 59% | Training loss: 0.6870570801393816
Epoch: 82 | Iteration number: [2680/4518] 59% | Training loss: 0.6870558796089087
Epoch: 82 | Iteration number: [2690/4518] 59% | Training loss: 0.687048414183372
Epoch: 82 | Iteration number: [2700/4518] 59% | Training loss: 0.6870476860470242
Epoch: 82 | Iteration number: [2710/4518] 59% | Training loss: 0.6870498785673472
Epoch: 82 | Iteration number: [2720/4518] 60% | Training loss: 0.6870503328083193
Epoch: 82 | Iteration number: [2730/4518] 60% | Training loss: 0.6870505519838996
Epoch: 82 | Iteration number: [2740/4518] 60% | Training loss: 0.6870510807220083
Epoch: 82 | Iteration number: [2750/4518] 60% | Training loss: 0.6870468472784216
Epoch: 82 | Iteration number: [2760/4518] 61% | Training loss: 0.6870503804389981
Epoch: 82 | Iteration number: [2770/4518] 61% | Training loss: 0.6870503784947447
Epoch: 82 | Iteration number: [2780/4518] 61% | Training loss: 0.6870501519964753
Epoch: 82 | Iteration number: [2790/4518] 61% | Training loss: 0.6870511829425784
Epoch: 82 | Iteration number: [2800/4518] 61% | Training loss: 0.687048538838114
Epoch: 82 | Iteration number: [2810/4518] 62% | Training loss: 0.6870469911666952
Epoch: 82 | Iteration number: [2820/4518] 62% | Training loss: 0.6870463735245643
Epoch: 82 | Iteration number: [2830/4518] 62% | Training loss: 0.6870428062580499
Epoch: 82 | Iteration number: [2840/4518] 62% | Training loss: 0.6870381050546405
Epoch: 82 | Iteration number: [2850/4518] 63% | Training loss: 0.6870386090404109
Epoch: 82 | Iteration number: [2860/4518] 63% | Training loss: 0.6870376666734269
Epoch: 82 | Iteration number: [2870/4518] 63% | Training loss: 0.6870323662143136
Epoch: 82 | Iteration number: [2880/4518] 63% | Training loss: 0.6870302944133679
Epoch: 82 | Iteration number: [2890/4518] 63% | Training loss: 0.6870303034163676
Epoch: 82 | Iteration number: [2900/4518] 64% | Training loss: 0.687026318106158
Epoch: 82 | Iteration number: [2910/4518] 64% | Training loss: 0.6870245013450019
Epoch: 82 | Iteration number: [2920/4518] 64% | Training loss: 0.6870249524100186
Epoch: 82 | Iteration number: [2930/4518] 64% | Training loss: 0.6870250261480898
Epoch: 82 | Iteration number: [2940/4518] 65% | Training loss: 0.6870244432468804
Epoch: 82 | Iteration number: [2950/4518] 65% | Training loss: 0.687021563093541
Epoch: 82 | Iteration number: [2960/4518] 65% | Training loss: 0.6870206036076353
Epoch: 82 | Iteration number: [2970/4518] 65% | Training loss: 0.6870179318017028
Epoch: 82 | Iteration number: [2980/4518] 65% | Training loss: 0.6870194227103419
Epoch: 82 | Iteration number: [2990/4518] 66% | Training loss: 0.6870178092682242
Epoch: 82 | Iteration number: [3000/4518] 66% | Training loss: 0.6870131633083025
Epoch: 82 | Iteration number: [3010/4518] 66% | Training loss: 0.6870129154172054
Epoch: 82 | Iteration number: [3020/4518] 66% | Training loss: 0.6870102926397955
Epoch: 82 | Iteration number: [3030/4518] 67% | Training loss: 0.6870079896631021
Epoch: 82 | Iteration number: [3040/4518] 67% | Training loss: 0.6870061620873841
Epoch: 82 | Iteration number: [3050/4518] 67% | Training loss: 0.6870045432497244
Epoch: 82 | Iteration number: [3060/4518] 67% | Training loss: 0.6870074145155015
Epoch: 82 | Iteration number: [3070/4518] 67% | Training loss: 0.6870077872509288
Epoch: 82 | Iteration number: [3080/4518] 68% | Training loss: 0.6870068305305073
Epoch: 82 | Iteration number: [3090/4518] 68% | Training loss: 0.6870068947088371
Epoch: 82 | Iteration number: [3100/4518] 68% | Training loss: 0.6870044994354249
Epoch: 82 | Iteration number: [3110/4518] 68% | Training loss: 0.6870032417620877
Epoch: 82 | Iteration number: [3120/4518] 69% | Training loss: 0.6870049878190725
Epoch: 82 | Iteration number: [3130/4518] 69% | Training loss: 0.6870033844210469
Epoch: 82 | Iteration number: [3140/4518] 69% | Training loss: 0.6870000759697265
Epoch: 82 | Iteration number: [3150/4518] 69% | Training loss: 0.6869970863206046
Epoch: 82 | Iteration number: [3160/4518] 69% | Training loss: 0.6869941622396059
Epoch: 82 | Iteration number: [3170/4518] 70% | Training loss: 0.686994710348382
Epoch: 82 | Iteration number: [3180/4518] 70% | Training loss: 0.6869916674101127
Epoch: 82 | Iteration number: [3190/4518] 70% | Training loss: 0.6869945805648278
Epoch: 82 | Iteration number: [3200/4518] 70% | Training loss: 0.6869882796891034
Epoch: 82 | Iteration number: [3210/4518] 71% | Training loss: 0.6869903667879254
Epoch: 82 | Iteration number: [3220/4518] 71% | Training loss: 0.68699397663152
Epoch: 82 | Iteration number: [3230/4518] 71% | Training loss: 0.6869910573627188
Epoch: 82 | Iteration number: [3240/4518] 71% | Training loss: 0.6869917655800596
Epoch: 82 | Iteration number: [3250/4518] 71% | Training loss: 0.6869909273110903
Epoch: 82 | Iteration number: [3260/4518] 72% | Training loss: 0.6869896861855969
Epoch: 82 | Iteration number: [3270/4518] 72% | Training loss: 0.6869883289760041
Epoch: 82 | Iteration number: [3280/4518] 72% | Training loss: 0.6869909142575613
Epoch: 82 | Iteration number: [3290/4518] 72% | Training loss: 0.686994204405231
Epoch: 82 | Iteration number: [3300/4518] 73% | Training loss: 0.6869940311077869
Epoch: 82 | Iteration number: [3310/4518] 73% | Training loss: 0.686994736558361
Epoch: 82 | Iteration number: [3320/4518] 73% | Training loss: 0.6869939470506576
Epoch: 82 | Iteration number: [3330/4518] 73% | Training loss: 0.686991040717374
Epoch: 82 | Iteration number: [3340/4518] 73% | Training loss: 0.686991328804079
Epoch: 82 | Iteration number: [3350/4518] 74% | Training loss: 0.6869912604787456
Epoch: 82 | Iteration number: [3360/4518] 74% | Training loss: 0.6869915337434837
Epoch: 82 | Iteration number: [3370/4518] 74% | Training loss: 0.6869918458008979
Epoch: 82 | Iteration number: [3380/4518] 74% | Training loss: 0.6869944975220945
Epoch: 82 | Iteration number: [3390/4518] 75% | Training loss: 0.6869932778113711
Epoch: 82 | Iteration number: [3400/4518] 75% | Training loss: 0.6869913397992359
Epoch: 82 | Iteration number: [3410/4518] 75% | Training loss: 0.6869843064340329
Epoch: 82 | Iteration number: [3420/4518] 75% | Training loss: 0.6869812452653695
Epoch: 82 | Iteration number: [3430/4518] 75% | Training loss: 0.6869818829760259
Epoch: 82 | Iteration number: [3440/4518] 76% | Training loss: 0.6869799208155898
Epoch: 82 | Iteration number: [3450/4518] 76% | Training loss: 0.6869766339357348
Epoch: 82 | Iteration number: [3460/4518] 76% | Training loss: 0.6869765162123421
Epoch: 82 | Iteration number: [3470/4518] 76% | Training loss: 0.6869776175757306
Epoch: 82 | Iteration number: [3480/4518] 77% | Training loss: 0.6869763621482355
Epoch: 82 | Iteration number: [3490/4518] 77% | Training loss: 0.686970451431493
Epoch: 82 | Iteration number: [3500/4518] 77% | Training loss: 0.6869696102312634
Epoch: 82 | Iteration number: [3510/4518] 77% | Training loss: 0.6869688575084393
Epoch: 82 | Iteration number: [3520/4518] 77% | Training loss: 0.6869672544469888
Epoch: 82 | Iteration number: [3530/4518] 78% | Training loss: 0.6869679341910581
Epoch: 82 | Iteration number: [3540/4518] 78% | Training loss: 0.6869694920919709
Epoch: 82 | Iteration number: [3550/4518] 78% | Training loss: 0.6869691044344028
Epoch: 82 | Iteration number: [3560/4518] 78% | Training loss: 0.6869737571377432
Epoch: 82 | Iteration number: [3570/4518] 79% | Training loss: 0.6869735808933483
Epoch: 82 | Iteration number: [3580/4518] 79% | Training loss: 0.6869781703589349
Epoch: 82 | Iteration number: [3590/4518] 79% | Training loss: 0.686978020159979
Epoch: 82 | Iteration number: [3600/4518] 79% | Training loss: 0.6869727873967754
Epoch: 82 | Iteration number: [3610/4518] 79% | Training loss: 0.6869693089224955
Epoch: 82 | Iteration number: [3620/4518] 80% | Training loss: 0.6869721388289941
Epoch: 82 | Iteration number: [3630/4518] 80% | Training loss: 0.6869680460162728
Epoch: 82 | Iteration number: [3640/4518] 80% | Training loss: 0.6869703194597265
Epoch: 82 | Iteration number: [3650/4518] 80% | Training loss: 0.6869725864064203
Epoch: 82 | Iteration number: [3660/4518] 81% | Training loss: 0.6869716734508348
Epoch: 82 | Iteration number: [3670/4518] 81% | Training loss: 0.686975195849624
Epoch: 82 | Iteration number: [3680/4518] 81% | Training loss: 0.6869735730730969
Epoch: 82 | Iteration number: [3690/4518] 81% | Training loss: 0.6869737349874605
Epoch: 82 | Iteration number: [3700/4518] 81% | Training loss: 0.6869728061315176
Epoch: 82 | Iteration number: [3710/4518] 82% | Training loss: 0.686973344058682
Epoch: 82 | Iteration number: [3720/4518] 82% | Training loss: 0.6869732699887727
Epoch: 82 | Iteration number: [3730/4518] 82% | Training loss: 0.6869693414135849
Epoch: 82 | Iteration number: [3740/4518] 82% | Training loss: 0.6869711154444332
Epoch: 82 | Iteration number: [3750/4518] 83% | Training loss: 0.6869711176872253
Epoch: 82 | Iteration number: [3760/4518] 83% | Training loss: 0.6869704925792014
Epoch: 82 | Iteration number: [3770/4518] 83% | Training loss: 0.6869689778402567
Epoch: 82 | Iteration number: [3780/4518] 83% | Training loss: 0.6869659865659381
Epoch: 82 | Iteration number: [3790/4518] 83% | Training loss: 0.6869592113356477
Epoch: 82 | Iteration number: [3800/4518] 84% | Training loss: 0.6869595384127215
Epoch: 82 | Iteration number: [3810/4518] 84% | Training loss: 0.686961373240929
Epoch: 82 | Iteration number: [3820/4518] 84% | Training loss: 0.6869593670386919
Epoch: 82 | Iteration number: [3830/4518] 84% | Training loss: 0.6869589621186568
Epoch: 82 | Iteration number: [3840/4518] 84% | Training loss: 0.686956486882021
Epoch: 82 | Iteration number: [3850/4518] 85% | Training loss: 0.6869520623807783
Epoch: 82 | Iteration number: [3860/4518] 85% | Training loss: 0.6869502862191571
Epoch: 82 | Iteration number: [3870/4518] 85% | Training loss: 0.6869444921497226
Epoch: 82 | Iteration number: [3880/4518] 85% | Training loss: 0.6869444589178587
Epoch: 82 | Iteration number: [3890/4518] 86% | Training loss: 0.6869450918353309
Epoch: 82 | Iteration number: [3900/4518] 86% | Training loss: 0.6869447927291576
Epoch: 82 | Iteration number: [3910/4518] 86% | Training loss: 0.6869443679252244
Epoch: 82 | Iteration number: [3920/4518] 86% | Training loss: 0.6869457474624624
Epoch: 82 | Iteration number: [3930/4518] 86% | Training loss: 0.6869454748909589
Epoch: 82 | Iteration number: [3940/4518] 87% | Training loss: 0.6869448303117365
Epoch: 82 | Iteration number: [3950/4518] 87% | Training loss: 0.6869431115253062
Epoch: 82 | Iteration number: [3960/4518] 87% | Training loss: 0.6869431066242131
Epoch: 82 | Iteration number: [3970/4518] 87% | Training loss: 0.686947036344999
Epoch: 82 | Iteration number: [3980/4518] 88% | Training loss: 0.68694687890048
Epoch: 82 | Iteration number: [3990/4518] 88% | Training loss: 0.6869454123471913
Epoch: 82 | Iteration number: [4000/4518] 88% | Training loss: 0.6869479722082615
Epoch: 82 | Iteration number: [4010/4518] 88% | Training loss: 0.6869473688620285
Epoch: 82 | Iteration number: [4020/4518] 88% | Training loss: 0.6869464311137128
Epoch: 82 | Iteration number: [4030/4518] 89% | Training loss: 0.68694229405512
Epoch: 82 | Iteration number: [4040/4518] 89% | Training loss: 0.6869408548911019
Epoch: 82 | Iteration number: [4050/4518] 89% | Training loss: 0.6869394266752549
Epoch: 82 | Iteration number: [4060/4518] 89% | Training loss: 0.6869378453258224
Epoch: 82 | Iteration number: [4070/4518] 90% | Training loss: 0.6869388028942689
Epoch: 82 | Iteration number: [4080/4518] 90% | Training loss: 0.686939607253846
Epoch: 82 | Iteration number: [4090/4518] 90% | Training loss: 0.6869384573112198
Epoch: 82 | Iteration number: [4100/4518] 90% | Training loss: 0.6869379010578481
Epoch: 82 | Iteration number: [4110/4518] 90% | Training loss: 0.6869376285377791
Epoch: 82 | Iteration number: [4120/4518] 91% | Training loss: 0.6869406760751623
Epoch: 82 | Iteration number: [4130/4518] 91% | Training loss: 0.6869366438567782
Epoch: 82 | Iteration number: [4140/4518] 91% | Training loss: 0.6869376457111847
Epoch: 82 | Iteration number: [4150/4518] 91% | Training loss: 0.6869350628249616
Epoch: 82 | Iteration number: [4160/4518] 92% | Training loss: 0.6869339803663584
Epoch: 82 | Iteration number: [4170/4518] 92% | Training loss: 0.6869323884411681
Epoch: 82 | Iteration number: [4180/4518] 92% | Training loss: 0.6869326845738306
Epoch: 82 | Iteration number: [4190/4518] 92% | Training loss: 0.6869333968526709
Epoch: 82 | Iteration number: [4200/4518] 92% | Training loss: 0.6869308431375595
Epoch: 82 | Iteration number: [4210/4518] 93% | Training loss: 0.6869282787316202
Epoch: 82 | Iteration number: [4220/4518] 93% | Training loss: 0.6869272830926977
Epoch: 82 | Iteration number: [4230/4518] 93% | Training loss: 0.6869297274038302
Epoch: 82 | Iteration number: [4240/4518] 93% | Training loss: 0.6869308928554912
Epoch: 82 | Iteration number: [4250/4518] 94% | Training loss: 0.6869334743864396
Epoch: 82 | Iteration number: [4260/4518] 94% | Training loss: 0.6869299828166693
Epoch: 82 | Iteration number: [4270/4518] 94% | Training loss: 0.6869276019812188
Epoch: 82 | Iteration number: [4280/4518] 94% | Training loss: 0.6869288306927013
Epoch: 82 | Iteration number: [4290/4518] 94% | Training loss: 0.6869300923008463
Epoch: 82 | Iteration number: [4300/4518] 95% | Training loss: 0.6869274313643922
Epoch: 82 | Iteration number: [4310/4518] 95% | Training loss: 0.6869300934112266
Epoch: 82 | Iteration number: [4320/4518] 95% | Training loss: 0.6869305119056393
Epoch: 82 | Iteration number: [4330/4518] 95% | Training loss: 0.6869304485326551
Epoch: 82 | Iteration number: [4340/4518] 96% | Training loss: 0.6869293961656808
Epoch: 82 | Iteration number: [4350/4518] 96% | Training loss: 0.6869300345579783
Epoch: 82 | Iteration number: [4360/4518] 96% | Training loss: 0.6869313676422889
Epoch: 82 | Iteration number: [4370/4518] 96% | Training loss: 0.6869307710867998
Epoch: 82 | Iteration number: [4380/4518] 96% | Training loss: 0.6869310612411804
Epoch: 82 | Iteration number: [4390/4518] 97% | Training loss: 0.686931502588246
Epoch: 82 | Iteration number: [4400/4518] 97% | Training loss: 0.6869316539710218
Epoch: 82 | Iteration number: [4410/4518] 97% | Training loss: 0.686933972465208
Epoch: 82 | Iteration number: [4420/4518] 97% | Training loss: 0.6869297391418958
Epoch: 82 | Iteration number: [4430/4518] 98% | Training loss: 0.6869293664163715
Epoch: 82 | Iteration number: [4440/4518] 98% | Training loss: 0.6869312658771738
Epoch: 82 | Iteration number: [4450/4518] 98% | Training loss: 0.686929920469777
Epoch: 82 | Iteration number: [4460/4518] 98% | Training loss: 0.6869252517485298
Epoch: 82 | Iteration number: [4470/4518] 98% | Training loss: 0.686927315492758
Epoch: 82 | Iteration number: [4480/4518] 99% | Training loss: 0.6869276207871735
Epoch: 82 | Iteration number: [4490/4518] 99% | Training loss: 0.6869294009256469
Epoch: 82 | Iteration number: [4500/4518] 99% | Training loss: 0.6869291364086999
Epoch: 82 | Iteration number: [4510/4518] 99% | Training loss: 0.6869255875008069

 End of epoch: 82 | Train Loss: 0.6867723832910385 | Training Time: 641 

 End of epoch: 82 | Eval Loss: 0.6899845417664976 | Evaluating Time: 17 
Epoch: 83 | Iteration number: [10/4518] 0% | Training loss: 0.7560192942619324
Epoch: 83 | Iteration number: [20/4518] 0% | Training loss: 0.7213169664144516
Epoch: 83 | Iteration number: [30/4518] 0% | Training loss: 0.7099161505699157
Epoch: 83 | Iteration number: [40/4518] 0% | Training loss: 0.7044176161289215
Epoch: 83 | Iteration number: [50/4518] 1% | Training loss: 0.7008524072170258
Epoch: 83 | Iteration number: [60/4518] 1% | Training loss: 0.6984012583891551
Epoch: 83 | Iteration number: [70/4518] 1% | Training loss: 0.6966628840991429
Epoch: 83 | Iteration number: [80/4518] 1% | Training loss: 0.695328240096569
Epoch: 83 | Iteration number: [90/4518] 1% | Training loss: 0.6941776096820831
Epoch: 83 | Iteration number: [100/4518] 2% | Training loss: 0.6933829456567764
Epoch: 83 | Iteration number: [110/4518] 2% | Training loss: 0.6928033639084209
Epoch: 83 | Iteration number: [120/4518] 2% | Training loss: 0.6922899613777797
Epoch: 83 | Iteration number: [130/4518] 2% | Training loss: 0.6920327049035292
Epoch: 83 | Iteration number: [140/4518] 3% | Training loss: 0.6915708588702338
Epoch: 83 | Iteration number: [150/4518] 3% | Training loss: 0.6912096734841665
Epoch: 83 | Iteration number: [160/4518] 3% | Training loss: 0.6909007478505373
Epoch: 83 | Iteration number: [170/4518] 3% | Training loss: 0.6906670444151934
Epoch: 83 | Iteration number: [180/4518] 3% | Training loss: 0.6904845933119456
Epoch: 83 | Iteration number: [190/4518] 4% | Training loss: 0.6903172791004181
Epoch: 83 | Iteration number: [200/4518] 4% | Training loss: 0.6900922623276711
Epoch: 83 | Iteration number: [210/4518] 4% | Training loss: 0.6899729896159399
Epoch: 83 | Iteration number: [220/4518] 4% | Training loss: 0.6898059804331172
Epoch: 83 | Iteration number: [230/4518] 5% | Training loss: 0.6896572677985482
Epoch: 83 | Iteration number: [240/4518] 5% | Training loss: 0.6895440871516864
Epoch: 83 | Iteration number: [250/4518] 5% | Training loss: 0.6894513509273529
Epoch: 83 | Iteration number: [260/4518] 5% | Training loss: 0.6892967260800875
Epoch: 83 | Iteration number: [270/4518] 5% | Training loss: 0.6892015198866527
Epoch: 83 | Iteration number: [280/4518] 6% | Training loss: 0.6890872169818197
Epoch: 83 | Iteration number: [290/4518] 6% | Training loss: 0.68900075698721
Epoch: 83 | Iteration number: [300/4518] 6% | Training loss: 0.6889242746432622
Epoch: 83 | Iteration number: [310/4518] 6% | Training loss: 0.6888704217249347
Epoch: 83 | Iteration number: [320/4518] 7% | Training loss: 0.6888146810233593
Epoch: 83 | Iteration number: [330/4518] 7% | Training loss: 0.6887353627970725
Epoch: 83 | Iteration number: [340/4518] 7% | Training loss: 0.688669596174184
Epoch: 83 | Iteration number: [350/4518] 7% | Training loss: 0.6886240567479814
Epoch: 83 | Iteration number: [360/4518] 7% | Training loss: 0.6885557055473328
Epoch: 83 | Iteration number: [370/4518] 8% | Training loss: 0.6885250634438282
Epoch: 83 | Iteration number: [380/4518] 8% | Training loss: 0.6884828561230709
Epoch: 83 | Iteration number: [390/4518] 8% | Training loss: 0.6884285824421125
Epoch: 83 | Iteration number: [400/4518] 8% | Training loss: 0.6884062373638153
Epoch: 83 | Iteration number: [410/4518] 9% | Training loss: 0.6884019156781639
Epoch: 83 | Iteration number: [420/4518] 9% | Training loss: 0.688371981893267
Epoch: 83 | Iteration number: [430/4518] 9% | Training loss: 0.6883354238299436
Epoch: 83 | Iteration number: [440/4518] 9% | Training loss: 0.6882961072705008
Epoch: 83 | Iteration number: [450/4518] 9% | Training loss: 0.6882660382323795
Epoch: 83 | Iteration number: [460/4518] 10% | Training loss: 0.6882434225600699
Epoch: 83 | Iteration number: [470/4518] 10% | Training loss: 0.6882181040784145
Epoch: 83 | Iteration number: [480/4518] 10% | Training loss: 0.6881767733643452
Epoch: 83 | Iteration number: [490/4518] 10% | Training loss: 0.6881471228842833
Epoch: 83 | Iteration number: [500/4518] 11% | Training loss: 0.6881271872520447
Epoch: 83 | Iteration number: [510/4518] 11% | Training loss: 0.6880811795300128
Epoch: 83 | Iteration number: [520/4518] 11% | Training loss: 0.6880581704469827
Epoch: 83 | Iteration number: [530/4518] 11% | Training loss: 0.6880412494236569
Epoch: 83 | Iteration number: [540/4518] 11% | Training loss: 0.6880286004808214
Epoch: 83 | Iteration number: [550/4518] 12% | Training loss: 0.6880121102116324
Epoch: 83 | Iteration number: [560/4518] 12% | Training loss: 0.6879821286669799
Epoch: 83 | Iteration number: [570/4518] 12% | Training loss: 0.6879215608563339
Epoch: 83 | Iteration number: [580/4518] 12% | Training loss: 0.6879136149225564
Epoch: 83 | Iteration number: [590/4518] 13% | Training loss: 0.687885152485411
Epoch: 83 | Iteration number: [600/4518] 13% | Training loss: 0.6878823176026344
Epoch: 83 | Iteration number: [610/4518] 13% | Training loss: 0.6878710585539458
Epoch: 83 | Iteration number: [620/4518] 13% | Training loss: 0.6878565906516967
Epoch: 83 | Iteration number: [630/4518] 13% | Training loss: 0.6878438522891392
Epoch: 83 | Iteration number: [640/4518] 14% | Training loss: 0.687816864438355
Epoch: 83 | Iteration number: [650/4518] 14% | Training loss: 0.6878040206432342
Epoch: 83 | Iteration number: [660/4518] 14% | Training loss: 0.6877748333143465
Epoch: 83 | Iteration number: [670/4518] 14% | Training loss: 0.6877645961384276
Epoch: 83 | Iteration number: [680/4518] 15% | Training loss: 0.6877594993394964
Epoch: 83 | Iteration number: [690/4518] 15% | Training loss: 0.6877270013525866
Epoch: 83 | Iteration number: [700/4518] 15% | Training loss: 0.6877209774936949
Epoch: 83 | Iteration number: [710/4518] 15% | Training loss: 0.6877065438619802
Epoch: 83 | Iteration number: [720/4518] 15% | Training loss: 0.6877011527617772
Epoch: 83 | Iteration number: [730/4518] 16% | Training loss: 0.6876872466851587
Epoch: 83 | Iteration number: [740/4518] 16% | Training loss: 0.6876598742362615
Epoch: 83 | Iteration number: [750/4518] 16% | Training loss: 0.6876601754824321
Epoch: 83 | Iteration number: [760/4518] 16% | Training loss: 0.6876386012685927
Epoch: 83 | Iteration number: [770/4518] 17% | Training loss: 0.6876124779899399
Epoch: 83 | Iteration number: [780/4518] 17% | Training loss: 0.6876065651575725
Epoch: 83 | Iteration number: [790/4518] 17% | Training loss: 0.6875943776927417
Epoch: 83 | Iteration number: [800/4518] 17% | Training loss: 0.6875905634462833
Epoch: 83 | Iteration number: [810/4518] 17% | Training loss: 0.6876069649502083
Epoch: 83 | Iteration number: [820/4518] 18% | Training loss: 0.6876052420313765
Epoch: 83 | Iteration number: [830/4518] 18% | Training loss: 0.6875922210245248
Epoch: 83 | Iteration number: [840/4518] 18% | Training loss: 0.6875907733326867
Epoch: 83 | Iteration number: [850/4518] 18% | Training loss: 0.6875871722838458
Epoch: 83 | Iteration number: [860/4518] 19% | Training loss: 0.6875671172557876
Epoch: 83 | Iteration number: [870/4518] 19% | Training loss: 0.6875616581960656
Epoch: 83 | Iteration number: [880/4518] 19% | Training loss: 0.6875575977292928
Epoch: 83 | Iteration number: [890/4518] 19% | Training loss: 0.6875464441401236
Epoch: 83 | Iteration number: [900/4518] 19% | Training loss: 0.6875221635235681
Epoch: 83 | Iteration number: [910/4518] 20% | Training loss: 0.6875144251755305
Epoch: 83 | Iteration number: [920/4518] 20% | Training loss: 0.6875108637239622
Epoch: 83 | Iteration number: [930/4518] 20% | Training loss: 0.6875007703740109
Epoch: 83 | Iteration number: [940/4518] 20% | Training loss: 0.6874850491259961
Epoch: 83 | Iteration number: [950/4518] 21% | Training loss: 0.6874731143524773
Epoch: 83 | Iteration number: [960/4518] 21% | Training loss: 0.6874738397697607
Epoch: 83 | Iteration number: [970/4518] 21% | Training loss: 0.6874763147118166
Epoch: 83 | Iteration number: [980/4518] 21% | Training loss: 0.687468532883391
Epoch: 83 | Iteration number: [990/4518] 21% | Training loss: 0.6874632950383003
Epoch: 83 | Iteration number: [1000/4518] 22% | Training loss: 0.6874586988091469
Epoch: 83 | Iteration number: [1010/4518] 22% | Training loss: 0.687448778364918
Epoch: 83 | Iteration number: [1020/4518] 22% | Training loss: 0.6874467704225989
Epoch: 83 | Iteration number: [1030/4518] 22% | Training loss: 0.6874449309793491
Epoch: 83 | Iteration number: [1040/4518] 23% | Training loss: 0.6874400857549448
Epoch: 83 | Iteration number: [1050/4518] 23% | Training loss: 0.6874354478291103
Epoch: 83 | Iteration number: [1060/4518] 23% | Training loss: 0.6874299342339893
Epoch: 83 | Iteration number: [1070/4518] 23% | Training loss: 0.6874227007415807
Epoch: 83 | Iteration number: [1080/4518] 23% | Training loss: 0.6874124646186829
Epoch: 83 | Iteration number: [1090/4518] 24% | Training loss: 0.6874062590095975
Epoch: 83 | Iteration number: [1100/4518] 24% | Training loss: 0.6874016516317021
Epoch: 83 | Iteration number: [1110/4518] 24% | Training loss: 0.6873981758817896
Epoch: 83 | Iteration number: [1120/4518] 24% | Training loss: 0.6873893992709262
Epoch: 83 | Iteration number: [1130/4518] 25% | Training loss: 0.6873877703616049
Epoch: 83 | Iteration number: [1140/4518] 25% | Training loss: 0.6873799159861448
Epoch: 83 | Iteration number: [1150/4518] 25% | Training loss: 0.6873812058179275
Epoch: 83 | Iteration number: [1160/4518] 25% | Training loss: 0.687378685741589
Epoch: 83 | Iteration number: [1170/4518] 25% | Training loss: 0.6873729415938385
Epoch: 83 | Iteration number: [1180/4518] 26% | Training loss: 0.6873677691160622
Epoch: 83 | Iteration number: [1190/4518] 26% | Training loss: 0.687364990520878
Epoch: 83 | Iteration number: [1200/4518] 26% | Training loss: 0.6873615075647831
Epoch: 83 | Iteration number: [1210/4518] 26% | Training loss: 0.6873556701604985
Epoch: 83 | Iteration number: [1220/4518] 27% | Training loss: 0.6873481801298799
Epoch: 83 | Iteration number: [1230/4518] 27% | Training loss: 0.6873423544856591
Epoch: 83 | Iteration number: [1240/4518] 27% | Training loss: 0.6873336484355311
Epoch: 83 | Iteration number: [1250/4518] 27% | Training loss: 0.6873373777389526
Epoch: 83 | Iteration number: [1260/4518] 27% | Training loss: 0.6873327138404998
Epoch: 83 | Iteration number: [1270/4518] 28% | Training loss: 0.6873256142214528
Epoch: 83 | Iteration number: [1280/4518] 28% | Training loss: 0.6873138643801212
Epoch: 83 | Iteration number: [1290/4518] 28% | Training loss: 0.6873079420060151
Epoch: 83 | Iteration number: [1300/4518] 28% | Training loss: 0.6873066018177912
Epoch: 83 | Iteration number: [1310/4518] 28% | Training loss: 0.6872991250671503
Epoch: 83 | Iteration number: [1320/4518] 29% | Training loss: 0.6872904596455169
Epoch: 83 | Iteration number: [1330/4518] 29% | Training loss: 0.6872831465158248
Epoch: 83 | Iteration number: [1340/4518] 29% | Training loss: 0.6872766031702953
Epoch: 83 | Iteration number: [1350/4518] 29% | Training loss: 0.6872816448299973
Epoch: 83 | Iteration number: [1360/4518] 30% | Training loss: 0.6872760516755722
Epoch: 83 | Iteration number: [1370/4518] 30% | Training loss: 0.6872667598463323
Epoch: 83 | Iteration number: [1380/4518] 30% | Training loss: 0.6872679443463036
Epoch: 83 | Iteration number: [1390/4518] 30% | Training loss: 0.6872626805048194
Epoch: 83 | Iteration number: [1400/4518] 30% | Training loss: 0.6872596226845469
Epoch: 83 | Iteration number: [1410/4518] 31% | Training loss: 0.6872575461441743
Epoch: 83 | Iteration number: [1420/4518] 31% | Training loss: 0.6872530970774906
Epoch: 83 | Iteration number: [1430/4518] 31% | Training loss: 0.6872396063971353
Epoch: 83 | Iteration number: [1440/4518] 31% | Training loss: 0.6872336366110378
Epoch: 83 | Iteration number: [1450/4518] 32% | Training loss: 0.6872299563473668
Epoch: 83 | Iteration number: [1460/4518] 32% | Training loss: 0.6872187085755884
Epoch: 83 | Iteration number: [1470/4518] 32% | Training loss: 0.6872184256307122
Epoch: 83 | Iteration number: [1480/4518] 32% | Training loss: 0.6872188897954451
Epoch: 83 | Iteration number: [1490/4518] 32% | Training loss: 0.6872188654121937
Epoch: 83 | Iteration number: [1500/4518] 33% | Training loss: 0.6872180637518565
Epoch: 83 | Iteration number: [1510/4518] 33% | Training loss: 0.6872237944445073
Epoch: 83 | Iteration number: [1520/4518] 33% | Training loss: 0.687228751104129
Epoch: 83 | Iteration number: [1530/4518] 33% | Training loss: 0.6872276502886628
Epoch: 83 | Iteration number: [1540/4518] 34% | Training loss: 0.6872199895707044
Epoch: 83 | Iteration number: [1550/4518] 34% | Training loss: 0.6872243755479013
Epoch: 83 | Iteration number: [1560/4518] 34% | Training loss: 0.6872163101266592
Epoch: 83 | Iteration number: [1570/4518] 34% | Training loss: 0.6872132311201399
Epoch: 83 | Iteration number: [1580/4518] 34% | Training loss: 0.6872175562608092
Epoch: 83 | Iteration number: [1590/4518] 35% | Training loss: 0.6872193546040253
Epoch: 83 | Iteration number: [1600/4518] 35% | Training loss: 0.6872138312086463
Epoch: 83 | Iteration number: [1610/4518] 35% | Training loss: 0.6872091696869512
Epoch: 83 | Iteration number: [1620/4518] 35% | Training loss: 0.6872095336884628
Epoch: 83 | Iteration number: [1630/4518] 36% | Training loss: 0.687209870442291
Epoch: 83 | Iteration number: [1640/4518] 36% | Training loss: 0.687207708853047
Epoch: 83 | Iteration number: [1650/4518] 36% | Training loss: 0.6872063452186007
Epoch: 83 | Iteration number: [1660/4518] 36% | Training loss: 0.6872016666165317
Epoch: 83 | Iteration number: [1670/4518] 36% | Training loss: 0.6871942252456071
Epoch: 83 | Iteration number: [1680/4518] 37% | Training loss: 0.6871901220154195
Epoch: 83 | Iteration number: [1690/4518] 37% | Training loss: 0.687188907487858
Epoch: 83 | Iteration number: [1700/4518] 37% | Training loss: 0.6871885259361828
Epoch: 83 | Iteration number: [1710/4518] 37% | Training loss: 0.687185578910928
Epoch: 83 | Iteration number: [1720/4518] 38% | Training loss: 0.6871905554172605
Epoch: 83 | Iteration number: [1730/4518] 38% | Training loss: 0.6871927683064014
Epoch: 83 | Iteration number: [1740/4518] 38% | Training loss: 0.6871800619980385
Epoch: 83 | Iteration number: [1750/4518] 38% | Training loss: 0.6871815983908517
Epoch: 83 | Iteration number: [1760/4518] 38% | Training loss: 0.6871768327599223
Epoch: 83 | Iteration number: [1770/4518] 39% | Training loss: 0.6871777050912717
Epoch: 83 | Iteration number: [1780/4518] 39% | Training loss: 0.6871756550971042
Epoch: 83 | Iteration number: [1790/4518] 39% | Training loss: 0.6871679819162998
Epoch: 83 | Iteration number: [1800/4518] 39% | Training loss: 0.6871727907326486
Epoch: 83 | Iteration number: [1810/4518] 40% | Training loss: 0.6871736513316961
Epoch: 83 | Iteration number: [1820/4518] 40% | Training loss: 0.6871675567967551
Epoch: 83 | Iteration number: [1830/4518] 40% | Training loss: 0.6871588735958266
Epoch: 83 | Iteration number: [1840/4518] 40% | Training loss: 0.6871415434000285
Epoch: 83 | Iteration number: [1850/4518] 40% | Training loss: 0.6871365273320997
Epoch: 83 | Iteration number: [1860/4518] 41% | Training loss: 0.6871274341498652
Epoch: 83 | Iteration number: [1870/4518] 41% | Training loss: 0.6871249903332103
Epoch: 83 | Iteration number: [1880/4518] 41% | Training loss: 0.6871210914660008
Epoch: 83 | Iteration number: [1890/4518] 41% | Training loss: 0.6871157242192163
Epoch: 83 | Iteration number: [1900/4518] 42% | Training loss: 0.6871166217954535
Epoch: 83 | Iteration number: [1910/4518] 42% | Training loss: 0.6871232106111437
Epoch: 83 | Iteration number: [1920/4518] 42% | Training loss: 0.6871253590099513
Epoch: 83 | Iteration number: [1930/4518] 42% | Training loss: 0.6871185609096072
Epoch: 83 | Iteration number: [1940/4518] 42% | Training loss: 0.6871156737669227
Epoch: 83 | Iteration number: [1950/4518] 43% | Training loss: 0.6871125478010911
Epoch: 83 | Iteration number: [1960/4518] 43% | Training loss: 0.6871124380705308
Epoch: 83 | Iteration number: [1970/4518] 43% | Training loss: 0.6871057255013945
Epoch: 83 | Iteration number: [1980/4518] 43% | Training loss: 0.6871019081635908
Epoch: 83 | Iteration number: [1990/4518] 44% | Training loss: 0.6870974198657663
Epoch: 83 | Iteration number: [2000/4518] 44% | Training loss: 0.6871015399694442
Epoch: 83 | Iteration number: [2010/4518] 44% | Training loss: 0.6871005849458685
Epoch: 83 | Iteration number: [2020/4518] 44% | Training loss: 0.6871007580863367
Epoch: 83 | Iteration number: [2030/4518] 44% | Training loss: 0.68709518950561
Epoch: 83 | Iteration number: [2040/4518] 45% | Training loss: 0.6870906902002353
Epoch: 83 | Iteration number: [2050/4518] 45% | Training loss: 0.68708828431804
Epoch: 83 | Iteration number: [2060/4518] 45% | Training loss: 0.6870856320684396
Epoch: 83 | Iteration number: [2070/4518] 45% | Training loss: 0.687086710607372
Epoch: 83 | Iteration number: [2080/4518] 46% | Training loss: 0.6870893557484333
Epoch: 83 | Iteration number: [2090/4518] 46% | Training loss: 0.6870890444545654
Epoch: 83 | Iteration number: [2100/4518] 46% | Training loss: 0.6870884868360702
Epoch: 83 | Iteration number: [2110/4518] 46% | Training loss: 0.687093344344912
Epoch: 83 | Iteration number: [2120/4518] 46% | Training loss: 0.6870870665840383
Epoch: 83 | Iteration number: [2130/4518] 47% | Training loss: 0.6870843983592002
Epoch: 83 | Iteration number: [2140/4518] 47% | Training loss: 0.6870847590894342
Epoch: 83 | Iteration number: [2150/4518] 47% | Training loss: 0.6870899838902229
Epoch: 83 | Iteration number: [2160/4518] 47% | Training loss: 0.6870852107803027
Epoch: 83 | Iteration number: [2170/4518] 48% | Training loss: 0.6870815649834646
Epoch: 83 | Iteration number: [2180/4518] 48% | Training loss: 0.6870835287035059
Epoch: 83 | Iteration number: [2190/4518] 48% | Training loss: 0.6870834547362915
Epoch: 83 | Iteration number: [2200/4518] 48% | Training loss: 0.6870824309912595
Epoch: 83 | Iteration number: [2210/4518] 48% | Training loss: 0.6870870425420649
Epoch: 83 | Iteration number: [2220/4518] 49% | Training loss: 0.6870864646391825
Epoch: 83 | Iteration number: [2230/4518] 49% | Training loss: 0.6870857879719927
Epoch: 83 | Iteration number: [2240/4518] 49% | Training loss: 0.6870802952242749
Epoch: 83 | Iteration number: [2250/4518] 49% | Training loss: 0.687081050157547
Epoch: 83 | Iteration number: [2260/4518] 50% | Training loss: 0.6870762076789299
Epoch: 83 | Iteration number: [2270/4518] 50% | Training loss: 0.6870729258932206
Epoch: 83 | Iteration number: [2280/4518] 50% | Training loss: 0.6870699532983596
Epoch: 83 | Iteration number: [2290/4518] 50% | Training loss: 0.6870650348965257
Epoch: 83 | Iteration number: [2300/4518] 50% | Training loss: 0.6870656146692193
Epoch: 83 | Iteration number: [2310/4518] 51% | Training loss: 0.6870637645195057
Epoch: 83 | Iteration number: [2320/4518] 51% | Training loss: 0.6870600309865228
Epoch: 83 | Iteration number: [2330/4518] 51% | Training loss: 0.687066202306952
Epoch: 83 | Iteration number: [2340/4518] 51% | Training loss: 0.6870690399255508
Epoch: 83 | Iteration number: [2350/4518] 52% | Training loss: 0.6870696109660128
Epoch: 83 | Iteration number: [2360/4518] 52% | Training loss: 0.6870728298011473
Epoch: 83 | Iteration number: [2370/4518] 52% | Training loss: 0.6870650543945248
Epoch: 83 | Iteration number: [2380/4518] 52% | Training loss: 0.6870612171016821
Epoch: 83 | Iteration number: [2390/4518] 52% | Training loss: 0.6870621789948212
Epoch: 83 | Iteration number: [2400/4518] 53% | Training loss: 0.6870624884963036
Epoch: 83 | Iteration number: [2410/4518] 53% | Training loss: 0.6870639999625099
Epoch: 83 | Iteration number: [2420/4518] 53% | Training loss: 0.6870624036582048
Epoch: 83 | Iteration number: [2430/4518] 53% | Training loss: 0.6870579964094201
Epoch: 83 | Iteration number: [2440/4518] 54% | Training loss: 0.6870606758799709
Epoch: 83 | Iteration number: [2450/4518] 54% | Training loss: 0.687064960221855
Epoch: 83 | Iteration number: [2460/4518] 54% | Training loss: 0.6870632246984699
Epoch: 83 | Iteration number: [2470/4518] 54% | Training loss: 0.6870649032023272
Epoch: 83 | Iteration number: [2480/4518] 54% | Training loss: 0.6870637719429309
Epoch: 83 | Iteration number: [2490/4518] 55% | Training loss: 0.6870603565710137
Epoch: 83 | Iteration number: [2500/4518] 55% | Training loss: 0.6870545694351197
Epoch: 83 | Iteration number: [2510/4518] 55% | Training loss: 0.6870551382877912
Epoch: 83 | Iteration number: [2520/4518] 55% | Training loss: 0.6870545810886792
Epoch: 83 | Iteration number: [2530/4518] 55% | Training loss: 0.6870532015095586
Epoch: 83 | Iteration number: [2540/4518] 56% | Training loss: 0.6870488820113535
Epoch: 83 | Iteration number: [2550/4518] 56% | Training loss: 0.6870508881409964
Epoch: 83 | Iteration number: [2560/4518] 56% | Training loss: 0.6870531987864524
Epoch: 83 | Iteration number: [2570/4518] 56% | Training loss: 0.6870509209567934
Epoch: 83 | Iteration number: [2580/4518] 57% | Training loss: 0.6870463111834932
Epoch: 83 | Iteration number: [2590/4518] 57% | Training loss: 0.6870413024222989
Epoch: 83 | Iteration number: [2600/4518] 57% | Training loss: 0.6870410407506503
Epoch: 83 | Iteration number: [2610/4518] 57% | Training loss: 0.6870376555398963
Epoch: 83 | Iteration number: [2620/4518] 57% | Training loss: 0.6870358446172176
Epoch: 83 | Iteration number: [2630/4518] 58% | Training loss: 0.6870339454580169
Epoch: 83 | Iteration number: [2640/4518] 58% | Training loss: 0.6870323803162937
Epoch: 83 | Iteration number: [2650/4518] 58% | Training loss: 0.6870298996736418
Epoch: 83 | Iteration number: [2660/4518] 58% | Training loss: 0.6870310082695538
Epoch: 83 | Iteration number: [2670/4518] 59% | Training loss: 0.6870364012566399
Epoch: 83 | Iteration number: [2680/4518] 59% | Training loss: 0.6870353201209609
Epoch: 83 | Iteration number: [2690/4518] 59% | Training loss: 0.6870353019592044
Epoch: 83 | Iteration number: [2700/4518] 59% | Training loss: 0.6870357498195436
Epoch: 83 | Iteration number: [2710/4518] 59% | Training loss: 0.687036313451964
Epoch: 83 | Iteration number: [2720/4518] 60% | Training loss: 0.6870348978130256
Epoch: 83 | Iteration number: [2730/4518] 60% | Training loss: 0.6870311055864606
Epoch: 83 | Iteration number: [2740/4518] 60% | Training loss: 0.6870279829432494
Epoch: 83 | Iteration number: [2750/4518] 60% | Training loss: 0.6870294595198198
Epoch: 83 | Iteration number: [2760/4518] 61% | Training loss: 0.6870322515783103
Epoch: 83 | Iteration number: [2770/4518] 61% | Training loss: 0.6870337966762294
Epoch: 83 | Iteration number: [2780/4518] 61% | Training loss: 0.6870300265953695
Epoch: 83 | Iteration number: [2790/4518] 61% | Training loss: 0.687028521961636
Epoch: 83 | Iteration number: [2800/4518] 61% | Training loss: 0.687027954437903
Epoch: 83 | Iteration number: [2810/4518] 62% | Training loss: 0.6870231409301961
Epoch: 83 | Iteration number: [2820/4518] 62% | Training loss: 0.6870198091082539
Epoch: 83 | Iteration number: [2830/4518] 62% | Training loss: 0.687015615672189
Epoch: 83 | Iteration number: [2840/4518] 62% | Training loss: 0.6870153363321868
Epoch: 83 | Iteration number: [2850/4518] 63% | Training loss: 0.6870136903252518
Epoch: 83 | Iteration number: [2860/4518] 63% | Training loss: 0.6870156020551295
Epoch: 83 | Iteration number: [2870/4518] 63% | Training loss: 0.6870152908542846
Epoch: 83 | Iteration number: [2880/4518] 63% | Training loss: 0.6870112739710345
Epoch: 83 | Iteration number: [2890/4518] 63% | Training loss: 0.6870071982017438
Epoch: 83 | Iteration number: [2900/4518] 64% | Training loss: 0.6870064377579196
Epoch: 83 | Iteration number: [2910/4518] 64% | Training loss: 0.687003263370278
Epoch: 83 | Iteration number: [2920/4518] 64% | Training loss: 0.6870009688277767
Epoch: 83 | Iteration number: [2930/4518] 64% | Training loss: 0.6869977167441983
Epoch: 83 | Iteration number: [2940/4518] 65% | Training loss: 0.6869940232865664
Epoch: 83 | Iteration number: [2950/4518] 65% | Training loss: 0.6869939648903023
Epoch: 83 | Iteration number: [2960/4518] 65% | Training loss: 0.6869951556260522
Epoch: 83 | Iteration number: [2970/4518] 65% | Training loss: 0.6869949137923693
Epoch: 83 | Iteration number: [2980/4518] 65% | Training loss: 0.6869976876166043
Epoch: 83 | Iteration number: [2990/4518] 66% | Training loss: 0.6869967795135983
Epoch: 83 | Iteration number: [3000/4518] 66% | Training loss: 0.6869950012365977
Epoch: 83 | Iteration number: [3010/4518] 66% | Training loss: 0.6869946832078636
Epoch: 83 | Iteration number: [3020/4518] 66% | Training loss: 0.6869990705259589
Epoch: 83 | Iteration number: [3030/4518] 67% | Training loss: 0.6869953710253877
Epoch: 83 | Iteration number: [3040/4518] 67% | Training loss: 0.6869944799495371
Epoch: 83 | Iteration number: [3050/4518] 67% | Training loss: 0.6870004972278094
Epoch: 83 | Iteration number: [3060/4518] 67% | Training loss: 0.6870020754781424
Epoch: 83 | Iteration number: [3070/4518] 67% | Training loss: 0.6870009781677482
Epoch: 83 | Iteration number: [3080/4518] 68% | Training loss: 0.686999365280975
Epoch: 83 | Iteration number: [3090/4518] 68% | Training loss: 0.686996170482975
Epoch: 83 | Iteration number: [3100/4518] 68% | Training loss: 0.686992276580103
Epoch: 83 | Iteration number: [3110/4518] 68% | Training loss: 0.6869925737764291
Epoch: 83 | Iteration number: [3120/4518] 69% | Training loss: 0.6869944870854036
Epoch: 83 | Iteration number: [3130/4518] 69% | Training loss: 0.6869932958493218
Epoch: 83 | Iteration number: [3140/4518] 69% | Training loss: 0.68698873844496
Epoch: 83 | Iteration number: [3150/4518] 69% | Training loss: 0.6869875344965193
Epoch: 83 | Iteration number: [3160/4518] 69% | Training loss: 0.6869881613345086
Epoch: 83 | Iteration number: [3170/4518] 70% | Training loss: 0.6869897311418215
Epoch: 83 | Iteration number: [3180/4518] 70% | Training loss: 0.6869873334214373
Epoch: 83 | Iteration number: [3190/4518] 70% | Training loss: 0.6869843505019304
Epoch: 83 | Iteration number: [3200/4518] 70% | Training loss: 0.6869828910566866
Epoch: 83 | Iteration number: [3210/4518] 71% | Training loss: 0.6869839151886022
Epoch: 83 | Iteration number: [3220/4518] 71% | Training loss: 0.6869817276734003
Epoch: 83 | Iteration number: [3230/4518] 71% | Training loss: 0.6869825612649829
Epoch: 83 | Iteration number: [3240/4518] 71% | Training loss: 0.6869762451744373
Epoch: 83 | Iteration number: [3250/4518] 71% | Training loss: 0.6869788239185627
Epoch: 83 | Iteration number: [3260/4518] 72% | Training loss: 0.6869782724263478
Epoch: 83 | Iteration number: [3270/4518] 72% | Training loss: 0.686974025428842
Epoch: 83 | Iteration number: [3280/4518] 72% | Training loss: 0.6869734868043806
Epoch: 83 | Iteration number: [3290/4518] 72% | Training loss: 0.6869731116620965
Epoch: 83 | Iteration number: [3300/4518] 73% | Training loss: 0.6869770787520842
Epoch: 83 | Iteration number: [3310/4518] 73% | Training loss: 0.6869743409473731
Epoch: 83 | Iteration number: [3320/4518] 73% | Training loss: 0.6869735722979867
Epoch: 83 | Iteration number: [3330/4518] 73% | Training loss: 0.6869732793386992
Epoch: 83 | Iteration number: [3340/4518] 73% | Training loss: 0.6869741104498595
Epoch: 83 | Iteration number: [3350/4518] 74% | Training loss: 0.686968249562961
Epoch: 83 | Iteration number: [3360/4518] 74% | Training loss: 0.6869640027838094
Epoch: 83 | Iteration number: [3370/4518] 74% | Training loss: 0.6869682640279436
Epoch: 83 | Iteration number: [3380/4518] 74% | Training loss: 0.6869677758781162
Epoch: 83 | Iteration number: [3390/4518] 75% | Training loss: 0.6869655736076445
Epoch: 83 | Iteration number: [3400/4518] 75% | Training loss: 0.6869672264071072
Epoch: 83 | Iteration number: [3410/4518] 75% | Training loss: 0.686969878631603
Epoch: 83 | Iteration number: [3420/4518] 75% | Training loss: 0.6869694716749135
Epoch: 83 | Iteration number: [3430/4518] 75% | Training loss: 0.6869713813327144
Epoch: 83 | Iteration number: [3440/4518] 76% | Training loss: 0.6869696758167688
Epoch: 83 | Iteration number: [3450/4518] 76% | Training loss: 0.6869695237926815
Epoch: 83 | Iteration number: [3460/4518] 76% | Training loss: 0.6869685233500652
Epoch: 83 | Iteration number: [3470/4518] 76% | Training loss: 0.6869686978179371
Epoch: 83 | Iteration number: [3480/4518] 77% | Training loss: 0.6869702398777008
Epoch: 83 | Iteration number: [3490/4518] 77% | Training loss: 0.6869694561705548
Epoch: 83 | Iteration number: [3500/4518] 77% | Training loss: 0.6869673549788339
Epoch: 83 | Iteration number: [3510/4518] 77% | Training loss: 0.6869641764890774
Epoch: 83 | Iteration number: [3520/4518] 77% | Training loss: 0.6869652384045449
Epoch: 83 | Iteration number: [3530/4518] 78% | Training loss: 0.6869641743368198
Epoch: 83 | Iteration number: [3540/4518] 78% | Training loss: 0.6869636632965109
Epoch: 83 | Iteration number: [3550/4518] 78% | Training loss: 0.6869659344075432
Epoch: 83 | Iteration number: [3560/4518] 78% | Training loss: 0.6869653460015072
Epoch: 83 | Iteration number: [3570/4518] 79% | Training loss: 0.6869632790903417
Epoch: 83 | Iteration number: [3580/4518] 79% | Training loss: 0.6869653664154713
Epoch: 83 | Iteration number: [3590/4518] 79% | Training loss: 0.686964518977407
Epoch: 83 | Iteration number: [3600/4518] 79% | Training loss: 0.6869661258657773
Epoch: 83 | Iteration number: [3610/4518] 79% | Training loss: 0.6869654661400496
Epoch: 83 | Iteration number: [3620/4518] 80% | Training loss: 0.6869672387015096
Epoch: 83 | Iteration number: [3630/4518] 80% | Training loss: 0.6869647771694772
Epoch: 83 | Iteration number: [3640/4518] 80% | Training loss: 0.6869660698450528
Epoch: 83 | Iteration number: [3650/4518] 80% | Training loss: 0.6869674298861256
Epoch: 83 | Iteration number: [3660/4518] 81% | Training loss: 0.6869689351548263
Epoch: 83 | Iteration number: [3670/4518] 81% | Training loss: 0.6869633562071122
Epoch: 83 | Iteration number: [3680/4518] 81% | Training loss: 0.6869611732337786
Epoch: 83 | Iteration number: [3690/4518] 81% | Training loss: 0.6869605059223123
Epoch: 83 | Iteration number: [3700/4518] 81% | Training loss: 0.6869592819826023
Epoch: 83 | Iteration number: [3710/4518] 82% | Training loss: 0.6869594058097213
Epoch: 83 | Iteration number: [3720/4518] 82% | Training loss: 0.6869568840470365
Epoch: 83 | Iteration number: [3730/4518] 82% | Training loss: 0.6869612279909865
Epoch: 83 | Iteration number: [3740/4518] 82% | Training loss: 0.686961491541429
Epoch: 83 | Iteration number: [3750/4518] 83% | Training loss: 0.6869595719814301
Epoch: 83 | Iteration number: [3760/4518] 83% | Training loss: 0.6869576470648989
Epoch: 83 | Iteration number: [3770/4518] 83% | Training loss: 0.6869593825359244
Epoch: 83 | Iteration number: [3780/4518] 83% | Training loss: 0.6869617838550497
Epoch: 83 | Iteration number: [3790/4518] 83% | Training loss: 0.6869637518728
Epoch: 83 | Iteration number: [3800/4518] 84% | Training loss: 0.6869635753725705
Epoch: 83 | Iteration number: [3810/4518] 84% | Training loss: 0.6869610467295009
Epoch: 83 | Iteration number: [3820/4518] 84% | Training loss: 0.6869606912136078
Epoch: 83 | Iteration number: [3830/4518] 84% | Training loss: 0.6869587142380348
Epoch: 83 | Iteration number: [3840/4518] 84% | Training loss: 0.6869561354629695
Epoch: 83 | Iteration number: [3850/4518] 85% | Training loss: 0.6869539830746588
Epoch: 83 | Iteration number: [3860/4518] 85% | Training loss: 0.6869540301474882
Epoch: 83 | Iteration number: [3870/4518] 85% | Training loss: 0.686955892238814
Epoch: 83 | Iteration number: [3880/4518] 85% | Training loss: 0.6869530363949303
Epoch: 83 | Iteration number: [3890/4518] 86% | Training loss: 0.6869528171029373
Epoch: 83 | Iteration number: [3900/4518] 86% | Training loss: 0.6869513406050511
Epoch: 83 | Iteration number: [3910/4518] 86% | Training loss: 0.6869495157085721
Epoch: 83 | Iteration number: [3920/4518] 86% | Training loss: 0.6869520850023445
Epoch: 83 | Iteration number: [3930/4518] 86% | Training loss: 0.686956160107945
Epoch: 83 | Iteration number: [3940/4518] 87% | Training loss: 0.6869511751656605
Epoch: 83 | Iteration number: [3950/4518] 87% | Training loss: 0.6869471867929531
Epoch: 83 | Iteration number: [3960/4518] 87% | Training loss: 0.6869496117637615
Epoch: 83 | Iteration number: [3970/4518] 87% | Training loss: 0.6869484658205239
Epoch: 83 | Iteration number: [3980/4518] 88% | Training loss: 0.6869480546545144
Epoch: 83 | Iteration number: [3990/4518] 88% | Training loss: 0.6869482529641393
Epoch: 83 | Iteration number: [4000/4518] 88% | Training loss: 0.6869444238692523
Epoch: 83 | Iteration number: [4010/4518] 88% | Training loss: 0.6869425423870658
Epoch: 83 | Iteration number: [4020/4518] 88% | Training loss: 0.6869439051963797
Epoch: 83 | Iteration number: [4030/4518] 89% | Training loss: 0.6869417819876233
Epoch: 83 | Iteration number: [4040/4518] 89% | Training loss: 0.6869481882836559
Epoch: 83 | Iteration number: [4050/4518] 89% | Training loss: 0.6869499705603094
Epoch: 83 | Iteration number: [4060/4518] 89% | Training loss: 0.6869502293652502
Epoch: 83 | Iteration number: [4070/4518] 90% | Training loss: 0.6869502751188723
Epoch: 83 | Iteration number: [4080/4518] 90% | Training loss: 0.686954535222521
Epoch: 83 | Iteration number: [4090/4518] 90% | Training loss: 0.6869511386730268
Epoch: 83 | Iteration number: [4100/4518] 90% | Training loss: 0.6869511613613222
Epoch: 83 | Iteration number: [4110/4518] 90% | Training loss: 0.6869507200671519
Epoch: 83 | Iteration number: [4120/4518] 91% | Training loss: 0.6869524372723496
Epoch: 83 | Iteration number: [4130/4518] 91% | Training loss: 0.6869511966988192
Epoch: 83 | Iteration number: [4140/4518] 91% | Training loss: 0.6869476236726927
Epoch: 83 | Iteration number: [4150/4518] 91% | Training loss: 0.6869490133567029
Epoch: 83 | Iteration number: [4160/4518] 92% | Training loss: 0.6869451746344566
Epoch: 83 | Iteration number: [4170/4518] 92% | Training loss: 0.6869427265023156
Epoch: 83 | Iteration number: [4180/4518] 92% | Training loss: 0.6869379834267512
Epoch: 83 | Iteration number: [4190/4518] 92% | Training loss: 0.6869382799952013
Epoch: 83 | Iteration number: [4200/4518] 92% | Training loss: 0.6869356051796959
Epoch: 83 | Iteration number: [4210/4518] 93% | Training loss: 0.6869337337741942
Epoch: 83 | Iteration number: [4220/4518] 93% | Training loss: 0.6869359252577144
Epoch: 83 | Iteration number: [4230/4518] 93% | Training loss: 0.6869352074238707
Epoch: 83 | Iteration number: [4240/4518] 93% | Training loss: 0.6869330139936142
Epoch: 83 | Iteration number: [4250/4518] 94% | Training loss: 0.6869333013786989
Epoch: 83 | Iteration number: [4260/4518] 94% | Training loss: 0.6869332998851095
Epoch: 83 | Iteration number: [4270/4518] 94% | Training loss: 0.686929806836595
Epoch: 83 | Iteration number: [4280/4518] 94% | Training loss: 0.6869287322475531
Epoch: 83 | Iteration number: [4290/4518] 94% | Training loss: 0.6869290846766848
Epoch: 83 | Iteration number: [4300/4518] 95% | Training loss: 0.6869286449426828
Epoch: 83 | Iteration number: [4310/4518] 95% | Training loss: 0.6869288942100277
Epoch: 83 | Iteration number: [4320/4518] 95% | Training loss: 0.686928802356124
Epoch: 83 | Iteration number: [4330/4518] 95% | Training loss: 0.6869293792693775
Epoch: 83 | Iteration number: [4340/4518] 96% | Training loss: 0.686927338308453
Epoch: 83 | Iteration number: [4350/4518] 96% | Training loss: 0.6869285257794391
Epoch: 83 | Iteration number: [4360/4518] 96% | Training loss: 0.6869251356622494
Epoch: 83 | Iteration number: [4370/4518] 96% | Training loss: 0.6869245393734502
Epoch: 83 | Iteration number: [4380/4518] 96% | Training loss: 0.6869246361326409
Epoch: 83 | Iteration number: [4390/4518] 97% | Training loss: 0.6869250197073865
Epoch: 83 | Iteration number: [4400/4518] 97% | Training loss: 0.686925198693167
Epoch: 83 | Iteration number: [4410/4518] 97% | Training loss: 0.6869229225750142
Epoch: 83 | Iteration number: [4420/4518] 97% | Training loss: 0.6869219096402777
Epoch: 83 | Iteration number: [4430/4518] 98% | Training loss: 0.6869216895668555
Epoch: 83 | Iteration number: [4440/4518] 98% | Training loss: 0.686920228399135
Epoch: 83 | Iteration number: [4450/4518] 98% | Training loss: 0.6869193185045478
Epoch: 83 | Iteration number: [4460/4518] 98% | Training loss: 0.6869180079532846
Epoch: 83 | Iteration number: [4470/4518] 98% | Training loss: 0.6869164789416379
Epoch: 83 | Iteration number: [4480/4518] 99% | Training loss: 0.6869178915130241
Epoch: 83 | Iteration number: [4490/4518] 99% | Training loss: 0.6869176553724072
Epoch: 83 | Iteration number: [4500/4518] 99% | Training loss: 0.6869180728329553
Epoch: 83 | Iteration number: [4510/4518] 99% | Training loss: 0.686919204636318

 End of epoch: 83 | Train Loss: 0.6867674837443828 | Training Time: 639 

 End of epoch: 83 | Eval Loss: 0.6899601172427742 | Evaluating Time: 17 
Epoch: 84 | Iteration number: [10/4518] 0% | Training loss: 0.756359088420868
Epoch: 84 | Iteration number: [20/4518] 0% | Training loss: 0.721503609418869
Epoch: 84 | Iteration number: [30/4518] 0% | Training loss: 0.7099338908990224
Epoch: 84 | Iteration number: [40/4518] 0% | Training loss: 0.7044048205018043
Epoch: 84 | Iteration number: [50/4518] 1% | Training loss: 0.7010900807380677
Epoch: 84 | Iteration number: [60/4518] 1% | Training loss: 0.6987818866968155
Epoch: 84 | Iteration number: [70/4518] 1% | Training loss: 0.6971342188971383
Epoch: 84 | Iteration number: [80/4518] 1% | Training loss: 0.6957830518484116
Epoch: 84 | Iteration number: [90/4518] 1% | Training loss: 0.6948274347517226
Epoch: 84 | Iteration number: [100/4518] 2% | Training loss: 0.6940172702074051
Epoch: 84 | Iteration number: [110/4518] 2% | Training loss: 0.693290688232942
Epoch: 84 | Iteration number: [120/4518] 2% | Training loss: 0.6928127959370614
Epoch: 84 | Iteration number: [130/4518] 2% | Training loss: 0.6922435600024003
Epoch: 84 | Iteration number: [140/4518] 3% | Training loss: 0.6918626329728536
Epoch: 84 | Iteration number: [150/4518] 3% | Training loss: 0.6914444661140442
Epoch: 84 | Iteration number: [160/4518] 3% | Training loss: 0.6911471001803875
Epoch: 84 | Iteration number: [170/4518] 3% | Training loss: 0.6908622787279242
Epoch: 84 | Iteration number: [180/4518] 3% | Training loss: 0.6906127979358038
Epoch: 84 | Iteration number: [190/4518] 4% | Training loss: 0.6904308485357384
Epoch: 84 | Iteration number: [200/4518] 4% | Training loss: 0.6902924388647079
Epoch: 84 | Iteration number: [210/4518] 4% | Training loss: 0.6901124409266881
Epoch: 84 | Iteration number: [220/4518] 4% | Training loss: 0.6899780002507296
Epoch: 84 | Iteration number: [230/4518] 5% | Training loss: 0.6898250712000805
Epoch: 84 | Iteration number: [240/4518] 5% | Training loss: 0.6897012206415335
Epoch: 84 | Iteration number: [250/4518] 5% | Training loss: 0.6896313960552216
Epoch: 84 | Iteration number: [260/4518] 5% | Training loss: 0.6895378234294745
Epoch: 84 | Iteration number: [270/4518] 5% | Training loss: 0.6894299866976561
Epoch: 84 | Iteration number: [280/4518] 6% | Training loss: 0.6893591165542603
Epoch: 84 | Iteration number: [290/4518] 6% | Training loss: 0.689292363462777
Epoch: 84 | Iteration number: [300/4518] 6% | Training loss: 0.689227533141772
Epoch: 84 | Iteration number: [310/4518] 6% | Training loss: 0.6891166931198489
Epoch: 84 | Iteration number: [320/4518] 7% | Training loss: 0.6890790462493896
Epoch: 84 | Iteration number: [330/4518] 7% | Training loss: 0.6889935052756108
Epoch: 84 | Iteration number: [340/4518] 7% | Training loss: 0.6889443202930339
Epoch: 84 | Iteration number: [350/4518] 7% | Training loss: 0.6888708324091775
Epoch: 84 | Iteration number: [360/4518] 7% | Training loss: 0.6888347514801555
Epoch: 84 | Iteration number: [370/4518] 8% | Training loss: 0.6887767720866848
Epoch: 84 | Iteration number: [380/4518] 8% | Training loss: 0.688694703578949
Epoch: 84 | Iteration number: [390/4518] 8% | Training loss: 0.6886481451682556
Epoch: 84 | Iteration number: [400/4518] 8% | Training loss: 0.6886323402822018
Epoch: 84 | Iteration number: [410/4518] 9% | Training loss: 0.6886244554345201
Epoch: 84 | Iteration number: [420/4518] 9% | Training loss: 0.6885876313561485
Epoch: 84 | Iteration number: [430/4518] 9% | Training loss: 0.6885419679242512
Epoch: 84 | Iteration number: [440/4518] 9% | Training loss: 0.6885196604511955
Epoch: 84 | Iteration number: [450/4518] 9% | Training loss: 0.6884828599294027
Epoch: 84 | Iteration number: [460/4518] 10% | Training loss: 0.6884539578271949
Epoch: 84 | Iteration number: [470/4518] 10% | Training loss: 0.6884199851370872
Epoch: 84 | Iteration number: [480/4518] 10% | Training loss: 0.6883905041962862
Epoch: 84 | Iteration number: [490/4518] 10% | Training loss: 0.6883350648442094
Epoch: 84 | Iteration number: [500/4518] 11% | Training loss: 0.6883032687902451
Epoch: 84 | Iteration number: [510/4518] 11% | Training loss: 0.6882872693678912
Epoch: 84 | Iteration number: [520/4518] 11% | Training loss: 0.6882440565870358
Epoch: 84 | Iteration number: [530/4518] 11% | Training loss: 0.688221833840856
Epoch: 84 | Iteration number: [540/4518] 11% | Training loss: 0.6881715716035278
Epoch: 84 | Iteration number: [550/4518] 12% | Training loss: 0.6881259007887407
Epoch: 84 | Iteration number: [560/4518] 12% | Training loss: 0.6881297562803541
Epoch: 84 | Iteration number: [570/4518] 12% | Training loss: 0.6880965738965754
Epoch: 84 | Iteration number: [580/4518] 12% | Training loss: 0.6880891451547886
Epoch: 84 | Iteration number: [590/4518] 13% | Training loss: 0.6880616731562856
Epoch: 84 | Iteration number: [600/4518] 13% | Training loss: 0.6880290919542312
Epoch: 84 | Iteration number: [610/4518] 13% | Training loss: 0.6880104180242195
Epoch: 84 | Iteration number: [620/4518] 13% | Training loss: 0.687999767930277
Epoch: 84 | Iteration number: [630/4518] 13% | Training loss: 0.6879571091561091
Epoch: 84 | Iteration number: [640/4518] 14% | Training loss: 0.6879230326041579
Epoch: 84 | Iteration number: [650/4518] 14% | Training loss: 0.6879043494738065
Epoch: 84 | Iteration number: [660/4518] 14% | Training loss: 0.6878903127980954
Epoch: 84 | Iteration number: [670/4518] 14% | Training loss: 0.6878778598201809
Epoch: 84 | Iteration number: [680/4518] 15% | Training loss: 0.6878625737393603
Epoch: 84 | Iteration number: [690/4518] 15% | Training loss: 0.6878487428029378
Epoch: 84 | Iteration number: [700/4518] 15% | Training loss: 0.6878192733015333
Epoch: 84 | Iteration number: [710/4518] 15% | Training loss: 0.6877936233936901
Epoch: 84 | Iteration number: [720/4518] 15% | Training loss: 0.6877739179465506
Epoch: 84 | Iteration number: [730/4518] 16% | Training loss: 0.6877517387475053
Epoch: 84 | Iteration number: [740/4518] 16% | Training loss: 0.6877577055144954
Epoch: 84 | Iteration number: [750/4518] 16% | Training loss: 0.687730761051178
Epoch: 84 | Iteration number: [760/4518] 16% | Training loss: 0.6877160635433699
Epoch: 84 | Iteration number: [770/4518] 17% | Training loss: 0.6876926183700561
Epoch: 84 | Iteration number: [780/4518] 17% | Training loss: 0.687661349773407
Epoch: 84 | Iteration number: [790/4518] 17% | Training loss: 0.6876541782783556
Epoch: 84 | Iteration number: [800/4518] 17% | Training loss: 0.6876352934539318
Epoch: 84 | Iteration number: [810/4518] 17% | Training loss: 0.6876442849636077
Epoch: 84 | Iteration number: [820/4518] 18% | Training loss: 0.6876286552446644
Epoch: 84 | Iteration number: [830/4518] 18% | Training loss: 0.6876040810562042
Epoch: 84 | Iteration number: [840/4518] 18% | Training loss: 0.687597035013494
Epoch: 84 | Iteration number: [850/4518] 18% | Training loss: 0.6875979157055125
Epoch: 84 | Iteration number: [860/4518] 19% | Training loss: 0.6875885318185008
Epoch: 84 | Iteration number: [870/4518] 19% | Training loss: 0.6875808672658328
Epoch: 84 | Iteration number: [880/4518] 19% | Training loss: 0.687558663636446
Epoch: 84 | Iteration number: [890/4518] 19% | Training loss: 0.6875345211350516
Epoch: 84 | Iteration number: [900/4518] 19% | Training loss: 0.6875399267011219
Epoch: 84 | Iteration number: [910/4518] 20% | Training loss: 0.6875332768801804
Epoch: 84 | Iteration number: [920/4518] 20% | Training loss: 0.6875126519928808
Epoch: 84 | Iteration number: [930/4518] 20% | Training loss: 0.6875025894052239
Epoch: 84 | Iteration number: [940/4518] 20% | Training loss: 0.6874863022819478
Epoch: 84 | Iteration number: [950/4518] 21% | Training loss: 0.6874837348335667
Epoch: 84 | Iteration number: [960/4518] 21% | Training loss: 0.6874765089402596
Epoch: 84 | Iteration number: [970/4518] 21% | Training loss: 0.6874614642452948
Epoch: 84 | Iteration number: [980/4518] 21% | Training loss: 0.6874668713126864
Epoch: 84 | Iteration number: [990/4518] 21% | Training loss: 0.6874697522683577
Epoch: 84 | Iteration number: [1000/4518] 22% | Training loss: 0.687459134042263
Epoch: 84 | Iteration number: [1010/4518] 22% | Training loss: 0.6874616428176955
Epoch: 84 | Iteration number: [1020/4518] 22% | Training loss: 0.6874607121827556
Epoch: 84 | Iteration number: [1030/4518] 22% | Training loss: 0.6874505794742732
Epoch: 84 | Iteration number: [1040/4518] 23% | Training loss: 0.6874487630449808
Epoch: 84 | Iteration number: [1050/4518] 23% | Training loss: 0.6874355527900514
Epoch: 84 | Iteration number: [1060/4518] 23% | Training loss: 0.6874343082589923
Epoch: 84 | Iteration number: [1070/4518] 23% | Training loss: 0.6874222527040499
Epoch: 84 | Iteration number: [1080/4518] 23% | Training loss: 0.6874267170274699
Epoch: 84 | Iteration number: [1090/4518] 24% | Training loss: 0.6874141909113718
Epoch: 84 | Iteration number: [1100/4518] 24% | Training loss: 0.6874080859531055
Epoch: 84 | Iteration number: [1110/4518] 24% | Training loss: 0.6873866380334974
Epoch: 84 | Iteration number: [1120/4518] 24% | Training loss: 0.6873738064297608
Epoch: 84 | Iteration number: [1130/4518] 25% | Training loss: 0.6873773927182223
Epoch: 84 | Iteration number: [1140/4518] 25% | Training loss: 0.6873715089078535
Epoch: 84 | Iteration number: [1150/4518] 25% | Training loss: 0.6873754847049713
Epoch: 84 | Iteration number: [1160/4518] 25% | Training loss: 0.6873633447906067
Epoch: 84 | Iteration number: [1170/4518] 25% | Training loss: 0.6873700055301699
Epoch: 84 | Iteration number: [1180/4518] 26% | Training loss: 0.6873719297223172
Epoch: 84 | Iteration number: [1190/4518] 26% | Training loss: 0.6873695954054344
Epoch: 84 | Iteration number: [1200/4518] 26% | Training loss: 0.6873657457033793
Epoch: 84 | Iteration number: [1210/4518] 26% | Training loss: 0.6873643235234189
Epoch: 84 | Iteration number: [1220/4518] 27% | Training loss: 0.6873606333478552
Epoch: 84 | Iteration number: [1230/4518] 27% | Training loss: 0.6873573980680326
Epoch: 84 | Iteration number: [1240/4518] 27% | Training loss: 0.6873616830956552
Epoch: 84 | Iteration number: [1250/4518] 27% | Training loss: 0.6873593894481659
Epoch: 84 | Iteration number: [1260/4518] 27% | Training loss: 0.687360782803051
Epoch: 84 | Iteration number: [1270/4518] 28% | Training loss: 0.6873607334189528
Epoch: 84 | Iteration number: [1280/4518] 28% | Training loss: 0.6873680454213172
Epoch: 84 | Iteration number: [1290/4518] 28% | Training loss: 0.6873614819936974
Epoch: 84 | Iteration number: [1300/4518] 28% | Training loss: 0.6873614450601431
Epoch: 84 | Iteration number: [1310/4518] 28% | Training loss: 0.6873636104223383
Epoch: 84 | Iteration number: [1320/4518] 29% | Training loss: 0.6873565476952177
Epoch: 84 | Iteration number: [1330/4518] 29% | Training loss: 0.6873462634875362
Epoch: 84 | Iteration number: [1340/4518] 29% | Training loss: 0.6873329030044043
Epoch: 84 | Iteration number: [1350/4518] 29% | Training loss: 0.687333349607609
Epoch: 84 | Iteration number: [1360/4518] 30% | Training loss: 0.6873249639921328
Epoch: 84 | Iteration number: [1370/4518] 30% | Training loss: 0.6873198322571107
Epoch: 84 | Iteration number: [1380/4518] 30% | Training loss: 0.6873154850541682
Epoch: 84 | Iteration number: [1390/4518] 30% | Training loss: 0.6873019299918799
Epoch: 84 | Iteration number: [1400/4518] 30% | Training loss: 0.6872970042909895
Epoch: 84 | Iteration number: [1410/4518] 31% | Training loss: 0.6872926600435947
Epoch: 84 | Iteration number: [1420/4518] 31% | Training loss: 0.6872847168798178
Epoch: 84 | Iteration number: [1430/4518] 31% | Training loss: 0.6872870436498335
Epoch: 84 | Iteration number: [1440/4518] 31% | Training loss: 0.6872870008978579
Epoch: 84 | Iteration number: [1450/4518] 32% | Training loss: 0.6872761653620622
Epoch: 84 | Iteration number: [1460/4518] 32% | Training loss: 0.6872783189358777
Epoch: 84 | Iteration number: [1470/4518] 32% | Training loss: 0.6872796791345894
Epoch: 84 | Iteration number: [1480/4518] 32% | Training loss: 0.6872699075856724
Epoch: 84 | Iteration number: [1490/4518] 32% | Training loss: 0.6872697187350101
Epoch: 84 | Iteration number: [1500/4518] 33% | Training loss: 0.6872717138528824
Epoch: 84 | Iteration number: [1510/4518] 33% | Training loss: 0.6872657721405787
Epoch: 84 | Iteration number: [1520/4518] 33% | Training loss: 0.687258392572403
Epoch: 84 | Iteration number: [1530/4518] 33% | Training loss: 0.6872646921210819
Epoch: 84 | Iteration number: [1540/4518] 34% | Training loss: 0.6872551111818908
Epoch: 84 | Iteration number: [1550/4518] 34% | Training loss: 0.6872572793499115
Epoch: 84 | Iteration number: [1560/4518] 34% | Training loss: 0.6872529067672216
Epoch: 84 | Iteration number: [1570/4518] 34% | Training loss: 0.6872522469538792
Epoch: 84 | Iteration number: [1580/4518] 34% | Training loss: 0.6872457574439954
Epoch: 84 | Iteration number: [1590/4518] 35% | Training loss: 0.6872396799003553
Epoch: 84 | Iteration number: [1600/4518] 35% | Training loss: 0.687234017290175
Epoch: 84 | Iteration number: [1610/4518] 35% | Training loss: 0.6872318479955567
Epoch: 84 | Iteration number: [1620/4518] 35% | Training loss: 0.6872294371878659
Epoch: 84 | Iteration number: [1630/4518] 36% | Training loss: 0.6872391207452201
Epoch: 84 | Iteration number: [1640/4518] 36% | Training loss: 0.6872348353266716
Epoch: 84 | Iteration number: [1650/4518] 36% | Training loss: 0.6872328951142052
Epoch: 84 | Iteration number: [1660/4518] 36% | Training loss: 0.6872353463287814
Epoch: 84 | Iteration number: [1670/4518] 36% | Training loss: 0.6872288758883219
Epoch: 84 | Iteration number: [1680/4518] 37% | Training loss: 0.6872210082908471
Epoch: 84 | Iteration number: [1690/4518] 37% | Training loss: 0.6872165067661443
Epoch: 84 | Iteration number: [1700/4518] 37% | Training loss: 0.6872136515028336
Epoch: 84 | Iteration number: [1710/4518] 37% | Training loss: 0.6872057691652175
Epoch: 84 | Iteration number: [1720/4518] 38% | Training loss: 0.6872016451733057
Epoch: 84 | Iteration number: [1730/4518] 38% | Training loss: 0.6872000269807143
Epoch: 84 | Iteration number: [1740/4518] 38% | Training loss: 0.6871993884272959
Epoch: 84 | Iteration number: [1750/4518] 38% | Training loss: 0.6872019911152976
Epoch: 84 | Iteration number: [1760/4518] 38% | Training loss: 0.6872014101594687
Epoch: 84 | Iteration number: [1770/4518] 39% | Training loss: 0.6871923689451594
Epoch: 84 | Iteration number: [1780/4518] 39% | Training loss: 0.6871958684385493
Epoch: 84 | Iteration number: [1790/4518] 39% | Training loss: 0.6871852608699373
Epoch: 84 | Iteration number: [1800/4518] 39% | Training loss: 0.6871795791718694
Epoch: 84 | Iteration number: [1810/4518] 40% | Training loss: 0.6871756941903362
Epoch: 84 | Iteration number: [1820/4518] 40% | Training loss: 0.6871706873833479
Epoch: 84 | Iteration number: [1830/4518] 40% | Training loss: 0.6871758441456028
Epoch: 84 | Iteration number: [1840/4518] 40% | Training loss: 0.6871774917387444
Epoch: 84 | Iteration number: [1850/4518] 40% | Training loss: 0.687174811975376
Epoch: 84 | Iteration number: [1860/4518] 41% | Training loss: 0.6871703890703058
Epoch: 84 | Iteration number: [1870/4518] 41% | Training loss: 0.6871637775617487
Epoch: 84 | Iteration number: [1880/4518] 41% | Training loss: 0.6871631851855745
Epoch: 84 | Iteration number: [1890/4518] 41% | Training loss: 0.6871648998172195
Epoch: 84 | Iteration number: [1900/4518] 42% | Training loss: 0.6871696613336864
Epoch: 84 | Iteration number: [1910/4518] 42% | Training loss: 0.6871633629524271
Epoch: 84 | Iteration number: [1920/4518] 42% | Training loss: 0.6871576405751209
Epoch: 84 | Iteration number: [1930/4518] 42% | Training loss: 0.6871587952492768
Epoch: 84 | Iteration number: [1940/4518] 42% | Training loss: 0.6871555216840862
Epoch: 84 | Iteration number: [1950/4518] 43% | Training loss: 0.6871565417754344
Epoch: 84 | Iteration number: [1960/4518] 43% | Training loss: 0.6871540785139921
Epoch: 84 | Iteration number: [1970/4518] 43% | Training loss: 0.687153039819698
Epoch: 84 | Iteration number: [1980/4518] 43% | Training loss: 0.6871550887221037
Epoch: 84 | Iteration number: [1990/4518] 44% | Training loss: 0.6871440784715528
Epoch: 84 | Iteration number: [2000/4518] 44% | Training loss: 0.6871415458917618
Epoch: 84 | Iteration number: [2010/4518] 44% | Training loss: 0.6871405201764842
Epoch: 84 | Iteration number: [2020/4518] 44% | Training loss: 0.6871420027595936
Epoch: 84 | Iteration number: [2030/4518] 44% | Training loss: 0.6871433564888433
Epoch: 84 | Iteration number: [2040/4518] 45% | Training loss: 0.6871479861292185
Epoch: 84 | Iteration number: [2050/4518] 45% | Training loss: 0.6871439173744947
Epoch: 84 | Iteration number: [2060/4518] 45% | Training loss: 0.6871441558726783
Epoch: 84 | Iteration number: [2070/4518] 45% | Training loss: 0.6871375457388191
Epoch: 84 | Iteration number: [2080/4518] 46% | Training loss: 0.687132878200366
Epoch: 84 | Iteration number: [2090/4518] 46% | Training loss: 0.6871343526258423
Epoch: 84 | Iteration number: [2100/4518] 46% | Training loss: 0.6871337603955042
Epoch: 84 | Iteration number: [2110/4518] 46% | Training loss: 0.6871327363766765
Epoch: 84 | Iteration number: [2120/4518] 46% | Training loss: 0.6871241457057449
Epoch: 84 | Iteration number: [2130/4518] 47% | Training loss: 0.6871180620831503
Epoch: 84 | Iteration number: [2140/4518] 47% | Training loss: 0.687111364987409
Epoch: 84 | Iteration number: [2150/4518] 47% | Training loss: 0.6871127843302349
Epoch: 84 | Iteration number: [2160/4518] 47% | Training loss: 0.6871136118140485
Epoch: 84 | Iteration number: [2170/4518] 48% | Training loss: 0.6871107778516233
Epoch: 84 | Iteration number: [2180/4518] 48% | Training loss: 0.6871110512849388
Epoch: 84 | Iteration number: [2190/4518] 48% | Training loss: 0.6871071877272706
Epoch: 84 | Iteration number: [2200/4518] 48% | Training loss: 0.687106314545328
Epoch: 84 | Iteration number: [2210/4518] 48% | Training loss: 0.6871072676117064
Epoch: 84 | Iteration number: [2220/4518] 49% | Training loss: 0.6871045430501302
Epoch: 84 | Iteration number: [2230/4518] 49% | Training loss: 0.6871086758348439
Epoch: 84 | Iteration number: [2240/4518] 49% | Training loss: 0.6871061565088374
Epoch: 84 | Iteration number: [2250/4518] 49% | Training loss: 0.6871004701455434
Epoch: 84 | Iteration number: [2260/4518] 50% | Training loss: 0.6871011228424257
Epoch: 84 | Iteration number: [2270/4518] 50% | Training loss: 0.6871008718328854
Epoch: 84 | Iteration number: [2280/4518] 50% | Training loss: 0.6871021425253466
Epoch: 84 | Iteration number: [2290/4518] 50% | Training loss: 0.6871008564030759
Epoch: 84 | Iteration number: [2300/4518] 50% | Training loss: 0.6870982526955397
Epoch: 84 | Iteration number: [2310/4518] 51% | Training loss: 0.6871005654076994
Epoch: 84 | Iteration number: [2320/4518] 51% | Training loss: 0.6871024369679648
Epoch: 84 | Iteration number: [2330/4518] 51% | Training loss: 0.6871001095475046
Epoch: 84 | Iteration number: [2340/4518] 51% | Training loss: 0.6871002404608278
Epoch: 84 | Iteration number: [2350/4518] 52% | Training loss: 0.6870953014556398
Epoch: 84 | Iteration number: [2360/4518] 52% | Training loss: 0.6870909233972178
Epoch: 84 | Iteration number: [2370/4518] 52% | Training loss: 0.6870882504851507
Epoch: 84 | Iteration number: [2380/4518] 52% | Training loss: 0.687085949748504
Epoch: 84 | Iteration number: [2390/4518] 52% | Training loss: 0.687082132983906
Epoch: 84 | Iteration number: [2400/4518] 53% | Training loss: 0.6870782605310282
Epoch: 84 | Iteration number: [2410/4518] 53% | Training loss: 0.6870760317659972
Epoch: 84 | Iteration number: [2420/4518] 53% | Training loss: 0.6870657165927335
Epoch: 84 | Iteration number: [2430/4518] 53% | Training loss: 0.6870684742191692
Epoch: 84 | Iteration number: [2440/4518] 54% | Training loss: 0.6870690927886572
Epoch: 84 | Iteration number: [2450/4518] 54% | Training loss: 0.6870653768948146
Epoch: 84 | Iteration number: [2460/4518] 54% | Training loss: 0.6870588286620815
Epoch: 84 | Iteration number: [2470/4518] 54% | Training loss: 0.6870578253076144
Epoch: 84 | Iteration number: [2480/4518] 54% | Training loss: 0.6870556124756413
Epoch: 84 | Iteration number: [2490/4518] 55% | Training loss: 0.6870578416380059
Epoch: 84 | Iteration number: [2500/4518] 55% | Training loss: 0.6870572730779648
Epoch: 84 | Iteration number: [2510/4518] 55% | Training loss: 0.687058267887845
Epoch: 84 | Iteration number: [2520/4518] 55% | Training loss: 0.6870562024769329
Epoch: 84 | Iteration number: [2530/4518] 55% | Training loss: 0.6870558598060382
Epoch: 84 | Iteration number: [2540/4518] 56% | Training loss: 0.6870532837205046
Epoch: 84 | Iteration number: [2550/4518] 56% | Training loss: 0.6870535958514494
Epoch: 84 | Iteration number: [2560/4518] 56% | Training loss: 0.6870560976210982
Epoch: 84 | Iteration number: [2570/4518] 56% | Training loss: 0.6870530026200217
Epoch: 84 | Iteration number: [2580/4518] 57% | Training loss: 0.6870477824248085
Epoch: 84 | Iteration number: [2590/4518] 57% | Training loss: 0.6870471354386981
Epoch: 84 | Iteration number: [2600/4518] 57% | Training loss: 0.6870474821329117
Epoch: 84 | Iteration number: [2610/4518] 57% | Training loss: 0.6870482538851742
Epoch: 84 | Iteration number: [2620/4518] 57% | Training loss: 0.6870516125709956
Epoch: 84 | Iteration number: [2630/4518] 58% | Training loss: 0.6870517914059497
Epoch: 84 | Iteration number: [2640/4518] 58% | Training loss: 0.6870514234132838
Epoch: 84 | Iteration number: [2650/4518] 58% | Training loss: 0.687051758743682
Epoch: 84 | Iteration number: [2660/4518] 58% | Training loss: 0.6870462760441285
Epoch: 84 | Iteration number: [2670/4518] 59% | Training loss: 0.6870460414038169
Epoch: 84 | Iteration number: [2680/4518] 59% | Training loss: 0.6870463834324879
Epoch: 84 | Iteration number: [2690/4518] 59% | Training loss: 0.6870476266930094
Epoch: 84 | Iteration number: [2700/4518] 59% | Training loss: 0.6870473677140695
Epoch: 84 | Iteration number: [2710/4518] 59% | Training loss: 0.6870516028571393
Epoch: 84 | Iteration number: [2720/4518] 60% | Training loss: 0.6870464332401752
Epoch: 84 | Iteration number: [2730/4518] 60% | Training loss: 0.6870465305043664
Epoch: 84 | Iteration number: [2740/4518] 60% | Training loss: 0.6870407217392956
Epoch: 84 | Iteration number: [2750/4518] 60% | Training loss: 0.6870380315347151
Epoch: 84 | Iteration number: [2760/4518] 61% | Training loss: 0.687037382480027
Epoch: 84 | Iteration number: [2770/4518] 61% | Training loss: 0.6870314467254528
Epoch: 84 | Iteration number: [2780/4518] 61% | Training loss: 0.687031048429098
Epoch: 84 | Iteration number: [2790/4518] 61% | Training loss: 0.6870355661411012
Epoch: 84 | Iteration number: [2800/4518] 61% | Training loss: 0.6870384352334908
Epoch: 84 | Iteration number: [2810/4518] 62% | Training loss: 0.6870368201113256
Epoch: 84 | Iteration number: [2820/4518] 62% | Training loss: 0.6870364477237065
Epoch: 84 | Iteration number: [2830/4518] 62% | Training loss: 0.6870380845592216
Epoch: 84 | Iteration number: [2840/4518] 62% | Training loss: 0.6870370941052975
Epoch: 84 | Iteration number: [2850/4518] 63% | Training loss: 0.6870360736679613
Epoch: 84 | Iteration number: [2860/4518] 63% | Training loss: 0.6870348153414426
Epoch: 84 | Iteration number: [2870/4518] 63% | Training loss: 0.6870362969225707
Epoch: 84 | Iteration number: [2880/4518] 63% | Training loss: 0.6870329097534219
Epoch: 84 | Iteration number: [2890/4518] 63% | Training loss: 0.6870337648581468
Epoch: 84 | Iteration number: [2900/4518] 64% | Training loss: 0.6870389713090042
Epoch: 84 | Iteration number: [2910/4518] 64% | Training loss: 0.6870352647558521
Epoch: 84 | Iteration number: [2920/4518] 64% | Training loss: 0.6870345957883417
Epoch: 84 | Iteration number: [2930/4518] 64% | Training loss: 0.6870309298966119
Epoch: 84 | Iteration number: [2940/4518] 65% | Training loss: 0.6870305673402994
Epoch: 84 | Iteration number: [2950/4518] 65% | Training loss: 0.687032704090668
Epoch: 84 | Iteration number: [2960/4518] 65% | Training loss: 0.6870324904048765
Epoch: 84 | Iteration number: [2970/4518] 65% | Training loss: 0.687027886459723
Epoch: 84 | Iteration number: [2980/4518] 65% | Training loss: 0.6870236036761496
Epoch: 84 | Iteration number: [2990/4518] 66% | Training loss: 0.6870259282780331
Epoch: 84 | Iteration number: [3000/4518] 66% | Training loss: 0.6870300239920616
Epoch: 84 | Iteration number: [3010/4518] 66% | Training loss: 0.687028430743867
Epoch: 84 | Iteration number: [3020/4518] 66% | Training loss: 0.6870286187391408
Epoch: 84 | Iteration number: [3030/4518] 67% | Training loss: 0.6870230107220879
Epoch: 84 | Iteration number: [3040/4518] 67% | Training loss: 0.6870215695939565
Epoch: 84 | Iteration number: [3050/4518] 67% | Training loss: 0.6870159677794723
Epoch: 84 | Iteration number: [3060/4518] 67% | Training loss: 0.6870147045531304
Epoch: 84 | Iteration number: [3070/4518] 67% | Training loss: 0.6870174600169402
Epoch: 84 | Iteration number: [3080/4518] 68% | Training loss: 0.6870148398272403
Epoch: 84 | Iteration number: [3090/4518] 68% | Training loss: 0.687013119266257
Epoch: 84 | Iteration number: [3100/4518] 68% | Training loss: 0.6870130605274631
Epoch: 84 | Iteration number: [3110/4518] 68% | Training loss: 0.6870154746092401
Epoch: 84 | Iteration number: [3120/4518] 69% | Training loss: 0.6870164721249006
Epoch: 84 | Iteration number: [3130/4518] 69% | Training loss: 0.6870205149863855
Epoch: 84 | Iteration number: [3140/4518] 69% | Training loss: 0.687018739892419
Epoch: 84 | Iteration number: [3150/4518] 69% | Training loss: 0.6870171892075312
Epoch: 84 | Iteration number: [3160/4518] 69% | Training loss: 0.6870184874421433
Epoch: 84 | Iteration number: [3170/4518] 70% | Training loss: 0.687019688473891
Epoch: 84 | Iteration number: [3180/4518] 70% | Training loss: 0.6870198210642773
Epoch: 84 | Iteration number: [3190/4518] 70% | Training loss: 0.6870195993622269
Epoch: 84 | Iteration number: [3200/4518] 70% | Training loss: 0.6870208048634231
Epoch: 84 | Iteration number: [3210/4518] 71% | Training loss: 0.6870172726031033
Epoch: 84 | Iteration number: [3220/4518] 71% | Training loss: 0.6870171452346056
Epoch: 84 | Iteration number: [3230/4518] 71% | Training loss: 0.6870139615823609
Epoch: 84 | Iteration number: [3240/4518] 71% | Training loss: 0.6870159635573257
Epoch: 84 | Iteration number: [3250/4518] 71% | Training loss: 0.6870164104608389
Epoch: 84 | Iteration number: [3260/4518] 72% | Training loss: 0.6870140682334549
Epoch: 84 | Iteration number: [3270/4518] 72% | Training loss: 0.687015688291748
Epoch: 84 | Iteration number: [3280/4518] 72% | Training loss: 0.6870131743208664
Epoch: 84 | Iteration number: [3290/4518] 72% | Training loss: 0.6870092263518858
Epoch: 84 | Iteration number: [3300/4518] 73% | Training loss: 0.6870086837898601
Epoch: 84 | Iteration number: [3310/4518] 73% | Training loss: 0.6870084795526867
Epoch: 84 | Iteration number: [3320/4518] 73% | Training loss: 0.6870054851095361
Epoch: 84 | Iteration number: [3330/4518] 73% | Training loss: 0.6870038602445219
Epoch: 84 | Iteration number: [3340/4518] 73% | Training loss: 0.687005390646215
Epoch: 84 | Iteration number: [3350/4518] 74% | Training loss: 0.6870072590593082
Epoch: 84 | Iteration number: [3360/4518] 74% | Training loss: 0.6870068768128044
Epoch: 84 | Iteration number: [3370/4518] 74% | Training loss: 0.6870038721610955
Epoch: 84 | Iteration number: [3380/4518] 74% | Training loss: 0.687003495072472
Epoch: 84 | Iteration number: [3390/4518] 75% | Training loss: 0.6870018957462986
Epoch: 84 | Iteration number: [3400/4518] 75% | Training loss: 0.6870019280384568
Epoch: 84 | Iteration number: [3410/4518] 75% | Training loss: 0.6870009866103399
Epoch: 84 | Iteration number: [3420/4518] 75% | Training loss: 0.6870004665956163
Epoch: 84 | Iteration number: [3430/4518] 75% | Training loss: 0.6869982532961375
Epoch: 84 | Iteration number: [3440/4518] 76% | Training loss: 0.6869992533395457
Epoch: 84 | Iteration number: [3450/4518] 76% | Training loss: 0.6869999301260796
Epoch: 84 | Iteration number: [3460/4518] 76% | Training loss: 0.686995215429736
Epoch: 84 | Iteration number: [3470/4518] 76% | Training loss: 0.6869900948032522
Epoch: 84 | Iteration number: [3480/4518] 77% | Training loss: 0.6869862296971782
Epoch: 84 | Iteration number: [3490/4518] 77% | Training loss: 0.6869873268214884
Epoch: 84 | Iteration number: [3500/4518] 77% | Training loss: 0.6869824904544013
Epoch: 84 | Iteration number: [3510/4518] 77% | Training loss: 0.6869809722628688
Epoch: 84 | Iteration number: [3520/4518] 77% | Training loss: 0.6869822957129641
Epoch: 84 | Iteration number: [3530/4518] 78% | Training loss: 0.686980558505477
Epoch: 84 | Iteration number: [3540/4518] 78% | Training loss: 0.6869825700918833
Epoch: 84 | Iteration number: [3550/4518] 78% | Training loss: 0.6869824277850943
Epoch: 84 | Iteration number: [3560/4518] 78% | Training loss: 0.6869830235169175
Epoch: 84 | Iteration number: [3570/4518] 79% | Training loss: 0.6869805183397287
Epoch: 84 | Iteration number: [3580/4518] 79% | Training loss: 0.6869797090411852
Epoch: 84 | Iteration number: [3590/4518] 79% | Training loss: 0.686979025951003
Epoch: 84 | Iteration number: [3600/4518] 79% | Training loss: 0.6869769440425767
Epoch: 84 | Iteration number: [3610/4518] 79% | Training loss: 0.68697981302758
Epoch: 84 | Iteration number: [3620/4518] 80% | Training loss: 0.6869815623562638
Epoch: 84 | Iteration number: [3630/4518] 80% | Training loss: 0.6869776100823374
Epoch: 84 | Iteration number: [3640/4518] 80% | Training loss: 0.6869759757767667
Epoch: 84 | Iteration number: [3650/4518] 80% | Training loss: 0.6869767864109718
Epoch: 84 | Iteration number: [3660/4518] 81% | Training loss: 0.6869790209772808
Epoch: 84 | Iteration number: [3670/4518] 81% | Training loss: 0.6869767872124342
Epoch: 84 | Iteration number: [3680/4518] 81% | Training loss: 0.6869770903788183
Epoch: 84 | Iteration number: [3690/4518] 81% | Training loss: 0.6869785782282914
Epoch: 84 | Iteration number: [3700/4518] 81% | Training loss: 0.6869742317457457
Epoch: 84 | Iteration number: [3710/4518] 82% | Training loss: 0.6869751046128029
Epoch: 84 | Iteration number: [3720/4518] 82% | Training loss: 0.6869700306365567
Epoch: 84 | Iteration number: [3730/4518] 82% | Training loss: 0.6869720837705576
Epoch: 84 | Iteration number: [3740/4518] 82% | Training loss: 0.6869731534132983
Epoch: 84 | Iteration number: [3750/4518] 83% | Training loss: 0.6869719939867656
Epoch: 84 | Iteration number: [3760/4518] 83% | Training loss: 0.6869723547963386
Epoch: 84 | Iteration number: [3770/4518] 83% | Training loss: 0.6869693934126937
Epoch: 84 | Iteration number: [3780/4518] 83% | Training loss: 0.6869697540683091
Epoch: 84 | Iteration number: [3790/4518] 83% | Training loss: 0.6869710726127776
Epoch: 84 | Iteration number: [3800/4518] 84% | Training loss: 0.686966485945802
Epoch: 84 | Iteration number: [3810/4518] 84% | Training loss: 0.6869601415054691
Epoch: 84 | Iteration number: [3820/4518] 84% | Training loss: 0.6869611241898611
Epoch: 84 | Iteration number: [3830/4518] 84% | Training loss: 0.686962393385312
Epoch: 84 | Iteration number: [3840/4518] 84% | Training loss: 0.6869639591779559
Epoch: 84 | Iteration number: [3850/4518] 85% | Training loss: 0.6869600189041781
Epoch: 84 | Iteration number: [3860/4518] 85% | Training loss: 0.6869588492911096
Epoch: 84 | Iteration number: [3870/4518] 85% | Training loss: 0.6869599369915265
Epoch: 84 | Iteration number: [3880/4518] 85% | Training loss: 0.6869616691599187
Epoch: 84 | Iteration number: [3890/4518] 86% | Training loss: 0.686959220311942
Epoch: 84 | Iteration number: [3900/4518] 86% | Training loss: 0.6869571364995761
Epoch: 84 | Iteration number: [3910/4518] 86% | Training loss: 0.6869554699534346
Epoch: 84 | Iteration number: [3920/4518] 86% | Training loss: 0.6869556580118987
Epoch: 84 | Iteration number: [3930/4518] 86% | Training loss: 0.6869542650290724
Epoch: 84 | Iteration number: [3940/4518] 87% | Training loss: 0.6869586155196737
Epoch: 84 | Iteration number: [3950/4518] 87% | Training loss: 0.6869562831860554
Epoch: 84 | Iteration number: [3960/4518] 87% | Training loss: 0.686958118370085
Epoch: 84 | Iteration number: [3970/4518] 87% | Training loss: 0.6869522602492075
Epoch: 84 | Iteration number: [3980/4518] 88% | Training loss: 0.6869503163512628
Epoch: 84 | Iteration number: [3990/4518] 88% | Training loss: 0.6869509541301202
Epoch: 84 | Iteration number: [4000/4518] 88% | Training loss: 0.686950484842062
Epoch: 84 | Iteration number: [4010/4518] 88% | Training loss: 0.6869504939885508
Epoch: 84 | Iteration number: [4020/4518] 88% | Training loss: 0.6869478732792299
Epoch: 84 | Iteration number: [4030/4518] 89% | Training loss: 0.6869466203761752
Epoch: 84 | Iteration number: [4040/4518] 89% | Training loss: 0.6869484769235743
Epoch: 84 | Iteration number: [4050/4518] 89% | Training loss: 0.6869485488350009
Epoch: 84 | Iteration number: [4060/4518] 89% | Training loss: 0.686945064182352
Epoch: 84 | Iteration number: [4070/4518] 90% | Training loss: 0.6869445404930256
Epoch: 84 | Iteration number: [4080/4518] 90% | Training loss: 0.686944389167954
Epoch: 84 | Iteration number: [4090/4518] 90% | Training loss: 0.68694208791903
Epoch: 84 | Iteration number: [4100/4518] 90% | Training loss: 0.6869397613042738
Epoch: 84 | Iteration number: [4110/4518] 90% | Training loss: 0.6869390398336443
Epoch: 84 | Iteration number: [4120/4518] 91% | Training loss: 0.6869358274977184
Epoch: 84 | Iteration number: [4130/4518] 91% | Training loss: 0.6869356258440826
Epoch: 84 | Iteration number: [4140/4518] 91% | Training loss: 0.6869354081614581
Epoch: 84 | Iteration number: [4150/4518] 91% | Training loss: 0.6869342175305608
Epoch: 84 | Iteration number: [4160/4518] 92% | Training loss: 0.6869329991392218
Epoch: 84 | Iteration number: [4170/4518] 92% | Training loss: 0.6869355816206486
Epoch: 84 | Iteration number: [4180/4518] 92% | Training loss: 0.6869394704343029
Epoch: 84 | Iteration number: [4190/4518] 92% | Training loss: 0.6869421271549488
Epoch: 84 | Iteration number: [4200/4518] 92% | Training loss: 0.6869451406881922
Epoch: 84 | Iteration number: [4210/4518] 93% | Training loss: 0.6869449801512965
Epoch: 84 | Iteration number: [4220/4518] 93% | Training loss: 0.6869467888539437
Epoch: 84 | Iteration number: [4230/4518] 93% | Training loss: 0.6869478535426706
Epoch: 84 | Iteration number: [4240/4518] 93% | Training loss: 0.6869469788698656
Epoch: 84 | Iteration number: [4250/4518] 94% | Training loss: 0.6869458384513855
Epoch: 84 | Iteration number: [4260/4518] 94% | Training loss: 0.6869427022939557
Epoch: 84 | Iteration number: [4270/4518] 94% | Training loss: 0.6869438631891925
Epoch: 84 | Iteration number: [4280/4518] 94% | Training loss: 0.6869428134967234
Epoch: 84 | Iteration number: [4290/4518] 94% | Training loss: 0.6869461103752776
Epoch: 84 | Iteration number: [4300/4518] 95% | Training loss: 0.6869425745897515
Epoch: 84 | Iteration number: [4310/4518] 95% | Training loss: 0.6869410743569553
Epoch: 84 | Iteration number: [4320/4518] 95% | Training loss: 0.6869413132606833
Epoch: 84 | Iteration number: [4330/4518] 95% | Training loss: 0.6869395503959259
Epoch: 84 | Iteration number: [4340/4518] 96% | Training loss: 0.6869362843750809
Epoch: 84 | Iteration number: [4350/4518] 96% | Training loss: 0.6869345094280681
Epoch: 84 | Iteration number: [4360/4518] 96% | Training loss: 0.686934750069172
Epoch: 84 | Iteration number: [4370/4518] 96% | Training loss: 0.6869354556572519
Epoch: 84 | Iteration number: [4380/4518] 96% | Training loss: 0.6869341241170283
Epoch: 84 | Iteration number: [4390/4518] 97% | Training loss: 0.6869311922910817
Epoch: 84 | Iteration number: [4400/4518] 97% | Training loss: 0.6869278284500946
Epoch: 84 | Iteration number: [4410/4518] 97% | Training loss: 0.686928129588125
Epoch: 84 | Iteration number: [4420/4518] 97% | Training loss: 0.6869272699992581
Epoch: 84 | Iteration number: [4430/4518] 98% | Training loss: 0.6869245381710491
Epoch: 84 | Iteration number: [4440/4518] 98% | Training loss: 0.6869250429911656
Epoch: 84 | Iteration number: [4450/4518] 98% | Training loss: 0.6869253088785021
Epoch: 84 | Iteration number: [4460/4518] 98% | Training loss: 0.6869217193313778
Epoch: 84 | Iteration number: [4470/4518] 98% | Training loss: 0.6869203322819148
Epoch: 84 | Iteration number: [4480/4518] 99% | Training loss: 0.6869202308356762
Epoch: 84 | Iteration number: [4490/4518] 99% | Training loss: 0.6869190436163565
Epoch: 84 | Iteration number: [4500/4518] 99% | Training loss: 0.6869194289048512
Epoch: 84 | Iteration number: [4510/4518] 99% | Training loss: 0.686921922647768

 End of epoch: 84 | Train Loss: 0.6867688964325118 | Training Time: 641 

 End of epoch: 84 | Eval Loss: 0.6899515876964647 | Evaluating Time: 17 
Epoch: 85 | Iteration number: [10/4518] 0% | Training loss: 0.7564168155193329
Epoch: 85 | Iteration number: [20/4518] 0% | Training loss: 0.7215575337409973
Epoch: 85 | Iteration number: [30/4518] 0% | Training loss: 0.7102260331312815
Epoch: 85 | Iteration number: [40/4518] 0% | Training loss: 0.7046415373682976
Epoch: 85 | Iteration number: [50/4518] 1% | Training loss: 0.7014542269706726
Epoch: 85 | Iteration number: [60/4518] 1% | Training loss: 0.6989032755295436
Epoch: 85 | Iteration number: [70/4518] 1% | Training loss: 0.6972603576523917
Epoch: 85 | Iteration number: [80/4518] 1% | Training loss: 0.6960354417562484
Epoch: 85 | Iteration number: [90/4518] 1% | Training loss: 0.6951068825191922
Epoch: 85 | Iteration number: [100/4518] 2% | Training loss: 0.6943397200107575
Epoch: 85 | Iteration number: [110/4518] 2% | Training loss: 0.6936564700169997
Epoch: 85 | Iteration number: [120/4518] 2% | Training loss: 0.6930653711160024
Epoch: 85 | Iteration number: [130/4518] 2% | Training loss: 0.6926571016128247
Epoch: 85 | Iteration number: [140/4518] 3% | Training loss: 0.692291944367545
Epoch: 85 | Iteration number: [150/4518] 3% | Training loss: 0.691923615137736
Epoch: 85 | Iteration number: [160/4518] 3% | Training loss: 0.6915777157992125
Epoch: 85 | Iteration number: [170/4518] 3% | Training loss: 0.6912875838139478
Epoch: 85 | Iteration number: [180/4518] 3% | Training loss: 0.6910243226422204
Epoch: 85 | Iteration number: [190/4518] 4% | Training loss: 0.6907852997905329
Epoch: 85 | Iteration number: [200/4518] 4% | Training loss: 0.6905919641256333
Epoch: 85 | Iteration number: [210/4518] 4% | Training loss: 0.6903564609232403
Epoch: 85 | Iteration number: [220/4518] 4% | Training loss: 0.6901721740310842
Epoch: 85 | Iteration number: [230/4518] 5% | Training loss: 0.689998791269634
Epoch: 85 | Iteration number: [240/4518] 5% | Training loss: 0.6899288860460122
Epoch: 85 | Iteration number: [250/4518] 5% | Training loss: 0.6898593521118164
Epoch: 85 | Iteration number: [260/4518] 5% | Training loss: 0.6897619515657425
Epoch: 85 | Iteration number: [270/4518] 5% | Training loss: 0.6896230693216677
Epoch: 85 | Iteration number: [280/4518] 6% | Training loss: 0.6894907025354249
Epoch: 85 | Iteration number: [290/4518] 6% | Training loss: 0.689390277245949
Epoch: 85 | Iteration number: [300/4518] 6% | Training loss: 0.6892817395925522
Epoch: 85 | Iteration number: [310/4518] 6% | Training loss: 0.689217447657739
Epoch: 85 | Iteration number: [320/4518] 7% | Training loss: 0.6891510665416718
Epoch: 85 | Iteration number: [330/4518] 7% | Training loss: 0.6890733590631773
Epoch: 85 | Iteration number: [340/4518] 7% | Training loss: 0.6890110305126975
Epoch: 85 | Iteration number: [350/4518] 7% | Training loss: 0.6889436929566519
Epoch: 85 | Iteration number: [360/4518] 7% | Training loss: 0.6888752655850516
Epoch: 85 | Iteration number: [370/4518] 8% | Training loss: 0.6888443595654256
Epoch: 85 | Iteration number: [380/4518] 8% | Training loss: 0.6887472875808415
Epoch: 85 | Iteration number: [390/4518] 8% | Training loss: 0.6886606801778842
Epoch: 85 | Iteration number: [400/4518] 8% | Training loss: 0.6886153392493725
Epoch: 85 | Iteration number: [410/4518] 9% | Training loss: 0.6885745914970957
Epoch: 85 | Iteration number: [420/4518] 9% | Training loss: 0.6885081215983345
Epoch: 85 | Iteration number: [430/4518] 9% | Training loss: 0.6884603984134142
Epoch: 85 | Iteration number: [440/4518] 9% | Training loss: 0.6883854596452279
Epoch: 85 | Iteration number: [450/4518] 9% | Training loss: 0.6883500487274594
Epoch: 85 | Iteration number: [460/4518] 10% | Training loss: 0.6883267756389535
Epoch: 85 | Iteration number: [470/4518] 10% | Training loss: 0.6882976452086834
Epoch: 85 | Iteration number: [480/4518] 10% | Training loss: 0.6882770960529645
Epoch: 85 | Iteration number: [490/4518] 10% | Training loss: 0.688239298304733
Epoch: 85 | Iteration number: [500/4518] 11% | Training loss: 0.688211622595787
Epoch: 85 | Iteration number: [510/4518] 11% | Training loss: 0.688178385589637
Epoch: 85 | Iteration number: [520/4518] 11% | Training loss: 0.6881741838959547
Epoch: 85 | Iteration number: [530/4518] 11% | Training loss: 0.6881449720769558
Epoch: 85 | Iteration number: [540/4518] 11% | Training loss: 0.688115660570286
Epoch: 85 | Iteration number: [550/4518] 12% | Training loss: 0.6881111414866014
Epoch: 85 | Iteration number: [560/4518] 12% | Training loss: 0.6880918399563858
Epoch: 85 | Iteration number: [570/4518] 12% | Training loss: 0.6880411304925618
Epoch: 85 | Iteration number: [580/4518] 12% | Training loss: 0.6880152882173144
Epoch: 85 | Iteration number: [590/4518] 13% | Training loss: 0.6880067121174376
Epoch: 85 | Iteration number: [600/4518] 13% | Training loss: 0.688003311753273
Epoch: 85 | Iteration number: [610/4518] 13% | Training loss: 0.6879832053770785
Epoch: 85 | Iteration number: [620/4518] 13% | Training loss: 0.6879580581380474
Epoch: 85 | Iteration number: [630/4518] 13% | Training loss: 0.6879502854649983
Epoch: 85 | Iteration number: [640/4518] 14% | Training loss: 0.6879278853535652
Epoch: 85 | Iteration number: [650/4518] 14% | Training loss: 0.6878901673280275
Epoch: 85 | Iteration number: [660/4518] 14% | Training loss: 0.6878842021479751
Epoch: 85 | Iteration number: [670/4518] 14% | Training loss: 0.6878703041752773
Epoch: 85 | Iteration number: [680/4518] 15% | Training loss: 0.6878466340548852
Epoch: 85 | Iteration number: [690/4518] 15% | Training loss: 0.6878512163093125
Epoch: 85 | Iteration number: [700/4518] 15% | Training loss: 0.687841544832502
Epoch: 85 | Iteration number: [710/4518] 15% | Training loss: 0.6878269357580534
Epoch: 85 | Iteration number: [720/4518] 15% | Training loss: 0.6878136475053098
Epoch: 85 | Iteration number: [730/4518] 16% | Training loss: 0.6877893093514116
Epoch: 85 | Iteration number: [740/4518] 16% | Training loss: 0.6877757117554948
Epoch: 85 | Iteration number: [750/4518] 16% | Training loss: 0.6877466938495636
Epoch: 85 | Iteration number: [760/4518] 16% | Training loss: 0.6877290266124826
Epoch: 85 | Iteration number: [770/4518] 17% | Training loss: 0.6877256036578835
Epoch: 85 | Iteration number: [780/4518] 17% | Training loss: 0.687709459127524
Epoch: 85 | Iteration number: [790/4518] 17% | Training loss: 0.6876855780806722
Epoch: 85 | Iteration number: [800/4518] 17% | Training loss: 0.6876750788092614
Epoch: 85 | Iteration number: [810/4518] 17% | Training loss: 0.6876645734280715
Epoch: 85 | Iteration number: [820/4518] 18% | Training loss: 0.6876626971291333
Epoch: 85 | Iteration number: [830/4518] 18% | Training loss: 0.6876474176544741
Epoch: 85 | Iteration number: [840/4518] 18% | Training loss: 0.6876421130838848
Epoch: 85 | Iteration number: [850/4518] 18% | Training loss: 0.6876224549377665
Epoch: 85 | Iteration number: [860/4518] 19% | Training loss: 0.6876021168952764
Epoch: 85 | Iteration number: [870/4518] 19% | Training loss: 0.6875913691246647
Epoch: 85 | Iteration number: [880/4518] 19% | Training loss: 0.6875756936994466
Epoch: 85 | Iteration number: [890/4518] 19% | Training loss: 0.6875699844922912
Epoch: 85 | Iteration number: [900/4518] 19% | Training loss: 0.6875658804178237
Epoch: 85 | Iteration number: [910/4518] 20% | Training loss: 0.6875724440092569
Epoch: 85 | Iteration number: [920/4518] 20% | Training loss: 0.6875515881439914
Epoch: 85 | Iteration number: [930/4518] 20% | Training loss: 0.6875365386727036
Epoch: 85 | Iteration number: [940/4518] 20% | Training loss: 0.6875377991098038
Epoch: 85 | Iteration number: [950/4518] 21% | Training loss: 0.6875349628297907
Epoch: 85 | Iteration number: [960/4518] 21% | Training loss: 0.6875194074586034
Epoch: 85 | Iteration number: [970/4518] 21% | Training loss: 0.6875142486439538
Epoch: 85 | Iteration number: [980/4518] 21% | Training loss: 0.6874927650300824
Epoch: 85 | Iteration number: [990/4518] 21% | Training loss: 0.6874828935271562
Epoch: 85 | Iteration number: [1000/4518] 22% | Training loss: 0.6874848004579545
Epoch: 85 | Iteration number: [1010/4518] 22% | Training loss: 0.6874764428280368
Epoch: 85 | Iteration number: [1020/4518] 22% | Training loss: 0.6874685819826875
Epoch: 85 | Iteration number: [1030/4518] 22% | Training loss: 0.6874655136205617
Epoch: 85 | Iteration number: [1040/4518] 23% | Training loss: 0.6874695660976263
Epoch: 85 | Iteration number: [1050/4518] 23% | Training loss: 0.6874476806890397
Epoch: 85 | Iteration number: [1060/4518] 23% | Training loss: 0.6874369581915297
Epoch: 85 | Iteration number: [1070/4518] 23% | Training loss: 0.6874345972159198
Epoch: 85 | Iteration number: [1080/4518] 23% | Training loss: 0.687423512118834
Epoch: 85 | Iteration number: [1090/4518] 24% | Training loss: 0.6874176131475956
Epoch: 85 | Iteration number: [1100/4518] 24% | Training loss: 0.6873995590209961
Epoch: 85 | Iteration number: [1110/4518] 24% | Training loss: 0.6874020113064362
Epoch: 85 | Iteration number: [1120/4518] 24% | Training loss: 0.6873949752854449
Epoch: 85 | Iteration number: [1130/4518] 25% | Training loss: 0.6874039805568425
Epoch: 85 | Iteration number: [1140/4518] 25% | Training loss: 0.6873996255690591
Epoch: 85 | Iteration number: [1150/4518] 25% | Training loss: 0.6874000575231469
Epoch: 85 | Iteration number: [1160/4518] 25% | Training loss: 0.6873863092784224
Epoch: 85 | Iteration number: [1170/4518] 25% | Training loss: 0.6873771770387633
Epoch: 85 | Iteration number: [1180/4518] 26% | Training loss: 0.687374645724135
Epoch: 85 | Iteration number: [1190/4518] 26% | Training loss: 0.6873710074845483
Epoch: 85 | Iteration number: [1200/4518] 26% | Training loss: 0.6873804202179113
Epoch: 85 | Iteration number: [1210/4518] 26% | Training loss: 0.6873782431291154
Epoch: 85 | Iteration number: [1220/4518] 27% | Training loss: 0.687363474632873
Epoch: 85 | Iteration number: [1230/4518] 27% | Training loss: 0.6873675013460764
Epoch: 85 | Iteration number: [1240/4518] 27% | Training loss: 0.6873681273671889
Epoch: 85 | Iteration number: [1250/4518] 27% | Training loss: 0.6873640737056732
Epoch: 85 | Iteration number: [1260/4518] 27% | Training loss: 0.6873648826092008
Epoch: 85 | Iteration number: [1270/4518] 28% | Training loss: 0.6873557346073661
Epoch: 85 | Iteration number: [1280/4518] 28% | Training loss: 0.6873562651220709
Epoch: 85 | Iteration number: [1290/4518] 28% | Training loss: 0.6873477787010429
Epoch: 85 | Iteration number: [1300/4518] 28% | Training loss: 0.6873559674849877
Epoch: 85 | Iteration number: [1310/4518] 28% | Training loss: 0.6873548748838992
Epoch: 85 | Iteration number: [1320/4518] 29% | Training loss: 0.6873429135391207
Epoch: 85 | Iteration number: [1330/4518] 29% | Training loss: 0.6873400264216545
Epoch: 85 | Iteration number: [1340/4518] 29% | Training loss: 0.6873408425654938
Epoch: 85 | Iteration number: [1350/4518] 29% | Training loss: 0.6873328368310575
Epoch: 85 | Iteration number: [1360/4518] 30% | Training loss: 0.687322573319954
Epoch: 85 | Iteration number: [1370/4518] 30% | Training loss: 0.6873190078422101
Epoch: 85 | Iteration number: [1380/4518] 30% | Training loss: 0.6873232736967612
Epoch: 85 | Iteration number: [1390/4518] 30% | Training loss: 0.68732383697153
Epoch: 85 | Iteration number: [1400/4518] 30% | Training loss: 0.6873223081656865
Epoch: 85 | Iteration number: [1410/4518] 31% | Training loss: 0.6873055922646895
Epoch: 85 | Iteration number: [1420/4518] 31% | Training loss: 0.6872918947901524
Epoch: 85 | Iteration number: [1430/4518] 31% | Training loss: 0.6872919754965322
Epoch: 85 | Iteration number: [1440/4518] 31% | Training loss: 0.6872816836668385
Epoch: 85 | Iteration number: [1450/4518] 32% | Training loss: 0.6872791582551496
Epoch: 85 | Iteration number: [1460/4518] 32% | Training loss: 0.6872724117073294
Epoch: 85 | Iteration number: [1470/4518] 32% | Training loss: 0.6872656594733803
Epoch: 85 | Iteration number: [1480/4518] 32% | Training loss: 0.6872616879843377
Epoch: 85 | Iteration number: [1490/4518] 32% | Training loss: 0.687262207429681
Epoch: 85 | Iteration number: [1500/4518] 33% | Training loss: 0.6872651613156001
Epoch: 85 | Iteration number: [1510/4518] 33% | Training loss: 0.6872660490456006
Epoch: 85 | Iteration number: [1520/4518] 33% | Training loss: 0.6872703955753854
Epoch: 85 | Iteration number: [1530/4518] 33% | Training loss: 0.6872644186019897
Epoch: 85 | Iteration number: [1540/4518] 34% | Training loss: 0.6872630886830293
Epoch: 85 | Iteration number: [1550/4518] 34% | Training loss: 0.68725956432281
Epoch: 85 | Iteration number: [1560/4518] 34% | Training loss: 0.6872568908028114
Epoch: 85 | Iteration number: [1570/4518] 34% | Training loss: 0.6872510271846869
Epoch: 85 | Iteration number: [1580/4518] 34% | Training loss: 0.6872441053767747
Epoch: 85 | Iteration number: [1590/4518] 35% | Training loss: 0.687236335255065
Epoch: 85 | Iteration number: [1600/4518] 35% | Training loss: 0.6872384672611952
Epoch: 85 | Iteration number: [1610/4518] 35% | Training loss: 0.6872338751088019
Epoch: 85 | Iteration number: [1620/4518] 35% | Training loss: 0.6872205353813406
Epoch: 85 | Iteration number: [1630/4518] 36% | Training loss: 0.687223305146387
Epoch: 85 | Iteration number: [1640/4518] 36% | Training loss: 0.6872231628836655
Epoch: 85 | Iteration number: [1650/4518] 36% | Training loss: 0.6872241248145248
Epoch: 85 | Iteration number: [1660/4518] 36% | Training loss: 0.6872246704546802
Epoch: 85 | Iteration number: [1670/4518] 36% | Training loss: 0.6872233967581195
Epoch: 85 | Iteration number: [1680/4518] 37% | Training loss: 0.6872204596088046
Epoch: 85 | Iteration number: [1690/4518] 37% | Training loss: 0.6872244658202109
Epoch: 85 | Iteration number: [1700/4518] 37% | Training loss: 0.687222981523065
Epoch: 85 | Iteration number: [1710/4518] 37% | Training loss: 0.6872186058097416
Epoch: 85 | Iteration number: [1720/4518] 38% | Training loss: 0.6872168578380762
Epoch: 85 | Iteration number: [1730/4518] 38% | Training loss: 0.6872100601995611
Epoch: 85 | Iteration number: [1740/4518] 38% | Training loss: 0.6872141235176175
Epoch: 85 | Iteration number: [1750/4518] 38% | Training loss: 0.6872144810812814
Epoch: 85 | Iteration number: [1760/4518] 38% | Training loss: 0.6872034234756773
Epoch: 85 | Iteration number: [1770/4518] 39% | Training loss: 0.6872059280926225
Epoch: 85 | Iteration number: [1780/4518] 39% | Training loss: 0.6872045501229468
Epoch: 85 | Iteration number: [1790/4518] 39% | Training loss: 0.6872014659077096
Epoch: 85 | Iteration number: [1800/4518] 39% | Training loss: 0.6871951970126894
Epoch: 85 | Iteration number: [1810/4518] 40% | Training loss: 0.6871965619740565
Epoch: 85 | Iteration number: [1820/4518] 40% | Training loss: 0.687192546568074
Epoch: 85 | Iteration number: [1830/4518] 40% | Training loss: 0.6871924388604086
Epoch: 85 | Iteration number: [1840/4518] 40% | Training loss: 0.6871850849169752
Epoch: 85 | Iteration number: [1850/4518] 40% | Training loss: 0.687176311692676
Epoch: 85 | Iteration number: [1860/4518] 41% | Training loss: 0.6871744903505489
Epoch: 85 | Iteration number: [1870/4518] 41% | Training loss: 0.6871699681256545
Epoch: 85 | Iteration number: [1880/4518] 41% | Training loss: 0.6871668229077724
Epoch: 85 | Iteration number: [1890/4518] 41% | Training loss: 0.6871603005146855
Epoch: 85 | Iteration number: [1900/4518] 42% | Training loss: 0.6871637403337579
Epoch: 85 | Iteration number: [1910/4518] 42% | Training loss: 0.6871645542027438
Epoch: 85 | Iteration number: [1920/4518] 42% | Training loss: 0.6871615742954115
Epoch: 85 | Iteration number: [1930/4518] 42% | Training loss: 0.6871528355877634
Epoch: 85 | Iteration number: [1940/4518] 42% | Training loss: 0.6871543666751114
Epoch: 85 | Iteration number: [1950/4518] 43% | Training loss: 0.6871536005460299
Epoch: 85 | Iteration number: [1960/4518] 43% | Training loss: 0.6871442051566377
Epoch: 85 | Iteration number: [1970/4518] 43% | Training loss: 0.6871425534867999
Epoch: 85 | Iteration number: [1980/4518] 43% | Training loss: 0.68714038293169
Epoch: 85 | Iteration number: [1990/4518] 44% | Training loss: 0.6871367057963232
Epoch: 85 | Iteration number: [2000/4518] 44% | Training loss: 0.6871301130652427
Epoch: 85 | Iteration number: [2010/4518] 44% | Training loss: 0.6871236535447154
Epoch: 85 | Iteration number: [2020/4518] 44% | Training loss: 0.6871198762171339
Epoch: 85 | Iteration number: [2030/4518] 44% | Training loss: 0.6871196302874335
Epoch: 85 | Iteration number: [2040/4518] 45% | Training loss: 0.6871217687924703
Epoch: 85 | Iteration number: [2050/4518] 45% | Training loss: 0.6871294155062698
Epoch: 85 | Iteration number: [2060/4518] 45% | Training loss: 0.6871297107738199
Epoch: 85 | Iteration number: [2070/4518] 45% | Training loss: 0.6871333676259874
Epoch: 85 | Iteration number: [2080/4518] 46% | Training loss: 0.6871244055147354
Epoch: 85 | Iteration number: [2090/4518] 46% | Training loss: 0.6871175811051181
Epoch: 85 | Iteration number: [2100/4518] 46% | Training loss: 0.687122286870366
Epoch: 85 | Iteration number: [2110/4518] 46% | Training loss: 0.687121921156255
Epoch: 85 | Iteration number: [2120/4518] 46% | Training loss: 0.687119269174225
Epoch: 85 | Iteration number: [2130/4518] 47% | Training loss: 0.6871145938483763
Epoch: 85 | Iteration number: [2140/4518] 47% | Training loss: 0.6871131224888507
Epoch: 85 | Iteration number: [2150/4518] 47% | Training loss: 0.6871121714835943
Epoch: 85 | Iteration number: [2160/4518] 47% | Training loss: 0.6871093341321857
Epoch: 85 | Iteration number: [2170/4518] 48% | Training loss: 0.6871079730548068
Epoch: 85 | Iteration number: [2180/4518] 48% | Training loss: 0.6871077559956716
Epoch: 85 | Iteration number: [2190/4518] 48% | Training loss: 0.6871059340156921
Epoch: 85 | Iteration number: [2200/4518] 48% | Training loss: 0.6871073613925414
Epoch: 85 | Iteration number: [2210/4518] 48% | Training loss: 0.687108312526979
Epoch: 85 | Iteration number: [2220/4518] 49% | Training loss: 0.6871115747604284
Epoch: 85 | Iteration number: [2230/4518] 49% | Training loss: 0.6871139915000163
Epoch: 85 | Iteration number: [2240/4518] 49% | Training loss: 0.6871147327391165
Epoch: 85 | Iteration number: [2250/4518] 49% | Training loss: 0.6871142295731438
Epoch: 85 | Iteration number: [2260/4518] 50% | Training loss: 0.6871148226799163
Epoch: 85 | Iteration number: [2270/4518] 50% | Training loss: 0.6871169811828546
Epoch: 85 | Iteration number: [2280/4518] 50% | Training loss: 0.6871121150882621
Epoch: 85 | Iteration number: [2290/4518] 50% | Training loss: 0.6871142219768341
Epoch: 85 | Iteration number: [2300/4518] 50% | Training loss: 0.6871112325917119
Epoch: 85 | Iteration number: [2310/4518] 51% | Training loss: 0.6871055983877802
Epoch: 85 | Iteration number: [2320/4518] 51% | Training loss: 0.6870977620369402
Epoch: 85 | Iteration number: [2330/4518] 51% | Training loss: 0.6870992713987571
Epoch: 85 | Iteration number: [2340/4518] 51% | Training loss: 0.6871000278709282
Epoch: 85 | Iteration number: [2350/4518] 52% | Training loss: 0.6870994810094224
Epoch: 85 | Iteration number: [2360/4518] 52% | Training loss: 0.6870918646202249
Epoch: 85 | Iteration number: [2370/4518] 52% | Training loss: 0.6870900897285607
Epoch: 85 | Iteration number: [2380/4518] 52% | Training loss: 0.6870882551209265
Epoch: 85 | Iteration number: [2390/4518] 52% | Training loss: 0.6870871308957184
Epoch: 85 | Iteration number: [2400/4518] 53% | Training loss: 0.6870804142951965
Epoch: 85 | Iteration number: [2410/4518] 53% | Training loss: 0.6870851404192042
Epoch: 85 | Iteration number: [2420/4518] 53% | Training loss: 0.6870892601811196
Epoch: 85 | Iteration number: [2430/4518] 53% | Training loss: 0.6870864704557897
Epoch: 85 | Iteration number: [2440/4518] 54% | Training loss: 0.6870867266029608
Epoch: 85 | Iteration number: [2450/4518] 54% | Training loss: 0.6870837084371216
Epoch: 85 | Iteration number: [2460/4518] 54% | Training loss: 0.6870798719850013
Epoch: 85 | Iteration number: [2470/4518] 54% | Training loss: 0.6870769714778252
Epoch: 85 | Iteration number: [2480/4518] 54% | Training loss: 0.6870700234847684
Epoch: 85 | Iteration number: [2490/4518] 55% | Training loss: 0.6870704696360362
Epoch: 85 | Iteration number: [2500/4518] 55% | Training loss: 0.6870661289930343
Epoch: 85 | Iteration number: [2510/4518] 55% | Training loss: 0.687062377402507
Epoch: 85 | Iteration number: [2520/4518] 55% | Training loss: 0.6870624124767288
Epoch: 85 | Iteration number: [2530/4518] 55% | Training loss: 0.6870605803054312
Epoch: 85 | Iteration number: [2540/4518] 56% | Training loss: 0.6870542634894529
Epoch: 85 | Iteration number: [2550/4518] 56% | Training loss: 0.6870468450060078
Epoch: 85 | Iteration number: [2560/4518] 56% | Training loss: 0.6870423587039113
Epoch: 85 | Iteration number: [2570/4518] 56% | Training loss: 0.6870438341500694
Epoch: 85 | Iteration number: [2580/4518] 57% | Training loss: 0.6870440102593843
Epoch: 85 | Iteration number: [2590/4518] 57% | Training loss: 0.6870445573882247
Epoch: 85 | Iteration number: [2600/4518] 57% | Training loss: 0.6870449856840647
Epoch: 85 | Iteration number: [2610/4518] 57% | Training loss: 0.6870402537543198
Epoch: 85 | Iteration number: [2620/4518] 57% | Training loss: 0.687036156813607
Epoch: 85 | Iteration number: [2630/4518] 58% | Training loss: 0.6870356254931185
Epoch: 85 | Iteration number: [2640/4518] 58% | Training loss: 0.6870284491190405
Epoch: 85 | Iteration number: [2650/4518] 58% | Training loss: 0.6870256462187138
Epoch: 85 | Iteration number: [2660/4518] 58% | Training loss: 0.687025715914884
Epoch: 85 | Iteration number: [2670/4518] 59% | Training loss: 0.6870239847608274
Epoch: 85 | Iteration number: [2680/4518] 59% | Training loss: 0.6870266332332767
Epoch: 85 | Iteration number: [2690/4518] 59% | Training loss: 0.6870230774454025
Epoch: 85 | Iteration number: [2700/4518] 59% | Training loss: 0.687022113998731
Epoch: 85 | Iteration number: [2710/4518] 59% | Training loss: 0.6870198280169075
Epoch: 85 | Iteration number: [2720/4518] 60% | Training loss: 0.6870163798551349
Epoch: 85 | Iteration number: [2730/4518] 60% | Training loss: 0.6870190539639511
Epoch: 85 | Iteration number: [2740/4518] 60% | Training loss: 0.6870145493615283
Epoch: 85 | Iteration number: [2750/4518] 60% | Training loss: 0.6870115967230364
Epoch: 85 | Iteration number: [2760/4518] 61% | Training loss: 0.6870124127985775
Epoch: 85 | Iteration number: [2770/4518] 61% | Training loss: 0.6870127394096085
Epoch: 85 | Iteration number: [2780/4518] 61% | Training loss: 0.687011461892574
Epoch: 85 | Iteration number: [2790/4518] 61% | Training loss: 0.6870091685471141
Epoch: 85 | Iteration number: [2800/4518] 61% | Training loss: 0.6870085904640811
Epoch: 85 | Iteration number: [2810/4518] 62% | Training loss: 0.6870046895806051
Epoch: 85 | Iteration number: [2820/4518] 62% | Training loss: 0.6870044153844211
Epoch: 85 | Iteration number: [2830/4518] 62% | Training loss: 0.6870064592192956
Epoch: 85 | Iteration number: [2840/4518] 62% | Training loss: 0.6870075428779696
Epoch: 85 | Iteration number: [2850/4518] 63% | Training loss: 0.6870034573161811
Epoch: 85 | Iteration number: [2860/4518] 63% | Training loss: 0.6870007332596746
Epoch: 85 | Iteration number: [2870/4518] 63% | Training loss: 0.6870043004223694
Epoch: 85 | Iteration number: [2880/4518] 63% | Training loss: 0.6870043630194332
Epoch: 85 | Iteration number: [2890/4518] 63% | Training loss: 0.6870062824351565
Epoch: 85 | Iteration number: [2900/4518] 64% | Training loss: 0.687002607542893
Epoch: 85 | Iteration number: [2910/4518] 64% | Training loss: 0.6870000329623926
Epoch: 85 | Iteration number: [2920/4518] 64% | Training loss: 0.6870002046839832
Epoch: 85 | Iteration number: [2930/4518] 64% | Training loss: 0.6869983920261722
Epoch: 85 | Iteration number: [2940/4518] 65% | Training loss: 0.686999230117214
Epoch: 85 | Iteration number: [2950/4518] 65% | Training loss: 0.6869936878398314
Epoch: 85 | Iteration number: [2960/4518] 65% | Training loss: 0.6869910595988905
Epoch: 85 | Iteration number: [2970/4518] 65% | Training loss: 0.6869943806418666
Epoch: 85 | Iteration number: [2980/4518] 65% | Training loss: 0.6869929874903403
Epoch: 85 | Iteration number: [2990/4518] 66% | Training loss: 0.6869921794503827
Epoch: 85 | Iteration number: [3000/4518] 66% | Training loss: 0.6869917310873668
Epoch: 85 | Iteration number: [3010/4518] 66% | Training loss: 0.6869956431198754
Epoch: 85 | Iteration number: [3020/4518] 66% | Training loss: 0.686998634109434
Epoch: 85 | Iteration number: [3030/4518] 67% | Training loss: 0.6869937952595575
Epoch: 85 | Iteration number: [3040/4518] 67% | Training loss: 0.6869944399712902
Epoch: 85 | Iteration number: [3050/4518] 67% | Training loss: 0.6869913743558477
Epoch: 85 | Iteration number: [3060/4518] 67% | Training loss: 0.6869879099473455
Epoch: 85 | Iteration number: [3070/4518] 67% | Training loss: 0.6869868660788583
Epoch: 85 | Iteration number: [3080/4518] 68% | Training loss: 0.686984033031123
Epoch: 85 | Iteration number: [3090/4518] 68% | Training loss: 0.6869808328190282
Epoch: 85 | Iteration number: [3100/4518] 68% | Training loss: 0.6869853773616975
Epoch: 85 | Iteration number: [3110/4518] 68% | Training loss: 0.6869893089559684
Epoch: 85 | Iteration number: [3120/4518] 69% | Training loss: 0.6869887075745142
Epoch: 85 | Iteration number: [3130/4518] 69% | Training loss: 0.6869852639806157
Epoch: 85 | Iteration number: [3140/4518] 69% | Training loss: 0.6869818432885371
Epoch: 85 | Iteration number: [3150/4518] 69% | Training loss: 0.6869781077854217
Epoch: 85 | Iteration number: [3160/4518] 69% | Training loss: 0.6869758373385744
Epoch: 85 | Iteration number: [3170/4518] 70% | Training loss: 0.686976874927617
Epoch: 85 | Iteration number: [3180/4518] 70% | Training loss: 0.6869791664042563
Epoch: 85 | Iteration number: [3190/4518] 70% | Training loss: 0.6869841112425334
Epoch: 85 | Iteration number: [3200/4518] 70% | Training loss: 0.6869791573658586
Epoch: 85 | Iteration number: [3210/4518] 71% | Training loss: 0.6869774594856571
Epoch: 85 | Iteration number: [3220/4518] 71% | Training loss: 0.6869766365297092
Epoch: 85 | Iteration number: [3230/4518] 71% | Training loss: 0.6869733577542261
Epoch: 85 | Iteration number: [3240/4518] 71% | Training loss: 0.6869743846448851
Epoch: 85 | Iteration number: [3250/4518] 71% | Training loss: 0.6869777757938091
Epoch: 85 | Iteration number: [3260/4518] 72% | Training loss: 0.6869711167241898
Epoch: 85 | Iteration number: [3270/4518] 72% | Training loss: 0.6869728595109525
Epoch: 85 | Iteration number: [3280/4518] 72% | Training loss: 0.6869715302455716
Epoch: 85 | Iteration number: [3290/4518] 72% | Training loss: 0.6869731776801287
Epoch: 85 | Iteration number: [3300/4518] 73% | Training loss: 0.6869713973999023
Epoch: 85 | Iteration number: [3310/4518] 73% | Training loss: 0.6869703819744537
Epoch: 85 | Iteration number: [3320/4518] 73% | Training loss: 0.6869688854339611
Epoch: 85 | Iteration number: [3330/4518] 73% | Training loss: 0.6869702411843491
Epoch: 85 | Iteration number: [3340/4518] 73% | Training loss: 0.6869696634615253
Epoch: 85 | Iteration number: [3350/4518] 74% | Training loss: 0.6869703401914283
Epoch: 85 | Iteration number: [3360/4518] 74% | Training loss: 0.686970915237353
Epoch: 85 | Iteration number: [3370/4518] 74% | Training loss: 0.6869660605839523
Epoch: 85 | Iteration number: [3380/4518] 74% | Training loss: 0.6869637814499218
Epoch: 85 | Iteration number: [3390/4518] 75% | Training loss: 0.6869665232907354
Epoch: 85 | Iteration number: [3400/4518] 75% | Training loss: 0.6869682906655704
Epoch: 85 | Iteration number: [3410/4518] 75% | Training loss: 0.6869686667520629
Epoch: 85 | Iteration number: [3420/4518] 75% | Training loss: 0.6869647045407379
Epoch: 85 | Iteration number: [3430/4518] 75% | Training loss: 0.6869634466685637
Epoch: 85 | Iteration number: [3440/4518] 76% | Training loss: 0.6869643928006638
Epoch: 85 | Iteration number: [3450/4518] 76% | Training loss: 0.6869663803473763
Epoch: 85 | Iteration number: [3460/4518] 76% | Training loss: 0.6869664090733997
Epoch: 85 | Iteration number: [3470/4518] 76% | Training loss: 0.6869672460411742
Epoch: 85 | Iteration number: [3480/4518] 77% | Training loss: 0.6869691179401574
Epoch: 85 | Iteration number: [3490/4518] 77% | Training loss: 0.686968294870546
Epoch: 85 | Iteration number: [3500/4518] 77% | Training loss: 0.6869703401156834
Epoch: 85 | Iteration number: [3510/4518] 77% | Training loss: 0.6869681566529124
Epoch: 85 | Iteration number: [3520/4518] 77% | Training loss: 0.6869681884619323
Epoch: 85 | Iteration number: [3530/4518] 78% | Training loss: 0.6869670335192856
Epoch: 85 | Iteration number: [3540/4518] 78% | Training loss: 0.6869689921201285
Epoch: 85 | Iteration number: [3550/4518] 78% | Training loss: 0.6869709537230747
Epoch: 85 | Iteration number: [3560/4518] 78% | Training loss: 0.6869696419058221
Epoch: 85 | Iteration number: [3570/4518] 79% | Training loss: 0.6869678335363457
Epoch: 85 | Iteration number: [3580/4518] 79% | Training loss: 0.6869670914871067
Epoch: 85 | Iteration number: [3590/4518] 79% | Training loss: 0.6869691408278218
Epoch: 85 | Iteration number: [3600/4518] 79% | Training loss: 0.6869694225986799
Epoch: 85 | Iteration number: [3610/4518] 79% | Training loss: 0.6869655639511066
Epoch: 85 | Iteration number: [3620/4518] 80% | Training loss: 0.6869633850965711
Epoch: 85 | Iteration number: [3630/4518] 80% | Training loss: 0.6869634172968956
Epoch: 85 | Iteration number: [3640/4518] 80% | Training loss: 0.6869632322054643
Epoch: 85 | Iteration number: [3650/4518] 80% | Training loss: 0.6869608106188578
Epoch: 85 | Iteration number: [3660/4518] 81% | Training loss: 0.6869572084783856
Epoch: 85 | Iteration number: [3670/4518] 81% | Training loss: 0.6869556972863564
Epoch: 85 | Iteration number: [3680/4518] 81% | Training loss: 0.6869611384266097
Epoch: 85 | Iteration number: [3690/4518] 81% | Training loss: 0.6869601320606583
Epoch: 85 | Iteration number: [3700/4518] 81% | Training loss: 0.6869563404289452
Epoch: 85 | Iteration number: [3710/4518] 82% | Training loss: 0.6869571669082436
Epoch: 85 | Iteration number: [3720/4518] 82% | Training loss: 0.686957204630298
Epoch: 85 | Iteration number: [3730/4518] 82% | Training loss: 0.6869574853945674
Epoch: 85 | Iteration number: [3740/4518] 82% | Training loss: 0.686953550656849
Epoch: 85 | Iteration number: [3750/4518] 83% | Training loss: 0.686955044221878
Epoch: 85 | Iteration number: [3760/4518] 83% | Training loss: 0.6869557323132424
Epoch: 85 | Iteration number: [3770/4518] 83% | Training loss: 0.6869558078066423
Epoch: 85 | Iteration number: [3780/4518] 83% | Training loss: 0.6869560308872708
Epoch: 85 | Iteration number: [3790/4518] 83% | Training loss: 0.686953923287052
Epoch: 85 | Iteration number: [3800/4518] 84% | Training loss: 0.686951309724858
Epoch: 85 | Iteration number: [3810/4518] 84% | Training loss: 0.6869518587595521
Epoch: 85 | Iteration number: [3820/4518] 84% | Training loss: 0.6869524595157014
Epoch: 85 | Iteration number: [3830/4518] 84% | Training loss: 0.6869510992700064
Epoch: 85 | Iteration number: [3840/4518] 84% | Training loss: 0.6869502009203037
Epoch: 85 | Iteration number: [3850/4518] 85% | Training loss: 0.6869450168640583
Epoch: 85 | Iteration number: [3860/4518] 85% | Training loss: 0.6869453516803257
Epoch: 85 | Iteration number: [3870/4518] 85% | Training loss: 0.6869448892829955
Epoch: 85 | Iteration number: [3880/4518] 85% | Training loss: 0.6869447197496277
Epoch: 85 | Iteration number: [3890/4518] 86% | Training loss: 0.686940184963393
Epoch: 85 | Iteration number: [3900/4518] 86% | Training loss: 0.6869412923929019
Epoch: 85 | Iteration number: [3910/4518] 86% | Training loss: 0.6869397553946356
Epoch: 85 | Iteration number: [3920/4518] 86% | Training loss: 0.6869380362027762
Epoch: 85 | Iteration number: [3930/4518] 86% | Training loss: 0.6869374773884548
Epoch: 85 | Iteration number: [3940/4518] 87% | Training loss: 0.6869374684875992
Epoch: 85 | Iteration number: [3950/4518] 87% | Training loss: 0.6869370074060899
Epoch: 85 | Iteration number: [3960/4518] 87% | Training loss: 0.6869343525382003
Epoch: 85 | Iteration number: [3970/4518] 87% | Training loss: 0.6869350822956797
Epoch: 85 | Iteration number: [3980/4518] 88% | Training loss: 0.6869348758878421
Epoch: 85 | Iteration number: [3990/4518] 88% | Training loss: 0.6869322212865777
Epoch: 85 | Iteration number: [4000/4518] 88% | Training loss: 0.6869310564100742
Epoch: 85 | Iteration number: [4010/4518] 88% | Training loss: 0.6869320283655513
Epoch: 85 | Iteration number: [4020/4518] 88% | Training loss: 0.6869303586619411
Epoch: 85 | Iteration number: [4030/4518] 89% | Training loss: 0.6869276130317754
Epoch: 85 | Iteration number: [4040/4518] 89% | Training loss: 0.6869274742827557
Epoch: 85 | Iteration number: [4050/4518] 89% | Training loss: 0.6869251275651249
Epoch: 85 | Iteration number: [4060/4518] 89% | Training loss: 0.6869256442256749
Epoch: 85 | Iteration number: [4070/4518] 90% | Training loss: 0.6869267439812934
Epoch: 85 | Iteration number: [4080/4518] 90% | Training loss: 0.6869284278621861
Epoch: 85 | Iteration number: [4090/4518] 90% | Training loss: 0.6869267127333177
Epoch: 85 | Iteration number: [4100/4518] 90% | Training loss: 0.6869241711424618
Epoch: 85 | Iteration number: [4110/4518] 90% | Training loss: 0.6869239432968363
Epoch: 85 | Iteration number: [4120/4518] 91% | Training loss: 0.6869224907125084
Epoch: 85 | Iteration number: [4130/4518] 91% | Training loss: 0.6869223735378672
Epoch: 85 | Iteration number: [4140/4518] 91% | Training loss: 0.6869197713004218
Epoch: 85 | Iteration number: [4150/4518] 91% | Training loss: 0.6869197309160807
Epoch: 85 | Iteration number: [4160/4518] 92% | Training loss: 0.6869204789400101
Epoch: 85 | Iteration number: [4170/4518] 92% | Training loss: 0.6869192790784996
Epoch: 85 | Iteration number: [4180/4518] 92% | Training loss: 0.6869209040294993
Epoch: 85 | Iteration number: [4190/4518] 92% | Training loss: 0.686919403460259
Epoch: 85 | Iteration number: [4200/4518] 92% | Training loss: 0.6869204662527357
Epoch: 85 | Iteration number: [4210/4518] 93% | Training loss: 0.6869217105829234
Epoch: 85 | Iteration number: [4220/4518] 93% | Training loss: 0.6869223291133817
Epoch: 85 | Iteration number: [4230/4518] 93% | Training loss: 0.6869210231247805
Epoch: 85 | Iteration number: [4240/4518] 93% | Training loss: 0.6869202981439402
Epoch: 85 | Iteration number: [4250/4518] 94% | Training loss: 0.6869181919238146
Epoch: 85 | Iteration number: [4260/4518] 94% | Training loss: 0.6869188400641294
Epoch: 85 | Iteration number: [4270/4518] 94% | Training loss: 0.6869153634586156
Epoch: 85 | Iteration number: [4280/4518] 94% | Training loss: 0.6869159695840328
Epoch: 85 | Iteration number: [4290/4518] 94% | Training loss: 0.6869159868963949
Epoch: 85 | Iteration number: [4300/4518] 95% | Training loss: 0.6869177430036456
Epoch: 85 | Iteration number: [4310/4518] 95% | Training loss: 0.6869200418830748
Epoch: 85 | Iteration number: [4320/4518] 95% | Training loss: 0.6869189385600664
Epoch: 85 | Iteration number: [4330/4518] 95% | Training loss: 0.6869196041626964
Epoch: 85 | Iteration number: [4340/4518] 96% | Training loss: 0.6869196189164016
Epoch: 85 | Iteration number: [4350/4518] 96% | Training loss: 0.6869219761333246
Epoch: 85 | Iteration number: [4360/4518] 96% | Training loss: 0.686922413835285
Epoch: 85 | Iteration number: [4370/4518] 96% | Training loss: 0.6869218015834451
Epoch: 85 | Iteration number: [4380/4518] 96% | Training loss: 0.6869193277810807
Epoch: 85 | Iteration number: [4390/4518] 97% | Training loss: 0.6869184833724298
Epoch: 85 | Iteration number: [4400/4518] 97% | Training loss: 0.6869206832484765
Epoch: 85 | Iteration number: [4410/4518] 97% | Training loss: 0.6869198582475148
Epoch: 85 | Iteration number: [4420/4518] 97% | Training loss: 0.6869209023352661
Epoch: 85 | Iteration number: [4430/4518] 98% | Training loss: 0.6869192702910163
Epoch: 85 | Iteration number: [4440/4518] 98% | Training loss: 0.6869195711236816
Epoch: 85 | Iteration number: [4450/4518] 98% | Training loss: 0.6869207142578082
Epoch: 85 | Iteration number: [4460/4518] 98% | Training loss: 0.6869209833342933
Epoch: 85 | Iteration number: [4470/4518] 98% | Training loss: 0.6869244310279821
Epoch: 85 | Iteration number: [4480/4518] 99% | Training loss: 0.6869231804274023
Epoch: 85 | Iteration number: [4490/4518] 99% | Training loss: 0.6869235353374269
Epoch: 85 | Iteration number: [4500/4518] 99% | Training loss: 0.6869203511079153
Epoch: 85 | Iteration number: [4510/4518] 99% | Training loss: 0.6869210597548939

 End of epoch: 85 | Train Loss: 0.6867687378561882 | Training Time: 642 

 End of epoch: 85 | Eval Loss: 0.689995527267456 | Evaluating Time: 17 
Epoch: 86 | Iteration number: [10/4518] 0% | Training loss: 0.7560861766338348
Epoch: 86 | Iteration number: [20/4518] 0% | Training loss: 0.7205180108547211
Epoch: 86 | Iteration number: [30/4518] 0% | Training loss: 0.7096547802289327
Epoch: 86 | Iteration number: [40/4518] 0% | Training loss: 0.7042286738753318
Epoch: 86 | Iteration number: [50/4518] 1% | Training loss: 0.7006957733631134
Epoch: 86 | Iteration number: [60/4518] 1% | Training loss: 0.6982988814512888
Epoch: 86 | Iteration number: [70/4518] 1% | Training loss: 0.6966475810323443
Epoch: 86 | Iteration number: [80/4518] 1% | Training loss: 0.6954448066651822
Epoch: 86 | Iteration number: [90/4518] 1% | Training loss: 0.6945272299978468
Epoch: 86 | Iteration number: [100/4518] 2% | Training loss: 0.6938298469781876
Epoch: 86 | Iteration number: [110/4518] 2% | Training loss: 0.6932606978849931
Epoch: 86 | Iteration number: [120/4518] 2% | Training loss: 0.6928015475471815
Epoch: 86 | Iteration number: [130/4518] 2% | Training loss: 0.6923018606809469
Epoch: 86 | Iteration number: [140/4518] 3% | Training loss: 0.6918836453131267
Epoch: 86 | Iteration number: [150/4518] 3% | Training loss: 0.69155965924263
Epoch: 86 | Iteration number: [160/4518] 3% | Training loss: 0.6912209011614323
Epoch: 86 | Iteration number: [170/4518] 3% | Training loss: 0.6910263622508329
Epoch: 86 | Iteration number: [180/4518] 3% | Training loss: 0.690738875998391
Epoch: 86 | Iteration number: [190/4518] 4% | Training loss: 0.6905561945940318
Epoch: 86 | Iteration number: [200/4518] 4% | Training loss: 0.6903189805150032
Epoch: 86 | Iteration number: [210/4518] 4% | Training loss: 0.6901695197536832
Epoch: 86 | Iteration number: [220/4518] 4% | Training loss: 0.6900324249809439
Epoch: 86 | Iteration number: [230/4518] 5% | Training loss: 0.6899004106936247
Epoch: 86 | Iteration number: [240/4518] 5% | Training loss: 0.6898010561863581
Epoch: 86 | Iteration number: [250/4518] 5% | Training loss: 0.6897043492794037
Epoch: 86 | Iteration number: [260/4518] 5% | Training loss: 0.6895674765110016
Epoch: 86 | Iteration number: [270/4518] 5% | Training loss: 0.689472234028357
Epoch: 86 | Iteration number: [280/4518] 6% | Training loss: 0.6894055632608277
Epoch: 86 | Iteration number: [290/4518] 6% | Training loss: 0.6893129126778964
Epoch: 86 | Iteration number: [300/4518] 6% | Training loss: 0.6892056802908579
Epoch: 86 | Iteration number: [310/4518] 6% | Training loss: 0.6891200680886546
Epoch: 86 | Iteration number: [320/4518] 7% | Training loss: 0.6890773704275489
Epoch: 86 | Iteration number: [330/4518] 7% | Training loss: 0.6890209949377811
Epoch: 86 | Iteration number: [340/4518] 7% | Training loss: 0.6889530688524246
Epoch: 86 | Iteration number: [350/4518] 7% | Training loss: 0.6888727809701647
Epoch: 86 | Iteration number: [360/4518] 7% | Training loss: 0.688846285144488
Epoch: 86 | Iteration number: [370/4518] 8% | Training loss: 0.6887537474567825
Epoch: 86 | Iteration number: [380/4518] 8% | Training loss: 0.6887188423621027
Epoch: 86 | Iteration number: [390/4518] 8% | Training loss: 0.6886544809891627
Epoch: 86 | Iteration number: [400/4518] 8% | Training loss: 0.6886054742336273
Epoch: 86 | Iteration number: [410/4518] 9% | Training loss: 0.6885556825777379
Epoch: 86 | Iteration number: [420/4518] 9% | Training loss: 0.6884956646533239
Epoch: 86 | Iteration number: [430/4518] 9% | Training loss: 0.688452674483144
Epoch: 86 | Iteration number: [440/4518] 9% | Training loss: 0.6883824635635722
Epoch: 86 | Iteration number: [450/4518] 9% | Training loss: 0.6883835591210259
Epoch: 86 | Iteration number: [460/4518] 10% | Training loss: 0.6883583392785944
Epoch: 86 | Iteration number: [470/4518] 10% | Training loss: 0.6883378898843806
Epoch: 86 | Iteration number: [480/4518] 10% | Training loss: 0.6882949595650037
Epoch: 86 | Iteration number: [490/4518] 10% | Training loss: 0.6882796035737407
Epoch: 86 | Iteration number: [500/4518] 11% | Training loss: 0.6882470444440841
Epoch: 86 | Iteration number: [510/4518] 11% | Training loss: 0.6882112084650526
Epoch: 86 | Iteration number: [520/4518] 11% | Training loss: 0.6881765348406939
Epoch: 86 | Iteration number: [530/4518] 11% | Training loss: 0.6881283700466156
Epoch: 86 | Iteration number: [540/4518] 11% | Training loss: 0.6881084655170088
Epoch: 86 | Iteration number: [550/4518] 12% | Training loss: 0.6880714765462008
Epoch: 86 | Iteration number: [560/4518] 12% | Training loss: 0.6880454047449998
Epoch: 86 | Iteration number: [570/4518] 12% | Training loss: 0.6880150646494146
Epoch: 86 | Iteration number: [580/4518] 12% | Training loss: 0.6879821742403096
Epoch: 86 | Iteration number: [590/4518] 13% | Training loss: 0.6879484751466978
Epoch: 86 | Iteration number: [600/4518] 13% | Training loss: 0.6879300258557002
Epoch: 86 | Iteration number: [610/4518] 13% | Training loss: 0.6879202887660167
Epoch: 86 | Iteration number: [620/4518] 13% | Training loss: 0.6878940873569058
Epoch: 86 | Iteration number: [630/4518] 13% | Training loss: 0.6878721873911601
Epoch: 86 | Iteration number: [640/4518] 14% | Training loss: 0.6878605237230658
Epoch: 86 | Iteration number: [650/4518] 14% | Training loss: 0.6878542514947744
Epoch: 86 | Iteration number: [660/4518] 14% | Training loss: 0.687827807393941
Epoch: 86 | Iteration number: [670/4518] 14% | Training loss: 0.6878169954712711
Epoch: 86 | Iteration number: [680/4518] 15% | Training loss: 0.6878211564000916
Epoch: 86 | Iteration number: [690/4518] 15% | Training loss: 0.6877961214037909
Epoch: 86 | Iteration number: [700/4518] 15% | Training loss: 0.6877624528748648
Epoch: 86 | Iteration number: [710/4518] 15% | Training loss: 0.6877641346253139
Epoch: 86 | Iteration number: [720/4518] 15% | Training loss: 0.687753149949842
Epoch: 86 | Iteration number: [730/4518] 16% | Training loss: 0.6877409025414349
Epoch: 86 | Iteration number: [740/4518] 16% | Training loss: 0.6877340654263625
Epoch: 86 | Iteration number: [750/4518] 16% | Training loss: 0.6877223006884257
Epoch: 86 | Iteration number: [760/4518] 16% | Training loss: 0.6877053743914554
Epoch: 86 | Iteration number: [770/4518] 17% | Training loss: 0.6876884202678483
Epoch: 86 | Iteration number: [780/4518] 17% | Training loss: 0.6876637525283373
Epoch: 86 | Iteration number: [790/4518] 17% | Training loss: 0.6876580190054978
Epoch: 86 | Iteration number: [800/4518] 17% | Training loss: 0.6876268397271633
Epoch: 86 | Iteration number: [810/4518] 17% | Training loss: 0.6876405868265364
Epoch: 86 | Iteration number: [820/4518] 18% | Training loss: 0.6876243884970502
Epoch: 86 | Iteration number: [830/4518] 18% | Training loss: 0.6876118441662157
Epoch: 86 | Iteration number: [840/4518] 18% | Training loss: 0.6875915371236347
Epoch: 86 | Iteration number: [850/4518] 18% | Training loss: 0.6875695382847505
Epoch: 86 | Iteration number: [860/4518] 19% | Training loss: 0.6875700775967087
Epoch: 86 | Iteration number: [870/4518] 19% | Training loss: 0.6875692268897747
Epoch: 86 | Iteration number: [880/4518] 19% | Training loss: 0.6875749755989421
Epoch: 86 | Iteration number: [890/4518] 19% | Training loss: 0.6875792404239097
Epoch: 86 | Iteration number: [900/4518] 19% | Training loss: 0.6875579339265824
Epoch: 86 | Iteration number: [910/4518] 20% | Training loss: 0.6875550511774126
Epoch: 86 | Iteration number: [920/4518] 20% | Training loss: 0.6875542678910753
Epoch: 86 | Iteration number: [930/4518] 20% | Training loss: 0.6875400844440666
Epoch: 86 | Iteration number: [940/4518] 20% | Training loss: 0.6875408076859535
Epoch: 86 | Iteration number: [950/4518] 21% | Training loss: 0.6875354518388447
Epoch: 86 | Iteration number: [960/4518] 21% | Training loss: 0.6875271751234929
Epoch: 86 | Iteration number: [970/4518] 21% | Training loss: 0.6874977412297554
Epoch: 86 | Iteration number: [980/4518] 21% | Training loss: 0.6874918036923117
Epoch: 86 | Iteration number: [990/4518] 21% | Training loss: 0.687481759232704
Epoch: 86 | Iteration number: [1000/4518] 22% | Training loss: 0.6874831315875053
Epoch: 86 | Iteration number: [1010/4518] 22% | Training loss: 0.6874789964444566
Epoch: 86 | Iteration number: [1020/4518] 22% | Training loss: 0.6874628855317246
Epoch: 86 | Iteration number: [1030/4518] 22% | Training loss: 0.6874370515346527
Epoch: 86 | Iteration number: [1040/4518] 23% | Training loss: 0.6874334536492824
Epoch: 86 | Iteration number: [1050/4518] 23% | Training loss: 0.6874296011243548
Epoch: 86 | Iteration number: [1060/4518] 23% | Training loss: 0.6874213851285431
Epoch: 86 | Iteration number: [1070/4518] 23% | Training loss: 0.6874099350421228
Epoch: 86 | Iteration number: [1080/4518] 23% | Training loss: 0.6874197611102352
Epoch: 86 | Iteration number: [1090/4518] 24% | Training loss: 0.6874167419901681
Epoch: 86 | Iteration number: [1100/4518] 24% | Training loss: 0.6874136799032038
Epoch: 86 | Iteration number: [1110/4518] 24% | Training loss: 0.6874180612800358
Epoch: 86 | Iteration number: [1120/4518] 24% | Training loss: 0.6874185222600188
Epoch: 86 | Iteration number: [1130/4518] 25% | Training loss: 0.6874098702869584
Epoch: 86 | Iteration number: [1140/4518] 25% | Training loss: 0.6874000682119737
Epoch: 86 | Iteration number: [1150/4518] 25% | Training loss: 0.6873940736314524
Epoch: 86 | Iteration number: [1160/4518] 25% | Training loss: 0.6874000202479034
Epoch: 86 | Iteration number: [1170/4518] 25% | Training loss: 0.6873906858965881
Epoch: 86 | Iteration number: [1180/4518] 26% | Training loss: 0.6873731583861982
Epoch: 86 | Iteration number: [1190/4518] 26% | Training loss: 0.6873716740047231
Epoch: 86 | Iteration number: [1200/4518] 26% | Training loss: 0.6873696249723434
Epoch: 86 | Iteration number: [1210/4518] 26% | Training loss: 0.6873608880791783
Epoch: 86 | Iteration number: [1220/4518] 27% | Training loss: 0.6873589527900101
Epoch: 86 | Iteration number: [1230/4518] 27% | Training loss: 0.6873558168004199
Epoch: 86 | Iteration number: [1240/4518] 27% | Training loss: 0.6873599449473042
Epoch: 86 | Iteration number: [1250/4518] 27% | Training loss: 0.687344394159317
Epoch: 86 | Iteration number: [1260/4518] 27% | Training loss: 0.6873489384140287
Epoch: 86 | Iteration number: [1270/4518] 28% | Training loss: 0.6873506533817982
Epoch: 86 | Iteration number: [1280/4518] 28% | Training loss: 0.6873468646313995
Epoch: 86 | Iteration number: [1290/4518] 28% | Training loss: 0.6873390547064848
Epoch: 86 | Iteration number: [1300/4518] 28% | Training loss: 0.6873211198128186
Epoch: 86 | Iteration number: [1310/4518] 28% | Training loss: 0.6873258199400574
Epoch: 86 | Iteration number: [1320/4518] 29% | Training loss: 0.6873120195034779
Epoch: 86 | Iteration number: [1330/4518] 29% | Training loss: 0.6873040526433098
Epoch: 86 | Iteration number: [1340/4518] 29% | Training loss: 0.6872973964730306
Epoch: 86 | Iteration number: [1350/4518] 29% | Training loss: 0.6872965172043554
Epoch: 86 | Iteration number: [1360/4518] 30% | Training loss: 0.6872941249871956
Epoch: 86 | Iteration number: [1370/4518] 30% | Training loss: 0.6872952460807605
Epoch: 86 | Iteration number: [1380/4518] 30% | Training loss: 0.6872861077820045
Epoch: 86 | Iteration number: [1390/4518] 30% | Training loss: 0.6872865209905363
Epoch: 86 | Iteration number: [1400/4518] 30% | Training loss: 0.6872801700234413
Epoch: 86 | Iteration number: [1410/4518] 31% | Training loss: 0.6872895953080332
Epoch: 86 | Iteration number: [1420/4518] 31% | Training loss: 0.6872783172718236
Epoch: 86 | Iteration number: [1430/4518] 31% | Training loss: 0.6872830629765571
Epoch: 86 | Iteration number: [1440/4518] 31% | Training loss: 0.6872808106243611
Epoch: 86 | Iteration number: [1450/4518] 32% | Training loss: 0.6872773661284611
Epoch: 86 | Iteration number: [1460/4518] 32% | Training loss: 0.6872750446404496
Epoch: 86 | Iteration number: [1470/4518] 32% | Training loss: 0.6872747917564548
Epoch: 86 | Iteration number: [1480/4518] 32% | Training loss: 0.6872753909310779
Epoch: 86 | Iteration number: [1490/4518] 32% | Training loss: 0.6872731364013365
Epoch: 86 | Iteration number: [1500/4518] 33% | Training loss: 0.6872720041672389
Epoch: 86 | Iteration number: [1510/4518] 33% | Training loss: 0.6872709686787712
Epoch: 86 | Iteration number: [1520/4518] 33% | Training loss: 0.6872686135925745
Epoch: 86 | Iteration number: [1530/4518] 33% | Training loss: 0.6872674238837623
Epoch: 86 | Iteration number: [1540/4518] 34% | Training loss: 0.6872621819570467
Epoch: 86 | Iteration number: [1550/4518] 34% | Training loss: 0.6872599057997427
Epoch: 86 | Iteration number: [1560/4518] 34% | Training loss: 0.6872524540775862
Epoch: 86 | Iteration number: [1570/4518] 34% | Training loss: 0.6872367832691046
Epoch: 86 | Iteration number: [1580/4518] 34% | Training loss: 0.6872352108547959
Epoch: 86 | Iteration number: [1590/4518] 35% | Training loss: 0.6872329580333998
Epoch: 86 | Iteration number: [1600/4518] 35% | Training loss: 0.687237083055079
Epoch: 86 | Iteration number: [1610/4518] 35% | Training loss: 0.6872359245090011
Epoch: 86 | Iteration number: [1620/4518] 35% | Training loss: 0.6872368542132554
Epoch: 86 | Iteration number: [1630/4518] 36% | Training loss: 0.6872381129513488
Epoch: 86 | Iteration number: [1640/4518] 36% | Training loss: 0.6872417213349807
Epoch: 86 | Iteration number: [1650/4518] 36% | Training loss: 0.6872432547265833
Epoch: 86 | Iteration number: [1660/4518] 36% | Training loss: 0.6872389672391386
Epoch: 86 | Iteration number: [1670/4518] 36% | Training loss: 0.6872267608871003
Epoch: 86 | Iteration number: [1680/4518] 37% | Training loss: 0.6872206942666145
Epoch: 86 | Iteration number: [1690/4518] 37% | Training loss: 0.6872104171817824
Epoch: 86 | Iteration number: [1700/4518] 37% | Training loss: 0.687195649988511
Epoch: 86 | Iteration number: [1710/4518] 37% | Training loss: 0.6871980044228292
Epoch: 86 | Iteration number: [1720/4518] 38% | Training loss: 0.6871917410645374
Epoch: 86 | Iteration number: [1730/4518] 38% | Training loss: 0.6871948115053893
Epoch: 86 | Iteration number: [1740/4518] 38% | Training loss: 0.6871916331778998
Epoch: 86 | Iteration number: [1750/4518] 38% | Training loss: 0.6871846726621901
Epoch: 86 | Iteration number: [1760/4518] 38% | Training loss: 0.6871751095422289
Epoch: 86 | Iteration number: [1770/4518] 39% | Training loss: 0.6871737180456603
Epoch: 86 | Iteration number: [1780/4518] 39% | Training loss: 0.6871752048476358
Epoch: 86 | Iteration number: [1790/4518] 39% | Training loss: 0.6871728255762068
Epoch: 86 | Iteration number: [1800/4518] 39% | Training loss: 0.6871662307447858
Epoch: 86 | Iteration number: [1810/4518] 40% | Training loss: 0.6871588979966075
Epoch: 86 | Iteration number: [1820/4518] 40% | Training loss: 0.6871538315500532
Epoch: 86 | Iteration number: [1830/4518] 40% | Training loss: 0.6871565276482067
Epoch: 86 | Iteration number: [1840/4518] 40% | Training loss: 0.6871607470447603
Epoch: 86 | Iteration number: [1850/4518] 40% | Training loss: 0.687162956514874
Epoch: 86 | Iteration number: [1860/4518] 41% | Training loss: 0.6871598289538455
Epoch: 86 | Iteration number: [1870/4518] 41% | Training loss: 0.6871490793432143
Epoch: 86 | Iteration number: [1880/4518] 41% | Training loss: 0.6871447913190152
Epoch: 86 | Iteration number: [1890/4518] 41% | Training loss: 0.6871400388144943
Epoch: 86 | Iteration number: [1900/4518] 42% | Training loss: 0.6871385900597823
Epoch: 86 | Iteration number: [1910/4518] 42% | Training loss: 0.6871386252772745
Epoch: 86 | Iteration number: [1920/4518] 42% | Training loss: 0.6871398819610477
Epoch: 86 | Iteration number: [1930/4518] 42% | Training loss: 0.6871390858153605
Epoch: 86 | Iteration number: [1940/4518] 42% | Training loss: 0.6871379098019649
Epoch: 86 | Iteration number: [1950/4518] 43% | Training loss: 0.6871336534695748
Epoch: 86 | Iteration number: [1960/4518] 43% | Training loss: 0.6871341357121662
Epoch: 86 | Iteration number: [1970/4518] 43% | Training loss: 0.6871312530512738
Epoch: 86 | Iteration number: [1980/4518] 43% | Training loss: 0.6871292830416651
Epoch: 86 | Iteration number: [1990/4518] 44% | Training loss: 0.6871259530884537
Epoch: 86 | Iteration number: [2000/4518] 44% | Training loss: 0.6871241123080254
Epoch: 86 | Iteration number: [2010/4518] 44% | Training loss: 0.6871229213268603
Epoch: 86 | Iteration number: [2020/4518] 44% | Training loss: 0.6871281770786436
Epoch: 86 | Iteration number: [2030/4518] 44% | Training loss: 0.6871222933231316
Epoch: 86 | Iteration number: [2040/4518] 45% | Training loss: 0.6871188120222559
Epoch: 86 | Iteration number: [2050/4518] 45% | Training loss: 0.6871191291983535
Epoch: 86 | Iteration number: [2060/4518] 45% | Training loss: 0.6871147095289045
Epoch: 86 | Iteration number: [2070/4518] 45% | Training loss: 0.6871124781272262
Epoch: 86 | Iteration number: [2080/4518] 46% | Training loss: 0.6871113685747752
Epoch: 86 | Iteration number: [2090/4518] 46% | Training loss: 0.6871059483033047
Epoch: 86 | Iteration number: [2100/4518] 46% | Training loss: 0.6871053993985766
Epoch: 86 | Iteration number: [2110/4518] 46% | Training loss: 0.6871007190778922
Epoch: 86 | Iteration number: [2120/4518] 46% | Training loss: 0.6871037982544809
Epoch: 86 | Iteration number: [2130/4518] 47% | Training loss: 0.6871060301720257
Epoch: 86 | Iteration number: [2140/4518] 47% | Training loss: 0.6871010275923203
Epoch: 86 | Iteration number: [2150/4518] 47% | Training loss: 0.6870978441626526
Epoch: 86 | Iteration number: [2160/4518] 47% | Training loss: 0.6871028076995302
Epoch: 86 | Iteration number: [2170/4518] 48% | Training loss: 0.6870996049746939
Epoch: 86 | Iteration number: [2180/4518] 48% | Training loss: 0.6871009389741705
Epoch: 86 | Iteration number: [2190/4518] 48% | Training loss: 0.6871017291665622
Epoch: 86 | Iteration number: [2200/4518] 48% | Training loss: 0.687099959471009
Epoch: 86 | Iteration number: [2210/4518] 48% | Training loss: 0.6871052274337182
Epoch: 86 | Iteration number: [2220/4518] 49% | Training loss: 0.6871042041091232
Epoch: 86 | Iteration number: [2230/4518] 49% | Training loss: 0.6871020533578813
Epoch: 86 | Iteration number: [2240/4518] 49% | Training loss: 0.6871015900745988
Epoch: 86 | Iteration number: [2250/4518] 49% | Training loss: 0.6870987964206272
Epoch: 86 | Iteration number: [2260/4518] 50% | Training loss: 0.6870921538203163
Epoch: 86 | Iteration number: [2270/4518] 50% | Training loss: 0.687089527756107
Epoch: 86 | Iteration number: [2280/4518] 50% | Training loss: 0.6870921761843196
Epoch: 86 | Iteration number: [2290/4518] 50% | Training loss: 0.6870901785563174
Epoch: 86 | Iteration number: [2300/4518] 50% | Training loss: 0.6870882729343746
Epoch: 86 | Iteration number: [2310/4518] 51% | Training loss: 0.6870888426706389
Epoch: 86 | Iteration number: [2320/4518] 51% | Training loss: 0.6870883667006575
Epoch: 86 | Iteration number: [2330/4518] 51% | Training loss: 0.6870849156840165
Epoch: 86 | Iteration number: [2340/4518] 51% | Training loss: 0.6870832718845107
Epoch: 86 | Iteration number: [2350/4518] 52% | Training loss: 0.6870820757683287
Epoch: 86 | Iteration number: [2360/4518] 52% | Training loss: 0.6870812160483861
Epoch: 86 | Iteration number: [2370/4518] 52% | Training loss: 0.687075637387827
Epoch: 86 | Iteration number: [2380/4518] 52% | Training loss: 0.6870670454842703
Epoch: 86 | Iteration number: [2390/4518] 52% | Training loss: 0.6870642563787963
Epoch: 86 | Iteration number: [2400/4518] 53% | Training loss: 0.6870656712849935
Epoch: 86 | Iteration number: [2410/4518] 53% | Training loss: 0.6870612943320848
Epoch: 86 | Iteration number: [2420/4518] 53% | Training loss: 0.6870623065420419
Epoch: 86 | Iteration number: [2430/4518] 53% | Training loss: 0.6870630420529793
Epoch: 86 | Iteration number: [2440/4518] 54% | Training loss: 0.6870618037268764
Epoch: 86 | Iteration number: [2450/4518] 54% | Training loss: 0.6870607676068131
Epoch: 86 | Iteration number: [2460/4518] 54% | Training loss: 0.6870559026555317
Epoch: 86 | Iteration number: [2470/4518] 54% | Training loss: 0.6870602044016726
Epoch: 86 | Iteration number: [2480/4518] 54% | Training loss: 0.6870587574378136
Epoch: 86 | Iteration number: [2490/4518] 55% | Training loss: 0.6870561263647424
Epoch: 86 | Iteration number: [2500/4518] 55% | Training loss: 0.6870568974971771
Epoch: 86 | Iteration number: [2510/4518] 55% | Training loss: 0.6870574875656827
Epoch: 86 | Iteration number: [2520/4518] 55% | Training loss: 0.687058094309436
Epoch: 86 | Iteration number: [2530/4518] 55% | Training loss: 0.6870602054793844
Epoch: 86 | Iteration number: [2540/4518] 56% | Training loss: 0.6870588991351015
Epoch: 86 | Iteration number: [2550/4518] 56% | Training loss: 0.6870522857179828
Epoch: 86 | Iteration number: [2560/4518] 56% | Training loss: 0.6870538210729137
Epoch: 86 | Iteration number: [2570/4518] 56% | Training loss: 0.6870565284318961
Epoch: 86 | Iteration number: [2580/4518] 57% | Training loss: 0.687054633077725
Epoch: 86 | Iteration number: [2590/4518] 57% | Training loss: 0.6870559002902057
Epoch: 86 | Iteration number: [2600/4518] 57% | Training loss: 0.6870595380205374
Epoch: 86 | Iteration number: [2610/4518] 57% | Training loss: 0.6870585725910362
Epoch: 86 | Iteration number: [2620/4518] 57% | Training loss: 0.6870521965600153
Epoch: 86 | Iteration number: [2630/4518] 58% | Training loss: 0.6870487305374653
Epoch: 86 | Iteration number: [2640/4518] 58% | Training loss: 0.6870452452789654
Epoch: 86 | Iteration number: [2650/4518] 58% | Training loss: 0.6870503595415152
Epoch: 86 | Iteration number: [2660/4518] 58% | Training loss: 0.68704825126587
Epoch: 86 | Iteration number: [2670/4518] 59% | Training loss: 0.6870476127340552
Epoch: 86 | Iteration number: [2680/4518] 59% | Training loss: 0.6870488429247443
Epoch: 86 | Iteration number: [2690/4518] 59% | Training loss: 0.6870454861550526
Epoch: 86 | Iteration number: [2700/4518] 59% | Training loss: 0.6870487345368774
Epoch: 86 | Iteration number: [2710/4518] 59% | Training loss: 0.6870482197766814
Epoch: 86 | Iteration number: [2720/4518] 60% | Training loss: 0.6870447368963676
Epoch: 86 | Iteration number: [2730/4518] 60% | Training loss: 0.6870448110522804
Epoch: 86 | Iteration number: [2740/4518] 60% | Training loss: 0.6870422278007452
Epoch: 86 | Iteration number: [2750/4518] 60% | Training loss: 0.6870392919887196
Epoch: 86 | Iteration number: [2760/4518] 61% | Training loss: 0.6870333515215611
Epoch: 86 | Iteration number: [2770/4518] 61% | Training loss: 0.6870358257517487
Epoch: 86 | Iteration number: [2780/4518] 61% | Training loss: 0.6870400842145192
Epoch: 86 | Iteration number: [2790/4518] 61% | Training loss: 0.6870404725647314
Epoch: 86 | Iteration number: [2800/4518] 61% | Training loss: 0.6870389714198453
Epoch: 86 | Iteration number: [2810/4518] 62% | Training loss: 0.6870421507180373
Epoch: 86 | Iteration number: [2820/4518] 62% | Training loss: 0.6870406383529623
Epoch: 86 | Iteration number: [2830/4518] 62% | Training loss: 0.6870384397228699
Epoch: 86 | Iteration number: [2840/4518] 62% | Training loss: 0.6870387808118068
Epoch: 86 | Iteration number: [2850/4518] 63% | Training loss: 0.6870332414434667
Epoch: 86 | Iteration number: [2860/4518] 63% | Training loss: 0.6870274442059177
Epoch: 86 | Iteration number: [2870/4518] 63% | Training loss: 0.6870328905067378
Epoch: 86 | Iteration number: [2880/4518] 63% | Training loss: 0.6870336493063304
Epoch: 86 | Iteration number: [2890/4518] 63% | Training loss: 0.6870357198286221
Epoch: 86 | Iteration number: [2900/4518] 64% | Training loss: 0.6870311134848102
Epoch: 86 | Iteration number: [2910/4518] 64% | Training loss: 0.6870317900918194
Epoch: 86 | Iteration number: [2920/4518] 64% | Training loss: 0.687034200274781
Epoch: 86 | Iteration number: [2930/4518] 64% | Training loss: 0.6870321941863962
Epoch: 86 | Iteration number: [2940/4518] 65% | Training loss: 0.6870299523785001
Epoch: 86 | Iteration number: [2950/4518] 65% | Training loss: 0.6870288681377799
Epoch: 86 | Iteration number: [2960/4518] 65% | Training loss: 0.6870198744172985
Epoch: 86 | Iteration number: [2970/4518] 65% | Training loss: 0.6870194255904316
Epoch: 86 | Iteration number: [2980/4518] 65% | Training loss: 0.687015836790904
Epoch: 86 | Iteration number: [2990/4518] 66% | Training loss: 0.6870180876956735
Epoch: 86 | Iteration number: [3000/4518] 66% | Training loss: 0.6870167446335157
Epoch: 86 | Iteration number: [3010/4518] 66% | Training loss: 0.6870184527877161
Epoch: 86 | Iteration number: [3020/4518] 66% | Training loss: 0.6870145898188976
Epoch: 86 | Iteration number: [3030/4518] 67% | Training loss: 0.6870125472545624
Epoch: 86 | Iteration number: [3040/4518] 67% | Training loss: 0.6870117520227244
Epoch: 86 | Iteration number: [3050/4518] 67% | Training loss: 0.6870062784288751
Epoch: 86 | Iteration number: [3060/4518] 67% | Training loss: 0.6870053760561289
Epoch: 86 | Iteration number: [3070/4518] 67% | Training loss: 0.6870033178927456
Epoch: 86 | Iteration number: [3080/4518] 68% | Training loss: 0.6869982034742058
Epoch: 86 | Iteration number: [3090/4518] 68% | Training loss: 0.6869970444143783
Epoch: 86 | Iteration number: [3100/4518] 68% | Training loss: 0.6869975802398497
Epoch: 86 | Iteration number: [3110/4518] 68% | Training loss: 0.6869945363408116
Epoch: 86 | Iteration number: [3120/4518] 69% | Training loss: 0.6869962107676726
Epoch: 86 | Iteration number: [3130/4518] 69% | Training loss: 0.6869969008829647
Epoch: 86 | Iteration number: [3140/4518] 69% | Training loss: 0.6869972916545382
Epoch: 86 | Iteration number: [3150/4518] 69% | Training loss: 0.687001950021774
Epoch: 86 | Iteration number: [3160/4518] 69% | Training loss: 0.6870040564974652
Epoch: 86 | Iteration number: [3170/4518] 70% | Training loss: 0.6870021074916286
Epoch: 86 | Iteration number: [3180/4518] 70% | Training loss: 0.6869999177238476
Epoch: 86 | Iteration number: [3190/4518] 70% | Training loss: 0.6870000465536567
Epoch: 86 | Iteration number: [3200/4518] 70% | Training loss: 0.6869997850805521
Epoch: 86 | Iteration number: [3210/4518] 71% | Training loss: 0.6869970878893713
Epoch: 86 | Iteration number: [3220/4518] 71% | Training loss: 0.6869983261601526
Epoch: 86 | Iteration number: [3230/4518] 71% | Training loss: 0.686997258847712
Epoch: 86 | Iteration number: [3240/4518] 71% | Training loss: 0.686995222778232
Epoch: 86 | Iteration number: [3250/4518] 71% | Training loss: 0.6869939602888547
Epoch: 86 | Iteration number: [3260/4518] 72% | Training loss: 0.6869934250423513
Epoch: 86 | Iteration number: [3270/4518] 72% | Training loss: 0.6869908275407388
Epoch: 86 | Iteration number: [3280/4518] 72% | Training loss: 0.6869895259963303
Epoch: 86 | Iteration number: [3290/4518] 72% | Training loss: 0.6869920501593036
Epoch: 86 | Iteration number: [3300/4518] 73% | Training loss: 0.6869932330196554
Epoch: 86 | Iteration number: [3310/4518] 73% | Training loss: 0.6869902630046776
Epoch: 86 | Iteration number: [3320/4518] 73% | Training loss: 0.6869872986372695
Epoch: 86 | Iteration number: [3330/4518] 73% | Training loss: 0.6869831749447831
Epoch: 86 | Iteration number: [3340/4518] 73% | Training loss: 0.6869796723662737
Epoch: 86 | Iteration number: [3350/4518] 74% | Training loss: 0.6869806822378244
Epoch: 86 | Iteration number: [3360/4518] 74% | Training loss: 0.6869799904347885
Epoch: 86 | Iteration number: [3370/4518] 74% | Training loss: 0.6869839625471778
Epoch: 86 | Iteration number: [3380/4518] 74% | Training loss: 0.6869835460856116
Epoch: 86 | Iteration number: [3390/4518] 75% | Training loss: 0.6869829427176168
Epoch: 86 | Iteration number: [3400/4518] 75% | Training loss: 0.6869838882719769
Epoch: 86 | Iteration number: [3410/4518] 75% | Training loss: 0.6869833751857456
Epoch: 86 | Iteration number: [3420/4518] 75% | Training loss: 0.6869792741990229
Epoch: 86 | Iteration number: [3430/4518] 75% | Training loss: 0.6869817959150142
Epoch: 86 | Iteration number: [3440/4518] 76% | Training loss: 0.6869817854533362
Epoch: 86 | Iteration number: [3450/4518] 76% | Training loss: 0.6869789768129155
Epoch: 86 | Iteration number: [3460/4518] 76% | Training loss: 0.6869775759691448
Epoch: 86 | Iteration number: [3470/4518] 76% | Training loss: 0.6869769048106773
Epoch: 86 | Iteration number: [3480/4518] 77% | Training loss: 0.6869774339870475
Epoch: 86 | Iteration number: [3490/4518] 77% | Training loss: 0.6869777762104242
Epoch: 86 | Iteration number: [3500/4518] 77% | Training loss: 0.6869748357023512
Epoch: 86 | Iteration number: [3510/4518] 77% | Training loss: 0.686973828332037
Epoch: 86 | Iteration number: [3520/4518] 77% | Training loss: 0.6869734093377536
Epoch: 86 | Iteration number: [3530/4518] 78% | Training loss: 0.6869715817082706
Epoch: 86 | Iteration number: [3540/4518] 78% | Training loss: 0.6869734782283589
Epoch: 86 | Iteration number: [3550/4518] 78% | Training loss: 0.6869725339177629
Epoch: 86 | Iteration number: [3560/4518] 78% | Training loss: 0.686971949827805
Epoch: 86 | Iteration number: [3570/4518] 79% | Training loss: 0.686970752310686
Epoch: 86 | Iteration number: [3580/4518] 79% | Training loss: 0.6869714122411259
Epoch: 86 | Iteration number: [3590/4518] 79% | Training loss: 0.686970802352953
Epoch: 86 | Iteration number: [3600/4518] 79% | Training loss: 0.6869694933626387
Epoch: 86 | Iteration number: [3610/4518] 79% | Training loss: 0.686969614656348
Epoch: 86 | Iteration number: [3620/4518] 80% | Training loss: 0.6869696064054637
Epoch: 86 | Iteration number: [3630/4518] 80% | Training loss: 0.6869689232061718
Epoch: 86 | Iteration number: [3640/4518] 80% | Training loss: 0.6869676376109595
Epoch: 86 | Iteration number: [3650/4518] 80% | Training loss: 0.6869696319429842
Epoch: 86 | Iteration number: [3660/4518] 81% | Training loss: 0.6869681573304973
Epoch: 86 | Iteration number: [3670/4518] 81% | Training loss: 0.686965169406392
Epoch: 86 | Iteration number: [3680/4518] 81% | Training loss: 0.6869630288818608
Epoch: 86 | Iteration number: [3690/4518] 81% | Training loss: 0.6869658140147604
Epoch: 86 | Iteration number: [3700/4518] 81% | Training loss: 0.6869625759446943
Epoch: 86 | Iteration number: [3710/4518] 82% | Training loss: 0.6869601323598158
Epoch: 86 | Iteration number: [3720/4518] 82% | Training loss: 0.6869603616736268
Epoch: 86 | Iteration number: [3730/4518] 82% | Training loss: 0.6869627248505804
Epoch: 86 | Iteration number: [3740/4518] 82% | Training loss: 0.6869608285592839
Epoch: 86 | Iteration number: [3750/4518] 83% | Training loss: 0.6869620297273
Epoch: 86 | Iteration number: [3760/4518] 83% | Training loss: 0.6869606139812063
Epoch: 86 | Iteration number: [3770/4518] 83% | Training loss: 0.6869619501048121
Epoch: 86 | Iteration number: [3780/4518] 83% | Training loss: 0.6869602065395426
Epoch: 86 | Iteration number: [3790/4518] 83% | Training loss: 0.686963453503586
Epoch: 86 | Iteration number: [3800/4518] 84% | Training loss: 0.6869603791362361
Epoch: 86 | Iteration number: [3810/4518] 84% | Training loss: 0.6869579555481438
Epoch: 86 | Iteration number: [3820/4518] 84% | Training loss: 0.6869599551898646
Epoch: 86 | Iteration number: [3830/4518] 84% | Training loss: 0.686962803132229
Epoch: 86 | Iteration number: [3840/4518] 84% | Training loss: 0.6869644076408198
Epoch: 86 | Iteration number: [3850/4518] 85% | Training loss: 0.686963735307966
Epoch: 86 | Iteration number: [3860/4518] 85% | Training loss: 0.6869621003230001
Epoch: 86 | Iteration number: [3870/4518] 85% | Training loss: 0.6869613112251272
Epoch: 86 | Iteration number: [3880/4518] 85% | Training loss: 0.6869618820775415
Epoch: 86 | Iteration number: [3890/4518] 86% | Training loss: 0.686959927446738
Epoch: 86 | Iteration number: [3900/4518] 86% | Training loss: 0.6869579535264235
Epoch: 86 | Iteration number: [3910/4518] 86% | Training loss: 0.6869575263289235
Epoch: 86 | Iteration number: [3920/4518] 86% | Training loss: 0.6869560440432052
Epoch: 86 | Iteration number: [3930/4518] 86% | Training loss: 0.6869545277596734
Epoch: 86 | Iteration number: [3940/4518] 87% | Training loss: 0.6869569340030554
Epoch: 86 | Iteration number: [3950/4518] 87% | Training loss: 0.6869530348989028
Epoch: 86 | Iteration number: [3960/4518] 87% | Training loss: 0.6869549715609261
Epoch: 86 | Iteration number: [3970/4518] 87% | Training loss: 0.6869553558321984
Epoch: 86 | Iteration number: [3980/4518] 88% | Training loss: 0.6869545965637993
Epoch: 86 | Iteration number: [3990/4518] 88% | Training loss: 0.686953633246864
Epoch: 86 | Iteration number: [4000/4518] 88% | Training loss: 0.6869514944851398
Epoch: 86 | Iteration number: [4010/4518] 88% | Training loss: 0.6869516412813468
Epoch: 86 | Iteration number: [4020/4518] 88% | Training loss: 0.6869527669540092
Epoch: 86 | Iteration number: [4030/4518] 89% | Training loss: 0.6869524995091535
Epoch: 86 | Iteration number: [4040/4518] 89% | Training loss: 0.6869506466801804
Epoch: 86 | Iteration number: [4050/4518] 89% | Training loss: 0.6869501858876075
Epoch: 86 | Iteration number: [4060/4518] 89% | Training loss: 0.6869504923156917
Epoch: 86 | Iteration number: [4070/4518] 90% | Training loss: 0.6869516400505928
Epoch: 86 | Iteration number: [4080/4518] 90% | Training loss: 0.6869525027625701
Epoch: 86 | Iteration number: [4090/4518] 90% | Training loss: 0.6869515151878441
Epoch: 86 | Iteration number: [4100/4518] 90% | Training loss: 0.6869499326915276
Epoch: 86 | Iteration number: [4110/4518] 90% | Training loss: 0.686946855075748
Epoch: 86 | Iteration number: [4120/4518] 91% | Training loss: 0.6869462364651624
Epoch: 86 | Iteration number: [4130/4518] 91% | Training loss: 0.6869461368417624
Epoch: 86 | Iteration number: [4140/4518] 91% | Training loss: 0.6869442444060736
Epoch: 86 | Iteration number: [4150/4518] 91% | Training loss: 0.6869422540319972
Epoch: 86 | Iteration number: [4160/4518] 92% | Training loss: 0.6869425890823969
Epoch: 86 | Iteration number: [4170/4518] 92% | Training loss: 0.6869399852175221
Epoch: 86 | Iteration number: [4180/4518] 92% | Training loss: 0.6869371275297192
Epoch: 86 | Iteration number: [4190/4518] 92% | Training loss: 0.6869357871411809
Epoch: 86 | Iteration number: [4200/4518] 92% | Training loss: 0.6869364708662034
Epoch: 86 | Iteration number: [4210/4518] 93% | Training loss: 0.6869375862588225
Epoch: 86 | Iteration number: [4220/4518] 93% | Training loss: 0.6869404327954162
Epoch: 86 | Iteration number: [4230/4518] 93% | Training loss: 0.6869396629485678
Epoch: 86 | Iteration number: [4240/4518] 93% | Training loss: 0.6869397588777092
Epoch: 86 | Iteration number: [4250/4518] 94% | Training loss: 0.6869358017304364
Epoch: 86 | Iteration number: [4260/4518] 94% | Training loss: 0.6869352573380224
Epoch: 86 | Iteration number: [4270/4518] 94% | Training loss: 0.6869337560700588
Epoch: 86 | Iteration number: [4280/4518] 94% | Training loss: 0.6869335843720169
Epoch: 86 | Iteration number: [4290/4518] 94% | Training loss: 0.6869349117879268
Epoch: 86 | Iteration number: [4300/4518] 95% | Training loss: 0.6869345000732777
Epoch: 86 | Iteration number: [4310/4518] 95% | Training loss: 0.6869318644436219
Epoch: 86 | Iteration number: [4320/4518] 95% | Training loss: 0.686927192768565
Epoch: 86 | Iteration number: [4330/4518] 95% | Training loss: 0.6869263662752323
Epoch: 86 | Iteration number: [4340/4518] 96% | Training loss: 0.686927395029002
Epoch: 86 | Iteration number: [4350/4518] 96% | Training loss: 0.686927370614019
Epoch: 86 | Iteration number: [4360/4518] 96% | Training loss: 0.6869254878354729
Epoch: 86 | Iteration number: [4370/4518] 96% | Training loss: 0.6869271360491178
Epoch: 86 | Iteration number: [4380/4518] 96% | Training loss: 0.6869280039039377
Epoch: 86 | Iteration number: [4390/4518] 97% | Training loss: 0.6869294217615844
Epoch: 86 | Iteration number: [4400/4518] 97% | Training loss: 0.6869285743073984
Epoch: 86 | Iteration number: [4410/4518] 97% | Training loss: 0.6869274036008485
Epoch: 86 | Iteration number: [4420/4518] 97% | Training loss: 0.6869267689965969
Epoch: 86 | Iteration number: [4430/4518] 98% | Training loss: 0.6869258670317131
Epoch: 86 | Iteration number: [4440/4518] 98% | Training loss: 0.6869248785279892
Epoch: 86 | Iteration number: [4450/4518] 98% | Training loss: 0.6869275202108233
Epoch: 86 | Iteration number: [4460/4518] 98% | Training loss: 0.6869250293670749
Epoch: 86 | Iteration number: [4470/4518] 98% | Training loss: 0.6869202496621433
Epoch: 86 | Iteration number: [4480/4518] 99% | Training loss: 0.6869223595064665
Epoch: 86 | Iteration number: [4490/4518] 99% | Training loss: 0.6869230659873554
Epoch: 86 | Iteration number: [4500/4518] 99% | Training loss: 0.6869213703605864
Epoch: 86 | Iteration number: [4510/4518] 99% | Training loss: 0.6869215812889277

 End of epoch: 86 | Train Loss: 0.6867683739090135 | Training Time: 641 

 End of epoch: 86 | Eval Loss: 0.6899687441027894 | Evaluating Time: 17 
Epoch: 87 | Iteration number: [10/4518] 0% | Training loss: 0.7551545083522797
Epoch: 87 | Iteration number: [20/4518] 0% | Training loss: 0.7209295988082886
Epoch: 87 | Iteration number: [30/4518] 0% | Training loss: 0.7095712999502818
Epoch: 87 | Iteration number: [40/4518] 0% | Training loss: 0.7037321761250496
Epoch: 87 | Iteration number: [50/4518] 1% | Training loss: 0.700319983959198
Epoch: 87 | Iteration number: [60/4518] 1% | Training loss: 0.6981259057919185
Epoch: 87 | Iteration number: [70/4518] 1% | Training loss: 0.6965962486607687
Epoch: 87 | Iteration number: [80/4518] 1% | Training loss: 0.6955211862921715
Epoch: 87 | Iteration number: [90/4518] 1% | Training loss: 0.6945669697390662
Epoch: 87 | Iteration number: [100/4518] 2% | Training loss: 0.6937557202577591
Epoch: 87 | Iteration number: [110/4518] 2% | Training loss: 0.6930772645906969
Epoch: 87 | Iteration number: [120/4518] 2% | Training loss: 0.6925854921340943
Epoch: 87 | Iteration number: [130/4518] 2% | Training loss: 0.6920265972614288
Epoch: 87 | Iteration number: [140/4518] 3% | Training loss: 0.691595361488206
Epoch: 87 | Iteration number: [150/4518] 3% | Training loss: 0.6913000698884328
Epoch: 87 | Iteration number: [160/4518] 3% | Training loss: 0.6910158008337021
Epoch: 87 | Iteration number: [170/4518] 3% | Training loss: 0.6907813324647791
Epoch: 87 | Iteration number: [180/4518] 3% | Training loss: 0.6905868997176489
Epoch: 87 | Iteration number: [190/4518] 4% | Training loss: 0.690377266156046
Epoch: 87 | Iteration number: [200/4518] 4% | Training loss: 0.6901539659500122
Epoch: 87 | Iteration number: [210/4518] 4% | Training loss: 0.6900006473064423
Epoch: 87 | Iteration number: [220/4518] 4% | Training loss: 0.6898876452987844
Epoch: 87 | Iteration number: [230/4518] 5% | Training loss: 0.6897582893786223
Epoch: 87 | Iteration number: [240/4518] 5% | Training loss: 0.6895667381584645
Epoch: 87 | Iteration number: [250/4518] 5% | Training loss: 0.689504693031311
Epoch: 87 | Iteration number: [260/4518] 5% | Training loss: 0.6893615252696551
Epoch: 87 | Iteration number: [270/4518] 5% | Training loss: 0.6892325535968498
Epoch: 87 | Iteration number: [280/4518] 6% | Training loss: 0.6892107231276375
Epoch: 87 | Iteration number: [290/4518] 6% | Training loss: 0.6891550614916045
Epoch: 87 | Iteration number: [300/4518] 6% | Training loss: 0.6890866976976394
Epoch: 87 | Iteration number: [310/4518] 6% | Training loss: 0.6890014254277752
Epoch: 87 | Iteration number: [320/4518] 7% | Training loss: 0.6889270208775997
Epoch: 87 | Iteration number: [330/4518] 7% | Training loss: 0.6888535649487466
Epoch: 87 | Iteration number: [340/4518] 7% | Training loss: 0.6888157842790379
Epoch: 87 | Iteration number: [350/4518] 7% | Training loss: 0.6887627853666033
Epoch: 87 | Iteration number: [360/4518] 7% | Training loss: 0.6886946250995
Epoch: 87 | Iteration number: [370/4518] 8% | Training loss: 0.6886309979735195
Epoch: 87 | Iteration number: [380/4518] 8% | Training loss: 0.6885842008026023
Epoch: 87 | Iteration number: [390/4518] 8% | Training loss: 0.6885415793993535
Epoch: 87 | Iteration number: [400/4518] 8% | Training loss: 0.6884646002948284
Epoch: 87 | Iteration number: [410/4518] 9% | Training loss: 0.6884320462622293
Epoch: 87 | Iteration number: [420/4518] 9% | Training loss: 0.6884014160860152
Epoch: 87 | Iteration number: [430/4518] 9% | Training loss: 0.6883505850337273
Epoch: 87 | Iteration number: [440/4518] 9% | Training loss: 0.6883238154378805
Epoch: 87 | Iteration number: [450/4518] 9% | Training loss: 0.6882819859186808
Epoch: 87 | Iteration number: [460/4518] 10% | Training loss: 0.6882490808549134
Epoch: 87 | Iteration number: [470/4518] 10% | Training loss: 0.6882261798736897
Epoch: 87 | Iteration number: [480/4518] 10% | Training loss: 0.6881853205462297
Epoch: 87 | Iteration number: [490/4518] 10% | Training loss: 0.6881340720215622
Epoch: 87 | Iteration number: [500/4518] 11% | Training loss: 0.688095852971077
Epoch: 87 | Iteration number: [510/4518] 11% | Training loss: 0.6880542007147097
Epoch: 87 | Iteration number: [520/4518] 11% | Training loss: 0.6880183344850174
Epoch: 87 | Iteration number: [530/4518] 11% | Training loss: 0.6880017784406554
Epoch: 87 | Iteration number: [540/4518] 11% | Training loss: 0.6879799754531295
Epoch: 87 | Iteration number: [550/4518] 12% | Training loss: 0.6879671102220362
Epoch: 87 | Iteration number: [560/4518] 12% | Training loss: 0.6879445798695087
Epoch: 87 | Iteration number: [570/4518] 12% | Training loss: 0.6879222551981609
Epoch: 87 | Iteration number: [580/4518] 12% | Training loss: 0.6879086248833558
Epoch: 87 | Iteration number: [590/4518] 13% | Training loss: 0.6878798559560614
Epoch: 87 | Iteration number: [600/4518] 13% | Training loss: 0.6878646359841029
Epoch: 87 | Iteration number: [610/4518] 13% | Training loss: 0.6878475657252014
Epoch: 87 | Iteration number: [620/4518] 13% | Training loss: 0.6878245435414776
Epoch: 87 | Iteration number: [630/4518] 13% | Training loss: 0.6878114821418884
Epoch: 87 | Iteration number: [640/4518] 14% | Training loss: 0.6878210064023733
Epoch: 87 | Iteration number: [650/4518] 14% | Training loss: 0.6878146089040316
Epoch: 87 | Iteration number: [660/4518] 14% | Training loss: 0.687809487454819
Epoch: 87 | Iteration number: [670/4518] 14% | Training loss: 0.6877839907781401
Epoch: 87 | Iteration number: [680/4518] 15% | Training loss: 0.687756440306411
Epoch: 87 | Iteration number: [690/4518] 15% | Training loss: 0.68772762167281
Epoch: 87 | Iteration number: [700/4518] 15% | Training loss: 0.6877404934167862
Epoch: 87 | Iteration number: [710/4518] 15% | Training loss: 0.6877091409454883
Epoch: 87 | Iteration number: [720/4518] 15% | Training loss: 0.6877144415345456
Epoch: 87 | Iteration number: [730/4518] 16% | Training loss: 0.6877073859515256
Epoch: 87 | Iteration number: [740/4518] 16% | Training loss: 0.6876835097332259
Epoch: 87 | Iteration number: [750/4518] 16% | Training loss: 0.6876681037743886
Epoch: 87 | Iteration number: [760/4518] 16% | Training loss: 0.6876610494757953
Epoch: 87 | Iteration number: [770/4518] 17% | Training loss: 0.6876380379323835
Epoch: 87 | Iteration number: [780/4518] 17% | Training loss: 0.6876292543533521
Epoch: 87 | Iteration number: [790/4518] 17% | Training loss: 0.6875898320463639
Epoch: 87 | Iteration number: [800/4518] 17% | Training loss: 0.6875830667465925
Epoch: 87 | Iteration number: [810/4518] 17% | Training loss: 0.6875735722942117
Epoch: 87 | Iteration number: [820/4518] 18% | Training loss: 0.6875756364770051
Epoch: 87 | Iteration number: [830/4518] 18% | Training loss: 0.6875723891947643
Epoch: 87 | Iteration number: [840/4518] 18% | Training loss: 0.6875659752459753
Epoch: 87 | Iteration number: [850/4518] 18% | Training loss: 0.6875571109968073
Epoch: 87 | Iteration number: [860/4518] 19% | Training loss: 0.6875630917937257
Epoch: 87 | Iteration number: [870/4518] 19% | Training loss: 0.6875615363833548
Epoch: 87 | Iteration number: [880/4518] 19% | Training loss: 0.6875539736314253
Epoch: 87 | Iteration number: [890/4518] 19% | Training loss: 0.687560434622711
Epoch: 87 | Iteration number: [900/4518] 19% | Training loss: 0.6875462851259444
Epoch: 87 | Iteration number: [910/4518] 20% | Training loss: 0.6875296260629381
Epoch: 87 | Iteration number: [920/4518] 20% | Training loss: 0.6875121312944785
Epoch: 87 | Iteration number: [930/4518] 20% | Training loss: 0.6874961774195394
Epoch: 87 | Iteration number: [940/4518] 20% | Training loss: 0.6874853441055785
Epoch: 87 | Iteration number: [950/4518] 21% | Training loss: 0.6874900581962184
Epoch: 87 | Iteration number: [960/4518] 21% | Training loss: 0.6874753057335814
Epoch: 87 | Iteration number: [970/4518] 21% | Training loss: 0.6874641286958124
Epoch: 87 | Iteration number: [980/4518] 21% | Training loss: 0.6874666322858967
Epoch: 87 | Iteration number: [990/4518] 21% | Training loss: 0.6874540607134502
Epoch: 87 | Iteration number: [1000/4518] 22% | Training loss: 0.6874545353651047
Epoch: 87 | Iteration number: [1010/4518] 22% | Training loss: 0.687452366859606
Epoch: 87 | Iteration number: [1020/4518] 22% | Training loss: 0.6874371035426271
Epoch: 87 | Iteration number: [1030/4518] 22% | Training loss: 0.6874253676354306
Epoch: 87 | Iteration number: [1040/4518] 23% | Training loss: 0.687421763745638
Epoch: 87 | Iteration number: [1050/4518] 23% | Training loss: 0.68741195724124
Epoch: 87 | Iteration number: [1060/4518] 23% | Training loss: 0.6873992177675355
Epoch: 87 | Iteration number: [1070/4518] 23% | Training loss: 0.6873915793739747
Epoch: 87 | Iteration number: [1080/4518] 23% | Training loss: 0.6873911315092334
Epoch: 87 | Iteration number: [1090/4518] 24% | Training loss: 0.687379091595291
Epoch: 87 | Iteration number: [1100/4518] 24% | Training loss: 0.6873531818389893
Epoch: 87 | Iteration number: [1110/4518] 24% | Training loss: 0.6873478493174991
Epoch: 87 | Iteration number: [1120/4518] 24% | Training loss: 0.6873507983450379
Epoch: 87 | Iteration number: [1130/4518] 25% | Training loss: 0.687340661909728
Epoch: 87 | Iteration number: [1140/4518] 25% | Training loss: 0.6873319388481609
Epoch: 87 | Iteration number: [1150/4518] 25% | Training loss: 0.6873301247928454
Epoch: 87 | Iteration number: [1160/4518] 25% | Training loss: 0.687333366326217
Epoch: 87 | Iteration number: [1170/4518] 25% | Training loss: 0.6873232334088056
Epoch: 87 | Iteration number: [1180/4518] 26% | Training loss: 0.6873143374919891
Epoch: 87 | Iteration number: [1190/4518] 26% | Training loss: 0.687305361733717
Epoch: 87 | Iteration number: [1200/4518] 26% | Training loss: 0.6873061300814152
Epoch: 87 | Iteration number: [1210/4518] 26% | Training loss: 0.6872957527144882
Epoch: 87 | Iteration number: [1220/4518] 27% | Training loss: 0.6872925829203402
Epoch: 87 | Iteration number: [1230/4518] 27% | Training loss: 0.6872860531012217
Epoch: 87 | Iteration number: [1240/4518] 27% | Training loss: 0.6872865563438785
Epoch: 87 | Iteration number: [1250/4518] 27% | Training loss: 0.6872783390522004
Epoch: 87 | Iteration number: [1260/4518] 27% | Training loss: 0.6872777495592359
Epoch: 87 | Iteration number: [1270/4518] 28% | Training loss: 0.6872746487771432
Epoch: 87 | Iteration number: [1280/4518] 28% | Training loss: 0.6872636218089611
Epoch: 87 | Iteration number: [1290/4518] 28% | Training loss: 0.6872643863969995
Epoch: 87 | Iteration number: [1300/4518] 28% | Training loss: 0.687262814274201
Epoch: 87 | Iteration number: [1310/4518] 28% | Training loss: 0.6872672918188663
Epoch: 87 | Iteration number: [1320/4518] 29% | Training loss: 0.6872703989798372
Epoch: 87 | Iteration number: [1330/4518] 29% | Training loss: 0.687271550499407
Epoch: 87 | Iteration number: [1340/4518] 29% | Training loss: 0.6872752830163756
Epoch: 87 | Iteration number: [1350/4518] 29% | Training loss: 0.6872688346438938
Epoch: 87 | Iteration number: [1360/4518] 30% | Training loss: 0.6872615925091154
Epoch: 87 | Iteration number: [1370/4518] 30% | Training loss: 0.6872545297563512
Epoch: 87 | Iteration number: [1380/4518] 30% | Training loss: 0.6872561193030814
Epoch: 87 | Iteration number: [1390/4518] 30% | Training loss: 0.6872512853831696
Epoch: 87 | Iteration number: [1400/4518] 30% | Training loss: 0.6872440955042839
Epoch: 87 | Iteration number: [1410/4518] 31% | Training loss: 0.6872369711703442
Epoch: 87 | Iteration number: [1420/4518] 31% | Training loss: 0.6872281343584329
Epoch: 87 | Iteration number: [1430/4518] 31% | Training loss: 0.687230767903628
Epoch: 87 | Iteration number: [1440/4518] 31% | Training loss: 0.6872348166174359
Epoch: 87 | Iteration number: [1450/4518] 32% | Training loss: 0.6872345801057487
Epoch: 87 | Iteration number: [1460/4518] 32% | Training loss: 0.6872202699723309
Epoch: 87 | Iteration number: [1470/4518] 32% | Training loss: 0.6872202626296452
Epoch: 87 | Iteration number: [1480/4518] 32% | Training loss: 0.6872128211968654
Epoch: 87 | Iteration number: [1490/4518] 32% | Training loss: 0.6872130823215382
Epoch: 87 | Iteration number: [1500/4518] 33% | Training loss: 0.6872064747810364
Epoch: 87 | Iteration number: [1510/4518] 33% | Training loss: 0.6872076865458331
Epoch: 87 | Iteration number: [1520/4518] 33% | Training loss: 0.6872033017246346
Epoch: 87 | Iteration number: [1530/4518] 33% | Training loss: 0.6871949297150756
Epoch: 87 | Iteration number: [1540/4518] 34% | Training loss: 0.6871911849681434
Epoch: 87 | Iteration number: [1550/4518] 34% | Training loss: 0.6871957887757209
Epoch: 87 | Iteration number: [1560/4518] 34% | Training loss: 0.6871950402091711
Epoch: 87 | Iteration number: [1570/4518] 34% | Training loss: 0.6871942867898637
Epoch: 87 | Iteration number: [1580/4518] 34% | Training loss: 0.6871880009204526
Epoch: 87 | Iteration number: [1590/4518] 35% | Training loss: 0.6871848557730141
Epoch: 87 | Iteration number: [1600/4518] 35% | Training loss: 0.6871850510686636
Epoch: 87 | Iteration number: [1610/4518] 35% | Training loss: 0.687180572377969
Epoch: 87 | Iteration number: [1620/4518] 35% | Training loss: 0.6871795849299726
Epoch: 87 | Iteration number: [1630/4518] 36% | Training loss: 0.6871824293780181
Epoch: 87 | Iteration number: [1640/4518] 36% | Training loss: 0.6871685864358413
Epoch: 87 | Iteration number: [1650/4518] 36% | Training loss: 0.6871658419479023
Epoch: 87 | Iteration number: [1660/4518] 36% | Training loss: 0.6871666870921491
Epoch: 87 | Iteration number: [1670/4518] 36% | Training loss: 0.6871627761218362
Epoch: 87 | Iteration number: [1680/4518] 37% | Training loss: 0.6871641998489698
Epoch: 87 | Iteration number: [1690/4518] 37% | Training loss: 0.6871698499431271
Epoch: 87 | Iteration number: [1700/4518] 37% | Training loss: 0.6871713494553285
Epoch: 87 | Iteration number: [1710/4518] 37% | Training loss: 0.6871693557465983
Epoch: 87 | Iteration number: [1720/4518] 38% | Training loss: 0.6871639581960302
Epoch: 87 | Iteration number: [1730/4518] 38% | Training loss: 0.6871590397950542
Epoch: 87 | Iteration number: [1740/4518] 38% | Training loss: 0.6871604059619465
Epoch: 87 | Iteration number: [1750/4518] 38% | Training loss: 0.6871654016290393
Epoch: 87 | Iteration number: [1760/4518] 38% | Training loss: 0.6871651011773131
Epoch: 87 | Iteration number: [1770/4518] 39% | Training loss: 0.6871600645410139
Epoch: 87 | Iteration number: [1780/4518] 39% | Training loss: 0.6871576278732064
Epoch: 87 | Iteration number: [1790/4518] 39% | Training loss: 0.6871543556618291
Epoch: 87 | Iteration number: [1800/4518] 39% | Training loss: 0.6871485145886739
Epoch: 87 | Iteration number: [1810/4518] 40% | Training loss: 0.6871498723385743
Epoch: 87 | Iteration number: [1820/4518] 40% | Training loss: 0.6871554862339418
Epoch: 87 | Iteration number: [1830/4518] 40% | Training loss: 0.6871495550773182
Epoch: 87 | Iteration number: [1840/4518] 40% | Training loss: 0.6871499811501607
Epoch: 87 | Iteration number: [1850/4518] 40% | Training loss: 0.6871540039938849
Epoch: 87 | Iteration number: [1860/4518] 41% | Training loss: 0.6871543777886258
Epoch: 87 | Iteration number: [1870/4518] 41% | Training loss: 0.6871557730404451
Epoch: 87 | Iteration number: [1880/4518] 41% | Training loss: 0.6871548303264252
Epoch: 87 | Iteration number: [1890/4518] 41% | Training loss: 0.6871478453515067
Epoch: 87 | Iteration number: [1900/4518] 42% | Training loss: 0.6871490596783788
Epoch: 87 | Iteration number: [1910/4518] 42% | Training loss: 0.687146836051142
Epoch: 87 | Iteration number: [1920/4518] 42% | Training loss: 0.6871373469630877
Epoch: 87 | Iteration number: [1930/4518] 42% | Training loss: 0.6871364014445192
Epoch: 87 | Iteration number: [1940/4518] 42% | Training loss: 0.6871277779647984
Epoch: 87 | Iteration number: [1950/4518] 43% | Training loss: 0.687128601532716
Epoch: 87 | Iteration number: [1960/4518] 43% | Training loss: 0.6871246726233132
Epoch: 87 | Iteration number: [1970/4518] 43% | Training loss: 0.6871246254686172
Epoch: 87 | Iteration number: [1980/4518] 43% | Training loss: 0.6871206221556423
Epoch: 87 | Iteration number: [1990/4518] 44% | Training loss: 0.6871140985333141
Epoch: 87 | Iteration number: [2000/4518] 44% | Training loss: 0.687111196488142
Epoch: 87 | Iteration number: [2010/4518] 44% | Training loss: 0.6871171139365998
Epoch: 87 | Iteration number: [2020/4518] 44% | Training loss: 0.687115807609983
Epoch: 87 | Iteration number: [2030/4518] 44% | Training loss: 0.6871136919324621
Epoch: 87 | Iteration number: [2040/4518] 45% | Training loss: 0.6871149648638333
Epoch: 87 | Iteration number: [2050/4518] 45% | Training loss: 0.687107246212843
Epoch: 87 | Iteration number: [2060/4518] 45% | Training loss: 0.6871079575378918
Epoch: 87 | Iteration number: [2070/4518] 45% | Training loss: 0.6871011065976055
Epoch: 87 | Iteration number: [2080/4518] 46% | Training loss: 0.6870975583218611
Epoch: 87 | Iteration number: [2090/4518] 46% | Training loss: 0.6870958491945951
Epoch: 87 | Iteration number: [2100/4518] 46% | Training loss: 0.6870920907031922
Epoch: 87 | Iteration number: [2110/4518] 46% | Training loss: 0.6870868404329671
Epoch: 87 | Iteration number: [2120/4518] 46% | Training loss: 0.6870835032946658
Epoch: 87 | Iteration number: [2130/4518] 47% | Training loss: 0.687086033541272
Epoch: 87 | Iteration number: [2140/4518] 47% | Training loss: 0.6870866217345835
Epoch: 87 | Iteration number: [2150/4518] 47% | Training loss: 0.6870752688341363
Epoch: 87 | Iteration number: [2160/4518] 47% | Training loss: 0.6870728891480852
Epoch: 87 | Iteration number: [2170/4518] 48% | Training loss: 0.6870652145504402
Epoch: 87 | Iteration number: [2180/4518] 48% | Training loss: 0.687060731704082
Epoch: 87 | Iteration number: [2190/4518] 48% | Training loss: 0.6870585883044761
Epoch: 87 | Iteration number: [2200/4518] 48% | Training loss: 0.6870599228685552
Epoch: 87 | Iteration number: [2210/4518] 48% | Training loss: 0.6870565872116866
Epoch: 87 | Iteration number: [2220/4518] 49% | Training loss: 0.6870580781955977
Epoch: 87 | Iteration number: [2230/4518] 49% | Training loss: 0.6870583206816104
Epoch: 87 | Iteration number: [2240/4518] 49% | Training loss: 0.687055631460888
Epoch: 87 | Iteration number: [2250/4518] 49% | Training loss: 0.6870479582150777
Epoch: 87 | Iteration number: [2260/4518] 50% | Training loss: 0.6870527924162096
Epoch: 87 | Iteration number: [2270/4518] 50% | Training loss: 0.6870456405935834
Epoch: 87 | Iteration number: [2280/4518] 50% | Training loss: 0.6870441642508173
Epoch: 87 | Iteration number: [2290/4518] 50% | Training loss: 0.6870467923353853
Epoch: 87 | Iteration number: [2300/4518] 50% | Training loss: 0.6870444635463797
Epoch: 87 | Iteration number: [2310/4518] 51% | Training loss: 0.6870400958763057
Epoch: 87 | Iteration number: [2320/4518] 51% | Training loss: 0.6870382963840304
Epoch: 87 | Iteration number: [2330/4518] 51% | Training loss: 0.6870397002911874
Epoch: 87 | Iteration number: [2340/4518] 51% | Training loss: 0.6870420950345504
Epoch: 87 | Iteration number: [2350/4518] 52% | Training loss: 0.6870348928837066
Epoch: 87 | Iteration number: [2360/4518] 52% | Training loss: 0.6870367004457166
Epoch: 87 | Iteration number: [2370/4518] 52% | Training loss: 0.6870294330492301
Epoch: 87 | Iteration number: [2380/4518] 52% | Training loss: 0.6870228850040115
Epoch: 87 | Iteration number: [2390/4518] 52% | Training loss: 0.6870204955464128
Epoch: 87 | Iteration number: [2400/4518] 53% | Training loss: 0.6870226445545753
Epoch: 87 | Iteration number: [2410/4518] 53% | Training loss: 0.6870189912091647
Epoch: 87 | Iteration number: [2420/4518] 53% | Training loss: 0.6870184914878578
Epoch: 87 | Iteration number: [2430/4518] 53% | Training loss: 0.6870134549131118
Epoch: 87 | Iteration number: [2440/4518] 54% | Training loss: 0.6870134032407745
Epoch: 87 | Iteration number: [2450/4518] 54% | Training loss: 0.6870166963460494
Epoch: 87 | Iteration number: [2460/4518] 54% | Training loss: 0.6870155446655382
Epoch: 87 | Iteration number: [2470/4518] 54% | Training loss: 0.6870141606099209
Epoch: 87 | Iteration number: [2480/4518] 54% | Training loss: 0.6870105969329035
Epoch: 87 | Iteration number: [2490/4518] 55% | Training loss: 0.68700972309553
Epoch: 87 | Iteration number: [2500/4518] 55% | Training loss: 0.6870034289836884
Epoch: 87 | Iteration number: [2510/4518] 55% | Training loss: 0.6869990782908709
Epoch: 87 | Iteration number: [2520/4518] 55% | Training loss: 0.6869956287836272
Epoch: 87 | Iteration number: [2530/4518] 55% | Training loss: 0.6869964312187767
Epoch: 87 | Iteration number: [2540/4518] 56% | Training loss: 0.6869956311043792
Epoch: 87 | Iteration number: [2550/4518] 56% | Training loss: 0.6869921448885226
Epoch: 87 | Iteration number: [2560/4518] 56% | Training loss: 0.6869987641461194
Epoch: 87 | Iteration number: [2570/4518] 56% | Training loss: 0.6869986474745933
Epoch: 87 | Iteration number: [2580/4518] 57% | Training loss: 0.6869961001152216
Epoch: 87 | Iteration number: [2590/4518] 57% | Training loss: 0.6869952359254756
Epoch: 87 | Iteration number: [2600/4518] 57% | Training loss: 0.6869939330449472
Epoch: 87 | Iteration number: [2610/4518] 57% | Training loss: 0.6869885567275957
Epoch: 87 | Iteration number: [2620/4518] 57% | Training loss: 0.6869876315575519
Epoch: 87 | Iteration number: [2630/4518] 58% | Training loss: 0.686985176892335
Epoch: 87 | Iteration number: [2640/4518] 58% | Training loss: 0.6869832888922908
Epoch: 87 | Iteration number: [2650/4518] 58% | Training loss: 0.6869854993190405
Epoch: 87 | Iteration number: [2660/4518] 58% | Training loss: 0.6869814614828368
Epoch: 87 | Iteration number: [2670/4518] 59% | Training loss: 0.6869845374693139
Epoch: 87 | Iteration number: [2680/4518] 59% | Training loss: 0.6869872447492471
Epoch: 87 | Iteration number: [2690/4518] 59% | Training loss: 0.6869915678377045
Epoch: 87 | Iteration number: [2700/4518] 59% | Training loss: 0.6869930959851653
Epoch: 87 | Iteration number: [2710/4518] 59% | Training loss: 0.6869917777631556
Epoch: 87 | Iteration number: [2720/4518] 60% | Training loss: 0.6869944190058638
Epoch: 87 | Iteration number: [2730/4518] 60% | Training loss: 0.6869973145780109
Epoch: 87 | Iteration number: [2740/4518] 60% | Training loss: 0.6869914566513395
Epoch: 87 | Iteration number: [2750/4518] 60% | Training loss: 0.6869918396906419
Epoch: 87 | Iteration number: [2760/4518] 61% | Training loss: 0.6869872724448425
Epoch: 87 | Iteration number: [2770/4518] 61% | Training loss: 0.6869887859597533
Epoch: 87 | Iteration number: [2780/4518] 61% | Training loss: 0.6869816681678347
Epoch: 87 | Iteration number: [2790/4518] 61% | Training loss: 0.6869852003230843
Epoch: 87 | Iteration number: [2800/4518] 61% | Training loss: 0.6869846785494259
Epoch: 87 | Iteration number: [2810/4518] 62% | Training loss: 0.6869803514344837
Epoch: 87 | Iteration number: [2820/4518] 62% | Training loss: 0.686980754390676
Epoch: 87 | Iteration number: [2830/4518] 62% | Training loss: 0.6869807085594946
Epoch: 87 | Iteration number: [2840/4518] 62% | Training loss: 0.6869779594977137
Epoch: 87 | Iteration number: [2850/4518] 63% | Training loss: 0.6869763232741439
Epoch: 87 | Iteration number: [2860/4518] 63% | Training loss: 0.6869780767214048
Epoch: 87 | Iteration number: [2870/4518] 63% | Training loss: 0.6869778843083864
Epoch: 87 | Iteration number: [2880/4518] 63% | Training loss: 0.6869763331901696
Epoch: 87 | Iteration number: [2890/4518] 63% | Training loss: 0.6869795076781078
Epoch: 87 | Iteration number: [2900/4518] 64% | Training loss: 0.6869799223439447
Epoch: 87 | Iteration number: [2910/4518] 64% | Training loss: 0.6869795303574133
Epoch: 87 | Iteration number: [2920/4518] 64% | Training loss: 0.6869788893689848
Epoch: 87 | Iteration number: [2930/4518] 64% | Training loss: 0.6869769324825079
Epoch: 87 | Iteration number: [2940/4518] 65% | Training loss: 0.6869787716135687
Epoch: 87 | Iteration number: [2950/4518] 65% | Training loss: 0.6869784863924576
Epoch: 87 | Iteration number: [2960/4518] 65% | Training loss: 0.6869756263051484
Epoch: 87 | Iteration number: [2970/4518] 65% | Training loss: 0.686977150845608
Epoch: 87 | Iteration number: [2980/4518] 65% | Training loss: 0.686979658331647
Epoch: 87 | Iteration number: [2990/4518] 66% | Training loss: 0.6869752371988966
Epoch: 87 | Iteration number: [3000/4518] 66% | Training loss: 0.6869712150692939
Epoch: 87 | Iteration number: [3010/4518] 66% | Training loss: 0.6869764770780291
Epoch: 87 | Iteration number: [3020/4518] 66% | Training loss: 0.6869773889811623
Epoch: 87 | Iteration number: [3030/4518] 67% | Training loss: 0.6869781306277801
Epoch: 87 | Iteration number: [3040/4518] 67% | Training loss: 0.6869792322579183
Epoch: 87 | Iteration number: [3050/4518] 67% | Training loss: 0.6869745139997514
Epoch: 87 | Iteration number: [3060/4518] 67% | Training loss: 0.686974399522239
Epoch: 87 | Iteration number: [3070/4518] 67% | Training loss: 0.6869742755198711
Epoch: 87 | Iteration number: [3080/4518] 68% | Training loss: 0.6869694106764608
Epoch: 87 | Iteration number: [3090/4518] 68% | Training loss: 0.6869690807120314
Epoch: 87 | Iteration number: [3100/4518] 68% | Training loss: 0.6869723707822062
Epoch: 87 | Iteration number: [3110/4518] 68% | Training loss: 0.6869678714842659
Epoch: 87 | Iteration number: [3120/4518] 69% | Training loss: 0.6869691831943316
Epoch: 87 | Iteration number: [3130/4518] 69% | Training loss: 0.6869689005061079
Epoch: 87 | Iteration number: [3140/4518] 69% | Training loss: 0.6869614752234927
Epoch: 87 | Iteration number: [3150/4518] 69% | Training loss: 0.6869642325810024
Epoch: 87 | Iteration number: [3160/4518] 69% | Training loss: 0.6869631473776661
Epoch: 87 | Iteration number: [3170/4518] 70% | Training loss: 0.6869625062596535
Epoch: 87 | Iteration number: [3180/4518] 70% | Training loss: 0.6869629966950267
Epoch: 87 | Iteration number: [3190/4518] 70% | Training loss: 0.686964234139852
Epoch: 87 | Iteration number: [3200/4518] 70% | Training loss: 0.6869696907885373
Epoch: 87 | Iteration number: [3210/4518] 71% | Training loss: 0.6869700915345521
Epoch: 87 | Iteration number: [3220/4518] 71% | Training loss: 0.6869691409124351
Epoch: 87 | Iteration number: [3230/4518] 71% | Training loss: 0.6869680391007532
Epoch: 87 | Iteration number: [3240/4518] 71% | Training loss: 0.686968798769845
Epoch: 87 | Iteration number: [3250/4518] 71% | Training loss: 0.6869688902634841
Epoch: 87 | Iteration number: [3260/4518] 72% | Training loss: 0.6869641627453588
Epoch: 87 | Iteration number: [3270/4518] 72% | Training loss: 0.6869642853372323
Epoch: 87 | Iteration number: [3280/4518] 72% | Training loss: 0.6869652740839051
Epoch: 87 | Iteration number: [3290/4518] 72% | Training loss: 0.6869667022786242
Epoch: 87 | Iteration number: [3300/4518] 73% | Training loss: 0.6869642832604321
Epoch: 87 | Iteration number: [3310/4518] 73% | Training loss: 0.6869632095368607
Epoch: 87 | Iteration number: [3320/4518] 73% | Training loss: 0.6869645721222981
Epoch: 87 | Iteration number: [3330/4518] 73% | Training loss: 0.6869618145016221
Epoch: 87 | Iteration number: [3340/4518] 73% | Training loss: 0.6869597476042674
Epoch: 87 | Iteration number: [3350/4518] 74% | Training loss: 0.6869613938011341
Epoch: 87 | Iteration number: [3360/4518] 74% | Training loss: 0.6869610752023402
Epoch: 87 | Iteration number: [3370/4518] 74% | Training loss: 0.6869585075788752
Epoch: 87 | Iteration number: [3380/4518] 74% | Training loss: 0.6869601165754555
Epoch: 87 | Iteration number: [3390/4518] 75% | Training loss: 0.6869591183191204
Epoch: 87 | Iteration number: [3400/4518] 75% | Training loss: 0.6869590880590327
Epoch: 87 | Iteration number: [3410/4518] 75% | Training loss: 0.6869571189202172
Epoch: 87 | Iteration number: [3420/4518] 75% | Training loss: 0.686958771473483
Epoch: 87 | Iteration number: [3430/4518] 75% | Training loss: 0.6869547523840523
Epoch: 87 | Iteration number: [3440/4518] 76% | Training loss: 0.6869522387898246
Epoch: 87 | Iteration number: [3450/4518] 76% | Training loss: 0.6869530648252239
Epoch: 87 | Iteration number: [3460/4518] 76% | Training loss: 0.68695313751353
Epoch: 87 | Iteration number: [3470/4518] 76% | Training loss: 0.6869517727956305
Epoch: 87 | Iteration number: [3480/4518] 77% | Training loss: 0.6869507769229768
Epoch: 87 | Iteration number: [3490/4518] 77% | Training loss: 0.6869506709042797
Epoch: 87 | Iteration number: [3500/4518] 77% | Training loss: 0.6869499966587339
Epoch: 87 | Iteration number: [3510/4518] 77% | Training loss: 0.6869480390324552
Epoch: 87 | Iteration number: [3520/4518] 77% | Training loss: 0.6869479806416414
Epoch: 87 | Iteration number: [3530/4518] 78% | Training loss: 0.6869468922993279
Epoch: 87 | Iteration number: [3540/4518] 78% | Training loss: 0.6869451611223868
Epoch: 87 | Iteration number: [3550/4518] 78% | Training loss: 0.6869483267253553
Epoch: 87 | Iteration number: [3560/4518] 78% | Training loss: 0.6869492958100994
Epoch: 87 | Iteration number: [3570/4518] 79% | Training loss: 0.6869479165524661
Epoch: 87 | Iteration number: [3580/4518] 79% | Training loss: 0.6869489565741417
Epoch: 87 | Iteration number: [3590/4518] 79% | Training loss: 0.6869501354468566
Epoch: 87 | Iteration number: [3600/4518] 79% | Training loss: 0.6869516641894976
Epoch: 87 | Iteration number: [3610/4518] 79% | Training loss: 0.6869498698334945
Epoch: 87 | Iteration number: [3620/4518] 80% | Training loss: 0.6869507012940244
Epoch: 87 | Iteration number: [3630/4518] 80% | Training loss: 0.6869492808320963
Epoch: 87 | Iteration number: [3640/4518] 80% | Training loss: 0.6869487348821137
Epoch: 87 | Iteration number: [3650/4518] 80% | Training loss: 0.6869471930967619
Epoch: 87 | Iteration number: [3660/4518] 81% | Training loss: 0.6869423981247053
Epoch: 87 | Iteration number: [3670/4518] 81% | Training loss: 0.6869412290302869
Epoch: 87 | Iteration number: [3680/4518] 81% | Training loss: 0.6869424100479354
Epoch: 87 | Iteration number: [3690/4518] 81% | Training loss: 0.6869431438323282
Epoch: 87 | Iteration number: [3700/4518] 81% | Training loss: 0.6869413965457195
Epoch: 87 | Iteration number: [3710/4518] 82% | Training loss: 0.6869406380422032
Epoch: 87 | Iteration number: [3720/4518] 82% | Training loss: 0.6869406645336459
Epoch: 87 | Iteration number: [3730/4518] 82% | Training loss: 0.6869397532844033
Epoch: 87 | Iteration number: [3740/4518] 82% | Training loss: 0.6869359989536
Epoch: 87 | Iteration number: [3750/4518] 83% | Training loss: 0.686934210618337
Epoch: 87 | Iteration number: [3760/4518] 83% | Training loss: 0.686932869635998
Epoch: 87 | Iteration number: [3770/4518] 83% | Training loss: 0.6869316944867293
Epoch: 87 | Iteration number: [3780/4518] 83% | Training loss: 0.6869313562515551
Epoch: 87 | Iteration number: [3790/4518] 83% | Training loss: 0.6869277980522619
Epoch: 87 | Iteration number: [3800/4518] 84% | Training loss: 0.6869296520477847
Epoch: 87 | Iteration number: [3810/4518] 84% | Training loss: 0.6869304425916647
Epoch: 87 | Iteration number: [3820/4518] 84% | Training loss: 0.6869380052957236
Epoch: 87 | Iteration number: [3830/4518] 84% | Training loss: 0.6869331615089437
Epoch: 87 | Iteration number: [3840/4518] 84% | Training loss: 0.6869332274887711
Epoch: 87 | Iteration number: [3850/4518] 85% | Training loss: 0.6869339949434454
Epoch: 87 | Iteration number: [3860/4518] 85% | Training loss: 0.6869327913757433
Epoch: 87 | Iteration number: [3870/4518] 85% | Training loss: 0.6869312964822587
Epoch: 87 | Iteration number: [3880/4518] 85% | Training loss: 0.6869310014180301
Epoch: 87 | Iteration number: [3890/4518] 86% | Training loss: 0.6869308589969625
Epoch: 87 | Iteration number: [3900/4518] 86% | Training loss: 0.6869259187961236
Epoch: 87 | Iteration number: [3910/4518] 86% | Training loss: 0.6869241288708299
Epoch: 87 | Iteration number: [3920/4518] 86% | Training loss: 0.6869248425017814
Epoch: 87 | Iteration number: [3930/4518] 86% | Training loss: 0.6869271151892101
Epoch: 87 | Iteration number: [3940/4518] 87% | Training loss: 0.6869271395321425
Epoch: 87 | Iteration number: [3950/4518] 87% | Training loss: 0.6869271958779685
Epoch: 87 | Iteration number: [3960/4518] 87% | Training loss: 0.6869285572056818
Epoch: 87 | Iteration number: [3970/4518] 87% | Training loss: 0.6869288407284907
Epoch: 87 | Iteration number: [3980/4518] 88% | Training loss: 0.6869266188174636
Epoch: 87 | Iteration number: [3990/4518] 88% | Training loss: 0.686927027287041
Epoch: 87 | Iteration number: [4000/4518] 88% | Training loss: 0.6869241976588965
Epoch: 87 | Iteration number: [4010/4518] 88% | Training loss: 0.6869290236968947
Epoch: 87 | Iteration number: [4020/4518] 88% | Training loss: 0.6869261692412457
Epoch: 87 | Iteration number: [4030/4518] 89% | Training loss: 0.6869291381267992
Epoch: 87 | Iteration number: [4040/4518] 89% | Training loss: 0.686928184109159
Epoch: 87 | Iteration number: [4050/4518] 89% | Training loss: 0.6869270797423375
Epoch: 87 | Iteration number: [4060/4518] 89% | Training loss: 0.6869270613334449
Epoch: 87 | Iteration number: [4070/4518] 90% | Training loss: 0.6869260006366842
Epoch: 87 | Iteration number: [4080/4518] 90% | Training loss: 0.6869246171677814
Epoch: 87 | Iteration number: [4090/4518] 90% | Training loss: 0.6869219646622907
Epoch: 87 | Iteration number: [4100/4518] 90% | Training loss: 0.6869241106655539
Epoch: 87 | Iteration number: [4110/4518] 90% | Training loss: 0.686925830603226
Epoch: 87 | Iteration number: [4120/4518] 91% | Training loss: 0.686925153376408
Epoch: 87 | Iteration number: [4130/4518] 91% | Training loss: 0.6869263628060246
Epoch: 87 | Iteration number: [4140/4518] 91% | Training loss: 0.6869267412573818
Epoch: 87 | Iteration number: [4150/4518] 91% | Training loss: 0.6869236152717866
Epoch: 87 | Iteration number: [4160/4518] 92% | Training loss: 0.686923742108047
Epoch: 87 | Iteration number: [4170/4518] 92% | Training loss: 0.6869186787010668
Epoch: 87 | Iteration number: [4180/4518] 92% | Training loss: 0.686919646585387
Epoch: 87 | Iteration number: [4190/4518] 92% | Training loss: 0.6869169675791748
Epoch: 87 | Iteration number: [4200/4518] 92% | Training loss: 0.6869171976475489
Epoch: 87 | Iteration number: [4210/4518] 93% | Training loss: 0.6869175560400774
Epoch: 87 | Iteration number: [4220/4518] 93% | Training loss: 0.6869164136772472
Epoch: 87 | Iteration number: [4230/4518] 93% | Training loss: 0.6869168712455894
Epoch: 87 | Iteration number: [4240/4518] 93% | Training loss: 0.6869165315380636
Epoch: 87 | Iteration number: [4250/4518] 94% | Training loss: 0.6869159628924202
Epoch: 87 | Iteration number: [4260/4518] 94% | Training loss: 0.6869150632703808
Epoch: 87 | Iteration number: [4270/4518] 94% | Training loss: 0.6869152087517588
Epoch: 87 | Iteration number: [4280/4518] 94% | Training loss: 0.6869131043971142
Epoch: 87 | Iteration number: [4290/4518] 94% | Training loss: 0.6869121579301385
Epoch: 87 | Iteration number: [4300/4518] 95% | Training loss: 0.6869126332083414
Epoch: 87 | Iteration number: [4310/4518] 95% | Training loss: 0.686912487568269
Epoch: 87 | Iteration number: [4320/4518] 95% | Training loss: 0.6869127781026894
Epoch: 87 | Iteration number: [4330/4518] 95% | Training loss: 0.6869146887479698
Epoch: 87 | Iteration number: [4340/4518] 96% | Training loss: 0.6869131985210604
Epoch: 87 | Iteration number: [4350/4518] 96% | Training loss: 0.6869136669169897
Epoch: 87 | Iteration number: [4360/4518] 96% | Training loss: 0.6869143087246002
Epoch: 87 | Iteration number: [4370/4518] 96% | Training loss: 0.6869137506735953
Epoch: 87 | Iteration number: [4380/4518] 96% | Training loss: 0.6869135355568368
Epoch: 87 | Iteration number: [4390/4518] 97% | Training loss: 0.6869154964329713
Epoch: 87 | Iteration number: [4400/4518] 97% | Training loss: 0.6869180155071345
Epoch: 87 | Iteration number: [4410/4518] 97% | Training loss: 0.6869137818580853
Epoch: 87 | Iteration number: [4420/4518] 97% | Training loss: 0.6869134582815127
Epoch: 87 | Iteration number: [4430/4518] 98% | Training loss: 0.6869150629161981
Epoch: 87 | Iteration number: [4440/4518] 98% | Training loss: 0.6869155050397994
Epoch: 87 | Iteration number: [4450/4518] 98% | Training loss: 0.6869191319085239
Epoch: 87 | Iteration number: [4460/4518] 98% | Training loss: 0.6869174099690176
Epoch: 87 | Iteration number: [4470/4518] 98% | Training loss: 0.6869180503174229
Epoch: 87 | Iteration number: [4480/4518] 99% | Training loss: 0.6869189233785229
Epoch: 87 | Iteration number: [4490/4518] 99% | Training loss: 0.6869191177438256
Epoch: 87 | Iteration number: [4500/4518] 99% | Training loss: 0.6869183451599545
Epoch: 87 | Iteration number: [4510/4518] 99% | Training loss: 0.6869173964349234

 End of epoch: 87 | Train Loss: 0.6867642949750435 | Training Time: 639 

 End of epoch: 87 | Eval Loss: 0.6899466964663291 | Evaluating Time: 16 
Epoch: 88 | Iteration number: [10/4518] 0% | Training loss: 0.7549541532993317
Epoch: 88 | Iteration number: [20/4518] 0% | Training loss: 0.7210477590560913
Epoch: 88 | Iteration number: [30/4518] 0% | Training loss: 0.7096462905406952
Epoch: 88 | Iteration number: [40/4518] 0% | Training loss: 0.7039970248937607
Epoch: 88 | Iteration number: [50/4518] 1% | Training loss: 0.7006240022182465
Epoch: 88 | Iteration number: [60/4518] 1% | Training loss: 0.6985767354567846
Epoch: 88 | Iteration number: [70/4518] 1% | Training loss: 0.6968050880091531
Epoch: 88 | Iteration number: [80/4518] 1% | Training loss: 0.695533835887909
Epoch: 88 | Iteration number: [90/4518] 1% | Training loss: 0.6945294088787503
Epoch: 88 | Iteration number: [100/4518] 2% | Training loss: 0.6938607627153397
Epoch: 88 | Iteration number: [110/4518] 2% | Training loss: 0.6933789567513899
Epoch: 88 | Iteration number: [120/4518] 2% | Training loss: 0.6928423111637433
Epoch: 88 | Iteration number: [130/4518] 2% | Training loss: 0.692397120824227
Epoch: 88 | Iteration number: [140/4518] 3% | Training loss: 0.6920250867094312
Epoch: 88 | Iteration number: [150/4518] 3% | Training loss: 0.6916940589745839
Epoch: 88 | Iteration number: [160/4518] 3% | Training loss: 0.6914293516427279
Epoch: 88 | Iteration number: [170/4518] 3% | Training loss: 0.6911476240438573
Epoch: 88 | Iteration number: [180/4518] 3% | Training loss: 0.6909386770592796
Epoch: 88 | Iteration number: [190/4518] 4% | Training loss: 0.6906332819085372
Epoch: 88 | Iteration number: [200/4518] 4% | Training loss: 0.6904589122533799
Epoch: 88 | Iteration number: [210/4518] 4% | Training loss: 0.6902454149155389
Epoch: 88 | Iteration number: [220/4518] 4% | Training loss: 0.6901201240041039
Epoch: 88 | Iteration number: [230/4518] 5% | Training loss: 0.6900014185387155
Epoch: 88 | Iteration number: [240/4518] 5% | Training loss: 0.6898695923388004
Epoch: 88 | Iteration number: [250/4518] 5% | Training loss: 0.6897467889785767
Epoch: 88 | Iteration number: [260/4518] 5% | Training loss: 0.6896138266875194
Epoch: 88 | Iteration number: [270/4518] 5% | Training loss: 0.6895437547454127
Epoch: 88 | Iteration number: [280/4518] 6% | Training loss: 0.6894484943577222
Epoch: 88 | Iteration number: [290/4518] 6% | Training loss: 0.6893679320812225
Epoch: 88 | Iteration number: [300/4518] 6% | Training loss: 0.6892961072921753
Epoch: 88 | Iteration number: [310/4518] 6% | Training loss: 0.6891967381200482
Epoch: 88 | Iteration number: [320/4518] 7% | Training loss: 0.6891286408528685
Epoch: 88 | Iteration number: [330/4518] 7% | Training loss: 0.6890680959730437
Epoch: 88 | Iteration number: [340/4518] 7% | Training loss: 0.6889825889292885
Epoch: 88 | Iteration number: [350/4518] 7% | Training loss: 0.688909490619387
Epoch: 88 | Iteration number: [360/4518] 7% | Training loss: 0.688877928422557
Epoch: 88 | Iteration number: [370/4518] 8% | Training loss: 0.6888227166356267
Epoch: 88 | Iteration number: [380/4518] 8% | Training loss: 0.6887580844916795
Epoch: 88 | Iteration number: [390/4518] 8% | Training loss: 0.6887516547472049
Epoch: 88 | Iteration number: [400/4518] 8% | Training loss: 0.6886833781003951
Epoch: 88 | Iteration number: [410/4518] 9% | Training loss: 0.688627018143491
Epoch: 88 | Iteration number: [420/4518] 9% | Training loss: 0.6885969303903126
Epoch: 88 | Iteration number: [430/4518] 9% | Training loss: 0.688567385978477
Epoch: 88 | Iteration number: [440/4518] 9% | Training loss: 0.6885206883603876
Epoch: 88 | Iteration number: [450/4518] 9% | Training loss: 0.6884661165873209
Epoch: 88 | Iteration number: [460/4518] 10% | Training loss: 0.688425480671551
Epoch: 88 | Iteration number: [470/4518] 10% | Training loss: 0.6883992377747881
Epoch: 88 | Iteration number: [480/4518] 10% | Training loss: 0.6883783591290314
Epoch: 88 | Iteration number: [490/4518] 10% | Training loss: 0.6883560397187057
Epoch: 88 | Iteration number: [500/4518] 11% | Training loss: 0.6883268948793412
Epoch: 88 | Iteration number: [510/4518] 11% | Training loss: 0.6883061401984271
Epoch: 88 | Iteration number: [520/4518] 11% | Training loss: 0.6882536425040319
Epoch: 88 | Iteration number: [530/4518] 11% | Training loss: 0.6882234041420918
Epoch: 88 | Iteration number: [540/4518] 11% | Training loss: 0.6881654308901892
Epoch: 88 | Iteration number: [550/4518] 12% | Training loss: 0.6881167088855397
Epoch: 88 | Iteration number: [560/4518] 12% | Training loss: 0.6880722272608961
Epoch: 88 | Iteration number: [570/4518] 12% | Training loss: 0.6880494284002404
Epoch: 88 | Iteration number: [580/4518] 12% | Training loss: 0.6880363177636574
Epoch: 88 | Iteration number: [590/4518] 13% | Training loss: 0.6880143120127209
Epoch: 88 | Iteration number: [600/4518] 13% | Training loss: 0.6879935834805171
Epoch: 88 | Iteration number: [610/4518] 13% | Training loss: 0.6879645175621157
Epoch: 88 | Iteration number: [620/4518] 13% | Training loss: 0.6879521571820782
Epoch: 88 | Iteration number: [630/4518] 13% | Training loss: 0.6879405923305996
Epoch: 88 | Iteration number: [640/4518] 14% | Training loss: 0.6879083541221916
Epoch: 88 | Iteration number: [650/4518] 14% | Training loss: 0.687876878793423
Epoch: 88 | Iteration number: [660/4518] 14% | Training loss: 0.6878323033903584
Epoch: 88 | Iteration number: [670/4518] 14% | Training loss: 0.6878348751744228
Epoch: 88 | Iteration number: [680/4518] 15% | Training loss: 0.6878296850358738
Epoch: 88 | Iteration number: [690/4518] 15% | Training loss: 0.6878244129643925
Epoch: 88 | Iteration number: [700/4518] 15% | Training loss: 0.6878349685668945
Epoch: 88 | Iteration number: [710/4518] 15% | Training loss: 0.6878041184284318
Epoch: 88 | Iteration number: [720/4518] 15% | Training loss: 0.6878021683957841
Epoch: 88 | Iteration number: [730/4518] 16% | Training loss: 0.6877937323426547
Epoch: 88 | Iteration number: [740/4518] 16% | Training loss: 0.6877682285534369
Epoch: 88 | Iteration number: [750/4518] 16% | Training loss: 0.6877411413192749
Epoch: 88 | Iteration number: [760/4518] 16% | Training loss: 0.6877447746301952
Epoch: 88 | Iteration number: [770/4518] 17% | Training loss: 0.6877254303399618
Epoch: 88 | Iteration number: [780/4518] 17% | Training loss: 0.6877254886504931
Epoch: 88 | Iteration number: [790/4518] 17% | Training loss: 0.6877107926561863
Epoch: 88 | Iteration number: [800/4518] 17% | Training loss: 0.6876863189786673
Epoch: 88 | Iteration number: [810/4518] 17% | Training loss: 0.687663142548667
Epoch: 88 | Iteration number: [820/4518] 18% | Training loss: 0.6876700379499575
Epoch: 88 | Iteration number: [830/4518] 18% | Training loss: 0.6876619118523885
Epoch: 88 | Iteration number: [840/4518] 18% | Training loss: 0.6876509233599617
Epoch: 88 | Iteration number: [850/4518] 18% | Training loss: 0.687633058533949
Epoch: 88 | Iteration number: [860/4518] 19% | Training loss: 0.6876167427661807
Epoch: 88 | Iteration number: [870/4518] 19% | Training loss: 0.6876230781105743
Epoch: 88 | Iteration number: [880/4518] 19% | Training loss: 0.6876213115047325
Epoch: 88 | Iteration number: [890/4518] 19% | Training loss: 0.6876169530863172
Epoch: 88 | Iteration number: [900/4518] 19% | Training loss: 0.6876037834750282
Epoch: 88 | Iteration number: [910/4518] 20% | Training loss: 0.6875990131399133
Epoch: 88 | Iteration number: [920/4518] 20% | Training loss: 0.6875809838590414
Epoch: 88 | Iteration number: [930/4518] 20% | Training loss: 0.6875791993833358
Epoch: 88 | Iteration number: [940/4518] 20% | Training loss: 0.6875656431025647
Epoch: 88 | Iteration number: [950/4518] 21% | Training loss: 0.6875653059231608
Epoch: 88 | Iteration number: [960/4518] 21% | Training loss: 0.6875510347386201
Epoch: 88 | Iteration number: [970/4518] 21% | Training loss: 0.6875452133183627
Epoch: 88 | Iteration number: [980/4518] 21% | Training loss: 0.6875332314140943
Epoch: 88 | Iteration number: [990/4518] 21% | Training loss: 0.6875184666026722
Epoch: 88 | Iteration number: [1000/4518] 22% | Training loss: 0.687501490175724
Epoch: 88 | Iteration number: [1010/4518] 22% | Training loss: 0.6874887006117566
Epoch: 88 | Iteration number: [1020/4518] 22% | Training loss: 0.6874914484281166
Epoch: 88 | Iteration number: [1030/4518] 22% | Training loss: 0.6874683206521192
Epoch: 88 | Iteration number: [1040/4518] 23% | Training loss: 0.6874793448127233
Epoch: 88 | Iteration number: [1050/4518] 23% | Training loss: 0.6874816890557607
Epoch: 88 | Iteration number: [1060/4518] 23% | Training loss: 0.6874678893471664
Epoch: 88 | Iteration number: [1070/4518] 23% | Training loss: 0.6874591451381968
Epoch: 88 | Iteration number: [1080/4518] 23% | Training loss: 0.6874481049952683
Epoch: 88 | Iteration number: [1090/4518] 24% | Training loss: 0.6874559136705661
Epoch: 88 | Iteration number: [1100/4518] 24% | Training loss: 0.6874573244831779
Epoch: 88 | Iteration number: [1110/4518] 24% | Training loss: 0.6874513569715861
Epoch: 88 | Iteration number: [1120/4518] 24% | Training loss: 0.6874420205397266
Epoch: 88 | Iteration number: [1130/4518] 25% | Training loss: 0.6874259613256539
Epoch: 88 | Iteration number: [1140/4518] 25% | Training loss: 0.6874191953947669
Epoch: 88 | Iteration number: [1150/4518] 25% | Training loss: 0.6874184164793595
Epoch: 88 | Iteration number: [1160/4518] 25% | Training loss: 0.6874231528105407
Epoch: 88 | Iteration number: [1170/4518] 25% | Training loss: 0.6874075968041379
Epoch: 88 | Iteration number: [1180/4518] 26% | Training loss: 0.6873878912905516
Epoch: 88 | Iteration number: [1190/4518] 26% | Training loss: 0.6873803452283395
Epoch: 88 | Iteration number: [1200/4518] 26% | Training loss: 0.6873793046673139
Epoch: 88 | Iteration number: [1210/4518] 26% | Training loss: 0.6873713582015235
Epoch: 88 | Iteration number: [1220/4518] 27% | Training loss: 0.687355527965749
Epoch: 88 | Iteration number: [1230/4518] 27% | Training loss: 0.6873602665536772
Epoch: 88 | Iteration number: [1240/4518] 27% | Training loss: 0.6873578079765843
Epoch: 88 | Iteration number: [1250/4518] 27% | Training loss: 0.6873440878868103
Epoch: 88 | Iteration number: [1260/4518] 27% | Training loss: 0.6873405479722553
Epoch: 88 | Iteration number: [1270/4518] 28% | Training loss: 0.6873352631339876
Epoch: 88 | Iteration number: [1280/4518] 28% | Training loss: 0.687325988849625
Epoch: 88 | Iteration number: [1290/4518] 28% | Training loss: 0.6873139127742413
Epoch: 88 | Iteration number: [1300/4518] 28% | Training loss: 0.6873074905688946
Epoch: 88 | Iteration number: [1310/4518] 28% | Training loss: 0.6873139113870286
Epoch: 88 | Iteration number: [1320/4518] 29% | Training loss: 0.6873037041588264
Epoch: 88 | Iteration number: [1330/4518] 29% | Training loss: 0.6873071639609516
Epoch: 88 | Iteration number: [1340/4518] 29% | Training loss: 0.6873017134506311
Epoch: 88 | Iteration number: [1350/4518] 29% | Training loss: 0.687296638003102
Epoch: 88 | Iteration number: [1360/4518] 30% | Training loss: 0.6872906077872304
Epoch: 88 | Iteration number: [1370/4518] 30% | Training loss: 0.6872854799684817
Epoch: 88 | Iteration number: [1380/4518] 30% | Training loss: 0.687277411809866
Epoch: 88 | Iteration number: [1390/4518] 30% | Training loss: 0.6872862835153402
Epoch: 88 | Iteration number: [1400/4518] 30% | Training loss: 0.687279845901898
Epoch: 88 | Iteration number: [1410/4518] 31% | Training loss: 0.6872743297553231
Epoch: 88 | Iteration number: [1420/4518] 31% | Training loss: 0.6872715113028675
Epoch: 88 | Iteration number: [1430/4518] 31% | Training loss: 0.6872657990122175
Epoch: 88 | Iteration number: [1440/4518] 31% | Training loss: 0.687257446679804
Epoch: 88 | Iteration number: [1450/4518] 32% | Training loss: 0.6872524069917613
Epoch: 88 | Iteration number: [1460/4518] 32% | Training loss: 0.6872453625071538
Epoch: 88 | Iteration number: [1470/4518] 32% | Training loss: 0.6872417859479684
Epoch: 88 | Iteration number: [1480/4518] 32% | Training loss: 0.6872439380835842
Epoch: 88 | Iteration number: [1490/4518] 32% | Training loss: 0.6872343929822012
Epoch: 88 | Iteration number: [1500/4518] 33% | Training loss: 0.6872265650033951
Epoch: 88 | Iteration number: [1510/4518] 33% | Training loss: 0.6872238956145104
Epoch: 88 | Iteration number: [1520/4518] 33% | Training loss: 0.6872177724383379
Epoch: 88 | Iteration number: [1530/4518] 33% | Training loss: 0.6872248895417631
Epoch: 88 | Iteration number: [1540/4518] 34% | Training loss: 0.6872201607211844
Epoch: 88 | Iteration number: [1550/4518] 34% | Training loss: 0.6872141513516826
Epoch: 88 | Iteration number: [1560/4518] 34% | Training loss: 0.6872092762054541
Epoch: 88 | Iteration number: [1570/4518] 34% | Training loss: 0.6872062715755147
Epoch: 88 | Iteration number: [1580/4518] 34% | Training loss: 0.6871955178960969
Epoch: 88 | Iteration number: [1590/4518] 35% | Training loss: 0.6872004180209442
Epoch: 88 | Iteration number: [1600/4518] 35% | Training loss: 0.6871961828321218
Epoch: 88 | Iteration number: [1610/4518] 35% | Training loss: 0.6871949772286859
Epoch: 88 | Iteration number: [1620/4518] 35% | Training loss: 0.6871981801810088
Epoch: 88 | Iteration number: [1630/4518] 36% | Training loss: 0.687196100014119
Epoch: 88 | Iteration number: [1640/4518] 36% | Training loss: 0.687185555878209
Epoch: 88 | Iteration number: [1650/4518] 36% | Training loss: 0.6871818923950195
Epoch: 88 | Iteration number: [1660/4518] 36% | Training loss: 0.6871787270508617
Epoch: 88 | Iteration number: [1670/4518] 36% | Training loss: 0.6871794144907397
Epoch: 88 | Iteration number: [1680/4518] 37% | Training loss: 0.6871747210621834
Epoch: 88 | Iteration number: [1690/4518] 37% | Training loss: 0.6871757734456712
Epoch: 88 | Iteration number: [1700/4518] 37% | Training loss: 0.6871791588909486
Epoch: 88 | Iteration number: [1710/4518] 37% | Training loss: 0.6871721035555789
Epoch: 88 | Iteration number: [1720/4518] 38% | Training loss: 0.6871768850919813
Epoch: 88 | Iteration number: [1730/4518] 38% | Training loss: 0.6871823703622543
Epoch: 88 | Iteration number: [1740/4518] 38% | Training loss: 0.687177963640498
Epoch: 88 | Iteration number: [1750/4518] 38% | Training loss: 0.687170268705913
Epoch: 88 | Iteration number: [1760/4518] 38% | Training loss: 0.687167481163686
Epoch: 88 | Iteration number: [1770/4518] 39% | Training loss: 0.6871647936812902
Epoch: 88 | Iteration number: [1780/4518] 39% | Training loss: 0.6871658788638169
Epoch: 88 | Iteration number: [1790/4518] 39% | Training loss: 0.6871614892722508
Epoch: 88 | Iteration number: [1800/4518] 39% | Training loss: 0.6871579216255082
Epoch: 88 | Iteration number: [1810/4518] 40% | Training loss: 0.6871607048076819
Epoch: 88 | Iteration number: [1820/4518] 40% | Training loss: 0.6871613176969381
Epoch: 88 | Iteration number: [1830/4518] 40% | Training loss: 0.6871588029496657
Epoch: 88 | Iteration number: [1840/4518] 40% | Training loss: 0.6871591616259969
Epoch: 88 | Iteration number: [1850/4518] 40% | Training loss: 0.6871603252114477
Epoch: 88 | Iteration number: [1860/4518] 41% | Training loss: 0.6871608255050515
Epoch: 88 | Iteration number: [1870/4518] 41% | Training loss: 0.6871569626152834
Epoch: 88 | Iteration number: [1880/4518] 41% | Training loss: 0.6871532443673053
Epoch: 88 | Iteration number: [1890/4518] 41% | Training loss: 0.687146897196139
Epoch: 88 | Iteration number: [1900/4518] 42% | Training loss: 0.6871390352437371
Epoch: 88 | Iteration number: [1910/4518] 42% | Training loss: 0.6871336219198416
Epoch: 88 | Iteration number: [1920/4518] 42% | Training loss: 0.6871245320886373
Epoch: 88 | Iteration number: [1930/4518] 42% | Training loss: 0.6871281973747392
Epoch: 88 | Iteration number: [1940/4518] 42% | Training loss: 0.687130073911136
Epoch: 88 | Iteration number: [1950/4518] 43% | Training loss: 0.6871278071097838
Epoch: 88 | Iteration number: [1960/4518] 43% | Training loss: 0.6871246846962948
Epoch: 88 | Iteration number: [1970/4518] 43% | Training loss: 0.6871187281487557
Epoch: 88 | Iteration number: [1980/4518] 43% | Training loss: 0.687116338357781
Epoch: 88 | Iteration number: [1990/4518] 44% | Training loss: 0.687112581759841
Epoch: 88 | Iteration number: [2000/4518] 44% | Training loss: 0.6871094865202904
Epoch: 88 | Iteration number: [2010/4518] 44% | Training loss: 0.6871127724054441
Epoch: 88 | Iteration number: [2020/4518] 44% | Training loss: 0.6871082569703018
Epoch: 88 | Iteration number: [2030/4518] 44% | Training loss: 0.687109944679467
Epoch: 88 | Iteration number: [2040/4518] 45% | Training loss: 0.6871092232711175
Epoch: 88 | Iteration number: [2050/4518] 45% | Training loss: 0.68711474642521
Epoch: 88 | Iteration number: [2060/4518] 45% | Training loss: 0.6871133162269315
Epoch: 88 | Iteration number: [2070/4518] 45% | Training loss: 0.6871146077407155
Epoch: 88 | Iteration number: [2080/4518] 46% | Training loss: 0.6871086628677753
Epoch: 88 | Iteration number: [2090/4518] 46% | Training loss: 0.6871062938961686
Epoch: 88 | Iteration number: [2100/4518] 46% | Training loss: 0.6871067831062135
Epoch: 88 | Iteration number: [2110/4518] 46% | Training loss: 0.6871070562098264
Epoch: 88 | Iteration number: [2120/4518] 46% | Training loss: 0.6871067421616248
Epoch: 88 | Iteration number: [2130/4518] 47% | Training loss: 0.6871031057107057
Epoch: 88 | Iteration number: [2140/4518] 47% | Training loss: 0.6871057962424287
Epoch: 88 | Iteration number: [2150/4518] 47% | Training loss: 0.6870950203995372
Epoch: 88 | Iteration number: [2160/4518] 47% | Training loss: 0.6870997058020698
Epoch: 88 | Iteration number: [2170/4518] 48% | Training loss: 0.687091657945088
Epoch: 88 | Iteration number: [2180/4518] 48% | Training loss: 0.6870911294714026
Epoch: 88 | Iteration number: [2190/4518] 48% | Training loss: 0.6870913066276132
Epoch: 88 | Iteration number: [2200/4518] 48% | Training loss: 0.687094191475348
Epoch: 88 | Iteration number: [2210/4518] 48% | Training loss: 0.6870961082736831
Epoch: 88 | Iteration number: [2220/4518] 49% | Training loss: 0.6870982303007229
Epoch: 88 | Iteration number: [2230/4518] 49% | Training loss: 0.6871034171549194
Epoch: 88 | Iteration number: [2240/4518] 49% | Training loss: 0.687105905264616
Epoch: 88 | Iteration number: [2250/4518] 49% | Training loss: 0.6871027902497185
Epoch: 88 | Iteration number: [2260/4518] 50% | Training loss: 0.6871018268629513
Epoch: 88 | Iteration number: [2270/4518] 50% | Training loss: 0.6870988571696345
Epoch: 88 | Iteration number: [2280/4518] 50% | Training loss: 0.6870929000931874
Epoch: 88 | Iteration number: [2290/4518] 50% | Training loss: 0.6870865796590997
Epoch: 88 | Iteration number: [2300/4518] 50% | Training loss: 0.6870822341804919
Epoch: 88 | Iteration number: [2310/4518] 51% | Training loss: 0.687081413170992
Epoch: 88 | Iteration number: [2320/4518] 51% | Training loss: 0.6870814951586313
Epoch: 88 | Iteration number: [2330/4518] 51% | Training loss: 0.6870768188151167
Epoch: 88 | Iteration number: [2340/4518] 51% | Training loss: 0.6870835986911741
Epoch: 88 | Iteration number: [2350/4518] 52% | Training loss: 0.6870882932175981
Epoch: 88 | Iteration number: [2360/4518] 52% | Training loss: 0.687084248914557
Epoch: 88 | Iteration number: [2370/4518] 52% | Training loss: 0.6870838336803742
Epoch: 88 | Iteration number: [2380/4518] 52% | Training loss: 0.6870776038710811
Epoch: 88 | Iteration number: [2390/4518] 52% | Training loss: 0.6870757324176853
Epoch: 88 | Iteration number: [2400/4518] 53% | Training loss: 0.6870755062500635
Epoch: 88 | Iteration number: [2410/4518] 53% | Training loss: 0.6870739923720538
Epoch: 88 | Iteration number: [2420/4518] 53% | Training loss: 0.6870735430274127
Epoch: 88 | Iteration number: [2430/4518] 53% | Training loss: 0.6870698164274663
Epoch: 88 | Iteration number: [2440/4518] 54% | Training loss: 0.6870728099443874
Epoch: 88 | Iteration number: [2450/4518] 54% | Training loss: 0.6870737242455385
Epoch: 88 | Iteration number: [2460/4518] 54% | Training loss: 0.687068593380897
Epoch: 88 | Iteration number: [2470/4518] 54% | Training loss: 0.6870696076014746
Epoch: 88 | Iteration number: [2480/4518] 54% | Training loss: 0.6870690055191517
Epoch: 88 | Iteration number: [2490/4518] 55% | Training loss: 0.6870690833612618
Epoch: 88 | Iteration number: [2500/4518] 55% | Training loss: 0.6870693816900253
Epoch: 88 | Iteration number: [2510/4518] 55% | Training loss: 0.6870652319663074
Epoch: 88 | Iteration number: [2520/4518] 55% | Training loss: 0.6870661362059532
Epoch: 88 | Iteration number: [2530/4518] 55% | Training loss: 0.6870637592590845
Epoch: 88 | Iteration number: [2540/4518] 56% | Training loss: 0.6870627595449057
Epoch: 88 | Iteration number: [2550/4518] 56% | Training loss: 0.6870583490296907
Epoch: 88 | Iteration number: [2560/4518] 56% | Training loss: 0.687054870207794
Epoch: 88 | Iteration number: [2570/4518] 56% | Training loss: 0.687052931790222
Epoch: 88 | Iteration number: [2580/4518] 57% | Training loss: 0.6870539510203887
Epoch: 88 | Iteration number: [2590/4518] 57% | Training loss: 0.687055495576969
Epoch: 88 | Iteration number: [2600/4518] 57% | Training loss: 0.6870513998774381
Epoch: 88 | Iteration number: [2610/4518] 57% | Training loss: 0.6870518292732166
Epoch: 88 | Iteration number: [2620/4518] 57% | Training loss: 0.6870468959098553
Epoch: 88 | Iteration number: [2630/4518] 58% | Training loss: 0.687050060174311
Epoch: 88 | Iteration number: [2640/4518] 58% | Training loss: 0.6870540813288906
Epoch: 88 | Iteration number: [2650/4518] 58% | Training loss: 0.6870499304780421
Epoch: 88 | Iteration number: [2660/4518] 58% | Training loss: 0.6870499981749326
Epoch: 88 | Iteration number: [2670/4518] 59% | Training loss: 0.6870481163151702
Epoch: 88 | Iteration number: [2680/4518] 59% | Training loss: 0.6870506200327802
Epoch: 88 | Iteration number: [2690/4518] 59% | Training loss: 0.6870475627675818
Epoch: 88 | Iteration number: [2700/4518] 59% | Training loss: 0.6870432581945702
Epoch: 88 | Iteration number: [2710/4518] 59% | Training loss: 0.6870415412851805
Epoch: 88 | Iteration number: [2720/4518] 60% | Training loss: 0.6870404006365467
Epoch: 88 | Iteration number: [2730/4518] 60% | Training loss: 0.687040448538113
Epoch: 88 | Iteration number: [2740/4518] 60% | Training loss: 0.687040140006664
Epoch: 88 | Iteration number: [2750/4518] 60% | Training loss: 0.6870364651679993
Epoch: 88 | Iteration number: [2760/4518] 61% | Training loss: 0.687038166237914
Epoch: 88 | Iteration number: [2770/4518] 61% | Training loss: 0.6870339989231812
Epoch: 88 | Iteration number: [2780/4518] 61% | Training loss: 0.6870295812543348
Epoch: 88 | Iteration number: [2790/4518] 61% | Training loss: 0.6870261523458693
Epoch: 88 | Iteration number: [2800/4518] 61% | Training loss: 0.687019448024886
Epoch: 88 | Iteration number: [2810/4518] 62% | Training loss: 0.6870196737428577
Epoch: 88 | Iteration number: [2820/4518] 62% | Training loss: 0.6870148055730982
Epoch: 88 | Iteration number: [2830/4518] 62% | Training loss: 0.6870168973826688
Epoch: 88 | Iteration number: [2840/4518] 62% | Training loss: 0.6870172071834685
Epoch: 88 | Iteration number: [2850/4518] 63% | Training loss: 0.6870146819164878
Epoch: 88 | Iteration number: [2860/4518] 63% | Training loss: 0.6870138689354583
Epoch: 88 | Iteration number: [2870/4518] 63% | Training loss: 0.6870068765475775
Epoch: 88 | Iteration number: [2880/4518] 63% | Training loss: 0.6870062602476941
Epoch: 88 | Iteration number: [2890/4518] 63% | Training loss: 0.6870032722768487
Epoch: 88 | Iteration number: [2900/4518] 64% | Training loss: 0.687000613377012
Epoch: 88 | Iteration number: [2910/4518] 64% | Training loss: 0.687000552813212
Epoch: 88 | Iteration number: [2920/4518] 64% | Training loss: 0.686996504623596
Epoch: 88 | Iteration number: [2930/4518] 64% | Training loss: 0.6870011467779049
Epoch: 88 | Iteration number: [2940/4518] 65% | Training loss: 0.6869978835388105
Epoch: 88 | Iteration number: [2950/4518] 65% | Training loss: 0.6869960424657595
Epoch: 88 | Iteration number: [2960/4518] 65% | Training loss: 0.6869947122158231
Epoch: 88 | Iteration number: [2970/4518] 65% | Training loss: 0.6869961964963662
Epoch: 88 | Iteration number: [2980/4518] 65% | Training loss: 0.6869872718449407
Epoch: 88 | Iteration number: [2990/4518] 66% | Training loss: 0.6869873162695397
Epoch: 88 | Iteration number: [3000/4518] 66% | Training loss: 0.6869861589272817
Epoch: 88 | Iteration number: [3010/4518] 66% | Training loss: 0.6869851863265434
Epoch: 88 | Iteration number: [3020/4518] 66% | Training loss: 0.6869853106752926
Epoch: 88 | Iteration number: [3030/4518] 67% | Training loss: 0.6869823820126726
Epoch: 88 | Iteration number: [3040/4518] 67% | Training loss: 0.686978534550259
Epoch: 88 | Iteration number: [3050/4518] 67% | Training loss: 0.686978507921344
Epoch: 88 | Iteration number: [3060/4518] 67% | Training loss: 0.6869776618831298
Epoch: 88 | Iteration number: [3070/4518] 67% | Training loss: 0.6869809762662707
Epoch: 88 | Iteration number: [3080/4518] 68% | Training loss: 0.6869782298222765
Epoch: 88 | Iteration number: [3090/4518] 68% | Training loss: 0.6869783014155515
Epoch: 88 | Iteration number: [3100/4518] 68% | Training loss: 0.6869769774137005
Epoch: 88 | Iteration number: [3110/4518] 68% | Training loss: 0.6869731290739065
Epoch: 88 | Iteration number: [3120/4518] 69% | Training loss: 0.6869742793150437
Epoch: 88 | Iteration number: [3130/4518] 69% | Training loss: 0.6869739970269676
Epoch: 88 | Iteration number: [3140/4518] 69% | Training loss: 0.6869719354969681
Epoch: 88 | Iteration number: [3150/4518] 69% | Training loss: 0.6869689460406228
Epoch: 88 | Iteration number: [3160/4518] 69% | Training loss: 0.6869750388815433
Epoch: 88 | Iteration number: [3170/4518] 70% | Training loss: 0.6869721760885197
Epoch: 88 | Iteration number: [3180/4518] 70% | Training loss: 0.6869723027232308
Epoch: 88 | Iteration number: [3190/4518] 70% | Training loss: 0.6869697453086279
Epoch: 88 | Iteration number: [3200/4518] 70% | Training loss: 0.6869644394516945
Epoch: 88 | Iteration number: [3210/4518] 71% | Training loss: 0.6869604544847554
Epoch: 88 | Iteration number: [3220/4518] 71% | Training loss: 0.6869620032562233
Epoch: 88 | Iteration number: [3230/4518] 71% | Training loss: 0.6869627227355083
Epoch: 88 | Iteration number: [3240/4518] 71% | Training loss: 0.6869661289968608
Epoch: 88 | Iteration number: [3250/4518] 71% | Training loss: 0.6869647272733541
Epoch: 88 | Iteration number: [3260/4518] 72% | Training loss: 0.6869659840329293
Epoch: 88 | Iteration number: [3270/4518] 72% | Training loss: 0.6869695245308249
Epoch: 88 | Iteration number: [3280/4518] 72% | Training loss: 0.6869745780055115
Epoch: 88 | Iteration number: [3290/4518] 72% | Training loss: 0.6869741645446302
Epoch: 88 | Iteration number: [3300/4518] 73% | Training loss: 0.6869756968996742
Epoch: 88 | Iteration number: [3310/4518] 73% | Training loss: 0.6869744330194422
Epoch: 88 | Iteration number: [3320/4518] 73% | Training loss: 0.6869773637278971
Epoch: 88 | Iteration number: [3330/4518] 73% | Training loss: 0.6869754018368306
Epoch: 88 | Iteration number: [3340/4518] 73% | Training loss: 0.6869752663338256
Epoch: 88 | Iteration number: [3350/4518] 74% | Training loss: 0.6869756128538901
Epoch: 88 | Iteration number: [3360/4518] 74% | Training loss: 0.6869737636830126
Epoch: 88 | Iteration number: [3370/4518] 74% | Training loss: 0.6869720307408171
Epoch: 88 | Iteration number: [3380/4518] 74% | Training loss: 0.6869714183567543
Epoch: 88 | Iteration number: [3390/4518] 75% | Training loss: 0.6869762476390794
Epoch: 88 | Iteration number: [3400/4518] 75% | Training loss: 0.6869755017231493
Epoch: 88 | Iteration number: [3410/4518] 75% | Training loss: 0.6869779578227102
Epoch: 88 | Iteration number: [3420/4518] 75% | Training loss: 0.6869783115840098
Epoch: 88 | Iteration number: [3430/4518] 75% | Training loss: 0.6869744203876128
Epoch: 88 | Iteration number: [3440/4518] 76% | Training loss: 0.686970738754716
Epoch: 88 | Iteration number: [3450/4518] 76% | Training loss: 0.6869723526809527
Epoch: 88 | Iteration number: [3460/4518] 76% | Training loss: 0.6869713736924132
Epoch: 88 | Iteration number: [3470/4518] 76% | Training loss: 0.686969180117423
Epoch: 88 | Iteration number: [3480/4518] 77% | Training loss: 0.6869650166952747
Epoch: 88 | Iteration number: [3490/4518] 77% | Training loss: 0.6869639596829783
Epoch: 88 | Iteration number: [3500/4518] 77% | Training loss: 0.6869654302086149
Epoch: 88 | Iteration number: [3510/4518] 77% | Training loss: 0.6869637228145219
Epoch: 88 | Iteration number: [3520/4518] 77% | Training loss: 0.6869637164033272
Epoch: 88 | Iteration number: [3530/4518] 78% | Training loss: 0.6869635681423857
Epoch: 88 | Iteration number: [3540/4518] 78% | Training loss: 0.6869647576142166
Epoch: 88 | Iteration number: [3550/4518] 78% | Training loss: 0.6869616619633957
Epoch: 88 | Iteration number: [3560/4518] 78% | Training loss: 0.6869599058721843
Epoch: 88 | Iteration number: [3570/4518] 79% | Training loss: 0.6869567131795803
Epoch: 88 | Iteration number: [3580/4518] 79% | Training loss: 0.6869569224851757
Epoch: 88 | Iteration number: [3590/4518] 79% | Training loss: 0.6869550674572629
Epoch: 88 | Iteration number: [3600/4518] 79% | Training loss: 0.686950034979317
Epoch: 88 | Iteration number: [3610/4518] 79% | Training loss: 0.6869506105986989
Epoch: 88 | Iteration number: [3620/4518] 80% | Training loss: 0.6869503356310545
Epoch: 88 | Iteration number: [3630/4518] 80% | Training loss: 0.6869506764346246
Epoch: 88 | Iteration number: [3640/4518] 80% | Training loss: 0.6869518007878419
Epoch: 88 | Iteration number: [3650/4518] 80% | Training loss: 0.6869525299006946
Epoch: 88 | Iteration number: [3660/4518] 81% | Training loss: 0.686954037022721
Epoch: 88 | Iteration number: [3670/4518] 81% | Training loss: 0.686950774641063
Epoch: 88 | Iteration number: [3680/4518] 81% | Training loss: 0.6869509180764789
Epoch: 88 | Iteration number: [3690/4518] 81% | Training loss: 0.6869507357195463
Epoch: 88 | Iteration number: [3700/4518] 81% | Training loss: 0.6869496194736378
Epoch: 88 | Iteration number: [3710/4518] 82% | Training loss: 0.6869518268461818
Epoch: 88 | Iteration number: [3720/4518] 82% | Training loss: 0.6869548597322997
Epoch: 88 | Iteration number: [3730/4518] 82% | Training loss: 0.6869509719491964
Epoch: 88 | Iteration number: [3740/4518] 82% | Training loss: 0.6869518372783049
Epoch: 88 | Iteration number: [3750/4518] 83% | Training loss: 0.6869504223346711
Epoch: 88 | Iteration number: [3760/4518] 83% | Training loss: 0.6869460264101942
Epoch: 88 | Iteration number: [3770/4518] 83% | Training loss: 0.6869415907549922
Epoch: 88 | Iteration number: [3780/4518] 83% | Training loss: 0.6869427116301955
Epoch: 88 | Iteration number: [3790/4518] 83% | Training loss: 0.6869384693281632
Epoch: 88 | Iteration number: [3800/4518] 84% | Training loss: 0.6869390181334395
Epoch: 88 | Iteration number: [3810/4518] 84% | Training loss: 0.6869405501001463
Epoch: 88 | Iteration number: [3820/4518] 84% | Training loss: 0.6869402813661785
Epoch: 88 | Iteration number: [3830/4518] 84% | Training loss: 0.6869377969917367
Epoch: 88 | Iteration number: [3840/4518] 84% | Training loss: 0.6869378058550258
Epoch: 88 | Iteration number: [3850/4518] 85% | Training loss: 0.6869383098707571
Epoch: 88 | Iteration number: [3860/4518] 85% | Training loss: 0.6869335933824895
Epoch: 88 | Iteration number: [3870/4518] 85% | Training loss: 0.6869312243560179
Epoch: 88 | Iteration number: [3880/4518] 85% | Training loss: 0.6869311893723674
Epoch: 88 | Iteration number: [3890/4518] 86% | Training loss: 0.6869320008779246
Epoch: 88 | Iteration number: [3900/4518] 86% | Training loss: 0.6869277526476444
Epoch: 88 | Iteration number: [3910/4518] 86% | Training loss: 0.6869296390991991
Epoch: 88 | Iteration number: [3920/4518] 86% | Training loss: 0.6869253977068833
Epoch: 88 | Iteration number: [3930/4518] 86% | Training loss: 0.6869239518660626
Epoch: 88 | Iteration number: [3940/4518] 87% | Training loss: 0.6869246233387042
Epoch: 88 | Iteration number: [3950/4518] 87% | Training loss: 0.6869220714176757
Epoch: 88 | Iteration number: [3960/4518] 87% | Training loss: 0.6869198051215423
Epoch: 88 | Iteration number: [3970/4518] 87% | Training loss: 0.6869195550454954
Epoch: 88 | Iteration number: [3980/4518] 88% | Training loss: 0.6869215466868338
Epoch: 88 | Iteration number: [3990/4518] 88% | Training loss: 0.6869230855676465
Epoch: 88 | Iteration number: [4000/4518] 88% | Training loss: 0.6869266268163919
Epoch: 88 | Iteration number: [4010/4518] 88% | Training loss: 0.6869293682295783
Epoch: 88 | Iteration number: [4020/4518] 88% | Training loss: 0.6869310465321612
Epoch: 88 | Iteration number: [4030/4518] 89% | Training loss: 0.6869306038538221
Epoch: 88 | Iteration number: [4040/4518] 89% | Training loss: 0.6869295366772331
Epoch: 88 | Iteration number: [4050/4518] 89% | Training loss: 0.6869281955412877
Epoch: 88 | Iteration number: [4060/4518] 89% | Training loss: 0.686925072314704
Epoch: 88 | Iteration number: [4070/4518] 90% | Training loss: 0.6869246082751113
Epoch: 88 | Iteration number: [4080/4518] 90% | Training loss: 0.6869244687843556
Epoch: 88 | Iteration number: [4090/4518] 90% | Training loss: 0.6869261115279349
Epoch: 88 | Iteration number: [4100/4518] 90% | Training loss: 0.6869243181333309
Epoch: 88 | Iteration number: [4110/4518] 90% | Training loss: 0.6869254834025446
Epoch: 88 | Iteration number: [4120/4518] 91% | Training loss: 0.6869273276149648
Epoch: 88 | Iteration number: [4130/4518] 91% | Training loss: 0.6869244674504813
Epoch: 88 | Iteration number: [4140/4518] 91% | Training loss: 0.6869271776814392
Epoch: 88 | Iteration number: [4150/4518] 91% | Training loss: 0.6869266610116844
Epoch: 88 | Iteration number: [4160/4518] 92% | Training loss: 0.6869281963373606
Epoch: 88 | Iteration number: [4170/4518] 92% | Training loss: 0.6869269030986073
Epoch: 88 | Iteration number: [4180/4518] 92% | Training loss: 0.6869237701573441
Epoch: 88 | Iteration number: [4190/4518] 92% | Training loss: 0.6869236699152107
Epoch: 88 | Iteration number: [4200/4518] 92% | Training loss: 0.6869244666468529
Epoch: 88 | Iteration number: [4210/4518] 93% | Training loss: 0.6869251365899474
Epoch: 88 | Iteration number: [4220/4518] 93% | Training loss: 0.6869224276164132
Epoch: 88 | Iteration number: [4230/4518] 93% | Training loss: 0.6869228600610232
Epoch: 88 | Iteration number: [4240/4518] 93% | Training loss: 0.6869225550934953
Epoch: 88 | Iteration number: [4250/4518] 94% | Training loss: 0.6869216911933002
Epoch: 88 | Iteration number: [4260/4518] 94% | Training loss: 0.6869182810537132
Epoch: 88 | Iteration number: [4270/4518] 94% | Training loss: 0.6869188587196537
Epoch: 88 | Iteration number: [4280/4518] 94% | Training loss: 0.6869164905119165
Epoch: 88 | Iteration number: [4290/4518] 94% | Training loss: 0.6869173402830715
Epoch: 88 | Iteration number: [4300/4518] 95% | Training loss: 0.6869176608878512
Epoch: 88 | Iteration number: [4310/4518] 95% | Training loss: 0.6869165432287203
Epoch: 88 | Iteration number: [4320/4518] 95% | Training loss: 0.6869171317252848
Epoch: 88 | Iteration number: [4330/4518] 95% | Training loss: 0.6869162965729385
Epoch: 88 | Iteration number: [4340/4518] 96% | Training loss: 0.6869139413954476
Epoch: 88 | Iteration number: [4350/4518] 96% | Training loss: 0.6869135706726162
Epoch: 88 | Iteration number: [4360/4518] 96% | Training loss: 0.6869135958612512
Epoch: 88 | Iteration number: [4370/4518] 96% | Training loss: 0.6869129904484039
Epoch: 88 | Iteration number: [4380/4518] 96% | Training loss: 0.6869130608425837
Epoch: 88 | Iteration number: [4390/4518] 97% | Training loss: 0.6869157453332784
Epoch: 88 | Iteration number: [4400/4518] 97% | Training loss: 0.6869141492112116
Epoch: 88 | Iteration number: [4410/4518] 97% | Training loss: 0.6869138352184339
Epoch: 88 | Iteration number: [4420/4518] 97% | Training loss: 0.6869167964652653
Epoch: 88 | Iteration number: [4430/4518] 98% | Training loss: 0.6869134709609013
Epoch: 88 | Iteration number: [4440/4518] 98% | Training loss: 0.6869120735977147
Epoch: 88 | Iteration number: [4450/4518] 98% | Training loss: 0.6869123817963546
Epoch: 88 | Iteration number: [4460/4518] 98% | Training loss: 0.6869123944252595
Epoch: 88 | Iteration number: [4470/4518] 98% | Training loss: 0.6869111355519135
Epoch: 88 | Iteration number: [4480/4518] 99% | Training loss: 0.686910005725388
Epoch: 88 | Iteration number: [4490/4518] 99% | Training loss: 0.6869096608363706
Epoch: 88 | Iteration number: [4500/4518] 99% | Training loss: 0.6869124935335583
Epoch: 88 | Iteration number: [4510/4518] 99% | Training loss: 0.686910961617916

 End of epoch: 88 | Train Loss: 0.6867630181849768 | Training Time: 630 

 End of epoch: 88 | Eval Loss: 0.6899822999020012 | Evaluating Time: 16 
Epoch: 89 | Iteration number: [10/4518] 0% | Training loss: 0.754310131072998
Epoch: 89 | Iteration number: [20/4518] 0% | Training loss: 0.7206884801387787
Epoch: 89 | Iteration number: [30/4518] 0% | Training loss: 0.709260618686676
Epoch: 89 | Iteration number: [40/4518] 0% | Training loss: 0.7036163523793221
Epoch: 89 | Iteration number: [50/4518] 1% | Training loss: 0.7000688648223877
Epoch: 89 | Iteration number: [60/4518] 1% | Training loss: 0.6980115950107575
Epoch: 89 | Iteration number: [70/4518] 1% | Training loss: 0.6964949752603259
Epoch: 89 | Iteration number: [80/4518] 1% | Training loss: 0.6953399129211902
Epoch: 89 | Iteration number: [90/4518] 1% | Training loss: 0.6942668716112773
Epoch: 89 | Iteration number: [100/4518] 2% | Training loss: 0.6934576708078385
Epoch: 89 | Iteration number: [110/4518] 2% | Training loss: 0.6929850930517371
Epoch: 89 | Iteration number: [120/4518] 2% | Training loss: 0.6925649250547091
Epoch: 89 | Iteration number: [130/4518] 2% | Training loss: 0.6920563170543084
Epoch: 89 | Iteration number: [140/4518] 3% | Training loss: 0.6917451926640101
Epoch: 89 | Iteration number: [150/4518] 3% | Training loss: 0.6914078454176585
Epoch: 89 | Iteration number: [160/4518] 3% | Training loss: 0.6910486321896314
Epoch: 89 | Iteration number: [170/4518] 3% | Training loss: 0.6907772239516763
Epoch: 89 | Iteration number: [180/4518] 3% | Training loss: 0.690462009774314
Epoch: 89 | Iteration number: [190/4518] 4% | Training loss: 0.6903425884874244
Epoch: 89 | Iteration number: [200/4518] 4% | Training loss: 0.6902384549379349
Epoch: 89 | Iteration number: [210/4518] 4% | Training loss: 0.690132581903821
Epoch: 89 | Iteration number: [220/4518] 4% | Training loss: 0.6899967174638402
Epoch: 89 | Iteration number: [230/4518] 5% | Training loss: 0.6898833225602689
Epoch: 89 | Iteration number: [240/4518] 5% | Training loss: 0.6897303824623425
Epoch: 89 | Iteration number: [250/4518] 5% | Training loss: 0.6896482942104339
Epoch: 89 | Iteration number: [260/4518] 5% | Training loss: 0.6895005448506428
Epoch: 89 | Iteration number: [270/4518] 5% | Training loss: 0.6894447825573109
Epoch: 89 | Iteration number: [280/4518] 6% | Training loss: 0.6893680781126023
Epoch: 89 | Iteration number: [290/4518] 6% | Training loss: 0.6892802150085054
Epoch: 89 | Iteration number: [300/4518] 6% | Training loss: 0.6892139518260956
Epoch: 89 | Iteration number: [310/4518] 6% | Training loss: 0.6891222578863944
Epoch: 89 | Iteration number: [320/4518] 7% | Training loss: 0.6890850733965636
Epoch: 89 | Iteration number: [330/4518] 7% | Training loss: 0.6889742159482205
Epoch: 89 | Iteration number: [340/4518] 7% | Training loss: 0.6888975106617984
Epoch: 89 | Iteration number: [350/4518] 7% | Training loss: 0.6888110504831586
Epoch: 89 | Iteration number: [360/4518] 7% | Training loss: 0.6887450650334358
Epoch: 89 | Iteration number: [370/4518] 8% | Training loss: 0.688695511946807
Epoch: 89 | Iteration number: [380/4518] 8% | Training loss: 0.6886588543653488
Epoch: 89 | Iteration number: [390/4518] 8% | Training loss: 0.6886439960736495
Epoch: 89 | Iteration number: [400/4518] 8% | Training loss: 0.6886097018420696
Epoch: 89 | Iteration number: [410/4518] 9% | Training loss: 0.6885717532983641
Epoch: 89 | Iteration number: [420/4518] 9% | Training loss: 0.6885158182609649
Epoch: 89 | Iteration number: [430/4518] 9% | Training loss: 0.6884661623211794
Epoch: 89 | Iteration number: [440/4518] 9% | Training loss: 0.6884484143419699
Epoch: 89 | Iteration number: [450/4518] 9% | Training loss: 0.6884256076812744
Epoch: 89 | Iteration number: [460/4518] 10% | Training loss: 0.6883811380552209
Epoch: 89 | Iteration number: [470/4518] 10% | Training loss: 0.6883273266731424
Epoch: 89 | Iteration number: [480/4518] 10% | Training loss: 0.6883051722000043
Epoch: 89 | Iteration number: [490/4518] 10% | Training loss: 0.6882721121213874
Epoch: 89 | Iteration number: [500/4518] 11% | Training loss: 0.6882772629261017
Epoch: 89 | Iteration number: [510/4518] 11% | Training loss: 0.6882208807795656
Epoch: 89 | Iteration number: [520/4518] 11% | Training loss: 0.6882040744790664
Epoch: 89 | Iteration number: [530/4518] 11% | Training loss: 0.6881766043743998
Epoch: 89 | Iteration number: [540/4518] 11% | Training loss: 0.688156838218371
Epoch: 89 | Iteration number: [550/4518] 12% | Training loss: 0.6881254041194915
Epoch: 89 | Iteration number: [560/4518] 12% | Training loss: 0.6880974840904985
Epoch: 89 | Iteration number: [570/4518] 12% | Training loss: 0.6880831642109051
Epoch: 89 | Iteration number: [580/4518] 12% | Training loss: 0.6880824811499694
Epoch: 89 | Iteration number: [590/4518] 13% | Training loss: 0.6880442492032455
Epoch: 89 | Iteration number: [600/4518] 13% | Training loss: 0.6880188866456349
Epoch: 89 | Iteration number: [610/4518] 13% | Training loss: 0.6880008568529223
Epoch: 89 | Iteration number: [620/4518] 13% | Training loss: 0.6879905118096259
Epoch: 89 | Iteration number: [630/4518] 13% | Training loss: 0.6879581938660334
Epoch: 89 | Iteration number: [640/4518] 14% | Training loss: 0.6879346842877567
Epoch: 89 | Iteration number: [650/4518] 14% | Training loss: 0.6879104089736938
Epoch: 89 | Iteration number: [660/4518] 14% | Training loss: 0.6879083055438417
Epoch: 89 | Iteration number: [670/4518] 14% | Training loss: 0.6878935275682763
Epoch: 89 | Iteration number: [680/4518] 15% | Training loss: 0.6878826232517466
Epoch: 89 | Iteration number: [690/4518] 15% | Training loss: 0.6878744715365811
Epoch: 89 | Iteration number: [700/4518] 15% | Training loss: 0.6878405940532685
Epoch: 89 | Iteration number: [710/4518] 15% | Training loss: 0.6878361059746272
Epoch: 89 | Iteration number: [720/4518] 15% | Training loss: 0.6878250190781222
Epoch: 89 | Iteration number: [730/4518] 16% | Training loss: 0.6878201719016245
Epoch: 89 | Iteration number: [740/4518] 16% | Training loss: 0.6878122524635212
Epoch: 89 | Iteration number: [750/4518] 16% | Training loss: 0.687780769109726
Epoch: 89 | Iteration number: [760/4518] 16% | Training loss: 0.6877622288308646
Epoch: 89 | Iteration number: [770/4518] 17% | Training loss: 0.6877499468914874
Epoch: 89 | Iteration number: [780/4518] 17% | Training loss: 0.6877299566299487
Epoch: 89 | Iteration number: [790/4518] 17% | Training loss: 0.6877078886273541
Epoch: 89 | Iteration number: [800/4518] 17% | Training loss: 0.687704600468278
Epoch: 89 | Iteration number: [810/4518] 17% | Training loss: 0.6876984489552769
Epoch: 89 | Iteration number: [820/4518] 18% | Training loss: 0.6876873221339249
Epoch: 89 | Iteration number: [830/4518] 18% | Training loss: 0.6876601680215583
Epoch: 89 | Iteration number: [840/4518] 18% | Training loss: 0.6876410611328625
Epoch: 89 | Iteration number: [850/4518] 18% | Training loss: 0.6876313853263855
Epoch: 89 | Iteration number: [860/4518] 19% | Training loss: 0.6876396800889525
Epoch: 89 | Iteration number: [870/4518] 19% | Training loss: 0.6876420247143713
Epoch: 89 | Iteration number: [880/4518] 19% | Training loss: 0.6876416589726101
Epoch: 89 | Iteration number: [890/4518] 19% | Training loss: 0.6876397284898865
Epoch: 89 | Iteration number: [900/4518] 19% | Training loss: 0.687631543411149
Epoch: 89 | Iteration number: [910/4518] 20% | Training loss: 0.6876074894443973
Epoch: 89 | Iteration number: [920/4518] 20% | Training loss: 0.6875878259539604
Epoch: 89 | Iteration number: [930/4518] 20% | Training loss: 0.6875828321262073
Epoch: 89 | Iteration number: [940/4518] 20% | Training loss: 0.6875581426189301
Epoch: 89 | Iteration number: [950/4518] 21% | Training loss: 0.6875511557804911
Epoch: 89 | Iteration number: [960/4518] 21% | Training loss: 0.6875476624195774
Epoch: 89 | Iteration number: [970/4518] 21% | Training loss: 0.6875391808981748
Epoch: 89 | Iteration number: [980/4518] 21% | Training loss: 0.6875299832650593
Epoch: 89 | Iteration number: [990/4518] 21% | Training loss: 0.6875211593478617
Epoch: 89 | Iteration number: [1000/4518] 22% | Training loss: 0.6875174923539161
Epoch: 89 | Iteration number: [1010/4518] 22% | Training loss: 0.6875114650419443
Epoch: 89 | Iteration number: [1020/4518] 22% | Training loss: 0.6875091244777044
Epoch: 89 | Iteration number: [1030/4518] 22% | Training loss: 0.6875107034317498
Epoch: 89 | Iteration number: [1040/4518] 23% | Training loss: 0.6874829833324139
Epoch: 89 | Iteration number: [1050/4518] 23% | Training loss: 0.6874862174760727
Epoch: 89 | Iteration number: [1060/4518] 23% | Training loss: 0.6874543920440493
Epoch: 89 | Iteration number: [1070/4518] 23% | Training loss: 0.6874349909408071
Epoch: 89 | Iteration number: [1080/4518] 23% | Training loss: 0.687426990877699
Epoch: 89 | Iteration number: [1090/4518] 24% | Training loss: 0.687423852878973
Epoch: 89 | Iteration number: [1100/4518] 24% | Training loss: 0.6874108926274559
Epoch: 89 | Iteration number: [1110/4518] 24% | Training loss: 0.687401508425807
Epoch: 89 | Iteration number: [1120/4518] 24% | Training loss: 0.6874061672815255
Epoch: 89 | Iteration number: [1130/4518] 25% | Training loss: 0.6873988787157346
Epoch: 89 | Iteration number: [1140/4518] 25% | Training loss: 0.6873961611275088
Epoch: 89 | Iteration number: [1150/4518] 25% | Training loss: 0.6873876536410788
Epoch: 89 | Iteration number: [1160/4518] 25% | Training loss: 0.6873811295834081
Epoch: 89 | Iteration number: [1170/4518] 25% | Training loss: 0.6873647238454248
Epoch: 89 | Iteration number: [1180/4518] 26% | Training loss: 0.6873614083407289
Epoch: 89 | Iteration number: [1190/4518] 26% | Training loss: 0.6873601651993119
Epoch: 89 | Iteration number: [1200/4518] 26% | Training loss: 0.687359350224336
Epoch: 89 | Iteration number: [1210/4518] 26% | Training loss: 0.6873531084415341
Epoch: 89 | Iteration number: [1220/4518] 27% | Training loss: 0.6873485818261006
Epoch: 89 | Iteration number: [1230/4518] 27% | Training loss: 0.6873448580261169
Epoch: 89 | Iteration number: [1240/4518] 27% | Training loss: 0.6873430228041064
Epoch: 89 | Iteration number: [1250/4518] 27% | Training loss: 0.6873384115695953
Epoch: 89 | Iteration number: [1260/4518] 27% | Training loss: 0.6873298094386147
Epoch: 89 | Iteration number: [1270/4518] 28% | Training loss: 0.6873223484501125
Epoch: 89 | Iteration number: [1280/4518] 28% | Training loss: 0.6873100634664298
Epoch: 89 | Iteration number: [1290/4518] 28% | Training loss: 0.6873097201188405
Epoch: 89 | Iteration number: [1300/4518] 28% | Training loss: 0.6873059576749802
Epoch: 89 | Iteration number: [1310/4518] 28% | Training loss: 0.6873096653068339
Epoch: 89 | Iteration number: [1320/4518] 29% | Training loss: 0.6873104937600367
Epoch: 89 | Iteration number: [1330/4518] 29% | Training loss: 0.6873016652756168
Epoch: 89 | Iteration number: [1340/4518] 29% | Training loss: 0.6873051601114558
Epoch: 89 | Iteration number: [1350/4518] 29% | Training loss: 0.6872942273705094
Epoch: 89 | Iteration number: [1360/4518] 30% | Training loss: 0.6872899819384602
Epoch: 89 | Iteration number: [1370/4518] 30% | Training loss: 0.6872847081970994
Epoch: 89 | Iteration number: [1380/4518] 30% | Training loss: 0.6872778196265732
Epoch: 89 | Iteration number: [1390/4518] 30% | Training loss: 0.6872692928468581
Epoch: 89 | Iteration number: [1400/4518] 30% | Training loss: 0.6872667748161725
Epoch: 89 | Iteration number: [1410/4518] 31% | Training loss: 0.6872581327637882
Epoch: 89 | Iteration number: [1420/4518] 31% | Training loss: 0.6872657906421473
Epoch: 89 | Iteration number: [1430/4518] 31% | Training loss: 0.6872625643139952
Epoch: 89 | Iteration number: [1440/4518] 31% | Training loss: 0.6872678837842412
Epoch: 89 | Iteration number: [1450/4518] 32% | Training loss: 0.6872504901063853
Epoch: 89 | Iteration number: [1460/4518] 32% | Training loss: 0.6872392088991321
Epoch: 89 | Iteration number: [1470/4518] 32% | Training loss: 0.6872312460221401
Epoch: 89 | Iteration number: [1480/4518] 32% | Training loss: 0.6872343008985391
Epoch: 89 | Iteration number: [1490/4518] 32% | Training loss: 0.687233013034667
Epoch: 89 | Iteration number: [1500/4518] 33% | Training loss: 0.6872220532099406
Epoch: 89 | Iteration number: [1510/4518] 33% | Training loss: 0.6872089560852935
Epoch: 89 | Iteration number: [1520/4518] 33% | Training loss: 0.6872086217528895
Epoch: 89 | Iteration number: [1530/4518] 33% | Training loss: 0.6872131251431758
Epoch: 89 | Iteration number: [1540/4518] 34% | Training loss: 0.6872117313858751
Epoch: 89 | Iteration number: [1550/4518] 34% | Training loss: 0.6872078040722878
Epoch: 89 | Iteration number: [1560/4518] 34% | Training loss: 0.6872047456793297
Epoch: 89 | Iteration number: [1570/4518] 34% | Training loss: 0.6871906189781845
Epoch: 89 | Iteration number: [1580/4518] 34% | Training loss: 0.6871903807679309
Epoch: 89 | Iteration number: [1590/4518] 35% | Training loss: 0.6871906829705028
Epoch: 89 | Iteration number: [1600/4518] 35% | Training loss: 0.6871880689263343
Epoch: 89 | Iteration number: [1610/4518] 35% | Training loss: 0.6871866405380439
Epoch: 89 | Iteration number: [1620/4518] 35% | Training loss: 0.6871881182546968
Epoch: 89 | Iteration number: [1630/4518] 36% | Training loss: 0.6871932192814131
Epoch: 89 | Iteration number: [1640/4518] 36% | Training loss: 0.6871928473434797
Epoch: 89 | Iteration number: [1650/4518] 36% | Training loss: 0.6871916181752176
Epoch: 89 | Iteration number: [1660/4518] 36% | Training loss: 0.6871860473989004
Epoch: 89 | Iteration number: [1670/4518] 36% | Training loss: 0.6871873241341756
Epoch: 89 | Iteration number: [1680/4518] 37% | Training loss: 0.687186505255245
Epoch: 89 | Iteration number: [1690/4518] 37% | Training loss: 0.6871787219357913
Epoch: 89 | Iteration number: [1700/4518] 37% | Training loss: 0.6871677603791742
Epoch: 89 | Iteration number: [1710/4518] 37% | Training loss: 0.6871631731415353
Epoch: 89 | Iteration number: [1720/4518] 38% | Training loss: 0.6871600960922796
Epoch: 89 | Iteration number: [1730/4518] 38% | Training loss: 0.6871600800856
Epoch: 89 | Iteration number: [1740/4518] 38% | Training loss: 0.6871643261662845
Epoch: 89 | Iteration number: [1750/4518] 38% | Training loss: 0.6871580073152269
Epoch: 89 | Iteration number: [1760/4518] 38% | Training loss: 0.6871571469374679
Epoch: 89 | Iteration number: [1770/4518] 39% | Training loss: 0.6871484823819608
Epoch: 89 | Iteration number: [1780/4518] 39% | Training loss: 0.6871485706125753
Epoch: 89 | Iteration number: [1790/4518] 39% | Training loss: 0.6871477341185734
Epoch: 89 | Iteration number: [1800/4518] 39% | Training loss: 0.687147388458252
Epoch: 89 | Iteration number: [1810/4518] 40% | Training loss: 0.6871408159232272
Epoch: 89 | Iteration number: [1820/4518] 40% | Training loss: 0.6871331695999418
Epoch: 89 | Iteration number: [1830/4518] 40% | Training loss: 0.6871279968590033
Epoch: 89 | Iteration number: [1840/4518] 40% | Training loss: 0.6871286268791427
Epoch: 89 | Iteration number: [1850/4518] 40% | Training loss: 0.6871290849994969
Epoch: 89 | Iteration number: [1860/4518] 41% | Training loss: 0.6871349553908072
Epoch: 89 | Iteration number: [1870/4518] 41% | Training loss: 0.6871253503835137
Epoch: 89 | Iteration number: [1880/4518] 41% | Training loss: 0.6871236311628464
Epoch: 89 | Iteration number: [1890/4518] 41% | Training loss: 0.6871124760499077
Epoch: 89 | Iteration number: [1900/4518] 42% | Training loss: 0.6871116659829491
Epoch: 89 | Iteration number: [1910/4518] 42% | Training loss: 0.6871018296136906
Epoch: 89 | Iteration number: [1920/4518] 42% | Training loss: 0.687096024521937
Epoch: 89 | Iteration number: [1930/4518] 42% | Training loss: 0.6870963499644878
Epoch: 89 | Iteration number: [1940/4518] 42% | Training loss: 0.6870903313467183
Epoch: 89 | Iteration number: [1950/4518] 43% | Training loss: 0.6870922344770187
Epoch: 89 | Iteration number: [1960/4518] 43% | Training loss: 0.6870856098678647
Epoch: 89 | Iteration number: [1970/4518] 43% | Training loss: 0.6870833580566542
Epoch: 89 | Iteration number: [1980/4518] 43% | Training loss: 0.6870859538364892
Epoch: 89 | Iteration number: [1990/4518] 44% | Training loss: 0.6870876951433307
Epoch: 89 | Iteration number: [2000/4518] 44% | Training loss: 0.687086337864399
Epoch: 89 | Iteration number: [2010/4518] 44% | Training loss: 0.6870832021260143
Epoch: 89 | Iteration number: [2020/4518] 44% | Training loss: 0.68708649139003
Epoch: 89 | Iteration number: [2030/4518] 44% | Training loss: 0.6870871915312237
Epoch: 89 | Iteration number: [2040/4518] 45% | Training loss: 0.6870843770749429
Epoch: 89 | Iteration number: [2050/4518] 45% | Training loss: 0.6870857199226937
Epoch: 89 | Iteration number: [2060/4518] 45% | Training loss: 0.6870806233107465
Epoch: 89 | Iteration number: [2070/4518] 45% | Training loss: 0.6870844087450977
Epoch: 89 | Iteration number: [2080/4518] 46% | Training loss: 0.6870857431338384
Epoch: 89 | Iteration number: [2090/4518] 46% | Training loss: 0.6870888103993886
Epoch: 89 | Iteration number: [2100/4518] 46% | Training loss: 0.6870874791769754
Epoch: 89 | Iteration number: [2110/4518] 46% | Training loss: 0.687088849194242
Epoch: 89 | Iteration number: [2120/4518] 46% | Training loss: 0.6870896122646781
Epoch: 89 | Iteration number: [2130/4518] 47% | Training loss: 0.687087559895896
Epoch: 89 | Iteration number: [2140/4518] 47% | Training loss: 0.6870897204519433
Epoch: 89 | Iteration number: [2150/4518] 47% | Training loss: 0.6870889709439388
Epoch: 89 | Iteration number: [2160/4518] 47% | Training loss: 0.6870865518020259
Epoch: 89 | Iteration number: [2170/4518] 48% | Training loss: 0.6870784012952708
Epoch: 89 | Iteration number: [2180/4518] 48% | Training loss: 0.6870753239601031
Epoch: 89 | Iteration number: [2190/4518] 48% | Training loss: 0.6870733426586134
Epoch: 89 | Iteration number: [2200/4518] 48% | Training loss: 0.6870708824016831
Epoch: 89 | Iteration number: [2210/4518] 48% | Training loss: 0.68706577503843
Epoch: 89 | Iteration number: [2220/4518] 49% | Training loss: 0.6870635798385551
Epoch: 89 | Iteration number: [2230/4518] 49% | Training loss: 0.687061182853887
Epoch: 89 | Iteration number: [2240/4518] 49% | Training loss: 0.6870575602831585
Epoch: 89 | Iteration number: [2250/4518] 49% | Training loss: 0.6870548735194736
Epoch: 89 | Iteration number: [2260/4518] 50% | Training loss: 0.68705286589344
Epoch: 89 | Iteration number: [2270/4518] 50% | Training loss: 0.6870550862230393
Epoch: 89 | Iteration number: [2280/4518] 50% | Training loss: 0.6870497075873508
Epoch: 89 | Iteration number: [2290/4518] 50% | Training loss: 0.6870432915906198
Epoch: 89 | Iteration number: [2300/4518] 50% | Training loss: 0.6870425820091496
Epoch: 89 | Iteration number: [2310/4518] 51% | Training loss: 0.68704019485614
Epoch: 89 | Iteration number: [2320/4518] 51% | Training loss: 0.6870394058268646
Epoch: 89 | Iteration number: [2330/4518] 51% | Training loss: 0.6870343794382693
Epoch: 89 | Iteration number: [2340/4518] 51% | Training loss: 0.6870302600483609
Epoch: 89 | Iteration number: [2350/4518] 52% | Training loss: 0.6870304063025942
Epoch: 89 | Iteration number: [2360/4518] 52% | Training loss: 0.6870296186057188
Epoch: 89 | Iteration number: [2370/4518] 52% | Training loss: 0.6870300312585469
Epoch: 89 | Iteration number: [2380/4518] 52% | Training loss: 0.6870227282538134
Epoch: 89 | Iteration number: [2390/4518] 52% | Training loss: 0.6870235362561676
Epoch: 89 | Iteration number: [2400/4518] 53% | Training loss: 0.6870217383901278
Epoch: 89 | Iteration number: [2410/4518] 53% | Training loss: 0.6870201760802526
Epoch: 89 | Iteration number: [2420/4518] 53% | Training loss: 0.6870227968150919
Epoch: 89 | Iteration number: [2430/4518] 53% | Training loss: 0.6870199840745809
Epoch: 89 | Iteration number: [2440/4518] 54% | Training loss: 0.6870223911082158
Epoch: 89 | Iteration number: [2450/4518] 54% | Training loss: 0.6870199743582278
Epoch: 89 | Iteration number: [2460/4518] 54% | Training loss: 0.6870233007562839
Epoch: 89 | Iteration number: [2470/4518] 54% | Training loss: 0.6870228098712952
Epoch: 89 | Iteration number: [2480/4518] 54% | Training loss: 0.6870173596807064
Epoch: 89 | Iteration number: [2490/4518] 55% | Training loss: 0.6870185903037888
Epoch: 89 | Iteration number: [2500/4518] 55% | Training loss: 0.6870206191539764
Epoch: 89 | Iteration number: [2510/4518] 55% | Training loss: 0.6870211907117015
Epoch: 89 | Iteration number: [2520/4518] 55% | Training loss: 0.6870220395071166
Epoch: 89 | Iteration number: [2530/4518] 55% | Training loss: 0.6870250890613073
Epoch: 89 | Iteration number: [2540/4518] 56% | Training loss: 0.6870312389426344
Epoch: 89 | Iteration number: [2550/4518] 56% | Training loss: 0.6870270231190849
Epoch: 89 | Iteration number: [2560/4518] 56% | Training loss: 0.6870244579622522
Epoch: 89 | Iteration number: [2570/4518] 56% | Training loss: 0.6870294483487244
Epoch: 89 | Iteration number: [2580/4518] 57% | Training loss: 0.6870305985905404
Epoch: 89 | Iteration number: [2590/4518] 57% | Training loss: 0.6870289501996574
Epoch: 89 | Iteration number: [2600/4518] 57% | Training loss: 0.6870284911760917
Epoch: 89 | Iteration number: [2610/4518] 57% | Training loss: 0.6870243895556278
Epoch: 89 | Iteration number: [2620/4518] 57% | Training loss: 0.6870213780239338
Epoch: 89 | Iteration number: [2630/4518] 58% | Training loss: 0.6870241031900558
Epoch: 89 | Iteration number: [2640/4518] 58% | Training loss: 0.6870213403620503
Epoch: 89 | Iteration number: [2650/4518] 58% | Training loss: 0.6870207186689916
Epoch: 89 | Iteration number: [2660/4518] 58% | Training loss: 0.6870234015740846
Epoch: 89 | Iteration number: [2670/4518] 59% | Training loss: 0.6870159924253543
Epoch: 89 | Iteration number: [2680/4518] 59% | Training loss: 0.6870066946122184
Epoch: 89 | Iteration number: [2690/4518] 59% | Training loss: 0.6870074315585168
Epoch: 89 | Iteration number: [2700/4518] 59% | Training loss: 0.6870099978756021
Epoch: 89 | Iteration number: [2710/4518] 59% | Training loss: 0.6870097550078952
Epoch: 89 | Iteration number: [2720/4518] 60% | Training loss: 0.6870087397010888
Epoch: 89 | Iteration number: [2730/4518] 60% | Training loss: 0.6870043974219661
Epoch: 89 | Iteration number: [2740/4518] 60% | Training loss: 0.6870034719688178
Epoch: 89 | Iteration number: [2750/4518] 60% | Training loss: 0.6870070445320823
Epoch: 89 | Iteration number: [2760/4518] 61% | Training loss: 0.6870066511242287
Epoch: 89 | Iteration number: [2770/4518] 61% | Training loss: 0.6870061335365695
Epoch: 89 | Iteration number: [2780/4518] 61% | Training loss: 0.6869979890130407
Epoch: 89 | Iteration number: [2790/4518] 61% | Training loss: 0.6869978114695532
Epoch: 89 | Iteration number: [2800/4518] 61% | Training loss: 0.6869916965493134
Epoch: 89 | Iteration number: [2810/4518] 62% | Training loss: 0.6869917075617034
Epoch: 89 | Iteration number: [2820/4518] 62% | Training loss: 0.6869872794717762
Epoch: 89 | Iteration number: [2830/4518] 62% | Training loss: 0.686990267501703
Epoch: 89 | Iteration number: [2840/4518] 62% | Training loss: 0.686989194217702
Epoch: 89 | Iteration number: [2850/4518] 63% | Training loss: 0.6869880598888063
Epoch: 89 | Iteration number: [2860/4518] 63% | Training loss: 0.6869862925547819
Epoch: 89 | Iteration number: [2870/4518] 63% | Training loss: 0.6869878791973566
Epoch: 89 | Iteration number: [2880/4518] 63% | Training loss: 0.6869893696986966
Epoch: 89 | Iteration number: [2890/4518] 63% | Training loss: 0.6869921752119559
Epoch: 89 | Iteration number: [2900/4518] 64% | Training loss: 0.6869941483694931
Epoch: 89 | Iteration number: [2910/4518] 64% | Training loss: 0.6869926577171509
Epoch: 89 | Iteration number: [2920/4518] 64% | Training loss: 0.6869934998350601
Epoch: 89 | Iteration number: [2930/4518] 64% | Training loss: 0.6869943082739469
Epoch: 89 | Iteration number: [2940/4518] 65% | Training loss: 0.6869942708283054
Epoch: 89 | Iteration number: [2950/4518] 65% | Training loss: 0.686993672180984
Epoch: 89 | Iteration number: [2960/4518] 65% | Training loss: 0.686994213510204
Epoch: 89 | Iteration number: [2970/4518] 65% | Training loss: 0.686993251284365
Epoch: 89 | Iteration number: [2980/4518] 65% | Training loss: 0.6869904014888226
Epoch: 89 | Iteration number: [2990/4518] 66% | Training loss: 0.6869852336752773
Epoch: 89 | Iteration number: [3000/4518] 66% | Training loss: 0.6869831788341204
Epoch: 89 | Iteration number: [3010/4518] 66% | Training loss: 0.6869779365403311
Epoch: 89 | Iteration number: [3020/4518] 66% | Training loss: 0.6869782886757756
Epoch: 89 | Iteration number: [3030/4518] 67% | Training loss: 0.6869784843016772
Epoch: 89 | Iteration number: [3040/4518] 67% | Training loss: 0.6869751164787694
Epoch: 89 | Iteration number: [3050/4518] 67% | Training loss: 0.6869724753450175
Epoch: 89 | Iteration number: [3060/4518] 67% | Training loss: 0.6869771195392983
Epoch: 89 | Iteration number: [3070/4518] 67% | Training loss: 0.6869803405934126
Epoch: 89 | Iteration number: [3080/4518] 68% | Training loss: 0.6869830403815617
Epoch: 89 | Iteration number: [3090/4518] 68% | Training loss: 0.6869751249702232
Epoch: 89 | Iteration number: [3100/4518] 68% | Training loss: 0.6869736397458661
Epoch: 89 | Iteration number: [3110/4518] 68% | Training loss: 0.686975960198706
Epoch: 89 | Iteration number: [3120/4518] 69% | Training loss: 0.6869742400753193
Epoch: 89 | Iteration number: [3130/4518] 69% | Training loss: 0.6869752498861319
Epoch: 89 | Iteration number: [3140/4518] 69% | Training loss: 0.6869739988047606
Epoch: 89 | Iteration number: [3150/4518] 69% | Training loss: 0.6869709285478743
Epoch: 89 | Iteration number: [3160/4518] 69% | Training loss: 0.6869679377803319
Epoch: 89 | Iteration number: [3170/4518] 70% | Training loss: 0.686966023704607
Epoch: 89 | Iteration number: [3180/4518] 70% | Training loss: 0.6869630611730072
Epoch: 89 | Iteration number: [3190/4518] 70% | Training loss: 0.686962554148372
Epoch: 89 | Iteration number: [3200/4518] 70% | Training loss: 0.6869641141220927
Epoch: 89 | Iteration number: [3210/4518] 71% | Training loss: 0.6869642605477033
Epoch: 89 | Iteration number: [3220/4518] 71% | Training loss: 0.6869599250903041
Epoch: 89 | Iteration number: [3230/4518] 71% | Training loss: 0.6869598034550162
Epoch: 89 | Iteration number: [3240/4518] 71% | Training loss: 0.6869598534188153
Epoch: 89 | Iteration number: [3250/4518] 71% | Training loss: 0.6869600376899426
Epoch: 89 | Iteration number: [3260/4518] 72% | Training loss: 0.6869559808011435
Epoch: 89 | Iteration number: [3270/4518] 72% | Training loss: 0.6869599635083377
Epoch: 89 | Iteration number: [3280/4518] 72% | Training loss: 0.6869562097620673
Epoch: 89 | Iteration number: [3290/4518] 72% | Training loss: 0.6869551740156481
Epoch: 89 | Iteration number: [3300/4518] 73% | Training loss: 0.6869530805493846
Epoch: 89 | Iteration number: [3310/4518] 73% | Training loss: 0.6869547551672264
Epoch: 89 | Iteration number: [3320/4518] 73% | Training loss: 0.6869562064667782
Epoch: 89 | Iteration number: [3330/4518] 73% | Training loss: 0.6869534841707877
Epoch: 89 | Iteration number: [3340/4518] 73% | Training loss: 0.6869513778986331
Epoch: 89 | Iteration number: [3350/4518] 74% | Training loss: 0.6869496673256603
Epoch: 89 | Iteration number: [3360/4518] 74% | Training loss: 0.6869505929804983
Epoch: 89 | Iteration number: [3370/4518] 74% | Training loss: 0.6869447478200986
Epoch: 89 | Iteration number: [3380/4518] 74% | Training loss: 0.686943949256423
Epoch: 89 | Iteration number: [3390/4518] 75% | Training loss: 0.6869452019005047
Epoch: 89 | Iteration number: [3400/4518] 75% | Training loss: 0.6869485904539333
Epoch: 89 | Iteration number: [3410/4518] 75% | Training loss: 0.6869458891779097
Epoch: 89 | Iteration number: [3420/4518] 75% | Training loss: 0.6869480291653794
Epoch: 89 | Iteration number: [3430/4518] 75% | Training loss: 0.6869499646539938
Epoch: 89 | Iteration number: [3440/4518] 76% | Training loss: 0.6869524793915971
Epoch: 89 | Iteration number: [3450/4518] 76% | Training loss: 0.6869556956014772
Epoch: 89 | Iteration number: [3460/4518] 76% | Training loss: 0.6869579474533224
Epoch: 89 | Iteration number: [3470/4518] 76% | Training loss: 0.6869586544181153
Epoch: 89 | Iteration number: [3480/4518] 77% | Training loss: 0.6869585084332817
Epoch: 89 | Iteration number: [3490/4518] 77% | Training loss: 0.6869592457070391
Epoch: 89 | Iteration number: [3500/4518] 77% | Training loss: 0.6869561842679978
Epoch: 89 | Iteration number: [3510/4518] 77% | Training loss: 0.6869567772771559
Epoch: 89 | Iteration number: [3520/4518] 77% | Training loss: 0.686956806904213
Epoch: 89 | Iteration number: [3530/4518] 78% | Training loss: 0.6869546131101614
Epoch: 89 | Iteration number: [3540/4518] 78% | Training loss: 0.6869518305285502
Epoch: 89 | Iteration number: [3550/4518] 78% | Training loss: 0.6869525441653292
Epoch: 89 | Iteration number: [3560/4518] 78% | Training loss: 0.6869499275858483
Epoch: 89 | Iteration number: [3570/4518] 79% | Training loss: 0.6869524002576075
Epoch: 89 | Iteration number: [3580/4518] 79% | Training loss: 0.6869488510173126
Epoch: 89 | Iteration number: [3590/4518] 79% | Training loss: 0.6869461449241904
Epoch: 89 | Iteration number: [3600/4518] 79% | Training loss: 0.6869453576538298
Epoch: 89 | Iteration number: [3610/4518] 79% | Training loss: 0.6869428028360298
Epoch: 89 | Iteration number: [3620/4518] 80% | Training loss: 0.6869457161887574
Epoch: 89 | Iteration number: [3630/4518] 80% | Training loss: 0.6869443203792099
Epoch: 89 | Iteration number: [3640/4518] 80% | Training loss: 0.6869452192724406
Epoch: 89 | Iteration number: [3650/4518] 80% | Training loss: 0.6869422627801764
Epoch: 89 | Iteration number: [3660/4518] 81% | Training loss: 0.6869416063763405
Epoch: 89 | Iteration number: [3670/4518] 81% | Training loss: 0.6869398587568579
Epoch: 89 | Iteration number: [3680/4518] 81% | Training loss: 0.6869389697585417
Epoch: 89 | Iteration number: [3690/4518] 81% | Training loss: 0.6869370402520911
Epoch: 89 | Iteration number: [3700/4518] 81% | Training loss: 0.686936718128823
Epoch: 89 | Iteration number: [3710/4518] 82% | Training loss: 0.6869387828114861
Epoch: 89 | Iteration number: [3720/4518] 82% | Training loss: 0.6869407125858851
Epoch: 89 | Iteration number: [3730/4518] 82% | Training loss: 0.686937708797148
Epoch: 89 | Iteration number: [3740/4518] 82% | Training loss: 0.6869359169414336
Epoch: 89 | Iteration number: [3750/4518] 83% | Training loss: 0.6869366920471192
Epoch: 89 | Iteration number: [3760/4518] 83% | Training loss: 0.6869375522307893
Epoch: 89 | Iteration number: [3770/4518] 83% | Training loss: 0.6869375558367459
Epoch: 89 | Iteration number: [3780/4518] 83% | Training loss: 0.6869368055194774
Epoch: 89 | Iteration number: [3790/4518] 83% | Training loss: 0.6869359378135299
Epoch: 89 | Iteration number: [3800/4518] 84% | Training loss: 0.6869352391675899
Epoch: 89 | Iteration number: [3810/4518] 84% | Training loss: 0.6869342345578151
Epoch: 89 | Iteration number: [3820/4518] 84% | Training loss: 0.6869345334968018
Epoch: 89 | Iteration number: [3830/4518] 84% | Training loss: 0.6869346218694283
Epoch: 89 | Iteration number: [3840/4518] 84% | Training loss: 0.6869349322902659
Epoch: 89 | Iteration number: [3850/4518] 85% | Training loss: 0.6869370429546802
Epoch: 89 | Iteration number: [3860/4518] 85% | Training loss: 0.686934593798583
Epoch: 89 | Iteration number: [3870/4518] 85% | Training loss: 0.6869321572380165
Epoch: 89 | Iteration number: [3880/4518] 85% | Training loss: 0.6869322409334871
Epoch: 89 | Iteration number: [3890/4518] 86% | Training loss: 0.6869331693741227
Epoch: 89 | Iteration number: [3900/4518] 86% | Training loss: 0.6869321540227303
Epoch: 89 | Iteration number: [3910/4518] 86% | Training loss: 0.6869308309939206
Epoch: 89 | Iteration number: [3920/4518] 86% | Training loss: 0.6869301400622543
Epoch: 89 | Iteration number: [3930/4518] 86% | Training loss: 0.6869298992114516
Epoch: 89 | Iteration number: [3940/4518] 87% | Training loss: 0.686930074576799
Epoch: 89 | Iteration number: [3950/4518] 87% | Training loss: 0.6869295265252077
Epoch: 89 | Iteration number: [3960/4518] 87% | Training loss: 0.686932036325787
Epoch: 89 | Iteration number: [3970/4518] 87% | Training loss: 0.6869295894048676
Epoch: 89 | Iteration number: [3980/4518] 88% | Training loss: 0.6869267858901814
Epoch: 89 | Iteration number: [3990/4518] 88% | Training loss: 0.6869268866111162
Epoch: 89 | Iteration number: [4000/4518] 88% | Training loss: 0.6869224337637424
Epoch: 89 | Iteration number: [4010/4518] 88% | Training loss: 0.6869216650204171
Epoch: 89 | Iteration number: [4020/4518] 88% | Training loss: 0.6869195724749446
Epoch: 89 | Iteration number: [4030/4518] 89% | Training loss: 0.6869195060901547
Epoch: 89 | Iteration number: [4040/4518] 89% | Training loss: 0.6869180589324176
Epoch: 89 | Iteration number: [4050/4518] 89% | Training loss: 0.686917424849522
Epoch: 89 | Iteration number: [4060/4518] 89% | Training loss: 0.6869168450532875
Epoch: 89 | Iteration number: [4070/4518] 90% | Training loss: 0.6869149555005957
Epoch: 89 | Iteration number: [4080/4518] 90% | Training loss: 0.6869189945944384
Epoch: 89 | Iteration number: [4090/4518] 90% | Training loss: 0.6869219191208445
Epoch: 89 | Iteration number: [4100/4518] 90% | Training loss: 0.6869190733897976
Epoch: 89 | Iteration number: [4110/4518] 90% | Training loss: 0.6869180481364258
Epoch: 89 | Iteration number: [4120/4518] 91% | Training loss: 0.686916446975134
Epoch: 89 | Iteration number: [4130/4518] 91% | Training loss: 0.6869179588974821
Epoch: 89 | Iteration number: [4140/4518] 91% | Training loss: 0.6869155083445535
Epoch: 89 | Iteration number: [4150/4518] 91% | Training loss: 0.6869174399720617
Epoch: 89 | Iteration number: [4160/4518] 92% | Training loss: 0.686916928867308
Epoch: 89 | Iteration number: [4170/4518] 92% | Training loss: 0.6869156531721567
Epoch: 89 | Iteration number: [4180/4518] 92% | Training loss: 0.6869123480679316
Epoch: 89 | Iteration number: [4190/4518] 92% | Training loss: 0.6869111631963589
Epoch: 89 | Iteration number: [4200/4518] 92% | Training loss: 0.6869092044376192
Epoch: 89 | Iteration number: [4210/4518] 93% | Training loss: 0.6869071175395168
Epoch: 89 | Iteration number: [4220/4518] 93% | Training loss: 0.6869063952381577
Epoch: 89 | Iteration number: [4230/4518] 93% | Training loss: 0.6869086885705907
Epoch: 89 | Iteration number: [4240/4518] 93% | Training loss: 0.6869057915401908
Epoch: 89 | Iteration number: [4250/4518] 94% | Training loss: 0.6869063119748059
Epoch: 89 | Iteration number: [4260/4518] 94% | Training loss: 0.6869065488867916
Epoch: 89 | Iteration number: [4270/4518] 94% | Training loss: 0.6869103556215345
Epoch: 89 | Iteration number: [4280/4518] 94% | Training loss: 0.6869109024232793
Epoch: 89 | Iteration number: [4290/4518] 94% | Training loss: 0.6869121176518482
Epoch: 89 | Iteration number: [4300/4518] 95% | Training loss: 0.6869128716962282
Epoch: 89 | Iteration number: [4310/4518] 95% | Training loss: 0.6869127998357583
Epoch: 89 | Iteration number: [4320/4518] 95% | Training loss: 0.6869086610360278
Epoch: 89 | Iteration number: [4330/4518] 95% | Training loss: 0.6869099619482186
Epoch: 89 | Iteration number: [4340/4518] 96% | Training loss: 0.6869085172903703
Epoch: 89 | Iteration number: [4350/4518] 96% | Training loss: 0.6869094225455975
Epoch: 89 | Iteration number: [4360/4518] 96% | Training loss: 0.686910424839466
Epoch: 89 | Iteration number: [4370/4518] 96% | Training loss: 0.6869116632561935
Epoch: 89 | Iteration number: [4380/4518] 96% | Training loss: 0.6869113066288979
Epoch: 89 | Iteration number: [4390/4518] 97% | Training loss: 0.6869127969806993
Epoch: 89 | Iteration number: [4400/4518] 97% | Training loss: 0.6869132799858396
Epoch: 89 | Iteration number: [4410/4518] 97% | Training loss: 0.686913909068724
Epoch: 89 | Iteration number: [4420/4518] 97% | Training loss: 0.6869146303084102
Epoch: 89 | Iteration number: [4430/4518] 98% | Training loss: 0.6869158640133877
Epoch: 89 | Iteration number: [4440/4518] 98% | Training loss: 0.6869158705478315
Epoch: 89 | Iteration number: [4450/4518] 98% | Training loss: 0.686914310267802
Epoch: 89 | Iteration number: [4460/4518] 98% | Training loss: 0.686913737561136
Epoch: 89 | Iteration number: [4470/4518] 98% | Training loss: 0.6869110339839987
Epoch: 89 | Iteration number: [4480/4518] 99% | Training loss: 0.6869135369014527
Epoch: 89 | Iteration number: [4490/4518] 99% | Training loss: 0.6869129102851341
Epoch: 89 | Iteration number: [4500/4518] 99% | Training loss: 0.6869135063489278
Epoch: 89 | Iteration number: [4510/4518] 99% | Training loss: 0.6869143152977041

 End of epoch: 89 | Train Loss: 0.6867638474388849 | Training Time: 632 

 End of epoch: 89 | Eval Loss: 0.6899622751741993 | Evaluating Time: 17 
Epoch: 90 | Iteration number: [10/4518] 0% | Training loss: 0.7560715138912201
Epoch: 90 | Iteration number: [20/4518] 0% | Training loss: 0.7214161276817321
Epoch: 90 | Iteration number: [30/4518] 0% | Training loss: 0.7095791916052501
Epoch: 90 | Iteration number: [40/4518] 0% | Training loss: 0.7041236624121666
Epoch: 90 | Iteration number: [50/4518] 1% | Training loss: 0.7005654335021972
Epoch: 90 | Iteration number: [60/4518] 1% | Training loss: 0.6981604019800822
Epoch: 90 | Iteration number: [70/4518] 1% | Training loss: 0.6965944758483342
Epoch: 90 | Iteration number: [80/4518] 1% | Training loss: 0.6954182900488377
Epoch: 90 | Iteration number: [90/4518] 1% | Training loss: 0.6945754455195533
Epoch: 90 | Iteration number: [100/4518] 2% | Training loss: 0.6939320611953735
Epoch: 90 | Iteration number: [110/4518] 2% | Training loss: 0.6933126747608185
Epoch: 90 | Iteration number: [120/4518] 2% | Training loss: 0.6926806191603343
Epoch: 90 | Iteration number: [130/4518] 2% | Training loss: 0.6923440497655134
Epoch: 90 | Iteration number: [140/4518] 3% | Training loss: 0.6919831931591034
Epoch: 90 | Iteration number: [150/4518] 3% | Training loss: 0.6916079819202423
Epoch: 90 | Iteration number: [160/4518] 3% | Training loss: 0.691300505772233
Epoch: 90 | Iteration number: [170/4518] 3% | Training loss: 0.6910276640863979
Epoch: 90 | Iteration number: [180/4518] 3% | Training loss: 0.6908076812823614
Epoch: 90 | Iteration number: [190/4518] 4% | Training loss: 0.6905613579248128
Epoch: 90 | Iteration number: [200/4518] 4% | Training loss: 0.6903398662805558
Epoch: 90 | Iteration number: [210/4518] 4% | Training loss: 0.6901763081550598
Epoch: 90 | Iteration number: [220/4518] 4% | Training loss: 0.6900308243253014
Epoch: 90 | Iteration number: [230/4518] 5% | Training loss: 0.6898887009724327
Epoch: 90 | Iteration number: [240/4518] 5% | Training loss: 0.6897361546754837
Epoch: 90 | Iteration number: [250/4518] 5% | Training loss: 0.689673285484314
Epoch: 90 | Iteration number: [260/4518] 5% | Training loss: 0.6895946523317924
Epoch: 90 | Iteration number: [270/4518] 5% | Training loss: 0.6895021127329932
Epoch: 90 | Iteration number: [280/4518] 6% | Training loss: 0.6894155630043575
Epoch: 90 | Iteration number: [290/4518] 6% | Training loss: 0.6893480948333083
Epoch: 90 | Iteration number: [300/4518] 6% | Training loss: 0.6892293115456899
Epoch: 90 | Iteration number: [310/4518] 6% | Training loss: 0.6891165673732758
Epoch: 90 | Iteration number: [320/4518] 7% | Training loss: 0.6890175944194198
Epoch: 90 | Iteration number: [330/4518] 7% | Training loss: 0.688955528085882
Epoch: 90 | Iteration number: [340/4518] 7% | Training loss: 0.688866143191562
Epoch: 90 | Iteration number: [350/4518] 7% | Training loss: 0.6887959946904864
Epoch: 90 | Iteration number: [360/4518] 7% | Training loss: 0.6887130338284705
Epoch: 90 | Iteration number: [370/4518] 8% | Training loss: 0.6886042694787722
Epoch: 90 | Iteration number: [380/4518] 8% | Training loss: 0.6885563433170319
Epoch: 90 | Iteration number: [390/4518] 8% | Training loss: 0.6884977458379208
Epoch: 90 | Iteration number: [400/4518] 8% | Training loss: 0.688428709357977
Epoch: 90 | Iteration number: [410/4518] 9% | Training loss: 0.6883996402345053
Epoch: 90 | Iteration number: [420/4518] 9% | Training loss: 0.688355510433515
Epoch: 90 | Iteration number: [430/4518] 9% | Training loss: 0.6883338610793269
Epoch: 90 | Iteration number: [440/4518] 9% | Training loss: 0.6882850716059858
Epoch: 90 | Iteration number: [450/4518] 9% | Training loss: 0.6882377530468835
Epoch: 90 | Iteration number: [460/4518] 10% | Training loss: 0.688166424891223
Epoch: 90 | Iteration number: [470/4518] 10% | Training loss: 0.6881460850543164
Epoch: 90 | Iteration number: [480/4518] 10% | Training loss: 0.6881119520713885
Epoch: 90 | Iteration number: [490/4518] 10% | Training loss: 0.6880620079381126
Epoch: 90 | Iteration number: [500/4518] 11% | Training loss: 0.6880430455207824
Epoch: 90 | Iteration number: [510/4518] 11% | Training loss: 0.6880409812226015
Epoch: 90 | Iteration number: [520/4518] 11% | Training loss: 0.688018044256247
Epoch: 90 | Iteration number: [530/4518] 11% | Training loss: 0.6879906736454874
Epoch: 90 | Iteration number: [540/4518] 11% | Training loss: 0.6879902411390234
Epoch: 90 | Iteration number: [550/4518] 12% | Training loss: 0.6879602686925368
Epoch: 90 | Iteration number: [560/4518] 12% | Training loss: 0.687955918269498
Epoch: 90 | Iteration number: [570/4518] 12% | Training loss: 0.6879269473385392
Epoch: 90 | Iteration number: [580/4518] 12% | Training loss: 0.6879138506692032
Epoch: 90 | Iteration number: [590/4518] 13% | Training loss: 0.6878957493830535
Epoch: 90 | Iteration number: [600/4518] 13% | Training loss: 0.687887676457564
Epoch: 90 | Iteration number: [610/4518] 13% | Training loss: 0.6878732095976345
Epoch: 90 | Iteration number: [620/4518] 13% | Training loss: 0.687853110317261
Epoch: 90 | Iteration number: [630/4518] 13% | Training loss: 0.6878521805717832
Epoch: 90 | Iteration number: [640/4518] 14% | Training loss: 0.687861941754818
Epoch: 90 | Iteration number: [650/4518] 14% | Training loss: 0.6878410807939677
Epoch: 90 | Iteration number: [660/4518] 14% | Training loss: 0.6878388969284115
Epoch: 90 | Iteration number: [670/4518] 14% | Training loss: 0.6878481637186079
Epoch: 90 | Iteration number: [680/4518] 15% | Training loss: 0.6878339214360013
Epoch: 90 | Iteration number: [690/4518] 15% | Training loss: 0.6878106919751651
Epoch: 90 | Iteration number: [700/4518] 15% | Training loss: 0.6877969861882074
Epoch: 90 | Iteration number: [710/4518] 15% | Training loss: 0.6877748466713328
Epoch: 90 | Iteration number: [720/4518] 15% | Training loss: 0.6877634776963129
Epoch: 90 | Iteration number: [730/4518] 16% | Training loss: 0.6877588902434257
Epoch: 90 | Iteration number: [740/4518] 16% | Training loss: 0.687756597593024
Epoch: 90 | Iteration number: [750/4518] 16% | Training loss: 0.6877507604757944
Epoch: 90 | Iteration number: [760/4518] 16% | Training loss: 0.687735503362982
Epoch: 90 | Iteration number: [770/4518] 17% | Training loss: 0.68772569027814
Epoch: 90 | Iteration number: [780/4518] 17% | Training loss: 0.6876983460707542
Epoch: 90 | Iteration number: [790/4518] 17% | Training loss: 0.6876751686198802
Epoch: 90 | Iteration number: [800/4518] 17% | Training loss: 0.6876601723581552
Epoch: 90 | Iteration number: [810/4518] 17% | Training loss: 0.6876602132379273
Epoch: 90 | Iteration number: [820/4518] 18% | Training loss: 0.6876412263730677
Epoch: 90 | Iteration number: [830/4518] 18% | Training loss: 0.6876321382551308
Epoch: 90 | Iteration number: [840/4518] 18% | Training loss: 0.6876167872831935
Epoch: 90 | Iteration number: [850/4518] 18% | Training loss: 0.6876133129175972
Epoch: 90 | Iteration number: [860/4518] 19% | Training loss: 0.6876060870497726
Epoch: 90 | Iteration number: [870/4518] 19% | Training loss: 0.6876023485057655
Epoch: 90 | Iteration number: [880/4518] 19% | Training loss: 0.6876007404517044
Epoch: 90 | Iteration number: [890/4518] 19% | Training loss: 0.6875954658127903
Epoch: 90 | Iteration number: [900/4518] 19% | Training loss: 0.6875811110602484
Epoch: 90 | Iteration number: [910/4518] 20% | Training loss: 0.6875770477803199
Epoch: 90 | Iteration number: [920/4518] 20% | Training loss: 0.687574196120967
Epoch: 90 | Iteration number: [930/4518] 20% | Training loss: 0.6875725468640687
Epoch: 90 | Iteration number: [940/4518] 20% | Training loss: 0.6875647527740357
Epoch: 90 | Iteration number: [950/4518] 21% | Training loss: 0.687548666753267
Epoch: 90 | Iteration number: [960/4518] 21% | Training loss: 0.6875515708078941
Epoch: 90 | Iteration number: [970/4518] 21% | Training loss: 0.6875444543730352
Epoch: 90 | Iteration number: [980/4518] 21% | Training loss: 0.6875426107523392
Epoch: 90 | Iteration number: [990/4518] 21% | Training loss: 0.6875467858531258
Epoch: 90 | Iteration number: [1000/4518] 22% | Training loss: 0.6875574094057083
Epoch: 90 | Iteration number: [1010/4518] 22% | Training loss: 0.6875439155219805
Epoch: 90 | Iteration number: [1020/4518] 22% | Training loss: 0.6875474680872524
Epoch: 90 | Iteration number: [1030/4518] 22% | Training loss: 0.6875402741640517
Epoch: 90 | Iteration number: [1040/4518] 23% | Training loss: 0.6875283745045845
Epoch: 90 | Iteration number: [1050/4518] 23% | Training loss: 0.6875276839733124
Epoch: 90 | Iteration number: [1060/4518] 23% | Training loss: 0.6875162331563122
Epoch: 90 | Iteration number: [1070/4518] 23% | Training loss: 0.6875013674531028
Epoch: 90 | Iteration number: [1080/4518] 23% | Training loss: 0.6875013099776374
Epoch: 90 | Iteration number: [1090/4518] 24% | Training loss: 0.6874981144699481
Epoch: 90 | Iteration number: [1100/4518] 24% | Training loss: 0.687493921897628
Epoch: 90 | Iteration number: [1110/4518] 24% | Training loss: 0.6874848983309291
Epoch: 90 | Iteration number: [1120/4518] 24% | Training loss: 0.6874821566045284
Epoch: 90 | Iteration number: [1130/4518] 25% | Training loss: 0.6874819999247526
Epoch: 90 | Iteration number: [1140/4518] 25% | Training loss: 0.6874855730617255
Epoch: 90 | Iteration number: [1150/4518] 25% | Training loss: 0.6874743251696877
Epoch: 90 | Iteration number: [1160/4518] 25% | Training loss: 0.6874771784605651
Epoch: 90 | Iteration number: [1170/4518] 25% | Training loss: 0.6874728133535792
Epoch: 90 | Iteration number: [1180/4518] 26% | Training loss: 0.6874675533529055
Epoch: 90 | Iteration number: [1190/4518] 26% | Training loss: 0.6874552150734332
Epoch: 90 | Iteration number: [1200/4518] 26% | Training loss: 0.6874421620865663
Epoch: 90 | Iteration number: [1210/4518] 26% | Training loss: 0.6874419109880432
Epoch: 90 | Iteration number: [1220/4518] 27% | Training loss: 0.6874380588531495
Epoch: 90 | Iteration number: [1230/4518] 27% | Training loss: 0.6874265415397117
Epoch: 90 | Iteration number: [1240/4518] 27% | Training loss: 0.6874252285207472
Epoch: 90 | Iteration number: [1250/4518] 27% | Training loss: 0.6874202356338501
Epoch: 90 | Iteration number: [1260/4518] 27% | Training loss: 0.6874267406879909
Epoch: 90 | Iteration number: [1270/4518] 28% | Training loss: 0.687416051081785
Epoch: 90 | Iteration number: [1280/4518] 28% | Training loss: 0.6874084623996168
Epoch: 90 | Iteration number: [1290/4518] 28% | Training loss: 0.6874080842779589
Epoch: 90 | Iteration number: [1300/4518] 28% | Training loss: 0.6874016534823638
Epoch: 90 | Iteration number: [1310/4518] 28% | Training loss: 0.6873935067471657
Epoch: 90 | Iteration number: [1320/4518] 29% | Training loss: 0.6873915071740295
Epoch: 90 | Iteration number: [1330/4518] 29% | Training loss: 0.6873866535219034
Epoch: 90 | Iteration number: [1340/4518] 29% | Training loss: 0.6873774327893756
Epoch: 90 | Iteration number: [1350/4518] 29% | Training loss: 0.6873833932699981
Epoch: 90 | Iteration number: [1360/4518] 30% | Training loss: 0.6873562418362673
Epoch: 90 | Iteration number: [1370/4518] 30% | Training loss: 0.6873502997586327
Epoch: 90 | Iteration number: [1380/4518] 30% | Training loss: 0.6873462851928628
Epoch: 90 | Iteration number: [1390/4518] 30% | Training loss: 0.6873321834656833
Epoch: 90 | Iteration number: [1400/4518] 30% | Training loss: 0.6873304402402469
Epoch: 90 | Iteration number: [1410/4518] 31% | Training loss: 0.6873178523905734
Epoch: 90 | Iteration number: [1420/4518] 31% | Training loss: 0.6873140287651143
Epoch: 90 | Iteration number: [1430/4518] 31% | Training loss: 0.687313585598152
Epoch: 90 | Iteration number: [1440/4518] 31% | Training loss: 0.687321822759178
Epoch: 90 | Iteration number: [1450/4518] 32% | Training loss: 0.6873266424803898
Epoch: 90 | Iteration number: [1460/4518] 32% | Training loss: 0.6873252297509207
Epoch: 90 | Iteration number: [1470/4518] 32% | Training loss: 0.6873181376732936
Epoch: 90 | Iteration number: [1480/4518] 32% | Training loss: 0.6873067707628817
Epoch: 90 | Iteration number: [1490/4518] 32% | Training loss: 0.68731782964412
Epoch: 90 | Iteration number: [1500/4518] 33% | Training loss: 0.6873133331139882
Epoch: 90 | Iteration number: [1510/4518] 33% | Training loss: 0.6873139896534926
Epoch: 90 | Iteration number: [1520/4518] 33% | Training loss: 0.6873104895416059
Epoch: 90 | Iteration number: [1530/4518] 33% | Training loss: 0.6873123812130074
Epoch: 90 | Iteration number: [1540/4518] 34% | Training loss: 0.6873051498617445
Epoch: 90 | Iteration number: [1550/4518] 34% | Training loss: 0.6872983658313752
Epoch: 90 | Iteration number: [1560/4518] 34% | Training loss: 0.6872914801805448
Epoch: 90 | Iteration number: [1570/4518] 34% | Training loss: 0.687291115180702
Epoch: 90 | Iteration number: [1580/4518] 34% | Training loss: 0.687279177353352
Epoch: 90 | Iteration number: [1590/4518] 35% | Training loss: 0.6872768039598405
Epoch: 90 | Iteration number: [1600/4518] 35% | Training loss: 0.6872744704410434
Epoch: 90 | Iteration number: [1610/4518] 35% | Training loss: 0.6872699928950079
Epoch: 90 | Iteration number: [1620/4518] 35% | Training loss: 0.6872790174719728
Epoch: 90 | Iteration number: [1630/4518] 36% | Training loss: 0.6872803098219304
Epoch: 90 | Iteration number: [1640/4518] 36% | Training loss: 0.6872808039551828
Epoch: 90 | Iteration number: [1650/4518] 36% | Training loss: 0.6872749315969872
Epoch: 90 | Iteration number: [1660/4518] 36% | Training loss: 0.6872651363711759
Epoch: 90 | Iteration number: [1670/4518] 36% | Training loss: 0.6872690152979183
Epoch: 90 | Iteration number: [1680/4518] 37% | Training loss: 0.6872675827926114
Epoch: 90 | Iteration number: [1690/4518] 37% | Training loss: 0.6872666732446682
Epoch: 90 | Iteration number: [1700/4518] 37% | Training loss: 0.6872593340803596
Epoch: 90 | Iteration number: [1710/4518] 37% | Training loss: 0.6872586386245594
Epoch: 90 | Iteration number: [1720/4518] 38% | Training loss: 0.6872499823570252
Epoch: 90 | Iteration number: [1730/4518] 38% | Training loss: 0.6872476495070264
Epoch: 90 | Iteration number: [1740/4518] 38% | Training loss: 0.6872420800143275
Epoch: 90 | Iteration number: [1750/4518] 38% | Training loss: 0.6872386647633144
Epoch: 90 | Iteration number: [1760/4518] 38% | Training loss: 0.6872394723987038
Epoch: 90 | Iteration number: [1770/4518] 39% | Training loss: 0.6872327387669666
Epoch: 90 | Iteration number: [1780/4518] 39% | Training loss: 0.6872232663162638
Epoch: 90 | Iteration number: [1790/4518] 39% | Training loss: 0.6872197457864964
Epoch: 90 | Iteration number: [1800/4518] 39% | Training loss: 0.6872083807984988
Epoch: 90 | Iteration number: [1810/4518] 40% | Training loss: 0.6872032065417885
Epoch: 90 | Iteration number: [1820/4518] 40% | Training loss: 0.6872052186793023
Epoch: 90 | Iteration number: [1830/4518] 40% | Training loss: 0.6871981082718229
Epoch: 90 | Iteration number: [1840/4518] 40% | Training loss: 0.6871938993425473
Epoch: 90 | Iteration number: [1850/4518] 40% | Training loss: 0.6871965115456967
Epoch: 90 | Iteration number: [1860/4518] 41% | Training loss: 0.6871865332126618
Epoch: 90 | Iteration number: [1870/4518] 41% | Training loss: 0.6871892256532761
Epoch: 90 | Iteration number: [1880/4518] 41% | Training loss: 0.6871830813745234
Epoch: 90 | Iteration number: [1890/4518] 41% | Training loss: 0.687178124227221
Epoch: 90 | Iteration number: [1900/4518] 42% | Training loss: 0.6871744487787548
Epoch: 90 | Iteration number: [1910/4518] 42% | Training loss: 0.6871745106437444
Epoch: 90 | Iteration number: [1920/4518] 42% | Training loss: 0.6871803710858028
Epoch: 90 | Iteration number: [1930/4518] 42% | Training loss: 0.6871816109190333
Epoch: 90 | Iteration number: [1940/4518] 42% | Training loss: 0.6871785882514777
Epoch: 90 | Iteration number: [1950/4518] 43% | Training loss: 0.6871715899614187
Epoch: 90 | Iteration number: [1960/4518] 43% | Training loss: 0.6871702286965993
Epoch: 90 | Iteration number: [1970/4518] 43% | Training loss: 0.6871686486423318
Epoch: 90 | Iteration number: [1980/4518] 43% | Training loss: 0.6871645637232848
Epoch: 90 | Iteration number: [1990/4518] 44% | Training loss: 0.6871600548825672
Epoch: 90 | Iteration number: [2000/4518] 44% | Training loss: 0.6871520668268204
Epoch: 90 | Iteration number: [2010/4518] 44% | Training loss: 0.687154456483784
Epoch: 90 | Iteration number: [2020/4518] 44% | Training loss: 0.687151825073922
Epoch: 90 | Iteration number: [2030/4518] 44% | Training loss: 0.687150200893139
Epoch: 90 | Iteration number: [2040/4518] 45% | Training loss: 0.6871499945720037
Epoch: 90 | Iteration number: [2050/4518] 45% | Training loss: 0.6871426333159936
Epoch: 90 | Iteration number: [2060/4518] 45% | Training loss: 0.6871377585003677
Epoch: 90 | Iteration number: [2070/4518] 45% | Training loss: 0.6871395727862483
Epoch: 90 | Iteration number: [2080/4518] 46% | Training loss: 0.6871401872485876
Epoch: 90 | Iteration number: [2090/4518] 46% | Training loss: 0.687128384660876
Epoch: 90 | Iteration number: [2100/4518] 46% | Training loss: 0.6871330201909656
Epoch: 90 | Iteration number: [2110/4518] 46% | Training loss: 0.6871331693436862
Epoch: 90 | Iteration number: [2120/4518] 46% | Training loss: 0.6871263082578497
Epoch: 90 | Iteration number: [2130/4518] 47% | Training loss: 0.6871225620659305
Epoch: 90 | Iteration number: [2140/4518] 47% | Training loss: 0.6871222118072421
Epoch: 90 | Iteration number: [2150/4518] 47% | Training loss: 0.6871181774416635
Epoch: 90 | Iteration number: [2160/4518] 47% | Training loss: 0.687119722366333
Epoch: 90 | Iteration number: [2170/4518] 48% | Training loss: 0.687113227382783
Epoch: 90 | Iteration number: [2180/4518] 48% | Training loss: 0.687111486180113
Epoch: 90 | Iteration number: [2190/4518] 48% | Training loss: 0.6871172750105052
Epoch: 90 | Iteration number: [2200/4518] 48% | Training loss: 0.6871120202541351
Epoch: 90 | Iteration number: [2210/4518] 48% | Training loss: 0.6871118297673998
Epoch: 90 | Iteration number: [2220/4518] 49% | Training loss: 0.6871102328236038
Epoch: 90 | Iteration number: [2230/4518] 49% | Training loss: 0.6871099978551737
Epoch: 90 | Iteration number: [2240/4518] 49% | Training loss: 0.6871135417371989
Epoch: 90 | Iteration number: [2250/4518] 49% | Training loss: 0.6871084535916646
Epoch: 90 | Iteration number: [2260/4518] 50% | Training loss: 0.6871104313208993
Epoch: 90 | Iteration number: [2270/4518] 50% | Training loss: 0.6871088407638315
Epoch: 90 | Iteration number: [2280/4518] 50% | Training loss: 0.687107706122231
Epoch: 90 | Iteration number: [2290/4518] 50% | Training loss: 0.6871077997715712
Epoch: 90 | Iteration number: [2300/4518] 50% | Training loss: 0.6871012480362602
Epoch: 90 | Iteration number: [2310/4518] 51% | Training loss: 0.6871044154033
Epoch: 90 | Iteration number: [2320/4518] 51% | Training loss: 0.6871056708282438
Epoch: 90 | Iteration number: [2330/4518] 51% | Training loss: 0.6871060566584951
Epoch: 90 | Iteration number: [2340/4518] 51% | Training loss: 0.6871049048044743
Epoch: 90 | Iteration number: [2350/4518] 52% | Training loss: 0.6871058439447525
Epoch: 90 | Iteration number: [2360/4518] 52% | Training loss: 0.6871100702275664
Epoch: 90 | Iteration number: [2370/4518] 52% | Training loss: 0.6871132563941086
Epoch: 90 | Iteration number: [2380/4518] 52% | Training loss: 0.6871135463734634
Epoch: 90 | Iteration number: [2390/4518] 52% | Training loss: 0.6871088437206077
Epoch: 90 | Iteration number: [2400/4518] 53% | Training loss: 0.6871062596390645
Epoch: 90 | Iteration number: [2410/4518] 53% | Training loss: 0.6871011492622344
Epoch: 90 | Iteration number: [2420/4518] 53% | Training loss: 0.6870991791329109
Epoch: 90 | Iteration number: [2430/4518] 53% | Training loss: 0.6870986529338508
Epoch: 90 | Iteration number: [2440/4518] 54% | Training loss: 0.6870993946419388
Epoch: 90 | Iteration number: [2450/4518] 54% | Training loss: 0.6870971472652591
Epoch: 90 | Iteration number: [2460/4518] 54% | Training loss: 0.6870974307864662
Epoch: 90 | Iteration number: [2470/4518] 54% | Training loss: 0.68709501870248
Epoch: 90 | Iteration number: [2480/4518] 54% | Training loss: 0.6870849834334466
Epoch: 90 | Iteration number: [2490/4518] 55% | Training loss: 0.6870820256122144
Epoch: 90 | Iteration number: [2500/4518] 55% | Training loss: 0.687084181022644
Epoch: 90 | Iteration number: [2510/4518] 55% | Training loss: 0.6870822498997844
Epoch: 90 | Iteration number: [2520/4518] 55% | Training loss: 0.6870769142394975
Epoch: 90 | Iteration number: [2530/4518] 55% | Training loss: 0.6870778056237066
Epoch: 90 | Iteration number: [2540/4518] 56% | Training loss: 0.6870733320947707
Epoch: 90 | Iteration number: [2550/4518] 56% | Training loss: 0.6870736133818532
Epoch: 90 | Iteration number: [2560/4518] 56% | Training loss: 0.6870731809409335
Epoch: 90 | Iteration number: [2570/4518] 56% | Training loss: 0.6870719887403198
Epoch: 90 | Iteration number: [2580/4518] 57% | Training loss: 0.687077716893928
Epoch: 90 | Iteration number: [2590/4518] 57% | Training loss: 0.6870761306359501
Epoch: 90 | Iteration number: [2600/4518] 57% | Training loss: 0.6870718060089992
Epoch: 90 | Iteration number: [2610/4518] 57% | Training loss: 0.6870714914067951
Epoch: 90 | Iteration number: [2620/4518] 57% | Training loss: 0.6870627904211292
Epoch: 90 | Iteration number: [2630/4518] 58% | Training loss: 0.6870556116784027
Epoch: 90 | Iteration number: [2640/4518] 58% | Training loss: 0.687054968534997
Epoch: 90 | Iteration number: [2650/4518] 58% | Training loss: 0.68705260951564
Epoch: 90 | Iteration number: [2660/4518] 58% | Training loss: 0.6870559444552974
Epoch: 90 | Iteration number: [2670/4518] 59% | Training loss: 0.6870538399014133
Epoch: 90 | Iteration number: [2680/4518] 59% | Training loss: 0.6870487530507259
Epoch: 90 | Iteration number: [2690/4518] 59% | Training loss: 0.6870440577264169
Epoch: 90 | Iteration number: [2700/4518] 59% | Training loss: 0.6870453596777386
Epoch: 90 | Iteration number: [2710/4518] 59% | Training loss: 0.6870417977611077
Epoch: 90 | Iteration number: [2720/4518] 60% | Training loss: 0.6870409990277361
Epoch: 90 | Iteration number: [2730/4518] 60% | Training loss: 0.6870369001622602
Epoch: 90 | Iteration number: [2740/4518] 60% | Training loss: 0.6870368245091751
Epoch: 90 | Iteration number: [2750/4518] 60% | Training loss: 0.6870332852710377
Epoch: 90 | Iteration number: [2760/4518] 61% | Training loss: 0.6870301286811414
Epoch: 90 | Iteration number: [2770/4518] 61% | Training loss: 0.6870276740742074
Epoch: 90 | Iteration number: [2780/4518] 61% | Training loss: 0.6870227588166435
Epoch: 90 | Iteration number: [2790/4518] 61% | Training loss: 0.6870207220422752
Epoch: 90 | Iteration number: [2800/4518] 61% | Training loss: 0.6870230839295046
Epoch: 90 | Iteration number: [2810/4518] 62% | Training loss: 0.687017944444541
Epoch: 90 | Iteration number: [2820/4518] 62% | Training loss: 0.6870198124689413
Epoch: 90 | Iteration number: [2830/4518] 62% | Training loss: 0.6870208117018319
Epoch: 90 | Iteration number: [2840/4518] 62% | Training loss: 0.6870237379006936
Epoch: 90 | Iteration number: [2850/4518] 63% | Training loss: 0.6870251594300856
Epoch: 90 | Iteration number: [2860/4518] 63% | Training loss: 0.6870209675360393
Epoch: 90 | Iteration number: [2870/4518] 63% | Training loss: 0.6870209386124428
Epoch: 90 | Iteration number: [2880/4518] 63% | Training loss: 0.6870191040759285
Epoch: 90 | Iteration number: [2890/4518] 63% | Training loss: 0.687020481375262
Epoch: 90 | Iteration number: [2900/4518] 64% | Training loss: 0.6870178184632597
Epoch: 90 | Iteration number: [2910/4518] 64% | Training loss: 0.6870215037434372
Epoch: 90 | Iteration number: [2920/4518] 64% | Training loss: 0.6870224169264101
Epoch: 90 | Iteration number: [2930/4518] 64% | Training loss: 0.6870219678602121
Epoch: 90 | Iteration number: [2940/4518] 65% | Training loss: 0.6870192808561585
Epoch: 90 | Iteration number: [2950/4518] 65% | Training loss: 0.6870214868198007
Epoch: 90 | Iteration number: [2960/4518] 65% | Training loss: 0.6870227527578134
Epoch: 90 | Iteration number: [2970/4518] 65% | Training loss: 0.6870204681097859
Epoch: 90 | Iteration number: [2980/4518] 65% | Training loss: 0.6870215774782552
Epoch: 90 | Iteration number: [2990/4518] 66% | Training loss: 0.6870219002399955
Epoch: 90 | Iteration number: [3000/4518] 66% | Training loss: 0.6870230794151624
Epoch: 90 | Iteration number: [3010/4518] 66% | Training loss: 0.6870184470648781
Epoch: 90 | Iteration number: [3020/4518] 66% | Training loss: 0.6870219650055399
Epoch: 90 | Iteration number: [3030/4518] 67% | Training loss: 0.6870179006565522
Epoch: 90 | Iteration number: [3040/4518] 67% | Training loss: 0.6870163857544723
Epoch: 90 | Iteration number: [3050/4518] 67% | Training loss: 0.6870179337947095
Epoch: 90 | Iteration number: [3060/4518] 67% | Training loss: 0.6870162762263242
Epoch: 90 | Iteration number: [3070/4518] 67% | Training loss: 0.6870125889389833
Epoch: 90 | Iteration number: [3080/4518] 68% | Training loss: 0.687008720171916
Epoch: 90 | Iteration number: [3090/4518] 68% | Training loss: 0.6870049819591362
Epoch: 90 | Iteration number: [3100/4518] 68% | Training loss: 0.6870066095936683
Epoch: 90 | Iteration number: [3110/4518] 68% | Training loss: 0.687005119940859
Epoch: 90 | Iteration number: [3120/4518] 69% | Training loss: 0.6870028096704911
Epoch: 90 | Iteration number: [3130/4518] 69% | Training loss: 0.6870002830180878
Epoch: 90 | Iteration number: [3140/4518] 69% | Training loss: 0.6869991098050099
Epoch: 90 | Iteration number: [3150/4518] 69% | Training loss: 0.6869945781571525
Epoch: 90 | Iteration number: [3160/4518] 69% | Training loss: 0.686995029543774
Epoch: 90 | Iteration number: [3170/4518] 70% | Training loss: 0.6869951595643341
Epoch: 90 | Iteration number: [3180/4518] 70% | Training loss: 0.6869964721817641
Epoch: 90 | Iteration number: [3190/4518] 70% | Training loss: 0.6869993614365688
Epoch: 90 | Iteration number: [3200/4518] 70% | Training loss: 0.6869968435168267
Epoch: 90 | Iteration number: [3210/4518] 71% | Training loss: 0.686994537033396
Epoch: 90 | Iteration number: [3220/4518] 71% | Training loss: 0.6869902056196462
Epoch: 90 | Iteration number: [3230/4518] 71% | Training loss: 0.686990771057436
Epoch: 90 | Iteration number: [3240/4518] 71% | Training loss: 0.6869876615611124
Epoch: 90 | Iteration number: [3250/4518] 71% | Training loss: 0.6869854876628289
Epoch: 90 | Iteration number: [3260/4518] 72% | Training loss: 0.6869844010454014
Epoch: 90 | Iteration number: [3270/4518] 72% | Training loss: 0.6869815606042879
Epoch: 90 | Iteration number: [3280/4518] 72% | Training loss: 0.6869833451582165
Epoch: 90 | Iteration number: [3290/4518] 72% | Training loss: 0.6869766943179365
Epoch: 90 | Iteration number: [3300/4518] 73% | Training loss: 0.6869785024903038
Epoch: 90 | Iteration number: [3310/4518] 73% | Training loss: 0.6869783883008352
Epoch: 90 | Iteration number: [3320/4518] 73% | Training loss: 0.6869772410536387
Epoch: 90 | Iteration number: [3330/4518] 73% | Training loss: 0.6869720460595311
Epoch: 90 | Iteration number: [3340/4518] 73% | Training loss: 0.6869696212207486
Epoch: 90 | Iteration number: [3350/4518] 74% | Training loss: 0.6869687765391905
Epoch: 90 | Iteration number: [3360/4518] 74% | Training loss: 0.6869663856391396
Epoch: 90 | Iteration number: [3370/4518] 74% | Training loss: 0.6869669553964711
Epoch: 90 | Iteration number: [3380/4518] 74% | Training loss: 0.6869647754719976
Epoch: 90 | Iteration number: [3390/4518] 75% | Training loss: 0.686967305148949
Epoch: 90 | Iteration number: [3400/4518] 75% | Training loss: 0.686970597856185
Epoch: 90 | Iteration number: [3410/4518] 75% | Training loss: 0.6869728137321136
Epoch: 90 | Iteration number: [3420/4518] 75% | Training loss: 0.6869741333681241
Epoch: 90 | Iteration number: [3430/4518] 75% | Training loss: 0.6869700043785328
Epoch: 90 | Iteration number: [3440/4518] 76% | Training loss: 0.6869757456834926
Epoch: 90 | Iteration number: [3450/4518] 76% | Training loss: 0.6869710988929306
Epoch: 90 | Iteration number: [3460/4518] 76% | Training loss: 0.6869719688775222
Epoch: 90 | Iteration number: [3470/4518] 76% | Training loss: 0.6869725675679078
Epoch: 90 | Iteration number: [3480/4518] 77% | Training loss: 0.6869737129101808
Epoch: 90 | Iteration number: [3490/4518] 77% | Training loss: 0.6869703010023495
Epoch: 90 | Iteration number: [3500/4518] 77% | Training loss: 0.6869730486869812
Epoch: 90 | Iteration number: [3510/4518] 77% | Training loss: 0.6869725269130152
Epoch: 90 | Iteration number: [3520/4518] 77% | Training loss: 0.6869733983989467
Epoch: 90 | Iteration number: [3530/4518] 78% | Training loss: 0.6869763868895198
Epoch: 90 | Iteration number: [3540/4518] 78% | Training loss: 0.6869761478597834
Epoch: 90 | Iteration number: [3550/4518] 78% | Training loss: 0.6869733743768343
Epoch: 90 | Iteration number: [3560/4518] 78% | Training loss: 0.6869678819949707
Epoch: 90 | Iteration number: [3570/4518] 79% | Training loss: 0.6869729672827306
Epoch: 90 | Iteration number: [3580/4518] 79% | Training loss: 0.686972964292798
Epoch: 90 | Iteration number: [3590/4518] 79% | Training loss: 0.6869711738110917
Epoch: 90 | Iteration number: [3600/4518] 79% | Training loss: 0.686969523280859
Epoch: 90 | Iteration number: [3610/4518] 79% | Training loss: 0.6869690494689255
Epoch: 90 | Iteration number: [3620/4518] 80% | Training loss: 0.6869674099578383
Epoch: 90 | Iteration number: [3630/4518] 80% | Training loss: 0.6869635300038603
Epoch: 90 | Iteration number: [3640/4518] 80% | Training loss: 0.686963802756189
Epoch: 90 | Iteration number: [3650/4518] 80% | Training loss: 0.6869627052627197
Epoch: 90 | Iteration number: [3660/4518] 81% | Training loss: 0.6869608758740087
Epoch: 90 | Iteration number: [3670/4518] 81% | Training loss: 0.6869577657136995
Epoch: 90 | Iteration number: [3680/4518] 81% | Training loss: 0.6869596985047278
Epoch: 90 | Iteration number: [3690/4518] 81% | Training loss: 0.6869597168149664
Epoch: 90 | Iteration number: [3700/4518] 81% | Training loss: 0.6869616509933729
Epoch: 90 | Iteration number: [3710/4518] 82% | Training loss: 0.6869608621712965
Epoch: 90 | Iteration number: [3720/4518] 82% | Training loss: 0.686957842143633
Epoch: 90 | Iteration number: [3730/4518] 82% | Training loss: 0.6869601343336438
Epoch: 90 | Iteration number: [3740/4518] 82% | Training loss: 0.6869575043413091
Epoch: 90 | Iteration number: [3750/4518] 83% | Training loss: 0.686956583182017
Epoch: 90 | Iteration number: [3760/4518] 83% | Training loss: 0.6869553352607057
Epoch: 90 | Iteration number: [3770/4518] 83% | Training loss: 0.6869560719168787
Epoch: 90 | Iteration number: [3780/4518] 83% | Training loss: 0.6869574922575522
Epoch: 90 | Iteration number: [3790/4518] 83% | Training loss: 0.6869573325311917
Epoch: 90 | Iteration number: [3800/4518] 84% | Training loss: 0.6869572597742081
Epoch: 90 | Iteration number: [3810/4518] 84% | Training loss: 0.6869577551607697
Epoch: 90 | Iteration number: [3820/4518] 84% | Training loss: 0.6869562672850973
Epoch: 90 | Iteration number: [3830/4518] 84% | Training loss: 0.6869570468486756
Epoch: 90 | Iteration number: [3840/4518] 84% | Training loss: 0.6869595360631744
Epoch: 90 | Iteration number: [3850/4518] 85% | Training loss: 0.6869545002262314
Epoch: 90 | Iteration number: [3860/4518] 85% | Training loss: 0.6869515644145135
Epoch: 90 | Iteration number: [3870/4518] 85% | Training loss: 0.6869504865595845
Epoch: 90 | Iteration number: [3880/4518] 85% | Training loss: 0.6869502642566396
Epoch: 90 | Iteration number: [3890/4518] 86% | Training loss: 0.6869505792319928
Epoch: 90 | Iteration number: [3900/4518] 86% | Training loss: 0.6869490021467208
Epoch: 90 | Iteration number: [3910/4518] 86% | Training loss: 0.6869490091453123
Epoch: 90 | Iteration number: [3920/4518] 86% | Training loss: 0.6869442417761501
Epoch: 90 | Iteration number: [3930/4518] 86% | Training loss: 0.6869446253958549
Epoch: 90 | Iteration number: [3940/4518] 87% | Training loss: 0.6869432963998184
Epoch: 90 | Iteration number: [3950/4518] 87% | Training loss: 0.6869390017322348
Epoch: 90 | Iteration number: [3960/4518] 87% | Training loss: 0.6869382470394626
Epoch: 90 | Iteration number: [3970/4518] 87% | Training loss: 0.6869372311256995
Epoch: 90 | Iteration number: [3980/4518] 88% | Training loss: 0.6869390942043995
Epoch: 90 | Iteration number: [3990/4518] 88% | Training loss: 0.6869386635627364
Epoch: 90 | Iteration number: [4000/4518] 88% | Training loss: 0.6869362443685532
Epoch: 90 | Iteration number: [4010/4518] 88% | Training loss: 0.6869377223036236
Epoch: 90 | Iteration number: [4020/4518] 88% | Training loss: 0.6869367205533222
Epoch: 90 | Iteration number: [4030/4518] 89% | Training loss: 0.6869368165361674
Epoch: 90 | Iteration number: [4040/4518] 89% | Training loss: 0.6869380515548262
Epoch: 90 | Iteration number: [4050/4518] 89% | Training loss: 0.6869377273394738
Epoch: 90 | Iteration number: [4060/4518] 89% | Training loss: 0.6869380510352515
Epoch: 90 | Iteration number: [4070/4518] 90% | Training loss: 0.6869365995287602
Epoch: 90 | Iteration number: [4080/4518] 90% | Training loss: 0.6869372576182964
Epoch: 90 | Iteration number: [4090/4518] 90% | Training loss: 0.6869349395587566
Epoch: 90 | Iteration number: [4100/4518] 90% | Training loss: 0.6869354431949011
Epoch: 90 | Iteration number: [4110/4518] 90% | Training loss: 0.6869361889043284
Epoch: 90 | Iteration number: [4120/4518] 91% | Training loss: 0.6869358936415135
Epoch: 90 | Iteration number: [4130/4518] 91% | Training loss: 0.6869363086852842
Epoch: 90 | Iteration number: [4140/4518] 91% | Training loss: 0.6869379939088499
Epoch: 90 | Iteration number: [4150/4518] 91% | Training loss: 0.6869340864865177
Epoch: 90 | Iteration number: [4160/4518] 92% | Training loss: 0.6869346231651994
Epoch: 90 | Iteration number: [4170/4518] 92% | Training loss: 0.6869351886730972
Epoch: 90 | Iteration number: [4180/4518] 92% | Training loss: 0.6869359490546313
Epoch: 90 | Iteration number: [4190/4518] 92% | Training loss: 0.6869318940901245
Epoch: 90 | Iteration number: [4200/4518] 92% | Training loss: 0.6869298363441513
Epoch: 90 | Iteration number: [4210/4518] 93% | Training loss: 0.68693369393394
Epoch: 90 | Iteration number: [4220/4518] 93% | Training loss: 0.6869317357009056
Epoch: 90 | Iteration number: [4230/4518] 93% | Training loss: 0.6869275210878809
Epoch: 90 | Iteration number: [4240/4518] 93% | Training loss: 0.6869257916538221
Epoch: 90 | Iteration number: [4250/4518] 94% | Training loss: 0.6869240220574772
Epoch: 90 | Iteration number: [4260/4518] 94% | Training loss: 0.6869239744865838
Epoch: 90 | Iteration number: [4270/4518] 94% | Training loss: 0.6869237580679061
Epoch: 90 | Iteration number: [4280/4518] 94% | Training loss: 0.6869232207954487
Epoch: 90 | Iteration number: [4290/4518] 94% | Training loss: 0.6869221999372913
Epoch: 90 | Iteration number: [4300/4518] 95% | Training loss: 0.6869229690695918
Epoch: 90 | Iteration number: [4310/4518] 95% | Training loss: 0.6869208888775235
Epoch: 90 | Iteration number: [4320/4518] 95% | Training loss: 0.6869207187797184
Epoch: 90 | Iteration number: [4330/4518] 95% | Training loss: 0.6869210680142286
Epoch: 90 | Iteration number: [4340/4518] 96% | Training loss: 0.6869198286862966
Epoch: 90 | Iteration number: [4350/4518] 96% | Training loss: 0.6869207942759854
Epoch: 90 | Iteration number: [4360/4518] 96% | Training loss: 0.6869193404092702
Epoch: 90 | Iteration number: [4370/4518] 96% | Training loss: 0.6869180669500844
Epoch: 90 | Iteration number: [4380/4518] 96% | Training loss: 0.6869181079679428
Epoch: 90 | Iteration number: [4390/4518] 97% | Training loss: 0.6869185034126247
Epoch: 90 | Iteration number: [4400/4518] 97% | Training loss: 0.6869167353348299
Epoch: 90 | Iteration number: [4410/4518] 97% | Training loss: 0.6869215135941971
Epoch: 90 | Iteration number: [4420/4518] 97% | Training loss: 0.6869211471997775
Epoch: 90 | Iteration number: [4430/4518] 98% | Training loss: 0.6869220026594253
Epoch: 90 | Iteration number: [4440/4518] 98% | Training loss: 0.686922433811265
Epoch: 90 | Iteration number: [4450/4518] 98% | Training loss: 0.6869213564610214
Epoch: 90 | Iteration number: [4460/4518] 98% | Training loss: 0.686920833814839
Epoch: 90 | Iteration number: [4470/4518] 98% | Training loss: 0.6869224012431415
Epoch: 90 | Iteration number: [4480/4518] 99% | Training loss: 0.6869197068070727
Epoch: 90 | Iteration number: [4490/4518] 99% | Training loss: 0.6869189727412566
Epoch: 90 | Iteration number: [4500/4518] 99% | Training loss: 0.6869174732764562
Epoch: 90 | Iteration number: [4510/4518] 99% | Training loss: 0.6869160728285424

 End of epoch: 90 | Train Loss: 0.6867626675228569 | Training Time: 632 

 End of epoch: 90 | Eval Loss: 0.6899493835410293 | Evaluating Time: 17 
Epoch: 91 | Iteration number: [10/4518] 0% | Training loss: 0.755486398935318
Epoch: 91 | Iteration number: [20/4518] 0% | Training loss: 0.7206130236387253
Epoch: 91 | Iteration number: [30/4518] 0% | Training loss: 0.7094822665055592
Epoch: 91 | Iteration number: [40/4518] 0% | Training loss: 0.7037624880671501
Epoch: 91 | Iteration number: [50/4518] 1% | Training loss: 0.7004484474658966
Epoch: 91 | Iteration number: [60/4518] 1% | Training loss: 0.6981380969285965
Epoch: 91 | Iteration number: [70/4518] 1% | Training loss: 0.6964143088885716
Epoch: 91 | Iteration number: [80/4518] 1% | Training loss: 0.6953016430139541
Epoch: 91 | Iteration number: [90/4518] 1% | Training loss: 0.694350027375751
Epoch: 91 | Iteration number: [100/4518] 2% | Training loss: 0.6935682606697082
Epoch: 91 | Iteration number: [110/4518] 2% | Training loss: 0.6929523153738542
Epoch: 91 | Iteration number: [120/4518] 2% | Training loss: 0.6924784501393636
Epoch: 91 | Iteration number: [130/4518] 2% | Training loss: 0.692062070278021
Epoch: 91 | Iteration number: [140/4518] 3% | Training loss: 0.6916526117495128
Epoch: 91 | Iteration number: [150/4518] 3% | Training loss: 0.6913951059182485
Epoch: 91 | Iteration number: [160/4518] 3% | Training loss: 0.6910837803035974
Epoch: 91 | Iteration number: [170/4518] 3% | Training loss: 0.6909044584807228
Epoch: 91 | Iteration number: [180/4518] 3% | Training loss: 0.6905890239609612
Epoch: 91 | Iteration number: [190/4518] 4% | Training loss: 0.6903171416960264
Epoch: 91 | Iteration number: [200/4518] 4% | Training loss: 0.6901131948828697
Epoch: 91 | Iteration number: [210/4518] 4% | Training loss: 0.6899529170422327
Epoch: 91 | Iteration number: [220/4518] 4% | Training loss: 0.6897657418792899
Epoch: 91 | Iteration number: [230/4518] 5% | Training loss: 0.6896756021872811
Epoch: 91 | Iteration number: [240/4518] 5% | Training loss: 0.6895273178815842
Epoch: 91 | Iteration number: [250/4518] 5% | Training loss: 0.6894447989463807
Epoch: 91 | Iteration number: [260/4518] 5% | Training loss: 0.6893620094427696
Epoch: 91 | Iteration number: [270/4518] 5% | Training loss: 0.6892174314569544
Epoch: 91 | Iteration number: [280/4518] 6% | Training loss: 0.689128469143595
Epoch: 91 | Iteration number: [290/4518] 6% | Training loss: 0.6890517984998638
Epoch: 91 | Iteration number: [300/4518] 6% | Training loss: 0.6889841850598654
Epoch: 91 | Iteration number: [310/4518] 6% | Training loss: 0.6889099299907684
Epoch: 91 | Iteration number: [320/4518] 7% | Training loss: 0.6888330386951566
Epoch: 91 | Iteration number: [330/4518] 7% | Training loss: 0.6887496630350749
Epoch: 91 | Iteration number: [340/4518] 7% | Training loss: 0.6886658652740366
Epoch: 91 | Iteration number: [350/4518] 7% | Training loss: 0.6886120562894004
Epoch: 91 | Iteration number: [360/4518] 7% | Training loss: 0.6885455840163761
Epoch: 91 | Iteration number: [370/4518] 8% | Training loss: 0.6884654995557424
Epoch: 91 | Iteration number: [380/4518] 8% | Training loss: 0.688387847260425
Epoch: 91 | Iteration number: [390/4518] 8% | Training loss: 0.6883030897531754
Epoch: 91 | Iteration number: [400/4518] 8% | Training loss: 0.6882862511277199
Epoch: 91 | Iteration number: [410/4518] 9% | Training loss: 0.6882544859153469
Epoch: 91 | Iteration number: [420/4518] 9% | Training loss: 0.6882471242121287
Epoch: 91 | Iteration number: [430/4518] 9% | Training loss: 0.6882146864436394
Epoch: 91 | Iteration number: [440/4518] 9% | Training loss: 0.6881565813313831
Epoch: 91 | Iteration number: [450/4518] 9% | Training loss: 0.6881021098295848
Epoch: 91 | Iteration number: [460/4518] 10% | Training loss: 0.6880924294824186
Epoch: 91 | Iteration number: [470/4518] 10% | Training loss: 0.688091119426362
Epoch: 91 | Iteration number: [480/4518] 10% | Training loss: 0.6880789296080668
Epoch: 91 | Iteration number: [490/4518] 10% | Training loss: 0.6880683868515248
Epoch: 91 | Iteration number: [500/4518] 11% | Training loss: 0.6880499343872071
Epoch: 91 | Iteration number: [510/4518] 11% | Training loss: 0.6880193445028043
Epoch: 91 | Iteration number: [520/4518] 11% | Training loss: 0.6880045910294239
Epoch: 91 | Iteration number: [530/4518] 11% | Training loss: 0.6879906841044156
Epoch: 91 | Iteration number: [540/4518] 11% | Training loss: 0.6879761494972088
Epoch: 91 | Iteration number: [550/4518] 12% | Training loss: 0.6879760549285195
Epoch: 91 | Iteration number: [560/4518] 12% | Training loss: 0.6879653500659125
Epoch: 91 | Iteration number: [570/4518] 12% | Training loss: 0.6879562723009209
Epoch: 91 | Iteration number: [580/4518] 12% | Training loss: 0.687940000357299
Epoch: 91 | Iteration number: [590/4518] 13% | Training loss: 0.687919779147132
Epoch: 91 | Iteration number: [600/4518] 13% | Training loss: 0.6879076029857
Epoch: 91 | Iteration number: [610/4518] 13% | Training loss: 0.6878802350310028
Epoch: 91 | Iteration number: [620/4518] 13% | Training loss: 0.6878819757892239
Epoch: 91 | Iteration number: [630/4518] 13% | Training loss: 0.6878824474319579
Epoch: 91 | Iteration number: [640/4518] 14% | Training loss: 0.6878584811463953
Epoch: 91 | Iteration number: [650/4518] 14% | Training loss: 0.6878507353709294
Epoch: 91 | Iteration number: [660/4518] 14% | Training loss: 0.6878262372631015
Epoch: 91 | Iteration number: [670/4518] 14% | Training loss: 0.6878063539960491
Epoch: 91 | Iteration number: [680/4518] 15% | Training loss: 0.6877928190371569
Epoch: 91 | Iteration number: [690/4518] 15% | Training loss: 0.6877673464408819
Epoch: 91 | Iteration number: [700/4518] 15% | Training loss: 0.6877716604300907
Epoch: 91 | Iteration number: [710/4518] 15% | Training loss: 0.6877507486813504
Epoch: 91 | Iteration number: [720/4518] 15% | Training loss: 0.687732158601284
Epoch: 91 | Iteration number: [730/4518] 16% | Training loss: 0.6876984843652543
Epoch: 91 | Iteration number: [740/4518] 16% | Training loss: 0.6876886832552987
Epoch: 91 | Iteration number: [750/4518] 16% | Training loss: 0.687686985651652
Epoch: 91 | Iteration number: [760/4518] 16% | Training loss: 0.6876690255968194
Epoch: 91 | Iteration number: [770/4518] 17% | Training loss: 0.6876546129003748
Epoch: 91 | Iteration number: [780/4518] 17% | Training loss: 0.6876499318923706
Epoch: 91 | Iteration number: [790/4518] 17% | Training loss: 0.687615687107738
Epoch: 91 | Iteration number: [800/4518] 17% | Training loss: 0.6876050309091807
Epoch: 91 | Iteration number: [810/4518] 17% | Training loss: 0.6875941937352404
Epoch: 91 | Iteration number: [820/4518] 18% | Training loss: 0.6875782877933688
Epoch: 91 | Iteration number: [830/4518] 18% | Training loss: 0.6875857705093292
Epoch: 91 | Iteration number: [840/4518] 18% | Training loss: 0.6875798255205154
Epoch: 91 | Iteration number: [850/4518] 18% | Training loss: 0.687568369472728
Epoch: 91 | Iteration number: [860/4518] 19% | Training loss: 0.68755863295045
Epoch: 91 | Iteration number: [870/4518] 19% | Training loss: 0.6875586815949144
Epoch: 91 | Iteration number: [880/4518] 19% | Training loss: 0.6875516917217862
Epoch: 91 | Iteration number: [890/4518] 19% | Training loss: 0.6875425857774328
Epoch: 91 | Iteration number: [900/4518] 19% | Training loss: 0.6875392432345284
Epoch: 91 | Iteration number: [910/4518] 20% | Training loss: 0.6875311977260715
Epoch: 91 | Iteration number: [920/4518] 20% | Training loss: 0.6875320428739423
Epoch: 91 | Iteration number: [930/4518] 20% | Training loss: 0.6875318506712554
Epoch: 91 | Iteration number: [940/4518] 20% | Training loss: 0.6875109324429898
Epoch: 91 | Iteration number: [950/4518] 21% | Training loss: 0.6874869434457076
Epoch: 91 | Iteration number: [960/4518] 21% | Training loss: 0.6874765587349733
Epoch: 91 | Iteration number: [970/4518] 21% | Training loss: 0.6874538446824575
Epoch: 91 | Iteration number: [980/4518] 21% | Training loss: 0.6874419633223086
Epoch: 91 | Iteration number: [990/4518] 21% | Training loss: 0.6874232133229573
Epoch: 91 | Iteration number: [1000/4518] 22% | Training loss: 0.687419834792614
Epoch: 91 | Iteration number: [1010/4518] 22% | Training loss: 0.6874157846564114
Epoch: 91 | Iteration number: [1020/4518] 22% | Training loss: 0.6874044550984514
Epoch: 91 | Iteration number: [1030/4518] 22% | Training loss: 0.6873882530383694
Epoch: 91 | Iteration number: [1040/4518] 23% | Training loss: 0.6873687129181165
Epoch: 91 | Iteration number: [1050/4518] 23% | Training loss: 0.6873648106484186
Epoch: 91 | Iteration number: [1060/4518] 23% | Training loss: 0.6873560411750146
Epoch: 91 | Iteration number: [1070/4518] 23% | Training loss: 0.6873529420834835
Epoch: 91 | Iteration number: [1080/4518] 23% | Training loss: 0.6873461121210346
Epoch: 91 | Iteration number: [1090/4518] 24% | Training loss: 0.6873431071775769
Epoch: 91 | Iteration number: [1100/4518] 24% | Training loss: 0.6873410179940137
Epoch: 91 | Iteration number: [1110/4518] 24% | Training loss: 0.687337223420272
Epoch: 91 | Iteration number: [1120/4518] 24% | Training loss: 0.6873365014791488
Epoch: 91 | Iteration number: [1130/4518] 25% | Training loss: 0.687330476161653
Epoch: 91 | Iteration number: [1140/4518] 25% | Training loss: 0.6873258301040582
Epoch: 91 | Iteration number: [1150/4518] 25% | Training loss: 0.6873180080496747
Epoch: 91 | Iteration number: [1160/4518] 25% | Training loss: 0.6873146486693416
Epoch: 91 | Iteration number: [1170/4518] 25% | Training loss: 0.6873009599681593
Epoch: 91 | Iteration number: [1180/4518] 26% | Training loss: 0.6872930142333952
Epoch: 91 | Iteration number: [1190/4518] 26% | Training loss: 0.6872871499602534
Epoch: 91 | Iteration number: [1200/4518] 26% | Training loss: 0.6872860646247864
Epoch: 91 | Iteration number: [1210/4518] 26% | Training loss: 0.6872792389767229
Epoch: 91 | Iteration number: [1220/4518] 27% | Training loss: 0.68727023679702
Epoch: 91 | Iteration number: [1230/4518] 27% | Training loss: 0.6872629878482198
Epoch: 91 | Iteration number: [1240/4518] 27% | Training loss: 0.6872539837514201
Epoch: 91 | Iteration number: [1250/4518] 27% | Training loss: 0.6872348226070404
Epoch: 91 | Iteration number: [1260/4518] 27% | Training loss: 0.6872285019310694
Epoch: 91 | Iteration number: [1270/4518] 28% | Training loss: 0.6872178812195936
Epoch: 91 | Iteration number: [1280/4518] 28% | Training loss: 0.6872187749948353
Epoch: 91 | Iteration number: [1290/4518] 28% | Training loss: 0.687211235595304
Epoch: 91 | Iteration number: [1300/4518] 28% | Training loss: 0.687204886995829
Epoch: 91 | Iteration number: [1310/4518] 28% | Training loss: 0.6871989733390226
Epoch: 91 | Iteration number: [1320/4518] 29% | Training loss: 0.6871862731648214
Epoch: 91 | Iteration number: [1330/4518] 29% | Training loss: 0.6871796505343645
Epoch: 91 | Iteration number: [1340/4518] 29% | Training loss: 0.6871691160237611
Epoch: 91 | Iteration number: [1350/4518] 29% | Training loss: 0.6871647366329475
Epoch: 91 | Iteration number: [1360/4518] 30% | Training loss: 0.6871658508830211
Epoch: 91 | Iteration number: [1370/4518] 30% | Training loss: 0.6871571773160113
Epoch: 91 | Iteration number: [1380/4518] 30% | Training loss: 0.6871522374343181
Epoch: 91 | Iteration number: [1390/4518] 30% | Training loss: 0.6871463252486085
Epoch: 91 | Iteration number: [1400/4518] 30% | Training loss: 0.6871399581432343
Epoch: 91 | Iteration number: [1410/4518] 31% | Training loss: 0.6871421400114154
Epoch: 91 | Iteration number: [1420/4518] 31% | Training loss: 0.687134121757158
Epoch: 91 | Iteration number: [1430/4518] 31% | Training loss: 0.6871347110171419
Epoch: 91 | Iteration number: [1440/4518] 31% | Training loss: 0.6871420969565709
Epoch: 91 | Iteration number: [1450/4518] 32% | Training loss: 0.6871409602000795
Epoch: 91 | Iteration number: [1460/4518] 32% | Training loss: 0.6871397222966364
Epoch: 91 | Iteration number: [1470/4518] 32% | Training loss: 0.6871375179209677
Epoch: 91 | Iteration number: [1480/4518] 32% | Training loss: 0.6871378040797002
Epoch: 91 | Iteration number: [1490/4518] 32% | Training loss: 0.6871350040371786
Epoch: 91 | Iteration number: [1500/4518] 33% | Training loss: 0.6871347589890162
Epoch: 91 | Iteration number: [1510/4518] 33% | Training loss: 0.6871317009262691
Epoch: 91 | Iteration number: [1520/4518] 33% | Training loss: 0.6871340984184491
Epoch: 91 | Iteration number: [1530/4518] 33% | Training loss: 0.687133667593688
Epoch: 91 | Iteration number: [1540/4518] 34% | Training loss: 0.6871274400841106
Epoch: 91 | Iteration number: [1550/4518] 34% | Training loss: 0.6871225595089697
Epoch: 91 | Iteration number: [1560/4518] 34% | Training loss: 0.6871134427877573
Epoch: 91 | Iteration number: [1570/4518] 34% | Training loss: 0.6871126151388618
Epoch: 91 | Iteration number: [1580/4518] 34% | Training loss: 0.6871116242076777
Epoch: 91 | Iteration number: [1590/4518] 35% | Training loss: 0.6871090767893401
Epoch: 91 | Iteration number: [1600/4518] 35% | Training loss: 0.6871055290848017
Epoch: 91 | Iteration number: [1610/4518] 35% | Training loss: 0.6871033612985789
Epoch: 91 | Iteration number: [1620/4518] 35% | Training loss: 0.6871013827897884
Epoch: 91 | Iteration number: [1630/4518] 36% | Training loss: 0.6871048640254085
Epoch: 91 | Iteration number: [1640/4518] 36% | Training loss: 0.6871071418611014
Epoch: 91 | Iteration number: [1650/4518] 36% | Training loss: 0.687099991458835
Epoch: 91 | Iteration number: [1660/4518] 36% | Training loss: 0.6871064179633037
Epoch: 91 | Iteration number: [1670/4518] 36% | Training loss: 0.6871034558661684
Epoch: 91 | Iteration number: [1680/4518] 37% | Training loss: 0.6871067000996499
Epoch: 91 | Iteration number: [1690/4518] 37% | Training loss: 0.6871120347426488
Epoch: 91 | Iteration number: [1700/4518] 37% | Training loss: 0.6871097206718781
Epoch: 91 | Iteration number: [1710/4518] 37% | Training loss: 0.6871076804155495
Epoch: 91 | Iteration number: [1720/4518] 38% | Training loss: 0.687105217056219
Epoch: 91 | Iteration number: [1730/4518] 38% | Training loss: 0.6871006161491305
Epoch: 91 | Iteration number: [1740/4518] 38% | Training loss: 0.6871025326950797
Epoch: 91 | Iteration number: [1750/4518] 38% | Training loss: 0.6871027140957968
Epoch: 91 | Iteration number: [1760/4518] 38% | Training loss: 0.6870989733121612
Epoch: 91 | Iteration number: [1770/4518] 39% | Training loss: 0.6870990028152358
Epoch: 91 | Iteration number: [1780/4518] 39% | Training loss: 0.6870930826730942
Epoch: 91 | Iteration number: [1790/4518] 39% | Training loss: 0.6870954247493317
Epoch: 91 | Iteration number: [1800/4518] 39% | Training loss: 0.6870943350924386
Epoch: 91 | Iteration number: [1810/4518] 40% | Training loss: 0.6871043450924573
Epoch: 91 | Iteration number: [1820/4518] 40% | Training loss: 0.6870991804115065
Epoch: 91 | Iteration number: [1830/4518] 40% | Training loss: 0.6870860323879888
Epoch: 91 | Iteration number: [1840/4518] 40% | Training loss: 0.68708316952638
Epoch: 91 | Iteration number: [1850/4518] 40% | Training loss: 0.6870813128754899
Epoch: 91 | Iteration number: [1860/4518] 41% | Training loss: 0.6870770984118985
Epoch: 91 | Iteration number: [1870/4518] 41% | Training loss: 0.6870768202498635
Epoch: 91 | Iteration number: [1880/4518] 41% | Training loss: 0.6870683810812361
Epoch: 91 | Iteration number: [1890/4518] 41% | Training loss: 0.6870718288989294
Epoch: 91 | Iteration number: [1900/4518] 42% | Training loss: 0.6870695257814307
Epoch: 91 | Iteration number: [1910/4518] 42% | Training loss: 0.6870725223219207
Epoch: 91 | Iteration number: [1920/4518] 42% | Training loss: 0.6870684258329371
Epoch: 91 | Iteration number: [1930/4518] 42% | Training loss: 0.6870668871723926
Epoch: 91 | Iteration number: [1940/4518] 42% | Training loss: 0.6870608431162294
Epoch: 91 | Iteration number: [1950/4518] 43% | Training loss: 0.6870624937766637
Epoch: 91 | Iteration number: [1960/4518] 43% | Training loss: 0.6870570978035733
Epoch: 91 | Iteration number: [1970/4518] 43% | Training loss: 0.6870528347298579
Epoch: 91 | Iteration number: [1980/4518] 43% | Training loss: 0.6870538545076293
Epoch: 91 | Iteration number: [1990/4518] 44% | Training loss: 0.6870484575853875
Epoch: 91 | Iteration number: [2000/4518] 44% | Training loss: 0.6870475445985794
Epoch: 91 | Iteration number: [2010/4518] 44% | Training loss: 0.6870454803035034
Epoch: 91 | Iteration number: [2020/4518] 44% | Training loss: 0.6870406985873043
Epoch: 91 | Iteration number: [2030/4518] 44% | Training loss: 0.6870404981627253
Epoch: 91 | Iteration number: [2040/4518] 45% | Training loss: 0.687048389835685
Epoch: 91 | Iteration number: [2050/4518] 45% | Training loss: 0.6870409172918739
Epoch: 91 | Iteration number: [2060/4518] 45% | Training loss: 0.6870452291178472
Epoch: 91 | Iteration number: [2070/4518] 45% | Training loss: 0.6870493735380219
Epoch: 91 | Iteration number: [2080/4518] 46% | Training loss: 0.687048185760012
Epoch: 91 | Iteration number: [2090/4518] 46% | Training loss: 0.6870407122744328
Epoch: 91 | Iteration number: [2100/4518] 46% | Training loss: 0.6870404275258383
Epoch: 91 | Iteration number: [2110/4518] 46% | Training loss: 0.687034712809522
Epoch: 91 | Iteration number: [2120/4518] 46% | Training loss: 0.6870356516455705
Epoch: 91 | Iteration number: [2130/4518] 47% | Training loss: 0.6870292038425033
Epoch: 91 | Iteration number: [2140/4518] 47% | Training loss: 0.6870284599678539
Epoch: 91 | Iteration number: [2150/4518] 47% | Training loss: 0.6870244101313657
Epoch: 91 | Iteration number: [2160/4518] 47% | Training loss: 0.6870252719080007
Epoch: 91 | Iteration number: [2170/4518] 48% | Training loss: 0.687021463505134
Epoch: 91 | Iteration number: [2180/4518] 48% | Training loss: 0.687022737434151
Epoch: 91 | Iteration number: [2190/4518] 48% | Training loss: 0.6870183402816998
Epoch: 91 | Iteration number: [2200/4518] 48% | Training loss: 0.6870164654200728
Epoch: 91 | Iteration number: [2210/4518] 48% | Training loss: 0.687019791835034
Epoch: 91 | Iteration number: [2220/4518] 49% | Training loss: 0.6870172417110151
Epoch: 91 | Iteration number: [2230/4518] 49% | Training loss: 0.687018767654094
Epoch: 91 | Iteration number: [2240/4518] 49% | Training loss: 0.6870158303262932
Epoch: 91 | Iteration number: [2250/4518] 49% | Training loss: 0.6870117492675781
Epoch: 91 | Iteration number: [2260/4518] 50% | Training loss: 0.6870152563384149
Epoch: 91 | Iteration number: [2270/4518] 50% | Training loss: 0.6870123517670821
Epoch: 91 | Iteration number: [2280/4518] 50% | Training loss: 0.6870178879875886
Epoch: 91 | Iteration number: [2290/4518] 50% | Training loss: 0.6870149843557433
Epoch: 91 | Iteration number: [2300/4518] 50% | Training loss: 0.687017828044684
Epoch: 91 | Iteration number: [2310/4518] 51% | Training loss: 0.6870096682212053
Epoch: 91 | Iteration number: [2320/4518] 51% | Training loss: 0.6870049091505593
Epoch: 91 | Iteration number: [2330/4518] 51% | Training loss: 0.6870043126298634
Epoch: 91 | Iteration number: [2340/4518] 51% | Training loss: 0.6870033473540575
Epoch: 91 | Iteration number: [2350/4518] 52% | Training loss: 0.6870008252275751
Epoch: 91 | Iteration number: [2360/4518] 52% | Training loss: 0.6870025711797052
Epoch: 91 | Iteration number: [2370/4518] 52% | Training loss: 0.6870046993599662
Epoch: 91 | Iteration number: [2380/4518] 52% | Training loss: 0.6869990811628454
Epoch: 91 | Iteration number: [2390/4518] 52% | Training loss: 0.6870026831596965
Epoch: 91 | Iteration number: [2400/4518] 53% | Training loss: 0.6870049816370011
Epoch: 91 | Iteration number: [2410/4518] 53% | Training loss: 0.6870019783864872
Epoch: 91 | Iteration number: [2420/4518] 53% | Training loss: 0.6870048679349836
Epoch: 91 | Iteration number: [2430/4518] 53% | Training loss: 0.6870052328080307
Epoch: 91 | Iteration number: [2440/4518] 54% | Training loss: 0.6870055833800894
Epoch: 91 | Iteration number: [2450/4518] 54% | Training loss: 0.6870041854040964
Epoch: 91 | Iteration number: [2460/4518] 54% | Training loss: 0.6869999935229619
Epoch: 91 | Iteration number: [2470/4518] 54% | Training loss: 0.6869982474246006
Epoch: 91 | Iteration number: [2480/4518] 54% | Training loss: 0.6869982374291266
Epoch: 91 | Iteration number: [2490/4518] 55% | Training loss: 0.686993307784858
Epoch: 91 | Iteration number: [2500/4518] 55% | Training loss: 0.6869941564559936
Epoch: 91 | Iteration number: [2510/4518] 55% | Training loss: 0.6869928970754859
Epoch: 91 | Iteration number: [2520/4518] 55% | Training loss: 0.6869983370341952
Epoch: 91 | Iteration number: [2530/4518] 55% | Training loss: 0.6869967007118722
Epoch: 91 | Iteration number: [2540/4518] 56% | Training loss: 0.6869979592289511
Epoch: 91 | Iteration number: [2550/4518] 56% | Training loss: 0.6869990324039085
Epoch: 91 | Iteration number: [2560/4518] 56% | Training loss: 0.6869994006352499
Epoch: 91 | Iteration number: [2570/4518] 56% | Training loss: 0.6869981089686605
Epoch: 91 | Iteration number: [2580/4518] 57% | Training loss: 0.6869898898888004
Epoch: 91 | Iteration number: [2590/4518] 57% | Training loss: 0.6869872071798243
Epoch: 91 | Iteration number: [2600/4518] 57% | Training loss: 0.6869844573506942
Epoch: 91 | Iteration number: [2610/4518] 57% | Training loss: 0.6869806227099393
Epoch: 91 | Iteration number: [2620/4518] 57% | Training loss: 0.6869828561562619
Epoch: 91 | Iteration number: [2630/4518] 58% | Training loss: 0.6869837220404085
Epoch: 91 | Iteration number: [2640/4518] 58% | Training loss: 0.6869821793427973
Epoch: 91 | Iteration number: [2650/4518] 58% | Training loss: 0.6869788509269931
Epoch: 91 | Iteration number: [2660/4518] 58% | Training loss: 0.6869758295833617
Epoch: 91 | Iteration number: [2670/4518] 59% | Training loss: 0.6869764021050171
Epoch: 91 | Iteration number: [2680/4518] 59% | Training loss: 0.6869805487679012
Epoch: 91 | Iteration number: [2690/4518] 59% | Training loss: 0.6869829325206218
Epoch: 91 | Iteration number: [2700/4518] 59% | Training loss: 0.6869862685600917
Epoch: 91 | Iteration number: [2710/4518] 59% | Training loss: 0.6869880947239725
Epoch: 91 | Iteration number: [2720/4518] 60% | Training loss: 0.6869860273511971
Epoch: 91 | Iteration number: [2730/4518] 60% | Training loss: 0.6869878333348495
Epoch: 91 | Iteration number: [2740/4518] 60% | Training loss: 0.6869882628865486
Epoch: 91 | Iteration number: [2750/4518] 60% | Training loss: 0.6869890687248924
Epoch: 91 | Iteration number: [2760/4518] 61% | Training loss: 0.6869833877121193
Epoch: 91 | Iteration number: [2770/4518] 61% | Training loss: 0.6869827777254883
Epoch: 91 | Iteration number: [2780/4518] 61% | Training loss: 0.6869789952425648
Epoch: 91 | Iteration number: [2790/4518] 61% | Training loss: 0.6869800694099891
Epoch: 91 | Iteration number: [2800/4518] 61% | Training loss: 0.6869847746832031
Epoch: 91 | Iteration number: [2810/4518] 62% | Training loss: 0.6869837149818597
Epoch: 91 | Iteration number: [2820/4518] 62% | Training loss: 0.6869820989192801
Epoch: 91 | Iteration number: [2830/4518] 62% | Training loss: 0.6869810530659167
Epoch: 91 | Iteration number: [2840/4518] 62% | Training loss: 0.6869827377544322
Epoch: 91 | Iteration number: [2850/4518] 63% | Training loss: 0.6869847044191862
Epoch: 91 | Iteration number: [2860/4518] 63% | Training loss: 0.6869816354729913
Epoch: 91 | Iteration number: [2870/4518] 63% | Training loss: 0.6869806282611675
Epoch: 91 | Iteration number: [2880/4518] 63% | Training loss: 0.6869849142101075
Epoch: 91 | Iteration number: [2890/4518] 63% | Training loss: 0.6869866442309119
Epoch: 91 | Iteration number: [2900/4518] 64% | Training loss: 0.6869856460957692
Epoch: 91 | Iteration number: [2910/4518] 64% | Training loss: 0.6869841711832486
Epoch: 91 | Iteration number: [2920/4518] 64% | Training loss: 0.6869834186891987
Epoch: 91 | Iteration number: [2930/4518] 64% | Training loss: 0.6869830652715403
Epoch: 91 | Iteration number: [2940/4518] 65% | Training loss: 0.6869793835545883
Epoch: 91 | Iteration number: [2950/4518] 65% | Training loss: 0.6869778440362316
Epoch: 91 | Iteration number: [2960/4518] 65% | Training loss: 0.6869734700467135
Epoch: 91 | Iteration number: [2970/4518] 65% | Training loss: 0.68697359638182
Epoch: 91 | Iteration number: [2980/4518] 65% | Training loss: 0.6869746259994954
Epoch: 91 | Iteration number: [2990/4518] 66% | Training loss: 0.6869771292377076
Epoch: 91 | Iteration number: [3000/4518] 66% | Training loss: 0.6869750765760739
Epoch: 91 | Iteration number: [3010/4518] 66% | Training loss: 0.6869717160728682
Epoch: 91 | Iteration number: [3020/4518] 66% | Training loss: 0.6869754165608362
Epoch: 91 | Iteration number: [3030/4518] 67% | Training loss: 0.6869732754065259
Epoch: 91 | Iteration number: [3040/4518] 67% | Training loss: 0.6869730100819939
Epoch: 91 | Iteration number: [3050/4518] 67% | Training loss: 0.686972452792965
Epoch: 91 | Iteration number: [3060/4518] 67% | Training loss: 0.6869699429063236
Epoch: 91 | Iteration number: [3070/4518] 67% | Training loss: 0.6869686838469987
Epoch: 91 | Iteration number: [3080/4518] 68% | Training loss: 0.686965059150349
Epoch: 91 | Iteration number: [3090/4518] 68% | Training loss: 0.6869669095597992
Epoch: 91 | Iteration number: [3100/4518] 68% | Training loss: 0.6869669532006787
Epoch: 91 | Iteration number: [3110/4518] 68% | Training loss: 0.6869672497369086
Epoch: 91 | Iteration number: [3120/4518] 69% | Training loss: 0.6869678389376555
Epoch: 91 | Iteration number: [3130/4518] 69% | Training loss: 0.686966861284579
Epoch: 91 | Iteration number: [3140/4518] 69% | Training loss: 0.6869696586564847
Epoch: 91 | Iteration number: [3150/4518] 69% | Training loss: 0.6869677106539408
Epoch: 91 | Iteration number: [3160/4518] 69% | Training loss: 0.6869658069142812
Epoch: 91 | Iteration number: [3170/4518] 70% | Training loss: 0.686967588110301
Epoch: 91 | Iteration number: [3180/4518] 70% | Training loss: 0.6869731044806774
Epoch: 91 | Iteration number: [3190/4518] 70% | Training loss: 0.6869699166486256
Epoch: 91 | Iteration number: [3200/4518] 70% | Training loss: 0.68696678834036
Epoch: 91 | Iteration number: [3210/4518] 71% | Training loss: 0.686963152885437
Epoch: 91 | Iteration number: [3220/4518] 71% | Training loss: 0.6869590952344563
Epoch: 91 | Iteration number: [3230/4518] 71% | Training loss: 0.6869587577348892
Epoch: 91 | Iteration number: [3240/4518] 71% | Training loss: 0.6869568855490213
Epoch: 91 | Iteration number: [3250/4518] 71% | Training loss: 0.6869573829907637
Epoch: 91 | Iteration number: [3260/4518] 72% | Training loss: 0.6869601275657583
Epoch: 91 | Iteration number: [3270/4518] 72% | Training loss: 0.6869611626371331
Epoch: 91 | Iteration number: [3280/4518] 72% | Training loss: 0.6869640889691143
Epoch: 91 | Iteration number: [3290/4518] 72% | Training loss: 0.6869632536698257
Epoch: 91 | Iteration number: [3300/4518] 73% | Training loss: 0.6869630245006446
Epoch: 91 | Iteration number: [3310/4518] 73% | Training loss: 0.6869590742710494
Epoch: 91 | Iteration number: [3320/4518] 73% | Training loss: 0.6869554731501154
Epoch: 91 | Iteration number: [3330/4518] 73% | Training loss: 0.6869527194056066
Epoch: 91 | Iteration number: [3340/4518] 73% | Training loss: 0.686951120617147
Epoch: 91 | Iteration number: [3350/4518] 74% | Training loss: 0.6869502931032608
Epoch: 91 | Iteration number: [3360/4518] 74% | Training loss: 0.6869517181246053
Epoch: 91 | Iteration number: [3370/4518] 74% | Training loss: 0.6869546087276335
Epoch: 91 | Iteration number: [3380/4518] 74% | Training loss: 0.6869591852616982
Epoch: 91 | Iteration number: [3390/4518] 75% | Training loss: 0.6869607419390946
Epoch: 91 | Iteration number: [3400/4518] 75% | Training loss: 0.686958191394806
Epoch: 91 | Iteration number: [3410/4518] 75% | Training loss: 0.6869606017017644
Epoch: 91 | Iteration number: [3420/4518] 75% | Training loss: 0.6869575679127933
Epoch: 91 | Iteration number: [3430/4518] 75% | Training loss: 0.686956439369274
Epoch: 91 | Iteration number: [3440/4518] 76% | Training loss: 0.6869579388825007
Epoch: 91 | Iteration number: [3450/4518] 76% | Training loss: 0.6869554483890533
Epoch: 91 | Iteration number: [3460/4518] 76% | Training loss: 0.6869528372680521
Epoch: 91 | Iteration number: [3470/4518] 76% | Training loss: 0.6869514432523711
Epoch: 91 | Iteration number: [3480/4518] 77% | Training loss: 0.6869500567858247
Epoch: 91 | Iteration number: [3490/4518] 77% | Training loss: 0.6869497116281514
Epoch: 91 | Iteration number: [3500/4518] 77% | Training loss: 0.686948025396892
Epoch: 91 | Iteration number: [3510/4518] 77% | Training loss: 0.6869471661215834
Epoch: 91 | Iteration number: [3520/4518] 77% | Training loss: 0.6869448983195153
Epoch: 91 | Iteration number: [3530/4518] 78% | Training loss: 0.6869418340938287
Epoch: 91 | Iteration number: [3540/4518] 78% | Training loss: 0.6869427693597341
Epoch: 91 | Iteration number: [3550/4518] 78% | Training loss: 0.6869406168225786
Epoch: 91 | Iteration number: [3560/4518] 78% | Training loss: 0.6869376951556527
Epoch: 91 | Iteration number: [3570/4518] 79% | Training loss: 0.6869356009138733
Epoch: 91 | Iteration number: [3580/4518] 79% | Training loss: 0.6869364354863513
Epoch: 91 | Iteration number: [3590/4518] 79% | Training loss: 0.6869317020214367
Epoch: 91 | Iteration number: [3600/4518] 79% | Training loss: 0.6869293952484926
Epoch: 91 | Iteration number: [3610/4518] 79% | Training loss: 0.6869296872054441
Epoch: 91 | Iteration number: [3620/4518] 80% | Training loss: 0.6869320405451632
Epoch: 91 | Iteration number: [3630/4518] 80% | Training loss: 0.6869280974562831
Epoch: 91 | Iteration number: [3640/4518] 80% | Training loss: 0.6869295890350918
Epoch: 91 | Iteration number: [3650/4518] 80% | Training loss: 0.6869323452858076
Epoch: 91 | Iteration number: [3660/4518] 81% | Training loss: 0.6869315597366115
Epoch: 91 | Iteration number: [3670/4518] 81% | Training loss: 0.6869313006180183
Epoch: 91 | Iteration number: [3680/4518] 81% | Training loss: 0.686930464969381
Epoch: 91 | Iteration number: [3690/4518] 81% | Training loss: 0.6869282530413734
Epoch: 91 | Iteration number: [3700/4518] 81% | Training loss: 0.6869281331107423
Epoch: 91 | Iteration number: [3710/4518] 82% | Training loss: 0.6869299281318233
Epoch: 91 | Iteration number: [3720/4518] 82% | Training loss: 0.6869328560367707
Epoch: 91 | Iteration number: [3730/4518] 82% | Training loss: 0.6869314512043153
Epoch: 91 | Iteration number: [3740/4518] 82% | Training loss: 0.6869321408596906
Epoch: 91 | Iteration number: [3750/4518] 83% | Training loss: 0.6869334782282511
Epoch: 91 | Iteration number: [3760/4518] 83% | Training loss: 0.6869340249991164
Epoch: 91 | Iteration number: [3770/4518] 83% | Training loss: 0.6869317022021316
Epoch: 91 | Iteration number: [3780/4518] 83% | Training loss: 0.6869315537195357
Epoch: 91 | Iteration number: [3790/4518] 83% | Training loss: 0.6869328547436203
Epoch: 91 | Iteration number: [3800/4518] 84% | Training loss: 0.6869306033692862
Epoch: 91 | Iteration number: [3810/4518] 84% | Training loss: 0.6869285944722143
Epoch: 91 | Iteration number: [3820/4518] 84% | Training loss: 0.6869262301797018
Epoch: 91 | Iteration number: [3830/4518] 84% | Training loss: 0.6869288765419246
Epoch: 91 | Iteration number: [3840/4518] 84% | Training loss: 0.6869307995773852
Epoch: 91 | Iteration number: [3850/4518] 85% | Training loss: 0.6869294517535668
Epoch: 91 | Iteration number: [3860/4518] 85% | Training loss: 0.6869315023558128
Epoch: 91 | Iteration number: [3870/4518] 85% | Training loss: 0.6869297002175058
Epoch: 91 | Iteration number: [3880/4518] 85% | Training loss: 0.6869329839176739
Epoch: 91 | Iteration number: [3890/4518] 86% | Training loss: 0.6869334215983021
Epoch: 91 | Iteration number: [3900/4518] 86% | Training loss: 0.6869333087480985
Epoch: 91 | Iteration number: [3910/4518] 86% | Training loss: 0.6869327653094631
Epoch: 91 | Iteration number: [3920/4518] 86% | Training loss: 0.6869327487994213
Epoch: 91 | Iteration number: [3930/4518] 86% | Training loss: 0.686929526189508
Epoch: 91 | Iteration number: [3940/4518] 87% | Training loss: 0.6869279195058164
Epoch: 91 | Iteration number: [3950/4518] 87% | Training loss: 0.6869231864319572
Epoch: 91 | Iteration number: [3960/4518] 87% | Training loss: 0.6869225745399793
Epoch: 91 | Iteration number: [3970/4518] 87% | Training loss: 0.6869238676442307
Epoch: 91 | Iteration number: [3980/4518] 88% | Training loss: 0.6869213096011224
Epoch: 91 | Iteration number: [3990/4518] 88% | Training loss: 0.6869181305244751
Epoch: 91 | Iteration number: [4000/4518] 88% | Training loss: 0.6869211097508668
Epoch: 91 | Iteration number: [4010/4518] 88% | Training loss: 0.686920377545226
Epoch: 91 | Iteration number: [4020/4518] 88% | Training loss: 0.6869191542638475
Epoch: 91 | Iteration number: [4030/4518] 89% | Training loss: 0.6869194165057048
Epoch: 91 | Iteration number: [4040/4518] 89% | Training loss: 0.6869214207376584
Epoch: 91 | Iteration number: [4050/4518] 89% | Training loss: 0.6869196520469807
Epoch: 91 | Iteration number: [4060/4518] 89% | Training loss: 0.686920117553819
Epoch: 91 | Iteration number: [4070/4518] 90% | Training loss: 0.6869228610096165
Epoch: 91 | Iteration number: [4080/4518] 90% | Training loss: 0.6869241084684344
Epoch: 91 | Iteration number: [4090/4518] 90% | Training loss: 0.6869255768786433
Epoch: 91 | Iteration number: [4100/4518] 90% | Training loss: 0.6869233525526233
Epoch: 91 | Iteration number: [4110/4518] 90% | Training loss: 0.6869218710565219
Epoch: 91 | Iteration number: [4120/4518] 91% | Training loss: 0.6869198699888673
Epoch: 91 | Iteration number: [4130/4518] 91% | Training loss: 0.6869162787392411
Epoch: 91 | Iteration number: [4140/4518] 91% | Training loss: 0.6869177705567816
Epoch: 91 | Iteration number: [4150/4518] 91% | Training loss: 0.686921562042581
Epoch: 91 | Iteration number: [4160/4518] 92% | Training loss: 0.6869216046797542
Epoch: 91 | Iteration number: [4170/4518] 92% | Training loss: 0.6869216181963181
Epoch: 91 | Iteration number: [4180/4518] 92% | Training loss: 0.6869236783262646
Epoch: 91 | Iteration number: [4190/4518] 92% | Training loss: 0.6869243422812096
Epoch: 91 | Iteration number: [4200/4518] 92% | Training loss: 0.6869223382075628
Epoch: 91 | Iteration number: [4210/4518] 93% | Training loss: 0.6869217582100078
Epoch: 91 | Iteration number: [4220/4518] 93% | Training loss: 0.6869191846858833
Epoch: 91 | Iteration number: [4230/4518] 93% | Training loss: 0.6869197814318023
Epoch: 91 | Iteration number: [4240/4518] 93% | Training loss: 0.6869182746787116
Epoch: 91 | Iteration number: [4250/4518] 94% | Training loss: 0.6869203571712269
Epoch: 91 | Iteration number: [4260/4518] 94% | Training loss: 0.6869209833408185
Epoch: 91 | Iteration number: [4270/4518] 94% | Training loss: 0.6869198596030822
Epoch: 91 | Iteration number: [4280/4518] 94% | Training loss: 0.6869174878034636
Epoch: 91 | Iteration number: [4290/4518] 94% | Training loss: 0.686913938400073
Epoch: 91 | Iteration number: [4300/4518] 95% | Training loss: 0.686911090168842
Epoch: 91 | Iteration number: [4310/4518] 95% | Training loss: 0.6869098644383822
Epoch: 91 | Iteration number: [4320/4518] 95% | Training loss: 0.6869085874132536
Epoch: 91 | Iteration number: [4330/4518] 95% | Training loss: 0.6869086431438323
Epoch: 91 | Iteration number: [4340/4518] 96% | Training loss: 0.6869092671552561
Epoch: 91 | Iteration number: [4350/4518] 96% | Training loss: 0.6869119889297705
Epoch: 91 | Iteration number: [4360/4518] 96% | Training loss: 0.686911138878503
Epoch: 91 | Iteration number: [4370/4518] 96% | Training loss: 0.6869094135968582
Epoch: 91 | Iteration number: [4380/4518] 96% | Training loss: 0.6869058985007952
Epoch: 91 | Iteration number: [4390/4518] 97% | Training loss: 0.6869081371465957
Epoch: 91 | Iteration number: [4400/4518] 97% | Training loss: 0.6869081948697567
Epoch: 91 | Iteration number: [4410/4518] 97% | Training loss: 0.6869086161897837
Epoch: 91 | Iteration number: [4420/4518] 97% | Training loss: 0.6869090903128974
Epoch: 91 | Iteration number: [4430/4518] 98% | Training loss: 0.6869084046199144
Epoch: 91 | Iteration number: [4440/4518] 98% | Training loss: 0.6869111106470899
Epoch: 91 | Iteration number: [4450/4518] 98% | Training loss: 0.6869089839297734
Epoch: 91 | Iteration number: [4460/4518] 98% | Training loss: 0.6869099199638239
Epoch: 91 | Iteration number: [4470/4518] 98% | Training loss: 0.6869075287241797
Epoch: 91 | Iteration number: [4480/4518] 99% | Training loss: 0.6869088261521288
Epoch: 91 | Iteration number: [4490/4518] 99% | Training loss: 0.6869084280689469
Epoch: 91 | Iteration number: [4500/4518] 99% | Training loss: 0.6869102741612328
Epoch: 91 | Iteration number: [4510/4518] 99% | Training loss: 0.6869108802595583

 End of epoch: 91 | Train Loss: 0.6867600841667865 | Training Time: 634 

 End of epoch: 91 | Eval Loss: 0.6899308489293469 | Evaluating Time: 17 
Epoch: 92 | Iteration number: [10/4518] 0% | Training loss: 0.7563198328018188
Epoch: 92 | Iteration number: [20/4518] 0% | Training loss: 0.7215694308280944
Epoch: 92 | Iteration number: [30/4518] 0% | Training loss: 0.709850686788559
Epoch: 92 | Iteration number: [40/4518] 0% | Training loss: 0.7036923825740814
Epoch: 92 | Iteration number: [50/4518] 1% | Training loss: 0.7003615236282349
Epoch: 92 | Iteration number: [60/4518] 1% | Training loss: 0.6980131675799688
Epoch: 92 | Iteration number: [70/4518] 1% | Training loss: 0.6963489660194941
Epoch: 92 | Iteration number: [80/4518] 1% | Training loss: 0.6951004058122635
Epoch: 92 | Iteration number: [90/4518] 1% | Training loss: 0.6941713988780975
Epoch: 92 | Iteration number: [100/4518] 2% | Training loss: 0.6933580350875854
Epoch: 92 | Iteration number: [110/4518] 2% | Training loss: 0.6926878203045238
Epoch: 92 | Iteration number: [120/4518] 2% | Training loss: 0.6922110478083293
Epoch: 92 | Iteration number: [130/4518] 2% | Training loss: 0.6918178164041959
Epoch: 92 | Iteration number: [140/4518] 3% | Training loss: 0.6913561918905803
Epoch: 92 | Iteration number: [150/4518] 3% | Training loss: 0.6910555970668792
Epoch: 92 | Iteration number: [160/4518] 3% | Training loss: 0.6908474907279014
Epoch: 92 | Iteration number: [170/4518] 3% | Training loss: 0.6906340073136722
Epoch: 92 | Iteration number: [180/4518] 3% | Training loss: 0.6903842048512565
Epoch: 92 | Iteration number: [190/4518] 4% | Training loss: 0.6901548009169729
Epoch: 92 | Iteration number: [200/4518] 4% | Training loss: 0.6899734672904014
Epoch: 92 | Iteration number: [210/4518] 4% | Training loss: 0.6898829843316759
Epoch: 92 | Iteration number: [220/4518] 4% | Training loss: 0.6897384126077999
Epoch: 92 | Iteration number: [230/4518] 5% | Training loss: 0.689634598078935
Epoch: 92 | Iteration number: [240/4518] 5% | Training loss: 0.689513248950243
Epoch: 92 | Iteration number: [250/4518] 5% | Training loss: 0.689443103313446
Epoch: 92 | Iteration number: [260/4518] 5% | Training loss: 0.6893211701741585
Epoch: 92 | Iteration number: [270/4518] 5% | Training loss: 0.6892330180715631
Epoch: 92 | Iteration number: [280/4518] 6% | Training loss: 0.6891606003046036
Epoch: 92 | Iteration number: [290/4518] 6% | Training loss: 0.6890468897490666
Epoch: 92 | Iteration number: [300/4518] 6% | Training loss: 0.6889127775033315
Epoch: 92 | Iteration number: [310/4518] 6% | Training loss: 0.6888030644386045
Epoch: 92 | Iteration number: [320/4518] 7% | Training loss: 0.6887277221307159
Epoch: 92 | Iteration number: [330/4518] 7% | Training loss: 0.6886565446853637
Epoch: 92 | Iteration number: [340/4518] 7% | Training loss: 0.6886048218783211
Epoch: 92 | Iteration number: [350/4518] 7% | Training loss: 0.688521374804633
Epoch: 92 | Iteration number: [360/4518] 7% | Training loss: 0.6884750497010019
Epoch: 92 | Iteration number: [370/4518] 8% | Training loss: 0.688430274177242
Epoch: 92 | Iteration number: [380/4518] 8% | Training loss: 0.6884081853063483
Epoch: 92 | Iteration number: [390/4518] 8% | Training loss: 0.6883267894769326
Epoch: 92 | Iteration number: [400/4518] 8% | Training loss: 0.688281751871109
Epoch: 92 | Iteration number: [410/4518] 9% | Training loss: 0.6882250333704599
Epoch: 92 | Iteration number: [420/4518] 9% | Training loss: 0.6881874725932167
Epoch: 92 | Iteration number: [430/4518] 9% | Training loss: 0.6881427943706513
Epoch: 92 | Iteration number: [440/4518] 9% | Training loss: 0.6881289234215563
Epoch: 92 | Iteration number: [450/4518] 9% | Training loss: 0.6881100606918334
Epoch: 92 | Iteration number: [460/4518] 10% | Training loss: 0.688085024771483
Epoch: 92 | Iteration number: [470/4518] 10% | Training loss: 0.6880558147075329
Epoch: 92 | Iteration number: [480/4518] 10% | Training loss: 0.6880275419602792
Epoch: 92 | Iteration number: [490/4518] 10% | Training loss: 0.6880106788508746
Epoch: 92 | Iteration number: [500/4518] 11% | Training loss: 0.6880018619298935
Epoch: 92 | Iteration number: [510/4518] 11% | Training loss: 0.6879811718183405
Epoch: 92 | Iteration number: [520/4518] 11% | Training loss: 0.687946207018999
Epoch: 92 | Iteration number: [530/4518] 11% | Training loss: 0.6879290789928076
Epoch: 92 | Iteration number: [540/4518] 11% | Training loss: 0.687911816769176
Epoch: 92 | Iteration number: [550/4518] 12% | Training loss: 0.6878692224892703
Epoch: 92 | Iteration number: [560/4518] 12% | Training loss: 0.6878395182745797
Epoch: 92 | Iteration number: [570/4518] 12% | Training loss: 0.6878204570527662
Epoch: 92 | Iteration number: [580/4518] 12% | Training loss: 0.6878124341882509
Epoch: 92 | Iteration number: [590/4518] 13% | Training loss: 0.6877917150319632
Epoch: 92 | Iteration number: [600/4518] 13% | Training loss: 0.6877743898828824
Epoch: 92 | Iteration number: [610/4518] 13% | Training loss: 0.6877687720978847
Epoch: 92 | Iteration number: [620/4518] 13% | Training loss: 0.6877597351228038
Epoch: 92 | Iteration number: [630/4518] 13% | Training loss: 0.6877503025153326
Epoch: 92 | Iteration number: [640/4518] 14% | Training loss: 0.6877420276403428
Epoch: 92 | Iteration number: [650/4518] 14% | Training loss: 0.6877267712813158
Epoch: 92 | Iteration number: [660/4518] 14% | Training loss: 0.6877028772325227
Epoch: 92 | Iteration number: [670/4518] 14% | Training loss: 0.6876745412598795
Epoch: 92 | Iteration number: [680/4518] 15% | Training loss: 0.6876505465191953
Epoch: 92 | Iteration number: [690/4518] 15% | Training loss: 0.6876569961292156
Epoch: 92 | Iteration number: [700/4518] 15% | Training loss: 0.6876324279819216
Epoch: 92 | Iteration number: [710/4518] 15% | Training loss: 0.6876126592427911
Epoch: 92 | Iteration number: [720/4518] 15% | Training loss: 0.687592304084036
Epoch: 92 | Iteration number: [730/4518] 16% | Training loss: 0.6875878929275356
Epoch: 92 | Iteration number: [740/4518] 16% | Training loss: 0.687575475589649
Epoch: 92 | Iteration number: [750/4518] 16% | Training loss: 0.6875488297939301
Epoch: 92 | Iteration number: [760/4518] 16% | Training loss: 0.6875293836781853
Epoch: 92 | Iteration number: [770/4518] 17% | Training loss: 0.687523113829749
Epoch: 92 | Iteration number: [780/4518] 17% | Training loss: 0.6875250512972856
Epoch: 92 | Iteration number: [790/4518] 17% | Training loss: 0.6875294270394724
Epoch: 92 | Iteration number: [800/4518] 17% | Training loss: 0.6875096056610346
Epoch: 92 | Iteration number: [810/4518] 17% | Training loss: 0.6874920414553748
Epoch: 92 | Iteration number: [820/4518] 18% | Training loss: 0.6874817837302277
Epoch: 92 | Iteration number: [830/4518] 18% | Training loss: 0.6874709079782647
Epoch: 92 | Iteration number: [840/4518] 18% | Training loss: 0.6874675797564643
Epoch: 92 | Iteration number: [850/4518] 18% | Training loss: 0.68747258922633
Epoch: 92 | Iteration number: [860/4518] 19% | Training loss: 0.6874454067196957
Epoch: 92 | Iteration number: [870/4518] 19% | Training loss: 0.6874302828448943
Epoch: 92 | Iteration number: [880/4518] 19% | Training loss: 0.6874296396970749
Epoch: 92 | Iteration number: [890/4518] 19% | Training loss: 0.6874172648017326
Epoch: 92 | Iteration number: [900/4518] 19% | Training loss: 0.6874040829473071
Epoch: 92 | Iteration number: [910/4518] 20% | Training loss: 0.6873939290806488
Epoch: 92 | Iteration number: [920/4518] 20% | Training loss: 0.687387490466885
Epoch: 92 | Iteration number: [930/4518] 20% | Training loss: 0.687383847659634
Epoch: 92 | Iteration number: [940/4518] 20% | Training loss: 0.6873749867398689
Epoch: 92 | Iteration number: [950/4518] 21% | Training loss: 0.6873723961805043
Epoch: 92 | Iteration number: [960/4518] 21% | Training loss: 0.6873648901159565
Epoch: 92 | Iteration number: [970/4518] 21% | Training loss: 0.687366908051304
Epoch: 92 | Iteration number: [980/4518] 21% | Training loss: 0.6873606916593046
Epoch: 92 | Iteration number: [990/4518] 21% | Training loss: 0.6873545045804496
Epoch: 92 | Iteration number: [1000/4518] 22% | Training loss: 0.6873520256876946
Epoch: 92 | Iteration number: [1010/4518] 22% | Training loss: 0.6873432507609377
Epoch: 92 | Iteration number: [1020/4518] 22% | Training loss: 0.6873325095457189
Epoch: 92 | Iteration number: [1030/4518] 22% | Training loss: 0.6873248954999794
Epoch: 92 | Iteration number: [1040/4518] 23% | Training loss: 0.6873265729500697
Epoch: 92 | Iteration number: [1050/4518] 23% | Training loss: 0.687322308960415
Epoch: 92 | Iteration number: [1060/4518] 23% | Training loss: 0.6873262930028844
Epoch: 92 | Iteration number: [1070/4518] 23% | Training loss: 0.6873256318480054
Epoch: 92 | Iteration number: [1080/4518] 23% | Training loss: 0.6873067456814977
Epoch: 92 | Iteration number: [1090/4518] 24% | Training loss: 0.6872981616663276
Epoch: 92 | Iteration number: [1100/4518] 24% | Training loss: 0.6872911498763344
Epoch: 92 | Iteration number: [1110/4518] 24% | Training loss: 0.6872894424038964
Epoch: 92 | Iteration number: [1120/4518] 24% | Training loss: 0.6872927138847964
Epoch: 92 | Iteration number: [1130/4518] 25% | Training loss: 0.6872830845613396
Epoch: 92 | Iteration number: [1140/4518] 25% | Training loss: 0.6872722096610487
Epoch: 92 | Iteration number: [1150/4518] 25% | Training loss: 0.6872719802027163
Epoch: 92 | Iteration number: [1160/4518] 25% | Training loss: 0.6872699604979877
Epoch: 92 | Iteration number: [1170/4518] 25% | Training loss: 0.6872701105908451
Epoch: 92 | Iteration number: [1180/4518] 26% | Training loss: 0.6872649103908216
Epoch: 92 | Iteration number: [1190/4518] 26% | Training loss: 0.6872503038714913
Epoch: 92 | Iteration number: [1200/4518] 26% | Training loss: 0.6872512668867906
Epoch: 92 | Iteration number: [1210/4518] 26% | Training loss: 0.6872528233803994
Epoch: 92 | Iteration number: [1220/4518] 27% | Training loss: 0.6872378535446574
Epoch: 92 | Iteration number: [1230/4518] 27% | Training loss: 0.6872293189289124
Epoch: 92 | Iteration number: [1240/4518] 27% | Training loss: 0.687236684608844
Epoch: 92 | Iteration number: [1250/4518] 27% | Training loss: 0.6872461084842681
Epoch: 92 | Iteration number: [1260/4518] 27% | Training loss: 0.6872413771020042
Epoch: 92 | Iteration number: [1270/4518] 28% | Training loss: 0.6872448411982829
Epoch: 92 | Iteration number: [1280/4518] 28% | Training loss: 0.6872431569267065
Epoch: 92 | Iteration number: [1290/4518] 28% | Training loss: 0.6872333788132483
Epoch: 92 | Iteration number: [1300/4518] 28% | Training loss: 0.6872220855034314
Epoch: 92 | Iteration number: [1310/4518] 28% | Training loss: 0.6872128085325693
Epoch: 92 | Iteration number: [1320/4518] 29% | Training loss: 0.6872046511281621
Epoch: 92 | Iteration number: [1330/4518] 29% | Training loss: 0.687200861676295
Epoch: 92 | Iteration number: [1340/4518] 29% | Training loss: 0.6871967679084237
Epoch: 92 | Iteration number: [1350/4518] 29% | Training loss: 0.6871939987606472
Epoch: 92 | Iteration number: [1360/4518] 30% | Training loss: 0.687192494641332
Epoch: 92 | Iteration number: [1370/4518] 30% | Training loss: 0.6871910750865936
Epoch: 92 | Iteration number: [1380/4518] 30% | Training loss: 0.6871828762949377
Epoch: 92 | Iteration number: [1390/4518] 30% | Training loss: 0.6871798265752175
Epoch: 92 | Iteration number: [1400/4518] 30% | Training loss: 0.6871837751780238
Epoch: 92 | Iteration number: [1410/4518] 31% | Training loss: 0.687185222037295
Epoch: 92 | Iteration number: [1420/4518] 31% | Training loss: 0.6871863743369009
Epoch: 92 | Iteration number: [1430/4518] 31% | Training loss: 0.6871935042467985
Epoch: 92 | Iteration number: [1440/4518] 31% | Training loss: 0.6871910096870528
Epoch: 92 | Iteration number: [1450/4518] 32% | Training loss: 0.6871824282202227
Epoch: 92 | Iteration number: [1460/4518] 32% | Training loss: 0.6871812604061545
Epoch: 92 | Iteration number: [1470/4518] 32% | Training loss: 0.6871827290577143
Epoch: 92 | Iteration number: [1480/4518] 32% | Training loss: 0.687180728847916
Epoch: 92 | Iteration number: [1490/4518] 32% | Training loss: 0.6871777648093716
Epoch: 92 | Iteration number: [1500/4518] 33% | Training loss: 0.6871805319388707
Epoch: 92 | Iteration number: [1510/4518] 33% | Training loss: 0.6871771606388472
Epoch: 92 | Iteration number: [1520/4518] 33% | Training loss: 0.6871728558681514
Epoch: 92 | Iteration number: [1530/4518] 33% | Training loss: 0.6871611516070522
Epoch: 92 | Iteration number: [1540/4518] 34% | Training loss: 0.6871585849817697
Epoch: 92 | Iteration number: [1550/4518] 34% | Training loss: 0.6871566827835576
Epoch: 92 | Iteration number: [1560/4518] 34% | Training loss: 0.6871463761497767
Epoch: 92 | Iteration number: [1570/4518] 34% | Training loss: 0.6871488529026129
Epoch: 92 | Iteration number: [1580/4518] 34% | Training loss: 0.6871460358930539
Epoch: 92 | Iteration number: [1590/4518] 35% | Training loss: 0.6871406430718284
Epoch: 92 | Iteration number: [1600/4518] 35% | Training loss: 0.6871408556774259
Epoch: 92 | Iteration number: [1610/4518] 35% | Training loss: 0.6871360855443137
Epoch: 92 | Iteration number: [1620/4518] 35% | Training loss: 0.6871313805197492
Epoch: 92 | Iteration number: [1630/4518] 36% | Training loss: 0.6871300715610293
Epoch: 92 | Iteration number: [1640/4518] 36% | Training loss: 0.6871284630603907
Epoch: 92 | Iteration number: [1650/4518] 36% | Training loss: 0.6871259519548127
Epoch: 92 | Iteration number: [1660/4518] 36% | Training loss: 0.6871238377438971
Epoch: 92 | Iteration number: [1670/4518] 36% | Training loss: 0.6871227071670715
Epoch: 92 | Iteration number: [1680/4518] 37% | Training loss: 0.6871227683765547
Epoch: 92 | Iteration number: [1690/4518] 37% | Training loss: 0.6871149895106548
Epoch: 92 | Iteration number: [1700/4518] 37% | Training loss: 0.6871172669354607
Epoch: 92 | Iteration number: [1710/4518] 37% | Training loss: 0.6871132081015068
Epoch: 92 | Iteration number: [1720/4518] 38% | Training loss: 0.6871096900036169
Epoch: 92 | Iteration number: [1730/4518] 38% | Training loss: 0.687106282070193
Epoch: 92 | Iteration number: [1740/4518] 38% | Training loss: 0.6871003833652913
Epoch: 92 | Iteration number: [1750/4518] 38% | Training loss: 0.6870895944663457
Epoch: 92 | Iteration number: [1760/4518] 38% | Training loss: 0.6870941723612222
Epoch: 92 | Iteration number: [1770/4518] 39% | Training loss: 0.6870918160441232
Epoch: 92 | Iteration number: [1780/4518] 39% | Training loss: 0.6870960691671693
Epoch: 92 | Iteration number: [1790/4518] 39% | Training loss: 0.687097243257075
Epoch: 92 | Iteration number: [1800/4518] 39% | Training loss: 0.6870862905184428
Epoch: 92 | Iteration number: [1810/4518] 40% | Training loss: 0.6870814225291679
Epoch: 92 | Iteration number: [1820/4518] 40% | Training loss: 0.6870765504928735
Epoch: 92 | Iteration number: [1830/4518] 40% | Training loss: 0.6870757402618075
Epoch: 92 | Iteration number: [1840/4518] 40% | Training loss: 0.6870656566127487
Epoch: 92 | Iteration number: [1850/4518] 40% | Training loss: 0.6870643605090476
Epoch: 92 | Iteration number: [1860/4518] 41% | Training loss: 0.6870631658902733
Epoch: 92 | Iteration number: [1870/4518] 41% | Training loss: 0.6870622115339188
Epoch: 92 | Iteration number: [1880/4518] 41% | Training loss: 0.6870574485431327
Epoch: 92 | Iteration number: [1890/4518] 41% | Training loss: 0.6870611880822156
Epoch: 92 | Iteration number: [1900/4518] 42% | Training loss: 0.687062796542519
Epoch: 92 | Iteration number: [1910/4518] 42% | Training loss: 0.6870674440061859
Epoch: 92 | Iteration number: [1920/4518] 42% | Training loss: 0.6870656119969983
Epoch: 92 | Iteration number: [1930/4518] 42% | Training loss: 0.6870610631809333
Epoch: 92 | Iteration number: [1940/4518] 42% | Training loss: 0.6870572611535948
Epoch: 92 | Iteration number: [1950/4518] 43% | Training loss: 0.6870572468562004
Epoch: 92 | Iteration number: [1960/4518] 43% | Training loss: 0.6870601190900316
Epoch: 92 | Iteration number: [1970/4518] 43% | Training loss: 0.6870606860231022
Epoch: 92 | Iteration number: [1980/4518] 43% | Training loss: 0.6870574392754623
Epoch: 92 | Iteration number: [1990/4518] 44% | Training loss: 0.6870536424406809
Epoch: 92 | Iteration number: [2000/4518] 44% | Training loss: 0.6870557872354984
Epoch: 92 | Iteration number: [2010/4518] 44% | Training loss: 0.6870514207514957
Epoch: 92 | Iteration number: [2020/4518] 44% | Training loss: 0.687054171538589
Epoch: 92 | Iteration number: [2030/4518] 44% | Training loss: 0.6870492934593426
Epoch: 92 | Iteration number: [2040/4518] 45% | Training loss: 0.6870460267744812
Epoch: 92 | Iteration number: [2050/4518] 45% | Training loss: 0.6870434222279526
Epoch: 92 | Iteration number: [2060/4518] 45% | Training loss: 0.6870424213629325
Epoch: 92 | Iteration number: [2070/4518] 45% | Training loss: 0.6870377227592007
Epoch: 92 | Iteration number: [2080/4518] 46% | Training loss: 0.6870356500721895
Epoch: 92 | Iteration number: [2090/4518] 46% | Training loss: 0.6870316470924177
Epoch: 92 | Iteration number: [2100/4518] 46% | Training loss: 0.6870341245333353
Epoch: 92 | Iteration number: [2110/4518] 46% | Training loss: 0.6870314133958229
Epoch: 92 | Iteration number: [2120/4518] 46% | Training loss: 0.6870278741672354
Epoch: 92 | Iteration number: [2130/4518] 47% | Training loss: 0.6870273561264987
Epoch: 92 | Iteration number: [2140/4518] 47% | Training loss: 0.6870263668142746
Epoch: 92 | Iteration number: [2150/4518] 47% | Training loss: 0.6870260485382967
Epoch: 92 | Iteration number: [2160/4518] 47% | Training loss: 0.6870258523358239
Epoch: 92 | Iteration number: [2170/4518] 48% | Training loss: 0.6870205167526474
Epoch: 92 | Iteration number: [2180/4518] 48% | Training loss: 0.6870166585259482
Epoch: 92 | Iteration number: [2190/4518] 48% | Training loss: 0.6870126536992043
Epoch: 92 | Iteration number: [2200/4518] 48% | Training loss: 0.687010198533535
Epoch: 92 | Iteration number: [2210/4518] 48% | Training loss: 0.6870121787845819
Epoch: 92 | Iteration number: [2220/4518] 49% | Training loss: 0.6870113943879669
Epoch: 92 | Iteration number: [2230/4518] 49% | Training loss: 0.6870098393059633
Epoch: 92 | Iteration number: [2240/4518] 49% | Training loss: 0.6870044976206763
Epoch: 92 | Iteration number: [2250/4518] 49% | Training loss: 0.6870082517994774
Epoch: 92 | Iteration number: [2260/4518] 50% | Training loss: 0.6870089909407945
Epoch: 92 | Iteration number: [2270/4518] 50% | Training loss: 0.6870024894040061
Epoch: 92 | Iteration number: [2280/4518] 50% | Training loss: 0.6870004385709763
Epoch: 92 | Iteration number: [2290/4518] 50% | Training loss: 0.686999581916884
Epoch: 92 | Iteration number: [2300/4518] 50% | Training loss: 0.6869976706349331
Epoch: 92 | Iteration number: [2310/4518] 51% | Training loss: 0.6869948472811546
Epoch: 92 | Iteration number: [2320/4518] 51% | Training loss: 0.6869930826898278
Epoch: 92 | Iteration number: [2330/4518] 51% | Training loss: 0.686993017319446
Epoch: 92 | Iteration number: [2340/4518] 51% | Training loss: 0.6869847264554766
Epoch: 92 | Iteration number: [2350/4518] 52% | Training loss: 0.686979065829135
Epoch: 92 | Iteration number: [2360/4518] 52% | Training loss: 0.6869773007045358
Epoch: 92 | Iteration number: [2370/4518] 52% | Training loss: 0.6869761142549635
Epoch: 92 | Iteration number: [2380/4518] 52% | Training loss: 0.686976603074234
Epoch: 92 | Iteration number: [2390/4518] 52% | Training loss: 0.6869792137684683
Epoch: 92 | Iteration number: [2400/4518] 53% | Training loss: 0.686975301404794
Epoch: 92 | Iteration number: [2410/4518] 53% | Training loss: 0.6869767186799979
Epoch: 92 | Iteration number: [2420/4518] 53% | Training loss: 0.6869742925748352
Epoch: 92 | Iteration number: [2430/4518] 53% | Training loss: 0.6869748375052778
Epoch: 92 | Iteration number: [2440/4518] 54% | Training loss: 0.6869762787320575
Epoch: 92 | Iteration number: [2450/4518] 54% | Training loss: 0.6869762938606496
Epoch: 92 | Iteration number: [2460/4518] 54% | Training loss: 0.6869704075460511
Epoch: 92 | Iteration number: [2470/4518] 54% | Training loss: 0.6869649162900593
Epoch: 92 | Iteration number: [2480/4518] 54% | Training loss: 0.6869628881494845
Epoch: 92 | Iteration number: [2490/4518] 55% | Training loss: 0.6869566399170213
Epoch: 92 | Iteration number: [2500/4518] 55% | Training loss: 0.6869580151557922
Epoch: 92 | Iteration number: [2510/4518] 55% | Training loss: 0.6869550081125768
Epoch: 92 | Iteration number: [2520/4518] 55% | Training loss: 0.6869540055119802
Epoch: 92 | Iteration number: [2530/4518] 55% | Training loss: 0.6869471227463055
Epoch: 92 | Iteration number: [2540/4518] 56% | Training loss: 0.6869476674813924
Epoch: 92 | Iteration number: [2550/4518] 56% | Training loss: 0.6869410871290693
Epoch: 92 | Iteration number: [2560/4518] 56% | Training loss: 0.6869387684157118
Epoch: 92 | Iteration number: [2570/4518] 56% | Training loss: 0.686936327130878
Epoch: 92 | Iteration number: [2580/4518] 57% | Training loss: 0.6869413279516753
Epoch: 92 | Iteration number: [2590/4518] 57% | Training loss: 0.6869403010859912
Epoch: 92 | Iteration number: [2600/4518] 57% | Training loss: 0.6869367928688342
Epoch: 92 | Iteration number: [2610/4518] 57% | Training loss: 0.6869375025860651
Epoch: 92 | Iteration number: [2620/4518] 57% | Training loss: 0.686939083142135
Epoch: 92 | Iteration number: [2630/4518] 58% | Training loss: 0.6869384487318902
Epoch: 92 | Iteration number: [2640/4518] 58% | Training loss: 0.68693691907507
Epoch: 92 | Iteration number: [2650/4518] 58% | Training loss: 0.6869335721573739
Epoch: 92 | Iteration number: [2660/4518] 58% | Training loss: 0.6869322996838648
Epoch: 92 | Iteration number: [2670/4518] 59% | Training loss: 0.6869323173489017
Epoch: 92 | Iteration number: [2680/4518] 59% | Training loss: 0.6869326645758614
Epoch: 92 | Iteration number: [2690/4518] 59% | Training loss: 0.6869293441781325
Epoch: 92 | Iteration number: [2700/4518] 59% | Training loss: 0.6869307051543836
Epoch: 92 | Iteration number: [2710/4518] 59% | Training loss: 0.6869293914069988
Epoch: 92 | Iteration number: [2720/4518] 60% | Training loss: 0.6869285977500327
Epoch: 92 | Iteration number: [2730/4518] 60% | Training loss: 0.6869228028115772
Epoch: 92 | Iteration number: [2740/4518] 60% | Training loss: 0.6869264141268974
Epoch: 92 | Iteration number: [2750/4518] 60% | Training loss: 0.6869216426719319
Epoch: 92 | Iteration number: [2760/4518] 61% | Training loss: 0.6869200898901276
Epoch: 92 | Iteration number: [2770/4518] 61% | Training loss: 0.6869201992823328
Epoch: 92 | Iteration number: [2780/4518] 61% | Training loss: 0.6869160969480336
Epoch: 92 | Iteration number: [2790/4518] 61% | Training loss: 0.6869127282105039
Epoch: 92 | Iteration number: [2800/4518] 61% | Training loss: 0.6869161025754043
Epoch: 92 | Iteration number: [2810/4518] 62% | Training loss: 0.6869169155685927
Epoch: 92 | Iteration number: [2820/4518] 62% | Training loss: 0.6869151558859129
Epoch: 92 | Iteration number: [2830/4518] 62% | Training loss: 0.6869186122720738
Epoch: 92 | Iteration number: [2840/4518] 62% | Training loss: 0.686918595349285
Epoch: 92 | Iteration number: [2850/4518] 63% | Training loss: 0.6869219631479497
Epoch: 92 | Iteration number: [2860/4518] 63% | Training loss: 0.6869196997447448
Epoch: 92 | Iteration number: [2870/4518] 63% | Training loss: 0.6869216983326636
Epoch: 92 | Iteration number: [2880/4518] 63% | Training loss: 0.6869183375810584
Epoch: 92 | Iteration number: [2890/4518] 63% | Training loss: 0.6869171532380127
Epoch: 92 | Iteration number: [2900/4518] 64% | Training loss: 0.6869175127045861
Epoch: 92 | Iteration number: [2910/4518] 64% | Training loss: 0.6869200331443773
Epoch: 92 | Iteration number: [2920/4518] 64% | Training loss: 0.6869197500691022
Epoch: 92 | Iteration number: [2930/4518] 64% | Training loss: 0.6869245784477976
Epoch: 92 | Iteration number: [2940/4518] 65% | Training loss: 0.6869237321371935
Epoch: 92 | Iteration number: [2950/4518] 65% | Training loss: 0.6869261997028933
Epoch: 92 | Iteration number: [2960/4518] 65% | Training loss: 0.6869260299044686
Epoch: 92 | Iteration number: [2970/4518] 65% | Training loss: 0.6869282658854718
Epoch: 92 | Iteration number: [2980/4518] 65% | Training loss: 0.686927555411454
Epoch: 92 | Iteration number: [2990/4518] 66% | Training loss: 0.6869280447928005
Epoch: 92 | Iteration number: [3000/4518] 66% | Training loss: 0.6869245897730192
Epoch: 92 | Iteration number: [3010/4518] 66% | Training loss: 0.6869229716319974
Epoch: 92 | Iteration number: [3020/4518] 66% | Training loss: 0.686921195143106
Epoch: 92 | Iteration number: [3030/4518] 67% | Training loss: 0.6869210472201357
Epoch: 92 | Iteration number: [3040/4518] 67% | Training loss: 0.6869249554449006
Epoch: 92 | Iteration number: [3050/4518] 67% | Training loss: 0.6869251390949624
Epoch: 92 | Iteration number: [3060/4518] 67% | Training loss: 0.6869308194303825
Epoch: 92 | Iteration number: [3070/4518] 67% | Training loss: 0.6869313546617178
Epoch: 92 | Iteration number: [3080/4518] 68% | Training loss: 0.6869280852474176
Epoch: 92 | Iteration number: [3090/4518] 68% | Training loss: 0.686926394295924
Epoch: 92 | Iteration number: [3100/4518] 68% | Training loss: 0.686925701229803
Epoch: 92 | Iteration number: [3110/4518] 68% | Training loss: 0.6869305032434188
Epoch: 92 | Iteration number: [3120/4518] 69% | Training loss: 0.6869289755630188
Epoch: 92 | Iteration number: [3130/4518] 69% | Training loss: 0.6869247769204954
Epoch: 92 | Iteration number: [3140/4518] 69% | Training loss: 0.6869280235023255
Epoch: 92 | Iteration number: [3150/4518] 69% | Training loss: 0.6869246549454946
Epoch: 92 | Iteration number: [3160/4518] 69% | Training loss: 0.6869216650913034
Epoch: 92 | Iteration number: [3170/4518] 70% | Training loss: 0.6869223750352107
Epoch: 92 | Iteration number: [3180/4518] 70% | Training loss: 0.6869223666640948
Epoch: 92 | Iteration number: [3190/4518] 70% | Training loss: 0.6869209832345431
Epoch: 92 | Iteration number: [3200/4518] 70% | Training loss: 0.6869213119149208
Epoch: 92 | Iteration number: [3210/4518] 71% | Training loss: 0.6869192956392639
Epoch: 92 | Iteration number: [3220/4518] 71% | Training loss: 0.6869214081616135
Epoch: 92 | Iteration number: [3230/4518] 71% | Training loss: 0.6869233095978067
Epoch: 92 | Iteration number: [3240/4518] 71% | Training loss: 0.6869206725999161
Epoch: 92 | Iteration number: [3250/4518] 71% | Training loss: 0.6869181226033431
Epoch: 92 | Iteration number: [3260/4518] 72% | Training loss: 0.6869195114066996
Epoch: 92 | Iteration number: [3270/4518] 72% | Training loss: 0.6869224080434269
Epoch: 92 | Iteration number: [3280/4518] 72% | Training loss: 0.6869254932352682
Epoch: 92 | Iteration number: [3290/4518] 72% | Training loss: 0.686925700479003
Epoch: 92 | Iteration number: [3300/4518] 73% | Training loss: 0.686925558682644
Epoch: 92 | Iteration number: [3310/4518] 73% | Training loss: 0.6869229322113659
Epoch: 92 | Iteration number: [3320/4518] 73% | Training loss: 0.6869254570050412
Epoch: 92 | Iteration number: [3330/4518] 73% | Training loss: 0.686927336669183
Epoch: 92 | Iteration number: [3340/4518] 73% | Training loss: 0.6869290213920399
Epoch: 92 | Iteration number: [3350/4518] 74% | Training loss: 0.6869240768276044
Epoch: 92 | Iteration number: [3360/4518] 74% | Training loss: 0.6869244285105239
Epoch: 92 | Iteration number: [3370/4518] 74% | Training loss: 0.6869276603180859
Epoch: 92 | Iteration number: [3380/4518] 74% | Training loss: 0.6869203944354367
Epoch: 92 | Iteration number: [3390/4518] 75% | Training loss: 0.6869153369141188
Epoch: 92 | Iteration number: [3400/4518] 75% | Training loss: 0.6869174667316325
Epoch: 92 | Iteration number: [3410/4518] 75% | Training loss: 0.6869182550837217
Epoch: 92 | Iteration number: [3420/4518] 75% | Training loss: 0.6869196565527665
Epoch: 92 | Iteration number: [3430/4518] 75% | Training loss: 0.6869217454518243
Epoch: 92 | Iteration number: [3440/4518] 76% | Training loss: 0.6869173288518606
Epoch: 92 | Iteration number: [3450/4518] 76% | Training loss: 0.6869192768698154
Epoch: 92 | Iteration number: [3460/4518] 76% | Training loss: 0.6869118679293318
Epoch: 92 | Iteration number: [3470/4518] 76% | Training loss: 0.6869157396063681
Epoch: 92 | Iteration number: [3480/4518] 77% | Training loss: 0.6869168131858453
Epoch: 92 | Iteration number: [3490/4518] 77% | Training loss: 0.6869168654383083
Epoch: 92 | Iteration number: [3500/4518] 77% | Training loss: 0.6869196222850255
Epoch: 92 | Iteration number: [3510/4518] 77% | Training loss: 0.6869191131021223
Epoch: 92 | Iteration number: [3520/4518] 77% | Training loss: 0.686920286393301
Epoch: 92 | Iteration number: [3530/4518] 78% | Training loss: 0.6869178075628307
Epoch: 92 | Iteration number: [3540/4518] 78% | Training loss: 0.6869214692694993
Epoch: 92 | Iteration number: [3550/4518] 78% | Training loss: 0.6869236891874125
Epoch: 92 | Iteration number: [3560/4518] 78% | Training loss: 0.686925152965476
Epoch: 92 | Iteration number: [3570/4518] 79% | Training loss: 0.6869232258876833
Epoch: 92 | Iteration number: [3580/4518] 79% | Training loss: 0.686922802771936
Epoch: 92 | Iteration number: [3590/4518] 79% | Training loss: 0.6869211655141252
Epoch: 92 | Iteration number: [3600/4518] 79% | Training loss: 0.6869222498602338
Epoch: 92 | Iteration number: [3610/4518] 79% | Training loss: 0.6869201930606134
Epoch: 92 | Iteration number: [3620/4518] 80% | Training loss: 0.6869165571684337
Epoch: 92 | Iteration number: [3630/4518] 80% | Training loss: 0.6869191539845848
Epoch: 92 | Iteration number: [3640/4518] 80% | Training loss: 0.6869187792578896
Epoch: 92 | Iteration number: [3650/4518] 80% | Training loss: 0.6869186623129127
Epoch: 92 | Iteration number: [3660/4518] 81% | Training loss: 0.6869186086569979
Epoch: 92 | Iteration number: [3670/4518] 81% | Training loss: 0.6869199825080279
Epoch: 92 | Iteration number: [3680/4518] 81% | Training loss: 0.6869170539728974
Epoch: 92 | Iteration number: [3690/4518] 81% | Training loss: 0.686912221152608
Epoch: 92 | Iteration number: [3700/4518] 81% | Training loss: 0.6869138768395862
Epoch: 92 | Iteration number: [3710/4518] 82% | Training loss: 0.6869106399723783
Epoch: 92 | Iteration number: [3720/4518] 82% | Training loss: 0.6869112973732333
Epoch: 92 | Iteration number: [3730/4518] 82% | Training loss: 0.6869075267468316
Epoch: 92 | Iteration number: [3740/4518] 82% | Training loss: 0.6869080730141165
Epoch: 92 | Iteration number: [3750/4518] 83% | Training loss: 0.68690891178449
Epoch: 92 | Iteration number: [3760/4518] 83% | Training loss: 0.6869099546620187
Epoch: 92 | Iteration number: [3770/4518] 83% | Training loss: 0.6869111586628921
Epoch: 92 | Iteration number: [3780/4518] 83% | Training loss: 0.6869086884789997
Epoch: 92 | Iteration number: [3790/4518] 83% | Training loss: 0.6869036337945581
Epoch: 92 | Iteration number: [3800/4518] 84% | Training loss: 0.6869034727937297
Epoch: 92 | Iteration number: [3810/4518] 84% | Training loss: 0.686903347696845
Epoch: 92 | Iteration number: [3820/4518] 84% | Training loss: 0.6869052418395487
Epoch: 92 | Iteration number: [3830/4518] 84% | Training loss: 0.6869048451630316
Epoch: 92 | Iteration number: [3840/4518] 84% | Training loss: 0.6869080184337993
Epoch: 92 | Iteration number: [3850/4518] 85% | Training loss: 0.6869118784000348
Epoch: 92 | Iteration number: [3860/4518] 85% | Training loss: 0.6869135691403108
Epoch: 92 | Iteration number: [3870/4518] 85% | Training loss: 0.6869106251139974
Epoch: 92 | Iteration number: [3880/4518] 85% | Training loss: 0.6869112842169005
Epoch: 92 | Iteration number: [3890/4518] 86% | Training loss: 0.6869068066687695
Epoch: 92 | Iteration number: [3900/4518] 86% | Training loss: 0.6869072111906149
Epoch: 92 | Iteration number: [3910/4518] 86% | Training loss: 0.6869067506412107
Epoch: 92 | Iteration number: [3920/4518] 86% | Training loss: 0.686906672786085
Epoch: 92 | Iteration number: [3930/4518] 86% | Training loss: 0.6869072983283123
Epoch: 92 | Iteration number: [3940/4518] 87% | Training loss: 0.6869068077524302
Epoch: 92 | Iteration number: [3950/4518] 87% | Training loss: 0.6869067520431326
Epoch: 92 | Iteration number: [3960/4518] 87% | Training loss: 0.6869017815650111
Epoch: 92 | Iteration number: [3970/4518] 87% | Training loss: 0.686903382128372
Epoch: 92 | Iteration number: [3980/4518] 88% | Training loss: 0.6869070174706042
Epoch: 92 | Iteration number: [3990/4518] 88% | Training loss: 0.6869090591158186
Epoch: 92 | Iteration number: [4000/4518] 88% | Training loss: 0.6869090658724308
Epoch: 92 | Iteration number: [4010/4518] 88% | Training loss: 0.6869135855885218
Epoch: 92 | Iteration number: [4020/4518] 88% | Training loss: 0.686910092282058
Epoch: 92 | Iteration number: [4030/4518] 89% | Training loss: 0.6869079753423742
Epoch: 92 | Iteration number: [4040/4518] 89% | Training loss: 0.6869065242238565
Epoch: 92 | Iteration number: [4050/4518] 89% | Training loss: 0.6869088657108354
Epoch: 92 | Iteration number: [4060/4518] 89% | Training loss: 0.6869107222762602
Epoch: 92 | Iteration number: [4070/4518] 90% | Training loss: 0.6869083474250625
Epoch: 92 | Iteration number: [4080/4518] 90% | Training loss: 0.6869049754066795
Epoch: 92 | Iteration number: [4090/4518] 90% | Training loss: 0.6869056818391991
Epoch: 92 | Iteration number: [4100/4518] 90% | Training loss: 0.6869038764005754
Epoch: 92 | Iteration number: [4110/4518] 90% | Training loss: 0.6869035471529856
Epoch: 92 | Iteration number: [4120/4518] 91% | Training loss: 0.6869024479128782
Epoch: 92 | Iteration number: [4130/4518] 91% | Training loss: 0.6869054464248999
Epoch: 92 | Iteration number: [4140/4518] 91% | Training loss: 0.6869049179093273
Epoch: 92 | Iteration number: [4150/4518] 91% | Training loss: 0.6869060998939606
Epoch: 92 | Iteration number: [4160/4518] 92% | Training loss: 0.6869060902211529
Epoch: 92 | Iteration number: [4170/4518] 92% | Training loss: 0.6869058104156018
Epoch: 92 | Iteration number: [4180/4518] 92% | Training loss: 0.686907128697377
Epoch: 92 | Iteration number: [4190/4518] 92% | Training loss: 0.686909110449379
Epoch: 92 | Iteration number: [4200/4518] 92% | Training loss: 0.6869097193933669
Epoch: 92 | Iteration number: [4210/4518] 93% | Training loss: 0.6869121062359165
Epoch: 92 | Iteration number: [4220/4518] 93% | Training loss: 0.6869118398964688
Epoch: 92 | Iteration number: [4230/4518] 93% | Training loss: 0.6869116798360297
Epoch: 92 | Iteration number: [4240/4518] 93% | Training loss: 0.6869119175621924
Epoch: 92 | Iteration number: [4250/4518] 94% | Training loss: 0.6869154941614937
Epoch: 92 | Iteration number: [4260/4518] 94% | Training loss: 0.6869169336249571
Epoch: 92 | Iteration number: [4270/4518] 94% | Training loss: 0.6869179930005754
Epoch: 92 | Iteration number: [4280/4518] 94% | Training loss: 0.686917800741775
Epoch: 92 | Iteration number: [4290/4518] 94% | Training loss: 0.6869177859424155
Epoch: 92 | Iteration number: [4300/4518] 95% | Training loss: 0.6869161056917767
Epoch: 92 | Iteration number: [4310/4518] 95% | Training loss: 0.6869141602460856
Epoch: 92 | Iteration number: [4320/4518] 95% | Training loss: 0.6869152216033803
Epoch: 92 | Iteration number: [4330/4518] 95% | Training loss: 0.6869137181145489
Epoch: 92 | Iteration number: [4340/4518] 96% | Training loss: 0.6869125973519092
Epoch: 92 | Iteration number: [4350/4518] 96% | Training loss: 0.686912895482162
Epoch: 92 | Iteration number: [4360/4518] 96% | Training loss: 0.6869123199117293
Epoch: 92 | Iteration number: [4370/4518] 96% | Training loss: 0.6869139464687155
Epoch: 92 | Iteration number: [4380/4518] 96% | Training loss: 0.6869131567679584
Epoch: 92 | Iteration number: [4390/4518] 97% | Training loss: 0.686910838825556
Epoch: 92 | Iteration number: [4400/4518] 97% | Training loss: 0.6869066799228841
Epoch: 92 | Iteration number: [4410/4518] 97% | Training loss: 0.6869073614647059
Epoch: 92 | Iteration number: [4420/4518] 97% | Training loss: 0.6869058463098776
Epoch: 92 | Iteration number: [4430/4518] 98% | Training loss: 0.6869088985984535
Epoch: 92 | Iteration number: [4440/4518] 98% | Training loss: 0.6869078823172294
Epoch: 92 | Iteration number: [4450/4518] 98% | Training loss: 0.6869096776072898
Epoch: 92 | Iteration number: [4460/4518] 98% | Training loss: 0.6869083448108536
Epoch: 92 | Iteration number: [4470/4518] 98% | Training loss: 0.686909046762475
Epoch: 92 | Iteration number: [4480/4518] 99% | Training loss: 0.6869073915428349
Epoch: 92 | Iteration number: [4490/4518] 99% | Training loss: 0.6869077081536928
Epoch: 92 | Iteration number: [4500/4518] 99% | Training loss: 0.6869083220296436
Epoch: 92 | Iteration number: [4510/4518] 99% | Training loss: 0.6869105154685593

 End of epoch: 92 | Train Loss: 0.6867611900057714 | Training Time: 633 

 End of epoch: 92 | Eval Loss: 0.6899442028026191 | Evaluating Time: 16 
Epoch: 93 | Iteration number: [10/4518] 0% | Training loss: 0.7559225618839264
Epoch: 93 | Iteration number: [20/4518] 0% | Training loss: 0.7213722854852677
Epoch: 93 | Iteration number: [30/4518] 0% | Training loss: 0.7096065600713094
Epoch: 93 | Iteration number: [40/4518] 0% | Training loss: 0.7042056053876877
Epoch: 93 | Iteration number: [50/4518] 1% | Training loss: 0.7006685006618499
Epoch: 93 | Iteration number: [60/4518] 1% | Training loss: 0.6985040913025539
Epoch: 93 | Iteration number: [70/4518] 1% | Training loss: 0.6969274733747755
Epoch: 93 | Iteration number: [80/4518] 1% | Training loss: 0.6957056604325771
Epoch: 93 | Iteration number: [90/4518] 1% | Training loss: 0.6945408178700341
Epoch: 93 | Iteration number: [100/4518] 2% | Training loss: 0.6938135904073716
Epoch: 93 | Iteration number: [110/4518] 2% | Training loss: 0.693200149861249
Epoch: 93 | Iteration number: [120/4518] 2% | Training loss: 0.6926289578278859
Epoch: 93 | Iteration number: [130/4518] 2% | Training loss: 0.6921626517405877
Epoch: 93 | Iteration number: [140/4518] 3% | Training loss: 0.6917872458696366
Epoch: 93 | Iteration number: [150/4518] 3% | Training loss: 0.691543075243632
Epoch: 93 | Iteration number: [160/4518] 3% | Training loss: 0.6912873316556215
Epoch: 93 | Iteration number: [170/4518] 3% | Training loss: 0.6910693866365096
Epoch: 93 | Iteration number: [180/4518] 3% | Training loss: 0.6908144762118658
Epoch: 93 | Iteration number: [190/4518] 4% | Training loss: 0.690613539595353
Epoch: 93 | Iteration number: [200/4518] 4% | Training loss: 0.6904198154807091
Epoch: 93 | Iteration number: [210/4518] 4% | Training loss: 0.6902489991415115
Epoch: 93 | Iteration number: [220/4518] 4% | Training loss: 0.6900970924984325
Epoch: 93 | Iteration number: [230/4518] 5% | Training loss: 0.6899753705314968
Epoch: 93 | Iteration number: [240/4518] 5% | Training loss: 0.6898585639894008
Epoch: 93 | Iteration number: [250/4518] 5% | Training loss: 0.6897586846351623
Epoch: 93 | Iteration number: [260/4518] 5% | Training loss: 0.6896020187781408
Epoch: 93 | Iteration number: [270/4518] 5% | Training loss: 0.6895101792282529
Epoch: 93 | Iteration number: [280/4518] 6% | Training loss: 0.6893954517585891
Epoch: 93 | Iteration number: [290/4518] 6% | Training loss: 0.6892563464312718
Epoch: 93 | Iteration number: [300/4518] 6% | Training loss: 0.6891701422135035
Epoch: 93 | Iteration number: [310/4518] 6% | Training loss: 0.6891119670483374
Epoch: 93 | Iteration number: [320/4518] 7% | Training loss: 0.6890624731779098
Epoch: 93 | Iteration number: [330/4518] 7% | Training loss: 0.6889888049978199
Epoch: 93 | Iteration number: [340/4518] 7% | Training loss: 0.6889471452025806
Epoch: 93 | Iteration number: [350/4518] 7% | Training loss: 0.6888781729766301
Epoch: 93 | Iteration number: [360/4518] 7% | Training loss: 0.6888686665230327
Epoch: 93 | Iteration number: [370/4518] 8% | Training loss: 0.6888062258024473
Epoch: 93 | Iteration number: [380/4518] 8% | Training loss: 0.6887637568147559
Epoch: 93 | Iteration number: [390/4518] 8% | Training loss: 0.6887035372929695
Epoch: 93 | Iteration number: [400/4518] 8% | Training loss: 0.6886661770939827
Epoch: 93 | Iteration number: [410/4518] 9% | Training loss: 0.6886210930056689
Epoch: 93 | Iteration number: [420/4518] 9% | Training loss: 0.6885845960605712
Epoch: 93 | Iteration number: [430/4518] 9% | Training loss: 0.6885161007559577
Epoch: 93 | Iteration number: [440/4518] 9% | Training loss: 0.6884572221474214
Epoch: 93 | Iteration number: [450/4518] 9% | Training loss: 0.6884098022513919
Epoch: 93 | Iteration number: [460/4518] 10% | Training loss: 0.688371059557666
Epoch: 93 | Iteration number: [470/4518] 10% | Training loss: 0.6883355294136291
Epoch: 93 | Iteration number: [480/4518] 10% | Training loss: 0.688319884116451
Epoch: 93 | Iteration number: [490/4518] 10% | Training loss: 0.6882793146736768
Epoch: 93 | Iteration number: [500/4518] 11% | Training loss: 0.6882549171447754
Epoch: 93 | Iteration number: [510/4518] 11% | Training loss: 0.6882382232768863
Epoch: 93 | Iteration number: [520/4518] 11% | Training loss: 0.6882225626936326
Epoch: 93 | Iteration number: [530/4518] 11% | Training loss: 0.688189552415092
Epoch: 93 | Iteration number: [540/4518] 11% | Training loss: 0.6881516947790428
Epoch: 93 | Iteration number: [550/4518] 12% | Training loss: 0.6881326532363892
Epoch: 93 | Iteration number: [560/4518] 12% | Training loss: 0.6881287095802171
Epoch: 93 | Iteration number: [570/4518] 12% | Training loss: 0.6881009365382947
Epoch: 93 | Iteration number: [580/4518] 12% | Training loss: 0.6880992511223103
Epoch: 93 | Iteration number: [590/4518] 13% | Training loss: 0.6880814437138832
Epoch: 93 | Iteration number: [600/4518] 13% | Training loss: 0.6880529675881067
Epoch: 93 | Iteration number: [610/4518] 13% | Training loss: 0.6880268938228732
Epoch: 93 | Iteration number: [620/4518] 13% | Training loss: 0.6879995858477008
Epoch: 93 | Iteration number: [630/4518] 13% | Training loss: 0.6879948597105723
Epoch: 93 | Iteration number: [640/4518] 14% | Training loss: 0.6879892664030194
Epoch: 93 | Iteration number: [650/4518] 14% | Training loss: 0.6879734839842869
Epoch: 93 | Iteration number: [660/4518] 14% | Training loss: 0.6879468872691645
Epoch: 93 | Iteration number: [670/4518] 14% | Training loss: 0.68792785708584
Epoch: 93 | Iteration number: [680/4518] 15% | Training loss: 0.6879265970166992
Epoch: 93 | Iteration number: [690/4518] 15% | Training loss: 0.6878968173179074
Epoch: 93 | Iteration number: [700/4518] 15% | Training loss: 0.6878686998571668
Epoch: 93 | Iteration number: [710/4518] 15% | Training loss: 0.6878679346870369
Epoch: 93 | Iteration number: [720/4518] 15% | Training loss: 0.6878435933755503
Epoch: 93 | Iteration number: [730/4518] 16% | Training loss: 0.6878126775565213
Epoch: 93 | Iteration number: [740/4518] 16% | Training loss: 0.6877863617362203
Epoch: 93 | Iteration number: [750/4518] 16% | Training loss: 0.6877680265108744
Epoch: 93 | Iteration number: [760/4518] 16% | Training loss: 0.6877608115735807
Epoch: 93 | Iteration number: [770/4518] 17% | Training loss: 0.687753813839578
Epoch: 93 | Iteration number: [780/4518] 17% | Training loss: 0.6877413983528431
Epoch: 93 | Iteration number: [790/4518] 17% | Training loss: 0.6877605094185358
Epoch: 93 | Iteration number: [800/4518] 17% | Training loss: 0.6877530796825886
Epoch: 93 | Iteration number: [810/4518] 17% | Training loss: 0.6877339216662042
Epoch: 93 | Iteration number: [820/4518] 18% | Training loss: 0.6877246605913814
Epoch: 93 | Iteration number: [830/4518] 18% | Training loss: 0.6877329926892936
Epoch: 93 | Iteration number: [840/4518] 18% | Training loss: 0.687727552652359
Epoch: 93 | Iteration number: [850/4518] 18% | Training loss: 0.687704647358726
Epoch: 93 | Iteration number: [860/4518] 19% | Training loss: 0.6876942014971444
Epoch: 93 | Iteration number: [870/4518] 19% | Training loss: 0.6876909171027699
Epoch: 93 | Iteration number: [880/4518] 19% | Training loss: 0.687669022178108
Epoch: 93 | Iteration number: [890/4518] 19% | Training loss: 0.6876593930667706
Epoch: 93 | Iteration number: [900/4518] 19% | Training loss: 0.6876461166143417
Epoch: 93 | Iteration number: [910/4518] 20% | Training loss: 0.6876306065491268
Epoch: 93 | Iteration number: [920/4518] 20% | Training loss: 0.6876209059487218
Epoch: 93 | Iteration number: [930/4518] 20% | Training loss: 0.6875898981607088
Epoch: 93 | Iteration number: [940/4518] 20% | Training loss: 0.6875712729514913
Epoch: 93 | Iteration number: [950/4518] 21% | Training loss: 0.6875681610483872
Epoch: 93 | Iteration number: [960/4518] 21% | Training loss: 0.6875608186547955
Epoch: 93 | Iteration number: [970/4518] 21% | Training loss: 0.6875558555740671
Epoch: 93 | Iteration number: [980/4518] 21% | Training loss: 0.687556653302543
Epoch: 93 | Iteration number: [990/4518] 21% | Training loss: 0.6875372519396772
Epoch: 93 | Iteration number: [1000/4518] 22% | Training loss: 0.6875274093747139
Epoch: 93 | Iteration number: [1010/4518] 22% | Training loss: 0.6875217749930844
Epoch: 93 | Iteration number: [1020/4518] 22% | Training loss: 0.6875169329783496
Epoch: 93 | Iteration number: [1030/4518] 22% | Training loss: 0.6875253851552612
Epoch: 93 | Iteration number: [1040/4518] 23% | Training loss: 0.6875196518806311
Epoch: 93 | Iteration number: [1050/4518] 23% | Training loss: 0.6875046187355405
Epoch: 93 | Iteration number: [1060/4518] 23% | Training loss: 0.6874854393162817
Epoch: 93 | Iteration number: [1070/4518] 23% | Training loss: 0.6874878620432916
Epoch: 93 | Iteration number: [1080/4518] 23% | Training loss: 0.6874770122545737
Epoch: 93 | Iteration number: [1090/4518] 24% | Training loss: 0.687473998430672
Epoch: 93 | Iteration number: [1100/4518] 24% | Training loss: 0.687468245733868
Epoch: 93 | Iteration number: [1110/4518] 24% | Training loss: 0.6874553404412828
Epoch: 93 | Iteration number: [1120/4518] 24% | Training loss: 0.687443947525961
Epoch: 93 | Iteration number: [1130/4518] 25% | Training loss: 0.6874358292702025
Epoch: 93 | Iteration number: [1140/4518] 25% | Training loss: 0.6874347714478509
Epoch: 93 | Iteration number: [1150/4518] 25% | Training loss: 0.687429809362992
Epoch: 93 | Iteration number: [1160/4518] 25% | Training loss: 0.6874213759241433
Epoch: 93 | Iteration number: [1170/4518] 25% | Training loss: 0.6874121467781882
Epoch: 93 | Iteration number: [1180/4518] 26% | Training loss: 0.6874069640191934
Epoch: 93 | Iteration number: [1190/4518] 26% | Training loss: 0.68740828643326
Epoch: 93 | Iteration number: [1200/4518] 26% | Training loss: 0.6873973025381566
Epoch: 93 | Iteration number: [1210/4518] 26% | Training loss: 0.687392262732687
Epoch: 93 | Iteration number: [1220/4518] 27% | Training loss: 0.6873918235790534
Epoch: 93 | Iteration number: [1230/4518] 27% | Training loss: 0.6873906011988477
Epoch: 93 | Iteration number: [1240/4518] 27% | Training loss: 0.6873816267136604
Epoch: 93 | Iteration number: [1250/4518] 27% | Training loss: 0.6873791015625
Epoch: 93 | Iteration number: [1260/4518] 27% | Training loss: 0.6873665721643538
Epoch: 93 | Iteration number: [1270/4518] 28% | Training loss: 0.6873667440076513
Epoch: 93 | Iteration number: [1280/4518] 28% | Training loss: 0.6873606567271053
Epoch: 93 | Iteration number: [1290/4518] 28% | Training loss: 0.687367961757867
Epoch: 93 | Iteration number: [1300/4518] 28% | Training loss: 0.6873667677090718
Epoch: 93 | Iteration number: [1310/4518] 28% | Training loss: 0.6873592297994453
Epoch: 93 | Iteration number: [1320/4518] 29% | Training loss: 0.687355174169396
Epoch: 93 | Iteration number: [1330/4518] 29% | Training loss: 0.6873441869603064
Epoch: 93 | Iteration number: [1340/4518] 29% | Training loss: 0.6873368835271294
Epoch: 93 | Iteration number: [1350/4518] 29% | Training loss: 0.6873288012875451
Epoch: 93 | Iteration number: [1360/4518] 30% | Training loss: 0.6873133639640668
Epoch: 93 | Iteration number: [1370/4518] 30% | Training loss: 0.6873120793896
Epoch: 93 | Iteration number: [1380/4518] 30% | Training loss: 0.6873078339773676
Epoch: 93 | Iteration number: [1390/4518] 30% | Training loss: 0.6873039422275351
Epoch: 93 | Iteration number: [1400/4518] 30% | Training loss: 0.6873006585240364
Epoch: 93 | Iteration number: [1410/4518] 31% | Training loss: 0.6873074085154431
Epoch: 93 | Iteration number: [1420/4518] 31% | Training loss: 0.6873085514760353
Epoch: 93 | Iteration number: [1430/4518] 31% | Training loss: 0.6872962056340037
Epoch: 93 | Iteration number: [1440/4518] 31% | Training loss: 0.6872985987613599
Epoch: 93 | Iteration number: [1450/4518] 32% | Training loss: 0.6872989397624444
Epoch: 93 | Iteration number: [1460/4518] 32% | Training loss: 0.6873068802977261
Epoch: 93 | Iteration number: [1470/4518] 32% | Training loss: 0.6873025160257508
Epoch: 93 | Iteration number: [1480/4518] 32% | Training loss: 0.6873025876444739
Epoch: 93 | Iteration number: [1490/4518] 32% | Training loss: 0.6873000291369905
Epoch: 93 | Iteration number: [1500/4518] 33% | Training loss: 0.687284676194191
Epoch: 93 | Iteration number: [1510/4518] 33% | Training loss: 0.6872811187971507
Epoch: 93 | Iteration number: [1520/4518] 33% | Training loss: 0.6872753584855481
Epoch: 93 | Iteration number: [1530/4518] 33% | Training loss: 0.687266583068698
Epoch: 93 | Iteration number: [1540/4518] 34% | Training loss: 0.6872727038798394
Epoch: 93 | Iteration number: [1550/4518] 34% | Training loss: 0.687274081284
Epoch: 93 | Iteration number: [1560/4518] 34% | Training loss: 0.6872619251792248
Epoch: 93 | Iteration number: [1570/4518] 34% | Training loss: 0.6872470651082931
Epoch: 93 | Iteration number: [1580/4518] 34% | Training loss: 0.6872517148527918
Epoch: 93 | Iteration number: [1590/4518] 35% | Training loss: 0.6872496189186408
Epoch: 93 | Iteration number: [1600/4518] 35% | Training loss: 0.6872472444176674
Epoch: 93 | Iteration number: [1610/4518] 35% | Training loss: 0.6872430152034167
Epoch: 93 | Iteration number: [1620/4518] 35% | Training loss: 0.68725125933135
Epoch: 93 | Iteration number: [1630/4518] 36% | Training loss: 0.6872405120200175
Epoch: 93 | Iteration number: [1640/4518] 36% | Training loss: 0.6872335986756697
Epoch: 93 | Iteration number: [1650/4518] 36% | Training loss: 0.68723477862098
Epoch: 93 | Iteration number: [1660/4518] 36% | Training loss: 0.6872254511319011
Epoch: 93 | Iteration number: [1670/4518] 36% | Training loss: 0.6872250159343559
Epoch: 93 | Iteration number: [1680/4518] 37% | Training loss: 0.6872205806275209
Epoch: 93 | Iteration number: [1690/4518] 37% | Training loss: 0.6872179282134807
Epoch: 93 | Iteration number: [1700/4518] 37% | Training loss: 0.6872168645438026
Epoch: 93 | Iteration number: [1710/4518] 37% | Training loss: 0.6872185227815171
Epoch: 93 | Iteration number: [1720/4518] 38% | Training loss: 0.6872123318702675
Epoch: 93 | Iteration number: [1730/4518] 38% | Training loss: 0.6872080022889065
Epoch: 93 | Iteration number: [1740/4518] 38% | Training loss: 0.6872056555816497
Epoch: 93 | Iteration number: [1750/4518] 38% | Training loss: 0.6872034220014299
Epoch: 93 | Iteration number: [1760/4518] 38% | Training loss: 0.687202876298265
Epoch: 93 | Iteration number: [1770/4518] 39% | Training loss: 0.6872069648430172
Epoch: 93 | Iteration number: [1780/4518] 39% | Training loss: 0.6872078125396471
Epoch: 93 | Iteration number: [1790/4518] 39% | Training loss: 0.687202817234913
Epoch: 93 | Iteration number: [1800/4518] 39% | Training loss: 0.6871983285744985
Epoch: 93 | Iteration number: [1810/4518] 40% | Training loss: 0.687195309914278
Epoch: 93 | Iteration number: [1820/4518] 40% | Training loss: 0.6871881855713142
Epoch: 93 | Iteration number: [1830/4518] 40% | Training loss: 0.6871862628746553
Epoch: 93 | Iteration number: [1840/4518] 40% | Training loss: 0.6871815143719964
Epoch: 93 | Iteration number: [1850/4518] 40% | Training loss: 0.6871772653992112
Epoch: 93 | Iteration number: [1860/4518] 41% | Training loss: 0.687168810476539
Epoch: 93 | Iteration number: [1870/4518] 41% | Training loss: 0.6871662312331684
Epoch: 93 | Iteration number: [1880/4518] 41% | Training loss: 0.687163540689235
Epoch: 93 | Iteration number: [1890/4518] 41% | Training loss: 0.6871560328221195
Epoch: 93 | Iteration number: [1900/4518] 42% | Training loss: 0.6871546992816423
Epoch: 93 | Iteration number: [1910/4518] 42% | Training loss: 0.6871545611251711
Epoch: 93 | Iteration number: [1920/4518] 42% | Training loss: 0.6871512648649514
Epoch: 93 | Iteration number: [1930/4518] 42% | Training loss: 0.6871554342576259
Epoch: 93 | Iteration number: [1940/4518] 42% | Training loss: 0.6871549469908488
Epoch: 93 | Iteration number: [1950/4518] 43% | Training loss: 0.6871477317810059
Epoch: 93 | Iteration number: [1960/4518] 43% | Training loss: 0.6871427252280469
Epoch: 93 | Iteration number: [1970/4518] 43% | Training loss: 0.687138641848782
Epoch: 93 | Iteration number: [1980/4518] 43% | Training loss: 0.6871348168512788
Epoch: 93 | Iteration number: [1990/4518] 44% | Training loss: 0.6871315986966368
Epoch: 93 | Iteration number: [2000/4518] 44% | Training loss: 0.68712683609128
Epoch: 93 | Iteration number: [2010/4518] 44% | Training loss: 0.6871249949457634
Epoch: 93 | Iteration number: [2020/4518] 44% | Training loss: 0.6871198231926059
Epoch: 93 | Iteration number: [2030/4518] 44% | Training loss: 0.6871174388331146
Epoch: 93 | Iteration number: [2040/4518] 45% | Training loss: 0.6871194952843236
Epoch: 93 | Iteration number: [2050/4518] 45% | Training loss: 0.6871193487469743
Epoch: 93 | Iteration number: [2060/4518] 45% | Training loss: 0.6871097243526607
Epoch: 93 | Iteration number: [2070/4518] 45% | Training loss: 0.6871019791289804
Epoch: 93 | Iteration number: [2080/4518] 46% | Training loss: 0.6870947906317619
Epoch: 93 | Iteration number: [2090/4518] 46% | Training loss: 0.68709373559678
Epoch: 93 | Iteration number: [2100/4518] 46% | Training loss: 0.6870945495650882
Epoch: 93 | Iteration number: [2110/4518] 46% | Training loss: 0.6870954380781165
Epoch: 93 | Iteration number: [2120/4518] 46% | Training loss: 0.6870937256599372
Epoch: 93 | Iteration number: [2130/4518] 47% | Training loss: 0.6870836906030144
Epoch: 93 | Iteration number: [2140/4518] 47% | Training loss: 0.687086973986893
Epoch: 93 | Iteration number: [2150/4518] 47% | Training loss: 0.6870839523714642
Epoch: 93 | Iteration number: [2160/4518] 47% | Training loss: 0.6870793641441398
Epoch: 93 | Iteration number: [2170/4518] 48% | Training loss: 0.6870782386048049
Epoch: 93 | Iteration number: [2180/4518] 48% | Training loss: 0.687077350408659
Epoch: 93 | Iteration number: [2190/4518] 48% | Training loss: 0.6870696656235821
Epoch: 93 | Iteration number: [2200/4518] 48% | Training loss: 0.6870708038048311
Epoch: 93 | Iteration number: [2210/4518] 48% | Training loss: 0.6870679011172299
Epoch: 93 | Iteration number: [2220/4518] 49% | Training loss: 0.6870680928767264
Epoch: 93 | Iteration number: [2230/4518] 49% | Training loss: 0.687060937218602
Epoch: 93 | Iteration number: [2240/4518] 49% | Training loss: 0.6870535277628473
Epoch: 93 | Iteration number: [2250/4518] 49% | Training loss: 0.6870493671629164
Epoch: 93 | Iteration number: [2260/4518] 50% | Training loss: 0.6870467032215236
Epoch: 93 | Iteration number: [2270/4518] 50% | Training loss: 0.6870438961468079
Epoch: 93 | Iteration number: [2280/4518] 50% | Training loss: 0.6870442687942271
Epoch: 93 | Iteration number: [2290/4518] 50% | Training loss: 0.6870458394419158
Epoch: 93 | Iteration number: [2300/4518] 50% | Training loss: 0.687045493747877
Epoch: 93 | Iteration number: [2310/4518] 51% | Training loss: 0.6870454657129395
Epoch: 93 | Iteration number: [2320/4518] 51% | Training loss: 0.6870513723071279
Epoch: 93 | Iteration number: [2330/4518] 51% | Training loss: 0.6870522813991415
Epoch: 93 | Iteration number: [2340/4518] 51% | Training loss: 0.6870533399092845
Epoch: 93 | Iteration number: [2350/4518] 52% | Training loss: 0.6870520351541803
Epoch: 93 | Iteration number: [2360/4518] 52% | Training loss: 0.6870395531593743
Epoch: 93 | Iteration number: [2370/4518] 52% | Training loss: 0.687038134371681
Epoch: 93 | Iteration number: [2380/4518] 52% | Training loss: 0.6870412737631998
Epoch: 93 | Iteration number: [2390/4518] 52% | Training loss: 0.6870361170010587
Epoch: 93 | Iteration number: [2400/4518] 53% | Training loss: 0.6870372119297584
Epoch: 93 | Iteration number: [2410/4518] 53% | Training loss: 0.6870357112765807
Epoch: 93 | Iteration number: [2420/4518] 53% | Training loss: 0.6870380961205349
Epoch: 93 | Iteration number: [2430/4518] 53% | Training loss: 0.6870378601207655
Epoch: 93 | Iteration number: [2440/4518] 54% | Training loss: 0.6870378082648653
Epoch: 93 | Iteration number: [2450/4518] 54% | Training loss: 0.6870366397439217
Epoch: 93 | Iteration number: [2460/4518] 54% | Training loss: 0.6870290042908211
Epoch: 93 | Iteration number: [2470/4518] 54% | Training loss: 0.6870283660135771
Epoch: 93 | Iteration number: [2480/4518] 54% | Training loss: 0.6870266958350135
Epoch: 93 | Iteration number: [2490/4518] 55% | Training loss: 0.6870267763195268
Epoch: 93 | Iteration number: [2500/4518] 55% | Training loss: 0.687029782652855
Epoch: 93 | Iteration number: [2510/4518] 55% | Training loss: 0.6870303739114586
Epoch: 93 | Iteration number: [2520/4518] 55% | Training loss: 0.6870308360883168
Epoch: 93 | Iteration number: [2530/4518] 55% | Training loss: 0.6870303193571068
Epoch: 93 | Iteration number: [2540/4518] 56% | Training loss: 0.6870285726907686
Epoch: 93 | Iteration number: [2550/4518] 56% | Training loss: 0.6870265873506958
Epoch: 93 | Iteration number: [2560/4518] 56% | Training loss: 0.6870298101799562
Epoch: 93 | Iteration number: [2570/4518] 56% | Training loss: 0.6870280923314596
Epoch: 93 | Iteration number: [2580/4518] 57% | Training loss: 0.6870304715263751
Epoch: 93 | Iteration number: [2590/4518] 57% | Training loss: 0.6870258645891683
Epoch: 93 | Iteration number: [2600/4518] 57% | Training loss: 0.687025213768849
Epoch: 93 | Iteration number: [2610/4518] 57% | Training loss: 0.687024349042739
Epoch: 93 | Iteration number: [2620/4518] 57% | Training loss: 0.6870259292935597
Epoch: 93 | Iteration number: [2630/4518] 58% | Training loss: 0.6870206382564719
Epoch: 93 | Iteration number: [2640/4518] 58% | Training loss: 0.6870198268330459
Epoch: 93 | Iteration number: [2650/4518] 58% | Training loss: 0.6870146057515775
Epoch: 93 | Iteration number: [2660/4518] 58% | Training loss: 0.6870130811418805
Epoch: 93 | Iteration number: [2670/4518] 59% | Training loss: 0.6870135622971066
Epoch: 93 | Iteration number: [2680/4518] 59% | Training loss: 0.6870125333319849
Epoch: 93 | Iteration number: [2690/4518] 59% | Training loss: 0.6870080926161273
Epoch: 93 | Iteration number: [2700/4518] 59% | Training loss: 0.6870098836112906
Epoch: 93 | Iteration number: [2710/4518] 59% | Training loss: 0.6870129497948608
Epoch: 93 | Iteration number: [2720/4518] 60% | Training loss: 0.6870105039766606
Epoch: 93 | Iteration number: [2730/4518] 60% | Training loss: 0.6870094245606726
Epoch: 93 | Iteration number: [2740/4518] 60% | Training loss: 0.6870062770199602
Epoch: 93 | Iteration number: [2750/4518] 60% | Training loss: 0.6870042502880096
Epoch: 93 | Iteration number: [2760/4518] 61% | Training loss: 0.687010195656963
Epoch: 93 | Iteration number: [2770/4518] 61% | Training loss: 0.6870054727211756
Epoch: 93 | Iteration number: [2780/4518] 61% | Training loss: 0.6870025130699007
Epoch: 93 | Iteration number: [2790/4518] 61% | Training loss: 0.6870062059612685
Epoch: 93 | Iteration number: [2800/4518] 61% | Training loss: 0.6870058976539544
Epoch: 93 | Iteration number: [2810/4518] 62% | Training loss: 0.687003833013073
Epoch: 93 | Iteration number: [2820/4518] 62% | Training loss: 0.6869993494757524
Epoch: 93 | Iteration number: [2830/4518] 62% | Training loss: 0.6869944180490272
Epoch: 93 | Iteration number: [2840/4518] 62% | Training loss: 0.6869912934555135
Epoch: 93 | Iteration number: [2850/4518] 63% | Training loss: 0.6869864308624937
Epoch: 93 | Iteration number: [2860/4518] 63% | Training loss: 0.6869920012000558
Epoch: 93 | Iteration number: [2870/4518] 63% | Training loss: 0.6869942705182663
Epoch: 93 | Iteration number: [2880/4518] 63% | Training loss: 0.6869913062701622
Epoch: 93 | Iteration number: [2890/4518] 63% | Training loss: 0.6869866711870609
Epoch: 93 | Iteration number: [2900/4518] 64% | Training loss: 0.6869798230508278
Epoch: 93 | Iteration number: [2910/4518] 64% | Training loss: 0.686980530404553
Epoch: 93 | Iteration number: [2920/4518] 64% | Training loss: 0.6869804114103317
Epoch: 93 | Iteration number: [2930/4518] 64% | Training loss: 0.6869787303660917
Epoch: 93 | Iteration number: [2940/4518] 65% | Training loss: 0.6869809173605069
Epoch: 93 | Iteration number: [2950/4518] 65% | Training loss: 0.6869778637966867
Epoch: 93 | Iteration number: [2960/4518] 65% | Training loss: 0.6869732228888048
Epoch: 93 | Iteration number: [2970/4518] 65% | Training loss: 0.6869727988837142
Epoch: 93 | Iteration number: [2980/4518] 65% | Training loss: 0.6869728884840972
Epoch: 93 | Iteration number: [2990/4518] 66% | Training loss: 0.6869695689566558
Epoch: 93 | Iteration number: [3000/4518] 66% | Training loss: 0.6869715269406637
Epoch: 93 | Iteration number: [3010/4518] 66% | Training loss: 0.6869749939916934
Epoch: 93 | Iteration number: [3020/4518] 66% | Training loss: 0.6869751401689669
Epoch: 93 | Iteration number: [3030/4518] 67% | Training loss: 0.6869766364396602
Epoch: 93 | Iteration number: [3040/4518] 67% | Training loss: 0.6869745314905518
Epoch: 93 | Iteration number: [3050/4518] 67% | Training loss: 0.6869721205312698
Epoch: 93 | Iteration number: [3060/4518] 67% | Training loss: 0.6869714283865261
Epoch: 93 | Iteration number: [3070/4518] 67% | Training loss: 0.686967358255231
Epoch: 93 | Iteration number: [3080/4518] 68% | Training loss: 0.6869714956585463
Epoch: 93 | Iteration number: [3090/4518] 68% | Training loss: 0.6869708509699812
Epoch: 93 | Iteration number: [3100/4518] 68% | Training loss: 0.6869724458263766
Epoch: 93 | Iteration number: [3110/4518] 68% | Training loss: 0.6869757522340756
Epoch: 93 | Iteration number: [3120/4518] 69% | Training loss: 0.6869753637183935
Epoch: 93 | Iteration number: [3130/4518] 69% | Training loss: 0.6869734147676645
Epoch: 93 | Iteration number: [3140/4518] 69% | Training loss: 0.6869722455550151
Epoch: 93 | Iteration number: [3150/4518] 69% | Training loss: 0.6869685397829328
Epoch: 93 | Iteration number: [3160/4518] 69% | Training loss: 0.6869698776663105
Epoch: 93 | Iteration number: [3170/4518] 70% | Training loss: 0.6869689519097
Epoch: 93 | Iteration number: [3180/4518] 70% | Training loss: 0.6869693293511493
Epoch: 93 | Iteration number: [3190/4518] 70% | Training loss: 0.6869632545683452
Epoch: 93 | Iteration number: [3200/4518] 70% | Training loss: 0.6869628855586052
Epoch: 93 | Iteration number: [3210/4518] 71% | Training loss: 0.6869564015360264
Epoch: 93 | Iteration number: [3220/4518] 71% | Training loss: 0.6869560859403255
Epoch: 93 | Iteration number: [3230/4518] 71% | Training loss: 0.6869582869320093
Epoch: 93 | Iteration number: [3240/4518] 71% | Training loss: 0.6869564209455326
Epoch: 93 | Iteration number: [3250/4518] 71% | Training loss: 0.6869574970648838
Epoch: 93 | Iteration number: [3260/4518] 72% | Training loss: 0.6869578785325852
Epoch: 93 | Iteration number: [3270/4518] 72% | Training loss: 0.6869548810731381
Epoch: 93 | Iteration number: [3280/4518] 72% | Training loss: 0.6869532372893357
Epoch: 93 | Iteration number: [3290/4518] 72% | Training loss: 0.6869535263004999
Epoch: 93 | Iteration number: [3300/4518] 73% | Training loss: 0.68695459466992
Epoch: 93 | Iteration number: [3310/4518] 73% | Training loss: 0.6869511916738262
Epoch: 93 | Iteration number: [3320/4518] 73% | Training loss: 0.6869525940662407
Epoch: 93 | Iteration number: [3330/4518] 73% | Training loss: 0.6869509264155551
Epoch: 93 | Iteration number: [3340/4518] 73% | Training loss: 0.6869490809961707
Epoch: 93 | Iteration number: [3350/4518] 74% | Training loss: 0.6869495052366115
Epoch: 93 | Iteration number: [3360/4518] 74% | Training loss: 0.6869501718275604
Epoch: 93 | Iteration number: [3370/4518] 74% | Training loss: 0.6869482739212251
Epoch: 93 | Iteration number: [3380/4518] 74% | Training loss: 0.6869468888763846
Epoch: 93 | Iteration number: [3390/4518] 75% | Training loss: 0.6869456273264589
Epoch: 93 | Iteration number: [3400/4518] 75% | Training loss: 0.6869475744401707
Epoch: 93 | Iteration number: [3410/4518] 75% | Training loss: 0.6869450450992305
Epoch: 93 | Iteration number: [3420/4518] 75% | Training loss: 0.6869434981492528
Epoch: 93 | Iteration number: [3430/4518] 75% | Training loss: 0.6869424744006843
Epoch: 93 | Iteration number: [3440/4518] 76% | Training loss: 0.6869446982131447
Epoch: 93 | Iteration number: [3450/4518] 76% | Training loss: 0.6869421537544417
Epoch: 93 | Iteration number: [3460/4518] 76% | Training loss: 0.6869435293998333
Epoch: 93 | Iteration number: [3470/4518] 76% | Training loss: 0.6869411045089578
Epoch: 93 | Iteration number: [3480/4518] 77% | Training loss: 0.6869391003045543
Epoch: 93 | Iteration number: [3490/4518] 77% | Training loss: 0.6869364913008617
Epoch: 93 | Iteration number: [3500/4518] 77% | Training loss: 0.6869346212659563
Epoch: 93 | Iteration number: [3510/4518] 77% | Training loss: 0.6869305038723851
Epoch: 93 | Iteration number: [3520/4518] 77% | Training loss: 0.6869318583133546
Epoch: 93 | Iteration number: [3530/4518] 78% | Training loss: 0.6869341765179513
Epoch: 93 | Iteration number: [3540/4518] 78% | Training loss: 0.6869365463317451
Epoch: 93 | Iteration number: [3550/4518] 78% | Training loss: 0.6869332293053748
Epoch: 93 | Iteration number: [3560/4518] 78% | Training loss: 0.6869335764914416
Epoch: 93 | Iteration number: [3570/4518] 79% | Training loss: 0.6869349843647634
Epoch: 93 | Iteration number: [3580/4518] 79% | Training loss: 0.6869338123658516
Epoch: 93 | Iteration number: [3590/4518] 79% | Training loss: 0.6869294766762131
Epoch: 93 | Iteration number: [3600/4518] 79% | Training loss: 0.686932882749372
Epoch: 93 | Iteration number: [3610/4518] 79% | Training loss: 0.6869332115075595
Epoch: 93 | Iteration number: [3620/4518] 80% | Training loss: 0.6869355626692429
Epoch: 93 | Iteration number: [3630/4518] 80% | Training loss: 0.686933266147766
Epoch: 93 | Iteration number: [3640/4518] 80% | Training loss: 0.6869316937340485
Epoch: 93 | Iteration number: [3650/4518] 80% | Training loss: 0.686931021425822
Epoch: 93 | Iteration number: [3660/4518] 81% | Training loss: 0.6869270692431861
Epoch: 93 | Iteration number: [3670/4518] 81% | Training loss: 0.6869231426748333
Epoch: 93 | Iteration number: [3680/4518] 81% | Training loss: 0.6869228342952935
Epoch: 93 | Iteration number: [3690/4518] 81% | Training loss: 0.6869243125443859
Epoch: 93 | Iteration number: [3700/4518] 81% | Training loss: 0.6869252619872223
Epoch: 93 | Iteration number: [3710/4518] 82% | Training loss: 0.686925817017928
Epoch: 93 | Iteration number: [3720/4518] 82% | Training loss: 0.6869254287212125
Epoch: 93 | Iteration number: [3730/4518] 82% | Training loss: 0.6869261890090502
Epoch: 93 | Iteration number: [3740/4518] 82% | Training loss: 0.686925722969407
Epoch: 93 | Iteration number: [3750/4518] 83% | Training loss: 0.6869282447655995
Epoch: 93 | Iteration number: [3760/4518] 83% | Training loss: 0.6869293622514034
Epoch: 93 | Iteration number: [3770/4518] 83% | Training loss: 0.6869304915796224
Epoch: 93 | Iteration number: [3780/4518] 83% | Training loss: 0.6869286458012919
Epoch: 93 | Iteration number: [3790/4518] 83% | Training loss: 0.6869277456819539
Epoch: 93 | Iteration number: [3800/4518] 84% | Training loss: 0.6869295174354001
Epoch: 93 | Iteration number: [3810/4518] 84% | Training loss: 0.6869315812593996
Epoch: 93 | Iteration number: [3820/4518] 84% | Training loss: 0.686934505083174
Epoch: 93 | Iteration number: [3830/4518] 84% | Training loss: 0.6869335114955902
Epoch: 93 | Iteration number: [3840/4518] 84% | Training loss: 0.686931539978832
Epoch: 93 | Iteration number: [3850/4518] 85% | Training loss: 0.6869317742911252
Epoch: 93 | Iteration number: [3860/4518] 85% | Training loss: 0.6869282927846662
Epoch: 93 | Iteration number: [3870/4518] 85% | Training loss: 0.6869265959244366
Epoch: 93 | Iteration number: [3880/4518] 85% | Training loss: 0.6869244033374737
Epoch: 93 | Iteration number: [3890/4518] 86% | Training loss: 0.6869251788888309
Epoch: 93 | Iteration number: [3900/4518] 86% | Training loss: 0.6869235503062224
Epoch: 93 | Iteration number: [3910/4518] 86% | Training loss: 0.6869239940057935
Epoch: 93 | Iteration number: [3920/4518] 86% | Training loss: 0.6869252581833577
Epoch: 93 | Iteration number: [3930/4518] 86% | Training loss: 0.6869269815565066
Epoch: 93 | Iteration number: [3940/4518] 87% | Training loss: 0.686927756258679
Epoch: 93 | Iteration number: [3950/4518] 87% | Training loss: 0.6869307002689266
Epoch: 93 | Iteration number: [3960/4518] 87% | Training loss: 0.6869328506366171
Epoch: 93 | Iteration number: [3970/4518] 87% | Training loss: 0.6869354238588203
Epoch: 93 | Iteration number: [3980/4518] 88% | Training loss: 0.6869363871201798
Epoch: 93 | Iteration number: [3990/4518] 88% | Training loss: 0.686932966628469
Epoch: 93 | Iteration number: [4000/4518] 88% | Training loss: 0.6869353010803461
Epoch: 93 | Iteration number: [4010/4518] 88% | Training loss: 0.6869323019969493
Epoch: 93 | Iteration number: [4020/4518] 88% | Training loss: 0.6869289602064967
Epoch: 93 | Iteration number: [4030/4518] 89% | Training loss: 0.6869286232639483
Epoch: 93 | Iteration number: [4040/4518] 89% | Training loss: 0.6869261406140752
Epoch: 93 | Iteration number: [4050/4518] 89% | Training loss: 0.6869270713829699
Epoch: 93 | Iteration number: [4060/4518] 89% | Training loss: 0.6869295353959934
Epoch: 93 | Iteration number: [4070/4518] 90% | Training loss: 0.6869276937747177
Epoch: 93 | Iteration number: [4080/4518] 90% | Training loss: 0.6869278375862861
Epoch: 93 | Iteration number: [4090/4518] 90% | Training loss: 0.6869266065379518
Epoch: 93 | Iteration number: [4100/4518] 90% | Training loss: 0.6869226007345246
Epoch: 93 | Iteration number: [4110/4518] 90% | Training loss: 0.686922681389644
Epoch: 93 | Iteration number: [4120/4518] 91% | Training loss: 0.6869202384381619
Epoch: 93 | Iteration number: [4130/4518] 91% | Training loss: 0.6869210973057274
Epoch: 93 | Iteration number: [4140/4518] 91% | Training loss: 0.6869203199079071
Epoch: 93 | Iteration number: [4150/4518] 91% | Training loss: 0.6869171434138195
Epoch: 93 | Iteration number: [4160/4518] 92% | Training loss: 0.6869163190516142
Epoch: 93 | Iteration number: [4170/4518] 92% | Training loss: 0.6869173989450331
Epoch: 93 | Iteration number: [4180/4518] 92% | Training loss: 0.6869155000556599
Epoch: 93 | Iteration number: [4190/4518] 92% | Training loss: 0.6869162480558018
Epoch: 93 | Iteration number: [4200/4518] 92% | Training loss: 0.6869150898002443
Epoch: 93 | Iteration number: [4210/4518] 93% | Training loss: 0.6869134369343873
Epoch: 93 | Iteration number: [4220/4518] 93% | Training loss: 0.6869135246881376
Epoch: 93 | Iteration number: [4230/4518] 93% | Training loss: 0.686911071431834
Epoch: 93 | Iteration number: [4240/4518] 93% | Training loss: 0.6869083908228379
Epoch: 93 | Iteration number: [4250/4518] 94% | Training loss: 0.6869098404014812
Epoch: 93 | Iteration number: [4260/4518] 94% | Training loss: 0.6869061562516879
Epoch: 93 | Iteration number: [4270/4518] 94% | Training loss: 0.6869052999471892
Epoch: 93 | Iteration number: [4280/4518] 94% | Training loss: 0.6869056295429434
Epoch: 93 | Iteration number: [4290/4518] 94% | Training loss: 0.6869029854700004
Epoch: 93 | Iteration number: [4300/4518] 95% | Training loss: 0.6869032134982043
Epoch: 93 | Iteration number: [4310/4518] 95% | Training loss: 0.6868992179009865
Epoch: 93 | Iteration number: [4320/4518] 95% | Training loss: 0.6868992596450779
Epoch: 93 | Iteration number: [4330/4518] 95% | Training loss: 0.6869006198080252
Epoch: 93 | Iteration number: [4340/4518] 96% | Training loss: 0.6869025564688142
Epoch: 93 | Iteration number: [4350/4518] 96% | Training loss: 0.6869034613549024
Epoch: 93 | Iteration number: [4360/4518] 96% | Training loss: 0.6869044310456022
Epoch: 93 | Iteration number: [4370/4518] 96% | Training loss: 0.6869023928107604
Epoch: 93 | Iteration number: [4380/4518] 96% | Training loss: 0.6869028981145658
Epoch: 93 | Iteration number: [4390/4518] 97% | Training loss: 0.6869024234915105
Epoch: 93 | Iteration number: [4400/4518] 97% | Training loss: 0.6869044829363172
Epoch: 93 | Iteration number: [4410/4518] 97% | Training loss: 0.6869036982118948
Epoch: 93 | Iteration number: [4420/4518] 97% | Training loss: 0.6869024713924028
Epoch: 93 | Iteration number: [4430/4518] 98% | Training loss: 0.6869033764232093
Epoch: 93 | Iteration number: [4440/4518] 98% | Training loss: 0.6869033197696145
Epoch: 93 | Iteration number: [4450/4518] 98% | Training loss: 0.686903475924824
Epoch: 93 | Iteration number: [4460/4518] 98% | Training loss: 0.6869063181593814
Epoch: 93 | Iteration number: [4470/4518] 98% | Training loss: 0.6869060764643437
Epoch: 93 | Iteration number: [4480/4518] 99% | Training loss: 0.6869073472784034
Epoch: 93 | Iteration number: [4490/4518] 99% | Training loss: 0.6869082364712101
Epoch: 93 | Iteration number: [4500/4518] 99% | Training loss: 0.6869105635616515
Epoch: 93 | Iteration number: [4510/4518] 99% | Training loss: 0.6869120849077559

 End of epoch: 93 | Train Loss: 0.6867586993680374 | Training Time: 633 

 End of epoch: 93 | Eval Loss: 0.689958741470259 | Evaluating Time: 16 
Epoch: 94 | Iteration number: [10/4518] 0% | Training loss: 0.7570804953575134
Epoch: 94 | Iteration number: [20/4518] 0% | Training loss: 0.7223343014717102
Epoch: 94 | Iteration number: [30/4518] 0% | Training loss: 0.7101776639620463
Epoch: 94 | Iteration number: [40/4518] 0% | Training loss: 0.7043227076530456
Epoch: 94 | Iteration number: [50/4518] 1% | Training loss: 0.7006598424911499
Epoch: 94 | Iteration number: [60/4518] 1% | Training loss: 0.698566256960233
Epoch: 94 | Iteration number: [70/4518] 1% | Training loss: 0.6969338400023324
Epoch: 94 | Iteration number: [80/4518] 1% | Training loss: 0.6956332869827747
Epoch: 94 | Iteration number: [90/4518] 1% | Training loss: 0.6946998609436883
Epoch: 94 | Iteration number: [100/4518] 2% | Training loss: 0.6939999341964722
Epoch: 94 | Iteration number: [110/4518] 2% | Training loss: 0.6933455087921836
Epoch: 94 | Iteration number: [120/4518] 2% | Training loss: 0.6927461365858714
Epoch: 94 | Iteration number: [130/4518] 2% | Training loss: 0.692293688425651
Epoch: 94 | Iteration number: [140/4518] 3% | Training loss: 0.6919192135334015
Epoch: 94 | Iteration number: [150/4518] 3% | Training loss: 0.6915674364566803
Epoch: 94 | Iteration number: [160/4518] 3% | Training loss: 0.6912808265537024
Epoch: 94 | Iteration number: [170/4518] 3% | Training loss: 0.6910754442214966
Epoch: 94 | Iteration number: [180/4518] 3% | Training loss: 0.6908706274297503
Epoch: 94 | Iteration number: [190/4518] 4% | Training loss: 0.6906880093248267
Epoch: 94 | Iteration number: [200/4518] 4% | Training loss: 0.6904569545388222
Epoch: 94 | Iteration number: [210/4518] 4% | Training loss: 0.6902610523360116
Epoch: 94 | Iteration number: [220/4518] 4% | Training loss: 0.6900648122484033
Epoch: 94 | Iteration number: [230/4518] 5% | Training loss: 0.689951769683672
Epoch: 94 | Iteration number: [240/4518] 5% | Training loss: 0.6898209236562252
Epoch: 94 | Iteration number: [250/4518] 5% | Training loss: 0.6896421709060669
Epoch: 94 | Iteration number: [260/4518] 5% | Training loss: 0.6894907492857713
Epoch: 94 | Iteration number: [270/4518] 5% | Training loss: 0.6893727547592587
Epoch: 94 | Iteration number: [280/4518] 6% | Training loss: 0.6892401978373528
Epoch: 94 | Iteration number: [290/4518] 6% | Training loss: 0.6891546644013503
Epoch: 94 | Iteration number: [300/4518] 6% | Training loss: 0.6890819986661275
Epoch: 94 | Iteration number: [310/4518] 6% | Training loss: 0.6890122705890286
Epoch: 94 | Iteration number: [320/4518] 7% | Training loss: 0.6889485351741313
Epoch: 94 | Iteration number: [330/4518] 7% | Training loss: 0.6888588945070903
Epoch: 94 | Iteration number: [340/4518] 7% | Training loss: 0.6888109724311268
Epoch: 94 | Iteration number: [350/4518] 7% | Training loss: 0.6887344934259142
Epoch: 94 | Iteration number: [360/4518] 7% | Training loss: 0.6886171970102523
Epoch: 94 | Iteration number: [370/4518] 8% | Training loss: 0.6885759901356052
Epoch: 94 | Iteration number: [380/4518] 8% | Training loss: 0.6884902950964475
Epoch: 94 | Iteration number: [390/4518] 8% | Training loss: 0.6884748438994089
Epoch: 94 | Iteration number: [400/4518] 8% | Training loss: 0.6884614951908589
Epoch: 94 | Iteration number: [410/4518] 9% | Training loss: 0.6884517967700958
Epoch: 94 | Iteration number: [420/4518] 9% | Training loss: 0.6884237581775302
Epoch: 94 | Iteration number: [430/4518] 9% | Training loss: 0.6883907027022783
Epoch: 94 | Iteration number: [440/4518] 9% | Training loss: 0.6883427861061964
Epoch: 94 | Iteration number: [450/4518] 9% | Training loss: 0.6883027113808526
Epoch: 94 | Iteration number: [460/4518] 10% | Training loss: 0.6882429415765016
Epoch: 94 | Iteration number: [470/4518] 10% | Training loss: 0.6882087938329007
Epoch: 94 | Iteration number: [480/4518] 10% | Training loss: 0.6881746393938859
Epoch: 94 | Iteration number: [490/4518] 10% | Training loss: 0.6881237875442116
Epoch: 94 | Iteration number: [500/4518] 11% | Training loss: 0.6880887099504471
Epoch: 94 | Iteration number: [510/4518] 11% | Training loss: 0.6880724276982102
Epoch: 94 | Iteration number: [520/4518] 11% | Training loss: 0.688043925853876
Epoch: 94 | Iteration number: [530/4518] 11% | Training loss: 0.6880399798447231
Epoch: 94 | Iteration number: [540/4518] 11% | Training loss: 0.6880385354713158
Epoch: 94 | Iteration number: [550/4518] 12% | Training loss: 0.6880361472476613
Epoch: 94 | Iteration number: [560/4518] 12% | Training loss: 0.688006949105433
Epoch: 94 | Iteration number: [570/4518] 12% | Training loss: 0.6879675848442212
Epoch: 94 | Iteration number: [580/4518] 12% | Training loss: 0.6879477470085539
Epoch: 94 | Iteration number: [590/4518] 13% | Training loss: 0.687921204304291
Epoch: 94 | Iteration number: [600/4518] 13% | Training loss: 0.687897045314312
Epoch: 94 | Iteration number: [610/4518] 13% | Training loss: 0.687884982492103
Epoch: 94 | Iteration number: [620/4518] 13% | Training loss: 0.6878450833020672
Epoch: 94 | Iteration number: [630/4518] 13% | Training loss: 0.6878225049329183
Epoch: 94 | Iteration number: [640/4518] 14% | Training loss: 0.6878228631801904
Epoch: 94 | Iteration number: [650/4518] 14% | Training loss: 0.6877988804303683
Epoch: 94 | Iteration number: [660/4518] 14% | Training loss: 0.6877821817542568
Epoch: 94 | Iteration number: [670/4518] 14% | Training loss: 0.6877679792802726
Epoch: 94 | Iteration number: [680/4518] 15% | Training loss: 0.6877504782641635
Epoch: 94 | Iteration number: [690/4518] 15% | Training loss: 0.687728866805201
Epoch: 94 | Iteration number: [700/4518] 15% | Training loss: 0.6877232376166752
Epoch: 94 | Iteration number: [710/4518] 15% | Training loss: 0.6877065502421956
Epoch: 94 | Iteration number: [720/4518] 15% | Training loss: 0.6876884644230207
Epoch: 94 | Iteration number: [730/4518] 16% | Training loss: 0.6876588487461822
Epoch: 94 | Iteration number: [740/4518] 16% | Training loss: 0.6876482177425075
Epoch: 94 | Iteration number: [750/4518] 16% | Training loss: 0.6876380841732025
Epoch: 94 | Iteration number: [760/4518] 16% | Training loss: 0.6876184952102209
Epoch: 94 | Iteration number: [770/4518] 17% | Training loss: 0.6876037667324016
Epoch: 94 | Iteration number: [780/4518] 17% | Training loss: 0.687591914488719
Epoch: 94 | Iteration number: [790/4518] 17% | Training loss: 0.6875773340840883
Epoch: 94 | Iteration number: [800/4518] 17% | Training loss: 0.6875706992298365
Epoch: 94 | Iteration number: [810/4518] 17% | Training loss: 0.6875408086511824
Epoch: 94 | Iteration number: [820/4518] 18% | Training loss: 0.6875438940234301
Epoch: 94 | Iteration number: [830/4518] 18% | Training loss: 0.6875372384686068
Epoch: 94 | Iteration number: [840/4518] 18% | Training loss: 0.6875394587715467
Epoch: 94 | Iteration number: [850/4518] 18% | Training loss: 0.6875371437213
Epoch: 94 | Iteration number: [860/4518] 19% | Training loss: 0.6875388568223909
Epoch: 94 | Iteration number: [870/4518] 19% | Training loss: 0.6875174068171402
Epoch: 94 | Iteration number: [880/4518] 19% | Training loss: 0.6874991884285754
Epoch: 94 | Iteration number: [890/4518] 19% | Training loss: 0.6874726756904902
Epoch: 94 | Iteration number: [900/4518] 19% | Training loss: 0.6874567388825946
Epoch: 94 | Iteration number: [910/4518] 20% | Training loss: 0.6874449414211316
Epoch: 94 | Iteration number: [920/4518] 20% | Training loss: 0.6874427766255711
Epoch: 94 | Iteration number: [930/4518] 20% | Training loss: 0.6874305323887897
Epoch: 94 | Iteration number: [940/4518] 20% | Training loss: 0.6874049213972497
Epoch: 94 | Iteration number: [950/4518] 21% | Training loss: 0.6874104460289604
Epoch: 94 | Iteration number: [960/4518] 21% | Training loss: 0.6874047843118508
Epoch: 94 | Iteration number: [970/4518] 21% | Training loss: 0.6873893340223843
Epoch: 94 | Iteration number: [980/4518] 21% | Training loss: 0.6873830943691487
Epoch: 94 | Iteration number: [990/4518] 21% | Training loss: 0.6873746418591702
Epoch: 94 | Iteration number: [1000/4518] 22% | Training loss: 0.6873629192113876
Epoch: 94 | Iteration number: [1010/4518] 22% | Training loss: 0.6873518135878119
Epoch: 94 | Iteration number: [1020/4518] 22% | Training loss: 0.6873398796016095
Epoch: 94 | Iteration number: [1030/4518] 22% | Training loss: 0.6873416812095827
Epoch: 94 | Iteration number: [1040/4518] 23% | Training loss: 0.6873335074346799
Epoch: 94 | Iteration number: [1050/4518] 23% | Training loss: 0.6873231374649774
Epoch: 94 | Iteration number: [1060/4518] 23% | Training loss: 0.6873156607151032
Epoch: 94 | Iteration number: [1070/4518] 23% | Training loss: 0.6873152789668502
Epoch: 94 | Iteration number: [1080/4518] 23% | Training loss: 0.6873081084754732
Epoch: 94 | Iteration number: [1090/4518] 24% | Training loss: 0.6873002125035732
Epoch: 94 | Iteration number: [1100/4518] 24% | Training loss: 0.6873002934455872
Epoch: 94 | Iteration number: [1110/4518] 24% | Training loss: 0.6872948945105612
Epoch: 94 | Iteration number: [1120/4518] 24% | Training loss: 0.6873050900974444
Epoch: 94 | Iteration number: [1130/4518] 25% | Training loss: 0.6873093119237276
Epoch: 94 | Iteration number: [1140/4518] 25% | Training loss: 0.6872984191827607
Epoch: 94 | Iteration number: [1150/4518] 25% | Training loss: 0.6873036758796028
Epoch: 94 | Iteration number: [1160/4518] 25% | Training loss: 0.687306786045946
Epoch: 94 | Iteration number: [1170/4518] 25% | Training loss: 0.6872992368844839
Epoch: 94 | Iteration number: [1180/4518] 26% | Training loss: 0.6873006737838357
Epoch: 94 | Iteration number: [1190/4518] 26% | Training loss: 0.6873039777539357
Epoch: 94 | Iteration number: [1200/4518] 26% | Training loss: 0.6873022501667341
Epoch: 94 | Iteration number: [1210/4518] 26% | Training loss: 0.6872926168697925
Epoch: 94 | Iteration number: [1220/4518] 27% | Training loss: 0.6872840480237711
Epoch: 94 | Iteration number: [1230/4518] 27% | Training loss: 0.6872799292812503
Epoch: 94 | Iteration number: [1240/4518] 27% | Training loss: 0.6872683753890376
Epoch: 94 | Iteration number: [1250/4518] 27% | Training loss: 0.6872699442386627
Epoch: 94 | Iteration number: [1260/4518] 27% | Training loss: 0.6872622339971481
Epoch: 94 | Iteration number: [1270/4518] 28% | Training loss: 0.6872624004919697
Epoch: 94 | Iteration number: [1280/4518] 28% | Training loss: 0.6872584609314799
Epoch: 94 | Iteration number: [1290/4518] 28% | Training loss: 0.6872664214104645
Epoch: 94 | Iteration number: [1300/4518] 28% | Training loss: 0.6872633903301679
Epoch: 94 | Iteration number: [1310/4518] 28% | Training loss: 0.6872647909717705
Epoch: 94 | Iteration number: [1320/4518] 29% | Training loss: 0.6872587863242987
Epoch: 94 | Iteration number: [1330/4518] 29% | Training loss: 0.6872443807304354
Epoch: 94 | Iteration number: [1340/4518] 29% | Training loss: 0.687237558525
Epoch: 94 | Iteration number: [1350/4518] 29% | Training loss: 0.6872253228116918
Epoch: 94 | Iteration number: [1360/4518] 30% | Training loss: 0.6872239669894471
Epoch: 94 | Iteration number: [1370/4518] 30% | Training loss: 0.687227278686788
Epoch: 94 | Iteration number: [1380/4518] 30% | Training loss: 0.6872259282115577
Epoch: 94 | Iteration number: [1390/4518] 30% | Training loss: 0.6872310052243926
Epoch: 94 | Iteration number: [1400/4518] 30% | Training loss: 0.6872310893024717
Epoch: 94 | Iteration number: [1410/4518] 31% | Training loss: 0.6872331239230244
Epoch: 94 | Iteration number: [1420/4518] 31% | Training loss: 0.687222421589032
Epoch: 94 | Iteration number: [1430/4518] 31% | Training loss: 0.687209877767763
Epoch: 94 | Iteration number: [1440/4518] 31% | Training loss: 0.6872172060526079
Epoch: 94 | Iteration number: [1450/4518] 32% | Training loss: 0.6872079461196373
Epoch: 94 | Iteration number: [1460/4518] 32% | Training loss: 0.6872167462763721
Epoch: 94 | Iteration number: [1470/4518] 32% | Training loss: 0.6872148420534977
Epoch: 94 | Iteration number: [1480/4518] 32% | Training loss: 0.6872157590212049
Epoch: 94 | Iteration number: [1490/4518] 32% | Training loss: 0.6872191391935285
Epoch: 94 | Iteration number: [1500/4518] 33% | Training loss: 0.6872278616031011
Epoch: 94 | Iteration number: [1510/4518] 33% | Training loss: 0.6872252856658784
Epoch: 94 | Iteration number: [1520/4518] 33% | Training loss: 0.6872185572981835
Epoch: 94 | Iteration number: [1530/4518] 33% | Training loss: 0.6872184365403419
Epoch: 94 | Iteration number: [1540/4518] 34% | Training loss: 0.6872174539736339
Epoch: 94 | Iteration number: [1550/4518] 34% | Training loss: 0.6872121101810086
Epoch: 94 | Iteration number: [1560/4518] 34% | Training loss: 0.6872059233295612
Epoch: 94 | Iteration number: [1570/4518] 34% | Training loss: 0.6872000744388361
Epoch: 94 | Iteration number: [1580/4518] 34% | Training loss: 0.6872035700309126
Epoch: 94 | Iteration number: [1590/4518] 35% | Training loss: 0.6871989087113795
Epoch: 94 | Iteration number: [1600/4518] 35% | Training loss: 0.6871940898522735
Epoch: 94 | Iteration number: [1610/4518] 35% | Training loss: 0.6871981613754485
Epoch: 94 | Iteration number: [1620/4518] 35% | Training loss: 0.6872006114250347
Epoch: 94 | Iteration number: [1630/4518] 36% | Training loss: 0.6871966776672317
Epoch: 94 | Iteration number: [1640/4518] 36% | Training loss: 0.6871939942967601
Epoch: 94 | Iteration number: [1650/4518] 36% | Training loss: 0.6871947988958069
Epoch: 94 | Iteration number: [1660/4518] 36% | Training loss: 0.6871937685343157
Epoch: 94 | Iteration number: [1670/4518] 36% | Training loss: 0.6871952794626087
Epoch: 94 | Iteration number: [1680/4518] 37% | Training loss: 0.6871955994339216
Epoch: 94 | Iteration number: [1690/4518] 37% | Training loss: 0.6871921913158259
Epoch: 94 | Iteration number: [1700/4518] 37% | Training loss: 0.687196940218701
Epoch: 94 | Iteration number: [1710/4518] 37% | Training loss: 0.6871960834104415
Epoch: 94 | Iteration number: [1720/4518] 38% | Training loss: 0.6871944700216138
Epoch: 94 | Iteration number: [1730/4518] 38% | Training loss: 0.6871926048932048
Epoch: 94 | Iteration number: [1740/4518] 38% | Training loss: 0.687181270054017
Epoch: 94 | Iteration number: [1750/4518] 38% | Training loss: 0.68717755147389
Epoch: 94 | Iteration number: [1760/4518] 38% | Training loss: 0.6871719372204759
Epoch: 94 | Iteration number: [1770/4518] 39% | Training loss: 0.6871728516904648
Epoch: 94 | Iteration number: [1780/4518] 39% | Training loss: 0.6871696419260475
Epoch: 94 | Iteration number: [1790/4518] 39% | Training loss: 0.6871653906459915
Epoch: 94 | Iteration number: [1800/4518] 39% | Training loss: 0.6871543825997246
Epoch: 94 | Iteration number: [1810/4518] 40% | Training loss: 0.6871529125047652
Epoch: 94 | Iteration number: [1820/4518] 40% | Training loss: 0.6871504293693291
Epoch: 94 | Iteration number: [1830/4518] 40% | Training loss: 0.6871450145713619
Epoch: 94 | Iteration number: [1840/4518] 40% | Training loss: 0.6871412822733755
Epoch: 94 | Iteration number: [1850/4518] 40% | Training loss: 0.6871313162429913
Epoch: 94 | Iteration number: [1860/4518] 41% | Training loss: 0.6871293472346439
Epoch: 94 | Iteration number: [1870/4518] 41% | Training loss: 0.6871254693696843
Epoch: 94 | Iteration number: [1880/4518] 41% | Training loss: 0.6871216696627597
Epoch: 94 | Iteration number: [1890/4518] 41% | Training loss: 0.687120732554683
Epoch: 94 | Iteration number: [1900/4518] 42% | Training loss: 0.687124622683776
Epoch: 94 | Iteration number: [1910/4518] 42% | Training loss: 0.6871197625292533
Epoch: 94 | Iteration number: [1920/4518] 42% | Training loss: 0.687115403264761
Epoch: 94 | Iteration number: [1930/4518] 42% | Training loss: 0.6871183822809723
Epoch: 94 | Iteration number: [1940/4518] 42% | Training loss: 0.6871166394543402
Epoch: 94 | Iteration number: [1950/4518] 43% | Training loss: 0.6871197186372219
Epoch: 94 | Iteration number: [1960/4518] 43% | Training loss: 0.6871188221233232
Epoch: 94 | Iteration number: [1970/4518] 43% | Training loss: 0.6871129601437428
Epoch: 94 | Iteration number: [1980/4518] 43% | Training loss: 0.6871135878743547
Epoch: 94 | Iteration number: [1990/4518] 44% | Training loss: 0.6871109258888954
Epoch: 94 | Iteration number: [2000/4518] 44% | Training loss: 0.6871072607636451
Epoch: 94 | Iteration number: [2010/4518] 44% | Training loss: 0.6871042512542572
Epoch: 94 | Iteration number: [2020/4518] 44% | Training loss: 0.6871076975128438
Epoch: 94 | Iteration number: [2030/4518] 44% | Training loss: 0.6871033042228868
Epoch: 94 | Iteration number: [2040/4518] 45% | Training loss: 0.6871050323049227
Epoch: 94 | Iteration number: [2050/4518] 45% | Training loss: 0.6871019256987223
Epoch: 94 | Iteration number: [2060/4518] 45% | Training loss: 0.6871040001945589
Epoch: 94 | Iteration number: [2070/4518] 45% | Training loss: 0.687101736218457
Epoch: 94 | Iteration number: [2080/4518] 46% | Training loss: 0.6870977213749518
Epoch: 94 | Iteration number: [2090/4518] 46% | Training loss: 0.6870971756403526
Epoch: 94 | Iteration number: [2100/4518] 46% | Training loss: 0.6870953182947068
Epoch: 94 | Iteration number: [2110/4518] 46% | Training loss: 0.6870902892537591
Epoch: 94 | Iteration number: [2120/4518] 46% | Training loss: 0.6870907684823252
Epoch: 94 | Iteration number: [2130/4518] 47% | Training loss: 0.6870908464624288
Epoch: 94 | Iteration number: [2140/4518] 47% | Training loss: 0.6870802527833207
Epoch: 94 | Iteration number: [2150/4518] 47% | Training loss: 0.6870801010519959
Epoch: 94 | Iteration number: [2160/4518] 47% | Training loss: 0.687075123384043
Epoch: 94 | Iteration number: [2170/4518] 48% | Training loss: 0.687074292365307
Epoch: 94 | Iteration number: [2180/4518] 48% | Training loss: 0.6870751699176403
Epoch: 94 | Iteration number: [2190/4518] 48% | Training loss: 0.6870699958169841
Epoch: 94 | Iteration number: [2200/4518] 48% | Training loss: 0.6870745361393148
Epoch: 94 | Iteration number: [2210/4518] 48% | Training loss: 0.6870710181434769
Epoch: 94 | Iteration number: [2220/4518] 49% | Training loss: 0.687066080468195
Epoch: 94 | Iteration number: [2230/4518] 49% | Training loss: 0.6870664134688441
Epoch: 94 | Iteration number: [2240/4518] 49% | Training loss: 0.6870631839281747
Epoch: 94 | Iteration number: [2250/4518] 49% | Training loss: 0.6870639866193136
Epoch: 94 | Iteration number: [2260/4518] 50% | Training loss: 0.6870624017662706
Epoch: 94 | Iteration number: [2270/4518] 50% | Training loss: 0.6870589471073403
Epoch: 94 | Iteration number: [2280/4518] 50% | Training loss: 0.6870526750882466
Epoch: 94 | Iteration number: [2290/4518] 50% | Training loss: 0.6870538493431291
Epoch: 94 | Iteration number: [2300/4518] 50% | Training loss: 0.6870557229674381
Epoch: 94 | Iteration number: [2310/4518] 51% | Training loss: 0.687061417257631
Epoch: 94 | Iteration number: [2320/4518] 51% | Training loss: 0.6870647382633439
Epoch: 94 | Iteration number: [2330/4518] 51% | Training loss: 0.6870684488136881
Epoch: 94 | Iteration number: [2340/4518] 51% | Training loss: 0.6870640554489233
Epoch: 94 | Iteration number: [2350/4518] 52% | Training loss: 0.6870667433738709
Epoch: 94 | Iteration number: [2360/4518] 52% | Training loss: 0.6870687807768078
Epoch: 94 | Iteration number: [2370/4518] 52% | Training loss: 0.6870649772354319
Epoch: 94 | Iteration number: [2380/4518] 52% | Training loss: 0.687066474531879
Epoch: 94 | Iteration number: [2390/4518] 52% | Training loss: 0.6870643179286973
Epoch: 94 | Iteration number: [2400/4518] 53% | Training loss: 0.6870629482716322
Epoch: 94 | Iteration number: [2410/4518] 53% | Training loss: 0.6870674422915051
Epoch: 94 | Iteration number: [2420/4518] 53% | Training loss: 0.6870671023760946
Epoch: 94 | Iteration number: [2430/4518] 53% | Training loss: 0.6870630224055223
Epoch: 94 | Iteration number: [2440/4518] 54% | Training loss: 0.6870636001717849
Epoch: 94 | Iteration number: [2450/4518] 54% | Training loss: 0.6870660427881747
Epoch: 94 | Iteration number: [2460/4518] 54% | Training loss: 0.6870644450429978
Epoch: 94 | Iteration number: [2470/4518] 54% | Training loss: 0.6870688816072487
Epoch: 94 | Iteration number: [2480/4518] 54% | Training loss: 0.6870748516532683
Epoch: 94 | Iteration number: [2490/4518] 55% | Training loss: 0.6870720253172649
Epoch: 94 | Iteration number: [2500/4518] 55% | Training loss: 0.6870679466724395
Epoch: 94 | Iteration number: [2510/4518] 55% | Training loss: 0.6870703563034772
Epoch: 94 | Iteration number: [2520/4518] 55% | Training loss: 0.6870688422095208
Epoch: 94 | Iteration number: [2530/4518] 55% | Training loss: 0.6870699601682279
Epoch: 94 | Iteration number: [2540/4518] 56% | Training loss: 0.68707174888746
Epoch: 94 | Iteration number: [2550/4518] 56% | Training loss: 0.6870724604877771
Epoch: 94 | Iteration number: [2560/4518] 56% | Training loss: 0.6870693205622956
Epoch: 94 | Iteration number: [2570/4518] 56% | Training loss: 0.6870730172335405
Epoch: 94 | Iteration number: [2580/4518] 57% | Training loss: 0.687073941401733
Epoch: 94 | Iteration number: [2590/4518] 57% | Training loss: 0.6870747397995364
Epoch: 94 | Iteration number: [2600/4518] 57% | Training loss: 0.6870722183585167
Epoch: 94 | Iteration number: [2610/4518] 57% | Training loss: 0.6870744630066371
Epoch: 94 | Iteration number: [2620/4518] 57% | Training loss: 0.6870757293155175
Epoch: 94 | Iteration number: [2630/4518] 58% | Training loss: 0.6870754959012165
Epoch: 94 | Iteration number: [2640/4518] 58% | Training loss: 0.6870793332430449
Epoch: 94 | Iteration number: [2650/4518] 58% | Training loss: 0.6870775915991585
Epoch: 94 | Iteration number: [2660/4518] 58% | Training loss: 0.6870797507744982
Epoch: 94 | Iteration number: [2670/4518] 59% | Training loss: 0.6870779988024566
Epoch: 94 | Iteration number: [2680/4518] 59% | Training loss: 0.6870738720938341
Epoch: 94 | Iteration number: [2690/4518] 59% | Training loss: 0.6870773486709949
Epoch: 94 | Iteration number: [2700/4518] 59% | Training loss: 0.687078915172153
Epoch: 94 | Iteration number: [2710/4518] 59% | Training loss: 0.6870808444119907
Epoch: 94 | Iteration number: [2720/4518] 60% | Training loss: 0.6870826525065828
Epoch: 94 | Iteration number: [2730/4518] 60% | Training loss: 0.6870817441425044
Epoch: 94 | Iteration number: [2740/4518] 60% | Training loss: 0.687074195729555
Epoch: 94 | Iteration number: [2750/4518] 60% | Training loss: 0.6870713308941234
Epoch: 94 | Iteration number: [2760/4518] 61% | Training loss: 0.6870714910436367
Epoch: 94 | Iteration number: [2770/4518] 61% | Training loss: 0.6870670839337235
Epoch: 94 | Iteration number: [2780/4518] 61% | Training loss: 0.6870657312784264
Epoch: 94 | Iteration number: [2790/4518] 61% | Training loss: 0.6870640586567609
Epoch: 94 | Iteration number: [2800/4518] 61% | Training loss: 0.6870704074203968
Epoch: 94 | Iteration number: [2810/4518] 62% | Training loss: 0.6870683242629856
Epoch: 94 | Iteration number: [2820/4518] 62% | Training loss: 0.6870681025246357
Epoch: 94 | Iteration number: [2830/4518] 62% | Training loss: 0.6870684128978648
Epoch: 94 | Iteration number: [2840/4518] 62% | Training loss: 0.6870690962168532
Epoch: 94 | Iteration number: [2850/4518] 63% | Training loss: 0.6870730405523066
Epoch: 94 | Iteration number: [2860/4518] 63% | Training loss: 0.6870712093748412
Epoch: 94 | Iteration number: [2870/4518] 63% | Training loss: 0.6870660287370249
Epoch: 94 | Iteration number: [2880/4518] 63% | Training loss: 0.687058036112123
Epoch: 94 | Iteration number: [2890/4518] 63% | Training loss: 0.6870551174487209
Epoch: 94 | Iteration number: [2900/4518] 64% | Training loss: 0.6870544692154589
Epoch: 94 | Iteration number: [2910/4518] 64% | Training loss: 0.687051478222883
Epoch: 94 | Iteration number: [2920/4518] 64% | Training loss: 0.6870530367101708
Epoch: 94 | Iteration number: [2930/4518] 64% | Training loss: 0.6870517816763282
Epoch: 94 | Iteration number: [2940/4518] 65% | Training loss: 0.6870491683483124
Epoch: 94 | Iteration number: [2950/4518] 65% | Training loss: 0.68704568317381
Epoch: 94 | Iteration number: [2960/4518] 65% | Training loss: 0.6870437701408928
Epoch: 94 | Iteration number: [2970/4518] 65% | Training loss: 0.68704530323796
Epoch: 94 | Iteration number: [2980/4518] 65% | Training loss: 0.6870446242142043
Epoch: 94 | Iteration number: [2990/4518] 66% | Training loss: 0.6870439607562827
Epoch: 94 | Iteration number: [3000/4518] 66% | Training loss: 0.6870504690210024
Epoch: 94 | Iteration number: [3010/4518] 66% | Training loss: 0.6870491421895962
Epoch: 94 | Iteration number: [3020/4518] 66% | Training loss: 0.6870461962278316
Epoch: 94 | Iteration number: [3030/4518] 67% | Training loss: 0.6870445813873026
Epoch: 94 | Iteration number: [3040/4518] 67% | Training loss: 0.6870464469845358
Epoch: 94 | Iteration number: [3050/4518] 67% | Training loss: 0.6870492964494423
Epoch: 94 | Iteration number: [3060/4518] 67% | Training loss: 0.6870459008450601
Epoch: 94 | Iteration number: [3070/4518] 67% | Training loss: 0.6870456390155643
Epoch: 94 | Iteration number: [3080/4518] 68% | Training loss: 0.6870433808147133
Epoch: 94 | Iteration number: [3090/4518] 68% | Training loss: 0.6870418840627455
Epoch: 94 | Iteration number: [3100/4518] 68% | Training loss: 0.6870390148701206
Epoch: 94 | Iteration number: [3110/4518] 68% | Training loss: 0.6870368438518316
Epoch: 94 | Iteration number: [3120/4518] 69% | Training loss: 0.6870414757575745
Epoch: 94 | Iteration number: [3130/4518] 69% | Training loss: 0.687038182926635
Epoch: 94 | Iteration number: [3140/4518] 69% | Training loss: 0.6870381759610146
Epoch: 94 | Iteration number: [3150/4518] 69% | Training loss: 0.6870358777992309
Epoch: 94 | Iteration number: [3160/4518] 69% | Training loss: 0.6870332923493808
Epoch: 94 | Iteration number: [3170/4518] 70% | Training loss: 0.6870301851338768
Epoch: 94 | Iteration number: [3180/4518] 70% | Training loss: 0.6870314975767016
Epoch: 94 | Iteration number: [3190/4518] 70% | Training loss: 0.6870331840081648
Epoch: 94 | Iteration number: [3200/4518] 70% | Training loss: 0.6870328377373517
Epoch: 94 | Iteration number: [3210/4518] 71% | Training loss: 0.6870269393252435
Epoch: 94 | Iteration number: [3220/4518] 71% | Training loss: 0.6870233686259074
Epoch: 94 | Iteration number: [3230/4518] 71% | Training loss: 0.6870247770573702
Epoch: 94 | Iteration number: [3240/4518] 71% | Training loss: 0.6870239038158346
Epoch: 94 | Iteration number: [3250/4518] 71% | Training loss: 0.6870178546355321
Epoch: 94 | Iteration number: [3260/4518] 72% | Training loss: 0.6870188533162778
Epoch: 94 | Iteration number: [3270/4518] 72% | Training loss: 0.6870196237294317
Epoch: 94 | Iteration number: [3280/4518] 72% | Training loss: 0.6870135178471484
Epoch: 94 | Iteration number: [3290/4518] 72% | Training loss: 0.6870116237630235
Epoch: 94 | Iteration number: [3300/4518] 73% | Training loss: 0.6870096549482057
Epoch: 94 | Iteration number: [3310/4518] 73% | Training loss: 0.6870068003043668
Epoch: 94 | Iteration number: [3320/4518] 73% | Training loss: 0.6870063203106443
Epoch: 94 | Iteration number: [3330/4518] 73% | Training loss: 0.6870045029365265
Epoch: 94 | Iteration number: [3340/4518] 73% | Training loss: 0.6870015189319314
Epoch: 94 | Iteration number: [3350/4518] 74% | Training loss: 0.6870009643106318
Epoch: 94 | Iteration number: [3360/4518] 74% | Training loss: 0.6870020921386424
Epoch: 94 | Iteration number: [3370/4518] 74% | Training loss: 0.6870020901060245
Epoch: 94 | Iteration number: [3380/4518] 74% | Training loss: 0.6869970634491486
Epoch: 94 | Iteration number: [3390/4518] 75% | Training loss: 0.6869956529421792
Epoch: 94 | Iteration number: [3400/4518] 75% | Training loss: 0.6869940106658374
Epoch: 94 | Iteration number: [3410/4518] 75% | Training loss: 0.6869930762349685
Epoch: 94 | Iteration number: [3420/4518] 75% | Training loss: 0.6869933752114312
Epoch: 94 | Iteration number: [3430/4518] 75% | Training loss: 0.686993858122617
Epoch: 94 | Iteration number: [3440/4518] 76% | Training loss: 0.6869919700851274
Epoch: 94 | Iteration number: [3450/4518] 76% | Training loss: 0.686990011083907
Epoch: 94 | Iteration number: [3460/4518] 76% | Training loss: 0.6869894212036464
Epoch: 94 | Iteration number: [3470/4518] 76% | Training loss: 0.6869903777621321
Epoch: 94 | Iteration number: [3480/4518] 77% | Training loss: 0.6869903276364009
Epoch: 94 | Iteration number: [3490/4518] 77% | Training loss: 0.6869864141531182
Epoch: 94 | Iteration number: [3500/4518] 77% | Training loss: 0.6869816289458957
Epoch: 94 | Iteration number: [3510/4518] 77% | Training loss: 0.6869827848723811
Epoch: 94 | Iteration number: [3520/4518] 77% | Training loss: 0.6869792479683052
Epoch: 94 | Iteration number: [3530/4518] 78% | Training loss: 0.6869739475398834
Epoch: 94 | Iteration number: [3540/4518] 78% | Training loss: 0.6869748181710809
Epoch: 94 | Iteration number: [3550/4518] 78% | Training loss: 0.6869754678766492
Epoch: 94 | Iteration number: [3560/4518] 78% | Training loss: 0.6869758887739664
Epoch: 94 | Iteration number: [3570/4518] 79% | Training loss: 0.6869768975495625
Epoch: 94 | Iteration number: [3580/4518] 79% | Training loss: 0.6869762698032337
Epoch: 94 | Iteration number: [3590/4518] 79% | Training loss: 0.6869732342722689
Epoch: 94 | Iteration number: [3600/4518] 79% | Training loss: 0.6869717715183894
Epoch: 94 | Iteration number: [3610/4518] 79% | Training loss: 0.6869707137428822
Epoch: 94 | Iteration number: [3620/4518] 80% | Training loss: 0.6869707506335243
Epoch: 94 | Iteration number: [3630/4518] 80% | Training loss: 0.6869717332614026
Epoch: 94 | Iteration number: [3640/4518] 80% | Training loss: 0.6869721169818889
Epoch: 94 | Iteration number: [3650/4518] 80% | Training loss: 0.6869676006983404
Epoch: 94 | Iteration number: [3660/4518] 81% | Training loss: 0.6869684577639638
Epoch: 94 | Iteration number: [3670/4518] 81% | Training loss: 0.6869651499496169
Epoch: 94 | Iteration number: [3680/4518] 81% | Training loss: 0.6869650198713593
Epoch: 94 | Iteration number: [3690/4518] 81% | Training loss: 0.6869652279024202
Epoch: 94 | Iteration number: [3700/4518] 81% | Training loss: 0.6869641187706509
Epoch: 94 | Iteration number: [3710/4518] 82% | Training loss: 0.6869597640320297
Epoch: 94 | Iteration number: [3720/4518] 82% | Training loss: 0.6869644791208288
Epoch: 94 | Iteration number: [3730/4518] 82% | Training loss: 0.686964224027245
Epoch: 94 | Iteration number: [3740/4518] 82% | Training loss: 0.6869631207244281
Epoch: 94 | Iteration number: [3750/4518] 83% | Training loss: 0.6869604353745778
Epoch: 94 | Iteration number: [3760/4518] 83% | Training loss: 0.6869629534476615
Epoch: 94 | Iteration number: [3770/4518] 83% | Training loss: 0.6869634867821195
Epoch: 94 | Iteration number: [3780/4518] 83% | Training loss: 0.6869601847791167
Epoch: 94 | Iteration number: [3790/4518] 83% | Training loss: 0.6869602715591642
Epoch: 94 | Iteration number: [3800/4518] 84% | Training loss: 0.6869594211641111
Epoch: 94 | Iteration number: [3810/4518] 84% | Training loss: 0.6869585224180397
Epoch: 94 | Iteration number: [3820/4518] 84% | Training loss: 0.6869580920454095
Epoch: 94 | Iteration number: [3830/4518] 84% | Training loss: 0.6869549784274388
Epoch: 94 | Iteration number: [3840/4518] 84% | Training loss: 0.6869530782103539
Epoch: 94 | Iteration number: [3850/4518] 85% | Training loss: 0.6869539294304786
Epoch: 94 | Iteration number: [3860/4518] 85% | Training loss: 0.6869532013340935
Epoch: 94 | Iteration number: [3870/4518] 85% | Training loss: 0.6869535159541039
Epoch: 94 | Iteration number: [3880/4518] 85% | Training loss: 0.686951748765621
Epoch: 94 | Iteration number: [3890/4518] 86% | Training loss: 0.6869496273044449
Epoch: 94 | Iteration number: [3900/4518] 86% | Training loss: 0.6869500209887822
Epoch: 94 | Iteration number: [3910/4518] 86% | Training loss: 0.6869476395342357
Epoch: 94 | Iteration number: [3920/4518] 86% | Training loss: 0.6869482611058926
Epoch: 94 | Iteration number: [3930/4518] 86% | Training loss: 0.6869463514887346
Epoch: 94 | Iteration number: [3940/4518] 87% | Training loss: 0.686943510129367
Epoch: 94 | Iteration number: [3950/4518] 87% | Training loss: 0.6869426860235914
Epoch: 94 | Iteration number: [3960/4518] 87% | Training loss: 0.6869446439875497
Epoch: 94 | Iteration number: [3970/4518] 87% | Training loss: 0.6869443511782726
Epoch: 94 | Iteration number: [3980/4518] 88% | Training loss: 0.686941060034474
Epoch: 94 | Iteration number: [3990/4518] 88% | Training loss: 0.6869414078860654
Epoch: 94 | Iteration number: [4000/4518] 88% | Training loss: 0.6869411776661873
Epoch: 94 | Iteration number: [4010/4518] 88% | Training loss: 0.686937815872511
Epoch: 94 | Iteration number: [4020/4518] 88% | Training loss: 0.6869380940993627
Epoch: 94 | Iteration number: [4030/4518] 89% | Training loss: 0.6869389781733009
Epoch: 94 | Iteration number: [4040/4518] 89% | Training loss: 0.6869400940319099
Epoch: 94 | Iteration number: [4050/4518] 89% | Training loss: 0.6869383101993137
Epoch: 94 | Iteration number: [4060/4518] 89% | Training loss: 0.686939347245423
Epoch: 94 | Iteration number: [4070/4518] 90% | Training loss: 0.6869404029787612
Epoch: 94 | Iteration number: [4080/4518] 90% | Training loss: 0.6869419236539626
Epoch: 94 | Iteration number: [4090/4518] 90% | Training loss: 0.6869436130401266
Epoch: 94 | Iteration number: [4100/4518] 90% | Training loss: 0.6869411771471907
Epoch: 94 | Iteration number: [4110/4518] 90% | Training loss: 0.6869393223103526
Epoch: 94 | Iteration number: [4120/4518] 91% | Training loss: 0.6869377427454134
Epoch: 94 | Iteration number: [4130/4518] 91% | Training loss: 0.6869371284728477
Epoch: 94 | Iteration number: [4140/4518] 91% | Training loss: 0.6869363443431071
Epoch: 94 | Iteration number: [4150/4518] 91% | Training loss: 0.6869390528316958
Epoch: 94 | Iteration number: [4160/4518] 92% | Training loss: 0.6869382686913014
Epoch: 94 | Iteration number: [4170/4518] 92% | Training loss: 0.68693910625627
Epoch: 94 | Iteration number: [4180/4518] 92% | Training loss: 0.6869410315198762
Epoch: 94 | Iteration number: [4190/4518] 92% | Training loss: 0.6869407848839544
Epoch: 94 | Iteration number: [4200/4518] 92% | Training loss: 0.6869370313911211
Epoch: 94 | Iteration number: [4210/4518] 93% | Training loss: 0.6869322079660773
Epoch: 94 | Iteration number: [4220/4518] 93% | Training loss: 0.6869308569984979
Epoch: 94 | Iteration number: [4230/4518] 93% | Training loss: 0.6869283336696895
Epoch: 94 | Iteration number: [4240/4518] 93% | Training loss: 0.6869268049608986
Epoch: 94 | Iteration number: [4250/4518] 94% | Training loss: 0.6869270633949953
Epoch: 94 | Iteration number: [4260/4518] 94% | Training loss: 0.6869282123768273
Epoch: 94 | Iteration number: [4270/4518] 94% | Training loss: 0.6869257345970118
Epoch: 94 | Iteration number: [4280/4518] 94% | Training loss: 0.6869230382631872
Epoch: 94 | Iteration number: [4290/4518] 94% | Training loss: 0.6869232184125549
Epoch: 94 | Iteration number: [4300/4518] 95% | Training loss: 0.6869243868423063
Epoch: 94 | Iteration number: [4310/4518] 95% | Training loss: 0.6869248570256333
Epoch: 94 | Iteration number: [4320/4518] 95% | Training loss: 0.6869254890415404
Epoch: 94 | Iteration number: [4330/4518] 95% | Training loss: 0.686922843558133
Epoch: 94 | Iteration number: [4340/4518] 96% | Training loss: 0.6869218615480283
Epoch: 94 | Iteration number: [4350/4518] 96% | Training loss: 0.6869193884696083
Epoch: 94 | Iteration number: [4360/4518] 96% | Training loss: 0.6869215084598699
Epoch: 94 | Iteration number: [4370/4518] 96% | Training loss: 0.6869204179373158
Epoch: 94 | Iteration number: [4380/4518] 96% | Training loss: 0.6869219175484627
Epoch: 94 | Iteration number: [4390/4518] 97% | Training loss: 0.6869221037911392
Epoch: 94 | Iteration number: [4400/4518] 97% | Training loss: 0.6869211545315655
Epoch: 94 | Iteration number: [4410/4518] 97% | Training loss: 0.6869214774799995
Epoch: 94 | Iteration number: [4420/4518] 97% | Training loss: 0.6869181811944391
Epoch: 94 | Iteration number: [4430/4518] 98% | Training loss: 0.686917005839251
Epoch: 94 | Iteration number: [4440/4518] 98% | Training loss: 0.6869160176531689
Epoch: 94 | Iteration number: [4450/4518] 98% | Training loss: 0.6869163969259584
Epoch: 94 | Iteration number: [4460/4518] 98% | Training loss: 0.6869130467219203
Epoch: 94 | Iteration number: [4470/4518] 98% | Training loss: 0.6869132293417416
Epoch: 94 | Iteration number: [4480/4518] 99% | Training loss: 0.6869135042253349
Epoch: 94 | Iteration number: [4490/4518] 99% | Training loss: 0.6869129119577811
Epoch: 94 | Iteration number: [4500/4518] 99% | Training loss: 0.6869130018817053
Epoch: 94 | Iteration number: [4510/4518] 99% | Training loss: 0.6869148651142079

 End of epoch: 94 | Train Loss: 0.6867605676398757 | Training Time: 632 

 End of epoch: 94 | Eval Loss: 0.6900254901574583 | Evaluating Time: 18 
Epoch: 95 | Iteration number: [10/4518] 0% | Training loss: 0.756002938747406
Epoch: 95 | Iteration number: [20/4518] 0% | Training loss: 0.7219399571418762
Epoch: 95 | Iteration number: [30/4518] 0% | Training loss: 0.7104429264863332
Epoch: 95 | Iteration number: [40/4518] 0% | Training loss: 0.7044575855135917
Epoch: 95 | Iteration number: [50/4518] 1% | Training loss: 0.7008960330486298
Epoch: 95 | Iteration number: [60/4518] 1% | Training loss: 0.6987663894891739
Epoch: 95 | Iteration number: [70/4518] 1% | Training loss: 0.6970347361905235
Epoch: 95 | Iteration number: [80/4518] 1% | Training loss: 0.695767767727375
Epoch: 95 | Iteration number: [90/4518] 1% | Training loss: 0.6948530362712012
Epoch: 95 | Iteration number: [100/4518] 2% | Training loss: 0.6940413165092468
Epoch: 95 | Iteration number: [110/4518] 2% | Training loss: 0.6933808494697917
Epoch: 95 | Iteration number: [120/4518] 2% | Training loss: 0.6928421104947726
Epoch: 95 | Iteration number: [130/4518] 2% | Training loss: 0.6923486888408661
Epoch: 95 | Iteration number: [140/4518] 3% | Training loss: 0.6918973420347486
Epoch: 95 | Iteration number: [150/4518] 3% | Training loss: 0.6914812298615773
Epoch: 95 | Iteration number: [160/4518] 3% | Training loss: 0.6912033516913653
Epoch: 95 | Iteration number: [170/4518] 3% | Training loss: 0.6909070148187525
Epoch: 95 | Iteration number: [180/4518] 3% | Training loss: 0.6906419313616223
Epoch: 95 | Iteration number: [190/4518] 4% | Training loss: 0.6904569233718671
Epoch: 95 | Iteration number: [200/4518] 4% | Training loss: 0.6902640905976295
Epoch: 95 | Iteration number: [210/4518] 4% | Training loss: 0.6900250906036014
Epoch: 95 | Iteration number: [220/4518] 4% | Training loss: 0.6898082893003117
Epoch: 95 | Iteration number: [230/4518] 5% | Training loss: 0.6897293723147848
Epoch: 95 | Iteration number: [240/4518] 5% | Training loss: 0.6896719637016455
Epoch: 95 | Iteration number: [250/4518] 5% | Training loss: 0.6895485942363739
Epoch: 95 | Iteration number: [260/4518] 5% | Training loss: 0.6894355673056383
Epoch: 95 | Iteration number: [270/4518] 5% | Training loss: 0.6893698270674105
Epoch: 95 | Iteration number: [280/4518] 6% | Training loss: 0.6892498069575854
Epoch: 95 | Iteration number: [290/4518] 6% | Training loss: 0.6891750683044565
Epoch: 95 | Iteration number: [300/4518] 6% | Training loss: 0.6890734831492106
Epoch: 95 | Iteration number: [310/4518] 6% | Training loss: 0.6889968152969114
Epoch: 95 | Iteration number: [320/4518] 7% | Training loss: 0.6889315340667963
Epoch: 95 | Iteration number: [330/4518] 7% | Training loss: 0.6888741896008
Epoch: 95 | Iteration number: [340/4518] 7% | Training loss: 0.6887978227699504
Epoch: 95 | Iteration number: [350/4518] 7% | Training loss: 0.6887672897747584
Epoch: 95 | Iteration number: [360/4518] 7% | Training loss: 0.688717798391978
Epoch: 95 | Iteration number: [370/4518] 8% | Training loss: 0.6886352329640775
Epoch: 95 | Iteration number: [380/4518] 8% | Training loss: 0.6885905772447586
Epoch: 95 | Iteration number: [390/4518] 8% | Training loss: 0.6885607760686141
Epoch: 95 | Iteration number: [400/4518] 8% | Training loss: 0.6885404741764068
Epoch: 95 | Iteration number: [410/4518] 9% | Training loss: 0.688501154358794
Epoch: 95 | Iteration number: [420/4518] 9% | Training loss: 0.6884644207500276
Epoch: 95 | Iteration number: [430/4518] 9% | Training loss: 0.6884482333826464
Epoch: 95 | Iteration number: [440/4518] 9% | Training loss: 0.688445634869012
Epoch: 95 | Iteration number: [450/4518] 9% | Training loss: 0.6883955391248068
Epoch: 95 | Iteration number: [460/4518] 10% | Training loss: 0.6883698101924813
Epoch: 95 | Iteration number: [470/4518] 10% | Training loss: 0.68830403114887
Epoch: 95 | Iteration number: [480/4518] 10% | Training loss: 0.688284445554018
Epoch: 95 | Iteration number: [490/4518] 10% | Training loss: 0.6882475485607069
Epoch: 95 | Iteration number: [500/4518] 11% | Training loss: 0.6882152006626129
Epoch: 95 | Iteration number: [510/4518] 11% | Training loss: 0.6881910257479724
Epoch: 95 | Iteration number: [520/4518] 11% | Training loss: 0.6881711797072337
Epoch: 95 | Iteration number: [530/4518] 11% | Training loss: 0.6881450581100752
Epoch: 95 | Iteration number: [540/4518] 11% | Training loss: 0.6881234830176389
Epoch: 95 | Iteration number: [550/4518] 12% | Training loss: 0.6881021169098941
Epoch: 95 | Iteration number: [560/4518] 12% | Training loss: 0.6880888948483127
Epoch: 95 | Iteration number: [570/4518] 12% | Training loss: 0.6880561483533759
Epoch: 95 | Iteration number: [580/4518] 12% | Training loss: 0.6880484405262717
Epoch: 95 | Iteration number: [590/4518] 13% | Training loss: 0.68803975753865
Epoch: 95 | Iteration number: [600/4518] 13% | Training loss: 0.6880421481529871
Epoch: 95 | Iteration number: [610/4518] 13% | Training loss: 0.6880092763509906
Epoch: 95 | Iteration number: [620/4518] 13% | Training loss: 0.6880057782896103
Epoch: 95 | Iteration number: [630/4518] 13% | Training loss: 0.6879689899701921
Epoch: 95 | Iteration number: [640/4518] 14% | Training loss: 0.6879556918516755
Epoch: 95 | Iteration number: [650/4518] 14% | Training loss: 0.6879194887784811
Epoch: 95 | Iteration number: [660/4518] 14% | Training loss: 0.687904260375283
Epoch: 95 | Iteration number: [670/4518] 14% | Training loss: 0.687901743223418
Epoch: 95 | Iteration number: [680/4518] 15% | Training loss: 0.6878848105669022
Epoch: 95 | Iteration number: [690/4518] 15% | Training loss: 0.687884069007376
Epoch: 95 | Iteration number: [700/4518] 15% | Training loss: 0.6878555572032928
Epoch: 95 | Iteration number: [710/4518] 15% | Training loss: 0.6878284876615228
Epoch: 95 | Iteration number: [720/4518] 15% | Training loss: 0.6878143035703235
Epoch: 95 | Iteration number: [730/4518] 16% | Training loss: 0.6878034440621937
Epoch: 95 | Iteration number: [740/4518] 16% | Training loss: 0.6877962660145115
Epoch: 95 | Iteration number: [750/4518] 16% | Training loss: 0.6877914490699768
Epoch: 95 | Iteration number: [760/4518] 16% | Training loss: 0.687782159918233
Epoch: 95 | Iteration number: [770/4518] 17% | Training loss: 0.6877629015352819
Epoch: 95 | Iteration number: [780/4518] 17% | Training loss: 0.687751236710793
Epoch: 95 | Iteration number: [790/4518] 17% | Training loss: 0.6877466942690595
Epoch: 95 | Iteration number: [800/4518] 17% | Training loss: 0.6877476334571838
Epoch: 95 | Iteration number: [810/4518] 17% | Training loss: 0.6877410946804801
Epoch: 95 | Iteration number: [820/4518] 18% | Training loss: 0.6877379092501431
Epoch: 95 | Iteration number: [830/4518] 18% | Training loss: 0.68773788522525
Epoch: 95 | Iteration number: [840/4518] 18% | Training loss: 0.6877217976819902
Epoch: 95 | Iteration number: [850/4518] 18% | Training loss: 0.6877143750471227
Epoch: 95 | Iteration number: [860/4518] 19% | Training loss: 0.6877103994059008
Epoch: 95 | Iteration number: [870/4518] 19% | Training loss: 0.6877069012872103
Epoch: 95 | Iteration number: [880/4518] 19% | Training loss: 0.6876907904717056
Epoch: 95 | Iteration number: [890/4518] 19% | Training loss: 0.6876805265967766
Epoch: 95 | Iteration number: [900/4518] 19% | Training loss: 0.6876734539535311
Epoch: 95 | Iteration number: [910/4518] 20% | Training loss: 0.6876566926201622
Epoch: 95 | Iteration number: [920/4518] 20% | Training loss: 0.6876483918532081
Epoch: 95 | Iteration number: [930/4518] 20% | Training loss: 0.68765276106455
Epoch: 95 | Iteration number: [940/4518] 20% | Training loss: 0.6876272483074919
Epoch: 95 | Iteration number: [950/4518] 21% | Training loss: 0.6876055355448472
Epoch: 95 | Iteration number: [960/4518] 21% | Training loss: 0.6876092300439874
Epoch: 95 | Iteration number: [970/4518] 21% | Training loss: 0.6875931068179534
Epoch: 95 | Iteration number: [980/4518] 21% | Training loss: 0.6875964963314485
Epoch: 95 | Iteration number: [990/4518] 21% | Training loss: 0.6875959681742119
Epoch: 95 | Iteration number: [1000/4518] 22% | Training loss: 0.6876063990592957
Epoch: 95 | Iteration number: [1010/4518] 22% | Training loss: 0.6875964109850402
Epoch: 95 | Iteration number: [1020/4518] 22% | Training loss: 0.687571357979494
Epoch: 95 | Iteration number: [1030/4518] 22% | Training loss: 0.6875587028207131
Epoch: 95 | Iteration number: [1040/4518] 23% | Training loss: 0.6875463423247521
Epoch: 95 | Iteration number: [1050/4518] 23% | Training loss: 0.6875260086286635
Epoch: 95 | Iteration number: [1060/4518] 23% | Training loss: 0.6875290389330881
Epoch: 95 | Iteration number: [1070/4518] 23% | Training loss: 0.6875270470837567
Epoch: 95 | Iteration number: [1080/4518] 23% | Training loss: 0.687538030412462
Epoch: 95 | Iteration number: [1090/4518] 24% | Training loss: 0.6875269163639174
Epoch: 95 | Iteration number: [1100/4518] 24% | Training loss: 0.6875200467759912
Epoch: 95 | Iteration number: [1110/4518] 24% | Training loss: 0.687502280173001
Epoch: 95 | Iteration number: [1120/4518] 24% | Training loss: 0.687493066915444
Epoch: 95 | Iteration number: [1130/4518] 25% | Training loss: 0.6874914246322834
Epoch: 95 | Iteration number: [1140/4518] 25% | Training loss: 0.6874852248451166
Epoch: 95 | Iteration number: [1150/4518] 25% | Training loss: 0.687488309248634
Epoch: 95 | Iteration number: [1160/4518] 25% | Training loss: 0.6874844064486438
Epoch: 95 | Iteration number: [1170/4518] 25% | Training loss: 0.6874790571184239
Epoch: 95 | Iteration number: [1180/4518] 26% | Training loss: 0.6874694307981911
Epoch: 95 | Iteration number: [1190/4518] 26% | Training loss: 0.6874650886078842
Epoch: 95 | Iteration number: [1200/4518] 26% | Training loss: 0.6874659407138825
Epoch: 95 | Iteration number: [1210/4518] 26% | Training loss: 0.6874552508523641
Epoch: 95 | Iteration number: [1220/4518] 27% | Training loss: 0.6874549525683044
Epoch: 95 | Iteration number: [1230/4518] 27% | Training loss: 0.6874495024603556
Epoch: 95 | Iteration number: [1240/4518] 27% | Training loss: 0.6874482592267375
Epoch: 95 | Iteration number: [1250/4518] 27% | Training loss: 0.6874410660266876
Epoch: 95 | Iteration number: [1260/4518] 27% | Training loss: 0.6874319147022944
Epoch: 95 | Iteration number: [1270/4518] 28% | Training loss: 0.6874193841547478
Epoch: 95 | Iteration number: [1280/4518] 28% | Training loss: 0.6874174759257585
Epoch: 95 | Iteration number: [1290/4518] 28% | Training loss: 0.6874056664086128
Epoch: 95 | Iteration number: [1300/4518] 28% | Training loss: 0.687405149111381
Epoch: 95 | Iteration number: [1310/4518] 28% | Training loss: 0.6874005663485927
Epoch: 95 | Iteration number: [1320/4518] 29% | Training loss: 0.6873868325894529
Epoch: 95 | Iteration number: [1330/4518] 29% | Training loss: 0.6873771263692612
Epoch: 95 | Iteration number: [1340/4518] 29% | Training loss: 0.6873759558396553
Epoch: 95 | Iteration number: [1350/4518] 29% | Training loss: 0.687370105319553
Epoch: 95 | Iteration number: [1360/4518] 30% | Training loss: 0.687367417444201
Epoch: 95 | Iteration number: [1370/4518] 30% | Training loss: 0.6873604338099487
Epoch: 95 | Iteration number: [1380/4518] 30% | Training loss: 0.6873510008272917
Epoch: 95 | Iteration number: [1390/4518] 30% | Training loss: 0.6873474481294481
Epoch: 95 | Iteration number: [1400/4518] 30% | Training loss: 0.6873414246099335
Epoch: 95 | Iteration number: [1410/4518] 31% | Training loss: 0.6873377011600116
Epoch: 95 | Iteration number: [1420/4518] 31% | Training loss: 0.687329820805872
Epoch: 95 | Iteration number: [1430/4518] 31% | Training loss: 0.6873271031813188
Epoch: 95 | Iteration number: [1440/4518] 31% | Training loss: 0.6873186079992188
Epoch: 95 | Iteration number: [1450/4518] 32% | Training loss: 0.6873204242361003
Epoch: 95 | Iteration number: [1460/4518] 32% | Training loss: 0.6873163701328513
Epoch: 95 | Iteration number: [1470/4518] 32% | Training loss: 0.6873160021240209
Epoch: 95 | Iteration number: [1480/4518] 32% | Training loss: 0.6873276599355647
Epoch: 95 | Iteration number: [1490/4518] 32% | Training loss: 0.6873235966935254
Epoch: 95 | Iteration number: [1500/4518] 33% | Training loss: 0.6873120117982229
Epoch: 95 | Iteration number: [1510/4518] 33% | Training loss: 0.6873021267897246
Epoch: 95 | Iteration number: [1520/4518] 33% | Training loss: 0.6873000553956158
Epoch: 95 | Iteration number: [1530/4518] 33% | Training loss: 0.6872874909366657
Epoch: 95 | Iteration number: [1540/4518] 34% | Training loss: 0.6872876150654508
Epoch: 95 | Iteration number: [1550/4518] 34% | Training loss: 0.6872822708852829
Epoch: 95 | Iteration number: [1560/4518] 34% | Training loss: 0.6872770952872741
Epoch: 95 | Iteration number: [1570/4518] 34% | Training loss: 0.6872608644567477
Epoch: 95 | Iteration number: [1580/4518] 34% | Training loss: 0.6872506051123897
Epoch: 95 | Iteration number: [1590/4518] 35% | Training loss: 0.6872428354227318
Epoch: 95 | Iteration number: [1600/4518] 35% | Training loss: 0.6872351893037557
Epoch: 95 | Iteration number: [1610/4518] 35% | Training loss: 0.687231225034465
Epoch: 95 | Iteration number: [1620/4518] 35% | Training loss: 0.6872157881657283
Epoch: 95 | Iteration number: [1630/4518] 36% | Training loss: 0.6872112025878181
Epoch: 95 | Iteration number: [1640/4518] 36% | Training loss: 0.6872106928287482
Epoch: 95 | Iteration number: [1650/4518] 36% | Training loss: 0.6872152216145486
Epoch: 95 | Iteration number: [1660/4518] 36% | Training loss: 0.6872171674148146
Epoch: 95 | Iteration number: [1670/4518] 36% | Training loss: 0.687208668236247
Epoch: 95 | Iteration number: [1680/4518] 37% | Training loss: 0.6872076515640532
Epoch: 95 | Iteration number: [1690/4518] 37% | Training loss: 0.687204671082412
Epoch: 95 | Iteration number: [1700/4518] 37% | Training loss: 0.6871987561969196
Epoch: 95 | Iteration number: [1710/4518] 37% | Training loss: 0.6871959766797852
Epoch: 95 | Iteration number: [1720/4518] 38% | Training loss: 0.6871842111612475
Epoch: 95 | Iteration number: [1730/4518] 38% | Training loss: 0.6871818311986206
Epoch: 95 | Iteration number: [1740/4518] 38% | Training loss: 0.6871763339672966
Epoch: 95 | Iteration number: [1750/4518] 38% | Training loss: 0.6871699458530971
Epoch: 95 | Iteration number: [1760/4518] 38% | Training loss: 0.6871630925346505
Epoch: 95 | Iteration number: [1770/4518] 39% | Training loss: 0.6871632456105982
Epoch: 95 | Iteration number: [1780/4518] 39% | Training loss: 0.6871611458197069
Epoch: 95 | Iteration number: [1790/4518] 39% | Training loss: 0.6871571907451033
Epoch: 95 | Iteration number: [1800/4518] 39% | Training loss: 0.6871482424934705
Epoch: 95 | Iteration number: [1810/4518] 40% | Training loss: 0.6871481296107256
Epoch: 95 | Iteration number: [1820/4518] 40% | Training loss: 0.6871457396627783
Epoch: 95 | Iteration number: [1830/4518] 40% | Training loss: 0.6871370133806447
Epoch: 95 | Iteration number: [1840/4518] 40% | Training loss: 0.687137336121953
Epoch: 95 | Iteration number: [1850/4518] 40% | Training loss: 0.6871239268779754
Epoch: 95 | Iteration number: [1860/4518] 41% | Training loss: 0.6871217894297774
Epoch: 95 | Iteration number: [1870/4518] 41% | Training loss: 0.6871157209503459
Epoch: 95 | Iteration number: [1880/4518] 41% | Training loss: 0.6871208284763579
Epoch: 95 | Iteration number: [1890/4518] 41% | Training loss: 0.6871257519280469
Epoch: 95 | Iteration number: [1900/4518] 42% | Training loss: 0.6871218438524949
Epoch: 95 | Iteration number: [1910/4518] 42% | Training loss: 0.6871210764527945
Epoch: 95 | Iteration number: [1920/4518] 42% | Training loss: 0.6871201967199644
Epoch: 95 | Iteration number: [1930/4518] 42% | Training loss: 0.6871123438363248
Epoch: 95 | Iteration number: [1940/4518] 42% | Training loss: 0.6871066941735671
Epoch: 95 | Iteration number: [1950/4518] 43% | Training loss: 0.6871038334491926
Epoch: 95 | Iteration number: [1960/4518] 43% | Training loss: 0.687104494869709
Epoch: 95 | Iteration number: [1970/4518] 43% | Training loss: 0.687107400089351
Epoch: 95 | Iteration number: [1980/4518] 43% | Training loss: 0.6871013661827704
Epoch: 95 | Iteration number: [1990/4518] 44% | Training loss: 0.6871074341349865
Epoch: 95 | Iteration number: [2000/4518] 44% | Training loss: 0.6870957605242729
Epoch: 95 | Iteration number: [2010/4518] 44% | Training loss: 0.6870941487414327
Epoch: 95 | Iteration number: [2020/4518] 44% | Training loss: 0.6870871771975319
Epoch: 95 | Iteration number: [2030/4518] 44% | Training loss: 0.6870874566691262
Epoch: 95 | Iteration number: [2040/4518] 45% | Training loss: 0.687083241518806
Epoch: 95 | Iteration number: [2050/4518] 45% | Training loss: 0.6870838976778635
Epoch: 95 | Iteration number: [2060/4518] 45% | Training loss: 0.6870783401345744
Epoch: 95 | Iteration number: [2070/4518] 45% | Training loss: 0.6870765457406712
Epoch: 95 | Iteration number: [2080/4518] 46% | Training loss: 0.687078455921549
Epoch: 95 | Iteration number: [2090/4518] 46% | Training loss: 0.6870773561833577
Epoch: 95 | Iteration number: [2100/4518] 46% | Training loss: 0.6870788997979391
Epoch: 95 | Iteration number: [2110/4518] 46% | Training loss: 0.6870753976971052
Epoch: 95 | Iteration number: [2120/4518] 46% | Training loss: 0.6870732520267648
Epoch: 95 | Iteration number: [2130/4518] 47% | Training loss: 0.6870741263801503
Epoch: 95 | Iteration number: [2140/4518] 47% | Training loss: 0.6870718141025471
Epoch: 95 | Iteration number: [2150/4518] 47% | Training loss: 0.6870721106196559
Epoch: 95 | Iteration number: [2160/4518] 47% | Training loss: 0.6870679829959516
Epoch: 95 | Iteration number: [2170/4518] 48% | Training loss: 0.687062462024425
Epoch: 95 | Iteration number: [2180/4518] 48% | Training loss: 0.6870567446181534
Epoch: 95 | Iteration number: [2190/4518] 48% | Training loss: 0.6870593137937049
Epoch: 95 | Iteration number: [2200/4518] 48% | Training loss: 0.6870589755069125
Epoch: 95 | Iteration number: [2210/4518] 48% | Training loss: 0.6870628060258891
Epoch: 95 | Iteration number: [2220/4518] 49% | Training loss: 0.68706061520555
Epoch: 95 | Iteration number: [2230/4518] 49% | Training loss: 0.6870629147296529
Epoch: 95 | Iteration number: [2240/4518] 49% | Training loss: 0.6870594263875058
Epoch: 95 | Iteration number: [2250/4518] 49% | Training loss: 0.6870635444588131
Epoch: 95 | Iteration number: [2260/4518] 50% | Training loss: 0.687059041699477
Epoch: 95 | Iteration number: [2270/4518] 50% | Training loss: 0.6870608000503238
Epoch: 95 | Iteration number: [2280/4518] 50% | Training loss: 0.6870607855550029
Epoch: 95 | Iteration number: [2290/4518] 50% | Training loss: 0.6870638040736252
Epoch: 95 | Iteration number: [2300/4518] 50% | Training loss: 0.6870625932579455
Epoch: 95 | Iteration number: [2310/4518] 51% | Training loss: 0.6870613692126749
Epoch: 95 | Iteration number: [2320/4518] 51% | Training loss: 0.6870626368913157
Epoch: 95 | Iteration number: [2330/4518] 51% | Training loss: 0.6870637778304677
Epoch: 95 | Iteration number: [2340/4518] 51% | Training loss: 0.6870618717537986
Epoch: 95 | Iteration number: [2350/4518] 52% | Training loss: 0.6870632757785472
Epoch: 95 | Iteration number: [2360/4518] 52% | Training loss: 0.6870636485138182
Epoch: 95 | Iteration number: [2370/4518] 52% | Training loss: 0.6870677063736734
Epoch: 95 | Iteration number: [2380/4518] 52% | Training loss: 0.6870651586216037
Epoch: 95 | Iteration number: [2390/4518] 52% | Training loss: 0.6870633141016861
Epoch: 95 | Iteration number: [2400/4518] 53% | Training loss: 0.6870669907579819
Epoch: 95 | Iteration number: [2410/4518] 53% | Training loss: 0.6870718765555576
Epoch: 95 | Iteration number: [2420/4518] 53% | Training loss: 0.6870703702869494
Epoch: 95 | Iteration number: [2430/4518] 53% | Training loss: 0.6870706873911399
Epoch: 95 | Iteration number: [2440/4518] 54% | Training loss: 0.6870724150147595
Epoch: 95 | Iteration number: [2450/4518] 54% | Training loss: 0.6870730768417825
Epoch: 95 | Iteration number: [2460/4518] 54% | Training loss: 0.6870749945078439
Epoch: 95 | Iteration number: [2470/4518] 54% | Training loss: 0.6870697054061813
Epoch: 95 | Iteration number: [2480/4518] 54% | Training loss: 0.6870699140573702
Epoch: 95 | Iteration number: [2490/4518] 55% | Training loss: 0.6870657348489186
Epoch: 95 | Iteration number: [2500/4518] 55% | Training loss: 0.6870658664941788
Epoch: 95 | Iteration number: [2510/4518] 55% | Training loss: 0.6870663270294903
Epoch: 95 | Iteration number: [2520/4518] 55% | Training loss: 0.6870652267620677
Epoch: 95 | Iteration number: [2530/4518] 55% | Training loss: 0.6870638517758592
Epoch: 95 | Iteration number: [2540/4518] 56% | Training loss: 0.6870689375194039
Epoch: 95 | Iteration number: [2550/4518] 56% | Training loss: 0.687068585695005
Epoch: 95 | Iteration number: [2560/4518] 56% | Training loss: 0.6870724608423189
Epoch: 95 | Iteration number: [2570/4518] 56% | Training loss: 0.6870703023927222
Epoch: 95 | Iteration number: [2580/4518] 57% | Training loss: 0.6870688626470491
Epoch: 95 | Iteration number: [2590/4518] 57% | Training loss: 0.6870677373584173
Epoch: 95 | Iteration number: [2600/4518] 57% | Training loss: 0.6870660432256185
Epoch: 95 | Iteration number: [2610/4518] 57% | Training loss: 0.6870682059805056
Epoch: 95 | Iteration number: [2620/4518] 57% | Training loss: 0.6870668929041797
Epoch: 95 | Iteration number: [2630/4518] 58% | Training loss: 0.6870688216087936
Epoch: 95 | Iteration number: [2640/4518] 58% | Training loss: 0.6870685002568996
Epoch: 95 | Iteration number: [2650/4518] 58% | Training loss: 0.6870674360023354
Epoch: 95 | Iteration number: [2660/4518] 58% | Training loss: 0.6870683640017545
Epoch: 95 | Iteration number: [2670/4518] 59% | Training loss: 0.6870737918084033
Epoch: 95 | Iteration number: [2680/4518] 59% | Training loss: 0.6870693315988157
Epoch: 95 | Iteration number: [2690/4518] 59% | Training loss: 0.6870731658430348
Epoch: 95 | Iteration number: [2700/4518] 59% | Training loss: 0.6870759137692275
Epoch: 95 | Iteration number: [2710/4518] 59% | Training loss: 0.6870735647053736
Epoch: 95 | Iteration number: [2720/4518] 60% | Training loss: 0.6870707234258161
Epoch: 95 | Iteration number: [2730/4518] 60% | Training loss: 0.6870722934439942
Epoch: 95 | Iteration number: [2740/4518] 60% | Training loss: 0.6870673780458687
Epoch: 95 | Iteration number: [2750/4518] 60% | Training loss: 0.6870616998238998
Epoch: 95 | Iteration number: [2760/4518] 61% | Training loss: 0.6870605903259223
Epoch: 95 | Iteration number: [2770/4518] 61% | Training loss: 0.6870559113981061
Epoch: 95 | Iteration number: [2780/4518] 61% | Training loss: 0.6870554392500747
Epoch: 95 | Iteration number: [2790/4518] 61% | Training loss: 0.6870559143122806
Epoch: 95 | Iteration number: [2800/4518] 61% | Training loss: 0.6870510288434369
Epoch: 95 | Iteration number: [2810/4518] 62% | Training loss: 0.6870487040472201
Epoch: 95 | Iteration number: [2820/4518] 62% | Training loss: 0.687047115877165
Epoch: 95 | Iteration number: [2830/4518] 62% | Training loss: 0.687043698537476
Epoch: 95 | Iteration number: [2840/4518] 62% | Training loss: 0.6870439676541678
Epoch: 95 | Iteration number: [2850/4518] 63% | Training loss: 0.6870421324905597
Epoch: 95 | Iteration number: [2860/4518] 63% | Training loss: 0.6870469923411215
Epoch: 95 | Iteration number: [2870/4518] 63% | Training loss: 0.6870475550769514
Epoch: 95 | Iteration number: [2880/4518] 63% | Training loss: 0.687051277856032
Epoch: 95 | Iteration number: [2890/4518] 63% | Training loss: 0.6870492393788994
Epoch: 95 | Iteration number: [2900/4518] 64% | Training loss: 0.6870506621023704
Epoch: 95 | Iteration number: [2910/4518] 64% | Training loss: 0.6870525807654325
Epoch: 95 | Iteration number: [2920/4518] 64% | Training loss: 0.6870513635547194
Epoch: 95 | Iteration number: [2930/4518] 64% | Training loss: 0.6870522225472707
Epoch: 95 | Iteration number: [2940/4518] 65% | Training loss: 0.6870509624683938
Epoch: 95 | Iteration number: [2950/4518] 65% | Training loss: 0.6870515701528322
Epoch: 95 | Iteration number: [2960/4518] 65% | Training loss: 0.6870491323036116
Epoch: 95 | Iteration number: [2970/4518] 65% | Training loss: 0.6870492905077308
Epoch: 95 | Iteration number: [2980/4518] 65% | Training loss: 0.6870474473141984
Epoch: 95 | Iteration number: [2990/4518] 66% | Training loss: 0.6870512292935298
Epoch: 95 | Iteration number: [3000/4518] 66% | Training loss: 0.6870497083862622
Epoch: 95 | Iteration number: [3010/4518] 66% | Training loss: 0.6870462577604376
Epoch: 95 | Iteration number: [3020/4518] 66% | Training loss: 0.6870470118246331
Epoch: 95 | Iteration number: [3030/4518] 67% | Training loss: 0.6870443351001236
Epoch: 95 | Iteration number: [3040/4518] 67% | Training loss: 0.6870418779748051
Epoch: 95 | Iteration number: [3050/4518] 67% | Training loss: 0.6870407293468225
Epoch: 95 | Iteration number: [3060/4518] 67% | Training loss: 0.6870339338880739
Epoch: 95 | Iteration number: [3070/4518] 67% | Training loss: 0.6870314934354652
Epoch: 95 | Iteration number: [3080/4518] 68% | Training loss: 0.6870324799573266
Epoch: 95 | Iteration number: [3090/4518] 68% | Training loss: 0.6870273101098329
Epoch: 95 | Iteration number: [3100/4518] 68% | Training loss: 0.687029573417479
Epoch: 95 | Iteration number: [3110/4518] 68% | Training loss: 0.687026172397221
Epoch: 95 | Iteration number: [3120/4518] 69% | Training loss: 0.6870275282898011
Epoch: 95 | Iteration number: [3130/4518] 69% | Training loss: 0.6870264262246628
Epoch: 95 | Iteration number: [3140/4518] 69% | Training loss: 0.687023949167531
Epoch: 95 | Iteration number: [3150/4518] 69% | Training loss: 0.6870207996217031
Epoch: 95 | Iteration number: [3160/4518] 69% | Training loss: 0.687023987215531
Epoch: 95 | Iteration number: [3170/4518] 70% | Training loss: 0.6870217381027595
Epoch: 95 | Iteration number: [3180/4518] 70% | Training loss: 0.6870199171814528
Epoch: 95 | Iteration number: [3190/4518] 70% | Training loss: 0.6870179902984057
Epoch: 95 | Iteration number: [3200/4518] 70% | Training loss: 0.6870177878811955
Epoch: 95 | Iteration number: [3210/4518] 71% | Training loss: 0.6870174084497018
Epoch: 95 | Iteration number: [3220/4518] 71% | Training loss: 0.6870145002322168
Epoch: 95 | Iteration number: [3230/4518] 71% | Training loss: 0.6870144697719314
Epoch: 95 | Iteration number: [3240/4518] 71% | Training loss: 0.6870081515959752
Epoch: 95 | Iteration number: [3250/4518] 71% | Training loss: 0.6870034533830789
Epoch: 95 | Iteration number: [3260/4518] 72% | Training loss: 0.6869972725221716
Epoch: 95 | Iteration number: [3270/4518] 72% | Training loss: 0.6869963892920666
Epoch: 95 | Iteration number: [3280/4518] 72% | Training loss: 0.6869966679229969
Epoch: 95 | Iteration number: [3290/4518] 72% | Training loss: 0.6869931268836952
Epoch: 95 | Iteration number: [3300/4518] 73% | Training loss: 0.6869898667299387
Epoch: 95 | Iteration number: [3310/4518] 73% | Training loss: 0.6869926225382756
Epoch: 95 | Iteration number: [3320/4518] 73% | Training loss: 0.686993029659771
Epoch: 95 | Iteration number: [3330/4518] 73% | Training loss: 0.6869918095098959
Epoch: 95 | Iteration number: [3340/4518] 73% | Training loss: 0.686991641728464
Epoch: 95 | Iteration number: [3350/4518] 74% | Training loss: 0.6869947135092607
Epoch: 95 | Iteration number: [3360/4518] 74% | Training loss: 0.6869950948016984
Epoch: 95 | Iteration number: [3370/4518] 74% | Training loss: 0.686991386632891
Epoch: 95 | Iteration number: [3380/4518] 74% | Training loss: 0.6869923132234776
Epoch: 95 | Iteration number: [3390/4518] 75% | Training loss: 0.6869903367001751
Epoch: 95 | Iteration number: [3400/4518] 75% | Training loss: 0.6869888577741735
Epoch: 95 | Iteration number: [3410/4518] 75% | Training loss: 0.6869921274024371
Epoch: 95 | Iteration number: [3420/4518] 75% | Training loss: 0.6869931184234674
Epoch: 95 | Iteration number: [3430/4518] 75% | Training loss: 0.6869881726910004
Epoch: 95 | Iteration number: [3440/4518] 76% | Training loss: 0.6869852876074092
Epoch: 95 | Iteration number: [3450/4518] 76% | Training loss: 0.6869816405704056
Epoch: 95 | Iteration number: [3460/4518] 76% | Training loss: 0.6869798797058921
Epoch: 95 | Iteration number: [3470/4518] 76% | Training loss: 0.686975441301934
Epoch: 95 | Iteration number: [3480/4518] 77% | Training loss: 0.6869780376724813
Epoch: 95 | Iteration number: [3490/4518] 77% | Training loss: 0.686976226267637
Epoch: 95 | Iteration number: [3500/4518] 77% | Training loss: 0.6869787032604218
Epoch: 95 | Iteration number: [3510/4518] 77% | Training loss: 0.6869766038537365
Epoch: 95 | Iteration number: [3520/4518] 77% | Training loss: 0.6869748825207352
Epoch: 95 | Iteration number: [3530/4518] 78% | Training loss: 0.6869740143038395
Epoch: 95 | Iteration number: [3540/4518] 78% | Training loss: 0.6869724607400302
Epoch: 95 | Iteration number: [3550/4518] 78% | Training loss: 0.6869686285710671
Epoch: 95 | Iteration number: [3560/4518] 78% | Training loss: 0.6869660167546755
Epoch: 95 | Iteration number: [3570/4518] 79% | Training loss: 0.6869638143133383
Epoch: 95 | Iteration number: [3580/4518] 79% | Training loss: 0.6869634652437444
Epoch: 95 | Iteration number: [3590/4518] 79% | Training loss: 0.686964426581906
Epoch: 95 | Iteration number: [3600/4518] 79% | Training loss: 0.6869631827208731
Epoch: 95 | Iteration number: [3610/4518] 79% | Training loss: 0.6869618079834037
Epoch: 95 | Iteration number: [3620/4518] 80% | Training loss: 0.686964125198554
Epoch: 95 | Iteration number: [3630/4518] 80% | Training loss: 0.686967277001415
Epoch: 95 | Iteration number: [3640/4518] 80% | Training loss: 0.6869660351793845
Epoch: 95 | Iteration number: [3650/4518] 80% | Training loss: 0.6869656067025172
Epoch: 95 | Iteration number: [3660/4518] 81% | Training loss: 0.6869660297215311
Epoch: 95 | Iteration number: [3670/4518] 81% | Training loss: 0.686967797776334
Epoch: 95 | Iteration number: [3680/4518] 81% | Training loss: 0.686967060342431
Epoch: 95 | Iteration number: [3690/4518] 81% | Training loss: 0.6869659852690813
Epoch: 95 | Iteration number: [3700/4518] 81% | Training loss: 0.6869663039413658
Epoch: 95 | Iteration number: [3710/4518] 82% | Training loss: 0.6869663708454193
Epoch: 95 | Iteration number: [3720/4518] 82% | Training loss: 0.6869631416054183
Epoch: 95 | Iteration number: [3730/4518] 82% | Training loss: 0.6869636220203328
Epoch: 95 | Iteration number: [3740/4518] 82% | Training loss: 0.6869641078347191
Epoch: 95 | Iteration number: [3750/4518] 83% | Training loss: 0.6869648026784261
Epoch: 95 | Iteration number: [3760/4518] 83% | Training loss: 0.6869640825910771
Epoch: 95 | Iteration number: [3770/4518] 83% | Training loss: 0.6869603156885354
Epoch: 95 | Iteration number: [3780/4518] 83% | Training loss: 0.6869578430734614
Epoch: 95 | Iteration number: [3790/4518] 83% | Training loss: 0.6869584234220056
Epoch: 95 | Iteration number: [3800/4518] 84% | Training loss: 0.6869572808868006
Epoch: 95 | Iteration number: [3810/4518] 84% | Training loss: 0.686959028509971
Epoch: 95 | Iteration number: [3820/4518] 84% | Training loss: 0.6869610821857502
Epoch: 95 | Iteration number: [3830/4518] 84% | Training loss: 0.6869583551005969
Epoch: 95 | Iteration number: [3840/4518] 84% | Training loss: 0.6869554462532202
Epoch: 95 | Iteration number: [3850/4518] 85% | Training loss: 0.6869561677784115
Epoch: 95 | Iteration number: [3860/4518] 85% | Training loss: 0.686952404145132
Epoch: 95 | Iteration number: [3870/4518] 85% | Training loss: 0.6869486559885108
Epoch: 95 | Iteration number: [3880/4518] 85% | Training loss: 0.6869495104268654
Epoch: 95 | Iteration number: [3890/4518] 86% | Training loss: 0.6869443955029191
Epoch: 95 | Iteration number: [3900/4518] 86% | Training loss: 0.686941895973988
Epoch: 95 | Iteration number: [3910/4518] 86% | Training loss: 0.6869377834565195
Epoch: 95 | Iteration number: [3920/4518] 86% | Training loss: 0.6869354930459236
Epoch: 95 | Iteration number: [3930/4518] 86% | Training loss: 0.686933210226719
Epoch: 95 | Iteration number: [3940/4518] 87% | Training loss: 0.6869377787191856
Epoch: 95 | Iteration number: [3950/4518] 87% | Training loss: 0.6869360264947143
Epoch: 95 | Iteration number: [3960/4518] 87% | Training loss: 0.6869373340648834
Epoch: 95 | Iteration number: [3970/4518] 87% | Training loss: 0.6869357182036719
Epoch: 95 | Iteration number: [3980/4518] 88% | Training loss: 0.6869335648252737
Epoch: 95 | Iteration number: [3990/4518] 88% | Training loss: 0.6869332604390338
Epoch: 95 | Iteration number: [4000/4518] 88% | Training loss: 0.6869311197847128
Epoch: 95 | Iteration number: [4010/4518] 88% | Training loss: 0.6869313609570339
Epoch: 95 | Iteration number: [4020/4518] 88% | Training loss: 0.6869337312172894
Epoch: 95 | Iteration number: [4030/4518] 89% | Training loss: 0.6869332199652792
Epoch: 95 | Iteration number: [4040/4518] 89% | Training loss: 0.6869329076739821
Epoch: 95 | Iteration number: [4050/4518] 89% | Training loss: 0.6869315847496927
Epoch: 95 | Iteration number: [4060/4518] 89% | Training loss: 0.6869314921166509
Epoch: 95 | Iteration number: [4070/4518] 90% | Training loss: 0.6869272336473629
Epoch: 95 | Iteration number: [4080/4518] 90% | Training loss: 0.686927677603329
Epoch: 95 | Iteration number: [4090/4518] 90% | Training loss: 0.6869256560697532
Epoch: 95 | Iteration number: [4100/4518] 90% | Training loss: 0.6869222810210251
Epoch: 95 | Iteration number: [4110/4518] 90% | Training loss: 0.6869200461972369
Epoch: 95 | Iteration number: [4120/4518] 91% | Training loss: 0.6869232893424126
Epoch: 95 | Iteration number: [4130/4518] 91% | Training loss: 0.6869223848815115
Epoch: 95 | Iteration number: [4140/4518] 91% | Training loss: 0.6869241532208263
Epoch: 95 | Iteration number: [4150/4518] 91% | Training loss: 0.6869241978892361
Epoch: 95 | Iteration number: [4160/4518] 92% | Training loss: 0.6869243053002999
Epoch: 95 | Iteration number: [4170/4518] 92% | Training loss: 0.6869230036684078
Epoch: 95 | Iteration number: [4180/4518] 92% | Training loss: 0.6869236225431615
Epoch: 95 | Iteration number: [4190/4518] 92% | Training loss: 0.6869263067877094
Epoch: 95 | Iteration number: [4200/4518] 92% | Training loss: 0.6869297419985135
Epoch: 95 | Iteration number: [4210/4518] 93% | Training loss: 0.6869283704180049
Epoch: 95 | Iteration number: [4220/4518] 93% | Training loss: 0.6869279144358296
Epoch: 95 | Iteration number: [4230/4518] 93% | Training loss: 0.6869268599976884
Epoch: 95 | Iteration number: [4240/4518] 93% | Training loss: 0.6869264893936661
Epoch: 95 | Iteration number: [4250/4518] 94% | Training loss: 0.6869277063257554
Epoch: 95 | Iteration number: [4260/4518] 94% | Training loss: 0.6869285557331614
Epoch: 95 | Iteration number: [4270/4518] 94% | Training loss: 0.6869296477326744
Epoch: 95 | Iteration number: [4280/4518] 94% | Training loss: 0.6869267065530625
Epoch: 95 | Iteration number: [4290/4518] 94% | Training loss: 0.6869243234743327
Epoch: 95 | Iteration number: [4300/4518] 95% | Training loss: 0.6869246652930282
Epoch: 95 | Iteration number: [4310/4518] 95% | Training loss: 0.6869245832729782
Epoch: 95 | Iteration number: [4320/4518] 95% | Training loss: 0.6869248713470167
Epoch: 95 | Iteration number: [4330/4518] 95% | Training loss: 0.6869231033683099
Epoch: 95 | Iteration number: [4340/4518] 96% | Training loss: 0.686919556564999
Epoch: 95 | Iteration number: [4350/4518] 96% | Training loss: 0.6869197390545374
Epoch: 95 | Iteration number: [4360/4518] 96% | Training loss: 0.6869175917374979
Epoch: 95 | Iteration number: [4370/4518] 96% | Training loss: 0.6869168456959234
Epoch: 95 | Iteration number: [4380/4518] 96% | Training loss: 0.6869174728246584
Epoch: 95 | Iteration number: [4390/4518] 97% | Training loss: 0.6869177927460377
Epoch: 95 | Iteration number: [4400/4518] 97% | Training loss: 0.6869163643636487
Epoch: 95 | Iteration number: [4410/4518] 97% | Training loss: 0.6869150515045979
Epoch: 95 | Iteration number: [4420/4518] 97% | Training loss: 0.6869156362918707
Epoch: 95 | Iteration number: [4430/4518] 98% | Training loss: 0.6869156495308499
Epoch: 95 | Iteration number: [4440/4518] 98% | Training loss: 0.6869149699270188
Epoch: 95 | Iteration number: [4450/4518] 98% | Training loss: 0.6869145459539435
Epoch: 95 | Iteration number: [4460/4518] 98% | Training loss: 0.6869165878124835
Epoch: 95 | Iteration number: [4470/4518] 98% | Training loss: 0.6869136108648057
Epoch: 95 | Iteration number: [4480/4518] 99% | Training loss: 0.6869137939730925
Epoch: 95 | Iteration number: [4490/4518] 99% | Training loss: 0.6869158257222122
Epoch: 95 | Iteration number: [4500/4518] 99% | Training loss: 0.6869150044255786
Epoch: 95 | Iteration number: [4510/4518] 99% | Training loss: 0.6869166647383484

 End of epoch: 95 | Train Loss: 0.6867609437903033 | Training Time: 633 

 End of epoch: 95 | Eval Loss: 0.6899249602337273 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/4518] 0% | Training loss: 0.7558827102184296
Epoch: 96 | Iteration number: [20/4518] 0% | Training loss: 0.7208672165870667
Epoch: 96 | Iteration number: [30/4518] 0% | Training loss: 0.7097845633824666
Epoch: 96 | Iteration number: [40/4518] 0% | Training loss: 0.7039404824376106
Epoch: 96 | Iteration number: [50/4518] 1% | Training loss: 0.7004270565509796
Epoch: 96 | Iteration number: [60/4518] 1% | Training loss: 0.6982895205418269
Epoch: 96 | Iteration number: [70/4518] 1% | Training loss: 0.6965422902788435
Epoch: 96 | Iteration number: [80/4518] 1% | Training loss: 0.6952214539051056
Epoch: 96 | Iteration number: [90/4518] 1% | Training loss: 0.6942031198077732
Epoch: 96 | Iteration number: [100/4518] 2% | Training loss: 0.6935075467824936
Epoch: 96 | Iteration number: [110/4518] 2% | Training loss: 0.6928498690778558
Epoch: 96 | Iteration number: [120/4518] 2% | Training loss: 0.6922410060962041
Epoch: 96 | Iteration number: [130/4518] 2% | Training loss: 0.6917439552453848
Epoch: 96 | Iteration number: [140/4518] 3% | Training loss: 0.6914320613656725
Epoch: 96 | Iteration number: [150/4518] 3% | Training loss: 0.6910223535696666
Epoch: 96 | Iteration number: [160/4518] 3% | Training loss: 0.6906709022819996
Epoch: 96 | Iteration number: [170/4518] 3% | Training loss: 0.690408202830483
Epoch: 96 | Iteration number: [180/4518] 3% | Training loss: 0.6901960561672846
Epoch: 96 | Iteration number: [190/4518] 4% | Training loss: 0.6899765184051112
Epoch: 96 | Iteration number: [200/4518] 4% | Training loss: 0.6898296648263931
Epoch: 96 | Iteration number: [210/4518] 4% | Training loss: 0.6896780110540844
Epoch: 96 | Iteration number: [220/4518] 4% | Training loss: 0.6895507273348895
Epoch: 96 | Iteration number: [230/4518] 5% | Training loss: 0.6893890888794608
Epoch: 96 | Iteration number: [240/4518] 5% | Training loss: 0.689312673608462
Epoch: 96 | Iteration number: [250/4518] 5% | Training loss: 0.6892259657382965
Epoch: 96 | Iteration number: [260/4518] 5% | Training loss: 0.6891209755952542
Epoch: 96 | Iteration number: [270/4518] 5% | Training loss: 0.6890480822987026
Epoch: 96 | Iteration number: [280/4518] 6% | Training loss: 0.6889739807162966
Epoch: 96 | Iteration number: [290/4518] 6% | Training loss: 0.6888954051609697
Epoch: 96 | Iteration number: [300/4518] 6% | Training loss: 0.6888115231196086
Epoch: 96 | Iteration number: [310/4518] 6% | Training loss: 0.6887107531870565
Epoch: 96 | Iteration number: [320/4518] 7% | Training loss: 0.6886378202587367
Epoch: 96 | Iteration number: [330/4518] 7% | Training loss: 0.688562872915557
Epoch: 96 | Iteration number: [340/4518] 7% | Training loss: 0.6884989086319419
Epoch: 96 | Iteration number: [350/4518] 7% | Training loss: 0.6884360061373029
Epoch: 96 | Iteration number: [360/4518] 7% | Training loss: 0.688409729136361
Epoch: 96 | Iteration number: [370/4518] 8% | Training loss: 0.6884100377559662
Epoch: 96 | Iteration number: [380/4518] 8% | Training loss: 0.6883934927614112
Epoch: 96 | Iteration number: [390/4518] 8% | Training loss: 0.6883482777155363
Epoch: 96 | Iteration number: [400/4518] 8% | Training loss: 0.6883118183910847
Epoch: 96 | Iteration number: [410/4518] 9% | Training loss: 0.6882376768240115
Epoch: 96 | Iteration number: [420/4518] 9% | Training loss: 0.6881954574868793
Epoch: 96 | Iteration number: [430/4518] 9% | Training loss: 0.6881667408832284
Epoch: 96 | Iteration number: [440/4518] 9% | Training loss: 0.6881451106884263
Epoch: 96 | Iteration number: [450/4518] 9% | Training loss: 0.6881209894021352
Epoch: 96 | Iteration number: [460/4518] 10% | Training loss: 0.6881004841431327
Epoch: 96 | Iteration number: [470/4518] 10% | Training loss: 0.6880662994181856
Epoch: 96 | Iteration number: [480/4518] 10% | Training loss: 0.6880515952905019
Epoch: 96 | Iteration number: [490/4518] 10% | Training loss: 0.6880478042729047
Epoch: 96 | Iteration number: [500/4518] 11% | Training loss: 0.6880279259681702
Epoch: 96 | Iteration number: [510/4518] 11% | Training loss: 0.688002821744657
Epoch: 96 | Iteration number: [520/4518] 11% | Training loss: 0.6880216159499608
Epoch: 96 | Iteration number: [530/4518] 11% | Training loss: 0.6880081179007045
Epoch: 96 | Iteration number: [540/4518] 11% | Training loss: 0.688013842370775
Epoch: 96 | Iteration number: [550/4518] 12% | Training loss: 0.6879853168400851
Epoch: 96 | Iteration number: [560/4518] 12% | Training loss: 0.6879534063594682
Epoch: 96 | Iteration number: [570/4518] 12% | Training loss: 0.6879350872416246
Epoch: 96 | Iteration number: [580/4518] 12% | Training loss: 0.687910226912334
Epoch: 96 | Iteration number: [590/4518] 13% | Training loss: 0.6878821161843962
Epoch: 96 | Iteration number: [600/4518] 13% | Training loss: 0.6878814160823822
Epoch: 96 | Iteration number: [610/4518] 13% | Training loss: 0.687870185003906
Epoch: 96 | Iteration number: [620/4518] 13% | Training loss: 0.6878445487829947
Epoch: 96 | Iteration number: [630/4518] 13% | Training loss: 0.6878359546737065
Epoch: 96 | Iteration number: [640/4518] 14% | Training loss: 0.6878090092912317
Epoch: 96 | Iteration number: [650/4518] 14% | Training loss: 0.6877985732371991
Epoch: 96 | Iteration number: [660/4518] 14% | Training loss: 0.6877777960264322
Epoch: 96 | Iteration number: [670/4518] 14% | Training loss: 0.6877783600074142
Epoch: 96 | Iteration number: [680/4518] 15% | Training loss: 0.6877528134514304
Epoch: 96 | Iteration number: [690/4518] 15% | Training loss: 0.6877466933450838
Epoch: 96 | Iteration number: [700/4518] 15% | Training loss: 0.6877217367717198
Epoch: 96 | Iteration number: [710/4518] 15% | Training loss: 0.6877038304234894
Epoch: 96 | Iteration number: [720/4518] 15% | Training loss: 0.6876990180048678
Epoch: 96 | Iteration number: [730/4518] 16% | Training loss: 0.6876759126578291
Epoch: 96 | Iteration number: [740/4518] 16% | Training loss: 0.6876494293277328
Epoch: 96 | Iteration number: [750/4518] 16% | Training loss: 0.6876265076796214
Epoch: 96 | Iteration number: [760/4518] 16% | Training loss: 0.6876191958000786
Epoch: 96 | Iteration number: [770/4518] 17% | Training loss: 0.6876131060835603
Epoch: 96 | Iteration number: [780/4518] 17% | Training loss: 0.6876019978370422
Epoch: 96 | Iteration number: [790/4518] 17% | Training loss: 0.6875855114641068
Epoch: 96 | Iteration number: [800/4518] 17% | Training loss: 0.6875619437545538
Epoch: 96 | Iteration number: [810/4518] 17% | Training loss: 0.6875417015434783
Epoch: 96 | Iteration number: [820/4518] 18% | Training loss: 0.6875284519137406
Epoch: 96 | Iteration number: [830/4518] 18% | Training loss: 0.6875314018094396
Epoch: 96 | Iteration number: [840/4518] 18% | Training loss: 0.6875243645338786
Epoch: 96 | Iteration number: [850/4518] 18% | Training loss: 0.6875164856630213
Epoch: 96 | Iteration number: [860/4518] 19% | Training loss: 0.6875101783940959
Epoch: 96 | Iteration number: [870/4518] 19% | Training loss: 0.6874991046286177
Epoch: 96 | Iteration number: [880/4518] 19% | Training loss: 0.6874903763559732
Epoch: 96 | Iteration number: [890/4518] 19% | Training loss: 0.6874915291754048
Epoch: 96 | Iteration number: [900/4518] 19% | Training loss: 0.6874606296088961
Epoch: 96 | Iteration number: [910/4518] 20% | Training loss: 0.687456122990493
Epoch: 96 | Iteration number: [920/4518] 20% | Training loss: 0.6874564775954122
Epoch: 96 | Iteration number: [930/4518] 20% | Training loss: 0.6874355061079866
Epoch: 96 | Iteration number: [940/4518] 20% | Training loss: 0.687441013214436
Epoch: 96 | Iteration number: [950/4518] 21% | Training loss: 0.6874246118570629
Epoch: 96 | Iteration number: [960/4518] 21% | Training loss: 0.6874211426203449
Epoch: 96 | Iteration number: [970/4518] 21% | Training loss: 0.6874031831308739
Epoch: 96 | Iteration number: [980/4518] 21% | Training loss: 0.6873988495189316
Epoch: 96 | Iteration number: [990/4518] 21% | Training loss: 0.6874013273402898
Epoch: 96 | Iteration number: [1000/4518] 22% | Training loss: 0.6873793622851372
Epoch: 96 | Iteration number: [1010/4518] 22% | Training loss: 0.687376895753464
Epoch: 96 | Iteration number: [1020/4518] 22% | Training loss: 0.6873599546797136
Epoch: 96 | Iteration number: [1030/4518] 22% | Training loss: 0.6873420254119391
Epoch: 96 | Iteration number: [1040/4518] 23% | Training loss: 0.687341294151086
Epoch: 96 | Iteration number: [1050/4518] 23% | Training loss: 0.6873238758246104
Epoch: 96 | Iteration number: [1060/4518] 23% | Training loss: 0.687319755329276
Epoch: 96 | Iteration number: [1070/4518] 23% | Training loss: 0.6873211371564419
Epoch: 96 | Iteration number: [1080/4518] 23% | Training loss: 0.6873192581313627
Epoch: 96 | Iteration number: [1090/4518] 24% | Training loss: 0.6873149701214711
Epoch: 96 | Iteration number: [1100/4518] 24% | Training loss: 0.6873178033395247
Epoch: 96 | Iteration number: [1110/4518] 24% | Training loss: 0.6873015821517051
Epoch: 96 | Iteration number: [1120/4518] 24% | Training loss: 0.6873012049921922
Epoch: 96 | Iteration number: [1130/4518] 25% | Training loss: 0.6873106547161542
Epoch: 96 | Iteration number: [1140/4518] 25% | Training loss: 0.6873115230547754
Epoch: 96 | Iteration number: [1150/4518] 25% | Training loss: 0.687297915790392
Epoch: 96 | Iteration number: [1160/4518] 25% | Training loss: 0.6872854007215335
Epoch: 96 | Iteration number: [1170/4518] 25% | Training loss: 0.6872817009432703
Epoch: 96 | Iteration number: [1180/4518] 26% | Training loss: 0.6872730877439854
Epoch: 96 | Iteration number: [1190/4518] 26% | Training loss: 0.6872672506240236
Epoch: 96 | Iteration number: [1200/4518] 26% | Training loss: 0.6872633635997772
Epoch: 96 | Iteration number: [1210/4518] 26% | Training loss: 0.6872609842907299
Epoch: 96 | Iteration number: [1220/4518] 27% | Training loss: 0.6872566721478447
Epoch: 96 | Iteration number: [1230/4518] 27% | Training loss: 0.6872539539162705
Epoch: 96 | Iteration number: [1240/4518] 27% | Training loss: 0.6872499558714128
Epoch: 96 | Iteration number: [1250/4518] 27% | Training loss: 0.6872462844371796
Epoch: 96 | Iteration number: [1260/4518] 27% | Training loss: 0.6872452359350901
Epoch: 96 | Iteration number: [1270/4518] 28% | Training loss: 0.6872371332851921
Epoch: 96 | Iteration number: [1280/4518] 28% | Training loss: 0.6872372118290514
Epoch: 96 | Iteration number: [1290/4518] 28% | Training loss: 0.6872311192427495
Epoch: 96 | Iteration number: [1300/4518] 28% | Training loss: 0.6872291682775205
Epoch: 96 | Iteration number: [1310/4518] 28% | Training loss: 0.687233767254662
Epoch: 96 | Iteration number: [1320/4518] 29% | Training loss: 0.6872360700007641
Epoch: 96 | Iteration number: [1330/4518] 29% | Training loss: 0.6872359822567244
Epoch: 96 | Iteration number: [1340/4518] 29% | Training loss: 0.6872289557065536
Epoch: 96 | Iteration number: [1350/4518] 29% | Training loss: 0.6872257627381219
Epoch: 96 | Iteration number: [1360/4518] 30% | Training loss: 0.6872117213904858
Epoch: 96 | Iteration number: [1370/4518] 30% | Training loss: 0.6872053406099333
Epoch: 96 | Iteration number: [1380/4518] 30% | Training loss: 0.6872033132591109
Epoch: 96 | Iteration number: [1390/4518] 30% | Training loss: 0.6872034017988247
Epoch: 96 | Iteration number: [1400/4518] 30% | Training loss: 0.6872064228143011
Epoch: 96 | Iteration number: [1410/4518] 31% | Training loss: 0.6872073951342427
Epoch: 96 | Iteration number: [1420/4518] 31% | Training loss: 0.6872075754152217
Epoch: 96 | Iteration number: [1430/4518] 31% | Training loss: 0.6871975038435075
Epoch: 96 | Iteration number: [1440/4518] 31% | Training loss: 0.6871901590791013
Epoch: 96 | Iteration number: [1450/4518] 32% | Training loss: 0.6871885346133133
Epoch: 96 | Iteration number: [1460/4518] 32% | Training loss: 0.6871800162204325
Epoch: 96 | Iteration number: [1470/4518] 32% | Training loss: 0.6871789503259723
Epoch: 96 | Iteration number: [1480/4518] 32% | Training loss: 0.6871748362844055
Epoch: 96 | Iteration number: [1490/4518] 32% | Training loss: 0.687166709547875
Epoch: 96 | Iteration number: [1500/4518] 33% | Training loss: 0.6871569525798161
Epoch: 96 | Iteration number: [1510/4518] 33% | Training loss: 0.6871549289352846
Epoch: 96 | Iteration number: [1520/4518] 33% | Training loss: 0.6871506651373286
Epoch: 96 | Iteration number: [1530/4518] 33% | Training loss: 0.6871556169456906
Epoch: 96 | Iteration number: [1540/4518] 34% | Training loss: 0.6871539994106665
Epoch: 96 | Iteration number: [1550/4518] 34% | Training loss: 0.6871541271286626
Epoch: 96 | Iteration number: [1560/4518] 34% | Training loss: 0.6871500383967009
Epoch: 96 | Iteration number: [1570/4518] 34% | Training loss: 0.6871458042958739
Epoch: 96 | Iteration number: [1580/4518] 34% | Training loss: 0.6871377142924296
Epoch: 96 | Iteration number: [1590/4518] 35% | Training loss: 0.6871247968583737
Epoch: 96 | Iteration number: [1600/4518] 35% | Training loss: 0.6871256704628468
Epoch: 96 | Iteration number: [1610/4518] 35% | Training loss: 0.6871305948458843
Epoch: 96 | Iteration number: [1620/4518] 35% | Training loss: 0.6871300096865054
Epoch: 96 | Iteration number: [1630/4518] 36% | Training loss: 0.6871304204858886
Epoch: 96 | Iteration number: [1640/4518] 36% | Training loss: 0.6871217539397682
Epoch: 96 | Iteration number: [1650/4518] 36% | Training loss: 0.6871242141001153
Epoch: 96 | Iteration number: [1660/4518] 36% | Training loss: 0.6871207965066634
Epoch: 96 | Iteration number: [1670/4518] 36% | Training loss: 0.6871252115972027
Epoch: 96 | Iteration number: [1680/4518] 37% | Training loss: 0.6871228991519838
Epoch: 96 | Iteration number: [1690/4518] 37% | Training loss: 0.6871242972873371
Epoch: 96 | Iteration number: [1700/4518] 37% | Training loss: 0.6871257593000636
Epoch: 96 | Iteration number: [1710/4518] 37% | Training loss: 0.6871260998193284
Epoch: 96 | Iteration number: [1720/4518] 38% | Training loss: 0.687126393754815
Epoch: 96 | Iteration number: [1730/4518] 38% | Training loss: 0.6871151827663355
Epoch: 96 | Iteration number: [1740/4518] 38% | Training loss: 0.6871132918815503
Epoch: 96 | Iteration number: [1750/4518] 38% | Training loss: 0.687112140927996
Epoch: 96 | Iteration number: [1760/4518] 38% | Training loss: 0.6871168192137371
Epoch: 96 | Iteration number: [1770/4518] 39% | Training loss: 0.6871149337897866
Epoch: 96 | Iteration number: [1780/4518] 39% | Training loss: 0.6871132295453146
Epoch: 96 | Iteration number: [1790/4518] 39% | Training loss: 0.687111493029408
Epoch: 96 | Iteration number: [1800/4518] 39% | Training loss: 0.6871112673481305
Epoch: 96 | Iteration number: [1810/4518] 40% | Training loss: 0.6871116550587817
Epoch: 96 | Iteration number: [1820/4518] 40% | Training loss: 0.6870979855676274
Epoch: 96 | Iteration number: [1830/4518] 40% | Training loss: 0.687085167208656
Epoch: 96 | Iteration number: [1840/4518] 40% | Training loss: 0.6870874992855217
Epoch: 96 | Iteration number: [1850/4518] 40% | Training loss: 0.68707689217619
Epoch: 96 | Iteration number: [1860/4518] 41% | Training loss: 0.6870770313726958
Epoch: 96 | Iteration number: [1870/4518] 41% | Training loss: 0.6870789588772677
Epoch: 96 | Iteration number: [1880/4518] 41% | Training loss: 0.6870723894618928
Epoch: 96 | Iteration number: [1890/4518] 41% | Training loss: 0.6870692782616489
Epoch: 96 | Iteration number: [1900/4518] 42% | Training loss: 0.6870669527743992
Epoch: 96 | Iteration number: [1910/4518] 42% | Training loss: 0.6870617779761709
Epoch: 96 | Iteration number: [1920/4518] 42% | Training loss: 0.6870672561849157
Epoch: 96 | Iteration number: [1930/4518] 42% | Training loss: 0.6870697030440513
Epoch: 96 | Iteration number: [1940/4518] 42% | Training loss: 0.687060238190533
Epoch: 96 | Iteration number: [1950/4518] 43% | Training loss: 0.687053992778827
Epoch: 96 | Iteration number: [1960/4518] 43% | Training loss: 0.6870545807845738
Epoch: 96 | Iteration number: [1970/4518] 43% | Training loss: 0.6870518148853089
Epoch: 96 | Iteration number: [1980/4518] 43% | Training loss: 0.6870587463330741
Epoch: 96 | Iteration number: [1990/4518] 44% | Training loss: 0.687054266492326
Epoch: 96 | Iteration number: [2000/4518] 44% | Training loss: 0.6870568411350251
Epoch: 96 | Iteration number: [2010/4518] 44% | Training loss: 0.6870565121446676
Epoch: 96 | Iteration number: [2020/4518] 44% | Training loss: 0.6870603523041943
Epoch: 96 | Iteration number: [2030/4518] 44% | Training loss: 0.6870595175938066
Epoch: 96 | Iteration number: [2040/4518] 45% | Training loss: 0.6870568605906823
Epoch: 96 | Iteration number: [2050/4518] 45% | Training loss: 0.6870516255134489
Epoch: 96 | Iteration number: [2060/4518] 45% | Training loss: 0.6870538279558849
Epoch: 96 | Iteration number: [2070/4518] 45% | Training loss: 0.6870484526606574
Epoch: 96 | Iteration number: [2080/4518] 46% | Training loss: 0.6870505890594079
Epoch: 96 | Iteration number: [2090/4518] 46% | Training loss: 0.6870456680726776
Epoch: 96 | Iteration number: [2100/4518] 46% | Training loss: 0.6870444090309598
Epoch: 96 | Iteration number: [2110/4518] 46% | Training loss: 0.6870482932899801
Epoch: 96 | Iteration number: [2120/4518] 46% | Training loss: 0.6870465569057554
Epoch: 96 | Iteration number: [2130/4518] 47% | Training loss: 0.6870451033395221
Epoch: 96 | Iteration number: [2140/4518] 47% | Training loss: 0.6870452530194666
Epoch: 96 | Iteration number: [2150/4518] 47% | Training loss: 0.6870400586793589
Epoch: 96 | Iteration number: [2160/4518] 47% | Training loss: 0.6870394810206361
Epoch: 96 | Iteration number: [2170/4518] 48% | Training loss: 0.6870348788900859
Epoch: 96 | Iteration number: [2180/4518] 48% | Training loss: 0.6870339652267071
Epoch: 96 | Iteration number: [2190/4518] 48% | Training loss: 0.6870356361343436
Epoch: 96 | Iteration number: [2200/4518] 48% | Training loss: 0.6870345529913903
Epoch: 96 | Iteration number: [2210/4518] 48% | Training loss: 0.6870270527326143
Epoch: 96 | Iteration number: [2220/4518] 49% | Training loss: 0.6870291918516159
Epoch: 96 | Iteration number: [2230/4518] 49% | Training loss: 0.6870271993859467
Epoch: 96 | Iteration number: [2240/4518] 49% | Training loss: 0.6870262290750231
Epoch: 96 | Iteration number: [2250/4518] 49% | Training loss: 0.6870190700689952
Epoch: 96 | Iteration number: [2260/4518] 50% | Training loss: 0.6870213187637583
Epoch: 96 | Iteration number: [2270/4518] 50% | Training loss: 0.6870189829807449
Epoch: 96 | Iteration number: [2280/4518] 50% | Training loss: 0.687013849433054
Epoch: 96 | Iteration number: [2290/4518] 50% | Training loss: 0.6870166046650649
Epoch: 96 | Iteration number: [2300/4518] 50% | Training loss: 0.6870168117595755
Epoch: 96 | Iteration number: [2310/4518] 51% | Training loss: 0.6870118565889664
Epoch: 96 | Iteration number: [2320/4518] 51% | Training loss: 0.6870150276556097
Epoch: 96 | Iteration number: [2330/4518] 51% | Training loss: 0.6870117649755765
Epoch: 96 | Iteration number: [2340/4518] 51% | Training loss: 0.6870120194223192
Epoch: 96 | Iteration number: [2350/4518] 52% | Training loss: 0.6870059885116334
Epoch: 96 | Iteration number: [2360/4518] 52% | Training loss: 0.6870034557277873
Epoch: 96 | Iteration number: [2370/4518] 52% | Training loss: 0.6870072660818382
Epoch: 96 | Iteration number: [2380/4518] 52% | Training loss: 0.6870040085135388
Epoch: 96 | Iteration number: [2390/4518] 52% | Training loss: 0.6869951052146975
Epoch: 96 | Iteration number: [2400/4518] 53% | Training loss: 0.6869941914826632
Epoch: 96 | Iteration number: [2410/4518] 53% | Training loss: 0.6869942350011643
Epoch: 96 | Iteration number: [2420/4518] 53% | Training loss: 0.6869908940939864
Epoch: 96 | Iteration number: [2430/4518] 53% | Training loss: 0.6869908345579611
Epoch: 96 | Iteration number: [2440/4518] 54% | Training loss: 0.6869859350753612
Epoch: 96 | Iteration number: [2450/4518] 54% | Training loss: 0.686983961548124
Epoch: 96 | Iteration number: [2460/4518] 54% | Training loss: 0.6869782533587478
Epoch: 96 | Iteration number: [2470/4518] 54% | Training loss: 0.6869820911633341
Epoch: 96 | Iteration number: [2480/4518] 54% | Training loss: 0.6869852042726932
Epoch: 96 | Iteration number: [2490/4518] 55% | Training loss: 0.6869814468196118
Epoch: 96 | Iteration number: [2500/4518] 55% | Training loss: 0.6869771263122558
Epoch: 96 | Iteration number: [2510/4518] 55% | Training loss: 0.6869739207376047
Epoch: 96 | Iteration number: [2520/4518] 55% | Training loss: 0.6869713006511567
Epoch: 96 | Iteration number: [2530/4518] 55% | Training loss: 0.6869680841920875
Epoch: 96 | Iteration number: [2540/4518] 56% | Training loss: 0.6869673535110443
Epoch: 96 | Iteration number: [2550/4518] 56% | Training loss: 0.6869674589820937
Epoch: 96 | Iteration number: [2560/4518] 56% | Training loss: 0.6869697000132874
Epoch: 96 | Iteration number: [2570/4518] 56% | Training loss: 0.6869633465193589
Epoch: 96 | Iteration number: [2580/4518] 57% | Training loss: 0.6869653009629064
Epoch: 96 | Iteration number: [2590/4518] 57% | Training loss: 0.6869652908050876
Epoch: 96 | Iteration number: [2600/4518] 57% | Training loss: 0.6869624470747434
Epoch: 96 | Iteration number: [2610/4518] 57% | Training loss: 0.6869607063088837
Epoch: 96 | Iteration number: [2620/4518] 57% | Training loss: 0.6869629069594027
Epoch: 96 | Iteration number: [2630/4518] 58% | Training loss: 0.6869606116878669
Epoch: 96 | Iteration number: [2640/4518] 58% | Training loss: 0.6869577549623721
Epoch: 96 | Iteration number: [2650/4518] 58% | Training loss: 0.6869524621288732
Epoch: 96 | Iteration number: [2660/4518] 58% | Training loss: 0.6869489488296939
Epoch: 96 | Iteration number: [2670/4518] 59% | Training loss: 0.6869490631733941
Epoch: 96 | Iteration number: [2680/4518] 59% | Training loss: 0.68695054992811
Epoch: 96 | Iteration number: [2690/4518] 59% | Training loss: 0.6869493057958256
Epoch: 96 | Iteration number: [2700/4518] 59% | Training loss: 0.6869455875511523
Epoch: 96 | Iteration number: [2710/4518] 59% | Training loss: 0.6869491153757511
Epoch: 96 | Iteration number: [2720/4518] 60% | Training loss: 0.6869454189258464
Epoch: 96 | Iteration number: [2730/4518] 60% | Training loss: 0.6869475132161444
Epoch: 96 | Iteration number: [2740/4518] 60% | Training loss: 0.6869431139996452
Epoch: 96 | Iteration number: [2750/4518] 60% | Training loss: 0.6869394117485393
Epoch: 96 | Iteration number: [2760/4518] 61% | Training loss: 0.6869431496962257
Epoch: 96 | Iteration number: [2770/4518] 61% | Training loss: 0.6869430679061352
Epoch: 96 | Iteration number: [2780/4518] 61% | Training loss: 0.6869413937596108
Epoch: 96 | Iteration number: [2790/4518] 61% | Training loss: 0.6869409572479973
Epoch: 96 | Iteration number: [2800/4518] 61% | Training loss: 0.6869381138043744
Epoch: 96 | Iteration number: [2810/4518] 62% | Training loss: 0.6869439560323424
Epoch: 96 | Iteration number: [2820/4518] 62% | Training loss: 0.6869421012646763
Epoch: 96 | Iteration number: [2830/4518] 62% | Training loss: 0.6869428147696774
Epoch: 96 | Iteration number: [2840/4518] 62% | Training loss: 0.6869449603095861
Epoch: 96 | Iteration number: [2850/4518] 63% | Training loss: 0.6869418086085404
Epoch: 96 | Iteration number: [2860/4518] 63% | Training loss: 0.6869454519315199
Epoch: 96 | Iteration number: [2870/4518] 63% | Training loss: 0.6869405502641658
Epoch: 96 | Iteration number: [2880/4518] 63% | Training loss: 0.6869396615152558
Epoch: 96 | Iteration number: [2890/4518] 63% | Training loss: 0.6869395966554596
Epoch: 96 | Iteration number: [2900/4518] 64% | Training loss: 0.6869370555877685
Epoch: 96 | Iteration number: [2910/4518] 64% | Training loss: 0.6869321505228678
Epoch: 96 | Iteration number: [2920/4518] 64% | Training loss: 0.6869339034369547
Epoch: 96 | Iteration number: [2930/4518] 64% | Training loss: 0.6869309746974971
Epoch: 96 | Iteration number: [2940/4518] 65% | Training loss: 0.6869345595439275
Epoch: 96 | Iteration number: [2950/4518] 65% | Training loss: 0.686932281316337
Epoch: 96 | Iteration number: [2960/4518] 65% | Training loss: 0.6869319167290185
Epoch: 96 | Iteration number: [2970/4518] 65% | Training loss: 0.6869310375014539
Epoch: 96 | Iteration number: [2980/4518] 65% | Training loss: 0.6869309133531263
Epoch: 96 | Iteration number: [2990/4518] 66% | Training loss: 0.6869336789667009
Epoch: 96 | Iteration number: [3000/4518] 66% | Training loss: 0.6869348383148511
Epoch: 96 | Iteration number: [3010/4518] 66% | Training loss: 0.6869338975198245
Epoch: 96 | Iteration number: [3020/4518] 66% | Training loss: 0.6869338089661883
Epoch: 96 | Iteration number: [3030/4518] 67% | Training loss: 0.6869331337044341
Epoch: 96 | Iteration number: [3040/4518] 67% | Training loss: 0.6869307277233977
Epoch: 96 | Iteration number: [3050/4518] 67% | Training loss: 0.6869311618414081
Epoch: 96 | Iteration number: [3060/4518] 67% | Training loss: 0.6869298382132661
Epoch: 96 | Iteration number: [3070/4518] 67% | Training loss: 0.6869305498825222
Epoch: 96 | Iteration number: [3080/4518] 68% | Training loss: 0.6869320230244043
Epoch: 96 | Iteration number: [3090/4518] 68% | Training loss: 0.6869282879297016
Epoch: 96 | Iteration number: [3100/4518] 68% | Training loss: 0.6869294282121043
Epoch: 96 | Iteration number: [3110/4518] 68% | Training loss: 0.6869305597240902
Epoch: 96 | Iteration number: [3120/4518] 69% | Training loss: 0.6869264586231647
Epoch: 96 | Iteration number: [3130/4518] 69% | Training loss: 0.6869233947592421
Epoch: 96 | Iteration number: [3140/4518] 69% | Training loss: 0.6869168301107018
Epoch: 96 | Iteration number: [3150/4518] 69% | Training loss: 0.6869153075937241
Epoch: 96 | Iteration number: [3160/4518] 69% | Training loss: 0.6869168706898447
Epoch: 96 | Iteration number: [3170/4518] 70% | Training loss: 0.686918010057335
Epoch: 96 | Iteration number: [3180/4518] 70% | Training loss: 0.6869188000945925
Epoch: 96 | Iteration number: [3190/4518] 70% | Training loss: 0.6869209131477021
Epoch: 96 | Iteration number: [3200/4518] 70% | Training loss: 0.6869238461181522
Epoch: 96 | Iteration number: [3210/4518] 71% | Training loss: 0.6869232612792576
Epoch: 96 | Iteration number: [3220/4518] 71% | Training loss: 0.6869248148077023
Epoch: 96 | Iteration number: [3230/4518] 71% | Training loss: 0.6869250090498673
Epoch: 96 | Iteration number: [3240/4518] 71% | Training loss: 0.6869247794887166
Epoch: 96 | Iteration number: [3250/4518] 71% | Training loss: 0.6869283091655144
Epoch: 96 | Iteration number: [3260/4518] 72% | Training loss: 0.6869236396317102
Epoch: 96 | Iteration number: [3270/4518] 72% | Training loss: 0.6869237040707824
Epoch: 96 | Iteration number: [3280/4518] 72% | Training loss: 0.6869185233443249
Epoch: 96 | Iteration number: [3290/4518] 72% | Training loss: 0.6869172437031581
Epoch: 96 | Iteration number: [3300/4518] 73% | Training loss: 0.686919838587443
Epoch: 96 | Iteration number: [3310/4518] 73% | Training loss: 0.6869256539287164
Epoch: 96 | Iteration number: [3320/4518] 73% | Training loss: 0.6869260513279811
Epoch: 96 | Iteration number: [3330/4518] 73% | Training loss: 0.6869271253859317
Epoch: 96 | Iteration number: [3340/4518] 73% | Training loss: 0.6869257805411687
Epoch: 96 | Iteration number: [3350/4518] 74% | Training loss: 0.6869272694480953
Epoch: 96 | Iteration number: [3360/4518] 74% | Training loss: 0.6869295489397786
Epoch: 96 | Iteration number: [3370/4518] 74% | Training loss: 0.6869274196532784
Epoch: 96 | Iteration number: [3380/4518] 74% | Training loss: 0.6869287486612444
Epoch: 96 | Iteration number: [3390/4518] 75% | Training loss: 0.6869306437912944
Epoch: 96 | Iteration number: [3400/4518] 75% | Training loss: 0.6869318542936269
Epoch: 96 | Iteration number: [3410/4518] 75% | Training loss: 0.6869339575515814
Epoch: 96 | Iteration number: [3420/4518] 75% | Training loss: 0.6869328078470732
Epoch: 96 | Iteration number: [3430/4518] 75% | Training loss: 0.686933948938075
Epoch: 96 | Iteration number: [3440/4518] 76% | Training loss: 0.686934824131949
Epoch: 96 | Iteration number: [3450/4518] 76% | Training loss: 0.6869336231722348
Epoch: 96 | Iteration number: [3460/4518] 76% | Training loss: 0.6869318667691567
Epoch: 96 | Iteration number: [3470/4518] 76% | Training loss: 0.6869289811303362
Epoch: 96 | Iteration number: [3480/4518] 77% | Training loss: 0.6869295514006725
Epoch: 96 | Iteration number: [3490/4518] 77% | Training loss: 0.6869290869522915
Epoch: 96 | Iteration number: [3500/4518] 77% | Training loss: 0.6869295163835798
Epoch: 96 | Iteration number: [3510/4518] 77% | Training loss: 0.6869307020450929
Epoch: 96 | Iteration number: [3520/4518] 77% | Training loss: 0.6869341817599806
Epoch: 96 | Iteration number: [3530/4518] 78% | Training loss: 0.6869364773247802
Epoch: 96 | Iteration number: [3540/4518] 78% | Training loss: 0.6869339000033794
Epoch: 96 | Iteration number: [3550/4518] 78% | Training loss: 0.6869355149168364
Epoch: 96 | Iteration number: [3560/4518] 78% | Training loss: 0.6869370801395245
Epoch: 96 | Iteration number: [3570/4518] 79% | Training loss: 0.6869391760238412
Epoch: 96 | Iteration number: [3580/4518] 79% | Training loss: 0.6869398668158654
Epoch: 96 | Iteration number: [3590/4518] 79% | Training loss: 0.6869356775350225
Epoch: 96 | Iteration number: [3600/4518] 79% | Training loss: 0.6869361019134521
Epoch: 96 | Iteration number: [3610/4518] 79% | Training loss: 0.6869331807641111
Epoch: 96 | Iteration number: [3620/4518] 80% | Training loss: 0.6869335552605477
Epoch: 96 | Iteration number: [3630/4518] 80% | Training loss: 0.6869326253239445
Epoch: 96 | Iteration number: [3640/4518] 80% | Training loss: 0.6869324706576683
Epoch: 96 | Iteration number: [3650/4518] 80% | Training loss: 0.6869351605519857
Epoch: 96 | Iteration number: [3660/4518] 81% | Training loss: 0.6869342887825002
Epoch: 96 | Iteration number: [3670/4518] 81% | Training loss: 0.6869377482652015
Epoch: 96 | Iteration number: [3680/4518] 81% | Training loss: 0.6869336978896804
Epoch: 96 | Iteration number: [3690/4518] 81% | Training loss: 0.6869292871900368
Epoch: 96 | Iteration number: [3700/4518] 81% | Training loss: 0.6869310113546011
Epoch: 96 | Iteration number: [3710/4518] 82% | Training loss: 0.6869283519825845
Epoch: 96 | Iteration number: [3720/4518] 82% | Training loss: 0.6869238228567185
Epoch: 96 | Iteration number: [3730/4518] 82% | Training loss: 0.6869252315475218
Epoch: 96 | Iteration number: [3740/4518] 82% | Training loss: 0.6869251802324611
Epoch: 96 | Iteration number: [3750/4518] 83% | Training loss: 0.6869246354262034
Epoch: 96 | Iteration number: [3760/4518] 83% | Training loss: 0.686925489217677
Epoch: 96 | Iteration number: [3770/4518] 83% | Training loss: 0.6869226482724005
Epoch: 96 | Iteration number: [3780/4518] 83% | Training loss: 0.6869211538128122
Epoch: 96 | Iteration number: [3790/4518] 83% | Training loss: 0.686918801037806
Epoch: 96 | Iteration number: [3800/4518] 84% | Training loss: 0.6869204837397526
Epoch: 96 | Iteration number: [3810/4518] 84% | Training loss: 0.6869220863177081
Epoch: 96 | Iteration number: [3820/4518] 84% | Training loss: 0.6869253011118055
Epoch: 96 | Iteration number: [3830/4518] 84% | Training loss: 0.6869283939154901
Epoch: 96 | Iteration number: [3840/4518] 84% | Training loss: 0.6869294216235479
Epoch: 96 | Iteration number: [3850/4518] 85% | Training loss: 0.686928651967606
Epoch: 96 | Iteration number: [3860/4518] 85% | Training loss: 0.686930569342381
Epoch: 96 | Iteration number: [3870/4518] 85% | Training loss: 0.6869320417713441
Epoch: 96 | Iteration number: [3880/4518] 85% | Training loss: 0.6869346565038887
Epoch: 96 | Iteration number: [3890/4518] 86% | Training loss: 0.686933996116594
Epoch: 96 | Iteration number: [3900/4518] 86% | Training loss: 0.6869345251413492
Epoch: 96 | Iteration number: [3910/4518] 86% | Training loss: 0.6869340967491765
Epoch: 96 | Iteration number: [3920/4518] 86% | Training loss: 0.6869333629097257
Epoch: 96 | Iteration number: [3930/4518] 86% | Training loss: 0.6869303308370459
Epoch: 96 | Iteration number: [3940/4518] 87% | Training loss: 0.6869281171844696
Epoch: 96 | Iteration number: [3950/4518] 87% | Training loss: 0.6869298009329204
Epoch: 96 | Iteration number: [3960/4518] 87% | Training loss: 0.686930868330628
Epoch: 96 | Iteration number: [3970/4518] 87% | Training loss: 0.6869284435693803
Epoch: 96 | Iteration number: [3980/4518] 88% | Training loss: 0.6869288123881997
Epoch: 96 | Iteration number: [3990/4518] 88% | Training loss: 0.6869309108358875
Epoch: 96 | Iteration number: [4000/4518] 88% | Training loss: 0.6869283165037632
Epoch: 96 | Iteration number: [4010/4518] 88% | Training loss: 0.6869275009097007
Epoch: 96 | Iteration number: [4020/4518] 88% | Training loss: 0.6869255939229804
Epoch: 96 | Iteration number: [4030/4518] 89% | Training loss: 0.6869256687962979
Epoch: 96 | Iteration number: [4040/4518] 89% | Training loss: 0.686927633548137
Epoch: 96 | Iteration number: [4050/4518] 89% | Training loss: 0.6869274855690238
Epoch: 96 | Iteration number: [4060/4518] 89% | Training loss: 0.6869283693177359
Epoch: 96 | Iteration number: [4070/4518] 90% | Training loss: 0.686927194706638
Epoch: 96 | Iteration number: [4080/4518] 90% | Training loss: 0.6869281272531724
Epoch: 96 | Iteration number: [4090/4518] 90% | Training loss: 0.6869278606109339
Epoch: 96 | Iteration number: [4100/4518] 90% | Training loss: 0.6869286333060846
Epoch: 96 | Iteration number: [4110/4518] 90% | Training loss: 0.6869294648042851
Epoch: 96 | Iteration number: [4120/4518] 91% | Training loss: 0.6869298340481462
Epoch: 96 | Iteration number: [4130/4518] 91% | Training loss: 0.6869325264602827
Epoch: 96 | Iteration number: [4140/4518] 91% | Training loss: 0.6869347817943868
Epoch: 96 | Iteration number: [4150/4518] 91% | Training loss: 0.6869364626292723
Epoch: 96 | Iteration number: [4160/4518] 92% | Training loss: 0.6869348115932483
Epoch: 96 | Iteration number: [4170/4518] 92% | Training loss: 0.6869355854370611
Epoch: 96 | Iteration number: [4180/4518] 92% | Training loss: 0.6869344633161737
Epoch: 96 | Iteration number: [4190/4518] 92% | Training loss: 0.6869307639775242
Epoch: 96 | Iteration number: [4200/4518] 92% | Training loss: 0.6869326733833268
Epoch: 96 | Iteration number: [4210/4518] 93% | Training loss: 0.6869350373320229
Epoch: 96 | Iteration number: [4220/4518] 93% | Training loss: 0.6869324644312474
Epoch: 96 | Iteration number: [4230/4518] 93% | Training loss: 0.6869305081119492
Epoch: 96 | Iteration number: [4240/4518] 93% | Training loss: 0.6869316828560155
Epoch: 96 | Iteration number: [4250/4518] 94% | Training loss: 0.6869322290420532
Epoch: 96 | Iteration number: [4260/4518] 94% | Training loss: 0.6869333917825995
Epoch: 96 | Iteration number: [4270/4518] 94% | Training loss: 0.6869332981472551
Epoch: 96 | Iteration number: [4280/4518] 94% | Training loss: 0.6869308426001361
Epoch: 96 | Iteration number: [4290/4518] 94% | Training loss: 0.68693024870399
Epoch: 96 | Iteration number: [4300/4518] 95% | Training loss: 0.6869301167061163
Epoch: 96 | Iteration number: [4310/4518] 95% | Training loss: 0.6869312687567382
Epoch: 96 | Iteration number: [4320/4518] 95% | Training loss: 0.6869323884861337
Epoch: 96 | Iteration number: [4330/4518] 95% | Training loss: 0.6869336332102021
Epoch: 96 | Iteration number: [4340/4518] 96% | Training loss: 0.6869307620871452
Epoch: 96 | Iteration number: [4350/4518] 96% | Training loss: 0.6869262524582874
Epoch: 96 | Iteration number: [4360/4518] 96% | Training loss: 0.6869227651745902
Epoch: 96 | Iteration number: [4370/4518] 96% | Training loss: 0.6869235580927721
Epoch: 96 | Iteration number: [4380/4518] 96% | Training loss: 0.6869239440111264
Epoch: 96 | Iteration number: [4390/4518] 97% | Training loss: 0.6869253296922714
Epoch: 96 | Iteration number: [4400/4518] 97% | Training loss: 0.6869251214780591
Epoch: 96 | Iteration number: [4410/4518] 97% | Training loss: 0.686925429470685
Epoch: 96 | Iteration number: [4420/4518] 97% | Training loss: 0.6869242766728768
Epoch: 96 | Iteration number: [4430/4518] 98% | Training loss: 0.6869211653554412
Epoch: 96 | Iteration number: [4440/4518] 98% | Training loss: 0.6869184841712316
Epoch: 96 | Iteration number: [4450/4518] 98% | Training loss: 0.6869154094176346
Epoch: 96 | Iteration number: [4460/4518] 98% | Training loss: 0.6869170824241211
Epoch: 96 | Iteration number: [4470/4518] 98% | Training loss: 0.6869153458266717
Epoch: 96 | Iteration number: [4480/4518] 99% | Training loss: 0.6869125080294907
Epoch: 96 | Iteration number: [4490/4518] 99% | Training loss: 0.686909910366105
Epoch: 96 | Iteration number: [4500/4518] 99% | Training loss: 0.686909714712037
Epoch: 96 | Iteration number: [4510/4518] 99% | Training loss: 0.6869073567131406

 End of epoch: 96 | Train Loss: 0.6867547443003821 | Training Time: 641 

 End of epoch: 96 | Eval Loss: 0.68991369982155 | Evaluating Time: 17 
Epoch: 97 | Iteration number: [10/4518] 0% | Training loss: 0.75622438788414
Epoch: 97 | Iteration number: [20/4518] 0% | Training loss: 0.7216083198785782
Epoch: 97 | Iteration number: [30/4518] 0% | Training loss: 0.7097965478897095
Epoch: 97 | Iteration number: [40/4518] 0% | Training loss: 0.703949548304081
Epoch: 97 | Iteration number: [50/4518] 1% | Training loss: 0.7003857398033142
Epoch: 97 | Iteration number: [60/4518] 1% | Training loss: 0.6981069962183635
Epoch: 97 | Iteration number: [70/4518] 1% | Training loss: 0.6964289699281965
Epoch: 97 | Iteration number: [80/4518] 1% | Training loss: 0.6951830290257931
Epoch: 97 | Iteration number: [90/4518] 1% | Training loss: 0.6942381819089254
Epoch: 97 | Iteration number: [100/4518] 2% | Training loss: 0.6935300505161286
Epoch: 97 | Iteration number: [110/4518] 2% | Training loss: 0.6928888304667039
Epoch: 97 | Iteration number: [120/4518] 2% | Training loss: 0.6923799410462379
Epoch: 97 | Iteration number: [130/4518] 2% | Training loss: 0.6918933134812575
Epoch: 97 | Iteration number: [140/4518] 3% | Training loss: 0.6915793567895889
Epoch: 97 | Iteration number: [150/4518] 3% | Training loss: 0.6913055189450582
Epoch: 97 | Iteration number: [160/4518] 3% | Training loss: 0.6911376006901264
Epoch: 97 | Iteration number: [170/4518] 3% | Training loss: 0.6907995756934671
Epoch: 97 | Iteration number: [180/4518] 3% | Training loss: 0.6905990531047185
Epoch: 97 | Iteration number: [190/4518] 4% | Training loss: 0.6903874864703731
Epoch: 97 | Iteration number: [200/4518] 4% | Training loss: 0.6901793074607849
Epoch: 97 | Iteration number: [210/4518] 4% | Training loss: 0.6899408383028848
Epoch: 97 | Iteration number: [220/4518] 4% | Training loss: 0.6898269076238979
Epoch: 97 | Iteration number: [230/4518] 5% | Training loss: 0.6897067116654437
Epoch: 97 | Iteration number: [240/4518] 5% | Training loss: 0.6895726129412652
Epoch: 97 | Iteration number: [250/4518] 5% | Training loss: 0.6894154064655303
Epoch: 97 | Iteration number: [260/4518] 5% | Training loss: 0.6893135799811436
Epoch: 97 | Iteration number: [270/4518] 5% | Training loss: 0.689220533768336
Epoch: 97 | Iteration number: [280/4518] 6% | Training loss: 0.6890950341309819
Epoch: 97 | Iteration number: [290/4518] 6% | Training loss: 0.6890382398819102
Epoch: 97 | Iteration number: [300/4518] 6% | Training loss: 0.6889919543266296
Epoch: 97 | Iteration number: [310/4518] 6% | Training loss: 0.6889251207151721
Epoch: 97 | Iteration number: [320/4518] 7% | Training loss: 0.6888410434126854
Epoch: 97 | Iteration number: [330/4518] 7% | Training loss: 0.6887946408806425
Epoch: 97 | Iteration number: [340/4518] 7% | Training loss: 0.6887208444230697
Epoch: 97 | Iteration number: [350/4518] 7% | Training loss: 0.6886935523578099
Epoch: 97 | Iteration number: [360/4518] 7% | Training loss: 0.6886534045139948
Epoch: 97 | Iteration number: [370/4518] 8% | Training loss: 0.6885661651959291
Epoch: 97 | Iteration number: [380/4518] 8% | Training loss: 0.6885450314534338
Epoch: 97 | Iteration number: [390/4518] 8% | Training loss: 0.6885175610199953
Epoch: 97 | Iteration number: [400/4518] 8% | Training loss: 0.6884973174333573
Epoch: 97 | Iteration number: [410/4518] 9% | Training loss: 0.6884506629734505
Epoch: 97 | Iteration number: [420/4518] 9% | Training loss: 0.688419601605052
Epoch: 97 | Iteration number: [430/4518] 9% | Training loss: 0.688367344612299
Epoch: 97 | Iteration number: [440/4518] 9% | Training loss: 0.6883325565945019
Epoch: 97 | Iteration number: [450/4518] 9% | Training loss: 0.6882916792233785
Epoch: 97 | Iteration number: [460/4518] 10% | Training loss: 0.6882302330887836
Epoch: 97 | Iteration number: [470/4518] 10% | Training loss: 0.6882000048109825
Epoch: 97 | Iteration number: [480/4518] 10% | Training loss: 0.6881628040224314
Epoch: 97 | Iteration number: [490/4518] 10% | Training loss: 0.6881329139884638
Epoch: 97 | Iteration number: [500/4518] 11% | Training loss: 0.6880792859792709
Epoch: 97 | Iteration number: [510/4518] 11% | Training loss: 0.6880638540959826
Epoch: 97 | Iteration number: [520/4518] 11% | Training loss: 0.6880430310964585
Epoch: 97 | Iteration number: [530/4518] 11% | Training loss: 0.6880062604850193
Epoch: 97 | Iteration number: [540/4518] 11% | Training loss: 0.6879924226690222
Epoch: 97 | Iteration number: [550/4518] 12% | Training loss: 0.6879629888317802
Epoch: 97 | Iteration number: [560/4518] 12% | Training loss: 0.687934559477227
Epoch: 97 | Iteration number: [570/4518] 12% | Training loss: 0.687896951771619
Epoch: 97 | Iteration number: [580/4518] 12% | Training loss: 0.6878870165553587
Epoch: 97 | Iteration number: [590/4518] 13% | Training loss: 0.6878746011499631
Epoch: 97 | Iteration number: [600/4518] 13% | Training loss: 0.6878545945882797
Epoch: 97 | Iteration number: [610/4518] 13% | Training loss: 0.6878470919171318
Epoch: 97 | Iteration number: [620/4518] 13% | Training loss: 0.6878062948103874
Epoch: 97 | Iteration number: [630/4518] 13% | Training loss: 0.6877978690086849
Epoch: 97 | Iteration number: [640/4518] 14% | Training loss: 0.6877759917639196
Epoch: 97 | Iteration number: [650/4518] 14% | Training loss: 0.6877573125178997
Epoch: 97 | Iteration number: [660/4518] 14% | Training loss: 0.6877666867140567
Epoch: 97 | Iteration number: [670/4518] 14% | Training loss: 0.6877546196553245
Epoch: 97 | Iteration number: [680/4518] 15% | Training loss: 0.6877462880576358
Epoch: 97 | Iteration number: [690/4518] 15% | Training loss: 0.6877331954845484
Epoch: 97 | Iteration number: [700/4518] 15% | Training loss: 0.6877240930284773
Epoch: 97 | Iteration number: [710/4518] 15% | Training loss: 0.6877013300506162
Epoch: 97 | Iteration number: [720/4518] 15% | Training loss: 0.6876755742563142
Epoch: 97 | Iteration number: [730/4518] 16% | Training loss: 0.687654909450714
Epoch: 97 | Iteration number: [740/4518] 16% | Training loss: 0.6876460808354455
Epoch: 97 | Iteration number: [750/4518] 16% | Training loss: 0.6876315390268961
Epoch: 97 | Iteration number: [760/4518] 16% | Training loss: 0.6876221631702624
Epoch: 97 | Iteration number: [770/4518] 17% | Training loss: 0.6876121303477845
Epoch: 97 | Iteration number: [780/4518] 17% | Training loss: 0.6875935237377118
Epoch: 97 | Iteration number: [790/4518] 17% | Training loss: 0.6875820297229139
Epoch: 97 | Iteration number: [800/4518] 17% | Training loss: 0.6875770574808121
Epoch: 97 | Iteration number: [810/4518] 17% | Training loss: 0.6875708839775604
Epoch: 97 | Iteration number: [820/4518] 18% | Training loss: 0.6875616615138402
Epoch: 97 | Iteration number: [830/4518] 18% | Training loss: 0.6875475160328739
Epoch: 97 | Iteration number: [840/4518] 18% | Training loss: 0.6875371085745948
Epoch: 97 | Iteration number: [850/4518] 18% | Training loss: 0.6875274062156678
Epoch: 97 | Iteration number: [860/4518] 19% | Training loss: 0.6875102401472801
Epoch: 97 | Iteration number: [870/4518] 19% | Training loss: 0.6874914396768329
Epoch: 97 | Iteration number: [880/4518] 19% | Training loss: 0.6874800100245259
Epoch: 97 | Iteration number: [890/4518] 19% | Training loss: 0.687472903192713
Epoch: 97 | Iteration number: [900/4518] 19% | Training loss: 0.6874754894442029
Epoch: 97 | Iteration number: [910/4518] 20% | Training loss: 0.6874690961051774
Epoch: 97 | Iteration number: [920/4518] 20% | Training loss: 0.6874641089335732
Epoch: 97 | Iteration number: [930/4518] 20% | Training loss: 0.687474448257877
Epoch: 97 | Iteration number: [940/4518] 20% | Training loss: 0.6874773499813486
Epoch: 97 | Iteration number: [950/4518] 21% | Training loss: 0.6874731993047815
Epoch: 97 | Iteration number: [960/4518] 21% | Training loss: 0.687465101480484
Epoch: 97 | Iteration number: [970/4518] 21% | Training loss: 0.6874747716274459
Epoch: 97 | Iteration number: [980/4518] 21% | Training loss: 0.6874680702783623
Epoch: 97 | Iteration number: [990/4518] 21% | Training loss: 0.6874530277468941
Epoch: 97 | Iteration number: [1000/4518] 22% | Training loss: 0.6874453783631325
Epoch: 97 | Iteration number: [1010/4518] 22% | Training loss: 0.6874383493815318
Epoch: 97 | Iteration number: [1020/4518] 22% | Training loss: 0.6874335916603312
Epoch: 97 | Iteration number: [1030/4518] 22% | Training loss: 0.6874201719622011
Epoch: 97 | Iteration number: [1040/4518] 23% | Training loss: 0.6874133161627329
Epoch: 97 | Iteration number: [1050/4518] 23% | Training loss: 0.6874138071423486
Epoch: 97 | Iteration number: [1060/4518] 23% | Training loss: 0.6874020758664833
Epoch: 97 | Iteration number: [1070/4518] 23% | Training loss: 0.6873810906833577
Epoch: 97 | Iteration number: [1080/4518] 23% | Training loss: 0.6873694651656681
Epoch: 97 | Iteration number: [1090/4518] 24% | Training loss: 0.6873665880719456
Epoch: 97 | Iteration number: [1100/4518] 24% | Training loss: 0.6873601051894102
Epoch: 97 | Iteration number: [1110/4518] 24% | Training loss: 0.6873585565133138
Epoch: 97 | Iteration number: [1120/4518] 24% | Training loss: 0.6873507755675486
Epoch: 97 | Iteration number: [1130/4518] 25% | Training loss: 0.6873456326733648
Epoch: 97 | Iteration number: [1140/4518] 25% | Training loss: 0.6873303800821304
Epoch: 97 | Iteration number: [1150/4518] 25% | Training loss: 0.6873262721559276
Epoch: 97 | Iteration number: [1160/4518] 25% | Training loss: 0.6873178709683747
Epoch: 97 | Iteration number: [1170/4518] 25% | Training loss: 0.6873118287477737
Epoch: 97 | Iteration number: [1180/4518] 26% | Training loss: 0.6873134138725572
Epoch: 97 | Iteration number: [1190/4518] 26% | Training loss: 0.6873135438486307
Epoch: 97 | Iteration number: [1200/4518] 26% | Training loss: 0.6873129460712274
Epoch: 97 | Iteration number: [1210/4518] 26% | Training loss: 0.687310444914605
Epoch: 97 | Iteration number: [1220/4518] 27% | Training loss: 0.687302414901921
Epoch: 97 | Iteration number: [1230/4518] 27% | Training loss: 0.6872967077464592
Epoch: 97 | Iteration number: [1240/4518] 27% | Training loss: 0.6872918020813695
Epoch: 97 | Iteration number: [1250/4518] 27% | Training loss: 0.6872776283740998
Epoch: 97 | Iteration number: [1260/4518] 27% | Training loss: 0.6872722421373639
Epoch: 97 | Iteration number: [1270/4518] 28% | Training loss: 0.6872627061183059
Epoch: 97 | Iteration number: [1280/4518] 28% | Training loss: 0.6872546416707337
Epoch: 97 | Iteration number: [1290/4518] 28% | Training loss: 0.6872507281081621
Epoch: 97 | Iteration number: [1300/4518] 28% | Training loss: 0.6872405449702189
Epoch: 97 | Iteration number: [1310/4518] 28% | Training loss: 0.6872371475205167
Epoch: 97 | Iteration number: [1320/4518] 29% | Training loss: 0.6872300604527647
Epoch: 97 | Iteration number: [1330/4518] 29% | Training loss: 0.6872239381747138
Epoch: 97 | Iteration number: [1340/4518] 29% | Training loss: 0.687214797601771
Epoch: 97 | Iteration number: [1350/4518] 29% | Training loss: 0.6872115812478242
Epoch: 97 | Iteration number: [1360/4518] 30% | Training loss: 0.6872129494214759
Epoch: 97 | Iteration number: [1370/4518] 30% | Training loss: 0.6872049337756024
Epoch: 97 | Iteration number: [1380/4518] 30% | Training loss: 0.6872023812670639
Epoch: 97 | Iteration number: [1390/4518] 30% | Training loss: 0.6871983086891311
Epoch: 97 | Iteration number: [1400/4518] 30% | Training loss: 0.6871906208566257
Epoch: 97 | Iteration number: [1410/4518] 31% | Training loss: 0.6871756313540411
Epoch: 97 | Iteration number: [1420/4518] 31% | Training loss: 0.6871622553593676
Epoch: 97 | Iteration number: [1430/4518] 31% | Training loss: 0.6871581448124839
Epoch: 97 | Iteration number: [1440/4518] 31% | Training loss: 0.6871635788844691
Epoch: 97 | Iteration number: [1450/4518] 32% | Training loss: 0.6871587122308797
Epoch: 97 | Iteration number: [1460/4518] 32% | Training loss: 0.6871528599360218
Epoch: 97 | Iteration number: [1470/4518] 32% | Training loss: 0.6871594218169751
Epoch: 97 | Iteration number: [1480/4518] 32% | Training loss: 0.6871558000912538
Epoch: 97 | Iteration number: [1490/4518] 32% | Training loss: 0.6871516502143553
Epoch: 97 | Iteration number: [1500/4518] 33% | Training loss: 0.6871502523422242
Epoch: 97 | Iteration number: [1510/4518] 33% | Training loss: 0.6871457373069612
Epoch: 97 | Iteration number: [1520/4518] 33% | Training loss: 0.6871436125353763
Epoch: 97 | Iteration number: [1530/4518] 33% | Training loss: 0.6871470057107265
Epoch: 97 | Iteration number: [1540/4518] 34% | Training loss: 0.687155719353007
Epoch: 97 | Iteration number: [1550/4518] 34% | Training loss: 0.6871530495151397
Epoch: 97 | Iteration number: [1560/4518] 34% | Training loss: 0.6871405514386985
Epoch: 97 | Iteration number: [1570/4518] 34% | Training loss: 0.6871352723449659
Epoch: 97 | Iteration number: [1580/4518] 34% | Training loss: 0.6871339663297316
Epoch: 97 | Iteration number: [1590/4518] 35% | Training loss: 0.6871376588659467
Epoch: 97 | Iteration number: [1600/4518] 35% | Training loss: 0.6871318635717034
Epoch: 97 | Iteration number: [1610/4518] 35% | Training loss: 0.6871280877856735
Epoch: 97 | Iteration number: [1620/4518] 35% | Training loss: 0.6871185846902707
Epoch: 97 | Iteration number: [1630/4518] 36% | Training loss: 0.6871153781750451
Epoch: 97 | Iteration number: [1640/4518] 36% | Training loss: 0.6871142956178363
Epoch: 97 | Iteration number: [1650/4518] 36% | Training loss: 0.6871052518396666
Epoch: 97 | Iteration number: [1660/4518] 36% | Training loss: 0.6871044324464108
Epoch: 97 | Iteration number: [1670/4518] 36% | Training loss: 0.6870952356004429
Epoch: 97 | Iteration number: [1680/4518] 37% | Training loss: 0.6870943147511709
Epoch: 97 | Iteration number: [1690/4518] 37% | Training loss: 0.687087305657257
Epoch: 97 | Iteration number: [1700/4518] 37% | Training loss: 0.687085135438863
Epoch: 97 | Iteration number: [1710/4518] 37% | Training loss: 0.6870887708942792
Epoch: 97 | Iteration number: [1720/4518] 38% | Training loss: 0.6870902752113897
Epoch: 97 | Iteration number: [1730/4518] 38% | Training loss: 0.6870873906364331
Epoch: 97 | Iteration number: [1740/4518] 38% | Training loss: 0.6870789357985573
Epoch: 97 | Iteration number: [1750/4518] 38% | Training loss: 0.6870727122170585
Epoch: 97 | Iteration number: [1760/4518] 38% | Training loss: 0.6870683175934986
Epoch: 97 | Iteration number: [1770/4518] 39% | Training loss: 0.6870626163347966
Epoch: 97 | Iteration number: [1780/4518] 39% | Training loss: 0.6870580099941639
Epoch: 97 | Iteration number: [1790/4518] 39% | Training loss: 0.6870530636616925
Epoch: 97 | Iteration number: [1800/4518] 39% | Training loss: 0.6870570925209257
Epoch: 97 | Iteration number: [1810/4518] 40% | Training loss: 0.6870565534625923
Epoch: 97 | Iteration number: [1820/4518] 40% | Training loss: 0.6870572045281693
Epoch: 97 | Iteration number: [1830/4518] 40% | Training loss: 0.6870545552727955
Epoch: 97 | Iteration number: [1840/4518] 40% | Training loss: 0.6870434861468232
Epoch: 97 | Iteration number: [1850/4518] 40% | Training loss: 0.6870446739325652
Epoch: 97 | Iteration number: [1860/4518] 41% | Training loss: 0.6870409796955765
Epoch: 97 | Iteration number: [1870/4518] 41% | Training loss: 0.6870337027598192
Epoch: 97 | Iteration number: [1880/4518] 41% | Training loss: 0.687032435739294
Epoch: 97 | Iteration number: [1890/4518] 41% | Training loss: 0.6870281747724644
Epoch: 97 | Iteration number: [1900/4518] 42% | Training loss: 0.6870293715125636
Epoch: 97 | Iteration number: [1910/4518] 42% | Training loss: 0.6870275477464286
Epoch: 97 | Iteration number: [1920/4518] 42% | Training loss: 0.6870263407627741
Epoch: 97 | Iteration number: [1930/4518] 42% | Training loss: 0.6870210310955739
Epoch: 97 | Iteration number: [1940/4518] 42% | Training loss: 0.6870206270021262
Epoch: 97 | Iteration number: [1950/4518] 43% | Training loss: 0.6870218165104206
Epoch: 97 | Iteration number: [1960/4518] 43% | Training loss: 0.6870167404109118
Epoch: 97 | Iteration number: [1970/4518] 43% | Training loss: 0.6870190093662533
Epoch: 97 | Iteration number: [1980/4518] 43% | Training loss: 0.687023234909231
Epoch: 97 | Iteration number: [1990/4518] 44% | Training loss: 0.68701472258448
Epoch: 97 | Iteration number: [2000/4518] 44% | Training loss: 0.6870161030292511
Epoch: 97 | Iteration number: [2010/4518] 44% | Training loss: 0.6870171394810748
Epoch: 97 | Iteration number: [2020/4518] 44% | Training loss: 0.6870193554033147
Epoch: 97 | Iteration number: [2030/4518] 44% | Training loss: 0.6870171677009226
Epoch: 97 | Iteration number: [2040/4518] 45% | Training loss: 0.6870126375965043
Epoch: 97 | Iteration number: [2050/4518] 45% | Training loss: 0.6870079724381609
Epoch: 97 | Iteration number: [2060/4518] 45% | Training loss: 0.6870061333029015
Epoch: 97 | Iteration number: [2070/4518] 45% | Training loss: 0.6870086326403319
Epoch: 97 | Iteration number: [2080/4518] 46% | Training loss: 0.6870074307402739
Epoch: 97 | Iteration number: [2090/4518] 46% | Training loss: 0.6870026948634518
Epoch: 97 | Iteration number: [2100/4518] 46% | Training loss: 0.6869961576518558
Epoch: 97 | Iteration number: [2110/4518] 46% | Training loss: 0.6869930077503078
Epoch: 97 | Iteration number: [2120/4518] 46% | Training loss: 0.6869880868860011
Epoch: 97 | Iteration number: [2130/4518] 47% | Training loss: 0.6869931460546216
Epoch: 97 | Iteration number: [2140/4518] 47% | Training loss: 0.6869957649262152
Epoch: 97 | Iteration number: [2150/4518] 47% | Training loss: 0.6869986985450567
Epoch: 97 | Iteration number: [2160/4518] 47% | Training loss: 0.6869976133935981
Epoch: 97 | Iteration number: [2170/4518] 48% | Training loss: 0.6869936286579079
Epoch: 97 | Iteration number: [2180/4518] 48% | Training loss: 0.6869967629329874
Epoch: 97 | Iteration number: [2190/4518] 48% | Training loss: 0.6869986221942728
Epoch: 97 | Iteration number: [2200/4518] 48% | Training loss: 0.6870044024153189
Epoch: 97 | Iteration number: [2210/4518] 48% | Training loss: 0.6869993408610918
Epoch: 97 | Iteration number: [2220/4518] 49% | Training loss: 0.686997844238539
Epoch: 97 | Iteration number: [2230/4518] 49% | Training loss: 0.6870008677377829
Epoch: 97 | Iteration number: [2240/4518] 49% | Training loss: 0.6870049563103489
Epoch: 97 | Iteration number: [2250/4518] 49% | Training loss: 0.6870009351571401
Epoch: 97 | Iteration number: [2260/4518] 50% | Training loss: 0.6870010547933325
Epoch: 97 | Iteration number: [2270/4518] 50% | Training loss: 0.6870010524331736
Epoch: 97 | Iteration number: [2280/4518] 50% | Training loss: 0.6869996718147344
Epoch: 97 | Iteration number: [2290/4518] 50% | Training loss: 0.6869955510031188
Epoch: 97 | Iteration number: [2300/4518] 50% | Training loss: 0.6869900948327521
Epoch: 97 | Iteration number: [2310/4518] 51% | Training loss: 0.6869876826996411
Epoch: 97 | Iteration number: [2320/4518] 51% | Training loss: 0.6869828344162168
Epoch: 97 | Iteration number: [2330/4518] 51% | Training loss: 0.6869807370486689
Epoch: 97 | Iteration number: [2340/4518] 51% | Training loss: 0.6869771246726696
Epoch: 97 | Iteration number: [2350/4518] 52% | Training loss: 0.6869805882839446
Epoch: 97 | Iteration number: [2360/4518] 52% | Training loss: 0.6869843903992136
Epoch: 97 | Iteration number: [2370/4518] 52% | Training loss: 0.68698657358749
Epoch: 97 | Iteration number: [2380/4518] 52% | Training loss: 0.6869912207377057
Epoch: 97 | Iteration number: [2390/4518] 52% | Training loss: 0.6869900476982403
Epoch: 97 | Iteration number: [2400/4518] 53% | Training loss: 0.6869917122522989
Epoch: 97 | Iteration number: [2410/4518] 53% | Training loss: 0.6869923573806572
Epoch: 97 | Iteration number: [2420/4518] 53% | Training loss: 0.6869955054492005
Epoch: 97 | Iteration number: [2430/4518] 53% | Training loss: 0.686997605253149
Epoch: 97 | Iteration number: [2440/4518] 54% | Training loss: 0.686998699434468
Epoch: 97 | Iteration number: [2450/4518] 54% | Training loss: 0.6869978512063318
Epoch: 97 | Iteration number: [2460/4518] 54% | Training loss: 0.6869947825505481
Epoch: 97 | Iteration number: [2470/4518] 54% | Training loss: 0.6869906558440282
Epoch: 97 | Iteration number: [2480/4518] 54% | Training loss: 0.6869872598398117
Epoch: 97 | Iteration number: [2490/4518] 55% | Training loss: 0.6869856399225901
Epoch: 97 | Iteration number: [2500/4518] 55% | Training loss: 0.6869789695978165
Epoch: 97 | Iteration number: [2510/4518] 55% | Training loss: 0.6869754728805496
Epoch: 97 | Iteration number: [2520/4518] 55% | Training loss: 0.6869729745482641
Epoch: 97 | Iteration number: [2530/4518] 55% | Training loss: 0.6869703527966978
Epoch: 97 | Iteration number: [2540/4518] 56% | Training loss: 0.6869727541846553
Epoch: 97 | Iteration number: [2550/4518] 56% | Training loss: 0.6869671010269838
Epoch: 97 | Iteration number: [2560/4518] 56% | Training loss: 0.6869650603504851
Epoch: 97 | Iteration number: [2570/4518] 56% | Training loss: 0.6869603566854381
Epoch: 97 | Iteration number: [2580/4518] 57% | Training loss: 0.6869637935198555
Epoch: 97 | Iteration number: [2590/4518] 57% | Training loss: 0.6869604344303544
Epoch: 97 | Iteration number: [2600/4518] 57% | Training loss: 0.6869570045287793
Epoch: 97 | Iteration number: [2610/4518] 57% | Training loss: 0.686955171366761
Epoch: 97 | Iteration number: [2620/4518] 57% | Training loss: 0.6869560894392829
Epoch: 97 | Iteration number: [2630/4518] 58% | Training loss: 0.6869516195906432
Epoch: 97 | Iteration number: [2640/4518] 58% | Training loss: 0.6869522901647018
Epoch: 97 | Iteration number: [2650/4518] 58% | Training loss: 0.6869586664325786
Epoch: 97 | Iteration number: [2660/4518] 58% | Training loss: 0.6869558445044927
Epoch: 97 | Iteration number: [2670/4518] 59% | Training loss: 0.6869526905959912
Epoch: 97 | Iteration number: [2680/4518] 59% | Training loss: 0.6869564125342156
Epoch: 97 | Iteration number: [2690/4518] 59% | Training loss: 0.6869582193934785
Epoch: 97 | Iteration number: [2700/4518] 59% | Training loss: 0.686959527598487
Epoch: 97 | Iteration number: [2710/4518] 59% | Training loss: 0.6869566439262615
Epoch: 97 | Iteration number: [2720/4518] 60% | Training loss: 0.6869523784474415
Epoch: 97 | Iteration number: [2730/4518] 60% | Training loss: 0.686955255357337
Epoch: 97 | Iteration number: [2740/4518] 60% | Training loss: 0.6869530614057596
Epoch: 97 | Iteration number: [2750/4518] 60% | Training loss: 0.6869559927853671
Epoch: 97 | Iteration number: [2760/4518] 61% | Training loss: 0.6869494442274605
Epoch: 97 | Iteration number: [2770/4518] 61% | Training loss: 0.6869471681892657
Epoch: 97 | Iteration number: [2780/4518] 61% | Training loss: 0.6869469986545096
Epoch: 97 | Iteration number: [2790/4518] 61% | Training loss: 0.6869501945365715
Epoch: 97 | Iteration number: [2800/4518] 61% | Training loss: 0.6869496393203736
Epoch: 97 | Iteration number: [2810/4518] 62% | Training loss: 0.6869480654650312
Epoch: 97 | Iteration number: [2820/4518] 62% | Training loss: 0.686946137471402
Epoch: 97 | Iteration number: [2830/4518] 62% | Training loss: 0.6869462833808926
Epoch: 97 | Iteration number: [2840/4518] 62% | Training loss: 0.6869433372583188
Epoch: 97 | Iteration number: [2850/4518] 63% | Training loss: 0.6869429306398358
Epoch: 97 | Iteration number: [2860/4518] 63% | Training loss: 0.6869428647981657
Epoch: 97 | Iteration number: [2870/4518] 63% | Training loss: 0.6869423730863511
Epoch: 97 | Iteration number: [2880/4518] 63% | Training loss: 0.6869445708890756
Epoch: 97 | Iteration number: [2890/4518] 63% | Training loss: 0.6869447800939883
Epoch: 97 | Iteration number: [2900/4518] 64% | Training loss: 0.6869431547255351
Epoch: 97 | Iteration number: [2910/4518] 64% | Training loss: 0.6869396089893026
Epoch: 97 | Iteration number: [2920/4518] 64% | Training loss: 0.6869353915118191
Epoch: 97 | Iteration number: [2930/4518] 64% | Training loss: 0.6869373404532162
Epoch: 97 | Iteration number: [2940/4518] 65% | Training loss: 0.6869405523043911
Epoch: 97 | Iteration number: [2950/4518] 65% | Training loss: 0.6869401982275106
Epoch: 97 | Iteration number: [2960/4518] 65% | Training loss: 0.686938354050791
Epoch: 97 | Iteration number: [2970/4518] 65% | Training loss: 0.6869426147303598
Epoch: 97 | Iteration number: [2980/4518] 65% | Training loss: 0.6869446625245498
Epoch: 97 | Iteration number: [2990/4518] 66% | Training loss: 0.6869401999939245
Epoch: 97 | Iteration number: [3000/4518] 66% | Training loss: 0.6869400579333306
Epoch: 97 | Iteration number: [3010/4518] 66% | Training loss: 0.6869386624854268
Epoch: 97 | Iteration number: [3020/4518] 66% | Training loss: 0.6869344973998354
Epoch: 97 | Iteration number: [3030/4518] 67% | Training loss: 0.6869328318059248
Epoch: 97 | Iteration number: [3040/4518] 67% | Training loss: 0.6869299835280368
Epoch: 97 | Iteration number: [3050/4518] 67% | Training loss: 0.686929740417199
Epoch: 97 | Iteration number: [3060/4518] 67% | Training loss: 0.6869291824453018
Epoch: 97 | Iteration number: [3070/4518] 67% | Training loss: 0.6869241459167741
Epoch: 97 | Iteration number: [3080/4518] 68% | Training loss: 0.6869277809927989
Epoch: 97 | Iteration number: [3090/4518] 68% | Training loss: 0.6869287653841247
Epoch: 97 | Iteration number: [3100/4518] 68% | Training loss: 0.6869280562862273
Epoch: 97 | Iteration number: [3110/4518] 68% | Training loss: 0.6869325454403733
Epoch: 97 | Iteration number: [3120/4518] 69% | Training loss: 0.6869352761178444
Epoch: 97 | Iteration number: [3130/4518] 69% | Training loss: 0.6869366014727388
Epoch: 97 | Iteration number: [3140/4518] 69% | Training loss: 0.6869353636245059
Epoch: 97 | Iteration number: [3150/4518] 69% | Training loss: 0.6869352443256076
Epoch: 97 | Iteration number: [3160/4518] 69% | Training loss: 0.6869354129592075
Epoch: 97 | Iteration number: [3170/4518] 70% | Training loss: 0.6869342013864487
Epoch: 97 | Iteration number: [3180/4518] 70% | Training loss: 0.6869352722317917
Epoch: 97 | Iteration number: [3190/4518] 70% | Training loss: 0.6869317482070864
Epoch: 97 | Iteration number: [3200/4518] 70% | Training loss: 0.6869295009225607
Epoch: 97 | Iteration number: [3210/4518] 71% | Training loss: 0.6869280038035919
Epoch: 97 | Iteration number: [3220/4518] 71% | Training loss: 0.6869270315266544
Epoch: 97 | Iteration number: [3230/4518] 71% | Training loss: 0.6869270979435451
Epoch: 97 | Iteration number: [3240/4518] 71% | Training loss: 0.6869268169557606
Epoch: 97 | Iteration number: [3250/4518] 71% | Training loss: 0.6869300635594588
Epoch: 97 | Iteration number: [3260/4518] 72% | Training loss: 0.6869310808876541
Epoch: 97 | Iteration number: [3270/4518] 72% | Training loss: 0.6869312948043194
Epoch: 97 | Iteration number: [3280/4518] 72% | Training loss: 0.6869288008024053
Epoch: 97 | Iteration number: [3290/4518] 72% | Training loss: 0.6869299576999931
Epoch: 97 | Iteration number: [3300/4518] 73% | Training loss: 0.6869324480584174
Epoch: 97 | Iteration number: [3310/4518] 73% | Training loss: 0.6869330274914687
Epoch: 97 | Iteration number: [3320/4518] 73% | Training loss: 0.6869321369263063
Epoch: 97 | Iteration number: [3330/4518] 73% | Training loss: 0.6869329456989471
Epoch: 97 | Iteration number: [3340/4518] 73% | Training loss: 0.686932475159982
Epoch: 97 | Iteration number: [3350/4518] 74% | Training loss: 0.6869307770302047
Epoch: 97 | Iteration number: [3360/4518] 74% | Training loss: 0.6869294915880476
Epoch: 97 | Iteration number: [3370/4518] 74% | Training loss: 0.6869278789274063
Epoch: 97 | Iteration number: [3380/4518] 74% | Training loss: 0.6869277067085695
Epoch: 97 | Iteration number: [3390/4518] 75% | Training loss: 0.686927682477816
Epoch: 97 | Iteration number: [3400/4518] 75% | Training loss: 0.6869267124989453
Epoch: 97 | Iteration number: [3410/4518] 75% | Training loss: 0.6869246505222713
Epoch: 97 | Iteration number: [3420/4518] 75% | Training loss: 0.6869240514890492
Epoch: 97 | Iteration number: [3430/4518] 75% | Training loss: 0.6869278050025073
Epoch: 97 | Iteration number: [3440/4518] 76% | Training loss: 0.6869261549655781
Epoch: 97 | Iteration number: [3450/4518] 76% | Training loss: 0.6869269965005957
Epoch: 97 | Iteration number: [3460/4518] 76% | Training loss: 0.6869262487902118
Epoch: 97 | Iteration number: [3470/4518] 76% | Training loss: 0.6869273023921406
Epoch: 97 | Iteration number: [3480/4518] 77% | Training loss: 0.6869238669159768
Epoch: 97 | Iteration number: [3490/4518] 77% | Training loss: 0.68692437562355
Epoch: 97 | Iteration number: [3500/4518] 77% | Training loss: 0.6869272086109434
Epoch: 97 | Iteration number: [3510/4518] 77% | Training loss: 0.6869298579855861
Epoch: 97 | Iteration number: [3520/4518] 77% | Training loss: 0.6869313053448092
Epoch: 97 | Iteration number: [3530/4518] 78% | Training loss: 0.6869311029276159
Epoch: 97 | Iteration number: [3540/4518] 78% | Training loss: 0.6869296797756421
Epoch: 97 | Iteration number: [3550/4518] 78% | Training loss: 0.686932381273995
Epoch: 97 | Iteration number: [3560/4518] 78% | Training loss: 0.6869312503866936
Epoch: 97 | Iteration number: [3570/4518] 79% | Training loss: 0.6869353953195887
Epoch: 97 | Iteration number: [3580/4518] 79% | Training loss: 0.6869339640913062
Epoch: 97 | Iteration number: [3590/4518] 79% | Training loss: 0.6869247119406804
Epoch: 97 | Iteration number: [3600/4518] 79% | Training loss: 0.6869240481654802
Epoch: 97 | Iteration number: [3610/4518] 79% | Training loss: 0.6869259736874758
Epoch: 97 | Iteration number: [3620/4518] 80% | Training loss: 0.6869268107315454
Epoch: 97 | Iteration number: [3630/4518] 80% | Training loss: 0.6869230229171511
Epoch: 97 | Iteration number: [3640/4518] 80% | Training loss: 0.686926559989269
Epoch: 97 | Iteration number: [3650/4518] 80% | Training loss: 0.6869292784227083
Epoch: 97 | Iteration number: [3660/4518] 81% | Training loss: 0.6869282616780755
Epoch: 97 | Iteration number: [3670/4518] 81% | Training loss: 0.6869255522453818
Epoch: 97 | Iteration number: [3680/4518] 81% | Training loss: 0.686928356471269
Epoch: 97 | Iteration number: [3690/4518] 81% | Training loss: 0.6869292927143696
Epoch: 97 | Iteration number: [3700/4518] 81% | Training loss: 0.686929806696402
Epoch: 97 | Iteration number: [3710/4518] 82% | Training loss: 0.6869317527729867
Epoch: 97 | Iteration number: [3720/4518] 82% | Training loss: 0.686930023117732
Epoch: 97 | Iteration number: [3730/4518] 82% | Training loss: 0.6869296260238014
Epoch: 97 | Iteration number: [3740/4518] 82% | Training loss: 0.6869286905476116
Epoch: 97 | Iteration number: [3750/4518] 83% | Training loss: 0.6869282028992971
Epoch: 97 | Iteration number: [3760/4518] 83% | Training loss: 0.6869298910999552
Epoch: 97 | Iteration number: [3770/4518] 83% | Training loss: 0.6869320350079069
Epoch: 97 | Iteration number: [3780/4518] 83% | Training loss: 0.6869339181790276
Epoch: 97 | Iteration number: [3790/4518] 83% | Training loss: 0.6869342988273399
Epoch: 97 | Iteration number: [3800/4518] 84% | Training loss: 0.6869348734303524
Epoch: 97 | Iteration number: [3810/4518] 84% | Training loss: 0.6869335409380946
Epoch: 97 | Iteration number: [3820/4518] 84% | Training loss: 0.686933607471551
Epoch: 97 | Iteration number: [3830/4518] 84% | Training loss: 0.6869326159941621
Epoch: 97 | Iteration number: [3840/4518] 84% | Training loss: 0.6869285464442024
Epoch: 97 | Iteration number: [3850/4518] 85% | Training loss: 0.6869261405529914
Epoch: 97 | Iteration number: [3860/4518] 85% | Training loss: 0.6869269865318901
Epoch: 97 | Iteration number: [3870/4518] 85% | Training loss: 0.6869272179227774
Epoch: 97 | Iteration number: [3880/4518] 85% | Training loss: 0.6869275963951632
Epoch: 97 | Iteration number: [3890/4518] 86% | Training loss: 0.686927006774819
Epoch: 97 | Iteration number: [3900/4518] 86% | Training loss: 0.6869272502721885
Epoch: 97 | Iteration number: [3910/4518] 86% | Training loss: 0.68692622931717
Epoch: 97 | Iteration number: [3920/4518] 86% | Training loss: 0.6869270280611758
Epoch: 97 | Iteration number: [3930/4518] 86% | Training loss: 0.6869299483814919
Epoch: 97 | Iteration number: [3940/4518] 87% | Training loss: 0.686928151404192
Epoch: 97 | Iteration number: [3950/4518] 87% | Training loss: 0.6869272082666807
Epoch: 97 | Iteration number: [3960/4518] 87% | Training loss: 0.6869256463616785
Epoch: 97 | Iteration number: [3970/4518] 87% | Training loss: 0.6869232335979452
Epoch: 97 | Iteration number: [3980/4518] 88% | Training loss: 0.6869266455796496
Epoch: 97 | Iteration number: [3990/4518] 88% | Training loss: 0.6869275425161634
Epoch: 97 | Iteration number: [4000/4518] 88% | Training loss: 0.6869273231327534
Epoch: 97 | Iteration number: [4010/4518] 88% | Training loss: 0.6869275582252893
Epoch: 97 | Iteration number: [4020/4518] 88% | Training loss: 0.6869270294756439
Epoch: 97 | Iteration number: [4030/4518] 89% | Training loss: 0.6869252230925832
Epoch: 97 | Iteration number: [4040/4518] 89% | Training loss: 0.6869256824697598
Epoch: 97 | Iteration number: [4050/4518] 89% | Training loss: 0.6869274995797946
Epoch: 97 | Iteration number: [4060/4518] 89% | Training loss: 0.6869246252211444
Epoch: 97 | Iteration number: [4070/4518] 90% | Training loss: 0.6869235530825153
Epoch: 97 | Iteration number: [4080/4518] 90% | Training loss: 0.686923601697473
Epoch: 97 | Iteration number: [4090/4518] 90% | Training loss: 0.6869214605439846
Epoch: 97 | Iteration number: [4100/4518] 90% | Training loss: 0.6869218158140415
Epoch: 97 | Iteration number: [4110/4518] 90% | Training loss: 0.6869197238970847
Epoch: 97 | Iteration number: [4120/4518] 91% | Training loss: 0.6869186393265585
Epoch: 97 | Iteration number: [4130/4518] 91% | Training loss: 0.6869185044026548
Epoch: 97 | Iteration number: [4140/4518] 91% | Training loss: 0.6869182154176315
Epoch: 97 | Iteration number: [4150/4518] 91% | Training loss: 0.686920230302466
Epoch: 97 | Iteration number: [4160/4518] 92% | Training loss: 0.6869189890388113
Epoch: 97 | Iteration number: [4170/4518] 92% | Training loss: 0.6869206592619276
Epoch: 97 | Iteration number: [4180/4518] 92% | Training loss: 0.6869199014736704
Epoch: 97 | Iteration number: [4190/4518] 92% | Training loss: 0.6869147414239324
Epoch: 97 | Iteration number: [4200/4518] 92% | Training loss: 0.6869151244418962
Epoch: 97 | Iteration number: [4210/4518] 93% | Training loss: 0.6869157357340471
Epoch: 97 | Iteration number: [4220/4518] 93% | Training loss: 0.6869164723496867
Epoch: 97 | Iteration number: [4230/4518] 93% | Training loss: 0.6869141543869713
Epoch: 97 | Iteration number: [4240/4518] 93% | Training loss: 0.6869112156050385
Epoch: 97 | Iteration number: [4250/4518] 94% | Training loss: 0.6869148241632125
Epoch: 97 | Iteration number: [4260/4518] 94% | Training loss: 0.6869181143006249
Epoch: 97 | Iteration number: [4270/4518] 94% | Training loss: 0.6869168281694765
Epoch: 97 | Iteration number: [4280/4518] 94% | Training loss: 0.686914843209436
Epoch: 97 | Iteration number: [4290/4518] 94% | Training loss: 0.6869171669016351
Epoch: 97 | Iteration number: [4300/4518] 95% | Training loss: 0.6869163260071777
Epoch: 97 | Iteration number: [4310/4518] 95% | Training loss: 0.6869152947395971
Epoch: 97 | Iteration number: [4320/4518] 95% | Training loss: 0.6869150687009096
Epoch: 97 | Iteration number: [4330/4518] 95% | Training loss: 0.6869147755670217
Epoch: 97 | Iteration number: [4340/4518] 96% | Training loss: 0.6869144986164735
Epoch: 97 | Iteration number: [4350/4518] 96% | Training loss: 0.6869144545067316
Epoch: 97 | Iteration number: [4360/4518] 96% | Training loss: 0.6869139242746415
Epoch: 97 | Iteration number: [4370/4518] 96% | Training loss: 0.6869122610621375
Epoch: 97 | Iteration number: [4380/4518] 96% | Training loss: 0.6869124198749185
Epoch: 97 | Iteration number: [4390/4518] 97% | Training loss: 0.6869086717147219
Epoch: 97 | Iteration number: [4400/4518] 97% | Training loss: 0.6869091734561054
Epoch: 97 | Iteration number: [4410/4518] 97% | Training loss: 0.6869107592808686
Epoch: 97 | Iteration number: [4420/4518] 97% | Training loss: 0.6869098426664577
Epoch: 97 | Iteration number: [4430/4518] 98% | Training loss: 0.6869084602150368
Epoch: 97 | Iteration number: [4440/4518] 98% | Training loss: 0.6869077620608313
Epoch: 97 | Iteration number: [4450/4518] 98% | Training loss: 0.6869065938906723
Epoch: 97 | Iteration number: [4460/4518] 98% | Training loss: 0.6869061345744026
Epoch: 97 | Iteration number: [4470/4518] 98% | Training loss: 0.6869074797070266
Epoch: 97 | Iteration number: [4480/4518] 99% | Training loss: 0.6869080263988248
Epoch: 97 | Iteration number: [4490/4518] 99% | Training loss: 0.6869103523166249
Epoch: 97 | Iteration number: [4500/4518] 99% | Training loss: 0.6869093343284395
Epoch: 97 | Iteration number: [4510/4518] 99% | Training loss: 0.6869089557035535

 End of epoch: 97 | Train Loss: 0.6867539773424308 | Training Time: 641 

 End of epoch: 97 | Eval Loss: 0.6899151157359688 | Evaluating Time: 17 
Epoch: 98 | Iteration number: [10/4518] 0% | Training loss: 0.7560557782649994
Epoch: 98 | Iteration number: [20/4518] 0% | Training loss: 0.7215273588895798
Epoch: 98 | Iteration number: [30/4518] 0% | Training loss: 0.7098417202631633
Epoch: 98 | Iteration number: [40/4518] 0% | Training loss: 0.7038264736533165
Epoch: 98 | Iteration number: [50/4518] 1% | Training loss: 0.7003098976612091
Epoch: 98 | Iteration number: [60/4518] 1% | Training loss: 0.6978847155968348
Epoch: 98 | Iteration number: [70/4518] 1% | Training loss: 0.6961731391293662
Epoch: 98 | Iteration number: [80/4518] 1% | Training loss: 0.6949025817215443
Epoch: 98 | Iteration number: [90/4518] 1% | Training loss: 0.6941213323010339
Epoch: 98 | Iteration number: [100/4518] 2% | Training loss: 0.6933395767211914
Epoch: 98 | Iteration number: [110/4518] 2% | Training loss: 0.6927419429475611
Epoch: 98 | Iteration number: [120/4518] 2% | Training loss: 0.6922984957695008
Epoch: 98 | Iteration number: [130/4518] 2% | Training loss: 0.6918029840175922
Epoch: 98 | Iteration number: [140/4518] 3% | Training loss: 0.6914540942226137
Epoch: 98 | Iteration number: [150/4518] 3% | Training loss: 0.6911111529668172
Epoch: 98 | Iteration number: [160/4518] 3% | Training loss: 0.6908021584153176
Epoch: 98 | Iteration number: [170/4518] 3% | Training loss: 0.6905741740675534
Epoch: 98 | Iteration number: [180/4518] 3% | Training loss: 0.6903269622060988
Epoch: 98 | Iteration number: [190/4518] 4% | Training loss: 0.6901498992192118
Epoch: 98 | Iteration number: [200/4518] 4% | Training loss: 0.6899795216321946
Epoch: 98 | Iteration number: [210/4518] 4% | Training loss: 0.6897517252536047
Epoch: 98 | Iteration number: [220/4518] 4% | Training loss: 0.6895711917768825
Epoch: 98 | Iteration number: [230/4518] 5% | Training loss: 0.6894679758859718
Epoch: 98 | Iteration number: [240/4518] 5% | Training loss: 0.6893375424047311
Epoch: 98 | Iteration number: [250/4518] 5% | Training loss: 0.6892197988033295
Epoch: 98 | Iteration number: [260/4518] 5% | Training loss: 0.6891191519223727
Epoch: 98 | Iteration number: [270/4518] 5% | Training loss: 0.689048801307325
Epoch: 98 | Iteration number: [280/4518] 6% | Training loss: 0.688976358303002
Epoch: 98 | Iteration number: [290/4518] 6% | Training loss: 0.6888925739403429
Epoch: 98 | Iteration number: [300/4518] 6% | Training loss: 0.6888193647066753
Epoch: 98 | Iteration number: [310/4518] 6% | Training loss: 0.6887719863845456
Epoch: 98 | Iteration number: [320/4518] 7% | Training loss: 0.6887417180463672
Epoch: 98 | Iteration number: [330/4518] 7% | Training loss: 0.6886866659829111
Epoch: 98 | Iteration number: [340/4518] 7% | Training loss: 0.6886542113388285
Epoch: 98 | Iteration number: [350/4518] 7% | Training loss: 0.6885950657299587
Epoch: 98 | Iteration number: [360/4518] 7% | Training loss: 0.6885251646240552
Epoch: 98 | Iteration number: [370/4518] 8% | Training loss: 0.6884817886996913
Epoch: 98 | Iteration number: [380/4518] 8% | Training loss: 0.6884361447472321
Epoch: 98 | Iteration number: [390/4518] 8% | Training loss: 0.6883676779575837
Epoch: 98 | Iteration number: [400/4518] 8% | Training loss: 0.6883283872902394
Epoch: 98 | Iteration number: [410/4518] 9% | Training loss: 0.6882671200647587
Epoch: 98 | Iteration number: [420/4518] 9% | Training loss: 0.6882248149031684
Epoch: 98 | Iteration number: [430/4518] 9% | Training loss: 0.688185329769933
Epoch: 98 | Iteration number: [440/4518] 9% | Training loss: 0.6881461117755283
Epoch: 98 | Iteration number: [450/4518] 9% | Training loss: 0.6881045638190375
Epoch: 98 | Iteration number: [460/4518] 10% | Training loss: 0.688086035458938
Epoch: 98 | Iteration number: [470/4518] 10% | Training loss: 0.6880415317860056
Epoch: 98 | Iteration number: [480/4518] 10% | Training loss: 0.6880016459772984
Epoch: 98 | Iteration number: [490/4518] 10% | Training loss: 0.687968293258122
Epoch: 98 | Iteration number: [500/4518] 11% | Training loss: 0.687925836801529
Epoch: 98 | Iteration number: [510/4518] 11% | Training loss: 0.6879141989876242
Epoch: 98 | Iteration number: [520/4518] 11% | Training loss: 0.6878987814371402
Epoch: 98 | Iteration number: [530/4518] 11% | Training loss: 0.6878504218920222
Epoch: 98 | Iteration number: [540/4518] 11% | Training loss: 0.6878212951951557
Epoch: 98 | Iteration number: [550/4518] 12% | Training loss: 0.687797922221097
Epoch: 98 | Iteration number: [560/4518] 12% | Training loss: 0.6877896127956254
Epoch: 98 | Iteration number: [570/4518] 12% | Training loss: 0.6877700252491131
Epoch: 98 | Iteration number: [580/4518] 12% | Training loss: 0.6877642224574911
Epoch: 98 | Iteration number: [590/4518] 13% | Training loss: 0.6877597303713783
Epoch: 98 | Iteration number: [600/4518] 13% | Training loss: 0.6877319108446439
Epoch: 98 | Iteration number: [610/4518] 13% | Training loss: 0.6876993293644952
Epoch: 98 | Iteration number: [620/4518] 13% | Training loss: 0.6876753690742677
Epoch: 98 | Iteration number: [630/4518] 13% | Training loss: 0.6876645225381094
Epoch: 98 | Iteration number: [640/4518] 14% | Training loss: 0.6876445103436708
Epoch: 98 | Iteration number: [650/4518] 14% | Training loss: 0.687650858438932
Epoch: 98 | Iteration number: [660/4518] 14% | Training loss: 0.6876357241110368
Epoch: 98 | Iteration number: [670/4518] 14% | Training loss: 0.6876158656469032
Epoch: 98 | Iteration number: [680/4518] 15% | Training loss: 0.6876095155582709
Epoch: 98 | Iteration number: [690/4518] 15% | Training loss: 0.6875973626323368
Epoch: 98 | Iteration number: [700/4518] 15% | Training loss: 0.6875901226486478
Epoch: 98 | Iteration number: [710/4518] 15% | Training loss: 0.6875799296607434
Epoch: 98 | Iteration number: [720/4518] 15% | Training loss: 0.6875868877602949
Epoch: 98 | Iteration number: [730/4518] 16% | Training loss: 0.6875634377133356
Epoch: 98 | Iteration number: [740/4518] 16% | Training loss: 0.6875603927148355
Epoch: 98 | Iteration number: [750/4518] 16% | Training loss: 0.6875268709659577
Epoch: 98 | Iteration number: [760/4518] 16% | Training loss: 0.6875175117662079
Epoch: 98 | Iteration number: [770/4518] 17% | Training loss: 0.6874933166937395
Epoch: 98 | Iteration number: [780/4518] 17% | Training loss: 0.68748666147391
Epoch: 98 | Iteration number: [790/4518] 17% | Training loss: 0.6874642669400083
Epoch: 98 | Iteration number: [800/4518] 17% | Training loss: 0.6874636141955852
Epoch: 98 | Iteration number: [810/4518] 17% | Training loss: 0.6874752678253032
Epoch: 98 | Iteration number: [820/4518] 18% | Training loss: 0.6874715707650999
Epoch: 98 | Iteration number: [830/4518] 18% | Training loss: 0.6874672922025243
Epoch: 98 | Iteration number: [840/4518] 18% | Training loss: 0.6874393561056682
Epoch: 98 | Iteration number: [850/4518] 18% | Training loss: 0.6874252166467555
Epoch: 98 | Iteration number: [860/4518] 19% | Training loss: 0.6874180291974268
Epoch: 98 | Iteration number: [870/4518] 19% | Training loss: 0.687413754476898
Epoch: 98 | Iteration number: [880/4518] 19% | Training loss: 0.6873914581130851
Epoch: 98 | Iteration number: [890/4518] 19% | Training loss: 0.687375106838312
Epoch: 98 | Iteration number: [900/4518] 19% | Training loss: 0.6873779100841946
Epoch: 98 | Iteration number: [910/4518] 20% | Training loss: 0.6873863761896616
Epoch: 98 | Iteration number: [920/4518] 20% | Training loss: 0.68738340638254
Epoch: 98 | Iteration number: [930/4518] 20% | Training loss: 0.6873707455973471
Epoch: 98 | Iteration number: [940/4518] 20% | Training loss: 0.6873727739491361
Epoch: 98 | Iteration number: [950/4518] 21% | Training loss: 0.687361447497418
Epoch: 98 | Iteration number: [960/4518] 21% | Training loss: 0.6873476122816403
Epoch: 98 | Iteration number: [970/4518] 21% | Training loss: 0.687350140097215
Epoch: 98 | Iteration number: [980/4518] 21% | Training loss: 0.6873332116676837
Epoch: 98 | Iteration number: [990/4518] 21% | Training loss: 0.6873313063322896
Epoch: 98 | Iteration number: [1000/4518] 22% | Training loss: 0.6873147712945938
Epoch: 98 | Iteration number: [1010/4518] 22% | Training loss: 0.6873196320368512
Epoch: 98 | Iteration number: [1020/4518] 22% | Training loss: 0.6873230382507922
Epoch: 98 | Iteration number: [1030/4518] 22% | Training loss: 0.687318057400509
Epoch: 98 | Iteration number: [1040/4518] 23% | Training loss: 0.6873141613144141
Epoch: 98 | Iteration number: [1050/4518] 23% | Training loss: 0.6873057279132662
Epoch: 98 | Iteration number: [1060/4518] 23% | Training loss: 0.6873058460793405
Epoch: 98 | Iteration number: [1070/4518] 23% | Training loss: 0.6873069332024762
Epoch: 98 | Iteration number: [1080/4518] 23% | Training loss: 0.687299852569898
Epoch: 98 | Iteration number: [1090/4518] 24% | Training loss: 0.6873000488368743
Epoch: 98 | Iteration number: [1100/4518] 24% | Training loss: 0.6872864524884658
Epoch: 98 | Iteration number: [1110/4518] 24% | Training loss: 0.6872669929319674
Epoch: 98 | Iteration number: [1120/4518] 24% | Training loss: 0.6872641976922751
Epoch: 98 | Iteration number: [1130/4518] 25% | Training loss: 0.6872563410649257
Epoch: 98 | Iteration number: [1140/4518] 25% | Training loss: 0.6872535878106167
Epoch: 98 | Iteration number: [1150/4518] 25% | Training loss: 0.6872400668911312
Epoch: 98 | Iteration number: [1160/4518] 25% | Training loss: 0.6872413739048201
Epoch: 98 | Iteration number: [1170/4518] 25% | Training loss: 0.6872373288003807
Epoch: 98 | Iteration number: [1180/4518] 26% | Training loss: 0.6872278577190335
Epoch: 98 | Iteration number: [1190/4518] 26% | Training loss: 0.6872250893536735
Epoch: 98 | Iteration number: [1200/4518] 26% | Training loss: 0.6872236589094003
Epoch: 98 | Iteration number: [1210/4518] 26% | Training loss: 0.6872096939027802
Epoch: 98 | Iteration number: [1220/4518] 27% | Training loss: 0.6871990729062284
Epoch: 98 | Iteration number: [1230/4518] 27% | Training loss: 0.6871997377736782
Epoch: 98 | Iteration number: [1240/4518] 27% | Training loss: 0.6872013191542318
Epoch: 98 | Iteration number: [1250/4518] 27% | Training loss: 0.6871988443851471
Epoch: 98 | Iteration number: [1260/4518] 27% | Training loss: 0.6871905589860583
Epoch: 98 | Iteration number: [1270/4518] 28% | Training loss: 0.6871859389496601
Epoch: 98 | Iteration number: [1280/4518] 28% | Training loss: 0.6871828893199563
Epoch: 98 | Iteration number: [1290/4518] 28% | Training loss: 0.6871846046558646
Epoch: 98 | Iteration number: [1300/4518] 28% | Training loss: 0.687176563510528
Epoch: 98 | Iteration number: [1310/4518] 28% | Training loss: 0.6871789833971562
Epoch: 98 | Iteration number: [1320/4518] 29% | Training loss: 0.6871812442486936
Epoch: 98 | Iteration number: [1330/4518] 29% | Training loss: 0.6871835024733293
Epoch: 98 | Iteration number: [1340/4518] 29% | Training loss: 0.6871792968084564
Epoch: 98 | Iteration number: [1350/4518] 29% | Training loss: 0.687180390269668
Epoch: 98 | Iteration number: [1360/4518] 30% | Training loss: 0.6871837060241138
Epoch: 98 | Iteration number: [1370/4518] 30% | Training loss: 0.6871819810275613
Epoch: 98 | Iteration number: [1380/4518] 30% | Training loss: 0.6871812105610751
Epoch: 98 | Iteration number: [1390/4518] 30% | Training loss: 0.6871716515194598
Epoch: 98 | Iteration number: [1400/4518] 30% | Training loss: 0.6871668839028904
Epoch: 98 | Iteration number: [1410/4518] 31% | Training loss: 0.6871652771395149
Epoch: 98 | Iteration number: [1420/4518] 31% | Training loss: 0.6871644861681361
Epoch: 98 | Iteration number: [1430/4518] 31% | Training loss: 0.6871562183320106
Epoch: 98 | Iteration number: [1440/4518] 31% | Training loss: 0.6871510197305017
Epoch: 98 | Iteration number: [1450/4518] 32% | Training loss: 0.687138433333101
Epoch: 98 | Iteration number: [1460/4518] 32% | Training loss: 0.687138509668716
Epoch: 98 | Iteration number: [1470/4518] 32% | Training loss: 0.6871386641953268
Epoch: 98 | Iteration number: [1480/4518] 32% | Training loss: 0.6871379274774242
Epoch: 98 | Iteration number: [1490/4518] 32% | Training loss: 0.6871468021965667
Epoch: 98 | Iteration number: [1500/4518] 33% | Training loss: 0.6871458609501521
Epoch: 98 | Iteration number: [1510/4518] 33% | Training loss: 0.6871451876416111
Epoch: 98 | Iteration number: [1520/4518] 33% | Training loss: 0.6871414516317217
Epoch: 98 | Iteration number: [1530/4518] 33% | Training loss: 0.6871394785401089
Epoch: 98 | Iteration number: [1540/4518] 34% | Training loss: 0.6871327402916821
Epoch: 98 | Iteration number: [1550/4518] 34% | Training loss: 0.6871398835797464
Epoch: 98 | Iteration number: [1560/4518] 34% | Training loss: 0.6871360176648849
Epoch: 98 | Iteration number: [1570/4518] 34% | Training loss: 0.6871353091328007
Epoch: 98 | Iteration number: [1580/4518] 34% | Training loss: 0.6871414278504214
Epoch: 98 | Iteration number: [1590/4518] 35% | Training loss: 0.6871424324857364
Epoch: 98 | Iteration number: [1600/4518] 35% | Training loss: 0.687146341688931
Epoch: 98 | Iteration number: [1610/4518] 35% | Training loss: 0.6871445769108601
Epoch: 98 | Iteration number: [1620/4518] 35% | Training loss: 0.6871361503998439
Epoch: 98 | Iteration number: [1630/4518] 36% | Training loss: 0.6871350920639155
Epoch: 98 | Iteration number: [1640/4518] 36% | Training loss: 0.6871368937376069
Epoch: 98 | Iteration number: [1650/4518] 36% | Training loss: 0.6871292726198832
Epoch: 98 | Iteration number: [1660/4518] 36% | Training loss: 0.687125364987247
Epoch: 98 | Iteration number: [1670/4518] 36% | Training loss: 0.6871321446167494
Epoch: 98 | Iteration number: [1680/4518] 37% | Training loss: 0.6871328164779005
Epoch: 98 | Iteration number: [1690/4518] 37% | Training loss: 0.6871337987614806
Epoch: 98 | Iteration number: [1700/4518] 37% | Training loss: 0.6871361057547962
Epoch: 98 | Iteration number: [1710/4518] 37% | Training loss: 0.6871321165073685
Epoch: 98 | Iteration number: [1720/4518] 38% | Training loss: 0.6871260352259458
Epoch: 98 | Iteration number: [1730/4518] 38% | Training loss: 0.6871181127652957
Epoch: 98 | Iteration number: [1740/4518] 38% | Training loss: 0.6871172563440499
Epoch: 98 | Iteration number: [1750/4518] 38% | Training loss: 0.6871144401005336
Epoch: 98 | Iteration number: [1760/4518] 38% | Training loss: 0.6871102726933631
Epoch: 98 | Iteration number: [1770/4518] 39% | Training loss: 0.6871103168544123
Epoch: 98 | Iteration number: [1780/4518] 39% | Training loss: 0.6871064967653725
Epoch: 98 | Iteration number: [1790/4518] 39% | Training loss: 0.687112042424399
Epoch: 98 | Iteration number: [1800/4518] 39% | Training loss: 0.6871142042676608
Epoch: 98 | Iteration number: [1810/4518] 40% | Training loss: 0.6871168352293047
Epoch: 98 | Iteration number: [1820/4518] 40% | Training loss: 0.6871183743843665
Epoch: 98 | Iteration number: [1830/4518] 40% | Training loss: 0.687118696710451
Epoch: 98 | Iteration number: [1840/4518] 40% | Training loss: 0.6871158282393994
Epoch: 98 | Iteration number: [1850/4518] 40% | Training loss: 0.6871163143338384
Epoch: 98 | Iteration number: [1860/4518] 41% | Training loss: 0.6871278098193548
Epoch: 98 | Iteration number: [1870/4518] 41% | Training loss: 0.6871263554070722
Epoch: 98 | Iteration number: [1880/4518] 41% | Training loss: 0.6871247824519239
Epoch: 98 | Iteration number: [1890/4518] 41% | Training loss: 0.6871187847758097
Epoch: 98 | Iteration number: [1900/4518] 42% | Training loss: 0.6871227473334263
Epoch: 98 | Iteration number: [1910/4518] 42% | Training loss: 0.6871128667399521
Epoch: 98 | Iteration number: [1920/4518] 42% | Training loss: 0.6871091509237885
Epoch: 98 | Iteration number: [1930/4518] 42% | Training loss: 0.6871074672498851
Epoch: 98 | Iteration number: [1940/4518] 42% | Training loss: 0.68711276675008
Epoch: 98 | Iteration number: [1950/4518] 43% | Training loss: 0.6871116431248494
Epoch: 98 | Iteration number: [1960/4518] 43% | Training loss: 0.687110996824138
Epoch: 98 | Iteration number: [1970/4518] 43% | Training loss: 0.6871042106054761
Epoch: 98 | Iteration number: [1980/4518] 43% | Training loss: 0.6871112545632353
Epoch: 98 | Iteration number: [1990/4518] 44% | Training loss: 0.6871119554617896
Epoch: 98 | Iteration number: [2000/4518] 44% | Training loss: 0.6871119872629643
Epoch: 98 | Iteration number: [2010/4518] 44% | Training loss: 0.6871056271726219
Epoch: 98 | Iteration number: [2020/4518] 44% | Training loss: 0.687104937847298
Epoch: 98 | Iteration number: [2030/4518] 44% | Training loss: 0.6871029091586033
Epoch: 98 | Iteration number: [2040/4518] 45% | Training loss: 0.687099059364375
Epoch: 98 | Iteration number: [2050/4518] 45% | Training loss: 0.6870974587521902
Epoch: 98 | Iteration number: [2060/4518] 45% | Training loss: 0.687099002605503
Epoch: 98 | Iteration number: [2070/4518] 45% | Training loss: 0.6870975120344024
Epoch: 98 | Iteration number: [2080/4518] 46% | Training loss: 0.6870970353770715
Epoch: 98 | Iteration number: [2090/4518] 46% | Training loss: 0.6870959985484347
Epoch: 98 | Iteration number: [2100/4518] 46% | Training loss: 0.6870957242874872
Epoch: 98 | Iteration number: [2110/4518] 46% | Training loss: 0.6870928666320457
Epoch: 98 | Iteration number: [2120/4518] 46% | Training loss: 0.6870928259953013
Epoch: 98 | Iteration number: [2130/4518] 47% | Training loss: 0.6870847628709856
Epoch: 98 | Iteration number: [2140/4518] 47% | Training loss: 0.6870847720130582
Epoch: 98 | Iteration number: [2150/4518] 47% | Training loss: 0.6870823238616766
Epoch: 98 | Iteration number: [2160/4518] 47% | Training loss: 0.6870870538055897
Epoch: 98 | Iteration number: [2170/4518] 48% | Training loss: 0.6870825645835719
Epoch: 98 | Iteration number: [2180/4518] 48% | Training loss: 0.687090315184462
Epoch: 98 | Iteration number: [2190/4518] 48% | Training loss: 0.6870860493074269
Epoch: 98 | Iteration number: [2200/4518] 48% | Training loss: 0.6870907109975815
Epoch: 98 | Iteration number: [2210/4518] 48% | Training loss: 0.6870868758917934
Epoch: 98 | Iteration number: [2220/4518] 49% | Training loss: 0.6870858367230441
Epoch: 98 | Iteration number: [2230/4518] 49% | Training loss: 0.6870820775962196
Epoch: 98 | Iteration number: [2240/4518] 49% | Training loss: 0.6870769412389823
Epoch: 98 | Iteration number: [2250/4518] 49% | Training loss: 0.6870796404149797
Epoch: 98 | Iteration number: [2260/4518] 50% | Training loss: 0.6870791941617442
Epoch: 98 | Iteration number: [2270/4518] 50% | Training loss: 0.6870811154663825
Epoch: 98 | Iteration number: [2280/4518] 50% | Training loss: 0.6870760112739446
Epoch: 98 | Iteration number: [2290/4518] 50% | Training loss: 0.6870698887187842
Epoch: 98 | Iteration number: [2300/4518] 50% | Training loss: 0.6870653668175573
Epoch: 98 | Iteration number: [2310/4518] 51% | Training loss: 0.6870648157803011
Epoch: 98 | Iteration number: [2320/4518] 51% | Training loss: 0.6870609614869644
Epoch: 98 | Iteration number: [2330/4518] 51% | Training loss: 0.687063712623498
Epoch: 98 | Iteration number: [2340/4518] 51% | Training loss: 0.6870649314843691
Epoch: 98 | Iteration number: [2350/4518] 52% | Training loss: 0.6870653915151637
Epoch: 98 | Iteration number: [2360/4518] 52% | Training loss: 0.6870649106169151
Epoch: 98 | Iteration number: [2370/4518] 52% | Training loss: 0.687057110151661
Epoch: 98 | Iteration number: [2380/4518] 52% | Training loss: 0.6870568522886068
Epoch: 98 | Iteration number: [2390/4518] 52% | Training loss: 0.6870512551842374
Epoch: 98 | Iteration number: [2400/4518] 53% | Training loss: 0.6870449939866861
Epoch: 98 | Iteration number: [2410/4518] 53% | Training loss: 0.6870432701100947
Epoch: 98 | Iteration number: [2420/4518] 53% | Training loss: 0.6870420513566861
Epoch: 98 | Iteration number: [2430/4518] 53% | Training loss: 0.687038918949449
Epoch: 98 | Iteration number: [2440/4518] 54% | Training loss: 0.6870383705760612
Epoch: 98 | Iteration number: [2450/4518] 54% | Training loss: 0.6870382088301134
Epoch: 98 | Iteration number: [2460/4518] 54% | Training loss: 0.6870355201930535
Epoch: 98 | Iteration number: [2470/4518] 54% | Training loss: 0.6870344296399399
Epoch: 98 | Iteration number: [2480/4518] 54% | Training loss: 0.6870340782067468
Epoch: 98 | Iteration number: [2490/4518] 55% | Training loss: 0.6870360306467876
Epoch: 98 | Iteration number: [2500/4518] 55% | Training loss: 0.6870343971014022
Epoch: 98 | Iteration number: [2510/4518] 55% | Training loss: 0.687034300646459
Epoch: 98 | Iteration number: [2520/4518] 55% | Training loss: 0.6870393717809329
Epoch: 98 | Iteration number: [2530/4518] 55% | Training loss: 0.6870389338067397
Epoch: 98 | Iteration number: [2540/4518] 56% | Training loss: 0.6870318779560525
Epoch: 98 | Iteration number: [2550/4518] 56% | Training loss: 0.6870294609724307
Epoch: 98 | Iteration number: [2560/4518] 56% | Training loss: 0.687023552483879
Epoch: 98 | Iteration number: [2570/4518] 56% | Training loss: 0.6870259156718792
Epoch: 98 | Iteration number: [2580/4518] 57% | Training loss: 0.6870216218076011
Epoch: 98 | Iteration number: [2590/4518] 57% | Training loss: 0.6870180558744085
Epoch: 98 | Iteration number: [2600/4518] 57% | Training loss: 0.6870191472539535
Epoch: 98 | Iteration number: [2610/4518] 57% | Training loss: 0.6870155827524105
Epoch: 98 | Iteration number: [2620/4518] 57% | Training loss: 0.6870122196565147
Epoch: 98 | Iteration number: [2630/4518] 58% | Training loss: 0.6870082644681966
Epoch: 98 | Iteration number: [2640/4518] 58% | Training loss: 0.687003695603573
Epoch: 98 | Iteration number: [2650/4518] 58% | Training loss: 0.6870045373799666
Epoch: 98 | Iteration number: [2660/4518] 58% | Training loss: 0.687005940931184
Epoch: 98 | Iteration number: [2670/4518] 59% | Training loss: 0.6870062877399644
Epoch: 98 | Iteration number: [2680/4518] 59% | Training loss: 0.6870025480193879
Epoch: 98 | Iteration number: [2690/4518] 59% | Training loss: 0.6870019159574048
Epoch: 98 | Iteration number: [2700/4518] 59% | Training loss: 0.6870027994668042
Epoch: 98 | Iteration number: [2710/4518] 59% | Training loss: 0.6870025505878828
Epoch: 98 | Iteration number: [2720/4518] 60% | Training loss: 0.6869985487312078
Epoch: 98 | Iteration number: [2730/4518] 60% | Training loss: 0.686995042571218
Epoch: 98 | Iteration number: [2740/4518] 60% | Training loss: 0.6869950740441789
Epoch: 98 | Iteration number: [2750/4518] 60% | Training loss: 0.6869923656853762
Epoch: 98 | Iteration number: [2760/4518] 61% | Training loss: 0.6869958834371706
Epoch: 98 | Iteration number: [2770/4518] 61% | Training loss: 0.6869940593569718
Epoch: 98 | Iteration number: [2780/4518] 61% | Training loss: 0.6869974810013668
Epoch: 98 | Iteration number: [2790/4518] 61% | Training loss: 0.686999354118942
Epoch: 98 | Iteration number: [2800/4518] 61% | Training loss: 0.6869962425317083
Epoch: 98 | Iteration number: [2810/4518] 62% | Training loss: 0.6869889028980214
Epoch: 98 | Iteration number: [2820/4518] 62% | Training loss: 0.6869863017019651
Epoch: 98 | Iteration number: [2830/4518] 62% | Training loss: 0.6869862488006956
Epoch: 98 | Iteration number: [2840/4518] 62% | Training loss: 0.6869879694052146
Epoch: 98 | Iteration number: [2850/4518] 63% | Training loss: 0.6869875630997775
Epoch: 98 | Iteration number: [2860/4518] 63% | Training loss: 0.6869840480647721
Epoch: 98 | Iteration number: [2870/4518] 63% | Training loss: 0.6869832391107539
Epoch: 98 | Iteration number: [2880/4518] 63% | Training loss: 0.6869856066794859
Epoch: 98 | Iteration number: [2890/4518] 63% | Training loss: 0.6869841928300561
Epoch: 98 | Iteration number: [2900/4518] 64% | Training loss: 0.6869836606444983
Epoch: 98 | Iteration number: [2910/4518] 64% | Training loss: 0.6869863459129923
Epoch: 98 | Iteration number: [2920/4518] 64% | Training loss: 0.6869832285054742
Epoch: 98 | Iteration number: [2930/4518] 64% | Training loss: 0.6869848672237006
Epoch: 98 | Iteration number: [2940/4518] 65% | Training loss: 0.6869866652350848
Epoch: 98 | Iteration number: [2950/4518] 65% | Training loss: 0.6869860823881828
Epoch: 98 | Iteration number: [2960/4518] 65% | Training loss: 0.6869856399861543
Epoch: 98 | Iteration number: [2970/4518] 65% | Training loss: 0.6869851942014212
Epoch: 98 | Iteration number: [2980/4518] 65% | Training loss: 0.6869849810064239
Epoch: 98 | Iteration number: [2990/4518] 66% | Training loss: 0.6869840248372643
Epoch: 98 | Iteration number: [3000/4518] 66% | Training loss: 0.686980040550232
Epoch: 98 | Iteration number: [3010/4518] 66% | Training loss: 0.686977271007937
Epoch: 98 | Iteration number: [3020/4518] 66% | Training loss: 0.6869787668550251
Epoch: 98 | Iteration number: [3030/4518] 67% | Training loss: 0.6869740685614029
Epoch: 98 | Iteration number: [3040/4518] 67% | Training loss: 0.686974771771776
Epoch: 98 | Iteration number: [3050/4518] 67% | Training loss: 0.6869694204799465
Epoch: 98 | Iteration number: [3060/4518] 67% | Training loss: 0.686971005427292
Epoch: 98 | Iteration number: [3070/4518] 67% | Training loss: 0.6869672557235929
Epoch: 98 | Iteration number: [3080/4518] 68% | Training loss: 0.6869642672987727
Epoch: 98 | Iteration number: [3090/4518] 68% | Training loss: 0.6869629811507598
Epoch: 98 | Iteration number: [3100/4518] 68% | Training loss: 0.6869596647831702
Epoch: 98 | Iteration number: [3110/4518] 68% | Training loss: 0.6869606068663275
Epoch: 98 | Iteration number: [3120/4518] 69% | Training loss: 0.6869552489083547
Epoch: 98 | Iteration number: [3130/4518] 69% | Training loss: 0.6869528176304631
Epoch: 98 | Iteration number: [3140/4518] 69% | Training loss: 0.6869521940969358
Epoch: 98 | Iteration number: [3150/4518] 69% | Training loss: 0.6869541454315186
Epoch: 98 | Iteration number: [3160/4518] 69% | Training loss: 0.6869566228004951
Epoch: 98 | Iteration number: [3170/4518] 70% | Training loss: 0.6869556963819811
Epoch: 98 | Iteration number: [3180/4518] 70% | Training loss: 0.6869524997360301
Epoch: 98 | Iteration number: [3190/4518] 70% | Training loss: 0.6869538267391229
Epoch: 98 | Iteration number: [3200/4518] 70% | Training loss: 0.6869536619633436
Epoch: 98 | Iteration number: [3210/4518] 71% | Training loss: 0.686950953541515
Epoch: 98 | Iteration number: [3220/4518] 71% | Training loss: 0.686948163779626
Epoch: 98 | Iteration number: [3230/4518] 71% | Training loss: 0.6869471918318663
Epoch: 98 | Iteration number: [3240/4518] 71% | Training loss: 0.6869455131483667
Epoch: 98 | Iteration number: [3250/4518] 71% | Training loss: 0.6869449318188887
Epoch: 98 | Iteration number: [3260/4518] 72% | Training loss: 0.6869466404059182
Epoch: 98 | Iteration number: [3270/4518] 72% | Training loss: 0.6869447413205372
Epoch: 98 | Iteration number: [3280/4518] 72% | Training loss: 0.686945132747656
Epoch: 98 | Iteration number: [3290/4518] 72% | Training loss: 0.6869471158118958
Epoch: 98 | Iteration number: [3300/4518] 73% | Training loss: 0.6869491920687936
Epoch: 98 | Iteration number: [3310/4518] 73% | Training loss: 0.6869489015409234
Epoch: 98 | Iteration number: [3320/4518] 73% | Training loss: 0.6869502177978136
Epoch: 98 | Iteration number: [3330/4518] 73% | Training loss: 0.686950556956254
Epoch: 98 | Iteration number: [3340/4518] 73% | Training loss: 0.6869511132290264
Epoch: 98 | Iteration number: [3350/4518] 74% | Training loss: 0.6869500767117116
Epoch: 98 | Iteration number: [3360/4518] 74% | Training loss: 0.6869508568907068
Epoch: 98 | Iteration number: [3370/4518] 74% | Training loss: 0.6869527707644669
Epoch: 98 | Iteration number: [3380/4518] 74% | Training loss: 0.6869499107613366
Epoch: 98 | Iteration number: [3390/4518] 75% | Training loss: 0.6869479698417461
Epoch: 98 | Iteration number: [3400/4518] 75% | Training loss: 0.6869463015829815
Epoch: 98 | Iteration number: [3410/4518] 75% | Training loss: 0.6869425632387313
Epoch: 98 | Iteration number: [3420/4518] 75% | Training loss: 0.686942586145903
Epoch: 98 | Iteration number: [3430/4518] 75% | Training loss: 0.6869421549684452
Epoch: 98 | Iteration number: [3440/4518] 76% | Training loss: 0.6869419329734736
Epoch: 98 | Iteration number: [3450/4518] 76% | Training loss: 0.6869441020834273
Epoch: 98 | Iteration number: [3460/4518] 76% | Training loss: 0.6869411320700122
Epoch: 98 | Iteration number: [3470/4518] 76% | Training loss: 0.6869411689231993
Epoch: 98 | Iteration number: [3480/4518] 77% | Training loss: 0.6869440965782637
Epoch: 98 | Iteration number: [3490/4518] 77% | Training loss: 0.686941493428539
Epoch: 98 | Iteration number: [3500/4518] 77% | Training loss: 0.6869413253409522
Epoch: 98 | Iteration number: [3510/4518] 77% | Training loss: 0.6869375370336733
Epoch: 98 | Iteration number: [3520/4518] 77% | Training loss: 0.6869358929212798
Epoch: 98 | Iteration number: [3530/4518] 78% | Training loss: 0.6869372999026485
Epoch: 98 | Iteration number: [3540/4518] 78% | Training loss: 0.6869352652359817
Epoch: 98 | Iteration number: [3550/4518] 78% | Training loss: 0.6869371810765333
Epoch: 98 | Iteration number: [3560/4518] 78% | Training loss: 0.6869349053569054
Epoch: 98 | Iteration number: [3570/4518] 79% | Training loss: 0.6869384834078514
Epoch: 98 | Iteration number: [3580/4518] 79% | Training loss: 0.6869389825360069
Epoch: 98 | Iteration number: [3590/4518] 79% | Training loss: 0.6869413599164373
Epoch: 98 | Iteration number: [3600/4518] 79% | Training loss: 0.6869401076932748
Epoch: 98 | Iteration number: [3610/4518] 79% | Training loss: 0.6869390661531538
Epoch: 98 | Iteration number: [3620/4518] 80% | Training loss: 0.6869389174557523
Epoch: 98 | Iteration number: [3630/4518] 80% | Training loss: 0.6869375574358896
Epoch: 98 | Iteration number: [3640/4518] 80% | Training loss: 0.686936295556498
Epoch: 98 | Iteration number: [3650/4518] 80% | Training loss: 0.6869388204404753
Epoch: 98 | Iteration number: [3660/4518] 81% | Training loss: 0.6869367671957433
Epoch: 98 | Iteration number: [3670/4518] 81% | Training loss: 0.6869352236755537
Epoch: 98 | Iteration number: [3680/4518] 81% | Training loss: 0.6869359188591656
Epoch: 98 | Iteration number: [3690/4518] 81% | Training loss: 0.6869357714323494
Epoch: 98 | Iteration number: [3700/4518] 81% | Training loss: 0.6869373178482056
Epoch: 98 | Iteration number: [3710/4518] 82% | Training loss: 0.6869364592424942
Epoch: 98 | Iteration number: [3720/4518] 82% | Training loss: 0.686939494343855
Epoch: 98 | Iteration number: [3730/4518] 82% | Training loss: 0.6869385912175473
Epoch: 98 | Iteration number: [3740/4518] 82% | Training loss: 0.686936847411375
Epoch: 98 | Iteration number: [3750/4518] 83% | Training loss: 0.6869361716270447
Epoch: 98 | Iteration number: [3760/4518] 83% | Training loss: 0.6869397852807603
Epoch: 98 | Iteration number: [3770/4518] 83% | Training loss: 0.6869418199878157
Epoch: 98 | Iteration number: [3780/4518] 83% | Training loss: 0.686940460246076
Epoch: 98 | Iteration number: [3790/4518] 83% | Training loss: 0.6869406827364245
Epoch: 98 | Iteration number: [3800/4518] 84% | Training loss: 0.6869434471349967
Epoch: 98 | Iteration number: [3810/4518] 84% | Training loss: 0.6869430995988721
Epoch: 98 | Iteration number: [3820/4518] 84% | Training loss: 0.6869423991878619
Epoch: 98 | Iteration number: [3830/4518] 84% | Training loss: 0.6869421353850601
Epoch: 98 | Iteration number: [3840/4518] 84% | Training loss: 0.6869402241582672
Epoch: 98 | Iteration number: [3850/4518] 85% | Training loss: 0.6869404751294619
Epoch: 98 | Iteration number: [3860/4518] 85% | Training loss: 0.6869365918358373
Epoch: 98 | Iteration number: [3870/4518] 85% | Training loss: 0.6869401058639358
Epoch: 98 | Iteration number: [3880/4518] 85% | Training loss: 0.6869392047684217
Epoch: 98 | Iteration number: [3890/4518] 86% | Training loss: 0.6869395107260706
Epoch: 98 | Iteration number: [3900/4518] 86% | Training loss: 0.6869366280237834
Epoch: 98 | Iteration number: [3910/4518] 86% | Training loss: 0.6869373897914691
Epoch: 98 | Iteration number: [3920/4518] 86% | Training loss: 0.6869367613780255
Epoch: 98 | Iteration number: [3930/4518] 86% | Training loss: 0.6869359783392219
Epoch: 98 | Iteration number: [3940/4518] 87% | Training loss: 0.6869338110618785
Epoch: 98 | Iteration number: [3950/4518] 87% | Training loss: 0.686936859435673
Epoch: 98 | Iteration number: [3960/4518] 87% | Training loss: 0.6869382359162726
Epoch: 98 | Iteration number: [3970/4518] 87% | Training loss: 0.6869370951610488
Epoch: 98 | Iteration number: [3980/4518] 88% | Training loss: 0.6869365992707823
Epoch: 98 | Iteration number: [3990/4518] 88% | Training loss: 0.6869365136724964
Epoch: 98 | Iteration number: [4000/4518] 88% | Training loss: 0.6869348749220371
Epoch: 98 | Iteration number: [4010/4518] 88% | Training loss: 0.6869352022608617
Epoch: 98 | Iteration number: [4020/4518] 88% | Training loss: 0.686934807244225
Epoch: 98 | Iteration number: [4030/4518] 89% | Training loss: 0.6869334420406493
Epoch: 98 | Iteration number: [4040/4518] 89% | Training loss: 0.6869334764999918
Epoch: 98 | Iteration number: [4050/4518] 89% | Training loss: 0.6869332882357232
Epoch: 98 | Iteration number: [4060/4518] 89% | Training loss: 0.6869283539761464
Epoch: 98 | Iteration number: [4070/4518] 90% | Training loss: 0.6869278596132921
Epoch: 98 | Iteration number: [4080/4518] 90% | Training loss: 0.6869300962517074
Epoch: 98 | Iteration number: [4090/4518] 90% | Training loss: 0.6869303176630388
Epoch: 98 | Iteration number: [4100/4518] 90% | Training loss: 0.6869288784992404
Epoch: 98 | Iteration number: [4110/4518] 90% | Training loss: 0.686926924196183
Epoch: 98 | Iteration number: [4120/4518] 91% | Training loss: 0.6869263163035356
Epoch: 98 | Iteration number: [4130/4518] 91% | Training loss: 0.6869239906999158
Epoch: 98 | Iteration number: [4140/4518] 91% | Training loss: 0.6869230776161387
Epoch: 98 | Iteration number: [4150/4518] 91% | Training loss: 0.686923815213054
Epoch: 98 | Iteration number: [4160/4518] 92% | Training loss: 0.6869220670742484
Epoch: 98 | Iteration number: [4170/4518] 92% | Training loss: 0.6869246561607297
Epoch: 98 | Iteration number: [4180/4518] 92% | Training loss: 0.6869276318681297
Epoch: 98 | Iteration number: [4190/4518] 92% | Training loss: 0.6869263081533528
Epoch: 98 | Iteration number: [4200/4518] 92% | Training loss: 0.6869257110783032
Epoch: 98 | Iteration number: [4210/4518] 93% | Training loss: 0.6869225727124338
Epoch: 98 | Iteration number: [4220/4518] 93% | Training loss: 0.6869216539001013
Epoch: 98 | Iteration number: [4230/4518] 93% | Training loss: 0.6869193971157074
Epoch: 98 | Iteration number: [4240/4518] 93% | Training loss: 0.6869219675941287
Epoch: 98 | Iteration number: [4250/4518] 94% | Training loss: 0.6869232528490179
Epoch: 98 | Iteration number: [4260/4518] 94% | Training loss: 0.6869231932879614
Epoch: 98 | Iteration number: [4270/4518] 94% | Training loss: 0.6869222106503658
Epoch: 98 | Iteration number: [4280/4518] 94% | Training loss: 0.6869205663415873
Epoch: 98 | Iteration number: [4290/4518] 94% | Training loss: 0.686917832500729
Epoch: 98 | Iteration number: [4300/4518] 95% | Training loss: 0.6869158267974853
Epoch: 98 | Iteration number: [4310/4518] 95% | Training loss: 0.6869146952911209
Epoch: 98 | Iteration number: [4320/4518] 95% | Training loss: 0.6869138564224596
Epoch: 98 | Iteration number: [4330/4518] 95% | Training loss: 0.6869128820527233
Epoch: 98 | Iteration number: [4340/4518] 96% | Training loss: 0.6869112306476188
Epoch: 98 | Iteration number: [4350/4518] 96% | Training loss: 0.6869122150985674
Epoch: 98 | Iteration number: [4360/4518] 96% | Training loss: 0.6869084756582156
Epoch: 98 | Iteration number: [4370/4518] 96% | Training loss: 0.6869106048577437
Epoch: 98 | Iteration number: [4380/4518] 96% | Training loss: 0.6869119743233947
Epoch: 98 | Iteration number: [4390/4518] 97% | Training loss: 0.6869105752481144
Epoch: 98 | Iteration number: [4400/4518] 97% | Training loss: 0.686911191818389
Epoch: 98 | Iteration number: [4410/4518] 97% | Training loss: 0.6869112310496047
Epoch: 98 | Iteration number: [4420/4518] 97% | Training loss: 0.6869131197082511
Epoch: 98 | Iteration number: [4430/4518] 98% | Training loss: 0.6869133001794664
Epoch: 98 | Iteration number: [4440/4518] 98% | Training loss: 0.6869125640070116
Epoch: 98 | Iteration number: [4450/4518] 98% | Training loss: 0.6869102474009053
Epoch: 98 | Iteration number: [4460/4518] 98% | Training loss: 0.6869118687817869
Epoch: 98 | Iteration number: [4470/4518] 98% | Training loss: 0.6869069128495201
Epoch: 98 | Iteration number: [4480/4518] 99% | Training loss: 0.6869078458819006
Epoch: 98 | Iteration number: [4490/4518] 99% | Training loss: 0.6869049873410461
Epoch: 98 | Iteration number: [4500/4518] 99% | Training loss: 0.6869073773490058
Epoch: 98 | Iteration number: [4510/4518] 99% | Training loss: 0.6869091630114156

 End of epoch: 98 | Train Loss: 0.6867570727733766 | Training Time: 643 

 End of epoch: 98 | Eval Loss: 0.6899092842121514 | Evaluating Time: 17 
Epoch: 99 | Iteration number: [10/4518] 0% | Training loss: 0.75668363571167
Epoch: 99 | Iteration number: [20/4518] 0% | Training loss: 0.7221439152956008
Epoch: 99 | Iteration number: [30/4518] 0% | Training loss: 0.7098947127660116
Epoch: 99 | Iteration number: [40/4518] 0% | Training loss: 0.7042535826563835
Epoch: 99 | Iteration number: [50/4518] 1% | Training loss: 0.7008096647262573
Epoch: 99 | Iteration number: [60/4518] 1% | Training loss: 0.6985444217920304
Epoch: 99 | Iteration number: [70/4518] 1% | Training loss: 0.696581826891218
Epoch: 99 | Iteration number: [80/4518] 1% | Training loss: 0.6953286282718182
Epoch: 99 | Iteration number: [90/4518] 1% | Training loss: 0.6943351414468554
Epoch: 99 | Iteration number: [100/4518] 2% | Training loss: 0.6934261983633041
Epoch: 99 | Iteration number: [110/4518] 2% | Training loss: 0.6929593438451941
Epoch: 99 | Iteration number: [120/4518] 2% | Training loss: 0.6924515793720881
Epoch: 99 | Iteration number: [130/4518] 2% | Training loss: 0.6921084532370934
Epoch: 99 | Iteration number: [140/4518] 3% | Training loss: 0.6917088495833533
Epoch: 99 | Iteration number: [150/4518] 3% | Training loss: 0.6914454809824626
Epoch: 99 | Iteration number: [160/4518] 3% | Training loss: 0.691211624071002
Epoch: 99 | Iteration number: [170/4518] 3% | Training loss: 0.690992902657565
Epoch: 99 | Iteration number: [180/4518] 3% | Training loss: 0.6907366388373904
Epoch: 99 | Iteration number: [190/4518] 4% | Training loss: 0.6904926039670644
Epoch: 99 | Iteration number: [200/4518] 4% | Training loss: 0.6902994719147683
Epoch: 99 | Iteration number: [210/4518] 4% | Training loss: 0.69011272305534
Epoch: 99 | Iteration number: [220/4518] 4% | Training loss: 0.689981334046884
Epoch: 99 | Iteration number: [230/4518] 5% | Training loss: 0.6898485292559084
Epoch: 99 | Iteration number: [240/4518] 5% | Training loss: 0.6897015196581682
Epoch: 99 | Iteration number: [250/4518] 5% | Training loss: 0.6895909767150878
Epoch: 99 | Iteration number: [260/4518] 5% | Training loss: 0.6894493671563956
Epoch: 99 | Iteration number: [270/4518] 5% | Training loss: 0.6893458953610173
Epoch: 99 | Iteration number: [280/4518] 6% | Training loss: 0.6893022903374263
Epoch: 99 | Iteration number: [290/4518] 6% | Training loss: 0.689189690968086
Epoch: 99 | Iteration number: [300/4518] 6% | Training loss: 0.6890931198994319
Epoch: 99 | Iteration number: [310/4518] 6% | Training loss: 0.6890286159130835
Epoch: 99 | Iteration number: [320/4518] 7% | Training loss: 0.6889614017680288
Epoch: 99 | Iteration number: [330/4518] 7% | Training loss: 0.6889228194048911
Epoch: 99 | Iteration number: [340/4518] 7% | Training loss: 0.6888494794859605
Epoch: 99 | Iteration number: [350/4518] 7% | Training loss: 0.6887805867195129
Epoch: 99 | Iteration number: [360/4518] 7% | Training loss: 0.6887119566400846
Epoch: 99 | Iteration number: [370/4518] 8% | Training loss: 0.6886181749202109
Epoch: 99 | Iteration number: [380/4518] 8% | Training loss: 0.6885625022022348
Epoch: 99 | Iteration number: [390/4518] 8% | Training loss: 0.6885203471550575
Epoch: 99 | Iteration number: [400/4518] 8% | Training loss: 0.6884836357831955
Epoch: 99 | Iteration number: [410/4518] 9% | Training loss: 0.6884169719568113
Epoch: 99 | Iteration number: [420/4518] 9% | Training loss: 0.6883543488525209
Epoch: 99 | Iteration number: [430/4518] 9% | Training loss: 0.6883194209531296
Epoch: 99 | Iteration number: [440/4518] 9% | Training loss: 0.6883155026219108
Epoch: 99 | Iteration number: [450/4518] 9% | Training loss: 0.6883023256725735
Epoch: 99 | Iteration number: [460/4518] 10% | Training loss: 0.6882691595865332
Epoch: 99 | Iteration number: [470/4518] 10% | Training loss: 0.6882172546488173
Epoch: 99 | Iteration number: [480/4518] 10% | Training loss: 0.6882025515039761
Epoch: 99 | Iteration number: [490/4518] 10% | Training loss: 0.6881603057287178
Epoch: 99 | Iteration number: [500/4518] 11% | Training loss: 0.6881463820934296
Epoch: 99 | Iteration number: [510/4518] 11% | Training loss: 0.6881319186266731
Epoch: 99 | Iteration number: [520/4518] 11% | Training loss: 0.6881090636436756
Epoch: 99 | Iteration number: [530/4518] 11% | Training loss: 0.6881100976242209
Epoch: 99 | Iteration number: [540/4518] 11% | Training loss: 0.6881130278110504
Epoch: 99 | Iteration number: [550/4518] 12% | Training loss: 0.6880953446301546
Epoch: 99 | Iteration number: [560/4518] 12% | Training loss: 0.6880838379263878
Epoch: 99 | Iteration number: [570/4518] 12% | Training loss: 0.688068970253593
Epoch: 99 | Iteration number: [580/4518] 12% | Training loss: 0.6880761221565049
Epoch: 99 | Iteration number: [590/4518] 13% | Training loss: 0.6880779553267915
Epoch: 99 | Iteration number: [600/4518] 13% | Training loss: 0.6880577675501506
Epoch: 99 | Iteration number: [610/4518] 13% | Training loss: 0.6880041993055187
Epoch: 99 | Iteration number: [620/4518] 13% | Training loss: 0.6879824002904277
Epoch: 99 | Iteration number: [630/4518] 13% | Training loss: 0.6879870341883765
Epoch: 99 | Iteration number: [640/4518] 14% | Training loss: 0.6879736627452075
Epoch: 99 | Iteration number: [650/4518] 14% | Training loss: 0.687961657689168
Epoch: 99 | Iteration number: [660/4518] 14% | Training loss: 0.6879461887207898
Epoch: 99 | Iteration number: [670/4518] 14% | Training loss: 0.6879279390199861
Epoch: 99 | Iteration number: [680/4518] 15% | Training loss: 0.6878954009098165
Epoch: 99 | Iteration number: [690/4518] 15% | Training loss: 0.6878581814143969
Epoch: 99 | Iteration number: [700/4518] 15% | Training loss: 0.6878339861120496
Epoch: 99 | Iteration number: [710/4518] 15% | Training loss: 0.6878328313290233
Epoch: 99 | Iteration number: [720/4518] 15% | Training loss: 0.687824055718051
Epoch: 99 | Iteration number: [730/4518] 16% | Training loss: 0.6877852798324742
Epoch: 99 | Iteration number: [740/4518] 16% | Training loss: 0.6877748326675311
Epoch: 99 | Iteration number: [750/4518] 16% | Training loss: 0.6877701700528462
Epoch: 99 | Iteration number: [760/4518] 16% | Training loss: 0.6877377995534947
Epoch: 99 | Iteration number: [770/4518] 17% | Training loss: 0.6877286354442695
Epoch: 99 | Iteration number: [780/4518] 17% | Training loss: 0.6877029778101506
Epoch: 99 | Iteration number: [790/4518] 17% | Training loss: 0.6876974185056324
Epoch: 99 | Iteration number: [800/4518] 17% | Training loss: 0.6876833534240723
Epoch: 99 | Iteration number: [810/4518] 17% | Training loss: 0.6876775603971363
Epoch: 99 | Iteration number: [820/4518] 18% | Training loss: 0.6876625790101726
Epoch: 99 | Iteration number: [830/4518] 18% | Training loss: 0.6876491052558623
Epoch: 99 | Iteration number: [840/4518] 18% | Training loss: 0.6876388329835165
Epoch: 99 | Iteration number: [850/4518] 18% | Training loss: 0.6876233754438512
Epoch: 99 | Iteration number: [860/4518] 19% | Training loss: 0.6876193032708279
Epoch: 99 | Iteration number: [870/4518] 19% | Training loss: 0.6875991702079773
Epoch: 99 | Iteration number: [880/4518] 19% | Training loss: 0.6876026668331839
Epoch: 99 | Iteration number: [890/4518] 19% | Training loss: 0.6875925427072503
Epoch: 99 | Iteration number: [900/4518] 19% | Training loss: 0.6875696306096183
Epoch: 99 | Iteration number: [910/4518] 20% | Training loss: 0.687573334803948
Epoch: 99 | Iteration number: [920/4518] 20% | Training loss: 0.6875729789552482
Epoch: 99 | Iteration number: [930/4518] 20% | Training loss: 0.687552955009604
Epoch: 99 | Iteration number: [940/4518] 20% | Training loss: 0.6875342428050143
Epoch: 99 | Iteration number: [950/4518] 21% | Training loss: 0.6875196470084943
Epoch: 99 | Iteration number: [960/4518] 21% | Training loss: 0.6875015982116263
Epoch: 99 | Iteration number: [970/4518] 21% | Training loss: 0.687476222293893
Epoch: 99 | Iteration number: [980/4518] 21% | Training loss: 0.6874579632768826
Epoch: 99 | Iteration number: [990/4518] 21% | Training loss: 0.6874465256628364
Epoch: 99 | Iteration number: [1000/4518] 22% | Training loss: 0.6874365020990372
Epoch: 99 | Iteration number: [1010/4518] 22% | Training loss: 0.6874333702101566
Epoch: 99 | Iteration number: [1020/4518] 22% | Training loss: 0.6874306622673484
Epoch: 99 | Iteration number: [1030/4518] 22% | Training loss: 0.6874189902277826
Epoch: 99 | Iteration number: [1040/4518] 23% | Training loss: 0.6874042941973759
Epoch: 99 | Iteration number: [1050/4518] 23% | Training loss: 0.687396612791788
Epoch: 99 | Iteration number: [1060/4518] 23% | Training loss: 0.6873909121414401
Epoch: 99 | Iteration number: [1070/4518] 23% | Training loss: 0.6873911948961632
Epoch: 99 | Iteration number: [1080/4518] 23% | Training loss: 0.687384483659709
Epoch: 99 | Iteration number: [1090/4518] 24% | Training loss: 0.6873657731834901
Epoch: 99 | Iteration number: [1100/4518] 24% | Training loss: 0.6873665714263916
Epoch: 99 | Iteration number: [1110/4518] 24% | Training loss: 0.6873549371689289
Epoch: 99 | Iteration number: [1120/4518] 24% | Training loss: 0.6873554356396199
Epoch: 99 | Iteration number: [1130/4518] 25% | Training loss: 0.6873520640145361
Epoch: 99 | Iteration number: [1140/4518] 25% | Training loss: 0.6873445031935709
Epoch: 99 | Iteration number: [1150/4518] 25% | Training loss: 0.6873443164514459
Epoch: 99 | Iteration number: [1160/4518] 25% | Training loss: 0.6873331396744169
Epoch: 99 | Iteration number: [1170/4518] 25% | Training loss: 0.6873207229324895
Epoch: 99 | Iteration number: [1180/4518] 26% | Training loss: 0.687324396634506
Epoch: 99 | Iteration number: [1190/4518] 26% | Training loss: 0.6873136088627727
Epoch: 99 | Iteration number: [1200/4518] 26% | Training loss: 0.6873096086581548
Epoch: 99 | Iteration number: [1210/4518] 26% | Training loss: 0.6873029403450075
Epoch: 99 | Iteration number: [1220/4518] 27% | Training loss: 0.687288027220085
Epoch: 99 | Iteration number: [1230/4518] 27% | Training loss: 0.6872951068044678
Epoch: 99 | Iteration number: [1240/4518] 27% | Training loss: 0.6872783687806898
Epoch: 99 | Iteration number: [1250/4518] 27% | Training loss: 0.6872766113758088
Epoch: 99 | Iteration number: [1260/4518] 27% | Training loss: 0.687260642789659
Epoch: 99 | Iteration number: [1270/4518] 28% | Training loss: 0.6872480704559116
Epoch: 99 | Iteration number: [1280/4518] 28% | Training loss: 0.6872556724119931
Epoch: 99 | Iteration number: [1290/4518] 28% | Training loss: 0.687237542405609
Epoch: 99 | Iteration number: [1300/4518] 28% | Training loss: 0.6872359780164865
Epoch: 99 | Iteration number: [1310/4518] 28% | Training loss: 0.6872354508811281
Epoch: 99 | Iteration number: [1320/4518] 29% | Training loss: 0.6872386342648303
Epoch: 99 | Iteration number: [1330/4518] 29% | Training loss: 0.6872373731512772
Epoch: 99 | Iteration number: [1340/4518] 29% | Training loss: 0.6872273516743931
Epoch: 99 | Iteration number: [1350/4518] 29% | Training loss: 0.6872259739151707
Epoch: 99 | Iteration number: [1360/4518] 30% | Training loss: 0.6872196536292048
Epoch: 99 | Iteration number: [1370/4518] 30% | Training loss: 0.6872188906600005
Epoch: 99 | Iteration number: [1380/4518] 30% | Training loss: 0.6872101286183233
Epoch: 99 | Iteration number: [1390/4518] 30% | Training loss: 0.6872122747863797
Epoch: 99 | Iteration number: [1400/4518] 30% | Training loss: 0.6871988551957267
Epoch: 99 | Iteration number: [1410/4518] 31% | Training loss: 0.6871941653971977
Epoch: 99 | Iteration number: [1420/4518] 31% | Training loss: 0.6871930571089329
Epoch: 99 | Iteration number: [1430/4518] 31% | Training loss: 0.6871900993627268
Epoch: 99 | Iteration number: [1440/4518] 31% | Training loss: 0.6871883297959963
Epoch: 99 | Iteration number: [1450/4518] 32% | Training loss: 0.6871821925557893
Epoch: 99 | Iteration number: [1460/4518] 32% | Training loss: 0.6871773049439469
Epoch: 99 | Iteration number: [1470/4518] 32% | Training loss: 0.6871784474573979
Epoch: 99 | Iteration number: [1480/4518] 32% | Training loss: 0.687181629844614
Epoch: 99 | Iteration number: [1490/4518] 32% | Training loss: 0.6871788919772077
Epoch: 99 | Iteration number: [1500/4518] 33% | Training loss: 0.6871716692050298
Epoch: 99 | Iteration number: [1510/4518] 33% | Training loss: 0.6871719087591235
Epoch: 99 | Iteration number: [1520/4518] 33% | Training loss: 0.6871740819984361
Epoch: 99 | Iteration number: [1530/4518] 33% | Training loss: 0.6871759074186188
Epoch: 99 | Iteration number: [1540/4518] 34% | Training loss: 0.6871719295715357
Epoch: 99 | Iteration number: [1550/4518] 34% | Training loss: 0.6871703519359712
Epoch: 99 | Iteration number: [1560/4518] 34% | Training loss: 0.6871673347476202
Epoch: 99 | Iteration number: [1570/4518] 34% | Training loss: 0.6871674703564613
Epoch: 99 | Iteration number: [1580/4518] 34% | Training loss: 0.6871775501136539
Epoch: 99 | Iteration number: [1590/4518] 35% | Training loss: 0.6871694750755838
Epoch: 99 | Iteration number: [1600/4518] 35% | Training loss: 0.6871735541522503
Epoch: 99 | Iteration number: [1610/4518] 35% | Training loss: 0.6871675757517726
Epoch: 99 | Iteration number: [1620/4518] 35% | Training loss: 0.6871608357002705
Epoch: 99 | Iteration number: [1630/4518] 36% | Training loss: 0.6871672262809028
Epoch: 99 | Iteration number: [1640/4518] 36% | Training loss: 0.6871698529255099
Epoch: 99 | Iteration number: [1650/4518] 36% | Training loss: 0.6871674042398279
Epoch: 99 | Iteration number: [1660/4518] 36% | Training loss: 0.6871609153876822
Epoch: 99 | Iteration number: [1670/4518] 36% | Training loss: 0.6871658505079989
Epoch: 99 | Iteration number: [1680/4518] 37% | Training loss: 0.6871574139311201
Epoch: 99 | Iteration number: [1690/4518] 37% | Training loss: 0.6871567957500029
Epoch: 99 | Iteration number: [1700/4518] 37% | Training loss: 0.6871571335021187
Epoch: 99 | Iteration number: [1710/4518] 37% | Training loss: 0.687151759270339
Epoch: 99 | Iteration number: [1720/4518] 38% | Training loss: 0.6871366476596787
Epoch: 99 | Iteration number: [1730/4518] 38% | Training loss: 0.6871324870972275
Epoch: 99 | Iteration number: [1740/4518] 38% | Training loss: 0.6871250380387252
Epoch: 99 | Iteration number: [1750/4518] 38% | Training loss: 0.687126302582877
Epoch: 99 | Iteration number: [1760/4518] 38% | Training loss: 0.687126794254238
Epoch: 99 | Iteration number: [1770/4518] 39% | Training loss: 0.6871282182844345
Epoch: 99 | Iteration number: [1780/4518] 39% | Training loss: 0.6871182339914729
Epoch: 99 | Iteration number: [1790/4518] 39% | Training loss: 0.6871190560929602
Epoch: 99 | Iteration number: [1800/4518] 39% | Training loss: 0.6871181953615613
Epoch: 99 | Iteration number: [1810/4518] 40% | Training loss: 0.6871141980366153
Epoch: 99 | Iteration number: [1820/4518] 40% | Training loss: 0.6871115685491771
Epoch: 99 | Iteration number: [1830/4518] 40% | Training loss: 0.6871153504796367
Epoch: 99 | Iteration number: [1840/4518] 40% | Training loss: 0.687112245708704
Epoch: 99 | Iteration number: [1850/4518] 40% | Training loss: 0.687106386068705
Epoch: 99 | Iteration number: [1860/4518] 41% | Training loss: 0.6871030674826715
Epoch: 99 | Iteration number: [1870/4518] 41% | Training loss: 0.687103438536751
Epoch: 99 | Iteration number: [1880/4518] 41% | Training loss: 0.6871027008967197
Epoch: 99 | Iteration number: [1890/4518] 41% | Training loss: 0.6870990934195342
Epoch: 99 | Iteration number: [1900/4518] 42% | Training loss: 0.6870942023239638
Epoch: 99 | Iteration number: [1910/4518] 42% | Training loss: 0.687087792969499
Epoch: 99 | Iteration number: [1920/4518] 42% | Training loss: 0.6870824018803735
Epoch: 99 | Iteration number: [1930/4518] 42% | Training loss: 0.6870722404415743
Epoch: 99 | Iteration number: [1940/4518] 42% | Training loss: 0.6870717919671658
Epoch: 99 | Iteration number: [1950/4518] 43% | Training loss: 0.6870720283801739
Epoch: 99 | Iteration number: [1960/4518] 43% | Training loss: 0.6870671385709121
Epoch: 99 | Iteration number: [1970/4518] 43% | Training loss: 0.6870756179548158
Epoch: 99 | Iteration number: [1980/4518] 43% | Training loss: 0.6870824841537861
Epoch: 99 | Iteration number: [1990/4518] 44% | Training loss: 0.6870813198724584
Epoch: 99 | Iteration number: [2000/4518] 44% | Training loss: 0.6870716487765313
Epoch: 99 | Iteration number: [2010/4518] 44% | Training loss: 0.6870722863804641
Epoch: 99 | Iteration number: [2020/4518] 44% | Training loss: 0.6870736704014315
Epoch: 99 | Iteration number: [2030/4518] 44% | Training loss: 0.6870718344972638
Epoch: 99 | Iteration number: [2040/4518] 45% | Training loss: 0.687067530727854
Epoch: 99 | Iteration number: [2050/4518] 45% | Training loss: 0.6870609851581294
Epoch: 99 | Iteration number: [2060/4518] 45% | Training loss: 0.6870642326699877
Epoch: 99 | Iteration number: [2070/4518] 45% | Training loss: 0.6870711724827255
Epoch: 99 | Iteration number: [2080/4518] 46% | Training loss: 0.6870704603023254
Epoch: 99 | Iteration number: [2090/4518] 46% | Training loss: 0.6870701524344358
Epoch: 99 | Iteration number: [2100/4518] 46% | Training loss: 0.687064838608106
Epoch: 99 | Iteration number: [2110/4518] 46% | Training loss: 0.687053823979545
Epoch: 99 | Iteration number: [2120/4518] 46% | Training loss: 0.6870576477838013
Epoch: 99 | Iteration number: [2130/4518] 47% | Training loss: 0.6870600648329291
Epoch: 99 | Iteration number: [2140/4518] 47% | Training loss: 0.687053615829655
Epoch: 99 | Iteration number: [2150/4518] 47% | Training loss: 0.687049253319585
Epoch: 99 | Iteration number: [2160/4518] 47% | Training loss: 0.6870489589318082
Epoch: 99 | Iteration number: [2170/4518] 48% | Training loss: 0.687043972581213
Epoch: 99 | Iteration number: [2180/4518] 48% | Training loss: 0.6870358644822322
Epoch: 99 | Iteration number: [2190/4518] 48% | Training loss: 0.6870363218599258
Epoch: 99 | Iteration number: [2200/4518] 48% | Training loss: 0.6870360247384418
Epoch: 99 | Iteration number: [2210/4518] 48% | Training loss: 0.6870340550916767
Epoch: 99 | Iteration number: [2220/4518] 49% | Training loss: 0.6870358181966317
Epoch: 99 | Iteration number: [2230/4518] 49% | Training loss: 0.6870317561209469
Epoch: 99 | Iteration number: [2240/4518] 49% | Training loss: 0.6870295765410577
Epoch: 99 | Iteration number: [2250/4518] 49% | Training loss: 0.687029783407847
Epoch: 99 | Iteration number: [2260/4518] 50% | Training loss: 0.6870234547199401
Epoch: 99 | Iteration number: [2270/4518] 50% | Training loss: 0.6870212788623861
Epoch: 99 | Iteration number: [2280/4518] 50% | Training loss: 0.6870192067403542
Epoch: 99 | Iteration number: [2290/4518] 50% | Training loss: 0.6870199718850148
Epoch: 99 | Iteration number: [2300/4518] 50% | Training loss: 0.6870201474946478
Epoch: 99 | Iteration number: [2310/4518] 51% | Training loss: 0.6870218351547852
Epoch: 99 | Iteration number: [2320/4518] 51% | Training loss: 0.6870171184683668
Epoch: 99 | Iteration number: [2330/4518] 51% | Training loss: 0.6870057427576172
Epoch: 99 | Iteration number: [2340/4518] 51% | Training loss: 0.6870039127830766
Epoch: 99 | Iteration number: [2350/4518] 52% | Training loss: 0.6870047783851624
Epoch: 99 | Iteration number: [2360/4518] 52% | Training loss: 0.6870040199261601
Epoch: 99 | Iteration number: [2370/4518] 52% | Training loss: 0.6870002007937129
Epoch: 99 | Iteration number: [2380/4518] 52% | Training loss: 0.6869994927354219
Epoch: 99 | Iteration number: [2390/4518] 52% | Training loss: 0.6869991144126429
Epoch: 99 | Iteration number: [2400/4518] 53% | Training loss: 0.6870000413060189
Epoch: 99 | Iteration number: [2410/4518] 53% | Training loss: 0.6869916175163633
Epoch: 99 | Iteration number: [2420/4518] 53% | Training loss: 0.6869914139105269
Epoch: 99 | Iteration number: [2430/4518] 53% | Training loss: 0.6869878345310934
Epoch: 99 | Iteration number: [2440/4518] 54% | Training loss: 0.6869888924917237
Epoch: 99 | Iteration number: [2450/4518] 54% | Training loss: 0.6869891184446762
Epoch: 99 | Iteration number: [2460/4518] 54% | Training loss: 0.6869872285583155
Epoch: 99 | Iteration number: [2470/4518] 54% | Training loss: 0.6869857068727856
Epoch: 99 | Iteration number: [2480/4518] 54% | Training loss: 0.6869910951823958
Epoch: 99 | Iteration number: [2490/4518] 55% | Training loss: 0.6869916084540417
Epoch: 99 | Iteration number: [2500/4518] 55% | Training loss: 0.6869917627334595
Epoch: 99 | Iteration number: [2510/4518] 55% | Training loss: 0.6869915612665306
Epoch: 99 | Iteration number: [2520/4518] 55% | Training loss: 0.6869927706699522
Epoch: 99 | Iteration number: [2530/4518] 55% | Training loss: 0.6869877409793642
Epoch: 99 | Iteration number: [2540/4518] 56% | Training loss: 0.6869859358222465
Epoch: 99 | Iteration number: [2550/4518] 56% | Training loss: 0.6869816274502698
Epoch: 99 | Iteration number: [2560/4518] 56% | Training loss: 0.6869821908418089
Epoch: 99 | Iteration number: [2570/4518] 56% | Training loss: 0.6869811308523096
Epoch: 99 | Iteration number: [2580/4518] 57% | Training loss: 0.6869789561559988
Epoch: 99 | Iteration number: [2590/4518] 57% | Training loss: 0.6869781731868803
Epoch: 99 | Iteration number: [2600/4518] 57% | Training loss: 0.6869711032051307
Epoch: 99 | Iteration number: [2610/4518] 57% | Training loss: 0.6869704022261375
Epoch: 99 | Iteration number: [2620/4518] 57% | Training loss: 0.6869714275798725
Epoch: 99 | Iteration number: [2630/4518] 58% | Training loss: 0.6869676164121229
Epoch: 99 | Iteration number: [2640/4518] 58% | Training loss: 0.6869680491586526
Epoch: 99 | Iteration number: [2650/4518] 58% | Training loss: 0.6869670231612224
Epoch: 99 | Iteration number: [2660/4518] 58% | Training loss: 0.686971056573373
Epoch: 99 | Iteration number: [2670/4518] 59% | Training loss: 0.6869740395510241
Epoch: 99 | Iteration number: [2680/4518] 59% | Training loss: 0.6869762703109143
Epoch: 99 | Iteration number: [2690/4518] 59% | Training loss: 0.6869736015131925
Epoch: 99 | Iteration number: [2700/4518] 59% | Training loss: 0.6869709947815648
Epoch: 99 | Iteration number: [2710/4518] 59% | Training loss: 0.6869684948032633
Epoch: 99 | Iteration number: [2720/4518] 60% | Training loss: 0.6869677729904652
Epoch: 99 | Iteration number: [2730/4518] 60% | Training loss: 0.6869714307042706
Epoch: 99 | Iteration number: [2740/4518] 60% | Training loss: 0.6869668709970739
Epoch: 99 | Iteration number: [2750/4518] 60% | Training loss: 0.686964486729015
Epoch: 99 | Iteration number: [2760/4518] 61% | Training loss: 0.6869680699015009
Epoch: 99 | Iteration number: [2770/4518] 61% | Training loss: 0.686965099246063
Epoch: 99 | Iteration number: [2780/4518] 61% | Training loss: 0.686963896678506
Epoch: 99 | Iteration number: [2790/4518] 61% | Training loss: 0.686961206868558
Epoch: 99 | Iteration number: [2800/4518] 61% | Training loss: 0.6869636198665414
Epoch: 99 | Iteration number: [2810/4518] 62% | Training loss: 0.6869618638554502
Epoch: 99 | Iteration number: [2820/4518] 62% | Training loss: 0.68696195170389
Epoch: 99 | Iteration number: [2830/4518] 62% | Training loss: 0.6869558549390665
Epoch: 99 | Iteration number: [2840/4518] 62% | Training loss: 0.6869560500685598
Epoch: 99 | Iteration number: [2850/4518] 63% | Training loss: 0.6869554695539307
Epoch: 99 | Iteration number: [2860/4518] 63% | Training loss: 0.6869529917523578
Epoch: 99 | Iteration number: [2870/4518] 63% | Training loss: 0.6869538384862893
Epoch: 99 | Iteration number: [2880/4518] 63% | Training loss: 0.6869544340918462
Epoch: 99 | Iteration number: [2890/4518] 63% | Training loss: 0.6869537900063406
Epoch: 99 | Iteration number: [2900/4518] 64% | Training loss: 0.6869549586855132
Epoch: 99 | Iteration number: [2910/4518] 64% | Training loss: 0.686952449734678
Epoch: 99 | Iteration number: [2920/4518] 64% | Training loss: 0.6869565957825478
Epoch: 99 | Iteration number: [2930/4518] 64% | Training loss: 0.6869543492387179
Epoch: 99 | Iteration number: [2940/4518] 65% | Training loss: 0.6869536336790136
Epoch: 99 | Iteration number: [2950/4518] 65% | Training loss: 0.6869491566439806
Epoch: 99 | Iteration number: [2960/4518] 65% | Training loss: 0.6869508401767628
Epoch: 99 | Iteration number: [2970/4518] 65% | Training loss: 0.6869552688365833
Epoch: 99 | Iteration number: [2980/4518] 65% | Training loss: 0.6869524323300227
Epoch: 99 | Iteration number: [2990/4518] 66% | Training loss: 0.6869487731153749
Epoch: 99 | Iteration number: [3000/4518] 66% | Training loss: 0.6869486413399378
Epoch: 99 | Iteration number: [3010/4518] 66% | Training loss: 0.6869474414377117
Epoch: 99 | Iteration number: [3020/4518] 66% | Training loss: 0.6869431588231333
Epoch: 99 | Iteration number: [3030/4518] 67% | Training loss: 0.6869412229202762
Epoch: 99 | Iteration number: [3040/4518] 67% | Training loss: 0.6869356396951174
Epoch: 99 | Iteration number: [3050/4518] 67% | Training loss: 0.6869298388723467
Epoch: 99 | Iteration number: [3060/4518] 67% | Training loss: 0.6869254328261793
Epoch: 99 | Iteration number: [3070/4518] 67% | Training loss: 0.6869240323378908
Epoch: 99 | Iteration number: [3080/4518] 68% | Training loss: 0.6869244688130044
Epoch: 99 | Iteration number: [3090/4518] 68% | Training loss: 0.6869248693622045
Epoch: 99 | Iteration number: [3100/4518] 68% | Training loss: 0.6869253980728888
Epoch: 99 | Iteration number: [3110/4518] 68% | Training loss: 0.6869264470227662
Epoch: 99 | Iteration number: [3120/4518] 69% | Training loss: 0.6869229639760959
Epoch: 99 | Iteration number: [3130/4518] 69% | Training loss: 0.6869217486236804
Epoch: 99 | Iteration number: [3140/4518] 69% | Training loss: 0.6869223643450221
Epoch: 99 | Iteration number: [3150/4518] 69% | Training loss: 0.6869202628779033
Epoch: 99 | Iteration number: [3160/4518] 69% | Training loss: 0.686920224903505
Epoch: 99 | Iteration number: [3170/4518] 70% | Training loss: 0.6869214551681976
Epoch: 99 | Iteration number: [3180/4518] 70% | Training loss: 0.6869221325940306
Epoch: 99 | Iteration number: [3190/4518] 70% | Training loss: 0.686920241876082
Epoch: 99 | Iteration number: [3200/4518] 70% | Training loss: 0.6869211025163531
Epoch: 99 | Iteration number: [3210/4518] 71% | Training loss: 0.6869226724744957
Epoch: 99 | Iteration number: [3220/4518] 71% | Training loss: 0.6869237222471593
Epoch: 99 | Iteration number: [3230/4518] 71% | Training loss: 0.686925878004393
Epoch: 99 | Iteration number: [3240/4518] 71% | Training loss: 0.6869271462530265
Epoch: 99 | Iteration number: [3250/4518] 71% | Training loss: 0.6869271738345807
Epoch: 99 | Iteration number: [3260/4518] 72% | Training loss: 0.686926056142965
Epoch: 99 | Iteration number: [3270/4518] 72% | Training loss: 0.6869190457764022
Epoch: 99 | Iteration number: [3280/4518] 72% | Training loss: 0.6869217103937777
Epoch: 99 | Iteration number: [3290/4518] 72% | Training loss: 0.6869213539235135
Epoch: 99 | Iteration number: [3300/4518] 73% | Training loss: 0.6869225720022664
Epoch: 99 | Iteration number: [3310/4518] 73% | Training loss: 0.6869235864038554
Epoch: 99 | Iteration number: [3320/4518] 73% | Training loss: 0.6869243471737367
Epoch: 99 | Iteration number: [3330/4518] 73% | Training loss: 0.6869208190176223
Epoch: 99 | Iteration number: [3340/4518] 73% | Training loss: 0.6869244242678145
Epoch: 99 | Iteration number: [3350/4518] 74% | Training loss: 0.6869252179807691
Epoch: 99 | Iteration number: [3360/4518] 74% | Training loss: 0.6869226549707708
Epoch: 99 | Iteration number: [3370/4518] 74% | Training loss: 0.6869249764465083
Epoch: 99 | Iteration number: [3380/4518] 74% | Training loss: 0.6869244247674942
Epoch: 99 | Iteration number: [3390/4518] 75% | Training loss: 0.6869232645428638
Epoch: 99 | Iteration number: [3400/4518] 75% | Training loss: 0.686924708906342
Epoch: 99 | Iteration number: [3410/4518] 75% | Training loss: 0.6869226801430375
Epoch: 99 | Iteration number: [3420/4518] 75% | Training loss: 0.6869248369458126
Epoch: 99 | Iteration number: [3430/4518] 75% | Training loss: 0.6869264859326032
Epoch: 99 | Iteration number: [3440/4518] 76% | Training loss: 0.6869297727942467
Epoch: 99 | Iteration number: [3450/4518] 76% | Training loss: 0.686930152747942
Epoch: 99 | Iteration number: [3460/4518] 76% | Training loss: 0.6869307744020672
Epoch: 99 | Iteration number: [3470/4518] 76% | Training loss: 0.6869313570023957
Epoch: 99 | Iteration number: [3480/4518] 77% | Training loss: 0.6869304738510614
Epoch: 99 | Iteration number: [3490/4518] 77% | Training loss: 0.6869304381332288
Epoch: 99 | Iteration number: [3500/4518] 77% | Training loss: 0.6869293884038925
Epoch: 99 | Iteration number: [3510/4518] 77% | Training loss: 0.6869277392527317
Epoch: 99 | Iteration number: [3520/4518] 77% | Training loss: 0.686928444203328
Epoch: 99 | Iteration number: [3530/4518] 78% | Training loss: 0.6869307561569106
Epoch: 99 | Iteration number: [3540/4518] 78% | Training loss: 0.6869344933558319
Epoch: 99 | Iteration number: [3550/4518] 78% | Training loss: 0.686934726338991
Epoch: 99 | Iteration number: [3560/4518] 78% | Training loss: 0.6869321995404329
Epoch: 99 | Iteration number: [3570/4518] 79% | Training loss: 0.6869340279690024
Epoch: 99 | Iteration number: [3580/4518] 79% | Training loss: 0.6869336419265364
Epoch: 99 | Iteration number: [3590/4518] 79% | Training loss: 0.6869339695215889
Epoch: 99 | Iteration number: [3600/4518] 79% | Training loss: 0.6869329773220751
Epoch: 99 | Iteration number: [3610/4518] 79% | Training loss: 0.6869350157946431
Epoch: 99 | Iteration number: [3620/4518] 80% | Training loss: 0.686932859582137
Epoch: 99 | Iteration number: [3630/4518] 80% | Training loss: 0.686935579858864
Epoch: 99 | Iteration number: [3640/4518] 80% | Training loss: 0.6869354005698319
Epoch: 99 | Iteration number: [3650/4518] 80% | Training loss: 0.6869355133624926
Epoch: 99 | Iteration number: [3660/4518] 81% | Training loss: 0.68693450176325
Epoch: 99 | Iteration number: [3670/4518] 81% | Training loss: 0.6869359630005236
Epoch: 99 | Iteration number: [3680/4518] 81% | Training loss: 0.6869386038540498
Epoch: 99 | Iteration number: [3690/4518] 81% | Training loss: 0.686940592931215
Epoch: 99 | Iteration number: [3700/4518] 81% | Training loss: 0.6869400134763202
Epoch: 99 | Iteration number: [3710/4518] 82% | Training loss: 0.686936463467837
Epoch: 99 | Iteration number: [3720/4518] 82% | Training loss: 0.6869312738539071
Epoch: 99 | Iteration number: [3730/4518] 82% | Training loss: 0.6869284559191072
Epoch: 99 | Iteration number: [3740/4518] 82% | Training loss: 0.6869280824208642
Epoch: 99 | Iteration number: [3750/4518] 83% | Training loss: 0.6869278496742248
Epoch: 99 | Iteration number: [3760/4518] 83% | Training loss: 0.6869306132514426
Epoch: 99 | Iteration number: [3770/4518] 83% | Training loss: 0.6869310803849754
Epoch: 99 | Iteration number: [3780/4518] 83% | Training loss: 0.6869319686025539
Epoch: 99 | Iteration number: [3790/4518] 83% | Training loss: 0.6869273404804572
Epoch: 99 | Iteration number: [3800/4518] 84% | Training loss: 0.6869212796343
Epoch: 99 | Iteration number: [3810/4518] 84% | Training loss: 0.6869253598642474
Epoch: 99 | Iteration number: [3820/4518] 84% | Training loss: 0.6869212504612838
Epoch: 99 | Iteration number: [3830/4518] 84% | Training loss: 0.686922345724803
Epoch: 99 | Iteration number: [3840/4518] 84% | Training loss: 0.6869252832451215
Epoch: 99 | Iteration number: [3850/4518] 85% | Training loss: 0.6869296475973996
Epoch: 99 | Iteration number: [3860/4518] 85% | Training loss: 0.686932125085376
Epoch: 99 | Iteration number: [3870/4518] 85% | Training loss: 0.6869343171132011
Epoch: 99 | Iteration number: [3880/4518] 85% | Training loss: 0.6869271748151976
Epoch: 99 | Iteration number: [3890/4518] 86% | Training loss: 0.6869246584590726
Epoch: 99 | Iteration number: [3900/4518] 86% | Training loss: 0.6869253131976495
Epoch: 99 | Iteration number: [3910/4518] 86% | Training loss: 0.6869233214336893
Epoch: 99 | Iteration number: [3920/4518] 86% | Training loss: 0.6869240708040948
Epoch: 99 | Iteration number: [3930/4518] 86% | Training loss: 0.6869247060089014
Epoch: 99 | Iteration number: [3940/4518] 87% | Training loss: 0.6869217009259965
Epoch: 99 | Iteration number: [3950/4518] 87% | Training loss: 0.6869192541701884
Epoch: 99 | Iteration number: [3960/4518] 87% | Training loss: 0.686920455293824
Epoch: 99 | Iteration number: [3970/4518] 87% | Training loss: 0.686921005375139
Epoch: 99 | Iteration number: [3980/4518] 88% | Training loss: 0.6869206180524586
Epoch: 99 | Iteration number: [3990/4518] 88% | Training loss: 0.686917038175994
Epoch: 99 | Iteration number: [4000/4518] 88% | Training loss: 0.6869207778871059
Epoch: 99 | Iteration number: [4010/4518] 88% | Training loss: 0.6869187756369536
Epoch: 99 | Iteration number: [4020/4518] 88% | Training loss: 0.6869197773547908
Epoch: 99 | Iteration number: [4030/4518] 89% | Training loss: 0.6869164565804579
Epoch: 99 | Iteration number: [4040/4518] 89% | Training loss: 0.6869183743354117
Epoch: 99 | Iteration number: [4050/4518] 89% | Training loss: 0.6869210248964804
Epoch: 99 | Iteration number: [4060/4518] 89% | Training loss: 0.686920882754138
Epoch: 99 | Iteration number: [4070/4518] 90% | Training loss: 0.6869221061687798
Epoch: 99 | Iteration number: [4080/4518] 90% | Training loss: 0.68692308347307
Epoch: 99 | Iteration number: [4090/4518] 90% | Training loss: 0.6869214933629724
Epoch: 99 | Iteration number: [4100/4518] 90% | Training loss: 0.6869208819982482
Epoch: 99 | Iteration number: [4110/4518] 90% | Training loss: 0.686921935403434
Epoch: 99 | Iteration number: [4120/4518] 91% | Training loss: 0.6869243475852661
Epoch: 99 | Iteration number: [4130/4518] 91% | Training loss: 0.6869247195218435
Epoch: 99 | Iteration number: [4140/4518] 91% | Training loss: 0.6869238152452137
Epoch: 99 | Iteration number: [4150/4518] 91% | Training loss: 0.686924761375749
Epoch: 99 | Iteration number: [4160/4518] 92% | Training loss: 0.6869251839673289
Epoch: 99 | Iteration number: [4170/4518] 92% | Training loss: 0.6869233441152732
Epoch: 99 | Iteration number: [4180/4518] 92% | Training loss: 0.6869223790020463
Epoch: 99 | Iteration number: [4190/4518] 92% | Training loss: 0.6869220185251396
Epoch: 99 | Iteration number: [4200/4518] 92% | Training loss: 0.6869177975257238
Epoch: 99 | Iteration number: [4210/4518] 93% | Training loss: 0.6869168336204565
Epoch: 99 | Iteration number: [4220/4518] 93% | Training loss: 0.6869174690043192
Epoch: 99 | Iteration number: [4230/4518] 93% | Training loss: 0.686918470608709
Epoch: 99 | Iteration number: [4240/4518] 93% | Training loss: 0.6869198518963355
Epoch: 99 | Iteration number: [4250/4518] 94% | Training loss: 0.6869178596805123
Epoch: 99 | Iteration number: [4260/4518] 94% | Training loss: 0.6869101396468883
Epoch: 99 | Iteration number: [4270/4518] 94% | Training loss: 0.6869099506449644
Epoch: 99 | Iteration number: [4280/4518] 94% | Training loss: 0.6869073017178294
Epoch: 99 | Iteration number: [4290/4518] 94% | Training loss: 0.6869077488259002
Epoch: 99 | Iteration number: [4300/4518] 95% | Training loss: 0.6869068914790486
Epoch: 99 | Iteration number: [4310/4518] 95% | Training loss: 0.6869059258436658
Epoch: 99 | Iteration number: [4320/4518] 95% | Training loss: 0.6869071958241639
Epoch: 99 | Iteration number: [4330/4518] 95% | Training loss: 0.6869088615473644
Epoch: 99 | Iteration number: [4340/4518] 96% | Training loss: 0.6869088547295689
Epoch: 99 | Iteration number: [4350/4518] 96% | Training loss: 0.6869082962918556
Epoch: 99 | Iteration number: [4360/4518] 96% | Training loss: 0.6869083917742476
Epoch: 99 | Iteration number: [4370/4518] 96% | Training loss: 0.6869086121121588
Epoch: 99 | Iteration number: [4380/4518] 96% | Training loss: 0.6869096950853252
Epoch: 99 | Iteration number: [4390/4518] 97% | Training loss: 0.6869106062859772
Epoch: 99 | Iteration number: [4400/4518] 97% | Training loss: 0.6869119527935982
Epoch: 99 | Iteration number: [4410/4518] 97% | Training loss: 0.6869079348586854
Epoch: 99 | Iteration number: [4420/4518] 97% | Training loss: 0.6869087131584392
Epoch: 99 | Iteration number: [4430/4518] 98% | Training loss: 0.6869087307501592
Epoch: 99 | Iteration number: [4440/4518] 98% | Training loss: 0.6869060512732815
Epoch: 99 | Iteration number: [4450/4518] 98% | Training loss: 0.6869062510501133
Epoch: 99 | Iteration number: [4460/4518] 98% | Training loss: 0.6869051952666766
Epoch: 99 | Iteration number: [4470/4518] 98% | Training loss: 0.6869063119360265
Epoch: 99 | Iteration number: [4480/4518] 99% | Training loss: 0.6869078305549919
Epoch: 99 | Iteration number: [4490/4518] 99% | Training loss: 0.6869083767213375
Epoch: 99 | Iteration number: [4500/4518] 99% | Training loss: 0.6869059379498164
Epoch: 99 | Iteration number: [4510/4518] 99% | Training loss: 0.6869068025881858

 End of epoch: 99 | Train Loss: 0.6867541500613351 | Training Time: 642 

 End of epoch: 99 | Eval Loss: 0.689948279030469 | Evaluating Time: 17 
Epoch: 100 | Iteration number: [10/4518] 0% | Training loss: 0.7571279823780059
Epoch: 100 | Iteration number: [20/4518] 0% | Training loss: 0.722241348028183
Epoch: 100 | Iteration number: [30/4518] 0% | Training loss: 0.7105690141518911
Epoch: 100 | Iteration number: [40/4518] 0% | Training loss: 0.7045907855033875
Epoch: 100 | Iteration number: [50/4518] 1% | Training loss: 0.7011991560459137
Epoch: 100 | Iteration number: [60/4518] 1% | Training loss: 0.6988018522659938
Epoch: 100 | Iteration number: [70/4518] 1% | Training loss: 0.6972154429980687
Epoch: 100 | Iteration number: [80/4518] 1% | Training loss: 0.6957921028137207
Epoch: 100 | Iteration number: [90/4518] 1% | Training loss: 0.6947205622990926
Epoch: 100 | Iteration number: [100/4518] 2% | Training loss: 0.6938031148910523
Epoch: 100 | Iteration number: [110/4518] 2% | Training loss: 0.6931697791272944
Epoch: 100 | Iteration number: [120/4518] 2% | Training loss: 0.6925437490145365
Epoch: 100 | Iteration number: [130/4518] 2% | Training loss: 0.6920778549634493
Epoch: 100 | Iteration number: [140/4518] 3% | Training loss: 0.691709880743708
Epoch: 100 | Iteration number: [150/4518] 3% | Training loss: 0.6913457977771759
Epoch: 100 | Iteration number: [160/4518] 3% | Training loss: 0.6910667568445206
Epoch: 100 | Iteration number: [170/4518] 3% | Training loss: 0.6907551895169651
Epoch: 100 | Iteration number: [180/4518] 3% | Training loss: 0.690535776482688
Epoch: 100 | Iteration number: [190/4518] 4% | Training loss: 0.6903423657542781
Epoch: 100 | Iteration number: [200/4518] 4% | Training loss: 0.6902125045657158
Epoch: 100 | Iteration number: [210/4518] 4% | Training loss: 0.6900368480455308
Epoch: 100 | Iteration number: [220/4518] 4% | Training loss: 0.6898779419335452
Epoch: 100 | Iteration number: [230/4518] 5% | Training loss: 0.6897679992344068
Epoch: 100 | Iteration number: [240/4518] 5% | Training loss: 0.6896258470912774
Epoch: 100 | Iteration number: [250/4518] 5% | Training loss: 0.6895489234924317
Epoch: 100 | Iteration number: [260/4518] 5% | Training loss: 0.6894367981415529
Epoch: 100 | Iteration number: [270/4518] 5% | Training loss: 0.6893140174724438
Epoch: 100 | Iteration number: [280/4518] 6% | Training loss: 0.689247904079301
Epoch: 100 | Iteration number: [290/4518] 6% | Training loss: 0.6891478413137896
Epoch: 100 | Iteration number: [300/4518] 6% | Training loss: 0.6890635621547699
Epoch: 100 | Iteration number: [310/4518] 6% | Training loss: 0.6889147741179312
Epoch: 100 | Iteration number: [320/4518] 7% | Training loss: 0.6888457974418998
Epoch: 100 | Iteration number: [330/4518] 7% | Training loss: 0.6888022220495975
Epoch: 100 | Iteration number: [340/4518] 7% | Training loss: 0.6887405556790969
Epoch: 100 | Iteration number: [350/4518] 7% | Training loss: 0.6886619591712951
Epoch: 100 | Iteration number: [360/4518] 7% | Training loss: 0.6886275321245193
Epoch: 100 | Iteration number: [370/4518] 8% | Training loss: 0.6885699906864682
Epoch: 100 | Iteration number: [380/4518] 8% | Training loss: 0.6885356499960548
Epoch: 100 | Iteration number: [390/4518] 8% | Training loss: 0.6884947674396711
Epoch: 100 | Iteration number: [400/4518] 8% | Training loss: 0.6884416402876377
Epoch: 100 | Iteration number: [410/4518] 9% | Training loss: 0.6884165177984936
Epoch: 100 | Iteration number: [420/4518] 9% | Training loss: 0.6884037947370892
Epoch: 100 | Iteration number: [430/4518] 9% | Training loss: 0.6883830530698909
Epoch: 100 | Iteration number: [440/4518] 9% | Training loss: 0.6883655573834072
Epoch: 100 | Iteration number: [450/4518] 9% | Training loss: 0.6882785806390974
Epoch: 100 | Iteration number: [460/4518] 10% | Training loss: 0.6882246844146562
Epoch: 100 | Iteration number: [470/4518] 10% | Training loss: 0.6882168970209487
Epoch: 100 | Iteration number: [480/4518] 10% | Training loss: 0.6881899772832791
Epoch: 100 | Iteration number: [490/4518] 10% | Training loss: 0.6881608671071578
Epoch: 100 | Iteration number: [500/4518] 11% | Training loss: 0.6880922950506211
Epoch: 100 | Iteration number: [510/4518] 11% | Training loss: 0.6880845252205344
Epoch: 100 | Iteration number: [520/4518] 11% | Training loss: 0.6880501762032509
Epoch: 100 | Iteration number: [530/4518] 11% | Training loss: 0.6880299252159191
Epoch: 100 | Iteration number: [540/4518] 11% | Training loss: 0.6880028394637284
Epoch: 100 | Iteration number: [550/4518] 12% | Training loss: 0.6879875063896179
Epoch: 100 | Iteration number: [560/4518] 12% | Training loss: 0.6879549176565238
Epoch: 100 | Iteration number: [570/4518] 12% | Training loss: 0.6879010780861503
Epoch: 100 | Iteration number: [580/4518] 12% | Training loss: 0.6878822725394677
Epoch: 100 | Iteration number: [590/4518] 13% | Training loss: 0.6878692160218449
Epoch: 100 | Iteration number: [600/4518] 13% | Training loss: 0.6878563741842906
Epoch: 100 | Iteration number: [610/4518] 13% | Training loss: 0.6878361252487682
Epoch: 100 | Iteration number: [620/4518] 13% | Training loss: 0.6878305275594034
Epoch: 100 | Iteration number: [630/4518] 13% | Training loss: 0.6878089721240694
Epoch: 100 | Iteration number: [640/4518] 14% | Training loss: 0.6878031791187823
Epoch: 100 | Iteration number: [650/4518] 14% | Training loss: 0.687777705009167
Epoch: 100 | Iteration number: [660/4518] 14% | Training loss: 0.6877804655017274
Epoch: 100 | Iteration number: [670/4518] 14% | Training loss: 0.6877611224331073
Epoch: 100 | Iteration number: [680/4518] 15% | Training loss: 0.6877481437781278
Epoch: 100 | Iteration number: [690/4518] 15% | Training loss: 0.6877310644025388
Epoch: 100 | Iteration number: [700/4518] 15% | Training loss: 0.6877294106994356
Epoch: 100 | Iteration number: [710/4518] 15% | Training loss: 0.6877197138860192
Epoch: 100 | Iteration number: [720/4518] 15% | Training loss: 0.6877068225708273
Epoch: 100 | Iteration number: [730/4518] 16% | Training loss: 0.6876889129207558
Epoch: 100 | Iteration number: [740/4518] 16% | Training loss: 0.6876755281880095
Epoch: 100 | Iteration number: [750/4518] 16% | Training loss: 0.6876545912424723
Epoch: 100 | Iteration number: [760/4518] 16% | Training loss: 0.6876285457297375
Epoch: 100 | Iteration number: [770/4518] 17% | Training loss: 0.6875975702490126
Epoch: 100 | Iteration number: [780/4518] 17% | Training loss: 0.6875930340626301
Epoch: 100 | Iteration number: [790/4518] 17% | Training loss: 0.687581745431393
Epoch: 100 | Iteration number: [800/4518] 17% | Training loss: 0.6875645667314529
Epoch: 100 | Iteration number: [810/4518] 17% | Training loss: 0.687557797152319
Epoch: 100 | Iteration number: [820/4518] 18% | Training loss: 0.6875467991683542
Epoch: 100 | Iteration number: [830/4518] 18% | Training loss: 0.6875263015907931
Epoch: 100 | Iteration number: [840/4518] 18% | Training loss: 0.6875257499870799
Epoch: 100 | Iteration number: [850/4518] 18% | Training loss: 0.6875256130274604
Epoch: 100 | Iteration number: [860/4518] 19% | Training loss: 0.6875100540560345
Epoch: 100 | Iteration number: [870/4518] 19% | Training loss: 0.6875022454508419
Epoch: 100 | Iteration number: [880/4518] 19% | Training loss: 0.6874949731610038
Epoch: 100 | Iteration number: [890/4518] 19% | Training loss: 0.687485555182682
Epoch: 100 | Iteration number: [900/4518] 19% | Training loss: 0.6874898339642419
Epoch: 100 | Iteration number: [910/4518] 20% | Training loss: 0.6874912561951103
Epoch: 100 | Iteration number: [920/4518] 20% | Training loss: 0.6874880910567616
Epoch: 100 | Iteration number: [930/4518] 20% | Training loss: 0.6874777205528751
Epoch: 100 | Iteration number: [940/4518] 20% | Training loss: 0.687470043720083
Epoch: 100 | Iteration number: [950/4518] 21% | Training loss: 0.6874694967897315
Epoch: 100 | Iteration number: [960/4518] 21% | Training loss: 0.6874646802743276
Epoch: 100 | Iteration number: [970/4518] 21% | Training loss: 0.6874500857186072
Epoch: 100 | Iteration number: [980/4518] 21% | Training loss: 0.6874427033322198
Epoch: 100 | Iteration number: [990/4518] 21% | Training loss: 0.6874440825948811
Epoch: 100 | Iteration number: [1000/4518] 22% | Training loss: 0.6874420307874679
Epoch: 100 | Iteration number: [1010/4518] 22% | Training loss: 0.6874349381664012
Epoch: 100 | Iteration number: [1020/4518] 22% | Training loss: 0.687417270915181
Epoch: 100 | Iteration number: [1030/4518] 22% | Training loss: 0.6874081632465993
Epoch: 100 | Iteration number: [1040/4518] 23% | Training loss: 0.6874140208157209
Epoch: 100 | Iteration number: [1050/4518] 23% | Training loss: 0.6874194778147198
Epoch: 100 | Iteration number: [1060/4518] 23% | Training loss: 0.6874172793244416
Epoch: 100 | Iteration number: [1070/4518] 23% | Training loss: 0.6874209944332872
Epoch: 100 | Iteration number: [1080/4518] 23% | Training loss: 0.687402668484935
Epoch: 100 | Iteration number: [1090/4518] 24% | Training loss: 0.6873967878315427
Epoch: 100 | Iteration number: [1100/4518] 24% | Training loss: 0.6873839444463903
Epoch: 100 | Iteration number: [1110/4518] 24% | Training loss: 0.6873716604602229
Epoch: 100 | Iteration number: [1120/4518] 24% | Training loss: 0.6873694296394076
Epoch: 100 | Iteration number: [1130/4518] 25% | Training loss: 0.6873573579091942
Epoch: 100 | Iteration number: [1140/4518] 25% | Training loss: 0.6873515586581147
Epoch: 100 | Iteration number: [1150/4518] 25% | Training loss: 0.6873549274776293
Epoch: 100 | Iteration number: [1160/4518] 25% | Training loss: 0.6873460218310357
Epoch: 100 | Iteration number: [1170/4518] 25% | Training loss: 0.6873373963384547
Epoch: 100 | Iteration number: [1180/4518] 26% | Training loss: 0.6873254653760943
Epoch: 100 | Iteration number: [1190/4518] 26% | Training loss: 0.6873223804626144
Epoch: 100 | Iteration number: [1200/4518] 26% | Training loss: 0.6873188080390294
Epoch: 100 | Iteration number: [1210/4518] 26% | Training loss: 0.6873111389392663
Epoch: 100 | Iteration number: [1220/4518] 27% | Training loss: 0.6873153336224008
Epoch: 100 | Iteration number: [1230/4518] 27% | Training loss: 0.6873097442514529
Epoch: 100 | Iteration number: [1240/4518] 27% | Training loss: 0.6873063649862043
Epoch: 100 | Iteration number: [1250/4518] 27% | Training loss: 0.6872972196578979
Epoch: 100 | Iteration number: [1260/4518] 27% | Training loss: 0.6872938417726093
Epoch: 100 | Iteration number: [1270/4518] 28% | Training loss: 0.6872909258669756
Epoch: 100 | Iteration number: [1280/4518] 28% | Training loss: 0.6872846616897732
Epoch: 100 | Iteration number: [1290/4518] 28% | Training loss: 0.6872843093188234
Epoch: 100 | Iteration number: [1300/4518] 28% | Training loss: 0.687281581392655
Epoch: 100 | Iteration number: [1310/4518] 28% | Training loss: 0.6872848094874666
Epoch: 100 | Iteration number: [1320/4518] 29% | Training loss: 0.687276941447547
Epoch: 100 | Iteration number: [1330/4518] 29% | Training loss: 0.6872775629498905
Epoch: 100 | Iteration number: [1340/4518] 29% | Training loss: 0.6872788520891275
Epoch: 100 | Iteration number: [1350/4518] 29% | Training loss: 0.6872752184779556
Epoch: 100 | Iteration number: [1360/4518] 30% | Training loss: 0.6872641969691304
Epoch: 100 | Iteration number: [1370/4518] 30% | Training loss: 0.6872510103413658
Epoch: 100 | Iteration number: [1380/4518] 30% | Training loss: 0.6872378081515216
Epoch: 100 | Iteration number: [1390/4518] 30% | Training loss: 0.6872319779378905
Epoch: 100 | Iteration number: [1400/4518] 30% | Training loss: 0.687225205387388
Epoch: 100 | Iteration number: [1410/4518] 31% | Training loss: 0.6872276868803281
Epoch: 100 | Iteration number: [1420/4518] 31% | Training loss: 0.6872268787991833
Epoch: 100 | Iteration number: [1430/4518] 31% | Training loss: 0.6872329395967763
Epoch: 100 | Iteration number: [1440/4518] 31% | Training loss: 0.6872324062718286
Epoch: 100 | Iteration number: [1450/4518] 32% | Training loss: 0.6872201083857438
Epoch: 100 | Iteration number: [1460/4518] 32% | Training loss: 0.6872212752495727
Epoch: 100 | Iteration number: [1470/4518] 32% | Training loss: 0.6872164157377619
Epoch: 100 | Iteration number: [1480/4518] 32% | Training loss: 0.6872205923537951
Epoch: 100 | Iteration number: [1490/4518] 32% | Training loss: 0.6872221143053682
Epoch: 100 | Iteration number: [1500/4518] 33% | Training loss: 0.6872068589131037
Epoch: 100 | Iteration number: [1510/4518] 33% | Training loss: 0.6871973894289787
Epoch: 100 | Iteration number: [1520/4518] 33% | Training loss: 0.6871933524938006
Epoch: 100 | Iteration number: [1530/4518] 33% | Training loss: 0.6871875729046616
Epoch: 100 | Iteration number: [1540/4518] 34% | Training loss: 0.6871816240347826
Epoch: 100 | Iteration number: [1550/4518] 34% | Training loss: 0.6871824081866972
Epoch: 100 | Iteration number: [1560/4518] 34% | Training loss: 0.687171919682087
Epoch: 100 | Iteration number: [1570/4518] 34% | Training loss: 0.6871661865407495
Epoch: 100 | Iteration number: [1580/4518] 34% | Training loss: 0.6871686020606681
Epoch: 100 | Iteration number: [1590/4518] 35% | Training loss: 0.687166328587622
Epoch: 100 | Iteration number: [1600/4518] 35% | Training loss: 0.6871574296057225
Epoch: 100 | Iteration number: [1610/4518] 35% | Training loss: 0.6871628854955946
Epoch: 100 | Iteration number: [1620/4518] 35% | Training loss: 0.6871638225552477
Epoch: 100 | Iteration number: [1630/4518] 36% | Training loss: 0.6871571606287927
Epoch: 100 | Iteration number: [1640/4518] 36% | Training loss: 0.6871558726560779
Epoch: 100 | Iteration number: [1650/4518] 36% | Training loss: 0.687152956796415
Epoch: 100 | Iteration number: [1660/4518] 36% | Training loss: 0.6871493406324501
Epoch: 100 | Iteration number: [1670/4518] 36% | Training loss: 0.6871497452615978
Epoch: 100 | Iteration number: [1680/4518] 37% | Training loss: 0.6871541180780956
Epoch: 100 | Iteration number: [1690/4518] 37% | Training loss: 0.6871496368089371
Epoch: 100 | Iteration number: [1700/4518] 37% | Training loss: 0.6871523652357213
Epoch: 100 | Iteration number: [1710/4518] 37% | Training loss: 0.6871461738619888
Epoch: 100 | Iteration number: [1720/4518] 38% | Training loss: 0.6871445595525032
Epoch: 100 | Iteration number: [1730/4518] 38% | Training loss: 0.6871434455317569
Epoch: 100 | Iteration number: [1740/4518] 38% | Training loss: 0.6871380802886239
Epoch: 100 | Iteration number: [1750/4518] 38% | Training loss: 0.6871334161758423
Epoch: 100 | Iteration number: [1760/4518] 38% | Training loss: 0.687124094942754
Epoch: 100 | Iteration number: [1770/4518] 39% | Training loss: 0.687122372786204
Epoch: 100 | Iteration number: [1780/4518] 39% | Training loss: 0.6871185292018933
Epoch: 100 | Iteration number: [1790/4518] 39% | Training loss: 0.6871152300075446
Epoch: 100 | Iteration number: [1800/4518] 39% | Training loss: 0.6871099815766016
Epoch: 100 | Iteration number: [1810/4518] 40% | Training loss: 0.6871142788815894
Epoch: 100 | Iteration number: [1820/4518] 40% | Training loss: 0.6871210177193631
Epoch: 100 | Iteration number: [1830/4518] 40% | Training loss: 0.6871176350312155
Epoch: 100 | Iteration number: [1840/4518] 40% | Training loss: 0.6871148155435272
Epoch: 100 | Iteration number: [1850/4518] 40% | Training loss: 0.6871091213741818
Epoch: 100 | Iteration number: [1860/4518] 41% | Training loss: 0.6871078714888583
Epoch: 100 | Iteration number: [1870/4518] 41% | Training loss: 0.6871068053704532
Epoch: 100 | Iteration number: [1880/4518] 41% | Training loss: 0.6871051369512334
Epoch: 100 | Iteration number: [1890/4518] 41% | Training loss: 0.6871097197292974
Epoch: 100 | Iteration number: [1900/4518] 42% | Training loss: 0.6871065754325766
Epoch: 100 | Iteration number: [1910/4518] 42% | Training loss: 0.6870960409104512
Epoch: 100 | Iteration number: [1920/4518] 42% | Training loss: 0.6870934118827184
Epoch: 100 | Iteration number: [1930/4518] 42% | Training loss: 0.687088577117327
Epoch: 100 | Iteration number: [1940/4518] 42% | Training loss: 0.6870832636184299
Epoch: 100 | Iteration number: [1950/4518] 43% | Training loss: 0.6870772374898959
Epoch: 100 | Iteration number: [1960/4518] 43% | Training loss: 0.6870689552049247
Epoch: 100 | Iteration number: [1970/4518] 43% | Training loss: 0.6870700882473573
Epoch: 100 | Iteration number: [1980/4518] 43% | Training loss: 0.6870718079684961
Epoch: 100 | Iteration number: [1990/4518] 44% | Training loss: 0.6870723783969879
Epoch: 100 | Iteration number: [2000/4518] 44% | Training loss: 0.687078020632267
Epoch: 100 | Iteration number: [2010/4518] 44% | Training loss: 0.6870718512665573
Epoch: 100 | Iteration number: [2020/4518] 44% | Training loss: 0.6870697298852524
Epoch: 100 | Iteration number: [2030/4518] 44% | Training loss: 0.6870655778006379
Epoch: 100 | Iteration number: [2040/4518] 45% | Training loss: 0.6870601653176196
Epoch: 100 | Iteration number: [2050/4518] 45% | Training loss: 0.6870608666175749
Epoch: 100 | Iteration number: [2060/4518] 45% | Training loss: 0.6870514456797572
Epoch: 100 | Iteration number: [2070/4518] 45% | Training loss: 0.6870485988216124
Epoch: 100 | Iteration number: [2080/4518] 46% | Training loss: 0.6870454875609049
Epoch: 100 | Iteration number: [2090/4518] 46% | Training loss: 0.6870413830690977
Epoch: 100 | Iteration number: [2100/4518] 46% | Training loss: 0.6870415148848579
Epoch: 100 | Iteration number: [2110/4518] 46% | Training loss: 0.6870423901985042
Epoch: 100 | Iteration number: [2120/4518] 46% | Training loss: 0.6870432577886671
Epoch: 100 | Iteration number: [2130/4518] 47% | Training loss: 0.687042068483684
Epoch: 100 | Iteration number: [2140/4518] 47% | Training loss: 0.6870436497380801
Epoch: 100 | Iteration number: [2150/4518] 47% | Training loss: 0.6870422673502634
Epoch: 100 | Iteration number: [2160/4518] 47% | Training loss: 0.6870338654352559
Epoch: 100 | Iteration number: [2170/4518] 48% | Training loss: 0.6870302165158882
Epoch: 100 | Iteration number: [2180/4518] 48% | Training loss: 0.6870308767218108
Epoch: 100 | Iteration number: [2190/4518] 48% | Training loss: 0.6870326811592329
Epoch: 100 | Iteration number: [2200/4518] 48% | Training loss: 0.6870361332188953
Epoch: 100 | Iteration number: [2210/4518] 48% | Training loss: 0.6870297010398019
Epoch: 100 | Iteration number: [2220/4518] 49% | Training loss: 0.6870283291415051
Epoch: 100 | Iteration number: [2230/4518] 49% | Training loss: 0.6870261791842935
Epoch: 100 | Iteration number: [2240/4518] 49% | Training loss: 0.687024487182498
Epoch: 100 | Iteration number: [2250/4518] 49% | Training loss: 0.6870221883985731
Epoch: 100 | Iteration number: [2260/4518] 50% | Training loss: 0.6870239729111174
Epoch: 100 | Iteration number: [2270/4518] 50% | Training loss: 0.6870217500016553
Epoch: 100 | Iteration number: [2280/4518] 50% | Training loss: 0.6870166049191826
Epoch: 100 | Iteration number: [2290/4518] 50% | Training loss: 0.6870188858050967
Epoch: 100 | Iteration number: [2300/4518] 50% | Training loss: 0.6870224657525187
Epoch: 100 | Iteration number: [2310/4518] 51% | Training loss: 0.6870178475266411
Epoch: 100 | Iteration number: [2320/4518] 51% | Training loss: 0.687020432666458
Epoch: 100 | Iteration number: [2330/4518] 51% | Training loss: 0.6870251739997209
Epoch: 100 | Iteration number: [2340/4518] 51% | Training loss: 0.6870241109632019
Epoch: 100 | Iteration number: [2350/4518] 52% | Training loss: 0.6870192640893003
Epoch: 100 | Iteration number: [2360/4518] 52% | Training loss: 0.6870194565694211
Epoch: 100 | Iteration number: [2370/4518] 52% | Training loss: 0.6870181344732453
Epoch: 100 | Iteration number: [2380/4518] 52% | Training loss: 0.6870174146750394
Epoch: 100 | Iteration number: [2390/4518] 52% | Training loss: 0.6870156678943953
Epoch: 100 | Iteration number: [2400/4518] 53% | Training loss: 0.6870110247284174
Epoch: 100 | Iteration number: [2410/4518] 53% | Training loss: 0.687009725283785
Epoch: 100 | Iteration number: [2420/4518] 53% | Training loss: 0.6870139568551513
Epoch: 100 | Iteration number: [2430/4518] 53% | Training loss: 0.6870137911765173
Epoch: 100 | Iteration number: [2440/4518] 54% | Training loss: 0.6870153907136839
Epoch: 100 | Iteration number: [2450/4518] 54% | Training loss: 0.6870172937062322
Epoch: 100 | Iteration number: [2460/4518] 54% | Training loss: 0.6870179385189118
Epoch: 100 | Iteration number: [2470/4518] 54% | Training loss: 0.6870187866060358
Epoch: 100 | Iteration number: [2480/4518] 54% | Training loss: 0.6870164862803875
Epoch: 100 | Iteration number: [2490/4518] 55% | Training loss: 0.6870109105684671
Epoch: 100 | Iteration number: [2500/4518] 55% | Training loss: 0.6870069616794586
Epoch: 100 | Iteration number: [2510/4518] 55% | Training loss: 0.6870072915022116
Epoch: 100 | Iteration number: [2520/4518] 55% | Training loss: 0.6870064429347478
Epoch: 100 | Iteration number: [2530/4518] 55% | Training loss: 0.6870053243731321
Epoch: 100 | Iteration number: [2540/4518] 56% | Training loss: 0.6870084548090386
Epoch: 100 | Iteration number: [2550/4518] 56% | Training loss: 0.6870116433442808
Epoch: 100 | Iteration number: [2560/4518] 56% | Training loss: 0.6870155924465507
Epoch: 100 | Iteration number: [2570/4518] 56% | Training loss: 0.6870158117800835
Epoch: 100 | Iteration number: [2580/4518] 57% | Training loss: 0.6870132821243863
Epoch: 100 | Iteration number: [2590/4518] 57% | Training loss: 0.6870157444569135
Epoch: 100 | Iteration number: [2600/4518] 57% | Training loss: 0.6870178700181154
Epoch: 100 | Iteration number: [2610/4518] 57% | Training loss: 0.6870187797765622
Epoch: 100 | Iteration number: [2620/4518] 57% | Training loss: 0.6870190650452185
Epoch: 100 | Iteration number: [2630/4518] 58% | Training loss: 0.6870142022693112
Epoch: 100 | Iteration number: [2640/4518] 58% | Training loss: 0.6870111325473497
Epoch: 100 | Iteration number: [2650/4518] 58% | Training loss: 0.6870111994923286
Epoch: 100 | Iteration number: [2660/4518] 58% | Training loss: 0.6870069732343344
Epoch: 100 | Iteration number: [2670/4518] 59% | Training loss: 0.6870066124401736
Epoch: 100 | Iteration number: [2680/4518] 59% | Training loss: 0.687008930386892
Epoch: 100 | Iteration number: [2690/4518] 59% | Training loss: 0.6870111374163717
Epoch: 100 | Iteration number: [2700/4518] 59% | Training loss: 0.6870069995191362
Epoch: 100 | Iteration number: [2710/4518] 59% | Training loss: 0.6870076154430854
Epoch: 100 | Iteration number: [2720/4518] 60% | Training loss: 0.6870082464069128
Epoch: 100 | Iteration number: [2730/4518] 60% | Training loss: 0.6870070834954579
Epoch: 100 | Iteration number: [2740/4518] 60% | Training loss: 0.6870035029893374
Epoch: 100 | Iteration number: [2750/4518] 60% | Training loss: 0.687005009282719
Epoch: 100 | Iteration number: [2760/4518] 61% | Training loss: 0.6870067072951276
Epoch: 100 | Iteration number: [2770/4518] 61% | Training loss: 0.6870031651822238
Epoch: 100 | Iteration number: [2780/4518] 61% | Training loss: 0.6870049581896487
Epoch: 100 | Iteration number: [2790/4518] 61% | Training loss: 0.6869996225962075
Epoch: 100 | Iteration number: [2800/4518] 61% | Training loss: 0.686994963905641
Epoch: 100 | Iteration number: [2810/4518] 62% | Training loss: 0.6869953385663626
Epoch: 100 | Iteration number: [2820/4518] 62% | Training loss: 0.686993778195787
Epoch: 100 | Iteration number: [2830/4518] 62% | Training loss: 0.6869944986943222
Epoch: 100 | Iteration number: [2840/4518] 62% | Training loss: 0.6869929242301994
Epoch: 100 | Iteration number: [2850/4518] 63% | Training loss: 0.6869901811030873
Epoch: 100 | Iteration number: [2860/4518] 63% | Training loss: 0.6869869316374505
Epoch: 100 | Iteration number: [2870/4518] 63% | Training loss: 0.686984838612819
Epoch: 100 | Iteration number: [2880/4518] 63% | Training loss: 0.6869848252998458
Epoch: 100 | Iteration number: [2890/4518] 63% | Training loss: 0.686982687513721
Epoch: 100 | Iteration number: [2900/4518] 64% | Training loss: 0.6869817954507368
Epoch: 100 | Iteration number: [2910/4518] 64% | Training loss: 0.6869806000457187
Epoch: 100 | Iteration number: [2920/4518] 64% | Training loss: 0.6869804908967998
Epoch: 100 | Iteration number: [2930/4518] 64% | Training loss: 0.6869811537933024
Epoch: 100 | Iteration number: [2940/4518] 65% | Training loss: 0.6869805172998078
Epoch: 100 | Iteration number: [2950/4518] 65% | Training loss: 0.6869798730187497
Epoch: 100 | Iteration number: [2960/4518] 65% | Training loss: 0.6869783187033357
Epoch: 100 | Iteration number: [2970/4518] 65% | Training loss: 0.6869759315392786
Epoch: 100 | Iteration number: [2980/4518] 65% | Training loss: 0.6869816342656244
Epoch: 100 | Iteration number: [2990/4518] 66% | Training loss: 0.686979042666413
Epoch: 100 | Iteration number: [3000/4518] 66% | Training loss: 0.6869772067467371
Epoch: 100 | Iteration number: [3010/4518] 66% | Training loss: 0.6869791837625725
Epoch: 100 | Iteration number: [3020/4518] 66% | Training loss: 0.6869788438279107
Epoch: 100 | Iteration number: [3030/4518] 67% | Training loss: 0.6869782342375702
Epoch: 100 | Iteration number: [3040/4518] 67% | Training loss: 0.6869802200872647
Epoch: 100 | Iteration number: [3050/4518] 67% | Training loss: 0.6869799538127711
Epoch: 100 | Iteration number: [3060/4518] 67% | Training loss: 0.6869757062664219
Epoch: 100 | Iteration number: [3070/4518] 67% | Training loss: 0.6869714012557598
Epoch: 100 | Iteration number: [3080/4518] 68% | Training loss: 0.6869712362428764
Epoch: 100 | Iteration number: [3090/4518] 68% | Training loss: 0.6869698866671343
Epoch: 100 | Iteration number: [3100/4518] 68% | Training loss: 0.6869702298987296
Epoch: 100 | Iteration number: [3110/4518] 68% | Training loss: 0.6869675238799435
Epoch: 100 | Iteration number: [3120/4518] 69% | Training loss: 0.6869645304022691
Epoch: 100 | Iteration number: [3130/4518] 69% | Training loss: 0.6869627305684379
Epoch: 100 | Iteration number: [3140/4518] 69% | Training loss: 0.6869646357502907
Epoch: 100 | Iteration number: [3150/4518] 69% | Training loss: 0.6869647844254024
Epoch: 100 | Iteration number: [3160/4518] 69% | Training loss: 0.6869659094116356
Epoch: 100 | Iteration number: [3170/4518] 70% | Training loss: 0.6869621279863906
Epoch: 100 | Iteration number: [3180/4518] 70% | Training loss: 0.6869608732139539
Epoch: 100 | Iteration number: [3190/4518] 70% | Training loss: 0.6869613148015121
Epoch: 100 | Iteration number: [3200/4518] 70% | Training loss: 0.6869605600088835
Epoch: 100 | Iteration number: [3210/4518] 71% | Training loss: 0.6869557930487339
Epoch: 100 | Iteration number: [3220/4518] 71% | Training loss: 0.68695525614001
Epoch: 100 | Iteration number: [3230/4518] 71% | Training loss: 0.6869561678484867
Epoch: 100 | Iteration number: [3240/4518] 71% | Training loss: 0.6869518685304088
Epoch: 100 | Iteration number: [3250/4518] 71% | Training loss: 0.686951330936872
Epoch: 100 | Iteration number: [3260/4518] 72% | Training loss: 0.6869551612921287
Epoch: 100 | Iteration number: [3270/4518] 72% | Training loss: 0.6869551233924492
Epoch: 100 | Iteration number: [3280/4518] 72% | Training loss: 0.686954805600207
Epoch: 100 | Iteration number: [3290/4518] 72% | Training loss: 0.6869523870908743
Epoch: 100 | Iteration number: [3300/4518] 73% | Training loss: 0.6869504285581184
Epoch: 100 | Iteration number: [3310/4518] 73% | Training loss: 0.6869465592044358
Epoch: 100 | Iteration number: [3320/4518] 73% | Training loss: 0.6869478712598962
Epoch: 100 | Iteration number: [3330/4518] 73% | Training loss: 0.6869445705199027
Epoch: 100 | Iteration number: [3340/4518] 73% | Training loss: 0.6869448192283779
Epoch: 100 | Iteration number: [3350/4518] 74% | Training loss: 0.6869442352608068
Epoch: 100 | Iteration number: [3360/4518] 74% | Training loss: 0.6869457844999575
Epoch: 100 | Iteration number: [3370/4518] 74% | Training loss: 0.6869489680588776
Epoch: 100 | Iteration number: [3380/4518] 74% | Training loss: 0.6869451966687773
Epoch: 100 | Iteration number: [3390/4518] 75% | Training loss: 0.6869472298650263
Epoch: 100 | Iteration number: [3400/4518] 75% | Training loss: 0.6869456502269297
Epoch: 100 | Iteration number: [3410/4518] 75% | Training loss: 0.6869414332675094
Epoch: 100 | Iteration number: [3420/4518] 75% | Training loss: 0.6869410293492657
Epoch: 100 | Iteration number: [3430/4518] 75% | Training loss: 0.686938908965525
Epoch: 100 | Iteration number: [3440/4518] 76% | Training loss: 0.6869346638058507
Epoch: 100 | Iteration number: [3450/4518] 76% | Training loss: 0.6869344556677168
Epoch: 100 | Iteration number: [3460/4518] 76% | Training loss: 0.6869323137006319
Epoch: 100 | Iteration number: [3470/4518] 76% | Training loss: 0.6869277665697532
Epoch: 100 | Iteration number: [3480/4518] 77% | Training loss: 0.6869266853250307
Epoch: 100 | Iteration number: [3490/4518] 77% | Training loss: 0.686927514585178
Epoch: 100 | Iteration number: [3500/4518] 77% | Training loss: 0.6869247408594404
Epoch: 100 | Iteration number: [3510/4518] 77% | Training loss: 0.6869264024954576
Epoch: 100 | Iteration number: [3520/4518] 77% | Training loss: 0.6869236933914098
Epoch: 100 | Iteration number: [3530/4518] 78% | Training loss: 0.6869181323828171
Epoch: 100 | Iteration number: [3540/4518] 78% | Training loss: 0.6869152887392852
Epoch: 100 | Iteration number: [3550/4518] 78% | Training loss: 0.6869175722061748
Epoch: 100 | Iteration number: [3560/4518] 78% | Training loss: 0.6869177350837193
Epoch: 100 | Iteration number: [3570/4518] 79% | Training loss: 0.6869172089907969
Epoch: 100 | Iteration number: [3580/4518] 79% | Training loss: 0.6869174545204173
Epoch: 100 | Iteration number: [3590/4518] 79% | Training loss: 0.6869155475522151
Epoch: 100 | Iteration number: [3600/4518] 79% | Training loss: 0.6869111823042234
Epoch: 100 | Iteration number: [3610/4518] 79% | Training loss: 0.6869125469074355
Epoch: 100 | Iteration number: [3620/4518] 80% | Training loss: 0.6869130144626396
Epoch: 100 | Iteration number: [3630/4518] 80% | Training loss: 0.6869113689283366
Epoch: 100 | Iteration number: [3640/4518] 80% | Training loss: 0.6869111008205256
Epoch: 100 | Iteration number: [3650/4518] 80% | Training loss: 0.6869116404121869
Epoch: 100 | Iteration number: [3660/4518] 81% | Training loss: 0.6869117523477377
Epoch: 100 | Iteration number: [3670/4518] 81% | Training loss: 0.6869130010500916
Epoch: 100 | Iteration number: [3680/4518] 81% | Training loss: 0.6869116115343311
Epoch: 100 | Iteration number: [3690/4518] 81% | Training loss: 0.6869103189890947
Epoch: 100 | Iteration number: [3700/4518] 81% | Training loss: 0.6869101839291083
Epoch: 100 | Iteration number: [3710/4518] 82% | Training loss: 0.6869096675009098
Epoch: 100 | Iteration number: [3720/4518] 82% | Training loss: 0.6869067861027615
Epoch: 100 | Iteration number: [3730/4518] 82% | Training loss: 0.6869019211616977
Epoch: 100 | Iteration number: [3740/4518] 82% | Training loss: 0.6869018217937194
Epoch: 100 | Iteration number: [3750/4518] 83% | Training loss: 0.6868999090830485
Epoch: 100 | Iteration number: [3760/4518] 83% | Training loss: 0.6868996743192064
Epoch: 100 | Iteration number: [3770/4518] 83% | Training loss: 0.6868985111264398
Epoch: 100 | Iteration number: [3780/4518] 83% | Training loss: 0.6869001064666365
Epoch: 100 | Iteration number: [3790/4518] 83% | Training loss: 0.6869025594955384
Epoch: 100 | Iteration number: [3800/4518] 84% | Training loss: 0.6869041261704345
Epoch: 100 | Iteration number: [3810/4518] 84% | Training loss: 0.6869044117883747
Epoch: 100 | Iteration number: [3820/4518] 84% | Training loss: 0.6869043528877627
Epoch: 100 | Iteration number: [3830/4518] 84% | Training loss: 0.6869043345706581
Epoch: 100 | Iteration number: [3840/4518] 84% | Training loss: 0.6869058587743591
Epoch: 100 | Iteration number: [3850/4518] 85% | Training loss: 0.6869045392259375
Epoch: 100 | Iteration number: [3860/4518] 85% | Training loss: 0.6869071668911474
Epoch: 100 | Iteration number: [3870/4518] 85% | Training loss: 0.6869079982433516
Epoch: 100 | Iteration number: [3880/4518] 85% | Training loss: 0.6869090672774413
Epoch: 100 | Iteration number: [3890/4518] 86% | Training loss: 0.6869100564856149
Epoch: 100 | Iteration number: [3900/4518] 86% | Training loss: 0.686910686813868
Epoch: 100 | Iteration number: [3910/4518] 86% | Training loss: 0.6869097380991787
Epoch: 100 | Iteration number: [3920/4518] 86% | Training loss: 0.6869113127491913
Epoch: 100 | Iteration number: [3930/4518] 86% | Training loss: 0.6869124174421374
Epoch: 100 | Iteration number: [3940/4518] 87% | Training loss: 0.6869114360833531
Epoch: 100 | Iteration number: [3950/4518] 87% | Training loss: 0.6869088890431803
Epoch: 100 | Iteration number: [3960/4518] 87% | Training loss: 0.6869060007008639
Epoch: 100 | Iteration number: [3970/4518] 87% | Training loss: 0.6869069128552973
Epoch: 100 | Iteration number: [3980/4518] 88% | Training loss: 0.6869040840534708
Epoch: 100 | Iteration number: [3990/4518] 88% | Training loss: 0.6869062544707966
Epoch: 100 | Iteration number: [4000/4518] 88% | Training loss: 0.6869104979932308
Epoch: 100 | Iteration number: [4010/4518] 88% | Training loss: 0.6869110159445879
Epoch: 100 | Iteration number: [4020/4518] 88% | Training loss: 0.6869129673165468
Epoch: 100 | Iteration number: [4030/4518] 89% | Training loss: 0.686912585029531
Epoch: 100 | Iteration number: [4040/4518] 89% | Training loss: 0.6869133200238247
Epoch: 100 | Iteration number: [4050/4518] 89% | Training loss: 0.6869145155836035
Epoch: 100 | Iteration number: [4060/4518] 89% | Training loss: 0.6869166842235133
Epoch: 100 | Iteration number: [4070/4518] 90% | Training loss: 0.6869142216019314
Epoch: 100 | Iteration number: [4080/4518] 90% | Training loss: 0.6869163663071745
Epoch: 100 | Iteration number: [4090/4518] 90% | Training loss: 0.6869187781892371
Epoch: 100 | Iteration number: [4100/4518] 90% | Training loss: 0.6869210911233251
Epoch: 100 | Iteration number: [4110/4518] 90% | Training loss: 0.6869195478821033
Epoch: 100 | Iteration number: [4120/4518] 91% | Training loss: 0.6869183938335447
Epoch: 100 | Iteration number: [4130/4518] 91% | Training loss: 0.686920536603535
Epoch: 100 | Iteration number: [4140/4518] 91% | Training loss: 0.686918918982796
Epoch: 100 | Iteration number: [4150/4518] 91% | Training loss: 0.6869173378685871
Epoch: 100 | Iteration number: [4160/4518] 92% | Training loss: 0.6869176591388308
Epoch: 100 | Iteration number: [4170/4518] 92% | Training loss: 0.6869203394122547
Epoch: 100 | Iteration number: [4180/4518] 92% | Training loss: 0.6869194989712044
Epoch: 100 | Iteration number: [4190/4518] 92% | Training loss: 0.6869205879425376
Epoch: 100 | Iteration number: [4200/4518] 92% | Training loss: 0.6869202513212249
Epoch: 100 | Iteration number: [4210/4518] 93% | Training loss: 0.6869211269529302
Epoch: 100 | Iteration number: [4220/4518] 93% | Training loss: 0.6869187920155684
Epoch: 100 | Iteration number: [4230/4518] 93% | Training loss: 0.6869183879090257
Epoch: 100 | Iteration number: [4240/4518] 93% | Training loss: 0.6869184270922868
Epoch: 100 | Iteration number: [4250/4518] 94% | Training loss: 0.6869153833249037
Epoch: 100 | Iteration number: [4260/4518] 94% | Training loss: 0.686917178829511
Epoch: 100 | Iteration number: [4270/4518] 94% | Training loss: 0.6869164482073148
Epoch: 100 | Iteration number: [4280/4518] 94% | Training loss: 0.6869186623909763
Epoch: 100 | Iteration number: [4290/4518] 94% | Training loss: 0.6869182038279402
Epoch: 100 | Iteration number: [4300/4518] 95% | Training loss: 0.6869181065503941
Epoch: 100 | Iteration number: [4310/4518] 95% | Training loss: 0.6869150746587811
Epoch: 100 | Iteration number: [4320/4518] 95% | Training loss: 0.6869160266386138
Epoch: 100 | Iteration number: [4330/4518] 95% | Training loss: 0.6869160357303488
Epoch: 100 | Iteration number: [4340/4518] 96% | Training loss: 0.6869169255143487
Epoch: 100 | Iteration number: [4350/4518] 96% | Training loss: 0.6869130034282289
Epoch: 100 | Iteration number: [4360/4518] 96% | Training loss: 0.686912831294974
Epoch: 100 | Iteration number: [4370/4518] 96% | Training loss: 0.6869130163498274
Epoch: 100 | Iteration number: [4380/4518] 96% | Training loss: 0.6869147285751012
Epoch: 100 | Iteration number: [4390/4518] 97% | Training loss: 0.6869153070015354
Epoch: 100 | Iteration number: [4400/4518] 97% | Training loss: 0.686916085197167
Epoch: 100 | Iteration number: [4410/4518] 97% | Training loss: 0.6869130036187551
Epoch: 100 | Iteration number: [4420/4518] 97% | Training loss: 0.6869123437960223
Epoch: 100 | Iteration number: [4430/4518] 98% | Training loss: 0.6869128883557718
Epoch: 100 | Iteration number: [4440/4518] 98% | Training loss: 0.6869107804722614
Epoch: 100 | Iteration number: [4450/4518] 98% | Training loss: 0.686912363861384
Epoch: 100 | Iteration number: [4460/4518] 98% | Training loss: 0.6869122403485892
Epoch: 100 | Iteration number: [4470/4518] 98% | Training loss: 0.6869131824180851
Epoch: 100 | Iteration number: [4480/4518] 99% | Training loss: 0.6869134118780493
Epoch: 100 | Iteration number: [4490/4518] 99% | Training loss: 0.6869139397064667
Epoch: 100 | Iteration number: [4500/4518] 99% | Training loss: 0.6869126050869624
Epoch: 100 | Iteration number: [4510/4518] 99% | Training loss: 0.6869107993108999

 End of epoch: 100 | Train Loss: 0.6867561165000972 | Training Time: 641 

 End of epoch: 100 | Eval Loss: 0.6899040754960508 | Evaluating Time: 17 

 End of Test | Dice Loss: 0.9561139035224915 | Binary Cross Entropy With Logits Loss: 0.6889422571659088 
