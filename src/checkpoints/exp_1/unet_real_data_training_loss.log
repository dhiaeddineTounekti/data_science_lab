Epoch: 1 | Iteration number: [10/393] 2% | Training loss: 1.0767467439174652
Epoch: 1 | Iteration number: [20/393] 5% | Training loss: 1.0173445999622346
Epoch: 1 | Iteration number: [30/393] 7% | Training loss: 0.992661694685618
Epoch: 1 | Iteration number: [40/393] 10% | Training loss: 0.9781396314501762
Epoch: 1 | Iteration number: [50/393] 12% | Training loss: 0.966666749715805
Epoch: 1 | Iteration number: [60/393] 15% | Training loss: 0.9575710992018381
Epoch: 1 | Iteration number: [70/393] 17% | Training loss: 0.9501231253147125
Epoch: 1 | Iteration number: [80/393] 20% | Training loss: 0.943608095496893
Epoch: 1 | Iteration number: [90/393] 22% | Training loss: 0.9377202722761366
Epoch: 1 | Iteration number: [100/393] 25% | Training loss: 0.9328379648923874
Epoch: 1 | Iteration number: [110/393] 27% | Training loss: 0.9285632447762923
Epoch: 1 | Iteration number: [120/393] 30% | Training loss: 0.9248253419995308
Epoch: 1 | Iteration number: [130/393] 33% | Training loss: 0.9213812731779538
Epoch: 1 | Iteration number: [140/393] 35% | Training loss: 0.9183948201792581
Epoch: 1 | Iteration number: [150/393] 38% | Training loss: 0.9157218174139659
Epoch: 1 | Iteration number: [160/393] 40% | Training loss: 0.9132134281098843
Epoch: 1 | Iteration number: [170/393] 43% | Training loss: 0.9109024615848765
Epoch: 1 | Iteration number: [180/393] 45% | Training loss: 0.90864404241244
Epoch: 1 | Iteration number: [190/393] 48% | Training loss: 0.9065583705902099
Epoch: 1 | Iteration number: [200/393] 50% | Training loss: 0.9045663571357727
Epoch: 1 | Iteration number: [210/393] 53% | Training loss: 0.9026664577779315
Epoch: 1 | Iteration number: [220/393] 55% | Training loss: 0.9008941238576715
Epoch: 1 | Iteration number: [230/393] 58% | Training loss: 0.8992000999658004
Epoch: 1 | Iteration number: [240/393] 61% | Training loss: 0.8975637927651405
Epoch: 1 | Iteration number: [250/393] 63% | Training loss: 0.8961664967536926
Epoch: 1 | Iteration number: [260/393] 66% | Training loss: 0.8948254942893982
Epoch: 1 | Iteration number: [270/393] 68% | Training loss: 0.8933680940557409
Epoch: 1 | Iteration number: [280/393] 71% | Training loss: 0.8920436876160758
Epoch: 1 | Iteration number: [290/393] 73% | Training loss: 0.8906097255904099
Epoch: 1 | Iteration number: [300/393] 76% | Training loss: 0.8893027285734812
Epoch: 1 | Iteration number: [310/393] 78% | Training loss: 0.888045399611996
Epoch: 1 | Iteration number: [320/393] 81% | Training loss: 0.8867740966379642
Epoch: 1 | Iteration number: [330/393] 83% | Training loss: 0.8855689393751549
Epoch: 1 | Iteration number: [340/393] 86% | Training loss: 0.8844102664905436
Epoch: 1 | Iteration number: [350/393] 89% | Training loss: 0.88341655424663
Epoch: 1 | Iteration number: [360/393] 91% | Training loss: 0.882332956790924
Epoch: 1 | Iteration number: [370/393] 94% | Training loss: 0.8812702974757632
Epoch: 1 | Iteration number: [380/393] 96% | Training loss: 0.8801707612840752
Epoch: 1 | Iteration number: [390/393] 99% | Training loss: 0.8790880984220749

 End of epoch: 1 | Train Loss: 0.8766366411711424 | Training Time: 68 

 End of epoch: 1 | Eval Loss: 0.8389367740981433 | Evaluating Time: 19 
Epoch: 2 | Iteration number: [10/393] 2% | Training loss: 0.9209806978702545
Epoch: 2 | Iteration number: [20/393] 5% | Training loss: 0.8779264658689498
Epoch: 2 | Iteration number: [30/393] 7% | Training loss: 0.8636308948198954
Epoch: 2 | Iteration number: [40/393] 10% | Training loss: 0.8560089021921158
Epoch: 2 | Iteration number: [50/393] 12% | Training loss: 0.8512947511672974
Epoch: 2 | Iteration number: [60/393] 15% | Training loss: 0.8480243275562922
Epoch: 2 | Iteration number: [70/393] 17% | Training loss: 0.8456674873828888
Epoch: 2 | Iteration number: [80/393] 20% | Training loss: 0.8432361796498299
Epoch: 2 | Iteration number: [90/393] 22% | Training loss: 0.8413510256343417
Epoch: 2 | Iteration number: [100/393] 25% | Training loss: 0.8396770310401916
Epoch: 2 | Iteration number: [110/393] 27% | Training loss: 0.8382677842270244
Epoch: 2 | Iteration number: [120/393] 30% | Training loss: 0.8370143458247185
Epoch: 2 | Iteration number: [130/393] 33% | Training loss: 0.8358732200585879
Epoch: 2 | Iteration number: [140/393] 35% | Training loss: 0.8348318862063544
Epoch: 2 | Iteration number: [150/393] 38% | Training loss: 0.8337964141368865
Epoch: 2 | Iteration number: [160/393] 40% | Training loss: 0.832901070266962
Epoch: 2 | Iteration number: [170/393] 43% | Training loss: 0.8322174033697913
Epoch: 2 | Iteration number: [180/393] 45% | Training loss: 0.8315196040603849
Epoch: 2 | Iteration number: [190/393] 48% | Training loss: 0.8307462874211763
Epoch: 2 | Iteration number: [200/393] 50% | Training loss: 0.82996687322855
Epoch: 2 | Iteration number: [210/393] 53% | Training loss: 0.8292181242079962
Epoch: 2 | Iteration number: [220/393] 55% | Training loss: 0.8285412601449272
Epoch: 2 | Iteration number: [230/393] 58% | Training loss: 0.8277257955592612
Epoch: 2 | Iteration number: [240/393] 61% | Training loss: 0.8270441653827826
Epoch: 2 | Iteration number: [250/393] 63% | Training loss: 0.8262556848526001
Epoch: 2 | Iteration number: [260/393] 66% | Training loss: 0.8255142899659964
Epoch: 2 | Iteration number: [270/393] 68% | Training loss: 0.8248649575092174
Epoch: 2 | Iteration number: [280/393] 71% | Training loss: 0.8241649691547667
Epoch: 2 | Iteration number: [290/393] 73% | Training loss: 0.8234542893952337
Epoch: 2 | Iteration number: [300/393] 76% | Training loss: 0.8227608277400335
Epoch: 2 | Iteration number: [310/393] 78% | Training loss: 0.8221260545715209
Epoch: 2 | Iteration number: [320/393] 81% | Training loss: 0.8214349063113332
Epoch: 2 | Iteration number: [330/393] 83% | Training loss: 0.8208361654570608
Epoch: 2 | Iteration number: [340/393] 86% | Training loss: 0.8202074682011323
Epoch: 2 | Iteration number: [350/393] 89% | Training loss: 0.8195300737449102
Epoch: 2 | Iteration number: [360/393] 91% | Training loss: 0.8188901166121165
Epoch: 2 | Iteration number: [370/393] 94% | Training loss: 0.8182043824646924
Epoch: 2 | Iteration number: [380/393] 96% | Training loss: 0.8175809003804859
Epoch: 2 | Iteration number: [390/393] 99% | Training loss: 0.8169829854598412

 End of epoch: 2 | Train Loss: 0.8147844596370183 | Training Time: 66 

 End of epoch: 2 | Eval Loss: 0.7934518444294832 | Evaluating Time: 16 
Epoch: 3 | Iteration number: [10/393] 2% | Training loss: 0.8708056032657623
Epoch: 3 | Iteration number: [20/393] 5% | Training loss: 0.8307976990938186
Epoch: 3 | Iteration number: [30/393] 7% | Training loss: 0.8173679490884145
Epoch: 3 | Iteration number: [40/393] 10% | Training loss: 0.8101586163043976
Epoch: 3 | Iteration number: [50/393] 12% | Training loss: 0.8055736470222473
Epoch: 3 | Iteration number: [60/393] 15% | Training loss: 0.8022982478141785
Epoch: 3 | Iteration number: [70/393] 17% | Training loss: 0.8000591950757163
Epoch: 3 | Iteration number: [80/393] 20% | Training loss: 0.7983175843954087
Epoch: 3 | Iteration number: [90/393] 22% | Training loss: 0.7966924217012193
Epoch: 3 | Iteration number: [100/393] 25% | Training loss: 0.7953683483600616
Epoch: 3 | Iteration number: [110/393] 27% | Training loss: 0.7942157284779983
Epoch: 3 | Iteration number: [120/393] 30% | Training loss: 0.793166221678257
Epoch: 3 | Iteration number: [130/393] 33% | Training loss: 0.7922564433171199
Epoch: 3 | Iteration number: [140/393] 35% | Training loss: 0.7913608380726406
Epoch: 3 | Iteration number: [150/393] 38% | Training loss: 0.7905229024092356
Epoch: 3 | Iteration number: [160/393] 40% | Training loss: 0.7898061152547597
Epoch: 3 | Iteration number: [170/393] 43% | Training loss: 0.7890877884977004
Epoch: 3 | Iteration number: [180/393] 45% | Training loss: 0.7883938954936134
Epoch: 3 | Iteration number: [190/393] 48% | Training loss: 0.7877345831770646
Epoch: 3 | Iteration number: [200/393] 50% | Training loss: 0.7871985679864884
Epoch: 3 | Iteration number: [210/393] 53% | Training loss: 0.7866270343462626
Epoch: 3 | Iteration number: [220/393] 55% | Training loss: 0.7860512551936236
Epoch: 3 | Iteration number: [230/393] 58% | Training loss: 0.7855301027712615
Epoch: 3 | Iteration number: [240/393] 61% | Training loss: 0.7849783053000768
Epoch: 3 | Iteration number: [250/393] 63% | Training loss: 0.7844016284942626
Epoch: 3 | Iteration number: [260/393] 66% | Training loss: 0.78381316111638
Epoch: 3 | Iteration number: [270/393] 68% | Training loss: 0.7833397408326467
Epoch: 3 | Iteration number: [280/393] 71% | Training loss: 0.7828390872904233
Epoch: 3 | Iteration number: [290/393] 73% | Training loss: 0.7823263616397463
Epoch: 3 | Iteration number: [300/393] 76% | Training loss: 0.7818062647183737
Epoch: 3 | Iteration number: [310/393] 78% | Training loss: 0.7813636808626113
Epoch: 3 | Iteration number: [320/393] 81% | Training loss: 0.7808794338256121
Epoch: 3 | Iteration number: [330/393] 83% | Training loss: 0.7805634809262825
Epoch: 3 | Iteration number: [340/393] 86% | Training loss: 0.7801527922644335
Epoch: 3 | Iteration number: [350/393] 89% | Training loss: 0.7797295577185495
Epoch: 3 | Iteration number: [360/393] 91% | Training loss: 0.7793382133046786
Epoch: 3 | Iteration number: [370/393] 94% | Training loss: 0.7788695686572307
Epoch: 3 | Iteration number: [380/393] 96% | Training loss: 0.7784365815551657
Epoch: 3 | Iteration number: [390/393] 99% | Training loss: 0.7780369567565429

 End of epoch: 3 | Train Loss: 0.7759733392688761 | Training Time: 69 

 End of epoch: 3 | Eval Loss: 0.7614588591517234 | Evaluating Time: 17 
Epoch: 4 | Iteration number: [10/393] 2% | Training loss: 0.8372513949871063
Epoch: 4 | Iteration number: [20/393] 5% | Training loss: 0.7984436213970184
Epoch: 4 | Iteration number: [30/393] 7% | Training loss: 0.7852996130784352
Epoch: 4 | Iteration number: [40/393] 10% | Training loss: 0.7788592457771302
Epoch: 4 | Iteration number: [50/393] 12% | Training loss: 0.7745157456398011
Epoch: 4 | Iteration number: [60/393] 15% | Training loss: 0.7716815054416657
Epoch: 4 | Iteration number: [70/393] 17% | Training loss: 0.7694132055555071
Epoch: 4 | Iteration number: [80/393] 20% | Training loss: 0.7676772512495518
Epoch: 4 | Iteration number: [90/393] 22% | Training loss: 0.7663617087735071
Epoch: 4 | Iteration number: [100/393] 25% | Training loss: 0.7653227895498276
Epoch: 4 | Iteration number: [110/393] 27% | Training loss: 0.7642971754074097
Epoch: 4 | Iteration number: [120/393] 30% | Training loss: 0.7633563344677289
Epoch: 4 | Iteration number: [130/393] 33% | Training loss: 0.762570648926955
Epoch: 4 | Iteration number: [140/393] 35% | Training loss: 0.7618437911782946
Epoch: 4 | Iteration number: [150/393] 38% | Training loss: 0.7611884899934133
Epoch: 4 | Iteration number: [160/393] 40% | Training loss: 0.760539174079895
Epoch: 4 | Iteration number: [170/393] 43% | Training loss: 0.7599590266452116
Epoch: 4 | Iteration number: [180/393] 45% | Training loss: 0.7594258079926173
Epoch: 4 | Iteration number: [190/393] 48% | Training loss: 0.758869449088448
Epoch: 4 | Iteration number: [200/393] 50% | Training loss: 0.7583892306685448
Epoch: 4 | Iteration number: [210/393] 53% | Training loss: 0.7578702869869414
Epoch: 4 | Iteration number: [220/393] 55% | Training loss: 0.7574461682276292
Epoch: 4 | Iteration number: [230/393] 58% | Training loss: 0.7570264450881792
Epoch: 4 | Iteration number: [240/393] 61% | Training loss: 0.756579191237688
Epoch: 4 | Iteration number: [250/393] 63% | Training loss: 0.7561289024353027
Epoch: 4 | Iteration number: [260/393] 66% | Training loss: 0.755718899002442
Epoch: 4 | Iteration number: [270/393] 68% | Training loss: 0.7552721164844655
Epoch: 4 | Iteration number: [280/393] 71% | Training loss: 0.7548835633056504
Epoch: 4 | Iteration number: [290/393] 73% | Training loss: 0.7544824248757855
Epoch: 4 | Iteration number: [300/393] 76% | Training loss: 0.7540853027502695
Epoch: 4 | Iteration number: [310/393] 78% | Training loss: 0.7537308479509046
Epoch: 4 | Iteration number: [320/393] 81% | Training loss: 0.7534173073247075
Epoch: 4 | Iteration number: [330/393] 83% | Training loss: 0.7530922765081579
Epoch: 4 | Iteration number: [340/393] 86% | Training loss: 0.7527316482628092
Epoch: 4 | Iteration number: [350/393] 89% | Training loss: 0.7524185972554344
Epoch: 4 | Iteration number: [360/393] 91% | Training loss: 0.7521125528547499
Epoch: 4 | Iteration number: [370/393] 94% | Training loss: 0.7518078534989744
Epoch: 4 | Iteration number: [380/393] 96% | Training loss: 0.7514957859327919
Epoch: 4 | Iteration number: [390/393] 99% | Training loss: 0.751187692850064

 End of epoch: 4 | Train Loss: 0.7492133612547819 | Training Time: 70 

 End of epoch: 4 | Eval Loss: 0.7390090981308295 | Evaluating Time: 17 
Epoch: 5 | Iteration number: [10/393] 2% | Training loss: 0.8123387217521667
Epoch: 5 | Iteration number: [20/393] 5% | Training loss: 0.7753114968538284
Epoch: 5 | Iteration number: [30/393] 7% | Training loss: 0.7628725151220958
Epoch: 5 | Iteration number: [40/393] 10% | Training loss: 0.756365779042244
Epoch: 5 | Iteration number: [50/393] 12% | Training loss: 0.7525483989715576
Epoch: 5 | Iteration number: [60/393] 15% | Training loss: 0.7498859534660975
Epoch: 5 | Iteration number: [70/393] 17% | Training loss: 0.7478309963430677
Epoch: 5 | Iteration number: [80/393] 20% | Training loss: 0.7462766148149967
Epoch: 5 | Iteration number: [90/393] 22% | Training loss: 0.7450800167189704
Epoch: 5 | Iteration number: [100/393] 25% | Training loss: 0.7440195018053055
Epoch: 5 | Iteration number: [110/393] 27% | Training loss: 0.7432796781713312
Epoch: 5 | Iteration number: [120/393] 30% | Training loss: 0.7425116901596387
Epoch: 5 | Iteration number: [130/393] 33% | Training loss: 0.7418423240001385
Epoch: 5 | Iteration number: [140/393] 35% | Training loss: 0.7411927397762026
Epoch: 5 | Iteration number: [150/393] 38% | Training loss: 0.7407276674111685
Epoch: 5 | Iteration number: [160/393] 40% | Training loss: 0.7401958517730236
Epoch: 5 | Iteration number: [170/393] 43% | Training loss: 0.7396573711844051
Epoch: 5 | Iteration number: [180/393] 45% | Training loss: 0.7391847732994291
Epoch: 5 | Iteration number: [190/393] 48% | Training loss: 0.7388348344125246
Epoch: 5 | Iteration number: [200/393] 50% | Training loss: 0.7384785059094429
Epoch: 5 | Iteration number: [210/393] 53% | Training loss: 0.7381099811622075
Epoch: 5 | Iteration number: [220/393] 55% | Training loss: 0.7378082478588278
Epoch: 5 | Iteration number: [230/393] 58% | Training loss: 0.7374397876469986
Epoch: 5 | Iteration number: [240/393] 61% | Training loss: 0.7371382576723894
Epoch: 5 | Iteration number: [250/393] 63% | Training loss: 0.7367951481342315
Epoch: 5 | Iteration number: [260/393] 66% | Training loss: 0.736472076177597
Epoch: 5 | Iteration number: [270/393] 68% | Training loss: 0.7361638607802214
Epoch: 5 | Iteration number: [280/393] 71% | Training loss: 0.7358260703938347
Epoch: 5 | Iteration number: [290/393] 73% | Training loss: 0.7355236178842084
Epoch: 5 | Iteration number: [300/393] 76% | Training loss: 0.7353084411223729
Epoch: 5 | Iteration number: [310/393] 78% | Training loss: 0.7350685796430034
Epoch: 5 | Iteration number: [320/393] 81% | Training loss: 0.7348368547856807
Epoch: 5 | Iteration number: [330/393] 83% | Training loss: 0.7345946163842172
Epoch: 5 | Iteration number: [340/393] 86% | Training loss: 0.7343474982415928
Epoch: 5 | Iteration number: [350/393] 89% | Training loss: 0.734103855916432
Epoch: 5 | Iteration number: [360/393] 91% | Training loss: 0.7338854038053089
Epoch: 5 | Iteration number: [370/393] 94% | Training loss: 0.7336785664429536
Epoch: 5 | Iteration number: [380/393] 96% | Training loss: 0.7334713884090123
Epoch: 5 | Iteration number: [390/393] 99% | Training loss: 0.7332677865639711

 End of epoch: 5 | Train Loss: 0.731353077573024 | Training Time: 69 

 End of epoch: 5 | Eval Loss: 0.7248529061979178 | Evaluating Time: 17 
Epoch: 6 | Iteration number: [10/393] 2% | Training loss: 0.7984357833862304
Epoch: 6 | Iteration number: [20/393] 5% | Training loss: 0.7616832971572876
Epoch: 6 | Iteration number: [30/393] 7% | Training loss: 0.7490057051181793
Epoch: 6 | Iteration number: [40/393] 10% | Training loss: 0.7427625194191932
Epoch: 6 | Iteration number: [50/393] 12% | Training loss: 0.7390404653549194
Epoch: 6 | Iteration number: [60/393] 15% | Training loss: 0.7363311688105265
Epoch: 6 | Iteration number: [70/393] 17% | Training loss: 0.7340781033039093
Epoch: 6 | Iteration number: [80/393] 20% | Training loss: 0.7327441811561585
Epoch: 6 | Iteration number: [90/393] 22% | Training loss: 0.7316396951675415
Epoch: 6 | Iteration number: [100/393] 25% | Training loss: 0.7306883829832077
Epoch: 6 | Iteration number: [110/393] 27% | Training loss: 0.7299003844911401
Epoch: 6 | Iteration number: [120/393] 30% | Training loss: 0.7291893646121025
Epoch: 6 | Iteration number: [130/393] 33% | Training loss: 0.7285395585573636
Epoch: 6 | Iteration number: [140/393] 35% | Training loss: 0.7280185848474503
Epoch: 6 | Iteration number: [150/393] 38% | Training loss: 0.7274972506364187
Epoch: 6 | Iteration number: [160/393] 40% | Training loss: 0.7270156100392342
Epoch: 6 | Iteration number: [170/393] 43% | Training loss: 0.7267204614246593
Epoch: 6 | Iteration number: [180/393] 45% | Training loss: 0.7263288289308548
Epoch: 6 | Iteration number: [190/393] 48% | Training loss: 0.7259962288956893
Epoch: 6 | Iteration number: [200/393] 50% | Training loss: 0.725736300945282
Epoch: 6 | Iteration number: [210/393] 53% | Training loss: 0.725433227561769
Epoch: 6 | Iteration number: [220/393] 55% | Training loss: 0.7251906302842227
Epoch: 6 | Iteration number: [230/393] 58% | Training loss: 0.7248304786889449
Epoch: 6 | Iteration number: [240/393] 61% | Training loss: 0.7246173585454623
Epoch: 6 | Iteration number: [250/393] 63% | Training loss: 0.7244070358276368
Epoch: 6 | Iteration number: [260/393] 66% | Training loss: 0.7241517468140676
Epoch: 6 | Iteration number: [270/393] 68% | Training loss: 0.7239576174153222
Epoch: 6 | Iteration number: [280/393] 71% | Training loss: 0.7237264360700335
Epoch: 6 | Iteration number: [290/393] 73% | Training loss: 0.7235394054445727
Epoch: 6 | Iteration number: [300/393] 76% | Training loss: 0.7233421089251836
Epoch: 6 | Iteration number: [310/393] 78% | Training loss: 0.7231401385799531
Epoch: 6 | Iteration number: [320/393] 81% | Training loss: 0.7229525508359075
Epoch: 6 | Iteration number: [330/393] 83% | Training loss: 0.7227523108323415
Epoch: 6 | Iteration number: [340/393] 86% | Training loss: 0.7225656919619616
Epoch: 6 | Iteration number: [350/393] 89% | Training loss: 0.7223799308708736
Epoch: 6 | Iteration number: [360/393] 91% | Training loss: 0.722192944586277
Epoch: 6 | Iteration number: [370/393] 94% | Training loss: 0.7220221248832909
Epoch: 6 | Iteration number: [380/393] 96% | Training loss: 0.721813703524439
Epoch: 6 | Iteration number: [390/393] 99% | Training loss: 0.7216855116379567

 End of epoch: 6 | Train Loss: 0.7198195192043412 | Training Time: 69 

 End of epoch: 6 | Eval Loss: 0.7146997220662176 | Evaluating Time: 17 
Epoch: 7 | Iteration number: [10/393] 2% | Training loss: 0.7862234294414521
Epoch: 7 | Iteration number: [20/393] 5% | Training loss: 0.7500804960727692
Epoch: 7 | Iteration number: [30/393] 7% | Training loss: 0.737842341264089
Epoch: 7 | Iteration number: [40/393] 10% | Training loss: 0.7320784315466881
Epoch: 7 | Iteration number: [50/393] 12% | Training loss: 0.7285330247879028
Epoch: 7 | Iteration number: [60/393] 15% | Training loss: 0.7262995670239131
Epoch: 7 | Iteration number: [70/393] 17% | Training loss: 0.724416309595108
Epoch: 7 | Iteration number: [80/393] 20% | Training loss: 0.7230070866644382
Epoch: 7 | Iteration number: [90/393] 22% | Training loss: 0.7218585146798028
Epoch: 7 | Iteration number: [100/393] 25% | Training loss: 0.72102179646492
Epoch: 7 | Iteration number: [110/393] 27% | Training loss: 0.7202864012934945
Epoch: 7 | Iteration number: [120/393] 30% | Training loss: 0.7195983643333117
Epoch: 7 | Iteration number: [130/393] 33% | Training loss: 0.7190414405786074
Epoch: 7 | Iteration number: [140/393] 35% | Training loss: 0.7185443175690515
Epoch: 7 | Iteration number: [150/393] 38% | Training loss: 0.7180803831418355
Epoch: 7 | Iteration number: [160/393] 40% | Training loss: 0.7176824480295181
Epoch: 7 | Iteration number: [170/393] 43% | Training loss: 0.717334835318958
Epoch: 7 | Iteration number: [180/393] 45% | Training loss: 0.7170090907149844
Epoch: 7 | Iteration number: [190/393] 48% | Training loss: 0.7166895543274127
Epoch: 7 | Iteration number: [200/393] 50% | Training loss: 0.7164020881056785
Epoch: 7 | Iteration number: [210/393] 53% | Training loss: 0.7161996639910199
Epoch: 7 | Iteration number: [220/393] 55% | Training loss: 0.7159766096960415
Epoch: 7 | Iteration number: [230/393] 58% | Training loss: 0.7157452285289765
Epoch: 7 | Iteration number: [240/393] 61% | Training loss: 0.7155592980484168
Epoch: 7 | Iteration number: [250/393] 63% | Training loss: 0.7153332982063293
Epoch: 7 | Iteration number: [260/393] 66% | Training loss: 0.7151600640553695
Epoch: 7 | Iteration number: [270/393] 68% | Training loss: 0.715023934841156
Epoch: 7 | Iteration number: [280/393] 71% | Training loss: 0.7148816677076476
Epoch: 7 | Iteration number: [290/393] 73% | Training loss: 0.7147563455433681
Epoch: 7 | Iteration number: [300/393] 76% | Training loss: 0.7146296972036361
Epoch: 7 | Iteration number: [310/393] 78% | Training loss: 0.7144770989494938
Epoch: 7 | Iteration number: [320/393] 81% | Training loss: 0.7143369045108556
Epoch: 7 | Iteration number: [330/393] 83% | Training loss: 0.714199923024033
Epoch: 7 | Iteration number: [340/393] 86% | Training loss: 0.7140638919437633
Epoch: 7 | Iteration number: [350/393] 89% | Training loss: 0.7139261736188616
Epoch: 7 | Iteration number: [360/393] 91% | Training loss: 0.7137982179721196
Epoch: 7 | Iteration number: [370/393] 94% | Training loss: 0.7136723279953003
Epoch: 7 | Iteration number: [380/393] 96% | Training loss: 0.7135631609904138
Epoch: 7 | Iteration number: [390/393] 99% | Training loss: 0.7134402328576797

 End of epoch: 7 | Train Loss: 0.7115913351983515 | Training Time: 68 

 End of epoch: 7 | Eval Loss: 0.7085937261581421 | Evaluating Time: 16 
Epoch: 8 | Iteration number: [10/393] 2% | Training loss: 0.7794675588607788
Epoch: 8 | Iteration number: [20/393] 5% | Training loss: 0.7438875406980514
Epoch: 8 | Iteration number: [30/393] 7% | Training loss: 0.7319516539573669
Epoch: 8 | Iteration number: [40/393] 10% | Training loss: 0.7261564448475838
Epoch: 8 | Iteration number: [50/393] 12% | Training loss: 0.7226327168941498
Epoch: 8 | Iteration number: [60/393] 15% | Training loss: 0.7200085818767548
Epoch: 8 | Iteration number: [70/393] 17% | Training loss: 0.7183926931449345
Epoch: 8 | Iteration number: [80/393] 20% | Training loss: 0.7169961348176003
Epoch: 8 | Iteration number: [90/393] 22% | Training loss: 0.7159644762674967
Epoch: 8 | Iteration number: [100/393] 25% | Training loss: 0.7151431483030319
Epoch: 8 | Iteration number: [110/393] 27% | Training loss: 0.7143153109333732
Epoch: 8 | Iteration number: [120/393] 30% | Training loss: 0.7138476277391116
Epoch: 8 | Iteration number: [130/393] 33% | Training loss: 0.7133716743725996
Epoch: 8 | Iteration number: [140/393] 35% | Training loss: 0.7128725400992802
Epoch: 8 | Iteration number: [150/393] 38% | Training loss: 0.7124442295233409
Epoch: 8 | Iteration number: [160/393] 40% | Training loss: 0.7121785551309585
Epoch: 8 | Iteration number: [170/393] 43% | Training loss: 0.7118430211263544
Epoch: 8 | Iteration number: [180/393] 45% | Training loss: 0.7115368260277642
Epoch: 8 | Iteration number: [190/393] 48% | Training loss: 0.7113092137010474
Epoch: 8 | Iteration number: [200/393] 50% | Training loss: 0.7110663652420044
Epoch: 8 | Iteration number: [210/393] 53% | Training loss: 0.710839147227151
Epoch: 8 | Iteration number: [220/393] 55% | Training loss: 0.710688283497637
Epoch: 8 | Iteration number: [230/393] 58% | Training loss: 0.7104840348596159
Epoch: 8 | Iteration number: [240/393] 61% | Training loss: 0.7102954596281051
Epoch: 8 | Iteration number: [250/393] 63% | Training loss: 0.7100971505641938
Epoch: 8 | Iteration number: [260/393] 66% | Training loss: 0.7099313939993198
Epoch: 8 | Iteration number: [270/393] 68% | Training loss: 0.7097641450387461
Epoch: 8 | Iteration number: [280/393] 71% | Training loss: 0.7096075745565551
Epoch: 8 | Iteration number: [290/393] 73% | Training loss: 0.709443526432432
Epoch: 8 | Iteration number: [300/393] 76% | Training loss: 0.7092767965793609
Epoch: 8 | Iteration number: [310/393] 78% | Training loss: 0.7091277116729368
Epoch: 8 | Iteration number: [320/393] 81% | Training loss: 0.7089517330750823
Epoch: 8 | Iteration number: [330/393] 83% | Training loss: 0.7088161638288787
Epoch: 8 | Iteration number: [340/393] 86% | Training loss: 0.7086906385772368
Epoch: 8 | Iteration number: [350/393] 89% | Training loss: 0.7085590783187321
Epoch: 8 | Iteration number: [360/393] 91% | Training loss: 0.7084320874677764
Epoch: 8 | Iteration number: [370/393] 94% | Training loss: 0.7083204288740416
Epoch: 8 | Iteration number: [380/393] 96% | Training loss: 0.7082376257369393
Epoch: 8 | Iteration number: [390/393] 99% | Training loss: 0.7082102355284569

 End of epoch: 8 | Train Loss: 0.7063938609819679 | Training Time: 65 

 End of epoch: 8 | Eval Loss: 0.7050689580489178 | Evaluating Time: 16 
Epoch: 9 | Iteration number: [10/393] 2% | Training loss: 0.7755291938781739
Epoch: 9 | Iteration number: [20/393] 5% | Training loss: 0.7406075417995452
Epoch: 9 | Iteration number: [30/393] 7% | Training loss: 0.7284348050753275
Epoch: 9 | Iteration number: [40/393] 10% | Training loss: 0.722528052330017
Epoch: 9 | Iteration number: [50/393] 12% | Training loss: 0.7189010238647461
Epoch: 9 | Iteration number: [60/393] 15% | Training loss: 0.7162979592879614
Epoch: 9 | Iteration number: [70/393] 17% | Training loss: 0.7145365187100001
Epoch: 9 | Iteration number: [80/393] 20% | Training loss: 0.7132084563374519
Epoch: 9 | Iteration number: [90/393] 22% | Training loss: 0.7120713426007165
Epoch: 9 | Iteration number: [100/393] 25% | Training loss: 0.711199956536293
Epoch: 9 | Iteration number: [110/393] 27% | Training loss: 0.7105196882377971
Epoch: 9 | Iteration number: [120/393] 30% | Training loss: 0.7099091758330663
Epoch: 9 | Iteration number: [130/393] 33% | Training loss: 0.7093939616129948
Epoch: 9 | Iteration number: [140/393] 35% | Training loss: 0.7089675558464867
Epoch: 9 | Iteration number: [150/393] 38% | Training loss: 0.7086400739351908
Epoch: 9 | Iteration number: [160/393] 40% | Training loss: 0.7083151184022427
Epoch: 9 | Iteration number: [170/393] 43% | Training loss: 0.7079341236282798
Epoch: 9 | Iteration number: [180/393] 45% | Training loss: 0.7076744155751334
Epoch: 9 | Iteration number: [190/393] 48% | Training loss: 0.7074102699756623
Epoch: 9 | Iteration number: [200/393] 50% | Training loss: 0.7072283002734184
Epoch: 9 | Iteration number: [210/393] 53% | Training loss: 0.7070738483042944
Epoch: 9 | Iteration number: [220/393] 55% | Training loss: 0.7069451169534163
Epoch: 9 | Iteration number: [230/393] 58% | Training loss: 0.7068154923293901
Epoch: 9 | Iteration number: [240/393] 61% | Training loss: 0.7066579508284728
Epoch: 9 | Iteration number: [250/393] 63% | Training loss: 0.7064693148136139
Epoch: 9 | Iteration number: [260/393] 66% | Training loss: 0.7063147780986933
Epoch: 9 | Iteration number: [270/393] 68% | Training loss: 0.7061732371648153
Epoch: 9 | Iteration number: [280/393] 71% | Training loss: 0.70602186024189
Epoch: 9 | Iteration number: [290/393] 73% | Training loss: 0.7058626333187367
Epoch: 9 | Iteration number: [300/393] 76% | Training loss: 0.7057333443562189
Epoch: 9 | Iteration number: [310/393] 78% | Training loss: 0.7056172866975108
Epoch: 9 | Iteration number: [320/393] 81% | Training loss: 0.7054760610684753
Epoch: 9 | Iteration number: [330/393] 83% | Training loss: 0.7053590494574923
Epoch: 9 | Iteration number: [340/393] 86% | Training loss: 0.7052662467255312
Epoch: 9 | Iteration number: [350/393] 89% | Training loss: 0.7051182227475302
Epoch: 9 | Iteration number: [360/393] 91% | Training loss: 0.7050678160455491
Epoch: 9 | Iteration number: [370/393] 94% | Training loss: 0.7049646053765272
Epoch: 9 | Iteration number: [380/393] 96% | Training loss: 0.704878380424098
Epoch: 9 | Iteration number: [390/393] 99% | Training loss: 0.704785248866448

 End of epoch: 9 | Train Loss: 0.7029674324673854 | Training Time: 67 

 End of epoch: 9 | Eval Loss: 0.70087794381745 | Evaluating Time: 16 
Epoch: 10 | Iteration number: [10/393] 2% | Training loss: 0.7718462765216827
Epoch: 10 | Iteration number: [20/393] 5% | Training loss: 0.7362501621246338
Epoch: 10 | Iteration number: [30/393] 7% | Training loss: 0.724612424770991
Epoch: 10 | Iteration number: [40/393] 10% | Training loss: 0.7186915427446365
Epoch: 10 | Iteration number: [50/393] 12% | Training loss: 0.7151514089107514
Epoch: 10 | Iteration number: [60/393] 15% | Training loss: 0.7127190510431926
Epoch: 10 | Iteration number: [70/393] 17% | Training loss: 0.7110182447092873
Epoch: 10 | Iteration number: [80/393] 20% | Training loss: 0.709773077070713
Epoch: 10 | Iteration number: [90/393] 22% | Training loss: 0.7088465147548252
Epoch: 10 | Iteration number: [100/393] 25% | Training loss: 0.7080008602142334
Epoch: 10 | Iteration number: [110/393] 27% | Training loss: 0.7072693434628573
Epoch: 10 | Iteration number: [120/393] 30% | Training loss: 0.7067226871848107
Epoch: 10 | Iteration number: [130/393] 33% | Training loss: 0.7062261984898494
Epoch: 10 | Iteration number: [140/393] 35% | Training loss: 0.7058201351336071
Epoch: 10 | Iteration number: [150/393] 38% | Training loss: 0.7054264756043752
Epoch: 10 | Iteration number: [160/393] 40% | Training loss: 0.7051504034548998
Epoch: 10 | Iteration number: [170/393] 43% | Training loss: 0.7049107123823727
Epoch: 10 | Iteration number: [180/393] 45% | Training loss: 0.7047377424107657
Epoch: 10 | Iteration number: [190/393] 48% | Training loss: 0.7045461510357104
Epoch: 10 | Iteration number: [200/393] 50% | Training loss: 0.7042984732985497
Epoch: 10 | Iteration number: [210/393] 53% | Training loss: 0.7041097765877133
Epoch: 10 | Iteration number: [220/393] 55% | Training loss: 0.7039038492874665
Epoch: 10 | Iteration number: [230/393] 58% | Training loss: 0.7037336559399314
Epoch: 10 | Iteration number: [240/393] 61% | Training loss: 0.7035576269030571
Epoch: 10 | Iteration number: [250/393] 63% | Training loss: 0.7034723343849182
Epoch: 10 | Iteration number: [260/393] 66% | Training loss: 0.7033227317608319
Epoch: 10 | Iteration number: [270/393] 68% | Training loss: 0.7032063583532969
Epoch: 10 | Iteration number: [280/393] 71% | Training loss: 0.7031069334064212
Epoch: 10 | Iteration number: [290/393] 73% | Training loss: 0.7030093965859249
Epoch: 10 | Iteration number: [300/393] 76% | Training loss: 0.7029153662919998
Epoch: 10 | Iteration number: [310/393] 78% | Training loss: 0.7028170885578279
Epoch: 10 | Iteration number: [320/393] 81% | Training loss: 0.7027207531034947
Epoch: 10 | Iteration number: [330/393] 83% | Training loss: 0.7026303468328534
Epoch: 10 | Iteration number: [340/393] 86% | Training loss: 0.7025131388622172
Epoch: 10 | Iteration number: [350/393] 89% | Training loss: 0.7024308548654828
Epoch: 10 | Iteration number: [360/393] 91% | Training loss: 0.702285224530432
Epoch: 10 | Iteration number: [370/393] 94% | Training loss: 0.7021998674482912
Epoch: 10 | Iteration number: [380/393] 96% | Training loss: 0.7020949045294209
Epoch: 10 | Iteration number: [390/393] 99% | Training loss: 0.7019904468304071

 End of epoch: 10 | Train Loss: 0.7001927457086305 | Training Time: 64 

 End of epoch: 10 | Eval Loss: 0.6985033373443448 | Evaluating Time: 16 
Epoch: 11 | Iteration number: [10/393] 2% | Training loss: 0.7686909317970276
Epoch: 11 | Iteration number: [20/393] 5% | Training loss: 0.7343974083662033
Epoch: 11 | Iteration number: [30/393] 7% | Training loss: 0.723157529036204
Epoch: 11 | Iteration number: [40/393] 10% | Training loss: 0.7169100672006607
Epoch: 11 | Iteration number: [50/393] 12% | Training loss: 0.7135134983062744
Epoch: 11 | Iteration number: [60/393] 15% | Training loss: 0.7111137578884761
Epoch: 11 | Iteration number: [70/393] 17% | Training loss: 0.7092462658882142
Epoch: 11 | Iteration number: [80/393] 20% | Training loss: 0.707965687662363
Epoch: 11 | Iteration number: [90/393] 22% | Training loss: 0.7069369660483467
Epoch: 11 | Iteration number: [100/393] 25% | Training loss: 0.7061001718044281
Epoch: 11 | Iteration number: [110/393] 27% | Training loss: 0.705430913513357
Epoch: 11 | Iteration number: [120/393] 30% | Training loss: 0.7048810010155042
Epoch: 11 | Iteration number: [130/393] 33% | Training loss: 0.7043697292988117
Epoch: 11 | Iteration number: [140/393] 35% | Training loss: 0.7039696876491819
Epoch: 11 | Iteration number: [150/393] 38% | Training loss: 0.703568617105484
Epoch: 11 | Iteration number: [160/393] 40% | Training loss: 0.7032852694392204
Epoch: 11 | Iteration number: [170/393] 43% | Training loss: 0.7029715552049525
Epoch: 11 | Iteration number: [180/393] 45% | Training loss: 0.7027357445822822
Epoch: 11 | Iteration number: [190/393] 48% | Training loss: 0.7024507946089694
Epoch: 11 | Iteration number: [200/393] 50% | Training loss: 0.7021614092588425
Epoch: 11 | Iteration number: [210/393] 53% | Training loss: 0.7019548030126662
Epoch: 11 | Iteration number: [220/393] 55% | Training loss: 0.7017734855413437
Epoch: 11 | Iteration number: [230/393] 58% | Training loss: 0.7015733641126881
Epoch: 11 | Iteration number: [240/393] 61% | Training loss: 0.701399024327596
Epoch: 11 | Iteration number: [250/393] 63% | Training loss: 0.7012546291351318
Epoch: 11 | Iteration number: [260/393] 66% | Training loss: 0.7010999961541249
Epoch: 11 | Iteration number: [270/393] 68% | Training loss: 0.7009633706675635
Epoch: 11 | Iteration number: [280/393] 71% | Training loss: 0.7008089220949582
Epoch: 11 | Iteration number: [290/393] 73% | Training loss: 0.7006433392393178
Epoch: 11 | Iteration number: [300/393] 76% | Training loss: 0.7005212138096492
Epoch: 11 | Iteration number: [310/393] 78% | Training loss: 0.7004354557683391
Epoch: 11 | Iteration number: [320/393] 81% | Training loss: 0.7003601443022489
Epoch: 11 | Iteration number: [330/393] 83% | Training loss: 0.7002677731441729
Epoch: 11 | Iteration number: [340/393] 86% | Training loss: 0.7001867262756123
Epoch: 11 | Iteration number: [350/393] 89% | Training loss: 0.7001158622332981
Epoch: 11 | Iteration number: [360/393] 91% | Training loss: 0.7000230100419786
Epoch: 11 | Iteration number: [370/393] 94% | Training loss: 0.6999340840288111
Epoch: 11 | Iteration number: [380/393] 96% | Training loss: 0.6998791755814301
Epoch: 11 | Iteration number: [390/393] 99% | Training loss: 0.6998057093375768

 End of epoch: 11 | Train Loss: 0.6980032332374243 | Training Time: 64 

 End of epoch: 11 | Eval Loss: 0.6968917469589078 | Evaluating Time: 16 
Epoch: 12 | Iteration number: [10/393] 2% | Training loss: 0.7660915076732635
Epoch: 12 | Iteration number: [20/393] 5% | Training loss: 0.7317851155996322
Epoch: 12 | Iteration number: [30/393] 7% | Training loss: 0.7204604427019755
Epoch: 12 | Iteration number: [40/393] 10% | Training loss: 0.7144687518477439
Epoch: 12 | Iteration number: [50/393] 12% | Training loss: 0.7108652591705322
Epoch: 12 | Iteration number: [60/393] 15% | Training loss: 0.7086068868637085
Epoch: 12 | Iteration number: [70/393] 17% | Training loss: 0.7070464253425598
Epoch: 12 | Iteration number: [80/393] 20% | Training loss: 0.705794022232294
Epoch: 12 | Iteration number: [90/393] 22% | Training loss: 0.7048409005006154
Epoch: 12 | Iteration number: [100/393] 25% | Training loss: 0.7041033148765564
Epoch: 12 | Iteration number: [110/393] 27% | Training loss: 0.7033784633333032
Epoch: 12 | Iteration number: [120/393] 30% | Training loss: 0.7027954310178757
Epoch: 12 | Iteration number: [130/393] 33% | Training loss: 0.7023789891829857
Epoch: 12 | Iteration number: [140/393] 35% | Training loss: 0.7018700207982744
Epoch: 12 | Iteration number: [150/393] 38% | Training loss: 0.7015178390343983
Epoch: 12 | Iteration number: [160/393] 40% | Training loss: 0.701197937130928
Epoch: 12 | Iteration number: [170/393] 43% | Training loss: 0.7008132464745466
Epoch: 12 | Iteration number: [180/393] 45% | Training loss: 0.700558352139261
Epoch: 12 | Iteration number: [190/393] 48% | Training loss: 0.7003396975366692
Epoch: 12 | Iteration number: [200/393] 50% | Training loss: 0.7002089875936508
Epoch: 12 | Iteration number: [210/393] 53% | Training loss: 0.7000723308040983
Epoch: 12 | Iteration number: [220/393] 55% | Training loss: 0.6998865639621561
Epoch: 12 | Iteration number: [230/393] 58% | Training loss: 0.6996943911780482
Epoch: 12 | Iteration number: [240/393] 61% | Training loss: 0.699573295811812
Epoch: 12 | Iteration number: [250/393] 63% | Training loss: 0.69940948843956
Epoch: 12 | Iteration number: [260/393] 66% | Training loss: 0.6993093648782143
Epoch: 12 | Iteration number: [270/393] 68% | Training loss: 0.699194715641163
Epoch: 12 | Iteration number: [280/393] 71% | Training loss: 0.699082449717181
Epoch: 12 | Iteration number: [290/393] 73% | Training loss: 0.6989857934672257
Epoch: 12 | Iteration number: [300/393] 76% | Training loss: 0.6988679699103038
Epoch: 12 | Iteration number: [310/393] 78% | Training loss: 0.6987699102970861
Epoch: 12 | Iteration number: [320/393] 81% | Training loss: 0.6986567888408899
Epoch: 12 | Iteration number: [330/393] 83% | Training loss: 0.6985665957132975
Epoch: 12 | Iteration number: [340/393] 86% | Training loss: 0.6985072914291831
Epoch: 12 | Iteration number: [350/393] 89% | Training loss: 0.6984562725680215
Epoch: 12 | Iteration number: [360/393] 91% | Training loss: 0.6983879079421361
Epoch: 12 | Iteration number: [370/393] 94% | Training loss: 0.6983227945662833
Epoch: 12 | Iteration number: [380/393] 96% | Training loss: 0.698234559203449
Epoch: 12 | Iteration number: [390/393] 99% | Training loss: 0.6981542941851494

 End of epoch: 12 | Train Loss: 0.6963725378191805 | Training Time: 64 

 End of epoch: 12 | Eval Loss: 0.6954862584873122 | Evaluating Time: 16 
Epoch: 13 | Iteration number: [10/393] 2% | Training loss: 0.7654777348041535
Epoch: 13 | Iteration number: [20/393] 5% | Training loss: 0.7308788001537323
Epoch: 13 | Iteration number: [30/393] 7% | Training loss: 0.7187568147977194
Epoch: 13 | Iteration number: [40/393] 10% | Training loss: 0.7130174413323402
Epoch: 13 | Iteration number: [50/393] 12% | Training loss: 0.7096349620819091
Epoch: 13 | Iteration number: [60/393] 15% | Training loss: 0.7073889305194219
Epoch: 13 | Iteration number: [70/393] 17% | Training loss: 0.7056693170751844
Epoch: 13 | Iteration number: [80/393] 20% | Training loss: 0.7043941482901573
Epoch: 13 | Iteration number: [90/393] 22% | Training loss: 0.7033209615283542
Epoch: 13 | Iteration number: [100/393] 25% | Training loss: 0.702546084523201
Epoch: 13 | Iteration number: [110/393] 27% | Training loss: 0.7019085315140811
Epoch: 13 | Iteration number: [120/393] 30% | Training loss: 0.701345477004846
Epoch: 13 | Iteration number: [130/393] 33% | Training loss: 0.7009434094795814
Epoch: 13 | Iteration number: [140/393] 35% | Training loss: 0.7005015024117061
Epoch: 13 | Iteration number: [150/393] 38% | Training loss: 0.7001487819353739
Epoch: 13 | Iteration number: [160/393] 40% | Training loss: 0.6998612474650144
Epoch: 13 | Iteration number: [170/393] 43% | Training loss: 0.6995964302736171
Epoch: 13 | Iteration number: [180/393] 45% | Training loss: 0.6993537654479345
Epoch: 13 | Iteration number: [190/393] 48% | Training loss: 0.6991323493028941
Epoch: 13 | Iteration number: [200/393] 50% | Training loss: 0.6989708158373833
Epoch: 13 | Iteration number: [210/393] 53% | Training loss: 0.6987969370115371
Epoch: 13 | Iteration number: [220/393] 55% | Training loss: 0.6986748104745691
Epoch: 13 | Iteration number: [230/393] 58% | Training loss: 0.6984619296115377
Epoch: 13 | Iteration number: [240/393] 61% | Training loss: 0.6983302588264148
Epoch: 13 | Iteration number: [250/393] 63% | Training loss: 0.6982009146213531
Epoch: 13 | Iteration number: [260/393] 66% | Training loss: 0.6980878669482011
Epoch: 13 | Iteration number: [270/393] 68% | Training loss: 0.6979755487706926
Epoch: 13 | Iteration number: [280/393] 71% | Training loss: 0.6978485999362809
Epoch: 13 | Iteration number: [290/393] 73% | Training loss: 0.6977442780445362
Epoch: 13 | Iteration number: [300/393] 76% | Training loss: 0.6976662733157476
Epoch: 13 | Iteration number: [310/393] 78% | Training loss: 0.6975735854717993
Epoch: 13 | Iteration number: [320/393] 81% | Training loss: 0.6975047020241618
Epoch: 13 | Iteration number: [330/393] 83% | Training loss: 0.6974092059063189
Epoch: 13 | Iteration number: [340/393] 86% | Training loss: 0.6973240689319723
Epoch: 13 | Iteration number: [350/393] 89% | Training loss: 0.697261792251042
Epoch: 13 | Iteration number: [360/393] 91% | Training loss: 0.6971701598829694
Epoch: 13 | Iteration number: [370/393] 94% | Training loss: 0.6971219539642334
Epoch: 13 | Iteration number: [380/393] 96% | Training loss: 0.6970606156085667
Epoch: 13 | Iteration number: [390/393] 99% | Training loss: 0.6970094407216096

 End of epoch: 13 | Train Loss: 0.6952209678921687 | Training Time: 64 

 End of epoch: 13 | Eval Loss: 0.6945421671380803 | Evaluating Time: 16 
Epoch: 14 | Iteration number: [10/393] 2% | Training loss: 0.7636630654335022
Epoch: 14 | Iteration number: [20/393] 5% | Training loss: 0.7294183522462845
Epoch: 14 | Iteration number: [30/393] 7% | Training loss: 0.7180620431900024
Epoch: 14 | Iteration number: [40/393] 10% | Training loss: 0.7123457700014114
Epoch: 14 | Iteration number: [50/393] 12% | Training loss: 0.7089870226383209
Epoch: 14 | Iteration number: [60/393] 15% | Training loss: 0.7065024316310883
Epoch: 14 | Iteration number: [70/393] 17% | Training loss: 0.7050392201968602
Epoch: 14 | Iteration number: [80/393] 20% | Training loss: 0.7038148403167724
Epoch: 14 | Iteration number: [90/393] 22% | Training loss: 0.7028011745876737
Epoch: 14 | Iteration number: [100/393] 25% | Training loss: 0.7020291179418564
Epoch: 14 | Iteration number: [110/393] 27% | Training loss: 0.701422209631313
Epoch: 14 | Iteration number: [120/393] 30% | Training loss: 0.7008810892701149
Epoch: 14 | Iteration number: [130/393] 33% | Training loss: 0.7004185603215144
Epoch: 14 | Iteration number: [140/393] 35% | Training loss: 0.6999512029545648
Epoch: 14 | Iteration number: [150/393] 38% | Training loss: 0.6996220576763154
Epoch: 14 | Iteration number: [160/393] 40% | Training loss: 0.6992726970463992
Epoch: 14 | Iteration number: [170/393] 43% | Training loss: 0.6989930836593403
Epoch: 14 | Iteration number: [180/393] 45% | Training loss: 0.6988066262669034
Epoch: 14 | Iteration number: [190/393] 48% | Training loss: 0.6986098935729579
Epoch: 14 | Iteration number: [200/393] 50% | Training loss: 0.698353867828846
Epoch: 14 | Iteration number: [210/393] 53% | Training loss: 0.6981504902953193
Epoch: 14 | Iteration number: [220/393] 55% | Training loss: 0.6979143652048978
Epoch: 14 | Iteration number: [230/393] 58% | Training loss: 0.6977679431438446
Epoch: 14 | Iteration number: [240/393] 61% | Training loss: 0.6976063912113507
Epoch: 14 | Iteration number: [250/393] 63% | Training loss: 0.6974657566547394
Epoch: 14 | Iteration number: [260/393] 66% | Training loss: 0.697343714420612
Epoch: 14 | Iteration number: [270/393] 68% | Training loss: 0.6971975229404591
Epoch: 14 | Iteration number: [280/393] 71% | Training loss: 0.6970786056348256
Epoch: 14 | Iteration number: [290/393] 73% | Training loss: 0.6969126732184969
Epoch: 14 | Iteration number: [300/393] 76% | Training loss: 0.6968187459309896
Epoch: 14 | Iteration number: [310/393] 78% | Training loss: 0.696703722592323
Epoch: 14 | Iteration number: [320/393] 81% | Training loss: 0.6966131107881666
Epoch: 14 | Iteration number: [330/393] 83% | Training loss: 0.6965472528428742
Epoch: 14 | Iteration number: [340/393] 86% | Training loss: 0.6964894757551305
Epoch: 14 | Iteration number: [350/393] 89% | Training loss: 0.6964086764199393
Epoch: 14 | Iteration number: [360/393] 91% | Training loss: 0.6963412331210243
Epoch: 14 | Iteration number: [370/393] 94% | Training loss: 0.69628363026155
Epoch: 14 | Iteration number: [380/393] 96% | Training loss: 0.6962202563097603
Epoch: 14 | Iteration number: [390/393] 99% | Training loss: 0.6961717955577068

 End of epoch: 14 | Train Loss: 0.6943925039762152 | Training Time: 65 

 End of epoch: 14 | Eval Loss: 0.6939923982230984 | Evaluating Time: 16 
Epoch: 15 | Iteration number: [10/393] 2% | Training loss: 0.7636915802955627
Epoch: 15 | Iteration number: [20/393] 5% | Training loss: 0.7290446609258652
Epoch: 15 | Iteration number: [30/393] 7% | Training loss: 0.7172838389873505
Epoch: 15 | Iteration number: [40/393] 10% | Training loss: 0.7113337978720665
Epoch: 15 | Iteration number: [50/393] 12% | Training loss: 0.707909927368164
Epoch: 15 | Iteration number: [60/393] 15% | Training loss: 0.705518169204394
Epoch: 15 | Iteration number: [70/393] 17% | Training loss: 0.7037376872130803
Epoch: 15 | Iteration number: [80/393] 20% | Training loss: 0.7024712853133679
Epoch: 15 | Iteration number: [90/393] 22% | Training loss: 0.7014606965912713
Epoch: 15 | Iteration number: [100/393] 25% | Training loss: 0.7006893181800842
Epoch: 15 | Iteration number: [110/393] 27% | Training loss: 0.700012061812661
Epoch: 15 | Iteration number: [120/393] 30% | Training loss: 0.6994283199310303
Epoch: 15 | Iteration number: [130/393] 33% | Training loss: 0.6989303419223198
Epoch: 15 | Iteration number: [140/393] 35% | Training loss: 0.6985706286770957
Epoch: 15 | Iteration number: [150/393] 38% | Training loss: 0.6982387626171112
Epoch: 15 | Iteration number: [160/393] 40% | Training loss: 0.6979538761079311
Epoch: 15 | Iteration number: [170/393] 43% | Training loss: 0.6976730287075043
Epoch: 15 | Iteration number: [180/393] 45% | Training loss: 0.6974948402908113
Epoch: 15 | Iteration number: [190/393] 48% | Training loss: 0.6973319819099024
Epoch: 15 | Iteration number: [200/393] 50% | Training loss: 0.6971303579211235
Epoch: 15 | Iteration number: [210/393] 53% | Training loss: 0.6969577301116217
Epoch: 15 | Iteration number: [220/393] 55% | Training loss: 0.6968348971822045
Epoch: 15 | Iteration number: [230/393] 58% | Training loss: 0.6967360696066981
Epoch: 15 | Iteration number: [240/393] 61% | Training loss: 0.6965996598203977
Epoch: 15 | Iteration number: [250/393] 63% | Training loss: 0.696463128566742
Epoch: 15 | Iteration number: [260/393] 66% | Training loss: 0.6963721101100628
Epoch: 15 | Iteration number: [270/393] 68% | Training loss: 0.69624961482154
Epoch: 15 | Iteration number: [280/393] 71% | Training loss: 0.696134168122496
Epoch: 15 | Iteration number: [290/393] 73% | Training loss: 0.6960500112895308
Epoch: 15 | Iteration number: [300/393] 76% | Training loss: 0.6959535278876623
Epoch: 15 | Iteration number: [310/393] 78% | Training loss: 0.6958782171049426
Epoch: 15 | Iteration number: [320/393] 81% | Training loss: 0.6958022620528936
Epoch: 15 | Iteration number: [330/393] 83% | Training loss: 0.6957485953966777
Epoch: 15 | Iteration number: [340/393] 86% | Training loss: 0.6956960462472018
Epoch: 15 | Iteration number: [350/393] 89% | Training loss: 0.6956394597462245
Epoch: 15 | Iteration number: [360/393] 91% | Training loss: 0.6955654606223106
Epoch: 15 | Iteration number: [370/393] 94% | Training loss: 0.6955251431142961
Epoch: 15 | Iteration number: [380/393] 96% | Training loss: 0.6954390977558337
Epoch: 15 | Iteration number: [390/393] 99% | Training loss: 0.6953873817737286

 End of epoch: 15 | Train Loss: 0.6936023575052354 | Training Time: 64 

 End of epoch: 15 | Eval Loss: 0.6933686818395343 | Evaluating Time: 16 
Epoch: 16 | Iteration number: [10/393] 2% | Training loss: 0.7623864471912384
Epoch: 16 | Iteration number: [20/393] 5% | Training loss: 0.7274209976196289
Epoch: 16 | Iteration number: [30/393] 7% | Training loss: 0.7159777581691742
Epoch: 16 | Iteration number: [40/393] 10% | Training loss: 0.7102170154452324
Epoch: 16 | Iteration number: [50/393] 12% | Training loss: 0.7068443357944488
Epoch: 16 | Iteration number: [60/393] 15% | Training loss: 0.7046559611956279
Epoch: 16 | Iteration number: [70/393] 17% | Training loss: 0.7030353478022984
Epoch: 16 | Iteration number: [80/393] 20% | Training loss: 0.7018499955534935
Epoch: 16 | Iteration number: [90/393] 22% | Training loss: 0.7008289555708568
Epoch: 16 | Iteration number: [100/393] 25% | Training loss: 0.7000568455457687
Epoch: 16 | Iteration number: [110/393] 27% | Training loss: 0.6994516280564395
Epoch: 16 | Iteration number: [120/393] 30% | Training loss: 0.6989510908722878
Epoch: 16 | Iteration number: [130/393] 33% | Training loss: 0.6985586129702055
Epoch: 16 | Iteration number: [140/393] 35% | Training loss: 0.698274410196713
Epoch: 16 | Iteration number: [150/393] 38% | Training loss: 0.6980424797534943
Epoch: 16 | Iteration number: [160/393] 40% | Training loss: 0.6976745955646038
Epoch: 16 | Iteration number: [170/393] 43% | Training loss: 0.6974234826424542
Epoch: 16 | Iteration number: [180/393] 45% | Training loss: 0.6971343245771197
Epoch: 16 | Iteration number: [190/393] 48% | Training loss: 0.6969033191078587
Epoch: 16 | Iteration number: [200/393] 50% | Training loss: 0.6967385217547417
Epoch: 16 | Iteration number: [210/393] 53% | Training loss: 0.6965479342710404
Epoch: 16 | Iteration number: [220/393] 55% | Training loss: 0.6963912774216044
Epoch: 16 | Iteration number: [230/393] 58% | Training loss: 0.6962387434814288
Epoch: 16 | Iteration number: [240/393] 61% | Training loss: 0.696116212507089
Epoch: 16 | Iteration number: [250/393] 63% | Training loss: 0.696003591299057
Epoch: 16 | Iteration number: [260/393] 66% | Training loss: 0.6959203529816408
Epoch: 16 | Iteration number: [270/393] 68% | Training loss: 0.6958305630418989
Epoch: 16 | Iteration number: [280/393] 71% | Training loss: 0.6956931567617826
Epoch: 16 | Iteration number: [290/393] 73% | Training loss: 0.695617851923252
Epoch: 16 | Iteration number: [300/393] 76% | Training loss: 0.6955182719230651
Epoch: 16 | Iteration number: [310/393] 78% | Training loss: 0.6954117246212498
Epoch: 16 | Iteration number: [320/393] 81% | Training loss: 0.695328914374113
Epoch: 16 | Iteration number: [330/393] 83% | Training loss: 0.6952595138188564
Epoch: 16 | Iteration number: [340/393] 86% | Training loss: 0.6952014791614869
Epoch: 16 | Iteration number: [350/393] 89% | Training loss: 0.6951559126377106
Epoch: 16 | Iteration number: [360/393] 91% | Training loss: 0.6951169204380777
Epoch: 16 | Iteration number: [370/393] 94% | Training loss: 0.6950773935060244
Epoch: 16 | Iteration number: [380/393] 96% | Training loss: 0.6950213888758108
Epoch: 16 | Iteration number: [390/393] 99% | Training loss: 0.6949477368440383

 End of epoch: 16 | Train Loss: 0.6931756971446612 | Training Time: 64 

 End of epoch: 16 | Eval Loss: 0.6930749586650303 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/393] 2% | Training loss: 0.7612809062004089
Epoch: 17 | Iteration number: [20/393] 5% | Training loss: 0.7271478921175003
Epoch: 17 | Iteration number: [30/393] 7% | Training loss: 0.7158324321111044
Epoch: 17 | Iteration number: [40/393] 10% | Training loss: 0.7100235030055047
Epoch: 17 | Iteration number: [50/393] 12% | Training loss: 0.7066490340232849
Epoch: 17 | Iteration number: [60/393] 15% | Training loss: 0.7044210970401764
Epoch: 17 | Iteration number: [70/393] 17% | Training loss: 0.7028899610042572
Epoch: 17 | Iteration number: [80/393] 20% | Training loss: 0.7015614844858646
Epoch: 17 | Iteration number: [90/393] 22% | Training loss: 0.7007363074355655
Epoch: 17 | Iteration number: [100/393] 25% | Training loss: 0.6999659085273743
Epoch: 17 | Iteration number: [110/393] 27% | Training loss: 0.6993184864521027
Epoch: 17 | Iteration number: [120/393] 30% | Training loss: 0.6987537319461504
Epoch: 17 | Iteration number: [130/393] 33% | Training loss: 0.698245178277676
Epoch: 17 | Iteration number: [140/393] 35% | Training loss: 0.6979238769837788
Epoch: 17 | Iteration number: [150/393] 38% | Training loss: 0.6975856304168702
Epoch: 17 | Iteration number: [160/393] 40% | Training loss: 0.6973219156265259
Epoch: 17 | Iteration number: [170/393] 43% | Training loss: 0.6969996788922478
Epoch: 17 | Iteration number: [180/393] 45% | Training loss: 0.6967398203081555
Epoch: 17 | Iteration number: [190/393] 48% | Training loss: 0.6965860605239869
Epoch: 17 | Iteration number: [200/393] 50% | Training loss: 0.6964628183841706
Epoch: 17 | Iteration number: [210/393] 53% | Training loss: 0.6962688545385997
Epoch: 17 | Iteration number: [220/393] 55% | Training loss: 0.6961075858636336
Epoch: 17 | Iteration number: [230/393] 58% | Training loss: 0.6959401547908783
Epoch: 17 | Iteration number: [240/393] 61% | Training loss: 0.6957885302603245
Epoch: 17 | Iteration number: [250/393] 63% | Training loss: 0.6956769769191742
Epoch: 17 | Iteration number: [260/393] 66% | Training loss: 0.695527117068951
Epoch: 17 | Iteration number: [270/393] 68% | Training loss: 0.6954267484170419
Epoch: 17 | Iteration number: [280/393] 71% | Training loss: 0.6953160613775253
Epoch: 17 | Iteration number: [290/393] 73% | Training loss: 0.6951888846940008
Epoch: 17 | Iteration number: [300/393] 76% | Training loss: 0.6950560905536016
Epoch: 17 | Iteration number: [310/393] 78% | Training loss: 0.6949867252380617
Epoch: 17 | Iteration number: [320/393] 81% | Training loss: 0.6949052024632693
Epoch: 17 | Iteration number: [330/393] 83% | Training loss: 0.6948272316744833
Epoch: 17 | Iteration number: [340/393] 86% | Training loss: 0.6947696570087881
Epoch: 17 | Iteration number: [350/393] 89% | Training loss: 0.6947179891381945
Epoch: 17 | Iteration number: [360/393] 91% | Training loss: 0.6946268578370413
Epoch: 17 | Iteration number: [370/393] 94% | Training loss: 0.6945790846605558
Epoch: 17 | Iteration number: [380/393] 96% | Training loss: 0.6945238449071583
Epoch: 17 | Iteration number: [390/393] 99% | Training loss: 0.6944918426183554

 End of epoch: 17 | Train Loss: 0.6927107156991352 | Training Time: 65 

 End of epoch: 17 | Eval Loss: 0.692339301109314 | Evaluating Time: 16 
Epoch: 18 | Iteration number: [10/393] 2% | Training loss: 0.762110298871994
Epoch: 18 | Iteration number: [20/393] 5% | Training loss: 0.726640260219574
Epoch: 18 | Iteration number: [30/393] 7% | Training loss: 0.7153004089991252
Epoch: 18 | Iteration number: [40/393] 10% | Training loss: 0.709604024887085
Epoch: 18 | Iteration number: [50/393] 12% | Training loss: 0.706098610162735
Epoch: 18 | Iteration number: [60/393] 15% | Training loss: 0.7039690862099329
Epoch: 18 | Iteration number: [70/393] 17% | Training loss: 0.702428559746061
Epoch: 18 | Iteration number: [80/393] 20% | Training loss: 0.7011961579322815
Epoch: 18 | Iteration number: [90/393] 22% | Training loss: 0.7002841850121816
Epoch: 18 | Iteration number: [100/393] 25% | Training loss: 0.6995516973733902
Epoch: 18 | Iteration number: [110/393] 27% | Training loss: 0.6989565936001865
Epoch: 18 | Iteration number: [120/393] 30% | Training loss: 0.6984176049629848
Epoch: 18 | Iteration number: [130/393] 33% | Training loss: 0.6980090806117425
Epoch: 18 | Iteration number: [140/393] 35% | Training loss: 0.6975676523787635
Epoch: 18 | Iteration number: [150/393] 38% | Training loss: 0.6972113088766734
Epoch: 18 | Iteration number: [160/393] 40% | Training loss: 0.6968458786606788
Epoch: 18 | Iteration number: [170/393] 43% | Training loss: 0.6965773947098676
Epoch: 18 | Iteration number: [180/393] 45% | Training loss: 0.6963658339447445
Epoch: 18 | Iteration number: [190/393] 48% | Training loss: 0.6961784968250676
Epoch: 18 | Iteration number: [200/393] 50% | Training loss: 0.6959252753853797
Epoch: 18 | Iteration number: [210/393] 53% | Training loss: 0.6957409469854264
Epoch: 18 | Iteration number: [220/393] 55% | Training loss: 0.6955605639652772
Epoch: 18 | Iteration number: [230/393] 58% | Training loss: 0.6954322164473327
Epoch: 18 | Iteration number: [240/393] 61% | Training loss: 0.6953108042478562
Epoch: 18 | Iteration number: [250/393] 63% | Training loss: 0.6951741921901703
Epoch: 18 | Iteration number: [260/393] 66% | Training loss: 0.6950890442499748
Epoch: 18 | Iteration number: [270/393] 68% | Training loss: 0.6949893757149025
Epoch: 18 | Iteration number: [280/393] 71% | Training loss: 0.6949093933616366
Epoch: 18 | Iteration number: [290/393] 73% | Training loss: 0.6948388042121098
Epoch: 18 | Iteration number: [300/393] 76% | Training loss: 0.6947890742619832
Epoch: 18 | Iteration number: [310/393] 78% | Training loss: 0.6946964088947543
Epoch: 18 | Iteration number: [320/393] 81% | Training loss: 0.6946071336045861
Epoch: 18 | Iteration number: [330/393] 83% | Training loss: 0.6945395209572532
Epoch: 18 | Iteration number: [340/393] 86% | Training loss: 0.6944722554262946
Epoch: 18 | Iteration number: [350/393] 89% | Training loss: 0.6944057127407619
Epoch: 18 | Iteration number: [360/393] 91% | Training loss: 0.6943180013034079
Epoch: 18 | Iteration number: [370/393] 94% | Training loss: 0.6942585737318606
Epoch: 18 | Iteration number: [380/393] 96% | Training loss: 0.6942166538614976
Epoch: 18 | Iteration number: [390/393] 99% | Training loss: 0.6941625550771371

 End of epoch: 18 | Train Loss: 0.6923779699638599 | Training Time: 64 

 End of epoch: 18 | Eval Loss: 0.6921996632400824 | Evaluating Time: 29 
Epoch: 19 | Iteration number: [10/393] 2% | Training loss: 0.762575763463974
Epoch: 19 | Iteration number: [20/393] 5% | Training loss: 0.7273823946714402
Epoch: 19 | Iteration number: [30/393] 7% | Training loss: 0.715585446357727
Epoch: 19 | Iteration number: [40/393] 10% | Training loss: 0.709541243314743
Epoch: 19 | Iteration number: [50/393] 12% | Training loss: 0.7059193301200867
Epoch: 19 | Iteration number: [60/393] 15% | Training loss: 0.7036555866400401
Epoch: 19 | Iteration number: [70/393] 17% | Training loss: 0.7020271846226284
Epoch: 19 | Iteration number: [80/393] 20% | Training loss: 0.7008517645299435
Epoch: 19 | Iteration number: [90/393] 22% | Training loss: 0.6999421232276493
Epoch: 19 | Iteration number: [100/393] 25% | Training loss: 0.699076092839241
Epoch: 19 | Iteration number: [110/393] 27% | Training loss: 0.6984906592152336
Epoch: 19 | Iteration number: [120/393] 30% | Training loss: 0.6979366362094879
Epoch: 19 | Iteration number: [130/393] 33% | Training loss: 0.6975315855099604
Epoch: 19 | Iteration number: [140/393] 35% | Training loss: 0.6970827008996691
Epoch: 19 | Iteration number: [150/393] 38% | Training loss: 0.6967522136370341
Epoch: 19 | Iteration number: [160/393] 40% | Training loss: 0.6965122159570456
Epoch: 19 | Iteration number: [170/393] 43% | Training loss: 0.6962645397466771
Epoch: 19 | Iteration number: [180/393] 45% | Training loss: 0.6960219830274582
Epoch: 19 | Iteration number: [190/393] 48% | Training loss: 0.6958838020500384
Epoch: 19 | Iteration number: [200/393] 50% | Training loss: 0.6956756463646889
Epoch: 19 | Iteration number: [210/393] 53% | Training loss: 0.6955302011399042
Epoch: 19 | Iteration number: [220/393] 55% | Training loss: 0.695356261730194
Epoch: 19 | Iteration number: [230/393] 58% | Training loss: 0.6951983630657196
Epoch: 19 | Iteration number: [240/393] 61% | Training loss: 0.6950554514924685
Epoch: 19 | Iteration number: [250/393] 63% | Training loss: 0.6949082126617432
Epoch: 19 | Iteration number: [260/393] 66% | Training loss: 0.6947907064969723
Epoch: 19 | Iteration number: [270/393] 68% | Training loss: 0.694644589556588
Epoch: 19 | Iteration number: [280/393] 71% | Training loss: 0.6945616047297205
Epoch: 19 | Iteration number: [290/393] 73% | Training loss: 0.6944689504031477
Epoch: 19 | Iteration number: [300/393] 76% | Training loss: 0.6943890551726023
Epoch: 19 | Iteration number: [310/393] 78% | Training loss: 0.6942964826860736
Epoch: 19 | Iteration number: [320/393] 81% | Training loss: 0.6942280750721693
Epoch: 19 | Iteration number: [330/393] 83% | Training loss: 0.6941747161475095
Epoch: 19 | Iteration number: [340/393] 86% | Training loss: 0.6940836806507672
Epoch: 19 | Iteration number: [350/393] 89% | Training loss: 0.6939931237697601
Epoch: 19 | Iteration number: [360/393] 91% | Training loss: 0.6939653343624539
Epoch: 19 | Iteration number: [370/393] 94% | Training loss: 0.6939124349001292
Epoch: 19 | Iteration number: [380/393] 96% | Training loss: 0.6938839537532706
Epoch: 19 | Iteration number: [390/393] 99% | Training loss: 0.6938425056445293

 End of epoch: 19 | Train Loss: 0.6920623554831546 | Training Time: 65 

 End of epoch: 19 | Eval Loss: 0.6919885934615622 | Evaluating Time: 17 
Epoch: 20 | Iteration number: [10/393] 2% | Training loss: 0.7609223246574401
Epoch: 20 | Iteration number: [20/393] 5% | Training loss: 0.7261725783348083
Epoch: 20 | Iteration number: [30/393] 7% | Training loss: 0.7150250554084778
Epoch: 20 | Iteration number: [40/393] 10% | Training loss: 0.7090551361441613
Epoch: 20 | Iteration number: [50/393] 12% | Training loss: 0.7057283198833466
Epoch: 20 | Iteration number: [60/393] 15% | Training loss: 0.703502768278122
Epoch: 20 | Iteration number: [70/393] 17% | Training loss: 0.7020305599485125
Epoch: 20 | Iteration number: [80/393] 20% | Training loss: 0.7008606798946857
Epoch: 20 | Iteration number: [90/393] 22% | Training loss: 0.6998495519161224
Epoch: 20 | Iteration number: [100/393] 25% | Training loss: 0.6990561479330063
Epoch: 20 | Iteration number: [110/393] 27% | Training loss: 0.6984186540950429
Epoch: 20 | Iteration number: [120/393] 30% | Training loss: 0.697911691168944
Epoch: 20 | Iteration number: [130/393] 33% | Training loss: 0.6974167273594782
Epoch: 20 | Iteration number: [140/393] 35% | Training loss: 0.6970712155103683
Epoch: 20 | Iteration number: [150/393] 38% | Training loss: 0.6967220942179362
Epoch: 20 | Iteration number: [160/393] 40% | Training loss: 0.6963918205350638
Epoch: 20 | Iteration number: [170/393] 43% | Training loss: 0.696165812366149
Epoch: 20 | Iteration number: [180/393] 45% | Training loss: 0.6959301991595163
Epoch: 20 | Iteration number: [190/393] 48% | Training loss: 0.6956858757295107
Epoch: 20 | Iteration number: [200/393] 50% | Training loss: 0.6954613500833511
Epoch: 20 | Iteration number: [210/393] 53% | Training loss: 0.6952584831487565
Epoch: 20 | Iteration number: [220/393] 55% | Training loss: 0.6951314470984719
Epoch: 20 | Iteration number: [230/393] 58% | Training loss: 0.6949422709319902
Epoch: 20 | Iteration number: [240/393] 61% | Training loss: 0.6947869002819062
Epoch: 20 | Iteration number: [250/393] 63% | Training loss: 0.6946621823310852
Epoch: 20 | Iteration number: [260/393] 66% | Training loss: 0.6945543536773094
Epoch: 20 | Iteration number: [270/393] 68% | Training loss: 0.6944397524551109
Epoch: 20 | Iteration number: [280/393] 71% | Training loss: 0.6943590936916215
Epoch: 20 | Iteration number: [290/393] 73% | Training loss: 0.6942917238021719
Epoch: 20 | Iteration number: [300/393] 76% | Training loss: 0.6941959303617478
Epoch: 20 | Iteration number: [310/393] 78% | Training loss: 0.6941292320528338
Epoch: 20 | Iteration number: [320/393] 81% | Training loss: 0.6940383836627007
Epoch: 20 | Iteration number: [330/393] 83% | Training loss: 0.6939659275791862
Epoch: 20 | Iteration number: [340/393] 86% | Training loss: 0.6938945167204913
Epoch: 20 | Iteration number: [350/393] 89% | Training loss: 0.6938183901991163
Epoch: 20 | Iteration number: [360/393] 91% | Training loss: 0.6937404430574841
Epoch: 20 | Iteration number: [370/393] 94% | Training loss: 0.6936555467747353
Epoch: 20 | Iteration number: [380/393] 96% | Training loss: 0.6935845753079967
Epoch: 20 | Iteration number: [390/393] 99% | Training loss: 0.6935483872890472

 End of epoch: 20 | Train Loss: 0.6917843330300795 | Training Time: 65 

 End of epoch: 20 | Eval Loss: 0.6916795786546202 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/393] 2% | Training loss: 0.7606873512268066
Epoch: 21 | Iteration number: [20/393] 5% | Training loss: 0.7259007185697556
Epoch: 21 | Iteration number: [30/393] 7% | Training loss: 0.7147356947263082
Epoch: 21 | Iteration number: [40/393] 10% | Training loss: 0.708929018676281
Epoch: 21 | Iteration number: [50/393] 12% | Training loss: 0.7054575610160828
Epoch: 21 | Iteration number: [60/393] 15% | Training loss: 0.7034218619267146
Epoch: 21 | Iteration number: [70/393] 17% | Training loss: 0.7020554619176047
Epoch: 21 | Iteration number: [80/393] 20% | Training loss: 0.7010341227054596
Epoch: 21 | Iteration number: [90/393] 22% | Training loss: 0.7002350787321726
Epoch: 21 | Iteration number: [100/393] 25% | Training loss: 0.6995958548784256
Epoch: 21 | Iteration number: [110/393] 27% | Training loss: 0.6990651347420432
Epoch: 21 | Iteration number: [120/393] 30% | Training loss: 0.6986159851153692
Epoch: 21 | Iteration number: [130/393] 33% | Training loss: 0.6982457426878123
Epoch: 21 | Iteration number: [140/393] 35% | Training loss: 0.6979069190365927
Epoch: 21 | Iteration number: [150/393] 38% | Training loss: 0.6975863969326019
Epoch: 21 | Iteration number: [160/393] 40% | Training loss: 0.6971850175410509
Epoch: 21 | Iteration number: [170/393] 43% | Training loss: 0.6968651396386764
Epoch: 21 | Iteration number: [180/393] 45% | Training loss: 0.696658726533254
Epoch: 21 | Iteration number: [190/393] 48% | Training loss: 0.6964183129762348
Epoch: 21 | Iteration number: [200/393] 50% | Training loss: 0.6962164604663849
Epoch: 21 | Iteration number: [210/393] 53% | Training loss: 0.696002539566585
Epoch: 21 | Iteration number: [220/393] 55% | Training loss: 0.6957957508889112
Epoch: 21 | Iteration number: [230/393] 58% | Training loss: 0.6956179328586745
Epoch: 21 | Iteration number: [240/393] 61% | Training loss: 0.6954312148193519
Epoch: 21 | Iteration number: [250/393] 63% | Training loss: 0.6952732574939727
Epoch: 21 | Iteration number: [260/393] 66% | Training loss: 0.6951107708307412
Epoch: 21 | Iteration number: [270/393] 68% | Training loss: 0.6950089891751607
Epoch: 21 | Iteration number: [280/393] 71% | Training loss: 0.6948938657130513
Epoch: 21 | Iteration number: [290/393] 73% | Training loss: 0.6947926704225869
Epoch: 21 | Iteration number: [300/393] 76% | Training loss: 0.694720565478007
Epoch: 21 | Iteration number: [310/393] 78% | Training loss: 0.694600325246011
Epoch: 21 | Iteration number: [320/393] 81% | Training loss: 0.6945205284282565
Epoch: 21 | Iteration number: [330/393] 83% | Training loss: 0.6944397276098078
Epoch: 21 | Iteration number: [340/393] 86% | Training loss: 0.6943614524953505
Epoch: 21 | Iteration number: [350/393] 89% | Training loss: 0.6942896565369198
Epoch: 21 | Iteration number: [360/393] 91% | Training loss: 0.6941814369625515
Epoch: 21 | Iteration number: [370/393] 94% | Training loss: 0.6941262473931183
Epoch: 21 | Iteration number: [380/393] 96% | Training loss: 0.6940634990993299
Epoch: 21 | Iteration number: [390/393] 99% | Training loss: 0.6940065319721516

 End of epoch: 21 | Train Loss: 0.6922326846280474 | Training Time: 65 

 End of epoch: 21 | Eval Loss: 0.691758564540318 | Evaluating Time: 16 
Epoch: 22 | Iteration number: [10/393] 2% | Training loss: 0.7608531236648559
Epoch: 22 | Iteration number: [20/393] 5% | Training loss: 0.7261429280042648
Epoch: 22 | Iteration number: [30/393] 7% | Training loss: 0.7146795352300008
Epoch: 22 | Iteration number: [40/393] 10% | Training loss: 0.708834308385849
Epoch: 22 | Iteration number: [50/393] 12% | Training loss: 0.705581876039505
Epoch: 22 | Iteration number: [60/393] 15% | Training loss: 0.7032306720813115
Epoch: 22 | Iteration number: [70/393] 17% | Training loss: 0.7015117449419839
Epoch: 22 | Iteration number: [80/393] 20% | Training loss: 0.7003300361335277
Epoch: 22 | Iteration number: [90/393] 22% | Training loss: 0.6994184666209751
Epoch: 22 | Iteration number: [100/393] 25% | Training loss: 0.6987006920576095
Epoch: 22 | Iteration number: [110/393] 27% | Training loss: 0.6980337278409438
Epoch: 22 | Iteration number: [120/393] 30% | Training loss: 0.6975459337234498
Epoch: 22 | Iteration number: [130/393] 33% | Training loss: 0.6970768217857067
Epoch: 22 | Iteration number: [140/393] 35% | Training loss: 0.696694045833179
Epoch: 22 | Iteration number: [150/393] 38% | Training loss: 0.6963603715101878
Epoch: 22 | Iteration number: [160/393] 40% | Training loss: 0.6960998300462962
Epoch: 22 | Iteration number: [170/393] 43% | Training loss: 0.6958423225318684
Epoch: 22 | Iteration number: [180/393] 45% | Training loss: 0.6956669181585312
Epoch: 22 | Iteration number: [190/393] 48% | Training loss: 0.6954133805475737
Epoch: 22 | Iteration number: [200/393] 50% | Training loss: 0.6951986998319626
Epoch: 22 | Iteration number: [210/393] 53% | Training loss: 0.6949926597731454
Epoch: 22 | Iteration number: [220/393] 55% | Training loss: 0.6948795007033781
Epoch: 22 | Iteration number: [230/393] 58% | Training loss: 0.6947359872900921
Epoch: 22 | Iteration number: [240/393] 61% | Training loss: 0.6945667274296283
Epoch: 22 | Iteration number: [250/393] 63% | Training loss: 0.6944089434146881
Epoch: 22 | Iteration number: [260/393] 66% | Training loss: 0.6942795877273266
Epoch: 22 | Iteration number: [270/393] 68% | Training loss: 0.694182323747211
Epoch: 22 | Iteration number: [280/393] 71% | Training loss: 0.6940944054297038
Epoch: 22 | Iteration number: [290/393] 73% | Training loss: 0.6940019817187868
Epoch: 22 | Iteration number: [300/393] 76% | Training loss: 0.6938977007071178
Epoch: 22 | Iteration number: [310/393] 78% | Training loss: 0.6938177220283016
Epoch: 22 | Iteration number: [320/393] 81% | Training loss: 0.6937346830964088
Epoch: 22 | Iteration number: [330/393] 83% | Training loss: 0.6936430616812272
Epoch: 22 | Iteration number: [340/393] 86% | Training loss: 0.6935442126849118
Epoch: 22 | Iteration number: [350/393] 89% | Training loss: 0.6934916041578565
Epoch: 22 | Iteration number: [360/393] 91% | Training loss: 0.6934311555491554
Epoch: 22 | Iteration number: [370/393] 94% | Training loss: 0.6933738371810397
Epoch: 22 | Iteration number: [380/393] 96% | Training loss: 0.6933196933645951
Epoch: 22 | Iteration number: [390/393] 99% | Training loss: 0.693258482676286

 End of epoch: 22 | Train Loss: 0.6914836327538235 | Training Time: 65 

 End of epoch: 22 | Eval Loss: 0.6914597713217443 | Evaluating Time: 16 
Epoch: 23 | Iteration number: [10/393] 2% | Training loss: 0.761099374294281
Epoch: 23 | Iteration number: [20/393] 5% | Training loss: 0.7261016070842743
Epoch: 23 | Iteration number: [30/393] 7% | Training loss: 0.714653883377711
Epoch: 23 | Iteration number: [40/393] 10% | Training loss: 0.7088260442018509
Epoch: 23 | Iteration number: [50/393] 12% | Training loss: 0.7052430081367492
Epoch: 23 | Iteration number: [60/393] 15% | Training loss: 0.7030214389165242
Epoch: 23 | Iteration number: [70/393] 17% | Training loss: 0.7013532204287393
Epoch: 23 | Iteration number: [80/393] 20% | Training loss: 0.7000374168157577
Epoch: 23 | Iteration number: [90/393] 22% | Training loss: 0.699086512459649
Epoch: 23 | Iteration number: [100/393] 25% | Training loss: 0.6983052742481232
Epoch: 23 | Iteration number: [110/393] 27% | Training loss: 0.6976251461289146
Epoch: 23 | Iteration number: [120/393] 30% | Training loss: 0.6971356625358264
Epoch: 23 | Iteration number: [130/393] 33% | Training loss: 0.6966670086750617
Epoch: 23 | Iteration number: [140/393] 35% | Training loss: 0.6963197763477053
Epoch: 23 | Iteration number: [150/393] 38% | Training loss: 0.6960342701276143
Epoch: 23 | Iteration number: [160/393] 40% | Training loss: 0.6957482360303402
Epoch: 23 | Iteration number: [170/393] 43% | Training loss: 0.6954923969857832
Epoch: 23 | Iteration number: [180/393] 45% | Training loss: 0.6953376001781888
Epoch: 23 | Iteration number: [190/393] 48% | Training loss: 0.6951111423341851
Epoch: 23 | Iteration number: [200/393] 50% | Training loss: 0.694880273938179
Epoch: 23 | Iteration number: [210/393] 53% | Training loss: 0.6946779112021129
Epoch: 23 | Iteration number: [220/393] 55% | Training loss: 0.6945592479272322
Epoch: 23 | Iteration number: [230/393] 58% | Training loss: 0.6944347780683766
Epoch: 23 | Iteration number: [240/393] 61% | Training loss: 0.6943505555391312
Epoch: 23 | Iteration number: [250/393] 63% | Training loss: 0.6941861155033111
Epoch: 23 | Iteration number: [260/393] 66% | Training loss: 0.6940925460595351
Epoch: 23 | Iteration number: [270/393] 68% | Training loss: 0.6940241756262603
Epoch: 23 | Iteration number: [280/393] 71% | Training loss: 0.693929687993867
Epoch: 23 | Iteration number: [290/393] 73% | Training loss: 0.6938606451297629
Epoch: 23 | Iteration number: [300/393] 76% | Training loss: 0.6937606336673101
Epoch: 23 | Iteration number: [310/393] 78% | Training loss: 0.6936900309977992
Epoch: 23 | Iteration number: [320/393] 81% | Training loss: 0.6935982588678599
Epoch: 23 | Iteration number: [330/393] 83% | Training loss: 0.6935337483882904
Epoch: 23 | Iteration number: [340/393] 86% | Training loss: 0.6934647763476652
Epoch: 23 | Iteration number: [350/393] 89% | Training loss: 0.6934058773517608
Epoch: 23 | Iteration number: [360/393] 91% | Training loss: 0.6933187584082285
Epoch: 23 | Iteration number: [370/393] 94% | Training loss: 0.693261314566071
Epoch: 23 | Iteration number: [380/393] 96% | Training loss: 0.6932077741936633
Epoch: 23 | Iteration number: [390/393] 99% | Training loss: 0.6931480939571674

 End of epoch: 23 | Train Loss: 0.6913737927684347 | Training Time: 65 

 End of epoch: 23 | Eval Loss: 0.6913257460204922 | Evaluating Time: 16 
Epoch: 24 | Iteration number: [10/393] 2% | Training loss: 0.760921061038971
Epoch: 24 | Iteration number: [20/393] 5% | Training loss: 0.7262619882822037
Epoch: 24 | Iteration number: [30/393] 7% | Training loss: 0.7143625994523366
Epoch: 24 | Iteration number: [40/393] 10% | Training loss: 0.7085942879319191
Epoch: 24 | Iteration number: [50/393] 12% | Training loss: 0.7052343142032623
Epoch: 24 | Iteration number: [60/393] 15% | Training loss: 0.7028776238361994
Epoch: 24 | Iteration number: [70/393] 17% | Training loss: 0.701158515044621
Epoch: 24 | Iteration number: [80/393] 20% | Training loss: 0.6999175474047661
Epoch: 24 | Iteration number: [90/393] 22% | Training loss: 0.6988622923692067
Epoch: 24 | Iteration number: [100/393] 25% | Training loss: 0.698042049407959
Epoch: 24 | Iteration number: [110/393] 27% | Training loss: 0.6974913759665056
Epoch: 24 | Iteration number: [120/393] 30% | Training loss: 0.6969541639089585
Epoch: 24 | Iteration number: [130/393] 33% | Training loss: 0.6965322613716125
Epoch: 24 | Iteration number: [140/393] 35% | Training loss: 0.6961446076631546
Epoch: 24 | Iteration number: [150/393] 38% | Training loss: 0.6958425235748291
Epoch: 24 | Iteration number: [160/393] 40% | Training loss: 0.6955688796937466
Epoch: 24 | Iteration number: [170/393] 43% | Training loss: 0.6953231397797079
Epoch: 24 | Iteration number: [180/393] 45% | Training loss: 0.6951044172048568
Epoch: 24 | Iteration number: [190/393] 48% | Training loss: 0.6949203478662591
Epoch: 24 | Iteration number: [200/393] 50% | Training loss: 0.6946914187073707
Epoch: 24 | Iteration number: [210/393] 53% | Training loss: 0.6944683029538109
Epoch: 24 | Iteration number: [220/393] 55% | Training loss: 0.6943042998964136
Epoch: 24 | Iteration number: [230/393] 58% | Training loss: 0.6941915465437848
Epoch: 24 | Iteration number: [240/393] 61% | Training loss: 0.6940924229721228
Epoch: 24 | Iteration number: [250/393] 63% | Training loss: 0.6940028247833252
Epoch: 24 | Iteration number: [260/393] 66% | Training loss: 0.6939192762741676
Epoch: 24 | Iteration number: [270/393] 68% | Training loss: 0.693838009348622
Epoch: 24 | Iteration number: [280/393] 71% | Training loss: 0.6937673798629216
Epoch: 24 | Iteration number: [290/393] 73% | Training loss: 0.693679817997176
Epoch: 24 | Iteration number: [300/393] 76% | Training loss: 0.6936000663042069
Epoch: 24 | Iteration number: [310/393] 78% | Training loss: 0.6934940328521113
Epoch: 24 | Iteration number: [320/393] 81% | Training loss: 0.6934070022776723
Epoch: 24 | Iteration number: [330/393] 83% | Training loss: 0.6933428236932465
Epoch: 24 | Iteration number: [340/393] 86% | Training loss: 0.6932947348145878
Epoch: 24 | Iteration number: [350/393] 89% | Training loss: 0.6932278851100376
Epoch: 24 | Iteration number: [360/393] 91% | Training loss: 0.693173832529121
Epoch: 24 | Iteration number: [370/393] 94% | Training loss: 0.6931278420461191
Epoch: 24 | Iteration number: [380/393] 96% | Training loss: 0.6930994596920516
Epoch: 24 | Iteration number: [390/393] 99% | Training loss: 0.6930124047474984

 End of epoch: 24 | Train Loss: 0.6912499773896681 | Training Time: 64 

 End of epoch: 24 | Eval Loss: 0.6912570182158022 | Evaluating Time: 16 
Epoch: 25 | Iteration number: [10/393] 2% | Training loss: 0.7603232383728027
Epoch: 25 | Iteration number: [20/393] 5% | Training loss: 0.7260031908750534
Epoch: 25 | Iteration number: [30/393] 7% | Training loss: 0.7143086751302083
Epoch: 25 | Iteration number: [40/393] 10% | Training loss: 0.7086327344179153
Epoch: 25 | Iteration number: [50/393] 12% | Training loss: 0.7050733530521393
Epoch: 25 | Iteration number: [60/393] 15% | Training loss: 0.7027103900909424
Epoch: 25 | Iteration number: [70/393] 17% | Training loss: 0.7010320118495397
Epoch: 25 | Iteration number: [80/393] 20% | Training loss: 0.6998060874640941
Epoch: 25 | Iteration number: [90/393] 22% | Training loss: 0.6987843334674835
Epoch: 25 | Iteration number: [100/393] 25% | Training loss: 0.6978971064090729
Epoch: 25 | Iteration number: [110/393] 27% | Training loss: 0.6972724226388064
Epoch: 25 | Iteration number: [120/393] 30% | Training loss: 0.6968287671605746
Epoch: 25 | Iteration number: [130/393] 33% | Training loss: 0.6963721880545983
Epoch: 25 | Iteration number: [140/393] 35% | Training loss: 0.6958978669984001
Epoch: 25 | Iteration number: [150/393] 38% | Training loss: 0.6955686700344086
Epoch: 25 | Iteration number: [160/393] 40% | Training loss: 0.6952720709145069
Epoch: 25 | Iteration number: [170/393] 43% | Training loss: 0.6950522471876706
Epoch: 25 | Iteration number: [180/393] 45% | Training loss: 0.694827965233061
Epoch: 25 | Iteration number: [190/393] 48% | Training loss: 0.6946452580000225
Epoch: 25 | Iteration number: [200/393] 50% | Training loss: 0.694427357017994
Epoch: 25 | Iteration number: [210/393] 53% | Training loss: 0.6943544484320141
Epoch: 25 | Iteration number: [220/393] 55% | Training loss: 0.6942540588704023
Epoch: 25 | Iteration number: [230/393] 58% | Training loss: 0.6941213156865991
Epoch: 25 | Iteration number: [240/393] 61% | Training loss: 0.6940006246169408
Epoch: 25 | Iteration number: [250/393] 63% | Training loss: 0.6938935060501099
Epoch: 25 | Iteration number: [260/393] 66% | Training loss: 0.693745865042393
Epoch: 25 | Iteration number: [270/393] 68% | Training loss: 0.6936553259690602
Epoch: 25 | Iteration number: [280/393] 71% | Training loss: 0.6935724424464362
Epoch: 25 | Iteration number: [290/393] 73% | Training loss: 0.6935370371259492
Epoch: 25 | Iteration number: [300/393] 76% | Training loss: 0.6934780160586039
Epoch: 25 | Iteration number: [310/393] 78% | Training loss: 0.6934103152444285
Epoch: 25 | Iteration number: [320/393] 81% | Training loss: 0.6933674454689026
Epoch: 25 | Iteration number: [330/393] 83% | Training loss: 0.6932896500284021
Epoch: 25 | Iteration number: [340/393] 86% | Training loss: 0.6932087202282513
Epoch: 25 | Iteration number: [350/393] 89% | Training loss: 0.6931297084263393
Epoch: 25 | Iteration number: [360/393] 91% | Training loss: 0.6930556019147237
Epoch: 25 | Iteration number: [370/393] 94% | Training loss: 0.693022936260378
Epoch: 25 | Iteration number: [380/393] 96% | Training loss: 0.6929592057278282
Epoch: 25 | Iteration number: [390/393] 99% | Training loss: 0.6929246087869009

 End of epoch: 25 | Train Loss: 0.691148790087712 | Training Time: 65 

 End of epoch: 25 | Eval Loss: 0.6911040228240344 | Evaluating Time: 17 
Epoch: 26 | Iteration number: [10/393] 2% | Training loss: 0.759816688299179
Epoch: 26 | Iteration number: [20/393] 5% | Training loss: 0.7254656672477722
Epoch: 26 | Iteration number: [30/393] 7% | Training loss: 0.7139092763264974
Epoch: 26 | Iteration number: [40/393] 10% | Training loss: 0.7081290066242218
Epoch: 26 | Iteration number: [50/393] 12% | Training loss: 0.7045770883560181
Epoch: 26 | Iteration number: [60/393] 15% | Training loss: 0.7022989958524704
Epoch: 26 | Iteration number: [70/393] 17% | Training loss: 0.7007539119039263
Epoch: 26 | Iteration number: [80/393] 20% | Training loss: 0.6995232798159122
Epoch: 26 | Iteration number: [90/393] 22% | Training loss: 0.6986321813530392
Epoch: 26 | Iteration number: [100/393] 25% | Training loss: 0.6978106904029846
Epoch: 26 | Iteration number: [110/393] 27% | Training loss: 0.6971284682100469
Epoch: 26 | Iteration number: [120/393] 30% | Training loss: 0.6967166403929392
Epoch: 26 | Iteration number: [130/393] 33% | Training loss: 0.6962391867087437
Epoch: 26 | Iteration number: [140/393] 35% | Training loss: 0.6959487374339784
Epoch: 26 | Iteration number: [150/393] 38% | Training loss: 0.6956332079569498
Epoch: 26 | Iteration number: [160/393] 40% | Training loss: 0.6953503005206585
Epoch: 26 | Iteration number: [170/393] 43% | Training loss: 0.6950923155335819
Epoch: 26 | Iteration number: [180/393] 45% | Training loss: 0.6948637160989973
Epoch: 26 | Iteration number: [190/393] 48% | Training loss: 0.6947025035556994
Epoch: 26 | Iteration number: [200/393] 50% | Training loss: 0.694471692442894
Epoch: 26 | Iteration number: [210/393] 53% | Training loss: 0.6943323938619523
Epoch: 26 | Iteration number: [220/393] 55% | Training loss: 0.6941288560628891
Epoch: 26 | Iteration number: [230/393] 58% | Training loss: 0.6940149890339893
Epoch: 26 | Iteration number: [240/393] 61% | Training loss: 0.6939186704655488
Epoch: 26 | Iteration number: [250/393] 63% | Training loss: 0.6938085639476776
Epoch: 26 | Iteration number: [260/393] 66% | Training loss: 0.6936719649113141
Epoch: 26 | Iteration number: [270/393] 68% | Training loss: 0.6935802985120703
Epoch: 26 | Iteration number: [280/393] 71% | Training loss: 0.693483087846211
Epoch: 26 | Iteration number: [290/393] 73% | Training loss: 0.693417907172236
Epoch: 26 | Iteration number: [300/393] 76% | Training loss: 0.6933370129267374
Epoch: 26 | Iteration number: [310/393] 78% | Training loss: 0.6932423860796036
Epoch: 26 | Iteration number: [320/393] 81% | Training loss: 0.6932046568021178
Epoch: 26 | Iteration number: [330/393] 83% | Training loss: 0.6931367195013798
Epoch: 26 | Iteration number: [340/393] 86% | Training loss: 0.6930280734510983
Epoch: 26 | Iteration number: [350/393] 89% | Training loss: 0.6930074536800385
Epoch: 26 | Iteration number: [360/393] 91% | Training loss: 0.6929322106970681
Epoch: 26 | Iteration number: [370/393] 94% | Training loss: 0.6928825586228757
Epoch: 26 | Iteration number: [380/393] 96% | Training loss: 0.6928281969145724
Epoch: 26 | Iteration number: [390/393] 99% | Training loss: 0.6928057768406012

 End of epoch: 26 | Train Loss: 0.6910448500521613 | Training Time: 66 

 End of epoch: 26 | Eval Loss: 0.6921041693006244 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/393] 2% | Training loss: 0.7595236003398895
Epoch: 27 | Iteration number: [20/393] 5% | Training loss: 0.7246887296438217
Epoch: 27 | Iteration number: [30/393] 7% | Training loss: 0.713424148162206
Epoch: 27 | Iteration number: [40/393] 10% | Training loss: 0.7078754261136055
Epoch: 27 | Iteration number: [50/393] 12% | Training loss: 0.7046059477329254
Epoch: 27 | Iteration number: [60/393] 15% | Training loss: 0.7023274461428325
Epoch: 27 | Iteration number: [70/393] 17% | Training loss: 0.7006374163287027
Epoch: 27 | Iteration number: [80/393] 20% | Training loss: 0.6994259640574455
Epoch: 27 | Iteration number: [90/393] 22% | Training loss: 0.6985473824871911
Epoch: 27 | Iteration number: [100/393] 25% | Training loss: 0.6978835409879685
Epoch: 27 | Iteration number: [110/393] 27% | Training loss: 0.6972589519890872
Epoch: 27 | Iteration number: [120/393] 30% | Training loss: 0.696641723314921
Epoch: 27 | Iteration number: [130/393] 33% | Training loss: 0.6961649702145503
Epoch: 27 | Iteration number: [140/393] 35% | Training loss: 0.6958096717085157
Epoch: 27 | Iteration number: [150/393] 38% | Training loss: 0.6955008808771769
Epoch: 27 | Iteration number: [160/393] 40% | Training loss: 0.6952489048242569
Epoch: 27 | Iteration number: [170/393] 43% | Training loss: 0.6949643033392289
Epoch: 27 | Iteration number: [180/393] 45% | Training loss: 0.6948149111535814
Epoch: 27 | Iteration number: [190/393] 48% | Training loss: 0.694605889445857
Epoch: 27 | Iteration number: [200/393] 50% | Training loss: 0.6944273233413696
Epoch: 27 | Iteration number: [210/393] 53% | Training loss: 0.6942879651274
Epoch: 27 | Iteration number: [220/393] 55% | Training loss: 0.6941797652027824
Epoch: 27 | Iteration number: [230/393] 58% | Training loss: 0.6940623700618744
Epoch: 27 | Iteration number: [240/393] 61% | Training loss: 0.6939470060169697
Epoch: 27 | Iteration number: [250/393] 63% | Training loss: 0.6938198013305664
Epoch: 27 | Iteration number: [260/393] 66% | Training loss: 0.6937031248441109
Epoch: 27 | Iteration number: [270/393] 68% | Training loss: 0.6936282433845379
Epoch: 27 | Iteration number: [280/393] 71% | Training loss: 0.6935013511351177
Epoch: 27 | Iteration number: [290/393] 73% | Training loss: 0.6934344669868207
Epoch: 27 | Iteration number: [300/393] 76% | Training loss: 0.6933612964550654
Epoch: 27 | Iteration number: [310/393] 78% | Training loss: 0.6932568677010075
Epoch: 27 | Iteration number: [320/393] 81% | Training loss: 0.6932007525116205
Epoch: 27 | Iteration number: [330/393] 83% | Training loss: 0.6931489509163481
Epoch: 27 | Iteration number: [340/393] 86% | Training loss: 0.6931113297448439
Epoch: 27 | Iteration number: [350/393] 89% | Training loss: 0.6930119221551078
Epoch: 27 | Iteration number: [360/393] 91% | Training loss: 0.6929630019598537
Epoch: 27 | Iteration number: [370/393] 94% | Training loss: 0.6929191507197715
Epoch: 27 | Iteration number: [380/393] 96% | Training loss: 0.692867239211735
Epoch: 27 | Iteration number: [390/393] 99% | Training loss: 0.6928028831115136

 End of epoch: 27 | Train Loss: 0.6910322560305511 | Training Time: 67 

 End of epoch: 27 | Eval Loss: 0.690983205425496 | Evaluating Time: 17 
Epoch: 28 | Iteration number: [10/393] 2% | Training loss: 0.7590958297252655
Epoch: 28 | Iteration number: [20/393] 5% | Training loss: 0.7251255303621292
Epoch: 28 | Iteration number: [30/393] 7% | Training loss: 0.7137691497802734
Epoch: 28 | Iteration number: [40/393] 10% | Training loss: 0.7082673266530037
Epoch: 28 | Iteration number: [50/393] 12% | Training loss: 0.7046724915504455
Epoch: 28 | Iteration number: [60/393] 15% | Training loss: 0.7023234069347382
Epoch: 28 | Iteration number: [70/393] 17% | Training loss: 0.7008151122501918
Epoch: 28 | Iteration number: [80/393] 20% | Training loss: 0.6995710261166096
Epoch: 28 | Iteration number: [90/393] 22% | Training loss: 0.698562679025862
Epoch: 28 | Iteration number: [100/393] 25% | Training loss: 0.697847597002983
Epoch: 28 | Iteration number: [110/393] 27% | Training loss: 0.6972408175468445
Epoch: 28 | Iteration number: [120/393] 30% | Training loss: 0.6967132012049357
Epoch: 28 | Iteration number: [130/393] 33% | Training loss: 0.6962674145515149
Epoch: 28 | Iteration number: [140/393] 35% | Training loss: 0.6957651700292314
Epoch: 28 | Iteration number: [150/393] 38% | Training loss: 0.6954583855470021
Epoch: 28 | Iteration number: [160/393] 40% | Training loss: 0.6952532261610032
Epoch: 28 | Iteration number: [170/393] 43% | Training loss: 0.6949988088187049
Epoch: 28 | Iteration number: [180/393] 45% | Training loss: 0.6947634892331229
Epoch: 28 | Iteration number: [190/393] 48% | Training loss: 0.6945718752710442
Epoch: 28 | Iteration number: [200/393] 50% | Training loss: 0.6943862178921699
Epoch: 28 | Iteration number: [210/393] 53% | Training loss: 0.694213581085205
Epoch: 28 | Iteration number: [220/393] 55% | Training loss: 0.6939875448291952
Epoch: 28 | Iteration number: [230/393] 58% | Training loss: 0.6938656016536381
Epoch: 28 | Iteration number: [240/393] 61% | Training loss: 0.6937334023416042
Epoch: 28 | Iteration number: [250/393] 63% | Training loss: 0.6936600124835968
Epoch: 28 | Iteration number: [260/393] 66% | Training loss: 0.6935350062755438
Epoch: 28 | Iteration number: [270/393] 68% | Training loss: 0.6934396712868302
Epoch: 28 | Iteration number: [280/393] 71% | Training loss: 0.6933587161558015
Epoch: 28 | Iteration number: [290/393] 73% | Training loss: 0.6933071520821802
Epoch: 28 | Iteration number: [300/393] 76% | Training loss: 0.6932252802451452
Epoch: 28 | Iteration number: [310/393] 78% | Training loss: 0.6931493641868715
Epoch: 28 | Iteration number: [320/393] 81% | Training loss: 0.6930784745141864
Epoch: 28 | Iteration number: [330/393] 83% | Training loss: 0.6930156124360634
Epoch: 28 | Iteration number: [340/393] 86% | Training loss: 0.6929233465124579
Epoch: 28 | Iteration number: [350/393] 89% | Training loss: 0.6928738638332912
Epoch: 28 | Iteration number: [360/393] 91% | Training loss: 0.6928394890493816
Epoch: 28 | Iteration number: [370/393] 94% | Training loss: 0.6928007802447758
Epoch: 28 | Iteration number: [380/393] 96% | Training loss: 0.6927763614215349
Epoch: 28 | Iteration number: [390/393] 99% | Training loss: 0.6927060578113947

 End of epoch: 28 | Train Loss: 0.6909409013716622 | Training Time: 67 

 End of epoch: 28 | Eval Loss: 0.6910935895783561 | Evaluating Time: 17 
Epoch: 29 | Iteration number: [10/393] 2% | Training loss: 0.7593939960002899
Epoch: 29 | Iteration number: [20/393] 5% | Training loss: 0.7252161651849747
Epoch: 29 | Iteration number: [30/393] 7% | Training loss: 0.7137606859207153
Epoch: 29 | Iteration number: [40/393] 10% | Training loss: 0.7083865687251091
Epoch: 29 | Iteration number: [50/393] 12% | Training loss: 0.704892715215683
Epoch: 29 | Iteration number: [60/393] 15% | Training loss: 0.7025500953197479
Epoch: 29 | Iteration number: [70/393] 17% | Training loss: 0.7006896121161325
Epoch: 29 | Iteration number: [80/393] 20% | Training loss: 0.6995228007435799
Epoch: 29 | Iteration number: [90/393] 22% | Training loss: 0.6985026617844899
Epoch: 29 | Iteration number: [100/393] 25% | Training loss: 0.697824729681015
Epoch: 29 | Iteration number: [110/393] 27% | Training loss: 0.6972511968829415
Epoch: 29 | Iteration number: [120/393] 30% | Training loss: 0.6968318313360214
Epoch: 29 | Iteration number: [130/393] 33% | Training loss: 0.6963251013022203
Epoch: 29 | Iteration number: [140/393] 35% | Training loss: 0.6959699928760529
Epoch: 29 | Iteration number: [150/393] 38% | Training loss: 0.6955622406800588
Epoch: 29 | Iteration number: [160/393] 40% | Training loss: 0.6952598974108696
Epoch: 29 | Iteration number: [170/393] 43% | Training loss: 0.6949535103405223
Epoch: 29 | Iteration number: [180/393] 45% | Training loss: 0.6947110368145837
Epoch: 29 | Iteration number: [190/393] 48% | Training loss: 0.6944792559272365
Epoch: 29 | Iteration number: [200/393] 50% | Training loss: 0.6942154994606972
Epoch: 29 | Iteration number: [210/393] 53% | Training loss: 0.6940331212111882
Epoch: 29 | Iteration number: [220/393] 55% | Training loss: 0.6938603057102724
Epoch: 29 | Iteration number: [230/393] 58% | Training loss: 0.6937326540117679
Epoch: 29 | Iteration number: [240/393] 61% | Training loss: 0.693603162219127
Epoch: 29 | Iteration number: [250/393] 63% | Training loss: 0.6935314946174621
Epoch: 29 | Iteration number: [260/393] 66% | Training loss: 0.6933842897415161
Epoch: 29 | Iteration number: [270/393] 68% | Training loss: 0.693321101533042
Epoch: 29 | Iteration number: [280/393] 71% | Training loss: 0.693242649095399
Epoch: 29 | Iteration number: [290/393] 73% | Training loss: 0.69316975309931
Epoch: 29 | Iteration number: [300/393] 76% | Training loss: 0.6931008420387904
Epoch: 29 | Iteration number: [310/393] 78% | Training loss: 0.6930391021313206
Epoch: 29 | Iteration number: [320/393] 81% | Training loss: 0.6930041672661901
Epoch: 29 | Iteration number: [330/393] 83% | Training loss: 0.6929133440508987
Epoch: 29 | Iteration number: [340/393] 86% | Training loss: 0.6928705075207878
Epoch: 29 | Iteration number: [350/393] 89% | Training loss: 0.692804605449949
Epoch: 29 | Iteration number: [360/393] 91% | Training loss: 0.692769618332386
Epoch: 29 | Iteration number: [370/393] 94% | Training loss: 0.6927392584246558
Epoch: 29 | Iteration number: [380/393] 96% | Training loss: 0.6926930932622207
Epoch: 29 | Iteration number: [390/393] 99% | Training loss: 0.6926533850339743

 End of epoch: 29 | Train Loss: 0.6908834063976472 | Training Time: 67 

 End of epoch: 29 | Eval Loss: 0.6909070744806406 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/393] 2% | Training loss: 0.7592163622379303
Epoch: 30 | Iteration number: [20/393] 5% | Training loss: 0.7255090355873108
Epoch: 30 | Iteration number: [30/393] 7% | Training loss: 0.7138761281967163
Epoch: 30 | Iteration number: [40/393] 10% | Training loss: 0.7081799134612083
Epoch: 30 | Iteration number: [50/393] 12% | Training loss: 0.7047160005569458
Epoch: 30 | Iteration number: [60/393] 15% | Training loss: 0.7023371557394663
Epoch: 30 | Iteration number: [70/393] 17% | Training loss: 0.7007120813642229
Epoch: 30 | Iteration number: [80/393] 20% | Training loss: 0.6995158642530441
Epoch: 30 | Iteration number: [90/393] 22% | Training loss: 0.6985596941577064
Epoch: 30 | Iteration number: [100/393] 25% | Training loss: 0.6977981305122376
Epoch: 30 | Iteration number: [110/393] 27% | Training loss: 0.6970504706556147
Epoch: 30 | Iteration number: [120/393] 30% | Training loss: 0.6964935650428136
Epoch: 30 | Iteration number: [130/393] 33% | Training loss: 0.6959556620854598
Epoch: 30 | Iteration number: [140/393] 35% | Training loss: 0.6955699235200882
Epoch: 30 | Iteration number: [150/393] 38% | Training loss: 0.6952809079488118
Epoch: 30 | Iteration number: [160/393] 40% | Training loss: 0.6950299598276615
Epoch: 30 | Iteration number: [170/393] 43% | Training loss: 0.6948114623041713
Epoch: 30 | Iteration number: [180/393] 45% | Training loss: 0.6944995241032706
Epoch: 30 | Iteration number: [190/393] 48% | Training loss: 0.6942851179524472
Epoch: 30 | Iteration number: [200/393] 50% | Training loss: 0.6941090503334999
Epoch: 30 | Iteration number: [210/393] 53% | Training loss: 0.6939816806997572
Epoch: 30 | Iteration number: [220/393] 55% | Training loss: 0.6938292836601084
Epoch: 30 | Iteration number: [230/393] 58% | Training loss: 0.6936895730702773
Epoch: 30 | Iteration number: [240/393] 61% | Training loss: 0.6936274237930775
Epoch: 30 | Iteration number: [250/393] 63% | Training loss: 0.6935204946994782
Epoch: 30 | Iteration number: [260/393] 66% | Training loss: 0.6934187095898848
Epoch: 30 | Iteration number: [270/393] 68% | Training loss: 0.6933209392759535
Epoch: 30 | Iteration number: [280/393] 71% | Training loss: 0.6932468505842345
Epoch: 30 | Iteration number: [290/393] 73% | Training loss: 0.6931716740131378
Epoch: 30 | Iteration number: [300/393] 76% | Training loss: 0.6930786289771398
Epoch: 30 | Iteration number: [310/393] 78% | Training loss: 0.6930286786248607
Epoch: 30 | Iteration number: [320/393] 81% | Training loss: 0.6929767921566963
Epoch: 30 | Iteration number: [330/393] 83% | Training loss: 0.6929156417196447
Epoch: 30 | Iteration number: [340/393] 86% | Training loss: 0.692824152988546
Epoch: 30 | Iteration number: [350/393] 89% | Training loss: 0.6927577703339713
Epoch: 30 | Iteration number: [360/393] 91% | Training loss: 0.6926739651295873
Epoch: 30 | Iteration number: [370/393] 94% | Training loss: 0.6926597696703833
Epoch: 30 | Iteration number: [380/393] 96% | Training loss: 0.6926377585059718
Epoch: 30 | Iteration number: [390/393] 99% | Training loss: 0.6926178938303238

 End of epoch: 30 | Train Loss: 0.6908433014199934 | Training Time: 67 

 End of epoch: 30 | Eval Loss: 0.6909304151729662 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/393] 2% | Training loss: 0.7600820541381836
Epoch: 31 | Iteration number: [20/393] 5% | Training loss: 0.7262073904275894
Epoch: 31 | Iteration number: [30/393] 7% | Training loss: 0.7144043207168579
Epoch: 31 | Iteration number: [40/393] 10% | Training loss: 0.7086514830589294
Epoch: 31 | Iteration number: [50/393] 12% | Training loss: 0.7050533533096314
Epoch: 31 | Iteration number: [60/393] 15% | Training loss: 0.7026905566453934
Epoch: 31 | Iteration number: [70/393] 17% | Training loss: 0.7010565161705017
Epoch: 31 | Iteration number: [80/393] 20% | Training loss: 0.699895953387022
Epoch: 31 | Iteration number: [90/393] 22% | Training loss: 0.6988820678657955
Epoch: 31 | Iteration number: [100/393] 25% | Training loss: 0.6979670768976212
Epoch: 31 | Iteration number: [110/393] 27% | Training loss: 0.6973831929943778
Epoch: 31 | Iteration number: [120/393] 30% | Training loss: 0.6968981832265854
Epoch: 31 | Iteration number: [130/393] 33% | Training loss: 0.6964496094446916
Epoch: 31 | Iteration number: [140/393] 35% | Training loss: 0.6960620735372816
Epoch: 31 | Iteration number: [150/393] 38% | Training loss: 0.6956487842400869
Epoch: 31 | Iteration number: [160/393] 40% | Training loss: 0.6953080110251904
Epoch: 31 | Iteration number: [170/393] 43% | Training loss: 0.6949535899302539
Epoch: 31 | Iteration number: [180/393] 45% | Training loss: 0.6947025616963705
Epoch: 31 | Iteration number: [190/393] 48% | Training loss: 0.6945152389375787
Epoch: 31 | Iteration number: [200/393] 50% | Training loss: 0.6943044263124466
Epoch: 31 | Iteration number: [210/393] 53% | Training loss: 0.6941716832774026
Epoch: 31 | Iteration number: [220/393] 55% | Training loss: 0.6940390787341378
Epoch: 31 | Iteration number: [230/393] 58% | Training loss: 0.693886907722639
Epoch: 31 | Iteration number: [240/393] 61% | Training loss: 0.6937636941671371
Epoch: 31 | Iteration number: [250/393] 63% | Training loss: 0.6936342227458954
Epoch: 31 | Iteration number: [260/393] 66% | Training loss: 0.6935674859927251
Epoch: 31 | Iteration number: [270/393] 68% | Training loss: 0.6935051670780888
Epoch: 31 | Iteration number: [280/393] 71% | Training loss: 0.6934275652681078
Epoch: 31 | Iteration number: [290/393] 73% | Training loss: 0.6933237429322867
Epoch: 31 | Iteration number: [300/393] 76% | Training loss: 0.6932287114858627
Epoch: 31 | Iteration number: [310/393] 78% | Training loss: 0.6931333341906147
Epoch: 31 | Iteration number: [320/393] 81% | Training loss: 0.6930512050166726
Epoch: 31 | Iteration number: [330/393] 83% | Training loss: 0.6929857568307356
Epoch: 31 | Iteration number: [340/393] 86% | Training loss: 0.6929176291998695
Epoch: 31 | Iteration number: [350/393] 89% | Training loss: 0.6928622954232352
Epoch: 31 | Iteration number: [360/393] 91% | Training loss: 0.6928200609154171
Epoch: 31 | Iteration number: [370/393] 94% | Training loss: 0.6927709054302524
Epoch: 31 | Iteration number: [380/393] 96% | Training loss: 0.6927194432208412
Epoch: 31 | Iteration number: [390/393] 99% | Training loss: 0.6926630478638869

 End of epoch: 31 | Train Loss: 0.6908980887051454 | Training Time: 68 

 End of epoch: 31 | Eval Loss: 0.6907917905826958 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/393] 2% | Training loss: 0.7591871917247772
Epoch: 32 | Iteration number: [20/393] 5% | Training loss: 0.7248777657747268
Epoch: 32 | Iteration number: [30/393] 7% | Training loss: 0.7133351643880208
Epoch: 32 | Iteration number: [40/393] 10% | Training loss: 0.7076435267925263
Epoch: 32 | Iteration number: [50/393] 12% | Training loss: 0.7042438530921936
Epoch: 32 | Iteration number: [60/393] 15% | Training loss: 0.7021264771620432
Epoch: 32 | Iteration number: [70/393] 17% | Training loss: 0.7005601746695382
Epoch: 32 | Iteration number: [80/393] 20% | Training loss: 0.6993920043110847
Epoch: 32 | Iteration number: [90/393] 22% | Training loss: 0.6984339601463742
Epoch: 32 | Iteration number: [100/393] 25% | Training loss: 0.6975737017393112
Epoch: 32 | Iteration number: [110/393] 27% | Training loss: 0.6969478390433571
Epoch: 32 | Iteration number: [120/393] 30% | Training loss: 0.6965004925926527
Epoch: 32 | Iteration number: [130/393] 33% | Training loss: 0.6959875216850868
Epoch: 32 | Iteration number: [140/393] 35% | Training loss: 0.695628115109035
Epoch: 32 | Iteration number: [150/393] 38% | Training loss: 0.6953116631507874
Epoch: 32 | Iteration number: [160/393] 40% | Training loss: 0.6949690692126751
Epoch: 32 | Iteration number: [170/393] 43% | Training loss: 0.6946873447474311
Epoch: 32 | Iteration number: [180/393] 45% | Training loss: 0.6944863177008099
Epoch: 32 | Iteration number: [190/393] 48% | Training loss: 0.6942733156053643
Epoch: 32 | Iteration number: [200/393] 50% | Training loss: 0.6940661174058914
Epoch: 32 | Iteration number: [210/393] 53% | Training loss: 0.6938836452506837
Epoch: 32 | Iteration number: [220/393] 55% | Training loss: 0.6937689496712252
Epoch: 32 | Iteration number: [230/393] 58% | Training loss: 0.6935979897561281
Epoch: 32 | Iteration number: [240/393] 61% | Training loss: 0.6934822080036004
Epoch: 32 | Iteration number: [250/393] 63% | Training loss: 0.6933997960090638
Epoch: 32 | Iteration number: [260/393] 66% | Training loss: 0.6933030942311653
Epoch: 32 | Iteration number: [270/393] 68% | Training loss: 0.6932306207992412
Epoch: 32 | Iteration number: [280/393] 71% | Training loss: 0.6931382605007717
Epoch: 32 | Iteration number: [290/393] 73% | Training loss: 0.6930667124945542
Epoch: 32 | Iteration number: [300/393] 76% | Training loss: 0.6929938852787018
Epoch: 32 | Iteration number: [310/393] 78% | Training loss: 0.6928858109058872
Epoch: 32 | Iteration number: [320/393] 81% | Training loss: 0.6928127130493522
Epoch: 32 | Iteration number: [330/393] 83% | Training loss: 0.6927441000938416
Epoch: 32 | Iteration number: [340/393] 86% | Training loss: 0.6927053730277454
Epoch: 32 | Iteration number: [350/393] 89% | Training loss: 0.6926604270935058
Epoch: 32 | Iteration number: [360/393] 91% | Training loss: 0.6925886717107561
Epoch: 32 | Iteration number: [370/393] 94% | Training loss: 0.6925372442683658
Epoch: 32 | Iteration number: [380/393] 96% | Training loss: 0.692461010813713
Epoch: 32 | Iteration number: [390/393] 99% | Training loss: 0.6924530966159624

 End of epoch: 32 | Train Loss: 0.6906807425671254 | Training Time: 68 

 End of epoch: 32 | Eval Loss: 0.6907540693575022 | Evaluating Time: 17 
Epoch: 33 | Iteration number: [10/393] 2% | Training loss: 0.760405158996582
Epoch: 33 | Iteration number: [20/393] 5% | Training loss: 0.7254872024059296
Epoch: 33 | Iteration number: [30/393] 7% | Training loss: 0.7135670145352682
Epoch: 33 | Iteration number: [40/393] 10% | Training loss: 0.707988041639328
Epoch: 33 | Iteration number: [50/393] 12% | Training loss: 0.7042794764041901
Epoch: 33 | Iteration number: [60/393] 15% | Training loss: 0.7021931608517965
Epoch: 33 | Iteration number: [70/393] 17% | Training loss: 0.700529259443283
Epoch: 33 | Iteration number: [80/393] 20% | Training loss: 0.6992115780711174
Epoch: 33 | Iteration number: [90/393] 22% | Training loss: 0.6983460896544986
Epoch: 33 | Iteration number: [100/393] 25% | Training loss: 0.6975439929962158
Epoch: 33 | Iteration number: [110/393] 27% | Training loss: 0.6968540435487574
Epoch: 33 | Iteration number: [120/393] 30% | Training loss: 0.6963131497303645
Epoch: 33 | Iteration number: [130/393] 33% | Training loss: 0.6958214947810539
Epoch: 33 | Iteration number: [140/393] 35% | Training loss: 0.6953652398926872
Epoch: 33 | Iteration number: [150/393] 38% | Training loss: 0.69507452805837
Epoch: 33 | Iteration number: [160/393] 40% | Training loss: 0.6947924379259348
Epoch: 33 | Iteration number: [170/393] 43% | Training loss: 0.6945498533108655
Epoch: 33 | Iteration number: [180/393] 45% | Training loss: 0.6943571779463026
Epoch: 33 | Iteration number: [190/393] 48% | Training loss: 0.6941594014042303
Epoch: 33 | Iteration number: [200/393] 50% | Training loss: 0.6939765784144402
Epoch: 33 | Iteration number: [210/393] 53% | Training loss: 0.6938396828515189
Epoch: 33 | Iteration number: [220/393] 55% | Training loss: 0.6937099212949926
Epoch: 33 | Iteration number: [230/393] 58% | Training loss: 0.6935964084189871
Epoch: 33 | Iteration number: [240/393] 61% | Training loss: 0.6934412196278572
Epoch: 33 | Iteration number: [250/393] 63% | Training loss: 0.6933262522220611
Epoch: 33 | Iteration number: [260/393] 66% | Training loss: 0.6932447949281105
Epoch: 33 | Iteration number: [270/393] 68% | Training loss: 0.693147153324551
Epoch: 33 | Iteration number: [280/393] 71% | Training loss: 0.6930819400719234
Epoch: 33 | Iteration number: [290/393] 73% | Training loss: 0.6929824068628508
Epoch: 33 | Iteration number: [300/393] 76% | Training loss: 0.6928770736853281
Epoch: 33 | Iteration number: [310/393] 78% | Training loss: 0.6928069235817078
Epoch: 33 | Iteration number: [320/393] 81% | Training loss: 0.6927300674840808
Epoch: 33 | Iteration number: [330/393] 83% | Training loss: 0.6926693486444878
Epoch: 33 | Iteration number: [340/393] 86% | Training loss: 0.6926150155418059
Epoch: 33 | Iteration number: [350/393] 89% | Training loss: 0.6925630995205471
Epoch: 33 | Iteration number: [360/393] 91% | Training loss: 0.6924756753775808
Epoch: 33 | Iteration number: [370/393] 94% | Training loss: 0.6924133817891817
Epoch: 33 | Iteration number: [380/393] 96% | Training loss: 0.6923912079710709
Epoch: 33 | Iteration number: [390/393] 99% | Training loss: 0.6923547954131395

 End of epoch: 33 | Train Loss: 0.690592250144512 | Training Time: 68 

 End of epoch: 33 | Eval Loss: 0.6907224813286139 | Evaluating Time: 17 
Epoch: 34 | Iteration number: [10/393] 2% | Training loss: 0.7591774523258209
Epoch: 34 | Iteration number: [20/393] 5% | Training loss: 0.7253188401460647
Epoch: 34 | Iteration number: [30/393] 7% | Training loss: 0.7139766613642374
Epoch: 34 | Iteration number: [40/393] 10% | Training loss: 0.7079711735248566
Epoch: 34 | Iteration number: [50/393] 12% | Training loss: 0.7044005954265594
Epoch: 34 | Iteration number: [60/393] 15% | Training loss: 0.7018951853116353
Epoch: 34 | Iteration number: [70/393] 17% | Training loss: 0.7003520982606071
Epoch: 34 | Iteration number: [80/393] 20% | Training loss: 0.6991985499858856
Epoch: 34 | Iteration number: [90/393] 22% | Training loss: 0.6981740249527826
Epoch: 34 | Iteration number: [100/393] 25% | Training loss: 0.6974172812700271
Epoch: 34 | Iteration number: [110/393] 27% | Training loss: 0.6966883681037209
Epoch: 34 | Iteration number: [120/393] 30% | Training loss: 0.6961338480313619
Epoch: 34 | Iteration number: [130/393] 33% | Training loss: 0.6956858093921955
Epoch: 34 | Iteration number: [140/393] 35% | Training loss: 0.6953757835286004
Epoch: 34 | Iteration number: [150/393] 38% | Training loss: 0.6950804122289022
Epoch: 34 | Iteration number: [160/393] 40% | Training loss: 0.6948163084685802
Epoch: 34 | Iteration number: [170/393] 43% | Training loss: 0.6946172286482418
Epoch: 34 | Iteration number: [180/393] 45% | Training loss: 0.6944000191158719
Epoch: 34 | Iteration number: [190/393] 48% | Training loss: 0.6942378837811319
Epoch: 34 | Iteration number: [200/393] 50% | Training loss: 0.6940036705136299
Epoch: 34 | Iteration number: [210/393] 53% | Training loss: 0.6938796889214288
Epoch: 34 | Iteration number: [220/393] 55% | Training loss: 0.6937478916211561
Epoch: 34 | Iteration number: [230/393] 58% | Training loss: 0.6936202577922655
Epoch: 34 | Iteration number: [240/393] 61% | Training loss: 0.693534804135561
Epoch: 34 | Iteration number: [250/393] 63% | Training loss: 0.6934173157215119
Epoch: 34 | Iteration number: [260/393] 66% | Training loss: 0.6932509287045552
Epoch: 34 | Iteration number: [270/393] 68% | Training loss: 0.6931392391522725
Epoch: 34 | Iteration number: [280/393] 71% | Training loss: 0.6930787644215992
Epoch: 34 | Iteration number: [290/393] 73% | Training loss: 0.6929457742592384
Epoch: 34 | Iteration number: [300/393] 76% | Training loss: 0.6928263237078984
Epoch: 34 | Iteration number: [310/393] 78% | Training loss: 0.6927309884179023
Epoch: 34 | Iteration number: [320/393] 81% | Training loss: 0.6926862334832549
Epoch: 34 | Iteration number: [330/393] 83% | Training loss: 0.692624628724474
Epoch: 34 | Iteration number: [340/393] 86% | Training loss: 0.69259432080914
Epoch: 34 | Iteration number: [350/393] 89% | Training loss: 0.6925453138351441
Epoch: 34 | Iteration number: [360/393] 91% | Training loss: 0.692524323032962
Epoch: 34 | Iteration number: [370/393] 94% | Training loss: 0.6924812144524343
Epoch: 34 | Iteration number: [380/393] 96% | Training loss: 0.6924239400186036
Epoch: 34 | Iteration number: [390/393] 99% | Training loss: 0.6923846567288423

 End of epoch: 34 | Train Loss: 0.6906140334430239 | Training Time: 68 

 End of epoch: 34 | Eval Loss: 0.6908314130744155 | Evaluating Time: 17 
Epoch: 35 | Iteration number: [10/393] 2% | Training loss: 0.7606035947799683
Epoch: 35 | Iteration number: [20/393] 5% | Training loss: 0.7254314333200454
Epoch: 35 | Iteration number: [30/393] 7% | Training loss: 0.7137186169624329
Epoch: 35 | Iteration number: [40/393] 10% | Training loss: 0.7079269796609878
Epoch: 35 | Iteration number: [50/393] 12% | Training loss: 0.7043934726715088
Epoch: 35 | Iteration number: [60/393] 15% | Training loss: 0.7020838429530462
Epoch: 35 | Iteration number: [70/393] 17% | Training loss: 0.7005272541727339
Epoch: 35 | Iteration number: [80/393] 20% | Training loss: 0.6992745086550712
Epoch: 35 | Iteration number: [90/393] 22% | Training loss: 0.6983132282892863
Epoch: 35 | Iteration number: [100/393] 25% | Training loss: 0.6974717050790786
Epoch: 35 | Iteration number: [110/393] 27% | Training loss: 0.6967932034622539
Epoch: 35 | Iteration number: [120/393] 30% | Training loss: 0.696222432454427
Epoch: 35 | Iteration number: [130/393] 33% | Training loss: 0.6957678877390348
Epoch: 35 | Iteration number: [140/393] 35% | Training loss: 0.695415141752788
Epoch: 35 | Iteration number: [150/393] 38% | Training loss: 0.6950717775026957
Epoch: 35 | Iteration number: [160/393] 40% | Training loss: 0.6948453933000565
Epoch: 35 | Iteration number: [170/393] 43% | Training loss: 0.694574782077004
Epoch: 35 | Iteration number: [180/393] 45% | Training loss: 0.6943679998318354
Epoch: 35 | Iteration number: [190/393] 48% | Training loss: 0.6941905153425116
Epoch: 35 | Iteration number: [200/393] 50% | Training loss: 0.6939451715350151
Epoch: 35 | Iteration number: [210/393] 53% | Training loss: 0.6937789366358802
Epoch: 35 | Iteration number: [220/393] 55% | Training loss: 0.6935981089418585
Epoch: 35 | Iteration number: [230/393] 58% | Training loss: 0.6934475160163381
Epoch: 35 | Iteration number: [240/393] 61% | Training loss: 0.6933562487363816
Epoch: 35 | Iteration number: [250/393] 63% | Training loss: 0.6932844135761261
Epoch: 35 | Iteration number: [260/393] 66% | Training loss: 0.6931976648477408
Epoch: 35 | Iteration number: [270/393] 68% | Training loss: 0.6931236233976152
Epoch: 35 | Iteration number: [280/393] 71% | Training loss: 0.693048509316785
Epoch: 35 | Iteration number: [290/393] 73% | Training loss: 0.6929448818338328
Epoch: 35 | Iteration number: [300/393] 76% | Training loss: 0.6928825706243515
Epoch: 35 | Iteration number: [310/393] 78% | Training loss: 0.6928094786982383
Epoch: 35 | Iteration number: [320/393] 81% | Training loss: 0.692772913351655
Epoch: 35 | Iteration number: [330/393] 83% | Training loss: 0.6927088466557589
Epoch: 35 | Iteration number: [340/393] 86% | Training loss: 0.6926049593616934
Epoch: 35 | Iteration number: [350/393] 89% | Training loss: 0.6925143049444471
Epoch: 35 | Iteration number: [360/393] 91% | Training loss: 0.6924718966086706
Epoch: 35 | Iteration number: [370/393] 94% | Training loss: 0.6924104369975425
Epoch: 35 | Iteration number: [380/393] 96% | Training loss: 0.6923741814337279
Epoch: 35 | Iteration number: [390/393] 99% | Training loss: 0.692330442636441

 End of epoch: 35 | Train Loss: 0.6905461916790057 | Training Time: 67 

 End of epoch: 35 | Eval Loss: 0.6906105219101419 | Evaluating Time: 18 
Epoch: 36 | Iteration number: [10/393] 2% | Training loss: 0.7606382668018341
Epoch: 36 | Iteration number: [20/393] 5% | Training loss: 0.725371915102005
Epoch: 36 | Iteration number: [30/393] 7% | Training loss: 0.713806672890981
Epoch: 36 | Iteration number: [40/393] 10% | Training loss: 0.7080542951822281
Epoch: 36 | Iteration number: [50/393] 12% | Training loss: 0.7046543216705322
Epoch: 36 | Iteration number: [60/393] 15% | Training loss: 0.7023391296466192
Epoch: 36 | Iteration number: [70/393] 17% | Training loss: 0.7005639501980373
Epoch: 36 | Iteration number: [80/393] 20% | Training loss: 0.699310627579689
Epoch: 36 | Iteration number: [90/393] 22% | Training loss: 0.6983951283825769
Epoch: 36 | Iteration number: [100/393] 25% | Training loss: 0.6974988788366318
Epoch: 36 | Iteration number: [110/393] 27% | Training loss: 0.6967006542465903
Epoch: 36 | Iteration number: [120/393] 30% | Training loss: 0.6961497073372205
Epoch: 36 | Iteration number: [130/393] 33% | Training loss: 0.695771333346
Epoch: 36 | Iteration number: [140/393] 35% | Training loss: 0.6954399079084397
Epoch: 36 | Iteration number: [150/393] 38% | Training loss: 0.6951404138406118
Epoch: 36 | Iteration number: [160/393] 40% | Training loss: 0.6948729597032071
Epoch: 36 | Iteration number: [170/393] 43% | Training loss: 0.6946577531449935
Epoch: 36 | Iteration number: [180/393] 45% | Training loss: 0.6944291657871671
Epoch: 36 | Iteration number: [190/393] 48% | Training loss: 0.6942491929782064
Epoch: 36 | Iteration number: [200/393] 50% | Training loss: 0.6940971165895462
Epoch: 36 | Iteration number: [210/393] 53% | Training loss: 0.6939846944241297
Epoch: 36 | Iteration number: [220/393] 55% | Training loss: 0.6938200387087735
Epoch: 36 | Iteration number: [230/393] 58% | Training loss: 0.6936600081298663
Epoch: 36 | Iteration number: [240/393] 61% | Training loss: 0.693570181975762
Epoch: 36 | Iteration number: [250/393] 63% | Training loss: 0.693455727815628
Epoch: 36 | Iteration number: [260/393] 66% | Training loss: 0.6933135420084
Epoch: 36 | Iteration number: [270/393] 68% | Training loss: 0.6932123133429775
Epoch: 36 | Iteration number: [280/393] 71% | Training loss: 0.6931348093918391
Epoch: 36 | Iteration number: [290/393] 73% | Training loss: 0.69307718811364
Epoch: 36 | Iteration number: [300/393] 76% | Training loss: 0.6930077850818634
Epoch: 36 | Iteration number: [310/393] 78% | Training loss: 0.692934819767552
Epoch: 36 | Iteration number: [320/393] 81% | Training loss: 0.6928616108372807
Epoch: 36 | Iteration number: [330/393] 83% | Training loss: 0.6927985380996358
Epoch: 36 | Iteration number: [340/393] 86% | Training loss: 0.6927538135472466
Epoch: 36 | Iteration number: [350/393] 89% | Training loss: 0.6927147006988525
Epoch: 36 | Iteration number: [360/393] 91% | Training loss: 0.6926527864403195
Epoch: 36 | Iteration number: [370/393] 94% | Training loss: 0.6925916579929559
Epoch: 36 | Iteration number: [380/393] 96% | Training loss: 0.6925405729758112
Epoch: 36 | Iteration number: [390/393] 99% | Training loss: 0.6925141226022672

 End of epoch: 36 | Train Loss: 0.6907398597581392 | Training Time: 68 

 End of epoch: 36 | Eval Loss: 0.6910533965850363 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/393] 2% | Training loss: 0.7590440034866333
Epoch: 37 | Iteration number: [20/393] 5% | Training loss: 0.7238705426454544
Epoch: 37 | Iteration number: [30/393] 7% | Training loss: 0.7129757304986318
Epoch: 37 | Iteration number: [40/393] 10% | Training loss: 0.707496227324009
Epoch: 37 | Iteration number: [50/393] 12% | Training loss: 0.7041862678527832
Epoch: 37 | Iteration number: [60/393] 15% | Training loss: 0.701687025030454
Epoch: 37 | Iteration number: [70/393] 17% | Training loss: 0.700005475963865
Epoch: 37 | Iteration number: [80/393] 20% | Training loss: 0.6988775663077831
Epoch: 37 | Iteration number: [90/393] 22% | Training loss: 0.69801577395863
Epoch: 37 | Iteration number: [100/393] 25% | Training loss: 0.6973866158723832
Epoch: 37 | Iteration number: [110/393] 27% | Training loss: 0.6968730552629991
Epoch: 37 | Iteration number: [120/393] 30% | Training loss: 0.6964049895604452
Epoch: 37 | Iteration number: [130/393] 33% | Training loss: 0.6959710653011616
Epoch: 37 | Iteration number: [140/393] 35% | Training loss: 0.6955762024436678
Epoch: 37 | Iteration number: [150/393] 38% | Training loss: 0.6952046390374501
Epoch: 37 | Iteration number: [160/393] 40% | Training loss: 0.6949341550469399
Epoch: 37 | Iteration number: [170/393] 43% | Training loss: 0.6947101305512821
Epoch: 37 | Iteration number: [180/393] 45% | Training loss: 0.6945075912608041
Epoch: 37 | Iteration number: [190/393] 48% | Training loss: 0.694271908622039
Epoch: 37 | Iteration number: [200/393] 50% | Training loss: 0.694098307788372
Epoch: 37 | Iteration number: [210/393] 53% | Training loss: 0.6939069722379957
Epoch: 37 | Iteration number: [220/393] 55% | Training loss: 0.6937024796550925
Epoch: 37 | Iteration number: [230/393] 58% | Training loss: 0.6935046447359997
Epoch: 37 | Iteration number: [240/393] 61% | Training loss: 0.6933698331316313
Epoch: 37 | Iteration number: [250/393] 63% | Training loss: 0.693276914358139
Epoch: 37 | Iteration number: [260/393] 66% | Training loss: 0.6931997526150483
Epoch: 37 | Iteration number: [270/393] 68% | Training loss: 0.6931011610560947
Epoch: 37 | Iteration number: [280/393] 71% | Training loss: 0.6929731622338295
Epoch: 37 | Iteration number: [290/393] 73% | Training loss: 0.692899278936715
Epoch: 37 | Iteration number: [300/393] 76% | Training loss: 0.6928536081314087
Epoch: 37 | Iteration number: [310/393] 78% | Training loss: 0.6927790378370593
Epoch: 37 | Iteration number: [320/393] 81% | Training loss: 0.6927234023809433
Epoch: 37 | Iteration number: [330/393] 83% | Training loss: 0.6926693168553439
Epoch: 37 | Iteration number: [340/393] 86% | Training loss: 0.6926277772468679
Epoch: 37 | Iteration number: [350/393] 89% | Training loss: 0.692583693265915
Epoch: 37 | Iteration number: [360/393] 91% | Training loss: 0.6925455600023269
Epoch: 37 | Iteration number: [370/393] 94% | Training loss: 0.6925034189546431
Epoch: 37 | Iteration number: [380/393] 96% | Training loss: 0.69245497223578
Epoch: 37 | Iteration number: [390/393] 99% | Training loss: 0.6923963986910306

 End of epoch: 37 | Train Loss: 0.6906292797954938 | Training Time: 68 

 End of epoch: 37 | Eval Loss: 0.690673831774264 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/393] 2% | Training loss: 0.7586490452289582
Epoch: 38 | Iteration number: [20/393] 5% | Training loss: 0.7245797932147979
Epoch: 38 | Iteration number: [30/393] 7% | Training loss: 0.7132314662138621
Epoch: 38 | Iteration number: [40/393] 10% | Training loss: 0.7072943642735481
Epoch: 38 | Iteration number: [50/393] 12% | Training loss: 0.7040803694725036
Epoch: 38 | Iteration number: [60/393] 15% | Training loss: 0.7017896105845769
Epoch: 38 | Iteration number: [70/393] 17% | Training loss: 0.700170886516571
Epoch: 38 | Iteration number: [80/393] 20% | Training loss: 0.6990334689617157
Epoch: 38 | Iteration number: [90/393] 22% | Training loss: 0.698180741071701
Epoch: 38 | Iteration number: [100/393] 25% | Training loss: 0.6974969321489334
Epoch: 38 | Iteration number: [110/393] 27% | Training loss: 0.6968779688531702
Epoch: 38 | Iteration number: [120/393] 30% | Training loss: 0.6963301777839661
Epoch: 38 | Iteration number: [130/393] 33% | Training loss: 0.6958831324027135
Epoch: 38 | Iteration number: [140/393] 35% | Training loss: 0.6954328515699931
Epoch: 38 | Iteration number: [150/393] 38% | Training loss: 0.695116331577301
Epoch: 38 | Iteration number: [160/393] 40% | Training loss: 0.6948302384465933
Epoch: 38 | Iteration number: [170/393] 43% | Training loss: 0.6945133991101209
Epoch: 38 | Iteration number: [180/393] 45% | Training loss: 0.6943288885884815
Epoch: 38 | Iteration number: [190/393] 48% | Training loss: 0.6941700113447089
Epoch: 38 | Iteration number: [200/393] 50% | Training loss: 0.6939638307690621
Epoch: 38 | Iteration number: [210/393] 53% | Training loss: 0.6937766986233848
Epoch: 38 | Iteration number: [220/393] 55% | Training loss: 0.693628391623497
Epoch: 38 | Iteration number: [230/393] 58% | Training loss: 0.6934600430986155
Epoch: 38 | Iteration number: [240/393] 61% | Training loss: 0.6933160287638506
Epoch: 38 | Iteration number: [250/393] 63% | Training loss: 0.6932004511356353
Epoch: 38 | Iteration number: [260/393] 66% | Training loss: 0.6931019993928763
Epoch: 38 | Iteration number: [270/393] 68% | Training loss: 0.6929985143520214
Epoch: 38 | Iteration number: [280/393] 71% | Training loss: 0.6929539959345545
Epoch: 38 | Iteration number: [290/393] 73% | Training loss: 0.6928526903020924
Epoch: 38 | Iteration number: [300/393] 76% | Training loss: 0.6927594399452209
Epoch: 38 | Iteration number: [310/393] 78% | Training loss: 0.6927204237830255
Epoch: 38 | Iteration number: [320/393] 81% | Training loss: 0.6926461614668369
Epoch: 38 | Iteration number: [330/393] 83% | Training loss: 0.6925898512204488
Epoch: 38 | Iteration number: [340/393] 86% | Training loss: 0.6925163041142857
Epoch: 38 | Iteration number: [350/393] 89% | Training loss: 0.6924875000544957
Epoch: 38 | Iteration number: [360/393] 91% | Training loss: 0.6924446115891139
Epoch: 38 | Iteration number: [370/393] 94% | Training loss: 0.6924017677436004
Epoch: 38 | Iteration number: [380/393] 96% | Training loss: 0.692358375536768
Epoch: 38 | Iteration number: [390/393] 99% | Training loss: 0.6923079800911439

 End of epoch: 38 | Train Loss: 0.6905415698165506 | Training Time: 68 

 End of epoch: 38 | Eval Loss: 0.6906873510808361 | Evaluating Time: 18 
Epoch: 39 | Iteration number: [10/393] 2% | Training loss: 0.7608215808868408
Epoch: 39 | Iteration number: [20/393] 5% | Training loss: 0.7253859102725982
Epoch: 39 | Iteration number: [30/393] 7% | Training loss: 0.7133687615394593
Epoch: 39 | Iteration number: [40/393] 10% | Training loss: 0.7075412109494209
Epoch: 39 | Iteration number: [50/393] 12% | Training loss: 0.70412060379982
Epoch: 39 | Iteration number: [60/393] 15% | Training loss: 0.7016734788815181
Epoch: 39 | Iteration number: [70/393] 17% | Training loss: 0.7000694002423967
Epoch: 39 | Iteration number: [80/393] 20% | Training loss: 0.698924207687378
Epoch: 39 | Iteration number: [90/393] 22% | Training loss: 0.6981484538979
Epoch: 39 | Iteration number: [100/393] 25% | Training loss: 0.6974250555038453
Epoch: 39 | Iteration number: [110/393] 27% | Training loss: 0.696797820112922
Epoch: 39 | Iteration number: [120/393] 30% | Training loss: 0.6962839032212893
Epoch: 39 | Iteration number: [130/393] 33% | Training loss: 0.6959476998219123
Epoch: 39 | Iteration number: [140/393] 35% | Training loss: 0.6954932038273131
Epoch: 39 | Iteration number: [150/393] 38% | Training loss: 0.6951401170094808
Epoch: 39 | Iteration number: [160/393] 40% | Training loss: 0.6949081487953663
Epoch: 39 | Iteration number: [170/393] 43% | Training loss: 0.6946080674143399
Epoch: 39 | Iteration number: [180/393] 45% | Training loss: 0.6943457113371955
Epoch: 39 | Iteration number: [190/393] 48% | Training loss: 0.6941059972110547
Epoch: 39 | Iteration number: [200/393] 50% | Training loss: 0.6939106351137161
Epoch: 39 | Iteration number: [210/393] 53% | Training loss: 0.6937544169880095
Epoch: 39 | Iteration number: [220/393] 55% | Training loss: 0.6936427549882369
Epoch: 39 | Iteration number: [230/393] 58% | Training loss: 0.6935067078341608
Epoch: 39 | Iteration number: [240/393] 61% | Training loss: 0.6933643368383249
Epoch: 39 | Iteration number: [250/393] 63% | Training loss: 0.6932304015159607
Epoch: 39 | Iteration number: [260/393] 66% | Training loss: 0.6931479424238205
Epoch: 39 | Iteration number: [270/393] 68% | Training loss: 0.6930254139282085
Epoch: 39 | Iteration number: [280/393] 71% | Training loss: 0.6929410455482347
Epoch: 39 | Iteration number: [290/393] 73% | Training loss: 0.6928636427583366
Epoch: 39 | Iteration number: [300/393] 76% | Training loss: 0.6927815075715383
Epoch: 39 | Iteration number: [310/393] 78% | Training loss: 0.6927089864207853
Epoch: 39 | Iteration number: [320/393] 81% | Training loss: 0.6926473490893841
Epoch: 39 | Iteration number: [330/393] 83% | Training loss: 0.6925975814010158
Epoch: 39 | Iteration number: [340/393] 86% | Training loss: 0.692530928289189
Epoch: 39 | Iteration number: [350/393] 89% | Training loss: 0.6924777470316206
Epoch: 39 | Iteration number: [360/393] 91% | Training loss: 0.6924372446205881
Epoch: 39 | Iteration number: [370/393] 94% | Training loss: 0.6923909387073002
Epoch: 39 | Iteration number: [380/393] 96% | Training loss: 0.6923228765788831
Epoch: 39 | Iteration number: [390/393] 99% | Training loss: 0.6922600084390396

 End of epoch: 39 | Train Loss: 0.6904826878591348 | Training Time: 67 

 End of epoch: 39 | Eval Loss: 0.6905554472183695 | Evaluating Time: 17 
Epoch: 40 | Iteration number: [10/393] 2% | Training loss: 0.759647524356842
Epoch: 40 | Iteration number: [20/393] 5% | Training loss: 0.7251261323690414
Epoch: 40 | Iteration number: [30/393] 7% | Training loss: 0.7135041693846385
Epoch: 40 | Iteration number: [40/393] 10% | Training loss: 0.7074691444635391
Epoch: 40 | Iteration number: [50/393] 12% | Training loss: 0.7042970025539398
Epoch: 40 | Iteration number: [60/393] 15% | Training loss: 0.7021302133798599
Epoch: 40 | Iteration number: [70/393] 17% | Training loss: 0.7008469130311693
Epoch: 40 | Iteration number: [80/393] 20% | Training loss: 0.6998699881136418
Epoch: 40 | Iteration number: [90/393] 22% | Training loss: 0.6990071528487736
Epoch: 40 | Iteration number: [100/393] 25% | Training loss: 0.6983635371923447
Epoch: 40 | Iteration number: [110/393] 27% | Training loss: 0.697841197794134
Epoch: 40 | Iteration number: [120/393] 30% | Training loss: 0.6974121655027071
Epoch: 40 | Iteration number: [130/393] 33% | Training loss: 0.6969382726229154
Epoch: 40 | Iteration number: [140/393] 35% | Training loss: 0.6965535823787962
Epoch: 40 | Iteration number: [150/393] 38% | Training loss: 0.6961018133163452
Epoch: 40 | Iteration number: [160/393] 40% | Training loss: 0.695761987566948
Epoch: 40 | Iteration number: [170/393] 43% | Training loss: 0.6954350082313313
Epoch: 40 | Iteration number: [180/393] 45% | Training loss: 0.6951981378926171
Epoch: 40 | Iteration number: [190/393] 48% | Training loss: 0.6949714218315325
Epoch: 40 | Iteration number: [200/393] 50% | Training loss: 0.6947924697399139
Epoch: 40 | Iteration number: [210/393] 53% | Training loss: 0.69456393463271
Epoch: 40 | Iteration number: [220/393] 55% | Training loss: 0.6943468554453416
Epoch: 40 | Iteration number: [230/393] 58% | Training loss: 0.694197198100712
Epoch: 40 | Iteration number: [240/393] 61% | Training loss: 0.6940226557354132
Epoch: 40 | Iteration number: [250/393] 63% | Training loss: 0.6938729686737061
Epoch: 40 | Iteration number: [260/393] 66% | Training loss: 0.6937667612846081
Epoch: 40 | Iteration number: [270/393] 68% | Training loss: 0.6936263857064424
Epoch: 40 | Iteration number: [280/393] 71% | Training loss: 0.6935305110045842
Epoch: 40 | Iteration number: [290/393] 73% | Training loss: 0.6934322410616381
Epoch: 40 | Iteration number: [300/393] 76% | Training loss: 0.6933465347687403
Epoch: 40 | Iteration number: [310/393] 78% | Training loss: 0.6932691664465012
Epoch: 40 | Iteration number: [320/393] 81% | Training loss: 0.6931929221376777
Epoch: 40 | Iteration number: [330/393] 83% | Training loss: 0.6930906897241419
Epoch: 40 | Iteration number: [340/393] 86% | Training loss: 0.6929941403515198
Epoch: 40 | Iteration number: [350/393] 89% | Training loss: 0.6929209928853172
Epoch: 40 | Iteration number: [360/393] 91% | Training loss: 0.6928781219654613
Epoch: 40 | Iteration number: [370/393] 94% | Training loss: 0.6928167736208116
Epoch: 40 | Iteration number: [380/393] 96% | Training loss: 0.6927396239418733
Epoch: 40 | Iteration number: [390/393] 99% | Training loss: 0.6927005616518167

 End of epoch: 40 | Train Loss: 0.6909301076226562 | Training Time: 67 

 End of epoch: 40 | Eval Loss: 0.6906551499756015 | Evaluating Time: 17 
Epoch: 41 | Iteration number: [10/393] 2% | Training loss: 0.7590063512325287
Epoch: 41 | Iteration number: [20/393] 5% | Training loss: 0.724942660331726
Epoch: 41 | Iteration number: [30/393] 7% | Training loss: 0.7133710225423177
Epoch: 41 | Iteration number: [40/393] 10% | Training loss: 0.7078641697764396
Epoch: 41 | Iteration number: [50/393] 12% | Training loss: 0.7043328928947449
Epoch: 41 | Iteration number: [60/393] 15% | Training loss: 0.7022363156080246
Epoch: 41 | Iteration number: [70/393] 17% | Training loss: 0.7005470888955253
Epoch: 41 | Iteration number: [80/393] 20% | Training loss: 0.6993244878947735
Epoch: 41 | Iteration number: [90/393] 22% | Training loss: 0.6982424285676744
Epoch: 41 | Iteration number: [100/393] 25% | Training loss: 0.6974452966451645
Epoch: 41 | Iteration number: [110/393] 27% | Training loss: 0.6966708947311748
Epoch: 41 | Iteration number: [120/393] 30% | Training loss: 0.6961113308866819
Epoch: 41 | Iteration number: [130/393] 33% | Training loss: 0.6956843504538903
Epoch: 41 | Iteration number: [140/393] 35% | Training loss: 0.6952324884278434
Epoch: 41 | Iteration number: [150/393] 38% | Training loss: 0.6949903126557668
Epoch: 41 | Iteration number: [160/393] 40% | Training loss: 0.6948080662637949
Epoch: 41 | Iteration number: [170/393] 43% | Training loss: 0.6945652747855467
Epoch: 41 | Iteration number: [180/393] 45% | Training loss: 0.6943538596232732
Epoch: 41 | Iteration number: [190/393] 48% | Training loss: 0.6941126472071597
Epoch: 41 | Iteration number: [200/393] 50% | Training loss: 0.693959292769432
Epoch: 41 | Iteration number: [210/393] 53% | Training loss: 0.6938128340811957
Epoch: 41 | Iteration number: [220/393] 55% | Training loss: 0.6936810604550622
Epoch: 41 | Iteration number: [230/393] 58% | Training loss: 0.693550548605297
Epoch: 41 | Iteration number: [240/393] 61% | Training loss: 0.6934278493126234
Epoch: 41 | Iteration number: [250/393] 63% | Training loss: 0.6933181750774383
Epoch: 41 | Iteration number: [260/393] 66% | Training loss: 0.6932295187161519
Epoch: 41 | Iteration number: [270/393] 68% | Training loss: 0.693160045809216
Epoch: 41 | Iteration number: [280/393] 71% | Training loss: 0.6930715441703796
Epoch: 41 | Iteration number: [290/393] 73% | Training loss: 0.6929924693600885
Epoch: 41 | Iteration number: [300/393] 76% | Training loss: 0.6928983829418818
Epoch: 41 | Iteration number: [310/393] 78% | Training loss: 0.692817650879583
Epoch: 41 | Iteration number: [320/393] 81% | Training loss: 0.6927641335874796
Epoch: 41 | Iteration number: [330/393] 83% | Training loss: 0.6926730544278116
Epoch: 41 | Iteration number: [340/393] 86% | Training loss: 0.692598113768241
Epoch: 41 | Iteration number: [350/393] 89% | Training loss: 0.6925108184133257
Epoch: 41 | Iteration number: [360/393] 91% | Training loss: 0.692442223098543
Epoch: 41 | Iteration number: [370/393] 94% | Training loss: 0.6923955675717947
Epoch: 41 | Iteration number: [380/393] 96% | Training loss: 0.6923625216672294
Epoch: 41 | Iteration number: [390/393] 99% | Training loss: 0.6923219155042599

 End of epoch: 41 | Train Loss: 0.6905485311233966 | Training Time: 67 

 End of epoch: 41 | Eval Loss: 0.6906448091779437 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/393] 2% | Training loss: 0.7591184318065644
Epoch: 42 | Iteration number: [20/393] 5% | Training loss: 0.724300816655159
Epoch: 42 | Iteration number: [30/393] 7% | Training loss: 0.7131075620651245
Epoch: 42 | Iteration number: [40/393] 10% | Training loss: 0.7074987187981605
Epoch: 42 | Iteration number: [50/393] 12% | Training loss: 0.7038341915607452
Epoch: 42 | Iteration number: [60/393] 15% | Training loss: 0.7015679736932119
Epoch: 42 | Iteration number: [70/393] 17% | Training loss: 0.6999321860926492
Epoch: 42 | Iteration number: [80/393] 20% | Training loss: 0.6988205373287201
Epoch: 42 | Iteration number: [90/393] 22% | Training loss: 0.6977984560860528
Epoch: 42 | Iteration number: [100/393] 25% | Training loss: 0.697039110660553
Epoch: 42 | Iteration number: [110/393] 27% | Training loss: 0.6965302451090379
Epoch: 42 | Iteration number: [120/393] 30% | Training loss: 0.6959891165296237
Epoch: 42 | Iteration number: [130/393] 33% | Training loss: 0.6954954028129577
Epoch: 42 | Iteration number: [140/393] 35% | Training loss: 0.6950672000646592
Epoch: 42 | Iteration number: [150/393] 38% | Training loss: 0.6947534410158793
Epoch: 42 | Iteration number: [160/393] 40% | Training loss: 0.6945115868002176
Epoch: 42 | Iteration number: [170/393] 43% | Training loss: 0.6943108951344209
Epoch: 42 | Iteration number: [180/393] 45% | Training loss: 0.6940041283766428
Epoch: 42 | Iteration number: [190/393] 48% | Training loss: 0.6938529560440465
Epoch: 42 | Iteration number: [200/393] 50% | Training loss: 0.6936903887987137
Epoch: 42 | Iteration number: [210/393] 53% | Training loss: 0.6935257366725377
Epoch: 42 | Iteration number: [220/393] 55% | Training loss: 0.6933970443227074
Epoch: 42 | Iteration number: [230/393] 58% | Training loss: 0.6933132257150567
Epoch: 42 | Iteration number: [240/393] 61% | Training loss: 0.6931991085410119
Epoch: 42 | Iteration number: [250/393] 63% | Training loss: 0.6931034917831421
Epoch: 42 | Iteration number: [260/393] 66% | Training loss: 0.6930254771159245
Epoch: 42 | Iteration number: [270/393] 68% | Training loss: 0.69292953742875
Epoch: 42 | Iteration number: [280/393] 71% | Training loss: 0.6928509588752474
Epoch: 42 | Iteration number: [290/393] 73% | Training loss: 0.6927435770117003
Epoch: 42 | Iteration number: [300/393] 76% | Training loss: 0.6927124263842901
Epoch: 42 | Iteration number: [310/393] 78% | Training loss: 0.6926534008595251
Epoch: 42 | Iteration number: [320/393] 81% | Training loss: 0.692627752199769
Epoch: 42 | Iteration number: [330/393] 83% | Training loss: 0.6925551074923891
Epoch: 42 | Iteration number: [340/393] 86% | Training loss: 0.6925051052780712
Epoch: 42 | Iteration number: [350/393] 89% | Training loss: 0.6924790293829781
Epoch: 42 | Iteration number: [360/393] 91% | Training loss: 0.6924348341094123
Epoch: 42 | Iteration number: [370/393] 94% | Training loss: 0.6924000646616961
Epoch: 42 | Iteration number: [380/393] 96% | Training loss: 0.6923649962011137
Epoch: 42 | Iteration number: [390/393] 99% | Training loss: 0.6923016416720855

 End of epoch: 42 | Train Loss: 0.6905198512793194 | Training Time: 67 

 End of epoch: 42 | Eval Loss: 0.6905895106646479 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/393] 2% | Training loss: 0.757946902513504
Epoch: 43 | Iteration number: [20/393] 5% | Training loss: 0.7242589563131332
Epoch: 43 | Iteration number: [30/393] 7% | Training loss: 0.7132432560125986
Epoch: 43 | Iteration number: [40/393] 10% | Training loss: 0.7077097311615944
Epoch: 43 | Iteration number: [50/393] 12% | Training loss: 0.7042086887359619
Epoch: 43 | Iteration number: [60/393] 15% | Training loss: 0.7017758389314016
Epoch: 43 | Iteration number: [70/393] 17% | Training loss: 0.7001908353396824
Epoch: 43 | Iteration number: [80/393] 20% | Training loss: 0.6991329319775105
Epoch: 43 | Iteration number: [90/393] 22% | Training loss: 0.6982245730029212
Epoch: 43 | Iteration number: [100/393] 25% | Training loss: 0.6974692988395691
Epoch: 43 | Iteration number: [110/393] 27% | Training loss: 0.696910665251992
Epoch: 43 | Iteration number: [120/393] 30% | Training loss: 0.6962602237860361
Epoch: 43 | Iteration number: [130/393] 33% | Training loss: 0.6957792268349574
Epoch: 43 | Iteration number: [140/393] 35% | Training loss: 0.6954757660627365
Epoch: 43 | Iteration number: [150/393] 38% | Training loss: 0.6951037132740021
Epoch: 43 | Iteration number: [160/393] 40% | Training loss: 0.6948293555527926
Epoch: 43 | Iteration number: [170/393] 43% | Training loss: 0.6945989535135382
Epoch: 43 | Iteration number: [180/393] 45% | Training loss: 0.6944135195679135
Epoch: 43 | Iteration number: [190/393] 48% | Training loss: 0.694222365868719
Epoch: 43 | Iteration number: [200/393] 50% | Training loss: 0.6940363520383834
Epoch: 43 | Iteration number: [210/393] 53% | Training loss: 0.6938523760863713
Epoch: 43 | Iteration number: [220/393] 55% | Training loss: 0.6937127042900432
Epoch: 43 | Iteration number: [230/393] 58% | Training loss: 0.6936017254124517
Epoch: 43 | Iteration number: [240/393] 61% | Training loss: 0.6934880388279756
Epoch: 43 | Iteration number: [250/393] 63% | Training loss: 0.6933192877769471
Epoch: 43 | Iteration number: [260/393] 66% | Training loss: 0.6931819998300992
Epoch: 43 | Iteration number: [270/393] 68% | Training loss: 0.6930903578246081
Epoch: 43 | Iteration number: [280/393] 71% | Training loss: 0.6929604687861034
Epoch: 43 | Iteration number: [290/393] 73% | Training loss: 0.6928647881951825
Epoch: 43 | Iteration number: [300/393] 76% | Training loss: 0.6927865169445674
Epoch: 43 | Iteration number: [310/393] 78% | Training loss: 0.692723379019768
Epoch: 43 | Iteration number: [320/393] 81% | Training loss: 0.6926489870995283
Epoch: 43 | Iteration number: [330/393] 83% | Training loss: 0.6925930308573174
Epoch: 43 | Iteration number: [340/393] 86% | Training loss: 0.6925605137558545
Epoch: 43 | Iteration number: [350/393] 89% | Training loss: 0.6924989724159241
Epoch: 43 | Iteration number: [360/393] 91% | Training loss: 0.6924223873350356
Epoch: 43 | Iteration number: [370/393] 94% | Training loss: 0.6923555652837495
Epoch: 43 | Iteration number: [380/393] 96% | Training loss: 0.6922797543437857
Epoch: 43 | Iteration number: [390/393] 99% | Training loss: 0.6922428312974098

 End of epoch: 43 | Train Loss: 0.690464039340274 | Training Time: 68 

 End of epoch: 43 | Eval Loss: 0.6905852848169755 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/393] 2% | Training loss: 0.7606806218624115
Epoch: 44 | Iteration number: [20/393] 5% | Training loss: 0.725801694393158
Epoch: 44 | Iteration number: [30/393] 7% | Training loss: 0.7138757189114888
Epoch: 44 | Iteration number: [40/393] 10% | Training loss: 0.7080736711621285
Epoch: 44 | Iteration number: [50/393] 12% | Training loss: 0.7045110881328582
Epoch: 44 | Iteration number: [60/393] 15% | Training loss: 0.7023078660170238
Epoch: 44 | Iteration number: [70/393] 17% | Training loss: 0.700519267150334
Epoch: 44 | Iteration number: [80/393] 20% | Training loss: 0.699355910718441
Epoch: 44 | Iteration number: [90/393] 22% | Training loss: 0.698349204328325
Epoch: 44 | Iteration number: [100/393] 25% | Training loss: 0.6975682079792023
Epoch: 44 | Iteration number: [110/393] 27% | Training loss: 0.696960003267635
Epoch: 44 | Iteration number: [120/393] 30% | Training loss: 0.6964357977112134
Epoch: 44 | Iteration number: [130/393] 33% | Training loss: 0.6960112122388986
Epoch: 44 | Iteration number: [140/393] 35% | Training loss: 0.6956086265189307
Epoch: 44 | Iteration number: [150/393] 38% | Training loss: 0.695256739060084
Epoch: 44 | Iteration number: [160/393] 40% | Training loss: 0.6949471350759268
Epoch: 44 | Iteration number: [170/393] 43% | Training loss: 0.6946226779152366
Epoch: 44 | Iteration number: [180/393] 45% | Training loss: 0.6943879067897797
Epoch: 44 | Iteration number: [190/393] 48% | Training loss: 0.6941888686857726
Epoch: 44 | Iteration number: [200/393] 50% | Training loss: 0.6939428582787514
Epoch: 44 | Iteration number: [210/393] 53% | Training loss: 0.6937425633271536
Epoch: 44 | Iteration number: [220/393] 55% | Training loss: 0.6935857171362096
Epoch: 44 | Iteration number: [230/393] 58% | Training loss: 0.6935046698736108
Epoch: 44 | Iteration number: [240/393] 61% | Training loss: 0.693391032765309
Epoch: 44 | Iteration number: [250/393] 63% | Training loss: 0.693256157875061
Epoch: 44 | Iteration number: [260/393] 66% | Training loss: 0.6931256963656499
Epoch: 44 | Iteration number: [270/393] 68% | Training loss: 0.6930552610644588
Epoch: 44 | Iteration number: [280/393] 71% | Training loss: 0.6929378222141948
Epoch: 44 | Iteration number: [290/393] 73% | Training loss: 0.6928899989045899
Epoch: 44 | Iteration number: [300/393] 76% | Training loss: 0.6928175562620162
Epoch: 44 | Iteration number: [310/393] 78% | Training loss: 0.6927160957167225
Epoch: 44 | Iteration number: [320/393] 81% | Training loss: 0.692634840682149
Epoch: 44 | Iteration number: [330/393] 83% | Training loss: 0.6925805931741541
Epoch: 44 | Iteration number: [340/393] 86% | Training loss: 0.6924936902873656
Epoch: 44 | Iteration number: [350/393] 89% | Training loss: 0.6924456703662872
Epoch: 44 | Iteration number: [360/393] 91% | Training loss: 0.6923918397890196
Epoch: 44 | Iteration number: [370/393] 94% | Training loss: 0.6923619623119767
Epoch: 44 | Iteration number: [380/393] 96% | Training loss: 0.6923125508584475
Epoch: 44 | Iteration number: [390/393] 99% | Training loss: 0.6922410290974838

 End of epoch: 44 | Train Loss: 0.6904563750626174 | Training Time: 68 

 End of epoch: 44 | Eval Loss: 0.6906272063449937 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/393] 2% | Training loss: 0.7603422582149506
Epoch: 45 | Iteration number: [20/393] 5% | Training loss: 0.7251777023077011
Epoch: 45 | Iteration number: [30/393] 7% | Training loss: 0.7136144856611888
Epoch: 45 | Iteration number: [40/393] 10% | Training loss: 0.7079225540161133
Epoch: 45 | Iteration number: [50/393] 12% | Training loss: 0.7043800508975983
Epoch: 45 | Iteration number: [60/393] 15% | Training loss: 0.7021357536315918
Epoch: 45 | Iteration number: [70/393] 17% | Training loss: 0.7005315440041678
Epoch: 45 | Iteration number: [80/393] 20% | Training loss: 0.6994340792298317
Epoch: 45 | Iteration number: [90/393] 22% | Training loss: 0.6984565562672085
Epoch: 45 | Iteration number: [100/393] 25% | Training loss: 0.6976037871837616
Epoch: 45 | Iteration number: [110/393] 27% | Training loss: 0.6968846532431516
Epoch: 45 | Iteration number: [120/393] 30% | Training loss: 0.6963016445438067
Epoch: 45 | Iteration number: [130/393] 33% | Training loss: 0.6958818440253918
Epoch: 45 | Iteration number: [140/393] 35% | Training loss: 0.6955261417797634
Epoch: 45 | Iteration number: [150/393] 38% | Training loss: 0.695192106962204
Epoch: 45 | Iteration number: [160/393] 40% | Training loss: 0.694930000603199
Epoch: 45 | Iteration number: [170/393] 43% | Training loss: 0.6946132439024308
Epoch: 45 | Iteration number: [180/393] 45% | Training loss: 0.694363264242808
Epoch: 45 | Iteration number: [190/393] 48% | Training loss: 0.6941052267425939
Epoch: 45 | Iteration number: [200/393] 50% | Training loss: 0.6938635832071305
Epoch: 45 | Iteration number: [210/393] 53% | Training loss: 0.6936415870984395
Epoch: 45 | Iteration number: [220/393] 55% | Training loss: 0.6934704875404184
Epoch: 45 | Iteration number: [230/393] 58% | Training loss: 0.6933452484400376
Epoch: 45 | Iteration number: [240/393] 61% | Training loss: 0.6932308867573738
Epoch: 45 | Iteration number: [250/393] 63% | Training loss: 0.6930900509357453
Epoch: 45 | Iteration number: [260/393] 66% | Training loss: 0.6929213938804774
Epoch: 45 | Iteration number: [270/393] 68% | Training loss: 0.6928424883771825
Epoch: 45 | Iteration number: [280/393] 71% | Training loss: 0.6927572986909322
Epoch: 45 | Iteration number: [290/393] 73% | Training loss: 0.6927148017390021
Epoch: 45 | Iteration number: [300/393] 76% | Training loss: 0.6926299319664637
Epoch: 45 | Iteration number: [310/393] 78% | Training loss: 0.6925814728583058
Epoch: 45 | Iteration number: [320/393] 81% | Training loss: 0.6925368154421448
Epoch: 45 | Iteration number: [330/393] 83% | Training loss: 0.6924871502500591
Epoch: 45 | Iteration number: [340/393] 86% | Training loss: 0.6924493628389695
Epoch: 45 | Iteration number: [350/393] 89% | Training loss: 0.6923719678606306
Epoch: 45 | Iteration number: [360/393] 91% | Training loss: 0.6923443069060643
Epoch: 45 | Iteration number: [370/393] 94% | Training loss: 0.6922955227864755
Epoch: 45 | Iteration number: [380/393] 96% | Training loss: 0.6922517346708398
Epoch: 45 | Iteration number: [390/393] 99% | Training loss: 0.6921939145296048

 End of epoch: 45 | Train Loss: 0.6904216748460862 | Training Time: 67 

 End of epoch: 45 | Eval Loss: 0.6906237638726527 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/393] 2% | Training loss: 0.7583466172218323
Epoch: 46 | Iteration number: [20/393] 5% | Training loss: 0.7239956855773926
Epoch: 46 | Iteration number: [30/393] 7% | Training loss: 0.7128659427165985
Epoch: 46 | Iteration number: [40/393] 10% | Training loss: 0.7076172605156898
Epoch: 46 | Iteration number: [50/393] 12% | Training loss: 0.7040945696830749
Epoch: 46 | Iteration number: [60/393] 15% | Training loss: 0.7018218119939168
Epoch: 46 | Iteration number: [70/393] 17% | Training loss: 0.6999905467033386
Epoch: 46 | Iteration number: [80/393] 20% | Training loss: 0.6987919420003891
Epoch: 46 | Iteration number: [90/393] 22% | Training loss: 0.697992820209927
Epoch: 46 | Iteration number: [100/393] 25% | Training loss: 0.6971718698740006
Epoch: 46 | Iteration number: [110/393] 27% | Training loss: 0.6965232090516524
Epoch: 46 | Iteration number: [120/393] 30% | Training loss: 0.6960550785064697
Epoch: 46 | Iteration number: [130/393] 33% | Training loss: 0.6955786998455341
Epoch: 46 | Iteration number: [140/393] 35% | Training loss: 0.6952514597347804
Epoch: 46 | Iteration number: [150/393] 38% | Training loss: 0.6948810537656148
Epoch: 46 | Iteration number: [160/393] 40% | Training loss: 0.6945766061544418
Epoch: 46 | Iteration number: [170/393] 43% | Training loss: 0.6943228679544785
Epoch: 46 | Iteration number: [180/393] 45% | Training loss: 0.6941075106461843
Epoch: 46 | Iteration number: [190/393] 48% | Training loss: 0.6939037821794811
Epoch: 46 | Iteration number: [200/393] 50% | Training loss: 0.6937708920240402
Epoch: 46 | Iteration number: [210/393] 53% | Training loss: 0.6936235419341497
Epoch: 46 | Iteration number: [220/393] 55% | Training loss: 0.6934911798347126
Epoch: 46 | Iteration number: [230/393] 58% | Training loss: 0.6933250352092412
Epoch: 46 | Iteration number: [240/393] 61% | Training loss: 0.6931590249141057
Epoch: 46 | Iteration number: [250/393] 63% | Training loss: 0.6930402085781098
Epoch: 46 | Iteration number: [260/393] 66% | Training loss: 0.6929621535998124
Epoch: 46 | Iteration number: [270/393] 68% | Training loss: 0.6928417236716659
Epoch: 46 | Iteration number: [280/393] 71% | Training loss: 0.6927982875279017
Epoch: 46 | Iteration number: [290/393] 73% | Training loss: 0.692649814383737
Epoch: 46 | Iteration number: [300/393] 76% | Training loss: 0.692608014345169
Epoch: 46 | Iteration number: [310/393] 78% | Training loss: 0.6924762412425011
Epoch: 46 | Iteration number: [320/393] 81% | Training loss: 0.6924266906455159
Epoch: 46 | Iteration number: [330/393] 83% | Training loss: 0.692353658062039
Epoch: 46 | Iteration number: [340/393] 86% | Training loss: 0.6922927703927545
Epoch: 46 | Iteration number: [350/393] 89% | Training loss: 0.6922465969835009
Epoch: 46 | Iteration number: [360/393] 91% | Training loss: 0.6922015910347302
Epoch: 46 | Iteration number: [370/393] 94% | Training loss: 0.6921674477087485
Epoch: 46 | Iteration number: [380/393] 96% | Training loss: 0.6921649424653304
Epoch: 46 | Iteration number: [390/393] 99% | Training loss: 0.6921403450843615

 End of epoch: 46 | Train Loss: 0.690380205028233 | Training Time: 68 

 End of epoch: 46 | Eval Loss: 0.690875201809163 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/393] 2% | Training loss: 0.7597469091415405
Epoch: 47 | Iteration number: [20/393] 5% | Training loss: 0.7248205512762069
Epoch: 47 | Iteration number: [30/393] 7% | Training loss: 0.713148973385493
Epoch: 47 | Iteration number: [40/393] 10% | Training loss: 0.7078074395656586
Epoch: 47 | Iteration number: [50/393] 12% | Training loss: 0.7045097613334655
Epoch: 47 | Iteration number: [60/393] 15% | Training loss: 0.7021415501832962
Epoch: 47 | Iteration number: [70/393] 17% | Training loss: 0.7004796888147081
Epoch: 47 | Iteration number: [80/393] 20% | Training loss: 0.6991039879620076
Epoch: 47 | Iteration number: [90/393] 22% | Training loss: 0.6981885969638825
Epoch: 47 | Iteration number: [100/393] 25% | Training loss: 0.6974103802442551
Epoch: 47 | Iteration number: [110/393] 27% | Training loss: 0.6967918032949622
Epoch: 47 | Iteration number: [120/393] 30% | Training loss: 0.6962769334514936
Epoch: 47 | Iteration number: [130/393] 33% | Training loss: 0.6957360258469215
Epoch: 47 | Iteration number: [140/393] 35% | Training loss: 0.6952200395720346
Epoch: 47 | Iteration number: [150/393] 38% | Training loss: 0.694886755545934
Epoch: 47 | Iteration number: [160/393] 40% | Training loss: 0.6945633523166179
Epoch: 47 | Iteration number: [170/393] 43% | Training loss: 0.6942134292686687
Epoch: 47 | Iteration number: [180/393] 45% | Training loss: 0.693955397605896
Epoch: 47 | Iteration number: [190/393] 48% | Training loss: 0.6937319783787979
Epoch: 47 | Iteration number: [200/393] 50% | Training loss: 0.6936238926649093
Epoch: 47 | Iteration number: [210/393] 53% | Training loss: 0.6934517125288645
Epoch: 47 | Iteration number: [220/393] 55% | Training loss: 0.6932906844399193
Epoch: 47 | Iteration number: [230/393] 58% | Training loss: 0.6931792077810868
Epoch: 47 | Iteration number: [240/393] 61% | Training loss: 0.6931221589446068
Epoch: 47 | Iteration number: [250/393] 63% | Training loss: 0.6930412335395812
Epoch: 47 | Iteration number: [260/393] 66% | Training loss: 0.6929572742718917
Epoch: 47 | Iteration number: [270/393] 68% | Training loss: 0.692881186803182
Epoch: 47 | Iteration number: [280/393] 71% | Training loss: 0.6928183540701867
Epoch: 47 | Iteration number: [290/393] 73% | Training loss: 0.692742090184113
Epoch: 47 | Iteration number: [300/393] 76% | Training loss: 0.6926827716827393
Epoch: 47 | Iteration number: [310/393] 78% | Training loss: 0.6926368013505013
Epoch: 47 | Iteration number: [320/393] 81% | Training loss: 0.692573674209416
Epoch: 47 | Iteration number: [330/393] 83% | Training loss: 0.6925138852813028
Epoch: 47 | Iteration number: [340/393] 86% | Training loss: 0.6924348010736353
Epoch: 47 | Iteration number: [350/393] 89% | Training loss: 0.6923860030514853
Epoch: 47 | Iteration number: [360/393] 91% | Training loss: 0.6923590113719305
Epoch: 47 | Iteration number: [370/393] 94% | Training loss: 0.6923218383982375
Epoch: 47 | Iteration number: [380/393] 96% | Training loss: 0.6922503612543407
Epoch: 47 | Iteration number: [390/393] 99% | Training loss: 0.6921805922801678

 End of epoch: 47 | Train Loss: 0.6904055059107812 | Training Time: 68 

 End of epoch: 47 | Eval Loss: 0.6905029756682259 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/393] 2% | Training loss: 0.7599357664585114
Epoch: 48 | Iteration number: [20/393] 5% | Training loss: 0.7252145737409592
Epoch: 48 | Iteration number: [30/393] 7% | Training loss: 0.7136720637480418
Epoch: 48 | Iteration number: [40/393] 10% | Training loss: 0.7078314408659935
Epoch: 48 | Iteration number: [50/393] 12% | Training loss: 0.7042820835113526
Epoch: 48 | Iteration number: [60/393] 15% | Training loss: 0.7019697159528733
Epoch: 48 | Iteration number: [70/393] 17% | Training loss: 0.7004392121519362
Epoch: 48 | Iteration number: [80/393] 20% | Training loss: 0.6990715958178043
Epoch: 48 | Iteration number: [90/393] 22% | Training loss: 0.6982735673586528
Epoch: 48 | Iteration number: [100/393] 25% | Training loss: 0.6974780964851379
Epoch: 48 | Iteration number: [110/393] 27% | Training loss: 0.6968456528403543
Epoch: 48 | Iteration number: [120/393] 30% | Training loss: 0.6962571978569031
Epoch: 48 | Iteration number: [130/393] 33% | Training loss: 0.6958222733094142
Epoch: 48 | Iteration number: [140/393] 35% | Training loss: 0.695462612594877
Epoch: 48 | Iteration number: [150/393] 38% | Training loss: 0.6951231586933136
Epoch: 48 | Iteration number: [160/393] 40% | Training loss: 0.694831957295537
Epoch: 48 | Iteration number: [170/393] 43% | Training loss: 0.6945587112623103
Epoch: 48 | Iteration number: [180/393] 45% | Training loss: 0.6943326390451855
Epoch: 48 | Iteration number: [190/393] 48% | Training loss: 0.6941124878431622
Epoch: 48 | Iteration number: [200/393] 50% | Training loss: 0.6939498019218445
Epoch: 48 | Iteration number: [210/393] 53% | Training loss: 0.6937760585830325
Epoch: 48 | Iteration number: [220/393] 55% | Training loss: 0.6936013042926789
Epoch: 48 | Iteration number: [230/393] 58% | Training loss: 0.6934521566266599
Epoch: 48 | Iteration number: [240/393] 61% | Training loss: 0.6933615336815516
Epoch: 48 | Iteration number: [250/393] 63% | Training loss: 0.6932370550632477
Epoch: 48 | Iteration number: [260/393] 66% | Training loss: 0.6931495171326857
Epoch: 48 | Iteration number: [270/393] 68% | Training loss: 0.6930760591118424
Epoch: 48 | Iteration number: [280/393] 71% | Training loss: 0.6929793932608196
Epoch: 48 | Iteration number: [290/393] 73% | Training loss: 0.6928285763181489
Epoch: 48 | Iteration number: [300/393] 76% | Training loss: 0.6926801164944967
Epoch: 48 | Iteration number: [310/393] 78% | Training loss: 0.6925939056181138
Epoch: 48 | Iteration number: [320/393] 81% | Training loss: 0.6925314212217927
Epoch: 48 | Iteration number: [330/393] 83% | Training loss: 0.6924232585863633
Epoch: 48 | Iteration number: [340/393] 86% | Training loss: 0.6923958005274043
Epoch: 48 | Iteration number: [350/393] 89% | Training loss: 0.6923205554485321
Epoch: 48 | Iteration number: [360/393] 91% | Training loss: 0.6922679952449269
Epoch: 48 | Iteration number: [370/393] 94% | Training loss: 0.6922250074309272
Epoch: 48 | Iteration number: [380/393] 96% | Training loss: 0.6921637648030331
Epoch: 48 | Iteration number: [390/393] 99% | Training loss: 0.6921143597517259

 End of epoch: 48 | Train Loss: 0.6903518658254589 | Training Time: 67 

 End of epoch: 48 | Eval Loss: 0.6904824753196872 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/393] 2% | Training loss: 0.7592311859130859
Epoch: 49 | Iteration number: [20/393] 5% | Training loss: 0.7243453651666641
Epoch: 49 | Iteration number: [30/393] 7% | Training loss: 0.7133644382158916
Epoch: 49 | Iteration number: [40/393] 10% | Training loss: 0.7077492117881775
Epoch: 49 | Iteration number: [50/393] 12% | Training loss: 0.7039965224266053
Epoch: 49 | Iteration number: [60/393] 15% | Training loss: 0.7016322553157807
Epoch: 49 | Iteration number: [70/393] 17% | Training loss: 0.700009070123945
Epoch: 49 | Iteration number: [80/393] 20% | Training loss: 0.6987560287117958
Epoch: 49 | Iteration number: [90/393] 22% | Training loss: 0.6978130353821649
Epoch: 49 | Iteration number: [100/393] 25% | Training loss: 0.6970507234334946
Epoch: 49 | Iteration number: [110/393] 27% | Training loss: 0.6963663523847407
Epoch: 49 | Iteration number: [120/393] 30% | Training loss: 0.6957737699151039
Epoch: 49 | Iteration number: [130/393] 33% | Training loss: 0.6953777203193078
Epoch: 49 | Iteration number: [140/393] 35% | Training loss: 0.6949425829308373
Epoch: 49 | Iteration number: [150/393] 38% | Training loss: 0.6946483592192332
Epoch: 49 | Iteration number: [160/393] 40% | Training loss: 0.694354198500514
Epoch: 49 | Iteration number: [170/393] 43% | Training loss: 0.6941238070235533
Epoch: 49 | Iteration number: [180/393] 45% | Training loss: 0.6939701080322266
Epoch: 49 | Iteration number: [190/393] 48% | Training loss: 0.6938208372969377
Epoch: 49 | Iteration number: [200/393] 50% | Training loss: 0.6936541149020194
Epoch: 49 | Iteration number: [210/393] 53% | Training loss: 0.6934601042951857
Epoch: 49 | Iteration number: [220/393] 55% | Training loss: 0.6932965993881226
Epoch: 49 | Iteration number: [230/393] 58% | Training loss: 0.6931974058565886
Epoch: 49 | Iteration number: [240/393] 61% | Training loss: 0.6930747173726559
Epoch: 49 | Iteration number: [250/393] 63% | Training loss: 0.6929880928993225
Epoch: 49 | Iteration number: [260/393] 66% | Training loss: 0.6929285597342711
Epoch: 49 | Iteration number: [270/393] 68% | Training loss: 0.6928656054867639
Epoch: 49 | Iteration number: [280/393] 71% | Training loss: 0.6927907347679139
Epoch: 49 | Iteration number: [290/393] 73% | Training loss: 0.6926980259089635
Epoch: 49 | Iteration number: [300/393] 76% | Training loss: 0.6926305917898814
Epoch: 49 | Iteration number: [310/393] 78% | Training loss: 0.692556437753862
Epoch: 49 | Iteration number: [320/393] 81% | Training loss: 0.6924462636932731
Epoch: 49 | Iteration number: [330/393] 83% | Training loss: 0.6924085024631385
Epoch: 49 | Iteration number: [340/393] 86% | Training loss: 0.6923659144078984
Epoch: 49 | Iteration number: [350/393] 89% | Training loss: 0.6923081069333212
Epoch: 49 | Iteration number: [360/393] 91% | Training loss: 0.6922304307421049
Epoch: 49 | Iteration number: [370/393] 94% | Training loss: 0.692191334350689
Epoch: 49 | Iteration number: [380/393] 96% | Training loss: 0.6921220471984462
Epoch: 49 | Iteration number: [390/393] 99% | Training loss: 0.6920898332045629

 End of epoch: 49 | Train Loss: 0.6903256444833964 | Training Time: 68 

 End of epoch: 49 | Eval Loss: 0.6906005557702513 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/393] 2% | Training loss: 0.7591351747512818
Epoch: 50 | Iteration number: [20/393] 5% | Training loss: 0.724689069390297
Epoch: 50 | Iteration number: [30/393] 7% | Training loss: 0.7128617743651072
Epoch: 50 | Iteration number: [40/393] 10% | Training loss: 0.7073908731341362
Epoch: 50 | Iteration number: [50/393] 12% | Training loss: 0.7041285705566406
Epoch: 50 | Iteration number: [60/393] 15% | Training loss: 0.7018946607907613
Epoch: 50 | Iteration number: [70/393] 17% | Training loss: 0.7003589783396039
Epoch: 50 | Iteration number: [80/393] 20% | Training loss: 0.699239407479763
Epoch: 50 | Iteration number: [90/393] 22% | Training loss: 0.6981345289283328
Epoch: 50 | Iteration number: [100/393] 25% | Training loss: 0.6973645740747452
Epoch: 50 | Iteration number: [110/393] 27% | Training loss: 0.6967918878251856
Epoch: 50 | Iteration number: [120/393] 30% | Training loss: 0.6962420652310054
Epoch: 50 | Iteration number: [130/393] 33% | Training loss: 0.6958608196331905
Epoch: 50 | Iteration number: [140/393] 35% | Training loss: 0.6955302229949406
Epoch: 50 | Iteration number: [150/393] 38% | Training loss: 0.6952205963929494
Epoch: 50 | Iteration number: [160/393] 40% | Training loss: 0.6948822744190692
Epoch: 50 | Iteration number: [170/393] 43% | Training loss: 0.6945570072707008
Epoch: 50 | Iteration number: [180/393] 45% | Training loss: 0.6943052553468281
Epoch: 50 | Iteration number: [190/393] 48% | Training loss: 0.6940726738227041
Epoch: 50 | Iteration number: [200/393] 50% | Training loss: 0.6938860136270523
Epoch: 50 | Iteration number: [210/393] 53% | Training loss: 0.6937923578988938
Epoch: 50 | Iteration number: [220/393] 55% | Training loss: 0.6936111070893027
Epoch: 50 | Iteration number: [230/393] 58% | Training loss: 0.6934635773949002
Epoch: 50 | Iteration number: [240/393] 61% | Training loss: 0.6933118087550004
Epoch: 50 | Iteration number: [250/393] 63% | Training loss: 0.693218195438385
Epoch: 50 | Iteration number: [260/393] 66% | Training loss: 0.6931117500250156
Epoch: 50 | Iteration number: [270/393] 68% | Training loss: 0.6930451430656291
Epoch: 50 | Iteration number: [280/393] 71% | Training loss: 0.6929469957947731
Epoch: 50 | Iteration number: [290/393] 73% | Training loss: 0.6928397227977884
Epoch: 50 | Iteration number: [300/393] 76% | Training loss: 0.6927554655075073
Epoch: 50 | Iteration number: [310/393] 78% | Training loss: 0.692689101926742
Epoch: 50 | Iteration number: [320/393] 81% | Training loss: 0.6926055377349257
Epoch: 50 | Iteration number: [330/393] 83% | Training loss: 0.6925287508603298
Epoch: 50 | Iteration number: [340/393] 86% | Training loss: 0.6924738529850455
Epoch: 50 | Iteration number: [350/393] 89% | Training loss: 0.6924006417819432
Epoch: 50 | Iteration number: [360/393] 91% | Training loss: 0.6923670704166095
Epoch: 50 | Iteration number: [370/393] 94% | Training loss: 0.6923326597020433
Epoch: 50 | Iteration number: [380/393] 96% | Training loss: 0.6922820864539397
Epoch: 50 | Iteration number: [390/393] 99% | Training loss: 0.6922012333686535

 End of epoch: 50 | Train Loss: 0.6904292522192608 | Training Time: 67 

 End of epoch: 50 | Eval Loss: 0.6906143025476106 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/393] 2% | Training loss: 0.759550952911377
Epoch: 51 | Iteration number: [20/393] 5% | Training loss: 0.7248838305473327
Epoch: 51 | Iteration number: [30/393] 7% | Training loss: 0.7135076800982157
Epoch: 51 | Iteration number: [40/393] 10% | Training loss: 0.707255308330059
Epoch: 51 | Iteration number: [50/393] 12% | Training loss: 0.7038903093338013
Epoch: 51 | Iteration number: [60/393] 15% | Training loss: 0.7015631566445033
Epoch: 51 | Iteration number: [70/393] 17% | Training loss: 0.6999876712049756
Epoch: 51 | Iteration number: [80/393] 20% | Training loss: 0.6987971171736718
Epoch: 51 | Iteration number: [90/393] 22% | Training loss: 0.6979239298237695
Epoch: 51 | Iteration number: [100/393] 25% | Training loss: 0.6971937733888626
Epoch: 51 | Iteration number: [110/393] 27% | Training loss: 0.6966026913036
Epoch: 51 | Iteration number: [120/393] 30% | Training loss: 0.6960891703764598
Epoch: 51 | Iteration number: [130/393] 33% | Training loss: 0.6957061052322387
Epoch: 51 | Iteration number: [140/393] 35% | Training loss: 0.6954076409339904
Epoch: 51 | Iteration number: [150/393] 38% | Training loss: 0.6951539146900177
Epoch: 51 | Iteration number: [160/393] 40% | Training loss: 0.6948853489011526
Epoch: 51 | Iteration number: [170/393] 43% | Training loss: 0.6945805398856892
Epoch: 51 | Iteration number: [180/393] 45% | Training loss: 0.6943874773052003
Epoch: 51 | Iteration number: [190/393] 48% | Training loss: 0.6941334627176586
Epoch: 51 | Iteration number: [200/393] 50% | Training loss: 0.6939093580842018
Epoch: 51 | Iteration number: [210/393] 53% | Training loss: 0.6937617548874446
Epoch: 51 | Iteration number: [220/393] 55% | Training loss: 0.6935780668800527
Epoch: 51 | Iteration number: [230/393] 58% | Training loss: 0.6934469870899035
Epoch: 51 | Iteration number: [240/393] 61% | Training loss: 0.6933151930570602
Epoch: 51 | Iteration number: [250/393] 63% | Training loss: 0.6931717717647552
Epoch: 51 | Iteration number: [260/393] 66% | Training loss: 0.6930671515373084
Epoch: 51 | Iteration number: [270/393] 68% | Training loss: 0.6929629226525624
Epoch: 51 | Iteration number: [280/393] 71% | Training loss: 0.6928433341639383
Epoch: 51 | Iteration number: [290/393] 73% | Training loss: 0.6927543229070203
Epoch: 51 | Iteration number: [300/393] 76% | Training loss: 0.6926627282301585
Epoch: 51 | Iteration number: [310/393] 78% | Training loss: 0.6925750478621452
Epoch: 51 | Iteration number: [320/393] 81% | Training loss: 0.6925386674702168
Epoch: 51 | Iteration number: [330/393] 83% | Training loss: 0.6924585223197937
Epoch: 51 | Iteration number: [340/393] 86% | Training loss: 0.6923809517832363
Epoch: 51 | Iteration number: [350/393] 89% | Training loss: 0.6923490381240844
Epoch: 51 | Iteration number: [360/393] 91% | Training loss: 0.6923134138186773
Epoch: 51 | Iteration number: [370/393] 94% | Training loss: 0.6922491987009306
Epoch: 51 | Iteration number: [380/393] 96% | Training loss: 0.6921978417195772
Epoch: 51 | Iteration number: [390/393] 99% | Training loss: 0.6921252009196159

 End of epoch: 51 | Train Loss: 0.6903485504118844 | Training Time: 68 

 End of epoch: 51 | Eval Loss: 0.6906117334657785 | Evaluating Time: 17 
Epoch: 52 | Iteration number: [10/393] 2% | Training loss: 0.7600358605384827
Epoch: 52 | Iteration number: [20/393] 5% | Training loss: 0.7249350249767303
Epoch: 52 | Iteration number: [30/393] 7% | Training loss: 0.7132631182670593
Epoch: 52 | Iteration number: [40/393] 10% | Training loss: 0.7073853522539139
Epoch: 52 | Iteration number: [50/393] 12% | Training loss: 0.7041597795486451
Epoch: 52 | Iteration number: [60/393] 15% | Training loss: 0.7017246097326278
Epoch: 52 | Iteration number: [70/393] 17% | Training loss: 0.7000806467873709
Epoch: 52 | Iteration number: [80/393] 20% | Training loss: 0.6988946169614791
Epoch: 52 | Iteration number: [90/393] 22% | Training loss: 0.6979676895671421
Epoch: 52 | Iteration number: [100/393] 25% | Training loss: 0.6970755273103714
Epoch: 52 | Iteration number: [110/393] 27% | Training loss: 0.6964783598076213
Epoch: 52 | Iteration number: [120/393] 30% | Training loss: 0.6959720795353254
Epoch: 52 | Iteration number: [130/393] 33% | Training loss: 0.6955591027553265
Epoch: 52 | Iteration number: [140/393] 35% | Training loss: 0.6951972629342761
Epoch: 52 | Iteration number: [150/393] 38% | Training loss: 0.6948849670092265
Epoch: 52 | Iteration number: [160/393] 40% | Training loss: 0.6946236960589885
Epoch: 52 | Iteration number: [170/393] 43% | Training loss: 0.694378213672077
Epoch: 52 | Iteration number: [180/393] 45% | Training loss: 0.694125410914421
Epoch: 52 | Iteration number: [190/393] 48% | Training loss: 0.6938863873481751
Epoch: 52 | Iteration number: [200/393] 50% | Training loss: 0.6937028130888939
Epoch: 52 | Iteration number: [210/393] 53% | Training loss: 0.6935318924131848
Epoch: 52 | Iteration number: [220/393] 55% | Training loss: 0.6933409135450016
Epoch: 52 | Iteration number: [230/393] 58% | Training loss: 0.6932124041992686
Epoch: 52 | Iteration number: [240/393] 61% | Training loss: 0.6931490321954091
Epoch: 52 | Iteration number: [250/393] 63% | Training loss: 0.6930072531700134
Epoch: 52 | Iteration number: [260/393] 66% | Training loss: 0.6929237317580443
Epoch: 52 | Iteration number: [270/393] 68% | Training loss: 0.6928579597561447
Epoch: 52 | Iteration number: [280/393] 71% | Training loss: 0.6928062543272973
Epoch: 52 | Iteration number: [290/393] 73% | Training loss: 0.6927034147854509
Epoch: 52 | Iteration number: [300/393] 76% | Training loss: 0.6926654676596323
Epoch: 52 | Iteration number: [310/393] 78% | Training loss: 0.6926078796386719
Epoch: 52 | Iteration number: [320/393] 81% | Training loss: 0.6925353901460767
Epoch: 52 | Iteration number: [330/393] 83% | Training loss: 0.69243317156127
Epoch: 52 | Iteration number: [340/393] 86% | Training loss: 0.6923818681169959
Epoch: 52 | Iteration number: [350/393] 89% | Training loss: 0.6923381839479719
Epoch: 52 | Iteration number: [360/393] 91% | Training loss: 0.6922991891702016
Epoch: 52 | Iteration number: [370/393] 94% | Training loss: 0.692210195032326
Epoch: 52 | Iteration number: [380/393] 96% | Training loss: 0.6921938221705587
Epoch: 52 | Iteration number: [390/393] 99% | Training loss: 0.6921355802279252

 End of epoch: 52 | Train Loss: 0.690370364498546 | Training Time: 68 

 End of epoch: 52 | Eval Loss: 0.6906259838415651 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/393] 2% | Training loss: 0.7605517506599426
Epoch: 53 | Iteration number: [20/393] 5% | Training loss: 0.7250428140163422
Epoch: 53 | Iteration number: [30/393] 7% | Training loss: 0.7134204626083374
Epoch: 53 | Iteration number: [40/393] 10% | Training loss: 0.7077544748783111
Epoch: 53 | Iteration number: [50/393] 12% | Training loss: 0.7043446552753448
Epoch: 53 | Iteration number: [60/393] 15% | Training loss: 0.7019100467363993
Epoch: 53 | Iteration number: [70/393] 17% | Training loss: 0.7002923207623618
Epoch: 53 | Iteration number: [80/393] 20% | Training loss: 0.6990117222070694
Epoch: 53 | Iteration number: [90/393] 22% | Training loss: 0.6980140440993838
Epoch: 53 | Iteration number: [100/393] 25% | Training loss: 0.6971873939037323
Epoch: 53 | Iteration number: [110/393] 27% | Training loss: 0.6965037270025773
Epoch: 53 | Iteration number: [120/393] 30% | Training loss: 0.695928581058979
Epoch: 53 | Iteration number: [130/393] 33% | Training loss: 0.6955604621997247
Epoch: 53 | Iteration number: [140/393] 35% | Training loss: 0.6951177086148943
Epoch: 53 | Iteration number: [150/393] 38% | Training loss: 0.6947651274998983
Epoch: 53 | Iteration number: [160/393] 40% | Training loss: 0.694477415829897
Epoch: 53 | Iteration number: [170/393] 43% | Training loss: 0.6942636430263519
Epoch: 53 | Iteration number: [180/393] 45% | Training loss: 0.6940896471341451
Epoch: 53 | Iteration number: [190/393] 48% | Training loss: 0.6938747045240904
Epoch: 53 | Iteration number: [200/393] 50% | Training loss: 0.6937133538722992
Epoch: 53 | Iteration number: [210/393] 53% | Training loss: 0.6935247560342153
Epoch: 53 | Iteration number: [220/393] 55% | Training loss: 0.6934030733325265
Epoch: 53 | Iteration number: [230/393] 58% | Training loss: 0.6933192452658777
Epoch: 53 | Iteration number: [240/393] 61% | Training loss: 0.6931826534370581
Epoch: 53 | Iteration number: [250/393] 63% | Training loss: 0.6930727150440216
Epoch: 53 | Iteration number: [260/393] 66% | Training loss: 0.6930310446482438
Epoch: 53 | Iteration number: [270/393] 68% | Training loss: 0.6929466923077902
Epoch: 53 | Iteration number: [280/393] 71% | Training loss: 0.6928821527532169
Epoch: 53 | Iteration number: [290/393] 73% | Training loss: 0.6928101800639054
Epoch: 53 | Iteration number: [300/393] 76% | Training loss: 0.6927299102147421
Epoch: 53 | Iteration number: [310/393] 78% | Training loss: 0.6926961631544175
Epoch: 53 | Iteration number: [320/393] 81% | Training loss: 0.6926270622760058
Epoch: 53 | Iteration number: [330/393] 83% | Training loss: 0.6925520140113253
Epoch: 53 | Iteration number: [340/393] 86% | Training loss: 0.6924635923960629
Epoch: 53 | Iteration number: [350/393] 89% | Training loss: 0.692386224440166
Epoch: 53 | Iteration number: [360/393] 91% | Training loss: 0.6922942443026436
Epoch: 53 | Iteration number: [370/393] 94% | Training loss: 0.6922203793719008
Epoch: 53 | Iteration number: [380/393] 96% | Training loss: 0.6921589286703812
Epoch: 53 | Iteration number: [390/393] 99% | Training loss: 0.6921027570198743

 End of epoch: 53 | Train Loss: 0.6903272723120284 | Training Time: 68 

 End of epoch: 53 | Eval Loss: 0.6904212431031831 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/393] 2% | Training loss: 0.7576959013938904
Epoch: 54 | Iteration number: [20/393] 5% | Training loss: 0.7237440466880798
Epoch: 54 | Iteration number: [30/393] 7% | Training loss: 0.7125451485315959
Epoch: 54 | Iteration number: [40/393] 10% | Training loss: 0.7069483086466789
Epoch: 54 | Iteration number: [50/393] 12% | Training loss: 0.7038185322284698
Epoch: 54 | Iteration number: [60/393] 15% | Training loss: 0.701457338531812
Epoch: 54 | Iteration number: [70/393] 17% | Training loss: 0.6996392335210527
Epoch: 54 | Iteration number: [80/393] 20% | Training loss: 0.698408518731594
Epoch: 54 | Iteration number: [90/393] 22% | Training loss: 0.6974480595853594
Epoch: 54 | Iteration number: [100/393] 25% | Training loss: 0.6967250657081604
Epoch: 54 | Iteration number: [110/393] 27% | Training loss: 0.6961458737199957
Epoch: 54 | Iteration number: [120/393] 30% | Training loss: 0.6957511593898137
Epoch: 54 | Iteration number: [130/393] 33% | Training loss: 0.695378392476302
Epoch: 54 | Iteration number: [140/393] 35% | Training loss: 0.6950644505875451
Epoch: 54 | Iteration number: [150/393] 38% | Training loss: 0.6947154458363851
Epoch: 54 | Iteration number: [160/393] 40% | Training loss: 0.694493505731225
Epoch: 54 | Iteration number: [170/393] 43% | Training loss: 0.6942164396538454
Epoch: 54 | Iteration number: [180/393] 45% | Training loss: 0.693975939353307
Epoch: 54 | Iteration number: [190/393] 48% | Training loss: 0.6938264216247357
Epoch: 54 | Iteration number: [200/393] 50% | Training loss: 0.6936534413695336
Epoch: 54 | Iteration number: [210/393] 53% | Training loss: 0.6934471365951357
Epoch: 54 | Iteration number: [220/393] 55% | Training loss: 0.6933198722926053
Epoch: 54 | Iteration number: [230/393] 58% | Training loss: 0.6932061993557473
Epoch: 54 | Iteration number: [240/393] 61% | Training loss: 0.6931216853360335
Epoch: 54 | Iteration number: [250/393] 63% | Training loss: 0.6929513523578644
Epoch: 54 | Iteration number: [260/393] 66% | Training loss: 0.6929042522723858
Epoch: 54 | Iteration number: [270/393] 68% | Training loss: 0.6928168716254057
Epoch: 54 | Iteration number: [280/393] 71% | Training loss: 0.6927232550723212
Epoch: 54 | Iteration number: [290/393] 73% | Training loss: 0.6926548931105384
Epoch: 54 | Iteration number: [300/393] 76% | Training loss: 0.6925676536560058
Epoch: 54 | Iteration number: [310/393] 78% | Training loss: 0.6924833063156374
Epoch: 54 | Iteration number: [320/393] 81% | Training loss: 0.6924382543191314
Epoch: 54 | Iteration number: [330/393] 83% | Training loss: 0.692348309357961
Epoch: 54 | Iteration number: [340/393] 86% | Training loss: 0.6922960482976016
Epoch: 54 | Iteration number: [350/393] 89% | Training loss: 0.692252232006618
Epoch: 54 | Iteration number: [360/393] 91% | Training loss: 0.6921724360850122
Epoch: 54 | Iteration number: [370/393] 94% | Training loss: 0.6921380249229637
Epoch: 54 | Iteration number: [380/393] 96% | Training loss: 0.692096746438428
Epoch: 54 | Iteration number: [390/393] 99% | Training loss: 0.692069410207944

 End of epoch: 54 | Train Loss: 0.6902990787083866 | Training Time: 67 

 End of epoch: 54 | Eval Loss: 0.6903707105286268 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/393] 2% | Training loss: 0.7600029230117797
Epoch: 55 | Iteration number: [20/393] 5% | Training loss: 0.7252934247255325
Epoch: 55 | Iteration number: [30/393] 7% | Training loss: 0.7136570155620575
Epoch: 55 | Iteration number: [40/393] 10% | Training loss: 0.7079035609960556
Epoch: 55 | Iteration number: [50/393] 12% | Training loss: 0.7041583752632141
Epoch: 55 | Iteration number: [60/393] 15% | Training loss: 0.7018166700998942
Epoch: 55 | Iteration number: [70/393] 17% | Training loss: 0.7001909196376801
Epoch: 55 | Iteration number: [80/393] 20% | Training loss: 0.6990570522844791
Epoch: 55 | Iteration number: [90/393] 22% | Training loss: 0.698193426264657
Epoch: 55 | Iteration number: [100/393] 25% | Training loss: 0.6973223912715912
Epoch: 55 | Iteration number: [110/393] 27% | Training loss: 0.696701810576699
Epoch: 55 | Iteration number: [120/393] 30% | Training loss: 0.6961857512593269
Epoch: 55 | Iteration number: [130/393] 33% | Training loss: 0.6957716607130491
Epoch: 55 | Iteration number: [140/393] 35% | Training loss: 0.6953250029257365
Epoch: 55 | Iteration number: [150/393] 38% | Training loss: 0.6949855971336365
Epoch: 55 | Iteration number: [160/393] 40% | Training loss: 0.6946904551237821
Epoch: 55 | Iteration number: [170/393] 43% | Training loss: 0.6944194544764126
Epoch: 55 | Iteration number: [180/393] 45% | Training loss: 0.6941508995162116
Epoch: 55 | Iteration number: [190/393] 48% | Training loss: 0.6940314054489136
Epoch: 55 | Iteration number: [200/393] 50% | Training loss: 0.6938817390799522
Epoch: 55 | Iteration number: [210/393] 53% | Training loss: 0.6936670924936023
Epoch: 55 | Iteration number: [220/393] 55% | Training loss: 0.6935160959308798
Epoch: 55 | Iteration number: [230/393] 58% | Training loss: 0.6934016362480495
Epoch: 55 | Iteration number: [240/393] 61% | Training loss: 0.6932904059688251
Epoch: 55 | Iteration number: [250/393] 63% | Training loss: 0.6931756384372711
Epoch: 55 | Iteration number: [260/393] 66% | Training loss: 0.6930505369718258
Epoch: 55 | Iteration number: [270/393] 68% | Training loss: 0.6929495787179029
Epoch: 55 | Iteration number: [280/393] 71% | Training loss: 0.692794985643455
Epoch: 55 | Iteration number: [290/393] 73% | Training loss: 0.6927012755953033
Epoch: 55 | Iteration number: [300/393] 76% | Training loss: 0.6926144715150198
Epoch: 55 | Iteration number: [310/393] 78% | Training loss: 0.6925092591393378
Epoch: 55 | Iteration number: [320/393] 81% | Training loss: 0.6924105901271105
Epoch: 55 | Iteration number: [330/393] 83% | Training loss: 0.692306129137675
Epoch: 55 | Iteration number: [340/393] 86% | Training loss: 0.6922307435204001
Epoch: 55 | Iteration number: [350/393] 89% | Training loss: 0.6921868707452502
Epoch: 55 | Iteration number: [360/393] 91% | Training loss: 0.6921458491020732
Epoch: 55 | Iteration number: [370/393] 94% | Training loss: 0.692098187755894
Epoch: 55 | Iteration number: [380/393] 96% | Training loss: 0.6920584680218446
Epoch: 55 | Iteration number: [390/393] 99% | Training loss: 0.6920379945865044

 End of epoch: 55 | Train Loss: 0.6902711022901171 | Training Time: 67 

 End of epoch: 55 | Eval Loss: 0.6904262657068214 | Evaluating Time: 17 
Epoch: 56 | Iteration number: [10/393] 2% | Training loss: 0.7594561874866486
Epoch: 56 | Iteration number: [20/393] 5% | Training loss: 0.7242743879556656
Epoch: 56 | Iteration number: [30/393] 7% | Training loss: 0.7130599617958069
Epoch: 56 | Iteration number: [40/393] 10% | Training loss: 0.7072319552302361
Epoch: 56 | Iteration number: [50/393] 12% | Training loss: 0.7038443636894226
Epoch: 56 | Iteration number: [60/393] 15% | Training loss: 0.7015044033527374
Epoch: 56 | Iteration number: [70/393] 17% | Training loss: 0.6999187563146864
Epoch: 56 | Iteration number: [80/393] 20% | Training loss: 0.6987291023135185
Epoch: 56 | Iteration number: [90/393] 22% | Training loss: 0.6976912948820326
Epoch: 56 | Iteration number: [100/393] 25% | Training loss: 0.6970810514688491
Epoch: 56 | Iteration number: [110/393] 27% | Training loss: 0.6965127711946314
Epoch: 56 | Iteration number: [120/393] 30% | Training loss: 0.6960751344760259
Epoch: 56 | Iteration number: [130/393] 33% | Training loss: 0.6955760006721203
Epoch: 56 | Iteration number: [140/393] 35% | Training loss: 0.695189848116466
Epoch: 56 | Iteration number: [150/393] 38% | Training loss: 0.6948624273141225
Epoch: 56 | Iteration number: [160/393] 40% | Training loss: 0.6945711456239223
Epoch: 56 | Iteration number: [170/393] 43% | Training loss: 0.6943133108756121
Epoch: 56 | Iteration number: [180/393] 45% | Training loss: 0.6941247277789646
Epoch: 56 | Iteration number: [190/393] 48% | Training loss: 0.693931540062553
Epoch: 56 | Iteration number: [200/393] 50% | Training loss: 0.6937931993603706
Epoch: 56 | Iteration number: [210/393] 53% | Training loss: 0.6935961953231267
Epoch: 56 | Iteration number: [220/393] 55% | Training loss: 0.6934504644437269
Epoch: 56 | Iteration number: [230/393] 58% | Training loss: 0.693349347943845
Epoch: 56 | Iteration number: [240/393] 61% | Training loss: 0.6932369905213515
Epoch: 56 | Iteration number: [250/393] 63% | Training loss: 0.6931115648746491
Epoch: 56 | Iteration number: [260/393] 66% | Training loss: 0.6930301308631897
Epoch: 56 | Iteration number: [270/393] 68% | Training loss: 0.692930073649795
Epoch: 56 | Iteration number: [280/393] 71% | Training loss: 0.6928465089627674
Epoch: 56 | Iteration number: [290/393] 73% | Training loss: 0.6927721518894722
Epoch: 56 | Iteration number: [300/393] 76% | Training loss: 0.6926631001631419
Epoch: 56 | Iteration number: [310/393] 78% | Training loss: 0.6925827199412931
Epoch: 56 | Iteration number: [320/393] 81% | Training loss: 0.6925009747967124
Epoch: 56 | Iteration number: [330/393] 83% | Training loss: 0.6924311390428832
Epoch: 56 | Iteration number: [340/393] 86% | Training loss: 0.6923804549609913
Epoch: 56 | Iteration number: [350/393] 89% | Training loss: 0.692324937411717
Epoch: 56 | Iteration number: [360/393] 91% | Training loss: 0.6922760551174482
Epoch: 56 | Iteration number: [370/393] 94% | Training loss: 0.6922214733587729
Epoch: 56 | Iteration number: [380/393] 96% | Training loss: 0.6921669323193399
Epoch: 56 | Iteration number: [390/393] 99% | Training loss: 0.6920937683337774

 End of epoch: 56 | Train Loss: 0.690317372632694 | Training Time: 67 

 End of epoch: 56 | Eval Loss: 0.6908112350775271 | Evaluating Time: 17 
Epoch: 57 | Iteration number: [10/393] 2% | Training loss: 0.7587444245815277
Epoch: 57 | Iteration number: [20/393] 5% | Training loss: 0.7248690307140351
Epoch: 57 | Iteration number: [30/393] 7% | Training loss: 0.7133794744809469
Epoch: 57 | Iteration number: [40/393] 10% | Training loss: 0.7076042279601097
Epoch: 57 | Iteration number: [50/393] 12% | Training loss: 0.7042446398735046
Epoch: 57 | Iteration number: [60/393] 15% | Training loss: 0.7018390784660975
Epoch: 57 | Iteration number: [70/393] 17% | Training loss: 0.7000438383647374
Epoch: 57 | Iteration number: [80/393] 20% | Training loss: 0.6988748863339425
Epoch: 57 | Iteration number: [90/393] 22% | Training loss: 0.6979344997141096
Epoch: 57 | Iteration number: [100/393] 25% | Training loss: 0.6971579319238663
Epoch: 57 | Iteration number: [110/393] 27% | Training loss: 0.6964838846163316
Epoch: 57 | Iteration number: [120/393] 30% | Training loss: 0.6959613288442293
Epoch: 57 | Iteration number: [130/393] 33% | Training loss: 0.695467477119886
Epoch: 57 | Iteration number: [140/393] 35% | Training loss: 0.6951745101383754
Epoch: 57 | Iteration number: [150/393] 38% | Training loss: 0.694874685605367
Epoch: 57 | Iteration number: [160/393] 40% | Training loss: 0.694552994146943
Epoch: 57 | Iteration number: [170/393] 43% | Training loss: 0.6942632706726298
Epoch: 57 | Iteration number: [180/393] 45% | Training loss: 0.6940691947937012
Epoch: 57 | Iteration number: [190/393] 48% | Training loss: 0.6939119404868076
Epoch: 57 | Iteration number: [200/393] 50% | Training loss: 0.6936724361777306
Epoch: 57 | Iteration number: [210/393] 53% | Training loss: 0.6935701937902541
Epoch: 57 | Iteration number: [220/393] 55% | Training loss: 0.6933933520858938
Epoch: 57 | Iteration number: [230/393] 58% | Training loss: 0.6932518396688544
Epoch: 57 | Iteration number: [240/393] 61% | Training loss: 0.6931317528088887
Epoch: 57 | Iteration number: [250/393] 63% | Training loss: 0.6930238661766053
Epoch: 57 | Iteration number: [260/393] 66% | Training loss: 0.6929107083724095
Epoch: 57 | Iteration number: [270/393] 68% | Training loss: 0.6928451365894741
Epoch: 57 | Iteration number: [280/393] 71% | Training loss: 0.6927761422736304
Epoch: 57 | Iteration number: [290/393] 73% | Training loss: 0.6927066839974502
Epoch: 57 | Iteration number: [300/393] 76% | Training loss: 0.6926364572842916
Epoch: 57 | Iteration number: [310/393] 78% | Training loss: 0.6925406592507516
Epoch: 57 | Iteration number: [320/393] 81% | Training loss: 0.6924563840031623
Epoch: 57 | Iteration number: [330/393] 83% | Training loss: 0.6923617261828798
Epoch: 57 | Iteration number: [340/393] 86% | Training loss: 0.6922884464263916
Epoch: 57 | Iteration number: [350/393] 89% | Training loss: 0.6922365450859069
Epoch: 57 | Iteration number: [360/393] 91% | Training loss: 0.6921994128161006
Epoch: 57 | Iteration number: [370/393] 94% | Training loss: 0.6921504744001337
Epoch: 57 | Iteration number: [380/393] 96% | Training loss: 0.6920873172973332
Epoch: 57 | Iteration number: [390/393] 99% | Training loss: 0.6920228459896185

 End of epoch: 57 | Train Loss: 0.6902562493586358 | Training Time: 67 

 End of epoch: 57 | Eval Loss: 0.6904149955632736 | Evaluating Time: 17 
Epoch: 58 | Iteration number: [10/393] 2% | Training loss: 0.7589968621730805
Epoch: 58 | Iteration number: [20/393] 5% | Training loss: 0.7240946054458618
Epoch: 58 | Iteration number: [30/393] 7% | Training loss: 0.7128353555997212
Epoch: 58 | Iteration number: [40/393] 10% | Training loss: 0.7072650223970414
Epoch: 58 | Iteration number: [50/393] 12% | Training loss: 0.7041139781475068
Epoch: 58 | Iteration number: [60/393] 15% | Training loss: 0.70185766518116
Epoch: 58 | Iteration number: [70/393] 17% | Training loss: 0.700165889944349
Epoch: 58 | Iteration number: [80/393] 20% | Training loss: 0.6989382147789002
Epoch: 58 | Iteration number: [90/393] 22% | Training loss: 0.6981098380353715
Epoch: 58 | Iteration number: [100/393] 25% | Training loss: 0.6972476351261139
Epoch: 58 | Iteration number: [110/393] 27% | Training loss: 0.6965308790857142
Epoch: 58 | Iteration number: [120/393] 30% | Training loss: 0.6960458308458328
Epoch: 58 | Iteration number: [130/393] 33% | Training loss: 0.6956331573999845
Epoch: 58 | Iteration number: [140/393] 35% | Training loss: 0.6951887407473155
Epoch: 58 | Iteration number: [150/393] 38% | Training loss: 0.6948500009377797
Epoch: 58 | Iteration number: [160/393] 40% | Training loss: 0.6945496439933777
Epoch: 58 | Iteration number: [170/393] 43% | Training loss: 0.6943324029445648
Epoch: 58 | Iteration number: [180/393] 45% | Training loss: 0.6940503272745344
Epoch: 58 | Iteration number: [190/393] 48% | Training loss: 0.6938894293810192
Epoch: 58 | Iteration number: [200/393] 50% | Training loss: 0.6937331700325012
Epoch: 58 | Iteration number: [210/393] 53% | Training loss: 0.693568191641853
Epoch: 58 | Iteration number: [220/393] 55% | Training loss: 0.6934752756899053
Epoch: 58 | Iteration number: [230/393] 58% | Training loss: 0.6933013524698175
Epoch: 58 | Iteration number: [240/393] 61% | Training loss: 0.6931214426954587
Epoch: 58 | Iteration number: [250/393] 63% | Training loss: 0.693012271642685
Epoch: 58 | Iteration number: [260/393] 66% | Training loss: 0.692924043077689
Epoch: 58 | Iteration number: [270/393] 68% | Training loss: 0.6928176619388439
Epoch: 58 | Iteration number: [280/393] 71% | Training loss: 0.6927488884755544
Epoch: 58 | Iteration number: [290/393] 73% | Training loss: 0.6925852849565703
Epoch: 58 | Iteration number: [300/393] 76% | Training loss: 0.6925317003329595
Epoch: 58 | Iteration number: [310/393] 78% | Training loss: 0.6924192219011245
Epoch: 58 | Iteration number: [320/393] 81% | Training loss: 0.6923603300005198
Epoch: 58 | Iteration number: [330/393] 83% | Training loss: 0.692319534222285
Epoch: 58 | Iteration number: [340/393] 86% | Training loss: 0.6922353672630647
Epoch: 58 | Iteration number: [350/393] 89% | Training loss: 0.692177677495139
Epoch: 58 | Iteration number: [360/393] 91% | Training loss: 0.6921219592293103
Epoch: 58 | Iteration number: [370/393] 94% | Training loss: 0.6920827372654065
Epoch: 58 | Iteration number: [380/393] 96% | Training loss: 0.6920252307465202
Epoch: 58 | Iteration number: [390/393] 99% | Training loss: 0.6919581485100281

 End of epoch: 58 | Train Loss: 0.6901826095641721 | Training Time: 68 

 End of epoch: 58 | Eval Loss: 0.6903121641704014 | Evaluating Time: 17 
Epoch: 59 | Iteration number: [10/393] 2% | Training loss: 0.7587835609912872
Epoch: 59 | Iteration number: [20/393] 5% | Training loss: 0.7238050937652588
Epoch: 59 | Iteration number: [30/393] 7% | Training loss: 0.7125301122665405
Epoch: 59 | Iteration number: [40/393] 10% | Training loss: 0.7071780294179917
Epoch: 59 | Iteration number: [50/393] 12% | Training loss: 0.7037744772434235
Epoch: 59 | Iteration number: [60/393] 15% | Training loss: 0.7015880266825358
Epoch: 59 | Iteration number: [70/393] 17% | Training loss: 0.6998694113322667
Epoch: 59 | Iteration number: [80/393] 20% | Training loss: 0.6987895488739013
Epoch: 59 | Iteration number: [90/393] 22% | Training loss: 0.6978615833653344
Epoch: 59 | Iteration number: [100/393] 25% | Training loss: 0.697118992805481
Epoch: 59 | Iteration number: [110/393] 27% | Training loss: 0.6963753001256423
Epoch: 59 | Iteration number: [120/393] 30% | Training loss: 0.6958757996559143
Epoch: 59 | Iteration number: [130/393] 33% | Training loss: 0.6953209721125089
Epoch: 59 | Iteration number: [140/393] 35% | Training loss: 0.6949447802134923
Epoch: 59 | Iteration number: [150/393] 38% | Training loss: 0.6945508031050364
Epoch: 59 | Iteration number: [160/393] 40% | Training loss: 0.6943131014704704
Epoch: 59 | Iteration number: [170/393] 43% | Training loss: 0.6941204326994279
Epoch: 59 | Iteration number: [180/393] 45% | Training loss: 0.6939175956779056
Epoch: 59 | Iteration number: [190/393] 48% | Training loss: 0.6937389963551571
Epoch: 59 | Iteration number: [200/393] 50% | Training loss: 0.6936049941182136
Epoch: 59 | Iteration number: [210/393] 53% | Training loss: 0.6934599805445898
Epoch: 59 | Iteration number: [220/393] 55% | Training loss: 0.6932900707830082
Epoch: 59 | Iteration number: [230/393] 58% | Training loss: 0.6931534982245902
Epoch: 59 | Iteration number: [240/393] 61% | Training loss: 0.6930505717794101
Epoch: 59 | Iteration number: [250/393] 63% | Training loss: 0.6929308798313141
Epoch: 59 | Iteration number: [260/393] 66% | Training loss: 0.692812503530429
Epoch: 59 | Iteration number: [270/393] 68% | Training loss: 0.6926692256221065
Epoch: 59 | Iteration number: [280/393] 71% | Training loss: 0.6925966341580664
Epoch: 59 | Iteration number: [290/393] 73% | Training loss: 0.6924936855661458
Epoch: 59 | Iteration number: [300/393] 76% | Training loss: 0.6924000547329585
Epoch: 59 | Iteration number: [310/393] 78% | Training loss: 0.6923541167090016
Epoch: 59 | Iteration number: [320/393] 81% | Training loss: 0.6922843962907791
Epoch: 59 | Iteration number: [330/393] 83% | Training loss: 0.692233615210562
Epoch: 59 | Iteration number: [340/393] 86% | Training loss: 0.6922091887277715
Epoch: 59 | Iteration number: [350/393] 89% | Training loss: 0.6921459863867079
Epoch: 59 | Iteration number: [360/393] 91% | Training loss: 0.6921104439430766
Epoch: 59 | Iteration number: [370/393] 94% | Training loss: 0.6920372173592851
Epoch: 59 | Iteration number: [380/393] 96% | Training loss: 0.6919809636316802
Epoch: 59 | Iteration number: [390/393] 99% | Training loss: 0.6919168586914356

 End of epoch: 59 | Train Loss: 0.6901589509185034 | Training Time: 68 

 End of epoch: 59 | Eval Loss: 0.6904068224284113 | Evaluating Time: 18 
Epoch: 60 | Iteration number: [10/393] 2% | Training loss: 0.760149073600769
Epoch: 60 | Iteration number: [20/393] 5% | Training loss: 0.7254595011472702
Epoch: 60 | Iteration number: [30/393] 7% | Training loss: 0.7131127993265788
Epoch: 60 | Iteration number: [40/393] 10% | Training loss: 0.7072217389941216
Epoch: 60 | Iteration number: [50/393] 12% | Training loss: 0.7039429700374603
Epoch: 60 | Iteration number: [60/393] 15% | Training loss: 0.7016467531522115
Epoch: 60 | Iteration number: [70/393] 17% | Training loss: 0.7001394484724317
Epoch: 60 | Iteration number: [80/393] 20% | Training loss: 0.69886891618371
Epoch: 60 | Iteration number: [90/393] 22% | Training loss: 0.6979420291052925
Epoch: 60 | Iteration number: [100/393] 25% | Training loss: 0.6971150243282318
Epoch: 60 | Iteration number: [110/393] 27% | Training loss: 0.6965960036624562
Epoch: 60 | Iteration number: [120/393] 30% | Training loss: 0.6960664629936218
Epoch: 60 | Iteration number: [130/393] 33% | Training loss: 0.6956104755401611
Epoch: 60 | Iteration number: [140/393] 35% | Training loss: 0.6952368927853448
Epoch: 60 | Iteration number: [150/393] 38% | Training loss: 0.6949269040425619
Epoch: 60 | Iteration number: [160/393] 40% | Training loss: 0.6946020103991032
Epoch: 60 | Iteration number: [170/393] 43% | Training loss: 0.6943289914551903
Epoch: 60 | Iteration number: [180/393] 45% | Training loss: 0.6939812554253473
Epoch: 60 | Iteration number: [190/393] 48% | Training loss: 0.6937789038607949
Epoch: 60 | Iteration number: [200/393] 50% | Training loss: 0.6935946333408356
Epoch: 60 | Iteration number: [210/393] 53% | Training loss: 0.693451715367181
Epoch: 60 | Iteration number: [220/393] 55% | Training loss: 0.6932465393434871
Epoch: 60 | Iteration number: [230/393] 58% | Training loss: 0.6931208703828895
Epoch: 60 | Iteration number: [240/393] 61% | Training loss: 0.6929717523356279
Epoch: 60 | Iteration number: [250/393] 63% | Training loss: 0.692873202085495
Epoch: 60 | Iteration number: [260/393] 66% | Training loss: 0.6927362462648978
Epoch: 60 | Iteration number: [270/393] 68% | Training loss: 0.6926611661911011
Epoch: 60 | Iteration number: [280/393] 71% | Training loss: 0.6925762353198869
Epoch: 60 | Iteration number: [290/393] 73% | Training loss: 0.692518163549489
Epoch: 60 | Iteration number: [300/393] 76% | Training loss: 0.6924279288450876
Epoch: 60 | Iteration number: [310/393] 78% | Training loss: 0.692339595863896
Epoch: 60 | Iteration number: [320/393] 81% | Training loss: 0.6922976121306419
Epoch: 60 | Iteration number: [330/393] 83% | Training loss: 0.6922427233421441
Epoch: 60 | Iteration number: [340/393] 86% | Training loss: 0.6921798322130652
Epoch: 60 | Iteration number: [350/393] 89% | Training loss: 0.6920900869369507
Epoch: 60 | Iteration number: [360/393] 91% | Training loss: 0.6920600199037128
Epoch: 60 | Iteration number: [370/393] 94% | Training loss: 0.692032369246354
Epoch: 60 | Iteration number: [380/393] 96% | Training loss: 0.6919771294844778
Epoch: 60 | Iteration number: [390/393] 99% | Training loss: 0.6919323849372375

 End of epoch: 60 | Train Loss: 0.6901506889260756 | Training Time: 67 

 End of epoch: 60 | Eval Loss: 0.6903931863453924 | Evaluating Time: 17 
Epoch: 61 | Iteration number: [10/393] 2% | Training loss: 0.7593495190143585
Epoch: 61 | Iteration number: [20/393] 5% | Training loss: 0.7247606724500656
Epoch: 61 | Iteration number: [30/393] 7% | Training loss: 0.7130904614925384
Epoch: 61 | Iteration number: [40/393] 10% | Training loss: 0.7074641153216362
Epoch: 61 | Iteration number: [50/393] 12% | Training loss: 0.7040333306789398
Epoch: 61 | Iteration number: [60/393] 15% | Training loss: 0.7017145335674286
Epoch: 61 | Iteration number: [70/393] 17% | Training loss: 0.7000551206724984
Epoch: 61 | Iteration number: [80/393] 20% | Training loss: 0.6987098902463913
Epoch: 61 | Iteration number: [90/393] 22% | Training loss: 0.6977918737464481
Epoch: 61 | Iteration number: [100/393] 25% | Training loss: 0.6971272814273834
Epoch: 61 | Iteration number: [110/393] 27% | Training loss: 0.6964990008961071
Epoch: 61 | Iteration number: [120/393] 30% | Training loss: 0.696012814839681
Epoch: 61 | Iteration number: [130/393] 33% | Training loss: 0.6956102068607624
Epoch: 61 | Iteration number: [140/393] 35% | Training loss: 0.6952247206653868
Epoch: 61 | Iteration number: [150/393] 38% | Training loss: 0.6949326872825623
Epoch: 61 | Iteration number: [160/393] 40% | Training loss: 0.6946154236793518
Epoch: 61 | Iteration number: [170/393] 43% | Training loss: 0.6943329783046946
Epoch: 61 | Iteration number: [180/393] 45% | Training loss: 0.6941140350368288
Epoch: 61 | Iteration number: [190/393] 48% | Training loss: 0.6939081806885569
Epoch: 61 | Iteration number: [200/393] 50% | Training loss: 0.6937214049696923
Epoch: 61 | Iteration number: [210/393] 53% | Training loss: 0.6936113891147432
Epoch: 61 | Iteration number: [220/393] 55% | Training loss: 0.6934361441568895
Epoch: 61 | Iteration number: [230/393] 58% | Training loss: 0.6933017378268035
Epoch: 61 | Iteration number: [240/393] 61% | Training loss: 0.6931834744910399
Epoch: 61 | Iteration number: [250/393] 63% | Training loss: 0.6930457422733307
Epoch: 61 | Iteration number: [260/393] 66% | Training loss: 0.6929650753736496
Epoch: 61 | Iteration number: [270/393] 68% | Training loss: 0.6928754102300715
Epoch: 61 | Iteration number: [280/393] 71% | Training loss: 0.6927687489560672
Epoch: 61 | Iteration number: [290/393] 73% | Training loss: 0.6926702386346356
Epoch: 61 | Iteration number: [300/393] 76% | Training loss: 0.6925896259148916
Epoch: 61 | Iteration number: [310/393] 78% | Training loss: 0.692501950071704
Epoch: 61 | Iteration number: [320/393] 81% | Training loss: 0.6924467198550701
Epoch: 61 | Iteration number: [330/393] 83% | Training loss: 0.6924113530101198
Epoch: 61 | Iteration number: [340/393] 86% | Training loss: 0.692370141954983
Epoch: 61 | Iteration number: [350/393] 89% | Training loss: 0.692311840227672
Epoch: 61 | Iteration number: [360/393] 91% | Training loss: 0.6922704663541582
Epoch: 61 | Iteration number: [370/393] 94% | Training loss: 0.6921732461130297
Epoch: 61 | Iteration number: [380/393] 96% | Training loss: 0.6921294613888389
Epoch: 61 | Iteration number: [390/393] 99% | Training loss: 0.6920852888853122

 End of epoch: 61 | Train Loss: 0.6903011656292826 | Training Time: 67 

 End of epoch: 61 | Eval Loss: 0.6903518791101417 | Evaluating Time: 17 
Epoch: 62 | Iteration number: [10/393] 2% | Training loss: 0.7607207953929901
Epoch: 62 | Iteration number: [20/393] 5% | Training loss: 0.7256773293018342
Epoch: 62 | Iteration number: [30/393] 7% | Training loss: 0.7141679545243581
Epoch: 62 | Iteration number: [40/393] 10% | Training loss: 0.7083083555102349
Epoch: 62 | Iteration number: [50/393] 12% | Training loss: 0.7046147501468658
Epoch: 62 | Iteration number: [60/393] 15% | Training loss: 0.702387265364329
Epoch: 62 | Iteration number: [70/393] 17% | Training loss: 0.7007533209664482
Epoch: 62 | Iteration number: [80/393] 20% | Training loss: 0.6993955865502357
Epoch: 62 | Iteration number: [90/393] 22% | Training loss: 0.6984278115961287
Epoch: 62 | Iteration number: [100/393] 25% | Training loss: 0.6974633979797363
Epoch: 62 | Iteration number: [110/393] 27% | Training loss: 0.6968037762425162
Epoch: 62 | Iteration number: [120/393] 30% | Training loss: 0.6961935023466747
Epoch: 62 | Iteration number: [130/393] 33% | Training loss: 0.6957784510575808
Epoch: 62 | Iteration number: [140/393] 35% | Training loss: 0.69535930284432
Epoch: 62 | Iteration number: [150/393] 38% | Training loss: 0.6949347126483917
Epoch: 62 | Iteration number: [160/393] 40% | Training loss: 0.6946413237601519
Epoch: 62 | Iteration number: [170/393] 43% | Training loss: 0.6943576840793385
Epoch: 62 | Iteration number: [180/393] 45% | Training loss: 0.6941386815574434
Epoch: 62 | Iteration number: [190/393] 48% | Training loss: 0.6939175753216994
Epoch: 62 | Iteration number: [200/393] 50% | Training loss: 0.6937427860498429
Epoch: 62 | Iteration number: [210/393] 53% | Training loss: 0.6936295813038236
Epoch: 62 | Iteration number: [220/393] 55% | Training loss: 0.6934550886804407
Epoch: 62 | Iteration number: [230/393] 58% | Training loss: 0.6933294550232265
Epoch: 62 | Iteration number: [240/393] 61% | Training loss: 0.693187831590573
Epoch: 62 | Iteration number: [250/393] 63% | Training loss: 0.6930528111457824
Epoch: 62 | Iteration number: [260/393] 66% | Training loss: 0.692946235720928
Epoch: 62 | Iteration number: [270/393] 68% | Training loss: 0.692825006114112
Epoch: 62 | Iteration number: [280/393] 71% | Training loss: 0.6927294639604432
Epoch: 62 | Iteration number: [290/393] 73% | Training loss: 0.6926480110349327
Epoch: 62 | Iteration number: [300/393] 76% | Training loss: 0.6925323812166849
Epoch: 62 | Iteration number: [310/393] 78% | Training loss: 0.6924141320490068
Epoch: 62 | Iteration number: [320/393] 81% | Training loss: 0.6923744717612863
Epoch: 62 | Iteration number: [330/393] 83% | Training loss: 0.6923158501133774
Epoch: 62 | Iteration number: [340/393] 86% | Training loss: 0.6922538105179282
Epoch: 62 | Iteration number: [350/393] 89% | Training loss: 0.692165561233248
Epoch: 62 | Iteration number: [360/393] 91% | Training loss: 0.6921294459038311
Epoch: 62 | Iteration number: [370/393] 94% | Training loss: 0.6920850824665379
Epoch: 62 | Iteration number: [380/393] 96% | Training loss: 0.6920325307469619
Epoch: 62 | Iteration number: [390/393] 99% | Training loss: 0.6919785137359913

 End of epoch: 62 | Train Loss: 0.6902098804333131 | Training Time: 67 

 End of epoch: 62 | Eval Loss: 0.6903435247285026 | Evaluating Time: 17 
Epoch: 63 | Iteration number: [10/393] 2% | Training loss: 0.7595157325267792
Epoch: 63 | Iteration number: [20/393] 5% | Training loss: 0.7247892320156097
Epoch: 63 | Iteration number: [30/393] 7% | Training loss: 0.7134044984976451
Epoch: 63 | Iteration number: [40/393] 10% | Training loss: 0.7078543603420258
Epoch: 63 | Iteration number: [50/393] 12% | Training loss: 0.7043381285667419
Epoch: 63 | Iteration number: [60/393] 15% | Training loss: 0.7020066608985265
Epoch: 63 | Iteration number: [70/393] 17% | Training loss: 0.7002185412815639
Epoch: 63 | Iteration number: [80/393] 20% | Training loss: 0.6989534959197045
Epoch: 63 | Iteration number: [90/393] 22% | Training loss: 0.6979263795746697
Epoch: 63 | Iteration number: [100/393] 25% | Training loss: 0.6972215908765793
Epoch: 63 | Iteration number: [110/393] 27% | Training loss: 0.6966017614711415
Epoch: 63 | Iteration number: [120/393] 30% | Training loss: 0.6960938408970833
Epoch: 63 | Iteration number: [130/393] 33% | Training loss: 0.6956144401660332
Epoch: 63 | Iteration number: [140/393] 35% | Training loss: 0.6952224122626441
Epoch: 63 | Iteration number: [150/393] 38% | Training loss: 0.6948879738648732
Epoch: 63 | Iteration number: [160/393] 40% | Training loss: 0.6945794899016619
Epoch: 63 | Iteration number: [170/393] 43% | Training loss: 0.6942618541857776
Epoch: 63 | Iteration number: [180/393] 45% | Training loss: 0.6940413845909966
Epoch: 63 | Iteration number: [190/393] 48% | Training loss: 0.6938620065387927
Epoch: 63 | Iteration number: [200/393] 50% | Training loss: 0.6936096298694611
Epoch: 63 | Iteration number: [210/393] 53% | Training loss: 0.693448976108006
Epoch: 63 | Iteration number: [220/393] 55% | Training loss: 0.6933078993450511
Epoch: 63 | Iteration number: [230/393] 58% | Training loss: 0.6931994720645572
Epoch: 63 | Iteration number: [240/393] 61% | Training loss: 0.6930795463422934
Epoch: 63 | Iteration number: [250/393] 63% | Training loss: 0.692947276353836
Epoch: 63 | Iteration number: [260/393] 66% | Training loss: 0.6928443844501789
Epoch: 63 | Iteration number: [270/393] 68% | Training loss: 0.6927438446769008
Epoch: 63 | Iteration number: [280/393] 71% | Training loss: 0.6926786480205399
Epoch: 63 | Iteration number: [290/393] 73% | Training loss: 0.6925727410563107
Epoch: 63 | Iteration number: [300/393] 76% | Training loss: 0.6924903585513433
Epoch: 63 | Iteration number: [310/393] 78% | Training loss: 0.6923928685726658
Epoch: 63 | Iteration number: [320/393] 81% | Training loss: 0.6923109641298651
Epoch: 63 | Iteration number: [330/393] 83% | Training loss: 0.6922563312631664
Epoch: 63 | Iteration number: [340/393] 86% | Training loss: 0.6921868574969908
Epoch: 63 | Iteration number: [350/393] 89% | Training loss: 0.6921111725057875
Epoch: 63 | Iteration number: [360/393] 91% | Training loss: 0.692023079097271
Epoch: 63 | Iteration number: [370/393] 94% | Training loss: 0.6919834091856673
Epoch: 63 | Iteration number: [380/393] 96% | Training loss: 0.6919351424041548
Epoch: 63 | Iteration number: [390/393] 99% | Training loss: 0.691917606194814

 End of epoch: 63 | Train Loss: 0.6901567846764135 | Training Time: 67 

 End of epoch: 63 | Eval Loss: 0.6903895747904875 | Evaluating Time: 17 
Epoch: 64 | Iteration number: [10/393] 2% | Training loss: 0.7595717489719391
Epoch: 64 | Iteration number: [20/393] 5% | Training loss: 0.7241773128509521
Epoch: 64 | Iteration number: [30/393] 7% | Training loss: 0.7124252776304881
Epoch: 64 | Iteration number: [40/393] 10% | Training loss: 0.7068704947829246
Epoch: 64 | Iteration number: [50/393] 12% | Training loss: 0.7036339104175567
Epoch: 64 | Iteration number: [60/393] 15% | Training loss: 0.7015930891036988
Epoch: 64 | Iteration number: [70/393] 17% | Training loss: 0.6999456260885512
Epoch: 64 | Iteration number: [80/393] 20% | Training loss: 0.6984910719096661
Epoch: 64 | Iteration number: [90/393] 22% | Training loss: 0.6976925373077393
Epoch: 64 | Iteration number: [100/393] 25% | Training loss: 0.6969784182310105
Epoch: 64 | Iteration number: [110/393] 27% | Training loss: 0.6963958019560034
Epoch: 64 | Iteration number: [120/393] 30% | Training loss: 0.6957473134001096
Epoch: 64 | Iteration number: [130/393] 33% | Training loss: 0.6952758133411407
Epoch: 64 | Iteration number: [140/393] 35% | Training loss: 0.6948291842426573
Epoch: 64 | Iteration number: [150/393] 38% | Training loss: 0.6945273133118948
Epoch: 64 | Iteration number: [160/393] 40% | Training loss: 0.6943337339907885
Epoch: 64 | Iteration number: [170/393] 43% | Training loss: 0.6941279407809763
Epoch: 64 | Iteration number: [180/393] 45% | Training loss: 0.6939448681142595
Epoch: 64 | Iteration number: [190/393] 48% | Training loss: 0.6937589149726064
Epoch: 64 | Iteration number: [200/393] 50% | Training loss: 0.6936348801851273
Epoch: 64 | Iteration number: [210/393] 53% | Training loss: 0.6934715449810028
Epoch: 64 | Iteration number: [220/393] 55% | Training loss: 0.6933615418997678
Epoch: 64 | Iteration number: [230/393] 58% | Training loss: 0.6932407412839973
Epoch: 64 | Iteration number: [240/393] 61% | Training loss: 0.6931018300354481
Epoch: 64 | Iteration number: [250/393] 63% | Training loss: 0.6929810330867767
Epoch: 64 | Iteration number: [260/393] 66% | Training loss: 0.6928709142483198
Epoch: 64 | Iteration number: [270/393] 68% | Training loss: 0.692755898060622
Epoch: 64 | Iteration number: [280/393] 71% | Training loss: 0.6926653761948858
Epoch: 64 | Iteration number: [290/393] 73% | Training loss: 0.6925833323906208
Epoch: 64 | Iteration number: [300/393] 76% | Training loss: 0.692484047015508
Epoch: 64 | Iteration number: [310/393] 78% | Training loss: 0.692417129970366
Epoch: 64 | Iteration number: [320/393] 81% | Training loss: 0.6923776583746075
Epoch: 64 | Iteration number: [330/393] 83% | Training loss: 0.6923329727216201
Epoch: 64 | Iteration number: [340/393] 86% | Training loss: 0.6922813890611424
Epoch: 64 | Iteration number: [350/393] 89% | Training loss: 0.6921883860656194
Epoch: 64 | Iteration number: [360/393] 91% | Training loss: 0.6921182460255093
Epoch: 64 | Iteration number: [370/393] 94% | Training loss: 0.692047989690626
Epoch: 64 | Iteration number: [380/393] 96% | Training loss: 0.6920138878257651
Epoch: 64 | Iteration number: [390/393] 99% | Training loss: 0.6919962970110086

 End of epoch: 64 | Train Loss: 0.6902233121049313 | Training Time: 67 

 End of epoch: 64 | Eval Loss: 0.6904540949938248 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/393] 2% | Training loss: 0.7591887533664703
Epoch: 65 | Iteration number: [20/393] 5% | Training loss: 0.72471784055233
Epoch: 65 | Iteration number: [30/393] 7% | Training loss: 0.7130309104919433
Epoch: 65 | Iteration number: [40/393] 10% | Training loss: 0.7072054579854011
Epoch: 65 | Iteration number: [50/393] 12% | Training loss: 0.7036260652542115
Epoch: 65 | Iteration number: [60/393] 15% | Training loss: 0.7012892097234726
Epoch: 65 | Iteration number: [70/393] 17% | Training loss: 0.6998413681983948
Epoch: 65 | Iteration number: [80/393] 20% | Training loss: 0.6985614351928234
Epoch: 65 | Iteration number: [90/393] 22% | Training loss: 0.6977225449350145
Epoch: 65 | Iteration number: [100/393] 25% | Training loss: 0.6969683009386063
Epoch: 65 | Iteration number: [110/393] 27% | Training loss: 0.6963289087468928
Epoch: 65 | Iteration number: [120/393] 30% | Training loss: 0.6956966802477836
Epoch: 65 | Iteration number: [130/393] 33% | Training loss: 0.6953191179495591
Epoch: 65 | Iteration number: [140/393] 35% | Training loss: 0.6949501659188951
Epoch: 65 | Iteration number: [150/393] 38% | Training loss: 0.6945642813046773
Epoch: 65 | Iteration number: [160/393] 40% | Training loss: 0.6943084694445133
Epoch: 65 | Iteration number: [170/393] 43% | Training loss: 0.6941300360595479
Epoch: 65 | Iteration number: [180/393] 45% | Training loss: 0.6939085513353348
Epoch: 65 | Iteration number: [190/393] 48% | Training loss: 0.6936719219935568
Epoch: 65 | Iteration number: [200/393] 50% | Training loss: 0.6934836056828498
Epoch: 65 | Iteration number: [210/393] 53% | Training loss: 0.6932898424920582
Epoch: 65 | Iteration number: [220/393] 55% | Training loss: 0.6931296291676434
Epoch: 65 | Iteration number: [230/393] 58% | Training loss: 0.6930418952651646
Epoch: 65 | Iteration number: [240/393] 61% | Training loss: 0.6929491614301999
Epoch: 65 | Iteration number: [250/393] 63% | Training loss: 0.6928839297294617
Epoch: 65 | Iteration number: [260/393] 66% | Training loss: 0.6927553931107888
Epoch: 65 | Iteration number: [270/393] 68% | Training loss: 0.6926829258600871
Epoch: 65 | Iteration number: [280/393] 71% | Training loss: 0.6926483941929681
Epoch: 65 | Iteration number: [290/393] 73% | Training loss: 0.6925724792069402
Epoch: 65 | Iteration number: [300/393] 76% | Training loss: 0.6924892993768056
Epoch: 65 | Iteration number: [310/393] 78% | Training loss: 0.6924468378866873
Epoch: 65 | Iteration number: [320/393] 81% | Training loss: 0.6923631252720952
Epoch: 65 | Iteration number: [330/393] 83% | Training loss: 0.6922533748727856
Epoch: 65 | Iteration number: [340/393] 86% | Training loss: 0.6922141678193037
Epoch: 65 | Iteration number: [350/393] 89% | Training loss: 0.692170091186251
Epoch: 65 | Iteration number: [360/393] 91% | Training loss: 0.6921389040019778
Epoch: 65 | Iteration number: [370/393] 94% | Training loss: 0.6920765337106344
Epoch: 65 | Iteration number: [380/393] 96% | Training loss: 0.6920040331388775
Epoch: 65 | Iteration number: [390/393] 99% | Training loss: 0.6919861133282001

 End of epoch: 65 | Train Loss: 0.6901838655083538 | Training Time: 67 

 End of epoch: 65 | Eval Loss: 0.6904497402054923 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/393] 2% | Training loss: 0.7594879508018494
Epoch: 66 | Iteration number: [20/393] 5% | Training loss: 0.724877017736435
Epoch: 66 | Iteration number: [30/393] 7% | Training loss: 0.7133826454480489
Epoch: 66 | Iteration number: [40/393] 10% | Training loss: 0.7074240386486054
Epoch: 66 | Iteration number: [50/393] 12% | Training loss: 0.7040627479553223
Epoch: 66 | Iteration number: [60/393] 15% | Training loss: 0.70162586470445
Epoch: 66 | Iteration number: [70/393] 17% | Training loss: 0.700122960124697
Epoch: 66 | Iteration number: [80/393] 20% | Training loss: 0.6989469408988953
Epoch: 66 | Iteration number: [90/393] 22% | Training loss: 0.6980129725403256
Epoch: 66 | Iteration number: [100/393] 25% | Training loss: 0.6972874075174331
Epoch: 66 | Iteration number: [110/393] 27% | Training loss: 0.6967049278996208
Epoch: 66 | Iteration number: [120/393] 30% | Training loss: 0.696202119688193
Epoch: 66 | Iteration number: [130/393] 33% | Training loss: 0.6956720696045802
Epoch: 66 | Iteration number: [140/393] 35% | Training loss: 0.6952734197889056
Epoch: 66 | Iteration number: [150/393] 38% | Training loss: 0.6948870686690013
Epoch: 66 | Iteration number: [160/393] 40% | Training loss: 0.6945971481502056
Epoch: 66 | Iteration number: [170/393] 43% | Training loss: 0.6943185438128079
Epoch: 66 | Iteration number: [180/393] 45% | Training loss: 0.6940716554721197
Epoch: 66 | Iteration number: [190/393] 48% | Training loss: 0.6938464368644514
Epoch: 66 | Iteration number: [200/393] 50% | Training loss: 0.693700626194477
Epoch: 66 | Iteration number: [210/393] 53% | Training loss: 0.6934783640361968
Epoch: 66 | Iteration number: [220/393] 55% | Training loss: 0.6932949169115586
Epoch: 66 | Iteration number: [230/393] 58% | Training loss: 0.6932045692982881
Epoch: 66 | Iteration number: [240/393] 61% | Training loss: 0.6930828797320525
Epoch: 66 | Iteration number: [250/393] 63% | Training loss: 0.692960422039032
Epoch: 66 | Iteration number: [260/393] 66% | Training loss: 0.6928239107131958
Epoch: 66 | Iteration number: [270/393] 68% | Training loss: 0.6927029364638858
Epoch: 66 | Iteration number: [280/393] 71% | Training loss: 0.6926011149372373
Epoch: 66 | Iteration number: [290/393] 73% | Training loss: 0.6925480782985687
Epoch: 66 | Iteration number: [300/393] 76% | Training loss: 0.6924706468979518
Epoch: 66 | Iteration number: [310/393] 78% | Training loss: 0.6924069969884811
Epoch: 66 | Iteration number: [320/393] 81% | Training loss: 0.6923363907262683
Epoch: 66 | Iteration number: [330/393] 83% | Training loss: 0.692301460649028
Epoch: 66 | Iteration number: [340/393] 86% | Training loss: 0.6922414711293052
Epoch: 66 | Iteration number: [350/393] 89% | Training loss: 0.6922173438753401
Epoch: 66 | Iteration number: [360/393] 91% | Training loss: 0.6921475984983974
Epoch: 66 | Iteration number: [370/393] 94% | Training loss: 0.6920723945707888
Epoch: 66 | Iteration number: [380/393] 96% | Training loss: 0.6919923454523087
Epoch: 66 | Iteration number: [390/393] 99% | Training loss: 0.6919770931586241

 End of epoch: 66 | Train Loss: 0.6902117134657222 | Training Time: 67 

 End of epoch: 66 | Eval Loss: 0.6905072428742234 | Evaluating Time: 17 
Epoch: 67 | Iteration number: [10/393] 2% | Training loss: 0.7578282177448272
Epoch: 67 | Iteration number: [20/393] 5% | Training loss: 0.723988264799118
Epoch: 67 | Iteration number: [30/393] 7% | Training loss: 0.71257231036822
Epoch: 67 | Iteration number: [40/393] 10% | Training loss: 0.706964784860611
Epoch: 67 | Iteration number: [50/393] 12% | Training loss: 0.7036943161487579
Epoch: 67 | Iteration number: [60/393] 15% | Training loss: 0.7013666093349457
Epoch: 67 | Iteration number: [70/393] 17% | Training loss: 0.6996702100549426
Epoch: 67 | Iteration number: [80/393] 20% | Training loss: 0.698561929166317
Epoch: 67 | Iteration number: [90/393] 22% | Training loss: 0.6976103822390238
Epoch: 67 | Iteration number: [100/393] 25% | Training loss: 0.6969984340667724
Epoch: 67 | Iteration number: [110/393] 27% | Training loss: 0.6964019358158111
Epoch: 67 | Iteration number: [120/393] 30% | Training loss: 0.6958473439017931
Epoch: 67 | Iteration number: [130/393] 33% | Training loss: 0.6954595795044533
Epoch: 67 | Iteration number: [140/393] 35% | Training loss: 0.6951265122209277
Epoch: 67 | Iteration number: [150/393] 38% | Training loss: 0.6948261435826619
Epoch: 67 | Iteration number: [160/393] 40% | Training loss: 0.6945161834359169
Epoch: 67 | Iteration number: [170/393] 43% | Training loss: 0.6942022965234869
Epoch: 67 | Iteration number: [180/393] 45% | Training loss: 0.6939355750878652
Epoch: 67 | Iteration number: [190/393] 48% | Training loss: 0.693726930179094
Epoch: 67 | Iteration number: [200/393] 50% | Training loss: 0.6935437229275704
Epoch: 67 | Iteration number: [210/393] 53% | Training loss: 0.6933205933797927
Epoch: 67 | Iteration number: [220/393] 55% | Training loss: 0.6931150940331545
Epoch: 67 | Iteration number: [230/393] 58% | Training loss: 0.6929988835168921
Epoch: 67 | Iteration number: [240/393] 61% | Training loss: 0.6928792168696721
Epoch: 67 | Iteration number: [250/393] 63% | Training loss: 0.6928077039718628
Epoch: 67 | Iteration number: [260/393] 66% | Training loss: 0.6927315897666491
Epoch: 67 | Iteration number: [270/393] 68% | Training loss: 0.6926350469942446
Epoch: 67 | Iteration number: [280/393] 71% | Training loss: 0.692509101331234
Epoch: 67 | Iteration number: [290/393] 73% | Training loss: 0.6924589237262463
Epoch: 67 | Iteration number: [300/393] 76% | Training loss: 0.6923737293481826
Epoch: 67 | Iteration number: [310/393] 78% | Training loss: 0.6923193681624628
Epoch: 67 | Iteration number: [320/393] 81% | Training loss: 0.6922683268785477
Epoch: 67 | Iteration number: [330/393] 83% | Training loss: 0.6922176176851446
Epoch: 67 | Iteration number: [340/393] 86% | Training loss: 0.6921485725571127
Epoch: 67 | Iteration number: [350/393] 89% | Training loss: 0.6921051413672311
Epoch: 67 | Iteration number: [360/393] 91% | Training loss: 0.6920609401332007
Epoch: 67 | Iteration number: [370/393] 94% | Training loss: 0.6920286349348119
Epoch: 67 | Iteration number: [380/393] 96% | Training loss: 0.6919628777002034
Epoch: 67 | Iteration number: [390/393] 99% | Training loss: 0.6919394375422062

 End of epoch: 67 | Train Loss: 0.6901790530020347 | Training Time: 68 

 End of epoch: 67 | Eval Loss: 0.690447464281199 | Evaluating Time: 17 
Epoch: 68 | Iteration number: [10/393] 2% | Training loss: 0.7594618439674378
Epoch: 68 | Iteration number: [20/393] 5% | Training loss: 0.7244160145521163
Epoch: 68 | Iteration number: [30/393] 7% | Training loss: 0.7128902236620586
Epoch: 68 | Iteration number: [40/393] 10% | Training loss: 0.7071369767189026
Epoch: 68 | Iteration number: [50/393] 12% | Training loss: 0.7038280200958252
Epoch: 68 | Iteration number: [60/393] 15% | Training loss: 0.7015218695004781
Epoch: 68 | Iteration number: [70/393] 17% | Training loss: 0.6999120771884918
Epoch: 68 | Iteration number: [80/393] 20% | Training loss: 0.698633486032486
Epoch: 68 | Iteration number: [90/393] 22% | Training loss: 0.6976952989896138
Epoch: 68 | Iteration number: [100/393] 25% | Training loss: 0.6969758343696594
Epoch: 68 | Iteration number: [110/393] 27% | Training loss: 0.6963485950773413
Epoch: 68 | Iteration number: [120/393] 30% | Training loss: 0.695827363928159
Epoch: 68 | Iteration number: [130/393] 33% | Training loss: 0.6953449409741622
Epoch: 68 | Iteration number: [140/393] 35% | Training loss: 0.6950108838932855
Epoch: 68 | Iteration number: [150/393] 38% | Training loss: 0.6947522672017415
Epoch: 68 | Iteration number: [160/393] 40% | Training loss: 0.6944426264613867
Epoch: 68 | Iteration number: [170/393] 43% | Training loss: 0.6941773723153507
Epoch: 68 | Iteration number: [180/393] 45% | Training loss: 0.6939825044737922
Epoch: 68 | Iteration number: [190/393] 48% | Training loss: 0.6937757178356773
Epoch: 68 | Iteration number: [200/393] 50% | Training loss: 0.6935285052657127
Epoch: 68 | Iteration number: [210/393] 53% | Training loss: 0.693371764251164
Epoch: 68 | Iteration number: [220/393] 55% | Training loss: 0.6931699544191361
Epoch: 68 | Iteration number: [230/393] 58% | Training loss: 0.6930572328360184
Epoch: 68 | Iteration number: [240/393] 61% | Training loss: 0.6929497790833314
Epoch: 68 | Iteration number: [250/393] 63% | Training loss: 0.6928655848503112
Epoch: 68 | Iteration number: [260/393] 66% | Training loss: 0.6927997797727585
Epoch: 68 | Iteration number: [270/393] 68% | Training loss: 0.6927008361728103
Epoch: 68 | Iteration number: [280/393] 71% | Training loss: 0.6926328493016106
Epoch: 68 | Iteration number: [290/393] 73% | Training loss: 0.6925583535227282
Epoch: 68 | Iteration number: [300/393] 76% | Training loss: 0.6925038927793503
Epoch: 68 | Iteration number: [310/393] 78% | Training loss: 0.6923743324895059
Epoch: 68 | Iteration number: [320/393] 81% | Training loss: 0.692346535436809
Epoch: 68 | Iteration number: [330/393] 83% | Training loss: 0.692309831127976
Epoch: 68 | Iteration number: [340/393] 86% | Training loss: 0.6922597268048455
Epoch: 68 | Iteration number: [350/393] 89% | Training loss: 0.6922089685712541
Epoch: 68 | Iteration number: [360/393] 91% | Training loss: 0.6921351298689842
Epoch: 68 | Iteration number: [370/393] 94% | Training loss: 0.6920832050813212
Epoch: 68 | Iteration number: [380/393] 96% | Training loss: 0.6920436783840782
Epoch: 68 | Iteration number: [390/393] 99% | Training loss: 0.6919760681115664

 End of epoch: 68 | Train Loss: 0.6901983527736809 | Training Time: 67 

 End of epoch: 68 | Eval Loss: 0.690337673741944 | Evaluating Time: 17 
Epoch: 69 | Iteration number: [10/393] 2% | Training loss: 0.7584660887718201
Epoch: 69 | Iteration number: [20/393] 5% | Training loss: 0.7238167196512222
Epoch: 69 | Iteration number: [30/393] 7% | Training loss: 0.7125297725200653
Epoch: 69 | Iteration number: [40/393] 10% | Training loss: 0.7067179039120675
Epoch: 69 | Iteration number: [50/393] 12% | Training loss: 0.7034675705432892
Epoch: 69 | Iteration number: [60/393] 15% | Training loss: 0.7014875690142314
Epoch: 69 | Iteration number: [70/393] 17% | Training loss: 0.699803763628006
Epoch: 69 | Iteration number: [80/393] 20% | Training loss: 0.6987202204763889
Epoch: 69 | Iteration number: [90/393] 22% | Training loss: 0.6977574712700314
Epoch: 69 | Iteration number: [100/393] 25% | Training loss: 0.6970289385318756
Epoch: 69 | Iteration number: [110/393] 27% | Training loss: 0.6964662410996177
Epoch: 69 | Iteration number: [120/393] 30% | Training loss: 0.6958732848366102
Epoch: 69 | Iteration number: [130/393] 33% | Training loss: 0.6954283388761374
Epoch: 69 | Iteration number: [140/393] 35% | Training loss: 0.6949806941407067
Epoch: 69 | Iteration number: [150/393] 38% | Training loss: 0.694646821419398
Epoch: 69 | Iteration number: [160/393] 40% | Training loss: 0.6944348882883787
Epoch: 69 | Iteration number: [170/393] 43% | Training loss: 0.6941606851185069
Epoch: 69 | Iteration number: [180/393] 45% | Training loss: 0.6939211090405782
Epoch: 69 | Iteration number: [190/393] 48% | Training loss: 0.6937540829181671
Epoch: 69 | Iteration number: [200/393] 50% | Training loss: 0.6935929143428803
Epoch: 69 | Iteration number: [210/393] 53% | Training loss: 0.6934562490099953
Epoch: 69 | Iteration number: [220/393] 55% | Training loss: 0.693276063691486
Epoch: 69 | Iteration number: [230/393] 58% | Training loss: 0.6931716136310412
Epoch: 69 | Iteration number: [240/393] 61% | Training loss: 0.6930420669416587
Epoch: 69 | Iteration number: [250/393] 63% | Training loss: 0.6929080271720887
Epoch: 69 | Iteration number: [260/393] 66% | Training loss: 0.6928113435323422
Epoch: 69 | Iteration number: [270/393] 68% | Training loss: 0.6927062959582717
Epoch: 69 | Iteration number: [280/393] 71% | Training loss: 0.6926322042942047
Epoch: 69 | Iteration number: [290/393] 73% | Training loss: 0.692600103082328
Epoch: 69 | Iteration number: [300/393] 76% | Training loss: 0.6925392405192057
Epoch: 69 | Iteration number: [310/393] 78% | Training loss: 0.6924159192269849
Epoch: 69 | Iteration number: [320/393] 81% | Training loss: 0.6923121044412255
Epoch: 69 | Iteration number: [330/393] 83% | Training loss: 0.6922571028723862
Epoch: 69 | Iteration number: [340/393] 86% | Training loss: 0.6921772721935721
Epoch: 69 | Iteration number: [350/393] 89% | Training loss: 0.692115888936179
Epoch: 69 | Iteration number: [360/393] 91% | Training loss: 0.6920293556319342
Epoch: 69 | Iteration number: [370/393] 94% | Training loss: 0.6919787344094869
Epoch: 69 | Iteration number: [380/393] 96% | Training loss: 0.6919479459524155
Epoch: 69 | Iteration number: [390/393] 99% | Training loss: 0.691879206437331

 End of epoch: 69 | Train Loss: 0.6901164267202673 | Training Time: 67 

 End of epoch: 69 | Eval Loss: 0.6903152502312953 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/393] 2% | Training loss: 0.7591146171092987
Epoch: 70 | Iteration number: [20/393] 5% | Training loss: 0.7244844198226928
Epoch: 70 | Iteration number: [30/393] 7% | Training loss: 0.7132682402928671
Epoch: 70 | Iteration number: [40/393] 10% | Training loss: 0.7071940779685975
Epoch: 70 | Iteration number: [50/393] 12% | Training loss: 0.7037749445438385
Epoch: 70 | Iteration number: [60/393] 15% | Training loss: 0.7014908899863561
Epoch: 70 | Iteration number: [70/393] 17% | Training loss: 0.6998164032186781
Epoch: 70 | Iteration number: [80/393] 20% | Training loss: 0.698481310158968
Epoch: 70 | Iteration number: [90/393] 22% | Training loss: 0.6974475926823086
Epoch: 70 | Iteration number: [100/393] 25% | Training loss: 0.6966449213027954
Epoch: 70 | Iteration number: [110/393] 27% | Training loss: 0.6960757900368083
Epoch: 70 | Iteration number: [120/393] 30% | Training loss: 0.6955218185981115
Epoch: 70 | Iteration number: [130/393] 33% | Training loss: 0.6951329180827508
Epoch: 70 | Iteration number: [140/393] 35% | Training loss: 0.6946584867579596
Epoch: 70 | Iteration number: [150/393] 38% | Training loss: 0.694376657406489
Epoch: 70 | Iteration number: [160/393] 40% | Training loss: 0.694127919524908
Epoch: 70 | Iteration number: [170/393] 43% | Training loss: 0.6939548913170309
Epoch: 70 | Iteration number: [180/393] 45% | Training loss: 0.6937585602204005
Epoch: 70 | Iteration number: [190/393] 48% | Training loss: 0.693583556539134
Epoch: 70 | Iteration number: [200/393] 50% | Training loss: 0.6934261575341225
Epoch: 70 | Iteration number: [210/393] 53% | Training loss: 0.693256188858123
Epoch: 70 | Iteration number: [220/393] 55% | Training loss: 0.6931094099174846
Epoch: 70 | Iteration number: [230/393] 58% | Training loss: 0.6929782605689505
Epoch: 70 | Iteration number: [240/393] 61% | Training loss: 0.6929012154539426
Epoch: 70 | Iteration number: [250/393] 63% | Training loss: 0.6927856171131134
Epoch: 70 | Iteration number: [260/393] 66% | Training loss: 0.6926850144679729
Epoch: 70 | Iteration number: [270/393] 68% | Training loss: 0.6925159633159638
Epoch: 70 | Iteration number: [280/393] 71% | Training loss: 0.6924072527459689
Epoch: 70 | Iteration number: [290/393] 73% | Training loss: 0.692304117309636
Epoch: 70 | Iteration number: [300/393] 76% | Training loss: 0.6922727314631144
Epoch: 70 | Iteration number: [310/393] 78% | Training loss: 0.6921917140483856
Epoch: 70 | Iteration number: [320/393] 81% | Training loss: 0.6921470263972879
Epoch: 70 | Iteration number: [330/393] 83% | Training loss: 0.6920743324539879
Epoch: 70 | Iteration number: [340/393] 86% | Training loss: 0.6920376037850099
Epoch: 70 | Iteration number: [350/393] 89% | Training loss: 0.6919769387585776
Epoch: 70 | Iteration number: [360/393] 91% | Training loss: 0.6919548233350118
Epoch: 70 | Iteration number: [370/393] 94% | Training loss: 0.6918988878662522
Epoch: 70 | Iteration number: [380/393] 96% | Training loss: 0.6918577798103032
Epoch: 70 | Iteration number: [390/393] 99% | Training loss: 0.6918441894726876

 End of epoch: 70 | Train Loss: 0.6900897459826093 | Training Time: 67 

 End of epoch: 70 | Eval Loss: 0.6903993998255048 | Evaluating Time: 17 
Epoch: 71 | Iteration number: [10/393] 2% | Training loss: 0.7597563207149506
Epoch: 71 | Iteration number: [20/393] 5% | Training loss: 0.7244403570890426
Epoch: 71 | Iteration number: [30/393] 7% | Training loss: 0.7132613221804301
Epoch: 71 | Iteration number: [40/393] 10% | Training loss: 0.707298731803894
Epoch: 71 | Iteration number: [50/393] 12% | Training loss: 0.7037485706806182
Epoch: 71 | Iteration number: [60/393] 15% | Training loss: 0.7016113926966985
Epoch: 71 | Iteration number: [70/393] 17% | Training loss: 0.6999347380229405
Epoch: 71 | Iteration number: [80/393] 20% | Training loss: 0.6987602703273297
Epoch: 71 | Iteration number: [90/393] 22% | Training loss: 0.6977719763914744
Epoch: 71 | Iteration number: [100/393] 25% | Training loss: 0.6970289653539657
Epoch: 71 | Iteration number: [110/393] 27% | Training loss: 0.696302245421843
Epoch: 71 | Iteration number: [120/393] 30% | Training loss: 0.6958023543159167
Epoch: 71 | Iteration number: [130/393] 33% | Training loss: 0.6952958285808564
Epoch: 71 | Iteration number: [140/393] 35% | Training loss: 0.6949428541319711
Epoch: 71 | Iteration number: [150/393] 38% | Training loss: 0.6946566712856292
Epoch: 71 | Iteration number: [160/393] 40% | Training loss: 0.6944472055882216
Epoch: 71 | Iteration number: [170/393] 43% | Training loss: 0.694139308087966
Epoch: 71 | Iteration number: [180/393] 45% | Training loss: 0.6939057625002332
Epoch: 71 | Iteration number: [190/393] 48% | Training loss: 0.6937674390642267
Epoch: 71 | Iteration number: [200/393] 50% | Training loss: 0.6935704866051674
Epoch: 71 | Iteration number: [210/393] 53% | Training loss: 0.6934534104097457
Epoch: 71 | Iteration number: [220/393] 55% | Training loss: 0.6932900854132392
Epoch: 71 | Iteration number: [230/393] 58% | Training loss: 0.693133140646893
Epoch: 71 | Iteration number: [240/393] 61% | Training loss: 0.6930245118836562
Epoch: 71 | Iteration number: [250/393] 63% | Training loss: 0.6929524347782136
Epoch: 71 | Iteration number: [260/393] 66% | Training loss: 0.692844820022583
Epoch: 71 | Iteration number: [270/393] 68% | Training loss: 0.6926941997475095
Epoch: 71 | Iteration number: [280/393] 71% | Training loss: 0.692647913311209
Epoch: 71 | Iteration number: [290/393] 73% | Training loss: 0.6925068257183864
Epoch: 71 | Iteration number: [300/393] 76% | Training loss: 0.6924045932292938
Epoch: 71 | Iteration number: [310/393] 78% | Training loss: 0.6923205212239296
Epoch: 71 | Iteration number: [320/393] 81% | Training loss: 0.6922569215297699
Epoch: 71 | Iteration number: [330/393] 83% | Training loss: 0.6921655510411118
Epoch: 71 | Iteration number: [340/393] 86% | Training loss: 0.6921084072659998
Epoch: 71 | Iteration number: [350/393] 89% | Training loss: 0.6920657515525818
Epoch: 71 | Iteration number: [360/393] 91% | Training loss: 0.6920147493481636
Epoch: 71 | Iteration number: [370/393] 94% | Training loss: 0.6919543142254289
Epoch: 71 | Iteration number: [380/393] 96% | Training loss: 0.6919216212473418
Epoch: 71 | Iteration number: [390/393] 99% | Training loss: 0.6918685644100874

 End of epoch: 71 | Train Loss: 0.690105732918999 | Training Time: 67 

 End of epoch: 71 | Eval Loss: 0.6903463431767055 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/393] 2% | Training loss: 0.75940802693367
Epoch: 72 | Iteration number: [20/393] 5% | Training loss: 0.724495193362236
Epoch: 72 | Iteration number: [30/393] 7% | Training loss: 0.7132297456264496
Epoch: 72 | Iteration number: [40/393] 10% | Training loss: 0.7073573112487793
Epoch: 72 | Iteration number: [50/393] 12% | Training loss: 0.7039577054977417
Epoch: 72 | Iteration number: [60/393] 15% | Training loss: 0.7017143438259761
Epoch: 72 | Iteration number: [70/393] 17% | Training loss: 0.7000549060957773
Epoch: 72 | Iteration number: [80/393] 20% | Training loss: 0.6989247612655163
Epoch: 72 | Iteration number: [90/393] 22% | Training loss: 0.6978004422452715
Epoch: 72 | Iteration number: [100/393] 25% | Training loss: 0.6970620477199554
Epoch: 72 | Iteration number: [110/393] 27% | Training loss: 0.6965060510418631
Epoch: 72 | Iteration number: [120/393] 30% | Training loss: 0.6960288668672244
Epoch: 72 | Iteration number: [130/393] 33% | Training loss: 0.6955568740001091
Epoch: 72 | Iteration number: [140/393] 35% | Training loss: 0.6951931072132927
Epoch: 72 | Iteration number: [150/393] 38% | Training loss: 0.6948505381743113
Epoch: 72 | Iteration number: [160/393] 40% | Training loss: 0.6945495154708624
Epoch: 72 | Iteration number: [170/393] 43% | Training loss: 0.6942483533831204
Epoch: 72 | Iteration number: [180/393] 45% | Training loss: 0.6940913660658731
Epoch: 72 | Iteration number: [190/393] 48% | Training loss: 0.6937786017593585
Epoch: 72 | Iteration number: [200/393] 50% | Training loss: 0.6935637357831002
Epoch: 72 | Iteration number: [210/393] 53% | Training loss: 0.6934473298844837
Epoch: 72 | Iteration number: [220/393] 55% | Training loss: 0.6932983040809632
Epoch: 72 | Iteration number: [230/393] 58% | Training loss: 0.6931128900984059
Epoch: 72 | Iteration number: [240/393] 61% | Training loss: 0.6930355690419674
Epoch: 72 | Iteration number: [250/393] 63% | Training loss: 0.6929453811645507
Epoch: 72 | Iteration number: [260/393] 66% | Training loss: 0.692824828166228
Epoch: 72 | Iteration number: [270/393] 68% | Training loss: 0.6927207562658522
Epoch: 72 | Iteration number: [280/393] 71% | Training loss: 0.6926191332084792
Epoch: 72 | Iteration number: [290/393] 73% | Training loss: 0.6925300497433234
Epoch: 72 | Iteration number: [300/393] 76% | Training loss: 0.6924729835987091
Epoch: 72 | Iteration number: [310/393] 78% | Training loss: 0.6924302035762417
Epoch: 72 | Iteration number: [320/393] 81% | Training loss: 0.6923038922250271
Epoch: 72 | Iteration number: [330/393] 83% | Training loss: 0.6922095569697293
Epoch: 72 | Iteration number: [340/393] 86% | Training loss: 0.6921742279739941
Epoch: 72 | Iteration number: [350/393] 89% | Training loss: 0.6921152230671473
Epoch: 72 | Iteration number: [360/393] 91% | Training loss: 0.6920822160111533
Epoch: 72 | Iteration number: [370/393] 94% | Training loss: 0.6920499945009077
Epoch: 72 | Iteration number: [380/393] 96% | Training loss: 0.6920040987039867
Epoch: 72 | Iteration number: [390/393] 99% | Training loss: 0.691957647831012

 End of epoch: 72 | Train Loss: 0.6901898751125384 | Training Time: 67 

 End of epoch: 72 | Eval Loss: 0.6903708637977133 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/393] 2% | Training loss: 0.7591558575630188
Epoch: 73 | Iteration number: [20/393] 5% | Training loss: 0.7245507717132569
Epoch: 73 | Iteration number: [30/393] 7% | Training loss: 0.713040542602539
Epoch: 73 | Iteration number: [40/393] 10% | Training loss: 0.7071451365947723
Epoch: 73 | Iteration number: [50/393] 12% | Training loss: 0.7037036800384522
Epoch: 73 | Iteration number: [60/393] 15% | Training loss: 0.7015576044718425
Epoch: 73 | Iteration number: [70/393] 17% | Training loss: 0.6999507963657379
Epoch: 73 | Iteration number: [80/393] 20% | Training loss: 0.6986957646906375
Epoch: 73 | Iteration number: [90/393] 22% | Training loss: 0.69789956079589
Epoch: 73 | Iteration number: [100/393] 25% | Training loss: 0.697161745429039
Epoch: 73 | Iteration number: [110/393] 27% | Training loss: 0.6964151057330045
Epoch: 73 | Iteration number: [120/393] 30% | Training loss: 0.695917276541392
Epoch: 73 | Iteration number: [130/393] 33% | Training loss: 0.6953506799844595
Epoch: 73 | Iteration number: [140/393] 35% | Training loss: 0.6950022105659758
Epoch: 73 | Iteration number: [150/393] 38% | Training loss: 0.6946395417054494
Epoch: 73 | Iteration number: [160/393] 40% | Training loss: 0.6944978572428226
Epoch: 73 | Iteration number: [170/393] 43% | Training loss: 0.6942767721765182
Epoch: 73 | Iteration number: [180/393] 45% | Training loss: 0.6940699802504645
Epoch: 73 | Iteration number: [190/393] 48% | Training loss: 0.6939137364688672
Epoch: 73 | Iteration number: [200/393] 50% | Training loss: 0.6937579110264778
Epoch: 73 | Iteration number: [210/393] 53% | Training loss: 0.6936155568985712
Epoch: 73 | Iteration number: [220/393] 55% | Training loss: 0.6934601802717556
Epoch: 73 | Iteration number: [230/393] 58% | Training loss: 0.6932760925396629
Epoch: 73 | Iteration number: [240/393] 61% | Training loss: 0.6931454842289289
Epoch: 73 | Iteration number: [250/393] 63% | Training loss: 0.6930027129650116
Epoch: 73 | Iteration number: [260/393] 66% | Training loss: 0.6928649936731045
Epoch: 73 | Iteration number: [270/393] 68% | Training loss: 0.6926913504247312
Epoch: 73 | Iteration number: [280/393] 71% | Training loss: 0.6925475407923971
Epoch: 73 | Iteration number: [290/393] 73% | Training loss: 0.69247833572585
Epoch: 73 | Iteration number: [300/393] 76% | Training loss: 0.6923672338326772
Epoch: 73 | Iteration number: [310/393] 78% | Training loss: 0.6923250475237447
Epoch: 73 | Iteration number: [320/393] 81% | Training loss: 0.6922664999961853
Epoch: 73 | Iteration number: [330/393] 83% | Training loss: 0.6922245489828515
Epoch: 73 | Iteration number: [340/393] 86% | Training loss: 0.6921712395022898
Epoch: 73 | Iteration number: [350/393] 89% | Training loss: 0.6920983595507485
Epoch: 73 | Iteration number: [360/393] 91% | Training loss: 0.692080050541295
Epoch: 73 | Iteration number: [370/393] 94% | Training loss: 0.692032128572464
Epoch: 73 | Iteration number: [380/393] 96% | Training loss: 0.6919885974181326
Epoch: 73 | Iteration number: [390/393] 99% | Training loss: 0.6919532092717978

 End of epoch: 73 | Train Loss: 0.6901787226740034 | Training Time: 67 

 End of epoch: 73 | Eval Loss: 0.6903215658907987 | Evaluating Time: 17 
Epoch: 74 | Iteration number: [10/393] 2% | Training loss: 0.7597328960895539
Epoch: 74 | Iteration number: [20/393] 5% | Training loss: 0.7248603850603104
Epoch: 74 | Iteration number: [30/393] 7% | Training loss: 0.7135159055391948
Epoch: 74 | Iteration number: [40/393] 10% | Training loss: 0.7075040087103843
Epoch: 74 | Iteration number: [50/393] 12% | Training loss: 0.7042691826820373
Epoch: 74 | Iteration number: [60/393] 15% | Training loss: 0.7019311894973119
Epoch: 74 | Iteration number: [70/393] 17% | Training loss: 0.700371275629316
Epoch: 74 | Iteration number: [80/393] 20% | Training loss: 0.6990105792880058
Epoch: 74 | Iteration number: [90/393] 22% | Training loss: 0.6978486537933349
Epoch: 74 | Iteration number: [100/393] 25% | Training loss: 0.6970630526542664
Epoch: 74 | Iteration number: [110/393] 27% | Training loss: 0.6964219879020345
Epoch: 74 | Iteration number: [120/393] 30% | Training loss: 0.6958645050724347
Epoch: 74 | Iteration number: [130/393] 33% | Training loss: 0.6954014209600595
Epoch: 74 | Iteration number: [140/393] 35% | Training loss: 0.6949345695120948
Epoch: 74 | Iteration number: [150/393] 38% | Training loss: 0.6946360186735789
Epoch: 74 | Iteration number: [160/393] 40% | Training loss: 0.6943848896771669
Epoch: 74 | Iteration number: [170/393] 43% | Training loss: 0.6941663079402026
Epoch: 74 | Iteration number: [180/393] 45% | Training loss: 0.6939610865381028
Epoch: 74 | Iteration number: [190/393] 48% | Training loss: 0.6937056497523659
Epoch: 74 | Iteration number: [200/393] 50% | Training loss: 0.6935086160898208
Epoch: 74 | Iteration number: [210/393] 53% | Training loss: 0.6933457261040097
Epoch: 74 | Iteration number: [220/393] 55% | Training loss: 0.6932477474212646
Epoch: 74 | Iteration number: [230/393] 58% | Training loss: 0.6931114603643832
Epoch: 74 | Iteration number: [240/393] 61% | Training loss: 0.6930191648503145
Epoch: 74 | Iteration number: [250/393] 63% | Training loss: 0.6929150865077972
Epoch: 74 | Iteration number: [260/393] 66% | Training loss: 0.69280678492326
Epoch: 74 | Iteration number: [270/393] 68% | Training loss: 0.6927092187934452
Epoch: 74 | Iteration number: [280/393] 71% | Training loss: 0.6925986979688917
Epoch: 74 | Iteration number: [290/393] 73% | Training loss: 0.692477756122063
Epoch: 74 | Iteration number: [300/393] 76% | Training loss: 0.6923715257644654
Epoch: 74 | Iteration number: [310/393] 78% | Training loss: 0.6923207829075475
Epoch: 74 | Iteration number: [320/393] 81% | Training loss: 0.6922492617741227
Epoch: 74 | Iteration number: [330/393] 83% | Training loss: 0.6922286376808628
Epoch: 74 | Iteration number: [340/393] 86% | Training loss: 0.6921726705396877
Epoch: 74 | Iteration number: [350/393] 89% | Training loss: 0.6921037529196058
Epoch: 74 | Iteration number: [360/393] 91% | Training loss: 0.6920494928956031
Epoch: 74 | Iteration number: [370/393] 94% | Training loss: 0.6919767911369736
Epoch: 74 | Iteration number: [380/393] 96% | Training loss: 0.6919360992155577
Epoch: 74 | Iteration number: [390/393] 99% | Training loss: 0.6918794381312835

 End of epoch: 74 | Train Loss: 0.6901141891952689 | Training Time: 67 

 End of epoch: 74 | Eval Loss: 0.6903565282724342 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/393] 2% | Training loss: 0.7601251065731048
Epoch: 75 | Iteration number: [20/393] 5% | Training loss: 0.7252517074346543
Epoch: 75 | Iteration number: [30/393] 7% | Training loss: 0.713462100426356
Epoch: 75 | Iteration number: [40/393] 10% | Training loss: 0.7078516736626626
Epoch: 75 | Iteration number: [50/393] 12% | Training loss: 0.7043409466743469
Epoch: 75 | Iteration number: [60/393] 15% | Training loss: 0.7021292964617412
Epoch: 75 | Iteration number: [70/393] 17% | Training loss: 0.7002561833177294
Epoch: 75 | Iteration number: [80/393] 20% | Training loss: 0.698961702734232
Epoch: 75 | Iteration number: [90/393] 22% | Training loss: 0.6979923480086856
Epoch: 75 | Iteration number: [100/393] 25% | Training loss: 0.6972053128480912
Epoch: 75 | Iteration number: [110/393] 27% | Training loss: 0.6965446266261014
Epoch: 75 | Iteration number: [120/393] 30% | Training loss: 0.6959967230757077
Epoch: 75 | Iteration number: [130/393] 33% | Training loss: 0.695504813010876
Epoch: 75 | Iteration number: [140/393] 35% | Training loss: 0.695129570364952
Epoch: 75 | Iteration number: [150/393] 38% | Training loss: 0.6947642354170481
Epoch: 75 | Iteration number: [160/393] 40% | Training loss: 0.6945080686360597
Epoch: 75 | Iteration number: [170/393] 43% | Training loss: 0.6941866780028624
Epoch: 75 | Iteration number: [180/393] 45% | Training loss: 0.6939616935120688
Epoch: 75 | Iteration number: [190/393] 48% | Training loss: 0.6936863892956784
Epoch: 75 | Iteration number: [200/393] 50% | Training loss: 0.6934819823503494
Epoch: 75 | Iteration number: [210/393] 53% | Training loss: 0.6933527387323833
Epoch: 75 | Iteration number: [220/393] 55% | Training loss: 0.6931692505424673
Epoch: 75 | Iteration number: [230/393] 58% | Training loss: 0.6930897710116013
Epoch: 75 | Iteration number: [240/393] 61% | Training loss: 0.6929666429758072
Epoch: 75 | Iteration number: [250/393] 63% | Training loss: 0.6928568334579468
Epoch: 75 | Iteration number: [260/393] 66% | Training loss: 0.6927425716932003
Epoch: 75 | Iteration number: [270/393] 68% | Training loss: 0.6926182791038796
Epoch: 75 | Iteration number: [280/393] 71% | Training loss: 0.6925313470619066
Epoch: 75 | Iteration number: [290/393] 73% | Training loss: 0.6924489058297256
Epoch: 75 | Iteration number: [300/393] 76% | Training loss: 0.6924054606755574
Epoch: 75 | Iteration number: [310/393] 78% | Training loss: 0.6923417100983281
Epoch: 75 | Iteration number: [320/393] 81% | Training loss: 0.6922592338174581
Epoch: 75 | Iteration number: [330/393] 83% | Training loss: 0.6921985665957133
Epoch: 75 | Iteration number: [340/393] 86% | Training loss: 0.6921491619418649
Epoch: 75 | Iteration number: [350/393] 89% | Training loss: 0.6921055383341653
Epoch: 75 | Iteration number: [360/393] 91% | Training loss: 0.6920472813977135
Epoch: 75 | Iteration number: [370/393] 94% | Training loss: 0.6920022502138808
Epoch: 75 | Iteration number: [380/393] 96% | Training loss: 0.6919540511934381
Epoch: 75 | Iteration number: [390/393] 99% | Training loss: 0.691884624499541

 End of epoch: 75 | Train Loss: 0.6901192149436505 | Training Time: 67 

 End of epoch: 75 | Eval Loss: 0.6903257528129889 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/393] 2% | Training loss: 0.7590850412845611
Epoch: 76 | Iteration number: [20/393] 5% | Training loss: 0.7245569735765457
Epoch: 76 | Iteration number: [30/393] 7% | Training loss: 0.7131243447462717
Epoch: 76 | Iteration number: [40/393] 10% | Training loss: 0.7074384585022926
Epoch: 76 | Iteration number: [50/393] 12% | Training loss: 0.7040784358978271
Epoch: 76 | Iteration number: [60/393] 15% | Training loss: 0.7015489310026168
Epoch: 76 | Iteration number: [70/393] 17% | Training loss: 0.6998180789606911
Epoch: 76 | Iteration number: [80/393] 20% | Training loss: 0.6985519774258137
Epoch: 76 | Iteration number: [90/393] 22% | Training loss: 0.6977555069658491
Epoch: 76 | Iteration number: [100/393] 25% | Training loss: 0.6971127021312714
Epoch: 76 | Iteration number: [110/393] 27% | Training loss: 0.6964194996790453
Epoch: 76 | Iteration number: [120/393] 30% | Training loss: 0.6959026917815209
Epoch: 76 | Iteration number: [130/393] 33% | Training loss: 0.6954855547501491
Epoch: 76 | Iteration number: [140/393] 35% | Training loss: 0.6950233323233468
Epoch: 76 | Iteration number: [150/393] 38% | Training loss: 0.6946355334917704
Epoch: 76 | Iteration number: [160/393] 40% | Training loss: 0.6943434033542871
Epoch: 76 | Iteration number: [170/393] 43% | Training loss: 0.6941442976979648
Epoch: 76 | Iteration number: [180/393] 45% | Training loss: 0.6939064178201887
Epoch: 76 | Iteration number: [190/393] 48% | Training loss: 0.6937487244606018
Epoch: 76 | Iteration number: [200/393] 50% | Training loss: 0.6935898476839065
Epoch: 76 | Iteration number: [210/393] 53% | Training loss: 0.6934652725855509
Epoch: 76 | Iteration number: [220/393] 55% | Training loss: 0.693304308977994
Epoch: 76 | Iteration number: [230/393] 58% | Training loss: 0.6931482239909794
Epoch: 76 | Iteration number: [240/393] 61% | Training loss: 0.6930213652551174
Epoch: 76 | Iteration number: [250/393] 63% | Training loss: 0.6929035942554473
Epoch: 76 | Iteration number: [260/393] 66% | Training loss: 0.6928193871791546
Epoch: 76 | Iteration number: [270/393] 68% | Training loss: 0.6927357327055048
Epoch: 76 | Iteration number: [280/393] 71% | Training loss: 0.6926660188606807
Epoch: 76 | Iteration number: [290/393] 73% | Training loss: 0.6925525180224714
Epoch: 76 | Iteration number: [300/393] 76% | Training loss: 0.6924639137585958
Epoch: 76 | Iteration number: [310/393] 78% | Training loss: 0.6923808988063566
Epoch: 76 | Iteration number: [320/393] 81% | Training loss: 0.6923139160498977
Epoch: 76 | Iteration number: [330/393] 83% | Training loss: 0.6922377640550786
Epoch: 76 | Iteration number: [340/393] 86% | Training loss: 0.6921720054219751
Epoch: 76 | Iteration number: [350/393] 89% | Training loss: 0.6921092128753662
Epoch: 76 | Iteration number: [360/393] 91% | Training loss: 0.6920430598987474
Epoch: 76 | Iteration number: [370/393] 94% | Training loss: 0.6920198649973482
Epoch: 76 | Iteration number: [380/393] 96% | Training loss: 0.6919825345277786
Epoch: 76 | Iteration number: [390/393] 99% | Training loss: 0.6919207339103405

 End of epoch: 76 | Train Loss: 0.6901388541432737 | Training Time: 67 

 End of epoch: 76 | Eval Loss: 0.6903723672944673 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/393] 2% | Training loss: 0.7597623288631439
Epoch: 77 | Iteration number: [20/393] 5% | Training loss: 0.7250824511051178
Epoch: 77 | Iteration number: [30/393] 7% | Training loss: 0.7133381168047587
Epoch: 77 | Iteration number: [40/393] 10% | Training loss: 0.7074374869465828
Epoch: 77 | Iteration number: [50/393] 12% | Training loss: 0.7040533757209778
Epoch: 77 | Iteration number: [60/393] 15% | Training loss: 0.7018838038047155
Epoch: 77 | Iteration number: [70/393] 17% | Training loss: 0.7002461825098311
Epoch: 77 | Iteration number: [80/393] 20% | Training loss: 0.6990283884108066
Epoch: 77 | Iteration number: [90/393] 22% | Training loss: 0.6980231483777364
Epoch: 77 | Iteration number: [100/393] 25% | Training loss: 0.6971161544322968
Epoch: 77 | Iteration number: [110/393] 27% | Training loss: 0.6965828239917755
Epoch: 77 | Iteration number: [120/393] 30% | Training loss: 0.6960616971055666
Epoch: 77 | Iteration number: [130/393] 33% | Training loss: 0.6956656089195838
Epoch: 77 | Iteration number: [140/393] 35% | Training loss: 0.6952174518789563
Epoch: 77 | Iteration number: [150/393] 38% | Training loss: 0.6948661589622498
Epoch: 77 | Iteration number: [160/393] 40% | Training loss: 0.6946031644940376
Epoch: 77 | Iteration number: [170/393] 43% | Training loss: 0.6943642798592062
Epoch: 77 | Iteration number: [180/393] 45% | Training loss: 0.6940902845727073
Epoch: 77 | Iteration number: [190/393] 48% | Training loss: 0.6938598538699903
Epoch: 77 | Iteration number: [200/393] 50% | Training loss: 0.6937171274423599
Epoch: 77 | Iteration number: [210/393] 53% | Training loss: 0.6935323289462498
Epoch: 77 | Iteration number: [220/393] 55% | Training loss: 0.6934061592275446
Epoch: 77 | Iteration number: [230/393] 58% | Training loss: 0.6932511798713519
Epoch: 77 | Iteration number: [240/393] 61% | Training loss: 0.6930920168757438
Epoch: 77 | Iteration number: [250/393] 63% | Training loss: 0.6929613211154938
Epoch: 77 | Iteration number: [260/393] 66% | Training loss: 0.6928826327507313
Epoch: 77 | Iteration number: [270/393] 68% | Training loss: 0.6928084154923757
Epoch: 77 | Iteration number: [280/393] 71% | Training loss: 0.6927244773932866
Epoch: 77 | Iteration number: [290/393] 73% | Training loss: 0.6926017337831958
Epoch: 77 | Iteration number: [300/393] 76% | Training loss: 0.6924894414345424
Epoch: 77 | Iteration number: [310/393] 78% | Training loss: 0.6924055051419042
Epoch: 77 | Iteration number: [320/393] 81% | Training loss: 0.6923319213092327
Epoch: 77 | Iteration number: [330/393] 83% | Training loss: 0.6922427215359428
Epoch: 77 | Iteration number: [340/393] 86% | Training loss: 0.6921882277025896
Epoch: 77 | Iteration number: [350/393] 89% | Training loss: 0.692097955771855
Epoch: 77 | Iteration number: [360/393] 91% | Training loss: 0.692042603260941
Epoch: 77 | Iteration number: [370/393] 94% | Training loss: 0.6919636455742089
Epoch: 77 | Iteration number: [380/393] 96% | Training loss: 0.6919192088277717
Epoch: 77 | Iteration number: [390/393] 99% | Training loss: 0.6918618818124135

 End of epoch: 77 | Train Loss: 0.6900939254360344 | Training Time: 67 

 End of epoch: 77 | Eval Loss: 0.6903442448499252 | Evaluating Time: 18 
Epoch: 78 | Iteration number: [10/393] 2% | Training loss: 0.7598839521408081
Epoch: 78 | Iteration number: [20/393] 5% | Training loss: 0.7253566801548004
Epoch: 78 | Iteration number: [30/393] 7% | Training loss: 0.7133867383003235
Epoch: 78 | Iteration number: [40/393] 10% | Training loss: 0.7075917959213257
Epoch: 78 | Iteration number: [50/393] 12% | Training loss: 0.7040398967266083
Epoch: 78 | Iteration number: [60/393] 15% | Training loss: 0.7018023739258449
Epoch: 78 | Iteration number: [70/393] 17% | Training loss: 0.7002016518797193
Epoch: 78 | Iteration number: [80/393] 20% | Training loss: 0.69896335080266
Epoch: 78 | Iteration number: [90/393] 22% | Training loss: 0.6978631913661957
Epoch: 78 | Iteration number: [100/393] 25% | Training loss: 0.6970376461744309
Epoch: 78 | Iteration number: [110/393] 27% | Training loss: 0.696429786898873
Epoch: 78 | Iteration number: [120/393] 30% | Training loss: 0.6958552236358325
Epoch: 78 | Iteration number: [130/393] 33% | Training loss: 0.6954042347577902
Epoch: 78 | Iteration number: [140/393] 35% | Training loss: 0.6950104990175792
Epoch: 78 | Iteration number: [150/393] 38% | Training loss: 0.694699577887853
Epoch: 78 | Iteration number: [160/393] 40% | Training loss: 0.6943905301392078
Epoch: 78 | Iteration number: [170/393] 43% | Training loss: 0.6941326386788312
Epoch: 78 | Iteration number: [180/393] 45% | Training loss: 0.6939336700571908
Epoch: 78 | Iteration number: [190/393] 48% | Training loss: 0.6937338182800694
Epoch: 78 | Iteration number: [200/393] 50% | Training loss: 0.6936006310582161
Epoch: 78 | Iteration number: [210/393] 53% | Training loss: 0.6934367704959142
Epoch: 78 | Iteration number: [220/393] 55% | Training loss: 0.6932881929657676
Epoch: 78 | Iteration number: [230/393] 58% | Training loss: 0.693130336118781
Epoch: 78 | Iteration number: [240/393] 61% | Training loss: 0.6929510911305745
Epoch: 78 | Iteration number: [250/393] 63% | Training loss: 0.6928890466690063
Epoch: 78 | Iteration number: [260/393] 66% | Training loss: 0.6927446904090735
Epoch: 78 | Iteration number: [270/393] 68% | Training loss: 0.6926785990043923
Epoch: 78 | Iteration number: [280/393] 71% | Training loss: 0.6925456855978285
Epoch: 78 | Iteration number: [290/393] 73% | Training loss: 0.6924318552017212
Epoch: 78 | Iteration number: [300/393] 76% | Training loss: 0.6923409752051035
Epoch: 78 | Iteration number: [310/393] 78% | Training loss: 0.6922939492810157
Epoch: 78 | Iteration number: [320/393] 81% | Training loss: 0.6922274719923734
Epoch: 78 | Iteration number: [330/393] 83% | Training loss: 0.6921858915776917
Epoch: 78 | Iteration number: [340/393] 86% | Training loss: 0.6921169231919682
Epoch: 78 | Iteration number: [350/393] 89% | Training loss: 0.6920560128348214
Epoch: 78 | Iteration number: [360/393] 91% | Training loss: 0.6919904538326793
Epoch: 78 | Iteration number: [370/393] 94% | Training loss: 0.6919392091196936
Epoch: 78 | Iteration number: [380/393] 96% | Training loss: 0.691855537891388
Epoch: 78 | Iteration number: [390/393] 99% | Training loss: 0.691829299621093

 End of epoch: 78 | Train Loss: 0.690059972173385 | Training Time: 68 

 End of epoch: 78 | Eval Loss: 0.6903832700787759 | Evaluating Time: 17 
Epoch: 79 | Iteration number: [10/393] 2% | Training loss: 0.7588035285472869
Epoch: 79 | Iteration number: [20/393] 5% | Training loss: 0.7241545140743255
Epoch: 79 | Iteration number: [30/393] 7% | Training loss: 0.7126410802205404
Epoch: 79 | Iteration number: [40/393] 10% | Training loss: 0.7069423899054528
Epoch: 79 | Iteration number: [50/393] 12% | Training loss: 0.7035699498653412
Epoch: 79 | Iteration number: [60/393] 15% | Training loss: 0.7014817694822947
Epoch: 79 | Iteration number: [70/393] 17% | Training loss: 0.6997950783797673
Epoch: 79 | Iteration number: [80/393] 20% | Training loss: 0.698523896932602
Epoch: 79 | Iteration number: [90/393] 22% | Training loss: 0.6976451489660475
Epoch: 79 | Iteration number: [100/393] 25% | Training loss: 0.6968612855672837
Epoch: 79 | Iteration number: [110/393] 27% | Training loss: 0.6962698530067097
Epoch: 79 | Iteration number: [120/393] 30% | Training loss: 0.6957796951134999
Epoch: 79 | Iteration number: [130/393] 33% | Training loss: 0.695278662443161
Epoch: 79 | Iteration number: [140/393] 35% | Training loss: 0.6949132536138807
Epoch: 79 | Iteration number: [150/393] 38% | Training loss: 0.6946260197957357
Epoch: 79 | Iteration number: [160/393] 40% | Training loss: 0.6943537209182977
Epoch: 79 | Iteration number: [170/393] 43% | Training loss: 0.6940983593463897
Epoch: 79 | Iteration number: [180/393] 45% | Training loss: 0.6938707384798262
Epoch: 79 | Iteration number: [190/393] 48% | Training loss: 0.6937121447763945
Epoch: 79 | Iteration number: [200/393] 50% | Training loss: 0.6934815329313279
Epoch: 79 | Iteration number: [210/393] 53% | Training loss: 0.6933509227775392
Epoch: 79 | Iteration number: [220/393] 55% | Training loss: 0.6932479752735659
Epoch: 79 | Iteration number: [230/393] 58% | Training loss: 0.6931406868540723
Epoch: 79 | Iteration number: [240/393] 61% | Training loss: 0.6929926646252473
Epoch: 79 | Iteration number: [250/393] 63% | Training loss: 0.6928523275852203
Epoch: 79 | Iteration number: [260/393] 66% | Training loss: 0.692753520149451
Epoch: 79 | Iteration number: [270/393] 68% | Training loss: 0.6926609056967276
Epoch: 79 | Iteration number: [280/393] 71% | Training loss: 0.6925946227141789
Epoch: 79 | Iteration number: [290/393] 73% | Training loss: 0.6925137269085851
Epoch: 79 | Iteration number: [300/393] 76% | Training loss: 0.6924258055289586
Epoch: 79 | Iteration number: [310/393] 78% | Training loss: 0.6923599548878209
Epoch: 79 | Iteration number: [320/393] 81% | Training loss: 0.6922626858577132
Epoch: 79 | Iteration number: [330/393] 83% | Training loss: 0.6921902445229617
Epoch: 79 | Iteration number: [340/393] 86% | Training loss: 0.6921299028045991
Epoch: 79 | Iteration number: [350/393] 89% | Training loss: 0.6920747421469007
Epoch: 79 | Iteration number: [360/393] 91% | Training loss: 0.6920607666174571
Epoch: 79 | Iteration number: [370/393] 94% | Training loss: 0.6919765403141847
Epoch: 79 | Iteration number: [380/393] 96% | Training loss: 0.6919241448766307
Epoch: 79 | Iteration number: [390/393] 99% | Training loss: 0.691876726425611

 End of epoch: 79 | Train Loss: 0.6900981990738982 | Training Time: 67 

 End of epoch: 79 | Eval Loss: 0.690301428035814 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/393] 2% | Training loss: 0.7588931143283844
Epoch: 80 | Iteration number: [20/393] 5% | Training loss: 0.7242103219032288
Epoch: 80 | Iteration number: [30/393] 7% | Training loss: 0.7126672645409902
Epoch: 80 | Iteration number: [40/393] 10% | Training loss: 0.707246595621109
Epoch: 80 | Iteration number: [50/393] 12% | Training loss: 0.7039932370185852
Epoch: 80 | Iteration number: [60/393] 15% | Training loss: 0.7016782730817794
Epoch: 80 | Iteration number: [70/393] 17% | Training loss: 0.6998639387743814
Epoch: 80 | Iteration number: [80/393] 20% | Training loss: 0.6986342243850231
Epoch: 80 | Iteration number: [90/393] 22% | Training loss: 0.6976931360032823
Epoch: 80 | Iteration number: [100/393] 25% | Training loss: 0.6969322556257248
Epoch: 80 | Iteration number: [110/393] 27% | Training loss: 0.6963291449980302
Epoch: 80 | Iteration number: [120/393] 30% | Training loss: 0.6958682010571162
Epoch: 80 | Iteration number: [130/393] 33% | Training loss: 0.6955322063886202
Epoch: 80 | Iteration number: [140/393] 35% | Training loss: 0.695108778987612
Epoch: 80 | Iteration number: [150/393] 38% | Training loss: 0.6947949266433716
Epoch: 80 | Iteration number: [160/393] 40% | Training loss: 0.6945399824529886
Epoch: 80 | Iteration number: [170/393] 43% | Training loss: 0.6942620298441718
Epoch: 80 | Iteration number: [180/393] 45% | Training loss: 0.694015402926339
Epoch: 80 | Iteration number: [190/393] 48% | Training loss: 0.6938605430879091
Epoch: 80 | Iteration number: [200/393] 50% | Training loss: 0.6936595687270164
Epoch: 80 | Iteration number: [210/393] 53% | Training loss: 0.6934674487227486
Epoch: 80 | Iteration number: [220/393] 55% | Training loss: 0.6932847302068363
Epoch: 80 | Iteration number: [230/393] 58% | Training loss: 0.6930728847565858
Epoch: 80 | Iteration number: [240/393] 61% | Training loss: 0.6929461960991223
Epoch: 80 | Iteration number: [250/393] 63% | Training loss: 0.6928341443538666
Epoch: 80 | Iteration number: [260/393] 66% | Training loss: 0.6927429873209733
Epoch: 80 | Iteration number: [270/393] 68% | Training loss: 0.6926789475811852
Epoch: 80 | Iteration number: [280/393] 71% | Training loss: 0.6925728595682553
Epoch: 80 | Iteration number: [290/393] 73% | Training loss: 0.6924882843576629
Epoch: 80 | Iteration number: [300/393] 76% | Training loss: 0.6924125734965006
Epoch: 80 | Iteration number: [310/393] 78% | Training loss: 0.6923319664693648
Epoch: 80 | Iteration number: [320/393] 81% | Training loss: 0.692289943061769
Epoch: 80 | Iteration number: [330/393] 83% | Training loss: 0.6922046366966133
Epoch: 80 | Iteration number: [340/393] 86% | Training loss: 0.692161044829032
Epoch: 80 | Iteration number: [350/393] 89% | Training loss: 0.6920952495506831
Epoch: 80 | Iteration number: [360/393] 91% | Training loss: 0.6920175049040053
Epoch: 80 | Iteration number: [370/393] 94% | Training loss: 0.6919703235497345
Epoch: 80 | Iteration number: [380/393] 96% | Training loss: 0.6919160706432242
Epoch: 80 | Iteration number: [390/393] 99% | Training loss: 0.6918521790932386

 End of epoch: 80 | Train Loss: 0.6900786325221754 | Training Time: 67 

 End of epoch: 80 | Eval Loss: 0.6903112749664151 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/393] 2% | Training loss: 0.7585353195667267
Epoch: 81 | Iteration number: [20/393] 5% | Training loss: 0.7231656700372696
Epoch: 81 | Iteration number: [30/393] 7% | Training loss: 0.7121550579865773
Epoch: 81 | Iteration number: [40/393] 10% | Training loss: 0.7065089344978333
Epoch: 81 | Iteration number: [50/393] 12% | Training loss: 0.7031936621665955
Epoch: 81 | Iteration number: [60/393] 15% | Training loss: 0.7012246499458948
Epoch: 81 | Iteration number: [70/393] 17% | Training loss: 0.6993960108075823
Epoch: 81 | Iteration number: [80/393] 20% | Training loss: 0.6982854045927525
Epoch: 81 | Iteration number: [90/393] 22% | Training loss: 0.6974567770957947
Epoch: 81 | Iteration number: [100/393] 25% | Training loss: 0.6967807465791702
Epoch: 81 | Iteration number: [110/393] 27% | Training loss: 0.6962418019771576
Epoch: 81 | Iteration number: [120/393] 30% | Training loss: 0.6956943516929944
Epoch: 81 | Iteration number: [130/393] 33% | Training loss: 0.6953341832527747
Epoch: 81 | Iteration number: [140/393] 35% | Training loss: 0.6950179151126317
Epoch: 81 | Iteration number: [150/393] 38% | Training loss: 0.694645816485087
Epoch: 81 | Iteration number: [160/393] 40% | Training loss: 0.6943212751299143
Epoch: 81 | Iteration number: [170/393] 43% | Training loss: 0.6941257473300485
Epoch: 81 | Iteration number: [180/393] 45% | Training loss: 0.6938514553838306
Epoch: 81 | Iteration number: [190/393] 48% | Training loss: 0.6936044994153474
Epoch: 81 | Iteration number: [200/393] 50% | Training loss: 0.6934645745158196
Epoch: 81 | Iteration number: [210/393] 53% | Training loss: 0.6933203910078322
Epoch: 81 | Iteration number: [220/393] 55% | Training loss: 0.6931554106148806
Epoch: 81 | Iteration number: [230/393] 58% | Training loss: 0.6930265084556911
Epoch: 81 | Iteration number: [240/393] 61% | Training loss: 0.6929433998962243
Epoch: 81 | Iteration number: [250/393] 63% | Training loss: 0.6928252971172333
Epoch: 81 | Iteration number: [260/393] 66% | Training loss: 0.6927483854385522
Epoch: 81 | Iteration number: [270/393] 68% | Training loss: 0.6926029008847696
Epoch: 81 | Iteration number: [280/393] 71% | Training loss: 0.6925319216081074
Epoch: 81 | Iteration number: [290/393] 73% | Training loss: 0.692424516842283
Epoch: 81 | Iteration number: [300/393] 76% | Training loss: 0.6923853439092637
Epoch: 81 | Iteration number: [310/393] 78% | Training loss: 0.692306597194364
Epoch: 81 | Iteration number: [320/393] 81% | Training loss: 0.6922171523794531
Epoch: 81 | Iteration number: [330/393] 83% | Training loss: 0.6921487082134593
Epoch: 81 | Iteration number: [340/393] 86% | Training loss: 0.6920477176413816
Epoch: 81 | Iteration number: [350/393] 89% | Training loss: 0.6919771925040654
Epoch: 81 | Iteration number: [360/393] 91% | Training loss: 0.6919312919179599
Epoch: 81 | Iteration number: [370/393] 94% | Training loss: 0.6919142054544912
Epoch: 81 | Iteration number: [380/393] 96% | Training loss: 0.6918913563615398
Epoch: 81 | Iteration number: [390/393] 99% | Training loss: 0.6918475640125764

 End of epoch: 81 | Train Loss: 0.6900806305669342 | Training Time: 67 

 End of epoch: 81 | Eval Loss: 0.6905694117351454 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/393] 2% | Training loss: 0.7591774225234985
Epoch: 82 | Iteration number: [20/393] 5% | Training loss: 0.7246814161539078
Epoch: 82 | Iteration number: [30/393] 7% | Training loss: 0.7131219228108724
Epoch: 82 | Iteration number: [40/393] 10% | Training loss: 0.7073769047856331
Epoch: 82 | Iteration number: [50/393] 12% | Training loss: 0.7040662944316864
Epoch: 82 | Iteration number: [60/393] 15% | Training loss: 0.7016571958859762
Epoch: 82 | Iteration number: [70/393] 17% | Training loss: 0.7000348355088916
Epoch: 82 | Iteration number: [80/393] 20% | Training loss: 0.6987203270196914
Epoch: 82 | Iteration number: [90/393] 22% | Training loss: 0.6976372533374362
Epoch: 82 | Iteration number: [100/393] 25% | Training loss: 0.6968886196613312
Epoch: 82 | Iteration number: [110/393] 27% | Training loss: 0.6962444657629187
Epoch: 82 | Iteration number: [120/393] 30% | Training loss: 0.6956550310055415
Epoch: 82 | Iteration number: [130/393] 33% | Training loss: 0.6951676332033597
Epoch: 82 | Iteration number: [140/393] 35% | Training loss: 0.694809695652553
Epoch: 82 | Iteration number: [150/393] 38% | Training loss: 0.6945715888341268
Epoch: 82 | Iteration number: [160/393] 40% | Training loss: 0.6943953078240156
Epoch: 82 | Iteration number: [170/393] 43% | Training loss: 0.6940927842084099
Epoch: 82 | Iteration number: [180/393] 45% | Training loss: 0.6939005808697807
Epoch: 82 | Iteration number: [190/393] 48% | Training loss: 0.6936639308929443
Epoch: 82 | Iteration number: [200/393] 50% | Training loss: 0.693499396443367
Epoch: 82 | Iteration number: [210/393] 53% | Training loss: 0.6933291474978129
Epoch: 82 | Iteration number: [220/393] 55% | Training loss: 0.6931949666955254
Epoch: 82 | Iteration number: [230/393] 58% | Training loss: 0.6930864984574525
Epoch: 82 | Iteration number: [240/393] 61% | Training loss: 0.6929448994497458
Epoch: 82 | Iteration number: [250/393] 63% | Training loss: 0.6928704664707184
Epoch: 82 | Iteration number: [260/393] 66% | Training loss: 0.6927583772402544
Epoch: 82 | Iteration number: [270/393] 68% | Training loss: 0.6926209173820637
Epoch: 82 | Iteration number: [280/393] 71% | Training loss: 0.6925192492348807
Epoch: 82 | Iteration number: [290/393] 73% | Training loss: 0.6924266743248907
Epoch: 82 | Iteration number: [300/393] 76% | Training loss: 0.69233247478803
Epoch: 82 | Iteration number: [310/393] 78% | Training loss: 0.6922829341503882
Epoch: 82 | Iteration number: [320/393] 81% | Training loss: 0.692217032238841
Epoch: 82 | Iteration number: [330/393] 83% | Training loss: 0.692154835209702
Epoch: 82 | Iteration number: [340/393] 86% | Training loss: 0.6921232293633853
Epoch: 82 | Iteration number: [350/393] 89% | Training loss: 0.6920563450881413
Epoch: 82 | Iteration number: [360/393] 91% | Training loss: 0.6920142286353641
Epoch: 82 | Iteration number: [370/393] 94% | Training loss: 0.6919529156104939
Epoch: 82 | Iteration number: [380/393] 96% | Training loss: 0.6918970824856507
Epoch: 82 | Iteration number: [390/393] 99% | Training loss: 0.6918549001216888

 End of epoch: 82 | Train Loss: 0.690084825641933 | Training Time: 67 

 End of epoch: 82 | Eval Loss: 0.690415446855584 | Evaluating Time: 17 
Epoch: 83 | Iteration number: [10/393] 2% | Training loss: 0.7594215512275696
Epoch: 83 | Iteration number: [20/393] 5% | Training loss: 0.7246584624052048
Epoch: 83 | Iteration number: [30/393] 7% | Training loss: 0.7127807299296062
Epoch: 83 | Iteration number: [40/393] 10% | Training loss: 0.7067762613296509
Epoch: 83 | Iteration number: [50/393] 12% | Training loss: 0.7035912871360779
Epoch: 83 | Iteration number: [60/393] 15% | Training loss: 0.7013776173194249
Epoch: 83 | Iteration number: [70/393] 17% | Training loss: 0.699737127338137
Epoch: 83 | Iteration number: [80/393] 20% | Training loss: 0.6985012352466583
Epoch: 83 | Iteration number: [90/393] 22% | Training loss: 0.6976186315218608
Epoch: 83 | Iteration number: [100/393] 25% | Training loss: 0.6970024329423904
Epoch: 83 | Iteration number: [110/393] 27% | Training loss: 0.6963832795619964
Epoch: 83 | Iteration number: [120/393] 30% | Training loss: 0.695863164961338
Epoch: 83 | Iteration number: [130/393] 33% | Training loss: 0.6954463330598978
Epoch: 83 | Iteration number: [140/393] 35% | Training loss: 0.695183082989284
Epoch: 83 | Iteration number: [150/393] 38% | Training loss: 0.6948526775836945
Epoch: 83 | Iteration number: [160/393] 40% | Training loss: 0.6946223810315132
Epoch: 83 | Iteration number: [170/393] 43% | Training loss: 0.6944314753308015
Epoch: 83 | Iteration number: [180/393] 45% | Training loss: 0.6941855142513911
Epoch: 83 | Iteration number: [190/393] 48% | Training loss: 0.6939635769317024
Epoch: 83 | Iteration number: [200/393] 50% | Training loss: 0.6938029211759568
Epoch: 83 | Iteration number: [210/393] 53% | Training loss: 0.6935985008875529
Epoch: 83 | Iteration number: [220/393] 55% | Training loss: 0.6933884680271148
Epoch: 83 | Iteration number: [230/393] 58% | Training loss: 0.6931960323582524
Epoch: 83 | Iteration number: [240/393] 61% | Training loss: 0.6930501885712147
Epoch: 83 | Iteration number: [250/393] 63% | Training loss: 0.6928832168579102
Epoch: 83 | Iteration number: [260/393] 66% | Training loss: 0.6927876376188719
Epoch: 83 | Iteration number: [270/393] 68% | Training loss: 0.692730360560947
Epoch: 83 | Iteration number: [280/393] 71% | Training loss: 0.6926703308309827
Epoch: 83 | Iteration number: [290/393] 73% | Training loss: 0.6926262177270034
Epoch: 83 | Iteration number: [300/393] 76% | Training loss: 0.6925220443805059
Epoch: 83 | Iteration number: [310/393] 78% | Training loss: 0.6924236291839231
Epoch: 83 | Iteration number: [320/393] 81% | Training loss: 0.6923771368339657
Epoch: 83 | Iteration number: [330/393] 83% | Training loss: 0.692317908821684
Epoch: 83 | Iteration number: [340/393] 86% | Training loss: 0.6922281705281313
Epoch: 83 | Iteration number: [350/393] 89% | Training loss: 0.6921429647718157
Epoch: 83 | Iteration number: [360/393] 91% | Training loss: 0.6920497104525566
Epoch: 83 | Iteration number: [370/393] 94% | Training loss: 0.6919963928493293
Epoch: 83 | Iteration number: [380/393] 96% | Training loss: 0.6919149853681263
Epoch: 83 | Iteration number: [390/393] 99% | Training loss: 0.6918641874423394

 End of epoch: 83 | Train Loss: 0.6900929018438015 | Training Time: 68 

 End of epoch: 83 | Eval Loss: 0.6902436565379707 | Evaluating Time: 17 
Epoch: 84 | Iteration number: [10/393] 2% | Training loss: 0.7591019392013549
Epoch: 84 | Iteration number: [20/393] 5% | Training loss: 0.7248131066560746
Epoch: 84 | Iteration number: [30/393] 7% | Training loss: 0.7131686866283417
Epoch: 84 | Iteration number: [40/393] 10% | Training loss: 0.7074467241764069
Epoch: 84 | Iteration number: [50/393] 12% | Training loss: 0.7041136264801026
Epoch: 84 | Iteration number: [60/393] 15% | Training loss: 0.7017079373200734
Epoch: 84 | Iteration number: [70/393] 17% | Training loss: 0.7000896539006914
Epoch: 84 | Iteration number: [80/393] 20% | Training loss: 0.6988516487181187
Epoch: 84 | Iteration number: [90/393] 22% | Training loss: 0.6979506757524279
Epoch: 84 | Iteration number: [100/393] 25% | Training loss: 0.6971459746360779
Epoch: 84 | Iteration number: [110/393] 27% | Training loss: 0.6964949792081659
Epoch: 84 | Iteration number: [120/393] 30% | Training loss: 0.6959591120481491
Epoch: 84 | Iteration number: [130/393] 33% | Training loss: 0.6955846383021428
Epoch: 84 | Iteration number: [140/393] 35% | Training loss: 0.6952327064105442
Epoch: 84 | Iteration number: [150/393] 38% | Training loss: 0.6949983215332032
Epoch: 84 | Iteration number: [160/393] 40% | Training loss: 0.6946544133126735
Epoch: 84 | Iteration number: [170/393] 43% | Training loss: 0.6943207554957446
Epoch: 84 | Iteration number: [180/393] 45% | Training loss: 0.6940937770737542
Epoch: 84 | Iteration number: [190/393] 48% | Training loss: 0.6938413209036777
Epoch: 84 | Iteration number: [200/393] 50% | Training loss: 0.6936416053771972
Epoch: 84 | Iteration number: [210/393] 53% | Training loss: 0.6934970932347434
Epoch: 84 | Iteration number: [220/393] 55% | Training loss: 0.6933535321192308
Epoch: 84 | Iteration number: [230/393] 58% | Training loss: 0.693233775574228
Epoch: 84 | Iteration number: [240/393] 61% | Training loss: 0.6931161195039749
Epoch: 84 | Iteration number: [250/393] 63% | Training loss: 0.6929030637741089
Epoch: 84 | Iteration number: [260/393] 66% | Training loss: 0.6927980711826911
Epoch: 84 | Iteration number: [270/393] 68% | Training loss: 0.692652428150177
Epoch: 84 | Iteration number: [280/393] 71% | Training loss: 0.6925780198403767
Epoch: 84 | Iteration number: [290/393] 73% | Training loss: 0.6925073492115942
Epoch: 84 | Iteration number: [300/393] 76% | Training loss: 0.6923935761054357
Epoch: 84 | Iteration number: [310/393] 78% | Training loss: 0.6923421202167388
Epoch: 84 | Iteration number: [320/393] 81% | Training loss: 0.692276688106358
Epoch: 84 | Iteration number: [330/393] 83% | Training loss: 0.6921815962502451
Epoch: 84 | Iteration number: [340/393] 86% | Training loss: 0.6921380353324553
Epoch: 84 | Iteration number: [350/393] 89% | Training loss: 0.6921032888548715
Epoch: 84 | Iteration number: [360/393] 91% | Training loss: 0.6920203944047292
Epoch: 84 | Iteration number: [370/393] 94% | Training loss: 0.691975848094837
Epoch: 84 | Iteration number: [380/393] 96% | Training loss: 0.69189398476952
Epoch: 84 | Iteration number: [390/393] 99% | Training loss: 0.6918383495929914

 End of epoch: 84 | Train Loss: 0.6900792067287532 | Training Time: 67 

 End of epoch: 84 | Eval Loss: 0.6903285347685522 | Evaluating Time: 17 
Epoch: 85 | Iteration number: [10/393] 2% | Training loss: 0.7596915125846863
Epoch: 85 | Iteration number: [20/393] 5% | Training loss: 0.7241707533597946
Epoch: 85 | Iteration number: [30/393] 7% | Training loss: 0.7128406882286071
Epoch: 85 | Iteration number: [40/393] 10% | Training loss: 0.7072934120893478
Epoch: 85 | Iteration number: [50/393] 12% | Training loss: 0.7039687860012055
Epoch: 85 | Iteration number: [60/393] 15% | Training loss: 0.7017354776461919
Epoch: 85 | Iteration number: [70/393] 17% | Training loss: 0.700085985660553
Epoch: 85 | Iteration number: [80/393] 20% | Training loss: 0.6988089121878147
Epoch: 85 | Iteration number: [90/393] 22% | Training loss: 0.697930109500885
Epoch: 85 | Iteration number: [100/393] 25% | Training loss: 0.6970181483030319
Epoch: 85 | Iteration number: [110/393] 27% | Training loss: 0.6964880509810014
Epoch: 85 | Iteration number: [120/393] 30% | Training loss: 0.6959752187132835
Epoch: 85 | Iteration number: [130/393] 33% | Training loss: 0.6955349431588099
Epoch: 85 | Iteration number: [140/393] 35% | Training loss: 0.6950701360191618
Epoch: 85 | Iteration number: [150/393] 38% | Training loss: 0.6947472576300303
Epoch: 85 | Iteration number: [160/393] 40% | Training loss: 0.6944791313260794
Epoch: 85 | Iteration number: [170/393] 43% | Training loss: 0.6941986743141623
Epoch: 85 | Iteration number: [180/393] 45% | Training loss: 0.6939275052812365
Epoch: 85 | Iteration number: [190/393] 48% | Training loss: 0.6937204706041437
Epoch: 85 | Iteration number: [200/393] 50% | Training loss: 0.6935311076045036
Epoch: 85 | Iteration number: [210/393] 53% | Training loss: 0.6933363766897293
Epoch: 85 | Iteration number: [220/393] 55% | Training loss: 0.6932173130187121
Epoch: 85 | Iteration number: [230/393] 58% | Training loss: 0.6930543370868849
Epoch: 85 | Iteration number: [240/393] 61% | Training loss: 0.6929228278497855
Epoch: 85 | Iteration number: [250/393] 63% | Training loss: 0.6928127677440643
Epoch: 85 | Iteration number: [260/393] 66% | Training loss: 0.6927305673177425
Epoch: 85 | Iteration number: [270/393] 68% | Training loss: 0.6926386566073807
Epoch: 85 | Iteration number: [280/393] 71% | Training loss: 0.6925664267369679
Epoch: 85 | Iteration number: [290/393] 73% | Training loss: 0.6925150121080464
Epoch: 85 | Iteration number: [300/393] 76% | Training loss: 0.692403930624326
Epoch: 85 | Iteration number: [310/393] 78% | Training loss: 0.6923304561645754
Epoch: 85 | Iteration number: [320/393] 81% | Training loss: 0.6922334084287286
Epoch: 85 | Iteration number: [330/393] 83% | Training loss: 0.6921639579715151
Epoch: 85 | Iteration number: [340/393] 86% | Training loss: 0.6921091830029207
Epoch: 85 | Iteration number: [350/393] 89% | Training loss: 0.6920287735121591
Epoch: 85 | Iteration number: [360/393] 91% | Training loss: 0.6920023303892877
Epoch: 85 | Iteration number: [370/393] 94% | Training loss: 0.6919705210505305
Epoch: 85 | Iteration number: [380/393] 96% | Training loss: 0.6919202658690904
Epoch: 85 | Iteration number: [390/393] 99% | Training loss: 0.6918919870486626

 End of epoch: 85 | Train Loss: 0.6901289421790126 | Training Time: 67 

 End of epoch: 85 | Eval Loss: 0.6903786513270164 | Evaluating Time: 17 
Epoch: 86 | Iteration number: [10/393] 2% | Training loss: 0.7605346202850342
Epoch: 86 | Iteration number: [20/393] 5% | Training loss: 0.7257392108440399
Epoch: 86 | Iteration number: [30/393] 7% | Training loss: 0.7138205965360006
Epoch: 86 | Iteration number: [40/393] 10% | Training loss: 0.7077991187572479
Epoch: 86 | Iteration number: [50/393] 12% | Training loss: 0.7043631589412689
Epoch: 86 | Iteration number: [60/393] 15% | Training loss: 0.7019214103619258
Epoch: 86 | Iteration number: [70/393] 17% | Training loss: 0.7001641775880542
Epoch: 86 | Iteration number: [80/393] 20% | Training loss: 0.6988143742084503
Epoch: 86 | Iteration number: [90/393] 22% | Training loss: 0.6977908531824748
Epoch: 86 | Iteration number: [100/393] 25% | Training loss: 0.6969438165426254
Epoch: 86 | Iteration number: [110/393] 27% | Training loss: 0.696363138068806
Epoch: 86 | Iteration number: [120/393] 30% | Training loss: 0.6958163325985273
Epoch: 86 | Iteration number: [130/393] 33% | Training loss: 0.6954521830265339
Epoch: 86 | Iteration number: [140/393] 35% | Training loss: 0.6951083251408168
Epoch: 86 | Iteration number: [150/393] 38% | Training loss: 0.6947183450063069
Epoch: 86 | Iteration number: [160/393] 40% | Training loss: 0.6944430641829967
Epoch: 86 | Iteration number: [170/393] 43% | Training loss: 0.6942398828618667
Epoch: 86 | Iteration number: [180/393] 45% | Training loss: 0.694037969575988
Epoch: 86 | Iteration number: [190/393] 48% | Training loss: 0.6938311536061136
Epoch: 86 | Iteration number: [200/393] 50% | Training loss: 0.6936662003397942
Epoch: 86 | Iteration number: [210/393] 53% | Training loss: 0.6934916902156103
Epoch: 86 | Iteration number: [220/393] 55% | Training loss: 0.6933002390644767
Epoch: 86 | Iteration number: [230/393] 58% | Training loss: 0.6931384457194287
Epoch: 86 | Iteration number: [240/393] 61% | Training loss: 0.6930376465121905
Epoch: 86 | Iteration number: [250/393] 63% | Training loss: 0.6929305250644684
Epoch: 86 | Iteration number: [260/393] 66% | Training loss: 0.6928378494886251
Epoch: 86 | Iteration number: [270/393] 68% | Training loss: 0.6927414406228949
Epoch: 86 | Iteration number: [280/393] 71% | Training loss: 0.6926257005759648
Epoch: 86 | Iteration number: [290/393] 73% | Training loss: 0.6925075561835848
Epoch: 86 | Iteration number: [300/393] 76% | Training loss: 0.6924225155512492
Epoch: 86 | Iteration number: [310/393] 78% | Training loss: 0.6923678832669412
Epoch: 86 | Iteration number: [320/393] 81% | Training loss: 0.6922870561480522
Epoch: 86 | Iteration number: [330/393] 83% | Training loss: 0.692204821471012
Epoch: 86 | Iteration number: [340/393] 86% | Training loss: 0.6921091048156514
Epoch: 86 | Iteration number: [350/393] 89% | Training loss: 0.6920317956379481
Epoch: 86 | Iteration number: [360/393] 91% | Training loss: 0.691959581606918
Epoch: 86 | Iteration number: [370/393] 94% | Training loss: 0.6919298647223292
Epoch: 86 | Iteration number: [380/393] 96% | Training loss: 0.6919021774279444
Epoch: 86 | Iteration number: [390/393] 99% | Training loss: 0.6918816486994426

 End of epoch: 86 | Train Loss: 0.6901145748813037 | Training Time: 67 

 End of epoch: 86 | Eval Loss: 0.6904682590036976 | Evaluating Time: 17 
Epoch: 87 | Iteration number: [10/393] 2% | Training loss: 0.7592706143856048
Epoch: 87 | Iteration number: [20/393] 5% | Training loss: 0.7244531899690628
Epoch: 87 | Iteration number: [30/393] 7% | Training loss: 0.7130254189173381
Epoch: 87 | Iteration number: [40/393] 10% | Training loss: 0.7074130460619926
Epoch: 87 | Iteration number: [50/393] 12% | Training loss: 0.7040833103656768
Epoch: 87 | Iteration number: [60/393] 15% | Training loss: 0.7017723659674326
Epoch: 87 | Iteration number: [70/393] 17% | Training loss: 0.7003065305096763
Epoch: 87 | Iteration number: [80/393] 20% | Training loss: 0.6989070303738117
Epoch: 87 | Iteration number: [90/393] 22% | Training loss: 0.6978902028666603
Epoch: 87 | Iteration number: [100/393] 25% | Training loss: 0.6969385969638825
Epoch: 87 | Iteration number: [110/393] 27% | Training loss: 0.6963724992491982
Epoch: 87 | Iteration number: [120/393] 30% | Training loss: 0.6959470545252164
Epoch: 87 | Iteration number: [130/393] 33% | Training loss: 0.6955746045479407
Epoch: 87 | Iteration number: [140/393] 35% | Training loss: 0.6952767848968506
Epoch: 87 | Iteration number: [150/393] 38% | Training loss: 0.6948383037249247
Epoch: 87 | Iteration number: [160/393] 40% | Training loss: 0.6945901826024056
Epoch: 87 | Iteration number: [170/393] 43% | Training loss: 0.6942981968907749
Epoch: 87 | Iteration number: [180/393] 45% | Training loss: 0.6940580685933431
Epoch: 87 | Iteration number: [190/393] 48% | Training loss: 0.6937846597872283
Epoch: 87 | Iteration number: [200/393] 50% | Training loss: 0.6936106419563294
Epoch: 87 | Iteration number: [210/393] 53% | Training loss: 0.6934432898248944
Epoch: 87 | Iteration number: [220/393] 55% | Training loss: 0.6932888082482598
Epoch: 87 | Iteration number: [230/393] 58% | Training loss: 0.6931220673996469
Epoch: 87 | Iteration number: [240/393] 61% | Training loss: 0.6929790879289309
Epoch: 87 | Iteration number: [250/393] 63% | Training loss: 0.6928381519317627
Epoch: 87 | Iteration number: [260/393] 66% | Training loss: 0.6927621807043369
Epoch: 87 | Iteration number: [270/393] 68% | Training loss: 0.6926498936282264
Epoch: 87 | Iteration number: [280/393] 71% | Training loss: 0.6925161261643682
Epoch: 87 | Iteration number: [290/393] 73% | Training loss: 0.6924565389238555
Epoch: 87 | Iteration number: [300/393] 76% | Training loss: 0.6924139736096064
Epoch: 87 | Iteration number: [310/393] 78% | Training loss: 0.6923244853173532
Epoch: 87 | Iteration number: [320/393] 81% | Training loss: 0.6922393914312124
Epoch: 87 | Iteration number: [330/393] 83% | Training loss: 0.6921731845899062
Epoch: 87 | Iteration number: [340/393] 86% | Training loss: 0.6921450015376596
Epoch: 87 | Iteration number: [350/393] 89% | Training loss: 0.6920601860114506
Epoch: 87 | Iteration number: [360/393] 91% | Training loss: 0.6919931323991881
Epoch: 87 | Iteration number: [370/393] 94% | Training loss: 0.6919300633507806
Epoch: 87 | Iteration number: [380/393] 96% | Training loss: 0.6919043071960148
Epoch: 87 | Iteration number: [390/393] 99% | Training loss: 0.6918307967675038

 End of epoch: 87 | Train Loss: 0.6900675543998641 | Training Time: 67 

 End of epoch: 87 | Eval Loss: 0.6903180102912747 | Evaluating Time: 17 
Epoch: 88 | Iteration number: [10/393] 2% | Training loss: 0.7587511956691741
Epoch: 88 | Iteration number: [20/393] 5% | Training loss: 0.724506276845932
Epoch: 88 | Iteration number: [30/393] 7% | Training loss: 0.7130930344263713
Epoch: 88 | Iteration number: [40/393] 10% | Training loss: 0.706971462070942
Epoch: 88 | Iteration number: [50/393] 12% | Training loss: 0.7036071562767029
Epoch: 88 | Iteration number: [60/393] 15% | Training loss: 0.7015284230311711
Epoch: 88 | Iteration number: [70/393] 17% | Training loss: 0.6999847412109375
Epoch: 88 | Iteration number: [80/393] 20% | Training loss: 0.6987998992204666
Epoch: 88 | Iteration number: [90/393] 22% | Training loss: 0.6978690842787425
Epoch: 88 | Iteration number: [100/393] 25% | Training loss: 0.6970591324567795
Epoch: 88 | Iteration number: [110/393] 27% | Training loss: 0.6963672112334859
Epoch: 88 | Iteration number: [120/393] 30% | Training loss: 0.6958910127480825
Epoch: 88 | Iteration number: [130/393] 33% | Training loss: 0.6953764470723959
Epoch: 88 | Iteration number: [140/393] 35% | Training loss: 0.6950150310993195
Epoch: 88 | Iteration number: [150/393] 38% | Training loss: 0.6946665461858114
Epoch: 88 | Iteration number: [160/393] 40% | Training loss: 0.6943273190408945
Epoch: 88 | Iteration number: [170/393] 43% | Training loss: 0.6941425309461706
Epoch: 88 | Iteration number: [180/393] 45% | Training loss: 0.6939043382803599
Epoch: 88 | Iteration number: [190/393] 48% | Training loss: 0.6936982600312483
Epoch: 88 | Iteration number: [200/393] 50% | Training loss: 0.693499273955822
Epoch: 88 | Iteration number: [210/393] 53% | Training loss: 0.6933813946587699
Epoch: 88 | Iteration number: [220/393] 55% | Training loss: 0.6932444523681294
Epoch: 88 | Iteration number: [230/393] 58% | Training loss: 0.6931206177110257
Epoch: 88 | Iteration number: [240/393] 61% | Training loss: 0.6929852637151878
Epoch: 88 | Iteration number: [250/393] 63% | Training loss: 0.6928952374458313
Epoch: 88 | Iteration number: [260/393] 66% | Training loss: 0.6927927079109045
Epoch: 88 | Iteration number: [270/393] 68% | Training loss: 0.692693559328715
Epoch: 88 | Iteration number: [280/393] 71% | Training loss: 0.692595919753824
Epoch: 88 | Iteration number: [290/393] 73% | Training loss: 0.6925218627370637
Epoch: 88 | Iteration number: [300/393] 76% | Training loss: 0.6924345616499583
Epoch: 88 | Iteration number: [310/393] 78% | Training loss: 0.6923154286799892
Epoch: 88 | Iteration number: [320/393] 81% | Training loss: 0.6922655256465078
Epoch: 88 | Iteration number: [330/393] 83% | Training loss: 0.692183158975659
Epoch: 88 | Iteration number: [340/393] 86% | Training loss: 0.6920653113547494
Epoch: 88 | Iteration number: [350/393] 89% | Training loss: 0.6920204683712551
Epoch: 88 | Iteration number: [360/393] 91% | Training loss: 0.6919607102870942
Epoch: 88 | Iteration number: [370/393] 94% | Training loss: 0.6919175315547634
Epoch: 88 | Iteration number: [380/393] 96% | Training loss: 0.6918689713666314
Epoch: 88 | Iteration number: [390/393] 99% | Training loss: 0.6918324273366194

 End of epoch: 88 | Train Loss: 0.6900555571830304 | Training Time: 67 

 End of epoch: 88 | Eval Loss: 0.6902025877212992 | Evaluating Time: 17 
Epoch: 89 | Iteration number: [10/393] 2% | Training loss: 0.7576990783214569
Epoch: 89 | Iteration number: [20/393] 5% | Training loss: 0.7226535439491272
Epoch: 89 | Iteration number: [30/393] 7% | Training loss: 0.7118486146132151
Epoch: 89 | Iteration number: [40/393] 10% | Training loss: 0.7063005447387696
Epoch: 89 | Iteration number: [50/393] 12% | Training loss: 0.7031461656093597
Epoch: 89 | Iteration number: [60/393] 15% | Training loss: 0.7010816216468811
Epoch: 89 | Iteration number: [70/393] 17% | Training loss: 0.6995304891041347
Epoch: 89 | Iteration number: [80/393] 20% | Training loss: 0.6983522787690163
Epoch: 89 | Iteration number: [90/393] 22% | Training loss: 0.6975160651736789
Epoch: 89 | Iteration number: [100/393] 25% | Training loss: 0.6968417775630951
Epoch: 89 | Iteration number: [110/393] 27% | Training loss: 0.6962832933122461
Epoch: 89 | Iteration number: [120/393] 30% | Training loss: 0.6957595879832904
Epoch: 89 | Iteration number: [130/393] 33% | Training loss: 0.6953550847677085
Epoch: 89 | Iteration number: [140/393] 35% | Training loss: 0.6949689660753523
Epoch: 89 | Iteration number: [150/393] 38% | Training loss: 0.6946367927392324
Epoch: 89 | Iteration number: [160/393] 40% | Training loss: 0.6944112095981836
Epoch: 89 | Iteration number: [170/393] 43% | Training loss: 0.694169962756774
Epoch: 89 | Iteration number: [180/393] 45% | Training loss: 0.6939474218421512
Epoch: 89 | Iteration number: [190/393] 48% | Training loss: 0.6937386164539738
Epoch: 89 | Iteration number: [200/393] 50% | Training loss: 0.693562385737896
Epoch: 89 | Iteration number: [210/393] 53% | Training loss: 0.6934144840354011
Epoch: 89 | Iteration number: [220/393] 55% | Training loss: 0.69323778396303
Epoch: 89 | Iteration number: [230/393] 58% | Training loss: 0.6930743378141652
Epoch: 89 | Iteration number: [240/393] 61% | Training loss: 0.6929587726791699
Epoch: 89 | Iteration number: [250/393] 63% | Training loss: 0.6928613803386688
Epoch: 89 | Iteration number: [260/393] 66% | Training loss: 0.6927472575352742
Epoch: 89 | Iteration number: [270/393] 68% | Training loss: 0.6926368554433187
Epoch: 89 | Iteration number: [280/393] 71% | Training loss: 0.6925246125885418
Epoch: 89 | Iteration number: [290/393] 73% | Training loss: 0.6924403772271913
Epoch: 89 | Iteration number: [300/393] 76% | Training loss: 0.6924221833546956
Epoch: 89 | Iteration number: [310/393] 78% | Training loss: 0.692358353830153
Epoch: 89 | Iteration number: [320/393] 81% | Training loss: 0.6922655876725912
Epoch: 89 | Iteration number: [330/393] 83% | Training loss: 0.6921840369701385
Epoch: 89 | Iteration number: [340/393] 86% | Training loss: 0.6921278921996846
Epoch: 89 | Iteration number: [350/393] 89% | Training loss: 0.6920581563881465
Epoch: 89 | Iteration number: [360/393] 91% | Training loss: 0.6919880949788624
Epoch: 89 | Iteration number: [370/393] 94% | Training loss: 0.6919443446236688
Epoch: 89 | Iteration number: [380/393] 96% | Training loss: 0.6918773091153094
Epoch: 89 | Iteration number: [390/393] 99% | Training loss: 0.6918327369751074

 End of epoch: 89 | Train Loss: 0.6900682670772834 | Training Time: 67 

 End of epoch: 89 | Eval Loss: 0.6902388735693328 | Evaluating Time: 18 
Epoch: 90 | Iteration number: [10/393] 2% | Training loss: 0.7589076220989227
Epoch: 90 | Iteration number: [20/393] 5% | Training loss: 0.7246114939451218
Epoch: 90 | Iteration number: [30/393] 7% | Training loss: 0.7134522080421448
Epoch: 90 | Iteration number: [40/393] 10% | Training loss: 0.7079979091882705
Epoch: 90 | Iteration number: [50/393] 12% | Training loss: 0.7045065820217132
Epoch: 90 | Iteration number: [60/393] 15% | Training loss: 0.7020173152287801
Epoch: 90 | Iteration number: [70/393] 17% | Training loss: 0.7003772820745195
Epoch: 90 | Iteration number: [80/393] 20% | Training loss: 0.6991907946765423
Epoch: 90 | Iteration number: [90/393] 22% | Training loss: 0.6980881604883405
Epoch: 90 | Iteration number: [100/393] 25% | Training loss: 0.697262202501297
Epoch: 90 | Iteration number: [110/393] 27% | Training loss: 0.6965225306424228
Epoch: 90 | Iteration number: [120/393] 30% | Training loss: 0.6961028128862381
Epoch: 90 | Iteration number: [130/393] 33% | Training loss: 0.695649233689675
Epoch: 90 | Iteration number: [140/393] 35% | Training loss: 0.695231870668275
Epoch: 90 | Iteration number: [150/393] 38% | Training loss: 0.6948245513439179
Epoch: 90 | Iteration number: [160/393] 40% | Training loss: 0.6945470627397299
Epoch: 90 | Iteration number: [170/393] 43% | Training loss: 0.694260875267141
Epoch: 90 | Iteration number: [180/393] 45% | Training loss: 0.6940315276384353
Epoch: 90 | Iteration number: [190/393] 48% | Training loss: 0.6938567616437611
Epoch: 90 | Iteration number: [200/393] 50% | Training loss: 0.6936646473407745
Epoch: 90 | Iteration number: [210/393] 53% | Training loss: 0.6934302758602869
Epoch: 90 | Iteration number: [220/393] 55% | Training loss: 0.6932634256102822
Epoch: 90 | Iteration number: [230/393] 58% | Training loss: 0.6931009808312292
Epoch: 90 | Iteration number: [240/393] 61% | Training loss: 0.6929298249383767
Epoch: 90 | Iteration number: [250/393] 63% | Training loss: 0.692813185453415
Epoch: 90 | Iteration number: [260/393] 66% | Training loss: 0.6927238455185524
Epoch: 90 | Iteration number: [270/393] 68% | Training loss: 0.692632069852617
Epoch: 90 | Iteration number: [280/393] 71% | Training loss: 0.6925541107143675
Epoch: 90 | Iteration number: [290/393] 73% | Training loss: 0.6924587701929027
Epoch: 90 | Iteration number: [300/393] 76% | Training loss: 0.6923631483316421
Epoch: 90 | Iteration number: [310/393] 78% | Training loss: 0.692309957742691
Epoch: 90 | Iteration number: [320/393] 81% | Training loss: 0.6922632092610002
Epoch: 90 | Iteration number: [330/393] 83% | Training loss: 0.6922077583544182
Epoch: 90 | Iteration number: [340/393] 86% | Training loss: 0.6921199609251584
Epoch: 90 | Iteration number: [350/393] 89% | Training loss: 0.6920317390986851
Epoch: 90 | Iteration number: [360/393] 91% | Training loss: 0.6919791171948115
Epoch: 90 | Iteration number: [370/393] 94% | Training loss: 0.6919370029423688
Epoch: 90 | Iteration number: [380/393] 96% | Training loss: 0.6919000304058979
Epoch: 90 | Iteration number: [390/393] 99% | Training loss: 0.6918423826877887

 End of epoch: 90 | Train Loss: 0.6900706162282833 | Training Time: 68 

 End of epoch: 90 | Eval Loss: 0.6904206312432581 | Evaluating Time: 17 
Epoch: 91 | Iteration number: [10/393] 2% | Training loss: 0.7604778409004211
Epoch: 91 | Iteration number: [20/393] 5% | Training loss: 0.7259630262851715
Epoch: 91 | Iteration number: [30/393] 7% | Training loss: 0.7143189489841462
Epoch: 91 | Iteration number: [40/393] 10% | Training loss: 0.708203348517418
Epoch: 91 | Iteration number: [50/393] 12% | Training loss: 0.7045694601535797
Epoch: 91 | Iteration number: [60/393] 15% | Training loss: 0.7022186696529389
Epoch: 91 | Iteration number: [70/393] 17% | Training loss: 0.7007006168365478
Epoch: 91 | Iteration number: [80/393] 20% | Training loss: 0.6993844024837017
Epoch: 91 | Iteration number: [90/393] 22% | Training loss: 0.6983494056595696
Epoch: 91 | Iteration number: [100/393] 25% | Training loss: 0.697621191740036
Epoch: 91 | Iteration number: [110/393] 27% | Training loss: 0.6969297522848302
Epoch: 91 | Iteration number: [120/393] 30% | Training loss: 0.696410113076369
Epoch: 91 | Iteration number: [130/393] 33% | Training loss: 0.6959714586918171
Epoch: 91 | Iteration number: [140/393] 35% | Training loss: 0.6955011086804527
Epoch: 91 | Iteration number: [150/393] 38% | Training loss: 0.6951688253879547
Epoch: 91 | Iteration number: [160/393] 40% | Training loss: 0.6947467137128115
Epoch: 91 | Iteration number: [170/393] 43% | Training loss: 0.6943461912519792
Epoch: 91 | Iteration number: [180/393] 45% | Training loss: 0.6940732522143258
Epoch: 91 | Iteration number: [190/393] 48% | Training loss: 0.6938318826650318
Epoch: 91 | Iteration number: [200/393] 50% | Training loss: 0.6936432600021363
Epoch: 91 | Iteration number: [210/393] 53% | Training loss: 0.6934324514298212
Epoch: 91 | Iteration number: [220/393] 55% | Training loss: 0.6933135514909571
Epoch: 91 | Iteration number: [230/393] 58% | Training loss: 0.6930911600589752
Epoch: 91 | Iteration number: [240/393] 61% | Training loss: 0.6930064966281255
Epoch: 91 | Iteration number: [250/393] 63% | Training loss: 0.6928941209316254
Epoch: 91 | Iteration number: [260/393] 66% | Training loss: 0.6928111181809352
Epoch: 91 | Iteration number: [270/393] 68% | Training loss: 0.6926937211442876
Epoch: 91 | Iteration number: [280/393] 71% | Training loss: 0.6925937631300517
Epoch: 91 | Iteration number: [290/393] 73% | Training loss: 0.692502414974673
Epoch: 91 | Iteration number: [300/393] 76% | Training loss: 0.6924561671415965
Epoch: 91 | Iteration number: [310/393] 78% | Training loss: 0.6923501943388293
Epoch: 91 | Iteration number: [320/393] 81% | Training loss: 0.6922462616115809
Epoch: 91 | Iteration number: [330/393] 83% | Training loss: 0.6921763131112764
Epoch: 91 | Iteration number: [340/393] 86% | Training loss: 0.6921299427747727
Epoch: 91 | Iteration number: [350/393] 89% | Training loss: 0.6920442732742854
Epoch: 91 | Iteration number: [360/393] 91% | Training loss: 0.6919991907146242
Epoch: 91 | Iteration number: [370/393] 94% | Training loss: 0.691954069040917
Epoch: 91 | Iteration number: [380/393] 96% | Training loss: 0.6919079854300147
Epoch: 91 | Iteration number: [390/393] 99% | Training loss: 0.6918384736929184

 End of epoch: 91 | Train Loss: 0.690063897889989 | Training Time: 68 

 End of epoch: 91 | Eval Loss: 0.6903150397904065 | Evaluating Time: 17 
Epoch: 92 | Iteration number: [10/393] 2% | Training loss: 0.7582475960254669
Epoch: 92 | Iteration number: [20/393] 5% | Training loss: 0.7240775227546692
Epoch: 92 | Iteration number: [30/393] 7% | Training loss: 0.7127183695634206
Epoch: 92 | Iteration number: [40/393] 10% | Training loss: 0.7069673880934715
Epoch: 92 | Iteration number: [50/393] 12% | Training loss: 0.7036137104034423
Epoch: 92 | Iteration number: [60/393] 15% | Training loss: 0.7013666987419128
Epoch: 92 | Iteration number: [70/393] 17% | Training loss: 0.6997472626822335
Epoch: 92 | Iteration number: [80/393] 20% | Training loss: 0.6986098982393741
Epoch: 92 | Iteration number: [90/393] 22% | Training loss: 0.697631283601125
Epoch: 92 | Iteration number: [100/393] 25% | Training loss: 0.6969308114051819
Epoch: 92 | Iteration number: [110/393] 27% | Training loss: 0.69624093987725
Epoch: 92 | Iteration number: [120/393] 30% | Training loss: 0.6957668582598369
Epoch: 92 | Iteration number: [130/393] 33% | Training loss: 0.6953856436105875
Epoch: 92 | Iteration number: [140/393] 35% | Training loss: 0.6950255687747683
Epoch: 92 | Iteration number: [150/393] 38% | Training loss: 0.6947024969259897
Epoch: 92 | Iteration number: [160/393] 40% | Training loss: 0.6943462695926428
Epoch: 92 | Iteration number: [170/393] 43% | Training loss: 0.6940718552645515
Epoch: 92 | Iteration number: [180/393] 45% | Training loss: 0.6939086188872655
Epoch: 92 | Iteration number: [190/393] 48% | Training loss: 0.6936842030600497
Epoch: 92 | Iteration number: [200/393] 50% | Training loss: 0.6934863266348839
Epoch: 92 | Iteration number: [210/393] 53% | Training loss: 0.6933195693152291
Epoch: 92 | Iteration number: [220/393] 55% | Training loss: 0.6931957583535802
Epoch: 92 | Iteration number: [230/393] 58% | Training loss: 0.6930216812569162
Epoch: 92 | Iteration number: [240/393] 61% | Training loss: 0.6929387062788009
Epoch: 92 | Iteration number: [250/393] 63% | Training loss: 0.6928536109924316
Epoch: 92 | Iteration number: [260/393] 66% | Training loss: 0.6927469806029246
Epoch: 92 | Iteration number: [270/393] 68% | Training loss: 0.6926026540773886
Epoch: 92 | Iteration number: [280/393] 71% | Training loss: 0.6924980282783508
Epoch: 92 | Iteration number: [290/393] 73% | Training loss: 0.6924160470222605
Epoch: 92 | Iteration number: [300/393] 76% | Training loss: 0.6923625489075979
Epoch: 92 | Iteration number: [310/393] 78% | Training loss: 0.6922888477002421
Epoch: 92 | Iteration number: [320/393] 81% | Training loss: 0.6922088196501136
Epoch: 92 | Iteration number: [330/393] 83% | Training loss: 0.6921656520077677
Epoch: 92 | Iteration number: [340/393] 86% | Training loss: 0.6921059284140082
Epoch: 92 | Iteration number: [350/393] 89% | Training loss: 0.6920170199871063
Epoch: 92 | Iteration number: [360/393] 91% | Training loss: 0.6919480785727501
Epoch: 92 | Iteration number: [370/393] 94% | Training loss: 0.6919235600007547
Epoch: 92 | Iteration number: [380/393] 96% | Training loss: 0.6918499337999444
Epoch: 92 | Iteration number: [390/393] 99% | Training loss: 0.6918083883248842

 End of epoch: 92 | Train Loss: 0.6900362047833644 | Training Time: 68 

 End of epoch: 92 | Eval Loss: 0.6902315081382284 | Evaluating Time: 17 
Epoch: 93 | Iteration number: [10/393] 2% | Training loss: 0.7591618359088897
Epoch: 93 | Iteration number: [20/393] 5% | Training loss: 0.723661157488823
Epoch: 93 | Iteration number: [30/393] 7% | Training loss: 0.7126755932966868
Epoch: 93 | Iteration number: [40/393] 10% | Training loss: 0.7071057900786399
Epoch: 93 | Iteration number: [50/393] 12% | Training loss: 0.7038406682014465
Epoch: 93 | Iteration number: [60/393] 15% | Training loss: 0.7016152948141098
Epoch: 93 | Iteration number: [70/393] 17% | Training loss: 0.7001072789941515
Epoch: 93 | Iteration number: [80/393] 20% | Training loss: 0.6990204878151417
Epoch: 93 | Iteration number: [90/393] 22% | Training loss: 0.6979761997858683
Epoch: 93 | Iteration number: [100/393] 25% | Training loss: 0.6970945811271667
Epoch: 93 | Iteration number: [110/393] 27% | Training loss: 0.6965170475569639
Epoch: 93 | Iteration number: [120/393] 30% | Training loss: 0.6960666428009669
Epoch: 93 | Iteration number: [130/393] 33% | Training loss: 0.695582254574849
Epoch: 93 | Iteration number: [140/393] 35% | Training loss: 0.6951587834528514
Epoch: 93 | Iteration number: [150/393] 38% | Training loss: 0.6947658530871074
Epoch: 93 | Iteration number: [160/393] 40% | Training loss: 0.6944913145154714
Epoch: 93 | Iteration number: [170/393] 43% | Training loss: 0.6942486054757062
Epoch: 93 | Iteration number: [180/393] 45% | Training loss: 0.6940286947621239
Epoch: 93 | Iteration number: [190/393] 48% | Training loss: 0.6937928212316413
Epoch: 93 | Iteration number: [200/393] 50% | Training loss: 0.6935522827506065
Epoch: 93 | Iteration number: [210/393] 53% | Training loss: 0.6933943163780939
Epoch: 93 | Iteration number: [220/393] 55% | Training loss: 0.6932494003664363
Epoch: 93 | Iteration number: [230/393] 58% | Training loss: 0.693101214585097
Epoch: 93 | Iteration number: [240/393] 61% | Training loss: 0.6929915981988112
Epoch: 93 | Iteration number: [250/393] 63% | Training loss: 0.6928861105442047
Epoch: 93 | Iteration number: [260/393] 66% | Training loss: 0.6927790352931389
Epoch: 93 | Iteration number: [270/393] 68% | Training loss: 0.6926495011206026
Epoch: 93 | Iteration number: [280/393] 71% | Training loss: 0.6925916437591825
Epoch: 93 | Iteration number: [290/393] 73% | Training loss: 0.6925434367410068
Epoch: 93 | Iteration number: [300/393] 76% | Training loss: 0.6924284313122432
Epoch: 93 | Iteration number: [310/393] 78% | Training loss: 0.6923208957718264
Epoch: 93 | Iteration number: [320/393] 81% | Training loss: 0.6922054700553417
Epoch: 93 | Iteration number: [330/393] 83% | Training loss: 0.6921614847399972
Epoch: 93 | Iteration number: [340/393] 86% | Training loss: 0.6920999924926197
Epoch: 93 | Iteration number: [350/393] 89% | Training loss: 0.6919720457281385
Epoch: 93 | Iteration number: [360/393] 91% | Training loss: 0.6918932520680957
Epoch: 93 | Iteration number: [370/393] 94% | Training loss: 0.6918700508169225
Epoch: 93 | Iteration number: [380/393] 96% | Training loss: 0.6918284431884163
Epoch: 93 | Iteration number: [390/393] 99% | Training loss: 0.691790590989284

 End of epoch: 93 | Train Loss: 0.6900184688373983 | Training Time: 67 

 End of epoch: 93 | Eval Loss: 0.690222325373669 | Evaluating Time: 17 
Epoch: 94 | Iteration number: [10/393] 2% | Training loss: 0.7582080364227295
Epoch: 94 | Iteration number: [20/393] 5% | Training loss: 0.7242104321718216
Epoch: 94 | Iteration number: [30/393] 7% | Training loss: 0.7126297016938528
Epoch: 94 | Iteration number: [40/393] 10% | Training loss: 0.706995838880539
Epoch: 94 | Iteration number: [50/393] 12% | Training loss: 0.703380492925644
Epoch: 94 | Iteration number: [60/393] 15% | Training loss: 0.7011754840612412
Epoch: 94 | Iteration number: [70/393] 17% | Training loss: 0.699634713785989
Epoch: 94 | Iteration number: [80/393] 20% | Training loss: 0.6984142765402794
Epoch: 94 | Iteration number: [90/393] 22% | Training loss: 0.6974880006578233
Epoch: 94 | Iteration number: [100/393] 25% | Training loss: 0.6967823177576065
Epoch: 94 | Iteration number: [110/393] 27% | Training loss: 0.6960189207033678
Epoch: 94 | Iteration number: [120/393] 30% | Training loss: 0.6954626535375913
Epoch: 94 | Iteration number: [130/393] 33% | Training loss: 0.6950919926166534
Epoch: 94 | Iteration number: [140/393] 35% | Training loss: 0.6947860585791724
Epoch: 94 | Iteration number: [150/393] 38% | Training loss: 0.6945206316312155
Epoch: 94 | Iteration number: [160/393] 40% | Training loss: 0.6942474234849214
Epoch: 94 | Iteration number: [170/393] 43% | Training loss: 0.6940575322684119
Epoch: 94 | Iteration number: [180/393] 45% | Training loss: 0.6938291877508164
Epoch: 94 | Iteration number: [190/393] 48% | Training loss: 0.6936623228223701
Epoch: 94 | Iteration number: [200/393] 50% | Training loss: 0.6934870129823685
Epoch: 94 | Iteration number: [210/393] 53% | Training loss: 0.6933322531836373
Epoch: 94 | Iteration number: [220/393] 55% | Training loss: 0.6931756816127084
Epoch: 94 | Iteration number: [230/393] 58% | Training loss: 0.6930600710537123
Epoch: 94 | Iteration number: [240/393] 61% | Training loss: 0.6929394769171874
Epoch: 94 | Iteration number: [250/393] 63% | Training loss: 0.6927982366085053
Epoch: 94 | Iteration number: [260/393] 66% | Training loss: 0.6926837756083561
Epoch: 94 | Iteration number: [270/393] 68% | Training loss: 0.6926003403133816
Epoch: 94 | Iteration number: [280/393] 71% | Training loss: 0.6925035870500973
Epoch: 94 | Iteration number: [290/393] 73% | Training loss: 0.6923886878737088
Epoch: 94 | Iteration number: [300/393] 76% | Training loss: 0.6923264918724695
Epoch: 94 | Iteration number: [310/393] 78% | Training loss: 0.6922428211858196
Epoch: 94 | Iteration number: [320/393] 81% | Training loss: 0.6921537255868315
Epoch: 94 | Iteration number: [330/393] 83% | Training loss: 0.6921001031543269
Epoch: 94 | Iteration number: [340/393] 86% | Training loss: 0.692037939674714
Epoch: 94 | Iteration number: [350/393] 89% | Training loss: 0.6920128176893506
Epoch: 94 | Iteration number: [360/393] 91% | Training loss: 0.6919482703010241
Epoch: 94 | Iteration number: [370/393] 94% | Training loss: 0.6919167170653472
Epoch: 94 | Iteration number: [380/393] 96% | Training loss: 0.691857795025173
Epoch: 94 | Iteration number: [390/393] 99% | Training loss: 0.6917877671046134

 End of epoch: 94 | Train Loss: 0.6900152802164015 | Training Time: 68 

 End of epoch: 94 | Eval Loss: 0.6902999172405321 | Evaluating Time: 17 
Epoch: 95 | Iteration number: [10/393] 2% | Training loss: 0.7588725864887238
Epoch: 95 | Iteration number: [20/393] 5% | Training loss: 0.7245555460453034
Epoch: 95 | Iteration number: [30/393] 7% | Training loss: 0.713091504573822
Epoch: 95 | Iteration number: [40/393] 10% | Training loss: 0.7073026835918427
Epoch: 95 | Iteration number: [50/393] 12% | Training loss: 0.7038659346103668
Epoch: 95 | Iteration number: [60/393] 15% | Training loss: 0.7016004264354706
Epoch: 95 | Iteration number: [70/393] 17% | Training loss: 0.6996806136199406
Epoch: 95 | Iteration number: [80/393] 20% | Training loss: 0.6985254168510437
Epoch: 95 | Iteration number: [90/393] 22% | Training loss: 0.69752586417728
Epoch: 95 | Iteration number: [100/393] 25% | Training loss: 0.6967042422294617
Epoch: 95 | Iteration number: [110/393] 27% | Training loss: 0.6960782457481731
Epoch: 95 | Iteration number: [120/393] 30% | Training loss: 0.695602276424567
Epoch: 95 | Iteration number: [130/393] 33% | Training loss: 0.6951649317374596
Epoch: 95 | Iteration number: [140/393] 35% | Training loss: 0.6947875103780201
Epoch: 95 | Iteration number: [150/393] 38% | Training loss: 0.6945322887102763
Epoch: 95 | Iteration number: [160/393] 40% | Training loss: 0.694327937066555
Epoch: 95 | Iteration number: [170/393] 43% | Training loss: 0.6941271143801072
Epoch: 95 | Iteration number: [180/393] 45% | Training loss: 0.6937937670283847
Epoch: 95 | Iteration number: [190/393] 48% | Training loss: 0.6936211121709723
Epoch: 95 | Iteration number: [200/393] 50% | Training loss: 0.693408481478691
Epoch: 95 | Iteration number: [210/393] 53% | Training loss: 0.6932799696922303
Epoch: 95 | Iteration number: [220/393] 55% | Training loss: 0.6931100417267192
Epoch: 95 | Iteration number: [230/393] 58% | Training loss: 0.6929762176845384
Epoch: 95 | Iteration number: [240/393] 61% | Training loss: 0.6928668300310771
Epoch: 95 | Iteration number: [250/393] 63% | Training loss: 0.6927538313865662
Epoch: 95 | Iteration number: [260/393] 66% | Training loss: 0.6926171761292678
Epoch: 95 | Iteration number: [270/393] 68% | Training loss: 0.6925472221992633
Epoch: 95 | Iteration number: [280/393] 71% | Training loss: 0.6924615791865758
Epoch: 95 | Iteration number: [290/393] 73% | Training loss: 0.6923782128712227
Epoch: 95 | Iteration number: [300/393] 76% | Training loss: 0.6923093758026759
Epoch: 95 | Iteration number: [310/393] 78% | Training loss: 0.6922792540442559
Epoch: 95 | Iteration number: [320/393] 81% | Training loss: 0.6921648664399982
Epoch: 95 | Iteration number: [330/393] 83% | Training loss: 0.6921141371582493
Epoch: 95 | Iteration number: [340/393] 86% | Training loss: 0.6920499926104265
Epoch: 95 | Iteration number: [350/393] 89% | Training loss: 0.6920018696784973
Epoch: 95 | Iteration number: [360/393] 91% | Training loss: 0.6919706698920992
Epoch: 95 | Iteration number: [370/393] 94% | Training loss: 0.6919272682151278
Epoch: 95 | Iteration number: [380/393] 96% | Training loss: 0.691878732411485
Epoch: 95 | Iteration number: [390/393] 99% | Training loss: 0.6918402655002398

 End of epoch: 95 | Train Loss: 0.6900640172509444 | Training Time: 67 

 End of epoch: 95 | Eval Loss: 0.6903511516901911 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/393] 2% | Training loss: 0.7577989935874939
Epoch: 96 | Iteration number: [20/393] 5% | Training loss: 0.7236061334609986
Epoch: 96 | Iteration number: [30/393] 7% | Training loss: 0.7124662637710572
Epoch: 96 | Iteration number: [40/393] 10% | Training loss: 0.706972812116146
Epoch: 96 | Iteration number: [50/393] 12% | Training loss: 0.7038362944126129
Epoch: 96 | Iteration number: [60/393] 15% | Training loss: 0.7014482875665029
Epoch: 96 | Iteration number: [70/393] 17% | Training loss: 0.6998997798987797
Epoch: 96 | Iteration number: [80/393] 20% | Training loss: 0.6985671706497669
Epoch: 96 | Iteration number: [90/393] 22% | Training loss: 0.6976058072514004
Epoch: 96 | Iteration number: [100/393] 25% | Training loss: 0.6967925637960434
Epoch: 96 | Iteration number: [110/393] 27% | Training loss: 0.6962496275251562
Epoch: 96 | Iteration number: [120/393] 30% | Training loss: 0.6957554151614507
Epoch: 96 | Iteration number: [130/393] 33% | Training loss: 0.6952116205142095
Epoch: 96 | Iteration number: [140/393] 35% | Training loss: 0.6948129679475512
Epoch: 96 | Iteration number: [150/393] 38% | Training loss: 0.6945044338703156
Epoch: 96 | Iteration number: [160/393] 40% | Training loss: 0.694180752709508
Epoch: 96 | Iteration number: [170/393] 43% | Training loss: 0.6939692483228795
Epoch: 96 | Iteration number: [180/393] 45% | Training loss: 0.6937398019764158
Epoch: 96 | Iteration number: [190/393] 48% | Training loss: 0.6935605055407474
Epoch: 96 | Iteration number: [200/393] 50% | Training loss: 0.6933204677700996
Epoch: 96 | Iteration number: [210/393] 53% | Training loss: 0.6931224539166405
Epoch: 96 | Iteration number: [220/393] 55% | Training loss: 0.6930112836035816
Epoch: 96 | Iteration number: [230/393] 58% | Training loss: 0.6928823380366615
Epoch: 96 | Iteration number: [240/393] 61% | Training loss: 0.6927897326648236
Epoch: 96 | Iteration number: [250/393] 63% | Training loss: 0.6926431124210357
Epoch: 96 | Iteration number: [260/393] 66% | Training loss: 0.6925935289034477
Epoch: 96 | Iteration number: [270/393] 68% | Training loss: 0.6924939193107463
Epoch: 96 | Iteration number: [280/393] 71% | Training loss: 0.6924177731786455
Epoch: 96 | Iteration number: [290/393] 73% | Training loss: 0.6923542643415517
Epoch: 96 | Iteration number: [300/393] 76% | Training loss: 0.6922888123989105
Epoch: 96 | Iteration number: [310/393] 78% | Training loss: 0.6922429375110134
Epoch: 96 | Iteration number: [320/393] 81% | Training loss: 0.6921834733337164
Epoch: 96 | Iteration number: [330/393] 83% | Training loss: 0.6920893537275719
Epoch: 96 | Iteration number: [340/393] 86% | Training loss: 0.6920653413323795
Epoch: 96 | Iteration number: [350/393] 89% | Training loss: 0.6920150431564877
Epoch: 96 | Iteration number: [360/393] 91% | Training loss: 0.6919853531652027
Epoch: 96 | Iteration number: [370/393] 94% | Training loss: 0.6919332926337783
Epoch: 96 | Iteration number: [380/393] 96% | Training loss: 0.6919108546093891
Epoch: 96 | Iteration number: [390/393] 99% | Training loss: 0.6918832540512085

 End of epoch: 96 | Train Loss: 0.6901232932360117 | Training Time: 68 

 End of epoch: 96 | Eval Loss: 0.6904447613930216 | Evaluating Time: 17 
Epoch: 97 | Iteration number: [10/393] 2% | Training loss: 0.7595510601997375
Epoch: 97 | Iteration number: [20/393] 5% | Training loss: 0.7250998198986054
Epoch: 97 | Iteration number: [30/393] 7% | Training loss: 0.7134416699409485
Epoch: 97 | Iteration number: [40/393] 10% | Training loss: 0.7076388612389565
Epoch: 97 | Iteration number: [50/393] 12% | Training loss: 0.7040039741992951
Epoch: 97 | Iteration number: [60/393] 15% | Training loss: 0.7016386886437734
Epoch: 97 | Iteration number: [70/393] 17% | Training loss: 0.6999623945781163
Epoch: 97 | Iteration number: [80/393] 20% | Training loss: 0.6987247005105018
Epoch: 97 | Iteration number: [90/393] 22% | Training loss: 0.6976096603605483
Epoch: 97 | Iteration number: [100/393] 25% | Training loss: 0.6968427401781082
Epoch: 97 | Iteration number: [110/393] 27% | Training loss: 0.6962082792412151
Epoch: 97 | Iteration number: [120/393] 30% | Training loss: 0.6956904744108517
Epoch: 97 | Iteration number: [130/393] 33% | Training loss: 0.6953066358199487
Epoch: 97 | Iteration number: [140/393] 35% | Training loss: 0.6949200498206275
Epoch: 97 | Iteration number: [150/393] 38% | Training loss: 0.6946102587381998
Epoch: 97 | Iteration number: [160/393] 40% | Training loss: 0.6943123873323203
Epoch: 97 | Iteration number: [170/393] 43% | Training loss: 0.6940171073464786
Epoch: 97 | Iteration number: [180/393] 45% | Training loss: 0.693769485089514
Epoch: 97 | Iteration number: [190/393] 48% | Training loss: 0.6935488493818985
Epoch: 97 | Iteration number: [200/393] 50% | Training loss: 0.6934063580632209
Epoch: 97 | Iteration number: [210/393] 53% | Training loss: 0.693243652298337
Epoch: 97 | Iteration number: [220/393] 55% | Training loss: 0.6930821627378464
Epoch: 97 | Iteration number: [230/393] 58% | Training loss: 0.6929548123608464
Epoch: 97 | Iteration number: [240/393] 61% | Training loss: 0.6928955758611361
Epoch: 97 | Iteration number: [250/393] 63% | Training loss: 0.6928197374343872
Epoch: 97 | Iteration number: [260/393] 66% | Training loss: 0.6926920709701685
Epoch: 97 | Iteration number: [270/393] 68% | Training loss: 0.6925607665821358
Epoch: 97 | Iteration number: [280/393] 71% | Training loss: 0.6924622791154044
Epoch: 97 | Iteration number: [290/393] 73% | Training loss: 0.6924044763219768
Epoch: 97 | Iteration number: [300/393] 76% | Training loss: 0.6923455812533696
Epoch: 97 | Iteration number: [310/393] 78% | Training loss: 0.6922643015461584
Epoch: 97 | Iteration number: [320/393] 81% | Training loss: 0.6921965574845672
Epoch: 97 | Iteration number: [330/393] 83% | Training loss: 0.6921288125442736
Epoch: 97 | Iteration number: [340/393] 86% | Training loss: 0.6920750996645759
Epoch: 97 | Iteration number: [350/393] 89% | Training loss: 0.6920459282398224
Epoch: 97 | Iteration number: [360/393] 91% | Training loss: 0.6920281795991792
Epoch: 97 | Iteration number: [370/393] 94% | Training loss: 0.6919971458009772
Epoch: 97 | Iteration number: [380/393] 96% | Training loss: 0.6919379565276598
Epoch: 97 | Iteration number: [390/393] 99% | Training loss: 0.6918493998356354

 End of epoch: 97 | Train Loss: 0.6900864979086335 | Training Time: 68 

 End of epoch: 97 | Eval Loss: 0.6903074821647333 | Evaluating Time: 17 
Epoch: 98 | Iteration number: [10/393] 2% | Training loss: 0.7594441533088684
Epoch: 98 | Iteration number: [20/393] 5% | Training loss: 0.7250343948602677
Epoch: 98 | Iteration number: [30/393] 7% | Training loss: 0.7133100310961406
Epoch: 98 | Iteration number: [40/393] 10% | Training loss: 0.7076779857277871
Epoch: 98 | Iteration number: [50/393] 12% | Training loss: 0.7043824064731598
Epoch: 98 | Iteration number: [60/393] 15% | Training loss: 0.7018871754407883
Epoch: 98 | Iteration number: [70/393] 17% | Training loss: 0.7000411518982479
Epoch: 98 | Iteration number: [80/393] 20% | Training loss: 0.6987856656312943
Epoch: 98 | Iteration number: [90/393] 22% | Training loss: 0.6978106988800896
Epoch: 98 | Iteration number: [100/393] 25% | Training loss: 0.6970651990175247
Epoch: 98 | Iteration number: [110/393] 27% | Training loss: 0.6963908509774641
Epoch: 98 | Iteration number: [120/393] 30% | Training loss: 0.6959290395180384
Epoch: 98 | Iteration number: [130/393] 33% | Training loss: 0.6954635661381942
Epoch: 98 | Iteration number: [140/393] 35% | Training loss: 0.6949806903089796
Epoch: 98 | Iteration number: [150/393] 38% | Training loss: 0.6946259188652039
Epoch: 98 | Iteration number: [160/393] 40% | Training loss: 0.6944174468517303
Epoch: 98 | Iteration number: [170/393] 43% | Training loss: 0.6942104444784276
Epoch: 98 | Iteration number: [180/393] 45% | Training loss: 0.693971182902654
Epoch: 98 | Iteration number: [190/393] 48% | Training loss: 0.6937631503531807
Epoch: 98 | Iteration number: [200/393] 50% | Training loss: 0.6935699844360351
Epoch: 98 | Iteration number: [210/393] 53% | Training loss: 0.6934421987760635
Epoch: 98 | Iteration number: [220/393] 55% | Training loss: 0.6932558173483069
Epoch: 98 | Iteration number: [230/393] 58% | Training loss: 0.69307636126228
Epoch: 98 | Iteration number: [240/393] 61% | Training loss: 0.6929284545282522
Epoch: 98 | Iteration number: [250/393] 63% | Training loss: 0.6927707691192627
Epoch: 98 | Iteration number: [260/393] 66% | Training loss: 0.6926050369556134
Epoch: 98 | Iteration number: [270/393] 68% | Training loss: 0.6925433576107025
Epoch: 98 | Iteration number: [280/393] 71% | Training loss: 0.692455538894449
Epoch: 98 | Iteration number: [290/393] 73% | Training loss: 0.6924121636768867
Epoch: 98 | Iteration number: [300/393] 76% | Training loss: 0.6923436009883881
Epoch: 98 | Iteration number: [310/393] 78% | Training loss: 0.6923059780751505
Epoch: 98 | Iteration number: [320/393] 81% | Training loss: 0.6922387711703777
Epoch: 98 | Iteration number: [330/393] 83% | Training loss: 0.6921835812655363
Epoch: 98 | Iteration number: [340/393] 86% | Training loss: 0.692140610779033
Epoch: 98 | Iteration number: [350/393] 89% | Training loss: 0.6920814021996089
Epoch: 98 | Iteration number: [360/393] 91% | Training loss: 0.6920372659961382
Epoch: 98 | Iteration number: [370/393] 94% | Training loss: 0.6919408749889683
Epoch: 98 | Iteration number: [380/393] 96% | Training loss: 0.691849389044862
Epoch: 98 | Iteration number: [390/393] 99% | Training loss: 0.6917990487355452

 End of epoch: 98 | Train Loss: 0.6900249563404015 | Training Time: 68 

 End of epoch: 98 | Eval Loss: 0.6903002773012433 | Evaluating Time: 17 
Epoch: 99 | Iteration number: [10/393] 2% | Training loss: 0.7574823379516602
Epoch: 99 | Iteration number: [20/393] 5% | Training loss: 0.7232873201370239
Epoch: 99 | Iteration number: [30/393] 7% | Training loss: 0.7123192469278972
Epoch: 99 | Iteration number: [40/393] 10% | Training loss: 0.7069607183337212
Epoch: 99 | Iteration number: [50/393] 12% | Training loss: 0.7035972237586975
Epoch: 99 | Iteration number: [60/393] 15% | Training loss: 0.7012249688307445
Epoch: 99 | Iteration number: [70/393] 17% | Training loss: 0.6995716154575348
Epoch: 99 | Iteration number: [80/393] 20% | Training loss: 0.6982449814677238
Epoch: 99 | Iteration number: [90/393] 22% | Training loss: 0.6973481211397383
Epoch: 99 | Iteration number: [100/393] 25% | Training loss: 0.6966317003965378
Epoch: 99 | Iteration number: [110/393] 27% | Training loss: 0.6960203159939159
Epoch: 99 | Iteration number: [120/393] 30% | Training loss: 0.6955782627065976
Epoch: 99 | Iteration number: [130/393] 33% | Training loss: 0.6951697468757629
Epoch: 99 | Iteration number: [140/393] 35% | Training loss: 0.6947645455598831
Epoch: 99 | Iteration number: [150/393] 38% | Training loss: 0.6944672691822052
Epoch: 99 | Iteration number: [160/393] 40% | Training loss: 0.6941730372607708
Epoch: 99 | Iteration number: [170/393] 43% | Training loss: 0.6939992497949039
Epoch: 99 | Iteration number: [180/393] 45% | Training loss: 0.6938370880153444
Epoch: 99 | Iteration number: [190/393] 48% | Training loss: 0.6936463425033971
Epoch: 99 | Iteration number: [200/393] 50% | Training loss: 0.6935162457823754
Epoch: 99 | Iteration number: [210/393] 53% | Training loss: 0.6933078899270012
Epoch: 99 | Iteration number: [220/393] 55% | Training loss: 0.6931847496466204
Epoch: 99 | Iteration number: [230/393] 58% | Training loss: 0.6930348113827084
Epoch: 99 | Iteration number: [240/393] 61% | Training loss: 0.6928959908584754
Epoch: 99 | Iteration number: [250/393] 63% | Training loss: 0.6928361766338348
Epoch: 99 | Iteration number: [260/393] 66% | Training loss: 0.6926743977344954
Epoch: 99 | Iteration number: [270/393] 68% | Training loss: 0.6925932908499682
Epoch: 99 | Iteration number: [280/393] 71% | Training loss: 0.6925048519458089
Epoch: 99 | Iteration number: [290/393] 73% | Training loss: 0.6924380530571116
Epoch: 99 | Iteration number: [300/393] 76% | Training loss: 0.6923468538125356
Epoch: 99 | Iteration number: [310/393] 78% | Training loss: 0.6922557546246436
Epoch: 99 | Iteration number: [320/393] 81% | Training loss: 0.6922091135755182
Epoch: 99 | Iteration number: [330/393] 83% | Training loss: 0.692170443498727
Epoch: 99 | Iteration number: [340/393] 86% | Training loss: 0.6921368944294313
Epoch: 99 | Iteration number: [350/393] 89% | Training loss: 0.692050506898335
Epoch: 99 | Iteration number: [360/393] 91% | Training loss: 0.6919494915339682
Epoch: 99 | Iteration number: [370/393] 94% | Training loss: 0.6918931721030055
Epoch: 99 | Iteration number: [380/393] 96% | Training loss: 0.691854729150471
Epoch: 99 | Iteration number: [390/393] 99% | Training loss: 0.6918046303284474

 End of epoch: 99 | Train Loss: 0.6900375591586261 | Training Time: 67 

 End of epoch: 99 | Eval Loss: 0.6902281106734762 | Evaluating Time: 17 
Epoch: 100 | Iteration number: [10/393] 2% | Training loss: 0.7594418346881866
Epoch: 100 | Iteration number: [20/393] 5% | Training loss: 0.7242253541946411
Epoch: 100 | Iteration number: [30/393] 7% | Training loss: 0.7125830431779225
Epoch: 100 | Iteration number: [40/393] 10% | Training loss: 0.7069196596741676
Epoch: 100 | Iteration number: [50/393] 12% | Training loss: 0.7033616030216217
Epoch: 100 | Iteration number: [60/393] 15% | Training loss: 0.7010535885890324
Epoch: 100 | Iteration number: [70/393] 17% | Training loss: 0.6992839395999908
Epoch: 100 | Iteration number: [80/393] 20% | Training loss: 0.6982423096895218
Epoch: 100 | Iteration number: [90/393] 22% | Training loss: 0.6973816679583655
Epoch: 100 | Iteration number: [100/393] 25% | Training loss: 0.6967203366756439
Epoch: 100 | Iteration number: [110/393] 27% | Training loss: 0.6961308961564844
Epoch: 100 | Iteration number: [120/393] 30% | Training loss: 0.6954781472682953
Epoch: 100 | Iteration number: [130/393] 33% | Training loss: 0.6950068950653077
Epoch: 100 | Iteration number: [140/393] 35% | Training loss: 0.6946950133357729
Epoch: 100 | Iteration number: [150/393] 38% | Training loss: 0.6944368386268616
Epoch: 100 | Iteration number: [160/393] 40% | Training loss: 0.6941576022654772
Epoch: 100 | Iteration number: [170/393] 43% | Training loss: 0.6938888974049512
Epoch: 100 | Iteration number: [180/393] 45% | Training loss: 0.6936892264419132
Epoch: 100 | Iteration number: [190/393] 48% | Training loss: 0.6934788201984606
Epoch: 100 | Iteration number: [200/393] 50% | Training loss: 0.6933384150266647
Epoch: 100 | Iteration number: [210/393] 53% | Training loss: 0.693232113974435
Epoch: 100 | Iteration number: [220/393] 55% | Training loss: 0.6930541919036345
Epoch: 100 | Iteration number: [230/393] 58% | Training loss: 0.6929531592389812
Epoch: 100 | Iteration number: [240/393] 61% | Training loss: 0.692877791573604
Epoch: 100 | Iteration number: [250/393] 63% | Training loss: 0.6927718894481659
Epoch: 100 | Iteration number: [260/393] 66% | Training loss: 0.6926241487264633
Epoch: 100 | Iteration number: [270/393] 68% | Training loss: 0.692536175471765
Epoch: 100 | Iteration number: [280/393] 71% | Training loss: 0.6924717143177986
Epoch: 100 | Iteration number: [290/393] 73% | Training loss: 0.6923825816861514
Epoch: 100 | Iteration number: [300/393] 76% | Training loss: 0.6922912599643072
Epoch: 100 | Iteration number: [310/393] 78% | Training loss: 0.69222016795989
Epoch: 100 | Iteration number: [320/393] 81% | Training loss: 0.692146479524672
Epoch: 100 | Iteration number: [330/393] 83% | Training loss: 0.6920898932399172
Epoch: 100 | Iteration number: [340/393] 86% | Training loss: 0.6920501798391342
Epoch: 100 | Iteration number: [350/393] 89% | Training loss: 0.6920015009811946
Epoch: 100 | Iteration number: [360/393] 91% | Training loss: 0.6919261636005507
Epoch: 100 | Iteration number: [370/393] 94% | Training loss: 0.6918605762559015
Epoch: 100 | Iteration number: [380/393] 96% | Training loss: 0.6917851219051763
Epoch: 100 | Iteration number: [390/393] 99% | Training loss: 0.6917406942599859

 End of epoch: 100 | Train Loss: 0.6899796772852502 | Training Time: 67 

 End of epoch: 100 | Eval Loss: 0.6902626168971159 | Evaluating Time: 17 

 End of Test | Dice Loss: 0.8322917407006025 | Binary Cross Entropy With Logits Loss: 0.6903881311416626 
