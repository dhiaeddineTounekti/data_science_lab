Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7641573667526245
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7291813671588898
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7173770765463511
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7115200579166412
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7079464793205261
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7055684477090836
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7038597898823874
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7025485016405583
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7015242397785186
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.700684461593628
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.6999912538311698
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.6994262675444285
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6989454503242786
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6985195300408772
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6981329794724782
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.697794995456934
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6975157537881066
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.697243935863177
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.6970195346756985
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6967937204241753
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6965736071268718
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6963936150074005
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6962239293948463
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6960538697739442
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6958934848308563
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6957522988319397
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6956198634924712
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6954856338245529
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.695347739704724
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6952264644702275
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6951179954313462
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.695006626099348
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6949107507864635
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6948172365917878
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6947249100889479
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.694634113377995
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6945432793449711
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6944612754018683
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6943877339363098
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6943206714093685
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6942563971368277
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6941853377081099
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6941218742104464
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6940599255941131
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6940021725495656
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6939502769190332
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6938893744286071
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6938332783679168
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6937663081957369
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6937115224599838
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6936520680492999
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6935999652514091
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6935456338918434
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6934970604048835
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6934537262266333
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6934056307588304

 End of epoch: 1 | Train Loss: 0.6921642763424763 | Training Time: 89 

 End of epoch: 1 | Eval Loss: 0.6933611035346985 | Evaluating Time: 6 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7596733152866364
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7252028852701187
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.713550720612208
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7078909784555435
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7044583868980407
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7021127243836721
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.700424815927233
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.6991672195494175
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.6982063776916928
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.697452307343483
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6968196256594225
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6962907811005911
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6958697653733767
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6954873651266098
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6951341672738394
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6948262717574835
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.69457587389385
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6943724211719301
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.694173801886408
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6939991444349289
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6938304364681244
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6936629528349096
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6935240071752797
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6933747003475825
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6932545623779297
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6931229919195175
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6930099301868015
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6928944638797215
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6927961511858578
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6927014658848445
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6926239763536761
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6925442704930902
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6924558480580648
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6923806150169933
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6923184279033116
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6922545764181349
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6921964753318477
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.692141832803425
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6920888440731244
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6920224402844906
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6919615912728193
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6919098872513998
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6918652601020281
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6918222423304211
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.691779842906528
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6917380296665689
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6916975660527006
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6916509351382653
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.691610028062548
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.691583372592926
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6915529736116821
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6915112440402691
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6914755547946354
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6914397903062679
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6914001262187958
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6913751222193241

 End of epoch: 2 | Train Loss: 0.6901446667392697 | Training Time: 90 

 End of epoch: 2 | Eval Loss: 0.692728579044342 | Evaluating Time: 6 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7586144030094146
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7241226702928543
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7126462797323863
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7068778976798058
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7034457337856292
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7011354366938273
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.699473238842828
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6982692055404186
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6972275058428447
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.696438131928444
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6957814330404455
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.695267416536808
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6948146091057704
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6944373377731868
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.694126314719518
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6938257038593292
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.693567775628146
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6933091359006034
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6930873045795842
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6929232862591743
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6927472344466619
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6925664197314869
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6924341466115869
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6922963706155618
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6921736385822296
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6920610253627484
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.691967675862489
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6918765425682067
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6917902424417693
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.691717196504275
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6916288564282079
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6915446486324072
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6914687445669463
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.691391302206937
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6913217834063938
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6912583513392343
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6912083459867013
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6911570588224812
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6911056536894579
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6910620437562466
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6910068732936208
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6909665580306734
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6909112230289814
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.690877962518822
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6908389306068421
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6908019928828529
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6907648491098526
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6907254261275132
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6906870867524828
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6906551951169968
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6906262120779822
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6905849845363543
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6905501644566374
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6905150306445581
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6904917285659097
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6904605356710297

 End of epoch: 3 | Train Loss: 0.6892219049740682 | Training Time: 88 

 End of epoch: 3 | Eval Loss: 0.6917076877185276 | Evaluating Time: 6 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7575799226760864
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7232002705335617
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7117867648601532
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7060224801301956
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7025790119171142
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7003036777178446
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6986753055027553
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6973721712827683
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6964308520158132
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6956965321302414
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6950893494215878
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6945593858758609
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6940922049375681
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.693740326166153
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6934157145023346
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6931178975850344
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6928827222655801
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6926521648963292
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.692421996907184
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.69222651720047
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6920583815801711
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6919055911627683
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6917516830174819
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6916066845258076
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.691481852054596
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6913728427428466
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6912757946385277
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6911801947014672
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6910748374873195
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6909893763065338
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.690908270882022
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6908318245783448
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6907604988777276
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6906935137860916
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6906458672455379
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6906097387274106
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6905517003020725
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6904994647753866
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6904507497946422
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6903991554677487
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6903613321664857
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6903213769197464
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6902815440366434
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6902349256656387
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6902006684409248
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6901605619036633
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6901181250176531
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6900879886001349
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6900537449486401
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6900250993967056
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6900003404009576
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6899729435260479
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6899423044807506
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6899192781360061
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6898995279182087
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6898796583924974

 End of epoch: 4 | Train Loss: 0.6886402881250973 | Training Time: 90 

 End of epoch: 4 | Eval Loss: 0.691779341016497 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7574573695659638
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7229640543460846
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7114204843839009
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7057887479662895
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7022978317737579
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.6999132196108501
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.6982534493718828
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6969910204410553
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6960766898261176
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6953346389532089
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6946918059479107
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6941757455468178
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6937105779464429
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6933518771614348
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6929911176363627
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6926947649568319
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6924254757516525
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6921727882491218
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6919698708935788
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6917923894524575
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6916311224301656
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6914905586025931
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6913462939469711
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6912214674055577
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6911171333789825
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6910112963272975
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6909000087667394
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6907993110162871
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.69072281081101
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6906467052300771
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6905604547069919
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6904856692999601
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6904199833219702
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6903463828213074
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6902860837323325
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6902118977573183
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6901580150062974
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6901110123646886
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6900535957935529
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6900109797716141
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6899587987399682
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6899121981291544
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6898765069107676
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6898444439877164
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6898100080755022
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6897715450628944
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6897307917158655
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6896963346749544
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6896665739769838
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6896428461074829
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.689618839820226
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6895964685540933
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6895726955161905
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6895432081487444
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6895098712227561
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.689488934725523

 End of epoch: 5 | Train Loss: 0.6882541613241212 | Training Time: 90 

 End of epoch: 5 | Eval Loss: 0.6915636488369533 | Evaluating Time: 5 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7570322096347809
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7227726072072983
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7111338436603546
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7055201962590217
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7019757056236267
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6996637225151062
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6980218955448696
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6968132108449936
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6958091159661611
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6950324249267578
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6944104785268957
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6939028734962146
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6934657509510334
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6931102888924735
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6927728815873464
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6924827411770821
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6922123141148511
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6919792069329156
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6917830097047906
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6915620312094688
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6914046977247511
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6912457338788293
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6910979923994645
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6909630879759788
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6908324530124664
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6907150837091299
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6906068333873042
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6905173693384443
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.690422692792169
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6903379724423091
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.690267175628293
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6902040891349316
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6901387397086982
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.690066000994514
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6899983634267535
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6899414390325547
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6898789009532413
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6898286601430491
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6897757531740727
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6897242517769336
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6896786813328906
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6896356155474981
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6895978199881176
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6895606007088314
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6895213598675198
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.689483858321024
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6894508240070749
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6894086128721635
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6893788039684295
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6893510825634003
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6893189724753884
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6892861566864528
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6892584534186237
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6892318152719074
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6892008483409882
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6891841132725988

 End of epoch: 6 | Train Loss: 0.6879573097271202 | Training Time: 88 

 End of epoch: 6 | Eval Loss: 0.6910073927470616 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7563296556472778
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7219668656587601
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7106019258499146
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7048321813344955
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7013643729686737
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6990989704926809
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6975169820444924
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6963268555700779
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6953651560677423
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.69463558614254
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6940133425322446
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6935179601113002
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6930941838484544
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6927244914429528
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6923843252658844
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.692111412063241
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6918612417052774
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916475418541167
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6914385993229716
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912382900714874
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6910736575013116
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.690917404402386
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6907817700634832
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6906319896380106
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.690531046628952
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.690425151357284
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6903210121172446
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6902453954730715
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6901728554018612
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6901047853628794
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6900181616506269
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6899450305849314
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.689875373876456
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6898130371290094
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6897609586375101
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6897014131148657
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6896487843345951
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6896008377012454
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6895555166097788
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.689506951123476
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6894643042145706
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6894214668444225
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6893812763136486
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6893379437652501
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.689299734433492
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6892739952906318
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6892450676319447
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6892055694013834
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.689171606910472
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6891411463022232
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6891005764989292
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6890721157193184
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6890435976802178
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6890162431531482
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6889978435906496
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6889747470617295

 End of epoch: 7 | Train Loss: 0.6877494695967278 | Training Time: 89 

 End of epoch: 7 | Eval Loss: 0.6910048978669303 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7567050337791443
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7222046047449112
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7108311812082927
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7050162941217423
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7015117573738098
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6991785258054733
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6975606722491128
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6963272385299206
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6953116337458293
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6945483630895615
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6938956249843944
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6933605169256528
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6929409306782942
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6925749548843929
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6922551739215851
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6919499605894088
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6917073761715609
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6914736092090606
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6912770403058905
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6910856908559799
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6909300508953277
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6907727471806786
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6906381632970727
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6904948172469934
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6903629312515259
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6902537316083908
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6901639474762811
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.690059101155826
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6899698602742163
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.689884272813797
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6898054501702708
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6897383717820048
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6896662858399478
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6896022412706824
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6895535043307713
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6894999313685629
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6894463009125478
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.689397066988443
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6893587164389782
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6893159167468548
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6892676231337757
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.689226585768518
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6891963188038316
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6891607820987702
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6891298582818773
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.68909579243349
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6890701146835977
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6890405505895615
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890027111890364
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6889737889766693
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6889474431673686
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889179548391929
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.688892844488036
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6888716959291035
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6888359798084606
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888241018567767

 End of epoch: 8 | Train Loss: 0.6875956933055304 | Training Time: 88 

 End of epoch: 8 | Eval Loss: 0.6911190067018781 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7565108180046082
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7219554603099823
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7104580044746399
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7046652615070343
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.701244615316391
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6990074495474498
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973697568689073
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6961310140788555
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6951653467284309
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6943843758106232
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6937987929040735
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6932181000709534
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6927839233325078
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6923896423407964
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6920767903327942
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6918259646743536
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6915650564081529
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6913215584225125
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6910782616389425
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6908848366141319
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6907237487179892
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.690572461756793
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6904137474039327
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6903024462362131
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6901936862468719
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6900967469582191
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6899962385495504
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6899028741887637
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6898181452833373
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6897454047203064
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6896802808007886
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6896164806559681
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6895482023557027
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6894907598986345
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6894491597584316
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.689401676091883
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6893380943182352
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6892803347424457
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6892469482544141
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6891961082816124
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6891539977818001
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891286594527108
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6890855725421462
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6890525846318765
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.689006269507938
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6889659304981647
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889266248713148
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6888938230772813
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6888532347825109
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6888249288797379
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888116316468108
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6887790787678498
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.688753005581082
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6887265426141245
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887119520794261
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6886907078325748

 End of epoch: 9 | Train Loss: 0.6874682672255862 | Training Time: 89 

 End of epoch: 9 | Eval Loss: 0.6908705404826573 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7561203598976135
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7217552304267884
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7103098074595133
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7045216128230095
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7010010850429534
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6987735519806544
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6972045166151865
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6959792487323284
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6950387703047858
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6942982798814774
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.693653923814947
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6931481798489888
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6927079361218672
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6923302526984896
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.69202783147494
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6917204987257719
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6914829657358281
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6912483841180801
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6910524164375506
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6908728647232055
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6907239510899499
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6905643888495185
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.690433172557665
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6903068296611309
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6901845145225525
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6900720163033559
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6899547729227278
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6898563204067094
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6897685307880927
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6896945714950562
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6896175644090099
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.689549777098
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6894892929178296
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894196354291018
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893417940820966
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6892953079607752
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689255434919048
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6891894625990014
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891473028904352
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6890986093878746
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.689067209348446
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890121309530167
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6889740557171578
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889342367649078
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6888880235619015
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.688850179185038
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888195805093076
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6887844149023294
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887508159997512
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887220683097839
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6886998430186627
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6886740169846095
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886393480705765
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6886173496643703
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6885925374247811
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6885726803115436

 End of epoch: 10 | Train Loss: 0.6873452639157793 | Training Time: 90 

 End of epoch: 10 | Eval Loss: 0.6911222508975438 | Evaluating Time: 5 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7565797388553619
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7219491094350815
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7102593004703521
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7045196503400802
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7010916459560395
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6987861394882202
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6971405591283526
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6959430739283562
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6949834101729923
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6942397010326385
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6935766165906733
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.69302795479695
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6925783973473769
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6922052592039108
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6918736966451009
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6915879927575588
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6913456292713389
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911234690083398
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6909162995062377
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6907562181353569
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6905730528490884
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6904328289357099
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.690303287298783
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6902029876907666
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6900863888263702
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6899788856506348
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6898841798305512
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6897756348763193
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896682303527306
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.689594395160675
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895082396845664
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6894421599805355
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6893650237357978
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6892952873426326
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892435337815966
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891911812954479
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891443650464754
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890926644990318
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6890410585281176
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.688998146802187
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6889491497016534
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889166850419272
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.688867647426073
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888290426947854
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6887898786862692
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6887593581624653
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887256627387189
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6886924497783184
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6886590443095383
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886396014690399
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886118082439199
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6885891452431678
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6885631902037926
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885375104568623
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885151219367981
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6884892157145909

 End of epoch: 11 | Train Loss: 0.6872598145915344 | Training Time: 89 

 End of epoch: 11 | Eval Loss: 0.6908584066799709 | Evaluating Time: 6 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7561130702495575
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7216127544641495
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7101782520612081
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7045043274760246
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010734128952026
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6988688558340073
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6972245795386178
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6960333243012429
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6950169497066074
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.69427494764328
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6936095221476122
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6930132667223613
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6925649661284227
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6921643414667674
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6918427296479543
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6915375560522079
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6912701634799733
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910466220643785
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6908536813761058
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906626424193383
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.690502681618645
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903487782586705
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6902174708635911
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.69009045312802
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6899686970710754
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6898618012666702
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.689766522248586
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896663386906896
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.689601953687339
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6895106842120489
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894499357669585
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893765809014439
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.68931016831687
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892588042161044
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6892110511234828
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.68916142301427
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6891089782521531
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890612274408341
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6890162946322025
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.688969861716032
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6889470694995508
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6889096700009846
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6888721617155297
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6888299688696862
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887947025563982
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6887710536303727
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6887377551261414
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6886987797915936
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6886635466497771
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6886287688016891
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6886035819848378
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885867330890435
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885573245444387
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6885353300306533
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6885012611475858
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884720798049654

 End of epoch: 12 | Train Loss: 0.6872461200815386 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6902276703289577 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7558919608592987
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7216876685619354
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.710342139005661
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7045358628034591
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7010406017303467
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.698760183652242
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6970851515020643
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6958145044744015
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6947909328672621
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6940235567092895
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6933925704522567
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6928521056969961
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6924320858258467
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6920723859752927
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917329998811086
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914405323565006
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6911677304436179
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909515096081628
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907562688777321
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905827882885933
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904234378110795
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6902580862695521
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901335483011992
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6900093582769234
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6899010734558105
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6898023421947773
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897090214270133
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6896242580243519
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895341455936432
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894751393795013
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6894065905001856
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6893379639834165
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892673485206835
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6891949585255455
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.689134589774268
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890528031521373
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6889917673291387
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6889427895608701
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6888872223022656
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6888412189483643
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888031330050491
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6887602225655601
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887216878491779
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.688690413263711
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6886525697178311
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886199962833653
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6885749308352774
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.688556157425046
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885348051178212
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885092548131942
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6884823157506831
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884515285491943
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884232778594179
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884036131479122
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6883723765069788
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883508055337838

 End of epoch: 13 | Train Loss: 0.6871288046372676 | Training Time: 90 

 End of epoch: 13 | Eval Loss: 0.6905978662627084 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.755633533000946
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7214795768260955
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7100725571314493
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7043674781918525
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7009378397464752
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6987166553735733
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6970965989998409
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6958420313894749
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6948403543896146
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6940494668483734
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6934171579100868
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6929000407457352
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6924409838823172
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6920384368726186
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6917209470272064
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6914602387696505
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6912029834354625
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909680773814519
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907423587221848
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905324172973633
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6903643469015758
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902133535255085
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6900822294794995
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899675759176414
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898527445793152
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897495024479352
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896457747176842
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895623856357166
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894897171135607
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6894085079431533
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893394102973323
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892700413241982
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6892016257300522
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891408439944772
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890689488819667
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6889995723962784
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889377872686129
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.688882169441173
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.688834607295501
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6887933450937271
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887528800382847
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6887126137812932
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6886752929798392
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886468062346632
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886110877990723
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6885815698167552
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885564660772364
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885304408768813
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.688500334292042
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884616408348083
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884404109973533
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.688417695921201
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6883924248083583
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883637144609734
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883396822755987
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883161325539862

 End of epoch: 14 | Train Loss: 0.6870904910880907 | Training Time: 89 

 End of epoch: 14 | Eval Loss: 0.6912281683513096 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7563295662403107
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.721786105632782
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7102567871411641
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7045606136322021
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7010120582580567
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6986420770486196
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6969797381332943
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6957398489117622
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6947768694824643
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6940653949975968
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6934238764372739
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6928847079475721
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.69244719010133
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6920627402407783
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6917191191514334
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.691445916891098
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6911863852949703
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6909762005011241
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6907672392694574
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6905690976977348
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903878041676113
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902315966107628
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900750307933144
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6899447249869506
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.6898239831924439
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897466920889341
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896461952615667
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.689554183610848
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894794026325489
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6893829123179118
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893137672255116
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892494393512607
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891978153676698
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6891389899394091
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890842132908958
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6890218435062303
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6889616690777444
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6889128653626693
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6888504687028053
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888030861318112
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887572707199469
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887239382380531
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886842626471852
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886378193443472
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886106283134884
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6885803217473238
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885621645349137
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885383288065593
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6885099120286047
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884759234189988
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884441427156037
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6884187150460023
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883941843824567
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.688365383722164
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883447876843539
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883186503180436

 End of epoch: 15 | Train Loss: 0.6870912508626955 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.690703979560307 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7555241882801056
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.721415838599205
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7100003004074097
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7042306229472161
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7007880127429962
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6985698501269023
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6969457915851048
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6956869445741176
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6946638034449684
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6939017486572265
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6932708778164604
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6927830050388972
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6923303512426523
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6919383896248681
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6916135418415069
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6913104094564915
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.691053965512444
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6908496780527963
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6906362382989181
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6904410743713378
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6902816011792138
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6901234697211872
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6900057696777842
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6898901370664438
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6897851552963257
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6896872795545138
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6895860665374332
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6894960867507117
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6894137585985249
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6893284128109614
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6892561220353649
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6891758432611823
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6891121497659972
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6890507712083704
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6889951528821673
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6889419653349452
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6888993598319388
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888487147657495
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.688806194678331
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887593396008015
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6887246419743793
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6886936873197556
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886551145897355
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886190232905475
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6885869161287943
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885588454163593
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.688534645070421
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884986406813065
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884680655537819
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884395127296448
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884143867913415
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883875891566277
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883533763435652
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883271517576994
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883021635358983
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882849347378527

 End of epoch: 16 | Train Loss: 0.6870587752983633 | Training Time: 89 

 End of epoch: 16 | Eval Loss: 0.6908900822911944 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7559696435928345
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7217534273862839
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7099697589874268
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7042163208127021
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7008970057964325
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.698649001121521
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.696946348462786
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6957710027694702
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6948363482952118
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6940240162611008
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6934155355800282
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6928525134921074
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923790262295649
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6920205895389829
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916827034950256
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6913978431373835
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6911262319368474
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908978091345893
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906898827929245
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6905224242806435
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6903713683287303
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6902106174013831
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6900618104831032
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6899388055006663
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6898085789680481
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.689692963545139
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895910399931449
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6894906659211432
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6893888508451396
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893084925413132
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892329671690541
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.689165067858994
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6890885445204649
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890364177086774
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6889691085474832
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889201939105988
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6888544103583774
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888076195591375
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887556496338967
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887103469669819
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886676491760626
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886142932233357
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.688576519073442
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885366172953086
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885146009922027
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6884886466938517
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6884484074217208
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884173192083836
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6883879058215083
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6883585656881333
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883386729979047
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883150454897147
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883000405329578
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6882714000013139
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6882501881772821
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.688237047621182

 End of epoch: 17 | Train Loss: 0.6870124416013734 | Training Time: 88 

 End of epoch: 17 | Eval Loss: 0.6903580001422337 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7555345296859741
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212787806987763
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7100821157296499
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7042593270540237
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7008713948726654
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6985431462526321
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6967833842550005
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6955611877143383
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6946456147564782
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6938897013664246
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932809558781711
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.692779544989268
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6923675514184512
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6920032786471503
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6916644684473674
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6913908388465643
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6911311381003435
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908988114860323
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6906854315807945
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904959493875503
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6903292085443224
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901648551225662
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.690035712459813
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898913264274598
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897701959609985
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896457101290042
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895431845276444
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894540086388588
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893778578988436
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6892964152495066
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892345622662575
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891449753195047
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6890849187518611
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890211717170828
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.688970775433949
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889140193661054
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888725172828983
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888125934098897
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887619363955962
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887195144593715
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886831886884642
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886463762748809
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886141402776851
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885836288332939
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885381337006887
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885040213232455
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884733494291915
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884430275609096
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884121920381273
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883831746578216
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883588558318569
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883347425323266
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6883139019867159
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6882877703066226
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882635973800313
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882378088576453

 End of epoch: 18 | Train Loss: 0.6870155842958299 | Training Time: 87 

 End of epoch: 18 | Eval Loss: 0.6910795058522906 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7553255379199981
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7212229549884797
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7098776400089264
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7042399272322655
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7008689999580383
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6986025840044021
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6969567384038653
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6956920929253101
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6947998464107513
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.694017287492752
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.693413030017506
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.692900317410628
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6924239846376272
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6920368782111577
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6916832443078359
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6913903340697288
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6911310076713562
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6909203877051672
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6907134357251619
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6905048233270645
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6903541922569275
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6902133166790009
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6900531968344813
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6899118654429912
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897961902618408
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896947500797418
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6896037066424334
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6895048284104892
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6894202252914166
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6893440425395966
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.689252233312976
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891879351809621
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6891186564257651
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6890559299903758
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6890100160666874
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6889543897575803
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6889119488161963
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6888649780499307
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6888130680108682
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6887736776471138
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6887202476582877
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886804729700089
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6886478029018225
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6886056413704699
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885665596856011
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6885281088559524
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884965393137424
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884596109390259
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6884309324682976
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883962680101394
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.68836389744983
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883384173879257
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6883124878946341
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882786616131111
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.688252299265428
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882260796214853

 End of epoch: 19 | Train Loss: 0.6869973291338017 | Training Time: 89 

 End of epoch: 19 | Eval Loss: 0.6903604524476188 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.75552898645401
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7214590728282928
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7100863456726074
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7043849408626557
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7009442865848541
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6986508826414745
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6970295539924076
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6957284614443779
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6947457783752018
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6939513707160949
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932971585880626
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927662536501884
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922729781040778
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6918906292745045
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6915613575776418
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6912887584418058
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6909886707277859
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6907684180471633
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.690567968393627
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.690399962067604
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902349889278412
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6900880063121969
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6899509515451349
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898487098515034
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897340698242187
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.689631698681758
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895193779910053
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6894260581050601
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893288452049782
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892660939693451
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6891984049350984
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.689131067506969
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890582984144037
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6889870079124675
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889235440322331
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6888645185364617
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888135940641971
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6887685107557397
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887294909892938
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6886845472455024
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886416900448683
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.688605813894953
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6885749066984931
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885325276038864
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6884973712762197
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884580726208894
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.688427626959821
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6883934547503789
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883598810555983
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883176934719085
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6882935538011439
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6882737579254004
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882443233480994
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.688228600886133
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882146394252777
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6881947487592697

 End of epoch: 20 | Train Loss: 0.6869609351706716 | Training Time: 89 

 End of epoch: 20 | Eval Loss: 0.6907513056482587 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7556986093521119
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.721146434545517
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7099627713362376
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7042141363024712
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7007403779029846
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6984733124574025
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6968451976776123
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6955540634691715
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.694577674070994
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938309025764465
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6932016524401579
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6926660016179085
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922254860401154
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6918152626071657
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6914904201030732
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912014432251453
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6909695008221794
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907277524471283
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6905204898432682
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6903266388177872
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6901673271542503
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6900280665267597
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899125487908073
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.689782386769851
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6896587424278259
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6895527688356546
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6894761315098515
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6893958973033087
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6892950138141369
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6892172984282176
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.689138291728112
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6890731142833829
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890218230811033
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.688965462586459
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889057748658316
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888717151350445
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888066256368482
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887558758258819
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887145604842748
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886690044403077
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886356379927658
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885995901766278
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885627538658852
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885271867567843
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884975892967647
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884600285602652
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884309515039971
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6883989091962576
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883754149991639
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883406972885132
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883155516549653
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882883523519222
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882640575462917
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882383016524491
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882200416651639
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6881947528038707

 End of epoch: 21 | Train Loss: 0.6869658459604314 | Training Time: 88 

 End of epoch: 21 | Eval Loss: 0.6905797634805951 | Evaluating Time: 6 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7555998384952545
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.721231397986412
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7096540868282318
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.704052883386612
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7006183397769928
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6982838650544484
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6967286109924317
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6954562447965145
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6944813662105136
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.693719226717949
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6930655035105618
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6925609091917674
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6921310511919169
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.691749586377825
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6914477773507436
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6911785006523132
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6909115577445311
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907050569852193
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6905202875011845
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903416436910629
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6901710058961595
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6900327636436983
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899005674797556
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6897861612339814
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896830775737762
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6895937651395798
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895024213525984
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894118443131447
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893355554547803
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.689267204006513
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891953950928104
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891261888667941
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890595064018712
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889876532204011
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889361791951316
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888705910907851
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6888214467345057
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887650823906848
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887246941908812
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886721186339855
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6886218469317367
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885708679755529
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885277698206347
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.688491803407669
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884583025508457
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884323101976644
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6883905166007103
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.688365550339222
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883370305810655
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883097487688065
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6882863049413643
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882623366438425
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882428153505865
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882249454657237
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6881999566338279
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.688176574238709

 End of epoch: 22 | Train Loss: 0.6869544610512995 | Training Time: 87 

 End of epoch: 22 | Eval Loss: 0.6907304951122829 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7552315175533295
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7211425989866257
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.709770405292511
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7039057314395905
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7005268776416779
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.698294672369957
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6967187293938228
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6954578407108783
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6945193356937832
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6937424671649933
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6931361561471766
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6926235660910607
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6921589956833766
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6917888036796025
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6914983093738556
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912202905863524
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6909879333832685
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907385832733578
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6905321419239044
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903495788574219
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6901909115768614
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900465851480311
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899176146673119
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6897965731720129
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6897041132450104
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895878404378891
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.689494898142638
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6894130772777967
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893338834417277
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892623156309128
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891926115558994
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6891118094325066
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890486357790051
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889767110347748
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889284816810063
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888674951261944
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6888157282326672
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887630734004473
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6887108055444864
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886604791879654
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886090137609622
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885606250592641
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885213979454927
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6884899146177552
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884557037883334
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884187229301618
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6883858693406937
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883504955718914
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.688320990484588
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.688296743273735
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6882749874217837
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.688253653393342
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882195194937148
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6881917082601123
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6881644746390256
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881462401577405

 End of epoch: 23 | Train Loss: 0.6869262549729473 | Training Time: 89 

 End of epoch: 23 | Eval Loss: 0.6900323033332825 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7556538701057434
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7212796300649643
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7101489047209422
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7042582258582115
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7008091032505035
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6985381831725438
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6969418295792171
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6957177869975567
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6947556946012708
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6939757549762726
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.693335774269971
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6927924424409866
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6923429305736836
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6919252374342509
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915997544924418
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912900909781456
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6910295686301063
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6908094180954827
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905958674455944
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6904187962412834
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902538055465335
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6900891114364971
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899528345336085
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.689822144061327
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6897033381462098
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895931654251539
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6894976951457836
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6893964386412076
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893264523867904
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892412519454956
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.689163661964478
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6890979891642928
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890324083241549
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889789938926697
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6889237751279559
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888709876272413
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888031187895182
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6887574669561888
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887151447626261
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.688665438145399
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886192802975818
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885819145611354
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.688527684849362
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6884896795858036
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6884530691305796
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884155916131061
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6883834051324966
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883421412358681
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.688313782701687
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6882905291318894
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882639494596743
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882311791181565
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6881993122820584
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6881840544718283
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6881662446802312
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881501826856817

 End of epoch: 24 | Train Loss: 0.6869267941576189 | Training Time: 90 

 End of epoch: 24 | Eval Loss: 0.6910076652254377 | Evaluating Time: 6 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.75591139793396
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7217260390520096
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.710246326526006
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7045348510146141
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7010017359256744
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6986251761515935
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.696944283587592
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6957213141024112
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6948129336039225
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6940388745069503
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6934057961810719
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6928600375850995
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6923824677100548
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6919965356588363
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6916321559747061
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6913857564330101
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6911013957332163
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6908596634864808
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.690625377391514
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6904519638419151
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902754272733416
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6901162792335856
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899781322997549
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898580965896447
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897370200157166
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6896329996677545
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895228193865882
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6894375511578151
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893516852937895
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892702235778173
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6892017574079575
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6891247291117907
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6890534265474839
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889944397351321
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6889278995990753
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888667454322179
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6888197285097999
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887660376335445
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887258969820462
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886810529232025
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886355596344645
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885869443416596
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885365328123403
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6884936580603773
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884646369351282
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884338809096295
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6884058074748263
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.688384997099638
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883541608343319
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6883254066705704
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882979248084274
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882669682686146
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882358826556296
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882071052436476
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881775197115811
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881553397646972

 End of epoch: 25 | Train Loss: 0.6869243987893636 | Training Time: 90 

 End of epoch: 25 | Eval Loss: 0.6904734202793666 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7555289030075073
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7213067591190339
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.709794036547343
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7040743947029113
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7006368947029114
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6983479817708333
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6967147069317954
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6954499818384647
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6944892757468754
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6937519711256027
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6931661974300037
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6926962941884994
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6922647755879622
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6919065369027001
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6915621709823608
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6912725832313299
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.691034017941531
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.690794422229131
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905996818291513
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6904209014773369
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6902275709878831
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900873078541322
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6899350583553314
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897922453780969
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896745219230652
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895783726985638
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894806815518273
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893722187195506
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6892764255918306
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6891997885704041
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.689133999232323
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890752758830786
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890116548899449
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889607871279997
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6889028268201011
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6888567432761192
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6888061463832855
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887611211914765
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6887119860221178
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886481736600399
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6885938217000264
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885466850939251
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885051655214887
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884795485572381
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884376145733727
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884050434050353
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.688373443040442
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.68834224678576
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883119237666228
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.688288640499115
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882617962126638
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882414890023378
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882237680678097
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881993388688122
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881806350838054
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881613925099372

 End of epoch: 26 | Train Loss: 0.6869368826393533 | Training Time: 89 

 End of epoch: 26 | Eval Loss: 0.690907495362418 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.755721265077591
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7212775439023972
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7099566698074341
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7041398078203202
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7006899845600129
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6983773142099381
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967874424798148
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955515079200267
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6945274227195316
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937736290693283
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931677753275091
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926489556829135
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922043364781599
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6918134370020458
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6914585872491201
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.69119931794703
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909267912892735
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907037691937552
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6904961604821055
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6903198316693306
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6901442902428764
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6899888797239824
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6898630839327108
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897525802254677
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6896560955047607
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895599335432052
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894490665859646
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893559621913092
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.68925487193568
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.689183022181193
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891125717470723
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890502979978919
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889854084361683
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.688928384290022
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888607631410871
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888021224074894
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887624275039982
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887206032087928
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886795074511797
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886346179246903
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885876712275715
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885531716403507
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885084028853926
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884629515084353
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884361211458842
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6883970969397089
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.688370643397595
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.688339555884401
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883029380623176
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882719725370408
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882402651450213
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882188375179584
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6881926424098465
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881752375099394
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881481669165871
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881265610456466

 End of epoch: 27 | Train Loss: 0.686898128437785 | Training Time: 88 

 End of epoch: 27 | Eval Loss: 0.6904453124318805 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7547311782836914
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7209899812936783
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7094921390215556
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7040085718035698
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7006602203845977
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.698372624317805
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6967755351747785
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6954479500651359
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6945058491494921
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937675642967224
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931760760870846
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6926683376232783
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6922111121507791
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6918402480227607
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.691495197614034
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912139110267163
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909621705027188
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6907667527596156
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6905649172632318
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903886878490448
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6902146557966868
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900793996724215
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6899595576783885
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6898412853479385
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6897253518104554
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6896052523301198
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6895233858514715
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6894287699035235
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6893352574315564
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6892415167888005
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891564384583504
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.68908970952034
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6890398473450632
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889769680359784
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6889192407471793
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888627042373021
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6888135893924816
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887636835637846
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6887115469345679
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886597140133381
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6886218270150627
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885827504453205
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6885456568973009
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6885023870251396
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884685156080458
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6884342119745587
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6884002865628993
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883607152849436
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883317932790639
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6883014334440232
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882737474114287
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882396647563347
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882189525748199
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6882021356511999
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881754241206429
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881496926503522

 End of epoch: 28 | Train Loss: 0.6869203427196604 | Training Time: 89 

 End of epoch: 28 | Eval Loss: 0.6908280764307294 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7555633962154389
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7213609397411347
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7097721815109252
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7041247069835663
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7006057989597321
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6983765830596288
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6967612036636898
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6955454021692276
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6945735428068373
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6938028806447982
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6931430372324857
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926311219731967
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6922058375982137
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918123343161174
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6914792203903198
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911954525858164
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909288823604584
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907213042179744
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905102042775405
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6903454893827439
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.690181406055178
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6900296232917092
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898939609527588
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6897550250093142
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896507625579834
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6895454922547707
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894634134239621
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893713484917369
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6893031297058895
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.689224530061086
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891555945719442
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890782641246915
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6890311616839785
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.688977557070115
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6889150554793222
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888610091474321
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887948215007782
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887440369317406
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886814575928908
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886411134898662
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885941724951674
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.688546611439614
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885035245917565
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884638966484503
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884199840492672
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6883847306603971
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.688352010605183
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883213754743338
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.688295984754757
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882754148244857
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882372775498559
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882084415509151
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6881812558983856
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881672949702652
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881419864567844
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881236118929727

 End of epoch: 29 | Train Loss: 0.6868952791247748 | Training Time: 87 

 End of epoch: 29 | Eval Loss: 0.6906755651746478 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7553941190242768
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7210933446884156
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7097251296043396
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7040015578269958
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7006455957889557
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6983508348464966
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6967149300234659
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6954747654497624
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.694465286201901
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937108671665192
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6931056141853332
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6925753225882848
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6921574120338146
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6918138231549944
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6915025361378988
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6912407748401165
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6910054638105281
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6907822923527823
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6905781946684185
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6904161494970321
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6902494776816596
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6900994750586423
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6899465102216472
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6898092418909073
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896732938289643
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895611593356499
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894611808988783
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893727236560413
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892859417816688
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.689203539888064
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891161295675462
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890466531738639
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889814620668238
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6889209521167419
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888500540597098
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887978308730656
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887436625119802
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886961551089036
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.68865942634069
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6886069816350937
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885536391560624
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885127845264617
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884804061678953
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884390537034382
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884061306052738
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883816650380259
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883522892251928
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.688314855719606
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6882800733556553
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.688260733127594
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882328793114307
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.688202786904115
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881791108059433
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881602663684774
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881341433525086
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881108932197094

 End of epoch: 30 | Train Loss: 0.6868786477409633 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6901415416172573 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7554639637470245
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7211286574602127
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.709837285677592
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7042050018906594
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7006799137592316
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6983300904432933
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6966478943824768
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6954257093369961
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6944956269529131
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.693728923201561
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6931031156669963
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6925715501109759
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6921211338960207
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6917711381401335
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914524130026499
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6911607407033443
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6908908205873826
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6907002124521467
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6905245078237433
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.690341460108757
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901801228523254
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6900291459126906
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6898921852526457
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6897800534963607
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.689644829750061
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895366317950762
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894355590696688
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6893371626734733
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6892480042474023
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6891732194026311
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6890918104879318
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890381874516607
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6889745999466289
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889095751678243
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888535218579429
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6887941736314032
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.688747334319192
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887076103373577
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886665709507771
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6886090710759163
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885665535926819
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885286905935832
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884877716386041
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884531756693667
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.688428310420778
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883893584427626
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883488698208585
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883165934433539
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6882807136798391
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882533165216446
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882272373227513
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882045702292369
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881772517033343
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881490512026681
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881256166371432
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881081774830818

 End of epoch: 31 | Train Loss: 0.6868837267951627 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.6902169074331012 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.75521879196167
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7210986912250519
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.709720927476883
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7040207490324975
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7005289876461029
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6981916387875875
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6965626461165292
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6953645788133145
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6944555719693501
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937015783786774
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6930764918977564
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6925401623050372
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921270008270557
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.691750140275274
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914320933818817
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911290038377047
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6908785571070278
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6906678289175033
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6904973315565209
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6903044122457505
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901409359205337
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6899982278997248
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898511477138685
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897266599039237
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.68960183095932
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6894946258801681
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6893889934928329
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893115916422435
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892193292749339
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891352854172389
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6890697186993014
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6889960879459978
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889258299813126
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6888616502285003
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888135022776467
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6887556392285559
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887045270687825
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.688662305317427
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.688613692460916
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6885763216018677
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885395095115755
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6884945774362201
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.688461218185203
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.688416240838441
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6883796889252133
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883515693571256
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883205209640746
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6882998241732518
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6882669889197057
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882354344129562
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882142987905764
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6881880407149975
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881645274612139
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881487759175124
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.688129990642721
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881032213568687

 End of epoch: 32 | Train Loss: 0.686875976081443 | Training Time: 88 

 End of epoch: 32 | Eval Loss: 0.6908842495509556 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7556875705718994
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7213876694440842
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7099377810955048
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7041437089443207
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.7006215727329255
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698305140932401
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6966501040118082
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953573226928711
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6944000462690989
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6937081325054169
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6931007645346902
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925447821617127
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6921341974001665
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917672459568296
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6914335298538208
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911519415676594
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908956289291381
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906908657815721
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904776482205642
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6903110578656196
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6901630061013359
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6900133959271691
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898863828700522
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6897577332953612
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6896278440952301
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6895249362175281
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6894171792047995
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893309671963964
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892401748690112
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891719651222229
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890917885688044
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6890230379998684
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.688953290383021
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888941768337699
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888424042293003
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887971157828967
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887486865391602
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.688707937221778
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886518530356578
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885998129844666
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885689893873727
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885247498750686
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884847132272498
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884457930922508
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.688407150639428
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883807538644128
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883424369578666
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883057003219922
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882732425417218
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882506958246231
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882233162720998
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882007462474016
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881731911650244
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881518443425496
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881333667581732
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881055967083999

 End of epoch: 33 | Train Loss: 0.6868821154653498 | Training Time: 88 

 End of epoch: 33 | Eval Loss: 0.6907086031777518 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7560398995876312
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7213456779718399
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7098165233929952
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7041002511978149
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7007164740562439
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6983149200677872
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6967063631330218
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6955259248614312
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.694626843267017
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6938101869821548
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6931664667346261
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6926123991608619
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921923958338224
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6918308219739369
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6915322279930115
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.691227376461029
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6909597607219921
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6907181236479017
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6905241812530317
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6903541588783264
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901768769536699
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6900145958770405
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898767533509628
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897696075340112
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6896436305046082
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.689545329946738
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894447366396587
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893541495714869
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892686108063008
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891959275801977
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.689113535035041
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890422310680151
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889666793924389
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6889001434340196
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888431530339377
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887894572483169
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887321923230145
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886863333614249
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886402775079776
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885859540104866
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885391039092367
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885067836159752
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.688454410503077
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884188867428086
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6883881521224976
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883468889671823
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.688324170416974
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6882975334922473
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882717318680822
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882490434646606
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882260787720774
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6881931020663334
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881691059976254
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881419296617861
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.688121132850647
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880949034222534

 End of epoch: 34 | Train Loss: 0.6868698514668288 | Training Time: 89 

 End of epoch: 34 | Eval Loss: 0.6907075132642474 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7552163124084472
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.720820939540863
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7094678620497386
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7038047403097153
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7004649937152863
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.698213009039561
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6966035153184619
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6954258769750595
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.694493685166041
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6937519323825836
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931068480014801
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.692614761988322
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921686291694641
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6917775111539023
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914528846740723
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6911671023815871
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6908937994171591
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907043314642376
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905018185314379
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.690330910384655
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901764977545966
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900192111730575
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898777306079864
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897399378319581
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896393840312958
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895215463179808
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894183432614361
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893161992941584
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892225951984011
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.689157569607099
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6890786876601558
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890081334859133
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889489446625565
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.688879257440567
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6887984110627856
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887431583470769
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887018558141348
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886617580526754
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886150242426456
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885538518428802
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885120729120766
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6884864188375928
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884562339893607
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884158876809207
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883910542064243
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883643434099529
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.688331105227166
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6882959045469761
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882705305303846
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882443987131118
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882208632487877
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6881976873828815
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881675731461003
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881431574070895
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881196959452196
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881027389849935

 End of epoch: 35 | Train Loss: 0.6868811837339823 | Training Time: 89 

 End of epoch: 35 | Eval Loss: 0.6907952342714582 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7554325997829437
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7210316896438599
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7097247401873271
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7038144707679749
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7003875350952149
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6981325914462407
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6964747352259499
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6952866487205028
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6943394694063398
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6935997200012207
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6930048584938049
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6924914240837097
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6920426460412833
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6916976043156216
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6913385760784149
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6910647679120302
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6908212626681608
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6905868924326367
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6903914122205032
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6902055737376213
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6900475624061766
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6899055898189544
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6897710893465125
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6896213879187901
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6895202724933625
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6893922535272745
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6893183279920507
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6892455733248166
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6891761703737851
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6891123044490814
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6890436403213008
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6889708297327161
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889037027503505
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6888397660325555
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6887904691696167
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887355777952406
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6886861437075847
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886300581066231
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6885883082181979
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885400840640068
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885043401543687
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6884780516227086
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884494947832684
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884152004664594
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6883773619598813
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883466553428899
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.688322107842628
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882873992125194
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.688269593277756
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882412366867066
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6882172489867491
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881888897373126
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881654038744153
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881423442452043
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881061684001576
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880823008716106

 End of epoch: 36 | Train Loss: 0.686854561662252 | Training Time: 91 

 End of epoch: 36 | Eval Loss: 0.6905830587659564 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7554171144962311
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7211033403873444
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7096879223982493
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7040784731507301
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7006471395492554
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6983696480592092
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6966759128229959
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6954924508929252
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6945364813009898
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.693757176399231
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.693107976696708
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6925884619355201
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6921410574362828
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6917581285749163
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6914062444368998
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.691112856939435
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6908459544181824
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.690631581346194
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904273723301134
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6902558758854866
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6900699490592593
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6899382436817343
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6897979122141134
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6896900904675325
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6895795457363129
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6894846157385752
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6893786942517316
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6892908396465438
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6892235155763298
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.689147557814916
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6890838809551731
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6890227720141411
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889675873698611
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.68888439273133
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888345737116678
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.688785281446245
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6887328302538073
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6886852123235402
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886356112284538
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6885996448993683
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885545272652696
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6885096169653393
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884681754334029
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.688427896797657
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883995317088233
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883668464163075
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.688321165581967
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6882943725834291
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882671987523838
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882421358823776
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882177804030624
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881923424509856
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881657601527448
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881377023679239
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881117991967635
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880881562829018

 End of epoch: 37 | Train Loss: 0.6868609271218291 | Training Time: 89 

 End of epoch: 37 | Eval Loss: 0.6902740512575422 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7553624927997589
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7211940288543701
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7097014307975769
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7039985999464988
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7006119990348816
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6982344388961792
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6966504922934941
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6953643560409546
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6943813112046984
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6936718547344207
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6930401921272278
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6925102427601815
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6920625122693869
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917150037629264
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6913861787319183
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6910790704190731
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908085928243749
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6905813558234108
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6903622564516569
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6901980510354042
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6900353968143463
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6898879766464233
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6897571454877439
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896308732529481
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895219583511353
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6894368173984381
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893285629925905
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892404643552644
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6891457050011076
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6890638824303945
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6889932726660083
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889420628547669
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6888814983945905
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888177482520833
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6887619629928043
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887088441186481
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6886610274379318
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886278445783415
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6885725334668771
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885369700193406
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6884869169898149
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884498610382989
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6884254151998564
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6883861154317856
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883550551202562
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883155611546143
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6882849014819936
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882620812704165
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882366960145989
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882041190862656
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.688184147605709
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6881656094239308
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.68813452855596
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881123301055696
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6880979593233628
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880695725125926

 End of epoch: 38 | Train Loss: 0.686841778839584 | Training Time: 89 

 End of epoch: 38 | Eval Loss: 0.6901340484619141 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7557297706604004
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7214611083269119
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7099283635616302
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7041721299290657
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7006812226772309
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983773718277614
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.696709064074925
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6954811237752437
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6945473909378052
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.693792467713356
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6931070376526226
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.692560675740242
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6921147511555599
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917396473033087
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.691412297487259
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6911136519163847
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6908410675385419
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6906104190482034
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6903858351080041
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6902290454506874
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6900857868648711
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899603979154066
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898094905459362
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897083215415478
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.689592943906784
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894685289034477
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893675212506895
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6892661650265967
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6891851178530989
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891035415728887
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890233497465811
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.688946533575654
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6888869814800493
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888247517978444
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6887749118464334
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.688716298672888
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6886675141953134
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886252536585457
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6885769575070112
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885335974395275
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6884901245919669
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6884490880228225
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884091079235077
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6883763661438769
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883438730239868
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883071068836295
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.688286991575931
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6882544606924057
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882163628023498
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6881937580108642
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.688170313133913
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881495027587964
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881287524160349
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881086657444636
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.688092624057423
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880756796470711

 End of epoch: 39 | Train Loss: 0.6868500689489652 | Training Time: 89 

 End of epoch: 39 | Eval Loss: 0.690295900617327 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7555950701236724
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7213215291500091
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7097291866938273
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.704060061275959
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7005497074127197
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6982947170734406
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6967039125306266
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954385593533516
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6944813125663334
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937425738573074
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6931178694421595
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.69259143024683
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.692125287422767
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917537118707384
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914063068230947
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911083541810512
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908754885196686
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.690656128194597
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904588715026253
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.69029953032732
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901292979717255
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899685797366228
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898167711237203
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6896683034797509
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6895658626556397
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6894702510191844
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6893763138188256
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6892847003681319
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892057379771923
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891341817378998
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890630706664055
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6889829037711024
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889208641919222
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.688850227173637
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6887896014962878
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887230922778448
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6886752006169912
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886233398788854
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6885719131200742
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.688539310246706
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.688496185948209
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884551465511322
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884174028108286
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6883874668316408
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883518001768324
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883147064758384
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6882819769230295
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882574286311864
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882240582485588
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6881997824907303
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6881654218131421
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881439682382804
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881198288134809
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6880985073469303
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6880801662531766
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880630857178143

 End of epoch: 40 | Train Loss: 0.6868380778658707 | Training Time: 89 

 End of epoch: 40 | Eval Loss: 0.6904827782085964 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7554538667201995
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7210933357477188
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7096047262350719
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041171982884407
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7005912399291992
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6982712854941686
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6965593184743609
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6953463405370712
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6943712115287781
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.693606978058815
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6929557691920888
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6924291337529819
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6920370257817782
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6916559508868626
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6913093054294586
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6910251021385193
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6907986223697662
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6905917790200975
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904121129136337
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6902324715256691
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6900806293601082
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6899264346469532
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6897788799327352
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6896717083950837
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6895670821666717
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6894717393013147
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6893705125208254
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.68929115320955
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892056177402365
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.689129444360733
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6890612748361403
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.688987716846168
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889168995799441
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6888604122049669
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888137689658573
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887654779685868
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887172900341653
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886654809901589
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886113715477479
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.688561655730009
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885180130237486
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6884827447789056
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884468384953433
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884123676202514
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6883702782789866
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.6883390387763147
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883085961037494
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6882778150339921
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882405563276641
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882126193046569
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6881905650391298
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881680697202682
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881515329738833
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881289924736376
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.688099623376673
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880738090191568

 End of epoch: 41 | Train Loss: 0.6868442074387474 | Training Time: 88 

 End of epoch: 41 | Eval Loss: 0.6906700985772269 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7557450473308563
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7212181091308594
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7096286733945211
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7039074823260307
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7004381608963013
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6981322397788365
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6965031726019723
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6953258767724038
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6943593051698472
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6936168831586838
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6930394817482342
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6924823542435964
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6920830538639655
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6917164381061282
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6913991399606069
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911431655287743
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6908918089726392
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6906668742497762
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6904666125774384
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6902583906054497
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901101892902738
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6899620606140657
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898392244525577
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6896982595324517
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6895834143161774
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6894859992540799
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6893937274261758
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.689275489108903
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6891972792559656
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891175532341003
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890514435306672
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6889858352020383
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889155469157479
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888579799848444
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888083010060446
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887575374709235
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6886919802910573
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886529470744885
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886049434160575
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885607521235942
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885212100133663
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884852258932023
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884470569532971
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.688404407961802
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883680310514239
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883375300013501
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883066551482424
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882857259362936
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882560045135264
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882216053009034
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6881853318681904
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881626140612822
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881344198055988
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881082359287474
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880895961414684
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880681838308061

 End of epoch: 42 | Train Loss: 0.686843573308624 | Training Time: 88 

 End of epoch: 42 | Eval Loss: 0.6900817155838013 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7551118075847626
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7209228485822677
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7094389379024506
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7036762654781341
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7003513157367707
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6981643905242284
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6965887197426387
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6953286483883858
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6944164673487345
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.69367136657238
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6930271939797835
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6925611565510432
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6921293909733112
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6917491487094334
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914606845378876
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6911594942212105
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6909407370230731
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6907144159078598
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6905059692106749
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6903175747394562
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6901603272983006
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6900024823167107
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.689861324040786
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897337161004543
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6896225998401642
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6894978754795514
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6893886045173362
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6893068279538835
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892245479698839
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891583820184072
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890743786288845
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6890080159530043
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.688943490115079
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888766301028869
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6888118704727718
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887573584914207
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6887095580229888
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886623537854144
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6886195415105575
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885773767530918
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885345300523246
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6885014816409065
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884655273237894
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884280785918235
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883917297257317
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883504069369772
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6883195393897118
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882896235833565
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882649386415676
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.688236407160759
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6882009461814282
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881729167241316
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881462147775687
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881203556502307
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6880903465097601
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880662362490382

 End of epoch: 43 | Train Loss: 0.6868411147488956 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.6905443753514972 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.75538250207901
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7212642043828964
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.70974760055542
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7039700388908386
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7004718017578125
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6981573532025019
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6965616609369005
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.695337713509798
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944022132290735
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6936389303207398
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6929612073031339
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6924282689889272
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6919636863928574
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.691562356693404
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6912579202651977
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6909897074103355
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6907286759685067
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6905175308386485
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6903414810958661
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6901696729660034
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6900081696964445
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6898642973466353
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6897415780502817
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6896083767215411
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895095131397248
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894100906757208
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893002724206007
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6892247668334416
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6891490623868745
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6890810068448384
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890214460511361
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889521528035403
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6888927326057896
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888371946180568
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6887804453713553
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887256180246671
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6886873282290794
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886388795940499
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.688593780535918
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885593184828758
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885042462407089
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884643852710723
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.688427022584649
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6883809724991972
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883474618858761
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.688316092154254
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6882811872248954
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882486888517936
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.688220926085297
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6881907442808152
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881681062427222
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881389686694512
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881115270110796
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6880895582614122
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880668577280912
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880472475928919

 End of epoch: 44 | Train Loss: 0.6868273878519514 | Training Time: 87 

 End of epoch: 44 | Eval Loss: 0.6895069054194859 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7557618200778962
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.72111976146698
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7096031208833059
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7039163067936898
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7004418575763702
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6982053359349568
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6965822058064597
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6954183079302311
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6944556792577108
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6937322181463241
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6930868219245564
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6925441399216652
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921047916779152
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917143957955497
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913890902201335
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6911329668015241
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6908860630848829
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906357500288222
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904481285496762
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6902692818641663
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.690115277540116
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899528075348247
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6898011236087136
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896964887777964
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895796699523926
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894469394133641
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893528242905934
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892699784466199
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6891849213633044
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891114801168442
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890292732946335
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889546368271112
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6888793441382322
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888183511355344
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887530902453831
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887092605233193
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886520782032528
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886177571196305
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6885725780939445
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.6885302802920341
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6884874654979241
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884544366881961
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884216738301654
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6883866707032377
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.688352242840661
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883216185414273
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6882987708487409
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882630859812101
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882214246963968
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6881915969848633
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.68816137454089
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881400899245189
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881148390050205
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6880887508392334
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880652670426802
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880440206399986

 End of epoch: 45 | Train Loss: 0.6868159786789818 | Training Time: 89 

 End of epoch: 45 | Eval Loss: 0.6903246556009565 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7553609430789947
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7212009906768799
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7097277343273163
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7040189862251282
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7005377352237702
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6983252336581548
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6966938274247306
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6954873904585839
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6945066432158152
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.693745750784874
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6931159962307323
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925643722216288
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921103550837591
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917277927909579
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6914147623380025
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911274809390306
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6908659209223355
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906395922104518
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6904382774704381
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.690275964140892
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901199806304205
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899622378024188
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898202051287112
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6896982287367185
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895979001522065
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894910862812629
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893919560644362
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892976575664111
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6892133299646707
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891350793838501
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890501285752942
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889685751870275
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6888990873640234
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888429405058132
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887696070330483
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887076858017179
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886751845076278
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886247595674113
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6885871627391913
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885293553769588
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6884904073505866
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884545360292708
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884160043195237
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6883752942085266
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883519162072076
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883148499157118
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.688300632796389
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882776090254387
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882540250311092
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882290284633636
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881907685130251
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881627881756196
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881389376127495
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881167747356274
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.688097888989882
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880719466933183

 End of epoch: 46 | Train Loss: 0.6868512337186695 | Training Time: 89 

 End of epoch: 46 | Eval Loss: 0.6900869267327445 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7554501056671142
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7211227655410767
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.709572837750117
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7039955541491508
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7005074512958527
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6982483764489492
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6966016003063746
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6953285723924637
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6943988018565708
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6936430889368057
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6930096236142245
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6925096412499746
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6920763483414283
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6916885746376855
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6913759167989095
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6910765688866377
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908095524591558
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6905823551946216
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.690400167829112
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902237614989281
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900472975912548
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6898923434994437
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6897822932056759
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896468388537565
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895315039157868
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894403090843788
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893506206848004
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892573750444821
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891742019817747
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6890856973330179
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890191729991667
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889549784362317
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.688888036662882
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888358521110871
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6887872518811907
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887414594491322
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6887043920723168
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886579193566975
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6886121755991227
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885577192902566
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885110753338511
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884741002605075
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.688443920224212
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.688403184576468
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883689514795939
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883296709993612
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6883016629421964
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882707104086876
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882482462999772
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6882234785556793
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881845904331582
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.688158176953976
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881280322119875
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6880967098253744
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.688082126270641
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880648340497698

 End of epoch: 47 | Train Loss: 0.686839293800624 | Training Time: 89 

 End of epoch: 47 | Eval Loss: 0.6900338019643512 | Evaluating Time: 5 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7559544384479523
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.721207320690155
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7096246242523193
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7039641305804253
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7005974507331848
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6983596483866373
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6967116986002241
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6954571776092052
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.694489472442203
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.693728872537613
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931144958192652
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6925772751371065
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6921384444603553
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6917824391807829
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914425706863403
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911372113972902
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908715104355532
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6906245417065091
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6904087785043215
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902248752117157
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6900639641852606
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899147415702993
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6897814017275106
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6896754550437133
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895596697330475
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.689465078482261
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893524545210379
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892544320651464
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891709027619197
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.689090869029363
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.689021336455499
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889517195522785
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6888843621268417
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888130421147627
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6887574359348843
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887154552671645
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886638257954572
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886167706627595
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6885784642818646
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885357244312763
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6884884691819912
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884402556078775
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6883980371231256
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883661165833473
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883208086755541
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6882936657770821
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6882680492198213
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882398186872403
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882130002488895
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881853017807007
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881595903751897
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881368807875193
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881065814000256
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6880843541136494
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880627425150437
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880410018776144

 End of epoch: 48 | Train Loss: 0.6868126677200858 | Training Time: 90 

 End of epoch: 48 | Eval Loss: 0.6903776100703648 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.75494863986969
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7207859516143799
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096046487490336
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7039084404706955
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7005279779434204
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6982032855351766
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6965968549251557
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6953791849315166
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6944257630242242
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6937142759561539
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930958921259099
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6925832266608875
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6921412252462827
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6917504646948406
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914199129740397
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6911176830530167
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.690870384608998
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906321509016885
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904286312429528
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902458101511002
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6900942407903217
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899576821110466
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.689827835559845
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6897140632073084
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895923883914947
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894747708852474
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893788540804827
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6892887209142957
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892000856070682
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891167054573695
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890562786209968
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889971394091845
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889455806125294
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.68886859942885
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888068721975599
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887573757105403
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6887038681958173
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886432886123657
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6886011462945204
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885608011484146
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885164920876666
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884749338740395
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884304052175477
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883867112073031
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883505018552144
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883200890344122
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882906761575253
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882603228092193
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882182757465207
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6881912602186203
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881550601884431
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881293075589033
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881078008210884
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6880885934388196
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880674183368682
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880445446286882

 End of epoch: 49 | Train Loss: 0.6868176599519442 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.6898692931447711 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7552426517009735
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7208476066589355
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7093917230765024
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7037584900856018
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7003524339199066
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6981254269679388
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6964882731437683
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6952304393053055
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6942965646584829
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6935531866550445
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6929319024085998
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6924003918965658
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6920035829910866
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6916390252964837
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6913559063275655
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6910885129123926
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908096366068897
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906119638019138
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904193846802963
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6902410957217217
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6900741690681094
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899410651488738
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898133622563404
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6896622218191624
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895451669692994
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894576721466504
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893552049442574
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892748040812356
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891920447349549
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6891209918260575
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890592227059026
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889802742749452
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6889090086474563
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888518256299636
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887799964632306
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887131207519107
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.688665963669081
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886072209006862
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6885591754546532
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885163153707982
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.688471045726683
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884318333296549
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6883981006090031
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883669658140703
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.688334525293774
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883029313191124
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882689859004731
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882317160566648
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6881998676426556
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6881763957738877
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881512688655479
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881280416479477
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881160342468405
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880902509998392
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880616980249231
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880386962422302

 End of epoch: 50 | Train Loss: 0.6868120585922647 | Training Time: 89 

 End of epoch: 50 | Eval Loss: 0.6902398381914411 | Evaluating Time: 5 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7551141440868377
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7210224449634552
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.70959858695666
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.703805311024189
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7004056167602539
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6981490085522334
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965384840965271
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953395664691925
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6944331970479753
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.693669438958168
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930480377240614
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6925319919983546
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920736950177413
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6917102988277163
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.691372135480245
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6911286454647779
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.690862305024091
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6906505435705185
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.690445045420998
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6902664887905121
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900844625064305
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6899356915192171
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6898141549981158
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896812962989013
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895543730258942
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894734031878985
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893847602385061
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892802255494254
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891901959633006
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6891079894701639
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890414983995499
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889715587720275
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.688900335629781
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888407412697287
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887940987518856
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887357297870847
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886948311651075
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886370434572823
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.688578507839105
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885352425277234
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884939593512838
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884449215162368
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884062816930372
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883671910925345
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883444033728705
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883167678895203
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6883007130724319
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.688279843578736
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882416756785645
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6882058497667313
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881731503150043
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881464035465167
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.68811717651925
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880971573017262
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880727836218747
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880442145679678

 End of epoch: 51 | Train Loss: 0.6868217357492025 | Training Time: 88 

 End of epoch: 51 | Eval Loss: 0.6902281812259129 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.755538386106491
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.721237576007843
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7098411480585735
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.704167976975441
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7007773566246033
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.698482138911883
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6967977770737239
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6955917663872242
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6945822536945343
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6938359016180038
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6931685398925435
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6926334425806999
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.692202379153325
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6918263473681041
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.691477388938268
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911970049142837
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.690937815694248
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906913621558084
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904723095266443
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902985394001007
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901364491099403
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899871162392877
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6898544422958208
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6897145013014475
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895753431320191
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894586134415407
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893741503909782
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892621632133211
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891785085201263
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6891013365983963
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890324071530373
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889574630185962
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6889005066770496
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888360796605839
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887832834039416
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887330096628931
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886848356272723
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886294438650734
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885820116752234
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885320308804512
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6884924062868444
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884575093076343
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884029321892317
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883715009147471
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883392582999336
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883048610842746
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882740057529287
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882405449946721
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882166318747462
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881870965957642
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881591826092963
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881363560373966
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6880997870328291
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880794862906138
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880592047084462
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880373527961118

 End of epoch: 52 | Train Loss: 0.6868144978464177 | Training Time: 88 

 End of epoch: 52 | Eval Loss: 0.690269010407584 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7555730104446411
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.721042338013649
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7094846685727437
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7037624701857567
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7003335344791413
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6980679611365
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6964620675359453
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6952253863215446
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.694305290778478
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6935552150011063
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6929235008629886
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6924303273359934
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6920317269288576
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.69162594803742
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6913344613711039
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6910747196525335
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908148137962117
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6905811154180103
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6903749277717188
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902108991146088
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6900767854281834
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899316963824359
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.689787286001703
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896751940250396
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6895797469615936
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894668780840361
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893709427780575
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.689269004549299
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6891843347713865
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6890898935000102
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890281104272412
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889451246708631
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6888814929759863
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888293934219024
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.688778510604586
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887195967965656
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6886691770038089
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886151509849648
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885633506836035
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885187393426895
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884720379259528
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884389570781163
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.688401449003885
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6883613129908388
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883298899067772
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6882973165615746
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882593948790368
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882313294957082
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882079777668934
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881813080310821
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881565427078921
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881313898242437
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.688108566684543
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6880870821299376
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880591026219455
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880382662372929

 End of epoch: 53 | Train Loss: 0.6868142880169691 | Training Time: 87 

 End of epoch: 53 | Eval Loss: 0.6905704481261117 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7555075943470001
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7211817592382431
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7097412486871083
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7040272355079651
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7004526603221893
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6981969356536866
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6965659865311213
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6953800827264786
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6944575627644857
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6936844855546951
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6930424245921049
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6924883450071017
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6920583894619575
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6916918286255428
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6913831412792206
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911080997437239
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6908607910661136
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6906046251455943
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6904196877228587
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6902315059304237
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.690055927776155
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6899025605483489
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6897668449775033
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6896381954352061
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895314817428588
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894174105845965
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893336847976402
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892309412360191
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891354682116673
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890640910466512
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6889977645489478
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889345850795507
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888721552762118
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.688810793967808
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887619716780526
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887075300017993
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.688643566659979
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6885948123116242
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885461548964182
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885098633170128
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.688475592398062
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884366845800763
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6883865759816281
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883546409281818
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883181529574924
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6882787410331809
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882508710343787
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882268903156121
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6881842830959631
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881603674888611
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881379834577149
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881155040401679
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881015170295284
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6880683946388739
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880545589056882
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880315441106047

 End of epoch: 54 | Train Loss: 0.686801363409093 | Training Time: 90 

 End of epoch: 54 | Eval Loss: 0.6902184912136623 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7555598199367524
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7210186123847961
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7096325774987539
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7039711207151413
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7005005526542664
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6982154250144958
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6965643056801387
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6953173868358136
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.694389232661989
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6936453080177307
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6930007804523814
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6925317505995433
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6921105990043053
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.691745497073446
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913926676909129
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.691137843951583
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6909007167114931
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6907183322641585
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.690526440896486
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6903451192378998
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6901637974239531
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6900112788785587
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6898481900277345
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6897372330228487
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6896149790287018
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6895071137409944
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6894130483821587
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6893175461462566
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6892346710994326
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6891444577773412
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.689067502175608
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889957457780838
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6889296889305114
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888754918294795
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6888086593151093
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887548272808393
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6887042198632215
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886606818751285
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.68861041084314
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885710842907429
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6885282231540215
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884910167682738
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6884388708791067
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883927243677053
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883482105202146
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6883198783449505
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882869471894933
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882621186474959
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6882236651011876
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881930954456329
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881597022215525
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881342164598978
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881105950418508
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880879098618472
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.688064472025091
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880422878478255

 End of epoch: 55 | Train Loss: 0.6868125182337466 | Training Time: 87 

 End of epoch: 55 | Eval Loss: 0.6900773048400879 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.755580085515976
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7213989049196243
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7099290132522583
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7041396886110306
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7006450748443603
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6983974774678549
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6967258870601654
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6955169536173343
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.694571934805976
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6938298803567886
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.693204356323589
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.692663632829984
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6921961912742027
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6918230554887227
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6915149358908336
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6912138033658266
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6909386119421791
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6907415628433228
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6905247675745111
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6903192478418351
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6901491346813383
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6899849021976644
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6898603784001391
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6897502849499385
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6896227059364319
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6895063354418828
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6893951797926867
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6892946392297745
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6892196936854
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6891192311048507
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6890471571876157
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889787886291743
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6889205573183117
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6888571193989586
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6888043647153037
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6887558465202649
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6887141024744189
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6886421302431508
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885970470232842
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885495452582836
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6885112884568005
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884659115757261
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884191155433654
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.688377331468192
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883375816875034
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.688303168701089
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882700162999174
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882409330457449
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882030271753973
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881680936813355
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881445643948574
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881246684835507
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881021142005921
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880776557657454
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880529534816742
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880286146487509

 End of epoch: 56 | Train Loss: 0.6867962540778438 | Training Time: 89 

 End of epoch: 56 | Eval Loss: 0.6904668041637966 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7557220995426178
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7212629228830337
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7097989718119303
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7040498360991478
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7005700898170472
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.698228508234024
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6965880521706173
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6953812099993228
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944145361582438
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6936294555664062
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930226000872526
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925144215424855
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6920598181394431
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917224305016654
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6913619963328044
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6910752065479755
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6908268591936897
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6905834171507094
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6903465198843103
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6901795732975006
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6900218645731608
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6898554782975804
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6897220155467157
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896065898239613
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6894850597381592
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6893723386984605
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6892775802700608
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6891747872744288
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.689106496038108
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6890314302841822
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6889784697563418
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889207908883691
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888546808199449
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888049307991476
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.688743382862636
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6886905019481977
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886309195209194
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6885800283206137
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.688538486071122
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6884999591112136
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884535200712157
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884131553627196
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6883816174296445
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883419068022207
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883047254880269
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6882743603509406
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882482617459399
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882146692524354
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6881819409983498
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.688158497095108
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881271673183815
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881116727223763
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6880845390400796
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880567923740104
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.688036383932287
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880153009934085

 End of epoch: 57 | Train Loss: 0.6867896736195657 | Training Time: 88 

 End of epoch: 57 | Eval Loss: 0.6906218528747559 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7550344347953797
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7208343118429184
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7096203406651814
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7038955152034759
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.700521434545517
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6982522815465927
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6966257785047804
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6953975066542626
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6944392999013265
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6936423230171204
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6930363774299622
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6925582324465116
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6920584435646351
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916878244706562
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913378997643789
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6910388130694628
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6907627631636227
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6905640463034312
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6903841219450298
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902117666602134
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900326501755487
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6899061552502892
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897800391135008
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896631407241026
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895391623973847
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.689426512672351
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6893414733586488
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.689247321656772
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891505233172712
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6890828323364258
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.689015289275877
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889351530000567
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888750274976094
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888127761728623
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.688750935792923
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6886950390206443
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886430120145952
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6885884888862309
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.688545237443386
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.688496403992176
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884398429858976
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884089073964528
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883753249811572
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883367125283588
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883001817597283
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882625455441682
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882346551469032
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882049322128296
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6881767624494981
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881504058837891
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881270110607147
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881032054240886
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6880815757895415
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880616060009709
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880370796810497
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880147252764021

 End of epoch: 58 | Train Loss: 0.686794092591885 | Training Time: 88 

 End of epoch: 58 | Eval Loss: 0.6902280620166233 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7556773126125336
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7209460437297821
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7095252871513367
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7039497658610344
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7006205558776856
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6983110328515371
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6966818928718567
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6954487353563309
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944892558786604
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.693716613650322
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6930594157088886
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6925437192122141
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6920920463708731
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6917444565466472
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6913944530487061
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911211747676134
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6908828738857719
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.690638037191497
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6904285694423474
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902537795901299
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.690097538346336
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899316194382581
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.689786935630052
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896465552349885
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6895535185337066
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6894627892054044
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.689353350577531
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892795130610466
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891956103259119
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6891086198886236
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890272709631151
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889802228659392
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6889103278969273
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.688853910740684
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887974556854793
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887469778458277
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.688696576936825
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6886448287650159
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885922821668479
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885460975766182
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884985550147731
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.6884562356131417
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6884047311405803
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883811261166226
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883459247483148
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883089898721032
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882745627393114
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.688240106528004
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.688210325703329
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881906366348267
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881664457274418
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881434007332875
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881198407344098
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880857039380956
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880677336996252
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880445966763156

 End of epoch: 59 | Train Loss: 0.6868198249192364 | Training Time: 89 

 End of epoch: 59 | Eval Loss: 0.6906960095678057 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7559264063835144
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7213395982980728
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7096967140833537
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.704017947614193
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7006370508670807
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6983491033315659
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6967317019190107
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6954596810042858
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6944838762283325
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.693738888502121
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6931015020067042
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.692598199347655
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.692124939423341
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917440559182848
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6914354232947032
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911451101303101
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6909138423555038
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906611227326923
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904656858820665
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902896046638489
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901128110431489
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899601762945001
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.689817451134972
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.689673089236021
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895685186386108
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894605283553784
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893699133837664
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892911391598838
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6892064063713468
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6891307187080383
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890414038012105
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889746379107237
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.688922131242174
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888480736928828
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887999383040837
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887448456552293
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886976292004456
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886496286643179
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6886024825083904
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885640403628349
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.68851576389336
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884745176349367
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6884394577769346
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6884056149558587
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883706467681461
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6883329491252484
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882991954367211
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.68826584306856
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882298137460436
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881938786506653
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881621153915629
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881342002978692
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881118808152541
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880917252213866
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880625615336678
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880394020250865

 End of epoch: 60 | Train Loss: 0.686810099551108 | Training Time: 90 

 End of epoch: 60 | Eval Loss: 0.6904487695012774 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7557226419448853
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.721477472782135
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7098745624224345
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7041656672954559
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7007148468494415
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6985178271929423
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6967700030122485
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6955415159463882
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6946039762761858
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6937931984663009
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.693148535490036
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6926445220907529
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6921913619224842
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6917941544737135
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6914660286903381
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6911659009754658
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6908964532263139
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6906833668549855
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904720566774669
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902921849489212
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6901072456723167
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6899580196900801
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6898385713929716
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6897002304593722
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6895585036277772
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894564961011593
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893589560632353
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6892651613269534
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891745380286513
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890973993142446
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890070534521534
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889531634747982
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888912616354046
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888303078272764
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887698980740139
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6887162233392398
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886608626391436
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886064683136187
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885539255081079
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885052838921547
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884575692618765
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884130466552008
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883724378985028
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883372748439962
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883127984735701
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882824012766714
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.688236432506683
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882083309193452
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881762622570505
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881467971801758
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881240145832884
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6880944350591073
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880776947399355
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880577563135712
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.688033531145616
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880157146070685

 End of epoch: 61 | Train Loss: 0.6867883783526125 | Training Time: 88 

 End of epoch: 61 | Eval Loss: 0.6903435587882996 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7550099313259124
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.720922765135765
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7095646500587464
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7037502199411392
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7003800797462464
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.698160860935847
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6965530472142356
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953556165099144
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6943770759635501
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936089253425598
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6929847050796856
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6924639681975047
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.692034466450031
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6916679795299258
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913741731643677
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6910754282027483
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6907915641279782
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.6905728290478389
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6903613341482062
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6901688480377197
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.69002267179035
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.689876219088381
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6897305413432743
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896256640553474
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895119259357453
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6893888608767436
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6892824195049427
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6891857890146119
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891253524813159
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890627495447794
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6889934414817441
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889264164492488
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888563784686002
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888045573935789
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887518497875759
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887046444747184
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886368791799288
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6885861366987228
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885416953991621
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885073187947274
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884621627447082
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884176614738646
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883855000484821
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883407693017612
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883035835954878
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882715137108513
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882289388078324
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882086427261432
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881776060376849
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881463203430176
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881214855932722
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.688100219460634
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880705455564103
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880469572764856
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880292690883983
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880122041063649

 End of epoch: 62 | Train Loss: 0.6867812754833593 | Training Time: 89 

 End of epoch: 62 | Eval Loss: 0.6904488461358207 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.7555123090744018
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7209389269351959
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7097494026025136
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7039047732949257
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7004616236686707
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6982317109902699
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6965916812419891
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6954486578702926
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.694472567902671
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.693694943189621
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.693086468631571
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6925771201650301
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6921206075411577
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6917227238416672
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6914082872867584
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6911249622702599
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6908527290119845
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6906365444262822
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6904501196585203
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902660182118416
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6901070251351311
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6899560001763431
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6898226652456366
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6896998313566048
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895901954174042
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6894767878147272
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6893912476521952
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6892788593258177
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891996264457703
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6891186453898748
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6890437351119134
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889709940180182
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6889009007901856
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6888293676516589
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887606678690229
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6887170907523897
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886593200064994
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885970780723973
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885633659668458
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885096229612827
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884725644821074
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884359767039617
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6884076671544895
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883739112453027
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883516358004675
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6883208134899969
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882839371549322
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882582089553276
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6882237633880304
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881907494068146
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881604883016325
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881385422669924
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6881105848078458
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880828208393521
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880569900165905
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880416512489319

 End of epoch: 63 | Train Loss: 0.6868128110877181 | Training Time: 89 

 End of epoch: 63 | Eval Loss: 0.6904156293187823 | Evaluating Time: 5 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7549440383911132
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7207837224006652
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7094897488753001
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7037831634283066
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7003217077255249
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.69800759156545
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6964447481291635
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.695262323319912
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6942864113383823
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6935185885429382
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.692918636040254
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6924250220259031
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6919805159935585
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6916356712579728
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6913178555170695
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6910590548068285
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6907856678261476
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6905572944217258
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.690349742299632
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6901618897914886
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.689997186547234
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.689834160154516
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6897044728631558
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896052402754624
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6894805190563202
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6893764670078572
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6892895998778167
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6891902789473534
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891091889348523
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890278991063435
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.688968530585689
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6888978822156787
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888226402528358
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6887670942965676
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887248904364449
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6886766195297241
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.688620120125848
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6885647936871178
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885334253311157
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6884944705665111
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884489808140731
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884100387493769
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883731069952943
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883491556752812
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883173716068268
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882883073195167
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882592348342246
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882234223186969
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6881937237418427
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881660574674606
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.688131924236522
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881004612033184
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880693035305671
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.688050146566497
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880262305519798
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880095675587654

 End of epoch: 64 | Train Loss: 0.686781940734492 | Training Time: 88 

 End of epoch: 64 | Eval Loss: 0.6899933985301426 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7555088579654694
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7214069783687591
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7098532597223918
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7042065724730492
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7006456673145294
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.698302901784579
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966224108423505
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953747995197773
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6944091399510701
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936309450864792
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6930296935818412
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.692487083375454
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920310955781203
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.6916530770914895
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913331615924835
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6910405129194259
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908022635123309
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6905783987707562
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6903961165955192
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902032554149627
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900268807297661
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.689868528734554
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897356906662817
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896199660996596
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6894914064407348
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6893857898620459
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6892925255828434
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.68919603569167
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6890873323226797
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890199699004491
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6889559088214752
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6888950640335679
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888474717284694
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6887789664899602
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887166173117502
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6886732245484988
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886171566473471
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6885711403269517
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.688535319077663
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6884920248389244
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884530929530539
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884143661885035
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6883827551852825
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883481903509661
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883248543739319
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882882969534916
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882639261002236
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882339203109343
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882115714404048
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881821331977844
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.688153983448066
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881105115780464
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6880832491055975
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880646860158002
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880358797853643
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.68801283080663

 End of epoch: 65 | Train Loss: 0.6867865730175929 | Training Time: 88 

 End of epoch: 65 | Eval Loss: 0.6900158865111214 | Evaluating Time: 6 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7549075543880462
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7208776205778122
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7095872759819031
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7038931906223297
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.700458288192749
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6981623748938243
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6964852256434304
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6952563568949699
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6942924327320523
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6935768324136734
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6929321695457805
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.692396092414856
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6919918174927051
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916529842785426
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.691350508928299
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6910315692424774
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6907911612707026
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6905681825346417
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6903754438224592
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6901830795407295
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.690019294761476
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.689870841123841
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897149682044983
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6895835702617963
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6894628863334655
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6893761978699611
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6892876825950763
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.689194715661662
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6890967015562386
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890237434705099
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6889499181701291
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.688879189454019
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888194784973607
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887598821345498
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887137487956456
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886613435215421
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.688599063899066
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885349769341318
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6885033294176444
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6884556029736996
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884262843829829
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6883832375208537
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883429760156676
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883086140860211
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6882796903451284
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882476607094641
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882049772333592
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6881831421206395
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6881597726928944
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881289591789246
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.688116675381567
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6880949676036835
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.688082424199806
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880666302310096
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880410002578389
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880188158580235

 End of epoch: 66 | Train Loss: 0.6867946579393033 | Training Time: 88 

 End of epoch: 66 | Eval Loss: 0.6905512128557477 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7558047890663147
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7213412582874298
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.709940892457962
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7040527179837227
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7006017851829529
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.698311181863149
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6966244918959481
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6954535894095898
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6944800423251258
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6937285423278808
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6930922161449086
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925545806686083
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6921326958216154
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6917172925812858
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.691393659512202
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6910951573401689
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6908424324849073
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6906322502427631
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904389080248381
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6902486711740494
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900944113731384
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899215446277098
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6897938508054484
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6896623944242796
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.689541217803955
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894410266326024
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893406340369472
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892437281353133
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891768689813285
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6890834617614746
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890116391643402
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889482773840427
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.688887233986999
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888275898554745
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887737573896136
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6887203849024243
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886669268479219
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.688612384231467
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885567645231883
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885190886259079
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884792795995387
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884486306281317
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6884095162846321
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883703781799837
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883265182707045
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882855112138002
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882544341239524
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882242303341627
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882021810327258
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.688176346540451
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881505312872868
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881221554600275
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880947310969515
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880677206648721
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880339322306893
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880099247608866

 End of epoch: 67 | Train Loss: 0.6867829745849677 | Training Time: 89 

 End of epoch: 67 | Eval Loss: 0.6903930902481079 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7550118863582611
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7210065484046936
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7097586035728455
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7040985286235809
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7006794846057892
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6983448177576065
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6967039236000606
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6954631894826889
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944998688167996
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6937540519237518
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6931008089672436
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925620446602504
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6921077104715201
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6917492611067636
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6914126364390055
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6911101814359426
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908554848502664
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6906414382987552
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6904450683217299
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902374535799026
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900763310137249
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899290472269058
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.68979572057724
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896539400021235
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895406239032745
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894312688937554
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893306489343997
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892465980989593
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891552351672073
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6890809790293375
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890138012747611
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889292195439338
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888729807102318
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888085885959513
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887469128199986
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6886839292115635
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.6886390222085489
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6885938595784338
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885462517921741
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885031516849994
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884593677229998
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884253364233743
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.688390401490899
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883474547754634
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883119191063775
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882834373608879
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882510739438077
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882253965983788
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881984722857573
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881729999780655
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881385581166136
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881076248792501
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880833146707067
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.688053802980317
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.688021384044127
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880017015550818

 End of epoch: 68 | Train Loss: 0.6867749841867296 | Training Time: 88 

 End of epoch: 68 | Eval Loss: 0.6899559497833252 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7552630782127381
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.721153301000595
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7097638785839081
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7040023282170296
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7005890166759491
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6983305841684342
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6966775476932525
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954319924116135
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6944421682092878
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6937127429246902
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.693090286579999
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6925731986761093
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.692146509885788
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917676214660917
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914478274186452
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6911400608718395
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6908847749233246
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906500965356827
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6904372052142494
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902536860108376
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900751193364462
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6899450036612425
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.689803240351055
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896945655345916
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895611357688903
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894376067014841
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893375802923132
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892438283988408
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891598343849182
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890777043501536
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890184979284963
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889463849365711
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.688874112295382
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.688804109657512
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887438889912196
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886926059921582
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886527953921138
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6886057389409919
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885633936295142
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6885171772539616
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884755745166685
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884285096611296
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883765052917392
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883294549855319
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883028240998587
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882709845252659
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.688232809305191
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882072682181994
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881709326286705
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881428666114807
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881149168108024
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6880938462339915
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880664603890113
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880423955343388
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880152824791995
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6879949977355344

 End of epoch: 69 | Train Loss: 0.6867739416856682 | Training Time: 90 

 End of epoch: 69 | Eval Loss: 0.6905572584697178 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7555436134338379
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7210183084011078
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7095475991566976
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7038321122527122
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7003474283218384
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.698076938589414
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6964687900883811
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6952459290623665
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6942646165688833
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6934913980960846
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6928587528792295
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6923254852493604
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6918920342738811
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6915386357477733
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6912245627244313
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6909261651337146
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6906764675589169
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6904710491498312
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6902945515356566
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6901252627372741
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6899424439384824
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6897997950965707
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6896869511707969
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6895560952524344
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6894435660839081
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6893399305068529
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6892600882936407
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6891785719564982
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891083074027095
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890225207805634
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889679224260392
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889165483415127
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.688859658169024
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888110180111492
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887476284163339
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6887010670370526
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886552879939208
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6886159206691541
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885718620740451
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6885235919058323
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884828125558249
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884519437948863
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6884154659371043
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883755670352416
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883369110690223
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6883023277572964
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882720764647139
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882400599618753
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881917845229714
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881626596450806
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881331068627975
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881106256292416
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880858484304176
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.688054503555651
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880289746414532
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880008018442563

 End of epoch: 70 | Train Loss: 0.6867758092627061 | Training Time: 88 

 End of epoch: 70 | Eval Loss: 0.6897038306508746 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7550516963005066
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.720909932255745
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.70960853099823
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7041155532002449
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005809259414673
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6983636210362116
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6967222545828138
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6954536579549313
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6944245239098866
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6936572432518006
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6930771432139656
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6925919150312742
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6921326903196482
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917507299355098
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6914455505212148
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6911795057356358
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6909291274407331
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6907052824894587
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6904760690111863
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902950817346573
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6901254710696992
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899627284570173
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6898158444010694
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6897020416955153
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895671634674072
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894488396552892
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893355555004543
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892439754945892
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891591265283782
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6890828573703766
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.689011315953347
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.688919086009264
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.688846995975032
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6887820459464017
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887273812294006
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6886694217721622
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6886210101681787
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6885678874818902
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885184891712971
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6884831750392914
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884382960272999
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6883973215307508
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883569077003834
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883233108303763
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6882840706242456
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882599934287693
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882341737442829
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6881971161812543
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881774053281667
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881465814113616
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881244482947331
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6880920231342316
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880623311366675
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880365125558995
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.688017968156121
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880002401769161

 End of epoch: 71 | Train Loss: 0.686771137524495 | Training Time: 87 

 End of epoch: 71 | Eval Loss: 0.6902220674923488 | Evaluating Time: 6 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7553836405277252
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7209005892276764
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.709665592511495
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.703762735426426
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7004372775554657
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6981947163740794
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6965437522956304
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6953023001551628
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6943543990453084
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6935883277654648
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6929712626067075
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6924365848302841
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6919887923277341
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6915895393916539
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6912724622090658
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6909924626350403
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6907676286557142
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905576003922357
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6903826653957367
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6901821532845497
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900172083150773
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898949747735804
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897628786771194
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896252642075221
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.689502730846405
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894045676176365
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893077971758665
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892186507582665
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891493123153161
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890704063574473
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6889972009966451
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.688936448097229
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.688872399113395
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888036254574271
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887439348016466
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.688678199549516
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886242985725403
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6885770756947367
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885488644624368
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885080422461033
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884648746106683
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884180087418783
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.688370890118355
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883210400288755
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.688288254208035
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882516765076181
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882276362561165
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882081902275483
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6881773983945652
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881423717737198
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881116447495479
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6880801169918134
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.688055738413109
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880361970927981
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880110529336062
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6879971158291612

 End of epoch: 72 | Train Loss: 0.6867708960465625 | Training Time: 89 

 End of epoch: 72 | Eval Loss: 0.6904891984803336 | Evaluating Time: 6 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7551938533782959
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7210095345973968
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7095823407173156
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.703908634185791
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7004308533668518
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6981406877438228
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6964395999908447
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.695251478254795
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6943596190876431
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6935799264907837
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.692913291129199
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.692378255724907
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6919306663366465
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6915748668568474
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6912758723894755
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6909930016845465
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6907387456473182
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905281944407358
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6903153413220455
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6901490145921707
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6899687928812844
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6898131852800196
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6896822348884915
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6895786094168822
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6894782223701477
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6893691172966591
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6892610165807936
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6891726038285664
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6890861332416535
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890308040380478
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.688971685594128
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6888965353369713
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888352513313294
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6887900008874781
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887393755572183
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.688692552016841
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886419127116332
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885846323088596
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885208388169607
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6884761510789394
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884384781849093
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6883950376794452
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883548470430596
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883119450374083
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6882765143447452
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882508255865263
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882172408256125
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6881937244286139
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881741355876534
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881457847356797
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881187360660702
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.688092173406711
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880571051588599
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.688039031624794
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880155470154502
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6879925000880446

 End of epoch: 73 | Train Loss: 0.6867667240379131 | Training Time: 88 

 End of epoch: 73 | Eval Loss: 0.6904648627553668 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7559454023838044
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.721200966835022
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7096951246261597
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7040182203054428
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.700713859796524
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6983697930971782
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6968005435807364
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6955293178558349
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6945487558841705
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6937806677818298
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6931169845841147
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6926093076666197
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.692155626645455
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6917994345937456
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6914447140693665
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6911727353930474
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6909279546316932
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6906893531481425
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6904909651530416
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6903046762943268
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6901055108933222
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6899572786959735
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.689813722734866
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896855980157852
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895687198638916
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894521406063667
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6893592163368508
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892498818891389
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891650925422537
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890671775738398
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6889904285630872
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.688926531560719
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888687991734707
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6888243599849588
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887552499771118
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886994322141011
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886669010729403
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6886211944253822
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885761444385236
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.688521112948656
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884723109443013
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6884336789449056
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883948284526203
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883564252745021
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6883259680536058
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882933476696844
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882537963542532
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6882223748912414
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.688189458968688
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881677354574204
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881418207112481
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881203720202813
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880974609896822
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880680614047581
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880441868305206
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880196122186525

 End of epoch: 74 | Train Loss: 0.6867932951555843 | Training Time: 90 

 End of epoch: 74 | Eval Loss: 0.6904649138450623 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7548584520816803
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7205090016126633
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7091028610865275
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7034049883484841
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7001258325576782
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6979116439819336
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6962826090199606
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6950774326920509
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6941527214315203
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6934141713380814
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6928307609124618
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6923617904384931
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6919417463816129
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6915769525936671
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6912850312391917
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6910097230225801
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6907732605934143
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6905658264954885
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6903727349482085
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.690203282237053
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900374639601935
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6898712133819407
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897256247375323
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6895907637973626
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6894861643314362
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6893843439909128
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6892768508858151
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6891993028776986
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891141961360799
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890436842044194
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889620159902881
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6888975411653518
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888404512044155
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887914587469662
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887402026993887
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886966447035472
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.688640328194644
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885916413445222
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.688542520847076
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6885020543634891
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884610173178882
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884292296000889
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6883916739807573
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883449962193315
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.688312404818005
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882719931395157
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882389999450521
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882021596034368
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881682915346963
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881491501331329
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881232696421006
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880938087518399
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880708467285588
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880601668799365
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880301356315612
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880024177687508

 End of epoch: 75 | Train Loss: 0.6867775023511026 | Training Time: 88 

 End of epoch: 75 | Eval Loss: 0.6900336061205182 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7553803741931915
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7211987316608429
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7097619970639547
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7039116397500038
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7004511380195617
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6981018135945002
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6964002072811126
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6951744198799134
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6942547367678749
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6935389053821563
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6929069670763883
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6924035479625066
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6919970200611995
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6916113461766924
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913054474194844
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6909754849970341
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.690712262953029
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6904655595620474
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6902721219941189
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.690093612074852
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.689941181171508
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6897889177907597
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6896833645260853
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6895638468364874
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6894555971622467
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6893531473783346
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6892582224475012
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6891911093677793
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891091572827306
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890409388144811
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.688976945800166
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889056107029319
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888257254253735
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.688760636308614
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887142731462206
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886587594946225
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886035012232291
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6885580381280497
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885128817497156
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6884682533144951
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884298496130036
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6883921756630852
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6883442460104476
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883110405369238
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6882921160591973
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882629171661708
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.688232271214749
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6882000934332609
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6881740084716252
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881521499156952
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881243918456283
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881027013063431
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880756550240067
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880482374518005
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880174956538461
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.687989294635398

 End of epoch: 76 | Train Loss: 0.6867646490578103 | Training Time: 88 

 End of epoch: 76 | Eval Loss: 0.690356160913195 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7551771223545074
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.720993310213089
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7097302655378978
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7038900092244148
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.700448385477066
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6981539924939474
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6965532651969365
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6953342661261559
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6943838033411238
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6936164700984955
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6929997698827224
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6924984281261762
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6920595966852628
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6917023752416883
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.691387087504069
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6911183495074511
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6908589601516724
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6906214651134279
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6904246995323583
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6902382895350456
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900785502933321
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6899328172206879
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897698226182357
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896473969022433
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895274827480317
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894185501795549
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893155599081958
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892169211591993
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891387742141197
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890643457571666
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889936135661218
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.68891183398664
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888392739223711
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6887700242154738
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887097983700888
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6886427670717239
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6885887236208529
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6885419246397521
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.688484259446462
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6884515607357025
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884052334762201
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6883658251592091
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883270791796751
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6882963689890775
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6882508897781372
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882247568472571
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6881948670174213
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6881638616323471
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881385756998646
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881136020421982
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881004895649704
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6880729455214281
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880507224010971
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880311245167697
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880132812803442
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6879881674689906

 End of epoch: 77 | Train Loss: 0.6867587265715135 | Training Time: 88 

 End of epoch: 77 | Eval Loss: 0.6903636029788426 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7556434869766235
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7211748421192169
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7097499171892802
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7038636431097984
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7004220223426819
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6980897376934687
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6964620700904302
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6952470734715461
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6942809131410387
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.693497548699379
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6929726470600475
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.692428708076477
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6919571042060852
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.691554115499769
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6912213198343913
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6909293834120035
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6906977373010972
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6904779742161433
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6902737024583314
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6901042959094048
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6899448502631415
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.689804891293699
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6896755200365315
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6895373707016309
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6894289336204529
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6893314538093713
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6892606289298446
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6891674073679107
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6890848131015384
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890125503142674
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889286681529014
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.688871006667614
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888031697634495
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.688722959686728
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6886778177533831
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886093916164504
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.688566035193366
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885155908371273
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6884816625179389
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884440353512764
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884132837376944
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6883732967433476
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883385751136514
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883015856146812
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882733609941271
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882430143978284
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882214476453498
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6881959973524014
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881724901345312
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881440532207489
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881110025387184
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6880835063182391
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.688058408701195
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880292246739069
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880110079591925
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6879840757165636

 End of epoch: 78 | Train Loss: 0.6867554503204548 | Training Time: 88 

 End of epoch: 78 | Eval Loss: 0.6905398028237479 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7551973402500153
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7211822777986526
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7097534298896789
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7038704678416252
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7003891563415527
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6980652272701263
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6964413830212184
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6952518932521343
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6943041430579291
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6935478538274765
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6929456347768957
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6924045021335284
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6920107318804815
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6916350458349501
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6913047142823537
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6910311054438353
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6907752717242521
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6905546516180039
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6903528743668607
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6901800999045372
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6899942383879707
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6898412837223573
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897085731444151
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6895808530350526
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.689487633228302
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6893861348812397
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6892839241910864
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6891958607094628
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891180490625316
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890337890386582
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6889470386889673
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6888802899047732
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888198722492564
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6887637564364602
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887049671581813
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6886593873302141
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.688602479084118
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.688562189434704
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885137530473563
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6884703113138676
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884254355256151
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6883844741753169
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883433328118436
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883060097694397
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6882720813486312
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882440279359403
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.688220620662608
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6881858183691899
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.688159865262557
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881455826759338
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881183603230645
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6880933813177622
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880653368976881
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880374965844331
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880211659994993
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.687998035975865

 End of epoch: 79 | Train Loss: 0.6867705194296035 | Training Time: 90 

 End of epoch: 79 | Eval Loss: 0.6904147267341614 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.755794370174408
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7213344246149063
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7098817586898803
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7040997430682182
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7005529081821442
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6982606718937556
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6966755526406424
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954350247979164
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6944900102085537
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6937065196037292
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6930511675097726
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6925130600730578
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6920639005991128
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6916828355618886
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.69135750969251
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6910754349082708
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908343876109404
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.690596964624193
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6903829649875038
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6902106818556786
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900510736874171
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6898892177776856
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897415282933609
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896085103352865
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895240306854248
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894243040910134
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.689338019379863
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.689252262881824
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891591867496227
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890787239869436
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889952669220586
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889408009126783
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888794181924878
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6888158288072137
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887630765778677
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6887100001176198
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886674565237921
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6886150251877935
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688563934350625
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6885157538950444
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884840181687983
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6884406851870674
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883948130663051
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883514868942174
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6883163040214114
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.688285055367843
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.688242762773595
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882081599285205
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881774097072835
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881422995328903
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881120169863981
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880843074275897
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880626636856008
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880397797734649
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880129159580578
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879931053944996

 End of epoch: 80 | Train Loss: 0.6867662432974418 | Training Time: 88 

 End of epoch: 80 | Eval Loss: 0.690568915435246 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7553198516368866
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7211070418357849
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7097194214661916
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7039099842309952
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7004919290542603
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6982122172911962
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6965533316135406
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6953704118728637
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6944998251067267
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6937464612722397
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6931297491897236
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.692629041771094
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6922057981674488
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6918034813233784
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6914606861273448
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6911572430282831
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6909328839358162
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.690675260954433
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6904456468004929
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6902429717779159
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6900759288242885
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6899120000275698
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897722848083662
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6896429128944874
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895269758701325
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894350437017588
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893325483357465
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892467302935464
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891679765849278
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890944204727809
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6890181239574186
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6889441048726439
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888816873232524
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6888171330970876
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887525781563351
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886937722563744
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6886269496904837
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.688577612293394
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885364569150485
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6885099768638611
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884700090419955
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884267931892758
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883875655573468
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883461490273476
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6883137910895878
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882740090722623
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882376924474188
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6881977662444114
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881624501578661
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881349614858627
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881209482164944
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880976289510727
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880665410239741
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880479979294317
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880247854102741
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6880071126988956

 End of epoch: 81 | Train Loss: 0.6867763009746518 | Training Time: 90 

 End of epoch: 81 | Eval Loss: 0.6896687320300511 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7555015921592713
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7211564511060715
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7098011016845703
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.704008786380291
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7004970526695251
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.69827960729599
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6966316682951791
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6953955054283142
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6944985502296024
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.693729184269905
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.693101954460144
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925512328743935
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6920955933057344
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6917482618774686
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6914018249511719
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6911161471158266
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908673430190367
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906242668628693
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.690423289725655
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902300688624382
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6900624752044677
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899205906824633
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6898022874541905
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.689659503599008
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6895432868003846
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6894648107198569
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6893832696808709
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892869983400617
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6891792924239718
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890996303160986
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890251582668674
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889433916658163
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888781852794416
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888266633538639
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.688771505015237
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6887178323335118
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886709701370548
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6886169367714932
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.688570619852115
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885184688866138
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884675041931432
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.688419548528535
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883781628553257
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883390361612494
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6883086164792379
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882741396841796
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882363097464784
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.688199790318807
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881688457362506
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881394164562226
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881097849677591
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880811921679056
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880593677736678
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880413260724809
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880182545835322
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879859959440572

 End of epoch: 82 | Train Loss: 0.6867555354548767 | Training Time: 88 

 End of epoch: 82 | Eval Loss: 0.6895159653254918 | Evaluating Time: 5 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7551969289779663
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7208972483873367
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7096794267495473
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7040053576231002
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004993641376496
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6981921325127284
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6965647603784288
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6952998906373977
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6943559421433343
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6935968542098999
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6929474342953075
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6924427663286526
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6919702465717609
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6915671212332589
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6912539446353912
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6909699980169535
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.69075246313039
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905061317814721
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.690325307218652
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6901605784893036
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900106123515538
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898702307180925
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897414471792138
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6895842658976714
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6894666244983673
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.68935258938716
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6892629442391572
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6891709170171193
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6890940816238009
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890176264444987
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889573616366232
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6888935349881649
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888387645735885
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6887813647003734
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887260246276855
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886763882305887
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886291429803179
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885802507400512
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885348974130092
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6884903520345688
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884409443634313
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884093066056569
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883679197278134
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883332259275696
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883027557531992
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882719461036765
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.688244471144169
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882221374660731
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881834066644007
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.688154234290123
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881199796994527
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880903315085631
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880648732185364
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880385565536994
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880194893750278
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6880028210580349

 End of epoch: 83 | Train Loss: 0.686774813601401 | Training Time: 89 

 End of epoch: 83 | Eval Loss: 0.6902701939855304 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7550924360752106
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7209534138441086
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.709441210826238
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7038565561175346
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7003888535499573
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6980798065662384
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6964614825589316
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6952266715466976
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6942454907629225
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6935319942235947
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929459658536044
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924612134695053
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920269837746253
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6916764906474522
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913157077630361
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6910165093839169
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6907630376956042
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6905198309156629
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903200704800455
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6901142239570618
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6899652381738027
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6898154440251264
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6896793497645337
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6895642499128978
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6894490706920624
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6893536198597688
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.689252695551625
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6891884673918997
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.689102048092875
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890357716878255
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6889629504372997
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6888968825340271
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888196080019979
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887630504720351
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887175978933062
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886610499686665
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6886072385955502
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885643341039357
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885187960588015
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884782718122006
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884395391475864
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6883990015302386
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883635706679766
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883267161521045
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.688299073378245
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882592611986658
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882311569883468
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882010833670695
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.68816274076092
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881323825120926
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881062086890726
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880858041919194
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880616561421808
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880383247578585
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880109806494279
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6879863145095961

 End of epoch: 84 | Train Loss: 0.6867633031532828 | Training Time: 89 

 End of epoch: 84 | Eval Loss: 0.6905373675482613 | Evaluating Time: 5 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7553061008453369
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7209024071693421
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7095159947872162
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.703712959587574
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.700245372056961
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6979118883609772
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6963184927191053
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6951477356255055
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6941856139236027
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6934235715866088
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6928364596583626
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6923633977770806
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6919133374324211
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6915122564349856
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.69118723154068
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6908964883536101
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6906482493176179
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.690415029393302
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6902247588885458
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6900530913472176
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6898881321861631
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.689746220274405
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6896120623401973
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6894947071870168
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.689414270401001
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893102661921428
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892135050561693
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6891209306461471
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6890462375920394
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6889636826515197
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889073546855681
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.68882639631629
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6887757196570887
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887121386387769
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6886514295850481
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886088002059195
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6885661289498612
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885142953772294
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6884781823708461
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884445215761662
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884126128219976
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6883610268433888
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883266150951386
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6882896512746811
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6882537465625339
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882321366797323
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6881907121932253
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6881670365730922
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881344718592507
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881176034212112
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6880962776202781
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.688065735078775
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880339287362008
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880238303431758
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880022954940795
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6879795784396785

 End of epoch: 85 | Train Loss: 0.6867537194648675 | Training Time: 88 

 End of epoch: 85 | Eval Loss: 0.6903599670955113 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7551671326160431
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7210935086011887
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7097323060035705
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7040376111865043
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7005658304691315
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982558329900106
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6965550269399371
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6952916085720062
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6943275623851353
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6936379081010818
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6930267323147167
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.692499894897143
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920550346374512
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916800230741501
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6913467216491699
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6910627651959658
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6907970253159018
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905850145551894
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903944385679145
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.690207291841507
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900445041202363
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898813700134104
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897630033285721
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896434890727202
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6895078122615814
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6893891804493391
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6892803470293681
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6891878783702851
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.689100189250091
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890322687228521
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889535507848186
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6888793103396893
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888170796813387
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6887678518014796
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887088935715812
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.688662643233935
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886078942466427
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885614770023446
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885152819829109
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884672281146049
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884196688489216
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6883849273125331
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883501221967298
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883077076890252
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882787768046061
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.688252520042917
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882213214610485
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6882013104856014
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881613649884049
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881257627010345
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6880960365136465
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880692569109109
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880457632946518
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880216477093873
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6879936914010482
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879800305834838

 End of epoch: 86 | Train Loss: 0.6867483062026775 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6902036155973162 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7557347357273102
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7214215159416199
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7098096430301666
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040037050843239
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7005248808860779
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6982938170433044
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6965888823781695
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6953291177749634
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6943669299284617
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.693564395904541
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6929306089878082
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6923785373568535
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6919508315049685
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6915954147066389
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6912547425429026
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6909888982772827
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.690723122218076
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6904738442765341
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6902995865595968
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6901482388377189
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6899834735052927
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6898381756110625
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6896905297818391
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6895717397332192
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6894663093090058
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6893700583623006
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6892534282472399
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6891495740839413
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6890592595626568
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6889924728870391
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889221208710824
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6888482641428709
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6887900357896631
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6887336361057618
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6886692377499172
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886240343252817
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.688570778434341
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885338551119754
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6884824716127835
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.688446294516325
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.688410206538875
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6883701585588001
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883436984794085
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883032006296245
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882716731230418
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882356946882995
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.688197297238289
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881638710697492
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881437070515691
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881144763231277
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6880901407961751
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880677833006932
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880455560279343
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880219313833449
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880041613362052
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879864359540598

 End of epoch: 87 | Train Loss: 0.686762728838794 | Training Time: 88 

 End of epoch: 87 | Eval Loss: 0.6899389624595642 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.755392050743103
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7213682711124421
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7098693390687306
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7040402442216873
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7005280256271362
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6982473641633987
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6966578560216087
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6954076737165451
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.694391045305464
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6936490488052368
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.693045378815044
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6925022910038631
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920563954573411
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6916951192276818
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913606635729472
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910568632185459
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6908021702485926
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905746847391129
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6904004674208791
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.690229754447937
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900533346902756
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.689889732003212
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897556556307751
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896102949976921
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6894920434951782
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6893975012577497
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.689307376631984
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892121864216668
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891308361086352
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890457258621852
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889759482875947
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889090051874518
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888469910982883
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6887808757669786
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887276496206011
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886646543939908
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886146271550978
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885622222172586
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885094916209197
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6884572787582874
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884187332013758
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6883912300779707
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883548237556635
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883150387894024
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882803711626265
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.688241578573766
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.688223686750899
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6881962582468987
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881657275618339
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881309596300125
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881105690610175
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6880858428203143
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880504872439043
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880242591654813
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880052928491073
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.687977462474789

 End of epoch: 88 | Train Loss: 0.6867519876598257 | Training Time: 90 

 End of epoch: 88 | Eval Loss: 0.689783147403172 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.754963493347168
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7207683205604554
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7094929933547973
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7038227409124375
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7004265093803406
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6982231587171555
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6965745040348598
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6953264333307743
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6944016310903761
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6936727756261826
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6930097081444481
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6924655760327975
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920194823008318
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916471987962722
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913172491391499
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910183247178793
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6907877708182616
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.690568463338746
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903608406844892
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901845046877861
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.690050866206487
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898971923372962
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897492375062859
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896185042957464
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895151793956756
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894137036341887
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893197655677795
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892188676765987
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891371903748348
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.689059145450592
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6889855004126025
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.688904338516295
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888443621722135
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6887837948168025
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887337172031402
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886894548932712
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886437483735987
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.688583315987336
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885237463009664
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6884670647978782
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884075047039404
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6883636155298778
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883278534855953
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6882899449630218
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882540464401246
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882158983012904
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6881874054036242
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6881613979736964
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.68813430180355
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881102287769317
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6880930040396896
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880665252988155
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880409177744163
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880170183049308
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.687994895956733
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879709401300975

 End of epoch: 89 | Train Loss: 0.686748476788006 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6901185086795262 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7559072971343994
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7212489634752274
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7098230501015981
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7041167959570884
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7006506359577179
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6983563641707102
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6966909987585885
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6954463578760623
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.694464342461692
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6937595289945603
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6931276305155321
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6926064575711887
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6921729803085327
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.691772677217211
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6914334801832834
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6911668211221695
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6908931423636043
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6906602654192183
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6904479428341515
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6902564486861229
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6901081289563861
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6899533908475529
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6898306745549907
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6897176548838615
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6895773627758026
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6894646225067286
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6893644079014107
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6892728073256357
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.689176260397352
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890909838676452
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.689007753902866
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889407062903047
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888716535134749
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6888117628939011
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887434417860848
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886886007255978
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.688624365265305
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885552161618282
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885149868635031
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884667843580246
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884215522103193
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883818450428191
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883381390294363
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883099156347188
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882706530888876
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.688248886362366
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882120982129523
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6881816922376554
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881523460757976
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881293667554855
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6880991631863164
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880719886376307
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880407913675848
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880180810336713
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6879919522458857
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879693077078888

 End of epoch: 90 | Train Loss: 0.6867463563395813 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6903788021632603 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7556874215602875
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7209737747907639
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7097138186295827
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7039520755410195
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7004677402973175
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6982198566198349
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965091662747519
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6952433876693249
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6943318969673581
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6935383975505829
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6929068223996596
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6924234077334404
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920120871984041
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916561714240483
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913333996136983
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6909982267767191
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6907470506780288
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905457692013847
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903165277681853
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6901267689466476
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.689962869598752
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6898233218626543
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6896834819213203
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6895662732422352
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6894475905895233
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6893451924507434
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6892465010837272
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.689150529886995
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6890580333512405
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6889825491110484
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6889170829326876
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6888568285852671
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.688805145928354
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887434787609998
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6886900636128017
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886377258433236
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6885882541940019
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885451996012738
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6884974597356258
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884559361636639
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884153613230077
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.688379503715606
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883436803207841
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883009078827771
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882682707574632
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882295081148977
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.688204441045193
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881846287598212
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.688160987776153
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881289212703705
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881008074564092
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.688078527381787
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.688054517642507
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.688031534464271
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880123088576577
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879811670098986

 End of epoch: 91 | Train Loss: 0.6867556997105083 | Training Time: 92 

 End of epoch: 91 | Eval Loss: 0.6903470754623413 | Evaluating Time: 5 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7554103374481201
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7211550742387771
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7097613215446472
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7038449764251709
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7004259288311004
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6980723718802134
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.696433938401086
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6952894642949105
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.694372973839442
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6936433678865432
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930314660072326
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.692498229444027
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6920470003898327
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6916569658688136
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913246432940165
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.691040825843811
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6907691902974072
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6905366950564914
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6903565682862934
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6901736783981324
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6899958678654262
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898465966636484
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.689704330071159
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6895686907072862
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6894559900760651
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6893503028612871
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6892632336528213
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891819994364466
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6890998406656857
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890395536025365
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889523465787211
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888805182650686
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888346834616228
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887649567688212
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6887046049322401
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886472683813837
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6885847687721253
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885339702430524
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6884849140277276
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.688438778668642
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884003192913242
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.688366779259273
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883307156174682
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6882908532565291
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882612931728364
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.68822679390078
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6881942320377269
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881645725419124
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881344811040528
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881027297973633
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6880744881489698
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880530902972588
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880262295030198
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880134631086279
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6879943590814417
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879744105041027

 End of epoch: 92 | Train Loss: 0.6867527505992788 | Training Time: 91 

 End of epoch: 92 | Eval Loss: 0.6891574263572693 | Evaluating Time: 5 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7554977059364318
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7210836917161941
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7094991604487101
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.703804025053978
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7003411877155304
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6981374343236287
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6965556681156159
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6952833101153374
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6943558474381765
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6935988926887512
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6929747874086554
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6924409364660581
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6920629285849058
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6916847024645124
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.691334844827652
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6910160303115844
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.690772901913699
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6905406869120068
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903341396858818
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6901749858260154
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6900146487213317
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898412233049219
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897078726602637
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6895998761057853
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6894857637882232
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6893923312425614
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6892926258069497
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6892030730843544
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.689122662256504
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6890423220396041
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889876127243042
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889093151316047
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6888439259745858
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6887790345093783
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887240884985243
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886568632390764
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6885974856647286
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.688558314348522
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885076993551009
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884595315158367
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884013937740792
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883806015763964
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.688356194246647
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883184400471773
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882793907324473
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882457086573477
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882147111791246
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881783536324898
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881486395183875
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881073524951935
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6880820813132268
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880623175547673
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880354043447746
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880141002160531
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6879910996827212
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879617635692868

 End of epoch: 93 | Train Loss: 0.6867431737680351 | Training Time: 90 

 End of epoch: 93 | Eval Loss: 0.6903094393866402 | Evaluating Time: 5 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7553964138031006
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7211307555437088
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7096360246340434
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7038585737347602
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7003597366809845
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6980556170145671
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6964182019233703
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6952236488461494
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.69429505666097
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6935430681705474
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.69288686839017
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6923393001159032
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6919086268314949
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6915861257484981
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6912274849414826
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6909394916146994
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6906956269460566
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6904738773902257
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.690288886271025
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901175272464752
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6899707592668988
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6898275844075463
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6896885306938835
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895759562651317
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.689466364145279
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6893636171634381
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6892505184367851
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6891640910080501
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6890969062673634
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890205947558085
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.688953963979598
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6888887982815504
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.688819288484978
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.688752470296972
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6886997853006636
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886569740043746
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886062773498329
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885464271432475
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.688494022228779
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884534761309624
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884030362454856
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883627651702791
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883265626984973
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6882785554636609
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6882469031545851
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882198429625968
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.688187997899157
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6881621140986681
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881344438815603
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881193089485168
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6880946885136997
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880678728222847
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880432731700393
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880215909745958
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6879963180151852
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879693535821778

 End of epoch: 94 | Train Loss: 0.6867481977538725 | Training Time: 91 

 End of epoch: 94 | Eval Loss: 0.6900871736662728 | Evaluating Time: 5 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7556694090366364
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7210588216781616
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7095539530118307
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7039514735341073
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7006066465377807
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6982491264740626
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6965935502733503
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6953339494764805
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6943802217642466
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6936200129985809
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6930031088265506
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924754485487938
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.692029007581564
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916393658944539
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.691303330262502
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910637341439724
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908217349473168
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6906077093548245
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.690414675913359
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.690227285027504
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900482719852811
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.689891489256512
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897585441236911
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896253238121669
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6894951741695404
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6893785735735527
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6892810803872568
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6891860304134233
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6890994382315668
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890204163392385
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889557782680757
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888806011527777
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888095261472644
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6887364699560053
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6886793686662401
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886366039514542
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6885923844736975
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885473519563675
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885050750695743
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884735313057899
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884332534743518
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883822695130394
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883354070574739
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883013917641206
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882708565394083
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882399643244951
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.6882084384877631
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881770843019088
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881529070893112
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881253008842468
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6880916930881201
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880639265363033
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880330497363828
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880093540306444
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6879904199730266
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879680747432368

 End of epoch: 95 | Train Loss: 0.6867456795894994 | Training Time: 91 

 End of epoch: 95 | Eval Loss: 0.690284013748169 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7556077182292938
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7212455570697784
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7097305476665496
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7039421290159226
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7005485332012177
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6982499837875367
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6965935255799974
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6952466808259488
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6942902260356479
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6935801523923874
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6928863915530118
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6923783734440804
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.691988252217953
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6915637024811336
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.691264873345693
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910112388432026
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907754607060377
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6905674113167657
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6903768078276985
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901975458860398
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6900466845149086
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6899073706431822
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6897806893224302
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6896658355991045
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6895487043857574
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.68944729749973
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6893286610091174
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6892405243856566
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6891532984273187
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890906099478403
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6890234230026122
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.688955421000719
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888839028098367
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.688813867463785
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887441926343101
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886931742231052
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886306380903399
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885807915737755
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6885364052576897
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.688488018065691
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884362956372703
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883966556617191
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883604939593825
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6883156535300341
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882791352272034
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882471013328303
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882217586040497
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881843421608209
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881487095842556
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881160390377045
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880893267837225
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.688066586966698
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880437245908774
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880264368322161
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.688000794540752
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879867651632854

 End of epoch: 96 | Train Loss: 0.6867612250083316 | Training Time: 91 

 End of epoch: 96 | Eval Loss: 0.6905075822557721 | Evaluating Time: 5 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7557969987392426
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7211985796689987
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.709792842467626
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7039867535233497
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7005207216739655
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6982025434573491
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6965763568878174
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6953371822834015
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6943782839510176
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6936175662279129
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929830025542866
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924267292022706
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.691983751150278
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916176080703735
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6913070591290792
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910088278353215
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6907283832045162
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905142201317681
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903375901673969
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6901860904693603
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6900020031701951
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.689858048341491
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897286018599634
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896095499396324
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.689484798669815
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6893771435205753
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6892757687303755
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6891881878886904
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891075734434456
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890233294169108
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889503067539584
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6888737546280026
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888059962879528
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887454010107938
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6886934346812112
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.688643379509449
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886031166927234
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885497924528624
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885098659075224
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884631779789925
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884269672196086
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6883852118537539
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883478645668474
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883137003941969
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.688277289337582
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.688246868615565
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882119070976338
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881832721332709
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.688154934863655
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881271010637283
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881051615172742
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880701771149269
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880416370787711
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880180617173512
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6879978965629231
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879657763455596

 End of epoch: 97 | Train Loss: 0.6867445966838736 | Training Time: 90 

 End of epoch: 97 | Eval Loss: 0.6904277035168239 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7552240192890167
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7207951754331589
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7093629757563273
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7037222132086753
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7004113507270813
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6981341302394867
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6964419773646764
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6952500909566879
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6942879888746474
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6934814441204071
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6928726266730916
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6923612574736278
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6918798066102542
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6915357223578862
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6912580517927805
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6909753702580929
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6906990128404954
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6904957877265082
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6902936430353868
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6901155203580857
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6899448386260442
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6898057487877932
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6896615660708884
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6895407378673554
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6894344773292541
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6893223290260021
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.689225576321284
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6891434345926557
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6890686795629304
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.688989556034406
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6889225279131244
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.688868946582079
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888180783300689
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887625135043088
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887072569983346
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886504956417614
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6885855568421854
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885270962589666
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.688478283240245
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.68843705996871
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6883875941357962
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883438072034291
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883001628310181
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6882686368443749
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.688235018518236
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.688199578160825
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6881764702340389
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881505434711774
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881199659133445
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881023958921433
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6880778777833079
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.688055292230386
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880389642040684
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880074161070364
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6879841025309129
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879688626953534

 End of epoch: 98 | Train Loss: 0.6867393364948509 | Training Time: 92 

 End of epoch: 98 | Eval Loss: 0.6900582398687091 | Evaluating Time: 5 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7555629193782807
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7211249560117722
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7097280561923981
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7040071234107017
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7005330264568329
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6981954822937647
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6965192369052342
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6952555529773236
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6942800031767951
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6935464996099472
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6929622574286027
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6924520586927732
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6920360835698934
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.691651925444603
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913433023293813
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910682428628206
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908262077499838
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6906132764286466
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.690420894560061
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6902334770560264
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6900646879559471
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6899160385131836
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897692835849264
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6896416142582893
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6895238583087921
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6894290020832649
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6893266854462801
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6892494823251452
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6891750956403798
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.689096277753512
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6890235395200791
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.688955657556653
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888923520391638
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6888184074093314
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6887593924999237
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6887009337544441
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886450042595734
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885968639662391
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6885672272780002
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.688529282361269
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884893539475232
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6884511221022833
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6884104771669521
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.688369436020201
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6883337516254849
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882860718861871
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882403657791463
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6882129176209371
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881911292368051
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881603403091431
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.688133305311203
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.688109378860547
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880888999633069
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880647659301757
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6880368931726976
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6880036029432501

 End of epoch: 99 | Train Loss: 0.6867794822802585 | Training Time: 92 

 End of epoch: 99 | Eval Loss: 0.6902015634945461 | Evaluating Time: 5 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7558265566825867
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7214838296175003
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7100418150424957
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7041547119617462
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7006882214546204
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6984116951624553
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6967090078762599
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6954461179673672
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6944631576538086
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6936827719211578
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6930525779724122
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6925101856390635
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920503483368801
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.691669191632952
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913631224632263
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910727914422751
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6907903611660003
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.690525660249922
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903438649679485
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.690149938762188
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6899997645900363
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.689840891957283
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897273123264313
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6895955637097358
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895032246112823
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6894041882111476
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893133013336746
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892356644783701
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891505490089285
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890883618593215
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6890051182239286
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6889254057779908
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888644391840154
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887842074913137
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887247628825052
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886609362231361
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886131338171056
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885762813844178
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885269045829773
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884917597472667
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884496568179712
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6884058012848808
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.688368141789769
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883228847926314
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.688283561733034
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882446767195411
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882123249642392
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881741863985856
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881481581804704
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881247907876968
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.688094659763224
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880729989363596
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880547910366418
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880277855528726
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.687995718717575
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.687971919136388

 End of epoch: 100 | Train Loss: 0.6867457385611745 | Training Time: 91 

 End of epoch: 100 | Eval Loss: 0.6904305985995701 | Evaluating Time: 5 

 End of Test | Dice Loss: 0.9609837872641427 | Binary Cross Entropy With Logits Loss: 0.6899094326155526 
