Epoch: 1 | Iteration number: [10/393] 2% | Training loss: 1.1025717198848723
Epoch: 1 | Iteration number: [20/393] 5% | Training loss: 1.0448484003543854
Epoch: 1 | Iteration number: [30/393] 7% | Training loss: 1.0208235879739125
Epoch: 1 | Iteration number: [40/393] 10% | Training loss: 1.0058233350515366
Epoch: 1 | Iteration number: [50/393] 12% | Training loss: 0.9942713904380799
Epoch: 1 | Iteration number: [60/393] 15% | Training loss: 0.9855904906988144
Epoch: 1 | Iteration number: [70/393] 17% | Training loss: 0.9792884741510663
Epoch: 1 | Iteration number: [80/393] 20% | Training loss: 0.9741384349763393
Epoch: 1 | Iteration number: [90/393] 22% | Training loss: 0.969451716211107
Epoch: 1 | Iteration number: [100/393] 25% | Training loss: 0.96559820830822
Epoch: 1 | Iteration number: [110/393] 27% | Training loss: 0.9620339848778464
Epoch: 1 | Iteration number: [120/393] 30% | Training loss: 0.958931665122509
Epoch: 1 | Iteration number: [130/393] 33% | Training loss: 0.9562033309386326
Epoch: 1 | Iteration number: [140/393] 35% | Training loss: 0.9536461327757154
Epoch: 1 | Iteration number: [150/393] 38% | Training loss: 0.9515149180094401
Epoch: 1 | Iteration number: [160/393] 40% | Training loss: 0.9493398994207383
Epoch: 1 | Iteration number: [170/393] 43% | Training loss: 0.9473185234210071
Epoch: 1 | Iteration number: [180/393] 45% | Training loss: 0.9455724355247286
Epoch: 1 | Iteration number: [190/393] 48% | Training loss: 0.943843999975606
Epoch: 1 | Iteration number: [200/393] 50% | Training loss: 0.942204342186451
Epoch: 1 | Iteration number: [210/393] 53% | Training loss: 0.9405281208810352
Epoch: 1 | Iteration number: [220/393] 55% | Training loss: 0.9390351663936268
Epoch: 1 | Iteration number: [230/393] 58% | Training loss: 0.9376053999299588
Epoch: 1 | Iteration number: [240/393] 61% | Training loss: 0.9362256459891796
Epoch: 1 | Iteration number: [250/393] 63% | Training loss: 0.9348164813518525
Epoch: 1 | Iteration number: [260/393] 66% | Training loss: 0.9335618188747993
Epoch: 1 | Iteration number: [270/393] 68% | Training loss: 0.9323016230706815
Epoch: 1 | Iteration number: [280/393] 71% | Training loss: 0.9310695539627757
Epoch: 1 | Iteration number: [290/393] 73% | Training loss: 0.9298321863700604
Epoch: 1 | Iteration number: [300/393] 76% | Training loss: 0.9287001748879751
Epoch: 1 | Iteration number: [310/393] 78% | Training loss: 0.9275631362392056
Epoch: 1 | Iteration number: [320/393] 81% | Training loss: 0.9264481451362372
Epoch: 1 | Iteration number: [330/393] 83% | Training loss: 0.9253078565453038
Epoch: 1 | Iteration number: [340/393] 86% | Training loss: 0.9242302579038283
Epoch: 1 | Iteration number: [350/393] 89% | Training loss: 0.9232026628085546
Epoch: 1 | Iteration number: [360/393] 91% | Training loss: 0.9222128679354985
Epoch: 1 | Iteration number: [370/393] 94% | Training loss: 0.9211737184911161
Epoch: 1 | Iteration number: [380/393] 96% | Training loss: 0.9202023408914867
Epoch: 1 | Iteration number: [390/393] 99% | Training loss: 0.9192430765200884

 End of epoch: 1 | Train Loss: 0.9166868427630902 | Training Time: 66 

 End of epoch: 1 | Eval Loss: 0.8803292233116773 | Evaluating Time: 17 
Epoch: 2 | Iteration number: [10/393] 2% | Training loss: 0.9702185153961181
Epoch: 2 | Iteration number: [20/393] 5% | Training loss: 0.9252885282039642
Epoch: 2 | Iteration number: [30/393] 7% | Training loss: 0.9092795471350352
Epoch: 2 | Iteration number: [40/393] 10% | Training loss: 0.9005632072687149
Epoch: 2 | Iteration number: [50/393] 12% | Training loss: 0.8952520537376404
Epoch: 2 | Iteration number: [60/393] 15% | Training loss: 0.8916086028019587
Epoch: 2 | Iteration number: [70/393] 17% | Training loss: 0.8891919672489166
Epoch: 2 | Iteration number: [80/393] 20% | Training loss: 0.8869162887334824
Epoch: 2 | Iteration number: [90/393] 22% | Training loss: 0.8845745722452799
Epoch: 2 | Iteration number: [100/393] 25% | Training loss: 0.8828976106643677
Epoch: 2 | Iteration number: [110/393] 27% | Training loss: 0.8812522091648796
Epoch: 2 | Iteration number: [120/393] 30% | Training loss: 0.879801885286967
Epoch: 2 | Iteration number: [130/393] 33% | Training loss: 0.8785498233941885
Epoch: 2 | Iteration number: [140/393] 35% | Training loss: 0.8773989583764757
Epoch: 2 | Iteration number: [150/393] 38% | Training loss: 0.8763568917910258
Epoch: 2 | Iteration number: [160/393] 40% | Training loss: 0.8753620143979788
Epoch: 2 | Iteration number: [170/393] 43% | Training loss: 0.8744289622587316
Epoch: 2 | Iteration number: [180/393] 45% | Training loss: 0.8734882053401735
Epoch: 2 | Iteration number: [190/393] 48% | Training loss: 0.8725648867456537
Epoch: 2 | Iteration number: [200/393] 50% | Training loss: 0.8715612655878067
Epoch: 2 | Iteration number: [210/393] 53% | Training loss: 0.8707722110407693
Epoch: 2 | Iteration number: [220/393] 55% | Training loss: 0.8699323150244627
Epoch: 2 | Iteration number: [230/393] 58% | Training loss: 0.8690078896024953
Epoch: 2 | Iteration number: [240/393] 61% | Training loss: 0.8681388894716898
Epoch: 2 | Iteration number: [250/393] 63% | Training loss: 0.8673911960124969
Epoch: 2 | Iteration number: [260/393] 66% | Training loss: 0.8665796759036871
Epoch: 2 | Iteration number: [270/393] 68% | Training loss: 0.8658300344590788
Epoch: 2 | Iteration number: [280/393] 71% | Training loss: 0.8651212032352175
Epoch: 2 | Iteration number: [290/393] 73% | Training loss: 0.8644164364913415
Epoch: 2 | Iteration number: [300/393] 76% | Training loss: 0.863646019299825
Epoch: 2 | Iteration number: [310/393] 78% | Training loss: 0.8628838906365056
Epoch: 2 | Iteration number: [320/393] 81% | Training loss: 0.862175308354199
Epoch: 2 | Iteration number: [330/393] 83% | Training loss: 0.8614810347557068
Epoch: 2 | Iteration number: [340/393] 86% | Training loss: 0.8607925474643707
Epoch: 2 | Iteration number: [350/393] 89% | Training loss: 0.8601277351379395
Epoch: 2 | Iteration number: [360/393] 91% | Training loss: 0.8594367141524951
Epoch: 2 | Iteration number: [370/393] 94% | Training loss: 0.858778491213515
Epoch: 2 | Iteration number: [380/393] 96% | Training loss: 0.8581624393400393
Epoch: 2 | Iteration number: [390/393] 99% | Training loss: 0.857536003834162

 End of epoch: 2 | Train Loss: 0.8552179871927994 | Training Time: 66 

 End of epoch: 2 | Eval Loss: 0.8320211877628249 | Evaluating Time: 16 
Epoch: 3 | Iteration number: [10/393] 2% | Training loss: 0.9157910883426666
Epoch: 3 | Iteration number: [20/393] 5% | Training loss: 0.8722374349832535
Epoch: 3 | Iteration number: [30/393] 7% | Training loss: 0.8580818374951681
Epoch: 3 | Iteration number: [40/393] 10% | Training loss: 0.8505495458841323
Epoch: 3 | Iteration number: [50/393] 12% | Training loss: 0.845535843372345
Epoch: 3 | Iteration number: [60/393] 15% | Training loss: 0.8419529338677724
Epoch: 3 | Iteration number: [70/393] 17% | Training loss: 0.8393262181963239
Epoch: 3 | Iteration number: [80/393] 20% | Training loss: 0.8372424118220806
Epoch: 3 | Iteration number: [90/393] 22% | Training loss: 0.835296184486813
Epoch: 3 | Iteration number: [100/393] 25% | Training loss: 0.8338550573587418
Epoch: 3 | Iteration number: [110/393] 27% | Training loss: 0.8323113338513808
Epoch: 3 | Iteration number: [120/393] 30% | Training loss: 0.8311340764164925
Epoch: 3 | Iteration number: [130/393] 33% | Training loss: 0.829969710111618
Epoch: 3 | Iteration number: [140/393] 35% | Training loss: 0.8286167246954782
Epoch: 3 | Iteration number: [150/393] 38% | Training loss: 0.8276664257049561
Epoch: 3 | Iteration number: [160/393] 40% | Training loss: 0.8266982980072498
Epoch: 3 | Iteration number: [170/393] 43% | Training loss: 0.8259018435197718
Epoch: 3 | Iteration number: [180/393] 45% | Training loss: 0.825001546409395
Epoch: 3 | Iteration number: [190/393] 48% | Training loss: 0.8241874848541461
Epoch: 3 | Iteration number: [200/393] 50% | Training loss: 0.8234352472424508
Epoch: 3 | Iteration number: [210/393] 53% | Training loss: 0.822730556272325
Epoch: 3 | Iteration number: [220/393] 55% | Training loss: 0.8220199278809808
Epoch: 3 | Iteration number: [230/393] 58% | Training loss: 0.8212611395379771
Epoch: 3 | Iteration number: [240/393] 61% | Training loss: 0.8205725098649661
Epoch: 3 | Iteration number: [250/393] 63% | Training loss: 0.8199034616947174
Epoch: 3 | Iteration number: [260/393] 66% | Training loss: 0.8192889850873214
Epoch: 3 | Iteration number: [270/393] 68% | Training loss: 0.8186635631102103
Epoch: 3 | Iteration number: [280/393] 71% | Training loss: 0.8180459656885692
Epoch: 3 | Iteration number: [290/393] 73% | Training loss: 0.8173780850295362
Epoch: 3 | Iteration number: [300/393] 76% | Training loss: 0.8167983529965083
Epoch: 3 | Iteration number: [310/393] 78% | Training loss: 0.8162172846255764
Epoch: 3 | Iteration number: [320/393] 81% | Training loss: 0.815620044246316
Epoch: 3 | Iteration number: [330/393] 83% | Training loss: 0.8150436417622999
Epoch: 3 | Iteration number: [340/393] 86% | Training loss: 0.8144642666858786
Epoch: 3 | Iteration number: [350/393] 89% | Training loss: 0.8139024182728358
Epoch: 3 | Iteration number: [360/393] 91% | Training loss: 0.8133427873253822
Epoch: 3 | Iteration number: [370/393] 94% | Training loss: 0.8128211472485517
Epoch: 3 | Iteration number: [380/393] 96% | Training loss: 0.812264392407317
Epoch: 3 | Iteration number: [390/393] 99% | Training loss: 0.8117371229025033

 End of epoch: 3 | Train Loss: 0.8095764994014614 | Training Time: 66 

 End of epoch: 3 | Eval Loss: 0.7909902200406912 | Evaluating Time: 16 
Epoch: 4 | Iteration number: [10/393] 2% | Training loss: 0.8673628509044647
Epoch: 4 | Iteration number: [20/393] 5% | Training loss: 0.8283013820648193
Epoch: 4 | Iteration number: [30/393] 7% | Training loss: 0.815234378973643
Epoch: 4 | Iteration number: [40/393] 10% | Training loss: 0.8082919761538505
Epoch: 4 | Iteration number: [50/393] 12% | Training loss: 0.8039188218116761
Epoch: 4 | Iteration number: [60/393] 15% | Training loss: 0.8011159072319667
Epoch: 4 | Iteration number: [70/393] 17% | Training loss: 0.7987295269966126
Epoch: 4 | Iteration number: [80/393] 20% | Training loss: 0.7967398881912231
Epoch: 4 | Iteration number: [90/393] 22% | Training loss: 0.7953220307826996
Epoch: 4 | Iteration number: [100/393] 25% | Training loss: 0.7939191806316376
Epoch: 4 | Iteration number: [110/393] 27% | Training loss: 0.7927375945177946
Epoch: 4 | Iteration number: [120/393] 30% | Training loss: 0.7917294040322304
Epoch: 4 | Iteration number: [130/393] 33% | Training loss: 0.7907509322349842
Epoch: 4 | Iteration number: [140/393] 35% | Training loss: 0.7900845829929625
Epoch: 4 | Iteration number: [150/393] 38% | Training loss: 0.7893168930212656
Epoch: 4 | Iteration number: [160/393] 40% | Training loss: 0.7884524781256914
Epoch: 4 | Iteration number: [170/393] 43% | Training loss: 0.7878049145726597
Epoch: 4 | Iteration number: [180/393] 45% | Training loss: 0.7871728354030185
Epoch: 4 | Iteration number: [190/393] 48% | Training loss: 0.7866188849273481
Epoch: 4 | Iteration number: [200/393] 50% | Training loss: 0.7859382110834122
Epoch: 4 | Iteration number: [210/393] 53% | Training loss: 0.7853154642241341
Epoch: 4 | Iteration number: [220/393] 55% | Training loss: 0.7848176373676821
Epoch: 4 | Iteration number: [230/393] 58% | Training loss: 0.7844564668510271
Epoch: 4 | Iteration number: [240/393] 61% | Training loss: 0.783981753885746
Epoch: 4 | Iteration number: [250/393] 63% | Training loss: 0.7834972512722015
Epoch: 4 | Iteration number: [260/393] 66% | Training loss: 0.7829711742126024
Epoch: 4 | Iteration number: [270/393] 68% | Training loss: 0.7825608412424724
Epoch: 4 | Iteration number: [280/393] 71% | Training loss: 0.7820340837751116
Epoch: 4 | Iteration number: [290/393] 73% | Training loss: 0.781531322824544
Epoch: 4 | Iteration number: [300/393] 76% | Training loss: 0.7810263552268346
Epoch: 4 | Iteration number: [310/393] 78% | Training loss: 0.7805712261507588
Epoch: 4 | Iteration number: [320/393] 81% | Training loss: 0.780124362744391
Epoch: 4 | Iteration number: [330/393] 83% | Training loss: 0.7796911732716993
Epoch: 4 | Iteration number: [340/393] 86% | Training loss: 0.7792441902791752
Epoch: 4 | Iteration number: [350/393] 89% | Training loss: 0.7788045835494996
Epoch: 4 | Iteration number: [360/393] 91% | Training loss: 0.7783942783872286
Epoch: 4 | Iteration number: [370/393] 94% | Training loss: 0.7779895809856621
Epoch: 4 | Iteration number: [380/393] 96% | Training loss: 0.7775291522866801
Epoch: 4 | Iteration number: [390/393] 99% | Training loss: 0.7771413375169803

 End of epoch: 4 | Train Loss: 0.7750831434441583 | Training Time: 67 

 End of epoch: 4 | Eval Loss: 0.7596921117938294 | Evaluating Time: 16 
Epoch: 5 | Iteration number: [10/393] 2% | Training loss: 0.836252361536026
Epoch: 5 | Iteration number: [20/393] 5% | Training loss: 0.797908478975296
Epoch: 5 | Iteration number: [30/393] 7% | Training loss: 0.7848315715789795
Epoch: 5 | Iteration number: [40/393] 10% | Training loss: 0.7788187503814697
Epoch: 5 | Iteration number: [50/393] 12% | Training loss: 0.7747583758831024
Epoch: 5 | Iteration number: [60/393] 15% | Training loss: 0.7718337525924047
Epoch: 5 | Iteration number: [70/393] 17% | Training loss: 0.7697671098368508
Epoch: 5 | Iteration number: [80/393] 20% | Training loss: 0.7679924480617046
Epoch: 5 | Iteration number: [90/393] 22% | Training loss: 0.7667554120222727
Epoch: 5 | Iteration number: [100/393] 25% | Training loss: 0.765711852312088
Epoch: 5 | Iteration number: [110/393] 27% | Training loss: 0.7647543040188876
Epoch: 5 | Iteration number: [120/393] 30% | Training loss: 0.7639061252276103
Epoch: 5 | Iteration number: [130/393] 33% | Training loss: 0.7631682767317846
Epoch: 5 | Iteration number: [140/393] 35% | Training loss: 0.7624587254864829
Epoch: 5 | Iteration number: [150/393] 38% | Training loss: 0.7616979352633159
Epoch: 5 | Iteration number: [160/393] 40% | Training loss: 0.7610750537365675
Epoch: 5 | Iteration number: [170/393] 43% | Training loss: 0.7604955999290242
Epoch: 5 | Iteration number: [180/393] 45% | Training loss: 0.7598953031831317
Epoch: 5 | Iteration number: [190/393] 48% | Training loss: 0.7593617022037507
Epoch: 5 | Iteration number: [200/393] 50% | Training loss: 0.758881117105484
Epoch: 5 | Iteration number: [210/393] 53% | Training loss: 0.758415413754327
Epoch: 5 | Iteration number: [220/393] 55% | Training loss: 0.7579927346923134
Epoch: 5 | Iteration number: [230/393] 58% | Training loss: 0.7575626080450805
Epoch: 5 | Iteration number: [240/393] 61% | Training loss: 0.7570391940573852
Epoch: 5 | Iteration number: [250/393] 63% | Training loss: 0.7566638646125794
Epoch: 5 | Iteration number: [260/393] 66% | Training loss: 0.7562522335694386
Epoch: 5 | Iteration number: [270/393] 68% | Training loss: 0.7558747781647577
Epoch: 5 | Iteration number: [280/393] 71% | Training loss: 0.7554703540035657
Epoch: 5 | Iteration number: [290/393] 73% | Training loss: 0.7551103367887694
Epoch: 5 | Iteration number: [300/393] 76% | Training loss: 0.7546949889262518
Epoch: 5 | Iteration number: [310/393] 78% | Training loss: 0.7543671184970486
Epoch: 5 | Iteration number: [320/393] 81% | Training loss: 0.754115441441536
Epoch: 5 | Iteration number: [330/393] 83% | Training loss: 0.7538339257240295
Epoch: 5 | Iteration number: [340/393] 86% | Training loss: 0.753552125657306
Epoch: 5 | Iteration number: [350/393] 89% | Training loss: 0.7532524658952441
Epoch: 5 | Iteration number: [360/393] 91% | Training loss: 0.7529804847306676
Epoch: 5 | Iteration number: [370/393] 94% | Training loss: 0.7527682475141577
Epoch: 5 | Iteration number: [380/393] 96% | Training loss: 0.7525161258484188
Epoch: 5 | Iteration number: [390/393] 99% | Training loss: 0.7522430053124061

 End of epoch: 5 | Train Loss: 0.7502704559998354 | Training Time: 66 

 End of epoch: 5 | Eval Loss: 0.7424965744115868 | Evaluating Time: 17 
Epoch: 6 | Iteration number: [10/393] 2% | Training loss: 0.8146124064922333
Epoch: 6 | Iteration number: [20/393] 5% | Training loss: 0.7772389680147171
Epoch: 6 | Iteration number: [30/393] 7% | Training loss: 0.7650697588920593
Epoch: 6 | Iteration number: [40/393] 10% | Training loss: 0.7588540628552437
Epoch: 6 | Iteration number: [50/393] 12% | Training loss: 0.7547078430652618
Epoch: 6 | Iteration number: [60/393] 15% | Training loss: 0.7522571980953217
Epoch: 6 | Iteration number: [70/393] 17% | Training loss: 0.7503807459558759
Epoch: 6 | Iteration number: [80/393] 20% | Training loss: 0.7488118901848793
Epoch: 6 | Iteration number: [90/393] 22% | Training loss: 0.7476229720645481
Epoch: 6 | Iteration number: [100/393] 25% | Training loss: 0.7465228682756424
Epoch: 6 | Iteration number: [110/393] 27% | Training loss: 0.7456144701350819
Epoch: 6 | Iteration number: [120/393] 30% | Training loss: 0.7448774531483651
Epoch: 6 | Iteration number: [130/393] 33% | Training loss: 0.7441439078404353
Epoch: 6 | Iteration number: [140/393] 35% | Training loss: 0.7435981720685959
Epoch: 6 | Iteration number: [150/393] 38% | Training loss: 0.7430206028620402
Epoch: 6 | Iteration number: [160/393] 40% | Training loss: 0.7425614893436432
Epoch: 6 | Iteration number: [170/393] 43% | Training loss: 0.7421414529576021
Epoch: 6 | Iteration number: [180/393] 45% | Training loss: 0.7416948937707477
Epoch: 6 | Iteration number: [190/393] 48% | Training loss: 0.7412106203405481
Epoch: 6 | Iteration number: [200/393] 50% | Training loss: 0.7407461112737656
Epoch: 6 | Iteration number: [210/393] 53% | Training loss: 0.7403292579310281
Epoch: 6 | Iteration number: [220/393] 55% | Training loss: 0.7399632822383534
Epoch: 6 | Iteration number: [230/393] 58% | Training loss: 0.7396107800628828
Epoch: 6 | Iteration number: [240/393] 61% | Training loss: 0.739240720619758
Epoch: 6 | Iteration number: [250/393] 63% | Training loss: 0.7389712448120117
Epoch: 6 | Iteration number: [260/393] 66% | Training loss: 0.7386626383432975
Epoch: 6 | Iteration number: [270/393] 68% | Training loss: 0.738406663691556
Epoch: 6 | Iteration number: [280/393] 71% | Training loss: 0.7381204162325178
Epoch: 6 | Iteration number: [290/393] 73% | Training loss: 0.7378473557274917
Epoch: 6 | Iteration number: [300/393] 76% | Training loss: 0.7375625914335251
Epoch: 6 | Iteration number: [310/393] 78% | Training loss: 0.7372845730473918
Epoch: 6 | Iteration number: [320/393] 81% | Training loss: 0.7370506346225738
Epoch: 6 | Iteration number: [330/393] 83% | Training loss: 0.7367976815411539
Epoch: 6 | Iteration number: [340/393] 86% | Training loss: 0.7365600713912178
Epoch: 6 | Iteration number: [350/393] 89% | Training loss: 0.7363215974399022
Epoch: 6 | Iteration number: [360/393] 91% | Training loss: 0.736049442158805
Epoch: 6 | Iteration number: [370/393] 94% | Training loss: 0.7358274024886053
Epoch: 6 | Iteration number: [380/393] 96% | Training loss: 0.7355819789986862
Epoch: 6 | Iteration number: [390/393] 99% | Training loss: 0.7353807495190547

 End of epoch: 6 | Train Loss: 0.7334684576393691 | Training Time: 66 

 End of epoch: 6 | Eval Loss: 0.7277551232552042 | Evaluating Time: 16 
Epoch: 7 | Iteration number: [10/393] 2% | Training loss: 0.7989027857780456
Epoch: 7 | Iteration number: [20/393] 5% | Training loss: 0.7623441874980926
Epoch: 7 | Iteration number: [30/393] 7% | Training loss: 0.7501610577106476
Epoch: 7 | Iteration number: [40/393] 10% | Training loss: 0.7444523751735688
Epoch: 7 | Iteration number: [50/393] 12% | Training loss: 0.7406050503253937
Epoch: 7 | Iteration number: [60/393] 15% | Training loss: 0.7380423764387767
Epoch: 7 | Iteration number: [70/393] 17% | Training loss: 0.7360224774905614
Epoch: 7 | Iteration number: [80/393] 20% | Training loss: 0.7346065796911716
Epoch: 7 | Iteration number: [90/393] 22% | Training loss: 0.7334021230538686
Epoch: 7 | Iteration number: [100/393] 25% | Training loss: 0.7323781228065491
Epoch: 7 | Iteration number: [110/393] 27% | Training loss: 0.7317022963003679
Epoch: 7 | Iteration number: [120/393] 30% | Training loss: 0.7309877986709277
Epoch: 7 | Iteration number: [130/393] 33% | Training loss: 0.730436607507559
Epoch: 7 | Iteration number: [140/393] 35% | Training loss: 0.7300478241273335
Epoch: 7 | Iteration number: [150/393] 38% | Training loss: 0.7297001735369364
Epoch: 7 | Iteration number: [160/393] 40% | Training loss: 0.7292801160365343
Epoch: 7 | Iteration number: [170/393] 43% | Training loss: 0.7288040841326994
Epoch: 7 | Iteration number: [180/393] 45% | Training loss: 0.7284289711051517
Epoch: 7 | Iteration number: [190/393] 48% | Training loss: 0.7281152166818318
Epoch: 7 | Iteration number: [200/393] 50% | Training loss: 0.7277981293201446
Epoch: 7 | Iteration number: [210/393] 53% | Training loss: 0.7275634572619484
Epoch: 7 | Iteration number: [220/393] 55% | Training loss: 0.7272147346626628
Epoch: 7 | Iteration number: [230/393] 58% | Training loss: 0.726852539052134
Epoch: 7 | Iteration number: [240/393] 61% | Training loss: 0.726643963654836
Epoch: 7 | Iteration number: [250/393] 63% | Training loss: 0.7263873677253723
Epoch: 7 | Iteration number: [260/393] 66% | Training loss: 0.7261535871487398
Epoch: 7 | Iteration number: [270/393] 68% | Training loss: 0.7259567397612112
Epoch: 7 | Iteration number: [280/393] 71% | Training loss: 0.7257399495158877
Epoch: 7 | Iteration number: [290/393] 73% | Training loss: 0.7254955534277291
Epoch: 7 | Iteration number: [300/393] 76% | Training loss: 0.7252716046571731
Epoch: 7 | Iteration number: [310/393] 78% | Training loss: 0.7250666829847521
Epoch: 7 | Iteration number: [320/393] 81% | Training loss: 0.7248394522815943
Epoch: 7 | Iteration number: [330/393] 83% | Training loss: 0.7246353875507008
Epoch: 7 | Iteration number: [340/393] 86% | Training loss: 0.7244482159614563
Epoch: 7 | Iteration number: [350/393] 89% | Training loss: 0.7242544790676662
Epoch: 7 | Iteration number: [360/393] 91% | Training loss: 0.7240855743487676
Epoch: 7 | Iteration number: [370/393] 94% | Training loss: 0.7238921917773582
Epoch: 7 | Iteration number: [380/393] 96% | Training loss: 0.7237523240478415
Epoch: 7 | Iteration number: [390/393] 99% | Training loss: 0.7235900917114355

 End of epoch: 7 | Train Loss: 0.7217120972601815 | Training Time: 66 

 End of epoch: 7 | Eval Loss: 0.7180016916625354 | Evaluating Time: 16 
Epoch: 8 | Iteration number: [10/393] 2% | Training loss: 0.7890945553779602
Epoch: 8 | Iteration number: [20/393] 5% | Training loss: 0.7546144515275955
Epoch: 8 | Iteration number: [30/393] 7% | Training loss: 0.7426684319972991
Epoch: 8 | Iteration number: [40/393] 10% | Training loss: 0.7367435067892074
Epoch: 8 | Iteration number: [50/393] 12% | Training loss: 0.7329071235656738
Epoch: 8 | Iteration number: [60/393] 15% | Training loss: 0.7301666975021363
Epoch: 8 | Iteration number: [70/393] 17% | Training loss: 0.7280999754156385
Epoch: 8 | Iteration number: [80/393] 20% | Training loss: 0.7266233161091804
Epoch: 8 | Iteration number: [90/393] 22% | Training loss: 0.7255065792136722
Epoch: 8 | Iteration number: [100/393] 25% | Training loss: 0.7246295589208603
Epoch: 8 | Iteration number: [110/393] 27% | Training loss: 0.7238085064021024
Epoch: 8 | Iteration number: [120/393] 30% | Training loss: 0.723136518895626
Epoch: 8 | Iteration number: [130/393] 33% | Training loss: 0.7225157205875103
Epoch: 8 | Iteration number: [140/393] 35% | Training loss: 0.7219489744731358
Epoch: 8 | Iteration number: [150/393] 38% | Training loss: 0.7214786875247955
Epoch: 8 | Iteration number: [160/393] 40% | Training loss: 0.7209674090147018
Epoch: 8 | Iteration number: [170/393] 43% | Training loss: 0.7206174973179312
Epoch: 8 | Iteration number: [180/393] 45% | Training loss: 0.7202907264232635
Epoch: 8 | Iteration number: [190/393] 48% | Training loss: 0.7198844028146644
Epoch: 8 | Iteration number: [200/393] 50% | Training loss: 0.7195931905508042
Epoch: 8 | Iteration number: [210/393] 53% | Training loss: 0.7193704261666253
Epoch: 8 | Iteration number: [220/393] 55% | Training loss: 0.7190737128257751
Epoch: 8 | Iteration number: [230/393] 58% | Training loss: 0.718819276664568
Epoch: 8 | Iteration number: [240/393] 61% | Training loss: 0.7186586496730646
Epoch: 8 | Iteration number: [250/393] 63% | Training loss: 0.7184327647686005
Epoch: 8 | Iteration number: [260/393] 66% | Training loss: 0.7181959498387117
Epoch: 8 | Iteration number: [270/393] 68% | Training loss: 0.717932359598301
Epoch: 8 | Iteration number: [280/393] 71% | Training loss: 0.7177002419318471
Epoch: 8 | Iteration number: [290/393] 73% | Training loss: 0.7174813745350673
Epoch: 8 | Iteration number: [300/393] 76% | Training loss: 0.7173054603735606
Epoch: 8 | Iteration number: [310/393] 78% | Training loss: 0.7171348808273192
Epoch: 8 | Iteration number: [320/393] 81% | Training loss: 0.7169922111555934
Epoch: 8 | Iteration number: [330/393] 83% | Training loss: 0.7168269077936809
Epoch: 8 | Iteration number: [340/393] 86% | Training loss: 0.7166487543021931
Epoch: 8 | Iteration number: [350/393] 89% | Training loss: 0.7164381728853498
Epoch: 8 | Iteration number: [360/393] 91% | Training loss: 0.7162926142414411
Epoch: 8 | Iteration number: [370/393] 94% | Training loss: 0.7161642941268714
Epoch: 8 | Iteration number: [380/393] 96% | Training loss: 0.7160116710160908
Epoch: 8 | Iteration number: [390/393] 99% | Training loss: 0.7158501952122419

 End of epoch: 8 | Train Loss: 0.7140002064122498 | Training Time: 66 

 End of epoch: 8 | Eval Loss: 0.7102180050343884 | Evaluating Time: 17 
Epoch: 9 | Iteration number: [10/393] 2% | Training loss: 0.7805987298488617
Epoch: 9 | Iteration number: [20/393] 5% | Training loss: 0.7450207620859146
Epoch: 9 | Iteration number: [30/393] 7% | Training loss: 0.7327906886736552
Epoch: 9 | Iteration number: [40/393] 10% | Training loss: 0.72713553160429
Epoch: 9 | Iteration number: [50/393] 12% | Training loss: 0.7236211109161377
Epoch: 9 | Iteration number: [60/393] 15% | Training loss: 0.7210874110460281
Epoch: 9 | Iteration number: [70/393] 17% | Training loss: 0.7196810586111886
Epoch: 9 | Iteration number: [80/393] 20% | Training loss: 0.7184422835707664
Epoch: 9 | Iteration number: [90/393] 22% | Training loss: 0.7173008984989591
Epoch: 9 | Iteration number: [100/393] 25% | Training loss: 0.7165302211046218
Epoch: 9 | Iteration number: [110/393] 27% | Training loss: 0.7158572137355804
Epoch: 9 | Iteration number: [120/393] 30% | Training loss: 0.7152696703871091
Epoch: 9 | Iteration number: [130/393] 33% | Training loss: 0.7147688732697414
Epoch: 9 | Iteration number: [140/393] 35% | Training loss: 0.7142850250005722
Epoch: 9 | Iteration number: [150/393] 38% | Training loss: 0.7139379171530406
Epoch: 9 | Iteration number: [160/393] 40% | Training loss: 0.7135931931436061
Epoch: 9 | Iteration number: [170/393] 43% | Training loss: 0.7133274288738475
Epoch: 9 | Iteration number: [180/393] 45% | Training loss: 0.713020395901468
Epoch: 9 | Iteration number: [190/393] 48% | Training loss: 0.7127621522075251
Epoch: 9 | Iteration number: [200/393] 50% | Training loss: 0.7125097945332527
Epoch: 9 | Iteration number: [210/393] 53% | Training loss: 0.7122626440865653
Epoch: 9 | Iteration number: [220/393] 55% | Training loss: 0.7120142402974042
Epoch: 9 | Iteration number: [230/393] 58% | Training loss: 0.711805051824321
Epoch: 9 | Iteration number: [240/393] 61% | Training loss: 0.7115925679604213
Epoch: 9 | Iteration number: [250/393] 63% | Training loss: 0.7114139015674591
Epoch: 9 | Iteration number: [260/393] 66% | Training loss: 0.7112271354748653
Epoch: 9 | Iteration number: [270/393] 68% | Training loss: 0.7110371128276542
Epoch: 9 | Iteration number: [280/393] 71% | Training loss: 0.7108437110270772
Epoch: 9 | Iteration number: [290/393] 73% | Training loss: 0.7107004829521837
Epoch: 9 | Iteration number: [300/393] 76% | Training loss: 0.7105650905768076
Epoch: 9 | Iteration number: [310/393] 78% | Training loss: 0.7104193435561272
Epoch: 9 | Iteration number: [320/393] 81% | Training loss: 0.7102527732029558
Epoch: 9 | Iteration number: [330/393] 83% | Training loss: 0.7101458332755349
Epoch: 9 | Iteration number: [340/393] 86% | Training loss: 0.7100460155921824
Epoch: 9 | Iteration number: [350/393] 89% | Training loss: 0.7099202719756535
Epoch: 9 | Iteration number: [360/393] 91% | Training loss: 0.7097969474063979
Epoch: 9 | Iteration number: [370/393] 94% | Training loss: 0.7096696537894172
Epoch: 9 | Iteration number: [380/393] 96% | Training loss: 0.7095475998363997
Epoch: 9 | Iteration number: [390/393] 99% | Training loss: 0.7094425287002172

 End of epoch: 9 | Train Loss: 0.7076124128797885 | Training Time: 67 

 End of epoch: 9 | Eval Loss: 0.7054809185923362 | Evaluating Time: 16 
Epoch: 10 | Iteration number: [10/393] 2% | Training loss: 0.7753880500793457
Epoch: 10 | Iteration number: [20/393] 5% | Training loss: 0.7401174187660218
Epoch: 10 | Iteration number: [30/393] 7% | Training loss: 0.7284387250741323
Epoch: 10 | Iteration number: [40/393] 10% | Training loss: 0.7225142329931259
Epoch: 10 | Iteration number: [50/393] 12% | Training loss: 0.7188871967792511
Epoch: 10 | Iteration number: [60/393] 15% | Training loss: 0.7165644566218058
Epoch: 10 | Iteration number: [70/393] 17% | Training loss: 0.7149433323315212
Epoch: 10 | Iteration number: [80/393] 20% | Training loss: 0.7138245664536953
Epoch: 10 | Iteration number: [90/393] 22% | Training loss: 0.7128713978661432
Epoch: 10 | Iteration number: [100/393] 25% | Training loss: 0.7120538502931595
Epoch: 10 | Iteration number: [110/393] 27% | Training loss: 0.7113588652827523
Epoch: 10 | Iteration number: [120/393] 30% | Training loss: 0.7108016545573871
Epoch: 10 | Iteration number: [130/393] 33% | Training loss: 0.7103019388822409
Epoch: 10 | Iteration number: [140/393] 35% | Training loss: 0.7098075773034777
Epoch: 10 | Iteration number: [150/393] 38% | Training loss: 0.7093404495716095
Epoch: 10 | Iteration number: [160/393] 40% | Training loss: 0.7090402159839868
Epoch: 10 | Iteration number: [170/393] 43% | Training loss: 0.7087346438099357
Epoch: 10 | Iteration number: [180/393] 45% | Training loss: 0.7084737575716442
Epoch: 10 | Iteration number: [190/393] 48% | Training loss: 0.7081757711736779
Epoch: 10 | Iteration number: [200/393] 50% | Training loss: 0.7079133623838425
Epoch: 10 | Iteration number: [210/393] 53% | Training loss: 0.7076633107094538
Epoch: 10 | Iteration number: [220/393] 55% | Training loss: 0.7075129411437294
Epoch: 10 | Iteration number: [230/393] 58% | Training loss: 0.7073181807994843
Epoch: 10 | Iteration number: [240/393] 61% | Training loss: 0.7071098191042741
Epoch: 10 | Iteration number: [250/393] 63% | Training loss: 0.706888444185257
Epoch: 10 | Iteration number: [260/393] 66% | Training loss: 0.7067331988077897
Epoch: 10 | Iteration number: [270/393] 68% | Training loss: 0.7066245279930256
Epoch: 10 | Iteration number: [280/393] 71% | Training loss: 0.7065035820007324
Epoch: 10 | Iteration number: [290/393] 73% | Training loss: 0.7063843955253732
Epoch: 10 | Iteration number: [300/393] 76% | Training loss: 0.7062520211935044
Epoch: 10 | Iteration number: [310/393] 78% | Training loss: 0.706132088745794
Epoch: 10 | Iteration number: [320/393] 81% | Training loss: 0.7059982703998685
Epoch: 10 | Iteration number: [330/393] 83% | Training loss: 0.705865517168334
Epoch: 10 | Iteration number: [340/393] 86% | Training loss: 0.7057827647994547
Epoch: 10 | Iteration number: [350/393] 89% | Training loss: 0.7056603487900325
Epoch: 10 | Iteration number: [360/393] 91% | Training loss: 0.7055459168222216
Epoch: 10 | Iteration number: [370/393] 94% | Training loss: 0.70543101462158
Epoch: 10 | Iteration number: [380/393] 96% | Training loss: 0.7053507596254349
Epoch: 10 | Iteration number: [390/393] 99% | Training loss: 0.7052545565825242

 End of epoch: 10 | Train Loss: 0.7034512573222774 | Training Time: 66 

 End of epoch: 10 | Eval Loss: 0.7016957937454691 | Evaluating Time: 17 
Epoch: 11 | Iteration number: [10/393] 2% | Training loss: 0.7710586607456207
Epoch: 11 | Iteration number: [20/393] 5% | Training loss: 0.7366742372512818
Epoch: 11 | Iteration number: [30/393] 7% | Training loss: 0.7252131342887879
Epoch: 11 | Iteration number: [40/393] 10% | Training loss: 0.7195052012801171
Epoch: 11 | Iteration number: [50/393] 12% | Training loss: 0.7160449874401092
Epoch: 11 | Iteration number: [60/393] 15% | Training loss: 0.7136523326237997
Epoch: 11 | Iteration number: [70/393] 17% | Training loss: 0.7118780919483729
Epoch: 11 | Iteration number: [80/393] 20% | Training loss: 0.710348516702652
Epoch: 11 | Iteration number: [90/393] 22% | Training loss: 0.7094451400968763
Epoch: 11 | Iteration number: [100/393] 25% | Training loss: 0.7085673743486405
Epoch: 11 | Iteration number: [110/393] 27% | Training loss: 0.7079780139706352
Epoch: 11 | Iteration number: [120/393] 30% | Training loss: 0.7075587396820386
Epoch: 11 | Iteration number: [130/393] 33% | Training loss: 0.7070063049976643
Epoch: 11 | Iteration number: [140/393] 35% | Training loss: 0.7066008435828345
Epoch: 11 | Iteration number: [150/393] 38% | Training loss: 0.706245475212733
Epoch: 11 | Iteration number: [160/393] 40% | Training loss: 0.7059286899864674
Epoch: 11 | Iteration number: [170/393] 43% | Training loss: 0.7056874531156877
Epoch: 11 | Iteration number: [180/393] 45% | Training loss: 0.7054002301560508
Epoch: 11 | Iteration number: [190/393] 48% | Training loss: 0.7051061407515877
Epoch: 11 | Iteration number: [200/393] 50% | Training loss: 0.7048996284604072
Epoch: 11 | Iteration number: [210/393] 53% | Training loss: 0.7047293884413582
Epoch: 11 | Iteration number: [220/393] 55% | Training loss: 0.7045421920039437
Epoch: 11 | Iteration number: [230/393] 58% | Training loss: 0.7043425443379775
Epoch: 11 | Iteration number: [240/393] 61% | Training loss: 0.7041616986195246
Epoch: 11 | Iteration number: [250/393] 63% | Training loss: 0.7040476622581482
Epoch: 11 | Iteration number: [260/393] 66% | Training loss: 0.70389355971263
Epoch: 11 | Iteration number: [270/393] 68% | Training loss: 0.703797619651865
Epoch: 11 | Iteration number: [280/393] 71% | Training loss: 0.7036758482456207
Epoch: 11 | Iteration number: [290/393] 73% | Training loss: 0.7035550384685911
Epoch: 11 | Iteration number: [300/393] 76% | Training loss: 0.7034403322140376
Epoch: 11 | Iteration number: [310/393] 78% | Training loss: 0.7033168663901668
Epoch: 11 | Iteration number: [320/393] 81% | Training loss: 0.7032034896314144
Epoch: 11 | Iteration number: [330/393] 83% | Training loss: 0.7030952161008661
Epoch: 11 | Iteration number: [340/393] 86% | Training loss: 0.7029737062313978
Epoch: 11 | Iteration number: [350/393] 89% | Training loss: 0.7028652237142835
Epoch: 11 | Iteration number: [360/393] 91% | Training loss: 0.7027681908673711
Epoch: 11 | Iteration number: [370/393] 94% | Training loss: 0.7026679216204463
Epoch: 11 | Iteration number: [380/393] 96% | Training loss: 0.7025842807794872
Epoch: 11 | Iteration number: [390/393] 99% | Training loss: 0.7025165932300763

 End of epoch: 11 | Train Loss: 0.7007130132680024 | Training Time: 66 

 End of epoch: 11 | Eval Loss: 0.6991724566537507 | Evaluating Time: 16 
Epoch: 12 | Iteration number: [10/393] 2% | Training loss: 0.7699789702892303
Epoch: 12 | Iteration number: [20/393] 5% | Training loss: 0.7345692783594131
Epoch: 12 | Iteration number: [30/393] 7% | Training loss: 0.722717938820521
Epoch: 12 | Iteration number: [40/393] 10% | Training loss: 0.7165281489491463
Epoch: 12 | Iteration number: [50/393] 12% | Training loss: 0.7129993724822998
Epoch: 12 | Iteration number: [60/393] 15% | Training loss: 0.7106760780016581
Epoch: 12 | Iteration number: [70/393] 17% | Training loss: 0.7090190282889774
Epoch: 12 | Iteration number: [80/393] 20% | Training loss: 0.7078276157379151
Epoch: 12 | Iteration number: [90/393] 22% | Training loss: 0.7067740619182586
Epoch: 12 | Iteration number: [100/393] 25% | Training loss: 0.7061238104104995
Epoch: 12 | Iteration number: [110/393] 27% | Training loss: 0.7054479393092069
Epoch: 12 | Iteration number: [120/393] 30% | Training loss: 0.7049821535746257
Epoch: 12 | Iteration number: [130/393] 33% | Training loss: 0.7045315036406884
Epoch: 12 | Iteration number: [140/393] 35% | Training loss: 0.7041389341865267
Epoch: 12 | Iteration number: [150/393] 38% | Training loss: 0.7038131968180339
Epoch: 12 | Iteration number: [160/393] 40% | Training loss: 0.7034853987395764
Epoch: 12 | Iteration number: [170/393] 43% | Training loss: 0.7032096989014569
Epoch: 12 | Iteration number: [180/393] 45% | Training loss: 0.7029222548007965
Epoch: 12 | Iteration number: [190/393] 48% | Training loss: 0.7026648904147901
Epoch: 12 | Iteration number: [200/393] 50% | Training loss: 0.7024429544806481
Epoch: 12 | Iteration number: [210/393] 53% | Training loss: 0.7022744059562683
Epoch: 12 | Iteration number: [220/393] 55% | Training loss: 0.702054946530949
Epoch: 12 | Iteration number: [230/393] 58% | Training loss: 0.7019340328548266
Epoch: 12 | Iteration number: [240/393] 61% | Training loss: 0.7018149775763353
Epoch: 12 | Iteration number: [250/393] 63% | Training loss: 0.7016735999584198
Epoch: 12 | Iteration number: [260/393] 66% | Training loss: 0.7015505634821378
Epoch: 12 | Iteration number: [270/393] 68% | Training loss: 0.7014197457719732
Epoch: 12 | Iteration number: [280/393] 71% | Training loss: 0.701301711159093
Epoch: 12 | Iteration number: [290/393] 73% | Training loss: 0.7011846018248591
Epoch: 12 | Iteration number: [300/393] 76% | Training loss: 0.7010660588741302
Epoch: 12 | Iteration number: [310/393] 78% | Training loss: 0.7008919279421529
Epoch: 12 | Iteration number: [320/393] 81% | Training loss: 0.7007977133616805
Epoch: 12 | Iteration number: [330/393] 83% | Training loss: 0.7007252501718926
Epoch: 12 | Iteration number: [340/393] 86% | Training loss: 0.7006574644761927
Epoch: 12 | Iteration number: [350/393] 89% | Training loss: 0.7005829855373927
Epoch: 12 | Iteration number: [360/393] 91% | Training loss: 0.700492758055528
Epoch: 12 | Iteration number: [370/393] 94% | Training loss: 0.7004190488441571
Epoch: 12 | Iteration number: [380/393] 96% | Training loss: 0.7003740273023906
Epoch: 12 | Iteration number: [390/393] 99% | Training loss: 0.7002799544578944

 End of epoch: 12 | Train Loss: 0.6984950423847325 | Training Time: 66 

 End of epoch: 12 | Eval Loss: 0.6974906167205499 | Evaluating Time: 16 
Epoch: 13 | Iteration number: [10/393] 2% | Training loss: 0.766068947315216
Epoch: 13 | Iteration number: [20/393] 5% | Training loss: 0.7320742636919022
Epoch: 13 | Iteration number: [30/393] 7% | Training loss: 0.7207230945428212
Epoch: 13 | Iteration number: [40/393] 10% | Training loss: 0.7145712465047837
Epoch: 13 | Iteration number: [50/393] 12% | Training loss: 0.7112860226631165
Epoch: 13 | Iteration number: [60/393] 15% | Training loss: 0.7088672151168187
Epoch: 13 | Iteration number: [70/393] 17% | Training loss: 0.7072143648351942
Epoch: 13 | Iteration number: [80/393] 20% | Training loss: 0.7060293726623058
Epoch: 13 | Iteration number: [90/393] 22% | Training loss: 0.7050661981105805
Epoch: 13 | Iteration number: [100/393] 25% | Training loss: 0.7043781018257141
Epoch: 13 | Iteration number: [110/393] 27% | Training loss: 0.7037748217582702
Epoch: 13 | Iteration number: [120/393] 30% | Training loss: 0.7032220646739006
Epoch: 13 | Iteration number: [130/393] 33% | Training loss: 0.7027178356280693
Epoch: 13 | Iteration number: [140/393] 35% | Training loss: 0.7022816270589829
Epoch: 13 | Iteration number: [150/393] 38% | Training loss: 0.7019100713729859
Epoch: 13 | Iteration number: [160/393] 40% | Training loss: 0.7015200357884168
Epoch: 13 | Iteration number: [170/393] 43% | Training loss: 0.7013116138822892
Epoch: 13 | Iteration number: [180/393] 45% | Training loss: 0.7010425905386607
Epoch: 13 | Iteration number: [190/393] 48% | Training loss: 0.7008564713754152
Epoch: 13 | Iteration number: [200/393] 50% | Training loss: 0.7006489384174347
Epoch: 13 | Iteration number: [210/393] 53% | Training loss: 0.700502093633016
Epoch: 13 | Iteration number: [220/393] 55% | Training loss: 0.7003534907644445
Epoch: 13 | Iteration number: [230/393] 58% | Training loss: 0.7002007593279299
Epoch: 13 | Iteration number: [240/393] 61% | Training loss: 0.7000806088248889
Epoch: 13 | Iteration number: [250/393] 63% | Training loss: 0.6999127357006073
Epoch: 13 | Iteration number: [260/393] 66% | Training loss: 0.6997865236722506
Epoch: 13 | Iteration number: [270/393] 68% | Training loss: 0.6996650636196137
Epoch: 13 | Iteration number: [280/393] 71% | Training loss: 0.6995417226638113
Epoch: 13 | Iteration number: [290/393] 73% | Training loss: 0.6994458679495187
Epoch: 13 | Iteration number: [300/393] 76% | Training loss: 0.699354723294576
Epoch: 13 | Iteration number: [310/393] 78% | Training loss: 0.6992538079138725
Epoch: 13 | Iteration number: [320/393] 81% | Training loss: 0.6991684960201383
Epoch: 13 | Iteration number: [330/393] 83% | Training loss: 0.6990969917990945
Epoch: 13 | Iteration number: [340/393] 86% | Training loss: 0.6990419166929581
Epoch: 13 | Iteration number: [350/393] 89% | Training loss: 0.6989482838766915
Epoch: 13 | Iteration number: [360/393] 91% | Training loss: 0.6988207520710097
Epoch: 13 | Iteration number: [370/393] 94% | Training loss: 0.6987348203723495
Epoch: 13 | Iteration number: [380/393] 96% | Training loss: 0.6986636185332349
Epoch: 13 | Iteration number: [390/393] 99% | Training loss: 0.6985875861767011

 End of epoch: 13 | Train Loss: 0.6968013812567442 | Training Time: 66 

 End of epoch: 13 | Eval Loss: 0.6958723360178422 | Evaluating Time: 16 
Epoch: 14 | Iteration number: [10/393] 2% | Training loss: 0.7651246905326843
Epoch: 14 | Iteration number: [20/393] 5% | Training loss: 0.7307479083538055
Epoch: 14 | Iteration number: [30/393] 7% | Training loss: 0.7188841462135315
Epoch: 14 | Iteration number: [40/393] 10% | Training loss: 0.7133210703730584
Epoch: 14 | Iteration number: [50/393] 12% | Training loss: 0.7098490691184998
Epoch: 14 | Iteration number: [60/393] 15% | Training loss: 0.7075439016024272
Epoch: 14 | Iteration number: [70/393] 17% | Training loss: 0.7059392639568873
Epoch: 14 | Iteration number: [80/393] 20% | Training loss: 0.7047995269298554
Epoch: 14 | Iteration number: [90/393] 22% | Training loss: 0.7038667963610755
Epoch: 14 | Iteration number: [100/393] 25% | Training loss: 0.7030444085597992
Epoch: 14 | Iteration number: [110/393] 27% | Training loss: 0.7025085850195452
Epoch: 14 | Iteration number: [120/393] 30% | Training loss: 0.7019911224643389
Epoch: 14 | Iteration number: [130/393] 33% | Training loss: 0.7014889703347132
Epoch: 14 | Iteration number: [140/393] 35% | Training loss: 0.7011357473475592
Epoch: 14 | Iteration number: [150/393] 38% | Training loss: 0.70072927236557
Epoch: 14 | Iteration number: [160/393] 40% | Training loss: 0.7004225961863995
Epoch: 14 | Iteration number: [170/393] 43% | Training loss: 0.7001628241118263
Epoch: 14 | Iteration number: [180/393] 45% | Training loss: 0.6998775422573089
Epoch: 14 | Iteration number: [190/393] 48% | Training loss: 0.6996944766295584
Epoch: 14 | Iteration number: [200/393] 50% | Training loss: 0.6994896018505097
Epoch: 14 | Iteration number: [210/393] 53% | Training loss: 0.6993729228065128
Epoch: 14 | Iteration number: [220/393] 55% | Training loss: 0.6992050089619376
Epoch: 14 | Iteration number: [230/393] 58% | Training loss: 0.6990208993787351
Epoch: 14 | Iteration number: [240/393] 61% | Training loss: 0.698845777908961
Epoch: 14 | Iteration number: [250/393] 63% | Training loss: 0.6986533889770508
Epoch: 14 | Iteration number: [260/393] 66% | Training loss: 0.6984984271801435
Epoch: 14 | Iteration number: [270/393] 68% | Training loss: 0.6983852287133535
Epoch: 14 | Iteration number: [280/393] 71% | Training loss: 0.6982771649956703
Epoch: 14 | Iteration number: [290/393] 73% | Training loss: 0.698154000167189
Epoch: 14 | Iteration number: [300/393] 76% | Training loss: 0.6980423206090927
Epoch: 14 | Iteration number: [310/393] 78% | Training loss: 0.697930940312724
Epoch: 14 | Iteration number: [320/393] 81% | Training loss: 0.6978252612054348
Epoch: 14 | Iteration number: [330/393] 83% | Training loss: 0.6978096665758076
Epoch: 14 | Iteration number: [340/393] 86% | Training loss: 0.6977202629341799
Epoch: 14 | Iteration number: [350/393] 89% | Training loss: 0.6976505770002093
Epoch: 14 | Iteration number: [360/393] 91% | Training loss: 0.6975729301571846
Epoch: 14 | Iteration number: [370/393] 94% | Training loss: 0.6975362661722544
Epoch: 14 | Iteration number: [380/393] 96% | Training loss: 0.6974483864872079
Epoch: 14 | Iteration number: [390/393] 99% | Training loss: 0.6973784879232064

 End of epoch: 14 | Train Loss: 0.6955737661162709 | Training Time: 66 

 End of epoch: 14 | Eval Loss: 0.6951266612325396 | Evaluating Time: 17 
Epoch: 15 | Iteration number: [10/393] 2% | Training loss: 0.7639441728591919
Epoch: 15 | Iteration number: [20/393] 5% | Training loss: 0.7292186468839645
Epoch: 15 | Iteration number: [30/393] 7% | Training loss: 0.7177147050698598
Epoch: 15 | Iteration number: [40/393] 10% | Training loss: 0.7120166882872582
Epoch: 15 | Iteration number: [50/393] 12% | Training loss: 0.7085598540306092
Epoch: 15 | Iteration number: [60/393] 15% | Training loss: 0.706294455130895
Epoch: 15 | Iteration number: [70/393] 17% | Training loss: 0.7047263009207589
Epoch: 15 | Iteration number: [80/393] 20% | Training loss: 0.7034418746829033
Epoch: 15 | Iteration number: [90/393] 22% | Training loss: 0.7023911780781216
Epoch: 15 | Iteration number: [100/393] 25% | Training loss: 0.7016197043657303
Epoch: 15 | Iteration number: [110/393] 27% | Training loss: 0.701021406325427
Epoch: 15 | Iteration number: [120/393] 30% | Training loss: 0.7004458298285802
Epoch: 15 | Iteration number: [130/393] 33% | Training loss: 0.7000163903603187
Epoch: 15 | Iteration number: [140/393] 35% | Training loss: 0.6995596034186227
Epoch: 15 | Iteration number: [150/393] 38% | Training loss: 0.699249943892161
Epoch: 15 | Iteration number: [160/393] 40% | Training loss: 0.6989069569855928
Epoch: 15 | Iteration number: [170/393] 43% | Training loss: 0.6986930727958679
Epoch: 15 | Iteration number: [180/393] 45% | Training loss: 0.6984492550293605
Epoch: 15 | Iteration number: [190/393] 48% | Training loss: 0.6983074451747694
Epoch: 15 | Iteration number: [200/393] 50% | Training loss: 0.6980594864487648
Epoch: 15 | Iteration number: [210/393] 53% | Training loss: 0.6978619433584667
Epoch: 15 | Iteration number: [220/393] 55% | Training loss: 0.6977158692750064
Epoch: 15 | Iteration number: [230/393] 58% | Training loss: 0.6976209264734518
Epoch: 15 | Iteration number: [240/393] 61% | Training loss: 0.6974825424452623
Epoch: 15 | Iteration number: [250/393] 63% | Training loss: 0.697389955997467
Epoch: 15 | Iteration number: [260/393] 66% | Training loss: 0.6972691710178669
Epoch: 15 | Iteration number: [270/393] 68% | Training loss: 0.6971666744461766
Epoch: 15 | Iteration number: [280/393] 71% | Training loss: 0.6970772006681987
Epoch: 15 | Iteration number: [290/393] 73% | Training loss: 0.6969610904825145
Epoch: 15 | Iteration number: [300/393] 76% | Training loss: 0.6968663956721624
Epoch: 15 | Iteration number: [310/393] 78% | Training loss: 0.6967958083075861
Epoch: 15 | Iteration number: [320/393] 81% | Training loss: 0.69671640843153
Epoch: 15 | Iteration number: [330/393] 83% | Training loss: 0.6966362290310137
Epoch: 15 | Iteration number: [340/393] 86% | Training loss: 0.6965690854717703
Epoch: 15 | Iteration number: [350/393] 89% | Training loss: 0.6965102469921112
Epoch: 15 | Iteration number: [360/393] 91% | Training loss: 0.6964308435718218
Epoch: 15 | Iteration number: [370/393] 94% | Training loss: 0.6963739517572763
Epoch: 15 | Iteration number: [380/393] 96% | Training loss: 0.6963053455478266
Epoch: 15 | Iteration number: [390/393] 99% | Training loss: 0.6962448624464181

 End of epoch: 15 | Train Loss: 0.6944716578828166 | Training Time: 66 

 End of epoch: 15 | Eval Loss: 0.6939043171551763 | Evaluating Time: 16 
Epoch: 16 | Iteration number: [10/393] 2% | Training loss: 0.7629897952079773
Epoch: 16 | Iteration number: [20/393] 5% | Training loss: 0.7286726862192154
Epoch: 16 | Iteration number: [30/393] 7% | Training loss: 0.7173858642578125
Epoch: 16 | Iteration number: [40/393] 10% | Training loss: 0.7115424647927284
Epoch: 16 | Iteration number: [50/393] 12% | Training loss: 0.7080138564109802
Epoch: 16 | Iteration number: [60/393] 15% | Training loss: 0.7057980845371882
Epoch: 16 | Iteration number: [70/393] 17% | Training loss: 0.7040609674794334
Epoch: 16 | Iteration number: [80/393] 20% | Training loss: 0.7027252659201622
Epoch: 16 | Iteration number: [90/393] 22% | Training loss: 0.701863204770618
Epoch: 16 | Iteration number: [100/393] 25% | Training loss: 0.7011159265041351
Epoch: 16 | Iteration number: [110/393] 27% | Training loss: 0.7004383000460538
Epoch: 16 | Iteration number: [120/393] 30% | Training loss: 0.6997390607992808
Epoch: 16 | Iteration number: [130/393] 33% | Training loss: 0.6993395796188941
Epoch: 16 | Iteration number: [140/393] 35% | Training loss: 0.698880768248013
Epoch: 16 | Iteration number: [150/393] 38% | Training loss: 0.698544100522995
Epoch: 16 | Iteration number: [160/393] 40% | Training loss: 0.6982442907989025
Epoch: 16 | Iteration number: [170/393] 43% | Training loss: 0.6979474835536059
Epoch: 16 | Iteration number: [180/393] 45% | Training loss: 0.6977013041575749
Epoch: 16 | Iteration number: [190/393] 48% | Training loss: 0.697466274311668
Epoch: 16 | Iteration number: [200/393] 50% | Training loss: 0.6973044037818908
Epoch: 16 | Iteration number: [210/393] 53% | Training loss: 0.6971115086759839
Epoch: 16 | Iteration number: [220/393] 55% | Training loss: 0.6969705362211575
Epoch: 16 | Iteration number: [230/393] 58% | Training loss: 0.6968086307463439
Epoch: 16 | Iteration number: [240/393] 61% | Training loss: 0.6966689666112263
Epoch: 16 | Iteration number: [250/393] 63% | Training loss: 0.6965590984821319
Epoch: 16 | Iteration number: [260/393] 66% | Training loss: 0.6964490895087903
Epoch: 16 | Iteration number: [270/393] 68% | Training loss: 0.6963589273117207
Epoch: 16 | Iteration number: [280/393] 71% | Training loss: 0.6962604595082147
Epoch: 16 | Iteration number: [290/393] 73% | Training loss: 0.6961202216559443
Epoch: 16 | Iteration number: [300/393] 76% | Training loss: 0.6960448014736176
Epoch: 16 | Iteration number: [310/393] 78% | Training loss: 0.695949508682374
Epoch: 16 | Iteration number: [320/393] 81% | Training loss: 0.6959134785458445
Epoch: 16 | Iteration number: [330/393] 83% | Training loss: 0.6958774763526339
Epoch: 16 | Iteration number: [340/393] 86% | Training loss: 0.6957730098682291
Epoch: 16 | Iteration number: [350/393] 89% | Training loss: 0.6957181182929447
Epoch: 16 | Iteration number: [360/393] 91% | Training loss: 0.6956571641895506
Epoch: 16 | Iteration number: [370/393] 94% | Training loss: 0.695595047763876
Epoch: 16 | Iteration number: [380/393] 96% | Training loss: 0.6955475556223016
Epoch: 16 | Iteration number: [390/393] 99% | Training loss: 0.6954914149565574

 End of epoch: 16 | Train Loss: 0.6937111708650758 | Training Time: 66 

 End of epoch: 16 | Eval Loss: 0.6931261006666689 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/393] 2% | Training loss: 0.7629371285438538
Epoch: 17 | Iteration number: [20/393] 5% | Training loss: 0.7281266957521438
Epoch: 17 | Iteration number: [30/393] 7% | Training loss: 0.7168624003728231
Epoch: 17 | Iteration number: [40/393] 10% | Training loss: 0.7112975612282753
Epoch: 17 | Iteration number: [50/393] 12% | Training loss: 0.7077443718910217
Epoch: 17 | Iteration number: [60/393] 15% | Training loss: 0.7053400705258052
Epoch: 17 | Iteration number: [70/393] 17% | Training loss: 0.7036448870386396
Epoch: 17 | Iteration number: [80/393] 20% | Training loss: 0.7022590927779675
Epoch: 17 | Iteration number: [90/393] 22% | Training loss: 0.7013088881969451
Epoch: 17 | Iteration number: [100/393] 25% | Training loss: 0.7004371017217637
Epoch: 17 | Iteration number: [110/393] 27% | Training loss: 0.6998803501779383
Epoch: 17 | Iteration number: [120/393] 30% | Training loss: 0.6993152384956678
Epoch: 17 | Iteration number: [130/393] 33% | Training loss: 0.698737965638821
Epoch: 17 | Iteration number: [140/393] 35% | Training loss: 0.6982770732470921
Epoch: 17 | Iteration number: [150/393] 38% | Training loss: 0.6979025570551555
Epoch: 17 | Iteration number: [160/393] 40% | Training loss: 0.6975597154349089
Epoch: 17 | Iteration number: [170/393] 43% | Training loss: 0.6972756280618555
Epoch: 17 | Iteration number: [180/393] 45% | Training loss: 0.6970710678233041
Epoch: 17 | Iteration number: [190/393] 48% | Training loss: 0.6967871596938685
Epoch: 17 | Iteration number: [200/393] 50% | Training loss: 0.6966958609223366
Epoch: 17 | Iteration number: [210/393] 53% | Training loss: 0.696544375306084
Epoch: 17 | Iteration number: [220/393] 55% | Training loss: 0.6963818514888936
Epoch: 17 | Iteration number: [230/393] 58% | Training loss: 0.6962295218654301
Epoch: 17 | Iteration number: [240/393] 61% | Training loss: 0.696115742623806
Epoch: 17 | Iteration number: [250/393] 63% | Training loss: 0.6959881181716919
Epoch: 17 | Iteration number: [260/393] 66% | Training loss: 0.6958499335325681
Epoch: 17 | Iteration number: [270/393] 68% | Training loss: 0.6957527354911521
Epoch: 17 | Iteration number: [280/393] 71% | Training loss: 0.695655471937997
Epoch: 17 | Iteration number: [290/393] 73% | Training loss: 0.6955713364584692
Epoch: 17 | Iteration number: [300/393] 76% | Training loss: 0.695449650088946
Epoch: 17 | Iteration number: [310/393] 78% | Training loss: 0.6953575766855671
Epoch: 17 | Iteration number: [320/393] 81% | Training loss: 0.6952919907867908
Epoch: 17 | Iteration number: [330/393] 83% | Training loss: 0.6952413732355291
Epoch: 17 | Iteration number: [340/393] 86% | Training loss: 0.6951291867915321
Epoch: 17 | Iteration number: [350/393] 89% | Training loss: 0.6950890411649432
Epoch: 17 | Iteration number: [360/393] 91% | Training loss: 0.6950367763638496
Epoch: 17 | Iteration number: [370/393] 94% | Training loss: 0.6950154592862
Epoch: 17 | Iteration number: [380/393] 96% | Training loss: 0.6949673636963493
Epoch: 17 | Iteration number: [390/393] 99% | Training loss: 0.6949236906491794

 End of epoch: 17 | Train Loss: 0.6931453335072855 | Training Time: 66 

 End of epoch: 17 | Eval Loss: 0.6927553695075366 | Evaluating Time: 16 
Epoch: 18 | Iteration number: [10/393] 2% | Training loss: 0.7621268928050995
Epoch: 18 | Iteration number: [20/393] 5% | Training loss: 0.7278463989496231
Epoch: 18 | Iteration number: [30/393] 7% | Training loss: 0.7160724818706512
Epoch: 18 | Iteration number: [40/393] 10% | Training loss: 0.7102598741650581
Epoch: 18 | Iteration number: [50/393] 12% | Training loss: 0.7068996202945709
Epoch: 18 | Iteration number: [60/393] 15% | Training loss: 0.704504989584287
Epoch: 18 | Iteration number: [70/393] 17% | Training loss: 0.7028304977076394
Epoch: 18 | Iteration number: [80/393] 20% | Training loss: 0.7015357688069344
Epoch: 18 | Iteration number: [90/393] 22% | Training loss: 0.7006046957439847
Epoch: 18 | Iteration number: [100/393] 25% | Training loss: 0.6997711843252182
Epoch: 18 | Iteration number: [110/393] 27% | Training loss: 0.6990674175999382
Epoch: 18 | Iteration number: [120/393] 30% | Training loss: 0.6985565811395645
Epoch: 18 | Iteration number: [130/393] 33% | Training loss: 0.6980920099295103
Epoch: 18 | Iteration number: [140/393] 35% | Training loss: 0.6977400409323828
Epoch: 18 | Iteration number: [150/393] 38% | Training loss: 0.6974328863620758
Epoch: 18 | Iteration number: [160/393] 40% | Training loss: 0.697126379981637
Epoch: 18 | Iteration number: [170/393] 43% | Training loss: 0.6968940668246325
Epoch: 18 | Iteration number: [180/393] 45% | Training loss: 0.6965836306413015
Epoch: 18 | Iteration number: [190/393] 48% | Training loss: 0.696396941887705
Epoch: 18 | Iteration number: [200/393] 50% | Training loss: 0.6961957004666328
Epoch: 18 | Iteration number: [210/393] 53% | Training loss: 0.6960524022579193
Epoch: 18 | Iteration number: [220/393] 55% | Training loss: 0.6959397540851073
Epoch: 18 | Iteration number: [230/393] 58% | Training loss: 0.695761724917785
Epoch: 18 | Iteration number: [240/393] 61% | Training loss: 0.6956618780891101
Epoch: 18 | Iteration number: [250/393] 63% | Training loss: 0.695511244058609
Epoch: 18 | Iteration number: [260/393] 66% | Training loss: 0.6953872343668571
Epoch: 18 | Iteration number: [270/393] 68% | Training loss: 0.695270041624705
Epoch: 18 | Iteration number: [280/393] 71% | Training loss: 0.6952002936175892
Epoch: 18 | Iteration number: [290/393] 73% | Training loss: 0.6950912759221833
Epoch: 18 | Iteration number: [300/393] 76% | Training loss: 0.6949855820337931
Epoch: 18 | Iteration number: [310/393] 78% | Training loss: 0.6949380776574535
Epoch: 18 | Iteration number: [320/393] 81% | Training loss: 0.6948622876778245
Epoch: 18 | Iteration number: [330/393] 83% | Training loss: 0.6948066805348252
Epoch: 18 | Iteration number: [340/393] 86% | Training loss: 0.6947371177813586
Epoch: 18 | Iteration number: [350/393] 89% | Training loss: 0.6946891748905182
Epoch: 18 | Iteration number: [360/393] 91% | Training loss: 0.694620613919364
Epoch: 18 | Iteration number: [370/393] 94% | Training loss: 0.6945720025011011
Epoch: 18 | Iteration number: [380/393] 96% | Training loss: 0.6945327074904191
Epoch: 18 | Iteration number: [390/393] 99% | Training loss: 0.6944860877134861

 End of epoch: 18 | Train Loss: 0.69271392479501 | Training Time: 66 

 End of epoch: 18 | Eval Loss: 0.6921836028293687 | Evaluating Time: 16 
Epoch: 19 | Iteration number: [10/393] 2% | Training loss: 0.7624184548854828
Epoch: 19 | Iteration number: [20/393] 5% | Training loss: 0.7281997561454773
Epoch: 19 | Iteration number: [30/393] 7% | Training loss: 0.7162473777929942
Epoch: 19 | Iteration number: [40/393] 10% | Training loss: 0.7101036816835403
Epoch: 19 | Iteration number: [50/393] 12% | Training loss: 0.7065178751945496
Epoch: 19 | Iteration number: [60/393] 15% | Training loss: 0.7043385565280914
Epoch: 19 | Iteration number: [70/393] 17% | Training loss: 0.7026001002107348
Epoch: 19 | Iteration number: [80/393] 20% | Training loss: 0.7013359397649765
Epoch: 19 | Iteration number: [90/393] 22% | Training loss: 0.7003429717487759
Epoch: 19 | Iteration number: [100/393] 25% | Training loss: 0.6995689809322357
Epoch: 19 | Iteration number: [110/393] 27% | Training loss: 0.6989225132898851
Epoch: 19 | Iteration number: [120/393] 30% | Training loss: 0.6983894109725952
Epoch: 19 | Iteration number: [130/393] 33% | Training loss: 0.6979387434629294
Epoch: 19 | Iteration number: [140/393] 35% | Training loss: 0.6975482740572521
Epoch: 19 | Iteration number: [150/393] 38% | Training loss: 0.6971569669246673
Epoch: 19 | Iteration number: [160/393] 40% | Training loss: 0.6968423407524824
Epoch: 19 | Iteration number: [170/393] 43% | Training loss: 0.6966225624084472
Epoch: 19 | Iteration number: [180/393] 45% | Training loss: 0.6964015344778697
Epoch: 19 | Iteration number: [190/393] 48% | Training loss: 0.6961837294854616
Epoch: 19 | Iteration number: [200/393] 50% | Training loss: 0.6959664541482925
Epoch: 19 | Iteration number: [210/393] 53% | Training loss: 0.6957452700251625
Epoch: 19 | Iteration number: [220/393] 55% | Training loss: 0.6956161247058348
Epoch: 19 | Iteration number: [230/393] 58% | Training loss: 0.6954621265763822
Epoch: 19 | Iteration number: [240/393] 61% | Training loss: 0.6953084642688433
Epoch: 19 | Iteration number: [250/393] 63% | Training loss: 0.6951928422451019
Epoch: 19 | Iteration number: [260/393] 66% | Training loss: 0.6950588395962348
Epoch: 19 | Iteration number: [270/393] 68% | Training loss: 0.6949904680252075
Epoch: 19 | Iteration number: [280/393] 71% | Training loss: 0.6948571675590106
Epoch: 19 | Iteration number: [290/393] 73% | Training loss: 0.6947988980802996
Epoch: 19 | Iteration number: [300/393] 76% | Training loss: 0.6947110623121262
Epoch: 19 | Iteration number: [310/393] 78% | Training loss: 0.6946536339098407
Epoch: 19 | Iteration number: [320/393] 81% | Training loss: 0.6945510767400265
Epoch: 19 | Iteration number: [330/393] 83% | Training loss: 0.694461646043893
Epoch: 19 | Iteration number: [340/393] 86% | Training loss: 0.6944104001802557
Epoch: 19 | Iteration number: [350/393] 89% | Training loss: 0.6943556444985526
Epoch: 19 | Iteration number: [360/393] 91% | Training loss: 0.6942923939890332
Epoch: 19 | Iteration number: [370/393] 94% | Training loss: 0.6942368921395895
Epoch: 19 | Iteration number: [380/393] 96% | Training loss: 0.6941996655966106
Epoch: 19 | Iteration number: [390/393] 99% | Training loss: 0.6941503723462422

 End of epoch: 19 | Train Loss: 0.6923687949435402 | Training Time: 66 

 End of epoch: 19 | Eval Loss: 0.6920329624292801 | Evaluating Time: 16 
Epoch: 20 | Iteration number: [10/393] 2% | Training loss: 0.7619782149791717
Epoch: 20 | Iteration number: [20/393] 5% | Training loss: 0.726951053738594
Epoch: 20 | Iteration number: [30/393] 7% | Training loss: 0.714990782737732
Epoch: 20 | Iteration number: [40/393] 10% | Training loss: 0.709375123679638
Epoch: 20 | Iteration number: [50/393] 12% | Training loss: 0.7062146377563476
Epoch: 20 | Iteration number: [60/393] 15% | Training loss: 0.7038378794987996
Epoch: 20 | Iteration number: [70/393] 17% | Training loss: 0.7022573419979641
Epoch: 20 | Iteration number: [80/393] 20% | Training loss: 0.7010405845940113
Epoch: 20 | Iteration number: [90/393] 22% | Training loss: 0.7000651299953461
Epoch: 20 | Iteration number: [100/393] 25% | Training loss: 0.699217078089714
Epoch: 20 | Iteration number: [110/393] 27% | Training loss: 0.698475819826126
Epoch: 20 | Iteration number: [120/393] 30% | Training loss: 0.6978978544473649
Epoch: 20 | Iteration number: [130/393] 33% | Training loss: 0.6975059270858764
Epoch: 20 | Iteration number: [140/393] 35% | Training loss: 0.6970655185835702
Epoch: 20 | Iteration number: [150/393] 38% | Training loss: 0.6966972537835439
Epoch: 20 | Iteration number: [160/393] 40% | Training loss: 0.6964194547384978
Epoch: 20 | Iteration number: [170/393] 43% | Training loss: 0.696196153234033
Epoch: 20 | Iteration number: [180/393] 45% | Training loss: 0.695956931842698
Epoch: 20 | Iteration number: [190/393] 48% | Training loss: 0.6957339496988999
Epoch: 20 | Iteration number: [200/393] 50% | Training loss: 0.6955454817414284
Epoch: 20 | Iteration number: [210/393] 53% | Training loss: 0.695329631510235
Epoch: 20 | Iteration number: [220/393] 55% | Training loss: 0.6952447208491239
Epoch: 20 | Iteration number: [230/393] 58% | Training loss: 0.6951915873133618
Epoch: 20 | Iteration number: [240/393] 61% | Training loss: 0.6951437475780646
Epoch: 20 | Iteration number: [250/393] 63% | Training loss: 0.6950577754974365
Epoch: 20 | Iteration number: [260/393] 66% | Training loss: 0.6949528687275373
Epoch: 20 | Iteration number: [270/393] 68% | Training loss: 0.6948784814940558
Epoch: 20 | Iteration number: [280/393] 71% | Training loss: 0.6947984831673758
Epoch: 20 | Iteration number: [290/393] 73% | Training loss: 0.6947254363832802
Epoch: 20 | Iteration number: [300/393] 76% | Training loss: 0.6946467761198679
Epoch: 20 | Iteration number: [310/393] 78% | Training loss: 0.6945652944426383
Epoch: 20 | Iteration number: [320/393] 81% | Training loss: 0.6944884467869997
Epoch: 20 | Iteration number: [330/393] 83% | Training loss: 0.694408016313206
Epoch: 20 | Iteration number: [340/393] 86% | Training loss: 0.6943624789223951
Epoch: 20 | Iteration number: [350/393] 89% | Training loss: 0.6942604756355286
Epoch: 20 | Iteration number: [360/393] 91% | Training loss: 0.6942241473330392
Epoch: 20 | Iteration number: [370/393] 94% | Training loss: 0.6941571052009995
Epoch: 20 | Iteration number: [380/393] 96% | Training loss: 0.6941115559715973
Epoch: 20 | Iteration number: [390/393] 99% | Training loss: 0.6940634622023656

 End of epoch: 20 | Train Loss: 0.6923004408525754 | Training Time: 66 

 End of epoch: 20 | Eval Loss: 0.6917578979414336 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/393] 2% | Training loss: 0.7606528639793396
Epoch: 21 | Iteration number: [20/393] 5% | Training loss: 0.7260089367628098
Epoch: 21 | Iteration number: [30/393] 7% | Training loss: 0.7146706640720367
Epoch: 21 | Iteration number: [40/393] 10% | Training loss: 0.7090895354747773
Epoch: 21 | Iteration number: [50/393] 12% | Training loss: 0.7055157363414765
Epoch: 21 | Iteration number: [60/393] 15% | Training loss: 0.7032584428787232
Epoch: 21 | Iteration number: [70/393] 17% | Training loss: 0.7017054838793618
Epoch: 21 | Iteration number: [80/393] 20% | Training loss: 0.7003260664641857
Epoch: 21 | Iteration number: [90/393] 22% | Training loss: 0.6992789063188765
Epoch: 21 | Iteration number: [100/393] 25% | Training loss: 0.6985227042436599
Epoch: 21 | Iteration number: [110/393] 27% | Training loss: 0.6979386324232275
Epoch: 21 | Iteration number: [120/393] 30% | Training loss: 0.6973873868584632
Epoch: 21 | Iteration number: [130/393] 33% | Training loss: 0.6969360851324522
Epoch: 21 | Iteration number: [140/393] 35% | Training loss: 0.6965383866003582
Epoch: 21 | Iteration number: [150/393] 38% | Training loss: 0.6962076508998871
Epoch: 21 | Iteration number: [160/393] 40% | Training loss: 0.6959771763533353
Epoch: 21 | Iteration number: [170/393] 43% | Training loss: 0.6957261478199678
Epoch: 21 | Iteration number: [180/393] 45% | Training loss: 0.6955296695232391
Epoch: 21 | Iteration number: [190/393] 48% | Training loss: 0.6953186198284752
Epoch: 21 | Iteration number: [200/393] 50% | Training loss: 0.6951228028535843
Epoch: 21 | Iteration number: [210/393] 53% | Training loss: 0.6949739649182274
Epoch: 21 | Iteration number: [220/393] 55% | Training loss: 0.6948252057487314
Epoch: 21 | Iteration number: [230/393] 58% | Training loss: 0.6947241912717405
Epoch: 21 | Iteration number: [240/393] 61% | Training loss: 0.6946041723092397
Epoch: 21 | Iteration number: [250/393] 63% | Training loss: 0.6944505240917206
Epoch: 21 | Iteration number: [260/393] 66% | Training loss: 0.6943717656227258
Epoch: 21 | Iteration number: [270/393] 68% | Training loss: 0.6942793696014969
Epoch: 21 | Iteration number: [280/393] 71% | Training loss: 0.6942095509597234
Epoch: 21 | Iteration number: [290/393] 73% | Training loss: 0.6941249904961422
Epoch: 21 | Iteration number: [300/393] 76% | Training loss: 0.6940528889497121
Epoch: 21 | Iteration number: [310/393] 78% | Training loss: 0.6940148492013255
Epoch: 21 | Iteration number: [320/393] 81% | Training loss: 0.6939480433240532
Epoch: 21 | Iteration number: [330/393] 83% | Training loss: 0.6939102933262333
Epoch: 21 | Iteration number: [340/393] 86% | Training loss: 0.6938339673420962
Epoch: 21 | Iteration number: [350/393] 89% | Training loss: 0.6937547704151699
Epoch: 21 | Iteration number: [360/393] 91% | Training loss: 0.6937070593237877
Epoch: 21 | Iteration number: [370/393] 94% | Training loss: 0.6936710120858373
Epoch: 21 | Iteration number: [380/393] 96% | Training loss: 0.6936204336191478
Epoch: 21 | Iteration number: [390/393] 99% | Training loss: 0.6935760235175108

 End of epoch: 21 | Train Loss: 0.6918024084040226 | Training Time: 66 

 End of epoch: 21 | Eval Loss: 0.6914332144114436 | Evaluating Time: 17 
Epoch: 22 | Iteration number: [10/393] 2% | Training loss: 0.7605361998081207
Epoch: 22 | Iteration number: [20/393] 5% | Training loss: 0.7265961527824402
Epoch: 22 | Iteration number: [30/393] 7% | Training loss: 0.7151031454404195
Epoch: 22 | Iteration number: [40/393] 10% | Training loss: 0.7093020901083946
Epoch: 22 | Iteration number: [50/393] 12% | Training loss: 0.7057629144191742
Epoch: 22 | Iteration number: [60/393] 15% | Training loss: 0.7036064028739929
Epoch: 22 | Iteration number: [70/393] 17% | Training loss: 0.7018574697630746
Epoch: 22 | Iteration number: [80/393] 20% | Training loss: 0.7006923250854016
Epoch: 22 | Iteration number: [90/393] 22% | Training loss: 0.6996624072392782
Epoch: 22 | Iteration number: [100/393] 25% | Training loss: 0.698895211815834
Epoch: 22 | Iteration number: [110/393] 27% | Training loss: 0.6981808597391302
Epoch: 22 | Iteration number: [120/393] 30% | Training loss: 0.6976327260335287
Epoch: 22 | Iteration number: [130/393] 33% | Training loss: 0.6971724881575658
Epoch: 22 | Iteration number: [140/393] 35% | Training loss: 0.6968095749616623
Epoch: 22 | Iteration number: [150/393] 38% | Training loss: 0.6964540322621663
Epoch: 22 | Iteration number: [160/393] 40% | Training loss: 0.6961386498063803
Epoch: 22 | Iteration number: [170/393] 43% | Training loss: 0.6958432558704825
Epoch: 22 | Iteration number: [180/393] 45% | Training loss: 0.6956164247459835
Epoch: 22 | Iteration number: [190/393] 48% | Training loss: 0.6954293618076726
Epoch: 22 | Iteration number: [200/393] 50% | Training loss: 0.6952056089043617
Epoch: 22 | Iteration number: [210/393] 53% | Training loss: 0.694997968844005
Epoch: 22 | Iteration number: [220/393] 55% | Training loss: 0.6948279174891385
Epoch: 22 | Iteration number: [230/393] 58% | Training loss: 0.6946441824021546
Epoch: 22 | Iteration number: [240/393] 61% | Training loss: 0.6945320283373196
Epoch: 22 | Iteration number: [250/393] 63% | Training loss: 0.694431559085846
Epoch: 22 | Iteration number: [260/393] 66% | Training loss: 0.6943195890921813
Epoch: 22 | Iteration number: [270/393] 68% | Training loss: 0.6941956762914304
Epoch: 22 | Iteration number: [280/393] 71% | Training loss: 0.6941095309598105
Epoch: 22 | Iteration number: [290/393] 73% | Training loss: 0.6939958212704495
Epoch: 22 | Iteration number: [300/393] 76% | Training loss: 0.6939304488897323
Epoch: 22 | Iteration number: [310/393] 78% | Training loss: 0.6938677474375694
Epoch: 22 | Iteration number: [320/393] 81% | Training loss: 0.6938179679214954
Epoch: 22 | Iteration number: [330/393] 83% | Training loss: 0.6937423848744595
Epoch: 22 | Iteration number: [340/393] 86% | Training loss: 0.6936856611686595
Epoch: 22 | Iteration number: [350/393] 89% | Training loss: 0.6936475675446646
Epoch: 22 | Iteration number: [360/393] 91% | Training loss: 0.6935726801554362
Epoch: 22 | Iteration number: [370/393] 94% | Training loss: 0.6935365383689468
Epoch: 22 | Iteration number: [380/393] 96% | Training loss: 0.6934662070713545
Epoch: 22 | Iteration number: [390/393] 99% | Training loss: 0.6934247833031875

 End of epoch: 22 | Train Loss: 0.6916521036897907 | Training Time: 66 

 End of epoch: 22 | Eval Loss: 0.6912765308302276 | Evaluating Time: 16 
Epoch: 23 | Iteration number: [10/393] 2% | Training loss: 0.7606480777263641
Epoch: 23 | Iteration number: [20/393] 5% | Training loss: 0.7258216679096222
Epoch: 23 | Iteration number: [30/393] 7% | Training loss: 0.7145048558712006
Epoch: 23 | Iteration number: [40/393] 10% | Training loss: 0.7087392345070839
Epoch: 23 | Iteration number: [50/393] 12% | Training loss: 0.7053169417381286
Epoch: 23 | Iteration number: [60/393] 15% | Training loss: 0.7028791934251786
Epoch: 23 | Iteration number: [70/393] 17% | Training loss: 0.7012722177164895
Epoch: 23 | Iteration number: [80/393] 20% | Training loss: 0.700039941072464
Epoch: 23 | Iteration number: [90/393] 22% | Training loss: 0.6991245004865858
Epoch: 23 | Iteration number: [100/393] 25% | Training loss: 0.6983366328477859
Epoch: 23 | Iteration number: [110/393] 27% | Training loss: 0.6977421386675401
Epoch: 23 | Iteration number: [120/393] 30% | Training loss: 0.6973441019654274
Epoch: 23 | Iteration number: [130/393] 33% | Training loss: 0.6968708638961498
Epoch: 23 | Iteration number: [140/393] 35% | Training loss: 0.6964403620788029
Epoch: 23 | Iteration number: [150/393] 38% | Training loss: 0.696118191878001
Epoch: 23 | Iteration number: [160/393] 40% | Training loss: 0.6958006765693426
Epoch: 23 | Iteration number: [170/393] 43% | Training loss: 0.6955065608024598
Epoch: 23 | Iteration number: [180/393] 45% | Training loss: 0.6953351438045502
Epoch: 23 | Iteration number: [190/393] 48% | Training loss: 0.695171239187843
Epoch: 23 | Iteration number: [200/393] 50% | Training loss: 0.6950000470876694
Epoch: 23 | Iteration number: [210/393] 53% | Training loss: 0.6948574531646002
Epoch: 23 | Iteration number: [220/393] 55% | Training loss: 0.694719364697283
Epoch: 23 | Iteration number: [230/393] 58% | Training loss: 0.694633212296859
Epoch: 23 | Iteration number: [240/393] 61% | Training loss: 0.6944815491636595
Epoch: 23 | Iteration number: [250/393] 63% | Training loss: 0.6943363738059998
Epoch: 23 | Iteration number: [260/393] 66% | Training loss: 0.6942152605606959
Epoch: 23 | Iteration number: [270/393] 68% | Training loss: 0.6941004417560719
Epoch: 23 | Iteration number: [280/393] 71% | Training loss: 0.6939849438411849
Epoch: 23 | Iteration number: [290/393] 73% | Training loss: 0.6938979029655457
Epoch: 23 | Iteration number: [300/393] 76% | Training loss: 0.6937454229593277
Epoch: 23 | Iteration number: [310/393] 78% | Training loss: 0.6937006148599809
Epoch: 23 | Iteration number: [320/393] 81% | Training loss: 0.6936351809650659
Epoch: 23 | Iteration number: [330/393] 83% | Training loss: 0.6935448904832204
Epoch: 23 | Iteration number: [340/393] 86% | Training loss: 0.6934877395629883
Epoch: 23 | Iteration number: [350/393] 89% | Training loss: 0.6934343908514295
Epoch: 23 | Iteration number: [360/393] 91% | Training loss: 0.6933901785148515
Epoch: 23 | Iteration number: [370/393] 94% | Training loss: 0.6933305833790754
Epoch: 23 | Iteration number: [380/393] 96% | Training loss: 0.6932904797165017
Epoch: 23 | Iteration number: [390/393] 99% | Training loss: 0.6932609059871772

 End of epoch: 23 | Train Loss: 0.6914763546171989 | Training Time: 66 

 End of epoch: 23 | Eval Loss: 0.6912153533526829 | Evaluating Time: 16 
Epoch: 24 | Iteration number: [10/393] 2% | Training loss: 0.7595874190330505
Epoch: 24 | Iteration number: [20/393] 5% | Training loss: 0.7256318092346191
Epoch: 24 | Iteration number: [30/393] 7% | Training loss: 0.7140913248062134
Epoch: 24 | Iteration number: [40/393] 10% | Training loss: 0.7085568502545356
Epoch: 24 | Iteration number: [50/393] 12% | Training loss: 0.7050453162193299
Epoch: 24 | Iteration number: [60/393] 15% | Training loss: 0.7028451502323151
Epoch: 24 | Iteration number: [70/393] 17% | Training loss: 0.7011965428079877
Epoch: 24 | Iteration number: [80/393] 20% | Training loss: 0.6999104909598828
Epoch: 24 | Iteration number: [90/393] 22% | Training loss: 0.6989579816659292
Epoch: 24 | Iteration number: [100/393] 25% | Training loss: 0.6982052063941956
Epoch: 24 | Iteration number: [110/393] 27% | Training loss: 0.6975628744472157
Epoch: 24 | Iteration number: [120/393] 30% | Training loss: 0.6970082839330037
Epoch: 24 | Iteration number: [130/393] 33% | Training loss: 0.6965233179239126
Epoch: 24 | Iteration number: [140/393] 35% | Training loss: 0.6961239763668605
Epoch: 24 | Iteration number: [150/393] 38% | Training loss: 0.6957948418458303
Epoch: 24 | Iteration number: [160/393] 40% | Training loss: 0.6955228321254253
Epoch: 24 | Iteration number: [170/393] 43% | Training loss: 0.6953044922912822
Epoch: 24 | Iteration number: [180/393] 45% | Training loss: 0.6950713743766149
Epoch: 24 | Iteration number: [190/393] 48% | Training loss: 0.6948801815509796
Epoch: 24 | Iteration number: [200/393] 50% | Training loss: 0.6946848425269126
Epoch: 24 | Iteration number: [210/393] 53% | Training loss: 0.6945631072634743
Epoch: 24 | Iteration number: [220/393] 55% | Training loss: 0.6943836038762873
Epoch: 24 | Iteration number: [230/393] 58% | Training loss: 0.6942493565704512
Epoch: 24 | Iteration number: [240/393] 61% | Training loss: 0.6940817731122176
Epoch: 24 | Iteration number: [250/393] 63% | Training loss: 0.6939852931499482
Epoch: 24 | Iteration number: [260/393] 66% | Training loss: 0.6938344265405948
Epoch: 24 | Iteration number: [270/393] 68% | Training loss: 0.6937623182932536
Epoch: 24 | Iteration number: [280/393] 71% | Training loss: 0.6937021898371832
Epoch: 24 | Iteration number: [290/393] 73% | Training loss: 0.6935954108320433
Epoch: 24 | Iteration number: [300/393] 76% | Training loss: 0.6934890860319137
Epoch: 24 | Iteration number: [310/393] 78% | Training loss: 0.6934503255351897
Epoch: 24 | Iteration number: [320/393] 81% | Training loss: 0.6933774206787348
Epoch: 24 | Iteration number: [330/393] 83% | Training loss: 0.6933536661393714
Epoch: 24 | Iteration number: [340/393] 86% | Training loss: 0.6932810211882872
Epoch: 24 | Iteration number: [350/393] 89% | Training loss: 0.6931904653140477
Epoch: 24 | Iteration number: [360/393] 91% | Training loss: 0.6931493421395619
Epoch: 24 | Iteration number: [370/393] 94% | Training loss: 0.6930858613671483
Epoch: 24 | Iteration number: [380/393] 96% | Training loss: 0.6930653545417284
Epoch: 24 | Iteration number: [390/393] 99% | Training loss: 0.6930250921310522

 End of epoch: 24 | Train Loss: 0.6912674594471473 | Training Time: 66 

 End of epoch: 24 | Eval Loss: 0.6911213349322883 | Evaluating Time: 17 
Epoch: 25 | Iteration number: [10/393] 2% | Training loss: 0.76041060090065
Epoch: 25 | Iteration number: [20/393] 5% | Training loss: 0.7260053336620331
Epoch: 25 | Iteration number: [30/393] 7% | Training loss: 0.7145992318789164
Epoch: 25 | Iteration number: [40/393] 10% | Training loss: 0.7086823403835296
Epoch: 25 | Iteration number: [50/393] 12% | Training loss: 0.7051586985588074
Epoch: 25 | Iteration number: [60/393] 15% | Training loss: 0.702794881661733
Epoch: 25 | Iteration number: [70/393] 17% | Training loss: 0.7011883403573718
Epoch: 25 | Iteration number: [80/393] 20% | Training loss: 0.6999458044767379
Epoch: 25 | Iteration number: [90/393] 22% | Training loss: 0.6988818546136221
Epoch: 25 | Iteration number: [100/393] 25% | Training loss: 0.6981531023979187
Epoch: 25 | Iteration number: [110/393] 27% | Training loss: 0.6974901540712877
Epoch: 25 | Iteration number: [120/393] 30% | Training loss: 0.6969327827294668
Epoch: 25 | Iteration number: [130/393] 33% | Training loss: 0.6965163840697361
Epoch: 25 | Iteration number: [140/393] 35% | Training loss: 0.6960641997201102
Epoch: 25 | Iteration number: [150/393] 38% | Training loss: 0.6957397385438283
Epoch: 25 | Iteration number: [160/393] 40% | Training loss: 0.695480753108859
Epoch: 25 | Iteration number: [170/393] 43% | Training loss: 0.6952489695128272
Epoch: 25 | Iteration number: [180/393] 45% | Training loss: 0.6950372364785936
Epoch: 25 | Iteration number: [190/393] 48% | Training loss: 0.694823282015951
Epoch: 25 | Iteration number: [200/393] 50% | Training loss: 0.6946482387185097
Epoch: 25 | Iteration number: [210/393] 53% | Training loss: 0.6944632078920092
Epoch: 25 | Iteration number: [220/393] 55% | Training loss: 0.6942917444489219
Epoch: 25 | Iteration number: [230/393] 58% | Training loss: 0.6941776900187783
Epoch: 25 | Iteration number: [240/393] 61% | Training loss: 0.694057739029328
Epoch: 25 | Iteration number: [250/393] 63% | Training loss: 0.6939740676879883
Epoch: 25 | Iteration number: [260/393] 66% | Training loss: 0.6938894319992799
Epoch: 25 | Iteration number: [270/393] 68% | Training loss: 0.6937919879401172
Epoch: 25 | Iteration number: [280/393] 71% | Training loss: 0.6937095441988537
Epoch: 25 | Iteration number: [290/393] 73% | Training loss: 0.6936418048266707
Epoch: 25 | Iteration number: [300/393] 76% | Training loss: 0.6935315036773682
Epoch: 25 | Iteration number: [310/393] 78% | Training loss: 0.6934390412222955
Epoch: 25 | Iteration number: [320/393] 81% | Training loss: 0.6933511013165117
Epoch: 25 | Iteration number: [330/393] 83% | Training loss: 0.6933072270769062
Epoch: 25 | Iteration number: [340/393] 86% | Training loss: 0.693252356262768
Epoch: 25 | Iteration number: [350/393] 89% | Training loss: 0.6931980812549591
Epoch: 25 | Iteration number: [360/393] 91% | Training loss: 0.6931723399294747
Epoch: 25 | Iteration number: [370/393] 94% | Training loss: 0.6931452293653746
Epoch: 25 | Iteration number: [380/393] 96% | Training loss: 0.6930920947539179
Epoch: 25 | Iteration number: [390/393] 99% | Training loss: 0.6930621857826527

 End of epoch: 25 | Train Loss: 0.6912764969066203 | Training Time: 66 

 End of epoch: 25 | Eval Loss: 0.6911898973036785 | Evaluating Time: 17 
Epoch: 26 | Iteration number: [10/393] 2% | Training loss: 0.7617126882076264
Epoch: 26 | Iteration number: [20/393] 5% | Training loss: 0.726738178730011
Epoch: 26 | Iteration number: [30/393] 7% | Training loss: 0.7146269877751669
Epoch: 26 | Iteration number: [40/393] 10% | Training loss: 0.7083884939551354
Epoch: 26 | Iteration number: [50/393] 12% | Training loss: 0.7049314963817597
Epoch: 26 | Iteration number: [60/393] 15% | Training loss: 0.7026027460892995
Epoch: 26 | Iteration number: [70/393] 17% | Training loss: 0.7010887827192034
Epoch: 26 | Iteration number: [80/393] 20% | Training loss: 0.6998730733990669
Epoch: 26 | Iteration number: [90/393] 22% | Training loss: 0.6989168789651659
Epoch: 26 | Iteration number: [100/393] 25% | Training loss: 0.6981862223148346
Epoch: 26 | Iteration number: [110/393] 27% | Training loss: 0.6976048881357366
Epoch: 26 | Iteration number: [120/393] 30% | Training loss: 0.6970554053783417
Epoch: 26 | Iteration number: [130/393] 33% | Training loss: 0.6965668724133418
Epoch: 26 | Iteration number: [140/393] 35% | Training loss: 0.6962457903793879
Epoch: 26 | Iteration number: [150/393] 38% | Training loss: 0.6959206187725067
Epoch: 26 | Iteration number: [160/393] 40% | Training loss: 0.6956197887659072
Epoch: 26 | Iteration number: [170/393] 43% | Training loss: 0.695349831090254
Epoch: 26 | Iteration number: [180/393] 45% | Training loss: 0.695104420516226
Epoch: 26 | Iteration number: [190/393] 48% | Training loss: 0.6948836590114392
Epoch: 26 | Iteration number: [200/393] 50% | Training loss: 0.6946924033761025
Epoch: 26 | Iteration number: [210/393] 53% | Training loss: 0.6945015030247824
Epoch: 26 | Iteration number: [220/393] 55% | Training loss: 0.6943233557722785
Epoch: 26 | Iteration number: [230/393] 58% | Training loss: 0.6941713372002477
Epoch: 26 | Iteration number: [240/393] 61% | Training loss: 0.6940105756123861
Epoch: 26 | Iteration number: [250/393] 63% | Training loss: 0.6938684799671173
Epoch: 26 | Iteration number: [260/393] 66% | Training loss: 0.6937482109436622
Epoch: 26 | Iteration number: [270/393] 68% | Training loss: 0.6937072985702091
Epoch: 26 | Iteration number: [280/393] 71% | Training loss: 0.6936308386070388
Epoch: 26 | Iteration number: [290/393] 73% | Training loss: 0.6935608430155392
Epoch: 26 | Iteration number: [300/393] 76% | Training loss: 0.6934984014431635
Epoch: 26 | Iteration number: [310/393] 78% | Training loss: 0.693443396206825
Epoch: 26 | Iteration number: [320/393] 81% | Training loss: 0.6933860333636404
Epoch: 26 | Iteration number: [330/393] 83% | Training loss: 0.6932739378827991
Epoch: 26 | Iteration number: [340/393] 86% | Training loss: 0.6932392667321597
Epoch: 26 | Iteration number: [350/393] 89% | Training loss: 0.6931951269081661
Epoch: 26 | Iteration number: [360/393] 91% | Training loss: 0.693127188914352
Epoch: 26 | Iteration number: [370/393] 94% | Training loss: 0.6930749028115659
Epoch: 26 | Iteration number: [380/393] 96% | Training loss: 0.6930137397427308
Epoch: 26 | Iteration number: [390/393] 99% | Training loss: 0.6929342870528882

 End of epoch: 26 | Train Loss: 0.6911650629140645 | Training Time: 66 

 End of epoch: 26 | Eval Loss: 0.6909420916012355 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/393] 2% | Training loss: 0.7605378091335296
Epoch: 27 | Iteration number: [20/393] 5% | Training loss: 0.7260055035352707
Epoch: 27 | Iteration number: [30/393] 7% | Training loss: 0.714526621500651
Epoch: 27 | Iteration number: [40/393] 10% | Training loss: 0.7086524143815041
Epoch: 27 | Iteration number: [50/393] 12% | Training loss: 0.7050675511360168
Epoch: 27 | Iteration number: [60/393] 15% | Training loss: 0.7027362724145253
Epoch: 27 | Iteration number: [70/393] 17% | Training loss: 0.7011670299938747
Epoch: 27 | Iteration number: [80/393] 20% | Training loss: 0.6999699853360652
Epoch: 27 | Iteration number: [90/393] 22% | Training loss: 0.6990240355332692
Epoch: 27 | Iteration number: [100/393] 25% | Training loss: 0.6981724023818969
Epoch: 27 | Iteration number: [110/393] 27% | Training loss: 0.6975143708965995
Epoch: 27 | Iteration number: [120/393] 30% | Training loss: 0.6969427282611529
Epoch: 27 | Iteration number: [130/393] 33% | Training loss: 0.6964674770832062
Epoch: 27 | Iteration number: [140/393] 35% | Training loss: 0.6961207896471023
Epoch: 27 | Iteration number: [150/393] 38% | Training loss: 0.695793795188268
Epoch: 27 | Iteration number: [160/393] 40% | Training loss: 0.6954491604119539
Epoch: 27 | Iteration number: [170/393] 43% | Training loss: 0.6952141200794894
Epoch: 27 | Iteration number: [180/393] 45% | Training loss: 0.6949206511179606
Epoch: 27 | Iteration number: [190/393] 48% | Training loss: 0.6947103654083453
Epoch: 27 | Iteration number: [200/393] 50% | Training loss: 0.6945368549227715
Epoch: 27 | Iteration number: [210/393] 53% | Training loss: 0.6944132589158558
Epoch: 27 | Iteration number: [220/393] 55% | Training loss: 0.694267467748035
Epoch: 27 | Iteration number: [230/393] 58% | Training loss: 0.6940732341745626
Epoch: 27 | Iteration number: [240/393] 61% | Training loss: 0.6939832697312037
Epoch: 27 | Iteration number: [250/393] 63% | Training loss: 0.6938223006725311
Epoch: 27 | Iteration number: [260/393] 66% | Training loss: 0.6936892209144739
Epoch: 27 | Iteration number: [270/393] 68% | Training loss: 0.6935610839614161
Epoch: 27 | Iteration number: [280/393] 71% | Training loss: 0.693445069875036
Epoch: 27 | Iteration number: [290/393] 73% | Training loss: 0.6933657327602649
Epoch: 27 | Iteration number: [300/393] 76% | Training loss: 0.6932720629374186
Epoch: 27 | Iteration number: [310/393] 78% | Training loss: 0.6932154255528604
Epoch: 27 | Iteration number: [320/393] 81% | Training loss: 0.6931793199852109
Epoch: 27 | Iteration number: [330/393] 83% | Training loss: 0.6931165657260201
Epoch: 27 | Iteration number: [340/393] 86% | Training loss: 0.6930900812149048
Epoch: 27 | Iteration number: [350/393] 89% | Training loss: 0.6930198572363172
Epoch: 27 | Iteration number: [360/393] 91% | Training loss: 0.6929853662848473
Epoch: 27 | Iteration number: [370/393] 94% | Training loss: 0.6929293092843648
Epoch: 27 | Iteration number: [380/393] 96% | Training loss: 0.6928854501561115
Epoch: 27 | Iteration number: [390/393] 99% | Training loss: 0.6928619507031563

 End of epoch: 27 | Train Loss: 0.6910850511859088 | Training Time: 66 

 End of epoch: 27 | Eval Loss: 0.6907131671905518 | Evaluating Time: 16 
Epoch: 28 | Iteration number: [10/393] 2% | Training loss: 0.7614133715629577
Epoch: 28 | Iteration number: [20/393] 5% | Training loss: 0.7261391997337341
Epoch: 28 | Iteration number: [30/393] 7% | Training loss: 0.7146050155162811
Epoch: 28 | Iteration number: [40/393] 10% | Training loss: 0.7084634706377984
Epoch: 28 | Iteration number: [50/393] 12% | Training loss: 0.7049351453781127
Epoch: 28 | Iteration number: [60/393] 15% | Training loss: 0.702754212419192
Epoch: 28 | Iteration number: [70/393] 17% | Training loss: 0.7009989959853036
Epoch: 28 | Iteration number: [80/393] 20% | Training loss: 0.6997364304959774
Epoch: 28 | Iteration number: [90/393] 22% | Training loss: 0.6987322363588545
Epoch: 28 | Iteration number: [100/393] 25% | Training loss: 0.698065642118454
Epoch: 28 | Iteration number: [110/393] 27% | Training loss: 0.697326969016682
Epoch: 28 | Iteration number: [120/393] 30% | Training loss: 0.6967696865399678
Epoch: 28 | Iteration number: [130/393] 33% | Training loss: 0.6961418367349185
Epoch: 28 | Iteration number: [140/393] 35% | Training loss: 0.6958417334726879
Epoch: 28 | Iteration number: [150/393] 38% | Training loss: 0.6954769587516785
Epoch: 28 | Iteration number: [160/393] 40% | Training loss: 0.6951948776841164
Epoch: 28 | Iteration number: [170/393] 43% | Training loss: 0.6949036272133098
Epoch: 28 | Iteration number: [180/393] 45% | Training loss: 0.6946969578663508
Epoch: 28 | Iteration number: [190/393] 48% | Training loss: 0.69453227990552
Epoch: 28 | Iteration number: [200/393] 50% | Training loss: 0.694410590827465
Epoch: 28 | Iteration number: [210/393] 53% | Training loss: 0.6942821315356663
Epoch: 28 | Iteration number: [220/393] 55% | Training loss: 0.6941524524580348
Epoch: 28 | Iteration number: [230/393] 58% | Training loss: 0.6939804813136226
Epoch: 28 | Iteration number: [240/393] 61% | Training loss: 0.6938613904019196
Epoch: 28 | Iteration number: [250/393] 63% | Training loss: 0.6937472972869873
Epoch: 28 | Iteration number: [260/393] 66% | Training loss: 0.6936499625444412
Epoch: 28 | Iteration number: [270/393] 68% | Training loss: 0.6935759919661063
Epoch: 28 | Iteration number: [280/393] 71% | Training loss: 0.693477702992303
Epoch: 28 | Iteration number: [290/393] 73% | Training loss: 0.6934005106317586
Epoch: 28 | Iteration number: [300/393] 76% | Training loss: 0.6933005058765411
Epoch: 28 | Iteration number: [310/393] 78% | Training loss: 0.6932061806801827
Epoch: 28 | Iteration number: [320/393] 81% | Training loss: 0.6931349007412791
Epoch: 28 | Iteration number: [330/393] 83% | Training loss: 0.6930771544124141
Epoch: 28 | Iteration number: [340/393] 86% | Training loss: 0.6930164142566568
Epoch: 28 | Iteration number: [350/393] 89% | Training loss: 0.6929433601243156
Epoch: 28 | Iteration number: [360/393] 91% | Training loss: 0.6928857412603167
Epoch: 28 | Iteration number: [370/393] 94% | Training loss: 0.6928484465624835
Epoch: 28 | Iteration number: [380/393] 96% | Training loss: 0.6928258199440805
Epoch: 28 | Iteration number: [390/393] 99% | Training loss: 0.6927579815571124

 End of epoch: 28 | Train Loss: 0.6909784421362646 | Training Time: 66 

 End of epoch: 28 | Eval Loss: 0.6905460892891397 | Evaluating Time: 16 
Epoch: 29 | Iteration number: [10/393] 2% | Training loss: 0.7579612970352173
Epoch: 29 | Iteration number: [20/393] 5% | Training loss: 0.7245954245328903
Epoch: 29 | Iteration number: [30/393] 7% | Training loss: 0.7133537669976552
Epoch: 29 | Iteration number: [40/393] 10% | Training loss: 0.7077994257211685
Epoch: 29 | Iteration number: [50/393] 12% | Training loss: 0.7044442296028137
Epoch: 29 | Iteration number: [60/393] 15% | Training loss: 0.7021965612967809
Epoch: 29 | Iteration number: [70/393] 17% | Training loss: 0.7006480199950081
Epoch: 29 | Iteration number: [80/393] 20% | Training loss: 0.6993932880461216
Epoch: 29 | Iteration number: [90/393] 22% | Training loss: 0.698428699043062
Epoch: 29 | Iteration number: [100/393] 25% | Training loss: 0.6976114845275879
Epoch: 29 | Iteration number: [110/393] 27% | Training loss: 0.6969737952405756
Epoch: 29 | Iteration number: [120/393] 30% | Training loss: 0.6964526961247126
Epoch: 29 | Iteration number: [130/393] 33% | Training loss: 0.6960770382330967
Epoch: 29 | Iteration number: [140/393] 35% | Training loss: 0.6957560956478119
Epoch: 29 | Iteration number: [150/393] 38% | Training loss: 0.6954177979628245
Epoch: 29 | Iteration number: [160/393] 40% | Training loss: 0.6951108533889055
Epoch: 29 | Iteration number: [170/393] 43% | Training loss: 0.6948886615388533
Epoch: 29 | Iteration number: [180/393] 45% | Training loss: 0.6947011914518144
Epoch: 29 | Iteration number: [190/393] 48% | Training loss: 0.6945401928926769
Epoch: 29 | Iteration number: [200/393] 50% | Training loss: 0.6943459933996201
Epoch: 29 | Iteration number: [210/393] 53% | Training loss: 0.6942076697236016
Epoch: 29 | Iteration number: [220/393] 55% | Training loss: 0.6940858727151697
Epoch: 29 | Iteration number: [230/393] 58% | Training loss: 0.6939525886722233
Epoch: 29 | Iteration number: [240/393] 61% | Training loss: 0.6938310732444127
Epoch: 29 | Iteration number: [250/393] 63% | Training loss: 0.6937712886333466
Epoch: 29 | Iteration number: [260/393] 66% | Training loss: 0.6936884776904033
Epoch: 29 | Iteration number: [270/393] 68% | Training loss: 0.6935792282775596
Epoch: 29 | Iteration number: [280/393] 71% | Training loss: 0.693513714841434
Epoch: 29 | Iteration number: [290/393] 73% | Training loss: 0.6934096169882807
Epoch: 29 | Iteration number: [300/393] 76% | Training loss: 0.6933222156763077
Epoch: 29 | Iteration number: [310/393] 78% | Training loss: 0.6931917582788775
Epoch: 29 | Iteration number: [320/393] 81% | Training loss: 0.693110361509025
Epoch: 29 | Iteration number: [330/393] 83% | Training loss: 0.6930434526819171
Epoch: 29 | Iteration number: [340/393] 86% | Training loss: 0.6929781610474867
Epoch: 29 | Iteration number: [350/393] 89% | Training loss: 0.6929257430349077
Epoch: 29 | Iteration number: [360/393] 91% | Training loss: 0.692898052599695
Epoch: 29 | Iteration number: [370/393] 94% | Training loss: 0.6928675361581751
Epoch: 29 | Iteration number: [380/393] 96% | Training loss: 0.6928186794644908
Epoch: 29 | Iteration number: [390/393] 99% | Training loss: 0.6927551871690995

 End of epoch: 29 | Train Loss: 0.6909824960104382 | Training Time: 66 

 End of epoch: 29 | Eval Loss: 0.6907590055952266 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/393] 2% | Training loss: 0.7594116389751434
Epoch: 30 | Iteration number: [20/393] 5% | Training loss: 0.7248759716749191
Epoch: 30 | Iteration number: [30/393] 7% | Training loss: 0.7136212786038717
Epoch: 30 | Iteration number: [40/393] 10% | Training loss: 0.7079918935894967
Epoch: 30 | Iteration number: [50/393] 12% | Training loss: 0.7045620799064636
Epoch: 30 | Iteration number: [60/393] 15% | Training loss: 0.702397828300794
Epoch: 30 | Iteration number: [70/393] 17% | Training loss: 0.7006885826587677
Epoch: 30 | Iteration number: [80/393] 20% | Training loss: 0.6994910888373852
Epoch: 30 | Iteration number: [90/393] 22% | Training loss: 0.6983902361657884
Epoch: 30 | Iteration number: [100/393] 25% | Training loss: 0.6977130913734436
Epoch: 30 | Iteration number: [110/393] 27% | Training loss: 0.6969782715493983
Epoch: 30 | Iteration number: [120/393] 30% | Training loss: 0.6964305450518926
Epoch: 30 | Iteration number: [130/393] 33% | Training loss: 0.6960105139475602
Epoch: 30 | Iteration number: [140/393] 35% | Training loss: 0.6957568662507193
Epoch: 30 | Iteration number: [150/393] 38% | Training loss: 0.6953342262903849
Epoch: 30 | Iteration number: [160/393] 40% | Training loss: 0.695074324682355
Epoch: 30 | Iteration number: [170/393] 43% | Training loss: 0.6948604029767653
Epoch: 30 | Iteration number: [180/393] 45% | Training loss: 0.6946206367678113
Epoch: 30 | Iteration number: [190/393] 48% | Training loss: 0.6944184698556599
Epoch: 30 | Iteration number: [200/393] 50% | Training loss: 0.694243140220642
Epoch: 30 | Iteration number: [210/393] 53% | Training loss: 0.694111118430183
Epoch: 30 | Iteration number: [220/393] 55% | Training loss: 0.6939796344800429
Epoch: 30 | Iteration number: [230/393] 58% | Training loss: 0.693812195373618
Epoch: 30 | Iteration number: [240/393] 61% | Training loss: 0.6936782340208689
Epoch: 30 | Iteration number: [250/393] 63% | Training loss: 0.6936364109516144
Epoch: 30 | Iteration number: [260/393] 66% | Training loss: 0.6935554376015296
Epoch: 30 | Iteration number: [270/393] 68% | Training loss: 0.6934690546106409
Epoch: 30 | Iteration number: [280/393] 71% | Training loss: 0.6933796497327941
Epoch: 30 | Iteration number: [290/393] 73% | Training loss: 0.6932554680725623
Epoch: 30 | Iteration number: [300/393] 76% | Training loss: 0.6931638558705647
Epoch: 30 | Iteration number: [310/393] 78% | Training loss: 0.6930853793697972
Epoch: 30 | Iteration number: [320/393] 81% | Training loss: 0.6930114617571235
Epoch: 30 | Iteration number: [330/393] 83% | Training loss: 0.6929093433148933
Epoch: 30 | Iteration number: [340/393] 86% | Training loss: 0.6928463068078546
Epoch: 30 | Iteration number: [350/393] 89% | Training loss: 0.6927882494245257
Epoch: 30 | Iteration number: [360/393] 91% | Training loss: 0.6927386343479156
Epoch: 30 | Iteration number: [370/393] 94% | Training loss: 0.6926676866170522
Epoch: 30 | Iteration number: [380/393] 96% | Training loss: 0.6926253467798233
Epoch: 30 | Iteration number: [390/393] 99% | Training loss: 0.6926173196389125

 End of epoch: 30 | Train Loss: 0.6908516677584661 | Training Time: 66 

 End of epoch: 30 | Eval Loss: 0.692668499995251 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/393] 2% | Training loss: 0.7615007519721985
Epoch: 31 | Iteration number: [20/393] 5% | Training loss: 0.7271277576684951
Epoch: 31 | Iteration number: [30/393] 7% | Training loss: 0.7152120033899944
Epoch: 31 | Iteration number: [40/393] 10% | Training loss: 0.7090622365474701
Epoch: 31 | Iteration number: [50/393] 12% | Training loss: 0.7054861581325531
Epoch: 31 | Iteration number: [60/393] 15% | Training loss: 0.7031504054864247
Epoch: 31 | Iteration number: [70/393] 17% | Training loss: 0.7013930133410863
Epoch: 31 | Iteration number: [80/393] 20% | Training loss: 0.7001440227031708
Epoch: 31 | Iteration number: [90/393] 22% | Training loss: 0.6991752929157681
Epoch: 31 | Iteration number: [100/393] 25% | Training loss: 0.6983401268720627
Epoch: 31 | Iteration number: [110/393] 27% | Training loss: 0.697596033594825
Epoch: 31 | Iteration number: [120/393] 30% | Training loss: 0.697068852186203
Epoch: 31 | Iteration number: [130/393] 33% | Training loss: 0.6966154048076043
Epoch: 31 | Iteration number: [140/393] 35% | Training loss: 0.6962867966720037
Epoch: 31 | Iteration number: [150/393] 38% | Training loss: 0.6959388800462087
Epoch: 31 | Iteration number: [160/393] 40% | Training loss: 0.6956127129495144
Epoch: 31 | Iteration number: [170/393] 43% | Training loss: 0.6953326435650096
Epoch: 31 | Iteration number: [180/393] 45% | Training loss: 0.6950480838616689
Epoch: 31 | Iteration number: [190/393] 48% | Training loss: 0.6948523901010815
Epoch: 31 | Iteration number: [200/393] 50% | Training loss: 0.6945833298563957
Epoch: 31 | Iteration number: [210/393] 53% | Training loss: 0.6944055273419335
Epoch: 31 | Iteration number: [220/393] 55% | Training loss: 0.6942613300952044
Epoch: 31 | Iteration number: [230/393] 58% | Training loss: 0.6941018213396487
Epoch: 31 | Iteration number: [240/393] 61% | Training loss: 0.6939730150004227
Epoch: 31 | Iteration number: [250/393] 63% | Training loss: 0.6938257048130035
Epoch: 31 | Iteration number: [260/393] 66% | Training loss: 0.6937583661996402
Epoch: 31 | Iteration number: [270/393] 68% | Training loss: 0.6936407705148061
Epoch: 31 | Iteration number: [280/393] 71% | Training loss: 0.6935265228152275
Epoch: 31 | Iteration number: [290/393] 73% | Training loss: 0.693420082536237
Epoch: 31 | Iteration number: [300/393] 76% | Training loss: 0.6933158644040426
Epoch: 31 | Iteration number: [310/393] 78% | Training loss: 0.693220550975492
Epoch: 31 | Iteration number: [320/393] 81% | Training loss: 0.6931363597512246
Epoch: 31 | Iteration number: [330/393] 83% | Training loss: 0.6930697695775465
Epoch: 31 | Iteration number: [340/393] 86% | Training loss: 0.6930106163024903
Epoch: 31 | Iteration number: [350/393] 89% | Training loss: 0.6929117228303637
Epoch: 31 | Iteration number: [360/393] 91% | Training loss: 0.6928388449880812
Epoch: 31 | Iteration number: [370/393] 94% | Training loss: 0.6927689629632073
Epoch: 31 | Iteration number: [380/393] 96% | Training loss: 0.6926993729252564
Epoch: 31 | Iteration number: [390/393] 99% | Training loss: 0.6926627197326758

 End of epoch: 31 | Train Loss: 0.6909027686555878 | Training Time: 66 

 End of epoch: 31 | Eval Loss: 0.6905524085979072 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/393] 2% | Training loss: 0.7599069058895112
Epoch: 32 | Iteration number: [20/393] 5% | Training loss: 0.7249372392892838
Epoch: 32 | Iteration number: [30/393] 7% | Training loss: 0.7134379049142202
Epoch: 32 | Iteration number: [40/393] 10% | Training loss: 0.7081221833825111
Epoch: 32 | Iteration number: [50/393] 12% | Training loss: 0.7046890330314636
Epoch: 32 | Iteration number: [60/393] 15% | Training loss: 0.7023694823185603
Epoch: 32 | Iteration number: [70/393] 17% | Training loss: 0.7007253902299063
Epoch: 32 | Iteration number: [80/393] 20% | Training loss: 0.6994922384619713
Epoch: 32 | Iteration number: [90/393] 22% | Training loss: 0.6984346012274424
Epoch: 32 | Iteration number: [100/393] 25% | Training loss: 0.6975209611654282
Epoch: 32 | Iteration number: [110/393] 27% | Training loss: 0.6969679794528267
Epoch: 32 | Iteration number: [120/393] 30% | Training loss: 0.6964533274372419
Epoch: 32 | Iteration number: [130/393] 33% | Training loss: 0.6960683391644404
Epoch: 32 | Iteration number: [140/393] 35% | Training loss: 0.6956605621746608
Epoch: 32 | Iteration number: [150/393] 38% | Training loss: 0.6953191153208415
Epoch: 32 | Iteration number: [160/393] 40% | Training loss: 0.6950014237314462
Epoch: 32 | Iteration number: [170/393] 43% | Training loss: 0.6947651105768541
Epoch: 32 | Iteration number: [180/393] 45% | Training loss: 0.6945164051320818
Epoch: 32 | Iteration number: [190/393] 48% | Training loss: 0.6943215084703345
Epoch: 32 | Iteration number: [200/393] 50% | Training loss: 0.6941941139101983
Epoch: 32 | Iteration number: [210/393] 53% | Training loss: 0.6940364301204681
Epoch: 32 | Iteration number: [220/393] 55% | Training loss: 0.6938532108610327
Epoch: 32 | Iteration number: [230/393] 58% | Training loss: 0.6937422692775727
Epoch: 32 | Iteration number: [240/393] 61% | Training loss: 0.6936105854809285
Epoch: 32 | Iteration number: [250/393] 63% | Training loss: 0.6934864037036895
Epoch: 32 | Iteration number: [260/393] 66% | Training loss: 0.6934089699616799
Epoch: 32 | Iteration number: [270/393] 68% | Training loss: 0.6933593025913944
Epoch: 32 | Iteration number: [280/393] 71% | Training loss: 0.6932738444634846
Epoch: 32 | Iteration number: [290/393] 73% | Training loss: 0.6931977568001583
Epoch: 32 | Iteration number: [300/393] 76% | Training loss: 0.6931337434053421
Epoch: 32 | Iteration number: [310/393] 78% | Training loss: 0.6930510801653709
Epoch: 32 | Iteration number: [320/393] 81% | Training loss: 0.6929325137287379
Epoch: 32 | Iteration number: [330/393] 83% | Training loss: 0.6928635718244495
Epoch: 32 | Iteration number: [340/393] 86% | Training loss: 0.6928246889044257
Epoch: 32 | Iteration number: [350/393] 89% | Training loss: 0.6927693397658212
Epoch: 32 | Iteration number: [360/393] 91% | Training loss: 0.6927234477467007
Epoch: 32 | Iteration number: [370/393] 94% | Training loss: 0.6926869268352921
Epoch: 32 | Iteration number: [380/393] 96% | Training loss: 0.6926438802166989
Epoch: 32 | Iteration number: [390/393] 99% | Training loss: 0.6925973135691422

 End of epoch: 32 | Train Loss: 0.6908244540673176 | Training Time: 66 

 End of epoch: 32 | Eval Loss: 0.6904998008085756 | Evaluating Time: 17 
Epoch: 33 | Iteration number: [10/393] 2% | Training loss: 0.759587287902832
Epoch: 33 | Iteration number: [20/393] 5% | Training loss: 0.724966236948967
Epoch: 33 | Iteration number: [30/393] 7% | Training loss: 0.7131742715835572
Epoch: 33 | Iteration number: [40/393] 10% | Training loss: 0.7075824171304703
Epoch: 33 | Iteration number: [50/393] 12% | Training loss: 0.7042337131500244
Epoch: 33 | Iteration number: [60/393] 15% | Training loss: 0.7019805500904719
Epoch: 33 | Iteration number: [70/393] 17% | Training loss: 0.7003935268947057
Epoch: 33 | Iteration number: [80/393] 20% | Training loss: 0.6991557151079177
Epoch: 33 | Iteration number: [90/393] 22% | Training loss: 0.6981321209006839
Epoch: 33 | Iteration number: [100/393] 25% | Training loss: 0.697465848326683
Epoch: 33 | Iteration number: [110/393] 27% | Training loss: 0.6967571545730937
Epoch: 33 | Iteration number: [120/393] 30% | Training loss: 0.6963609680533409
Epoch: 33 | Iteration number: [130/393] 33% | Training loss: 0.6958477327456841
Epoch: 33 | Iteration number: [140/393] 35% | Training loss: 0.6954386161906378
Epoch: 33 | Iteration number: [150/393] 38% | Training loss: 0.6951825241247813
Epoch: 33 | Iteration number: [160/393] 40% | Training loss: 0.6949447356164455
Epoch: 33 | Iteration number: [170/393] 43% | Training loss: 0.6946806266027339
Epoch: 33 | Iteration number: [180/393] 45% | Training loss: 0.6945051547553804
Epoch: 33 | Iteration number: [190/393] 48% | Training loss: 0.6943106651306152
Epoch: 33 | Iteration number: [200/393] 50% | Training loss: 0.6941079026460648
Epoch: 33 | Iteration number: [210/393] 53% | Training loss: 0.6939631601174673
Epoch: 33 | Iteration number: [220/393] 55% | Training loss: 0.6937840610742569
Epoch: 33 | Iteration number: [230/393] 58% | Training loss: 0.6936229418153348
Epoch: 33 | Iteration number: [240/393] 61% | Training loss: 0.6935073025524616
Epoch: 33 | Iteration number: [250/393] 63% | Training loss: 0.6933843178749084
Epoch: 33 | Iteration number: [260/393] 66% | Training loss: 0.6933017221780924
Epoch: 33 | Iteration number: [270/393] 68% | Training loss: 0.6932240382388786
Epoch: 33 | Iteration number: [280/393] 71% | Training loss: 0.6931265564901489
Epoch: 33 | Iteration number: [290/393] 73% | Training loss: 0.6930328182105361
Epoch: 33 | Iteration number: [300/393] 76% | Training loss: 0.6929499483108521
Epoch: 33 | Iteration number: [310/393] 78% | Training loss: 0.6928723575607423
Epoch: 33 | Iteration number: [320/393] 81% | Training loss: 0.6928120953962207
Epoch: 33 | Iteration number: [330/393] 83% | Training loss: 0.6927663281108394
Epoch: 33 | Iteration number: [340/393] 86% | Training loss: 0.6926929917405633
Epoch: 33 | Iteration number: [350/393] 89% | Training loss: 0.692614746434348
Epoch: 33 | Iteration number: [360/393] 91% | Training loss: 0.6925673875543806
Epoch: 33 | Iteration number: [370/393] 94% | Training loss: 0.6925220412177009
Epoch: 33 | Iteration number: [380/393] 96% | Training loss: 0.6924596229666158
Epoch: 33 | Iteration number: [390/393] 99% | Training loss: 0.6924173365800809

 End of epoch: 33 | Train Loss: 0.6906570504033231 | Training Time: 66 

 End of epoch: 33 | Eval Loss: 0.6905541918715652 | Evaluating Time: 16 
Epoch: 34 | Iteration number: [10/393] 2% | Training loss: 0.7589257657527924
Epoch: 34 | Iteration number: [20/393] 5% | Training loss: 0.7247471809387207
Epoch: 34 | Iteration number: [30/393] 7% | Training loss: 0.7134979605674744
Epoch: 34 | Iteration number: [40/393] 10% | Training loss: 0.7075550779700279
Epoch: 34 | Iteration number: [50/393] 12% | Training loss: 0.7043350386619568
Epoch: 34 | Iteration number: [60/393] 15% | Training loss: 0.7021145403385163
Epoch: 34 | Iteration number: [70/393] 17% | Training loss: 0.700386175939015
Epoch: 34 | Iteration number: [80/393] 20% | Training loss: 0.6992235004901886
Epoch: 34 | Iteration number: [90/393] 22% | Training loss: 0.6982727905114492
Epoch: 34 | Iteration number: [100/393] 25% | Training loss: 0.6974869966506958
Epoch: 34 | Iteration number: [110/393] 27% | Training loss: 0.696807097304951
Epoch: 34 | Iteration number: [120/393] 30% | Training loss: 0.6962506925066312
Epoch: 34 | Iteration number: [130/393] 33% | Training loss: 0.695801804615901
Epoch: 34 | Iteration number: [140/393] 35% | Training loss: 0.6955167710781097
Epoch: 34 | Iteration number: [150/393] 38% | Training loss: 0.6952324759960175
Epoch: 34 | Iteration number: [160/393] 40% | Training loss: 0.6949158556759357
Epoch: 34 | Iteration number: [170/393] 43% | Training loss: 0.6947230195297914
Epoch: 34 | Iteration number: [180/393] 45% | Training loss: 0.694510304927826
Epoch: 34 | Iteration number: [190/393] 48% | Training loss: 0.6942990654393246
Epoch: 34 | Iteration number: [200/393] 50% | Training loss: 0.6941180798411369
Epoch: 34 | Iteration number: [210/393] 53% | Training loss: 0.6939440551258269
Epoch: 34 | Iteration number: [220/393] 55% | Training loss: 0.6937630745497617
Epoch: 34 | Iteration number: [230/393] 58% | Training loss: 0.6936302687810815
Epoch: 34 | Iteration number: [240/393] 61% | Training loss: 0.6934948506454627
Epoch: 34 | Iteration number: [250/393] 63% | Training loss: 0.6933696031570434
Epoch: 34 | Iteration number: [260/393] 66% | Training loss: 0.6932255554657716
Epoch: 34 | Iteration number: [270/393] 68% | Training loss: 0.6931224076836198
Epoch: 34 | Iteration number: [280/393] 71% | Training loss: 0.6930573763591903
Epoch: 34 | Iteration number: [290/393] 73% | Training loss: 0.6929713943908955
Epoch: 34 | Iteration number: [300/393] 76% | Training loss: 0.6928630884488424
Epoch: 34 | Iteration number: [310/393] 78% | Training loss: 0.692834440546651
Epoch: 34 | Iteration number: [320/393] 81% | Training loss: 0.6928028589114547
Epoch: 34 | Iteration number: [330/393] 83% | Training loss: 0.6927477005756263
Epoch: 34 | Iteration number: [340/393] 86% | Training loss: 0.692715042478898
Epoch: 34 | Iteration number: [350/393] 89% | Training loss: 0.692660562821797
Epoch: 34 | Iteration number: [360/393] 91% | Training loss: 0.6925962020953497
Epoch: 34 | Iteration number: [370/393] 94% | Training loss: 0.6925243463065173
Epoch: 34 | Iteration number: [380/393] 96% | Training loss: 0.6924887484625766
Epoch: 34 | Iteration number: [390/393] 99% | Training loss: 0.6924567022384741

 End of epoch: 34 | Train Loss: 0.6906905148472191 | Training Time: 66 

 End of epoch: 34 | Eval Loss: 0.6903863366769285 | Evaluating Time: 16 
Epoch: 35 | Iteration number: [10/393] 2% | Training loss: 0.7601369678974151
Epoch: 35 | Iteration number: [20/393] 5% | Training loss: 0.7252540409564971
Epoch: 35 | Iteration number: [30/393] 7% | Training loss: 0.7136963287989299
Epoch: 35 | Iteration number: [40/393] 10% | Training loss: 0.7081043034791946
Epoch: 35 | Iteration number: [50/393] 12% | Training loss: 0.7046695172786712
Epoch: 35 | Iteration number: [60/393] 15% | Training loss: 0.7022136251131693
Epoch: 35 | Iteration number: [70/393] 17% | Training loss: 0.7003795240606581
Epoch: 35 | Iteration number: [80/393] 20% | Training loss: 0.699099174886942
Epoch: 35 | Iteration number: [90/393] 22% | Training loss: 0.6980948481294844
Epoch: 35 | Iteration number: [100/393] 25% | Training loss: 0.6973224121332169
Epoch: 35 | Iteration number: [110/393] 27% | Training loss: 0.6967576016079295
Epoch: 35 | Iteration number: [120/393] 30% | Training loss: 0.6962315618991852
Epoch: 35 | Iteration number: [130/393] 33% | Training loss: 0.6957928648361793
Epoch: 35 | Iteration number: [140/393] 35% | Training loss: 0.6954673264707838
Epoch: 35 | Iteration number: [150/393] 38% | Training loss: 0.6951518861452738
Epoch: 35 | Iteration number: [160/393] 40% | Training loss: 0.6948211126029491
Epoch: 35 | Iteration number: [170/393] 43% | Training loss: 0.6946088100180906
Epoch: 35 | Iteration number: [180/393] 45% | Training loss: 0.6943993753857083
Epoch: 35 | Iteration number: [190/393] 48% | Training loss: 0.694158113943903
Epoch: 35 | Iteration number: [200/393] 50% | Training loss: 0.6939669069647789
Epoch: 35 | Iteration number: [210/393] 53% | Training loss: 0.6938203226952325
Epoch: 35 | Iteration number: [220/393] 55% | Training loss: 0.6936875863508745
Epoch: 35 | Iteration number: [230/393] 58% | Training loss: 0.6936103382836217
Epoch: 35 | Iteration number: [240/393] 61% | Training loss: 0.6934481571118037
Epoch: 35 | Iteration number: [250/393] 63% | Training loss: 0.6933377785682678
Epoch: 35 | Iteration number: [260/393] 66% | Training loss: 0.693260931280943
Epoch: 35 | Iteration number: [270/393] 68% | Training loss: 0.6931564728418986
Epoch: 35 | Iteration number: [280/393] 71% | Training loss: 0.6930442903723035
Epoch: 35 | Iteration number: [290/393] 73% | Training loss: 0.6929814287300767
Epoch: 35 | Iteration number: [300/393] 76% | Training loss: 0.6929031028350194
Epoch: 35 | Iteration number: [310/393] 78% | Training loss: 0.6928342378908589
Epoch: 35 | Iteration number: [320/393] 81% | Training loss: 0.6927783720195293
Epoch: 35 | Iteration number: [330/393] 83% | Training loss: 0.6927129180142374
Epoch: 35 | Iteration number: [340/393] 86% | Training loss: 0.692686620705268
Epoch: 35 | Iteration number: [350/393] 89% | Training loss: 0.6926443959985461
Epoch: 35 | Iteration number: [360/393] 91% | Training loss: 0.6925366181466315
Epoch: 35 | Iteration number: [370/393] 94% | Training loss: 0.6924864451627474
Epoch: 35 | Iteration number: [380/393] 96% | Training loss: 0.692426032925907
Epoch: 35 | Iteration number: [390/393] 99% | Training loss: 0.6923822043797909

 End of epoch: 35 | Train Loss: 0.6906129546444532 | Training Time: 66 

 End of epoch: 35 | Eval Loss: 0.690644908924492 | Evaluating Time: 17 
Epoch: 36 | Iteration number: [10/393] 2% | Training loss: 0.7594789028167724
Epoch: 36 | Iteration number: [20/393] 5% | Training loss: 0.7253885179758072
Epoch: 36 | Iteration number: [30/393] 7% | Training loss: 0.7140934844811757
Epoch: 36 | Iteration number: [40/393] 10% | Training loss: 0.7083167150616646
Epoch: 36 | Iteration number: [50/393] 12% | Training loss: 0.7048725509643554
Epoch: 36 | Iteration number: [60/393] 15% | Training loss: 0.7026573568582535
Epoch: 36 | Iteration number: [70/393] 17% | Training loss: 0.7010360555989402
Epoch: 36 | Iteration number: [80/393] 20% | Training loss: 0.6995983257889747
Epoch: 36 | Iteration number: [90/393] 22% | Training loss: 0.69859342707528
Epoch: 36 | Iteration number: [100/393] 25% | Training loss: 0.6978874784708023
Epoch: 36 | Iteration number: [110/393] 27% | Training loss: 0.6971871972084045
Epoch: 36 | Iteration number: [120/393] 30% | Training loss: 0.6966402436296145
Epoch: 36 | Iteration number: [130/393] 33% | Training loss: 0.6962198142821973
Epoch: 36 | Iteration number: [140/393] 35% | Training loss: 0.6959140560456685
Epoch: 36 | Iteration number: [150/393] 38% | Training loss: 0.6954957294464111
Epoch: 36 | Iteration number: [160/393] 40% | Training loss: 0.6951590806245804
Epoch: 36 | Iteration number: [170/393] 43% | Training loss: 0.6948851364500382
Epoch: 36 | Iteration number: [180/393] 45% | Training loss: 0.6945826109912661
Epoch: 36 | Iteration number: [190/393] 48% | Training loss: 0.6943578971059698
Epoch: 36 | Iteration number: [200/393] 50% | Training loss: 0.69416030138731
Epoch: 36 | Iteration number: [210/393] 53% | Training loss: 0.6939779556932903
Epoch: 36 | Iteration number: [220/393] 55% | Training loss: 0.6937940854917873
Epoch: 36 | Iteration number: [230/393] 58% | Training loss: 0.6936478827310645
Epoch: 36 | Iteration number: [240/393] 61% | Training loss: 0.6935240268707276
Epoch: 36 | Iteration number: [250/393] 63% | Training loss: 0.6933859829902649
Epoch: 36 | Iteration number: [260/393] 66% | Training loss: 0.693273080770786
Epoch: 36 | Iteration number: [270/393] 68% | Training loss: 0.6931557741430071
Epoch: 36 | Iteration number: [280/393] 71% | Training loss: 0.6930657618812153
Epoch: 36 | Iteration number: [290/393] 73% | Training loss: 0.6929815816468206
Epoch: 36 | Iteration number: [300/393] 76% | Training loss: 0.6929174077510833
Epoch: 36 | Iteration number: [310/393] 78% | Training loss: 0.6928169631188915
Epoch: 36 | Iteration number: [320/393] 81% | Training loss: 0.6927217559888958
Epoch: 36 | Iteration number: [330/393] 83% | Training loss: 0.6926520757602923
Epoch: 36 | Iteration number: [340/393] 86% | Training loss: 0.6926055990597781
Epoch: 36 | Iteration number: [350/393] 89% | Training loss: 0.6925547787121364
Epoch: 36 | Iteration number: [360/393] 91% | Training loss: 0.6924831022818884
Epoch: 36 | Iteration number: [370/393] 94% | Training loss: 0.6924672352301108
Epoch: 36 | Iteration number: [380/393] 96% | Training loss: 0.6924202456286079
Epoch: 36 | Iteration number: [390/393] 99% | Training loss: 0.6923668511402913

 End of epoch: 36 | Train Loss: 0.690599387383643 | Training Time: 66 

 End of epoch: 36 | Eval Loss: 0.6903235000007006 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/393] 2% | Training loss: 0.759221762418747
Epoch: 37 | Iteration number: [20/393] 5% | Training loss: 0.7240659058094024
Epoch: 37 | Iteration number: [30/393] 7% | Training loss: 0.7131450295448303
Epoch: 37 | Iteration number: [40/393] 10% | Training loss: 0.707680481672287
Epoch: 37 | Iteration number: [50/393] 12% | Training loss: 0.7043627727031708
Epoch: 37 | Iteration number: [60/393] 15% | Training loss: 0.7020142803589503
Epoch: 37 | Iteration number: [70/393] 17% | Training loss: 0.7002235846860069
Epoch: 37 | Iteration number: [80/393] 20% | Training loss: 0.6986859127879143
Epoch: 37 | Iteration number: [90/393] 22% | Training loss: 0.6976463622517056
Epoch: 37 | Iteration number: [100/393] 25% | Training loss: 0.6969602876901626
Epoch: 37 | Iteration number: [110/393] 27% | Training loss: 0.6964185259558938
Epoch: 37 | Iteration number: [120/393] 30% | Training loss: 0.6959164718786875
Epoch: 37 | Iteration number: [130/393] 33% | Training loss: 0.69551794895759
Epoch: 37 | Iteration number: [140/393] 35% | Training loss: 0.6950977989605495
Epoch: 37 | Iteration number: [150/393] 38% | Training loss: 0.6947811162471771
Epoch: 37 | Iteration number: [160/393] 40% | Training loss: 0.6945559989660979
Epoch: 37 | Iteration number: [170/393] 43% | Training loss: 0.6943362937254064
Epoch: 37 | Iteration number: [180/393] 45% | Training loss: 0.6941488948133256
Epoch: 37 | Iteration number: [190/393] 48% | Training loss: 0.693997787801843
Epoch: 37 | Iteration number: [200/393] 50% | Training loss: 0.6938747328519821
Epoch: 37 | Iteration number: [210/393] 53% | Training loss: 0.6936874707539876
Epoch: 37 | Iteration number: [220/393] 55% | Training loss: 0.6935843110084534
Epoch: 37 | Iteration number: [230/393] 58% | Training loss: 0.6934858355833137
Epoch: 37 | Iteration number: [240/393] 61% | Training loss: 0.693376412242651
Epoch: 37 | Iteration number: [250/393] 63% | Training loss: 0.6932734580039978
Epoch: 37 | Iteration number: [260/393] 66% | Training loss: 0.6931575752221621
Epoch: 37 | Iteration number: [270/393] 68% | Training loss: 0.6931139477977046
Epoch: 37 | Iteration number: [280/393] 71% | Training loss: 0.6930509273494992
Epoch: 37 | Iteration number: [290/393] 73% | Training loss: 0.6929769176861336
Epoch: 37 | Iteration number: [300/393] 76% | Training loss: 0.6928962363799414
Epoch: 37 | Iteration number: [310/393] 78% | Training loss: 0.6928100357132573
Epoch: 37 | Iteration number: [320/393] 81% | Training loss: 0.6927604354918003
Epoch: 37 | Iteration number: [330/393] 83% | Training loss: 0.6927026046044898
Epoch: 37 | Iteration number: [340/393] 86% | Training loss: 0.6926430036039913
Epoch: 37 | Iteration number: [350/393] 89% | Training loss: 0.6925637587479183
Epoch: 37 | Iteration number: [360/393] 91% | Training loss: 0.692515240278509
Epoch: 37 | Iteration number: [370/393] 94% | Training loss: 0.692497818856626
Epoch: 37 | Iteration number: [380/393] 96% | Training loss: 0.692433982303268
Epoch: 37 | Iteration number: [390/393] 99% | Training loss: 0.6924026666543422

 End of epoch: 37 | Train Loss: 0.6906404037208654 | Training Time: 66 

 End of epoch: 37 | Eval Loss: 0.69052747439365 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/393] 2% | Training loss: 0.7585330486297608
Epoch: 38 | Iteration number: [20/393] 5% | Training loss: 0.7248801320791245
Epoch: 38 | Iteration number: [30/393] 7% | Training loss: 0.7135044078032176
Epoch: 38 | Iteration number: [40/393] 10% | Training loss: 0.7078677222132683
Epoch: 38 | Iteration number: [50/393] 12% | Training loss: 0.7044500374794006
Epoch: 38 | Iteration number: [60/393] 15% | Training loss: 0.7022789001464844
Epoch: 38 | Iteration number: [70/393] 17% | Training loss: 0.7006350117070335
Epoch: 38 | Iteration number: [80/393] 20% | Training loss: 0.6993585176765919
Epoch: 38 | Iteration number: [90/393] 22% | Training loss: 0.6984187854660882
Epoch: 38 | Iteration number: [100/393] 25% | Training loss: 0.6975947862863541
Epoch: 38 | Iteration number: [110/393] 27% | Training loss: 0.6970164591615851
Epoch: 38 | Iteration number: [120/393] 30% | Training loss: 0.6965047175685565
Epoch: 38 | Iteration number: [130/393] 33% | Training loss: 0.6960856740291302
Epoch: 38 | Iteration number: [140/393] 35% | Training loss: 0.6957792865378516
Epoch: 38 | Iteration number: [150/393] 38% | Training loss: 0.695457595984141
Epoch: 38 | Iteration number: [160/393] 40% | Training loss: 0.6951786939054727
Epoch: 38 | Iteration number: [170/393] 43% | Training loss: 0.6948951984153074
Epoch: 38 | Iteration number: [180/393] 45% | Training loss: 0.6946318474080827
Epoch: 38 | Iteration number: [190/393] 48% | Training loss: 0.6944277857479296
Epoch: 38 | Iteration number: [200/393] 50% | Training loss: 0.6942239010334015
Epoch: 38 | Iteration number: [210/393] 53% | Training loss: 0.6940486218248095
Epoch: 38 | Iteration number: [220/393] 55% | Training loss: 0.6938901741396297
Epoch: 38 | Iteration number: [230/393] 58% | Training loss: 0.6937138471914375
Epoch: 38 | Iteration number: [240/393] 61% | Training loss: 0.6935805827379227
Epoch: 38 | Iteration number: [250/393] 63% | Training loss: 0.6934466197490692
Epoch: 38 | Iteration number: [260/393] 66% | Training loss: 0.6933114510316115
Epoch: 38 | Iteration number: [270/393] 68% | Training loss: 0.6932175773161429
Epoch: 38 | Iteration number: [280/393] 71% | Training loss: 0.6931547648140363
Epoch: 38 | Iteration number: [290/393] 73% | Training loss: 0.693068979320855
Epoch: 38 | Iteration number: [300/393] 76% | Training loss: 0.6930030435323715
Epoch: 38 | Iteration number: [310/393] 78% | Training loss: 0.692913196932885
Epoch: 38 | Iteration number: [320/393] 81% | Training loss: 0.6928542150184512
Epoch: 38 | Iteration number: [330/393] 83% | Training loss: 0.6927724428249128
Epoch: 38 | Iteration number: [340/393] 86% | Training loss: 0.6926679446416742
Epoch: 38 | Iteration number: [350/393] 89% | Training loss: 0.6925732367379325
Epoch: 38 | Iteration number: [360/393] 91% | Training loss: 0.6924800771805976
Epoch: 38 | Iteration number: [370/393] 94% | Training loss: 0.692433745796616
Epoch: 38 | Iteration number: [380/393] 96% | Training loss: 0.6923574532333173
Epoch: 38 | Iteration number: [390/393] 99% | Training loss: 0.6923364671377036

 End of epoch: 38 | Train Loss: 0.6905685786072534 | Training Time: 66 

 End of epoch: 38 | Eval Loss: 0.6904657738549369 | Evaluating Time: 17 
Epoch: 39 | Iteration number: [10/393] 2% | Training loss: 0.7586083590984345
Epoch: 39 | Iteration number: [20/393] 5% | Training loss: 0.7241783320903779
Epoch: 39 | Iteration number: [30/393] 7% | Training loss: 0.7127047995726268
Epoch: 39 | Iteration number: [40/393] 10% | Training loss: 0.7072289660573006
Epoch: 39 | Iteration number: [50/393] 12% | Training loss: 0.7038476693630219
Epoch: 39 | Iteration number: [60/393] 15% | Training loss: 0.7014744738737743
Epoch: 39 | Iteration number: [70/393] 17% | Training loss: 0.6997349032333919
Epoch: 39 | Iteration number: [80/393] 20% | Training loss: 0.6985745020210743
Epoch: 39 | Iteration number: [90/393] 22% | Training loss: 0.6978107432524363
Epoch: 39 | Iteration number: [100/393] 25% | Training loss: 0.6971007198095321
Epoch: 39 | Iteration number: [110/393] 27% | Training loss: 0.6965020721608942
Epoch: 39 | Iteration number: [120/393] 30% | Training loss: 0.696138821542263
Epoch: 39 | Iteration number: [130/393] 33% | Training loss: 0.695710006585488
Epoch: 39 | Iteration number: [140/393] 35% | Training loss: 0.6952449411153794
Epoch: 39 | Iteration number: [150/393] 38% | Training loss: 0.6949464507897695
Epoch: 39 | Iteration number: [160/393] 40% | Training loss: 0.6946794010698796
Epoch: 39 | Iteration number: [170/393] 43% | Training loss: 0.6944866457406212
Epoch: 39 | Iteration number: [180/393] 45% | Training loss: 0.6942831741438972
Epoch: 39 | Iteration number: [190/393] 48% | Training loss: 0.694039091311003
Epoch: 39 | Iteration number: [200/393] 50% | Training loss: 0.6939035713672638
Epoch: 39 | Iteration number: [210/393] 53% | Training loss: 0.6937853762081692
Epoch: 39 | Iteration number: [220/393] 55% | Training loss: 0.6936728409745476
Epoch: 39 | Iteration number: [230/393] 58% | Training loss: 0.6934717152429664
Epoch: 39 | Iteration number: [240/393] 61% | Training loss: 0.6933759803573291
Epoch: 39 | Iteration number: [250/393] 63% | Training loss: 0.6932867121696472
Epoch: 39 | Iteration number: [260/393] 66% | Training loss: 0.6931179521175531
Epoch: 39 | Iteration number: [270/393] 68% | Training loss: 0.6930195424291823
Epoch: 39 | Iteration number: [280/393] 71% | Training loss: 0.6929470960583005
Epoch: 39 | Iteration number: [290/393] 73% | Training loss: 0.6928676416134012
Epoch: 39 | Iteration number: [300/393] 76% | Training loss: 0.692813530365626
Epoch: 39 | Iteration number: [310/393] 78% | Training loss: 0.6927485544835368
Epoch: 39 | Iteration number: [320/393] 81% | Training loss: 0.6926869694143534
Epoch: 39 | Iteration number: [330/393] 83% | Training loss: 0.692616256981185
Epoch: 39 | Iteration number: [340/393] 86% | Training loss: 0.6925868399002972
Epoch: 39 | Iteration number: [350/393] 89% | Training loss: 0.6925244307518006
Epoch: 39 | Iteration number: [360/393] 91% | Training loss: 0.6924714310301675
Epoch: 39 | Iteration number: [370/393] 94% | Training loss: 0.6924211640615721
Epoch: 39 | Iteration number: [380/393] 96% | Training loss: 0.6923680234896509
Epoch: 39 | Iteration number: [390/393] 99% | Training loss: 0.6923357873390883

 End of epoch: 39 | Train Loss: 0.6905694887534959 | Training Time: 66 

 End of epoch: 39 | Eval Loss: 0.690300884295483 | Evaluating Time: 16 
Epoch: 40 | Iteration number: [10/393] 2% | Training loss: 0.7602405190467835
Epoch: 40 | Iteration number: [20/393] 5% | Training loss: 0.7244682520627975
Epoch: 40 | Iteration number: [30/393] 7% | Training loss: 0.7133569359779358
Epoch: 40 | Iteration number: [40/393] 10% | Training loss: 0.7076338112354279
Epoch: 40 | Iteration number: [50/393] 12% | Training loss: 0.7039476931095123
Epoch: 40 | Iteration number: [60/393] 15% | Training loss: 0.7017628302176794
Epoch: 40 | Iteration number: [70/393] 17% | Training loss: 0.700193179505212
Epoch: 40 | Iteration number: [80/393] 20% | Training loss: 0.6989851109683514
Epoch: 40 | Iteration number: [90/393] 22% | Training loss: 0.6980042762226528
Epoch: 40 | Iteration number: [100/393] 25% | Training loss: 0.69730488717556
Epoch: 40 | Iteration number: [110/393] 27% | Training loss: 0.6966906422918493
Epoch: 40 | Iteration number: [120/393] 30% | Training loss: 0.6962038253744444
Epoch: 40 | Iteration number: [130/393] 33% | Training loss: 0.6957749440119817
Epoch: 40 | Iteration number: [140/393] 35% | Training loss: 0.6954093882015773
Epoch: 40 | Iteration number: [150/393] 38% | Training loss: 0.695120038986206
Epoch: 40 | Iteration number: [160/393] 40% | Training loss: 0.6948320783674717
Epoch: 40 | Iteration number: [170/393] 43% | Training loss: 0.694533213447122
Epoch: 40 | Iteration number: [180/393] 45% | Training loss: 0.6943242596255408
Epoch: 40 | Iteration number: [190/393] 48% | Training loss: 0.6940294159086127
Epoch: 40 | Iteration number: [200/393] 50% | Training loss: 0.693915678858757
Epoch: 40 | Iteration number: [210/393] 53% | Training loss: 0.6937565880162375
Epoch: 40 | Iteration number: [220/393] 55% | Training loss: 0.6936672457239844
Epoch: 40 | Iteration number: [230/393] 58% | Training loss: 0.6935439304165218
Epoch: 40 | Iteration number: [240/393] 61% | Training loss: 0.6934395755330721
Epoch: 40 | Iteration number: [250/393] 63% | Training loss: 0.6933394463062287
Epoch: 40 | Iteration number: [260/393] 66% | Training loss: 0.6932593861451516
Epoch: 40 | Iteration number: [270/393] 68% | Training loss: 0.6931422527189608
Epoch: 40 | Iteration number: [280/393] 71% | Training loss: 0.693078362090247
Epoch: 40 | Iteration number: [290/393] 73% | Training loss: 0.6929681775898769
Epoch: 40 | Iteration number: [300/393] 76% | Training loss: 0.692845437725385
Epoch: 40 | Iteration number: [310/393] 78% | Training loss: 0.6927853868853662
Epoch: 40 | Iteration number: [320/393] 81% | Training loss: 0.6927163917571306
Epoch: 40 | Iteration number: [330/393] 83% | Training loss: 0.6926357661232804
Epoch: 40 | Iteration number: [340/393] 86% | Training loss: 0.692572690984782
Epoch: 40 | Iteration number: [350/393] 89% | Training loss: 0.6925298813411168
Epoch: 40 | Iteration number: [360/393] 91% | Training loss: 0.6924629380305608
Epoch: 40 | Iteration number: [370/393] 94% | Training loss: 0.6924384049467138
Epoch: 40 | Iteration number: [380/393] 96% | Training loss: 0.692368492640947
Epoch: 40 | Iteration number: [390/393] 99% | Training loss: 0.6922978417995649

 End of epoch: 40 | Train Loss: 0.6905017865219796 | Training Time: 67 

 End of epoch: 40 | Eval Loss: 0.6902761106588402 | Evaluating Time: 17 
Epoch: 41 | Iteration number: [10/393] 2% | Training loss: 0.7600275337696075
Epoch: 41 | Iteration number: [20/393] 5% | Training loss: 0.725554358959198
Epoch: 41 | Iteration number: [30/393] 7% | Training loss: 0.7139327923456827
Epoch: 41 | Iteration number: [40/393] 10% | Training loss: 0.7078266710042953
Epoch: 41 | Iteration number: [50/393] 12% | Training loss: 0.7043472933769226
Epoch: 41 | Iteration number: [60/393] 15% | Training loss: 0.7019888520240783
Epoch: 41 | Iteration number: [70/393] 17% | Training loss: 0.7002522162028721
Epoch: 41 | Iteration number: [80/393] 20% | Training loss: 0.6990338139235973
Epoch: 41 | Iteration number: [90/393] 22% | Training loss: 0.698091365231408
Epoch: 41 | Iteration number: [100/393] 25% | Training loss: 0.6972960186004639
Epoch: 41 | Iteration number: [110/393] 27% | Training loss: 0.6966378878463398
Epoch: 41 | Iteration number: [120/393] 30% | Training loss: 0.6961724395553271
Epoch: 41 | Iteration number: [130/393] 33% | Training loss: 0.6956548305658193
Epoch: 41 | Iteration number: [140/393] 35% | Training loss: 0.6953110273395265
Epoch: 41 | Iteration number: [150/393] 38% | Training loss: 0.6949717446168264
Epoch: 41 | Iteration number: [160/393] 40% | Training loss: 0.6946318980306387
Epoch: 41 | Iteration number: [170/393] 43% | Training loss: 0.6943584803272697
Epoch: 41 | Iteration number: [180/393] 45% | Training loss: 0.694113533364402
Epoch: 41 | Iteration number: [190/393] 48% | Training loss: 0.6939577466563175
Epoch: 41 | Iteration number: [200/393] 50% | Training loss: 0.693810205757618
Epoch: 41 | Iteration number: [210/393] 53% | Training loss: 0.6936558297702244
Epoch: 41 | Iteration number: [220/393] 55% | Training loss: 0.6935281783342362
Epoch: 41 | Iteration number: [230/393] 58% | Training loss: 0.6933755273404328
Epoch: 41 | Iteration number: [240/393] 61% | Training loss: 0.6932571172714234
Epoch: 41 | Iteration number: [250/393] 63% | Training loss: 0.6931432008743286
Epoch: 41 | Iteration number: [260/393] 66% | Training loss: 0.6930763450952676
Epoch: 41 | Iteration number: [270/393] 68% | Training loss: 0.6930090679062737
Epoch: 41 | Iteration number: [280/393] 71% | Training loss: 0.6928981744817325
Epoch: 41 | Iteration number: [290/393] 73% | Training loss: 0.6928234926585494
Epoch: 41 | Iteration number: [300/393] 76% | Training loss: 0.692752835949262
Epoch: 41 | Iteration number: [310/393] 78% | Training loss: 0.6926871434334786
Epoch: 41 | Iteration number: [320/393] 81% | Training loss: 0.6926345966756344
Epoch: 41 | Iteration number: [330/393] 83% | Training loss: 0.6925455875468977
Epoch: 41 | Iteration number: [340/393] 86% | Training loss: 0.692482314916218
Epoch: 41 | Iteration number: [350/393] 89% | Training loss: 0.6924269483770643
Epoch: 41 | Iteration number: [360/393] 91% | Training loss: 0.6923679543866051
Epoch: 41 | Iteration number: [370/393] 94% | Training loss: 0.6922980661327774
Epoch: 41 | Iteration number: [380/393] 96% | Training loss: 0.6922597891406009
Epoch: 41 | Iteration number: [390/393] 99% | Training loss: 0.6922188202540079

 End of epoch: 41 | Train Loss: 0.6904600760105609 | Training Time: 66 

 End of epoch: 41 | Eval Loss: 0.6904201191298815 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/393] 2% | Training loss: 0.7595469176769256
Epoch: 42 | Iteration number: [20/393] 5% | Training loss: 0.7256663978099823
Epoch: 42 | Iteration number: [30/393] 7% | Training loss: 0.7139540990193685
Epoch: 42 | Iteration number: [40/393] 10% | Training loss: 0.7080305427312851
Epoch: 42 | Iteration number: [50/393] 12% | Training loss: 0.7044094288349152
Epoch: 42 | Iteration number: [60/393] 15% | Training loss: 0.7021033922831218
Epoch: 42 | Iteration number: [70/393] 17% | Training loss: 0.7004887095519474
Epoch: 42 | Iteration number: [80/393] 20% | Training loss: 0.6991934850811958
Epoch: 42 | Iteration number: [90/393] 22% | Training loss: 0.698222076230579
Epoch: 42 | Iteration number: [100/393] 25% | Training loss: 0.6974056029319763
Epoch: 42 | Iteration number: [110/393] 27% | Training loss: 0.6967238875952634
Epoch: 42 | Iteration number: [120/393] 30% | Training loss: 0.6961261187990506
Epoch: 42 | Iteration number: [130/393] 33% | Training loss: 0.6957816311946282
Epoch: 42 | Iteration number: [140/393] 35% | Training loss: 0.6954685977527073
Epoch: 42 | Iteration number: [150/393] 38% | Training loss: 0.6950910087426504
Epoch: 42 | Iteration number: [160/393] 40% | Training loss: 0.6948295589536428
Epoch: 42 | Iteration number: [170/393] 43% | Training loss: 0.6946008422795464
Epoch: 42 | Iteration number: [180/393] 45% | Training loss: 0.6943553851710426
Epoch: 42 | Iteration number: [190/393] 48% | Training loss: 0.6941192645775645
Epoch: 42 | Iteration number: [200/393] 50% | Training loss: 0.6939609867334365
Epoch: 42 | Iteration number: [210/393] 53% | Training loss: 0.6937810846737453
Epoch: 42 | Iteration number: [220/393] 55% | Training loss: 0.6936414474790746
Epoch: 42 | Iteration number: [230/393] 58% | Training loss: 0.693465430840202
Epoch: 42 | Iteration number: [240/393] 61% | Training loss: 0.6933378132681052
Epoch: 42 | Iteration number: [250/393] 63% | Training loss: 0.6932213468551636
Epoch: 42 | Iteration number: [260/393] 66% | Training loss: 0.6931367557782393
Epoch: 42 | Iteration number: [270/393] 68% | Training loss: 0.6930597994062636
Epoch: 42 | Iteration number: [280/393] 71% | Training loss: 0.6929596404944147
Epoch: 42 | Iteration number: [290/393] 73% | Training loss: 0.6928563524936807
Epoch: 42 | Iteration number: [300/393] 76% | Training loss: 0.692796763976415
Epoch: 42 | Iteration number: [310/393] 78% | Training loss: 0.6926972831449201
Epoch: 42 | Iteration number: [320/393] 81% | Training loss: 0.6926109099760651
Epoch: 42 | Iteration number: [330/393] 83% | Training loss: 0.692544821175662
Epoch: 42 | Iteration number: [340/393] 86% | Training loss: 0.6924708017531563
Epoch: 42 | Iteration number: [350/393] 89% | Training loss: 0.6924349328449794
Epoch: 42 | Iteration number: [360/393] 91% | Training loss: 0.6923489249414868
Epoch: 42 | Iteration number: [370/393] 94% | Training loss: 0.6922922292271176
Epoch: 42 | Iteration number: [380/393] 96% | Training loss: 0.6922497397974918
Epoch: 42 | Iteration number: [390/393] 99% | Training loss: 0.6922051171461742

 End of epoch: 42 | Train Loss: 0.6904246794965128 | Training Time: 66 

 End of epoch: 42 | Eval Loss: 0.6902608786310468 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/393] 2% | Training loss: 0.7604113519191742
Epoch: 43 | Iteration number: [20/393] 5% | Training loss: 0.7257762789726258
Epoch: 43 | Iteration number: [30/393] 7% | Training loss: 0.7139934678872426
Epoch: 43 | Iteration number: [40/393] 10% | Training loss: 0.7081455782055854
Epoch: 43 | Iteration number: [50/393] 12% | Training loss: 0.7046328020095826
Epoch: 43 | Iteration number: [60/393] 15% | Training loss: 0.7021991113821665
Epoch: 43 | Iteration number: [70/393] 17% | Training loss: 0.7006171541554588
Epoch: 43 | Iteration number: [80/393] 20% | Training loss: 0.6992927066981792
Epoch: 43 | Iteration number: [90/393] 22% | Training loss: 0.6983676685227288
Epoch: 43 | Iteration number: [100/393] 25% | Training loss: 0.6976561504602432
Epoch: 43 | Iteration number: [110/393] 27% | Training loss: 0.6968915191563693
Epoch: 43 | Iteration number: [120/393] 30% | Training loss: 0.6963536128401756
Epoch: 43 | Iteration number: [130/393] 33% | Training loss: 0.6959583089901851
Epoch: 43 | Iteration number: [140/393] 35% | Training loss: 0.6956221376146589
Epoch: 43 | Iteration number: [150/393] 38% | Training loss: 0.6952754831314087
Epoch: 43 | Iteration number: [160/393] 40% | Training loss: 0.6950196173042059
Epoch: 43 | Iteration number: [170/393] 43% | Training loss: 0.6948040425777435
Epoch: 43 | Iteration number: [180/393] 45% | Training loss: 0.694569174779786
Epoch: 43 | Iteration number: [190/393] 48% | Training loss: 0.6943913503697045
Epoch: 43 | Iteration number: [200/393] 50% | Training loss: 0.694166918694973
Epoch: 43 | Iteration number: [210/393] 53% | Training loss: 0.6940188598065149
Epoch: 43 | Iteration number: [220/393] 55% | Training loss: 0.6938202148134058
Epoch: 43 | Iteration number: [230/393] 58% | Training loss: 0.6936585916125256
Epoch: 43 | Iteration number: [240/393] 61% | Training loss: 0.6935034240285556
Epoch: 43 | Iteration number: [250/393] 63% | Training loss: 0.693349146604538
Epoch: 43 | Iteration number: [260/393] 66% | Training loss: 0.6931903958320618
Epoch: 43 | Iteration number: [270/393] 68% | Training loss: 0.6931047092985224
Epoch: 43 | Iteration number: [280/393] 71% | Training loss: 0.6930282609803337
Epoch: 43 | Iteration number: [290/393] 73% | Training loss: 0.692925507241282
Epoch: 43 | Iteration number: [300/393] 76% | Training loss: 0.6928387608130773
Epoch: 43 | Iteration number: [310/393] 78% | Training loss: 0.692689270934751
Epoch: 43 | Iteration number: [320/393] 81% | Training loss: 0.6926261672750116
Epoch: 43 | Iteration number: [330/393] 83% | Training loss: 0.6925463988925471
Epoch: 43 | Iteration number: [340/393] 86% | Training loss: 0.6924976140260697
Epoch: 43 | Iteration number: [350/393] 89% | Training loss: 0.6924286242893763
Epoch: 43 | Iteration number: [360/393] 91% | Training loss: 0.6923558488488197
Epoch: 43 | Iteration number: [370/393] 94% | Training loss: 0.6923127688266135
Epoch: 43 | Iteration number: [380/393] 96% | Training loss: 0.6922497178378858
Epoch: 43 | Iteration number: [390/393] 99% | Training loss: 0.6922469664842654

 End of epoch: 43 | Train Loss: 0.6904808672633184 | Training Time: 66 

 End of epoch: 43 | Eval Loss: 0.690433571533281 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/393] 2% | Training loss: 0.7583839952945709
Epoch: 44 | Iteration number: [20/393] 5% | Training loss: 0.724705719947815
Epoch: 44 | Iteration number: [30/393] 7% | Training loss: 0.7133804798126221
Epoch: 44 | Iteration number: [40/393] 10% | Training loss: 0.7075478792190552
Epoch: 44 | Iteration number: [50/393] 12% | Training loss: 0.7041703200340271
Epoch: 44 | Iteration number: [60/393] 15% | Training loss: 0.7018824696540833
Epoch: 44 | Iteration number: [70/393] 17% | Training loss: 0.7001103264944893
Epoch: 44 | Iteration number: [80/393] 20% | Training loss: 0.6988645739853382
Epoch: 44 | Iteration number: [90/393] 22% | Training loss: 0.6980002462863922
Epoch: 44 | Iteration number: [100/393] 25% | Training loss: 0.6971672886610031
Epoch: 44 | Iteration number: [110/393] 27% | Training loss: 0.6966413189064372
Epoch: 44 | Iteration number: [120/393] 30% | Training loss: 0.6961659381786982
Epoch: 44 | Iteration number: [130/393] 33% | Training loss: 0.6957533336602725
Epoch: 44 | Iteration number: [140/393] 35% | Training loss: 0.6954575159720012
Epoch: 44 | Iteration number: [150/393] 38% | Training loss: 0.6951903545856476
Epoch: 44 | Iteration number: [160/393] 40% | Training loss: 0.6949735797941685
Epoch: 44 | Iteration number: [170/393] 43% | Training loss: 0.6947455350090476
Epoch: 44 | Iteration number: [180/393] 45% | Training loss: 0.6946020358138614
Epoch: 44 | Iteration number: [190/393] 48% | Training loss: 0.6944239305822473
Epoch: 44 | Iteration number: [200/393] 50% | Training loss: 0.6942609405517578
Epoch: 44 | Iteration number: [210/393] 53% | Training loss: 0.6940873029686155
Epoch: 44 | Iteration number: [220/393] 55% | Training loss: 0.693927265568213
Epoch: 44 | Iteration number: [230/393] 58% | Training loss: 0.6938060006369715
Epoch: 44 | Iteration number: [240/393] 61% | Training loss: 0.6936800673604011
Epoch: 44 | Iteration number: [250/393] 63% | Training loss: 0.6935467023849488
Epoch: 44 | Iteration number: [260/393] 66% | Training loss: 0.6934151823704059
Epoch: 44 | Iteration number: [270/393] 68% | Training loss: 0.6933521429697672
Epoch: 44 | Iteration number: [280/393] 71% | Training loss: 0.6932493529149464
Epoch: 44 | Iteration number: [290/393] 73% | Training loss: 0.6930894584491335
Epoch: 44 | Iteration number: [300/393] 76% | Training loss: 0.6929713219404221
Epoch: 44 | Iteration number: [310/393] 78% | Training loss: 0.6928822950009377
Epoch: 44 | Iteration number: [320/393] 81% | Training loss: 0.6928501538932323
Epoch: 44 | Iteration number: [330/393] 83% | Training loss: 0.6927766102733034
Epoch: 44 | Iteration number: [340/393] 86% | Training loss: 0.6927206020144855
Epoch: 44 | Iteration number: [350/393] 89% | Training loss: 0.692650318145752
Epoch: 44 | Iteration number: [360/393] 91% | Training loss: 0.692567801144388
Epoch: 44 | Iteration number: [370/393] 94% | Training loss: 0.6925239637091353
Epoch: 44 | Iteration number: [380/393] 96% | Training loss: 0.6924665913770073
Epoch: 44 | Iteration number: [390/393] 99% | Training loss: 0.6924185945437504

 End of epoch: 44 | Train Loss: 0.6906600726469783 | Training Time: 67 

 End of epoch: 44 | Eval Loss: 0.6903919480284866 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/393] 2% | Training loss: 0.7594366729259491
Epoch: 45 | Iteration number: [20/393] 5% | Training loss: 0.7251244068145752
Epoch: 45 | Iteration number: [30/393] 7% | Training loss: 0.7135127305984497
Epoch: 45 | Iteration number: [40/393] 10% | Training loss: 0.7076425269246102
Epoch: 45 | Iteration number: [50/393] 12% | Training loss: 0.7042981731891632
Epoch: 45 | Iteration number: [60/393] 15% | Training loss: 0.702245847384135
Epoch: 45 | Iteration number: [70/393] 17% | Training loss: 0.7006773505892072
Epoch: 45 | Iteration number: [80/393] 20% | Training loss: 0.6992377445101738
Epoch: 45 | Iteration number: [90/393] 22% | Training loss: 0.6981841464837392
Epoch: 45 | Iteration number: [100/393] 25% | Training loss: 0.6973440045118332
Epoch: 45 | Iteration number: [110/393] 27% | Training loss: 0.6967035336927934
Epoch: 45 | Iteration number: [120/393] 30% | Training loss: 0.6961538329720497
Epoch: 45 | Iteration number: [130/393] 33% | Training loss: 0.6957800878928257
Epoch: 45 | Iteration number: [140/393] 35% | Training loss: 0.695412163223539
Epoch: 45 | Iteration number: [150/393] 38% | Training loss: 0.6950696102778117
Epoch: 45 | Iteration number: [160/393] 40% | Training loss: 0.6947586048394442
Epoch: 45 | Iteration number: [170/393] 43% | Training loss: 0.6944570888491238
Epoch: 45 | Iteration number: [180/393] 45% | Training loss: 0.6942256136073006
Epoch: 45 | Iteration number: [190/393] 48% | Training loss: 0.6940387110961111
Epoch: 45 | Iteration number: [200/393] 50% | Training loss: 0.6938948398828506
Epoch: 45 | Iteration number: [210/393] 53% | Training loss: 0.6936970038073403
Epoch: 45 | Iteration number: [220/393] 55% | Training loss: 0.6935505008155649
Epoch: 45 | Iteration number: [230/393] 58% | Training loss: 0.6934088110923767
Epoch: 45 | Iteration number: [240/393] 61% | Training loss: 0.693287671605746
Epoch: 45 | Iteration number: [250/393] 63% | Training loss: 0.693193708896637
Epoch: 45 | Iteration number: [260/393] 66% | Training loss: 0.6931075350596354
Epoch: 45 | Iteration number: [270/393] 68% | Training loss: 0.6929892120537935
Epoch: 45 | Iteration number: [280/393] 71% | Training loss: 0.6929271421262196
Epoch: 45 | Iteration number: [290/393] 73% | Training loss: 0.6928525256699529
Epoch: 45 | Iteration number: [300/393] 76% | Training loss: 0.6927937577168147
Epoch: 45 | Iteration number: [310/393] 78% | Training loss: 0.6927172820414266
Epoch: 45 | Iteration number: [320/393] 81% | Training loss: 0.6926289428025484
Epoch: 45 | Iteration number: [330/393] 83% | Training loss: 0.6925539908987103
Epoch: 45 | Iteration number: [340/393] 86% | Training loss: 0.6924704739276101
Epoch: 45 | Iteration number: [350/393] 89% | Training loss: 0.6924080080645425
Epoch: 45 | Iteration number: [360/393] 91% | Training loss: 0.6923260697060161
Epoch: 45 | Iteration number: [370/393] 94% | Training loss: 0.6922817718338322
Epoch: 45 | Iteration number: [380/393] 96% | Training loss: 0.6922349277295564
Epoch: 45 | Iteration number: [390/393] 99% | Training loss: 0.6921756074978755

 End of epoch: 45 | Train Loss: 0.6904119033243213 | Training Time: 67 

 End of epoch: 45 | Eval Loss: 0.690266913297225 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/393] 2% | Training loss: 0.7582213163375855
Epoch: 46 | Iteration number: [20/393] 5% | Training loss: 0.7244943767786026
Epoch: 46 | Iteration number: [30/393] 7% | Training loss: 0.7128566404183706
Epoch: 46 | Iteration number: [40/393] 10% | Training loss: 0.7071301937103271
Epoch: 46 | Iteration number: [50/393] 12% | Training loss: 0.7038496482372284
Epoch: 46 | Iteration number: [60/393] 15% | Training loss: 0.7016355633735657
Epoch: 46 | Iteration number: [70/393] 17% | Training loss: 0.7000901290348598
Epoch: 46 | Iteration number: [80/393] 20% | Training loss: 0.6988661669194698
Epoch: 46 | Iteration number: [90/393] 22% | Training loss: 0.6980972005261316
Epoch: 46 | Iteration number: [100/393] 25% | Training loss: 0.6972730195522309
Epoch: 46 | Iteration number: [110/393] 27% | Training loss: 0.6966533872214231
Epoch: 46 | Iteration number: [120/393] 30% | Training loss: 0.6962367216746013
Epoch: 46 | Iteration number: [130/393] 33% | Training loss: 0.6957343138181247
Epoch: 46 | Iteration number: [140/393] 35% | Training loss: 0.6952358279909406
Epoch: 46 | Iteration number: [150/393] 38% | Training loss: 0.6949178528785706
Epoch: 46 | Iteration number: [160/393] 40% | Training loss: 0.6946781311184168
Epoch: 46 | Iteration number: [170/393] 43% | Training loss: 0.6944277514429653
Epoch: 46 | Iteration number: [180/393] 45% | Training loss: 0.6942416740788354
Epoch: 46 | Iteration number: [190/393] 48% | Training loss: 0.6940273002574319
Epoch: 46 | Iteration number: [200/393] 50% | Training loss: 0.6938900199532508
Epoch: 46 | Iteration number: [210/393] 53% | Training loss: 0.6937120766866774
Epoch: 46 | Iteration number: [220/393] 55% | Training loss: 0.6935541982000525
Epoch: 46 | Iteration number: [230/393] 58% | Training loss: 0.6934194323809251
Epoch: 46 | Iteration number: [240/393] 61% | Training loss: 0.6933023554583391
Epoch: 46 | Iteration number: [250/393] 63% | Training loss: 0.6931661667823792
Epoch: 46 | Iteration number: [260/393] 66% | Training loss: 0.6930726626744637
Epoch: 46 | Iteration number: [270/393] 68% | Training loss: 0.6930008934603797
Epoch: 46 | Iteration number: [280/393] 71% | Training loss: 0.6928981898086412
Epoch: 46 | Iteration number: [290/393] 73% | Training loss: 0.6928314017838445
Epoch: 46 | Iteration number: [300/393] 76% | Training loss: 0.6927228091160457
Epoch: 46 | Iteration number: [310/393] 78% | Training loss: 0.6926632444704732
Epoch: 46 | Iteration number: [320/393] 81% | Training loss: 0.6926075125113129
Epoch: 46 | Iteration number: [330/393] 83% | Training loss: 0.6925695424730127
Epoch: 46 | Iteration number: [340/393] 86% | Training loss: 0.692523827272303
Epoch: 46 | Iteration number: [350/393] 89% | Training loss: 0.6924616777896881
Epoch: 46 | Iteration number: [360/393] 91% | Training loss: 0.6923894228206741
Epoch: 46 | Iteration number: [370/393] 94% | Training loss: 0.6923062469508197
Epoch: 46 | Iteration number: [380/393] 96% | Training loss: 0.6922416458004399
Epoch: 46 | Iteration number: [390/393] 99% | Training loss: 0.6921829382578532

 End of epoch: 46 | Train Loss: 0.6904146427113288 | Training Time: 66 

 End of epoch: 46 | Eval Loss: 0.6901431229649758 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/393] 2% | Training loss: 0.7581971347332
Epoch: 47 | Iteration number: [20/393] 5% | Training loss: 0.7243402451276779
Epoch: 47 | Iteration number: [30/393] 7% | Training loss: 0.7129991869131724
Epoch: 47 | Iteration number: [40/393] 10% | Training loss: 0.7070784643292427
Epoch: 47 | Iteration number: [50/393] 12% | Training loss: 0.7038672685623169
Epoch: 47 | Iteration number: [60/393] 15% | Training loss: 0.7015893965959549
Epoch: 47 | Iteration number: [70/393] 17% | Training loss: 0.700051646573203
Epoch: 47 | Iteration number: [80/393] 20% | Training loss: 0.6988895297050476
Epoch: 47 | Iteration number: [90/393] 22% | Training loss: 0.6978259881337484
Epoch: 47 | Iteration number: [100/393] 25% | Training loss: 0.6970905065536499
Epoch: 47 | Iteration number: [110/393] 27% | Training loss: 0.6965410243381154
Epoch: 47 | Iteration number: [120/393] 30% | Training loss: 0.695946249862512
Epoch: 47 | Iteration number: [130/393] 33% | Training loss: 0.6955542275538811
Epoch: 47 | Iteration number: [140/393] 35% | Training loss: 0.6951467313936779
Epoch: 47 | Iteration number: [150/393] 38% | Training loss: 0.6948413447539011
Epoch: 47 | Iteration number: [160/393] 40% | Training loss: 0.6945298995822669
Epoch: 47 | Iteration number: [170/393] 43% | Training loss: 0.6943461130647098
Epoch: 47 | Iteration number: [180/393] 45% | Training loss: 0.6941012402375539
Epoch: 47 | Iteration number: [190/393] 48% | Training loss: 0.6938997428668173
Epoch: 47 | Iteration number: [200/393] 50% | Training loss: 0.6937428379058838
Epoch: 47 | Iteration number: [210/393] 53% | Training loss: 0.6935661100205921
Epoch: 47 | Iteration number: [220/393] 55% | Training loss: 0.6934397803111509
Epoch: 47 | Iteration number: [230/393] 58% | Training loss: 0.6933536444021308
Epoch: 47 | Iteration number: [240/393] 61% | Training loss: 0.6932257605095704
Epoch: 47 | Iteration number: [250/393] 63% | Training loss: 0.6930973434448242
Epoch: 47 | Iteration number: [260/393] 66% | Training loss: 0.6930584648480782
Epoch: 47 | Iteration number: [270/393] 68% | Training loss: 0.6929788719724725
Epoch: 47 | Iteration number: [280/393] 71% | Training loss: 0.6928838638322694
Epoch: 47 | Iteration number: [290/393] 73% | Training loss: 0.6928288433058508
Epoch: 47 | Iteration number: [300/393] 76% | Training loss: 0.6927572679519653
Epoch: 47 | Iteration number: [310/393] 78% | Training loss: 0.6926582680594536
Epoch: 47 | Iteration number: [320/393] 81% | Training loss: 0.6926009401679039
Epoch: 47 | Iteration number: [330/393] 83% | Training loss: 0.6925159942020069
Epoch: 47 | Iteration number: [340/393] 86% | Training loss: 0.692448332379846
Epoch: 47 | Iteration number: [350/393] 89% | Training loss: 0.6924201711586544
Epoch: 47 | Iteration number: [360/393] 91% | Training loss: 0.6923858230312665
Epoch: 47 | Iteration number: [370/393] 94% | Training loss: 0.6923407876813734
Epoch: 47 | Iteration number: [380/393] 96% | Training loss: 0.6922879256700215
Epoch: 47 | Iteration number: [390/393] 99% | Training loss: 0.692222823546483

 End of epoch: 47 | Train Loss: 0.6904648783552738 | Training Time: 66 

 End of epoch: 47 | Eval Loss: 0.6903563798690329 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/393] 2% | Training loss: 0.7592637062072753
Epoch: 48 | Iteration number: [20/393] 5% | Training loss: 0.7247756779193878
Epoch: 48 | Iteration number: [30/393] 7% | Training loss: 0.7132296363512675
Epoch: 48 | Iteration number: [40/393] 10% | Training loss: 0.7076297387480736
Epoch: 48 | Iteration number: [50/393] 12% | Training loss: 0.7044874286651611
Epoch: 48 | Iteration number: [60/393] 15% | Training loss: 0.7023372312386831
Epoch: 48 | Iteration number: [70/393] 17% | Training loss: 0.7005868639264788
Epoch: 48 | Iteration number: [80/393] 20% | Training loss: 0.6992823101580143
Epoch: 48 | Iteration number: [90/393] 22% | Training loss: 0.6983414583735996
Epoch: 48 | Iteration number: [100/393] 25% | Training loss: 0.6975507658720016
Epoch: 48 | Iteration number: [110/393] 27% | Training loss: 0.6968311071395874
Epoch: 48 | Iteration number: [120/393] 30% | Training loss: 0.6962580507000288
Epoch: 48 | Iteration number: [130/393] 33% | Training loss: 0.6957839356018947
Epoch: 48 | Iteration number: [140/393] 35% | Training loss: 0.6954585828951427
Epoch: 48 | Iteration number: [150/393] 38% | Training loss: 0.6951869976520538
Epoch: 48 | Iteration number: [160/393] 40% | Training loss: 0.6949189338833094
Epoch: 48 | Iteration number: [170/393] 43% | Training loss: 0.6946975711513969
Epoch: 48 | Iteration number: [180/393] 45% | Training loss: 0.69444164302614
Epoch: 48 | Iteration number: [190/393] 48% | Training loss: 0.6942118026708302
Epoch: 48 | Iteration number: [200/393] 50% | Training loss: 0.6939548709988594
Epoch: 48 | Iteration number: [210/393] 53% | Training loss: 0.6937333498682294
Epoch: 48 | Iteration number: [220/393] 55% | Training loss: 0.6935973869128661
Epoch: 48 | Iteration number: [230/393] 58% | Training loss: 0.6934061159258303
Epoch: 48 | Iteration number: [240/393] 61% | Training loss: 0.6932776406407356
Epoch: 48 | Iteration number: [250/393] 63% | Training loss: 0.6931991834640503
Epoch: 48 | Iteration number: [260/393] 66% | Training loss: 0.6930561686937625
Epoch: 48 | Iteration number: [270/393] 68% | Training loss: 0.6929859112810206
Epoch: 48 | Iteration number: [280/393] 71% | Training loss: 0.6929307892918587
Epoch: 48 | Iteration number: [290/393] 73% | Training loss: 0.6928728751067458
Epoch: 48 | Iteration number: [300/393] 76% | Training loss: 0.6928182647625605
Epoch: 48 | Iteration number: [310/393] 78% | Training loss: 0.6927465254260647
Epoch: 48 | Iteration number: [320/393] 81% | Training loss: 0.6926580991595983
Epoch: 48 | Iteration number: [330/393] 83% | Training loss: 0.6925937583952239
Epoch: 48 | Iteration number: [340/393] 86% | Training loss: 0.6925422484383864
Epoch: 48 | Iteration number: [350/393] 89% | Training loss: 0.6924366906711034
Epoch: 48 | Iteration number: [360/393] 91% | Training loss: 0.6923694185084767
Epoch: 48 | Iteration number: [370/393] 94% | Training loss: 0.6923190050833934
Epoch: 48 | Iteration number: [380/393] 96% | Training loss: 0.69229064207328
Epoch: 48 | Iteration number: [390/393] 99% | Training loss: 0.6922486786658947

 End of epoch: 48 | Train Loss: 0.6904797739048344 | Training Time: 66 

 End of epoch: 48 | Eval Loss: 0.6901727026822616 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/393] 2% | Training loss: 0.7593204259872437
Epoch: 49 | Iteration number: [20/393] 5% | Training loss: 0.7246113121509552
Epoch: 49 | Iteration number: [30/393] 7% | Training loss: 0.7131636142730713
Epoch: 49 | Iteration number: [40/393] 10% | Training loss: 0.7077024638652801
Epoch: 49 | Iteration number: [50/393] 12% | Training loss: 0.704407434463501
Epoch: 49 | Iteration number: [60/393] 15% | Training loss: 0.7017780383427937
Epoch: 49 | Iteration number: [70/393] 17% | Training loss: 0.70033016034535
Epoch: 49 | Iteration number: [80/393] 20% | Training loss: 0.6990317508578301
Epoch: 49 | Iteration number: [90/393] 22% | Training loss: 0.6981126884619395
Epoch: 49 | Iteration number: [100/393] 25% | Training loss: 0.6974708437919617
Epoch: 49 | Iteration number: [110/393] 27% | Training loss: 0.6969341120936654
Epoch: 49 | Iteration number: [120/393] 30% | Training loss: 0.6963543410102526
Epoch: 49 | Iteration number: [130/393] 33% | Training loss: 0.6958785400940821
Epoch: 49 | Iteration number: [140/393] 35% | Training loss: 0.6955280636038099
Epoch: 49 | Iteration number: [150/393] 38% | Training loss: 0.6951236665248871
Epoch: 49 | Iteration number: [160/393] 40% | Training loss: 0.694780845940113
Epoch: 49 | Iteration number: [170/393] 43% | Training loss: 0.694536896312938
Epoch: 49 | Iteration number: [180/393] 45% | Training loss: 0.6943199406067531
Epoch: 49 | Iteration number: [190/393] 48% | Training loss: 0.6941070842115502
Epoch: 49 | Iteration number: [200/393] 50% | Training loss: 0.6939649817347526
Epoch: 49 | Iteration number: [210/393] 53% | Training loss: 0.6938270273662749
Epoch: 49 | Iteration number: [220/393] 55% | Training loss: 0.6936650636521253
Epoch: 49 | Iteration number: [230/393] 58% | Training loss: 0.6934989268365114
Epoch: 49 | Iteration number: [240/393] 61% | Training loss: 0.6933096192777157
Epoch: 49 | Iteration number: [250/393] 63% | Training loss: 0.6931809728145599
Epoch: 49 | Iteration number: [260/393] 66% | Training loss: 0.6930730395592176
Epoch: 49 | Iteration number: [270/393] 68% | Training loss: 0.6929791276101713
Epoch: 49 | Iteration number: [280/393] 71% | Training loss: 0.6928748356444495
Epoch: 49 | Iteration number: [290/393] 73% | Training loss: 0.6928006126962859
Epoch: 49 | Iteration number: [300/393] 76% | Training loss: 0.6927173690001169
Epoch: 49 | Iteration number: [310/393] 78% | Training loss: 0.6925921307456109
Epoch: 49 | Iteration number: [320/393] 81% | Training loss: 0.6925458827987313
Epoch: 49 | Iteration number: [330/393] 83% | Training loss: 0.6924968284187895
Epoch: 49 | Iteration number: [340/393] 86% | Training loss: 0.6924503715599284
Epoch: 49 | Iteration number: [350/393] 89% | Training loss: 0.6923803927217211
Epoch: 49 | Iteration number: [360/393] 91% | Training loss: 0.6923303397165405
Epoch: 49 | Iteration number: [370/393] 94% | Training loss: 0.6922918840034588
Epoch: 49 | Iteration number: [380/393] 96% | Training loss: 0.6922329177981928
Epoch: 49 | Iteration number: [390/393] 99% | Training loss: 0.69219160202222

 End of epoch: 49 | Train Loss: 0.6904159684217613 | Training Time: 66 

 End of epoch: 49 | Eval Loss: 0.6903356763781333 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/393] 2% | Training loss: 0.7584782361984252
Epoch: 50 | Iteration number: [20/393] 5% | Training loss: 0.7241367191076279
Epoch: 50 | Iteration number: [30/393] 7% | Training loss: 0.7128079692522685
Epoch: 50 | Iteration number: [40/393] 10% | Training loss: 0.7070464879274369
Epoch: 50 | Iteration number: [50/393] 12% | Training loss: 0.7038364458084106
Epoch: 50 | Iteration number: [60/393] 15% | Training loss: 0.7016475766897201
Epoch: 50 | Iteration number: [70/393] 17% | Training loss: 0.7002763501235417
Epoch: 50 | Iteration number: [80/393] 20% | Training loss: 0.6988992013037205
Epoch: 50 | Iteration number: [90/393] 22% | Training loss: 0.6978960235913595
Epoch: 50 | Iteration number: [100/393] 25% | Training loss: 0.6972269463539124
Epoch: 50 | Iteration number: [110/393] 27% | Training loss: 0.6965133341875943
Epoch: 50 | Iteration number: [120/393] 30% | Training loss: 0.695998732248942
Epoch: 50 | Iteration number: [130/393] 33% | Training loss: 0.6956168390237368
Epoch: 50 | Iteration number: [140/393] 35% | Training loss: 0.6953348789896284
Epoch: 50 | Iteration number: [150/393] 38% | Training loss: 0.6950511109828948
Epoch: 50 | Iteration number: [160/393] 40% | Training loss: 0.6947993904352188
Epoch: 50 | Iteration number: [170/393] 43% | Training loss: 0.6945568435332354
Epoch: 50 | Iteration number: [180/393] 45% | Training loss: 0.6943354580137465
Epoch: 50 | Iteration number: [190/393] 48% | Training loss: 0.6940398225658818
Epoch: 50 | Iteration number: [200/393] 50% | Training loss: 0.6938705062866211
Epoch: 50 | Iteration number: [210/393] 53% | Training loss: 0.6937204128219968
Epoch: 50 | Iteration number: [220/393] 55% | Training loss: 0.6935677203265104
Epoch: 50 | Iteration number: [230/393] 58% | Training loss: 0.693472163055254
Epoch: 50 | Iteration number: [240/393] 61% | Training loss: 0.6933638942738374
Epoch: 50 | Iteration number: [250/393] 63% | Training loss: 0.6932451300621033
Epoch: 50 | Iteration number: [260/393] 66% | Training loss: 0.6931425034999847
Epoch: 50 | Iteration number: [270/393] 68% | Training loss: 0.693075857118324
Epoch: 50 | Iteration number: [280/393] 71% | Training loss: 0.692998281121254
Epoch: 50 | Iteration number: [290/393] 73% | Training loss: 0.6929240202081615
Epoch: 50 | Iteration number: [300/393] 76% | Training loss: 0.6927944000562032
Epoch: 50 | Iteration number: [310/393] 78% | Training loss: 0.6927283785035533
Epoch: 50 | Iteration number: [320/393] 81% | Training loss: 0.6926248420029879
Epoch: 50 | Iteration number: [330/393] 83% | Training loss: 0.6925610517010544
Epoch: 50 | Iteration number: [340/393] 86% | Training loss: 0.692503003337804
Epoch: 50 | Iteration number: [350/393] 89% | Training loss: 0.6924442286150796
Epoch: 50 | Iteration number: [360/393] 91% | Training loss: 0.6923888421720928
Epoch: 50 | Iteration number: [370/393] 94% | Training loss: 0.6923395063426043
Epoch: 50 | Iteration number: [380/393] 96% | Training loss: 0.6922819010521236
Epoch: 50 | Iteration number: [390/393] 99% | Training loss: 0.6922273301161253

 End of epoch: 50 | Train Loss: 0.6904671234635603 | Training Time: 66 

 End of epoch: 50 | Eval Loss: 0.6901589875318566 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/393] 2% | Training loss: 0.7586640477180481
Epoch: 51 | Iteration number: [20/393] 5% | Training loss: 0.724571606516838
Epoch: 51 | Iteration number: [30/393] 7% | Training loss: 0.7134875456492106
Epoch: 51 | Iteration number: [40/393] 10% | Training loss: 0.7077754184603691
Epoch: 51 | Iteration number: [50/393] 12% | Training loss: 0.7043817043304443
Epoch: 51 | Iteration number: [60/393] 15% | Training loss: 0.7019620488087336
Epoch: 51 | Iteration number: [70/393] 17% | Training loss: 0.7002247018473489
Epoch: 51 | Iteration number: [80/393] 20% | Training loss: 0.6990144655108452
Epoch: 51 | Iteration number: [90/393] 22% | Training loss: 0.698206118742625
Epoch: 51 | Iteration number: [100/393] 25% | Training loss: 0.6974956804513931
Epoch: 51 | Iteration number: [110/393] 27% | Training loss: 0.6969506090337579
Epoch: 51 | Iteration number: [120/393] 30% | Training loss: 0.6963641891876856
Epoch: 51 | Iteration number: [130/393] 33% | Training loss: 0.6958374170156626
Epoch: 51 | Iteration number: [140/393] 35% | Training loss: 0.6954322291272027
Epoch: 51 | Iteration number: [150/393] 38% | Training loss: 0.6950501533349355
Epoch: 51 | Iteration number: [160/393] 40% | Training loss: 0.6947750236839056
Epoch: 51 | Iteration number: [170/393] 43% | Training loss: 0.6945397969554452
Epoch: 51 | Iteration number: [180/393] 45% | Training loss: 0.6942970782518387
Epoch: 51 | Iteration number: [190/393] 48% | Training loss: 0.6940769048113572
Epoch: 51 | Iteration number: [200/393] 50% | Training loss: 0.6939255982637406
Epoch: 51 | Iteration number: [210/393] 53% | Training loss: 0.6937105749334608
Epoch: 51 | Iteration number: [220/393] 55% | Training loss: 0.6935598248785192
Epoch: 51 | Iteration number: [230/393] 58% | Training loss: 0.6934214975522912
Epoch: 51 | Iteration number: [240/393] 61% | Training loss: 0.6933356583118438
Epoch: 51 | Iteration number: [250/393] 63% | Training loss: 0.6932285180091858
Epoch: 51 | Iteration number: [260/393] 66% | Training loss: 0.6931576611903998
Epoch: 51 | Iteration number: [270/393] 68% | Training loss: 0.6930431619838432
Epoch: 51 | Iteration number: [280/393] 71% | Training loss: 0.6929271310567856
Epoch: 51 | Iteration number: [290/393] 73% | Training loss: 0.6928314642659549
Epoch: 51 | Iteration number: [300/393] 76% | Training loss: 0.6927635540564855
Epoch: 51 | Iteration number: [310/393] 78% | Training loss: 0.6926618956750439
Epoch: 51 | Iteration number: [320/393] 81% | Training loss: 0.6925915479660034
Epoch: 51 | Iteration number: [330/393] 83% | Training loss: 0.6925291646610606
Epoch: 51 | Iteration number: [340/393] 86% | Training loss: 0.6924465775489808
Epoch: 51 | Iteration number: [350/393] 89% | Training loss: 0.6923663832460131
Epoch: 51 | Iteration number: [360/393] 91% | Training loss: 0.6923062374194463
Epoch: 51 | Iteration number: [370/393] 94% | Training loss: 0.6922651060529658
Epoch: 51 | Iteration number: [380/393] 96% | Training loss: 0.692199581861496
Epoch: 51 | Iteration number: [390/393] 99% | Training loss: 0.6921116017378294

 End of epoch: 51 | Train Loss: 0.690336222412022 | Training Time: 66 

 End of epoch: 51 | Eval Loss: 0.6902604613985334 | Evaluating Time: 17 
Epoch: 52 | Iteration number: [10/393] 2% | Training loss: 0.7583187162876129
Epoch: 52 | Iteration number: [20/393] 5% | Training loss: 0.7244468957185746
Epoch: 52 | Iteration number: [30/393] 7% | Training loss: 0.7131653010845185
Epoch: 52 | Iteration number: [40/393] 10% | Training loss: 0.7076940208673477
Epoch: 52 | Iteration number: [50/393] 12% | Training loss: 0.7043364727497101
Epoch: 52 | Iteration number: [60/393] 15% | Training loss: 0.7021022876103719
Epoch: 52 | Iteration number: [70/393] 17% | Training loss: 0.7003921610968453
Epoch: 52 | Iteration number: [80/393] 20% | Training loss: 0.6990553461015224
Epoch: 52 | Iteration number: [90/393] 22% | Training loss: 0.6981271558337742
Epoch: 52 | Iteration number: [100/393] 25% | Training loss: 0.6973580628633499
Epoch: 52 | Iteration number: [110/393] 27% | Training loss: 0.696749580448324
Epoch: 52 | Iteration number: [120/393] 30% | Training loss: 0.6963145400087039
Epoch: 52 | Iteration number: [130/393] 33% | Training loss: 0.6958300847273606
Epoch: 52 | Iteration number: [140/393] 35% | Training loss: 0.6953712403774261
Epoch: 52 | Iteration number: [150/393] 38% | Training loss: 0.6950638651847839
Epoch: 52 | Iteration number: [160/393] 40% | Training loss: 0.6947146270424127
Epoch: 52 | Iteration number: [170/393] 43% | Training loss: 0.6944706012220944
Epoch: 52 | Iteration number: [180/393] 45% | Training loss: 0.6942610674434238
Epoch: 52 | Iteration number: [190/393] 48% | Training loss: 0.6940419272372597
Epoch: 52 | Iteration number: [200/393] 50% | Training loss: 0.6938611999154091
Epoch: 52 | Iteration number: [210/393] 53% | Training loss: 0.6936532381035033
Epoch: 52 | Iteration number: [220/393] 55% | Training loss: 0.6935379572890021
Epoch: 52 | Iteration number: [230/393] 58% | Training loss: 0.6934098279994467
Epoch: 52 | Iteration number: [240/393] 61% | Training loss: 0.693294087300698
Epoch: 52 | Iteration number: [250/393] 63% | Training loss: 0.6931812665462493
Epoch: 52 | Iteration number: [260/393] 66% | Training loss: 0.6930729049902696
Epoch: 52 | Iteration number: [270/393] 68% | Training loss: 0.692986281492092
Epoch: 52 | Iteration number: [280/393] 71% | Training loss: 0.6929298681872231
Epoch: 52 | Iteration number: [290/393] 73% | Training loss: 0.6928394732804134
Epoch: 52 | Iteration number: [300/393] 76% | Training loss: 0.6927596304814021
Epoch: 52 | Iteration number: [310/393] 78% | Training loss: 0.6926692491577517
Epoch: 52 | Iteration number: [320/393] 81% | Training loss: 0.6925774583593011
Epoch: 52 | Iteration number: [330/393] 83% | Training loss: 0.6924959534948523
Epoch: 52 | Iteration number: [340/393] 86% | Training loss: 0.6924349646357929
Epoch: 52 | Iteration number: [350/393] 89% | Training loss: 0.6923889136314392
Epoch: 52 | Iteration number: [360/393] 91% | Training loss: 0.6923090005914371
Epoch: 52 | Iteration number: [370/393] 94% | Training loss: 0.6922822696131629
Epoch: 52 | Iteration number: [380/393] 96% | Training loss: 0.692257020504851
Epoch: 52 | Iteration number: [390/393] 99% | Training loss: 0.6922303869174077

 End of epoch: 52 | Train Loss: 0.6904611517758164 | Training Time: 67 

 End of epoch: 52 | Eval Loss: 0.6901845165661403 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/393] 2% | Training loss: 0.7598422944545746
Epoch: 53 | Iteration number: [20/393] 5% | Training loss: 0.7253651529550552
Epoch: 53 | Iteration number: [30/393] 7% | Training loss: 0.7138224085172017
Epoch: 53 | Iteration number: [40/393] 10% | Training loss: 0.7080744937062263
Epoch: 53 | Iteration number: [50/393] 12% | Training loss: 0.7047622370719909
Epoch: 53 | Iteration number: [60/393] 15% | Training loss: 0.7023776809374491
Epoch: 53 | Iteration number: [70/393] 17% | Training loss: 0.7005614927836827
Epoch: 53 | Iteration number: [80/393] 20% | Training loss: 0.6993078261613845
Epoch: 53 | Iteration number: [90/393] 22% | Training loss: 0.6983121805720859
Epoch: 53 | Iteration number: [100/393] 25% | Training loss: 0.6974263846874237
Epoch: 53 | Iteration number: [110/393] 27% | Training loss: 0.6967252064834941
Epoch: 53 | Iteration number: [120/393] 30% | Training loss: 0.6962042704224587
Epoch: 53 | Iteration number: [130/393] 33% | Training loss: 0.6957471696230081
Epoch: 53 | Iteration number: [140/393] 35% | Training loss: 0.6953313286815371
Epoch: 53 | Iteration number: [150/393] 38% | Training loss: 0.6949297006924947
Epoch: 53 | Iteration number: [160/393] 40% | Training loss: 0.6946803566068411
Epoch: 53 | Iteration number: [170/393] 43% | Training loss: 0.6944711474811329
Epoch: 53 | Iteration number: [180/393] 45% | Training loss: 0.694192287325859
Epoch: 53 | Iteration number: [190/393] 48% | Training loss: 0.6940027230664303
Epoch: 53 | Iteration number: [200/393] 50% | Training loss: 0.6938292130827903
Epoch: 53 | Iteration number: [210/393] 53% | Training loss: 0.6936670743283772
Epoch: 53 | Iteration number: [220/393] 55% | Training loss: 0.6935031175613403
Epoch: 53 | Iteration number: [230/393] 58% | Training loss: 0.6933815660684005
Epoch: 53 | Iteration number: [240/393] 61% | Training loss: 0.6932167145113151
Epoch: 53 | Iteration number: [250/393] 63% | Training loss: 0.693083988904953
Epoch: 53 | Iteration number: [260/393] 66% | Training loss: 0.6929816789351977
Epoch: 53 | Iteration number: [270/393] 68% | Training loss: 0.6928778164916568
Epoch: 53 | Iteration number: [280/393] 71% | Training loss: 0.6927999722106116
Epoch: 53 | Iteration number: [290/393] 73% | Training loss: 0.6926884589524105
Epoch: 53 | Iteration number: [300/393] 76% | Training loss: 0.6926263384024303
Epoch: 53 | Iteration number: [310/393] 78% | Training loss: 0.6925513384803649
Epoch: 53 | Iteration number: [320/393] 81% | Training loss: 0.6925145059823989
Epoch: 53 | Iteration number: [330/393] 83% | Training loss: 0.6924626198681918
Epoch: 53 | Iteration number: [340/393] 86% | Training loss: 0.6923944517093547
Epoch: 53 | Iteration number: [350/393] 89% | Training loss: 0.6923195418289729
Epoch: 53 | Iteration number: [360/393] 91% | Training loss: 0.6922788512375619
Epoch: 53 | Iteration number: [370/393] 94% | Training loss: 0.6922354814168569
Epoch: 53 | Iteration number: [380/393] 96% | Training loss: 0.6921821476597535
Epoch: 53 | Iteration number: [390/393] 99% | Training loss: 0.6921299355152326

 End of epoch: 53 | Train Loss: 0.6903660380809968 | Training Time: 66 

 End of epoch: 53 | Eval Loss: 0.6901619969582071 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/393] 2% | Training loss: 0.7599562764167785
Epoch: 54 | Iteration number: [20/393] 5% | Training loss: 0.7251243710517883
Epoch: 54 | Iteration number: [30/393] 7% | Training loss: 0.7134441117445628
Epoch: 54 | Iteration number: [40/393] 10% | Training loss: 0.7076995208859443
Epoch: 54 | Iteration number: [50/393] 12% | Training loss: 0.7043767893314361
Epoch: 54 | Iteration number: [60/393] 15% | Training loss: 0.7019104351600011
Epoch: 54 | Iteration number: [70/393] 17% | Training loss: 0.7001387817519051
Epoch: 54 | Iteration number: [80/393] 20% | Training loss: 0.6989162810146808
Epoch: 54 | Iteration number: [90/393] 22% | Training loss: 0.6979211476114061
Epoch: 54 | Iteration number: [100/393] 25% | Training loss: 0.6972547572851181
Epoch: 54 | Iteration number: [110/393] 27% | Training loss: 0.6966253215616399
Epoch: 54 | Iteration number: [120/393] 30% | Training loss: 0.6960883071025212
Epoch: 54 | Iteration number: [130/393] 33% | Training loss: 0.6956598199330843
Epoch: 54 | Iteration number: [140/393] 35% | Training loss: 0.695200817499842
Epoch: 54 | Iteration number: [150/393] 38% | Training loss: 0.6948948673407237
Epoch: 54 | Iteration number: [160/393] 40% | Training loss: 0.6945887967944145
Epoch: 54 | Iteration number: [170/393] 43% | Training loss: 0.6943728075307958
Epoch: 54 | Iteration number: [180/393] 45% | Training loss: 0.6941453125741747
Epoch: 54 | Iteration number: [190/393] 48% | Training loss: 0.6939703138251053
Epoch: 54 | Iteration number: [200/393] 50% | Training loss: 0.6938084506988526
Epoch: 54 | Iteration number: [210/393] 53% | Training loss: 0.693658439318339
Epoch: 54 | Iteration number: [220/393] 55% | Training loss: 0.6935307039455934
Epoch: 54 | Iteration number: [230/393] 58% | Training loss: 0.6934019601863364
Epoch: 54 | Iteration number: [240/393] 61% | Training loss: 0.6932611299057801
Epoch: 54 | Iteration number: [250/393] 63% | Training loss: 0.6931075162887573
Epoch: 54 | Iteration number: [260/393] 66% | Training loss: 0.693022590646377
Epoch: 54 | Iteration number: [270/393] 68% | Training loss: 0.6929267081949446
Epoch: 54 | Iteration number: [280/393] 71% | Training loss: 0.6928331147347178
Epoch: 54 | Iteration number: [290/393] 73% | Training loss: 0.6927405250483546
Epoch: 54 | Iteration number: [300/393] 76% | Training loss: 0.6926495772600174
Epoch: 54 | Iteration number: [310/393] 78% | Training loss: 0.692616266973557
Epoch: 54 | Iteration number: [320/393] 81% | Training loss: 0.6925189938396216
Epoch: 54 | Iteration number: [330/393] 83% | Training loss: 0.6924254551078334
Epoch: 54 | Iteration number: [340/393] 86% | Training loss: 0.692407324033625
Epoch: 54 | Iteration number: [350/393] 89% | Training loss: 0.6923724869319371
Epoch: 54 | Iteration number: [360/393] 91% | Training loss: 0.6923318990402751
Epoch: 54 | Iteration number: [370/393] 94% | Training loss: 0.6922701579493445
Epoch: 54 | Iteration number: [380/393] 96% | Training loss: 0.692238091795068
Epoch: 54 | Iteration number: [390/393] 99% | Training loss: 0.6921664587962322

 End of epoch: 54 | Train Loss: 0.6903970196046902 | Training Time: 66 

 End of epoch: 54 | Eval Loss: 0.6902442647486317 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/393] 2% | Training loss: 0.7596059083938599
Epoch: 55 | Iteration number: [20/393] 5% | Training loss: 0.725361755490303
Epoch: 55 | Iteration number: [30/393] 7% | Training loss: 0.7136436998844147
Epoch: 55 | Iteration number: [40/393] 10% | Training loss: 0.7079732969403267
Epoch: 55 | Iteration number: [50/393] 12% | Training loss: 0.704637953042984
Epoch: 55 | Iteration number: [60/393] 15% | Training loss: 0.70217038889726
Epoch: 55 | Iteration number: [70/393] 17% | Training loss: 0.7004791728087834
Epoch: 55 | Iteration number: [80/393] 20% | Training loss: 0.6991729594767093
Epoch: 55 | Iteration number: [90/393] 22% | Training loss: 0.6981195251146952
Epoch: 55 | Iteration number: [100/393] 25% | Training loss: 0.6973063981533051
Epoch: 55 | Iteration number: [110/393] 27% | Training loss: 0.6966419387947429
Epoch: 55 | Iteration number: [120/393] 30% | Training loss: 0.6960629974802335
Epoch: 55 | Iteration number: [130/393] 33% | Training loss: 0.695636724967223
Epoch: 55 | Iteration number: [140/393] 35% | Training loss: 0.6952842980623245
Epoch: 55 | Iteration number: [150/393] 38% | Training loss: 0.6950063518683116
Epoch: 55 | Iteration number: [160/393] 40% | Training loss: 0.6946653898805379
Epoch: 55 | Iteration number: [170/393] 43% | Training loss: 0.6944563711390775
Epoch: 55 | Iteration number: [180/393] 45% | Training loss: 0.6942173259125816
Epoch: 55 | Iteration number: [190/393] 48% | Training loss: 0.6939714519601119
Epoch: 55 | Iteration number: [200/393] 50% | Training loss: 0.693756146132946
Epoch: 55 | Iteration number: [210/393] 53% | Training loss: 0.693574690534955
Epoch: 55 | Iteration number: [220/393] 55% | Training loss: 0.6934311541644009
Epoch: 55 | Iteration number: [230/393] 58% | Training loss: 0.6933141412942306
Epoch: 55 | Iteration number: [240/393] 61% | Training loss: 0.6931817412376404
Epoch: 55 | Iteration number: [250/393] 63% | Training loss: 0.6930932259559631
Epoch: 55 | Iteration number: [260/393] 66% | Training loss: 0.6929613753007009
Epoch: 55 | Iteration number: [270/393] 68% | Training loss: 0.6928321443222187
Epoch: 55 | Iteration number: [280/393] 71% | Training loss: 0.6927578436476843
Epoch: 55 | Iteration number: [290/393] 73% | Training loss: 0.6926679644091376
Epoch: 55 | Iteration number: [300/393] 76% | Training loss: 0.6925904244184494
Epoch: 55 | Iteration number: [310/393] 78% | Training loss: 0.692521163917357
Epoch: 55 | Iteration number: [320/393] 81% | Training loss: 0.6924441449344159
Epoch: 55 | Iteration number: [330/393] 83% | Training loss: 0.6924164508328293
Epoch: 55 | Iteration number: [340/393] 86% | Training loss: 0.6923579219509574
Epoch: 55 | Iteration number: [350/393] 89% | Training loss: 0.6922926017216273
Epoch: 55 | Iteration number: [360/393] 91% | Training loss: 0.6922378089692858
Epoch: 55 | Iteration number: [370/393] 94% | Training loss: 0.6921918310023643
Epoch: 55 | Iteration number: [380/393] 96% | Training loss: 0.6921266497750032
Epoch: 55 | Iteration number: [390/393] 99% | Training loss: 0.6920672010152767

 End of epoch: 55 | Train Loss: 0.6903075499995671 | Training Time: 66 

 End of epoch: 55 | Eval Loss: 0.6902499867945301 | Evaluating Time: 16 
Epoch: 56 | Iteration number: [10/393] 2% | Training loss: 0.7600589036941529
Epoch: 56 | Iteration number: [20/393] 5% | Training loss: 0.7251150935888291
Epoch: 56 | Iteration number: [30/393] 7% | Training loss: 0.7137758096059164
Epoch: 56 | Iteration number: [40/393] 10% | Training loss: 0.7080300822854042
Epoch: 56 | Iteration number: [50/393] 12% | Training loss: 0.7044668018817901
Epoch: 56 | Iteration number: [60/393] 15% | Training loss: 0.7022208174069723
Epoch: 56 | Iteration number: [70/393] 17% | Training loss: 0.700606598172869
Epoch: 56 | Iteration number: [80/393] 20% | Training loss: 0.6993206955492497
Epoch: 56 | Iteration number: [90/393] 22% | Training loss: 0.6982351945506202
Epoch: 56 | Iteration number: [100/393] 25% | Training loss: 0.6974217957258224
Epoch: 56 | Iteration number: [110/393] 27% | Training loss: 0.6967492623762651
Epoch: 56 | Iteration number: [120/393] 30% | Training loss: 0.6962445462743442
Epoch: 56 | Iteration number: [130/393] 33% | Training loss: 0.6958511503843161
Epoch: 56 | Iteration number: [140/393] 35% | Training loss: 0.6954617547137397
Epoch: 56 | Iteration number: [150/393] 38% | Training loss: 0.6951101072629293
Epoch: 56 | Iteration number: [160/393] 40% | Training loss: 0.6947738248854876
Epoch: 56 | Iteration number: [170/393] 43% | Training loss: 0.6945487288867727
Epoch: 56 | Iteration number: [180/393] 45% | Training loss: 0.6943116856945886
Epoch: 56 | Iteration number: [190/393] 48% | Training loss: 0.694070658872002
Epoch: 56 | Iteration number: [200/393] 50% | Training loss: 0.6938549128174781
Epoch: 56 | Iteration number: [210/393] 53% | Training loss: 0.6936909476915996
Epoch: 56 | Iteration number: [220/393] 55% | Training loss: 0.6935463973067023
Epoch: 56 | Iteration number: [230/393] 58% | Training loss: 0.6933877483658168
Epoch: 56 | Iteration number: [240/393] 61% | Training loss: 0.6932229990760486
Epoch: 56 | Iteration number: [250/393] 63% | Training loss: 0.6931105611324311
Epoch: 56 | Iteration number: [260/393] 66% | Training loss: 0.6930309061820691
Epoch: 56 | Iteration number: [270/393] 68% | Training loss: 0.6929216342943686
Epoch: 56 | Iteration number: [280/393] 71% | Training loss: 0.6927855757730348
Epoch: 56 | Iteration number: [290/393] 73% | Training loss: 0.6926995174638156
Epoch: 56 | Iteration number: [300/393] 76% | Training loss: 0.6926256442070007
Epoch: 56 | Iteration number: [310/393] 78% | Training loss: 0.6925540935608648
Epoch: 56 | Iteration number: [320/393] 81% | Training loss: 0.692481429502368
Epoch: 56 | Iteration number: [330/393] 83% | Training loss: 0.6924247069792314
Epoch: 56 | Iteration number: [340/393] 86% | Training loss: 0.6923307355712441
Epoch: 56 | Iteration number: [350/393] 89% | Training loss: 0.6922865288598197
Epoch: 56 | Iteration number: [360/393] 91% | Training loss: 0.6922373995184898
Epoch: 56 | Iteration number: [370/393] 94% | Training loss: 0.69218718087351
Epoch: 56 | Iteration number: [380/393] 96% | Training loss: 0.6921520084142685
Epoch: 56 | Iteration number: [390/393] 99% | Training loss: 0.6921093101684864

 End of epoch: 56 | Train Loss: 0.6903404139987082 | Training Time: 66 

 End of epoch: 56 | Eval Loss: 0.6903260496197915 | Evaluating Time: 16 
Epoch: 57 | Iteration number: [10/393] 2% | Training loss: 0.7598820328712463
Epoch: 57 | Iteration number: [20/393] 5% | Training loss: 0.7252451360225678
Epoch: 57 | Iteration number: [30/393] 7% | Training loss: 0.7138944427172343
Epoch: 57 | Iteration number: [40/393] 10% | Training loss: 0.7079316839575768
Epoch: 57 | Iteration number: [50/393] 12% | Training loss: 0.7043712556362152
Epoch: 57 | Iteration number: [60/393] 15% | Training loss: 0.7018471429745357
Epoch: 57 | Iteration number: [70/393] 17% | Training loss: 0.7003978252410888
Epoch: 57 | Iteration number: [80/393] 20% | Training loss: 0.6992417044937611
Epoch: 57 | Iteration number: [90/393] 22% | Training loss: 0.6982962138122982
Epoch: 57 | Iteration number: [100/393] 25% | Training loss: 0.6975014787912369
Epoch: 57 | Iteration number: [110/393] 27% | Training loss: 0.6968614832921461
Epoch: 57 | Iteration number: [120/393] 30% | Training loss: 0.6963702167073885
Epoch: 57 | Iteration number: [130/393] 33% | Training loss: 0.6959155041437882
Epoch: 57 | Iteration number: [140/393] 35% | Training loss: 0.6955158872263772
Epoch: 57 | Iteration number: [150/393] 38% | Training loss: 0.6950956078370413
Epoch: 57 | Iteration number: [160/393] 40% | Training loss: 0.6947917614132166
Epoch: 57 | Iteration number: [170/393] 43% | Training loss: 0.6944911827059354
Epoch: 57 | Iteration number: [180/393] 45% | Training loss: 0.6942044377326966
Epoch: 57 | Iteration number: [190/393] 48% | Training loss: 0.6939952743680854
Epoch: 57 | Iteration number: [200/393] 50% | Training loss: 0.6937913540005683
Epoch: 57 | Iteration number: [210/393] 53% | Training loss: 0.6936216547375633
Epoch: 57 | Iteration number: [220/393] 55% | Training loss: 0.693498202345588
Epoch: 57 | Iteration number: [230/393] 58% | Training loss: 0.6934075143026269
Epoch: 57 | Iteration number: [240/393] 61% | Training loss: 0.6933149461944897
Epoch: 57 | Iteration number: [250/393] 63% | Training loss: 0.6931545846462249
Epoch: 57 | Iteration number: [260/393] 66% | Training loss: 0.6930774984451441
Epoch: 57 | Iteration number: [270/393] 68% | Training loss: 0.6929569681485493
Epoch: 57 | Iteration number: [280/393] 71% | Training loss: 0.6928706137197358
Epoch: 57 | Iteration number: [290/393] 73% | Training loss: 0.6927522038591319
Epoch: 57 | Iteration number: [300/393] 76% | Training loss: 0.6926416963338852
Epoch: 57 | Iteration number: [310/393] 78% | Training loss: 0.6925714846580259
Epoch: 57 | Iteration number: [320/393] 81% | Training loss: 0.6925440274178982
Epoch: 57 | Iteration number: [330/393] 83% | Training loss: 0.69250586791472
Epoch: 57 | Iteration number: [340/393] 86% | Training loss: 0.6924759977004107
Epoch: 57 | Iteration number: [350/393] 89% | Training loss: 0.6924603467328208
Epoch: 57 | Iteration number: [360/393] 91% | Training loss: 0.6923755453692542
Epoch: 57 | Iteration number: [370/393] 94% | Training loss: 0.6923156678676605
Epoch: 57 | Iteration number: [380/393] 96% | Training loss: 0.6922641581610629
Epoch: 57 | Iteration number: [390/393] 99% | Training loss: 0.6922201465337704

 End of epoch: 57 | Train Loss: 0.690444531028204 | Training Time: 66 

 End of epoch: 57 | Eval Loss: 0.690164535629506 | Evaluating Time: 16 
Epoch: 58 | Iteration number: [10/393] 2% | Training loss: 0.7591931819915771
Epoch: 58 | Iteration number: [20/393] 5% | Training loss: 0.7250114023685456
Epoch: 58 | Iteration number: [30/393] 7% | Training loss: 0.7131648858388265
Epoch: 58 | Iteration number: [40/393] 10% | Training loss: 0.7073204800486564
Epoch: 58 | Iteration number: [50/393] 12% | Training loss: 0.7038732969760895
Epoch: 58 | Iteration number: [60/393] 15% | Training loss: 0.7014160255591074
Epoch: 58 | Iteration number: [70/393] 17% | Training loss: 0.6997829394681113
Epoch: 58 | Iteration number: [80/393] 20% | Training loss: 0.6985827066004276
Epoch: 58 | Iteration number: [90/393] 22% | Training loss: 0.6977220429314508
Epoch: 58 | Iteration number: [100/393] 25% | Training loss: 0.6970658564567566
Epoch: 58 | Iteration number: [110/393] 27% | Training loss: 0.6964027106761932
Epoch: 58 | Iteration number: [120/393] 30% | Training loss: 0.6959871371587117
Epoch: 58 | Iteration number: [130/393] 33% | Training loss: 0.695570155290457
Epoch: 58 | Iteration number: [140/393] 35% | Training loss: 0.6952056965657643
Epoch: 58 | Iteration number: [150/393] 38% | Training loss: 0.6948289465904236
Epoch: 58 | Iteration number: [160/393] 40% | Training loss: 0.694479788467288
Epoch: 58 | Iteration number: [170/393] 43% | Training loss: 0.6942901825203615
Epoch: 58 | Iteration number: [180/393] 45% | Training loss: 0.6940659923685921
Epoch: 58 | Iteration number: [190/393] 48% | Training loss: 0.6938574838010888
Epoch: 58 | Iteration number: [200/393] 50% | Training loss: 0.6937138059735298
Epoch: 58 | Iteration number: [210/393] 53% | Training loss: 0.6935718930902935
Epoch: 58 | Iteration number: [220/393] 55% | Training loss: 0.6933571536432613
Epoch: 58 | Iteration number: [230/393] 58% | Training loss: 0.6932490864525671
Epoch: 58 | Iteration number: [240/393] 61% | Training loss: 0.6931026483575503
Epoch: 58 | Iteration number: [250/393] 63% | Training loss: 0.6930392985343933
Epoch: 58 | Iteration number: [260/393] 66% | Training loss: 0.6929305310432727
Epoch: 58 | Iteration number: [270/393] 68% | Training loss: 0.6928501550798063
Epoch: 58 | Iteration number: [280/393] 71% | Training loss: 0.6927887211952891
Epoch: 58 | Iteration number: [290/393] 73% | Training loss: 0.692686618813153
Epoch: 58 | Iteration number: [300/393] 76% | Training loss: 0.6926212757825851
Epoch: 58 | Iteration number: [310/393] 78% | Training loss: 0.6925575292879536
Epoch: 58 | Iteration number: [320/393] 81% | Training loss: 0.692475002259016
Epoch: 58 | Iteration number: [330/393] 83% | Training loss: 0.6924288231315034
Epoch: 58 | Iteration number: [340/393] 86% | Training loss: 0.692379969533752
Epoch: 58 | Iteration number: [350/393] 89% | Training loss: 0.6923300606863839
Epoch: 58 | Iteration number: [360/393] 91% | Training loss: 0.6922873419192103
Epoch: 58 | Iteration number: [370/393] 94% | Training loss: 0.6922642506457664
Epoch: 58 | Iteration number: [380/393] 96% | Training loss: 0.6922208012718903
Epoch: 58 | Iteration number: [390/393] 99% | Training loss: 0.692157189356975

 End of epoch: 58 | Train Loss: 0.690395098454473 | Training Time: 66 

 End of epoch: 58 | Eval Loss: 0.690332153621985 | Evaluating Time: 16 
Epoch: 59 | Iteration number: [10/393] 2% | Training loss: 0.7588901281356811
Epoch: 59 | Iteration number: [20/393] 5% | Training loss: 0.724640554189682
Epoch: 59 | Iteration number: [30/393] 7% | Training loss: 0.7133162140846252
Epoch: 59 | Iteration number: [40/393] 10% | Training loss: 0.7077541574835777
Epoch: 59 | Iteration number: [50/393] 12% | Training loss: 0.704267965555191
Epoch: 59 | Iteration number: [60/393] 15% | Training loss: 0.7018778214852015
Epoch: 59 | Iteration number: [70/393] 17% | Training loss: 0.7002314414296832
Epoch: 59 | Iteration number: [80/393] 20% | Training loss: 0.6989644840359688
Epoch: 59 | Iteration number: [90/393] 22% | Training loss: 0.6979997058709463
Epoch: 59 | Iteration number: [100/393] 25% | Training loss: 0.6971419233083725
Epoch: 59 | Iteration number: [110/393] 27% | Training loss: 0.6965308574112978
Epoch: 59 | Iteration number: [120/393] 30% | Training loss: 0.6960510139664015
Epoch: 59 | Iteration number: [130/393] 33% | Training loss: 0.6956619808307061
Epoch: 59 | Iteration number: [140/393] 35% | Training loss: 0.6953028125422341
Epoch: 59 | Iteration number: [150/393] 38% | Training loss: 0.6949864284197489
Epoch: 59 | Iteration number: [160/393] 40% | Training loss: 0.6946458946913481
Epoch: 59 | Iteration number: [170/393] 43% | Training loss: 0.6944706106887144
Epoch: 59 | Iteration number: [180/393] 45% | Training loss: 0.6942899564901988
Epoch: 59 | Iteration number: [190/393] 48% | Training loss: 0.6940952046921379
Epoch: 59 | Iteration number: [200/393] 50% | Training loss: 0.6938889971375466
Epoch: 59 | Iteration number: [210/393] 53% | Training loss: 0.6937480713639941
Epoch: 59 | Iteration number: [220/393] 55% | Training loss: 0.6936221808195114
Epoch: 59 | Iteration number: [230/393] 58% | Training loss: 0.6934315637401912
Epoch: 59 | Iteration number: [240/393] 61% | Training loss: 0.6933121713499228
Epoch: 59 | Iteration number: [250/393] 63% | Training loss: 0.6930953278541565
Epoch: 59 | Iteration number: [260/393] 66% | Training loss: 0.6929825849257982
Epoch: 59 | Iteration number: [270/393] 68% | Training loss: 0.692868126321722
Epoch: 59 | Iteration number: [280/393] 71% | Training loss: 0.6927625903061458
Epoch: 59 | Iteration number: [290/393] 73% | Training loss: 0.6926607405317241
Epoch: 59 | Iteration number: [300/393] 76% | Training loss: 0.6925834596157074
Epoch: 59 | Iteration number: [310/393] 78% | Training loss: 0.6924979705964366
Epoch: 59 | Iteration number: [320/393] 81% | Training loss: 0.6924306048080325
Epoch: 59 | Iteration number: [330/393] 83% | Training loss: 0.6924107493776264
Epoch: 59 | Iteration number: [340/393] 86% | Training loss: 0.6923526944483027
Epoch: 59 | Iteration number: [350/393] 89% | Training loss: 0.6922888025215694
Epoch: 59 | Iteration number: [360/393] 91% | Training loss: 0.6922374255127377
Epoch: 59 | Iteration number: [370/393] 94% | Training loss: 0.6921875304466969
Epoch: 59 | Iteration number: [380/393] 96% | Training loss: 0.692137650596468
Epoch: 59 | Iteration number: [390/393] 99% | Training loss: 0.6920726745556562

 End of epoch: 59 | Train Loss: 0.690301602730011 | Training Time: 66 

 End of epoch: 59 | Eval Loss: 0.6902417747341857 | Evaluating Time: 16 
Epoch: 60 | Iteration number: [10/393] 2% | Training loss: 0.7598199903964996
Epoch: 60 | Iteration number: [20/393] 5% | Training loss: 0.7250012725591659
Epoch: 60 | Iteration number: [30/393] 7% | Training loss: 0.7136762877305348
Epoch: 60 | Iteration number: [40/393] 10% | Training loss: 0.7080233380198478
Epoch: 60 | Iteration number: [50/393] 12% | Training loss: 0.7045631062984467
Epoch: 60 | Iteration number: [60/393] 15% | Training loss: 0.7020102322101593
Epoch: 60 | Iteration number: [70/393] 17% | Training loss: 0.7003929844924381
Epoch: 60 | Iteration number: [80/393] 20% | Training loss: 0.6992128551006317
Epoch: 60 | Iteration number: [90/393] 22% | Training loss: 0.6982897950543298
Epoch: 60 | Iteration number: [100/393] 25% | Training loss: 0.6975090390443802
Epoch: 60 | Iteration number: [110/393] 27% | Training loss: 0.696776932477951
Epoch: 60 | Iteration number: [120/393] 30% | Training loss: 0.6962975119551023
Epoch: 60 | Iteration number: [130/393] 33% | Training loss: 0.6958222645979661
Epoch: 60 | Iteration number: [140/393] 35% | Training loss: 0.6954754280192511
Epoch: 60 | Iteration number: [150/393] 38% | Training loss: 0.6951893099149068
Epoch: 60 | Iteration number: [160/393] 40% | Training loss: 0.6949548061937094
Epoch: 60 | Iteration number: [170/393] 43% | Training loss: 0.6946993343970355
Epoch: 60 | Iteration number: [180/393] 45% | Training loss: 0.6944045656257205
Epoch: 60 | Iteration number: [190/393] 48% | Training loss: 0.694220928455654
Epoch: 60 | Iteration number: [200/393] 50% | Training loss: 0.6940466976165771
Epoch: 60 | Iteration number: [210/393] 53% | Training loss: 0.6939116458098094
Epoch: 60 | Iteration number: [220/393] 55% | Training loss: 0.6936608176339757
Epoch: 60 | Iteration number: [230/393] 58% | Training loss: 0.6935067778048308
Epoch: 60 | Iteration number: [240/393] 61% | Training loss: 0.6934037881592909
Epoch: 60 | Iteration number: [250/393] 63% | Training loss: 0.6933036496639252
Epoch: 60 | Iteration number: [260/393] 66% | Training loss: 0.6931223873908703
Epoch: 60 | Iteration number: [270/393] 68% | Training loss: 0.6930032736725278
Epoch: 60 | Iteration number: [280/393] 71% | Training loss: 0.6928800089018685
Epoch: 60 | Iteration number: [290/393] 73% | Training loss: 0.6927563770063992
Epoch: 60 | Iteration number: [300/393] 76% | Training loss: 0.6925996577739716
Epoch: 60 | Iteration number: [310/393] 78% | Training loss: 0.692536497885181
Epoch: 60 | Iteration number: [320/393] 81% | Training loss: 0.6924814760684967
Epoch: 60 | Iteration number: [330/393] 83% | Training loss: 0.6924008230368296
Epoch: 60 | Iteration number: [340/393] 86% | Training loss: 0.6923113945652457
Epoch: 60 | Iteration number: [350/393] 89% | Training loss: 0.692246413571494
Epoch: 60 | Iteration number: [360/393] 91% | Training loss: 0.692216181092792
Epoch: 60 | Iteration number: [370/393] 94% | Training loss: 0.6921334405203123
Epoch: 60 | Iteration number: [380/393] 96% | Training loss: 0.6920980025278894
Epoch: 60 | Iteration number: [390/393] 99% | Training loss: 0.6920262512488243

 End of epoch: 60 | Train Loss: 0.6902543306350708 | Training Time: 66 

 End of epoch: 60 | Eval Loss: 0.690215025629316 | Evaluating Time: 16 
Epoch: 61 | Iteration number: [10/393] 2% | Training loss: 0.75977942943573
Epoch: 61 | Iteration number: [20/393] 5% | Training loss: 0.7254425257444381
Epoch: 61 | Iteration number: [30/393] 7% | Training loss: 0.7142472346623738
Epoch: 61 | Iteration number: [40/393] 10% | Training loss: 0.7079720720648766
Epoch: 61 | Iteration number: [50/393] 12% | Training loss: 0.7043644607067108
Epoch: 61 | Iteration number: [60/393] 15% | Training loss: 0.7020131419102351
Epoch: 61 | Iteration number: [70/393] 17% | Training loss: 0.7002423942089081
Epoch: 61 | Iteration number: [80/393] 20% | Training loss: 0.699009794741869
Epoch: 61 | Iteration number: [90/393] 22% | Training loss: 0.6980459484789107
Epoch: 61 | Iteration number: [100/393] 25% | Training loss: 0.6971950906515122
Epoch: 61 | Iteration number: [110/393] 27% | Training loss: 0.696542166037993
Epoch: 61 | Iteration number: [120/393] 30% | Training loss: 0.6959561581412951
Epoch: 61 | Iteration number: [130/393] 33% | Training loss: 0.6955229942615215
Epoch: 61 | Iteration number: [140/393] 35% | Training loss: 0.6952752871172768
Epoch: 61 | Iteration number: [150/393] 38% | Training loss: 0.6949376833438873
Epoch: 61 | Iteration number: [160/393] 40% | Training loss: 0.694652422145009
Epoch: 61 | Iteration number: [170/393] 43% | Training loss: 0.6943558742018306
Epoch: 61 | Iteration number: [180/393] 45% | Training loss: 0.6941463689009348
Epoch: 61 | Iteration number: [190/393] 48% | Training loss: 0.6939708141904128
Epoch: 61 | Iteration number: [200/393] 50% | Training loss: 0.6937651795148849
Epoch: 61 | Iteration number: [210/393] 53% | Training loss: 0.6935813977604821
Epoch: 61 | Iteration number: [220/393] 55% | Training loss: 0.6934204253283414
Epoch: 61 | Iteration number: [230/393] 58% | Training loss: 0.6932993756688159
Epoch: 61 | Iteration number: [240/393] 61% | Training loss: 0.6931628415981929
Epoch: 61 | Iteration number: [250/393] 63% | Training loss: 0.6930523045063018
Epoch: 61 | Iteration number: [260/393] 66% | Training loss: 0.692979561824065
Epoch: 61 | Iteration number: [270/393] 68% | Training loss: 0.6928607342419801
Epoch: 61 | Iteration number: [280/393] 71% | Training loss: 0.6927285594599587
Epoch: 61 | Iteration number: [290/393] 73% | Training loss: 0.6926477031461123
Epoch: 61 | Iteration number: [300/393] 76% | Training loss: 0.6925482515494029
Epoch: 61 | Iteration number: [310/393] 78% | Training loss: 0.6924797690683796
Epoch: 61 | Iteration number: [320/393] 81% | Training loss: 0.6924246471375227
Epoch: 61 | Iteration number: [330/393] 83% | Training loss: 0.6924089039817001
Epoch: 61 | Iteration number: [340/393] 86% | Training loss: 0.6923768211813534
Epoch: 61 | Iteration number: [350/393] 89% | Training loss: 0.6923111804894039
Epoch: 61 | Iteration number: [360/393] 91% | Training loss: 0.6922566996680366
Epoch: 61 | Iteration number: [370/393] 94% | Training loss: 0.692191132017084
Epoch: 61 | Iteration number: [380/393] 96% | Training loss: 0.692136486423643
Epoch: 61 | Iteration number: [390/393] 99% | Training loss: 0.6921088211047344

 End of epoch: 61 | Train Loss: 0.6903435132885707 | Training Time: 66 

 End of epoch: 61 | Eval Loss: 0.6906244170909025 | Evaluating Time: 16 
Epoch: 62 | Iteration number: [10/393] 2% | Training loss: 0.7592783808708191
Epoch: 62 | Iteration number: [20/393] 5% | Training loss: 0.7241386651992798
Epoch: 62 | Iteration number: [30/393] 7% | Training loss: 0.7133150557676952
Epoch: 62 | Iteration number: [40/393] 10% | Training loss: 0.707672156393528
Epoch: 62 | Iteration number: [50/393] 12% | Training loss: 0.7040976655483245
Epoch: 62 | Iteration number: [60/393] 15% | Training loss: 0.7019717653592428
Epoch: 62 | Iteration number: [70/393] 17% | Training loss: 0.700275285754885
Epoch: 62 | Iteration number: [80/393] 20% | Training loss: 0.6991219773888588
Epoch: 62 | Iteration number: [90/393] 22% | Training loss: 0.6981567170884874
Epoch: 62 | Iteration number: [100/393] 25% | Training loss: 0.6974073123931884
Epoch: 62 | Iteration number: [110/393] 27% | Training loss: 0.6965841054916382
Epoch: 62 | Iteration number: [120/393] 30% | Training loss: 0.6960772926608721
Epoch: 62 | Iteration number: [130/393] 33% | Training loss: 0.6955959966549506
Epoch: 62 | Iteration number: [140/393] 35% | Training loss: 0.6952431661742074
Epoch: 62 | Iteration number: [150/393] 38% | Training loss: 0.6949437069892883
Epoch: 62 | Iteration number: [160/393] 40% | Training loss: 0.6947007201611995
Epoch: 62 | Iteration number: [170/393] 43% | Training loss: 0.6944363850004532
Epoch: 62 | Iteration number: [180/393] 45% | Training loss: 0.6942116505569882
Epoch: 62 | Iteration number: [190/393] 48% | Training loss: 0.6939703655870337
Epoch: 62 | Iteration number: [200/393] 50% | Training loss: 0.6938349488377571
Epoch: 62 | Iteration number: [210/393] 53% | Training loss: 0.6935851627872104
Epoch: 62 | Iteration number: [220/393] 55% | Training loss: 0.6934680529616096
Epoch: 62 | Iteration number: [230/393] 58% | Training loss: 0.6933401022268378
Epoch: 62 | Iteration number: [240/393] 61% | Training loss: 0.6932198772827785
Epoch: 62 | Iteration number: [250/393] 63% | Training loss: 0.6930558924674988
Epoch: 62 | Iteration number: [260/393] 66% | Training loss: 0.6929134306999353
Epoch: 62 | Iteration number: [270/393] 68% | Training loss: 0.6927918933056019
Epoch: 62 | Iteration number: [280/393] 71% | Training loss: 0.6927088386246136
Epoch: 62 | Iteration number: [290/393] 73% | Training loss: 0.6925764005759667
Epoch: 62 | Iteration number: [300/393] 76% | Training loss: 0.6925005084276199
Epoch: 62 | Iteration number: [310/393] 78% | Training loss: 0.692426545773783
Epoch: 62 | Iteration number: [320/393] 81% | Training loss: 0.6923965238034725
Epoch: 62 | Iteration number: [330/393] 83% | Training loss: 0.6923465779333403
Epoch: 62 | Iteration number: [340/393] 86% | Training loss: 0.6922403365373612
Epoch: 62 | Iteration number: [350/393] 89% | Training loss: 0.6921869138308934
Epoch: 62 | Iteration number: [360/393] 91% | Training loss: 0.6921097124616306
Epoch: 62 | Iteration number: [370/393] 94% | Training loss: 0.6920848490418614
Epoch: 62 | Iteration number: [380/393] 96% | Training loss: 0.6920558982773831
Epoch: 62 | Iteration number: [390/393] 99% | Training loss: 0.6919930260915023

 End of epoch: 62 | Train Loss: 0.6902326971823326 | Training Time: 66 

 End of epoch: 62 | Eval Loss: 0.6901058992561029 | Evaluating Time: 16 
Epoch: 63 | Iteration number: [10/393] 2% | Training loss: 0.7595583319664001
Epoch: 63 | Iteration number: [20/393] 5% | Training loss: 0.7250868052244186
Epoch: 63 | Iteration number: [30/393] 7% | Training loss: 0.7135155280431111
Epoch: 63 | Iteration number: [40/393] 10% | Training loss: 0.7073725134134292
Epoch: 63 | Iteration number: [50/393] 12% | Training loss: 0.7038859212398529
Epoch: 63 | Iteration number: [60/393] 15% | Training loss: 0.7015580236911774
Epoch: 63 | Iteration number: [70/393] 17% | Training loss: 0.700098443882806
Epoch: 63 | Iteration number: [80/393] 20% | Training loss: 0.6989869892597198
Epoch: 63 | Iteration number: [90/393] 22% | Training loss: 0.6979932506879171
Epoch: 63 | Iteration number: [100/393] 25% | Training loss: 0.6972637450695038
Epoch: 63 | Iteration number: [110/393] 27% | Training loss: 0.6967327242547815
Epoch: 63 | Iteration number: [120/393] 30% | Training loss: 0.6962353443106015
Epoch: 63 | Iteration number: [130/393] 33% | Training loss: 0.6957975621406849
Epoch: 63 | Iteration number: [140/393] 35% | Training loss: 0.6954026401042939
Epoch: 63 | Iteration number: [150/393] 38% | Training loss: 0.6949708143870036
Epoch: 63 | Iteration number: [160/393] 40% | Training loss: 0.6946560461074114
Epoch: 63 | Iteration number: [170/393] 43% | Training loss: 0.694362979776719
Epoch: 63 | Iteration number: [180/393] 45% | Training loss: 0.694110753469997
Epoch: 63 | Iteration number: [190/393] 48% | Training loss: 0.6939714017667269
Epoch: 63 | Iteration number: [200/393] 50% | Training loss: 0.6937789833545684
Epoch: 63 | Iteration number: [210/393] 53% | Training loss: 0.6936683555444082
Epoch: 63 | Iteration number: [220/393] 55% | Training loss: 0.6935301507061178
Epoch: 63 | Iteration number: [230/393] 58% | Training loss: 0.693381672061008
Epoch: 63 | Iteration number: [240/393] 61% | Training loss: 0.6932582927246889
Epoch: 63 | Iteration number: [250/393] 63% | Training loss: 0.693127279996872
Epoch: 63 | Iteration number: [260/393] 66% | Training loss: 0.6930245337577966
Epoch: 63 | Iteration number: [270/393] 68% | Training loss: 0.6929208530320061
Epoch: 63 | Iteration number: [280/393] 71% | Training loss: 0.6927694588899612
Epoch: 63 | Iteration number: [290/393] 73% | Training loss: 0.6926322297803287
Epoch: 63 | Iteration number: [300/393] 76% | Training loss: 0.692519672314326
Epoch: 63 | Iteration number: [310/393] 78% | Training loss: 0.6924496900650763
Epoch: 63 | Iteration number: [320/393] 81% | Training loss: 0.6923849016427994
Epoch: 63 | Iteration number: [330/393] 83% | Training loss: 0.6923503599383615
Epoch: 63 | Iteration number: [340/393] 86% | Training loss: 0.692253691834562
Epoch: 63 | Iteration number: [350/393] 89% | Training loss: 0.6922038389955248
Epoch: 63 | Iteration number: [360/393] 91% | Training loss: 0.692120811343193
Epoch: 63 | Iteration number: [370/393] 94% | Training loss: 0.6920758769318864
Epoch: 63 | Iteration number: [380/393] 96% | Training loss: 0.6920346904742091
Epoch: 63 | Iteration number: [390/393] 99% | Training loss: 0.6919920918269035

 End of epoch: 63 | Train Loss: 0.6902273571824906 | Training Time: 66 

 End of epoch: 63 | Eval Loss: 0.6901431983830978 | Evaluating Time: 16 
Epoch: 64 | Iteration number: [10/393] 2% | Training loss: 0.7583817541599274
Epoch: 64 | Iteration number: [20/393] 5% | Training loss: 0.7241997838020324
Epoch: 64 | Iteration number: [30/393] 7% | Training loss: 0.7129799942175548
Epoch: 64 | Iteration number: [40/393] 10% | Training loss: 0.7070695832371712
Epoch: 64 | Iteration number: [50/393] 12% | Training loss: 0.703529587984085
Epoch: 64 | Iteration number: [60/393] 15% | Training loss: 0.7013082553942999
Epoch: 64 | Iteration number: [70/393] 17% | Training loss: 0.6997362809521811
Epoch: 64 | Iteration number: [80/393] 20% | Training loss: 0.6985534086823464
Epoch: 64 | Iteration number: [90/393] 22% | Training loss: 0.6977104160520765
Epoch: 64 | Iteration number: [100/393] 25% | Training loss: 0.6969833362102509
Epoch: 64 | Iteration number: [110/393] 27% | Training loss: 0.6964237234809182
Epoch: 64 | Iteration number: [120/393] 30% | Training loss: 0.695903325577577
Epoch: 64 | Iteration number: [130/393] 33% | Training loss: 0.6955813609636747
Epoch: 64 | Iteration number: [140/393] 35% | Training loss: 0.6952034928968974
Epoch: 64 | Iteration number: [150/393] 38% | Training loss: 0.6949331533908844
Epoch: 64 | Iteration number: [160/393] 40% | Training loss: 0.6946925621479749
Epoch: 64 | Iteration number: [170/393] 43% | Training loss: 0.6943571872570935
Epoch: 64 | Iteration number: [180/393] 45% | Training loss: 0.6941176888015536
Epoch: 64 | Iteration number: [190/393] 48% | Training loss: 0.6939026440444745
Epoch: 64 | Iteration number: [200/393] 50% | Training loss: 0.6937312933802605
Epoch: 64 | Iteration number: [210/393] 53% | Training loss: 0.693537380865642
Epoch: 64 | Iteration number: [220/393] 55% | Training loss: 0.6933148947629062
Epoch: 64 | Iteration number: [230/393] 58% | Training loss: 0.6932369115559951
Epoch: 64 | Iteration number: [240/393] 61% | Training loss: 0.693119918803374
Epoch: 64 | Iteration number: [250/393] 63% | Training loss: 0.6930221848487854
Epoch: 64 | Iteration number: [260/393] 66% | Training loss: 0.6929221513179632
Epoch: 64 | Iteration number: [270/393] 68% | Training loss: 0.6927922003799014
Epoch: 64 | Iteration number: [280/393] 71% | Training loss: 0.6926627689174243
Epoch: 64 | Iteration number: [290/393] 73% | Training loss: 0.6926446639258286
Epoch: 64 | Iteration number: [300/393] 76% | Training loss: 0.6925687064727147
Epoch: 64 | Iteration number: [310/393] 78% | Training loss: 0.6924541200360944
Epoch: 64 | Iteration number: [320/393] 81% | Training loss: 0.6923676395788789
Epoch: 64 | Iteration number: [330/393] 83% | Training loss: 0.6922810220357144
Epoch: 64 | Iteration number: [340/393] 86% | Training loss: 0.692170253571342
Epoch: 64 | Iteration number: [350/393] 89% | Training loss: 0.6920915809699467
Epoch: 64 | Iteration number: [360/393] 91% | Training loss: 0.6920351584752401
Epoch: 64 | Iteration number: [370/393] 94% | Training loss: 0.691998057429855
Epoch: 64 | Iteration number: [380/393] 96% | Training loss: 0.6919790845168264
Epoch: 64 | Iteration number: [390/393] 99% | Training loss: 0.6919476885061998

 End of epoch: 64 | Train Loss: 0.6901805649580239 | Training Time: 66 

 End of epoch: 64 | Eval Loss: 0.6901250834367714 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/393] 2% | Training loss: 0.7597265422344208
Epoch: 65 | Iteration number: [20/393] 5% | Training loss: 0.7252031862735748
Epoch: 65 | Iteration number: [30/393] 7% | Training loss: 0.7138539870580037
Epoch: 65 | Iteration number: [40/393] 10% | Training loss: 0.707893294095993
Epoch: 65 | Iteration number: [50/393] 12% | Training loss: 0.7042785608768463
Epoch: 65 | Iteration number: [60/393] 15% | Training loss: 0.7019284586111705
Epoch: 65 | Iteration number: [70/393] 17% | Training loss: 0.7000026490007129
Epoch: 65 | Iteration number: [80/393] 20% | Training loss: 0.6987548254430294
Epoch: 65 | Iteration number: [90/393] 22% | Training loss: 0.6979052186012268
Epoch: 65 | Iteration number: [100/393] 25% | Training loss: 0.6969841933250427
Epoch: 65 | Iteration number: [110/393] 27% | Training loss: 0.6963250853798606
Epoch: 65 | Iteration number: [120/393] 30% | Training loss: 0.6957747037212054
Epoch: 65 | Iteration number: [130/393] 33% | Training loss: 0.695323500266442
Epoch: 65 | Iteration number: [140/393] 35% | Training loss: 0.6949633811201368
Epoch: 65 | Iteration number: [150/393] 38% | Training loss: 0.6946526972452799
Epoch: 65 | Iteration number: [160/393] 40% | Training loss: 0.6944007080048322
Epoch: 65 | Iteration number: [170/393] 43% | Training loss: 0.6941637933254242
Epoch: 65 | Iteration number: [180/393] 45% | Training loss: 0.6939768963389926
Epoch: 65 | Iteration number: [190/393] 48% | Training loss: 0.6938153364156422
Epoch: 65 | Iteration number: [200/393] 50% | Training loss: 0.6936375430226326
Epoch: 65 | Iteration number: [210/393] 53% | Training loss: 0.6935427095208849
Epoch: 65 | Iteration number: [220/393] 55% | Training loss: 0.6933773693713274
Epoch: 65 | Iteration number: [230/393] 58% | Training loss: 0.6931712230910425
Epoch: 65 | Iteration number: [240/393] 61% | Training loss: 0.6930713047583897
Epoch: 65 | Iteration number: [250/393] 63% | Training loss: 0.6929153101444244
Epoch: 65 | Iteration number: [260/393] 66% | Training loss: 0.6928278732758302
Epoch: 65 | Iteration number: [270/393] 68% | Training loss: 0.692710656369174
Epoch: 65 | Iteration number: [280/393] 71% | Training loss: 0.6926154111112867
Epoch: 65 | Iteration number: [290/393] 73% | Training loss: 0.6925546078846372
Epoch: 65 | Iteration number: [300/393] 76% | Training loss: 0.6925054820378621
Epoch: 65 | Iteration number: [310/393] 78% | Training loss: 0.6924342272743103
Epoch: 65 | Iteration number: [320/393] 81% | Training loss: 0.6923958793282509
Epoch: 65 | Iteration number: [330/393] 83% | Training loss: 0.6923495625004624
Epoch: 65 | Iteration number: [340/393] 86% | Training loss: 0.692306352538221
Epoch: 65 | Iteration number: [350/393] 89% | Training loss: 0.692231423003333
Epoch: 65 | Iteration number: [360/393] 91% | Training loss: 0.6921631806426578
Epoch: 65 | Iteration number: [370/393] 94% | Training loss: 0.6920672186323115
Epoch: 65 | Iteration number: [380/393] 96% | Training loss: 0.6920045449545509
Epoch: 65 | Iteration number: [390/393] 99% | Training loss: 0.6919734947192363

 End of epoch: 65 | Train Loss: 0.6902048835014266 | Training Time: 67 

 End of epoch: 65 | Eval Loss: 0.6900588310494715 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/393] 2% | Training loss: 0.7581400632858276
Epoch: 66 | Iteration number: [20/393] 5% | Training loss: 0.7246256411075592
Epoch: 66 | Iteration number: [30/393] 7% | Training loss: 0.7128477176030477
Epoch: 66 | Iteration number: [40/393] 10% | Training loss: 0.7072999596595764
Epoch: 66 | Iteration number: [50/393] 12% | Training loss: 0.7039258825778961
Epoch: 66 | Iteration number: [60/393] 15% | Training loss: 0.7015816390514373
Epoch: 66 | Iteration number: [70/393] 17% | Training loss: 0.6999233288424356
Epoch: 66 | Iteration number: [80/393] 20% | Training loss: 0.6986638091504573
Epoch: 66 | Iteration number: [90/393] 22% | Training loss: 0.6978720049063365
Epoch: 66 | Iteration number: [100/393] 25% | Training loss: 0.6971024173498154
Epoch: 66 | Iteration number: [110/393] 27% | Training loss: 0.6964984091845425
Epoch: 66 | Iteration number: [120/393] 30% | Training loss: 0.6959810152649879
Epoch: 66 | Iteration number: [130/393] 33% | Training loss: 0.6955362668404212
Epoch: 66 | Iteration number: [140/393] 35% | Training loss: 0.6951827777283532
Epoch: 66 | Iteration number: [150/393] 38% | Training loss: 0.6948367091019948
Epoch: 66 | Iteration number: [160/393] 40% | Training loss: 0.6945623613893985
Epoch: 66 | Iteration number: [170/393] 43% | Training loss: 0.6943352993796853
Epoch: 66 | Iteration number: [180/393] 45% | Training loss: 0.6941453837686115
Epoch: 66 | Iteration number: [190/393] 48% | Training loss: 0.6939360800542329
Epoch: 66 | Iteration number: [200/393] 50% | Training loss: 0.6937807708978653
Epoch: 66 | Iteration number: [210/393] 53% | Training loss: 0.6935932190645309
Epoch: 66 | Iteration number: [220/393] 55% | Training loss: 0.6934054298834367
Epoch: 66 | Iteration number: [230/393] 58% | Training loss: 0.6932991727538731
Epoch: 66 | Iteration number: [240/393] 61% | Training loss: 0.693178516626358
Epoch: 66 | Iteration number: [250/393] 63% | Training loss: 0.6930743937492371
Epoch: 66 | Iteration number: [260/393] 66% | Training loss: 0.6929468982494794
Epoch: 66 | Iteration number: [270/393] 68% | Training loss: 0.6927641954686906
Epoch: 66 | Iteration number: [280/393] 71% | Training loss: 0.6926771585430418
Epoch: 66 | Iteration number: [290/393] 73% | Training loss: 0.6925756201661867
Epoch: 66 | Iteration number: [300/393] 76% | Training loss: 0.6924982865651449
Epoch: 66 | Iteration number: [310/393] 78% | Training loss: 0.6924254527015071
Epoch: 66 | Iteration number: [320/393] 81% | Training loss: 0.6923784060403705
Epoch: 66 | Iteration number: [330/393] 83% | Training loss: 0.6923103482434244
Epoch: 66 | Iteration number: [340/393] 86% | Training loss: 0.6922641701558057
Epoch: 66 | Iteration number: [350/393] 89% | Training loss: 0.6921815734250205
Epoch: 66 | Iteration number: [360/393] 91% | Training loss: 0.6921058454447322
Epoch: 66 | Iteration number: [370/393] 94% | Training loss: 0.6920417147713739
Epoch: 66 | Iteration number: [380/393] 96% | Training loss: 0.6919964062540155
Epoch: 66 | Iteration number: [390/393] 99% | Training loss: 0.6919452314193432

 End of epoch: 66 | Train Loss: 0.6901710794778877 | Training Time: 66 

 End of epoch: 66 | Eval Loss: 0.6900890080296264 | Evaluating Time: 16 
Epoch: 67 | Iteration number: [10/393] 2% | Training loss: 0.7590093016624451
Epoch: 67 | Iteration number: [20/393] 5% | Training loss: 0.7251718968153
Epoch: 67 | Iteration number: [30/393] 7% | Training loss: 0.7132354338963827
Epoch: 67 | Iteration number: [40/393] 10% | Training loss: 0.7077136307954788
Epoch: 67 | Iteration number: [50/393] 12% | Training loss: 0.7039433181285858
Epoch: 67 | Iteration number: [60/393] 15% | Training loss: 0.7016191770633061
Epoch: 67 | Iteration number: [70/393] 17% | Training loss: 0.7000060217721121
Epoch: 67 | Iteration number: [80/393] 20% | Training loss: 0.698782031238079
Epoch: 67 | Iteration number: [90/393] 22% | Training loss: 0.6977629906601376
Epoch: 67 | Iteration number: [100/393] 25% | Training loss: 0.6970269560813904
Epoch: 67 | Iteration number: [110/393] 27% | Training loss: 0.6963519589467482
Epoch: 67 | Iteration number: [120/393] 30% | Training loss: 0.6957949474453926
Epoch: 67 | Iteration number: [130/393] 33% | Training loss: 0.6953614542117486
Epoch: 67 | Iteration number: [140/393] 35% | Training loss: 0.6950153614793505
Epoch: 67 | Iteration number: [150/393] 38% | Training loss: 0.6947518825531006
Epoch: 67 | Iteration number: [160/393] 40% | Training loss: 0.6943970341235399
Epoch: 67 | Iteration number: [170/393] 43% | Training loss: 0.6940889670568354
Epoch: 67 | Iteration number: [180/393] 45% | Training loss: 0.693843146165212
Epoch: 67 | Iteration number: [190/393] 48% | Training loss: 0.6937057592366871
Epoch: 67 | Iteration number: [200/393] 50% | Training loss: 0.6935483676195144
Epoch: 67 | Iteration number: [210/393] 53% | Training loss: 0.6933768612997873
Epoch: 67 | Iteration number: [220/393] 55% | Training loss: 0.6931685241785916
Epoch: 67 | Iteration number: [230/393] 58% | Training loss: 0.6930303786111914
Epoch: 67 | Iteration number: [240/393] 61% | Training loss: 0.6929025116066138
Epoch: 67 | Iteration number: [250/393] 63% | Training loss: 0.6928273265361786
Epoch: 67 | Iteration number: [260/393] 66% | Training loss: 0.6927545066063221
Epoch: 67 | Iteration number: [270/393] 68% | Training loss: 0.6927184034276892
Epoch: 67 | Iteration number: [280/393] 71% | Training loss: 0.6926866192902837
Epoch: 67 | Iteration number: [290/393] 73% | Training loss: 0.6926125773068132
Epoch: 67 | Iteration number: [300/393] 76% | Training loss: 0.6925408291816711
Epoch: 67 | Iteration number: [310/393] 78% | Training loss: 0.6924553869232055
Epoch: 67 | Iteration number: [320/393] 81% | Training loss: 0.6923741670325398
Epoch: 67 | Iteration number: [330/393] 83% | Training loss: 0.6922626453818697
Epoch: 67 | Iteration number: [340/393] 86% | Training loss: 0.6921900360023274
Epoch: 67 | Iteration number: [350/393] 89% | Training loss: 0.6921090090274811
Epoch: 67 | Iteration number: [360/393] 91% | Training loss: 0.6920711586872736
Epoch: 67 | Iteration number: [370/393] 94% | Training loss: 0.691973600999729
Epoch: 67 | Iteration number: [380/393] 96% | Training loss: 0.6919441318825672
Epoch: 67 | Iteration number: [390/393] 99% | Training loss: 0.6919313514843966

 End of epoch: 67 | Train Loss: 0.690174639983335 | Training Time: 66 

 End of epoch: 67 | Eval Loss: 0.6906197703614527 | Evaluating Time: 17 
Epoch: 68 | Iteration number: [10/393] 2% | Training loss: 0.7591550469398498
Epoch: 68 | Iteration number: [20/393] 5% | Training loss: 0.7245407849550247
Epoch: 68 | Iteration number: [30/393] 7% | Training loss: 0.7131110270818074
Epoch: 68 | Iteration number: [40/393] 10% | Training loss: 0.707528218626976
Epoch: 68 | Iteration number: [50/393] 12% | Training loss: 0.704257527589798
Epoch: 68 | Iteration number: [60/393] 15% | Training loss: 0.702146926522255
Epoch: 68 | Iteration number: [70/393] 17% | Training loss: 0.7004461739744459
Epoch: 68 | Iteration number: [80/393] 20% | Training loss: 0.699167973548174
Epoch: 68 | Iteration number: [90/393] 22% | Training loss: 0.6982177999284532
Epoch: 68 | Iteration number: [100/393] 25% | Training loss: 0.6973618423938751
Epoch: 68 | Iteration number: [110/393] 27% | Training loss: 0.6967019828883084
Epoch: 68 | Iteration number: [120/393] 30% | Training loss: 0.6961077253023783
Epoch: 68 | Iteration number: [130/393] 33% | Training loss: 0.6956692489293905
Epoch: 68 | Iteration number: [140/393] 35% | Training loss: 0.6952035418578557
Epoch: 68 | Iteration number: [150/393] 38% | Training loss: 0.6948790574073791
Epoch: 68 | Iteration number: [160/393] 40% | Training loss: 0.6945915974676609
Epoch: 68 | Iteration number: [170/393] 43% | Training loss: 0.6943381912568036
Epoch: 68 | Iteration number: [180/393] 45% | Training loss: 0.6941460622681512
Epoch: 68 | Iteration number: [190/393] 48% | Training loss: 0.6939989359755265
Epoch: 68 | Iteration number: [200/393] 50% | Training loss: 0.6937860000133514
Epoch: 68 | Iteration number: [210/393] 53% | Training loss: 0.6935885083107721
Epoch: 68 | Iteration number: [220/393] 55% | Training loss: 0.6934082161296498
Epoch: 68 | Iteration number: [230/393] 58% | Training loss: 0.6932665806749593
Epoch: 68 | Iteration number: [240/393] 61% | Training loss: 0.6931236652036508
Epoch: 68 | Iteration number: [250/393] 63% | Training loss: 0.6930018556118012
Epoch: 68 | Iteration number: [260/393] 66% | Training loss: 0.6929045154498173
Epoch: 68 | Iteration number: [270/393] 68% | Training loss: 0.6928167722843311
Epoch: 68 | Iteration number: [280/393] 71% | Training loss: 0.6927265652588436
Epoch: 68 | Iteration number: [290/393] 73% | Training loss: 0.6926040371944164
Epoch: 68 | Iteration number: [300/393] 76% | Training loss: 0.6924883584181468
Epoch: 68 | Iteration number: [310/393] 78% | Training loss: 0.6924313206826487
Epoch: 68 | Iteration number: [320/393] 81% | Training loss: 0.6923477130010725
Epoch: 68 | Iteration number: [330/393] 83% | Training loss: 0.6922953993985147
Epoch: 68 | Iteration number: [340/393] 86% | Training loss: 0.6922550341662239
Epoch: 68 | Iteration number: [350/393] 89% | Training loss: 0.6922112357616425
Epoch: 68 | Iteration number: [360/393] 91% | Training loss: 0.6921551679571469
Epoch: 68 | Iteration number: [370/393] 94% | Training loss: 0.6920913280667486
Epoch: 68 | Iteration number: [380/393] 96% | Training loss: 0.6920181461070714
Epoch: 68 | Iteration number: [390/393] 99% | Training loss: 0.6919795303772658

 End of epoch: 68 | Train Loss: 0.6902076686914944 | Training Time: 66 

 End of epoch: 68 | Eval Loss: 0.690131391797747 | Evaluating Time: 16 
Epoch: 69 | Iteration number: [10/393] 2% | Training loss: 0.759599506855011
Epoch: 69 | Iteration number: [20/393] 5% | Training loss: 0.7248576611280442
Epoch: 69 | Iteration number: [30/393] 7% | Training loss: 0.7133320351441701
Epoch: 69 | Iteration number: [40/393] 10% | Training loss: 0.7075079679489136
Epoch: 69 | Iteration number: [50/393] 12% | Training loss: 0.7039168512821198
Epoch: 69 | Iteration number: [60/393] 15% | Training loss: 0.7015801588694255
Epoch: 69 | Iteration number: [70/393] 17% | Training loss: 0.6999288371631077
Epoch: 69 | Iteration number: [80/393] 20% | Training loss: 0.6986923091113567
Epoch: 69 | Iteration number: [90/393] 22% | Training loss: 0.6976565400759379
Epoch: 69 | Iteration number: [100/393] 25% | Training loss: 0.6968411892652512
Epoch: 69 | Iteration number: [110/393] 27% | Training loss: 0.696286448023536
Epoch: 69 | Iteration number: [120/393] 30% | Training loss: 0.6957362711429596
Epoch: 69 | Iteration number: [130/393] 33% | Training loss: 0.6952892748209146
Epoch: 69 | Iteration number: [140/393] 35% | Training loss: 0.6948557602507728
Epoch: 69 | Iteration number: [150/393] 38% | Training loss: 0.6946198145548502
Epoch: 69 | Iteration number: [160/393] 40% | Training loss: 0.6944378271698952
Epoch: 69 | Iteration number: [170/393] 43% | Training loss: 0.6942173316198237
Epoch: 69 | Iteration number: [180/393] 45% | Training loss: 0.6939439174201754
Epoch: 69 | Iteration number: [190/393] 48% | Training loss: 0.6937820274578897
Epoch: 69 | Iteration number: [200/393] 50% | Training loss: 0.6936224147677421
Epoch: 69 | Iteration number: [210/393] 53% | Training loss: 0.6934711084479377
Epoch: 69 | Iteration number: [220/393] 55% | Training loss: 0.6933272862976247
Epoch: 69 | Iteration number: [230/393] 58% | Training loss: 0.693203153040098
Epoch: 69 | Iteration number: [240/393] 61% | Training loss: 0.6930302609999974
Epoch: 69 | Iteration number: [250/393] 63% | Training loss: 0.6929070997238159
Epoch: 69 | Iteration number: [260/393] 66% | Training loss: 0.6928039745642589
Epoch: 69 | Iteration number: [270/393] 68% | Training loss: 0.6927011862949088
Epoch: 69 | Iteration number: [280/393] 71% | Training loss: 0.692641190971647
Epoch: 69 | Iteration number: [290/393] 73% | Training loss: 0.6925668769869311
Epoch: 69 | Iteration number: [300/393] 76% | Training loss: 0.6925032126903534
Epoch: 69 | Iteration number: [310/393] 78% | Training loss: 0.6923706339251611
Epoch: 69 | Iteration number: [320/393] 81% | Training loss: 0.6923136204481125
Epoch: 69 | Iteration number: [330/393] 83% | Training loss: 0.6922315080960592
Epoch: 69 | Iteration number: [340/393] 86% | Training loss: 0.6921988199738895
Epoch: 69 | Iteration number: [350/393] 89% | Training loss: 0.6921346696785519
Epoch: 69 | Iteration number: [360/393] 91% | Training loss: 0.692118627164099
Epoch: 69 | Iteration number: [370/393] 94% | Training loss: 0.692074214445578
Epoch: 69 | Iteration number: [380/393] 96% | Training loss: 0.6920428592907755
Epoch: 69 | Iteration number: [390/393] 99% | Training loss: 0.691953915816087

 End of epoch: 69 | Train Loss: 0.6901740565251455 | Training Time: 66 

 End of epoch: 69 | Eval Loss: 0.6901214536355467 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/393] 2% | Training loss: 0.7585680365562439
Epoch: 70 | Iteration number: [20/393] 5% | Training loss: 0.7247137427330017
Epoch: 70 | Iteration number: [30/393] 7% | Training loss: 0.7128577788670858
Epoch: 70 | Iteration number: [40/393] 10% | Training loss: 0.7073282033205033
Epoch: 70 | Iteration number: [50/393] 12% | Training loss: 0.7039498686790466
Epoch: 70 | Iteration number: [60/393] 15% | Training loss: 0.7016455352306366
Epoch: 70 | Iteration number: [70/393] 17% | Training loss: 0.6999244800635747
Epoch: 70 | Iteration number: [80/393] 20% | Training loss: 0.698725713044405
Epoch: 70 | Iteration number: [90/393] 22% | Training loss: 0.697720201810201
Epoch: 70 | Iteration number: [100/393] 25% | Training loss: 0.6969641798734665
Epoch: 70 | Iteration number: [110/393] 27% | Training loss: 0.69634957855398
Epoch: 70 | Iteration number: [120/393] 30% | Training loss: 0.6957912037769953
Epoch: 70 | Iteration number: [130/393] 33% | Training loss: 0.6953063625555772
Epoch: 70 | Iteration number: [140/393] 35% | Training loss: 0.6950236929314477
Epoch: 70 | Iteration number: [150/393] 38% | Training loss: 0.6947030429045359
Epoch: 70 | Iteration number: [160/393] 40% | Training loss: 0.6944338925182819
Epoch: 70 | Iteration number: [170/393] 43% | Training loss: 0.6941551348742316
Epoch: 70 | Iteration number: [180/393] 45% | Training loss: 0.693918581141366
Epoch: 70 | Iteration number: [190/393] 48% | Training loss: 0.6937494193252765
Epoch: 70 | Iteration number: [200/393] 50% | Training loss: 0.693591865003109
Epoch: 70 | Iteration number: [210/393] 53% | Training loss: 0.6934471207005637
Epoch: 70 | Iteration number: [220/393] 55% | Training loss: 0.6933314204216003
Epoch: 70 | Iteration number: [230/393] 58% | Training loss: 0.6931551166202711
Epoch: 70 | Iteration number: [240/393] 61% | Training loss: 0.6930335216224194
Epoch: 70 | Iteration number: [250/393] 63% | Training loss: 0.6928998579978943
Epoch: 70 | Iteration number: [260/393] 66% | Training loss: 0.6928457833253421
Epoch: 70 | Iteration number: [270/393] 68% | Training loss: 0.6927598547052454
Epoch: 70 | Iteration number: [280/393] 71% | Training loss: 0.6926451878888267
Epoch: 70 | Iteration number: [290/393] 73% | Training loss: 0.6925953201178847
Epoch: 70 | Iteration number: [300/393] 76% | Training loss: 0.6925192534923553
Epoch: 70 | Iteration number: [310/393] 78% | Training loss: 0.6924344330064712
Epoch: 70 | Iteration number: [320/393] 81% | Training loss: 0.6923627380281687
Epoch: 70 | Iteration number: [330/393] 83% | Training loss: 0.6922677607247324
Epoch: 70 | Iteration number: [340/393] 86% | Training loss: 0.6921985431629069
Epoch: 70 | Iteration number: [350/393] 89% | Training loss: 0.6921250651563917
Epoch: 70 | Iteration number: [360/393] 91% | Training loss: 0.6920873370435503
Epoch: 70 | Iteration number: [370/393] 94% | Training loss: 0.6920452053482468
Epoch: 70 | Iteration number: [380/393] 96% | Training loss: 0.692004712631828
Epoch: 70 | Iteration number: [390/393] 99% | Training loss: 0.6919928199205643

 End of epoch: 70 | Train Loss: 0.6902065061734226 | Training Time: 66 

 End of epoch: 70 | Eval Loss: 0.690085628811194 | Evaluating Time: 17 
Epoch: 71 | Iteration number: [10/393] 2% | Training loss: 0.7591532468795776
Epoch: 71 | Iteration number: [20/393] 5% | Training loss: 0.7240577310323715
Epoch: 71 | Iteration number: [30/393] 7% | Training loss: 0.7129281163215637
Epoch: 71 | Iteration number: [40/393] 10% | Training loss: 0.7068925142288208
Epoch: 71 | Iteration number: [50/393] 12% | Training loss: 0.7034023571014404
Epoch: 71 | Iteration number: [60/393] 15% | Training loss: 0.7014083246390025
Epoch: 71 | Iteration number: [70/393] 17% | Training loss: 0.6999087010111128
Epoch: 71 | Iteration number: [80/393] 20% | Training loss: 0.6986552558839321
Epoch: 71 | Iteration number: [90/393] 22% | Training loss: 0.6976797527737088
Epoch: 71 | Iteration number: [100/393] 25% | Training loss: 0.6969246226549148
Epoch: 71 | Iteration number: [110/393] 27% | Training loss: 0.6961948075077751
Epoch: 71 | Iteration number: [120/393] 30% | Training loss: 0.6956571449836095
Epoch: 71 | Iteration number: [130/393] 33% | Training loss: 0.6951583655980917
Epoch: 71 | Iteration number: [140/393] 35% | Training loss: 0.6947744160890579
Epoch: 71 | Iteration number: [150/393] 38% | Training loss: 0.6945164354642233
Epoch: 71 | Iteration number: [160/393] 40% | Training loss: 0.6942064110189676
Epoch: 71 | Iteration number: [170/393] 43% | Training loss: 0.6939779081765343
Epoch: 71 | Iteration number: [180/393] 45% | Training loss: 0.6937817146380743
Epoch: 71 | Iteration number: [190/393] 48% | Training loss: 0.6936081914525283
Epoch: 71 | Iteration number: [200/393] 50% | Training loss: 0.6934275293350219
Epoch: 71 | Iteration number: [210/393] 53% | Training loss: 0.6932714677992321
Epoch: 71 | Iteration number: [220/393] 55% | Training loss: 0.6931102432987907
Epoch: 71 | Iteration number: [230/393] 58% | Training loss: 0.6929814512315003
Epoch: 71 | Iteration number: [240/393] 61% | Training loss: 0.6928964162866275
Epoch: 71 | Iteration number: [250/393] 63% | Training loss: 0.6928052096366882
Epoch: 71 | Iteration number: [260/393] 66% | Training loss: 0.6927480092415443
Epoch: 71 | Iteration number: [270/393] 68% | Training loss: 0.6926594776135904
Epoch: 71 | Iteration number: [280/393] 71% | Training loss: 0.6925558013575418
Epoch: 71 | Iteration number: [290/393] 73% | Training loss: 0.6924679567073954
Epoch: 71 | Iteration number: [300/393] 76% | Training loss: 0.6924112536509832
Epoch: 71 | Iteration number: [310/393] 78% | Training loss: 0.6923423905526438
Epoch: 71 | Iteration number: [320/393] 81% | Training loss: 0.6922792179509998
Epoch: 71 | Iteration number: [330/393] 83% | Training loss: 0.6922160179326029
Epoch: 71 | Iteration number: [340/393] 86% | Training loss: 0.6921831944409539
Epoch: 71 | Iteration number: [350/393] 89% | Training loss: 0.6921146181651524
Epoch: 71 | Iteration number: [360/393] 91% | Training loss: 0.6920576032665041
Epoch: 71 | Iteration number: [370/393] 94% | Training loss: 0.6920109634463851
Epoch: 71 | Iteration number: [380/393] 96% | Training loss: 0.6919722535108265
Epoch: 71 | Iteration number: [390/393] 99% | Training loss: 0.6919348135972634

 End of epoch: 71 | Train Loss: 0.6901673257502587 | Training Time: 66 

 End of epoch: 71 | Eval Loss: 0.6900612809220139 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/393] 2% | Training loss: 0.7575070858001709
Epoch: 72 | Iteration number: [20/393] 5% | Training loss: 0.7240310907363892
Epoch: 72 | Iteration number: [30/393] 7% | Training loss: 0.7126577337582906
Epoch: 72 | Iteration number: [40/393] 10% | Training loss: 0.7070818364620208
Epoch: 72 | Iteration number: [50/393] 12% | Training loss: 0.7039260041713714
Epoch: 72 | Iteration number: [60/393] 15% | Training loss: 0.7015987694263458
Epoch: 72 | Iteration number: [70/393] 17% | Training loss: 0.7000534789902824
Epoch: 72 | Iteration number: [80/393] 20% | Training loss: 0.6988091073930264
Epoch: 72 | Iteration number: [90/393] 22% | Training loss: 0.6978544864389632
Epoch: 72 | Iteration number: [100/393] 25% | Training loss: 0.6970691424608231
Epoch: 72 | Iteration number: [110/393] 27% | Training loss: 0.6964880320158872
Epoch: 72 | Iteration number: [120/393] 30% | Training loss: 0.6960020040472349
Epoch: 72 | Iteration number: [130/393] 33% | Training loss: 0.6955153671594766
Epoch: 72 | Iteration number: [140/393] 35% | Training loss: 0.6950455350535256
Epoch: 72 | Iteration number: [150/393] 38% | Training loss: 0.6947800540924072
Epoch: 72 | Iteration number: [160/393] 40% | Training loss: 0.6945040576159954
Epoch: 72 | Iteration number: [170/393] 43% | Training loss: 0.6942149667178883
Epoch: 72 | Iteration number: [180/393] 45% | Training loss: 0.693979005350007
Epoch: 72 | Iteration number: [190/393] 48% | Training loss: 0.6937636585612046
Epoch: 72 | Iteration number: [200/393] 50% | Training loss: 0.69360126465559
Epoch: 72 | Iteration number: [210/393] 53% | Training loss: 0.6934931559222085
Epoch: 72 | Iteration number: [220/393] 55% | Training loss: 0.6933059042150324
Epoch: 72 | Iteration number: [230/393] 58% | Training loss: 0.6931897513244463
Epoch: 72 | Iteration number: [240/393] 61% | Training loss: 0.6930475026369095
Epoch: 72 | Iteration number: [250/393] 63% | Training loss: 0.692970858335495
Epoch: 72 | Iteration number: [260/393] 66% | Training loss: 0.6928890778468205
Epoch: 72 | Iteration number: [270/393] 68% | Training loss: 0.6927503376095383
Epoch: 72 | Iteration number: [280/393] 71% | Training loss: 0.6925591962678092
Epoch: 72 | Iteration number: [290/393] 73% | Training loss: 0.6924857893894458
Epoch: 72 | Iteration number: [300/393] 76% | Training loss: 0.6923335361480712
Epoch: 72 | Iteration number: [310/393] 78% | Training loss: 0.6921956118076078
Epoch: 72 | Iteration number: [320/393] 81% | Training loss: 0.6921481650322676
Epoch: 72 | Iteration number: [330/393] 83% | Training loss: 0.6921264216755376
Epoch: 72 | Iteration number: [340/393] 86% | Training loss: 0.6920857592540629
Epoch: 72 | Iteration number: [350/393] 89% | Training loss: 0.6920326043878283
Epoch: 72 | Iteration number: [360/393] 91% | Training loss: 0.6920012922750579
Epoch: 72 | Iteration number: [370/393] 94% | Training loss: 0.691986856267259
Epoch: 72 | Iteration number: [380/393] 96% | Training loss: 0.6919387039385344
Epoch: 72 | Iteration number: [390/393] 99% | Training loss: 0.6918709715207417

 End of epoch: 72 | Train Loss: 0.6900997923227363 | Training Time: 66 

 End of epoch: 72 | Eval Loss: 0.6900317425630531 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/393] 2% | Training loss: 0.7599904119968415
Epoch: 73 | Iteration number: [20/393] 5% | Training loss: 0.7253073781728745
Epoch: 73 | Iteration number: [30/393] 7% | Training loss: 0.7138279656569163
Epoch: 73 | Iteration number: [40/393] 10% | Training loss: 0.7080786511301994
Epoch: 73 | Iteration number: [50/393] 12% | Training loss: 0.7044012057781219
Epoch: 73 | Iteration number: [60/393] 15% | Training loss: 0.7019399106502533
Epoch: 73 | Iteration number: [70/393] 17% | Training loss: 0.7002177723816463
Epoch: 73 | Iteration number: [80/393] 20% | Training loss: 0.6989950142800808
Epoch: 73 | Iteration number: [90/393] 22% | Training loss: 0.6979942606555091
Epoch: 73 | Iteration number: [100/393] 25% | Training loss: 0.6970919555425644
Epoch: 73 | Iteration number: [110/393] 27% | Training loss: 0.6964855362068523
Epoch: 73 | Iteration number: [120/393] 30% | Training loss: 0.6959175040324529
Epoch: 73 | Iteration number: [130/393] 33% | Training loss: 0.6955133020877838
Epoch: 73 | Iteration number: [140/393] 35% | Training loss: 0.6950983758483614
Epoch: 73 | Iteration number: [150/393] 38% | Training loss: 0.6947615540027618
Epoch: 73 | Iteration number: [160/393] 40% | Training loss: 0.6944349315017462
Epoch: 73 | Iteration number: [170/393] 43% | Training loss: 0.6941581242224749
Epoch: 73 | Iteration number: [180/393] 45% | Training loss: 0.6939273287852605
Epoch: 73 | Iteration number: [190/393] 48% | Training loss: 0.6936842181180652
Epoch: 73 | Iteration number: [200/393] 50% | Training loss: 0.6935245478153229
Epoch: 73 | Iteration number: [210/393] 53% | Training loss: 0.6933986970356533
Epoch: 73 | Iteration number: [220/393] 55% | Training loss: 0.6932165433060039
Epoch: 73 | Iteration number: [230/393] 58% | Training loss: 0.6931132762328438
Epoch: 73 | Iteration number: [240/393] 61% | Training loss: 0.6929897859692573
Epoch: 73 | Iteration number: [250/393] 63% | Training loss: 0.6928904821872711
Epoch: 73 | Iteration number: [260/393] 66% | Training loss: 0.6927790380441226
Epoch: 73 | Iteration number: [270/393] 68% | Training loss: 0.6927096965136351
Epoch: 73 | Iteration number: [280/393] 71% | Training loss: 0.6925974513803209
Epoch: 73 | Iteration number: [290/393] 73% | Training loss: 0.692532604110652
Epoch: 73 | Iteration number: [300/393] 76% | Training loss: 0.6924504301945369
Epoch: 73 | Iteration number: [310/393] 78% | Training loss: 0.6923811183821771
Epoch: 73 | Iteration number: [320/393] 81% | Training loss: 0.6923259856179357
Epoch: 73 | Iteration number: [330/393] 83% | Training loss: 0.6922618074850603
Epoch: 73 | Iteration number: [340/393] 86% | Training loss: 0.6921847792232738
Epoch: 73 | Iteration number: [350/393] 89% | Training loss: 0.6921147472517831
Epoch: 73 | Iteration number: [360/393] 91% | Training loss: 0.6920738296376334
Epoch: 73 | Iteration number: [370/393] 94% | Training loss: 0.6920247628882125
Epoch: 73 | Iteration number: [380/393] 96% | Training loss: 0.6919985898231206
Epoch: 73 | Iteration number: [390/393] 99% | Training loss: 0.6919376741617154

 End of epoch: 73 | Train Loss: 0.6901708733641161 | Training Time: 66 

 End of epoch: 73 | Eval Loss: 0.69006034792686 | Evaluating Time: 16 
Epoch: 74 | Iteration number: [10/393] 2% | Training loss: 0.7601056098937988
Epoch: 74 | Iteration number: [20/393] 5% | Training loss: 0.7251374363899231
Epoch: 74 | Iteration number: [30/393] 7% | Training loss: 0.7138287742932637
Epoch: 74 | Iteration number: [40/393] 10% | Training loss: 0.708036196231842
Epoch: 74 | Iteration number: [50/393] 12% | Training loss: 0.7045257830619812
Epoch: 74 | Iteration number: [60/393] 15% | Training loss: 0.7021173934141794
Epoch: 74 | Iteration number: [70/393] 17% | Training loss: 0.7003623485565186
Epoch: 74 | Iteration number: [80/393] 20% | Training loss: 0.699086744338274
Epoch: 74 | Iteration number: [90/393] 22% | Training loss: 0.698230979177687
Epoch: 74 | Iteration number: [100/393] 25% | Training loss: 0.6974077254533768
Epoch: 74 | Iteration number: [110/393] 27% | Training loss: 0.6967821809378537
Epoch: 74 | Iteration number: [120/393] 30% | Training loss: 0.6960990875959396
Epoch: 74 | Iteration number: [130/393] 33% | Training loss: 0.6956436647818639
Epoch: 74 | Iteration number: [140/393] 35% | Training loss: 0.6952956395489829
Epoch: 74 | Iteration number: [150/393] 38% | Training loss: 0.6949741343657175
Epoch: 74 | Iteration number: [160/393] 40% | Training loss: 0.694680656120181
Epoch: 74 | Iteration number: [170/393] 43% | Training loss: 0.6944404090152068
Epoch: 74 | Iteration number: [180/393] 45% | Training loss: 0.6942614174551434
Epoch: 74 | Iteration number: [190/393] 48% | Training loss: 0.6940331186118879
Epoch: 74 | Iteration number: [200/393] 50% | Training loss: 0.6938675507903099
Epoch: 74 | Iteration number: [210/393] 53% | Training loss: 0.6936526607899439
Epoch: 74 | Iteration number: [220/393] 55% | Training loss: 0.6934756810014898
Epoch: 74 | Iteration number: [230/393] 58% | Training loss: 0.6933184361976126
Epoch: 74 | Iteration number: [240/393] 61% | Training loss: 0.6932010566194852
Epoch: 74 | Iteration number: [250/393] 63% | Training loss: 0.6931068201065064
Epoch: 74 | Iteration number: [260/393] 66% | Training loss: 0.6930018411232874
Epoch: 74 | Iteration number: [270/393] 68% | Training loss: 0.6928865684403314
Epoch: 74 | Iteration number: [280/393] 71% | Training loss: 0.6927908984678132
Epoch: 74 | Iteration number: [290/393] 73% | Training loss: 0.6926961230820623
Epoch: 74 | Iteration number: [300/393] 76% | Training loss: 0.692595104376475
Epoch: 74 | Iteration number: [310/393] 78% | Training loss: 0.6924988379401545
Epoch: 74 | Iteration number: [320/393] 81% | Training loss: 0.6924111057072878
Epoch: 74 | Iteration number: [330/393] 83% | Training loss: 0.6923569805694348
Epoch: 74 | Iteration number: [340/393] 86% | Training loss: 0.6922022738877465
Epoch: 74 | Iteration number: [350/393] 89% | Training loss: 0.6921442447389875
Epoch: 74 | Iteration number: [360/393] 91% | Training loss: 0.6920815742678113
Epoch: 74 | Iteration number: [370/393] 94% | Training loss: 0.6920398224044491
Epoch: 74 | Iteration number: [380/393] 96% | Training loss: 0.691980232219947
Epoch: 74 | Iteration number: [390/393] 99% | Training loss: 0.6919204526986831

 End of epoch: 74 | Train Loss: 0.6901610567976197 | Training Time: 66 

 End of epoch: 74 | Eval Loss: 0.6900248016629901 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/393] 2% | Training loss: 0.7594484269618988
Epoch: 75 | Iteration number: [20/393] 5% | Training loss: 0.7246267855167389
Epoch: 75 | Iteration number: [30/393] 7% | Training loss: 0.7129843513170878
Epoch: 75 | Iteration number: [40/393] 10% | Training loss: 0.7073539182543754
Epoch: 75 | Iteration number: [50/393] 12% | Training loss: 0.7040935146808625
Epoch: 75 | Iteration number: [60/393] 15% | Training loss: 0.701982311407725
Epoch: 75 | Iteration number: [70/393] 17% | Training loss: 0.7001812824181148
Epoch: 75 | Iteration number: [80/393] 20% | Training loss: 0.6989249154925347
Epoch: 75 | Iteration number: [90/393] 22% | Training loss: 0.6978986806339688
Epoch: 75 | Iteration number: [100/393] 25% | Training loss: 0.6971570199728012
Epoch: 75 | Iteration number: [110/393] 27% | Training loss: 0.6965128828178753
Epoch: 75 | Iteration number: [120/393] 30% | Training loss: 0.6960187296072642
Epoch: 75 | Iteration number: [130/393] 33% | Training loss: 0.6956214120754829
Epoch: 75 | Iteration number: [140/393] 35% | Training loss: 0.6951778671571187
Epoch: 75 | Iteration number: [150/393] 38% | Training loss: 0.6948144555091857
Epoch: 75 | Iteration number: [160/393] 40% | Training loss: 0.6945665389299392
Epoch: 75 | Iteration number: [170/393] 43% | Training loss: 0.6942512736600988
Epoch: 75 | Iteration number: [180/393] 45% | Training loss: 0.6939344363080131
Epoch: 75 | Iteration number: [190/393] 48% | Training loss: 0.6937424186028932
Epoch: 75 | Iteration number: [200/393] 50% | Training loss: 0.693612285554409
Epoch: 75 | Iteration number: [210/393] 53% | Training loss: 0.693448976959501
Epoch: 75 | Iteration number: [220/393] 55% | Training loss: 0.6932942157441919
Epoch: 75 | Iteration number: [230/393] 58% | Training loss: 0.69310960640078
Epoch: 75 | Iteration number: [240/393] 61% | Training loss: 0.6930120999614398
Epoch: 75 | Iteration number: [250/393] 63% | Training loss: 0.6928944928646088
Epoch: 75 | Iteration number: [260/393] 66% | Training loss: 0.6927838779412783
Epoch: 75 | Iteration number: [270/393] 68% | Training loss: 0.6927044437991248
Epoch: 75 | Iteration number: [280/393] 71% | Training loss: 0.6926017986876624
Epoch: 75 | Iteration number: [290/393] 73% | Training loss: 0.6925370880242052
Epoch: 75 | Iteration number: [300/393] 76% | Training loss: 0.6924440276622772
Epoch: 75 | Iteration number: [310/393] 78% | Training loss: 0.6923361647513605
Epoch: 75 | Iteration number: [320/393] 81% | Training loss: 0.6921856490895152
Epoch: 75 | Iteration number: [330/393] 83% | Training loss: 0.6921454760161313
Epoch: 75 | Iteration number: [340/393] 86% | Training loss: 0.6921008558834301
Epoch: 75 | Iteration number: [350/393] 89% | Training loss: 0.6920223537513188
Epoch: 75 | Iteration number: [360/393] 91% | Training loss: 0.6919497064418263
Epoch: 75 | Iteration number: [370/393] 94% | Training loss: 0.6919140163305644
Epoch: 75 | Iteration number: [380/393] 96% | Training loss: 0.6918773356236909
Epoch: 75 | Iteration number: [390/393] 99% | Training loss: 0.6918519064401969

 End of epoch: 75 | Train Loss: 0.6900813546192859 | Training Time: 66 

 End of epoch: 75 | Eval Loss: 0.6901015493334556 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/393] 2% | Training loss: 0.7579038679599762
Epoch: 76 | Iteration number: [20/393] 5% | Training loss: 0.7238368541002274
Epoch: 76 | Iteration number: [30/393] 7% | Training loss: 0.7124594251314799
Epoch: 76 | Iteration number: [40/393] 10% | Training loss: 0.7066999629139901
Epoch: 76 | Iteration number: [50/393] 12% | Training loss: 0.7034465324878693
Epoch: 76 | Iteration number: [60/393] 15% | Training loss: 0.7013758649428685
Epoch: 76 | Iteration number: [70/393] 17% | Training loss: 0.6999088321413313
Epoch: 76 | Iteration number: [80/393] 20% | Training loss: 0.698651359975338
Epoch: 76 | Iteration number: [90/393] 22% | Training loss: 0.6978643536567688
Epoch: 76 | Iteration number: [100/393] 25% | Training loss: 0.6971140158176422
Epoch: 76 | Iteration number: [110/393] 27% | Training loss: 0.6964930377223275
Epoch: 76 | Iteration number: [120/393] 30% | Training loss: 0.6960262204209964
Epoch: 76 | Iteration number: [130/393] 33% | Training loss: 0.6954895120400649
Epoch: 76 | Iteration number: [140/393] 35% | Training loss: 0.6951392710208892
Epoch: 76 | Iteration number: [150/393] 38% | Training loss: 0.6948268183072408
Epoch: 76 | Iteration number: [160/393] 40% | Training loss: 0.6945014592260123
Epoch: 76 | Iteration number: [170/393] 43% | Training loss: 0.6942413473830503
Epoch: 76 | Iteration number: [180/393] 45% | Training loss: 0.6940614081091351
Epoch: 76 | Iteration number: [190/393] 48% | Training loss: 0.6939133951538488
Epoch: 76 | Iteration number: [200/393] 50% | Training loss: 0.6937384155392646
Epoch: 76 | Iteration number: [210/393] 53% | Training loss: 0.6936227242151897
Epoch: 76 | Iteration number: [220/393] 55% | Training loss: 0.6934553062373942
Epoch: 76 | Iteration number: [230/393] 58% | Training loss: 0.6933557375617649
Epoch: 76 | Iteration number: [240/393] 61% | Training loss: 0.6932416362067063
Epoch: 76 | Iteration number: [250/393] 63% | Training loss: 0.6931251811981202
Epoch: 76 | Iteration number: [260/393] 66% | Training loss: 0.6929759188340261
Epoch: 76 | Iteration number: [270/393] 68% | Training loss: 0.692890586455663
Epoch: 76 | Iteration number: [280/393] 71% | Training loss: 0.6927422840680395
Epoch: 76 | Iteration number: [290/393] 73% | Training loss: 0.6926921338870607
Epoch: 76 | Iteration number: [300/393] 76% | Training loss: 0.6925983188549677
Epoch: 76 | Iteration number: [310/393] 78% | Training loss: 0.6924983080356352
Epoch: 76 | Iteration number: [320/393] 81% | Training loss: 0.6924382708966732
Epoch: 76 | Iteration number: [330/393] 83% | Training loss: 0.6923443398692392
Epoch: 76 | Iteration number: [340/393] 86% | Training loss: 0.6922712580246084
Epoch: 76 | Iteration number: [350/393] 89% | Training loss: 0.692204578604017
Epoch: 76 | Iteration number: [360/393] 91% | Training loss: 0.6921649795439508
Epoch: 76 | Iteration number: [370/393] 94% | Training loss: 0.6920958356277362
Epoch: 76 | Iteration number: [380/393] 96% | Training loss: 0.6920573286320034
Epoch: 76 | Iteration number: [390/393] 99% | Training loss: 0.6919696285174444

 End of epoch: 76 | Train Loss: 0.6901881922292346 | Training Time: 66 

 End of epoch: 76 | Eval Loss: 0.6901846564545924 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/393] 2% | Training loss: 0.7581055402755738
Epoch: 77 | Iteration number: [20/393] 5% | Training loss: 0.7242453426122666
Epoch: 77 | Iteration number: [30/393] 7% | Training loss: 0.7125110924243927
Epoch: 77 | Iteration number: [40/393] 10% | Training loss: 0.7069478332996368
Epoch: 77 | Iteration number: [50/393] 12% | Training loss: 0.7034186685085296
Epoch: 77 | Iteration number: [60/393] 15% | Training loss: 0.701202932993571
Epoch: 77 | Iteration number: [70/393] 17% | Training loss: 0.6996115795203618
Epoch: 77 | Iteration number: [80/393] 20% | Training loss: 0.6983347542583942
Epoch: 77 | Iteration number: [90/393] 22% | Training loss: 0.697428697347641
Epoch: 77 | Iteration number: [100/393] 25% | Training loss: 0.6966726034879684
Epoch: 77 | Iteration number: [110/393] 27% | Training loss: 0.6960671977563337
Epoch: 77 | Iteration number: [120/393] 30% | Training loss: 0.6956621184945107
Epoch: 77 | Iteration number: [130/393] 33% | Training loss: 0.6953735773379986
Epoch: 77 | Iteration number: [140/393] 35% | Training loss: 0.695084633571761
Epoch: 77 | Iteration number: [150/393] 38% | Training loss: 0.6947770869731903
Epoch: 77 | Iteration number: [160/393] 40% | Training loss: 0.694328286498785
Epoch: 77 | Iteration number: [170/393] 43% | Training loss: 0.6941305349854862
Epoch: 77 | Iteration number: [180/393] 45% | Training loss: 0.6939022087388569
Epoch: 77 | Iteration number: [190/393] 48% | Training loss: 0.6937144326536279
Epoch: 77 | Iteration number: [200/393] 50% | Training loss: 0.6934271630644798
Epoch: 77 | Iteration number: [210/393] 53% | Training loss: 0.6932867660408928
Epoch: 77 | Iteration number: [220/393] 55% | Training loss: 0.6931955681605773
Epoch: 77 | Iteration number: [230/393] 58% | Training loss: 0.693022539563801
Epoch: 77 | Iteration number: [240/393] 61% | Training loss: 0.6928202770650387
Epoch: 77 | Iteration number: [250/393] 63% | Training loss: 0.6927066974639893
Epoch: 77 | Iteration number: [260/393] 66% | Training loss: 0.6926296637608454
Epoch: 77 | Iteration number: [270/393] 68% | Training loss: 0.6925459592430679
Epoch: 77 | Iteration number: [280/393] 71% | Training loss: 0.6924999151911054
Epoch: 77 | Iteration number: [290/393] 73% | Training loss: 0.6924533903598785
Epoch: 77 | Iteration number: [300/393] 76% | Training loss: 0.6923836052417756
Epoch: 77 | Iteration number: [310/393] 78% | Training loss: 0.6923288826019534
Epoch: 77 | Iteration number: [320/393] 81% | Training loss: 0.6922805111855268
Epoch: 77 | Iteration number: [330/393] 83% | Training loss: 0.6922343449159102
Epoch: 77 | Iteration number: [340/393] 86% | Training loss: 0.6921858554377275
Epoch: 77 | Iteration number: [350/393] 89% | Training loss: 0.6921419325896672
Epoch: 77 | Iteration number: [360/393] 91% | Training loss: 0.6921345889568329
Epoch: 77 | Iteration number: [370/393] 94% | Training loss: 0.6920746569697921
Epoch: 77 | Iteration number: [380/393] 96% | Training loss: 0.691985213129144
Epoch: 77 | Iteration number: [390/393] 99% | Training loss: 0.6919520627229642

 End of epoch: 77 | Train Loss: 0.6901686824005069 | Training Time: 66 

 End of epoch: 77 | Eval Loss: 0.69006867554723 | Evaluating Time: 17 
Epoch: 78 | Iteration number: [10/393] 2% | Training loss: 0.7576136291027069
Epoch: 78 | Iteration number: [20/393] 5% | Training loss: 0.7240014463663101
Epoch: 78 | Iteration number: [30/393] 7% | Training loss: 0.7125453571478526
Epoch: 78 | Iteration number: [40/393] 10% | Training loss: 0.706710259616375
Epoch: 78 | Iteration number: [50/393] 12% | Training loss: 0.7034472119808197
Epoch: 78 | Iteration number: [60/393] 15% | Training loss: 0.7011243641376496
Epoch: 78 | Iteration number: [70/393] 17% | Training loss: 0.6995892865317208
Epoch: 78 | Iteration number: [80/393] 20% | Training loss: 0.6983634866774082
Epoch: 78 | Iteration number: [90/393] 22% | Training loss: 0.6974337564574348
Epoch: 78 | Iteration number: [100/393] 25% | Training loss: 0.6968434691429138
Epoch: 78 | Iteration number: [110/393] 27% | Training loss: 0.6962179720401764
Epoch: 78 | Iteration number: [120/393] 30% | Training loss: 0.695736572643121
Epoch: 78 | Iteration number: [130/393] 33% | Training loss: 0.6953472834367018
Epoch: 78 | Iteration number: [140/393] 35% | Training loss: 0.6949839110885347
Epoch: 78 | Iteration number: [150/393] 38% | Training loss: 0.6946787707010905
Epoch: 78 | Iteration number: [160/393] 40% | Training loss: 0.6943918410688639
Epoch: 78 | Iteration number: [170/393] 43% | Training loss: 0.6941517009454615
Epoch: 78 | Iteration number: [180/393] 45% | Training loss: 0.6939211659961276
Epoch: 78 | Iteration number: [190/393] 48% | Training loss: 0.6936718291357944
Epoch: 78 | Iteration number: [200/393] 50% | Training loss: 0.6935373213887215
Epoch: 78 | Iteration number: [210/393] 53% | Training loss: 0.693393025511787
Epoch: 78 | Iteration number: [220/393] 55% | Training loss: 0.6932019805366343
Epoch: 78 | Iteration number: [230/393] 58% | Training loss: 0.693087493336719
Epoch: 78 | Iteration number: [240/393] 61% | Training loss: 0.6929627428452174
Epoch: 78 | Iteration number: [250/393] 63% | Training loss: 0.6928930356502533
Epoch: 78 | Iteration number: [260/393] 66% | Training loss: 0.6928265117681943
Epoch: 78 | Iteration number: [270/393] 68% | Training loss: 0.6927155602861333
Epoch: 78 | Iteration number: [280/393] 71% | Training loss: 0.6925929050360408
Epoch: 78 | Iteration number: [290/393] 73% | Training loss: 0.692542726623601
Epoch: 78 | Iteration number: [300/393] 76% | Training loss: 0.6924799424409867
Epoch: 78 | Iteration number: [310/393] 78% | Training loss: 0.6924628186610438
Epoch: 78 | Iteration number: [320/393] 81% | Training loss: 0.6923911850899458
Epoch: 78 | Iteration number: [330/393] 83% | Training loss: 0.6923276655601732
Epoch: 78 | Iteration number: [340/393] 86% | Training loss: 0.6922550445093828
Epoch: 78 | Iteration number: [350/393] 89% | Training loss: 0.6921653049332755
Epoch: 78 | Iteration number: [360/393] 91% | Training loss: 0.6921159878373147
Epoch: 78 | Iteration number: [370/393] 94% | Training loss: 0.6920667223028234
Epoch: 78 | Iteration number: [380/393] 96% | Training loss: 0.6920154700153752
Epoch: 78 | Iteration number: [390/393] 99% | Training loss: 0.6919452768105727

 End of epoch: 78 | Train Loss: 0.6901744045980711 | Training Time: 66 

 End of epoch: 78 | Eval Loss: 0.6900628878145801 | Evaluating Time: 17 
Epoch: 79 | Iteration number: [10/393] 2% | Training loss: 0.7592266201972961
Epoch: 79 | Iteration number: [20/393] 5% | Training loss: 0.7242816269397736
Epoch: 79 | Iteration number: [30/393] 7% | Training loss: 0.7130961199601491
Epoch: 79 | Iteration number: [40/393] 10% | Training loss: 0.7073066100478173
Epoch: 79 | Iteration number: [50/393] 12% | Training loss: 0.7040180027484894
Epoch: 79 | Iteration number: [60/393] 15% | Training loss: 0.7018561174472173
Epoch: 79 | Iteration number: [70/393] 17% | Training loss: 0.6999917396477291
Epoch: 79 | Iteration number: [80/393] 20% | Training loss: 0.6987780570983887
Epoch: 79 | Iteration number: [90/393] 22% | Training loss: 0.6978738923867543
Epoch: 79 | Iteration number: [100/393] 25% | Training loss: 0.697118011713028
Epoch: 79 | Iteration number: [110/393] 27% | Training loss: 0.6964765792543238
Epoch: 79 | Iteration number: [120/393] 30% | Training loss: 0.696002755065759
Epoch: 79 | Iteration number: [130/393] 33% | Training loss: 0.695557257762322
Epoch: 79 | Iteration number: [140/393] 35% | Training loss: 0.6951967435223716
Epoch: 79 | Iteration number: [150/393] 38% | Training loss: 0.6948436351617178
Epoch: 79 | Iteration number: [160/393] 40% | Training loss: 0.6946051277220249
Epoch: 79 | Iteration number: [170/393] 43% | Training loss: 0.6942977754508748
Epoch: 79 | Iteration number: [180/393] 45% | Training loss: 0.6940799597236845
Epoch: 79 | Iteration number: [190/393] 48% | Training loss: 0.6938522392197659
Epoch: 79 | Iteration number: [200/393] 50% | Training loss: 0.6936761179566383
Epoch: 79 | Iteration number: [210/393] 53% | Training loss: 0.6935463048162914
Epoch: 79 | Iteration number: [220/393] 55% | Training loss: 0.6933512882752852
Epoch: 79 | Iteration number: [230/393] 58% | Training loss: 0.6931708970795507
Epoch: 79 | Iteration number: [240/393] 61% | Training loss: 0.6930334026614825
Epoch: 79 | Iteration number: [250/393] 63% | Training loss: 0.6928849391937256
Epoch: 79 | Iteration number: [260/393] 66% | Training loss: 0.6927787601947785
Epoch: 79 | Iteration number: [270/393] 68% | Training loss: 0.692681031315415
Epoch: 79 | Iteration number: [280/393] 71% | Training loss: 0.6925582413162504
Epoch: 79 | Iteration number: [290/393] 73% | Training loss: 0.6924610807977873
Epoch: 79 | Iteration number: [300/393] 76% | Training loss: 0.692375063498815
Epoch: 79 | Iteration number: [310/393] 78% | Training loss: 0.6922319542977118
Epoch: 79 | Iteration number: [320/393] 81% | Training loss: 0.6921791566535831
Epoch: 79 | Iteration number: [330/393] 83% | Training loss: 0.6921298697139278
Epoch: 79 | Iteration number: [340/393] 86% | Training loss: 0.6920835233786526
Epoch: 79 | Iteration number: [350/393] 89% | Training loss: 0.6920210981369018
Epoch: 79 | Iteration number: [360/393] 91% | Training loss: 0.6919977865285344
Epoch: 79 | Iteration number: [370/393] 94% | Training loss: 0.691945680089899
Epoch: 79 | Iteration number: [380/393] 96% | Training loss: 0.6919012353608482
Epoch: 79 | Iteration number: [390/393] 99% | Training loss: 0.6918731657358316

 End of epoch: 79 | Train Loss: 0.6901024784750611 | Training Time: 67 

 End of epoch: 79 | Eval Loss: 0.6900833759989057 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/393] 2% | Training loss: 0.75948366522789
Epoch: 80 | Iteration number: [20/393] 5% | Training loss: 0.7246849179267884
Epoch: 80 | Iteration number: [30/393] 7% | Training loss: 0.7131940603256226
Epoch: 80 | Iteration number: [40/393] 10% | Training loss: 0.707357807457447
Epoch: 80 | Iteration number: [50/393] 12% | Training loss: 0.7039017224311829
Epoch: 80 | Iteration number: [60/393] 15% | Training loss: 0.7015473693609238
Epoch: 80 | Iteration number: [70/393] 17% | Training loss: 0.6999542236328125
Epoch: 80 | Iteration number: [80/393] 20% | Training loss: 0.6987861335277558
Epoch: 80 | Iteration number: [90/393] 22% | Training loss: 0.6977231323719024
Epoch: 80 | Iteration number: [100/393] 25% | Training loss: 0.6969299924373626
Epoch: 80 | Iteration number: [110/393] 27% | Training loss: 0.6963121246207844
Epoch: 80 | Iteration number: [120/393] 30% | Training loss: 0.6958040977517764
Epoch: 80 | Iteration number: [130/393] 33% | Training loss: 0.6953260724361127
Epoch: 80 | Iteration number: [140/393] 35% | Training loss: 0.695014551281929
Epoch: 80 | Iteration number: [150/393] 38% | Training loss: 0.6946876362959544
Epoch: 80 | Iteration number: [160/393] 40% | Training loss: 0.6943945083767176
Epoch: 80 | Iteration number: [170/393] 43% | Training loss: 0.6941130441777846
Epoch: 80 | Iteration number: [180/393] 45% | Training loss: 0.6937948283221986
Epoch: 80 | Iteration number: [190/393] 48% | Training loss: 0.6936248606757114
Epoch: 80 | Iteration number: [200/393] 50% | Training loss: 0.6934348064661026
Epoch: 80 | Iteration number: [210/393] 53% | Training loss: 0.6932950286638169
Epoch: 80 | Iteration number: [220/393] 55% | Training loss: 0.6931924725120718
Epoch: 80 | Iteration number: [230/393] 58% | Training loss: 0.6930708815222201
Epoch: 80 | Iteration number: [240/393] 61% | Training loss: 0.692935108145078
Epoch: 80 | Iteration number: [250/393] 63% | Training loss: 0.6928441772460937
Epoch: 80 | Iteration number: [260/393] 66% | Training loss: 0.6927327999701867
Epoch: 80 | Iteration number: [270/393] 68% | Training loss: 0.6926297024444298
Epoch: 80 | Iteration number: [280/393] 71% | Training loss: 0.6925247156194279
Epoch: 80 | Iteration number: [290/393] 73% | Training loss: 0.692446368110591
Epoch: 80 | Iteration number: [300/393] 76% | Training loss: 0.6923651035626729
Epoch: 80 | Iteration number: [310/393] 78% | Training loss: 0.6923001766204834
Epoch: 80 | Iteration number: [320/393] 81% | Training loss: 0.692279502376914
Epoch: 80 | Iteration number: [330/393] 83% | Training loss: 0.6922107203440233
Epoch: 80 | Iteration number: [340/393] 86% | Training loss: 0.6921542763710022
Epoch: 80 | Iteration number: [350/393] 89% | Training loss: 0.6921037924289704
Epoch: 80 | Iteration number: [360/393] 91% | Training loss: 0.6920430547661252
Epoch: 80 | Iteration number: [370/393] 94% | Training loss: 0.6919909475622951
Epoch: 80 | Iteration number: [380/393] 96% | Training loss: 0.6919448344331038
Epoch: 80 | Iteration number: [390/393] 99% | Training loss: 0.6919102058960841

 End of epoch: 80 | Train Loss: 0.6901411324663623 | Training Time: 67 

 End of epoch: 80 | Eval Loss: 0.6901851028812175 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/393] 2% | Training loss: 0.7589182317256927
Epoch: 81 | Iteration number: [20/393] 5% | Training loss: 0.7250620871782303
Epoch: 81 | Iteration number: [30/393] 7% | Training loss: 0.7133100668589274
Epoch: 81 | Iteration number: [40/393] 10% | Training loss: 0.7075988188385963
Epoch: 81 | Iteration number: [50/393] 12% | Training loss: 0.7041422343254089
Epoch: 81 | Iteration number: [60/393] 15% | Training loss: 0.7016725907723109
Epoch: 81 | Iteration number: [70/393] 17% | Training loss: 0.6999636760779789
Epoch: 81 | Iteration number: [80/393] 20% | Training loss: 0.6987571321427822
Epoch: 81 | Iteration number: [90/393] 22% | Training loss: 0.6978179143534766
Epoch: 81 | Iteration number: [100/393] 25% | Training loss: 0.6970255410671234
Epoch: 81 | Iteration number: [110/393] 27% | Training loss: 0.6963897721333937
Epoch: 81 | Iteration number: [120/393] 30% | Training loss: 0.6959080507357915
Epoch: 81 | Iteration number: [130/393] 33% | Training loss: 0.6954535122101123
Epoch: 81 | Iteration number: [140/393] 35% | Training loss: 0.6950806507042476
Epoch: 81 | Iteration number: [150/393] 38% | Training loss: 0.6947808400789897
Epoch: 81 | Iteration number: [160/393] 40% | Training loss: 0.6945102244615555
Epoch: 81 | Iteration number: [170/393] 43% | Training loss: 0.6942220018190496
Epoch: 81 | Iteration number: [180/393] 45% | Training loss: 0.6939750406477186
Epoch: 81 | Iteration number: [190/393] 48% | Training loss: 0.6937958714209105
Epoch: 81 | Iteration number: [200/393] 50% | Training loss: 0.6936568531394005
Epoch: 81 | Iteration number: [210/393] 53% | Training loss: 0.6935711256095342
Epoch: 81 | Iteration number: [220/393] 55% | Training loss: 0.6933812699534676
Epoch: 81 | Iteration number: [230/393] 58% | Training loss: 0.6932049429934958
Epoch: 81 | Iteration number: [240/393] 61% | Training loss: 0.6930616614719232
Epoch: 81 | Iteration number: [250/393] 63% | Training loss: 0.6929781906604767
Epoch: 81 | Iteration number: [260/393] 66% | Training loss: 0.692852070239874
Epoch: 81 | Iteration number: [270/393] 68% | Training loss: 0.6927373546141166
Epoch: 81 | Iteration number: [280/393] 71% | Training loss: 0.6926646081464631
Epoch: 81 | Iteration number: [290/393] 73% | Training loss: 0.6925923516010416
Epoch: 81 | Iteration number: [300/393] 76% | Training loss: 0.692484297156334
Epoch: 81 | Iteration number: [310/393] 78% | Training loss: 0.6924436076994865
Epoch: 81 | Iteration number: [320/393] 81% | Training loss: 0.6923735002055764
Epoch: 81 | Iteration number: [330/393] 83% | Training loss: 0.6922774602066387
Epoch: 81 | Iteration number: [340/393] 86% | Training loss: 0.6922199806746314
Epoch: 81 | Iteration number: [350/393] 89% | Training loss: 0.692138842855181
Epoch: 81 | Iteration number: [360/393] 91% | Training loss: 0.6920936220222049
Epoch: 81 | Iteration number: [370/393] 94% | Training loss: 0.6920362765724595
Epoch: 81 | Iteration number: [380/393] 96% | Training loss: 0.6919827934942747
Epoch: 81 | Iteration number: [390/393] 99% | Training loss: 0.6919183500302144

 End of epoch: 81 | Train Loss: 0.6901441331734791 | Training Time: 66 

 End of epoch: 81 | Eval Loss: 0.6900774276986414 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/393] 2% | Training loss: 0.7601983189582825
Epoch: 82 | Iteration number: [20/393] 5% | Training loss: 0.7249466985464096
Epoch: 82 | Iteration number: [30/393] 7% | Training loss: 0.7132530907789866
Epoch: 82 | Iteration number: [40/393] 10% | Training loss: 0.7075243443250656
Epoch: 82 | Iteration number: [50/393] 12% | Training loss: 0.7040993583202362
Epoch: 82 | Iteration number: [60/393] 15% | Training loss: 0.7017002522945404
Epoch: 82 | Iteration number: [70/393] 17% | Training loss: 0.6999476534979684
Epoch: 82 | Iteration number: [80/393] 20% | Training loss: 0.698824942111969
Epoch: 82 | Iteration number: [90/393] 22% | Training loss: 0.6976064079337649
Epoch: 82 | Iteration number: [100/393] 25% | Training loss: 0.6969263404607773
Epoch: 82 | Iteration number: [110/393] 27% | Training loss: 0.6963837916200811
Epoch: 82 | Iteration number: [120/393] 30% | Training loss: 0.6958827624718348
Epoch: 82 | Iteration number: [130/393] 33% | Training loss: 0.6954133437230037
Epoch: 82 | Iteration number: [140/393] 35% | Training loss: 0.6950683227607182
Epoch: 82 | Iteration number: [150/393] 38% | Training loss: 0.6946879800160726
Epoch: 82 | Iteration number: [160/393] 40% | Training loss: 0.6943477869033814
Epoch: 82 | Iteration number: [170/393] 43% | Training loss: 0.6940778609584359
Epoch: 82 | Iteration number: [180/393] 45% | Training loss: 0.6938259326749378
Epoch: 82 | Iteration number: [190/393] 48% | Training loss: 0.6936290361379323
Epoch: 82 | Iteration number: [200/393] 50% | Training loss: 0.6934990710020066
Epoch: 82 | Iteration number: [210/393] 53% | Training loss: 0.6933517813682556
Epoch: 82 | Iteration number: [220/393] 55% | Training loss: 0.6932116248390892
Epoch: 82 | Iteration number: [230/393] 58% | Training loss: 0.6930558222791423
Epoch: 82 | Iteration number: [240/393] 61% | Training loss: 0.692967422803243
Epoch: 82 | Iteration number: [250/393] 63% | Training loss: 0.6928476033210754
Epoch: 82 | Iteration number: [260/393] 66% | Training loss: 0.6927679002285003
Epoch: 82 | Iteration number: [270/393] 68% | Training loss: 0.6926789650210627
Epoch: 82 | Iteration number: [280/393] 71% | Training loss: 0.6925922506621905
Epoch: 82 | Iteration number: [290/393] 73% | Training loss: 0.692507012753651
Epoch: 82 | Iteration number: [300/393] 76% | Training loss: 0.6924525670210521
Epoch: 82 | Iteration number: [310/393] 78% | Training loss: 0.6923741861697166
Epoch: 82 | Iteration number: [320/393] 81% | Training loss: 0.6923074839636684
Epoch: 82 | Iteration number: [330/393] 83% | Training loss: 0.6922241808790149
Epoch: 82 | Iteration number: [340/393] 86% | Training loss: 0.6921807967564639
Epoch: 82 | Iteration number: [350/393] 89% | Training loss: 0.692137862443924
Epoch: 82 | Iteration number: [360/393] 91% | Training loss: 0.6920913858546152
Epoch: 82 | Iteration number: [370/393] 94% | Training loss: 0.6920012842964481
Epoch: 82 | Iteration number: [380/393] 96% | Training loss: 0.69194009100136
Epoch: 82 | Iteration number: [390/393] 99% | Training loss: 0.6918919621369778

 End of epoch: 82 | Train Loss: 0.6901315189803223 | Training Time: 66 

 End of epoch: 82 | Eval Loss: 0.6900105598021526 | Evaluating Time: 17 
Epoch: 83 | Iteration number: [10/393] 2% | Training loss: 0.7584971725940705
Epoch: 83 | Iteration number: [20/393] 5% | Training loss: 0.7240812927484512
Epoch: 83 | Iteration number: [30/393] 7% | Training loss: 0.7123263438542684
Epoch: 83 | Iteration number: [40/393] 10% | Training loss: 0.7068271592259407
Epoch: 83 | Iteration number: [50/393] 12% | Training loss: 0.7035362410545349
Epoch: 83 | Iteration number: [60/393] 15% | Training loss: 0.7011725217103958
Epoch: 83 | Iteration number: [70/393] 17% | Training loss: 0.6996744990348815
Epoch: 83 | Iteration number: [80/393] 20% | Training loss: 0.6985402785241603
Epoch: 83 | Iteration number: [90/393] 22% | Training loss: 0.6976325631141662
Epoch: 83 | Iteration number: [100/393] 25% | Training loss: 0.6969128710031509
Epoch: 83 | Iteration number: [110/393] 27% | Training loss: 0.696257836710323
Epoch: 83 | Iteration number: [120/393] 30% | Training loss: 0.6957482700546582
Epoch: 83 | Iteration number: [130/393] 33% | Training loss: 0.6953610906234154
Epoch: 83 | Iteration number: [140/393] 35% | Training loss: 0.6949386136872427
Epoch: 83 | Iteration number: [150/393] 38% | Training loss: 0.6945852903525035
Epoch: 83 | Iteration number: [160/393] 40% | Training loss: 0.6943213392049075
Epoch: 83 | Iteration number: [170/393] 43% | Training loss: 0.6940392574843238
Epoch: 83 | Iteration number: [180/393] 45% | Training loss: 0.6938393768337038
Epoch: 83 | Iteration number: [190/393] 48% | Training loss: 0.6936805530598289
Epoch: 83 | Iteration number: [200/393] 50% | Training loss: 0.693550777733326
Epoch: 83 | Iteration number: [210/393] 53% | Training loss: 0.6933898048741477
Epoch: 83 | Iteration number: [220/393] 55% | Training loss: 0.6932141461155631
Epoch: 83 | Iteration number: [230/393] 58% | Training loss: 0.6930361434169438
Epoch: 83 | Iteration number: [240/393] 61% | Training loss: 0.6928781896829606
Epoch: 83 | Iteration number: [250/393] 63% | Training loss: 0.6927857716083526
Epoch: 83 | Iteration number: [260/393] 66% | Training loss: 0.692680520277757
Epoch: 83 | Iteration number: [270/393] 68% | Training loss: 0.6925642636087206
Epoch: 83 | Iteration number: [280/393] 71% | Training loss: 0.6924785184008735
Epoch: 83 | Iteration number: [290/393] 73% | Training loss: 0.6923893550346638
Epoch: 83 | Iteration number: [300/393] 76% | Training loss: 0.6923387132088343
Epoch: 83 | Iteration number: [310/393] 78% | Training loss: 0.6922211108669158
Epoch: 83 | Iteration number: [320/393] 81% | Training loss: 0.6921599278226495
Epoch: 83 | Iteration number: [330/393] 83% | Training loss: 0.6921183147213675
Epoch: 83 | Iteration number: [340/393] 86% | Training loss: 0.6920798219302121
Epoch: 83 | Iteration number: [350/393] 89% | Training loss: 0.6920165487698147
Epoch: 83 | Iteration number: [360/393] 91% | Training loss: 0.6919831251104672
Epoch: 83 | Iteration number: [370/393] 94% | Training loss: 0.6919649423779668
Epoch: 83 | Iteration number: [380/393] 96% | Training loss: 0.6919356201824389
Epoch: 83 | Iteration number: [390/393] 99% | Training loss: 0.6918759695994549

 End of epoch: 83 | Train Loss: 0.690106667635095 | Training Time: 67 

 End of epoch: 83 | Eval Loss: 0.6900145216863982 | Evaluating Time: 16 
Epoch: 84 | Iteration number: [10/393] 2% | Training loss: 0.7595182478427887
Epoch: 84 | Iteration number: [20/393] 5% | Training loss: 0.7247894316911697
Epoch: 84 | Iteration number: [30/393] 7% | Training loss: 0.7135250528653463
Epoch: 84 | Iteration number: [40/393] 10% | Training loss: 0.7079673543572426
Epoch: 84 | Iteration number: [50/393] 12% | Training loss: 0.7045453310012817
Epoch: 84 | Iteration number: [60/393] 15% | Training loss: 0.7020876864592235
Epoch: 84 | Iteration number: [70/393] 17% | Training loss: 0.7005563574177879
Epoch: 84 | Iteration number: [80/393] 20% | Training loss: 0.6993624396622181
Epoch: 84 | Iteration number: [90/393] 22% | Training loss: 0.6982384893629286
Epoch: 84 | Iteration number: [100/393] 25% | Training loss: 0.6973841720819474
Epoch: 84 | Iteration number: [110/393] 27% | Training loss: 0.6965764956040816
Epoch: 84 | Iteration number: [120/393] 30% | Training loss: 0.6960713719328244
Epoch: 84 | Iteration number: [130/393] 33% | Training loss: 0.6955830711584825
Epoch: 84 | Iteration number: [140/393] 35% | Training loss: 0.6952010887009757
Epoch: 84 | Iteration number: [150/393] 38% | Training loss: 0.694888885418574
Epoch: 84 | Iteration number: [160/393] 40% | Training loss: 0.69460011087358
Epoch: 84 | Iteration number: [170/393] 43% | Training loss: 0.6942494118914885
Epoch: 84 | Iteration number: [180/393] 45% | Training loss: 0.694014952911271
Epoch: 84 | Iteration number: [190/393] 48% | Training loss: 0.6937750050896092
Epoch: 84 | Iteration number: [200/393] 50% | Training loss: 0.6935143706202507
Epoch: 84 | Iteration number: [210/393] 53% | Training loss: 0.6933208212966011
Epoch: 84 | Iteration number: [220/393] 55% | Training loss: 0.6931139794262973
Epoch: 84 | Iteration number: [230/393] 58% | Training loss: 0.6929833894190581
Epoch: 84 | Iteration number: [240/393] 61% | Training loss: 0.6928678477803866
Epoch: 84 | Iteration number: [250/393] 63% | Training loss: 0.6927374262809753
Epoch: 84 | Iteration number: [260/393] 66% | Training loss: 0.6926210229213421
Epoch: 84 | Iteration number: [270/393] 68% | Training loss: 0.6925334831078848
Epoch: 84 | Iteration number: [280/393] 71% | Training loss: 0.6924508865390505
Epoch: 84 | Iteration number: [290/393] 73% | Training loss: 0.692385725111797
Epoch: 84 | Iteration number: [300/393] 76% | Training loss: 0.6923608605066935
Epoch: 84 | Iteration number: [310/393] 78% | Training loss: 0.6922680950933887
Epoch: 84 | Iteration number: [320/393] 81% | Training loss: 0.6922121465206146
Epoch: 84 | Iteration number: [330/393] 83% | Training loss: 0.6921738346417745
Epoch: 84 | Iteration number: [340/393] 86% | Training loss: 0.6921134110759286
Epoch: 84 | Iteration number: [350/393] 89% | Training loss: 0.6920524653366634
Epoch: 84 | Iteration number: [360/393] 91% | Training loss: 0.692007017797894
Epoch: 84 | Iteration number: [370/393] 94% | Training loss: 0.691941207002949
Epoch: 84 | Iteration number: [380/393] 96% | Training loss: 0.6919108386102476
Epoch: 84 | Iteration number: [390/393] 99% | Training loss: 0.691865227619807

 End of epoch: 84 | Train Loss: 0.6900937699786276 | Training Time: 65 

 End of epoch: 84 | Eval Loss: 0.6900792401664111 | Evaluating Time: 16 
Epoch: 85 | Iteration number: [10/393] 2% | Training loss: 0.7599328458309174
Epoch: 85 | Iteration number: [20/393] 5% | Training loss: 0.72492114007473
Epoch: 85 | Iteration number: [30/393] 7% | Training loss: 0.7134174942970276
Epoch: 85 | Iteration number: [40/393] 10% | Training loss: 0.7077719494700432
Epoch: 85 | Iteration number: [50/393] 12% | Training loss: 0.7042701780796051
Epoch: 85 | Iteration number: [60/393] 15% | Training loss: 0.7019967824220658
Epoch: 85 | Iteration number: [70/393] 17% | Training loss: 0.7003634435789926
Epoch: 85 | Iteration number: [80/393] 20% | Training loss: 0.6991237416863442
Epoch: 85 | Iteration number: [90/393] 22% | Training loss: 0.6982441438568963
Epoch: 85 | Iteration number: [100/393] 25% | Training loss: 0.6975572538375855
Epoch: 85 | Iteration number: [110/393] 27% | Training loss: 0.696877494725314
Epoch: 85 | Iteration number: [120/393] 30% | Training loss: 0.6963207686940829
Epoch: 85 | Iteration number: [130/393] 33% | Training loss: 0.6958300686799563
Epoch: 85 | Iteration number: [140/393] 35% | Training loss: 0.695419779419899
Epoch: 85 | Iteration number: [150/393] 38% | Training loss: 0.695053809483846
Epoch: 85 | Iteration number: [160/393] 40% | Training loss: 0.6946828693151474
Epoch: 85 | Iteration number: [170/393] 43% | Training loss: 0.6943968029583202
Epoch: 85 | Iteration number: [180/393] 45% | Training loss: 0.6941731572151184
Epoch: 85 | Iteration number: [190/393] 48% | Training loss: 0.6939764283205333
Epoch: 85 | Iteration number: [200/393] 50% | Training loss: 0.6936265540122986
Epoch: 85 | Iteration number: [210/393] 53% | Training loss: 0.6935042687824794
Epoch: 85 | Iteration number: [220/393] 55% | Training loss: 0.6933597483418205
Epoch: 85 | Iteration number: [230/393] 58% | Training loss: 0.6932428792766903
Epoch: 85 | Iteration number: [240/393] 61% | Training loss: 0.6930915820101897
Epoch: 85 | Iteration number: [250/393] 63% | Training loss: 0.6929802646636963
Epoch: 85 | Iteration number: [260/393] 66% | Training loss: 0.6928961343490161
Epoch: 85 | Iteration number: [270/393] 68% | Training loss: 0.6928092579046885
Epoch: 85 | Iteration number: [280/393] 71% | Training loss: 0.6927447561706815
Epoch: 85 | Iteration number: [290/393] 73% | Training loss: 0.6926648686672079
Epoch: 85 | Iteration number: [300/393] 76% | Training loss: 0.6925139824549357
Epoch: 85 | Iteration number: [310/393] 78% | Training loss: 0.6924085790111173
Epoch: 85 | Iteration number: [320/393] 81% | Training loss: 0.6922819538041949
Epoch: 85 | Iteration number: [330/393] 83% | Training loss: 0.6921958002177152
Epoch: 85 | Iteration number: [340/393] 86% | Training loss: 0.6920945456799339
Epoch: 85 | Iteration number: [350/393] 89% | Training loss: 0.6920239511557987
Epoch: 85 | Iteration number: [360/393] 91% | Training loss: 0.6919696791304483
Epoch: 85 | Iteration number: [370/393] 94% | Training loss: 0.6919381157771961
Epoch: 85 | Iteration number: [380/393] 96% | Training loss: 0.6918850169370049
Epoch: 85 | Iteration number: [390/393] 99% | Training loss: 0.6918175275509174

 End of epoch: 85 | Train Loss: 0.6900630329401438 | Training Time: 66 

 End of epoch: 85 | Eval Loss: 0.6900733940455378 | Evaluating Time: 17 
Epoch: 86 | Iteration number: [10/393] 2% | Training loss: 0.7587201476097107
Epoch: 86 | Iteration number: [20/393] 5% | Training loss: 0.7238162636756897
Epoch: 86 | Iteration number: [30/393] 7% | Training loss: 0.712784485022227
Epoch: 86 | Iteration number: [40/393] 10% | Training loss: 0.7070867121219635
Epoch: 86 | Iteration number: [50/393] 12% | Training loss: 0.70360342502594
Epoch: 86 | Iteration number: [60/393] 15% | Training loss: 0.7012849281231562
Epoch: 86 | Iteration number: [70/393] 17% | Training loss: 0.6995966741016932
Epoch: 86 | Iteration number: [80/393] 20% | Training loss: 0.698389832675457
Epoch: 86 | Iteration number: [90/393] 22% | Training loss: 0.6974015527301365
Epoch: 86 | Iteration number: [100/393] 25% | Training loss: 0.6967342275381089
Epoch: 86 | Iteration number: [110/393] 27% | Training loss: 0.6962058088996194
Epoch: 86 | Iteration number: [120/393] 30% | Training loss: 0.6956987634301186
Epoch: 86 | Iteration number: [130/393] 33% | Training loss: 0.6951900473007789
Epoch: 86 | Iteration number: [140/393] 35% | Training loss: 0.6948976555040904
Epoch: 86 | Iteration number: [150/393] 38% | Training loss: 0.6946221927801768
Epoch: 86 | Iteration number: [160/393] 40% | Training loss: 0.6943409480154514
Epoch: 86 | Iteration number: [170/393] 43% | Training loss: 0.6940560340881348
Epoch: 86 | Iteration number: [180/393] 45% | Training loss: 0.6938569631841448
Epoch: 86 | Iteration number: [190/393] 48% | Training loss: 0.6936962246894837
Epoch: 86 | Iteration number: [200/393] 50% | Training loss: 0.6935473349690437
Epoch: 86 | Iteration number: [210/393] 53% | Training loss: 0.6933845091433752
Epoch: 86 | Iteration number: [220/393] 55% | Training loss: 0.6932290502569892
Epoch: 86 | Iteration number: [230/393] 58% | Training loss: 0.6930977238261181
Epoch: 86 | Iteration number: [240/393] 61% | Training loss: 0.6930166413386663
Epoch: 86 | Iteration number: [250/393] 63% | Training loss: 0.6929161455631256
Epoch: 86 | Iteration number: [260/393] 66% | Training loss: 0.6927879225749236
Epoch: 86 | Iteration number: [270/393] 68% | Training loss: 0.6926607736834773
Epoch: 86 | Iteration number: [280/393] 71% | Training loss: 0.6926145323685238
Epoch: 86 | Iteration number: [290/393] 73% | Training loss: 0.6925364241517823
Epoch: 86 | Iteration number: [300/393] 76% | Training loss: 0.6924519530932108
Epoch: 86 | Iteration number: [310/393] 78% | Training loss: 0.692383929990953
Epoch: 86 | Iteration number: [320/393] 81% | Training loss: 0.6922890949994326
Epoch: 86 | Iteration number: [330/393] 83% | Training loss: 0.6922077715396882
Epoch: 86 | Iteration number: [340/393] 86% | Training loss: 0.6921502651537166
Epoch: 86 | Iteration number: [350/393] 89% | Training loss: 0.692088144336428
Epoch: 86 | Iteration number: [360/393] 91% | Training loss: 0.6920393071240849
Epoch: 86 | Iteration number: [370/393] 94% | Training loss: 0.6919771477982805
Epoch: 86 | Iteration number: [380/393] 96% | Training loss: 0.6919519033871199
Epoch: 86 | Iteration number: [390/393] 99% | Training loss: 0.691892885397642

 End of epoch: 86 | Train Loss: 0.6901267205789192 | Training Time: 66 

 End of epoch: 86 | Eval Loss: 0.6900528620700447 | Evaluating Time: 16 
Epoch: 87 | Iteration number: [10/393] 2% | Training loss: 0.7590871095657349
Epoch: 87 | Iteration number: [20/393] 5% | Training loss: 0.7255058020353318
Epoch: 87 | Iteration number: [30/393] 7% | Training loss: 0.7139840841293335
Epoch: 87 | Iteration number: [40/393] 10% | Training loss: 0.7082786798477173
Epoch: 87 | Iteration number: [50/393] 12% | Training loss: 0.7046759259700776
Epoch: 87 | Iteration number: [60/393] 15% | Training loss: 0.7024681160847346
Epoch: 87 | Iteration number: [70/393] 17% | Training loss: 0.7007641979626247
Epoch: 87 | Iteration number: [80/393] 20% | Training loss: 0.6994053021073341
Epoch: 87 | Iteration number: [90/393] 22% | Training loss: 0.6984217650360531
Epoch: 87 | Iteration number: [100/393] 25% | Training loss: 0.697592460513115
Epoch: 87 | Iteration number: [110/393] 27% | Training loss: 0.6969289210709658
Epoch: 87 | Iteration number: [120/393] 30% | Training loss: 0.6963322033484777
Epoch: 87 | Iteration number: [130/393] 33% | Training loss: 0.6958734865371997
Epoch: 87 | Iteration number: [140/393] 35% | Training loss: 0.6954445268426622
Epoch: 87 | Iteration number: [150/393] 38% | Training loss: 0.6951218024889628
Epoch: 87 | Iteration number: [160/393] 40% | Training loss: 0.6947655655443669
Epoch: 87 | Iteration number: [170/393] 43% | Training loss: 0.6944470247801613
Epoch: 87 | Iteration number: [180/393] 45% | Training loss: 0.6941688454813427
Epoch: 87 | Iteration number: [190/393] 48% | Training loss: 0.6939181265078093
Epoch: 87 | Iteration number: [200/393] 50% | Training loss: 0.6937300390005112
Epoch: 87 | Iteration number: [210/393] 53% | Training loss: 0.6935557626542591
Epoch: 87 | Iteration number: [220/393] 55% | Training loss: 0.6934373530474576
Epoch: 87 | Iteration number: [230/393] 58% | Training loss: 0.693269163629283
Epoch: 87 | Iteration number: [240/393] 61% | Training loss: 0.693111724158128
Epoch: 87 | Iteration number: [250/393] 63% | Training loss: 0.6929670298099517
Epoch: 87 | Iteration number: [260/393] 66% | Training loss: 0.6928796013960472
Epoch: 87 | Iteration number: [270/393] 68% | Training loss: 0.6927623742156559
Epoch: 87 | Iteration number: [280/393] 71% | Training loss: 0.6926664416279111
Epoch: 87 | Iteration number: [290/393] 73% | Training loss: 0.6925783780114404
Epoch: 87 | Iteration number: [300/393] 76% | Training loss: 0.6925335631767908
Epoch: 87 | Iteration number: [310/393] 78% | Training loss: 0.6924555816958028
Epoch: 87 | Iteration number: [320/393] 81% | Training loss: 0.6923626866191626
Epoch: 87 | Iteration number: [330/393] 83% | Training loss: 0.6922697148539804
Epoch: 87 | Iteration number: [340/393] 86% | Training loss: 0.692203633925494
Epoch: 87 | Iteration number: [350/393] 89% | Training loss: 0.6921304312774114
Epoch: 87 | Iteration number: [360/393] 91% | Training loss: 0.6921077178584205
Epoch: 87 | Iteration number: [370/393] 94% | Training loss: 0.6920608937740326
Epoch: 87 | Iteration number: [380/393] 96% | Training loss: 0.6920292763333572
Epoch: 87 | Iteration number: [390/393] 99% | Training loss: 0.6919472983250251

 End of epoch: 87 | Train Loss: 0.6901857346372143 | Training Time: 67 

 End of epoch: 87 | Eval Loss: 0.690061013309323 | Evaluating Time: 17 
Epoch: 88 | Iteration number: [10/393] 2% | Training loss: 0.7573168396949768
Epoch: 88 | Iteration number: [20/393] 5% | Training loss: 0.7235982865095139
Epoch: 88 | Iteration number: [30/393] 7% | Training loss: 0.7123697102069855
Epoch: 88 | Iteration number: [40/393] 10% | Training loss: 0.7068631783127785
Epoch: 88 | Iteration number: [50/393] 12% | Training loss: 0.703590235710144
Epoch: 88 | Iteration number: [60/393] 15% | Training loss: 0.701445284485817
Epoch: 88 | Iteration number: [70/393] 17% | Training loss: 0.6997459615979876
Epoch: 88 | Iteration number: [80/393] 20% | Training loss: 0.6985074579715729
Epoch: 88 | Iteration number: [90/393] 22% | Training loss: 0.6974805004066891
Epoch: 88 | Iteration number: [100/393] 25% | Training loss: 0.6967970889806747
Epoch: 88 | Iteration number: [110/393] 27% | Training loss: 0.6961623446507887
Epoch: 88 | Iteration number: [120/393] 30% | Training loss: 0.6956082974871
Epoch: 88 | Iteration number: [130/393] 33% | Training loss: 0.6951681866095616
Epoch: 88 | Iteration number: [140/393] 35% | Training loss: 0.6949158557823726
Epoch: 88 | Iteration number: [150/393] 38% | Training loss: 0.6945705608526865
Epoch: 88 | Iteration number: [160/393] 40% | Training loss: 0.6943078473210335
Epoch: 88 | Iteration number: [170/393] 43% | Training loss: 0.694099552491132
Epoch: 88 | Iteration number: [180/393] 45% | Training loss: 0.6939047008752823
Epoch: 88 | Iteration number: [190/393] 48% | Training loss: 0.6936924849685869
Epoch: 88 | Iteration number: [200/393] 50% | Training loss: 0.6935265532135964
Epoch: 88 | Iteration number: [210/393] 53% | Training loss: 0.6933996461686633
Epoch: 88 | Iteration number: [220/393] 55% | Training loss: 0.6931812240318819
Epoch: 88 | Iteration number: [230/393] 58% | Training loss: 0.6930483709210935
Epoch: 88 | Iteration number: [240/393] 61% | Training loss: 0.692917600274086
Epoch: 88 | Iteration number: [250/393] 63% | Training loss: 0.6928540992736817
Epoch: 88 | Iteration number: [260/393] 66% | Training loss: 0.6927252187178685
Epoch: 88 | Iteration number: [270/393] 68% | Training loss: 0.6926411758970331
Epoch: 88 | Iteration number: [280/393] 71% | Training loss: 0.692602028804166
Epoch: 88 | Iteration number: [290/393] 73% | Training loss: 0.6925112615371573
Epoch: 88 | Iteration number: [300/393] 76% | Training loss: 0.6924207011858622
Epoch: 88 | Iteration number: [310/393] 78% | Training loss: 0.6923695941125193
Epoch: 88 | Iteration number: [320/393] 81% | Training loss: 0.6922737121582031
Epoch: 88 | Iteration number: [330/393] 83% | Training loss: 0.6921829640865326
Epoch: 88 | Iteration number: [340/393] 86% | Training loss: 0.6921023829894908
Epoch: 88 | Iteration number: [350/393] 89% | Training loss: 0.6920551298345838
Epoch: 88 | Iteration number: [360/393] 91% | Training loss: 0.6920113465852208
Epoch: 88 | Iteration number: [370/393] 94% | Training loss: 0.6919662955644968
Epoch: 88 | Iteration number: [380/393] 96% | Training loss: 0.6919462931783575
Epoch: 88 | Iteration number: [390/393] 99% | Training loss: 0.691865518459907

 End of epoch: 88 | Train Loss: 0.6900708349303132 | Training Time: 67 

 End of epoch: 88 | Eval Loss: 0.6900667049446885 | Evaluating Time: 17 
Epoch: 89 | Iteration number: [10/393] 2% | Training loss: 0.759967041015625
Epoch: 89 | Iteration number: [20/393] 5% | Training loss: 0.7248764783143997
Epoch: 89 | Iteration number: [30/393] 7% | Training loss: 0.713176182905833
Epoch: 89 | Iteration number: [40/393] 10% | Training loss: 0.7074646949768066
Epoch: 89 | Iteration number: [50/393] 12% | Training loss: 0.7038513219356537
Epoch: 89 | Iteration number: [60/393] 15% | Training loss: 0.7013700038194657
Epoch: 89 | Iteration number: [70/393] 17% | Training loss: 0.6998935767582485
Epoch: 89 | Iteration number: [80/393] 20% | Training loss: 0.698789918422699
Epoch: 89 | Iteration number: [90/393] 22% | Training loss: 0.6977267377906375
Epoch: 89 | Iteration number: [100/393] 25% | Training loss: 0.6970238488912582
Epoch: 89 | Iteration number: [110/393] 27% | Training loss: 0.6963596073063937
Epoch: 89 | Iteration number: [120/393] 30% | Training loss: 0.6957934558391571
Epoch: 89 | Iteration number: [130/393] 33% | Training loss: 0.695356318125358
Epoch: 89 | Iteration number: [140/393] 35% | Training loss: 0.6949420447860445
Epoch: 89 | Iteration number: [150/393] 38% | Training loss: 0.694579568306605
Epoch: 89 | Iteration number: [160/393] 40% | Training loss: 0.6943213287740946
Epoch: 89 | Iteration number: [170/393] 43% | Training loss: 0.6940405337249531
Epoch: 89 | Iteration number: [180/393] 45% | Training loss: 0.693789451320966
Epoch: 89 | Iteration number: [190/393] 48% | Training loss: 0.6935668327306447
Epoch: 89 | Iteration number: [200/393] 50% | Training loss: 0.6933541822433472
Epoch: 89 | Iteration number: [210/393] 53% | Training loss: 0.6931919651372093
Epoch: 89 | Iteration number: [220/393] 55% | Training loss: 0.6930761247873306
Epoch: 89 | Iteration number: [230/393] 58% | Training loss: 0.6929414145324542
Epoch: 89 | Iteration number: [240/393] 61% | Training loss: 0.6928473201890787
Epoch: 89 | Iteration number: [250/393] 63% | Training loss: 0.6926870856285096
Epoch: 89 | Iteration number: [260/393] 66% | Training loss: 0.6926141835176027
Epoch: 89 | Iteration number: [270/393] 68% | Training loss: 0.6925326157499243
Epoch: 89 | Iteration number: [280/393] 71% | Training loss: 0.6924057260155678
Epoch: 89 | Iteration number: [290/393] 73% | Training loss: 0.692355091201848
Epoch: 89 | Iteration number: [300/393] 76% | Training loss: 0.6922594139973323
Epoch: 89 | Iteration number: [310/393] 78% | Training loss: 0.6922012465615426
Epoch: 89 | Iteration number: [320/393] 81% | Training loss: 0.6921389449387789
Epoch: 89 | Iteration number: [330/393] 83% | Training loss: 0.692049942594586
Epoch: 89 | Iteration number: [340/393] 86% | Training loss: 0.6920244430794436
Epoch: 89 | Iteration number: [350/393] 89% | Training loss: 0.6919822910853795
Epoch: 89 | Iteration number: [360/393] 91% | Training loss: 0.6919305375880666
Epoch: 89 | Iteration number: [370/393] 94% | Training loss: 0.6919121399119094
Epoch: 89 | Iteration number: [380/393] 96% | Training loss: 0.6918699440203215
Epoch: 89 | Iteration number: [390/393] 99% | Training loss: 0.6918220717173357

 End of epoch: 89 | Train Loss: 0.6900581426292886 | Training Time: 65 

 End of epoch: 89 | Eval Loss: 0.6900312754572654 | Evaluating Time: 16 
Epoch: 90 | Iteration number: [10/393] 2% | Training loss: 0.7580921113491058
Epoch: 90 | Iteration number: [20/393] 5% | Training loss: 0.7239952355623245
Epoch: 90 | Iteration number: [30/393] 7% | Training loss: 0.7128388126691182
Epoch: 90 | Iteration number: [40/393] 10% | Training loss: 0.7073260709643364
Epoch: 90 | Iteration number: [50/393] 12% | Training loss: 0.7037127053737641
Epoch: 90 | Iteration number: [60/393] 15% | Training loss: 0.7014655947685242
Epoch: 90 | Iteration number: [70/393] 17% | Training loss: 0.6999370132173811
Epoch: 90 | Iteration number: [80/393] 20% | Training loss: 0.6987104386091232
Epoch: 90 | Iteration number: [90/393] 22% | Training loss: 0.6978852060106066
Epoch: 90 | Iteration number: [100/393] 25% | Training loss: 0.6970818775892258
Epoch: 90 | Iteration number: [110/393] 27% | Training loss: 0.6965807345780459
Epoch: 90 | Iteration number: [120/393] 30% | Training loss: 0.6960291052858035
Epoch: 90 | Iteration number: [130/393] 33% | Training loss: 0.6955345314282637
Epoch: 90 | Iteration number: [140/393] 35% | Training loss: 0.6950923004320689
Epoch: 90 | Iteration number: [150/393] 38% | Training loss: 0.6946571592489879
Epoch: 90 | Iteration number: [160/393] 40% | Training loss: 0.6943766806274653
Epoch: 90 | Iteration number: [170/393] 43% | Training loss: 0.694104885003146
Epoch: 90 | Iteration number: [180/393] 45% | Training loss: 0.693896590007676
Epoch: 90 | Iteration number: [190/393] 48% | Training loss: 0.6936695105151126
Epoch: 90 | Iteration number: [200/393] 50% | Training loss: 0.6934282177686691
Epoch: 90 | Iteration number: [210/393] 53% | Training loss: 0.6932493275120145
Epoch: 90 | Iteration number: [220/393] 55% | Training loss: 0.6931200661442497
Epoch: 90 | Iteration number: [230/393] 58% | Training loss: 0.692942935746649
Epoch: 90 | Iteration number: [240/393] 61% | Training loss: 0.6928202169636886
Epoch: 90 | Iteration number: [250/393] 63% | Training loss: 0.6927106697559356
Epoch: 90 | Iteration number: [260/393] 66% | Training loss: 0.6926027639554098
Epoch: 90 | Iteration number: [270/393] 68% | Training loss: 0.6925192002896909
Epoch: 90 | Iteration number: [280/393] 71% | Training loss: 0.6924321459872382
Epoch: 90 | Iteration number: [290/393] 73% | Training loss: 0.6923695274468126
Epoch: 90 | Iteration number: [300/393] 76% | Training loss: 0.6923292988538742
Epoch: 90 | Iteration number: [310/393] 78% | Training loss: 0.6922768283274866
Epoch: 90 | Iteration number: [320/393] 81% | Training loss: 0.6921500496566295
Epoch: 90 | Iteration number: [330/393] 83% | Training loss: 0.6920910197677035
Epoch: 90 | Iteration number: [340/393] 86% | Training loss: 0.6920417650657542
Epoch: 90 | Iteration number: [350/393] 89% | Training loss: 0.69198753288814
Epoch: 90 | Iteration number: [360/393] 91% | Training loss: 0.6919256662329037
Epoch: 90 | Iteration number: [370/393] 94% | Training loss: 0.6918570790741895
Epoch: 90 | Iteration number: [380/393] 96% | Training loss: 0.6918142577535228
Epoch: 90 | Iteration number: [390/393] 99% | Training loss: 0.6917901399808052

 End of epoch: 90 | Train Loss: 0.6900289615298653 | Training Time: 67 

 End of epoch: 90 | Eval Loss: 0.6900909616022693 | Evaluating Time: 17 
Epoch: 91 | Iteration number: [10/393] 2% | Training loss: 0.7593955755233764
Epoch: 91 | Iteration number: [20/393] 5% | Training loss: 0.7251351237297058
Epoch: 91 | Iteration number: [30/393] 7% | Training loss: 0.7130362292130789
Epoch: 91 | Iteration number: [40/393] 10% | Training loss: 0.7074757501482963
Epoch: 91 | Iteration number: [50/393] 12% | Training loss: 0.7039269208908081
Epoch: 91 | Iteration number: [60/393] 15% | Training loss: 0.7013368636369706
Epoch: 91 | Iteration number: [70/393] 17% | Training loss: 0.6996100255421229
Epoch: 91 | Iteration number: [80/393] 20% | Training loss: 0.6983963564038277
Epoch: 91 | Iteration number: [90/393] 22% | Training loss: 0.6975205315483941
Epoch: 91 | Iteration number: [100/393] 25% | Training loss: 0.6968380206823349
Epoch: 91 | Iteration number: [110/393] 27% | Training loss: 0.6962452119046991
Epoch: 91 | Iteration number: [120/393] 30% | Training loss: 0.6957267170151075
Epoch: 91 | Iteration number: [130/393] 33% | Training loss: 0.6953517936743223
Epoch: 91 | Iteration number: [140/393] 35% | Training loss: 0.6948213658162525
Epoch: 91 | Iteration number: [150/393] 38% | Training loss: 0.694535737435023
Epoch: 91 | Iteration number: [160/393] 40% | Training loss: 0.6942749921232462
Epoch: 91 | Iteration number: [170/393] 43% | Training loss: 0.6940097282914555
Epoch: 91 | Iteration number: [180/393] 45% | Training loss: 0.693831236826049
Epoch: 91 | Iteration number: [190/393] 48% | Training loss: 0.6936208223041735
Epoch: 91 | Iteration number: [200/393] 50% | Training loss: 0.6934990429878235
Epoch: 91 | Iteration number: [210/393] 53% | Training loss: 0.6933424821921758
Epoch: 91 | Iteration number: [220/393] 55% | Training loss: 0.6931686525995081
Epoch: 91 | Iteration number: [230/393] 58% | Training loss: 0.6930768129618271
Epoch: 91 | Iteration number: [240/393] 61% | Training loss: 0.6929599146048228
Epoch: 91 | Iteration number: [250/393] 63% | Training loss: 0.6928512854576111
Epoch: 91 | Iteration number: [260/393] 66% | Training loss: 0.6927067678708296
Epoch: 91 | Iteration number: [270/393] 68% | Training loss: 0.6925988733768463
Epoch: 91 | Iteration number: [280/393] 71% | Training loss: 0.6925150081515312
Epoch: 91 | Iteration number: [290/393] 73% | Training loss: 0.6924138761799911
Epoch: 91 | Iteration number: [300/393] 76% | Training loss: 0.6923488700389862
Epoch: 91 | Iteration number: [310/393] 78% | Training loss: 0.6922742710959526
Epoch: 91 | Iteration number: [320/393] 81% | Training loss: 0.6922190031036735
Epoch: 91 | Iteration number: [330/393] 83% | Training loss: 0.6921376573316979
Epoch: 91 | Iteration number: [340/393] 86% | Training loss: 0.6920664266628378
Epoch: 91 | Iteration number: [350/393] 89% | Training loss: 0.692002865586962
Epoch: 91 | Iteration number: [360/393] 91% | Training loss: 0.6919698973496755
Epoch: 91 | Iteration number: [370/393] 94% | Training loss: 0.691938510778788
Epoch: 91 | Iteration number: [380/393] 96% | Training loss: 0.6918638241918463
Epoch: 91 | Iteration number: [390/393] 99% | Training loss: 0.691829370535337

 End of epoch: 91 | Train Loss: 0.6900625759712006 | Training Time: 67 

 End of epoch: 91 | Eval Loss: 0.6900988500945422 | Evaluating Time: 17 
Epoch: 92 | Iteration number: [10/393] 2% | Training loss: 0.7596475660800934
Epoch: 92 | Iteration number: [20/393] 5% | Training loss: 0.7248395085334778
Epoch: 92 | Iteration number: [30/393] 7% | Training loss: 0.7130394419034322
Epoch: 92 | Iteration number: [40/393] 10% | Training loss: 0.7073719024658203
Epoch: 92 | Iteration number: [50/393] 12% | Training loss: 0.7037755763530731
Epoch: 92 | Iteration number: [60/393] 15% | Training loss: 0.7015018790960312
Epoch: 92 | Iteration number: [70/393] 17% | Training loss: 0.6998777091503143
Epoch: 92 | Iteration number: [80/393] 20% | Training loss: 0.698651222139597
Epoch: 92 | Iteration number: [90/393] 22% | Training loss: 0.6976916531721751
Epoch: 92 | Iteration number: [100/393] 25% | Training loss: 0.6968783915042878
Epoch: 92 | Iteration number: [110/393] 27% | Training loss: 0.6961403359066356
Epoch: 92 | Iteration number: [120/393] 30% | Training loss: 0.6955624535679817
Epoch: 92 | Iteration number: [130/393] 33% | Training loss: 0.695162289417707
Epoch: 92 | Iteration number: [140/393] 35% | Training loss: 0.6947411779846464
Epoch: 92 | Iteration number: [150/393] 38% | Training loss: 0.6943617951869965
Epoch: 92 | Iteration number: [160/393] 40% | Training loss: 0.694038875028491
Epoch: 92 | Iteration number: [170/393] 43% | Training loss: 0.6938319416607127
Epoch: 92 | Iteration number: [180/393] 45% | Training loss: 0.6936330166127946
Epoch: 92 | Iteration number: [190/393] 48% | Training loss: 0.693469625711441
Epoch: 92 | Iteration number: [200/393] 50% | Training loss: 0.6933506172895432
Epoch: 92 | Iteration number: [210/393] 53% | Training loss: 0.6932273194903419
Epoch: 92 | Iteration number: [220/393] 55% | Training loss: 0.6930901478637349
Epoch: 92 | Iteration number: [230/393] 58% | Training loss: 0.6929561721241992
Epoch: 92 | Iteration number: [240/393] 61% | Training loss: 0.6928541163603464
Epoch: 92 | Iteration number: [250/393] 63% | Training loss: 0.6927403004169465
Epoch: 92 | Iteration number: [260/393] 66% | Training loss: 0.6926256344868587
Epoch: 92 | Iteration number: [270/393] 68% | Training loss: 0.692539796785072
Epoch: 92 | Iteration number: [280/393] 71% | Training loss: 0.6924547712717738
Epoch: 92 | Iteration number: [290/393] 73% | Training loss: 0.6923856400210282
Epoch: 92 | Iteration number: [300/393] 76% | Training loss: 0.6922987165053686
Epoch: 92 | Iteration number: [310/393] 78% | Training loss: 0.692235400215272
Epoch: 92 | Iteration number: [320/393] 81% | Training loss: 0.6921747209504246
Epoch: 92 | Iteration number: [330/393] 83% | Training loss: 0.6921188522468914
Epoch: 92 | Iteration number: [340/393] 86% | Training loss: 0.6920564304379856
Epoch: 92 | Iteration number: [350/393] 89% | Training loss: 0.6919956358841487
Epoch: 92 | Iteration number: [360/393] 91% | Training loss: 0.6919439444939296
Epoch: 92 | Iteration number: [370/393] 94% | Training loss: 0.6919144685203965
Epoch: 92 | Iteration number: [380/393] 96% | Training loss: 0.6918802469968796
Epoch: 92 | Iteration number: [390/393] 99% | Training loss: 0.6918438584376604

 End of epoch: 92 | Train Loss: 0.6900669647233784 | Training Time: 66 

 End of epoch: 92 | Eval Loss: 0.6900465865524448 | Evaluating Time: 16 
Epoch: 93 | Iteration number: [10/393] 2% | Training loss: 0.7598890244960785
Epoch: 93 | Iteration number: [20/393] 5% | Training loss: 0.724831160902977
Epoch: 93 | Iteration number: [30/393] 7% | Training loss: 0.7129106899102529
Epoch: 93 | Iteration number: [40/393] 10% | Training loss: 0.7071172162890434
Epoch: 93 | Iteration number: [50/393] 12% | Training loss: 0.7035887360572814
Epoch: 93 | Iteration number: [60/393] 15% | Training loss: 0.701580751935641
Epoch: 93 | Iteration number: [70/393] 17% | Training loss: 0.7000185583318983
Epoch: 93 | Iteration number: [80/393] 20% | Training loss: 0.6988247878849506
Epoch: 93 | Iteration number: [90/393] 22% | Training loss: 0.6980095717642042
Epoch: 93 | Iteration number: [100/393] 25% | Training loss: 0.6973159581422805
Epoch: 93 | Iteration number: [110/393] 27% | Training loss: 0.6965715998953039
Epoch: 93 | Iteration number: [120/393] 30% | Training loss: 0.6960114692648252
Epoch: 93 | Iteration number: [130/393] 33% | Training loss: 0.6955717114301828
Epoch: 93 | Iteration number: [140/393] 35% | Training loss: 0.6952391249792916
Epoch: 93 | Iteration number: [150/393] 38% | Training loss: 0.694904721180598
Epoch: 93 | Iteration number: [160/393] 40% | Training loss: 0.6946504507213831
Epoch: 93 | Iteration number: [170/393] 43% | Training loss: 0.6944375027628505
Epoch: 93 | Iteration number: [180/393] 45% | Training loss: 0.6941342506143782
Epoch: 93 | Iteration number: [190/393] 48% | Training loss: 0.6939260714932491
Epoch: 93 | Iteration number: [200/393] 50% | Training loss: 0.6936931496858597
Epoch: 93 | Iteration number: [210/393] 53% | Training loss: 0.6935241792883192
Epoch: 93 | Iteration number: [220/393] 55% | Training loss: 0.6933805441314523
Epoch: 93 | Iteration number: [230/393] 58% | Training loss: 0.6932598907014598
Epoch: 93 | Iteration number: [240/393] 61% | Training loss: 0.6931263891359171
Epoch: 93 | Iteration number: [250/393] 63% | Training loss: 0.6930359098911285
Epoch: 93 | Iteration number: [260/393] 66% | Training loss: 0.6928791811833015
Epoch: 93 | Iteration number: [270/393] 68% | Training loss: 0.6927613589498732
Epoch: 93 | Iteration number: [280/393] 71% | Training loss: 0.692595334989684
Epoch: 93 | Iteration number: [290/393] 73% | Training loss: 0.6925006138867346
Epoch: 93 | Iteration number: [300/393] 76% | Training loss: 0.6923993760347367
Epoch: 93 | Iteration number: [310/393] 78% | Training loss: 0.6923256104992283
Epoch: 93 | Iteration number: [320/393] 81% | Training loss: 0.6922472847625614
Epoch: 93 | Iteration number: [330/393] 83% | Training loss: 0.6921512706713243
Epoch: 93 | Iteration number: [340/393] 86% | Training loss: 0.6920577624264885
Epoch: 93 | Iteration number: [350/393] 89% | Training loss: 0.6920115603719439
Epoch: 93 | Iteration number: [360/393] 91% | Training loss: 0.6919744660456976
Epoch: 93 | Iteration number: [370/393] 94% | Training loss: 0.6919213083950249
Epoch: 93 | Iteration number: [380/393] 96% | Training loss: 0.6918545515913712
Epoch: 93 | Iteration number: [390/393] 99% | Training loss: 0.6918272640460577

 End of epoch: 93 | Train Loss: 0.6900732759907652 | Training Time: 66 

 End of epoch: 93 | Eval Loss: 0.6901137305765735 | Evaluating Time: 16 
Epoch: 94 | Iteration number: [10/393] 2% | Training loss: 0.7575567901134491
Epoch: 94 | Iteration number: [20/393] 5% | Training loss: 0.7245737671852112
Epoch: 94 | Iteration number: [30/393] 7% | Training loss: 0.7128413915634155
Epoch: 94 | Iteration number: [40/393] 10% | Training loss: 0.7069629848003387
Epoch: 94 | Iteration number: [50/393] 12% | Training loss: 0.7036642968654633
Epoch: 94 | Iteration number: [60/393] 15% | Training loss: 0.7013272285461426
Epoch: 94 | Iteration number: [70/393] 17% | Training loss: 0.6996633325304303
Epoch: 94 | Iteration number: [80/393] 20% | Training loss: 0.6984443731606007
Epoch: 94 | Iteration number: [90/393] 22% | Training loss: 0.69748438861635
Epoch: 94 | Iteration number: [100/393] 25% | Training loss: 0.6968211984634399
Epoch: 94 | Iteration number: [110/393] 27% | Training loss: 0.6961733482100747
Epoch: 94 | Iteration number: [120/393] 30% | Training loss: 0.6956301560004552
Epoch: 94 | Iteration number: [130/393] 33% | Training loss: 0.6952819287776947
Epoch: 94 | Iteration number: [140/393] 35% | Training loss: 0.6949307445968901
Epoch: 94 | Iteration number: [150/393] 38% | Training loss: 0.6946098518371582
Epoch: 94 | Iteration number: [160/393] 40% | Training loss: 0.694416131079197
Epoch: 94 | Iteration number: [170/393] 43% | Training loss: 0.6941473971394931
Epoch: 94 | Iteration number: [180/393] 45% | Training loss: 0.6939214981264539
Epoch: 94 | Iteration number: [190/393] 48% | Training loss: 0.6937705858757621
Epoch: 94 | Iteration number: [200/393] 50% | Training loss: 0.6935821363329887
Epoch: 94 | Iteration number: [210/393] 53% | Training loss: 0.69349005818367
Epoch: 94 | Iteration number: [220/393] 55% | Training loss: 0.6933497754010287
Epoch: 94 | Iteration number: [230/393] 58% | Training loss: 0.6931874692440033
Epoch: 94 | Iteration number: [240/393] 61% | Training loss: 0.6931078950564067
Epoch: 94 | Iteration number: [250/393] 63% | Training loss: 0.6929672603607178
Epoch: 94 | Iteration number: [260/393] 66% | Training loss: 0.6928563159245711
Epoch: 94 | Iteration number: [270/393] 68% | Training loss: 0.6926863076510252
Epoch: 94 | Iteration number: [280/393] 71% | Training loss: 0.6925986656120845
Epoch: 94 | Iteration number: [290/393] 73% | Training loss: 0.6925185978412628
Epoch: 94 | Iteration number: [300/393] 76% | Training loss: 0.6924159802993138
Epoch: 94 | Iteration number: [310/393] 78% | Training loss: 0.6923253830402128
Epoch: 94 | Iteration number: [320/393] 81% | Training loss: 0.692230217717588
Epoch: 94 | Iteration number: [330/393] 83% | Training loss: 0.6921290872675
Epoch: 94 | Iteration number: [340/393] 86% | Training loss: 0.6920847429948694
Epoch: 94 | Iteration number: [350/393] 89% | Training loss: 0.6920298378808157
Epoch: 94 | Iteration number: [360/393] 91% | Training loss: 0.6919609415862296
Epoch: 94 | Iteration number: [370/393] 94% | Training loss: 0.6919242159740345
Epoch: 94 | Iteration number: [380/393] 96% | Training loss: 0.6918813950137088
Epoch: 94 | Iteration number: [390/393] 99% | Training loss: 0.6918381389899132

 End of epoch: 94 | Train Loss: 0.6900694035088439 | Training Time: 65 

 End of epoch: 94 | Eval Loss: 0.690121224948338 | Evaluating Time: 16 
Epoch: 95 | Iteration number: [10/393] 2% | Training loss: 0.7606521666049957
Epoch: 95 | Iteration number: [20/393] 5% | Training loss: 0.7254808634519577
Epoch: 95 | Iteration number: [30/393] 7% | Training loss: 0.7138320485750834
Epoch: 95 | Iteration number: [40/393] 10% | Training loss: 0.7078013315796852
Epoch: 95 | Iteration number: [50/393] 12% | Training loss: 0.7043707942962647
Epoch: 95 | Iteration number: [60/393] 15% | Training loss: 0.7021303455034892
Epoch: 95 | Iteration number: [70/393] 17% | Training loss: 0.7004763398851667
Epoch: 95 | Iteration number: [80/393] 20% | Training loss: 0.6990271300077439
Epoch: 95 | Iteration number: [90/393] 22% | Training loss: 0.6979959017700619
Epoch: 95 | Iteration number: [100/393] 25% | Training loss: 0.6971679204702377
Epoch: 95 | Iteration number: [110/393] 27% | Training loss: 0.6965041193095121
Epoch: 95 | Iteration number: [120/393] 30% | Training loss: 0.6958573947350184
Epoch: 95 | Iteration number: [130/393] 33% | Training loss: 0.6954032760400038
Epoch: 95 | Iteration number: [140/393] 35% | Training loss: 0.6951418387038367
Epoch: 95 | Iteration number: [150/393] 38% | Training loss: 0.6947726500034332
Epoch: 95 | Iteration number: [160/393] 40% | Training loss: 0.6945103339850902
Epoch: 95 | Iteration number: [170/393] 43% | Training loss: 0.6942648842054255
Epoch: 95 | Iteration number: [180/393] 45% | Training loss: 0.6940302014350891
Epoch: 95 | Iteration number: [190/393] 48% | Training loss: 0.6938219515900863
Epoch: 95 | Iteration number: [200/393] 50% | Training loss: 0.6935436618328095
Epoch: 95 | Iteration number: [210/393] 53% | Training loss: 0.6933877891018277
Epoch: 95 | Iteration number: [220/393] 55% | Training loss: 0.6932608715512536
Epoch: 95 | Iteration number: [230/393] 58% | Training loss: 0.6931201921856922
Epoch: 95 | Iteration number: [240/393] 61% | Training loss: 0.6930039967099826
Epoch: 95 | Iteration number: [250/393] 63% | Training loss: 0.6928951168060302
Epoch: 95 | Iteration number: [260/393] 66% | Training loss: 0.6927477073210936
Epoch: 95 | Iteration number: [270/393] 68% | Training loss: 0.6926551534069909
Epoch: 95 | Iteration number: [280/393] 71% | Training loss: 0.6925583215696471
Epoch: 95 | Iteration number: [290/393] 73% | Training loss: 0.6924578452932424
Epoch: 95 | Iteration number: [300/393] 76% | Training loss: 0.6923987835645675
Epoch: 95 | Iteration number: [310/393] 78% | Training loss: 0.6923228215786719
Epoch: 95 | Iteration number: [320/393] 81% | Training loss: 0.6922567088156939
Epoch: 95 | Iteration number: [330/393] 83% | Training loss: 0.6922102236386501
Epoch: 95 | Iteration number: [340/393] 86% | Training loss: 0.6921515559448915
Epoch: 95 | Iteration number: [350/393] 89% | Training loss: 0.6920777245930263
Epoch: 95 | Iteration number: [360/393] 91% | Training loss: 0.692019081612428
Epoch: 95 | Iteration number: [370/393] 94% | Training loss: 0.691954251560005
Epoch: 95 | Iteration number: [380/393] 96% | Training loss: 0.6918735869620976
Epoch: 95 | Iteration number: [390/393] 99% | Training loss: 0.6918340744116367

 End of epoch: 95 | Train Loss: 0.6900515855117002 | Training Time: 68 

 End of epoch: 95 | Eval Loss: 0.6900777901921954 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/393] 2% | Training loss: 0.7589219748973847
Epoch: 96 | Iteration number: [20/393] 5% | Training loss: 0.724214231967926
Epoch: 96 | Iteration number: [30/393] 7% | Training loss: 0.7131470143795013
Epoch: 96 | Iteration number: [40/393] 10% | Training loss: 0.7074836760759353
Epoch: 96 | Iteration number: [50/393] 12% | Training loss: 0.7042017161846161
Epoch: 96 | Iteration number: [60/393] 15% | Training loss: 0.7019883245229721
Epoch: 96 | Iteration number: [70/393] 17% | Training loss: 0.7000661305018834
Epoch: 96 | Iteration number: [80/393] 20% | Training loss: 0.6987808920443058
Epoch: 96 | Iteration number: [90/393] 22% | Training loss: 0.6977291537655724
Epoch: 96 | Iteration number: [100/393] 25% | Training loss: 0.696901131272316
Epoch: 96 | Iteration number: [110/393] 27% | Training loss: 0.6962490775368431
Epoch: 96 | Iteration number: [120/393] 30% | Training loss: 0.6957426488399505
Epoch: 96 | Iteration number: [130/393] 33% | Training loss: 0.6953852415084839
Epoch: 96 | Iteration number: [140/393] 35% | Training loss: 0.6949678991522108
Epoch: 96 | Iteration number: [150/393] 38% | Training loss: 0.6946029047171275
Epoch: 96 | Iteration number: [160/393] 40% | Training loss: 0.6941990628838539
Epoch: 96 | Iteration number: [170/393] 43% | Training loss: 0.6939544509438907
Epoch: 96 | Iteration number: [180/393] 45% | Training loss: 0.6937254074547026
Epoch: 96 | Iteration number: [190/393] 48% | Training loss: 0.6934969296580866
Epoch: 96 | Iteration number: [200/393] 50% | Training loss: 0.6932519865036011
Epoch: 96 | Iteration number: [210/393] 53% | Training loss: 0.6931116226173583
Epoch: 96 | Iteration number: [220/393] 55% | Training loss: 0.6929205428470265
Epoch: 96 | Iteration number: [230/393] 58% | Training loss: 0.692774505459744
Epoch: 96 | Iteration number: [240/393] 61% | Training loss: 0.6926790113250415
Epoch: 96 | Iteration number: [250/393] 63% | Training loss: 0.6925712003707886
Epoch: 96 | Iteration number: [260/393] 66% | Training loss: 0.6925048559904099
Epoch: 96 | Iteration number: [270/393] 68% | Training loss: 0.6924390044477251
Epoch: 96 | Iteration number: [280/393] 71% | Training loss: 0.6923483695302691
Epoch: 96 | Iteration number: [290/393] 73% | Training loss: 0.6922884429323262
Epoch: 96 | Iteration number: [300/393] 76% | Training loss: 0.6922192857662837
Epoch: 96 | Iteration number: [310/393] 78% | Training loss: 0.6921499942579578
Epoch: 96 | Iteration number: [320/393] 81% | Training loss: 0.6921220667660236
Epoch: 96 | Iteration number: [330/393] 83% | Training loss: 0.6920580222751155
Epoch: 96 | Iteration number: [340/393] 86% | Training loss: 0.6919967448010164
Epoch: 96 | Iteration number: [350/393] 89% | Training loss: 0.6919732940196991
Epoch: 96 | Iteration number: [360/393] 91% | Training loss: 0.6919521854983436
Epoch: 96 | Iteration number: [370/393] 94% | Training loss: 0.6918935998066051
Epoch: 96 | Iteration number: [380/393] 96% | Training loss: 0.6918676205371556
Epoch: 96 | Iteration number: [390/393] 99% | Training loss: 0.6918182318027203

 End of epoch: 96 | Train Loss: 0.6900379067765544 | Training Time: 68 

 End of epoch: 96 | Eval Loss: 0.6900343761152151 | Evaluating Time: 16 
Epoch: 97 | Iteration number: [10/393] 2% | Training loss: 0.7595174252986908
Epoch: 97 | Iteration number: [20/393] 5% | Training loss: 0.7253549933433533
Epoch: 97 | Iteration number: [30/393] 7% | Training loss: 0.7138425350189209
Epoch: 97 | Iteration number: [40/393] 10% | Training loss: 0.7078524336218834
Epoch: 97 | Iteration number: [50/393] 12% | Training loss: 0.7043180763721466
Epoch: 97 | Iteration number: [60/393] 15% | Training loss: 0.7018770426511765
Epoch: 97 | Iteration number: [70/393] 17% | Training loss: 0.7002075459275927
Epoch: 97 | Iteration number: [80/393] 20% | Training loss: 0.6990247502923012
Epoch: 97 | Iteration number: [90/393] 22% | Training loss: 0.6980604840649499
Epoch: 97 | Iteration number: [100/393] 25% | Training loss: 0.6972955983877182
Epoch: 97 | Iteration number: [110/393] 27% | Training loss: 0.6967450271953236
Epoch: 97 | Iteration number: [120/393] 30% | Training loss: 0.6961959222952525
Epoch: 97 | Iteration number: [130/393] 33% | Training loss: 0.695620615207232
Epoch: 97 | Iteration number: [140/393] 35% | Training loss: 0.6953190003122602
Epoch: 97 | Iteration number: [150/393] 38% | Training loss: 0.6949845369656881
Epoch: 97 | Iteration number: [160/393] 40% | Training loss: 0.6947258166968823
Epoch: 97 | Iteration number: [170/393] 43% | Training loss: 0.6944621128194473
Epoch: 97 | Iteration number: [180/393] 45% | Training loss: 0.6941961927546395
Epoch: 97 | Iteration number: [190/393] 48% | Training loss: 0.6939241977114426
Epoch: 97 | Iteration number: [200/393] 50% | Training loss: 0.6937191838026047
Epoch: 97 | Iteration number: [210/393] 53% | Training loss: 0.6935176171007611
Epoch: 97 | Iteration number: [220/393] 55% | Training loss: 0.6932907245375893
Epoch: 97 | Iteration number: [230/393] 58% | Training loss: 0.6931040268877279
Epoch: 97 | Iteration number: [240/393] 61% | Training loss: 0.6929829527934392
Epoch: 97 | Iteration number: [250/393] 63% | Training loss: 0.6928648586273194
Epoch: 97 | Iteration number: [260/393] 66% | Training loss: 0.6927727380624185
Epoch: 97 | Iteration number: [270/393] 68% | Training loss: 0.6926719676565241
Epoch: 97 | Iteration number: [280/393] 71% | Training loss: 0.6925815675939833
Epoch: 97 | Iteration number: [290/393] 73% | Training loss: 0.6925066649913788
Epoch: 97 | Iteration number: [300/393] 76% | Training loss: 0.692423361937205
Epoch: 97 | Iteration number: [310/393] 78% | Training loss: 0.6923191785812378
Epoch: 97 | Iteration number: [320/393] 81% | Training loss: 0.6922314146533608
Epoch: 97 | Iteration number: [330/393] 83% | Training loss: 0.6921696312499769
Epoch: 97 | Iteration number: [340/393] 86% | Training loss: 0.6921138346195221
Epoch: 97 | Iteration number: [350/393] 89% | Training loss: 0.6920461813041142
Epoch: 97 | Iteration number: [360/393] 91% | Training loss: 0.6919601096047295
Epoch: 97 | Iteration number: [370/393] 94% | Training loss: 0.6919305938321191
Epoch: 97 | Iteration number: [380/393] 96% | Training loss: 0.6918917681041516
Epoch: 97 | Iteration number: [390/393] 99% | Training loss: 0.6918282510378422

 End of epoch: 97 | Train Loss: 0.6900405392391991 | Training Time: 66 

 End of epoch: 97 | Eval Loss: 0.6900573883737836 | Evaluating Time: 16 
Epoch: 98 | Iteration number: [10/393] 2% | Training loss: 0.7589584529399872
Epoch: 98 | Iteration number: [20/393] 5% | Training loss: 0.7245464861392975
Epoch: 98 | Iteration number: [30/393] 7% | Training loss: 0.7131389319896698
Epoch: 98 | Iteration number: [40/393] 10% | Training loss: 0.707354436814785
Epoch: 98 | Iteration number: [50/393] 12% | Training loss: 0.7038894379138947
Epoch: 98 | Iteration number: [60/393] 15% | Training loss: 0.7013513465722402
Epoch: 98 | Iteration number: [70/393] 17% | Training loss: 0.699813141141619
Epoch: 98 | Iteration number: [80/393] 20% | Training loss: 0.6986762307584286
Epoch: 98 | Iteration number: [90/393] 22% | Training loss: 0.6976777977413602
Epoch: 98 | Iteration number: [100/393] 25% | Training loss: 0.6967799317836761
Epoch: 98 | Iteration number: [110/393] 27% | Training loss: 0.6961700596592643
Epoch: 98 | Iteration number: [120/393] 30% | Training loss: 0.6955868914723397
Epoch: 98 | Iteration number: [130/393] 33% | Training loss: 0.6951857759402349
Epoch: 98 | Iteration number: [140/393] 35% | Training loss: 0.6948164096900395
Epoch: 98 | Iteration number: [150/393] 38% | Training loss: 0.6946219543615977
Epoch: 98 | Iteration number: [160/393] 40% | Training loss: 0.694368377700448
Epoch: 98 | Iteration number: [170/393] 43% | Training loss: 0.6941287633250741
Epoch: 98 | Iteration number: [180/393] 45% | Training loss: 0.6938817779223124
Epoch: 98 | Iteration number: [190/393] 48% | Training loss: 0.6936626089246649
Epoch: 98 | Iteration number: [200/393] 50% | Training loss: 0.6934949624538421
Epoch: 98 | Iteration number: [210/393] 53% | Training loss: 0.6933510028180622
Epoch: 98 | Iteration number: [220/393] 55% | Training loss: 0.69314957911318
Epoch: 98 | Iteration number: [230/393] 58% | Training loss: 0.6930098347041918
Epoch: 98 | Iteration number: [240/393] 61% | Training loss: 0.6928960134585699
Epoch: 98 | Iteration number: [250/393] 63% | Training loss: 0.6927305963039398
Epoch: 98 | Iteration number: [260/393] 66% | Training loss: 0.6926410340345823
Epoch: 98 | Iteration number: [270/393] 68% | Training loss: 0.6925344067591208
Epoch: 98 | Iteration number: [280/393] 71% | Training loss: 0.6924489860023771
Epoch: 98 | Iteration number: [290/393] 73% | Training loss: 0.6923794993038835
Epoch: 98 | Iteration number: [300/393] 76% | Training loss: 0.6922784539063772
Epoch: 98 | Iteration number: [310/393] 78% | Training loss: 0.6922520587521215
Epoch: 98 | Iteration number: [320/393] 81% | Training loss: 0.692163817025721
Epoch: 98 | Iteration number: [330/393] 83% | Training loss: 0.692120836539702
Epoch: 98 | Iteration number: [340/393] 86% | Training loss: 0.6920415254200206
Epoch: 98 | Iteration number: [350/393] 89% | Training loss: 0.6919599412168775
Epoch: 98 | Iteration number: [360/393] 91% | Training loss: 0.6918880906369951
Epoch: 98 | Iteration number: [370/393] 94% | Training loss: 0.6918389404142226
Epoch: 98 | Iteration number: [380/393] 96% | Training loss: 0.6918099080261432
Epoch: 98 | Iteration number: [390/393] 99% | Training loss: 0.6917941437317775

 End of epoch: 98 | Train Loss: 0.6900283263536506 | Training Time: 67 

 End of epoch: 98 | Eval Loss: 0.6900763049417612 | Evaluating Time: 17 
Epoch: 99 | Iteration number: [10/393] 2% | Training loss: 0.7593268692493439
Epoch: 99 | Iteration number: [20/393] 5% | Training loss: 0.7245388031005859
Epoch: 99 | Iteration number: [30/393] 7% | Training loss: 0.7133087575435638
Epoch: 99 | Iteration number: [40/393] 10% | Training loss: 0.7075640708208084
Epoch: 99 | Iteration number: [50/393] 12% | Training loss: 0.7041250097751618
Epoch: 99 | Iteration number: [60/393] 15% | Training loss: 0.7017503658930461
Epoch: 99 | Iteration number: [70/393] 17% | Training loss: 0.7001557954720088
Epoch: 99 | Iteration number: [80/393] 20% | Training loss: 0.6989873960614205
Epoch: 99 | Iteration number: [90/393] 22% | Training loss: 0.6979811178313361
Epoch: 99 | Iteration number: [100/393] 25% | Training loss: 0.6972232580184936
Epoch: 99 | Iteration number: [110/393] 27% | Training loss: 0.6965727253393693
Epoch: 99 | Iteration number: [120/393] 30% | Training loss: 0.6960468048850695
Epoch: 99 | Iteration number: [130/393] 33% | Training loss: 0.6956331422695747
Epoch: 99 | Iteration number: [140/393] 35% | Training loss: 0.6952236848218101
Epoch: 99 | Iteration number: [150/393] 38% | Training loss: 0.6949135657151541
Epoch: 99 | Iteration number: [160/393] 40% | Training loss: 0.6945961244404316
Epoch: 99 | Iteration number: [170/393] 43% | Training loss: 0.6943069265169256
Epoch: 99 | Iteration number: [180/393] 45% | Training loss: 0.6940928839974934
Epoch: 99 | Iteration number: [190/393] 48% | Training loss: 0.6938950729997535
Epoch: 99 | Iteration number: [200/393] 50% | Training loss: 0.6936395844817161
Epoch: 99 | Iteration number: [210/393] 53% | Training loss: 0.6934818344456809
Epoch: 99 | Iteration number: [220/393] 55% | Training loss: 0.6933156517418948
Epoch: 99 | Iteration number: [230/393] 58% | Training loss: 0.6931492206843003
Epoch: 99 | Iteration number: [240/393] 61% | Training loss: 0.6929998549322287
Epoch: 99 | Iteration number: [250/393] 63% | Training loss: 0.6928301253318787
Epoch: 99 | Iteration number: [260/393] 66% | Training loss: 0.6926839803273861
Epoch: 99 | Iteration number: [270/393] 68% | Training loss: 0.6925794122395692
Epoch: 99 | Iteration number: [280/393] 71% | Training loss: 0.6924903807895524
Epoch: 99 | Iteration number: [290/393] 73% | Training loss: 0.6924220796289116
Epoch: 99 | Iteration number: [300/393] 76% | Training loss: 0.6923585691054662
Epoch: 99 | Iteration number: [310/393] 78% | Training loss: 0.6922798497061575
Epoch: 99 | Iteration number: [320/393] 81% | Training loss: 0.6921886257827282
Epoch: 99 | Iteration number: [330/393] 83% | Training loss: 0.6921009488178022
Epoch: 99 | Iteration number: [340/393] 86% | Training loss: 0.6920481820316876
Epoch: 99 | Iteration number: [350/393] 89% | Training loss: 0.6919981622695923
Epoch: 99 | Iteration number: [360/393] 91% | Training loss: 0.6919286666644944
Epoch: 99 | Iteration number: [370/393] 94% | Training loss: 0.6919221744344041
Epoch: 99 | Iteration number: [380/393] 96% | Training loss: 0.6918855979254371
Epoch: 99 | Iteration number: [390/393] 99% | Training loss: 0.6918080195402487

 End of epoch: 99 | Train Loss: 0.690042366659975 | Training Time: 67 

 End of epoch: 99 | Eval Loss: 0.6900269085047196 | Evaluating Time: 17 
Epoch: 100 | Iteration number: [10/393] 2% | Training loss: 0.7577411532402039
Epoch: 100 | Iteration number: [20/393] 5% | Training loss: 0.7240259647369385
Epoch: 100 | Iteration number: [30/393] 7% | Training loss: 0.7130306979020437
Epoch: 100 | Iteration number: [40/393] 10% | Training loss: 0.7071406379342079
Epoch: 100 | Iteration number: [50/393] 12% | Training loss: 0.7036424279212952
Epoch: 100 | Iteration number: [60/393] 15% | Training loss: 0.7014910767475764
Epoch: 100 | Iteration number: [70/393] 17% | Training loss: 0.6999401705605643
Epoch: 100 | Iteration number: [80/393] 20% | Training loss: 0.6987012535333633
Epoch: 100 | Iteration number: [90/393] 22% | Training loss: 0.697734014193217
Epoch: 100 | Iteration number: [100/393] 25% | Training loss: 0.6970109987258911
Epoch: 100 | Iteration number: [110/393] 27% | Training loss: 0.69647447087548
Epoch: 100 | Iteration number: [120/393] 30% | Training loss: 0.695921395222346
Epoch: 100 | Iteration number: [130/393] 33% | Training loss: 0.6953843047985664
Epoch: 100 | Iteration number: [140/393] 35% | Training loss: 0.6950495472976139
Epoch: 100 | Iteration number: [150/393] 38% | Training loss: 0.6946740698814392
Epoch: 100 | Iteration number: [160/393] 40% | Training loss: 0.6943502984941006
Epoch: 100 | Iteration number: [170/393] 43% | Training loss: 0.6941477975424598
Epoch: 100 | Iteration number: [180/393] 45% | Training loss: 0.6938877830902735
Epoch: 100 | Iteration number: [190/393] 48% | Training loss: 0.6936899486340975
Epoch: 100 | Iteration number: [200/393] 50% | Training loss: 0.6934646487236023
Epoch: 100 | Iteration number: [210/393] 53% | Training loss: 0.6932901998360952
Epoch: 100 | Iteration number: [220/393] 55% | Training loss: 0.6931818555701863
Epoch: 100 | Iteration number: [230/393] 58% | Training loss: 0.6930571245110553
Epoch: 100 | Iteration number: [240/393] 61% | Training loss: 0.6929238446056842
Epoch: 100 | Iteration number: [250/393] 63% | Training loss: 0.692794093132019
Epoch: 100 | Iteration number: [260/393] 66% | Training loss: 0.6927160519819994
Epoch: 100 | Iteration number: [270/393] 68% | Training loss: 0.6926733317198577
Epoch: 100 | Iteration number: [280/393] 71% | Training loss: 0.6926108888217382
Epoch: 100 | Iteration number: [290/393] 73% | Training loss: 0.6925312153224288
Epoch: 100 | Iteration number: [300/393] 76% | Training loss: 0.6924392336606979
Epoch: 100 | Iteration number: [310/393] 78% | Training loss: 0.6923412834444354
Epoch: 100 | Iteration number: [320/393] 81% | Training loss: 0.6922264736145735
Epoch: 100 | Iteration number: [330/393] 83% | Training loss: 0.6921660083712954
Epoch: 100 | Iteration number: [340/393] 86% | Training loss: 0.6921136664993622
Epoch: 100 | Iteration number: [350/393] 89% | Training loss: 0.6920457465308053
Epoch: 100 | Iteration number: [360/393] 91% | Training loss: 0.6919668661223517
Epoch: 100 | Iteration number: [370/393] 94% | Training loss: 0.6919330004099253
Epoch: 100 | Iteration number: [380/393] 96% | Training loss: 0.6918794635095095
Epoch: 100 | Iteration number: [390/393] 99% | Training loss: 0.6917831789224576

 End of epoch: 100 | Train Loss: 0.6899977390092747 | Training Time: 67 

 End of epoch: 100 | Eval Loss: 0.6900691548172309 | Evaluating Time: 17 

 End of Test | Dice Loss: 0.8651095836516469 | Binary Cross Entropy With Logits Loss: 0.6903498804569245 
