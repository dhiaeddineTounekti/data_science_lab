Epoch: 1 | Iteration number: [10/4518] 0% | Training loss: 0.7608631491661072
Epoch: 1 | Iteration number: [20/4518] 0% | Training loss: 0.7263637542724609
Epoch: 1 | Iteration number: [30/4518] 0% | Training loss: 0.7144944210847218
Epoch: 1 | Iteration number: [40/4518] 0% | Training loss: 0.7088654711842537
Epoch: 1 | Iteration number: [50/4518] 1% | Training loss: 0.7055194103717803
Epoch: 1 | Iteration number: [60/4518] 1% | Training loss: 0.7032797396183014
Epoch: 1 | Iteration number: [70/4518] 1% | Training loss: 0.7016578452927725
Epoch: 1 | Iteration number: [80/4518] 1% | Training loss: 0.7003637745976448
Epoch: 1 | Iteration number: [90/4518] 1% | Training loss: 0.6992996282047695
Epoch: 1 | Iteration number: [100/4518] 2% | Training loss: 0.6984467631578446
Epoch: 1 | Iteration number: [110/4518] 2% | Training loss: 0.6977835557677529
Epoch: 1 | Iteration number: [120/4518] 2% | Training loss: 0.697207668920358
Epoch: 1 | Iteration number: [130/4518] 2% | Training loss: 0.696700073664005
Epoch: 1 | Iteration number: [140/4518] 3% | Training loss: 0.6963278242519924
Epoch: 1 | Iteration number: [150/4518] 3% | Training loss: 0.6959339034557342
Epoch: 1 | Iteration number: [160/4518] 3% | Training loss: 0.6955879312008619
Epoch: 1 | Iteration number: [170/4518] 3% | Training loss: 0.6953198969364166
Epoch: 1 | Iteration number: [180/4518] 3% | Training loss: 0.695074044002427
Epoch: 1 | Iteration number: [190/4518] 4% | Training loss: 0.6948322826310208
Epoch: 1 | Iteration number: [200/4518] 4% | Training loss: 0.6946241143345833
Epoch: 1 | Iteration number: [210/4518] 4% | Training loss: 0.6944407667432513
Epoch: 1 | Iteration number: [220/4518] 4% | Training loss: 0.694285589185628
Epoch: 1 | Iteration number: [230/4518] 5% | Training loss: 0.6941533347834712
Epoch: 1 | Iteration number: [240/4518] 5% | Training loss: 0.694039470454057
Epoch: 1 | Iteration number: [250/4518] 5% | Training loss: 0.6939011154174805
Epoch: 1 | Iteration number: [260/4518] 5% | Training loss: 0.6937518200049033
Epoch: 1 | Iteration number: [270/4518] 5% | Training loss: 0.6936652898788452
Epoch: 1 | Iteration number: [280/4518] 6% | Training loss: 0.6935210941093308
Epoch: 1 | Iteration number: [290/4518] 6% | Training loss: 0.6933928610949681
Epoch: 1 | Iteration number: [300/4518] 6% | Training loss: 0.6932896610101064
Epoch: 1 | Iteration number: [310/4518] 6% | Training loss: 0.6932283991767514
Epoch: 1 | Iteration number: [320/4518] 7% | Training loss: 0.6931258831173182
Epoch: 1 | Iteration number: [330/4518] 7% | Training loss: 0.6930815442041918
Epoch: 1 | Iteration number: [340/4518] 7% | Training loss: 0.6930013626813889
Epoch: 1 | Iteration number: [350/4518] 7% | Training loss: 0.692936840397971
Epoch: 1 | Iteration number: [360/4518] 7% | Training loss: 0.6928695773084959
Epoch: 1 | Iteration number: [370/4518] 8% | Training loss: 0.69280901567356
Epoch: 1 | Iteration number: [380/4518] 8% | Training loss: 0.6927462301756206
Epoch: 1 | Iteration number: [390/4518] 8% | Training loss: 0.6926889421083988
Epoch: 1 | Iteration number: [400/4518] 8% | Training loss: 0.6926312355697155
Epoch: 1 | Iteration number: [410/4518] 9% | Training loss: 0.6925755920933514
Epoch: 1 | Iteration number: [420/4518] 9% | Training loss: 0.6925350052969796
Epoch: 1 | Iteration number: [430/4518] 9% | Training loss: 0.6924902897934581
Epoch: 1 | Iteration number: [440/4518] 9% | Training loss: 0.6924380322748964
Epoch: 1 | Iteration number: [450/4518] 9% | Training loss: 0.6923897771040598
Epoch: 1 | Iteration number: [460/4518] 10% | Training loss: 0.6923372534306153
Epoch: 1 | Iteration number: [470/4518] 10% | Training loss: 0.6923025189562046
Epoch: 1 | Iteration number: [480/4518] 10% | Training loss: 0.6922689174612363
Epoch: 1 | Iteration number: [490/4518] 10% | Training loss: 0.6922323745124194
Epoch: 1 | Iteration number: [500/4518] 11% | Training loss: 0.6921711815595627
Epoch: 1 | Iteration number: [510/4518] 11% | Training loss: 0.6921377062797547
Epoch: 1 | Iteration number: [520/4518] 11% | Training loss: 0.6921053874951143
Epoch: 1 | Iteration number: [530/4518] 11% | Training loss: 0.6920853519214774
Epoch: 1 | Iteration number: [540/4518] 11% | Training loss: 0.6920573788660543
Epoch: 1 | Iteration number: [550/4518] 12% | Training loss: 0.6920163479718295
Epoch: 1 | Iteration number: [560/4518] 12% | Training loss: 0.691984313087804
Epoch: 1 | Iteration number: [570/4518] 12% | Training loss: 0.6919548775020399
Epoch: 1 | Iteration number: [580/4518] 12% | Training loss: 0.691903577282511
Epoch: 1 | Iteration number: [590/4518] 13% | Training loss: 0.6918672318175688
Epoch: 1 | Iteration number: [600/4518] 13% | Training loss: 0.6918321296572685
Epoch: 1 | Iteration number: [610/4518] 13% | Training loss: 0.691794323628066
Epoch: 1 | Iteration number: [620/4518] 13% | Training loss: 0.6917588145502152
Epoch: 1 | Iteration number: [630/4518] 13% | Training loss: 0.6917165475232261
Epoch: 1 | Iteration number: [640/4518] 14% | Training loss: 0.6916943853721023
Epoch: 1 | Iteration number: [650/4518] 14% | Training loss: 0.6916639731480525
Epoch: 1 | Iteration number: [660/4518] 14% | Training loss: 0.6916230348926602
Epoch: 1 | Iteration number: [670/4518] 14% | Training loss: 0.691609162714944
Epoch: 1 | Iteration number: [680/4518] 15% | Training loss: 0.6915870122173253
Epoch: 1 | Iteration number: [690/4518] 15% | Training loss: 0.6915687251782072
Epoch: 1 | Iteration number: [700/4518] 15% | Training loss: 0.6915360064165933
Epoch: 1 | Iteration number: [710/4518] 15% | Training loss: 0.6915259141317556
Epoch: 1 | Iteration number: [720/4518] 15% | Training loss: 0.6915065512061119
Epoch: 1 | Iteration number: [730/4518] 16% | Training loss: 0.6914739248687274
Epoch: 1 | Iteration number: [740/4518] 16% | Training loss: 0.6914584076082384
Epoch: 1 | Iteration number: [750/4518] 16% | Training loss: 0.6914339543978373
Epoch: 1 | Iteration number: [760/4518] 16% | Training loss: 0.6914182951575831
Epoch: 1 | Iteration number: [770/4518] 17% | Training loss: 0.6914059960222864
Epoch: 1 | Iteration number: [780/4518] 17% | Training loss: 0.6913841745028129
Epoch: 1 | Iteration number: [790/4518] 17% | Training loss: 0.6913728806036937
Epoch: 1 | Iteration number: [800/4518] 17% | Training loss: 0.6913595738261938
Epoch: 1 | Iteration number: [810/4518] 17% | Training loss: 0.6913417869879875
Epoch: 1 | Iteration number: [820/4518] 18% | Training loss: 0.6913380067522933
Epoch: 1 | Iteration number: [830/4518] 18% | Training loss: 0.6913219360702009
Epoch: 1 | Iteration number: [840/4518] 18% | Training loss: 0.6913109767295066
Epoch: 1 | Iteration number: [850/4518] 18% | Training loss: 0.6912884022207821
Epoch: 1 | Iteration number: [860/4518] 19% | Training loss: 0.691269493449566
Epoch: 1 | Iteration number: [870/4518] 19% | Training loss: 0.691248563719892
Epoch: 1 | Iteration number: [880/4518] 19% | Training loss: 0.6912178588184443
Epoch: 1 | Iteration number: [890/4518] 19% | Training loss: 0.6912036827441012
Epoch: 1 | Iteration number: [900/4518] 19% | Training loss: 0.6911891216701932
Epoch: 1 | Iteration number: [910/4518] 20% | Training loss: 0.6911784763519581
Epoch: 1 | Iteration number: [920/4518] 20% | Training loss: 0.691166353225708
Epoch: 1 | Iteration number: [930/4518] 20% | Training loss: 0.6911633588293548
Epoch: 1 | Iteration number: [940/4518] 20% | Training loss: 0.6911495355849571
Epoch: 1 | Iteration number: [950/4518] 21% | Training loss: 0.6911394050874208
Epoch: 1 | Iteration number: [960/4518] 21% | Training loss: 0.6911272577941417
Epoch: 1 | Iteration number: [970/4518] 21% | Training loss: 0.6911147311176221
Epoch: 1 | Iteration number: [980/4518] 21% | Training loss: 0.6911044252162077
Epoch: 1 | Iteration number: [990/4518] 21% | Training loss: 0.6910918866745149
Epoch: 1 | Iteration number: [1000/4518] 22% | Training loss: 0.6910838374495506
Epoch: 1 | Iteration number: [1010/4518] 22% | Training loss: 0.6910722377866801
Epoch: 1 | Iteration number: [1020/4518] 22% | Training loss: 0.6910554762564454
Epoch: 1 | Iteration number: [1030/4518] 22% | Training loss: 0.6910521110863361
Epoch: 1 | Iteration number: [1040/4518] 23% | Training loss: 0.6910360497923997
Epoch: 1 | Iteration number: [1050/4518] 23% | Training loss: 0.6910231858208066
Epoch: 1 | Iteration number: [1060/4518] 23% | Training loss: 0.691013286529847
Epoch: 1 | Iteration number: [1070/4518] 23% | Training loss: 0.6909925481426381
Epoch: 1 | Iteration number: [1080/4518] 23% | Training loss: 0.6909859043580514
Epoch: 1 | Iteration number: [1090/4518] 24% | Training loss: 0.6909770397418136
Epoch: 1 | Iteration number: [1100/4518] 24% | Training loss: 0.6909647213328969
Epoch: 1 | Iteration number: [1110/4518] 24% | Training loss: 0.6909490965508126
Epoch: 1 | Iteration number: [1120/4518] 24% | Training loss: 0.6909412518143654
Epoch: 1 | Iteration number: [1130/4518] 25% | Training loss: 0.6909395584490446
Epoch: 1 | Iteration number: [1140/4518] 25% | Training loss: 0.6909336487452189
Epoch: 1 | Iteration number: [1150/4518] 25% | Training loss: 0.6909279518023781
Epoch: 1 | Iteration number: [1160/4518] 25% | Training loss: 0.6909198866835956
Epoch: 1 | Iteration number: [1170/4518] 25% | Training loss: 0.6909123882778689
Epoch: 1 | Iteration number: [1180/4518] 26% | Training loss: 0.6908966791831841
Epoch: 1 | Iteration number: [1190/4518] 26% | Training loss: 0.6908923505234117
Epoch: 1 | Iteration number: [1200/4518] 26% | Training loss: 0.6908771230280399
Epoch: 1 | Iteration number: [1210/4518] 26% | Training loss: 0.6908634774448458
Epoch: 1 | Iteration number: [1220/4518] 27% | Training loss: 0.690857599797796
Epoch: 1 | Iteration number: [1230/4518] 27% | Training loss: 0.690839903965229
Epoch: 1 | Iteration number: [1240/4518] 27% | Training loss: 0.6908298017517213
Epoch: 1 | Iteration number: [1250/4518] 27% | Training loss: 0.6908116265773773
Epoch: 1 | Iteration number: [1260/4518] 27% | Training loss: 0.6908061824620716
Epoch: 1 | Iteration number: [1270/4518] 28% | Training loss: 0.6907945680336689
Epoch: 1 | Iteration number: [1280/4518] 28% | Training loss: 0.6907878707163035
Epoch: 1 | Iteration number: [1290/4518] 28% | Training loss: 0.6907816002535265
Epoch: 1 | Iteration number: [1300/4518] 28% | Training loss: 0.6907720646949915
Epoch: 1 | Iteration number: [1310/4518] 28% | Training loss: 0.6907650923000948
Epoch: 1 | Iteration number: [1320/4518] 29% | Training loss: 0.6907593328844417
Epoch: 1 | Iteration number: [1330/4518] 29% | Training loss: 0.690754551009128
Epoch: 1 | Iteration number: [1340/4518] 29% | Training loss: 0.690736923199981
Epoch: 1 | Iteration number: [1350/4518] 29% | Training loss: 0.6907330734199948
Epoch: 1 | Iteration number: [1360/4518] 30% | Training loss: 0.6907268146381659
Epoch: 1 | Iteration number: [1370/4518] 30% | Training loss: 0.6907197684267141
Epoch: 1 | Iteration number: [1380/4518] 30% | Training loss: 0.6907157215951145
Epoch: 1 | Iteration number: [1390/4518] 30% | Training loss: 0.6907016100643351
Epoch: 1 | Iteration number: [1400/4518] 30% | Training loss: 0.690692851458277
Epoch: 1 | Iteration number: [1410/4518] 31% | Training loss: 0.690686581405342
Epoch: 1 | Iteration number: [1420/4518] 31% | Training loss: 0.6906774164925159
Epoch: 1 | Iteration number: [1430/4518] 31% | Training loss: 0.6906704599623914
Epoch: 1 | Iteration number: [1440/4518] 31% | Training loss: 0.6906570345991188
Epoch: 1 | Iteration number: [1450/4518] 32% | Training loss: 0.6906481709562499
Epoch: 1 | Iteration number: [1460/4518] 32% | Training loss: 0.690639331446935
Epoch: 1 | Iteration number: [1470/4518] 32% | Training loss: 0.6906331817309062
Epoch: 1 | Iteration number: [1480/4518] 32% | Training loss: 0.6906232989317662
Epoch: 1 | Iteration number: [1490/4518] 32% | Training loss: 0.6906227645858022
Epoch: 1 | Iteration number: [1500/4518] 33% | Training loss: 0.6906139628887177
Epoch: 1 | Iteration number: [1510/4518] 33% | Training loss: 0.6906028149143749
Epoch: 1 | Iteration number: [1520/4518] 33% | Training loss: 0.6905969513090033
Epoch: 1 | Iteration number: [1530/4518] 33% | Training loss: 0.6905914756597257
Epoch: 1 | Iteration number: [1540/4518] 34% | Training loss: 0.6905819695104253
Epoch: 1 | Iteration number: [1550/4518] 34% | Training loss: 0.69057058638142
Epoch: 1 | Iteration number: [1560/4518] 34% | Training loss: 0.6905623519267792
Epoch: 1 | Iteration number: [1570/4518] 34% | Training loss: 0.6905588688744102
Epoch: 1 | Iteration number: [1580/4518] 34% | Training loss: 0.6905511806660061
Epoch: 1 | Iteration number: [1590/4518] 35% | Training loss: 0.6905461945998593
Epoch: 1 | Iteration number: [1600/4518] 35% | Training loss: 0.6905318532511592
Epoch: 1 | Iteration number: [1610/4518] 35% | Training loss: 0.6905171492084954
Epoch: 1 | Iteration number: [1620/4518] 35% | Training loss: 0.6905081532251688
Epoch: 1 | Iteration number: [1630/4518] 36% | Training loss: 0.6905040628339615
Epoch: 1 | Iteration number: [1640/4518] 36% | Training loss: 0.690497133063107
Epoch: 1 | Iteration number: [1650/4518] 36% | Training loss: 0.6904801055518064
Epoch: 1 | Iteration number: [1660/4518] 36% | Training loss: 0.6904769608414317
Epoch: 1 | Iteration number: [1670/4518] 36% | Training loss: 0.690469644562213
Epoch: 1 | Iteration number: [1680/4518] 37% | Training loss: 0.6904676595968859
Epoch: 1 | Iteration number: [1690/4518] 37% | Training loss: 0.6904624071699628
Epoch: 1 | Iteration number: [1700/4518] 37% | Training loss: 0.6904599467445822
Epoch: 1 | Iteration number: [1710/4518] 37% | Training loss: 0.6904550059497008
Epoch: 1 | Iteration number: [1720/4518] 38% | Training loss: 0.6904462034272593
Epoch: 1 | Iteration number: [1730/4518] 38% | Training loss: 0.6904358020407616
Epoch: 1 | Iteration number: [1740/4518] 38% | Training loss: 0.6904278423251777
Epoch: 1 | Iteration number: [1750/4518] 38% | Training loss: 0.690418076821736
Epoch: 1 | Iteration number: [1760/4518] 38% | Training loss: 0.6904120351780545
Epoch: 1 | Iteration number: [1770/4518] 39% | Training loss: 0.6904105760620138
Epoch: 1 | Iteration number: [1780/4518] 39% | Training loss: 0.6904052333885364
Epoch: 1 | Iteration number: [1790/4518] 39% | Training loss: 0.6903962329113283
Epoch: 1 | Iteration number: [1800/4518] 39% | Training loss: 0.6903943288988538
Epoch: 1 | Iteration number: [1810/4518] 40% | Training loss: 0.6903877449628398
Epoch: 1 | Iteration number: [1820/4518] 40% | Training loss: 0.6903797845919054
Epoch: 1 | Iteration number: [1830/4518] 40% | Training loss: 0.690372484531559
Epoch: 1 | Iteration number: [1840/4518] 40% | Training loss: 0.690360692758923
Epoch: 1 | Iteration number: [1850/4518] 40% | Training loss: 0.6903571678174508
Epoch: 1 | Iteration number: [1860/4518] 41% | Training loss: 0.6903496487486747
Epoch: 1 | Iteration number: [1870/4518] 41% | Training loss: 0.6903347700993645
Epoch: 1 | Iteration number: [1880/4518] 41% | Training loss: 0.69032902032771
Epoch: 1 | Iteration number: [1890/4518] 41% | Training loss: 0.6903209065634107
Epoch: 1 | Iteration number: [1900/4518] 42% | Training loss: 0.690318393801388
Epoch: 1 | Iteration number: [1910/4518] 42% | Training loss: 0.6903161948888089
Epoch: 1 | Iteration number: [1920/4518] 42% | Training loss: 0.690308844887962
Epoch: 1 | Iteration number: [1930/4518] 42% | Training loss: 0.69030585857253
Epoch: 1 | Iteration number: [1940/4518] 42% | Training loss: 0.6902904675793402
Epoch: 1 | Iteration number: [1950/4518] 43% | Training loss: 0.69029040822616
Epoch: 1 | Iteration number: [1960/4518] 43% | Training loss: 0.6902858620699571
Epoch: 1 | Iteration number: [1970/4518] 43% | Training loss: 0.690278770778385
Epoch: 1 | Iteration number: [1980/4518] 43% | Training loss: 0.6902707757371844
Epoch: 1 | Iteration number: [1990/4518] 44% | Training loss: 0.6902647016635493
Epoch: 1 | Iteration number: [2000/4518] 44% | Training loss: 0.6902546517848969
Epoch: 1 | Iteration number: [2010/4518] 44% | Training loss: 0.6902453768016094
Epoch: 1 | Iteration number: [2020/4518] 44% | Training loss: 0.690237311797567
Epoch: 1 | Iteration number: [2030/4518] 44% | Training loss: 0.6902288254552287
Epoch: 1 | Iteration number: [2040/4518] 45% | Training loss: 0.6902237032850583
Epoch: 1 | Iteration number: [2050/4518] 45% | Training loss: 0.6902139088584156
Epoch: 1 | Iteration number: [2060/4518] 45% | Training loss: 0.6902094562944857
Epoch: 1 | Iteration number: [2070/4518] 45% | Training loss: 0.690199495571247
Epoch: 1 | Iteration number: [2080/4518] 46% | Training loss: 0.6901928673283412
Epoch: 1 | Iteration number: [2090/4518] 46% | Training loss: 0.6901838019704134
Epoch: 1 | Iteration number: [2100/4518] 46% | Training loss: 0.6901807158050083
Epoch: 1 | Iteration number: [2110/4518] 46% | Training loss: 0.6901778778758659
Epoch: 1 | Iteration number: [2120/4518] 46% | Training loss: 0.69017680135538
Epoch: 1 | Iteration number: [2130/4518] 47% | Training loss: 0.6901736248546922
Epoch: 1 | Iteration number: [2140/4518] 47% | Training loss: 0.6901665387866653
Epoch: 1 | Iteration number: [2150/4518] 47% | Training loss: 0.6901634831206743
Epoch: 1 | Iteration number: [2160/4518] 47% | Training loss: 0.6901587934129768
Epoch: 1 | Iteration number: [2170/4518] 48% | Training loss: 0.6901461418872604
Epoch: 1 | Iteration number: [2180/4518] 48% | Training loss: 0.6901382498238064
Epoch: 1 | Iteration number: [2190/4518] 48% | Training loss: 0.690137685406698
Epoch: 1 | Iteration number: [2200/4518] 48% | Training loss: 0.6901300719922239
Epoch: 1 | Iteration number: [2210/4518] 48% | Training loss: 0.6901259865156666
Epoch: 1 | Iteration number: [2220/4518] 49% | Training loss: 0.6901207567066759
Epoch: 1 | Iteration number: [2230/4518] 49% | Training loss: 0.690115757801073
Epoch: 1 | Iteration number: [2240/4518] 49% | Training loss: 0.6901104066787022
Epoch: 1 | Iteration number: [2250/4518] 49% | Training loss: 0.6901042208141751
Epoch: 1 | Iteration number: [2260/4518] 50% | Training loss: 0.6901013655472645
Epoch: 1 | Iteration number: [2270/4518] 50% | Training loss: 0.6900959828614138
Epoch: 1 | Iteration number: [2280/4518] 50% | Training loss: 0.6900977723169746
Epoch: 1 | Iteration number: [2290/4518] 50% | Training loss: 0.6900863821329508
Epoch: 1 | Iteration number: [2300/4518] 50% | Training loss: 0.6900824802854787
Epoch: 1 | Iteration number: [2310/4518] 51% | Training loss: 0.6900786176388398
Epoch: 1 | Iteration number: [2320/4518] 51% | Training loss: 0.6900739800313423
Epoch: 1 | Iteration number: [2330/4518] 51% | Training loss: 0.6900723382894574
Epoch: 1 | Iteration number: [2340/4518] 51% | Training loss: 0.6900704333415398
Epoch: 1 | Iteration number: [2350/4518] 52% | Training loss: 0.6900628199983151
Epoch: 1 | Iteration number: [2360/4518] 52% | Training loss: 0.6900588416952198
Epoch: 1 | Iteration number: [2370/4518] 52% | Training loss: 0.6900526355590498
Epoch: 1 | Iteration number: [2380/4518] 52% | Training loss: 0.6900499983995902
Epoch: 1 | Iteration number: [2390/4518] 52% | Training loss: 0.6900448431030975
Epoch: 1 | Iteration number: [2400/4518] 53% | Training loss: 0.6900413198272387
Epoch: 1 | Iteration number: [2410/4518] 53% | Training loss: 0.6900365272003586
Epoch: 1 | Iteration number: [2420/4518] 53% | Training loss: 0.6900363019428962
Epoch: 1 | Iteration number: [2430/4518] 53% | Training loss: 0.6900289714091109
Epoch: 1 | Iteration number: [2440/4518] 54% | Training loss: 0.6900210433074685
Epoch: 1 | Iteration number: [2450/4518] 54% | Training loss: 0.690018148300599
Epoch: 1 | Iteration number: [2460/4518] 54% | Training loss: 0.6900140304633272
Epoch: 1 | Iteration number: [2470/4518] 54% | Training loss: 0.6900127338976996
Epoch: 1 | Iteration number: [2480/4518] 54% | Training loss: 0.6900057731616882
Epoch: 1 | Iteration number: [2490/4518] 55% | Training loss: 0.6899998705071139
Epoch: 1 | Iteration number: [2500/4518] 55% | Training loss: 0.6899943726778031
Epoch: 1 | Iteration number: [2510/4518] 55% | Training loss: 0.6899901829392786
Epoch: 1 | Iteration number: [2520/4518] 55% | Training loss: 0.6899857411308894
Epoch: 1 | Iteration number: [2530/4518] 55% | Training loss: 0.6899806415846226
Epoch: 1 | Iteration number: [2540/4518] 56% | Training loss: 0.6899745769388094
Epoch: 1 | Iteration number: [2550/4518] 56% | Training loss: 0.689972448793112
Epoch: 1 | Iteration number: [2560/4518] 56% | Training loss: 0.6899699044181034
Epoch: 1 | Iteration number: [2570/4518] 56% | Training loss: 0.6899661243425733
Epoch: 1 | Iteration number: [2580/4518] 57% | Training loss: 0.6899606756230657
Epoch: 1 | Iteration number: [2590/4518] 57% | Training loss: 0.6899575813166423
Epoch: 1 | Iteration number: [2600/4518] 57% | Training loss: 0.6899508227981054
Epoch: 1 | Iteration number: [2610/4518] 57% | Training loss: 0.6899513533288948
Epoch: 1 | Iteration number: [2620/4518] 57% | Training loss: 0.6899420312342753
Epoch: 1 | Iteration number: [2630/4518] 58% | Training loss: 0.689933387136278
Epoch: 1 | Iteration number: [2640/4518] 58% | Training loss: 0.6899285792627118
Epoch: 1 | Iteration number: [2650/4518] 58% | Training loss: 0.6899257583888072
Epoch: 1 | Iteration number: [2660/4518] 58% | Training loss: 0.6899235953737919
Epoch: 1 | Iteration number: [2670/4518] 59% | Training loss: 0.6899182982659072
Epoch: 1 | Iteration number: [2680/4518] 59% | Training loss: 0.689912469818521
Epoch: 1 | Iteration number: [2690/4518] 59% | Training loss: 0.6899111300596074
Epoch: 1 | Iteration number: [2700/4518] 59% | Training loss: 0.6899062882750122
Epoch: 1 | Iteration number: [2710/4518] 59% | Training loss: 0.6899036039725441
Epoch: 1 | Iteration number: [2720/4518] 60% | Training loss: 0.6899008842294707
Epoch: 1 | Iteration number: [2730/4518] 60% | Training loss: 0.6898976700209872
Epoch: 1 | Iteration number: [2740/4518] 60% | Training loss: 0.6898927667497718
Epoch: 1 | Iteration number: [2750/4518] 60% | Training loss: 0.6898869717121124
Epoch: 1 | Iteration number: [2760/4518] 61% | Training loss: 0.6898844600371693
Epoch: 1 | Iteration number: [2770/4518] 61% | Training loss: 0.6898808457360801
Epoch: 1 | Iteration number: [2780/4518] 61% | Training loss: 0.689877972306965
Epoch: 1 | Iteration number: [2790/4518] 61% | Training loss: 0.6898734096985136
Epoch: 1 | Iteration number: [2800/4518] 61% | Training loss: 0.6898687558940478
Epoch: 1 | Iteration number: [2810/4518] 62% | Training loss: 0.6898616229087857
Epoch: 1 | Iteration number: [2820/4518] 62% | Training loss: 0.6898547374187631
Epoch: 1 | Iteration number: [2830/4518] 62% | Training loss: 0.6898530691546181
Epoch: 1 | Iteration number: [2840/4518] 62% | Training loss: 0.6898533398836432
Epoch: 1 | Iteration number: [2850/4518] 63% | Training loss: 0.689851132129368
Epoch: 1 | Iteration number: [2860/4518] 63% | Training loss: 0.6898490579395028
Epoch: 1 | Iteration number: [2870/4518] 63% | Training loss: 0.6898473626645184
Epoch: 1 | Iteration number: [2880/4518] 63% | Training loss: 0.6898412991108166
Epoch: 1 | Iteration number: [2890/4518] 63% | Training loss: 0.6898346387597516
Epoch: 1 | Iteration number: [2900/4518] 64% | Training loss: 0.6898320027466478
Epoch: 1 | Iteration number: [2910/4518] 64% | Training loss: 0.689825998712651
Epoch: 1 | Iteration number: [2920/4518] 64% | Training loss: 0.68981929990935
Epoch: 1 | Iteration number: [2930/4518] 64% | Training loss: 0.6898158485978944
Epoch: 1 | Iteration number: [2940/4518] 65% | Training loss: 0.6898094449927207
Epoch: 1 | Iteration number: [2950/4518] 65% | Training loss: 0.6898090555102138
Epoch: 1 | Iteration number: [2960/4518] 65% | Training loss: 0.68980693454678
Epoch: 1 | Iteration number: [2970/4518] 65% | Training loss: 0.6898048218452569
Epoch: 1 | Iteration number: [2980/4518] 65% | Training loss: 0.6897950144222119
Epoch: 1 | Iteration number: [2990/4518] 66% | Training loss: 0.6897975609254677
Epoch: 1 | Iteration number: [3000/4518] 66% | Training loss: 0.6897934352755547
Epoch: 1 | Iteration number: [3010/4518] 66% | Training loss: 0.6897900469081346
Epoch: 1 | Iteration number: [3020/4518] 66% | Training loss: 0.6897876418781597
Epoch: 1 | Iteration number: [3030/4518] 67% | Training loss: 0.6897819168693555
Epoch: 1 | Iteration number: [3040/4518] 67% | Training loss: 0.6897783098644332
Epoch: 1 | Iteration number: [3050/4518] 67% | Training loss: 0.6897715838815345
Epoch: 1 | Iteration number: [3060/4518] 67% | Training loss: 0.6897666125126134
Epoch: 1 | Iteration number: [3070/4518] 67% | Training loss: 0.6897626071294667
Epoch: 1 | Iteration number: [3080/4518] 68% | Training loss: 0.6897605512823377
Epoch: 1 | Iteration number: [3090/4518] 68% | Training loss: 0.6897544289869784
Epoch: 1 | Iteration number: [3100/4518] 68% | Training loss: 0.689747675003544
Epoch: 1 | Iteration number: [3110/4518] 68% | Training loss: 0.6897480725858756
Epoch: 1 | Iteration number: [3120/4518] 69% | Training loss: 0.6897485887392973
Epoch: 1 | Iteration number: [3130/4518] 69% | Training loss: 0.689744488747356
Epoch: 1 | Iteration number: [3140/4518] 69% | Training loss: 0.6897421113434871
Epoch: 1 | Iteration number: [3150/4518] 69% | Training loss: 0.6897412184117332
Epoch: 1 | Iteration number: [3160/4518] 69% | Training loss: 0.6897378169283083
Epoch: 1 | Iteration number: [3170/4518] 70% | Training loss: 0.6897321928562802
Epoch: 1 | Iteration number: [3180/4518] 70% | Training loss: 0.6897270092799229
Epoch: 1 | Iteration number: [3190/4518] 70% | Training loss: 0.6897226605482609
Epoch: 1 | Iteration number: [3200/4518] 70% | Training loss: 0.689720724336803
Epoch: 1 | Iteration number: [3210/4518] 71% | Training loss: 0.6897127287967183
Epoch: 1 | Iteration number: [3220/4518] 71% | Training loss: 0.6897086384873953
Epoch: 1 | Iteration number: [3230/4518] 71% | Training loss: 0.6896998271299959
Epoch: 1 | Iteration number: [3240/4518] 71% | Training loss: 0.6896975150814763
Epoch: 1 | Iteration number: [3250/4518] 71% | Training loss: 0.6896939960076258
Epoch: 1 | Iteration number: [3260/4518] 72% | Training loss: 0.6896892809611888
Epoch: 1 | Iteration number: [3270/4518] 72% | Training loss: 0.6896842169652292
Epoch: 1 | Iteration number: [3280/4518] 72% | Training loss: 0.6896808220664176
Epoch: 1 | Iteration number: [3290/4518] 72% | Training loss: 0.6896751103792509
Epoch: 1 | Iteration number: [3300/4518] 73% | Training loss: 0.6896727061994148
Epoch: 1 | Iteration number: [3310/4518] 73% | Training loss: 0.6896688949305485
Epoch: 1 | Iteration number: [3320/4518] 73% | Training loss: 0.6896685849650797
Epoch: 1 | Iteration number: [3330/4518] 73% | Training loss: 0.6896659039878272
Epoch: 1 | Iteration number: [3340/4518] 73% | Training loss: 0.6896640448513145
Epoch: 1 | Iteration number: [3350/4518] 74% | Training loss: 0.689660668088429
Epoch: 1 | Iteration number: [3360/4518] 74% | Training loss: 0.689655151856797
Epoch: 1 | Iteration number: [3370/4518] 74% | Training loss: 0.6896494438103469
Epoch: 1 | Iteration number: [3380/4518] 74% | Training loss: 0.6896471605674755
Epoch: 1 | Iteration number: [3390/4518] 75% | Training loss: 0.6896456801610007
Epoch: 1 | Iteration number: [3400/4518] 75% | Training loss: 0.6896413146748263
Epoch: 1 | Iteration number: [3410/4518] 75% | Training loss: 0.6896365208360107
Epoch: 1 | Iteration number: [3420/4518] 75% | Training loss: 0.6896328981159723
Epoch: 1 | Iteration number: [3430/4518] 75% | Training loss: 0.6896264267906156
Epoch: 1 | Iteration number: [3440/4518] 76% | Training loss: 0.6896238649827103
Epoch: 1 | Iteration number: [3450/4518] 76% | Training loss: 0.6896205686659053
Epoch: 1 | Iteration number: [3460/4518] 76% | Training loss: 0.6896186079248527
Epoch: 1 | Iteration number: [3470/4518] 76% | Training loss: 0.689612821800908
Epoch: 1 | Iteration number: [3480/4518] 77% | Training loss: 0.6896091656609513
Epoch: 1 | Iteration number: [3490/4518] 77% | Training loss: 0.6896062273009117
Epoch: 1 | Iteration number: [3500/4518] 77% | Training loss: 0.6896019251857485
Epoch: 1 | Iteration number: [3510/4518] 77% | Training loss: 0.6895975519109655
Epoch: 1 | Iteration number: [3520/4518] 77% | Training loss: 0.6895949233661999
Epoch: 1 | Iteration number: [3530/4518] 78% | Training loss: 0.6895923918097283
Epoch: 1 | Iteration number: [3540/4518] 78% | Training loss: 0.689587479139452
Epoch: 1 | Iteration number: [3550/4518] 78% | Training loss: 0.6895852282685293
Epoch: 1 | Iteration number: [3560/4518] 78% | Training loss: 0.6895831259616305
Epoch: 1 | Iteration number: [3570/4518] 79% | Training loss: 0.6895807220989248
Epoch: 1 | Iteration number: [3580/4518] 79% | Training loss: 0.6895774921724916
Epoch: 1 | Iteration number: [3590/4518] 79% | Training loss: 0.6895730243917959
Epoch: 1 | Iteration number: [3600/4518] 79% | Training loss: 0.6895701622466246
Epoch: 1 | Iteration number: [3610/4518] 79% | Training loss: 0.6895689137589568
Epoch: 1 | Iteration number: [3620/4518] 80% | Training loss: 0.6895609275741472
Epoch: 1 | Iteration number: [3630/4518] 80% | Training loss: 0.6895604019815271
Epoch: 1 | Iteration number: [3640/4518] 80% | Training loss: 0.6895613136691051
Epoch: 1 | Iteration number: [3650/4518] 80% | Training loss: 0.6895611739648532
Epoch: 1 | Iteration number: [3660/4518] 81% | Training loss: 0.689560443276916
Epoch: 1 | Iteration number: [3670/4518] 81% | Training loss: 0.689556638908646
Epoch: 1 | Iteration number: [3680/4518] 81% | Training loss: 0.6895562901607026
Epoch: 1 | Iteration number: [3690/4518] 81% | Training loss: 0.6895503845802814
Epoch: 1 | Iteration number: [3700/4518] 81% | Training loss: 0.6895458083539395
Epoch: 1 | Iteration number: [3710/4518] 82% | Training loss: 0.689541685388416
Epoch: 1 | Iteration number: [3720/4518] 82% | Training loss: 0.6895380115797443
Epoch: 1 | Iteration number: [3730/4518] 82% | Training loss: 0.6895351661434123
Epoch: 1 | Iteration number: [3740/4518] 82% | Training loss: 0.6895333089611747
Epoch: 1 | Iteration number: [3750/4518] 83% | Training loss: 0.6895307268301646
Epoch: 1 | Iteration number: [3760/4518] 83% | Training loss: 0.6895291547825996
Epoch: 1 | Iteration number: [3770/4518] 83% | Training loss: 0.6895277195489059
Epoch: 1 | Iteration number: [3780/4518] 83% | Training loss: 0.689524132202542
Epoch: 1 | Iteration number: [3790/4518] 83% | Training loss: 0.6895239537183716
Epoch: 1 | Iteration number: [3800/4518] 84% | Training loss: 0.6895210298268418
Epoch: 1 | Iteration number: [3810/4518] 84% | Training loss: 0.6895196167972144
Epoch: 1 | Iteration number: [3820/4518] 84% | Training loss: 0.6895186063038741
Epoch: 1 | Iteration number: [3830/4518] 84% | Training loss: 0.6895144376835686
Epoch: 1 | Iteration number: [3840/4518] 84% | Training loss: 0.6895103503329059
Epoch: 1 | Iteration number: [3850/4518] 85% | Training loss: 0.6895103035499524
Epoch: 1 | Iteration number: [3860/4518] 85% | Training loss: 0.6895099432511651
Epoch: 1 | Iteration number: [3870/4518] 85% | Training loss: 0.6895051780443167
Epoch: 1 | Iteration number: [3880/4518] 85% | Training loss: 0.6895034856710237
Epoch: 1 | Iteration number: [3890/4518] 86% | Training loss: 0.6894998851502769
Epoch: 1 | Iteration number: [3900/4518] 86% | Training loss: 0.6894990713932575
Epoch: 1 | Iteration number: [3910/4518] 86% | Training loss: 0.6894982872869048
Epoch: 1 | Iteration number: [3920/4518] 86% | Training loss: 0.6894942070300482
Epoch: 1 | Iteration number: [3930/4518] 86% | Training loss: 0.689492272739192
Epoch: 1 | Iteration number: [3940/4518] 87% | Training loss: 0.6894929535346588
Epoch: 1 | Iteration number: [3950/4518] 87% | Training loss: 0.6894905761223805
Epoch: 1 | Iteration number: [3960/4518] 87% | Training loss: 0.6894876816808575
Epoch: 1 | Iteration number: [3970/4518] 87% | Training loss: 0.6894846570131461
Epoch: 1 | Iteration number: [3980/4518] 88% | Training loss: 0.6894848947998268
Epoch: 1 | Iteration number: [3990/4518] 88% | Training loss: 0.6894803541196618
Epoch: 1 | Iteration number: [4000/4518] 88% | Training loss: 0.6894771776646376
Epoch: 1 | Iteration number: [4010/4518] 88% | Training loss: 0.6894753968626484
Epoch: 1 | Iteration number: [4020/4518] 88% | Training loss: 0.6894723803991109
Epoch: 1 | Iteration number: [4030/4518] 89% | Training loss: 0.68946875459503
Epoch: 1 | Iteration number: [4040/4518] 89% | Training loss: 0.6894645165541384
Epoch: 1 | Iteration number: [4050/4518] 89% | Training loss: 0.6894611513908998
Epoch: 1 | Iteration number: [4060/4518] 89% | Training loss: 0.6894582504562556
Epoch: 1 | Iteration number: [4070/4518] 90% | Training loss: 0.6894542250498507
Epoch: 1 | Iteration number: [4080/4518] 90% | Training loss: 0.6894518980792924
Epoch: 1 | Iteration number: [4090/4518] 90% | Training loss: 0.6894501028404842
Epoch: 1 | Iteration number: [4100/4518] 90% | Training loss: 0.6894469212177323
Epoch: 1 | Iteration number: [4110/4518] 90% | Training loss: 0.6894454402500115
Epoch: 1 | Iteration number: [4120/4518] 91% | Training loss: 0.6894431099006273
Epoch: 1 | Iteration number: [4130/4518] 91% | Training loss: 0.689443184850291
Epoch: 1 | Iteration number: [4140/4518] 91% | Training loss: 0.6894413009213941
Epoch: 1 | Iteration number: [4150/4518] 91% | Training loss: 0.6894396212445684
Epoch: 1 | Iteration number: [4160/4518] 92% | Training loss: 0.6894366326670234
Epoch: 1 | Iteration number: [4170/4518] 92% | Training loss: 0.6894359690822858
Epoch: 1 | Iteration number: [4180/4518] 92% | Training loss: 0.689433955818272
Epoch: 1 | Iteration number: [4190/4518] 92% | Training loss: 0.6894317742037034
Epoch: 1 | Iteration number: [4200/4518] 92% | Training loss: 0.6894330362478892
Epoch: 1 | Iteration number: [4210/4518] 93% | Training loss: 0.6894324733780569
Epoch: 1 | Iteration number: [4220/4518] 93% | Training loss: 0.68942926393301
Epoch: 1 | Iteration number: [4230/4518] 93% | Training loss: 0.6894273874889311
Epoch: 1 | Iteration number: [4240/4518] 93% | Training loss: 0.6894264402535727
Epoch: 1 | Iteration number: [4250/4518] 94% | Training loss: 0.6894225799756891
Epoch: 1 | Iteration number: [4260/4518] 94% | Training loss: 0.6894199145651759
Epoch: 1 | Iteration number: [4270/4518] 94% | Training loss: 0.689419050685695
Epoch: 1 | Iteration number: [4280/4518] 94% | Training loss: 0.6894185620490636
Epoch: 1 | Iteration number: [4290/4518] 94% | Training loss: 0.6894172753626372
Epoch: 1 | Iteration number: [4300/4518] 95% | Training loss: 0.6894137101117954
Epoch: 1 | Iteration number: [4310/4518] 95% | Training loss: 0.689410517815924
Epoch: 1 | Iteration number: [4320/4518] 95% | Training loss: 0.689409473772954
Epoch: 1 | Iteration number: [4330/4518] 95% | Training loss: 0.6894066127701114
Epoch: 1 | Iteration number: [4340/4518] 96% | Training loss: 0.6894064480533248
Epoch: 1 | Iteration number: [4350/4518] 96% | Training loss: 0.6894060843018279
Epoch: 1 | Iteration number: [4360/4518] 96% | Training loss: 0.6894073119950951
Epoch: 1 | Iteration number: [4370/4518] 96% | Training loss: 0.6894064406508439
Epoch: 1 | Iteration number: [4380/4518] 96% | Training loss: 0.6894036029571812
Epoch: 1 | Iteration number: [4390/4518] 97% | Training loss: 0.6894040369498703
Epoch: 1 | Iteration number: [4400/4518] 97% | Training loss: 0.6894041848860004
Epoch: 1 | Iteration number: [4410/4518] 97% | Training loss: 0.6894027670494823
Epoch: 1 | Iteration number: [4420/4518] 97% | Training loss: 0.6894016203837158
Epoch: 1 | Iteration number: [4430/4518] 98% | Training loss: 0.6893957585970919
Epoch: 1 | Iteration number: [4440/4518] 98% | Training loss: 0.689393308423124
Epoch: 1 | Iteration number: [4450/4518] 98% | Training loss: 0.6893900608614589
Epoch: 1 | Iteration number: [4460/4518] 98% | Training loss: 0.6893886376523116
Epoch: 1 | Iteration number: [4470/4518] 98% | Training loss: 0.6893877744674682
Epoch: 1 | Iteration number: [4480/4518] 99% | Training loss: 0.6893867965521557
Epoch: 1 | Iteration number: [4490/4518] 99% | Training loss: 0.6893843655464112
Epoch: 1 | Iteration number: [4500/4518] 99% | Training loss: 0.6893812275860045
Epoch: 1 | Iteration number: [4510/4518] 99% | Training loss: 0.6893800240398247

 End of epoch: 1 | Train Loss: 0.6892275184775517 | Training Time: 640 

 End of epoch: 1 | Eval Loss: 0.6903863804680961 | Evaluating Time: 17 
Epoch: 2 | Iteration number: [10/4518] 0% | Training loss: 0.7565602958202362
Epoch: 2 | Iteration number: [20/4518] 0% | Training loss: 0.7224488347768784
Epoch: 2 | Iteration number: [30/4518] 0% | Training loss: 0.711015389362971
Epoch: 2 | Iteration number: [40/4518] 0% | Training loss: 0.7053809121251107
Epoch: 2 | Iteration number: [50/4518] 1% | Training loss: 0.7020685124397278
Epoch: 2 | Iteration number: [60/4518] 1% | Training loss: 0.699876410762469
Epoch: 2 | Iteration number: [70/4518] 1% | Training loss: 0.698292498077665
Epoch: 2 | Iteration number: [80/4518] 1% | Training loss: 0.6971320182085037
Epoch: 2 | Iteration number: [90/4518] 1% | Training loss: 0.6961757633421156
Epoch: 2 | Iteration number: [100/4518] 2% | Training loss: 0.6953602200746536
Epoch: 2 | Iteration number: [110/4518] 2% | Training loss: 0.6946902247992429
Epoch: 2 | Iteration number: [120/4518] 2% | Training loss: 0.6941319475571315
Epoch: 2 | Iteration number: [130/4518] 2% | Training loss: 0.6936521869439345
Epoch: 2 | Iteration number: [140/4518] 3% | Training loss: 0.6933844144855227
Epoch: 2 | Iteration number: [150/4518] 3% | Training loss: 0.6930729631582896
Epoch: 2 | Iteration number: [160/4518] 3% | Training loss: 0.6928151674568653
Epoch: 2 | Iteration number: [170/4518] 3% | Training loss: 0.692582017884535
Epoch: 2 | Iteration number: [180/4518] 3% | Training loss: 0.692280673318439
Epoch: 2 | Iteration number: [190/4518] 4% | Training loss: 0.6920776338953721
Epoch: 2 | Iteration number: [200/4518] 4% | Training loss: 0.69188541918993
Epoch: 2 | Iteration number: [210/4518] 4% | Training loss: 0.6916989894140334
Epoch: 2 | Iteration number: [220/4518] 4% | Training loss: 0.6915441873398694
Epoch: 2 | Iteration number: [230/4518] 5% | Training loss: 0.6914418536683787
Epoch: 2 | Iteration number: [240/4518] 5% | Training loss: 0.6913579973081748
Epoch: 2 | Iteration number: [250/4518] 5% | Training loss: 0.691260547876358
Epoch: 2 | Iteration number: [260/4518] 5% | Training loss: 0.6911594851658894
Epoch: 2 | Iteration number: [270/4518] 5% | Training loss: 0.6910549417689994
Epoch: 2 | Iteration number: [280/4518] 6% | Training loss: 0.6909740746021271
Epoch: 2 | Iteration number: [290/4518] 6% | Training loss: 0.6908344503106743
Epoch: 2 | Iteration number: [300/4518] 6% | Training loss: 0.6907716224590937
Epoch: 2 | Iteration number: [310/4518] 6% | Training loss: 0.6906694381467757
Epoch: 2 | Iteration number: [320/4518] 7% | Training loss: 0.6906310649588704
Epoch: 2 | Iteration number: [330/4518] 7% | Training loss: 0.6905684877525676
Epoch: 2 | Iteration number: [340/4518] 7% | Training loss: 0.6904716754660887
Epoch: 2 | Iteration number: [350/4518] 7% | Training loss: 0.6903865238598414
Epoch: 2 | Iteration number: [360/4518] 7% | Training loss: 0.6903347737259335
Epoch: 2 | Iteration number: [370/4518] 8% | Training loss: 0.6902973787204639
Epoch: 2 | Iteration number: [380/4518] 8% | Training loss: 0.6902496759828768
Epoch: 2 | Iteration number: [390/4518] 8% | Training loss: 0.6901981888673244
Epoch: 2 | Iteration number: [400/4518] 8% | Training loss: 0.6901288352906704
Epoch: 2 | Iteration number: [410/4518] 9% | Training loss: 0.6900767522614176
Epoch: 2 | Iteration number: [420/4518] 9% | Training loss: 0.690058363477389
Epoch: 2 | Iteration number: [430/4518] 9% | Training loss: 0.6900288002435551
Epoch: 2 | Iteration number: [440/4518] 9% | Training loss: 0.6899792088703676
Epoch: 2 | Iteration number: [450/4518] 9% | Training loss: 0.6899168354935116
Epoch: 2 | Iteration number: [460/4518] 10% | Training loss: 0.6898843425771465
Epoch: 2 | Iteration number: [470/4518] 10% | Training loss: 0.689850748346207
Epoch: 2 | Iteration number: [480/4518] 10% | Training loss: 0.6898065930853288
Epoch: 2 | Iteration number: [490/4518] 10% | Training loss: 0.6897747607863679
Epoch: 2 | Iteration number: [500/4518] 11% | Training loss: 0.6897414959669114
Epoch: 2 | Iteration number: [510/4518] 11% | Training loss: 0.6897087066781287
Epoch: 2 | Iteration number: [520/4518] 11% | Training loss: 0.6896766937696017
Epoch: 2 | Iteration number: [530/4518] 11% | Training loss: 0.6896395194080641
Epoch: 2 | Iteration number: [540/4518] 11% | Training loss: 0.6896125689700797
Epoch: 2 | Iteration number: [550/4518] 12% | Training loss: 0.6895903202620419
Epoch: 2 | Iteration number: [560/4518] 12% | Training loss: 0.6895560263523034
Epoch: 2 | Iteration number: [570/4518] 12% | Training loss: 0.6895163469147264
Epoch: 2 | Iteration number: [580/4518] 12% | Training loss: 0.6894842320475085
Epoch: 2 | Iteration number: [590/4518] 13% | Training loss: 0.6894870136753988
Epoch: 2 | Iteration number: [600/4518] 13% | Training loss: 0.6894526813427607
Epoch: 2 | Iteration number: [610/4518] 13% | Training loss: 0.6894147863153551
Epoch: 2 | Iteration number: [620/4518] 13% | Training loss: 0.6893903636163281
Epoch: 2 | Iteration number: [630/4518] 13% | Training loss: 0.6893699786965809
Epoch: 2 | Iteration number: [640/4518] 14% | Training loss: 0.6893400697037577
Epoch: 2 | Iteration number: [650/4518] 14% | Training loss: 0.689319637647042
Epoch: 2 | Iteration number: [660/4518] 14% | Training loss: 0.6893129071502975
Epoch: 2 | Iteration number: [670/4518] 14% | Training loss: 0.6892939258867236
Epoch: 2 | Iteration number: [680/4518] 15% | Training loss: 0.6892608462887652
Epoch: 2 | Iteration number: [690/4518] 15% | Training loss: 0.6892325904058374
Epoch: 2 | Iteration number: [700/4518] 15% | Training loss: 0.6892248960052217
Epoch: 2 | Iteration number: [710/4518] 15% | Training loss: 0.689218395528659
Epoch: 2 | Iteration number: [720/4518] 15% | Training loss: 0.6892063268356853
Epoch: 2 | Iteration number: [730/4518] 16% | Training loss: 0.6891852972442156
Epoch: 2 | Iteration number: [740/4518] 16% | Training loss: 0.6891750552364297
Epoch: 2 | Iteration number: [750/4518] 16% | Training loss: 0.68915545074145
Epoch: 2 | Iteration number: [760/4518] 16% | Training loss: 0.6891436424694564
Epoch: 2 | Iteration number: [770/4518] 17% | Training loss: 0.6891322700234203
Epoch: 2 | Iteration number: [780/4518] 17% | Training loss: 0.6891127163018935
Epoch: 2 | Iteration number: [790/4518] 17% | Training loss: 0.6891009079504616
Epoch: 2 | Iteration number: [800/4518] 17% | Training loss: 0.6890710990130902
Epoch: 2 | Iteration number: [810/4518] 17% | Training loss: 0.6890656460214544
Epoch: 2 | Iteration number: [820/4518] 18% | Training loss: 0.6890653437957531
Epoch: 2 | Iteration number: [830/4518] 18% | Training loss: 0.6890566565186145
Epoch: 2 | Iteration number: [840/4518] 18% | Training loss: 0.6890386837578956
Epoch: 2 | Iteration number: [850/4518] 18% | Training loss: 0.6890287953965805
Epoch: 2 | Iteration number: [860/4518] 19% | Training loss: 0.6890150533166043
Epoch: 2 | Iteration number: [870/4518] 19% | Training loss: 0.6890189551759041
Epoch: 2 | Iteration number: [880/4518] 19% | Training loss: 0.6890059018676932
Epoch: 2 | Iteration number: [890/4518] 19% | Training loss: 0.6889965991625625
Epoch: 2 | Iteration number: [900/4518] 19% | Training loss: 0.6889951562219195
Epoch: 2 | Iteration number: [910/4518] 20% | Training loss: 0.6889905437008366
Epoch: 2 | Iteration number: [920/4518] 20% | Training loss: 0.6889774710587834
Epoch: 2 | Iteration number: [930/4518] 20% | Training loss: 0.6889712388797473
Epoch: 2 | Iteration number: [940/4518] 20% | Training loss: 0.6889611912534592
Epoch: 2 | Iteration number: [950/4518] 21% | Training loss: 0.6889560355638202
Epoch: 2 | Iteration number: [960/4518] 21% | Training loss: 0.6889540445059538
Epoch: 2 | Iteration number: [970/4518] 21% | Training loss: 0.688939644380943
Epoch: 2 | Iteration number: [980/4518] 21% | Training loss: 0.688943503949107
Epoch: 2 | Iteration number: [990/4518] 21% | Training loss: 0.6889351010924638
Epoch: 2 | Iteration number: [1000/4518] 22% | Training loss: 0.6889367728233338
Epoch: 2 | Iteration number: [1010/4518] 22% | Training loss: 0.688928376861138
Epoch: 2 | Iteration number: [1020/4518] 22% | Training loss: 0.6889265073865067
Epoch: 2 | Iteration number: [1030/4518] 22% | Training loss: 0.6889215380242727
Epoch: 2 | Iteration number: [1040/4518] 23% | Training loss: 0.6889124001447972
Epoch: 2 | Iteration number: [1050/4518] 23% | Training loss: 0.6889070617584955
Epoch: 2 | Iteration number: [1060/4518] 23% | Training loss: 0.6888981988407531
Epoch: 2 | Iteration number: [1070/4518] 23% | Training loss: 0.6888955181447145
Epoch: 2 | Iteration number: [1080/4518] 23% | Training loss: 0.6888931684471943
Epoch: 2 | Iteration number: [1090/4518] 24% | Training loss: 0.6888951126588594
Epoch: 2 | Iteration number: [1100/4518] 24% | Training loss: 0.6888987004756928
Epoch: 2 | Iteration number: [1110/4518] 24% | Training loss: 0.6888981694573755
Epoch: 2 | Iteration number: [1120/4518] 24% | Training loss: 0.6888973543686526
Epoch: 2 | Iteration number: [1130/4518] 25% | Training loss: 0.6888945556847396
Epoch: 2 | Iteration number: [1140/4518] 25% | Training loss: 0.6888860510106672
Epoch: 2 | Iteration number: [1150/4518] 25% | Training loss: 0.6888772486603778
Epoch: 2 | Iteration number: [1160/4518] 25% | Training loss: 0.6888755280909867
Epoch: 2 | Iteration number: [1170/4518] 25% | Training loss: 0.6888668249814939
Epoch: 2 | Iteration number: [1180/4518] 26% | Training loss: 0.688863235661539
Epoch: 2 | Iteration number: [1190/4518] 26% | Training loss: 0.6888639688491821
Epoch: 2 | Iteration number: [1200/4518] 26% | Training loss: 0.6888517776628336
Epoch: 2 | Iteration number: [1210/4518] 26% | Training loss: 0.688846798967724
Epoch: 2 | Iteration number: [1220/4518] 27% | Training loss: 0.6888463334959062
Epoch: 2 | Iteration number: [1230/4518] 27% | Training loss: 0.6888409738618184
Epoch: 2 | Iteration number: [1240/4518] 27% | Training loss: 0.6888339312807206
Epoch: 2 | Iteration number: [1250/4518] 27% | Training loss: 0.688830776977539
Epoch: 2 | Iteration number: [1260/4518] 27% | Training loss: 0.6888248179167036
Epoch: 2 | Iteration number: [1270/4518] 28% | Training loss: 0.6888205049544808
Epoch: 2 | Iteration number: [1280/4518] 28% | Training loss: 0.6888132878113538
Epoch: 2 | Iteration number: [1290/4518] 28% | Training loss: 0.6888123558011165
Epoch: 2 | Iteration number: [1300/4518] 28% | Training loss: 0.6888046718560732
Epoch: 2 | Iteration number: [1310/4518] 28% | Training loss: 0.6887950172406117
Epoch: 2 | Iteration number: [1320/4518] 29% | Training loss: 0.6887864380171804
Epoch: 2 | Iteration number: [1330/4518] 29% | Training loss: 0.6887784330916584
Epoch: 2 | Iteration number: [1340/4518] 29% | Training loss: 0.6887761950492859
Epoch: 2 | Iteration number: [1350/4518] 29% | Training loss: 0.6887714528154444
Epoch: 2 | Iteration number: [1360/4518] 30% | Training loss: 0.6887670621275902
Epoch: 2 | Iteration number: [1370/4518] 30% | Training loss: 0.6887612725696425
Epoch: 2 | Iteration number: [1380/4518] 30% | Training loss: 0.6887605824332307
Epoch: 2 | Iteration number: [1390/4518] 30% | Training loss: 0.6887645859512493
Epoch: 2 | Iteration number: [1400/4518] 30% | Training loss: 0.6887702815021788
Epoch: 2 | Iteration number: [1410/4518] 31% | Training loss: 0.6887633023109841
Epoch: 2 | Iteration number: [1420/4518] 31% | Training loss: 0.6887639745860032
Epoch: 2 | Iteration number: [1430/4518] 31% | Training loss: 0.6887513677973848
Epoch: 2 | Iteration number: [1440/4518] 31% | Training loss: 0.6887467734515667
Epoch: 2 | Iteration number: [1450/4518] 32% | Training loss: 0.6887364369425281
Epoch: 2 | Iteration number: [1460/4518] 32% | Training loss: 0.6887321593010263
Epoch: 2 | Iteration number: [1470/4518] 32% | Training loss: 0.6887246352474705
Epoch: 2 | Iteration number: [1480/4518] 32% | Training loss: 0.6887180102435319
Epoch: 2 | Iteration number: [1490/4518] 32% | Training loss: 0.6887194401865837
Epoch: 2 | Iteration number: [1500/4518] 33% | Training loss: 0.6887232298851014
Epoch: 2 | Iteration number: [1510/4518] 33% | Training loss: 0.6887216578256216
Epoch: 2 | Iteration number: [1520/4518] 33% | Training loss: 0.6887186975463441
Epoch: 2 | Iteration number: [1530/4518] 33% | Training loss: 0.6887162265824337
Epoch: 2 | Iteration number: [1540/4518] 34% | Training loss: 0.6887157967338314
Epoch: 2 | Iteration number: [1550/4518] 34% | Training loss: 0.6887132463916655
Epoch: 2 | Iteration number: [1560/4518] 34% | Training loss: 0.6887100728276448
Epoch: 2 | Iteration number: [1570/4518] 34% | Training loss: 0.6887077917718584
Epoch: 2 | Iteration number: [1580/4518] 34% | Training loss: 0.688705577842797
Epoch: 2 | Iteration number: [1590/4518] 35% | Training loss: 0.6887060886284091
Epoch: 2 | Iteration number: [1600/4518] 35% | Training loss: 0.688706007823348
Epoch: 2 | Iteration number: [1610/4518] 35% | Training loss: 0.6887014886607294
Epoch: 2 | Iteration number: [1620/4518] 35% | Training loss: 0.6886935213833679
Epoch: 2 | Iteration number: [1630/4518] 36% | Training loss: 0.6886883844261521
Epoch: 2 | Iteration number: [1640/4518] 36% | Training loss: 0.6886849201307064
Epoch: 2 | Iteration number: [1650/4518] 36% | Training loss: 0.6886752340287873
Epoch: 2 | Iteration number: [1660/4518] 36% | Training loss: 0.6886790823864649
Epoch: 2 | Iteration number: [1670/4518] 36% | Training loss: 0.6886745746264201
Epoch: 2 | Iteration number: [1680/4518] 37% | Training loss: 0.6886684465266409
Epoch: 2 | Iteration number: [1690/4518] 37% | Training loss: 0.6886752850557926
Epoch: 2 | Iteration number: [1700/4518] 37% | Training loss: 0.6886744499557158
Epoch: 2 | Iteration number: [1710/4518] 37% | Training loss: 0.6886682938762576
Epoch: 2 | Iteration number: [1720/4518] 38% | Training loss: 0.6886683470287989
Epoch: 2 | Iteration number: [1730/4518] 38% | Training loss: 0.6886607756159898
Epoch: 2 | Iteration number: [1740/4518] 38% | Training loss: 0.6886548451651102
Epoch: 2 | Iteration number: [1750/4518] 38% | Training loss: 0.6886563629422869
Epoch: 2 | Iteration number: [1760/4518] 38% | Training loss: 0.6886529308828441
Epoch: 2 | Iteration number: [1770/4518] 39% | Training loss: 0.6886484175078613
Epoch: 2 | Iteration number: [1780/4518] 39% | Training loss: 0.6886488172110546
Epoch: 2 | Iteration number: [1790/4518] 39% | Training loss: 0.688646520615956
Epoch: 2 | Iteration number: [1800/4518] 39% | Training loss: 0.6886436340875096
Epoch: 2 | Iteration number: [1810/4518] 40% | Training loss: 0.6886395872627173
Epoch: 2 | Iteration number: [1820/4518] 40% | Training loss: 0.6886434264235444
Epoch: 2 | Iteration number: [1830/4518] 40% | Training loss: 0.6886441072479623
Epoch: 2 | Iteration number: [1840/4518] 40% | Training loss: 0.6886417101906693
Epoch: 2 | Iteration number: [1850/4518] 40% | Training loss: 0.6886356362781009
Epoch: 2 | Iteration number: [1860/4518] 41% | Training loss: 0.6886317507554126
Epoch: 2 | Iteration number: [1870/4518] 41% | Training loss: 0.6886332995432584
Epoch: 2 | Iteration number: [1880/4518] 41% | Training loss: 0.6886269687655124
Epoch: 2 | Iteration number: [1890/4518] 41% | Training loss: 0.6886254572679126
Epoch: 2 | Iteration number: [1900/4518] 42% | Training loss: 0.6886235348488156
Epoch: 2 | Iteration number: [1910/4518] 42% | Training loss: 0.6886176835492019
Epoch: 2 | Iteration number: [1920/4518] 42% | Training loss: 0.6886145772101978
Epoch: 2 | Iteration number: [1930/4518] 42% | Training loss: 0.6886159337864021
Epoch: 2 | Iteration number: [1940/4518] 42% | Training loss: 0.688615326967436
Epoch: 2 | Iteration number: [1950/4518] 43% | Training loss: 0.6886177571308918
Epoch: 2 | Iteration number: [1960/4518] 43% | Training loss: 0.688614002022208
Epoch: 2 | Iteration number: [1970/4518] 43% | Training loss: 0.6886080119513013
Epoch: 2 | Iteration number: [1980/4518] 43% | Training loss: 0.6886058033114731
Epoch: 2 | Iteration number: [1990/4518] 44% | Training loss: 0.6886038701138903
Epoch: 2 | Iteration number: [2000/4518] 44% | Training loss: 0.68859973731637
Epoch: 2 | Iteration number: [2010/4518] 44% | Training loss: 0.688595621710393
Epoch: 2 | Iteration number: [2020/4518] 44% | Training loss: 0.6885902101155554
Epoch: 2 | Iteration number: [2030/4518] 44% | Training loss: 0.6885912104486832
Epoch: 2 | Iteration number: [2040/4518] 45% | Training loss: 0.688588734730786
Epoch: 2 | Iteration number: [2050/4518] 45% | Training loss: 0.6885921046501253
Epoch: 2 | Iteration number: [2060/4518] 45% | Training loss: 0.6885849340737444
Epoch: 2 | Iteration number: [2070/4518] 45% | Training loss: 0.6885864219227851
Epoch: 2 | Iteration number: [2080/4518] 46% | Training loss: 0.6885879569042187
Epoch: 2 | Iteration number: [2090/4518] 46% | Training loss: 0.6885874583675531
Epoch: 2 | Iteration number: [2100/4518] 46% | Training loss: 0.6885857701301574
Epoch: 2 | Iteration number: [2110/4518] 46% | Training loss: 0.6885809481991411
Epoch: 2 | Iteration number: [2120/4518] 46% | Training loss: 0.688581124988367
Epoch: 2 | Iteration number: [2130/4518] 47% | Training loss: 0.688580854174117
Epoch: 2 | Iteration number: [2140/4518] 47% | Training loss: 0.6885746881226513
Epoch: 2 | Iteration number: [2150/4518] 47% | Training loss: 0.6885757070918416
Epoch: 2 | Iteration number: [2160/4518] 47% | Training loss: 0.6885768445553603
Epoch: 2 | Iteration number: [2170/4518] 48% | Training loss: 0.6885741809546123
Epoch: 2 | Iteration number: [2180/4518] 48% | Training loss: 0.6885696365745789
Epoch: 2 | Iteration number: [2190/4518] 48% | Training loss: 0.6885717190836118
Epoch: 2 | Iteration number: [2200/4518] 48% | Training loss: 0.6885665799541907
Epoch: 2 | Iteration number: [2210/4518] 48% | Training loss: 0.6885655210568354
Epoch: 2 | Iteration number: [2220/4518] 49% | Training loss: 0.6885609752423054
Epoch: 2 | Iteration number: [2230/4518] 49% | Training loss: 0.6885569546522047
Epoch: 2 | Iteration number: [2240/4518] 49% | Training loss: 0.6885502778525864
Epoch: 2 | Iteration number: [2250/4518] 49% | Training loss: 0.6885486521455977
Epoch: 2 | Iteration number: [2260/4518] 50% | Training loss: 0.6885498873691643
Epoch: 2 | Iteration number: [2270/4518] 50% | Training loss: 0.6885468295492264
Epoch: 2 | Iteration number: [2280/4518] 50% | Training loss: 0.6885472657387717
Epoch: 2 | Iteration number: [2290/4518] 50% | Training loss: 0.6885472039468423
Epoch: 2 | Iteration number: [2300/4518] 50% | Training loss: 0.6885467347113983
Epoch: 2 | Iteration number: [2310/4518] 51% | Training loss: 0.6885449330528061
Epoch: 2 | Iteration number: [2320/4518] 51% | Training loss: 0.68854052907434
Epoch: 2 | Iteration number: [2330/4518] 51% | Training loss: 0.6885357527006337
Epoch: 2 | Iteration number: [2340/4518] 51% | Training loss: 0.6885379350847668
Epoch: 2 | Iteration number: [2350/4518] 52% | Training loss: 0.6885341847196539
Epoch: 2 | Iteration number: [2360/4518] 52% | Training loss: 0.688534229109853
Epoch: 2 | Iteration number: [2370/4518] 52% | Training loss: 0.688534356295308
Epoch: 2 | Iteration number: [2380/4518] 52% | Training loss: 0.6885314176062576
Epoch: 2 | Iteration number: [2390/4518] 52% | Training loss: 0.6885344724525467
Epoch: 2 | Iteration number: [2400/4518] 53% | Training loss: 0.688536966368556
Epoch: 2 | Iteration number: [2410/4518] 53% | Training loss: 0.6885334248364714
Epoch: 2 | Iteration number: [2420/4518] 53% | Training loss: 0.6885278362873172
Epoch: 2 | Iteration number: [2430/4518] 53% | Training loss: 0.6885267574600722
Epoch: 2 | Iteration number: [2440/4518] 54% | Training loss: 0.6885280893474329
Epoch: 2 | Iteration number: [2450/4518] 54% | Training loss: 0.6885280968705002
Epoch: 2 | Iteration number: [2460/4518] 54% | Training loss: 0.6885240814065545
Epoch: 2 | Iteration number: [2470/4518] 54% | Training loss: 0.6885242181268298
Epoch: 2 | Iteration number: [2480/4518] 54% | Training loss: 0.6885275287733924
Epoch: 2 | Iteration number: [2490/4518] 55% | Training loss: 0.6885245002177824
Epoch: 2 | Iteration number: [2500/4518] 55% | Training loss: 0.6885249600887299
Epoch: 2 | Iteration number: [2510/4518] 55% | Training loss: 0.6885233258108694
Epoch: 2 | Iteration number: [2520/4518] 55% | Training loss: 0.6885191008921654
Epoch: 2 | Iteration number: [2530/4518] 55% | Training loss: 0.6885166985244148
Epoch: 2 | Iteration number: [2540/4518] 56% | Training loss: 0.6885115836548993
Epoch: 2 | Iteration number: [2550/4518] 56% | Training loss: 0.6885137792194591
Epoch: 2 | Iteration number: [2560/4518] 56% | Training loss: 0.6885127339046448
Epoch: 2 | Iteration number: [2570/4518] 56% | Training loss: 0.6885134011159147
Epoch: 2 | Iteration number: [2580/4518] 57% | Training loss: 0.6885135499774948
Epoch: 2 | Iteration number: [2590/4518] 57% | Training loss: 0.6885179857029418
Epoch: 2 | Iteration number: [2600/4518] 57% | Training loss: 0.6885150127685987
Epoch: 2 | Iteration number: [2610/4518] 57% | Training loss: 0.6885128830127789
Epoch: 2 | Iteration number: [2620/4518] 57% | Training loss: 0.6885080727229591
Epoch: 2 | Iteration number: [2630/4518] 58% | Training loss: 0.6885040850467101
Epoch: 2 | Iteration number: [2640/4518] 58% | Training loss: 0.688500987828681
Epoch: 2 | Iteration number: [2650/4518] 58% | Training loss: 0.6884964899746877
Epoch: 2 | Iteration number: [2660/4518] 58% | Training loss: 0.6884968412549872
Epoch: 2 | Iteration number: [2670/4518] 59% | Training loss: 0.6884953172465835
Epoch: 2 | Iteration number: [2680/4518] 59% | Training loss: 0.688495846915601
Epoch: 2 | Iteration number: [2690/4518] 59% | Training loss: 0.6884962571819475
Epoch: 2 | Iteration number: [2700/4518] 59% | Training loss: 0.6884939690872475
Epoch: 2 | Iteration number: [2710/4518] 59% | Training loss: 0.6884914291740784
Epoch: 2 | Iteration number: [2720/4518] 60% | Training loss: 0.688490782108377
Epoch: 2 | Iteration number: [2730/4518] 60% | Training loss: 0.6884896874864459
Epoch: 2 | Iteration number: [2740/4518] 60% | Training loss: 0.6884915586370621
Epoch: 2 | Iteration number: [2750/4518] 60% | Training loss: 0.6884888004823164
Epoch: 2 | Iteration number: [2760/4518] 61% | Training loss: 0.6884866838221965
Epoch: 2 | Iteration number: [2770/4518] 61% | Training loss: 0.6884845484465038
Epoch: 2 | Iteration number: [2780/4518] 61% | Training loss: 0.688485273268583
Epoch: 2 | Iteration number: [2790/4518] 61% | Training loss: 0.6884848735238489
Epoch: 2 | Iteration number: [2800/4518] 61% | Training loss: 0.6884814971046789
Epoch: 2 | Iteration number: [2810/4518] 62% | Training loss: 0.6884777553353021
Epoch: 2 | Iteration number: [2820/4518] 62% | Training loss: 0.6884783477225203
Epoch: 2 | Iteration number: [2830/4518] 62% | Training loss: 0.6884758816801617
Epoch: 2 | Iteration number: [2840/4518] 62% | Training loss: 0.6884764267105452
Epoch: 2 | Iteration number: [2850/4518] 63% | Training loss: 0.6884767054674918
Epoch: 2 | Iteration number: [2860/4518] 63% | Training loss: 0.6884748581822936
Epoch: 2 | Iteration number: [2870/4518] 63% | Training loss: 0.6884748305177855
Epoch: 2 | Iteration number: [2880/4518] 63% | Training loss: 0.6884722199704912
Epoch: 2 | Iteration number: [2890/4518] 63% | Training loss: 0.6884739488260144
Epoch: 2 | Iteration number: [2900/4518] 64% | Training loss: 0.6884742492026296
Epoch: 2 | Iteration number: [2910/4518] 64% | Training loss: 0.6884717589186639
Epoch: 2 | Iteration number: [2920/4518] 64% | Training loss: 0.6884698642851556
Epoch: 2 | Iteration number: [2930/4518] 64% | Training loss: 0.6884667950278663
Epoch: 2 | Iteration number: [2940/4518] 65% | Training loss: 0.6884685091623644
Epoch: 2 | Iteration number: [2950/4518] 65% | Training loss: 0.6884692555564945
Epoch: 2 | Iteration number: [2960/4518] 65% | Training loss: 0.6884674544672709
Epoch: 2 | Iteration number: [2970/4518] 65% | Training loss: 0.6884646353095469
Epoch: 2 | Iteration number: [2980/4518] 65% | Training loss: 0.6884612445863302
Epoch: 2 | Iteration number: [2990/4518] 66% | Training loss: 0.6884576959155475
Epoch: 2 | Iteration number: [3000/4518] 66% | Training loss: 0.6884628719886144
Epoch: 2 | Iteration number: [3010/4518] 66% | Training loss: 0.6884607489322904
Epoch: 2 | Iteration number: [3020/4518] 66% | Training loss: 0.6884595360779604
Epoch: 2 | Iteration number: [3030/4518] 67% | Training loss: 0.6884599442725922
Epoch: 2 | Iteration number: [3040/4518] 67% | Training loss: 0.6884584211793385
Epoch: 2 | Iteration number: [3050/4518] 67% | Training loss: 0.6884541986223127
Epoch: 2 | Iteration number: [3060/4518] 67% | Training loss: 0.6884516934553783
Epoch: 2 | Iteration number: [3070/4518] 67% | Training loss: 0.6884521971696362
Epoch: 2 | Iteration number: [3080/4518] 68% | Training loss: 0.6884491655346635
Epoch: 2 | Iteration number: [3090/4518] 68% | Training loss: 0.6884466534100689
Epoch: 2 | Iteration number: [3100/4518] 68% | Training loss: 0.6884485156113102
Epoch: 2 | Iteration number: [3110/4518] 68% | Training loss: 0.6884460071658781
Epoch: 2 | Iteration number: [3120/4518] 69% | Training loss: 0.6884430409432986
Epoch: 2 | Iteration number: [3130/4518] 69% | Training loss: 0.6884394432789982
Epoch: 2 | Iteration number: [3140/4518] 69% | Training loss: 0.6884356006125736
Epoch: 2 | Iteration number: [3150/4518] 69% | Training loss: 0.688434799606838
Epoch: 2 | Iteration number: [3160/4518] 69% | Training loss: 0.6884322549534749
Epoch: 2 | Iteration number: [3170/4518] 70% | Training loss: 0.6884300001036106
Epoch: 2 | Iteration number: [3180/4518] 70% | Training loss: 0.6884261592004284
Epoch: 2 | Iteration number: [3190/4518] 70% | Training loss: 0.6884218593189335
Epoch: 2 | Iteration number: [3200/4518] 70% | Training loss: 0.6884210395254194
Epoch: 2 | Iteration number: [3210/4518] 71% | Training loss: 0.6884220258097782
Epoch: 2 | Iteration number: [3220/4518] 71% | Training loss: 0.6884175149365241
Epoch: 2 | Iteration number: [3230/4518] 71% | Training loss: 0.6884138679172233
Epoch: 2 | Iteration number: [3240/4518] 71% | Training loss: 0.6884134553280877
Epoch: 2 | Iteration number: [3250/4518] 71% | Training loss: 0.6884131875771743
Epoch: 2 | Iteration number: [3260/4518] 72% | Training loss: 0.6884132252697565
Epoch: 2 | Iteration number: [3270/4518] 72% | Training loss: 0.6884105147571739
Epoch: 2 | Iteration number: [3280/4518] 72% | Training loss: 0.6884102747571178
Epoch: 2 | Iteration number: [3290/4518] 72% | Training loss: 0.68840413762081
Epoch: 2 | Iteration number: [3300/4518] 73% | Training loss: 0.6884015176693599
Epoch: 2 | Iteration number: [3310/4518] 73% | Training loss: 0.6883987908997204
Epoch: 2 | Iteration number: [3320/4518] 73% | Training loss: 0.6883958399834403
Epoch: 2 | Iteration number: [3330/4518] 73% | Training loss: 0.6883942701079108
Epoch: 2 | Iteration number: [3340/4518] 73% | Training loss: 0.688390228402115
Epoch: 2 | Iteration number: [3350/4518] 74% | Training loss: 0.6883867992749855
Epoch: 2 | Iteration number: [3360/4518] 74% | Training loss: 0.6883868120965504
Epoch: 2 | Iteration number: [3370/4518] 74% | Training loss: 0.6883805596333229
Epoch: 2 | Iteration number: [3380/4518] 74% | Training loss: 0.6883805765202765
Epoch: 2 | Iteration number: [3390/4518] 75% | Training loss: 0.6883818022445239
Epoch: 2 | Iteration number: [3400/4518] 75% | Training loss: 0.6883788793753175
Epoch: 2 | Iteration number: [3410/4518] 75% | Training loss: 0.6883789985935009
Epoch: 2 | Iteration number: [3420/4518] 75% | Training loss: 0.6883802508401592
Epoch: 2 | Iteration number: [3430/4518] 75% | Training loss: 0.6883809335377752
Epoch: 2 | Iteration number: [3440/4518] 76% | Training loss: 0.688379622857238
Epoch: 2 | Iteration number: [3450/4518] 76% | Training loss: 0.6883771366831185
Epoch: 2 | Iteration number: [3460/4518] 76% | Training loss: 0.6883776781703695
Epoch: 2 | Iteration number: [3470/4518] 76% | Training loss: 0.6883748478951303
Epoch: 2 | Iteration number: [3480/4518] 77% | Training loss: 0.6883750298071182
Epoch: 2 | Iteration number: [3490/4518] 77% | Training loss: 0.6883733735385119
Epoch: 2 | Iteration number: [3500/4518] 77% | Training loss: 0.6883738532236644
Epoch: 2 | Iteration number: [3510/4518] 77% | Training loss: 0.6883751080416546
Epoch: 2 | Iteration number: [3520/4518] 77% | Training loss: 0.6883728192611174
Epoch: 2 | Iteration number: [3530/4518] 78% | Training loss: 0.6883697467383852
Epoch: 2 | Iteration number: [3540/4518] 78% | Training loss: 0.6883673801260479
Epoch: 2 | Iteration number: [3550/4518] 78% | Training loss: 0.688366869671244
Epoch: 2 | Iteration number: [3560/4518] 78% | Training loss: 0.6883635148573457
Epoch: 2 | Iteration number: [3570/4518] 79% | Training loss: 0.688364671608981
Epoch: 2 | Iteration number: [3580/4518] 79% | Training loss: 0.6883652062555932
Epoch: 2 | Iteration number: [3590/4518] 79% | Training loss: 0.6883627942013542
Epoch: 2 | Iteration number: [3600/4518] 79% | Training loss: 0.6883597074117925
Epoch: 2 | Iteration number: [3610/4518] 79% | Training loss: 0.6883604711442773
Epoch: 2 | Iteration number: [3620/4518] 80% | Training loss: 0.6883553625799674
Epoch: 2 | Iteration number: [3630/4518] 80% | Training loss: 0.6883527728644284
Epoch: 2 | Iteration number: [3640/4518] 80% | Training loss: 0.688349437877372
Epoch: 2 | Iteration number: [3650/4518] 80% | Training loss: 0.6883473690405284
Epoch: 2 | Iteration number: [3660/4518] 81% | Training loss: 0.6883450623581319
Epoch: 2 | Iteration number: [3670/4518] 81% | Training loss: 0.6883443076863925
Epoch: 2 | Iteration number: [3680/4518] 81% | Training loss: 0.6883418452966472
Epoch: 2 | Iteration number: [3690/4518] 81% | Training loss: 0.6883402099292776
Epoch: 2 | Iteration number: [3700/4518] 81% | Training loss: 0.6883390786680015
Epoch: 2 | Iteration number: [3710/4518] 82% | Training loss: 0.6883374119865284
Epoch: 2 | Iteration number: [3720/4518] 82% | Training loss: 0.6883403703089683
Epoch: 2 | Iteration number: [3730/4518] 82% | Training loss: 0.6883391237131072
Epoch: 2 | Iteration number: [3740/4518] 82% | Training loss: 0.6883364105447728
Epoch: 2 | Iteration number: [3750/4518] 83% | Training loss: 0.6883349644978841
Epoch: 2 | Iteration number: [3760/4518] 83% | Training loss: 0.6883312945353224
Epoch: 2 | Iteration number: [3770/4518] 83% | Training loss: 0.6883292337943767
Epoch: 2 | Iteration number: [3780/4518] 83% | Training loss: 0.6883287171049723
Epoch: 2 | Iteration number: [3790/4518] 83% | Training loss: 0.6883257258064199
Epoch: 2 | Iteration number: [3800/4518] 84% | Training loss: 0.6883235652352634
Epoch: 2 | Iteration number: [3810/4518] 84% | Training loss: 0.6883239342002418
Epoch: 2 | Iteration number: [3820/4518] 84% | Training loss: 0.6883205337986272
Epoch: 2 | Iteration number: [3830/4518] 84% | Training loss: 0.6883194982227395
Epoch: 2 | Iteration number: [3840/4518] 84% | Training loss: 0.6883188530492286
Epoch: 2 | Iteration number: [3850/4518] 85% | Training loss: 0.688316899321296
Epoch: 2 | Iteration number: [3860/4518] 85% | Training loss: 0.6883170182686396
Epoch: 2 | Iteration number: [3870/4518] 85% | Training loss: 0.6883168939318152
Epoch: 2 | Iteration number: [3880/4518] 85% | Training loss: 0.6883131634482403
Epoch: 2 | Iteration number: [3890/4518] 86% | Training loss: 0.6883153004634043
Epoch: 2 | Iteration number: [3900/4518] 86% | Training loss: 0.6883112841691726
Epoch: 2 | Iteration number: [3910/4518] 86% | Training loss: 0.6883086425873934
Epoch: 2 | Iteration number: [3920/4518] 86% | Training loss: 0.6883063987657732
Epoch: 2 | Iteration number: [3930/4518] 86% | Training loss: 0.6883027154677394
Epoch: 2 | Iteration number: [3940/4518] 87% | Training loss: 0.6883020527471746
Epoch: 2 | Iteration number: [3950/4518] 87% | Training loss: 0.6883015075967281
Epoch: 2 | Iteration number: [3960/4518] 87% | Training loss: 0.6882976963363513
Epoch: 2 | Iteration number: [3970/4518] 87% | Training loss: 0.6883002316321174
Epoch: 2 | Iteration number: [3980/4518] 88% | Training loss: 0.6882993447570944
Epoch: 2 | Iteration number: [3990/4518] 88% | Training loss: 0.6882997372992953
Epoch: 2 | Iteration number: [4000/4518] 88% | Training loss: 0.6883002808988095
Epoch: 2 | Iteration number: [4010/4518] 88% | Training loss: 0.6882998903196054
Epoch: 2 | Iteration number: [4020/4518] 88% | Training loss: 0.6882990357146335
Epoch: 2 | Iteration number: [4030/4518] 89% | Training loss: 0.6882967627373877
Epoch: 2 | Iteration number: [4040/4518] 89% | Training loss: 0.6882960221850046
Epoch: 2 | Iteration number: [4050/4518] 89% | Training loss: 0.6882969346311357
Epoch: 2 | Iteration number: [4060/4518] 89% | Training loss: 0.6882954257021984
Epoch: 2 | Iteration number: [4070/4518] 90% | Training loss: 0.6882946596245215
Epoch: 2 | Iteration number: [4080/4518] 90% | Training loss: 0.6882933002914868
Epoch: 2 | Iteration number: [4090/4518] 90% | Training loss: 0.6882923967243698
Epoch: 2 | Iteration number: [4100/4518] 90% | Training loss: 0.6882913085890979
Epoch: 2 | Iteration number: [4110/4518] 90% | Training loss: 0.6882877940969165
Epoch: 2 | Iteration number: [4120/4518] 91% | Training loss: 0.6882897513150011
Epoch: 2 | Iteration number: [4130/4518] 91% | Training loss: 0.688289367979433
Epoch: 2 | Iteration number: [4140/4518] 91% | Training loss: 0.688287221852708
Epoch: 2 | Iteration number: [4150/4518] 91% | Training loss: 0.6882833820078746
Epoch: 2 | Iteration number: [4160/4518] 92% | Training loss: 0.688284423116308
Epoch: 2 | Iteration number: [4170/4518] 92% | Training loss: 0.6882804444082063
Epoch: 2 | Iteration number: [4180/4518] 92% | Training loss: 0.688279633844298
Epoch: 2 | Iteration number: [4190/4518] 92% | Training loss: 0.6882782411746022
Epoch: 2 | Iteration number: [4200/4518] 92% | Training loss: 0.6882767083957082
Epoch: 2 | Iteration number: [4210/4518] 93% | Training loss: 0.6882749808372625
Epoch: 2 | Iteration number: [4220/4518] 93% | Training loss: 0.6882718252909692
Epoch: 2 | Iteration number: [4230/4518] 93% | Training loss: 0.6882698938778952
Epoch: 2 | Iteration number: [4240/4518] 93% | Training loss: 0.6882683428672125
Epoch: 2 | Iteration number: [4250/4518] 94% | Training loss: 0.6882621966670541
Epoch: 2 | Iteration number: [4260/4518] 94% | Training loss: 0.6882619315609686
Epoch: 2 | Iteration number: [4270/4518] 94% | Training loss: 0.6882625139429642
Epoch: 2 | Iteration number: [4280/4518] 94% | Training loss: 0.6882567927241325
Epoch: 2 | Iteration number: [4290/4518] 94% | Training loss: 0.6882532170602492
Epoch: 2 | Iteration number: [4300/4518] 95% | Training loss: 0.6882514184436133
Epoch: 2 | Iteration number: [4310/4518] 95% | Training loss: 0.6882506297940167
Epoch: 2 | Iteration number: [4320/4518] 95% | Training loss: 0.6882468335054539
Epoch: 2 | Iteration number: [4330/4518] 95% | Training loss: 0.6882451609293253
Epoch: 2 | Iteration number: [4340/4518] 96% | Training loss: 0.688243768470628
Epoch: 2 | Iteration number: [4350/4518] 96% | Training loss: 0.6882454783066936
Epoch: 2 | Iteration number: [4360/4518] 96% | Training loss: 0.688243230917585
Epoch: 2 | Iteration number: [4370/4518] 96% | Training loss: 0.6882429618720878
Epoch: 2 | Iteration number: [4380/4518] 96% | Training loss: 0.6882411382241881
Epoch: 2 | Iteration number: [4390/4518] 97% | Training loss: 0.6882385949746351
Epoch: 2 | Iteration number: [4400/4518] 97% | Training loss: 0.6882380126823079
Epoch: 2 | Iteration number: [4410/4518] 97% | Training loss: 0.6882381824138754
Epoch: 2 | Iteration number: [4420/4518] 97% | Training loss: 0.6882353591298626
Epoch: 2 | Iteration number: [4430/4518] 98% | Training loss: 0.688234050642556
Epoch: 2 | Iteration number: [4440/4518] 98% | Training loss: 0.6882334505786767
Epoch: 2 | Iteration number: [4450/4518] 98% | Training loss: 0.6882335686147882
Epoch: 2 | Iteration number: [4460/4518] 98% | Training loss: 0.6882328754716924
Epoch: 2 | Iteration number: [4470/4518] 98% | Training loss: 0.6882318560175714
Epoch: 2 | Iteration number: [4480/4518] 99% | Training loss: 0.6882321071944066
Epoch: 2 | Iteration number: [4490/4518] 99% | Training loss: 0.6882288820228492
Epoch: 2 | Iteration number: [4500/4518] 99% | Training loss: 0.6882279385725657
Epoch: 2 | Iteration number: [4510/4518] 99% | Training loss: 0.6882280303078586

 End of epoch: 2 | Train Loss: 0.6880747423255374 | Training Time: 640 

 End of epoch: 2 | Eval Loss: 0.6903638645094268 | Evaluating Time: 17 
Epoch: 3 | Iteration number: [10/4518] 0% | Training loss: 0.7578226506710053
Epoch: 3 | Iteration number: [20/4518] 0% | Training loss: 0.7229424864053726
Epoch: 3 | Iteration number: [30/4518] 0% | Training loss: 0.7114366213480632
Epoch: 3 | Iteration number: [40/4518] 0% | Training loss: 0.705858588218689
Epoch: 3 | Iteration number: [50/4518] 1% | Training loss: 0.7018151295185089
Epoch: 3 | Iteration number: [60/4518] 1% | Training loss: 0.699415119489034
Epoch: 3 | Iteration number: [70/4518] 1% | Training loss: 0.6976200989314488
Epoch: 3 | Iteration number: [80/4518] 1% | Training loss: 0.6963280849158764
Epoch: 3 | Iteration number: [90/4518] 1% | Training loss: 0.6954162935415904
Epoch: 3 | Iteration number: [100/4518] 2% | Training loss: 0.6947050327062607
Epoch: 3 | Iteration number: [110/4518] 2% | Training loss: 0.6940281900492582
Epoch: 3 | Iteration number: [120/4518] 2% | Training loss: 0.6936478207508723
Epoch: 3 | Iteration number: [130/4518] 2% | Training loss: 0.6931729367146126
Epoch: 3 | Iteration number: [140/4518] 3% | Training loss: 0.6927501244204385
Epoch: 3 | Iteration number: [150/4518] 3% | Training loss: 0.6924001924196879
Epoch: 3 | Iteration number: [160/4518] 3% | Training loss: 0.6921125166118145
Epoch: 3 | Iteration number: [170/4518] 3% | Training loss: 0.6918910997755388
Epoch: 3 | Iteration number: [180/4518] 3% | Training loss: 0.6917183366086748
Epoch: 3 | Iteration number: [190/4518] 4% | Training loss: 0.6914847399059095
Epoch: 3 | Iteration number: [200/4518] 4% | Training loss: 0.6912612250447273
Epoch: 3 | Iteration number: [210/4518] 4% | Training loss: 0.6910501358054933
Epoch: 3 | Iteration number: [220/4518] 4% | Training loss: 0.6908973460847682
Epoch: 3 | Iteration number: [230/4518] 5% | Training loss: 0.6907623845597972
Epoch: 3 | Iteration number: [240/4518] 5% | Training loss: 0.6906571226815382
Epoch: 3 | Iteration number: [250/4518] 5% | Training loss: 0.6905319545269012
Epoch: 3 | Iteration number: [260/4518] 5% | Training loss: 0.6904297390809426
Epoch: 3 | Iteration number: [270/4518] 5% | Training loss: 0.6903439459977326
Epoch: 3 | Iteration number: [280/4518] 6% | Training loss: 0.69023785505976
Epoch: 3 | Iteration number: [290/4518] 6% | Training loss: 0.6901973342073375
Epoch: 3 | Iteration number: [300/4518] 6% | Training loss: 0.6901337756713232
Epoch: 3 | Iteration number: [310/4518] 6% | Training loss: 0.69009358248403
Epoch: 3 | Iteration number: [320/4518] 7% | Training loss: 0.6900034509599209
Epoch: 3 | Iteration number: [330/4518] 7% | Training loss: 0.6899211114103144
Epoch: 3 | Iteration number: [340/4518] 7% | Training loss: 0.6898619006661808
Epoch: 3 | Iteration number: [350/4518] 7% | Training loss: 0.6898269864491055
Epoch: 3 | Iteration number: [360/4518] 7% | Training loss: 0.6897651960452398
Epoch: 3 | Iteration number: [370/4518] 8% | Training loss: 0.6897258655444996
Epoch: 3 | Iteration number: [380/4518] 8% | Training loss: 0.6897088036725395
Epoch: 3 | Iteration number: [390/4518] 8% | Training loss: 0.6896568400737567
Epoch: 3 | Iteration number: [400/4518] 8% | Training loss: 0.6896064366400242
Epoch: 3 | Iteration number: [410/4518] 9% | Training loss: 0.6895060703521821
Epoch: 3 | Iteration number: [420/4518] 9% | Training loss: 0.6894766255503609
Epoch: 3 | Iteration number: [430/4518] 9% | Training loss: 0.6894067731014518
Epoch: 3 | Iteration number: [440/4518] 9% | Training loss: 0.6893500181761655
Epoch: 3 | Iteration number: [450/4518] 9% | Training loss: 0.6892821016576555
Epoch: 3 | Iteration number: [460/4518] 10% | Training loss: 0.6892462897559871
Epoch: 3 | Iteration number: [470/4518] 10% | Training loss: 0.689201950519643
Epoch: 3 | Iteration number: [480/4518] 10% | Training loss: 0.6891838273654382
Epoch: 3 | Iteration number: [490/4518] 10% | Training loss: 0.6891518735155767
Epoch: 3 | Iteration number: [500/4518] 11% | Training loss: 0.6891360800266266
Epoch: 3 | Iteration number: [510/4518] 11% | Training loss: 0.6891009754994336
Epoch: 3 | Iteration number: [520/4518] 11% | Training loss: 0.6890619963407516
Epoch: 3 | Iteration number: [530/4518] 11% | Training loss: 0.6890413643054243
Epoch: 3 | Iteration number: [540/4518] 11% | Training loss: 0.6889997788049557
Epoch: 3 | Iteration number: [550/4518] 12% | Training loss: 0.6889780687202107
Epoch: 3 | Iteration number: [560/4518] 12% | Training loss: 0.6889762927378927
Epoch: 3 | Iteration number: [570/4518] 12% | Training loss: 0.6889560300007201
Epoch: 3 | Iteration number: [580/4518] 12% | Training loss: 0.6889232540952748
Epoch: 3 | Iteration number: [590/4518] 13% | Training loss: 0.6889088565010135
Epoch: 3 | Iteration number: [600/4518] 13% | Training loss: 0.6888766772548358
Epoch: 3 | Iteration number: [610/4518] 13% | Training loss: 0.6888690560567574
Epoch: 3 | Iteration number: [620/4518] 13% | Training loss: 0.688869127727324
Epoch: 3 | Iteration number: [630/4518] 13% | Training loss: 0.6888453274492233
Epoch: 3 | Iteration number: [640/4518] 14% | Training loss: 0.6888327949680388
Epoch: 3 | Iteration number: [650/4518] 14% | Training loss: 0.6888132624442761
Epoch: 3 | Iteration number: [660/4518] 14% | Training loss: 0.6888071835041046
Epoch: 3 | Iteration number: [670/4518] 14% | Training loss: 0.6887833893299102
Epoch: 3 | Iteration number: [680/4518] 15% | Training loss: 0.6887805208563804
Epoch: 3 | Iteration number: [690/4518] 15% | Training loss: 0.688752283739007
Epoch: 3 | Iteration number: [700/4518] 15% | Training loss: 0.6887256156546729
Epoch: 3 | Iteration number: [710/4518] 15% | Training loss: 0.6887222146484214
Epoch: 3 | Iteration number: [720/4518] 15% | Training loss: 0.6887060670389069
Epoch: 3 | Iteration number: [730/4518] 16% | Training loss: 0.688680132529507
Epoch: 3 | Iteration number: [740/4518] 16% | Training loss: 0.6886607740376447
Epoch: 3 | Iteration number: [750/4518] 16% | Training loss: 0.6886234239737192
Epoch: 3 | Iteration number: [760/4518] 16% | Training loss: 0.6886150167960869
Epoch: 3 | Iteration number: [770/4518] 17% | Training loss: 0.6886066082236054
Epoch: 3 | Iteration number: [780/4518] 17% | Training loss: 0.6885969396585073
Epoch: 3 | Iteration number: [790/4518] 17% | Training loss: 0.6885880951639972
Epoch: 3 | Iteration number: [800/4518] 17% | Training loss: 0.6885850777477026
Epoch: 3 | Iteration number: [810/4518] 17% | Training loss: 0.6885831860112556
Epoch: 3 | Iteration number: [820/4518] 18% | Training loss: 0.688564071059227
Epoch: 3 | Iteration number: [830/4518] 18% | Training loss: 0.6885526667876416
Epoch: 3 | Iteration number: [840/4518] 18% | Training loss: 0.6885349647629828
Epoch: 3 | Iteration number: [850/4518] 18% | Training loss: 0.6885209224504583
Epoch: 3 | Iteration number: [860/4518] 19% | Training loss: 0.6885121062744496
Epoch: 3 | Iteration number: [870/4518] 19% | Training loss: 0.6884996038058708
Epoch: 3 | Iteration number: [880/4518] 19% | Training loss: 0.6884846548465166
Epoch: 3 | Iteration number: [890/4518] 19% | Training loss: 0.6884715213534537
Epoch: 3 | Iteration number: [900/4518] 19% | Training loss: 0.6884627205795711
Epoch: 3 | Iteration number: [910/4518] 20% | Training loss: 0.6884528005516136
Epoch: 3 | Iteration number: [920/4518] 20% | Training loss: 0.6884318408758744
Epoch: 3 | Iteration number: [930/4518] 20% | Training loss: 0.6884360844089139
Epoch: 3 | Iteration number: [940/4518] 20% | Training loss: 0.6884240698307118
Epoch: 3 | Iteration number: [950/4518] 21% | Training loss: 0.6883992281085567
Epoch: 3 | Iteration number: [960/4518] 21% | Training loss: 0.6883983559906482
Epoch: 3 | Iteration number: [970/4518] 21% | Training loss: 0.6883793308562839
Epoch: 3 | Iteration number: [980/4518] 21% | Training loss: 0.6883636669844997
Epoch: 3 | Iteration number: [990/4518] 21% | Training loss: 0.6883537160025702
Epoch: 3 | Iteration number: [1000/4518] 22% | Training loss: 0.6883459072709084
Epoch: 3 | Iteration number: [1010/4518] 22% | Training loss: 0.6883427981102821
Epoch: 3 | Iteration number: [1020/4518] 22% | Training loss: 0.6883405450512381
Epoch: 3 | Iteration number: [1030/4518] 22% | Training loss: 0.6883362908965176
Epoch: 3 | Iteration number: [1040/4518] 23% | Training loss: 0.6883350225022206
Epoch: 3 | Iteration number: [1050/4518] 23% | Training loss: 0.6883208799362183
Epoch: 3 | Iteration number: [1060/4518] 23% | Training loss: 0.688315353978355
Epoch: 3 | Iteration number: [1070/4518] 23% | Training loss: 0.6883037438459485
Epoch: 3 | Iteration number: [1080/4518] 23% | Training loss: 0.6883067418579703
Epoch: 3 | Iteration number: [1090/4518] 24% | Training loss: 0.688304521239132
Epoch: 3 | Iteration number: [1100/4518] 24% | Training loss: 0.6883052861148661
Epoch: 3 | Iteration number: [1110/4518] 24% | Training loss: 0.6882893057556839
Epoch: 3 | Iteration number: [1120/4518] 24% | Training loss: 0.6882913974778992
Epoch: 3 | Iteration number: [1130/4518] 25% | Training loss: 0.6882833890682828
Epoch: 3 | Iteration number: [1140/4518] 25% | Training loss: 0.688270730982747
Epoch: 3 | Iteration number: [1150/4518] 25% | Training loss: 0.688277260998021
Epoch: 3 | Iteration number: [1160/4518] 25% | Training loss: 0.688276927892504
Epoch: 3 | Iteration number: [1170/4518] 25% | Training loss: 0.6882859154134734
Epoch: 3 | Iteration number: [1180/4518] 26% | Training loss: 0.6882805182267043
Epoch: 3 | Iteration number: [1190/4518] 26% | Training loss: 0.688279045629902
Epoch: 3 | Iteration number: [1200/4518] 26% | Training loss: 0.6882683249314626
Epoch: 3 | Iteration number: [1210/4518] 26% | Training loss: 0.6882697593082081
Epoch: 3 | Iteration number: [1220/4518] 27% | Training loss: 0.6882732303416143
Epoch: 3 | Iteration number: [1230/4518] 27% | Training loss: 0.6882651605257174
Epoch: 3 | Iteration number: [1240/4518] 27% | Training loss: 0.688250694063402
Epoch: 3 | Iteration number: [1250/4518] 27% | Training loss: 0.6882450189113617
Epoch: 3 | Iteration number: [1260/4518] 27% | Training loss: 0.6882388992915078
Epoch: 3 | Iteration number: [1270/4518] 28% | Training loss: 0.6882331467988922
Epoch: 3 | Iteration number: [1280/4518] 28% | Training loss: 0.6882300145924092
Epoch: 3 | Iteration number: [1290/4518] 28% | Training loss: 0.6882206842418789
Epoch: 3 | Iteration number: [1300/4518] 28% | Training loss: 0.6882187890089475
Epoch: 3 | Iteration number: [1310/4518] 28% | Training loss: 0.6882093167031994
Epoch: 3 | Iteration number: [1320/4518] 29% | Training loss: 0.6882021178801855
Epoch: 3 | Iteration number: [1330/4518] 29% | Training loss: 0.6881929649894399
Epoch: 3 | Iteration number: [1340/4518] 29% | Training loss: 0.6881884816867202
Epoch: 3 | Iteration number: [1350/4518] 29% | Training loss: 0.6881798484148802
Epoch: 3 | Iteration number: [1360/4518] 30% | Training loss: 0.688173729707213
Epoch: 3 | Iteration number: [1370/4518] 30% | Training loss: 0.6881727189478213
Epoch: 3 | Iteration number: [1380/4518] 30% | Training loss: 0.6881608624821124
Epoch: 3 | Iteration number: [1390/4518] 30% | Training loss: 0.6881422549271755
Epoch: 3 | Iteration number: [1400/4518] 30% | Training loss: 0.6881339195796422
Epoch: 3 | Iteration number: [1410/4518] 31% | Training loss: 0.6881253557425019
Epoch: 3 | Iteration number: [1420/4518] 31% | Training loss: 0.6881261367613161
Epoch: 3 | Iteration number: [1430/4518] 31% | Training loss: 0.6881191018994871
Epoch: 3 | Iteration number: [1440/4518] 31% | Training loss: 0.6881215873691771
Epoch: 3 | Iteration number: [1450/4518] 32% | Training loss: 0.6881218645079382
Epoch: 3 | Iteration number: [1460/4518] 32% | Training loss: 0.6881160987566595
Epoch: 3 | Iteration number: [1470/4518] 32% | Training loss: 0.6881128210194257
Epoch: 3 | Iteration number: [1480/4518] 32% | Training loss: 0.6881064896647995
Epoch: 3 | Iteration number: [1490/4518] 32% | Training loss: 0.6881006604073031
Epoch: 3 | Iteration number: [1500/4518] 33% | Training loss: 0.6880951538483302
Epoch: 3 | Iteration number: [1510/4518] 33% | Training loss: 0.6880953885466847
Epoch: 3 | Iteration number: [1520/4518] 33% | Training loss: 0.6880856162231219
Epoch: 3 | Iteration number: [1530/4518] 33% | Training loss: 0.6880792680908652
Epoch: 3 | Iteration number: [1540/4518] 34% | Training loss: 0.6880845171677602
Epoch: 3 | Iteration number: [1550/4518] 34% | Training loss: 0.6880776393413544
Epoch: 3 | Iteration number: [1560/4518] 34% | Training loss: 0.6880648871644949
Epoch: 3 | Iteration number: [1570/4518] 34% | Training loss: 0.6880621594987857
Epoch: 3 | Iteration number: [1580/4518] 34% | Training loss: 0.6880578760104843
Epoch: 3 | Iteration number: [1590/4518] 35% | Training loss: 0.6880635391616221
Epoch: 3 | Iteration number: [1600/4518] 35% | Training loss: 0.6880655312538146
Epoch: 3 | Iteration number: [1610/4518] 35% | Training loss: 0.6880665264514663
Epoch: 3 | Iteration number: [1620/4518] 35% | Training loss: 0.6880698555781517
Epoch: 3 | Iteration number: [1630/4518] 36% | Training loss: 0.6880679924795232
Epoch: 3 | Iteration number: [1640/4518] 36% | Training loss: 0.6880676395645956
Epoch: 3 | Iteration number: [1650/4518] 36% | Training loss: 0.688063678669207
Epoch: 3 | Iteration number: [1660/4518] 36% | Training loss: 0.6880641625947262
Epoch: 3 | Iteration number: [1670/4518] 36% | Training loss: 0.6880525408747667
Epoch: 3 | Iteration number: [1680/4518] 37% | Training loss: 0.6880451751252016
Epoch: 3 | Iteration number: [1690/4518] 37% | Training loss: 0.6880422437332085
Epoch: 3 | Iteration number: [1700/4518] 37% | Training loss: 0.6880387497649473
Epoch: 3 | Iteration number: [1710/4518] 37% | Training loss: 0.6880313535531362
Epoch: 3 | Iteration number: [1720/4518] 38% | Training loss: 0.688018115176711
Epoch: 3 | Iteration number: [1730/4518] 38% | Training loss: 0.688016787154137
Epoch: 3 | Iteration number: [1740/4518] 38% | Training loss: 0.6880034873197819
Epoch: 3 | Iteration number: [1750/4518] 38% | Training loss: 0.6879979059696197
Epoch: 3 | Iteration number: [1760/4518] 38% | Training loss: 0.687996992468834
Epoch: 3 | Iteration number: [1770/4518] 39% | Training loss: 0.6879895739636179
Epoch: 3 | Iteration number: [1780/4518] 39% | Training loss: 0.6879879901248418
Epoch: 3 | Iteration number: [1790/4518] 39% | Training loss: 0.6879879754015853
Epoch: 3 | Iteration number: [1800/4518] 39% | Training loss: 0.6879912333687147
Epoch: 3 | Iteration number: [1810/4518] 40% | Training loss: 0.6879930691824434
Epoch: 3 | Iteration number: [1820/4518] 40% | Training loss: 0.6879875044573794
Epoch: 3 | Iteration number: [1830/4518] 40% | Training loss: 0.6879858350493218
Epoch: 3 | Iteration number: [1840/4518] 40% | Training loss: 0.6879828416135
Epoch: 3 | Iteration number: [1850/4518] 40% | Training loss: 0.6879756744487866
Epoch: 3 | Iteration number: [1860/4518] 41% | Training loss: 0.6879758518549703
Epoch: 3 | Iteration number: [1870/4518] 41% | Training loss: 0.6879760002069932
Epoch: 3 | Iteration number: [1880/4518] 41% | Training loss: 0.6879765420200977
Epoch: 3 | Iteration number: [1890/4518] 41% | Training loss: 0.6879702745291291
Epoch: 3 | Iteration number: [1900/4518] 42% | Training loss: 0.6879688602685928
Epoch: 3 | Iteration number: [1910/4518] 42% | Training loss: 0.6879673168921345
Epoch: 3 | Iteration number: [1920/4518] 42% | Training loss: 0.6879696345577637
Epoch: 3 | Iteration number: [1930/4518] 42% | Training loss: 0.6879648945800999
Epoch: 3 | Iteration number: [1940/4518] 42% | Training loss: 0.6879633540345221
Epoch: 3 | Iteration number: [1950/4518] 43% | Training loss: 0.6879610314430334
Epoch: 3 | Iteration number: [1960/4518] 43% | Training loss: 0.6879539240683828
Epoch: 3 | Iteration number: [1970/4518] 43% | Training loss: 0.6879613543827522
Epoch: 3 | Iteration number: [1980/4518] 43% | Training loss: 0.6879602509616601
Epoch: 3 | Iteration number: [1990/4518] 44% | Training loss: 0.687958805824644
Epoch: 3 | Iteration number: [2000/4518] 44% | Training loss: 0.6879582872092724
Epoch: 3 | Iteration number: [2010/4518] 44% | Training loss: 0.6879522783839287
Epoch: 3 | Iteration number: [2020/4518] 44% | Training loss: 0.6879538126511149
Epoch: 3 | Iteration number: [2030/4518] 44% | Training loss: 0.6879519288469418
Epoch: 3 | Iteration number: [2040/4518] 45% | Training loss: 0.6879518370125808
Epoch: 3 | Iteration number: [2050/4518] 45% | Training loss: 0.6879492310779851
Epoch: 3 | Iteration number: [2060/4518] 45% | Training loss: 0.6879490753400673
Epoch: 3 | Iteration number: [2070/4518] 45% | Training loss: 0.6879440009881909
Epoch: 3 | Iteration number: [2080/4518] 46% | Training loss: 0.6879354672936293
Epoch: 3 | Iteration number: [2090/4518] 46% | Training loss: 0.6879374859150517
Epoch: 3 | Iteration number: [2100/4518] 46% | Training loss: 0.6879344453981945
Epoch: 3 | Iteration number: [2110/4518] 46% | Training loss: 0.687933325372036
Epoch: 3 | Iteration number: [2120/4518] 46% | Training loss: 0.6879328834279528
Epoch: 3 | Iteration number: [2130/4518] 47% | Training loss: 0.6879321513041644
Epoch: 3 | Iteration number: [2140/4518] 47% | Training loss: 0.6879257012193448
Epoch: 3 | Iteration number: [2150/4518] 47% | Training loss: 0.6879195058345795
Epoch: 3 | Iteration number: [2160/4518] 47% | Training loss: 0.6879185257410562
Epoch: 3 | Iteration number: [2170/4518] 48% | Training loss: 0.6879119855742301
Epoch: 3 | Iteration number: [2180/4518] 48% | Training loss: 0.6879094048924402
Epoch: 3 | Iteration number: [2190/4518] 48% | Training loss: 0.687910160490367
Epoch: 3 | Iteration number: [2200/4518] 48% | Training loss: 0.687907175746831
Epoch: 3 | Iteration number: [2210/4518] 48% | Training loss: 0.6879060382487008
Epoch: 3 | Iteration number: [2220/4518] 49% | Training loss: 0.687900693835439
Epoch: 3 | Iteration number: [2230/4518] 49% | Training loss: 0.6879015997119015
Epoch: 3 | Iteration number: [2240/4518] 49% | Training loss: 0.6879013771191239
Epoch: 3 | Iteration number: [2250/4518] 49% | Training loss: 0.6878951717747582
Epoch: 3 | Iteration number: [2260/4518] 50% | Training loss: 0.6878977679309591
Epoch: 3 | Iteration number: [2270/4518] 50% | Training loss: 0.6878962725269637
Epoch: 3 | Iteration number: [2280/4518] 50% | Training loss: 0.6878942599683477
Epoch: 3 | Iteration number: [2290/4518] 50% | Training loss: 0.687891175184708
Epoch: 3 | Iteration number: [2300/4518] 50% | Training loss: 0.6878843606295793
Epoch: 3 | Iteration number: [2310/4518] 51% | Training loss: 0.6878808664037036
Epoch: 3 | Iteration number: [2320/4518] 51% | Training loss: 0.6878773919467268
Epoch: 3 | Iteration number: [2330/4518] 51% | Training loss: 0.687873783234363
Epoch: 3 | Iteration number: [2340/4518] 51% | Training loss: 0.6878701835361302
Epoch: 3 | Iteration number: [2350/4518] 52% | Training loss: 0.6878672079329795
Epoch: 3 | Iteration number: [2360/4518] 52% | Training loss: 0.6878646106033002
Epoch: 3 | Iteration number: [2370/4518] 52% | Training loss: 0.6878643465444508
Epoch: 3 | Iteration number: [2380/4518] 52% | Training loss: 0.6878649958291976
Epoch: 3 | Iteration number: [2390/4518] 52% | Training loss: 0.6878644123985179
Epoch: 3 | Iteration number: [2400/4518] 53% | Training loss: 0.6878686195860306
Epoch: 3 | Iteration number: [2410/4518] 53% | Training loss: 0.6878628789389282
Epoch: 3 | Iteration number: [2420/4518] 53% | Training loss: 0.6878602793640342
Epoch: 3 | Iteration number: [2430/4518] 53% | Training loss: 0.6878585759504342
Epoch: 3 | Iteration number: [2440/4518] 54% | Training loss: 0.6878589369234491
Epoch: 3 | Iteration number: [2450/4518] 54% | Training loss: 0.6878600147548987
Epoch: 3 | Iteration number: [2460/4518] 54% | Training loss: 0.6878596707330487
Epoch: 3 | Iteration number: [2470/4518] 54% | Training loss: 0.6878574453626084
Epoch: 3 | Iteration number: [2480/4518] 54% | Training loss: 0.687852496052942
Epoch: 3 | Iteration number: [2490/4518] 55% | Training loss: 0.6878533280278785
Epoch: 3 | Iteration number: [2500/4518] 55% | Training loss: 0.6878520863056183
Epoch: 3 | Iteration number: [2510/4518] 55% | Training loss: 0.6878506051116731
Epoch: 3 | Iteration number: [2520/4518] 55% | Training loss: 0.6878507946455289
Epoch: 3 | Iteration number: [2530/4518] 55% | Training loss: 0.6878455679407233
Epoch: 3 | Iteration number: [2540/4518] 56% | Training loss: 0.6878439139193437
Epoch: 3 | Iteration number: [2550/4518] 56% | Training loss: 0.6878422025605744
Epoch: 3 | Iteration number: [2560/4518] 56% | Training loss: 0.6878425403730943
Epoch: 3 | Iteration number: [2570/4518] 56% | Training loss: 0.6878379974383788
Epoch: 3 | Iteration number: [2580/4518] 57% | Training loss: 0.6878335140241209
Epoch: 3 | Iteration number: [2590/4518] 57% | Training loss: 0.6878287955830916
Epoch: 3 | Iteration number: [2600/4518] 57% | Training loss: 0.6878270895893757
Epoch: 3 | Iteration number: [2610/4518] 57% | Training loss: 0.68782799328424
Epoch: 3 | Iteration number: [2620/4518] 57% | Training loss: 0.687824482863186
Epoch: 3 | Iteration number: [2630/4518] 58% | Training loss: 0.687822988459366
Epoch: 3 | Iteration number: [2640/4518] 58% | Training loss: 0.6878224863247437
Epoch: 3 | Iteration number: [2650/4518] 58% | Training loss: 0.6878214698917461
Epoch: 3 | Iteration number: [2660/4518] 58% | Training loss: 0.6878195828289018
Epoch: 3 | Iteration number: [2670/4518] 59% | Training loss: 0.6878189803955707
Epoch: 3 | Iteration number: [2680/4518] 59% | Training loss: 0.6878146915960668
Epoch: 3 | Iteration number: [2690/4518] 59% | Training loss: 0.6878117632910221
Epoch: 3 | Iteration number: [2700/4518] 59% | Training loss: 0.6878094510458134
Epoch: 3 | Iteration number: [2710/4518] 59% | Training loss: 0.6878039268549958
Epoch: 3 | Iteration number: [2720/4518] 60% | Training loss: 0.6878025775665746
Epoch: 3 | Iteration number: [2730/4518] 60% | Training loss: 0.6878070062770075
Epoch: 3 | Iteration number: [2740/4518] 60% | Training loss: 0.687809170923964
Epoch: 3 | Iteration number: [2750/4518] 60% | Training loss: 0.687803601438349
Epoch: 3 | Iteration number: [2760/4518] 61% | Training loss: 0.6878026827305987
Epoch: 3 | Iteration number: [2770/4518] 61% | Training loss: 0.6878068548247271
Epoch: 3 | Iteration number: [2780/4518] 61% | Training loss: 0.6878055408704196
Epoch: 3 | Iteration number: [2790/4518] 61% | Training loss: 0.6878042954697832
Epoch: 3 | Iteration number: [2800/4518] 61% | Training loss: 0.687805663730417
Epoch: 3 | Iteration number: [2810/4518] 62% | Training loss: 0.687802351221071
Epoch: 3 | Iteration number: [2820/4518] 62% | Training loss: 0.6878041273735939
Epoch: 3 | Iteration number: [2830/4518] 62% | Training loss: 0.6878048697335138
Epoch: 3 | Iteration number: [2840/4518] 62% | Training loss: 0.687806434173819
Epoch: 3 | Iteration number: [2850/4518] 63% | Training loss: 0.6878096503123903
Epoch: 3 | Iteration number: [2860/4518] 63% | Training loss: 0.6878103440458124
Epoch: 3 | Iteration number: [2870/4518] 63% | Training loss: 0.6878074282553138
Epoch: 3 | Iteration number: [2880/4518] 63% | Training loss: 0.6878073796215984
Epoch: 3 | Iteration number: [2890/4518] 63% | Training loss: 0.6878038931676673
Epoch: 3 | Iteration number: [2900/4518] 64% | Training loss: 0.6878033284072218
Epoch: 3 | Iteration number: [2910/4518] 64% | Training loss: 0.6878035219059777
Epoch: 3 | Iteration number: [2920/4518] 64% | Training loss: 0.6878025009003405
Epoch: 3 | Iteration number: [2930/4518] 64% | Training loss: 0.6877983111773741
Epoch: 3 | Iteration number: [2940/4518] 65% | Training loss: 0.6877975446229079
Epoch: 3 | Iteration number: [2950/4518] 65% | Training loss: 0.6877933237108134
Epoch: 3 | Iteration number: [2960/4518] 65% | Training loss: 0.6877919544642036
Epoch: 3 | Iteration number: [2970/4518] 65% | Training loss: 0.687786830334551
Epoch: 3 | Iteration number: [2980/4518] 65% | Training loss: 0.6877850980766668
Epoch: 3 | Iteration number: [2990/4518] 66% | Training loss: 0.687785171067037
Epoch: 3 | Iteration number: [3000/4518] 66% | Training loss: 0.6877842741409937
Epoch: 3 | Iteration number: [3010/4518] 66% | Training loss: 0.6877815270146658
Epoch: 3 | Iteration number: [3020/4518] 66% | Training loss: 0.6877821790264143
Epoch: 3 | Iteration number: [3030/4518] 67% | Training loss: 0.6877773802862702
Epoch: 3 | Iteration number: [3040/4518] 67% | Training loss: 0.6877805139477315
Epoch: 3 | Iteration number: [3050/4518] 67% | Training loss: 0.6877791779940245
Epoch: 3 | Iteration number: [3060/4518] 67% | Training loss: 0.6877783838635176
Epoch: 3 | Iteration number: [3070/4518] 67% | Training loss: 0.6877786882537196
Epoch: 3 | Iteration number: [3080/4518] 68% | Training loss: 0.687772514642059
Epoch: 3 | Iteration number: [3090/4518] 68% | Training loss: 0.6877744697830052
Epoch: 3 | Iteration number: [3100/4518] 68% | Training loss: 0.6877745028465024
Epoch: 3 | Iteration number: [3110/4518] 68% | Training loss: 0.6877726372606885
Epoch: 3 | Iteration number: [3120/4518] 69% | Training loss: 0.687771354520168
Epoch: 3 | Iteration number: [3130/4518] 69% | Training loss: 0.6877726675603336
Epoch: 3 | Iteration number: [3140/4518] 69% | Training loss: 0.6877727161737005
Epoch: 3 | Iteration number: [3150/4518] 69% | Training loss: 0.6877757070556519
Epoch: 3 | Iteration number: [3160/4518] 69% | Training loss: 0.6877741735004171
Epoch: 3 | Iteration number: [3170/4518] 70% | Training loss: 0.6877738836623892
Epoch: 3 | Iteration number: [3180/4518] 70% | Training loss: 0.6877720617273319
Epoch: 3 | Iteration number: [3190/4518] 70% | Training loss: 0.6877736105066855
Epoch: 3 | Iteration number: [3200/4518] 70% | Training loss: 0.6877715179510414
Epoch: 3 | Iteration number: [3210/4518] 71% | Training loss: 0.6877705674676509
Epoch: 3 | Iteration number: [3220/4518] 71% | Training loss: 0.6877688679635895
Epoch: 3 | Iteration number: [3230/4518] 71% | Training loss: 0.6877644432956589
Epoch: 3 | Iteration number: [3240/4518] 71% | Training loss: 0.6877622400536949
Epoch: 3 | Iteration number: [3250/4518] 71% | Training loss: 0.6877588316110465
Epoch: 3 | Iteration number: [3260/4518] 72% | Training loss: 0.6877565850692293
Epoch: 3 | Iteration number: [3270/4518] 72% | Training loss: 0.6877568328052486
Epoch: 3 | Iteration number: [3280/4518] 72% | Training loss: 0.6877532123792462
Epoch: 3 | Iteration number: [3290/4518] 72% | Training loss: 0.6877546321657291
Epoch: 3 | Iteration number: [3300/4518] 73% | Training loss: 0.6877536540501046
Epoch: 3 | Iteration number: [3310/4518] 73% | Training loss: 0.6877534312964206
Epoch: 3 | Iteration number: [3320/4518] 73% | Training loss: 0.6877525019717504
Epoch: 3 | Iteration number: [3330/4518] 73% | Training loss: 0.6877506608719582
Epoch: 3 | Iteration number: [3340/4518] 73% | Training loss: 0.6877492440139462
Epoch: 3 | Iteration number: [3350/4518] 74% | Training loss: 0.687751923230157
Epoch: 3 | Iteration number: [3360/4518] 74% | Training loss: 0.6877471162627141
Epoch: 3 | Iteration number: [3370/4518] 74% | Training loss: 0.6877477513753342
Epoch: 3 | Iteration number: [3380/4518] 74% | Training loss: 0.6877483744945752
Epoch: 3 | Iteration number: [3390/4518] 75% | Training loss: 0.6877492529628552
Epoch: 3 | Iteration number: [3400/4518] 75% | Training loss: 0.6877466550644706
Epoch: 3 | Iteration number: [3410/4518] 75% | Training loss: 0.6877460397058918
Epoch: 3 | Iteration number: [3420/4518] 75% | Training loss: 0.6877458293012708
Epoch: 3 | Iteration number: [3430/4518] 75% | Training loss: 0.6877456763742964
Epoch: 3 | Iteration number: [3440/4518] 76% | Training loss: 0.6877475320946339
Epoch: 3 | Iteration number: [3450/4518] 76% | Training loss: 0.6877467752712361
Epoch: 3 | Iteration number: [3460/4518] 76% | Training loss: 0.6877427374351921
Epoch: 3 | Iteration number: [3470/4518] 76% | Training loss: 0.6877407616771951
Epoch: 3 | Iteration number: [3480/4518] 77% | Training loss: 0.6877395946746585
Epoch: 3 | Iteration number: [3490/4518] 77% | Training loss: 0.6877395772489914
Epoch: 3 | Iteration number: [3500/4518] 77% | Training loss: 0.6877392597709383
Epoch: 3 | Iteration number: [3510/4518] 77% | Training loss: 0.6877364677411538
Epoch: 3 | Iteration number: [3520/4518] 77% | Training loss: 0.6877344162288037
Epoch: 3 | Iteration number: [3530/4518] 78% | Training loss: 0.6877343403043558
Epoch: 3 | Iteration number: [3540/4518] 78% | Training loss: 0.6877337449519648
Epoch: 3 | Iteration number: [3550/4518] 78% | Training loss: 0.6877318320307934
Epoch: 3 | Iteration number: [3560/4518] 78% | Training loss: 0.6877328634262085
Epoch: 3 | Iteration number: [3570/4518] 79% | Training loss: 0.6877347081482243
Epoch: 3 | Iteration number: [3580/4518] 79% | Training loss: 0.6877343490303561
Epoch: 3 | Iteration number: [3590/4518] 79% | Training loss: 0.6877341718228747
Epoch: 3 | Iteration number: [3600/4518] 79% | Training loss: 0.6877343800001674
Epoch: 3 | Iteration number: [3610/4518] 79% | Training loss: 0.6877325997128051
Epoch: 3 | Iteration number: [3620/4518] 80% | Training loss: 0.6877298063336157
Epoch: 3 | Iteration number: [3630/4518] 80% | Training loss: 0.6877292245872749
Epoch: 3 | Iteration number: [3640/4518] 80% | Training loss: 0.6877237387083389
Epoch: 3 | Iteration number: [3650/4518] 80% | Training loss: 0.6877211948616864
Epoch: 3 | Iteration number: [3660/4518] 81% | Training loss: 0.6877201110124588
Epoch: 3 | Iteration number: [3670/4518] 81% | Training loss: 0.6877177709941968
Epoch: 3 | Iteration number: [3680/4518] 81% | Training loss: 0.6877181411275397
Epoch: 3 | Iteration number: [3690/4518] 81% | Training loss: 0.6877171472643772
Epoch: 3 | Iteration number: [3700/4518] 81% | Training loss: 0.6877152988395175
Epoch: 3 | Iteration number: [3710/4518] 82% | Training loss: 0.6877147422003939
Epoch: 3 | Iteration number: [3720/4518] 82% | Training loss: 0.6877139755634851
Epoch: 3 | Iteration number: [3730/4518] 82% | Training loss: 0.6877118460294708
Epoch: 3 | Iteration number: [3740/4518] 82% | Training loss: 0.6877101533553179
Epoch: 3 | Iteration number: [3750/4518] 83% | Training loss: 0.687710046339035
Epoch: 3 | Iteration number: [3760/4518] 83% | Training loss: 0.6877073637190018
Epoch: 3 | Iteration number: [3770/4518] 83% | Training loss: 0.6877089747541463
Epoch: 3 | Iteration number: [3780/4518] 83% | Training loss: 0.6877074138039634
Epoch: 3 | Iteration number: [3790/4518] 83% | Training loss: 0.6877069421997171
Epoch: 3 | Iteration number: [3800/4518] 84% | Training loss: 0.6877076155260989
Epoch: 3 | Iteration number: [3810/4518] 84% | Training loss: 0.6877047169865586
Epoch: 3 | Iteration number: [3820/4518] 84% | Training loss: 0.6877023233793169
Epoch: 3 | Iteration number: [3830/4518] 84% | Training loss: 0.6876989846129953
Epoch: 3 | Iteration number: [3840/4518] 84% | Training loss: 0.6877000947017222
Epoch: 3 | Iteration number: [3850/4518] 85% | Training loss: 0.6876966576607196
Epoch: 3 | Iteration number: [3860/4518] 85% | Training loss: 0.687696753017643
Epoch: 3 | Iteration number: [3870/4518] 85% | Training loss: 0.6876950460965011
Epoch: 3 | Iteration number: [3880/4518] 85% | Training loss: 0.6876923498726383
Epoch: 3 | Iteration number: [3890/4518] 86% | Training loss: 0.6876928652926398
Epoch: 3 | Iteration number: [3900/4518] 86% | Training loss: 0.6876928426516362
Epoch: 3 | Iteration number: [3910/4518] 86% | Training loss: 0.6876913381354584
Epoch: 3 | Iteration number: [3920/4518] 86% | Training loss: 0.6876888233027896
Epoch: 3 | Iteration number: [3930/4518] 86% | Training loss: 0.6876858686521157
Epoch: 3 | Iteration number: [3940/4518] 87% | Training loss: 0.6876849951780387
Epoch: 3 | Iteration number: [3950/4518] 87% | Training loss: 0.6876843438269217
Epoch: 3 | Iteration number: [3960/4518] 87% | Training loss: 0.68768398849049
Epoch: 3 | Iteration number: [3970/4518] 87% | Training loss: 0.6876863102618633
Epoch: 3 | Iteration number: [3980/4518] 88% | Training loss: 0.6876838116040781
Epoch: 3 | Iteration number: [3990/4518] 88% | Training loss: 0.6876847905174532
Epoch: 3 | Iteration number: [4000/4518] 88% | Training loss: 0.6876842027008534
Epoch: 3 | Iteration number: [4010/4518] 88% | Training loss: 0.6876823326001441
Epoch: 3 | Iteration number: [4020/4518] 88% | Training loss: 0.6876788213626662
Epoch: 3 | Iteration number: [4030/4518] 89% | Training loss: 0.6876801533231665
Epoch: 3 | Iteration number: [4040/4518] 89% | Training loss: 0.6876799206775014
Epoch: 3 | Iteration number: [4050/4518] 89% | Training loss: 0.6876820719242096
Epoch: 3 | Iteration number: [4060/4518] 89% | Training loss: 0.6876798381799547
Epoch: 3 | Iteration number: [4070/4518] 90% | Training loss: 0.6876780572043004
Epoch: 3 | Iteration number: [4080/4518] 90% | Training loss: 0.6876789109963997
Epoch: 3 | Iteration number: [4090/4518] 90% | Training loss: 0.6876802461362993
Epoch: 3 | Iteration number: [4100/4518] 90% | Training loss: 0.6876799731138276
Epoch: 3 | Iteration number: [4110/4518] 90% | Training loss: 0.6876811222293371
Epoch: 3 | Iteration number: [4120/4518] 91% | Training loss: 0.6876764868214292
Epoch: 3 | Iteration number: [4130/4518] 91% | Training loss: 0.6876744277107802
Epoch: 3 | Iteration number: [4140/4518] 91% | Training loss: 0.6876716026217465
Epoch: 3 | Iteration number: [4150/4518] 91% | Training loss: 0.6876730501077262
Epoch: 3 | Iteration number: [4160/4518] 92% | Training loss: 0.6876734872850088
Epoch: 3 | Iteration number: [4170/4518] 92% | Training loss: 0.687671294172319
Epoch: 3 | Iteration number: [4180/4518] 92% | Training loss: 0.6876724840208674
Epoch: 3 | Iteration number: [4190/4518] 92% | Training loss: 0.6876717797327155
Epoch: 3 | Iteration number: [4200/4518] 92% | Training loss: 0.6876726560081754
Epoch: 3 | Iteration number: [4210/4518] 93% | Training loss: 0.6876715233376927
Epoch: 3 | Iteration number: [4220/4518] 93% | Training loss: 0.6876714573369772
Epoch: 3 | Iteration number: [4230/4518] 93% | Training loss: 0.6876735003000174
Epoch: 3 | Iteration number: [4240/4518] 93% | Training loss: 0.6876690519024741
Epoch: 3 | Iteration number: [4250/4518] 94% | Training loss: 0.6876695303776685
Epoch: 3 | Iteration number: [4260/4518] 94% | Training loss: 0.6876709023551761
Epoch: 3 | Iteration number: [4270/4518] 94% | Training loss: 0.687673306869958
Epoch: 3 | Iteration number: [4280/4518] 94% | Training loss: 0.6876736609317432
Epoch: 3 | Iteration number: [4290/4518] 94% | Training loss: 0.6876725065680372
Epoch: 3 | Iteration number: [4300/4518] 95% | Training loss: 0.6876714501131412
Epoch: 3 | Iteration number: [4310/4518] 95% | Training loss: 0.6876717524987639
Epoch: 3 | Iteration number: [4320/4518] 95% | Training loss: 0.6876687235164421
Epoch: 3 | Iteration number: [4330/4518] 95% | Training loss: 0.6876683876641078
Epoch: 3 | Iteration number: [4340/4518] 96% | Training loss: 0.6876676788115831
Epoch: 3 | Iteration number: [4350/4518] 96% | Training loss: 0.6876668025707376
Epoch: 3 | Iteration number: [4360/4518] 96% | Training loss: 0.6876646860750444
Epoch: 3 | Iteration number: [4370/4518] 96% | Training loss: 0.6876623751915292
Epoch: 3 | Iteration number: [4380/4518] 96% | Training loss: 0.6876628880903601
Epoch: 3 | Iteration number: [4390/4518] 97% | Training loss: 0.6876615954287232
Epoch: 3 | Iteration number: [4400/4518] 97% | Training loss: 0.6876609402353113
Epoch: 3 | Iteration number: [4410/4518] 97% | Training loss: 0.6876601868070442
Epoch: 3 | Iteration number: [4420/4518] 97% | Training loss: 0.6876618669583248
Epoch: 3 | Iteration number: [4430/4518] 98% | Training loss: 0.6876628210259345
Epoch: 3 | Iteration number: [4440/4518] 98% | Training loss: 0.6876633570537911
Epoch: 3 | Iteration number: [4450/4518] 98% | Training loss: 0.6876601718248946
Epoch: 3 | Iteration number: [4460/4518] 98% | Training loss: 0.6876626439826905
Epoch: 3 | Iteration number: [4470/4518] 98% | Training loss: 0.6876635320767993
Epoch: 3 | Iteration number: [4480/4518] 99% | Training loss: 0.6876613861748151
Epoch: 3 | Iteration number: [4490/4518] 99% | Training loss: 0.687660403732202
Epoch: 3 | Iteration number: [4500/4518] 99% | Training loss: 0.687660099307696
Epoch: 3 | Iteration number: [4510/4518] 99% | Training loss: 0.6876617797065997

 End of epoch: 3 | Train Loss: 0.6875088976884954 | Training Time: 641 

 End of epoch: 3 | Eval Loss: 0.6903900333813259 | Evaluating Time: 17 
Epoch: 4 | Iteration number: [10/4518] 0% | Training loss: 0.7550194740295411
Epoch: 4 | Iteration number: [20/4518] 0% | Training loss: 0.72167928814888
Epoch: 4 | Iteration number: [30/4518] 0% | Training loss: 0.7101759095986684
Epoch: 4 | Iteration number: [40/4518] 0% | Training loss: 0.7044435605406761
Epoch: 4 | Iteration number: [50/4518] 1% | Training loss: 0.7011996674537658
Epoch: 4 | Iteration number: [60/4518] 1% | Training loss: 0.6988554616769155
Epoch: 4 | Iteration number: [70/4518] 1% | Training loss: 0.6971484925065722
Epoch: 4 | Iteration number: [80/4518] 1% | Training loss: 0.6957792334258557
Epoch: 4 | Iteration number: [90/4518] 1% | Training loss: 0.6949039671156142
Epoch: 4 | Iteration number: [100/4518] 2% | Training loss: 0.6942326259613038
Epoch: 4 | Iteration number: [110/4518] 2% | Training loss: 0.6935629384084181
Epoch: 4 | Iteration number: [120/4518] 2% | Training loss: 0.6930922364195188
Epoch: 4 | Iteration number: [130/4518] 2% | Training loss: 0.6926339218249687
Epoch: 4 | Iteration number: [140/4518] 3% | Training loss: 0.6922392053263527
Epoch: 4 | Iteration number: [150/4518] 3% | Training loss: 0.6919237856070201
Epoch: 4 | Iteration number: [160/4518] 3% | Training loss: 0.6916767608374357
Epoch: 4 | Iteration number: [170/4518] 3% | Training loss: 0.6914490016067729
Epoch: 4 | Iteration number: [180/4518] 3% | Training loss: 0.6911802404456668
Epoch: 4 | Iteration number: [190/4518] 4% | Training loss: 0.6910027817675942
Epoch: 4 | Iteration number: [200/4518] 4% | Training loss: 0.6908230301737786
Epoch: 4 | Iteration number: [210/4518] 4% | Training loss: 0.6906520656176975
Epoch: 4 | Iteration number: [220/4518] 4% | Training loss: 0.6905009063807401
Epoch: 4 | Iteration number: [230/4518] 5% | Training loss: 0.6903815515663313
Epoch: 4 | Iteration number: [240/4518] 5% | Training loss: 0.6902330592274666
Epoch: 4 | Iteration number: [250/4518] 5% | Training loss: 0.6900803594589233
Epoch: 4 | Iteration number: [260/4518] 5% | Training loss: 0.689964206631367
Epoch: 4 | Iteration number: [270/4518] 5% | Training loss: 0.6898580910982909
Epoch: 4 | Iteration number: [280/4518] 6% | Training loss: 0.6897758447698185
Epoch: 4 | Iteration number: [290/4518] 6% | Training loss: 0.6897245941490963
Epoch: 4 | Iteration number: [300/4518] 6% | Training loss: 0.6896725908915202
Epoch: 4 | Iteration number: [310/4518] 6% | Training loss: 0.6895820727271419
Epoch: 4 | Iteration number: [320/4518] 7% | Training loss: 0.6895182296633721
Epoch: 4 | Iteration number: [330/4518] 7% | Training loss: 0.6894551562540459
Epoch: 4 | Iteration number: [340/4518] 7% | Training loss: 0.6893674449009054
Epoch: 4 | Iteration number: [350/4518] 7% | Training loss: 0.6892992012841361
Epoch: 4 | Iteration number: [360/4518] 7% | Training loss: 0.6891979477471776
Epoch: 4 | Iteration number: [370/4518] 8% | Training loss: 0.6891425433996562
Epoch: 4 | Iteration number: [380/4518] 8% | Training loss: 0.6890895391765394
Epoch: 4 | Iteration number: [390/4518] 8% | Training loss: 0.6890645931928586
Epoch: 4 | Iteration number: [400/4518] 8% | Training loss: 0.6890032321214676
Epoch: 4 | Iteration number: [410/4518] 9% | Training loss: 0.6889798042250843
Epoch: 4 | Iteration number: [420/4518] 9% | Training loss: 0.6889537675040108
Epoch: 4 | Iteration number: [430/4518] 9% | Training loss: 0.6889484244723653
Epoch: 4 | Iteration number: [440/4518] 9% | Training loss: 0.6889210283756256
Epoch: 4 | Iteration number: [450/4518] 9% | Training loss: 0.6888819771342808
Epoch: 4 | Iteration number: [460/4518] 10% | Training loss: 0.6888517462688943
Epoch: 4 | Iteration number: [470/4518] 10% | Training loss: 0.6888356878402385
Epoch: 4 | Iteration number: [480/4518] 10% | Training loss: 0.6887773629277945
Epoch: 4 | Iteration number: [490/4518] 10% | Training loss: 0.6887541845136759
Epoch: 4 | Iteration number: [500/4518] 11% | Training loss: 0.6887287055253982
Epoch: 4 | Iteration number: [510/4518] 11% | Training loss: 0.688720677763808
Epoch: 4 | Iteration number: [520/4518] 11% | Training loss: 0.6886790107075985
Epoch: 4 | Iteration number: [530/4518] 11% | Training loss: 0.6886433527154743
Epoch: 4 | Iteration number: [540/4518] 11% | Training loss: 0.6886074164399394
Epoch: 4 | Iteration number: [550/4518] 12% | Training loss: 0.6885965543443506
Epoch: 4 | Iteration number: [560/4518] 12% | Training loss: 0.6885691179760864
Epoch: 4 | Iteration number: [570/4518] 12% | Training loss: 0.6885446961511645
Epoch: 4 | Iteration number: [580/4518] 12% | Training loss: 0.6885342823020343
Epoch: 4 | Iteration number: [590/4518] 13% | Training loss: 0.6885052857762676
Epoch: 4 | Iteration number: [600/4518] 13% | Training loss: 0.6884758521119754
Epoch: 4 | Iteration number: [610/4518] 13% | Training loss: 0.6884659617650705
Epoch: 4 | Iteration number: [620/4518] 13% | Training loss: 0.6884421708122377
Epoch: 4 | Iteration number: [630/4518] 13% | Training loss: 0.6884086158540513
Epoch: 4 | Iteration number: [640/4518] 14% | Training loss: 0.688397818338126
Epoch: 4 | Iteration number: [650/4518] 14% | Training loss: 0.6883818498941568
Epoch: 4 | Iteration number: [660/4518] 14% | Training loss: 0.6883610235922264
Epoch: 4 | Iteration number: [670/4518] 14% | Training loss: 0.6883521667167322
Epoch: 4 | Iteration number: [680/4518] 15% | Training loss: 0.6883480157922296
Epoch: 4 | Iteration number: [690/4518] 15% | Training loss: 0.6883263710616292
Epoch: 4 | Iteration number: [700/4518] 15% | Training loss: 0.6883185552699226
Epoch: 4 | Iteration number: [710/4518] 15% | Training loss: 0.6882976780475025
Epoch: 4 | Iteration number: [720/4518] 15% | Training loss: 0.6882981615761916
Epoch: 4 | Iteration number: [730/4518] 16% | Training loss: 0.6882897894676417
Epoch: 4 | Iteration number: [740/4518] 16% | Training loss: 0.688286142252587
Epoch: 4 | Iteration number: [750/4518] 16% | Training loss: 0.6882863672574361
Epoch: 4 | Iteration number: [760/4518] 16% | Training loss: 0.6882832058166203
Epoch: 4 | Iteration number: [770/4518] 17% | Training loss: 0.6882667960284592
Epoch: 4 | Iteration number: [780/4518] 17% | Training loss: 0.6882421045731275
Epoch: 4 | Iteration number: [790/4518] 17% | Training loss: 0.688245549156696
Epoch: 4 | Iteration number: [800/4518] 17% | Training loss: 0.6882405497133732
Epoch: 4 | Iteration number: [810/4518] 17% | Training loss: 0.6882330218215048
Epoch: 4 | Iteration number: [820/4518] 18% | Training loss: 0.6882303469064759
Epoch: 4 | Iteration number: [830/4518] 18% | Training loss: 0.6882228910923004
Epoch: 4 | Iteration number: [840/4518] 18% | Training loss: 0.68820674320062
Epoch: 4 | Iteration number: [850/4518] 18% | Training loss: 0.6882098610962138
Epoch: 4 | Iteration number: [860/4518] 19% | Training loss: 0.6881882636353027
Epoch: 4 | Iteration number: [870/4518] 19% | Training loss: 0.6881853098156808
Epoch: 4 | Iteration number: [880/4518] 19% | Training loss: 0.6881625959141688
Epoch: 4 | Iteration number: [890/4518] 19% | Training loss: 0.6881509139296714
Epoch: 4 | Iteration number: [900/4518] 19% | Training loss: 0.6881591324673758
Epoch: 4 | Iteration number: [910/4518] 20% | Training loss: 0.6881523294108255
Epoch: 4 | Iteration number: [920/4518] 20% | Training loss: 0.6881480073151381
Epoch: 4 | Iteration number: [930/4518] 20% | Training loss: 0.6881420237402762
Epoch: 4 | Iteration number: [940/4518] 20% | Training loss: 0.688127431146642
Epoch: 4 | Iteration number: [950/4518] 21% | Training loss: 0.6881290322228482
Epoch: 4 | Iteration number: [960/4518] 21% | Training loss: 0.6881195787340403
Epoch: 4 | Iteration number: [970/4518] 21% | Training loss: 0.6881056525658087
Epoch: 4 | Iteration number: [980/4518] 21% | Training loss: 0.6881015374344223
Epoch: 4 | Iteration number: [990/4518] 21% | Training loss: 0.6881020331623579
Epoch: 4 | Iteration number: [1000/4518] 22% | Training loss: 0.6880989673733712
Epoch: 4 | Iteration number: [1010/4518] 22% | Training loss: 0.6880894452628523
Epoch: 4 | Iteration number: [1020/4518] 22% | Training loss: 0.6880867775748758
Epoch: 4 | Iteration number: [1030/4518] 22% | Training loss: 0.6880823023689603
Epoch: 4 | Iteration number: [1040/4518] 23% | Training loss: 0.6880768437225085
Epoch: 4 | Iteration number: [1050/4518] 23% | Training loss: 0.688069585164388
Epoch: 4 | Iteration number: [1060/4518] 23% | Training loss: 0.6880619129482305
Epoch: 4 | Iteration number: [1070/4518] 23% | Training loss: 0.6880662173868339
Epoch: 4 | Iteration number: [1080/4518] 23% | Training loss: 0.6880549568820883
Epoch: 4 | Iteration number: [1090/4518] 24% | Training loss: 0.6880480002372636
Epoch: 4 | Iteration number: [1100/4518] 24% | Training loss: 0.6880392644622109
Epoch: 4 | Iteration number: [1110/4518] 24% | Training loss: 0.6880432630981411
Epoch: 4 | Iteration number: [1120/4518] 24% | Training loss: 0.6880241457905089
Epoch: 4 | Iteration number: [1130/4518] 25% | Training loss: 0.688014771875027
Epoch: 4 | Iteration number: [1140/4518] 25% | Training loss: 0.6880044912559944
Epoch: 4 | Iteration number: [1150/4518] 25% | Training loss: 0.6879891576455986
Epoch: 4 | Iteration number: [1160/4518] 25% | Training loss: 0.6879917649873372
Epoch: 4 | Iteration number: [1170/4518] 25% | Training loss: 0.6879947187554123
Epoch: 4 | Iteration number: [1180/4518] 26% | Training loss: 0.6879793915708187
Epoch: 4 | Iteration number: [1190/4518] 26% | Training loss: 0.6879828487123761
Epoch: 4 | Iteration number: [1200/4518] 26% | Training loss: 0.6879868473609289
Epoch: 4 | Iteration number: [1210/4518] 26% | Training loss: 0.6879786389425766
Epoch: 4 | Iteration number: [1220/4518] 27% | Training loss: 0.6879635052114237
Epoch: 4 | Iteration number: [1230/4518] 27% | Training loss: 0.6879521829325979
Epoch: 4 | Iteration number: [1240/4518] 27% | Training loss: 0.6879476030988078
Epoch: 4 | Iteration number: [1250/4518] 27% | Training loss: 0.6879336763858795
Epoch: 4 | Iteration number: [1260/4518] 27% | Training loss: 0.6879305248695706
Epoch: 4 | Iteration number: [1270/4518] 28% | Training loss: 0.6879173667881433
Epoch: 4 | Iteration number: [1280/4518] 28% | Training loss: 0.6879153459332883
Epoch: 4 | Iteration number: [1290/4518] 28% | Training loss: 0.6879122909187346
Epoch: 4 | Iteration number: [1300/4518] 28% | Training loss: 0.6879038692437686
Epoch: 4 | Iteration number: [1310/4518] 28% | Training loss: 0.6878964619782135
Epoch: 4 | Iteration number: [1320/4518] 29% | Training loss: 0.6878929829507163
Epoch: 4 | Iteration number: [1330/4518] 29% | Training loss: 0.6878868750611642
Epoch: 4 | Iteration number: [1340/4518] 29% | Training loss: 0.6878828054043784
Epoch: 4 | Iteration number: [1350/4518] 29% | Training loss: 0.6878714547333894
Epoch: 4 | Iteration number: [1360/4518] 30% | Training loss: 0.6878676622667733
Epoch: 4 | Iteration number: [1370/4518] 30% | Training loss: 0.6878692453795106
Epoch: 4 | Iteration number: [1380/4518] 30% | Training loss: 0.687878114848897
Epoch: 4 | Iteration number: [1390/4518] 30% | Training loss: 0.6878742110814979
Epoch: 4 | Iteration number: [1400/4518] 30% | Training loss: 0.6878729249749865
Epoch: 4 | Iteration number: [1410/4518] 31% | Training loss: 0.6878645896488893
Epoch: 4 | Iteration number: [1420/4518] 31% | Training loss: 0.6878571034737037
Epoch: 4 | Iteration number: [1430/4518] 31% | Training loss: 0.6878600433156207
Epoch: 4 | Iteration number: [1440/4518] 31% | Training loss: 0.6878551195893022
Epoch: 4 | Iteration number: [1450/4518] 32% | Training loss: 0.6878519195523756
Epoch: 4 | Iteration number: [1460/4518] 32% | Training loss: 0.6878443694277986
Epoch: 4 | Iteration number: [1470/4518] 32% | Training loss: 0.6878320171314032
Epoch: 4 | Iteration number: [1480/4518] 32% | Training loss: 0.6878288621435295
Epoch: 4 | Iteration number: [1490/4518] 32% | Training loss: 0.6878277687018349
Epoch: 4 | Iteration number: [1500/4518] 33% | Training loss: 0.6878217538992564
Epoch: 4 | Iteration number: [1510/4518] 33% | Training loss: 0.6878230433195632
Epoch: 4 | Iteration number: [1520/4518] 33% | Training loss: 0.6878238374857526
Epoch: 4 | Iteration number: [1530/4518] 33% | Training loss: 0.6878229927393346
Epoch: 4 | Iteration number: [1540/4518] 34% | Training loss: 0.6878177864210946
Epoch: 4 | Iteration number: [1550/4518] 34% | Training loss: 0.6878204344549487
Epoch: 4 | Iteration number: [1560/4518] 34% | Training loss: 0.6878160327672959
Epoch: 4 | Iteration number: [1570/4518] 34% | Training loss: 0.6878094853109615
Epoch: 4 | Iteration number: [1580/4518] 34% | Training loss: 0.687810688984545
Epoch: 4 | Iteration number: [1590/4518] 35% | Training loss: 0.6878134185038273
Epoch: 4 | Iteration number: [1600/4518] 35% | Training loss: 0.6878078852966428
Epoch: 4 | Iteration number: [1610/4518] 35% | Training loss: 0.6877999835873243
Epoch: 4 | Iteration number: [1620/4518] 35% | Training loss: 0.6877941091855367
Epoch: 4 | Iteration number: [1630/4518] 36% | Training loss: 0.6877863215888205
Epoch: 4 | Iteration number: [1640/4518] 36% | Training loss: 0.6877860819784606
Epoch: 4 | Iteration number: [1650/4518] 36% | Training loss: 0.6877794134255611
Epoch: 4 | Iteration number: [1660/4518] 36% | Training loss: 0.6877768819231584
Epoch: 4 | Iteration number: [1670/4518] 36% | Training loss: 0.6877759862088871
Epoch: 4 | Iteration number: [1680/4518] 37% | Training loss: 0.6877625108829566
Epoch: 4 | Iteration number: [1690/4518] 37% | Training loss: 0.6877560632115991
Epoch: 4 | Iteration number: [1700/4518] 37% | Training loss: 0.6877607900254866
Epoch: 4 | Iteration number: [1710/4518] 37% | Training loss: 0.6877571390037648
Epoch: 4 | Iteration number: [1720/4518] 38% | Training loss: 0.6877576336957688
Epoch: 4 | Iteration number: [1730/4518] 38% | Training loss: 0.6877558339882448
Epoch: 4 | Iteration number: [1740/4518] 38% | Training loss: 0.6877549759957983
Epoch: 4 | Iteration number: [1750/4518] 38% | Training loss: 0.6877538234506334
Epoch: 4 | Iteration number: [1760/4518] 38% | Training loss: 0.6877567159181291
Epoch: 4 | Iteration number: [1770/4518] 39% | Training loss: 0.6877580946784908
Epoch: 4 | Iteration number: [1780/4518] 39% | Training loss: 0.687756088275588
Epoch: 4 | Iteration number: [1790/4518] 39% | Training loss: 0.6877526770756898
Epoch: 4 | Iteration number: [1800/4518] 39% | Training loss: 0.6877560507588917
Epoch: 4 | Iteration number: [1810/4518] 40% | Training loss: 0.6877509841932118
Epoch: 4 | Iteration number: [1820/4518] 40% | Training loss: 0.6877566203638747
Epoch: 4 | Iteration number: [1830/4518] 40% | Training loss: 0.6877553858066517
Epoch: 4 | Iteration number: [1840/4518] 40% | Training loss: 0.6877475031368111
Epoch: 4 | Iteration number: [1850/4518] 40% | Training loss: 0.6877476022050187
Epoch: 4 | Iteration number: [1860/4518] 41% | Training loss: 0.687742773371358
Epoch: 4 | Iteration number: [1870/4518] 41% | Training loss: 0.6877425997014989
Epoch: 4 | Iteration number: [1880/4518] 41% | Training loss: 0.6877373651304144
Epoch: 4 | Iteration number: [1890/4518] 41% | Training loss: 0.6877370826466374
Epoch: 4 | Iteration number: [1900/4518] 42% | Training loss: 0.6877342851538407
Epoch: 4 | Iteration number: [1910/4518] 42% | Training loss: 0.6877346150225994
Epoch: 4 | Iteration number: [1920/4518] 42% | Training loss: 0.6877339301320414
Epoch: 4 | Iteration number: [1930/4518] 42% | Training loss: 0.6877323228151687
Epoch: 4 | Iteration number: [1940/4518] 42% | Training loss: 0.6877284777840388
Epoch: 4 | Iteration number: [1950/4518] 43% | Training loss: 0.6877274591800494
Epoch: 4 | Iteration number: [1960/4518] 43% | Training loss: 0.6877256471587687
Epoch: 4 | Iteration number: [1970/4518] 43% | Training loss: 0.6877188990866472
Epoch: 4 | Iteration number: [1980/4518] 43% | Training loss: 0.6877179616629475
Epoch: 4 | Iteration number: [1990/4518] 44% | Training loss: 0.6877162242954101
Epoch: 4 | Iteration number: [2000/4518] 44% | Training loss: 0.6877164490818978
Epoch: 4 | Iteration number: [2010/4518] 44% | Training loss: 0.6877139226417637
Epoch: 4 | Iteration number: [2020/4518] 44% | Training loss: 0.6877179149944004
Epoch: 4 | Iteration number: [2030/4518] 44% | Training loss: 0.6877205435278381
Epoch: 4 | Iteration number: [2040/4518] 45% | Training loss: 0.6877213235871464
Epoch: 4 | Iteration number: [2050/4518] 45% | Training loss: 0.6877188021380727
Epoch: 4 | Iteration number: [2060/4518] 45% | Training loss: 0.687711261719176
Epoch: 4 | Iteration number: [2070/4518] 45% | Training loss: 0.6877078951844846
Epoch: 4 | Iteration number: [2080/4518] 46% | Training loss: 0.6877019114505786
Epoch: 4 | Iteration number: [2090/4518] 46% | Training loss: 0.6877006004586744
Epoch: 4 | Iteration number: [2100/4518] 46% | Training loss: 0.687694531253406
Epoch: 4 | Iteration number: [2110/4518] 46% | Training loss: 0.687695261708933
Epoch: 4 | Iteration number: [2120/4518] 46% | Training loss: 0.6876937112437105
Epoch: 4 | Iteration number: [2130/4518] 47% | Training loss: 0.6876961444745041
Epoch: 4 | Iteration number: [2140/4518] 47% | Training loss: 0.6876912870139719
Epoch: 4 | Iteration number: [2150/4518] 47% | Training loss: 0.6876896627004756
Epoch: 4 | Iteration number: [2160/4518] 47% | Training loss: 0.6876899514761236
Epoch: 4 | Iteration number: [2170/4518] 48% | Training loss: 0.6876867810427318
Epoch: 4 | Iteration number: [2180/4518] 48% | Training loss: 0.6876828812131094
Epoch: 4 | Iteration number: [2190/4518] 48% | Training loss: 0.6876779087874443
Epoch: 4 | Iteration number: [2200/4518] 48% | Training loss: 0.6876730385422707
Epoch: 4 | Iteration number: [2210/4518] 48% | Training loss: 0.6876744891723356
Epoch: 4 | Iteration number: [2220/4518] 49% | Training loss: 0.6876736929556271
Epoch: 4 | Iteration number: [2230/4518] 49% | Training loss: 0.6876753388498931
Epoch: 4 | Iteration number: [2240/4518] 49% | Training loss: 0.6876799116177218
Epoch: 4 | Iteration number: [2250/4518] 49% | Training loss: 0.6876783203283946
Epoch: 4 | Iteration number: [2260/4518] 50% | Training loss: 0.6876709728114373
Epoch: 4 | Iteration number: [2270/4518] 50% | Training loss: 0.6876655074730844
Epoch: 4 | Iteration number: [2280/4518] 50% | Training loss: 0.6876613680207938
Epoch: 4 | Iteration number: [2290/4518] 50% | Training loss: 0.6876604885773888
Epoch: 4 | Iteration number: [2300/4518] 50% | Training loss: 0.6876608497681825
Epoch: 4 | Iteration number: [2310/4518] 51% | Training loss: 0.687654593625626
Epoch: 4 | Iteration number: [2320/4518] 51% | Training loss: 0.6876465232464773
Epoch: 4 | Iteration number: [2330/4518] 51% | Training loss: 0.6876457910425161
Epoch: 4 | Iteration number: [2340/4518] 51% | Training loss: 0.6876445031828351
Epoch: 4 | Iteration number: [2350/4518] 52% | Training loss: 0.6876398636686041
Epoch: 4 | Iteration number: [2360/4518] 52% | Training loss: 0.6876373540546934
Epoch: 4 | Iteration number: [2370/4518] 52% | Training loss: 0.6876367228695109
Epoch: 4 | Iteration number: [2380/4518] 52% | Training loss: 0.6876309895966234
Epoch: 4 | Iteration number: [2390/4518] 52% | Training loss: 0.6876341982366649
Epoch: 4 | Iteration number: [2400/4518] 53% | Training loss: 0.687632288535436
Epoch: 4 | Iteration number: [2410/4518] 53% | Training loss: 0.6876283519742894
Epoch: 4 | Iteration number: [2420/4518] 53% | Training loss: 0.6876289568903032
Epoch: 4 | Iteration number: [2430/4518] 53% | Training loss: 0.6876264447292674
Epoch: 4 | Iteration number: [2440/4518] 54% | Training loss: 0.6876191979793251
Epoch: 4 | Iteration number: [2450/4518] 54% | Training loss: 0.6876207256803707
Epoch: 4 | Iteration number: [2460/4518] 54% | Training loss: 0.6876158491140458
Epoch: 4 | Iteration number: [2470/4518] 54% | Training loss: 0.6876155361231522
Epoch: 4 | Iteration number: [2480/4518] 54% | Training loss: 0.6876135712189059
Epoch: 4 | Iteration number: [2490/4518] 55% | Training loss: 0.6876127776611283
Epoch: 4 | Iteration number: [2500/4518] 55% | Training loss: 0.6876102822780609
Epoch: 4 | Iteration number: [2510/4518] 55% | Training loss: 0.6876068184812706
Epoch: 4 | Iteration number: [2520/4518] 55% | Training loss: 0.6876047577176775
Epoch: 4 | Iteration number: [2530/4518] 55% | Training loss: 0.6876055069827279
Epoch: 4 | Iteration number: [2540/4518] 56% | Training loss: 0.6876045032045034
Epoch: 4 | Iteration number: [2550/4518] 56% | Training loss: 0.6876020144715028
Epoch: 4 | Iteration number: [2560/4518] 56% | Training loss: 0.6876004939200356
Epoch: 4 | Iteration number: [2570/4518] 56% | Training loss: 0.6875976134598951
Epoch: 4 | Iteration number: [2580/4518] 57% | Training loss: 0.6876030222390049
Epoch: 4 | Iteration number: [2590/4518] 57% | Training loss: 0.6876024597630077
Epoch: 4 | Iteration number: [2600/4518] 57% | Training loss: 0.6876060708211018
Epoch: 4 | Iteration number: [2610/4518] 57% | Training loss: 0.6876044303292972
Epoch: 4 | Iteration number: [2620/4518] 57% | Training loss: 0.6876049747676339
Epoch: 4 | Iteration number: [2630/4518] 58% | Training loss: 0.6876069911305895
Epoch: 4 | Iteration number: [2640/4518] 58% | Training loss: 0.6876091058281335
Epoch: 4 | Iteration number: [2650/4518] 58% | Training loss: 0.6876112776432397
Epoch: 4 | Iteration number: [2660/4518] 58% | Training loss: 0.6876060035667921
Epoch: 4 | Iteration number: [2670/4518] 59% | Training loss: 0.6875990424933058
Epoch: 4 | Iteration number: [2680/4518] 59% | Training loss: 0.6875995977378603
Epoch: 4 | Iteration number: [2690/4518] 59% | Training loss: 0.6875925370751703
Epoch: 4 | Iteration number: [2700/4518] 59% | Training loss: 0.6875939892397986
Epoch: 4 | Iteration number: [2710/4518] 59% | Training loss: 0.6875942877077968
Epoch: 4 | Iteration number: [2720/4518] 60% | Training loss: 0.6875906881164102
Epoch: 4 | Iteration number: [2730/4518] 60% | Training loss: 0.6875915545465309
Epoch: 4 | Iteration number: [2740/4518] 60% | Training loss: 0.6875836573595548
Epoch: 4 | Iteration number: [2750/4518] 60% | Training loss: 0.6875837711204182
Epoch: 4 | Iteration number: [2760/4518] 61% | Training loss: 0.6875834531326225
Epoch: 4 | Iteration number: [2770/4518] 61% | Training loss: 0.6875826893730714
Epoch: 4 | Iteration number: [2780/4518] 61% | Training loss: 0.6875839647200468
Epoch: 4 | Iteration number: [2790/4518] 61% | Training loss: 0.6875839605553603
Epoch: 4 | Iteration number: [2800/4518] 61% | Training loss: 0.6875846868540559
Epoch: 4 | Iteration number: [2810/4518] 62% | Training loss: 0.6875849853843132
Epoch: 4 | Iteration number: [2820/4518] 62% | Training loss: 0.6875861870692976
Epoch: 4 | Iteration number: [2830/4518] 62% | Training loss: 0.6875843888879244
Epoch: 4 | Iteration number: [2840/4518] 62% | Training loss: 0.6875809973604242
Epoch: 4 | Iteration number: [2850/4518] 63% | Training loss: 0.6875809394685846
Epoch: 4 | Iteration number: [2860/4518] 63% | Training loss: 0.6875788951878781
Epoch: 4 | Iteration number: [2870/4518] 63% | Training loss: 0.6875759071173984
Epoch: 4 | Iteration number: [2880/4518] 63% | Training loss: 0.6875708622650968
Epoch: 4 | Iteration number: [2890/4518] 63% | Training loss: 0.6875699946830842
Epoch: 4 | Iteration number: [2900/4518] 64% | Training loss: 0.6875663358178632
Epoch: 4 | Iteration number: [2910/4518] 64% | Training loss: 0.6875620755338178
Epoch: 4 | Iteration number: [2920/4518] 64% | Training loss: 0.6875605534200799
Epoch: 4 | Iteration number: [2930/4518] 64% | Training loss: 0.6875579858192404
Epoch: 4 | Iteration number: [2940/4518] 65% | Training loss: 0.687560835156311
Epoch: 4 | Iteration number: [2950/4518] 65% | Training loss: 0.6875600715208862
Epoch: 4 | Iteration number: [2960/4518] 65% | Training loss: 0.6875594378121801
Epoch: 4 | Iteration number: [2970/4518] 65% | Training loss: 0.6875540668514842
Epoch: 4 | Iteration number: [2980/4518] 65% | Training loss: 0.6875529015224252
Epoch: 4 | Iteration number: [2990/4518] 66% | Training loss: 0.687552062723549
Epoch: 4 | Iteration number: [3000/4518] 66% | Training loss: 0.6875530325571696
Epoch: 4 | Iteration number: [3010/4518] 66% | Training loss: 0.6875513374805451
Epoch: 4 | Iteration number: [3020/4518] 66% | Training loss: 0.6875469446182251
Epoch: 4 | Iteration number: [3030/4518] 67% | Training loss: 0.6875450128179179
Epoch: 4 | Iteration number: [3040/4518] 67% | Training loss: 0.6875463921968874
Epoch: 4 | Iteration number: [3050/4518] 67% | Training loss: 0.6875437090631391
Epoch: 4 | Iteration number: [3060/4518] 67% | Training loss: 0.6875417445220199
Epoch: 4 | Iteration number: [3070/4518] 67% | Training loss: 0.6875435379700863
Epoch: 4 | Iteration number: [3080/4518] 68% | Training loss: 0.6875428638287953
Epoch: 4 | Iteration number: [3090/4518] 68% | Training loss: 0.6875396132083387
Epoch: 4 | Iteration number: [3100/4518] 68% | Training loss: 0.6875375047422224
Epoch: 4 | Iteration number: [3110/4518] 68% | Training loss: 0.6875375272376745
Epoch: 4 | Iteration number: [3120/4518] 69% | Training loss: 0.6875318961838881
Epoch: 4 | Iteration number: [3130/4518] 69% | Training loss: 0.687532337043232
Epoch: 4 | Iteration number: [3140/4518] 69% | Training loss: 0.6875334236272581
Epoch: 4 | Iteration number: [3150/4518] 69% | Training loss: 0.6875343433826688
Epoch: 4 | Iteration number: [3160/4518] 69% | Training loss: 0.6875397017296356
Epoch: 4 | Iteration number: [3170/4518] 70% | Training loss: 0.6875390466455406
Epoch: 4 | Iteration number: [3180/4518] 70% | Training loss: 0.6875353693587225
Epoch: 4 | Iteration number: [3190/4518] 70% | Training loss: 0.6875369474618787
Epoch: 4 | Iteration number: [3200/4518] 70% | Training loss: 0.6875357865728438
Epoch: 4 | Iteration number: [3210/4518] 71% | Training loss: 0.6875374877749945
Epoch: 4 | Iteration number: [3220/4518] 71% | Training loss: 0.6875351955061374
Epoch: 4 | Iteration number: [3230/4518] 71% | Training loss: 0.6875330347763865
Epoch: 4 | Iteration number: [3240/4518] 71% | Training loss: 0.6875310868760686
Epoch: 4 | Iteration number: [3250/4518] 71% | Training loss: 0.6875301860479208
Epoch: 4 | Iteration number: [3260/4518] 72% | Training loss: 0.6875327763199075
Epoch: 4 | Iteration number: [3270/4518] 72% | Training loss: 0.6875322425219627
Epoch: 4 | Iteration number: [3280/4518] 72% | Training loss: 0.6875279250304873
Epoch: 4 | Iteration number: [3290/4518] 72% | Training loss: 0.6875241039190612
Epoch: 4 | Iteration number: [3300/4518] 73% | Training loss: 0.68752363410863
Epoch: 4 | Iteration number: [3310/4518] 73% | Training loss: 0.6875256308436034
Epoch: 4 | Iteration number: [3320/4518] 73% | Training loss: 0.6875270918191198
Epoch: 4 | Iteration number: [3330/4518] 73% | Training loss: 0.6875265726456055
Epoch: 4 | Iteration number: [3340/4518] 73% | Training loss: 0.6875262651971714
Epoch: 4 | Iteration number: [3350/4518] 74% | Training loss: 0.687525885389812
Epoch: 4 | Iteration number: [3360/4518] 74% | Training loss: 0.6875265710588012
Epoch: 4 | Iteration number: [3370/4518] 74% | Training loss: 0.6875278994838986
Epoch: 4 | Iteration number: [3380/4518] 74% | Training loss: 0.6875302057823486
Epoch: 4 | Iteration number: [3390/4518] 75% | Training loss: 0.6875326769014375
Epoch: 4 | Iteration number: [3400/4518] 75% | Training loss: 0.6875322114194141
Epoch: 4 | Iteration number: [3410/4518] 75% | Training loss: 0.6875317218890987
Epoch: 4 | Iteration number: [3420/4518] 75% | Training loss: 0.6875280555751588
Epoch: 4 | Iteration number: [3430/4518] 75% | Training loss: 0.6875266360993288
Epoch: 4 | Iteration number: [3440/4518] 76% | Training loss: 0.6875239004922468
Epoch: 4 | Iteration number: [3450/4518] 76% | Training loss: 0.6875199561879255
Epoch: 4 | Iteration number: [3460/4518] 76% | Training loss: 0.6875204384326935
Epoch: 4 | Iteration number: [3470/4518] 76% | Training loss: 0.6875207394619153
Epoch: 4 | Iteration number: [3480/4518] 77% | Training loss: 0.6875183648761661
Epoch: 4 | Iteration number: [3490/4518] 77% | Training loss: 0.6875190681577753
Epoch: 4 | Iteration number: [3500/4518] 77% | Training loss: 0.6875173198836191
Epoch: 4 | Iteration number: [3510/4518] 77% | Training loss: 0.6875213346250376
Epoch: 4 | Iteration number: [3520/4518] 77% | Training loss: 0.6875221945345402
Epoch: 4 | Iteration number: [3530/4518] 78% | Training loss: 0.6875212732860793
Epoch: 4 | Iteration number: [3540/4518] 78% | Training loss: 0.6875191120609725
Epoch: 4 | Iteration number: [3550/4518] 78% | Training loss: 0.6875201730828889
Epoch: 4 | Iteration number: [3560/4518] 78% | Training loss: 0.6875181958916482
Epoch: 4 | Iteration number: [3570/4518] 79% | Training loss: 0.687517676633947
Epoch: 4 | Iteration number: [3580/4518] 79% | Training loss: 0.6875163194853501
Epoch: 4 | Iteration number: [3590/4518] 79% | Training loss: 0.6875132809940487
Epoch: 4 | Iteration number: [3600/4518] 79% | Training loss: 0.6875099440415701
Epoch: 4 | Iteration number: [3610/4518] 79% | Training loss: 0.6875070478777476
Epoch: 4 | Iteration number: [3620/4518] 80% | Training loss: 0.687502923509034
Epoch: 4 | Iteration number: [3630/4518] 80% | Training loss: 0.6875017230668343
Epoch: 4 | Iteration number: [3640/4518] 80% | Training loss: 0.6874998981644819
Epoch: 4 | Iteration number: [3650/4518] 80% | Training loss: 0.687499161779064
Epoch: 4 | Iteration number: [3660/4518] 81% | Training loss: 0.6874991761693537
Epoch: 4 | Iteration number: [3670/4518] 81% | Training loss: 0.687499568215508
Epoch: 4 | Iteration number: [3680/4518] 81% | Training loss: 0.6874948023615972
Epoch: 4 | Iteration number: [3690/4518] 81% | Training loss: 0.6874950300548781
Epoch: 4 | Iteration number: [3700/4518] 81% | Training loss: 0.6874961384405961
Epoch: 4 | Iteration number: [3710/4518] 82% | Training loss: 0.6874958529787244
Epoch: 4 | Iteration number: [3720/4518] 82% | Training loss: 0.6874919959454127
Epoch: 4 | Iteration number: [3730/4518] 82% | Training loss: 0.6874914798436152
Epoch: 4 | Iteration number: [3740/4518] 82% | Training loss: 0.6874933093467498
Epoch: 4 | Iteration number: [3750/4518] 83% | Training loss: 0.6874918213049571
Epoch: 4 | Iteration number: [3760/4518] 83% | Training loss: 0.6874897419455204
Epoch: 4 | Iteration number: [3770/4518] 83% | Training loss: 0.6874890155912394
Epoch: 4 | Iteration number: [3780/4518] 83% | Training loss: 0.6874858361230325
Epoch: 4 | Iteration number: [3790/4518] 83% | Training loss: 0.6874845510422397
Epoch: 4 | Iteration number: [3800/4518] 84% | Training loss: 0.6874811180328068
Epoch: 4 | Iteration number: [3810/4518] 84% | Training loss: 0.6874811509462793
Epoch: 4 | Iteration number: [3820/4518] 84% | Training loss: 0.6874793766680812
Epoch: 4 | Iteration number: [3830/4518] 84% | Training loss: 0.6874805692593049
Epoch: 4 | Iteration number: [3840/4518] 84% | Training loss: 0.6874772422481328
Epoch: 4 | Iteration number: [3850/4518] 85% | Training loss: 0.6874795600346156
Epoch: 4 | Iteration number: [3860/4518] 85% | Training loss: 0.687480759157418
Epoch: 4 | Iteration number: [3870/4518] 85% | Training loss: 0.6874789710346735
Epoch: 4 | Iteration number: [3880/4518] 85% | Training loss: 0.6874761426571718
Epoch: 4 | Iteration number: [3890/4518] 86% | Training loss: 0.6874777349071208
Epoch: 4 | Iteration number: [3900/4518] 86% | Training loss: 0.6874781001836826
Epoch: 4 | Iteration number: [3910/4518] 86% | Training loss: 0.6874773270943586
Epoch: 4 | Iteration number: [3920/4518] 86% | Training loss: 0.6874760372298104
Epoch: 4 | Iteration number: [3930/4518] 86% | Training loss: 0.6874775569250868
Epoch: 4 | Iteration number: [3940/4518] 87% | Training loss: 0.687475707416002
Epoch: 4 | Iteration number: [3950/4518] 87% | Training loss: 0.6874766150909134
Epoch: 4 | Iteration number: [3960/4518] 87% | Training loss: 0.68747891171111
Epoch: 4 | Iteration number: [3970/4518] 87% | Training loss: 0.6874794423430032
Epoch: 4 | Iteration number: [3980/4518] 88% | Training loss: 0.6874806128105326
Epoch: 4 | Iteration number: [3990/4518] 88% | Training loss: 0.6874797044840074
Epoch: 4 | Iteration number: [4000/4518] 88% | Training loss: 0.6874777304381132
Epoch: 4 | Iteration number: [4010/4518] 88% | Training loss: 0.6874796978999255
Epoch: 4 | Iteration number: [4020/4518] 88% | Training loss: 0.6874805940324394
Epoch: 4 | Iteration number: [4030/4518] 89% | Training loss: 0.687481157744197
Epoch: 4 | Iteration number: [4040/4518] 89% | Training loss: 0.6874848528221102
Epoch: 4 | Iteration number: [4050/4518] 89% | Training loss: 0.6874820209432532
Epoch: 4 | Iteration number: [4060/4518] 89% | Training loss: 0.6874802340427643
Epoch: 4 | Iteration number: [4070/4518] 90% | Training loss: 0.6874780597352864
Epoch: 4 | Iteration number: [4080/4518] 90% | Training loss: 0.6874760643086013
Epoch: 4 | Iteration number: [4090/4518] 90% | Training loss: 0.6874736330765675
Epoch: 4 | Iteration number: [4100/4518] 90% | Training loss: 0.6874689627856743
Epoch: 4 | Iteration number: [4110/4518] 90% | Training loss: 0.6874700622692015
Epoch: 4 | Iteration number: [4120/4518] 91% | Training loss: 0.6874706502678325
Epoch: 4 | Iteration number: [4130/4518] 91% | Training loss: 0.6874707169307634
Epoch: 4 | Iteration number: [4140/4518] 91% | Training loss: 0.6874713038764714
Epoch: 4 | Iteration number: [4150/4518] 91% | Training loss: 0.687470467507121
Epoch: 4 | Iteration number: [4160/4518] 92% | Training loss: 0.6874687623805724
Epoch: 4 | Iteration number: [4170/4518] 92% | Training loss: 0.6874685867513113
Epoch: 4 | Iteration number: [4180/4518] 92% | Training loss: 0.6874704978112399
Epoch: 4 | Iteration number: [4190/4518] 92% | Training loss: 0.6874683993955216
Epoch: 4 | Iteration number: [4200/4518] 92% | Training loss: 0.687469773718289
Epoch: 4 | Iteration number: [4210/4518] 93% | Training loss: 0.6874686065025963
Epoch: 4 | Iteration number: [4220/4518] 93% | Training loss: 0.6874667593935655
Epoch: 4 | Iteration number: [4230/4518] 93% | Training loss: 0.6874635235074
Epoch: 4 | Iteration number: [4240/4518] 93% | Training loss: 0.6874617457670985
Epoch: 4 | Iteration number: [4250/4518] 94% | Training loss: 0.6874611540261437
Epoch: 4 | Iteration number: [4260/4518] 94% | Training loss: 0.6874612932613758
Epoch: 4 | Iteration number: [4270/4518] 94% | Training loss: 0.6874602911204309
Epoch: 4 | Iteration number: [4280/4518] 94% | Training loss: 0.6874601544481571
Epoch: 4 | Iteration number: [4290/4518] 94% | Training loss: 0.6874597361732474
Epoch: 4 | Iteration number: [4300/4518] 95% | Training loss: 0.6874597330010215
Epoch: 4 | Iteration number: [4310/4518] 95% | Training loss: 0.6874588559647448
Epoch: 4 | Iteration number: [4320/4518] 95% | Training loss: 0.6874594580934004
Epoch: 4 | Iteration number: [4330/4518] 95% | Training loss: 0.6874610319974516
Epoch: 4 | Iteration number: [4340/4518] 96% | Training loss: 0.6874576004007446
Epoch: 4 | Iteration number: [4350/4518] 96% | Training loss: 0.6874570973714192
Epoch: 4 | Iteration number: [4360/4518] 96% | Training loss: 0.6874586369603052
Epoch: 4 | Iteration number: [4370/4518] 96% | Training loss: 0.6874552548204461
Epoch: 4 | Iteration number: [4380/4518] 96% | Training loss: 0.6874551248332681
Epoch: 4 | Iteration number: [4390/4518] 97% | Training loss: 0.6874569816578494
Epoch: 4 | Iteration number: [4400/4518] 97% | Training loss: 0.687456945871765
Epoch: 4 | Iteration number: [4410/4518] 97% | Training loss: 0.6874570306196235
Epoch: 4 | Iteration number: [4420/4518] 97% | Training loss: 0.687455382606023
Epoch: 4 | Iteration number: [4430/4518] 98% | Training loss: 0.6874570845346688
Epoch: 4 | Iteration number: [4440/4518] 98% | Training loss: 0.6874574804225484
Epoch: 4 | Iteration number: [4450/4518] 98% | Training loss: 0.6874589543128281
Epoch: 4 | Iteration number: [4460/4518] 98% | Training loss: 0.6874568794340297
Epoch: 4 | Iteration number: [4470/4518] 98% | Training loss: 0.6874601815504249
Epoch: 4 | Iteration number: [4480/4518] 99% | Training loss: 0.6874616133581315
Epoch: 4 | Iteration number: [4490/4518] 99% | Training loss: 0.6874608165968235
Epoch: 4 | Iteration number: [4500/4518] 99% | Training loss: 0.6874606298738056
Epoch: 4 | Iteration number: [4510/4518] 99% | Training loss: 0.687460017732929

 End of epoch: 4 | Train Loss: 0.6873073177614165 | Training Time: 641 

 End of epoch: 4 | Eval Loss: 0.6903651490503427 | Evaluating Time: 17 
Epoch: 5 | Iteration number: [10/4518] 0% | Training loss: 0.7560230493545532
Epoch: 5 | Iteration number: [20/4518] 0% | Training loss: 0.7215516984462738
Epoch: 5 | Iteration number: [30/4518] 0% | Training loss: 0.7100793659687042
Epoch: 5 | Iteration number: [40/4518] 0% | Training loss: 0.7042015075683594
Epoch: 5 | Iteration number: [50/4518] 1% | Training loss: 0.7010159182548523
Epoch: 5 | Iteration number: [60/4518] 1% | Training loss: 0.6985916088024775
Epoch: 5 | Iteration number: [70/4518] 1% | Training loss: 0.6968552163669042
Epoch: 5 | Iteration number: [80/4518] 1% | Training loss: 0.6954663798213006
Epoch: 5 | Iteration number: [90/4518] 1% | Training loss: 0.6945241510868072
Epoch: 5 | Iteration number: [100/4518] 2% | Training loss: 0.6937466955184937
Epoch: 5 | Iteration number: [110/4518] 2% | Training loss: 0.6930746528235349
Epoch: 5 | Iteration number: [120/4518] 2% | Training loss: 0.6926600669821104
Epoch: 5 | Iteration number: [130/4518] 2% | Training loss: 0.6921460738548866
Epoch: 5 | Iteration number: [140/4518] 3% | Training loss: 0.6918098969118935
Epoch: 5 | Iteration number: [150/4518] 3% | Training loss: 0.691570942401886
Epoch: 5 | Iteration number: [160/4518] 3% | Training loss: 0.6913556404411793
Epoch: 5 | Iteration number: [170/4518] 3% | Training loss: 0.6910897282993093
Epoch: 5 | Iteration number: [180/4518] 3% | Training loss: 0.6909031732214822
Epoch: 5 | Iteration number: [190/4518] 4% | Training loss: 0.6906981521531155
Epoch: 5 | Iteration number: [200/4518] 4% | Training loss: 0.6905593666434288
Epoch: 5 | Iteration number: [210/4518] 4% | Training loss: 0.6904258256866819
Epoch: 5 | Iteration number: [220/4518] 4% | Training loss: 0.6902511463923888
Epoch: 5 | Iteration number: [230/4518] 5% | Training loss: 0.690102041285971
Epoch: 5 | Iteration number: [240/4518] 5% | Training loss: 0.689988948404789
Epoch: 5 | Iteration number: [250/4518] 5% | Training loss: 0.689899249792099
Epoch: 5 | Iteration number: [260/4518] 5% | Training loss: 0.6898117805902775
Epoch: 5 | Iteration number: [270/4518] 5% | Training loss: 0.6897225417472698
Epoch: 5 | Iteration number: [280/4518] 6% | Training loss: 0.6896496564149857
Epoch: 5 | Iteration number: [290/4518] 6% | Training loss: 0.6895388668981092
Epoch: 5 | Iteration number: [300/4518] 6% | Training loss: 0.6894519674777985
Epoch: 5 | Iteration number: [310/4518] 6% | Training loss: 0.689369672729123
Epoch: 5 | Iteration number: [320/4518] 7% | Training loss: 0.6892978519201278
Epoch: 5 | Iteration number: [330/4518] 7% | Training loss: 0.689202749006676
Epoch: 5 | Iteration number: [340/4518] 7% | Training loss: 0.6891580951564452
Epoch: 5 | Iteration number: [350/4518] 7% | Training loss: 0.6890859912122999
Epoch: 5 | Iteration number: [360/4518] 7% | Training loss: 0.6890156875054042
Epoch: 5 | Iteration number: [370/4518] 8% | Training loss: 0.6889697799811492
Epoch: 5 | Iteration number: [380/4518] 8% | Training loss: 0.6889378815889359
Epoch: 5 | Iteration number: [390/4518] 8% | Training loss: 0.6888866166273753
Epoch: 5 | Iteration number: [400/4518] 8% | Training loss: 0.6888363309204578
Epoch: 5 | Iteration number: [410/4518] 9% | Training loss: 0.6887802680818046
Epoch: 5 | Iteration number: [420/4518] 9% | Training loss: 0.6887121586572557
Epoch: 5 | Iteration number: [430/4518] 9% | Training loss: 0.6886612505413765
Epoch: 5 | Iteration number: [440/4518] 9% | Training loss: 0.6886381842873314
Epoch: 5 | Iteration number: [450/4518] 9% | Training loss: 0.6886068043443891
Epoch: 5 | Iteration number: [460/4518] 10% | Training loss: 0.6885939937570821
Epoch: 5 | Iteration number: [470/4518] 10% | Training loss: 0.6885427012088451
Epoch: 5 | Iteration number: [480/4518] 10% | Training loss: 0.6885408310840527
Epoch: 5 | Iteration number: [490/4518] 10% | Training loss: 0.6885126494631475
Epoch: 5 | Iteration number: [500/4518] 11% | Training loss: 0.6884806733131409
Epoch: 5 | Iteration number: [510/4518] 11% | Training loss: 0.68844460681373
Epoch: 5 | Iteration number: [520/4518] 11% | Training loss: 0.6884141470377262
Epoch: 5 | Iteration number: [530/4518] 11% | Training loss: 0.6884056316231781
Epoch: 5 | Iteration number: [540/4518] 11% | Training loss: 0.6883950258846636
Epoch: 5 | Iteration number: [550/4518] 12% | Training loss: 0.688372185121883
Epoch: 5 | Iteration number: [560/4518] 12% | Training loss: 0.6883538837943758
Epoch: 5 | Iteration number: [570/4518] 12% | Training loss: 0.6883299375835218
Epoch: 5 | Iteration number: [580/4518] 12% | Training loss: 0.6883107349790376
Epoch: 5 | Iteration number: [590/4518] 13% | Training loss: 0.6882852776575896
Epoch: 5 | Iteration number: [600/4518] 13% | Training loss: 0.6882730659842491
Epoch: 5 | Iteration number: [610/4518] 13% | Training loss: 0.6882619327209035
Epoch: 5 | Iteration number: [620/4518] 13% | Training loss: 0.6882323520798836
Epoch: 5 | Iteration number: [630/4518] 13% | Training loss: 0.6882099723059033
Epoch: 5 | Iteration number: [640/4518] 14% | Training loss: 0.6881971837952733
Epoch: 5 | Iteration number: [650/4518] 14% | Training loss: 0.6881673723000746
Epoch: 5 | Iteration number: [660/4518] 14% | Training loss: 0.6881419341672551
Epoch: 5 | Iteration number: [670/4518] 14% | Training loss: 0.6881292348477378
Epoch: 5 | Iteration number: [680/4518] 15% | Training loss: 0.688141854019726
Epoch: 5 | Iteration number: [690/4518] 15% | Training loss: 0.6881336508453756
Epoch: 5 | Iteration number: [700/4518] 15% | Training loss: 0.6881230979306358
Epoch: 5 | Iteration number: [710/4518] 15% | Training loss: 0.688114580973773
Epoch: 5 | Iteration number: [720/4518] 15% | Training loss: 0.6880925883849461
Epoch: 5 | Iteration number: [730/4518] 16% | Training loss: 0.6880916130052854
Epoch: 5 | Iteration number: [740/4518] 16% | Training loss: 0.6881040350005433
Epoch: 5 | Iteration number: [750/4518] 16% | Training loss: 0.6880971556504567
Epoch: 5 | Iteration number: [760/4518] 16% | Training loss: 0.6880866166008146
Epoch: 5 | Iteration number: [770/4518] 17% | Training loss: 0.6880738808737172
Epoch: 5 | Iteration number: [780/4518] 17% | Training loss: 0.6880498060049155
Epoch: 5 | Iteration number: [790/4518] 17% | Training loss: 0.688029413962666
Epoch: 5 | Iteration number: [800/4518] 17% | Training loss: 0.6880144342035055
Epoch: 5 | Iteration number: [810/4518] 17% | Training loss: 0.6880175343266239
Epoch: 5 | Iteration number: [820/4518] 18% | Training loss: 0.6880193636911671
Epoch: 5 | Iteration number: [830/4518] 18% | Training loss: 0.6880005692143039
Epoch: 5 | Iteration number: [840/4518] 18% | Training loss: 0.6879899466321582
Epoch: 5 | Iteration number: [850/4518] 18% | Training loss: 0.687970310940462
Epoch: 5 | Iteration number: [860/4518] 19% | Training loss: 0.687975548173106
Epoch: 5 | Iteration number: [870/4518] 19% | Training loss: 0.6879769317720128
Epoch: 5 | Iteration number: [880/4518] 19% | Training loss: 0.6879749909043312
Epoch: 5 | Iteration number: [890/4518] 19% | Training loss: 0.6879793293020698
Epoch: 5 | Iteration number: [900/4518] 19% | Training loss: 0.6879793110158708
Epoch: 5 | Iteration number: [910/4518] 20% | Training loss: 0.6879785706053724
Epoch: 5 | Iteration number: [920/4518] 20% | Training loss: 0.687962959577208
Epoch: 5 | Iteration number: [930/4518] 20% | Training loss: 0.6879612284962849
Epoch: 5 | Iteration number: [940/4518] 20% | Training loss: 0.687946726984166
Epoch: 5 | Iteration number: [950/4518] 21% | Training loss: 0.6879351056249519
Epoch: 5 | Iteration number: [960/4518] 21% | Training loss: 0.6879299017290275
Epoch: 5 | Iteration number: [970/4518] 21% | Training loss: 0.6879262416633134
Epoch: 5 | Iteration number: [980/4518] 21% | Training loss: 0.6879267693782339
Epoch: 5 | Iteration number: [990/4518] 21% | Training loss: 0.687922578869444
Epoch: 5 | Iteration number: [1000/4518] 22% | Training loss: 0.6879065378904342
Epoch: 5 | Iteration number: [1010/4518] 22% | Training loss: 0.6878815165840754
Epoch: 5 | Iteration number: [1020/4518] 22% | Training loss: 0.6878590061384089
Epoch: 5 | Iteration number: [1030/4518] 22% | Training loss: 0.6878511615748545
Epoch: 5 | Iteration number: [1040/4518] 23% | Training loss: 0.6878375416764846
Epoch: 5 | Iteration number: [1050/4518] 23% | Training loss: 0.6878275106634413
Epoch: 5 | Iteration number: [1060/4518] 23% | Training loss: 0.6878144326075069
Epoch: 5 | Iteration number: [1070/4518] 23% | Training loss: 0.6878012999195919
Epoch: 5 | Iteration number: [1080/4518] 23% | Training loss: 0.6877903558037899
Epoch: 5 | Iteration number: [1090/4518] 24% | Training loss: 0.6877901279051369
Epoch: 5 | Iteration number: [1100/4518] 24% | Training loss: 0.6877929481593046
Epoch: 5 | Iteration number: [1110/4518] 24% | Training loss: 0.6877809985800907
Epoch: 5 | Iteration number: [1120/4518] 24% | Training loss: 0.6877880230545997
Epoch: 5 | Iteration number: [1130/4518] 25% | Training loss: 0.6877691555867153
Epoch: 5 | Iteration number: [1140/4518] 25% | Training loss: 0.6877621619324935
Epoch: 5 | Iteration number: [1150/4518] 25% | Training loss: 0.6877550521104232
Epoch: 5 | Iteration number: [1160/4518] 25% | Training loss: 0.6877468168735504
Epoch: 5 | Iteration number: [1170/4518] 25% | Training loss: 0.6877422173817952
Epoch: 5 | Iteration number: [1180/4518] 26% | Training loss: 0.6877375714354595
Epoch: 5 | Iteration number: [1190/4518] 26% | Training loss: 0.6877346201103275
Epoch: 5 | Iteration number: [1200/4518] 26% | Training loss: 0.6877363372345765
Epoch: 5 | Iteration number: [1210/4518] 26% | Training loss: 0.6877381360727893
Epoch: 5 | Iteration number: [1220/4518] 27% | Training loss: 0.6877374381804076
Epoch: 5 | Iteration number: [1230/4518] 27% | Training loss: 0.6877382295887645
Epoch: 5 | Iteration number: [1240/4518] 27% | Training loss: 0.6877316271105121
Epoch: 5 | Iteration number: [1250/4518] 27% | Training loss: 0.6877338428497315
Epoch: 5 | Iteration number: [1260/4518] 27% | Training loss: 0.6877310987029757
Epoch: 5 | Iteration number: [1270/4518] 28% | Training loss: 0.6877247181464368
Epoch: 5 | Iteration number: [1280/4518] 28% | Training loss: 0.6877198244910687
Epoch: 5 | Iteration number: [1290/4518] 28% | Training loss: 0.68771714378697
Epoch: 5 | Iteration number: [1300/4518] 28% | Training loss: 0.6877129479096487
Epoch: 5 | Iteration number: [1310/4518] 28% | Training loss: 0.6877139149276355
Epoch: 5 | Iteration number: [1320/4518] 29% | Training loss: 0.6877178120342168
Epoch: 5 | Iteration number: [1330/4518] 29% | Training loss: 0.6877121130774791
Epoch: 5 | Iteration number: [1340/4518] 29% | Training loss: 0.6877129607681018
Epoch: 5 | Iteration number: [1350/4518] 29% | Training loss: 0.6877084645960067
Epoch: 5 | Iteration number: [1360/4518] 30% | Training loss: 0.6877076041610802
Epoch: 5 | Iteration number: [1370/4518] 30% | Training loss: 0.6877074545317323
Epoch: 5 | Iteration number: [1380/4518] 30% | Training loss: 0.687695833435957
Epoch: 5 | Iteration number: [1390/4518] 30% | Training loss: 0.6876844013766419
Epoch: 5 | Iteration number: [1400/4518] 30% | Training loss: 0.687681696329798
Epoch: 5 | Iteration number: [1410/4518] 31% | Training loss: 0.6876811675568845
Epoch: 5 | Iteration number: [1420/4518] 31% | Training loss: 0.6876856442488415
Epoch: 5 | Iteration number: [1430/4518] 31% | Training loss: 0.687678359480171
Epoch: 5 | Iteration number: [1440/4518] 31% | Training loss: 0.6876812450173828
Epoch: 5 | Iteration number: [1450/4518] 32% | Training loss: 0.6876679940470334
Epoch: 5 | Iteration number: [1460/4518] 32% | Training loss: 0.6876710474082869
Epoch: 5 | Iteration number: [1470/4518] 32% | Training loss: 0.6876627050289491
Epoch: 5 | Iteration number: [1480/4518] 32% | Training loss: 0.6876491428629772
Epoch: 5 | Iteration number: [1490/4518] 32% | Training loss: 0.6876481244628061
Epoch: 5 | Iteration number: [1500/4518] 33% | Training loss: 0.6876483376423518
Epoch: 5 | Iteration number: [1510/4518] 33% | Training loss: 0.6876404686874111
Epoch: 5 | Iteration number: [1520/4518] 33% | Training loss: 0.6876299142837524
Epoch: 5 | Iteration number: [1530/4518] 33% | Training loss: 0.6876245667342267
Epoch: 5 | Iteration number: [1540/4518] 34% | Training loss: 0.687625506249341
Epoch: 5 | Iteration number: [1550/4518] 34% | Training loss: 0.6876183571738581
Epoch: 5 | Iteration number: [1560/4518] 34% | Training loss: 0.6876093414349433
Epoch: 5 | Iteration number: [1570/4518] 34% | Training loss: 0.6875991101857204
Epoch: 5 | Iteration number: [1580/4518] 34% | Training loss: 0.6875911466305769
Epoch: 5 | Iteration number: [1590/4518] 35% | Training loss: 0.6875931995844691
Epoch: 5 | Iteration number: [1600/4518] 35% | Training loss: 0.687591917552054
Epoch: 5 | Iteration number: [1610/4518] 35% | Training loss: 0.6875901298123117
Epoch: 5 | Iteration number: [1620/4518] 35% | Training loss: 0.68758643972285
Epoch: 5 | Iteration number: [1630/4518] 36% | Training loss: 0.6875841105642494
Epoch: 5 | Iteration number: [1640/4518] 36% | Training loss: 0.6875833717061253
Epoch: 5 | Iteration number: [1650/4518] 36% | Training loss: 0.6875796500480537
Epoch: 5 | Iteration number: [1660/4518] 36% | Training loss: 0.6875760743416935
Epoch: 5 | Iteration number: [1670/4518] 36% | Training loss: 0.6875722110628368
Epoch: 5 | Iteration number: [1680/4518] 37% | Training loss: 0.6875724110929738
Epoch: 5 | Iteration number: [1690/4518] 37% | Training loss: 0.6875693097622437
Epoch: 5 | Iteration number: [1700/4518] 37% | Training loss: 0.6875733539286781
Epoch: 5 | Iteration number: [1710/4518] 37% | Training loss: 0.6875705661132322
Epoch: 5 | Iteration number: [1720/4518] 38% | Training loss: 0.6875662769689116
Epoch: 5 | Iteration number: [1730/4518] 38% | Training loss: 0.6875664725469027
Epoch: 5 | Iteration number: [1740/4518] 38% | Training loss: 0.6875655355124638
Epoch: 5 | Iteration number: [1750/4518] 38% | Training loss: 0.6875683472497123
Epoch: 5 | Iteration number: [1760/4518] 38% | Training loss: 0.6875658835877072
Epoch: 5 | Iteration number: [1770/4518] 39% | Training loss: 0.6875686653253049
Epoch: 5 | Iteration number: [1780/4518] 39% | Training loss: 0.6875596913059107
Epoch: 5 | Iteration number: [1790/4518] 39% | Training loss: 0.6875532215200989
Epoch: 5 | Iteration number: [1800/4518] 39% | Training loss: 0.687553218073315
Epoch: 5 | Iteration number: [1810/4518] 40% | Training loss: 0.6875519749209367
Epoch: 5 | Iteration number: [1820/4518] 40% | Training loss: 0.68755805849374
Epoch: 5 | Iteration number: [1830/4518] 40% | Training loss: 0.6875575346047761
Epoch: 5 | Iteration number: [1840/4518] 40% | Training loss: 0.687549122520115
Epoch: 5 | Iteration number: [1850/4518] 40% | Training loss: 0.6875498750403121
Epoch: 5 | Iteration number: [1860/4518] 41% | Training loss: 0.6875456814804385
Epoch: 5 | Iteration number: [1870/4518] 41% | Training loss: 0.687546173136502
Epoch: 5 | Iteration number: [1880/4518] 41% | Training loss: 0.6875394240972844
Epoch: 5 | Iteration number: [1890/4518] 41% | Training loss: 0.6875379402486105
Epoch: 5 | Iteration number: [1900/4518] 42% | Training loss: 0.6875321096495578
Epoch: 5 | Iteration number: [1910/4518] 42% | Training loss: 0.687533686984896
Epoch: 5 | Iteration number: [1920/4518] 42% | Training loss: 0.6875347789066534
Epoch: 5 | Iteration number: [1930/4518] 42% | Training loss: 0.6875342502495168
Epoch: 5 | Iteration number: [1940/4518] 42% | Training loss: 0.6875345945051036
Epoch: 5 | Iteration number: [1950/4518] 43% | Training loss: 0.6875354701433426
Epoch: 5 | Iteration number: [1960/4518] 43% | Training loss: 0.6875347864871122
Epoch: 5 | Iteration number: [1970/4518] 43% | Training loss: 0.6875377339154936
Epoch: 5 | Iteration number: [1980/4518] 43% | Training loss: 0.6875299381487298
Epoch: 5 | Iteration number: [1990/4518] 44% | Training loss: 0.6875261328328195
Epoch: 5 | Iteration number: [2000/4518] 44% | Training loss: 0.6875243457853795
Epoch: 5 | Iteration number: [2010/4518] 44% | Training loss: 0.6875159013923721
Epoch: 5 | Iteration number: [2020/4518] 44% | Training loss: 0.6875167671701695
Epoch: 5 | Iteration number: [2030/4518] 44% | Training loss: 0.6875128304723448
Epoch: 5 | Iteration number: [2040/4518] 45% | Training loss: 0.6875170357087079
Epoch: 5 | Iteration number: [2050/4518] 45% | Training loss: 0.6875104901267262
Epoch: 5 | Iteration number: [2060/4518] 45% | Training loss: 0.6875106838142988
Epoch: 5 | Iteration number: [2070/4518] 45% | Training loss: 0.6875127213300715
Epoch: 5 | Iteration number: [2080/4518] 46% | Training loss: 0.6875150015720954
Epoch: 5 | Iteration number: [2090/4518] 46% | Training loss: 0.6875165294231981
Epoch: 5 | Iteration number: [2100/4518] 46% | Training loss: 0.6875120679253623
Epoch: 5 | Iteration number: [2110/4518] 46% | Training loss: 0.6875083497915223
Epoch: 5 | Iteration number: [2120/4518] 46% | Training loss: 0.6875086930281711
Epoch: 5 | Iteration number: [2130/4518] 47% | Training loss: 0.6875142195694883
Epoch: 5 | Iteration number: [2140/4518] 47% | Training loss: 0.6875160467401843
Epoch: 5 | Iteration number: [2150/4518] 47% | Training loss: 0.6875164676267047
Epoch: 5 | Iteration number: [2160/4518] 47% | Training loss: 0.6875214395975625
Epoch: 5 | Iteration number: [2170/4518] 48% | Training loss: 0.6875162990137179
Epoch: 5 | Iteration number: [2180/4518] 48% | Training loss: 0.6875122116519771
Epoch: 5 | Iteration number: [2190/4518] 48% | Training loss: 0.6875129693175015
Epoch: 5 | Iteration number: [2200/4518] 48% | Training loss: 0.6875187183239243
Epoch: 5 | Iteration number: [2210/4518] 48% | Training loss: 0.6875217572865983
Epoch: 5 | Iteration number: [2220/4518] 49% | Training loss: 0.6875213560757336
Epoch: 5 | Iteration number: [2230/4518] 49% | Training loss: 0.6875219340014351
Epoch: 5 | Iteration number: [2240/4518] 49% | Training loss: 0.6875244249456696
Epoch: 5 | Iteration number: [2250/4518] 49% | Training loss: 0.6875208988189697
Epoch: 5 | Iteration number: [2260/4518] 50% | Training loss: 0.6875186407196838
Epoch: 5 | Iteration number: [2270/4518] 50% | Training loss: 0.6875144685417545
Epoch: 5 | Iteration number: [2280/4518] 50% | Training loss: 0.6875157709184446
Epoch: 5 | Iteration number: [2290/4518] 50% | Training loss: 0.6875189313461687
Epoch: 5 | Iteration number: [2300/4518] 50% | Training loss: 0.6875190947885099
Epoch: 5 | Iteration number: [2310/4518] 51% | Training loss: 0.6875213892428906
Epoch: 5 | Iteration number: [2320/4518] 51% | Training loss: 0.6875223585500799
Epoch: 5 | Iteration number: [2330/4518] 51% | Training loss: 0.6875225978347876
Epoch: 5 | Iteration number: [2340/4518] 51% | Training loss: 0.6875166492839145
Epoch: 5 | Iteration number: [2350/4518] 52% | Training loss: 0.6875112984028269
Epoch: 5 | Iteration number: [2360/4518] 52% | Training loss: 0.6875121393951319
Epoch: 5 | Iteration number: [2370/4518] 52% | Training loss: 0.687512484205423
Epoch: 5 | Iteration number: [2380/4518] 52% | Training loss: 0.6875079975408667
Epoch: 5 | Iteration number: [2390/4518] 52% | Training loss: 0.6874989086364602
Epoch: 5 | Iteration number: [2400/4518] 53% | Training loss: 0.6874943904330333
Epoch: 5 | Iteration number: [2410/4518] 53% | Training loss: 0.6874939303675133
Epoch: 5 | Iteration number: [2420/4518] 53% | Training loss: 0.6874905779834621
Epoch: 5 | Iteration number: [2430/4518] 53% | Training loss: 0.6874913868590147
Epoch: 5 | Iteration number: [2440/4518] 54% | Training loss: 0.6874962421958564
Epoch: 5 | Iteration number: [2450/4518] 54% | Training loss: 0.6874928424552995
Epoch: 5 | Iteration number: [2460/4518] 54% | Training loss: 0.687487467299632
Epoch: 5 | Iteration number: [2470/4518] 54% | Training loss: 0.6874878459855129
Epoch: 5 | Iteration number: [2480/4518] 54% | Training loss: 0.6874851256849305
Epoch: 5 | Iteration number: [2490/4518] 55% | Training loss: 0.6874835441390195
Epoch: 5 | Iteration number: [2500/4518] 55% | Training loss: 0.6874856273412705
Epoch: 5 | Iteration number: [2510/4518] 55% | Training loss: 0.6874812421333267
Epoch: 5 | Iteration number: [2520/4518] 55% | Training loss: 0.6874808668380692
Epoch: 5 | Iteration number: [2530/4518] 55% | Training loss: 0.6874795712972347
Epoch: 5 | Iteration number: [2540/4518] 56% | Training loss: 0.6874819344892277
Epoch: 5 | Iteration number: [2550/4518] 56% | Training loss: 0.6874766007357953
Epoch: 5 | Iteration number: [2560/4518] 56% | Training loss: 0.6874749938258902
Epoch: 5 | Iteration number: [2570/4518] 56% | Training loss: 0.6874716278180074
Epoch: 5 | Iteration number: [2580/4518] 57% | Training loss: 0.6874731946592183
Epoch: 5 | Iteration number: [2590/4518] 57% | Training loss: 0.6874701290287106
Epoch: 5 | Iteration number: [2600/4518] 57% | Training loss: 0.6874699318867463
Epoch: 5 | Iteration number: [2610/4518] 57% | Training loss: 0.6874700767783827
Epoch: 5 | Iteration number: [2620/4518] 57% | Training loss: 0.6874673914363366
Epoch: 5 | Iteration number: [2630/4518] 58% | Training loss: 0.6874671213527143
Epoch: 5 | Iteration number: [2640/4518] 58% | Training loss: 0.6874645348525409
Epoch: 5 | Iteration number: [2650/4518] 58% | Training loss: 0.6874609023220134
Epoch: 5 | Iteration number: [2660/4518] 58% | Training loss: 0.6874611121819432
Epoch: 5 | Iteration number: [2670/4518] 59% | Training loss: 0.687462981050827
Epoch: 5 | Iteration number: [2680/4518] 59% | Training loss: 0.6874625168851952
Epoch: 5 | Iteration number: [2690/4518] 59% | Training loss: 0.6874606912020857
Epoch: 5 | Iteration number: [2700/4518] 59% | Training loss: 0.6874621886014939
Epoch: 5 | Iteration number: [2710/4518] 59% | Training loss: 0.6874637436602828
Epoch: 5 | Iteration number: [2720/4518] 60% | Training loss: 0.6874635182759341
Epoch: 5 | Iteration number: [2730/4518] 60% | Training loss: 0.687460839682883
Epoch: 5 | Iteration number: [2740/4518] 60% | Training loss: 0.6874580870797165
Epoch: 5 | Iteration number: [2750/4518] 60% | Training loss: 0.6874590407284823
Epoch: 5 | Iteration number: [2760/4518] 61% | Training loss: 0.6874601652224859
Epoch: 5 | Iteration number: [2770/4518] 61% | Training loss: 0.6874604379657373
Epoch: 5 | Iteration number: [2780/4518] 61% | Training loss: 0.6874606264580926
Epoch: 5 | Iteration number: [2790/4518] 61% | Training loss: 0.6874620212662604
Epoch: 5 | Iteration number: [2800/4518] 61% | Training loss: 0.6874572512720313
Epoch: 5 | Iteration number: [2810/4518] 62% | Training loss: 0.6874566991346163
Epoch: 5 | Iteration number: [2820/4518] 62% | Training loss: 0.6874571466276832
Epoch: 5 | Iteration number: [2830/4518] 62% | Training loss: 0.6874598462674306
Epoch: 5 | Iteration number: [2840/4518] 62% | Training loss: 0.6874588496668238
Epoch: 5 | Iteration number: [2850/4518] 63% | Training loss: 0.6874574006858625
Epoch: 5 | Iteration number: [2860/4518] 63% | Training loss: 0.687458900596712
Epoch: 5 | Iteration number: [2870/4518] 63% | Training loss: 0.6874610362775649
Epoch: 5 | Iteration number: [2880/4518] 63% | Training loss: 0.6874604486135973
Epoch: 5 | Iteration number: [2890/4518] 63% | Training loss: 0.6874589914062856
Epoch: 5 | Iteration number: [2900/4518] 64% | Training loss: 0.687459236938378
Epoch: 5 | Iteration number: [2910/4518] 64% | Training loss: 0.687458973795278
Epoch: 5 | Iteration number: [2920/4518] 64% | Training loss: 0.6874600062631581
Epoch: 5 | Iteration number: [2930/4518] 64% | Training loss: 0.6874579325877765
Epoch: 5 | Iteration number: [2940/4518] 65% | Training loss: 0.68745634233465
Epoch: 5 | Iteration number: [2950/4518] 65% | Training loss: 0.687451690758689
Epoch: 5 | Iteration number: [2960/4518] 65% | Training loss: 0.6874568715691567
Epoch: 5 | Iteration number: [2970/4518] 65% | Training loss: 0.6874571647306885
Epoch: 5 | Iteration number: [2980/4518] 65% | Training loss: 0.6874561968665795
Epoch: 5 | Iteration number: [2990/4518] 66% | Training loss: 0.6874560063499272
Epoch: 5 | Iteration number: [3000/4518] 66% | Training loss: 0.6874584017793337
Epoch: 5 | Iteration number: [3010/4518] 66% | Training loss: 0.6874588625375615
Epoch: 5 | Iteration number: [3020/4518] 66% | Training loss: 0.6874600063688707
Epoch: 5 | Iteration number: [3030/4518] 67% | Training loss: 0.687462735825246
Epoch: 5 | Iteration number: [3040/4518] 67% | Training loss: 0.6874646818755489
Epoch: 5 | Iteration number: [3050/4518] 67% | Training loss: 0.687466625072917
Epoch: 5 | Iteration number: [3060/4518] 67% | Training loss: 0.6874658746657029
Epoch: 5 | Iteration number: [3070/4518] 67% | Training loss: 0.6874622652119068
Epoch: 5 | Iteration number: [3080/4518] 68% | Training loss: 0.6874632049497071
Epoch: 5 | Iteration number: [3090/4518] 68% | Training loss: 0.6874604089167512
Epoch: 5 | Iteration number: [3100/4518] 68% | Training loss: 0.6874582251617986
Epoch: 5 | Iteration number: [3110/4518] 68% | Training loss: 0.6874581942795941
Epoch: 5 | Iteration number: [3120/4518] 69% | Training loss: 0.6874553682139286
Epoch: 5 | Iteration number: [3130/4518] 69% | Training loss: 0.6874513347499287
Epoch: 5 | Iteration number: [3140/4518] 69% | Training loss: 0.6874513776059363
Epoch: 5 | Iteration number: [3150/4518] 69% | Training loss: 0.6874503084023793
Epoch: 5 | Iteration number: [3160/4518] 69% | Training loss: 0.6874442182764222
Epoch: 5 | Iteration number: [3170/4518] 70% | Training loss: 0.6874427723395712
Epoch: 5 | Iteration number: [3180/4518] 70% | Training loss: 0.6874429396300946
Epoch: 5 | Iteration number: [3190/4518] 70% | Training loss: 0.6874435887254517
Epoch: 5 | Iteration number: [3200/4518] 70% | Training loss: 0.6874452110007405
Epoch: 5 | Iteration number: [3210/4518] 71% | Training loss: 0.6874426962430603
Epoch: 5 | Iteration number: [3220/4518] 71% | Training loss: 0.6874420741885345
Epoch: 5 | Iteration number: [3230/4518] 71% | Training loss: 0.6874428549418139
Epoch: 5 | Iteration number: [3240/4518] 71% | Training loss: 0.6874429735136621
Epoch: 5 | Iteration number: [3250/4518] 71% | Training loss: 0.6874322461531712
Epoch: 5 | Iteration number: [3260/4518] 72% | Training loss: 0.6874305100163067
Epoch: 5 | Iteration number: [3270/4518] 72% | Training loss: 0.6874266659265629
Epoch: 5 | Iteration number: [3280/4518] 72% | Training loss: 0.6874264394546428
Epoch: 5 | Iteration number: [3290/4518] 72% | Training loss: 0.6874236530264822
Epoch: 5 | Iteration number: [3300/4518] 73% | Training loss: 0.687422414078857
Epoch: 5 | Iteration number: [3310/4518] 73% | Training loss: 0.6874188917461118
Epoch: 5 | Iteration number: [3320/4518] 73% | Training loss: 0.6874128878834735
Epoch: 5 | Iteration number: [3330/4518] 73% | Training loss: 0.6874138855540358
Epoch: 5 | Iteration number: [3340/4518] 73% | Training loss: 0.6874121644539748
Epoch: 5 | Iteration number: [3350/4518] 74% | Training loss: 0.6874111890081149
Epoch: 5 | Iteration number: [3360/4518] 74% | Training loss: 0.6874129028902167
Epoch: 5 | Iteration number: [3370/4518] 74% | Training loss: 0.6874087790707099
Epoch: 5 | Iteration number: [3380/4518] 74% | Training loss: 0.6874100701696069
Epoch: 5 | Iteration number: [3390/4518] 75% | Training loss: 0.6874105017797082
Epoch: 5 | Iteration number: [3400/4518] 75% | Training loss: 0.6874091446750304
Epoch: 5 | Iteration number: [3410/4518] 75% | Training loss: 0.6874046908445722
Epoch: 5 | Iteration number: [3420/4518] 75% | Training loss: 0.6874062079086638
Epoch: 5 | Iteration number: [3430/4518] 75% | Training loss: 0.6874057823297929
Epoch: 5 | Iteration number: [3440/4518] 76% | Training loss: 0.6874043929022412
Epoch: 5 | Iteration number: [3450/4518] 76% | Training loss: 0.6874044463254403
Epoch: 5 | Iteration number: [3460/4518] 76% | Training loss: 0.6874021443156149
Epoch: 5 | Iteration number: [3470/4518] 76% | Training loss: 0.6874028353594909
Epoch: 5 | Iteration number: [3480/4518] 77% | Training loss: 0.6874035943684906
Epoch: 5 | Iteration number: [3490/4518] 77% | Training loss: 0.6874045396944172
Epoch: 5 | Iteration number: [3500/4518] 77% | Training loss: 0.6874048474686486
Epoch: 5 | Iteration number: [3510/4518] 77% | Training loss: 0.6874044121500433
Epoch: 5 | Iteration number: [3520/4518] 77% | Training loss: 0.6874024861915545
Epoch: 5 | Iteration number: [3530/4518] 78% | Training loss: 0.687397418447662
Epoch: 5 | Iteration number: [3540/4518] 78% | Training loss: 0.6873987921382074
Epoch: 5 | Iteration number: [3550/4518] 78% | Training loss: 0.6874000771952347
Epoch: 5 | Iteration number: [3560/4518] 78% | Training loss: 0.687400561470664
Epoch: 5 | Iteration number: [3570/4518] 79% | Training loss: 0.6873991154322103
Epoch: 5 | Iteration number: [3580/4518] 79% | Training loss: 0.6873979632248426
Epoch: 5 | Iteration number: [3590/4518] 79% | Training loss: 0.6873994799543556
Epoch: 5 | Iteration number: [3600/4518] 79% | Training loss: 0.6874013205203745
Epoch: 5 | Iteration number: [3610/4518] 79% | Training loss: 0.6874020087586876
Epoch: 5 | Iteration number: [3620/4518] 80% | Training loss: 0.6874038221592402
Epoch: 5 | Iteration number: [3630/4518] 80% | Training loss: 0.6874002173584026
Epoch: 5 | Iteration number: [3640/4518] 80% | Training loss: 0.6874007463127703
Epoch: 5 | Iteration number: [3650/4518] 80% | Training loss: 0.6874029760491358
Epoch: 5 | Iteration number: [3660/4518] 81% | Training loss: 0.6874062993324519
Epoch: 5 | Iteration number: [3670/4518] 81% | Training loss: 0.687403534998361
Epoch: 5 | Iteration number: [3680/4518] 81% | Training loss: 0.6874057931744534
Epoch: 5 | Iteration number: [3690/4518] 81% | Training loss: 0.6874031208233459
Epoch: 5 | Iteration number: [3700/4518] 81% | Training loss: 0.6873994009720312
Epoch: 5 | Iteration number: [3710/4518] 82% | Training loss: 0.6874009319392819
Epoch: 5 | Iteration number: [3720/4518] 82% | Training loss: 0.6873995550858077
Epoch: 5 | Iteration number: [3730/4518] 82% | Training loss: 0.6873988904358554
Epoch: 5 | Iteration number: [3740/4518] 82% | Training loss: 0.6873983435292933
Epoch: 5 | Iteration number: [3750/4518] 83% | Training loss: 0.6873985650221507
Epoch: 5 | Iteration number: [3760/4518] 83% | Training loss: 0.687398310544643
Epoch: 5 | Iteration number: [3770/4518] 83% | Training loss: 0.6873977014019256
Epoch: 5 | Iteration number: [3780/4518] 83% | Training loss: 0.6873933531935252
Epoch: 5 | Iteration number: [3790/4518] 83% | Training loss: 0.6873925444475893
Epoch: 5 | Iteration number: [3800/4518] 84% | Training loss: 0.6873947531141733
Epoch: 5 | Iteration number: [3810/4518] 84% | Training loss: 0.6873973251484198
Epoch: 5 | Iteration number: [3820/4518] 84% | Training loss: 0.6874008585801299
Epoch: 5 | Iteration number: [3830/4518] 84% | Training loss: 0.687398543992802
Epoch: 5 | Iteration number: [3840/4518] 84% | Training loss: 0.6873952811428656
Epoch: 5 | Iteration number: [3850/4518] 85% | Training loss: 0.687393088185942
Epoch: 5 | Iteration number: [3860/4518] 85% | Training loss: 0.6873935933248985
Epoch: 5 | Iteration number: [3870/4518] 85% | Training loss: 0.6873932360216629
Epoch: 5 | Iteration number: [3880/4518] 85% | Training loss: 0.6873915180410306
Epoch: 5 | Iteration number: [3890/4518] 86% | Training loss: 0.6873931194792063
Epoch: 5 | Iteration number: [3900/4518] 86% | Training loss: 0.6873943618016365
Epoch: 5 | Iteration number: [3910/4518] 86% | Training loss: 0.6873941702001235
Epoch: 5 | Iteration number: [3920/4518] 86% | Training loss: 0.6873895646053918
Epoch: 5 | Iteration number: [3930/4518] 86% | Training loss: 0.6873878564088399
Epoch: 5 | Iteration number: [3940/4518] 87% | Training loss: 0.6873895974328675
Epoch: 5 | Iteration number: [3950/4518] 87% | Training loss: 0.6873875246621386
Epoch: 5 | Iteration number: [3960/4518] 87% | Training loss: 0.6873852185077137
Epoch: 5 | Iteration number: [3970/4518] 87% | Training loss: 0.6873807344238464
Epoch: 5 | Iteration number: [3980/4518] 88% | Training loss: 0.6873813315552084
Epoch: 5 | Iteration number: [3990/4518] 88% | Training loss: 0.687380235685143
Epoch: 5 | Iteration number: [4000/4518] 88% | Training loss: 0.6873805273473262
Epoch: 5 | Iteration number: [4010/4518] 88% | Training loss: 0.6873796776197201
Epoch: 5 | Iteration number: [4020/4518] 88% | Training loss: 0.687382610979958
Epoch: 5 | Iteration number: [4030/4518] 89% | Training loss: 0.6873822311905419
Epoch: 5 | Iteration number: [4040/4518] 89% | Training loss: 0.6873803623241953
Epoch: 5 | Iteration number: [4050/4518] 89% | Training loss: 0.6873788730450618
Epoch: 5 | Iteration number: [4060/4518] 89% | Training loss: 0.6873826925096841
Epoch: 5 | Iteration number: [4070/4518] 90% | Training loss: 0.6873815952706396
Epoch: 5 | Iteration number: [4080/4518] 90% | Training loss: 0.6873797063880107
Epoch: 5 | Iteration number: [4090/4518] 90% | Training loss: 0.6873827483514119
Epoch: 5 | Iteration number: [4100/4518] 90% | Training loss: 0.6873832211116465
Epoch: 5 | Iteration number: [4110/4518] 90% | Training loss: 0.6873816310779312
Epoch: 5 | Iteration number: [4120/4518] 91% | Training loss: 0.6873838613623554
Epoch: 5 | Iteration number: [4130/4518] 91% | Training loss: 0.6873803482938909
Epoch: 5 | Iteration number: [4140/4518] 91% | Training loss: 0.6873813296141832
Epoch: 5 | Iteration number: [4150/4518] 91% | Training loss: 0.687382811738784
Epoch: 5 | Iteration number: [4160/4518] 92% | Training loss: 0.6873821163120178
Epoch: 5 | Iteration number: [4170/4518] 92% | Training loss: 0.687380757820692
Epoch: 5 | Iteration number: [4180/4518] 92% | Training loss: 0.6873737223268126
Epoch: 5 | Iteration number: [4190/4518] 92% | Training loss: 0.6873690667755564
Epoch: 5 | Iteration number: [4200/4518] 92% | Training loss: 0.6873663033474059
Epoch: 5 | Iteration number: [4210/4518] 93% | Training loss: 0.6873646735861862
Epoch: 5 | Iteration number: [4220/4518] 93% | Training loss: 0.6873623483977611
Epoch: 5 | Iteration number: [4230/4518] 93% | Training loss: 0.6873634693329498
Epoch: 5 | Iteration number: [4240/4518] 93% | Training loss: 0.6873620368962018
Epoch: 5 | Iteration number: [4250/4518] 94% | Training loss: 0.6873610672670252
Epoch: 5 | Iteration number: [4260/4518] 94% | Training loss: 0.687361101799168
Epoch: 5 | Iteration number: [4270/4518] 94% | Training loss: 0.6873609622970956
Epoch: 5 | Iteration number: [4280/4518] 94% | Training loss: 0.68736025480745
Epoch: 5 | Iteration number: [4290/4518] 94% | Training loss: 0.6873633359139893
Epoch: 5 | Iteration number: [4300/4518] 95% | Training loss: 0.6873617591691572
Epoch: 5 | Iteration number: [4310/4518] 95% | Training loss: 0.6873592124599315
Epoch: 5 | Iteration number: [4320/4518] 95% | Training loss: 0.6873611399696933
Epoch: 5 | Iteration number: [4330/4518] 95% | Training loss: 0.6873598046308301
Epoch: 5 | Iteration number: [4340/4518] 96% | Training loss: 0.6873587337781757
Epoch: 5 | Iteration number: [4350/4518] 96% | Training loss: 0.6873553775233784
Epoch: 5 | Iteration number: [4360/4518] 96% | Training loss: 0.6873537533737104
Epoch: 5 | Iteration number: [4370/4518] 96% | Training loss: 0.6873545738461362
Epoch: 5 | Iteration number: [4380/4518] 96% | Training loss: 0.6873558230596046
Epoch: 5 | Iteration number: [4390/4518] 97% | Training loss: 0.6873565240166997
Epoch: 5 | Iteration number: [4400/4518] 97% | Training loss: 0.6873534878546541
Epoch: 5 | Iteration number: [4410/4518] 97% | Training loss: 0.6873535137327891
Epoch: 5 | Iteration number: [4420/4518] 97% | Training loss: 0.6873480599120732
Epoch: 5 | Iteration number: [4430/4518] 98% | Training loss: 0.6873485261242223
Epoch: 5 | Iteration number: [4440/4518] 98% | Training loss: 0.6873508650843088
Epoch: 5 | Iteration number: [4450/4518] 98% | Training loss: 0.6873514482278502
Epoch: 5 | Iteration number: [4460/4518] 98% | Training loss: 0.6873485247516846
Epoch: 5 | Iteration number: [4470/4518] 98% | Training loss: 0.6873488241394095
Epoch: 5 | Iteration number: [4480/4518] 99% | Training loss: 0.6873476405894118
Epoch: 5 | Iteration number: [4490/4518] 99% | Training loss: 0.6873463725990602
Epoch: 5 | Iteration number: [4500/4518] 99% | Training loss: 0.6873464314672681
Epoch: 5 | Iteration number: [4510/4518] 99% | Training loss: 0.6873453186383004

 End of epoch: 5 | Train Loss: 0.6871947948781724 | Training Time: 641 

 End of epoch: 5 | Eval Loss: 0.6904279978907838 | Evaluating Time: 17 
Epoch: 6 | Iteration number: [10/4518] 0% | Training loss: 0.7567395687103271
Epoch: 6 | Iteration number: [20/4518] 0% | Training loss: 0.7219810426235199
Epoch: 6 | Iteration number: [30/4518] 0% | Training loss: 0.7108520070711771
Epoch: 6 | Iteration number: [40/4518] 0% | Training loss: 0.7047926902770996
Epoch: 6 | Iteration number: [50/4518] 1% | Training loss: 0.7009852838516235
Epoch: 6 | Iteration number: [60/4518] 1% | Training loss: 0.6986706366141637
Epoch: 6 | Iteration number: [70/4518] 1% | Training loss: 0.6969425984791346
Epoch: 6 | Iteration number: [80/4518] 1% | Training loss: 0.6958219192922115
Epoch: 6 | Iteration number: [90/4518] 1% | Training loss: 0.6950411134295993
Epoch: 6 | Iteration number: [100/4518] 2% | Training loss: 0.694201632142067
Epoch: 6 | Iteration number: [110/4518] 2% | Training loss: 0.6935370960018852
Epoch: 6 | Iteration number: [120/4518] 2% | Training loss: 0.6930114264289539
Epoch: 6 | Iteration number: [130/4518] 2% | Training loss: 0.6924741364442385
Epoch: 6 | Iteration number: [140/4518] 3% | Training loss: 0.6920803095613207
Epoch: 6 | Iteration number: [150/4518] 3% | Training loss: 0.6916475419203441
Epoch: 6 | Iteration number: [160/4518] 3% | Training loss: 0.6913391292095185
Epoch: 6 | Iteration number: [170/4518] 3% | Training loss: 0.6911110317005831
Epoch: 6 | Iteration number: [180/4518] 3% | Training loss: 0.6908523377445009
Epoch: 6 | Iteration number: [190/4518] 4% | Training loss: 0.6906132704333255
Epoch: 6 | Iteration number: [200/4518] 4% | Training loss: 0.6905399635434151
Epoch: 6 | Iteration number: [210/4518] 4% | Training loss: 0.6902864058812459
Epoch: 6 | Iteration number: [220/4518] 4% | Training loss: 0.6901279254393144
Epoch: 6 | Iteration number: [230/4518] 5% | Training loss: 0.6900111237297888
Epoch: 6 | Iteration number: [240/4518] 5% | Training loss: 0.6899223794539769
Epoch: 6 | Iteration number: [250/4518] 5% | Training loss: 0.6898451321125031
Epoch: 6 | Iteration number: [260/4518] 5% | Training loss: 0.6897438239592772
Epoch: 6 | Iteration number: [270/4518] 5% | Training loss: 0.6896485222710503
Epoch: 6 | Iteration number: [280/4518] 6% | Training loss: 0.6895485556551388
Epoch: 6 | Iteration number: [290/4518] 6% | Training loss: 0.68943305837697
Epoch: 6 | Iteration number: [300/4518] 6% | Training loss: 0.6893325863281886
Epoch: 6 | Iteration number: [310/4518] 6% | Training loss: 0.6892445777693103
Epoch: 6 | Iteration number: [320/4518] 7% | Training loss: 0.6891976239159703
Epoch: 6 | Iteration number: [330/4518] 7% | Training loss: 0.6891364462447889
Epoch: 6 | Iteration number: [340/4518] 7% | Training loss: 0.6891103062559577
Epoch: 6 | Iteration number: [350/4518] 7% | Training loss: 0.6890305149555206
Epoch: 6 | Iteration number: [360/4518] 7% | Training loss: 0.6890244871377945
Epoch: 6 | Iteration number: [370/4518] 8% | Training loss: 0.6889210204820375
Epoch: 6 | Iteration number: [380/4518] 8% | Training loss: 0.6888577155376735
Epoch: 6 | Iteration number: [390/4518] 8% | Training loss: 0.6888162423402835
Epoch: 6 | Iteration number: [400/4518] 8% | Training loss: 0.6887566478550434
Epoch: 6 | Iteration number: [410/4518] 9% | Training loss: 0.6887359728173512
Epoch: 6 | Iteration number: [420/4518] 9% | Training loss: 0.6887010941902797
Epoch: 6 | Iteration number: [430/4518] 9% | Training loss: 0.6886992277101028
Epoch: 6 | Iteration number: [440/4518] 9% | Training loss: 0.6886612972075289
Epoch: 6 | Iteration number: [450/4518] 9% | Training loss: 0.6886005956596798
Epoch: 6 | Iteration number: [460/4518] 10% | Training loss: 0.6885782110950222
Epoch: 6 | Iteration number: [470/4518] 10% | Training loss: 0.6885399316219574
Epoch: 6 | Iteration number: [480/4518] 10% | Training loss: 0.6885153037806352
Epoch: 6 | Iteration number: [490/4518] 10% | Training loss: 0.6884980655446344
Epoch: 6 | Iteration number: [500/4518] 11% | Training loss: 0.6884530091285705
Epoch: 6 | Iteration number: [510/4518] 11% | Training loss: 0.688420638851091
Epoch: 6 | Iteration number: [520/4518] 11% | Training loss: 0.6883625589884245
Epoch: 6 | Iteration number: [530/4518] 11% | Training loss: 0.6883608874284997
Epoch: 6 | Iteration number: [540/4518] 11% | Training loss: 0.6883357950934658
Epoch: 6 | Iteration number: [550/4518] 12% | Training loss: 0.6883052313327789
Epoch: 6 | Iteration number: [560/4518] 12% | Training loss: 0.6882828693304743
Epoch: 6 | Iteration number: [570/4518] 12% | Training loss: 0.6882473072461914
Epoch: 6 | Iteration number: [580/4518] 12% | Training loss: 0.6882135112737787
Epoch: 6 | Iteration number: [590/4518] 13% | Training loss: 0.6882139448392189
Epoch: 6 | Iteration number: [600/4518] 13% | Training loss: 0.6881978141268095
Epoch: 6 | Iteration number: [610/4518] 13% | Training loss: 0.6881731337211171
Epoch: 6 | Iteration number: [620/4518] 13% | Training loss: 0.6881403548102225
Epoch: 6 | Iteration number: [630/4518] 13% | Training loss: 0.6881286707189348
Epoch: 6 | Iteration number: [640/4518] 14% | Training loss: 0.6880915770307183
Epoch: 6 | Iteration number: [650/4518] 14% | Training loss: 0.6880801938130305
Epoch: 6 | Iteration number: [660/4518] 14% | Training loss: 0.6880699704993855
Epoch: 6 | Iteration number: [670/4518] 14% | Training loss: 0.688065988003318
Epoch: 6 | Iteration number: [680/4518] 15% | Training loss: 0.6880425039459678
Epoch: 6 | Iteration number: [690/4518] 15% | Training loss: 0.6880387892757637
Epoch: 6 | Iteration number: [700/4518] 15% | Training loss: 0.6880155299391065
Epoch: 6 | Iteration number: [710/4518] 15% | Training loss: 0.6879940482092576
Epoch: 6 | Iteration number: [720/4518] 15% | Training loss: 0.6879896424710751
Epoch: 6 | Iteration number: [730/4518] 16% | Training loss: 0.6879747798998062
Epoch: 6 | Iteration number: [740/4518] 16% | Training loss: 0.6879630654244809
Epoch: 6 | Iteration number: [750/4518] 16% | Training loss: 0.6879556094010671
Epoch: 6 | Iteration number: [760/4518] 16% | Training loss: 0.687945840390105
Epoch: 6 | Iteration number: [770/4518] 17% | Training loss: 0.6879561661899863
Epoch: 6 | Iteration number: [780/4518] 17% | Training loss: 0.6879467483514394
Epoch: 6 | Iteration number: [790/4518] 17% | Training loss: 0.6879293176192272
Epoch: 6 | Iteration number: [800/4518] 17% | Training loss: 0.6879102525860071
Epoch: 6 | Iteration number: [810/4518] 17% | Training loss: 0.6878891436406124
Epoch: 6 | Iteration number: [820/4518] 18% | Training loss: 0.6878749508683274
Epoch: 6 | Iteration number: [830/4518] 18% | Training loss: 0.6878690391419882
Epoch: 6 | Iteration number: [840/4518] 18% | Training loss: 0.6878635168075562
Epoch: 6 | Iteration number: [850/4518] 18% | Training loss: 0.6878669737367069
Epoch: 6 | Iteration number: [860/4518] 19% | Training loss: 0.6878378212451934
Epoch: 6 | Iteration number: [870/4518] 19% | Training loss: 0.6878204645781681
Epoch: 6 | Iteration number: [880/4518] 19% | Training loss: 0.6878089400177653
Epoch: 6 | Iteration number: [890/4518] 19% | Training loss: 0.6877981456477991
Epoch: 6 | Iteration number: [900/4518] 19% | Training loss: 0.6877861997154024
Epoch: 6 | Iteration number: [910/4518] 20% | Training loss: 0.6877760478428432
Epoch: 6 | Iteration number: [920/4518] 20% | Training loss: 0.6877665656416313
Epoch: 6 | Iteration number: [930/4518] 20% | Training loss: 0.6877437415302441
Epoch: 6 | Iteration number: [940/4518] 20% | Training loss: 0.6877317022770009
Epoch: 6 | Iteration number: [950/4518] 21% | Training loss: 0.6877371657522101
Epoch: 6 | Iteration number: [960/4518] 21% | Training loss: 0.687731986058255
Epoch: 6 | Iteration number: [970/4518] 21% | Training loss: 0.6877356298805513
Epoch: 6 | Iteration number: [980/4518] 21% | Training loss: 0.6877316287585667
Epoch: 6 | Iteration number: [990/4518] 21% | Training loss: 0.6877293760728355
Epoch: 6 | Iteration number: [1000/4518] 22% | Training loss: 0.6877250030040741
Epoch: 6 | Iteration number: [1010/4518] 22% | Training loss: 0.6877215727130965
Epoch: 6 | Iteration number: [1020/4518] 22% | Training loss: 0.6877354411517873
Epoch: 6 | Iteration number: [1030/4518] 22% | Training loss: 0.6877165478988758
Epoch: 6 | Iteration number: [1040/4518] 23% | Training loss: 0.68771067743118
Epoch: 6 | Iteration number: [1050/4518] 23% | Training loss: 0.6877193511667705
Epoch: 6 | Iteration number: [1060/4518] 23% | Training loss: 0.6877166638959129
Epoch: 6 | Iteration number: [1070/4518] 23% | Training loss: 0.6877115541529433
Epoch: 6 | Iteration number: [1080/4518] 23% | Training loss: 0.6876923948526382
Epoch: 6 | Iteration number: [1090/4518] 24% | Training loss: 0.6876898195218603
Epoch: 6 | Iteration number: [1100/4518] 24% | Training loss: 0.6876800252632661
Epoch: 6 | Iteration number: [1110/4518] 24% | Training loss: 0.6876686494092683
Epoch: 6 | Iteration number: [1120/4518] 24% | Training loss: 0.6876704898795911
Epoch: 6 | Iteration number: [1130/4518] 25% | Training loss: 0.687665954522327
Epoch: 6 | Iteration number: [1140/4518] 25% | Training loss: 0.6876606036696518
Epoch: 6 | Iteration number: [1150/4518] 25% | Training loss: 0.6876601988336314
Epoch: 6 | Iteration number: [1160/4518] 25% | Training loss: 0.6876685670737562
Epoch: 6 | Iteration number: [1170/4518] 25% | Training loss: 0.6876670426283127
Epoch: 6 | Iteration number: [1180/4518] 26% | Training loss: 0.6876700857938346
Epoch: 6 | Iteration number: [1190/4518] 26% | Training loss: 0.6876621396100822
Epoch: 6 | Iteration number: [1200/4518] 26% | Training loss: 0.6876552178462346
Epoch: 6 | Iteration number: [1210/4518] 26% | Training loss: 0.6876547361208387
Epoch: 6 | Iteration number: [1220/4518] 27% | Training loss: 0.687651918950628
Epoch: 6 | Iteration number: [1230/4518] 27% | Training loss: 0.6876513718589534
Epoch: 6 | Iteration number: [1240/4518] 27% | Training loss: 0.6876535524283686
Epoch: 6 | Iteration number: [1250/4518] 27% | Training loss: 0.6876460436820984
Epoch: 6 | Iteration number: [1260/4518] 27% | Training loss: 0.6876420417475322
Epoch: 6 | Iteration number: [1270/4518] 28% | Training loss: 0.6876311595984331
Epoch: 6 | Iteration number: [1280/4518] 28% | Training loss: 0.6876323380507529
Epoch: 6 | Iteration number: [1290/4518] 28% | Training loss: 0.6876275678937749
Epoch: 6 | Iteration number: [1300/4518] 28% | Training loss: 0.6876351784742796
Epoch: 6 | Iteration number: [1310/4518] 28% | Training loss: 0.6876309630980019
Epoch: 6 | Iteration number: [1320/4518] 29% | Training loss: 0.6876318121949831
Epoch: 6 | Iteration number: [1330/4518] 29% | Training loss: 0.6876289887983996
Epoch: 6 | Iteration number: [1340/4518] 29% | Training loss: 0.6876161039765202
Epoch: 6 | Iteration number: [1350/4518] 29% | Training loss: 0.6876192558694769
Epoch: 6 | Iteration number: [1360/4518] 30% | Training loss: 0.6876190452891238
Epoch: 6 | Iteration number: [1370/4518] 30% | Training loss: 0.6876168013054089
Epoch: 6 | Iteration number: [1380/4518] 30% | Training loss: 0.6876041473253913
Epoch: 6 | Iteration number: [1390/4518] 30% | Training loss: 0.6876043442770732
Epoch: 6 | Iteration number: [1400/4518] 30% | Training loss: 0.6875977740543229
Epoch: 6 | Iteration number: [1410/4518] 31% | Training loss: 0.6875978566230612
Epoch: 6 | Iteration number: [1420/4518] 31% | Training loss: 0.6875870379343839
Epoch: 6 | Iteration number: [1430/4518] 31% | Training loss: 0.6875865776222069
Epoch: 6 | Iteration number: [1440/4518] 31% | Training loss: 0.6875811157541143
Epoch: 6 | Iteration number: [1450/4518] 32% | Training loss: 0.6875744170567085
Epoch: 6 | Iteration number: [1460/4518] 32% | Training loss: 0.6875800102132641
Epoch: 6 | Iteration number: [1470/4518] 32% | Training loss: 0.687577534492324
Epoch: 6 | Iteration number: [1480/4518] 32% | Training loss: 0.6875766404979938
Epoch: 6 | Iteration number: [1490/4518] 32% | Training loss: 0.6875638513357047
Epoch: 6 | Iteration number: [1500/4518] 33% | Training loss: 0.6875563134352366
Epoch: 6 | Iteration number: [1510/4518] 33% | Training loss: 0.6875556810802181
Epoch: 6 | Iteration number: [1520/4518] 33% | Training loss: 0.6875495033044564
Epoch: 6 | Iteration number: [1530/4518] 33% | Training loss: 0.6875478198325712
Epoch: 6 | Iteration number: [1540/4518] 34% | Training loss: 0.6875415288782739
Epoch: 6 | Iteration number: [1550/4518] 34% | Training loss: 0.6875402039097201
Epoch: 6 | Iteration number: [1560/4518] 34% | Training loss: 0.6875367276561566
Epoch: 6 | Iteration number: [1570/4518] 34% | Training loss: 0.6875374318687779
Epoch: 6 | Iteration number: [1580/4518] 34% | Training loss: 0.6875387506017202
Epoch: 6 | Iteration number: [1590/4518] 35% | Training loss: 0.6875374168719885
Epoch: 6 | Iteration number: [1600/4518] 35% | Training loss: 0.6875344721972942
Epoch: 6 | Iteration number: [1610/4518] 35% | Training loss: 0.687533401221222
Epoch: 6 | Iteration number: [1620/4518] 35% | Training loss: 0.6875323325027655
Epoch: 6 | Iteration number: [1630/4518] 36% | Training loss: 0.6875290585807496
Epoch: 6 | Iteration number: [1640/4518] 36% | Training loss: 0.6875169595930635
Epoch: 6 | Iteration number: [1650/4518] 36% | Training loss: 0.6875187213131876
Epoch: 6 | Iteration number: [1660/4518] 36% | Training loss: 0.6875195897846337
Epoch: 6 | Iteration number: [1670/4518] 36% | Training loss: 0.687516007451954
Epoch: 6 | Iteration number: [1680/4518] 37% | Training loss: 0.6875172491229716
Epoch: 6 | Iteration number: [1690/4518] 37% | Training loss: 0.6875114792550104
Epoch: 6 | Iteration number: [1700/4518] 37% | Training loss: 0.6875099273639567
Epoch: 6 | Iteration number: [1710/4518] 37% | Training loss: 0.6875048156718762
Epoch: 6 | Iteration number: [1720/4518] 38% | Training loss: 0.6875041748548663
Epoch: 6 | Iteration number: [1730/4518] 38% | Training loss: 0.6875062149384118
Epoch: 6 | Iteration number: [1740/4518] 38% | Training loss: 0.6874980555183586
Epoch: 6 | Iteration number: [1750/4518] 38% | Training loss: 0.6874952525411333
Epoch: 6 | Iteration number: [1760/4518] 38% | Training loss: 0.6874898018823429
Epoch: 6 | Iteration number: [1770/4518] 39% | Training loss: 0.6874963677198873
Epoch: 6 | Iteration number: [1780/4518] 39% | Training loss: 0.6874831610851073
Epoch: 6 | Iteration number: [1790/4518] 39% | Training loss: 0.6874835839484656
Epoch: 6 | Iteration number: [1800/4518] 39% | Training loss: 0.6874907426701652
Epoch: 6 | Iteration number: [1810/4518] 40% | Training loss: 0.687493894310946
Epoch: 6 | Iteration number: [1820/4518] 40% | Training loss: 0.6874885810600533
Epoch: 6 | Iteration number: [1830/4518] 40% | Training loss: 0.6874845785521418
Epoch: 6 | Iteration number: [1840/4518] 40% | Training loss: 0.6874780023551506
Epoch: 6 | Iteration number: [1850/4518] 40% | Training loss: 0.6874744273842992
Epoch: 6 | Iteration number: [1860/4518] 41% | Training loss: 0.6874696623574021
Epoch: 6 | Iteration number: [1870/4518] 41% | Training loss: 0.6874691875541912
Epoch: 6 | Iteration number: [1880/4518] 41% | Training loss: 0.6874668550618152
Epoch: 6 | Iteration number: [1890/4518] 41% | Training loss: 0.6874634028427185
Epoch: 6 | Iteration number: [1900/4518] 42% | Training loss: 0.6874670226009268
Epoch: 6 | Iteration number: [1910/4518] 42% | Training loss: 0.6874728265233064
Epoch: 6 | Iteration number: [1920/4518] 42% | Training loss: 0.6874751469430824
Epoch: 6 | Iteration number: [1930/4518] 42% | Training loss: 0.6874711395545327
Epoch: 6 | Iteration number: [1940/4518] 42% | Training loss: 0.6874724376447422
Epoch: 6 | Iteration number: [1950/4518] 43% | Training loss: 0.6874700282170222
Epoch: 6 | Iteration number: [1960/4518] 43% | Training loss: 0.6874722768457568
Epoch: 6 | Iteration number: [1970/4518] 43% | Training loss: 0.6874697164533102
Epoch: 6 | Iteration number: [1980/4518] 43% | Training loss: 0.6874720291055815
Epoch: 6 | Iteration number: [1990/4518] 44% | Training loss: 0.6874722512523134
Epoch: 6 | Iteration number: [2000/4518] 44% | Training loss: 0.6874724219739438
Epoch: 6 | Iteration number: [2010/4518] 44% | Training loss: 0.6874737322033935
Epoch: 6 | Iteration number: [2020/4518] 44% | Training loss: 0.6874732912176906
Epoch: 6 | Iteration number: [2030/4518] 44% | Training loss: 0.6874698191147133
Epoch: 6 | Iteration number: [2040/4518] 45% | Training loss: 0.687466984928823
Epoch: 6 | Iteration number: [2050/4518] 45% | Training loss: 0.6874653506278992
Epoch: 6 | Iteration number: [2060/4518] 45% | Training loss: 0.6874592856585401
Epoch: 6 | Iteration number: [2070/4518] 45% | Training loss: 0.6874603127223858
Epoch: 6 | Iteration number: [2080/4518] 46% | Training loss: 0.6874588920806463
Epoch: 6 | Iteration number: [2090/4518] 46% | Training loss: 0.6874541361080972
Epoch: 6 | Iteration number: [2100/4518] 46% | Training loss: 0.6874540516592207
Epoch: 6 | Iteration number: [2110/4518] 46% | Training loss: 0.687455329991065
Epoch: 6 | Iteration number: [2120/4518] 46% | Training loss: 0.6874507786249214
Epoch: 6 | Iteration number: [2130/4518] 47% | Training loss: 0.6874495225053437
Epoch: 6 | Iteration number: [2140/4518] 47% | Training loss: 0.6874479306635456
Epoch: 6 | Iteration number: [2150/4518] 47% | Training loss: 0.6874458775963894
Epoch: 6 | Iteration number: [2160/4518] 47% | Training loss: 0.6874412934813234
Epoch: 6 | Iteration number: [2170/4518] 48% | Training loss: 0.6874375060406698
Epoch: 6 | Iteration number: [2180/4518] 48% | Training loss: 0.6874430010351567
Epoch: 6 | Iteration number: [2190/4518] 48% | Training loss: 0.6874423348740356
Epoch: 6 | Iteration number: [2200/4518] 48% | Training loss: 0.6874393759261478
Epoch: 6 | Iteration number: [2210/4518] 48% | Training loss: 0.6874336637792544
Epoch: 6 | Iteration number: [2220/4518] 49% | Training loss: 0.6874342595403259
Epoch: 6 | Iteration number: [2230/4518] 49% | Training loss: 0.6874317486724512
Epoch: 6 | Iteration number: [2240/4518] 49% | Training loss: 0.6874373639534627
Epoch: 6 | Iteration number: [2250/4518] 49% | Training loss: 0.6874314636919233
Epoch: 6 | Iteration number: [2260/4518] 50% | Training loss: 0.6874344010796167
Epoch: 6 | Iteration number: [2270/4518] 50% | Training loss: 0.6874313217165187
Epoch: 6 | Iteration number: [2280/4518] 50% | Training loss: 0.6874334771643605
Epoch: 6 | Iteration number: [2290/4518] 50% | Training loss: 0.6874320344112846
Epoch: 6 | Iteration number: [2300/4518] 50% | Training loss: 0.6874297440052033
Epoch: 6 | Iteration number: [2310/4518] 51% | Training loss: 0.6874312140466847
Epoch: 6 | Iteration number: [2320/4518] 51% | Training loss: 0.6874319750944088
Epoch: 6 | Iteration number: [2330/4518] 51% | Training loss: 0.6874329560304404
Epoch: 6 | Iteration number: [2340/4518] 51% | Training loss: 0.6874318010022498
Epoch: 6 | Iteration number: [2350/4518] 52% | Training loss: 0.6874304422926395
Epoch: 6 | Iteration number: [2360/4518] 52% | Training loss: 0.6874237074437788
Epoch: 6 | Iteration number: [2370/4518] 52% | Training loss: 0.6874216310082608
Epoch: 6 | Iteration number: [2380/4518] 52% | Training loss: 0.6874242540918478
Epoch: 6 | Iteration number: [2390/4518] 52% | Training loss: 0.6874256379434753
Epoch: 6 | Iteration number: [2400/4518] 53% | Training loss: 0.6874245777974526
Epoch: 6 | Iteration number: [2410/4518] 53% | Training loss: 0.6874215348380235
Epoch: 6 | Iteration number: [2420/4518] 53% | Training loss: 0.6874213015245012
Epoch: 6 | Iteration number: [2430/4518] 53% | Training loss: 0.6874201090247543
Epoch: 6 | Iteration number: [2440/4518] 54% | Training loss: 0.687417510127435
Epoch: 6 | Iteration number: [2450/4518] 54% | Training loss: 0.6874135708565615
Epoch: 6 | Iteration number: [2460/4518] 54% | Training loss: 0.6874169356696974
Epoch: 6 | Iteration number: [2470/4518] 54% | Training loss: 0.6874177423565977
Epoch: 6 | Iteration number: [2480/4518] 54% | Training loss: 0.6874203512264836
Epoch: 6 | Iteration number: [2490/4518] 55% | Training loss: 0.6874198291435778
Epoch: 6 | Iteration number: [2500/4518] 55% | Training loss: 0.6874188359022141
Epoch: 6 | Iteration number: [2510/4518] 55% | Training loss: 0.6874155252578249
Epoch: 6 | Iteration number: [2520/4518] 55% | Training loss: 0.6874194627006849
Epoch: 6 | Iteration number: [2530/4518] 55% | Training loss: 0.6874188775130411
Epoch: 6 | Iteration number: [2540/4518] 56% | Training loss: 0.6874154741369833
Epoch: 6 | Iteration number: [2550/4518] 56% | Training loss: 0.6874154207285713
Epoch: 6 | Iteration number: [2560/4518] 56% | Training loss: 0.6874128036666661
Epoch: 6 | Iteration number: [2570/4518] 56% | Training loss: 0.6874146729359831
Epoch: 6 | Iteration number: [2580/4518] 57% | Training loss: 0.6874108201080514
Epoch: 6 | Iteration number: [2590/4518] 57% | Training loss: 0.6874112123227948
Epoch: 6 | Iteration number: [2600/4518] 57% | Training loss: 0.6874120195553853
Epoch: 6 | Iteration number: [2610/4518] 57% | Training loss: 0.6874128392601379
Epoch: 6 | Iteration number: [2620/4518] 57% | Training loss: 0.6874106665603987
Epoch: 6 | Iteration number: [2630/4518] 58% | Training loss: 0.6874121062429233
Epoch: 6 | Iteration number: [2640/4518] 58% | Training loss: 0.6874155896631154
Epoch: 6 | Iteration number: [2650/4518] 58% | Training loss: 0.6874143022411274
Epoch: 6 | Iteration number: [2660/4518] 58% | Training loss: 0.6874173198875628
Epoch: 6 | Iteration number: [2670/4518] 59% | Training loss: 0.6874167214172163
Epoch: 6 | Iteration number: [2680/4518] 59% | Training loss: 0.6874135449528694
Epoch: 6 | Iteration number: [2690/4518] 59% | Training loss: 0.6874145189404044
Epoch: 6 | Iteration number: [2700/4518] 59% | Training loss: 0.6874182725394213
Epoch: 6 | Iteration number: [2710/4518] 59% | Training loss: 0.6874175595401398
Epoch: 6 | Iteration number: [2720/4518] 60% | Training loss: 0.687418158440029
Epoch: 6 | Iteration number: [2730/4518] 60% | Training loss: 0.6874163697054098
Epoch: 6 | Iteration number: [2740/4518] 60% | Training loss: 0.6874187985693452
Epoch: 6 | Iteration number: [2750/4518] 60% | Training loss: 0.6874142813249068
Epoch: 6 | Iteration number: [2760/4518] 61% | Training loss: 0.6874125584744025
Epoch: 6 | Iteration number: [2770/4518] 61% | Training loss: 0.6874127216933006
Epoch: 6 | Iteration number: [2780/4518] 61% | Training loss: 0.6874133311587272
Epoch: 6 | Iteration number: [2790/4518] 61% | Training loss: 0.6874081234137217
Epoch: 6 | Iteration number: [2800/4518] 61% | Training loss: 0.6874039781945093
Epoch: 6 | Iteration number: [2810/4518] 62% | Training loss: 0.687407408638781
Epoch: 6 | Iteration number: [2820/4518] 62% | Training loss: 0.6874059870944801
Epoch: 6 | Iteration number: [2830/4518] 62% | Training loss: 0.6874019827311957
Epoch: 6 | Iteration number: [2840/4518] 62% | Training loss: 0.6873973096970102
Epoch: 6 | Iteration number: [2850/4518] 63% | Training loss: 0.6874004490961109
Epoch: 6 | Iteration number: [2860/4518] 63% | Training loss: 0.6874002117377062
Epoch: 6 | Iteration number: [2870/4518] 63% | Training loss: 0.6874001282848132
Epoch: 6 | Iteration number: [2880/4518] 63% | Training loss: 0.6873949462133977
Epoch: 6 | Iteration number: [2890/4518] 63% | Training loss: 0.6873938249675461
Epoch: 6 | Iteration number: [2900/4518] 64% | Training loss: 0.6873869762543974
Epoch: 6 | Iteration number: [2910/4518] 64% | Training loss: 0.6873900610351891
Epoch: 6 | Iteration number: [2920/4518] 64% | Training loss: 0.6873898447172283
Epoch: 6 | Iteration number: [2930/4518] 64% | Training loss: 0.6873854858679983
Epoch: 6 | Iteration number: [2940/4518] 65% | Training loss: 0.6873854644849998
Epoch: 6 | Iteration number: [2950/4518] 65% | Training loss: 0.6873875765275147
Epoch: 6 | Iteration number: [2960/4518] 65% | Training loss: 0.6873828039781468
Epoch: 6 | Iteration number: [2970/4518] 65% | Training loss: 0.6873832937442895
Epoch: 6 | Iteration number: [2980/4518] 65% | Training loss: 0.6873818351318373
Epoch: 6 | Iteration number: [2990/4518] 66% | Training loss: 0.6873775886652063
Epoch: 6 | Iteration number: [3000/4518] 66% | Training loss: 0.6873768806258838
Epoch: 6 | Iteration number: [3010/4518] 66% | Training loss: 0.6873791384538542
Epoch: 6 | Iteration number: [3020/4518] 66% | Training loss: 0.6873789540387147
Epoch: 6 | Iteration number: [3030/4518] 67% | Training loss: 0.6873716284733008
Epoch: 6 | Iteration number: [3040/4518] 67% | Training loss: 0.6873703394673373
Epoch: 6 | Iteration number: [3050/4518] 67% | Training loss: 0.687371304660547
Epoch: 6 | Iteration number: [3060/4518] 67% | Training loss: 0.6873677013551488
Epoch: 6 | Iteration number: [3070/4518] 67% | Training loss: 0.6873699266669805
Epoch: 6 | Iteration number: [3080/4518] 68% | Training loss: 0.6873672849946207
Epoch: 6 | Iteration number: [3090/4518] 68% | Training loss: 0.6873684566383609
Epoch: 6 | Iteration number: [3100/4518] 68% | Training loss: 0.6873652468573662
Epoch: 6 | Iteration number: [3110/4518] 68% | Training loss: 0.6873671402693562
Epoch: 6 | Iteration number: [3120/4518] 69% | Training loss: 0.6873672597683393
Epoch: 6 | Iteration number: [3130/4518] 69% | Training loss: 0.6873688846350477
Epoch: 6 | Iteration number: [3140/4518] 69% | Training loss: 0.6873720042265145
Epoch: 6 | Iteration number: [3150/4518] 69% | Training loss: 0.6873710976328169
Epoch: 6 | Iteration number: [3160/4518] 69% | Training loss: 0.6873691471883013
Epoch: 6 | Iteration number: [3170/4518] 70% | Training loss: 0.687368453771158
Epoch: 6 | Iteration number: [3180/4518] 70% | Training loss: 0.687367219332629
Epoch: 6 | Iteration number: [3190/4518] 70% | Training loss: 0.687364928681275
Epoch: 6 | Iteration number: [3200/4518] 70% | Training loss: 0.6873687679134309
Epoch: 6 | Iteration number: [3210/4518] 71% | Training loss: 0.6873677929428136
Epoch: 6 | Iteration number: [3220/4518] 71% | Training loss: 0.687366984294068
Epoch: 6 | Iteration number: [3230/4518] 71% | Training loss: 0.6873660083710225
Epoch: 6 | Iteration number: [3240/4518] 71% | Training loss: 0.6873658759542454
Epoch: 6 | Iteration number: [3250/4518] 71% | Training loss: 0.6873668475151062
Epoch: 6 | Iteration number: [3260/4518] 72% | Training loss: 0.6873628586713522
Epoch: 6 | Iteration number: [3270/4518] 72% | Training loss: 0.6873592950517614
Epoch: 6 | Iteration number: [3280/4518] 72% | Training loss: 0.6873587484221633
Epoch: 6 | Iteration number: [3290/4518] 72% | Training loss: 0.6873571719442095
Epoch: 6 | Iteration number: [3300/4518] 73% | Training loss: 0.6873622210098035
Epoch: 6 | Iteration number: [3310/4518] 73% | Training loss: 0.6873591531799639
Epoch: 6 | Iteration number: [3320/4518] 73% | Training loss: 0.6873561682112246
Epoch: 6 | Iteration number: [3330/4518] 73% | Training loss: 0.6873554996900014
Epoch: 6 | Iteration number: [3340/4518] 73% | Training loss: 0.687354648220325
Epoch: 6 | Iteration number: [3350/4518] 74% | Training loss: 0.6873545376044601
Epoch: 6 | Iteration number: [3360/4518] 74% | Training loss: 0.6873532908480792
Epoch: 6 | Iteration number: [3370/4518] 74% | Training loss: 0.6873513905160151
Epoch: 6 | Iteration number: [3380/4518] 74% | Training loss: 0.6873486319589897
Epoch: 6 | Iteration number: [3390/4518] 75% | Training loss: 0.6873492316686298
Epoch: 6 | Iteration number: [3400/4518] 75% | Training loss: 0.6873445894437678
Epoch: 6 | Iteration number: [3410/4518] 75% | Training loss: 0.6873425975747821
Epoch: 6 | Iteration number: [3420/4518] 75% | Training loss: 0.6873422489877332
Epoch: 6 | Iteration number: [3430/4518] 75% | Training loss: 0.6873394205340838
Epoch: 6 | Iteration number: [3440/4518] 76% | Training loss: 0.6873367461527503
Epoch: 6 | Iteration number: [3450/4518] 76% | Training loss: 0.6873329858330712
Epoch: 6 | Iteration number: [3460/4518] 76% | Training loss: 0.687331806596993
Epoch: 6 | Iteration number: [3470/4518] 76% | Training loss: 0.68733589448228
Epoch: 6 | Iteration number: [3480/4518] 77% | Training loss: 0.6873369668407002
Epoch: 6 | Iteration number: [3490/4518] 77% | Training loss: 0.6873335734820981
Epoch: 6 | Iteration number: [3500/4518] 77% | Training loss: 0.6873322426251003
Epoch: 6 | Iteration number: [3510/4518] 77% | Training loss: 0.6873278860522811
Epoch: 6 | Iteration number: [3520/4518] 77% | Training loss: 0.6873275849629532
Epoch: 6 | Iteration number: [3530/4518] 78% | Training loss: 0.6873281330123502
Epoch: 6 | Iteration number: [3540/4518] 78% | Training loss: 0.6873264620533097
Epoch: 6 | Iteration number: [3550/4518] 78% | Training loss: 0.6873256911022563
Epoch: 6 | Iteration number: [3560/4518] 78% | Training loss: 0.6873271858424284
Epoch: 6 | Iteration number: [3570/4518] 79% | Training loss: 0.6873255872425913
Epoch: 6 | Iteration number: [3580/4518] 79% | Training loss: 0.6873271651774145
Epoch: 6 | Iteration number: [3590/4518] 79% | Training loss: 0.6873275106331764
Epoch: 6 | Iteration number: [3600/4518] 79% | Training loss: 0.6873223268157906
Epoch: 6 | Iteration number: [3610/4518] 79% | Training loss: 0.687325149295733
Epoch: 6 | Iteration number: [3620/4518] 80% | Training loss: 0.6873251212071319
Epoch: 6 | Iteration number: [3630/4518] 80% | Training loss: 0.6873299738592352
Epoch: 6 | Iteration number: [3640/4518] 80% | Training loss: 0.6873248117310661
Epoch: 6 | Iteration number: [3650/4518] 80% | Training loss: 0.68732316066141
Epoch: 6 | Iteration number: [3660/4518] 81% | Training loss: 0.6873208809420059
Epoch: 6 | Iteration number: [3670/4518] 81% | Training loss: 0.6873208811562458
Epoch: 6 | Iteration number: [3680/4518] 81% | Training loss: 0.6873157660436371
Epoch: 6 | Iteration number: [3690/4518] 81% | Training loss: 0.6873198256906132
Epoch: 6 | Iteration number: [3700/4518] 81% | Training loss: 0.6873209172326166
Epoch: 6 | Iteration number: [3710/4518] 82% | Training loss: 0.6873204216160221
Epoch: 6 | Iteration number: [3720/4518] 82% | Training loss: 0.6873217025751709
Epoch: 6 | Iteration number: [3730/4518] 82% | Training loss: 0.6873228320966777
Epoch: 6 | Iteration number: [3740/4518] 82% | Training loss: 0.687323798996242
Epoch: 6 | Iteration number: [3750/4518] 83% | Training loss: 0.6873209329287211
Epoch: 6 | Iteration number: [3760/4518] 83% | Training loss: 0.6873234653568014
Epoch: 6 | Iteration number: [3770/4518] 83% | Training loss: 0.6873188405675661
Epoch: 6 | Iteration number: [3780/4518] 83% | Training loss: 0.6873198523565575
Epoch: 6 | Iteration number: [3790/4518] 83% | Training loss: 0.687321503291344
Epoch: 6 | Iteration number: [3800/4518] 84% | Training loss: 0.6873178627616481
Epoch: 6 | Iteration number: [3810/4518] 84% | Training loss: 0.6873172694773186
Epoch: 6 | Iteration number: [3820/4518] 84% | Training loss: 0.6873163695266734
Epoch: 6 | Iteration number: [3830/4518] 84% | Training loss: 0.6873179149067433
Epoch: 6 | Iteration number: [3840/4518] 84% | Training loss: 0.6873207112929474
Epoch: 6 | Iteration number: [3850/4518] 85% | Training loss: 0.6873210211852928
Epoch: 6 | Iteration number: [3860/4518] 85% | Training loss: 0.6873237963167497
Epoch: 6 | Iteration number: [3870/4518] 85% | Training loss: 0.6873258465174249
Epoch: 6 | Iteration number: [3880/4518] 85% | Training loss: 0.6873268839317499
Epoch: 6 | Iteration number: [3890/4518] 86% | Training loss: 0.6873233042829754
Epoch: 6 | Iteration number: [3900/4518] 86% | Training loss: 0.6873192411508315
Epoch: 6 | Iteration number: [3910/4518] 86% | Training loss: 0.6873183877114445
Epoch: 6 | Iteration number: [3920/4518] 86% | Training loss: 0.6873201284025396
Epoch: 6 | Iteration number: [3930/4518] 86% | Training loss: 0.6873210849501098
Epoch: 6 | Iteration number: [3940/4518] 87% | Training loss: 0.6873193046919586
Epoch: 6 | Iteration number: [3950/4518] 87% | Training loss: 0.6873198922072785
Epoch: 6 | Iteration number: [3960/4518] 87% | Training loss: 0.6873198067148526
Epoch: 6 | Iteration number: [3970/4518] 87% | Training loss: 0.6873190908047655
Epoch: 6 | Iteration number: [3980/4518] 88% | Training loss: 0.6873208498235923
Epoch: 6 | Iteration number: [3990/4518] 88% | Training loss: 0.6873169693134183
Epoch: 6 | Iteration number: [4000/4518] 88% | Training loss: 0.6873194650262594
Epoch: 6 | Iteration number: [4010/4518] 88% | Training loss: 0.687318929398149
Epoch: 6 | Iteration number: [4020/4518] 88% | Training loss: 0.6873196944223707
Epoch: 6 | Iteration number: [4030/4518] 89% | Training loss: 0.6873163836617624
Epoch: 6 | Iteration number: [4040/4518] 89% | Training loss: 0.6873149897497479
Epoch: 6 | Iteration number: [4050/4518] 89% | Training loss: 0.6873120019759661
Epoch: 6 | Iteration number: [4060/4518] 89% | Training loss: 0.6873099407685801
Epoch: 6 | Iteration number: [4070/4518] 90% | Training loss: 0.6873075220889483
Epoch: 6 | Iteration number: [4080/4518] 90% | Training loss: 0.6873079249233591
Epoch: 6 | Iteration number: [4090/4518] 90% | Training loss: 0.6873068091338888
Epoch: 6 | Iteration number: [4100/4518] 90% | Training loss: 0.6873075483339589
Epoch: 6 | Iteration number: [4110/4518] 90% | Training loss: 0.6873052602701814
Epoch: 6 | Iteration number: [4120/4518] 91% | Training loss: 0.6873056138603433
Epoch: 6 | Iteration number: [4130/4518] 91% | Training loss: 0.6873052269292512
Epoch: 6 | Iteration number: [4140/4518] 91% | Training loss: 0.6873058096366228
Epoch: 6 | Iteration number: [4150/4518] 91% | Training loss: 0.6873055767438498
Epoch: 6 | Iteration number: [4160/4518] 92% | Training loss: 0.6873053340671155
Epoch: 6 | Iteration number: [4170/4518] 92% | Training loss: 0.6873039429279254
Epoch: 6 | Iteration number: [4180/4518] 92% | Training loss: 0.6873065342030457
Epoch: 6 | Iteration number: [4190/4518] 92% | Training loss: 0.6873039246458996
Epoch: 6 | Iteration number: [4200/4518] 92% | Training loss: 0.6873056030983017
Epoch: 6 | Iteration number: [4210/4518] 93% | Training loss: 0.687301341683168
Epoch: 6 | Iteration number: [4220/4518] 93% | Training loss: 0.6872999620381125
Epoch: 6 | Iteration number: [4230/4518] 93% | Training loss: 0.6873004267119911
Epoch: 6 | Iteration number: [4240/4518] 93% | Training loss: 0.6872986786489217
Epoch: 6 | Iteration number: [4250/4518] 94% | Training loss: 0.6872991012404946
Epoch: 6 | Iteration number: [4260/4518] 94% | Training loss: 0.6872974018955454
Epoch: 6 | Iteration number: [4270/4518] 94% | Training loss: 0.6872980567973447
Epoch: 6 | Iteration number: [4280/4518] 94% | Training loss: 0.6873007651940685
Epoch: 6 | Iteration number: [4290/4518] 94% | Training loss: 0.6873014430066089
Epoch: 6 | Iteration number: [4300/4518] 95% | Training loss: 0.6873024967797967
Epoch: 6 | Iteration number: [4310/4518] 95% | Training loss: 0.6873013899387174
Epoch: 6 | Iteration number: [4320/4518] 95% | Training loss: 0.6872972786150596
Epoch: 6 | Iteration number: [4330/4518] 95% | Training loss: 0.6872967706403886
Epoch: 6 | Iteration number: [4340/4518] 96% | Training loss: 0.6872959486625162
Epoch: 6 | Iteration number: [4350/4518] 96% | Training loss: 0.6872972438116183
Epoch: 6 | Iteration number: [4360/4518] 96% | Training loss: 0.6872978660218213
Epoch: 6 | Iteration number: [4370/4518] 96% | Training loss: 0.6872980663378124
Epoch: 6 | Iteration number: [4380/4518] 96% | Training loss: 0.6872982557369693
Epoch: 6 | Iteration number: [4390/4518] 97% | Training loss: 0.6872972977867431
Epoch: 6 | Iteration number: [4400/4518] 97% | Training loss: 0.6872958789223974
Epoch: 6 | Iteration number: [4410/4518] 97% | Training loss: 0.6872940600864471
Epoch: 6 | Iteration number: [4420/4518] 97% | Training loss: 0.6872928399575782
Epoch: 6 | Iteration number: [4430/4518] 98% | Training loss: 0.6872924848415513
Epoch: 6 | Iteration number: [4440/4518] 98% | Training loss: 0.6872898641067582
Epoch: 6 | Iteration number: [4450/4518] 98% | Training loss: 0.6872914414727286
Epoch: 6 | Iteration number: [4460/4518] 98% | Training loss: 0.6872928586508661
Epoch: 6 | Iteration number: [4470/4518] 98% | Training loss: 0.6872955535215552
Epoch: 6 | Iteration number: [4480/4518] 99% | Training loss: 0.6872968783735165
Epoch: 6 | Iteration number: [4490/4518] 99% | Training loss: 0.6872983995684006
Epoch: 6 | Iteration number: [4500/4518] 99% | Training loss: 0.6872943093776703
Epoch: 6 | Iteration number: [4510/4518] 99% | Training loss: 0.6872913458394898

 End of epoch: 6 | Train Loss: 0.6871398251871452 | Training Time: 641 

 End of epoch: 6 | Eval Loss: 0.6904641389846802 | Evaluating Time: 17 
Epoch: 7 | Iteration number: [10/4518] 0% | Training loss: 0.756425005197525
Epoch: 7 | Iteration number: [20/4518] 0% | Training loss: 0.7218997865915299
Epoch: 7 | Iteration number: [30/4518] 0% | Training loss: 0.7102349321047465
Epoch: 7 | Iteration number: [40/4518] 0% | Training loss: 0.70453981757164
Epoch: 7 | Iteration number: [50/4518] 1% | Training loss: 0.7011600017547608
Epoch: 7 | Iteration number: [60/4518] 1% | Training loss: 0.6987216353416443
Epoch: 7 | Iteration number: [70/4518] 1% | Training loss: 0.6972135433128902
Epoch: 7 | Iteration number: [80/4518] 1% | Training loss: 0.6959882125258445
Epoch: 7 | Iteration number: [90/4518] 1% | Training loss: 0.6950221525298225
Epoch: 7 | Iteration number: [100/4518] 2% | Training loss: 0.6942178297042847
Epoch: 7 | Iteration number: [110/4518] 2% | Training loss: 0.6935356692834334
Epoch: 7 | Iteration number: [120/4518] 2% | Training loss: 0.6929811403155327
Epoch: 7 | Iteration number: [130/4518] 2% | Training loss: 0.6925378061257876
Epoch: 7 | Iteration number: [140/4518] 3% | Training loss: 0.69217298243727
Epoch: 7 | Iteration number: [150/4518] 3% | Training loss: 0.6918770976861318
Epoch: 7 | Iteration number: [160/4518] 3% | Training loss: 0.6915448848158121
Epoch: 7 | Iteration number: [170/4518] 3% | Training loss: 0.6912769419305465
Epoch: 7 | Iteration number: [180/4518] 3% | Training loss: 0.6910160919030507
Epoch: 7 | Iteration number: [190/4518] 4% | Training loss: 0.6908112039691523
Epoch: 7 | Iteration number: [200/4518] 4% | Training loss: 0.6905400508642197
Epoch: 7 | Iteration number: [210/4518] 4% | Training loss: 0.6904209378219787
Epoch: 7 | Iteration number: [220/4518] 4% | Training loss: 0.6902575587684457
Epoch: 7 | Iteration number: [230/4518] 5% | Training loss: 0.6900876229223998
Epoch: 7 | Iteration number: [240/4518] 5% | Training loss: 0.6899474998315175
Epoch: 7 | Iteration number: [250/4518] 5% | Training loss: 0.6898227000236511
Epoch: 7 | Iteration number: [260/4518] 5% | Training loss: 0.6897148185051405
Epoch: 7 | Iteration number: [270/4518] 5% | Training loss: 0.6896088622234485
Epoch: 7 | Iteration number: [280/4518] 6% | Training loss: 0.6895088444863047
Epoch: 7 | Iteration number: [290/4518] 6% | Training loss: 0.6894802693662972
Epoch: 7 | Iteration number: [300/4518] 6% | Training loss: 0.6893787622451782
Epoch: 7 | Iteration number: [310/4518] 6% | Training loss: 0.6892813551810479
Epoch: 7 | Iteration number: [320/4518] 7% | Training loss: 0.6892289681360125
Epoch: 7 | Iteration number: [330/4518] 7% | Training loss: 0.6891255479870421
Epoch: 7 | Iteration number: [340/4518] 7% | Training loss: 0.6890517722157871
Epoch: 7 | Iteration number: [350/4518] 7% | Training loss: 0.6889788167817252
Epoch: 7 | Iteration number: [360/4518] 7% | Training loss: 0.6889117186268171
Epoch: 7 | Iteration number: [370/4518] 8% | Training loss: 0.68884046464353
Epoch: 7 | Iteration number: [380/4518] 8% | Training loss: 0.6887956652202104
Epoch: 7 | Iteration number: [390/4518] 8% | Training loss: 0.6887809146673252
Epoch: 7 | Iteration number: [400/4518] 8% | Training loss: 0.6887544290721417
Epoch: 7 | Iteration number: [410/4518] 9% | Training loss: 0.6887044359998005
Epoch: 7 | Iteration number: [420/4518] 9% | Training loss: 0.688663492600123
Epoch: 7 | Iteration number: [430/4518] 9% | Training loss: 0.6886336264222167
Epoch: 7 | Iteration number: [440/4518] 9% | Training loss: 0.68858699825677
Epoch: 7 | Iteration number: [450/4518] 9% | Training loss: 0.6885691559314728
Epoch: 7 | Iteration number: [460/4518] 10% | Training loss: 0.6885144799947739
Epoch: 7 | Iteration number: [470/4518] 10% | Training loss: 0.688506040420938
Epoch: 7 | Iteration number: [480/4518] 10% | Training loss: 0.6884851699074109
Epoch: 7 | Iteration number: [490/4518] 10% | Training loss: 0.6884511400242241
Epoch: 7 | Iteration number: [500/4518] 11% | Training loss: 0.6884499768018723
Epoch: 7 | Iteration number: [510/4518] 11% | Training loss: 0.6884128246821609
Epoch: 7 | Iteration number: [520/4518] 11% | Training loss: 0.6884066629868287
Epoch: 7 | Iteration number: [530/4518] 11% | Training loss: 0.6884124858199425
Epoch: 7 | Iteration number: [540/4518] 11% | Training loss: 0.6883858167462878
Epoch: 7 | Iteration number: [550/4518] 12% | Training loss: 0.688359228589318
Epoch: 7 | Iteration number: [560/4518] 12% | Training loss: 0.6883496324930872
Epoch: 7 | Iteration number: [570/4518] 12% | Training loss: 0.6883355668762274
Epoch: 7 | Iteration number: [580/4518] 12% | Training loss: 0.6882905545933493
Epoch: 7 | Iteration number: [590/4518] 13% | Training loss: 0.688265368392912
Epoch: 7 | Iteration number: [600/4518] 13% | Training loss: 0.6882664073506991
Epoch: 7 | Iteration number: [610/4518] 13% | Training loss: 0.688225876601016
Epoch: 7 | Iteration number: [620/4518] 13% | Training loss: 0.6882001911440203
Epoch: 7 | Iteration number: [630/4518] 13% | Training loss: 0.6881799241853139
Epoch: 7 | Iteration number: [640/4518] 14% | Training loss: 0.688173511158675
Epoch: 7 | Iteration number: [650/4518] 14% | Training loss: 0.6881556101028736
Epoch: 7 | Iteration number: [660/4518] 14% | Training loss: 0.6881345200719255
Epoch: 7 | Iteration number: [670/4518] 14% | Training loss: 0.6881169747950425
Epoch: 7 | Iteration number: [680/4518] 15% | Training loss: 0.6880866529310451
Epoch: 7 | Iteration number: [690/4518] 15% | Training loss: 0.6880769935207091
Epoch: 7 | Iteration number: [700/4518] 15% | Training loss: 0.6880550129073006
Epoch: 7 | Iteration number: [710/4518] 15% | Training loss: 0.688042543471699
Epoch: 7 | Iteration number: [720/4518] 15% | Training loss: 0.6880378437538942
Epoch: 7 | Iteration number: [730/4518] 16% | Training loss: 0.6880320309776149
Epoch: 7 | Iteration number: [740/4518] 16% | Training loss: 0.6880179975483869
Epoch: 7 | Iteration number: [750/4518] 16% | Training loss: 0.6879998829364776
Epoch: 7 | Iteration number: [760/4518] 16% | Training loss: 0.6879988791911226
Epoch: 7 | Iteration number: [770/4518] 17% | Training loss: 0.6879793699685629
Epoch: 7 | Iteration number: [780/4518] 17% | Training loss: 0.6879684942655074
Epoch: 7 | Iteration number: [790/4518] 17% | Training loss: 0.6879580308364917
Epoch: 7 | Iteration number: [800/4518] 17% | Training loss: 0.6879632049053908
Epoch: 7 | Iteration number: [810/4518] 17% | Training loss: 0.6879520232294812
Epoch: 7 | Iteration number: [820/4518] 18% | Training loss: 0.6879490904691743
Epoch: 7 | Iteration number: [830/4518] 18% | Training loss: 0.6879300303487893
Epoch: 7 | Iteration number: [840/4518] 18% | Training loss: 0.6879138552007221
Epoch: 7 | Iteration number: [850/4518] 18% | Training loss: 0.6879063379764557
Epoch: 7 | Iteration number: [860/4518] 19% | Training loss: 0.6879053218420161
Epoch: 7 | Iteration number: [870/4518] 19% | Training loss: 0.6878963872619059
Epoch: 7 | Iteration number: [880/4518] 19% | Training loss: 0.6878890097818592
Epoch: 7 | Iteration number: [890/4518] 19% | Training loss: 0.6878808709342829
Epoch: 7 | Iteration number: [900/4518] 19% | Training loss: 0.6878756803274154
Epoch: 7 | Iteration number: [910/4518] 20% | Training loss: 0.6878645763947413
Epoch: 7 | Iteration number: [920/4518] 20% | Training loss: 0.6878589990994205
Epoch: 7 | Iteration number: [930/4518] 20% | Training loss: 0.6878511296805515
Epoch: 7 | Iteration number: [940/4518] 20% | Training loss: 0.6878423333802122
Epoch: 7 | Iteration number: [950/4518] 21% | Training loss: 0.6878357613714118
Epoch: 7 | Iteration number: [960/4518] 21% | Training loss: 0.6878117718423407
Epoch: 7 | Iteration number: [970/4518] 21% | Training loss: 0.6878083174376144
Epoch: 7 | Iteration number: [980/4518] 21% | Training loss: 0.6878007668621686
Epoch: 7 | Iteration number: [990/4518] 21% | Training loss: 0.6877863104295249
Epoch: 7 | Iteration number: [1000/4518] 22% | Training loss: 0.687781703710556
Epoch: 7 | Iteration number: [1010/4518] 22% | Training loss: 0.6877742206696237
Epoch: 7 | Iteration number: [1020/4518] 22% | Training loss: 0.6877669645290748
Epoch: 7 | Iteration number: [1030/4518] 22% | Training loss: 0.6877476612919743
Epoch: 7 | Iteration number: [1040/4518] 23% | Training loss: 0.6877354445365759
Epoch: 7 | Iteration number: [1050/4518] 23% | Training loss: 0.6877243299711319
Epoch: 7 | Iteration number: [1060/4518] 23% | Training loss: 0.6877166027730366
Epoch: 7 | Iteration number: [1070/4518] 23% | Training loss: 0.6877068539089132
Epoch: 7 | Iteration number: [1080/4518] 23% | Training loss: 0.6877074028606768
Epoch: 7 | Iteration number: [1090/4518] 24% | Training loss: 0.6877061033467634
Epoch: 7 | Iteration number: [1100/4518] 24% | Training loss: 0.6877111177010969
Epoch: 7 | Iteration number: [1110/4518] 24% | Training loss: 0.6877130793558585
Epoch: 7 | Iteration number: [1120/4518] 24% | Training loss: 0.6876977254769632
Epoch: 7 | Iteration number: [1130/4518] 25% | Training loss: 0.6876923925581232
Epoch: 7 | Iteration number: [1140/4518] 25% | Training loss: 0.6876959747912591
Epoch: 7 | Iteration number: [1150/4518] 25% | Training loss: 0.6876912066729173
Epoch: 7 | Iteration number: [1160/4518] 25% | Training loss: 0.6876829800420794
Epoch: 7 | Iteration number: [1170/4518] 25% | Training loss: 0.6876945636720739
Epoch: 7 | Iteration number: [1180/4518] 26% | Training loss: 0.6876866370439529
Epoch: 7 | Iteration number: [1190/4518] 26% | Training loss: 0.6876742313889896
Epoch: 7 | Iteration number: [1200/4518] 26% | Training loss: 0.6876554550230503
Epoch: 7 | Iteration number: [1210/4518] 26% | Training loss: 0.6876676140737927
Epoch: 7 | Iteration number: [1220/4518] 27% | Training loss: 0.687665192074463
Epoch: 7 | Iteration number: [1230/4518] 27% | Training loss: 0.6876526306799757
Epoch: 7 | Iteration number: [1240/4518] 27% | Training loss: 0.6876501938989086
Epoch: 7 | Iteration number: [1250/4518] 27% | Training loss: 0.6876426558494568
Epoch: 7 | Iteration number: [1260/4518] 27% | Training loss: 0.6876431083395368
Epoch: 7 | Iteration number: [1270/4518] 28% | Training loss: 0.687633600666767
Epoch: 7 | Iteration number: [1280/4518] 28% | Training loss: 0.6876384147442878
Epoch: 7 | Iteration number: [1290/4518] 28% | Training loss: 0.6876420996447866
Epoch: 7 | Iteration number: [1300/4518] 28% | Training loss: 0.6876319215847896
Epoch: 7 | Iteration number: [1310/4518] 28% | Training loss: 0.6876300290795683
Epoch: 7 | Iteration number: [1320/4518] 29% | Training loss: 0.6876257243481549
Epoch: 7 | Iteration number: [1330/4518] 29% | Training loss: 0.6876217567831053
Epoch: 7 | Iteration number: [1340/4518] 29% | Training loss: 0.6876131458513772
Epoch: 7 | Iteration number: [1350/4518] 29% | Training loss: 0.6876065397704089
Epoch: 7 | Iteration number: [1360/4518] 30% | Training loss: 0.6876004005179686
Epoch: 7 | Iteration number: [1370/4518] 30% | Training loss: 0.6876084155409875
Epoch: 7 | Iteration number: [1380/4518] 30% | Training loss: 0.6876089470973913
Epoch: 7 | Iteration number: [1390/4518] 30% | Training loss: 0.6876088090508962
Epoch: 7 | Iteration number: [1400/4518] 30% | Training loss: 0.6876046444262777
Epoch: 7 | Iteration number: [1410/4518] 31% | Training loss: 0.6875962047289449
Epoch: 7 | Iteration number: [1420/4518] 31% | Training loss: 0.6875982226200507
Epoch: 7 | Iteration number: [1430/4518] 31% | Training loss: 0.6875959895707511
Epoch: 7 | Iteration number: [1440/4518] 31% | Training loss: 0.6875917371776369
Epoch: 7 | Iteration number: [1450/4518] 32% | Training loss: 0.6875805919334806
Epoch: 7 | Iteration number: [1460/4518] 32% | Training loss: 0.6875792790765631
Epoch: 7 | Iteration number: [1470/4518] 32% | Training loss: 0.687577117949116
Epoch: 7 | Iteration number: [1480/4518] 32% | Training loss: 0.6875688691396971
Epoch: 7 | Iteration number: [1490/4518] 32% | Training loss: 0.6875608267400088
Epoch: 7 | Iteration number: [1500/4518] 33% | Training loss: 0.6875584444602331
Epoch: 7 | Iteration number: [1510/4518] 33% | Training loss: 0.6875547000509225
Epoch: 7 | Iteration number: [1520/4518] 33% | Training loss: 0.6875440508127213
Epoch: 7 | Iteration number: [1530/4518] 33% | Training loss: 0.6875339354564941
Epoch: 7 | Iteration number: [1540/4518] 34% | Training loss: 0.6875323279724492
Epoch: 7 | Iteration number: [1550/4518] 34% | Training loss: 0.6875240046362723
Epoch: 7 | Iteration number: [1560/4518] 34% | Training loss: 0.6875129445623129
Epoch: 7 | Iteration number: [1570/4518] 34% | Training loss: 0.6875105674479418
Epoch: 7 | Iteration number: [1580/4518] 34% | Training loss: 0.687499987173684
Epoch: 7 | Iteration number: [1590/4518] 35% | Training loss: 0.6874989567687676
Epoch: 7 | Iteration number: [1600/4518] 35% | Training loss: 0.6874974640831352
Epoch: 7 | Iteration number: [1610/4518] 35% | Training loss: 0.6874924091448695
Epoch: 7 | Iteration number: [1620/4518] 35% | Training loss: 0.6874926226374544
Epoch: 7 | Iteration number: [1630/4518] 36% | Training loss: 0.6874864908815161
Epoch: 7 | Iteration number: [1640/4518] 36% | Training loss: 0.6874825500860446
Epoch: 7 | Iteration number: [1650/4518] 36% | Training loss: 0.6874828597993562
Epoch: 7 | Iteration number: [1660/4518] 36% | Training loss: 0.6874839577330164
Epoch: 7 | Iteration number: [1670/4518] 36% | Training loss: 0.6874867573112785
Epoch: 7 | Iteration number: [1680/4518] 37% | Training loss: 0.6874828883579799
Epoch: 7 | Iteration number: [1690/4518] 37% | Training loss: 0.6874776527373748
Epoch: 7 | Iteration number: [1700/4518] 37% | Training loss: 0.6874761347560322
Epoch: 7 | Iteration number: [1710/4518] 37% | Training loss: 0.6874671366828227
Epoch: 7 | Iteration number: [1720/4518] 38% | Training loss: 0.6874672707776691
Epoch: 7 | Iteration number: [1730/4518] 38% | Training loss: 0.6874658120849918
Epoch: 7 | Iteration number: [1740/4518] 38% | Training loss: 0.6874626403224879
Epoch: 7 | Iteration number: [1750/4518] 38% | Training loss: 0.6874578963007246
Epoch: 7 | Iteration number: [1760/4518] 38% | Training loss: 0.6874617662619461
Epoch: 7 | Iteration number: [1770/4518] 39% | Training loss: 0.6874644916273106
Epoch: 7 | Iteration number: [1780/4518] 39% | Training loss: 0.6874672147999988
Epoch: 7 | Iteration number: [1790/4518] 39% | Training loss: 0.6874630443543696
Epoch: 7 | Iteration number: [1800/4518] 39% | Training loss: 0.6874547058675025
Epoch: 7 | Iteration number: [1810/4518] 40% | Training loss: 0.6874504613612897
Epoch: 7 | Iteration number: [1820/4518] 40% | Training loss: 0.6874434708566456
Epoch: 7 | Iteration number: [1830/4518] 40% | Training loss: 0.6874393343925476
Epoch: 7 | Iteration number: [1840/4518] 40% | Training loss: 0.6874394413569699
Epoch: 7 | Iteration number: [1850/4518] 40% | Training loss: 0.687431643685779
Epoch: 7 | Iteration number: [1860/4518] 41% | Training loss: 0.6874286124462723
Epoch: 7 | Iteration number: [1870/4518] 41% | Training loss: 0.6874323055705922
Epoch: 7 | Iteration number: [1880/4518] 41% | Training loss: 0.6874280753921955
Epoch: 7 | Iteration number: [1890/4518] 41% | Training loss: 0.6874262020070717
Epoch: 7 | Iteration number: [1900/4518] 42% | Training loss: 0.6874238162291677
Epoch: 7 | Iteration number: [1910/4518] 42% | Training loss: 0.6874191983832114
Epoch: 7 | Iteration number: [1920/4518] 42% | Training loss: 0.6874106710466246
Epoch: 7 | Iteration number: [1930/4518] 42% | Training loss: 0.687409024998314
Epoch: 7 | Iteration number: [1940/4518] 42% | Training loss: 0.6874083674752836
Epoch: 7 | Iteration number: [1950/4518] 43% | Training loss: 0.6874038591446021
Epoch: 7 | Iteration number: [1960/4518] 43% | Training loss: 0.6874090319993544
Epoch: 7 | Iteration number: [1970/4518] 43% | Training loss: 0.6874057542249031
Epoch: 7 | Iteration number: [1980/4518] 43% | Training loss: 0.6874059826135636
Epoch: 7 | Iteration number: [1990/4518] 44% | Training loss: 0.6874059180818012
Epoch: 7 | Iteration number: [2000/4518] 44% | Training loss: 0.6874077332913876
Epoch: 7 | Iteration number: [2010/4518] 44% | Training loss: 0.6874079923131573
Epoch: 7 | Iteration number: [2020/4518] 44% | Training loss: 0.6874023355764918
Epoch: 7 | Iteration number: [2030/4518] 44% | Training loss: 0.6874034383907695
Epoch: 7 | Iteration number: [2040/4518] 45% | Training loss: 0.6874015493428006
Epoch: 7 | Iteration number: [2050/4518] 45% | Training loss: 0.6874013591103437
Epoch: 7 | Iteration number: [2060/4518] 45% | Training loss: 0.6874030102225184
Epoch: 7 | Iteration number: [2070/4518] 45% | Training loss: 0.6873973332165519
Epoch: 7 | Iteration number: [2080/4518] 46% | Training loss: 0.6873946749533598
Epoch: 7 | Iteration number: [2090/4518] 46% | Training loss: 0.6873942757052097
Epoch: 7 | Iteration number: [2100/4518] 46% | Training loss: 0.68739189630463
Epoch: 7 | Iteration number: [2110/4518] 46% | Training loss: 0.6873912241786577
Epoch: 7 | Iteration number: [2120/4518] 46% | Training loss: 0.6873875394744693
Epoch: 7 | Iteration number: [2130/4518] 47% | Training loss: 0.6873769362487704
Epoch: 7 | Iteration number: [2140/4518] 47% | Training loss: 0.6873727450025416
Epoch: 7 | Iteration number: [2150/4518] 47% | Training loss: 0.6873716848118361
Epoch: 7 | Iteration number: [2160/4518] 47% | Training loss: 0.6873759459566187
Epoch: 7 | Iteration number: [2170/4518] 48% | Training loss: 0.6873777822964752
Epoch: 7 | Iteration number: [2180/4518] 48% | Training loss: 0.6873731042266986
Epoch: 7 | Iteration number: [2190/4518] 48% | Training loss: 0.687370762460308
Epoch: 7 | Iteration number: [2200/4518] 48% | Training loss: 0.6873698554797606
Epoch: 7 | Iteration number: [2210/4518] 48% | Training loss: 0.6873749178189498
Epoch: 7 | Iteration number: [2220/4518] 49% | Training loss: 0.6873711701448973
Epoch: 7 | Iteration number: [2230/4518] 49% | Training loss: 0.6873599407384214
Epoch: 7 | Iteration number: [2240/4518] 49% | Training loss: 0.6873534964929734
Epoch: 7 | Iteration number: [2250/4518] 49% | Training loss: 0.6873521276844873
Epoch: 7 | Iteration number: [2260/4518] 50% | Training loss: 0.687347345120084
Epoch: 7 | Iteration number: [2270/4518] 50% | Training loss: 0.6873484383333097
Epoch: 7 | Iteration number: [2280/4518] 50% | Training loss: 0.6873466402815099
Epoch: 7 | Iteration number: [2290/4518] 50% | Training loss: 0.6873464767849602
Epoch: 7 | Iteration number: [2300/4518] 50% | Training loss: 0.6873404080971428
Epoch: 7 | Iteration number: [2310/4518] 51% | Training loss: 0.687345130722244
Epoch: 7 | Iteration number: [2320/4518] 51% | Training loss: 0.6873457897582959
Epoch: 7 | Iteration number: [2330/4518] 51% | Training loss: 0.6873476211093527
Epoch: 7 | Iteration number: [2340/4518] 51% | Training loss: 0.6873499541201143
Epoch: 7 | Iteration number: [2350/4518] 52% | Training loss: 0.6873529821507475
Epoch: 7 | Iteration number: [2360/4518] 52% | Training loss: 0.6873531770908227
Epoch: 7 | Iteration number: [2370/4518] 52% | Training loss: 0.6873530165555608
Epoch: 7 | Iteration number: [2380/4518] 52% | Training loss: 0.6873577875499965
Epoch: 7 | Iteration number: [2390/4518] 52% | Training loss: 0.6873593938151163
Epoch: 7 | Iteration number: [2400/4518] 53% | Training loss: 0.687360274195671
Epoch: 7 | Iteration number: [2410/4518] 53% | Training loss: 0.6873638429582366
Epoch: 7 | Iteration number: [2420/4518] 53% | Training loss: 0.6873639184581347
Epoch: 7 | Iteration number: [2430/4518] 53% | Training loss: 0.6873631428543923
Epoch: 7 | Iteration number: [2440/4518] 54% | Training loss: 0.6873641982430317
Epoch: 7 | Iteration number: [2450/4518] 54% | Training loss: 0.6873669851312832
Epoch: 7 | Iteration number: [2460/4518] 54% | Training loss: 0.6873645907252784
Epoch: 7 | Iteration number: [2470/4518] 54% | Training loss: 0.6873590195227248
Epoch: 7 | Iteration number: [2480/4518] 54% | Training loss: 0.6873578478492075
Epoch: 7 | Iteration number: [2490/4518] 55% | Training loss: 0.6873597879007638
Epoch: 7 | Iteration number: [2500/4518] 55% | Training loss: 0.6873597889184951
Epoch: 7 | Iteration number: [2510/4518] 55% | Training loss: 0.6873558018312036
Epoch: 7 | Iteration number: [2520/4518] 55% | Training loss: 0.6873546784832364
Epoch: 7 | Iteration number: [2530/4518] 55% | Training loss: 0.6873537100350904
Epoch: 7 | Iteration number: [2540/4518] 56% | Training loss: 0.687358529642811
Epoch: 7 | Iteration number: [2550/4518] 56% | Training loss: 0.6873587565562305
Epoch: 7 | Iteration number: [2560/4518] 56% | Training loss: 0.6873632976552472
Epoch: 7 | Iteration number: [2570/4518] 56% | Training loss: 0.6873602762760356
Epoch: 7 | Iteration number: [2580/4518] 57% | Training loss: 0.6873557696508806
Epoch: 7 | Iteration number: [2590/4518] 57% | Training loss: 0.6873546566282
Epoch: 7 | Iteration number: [2600/4518] 57% | Training loss: 0.6873556228325917
Epoch: 7 | Iteration number: [2610/4518] 57% | Training loss: 0.6873527493056666
Epoch: 7 | Iteration number: [2620/4518] 57% | Training loss: 0.6873504401618288
Epoch: 7 | Iteration number: [2630/4518] 58% | Training loss: 0.6873486836826846
Epoch: 7 | Iteration number: [2640/4518] 58% | Training loss: 0.6873442328789018
Epoch: 7 | Iteration number: [2650/4518] 58% | Training loss: 0.6873478514518377
Epoch: 7 | Iteration number: [2660/4518] 58% | Training loss: 0.6873426004908139
Epoch: 7 | Iteration number: [2670/4518] 59% | Training loss: 0.6873395239369253
Epoch: 7 | Iteration number: [2680/4518] 59% | Training loss: 0.6873391328685319
Epoch: 7 | Iteration number: [2690/4518] 59% | Training loss: 0.6873395334167551
Epoch: 7 | Iteration number: [2700/4518] 59% | Training loss: 0.6873354444901149
Epoch: 7 | Iteration number: [2710/4518] 59% | Training loss: 0.687335949696298
Epoch: 7 | Iteration number: [2720/4518] 60% | Training loss: 0.6873322000836625
Epoch: 7 | Iteration number: [2730/4518] 60% | Training loss: 0.6873265358336242
Epoch: 7 | Iteration number: [2740/4518] 60% | Training loss: 0.6873229378766387
Epoch: 7 | Iteration number: [2750/4518] 60% | Training loss: 0.6873211026841944
Epoch: 7 | Iteration number: [2760/4518] 61% | Training loss: 0.6873196092204771
Epoch: 7 | Iteration number: [2770/4518] 61% | Training loss: 0.6873198545151239
Epoch: 7 | Iteration number: [2780/4518] 61% | Training loss: 0.6873225795493709
Epoch: 7 | Iteration number: [2790/4518] 61% | Training loss: 0.6873281619454797
Epoch: 7 | Iteration number: [2800/4518] 61% | Training loss: 0.6873298056423665
Epoch: 7 | Iteration number: [2810/4518] 62% | Training loss: 0.6873282985118785
Epoch: 7 | Iteration number: [2820/4518] 62% | Training loss: 0.6873243765628084
Epoch: 7 | Iteration number: [2830/4518] 62% | Training loss: 0.6873245337826625
Epoch: 7 | Iteration number: [2840/4518] 62% | Training loss: 0.6873262454086626
Epoch: 7 | Iteration number: [2850/4518] 63% | Training loss: 0.6873270551781905
Epoch: 7 | Iteration number: [2860/4518] 63% | Training loss: 0.687327932665398
Epoch: 7 | Iteration number: [2870/4518] 63% | Training loss: 0.6873256613568561
Epoch: 7 | Iteration number: [2880/4518] 63% | Training loss: 0.6873239925959044
Epoch: 7 | Iteration number: [2890/4518] 63% | Training loss: 0.6873200001188629
Epoch: 7 | Iteration number: [2900/4518] 64% | Training loss: 0.6873195537410933
Epoch: 7 | Iteration number: [2910/4518] 64% | Training loss: 0.6873198696223322
Epoch: 7 | Iteration number: [2920/4518] 64% | Training loss: 0.6873171535665041
Epoch: 7 | Iteration number: [2930/4518] 64% | Training loss: 0.6873180466300391
Epoch: 7 | Iteration number: [2940/4518] 65% | Training loss: 0.6873197652652961
Epoch: 7 | Iteration number: [2950/4518] 65% | Training loss: 0.6873243665089042
Epoch: 7 | Iteration number: [2960/4518] 65% | Training loss: 0.6873304350553332
Epoch: 7 | Iteration number: [2970/4518] 65% | Training loss: 0.6873312376364313
Epoch: 7 | Iteration number: [2980/4518] 65% | Training loss: 0.6873290789607387
Epoch: 7 | Iteration number: [2990/4518] 66% | Training loss: 0.6873296714945382
Epoch: 7 | Iteration number: [3000/4518] 66% | Training loss: 0.6873304897149404
Epoch: 7 | Iteration number: [3010/4518] 66% | Training loss: 0.6873276426150553
Epoch: 7 | Iteration number: [3020/4518] 66% | Training loss: 0.6873267837904936
Epoch: 7 | Iteration number: [3030/4518] 67% | Training loss: 0.6873232893424459
Epoch: 7 | Iteration number: [3040/4518] 67% | Training loss: 0.6873232999718503
Epoch: 7 | Iteration number: [3050/4518] 67% | Training loss: 0.6873202815407612
Epoch: 7 | Iteration number: [3060/4518] 67% | Training loss: 0.687316163751035
Epoch: 7 | Iteration number: [3070/4518] 67% | Training loss: 0.6873131509324238
Epoch: 7 | Iteration number: [3080/4518] 68% | Training loss: 0.6873126440814563
Epoch: 7 | Iteration number: [3090/4518] 68% | Training loss: 0.6873118609286435
Epoch: 7 | Iteration number: [3100/4518] 68% | Training loss: 0.6873078035539196
Epoch: 7 | Iteration number: [3110/4518] 68% | Training loss: 0.6873046804279377
Epoch: 7 | Iteration number: [3120/4518] 69% | Training loss: 0.687300313799045
Epoch: 7 | Iteration number: [3130/4518] 69% | Training loss: 0.6873012699067783
Epoch: 7 | Iteration number: [3140/4518] 69% | Training loss: 0.6873010893726045
Epoch: 7 | Iteration number: [3150/4518] 69% | Training loss: 0.6872985205763862
Epoch: 7 | Iteration number: [3160/4518] 69% | Training loss: 0.6873000087240074
Epoch: 7 | Iteration number: [3170/4518] 70% | Training loss: 0.6873006245879345
Epoch: 7 | Iteration number: [3180/4518] 70% | Training loss: 0.6873030665723033
Epoch: 7 | Iteration number: [3190/4518] 70% | Training loss: 0.6873040661355918
Epoch: 7 | Iteration number: [3200/4518] 70% | Training loss: 0.6873027112148702
Epoch: 7 | Iteration number: [3210/4518] 71% | Training loss: 0.6873033781846364
Epoch: 7 | Iteration number: [3220/4518] 71% | Training loss: 0.6873008916466873
Epoch: 7 | Iteration number: [3230/4518] 71% | Training loss: 0.6872981839873843
Epoch: 7 | Iteration number: [3240/4518] 71% | Training loss: 0.6872972794153073
Epoch: 7 | Iteration number: [3250/4518] 71% | Training loss: 0.6872965886226067
Epoch: 7 | Iteration number: [3260/4518] 72% | Training loss: 0.6872931761609996
Epoch: 7 | Iteration number: [3270/4518] 72% | Training loss: 0.6872927795127262
Epoch: 7 | Iteration number: [3280/4518] 72% | Training loss: 0.687292363058503
Epoch: 7 | Iteration number: [3290/4518] 72% | Training loss: 0.6872897442894503
Epoch: 7 | Iteration number: [3300/4518] 73% | Training loss: 0.6872890161022995
Epoch: 7 | Iteration number: [3310/4518] 73% | Training loss: 0.6872922670084904
Epoch: 7 | Iteration number: [3320/4518] 73% | Training loss: 0.687289044637996
Epoch: 7 | Iteration number: [3330/4518] 73% | Training loss: 0.6872864213791695
Epoch: 7 | Iteration number: [3340/4518] 73% | Training loss: 0.6872866228668989
Epoch: 7 | Iteration number: [3350/4518] 74% | Training loss: 0.6872906735939766
Epoch: 7 | Iteration number: [3360/4518] 74% | Training loss: 0.6872901163463082
Epoch: 7 | Iteration number: [3370/4518] 74% | Training loss: 0.6872901606276764
Epoch: 7 | Iteration number: [3380/4518] 74% | Training loss: 0.6872892294057023
Epoch: 7 | Iteration number: [3390/4518] 75% | Training loss: 0.6872916636565441
Epoch: 7 | Iteration number: [3400/4518] 75% | Training loss: 0.6872888104705249
Epoch: 7 | Iteration number: [3410/4518] 75% | Training loss: 0.6872845784310372
Epoch: 7 | Iteration number: [3420/4518] 75% | Training loss: 0.6872868725779461
Epoch: 7 | Iteration number: [3430/4518] 75% | Training loss: 0.6872859575136757
Epoch: 7 | Iteration number: [3440/4518] 76% | Training loss: 0.6872882617767467
Epoch: 7 | Iteration number: [3450/4518] 76% | Training loss: 0.6872894030550252
Epoch: 7 | Iteration number: [3460/4518] 76% | Training loss: 0.6872867921701057
Epoch: 7 | Iteration number: [3470/4518] 76% | Training loss: 0.6872911078957384
Epoch: 7 | Iteration number: [3480/4518] 77% | Training loss: 0.6872926065976592
Epoch: 7 | Iteration number: [3490/4518] 77% | Training loss: 0.6872901450255539
Epoch: 7 | Iteration number: [3500/4518] 77% | Training loss: 0.6872899074724742
Epoch: 7 | Iteration number: [3510/4518] 77% | Training loss: 0.6872891408765418
Epoch: 7 | Iteration number: [3520/4518] 77% | Training loss: 0.6872882392596115
Epoch: 7 | Iteration number: [3530/4518] 78% | Training loss: 0.6872870908580488
Epoch: 7 | Iteration number: [3540/4518] 78% | Training loss: 0.6872813200378148
Epoch: 7 | Iteration number: [3550/4518] 78% | Training loss: 0.6872844858236716
Epoch: 7 | Iteration number: [3560/4518] 78% | Training loss: 0.687282378938091
Epoch: 7 | Iteration number: [3570/4518] 79% | Training loss: 0.68728500698127
Epoch: 7 | Iteration number: [3580/4518] 79% | Training loss: 0.687287897853878
Epoch: 7 | Iteration number: [3590/4518] 79% | Training loss: 0.6872823879911375
Epoch: 7 | Iteration number: [3600/4518] 79% | Training loss: 0.6872800663941436
Epoch: 7 | Iteration number: [3610/4518] 79% | Training loss: 0.6872820991063052
Epoch: 7 | Iteration number: [3620/4518] 80% | Training loss: 0.6872801286739539
Epoch: 7 | Iteration number: [3630/4518] 80% | Training loss: 0.687279340189679
Epoch: 7 | Iteration number: [3640/4518] 80% | Training loss: 0.6872790497901675
Epoch: 7 | Iteration number: [3650/4518] 80% | Training loss: 0.687277714732575
Epoch: 7 | Iteration number: [3660/4518] 81% | Training loss: 0.6872739959772819
Epoch: 7 | Iteration number: [3670/4518] 81% | Training loss: 0.6872708669637789
Epoch: 7 | Iteration number: [3680/4518] 81% | Training loss: 0.6872689941817004
Epoch: 7 | Iteration number: [3690/4518] 81% | Training loss: 0.6872702150486996
Epoch: 7 | Iteration number: [3700/4518] 81% | Training loss: 0.6872679725530986
Epoch: 7 | Iteration number: [3710/4518] 82% | Training loss: 0.6872687187316925
Epoch: 7 | Iteration number: [3720/4518] 82% | Training loss: 0.6872680483165607
Epoch: 7 | Iteration number: [3730/4518] 82% | Training loss: 0.6872663698950657
Epoch: 7 | Iteration number: [3740/4518] 82% | Training loss: 0.6872683244593003
Epoch: 7 | Iteration number: [3750/4518] 83% | Training loss: 0.6872705911636352
Epoch: 7 | Iteration number: [3760/4518] 83% | Training loss: 0.6872697189291741
Epoch: 7 | Iteration number: [3770/4518] 83% | Training loss: 0.6872694172973026
Epoch: 7 | Iteration number: [3780/4518] 83% | Training loss: 0.6872694012979982
Epoch: 7 | Iteration number: [3790/4518] 83% | Training loss: 0.6872666255937088
Epoch: 7 | Iteration number: [3800/4518] 84% | Training loss: 0.687264245826947
Epoch: 7 | Iteration number: [3810/4518] 84% | Training loss: 0.6872642099700887
Epoch: 7 | Iteration number: [3820/4518] 84% | Training loss: 0.6872613508663876
Epoch: 7 | Iteration number: [3830/4518] 84% | Training loss: 0.6872599744765627
Epoch: 7 | Iteration number: [3840/4518] 84% | Training loss: 0.6872574621345848
Epoch: 7 | Iteration number: [3850/4518] 85% | Training loss: 0.68725506982246
Epoch: 7 | Iteration number: [3860/4518] 85% | Training loss: 0.6872545981036566
Epoch: 7 | Iteration number: [3870/4518] 85% | Training loss: 0.6872559484585311
Epoch: 7 | Iteration number: [3880/4518] 85% | Training loss: 0.6872579742184619
Epoch: 7 | Iteration number: [3890/4518] 86% | Training loss: 0.6872568912555136
Epoch: 7 | Iteration number: [3900/4518] 86% | Training loss: 0.6872553775249384
Epoch: 7 | Iteration number: [3910/4518] 86% | Training loss: 0.687256062503361
Epoch: 7 | Iteration number: [3920/4518] 86% | Training loss: 0.6872558637389115
Epoch: 7 | Iteration number: [3930/4518] 86% | Training loss: 0.6872600569221506
Epoch: 7 | Iteration number: [3940/4518] 87% | Training loss: 0.6872578239682967
Epoch: 7 | Iteration number: [3950/4518] 87% | Training loss: 0.6872562770451172
Epoch: 7 | Iteration number: [3960/4518] 87% | Training loss: 0.6872541071941154
Epoch: 7 | Iteration number: [3970/4518] 87% | Training loss: 0.6872547003274
Epoch: 7 | Iteration number: [3980/4518] 88% | Training loss: 0.687253538852361
Epoch: 7 | Iteration number: [3990/4518] 88% | Training loss: 0.6872549367578407
Epoch: 7 | Iteration number: [4000/4518] 88% | Training loss: 0.6872555697560311
Epoch: 7 | Iteration number: [4010/4518] 88% | Training loss: 0.6872534499947269
Epoch: 7 | Iteration number: [4020/4518] 88% | Training loss: 0.6872565299569078
Epoch: 7 | Iteration number: [4030/4518] 89% | Training loss: 0.6872518587644875
Epoch: 7 | Iteration number: [4040/4518] 89% | Training loss: 0.6872518137687503
Epoch: 7 | Iteration number: [4050/4518] 89% | Training loss: 0.6872499420613418
Epoch: 7 | Iteration number: [4060/4518] 89% | Training loss: 0.6872469063756501
Epoch: 7 | Iteration number: [4070/4518] 90% | Training loss: 0.6872445074580519
Epoch: 7 | Iteration number: [4080/4518] 90% | Training loss: 0.6872433881111005
Epoch: 7 | Iteration number: [4090/4518] 90% | Training loss: 0.6872399195482212
Epoch: 7 | Iteration number: [4100/4518] 90% | Training loss: 0.6872366806210541
Epoch: 7 | Iteration number: [4110/4518] 90% | Training loss: 0.6872363973563025
Epoch: 7 | Iteration number: [4120/4518] 91% | Training loss: 0.6872349293197243
Epoch: 7 | Iteration number: [4130/4518] 91% | Training loss: 0.6872356992945544
Epoch: 7 | Iteration number: [4140/4518] 91% | Training loss: 0.687233139725699
Epoch: 7 | Iteration number: [4150/4518] 91% | Training loss: 0.6872310725321252
Epoch: 7 | Iteration number: [4160/4518] 92% | Training loss: 0.6872303302041614
Epoch: 7 | Iteration number: [4170/4518] 92% | Training loss: 0.6872312766041972
Epoch: 7 | Iteration number: [4180/4518] 92% | Training loss: 0.6872327694909994
Epoch: 7 | Iteration number: [4190/4518] 92% | Training loss: 0.6872360287532032
Epoch: 7 | Iteration number: [4200/4518] 92% | Training loss: 0.6872356440481685
Epoch: 7 | Iteration number: [4210/4518] 93% | Training loss: 0.687237570433039
Epoch: 7 | Iteration number: [4220/4518] 93% | Training loss: 0.6872370970898894
Epoch: 7 | Iteration number: [4230/4518] 93% | Training loss: 0.6872380163370858
Epoch: 7 | Iteration number: [4240/4518] 93% | Training loss: 0.6872361455745292
Epoch: 7 | Iteration number: [4250/4518] 94% | Training loss: 0.6872368807371925
Epoch: 7 | Iteration number: [4260/4518] 94% | Training loss: 0.6872346226038507
Epoch: 7 | Iteration number: [4270/4518] 94% | Training loss: 0.6872372182107921
Epoch: 7 | Iteration number: [4280/4518] 94% | Training loss: 0.687235592514555
Epoch: 7 | Iteration number: [4290/4518] 94% | Training loss: 0.6872351206404902
Epoch: 7 | Iteration number: [4300/4518] 95% | Training loss: 0.6872327926962875
Epoch: 7 | Iteration number: [4310/4518] 95% | Training loss: 0.6872338683173718
Epoch: 7 | Iteration number: [4320/4518] 95% | Training loss: 0.6872379981809192
Epoch: 7 | Iteration number: [4330/4518] 95% | Training loss: 0.6872383727074771
Epoch: 7 | Iteration number: [4340/4518] 96% | Training loss: 0.6872369233501672
Epoch: 7 | Iteration number: [4350/4518] 96% | Training loss: 0.6872334846408887
Epoch: 7 | Iteration number: [4360/4518] 96% | Training loss: 0.6872335821390152
Epoch: 7 | Iteration number: [4370/4518] 96% | Training loss: 0.6872338670205742
Epoch: 7 | Iteration number: [4380/4518] 96% | Training loss: 0.6872340039575481
Epoch: 7 | Iteration number: [4390/4518] 97% | Training loss: 0.6872328608209831
Epoch: 7 | Iteration number: [4400/4518] 97% | Training loss: 0.687231687632474
Epoch: 7 | Iteration number: [4410/4518] 97% | Training loss: 0.6872299260157847
Epoch: 7 | Iteration number: [4420/4518] 97% | Training loss: 0.6872315180787134
Epoch: 7 | Iteration number: [4430/4518] 98% | Training loss: 0.6872330315898827
Epoch: 7 | Iteration number: [4440/4518] 98% | Training loss: 0.6872332949090648
Epoch: 7 | Iteration number: [4450/4518] 98% | Training loss: 0.6872327603650896
Epoch: 7 | Iteration number: [4460/4518] 98% | Training loss: 0.6872331067986552
Epoch: 7 | Iteration number: [4470/4518] 98% | Training loss: 0.6872340040318918
Epoch: 7 | Iteration number: [4480/4518] 99% | Training loss: 0.687233362160623
Epoch: 7 | Iteration number: [4490/4518] 99% | Training loss: 0.6872358082264728
Epoch: 7 | Iteration number: [4500/4518] 99% | Training loss: 0.6872376801835166
Epoch: 7 | Iteration number: [4510/4518] 99% | Training loss: 0.6872357925924653

 End of epoch: 7 | Train Loss: 0.6870814958284681 | Training Time: 641 

 End of epoch: 7 | Eval Loss: 0.690278924241358 | Evaluating Time: 16 
Epoch: 8 | Iteration number: [10/4518] 0% | Training loss: 0.7566974878311157
Epoch: 8 | Iteration number: [20/4518] 0% | Training loss: 0.7219984024763108
Epoch: 8 | Iteration number: [30/4518] 0% | Training loss: 0.7102222959200541
Epoch: 8 | Iteration number: [40/4518] 0% | Training loss: 0.7043532952666283
Epoch: 8 | Iteration number: [50/4518] 1% | Training loss: 0.7006130409240723
Epoch: 8 | Iteration number: [60/4518] 1% | Training loss: 0.6983969658613205
Epoch: 8 | Iteration number: [70/4518] 1% | Training loss: 0.6966624328068325
Epoch: 8 | Iteration number: [80/4518] 1% | Training loss: 0.6955349840223789
Epoch: 8 | Iteration number: [90/4518] 1% | Training loss: 0.6946307765112982
Epoch: 8 | Iteration number: [100/4518] 2% | Training loss: 0.6939230567216873
Epoch: 8 | Iteration number: [110/4518] 2% | Training loss: 0.6931676702065901
Epoch: 8 | Iteration number: [120/4518] 2% | Training loss: 0.6925814022620519
Epoch: 8 | Iteration number: [130/4518] 2% | Training loss: 0.6921601300056164
Epoch: 8 | Iteration number: [140/4518] 3% | Training loss: 0.6917645390544619
Epoch: 8 | Iteration number: [150/4518] 3% | Training loss: 0.6914696101347605
Epoch: 8 | Iteration number: [160/4518] 3% | Training loss: 0.6911529649049044
Epoch: 8 | Iteration number: [170/4518] 3% | Training loss: 0.6908978002912858
Epoch: 8 | Iteration number: [180/4518] 3% | Training loss: 0.6906349973546134
Epoch: 8 | Iteration number: [190/4518] 4% | Training loss: 0.6904746184223577
Epoch: 8 | Iteration number: [200/4518] 4% | Training loss: 0.6904005631804466
Epoch: 8 | Iteration number: [210/4518] 4% | Training loss: 0.6902656274182456
Epoch: 8 | Iteration number: [220/4518] 4% | Training loss: 0.6901391744613647
Epoch: 8 | Iteration number: [230/4518] 5% | Training loss: 0.6900757693726084
Epoch: 8 | Iteration number: [240/4518] 5% | Training loss: 0.6899340793490409
Epoch: 8 | Iteration number: [250/4518] 5% | Training loss: 0.6897711267471314
Epoch: 8 | Iteration number: [260/4518] 5% | Training loss: 0.6896816792396399
Epoch: 8 | Iteration number: [270/4518] 5% | Training loss: 0.6896102483625766
Epoch: 8 | Iteration number: [280/4518] 6% | Training loss: 0.6895263467516218
Epoch: 8 | Iteration number: [290/4518] 6% | Training loss: 0.6894691960564975
Epoch: 8 | Iteration number: [300/4518] 6% | Training loss: 0.6893688909212748
Epoch: 8 | Iteration number: [310/4518] 6% | Training loss: 0.6893201906834879
Epoch: 8 | Iteration number: [320/4518] 7% | Training loss: 0.6892703749239445
Epoch: 8 | Iteration number: [330/4518] 7% | Training loss: 0.6892049581715555
Epoch: 8 | Iteration number: [340/4518] 7% | Training loss: 0.689123903653201
Epoch: 8 | Iteration number: [350/4518] 7% | Training loss: 0.6890810423237936
Epoch: 8 | Iteration number: [360/4518] 7% | Training loss: 0.6890387427475717
Epoch: 8 | Iteration number: [370/4518] 8% | Training loss: 0.6889888715099644
Epoch: 8 | Iteration number: [380/4518] 8% | Training loss: 0.6889344053833109
Epoch: 8 | Iteration number: [390/4518] 8% | Training loss: 0.6889016292034051
Epoch: 8 | Iteration number: [400/4518] 8% | Training loss: 0.6888299138844013
Epoch: 8 | Iteration number: [410/4518] 9% | Training loss: 0.6888036615964843
Epoch: 8 | Iteration number: [420/4518] 9% | Training loss: 0.68877652940296
Epoch: 8 | Iteration number: [430/4518] 9% | Training loss: 0.6887498553409133
Epoch: 8 | Iteration number: [440/4518] 9% | Training loss: 0.688724672794342
Epoch: 8 | Iteration number: [450/4518] 9% | Training loss: 0.6886889836523268
Epoch: 8 | Iteration number: [460/4518] 10% | Training loss: 0.6886497908312341
Epoch: 8 | Iteration number: [470/4518] 10% | Training loss: 0.688610699202152
Epoch: 8 | Iteration number: [480/4518] 10% | Training loss: 0.6885778490453959
Epoch: 8 | Iteration number: [490/4518] 10% | Training loss: 0.6885485585854978
Epoch: 8 | Iteration number: [500/4518] 11% | Training loss: 0.6885243822336197
Epoch: 8 | Iteration number: [510/4518] 11% | Training loss: 0.6884833127844567
Epoch: 8 | Iteration number: [520/4518] 11% | Training loss: 0.6884573239546555
Epoch: 8 | Iteration number: [530/4518] 11% | Training loss: 0.6884412135718003
Epoch: 8 | Iteration number: [540/4518] 11% | Training loss: 0.6883974455021046
Epoch: 8 | Iteration number: [550/4518] 12% | Training loss: 0.6883747444369576
Epoch: 8 | Iteration number: [560/4518] 12% | Training loss: 0.6883552070174899
Epoch: 8 | Iteration number: [570/4518] 12% | Training loss: 0.688340114187776
Epoch: 8 | Iteration number: [580/4518] 12% | Training loss: 0.6883105762045959
Epoch: 8 | Iteration number: [590/4518] 13% | Training loss: 0.688287928447885
Epoch: 8 | Iteration number: [600/4518] 13% | Training loss: 0.6882816564043363
Epoch: 8 | Iteration number: [610/4518] 13% | Training loss: 0.68827630691841
Epoch: 8 | Iteration number: [620/4518] 13% | Training loss: 0.688253479811453
Epoch: 8 | Iteration number: [630/4518] 13% | Training loss: 0.6882395338444482
Epoch: 8 | Iteration number: [640/4518] 14% | Training loss: 0.6882001354359091
Epoch: 8 | Iteration number: [650/4518] 14% | Training loss: 0.6881639567705301
Epoch: 8 | Iteration number: [660/4518] 14% | Training loss: 0.6881363992438172
Epoch: 8 | Iteration number: [670/4518] 14% | Training loss: 0.6881160829494248
Epoch: 8 | Iteration number: [680/4518] 15% | Training loss: 0.6881049934555502
Epoch: 8 | Iteration number: [690/4518] 15% | Training loss: 0.6880804898946181
Epoch: 8 | Iteration number: [700/4518] 15% | Training loss: 0.6880678552389144
Epoch: 8 | Iteration number: [710/4518] 15% | Training loss: 0.6880535396052079
Epoch: 8 | Iteration number: [720/4518] 15% | Training loss: 0.6880443233582708
Epoch: 8 | Iteration number: [730/4518] 16% | Training loss: 0.6880331491770809
Epoch: 8 | Iteration number: [740/4518] 16% | Training loss: 0.6880342500435339
Epoch: 8 | Iteration number: [750/4518] 16% | Training loss: 0.6880440538724264
Epoch: 8 | Iteration number: [760/4518] 16% | Training loss: 0.6880313236462442
Epoch: 8 | Iteration number: [770/4518] 17% | Training loss: 0.6880128344932159
Epoch: 8 | Iteration number: [780/4518] 17% | Training loss: 0.6879880118828553
Epoch: 8 | Iteration number: [790/4518] 17% | Training loss: 0.6879553322550617
Epoch: 8 | Iteration number: [800/4518] 17% | Training loss: 0.6879547843337059
Epoch: 8 | Iteration number: [810/4518] 17% | Training loss: 0.6879642045792238
Epoch: 8 | Iteration number: [820/4518] 18% | Training loss: 0.6879501330416377
Epoch: 8 | Iteration number: [830/4518] 18% | Training loss: 0.6879237106765609
Epoch: 8 | Iteration number: [840/4518] 18% | Training loss: 0.6879258221104032
Epoch: 8 | Iteration number: [850/4518] 18% | Training loss: 0.6879121403133168
Epoch: 8 | Iteration number: [860/4518] 19% | Training loss: 0.6878905931184458
Epoch: 8 | Iteration number: [870/4518] 19% | Training loss: 0.6878766346251828
Epoch: 8 | Iteration number: [880/4518] 19% | Training loss: 0.687875318188559
Epoch: 8 | Iteration number: [890/4518] 19% | Training loss: 0.687867022096441
Epoch: 8 | Iteration number: [900/4518] 19% | Training loss: 0.687866225639979
Epoch: 8 | Iteration number: [910/4518] 20% | Training loss: 0.6878490603887117
Epoch: 8 | Iteration number: [920/4518] 20% | Training loss: 0.6878355966314026
Epoch: 8 | Iteration number: [930/4518] 20% | Training loss: 0.6878274360651611
Epoch: 8 | Iteration number: [940/4518] 20% | Training loss: 0.6878155105291529
Epoch: 8 | Iteration number: [950/4518] 21% | Training loss: 0.6878039676264712
Epoch: 8 | Iteration number: [960/4518] 21% | Training loss: 0.6877995643764734
Epoch: 8 | Iteration number: [970/4518] 21% | Training loss: 0.6877782342360191
Epoch: 8 | Iteration number: [980/4518] 21% | Training loss: 0.687775646484628
Epoch: 8 | Iteration number: [990/4518] 21% | Training loss: 0.6877552554462896
Epoch: 8 | Iteration number: [1000/4518] 22% | Training loss: 0.6877379387021064
Epoch: 8 | Iteration number: [1010/4518] 22% | Training loss: 0.6877324000443562
Epoch: 8 | Iteration number: [1020/4518] 22% | Training loss: 0.6877245431437212
Epoch: 8 | Iteration number: [1030/4518] 22% | Training loss: 0.6877245352106187
Epoch: 8 | Iteration number: [1040/4518] 23% | Training loss: 0.6877256978016634
Epoch: 8 | Iteration number: [1050/4518] 23% | Training loss: 0.687717148065567
Epoch: 8 | Iteration number: [1060/4518] 23% | Training loss: 0.687707393518034
Epoch: 8 | Iteration number: [1070/4518] 23% | Training loss: 0.6877075029310779
Epoch: 8 | Iteration number: [1080/4518] 23% | Training loss: 0.687699022171674
Epoch: 8 | Iteration number: [1090/4518] 24% | Training loss: 0.6876832567770547
Epoch: 8 | Iteration number: [1100/4518] 24% | Training loss: 0.6876742545041171
Epoch: 8 | Iteration number: [1110/4518] 24% | Training loss: 0.6876756800724579
Epoch: 8 | Iteration number: [1120/4518] 24% | Training loss: 0.6876678648803916
Epoch: 8 | Iteration number: [1130/4518] 25% | Training loss: 0.6876546931477775
Epoch: 8 | Iteration number: [1140/4518] 25% | Training loss: 0.6876465666189528
Epoch: 8 | Iteration number: [1150/4518] 25% | Training loss: 0.6876405217854873
Epoch: 8 | Iteration number: [1160/4518] 25% | Training loss: 0.6876418475960863
Epoch: 8 | Iteration number: [1170/4518] 25% | Training loss: 0.6876247281702156
Epoch: 8 | Iteration number: [1180/4518] 26% | Training loss: 0.6876105763649536
Epoch: 8 | Iteration number: [1190/4518] 26% | Training loss: 0.6876002906250352
Epoch: 8 | Iteration number: [1200/4518] 26% | Training loss: 0.6875923204421998
Epoch: 8 | Iteration number: [1210/4518] 26% | Training loss: 0.6875766437408353
Epoch: 8 | Iteration number: [1220/4518] 27% | Training loss: 0.6875716405325248
Epoch: 8 | Iteration number: [1230/4518] 27% | Training loss: 0.6875607223530126
Epoch: 8 | Iteration number: [1240/4518] 27% | Training loss: 0.6875510895444501
Epoch: 8 | Iteration number: [1250/4518] 27% | Training loss: 0.6875486454963684
Epoch: 8 | Iteration number: [1260/4518] 27% | Training loss: 0.6875391109122171
Epoch: 8 | Iteration number: [1270/4518] 28% | Training loss: 0.6875338102419545
Epoch: 8 | Iteration number: [1280/4518] 28% | Training loss: 0.6875255091581494
Epoch: 8 | Iteration number: [1290/4518] 28% | Training loss: 0.6875171285729076
Epoch: 8 | Iteration number: [1300/4518] 28% | Training loss: 0.6875061070002042
Epoch: 8 | Iteration number: [1310/4518] 28% | Training loss: 0.6874938183158409
Epoch: 8 | Iteration number: [1320/4518] 29% | Training loss: 0.687487110179482
Epoch: 8 | Iteration number: [1330/4518] 29% | Training loss: 0.6874925915908097
Epoch: 8 | Iteration number: [1340/4518] 29% | Training loss: 0.6874731882294612
Epoch: 8 | Iteration number: [1350/4518] 29% | Training loss: 0.6874794498637871
Epoch: 8 | Iteration number: [1360/4518] 30% | Training loss: 0.6874717693556758
Epoch: 8 | Iteration number: [1370/4518] 30% | Training loss: 0.6874668298411544
Epoch: 8 | Iteration number: [1380/4518] 30% | Training loss: 0.6874565665704616
Epoch: 8 | Iteration number: [1390/4518] 30% | Training loss: 0.687453623426904
Epoch: 8 | Iteration number: [1400/4518] 30% | Training loss: 0.687458585202694
Epoch: 8 | Iteration number: [1410/4518] 31% | Training loss: 0.6874578317851885
Epoch: 8 | Iteration number: [1420/4518] 31% | Training loss: 0.6874531969218187
Epoch: 8 | Iteration number: [1430/4518] 31% | Training loss: 0.6874473728500046
Epoch: 8 | Iteration number: [1440/4518] 31% | Training loss: 0.6874463865740432
Epoch: 8 | Iteration number: [1450/4518] 32% | Training loss: 0.6874383807593378
Epoch: 8 | Iteration number: [1460/4518] 32% | Training loss: 0.6874290196046438
Epoch: 8 | Iteration number: [1470/4518] 32% | Training loss: 0.6874311649069494
Epoch: 8 | Iteration number: [1480/4518] 32% | Training loss: 0.6874272266755233
Epoch: 8 | Iteration number: [1490/4518] 32% | Training loss: 0.6874361659456419
Epoch: 8 | Iteration number: [1500/4518] 33% | Training loss: 0.6874288453261057
Epoch: 8 | Iteration number: [1510/4518] 33% | Training loss: 0.6874244399418105
Epoch: 8 | Iteration number: [1520/4518] 33% | Training loss: 0.6874286502599716
Epoch: 8 | Iteration number: [1530/4518] 33% | Training loss: 0.6874228482542474
Epoch: 8 | Iteration number: [1540/4518] 34% | Training loss: 0.687425563319937
Epoch: 8 | Iteration number: [1550/4518] 34% | Training loss: 0.6874236167630842
Epoch: 8 | Iteration number: [1560/4518] 34% | Training loss: 0.6874249459077151
Epoch: 8 | Iteration number: [1570/4518] 34% | Training loss: 0.6874169714891227
Epoch: 8 | Iteration number: [1580/4518] 34% | Training loss: 0.6874087666408926
Epoch: 8 | Iteration number: [1590/4518] 35% | Training loss: 0.6874116982678947
Epoch: 8 | Iteration number: [1600/4518] 35% | Training loss: 0.6874030563235283
Epoch: 8 | Iteration number: [1610/4518] 35% | Training loss: 0.6874017842067695
Epoch: 8 | Iteration number: [1620/4518] 35% | Training loss: 0.6873908190815538
Epoch: 8 | Iteration number: [1630/4518] 36% | Training loss: 0.68739008146561
Epoch: 8 | Iteration number: [1640/4518] 36% | Training loss: 0.6873914974128328
Epoch: 8 | Iteration number: [1650/4518] 36% | Training loss: 0.6873859965078758
Epoch: 8 | Iteration number: [1660/4518] 36% | Training loss: 0.6873787245118474
Epoch: 8 | Iteration number: [1670/4518] 36% | Training loss: 0.6873785265191587
Epoch: 8 | Iteration number: [1680/4518] 37% | Training loss: 0.6873724876769951
Epoch: 8 | Iteration number: [1690/4518] 37% | Training loss: 0.6873698764651485
Epoch: 8 | Iteration number: [1700/4518] 37% | Training loss: 0.6873676594565896
Epoch: 8 | Iteration number: [1710/4518] 37% | Training loss: 0.6873689479995192
Epoch: 8 | Iteration number: [1720/4518] 38% | Training loss: 0.6873674190668173
Epoch: 8 | Iteration number: [1730/4518] 38% | Training loss: 0.6873646804018517
Epoch: 8 | Iteration number: [1740/4518] 38% | Training loss: 0.6873667898534358
Epoch: 8 | Iteration number: [1750/4518] 38% | Training loss: 0.6873686923980713
Epoch: 8 | Iteration number: [1760/4518] 38% | Training loss: 0.6873670470985499
Epoch: 8 | Iteration number: [1770/4518] 39% | Training loss: 0.687365971884485
Epoch: 8 | Iteration number: [1780/4518] 39% | Training loss: 0.6873637678583017
Epoch: 8 | Iteration number: [1790/4518] 39% | Training loss: 0.6873658948437462
Epoch: 8 | Iteration number: [1800/4518] 39% | Training loss: 0.6873664577139749
Epoch: 8 | Iteration number: [1810/4518] 40% | Training loss: 0.6873559333013566
Epoch: 8 | Iteration number: [1820/4518] 40% | Training loss: 0.6873566477508335
Epoch: 8 | Iteration number: [1830/4518] 40% | Training loss: 0.6873564436787465
Epoch: 8 | Iteration number: [1840/4518] 40% | Training loss: 0.6873461446036463
Epoch: 8 | Iteration number: [1850/4518] 40% | Training loss: 0.6873453037803238
Epoch: 8 | Iteration number: [1860/4518] 41% | Training loss: 0.6873407419650785
Epoch: 8 | Iteration number: [1870/4518] 41% | Training loss: 0.6873353844339197
Epoch: 8 | Iteration number: [1880/4518] 41% | Training loss: 0.687335283451892
Epoch: 8 | Iteration number: [1890/4518] 41% | Training loss: 0.687340837149393
Epoch: 8 | Iteration number: [1900/4518] 42% | Training loss: 0.6873336053835718
Epoch: 8 | Iteration number: [1910/4518] 42% | Training loss: 0.6873301256389518
Epoch: 8 | Iteration number: [1920/4518] 42% | Training loss: 0.6873312335150937
Epoch: 8 | Iteration number: [1930/4518] 42% | Training loss: 0.6873229401408082
Epoch: 8 | Iteration number: [1940/4518] 42% | Training loss: 0.6873222708702087
Epoch: 8 | Iteration number: [1950/4518] 43% | Training loss: 0.6873174020571586
Epoch: 8 | Iteration number: [1960/4518] 43% | Training loss: 0.687312716458525
Epoch: 8 | Iteration number: [1970/4518] 43% | Training loss: 0.6873107014876332
Epoch: 8 | Iteration number: [1980/4518] 43% | Training loss: 0.6873116315916331
Epoch: 8 | Iteration number: [1990/4518] 44% | Training loss: 0.6873143864336925
Epoch: 8 | Iteration number: [2000/4518] 44% | Training loss: 0.6873138288259506
Epoch: 8 | Iteration number: [2010/4518] 44% | Training loss: 0.687315874550473
Epoch: 8 | Iteration number: [2020/4518] 44% | Training loss: 0.6873187249249751
Epoch: 8 | Iteration number: [2030/4518] 44% | Training loss: 0.6873219686775959
Epoch: 8 | Iteration number: [2040/4518] 45% | Training loss: 0.6873207416312367
Epoch: 8 | Iteration number: [2050/4518] 45% | Training loss: 0.6873246839860591
Epoch: 8 | Iteration number: [2060/4518] 45% | Training loss: 0.687327377512617
Epoch: 8 | Iteration number: [2070/4518] 45% | Training loss: 0.6873235960801443
Epoch: 8 | Iteration number: [2080/4518] 46% | Training loss: 0.6873259698828825
Epoch: 8 | Iteration number: [2090/4518] 46% | Training loss: 0.6873288237021871
Epoch: 8 | Iteration number: [2100/4518] 46% | Training loss: 0.687325852967444
Epoch: 8 | Iteration number: [2110/4518] 46% | Training loss: 0.6873232910700884
Epoch: 8 | Iteration number: [2120/4518] 46% | Training loss: 0.6873252710081497
Epoch: 8 | Iteration number: [2130/4518] 47% | Training loss: 0.6873269127008501
Epoch: 8 | Iteration number: [2140/4518] 47% | Training loss: 0.6873266596938962
Epoch: 8 | Iteration number: [2150/4518] 47% | Training loss: 0.6873271460034126
Epoch: 8 | Iteration number: [2160/4518] 47% | Training loss: 0.6873273624314202
Epoch: 8 | Iteration number: [2170/4518] 48% | Training loss: 0.6873275834019832
Epoch: 8 | Iteration number: [2180/4518] 48% | Training loss: 0.6873219097699594
Epoch: 8 | Iteration number: [2190/4518] 48% | Training loss: 0.6873206731663447
Epoch: 8 | Iteration number: [2200/4518] 48% | Training loss: 0.687318614423275
Epoch: 8 | Iteration number: [2210/4518] 48% | Training loss: 0.6873257860878474
Epoch: 8 | Iteration number: [2220/4518] 49% | Training loss: 0.6873258350131748
Epoch: 8 | Iteration number: [2230/4518] 49% | Training loss: 0.6873199875044715
Epoch: 8 | Iteration number: [2240/4518] 49% | Training loss: 0.6873236361891031
Epoch: 8 | Iteration number: [2250/4518] 49% | Training loss: 0.6873294888602363
Epoch: 8 | Iteration number: [2260/4518] 50% | Training loss: 0.687329886550397
Epoch: 8 | Iteration number: [2270/4518] 50% | Training loss: 0.6873288966485582
Epoch: 8 | Iteration number: [2280/4518] 50% | Training loss: 0.6873273633551179
Epoch: 8 | Iteration number: [2290/4518] 50% | Training loss: 0.6873295602059261
Epoch: 8 | Iteration number: [2300/4518] 50% | Training loss: 0.6873213083329408
Epoch: 8 | Iteration number: [2310/4518] 51% | Training loss: 0.6873292919619259
Epoch: 8 | Iteration number: [2320/4518] 51% | Training loss: 0.6873296305280308
Epoch: 8 | Iteration number: [2330/4518] 51% | Training loss: 0.6873286319648759
Epoch: 8 | Iteration number: [2340/4518] 51% | Training loss: 0.6873232074527659
Epoch: 8 | Iteration number: [2350/4518] 52% | Training loss: 0.6873259638725443
Epoch: 8 | Iteration number: [2360/4518] 52% | Training loss: 0.6873263704322152
Epoch: 8 | Iteration number: [2370/4518] 52% | Training loss: 0.6873207069147488
Epoch: 8 | Iteration number: [2380/4518] 52% | Training loss: 0.6873198869098135
Epoch: 8 | Iteration number: [2390/4518] 52% | Training loss: 0.687319730989105
Epoch: 8 | Iteration number: [2400/4518] 53% | Training loss: 0.6873165256033341
Epoch: 8 | Iteration number: [2410/4518] 53% | Training loss: 0.6873103504606303
Epoch: 8 | Iteration number: [2420/4518] 53% | Training loss: 0.6873105610944023
Epoch: 8 | Iteration number: [2430/4518] 53% | Training loss: 0.6873124059826258
Epoch: 8 | Iteration number: [2440/4518] 54% | Training loss: 0.687314637176326
Epoch: 8 | Iteration number: [2450/4518] 54% | Training loss: 0.687315769560483
Epoch: 8 | Iteration number: [2460/4518] 54% | Training loss: 0.6873163456112389
Epoch: 8 | Iteration number: [2470/4518] 54% | Training loss: 0.6873156397931489
Epoch: 8 | Iteration number: [2480/4518] 54% | Training loss: 0.6873147360259487
Epoch: 8 | Iteration number: [2490/4518] 55% | Training loss: 0.6873125492329578
Epoch: 8 | Iteration number: [2500/4518] 55% | Training loss: 0.6873118701457978
Epoch: 8 | Iteration number: [2510/4518] 55% | Training loss: 0.6873091585370174
Epoch: 8 | Iteration number: [2520/4518] 55% | Training loss: 0.6873052165858329
Epoch: 8 | Iteration number: [2530/4518] 55% | Training loss: 0.687301128796438
Epoch: 8 | Iteration number: [2540/4518] 56% | Training loss: 0.6872954646198768
Epoch: 8 | Iteration number: [2550/4518] 56% | Training loss: 0.6872969969814899
Epoch: 8 | Iteration number: [2560/4518] 56% | Training loss: 0.6873010796261951
Epoch: 8 | Iteration number: [2570/4518] 56% | Training loss: 0.6873061045134577
Epoch: 8 | Iteration number: [2580/4518] 57% | Training loss: 0.6873063689054445
Epoch: 8 | Iteration number: [2590/4518] 57% | Training loss: 0.6873072880575556
Epoch: 8 | Iteration number: [2600/4518] 57% | Training loss: 0.6873057574492234
Epoch: 8 | Iteration number: [2610/4518] 57% | Training loss: 0.6873017721249226
Epoch: 8 | Iteration number: [2620/4518] 57% | Training loss: 0.6872960855260151
Epoch: 8 | Iteration number: [2630/4518] 58% | Training loss: 0.6872974450370658
Epoch: 8 | Iteration number: [2640/4518] 58% | Training loss: 0.6872899493033235
Epoch: 8 | Iteration number: [2650/4518] 58% | Training loss: 0.6872896099540422
Epoch: 8 | Iteration number: [2660/4518] 58% | Training loss: 0.6872864407256134
Epoch: 8 | Iteration number: [2670/4518] 59% | Training loss: 0.68728334827816
Epoch: 8 | Iteration number: [2680/4518] 59% | Training loss: 0.6872805632317244
Epoch: 8 | Iteration number: [2690/4518] 59% | Training loss: 0.6872774045706682
Epoch: 8 | Iteration number: [2700/4518] 59% | Training loss: 0.6872794713355876
Epoch: 8 | Iteration number: [2710/4518] 59% | Training loss: 0.6872770246324504
Epoch: 8 | Iteration number: [2720/4518] 60% | Training loss: 0.6872757574652925
Epoch: 8 | Iteration number: [2730/4518] 60% | Training loss: 0.687274147040678
Epoch: 8 | Iteration number: [2740/4518] 60% | Training loss: 0.6872678310331637
Epoch: 8 | Iteration number: [2750/4518] 60% | Training loss: 0.6872703755768863
Epoch: 8 | Iteration number: [2760/4518] 61% | Training loss: 0.6872634654243787
Epoch: 8 | Iteration number: [2770/4518] 61% | Training loss: 0.6872651362677343
Epoch: 8 | Iteration number: [2780/4518] 61% | Training loss: 0.6872639376053707
Epoch: 8 | Iteration number: [2790/4518] 61% | Training loss: 0.6872654128672829
Epoch: 8 | Iteration number: [2800/4518] 61% | Training loss: 0.6872622703654425
Epoch: 8 | Iteration number: [2810/4518] 62% | Training loss: 0.6872623046309922
Epoch: 8 | Iteration number: [2820/4518] 62% | Training loss: 0.6872631887594859
Epoch: 8 | Iteration number: [2830/4518] 62% | Training loss: 0.6872667565362613
Epoch: 8 | Iteration number: [2840/4518] 62% | Training loss: 0.6872602862791276
Epoch: 8 | Iteration number: [2850/4518] 63% | Training loss: 0.6872603100015406
Epoch: 8 | Iteration number: [2860/4518] 63% | Training loss: 0.6872635495204192
Epoch: 8 | Iteration number: [2870/4518] 63% | Training loss: 0.687262533392225
Epoch: 8 | Iteration number: [2880/4518] 63% | Training loss: 0.6872627834065093
Epoch: 8 | Iteration number: [2890/4518] 63% | Training loss: 0.6872590703947734
Epoch: 8 | Iteration number: [2900/4518] 64% | Training loss: 0.6872571347705249
Epoch: 8 | Iteration number: [2910/4518] 64% | Training loss: 0.6872515119023339
Epoch: 8 | Iteration number: [2920/4518] 64% | Training loss: 0.6872519101590326
Epoch: 8 | Iteration number: [2930/4518] 64% | Training loss: 0.6872510235871064
Epoch: 8 | Iteration number: [2940/4518] 65% | Training loss: 0.6872513204002056
Epoch: 8 | Iteration number: [2950/4518] 65% | Training loss: 0.6872523532479496
Epoch: 8 | Iteration number: [2960/4518] 65% | Training loss: 0.6872508208695296
Epoch: 8 | Iteration number: [2970/4518] 65% | Training loss: 0.6872484048207601
Epoch: 8 | Iteration number: [2980/4518] 65% | Training loss: 0.6872464054782919
Epoch: 8 | Iteration number: [2990/4518] 66% | Training loss: 0.6872485882661813
Epoch: 8 | Iteration number: [3000/4518] 66% | Training loss: 0.6872480068405469
Epoch: 8 | Iteration number: [3010/4518] 66% | Training loss: 0.6872535898241886
Epoch: 8 | Iteration number: [3020/4518] 66% | Training loss: 0.6872531288704335
Epoch: 8 | Iteration number: [3030/4518] 67% | Training loss: 0.6872523673296762
Epoch: 8 | Iteration number: [3040/4518] 67% | Training loss: 0.6872498733432669
Epoch: 8 | Iteration number: [3050/4518] 67% | Training loss: 0.6872490440431188
Epoch: 8 | Iteration number: [3060/4518] 67% | Training loss: 0.6872460742791494
Epoch: 8 | Iteration number: [3070/4518] 67% | Training loss: 0.6872419865589576
Epoch: 8 | Iteration number: [3080/4518] 68% | Training loss: 0.6872369776491994
Epoch: 8 | Iteration number: [3090/4518] 68% | Training loss: 0.6872367286566392
Epoch: 8 | Iteration number: [3100/4518] 68% | Training loss: 0.6872333763491723
Epoch: 8 | Iteration number: [3110/4518] 68% | Training loss: 0.687231382430558
Epoch: 8 | Iteration number: [3120/4518] 69% | Training loss: 0.6872305334569552
Epoch: 8 | Iteration number: [3130/4518] 69% | Training loss: 0.6872313117638182
Epoch: 8 | Iteration number: [3140/4518] 69% | Training loss: 0.6872296053512841
Epoch: 8 | Iteration number: [3150/4518] 69% | Training loss: 0.6872307145406329
Epoch: 8 | Iteration number: [3160/4518] 69% | Training loss: 0.68723129581047
Epoch: 8 | Iteration number: [3170/4518] 70% | Training loss: 0.6872312636593539
Epoch: 8 | Iteration number: [3180/4518] 70% | Training loss: 0.6872304649098114
Epoch: 8 | Iteration number: [3190/4518] 70% | Training loss: 0.6872291102678425
Epoch: 8 | Iteration number: [3200/4518] 70% | Training loss: 0.6872294523566961
Epoch: 8 | Iteration number: [3210/4518] 71% | Training loss: 0.6872291851823575
Epoch: 8 | Iteration number: [3220/4518] 71% | Training loss: 0.6872267916150715
Epoch: 8 | Iteration number: [3230/4518] 71% | Training loss: 0.6872280553213952
Epoch: 8 | Iteration number: [3240/4518] 71% | Training loss: 0.6872295001958624
Epoch: 8 | Iteration number: [3250/4518] 71% | Training loss: 0.6872298000409053
Epoch: 8 | Iteration number: [3260/4518] 72% | Training loss: 0.6872308396305775
Epoch: 8 | Iteration number: [3270/4518] 72% | Training loss: 0.6872315836608957
Epoch: 8 | Iteration number: [3280/4518] 72% | Training loss: 0.6872301495838457
Epoch: 8 | Iteration number: [3290/4518] 72% | Training loss: 0.6872307981582398
Epoch: 8 | Iteration number: [3300/4518] 73% | Training loss: 0.6872306552258405
Epoch: 8 | Iteration number: [3310/4518] 73% | Training loss: 0.6872347528120543
Epoch: 8 | Iteration number: [3320/4518] 73% | Training loss: 0.6872365433229022
Epoch: 8 | Iteration number: [3330/4518] 73% | Training loss: 0.6872383197327634
Epoch: 8 | Iteration number: [3340/4518] 73% | Training loss: 0.687237804146584
Epoch: 8 | Iteration number: [3350/4518] 74% | Training loss: 0.6872362540195237
Epoch: 8 | Iteration number: [3360/4518] 74% | Training loss: 0.6872353195079736
Epoch: 8 | Iteration number: [3370/4518] 74% | Training loss: 0.6872335312451382
Epoch: 8 | Iteration number: [3380/4518] 74% | Training loss: 0.6872336482684288
Epoch: 8 | Iteration number: [3390/4518] 75% | Training loss: 0.6872325249829475
Epoch: 8 | Iteration number: [3400/4518] 75% | Training loss: 0.6872324539633359
Epoch: 8 | Iteration number: [3410/4518] 75% | Training loss: 0.687230920319683
Epoch: 8 | Iteration number: [3420/4518] 75% | Training loss: 0.6872300569774115
Epoch: 8 | Iteration number: [3430/4518] 75% | Training loss: 0.6872272614313631
Epoch: 8 | Iteration number: [3440/4518] 76% | Training loss: 0.6872261838510979
Epoch: 8 | Iteration number: [3450/4518] 76% | Training loss: 0.6872252898458121
Epoch: 8 | Iteration number: [3460/4518] 76% | Training loss: 0.6872211034415086
Epoch: 8 | Iteration number: [3470/4518] 76% | Training loss: 0.6872238582424197
Epoch: 8 | Iteration number: [3480/4518] 77% | Training loss: 0.6872241042982573
Epoch: 8 | Iteration number: [3490/4518] 77% | Training loss: 0.6872211900344892
Epoch: 8 | Iteration number: [3500/4518] 77% | Training loss: 0.6872194570473262
Epoch: 8 | Iteration number: [3510/4518] 77% | Training loss: 0.6872209203718734
Epoch: 8 | Iteration number: [3520/4518] 77% | Training loss: 0.687218480032276
Epoch: 8 | Iteration number: [3530/4518] 78% | Training loss: 0.6872149652360857
Epoch: 8 | Iteration number: [3540/4518] 78% | Training loss: 0.687213930925407
Epoch: 8 | Iteration number: [3550/4518] 78% | Training loss: 0.6872137094215608
Epoch: 8 | Iteration number: [3560/4518] 78% | Training loss: 0.6872146031327462
Epoch: 8 | Iteration number: [3570/4518] 79% | Training loss: 0.687216694865908
Epoch: 8 | Iteration number: [3580/4518] 79% | Training loss: 0.6872167445760865
Epoch: 8 | Iteration number: [3590/4518] 79% | Training loss: 0.6872166128543759
Epoch: 8 | Iteration number: [3600/4518] 79% | Training loss: 0.6872170545823044
Epoch: 8 | Iteration number: [3610/4518] 79% | Training loss: 0.6872158917528771
Epoch: 8 | Iteration number: [3620/4518] 80% | Training loss: 0.6872168957199181
Epoch: 8 | Iteration number: [3630/4518] 80% | Training loss: 0.6872181243476132
Epoch: 8 | Iteration number: [3640/4518] 80% | Training loss: 0.6872198098308437
Epoch: 8 | Iteration number: [3650/4518] 80% | Training loss: 0.687219205784471
Epoch: 8 | Iteration number: [3660/4518] 81% | Training loss: 0.6872174039401643
Epoch: 8 | Iteration number: [3670/4518] 81% | Training loss: 0.6872178094750854
Epoch: 8 | Iteration number: [3680/4518] 81% | Training loss: 0.687215581730656
Epoch: 8 | Iteration number: [3690/4518] 81% | Training loss: 0.6872161502922131
Epoch: 8 | Iteration number: [3700/4518] 81% | Training loss: 0.6872161836559708
Epoch: 8 | Iteration number: [3710/4518] 82% | Training loss: 0.6872113385772448
Epoch: 8 | Iteration number: [3720/4518] 82% | Training loss: 0.687210469108115
Epoch: 8 | Iteration number: [3730/4518] 82% | Training loss: 0.6872112652251932
Epoch: 8 | Iteration number: [3740/4518] 82% | Training loss: 0.6872086378023586
Epoch: 8 | Iteration number: [3750/4518] 83% | Training loss: 0.6872084134419759
Epoch: 8 | Iteration number: [3760/4518] 83% | Training loss: 0.6872081306545024
Epoch: 8 | Iteration number: [3770/4518] 83% | Training loss: 0.6872087413973771
Epoch: 8 | Iteration number: [3780/4518] 83% | Training loss: 0.6872078719908599
Epoch: 8 | Iteration number: [3790/4518] 83% | Training loss: 0.6872076901565441
Epoch: 8 | Iteration number: [3800/4518] 84% | Training loss: 0.6872029514375486
Epoch: 8 | Iteration number: [3810/4518] 84% | Training loss: 0.6872025582264728
Epoch: 8 | Iteration number: [3820/4518] 84% | Training loss: 0.6872036672075381
Epoch: 8 | Iteration number: [3830/4518] 84% | Training loss: 0.6872018522444344
Epoch: 8 | Iteration number: [3840/4518] 84% | Training loss: 0.6872019642343123
Epoch: 8 | Iteration number: [3850/4518] 85% | Training loss: 0.6872002810162383
Epoch: 8 | Iteration number: [3860/4518] 85% | Training loss: 0.6872039081673548
Epoch: 8 | Iteration number: [3870/4518] 85% | Training loss: 0.6872039355972941
Epoch: 8 | Iteration number: [3880/4518] 85% | Training loss: 0.6872056941549802
Epoch: 8 | Iteration number: [3890/4518] 86% | Training loss: 0.6872065049517124
Epoch: 8 | Iteration number: [3900/4518] 86% | Training loss: 0.6872075622815352
Epoch: 8 | Iteration number: [3910/4518] 86% | Training loss: 0.6872075488652719
Epoch: 8 | Iteration number: [3920/4518] 86% | Training loss: 0.6872062790302598
Epoch: 8 | Iteration number: [3930/4518] 86% | Training loss: 0.6872081582479501
Epoch: 8 | Iteration number: [3940/4518] 87% | Training loss: 0.6872087682715528
Epoch: 8 | Iteration number: [3950/4518] 87% | Training loss: 0.6872069372255591
Epoch: 8 | Iteration number: [3960/4518] 87% | Training loss: 0.6872040921389454
Epoch: 8 | Iteration number: [3970/4518] 87% | Training loss: 0.6872025256943642
Epoch: 8 | Iteration number: [3980/4518] 88% | Training loss: 0.6872048009130823
Epoch: 8 | Iteration number: [3990/4518] 88% | Training loss: 0.6872044954234198
Epoch: 8 | Iteration number: [4000/4518] 88% | Training loss: 0.6872033985555172
Epoch: 8 | Iteration number: [4010/4518] 88% | Training loss: 0.6872022194606705
Epoch: 8 | Iteration number: [4020/4518] 88% | Training loss: 0.6872039455976059
Epoch: 8 | Iteration number: [4030/4518] 89% | Training loss: 0.6872042669256035
Epoch: 8 | Iteration number: [4040/4518] 89% | Training loss: 0.6872053481269591
Epoch: 8 | Iteration number: [4050/4518] 89% | Training loss: 0.6872062326802147
Epoch: 8 | Iteration number: [4060/4518] 89% | Training loss: 0.6872075655924276
Epoch: 8 | Iteration number: [4070/4518] 90% | Training loss: 0.687211104854026
Epoch: 8 | Iteration number: [4080/4518] 90% | Training loss: 0.6872117641217569
Epoch: 8 | Iteration number: [4090/4518] 90% | Training loss: 0.6872121207434274
Epoch: 8 | Iteration number: [4100/4518] 90% | Training loss: 0.6872133256894786
Epoch: 8 | Iteration number: [4110/4518] 90% | Training loss: 0.687214050182751
Epoch: 8 | Iteration number: [4120/4518] 91% | Training loss: 0.687214003836067
Epoch: 8 | Iteration number: [4130/4518] 91% | Training loss: 0.687215488211006
Epoch: 8 | Iteration number: [4140/4518] 91% | Training loss: 0.6872163725935895
Epoch: 8 | Iteration number: [4150/4518] 91% | Training loss: 0.68721519118332
Epoch: 8 | Iteration number: [4160/4518] 92% | Training loss: 0.6872131977516871
Epoch: 8 | Iteration number: [4170/4518] 92% | Training loss: 0.6872152349217047
Epoch: 8 | Iteration number: [4180/4518] 92% | Training loss: 0.6872150975979116
Epoch: 8 | Iteration number: [4190/4518] 92% | Training loss: 0.6872125059579608
Epoch: 8 | Iteration number: [4200/4518] 92% | Training loss: 0.6872109837475278
Epoch: 8 | Iteration number: [4210/4518] 93% | Training loss: 0.6872111391143391
Epoch: 8 | Iteration number: [4220/4518] 93% | Training loss: 0.6872076354603067
Epoch: 8 | Iteration number: [4230/4518] 93% | Training loss: 0.6872042121616662
Epoch: 8 | Iteration number: [4240/4518] 93% | Training loss: 0.6872045008079061
Epoch: 8 | Iteration number: [4250/4518] 94% | Training loss: 0.6872021156339084
Epoch: 8 | Iteration number: [4260/4518] 94% | Training loss: 0.6872014487853073
Epoch: 8 | Iteration number: [4270/4518] 94% | Training loss: 0.6872017436200618
Epoch: 8 | Iteration number: [4280/4518] 94% | Training loss: 0.6872002537423205
Epoch: 8 | Iteration number: [4290/4518] 94% | Training loss: 0.6872002834484572
Epoch: 8 | Iteration number: [4300/4518] 95% | Training loss: 0.6871996145747429
Epoch: 8 | Iteration number: [4310/4518] 95% | Training loss: 0.6871954618224965
Epoch: 8 | Iteration number: [4320/4518] 95% | Training loss: 0.6871974828204623
Epoch: 8 | Iteration number: [4330/4518] 95% | Training loss: 0.6871976043831118
Epoch: 8 | Iteration number: [4340/4518] 96% | Training loss: 0.6871970465793038
Epoch: 8 | Iteration number: [4350/4518] 96% | Training loss: 0.6871969538858567
Epoch: 8 | Iteration number: [4360/4518] 96% | Training loss: 0.6871962159188516
Epoch: 8 | Iteration number: [4370/4518] 96% | Training loss: 0.6871942863311593
Epoch: 8 | Iteration number: [4380/4518] 96% | Training loss: 0.6871950810086237
Epoch: 8 | Iteration number: [4390/4518] 97% | Training loss: 0.68719532090602
Epoch: 8 | Iteration number: [4400/4518] 97% | Training loss: 0.6871919463710351
Epoch: 8 | Iteration number: [4410/4518] 97% | Training loss: 0.6871945520917845
Epoch: 8 | Iteration number: [4420/4518] 97% | Training loss: 0.6871931058249322
Epoch: 8 | Iteration number: [4430/4518] 98% | Training loss: 0.6871926259375587
Epoch: 8 | Iteration number: [4440/4518] 98% | Training loss: 0.6871913487846787
Epoch: 8 | Iteration number: [4450/4518] 98% | Training loss: 0.6871926853094208
Epoch: 8 | Iteration number: [4460/4518] 98% | Training loss: 0.6871931386769086
Epoch: 8 | Iteration number: [4470/4518] 98% | Training loss: 0.6871960454205805
Epoch: 8 | Iteration number: [4480/4518] 99% | Training loss: 0.6871945676526853
Epoch: 8 | Iteration number: [4490/4518] 99% | Training loss: 0.6871951398976927
Epoch: 8 | Iteration number: [4500/4518] 99% | Training loss: 0.6871951895554861
Epoch: 8 | Iteration number: [4510/4518] 99% | Training loss: 0.6871963262029339

 End of epoch: 8 | Train Loss: 0.6870441582810831 | Training Time: 641 

 End of epoch: 8 | Eval Loss: 0.6903593114444188 | Evaluating Time: 17 
Epoch: 9 | Iteration number: [10/4518] 0% | Training loss: 0.7569565534591675
Epoch: 9 | Iteration number: [20/4518] 0% | Training loss: 0.7223196178674698
Epoch: 9 | Iteration number: [30/4518] 0% | Training loss: 0.7106535494327545
Epoch: 9 | Iteration number: [40/4518] 0% | Training loss: 0.7050221860408783
Epoch: 9 | Iteration number: [50/4518] 1% | Training loss: 0.7014084196090699
Epoch: 9 | Iteration number: [60/4518] 1% | Training loss: 0.6989525149265925
Epoch: 9 | Iteration number: [70/4518] 1% | Training loss: 0.6972680032253266
Epoch: 9 | Iteration number: [80/4518] 1% | Training loss: 0.6958394251763821
Epoch: 9 | Iteration number: [90/4518] 1% | Training loss: 0.6947208484013875
Epoch: 9 | Iteration number: [100/4518] 2% | Training loss: 0.6941115367412567
Epoch: 9 | Iteration number: [110/4518] 2% | Training loss: 0.6933239953084426
Epoch: 9 | Iteration number: [120/4518] 2% | Training loss: 0.6927862380941708
Epoch: 9 | Iteration number: [130/4518] 2% | Training loss: 0.6923594983724447
Epoch: 9 | Iteration number: [140/4518] 3% | Training loss: 0.6919172189065388
Epoch: 9 | Iteration number: [150/4518] 3% | Training loss: 0.6915303345521291
Epoch: 9 | Iteration number: [160/4518] 3% | Training loss: 0.6912960205227137
Epoch: 9 | Iteration number: [170/4518] 3% | Training loss: 0.6911083929678973
Epoch: 9 | Iteration number: [180/4518] 3% | Training loss: 0.6909244275755353
Epoch: 9 | Iteration number: [190/4518] 4% | Training loss: 0.6907857449431168
Epoch: 9 | Iteration number: [200/4518] 4% | Training loss: 0.690559338927269
Epoch: 9 | Iteration number: [210/4518] 4% | Training loss: 0.6903730341366359
Epoch: 9 | Iteration number: [220/4518] 4% | Training loss: 0.6902091765945608
Epoch: 9 | Iteration number: [230/4518] 5% | Training loss: 0.6900873005390167
Epoch: 9 | Iteration number: [240/4518] 5% | Training loss: 0.6899497397243977
Epoch: 9 | Iteration number: [250/4518] 5% | Training loss: 0.6898280487060547
Epoch: 9 | Iteration number: [260/4518] 5% | Training loss: 0.6896654598988019
Epoch: 9 | Iteration number: [270/4518] 5% | Training loss: 0.6895743509133657
Epoch: 9 | Iteration number: [280/4518] 6% | Training loss: 0.6894402461392539
Epoch: 9 | Iteration number: [290/4518] 6% | Training loss: 0.6893285905492716
Epoch: 9 | Iteration number: [300/4518] 6% | Training loss: 0.6892617543538412
Epoch: 9 | Iteration number: [310/4518] 6% | Training loss: 0.6891871984927885
Epoch: 9 | Iteration number: [320/4518] 7% | Training loss: 0.6891631171107292
Epoch: 9 | Iteration number: [330/4518] 7% | Training loss: 0.6890599729436817
Epoch: 9 | Iteration number: [340/4518] 7% | Training loss: 0.689004811819862
Epoch: 9 | Iteration number: [350/4518] 7% | Training loss: 0.6889602024214608
Epoch: 9 | Iteration number: [360/4518] 7% | Training loss: 0.6888824557264646
Epoch: 9 | Iteration number: [370/4518] 8% | Training loss: 0.6888037451215693
Epoch: 9 | Iteration number: [380/4518] 8% | Training loss: 0.688761513641006
Epoch: 9 | Iteration number: [390/4518] 8% | Training loss: 0.6887193979361118
Epoch: 9 | Iteration number: [400/4518] 8% | Training loss: 0.6886751592159271
Epoch: 9 | Iteration number: [410/4518] 9% | Training loss: 0.6886705727112002
Epoch: 9 | Iteration number: [420/4518] 9% | Training loss: 0.6886486527465638
Epoch: 9 | Iteration number: [430/4518] 9% | Training loss: 0.6886152414388435
Epoch: 9 | Iteration number: [440/4518] 9% | Training loss: 0.6885771319270134
Epoch: 9 | Iteration number: [450/4518] 9% | Training loss: 0.6885465394126045
Epoch: 9 | Iteration number: [460/4518] 10% | Training loss: 0.6884921124447947
Epoch: 9 | Iteration number: [470/4518] 10% | Training loss: 0.6884405469640772
Epoch: 9 | Iteration number: [480/4518] 10% | Training loss: 0.6884200035283963
Epoch: 9 | Iteration number: [490/4518] 10% | Training loss: 0.6883973471972407
Epoch: 9 | Iteration number: [500/4518] 11% | Training loss: 0.6883611965179444
Epoch: 9 | Iteration number: [510/4518] 11% | Training loss: 0.6883467472067066
Epoch: 9 | Iteration number: [520/4518] 11% | Training loss: 0.68833330479952
Epoch: 9 | Iteration number: [530/4518] 11% | Training loss: 0.6883200354171249
Epoch: 9 | Iteration number: [540/4518] 11% | Training loss: 0.6882911970218023
Epoch: 9 | Iteration number: [550/4518] 12% | Training loss: 0.6882740928909995
Epoch: 9 | Iteration number: [560/4518] 12% | Training loss: 0.6882419461650507
Epoch: 9 | Iteration number: [570/4518] 12% | Training loss: 0.6882119869976713
Epoch: 9 | Iteration number: [580/4518] 12% | Training loss: 0.6881969496093947
Epoch: 9 | Iteration number: [590/4518] 13% | Training loss: 0.6881856605158014
Epoch: 9 | Iteration number: [600/4518] 13% | Training loss: 0.6881635989745458
Epoch: 9 | Iteration number: [610/4518] 13% | Training loss: 0.6881661475681867
Epoch: 9 | Iteration number: [620/4518] 13% | Training loss: 0.6881419461581015
Epoch: 9 | Iteration number: [630/4518] 13% | Training loss: 0.6881196240584055
Epoch: 9 | Iteration number: [640/4518] 14% | Training loss: 0.6881143181584776
Epoch: 9 | Iteration number: [650/4518] 14% | Training loss: 0.688071662737773
Epoch: 9 | Iteration number: [660/4518] 14% | Training loss: 0.6880449692408244
Epoch: 9 | Iteration number: [670/4518] 14% | Training loss: 0.6880398908657814
Epoch: 9 | Iteration number: [680/4518] 15% | Training loss: 0.688016627728939
Epoch: 9 | Iteration number: [690/4518] 15% | Training loss: 0.6880226380583169
Epoch: 9 | Iteration number: [700/4518] 15% | Training loss: 0.688028199161802
Epoch: 9 | Iteration number: [710/4518] 15% | Training loss: 0.6880096103104067
Epoch: 9 | Iteration number: [720/4518] 15% | Training loss: 0.6880012580090099
Epoch: 9 | Iteration number: [730/4518] 16% | Training loss: 0.6879923510224852
Epoch: 9 | Iteration number: [740/4518] 16% | Training loss: 0.6879880647401552
Epoch: 9 | Iteration number: [750/4518] 16% | Training loss: 0.6879618604977925
Epoch: 9 | Iteration number: [760/4518] 16% | Training loss: 0.6879482473982008
Epoch: 9 | Iteration number: [770/4518] 17% | Training loss: 0.6879449978277281
Epoch: 9 | Iteration number: [780/4518] 17% | Training loss: 0.6879359916234628
Epoch: 9 | Iteration number: [790/4518] 17% | Training loss: 0.6879242393034923
Epoch: 9 | Iteration number: [800/4518] 17% | Training loss: 0.6879234179854393
Epoch: 9 | Iteration number: [810/4518] 17% | Training loss: 0.6879057757648421
Epoch: 9 | Iteration number: [820/4518] 18% | Training loss: 0.6879000499481108
Epoch: 9 | Iteration number: [830/4518] 18% | Training loss: 0.6878914940788086
Epoch: 9 | Iteration number: [840/4518] 18% | Training loss: 0.6878802616681371
Epoch: 9 | Iteration number: [850/4518] 18% | Training loss: 0.6878695466939141
Epoch: 9 | Iteration number: [860/4518] 19% | Training loss: 0.6878558102735254
Epoch: 9 | Iteration number: [870/4518] 19% | Training loss: 0.6878366168888136
Epoch: 9 | Iteration number: [880/4518] 19% | Training loss: 0.6878250833262097
Epoch: 9 | Iteration number: [890/4518] 19% | Training loss: 0.6878068110246337
Epoch: 9 | Iteration number: [900/4518] 19% | Training loss: 0.6877946149640614
Epoch: 9 | Iteration number: [910/4518] 20% | Training loss: 0.687792047235992
Epoch: 9 | Iteration number: [920/4518] 20% | Training loss: 0.6877834043425063
Epoch: 9 | Iteration number: [930/4518] 20% | Training loss: 0.687783573135253
Epoch: 9 | Iteration number: [940/4518] 20% | Training loss: 0.6877855123991662
Epoch: 9 | Iteration number: [950/4518] 21% | Training loss: 0.6877694903549395
Epoch: 9 | Iteration number: [960/4518] 21% | Training loss: 0.6877600907658538
Epoch: 9 | Iteration number: [970/4518] 21% | Training loss: 0.6877697996257507
Epoch: 9 | Iteration number: [980/4518] 21% | Training loss: 0.6877662849669554
Epoch: 9 | Iteration number: [990/4518] 21% | Training loss: 0.6877820988496145
Epoch: 9 | Iteration number: [1000/4518] 22% | Training loss: 0.6877838785052299
Epoch: 9 | Iteration number: [1010/4518] 22% | Training loss: 0.6877988221031605
Epoch: 9 | Iteration number: [1020/4518] 22% | Training loss: 0.6877885100303912
Epoch: 9 | Iteration number: [1030/4518] 22% | Training loss: 0.6877763756849233
Epoch: 9 | Iteration number: [1040/4518] 23% | Training loss: 0.687764402364309
Epoch: 9 | Iteration number: [1050/4518] 23% | Training loss: 0.6877517942587534
Epoch: 9 | Iteration number: [1060/4518] 23% | Training loss: 0.6877544041512147
Epoch: 9 | Iteration number: [1070/4518] 23% | Training loss: 0.6877437320825095
Epoch: 9 | Iteration number: [1080/4518] 23% | Training loss: 0.6877378310870241
Epoch: 9 | Iteration number: [1090/4518] 24% | Training loss: 0.6877376685995574
Epoch: 9 | Iteration number: [1100/4518] 24% | Training loss: 0.6877327598224987
Epoch: 9 | Iteration number: [1110/4518] 24% | Training loss: 0.6877286855701927
Epoch: 9 | Iteration number: [1120/4518] 24% | Training loss: 0.6877253494624581
Epoch: 9 | Iteration number: [1130/4518] 25% | Training loss: 0.6877166124044266
Epoch: 9 | Iteration number: [1140/4518] 25% | Training loss: 0.687707715912869
Epoch: 9 | Iteration number: [1150/4518] 25% | Training loss: 0.687696186511413
Epoch: 9 | Iteration number: [1160/4518] 25% | Training loss: 0.6876841856487866
Epoch: 9 | Iteration number: [1170/4518] 25% | Training loss: 0.6876627483938494
Epoch: 9 | Iteration number: [1180/4518] 26% | Training loss: 0.687659259569847
Epoch: 9 | Iteration number: [1190/4518] 26% | Training loss: 0.6876584054542189
Epoch: 9 | Iteration number: [1200/4518] 26% | Training loss: 0.6876491385201613
Epoch: 9 | Iteration number: [1210/4518] 26% | Training loss: 0.6876517157416698
Epoch: 9 | Iteration number: [1220/4518] 27% | Training loss: 0.6876449559067116
Epoch: 9 | Iteration number: [1230/4518] 27% | Training loss: 0.6876454376108279
Epoch: 9 | Iteration number: [1240/4518] 27% | Training loss: 0.6876432766837458
Epoch: 9 | Iteration number: [1250/4518] 27% | Training loss: 0.6876401772975922
Epoch: 9 | Iteration number: [1260/4518] 27% | Training loss: 0.687628080825957
Epoch: 9 | Iteration number: [1270/4518] 28% | Training loss: 0.6876264733123029
Epoch: 9 | Iteration number: [1280/4518] 28% | Training loss: 0.6876258775126189
Epoch: 9 | Iteration number: [1290/4518] 28% | Training loss: 0.6876257840053056
Epoch: 9 | Iteration number: [1300/4518] 28% | Training loss: 0.6876196194612063
Epoch: 9 | Iteration number: [1310/4518] 28% | Training loss: 0.687613987331172
Epoch: 9 | Iteration number: [1320/4518] 29% | Training loss: 0.6876123603546258
Epoch: 9 | Iteration number: [1330/4518] 29% | Training loss: 0.6876076502907545
Epoch: 9 | Iteration number: [1340/4518] 29% | Training loss: 0.6876081983100123
Epoch: 9 | Iteration number: [1350/4518] 29% | Training loss: 0.6876193429364098
Epoch: 9 | Iteration number: [1360/4518] 30% | Training loss: 0.6876059375265066
Epoch: 9 | Iteration number: [1370/4518] 30% | Training loss: 0.6875861080458564
Epoch: 9 | Iteration number: [1380/4518] 30% | Training loss: 0.6875833776981934
Epoch: 9 | Iteration number: [1390/4518] 30% | Training loss: 0.6875850214803819
Epoch: 9 | Iteration number: [1400/4518] 30% | Training loss: 0.6875861877628735
Epoch: 9 | Iteration number: [1410/4518] 31% | Training loss: 0.6875786460883229
Epoch: 9 | Iteration number: [1420/4518] 31% | Training loss: 0.6875820002085726
Epoch: 9 | Iteration number: [1430/4518] 31% | Training loss: 0.6875792937262075
Epoch: 9 | Iteration number: [1440/4518] 31% | Training loss: 0.6875755379597346
Epoch: 9 | Iteration number: [1450/4518] 32% | Training loss: 0.6875757218229359
Epoch: 9 | Iteration number: [1460/4518] 32% | Training loss: 0.6875727321595362
Epoch: 9 | Iteration number: [1470/4518] 32% | Training loss: 0.687559233392988
Epoch: 9 | Iteration number: [1480/4518] 32% | Training loss: 0.6875498246904966
Epoch: 9 | Iteration number: [1490/4518] 32% | Training loss: 0.6875462369230769
Epoch: 9 | Iteration number: [1500/4518] 33% | Training loss: 0.6875402799447378
Epoch: 9 | Iteration number: [1510/4518] 33% | Training loss: 0.6875334472450989
Epoch: 9 | Iteration number: [1520/4518] 33% | Training loss: 0.6875363983213901
Epoch: 9 | Iteration number: [1530/4518] 33% | Training loss: 0.687530989740409
Epoch: 9 | Iteration number: [1540/4518] 34% | Training loss: 0.687539653615518
Epoch: 9 | Iteration number: [1550/4518] 34% | Training loss: 0.687536081690942
Epoch: 9 | Iteration number: [1560/4518] 34% | Training loss: 0.68753209148462
Epoch: 9 | Iteration number: [1570/4518] 34% | Training loss: 0.6875226147615227
Epoch: 9 | Iteration number: [1580/4518] 34% | Training loss: 0.6875161315444149
Epoch: 9 | Iteration number: [1590/4518] 35% | Training loss: 0.6875131067614886
Epoch: 9 | Iteration number: [1600/4518] 35% | Training loss: 0.6875064682215453
Epoch: 9 | Iteration number: [1610/4518] 35% | Training loss: 0.687498517695421
Epoch: 9 | Iteration number: [1620/4518] 35% | Training loss: 0.6874974261831355
Epoch: 9 | Iteration number: [1630/4518] 36% | Training loss: 0.6874930563148546
Epoch: 9 | Iteration number: [1640/4518] 36% | Training loss: 0.687484638974434
Epoch: 9 | Iteration number: [1650/4518] 36% | Training loss: 0.6874842850728469
Epoch: 9 | Iteration number: [1660/4518] 36% | Training loss: 0.6874789420021585
Epoch: 9 | Iteration number: [1670/4518] 36% | Training loss: 0.6874719328152206
Epoch: 9 | Iteration number: [1680/4518] 37% | Training loss: 0.6874632855256398
Epoch: 9 | Iteration number: [1690/4518] 37% | Training loss: 0.6874579991461963
Epoch: 9 | Iteration number: [1700/4518] 37% | Training loss: 0.6874512209611781
Epoch: 9 | Iteration number: [1710/4518] 37% | Training loss: 0.6874500425935489
Epoch: 9 | Iteration number: [1720/4518] 38% | Training loss: 0.6874479685758436
Epoch: 9 | Iteration number: [1730/4518] 38% | Training loss: 0.6874494623586621
Epoch: 9 | Iteration number: [1740/4518] 38% | Training loss: 0.6874505294808027
Epoch: 9 | Iteration number: [1750/4518] 38% | Training loss: 0.6874513197285789
Epoch: 9 | Iteration number: [1760/4518] 38% | Training loss: 0.6874535736712543
Epoch: 9 | Iteration number: [1770/4518] 39% | Training loss: 0.6874589745607753
Epoch: 9 | Iteration number: [1780/4518] 39% | Training loss: 0.6874574721529243
Epoch: 9 | Iteration number: [1790/4518] 39% | Training loss: 0.6874567138416141
Epoch: 9 | Iteration number: [1800/4518] 39% | Training loss: 0.6874533592661222
Epoch: 9 | Iteration number: [1810/4518] 40% | Training loss: 0.6874496545251562
Epoch: 9 | Iteration number: [1820/4518] 40% | Training loss: 0.6874467178032948
Epoch: 9 | Iteration number: [1830/4518] 40% | Training loss: 0.6874467782961214
Epoch: 9 | Iteration number: [1840/4518] 40% | Training loss: 0.6874412770828475
Epoch: 9 | Iteration number: [1850/4518] 40% | Training loss: 0.6874385088198893
Epoch: 9 | Iteration number: [1860/4518] 41% | Training loss: 0.687434537724782
Epoch: 9 | Iteration number: [1870/4518] 41% | Training loss: 0.6874339232789004
Epoch: 9 | Iteration number: [1880/4518] 41% | Training loss: 0.6874291921232609
Epoch: 9 | Iteration number: [1890/4518] 41% | Training loss: 0.6874344583541628
Epoch: 9 | Iteration number: [1900/4518] 42% | Training loss: 0.687436170327036
Epoch: 9 | Iteration number: [1910/4518] 42% | Training loss: 0.6874317279972956
Epoch: 9 | Iteration number: [1920/4518] 42% | Training loss: 0.6874270386373004
Epoch: 9 | Iteration number: [1930/4518] 42% | Training loss: 0.6874310400201866
Epoch: 9 | Iteration number: [1940/4518] 42% | Training loss: 0.687425866999577
Epoch: 9 | Iteration number: [1950/4518] 43% | Training loss: 0.687428622398621
Epoch: 9 | Iteration number: [1960/4518] 43% | Training loss: 0.6874288457996991
Epoch: 9 | Iteration number: [1970/4518] 43% | Training loss: 0.6874253795836782
Epoch: 9 | Iteration number: [1980/4518] 43% | Training loss: 0.6874266830357638
Epoch: 9 | Iteration number: [1990/4518] 44% | Training loss: 0.6874269992861916
Epoch: 9 | Iteration number: [2000/4518] 44% | Training loss: 0.6874250248968601
Epoch: 9 | Iteration number: [2010/4518] 44% | Training loss: 0.6874235150529378
Epoch: 9 | Iteration number: [2020/4518] 44% | Training loss: 0.6874218496650752
Epoch: 9 | Iteration number: [2030/4518] 44% | Training loss: 0.6874220184798311
Epoch: 9 | Iteration number: [2040/4518] 45% | Training loss: 0.687411413005754
Epoch: 9 | Iteration number: [2050/4518] 45% | Training loss: 0.6874079392305235
Epoch: 9 | Iteration number: [2060/4518] 45% | Training loss: 0.6874037022150836
Epoch: 9 | Iteration number: [2070/4518] 45% | Training loss: 0.6874039844614296
Epoch: 9 | Iteration number: [2080/4518] 46% | Training loss: 0.6874011908872769
Epoch: 9 | Iteration number: [2090/4518] 46% | Training loss: 0.6874016114399194
Epoch: 9 | Iteration number: [2100/4518] 46% | Training loss: 0.6873957928305581
Epoch: 9 | Iteration number: [2110/4518] 46% | Training loss: 0.6873934890704132
Epoch: 9 | Iteration number: [2120/4518] 46% | Training loss: 0.6873894167115103
Epoch: 9 | Iteration number: [2130/4518] 47% | Training loss: 0.6873861306989697
Epoch: 9 | Iteration number: [2140/4518] 47% | Training loss: 0.6873804687896622
Epoch: 9 | Iteration number: [2150/4518] 47% | Training loss: 0.6873757716944051
Epoch: 9 | Iteration number: [2160/4518] 47% | Training loss: 0.6873724506960974
Epoch: 9 | Iteration number: [2170/4518] 48% | Training loss: 0.6873722640050721
Epoch: 9 | Iteration number: [2180/4518] 48% | Training loss: 0.6873758371270031
Epoch: 9 | Iteration number: [2190/4518] 48% | Training loss: 0.6873748005252995
Epoch: 9 | Iteration number: [2200/4518] 48% | Training loss: 0.6873745062676343
Epoch: 9 | Iteration number: [2210/4518] 48% | Training loss: 0.6873759996027968
Epoch: 9 | Iteration number: [2220/4518] 49% | Training loss: 0.6873709366128251
Epoch: 9 | Iteration number: [2230/4518] 49% | Training loss: 0.6873692457451414
Epoch: 9 | Iteration number: [2240/4518] 49% | Training loss: 0.6873652306518384
Epoch: 9 | Iteration number: [2250/4518] 49% | Training loss: 0.6873636153274112
Epoch: 9 | Iteration number: [2260/4518] 50% | Training loss: 0.6873608729744379
Epoch: 9 | Iteration number: [2270/4518] 50% | Training loss: 0.6873594030147082
Epoch: 9 | Iteration number: [2280/4518] 50% | Training loss: 0.687362329243568
Epoch: 9 | Iteration number: [2290/4518] 50% | Training loss: 0.6873589083096866
Epoch: 9 | Iteration number: [2300/4518] 50% | Training loss: 0.6873558434714442
Epoch: 9 | Iteration number: [2310/4518] 51% | Training loss: 0.6873488158632667
Epoch: 9 | Iteration number: [2320/4518] 51% | Training loss: 0.6873531506236257
Epoch: 9 | Iteration number: [2330/4518] 51% | Training loss: 0.687351174901995
Epoch: 9 | Iteration number: [2340/4518] 51% | Training loss: 0.687349199077003
Epoch: 9 | Iteration number: [2350/4518] 52% | Training loss: 0.68734579205513
Epoch: 9 | Iteration number: [2360/4518] 52% | Training loss: 0.687341347942918
Epoch: 9 | Iteration number: [2370/4518] 52% | Training loss: 0.6873392712717821
Epoch: 9 | Iteration number: [2380/4518] 52% | Training loss: 0.6873337898935591
Epoch: 9 | Iteration number: [2390/4518] 52% | Training loss: 0.6873263148583129
Epoch: 9 | Iteration number: [2400/4518] 53% | Training loss: 0.687317599778374
Epoch: 9 | Iteration number: [2410/4518] 53% | Training loss: 0.6873133754087187
Epoch: 9 | Iteration number: [2420/4518] 53% | Training loss: 0.6873127646190076
Epoch: 9 | Iteration number: [2430/4518] 53% | Training loss: 0.6873142579210147
Epoch: 9 | Iteration number: [2440/4518] 54% | Training loss: 0.6873094502042552
Epoch: 9 | Iteration number: [2450/4518] 54% | Training loss: 0.6873046601061918
Epoch: 9 | Iteration number: [2460/4518] 54% | Training loss: 0.6873007252691238
Epoch: 9 | Iteration number: [2470/4518] 54% | Training loss: 0.6872970964261877
Epoch: 9 | Iteration number: [2480/4518] 54% | Training loss: 0.687295768337865
Epoch: 9 | Iteration number: [2490/4518] 55% | Training loss: 0.6872905996429872
Epoch: 9 | Iteration number: [2500/4518] 55% | Training loss: 0.6872929107666016
Epoch: 9 | Iteration number: [2510/4518] 55% | Training loss: 0.68729012010107
Epoch: 9 | Iteration number: [2520/4518] 55% | Training loss: 0.6872857419980897
Epoch: 9 | Iteration number: [2530/4518] 55% | Training loss: 0.6872820109246748
Epoch: 9 | Iteration number: [2540/4518] 56% | Training loss: 0.6872856671650579
Epoch: 9 | Iteration number: [2550/4518] 56% | Training loss: 0.6872877388374479
Epoch: 9 | Iteration number: [2560/4518] 56% | Training loss: 0.6872854438144713
Epoch: 9 | Iteration number: [2570/4518] 56% | Training loss: 0.687285486872558
Epoch: 9 | Iteration number: [2580/4518] 57% | Training loss: 0.6872882565555647
Epoch: 9 | Iteration number: [2590/4518] 57% | Training loss: 0.6872885566190403
Epoch: 9 | Iteration number: [2600/4518] 57% | Training loss: 0.6872885017899366
Epoch: 9 | Iteration number: [2610/4518] 57% | Training loss: 0.6872883392933228
Epoch: 9 | Iteration number: [2620/4518] 57% | Training loss: 0.6872908148601765
Epoch: 9 | Iteration number: [2630/4518] 58% | Training loss: 0.687289118789448
Epoch: 9 | Iteration number: [2640/4518] 58% | Training loss: 0.6872897546399723
Epoch: 9 | Iteration number: [2650/4518] 58% | Training loss: 0.6872869404082028
Epoch: 9 | Iteration number: [2660/4518] 58% | Training loss: 0.6872879155596396
Epoch: 9 | Iteration number: [2670/4518] 59% | Training loss: 0.6872898045104094
Epoch: 9 | Iteration number: [2680/4518] 59% | Training loss: 0.6872871863085832
Epoch: 9 | Iteration number: [2690/4518] 59% | Training loss: 0.6872843958631324
Epoch: 9 | Iteration number: [2700/4518] 59% | Training loss: 0.6872815012931823
Epoch: 9 | Iteration number: [2710/4518] 59% | Training loss: 0.6872829082267311
Epoch: 9 | Iteration number: [2720/4518] 60% | Training loss: 0.6872867273495478
Epoch: 9 | Iteration number: [2730/4518] 60% | Training loss: 0.6872866271179674
Epoch: 9 | Iteration number: [2740/4518] 60% | Training loss: 0.6872814834552959
Epoch: 9 | Iteration number: [2750/4518] 60% | Training loss: 0.6872765288136222
Epoch: 9 | Iteration number: [2760/4518] 61% | Training loss: 0.6872738770600678
Epoch: 9 | Iteration number: [2770/4518] 61% | Training loss: 0.6872709470320264
Epoch: 9 | Iteration number: [2780/4518] 61% | Training loss: 0.6872681566922785
Epoch: 9 | Iteration number: [2790/4518] 61% | Training loss: 0.6872674093451551
Epoch: 9 | Iteration number: [2800/4518] 61% | Training loss: 0.6872612572780677
Epoch: 9 | Iteration number: [2810/4518] 62% | Training loss: 0.6872624708240143
Epoch: 9 | Iteration number: [2820/4518] 62% | Training loss: 0.6872635690667105
Epoch: 9 | Iteration number: [2830/4518] 62% | Training loss: 0.6872639460824825
Epoch: 9 | Iteration number: [2840/4518] 62% | Training loss: 0.6872650177755826
Epoch: 9 | Iteration number: [2850/4518] 63% | Training loss: 0.6872639633270732
Epoch: 9 | Iteration number: [2860/4518] 63% | Training loss: 0.6872619401324879
Epoch: 9 | Iteration number: [2870/4518] 63% | Training loss: 0.6872586852997438
Epoch: 9 | Iteration number: [2880/4518] 63% | Training loss: 0.6872622330776519
Epoch: 9 | Iteration number: [2890/4518] 63% | Training loss: 0.6872657139408547
Epoch: 9 | Iteration number: [2900/4518] 64% | Training loss: 0.6872605083728659
Epoch: 9 | Iteration number: [2910/4518] 64% | Training loss: 0.6872599634517919
Epoch: 9 | Iteration number: [2920/4518] 64% | Training loss: 0.6872595266120075
Epoch: 9 | Iteration number: [2930/4518] 64% | Training loss: 0.6872564489320684
Epoch: 9 | Iteration number: [2940/4518] 65% | Training loss: 0.6872544251534404
Epoch: 9 | Iteration number: [2950/4518] 65% | Training loss: 0.6872524292388205
Epoch: 9 | Iteration number: [2960/4518] 65% | Training loss: 0.6872486190014594
Epoch: 9 | Iteration number: [2970/4518] 65% | Training loss: 0.6872496562574046
Epoch: 9 | Iteration number: [2980/4518] 65% | Training loss: 0.6872522203914271
Epoch: 9 | Iteration number: [2990/4518] 66% | Training loss: 0.6872518045447742
Epoch: 9 | Iteration number: [3000/4518] 66% | Training loss: 0.6872503228584925
Epoch: 9 | Iteration number: [3010/4518] 66% | Training loss: 0.6872516337225207
Epoch: 9 | Iteration number: [3020/4518] 66% | Training loss: 0.6872534327751754
Epoch: 9 | Iteration number: [3030/4518] 67% | Training loss: 0.6872509814921779
Epoch: 9 | Iteration number: [3040/4518] 67% | Training loss: 0.6872479706610504
Epoch: 9 | Iteration number: [3050/4518] 67% | Training loss: 0.6872506575701667
Epoch: 9 | Iteration number: [3060/4518] 67% | Training loss: 0.6872519221181184
Epoch: 9 | Iteration number: [3070/4518] 67% | Training loss: 0.6872505866355151
Epoch: 9 | Iteration number: [3080/4518] 68% | Training loss: 0.6872533983611441
Epoch: 9 | Iteration number: [3090/4518] 68% | Training loss: 0.6872506444893994
Epoch: 9 | Iteration number: [3100/4518] 68% | Training loss: 0.687252252467217
Epoch: 9 | Iteration number: [3110/4518] 68% | Training loss: 0.6872512732671389
Epoch: 9 | Iteration number: [3120/4518] 69% | Training loss: 0.6872513439219732
Epoch: 9 | Iteration number: [3130/4518] 69% | Training loss: 0.6872494469435451
Epoch: 9 | Iteration number: [3140/4518] 69% | Training loss: 0.6872492149567149
Epoch: 9 | Iteration number: [3150/4518] 69% | Training loss: 0.6872482631130824
Epoch: 9 | Iteration number: [3160/4518] 69% | Training loss: 0.6872519128307512
Epoch: 9 | Iteration number: [3170/4518] 70% | Training loss: 0.6872495942687387
Epoch: 9 | Iteration number: [3180/4518] 70% | Training loss: 0.6872513240238406
Epoch: 9 | Iteration number: [3190/4518] 70% | Training loss: 0.6872498391750838
Epoch: 9 | Iteration number: [3200/4518] 70% | Training loss: 0.6872478040494024
Epoch: 9 | Iteration number: [3210/4518] 71% | Training loss: 0.6872480959535759
Epoch: 9 | Iteration number: [3220/4518] 71% | Training loss: 0.6872493493631019
Epoch: 9 | Iteration number: [3230/4518] 71% | Training loss: 0.687250463604558
Epoch: 9 | Iteration number: [3240/4518] 71% | Training loss: 0.6872496213258049
Epoch: 9 | Iteration number: [3250/4518] 71% | Training loss: 0.687247695684433
Epoch: 9 | Iteration number: [3260/4518] 72% | Training loss: 0.6872461993635798
Epoch: 9 | Iteration number: [3270/4518] 72% | Training loss: 0.6872421704483324
Epoch: 9 | Iteration number: [3280/4518] 72% | Training loss: 0.6872371057003009
Epoch: 9 | Iteration number: [3290/4518] 72% | Training loss: 0.6872383311345585
Epoch: 9 | Iteration number: [3300/4518] 73% | Training loss: 0.6872395026864427
Epoch: 9 | Iteration number: [3310/4518] 73% | Training loss: 0.6872421103301726
Epoch: 9 | Iteration number: [3320/4518] 73% | Training loss: 0.6872434274618884
Epoch: 9 | Iteration number: [3330/4518] 73% | Training loss: 0.6872430109046959
Epoch: 9 | Iteration number: [3340/4518] 73% | Training loss: 0.6872417050028989
Epoch: 9 | Iteration number: [3350/4518] 74% | Training loss: 0.6872398964326774
Epoch: 9 | Iteration number: [3360/4518] 74% | Training loss: 0.6872373727105913
Epoch: 9 | Iteration number: [3370/4518] 74% | Training loss: 0.6872368607747449
Epoch: 9 | Iteration number: [3380/4518] 74% | Training loss: 0.6872348464804994
Epoch: 9 | Iteration number: [3390/4518] 75% | Training loss: 0.6872357418579338
Epoch: 9 | Iteration number: [3400/4518] 75% | Training loss: 0.6872346101438298
Epoch: 9 | Iteration number: [3410/4518] 75% | Training loss: 0.6872362340300664
Epoch: 9 | Iteration number: [3420/4518] 75% | Training loss: 0.6872341772094804
Epoch: 9 | Iteration number: [3430/4518] 75% | Training loss: 0.6872333118067538
Epoch: 9 | Iteration number: [3440/4518] 76% | Training loss: 0.6872347097064173
Epoch: 9 | Iteration number: [3450/4518] 76% | Training loss: 0.6872363317876622
Epoch: 9 | Iteration number: [3460/4518] 76% | Training loss: 0.6872372662056389
Epoch: 9 | Iteration number: [3470/4518] 76% | Training loss: 0.6872363730191497
Epoch: 9 | Iteration number: [3480/4518] 77% | Training loss: 0.6872336458885807
Epoch: 9 | Iteration number: [3490/4518] 77% | Training loss: 0.6872297946566497
Epoch: 9 | Iteration number: [3500/4518] 77% | Training loss: 0.687227151955877
Epoch: 9 | Iteration number: [3510/4518] 77% | Training loss: 0.687230064845153
Epoch: 9 | Iteration number: [3520/4518] 77% | Training loss: 0.6872316898100755
Epoch: 9 | Iteration number: [3530/4518] 78% | Training loss: 0.6872310441715521
Epoch: 9 | Iteration number: [3540/4518] 78% | Training loss: 0.6872290656896635
Epoch: 9 | Iteration number: [3550/4518] 78% | Training loss: 0.6872296354132639
Epoch: 9 | Iteration number: [3560/4518] 78% | Training loss: 0.6872295195634446
Epoch: 9 | Iteration number: [3570/4518] 79% | Training loss: 0.687226283066079
Epoch: 9 | Iteration number: [3580/4518] 79% | Training loss: 0.6872271510975321
Epoch: 9 | Iteration number: [3590/4518] 79% | Training loss: 0.6872286218786638
Epoch: 9 | Iteration number: [3600/4518] 79% | Training loss: 0.6872267512314849
Epoch: 9 | Iteration number: [3610/4518] 79% | Training loss: 0.6872261507689458
Epoch: 9 | Iteration number: [3620/4518] 80% | Training loss: 0.6872276373166406
Epoch: 9 | Iteration number: [3630/4518] 80% | Training loss: 0.6872307200077151
Epoch: 9 | Iteration number: [3640/4518] 80% | Training loss: 0.6872319119972187
Epoch: 9 | Iteration number: [3650/4518] 80% | Training loss: 0.6872302435032309
Epoch: 9 | Iteration number: [3660/4518] 81% | Training loss: 0.6872292126625613
Epoch: 9 | Iteration number: [3670/4518] 81% | Training loss: 0.6872299923883797
Epoch: 9 | Iteration number: [3680/4518] 81% | Training loss: 0.6872324016107165
Epoch: 9 | Iteration number: [3690/4518] 81% | Training loss: 0.687234380283976
Epoch: 9 | Iteration number: [3700/4518] 81% | Training loss: 0.6872331836900195
Epoch: 9 | Iteration number: [3710/4518] 82% | Training loss: 0.6872333726150328
Epoch: 9 | Iteration number: [3720/4518] 82% | Training loss: 0.6872308145928127
Epoch: 9 | Iteration number: [3730/4518] 82% | Training loss: 0.687231605446051
Epoch: 9 | Iteration number: [3740/4518] 82% | Training loss: 0.6872300267538285
Epoch: 9 | Iteration number: [3750/4518] 83% | Training loss: 0.6872275304158528
Epoch: 9 | Iteration number: [3760/4518] 83% | Training loss: 0.6872280078365448
Epoch: 9 | Iteration number: [3770/4518] 83% | Training loss: 0.6872298648882291
Epoch: 9 | Iteration number: [3780/4518] 83% | Training loss: 0.6872315081654402
Epoch: 9 | Iteration number: [3790/4518] 83% | Training loss: 0.6872292404596283
Epoch: 9 | Iteration number: [3800/4518] 84% | Training loss: 0.6872266348725871
Epoch: 9 | Iteration number: [3810/4518] 84% | Training loss: 0.6872265925557595
Epoch: 9 | Iteration number: [3820/4518] 84% | Training loss: 0.6872253154272808
Epoch: 9 | Iteration number: [3830/4518] 84% | Training loss: 0.6872246873129753
Epoch: 9 | Iteration number: [3840/4518] 84% | Training loss: 0.6872248646182318
Epoch: 9 | Iteration number: [3850/4518] 85% | Training loss: 0.6872239529467248
Epoch: 9 | Iteration number: [3860/4518] 85% | Training loss: 0.6872200473911404
Epoch: 9 | Iteration number: [3870/4518] 85% | Training loss: 0.6872198770520607
Epoch: 9 | Iteration number: [3880/4518] 85% | Training loss: 0.6872119221797923
Epoch: 9 | Iteration number: [3890/4518] 86% | Training loss: 0.6872117013581921
Epoch: 9 | Iteration number: [3900/4518] 86% | Training loss: 0.6872125775844623
Epoch: 9 | Iteration number: [3910/4518] 86% | Training loss: 0.6872108707952378
Epoch: 9 | Iteration number: [3920/4518] 86% | Training loss: 0.687212070609842
Epoch: 9 | Iteration number: [3930/4518] 86% | Training loss: 0.687210687335211
Epoch: 9 | Iteration number: [3940/4518] 87% | Training loss: 0.6872073989531715
Epoch: 9 | Iteration number: [3950/4518] 87% | Training loss: 0.6872095755534836
Epoch: 9 | Iteration number: [3960/4518] 87% | Training loss: 0.6872114884130882
Epoch: 9 | Iteration number: [3970/4518] 87% | Training loss: 0.6872132617370308
Epoch: 9 | Iteration number: [3980/4518] 88% | Training loss: 0.6872127507948995
Epoch: 9 | Iteration number: [3990/4518] 88% | Training loss: 0.6872085419215056
Epoch: 9 | Iteration number: [4000/4518] 88% | Training loss: 0.6872074160426855
Epoch: 9 | Iteration number: [4010/4518] 88% | Training loss: 0.6872082783099719
Epoch: 9 | Iteration number: [4020/4518] 88% | Training loss: 0.6872078259489429
Epoch: 9 | Iteration number: [4030/4518] 89% | Training loss: 0.687207800992961
Epoch: 9 | Iteration number: [4040/4518] 89% | Training loss: 0.6872083318115461
Epoch: 9 | Iteration number: [4050/4518] 89% | Training loss: 0.6872049223640818
Epoch: 9 | Iteration number: [4060/4518] 89% | Training loss: 0.6872015108028656
Epoch: 9 | Iteration number: [4070/4518] 90% | Training loss: 0.6872005759644567
Epoch: 9 | Iteration number: [4080/4518] 90% | Training loss: 0.6871995057691546
Epoch: 9 | Iteration number: [4090/4518] 90% | Training loss: 0.6871979064638283
Epoch: 9 | Iteration number: [4100/4518] 90% | Training loss: 0.6871998458664592
Epoch: 9 | Iteration number: [4110/4518] 90% | Training loss: 0.6871982576928289
Epoch: 9 | Iteration number: [4120/4518] 91% | Training loss: 0.687195188183229
Epoch: 9 | Iteration number: [4130/4518] 91% | Training loss: 0.687194347035221
Epoch: 9 | Iteration number: [4140/4518] 91% | Training loss: 0.6871910587745013
Epoch: 9 | Iteration number: [4150/4518] 91% | Training loss: 0.6871939200521952
Epoch: 9 | Iteration number: [4160/4518] 92% | Training loss: 0.6871930776593776
Epoch: 9 | Iteration number: [4170/4518] 92% | Training loss: 0.6871934234953041
Epoch: 9 | Iteration number: [4180/4518] 92% | Training loss: 0.6871905025682952
Epoch: 9 | Iteration number: [4190/4518] 92% | Training loss: 0.6871887529664507
Epoch: 9 | Iteration number: [4200/4518] 92% | Training loss: 0.6871908476381074
Epoch: 9 | Iteration number: [4210/4518] 93% | Training loss: 0.6871892418685831
Epoch: 9 | Iteration number: [4220/4518] 93% | Training loss: 0.6871848821075042
Epoch: 9 | Iteration number: [4230/4518] 93% | Training loss: 0.687183231566251
Epoch: 9 | Iteration number: [4240/4518] 93% | Training loss: 0.6871817215293083
Epoch: 9 | Iteration number: [4250/4518] 94% | Training loss: 0.6871836518960841
Epoch: 9 | Iteration number: [4260/4518] 94% | Training loss: 0.6871843545649533
Epoch: 9 | Iteration number: [4270/4518] 94% | Training loss: 0.6871835555767846
Epoch: 9 | Iteration number: [4280/4518] 94% | Training loss: 0.6871856964776449
Epoch: 9 | Iteration number: [4290/4518] 94% | Training loss: 0.6871873538116198
Epoch: 9 | Iteration number: [4300/4518] 95% | Training loss: 0.6871858499909557
Epoch: 9 | Iteration number: [4310/4518] 95% | Training loss: 0.6871858729840431
Epoch: 9 | Iteration number: [4320/4518] 95% | Training loss: 0.6871855817873169
Epoch: 9 | Iteration number: [4330/4518] 95% | Training loss: 0.6871846746765163
Epoch: 9 | Iteration number: [4340/4518] 96% | Training loss: 0.6871822645037954
Epoch: 9 | Iteration number: [4350/4518] 96% | Training loss: 0.6871832969407926
Epoch: 9 | Iteration number: [4360/4518] 96% | Training loss: 0.6871848750278491
Epoch: 9 | Iteration number: [4370/4518] 96% | Training loss: 0.6871861483194189
Epoch: 9 | Iteration number: [4380/4518] 96% | Training loss: 0.6871857563246331
Epoch: 9 | Iteration number: [4390/4518] 97% | Training loss: 0.6871885255963492
Epoch: 9 | Iteration number: [4400/4518] 97% | Training loss: 0.6871874223784967
Epoch: 9 | Iteration number: [4410/4518] 97% | Training loss: 0.6871866668838492
Epoch: 9 | Iteration number: [4420/4518] 97% | Training loss: 0.6871876665909366
Epoch: 9 | Iteration number: [4430/4518] 98% | Training loss: 0.6871840880363843
Epoch: 9 | Iteration number: [4440/4518] 98% | Training loss: 0.687180724672906
Epoch: 9 | Iteration number: [4450/4518] 98% | Training loss: 0.6871811719155043
Epoch: 9 | Iteration number: [4460/4518] 98% | Training loss: 0.6871793012982527
Epoch: 9 | Iteration number: [4470/4518] 98% | Training loss: 0.6871807334540407
Epoch: 9 | Iteration number: [4480/4518] 99% | Training loss: 0.6871798442676663
Epoch: 9 | Iteration number: [4490/4518] 99% | Training loss: 0.687180295885273
Epoch: 9 | Iteration number: [4500/4518] 99% | Training loss: 0.6871796123319202
Epoch: 9 | Iteration number: [4510/4518] 99% | Training loss: 0.6871776644247862

 End of epoch: 9 | Train Loss: 0.6870263834319424 | Training Time: 641 

 End of epoch: 9 | Eval Loss: 0.6904272327617723 | Evaluating Time: 17 
Epoch: 10 | Iteration number: [10/4518] 0% | Training loss: 0.7557651281356812
Epoch: 10 | Iteration number: [20/4518] 0% | Training loss: 0.7221277862787246
Epoch: 10 | Iteration number: [30/4518] 0% | Training loss: 0.7106479525566101
Epoch: 10 | Iteration number: [40/4518] 0% | Training loss: 0.7048901543021202
Epoch: 10 | Iteration number: [50/4518] 1% | Training loss: 0.7015927171707154
Epoch: 10 | Iteration number: [60/4518] 1% | Training loss: 0.6992440958817799
Epoch: 10 | Iteration number: [70/4518] 1% | Training loss: 0.6976814423288618
Epoch: 10 | Iteration number: [80/4518] 1% | Training loss: 0.6962954364717007
Epoch: 10 | Iteration number: [90/4518] 1% | Training loss: 0.6952832606103685
Epoch: 10 | Iteration number: [100/4518] 2% | Training loss: 0.694522641301155
Epoch: 10 | Iteration number: [110/4518] 2% | Training loss: 0.6937376905571331
Epoch: 10 | Iteration number: [120/4518] 2% | Training loss: 0.693194713195165
Epoch: 10 | Iteration number: [130/4518] 2% | Training loss: 0.6927093336215386
Epoch: 10 | Iteration number: [140/4518] 3% | Training loss: 0.6923340942178454
Epoch: 10 | Iteration number: [150/4518] 3% | Training loss: 0.6920720450083415
Epoch: 10 | Iteration number: [160/4518] 3% | Training loss: 0.6916911002248526
Epoch: 10 | Iteration number: [170/4518] 3% | Training loss: 0.691417926199296
Epoch: 10 | Iteration number: [180/4518] 3% | Training loss: 0.6912092020114263
Epoch: 10 | Iteration number: [190/4518] 4% | Training loss: 0.690998166172128
Epoch: 10 | Iteration number: [200/4518] 4% | Training loss: 0.6907563763856888
Epoch: 10 | Iteration number: [210/4518] 4% | Training loss: 0.6905808965365092
Epoch: 10 | Iteration number: [220/4518] 4% | Training loss: 0.6904650165276094
Epoch: 10 | Iteration number: [230/4518] 5% | Training loss: 0.6903057634830475
Epoch: 10 | Iteration number: [240/4518] 5% | Training loss: 0.6901382048924763
Epoch: 10 | Iteration number: [250/4518] 5% | Training loss: 0.6900426990985871
Epoch: 10 | Iteration number: [260/4518] 5% | Training loss: 0.6899556386929292
Epoch: 10 | Iteration number: [270/4518] 5% | Training loss: 0.6898641292695646
Epoch: 10 | Iteration number: [280/4518] 6% | Training loss: 0.6897687279752323
Epoch: 10 | Iteration number: [290/4518] 6% | Training loss: 0.6896736903437253
Epoch: 10 | Iteration number: [300/4518] 6% | Training loss: 0.6896038333574931
Epoch: 10 | Iteration number: [310/4518] 6% | Training loss: 0.6895429824629138
Epoch: 10 | Iteration number: [320/4518] 7% | Training loss: 0.6894647413864732
Epoch: 10 | Iteration number: [330/4518] 7% | Training loss: 0.6893205312165347
Epoch: 10 | Iteration number: [340/4518] 7% | Training loss: 0.6892339916790233
Epoch: 10 | Iteration number: [350/4518] 7% | Training loss: 0.6891646294934409
Epoch: 10 | Iteration number: [360/4518] 7% | Training loss: 0.6891120268238915
Epoch: 10 | Iteration number: [370/4518] 8% | Training loss: 0.6890422365149936
Epoch: 10 | Iteration number: [380/4518] 8% | Training loss: 0.6889851347396249
Epoch: 10 | Iteration number: [390/4518] 8% | Training loss: 0.6889620273541182
Epoch: 10 | Iteration number: [400/4518] 8% | Training loss: 0.6889310853183269
Epoch: 10 | Iteration number: [410/4518] 9% | Training loss: 0.6888635011707864
Epoch: 10 | Iteration number: [420/4518] 9% | Training loss: 0.688811984942073
Epoch: 10 | Iteration number: [430/4518] 9% | Training loss: 0.6887637915999391
Epoch: 10 | Iteration number: [440/4518] 9% | Training loss: 0.6887303470210595
Epoch: 10 | Iteration number: [450/4518] 9% | Training loss: 0.6886773878998227
Epoch: 10 | Iteration number: [460/4518] 10% | Training loss: 0.6886257986659589
Epoch: 10 | Iteration number: [470/4518] 10% | Training loss: 0.6885960675300435
Epoch: 10 | Iteration number: [480/4518] 10% | Training loss: 0.6885752561191718
Epoch: 10 | Iteration number: [490/4518] 10% | Training loss: 0.6885303468120342
Epoch: 10 | Iteration number: [500/4518] 11% | Training loss: 0.6885187411308289
Epoch: 10 | Iteration number: [510/4518] 11% | Training loss: 0.6885051066968956
Epoch: 10 | Iteration number: [520/4518] 11% | Training loss: 0.6884352624416351
Epoch: 10 | Iteration number: [530/4518] 11% | Training loss: 0.6884125287802714
Epoch: 10 | Iteration number: [540/4518] 11% | Training loss: 0.6884076405454564
Epoch: 10 | Iteration number: [550/4518] 12% | Training loss: 0.6883853703195398
Epoch: 10 | Iteration number: [560/4518] 12% | Training loss: 0.68835509121418
Epoch: 10 | Iteration number: [570/4518] 12% | Training loss: 0.6883498665533567
Epoch: 10 | Iteration number: [580/4518] 12% | Training loss: 0.68831189911941
Epoch: 10 | Iteration number: [590/4518] 13% | Training loss: 0.6883046099695108
Epoch: 10 | Iteration number: [600/4518] 13% | Training loss: 0.6882924501101176
Epoch: 10 | Iteration number: [610/4518] 13% | Training loss: 0.6882884845381877
Epoch: 10 | Iteration number: [620/4518] 13% | Training loss: 0.6882744854496371
Epoch: 10 | Iteration number: [630/4518] 13% | Training loss: 0.6882764504069374
Epoch: 10 | Iteration number: [640/4518] 14% | Training loss: 0.6882646442390978
Epoch: 10 | Iteration number: [650/4518] 14% | Training loss: 0.6882304220016187
Epoch: 10 | Iteration number: [660/4518] 14% | Training loss: 0.6882212302901528
Epoch: 10 | Iteration number: [670/4518] 14% | Training loss: 0.6881965091869012
Epoch: 10 | Iteration number: [680/4518] 15% | Training loss: 0.688170954848037
Epoch: 10 | Iteration number: [690/4518] 15% | Training loss: 0.6881584119105685
Epoch: 10 | Iteration number: [700/4518] 15% | Training loss: 0.6881455911908831
Epoch: 10 | Iteration number: [710/4518] 15% | Training loss: 0.6881405246929384
Epoch: 10 | Iteration number: [720/4518] 15% | Training loss: 0.6881084227727519
Epoch: 10 | Iteration number: [730/4518] 16% | Training loss: 0.6880702285733942
Epoch: 10 | Iteration number: [740/4518] 16% | Training loss: 0.6880646645217329
Epoch: 10 | Iteration number: [750/4518] 16% | Training loss: 0.688057137409846
Epoch: 10 | Iteration number: [760/4518] 16% | Training loss: 0.6880443699265781
Epoch: 10 | Iteration number: [770/4518] 17% | Training loss: 0.6880168782426165
Epoch: 10 | Iteration number: [780/4518] 17% | Training loss: 0.6880094188910264
Epoch: 10 | Iteration number: [790/4518] 17% | Training loss: 0.6880026140544988
Epoch: 10 | Iteration number: [800/4518] 17% | Training loss: 0.68799375385046
Epoch: 10 | Iteration number: [810/4518] 17% | Training loss: 0.6879779960638212
Epoch: 10 | Iteration number: [820/4518] 18% | Training loss: 0.6879519849288754
Epoch: 10 | Iteration number: [830/4518] 18% | Training loss: 0.6879551571535777
Epoch: 10 | Iteration number: [840/4518] 18% | Training loss: 0.6879470934470494
Epoch: 10 | Iteration number: [850/4518] 18% | Training loss: 0.6879338893469642
Epoch: 10 | Iteration number: [860/4518] 19% | Training loss: 0.6879202573798423
Epoch: 10 | Iteration number: [870/4518] 19% | Training loss: 0.6879072430490077
Epoch: 10 | Iteration number: [880/4518] 19% | Training loss: 0.6879070153290575
Epoch: 10 | Iteration number: [890/4518] 19% | Training loss: 0.687896054983139
Epoch: 10 | Iteration number: [900/4518] 19% | Training loss: 0.6878821348481708
Epoch: 10 | Iteration number: [910/4518] 20% | Training loss: 0.6878617176642785
Epoch: 10 | Iteration number: [920/4518] 20% | Training loss: 0.6878391782874647
Epoch: 10 | Iteration number: [930/4518] 20% | Training loss: 0.6878408164747299
Epoch: 10 | Iteration number: [940/4518] 20% | Training loss: 0.6878411176990955
Epoch: 10 | Iteration number: [950/4518] 21% | Training loss: 0.6878478771761845
Epoch: 10 | Iteration number: [960/4518] 21% | Training loss: 0.6878499516596397
Epoch: 10 | Iteration number: [970/4518] 21% | Training loss: 0.6878361242333638
Epoch: 10 | Iteration number: [980/4518] 21% | Training loss: 0.687833772934213
Epoch: 10 | Iteration number: [990/4518] 21% | Training loss: 0.687829296034996
Epoch: 10 | Iteration number: [1000/4518] 22% | Training loss: 0.687815126478672
Epoch: 10 | Iteration number: [1010/4518] 22% | Training loss: 0.6878121791499676
Epoch: 10 | Iteration number: [1020/4518] 22% | Training loss: 0.6877968483695797
Epoch: 10 | Iteration number: [1030/4518] 22% | Training loss: 0.6877771540752893
Epoch: 10 | Iteration number: [1040/4518] 23% | Training loss: 0.687766738064014
Epoch: 10 | Iteration number: [1050/4518] 23% | Training loss: 0.6877490514800662
Epoch: 10 | Iteration number: [1060/4518] 23% | Training loss: 0.6877438424893145
Epoch: 10 | Iteration number: [1070/4518] 23% | Training loss: 0.6877316227026075
Epoch: 10 | Iteration number: [1080/4518] 23% | Training loss: 0.6877119538960633
Epoch: 10 | Iteration number: [1090/4518] 24% | Training loss: 0.6877181129718045
Epoch: 10 | Iteration number: [1100/4518] 24% | Training loss: 0.6877070910822262
Epoch: 10 | Iteration number: [1110/4518] 24% | Training loss: 0.6876987723079888
Epoch: 10 | Iteration number: [1120/4518] 24% | Training loss: 0.6876929090491363
Epoch: 10 | Iteration number: [1130/4518] 25% | Training loss: 0.6876861924091272
Epoch: 10 | Iteration number: [1140/4518] 25% | Training loss: 0.6876800030992742
Epoch: 10 | Iteration number: [1150/4518] 25% | Training loss: 0.6876598265896673
Epoch: 10 | Iteration number: [1160/4518] 25% | Training loss: 0.687667981406738
Epoch: 10 | Iteration number: [1170/4518] 25% | Training loss: 0.6876585463173369
Epoch: 10 | Iteration number: [1180/4518] 26% | Training loss: 0.6876415985115504
Epoch: 10 | Iteration number: [1190/4518] 26% | Training loss: 0.687641425944176
Epoch: 10 | Iteration number: [1200/4518] 26% | Training loss: 0.6876503845055898
Epoch: 10 | Iteration number: [1210/4518] 26% | Training loss: 0.6876289035663132
Epoch: 10 | Iteration number: [1220/4518] 27% | Training loss: 0.687629170544812
Epoch: 10 | Iteration number: [1230/4518] 27% | Training loss: 0.6876260684273108
Epoch: 10 | Iteration number: [1240/4518] 27% | Training loss: 0.6876210304037217
Epoch: 10 | Iteration number: [1250/4518] 27% | Training loss: 0.6876218876361847
Epoch: 10 | Iteration number: [1260/4518] 27% | Training loss: 0.687629245339878
Epoch: 10 | Iteration number: [1270/4518] 28% | Training loss: 0.6876340883923328
Epoch: 10 | Iteration number: [1280/4518] 28% | Training loss: 0.6876226235181093
Epoch: 10 | Iteration number: [1290/4518] 28% | Training loss: 0.6876164436340332
Epoch: 10 | Iteration number: [1300/4518] 28% | Training loss: 0.6876090121727724
Epoch: 10 | Iteration number: [1310/4518] 28% | Training loss: 0.6875935862537559
Epoch: 10 | Iteration number: [1320/4518] 29% | Training loss: 0.6875941816152948
Epoch: 10 | Iteration number: [1330/4518] 29% | Training loss: 0.6875914138958866
Epoch: 10 | Iteration number: [1340/4518] 29% | Training loss: 0.6875904111719843
Epoch: 10 | Iteration number: [1350/4518] 29% | Training loss: 0.6875939755086545
Epoch: 10 | Iteration number: [1360/4518] 30% | Training loss: 0.6875827632406178
Epoch: 10 | Iteration number: [1370/4518] 30% | Training loss: 0.687581134669102
Epoch: 10 | Iteration number: [1380/4518] 30% | Training loss: 0.6875890093437139
Epoch: 10 | Iteration number: [1390/4518] 30% | Training loss: 0.6875741458625244
Epoch: 10 | Iteration number: [1400/4518] 30% | Training loss: 0.6875781847749438
Epoch: 10 | Iteration number: [1410/4518] 31% | Training loss: 0.6875769524709553
Epoch: 10 | Iteration number: [1420/4518] 31% | Training loss: 0.6875768865078268
Epoch: 10 | Iteration number: [1430/4518] 31% | Training loss: 0.6875698422635352
Epoch: 10 | Iteration number: [1440/4518] 31% | Training loss: 0.6875666504932775
Epoch: 10 | Iteration number: [1450/4518] 32% | Training loss: 0.6875670322467541
Epoch: 10 | Iteration number: [1460/4518] 32% | Training loss: 0.6875598865420851
Epoch: 10 | Iteration number: [1470/4518] 32% | Training loss: 0.6875518397003615
Epoch: 10 | Iteration number: [1480/4518] 32% | Training loss: 0.6875518789967975
Epoch: 10 | Iteration number: [1490/4518] 32% | Training loss: 0.68753091352898
Epoch: 10 | Iteration number: [1500/4518] 33% | Training loss: 0.6875318232774734
Epoch: 10 | Iteration number: [1510/4518] 33% | Training loss: 0.6875212155825255
Epoch: 10 | Iteration number: [1520/4518] 33% | Training loss: 0.6875210447923134
Epoch: 10 | Iteration number: [1530/4518] 33% | Training loss: 0.6875144358553917
Epoch: 10 | Iteration number: [1540/4518] 34% | Training loss: 0.687513306969172
Epoch: 10 | Iteration number: [1550/4518] 34% | Training loss: 0.6875092596007931
Epoch: 10 | Iteration number: [1560/4518] 34% | Training loss: 0.6875051948886651
Epoch: 10 | Iteration number: [1570/4518] 34% | Training loss: 0.6874953344749037
Epoch: 10 | Iteration number: [1580/4518] 34% | Training loss: 0.6874903580433206
Epoch: 10 | Iteration number: [1590/4518] 35% | Training loss: 0.6874850740972555
Epoch: 10 | Iteration number: [1600/4518] 35% | Training loss: 0.687476202249527
Epoch: 10 | Iteration number: [1610/4518] 35% | Training loss: 0.6874724543612937
Epoch: 10 | Iteration number: [1620/4518] 35% | Training loss: 0.6874747935636544
Epoch: 10 | Iteration number: [1630/4518] 36% | Training loss: 0.6874720088909009
Epoch: 10 | Iteration number: [1640/4518] 36% | Training loss: 0.6874690432010627
Epoch: 10 | Iteration number: [1650/4518] 36% | Training loss: 0.6874635198983279
Epoch: 10 | Iteration number: [1660/4518] 36% | Training loss: 0.6874570737761188
Epoch: 10 | Iteration number: [1670/4518] 36% | Training loss: 0.6874569138010105
Epoch: 10 | Iteration number: [1680/4518] 37% | Training loss: 0.6874586413658801
Epoch: 10 | Iteration number: [1690/4518] 37% | Training loss: 0.6874496997813502
Epoch: 10 | Iteration number: [1700/4518] 37% | Training loss: 0.6874485851035399
Epoch: 10 | Iteration number: [1710/4518] 37% | Training loss: 0.687442955392146
Epoch: 10 | Iteration number: [1720/4518] 38% | Training loss: 0.6874419807001602
Epoch: 10 | Iteration number: [1730/4518] 38% | Training loss: 0.6874346313793536
Epoch: 10 | Iteration number: [1740/4518] 38% | Training loss: 0.6874316331641427
Epoch: 10 | Iteration number: [1750/4518] 38% | Training loss: 0.6874188172476632
Epoch: 10 | Iteration number: [1760/4518] 38% | Training loss: 0.6874125737696886
Epoch: 10 | Iteration number: [1770/4518] 39% | Training loss: 0.6874089130237278
Epoch: 10 | Iteration number: [1780/4518] 39% | Training loss: 0.6873985914032111
Epoch: 10 | Iteration number: [1790/4518] 39% | Training loss: 0.6874026267222186
Epoch: 10 | Iteration number: [1800/4518] 39% | Training loss: 0.6873986681964662
Epoch: 10 | Iteration number: [1810/4518] 40% | Training loss: 0.687394774289421
Epoch: 10 | Iteration number: [1820/4518] 40% | Training loss: 0.6873907589977915
Epoch: 10 | Iteration number: [1830/4518] 40% | Training loss: 0.6873865783865986
Epoch: 10 | Iteration number: [1840/4518] 40% | Training loss: 0.6873872571989246
Epoch: 10 | Iteration number: [1850/4518] 40% | Training loss: 0.6873891203790098
Epoch: 10 | Iteration number: [1860/4518] 41% | Training loss: 0.6873845373430559
Epoch: 10 | Iteration number: [1870/4518] 41% | Training loss: 0.6873871143807702
Epoch: 10 | Iteration number: [1880/4518] 41% | Training loss: 0.6873764151905445
Epoch: 10 | Iteration number: [1890/4518] 41% | Training loss: 0.687367062183915
Epoch: 10 | Iteration number: [1900/4518] 42% | Training loss: 0.687366205861694
Epoch: 10 | Iteration number: [1910/4518] 42% | Training loss: 0.6873582101305118
Epoch: 10 | Iteration number: [1920/4518] 42% | Training loss: 0.6873615401796996
Epoch: 10 | Iteration number: [1930/4518] 42% | Training loss: 0.6873510648858362
Epoch: 10 | Iteration number: [1940/4518] 42% | Training loss: 0.6873489254528714
Epoch: 10 | Iteration number: [1950/4518] 43% | Training loss: 0.6873488899072011
Epoch: 10 | Iteration number: [1960/4518] 43% | Training loss: 0.6873451808581547
Epoch: 10 | Iteration number: [1970/4518] 43% | Training loss: 0.6873448483229894
Epoch: 10 | Iteration number: [1980/4518] 43% | Training loss: 0.6873499134875307
Epoch: 10 | Iteration number: [1990/4518] 44% | Training loss: 0.6873466820273567
Epoch: 10 | Iteration number: [2000/4518] 44% | Training loss: 0.6873465624153614
Epoch: 10 | Iteration number: [2010/4518] 44% | Training loss: 0.6873508072907651
Epoch: 10 | Iteration number: [2020/4518] 44% | Training loss: 0.6873454478117499
Epoch: 10 | Iteration number: [2030/4518] 44% | Training loss: 0.6873491700353294
Epoch: 10 | Iteration number: [2040/4518] 45% | Training loss: 0.6873437340937408
Epoch: 10 | Iteration number: [2050/4518] 45% | Training loss: 0.6873440906768892
Epoch: 10 | Iteration number: [2060/4518] 45% | Training loss: 0.6873404945852687
Epoch: 10 | Iteration number: [2070/4518] 45% | Training loss: 0.6873368778378491
Epoch: 10 | Iteration number: [2080/4518] 46% | Training loss: 0.6873357844180785
Epoch: 10 | Iteration number: [2090/4518] 46% | Training loss: 0.6873332986991372
Epoch: 10 | Iteration number: [2100/4518] 46% | Training loss: 0.6873307789507367
Epoch: 10 | Iteration number: [2110/4518] 46% | Training loss: 0.6873290369578448
Epoch: 10 | Iteration number: [2120/4518] 46% | Training loss: 0.6873275641843958
Epoch: 10 | Iteration number: [2130/4518] 47% | Training loss: 0.6873217565073094
Epoch: 10 | Iteration number: [2140/4518] 47% | Training loss: 0.687319865516413
Epoch: 10 | Iteration number: [2150/4518] 47% | Training loss: 0.687317433745362
Epoch: 10 | Iteration number: [2160/4518] 47% | Training loss: 0.6873214773005909
Epoch: 10 | Iteration number: [2170/4518] 48% | Training loss: 0.6873249270674271
Epoch: 10 | Iteration number: [2180/4518] 48% | Training loss: 0.6873171763956
Epoch: 10 | Iteration number: [2190/4518] 48% | Training loss: 0.6873206638037886
Epoch: 10 | Iteration number: [2200/4518] 48% | Training loss: 0.6873113157532432
Epoch: 10 | Iteration number: [2210/4518] 48% | Training loss: 0.6873190781919125
Epoch: 10 | Iteration number: [2220/4518] 49% | Training loss: 0.687320810019433
Epoch: 10 | Iteration number: [2230/4518] 49% | Training loss: 0.6873224890285543
Epoch: 10 | Iteration number: [2240/4518] 49% | Training loss: 0.6873258244246244
Epoch: 10 | Iteration number: [2250/4518] 49% | Training loss: 0.6873239873515236
Epoch: 10 | Iteration number: [2260/4518] 50% | Training loss: 0.687328329603229
Epoch: 10 | Iteration number: [2270/4518] 50% | Training loss: 0.6873265484093569
Epoch: 10 | Iteration number: [2280/4518] 50% | Training loss: 0.6873242328041478
Epoch: 10 | Iteration number: [2290/4518] 50% | Training loss: 0.6873190797832855
Epoch: 10 | Iteration number: [2300/4518] 50% | Training loss: 0.6873201598291812
Epoch: 10 | Iteration number: [2310/4518] 51% | Training loss: 0.6873176705527615
Epoch: 10 | Iteration number: [2320/4518] 51% | Training loss: 0.6873196026631471
Epoch: 10 | Iteration number: [2330/4518] 51% | Training loss: 0.6873191264821736
Epoch: 10 | Iteration number: [2340/4518] 51% | Training loss: 0.6873166488531308
Epoch: 10 | Iteration number: [2350/4518] 52% | Training loss: 0.6873181287785793
Epoch: 10 | Iteration number: [2360/4518] 52% | Training loss: 0.6873170493012768
Epoch: 10 | Iteration number: [2370/4518] 52% | Training loss: 0.6873079745075371
Epoch: 10 | Iteration number: [2380/4518] 52% | Training loss: 0.6873092551441754
Epoch: 10 | Iteration number: [2390/4518] 52% | Training loss: 0.6873049855481631
Epoch: 10 | Iteration number: [2400/4518] 53% | Training loss: 0.6873002837349971
Epoch: 10 | Iteration number: [2410/4518] 53% | Training loss: 0.6873005927598328
Epoch: 10 | Iteration number: [2420/4518] 53% | Training loss: 0.6873025166594292
Epoch: 10 | Iteration number: [2430/4518] 53% | Training loss: 0.6873012190493046
Epoch: 10 | Iteration number: [2440/4518] 54% | Training loss: 0.6872977885310767
Epoch: 10 | Iteration number: [2450/4518] 54% | Training loss: 0.6872987249919347
Epoch: 10 | Iteration number: [2460/4518] 54% | Training loss: 0.6872969447112665
Epoch: 10 | Iteration number: [2470/4518] 54% | Training loss: 0.6872879944108276
Epoch: 10 | Iteration number: [2480/4518] 54% | Training loss: 0.6872875253279362
Epoch: 10 | Iteration number: [2490/4518] 55% | Training loss: 0.6872857233367292
Epoch: 10 | Iteration number: [2500/4518] 55% | Training loss: 0.6872895324468613
Epoch: 10 | Iteration number: [2510/4518] 55% | Training loss: 0.6872828696116033
Epoch: 10 | Iteration number: [2520/4518] 55% | Training loss: 0.6872823758730813
Epoch: 10 | Iteration number: [2530/4518] 55% | Training loss: 0.6872790881296391
Epoch: 10 | Iteration number: [2540/4518] 56% | Training loss: 0.6872752927889035
Epoch: 10 | Iteration number: [2550/4518] 56% | Training loss: 0.6872744211262347
Epoch: 10 | Iteration number: [2560/4518] 56% | Training loss: 0.6872679725987837
Epoch: 10 | Iteration number: [2570/4518] 56% | Training loss: 0.6872682439909835
Epoch: 10 | Iteration number: [2580/4518] 57% | Training loss: 0.687266821824303
Epoch: 10 | Iteration number: [2590/4518] 57% | Training loss: 0.6872612966763927
Epoch: 10 | Iteration number: [2600/4518] 57% | Training loss: 0.6872653158352925
Epoch: 10 | Iteration number: [2610/4518] 57% | Training loss: 0.6872643100119186
Epoch: 10 | Iteration number: [2620/4518] 57% | Training loss: 0.6872632385665224
Epoch: 10 | Iteration number: [2630/4518] 58% | Training loss: 0.6872624067752534
Epoch: 10 | Iteration number: [2640/4518] 58% | Training loss: 0.687265658288291
Epoch: 10 | Iteration number: [2650/4518] 58% | Training loss: 0.6872601474231144
Epoch: 10 | Iteration number: [2660/4518] 58% | Training loss: 0.6872605767465175
Epoch: 10 | Iteration number: [2670/4518] 59% | Training loss: 0.6872601378946268
Epoch: 10 | Iteration number: [2680/4518] 59% | Training loss: 0.6872603411327547
Epoch: 10 | Iteration number: [2690/4518] 59% | Training loss: 0.687259724858082
Epoch: 10 | Iteration number: [2700/4518] 59% | Training loss: 0.6872588116151315
Epoch: 10 | Iteration number: [2710/4518] 59% | Training loss: 0.6872609069206618
Epoch: 10 | Iteration number: [2720/4518] 60% | Training loss: 0.6872639704714804
Epoch: 10 | Iteration number: [2730/4518] 60% | Training loss: 0.6872596350126651
Epoch: 10 | Iteration number: [2740/4518] 60% | Training loss: 0.6872580237849786
Epoch: 10 | Iteration number: [2750/4518] 60% | Training loss: 0.6872599586140026
Epoch: 10 | Iteration number: [2760/4518] 61% | Training loss: 0.6872567430570505
Epoch: 10 | Iteration number: [2770/4518] 61% | Training loss: 0.6872575556973688
Epoch: 10 | Iteration number: [2780/4518] 61% | Training loss: 0.6872584912202341
Epoch: 10 | Iteration number: [2790/4518] 61% | Training loss: 0.6872565872353038
Epoch: 10 | Iteration number: [2800/4518] 61% | Training loss: 0.6872547582643372
Epoch: 10 | Iteration number: [2810/4518] 62% | Training loss: 0.687254762988922
Epoch: 10 | Iteration number: [2820/4518] 62% | Training loss: 0.6872566859350137
Epoch: 10 | Iteration number: [2830/4518] 62% | Training loss: 0.6872513724089512
Epoch: 10 | Iteration number: [2840/4518] 62% | Training loss: 0.6872515660356467
Epoch: 10 | Iteration number: [2850/4518] 63% | Training loss: 0.6872544159178148
Epoch: 10 | Iteration number: [2860/4518] 63% | Training loss: 0.6872519837601202
Epoch: 10 | Iteration number: [2870/4518] 63% | Training loss: 0.687250306444301
Epoch: 10 | Iteration number: [2880/4518] 63% | Training loss: 0.6872523679708441
Epoch: 10 | Iteration number: [2890/4518] 63% | Training loss: 0.6872541363057794
Epoch: 10 | Iteration number: [2900/4518] 64% | Training loss: 0.6872532527200107
Epoch: 10 | Iteration number: [2910/4518] 64% | Training loss: 0.6872460761635574
Epoch: 10 | Iteration number: [2920/4518] 64% | Training loss: 0.6872468777307092
Epoch: 10 | Iteration number: [2930/4518] 64% | Training loss: 0.6872512609681986
Epoch: 10 | Iteration number: [2940/4518] 65% | Training loss: 0.6872439448728043
Epoch: 10 | Iteration number: [2950/4518] 65% | Training loss: 0.6872441033185539
Epoch: 10 | Iteration number: [2960/4518] 65% | Training loss: 0.6872387773684553
Epoch: 10 | Iteration number: [2970/4518] 65% | Training loss: 0.6872338947422978
Epoch: 10 | Iteration number: [2980/4518] 65% | Training loss: 0.6872336785465278
Epoch: 10 | Iteration number: [2990/4518] 66% | Training loss: 0.687229023888757
Epoch: 10 | Iteration number: [3000/4518] 66% | Training loss: 0.6872295032540957
Epoch: 10 | Iteration number: [3010/4518] 66% | Training loss: 0.68722936594209
Epoch: 10 | Iteration number: [3020/4518] 66% | Training loss: 0.6872312235713794
Epoch: 10 | Iteration number: [3030/4518] 67% | Training loss: 0.6872320543814807
Epoch: 10 | Iteration number: [3040/4518] 67% | Training loss: 0.6872308215028361
Epoch: 10 | Iteration number: [3050/4518] 67% | Training loss: 0.6872288859085959
Epoch: 10 | Iteration number: [3060/4518] 67% | Training loss: 0.6872255310124042
Epoch: 10 | Iteration number: [3070/4518] 67% | Training loss: 0.6872241274153371
Epoch: 10 | Iteration number: [3080/4518] 68% | Training loss: 0.6872245818570063
Epoch: 10 | Iteration number: [3090/4518] 68% | Training loss: 0.6872169830073817
Epoch: 10 | Iteration number: [3100/4518] 68% | Training loss: 0.6872171610786069
Epoch: 10 | Iteration number: [3110/4518] 68% | Training loss: 0.687217350864717
Epoch: 10 | Iteration number: [3120/4518] 69% | Training loss: 0.6872194486168715
Epoch: 10 | Iteration number: [3130/4518] 69% | Training loss: 0.6872166180572571
Epoch: 10 | Iteration number: [3140/4518] 69% | Training loss: 0.6872157009354063
Epoch: 10 | Iteration number: [3150/4518] 69% | Training loss: 0.6872122993734148
Epoch: 10 | Iteration number: [3160/4518] 69% | Training loss: 0.6872084306010717
Epoch: 10 | Iteration number: [3170/4518] 70% | Training loss: 0.6872094582496006
Epoch: 10 | Iteration number: [3180/4518] 70% | Training loss: 0.6872089871632978
Epoch: 10 | Iteration number: [3190/4518] 70% | Training loss: 0.6872082406450588
Epoch: 10 | Iteration number: [3200/4518] 70% | Training loss: 0.6872068702243268
Epoch: 10 | Iteration number: [3210/4518] 71% | Training loss: 0.6872071186515772
Epoch: 10 | Iteration number: [3220/4518] 71% | Training loss: 0.6872070454662631
Epoch: 10 | Iteration number: [3230/4518] 71% | Training loss: 0.6872058133591809
Epoch: 10 | Iteration number: [3240/4518] 71% | Training loss: 0.6872048741689435
Epoch: 10 | Iteration number: [3250/4518] 71% | Training loss: 0.687203611263862
Epoch: 10 | Iteration number: [3260/4518] 72% | Training loss: 0.6872027584014495
Epoch: 10 | Iteration number: [3270/4518] 72% | Training loss: 0.6871998903948233
Epoch: 10 | Iteration number: [3280/4518] 72% | Training loss: 0.6871977626913931
Epoch: 10 | Iteration number: [3290/4518] 72% | Training loss: 0.6871992276794642
Epoch: 10 | Iteration number: [3300/4518] 73% | Training loss: 0.6871984475309199
Epoch: 10 | Iteration number: [3310/4518] 73% | Training loss: 0.6871990655304082
Epoch: 10 | Iteration number: [3320/4518] 73% | Training loss: 0.6872001033949565
Epoch: 10 | Iteration number: [3330/4518] 73% | Training loss: 0.6872018150202147
Epoch: 10 | Iteration number: [3340/4518] 73% | Training loss: 0.6872025112192074
Epoch: 10 | Iteration number: [3350/4518] 74% | Training loss: 0.6872015226243148
Epoch: 10 | Iteration number: [3360/4518] 74% | Training loss: 0.6872010276431129
Epoch: 10 | Iteration number: [3370/4518] 74% | Training loss: 0.6872023882073536
Epoch: 10 | Iteration number: [3380/4518] 74% | Training loss: 0.6871999343647759
Epoch: 10 | Iteration number: [3390/4518] 75% | Training loss: 0.6872012299246493
Epoch: 10 | Iteration number: [3400/4518] 75% | Training loss: 0.6872016086297876
Epoch: 10 | Iteration number: [3410/4518] 75% | Training loss: 0.6871978687051454
Epoch: 10 | Iteration number: [3420/4518] 75% | Training loss: 0.6871954821703726
Epoch: 10 | Iteration number: [3430/4518] 75% | Training loss: 0.687196925795113
Epoch: 10 | Iteration number: [3440/4518] 76% | Training loss: 0.6871953234423038
Epoch: 10 | Iteration number: [3450/4518] 76% | Training loss: 0.6871918163956076
Epoch: 10 | Iteration number: [3460/4518] 76% | Training loss: 0.6871903375221815
Epoch: 10 | Iteration number: [3470/4518] 76% | Training loss: 0.6871870334450725
Epoch: 10 | Iteration number: [3480/4518] 77% | Training loss: 0.6871863498427402
Epoch: 10 | Iteration number: [3490/4518] 77% | Training loss: 0.6871889945599957
Epoch: 10 | Iteration number: [3500/4518] 77% | Training loss: 0.6871900832823344
Epoch: 10 | Iteration number: [3510/4518] 77% | Training loss: 0.6871855092014683
Epoch: 10 | Iteration number: [3520/4518] 77% | Training loss: 0.6871853561563925
Epoch: 10 | Iteration number: [3530/4518] 78% | Training loss: 0.6871884937326901
Epoch: 10 | Iteration number: [3540/4518] 78% | Training loss: 0.6871890745594003
Epoch: 10 | Iteration number: [3550/4518] 78% | Training loss: 0.6871849665171663
Epoch: 10 | Iteration number: [3560/4518] 78% | Training loss: 0.6871894177760971
Epoch: 10 | Iteration number: [3570/4518] 79% | Training loss: 0.687188313488199
Epoch: 10 | Iteration number: [3580/4518] 79% | Training loss: 0.6871890446826733
Epoch: 10 | Iteration number: [3590/4518] 79% | Training loss: 0.6871895218127949
Epoch: 10 | Iteration number: [3600/4518] 79% | Training loss: 0.6871883926623398
Epoch: 10 | Iteration number: [3610/4518] 79% | Training loss: 0.6871857742193332
Epoch: 10 | Iteration number: [3620/4518] 80% | Training loss: 0.6871851128109252
Epoch: 10 | Iteration number: [3630/4518] 80% | Training loss: 0.6871845312354978
Epoch: 10 | Iteration number: [3640/4518] 80% | Training loss: 0.6871837067407566
Epoch: 10 | Iteration number: [3650/4518] 80% | Training loss: 0.6871817161775615
Epoch: 10 | Iteration number: [3660/4518] 81% | Training loss: 0.6871792081600981
Epoch: 10 | Iteration number: [3670/4518] 81% | Training loss: 0.6871814371617029
Epoch: 10 | Iteration number: [3680/4518] 81% | Training loss: 0.6871827584893807
Epoch: 10 | Iteration number: [3690/4518] 81% | Training loss: 0.6871843136423003
Epoch: 10 | Iteration number: [3700/4518] 81% | Training loss: 0.6871840828818244
Epoch: 10 | Iteration number: [3710/4518] 82% | Training loss: 0.6871821325262281
Epoch: 10 | Iteration number: [3720/4518] 82% | Training loss: 0.6871854422874348
Epoch: 10 | Iteration number: [3730/4518] 82% | Training loss: 0.6871877087984264
Epoch: 10 | Iteration number: [3740/4518] 82% | Training loss: 0.6871879470698974
Epoch: 10 | Iteration number: [3750/4518] 83% | Training loss: 0.6871888160387675
Epoch: 10 | Iteration number: [3760/4518] 83% | Training loss: 0.6871901552410836
Epoch: 10 | Iteration number: [3770/4518] 83% | Training loss: 0.6871909944068848
Epoch: 10 | Iteration number: [3780/4518] 83% | Training loss: 0.6871890929167863
Epoch: 10 | Iteration number: [3790/4518] 83% | Training loss: 0.6871895316408303
Epoch: 10 | Iteration number: [3800/4518] 84% | Training loss: 0.6871926184547575
Epoch: 10 | Iteration number: [3810/4518] 84% | Training loss: 0.6871954349864499
Epoch: 10 | Iteration number: [3820/4518] 84% | Training loss: 0.6871940827806583
Epoch: 10 | Iteration number: [3830/4518] 84% | Training loss: 0.6871923965666997
Epoch: 10 | Iteration number: [3840/4518] 84% | Training loss: 0.6871911509272953
Epoch: 10 | Iteration number: [3850/4518] 85% | Training loss: 0.687192892083874
Epoch: 10 | Iteration number: [3860/4518] 85% | Training loss: 0.6871911778968851
Epoch: 10 | Iteration number: [3870/4518] 85% | Training loss: 0.6871885805475003
Epoch: 10 | Iteration number: [3880/4518] 85% | Training loss: 0.6871842594951698
Epoch: 10 | Iteration number: [3890/4518] 86% | Training loss: 0.687185109366488
Epoch: 10 | Iteration number: [3900/4518] 86% | Training loss: 0.687185044838832
Epoch: 10 | Iteration number: [3910/4518] 86% | Training loss: 0.6871840161740628
Epoch: 10 | Iteration number: [3920/4518] 86% | Training loss: 0.6871836396352369
Epoch: 10 | Iteration number: [3930/4518] 86% | Training loss: 0.6871810442618741
Epoch: 10 | Iteration number: [3940/4518] 87% | Training loss: 0.6871817103345987
Epoch: 10 | Iteration number: [3950/4518] 87% | Training loss: 0.687177323389657
Epoch: 10 | Iteration number: [3960/4518] 87% | Training loss: 0.687176436547077
Epoch: 10 | Iteration number: [3970/4518] 87% | Training loss: 0.6871732483432635
Epoch: 10 | Iteration number: [3980/4518] 88% | Training loss: 0.6871732106160878
Epoch: 10 | Iteration number: [3990/4518] 88% | Training loss: 0.6871722527912685
Epoch: 10 | Iteration number: [4000/4518] 88% | Training loss: 0.6871701867431402
Epoch: 10 | Iteration number: [4010/4518] 88% | Training loss: 0.6871685524385172
Epoch: 10 | Iteration number: [4020/4518] 88% | Training loss: 0.687166295404458
Epoch: 10 | Iteration number: [4030/4518] 89% | Training loss: 0.6871649771115325
Epoch: 10 | Iteration number: [4040/4518] 89% | Training loss: 0.6871635265279524
Epoch: 10 | Iteration number: [4050/4518] 89% | Training loss: 0.6871622428923477
Epoch: 10 | Iteration number: [4060/4518] 89% | Training loss: 0.6871655518198249
Epoch: 10 | Iteration number: [4070/4518] 90% | Training loss: 0.6871668206532405
Epoch: 10 | Iteration number: [4080/4518] 90% | Training loss: 0.687163117294218
Epoch: 10 | Iteration number: [4090/4518] 90% | Training loss: 0.68715851917535
Epoch: 10 | Iteration number: [4100/4518] 90% | Training loss: 0.6871596515469435
Epoch: 10 | Iteration number: [4110/4518] 90% | Training loss: 0.687161721234774
Epoch: 10 | Iteration number: [4120/4518] 91% | Training loss: 0.6871610982759485
Epoch: 10 | Iteration number: [4130/4518] 91% | Training loss: 0.6871609738028944
Epoch: 10 | Iteration number: [4140/4518] 91% | Training loss: 0.6871619314819143
Epoch: 10 | Iteration number: [4150/4518] 91% | Training loss: 0.6871620659799461
Epoch: 10 | Iteration number: [4160/4518] 92% | Training loss: 0.6871639780986768
Epoch: 10 | Iteration number: [4170/4518] 92% | Training loss: 0.6871644610123668
Epoch: 10 | Iteration number: [4180/4518] 92% | Training loss: 0.6871641464638368
Epoch: 10 | Iteration number: [4190/4518] 92% | Training loss: 0.6871632391769164
Epoch: 10 | Iteration number: [4200/4518] 92% | Training loss: 0.6871649272385097
Epoch: 10 | Iteration number: [4210/4518] 93% | Training loss: 0.6871697211350511
Epoch: 10 | Iteration number: [4220/4518] 93% | Training loss: 0.6871669711377384
Epoch: 10 | Iteration number: [4230/4518] 93% | Training loss: 0.687166079153124
Epoch: 10 | Iteration number: [4240/4518] 93% | Training loss: 0.6871656383686471
Epoch: 10 | Iteration number: [4250/4518] 94% | Training loss: 0.6871644256675945
Epoch: 10 | Iteration number: [4260/4518] 94% | Training loss: 0.6871678409302179
Epoch: 10 | Iteration number: [4270/4518] 94% | Training loss: 0.6871695772825416
Epoch: 10 | Iteration number: [4280/4518] 94% | Training loss: 0.6871700718720383
Epoch: 10 | Iteration number: [4290/4518] 94% | Training loss: 0.6871720584817144
Epoch: 10 | Iteration number: [4300/4518] 95% | Training loss: 0.687173077727473
Epoch: 10 | Iteration number: [4310/4518] 95% | Training loss: 0.6871715035903205
Epoch: 10 | Iteration number: [4320/4518] 95% | Training loss: 0.6871729263690887
Epoch: 10 | Iteration number: [4330/4518] 95% | Training loss: 0.6871673400903133
Epoch: 10 | Iteration number: [4340/4518] 96% | Training loss: 0.687164062357718
Epoch: 10 | Iteration number: [4350/4518] 96% | Training loss: 0.6871627941487849
Epoch: 10 | Iteration number: [4360/4518] 96% | Training loss: 0.6871639998134124
Epoch: 10 | Iteration number: [4370/4518] 96% | Training loss: 0.6871637462342085
Epoch: 10 | Iteration number: [4380/4518] 96% | Training loss: 0.6871619351650482
Epoch: 10 | Iteration number: [4390/4518] 97% | Training loss: 0.6871593821836224
Epoch: 10 | Iteration number: [4400/4518] 97% | Training loss: 0.6871611774780534
Epoch: 10 | Iteration number: [4410/4518] 97% | Training loss: 0.6871598807997714
Epoch: 10 | Iteration number: [4420/4518] 97% | Training loss: 0.6871598889789969
Epoch: 10 | Iteration number: [4430/4518] 98% | Training loss: 0.6871574556316263
Epoch: 10 | Iteration number: [4440/4518] 98% | Training loss: 0.6871551824716834
Epoch: 10 | Iteration number: [4450/4518] 98% | Training loss: 0.6871531643492452
Epoch: 10 | Iteration number: [4460/4518] 98% | Training loss: 0.6871546638386132
Epoch: 10 | Iteration number: [4470/4518] 98% | Training loss: 0.6871560159412273
Epoch: 10 | Iteration number: [4480/4518] 99% | Training loss: 0.6871540901916368
Epoch: 10 | Iteration number: [4490/4518] 99% | Training loss: 0.6871536288601253
Epoch: 10 | Iteration number: [4500/4518] 99% | Training loss: 0.687153143260214
Epoch: 10 | Iteration number: [4510/4518] 99% | Training loss: 0.6871517257785585

 End of epoch: 10 | Train Loss: 0.6870015970554537 | Training Time: 642 

 End of epoch: 10 | Eval Loss: 0.6902301104701295 | Evaluating Time: 17 
Epoch: 11 | Iteration number: [10/4518] 0% | Training loss: 0.754295951128006
Epoch: 11 | Iteration number: [20/4518] 0% | Training loss: 0.7211312174797058
Epoch: 11 | Iteration number: [30/4518] 0% | Training loss: 0.7098366320133209
Epoch: 11 | Iteration number: [40/4518] 0% | Training loss: 0.7040175378322602
Epoch: 11 | Iteration number: [50/4518] 1% | Training loss: 0.7005221045017243
Epoch: 11 | Iteration number: [60/4518] 1% | Training loss: 0.698280558983485
Epoch: 11 | Iteration number: [70/4518] 1% | Training loss: 0.6967429314340864
Epoch: 11 | Iteration number: [80/4518] 1% | Training loss: 0.6955769561231137
Epoch: 11 | Iteration number: [90/4518] 1% | Training loss: 0.6945405900478363
Epoch: 11 | Iteration number: [100/4518] 2% | Training loss: 0.693713316321373
Epoch: 11 | Iteration number: [110/4518] 2% | Training loss: 0.6930949346585707
Epoch: 11 | Iteration number: [120/4518] 2% | Training loss: 0.692587973177433
Epoch: 11 | Iteration number: [130/4518] 2% | Training loss: 0.6922271004089943
Epoch: 11 | Iteration number: [140/4518] 3% | Training loss: 0.6918780471597399
Epoch: 11 | Iteration number: [150/4518] 3% | Training loss: 0.6915664652983348
Epoch: 11 | Iteration number: [160/4518] 3% | Training loss: 0.691243464499712
Epoch: 11 | Iteration number: [170/4518] 3% | Training loss: 0.6909951066269594
Epoch: 11 | Iteration number: [180/4518] 3% | Training loss: 0.6907081064250734
Epoch: 11 | Iteration number: [190/4518] 4% | Training loss: 0.6905957695684934
Epoch: 11 | Iteration number: [200/4518] 4% | Training loss: 0.6904157409071923
Epoch: 11 | Iteration number: [210/4518] 4% | Training loss: 0.6902187145891644
Epoch: 11 | Iteration number: [220/4518] 4% | Training loss: 0.6900473908944563
Epoch: 11 | Iteration number: [230/4518] 5% | Training loss: 0.6898987749348516
Epoch: 11 | Iteration number: [240/4518] 5% | Training loss: 0.689765687038501
Epoch: 11 | Iteration number: [250/4518] 5% | Training loss: 0.6897034201622009
Epoch: 11 | Iteration number: [260/4518] 5% | Training loss: 0.6896578266070439
Epoch: 11 | Iteration number: [270/4518] 5% | Training loss: 0.689559695897279
Epoch: 11 | Iteration number: [280/4518] 6% | Training loss: 0.6894443480031831
Epoch: 11 | Iteration number: [290/4518] 6% | Training loss: 0.6893476521146709
Epoch: 11 | Iteration number: [300/4518] 6% | Training loss: 0.6892855225006739
Epoch: 11 | Iteration number: [310/4518] 6% | Training loss: 0.6892012613434946
Epoch: 11 | Iteration number: [320/4518] 7% | Training loss: 0.6891799386590719
Epoch: 11 | Iteration number: [330/4518] 7% | Training loss: 0.6891268060062871
Epoch: 11 | Iteration number: [340/4518] 7% | Training loss: 0.6890150795964634
Epoch: 11 | Iteration number: [350/4518] 7% | Training loss: 0.6889829669679914
Epoch: 11 | Iteration number: [360/4518] 7% | Training loss: 0.6889565964539845
Epoch: 11 | Iteration number: [370/4518] 8% | Training loss: 0.6888839555753244
Epoch: 11 | Iteration number: [380/4518] 8% | Training loss: 0.688848960085919
Epoch: 11 | Iteration number: [390/4518] 8% | Training loss: 0.688774818334824
Epoch: 11 | Iteration number: [400/4518] 8% | Training loss: 0.6887449499964714
Epoch: 11 | Iteration number: [410/4518] 9% | Training loss: 0.6886436042262287
Epoch: 11 | Iteration number: [420/4518] 9% | Training loss: 0.688608790863128
Epoch: 11 | Iteration number: [430/4518] 9% | Training loss: 0.6885800252127093
Epoch: 11 | Iteration number: [440/4518] 9% | Training loss: 0.688535311953588
Epoch: 11 | Iteration number: [450/4518] 9% | Training loss: 0.6884883983929952
Epoch: 11 | Iteration number: [460/4518] 10% | Training loss: 0.6884519097597702
Epoch: 11 | Iteration number: [470/4518] 10% | Training loss: 0.6884138341913832
Epoch: 11 | Iteration number: [480/4518] 10% | Training loss: 0.6883722337583701
Epoch: 11 | Iteration number: [490/4518] 10% | Training loss: 0.688328227583243
Epoch: 11 | Iteration number: [500/4518] 11% | Training loss: 0.6883355853557587
Epoch: 11 | Iteration number: [510/4518] 11% | Training loss: 0.6882808192103517
Epoch: 11 | Iteration number: [520/4518] 11% | Training loss: 0.6882888204776324
Epoch: 11 | Iteration number: [530/4518] 11% | Training loss: 0.6882652024053177
Epoch: 11 | Iteration number: [540/4518] 11% | Training loss: 0.6882578407172804
Epoch: 11 | Iteration number: [550/4518] 12% | Training loss: 0.6882459678433158
Epoch: 11 | Iteration number: [560/4518] 12% | Training loss: 0.6882045135966369
Epoch: 11 | Iteration number: [570/4518] 12% | Training loss: 0.6881560298434475
Epoch: 11 | Iteration number: [580/4518] 12% | Training loss: 0.688115445909829
Epoch: 11 | Iteration number: [590/4518] 13% | Training loss: 0.6881046158782507
Epoch: 11 | Iteration number: [600/4518] 13% | Training loss: 0.6881159719824791
Epoch: 11 | Iteration number: [610/4518] 13% | Training loss: 0.6880926075528879
Epoch: 11 | Iteration number: [620/4518] 13% | Training loss: 0.6880914326637022
Epoch: 11 | Iteration number: [630/4518] 13% | Training loss: 0.6880830096820044
Epoch: 11 | Iteration number: [640/4518] 14% | Training loss: 0.6880480182357133
Epoch: 11 | Iteration number: [650/4518] 14% | Training loss: 0.6879986073420598
Epoch: 11 | Iteration number: [660/4518] 14% | Training loss: 0.6879736203135867
Epoch: 11 | Iteration number: [670/4518] 14% | Training loss: 0.6879514111511743
Epoch: 11 | Iteration number: [680/4518] 15% | Training loss: 0.6879232703762896
Epoch: 11 | Iteration number: [690/4518] 15% | Training loss: 0.6879171608150869
Epoch: 11 | Iteration number: [700/4518] 15% | Training loss: 0.6879172039031982
Epoch: 11 | Iteration number: [710/4518] 15% | Training loss: 0.6879192348936913
Epoch: 11 | Iteration number: [720/4518] 15% | Training loss: 0.6878999094168345
Epoch: 11 | Iteration number: [730/4518] 16% | Training loss: 0.6878802777153172
Epoch: 11 | Iteration number: [740/4518] 16% | Training loss: 0.6878548664821161
Epoch: 11 | Iteration number: [750/4518] 16% | Training loss: 0.6878251087665558
Epoch: 11 | Iteration number: [760/4518] 16% | Training loss: 0.6878340408205986
Epoch: 11 | Iteration number: [770/4518] 17% | Training loss: 0.6878220993203003
Epoch: 11 | Iteration number: [780/4518] 17% | Training loss: 0.687807718759928
Epoch: 11 | Iteration number: [790/4518] 17% | Training loss: 0.6877894335155246
Epoch: 11 | Iteration number: [800/4518] 17% | Training loss: 0.6877921707928181
Epoch: 11 | Iteration number: [810/4518] 17% | Training loss: 0.6877831194135878
Epoch: 11 | Iteration number: [820/4518] 18% | Training loss: 0.6877744396285312
Epoch: 11 | Iteration number: [830/4518] 18% | Training loss: 0.687752081615379
Epoch: 11 | Iteration number: [840/4518] 18% | Training loss: 0.6877355066793306
Epoch: 11 | Iteration number: [850/4518] 18% | Training loss: 0.6877251877504237
Epoch: 11 | Iteration number: [860/4518] 19% | Training loss: 0.6877077777025311
Epoch: 11 | Iteration number: [870/4518] 19% | Training loss: 0.6877042055130005
Epoch: 11 | Iteration number: [880/4518] 19% | Training loss: 0.687688499418172
Epoch: 11 | Iteration number: [890/4518] 19% | Training loss: 0.68768050503195
Epoch: 11 | Iteration number: [900/4518] 19% | Training loss: 0.6876725619369083
Epoch: 11 | Iteration number: [910/4518] 20% | Training loss: 0.6876513358655867
Epoch: 11 | Iteration number: [920/4518] 20% | Training loss: 0.6876553602192713
Epoch: 11 | Iteration number: [930/4518] 20% | Training loss: 0.687647622118714
Epoch: 11 | Iteration number: [940/4518] 20% | Training loss: 0.6876466600184745
Epoch: 11 | Iteration number: [950/4518] 21% | Training loss: 0.6876454768682781
Epoch: 11 | Iteration number: [960/4518] 21% | Training loss: 0.6876486716171105
Epoch: 11 | Iteration number: [970/4518] 21% | Training loss: 0.6876462285051641
Epoch: 11 | Iteration number: [980/4518] 21% | Training loss: 0.6876272627285549
Epoch: 11 | Iteration number: [990/4518] 21% | Training loss: 0.6876073236417288
Epoch: 11 | Iteration number: [1000/4518] 22% | Training loss: 0.6875941903591156
Epoch: 11 | Iteration number: [1010/4518] 22% | Training loss: 0.6875851330190602
Epoch: 11 | Iteration number: [1020/4518] 22% | Training loss: 0.6875887124561796
Epoch: 11 | Iteration number: [1030/4518] 22% | Training loss: 0.6875839665676784
Epoch: 11 | Iteration number: [1040/4518] 23% | Training loss: 0.6875782219263223
Epoch: 11 | Iteration number: [1050/4518] 23% | Training loss: 0.6875660124279204
Epoch: 11 | Iteration number: [1060/4518] 23% | Training loss: 0.6875635652047283
Epoch: 11 | Iteration number: [1070/4518] 23% | Training loss: 0.6875575908990664
Epoch: 11 | Iteration number: [1080/4518] 23% | Training loss: 0.6875619088610013
Epoch: 11 | Iteration number: [1090/4518] 24% | Training loss: 0.6875483620604244
Epoch: 11 | Iteration number: [1100/4518] 24% | Training loss: 0.6875429142605175
Epoch: 11 | Iteration number: [1110/4518] 24% | Training loss: 0.6875530336891209
Epoch: 11 | Iteration number: [1120/4518] 24% | Training loss: 0.6875443397888116
Epoch: 11 | Iteration number: [1130/4518] 25% | Training loss: 0.6875283210150963
Epoch: 11 | Iteration number: [1140/4518] 25% | Training loss: 0.6875288218259812
Epoch: 11 | Iteration number: [1150/4518] 25% | Training loss: 0.6875184727751691
Epoch: 11 | Iteration number: [1160/4518] 25% | Training loss: 0.6875103094968302
Epoch: 11 | Iteration number: [1170/4518] 25% | Training loss: 0.687504286185289
Epoch: 11 | Iteration number: [1180/4518] 26% | Training loss: 0.6874953410382998
Epoch: 11 | Iteration number: [1190/4518] 26% | Training loss: 0.6874828965223136
Epoch: 11 | Iteration number: [1200/4518] 26% | Training loss: 0.6874835593998432
Epoch: 11 | Iteration number: [1210/4518] 26% | Training loss: 0.6874834232586474
Epoch: 11 | Iteration number: [1220/4518] 27% | Training loss: 0.6874874589873142
Epoch: 11 | Iteration number: [1230/4518] 27% | Training loss: 0.6874730792472032
Epoch: 11 | Iteration number: [1240/4518] 27% | Training loss: 0.6874719464971173
Epoch: 11 | Iteration number: [1250/4518] 27% | Training loss: 0.6874658885002136
Epoch: 11 | Iteration number: [1260/4518] 27% | Training loss: 0.6874701218472586
Epoch: 11 | Iteration number: [1270/4518] 28% | Training loss: 0.6874672211061312
Epoch: 11 | Iteration number: [1280/4518] 28% | Training loss: 0.6874713435769081
Epoch: 11 | Iteration number: [1290/4518] 28% | Training loss: 0.6874636496684348
Epoch: 11 | Iteration number: [1300/4518] 28% | Training loss: 0.6874652821742572
Epoch: 11 | Iteration number: [1310/4518] 28% | Training loss: 0.6874618841036585
Epoch: 11 | Iteration number: [1320/4518] 29% | Training loss: 0.6874613652175123
Epoch: 11 | Iteration number: [1330/4518] 29% | Training loss: 0.6874562809341832
Epoch: 11 | Iteration number: [1340/4518] 29% | Training loss: 0.6874528534376799
Epoch: 11 | Iteration number: [1350/4518] 29% | Training loss: 0.6874560023678674
Epoch: 11 | Iteration number: [1360/4518] 30% | Training loss: 0.687455780234407
Epoch: 11 | Iteration number: [1370/4518] 30% | Training loss: 0.6874507122231226
Epoch: 11 | Iteration number: [1380/4518] 30% | Training loss: 0.6874511729547943
Epoch: 11 | Iteration number: [1390/4518] 30% | Training loss: 0.6874379591118518
Epoch: 11 | Iteration number: [1400/4518] 30% | Training loss: 0.6874291131751878
Epoch: 11 | Iteration number: [1410/4518] 31% | Training loss: 0.6874240827053151
Epoch: 11 | Iteration number: [1420/4518] 31% | Training loss: 0.687418901668468
Epoch: 11 | Iteration number: [1430/4518] 31% | Training loss: 0.6874277357038084
Epoch: 11 | Iteration number: [1440/4518] 31% | Training loss: 0.6874277967545721
Epoch: 11 | Iteration number: [1450/4518] 32% | Training loss: 0.6874282173041639
Epoch: 11 | Iteration number: [1460/4518] 32% | Training loss: 0.6874250245012649
Epoch: 11 | Iteration number: [1470/4518] 32% | Training loss: 0.6874233821622369
Epoch: 11 | Iteration number: [1480/4518] 32% | Training loss: 0.6874202812040174
Epoch: 11 | Iteration number: [1490/4518] 32% | Training loss: 0.6874172208693203
Epoch: 11 | Iteration number: [1500/4518] 33% | Training loss: 0.687425888856252
Epoch: 11 | Iteration number: [1510/4518] 33% | Training loss: 0.6874244629152563
Epoch: 11 | Iteration number: [1520/4518] 33% | Training loss: 0.6874092257336566
Epoch: 11 | Iteration number: [1530/4518] 33% | Training loss: 0.6874053830025243
Epoch: 11 | Iteration number: [1540/4518] 34% | Training loss: 0.6873936334987739
Epoch: 11 | Iteration number: [1550/4518] 34% | Training loss: 0.6873894685314548
Epoch: 11 | Iteration number: [1560/4518] 34% | Training loss: 0.6873882396098895
Epoch: 11 | Iteration number: [1570/4518] 34% | Training loss: 0.6873865725128514
Epoch: 11 | Iteration number: [1580/4518] 34% | Training loss: 0.6873856246471405
Epoch: 11 | Iteration number: [1590/4518] 35% | Training loss: 0.6873830297458097
Epoch: 11 | Iteration number: [1600/4518] 35% | Training loss: 0.6873760613799095
Epoch: 11 | Iteration number: [1610/4518] 35% | Training loss: 0.6873747408390045
Epoch: 11 | Iteration number: [1620/4518] 35% | Training loss: 0.6873694200942546
Epoch: 11 | Iteration number: [1630/4518] 36% | Training loss: 0.6873671793864549
Epoch: 11 | Iteration number: [1640/4518] 36% | Training loss: 0.6873729495013633
Epoch: 11 | Iteration number: [1650/4518] 36% | Training loss: 0.6873766847090288
Epoch: 11 | Iteration number: [1660/4518] 36% | Training loss: 0.6873757247465203
Epoch: 11 | Iteration number: [1670/4518] 36% | Training loss: 0.6873763085839277
Epoch: 11 | Iteration number: [1680/4518] 37% | Training loss: 0.6873675673490479
Epoch: 11 | Iteration number: [1690/4518] 37% | Training loss: 0.6873550970526137
Epoch: 11 | Iteration number: [1700/4518] 37% | Training loss: 0.6873584504688487
Epoch: 11 | Iteration number: [1710/4518] 37% | Training loss: 0.687353155348036
Epoch: 11 | Iteration number: [1720/4518] 38% | Training loss: 0.6873481831231782
Epoch: 11 | Iteration number: [1730/4518] 38% | Training loss: 0.6873438311105519
Epoch: 11 | Iteration number: [1740/4518] 38% | Training loss: 0.6873447132521662
Epoch: 11 | Iteration number: [1750/4518] 38% | Training loss: 0.6873469441618238
Epoch: 11 | Iteration number: [1760/4518] 38% | Training loss: 0.6873479909178886
Epoch: 11 | Iteration number: [1770/4518] 39% | Training loss: 0.687346097338671
Epoch: 11 | Iteration number: [1780/4518] 39% | Training loss: 0.6873441598053729
Epoch: 11 | Iteration number: [1790/4518] 39% | Training loss: 0.6873472390894118
Epoch: 11 | Iteration number: [1800/4518] 39% | Training loss: 0.687344473765956
Epoch: 11 | Iteration number: [1810/4518] 40% | Training loss: 0.6873445100876507
Epoch: 11 | Iteration number: [1820/4518] 40% | Training loss: 0.6873443283222533
Epoch: 11 | Iteration number: [1830/4518] 40% | Training loss: 0.6873458676325167
Epoch: 11 | Iteration number: [1840/4518] 40% | Training loss: 0.6873432127677876
Epoch: 11 | Iteration number: [1850/4518] 40% | Training loss: 0.6873382212020256
Epoch: 11 | Iteration number: [1860/4518] 41% | Training loss: 0.6873352990996453
Epoch: 11 | Iteration number: [1870/4518] 41% | Training loss: 0.6873316516850722
Epoch: 11 | Iteration number: [1880/4518] 41% | Training loss: 0.6873204281355473
Epoch: 11 | Iteration number: [1890/4518] 41% | Training loss: 0.6873199276192479
Epoch: 11 | Iteration number: [1900/4518] 42% | Training loss: 0.6873175013379047
Epoch: 11 | Iteration number: [1910/4518] 42% | Training loss: 0.6873218465225859
Epoch: 11 | Iteration number: [1920/4518] 42% | Training loss: 0.6873201260343194
Epoch: 11 | Iteration number: [1930/4518] 42% | Training loss: 0.687316993357604
Epoch: 11 | Iteration number: [1940/4518] 42% | Training loss: 0.6873184590302792
Epoch: 11 | Iteration number: [1950/4518] 43% | Training loss: 0.6873168775668511
Epoch: 11 | Iteration number: [1960/4518] 43% | Training loss: 0.6873108925259843
Epoch: 11 | Iteration number: [1970/4518] 43% | Training loss: 0.6873049970205666
Epoch: 11 | Iteration number: [1980/4518] 43% | Training loss: 0.6873053728631049
Epoch: 11 | Iteration number: [1990/4518] 44% | Training loss: 0.687303487978988
Epoch: 11 | Iteration number: [2000/4518] 44% | Training loss: 0.6872988091409207
Epoch: 11 | Iteration number: [2010/4518] 44% | Training loss: 0.6873065210693511
Epoch: 11 | Iteration number: [2020/4518] 44% | Training loss: 0.6873031180979001
Epoch: 11 | Iteration number: [2030/4518] 44% | Training loss: 0.6873015660370512
Epoch: 11 | Iteration number: [2040/4518] 45% | Training loss: 0.6873030270723736
Epoch: 11 | Iteration number: [2050/4518] 45% | Training loss: 0.6873057359020884
Epoch: 11 | Iteration number: [2060/4518] 45% | Training loss: 0.6873064300678309
Epoch: 11 | Iteration number: [2070/4518] 45% | Training loss: 0.6873094482410357
Epoch: 11 | Iteration number: [2080/4518] 46% | Training loss: 0.6873093821681463
Epoch: 11 | Iteration number: [2090/4518] 46% | Training loss: 0.6873063320463354
Epoch: 11 | Iteration number: [2100/4518] 46% | Training loss: 0.6873055100440979
Epoch: 11 | Iteration number: [2110/4518] 46% | Training loss: 0.687304567132516
Epoch: 11 | Iteration number: [2120/4518] 46% | Training loss: 0.6872964661638692
Epoch: 11 | Iteration number: [2130/4518] 47% | Training loss: 0.6872943803458147
Epoch: 11 | Iteration number: [2140/4518] 47% | Training loss: 0.6872891193238374
Epoch: 11 | Iteration number: [2150/4518] 47% | Training loss: 0.6872826766690543
Epoch: 11 | Iteration number: [2160/4518] 47% | Training loss: 0.687282822198338
Epoch: 11 | Iteration number: [2170/4518] 48% | Training loss: 0.6872793781592549
Epoch: 11 | Iteration number: [2180/4518] 48% | Training loss: 0.6872739046265226
Epoch: 11 | Iteration number: [2190/4518] 48% | Training loss: 0.6872724946503226
Epoch: 11 | Iteration number: [2200/4518] 48% | Training loss: 0.6872665096413005
Epoch: 11 | Iteration number: [2210/4518] 48% | Training loss: 0.6872602321982924
Epoch: 11 | Iteration number: [2220/4518] 49% | Training loss: 0.6872626430547989
Epoch: 11 | Iteration number: [2230/4518] 49% | Training loss: 0.6872594454363322
Epoch: 11 | Iteration number: [2240/4518] 49% | Training loss: 0.6872529307380318
Epoch: 11 | Iteration number: [2250/4518] 49% | Training loss: 0.6872549501789941
Epoch: 11 | Iteration number: [2260/4518] 50% | Training loss: 0.6872497390856785
Epoch: 11 | Iteration number: [2270/4518] 50% | Training loss: 0.6872470498347597
Epoch: 11 | Iteration number: [2280/4518] 50% | Training loss: 0.6872516172235472
Epoch: 11 | Iteration number: [2290/4518] 50% | Training loss: 0.6872537127228283
Epoch: 11 | Iteration number: [2300/4518] 50% | Training loss: 0.6872484966205514
Epoch: 11 | Iteration number: [2310/4518] 51% | Training loss: 0.6872497187548385
Epoch: 11 | Iteration number: [2320/4518] 51% | Training loss: 0.6872451696416427
Epoch: 11 | Iteration number: [2330/4518] 51% | Training loss: 0.6872444512762226
Epoch: 11 | Iteration number: [2340/4518] 51% | Training loss: 0.6872468127654149
Epoch: 11 | Iteration number: [2350/4518] 52% | Training loss: 0.6872457082728122
Epoch: 11 | Iteration number: [2360/4518] 52% | Training loss: 0.6872468446270894
Epoch: 11 | Iteration number: [2370/4518] 52% | Training loss: 0.687247297934842
Epoch: 11 | Iteration number: [2380/4518] 52% | Training loss: 0.6872426232119568
Epoch: 11 | Iteration number: [2390/4518] 52% | Training loss: 0.6872421557683825
Epoch: 11 | Iteration number: [2400/4518] 53% | Training loss: 0.6872439835220575
Epoch: 11 | Iteration number: [2410/4518] 53% | Training loss: 0.6872410806877485
Epoch: 11 | Iteration number: [2420/4518] 53% | Training loss: 0.6872406911012555
Epoch: 11 | Iteration number: [2430/4518] 53% | Training loss: 0.6872398088743658
Epoch: 11 | Iteration number: [2440/4518] 54% | Training loss: 0.6872400393740076
Epoch: 11 | Iteration number: [2450/4518] 54% | Training loss: 0.6872406042108731
Epoch: 11 | Iteration number: [2460/4518] 54% | Training loss: 0.6872401110525054
Epoch: 11 | Iteration number: [2470/4518] 54% | Training loss: 0.6872412270862563
Epoch: 11 | Iteration number: [2480/4518] 54% | Training loss: 0.6872397202157206
Epoch: 11 | Iteration number: [2490/4518] 55% | Training loss: 0.6872336380213618
Epoch: 11 | Iteration number: [2500/4518] 55% | Training loss: 0.6872334656715393
Epoch: 11 | Iteration number: [2510/4518] 55% | Training loss: 0.6872315836142734
Epoch: 11 | Iteration number: [2520/4518] 55% | Training loss: 0.6872303932905197
Epoch: 11 | Iteration number: [2530/4518] 55% | Training loss: 0.6872314259939986
Epoch: 11 | Iteration number: [2540/4518] 56% | Training loss: 0.6872229422640612
Epoch: 11 | Iteration number: [2550/4518] 56% | Training loss: 0.6872241830358318
Epoch: 11 | Iteration number: [2560/4518] 56% | Training loss: 0.6872253502020612
Epoch: 11 | Iteration number: [2570/4518] 56% | Training loss: 0.6872218921026831
Epoch: 11 | Iteration number: [2580/4518] 57% | Training loss: 0.6872186065875283
Epoch: 11 | Iteration number: [2590/4518] 57% | Training loss: 0.6872139321100758
Epoch: 11 | Iteration number: [2600/4518] 57% | Training loss: 0.6872142517795929
Epoch: 11 | Iteration number: [2610/4518] 57% | Training loss: 0.6872174583860741
Epoch: 11 | Iteration number: [2620/4518] 57% | Training loss: 0.6872125899746218
Epoch: 11 | Iteration number: [2630/4518] 58% | Training loss: 0.6872106969809804
Epoch: 11 | Iteration number: [2640/4518] 58% | Training loss: 0.6872050393485661
Epoch: 11 | Iteration number: [2650/4518] 58% | Training loss: 0.6872049588527319
Epoch: 11 | Iteration number: [2660/4518] 58% | Training loss: 0.6872037039215403
Epoch: 11 | Iteration number: [2670/4518] 59% | Training loss: 0.687199859516451
Epoch: 11 | Iteration number: [2680/4518] 59% | Training loss: 0.6872041927344763
Epoch: 11 | Iteration number: [2690/4518] 59% | Training loss: 0.6872076141346786
Epoch: 11 | Iteration number: [2700/4518] 59% | Training loss: 0.687206080004021
Epoch: 11 | Iteration number: [2710/4518] 59% | Training loss: 0.68720136456384
Epoch: 11 | Iteration number: [2720/4518] 60% | Training loss: 0.6872027174076614
Epoch: 11 | Iteration number: [2730/4518] 60% | Training loss: 0.6872035128074688
Epoch: 11 | Iteration number: [2740/4518] 60% | Training loss: 0.6872001898332234
Epoch: 11 | Iteration number: [2750/4518] 60% | Training loss: 0.6871981560316953
Epoch: 11 | Iteration number: [2760/4518] 61% | Training loss: 0.6871899307206057
Epoch: 11 | Iteration number: [2770/4518] 61% | Training loss: 0.6871887555406412
Epoch: 11 | Iteration number: [2780/4518] 61% | Training loss: 0.6871872203384372
Epoch: 11 | Iteration number: [2790/4518] 61% | Training loss: 0.687187086510402
Epoch: 11 | Iteration number: [2800/4518] 61% | Training loss: 0.6871852008572646
Epoch: 11 | Iteration number: [2810/4518] 62% | Training loss: 0.6871830423531583
Epoch: 11 | Iteration number: [2820/4518] 62% | Training loss: 0.6871791662053859
Epoch: 11 | Iteration number: [2830/4518] 62% | Training loss: 0.687178735029571
Epoch: 11 | Iteration number: [2840/4518] 62% | Training loss: 0.6871800167459837
Epoch: 11 | Iteration number: [2850/4518] 63% | Training loss: 0.6871808505267427
Epoch: 11 | Iteration number: [2860/4518] 63% | Training loss: 0.6871806534853848
Epoch: 11 | Iteration number: [2870/4518] 63% | Training loss: 0.6871819919825431
Epoch: 11 | Iteration number: [2880/4518] 63% | Training loss: 0.6871820851953493
Epoch: 11 | Iteration number: [2890/4518] 63% | Training loss: 0.6871833346294284
Epoch: 11 | Iteration number: [2900/4518] 64% | Training loss: 0.6871830744373387
Epoch: 11 | Iteration number: [2910/4518] 64% | Training loss: 0.6871769862691152
Epoch: 11 | Iteration number: [2920/4518] 64% | Training loss: 0.687175546749814
Epoch: 11 | Iteration number: [2930/4518] 64% | Training loss: 0.6871755266352318
Epoch: 11 | Iteration number: [2940/4518] 65% | Training loss: 0.6871764911275332
Epoch: 11 | Iteration number: [2950/4518] 65% | Training loss: 0.6871749680729236
Epoch: 11 | Iteration number: [2960/4518] 65% | Training loss: 0.6871708809322602
Epoch: 11 | Iteration number: [2970/4518] 65% | Training loss: 0.6871663455007855
Epoch: 11 | Iteration number: [2980/4518] 65% | Training loss: 0.6871724864380472
Epoch: 11 | Iteration number: [2990/4518] 66% | Training loss: 0.6871682291246178
Epoch: 11 | Iteration number: [3000/4518] 66% | Training loss: 0.6871694510976474
Epoch: 11 | Iteration number: [3010/4518] 66% | Training loss: 0.6871683283501685
Epoch: 11 | Iteration number: [3020/4518] 66% | Training loss: 0.6871645311448747
Epoch: 11 | Iteration number: [3030/4518] 67% | Training loss: 0.6871663364246734
Epoch: 11 | Iteration number: [3040/4518] 67% | Training loss: 0.6871653871708795
Epoch: 11 | Iteration number: [3050/4518] 67% | Training loss: 0.6871636865959793
Epoch: 11 | Iteration number: [3060/4518] 67% | Training loss: 0.6871598130347683
Epoch: 11 | Iteration number: [3070/4518] 67% | Training loss: 0.6871584134497938
Epoch: 11 | Iteration number: [3080/4518] 68% | Training loss: 0.6871584702815329
Epoch: 11 | Iteration number: [3090/4518] 68% | Training loss: 0.687155568310358
Epoch: 11 | Iteration number: [3100/4518] 68% | Training loss: 0.6871573135160631
Epoch: 11 | Iteration number: [3110/4518] 68% | Training loss: 0.6871592671924849
Epoch: 11 | Iteration number: [3120/4518] 69% | Training loss: 0.687157530299364
Epoch: 11 | Iteration number: [3130/4518] 69% | Training loss: 0.6871563422032438
Epoch: 11 | Iteration number: [3140/4518] 69% | Training loss: 0.6871552508348112
Epoch: 11 | Iteration number: [3150/4518] 69% | Training loss: 0.6871533709859091
Epoch: 11 | Iteration number: [3160/4518] 69% | Training loss: 0.687155123281328
Epoch: 11 | Iteration number: [3170/4518] 70% | Training loss: 0.687157497627878
Epoch: 11 | Iteration number: [3180/4518] 70% | Training loss: 0.687163028570841
Epoch: 11 | Iteration number: [3190/4518] 70% | Training loss: 0.6871628281651619
Epoch: 11 | Iteration number: [3200/4518] 70% | Training loss: 0.6871537578105926
Epoch: 11 | Iteration number: [3210/4518] 71% | Training loss: 0.6871498425987279
Epoch: 11 | Iteration number: [3220/4518] 71% | Training loss: 0.6871484715560948
Epoch: 11 | Iteration number: [3230/4518] 71% | Training loss: 0.6871435237558264
Epoch: 11 | Iteration number: [3240/4518] 71% | Training loss: 0.6871377992409247
Epoch: 11 | Iteration number: [3250/4518] 71% | Training loss: 0.6871395053496727
Epoch: 11 | Iteration number: [3260/4518] 72% | Training loss: 0.6871408543520909
Epoch: 11 | Iteration number: [3270/4518] 72% | Training loss: 0.6871382000614015
Epoch: 11 | Iteration number: [3280/4518] 72% | Training loss: 0.6871384777310418
Epoch: 11 | Iteration number: [3290/4518] 72% | Training loss: 0.6871386131979412
Epoch: 11 | Iteration number: [3300/4518] 73% | Training loss: 0.687140858913913
Epoch: 11 | Iteration number: [3310/4518] 73% | Training loss: 0.6871413453648098
Epoch: 11 | Iteration number: [3320/4518] 73% | Training loss: 0.6871422904442592
Epoch: 11 | Iteration number: [3330/4518] 73% | Training loss: 0.6871376485079974
Epoch: 11 | Iteration number: [3340/4518] 73% | Training loss: 0.6871350711691165
Epoch: 11 | Iteration number: [3350/4518] 74% | Training loss: 0.6871340683325013
Epoch: 11 | Iteration number: [3360/4518] 74% | Training loss: 0.6871338458997863
Epoch: 11 | Iteration number: [3370/4518] 74% | Training loss: 0.6871328857249251
Epoch: 11 | Iteration number: [3380/4518] 74% | Training loss: 0.6871306710518323
Epoch: 11 | Iteration number: [3390/4518] 75% | Training loss: 0.6871313184587653
Epoch: 11 | Iteration number: [3400/4518] 75% | Training loss: 0.6871339949264246
Epoch: 11 | Iteration number: [3410/4518] 75% | Training loss: 0.6871370305238931
Epoch: 11 | Iteration number: [3420/4518] 75% | Training loss: 0.6871380395708029
Epoch: 11 | Iteration number: [3430/4518] 75% | Training loss: 0.6871382509654187
Epoch: 11 | Iteration number: [3440/4518] 76% | Training loss: 0.6871365945699603
Epoch: 11 | Iteration number: [3450/4518] 76% | Training loss: 0.6871355030502099
Epoch: 11 | Iteration number: [3460/4518] 76% | Training loss: 0.6871341559756009
Epoch: 11 | Iteration number: [3470/4518] 76% | Training loss: 0.6871360465669495
Epoch: 11 | Iteration number: [3480/4518] 77% | Training loss: 0.6871347074364794
Epoch: 11 | Iteration number: [3490/4518] 77% | Training loss: 0.6871330190695459
Epoch: 11 | Iteration number: [3500/4518] 77% | Training loss: 0.6871347283295223
Epoch: 11 | Iteration number: [3510/4518] 77% | Training loss: 0.6871343373063623
Epoch: 11 | Iteration number: [3520/4518] 77% | Training loss: 0.687133389829912
Epoch: 11 | Iteration number: [3530/4518] 78% | Training loss: 0.6871308528330103
Epoch: 11 | Iteration number: [3540/4518] 78% | Training loss: 0.6871310695416509
Epoch: 11 | Iteration number: [3550/4518] 78% | Training loss: 0.6871313585361964
Epoch: 11 | Iteration number: [3560/4518] 78% | Training loss: 0.6871319002482329
Epoch: 11 | Iteration number: [3570/4518] 79% | Training loss: 0.6871321141719818
Epoch: 11 | Iteration number: [3580/4518] 79% | Training loss: 0.6871358728608605
Epoch: 11 | Iteration number: [3590/4518] 79% | Training loss: 0.6871350524319247
Epoch: 11 | Iteration number: [3600/4518] 79% | Training loss: 0.6871367678874069
Epoch: 11 | Iteration number: [3610/4518] 79% | Training loss: 0.687136182378864
Epoch: 11 | Iteration number: [3620/4518] 80% | Training loss: 0.6871356030689418
Epoch: 11 | Iteration number: [3630/4518] 80% | Training loss: 0.6871359021703074
Epoch: 11 | Iteration number: [3640/4518] 80% | Training loss: 0.6871354087368473
Epoch: 11 | Iteration number: [3650/4518] 80% | Training loss: 0.6871328213280194
Epoch: 11 | Iteration number: [3660/4518] 81% | Training loss: 0.6871336155576133
Epoch: 11 | Iteration number: [3670/4518] 81% | Training loss: 0.6871300888971023
Epoch: 11 | Iteration number: [3680/4518] 81% | Training loss: 0.6871341255210016
Epoch: 11 | Iteration number: [3690/4518] 81% | Training loss: 0.6871358532408065
Epoch: 11 | Iteration number: [3700/4518] 81% | Training loss: 0.6871338241486936
Epoch: 11 | Iteration number: [3710/4518] 82% | Training loss: 0.6871313831876873
Epoch: 11 | Iteration number: [3720/4518] 82% | Training loss: 0.6871306046042391
Epoch: 11 | Iteration number: [3730/4518] 82% | Training loss: 0.6871320231190955
Epoch: 11 | Iteration number: [3740/4518] 82% | Training loss: 0.6871320856764992
Epoch: 11 | Iteration number: [3750/4518] 83% | Training loss: 0.6871271780649821
Epoch: 11 | Iteration number: [3760/4518] 83% | Training loss: 0.6871233557608534
Epoch: 11 | Iteration number: [3770/4518] 83% | Training loss: 0.6871242812520946
Epoch: 11 | Iteration number: [3780/4518] 83% | Training loss: 0.687124443306494
Epoch: 11 | Iteration number: [3790/4518] 83% | Training loss: 0.6871263350062761
Epoch: 11 | Iteration number: [3800/4518] 84% | Training loss: 0.6871243991193019
Epoch: 11 | Iteration number: [3810/4518] 84% | Training loss: 0.6871253514540164
Epoch: 11 | Iteration number: [3820/4518] 84% | Training loss: 0.6871263503404188
Epoch: 11 | Iteration number: [3830/4518] 84% | Training loss: 0.6871277555161917
Epoch: 11 | Iteration number: [3840/4518] 84% | Training loss: 0.6871280843081574
Epoch: 11 | Iteration number: [3850/4518] 85% | Training loss: 0.6871271468447401
Epoch: 11 | Iteration number: [3860/4518] 85% | Training loss: 0.6871304478670032
Epoch: 11 | Iteration number: [3870/4518] 85% | Training loss: 0.6871305856901854
Epoch: 11 | Iteration number: [3880/4518] 85% | Training loss: 0.6871312964669208
Epoch: 11 | Iteration number: [3890/4518] 86% | Training loss: 0.687129707967714
Epoch: 11 | Iteration number: [3900/4518] 86% | Training loss: 0.6871260843215845
Epoch: 11 | Iteration number: [3910/4518] 86% | Training loss: 0.6871232890716904
Epoch: 11 | Iteration number: [3920/4518] 86% | Training loss: 0.6871212769071666
Epoch: 11 | Iteration number: [3930/4518] 86% | Training loss: 0.6871221371886082
Epoch: 11 | Iteration number: [3940/4518] 87% | Training loss: 0.6871221766859141
Epoch: 11 | Iteration number: [3950/4518] 87% | Training loss: 0.6871211412888539
Epoch: 11 | Iteration number: [3960/4518] 87% | Training loss: 0.6871204354094737
Epoch: 11 | Iteration number: [3970/4518] 87% | Training loss: 0.687116432219969
Epoch: 11 | Iteration number: [3980/4518] 88% | Training loss: 0.6871172864233429
Epoch: 11 | Iteration number: [3990/4518] 88% | Training loss: 0.6871192109465301
Epoch: 11 | Iteration number: [4000/4518] 88% | Training loss: 0.6871188547760249
Epoch: 11 | Iteration number: [4010/4518] 88% | Training loss: 0.6871205251264453
Epoch: 11 | Iteration number: [4020/4518] 88% | Training loss: 0.6871216691993363
Epoch: 11 | Iteration number: [4030/4518] 89% | Training loss: 0.687123499171018
Epoch: 11 | Iteration number: [4040/4518] 89% | Training loss: 0.6871203233699987
Epoch: 11 | Iteration number: [4050/4518] 89% | Training loss: 0.6871200863814648
Epoch: 11 | Iteration number: [4060/4518] 89% | Training loss: 0.6871213508210159
Epoch: 11 | Iteration number: [4070/4518] 90% | Training loss: 0.6871199868088566
Epoch: 11 | Iteration number: [4080/4518] 90% | Training loss: 0.687121897380726
Epoch: 11 | Iteration number: [4090/4518] 90% | Training loss: 0.68712444908753
Epoch: 11 | Iteration number: [4100/4518] 90% | Training loss: 0.6871229742649125
Epoch: 11 | Iteration number: [4110/4518] 90% | Training loss: 0.6871201127550027
Epoch: 11 | Iteration number: [4120/4518] 91% | Training loss: 0.6871226180525659
Epoch: 11 | Iteration number: [4130/4518] 91% | Training loss: 0.6871222398182959
Epoch: 11 | Iteration number: [4140/4518] 91% | Training loss: 0.6871236577989974
Epoch: 11 | Iteration number: [4150/4518] 91% | Training loss: 0.6871226522434188
Epoch: 11 | Iteration number: [4160/4518] 92% | Training loss: 0.6871247724128458
Epoch: 11 | Iteration number: [4170/4518] 92% | Training loss: 0.6871264063197075
Epoch: 11 | Iteration number: [4180/4518] 92% | Training loss: 0.6871271819018862
Epoch: 11 | Iteration number: [4190/4518] 92% | Training loss: 0.6871245895905824
Epoch: 11 | Iteration number: [4200/4518] 92% | Training loss: 0.6871238387908254
Epoch: 11 | Iteration number: [4210/4518] 93% | Training loss: 0.6871228660512141
Epoch: 11 | Iteration number: [4220/4518] 93% | Training loss: 0.6871214114376719
Epoch: 11 | Iteration number: [4230/4518] 93% | Training loss: 0.6871200605205329
Epoch: 11 | Iteration number: [4240/4518] 93% | Training loss: 0.6871191887360699
Epoch: 11 | Iteration number: [4250/4518] 94% | Training loss: 0.6871201766098247
Epoch: 11 | Iteration number: [4260/4518] 94% | Training loss: 0.6871216841007063
Epoch: 11 | Iteration number: [4270/4518] 94% | Training loss: 0.6871244297513359
Epoch: 11 | Iteration number: [4280/4518] 94% | Training loss: 0.6871250410364053
Epoch: 11 | Iteration number: [4290/4518] 94% | Training loss: 0.6871219914415222
Epoch: 11 | Iteration number: [4300/4518] 95% | Training loss: 0.6871216511171918
Epoch: 11 | Iteration number: [4310/4518] 95% | Training loss: 0.6871219596564079
Epoch: 11 | Iteration number: [4320/4518] 95% | Training loss: 0.6871209387977918
Epoch: 11 | Iteration number: [4330/4518] 95% | Training loss: 0.6871231269616178
Epoch: 11 | Iteration number: [4340/4518] 96% | Training loss: 0.6871223346566275
Epoch: 11 | Iteration number: [4350/4518] 96% | Training loss: 0.6871237803464648
Epoch: 11 | Iteration number: [4360/4518] 96% | Training loss: 0.6871243812485572
Epoch: 11 | Iteration number: [4370/4518] 96% | Training loss: 0.6871261625049861
Epoch: 11 | Iteration number: [4380/4518] 96% | Training loss: 0.6871242819991831
Epoch: 11 | Iteration number: [4390/4518] 97% | Training loss: 0.6871262212684865
Epoch: 11 | Iteration number: [4400/4518] 97% | Training loss: 0.6871238354932178
Epoch: 11 | Iteration number: [4410/4518] 97% | Training loss: 0.6871228671803766
Epoch: 11 | Iteration number: [4420/4518] 97% | Training loss: 0.687126009779818
Epoch: 11 | Iteration number: [4430/4518] 98% | Training loss: 0.6871256652992412
Epoch: 11 | Iteration number: [4440/4518] 98% | Training loss: 0.6871264466025808
Epoch: 11 | Iteration number: [4450/4518] 98% | Training loss: 0.6871272798334614
Epoch: 11 | Iteration number: [4460/4518] 98% | Training loss: 0.6871241380147335
Epoch: 11 | Iteration number: [4470/4518] 98% | Training loss: 0.6871226574483867
Epoch: 11 | Iteration number: [4480/4518] 99% | Training loss: 0.687121655313032
Epoch: 11 | Iteration number: [4490/4518] 99% | Training loss: 0.6871234025084362
Epoch: 11 | Iteration number: [4500/4518] 99% | Training loss: 0.6871246917645136
Epoch: 11 | Iteration number: [4510/4518] 99% | Training loss: 0.6871258992181385

 End of epoch: 11 | Train Loss: 0.6869737600504481 | Training Time: 642 

 End of epoch: 11 | Eval Loss: 0.6902217183794294 | Evaluating Time: 17 
Epoch: 12 | Iteration number: [10/4518] 0% | Training loss: 0.7551537275314331
Epoch: 12 | Iteration number: [20/4518] 0% | Training loss: 0.721658656001091
Epoch: 12 | Iteration number: [30/4518] 0% | Training loss: 0.7100823163986206
Epoch: 12 | Iteration number: [40/4518] 0% | Training loss: 0.7044427141547203
Epoch: 12 | Iteration number: [50/4518] 1% | Training loss: 0.7007481360435486
Epoch: 12 | Iteration number: [60/4518] 1% | Training loss: 0.6982893864313762
Epoch: 12 | Iteration number: [70/4518] 1% | Training loss: 0.6968026901994433
Epoch: 12 | Iteration number: [80/4518] 1% | Training loss: 0.6956852294504643
Epoch: 12 | Iteration number: [90/4518] 1% | Training loss: 0.6946514023674859
Epoch: 12 | Iteration number: [100/4518] 2% | Training loss: 0.6940297812223435
Epoch: 12 | Iteration number: [110/4518] 2% | Training loss: 0.693360893834721
Epoch: 12 | Iteration number: [120/4518] 2% | Training loss: 0.692895270884037
Epoch: 12 | Iteration number: [130/4518] 2% | Training loss: 0.6923819835369404
Epoch: 12 | Iteration number: [140/4518] 3% | Training loss: 0.6919784733227321
Epoch: 12 | Iteration number: [150/4518] 3% | Training loss: 0.6916549066702525
Epoch: 12 | Iteration number: [160/4518] 3% | Training loss: 0.6912757907062769
Epoch: 12 | Iteration number: [170/4518] 3% | Training loss: 0.6910935794605928
Epoch: 12 | Iteration number: [180/4518] 3% | Training loss: 0.6908303413126203
Epoch: 12 | Iteration number: [190/4518] 4% | Training loss: 0.6906127214431763
Epoch: 12 | Iteration number: [200/4518] 4% | Training loss: 0.6903416812419891
Epoch: 12 | Iteration number: [210/4518] 4% | Training loss: 0.6901433473541623
Epoch: 12 | Iteration number: [220/4518] 4% | Training loss: 0.6900493537837808
Epoch: 12 | Iteration number: [230/4518] 5% | Training loss: 0.689869027811548
Epoch: 12 | Iteration number: [240/4518] 5% | Training loss: 0.6897639458378156
Epoch: 12 | Iteration number: [250/4518] 5% | Training loss: 0.689648996591568
Epoch: 12 | Iteration number: [260/4518] 5% | Training loss: 0.689557887499149
Epoch: 12 | Iteration number: [270/4518] 5% | Training loss: 0.6894669208261702
Epoch: 12 | Iteration number: [280/4518] 6% | Training loss: 0.6894112222961017
Epoch: 12 | Iteration number: [290/4518] 6% | Training loss: 0.6893651236747873
Epoch: 12 | Iteration number: [300/4518] 6% | Training loss: 0.6892495761315028
Epoch: 12 | Iteration number: [310/4518] 6% | Training loss: 0.689177821143981
Epoch: 12 | Iteration number: [320/4518] 7% | Training loss: 0.6891368217766285
Epoch: 12 | Iteration number: [330/4518] 7% | Training loss: 0.6891076217998158
Epoch: 12 | Iteration number: [340/4518] 7% | Training loss: 0.6890329906169106
Epoch: 12 | Iteration number: [350/4518] 7% | Training loss: 0.6889802057402474
Epoch: 12 | Iteration number: [360/4518] 7% | Training loss: 0.6889477016197311
Epoch: 12 | Iteration number: [370/4518] 8% | Training loss: 0.6888614263083483
Epoch: 12 | Iteration number: [380/4518] 8% | Training loss: 0.6887787199334094
Epoch: 12 | Iteration number: [390/4518] 8% | Training loss: 0.6887414701474018
Epoch: 12 | Iteration number: [400/4518] 8% | Training loss: 0.6887020717561245
Epoch: 12 | Iteration number: [410/4518] 9% | Training loss: 0.688643786238461
Epoch: 12 | Iteration number: [420/4518] 9% | Training loss: 0.6885987545762743
Epoch: 12 | Iteration number: [430/4518] 9% | Training loss: 0.6885603444520817
Epoch: 12 | Iteration number: [440/4518] 9% | Training loss: 0.6885344517501918
Epoch: 12 | Iteration number: [450/4518] 9% | Training loss: 0.688496395084593
Epoch: 12 | Iteration number: [460/4518] 10% | Training loss: 0.688455480337143
Epoch: 12 | Iteration number: [470/4518] 10% | Training loss: 0.6884342555035936
Epoch: 12 | Iteration number: [480/4518] 10% | Training loss: 0.6884211386243503
Epoch: 12 | Iteration number: [490/4518] 10% | Training loss: 0.688398743405634
Epoch: 12 | Iteration number: [500/4518] 11% | Training loss: 0.6883638179302216
Epoch: 12 | Iteration number: [510/4518] 11% | Training loss: 0.6883514225482941
Epoch: 12 | Iteration number: [520/4518] 11% | Training loss: 0.6883115189579817
Epoch: 12 | Iteration number: [530/4518] 11% | Training loss: 0.6883061025502547
Epoch: 12 | Iteration number: [540/4518] 11% | Training loss: 0.6882779948137424
Epoch: 12 | Iteration number: [550/4518] 12% | Training loss: 0.688251507065513
Epoch: 12 | Iteration number: [560/4518] 12% | Training loss: 0.6882533137287412
Epoch: 12 | Iteration number: [570/4518] 12% | Training loss: 0.688202265584678
Epoch: 12 | Iteration number: [580/4518] 12% | Training loss: 0.688198774025358
Epoch: 12 | Iteration number: [590/4518] 13% | Training loss: 0.6881690324363062
Epoch: 12 | Iteration number: [600/4518] 13% | Training loss: 0.6881534123420715
Epoch: 12 | Iteration number: [610/4518] 13% | Training loss: 0.6881344316435642
Epoch: 12 | Iteration number: [620/4518] 13% | Training loss: 0.6881401534042051
Epoch: 12 | Iteration number: [630/4518] 13% | Training loss: 0.6881382932738652
Epoch: 12 | Iteration number: [640/4518] 14% | Training loss: 0.6881085772998631
Epoch: 12 | Iteration number: [650/4518] 14% | Training loss: 0.6880970691717588
Epoch: 12 | Iteration number: [660/4518] 14% | Training loss: 0.6880791868224289
Epoch: 12 | Iteration number: [670/4518] 14% | Training loss: 0.6880387132737174
Epoch: 12 | Iteration number: [680/4518] 15% | Training loss: 0.6880375522024491
Epoch: 12 | Iteration number: [690/4518] 15% | Training loss: 0.6880155211773471
Epoch: 12 | Iteration number: [700/4518] 15% | Training loss: 0.6879994716814586
Epoch: 12 | Iteration number: [710/4518] 15% | Training loss: 0.6879931412952047
Epoch: 12 | Iteration number: [720/4518] 15% | Training loss: 0.6879691076775392
Epoch: 12 | Iteration number: [730/4518] 16% | Training loss: 0.6879522967011962
Epoch: 12 | Iteration number: [740/4518] 16% | Training loss: 0.687944147474057
Epoch: 12 | Iteration number: [750/4518] 16% | Training loss: 0.6879297814369202
Epoch: 12 | Iteration number: [760/4518] 16% | Training loss: 0.6879209941939304
Epoch: 12 | Iteration number: [770/4518] 17% | Training loss: 0.68790618668903
Epoch: 12 | Iteration number: [780/4518] 17% | Training loss: 0.6878884435464174
Epoch: 12 | Iteration number: [790/4518] 17% | Training loss: 0.6878597466251518
Epoch: 12 | Iteration number: [800/4518] 17% | Training loss: 0.687851264923811
Epoch: 12 | Iteration number: [810/4518] 17% | Training loss: 0.6878404556233206
Epoch: 12 | Iteration number: [820/4518] 18% | Training loss: 0.687837346588693
Epoch: 12 | Iteration number: [830/4518] 18% | Training loss: 0.6878214438995683
Epoch: 12 | Iteration number: [840/4518] 18% | Training loss: 0.6878239410973731
Epoch: 12 | Iteration number: [850/4518] 18% | Training loss: 0.6878005426070269
Epoch: 12 | Iteration number: [860/4518] 19% | Training loss: 0.6877804914186167
Epoch: 12 | Iteration number: [870/4518] 19% | Training loss: 0.6877737737250054
Epoch: 12 | Iteration number: [880/4518] 19% | Training loss: 0.6877693273127079
Epoch: 12 | Iteration number: [890/4518] 19% | Training loss: 0.6877655607261015
Epoch: 12 | Iteration number: [900/4518] 19% | Training loss: 0.6877464957369699
Epoch: 12 | Iteration number: [910/4518] 20% | Training loss: 0.6877472487779764
Epoch: 12 | Iteration number: [920/4518] 20% | Training loss: 0.6877373589121777
Epoch: 12 | Iteration number: [930/4518] 20% | Training loss: 0.6877422759609838
Epoch: 12 | Iteration number: [940/4518] 20% | Training loss: 0.6877418951785311
Epoch: 12 | Iteration number: [950/4518] 21% | Training loss: 0.6877338950257552
Epoch: 12 | Iteration number: [960/4518] 21% | Training loss: 0.6877264382317663
Epoch: 12 | Iteration number: [970/4518] 21% | Training loss: 0.6877323634845695
Epoch: 12 | Iteration number: [980/4518] 21% | Training loss: 0.6877365905411389
Epoch: 12 | Iteration number: [990/4518] 21% | Training loss: 0.6877298261180068
Epoch: 12 | Iteration number: [1000/4518] 22% | Training loss: 0.6877405221462249
Epoch: 12 | Iteration number: [1010/4518] 22% | Training loss: 0.6877360734018949
Epoch: 12 | Iteration number: [1020/4518] 22% | Training loss: 0.687720742354206
Epoch: 12 | Iteration number: [1030/4518] 22% | Training loss: 0.6877010725076916
Epoch: 12 | Iteration number: [1040/4518] 23% | Training loss: 0.6876878044353082
Epoch: 12 | Iteration number: [1050/4518] 23% | Training loss: 0.6876899179390499
Epoch: 12 | Iteration number: [1060/4518] 23% | Training loss: 0.6876853568936294
Epoch: 12 | Iteration number: [1070/4518] 23% | Training loss: 0.6876864424932783
Epoch: 12 | Iteration number: [1080/4518] 23% | Training loss: 0.6876774508644034
Epoch: 12 | Iteration number: [1090/4518] 24% | Training loss: 0.6876754974553344
Epoch: 12 | Iteration number: [1100/4518] 24% | Training loss: 0.6876688945293427
Epoch: 12 | Iteration number: [1110/4518] 24% | Training loss: 0.6876591320510383
Epoch: 12 | Iteration number: [1120/4518] 24% | Training loss: 0.687652877452118
Epoch: 12 | Iteration number: [1130/4518] 25% | Training loss: 0.6876633131926039
Epoch: 12 | Iteration number: [1140/4518] 25% | Training loss: 0.6876493526132483
Epoch: 12 | Iteration number: [1150/4518] 25% | Training loss: 0.6876431090417116
Epoch: 12 | Iteration number: [1160/4518] 25% | Training loss: 0.6876497097056488
Epoch: 12 | Iteration number: [1170/4518] 25% | Training loss: 0.6876545355870174
Epoch: 12 | Iteration number: [1180/4518] 26% | Training loss: 0.6876500626236706
Epoch: 12 | Iteration number: [1190/4518] 26% | Training loss: 0.6876405148946938
Epoch: 12 | Iteration number: [1200/4518] 26% | Training loss: 0.6876340458790461
Epoch: 12 | Iteration number: [1210/4518] 26% | Training loss: 0.6876327127464547
Epoch: 12 | Iteration number: [1220/4518] 27% | Training loss: 0.6876182808250677
Epoch: 12 | Iteration number: [1230/4518] 27% | Training loss: 0.6876096470084617
Epoch: 12 | Iteration number: [1240/4518] 27% | Training loss: 0.687601223636058
Epoch: 12 | Iteration number: [1250/4518] 27% | Training loss: 0.687598063659668
Epoch: 12 | Iteration number: [1260/4518] 27% | Training loss: 0.6876053579742947
Epoch: 12 | Iteration number: [1270/4518] 28% | Training loss: 0.6876049713356288
Epoch: 12 | Iteration number: [1280/4518] 28% | Training loss: 0.687603227654472
Epoch: 12 | Iteration number: [1290/4518] 28% | Training loss: 0.6875970067903977
Epoch: 12 | Iteration number: [1300/4518] 28% | Training loss: 0.6875820797223311
Epoch: 12 | Iteration number: [1310/4518] 28% | Training loss: 0.6875745858399923
Epoch: 12 | Iteration number: [1320/4518] 29% | Training loss: 0.6875593163298838
Epoch: 12 | Iteration number: [1330/4518] 29% | Training loss: 0.6875528096704555
Epoch: 12 | Iteration number: [1340/4518] 29% | Training loss: 0.6875404130167035
Epoch: 12 | Iteration number: [1350/4518] 29% | Training loss: 0.6875429470892306
Epoch: 12 | Iteration number: [1360/4518] 30% | Training loss: 0.6875328006551547
Epoch: 12 | Iteration number: [1370/4518] 30% | Training loss: 0.6875313803227279
Epoch: 12 | Iteration number: [1380/4518] 30% | Training loss: 0.6875291780717131
Epoch: 12 | Iteration number: [1390/4518] 30% | Training loss: 0.6875275111026901
Epoch: 12 | Iteration number: [1400/4518] 30% | Training loss: 0.6875093310219901
Epoch: 12 | Iteration number: [1410/4518] 31% | Training loss: 0.6874987523183755
Epoch: 12 | Iteration number: [1420/4518] 31% | Training loss: 0.6875009960691694
Epoch: 12 | Iteration number: [1430/4518] 31% | Training loss: 0.6874930005807143
Epoch: 12 | Iteration number: [1440/4518] 31% | Training loss: 0.6874938310434421
Epoch: 12 | Iteration number: [1450/4518] 32% | Training loss: 0.6874890366504932
Epoch: 12 | Iteration number: [1460/4518] 32% | Training loss: 0.6874876271371972
Epoch: 12 | Iteration number: [1470/4518] 32% | Training loss: 0.6874868953309091
Epoch: 12 | Iteration number: [1480/4518] 32% | Training loss: 0.687477943703935
Epoch: 12 | Iteration number: [1490/4518] 32% | Training loss: 0.6874805648854915
Epoch: 12 | Iteration number: [1500/4518] 33% | Training loss: 0.6874781961043676
Epoch: 12 | Iteration number: [1510/4518] 33% | Training loss: 0.687469555131647
Epoch: 12 | Iteration number: [1520/4518] 33% | Training loss: 0.6874733598216584
Epoch: 12 | Iteration number: [1530/4518] 33% | Training loss: 0.6874665937782113
Epoch: 12 | Iteration number: [1540/4518] 34% | Training loss: 0.6874605849965826
Epoch: 12 | Iteration number: [1550/4518] 34% | Training loss: 0.6874536672330672
Epoch: 12 | Iteration number: [1560/4518] 34% | Training loss: 0.6874505860301164
Epoch: 12 | Iteration number: [1570/4518] 34% | Training loss: 0.6874499950818955
Epoch: 12 | Iteration number: [1580/4518] 34% | Training loss: 0.6874439465848705
Epoch: 12 | Iteration number: [1590/4518] 35% | Training loss: 0.6874358932552098
Epoch: 12 | Iteration number: [1600/4518] 35% | Training loss: 0.687428341768682
Epoch: 12 | Iteration number: [1610/4518] 35% | Training loss: 0.6874263877454011
Epoch: 12 | Iteration number: [1620/4518] 35% | Training loss: 0.6874260462360617
Epoch: 12 | Iteration number: [1630/4518] 36% | Training loss: 0.6874129764141481
Epoch: 12 | Iteration number: [1640/4518] 36% | Training loss: 0.6874193899878641
Epoch: 12 | Iteration number: [1650/4518] 36% | Training loss: 0.6874132580468149
Epoch: 12 | Iteration number: [1660/4518] 36% | Training loss: 0.6874143676944526
Epoch: 12 | Iteration number: [1670/4518] 36% | Training loss: 0.6874216283866745
Epoch: 12 | Iteration number: [1680/4518] 37% | Training loss: 0.6874147347751118
Epoch: 12 | Iteration number: [1690/4518] 37% | Training loss: 0.6874090559383821
Epoch: 12 | Iteration number: [1700/4518] 37% | Training loss: 0.6874085699460085
Epoch: 12 | Iteration number: [1710/4518] 37% | Training loss: 0.6873988726334265
Epoch: 12 | Iteration number: [1720/4518] 38% | Training loss: 0.6873987848675528
Epoch: 12 | Iteration number: [1730/4518] 38% | Training loss: 0.6873858091114573
Epoch: 12 | Iteration number: [1740/4518] 38% | Training loss: 0.687378514703663
Epoch: 12 | Iteration number: [1750/4518] 38% | Training loss: 0.6873778525420597
Epoch: 12 | Iteration number: [1760/4518] 38% | Training loss: 0.6873745383186773
Epoch: 12 | Iteration number: [1770/4518] 39% | Training loss: 0.6873687318489377
Epoch: 12 | Iteration number: [1780/4518] 39% | Training loss: 0.6873697908406847
Epoch: 12 | Iteration number: [1790/4518] 39% | Training loss: 0.6873672637193563
Epoch: 12 | Iteration number: [1800/4518] 39% | Training loss: 0.6873615456289716
Epoch: 12 | Iteration number: [1810/4518] 40% | Training loss: 0.6873633813133556
Epoch: 12 | Iteration number: [1820/4518] 40% | Training loss: 0.6873552935791539
Epoch: 12 | Iteration number: [1830/4518] 40% | Training loss: 0.6873533226101777
Epoch: 12 | Iteration number: [1840/4518] 40% | Training loss: 0.6873547569241213
Epoch: 12 | Iteration number: [1850/4518] 40% | Training loss: 0.6873551831374297
Epoch: 12 | Iteration number: [1860/4518] 41% | Training loss: 0.6873535924380826
Epoch: 12 | Iteration number: [1870/4518] 41% | Training loss: 0.6873545908991666
Epoch: 12 | Iteration number: [1880/4518] 41% | Training loss: 0.687348928857357
Epoch: 12 | Iteration number: [1890/4518] 41% | Training loss: 0.6873508030144626
Epoch: 12 | Iteration number: [1900/4518] 42% | Training loss: 0.687345585823059
Epoch: 12 | Iteration number: [1910/4518] 42% | Training loss: 0.6873419465506888
Epoch: 12 | Iteration number: [1920/4518] 42% | Training loss: 0.6873278346533577
Epoch: 12 | Iteration number: [1930/4518] 42% | Training loss: 0.6873221928900387
Epoch: 12 | Iteration number: [1940/4518] 42% | Training loss: 0.6873206708849091
Epoch: 12 | Iteration number: [1950/4518] 43% | Training loss: 0.6873193660149207
Epoch: 12 | Iteration number: [1960/4518] 43% | Training loss: 0.6873138907916692
Epoch: 12 | Iteration number: [1970/4518] 43% | Training loss: 0.6873073709495177
Epoch: 12 | Iteration number: [1980/4518] 43% | Training loss: 0.6873078311633583
Epoch: 12 | Iteration number: [1990/4518] 44% | Training loss: 0.6873098587270957
Epoch: 12 | Iteration number: [2000/4518] 44% | Training loss: 0.6873064181506634
Epoch: 12 | Iteration number: [2010/4518] 44% | Training loss: 0.6873026617723911
Epoch: 12 | Iteration number: [2020/4518] 44% | Training loss: 0.6872972928356416
Epoch: 12 | Iteration number: [2030/4518] 44% | Training loss: 0.6872960190761266
Epoch: 12 | Iteration number: [2040/4518] 45% | Training loss: 0.6872884520128661
Epoch: 12 | Iteration number: [2050/4518] 45% | Training loss: 0.6872871054963368
Epoch: 12 | Iteration number: [2060/4518] 45% | Training loss: 0.6872779351125643
Epoch: 12 | Iteration number: [2070/4518] 45% | Training loss: 0.6872727247827871
Epoch: 12 | Iteration number: [2080/4518] 46% | Training loss: 0.6872762787227448
Epoch: 12 | Iteration number: [2090/4518] 46% | Training loss: 0.6872793277199759
Epoch: 12 | Iteration number: [2100/4518] 46% | Training loss: 0.6872716672647567
Epoch: 12 | Iteration number: [2110/4518] 46% | Training loss: 0.687273269157274
Epoch: 12 | Iteration number: [2120/4518] 46% | Training loss: 0.6872696575972269
Epoch: 12 | Iteration number: [2130/4518] 47% | Training loss: 0.6872747849130855
Epoch: 12 | Iteration number: [2140/4518] 47% | Training loss: 0.6872771697902234
Epoch: 12 | Iteration number: [2150/4518] 47% | Training loss: 0.6872792262809221
Epoch: 12 | Iteration number: [2160/4518] 47% | Training loss: 0.6872807526478061
Epoch: 12 | Iteration number: [2170/4518] 48% | Training loss: 0.6872785192480835
Epoch: 12 | Iteration number: [2180/4518] 48% | Training loss: 0.6872769453109951
Epoch: 12 | Iteration number: [2190/4518] 48% | Training loss: 0.6872778435820314
Epoch: 12 | Iteration number: [2200/4518] 48% | Training loss: 0.687273574823683
Epoch: 12 | Iteration number: [2210/4518] 48% | Training loss: 0.687266096270462
Epoch: 12 | Iteration number: [2220/4518] 49% | Training loss: 0.6872591817701185
Epoch: 12 | Iteration number: [2230/4518] 49% | Training loss: 0.6872577350235841
Epoch: 12 | Iteration number: [2240/4518] 49% | Training loss: 0.6872584105070149
Epoch: 12 | Iteration number: [2250/4518] 49% | Training loss: 0.6872617659568787
Epoch: 12 | Iteration number: [2260/4518] 50% | Training loss: 0.6872616473024925
Epoch: 12 | Iteration number: [2270/4518] 50% | Training loss: 0.6872606242805851
Epoch: 12 | Iteration number: [2280/4518] 50% | Training loss: 0.6872567340993044
Epoch: 12 | Iteration number: [2290/4518] 50% | Training loss: 0.6872499932107967
Epoch: 12 | Iteration number: [2300/4518] 50% | Training loss: 0.6872462863766629
Epoch: 12 | Iteration number: [2310/4518] 51% | Training loss: 0.6872416964599064
Epoch: 12 | Iteration number: [2320/4518] 51% | Training loss: 0.6872386684191638
Epoch: 12 | Iteration number: [2330/4518] 51% | Training loss: 0.6872380190908653
Epoch: 12 | Iteration number: [2340/4518] 51% | Training loss: 0.6872388944411889
Epoch: 12 | Iteration number: [2350/4518] 52% | Training loss: 0.6872380304082911
Epoch: 12 | Iteration number: [2360/4518] 52% | Training loss: 0.6872414611658808
Epoch: 12 | Iteration number: [2370/4518] 52% | Training loss: 0.6872412089305588
Epoch: 12 | Iteration number: [2380/4518] 52% | Training loss: 0.6872429032285674
Epoch: 12 | Iteration number: [2390/4518] 52% | Training loss: 0.6872423512416903
Epoch: 12 | Iteration number: [2400/4518] 53% | Training loss: 0.6872426307698091
Epoch: 12 | Iteration number: [2410/4518] 53% | Training loss: 0.687241143458117
Epoch: 12 | Iteration number: [2420/4518] 53% | Training loss: 0.6872392931506653
Epoch: 12 | Iteration number: [2430/4518] 53% | Training loss: 0.6872405924424222
Epoch: 12 | Iteration number: [2440/4518] 54% | Training loss: 0.687241405444067
Epoch: 12 | Iteration number: [2450/4518] 54% | Training loss: 0.6872438722240681
Epoch: 12 | Iteration number: [2460/4518] 54% | Training loss: 0.687241364639949
Epoch: 12 | Iteration number: [2470/4518] 54% | Training loss: 0.687236865256962
Epoch: 12 | Iteration number: [2480/4518] 54% | Training loss: 0.6872356920473037
Epoch: 12 | Iteration number: [2490/4518] 55% | Training loss: 0.6872392350411319
Epoch: 12 | Iteration number: [2500/4518] 55% | Training loss: 0.6872352734088898
Epoch: 12 | Iteration number: [2510/4518] 55% | Training loss: 0.6872307202255583
Epoch: 12 | Iteration number: [2520/4518] 55% | Training loss: 0.6872224874439694
Epoch: 12 | Iteration number: [2530/4518] 55% | Training loss: 0.6872173122502128
Epoch: 12 | Iteration number: [2540/4518] 56% | Training loss: 0.6872186782557195
Epoch: 12 | Iteration number: [2550/4518] 56% | Training loss: 0.687220357282489
Epoch: 12 | Iteration number: [2560/4518] 56% | Training loss: 0.6872165716486052
Epoch: 12 | Iteration number: [2570/4518] 56% | Training loss: 0.6872119707356167
Epoch: 12 | Iteration number: [2580/4518] 57% | Training loss: 0.6872075507576152
Epoch: 12 | Iteration number: [2590/4518] 57% | Training loss: 0.6872094356185221
Epoch: 12 | Iteration number: [2600/4518] 57% | Training loss: 0.6872059071293244
Epoch: 12 | Iteration number: [2610/4518] 57% | Training loss: 0.6872055311997731
Epoch: 12 | Iteration number: [2620/4518] 57% | Training loss: 0.687210442842418
Epoch: 12 | Iteration number: [2630/4518] 58% | Training loss: 0.6872097454596835
Epoch: 12 | Iteration number: [2640/4518] 58% | Training loss: 0.6872151348175425
Epoch: 12 | Iteration number: [2650/4518] 58% | Training loss: 0.6872214815301715
Epoch: 12 | Iteration number: [2660/4518] 58% | Training loss: 0.6872244901675031
Epoch: 12 | Iteration number: [2670/4518] 59% | Training loss: 0.6872183942169733
Epoch: 12 | Iteration number: [2680/4518] 59% | Training loss: 0.6872181695121438
Epoch: 12 | Iteration number: [2690/4518] 59% | Training loss: 0.6872151006110095
Epoch: 12 | Iteration number: [2700/4518] 59% | Training loss: 0.6872127454589915
Epoch: 12 | Iteration number: [2710/4518] 59% | Training loss: 0.6872132550086483
Epoch: 12 | Iteration number: [2720/4518] 60% | Training loss: 0.6872170046848409
Epoch: 12 | Iteration number: [2730/4518] 60% | Training loss: 0.6872195213487297
Epoch: 12 | Iteration number: [2740/4518] 60% | Training loss: 0.6872203842131761
Epoch: 12 | Iteration number: [2750/4518] 60% | Training loss: 0.6872210132208737
Epoch: 12 | Iteration number: [2760/4518] 61% | Training loss: 0.6872216109996256
Epoch: 12 | Iteration number: [2770/4518] 61% | Training loss: 0.6872190803397004
Epoch: 12 | Iteration number: [2780/4518] 61% | Training loss: 0.687220005508807
Epoch: 12 | Iteration number: [2790/4518] 61% | Training loss: 0.6872190596595887
Epoch: 12 | Iteration number: [2800/4518] 61% | Training loss: 0.6872098362020084
Epoch: 12 | Iteration number: [2810/4518] 62% | Training loss: 0.6872099939190196
Epoch: 12 | Iteration number: [2820/4518] 62% | Training loss: 0.6872074476370574
Epoch: 12 | Iteration number: [2830/4518] 62% | Training loss: 0.687210384421972
Epoch: 12 | Iteration number: [2840/4518] 62% | Training loss: 0.6872104074753506
Epoch: 12 | Iteration number: [2850/4518] 63% | Training loss: 0.6872090102915178
Epoch: 12 | Iteration number: [2860/4518] 63% | Training loss: 0.6872074918521868
Epoch: 12 | Iteration number: [2870/4518] 63% | Training loss: 0.6872118240241805
Epoch: 12 | Iteration number: [2880/4518] 63% | Training loss: 0.6872093950501746
Epoch: 12 | Iteration number: [2890/4518] 63% | Training loss: 0.6872086567449734
Epoch: 12 | Iteration number: [2900/4518] 64% | Training loss: 0.6872073831845974
Epoch: 12 | Iteration number: [2910/4518] 64% | Training loss: 0.6872087744093432
Epoch: 12 | Iteration number: [2920/4518] 64% | Training loss: 0.6872093902671174
Epoch: 12 | Iteration number: [2930/4518] 64% | Training loss: 0.6872114852630238
Epoch: 12 | Iteration number: [2940/4518] 65% | Training loss: 0.6872111005037009
Epoch: 12 | Iteration number: [2950/4518] 65% | Training loss: 0.6872063466856035
Epoch: 12 | Iteration number: [2960/4518] 65% | Training loss: 0.6872048689505539
Epoch: 12 | Iteration number: [2970/4518] 65% | Training loss: 0.6872041324573736
Epoch: 12 | Iteration number: [2980/4518] 65% | Training loss: 0.6872080940728219
Epoch: 12 | Iteration number: [2990/4518] 66% | Training loss: 0.6872041652035155
Epoch: 12 | Iteration number: [3000/4518] 66% | Training loss: 0.6872013629674911
Epoch: 12 | Iteration number: [3010/4518] 66% | Training loss: 0.6872005178088761
Epoch: 12 | Iteration number: [3020/4518] 66% | Training loss: 0.6871976103016872
Epoch: 12 | Iteration number: [3030/4518] 67% | Training loss: 0.6871989324541375
Epoch: 12 | Iteration number: [3040/4518] 67% | Training loss: 0.6871977643158875
Epoch: 12 | Iteration number: [3050/4518] 67% | Training loss: 0.6871951162815094
Epoch: 12 | Iteration number: [3060/4518] 67% | Training loss: 0.6871938823095334
Epoch: 12 | Iteration number: [3070/4518] 67% | Training loss: 0.6871914703216926
Epoch: 12 | Iteration number: [3080/4518] 68% | Training loss: 0.6871946144413639
Epoch: 12 | Iteration number: [3090/4518] 68% | Training loss: 0.6872009415842568
Epoch: 12 | Iteration number: [3100/4518] 68% | Training loss: 0.6872072813587804
Epoch: 12 | Iteration number: [3110/4518] 68% | Training loss: 0.6872081547879713
Epoch: 12 | Iteration number: [3120/4518] 69% | Training loss: 0.68720970589381
Epoch: 12 | Iteration number: [3130/4518] 69% | Training loss: 0.6872100120344863
Epoch: 12 | Iteration number: [3140/4518] 69% | Training loss: 0.6872079396703441
Epoch: 12 | Iteration number: [3150/4518] 69% | Training loss: 0.6872032705185905
Epoch: 12 | Iteration number: [3160/4518] 69% | Training loss: 0.6872043752972083
Epoch: 12 | Iteration number: [3170/4518] 70% | Training loss: 0.6871980765264493
Epoch: 12 | Iteration number: [3180/4518] 70% | Training loss: 0.6871961718085426
Epoch: 12 | Iteration number: [3190/4518] 70% | Training loss: 0.6871991626147567
Epoch: 12 | Iteration number: [3200/4518] 70% | Training loss: 0.6871959444135427
Epoch: 12 | Iteration number: [3210/4518] 71% | Training loss: 0.6871942445867901
Epoch: 12 | Iteration number: [3220/4518] 71% | Training loss: 0.6871964951664765
Epoch: 12 | Iteration number: [3230/4518] 71% | Training loss: 0.6871945595962713
Epoch: 12 | Iteration number: [3240/4518] 71% | Training loss: 0.6871966154854975
Epoch: 12 | Iteration number: [3250/4518] 71% | Training loss: 0.6871950941636012
Epoch: 12 | Iteration number: [3260/4518] 72% | Training loss: 0.687190666392537
Epoch: 12 | Iteration number: [3270/4518] 72% | Training loss: 0.6871884917265049
Epoch: 12 | Iteration number: [3280/4518] 72% | Training loss: 0.6871851737724571
Epoch: 12 | Iteration number: [3290/4518] 72% | Training loss: 0.6871832267853989
Epoch: 12 | Iteration number: [3300/4518] 73% | Training loss: 0.6871809095324892
Epoch: 12 | Iteration number: [3310/4518] 73% | Training loss: 0.6871822982576319
Epoch: 12 | Iteration number: [3320/4518] 73% | Training loss: 0.6871804906661252
Epoch: 12 | Iteration number: [3330/4518] 73% | Training loss: 0.6871776524427775
Epoch: 12 | Iteration number: [3340/4518] 73% | Training loss: 0.6871737189278632
Epoch: 12 | Iteration number: [3350/4518] 74% | Training loss: 0.687172663478709
Epoch: 12 | Iteration number: [3360/4518] 74% | Training loss: 0.6871681013987178
Epoch: 12 | Iteration number: [3370/4518] 74% | Training loss: 0.6871696081642581
Epoch: 12 | Iteration number: [3380/4518] 74% | Training loss: 0.6871713596159185
Epoch: 12 | Iteration number: [3390/4518] 75% | Training loss: 0.687172176124072
Epoch: 12 | Iteration number: [3400/4518] 75% | Training loss: 0.6871678519950194
Epoch: 12 | Iteration number: [3410/4518] 75% | Training loss: 0.687169161937104
Epoch: 12 | Iteration number: [3420/4518] 75% | Training loss: 0.687166788302667
Epoch: 12 | Iteration number: [3430/4518] 75% | Training loss: 0.687171527856293
Epoch: 12 | Iteration number: [3440/4518] 76% | Training loss: 0.6871693190793658
Epoch: 12 | Iteration number: [3450/4518] 76% | Training loss: 0.6871662771701813
Epoch: 12 | Iteration number: [3460/4518] 76% | Training loss: 0.6871654579577419
Epoch: 12 | Iteration number: [3470/4518] 76% | Training loss: 0.6871656755205534
Epoch: 12 | Iteration number: [3480/4518] 77% | Training loss: 0.6871636266338415
Epoch: 12 | Iteration number: [3490/4518] 77% | Training loss: 0.687160642594526
Epoch: 12 | Iteration number: [3500/4518] 77% | Training loss: 0.6871597869055611
Epoch: 12 | Iteration number: [3510/4518] 77% | Training loss: 0.6871554515130839
Epoch: 12 | Iteration number: [3520/4518] 77% | Training loss: 0.6871500002389604
Epoch: 12 | Iteration number: [3530/4518] 78% | Training loss: 0.6871494663673487
Epoch: 12 | Iteration number: [3540/4518] 78% | Training loss: 0.6871452176974991
Epoch: 12 | Iteration number: [3550/4518] 78% | Training loss: 0.6871480736094462
Epoch: 12 | Iteration number: [3560/4518] 78% | Training loss: 0.6871476730771279
Epoch: 12 | Iteration number: [3570/4518] 79% | Training loss: 0.6871462337109221
Epoch: 12 | Iteration number: [3580/4518] 79% | Training loss: 0.6871455603804668
Epoch: 12 | Iteration number: [3590/4518] 79% | Training loss: 0.6871460651454819
Epoch: 12 | Iteration number: [3600/4518] 79% | Training loss: 0.6871493767698605
Epoch: 12 | Iteration number: [3610/4518] 79% | Training loss: 0.6871485562205645
Epoch: 12 | Iteration number: [3620/4518] 80% | Training loss: 0.6871497912466197
Epoch: 12 | Iteration number: [3630/4518] 80% | Training loss: 0.6871492541197575
Epoch: 12 | Iteration number: [3640/4518] 80% | Training loss: 0.6871481216707073
Epoch: 12 | Iteration number: [3650/4518] 80% | Training loss: 0.6871488102004952
Epoch: 12 | Iteration number: [3660/4518] 81% | Training loss: 0.6871463917317938
Epoch: 12 | Iteration number: [3670/4518] 81% | Training loss: 0.6871427959902086
Epoch: 12 | Iteration number: [3680/4518] 81% | Training loss: 0.6871420122845018
Epoch: 12 | Iteration number: [3690/4518] 81% | Training loss: 0.6871393777167571
Epoch: 12 | Iteration number: [3700/4518] 81% | Training loss: 0.6871390803118009
Epoch: 12 | Iteration number: [3710/4518] 82% | Training loss: 0.6871435153998454
Epoch: 12 | Iteration number: [3720/4518] 82% | Training loss: 0.6871468016056604
Epoch: 12 | Iteration number: [3730/4518] 82% | Training loss: 0.6871466735892258
Epoch: 12 | Iteration number: [3740/4518] 82% | Training loss: 0.6871460976288281
Epoch: 12 | Iteration number: [3750/4518] 83% | Training loss: 0.6871465993881225
Epoch: 12 | Iteration number: [3760/4518] 83% | Training loss: 0.6871460977545444
Epoch: 12 | Iteration number: [3770/4518] 83% | Training loss: 0.6871473673009746
Epoch: 12 | Iteration number: [3780/4518] 83% | Training loss: 0.6871471724655263
Epoch: 12 | Iteration number: [3790/4518] 83% | Training loss: 0.6871467799813263
Epoch: 12 | Iteration number: [3800/4518] 84% | Training loss: 0.6871465507463405
Epoch: 12 | Iteration number: [3810/4518] 84% | Training loss: 0.6871468935738712
Epoch: 12 | Iteration number: [3820/4518] 84% | Training loss: 0.6871460273003703
Epoch: 12 | Iteration number: [3830/4518] 84% | Training loss: 0.6871438410201209
Epoch: 12 | Iteration number: [3840/4518] 84% | Training loss: 0.6871459715844442
Epoch: 12 | Iteration number: [3850/4518] 85% | Training loss: 0.687144624180608
Epoch: 12 | Iteration number: [3860/4518] 85% | Training loss: 0.6871429328628155
Epoch: 12 | Iteration number: [3870/4518] 85% | Training loss: 0.6871452549477264
Epoch: 12 | Iteration number: [3880/4518] 85% | Training loss: 0.6871450989823981
Epoch: 12 | Iteration number: [3890/4518] 86% | Training loss: 0.6871424732753734
Epoch: 12 | Iteration number: [3900/4518] 86% | Training loss: 0.6871418672647231
Epoch: 12 | Iteration number: [3910/4518] 86% | Training loss: 0.6871425546191232
Epoch: 12 | Iteration number: [3920/4518] 86% | Training loss: 0.687142532349241
Epoch: 12 | Iteration number: [3930/4518] 86% | Training loss: 0.6871449245296362
Epoch: 12 | Iteration number: [3940/4518] 87% | Training loss: 0.6871439096588774
Epoch: 12 | Iteration number: [3950/4518] 87% | Training loss: 0.6871434328224085
Epoch: 12 | Iteration number: [3960/4518] 87% | Training loss: 0.6871439860324667
Epoch: 12 | Iteration number: [3970/4518] 87% | Training loss: 0.6871444404425489
Epoch: 12 | Iteration number: [3980/4518] 88% | Training loss: 0.6871373480139066
Epoch: 12 | Iteration number: [3990/4518] 88% | Training loss: 0.6871385250025823
Epoch: 12 | Iteration number: [4000/4518] 88% | Training loss: 0.6871373729556799
Epoch: 12 | Iteration number: [4010/4518] 88% | Training loss: 0.6871346985312768
Epoch: 12 | Iteration number: [4020/4518] 88% | Training loss: 0.6871357897620889
Epoch: 12 | Iteration number: [4030/4518] 89% | Training loss: 0.6871353966426613
Epoch: 12 | Iteration number: [4040/4518] 89% | Training loss: 0.6871334402130382
Epoch: 12 | Iteration number: [4050/4518] 89% | Training loss: 0.6871336282035451
Epoch: 12 | Iteration number: [4060/4518] 89% | Training loss: 0.68713242233974
Epoch: 12 | Iteration number: [4070/4518] 90% | Training loss: 0.687134777342658
Epoch: 12 | Iteration number: [4080/4518] 90% | Training loss: 0.6871352619108032
Epoch: 12 | Iteration number: [4090/4518] 90% | Training loss: 0.6871344539384678
Epoch: 12 | Iteration number: [4100/4518] 90% | Training loss: 0.687133531134303
Epoch: 12 | Iteration number: [4110/4518] 90% | Training loss: 0.6871361464769591
Epoch: 12 | Iteration number: [4120/4518] 91% | Training loss: 0.6871313333511353
Epoch: 12 | Iteration number: [4130/4518] 91% | Training loss: 0.6871318516517667
Epoch: 12 | Iteration number: [4140/4518] 91% | Training loss: 0.6871307969237296
Epoch: 12 | Iteration number: [4150/4518] 91% | Training loss: 0.6871295355457857
Epoch: 12 | Iteration number: [4160/4518] 92% | Training loss: 0.6871271682330049
Epoch: 12 | Iteration number: [4170/4518] 92% | Training loss: 0.6871230732622764
Epoch: 12 | Iteration number: [4180/4518] 92% | Training loss: 0.6871219549310265
Epoch: 12 | Iteration number: [4190/4518] 92% | Training loss: 0.6871240006426353
Epoch: 12 | Iteration number: [4200/4518] 92% | Training loss: 0.6871247852558181
Epoch: 12 | Iteration number: [4210/4518] 93% | Training loss: 0.6871229182937649
Epoch: 12 | Iteration number: [4220/4518] 93% | Training loss: 0.6871227198867437
Epoch: 12 | Iteration number: [4230/4518] 93% | Training loss: 0.6871222635673857
Epoch: 12 | Iteration number: [4240/4518] 93% | Training loss: 0.6871211719681631
Epoch: 12 | Iteration number: [4250/4518] 94% | Training loss: 0.6871217449412627
Epoch: 12 | Iteration number: [4260/4518] 94% | Training loss: 0.687120147518149
Epoch: 12 | Iteration number: [4270/4518] 94% | Training loss: 0.6871206701778975
Epoch: 12 | Iteration number: [4280/4518] 94% | Training loss: 0.6871201205337159
Epoch: 12 | Iteration number: [4290/4518] 94% | Training loss: 0.6871202965994259
Epoch: 12 | Iteration number: [4300/4518] 95% | Training loss: 0.687122101159983
Epoch: 12 | Iteration number: [4310/4518] 95% | Training loss: 0.6871212263394951
Epoch: 12 | Iteration number: [4320/4518] 95% | Training loss: 0.6871216859392546
Epoch: 12 | Iteration number: [4330/4518] 95% | Training loss: 0.6871223145351674
Epoch: 12 | Iteration number: [4340/4518] 96% | Training loss: 0.6871218608134353
Epoch: 12 | Iteration number: [4350/4518] 96% | Training loss: 0.6871221066891462
Epoch: 12 | Iteration number: [4360/4518] 96% | Training loss: 0.6871208260502291
Epoch: 12 | Iteration number: [4370/4518] 96% | Training loss: 0.687119996411304
Epoch: 12 | Iteration number: [4380/4518] 96% | Training loss: 0.6871205283354407
Epoch: 12 | Iteration number: [4390/4518] 97% | Training loss: 0.687119374989377
Epoch: 12 | Iteration number: [4400/4518] 97% | Training loss: 0.6871216775206003
Epoch: 12 | Iteration number: [4410/4518] 97% | Training loss: 0.6871193612649057
Epoch: 12 | Iteration number: [4420/4518] 97% | Training loss: 0.6871190491035514
Epoch: 12 | Iteration number: [4430/4518] 98% | Training loss: 0.6871177887943475
Epoch: 12 | Iteration number: [4440/4518] 98% | Training loss: 0.6871174099343317
Epoch: 12 | Iteration number: [4450/4518] 98% | Training loss: 0.6871157887142696
Epoch: 12 | Iteration number: [4460/4518] 98% | Training loss: 0.6871172666950611
Epoch: 12 | Iteration number: [4470/4518] 98% | Training loss: 0.6871186107463751
Epoch: 12 | Iteration number: [4480/4518] 99% | Training loss: 0.6871158270697508
Epoch: 12 | Iteration number: [4490/4518] 99% | Training loss: 0.6871160452243745
Epoch: 12 | Iteration number: [4500/4518] 99% | Training loss: 0.6871176255676481
Epoch: 12 | Iteration number: [4510/4518] 99% | Training loss: 0.6871188865796954

 End of epoch: 12 | Train Loss: 0.6869664195102102 | Training Time: 640 

 End of epoch: 12 | Eval Loss: 0.6902613080277735 | Evaluating Time: 17 
Epoch: 13 | Iteration number: [10/4518] 0% | Training loss: 0.7545698404312133
Epoch: 13 | Iteration number: [20/4518] 0% | Training loss: 0.7208012133836746
Epoch: 13 | Iteration number: [30/4518] 0% | Training loss: 0.7093783438205719
Epoch: 13 | Iteration number: [40/4518] 0% | Training loss: 0.7038565844297409
Epoch: 13 | Iteration number: [50/4518] 1% | Training loss: 0.6999105072021484
Epoch: 13 | Iteration number: [60/4518] 1% | Training loss: 0.6978294253349304
Epoch: 13 | Iteration number: [70/4518] 1% | Training loss: 0.6962597327572959
Epoch: 13 | Iteration number: [80/4518] 1% | Training loss: 0.6950786910951138
Epoch: 13 | Iteration number: [90/4518] 1% | Training loss: 0.6943067146672143
Epoch: 13 | Iteration number: [100/4518] 2% | Training loss: 0.6936344915628433
Epoch: 13 | Iteration number: [110/4518] 2% | Training loss: 0.693084792657332
Epoch: 13 | Iteration number: [120/4518] 2% | Training loss: 0.6926090170939764
Epoch: 13 | Iteration number: [130/4518] 2% | Training loss: 0.6921104490756989
Epoch: 13 | Iteration number: [140/4518] 3% | Training loss: 0.6917894691228866
Epoch: 13 | Iteration number: [150/4518] 3% | Training loss: 0.6916307242711385
Epoch: 13 | Iteration number: [160/4518] 3% | Training loss: 0.691370728239417
Epoch: 13 | Iteration number: [170/4518] 3% | Training loss: 0.6911338623832254
Epoch: 13 | Iteration number: [180/4518] 3% | Training loss: 0.6908580508497026
Epoch: 13 | Iteration number: [190/4518] 4% | Training loss: 0.6906277659692263
Epoch: 13 | Iteration number: [200/4518] 4% | Training loss: 0.6904739671945572
Epoch: 13 | Iteration number: [210/4518] 4% | Training loss: 0.6902650923956009
Epoch: 13 | Iteration number: [220/4518] 4% | Training loss: 0.6900775345889005
Epoch: 13 | Iteration number: [230/4518] 5% | Training loss: 0.6899118143579234
Epoch: 13 | Iteration number: [240/4518] 5% | Training loss: 0.6897797475258509
Epoch: 13 | Iteration number: [250/4518] 5% | Training loss: 0.6896246206760407
Epoch: 13 | Iteration number: [260/4518] 5% | Training loss: 0.6895367766802127
Epoch: 13 | Iteration number: [270/4518] 5% | Training loss: 0.689457916992682
Epoch: 13 | Iteration number: [280/4518] 6% | Training loss: 0.6893812058227403
Epoch: 13 | Iteration number: [290/4518] 6% | Training loss: 0.6892784542050855
Epoch: 13 | Iteration number: [300/4518] 6% | Training loss: 0.6892133627335231
Epoch: 13 | Iteration number: [310/4518] 6% | Training loss: 0.689158946083438
Epoch: 13 | Iteration number: [320/4518] 7% | Training loss: 0.6890716630965471
Epoch: 13 | Iteration number: [330/4518] 7% | Training loss: 0.6890317461707375
Epoch: 13 | Iteration number: [340/4518] 7% | Training loss: 0.6889702914392247
Epoch: 13 | Iteration number: [350/4518] 7% | Training loss: 0.6889135616166251
Epoch: 13 | Iteration number: [360/4518] 7% | Training loss: 0.6888503909111023
Epoch: 13 | Iteration number: [370/4518] 8% | Training loss: 0.688782510080853
Epoch: 13 | Iteration number: [380/4518] 8% | Training loss: 0.6887344391722429
Epoch: 13 | Iteration number: [390/4518] 8% | Training loss: 0.6886779062258892
Epoch: 13 | Iteration number: [400/4518] 8% | Training loss: 0.6886714807152748
Epoch: 13 | Iteration number: [410/4518] 9% | Training loss: 0.6886107398242485
Epoch: 13 | Iteration number: [420/4518] 9% | Training loss: 0.6885907632963998
Epoch: 13 | Iteration number: [430/4518] 9% | Training loss: 0.6885519582171773
Epoch: 13 | Iteration number: [440/4518] 9% | Training loss: 0.6885022258216684
Epoch: 13 | Iteration number: [450/4518] 9% | Training loss: 0.6884524595737457
Epoch: 13 | Iteration number: [460/4518] 10% | Training loss: 0.6884292936843375
Epoch: 13 | Iteration number: [470/4518] 10% | Training loss: 0.6883875395389314
Epoch: 13 | Iteration number: [480/4518] 10% | Training loss: 0.6883650581041972
Epoch: 13 | Iteration number: [490/4518] 10% | Training loss: 0.6883210431556313
Epoch: 13 | Iteration number: [500/4518] 11% | Training loss: 0.6883015375137329
Epoch: 13 | Iteration number: [510/4518] 11% | Training loss: 0.6883106115986319
Epoch: 13 | Iteration number: [520/4518] 11% | Training loss: 0.6882858777275452
Epoch: 13 | Iteration number: [530/4518] 11% | Training loss: 0.6882751996787089
Epoch: 13 | Iteration number: [540/4518] 11% | Training loss: 0.6882625669240952
Epoch: 13 | Iteration number: [550/4518] 12% | Training loss: 0.6882411549308083
Epoch: 13 | Iteration number: [560/4518] 12% | Training loss: 0.688230585200446
Epoch: 13 | Iteration number: [570/4518] 12% | Training loss: 0.6882023202745537
Epoch: 13 | Iteration number: [580/4518] 12% | Training loss: 0.6881680844158962
Epoch: 13 | Iteration number: [590/4518] 13% | Training loss: 0.6881654554504459
Epoch: 13 | Iteration number: [600/4518] 13% | Training loss: 0.6881383408109347
Epoch: 13 | Iteration number: [610/4518] 13% | Training loss: 0.6881404542532124
Epoch: 13 | Iteration number: [620/4518] 13% | Training loss: 0.6881241788787227
Epoch: 13 | Iteration number: [630/4518] 13% | Training loss: 0.6881192898939527
Epoch: 13 | Iteration number: [640/4518] 14% | Training loss: 0.6880979859270155
Epoch: 13 | Iteration number: [650/4518] 14% | Training loss: 0.6880823541604556
Epoch: 13 | Iteration number: [660/4518] 14% | Training loss: 0.6880502037026666
Epoch: 13 | Iteration number: [670/4518] 14% | Training loss: 0.6880281660983811
Epoch: 13 | Iteration number: [680/4518] 15% | Training loss: 0.6880076302325024
Epoch: 13 | Iteration number: [690/4518] 15% | Training loss: 0.6879948316276937
Epoch: 13 | Iteration number: [700/4518] 15% | Training loss: 0.6879920267207282
Epoch: 13 | Iteration number: [710/4518] 15% | Training loss: 0.6879624046070475
Epoch: 13 | Iteration number: [720/4518] 15% | Training loss: 0.6879602523313628
Epoch: 13 | Iteration number: [730/4518] 16% | Training loss: 0.6879625495165995
Epoch: 13 | Iteration number: [740/4518] 16% | Training loss: 0.687952010615452
Epoch: 13 | Iteration number: [750/4518] 16% | Training loss: 0.6879443147977193
Epoch: 13 | Iteration number: [760/4518] 16% | Training loss: 0.687923385830302
Epoch: 13 | Iteration number: [770/4518] 17% | Training loss: 0.6879154287375413
Epoch: 13 | Iteration number: [780/4518] 17% | Training loss: 0.6879081638959738
Epoch: 13 | Iteration number: [790/4518] 17% | Training loss: 0.6878844112535066
Epoch: 13 | Iteration number: [800/4518] 17% | Training loss: 0.6878594107180834
Epoch: 13 | Iteration number: [810/4518] 17% | Training loss: 0.6878637061442858
Epoch: 13 | Iteration number: [820/4518] 18% | Training loss: 0.6878610485210651
Epoch: 13 | Iteration number: [830/4518] 18% | Training loss: 0.687855029967894
Epoch: 13 | Iteration number: [840/4518] 18% | Training loss: 0.6878425064541045
Epoch: 13 | Iteration number: [850/4518] 18% | Training loss: 0.6878460912143483
Epoch: 13 | Iteration number: [860/4518] 19% | Training loss: 0.6878261401902798
Epoch: 13 | Iteration number: [870/4518] 19% | Training loss: 0.6878203124835574
Epoch: 13 | Iteration number: [880/4518] 19% | Training loss: 0.6878115459599278
Epoch: 13 | Iteration number: [890/4518] 19% | Training loss: 0.6878106186229191
Epoch: 13 | Iteration number: [900/4518] 19% | Training loss: 0.6877905433045494
Epoch: 13 | Iteration number: [910/4518] 20% | Training loss: 0.6877815714249245
Epoch: 13 | Iteration number: [920/4518] 20% | Training loss: 0.6877645940884299
Epoch: 13 | Iteration number: [930/4518] 20% | Training loss: 0.6877488611205932
Epoch: 13 | Iteration number: [940/4518] 20% | Training loss: 0.6877385189558597
Epoch: 13 | Iteration number: [950/4518] 21% | Training loss: 0.6877409461297487
Epoch: 13 | Iteration number: [960/4518] 21% | Training loss: 0.6877316624547044
Epoch: 13 | Iteration number: [970/4518] 21% | Training loss: 0.6877187918756426
Epoch: 13 | Iteration number: [980/4518] 21% | Training loss: 0.6877076273061791
Epoch: 13 | Iteration number: [990/4518] 21% | Training loss: 0.6876976676661559
Epoch: 13 | Iteration number: [1000/4518] 22% | Training loss: 0.687694892525673
Epoch: 13 | Iteration number: [1010/4518] 22% | Training loss: 0.6876890044401188
Epoch: 13 | Iteration number: [1020/4518] 22% | Training loss: 0.6876939507091746
Epoch: 13 | Iteration number: [1030/4518] 22% | Training loss: 0.687680786732331
Epoch: 13 | Iteration number: [1040/4518] 23% | Training loss: 0.6876807937828394
Epoch: 13 | Iteration number: [1050/4518] 23% | Training loss: 0.6876734391848246
Epoch: 13 | Iteration number: [1060/4518] 23% | Training loss: 0.6876717290226019
Epoch: 13 | Iteration number: [1070/4518] 23% | Training loss: 0.687662342998469
Epoch: 13 | Iteration number: [1080/4518] 23% | Training loss: 0.6876550235130169
Epoch: 13 | Iteration number: [1090/4518] 24% | Training loss: 0.6876532684772386
Epoch: 13 | Iteration number: [1100/4518] 24% | Training loss: 0.6876427925174886
Epoch: 13 | Iteration number: [1110/4518] 24% | Training loss: 0.6876446845832171
Epoch: 13 | Iteration number: [1120/4518] 24% | Training loss: 0.6876379698514938
Epoch: 13 | Iteration number: [1130/4518] 25% | Training loss: 0.6876318732721616
Epoch: 13 | Iteration number: [1140/4518] 25% | Training loss: 0.6876243114994284
Epoch: 13 | Iteration number: [1150/4518] 25% | Training loss: 0.6876170293662859
Epoch: 13 | Iteration number: [1160/4518] 25% | Training loss: 0.6876174456600486
Epoch: 13 | Iteration number: [1170/4518] 25% | Training loss: 0.6875972441628448
Epoch: 13 | Iteration number: [1180/4518] 26% | Training loss: 0.6876034747240907
Epoch: 13 | Iteration number: [1190/4518] 26% | Training loss: 0.687601056269237
Epoch: 13 | Iteration number: [1200/4518] 26% | Training loss: 0.6875972657899062
Epoch: 13 | Iteration number: [1210/4518] 26% | Training loss: 0.6875854047369366
Epoch: 13 | Iteration number: [1220/4518] 27% | Training loss: 0.6875718976141977
Epoch: 13 | Iteration number: [1230/4518] 27% | Training loss: 0.6875505633955079
Epoch: 13 | Iteration number: [1240/4518] 27% | Training loss: 0.6875517058757044
Epoch: 13 | Iteration number: [1250/4518] 27% | Training loss: 0.6875520281791687
Epoch: 13 | Iteration number: [1260/4518] 27% | Training loss: 0.6875525515703927
Epoch: 13 | Iteration number: [1270/4518] 28% | Training loss: 0.6875562972440494
Epoch: 13 | Iteration number: [1280/4518] 28% | Training loss: 0.6875526234507561
Epoch: 13 | Iteration number: [1290/4518] 28% | Training loss: 0.687553944744805
Epoch: 13 | Iteration number: [1300/4518] 28% | Training loss: 0.6875496879907754
Epoch: 13 | Iteration number: [1310/4518] 28% | Training loss: 0.6875479712286068
Epoch: 13 | Iteration number: [1320/4518] 29% | Training loss: 0.6875436190402869
Epoch: 13 | Iteration number: [1330/4518] 29% | Training loss: 0.687536134845332
Epoch: 13 | Iteration number: [1340/4518] 29% | Training loss: 0.6875283825308529
Epoch: 13 | Iteration number: [1350/4518] 29% | Training loss: 0.6875210120059826
Epoch: 13 | Iteration number: [1360/4518] 30% | Training loss: 0.687511272114866
Epoch: 13 | Iteration number: [1370/4518] 30% | Training loss: 0.687507565004112
Epoch: 13 | Iteration number: [1380/4518] 30% | Training loss: 0.6875046530495519
Epoch: 13 | Iteration number: [1390/4518] 30% | Training loss: 0.6874921842015904
Epoch: 13 | Iteration number: [1400/4518] 30% | Training loss: 0.6874976151755878
Epoch: 13 | Iteration number: [1410/4518] 31% | Training loss: 0.6874950208562486
Epoch: 13 | Iteration number: [1420/4518] 31% | Training loss: 0.6874867494677154
Epoch: 13 | Iteration number: [1430/4518] 31% | Training loss: 0.6874766464416797
Epoch: 13 | Iteration number: [1440/4518] 31% | Training loss: 0.687473901692364
Epoch: 13 | Iteration number: [1450/4518] 32% | Training loss: 0.6874664279099169
Epoch: 13 | Iteration number: [1460/4518] 32% | Training loss: 0.6874591097439805
Epoch: 13 | Iteration number: [1470/4518] 32% | Training loss: 0.6874577295212518
Epoch: 13 | Iteration number: [1480/4518] 32% | Training loss: 0.6874492768903037
Epoch: 13 | Iteration number: [1490/4518] 32% | Training loss: 0.6874380996563291
Epoch: 13 | Iteration number: [1500/4518] 33% | Training loss: 0.6874280461470286
Epoch: 13 | Iteration number: [1510/4518] 33% | Training loss: 0.6874286492534031
Epoch: 13 | Iteration number: [1520/4518] 33% | Training loss: 0.6874212152863803
Epoch: 13 | Iteration number: [1530/4518] 33% | Training loss: 0.6874184707410974
Epoch: 13 | Iteration number: [1540/4518] 34% | Training loss: 0.6874161922699445
Epoch: 13 | Iteration number: [1550/4518] 34% | Training loss: 0.6874042209886736
Epoch: 13 | Iteration number: [1560/4518] 34% | Training loss: 0.6873999054233233
Epoch: 13 | Iteration number: [1570/4518] 34% | Training loss: 0.6873948738073847
Epoch: 13 | Iteration number: [1580/4518] 34% | Training loss: 0.687390397583382
Epoch: 13 | Iteration number: [1590/4518] 35% | Training loss: 0.6873944435104634
Epoch: 13 | Iteration number: [1600/4518] 35% | Training loss: 0.6873940480872989
Epoch: 13 | Iteration number: [1610/4518] 35% | Training loss: 0.6873937148114909
Epoch: 13 | Iteration number: [1620/4518] 35% | Training loss: 0.6873841443179566
Epoch: 13 | Iteration number: [1630/4518] 36% | Training loss: 0.6873832060515515
Epoch: 13 | Iteration number: [1640/4518] 36% | Training loss: 0.6873868333493791
Epoch: 13 | Iteration number: [1650/4518] 36% | Training loss: 0.6873828592444912
Epoch: 13 | Iteration number: [1660/4518] 36% | Training loss: 0.6873778700110424
Epoch: 13 | Iteration number: [1670/4518] 36% | Training loss: 0.6873734847514216
Epoch: 13 | Iteration number: [1680/4518] 37% | Training loss: 0.6873678871563502
Epoch: 13 | Iteration number: [1690/4518] 37% | Training loss: 0.6873664726519726
Epoch: 13 | Iteration number: [1700/4518] 37% | Training loss: 0.6873615734366809
Epoch: 13 | Iteration number: [1710/4518] 37% | Training loss: 0.6873559936096794
Epoch: 13 | Iteration number: [1720/4518] 38% | Training loss: 0.6873538056778353
Epoch: 13 | Iteration number: [1730/4518] 38% | Training loss: 0.6873509511782255
Epoch: 13 | Iteration number: [1740/4518] 38% | Training loss: 0.6873512974073147
Epoch: 13 | Iteration number: [1750/4518] 38% | Training loss: 0.6873475798538753
Epoch: 13 | Iteration number: [1760/4518] 38% | Training loss: 0.6873416533185677
Epoch: 13 | Iteration number: [1770/4518] 39% | Training loss: 0.6873407439996967
Epoch: 13 | Iteration number: [1780/4518] 39% | Training loss: 0.6873359209700917
Epoch: 13 | Iteration number: [1790/4518] 39% | Training loss: 0.6873280350056441
Epoch: 13 | Iteration number: [1800/4518] 39% | Training loss: 0.6873207422759798
Epoch: 13 | Iteration number: [1810/4518] 40% | Training loss: 0.6873133953105021
Epoch: 13 | Iteration number: [1820/4518] 40% | Training loss: 0.687313261464402
Epoch: 13 | Iteration number: [1830/4518] 40% | Training loss: 0.6873076506976873
Epoch: 13 | Iteration number: [1840/4518] 40% | Training loss: 0.6873094272354375
Epoch: 13 | Iteration number: [1850/4518] 40% | Training loss: 0.6873120631398382
Epoch: 13 | Iteration number: [1860/4518] 41% | Training loss: 0.6873101822471106
Epoch: 13 | Iteration number: [1870/4518] 41% | Training loss: 0.6873052477836609
Epoch: 13 | Iteration number: [1880/4518] 41% | Training loss: 0.6873039422834173
Epoch: 13 | Iteration number: [1890/4518] 41% | Training loss: 0.6873014775533525
Epoch: 13 | Iteration number: [1900/4518] 42% | Training loss: 0.6873002553299854
Epoch: 13 | Iteration number: [1910/4518] 42% | Training loss: 0.6872963235640401
Epoch: 13 | Iteration number: [1920/4518] 42% | Training loss: 0.6872938174754382
Epoch: 13 | Iteration number: [1930/4518] 42% | Training loss: 0.6872796476504963
Epoch: 13 | Iteration number: [1940/4518] 42% | Training loss: 0.6872819535511057
Epoch: 13 | Iteration number: [1950/4518] 43% | Training loss: 0.6872866100837023
Epoch: 13 | Iteration number: [1960/4518] 43% | Training loss: 0.6872829515715034
Epoch: 13 | Iteration number: [1970/4518] 43% | Training loss: 0.6872801912617562
Epoch: 13 | Iteration number: [1980/4518] 43% | Training loss: 0.687279127733876
Epoch: 13 | Iteration number: [1990/4518] 44% | Training loss: 0.6872810742663379
Epoch: 13 | Iteration number: [2000/4518] 44% | Training loss: 0.687274904191494
Epoch: 13 | Iteration number: [2010/4518] 44% | Training loss: 0.6872655953637403
Epoch: 13 | Iteration number: [2020/4518] 44% | Training loss: 0.687261434120707
Epoch: 13 | Iteration number: [2030/4518] 44% | Training loss: 0.6872577515728955
Epoch: 13 | Iteration number: [2040/4518] 45% | Training loss: 0.6872595478506649
Epoch: 13 | Iteration number: [2050/4518] 45% | Training loss: 0.6872628217790185
Epoch: 13 | Iteration number: [2060/4518] 45% | Training loss: 0.6872676897974848
Epoch: 13 | Iteration number: [2070/4518] 45% | Training loss: 0.6872718006228479
Epoch: 13 | Iteration number: [2080/4518] 46% | Training loss: 0.6872690716328529
Epoch: 13 | Iteration number: [2090/4518] 46% | Training loss: 0.687266218690781
Epoch: 13 | Iteration number: [2100/4518] 46% | Training loss: 0.6872692075513658
Epoch: 13 | Iteration number: [2110/4518] 46% | Training loss: 0.6872715304813114
Epoch: 13 | Iteration number: [2120/4518] 46% | Training loss: 0.6872741677007586
Epoch: 13 | Iteration number: [2130/4518] 47% | Training loss: 0.6872700961262967
Epoch: 13 | Iteration number: [2140/4518] 47% | Training loss: 0.6872707427940636
Epoch: 13 | Iteration number: [2150/4518] 47% | Training loss: 0.6872670792424401
Epoch: 13 | Iteration number: [2160/4518] 47% | Training loss: 0.6872625024230392
Epoch: 13 | Iteration number: [2170/4518] 48% | Training loss: 0.6872622041932999
Epoch: 13 | Iteration number: [2180/4518] 48% | Training loss: 0.6872620357559361
Epoch: 13 | Iteration number: [2190/4518] 48% | Training loss: 0.6872579198177546
Epoch: 13 | Iteration number: [2200/4518] 48% | Training loss: 0.6872578458352523
Epoch: 13 | Iteration number: [2210/4518] 48% | Training loss: 0.6872568419616147
Epoch: 13 | Iteration number: [2220/4518] 49% | Training loss: 0.6872607839537096
Epoch: 13 | Iteration number: [2230/4518] 49% | Training loss: 0.6872631656214795
Epoch: 13 | Iteration number: [2240/4518] 49% | Training loss: 0.6872620491044862
Epoch: 13 | Iteration number: [2250/4518] 49% | Training loss: 0.6872626565032535
Epoch: 13 | Iteration number: [2260/4518] 50% | Training loss: 0.6872592257978641
Epoch: 13 | Iteration number: [2270/4518] 50% | Training loss: 0.6872556165714095
Epoch: 13 | Iteration number: [2280/4518] 50% | Training loss: 0.6872596281400898
Epoch: 13 | Iteration number: [2290/4518] 50% | Training loss: 0.6872568502176276
Epoch: 13 | Iteration number: [2300/4518] 50% | Training loss: 0.6872609326372976
Epoch: 13 | Iteration number: [2310/4518] 51% | Training loss: 0.6872628755125648
Epoch: 13 | Iteration number: [2320/4518] 51% | Training loss: 0.6872550771154207
Epoch: 13 | Iteration number: [2330/4518] 51% | Training loss: 0.6872588022584055
Epoch: 13 | Iteration number: [2340/4518] 51% | Training loss: 0.6872616612503671
Epoch: 13 | Iteration number: [2350/4518] 52% | Training loss: 0.6872561551662202
Epoch: 13 | Iteration number: [2360/4518] 52% | Training loss: 0.6872533741643874
Epoch: 13 | Iteration number: [2370/4518] 52% | Training loss: 0.6872544085174673
Epoch: 13 | Iteration number: [2380/4518] 52% | Training loss: 0.6872508093589494
Epoch: 13 | Iteration number: [2390/4518] 52% | Training loss: 0.6872521481753393
Epoch: 13 | Iteration number: [2400/4518] 53% | Training loss: 0.6872533773382504
Epoch: 13 | Iteration number: [2410/4518] 53% | Training loss: 0.6872524552078167
Epoch: 13 | Iteration number: [2420/4518] 53% | Training loss: 0.6872543792586682
Epoch: 13 | Iteration number: [2430/4518] 53% | Training loss: 0.6872533776387265
Epoch: 13 | Iteration number: [2440/4518] 54% | Training loss: 0.6872547766468564
Epoch: 13 | Iteration number: [2450/4518] 54% | Training loss: 0.6872523790719558
Epoch: 13 | Iteration number: [2460/4518] 54% | Training loss: 0.6872507373249628
Epoch: 13 | Iteration number: [2470/4518] 54% | Training loss: 0.6872465035210736
Epoch: 13 | Iteration number: [2480/4518] 54% | Training loss: 0.6872411036683667
Epoch: 13 | Iteration number: [2490/4518] 55% | Training loss: 0.6872391720134091
Epoch: 13 | Iteration number: [2500/4518] 55% | Training loss: 0.6872387369871139
Epoch: 13 | Iteration number: [2510/4518] 55% | Training loss: 0.6872397056376317
Epoch: 13 | Iteration number: [2520/4518] 55% | Training loss: 0.6872387992720755
Epoch: 13 | Iteration number: [2530/4518] 55% | Training loss: 0.687237602590101
Epoch: 13 | Iteration number: [2540/4518] 56% | Training loss: 0.6872414984102324
Epoch: 13 | Iteration number: [2550/4518] 56% | Training loss: 0.6872423422336579
Epoch: 13 | Iteration number: [2560/4518] 56% | Training loss: 0.6872414508601651
Epoch: 13 | Iteration number: [2570/4518] 56% | Training loss: 0.6872489275403524
Epoch: 13 | Iteration number: [2580/4518] 57% | Training loss: 0.6872482163037441
Epoch: 13 | Iteration number: [2590/4518] 57% | Training loss: 0.6872516827923911
Epoch: 13 | Iteration number: [2600/4518] 57% | Training loss: 0.6872525856586603
Epoch: 13 | Iteration number: [2610/4518] 57% | Training loss: 0.6872479528988001
Epoch: 13 | Iteration number: [2620/4518] 57% | Training loss: 0.6872490109833143
Epoch: 13 | Iteration number: [2630/4518] 58% | Training loss: 0.6872446282734889
Epoch: 13 | Iteration number: [2640/4518] 58% | Training loss: 0.6872438815507022
Epoch: 13 | Iteration number: [2650/4518] 58% | Training loss: 0.6872463348676574
Epoch: 13 | Iteration number: [2660/4518] 58% | Training loss: 0.6872384753442349
Epoch: 13 | Iteration number: [2670/4518] 59% | Training loss: 0.6872369874505961
Epoch: 13 | Iteration number: [2680/4518] 59% | Training loss: 0.6872342504449744
Epoch: 13 | Iteration number: [2690/4518] 59% | Training loss: 0.6872343111880207
Epoch: 13 | Iteration number: [2700/4518] 59% | Training loss: 0.6872298122776879
Epoch: 13 | Iteration number: [2710/4518] 59% | Training loss: 0.6872258029740675
Epoch: 13 | Iteration number: [2720/4518] 60% | Training loss: 0.6872260094565503
Epoch: 13 | Iteration number: [2730/4518] 60% | Training loss: 0.6872181948724684
Epoch: 13 | Iteration number: [2740/4518] 60% | Training loss: 0.6872196953662121
Epoch: 13 | Iteration number: [2750/4518] 60% | Training loss: 0.6872174591367894
Epoch: 13 | Iteration number: [2760/4518] 61% | Training loss: 0.6872170731857203
Epoch: 13 | Iteration number: [2770/4518] 61% | Training loss: 0.6872159007869473
Epoch: 13 | Iteration number: [2780/4518] 61% | Training loss: 0.6872141108024035
Epoch: 13 | Iteration number: [2790/4518] 61% | Training loss: 0.6872106586946809
Epoch: 13 | Iteration number: [2800/4518] 61% | Training loss: 0.6872143507003784
Epoch: 13 | Iteration number: [2810/4518] 62% | Training loss: 0.6872133576360886
Epoch: 13 | Iteration number: [2820/4518] 62% | Training loss: 0.6872114608473812
Epoch: 13 | Iteration number: [2830/4518] 62% | Training loss: 0.6872106749893498
Epoch: 13 | Iteration number: [2840/4518] 62% | Training loss: 0.6872094915156634
Epoch: 13 | Iteration number: [2850/4518] 63% | Training loss: 0.687211076836837
Epoch: 13 | Iteration number: [2860/4518] 63% | Training loss: 0.6872046512532067
Epoch: 13 | Iteration number: [2870/4518] 63% | Training loss: 0.687209157848192
Epoch: 13 | Iteration number: [2880/4518] 63% | Training loss: 0.6872110924786992
Epoch: 13 | Iteration number: [2890/4518] 63% | Training loss: 0.6872108592294079
Epoch: 13 | Iteration number: [2900/4518] 64% | Training loss: 0.6872085727083272
Epoch: 13 | Iteration number: [2910/4518] 64% | Training loss: 0.687208254415145
Epoch: 13 | Iteration number: [2920/4518] 64% | Training loss: 0.6872071332515103
Epoch: 13 | Iteration number: [2930/4518] 64% | Training loss: 0.6872051175950737
Epoch: 13 | Iteration number: [2940/4518] 65% | Training loss: 0.6872004113837975
Epoch: 13 | Iteration number: [2950/4518] 65% | Training loss: 0.6871990836878954
Epoch: 13 | Iteration number: [2960/4518] 65% | Training loss: 0.6871961599870308
Epoch: 13 | Iteration number: [2970/4518] 65% | Training loss: 0.6871982449433619
Epoch: 13 | Iteration number: [2980/4518] 65% | Training loss: 0.6871994163966019
Epoch: 13 | Iteration number: [2990/4518] 66% | Training loss: 0.6871947124849593
Epoch: 13 | Iteration number: [3000/4518] 66% | Training loss: 0.6871895761291186
Epoch: 13 | Iteration number: [3010/4518] 66% | Training loss: 0.6871882214696701
Epoch: 13 | Iteration number: [3020/4518] 66% | Training loss: 0.687186900768059
Epoch: 13 | Iteration number: [3030/4518] 67% | Training loss: 0.6871872902900079
Epoch: 13 | Iteration number: [3040/4518] 67% | Training loss: 0.6871857704496698
Epoch: 13 | Iteration number: [3050/4518] 67% | Training loss: 0.6871834586292017
Epoch: 13 | Iteration number: [3060/4518] 67% | Training loss: 0.6871835333459517
Epoch: 13 | Iteration number: [3070/4518] 67% | Training loss: 0.6871796324315211
Epoch: 13 | Iteration number: [3080/4518] 68% | Training loss: 0.687178699904448
Epoch: 13 | Iteration number: [3090/4518] 68% | Training loss: 0.6871799344190888
Epoch: 13 | Iteration number: [3100/4518] 68% | Training loss: 0.6871749727764437
Epoch: 13 | Iteration number: [3110/4518] 68% | Training loss: 0.6871740159497767
Epoch: 13 | Iteration number: [3120/4518] 69% | Training loss: 0.6871704331957377
Epoch: 13 | Iteration number: [3130/4518] 69% | Training loss: 0.6871747917831896
Epoch: 13 | Iteration number: [3140/4518] 69% | Training loss: 0.6871713695062953
Epoch: 13 | Iteration number: [3150/4518] 69% | Training loss: 0.687171778508595
Epoch: 13 | Iteration number: [3160/4518] 69% | Training loss: 0.687172315052793
Epoch: 13 | Iteration number: [3170/4518] 70% | Training loss: 0.687174034757945
Epoch: 13 | Iteration number: [3180/4518] 70% | Training loss: 0.687171564743204
Epoch: 13 | Iteration number: [3190/4518] 70% | Training loss: 0.6871682835596856
Epoch: 13 | Iteration number: [3200/4518] 70% | Training loss: 0.6871640253067016
Epoch: 13 | Iteration number: [3210/4518] 71% | Training loss: 0.6871659042307893
Epoch: 13 | Iteration number: [3220/4518] 71% | Training loss: 0.687168626144806
Epoch: 13 | Iteration number: [3230/4518] 71% | Training loss: 0.687167968487961
Epoch: 13 | Iteration number: [3240/4518] 71% | Training loss: 0.6871711070338885
Epoch: 13 | Iteration number: [3250/4518] 71% | Training loss: 0.6871656004832342
Epoch: 13 | Iteration number: [3260/4518] 72% | Training loss: 0.68716888506354
Epoch: 13 | Iteration number: [3270/4518] 72% | Training loss: 0.6871676720245898
Epoch: 13 | Iteration number: [3280/4518] 72% | Training loss: 0.6871639187924745
Epoch: 13 | Iteration number: [3290/4518] 72% | Training loss: 0.6871622472548558
Epoch: 13 | Iteration number: [3300/4518] 73% | Training loss: 0.6871643188324842
Epoch: 13 | Iteration number: [3310/4518] 73% | Training loss: 0.6871607470548405
Epoch: 13 | Iteration number: [3320/4518] 73% | Training loss: 0.6871607047427132
Epoch: 13 | Iteration number: [3330/4518] 73% | Training loss: 0.6871624762589509
Epoch: 13 | Iteration number: [3340/4518] 73% | Training loss: 0.6871633247700993
Epoch: 13 | Iteration number: [3350/4518] 74% | Training loss: 0.6871631235329073
Epoch: 13 | Iteration number: [3360/4518] 74% | Training loss: 0.6871662661610615
Epoch: 13 | Iteration number: [3370/4518] 74% | Training loss: 0.6871643170935464
Epoch: 13 | Iteration number: [3380/4518] 74% | Training loss: 0.6871650365330059
Epoch: 13 | Iteration number: [3390/4518] 75% | Training loss: 0.6871629447184481
Epoch: 13 | Iteration number: [3400/4518] 75% | Training loss: 0.6871619608822991
Epoch: 13 | Iteration number: [3410/4518] 75% | Training loss: 0.6871612220915182
Epoch: 13 | Iteration number: [3420/4518] 75% | Training loss: 0.6871650326321697
Epoch: 13 | Iteration number: [3430/4518] 75% | Training loss: 0.6871627481790048
Epoch: 13 | Iteration number: [3440/4518] 76% | Training loss: 0.6871647427768208
Epoch: 13 | Iteration number: [3450/4518] 76% | Training loss: 0.6871670171316119
Epoch: 13 | Iteration number: [3460/4518] 76% | Training loss: 0.6871656276759385
Epoch: 13 | Iteration number: [3470/4518] 76% | Training loss: 0.6871608090847301
Epoch: 13 | Iteration number: [3480/4518] 77% | Training loss: 0.6871613295941518
Epoch: 13 | Iteration number: [3490/4518] 77% | Training loss: 0.6871590886724029
Epoch: 13 | Iteration number: [3500/4518] 77% | Training loss: 0.6871597910778863
Epoch: 13 | Iteration number: [3510/4518] 77% | Training loss: 0.6871558391979956
Epoch: 13 | Iteration number: [3520/4518] 77% | Training loss: 0.6871561293574897
Epoch: 13 | Iteration number: [3530/4518] 78% | Training loss: 0.6871559719863762
Epoch: 13 | Iteration number: [3540/4518] 78% | Training loss: 0.6871564195991235
Epoch: 13 | Iteration number: [3550/4518] 78% | Training loss: 0.6871492151307388
Epoch: 13 | Iteration number: [3560/4518] 78% | Training loss: 0.687149374555336
Epoch: 13 | Iteration number: [3570/4518] 79% | Training loss: 0.6871483028936787
Epoch: 13 | Iteration number: [3580/4518] 79% | Training loss: 0.6871482608371606
Epoch: 13 | Iteration number: [3590/4518] 79% | Training loss: 0.6871464333162335
Epoch: 13 | Iteration number: [3600/4518] 79% | Training loss: 0.687144698103269
Epoch: 13 | Iteration number: [3610/4518] 79% | Training loss: 0.6871440372473645
Epoch: 13 | Iteration number: [3620/4518] 80% | Training loss: 0.6871451073588587
Epoch: 13 | Iteration number: [3630/4518] 80% | Training loss: 0.68714351995589
Epoch: 13 | Iteration number: [3640/4518] 80% | Training loss: 0.6871391605872375
Epoch: 13 | Iteration number: [3650/4518] 80% | Training loss: 0.6871407070388532
Epoch: 13 | Iteration number: [3660/4518] 81% | Training loss: 0.6871421340873333
Epoch: 13 | Iteration number: [3670/4518] 81% | Training loss: 0.6871403595407263
Epoch: 13 | Iteration number: [3680/4518] 81% | Training loss: 0.6871415479351645
Epoch: 13 | Iteration number: [3690/4518] 81% | Training loss: 0.6871387111139168
Epoch: 13 | Iteration number: [3700/4518] 81% | Training loss: 0.6871374464035034
Epoch: 13 | Iteration number: [3710/4518] 82% | Training loss: 0.6871390970087436
Epoch: 13 | Iteration number: [3720/4518] 82% | Training loss: 0.6871384996239857
Epoch: 13 | Iteration number: [3730/4518] 82% | Training loss: 0.6871362257579057
Epoch: 13 | Iteration number: [3740/4518] 82% | Training loss: 0.68713571536031
Epoch: 13 | Iteration number: [3750/4518] 83% | Training loss: 0.687134494638443
Epoch: 13 | Iteration number: [3760/4518] 83% | Training loss: 0.6871356155644072
Epoch: 13 | Iteration number: [3770/4518] 83% | Training loss: 0.6871353282220167
Epoch: 13 | Iteration number: [3780/4518] 83% | Training loss: 0.6871359201335402
Epoch: 13 | Iteration number: [3790/4518] 83% | Training loss: 0.687135329834704
Epoch: 13 | Iteration number: [3800/4518] 84% | Training loss: 0.6871359389863516
Epoch: 13 | Iteration number: [3810/4518] 84% | Training loss: 0.687133523063084
Epoch: 13 | Iteration number: [3820/4518] 84% | Training loss: 0.6871351971364146
Epoch: 13 | Iteration number: [3830/4518] 84% | Training loss: 0.6871375626278919
Epoch: 13 | Iteration number: [3840/4518] 84% | Training loss: 0.6871368771263708
Epoch: 13 | Iteration number: [3850/4518] 85% | Training loss: 0.6871356835458186
Epoch: 13 | Iteration number: [3860/4518] 85% | Training loss: 0.6871339859431271
Epoch: 13 | Iteration number: [3870/4518] 85% | Training loss: 0.6871308859774616
Epoch: 13 | Iteration number: [3880/4518] 85% | Training loss: 0.6871287312704263
Epoch: 13 | Iteration number: [3890/4518] 86% | Training loss: 0.6871276210696654
Epoch: 13 | Iteration number: [3900/4518] 86% | Training loss: 0.6871271218703343
Epoch: 13 | Iteration number: [3910/4518] 86% | Training loss: 0.6871295133667529
Epoch: 13 | Iteration number: [3920/4518] 86% | Training loss: 0.6871269425111157
Epoch: 13 | Iteration number: [3930/4518] 86% | Training loss: 0.6871249560181422
Epoch: 13 | Iteration number: [3940/4518] 87% | Training loss: 0.6871221776994957
Epoch: 13 | Iteration number: [3950/4518] 87% | Training loss: 0.6871207842193072
Epoch: 13 | Iteration number: [3960/4518] 87% | Training loss: 0.6871198810712256
Epoch: 13 | Iteration number: [3970/4518] 87% | Training loss: 0.6871158152443335
Epoch: 13 | Iteration number: [3980/4518] 88% | Training loss: 0.6871154006551857
Epoch: 13 | Iteration number: [3990/4518] 88% | Training loss: 0.6871183183408321
Epoch: 13 | Iteration number: [4000/4518] 88% | Training loss: 0.6871178778260947
Epoch: 13 | Iteration number: [4010/4518] 88% | Training loss: 0.6871205500831034
Epoch: 13 | Iteration number: [4020/4518] 88% | Training loss: 0.6871216459950404
Epoch: 13 | Iteration number: [4030/4518] 89% | Training loss: 0.6871207471373063
Epoch: 13 | Iteration number: [4040/4518] 89% | Training loss: 0.6871182736783925
Epoch: 13 | Iteration number: [4050/4518] 89% | Training loss: 0.6871182766667119
Epoch: 13 | Iteration number: [4060/4518] 89% | Training loss: 0.687117074819034
Epoch: 13 | Iteration number: [4070/4518] 90% | Training loss: 0.6871166403082724
Epoch: 13 | Iteration number: [4080/4518] 90% | Training loss: 0.6871138554431644
Epoch: 13 | Iteration number: [4090/4518] 90% | Training loss: 0.6871124825296892
Epoch: 13 | Iteration number: [4100/4518] 90% | Training loss: 0.6871137679059331
Epoch: 13 | Iteration number: [4110/4518] 90% | Training loss: 0.6871126699041566
Epoch: 13 | Iteration number: [4120/4518] 91% | Training loss: 0.6871089686323139
Epoch: 13 | Iteration number: [4130/4518] 91% | Training loss: 0.6871083821136207
Epoch: 13 | Iteration number: [4140/4518] 91% | Training loss: 0.6871084567717308
Epoch: 13 | Iteration number: [4150/4518] 91% | Training loss: 0.6871066882955023
Epoch: 13 | Iteration number: [4160/4518] 92% | Training loss: 0.68710933012458
Epoch: 13 | Iteration number: [4170/4518] 92% | Training loss: 0.6871072926824328
Epoch: 13 | Iteration number: [4180/4518] 92% | Training loss: 0.6871102126734109
Epoch: 13 | Iteration number: [4190/4518] 92% | Training loss: 0.6871111742920978
Epoch: 13 | Iteration number: [4200/4518] 92% | Training loss: 0.6871123847081547
Epoch: 13 | Iteration number: [4210/4518] 93% | Training loss: 0.6871108612085465
Epoch: 13 | Iteration number: [4220/4518] 93% | Training loss: 0.6871107554124994
Epoch: 13 | Iteration number: [4230/4518] 93% | Training loss: 0.6871102274309658
Epoch: 13 | Iteration number: [4240/4518] 93% | Training loss: 0.6871104498797993
Epoch: 13 | Iteration number: [4250/4518] 94% | Training loss: 0.687109220420613
Epoch: 13 | Iteration number: [4260/4518] 94% | Training loss: 0.6871104655411322
Epoch: 13 | Iteration number: [4270/4518] 94% | Training loss: 0.687109644979727
Epoch: 13 | Iteration number: [4280/4518] 94% | Training loss: 0.6871066392164364
Epoch: 13 | Iteration number: [4290/4518] 94% | Training loss: 0.6871051652031345
Epoch: 13 | Iteration number: [4300/4518] 95% | Training loss: 0.6871033921214037
Epoch: 13 | Iteration number: [4310/4518] 95% | Training loss: 0.6871018340167203
Epoch: 13 | Iteration number: [4320/4518] 95% | Training loss: 0.6871001305265559
Epoch: 13 | Iteration number: [4330/4518] 95% | Training loss: 0.6870971857950814
Epoch: 13 | Iteration number: [4340/4518] 96% | Training loss: 0.6870955923460595
Epoch: 13 | Iteration number: [4350/4518] 96% | Training loss: 0.6870950010042081
Epoch: 13 | Iteration number: [4360/4518] 96% | Training loss: 0.687095877637557
Epoch: 13 | Iteration number: [4370/4518] 96% | Training loss: 0.6870940887136917
Epoch: 13 | Iteration number: [4380/4518] 96% | Training loss: 0.687095093141952
Epoch: 13 | Iteration number: [4390/4518] 97% | Training loss: 0.6870966600665742
Epoch: 13 | Iteration number: [4400/4518] 97% | Training loss: 0.6870958369699391
Epoch: 13 | Iteration number: [4410/4518] 97% | Training loss: 0.687099191945156
Epoch: 13 | Iteration number: [4420/4518] 97% | Training loss: 0.6871007700311652
Epoch: 13 | Iteration number: [4430/4518] 98% | Training loss: 0.6871018259304641
Epoch: 13 | Iteration number: [4440/4518] 98% | Training loss: 0.6871037005438461
Epoch: 13 | Iteration number: [4450/4518] 98% | Training loss: 0.6871034855253241
Epoch: 13 | Iteration number: [4460/4518] 98% | Training loss: 0.6871013670625173
Epoch: 13 | Iteration number: [4470/4518] 98% | Training loss: 0.6871026372082815
Epoch: 13 | Iteration number: [4480/4518] 99% | Training loss: 0.6871036916439023
Epoch: 13 | Iteration number: [4490/4518] 99% | Training loss: 0.6871066478020895
Epoch: 13 | Iteration number: [4500/4518] 99% | Training loss: 0.6871090976662106
Epoch: 13 | Iteration number: [4510/4518] 99% | Training loss: 0.6871097605006393

 End of epoch: 13 | Train Loss: 0.6869559355835411 | Training Time: 640 

 End of epoch: 13 | Eval Loss: 0.6902701392465708 | Evaluating Time: 17 
Epoch: 14 | Iteration number: [10/4518] 0% | Training loss: 0.7554958760738373
Epoch: 14 | Iteration number: [20/4518] 0% | Training loss: 0.7204743653535843
Epoch: 14 | Iteration number: [30/4518] 0% | Training loss: 0.7091962039470673
Epoch: 14 | Iteration number: [40/4518] 0% | Training loss: 0.703603520989418
Epoch: 14 | Iteration number: [50/4518] 1% | Training loss: 0.7002731370925903
Epoch: 14 | Iteration number: [60/4518] 1% | Training loss: 0.6981921295324961
Epoch: 14 | Iteration number: [70/4518] 1% | Training loss: 0.6966268599033356
Epoch: 14 | Iteration number: [80/4518] 1% | Training loss: 0.695341094583273
Epoch: 14 | Iteration number: [90/4518] 1% | Training loss: 0.6942697551515368
Epoch: 14 | Iteration number: [100/4518] 2% | Training loss: 0.6935112792253494
Epoch: 14 | Iteration number: [110/4518] 2% | Training loss: 0.6929065644741058
Epoch: 14 | Iteration number: [120/4518] 2% | Training loss: 0.6923469851414362
Epoch: 14 | Iteration number: [130/4518] 2% | Training loss: 0.6918088729564961
Epoch: 14 | Iteration number: [140/4518] 3% | Training loss: 0.6914720688547407
Epoch: 14 | Iteration number: [150/4518] 3% | Training loss: 0.691192897160848
Epoch: 14 | Iteration number: [160/4518] 3% | Training loss: 0.6909589555114508
Epoch: 14 | Iteration number: [170/4518] 3% | Training loss: 0.690668764184503
Epoch: 14 | Iteration number: [180/4518] 3% | Training loss: 0.6904936754041248
Epoch: 14 | Iteration number: [190/4518] 4% | Training loss: 0.6901885365184984
Epoch: 14 | Iteration number: [200/4518] 4% | Training loss: 0.6900955170392991
Epoch: 14 | Iteration number: [210/4518] 4% | Training loss: 0.689913051752817
Epoch: 14 | Iteration number: [220/4518] 4% | Training loss: 0.6897801924835552
Epoch: 14 | Iteration number: [230/4518] 5% | Training loss: 0.6896331089994182
Epoch: 14 | Iteration number: [240/4518] 5% | Training loss: 0.6895841387410958
Epoch: 14 | Iteration number: [250/4518] 5% | Training loss: 0.6894813952445984
Epoch: 14 | Iteration number: [260/4518] 5% | Training loss: 0.6894056719083053
Epoch: 14 | Iteration number: [270/4518] 5% | Training loss: 0.6892756089016243
Epoch: 14 | Iteration number: [280/4518] 6% | Training loss: 0.6891746663621494
Epoch: 14 | Iteration number: [290/4518] 6% | Training loss: 0.689120990037918
Epoch: 14 | Iteration number: [300/4518] 6% | Training loss: 0.6890707755088806
Epoch: 14 | Iteration number: [310/4518] 6% | Training loss: 0.6890321877694899
Epoch: 14 | Iteration number: [320/4518] 7% | Training loss: 0.6889437915757298
Epoch: 14 | Iteration number: [330/4518] 7% | Training loss: 0.688853851592902
Epoch: 14 | Iteration number: [340/4518] 7% | Training loss: 0.6888142342076582
Epoch: 14 | Iteration number: [350/4518] 7% | Training loss: 0.6887428193432944
Epoch: 14 | Iteration number: [360/4518] 7% | Training loss: 0.6886924819813834
Epoch: 14 | Iteration number: [370/4518] 8% | Training loss: 0.6886254122128358
Epoch: 14 | Iteration number: [380/4518] 8% | Training loss: 0.6885764666293797
Epoch: 14 | Iteration number: [390/4518] 8% | Training loss: 0.6885501947158422
Epoch: 14 | Iteration number: [400/4518] 8% | Training loss: 0.6884987749159336
Epoch: 14 | Iteration number: [410/4518] 9% | Training loss: 0.6884623191705564
Epoch: 14 | Iteration number: [420/4518] 9% | Training loss: 0.6884346199887139
Epoch: 14 | Iteration number: [430/4518] 9% | Training loss: 0.6884280852107114
Epoch: 14 | Iteration number: [440/4518] 9% | Training loss: 0.6883770361542701
Epoch: 14 | Iteration number: [450/4518] 9% | Training loss: 0.688341089354621
Epoch: 14 | Iteration number: [460/4518] 10% | Training loss: 0.6883252049269883
Epoch: 14 | Iteration number: [470/4518] 10% | Training loss: 0.6882918132112381
Epoch: 14 | Iteration number: [480/4518] 10% | Training loss: 0.6882781252264977
Epoch: 14 | Iteration number: [490/4518] 10% | Training loss: 0.6882696212554464
Epoch: 14 | Iteration number: [500/4518] 11% | Training loss: 0.6882582567930221
Epoch: 14 | Iteration number: [510/4518] 11% | Training loss: 0.6882565427060221
Epoch: 14 | Iteration number: [520/4518] 11% | Training loss: 0.6882125476231942
Epoch: 14 | Iteration number: [530/4518] 11% | Training loss: 0.6882058879114547
Epoch: 14 | Iteration number: [540/4518] 11% | Training loss: 0.6881619051650718
Epoch: 14 | Iteration number: [550/4518] 12% | Training loss: 0.6881547085805373
Epoch: 14 | Iteration number: [560/4518] 12% | Training loss: 0.6881149873137474
Epoch: 14 | Iteration number: [570/4518] 12% | Training loss: 0.6880941789401205
Epoch: 14 | Iteration number: [580/4518] 12% | Training loss: 0.6880930703261803
Epoch: 14 | Iteration number: [590/4518] 13% | Training loss: 0.688096880205607
Epoch: 14 | Iteration number: [600/4518] 13% | Training loss: 0.6880846063296
Epoch: 14 | Iteration number: [610/4518] 13% | Training loss: 0.6880858007024546
Epoch: 14 | Iteration number: [620/4518] 13% | Training loss: 0.688072217856684
Epoch: 14 | Iteration number: [630/4518] 13% | Training loss: 0.688058606783549
Epoch: 14 | Iteration number: [640/4518] 14% | Training loss: 0.6880310919135809
Epoch: 14 | Iteration number: [650/4518] 14% | Training loss: 0.6880282438718356
Epoch: 14 | Iteration number: [660/4518] 14% | Training loss: 0.6880049607970498
Epoch: 14 | Iteration number: [670/4518] 14% | Training loss: 0.6879987454236444
Epoch: 14 | Iteration number: [680/4518] 15% | Training loss: 0.6879867686068311
Epoch: 14 | Iteration number: [690/4518] 15% | Training loss: 0.6879707560159158
Epoch: 14 | Iteration number: [700/4518] 15% | Training loss: 0.6879463539804731
Epoch: 14 | Iteration number: [710/4518] 15% | Training loss: 0.6879173226759467
Epoch: 14 | Iteration number: [720/4518] 15% | Training loss: 0.6878908736010393
Epoch: 14 | Iteration number: [730/4518] 16% | Training loss: 0.6878763523820328
Epoch: 14 | Iteration number: [740/4518] 16% | Training loss: 0.687861213812957
Epoch: 14 | Iteration number: [750/4518] 16% | Training loss: 0.6878541272481282
Epoch: 14 | Iteration number: [760/4518] 16% | Training loss: 0.6878384747003254
Epoch: 14 | Iteration number: [770/4518] 17% | Training loss: 0.6878198286155601
Epoch: 14 | Iteration number: [780/4518] 17% | Training loss: 0.6878172480907195
Epoch: 14 | Iteration number: [790/4518] 17% | Training loss: 0.6878078719483146
Epoch: 14 | Iteration number: [800/4518] 17% | Training loss: 0.6878026461601258
Epoch: 14 | Iteration number: [810/4518] 17% | Training loss: 0.6877911191663625
Epoch: 14 | Iteration number: [820/4518] 18% | Training loss: 0.6877786770099547
Epoch: 14 | Iteration number: [830/4518] 18% | Training loss: 0.687775197517441
Epoch: 14 | Iteration number: [840/4518] 18% | Training loss: 0.6877724976766677
Epoch: 14 | Iteration number: [850/4518] 18% | Training loss: 0.6877645552158356
Epoch: 14 | Iteration number: [860/4518] 19% | Training loss: 0.6877446977898132
Epoch: 14 | Iteration number: [870/4518] 19% | Training loss: 0.6877354137513829
Epoch: 14 | Iteration number: [880/4518] 19% | Training loss: 0.6877216498960148
Epoch: 14 | Iteration number: [890/4518] 19% | Training loss: 0.6876961917689677
Epoch: 14 | Iteration number: [900/4518] 19% | Training loss: 0.6876783900790744
Epoch: 14 | Iteration number: [910/4518] 20% | Training loss: 0.6876700617454864
Epoch: 14 | Iteration number: [920/4518] 20% | Training loss: 0.6876644271223441
Epoch: 14 | Iteration number: [930/4518] 20% | Training loss: 0.6876611568594492
Epoch: 14 | Iteration number: [940/4518] 20% | Training loss: 0.6876491795829002
Epoch: 14 | Iteration number: [950/4518] 21% | Training loss: 0.6876431240533527
Epoch: 14 | Iteration number: [960/4518] 21% | Training loss: 0.6876341773197054
Epoch: 14 | Iteration number: [970/4518] 21% | Training loss: 0.6876166354749621
Epoch: 14 | Iteration number: [980/4518] 21% | Training loss: 0.6876175727771253
Epoch: 14 | Iteration number: [990/4518] 21% | Training loss: 0.6876189076539242
Epoch: 14 | Iteration number: [1000/4518] 22% | Training loss: 0.6876101988554001
Epoch: 14 | Iteration number: [1010/4518] 22% | Training loss: 0.6876092826375867
Epoch: 14 | Iteration number: [1020/4518] 22% | Training loss: 0.6876011738590165
Epoch: 14 | Iteration number: [1030/4518] 22% | Training loss: 0.687597475989351
Epoch: 14 | Iteration number: [1040/4518] 23% | Training loss: 0.6875960123653595
Epoch: 14 | Iteration number: [1050/4518] 23% | Training loss: 0.6875806420189994
Epoch: 14 | Iteration number: [1060/4518] 23% | Training loss: 0.6875701741789871
Epoch: 14 | Iteration number: [1070/4518] 23% | Training loss: 0.6875639258701111
Epoch: 14 | Iteration number: [1080/4518] 23% | Training loss: 0.687557182709376
Epoch: 14 | Iteration number: [1090/4518] 24% | Training loss: 0.6875494612466305
Epoch: 14 | Iteration number: [1100/4518] 24% | Training loss: 0.6875491403449665
Epoch: 14 | Iteration number: [1110/4518] 24% | Training loss: 0.6875342005544954
Epoch: 14 | Iteration number: [1120/4518] 24% | Training loss: 0.6875387362071446
Epoch: 14 | Iteration number: [1130/4518] 25% | Training loss: 0.6875304965846306
Epoch: 14 | Iteration number: [1140/4518] 25% | Training loss: 0.6875423956335637
Epoch: 14 | Iteration number: [1150/4518] 25% | Training loss: 0.6875402220435765
Epoch: 14 | Iteration number: [1160/4518] 25% | Training loss: 0.687528567221658
Epoch: 14 | Iteration number: [1170/4518] 25% | Training loss: 0.6875127609468933
Epoch: 14 | Iteration number: [1180/4518] 26% | Training loss: 0.6875026452339301
Epoch: 14 | Iteration number: [1190/4518] 26% | Training loss: 0.6875042707479301
Epoch: 14 | Iteration number: [1200/4518] 26% | Training loss: 0.6875059000651041
Epoch: 14 | Iteration number: [1210/4518] 26% | Training loss: 0.6874968399686262
Epoch: 14 | Iteration number: [1220/4518] 27% | Training loss: 0.6874999307706707
Epoch: 14 | Iteration number: [1230/4518] 27% | Training loss: 0.6874909733853689
Epoch: 14 | Iteration number: [1240/4518] 27% | Training loss: 0.6874826494243838
Epoch: 14 | Iteration number: [1250/4518] 27% | Training loss: 0.6874671551227569
Epoch: 14 | Iteration number: [1260/4518] 27% | Training loss: 0.6874627984705426
Epoch: 14 | Iteration number: [1270/4518] 28% | Training loss: 0.687456627483443
Epoch: 14 | Iteration number: [1280/4518] 28% | Training loss: 0.6874592168722302
Epoch: 14 | Iteration number: [1290/4518] 28% | Training loss: 0.6874525629734808
Epoch: 14 | Iteration number: [1300/4518] 28% | Training loss: 0.6874469105096964
Epoch: 14 | Iteration number: [1310/4518] 28% | Training loss: 0.687439875793821
Epoch: 14 | Iteration number: [1320/4518] 29% | Training loss: 0.6874379419016116
Epoch: 14 | Iteration number: [1330/4518] 29% | Training loss: 0.6874287720461537
Epoch: 14 | Iteration number: [1340/4518] 29% | Training loss: 0.6874297141139187
Epoch: 14 | Iteration number: [1350/4518] 29% | Training loss: 0.687426267420804
Epoch: 14 | Iteration number: [1360/4518] 30% | Training loss: 0.6874173275249846
Epoch: 14 | Iteration number: [1370/4518] 30% | Training loss: 0.6874202084802363
Epoch: 14 | Iteration number: [1380/4518] 30% | Training loss: 0.687425819384879
Epoch: 14 | Iteration number: [1390/4518] 30% | Training loss: 0.6874235771971641
Epoch: 14 | Iteration number: [1400/4518] 30% | Training loss: 0.6874154465113367
Epoch: 14 | Iteration number: [1410/4518] 31% | Training loss: 0.6874077779604189
Epoch: 14 | Iteration number: [1420/4518] 31% | Training loss: 0.6874161104081382
Epoch: 14 | Iteration number: [1430/4518] 31% | Training loss: 0.6874125323512338
Epoch: 14 | Iteration number: [1440/4518] 31% | Training loss: 0.6874199435528782
Epoch: 14 | Iteration number: [1450/4518] 32% | Training loss: 0.6874155584697066
Epoch: 14 | Iteration number: [1460/4518] 32% | Training loss: 0.6874063469775735
Epoch: 14 | Iteration number: [1470/4518] 32% | Training loss: 0.687397632225841
Epoch: 14 | Iteration number: [1480/4518] 32% | Training loss: 0.6873974875018404
Epoch: 14 | Iteration number: [1490/4518] 32% | Training loss: 0.6873998690371546
Epoch: 14 | Iteration number: [1500/4518] 33% | Training loss: 0.687401815533638
Epoch: 14 | Iteration number: [1510/4518] 33% | Training loss: 0.6874004546380201
Epoch: 14 | Iteration number: [1520/4518] 33% | Training loss: 0.6874022214036238
Epoch: 14 | Iteration number: [1530/4518] 33% | Training loss: 0.6873915095344868
Epoch: 14 | Iteration number: [1540/4518] 34% | Training loss: 0.6873905147824969
Epoch: 14 | Iteration number: [1550/4518] 34% | Training loss: 0.6873731074794647
Epoch: 14 | Iteration number: [1560/4518] 34% | Training loss: 0.6873732710878054
Epoch: 14 | Iteration number: [1570/4518] 34% | Training loss: 0.6873738853794754
Epoch: 14 | Iteration number: [1580/4518] 34% | Training loss: 0.687369120762318
Epoch: 14 | Iteration number: [1590/4518] 35% | Training loss: 0.6873622651370066
Epoch: 14 | Iteration number: [1600/4518] 35% | Training loss: 0.6873569898679852
Epoch: 14 | Iteration number: [1610/4518] 35% | Training loss: 0.6873533618005907
Epoch: 14 | Iteration number: [1620/4518] 35% | Training loss: 0.6873488100590529
Epoch: 14 | Iteration number: [1630/4518] 36% | Training loss: 0.687353123550766
Epoch: 14 | Iteration number: [1640/4518] 36% | Training loss: 0.6873490082054603
Epoch: 14 | Iteration number: [1650/4518] 36% | Training loss: 0.6873467413584391
Epoch: 14 | Iteration number: [1660/4518] 36% | Training loss: 0.6873415813388595
Epoch: 14 | Iteration number: [1670/4518] 36% | Training loss: 0.6873373144757962
Epoch: 14 | Iteration number: [1680/4518] 37% | Training loss: 0.687332661591825
Epoch: 14 | Iteration number: [1690/4518] 37% | Training loss: 0.6873288544324728
Epoch: 14 | Iteration number: [1700/4518] 37% | Training loss: 0.6873278876262553
Epoch: 14 | Iteration number: [1710/4518] 37% | Training loss: 0.6873199220289263
Epoch: 14 | Iteration number: [1720/4518] 38% | Training loss: 0.6873162920045298
Epoch: 14 | Iteration number: [1730/4518] 38% | Training loss: 0.6873071271215561
Epoch: 14 | Iteration number: [1740/4518] 38% | Training loss: 0.6873082803241137
Epoch: 14 | Iteration number: [1750/4518] 38% | Training loss: 0.687309545653207
Epoch: 14 | Iteration number: [1760/4518] 38% | Training loss: 0.6873026535592296
Epoch: 14 | Iteration number: [1770/4518] 39% | Training loss: 0.6873073565757881
Epoch: 14 | Iteration number: [1780/4518] 39% | Training loss: 0.6873015317019452
Epoch: 14 | Iteration number: [1790/4518] 39% | Training loss: 0.6872971056892885
Epoch: 14 | Iteration number: [1800/4518] 39% | Training loss: 0.6873011358579
Epoch: 14 | Iteration number: [1810/4518] 40% | Training loss: 0.687297023857496
Epoch: 14 | Iteration number: [1820/4518] 40% | Training loss: 0.6872985487783349
Epoch: 14 | Iteration number: [1830/4518] 40% | Training loss: 0.6872984775428563
Epoch: 14 | Iteration number: [1840/4518] 40% | Training loss: 0.6872974237670069
Epoch: 14 | Iteration number: [1850/4518] 40% | Training loss: 0.6873031014042932
Epoch: 14 | Iteration number: [1860/4518] 41% | Training loss: 0.6873067028419946
Epoch: 14 | Iteration number: [1870/4518] 41% | Training loss: 0.6872968291216356
Epoch: 14 | Iteration number: [1880/4518] 41% | Training loss: 0.6872969410837965
Epoch: 14 | Iteration number: [1890/4518] 41% | Training loss: 0.6873000246822518
Epoch: 14 | Iteration number: [1900/4518] 42% | Training loss: 0.6873029316412775
Epoch: 14 | Iteration number: [1910/4518] 42% | Training loss: 0.6873033824703456
Epoch: 14 | Iteration number: [1920/4518] 42% | Training loss: 0.6873007674391071
Epoch: 14 | Iteration number: [1930/4518] 42% | Training loss: 0.687299153594773
Epoch: 14 | Iteration number: [1940/4518] 42% | Training loss: 0.6872966775574635
Epoch: 14 | Iteration number: [1950/4518] 43% | Training loss: 0.6872953909788376
Epoch: 14 | Iteration number: [1960/4518] 43% | Training loss: 0.6872907184520546
Epoch: 14 | Iteration number: [1970/4518] 43% | Training loss: 0.687289593243962
Epoch: 14 | Iteration number: [1980/4518] 43% | Training loss: 0.6872813875627036
Epoch: 14 | Iteration number: [1990/4518] 44% | Training loss: 0.6872834807065265
Epoch: 14 | Iteration number: [2000/4518] 44% | Training loss: 0.6872797926962375
Epoch: 14 | Iteration number: [2010/4518] 44% | Training loss: 0.6872814647890442
Epoch: 14 | Iteration number: [2020/4518] 44% | Training loss: 0.6872819345481325
Epoch: 14 | Iteration number: [2030/4518] 44% | Training loss: 0.6872855996557057
Epoch: 14 | Iteration number: [2040/4518] 45% | Training loss: 0.6872740507125854
Epoch: 14 | Iteration number: [2050/4518] 45% | Training loss: 0.6872779740356817
Epoch: 14 | Iteration number: [2060/4518] 45% | Training loss: 0.687275599681058
Epoch: 14 | Iteration number: [2070/4518] 45% | Training loss: 0.6872682967335706
Epoch: 14 | Iteration number: [2080/4518] 46% | Training loss: 0.6872664344998506
Epoch: 14 | Iteration number: [2090/4518] 46% | Training loss: 0.6872644256461751
Epoch: 14 | Iteration number: [2100/4518] 46% | Training loss: 0.6872657028834025
Epoch: 14 | Iteration number: [2110/4518] 46% | Training loss: 0.6872679077336008
Epoch: 14 | Iteration number: [2120/4518] 46% | Training loss: 0.6872691637221372
Epoch: 14 | Iteration number: [2130/4518] 47% | Training loss: 0.6872691622642284
Epoch: 14 | Iteration number: [2140/4518] 47% | Training loss: 0.6872672199367362
Epoch: 14 | Iteration number: [2150/4518] 47% | Training loss: 0.6872625910681347
Epoch: 14 | Iteration number: [2160/4518] 47% | Training loss: 0.6872681100059439
Epoch: 14 | Iteration number: [2170/4518] 48% | Training loss: 0.6872737271719814
Epoch: 14 | Iteration number: [2180/4518] 48% | Training loss: 0.6872760565455901
Epoch: 14 | Iteration number: [2190/4518] 48% | Training loss: 0.6872750437967309
Epoch: 14 | Iteration number: [2200/4518] 48% | Training loss: 0.6872748914361
Epoch: 14 | Iteration number: [2210/4518] 48% | Training loss: 0.687275739762578
Epoch: 14 | Iteration number: [2220/4518] 49% | Training loss: 0.6872713325259922
Epoch: 14 | Iteration number: [2230/4518] 49% | Training loss: 0.68726974950243
Epoch: 14 | Iteration number: [2240/4518] 49% | Training loss: 0.6872655451031667
Epoch: 14 | Iteration number: [2250/4518] 49% | Training loss: 0.6872623902161916
Epoch: 14 | Iteration number: [2260/4518] 50% | Training loss: 0.6872634733408953
Epoch: 14 | Iteration number: [2270/4518] 50% | Training loss: 0.6872607383696518
Epoch: 14 | Iteration number: [2280/4518] 50% | Training loss: 0.6872586181550695
Epoch: 14 | Iteration number: [2290/4518] 50% | Training loss: 0.6872607048942533
Epoch: 14 | Iteration number: [2300/4518] 50% | Training loss: 0.6872610683285671
Epoch: 14 | Iteration number: [2310/4518] 51% | Training loss: 0.6872654991232472
Epoch: 14 | Iteration number: [2320/4518] 51% | Training loss: 0.6872641342981108
Epoch: 14 | Iteration number: [2330/4518] 51% | Training loss: 0.6872563669354107
Epoch: 14 | Iteration number: [2340/4518] 51% | Training loss: 0.6872583262686036
Epoch: 14 | Iteration number: [2350/4518] 52% | Training loss: 0.6872588416870604
Epoch: 14 | Iteration number: [2360/4518] 52% | Training loss: 0.6872594983143322
Epoch: 14 | Iteration number: [2370/4518] 52% | Training loss: 0.687259884801092
Epoch: 14 | Iteration number: [2380/4518] 52% | Training loss: 0.6872581416819276
Epoch: 14 | Iteration number: [2390/4518] 52% | Training loss: 0.6872555289557788
Epoch: 14 | Iteration number: [2400/4518] 53% | Training loss: 0.6872511204332113
Epoch: 14 | Iteration number: [2410/4518] 53% | Training loss: 0.6872553161318371
Epoch: 14 | Iteration number: [2420/4518] 53% | Training loss: 0.6872578817704492
Epoch: 14 | Iteration number: [2430/4518] 53% | Training loss: 0.6872552331828287
Epoch: 14 | Iteration number: [2440/4518] 54% | Training loss: 0.687258324124774
Epoch: 14 | Iteration number: [2450/4518] 54% | Training loss: 0.687252308908774
Epoch: 14 | Iteration number: [2460/4518] 54% | Training loss: 0.6872529119495454
Epoch: 14 | Iteration number: [2470/4518] 54% | Training loss: 0.6872533043386483
Epoch: 14 | Iteration number: [2480/4518] 54% | Training loss: 0.6872552489080737
Epoch: 14 | Iteration number: [2490/4518] 55% | Training loss: 0.6872517267144828
Epoch: 14 | Iteration number: [2500/4518] 55% | Training loss: 0.6872517128229141
Epoch: 14 | Iteration number: [2510/4518] 55% | Training loss: 0.6872516666750509
Epoch: 14 | Iteration number: [2520/4518] 55% | Training loss: 0.687252220085689
Epoch: 14 | Iteration number: [2530/4518] 55% | Training loss: 0.6872543172638407
Epoch: 14 | Iteration number: [2540/4518] 56% | Training loss: 0.6872625693561524
Epoch: 14 | Iteration number: [2550/4518] 56% | Training loss: 0.6872664418407515
Epoch: 14 | Iteration number: [2560/4518] 56% | Training loss: 0.6872689730254933
Epoch: 14 | Iteration number: [2570/4518] 56% | Training loss: 0.6872690000422734
Epoch: 14 | Iteration number: [2580/4518] 57% | Training loss: 0.6872679169325866
Epoch: 14 | Iteration number: [2590/4518] 57% | Training loss: 0.6872659555733434
Epoch: 14 | Iteration number: [2600/4518] 57% | Training loss: 0.6872597788618161
Epoch: 14 | Iteration number: [2610/4518] 57% | Training loss: 0.6872535975043345
Epoch: 14 | Iteration number: [2620/4518] 57% | Training loss: 0.6872514094105203
Epoch: 14 | Iteration number: [2630/4518] 58% | Training loss: 0.687252100157647
Epoch: 14 | Iteration number: [2640/4518] 58% | Training loss: 0.6872533375566656
Epoch: 14 | Iteration number: [2650/4518] 58% | Training loss: 0.6872515065490075
Epoch: 14 | Iteration number: [2660/4518] 58% | Training loss: 0.6872548077339516
Epoch: 14 | Iteration number: [2670/4518] 59% | Training loss: 0.6872565197810698
Epoch: 14 | Iteration number: [2680/4518] 59% | Training loss: 0.6872582090212338
Epoch: 14 | Iteration number: [2690/4518] 59% | Training loss: 0.6872593832281886
Epoch: 14 | Iteration number: [2700/4518] 59% | Training loss: 0.6872551498368934
Epoch: 14 | Iteration number: [2710/4518] 59% | Training loss: 0.6872485619629441
Epoch: 14 | Iteration number: [2720/4518] 60% | Training loss: 0.6872465078664176
Epoch: 14 | Iteration number: [2730/4518] 60% | Training loss: 0.6872453290464241
Epoch: 14 | Iteration number: [2740/4518] 60% | Training loss: 0.6872484828216316
Epoch: 14 | Iteration number: [2750/4518] 60% | Training loss: 0.6872476951425726
Epoch: 14 | Iteration number: [2760/4518] 61% | Training loss: 0.6872460229025371
Epoch: 14 | Iteration number: [2770/4518] 61% | Training loss: 0.6872432781470812
Epoch: 14 | Iteration number: [2780/4518] 61% | Training loss: 0.687245765071121
Epoch: 14 | Iteration number: [2790/4518] 61% | Training loss: 0.6872409512065217
Epoch: 14 | Iteration number: [2800/4518] 61% | Training loss: 0.6872433912966932
Epoch: 14 | Iteration number: [2810/4518] 62% | Training loss: 0.6872455610923496
Epoch: 14 | Iteration number: [2820/4518] 62% | Training loss: 0.6872449177165404
Epoch: 14 | Iteration number: [2830/4518] 62% | Training loss: 0.6872437205205115
Epoch: 14 | Iteration number: [2840/4518] 62% | Training loss: 0.6872459850260909
Epoch: 14 | Iteration number: [2850/4518] 63% | Training loss: 0.6872392261655708
Epoch: 14 | Iteration number: [2860/4518] 63% | Training loss: 0.6872396979923848
Epoch: 14 | Iteration number: [2870/4518] 63% | Training loss: 0.6872323655292963
Epoch: 14 | Iteration number: [2880/4518] 63% | Training loss: 0.687235596920881
Epoch: 14 | Iteration number: [2890/4518] 63% | Training loss: 0.6872320739043213
Epoch: 14 | Iteration number: [2900/4518] 64% | Training loss: 0.6872324555495689
Epoch: 14 | Iteration number: [2910/4518] 64% | Training loss: 0.6872298443030656
Epoch: 14 | Iteration number: [2920/4518] 64% | Training loss: 0.6872276572536116
Epoch: 14 | Iteration number: [2930/4518] 64% | Training loss: 0.687225740110508
Epoch: 14 | Iteration number: [2940/4518] 65% | Training loss: 0.6872246539511648
Epoch: 14 | Iteration number: [2950/4518] 65% | Training loss: 0.6872238068863497
Epoch: 14 | Iteration number: [2960/4518] 65% | Training loss: 0.6872244629102784
Epoch: 14 | Iteration number: [2970/4518] 65% | Training loss: 0.6872206730674012
Epoch: 14 | Iteration number: [2980/4518] 65% | Training loss: 0.6872180215064311
Epoch: 14 | Iteration number: [2990/4518] 66% | Training loss: 0.6872182807396088
Epoch: 14 | Iteration number: [3000/4518] 66% | Training loss: 0.6872173610726993
Epoch: 14 | Iteration number: [3010/4518] 66% | Training loss: 0.6872152593642771
Epoch: 14 | Iteration number: [3020/4518] 66% | Training loss: 0.6872166398739973
Epoch: 14 | Iteration number: [3030/4518] 67% | Training loss: 0.6872190395794292
Epoch: 14 | Iteration number: [3040/4518] 67% | Training loss: 0.6872170225766144
Epoch: 14 | Iteration number: [3050/4518] 67% | Training loss: 0.6872145245700586
Epoch: 14 | Iteration number: [3060/4518] 67% | Training loss: 0.6872160681127722
Epoch: 14 | Iteration number: [3070/4518] 67% | Training loss: 0.6872156013883286
Epoch: 14 | Iteration number: [3080/4518] 68% | Training loss: 0.6872156440824657
Epoch: 14 | Iteration number: [3090/4518] 68% | Training loss: 0.6872105051398663
Epoch: 14 | Iteration number: [3100/4518] 68% | Training loss: 0.6872115581458614
Epoch: 14 | Iteration number: [3110/4518] 68% | Training loss: 0.6872108716481752
Epoch: 14 | Iteration number: [3120/4518] 69% | Training loss: 0.6872070592565415
Epoch: 14 | Iteration number: [3130/4518] 69% | Training loss: 0.6872060940098077
Epoch: 14 | Iteration number: [3140/4518] 69% | Training loss: 0.6872020399114889
Epoch: 14 | Iteration number: [3150/4518] 69% | Training loss: 0.6871993445403992
Epoch: 14 | Iteration number: [3160/4518] 69% | Training loss: 0.6871969029873233
Epoch: 14 | Iteration number: [3170/4518] 70% | Training loss: 0.6871964389781471
Epoch: 14 | Iteration number: [3180/4518] 70% | Training loss: 0.6871943539980823
Epoch: 14 | Iteration number: [3190/4518] 70% | Training loss: 0.6871929793335427
Epoch: 14 | Iteration number: [3200/4518] 70% | Training loss: 0.6871907903626561
Epoch: 14 | Iteration number: [3210/4518] 71% | Training loss: 0.6871890346951945
Epoch: 14 | Iteration number: [3220/4518] 71% | Training loss: 0.687184268254671
Epoch: 14 | Iteration number: [3230/4518] 71% | Training loss: 0.6871881656048837
Epoch: 14 | Iteration number: [3240/4518] 71% | Training loss: 0.6871854271785712
Epoch: 14 | Iteration number: [3250/4518] 71% | Training loss: 0.6871825688252082
Epoch: 14 | Iteration number: [3260/4518] 72% | Training loss: 0.6871789538421513
Epoch: 14 | Iteration number: [3270/4518] 72% | Training loss: 0.687181895789021
Epoch: 14 | Iteration number: [3280/4518] 72% | Training loss: 0.6871815830650853
Epoch: 14 | Iteration number: [3290/4518] 72% | Training loss: 0.6871836247415166
Epoch: 14 | Iteration number: [3300/4518] 73% | Training loss: 0.6871852896069035
Epoch: 14 | Iteration number: [3310/4518] 73% | Training loss: 0.6871815386495561
Epoch: 14 | Iteration number: [3320/4518] 73% | Training loss: 0.6871820743004959
Epoch: 14 | Iteration number: [3330/4518] 73% | Training loss: 0.6871849300446095
Epoch: 14 | Iteration number: [3340/4518] 73% | Training loss: 0.687184718572451
Epoch: 14 | Iteration number: [3350/4518] 74% | Training loss: 0.6871872277224241
Epoch: 14 | Iteration number: [3360/4518] 74% | Training loss: 0.6871868689145361
Epoch: 14 | Iteration number: [3370/4518] 74% | Training loss: 0.687184785027886
Epoch: 14 | Iteration number: [3380/4518] 74% | Training loss: 0.6871817765856636
Epoch: 14 | Iteration number: [3390/4518] 75% | Training loss: 0.6871798784859413
Epoch: 14 | Iteration number: [3400/4518] 75% | Training loss: 0.6871761096926297
Epoch: 14 | Iteration number: [3410/4518] 75% | Training loss: 0.6871757783498232
Epoch: 14 | Iteration number: [3420/4518] 75% | Training loss: 0.6871777915815164
Epoch: 14 | Iteration number: [3430/4518] 75% | Training loss: 0.687174731753658
Epoch: 14 | Iteration number: [3440/4518] 76% | Training loss: 0.6871752862840198
Epoch: 14 | Iteration number: [3450/4518] 76% | Training loss: 0.6871745911888454
Epoch: 14 | Iteration number: [3460/4518] 76% | Training loss: 0.6871766535188422
Epoch: 14 | Iteration number: [3470/4518] 76% | Training loss: 0.6871734474509181
Epoch: 14 | Iteration number: [3480/4518] 77% | Training loss: 0.6871722316262365
Epoch: 14 | Iteration number: [3490/4518] 77% | Training loss: 0.6871720194304228
Epoch: 14 | Iteration number: [3500/4518] 77% | Training loss: 0.687171248112406
Epoch: 14 | Iteration number: [3510/4518] 77% | Training loss: 0.6871676857485051
Epoch: 14 | Iteration number: [3520/4518] 77% | Training loss: 0.6871681238609282
Epoch: 14 | Iteration number: [3530/4518] 78% | Training loss: 0.6871629446153938
Epoch: 14 | Iteration number: [3540/4518] 78% | Training loss: 0.6871614887384372
Epoch: 14 | Iteration number: [3550/4518] 78% | Training loss: 0.6871620398843792
Epoch: 14 | Iteration number: [3560/4518] 78% | Training loss: 0.6871631791919804
Epoch: 14 | Iteration number: [3570/4518] 79% | Training loss: 0.687159638895708
Epoch: 14 | Iteration number: [3580/4518] 79% | Training loss: 0.6871598987272998
Epoch: 14 | Iteration number: [3590/4518] 79% | Training loss: 0.6871632292410126
Epoch: 14 | Iteration number: [3600/4518] 79% | Training loss: 0.6871651326616605
Epoch: 14 | Iteration number: [3610/4518] 79% | Training loss: 0.6871677290534709
Epoch: 14 | Iteration number: [3620/4518] 80% | Training loss: 0.6871646402455167
Epoch: 14 | Iteration number: [3630/4518] 80% | Training loss: 0.6871637774072075
Epoch: 14 | Iteration number: [3640/4518] 80% | Training loss: 0.6871649273476758
Epoch: 14 | Iteration number: [3650/4518] 80% | Training loss: 0.6871607776537333
Epoch: 14 | Iteration number: [3660/4518] 81% | Training loss: 0.6871597651086869
Epoch: 14 | Iteration number: [3670/4518] 81% | Training loss: 0.687160465226836
Epoch: 14 | Iteration number: [3680/4518] 81% | Training loss: 0.6871591338644857
Epoch: 14 | Iteration number: [3690/4518] 81% | Training loss: 0.6871570343086066
Epoch: 14 | Iteration number: [3700/4518] 81% | Training loss: 0.687155124706191
Epoch: 14 | Iteration number: [3710/4518] 82% | Training loss: 0.6871535248351547
Epoch: 14 | Iteration number: [3720/4518] 82% | Training loss: 0.6871516427045228
Epoch: 14 | Iteration number: [3730/4518] 82% | Training loss: 0.6871505286354801
Epoch: 14 | Iteration number: [3740/4518] 82% | Training loss: 0.6871532152202677
Epoch: 14 | Iteration number: [3750/4518] 83% | Training loss: 0.6871526324748993
Epoch: 14 | Iteration number: [3760/4518] 83% | Training loss: 0.6871551658403366
Epoch: 14 | Iteration number: [3770/4518] 83% | Training loss: 0.6871582232830695
Epoch: 14 | Iteration number: [3780/4518] 83% | Training loss: 0.6871564676679631
Epoch: 14 | Iteration number: [3790/4518] 83% | Training loss: 0.6871543911484741
Epoch: 14 | Iteration number: [3800/4518] 84% | Training loss: 0.6871548324509671
Epoch: 14 | Iteration number: [3810/4518] 84% | Training loss: 0.6871556852433313
Epoch: 14 | Iteration number: [3820/4518] 84% | Training loss: 0.687155660768454
Epoch: 14 | Iteration number: [3830/4518] 84% | Training loss: 0.687157108687234
Epoch: 14 | Iteration number: [3840/4518] 84% | Training loss: 0.6871572084259242
Epoch: 14 | Iteration number: [3850/4518] 85% | Training loss: 0.6871568733531159
Epoch: 14 | Iteration number: [3860/4518] 85% | Training loss: 0.6871547441562841
Epoch: 14 | Iteration number: [3870/4518] 85% | Training loss: 0.6871539833625774
Epoch: 14 | Iteration number: [3880/4518] 85% | Training loss: 0.6871524591882204
Epoch: 14 | Iteration number: [3890/4518] 86% | Training loss: 0.6871500850336717
Epoch: 14 | Iteration number: [3900/4518] 86% | Training loss: 0.6871522135000963
Epoch: 14 | Iteration number: [3910/4518] 86% | Training loss: 0.6871541238196975
Epoch: 14 | Iteration number: [3920/4518] 86% | Training loss: 0.6871517208613911
Epoch: 14 | Iteration number: [3930/4518] 86% | Training loss: 0.6871464631939662
Epoch: 14 | Iteration number: [3940/4518] 87% | Training loss: 0.687144442364044
Epoch: 14 | Iteration number: [3950/4518] 87% | Training loss: 0.6871452394014672
Epoch: 14 | Iteration number: [3960/4518] 87% | Training loss: 0.6871441577269574
Epoch: 14 | Iteration number: [3970/4518] 87% | Training loss: 0.6871444661911549
Epoch: 14 | Iteration number: [3980/4518] 88% | Training loss: 0.687142355283301
Epoch: 14 | Iteration number: [3990/4518] 88% | Training loss: 0.6871392149375495
Epoch: 14 | Iteration number: [4000/4518] 88% | Training loss: 0.6871349186450243
Epoch: 14 | Iteration number: [4010/4518] 88% | Training loss: 0.6871360572793537
Epoch: 14 | Iteration number: [4020/4518] 88% | Training loss: 0.6871340362438515
Epoch: 14 | Iteration number: [4030/4518] 89% | Training loss: 0.6871373789482021
Epoch: 14 | Iteration number: [4040/4518] 89% | Training loss: 0.6871366494362897
Epoch: 14 | Iteration number: [4050/4518] 89% | Training loss: 0.6871351753929515
Epoch: 14 | Iteration number: [4060/4518] 89% | Training loss: 0.6871362301663225
Epoch: 14 | Iteration number: [4070/4518] 90% | Training loss: 0.6871363617864229
Epoch: 14 | Iteration number: [4080/4518] 90% | Training loss: 0.6871340741567752
Epoch: 14 | Iteration number: [4090/4518] 90% | Training loss: 0.687130557922396
Epoch: 14 | Iteration number: [4100/4518] 90% | Training loss: 0.6871265013188851
Epoch: 14 | Iteration number: [4110/4518] 90% | Training loss: 0.6871237069150827
Epoch: 14 | Iteration number: [4120/4518] 91% | Training loss: 0.6871214649196967
Epoch: 14 | Iteration number: [4130/4518] 91% | Training loss: 0.6871205980639192
Epoch: 14 | Iteration number: [4140/4518] 91% | Training loss: 0.6871171175425755
Epoch: 14 | Iteration number: [4150/4518] 91% | Training loss: 0.6871151997238757
Epoch: 14 | Iteration number: [4160/4518] 92% | Training loss: 0.6871173254572428
Epoch: 14 | Iteration number: [4170/4518] 92% | Training loss: 0.6871155816588185
Epoch: 14 | Iteration number: [4180/4518] 92% | Training loss: 0.6871183160246844
Epoch: 14 | Iteration number: [4190/4518] 92% | Training loss: 0.6871202025464724
Epoch: 14 | Iteration number: [4200/4518] 92% | Training loss: 0.6871234163641929
Epoch: 14 | Iteration number: [4210/4518] 93% | Training loss: 0.6871215696006376
Epoch: 14 | Iteration number: [4220/4518] 93% | Training loss: 0.6871194513488155
Epoch: 14 | Iteration number: [4230/4518] 93% | Training loss: 0.6871158920563141
Epoch: 14 | Iteration number: [4240/4518] 93% | Training loss: 0.6871170223883862
Epoch: 14 | Iteration number: [4250/4518] 94% | Training loss: 0.6871132186861599
Epoch: 14 | Iteration number: [4260/4518] 94% | Training loss: 0.6871161312284604
Epoch: 14 | Iteration number: [4270/4518] 94% | Training loss: 0.6871143224646951
Epoch: 14 | Iteration number: [4280/4518] 94% | Training loss: 0.6871148595186037
Epoch: 14 | Iteration number: [4290/4518] 94% | Training loss: 0.6871113966672848
Epoch: 14 | Iteration number: [4300/4518] 95% | Training loss: 0.6871144312758778
Epoch: 14 | Iteration number: [4310/4518] 95% | Training loss: 0.6871150316329124
Epoch: 14 | Iteration number: [4320/4518] 95% | Training loss: 0.6871127588881387
Epoch: 14 | Iteration number: [4330/4518] 95% | Training loss: 0.6871107748281597
Epoch: 14 | Iteration number: [4340/4518] 96% | Training loss: 0.6871106105191367
Epoch: 14 | Iteration number: [4350/4518] 96% | Training loss: 0.6871093128604451
Epoch: 14 | Iteration number: [4360/4518] 96% | Training loss: 0.68710698546893
Epoch: 14 | Iteration number: [4370/4518] 96% | Training loss: 0.6871091387773814
Epoch: 14 | Iteration number: [4380/4518] 96% | Training loss: 0.6871080992973014
Epoch: 14 | Iteration number: [4390/4518] 97% | Training loss: 0.6871083549187775
Epoch: 14 | Iteration number: [4400/4518] 97% | Training loss: 0.68711032807827
Epoch: 14 | Iteration number: [4410/4518] 97% | Training loss: 0.6871079247419526
Epoch: 14 | Iteration number: [4420/4518] 97% | Training loss: 0.6871054884535155
Epoch: 14 | Iteration number: [4430/4518] 98% | Training loss: 0.6871044148979015
Epoch: 14 | Iteration number: [4440/4518] 98% | Training loss: 0.6871001903672476
Epoch: 14 | Iteration number: [4450/4518] 98% | Training loss: 0.6871014771702584
Epoch: 14 | Iteration number: [4460/4518] 98% | Training loss: 0.6871005879255688
Epoch: 14 | Iteration number: [4470/4518] 98% | Training loss: 0.6871021198079623
Epoch: 14 | Iteration number: [4480/4518] 99% | Training loss: 0.687102066911757
Epoch: 14 | Iteration number: [4490/4518] 99% | Training loss: 0.6871028391316633
Epoch: 14 | Iteration number: [4500/4518] 99% | Training loss: 0.6871024547815323
Epoch: 14 | Iteration number: [4510/4518] 99% | Training loss: 0.6870975926683641

 End of epoch: 14 | Train Loss: 0.6869478293650443 | Training Time: 643 

 End of epoch: 14 | Eval Loss: 0.6901515089735692 | Evaluating Time: 17 
Epoch: 15 | Iteration number: [10/4518] 0% | Training loss: 0.7548627257347107
Epoch: 15 | Iteration number: [20/4518] 0% | Training loss: 0.721244341135025
Epoch: 15 | Iteration number: [30/4518] 0% | Training loss: 0.7094084362188975
Epoch: 15 | Iteration number: [40/4518] 0% | Training loss: 0.7038056537508964
Epoch: 15 | Iteration number: [50/4518] 1% | Training loss: 0.7004557192325592
Epoch: 15 | Iteration number: [60/4518] 1% | Training loss: 0.6979741305112839
Epoch: 15 | Iteration number: [70/4518] 1% | Training loss: 0.6963075654847282
Epoch: 15 | Iteration number: [80/4518] 1% | Training loss: 0.6951359704136848
Epoch: 15 | Iteration number: [90/4518] 1% | Training loss: 0.6942365454302893
Epoch: 15 | Iteration number: [100/4518] 2% | Training loss: 0.6935010570287704
Epoch: 15 | Iteration number: [110/4518] 2% | Training loss: 0.6929703658277339
Epoch: 15 | Iteration number: [120/4518] 2% | Training loss: 0.6924364055196445
Epoch: 15 | Iteration number: [130/4518] 2% | Training loss: 0.6920658281216254
Epoch: 15 | Iteration number: [140/4518] 3% | Training loss: 0.6916425500597273
Epoch: 15 | Iteration number: [150/4518] 3% | Training loss: 0.6912640845775604
Epoch: 15 | Iteration number: [160/4518] 3% | Training loss: 0.6910847168415785
Epoch: 15 | Iteration number: [170/4518] 3% | Training loss: 0.6908328403444851
Epoch: 15 | Iteration number: [180/4518] 3% | Training loss: 0.690619573990504
Epoch: 15 | Iteration number: [190/4518] 4% | Training loss: 0.6904391075435438
Epoch: 15 | Iteration number: [200/4518] 4% | Training loss: 0.6902334329485893
Epoch: 15 | Iteration number: [210/4518] 4% | Training loss: 0.6900483761514936
Epoch: 15 | Iteration number: [220/4518] 4% | Training loss: 0.6898579456589439
Epoch: 15 | Iteration number: [230/4518] 5% | Training loss: 0.6897508683411971
Epoch: 15 | Iteration number: [240/4518] 5% | Training loss: 0.6896380220850309
Epoch: 15 | Iteration number: [250/4518] 5% | Training loss: 0.6895603971481323
Epoch: 15 | Iteration number: [260/4518] 5% | Training loss: 0.689437987941962
Epoch: 15 | Iteration number: [270/4518] 5% | Training loss: 0.6893227817835631
Epoch: 15 | Iteration number: [280/4518] 6% | Training loss: 0.6892494263393538
Epoch: 15 | Iteration number: [290/4518] 6% | Training loss: 0.6891768800801245
Epoch: 15 | Iteration number: [300/4518] 6% | Training loss: 0.6890920994679133
Epoch: 15 | Iteration number: [310/4518] 6% | Training loss: 0.6889936077979303
Epoch: 15 | Iteration number: [320/4518] 7% | Training loss: 0.6889014914631844
Epoch: 15 | Iteration number: [330/4518] 7% | Training loss: 0.6888566941925973
Epoch: 15 | Iteration number: [340/4518] 7% | Training loss: 0.6887919434729745
Epoch: 15 | Iteration number: [350/4518] 7% | Training loss: 0.6887379109859466
Epoch: 15 | Iteration number: [360/4518] 7% | Training loss: 0.688686795367135
Epoch: 15 | Iteration number: [370/4518] 8% | Training loss: 0.6886470673857509
Epoch: 15 | Iteration number: [380/4518] 8% | Training loss: 0.6886512092853847
Epoch: 15 | Iteration number: [390/4518] 8% | Training loss: 0.6886128074083573
Epoch: 15 | Iteration number: [400/4518] 8% | Training loss: 0.6885611973702908
Epoch: 15 | Iteration number: [410/4518] 9% | Training loss: 0.688534299920245
Epoch: 15 | Iteration number: [420/4518] 9% | Training loss: 0.688504948644411
Epoch: 15 | Iteration number: [430/4518] 9% | Training loss: 0.6884436367556106
Epoch: 15 | Iteration number: [440/4518] 9% | Training loss: 0.6884135296398943
Epoch: 15 | Iteration number: [450/4518] 9% | Training loss: 0.68840459479226
Epoch: 15 | Iteration number: [460/4518] 10% | Training loss: 0.6883417953615604
Epoch: 15 | Iteration number: [470/4518] 10% | Training loss: 0.6882966949584636
Epoch: 15 | Iteration number: [480/4518] 10% | Training loss: 0.6882552274813255
Epoch: 15 | Iteration number: [490/4518] 10% | Training loss: 0.6882404759222147
Epoch: 15 | Iteration number: [500/4518] 11% | Training loss: 0.6882141607999802
Epoch: 15 | Iteration number: [510/4518] 11% | Training loss: 0.6881664678162219
Epoch: 15 | Iteration number: [520/4518] 11% | Training loss: 0.6881583476295838
Epoch: 15 | Iteration number: [530/4518] 11% | Training loss: 0.688133346584608
Epoch: 15 | Iteration number: [540/4518] 11% | Training loss: 0.6881125414813006
Epoch: 15 | Iteration number: [550/4518] 12% | Training loss: 0.6881021142005921
Epoch: 15 | Iteration number: [560/4518] 12% | Training loss: 0.6880802297166415
Epoch: 15 | Iteration number: [570/4518] 12% | Training loss: 0.6880900553443976
Epoch: 15 | Iteration number: [580/4518] 12% | Training loss: 0.6880827416633738
Epoch: 15 | Iteration number: [590/4518] 13% | Training loss: 0.6880428793066639
Epoch: 15 | Iteration number: [600/4518] 13% | Training loss: 0.6880370015899341
Epoch: 15 | Iteration number: [610/4518] 13% | Training loss: 0.6880106625986881
Epoch: 15 | Iteration number: [620/4518] 13% | Training loss: 0.6879665708349597
Epoch: 15 | Iteration number: [630/4518] 13% | Training loss: 0.6879490961158087
Epoch: 15 | Iteration number: [640/4518] 14% | Training loss: 0.6879324554465711
Epoch: 15 | Iteration number: [650/4518] 14% | Training loss: 0.6879156333666582
Epoch: 15 | Iteration number: [660/4518] 14% | Training loss: 0.687911476781874
Epoch: 15 | Iteration number: [670/4518] 14% | Training loss: 0.6878762512064692
Epoch: 15 | Iteration number: [680/4518] 15% | Training loss: 0.6878604353350751
Epoch: 15 | Iteration number: [690/4518] 15% | Training loss: 0.6878396273523137
Epoch: 15 | Iteration number: [700/4518] 15% | Training loss: 0.6878258751119886
Epoch: 15 | Iteration number: [710/4518] 15% | Training loss: 0.6877966601244161
Epoch: 15 | Iteration number: [720/4518] 15% | Training loss: 0.6877792543835111
Epoch: 15 | Iteration number: [730/4518] 16% | Training loss: 0.6877761577090172
Epoch: 15 | Iteration number: [740/4518] 16% | Training loss: 0.687755865019721
Epoch: 15 | Iteration number: [750/4518] 16% | Training loss: 0.687767688035965
Epoch: 15 | Iteration number: [760/4518] 16% | Training loss: 0.687743710687286
Epoch: 15 | Iteration number: [770/4518] 17% | Training loss: 0.6877312660217285
Epoch: 15 | Iteration number: [780/4518] 17% | Training loss: 0.6877283790172675
Epoch: 15 | Iteration number: [790/4518] 17% | Training loss: 0.6877114397815511
Epoch: 15 | Iteration number: [800/4518] 17% | Training loss: 0.687699006125331
Epoch: 15 | Iteration number: [810/4518] 17% | Training loss: 0.6876892429810983
Epoch: 15 | Iteration number: [820/4518] 18% | Training loss: 0.6876760538758301
Epoch: 15 | Iteration number: [830/4518] 18% | Training loss: 0.6876670573849276
Epoch: 15 | Iteration number: [840/4518] 18% | Training loss: 0.6876555691872325
Epoch: 15 | Iteration number: [850/4518] 18% | Training loss: 0.687643465645173
Epoch: 15 | Iteration number: [860/4518] 19% | Training loss: 0.6876333323328994
Epoch: 15 | Iteration number: [870/4518] 19% | Training loss: 0.6876258306804744
Epoch: 15 | Iteration number: [880/4518] 19% | Training loss: 0.6876136669381099
Epoch: 15 | Iteration number: [890/4518] 19% | Training loss: 0.6876174742586157
Epoch: 15 | Iteration number: [900/4518] 19% | Training loss: 0.6876194016800986
Epoch: 15 | Iteration number: [910/4518] 20% | Training loss: 0.6876149613123673
Epoch: 15 | Iteration number: [920/4518] 20% | Training loss: 0.6876168584046156
Epoch: 15 | Iteration number: [930/4518] 20% | Training loss: 0.6876012563705445
Epoch: 15 | Iteration number: [940/4518] 20% | Training loss: 0.687595224000038
Epoch: 15 | Iteration number: [950/4518] 21% | Training loss: 0.6875957654651843
Epoch: 15 | Iteration number: [960/4518] 21% | Training loss: 0.6875932487348716
Epoch: 15 | Iteration number: [970/4518] 21% | Training loss: 0.6875832137987786
Epoch: 15 | Iteration number: [980/4518] 21% | Training loss: 0.6875730108849857
Epoch: 15 | Iteration number: [990/4518] 21% | Training loss: 0.687571707699034
Epoch: 15 | Iteration number: [1000/4518] 22% | Training loss: 0.6875620207190514
Epoch: 15 | Iteration number: [1010/4518] 22% | Training loss: 0.6875529168856026
Epoch: 15 | Iteration number: [1020/4518] 22% | Training loss: 0.6875572555789761
Epoch: 15 | Iteration number: [1030/4518] 22% | Training loss: 0.6875586205894507
Epoch: 15 | Iteration number: [1040/4518] 23% | Training loss: 0.6875599230711277
Epoch: 15 | Iteration number: [1050/4518] 23% | Training loss: 0.6875564811343239
Epoch: 15 | Iteration number: [1060/4518] 23% | Training loss: 0.6875490291500991
Epoch: 15 | Iteration number: [1070/4518] 23% | Training loss: 0.6875452067250404
Epoch: 15 | Iteration number: [1080/4518] 23% | Training loss: 0.6875401618304076
Epoch: 15 | Iteration number: [1090/4518] 24% | Training loss: 0.6875357024713393
Epoch: 15 | Iteration number: [1100/4518] 24% | Training loss: 0.6875362396782094
Epoch: 15 | Iteration number: [1110/4518] 24% | Training loss: 0.6875369478990366
Epoch: 15 | Iteration number: [1120/4518] 24% | Training loss: 0.6875269875462566
Epoch: 15 | Iteration number: [1130/4518] 25% | Training loss: 0.6875299432108888
Epoch: 15 | Iteration number: [1140/4518] 25% | Training loss: 0.6875233700400905
Epoch: 15 | Iteration number: [1150/4518] 25% | Training loss: 0.6875215058741362
Epoch: 15 | Iteration number: [1160/4518] 25% | Training loss: 0.687518054657969
Epoch: 15 | Iteration number: [1170/4518] 25% | Training loss: 0.6875138386192485
Epoch: 15 | Iteration number: [1180/4518] 26% | Training loss: 0.6875140730607308
Epoch: 15 | Iteration number: [1190/4518] 26% | Training loss: 0.6875032734971086
Epoch: 15 | Iteration number: [1200/4518] 26% | Training loss: 0.6874925484259923
Epoch: 15 | Iteration number: [1210/4518] 26% | Training loss: 0.6874948714390274
Epoch: 15 | Iteration number: [1220/4518] 27% | Training loss: 0.6874851440308524
Epoch: 15 | Iteration number: [1230/4518] 27% | Training loss: 0.6874827259439763
Epoch: 15 | Iteration number: [1240/4518] 27% | Training loss: 0.6874730599984046
Epoch: 15 | Iteration number: [1250/4518] 27% | Training loss: 0.6874766032218933
Epoch: 15 | Iteration number: [1260/4518] 27% | Training loss: 0.6874715044384911
Epoch: 15 | Iteration number: [1270/4518] 28% | Training loss: 0.6874570532577244
Epoch: 15 | Iteration number: [1280/4518] 28% | Training loss: 0.6874476669821888
Epoch: 15 | Iteration number: [1290/4518] 28% | Training loss: 0.6874430848646533
Epoch: 15 | Iteration number: [1300/4518] 28% | Training loss: 0.6874494457703371
Epoch: 15 | Iteration number: [1310/4518] 28% | Training loss: 0.6874431115070372
Epoch: 15 | Iteration number: [1320/4518] 29% | Training loss: 0.687439654406273
Epoch: 15 | Iteration number: [1330/4518] 29% | Training loss: 0.6874282240867615
Epoch: 15 | Iteration number: [1340/4518] 29% | Training loss: 0.6874247478460198
Epoch: 15 | Iteration number: [1350/4518] 29% | Training loss: 0.6874175424487502
Epoch: 15 | Iteration number: [1360/4518] 30% | Training loss: 0.6874181716757662
Epoch: 15 | Iteration number: [1370/4518] 30% | Training loss: 0.6874222537461858
Epoch: 15 | Iteration number: [1380/4518] 30% | Training loss: 0.6874240393655887
Epoch: 15 | Iteration number: [1390/4518] 30% | Training loss: 0.687419426827122
Epoch: 15 | Iteration number: [1400/4518] 30% | Training loss: 0.6874143886566162
Epoch: 15 | Iteration number: [1410/4518] 31% | Training loss: 0.6874114828752288
Epoch: 15 | Iteration number: [1420/4518] 31% | Training loss: 0.6874086752743788
Epoch: 15 | Iteration number: [1430/4518] 31% | Training loss: 0.6874027666095254
Epoch: 15 | Iteration number: [1440/4518] 31% | Training loss: 0.6873946417537
Epoch: 15 | Iteration number: [1450/4518] 32% | Training loss: 0.6873865036717777
Epoch: 15 | Iteration number: [1460/4518] 32% | Training loss: 0.6873758110281539
Epoch: 15 | Iteration number: [1470/4518] 32% | Training loss: 0.6873748052282398
Epoch: 15 | Iteration number: [1480/4518] 32% | Training loss: 0.687378293557747
Epoch: 15 | Iteration number: [1490/4518] 32% | Training loss: 0.6873725287466241
Epoch: 15 | Iteration number: [1500/4518] 33% | Training loss: 0.6873626761039098
Epoch: 15 | Iteration number: [1510/4518] 33% | Training loss: 0.687356116519069
Epoch: 15 | Iteration number: [1520/4518] 33% | Training loss: 0.6873627649326074
Epoch: 15 | Iteration number: [1530/4518] 33% | Training loss: 0.6873667803075578
Epoch: 15 | Iteration number: [1540/4518] 34% | Training loss: 0.687365487450129
Epoch: 15 | Iteration number: [1550/4518] 34% | Training loss: 0.6873559173076383
Epoch: 15 | Iteration number: [1560/4518] 34% | Training loss: 0.6873557229836782
Epoch: 15 | Iteration number: [1570/4518] 34% | Training loss: 0.6873559271833699
Epoch: 15 | Iteration number: [1580/4518] 34% | Training loss: 0.68735620549208
Epoch: 15 | Iteration number: [1590/4518] 35% | Training loss: 0.6873496882945487
Epoch: 15 | Iteration number: [1600/4518] 35% | Training loss: 0.6873488073050976
Epoch: 15 | Iteration number: [1610/4518] 35% | Training loss: 0.6873427482495397
Epoch: 15 | Iteration number: [1620/4518] 35% | Training loss: 0.6873409479120631
Epoch: 15 | Iteration number: [1630/4518] 36% | Training loss: 0.68734022733624
Epoch: 15 | Iteration number: [1640/4518] 36% | Training loss: 0.6873342838956089
Epoch: 15 | Iteration number: [1650/4518] 36% | Training loss: 0.6873360517891971
Epoch: 15 | Iteration number: [1660/4518] 36% | Training loss: 0.6873302391135548
Epoch: 15 | Iteration number: [1670/4518] 36% | Training loss: 0.6873276666966741
Epoch: 15 | Iteration number: [1680/4518] 37% | Training loss: 0.6873271926173142
Epoch: 15 | Iteration number: [1690/4518] 37% | Training loss: 0.6873187398064066
Epoch: 15 | Iteration number: [1700/4518] 37% | Training loss: 0.6873133079795276
Epoch: 15 | Iteration number: [1710/4518] 37% | Training loss: 0.6873133355413961
Epoch: 15 | Iteration number: [1720/4518] 38% | Training loss: 0.6873117793784586
Epoch: 15 | Iteration number: [1730/4518] 38% | Training loss: 0.6873105734414447
Epoch: 15 | Iteration number: [1740/4518] 38% | Training loss: 0.6873096132415465
Epoch: 15 | Iteration number: [1750/4518] 38% | Training loss: 0.6873033190454756
Epoch: 15 | Iteration number: [1760/4518] 38% | Training loss: 0.6872903601012447
Epoch: 15 | Iteration number: [1770/4518] 39% | Training loss: 0.6872873241281778
Epoch: 15 | Iteration number: [1780/4518] 39% | Training loss: 0.6872799799683389
Epoch: 15 | Iteration number: [1790/4518] 39% | Training loss: 0.6872765782825108
Epoch: 15 | Iteration number: [1800/4518] 39% | Training loss: 0.6872701321707831
Epoch: 15 | Iteration number: [1810/4518] 40% | Training loss: 0.6872590473343654
Epoch: 15 | Iteration number: [1820/4518] 40% | Training loss: 0.6872562080949217
Epoch: 15 | Iteration number: [1830/4518] 40% | Training loss: 0.68725010023091
Epoch: 15 | Iteration number: [1840/4518] 40% | Training loss: 0.6872439554204112
Epoch: 15 | Iteration number: [1850/4518] 40% | Training loss: 0.6872459856883899
Epoch: 15 | Iteration number: [1860/4518] 41% | Training loss: 0.6872433942812746
Epoch: 15 | Iteration number: [1870/4518] 41% | Training loss: 0.6872373036522279
Epoch: 15 | Iteration number: [1880/4518] 41% | Training loss: 0.687239783304803
Epoch: 15 | Iteration number: [1890/4518] 41% | Training loss: 0.6872387850410724
Epoch: 15 | Iteration number: [1900/4518] 42% | Training loss: 0.6872366107451289
Epoch: 15 | Iteration number: [1910/4518] 42% | Training loss: 0.6872334672830491
Epoch: 15 | Iteration number: [1920/4518] 42% | Training loss: 0.687236102608343
Epoch: 15 | Iteration number: [1930/4518] 42% | Training loss: 0.6872357357351273
Epoch: 15 | Iteration number: [1940/4518] 42% | Training loss: 0.6872337425492473
Epoch: 15 | Iteration number: [1950/4518] 43% | Training loss: 0.6872339494717427
Epoch: 15 | Iteration number: [1960/4518] 43% | Training loss: 0.6872327141615809
Epoch: 15 | Iteration number: [1970/4518] 43% | Training loss: 0.6872308661489922
Epoch: 15 | Iteration number: [1980/4518] 43% | Training loss: 0.6872292145033075
Epoch: 15 | Iteration number: [1990/4518] 44% | Training loss: 0.6872309531398754
Epoch: 15 | Iteration number: [2000/4518] 44% | Training loss: 0.687230477064848
Epoch: 15 | Iteration number: [2010/4518] 44% | Training loss: 0.6872332269872599
Epoch: 15 | Iteration number: [2020/4518] 44% | Training loss: 0.6872360634331656
Epoch: 15 | Iteration number: [2030/4518] 44% | Training loss: 0.6872316569236699
Epoch: 15 | Iteration number: [2040/4518] 45% | Training loss: 0.6872252140559402
Epoch: 15 | Iteration number: [2050/4518] 45% | Training loss: 0.687223151457019
Epoch: 15 | Iteration number: [2060/4518] 45% | Training loss: 0.6872201591730118
Epoch: 15 | Iteration number: [2070/4518] 45% | Training loss: 0.687223314922213
Epoch: 15 | Iteration number: [2080/4518] 46% | Training loss: 0.6872207150436365
Epoch: 15 | Iteration number: [2090/4518] 46% | Training loss: 0.6872221872852179
Epoch: 15 | Iteration number: [2100/4518] 46% | Training loss: 0.6872178409213111
Epoch: 15 | Iteration number: [2110/4518] 46% | Training loss: 0.6872172783053881
Epoch: 15 | Iteration number: [2120/4518] 46% | Training loss: 0.6872182915795524
Epoch: 15 | Iteration number: [2130/4518] 47% | Training loss: 0.6872145975979281
Epoch: 15 | Iteration number: [2140/4518] 47% | Training loss: 0.6872134692758043
Epoch: 15 | Iteration number: [2150/4518] 47% | Training loss: 0.6872063549174819
Epoch: 15 | Iteration number: [2160/4518] 47% | Training loss: 0.6872061974748417
Epoch: 15 | Iteration number: [2170/4518] 48% | Training loss: 0.6872038096326837
Epoch: 15 | Iteration number: [2180/4518] 48% | Training loss: 0.6872017066686525
Epoch: 15 | Iteration number: [2190/4518] 48% | Training loss: 0.6871984815760834
Epoch: 15 | Iteration number: [2200/4518] 48% | Training loss: 0.6871973151239482
Epoch: 15 | Iteration number: [2210/4518] 48% | Training loss: 0.6871953766540165
Epoch: 15 | Iteration number: [2220/4518] 49% | Training loss: 0.6871965984234939
Epoch: 15 | Iteration number: [2230/4518] 49% | Training loss: 0.6871958842993852
Epoch: 15 | Iteration number: [2240/4518] 49% | Training loss: 0.6871937897056342
Epoch: 15 | Iteration number: [2250/4518] 49% | Training loss: 0.6871929340362549
Epoch: 15 | Iteration number: [2260/4518] 50% | Training loss: 0.6871972782421956
Epoch: 15 | Iteration number: [2270/4518] 50% | Training loss: 0.6871932575093492
Epoch: 15 | Iteration number: [2280/4518] 50% | Training loss: 0.6871874457388594
Epoch: 15 | Iteration number: [2290/4518] 50% | Training loss: 0.6871907872664356
Epoch: 15 | Iteration number: [2300/4518] 50% | Training loss: 0.6871856070601422
Epoch: 15 | Iteration number: [2310/4518] 51% | Training loss: 0.6871841707270899
Epoch: 15 | Iteration number: [2320/4518] 51% | Training loss: 0.687180157596695
Epoch: 15 | Iteration number: [2330/4518] 51% | Training loss: 0.6871792680971612
Epoch: 15 | Iteration number: [2340/4518] 51% | Training loss: 0.6871758044784905
Epoch: 15 | Iteration number: [2350/4518] 52% | Training loss: 0.6871663097117809
Epoch: 15 | Iteration number: [2360/4518] 52% | Training loss: 0.68716332952855
Epoch: 15 | Iteration number: [2370/4518] 52% | Training loss: 0.6871644643540121
Epoch: 15 | Iteration number: [2380/4518] 52% | Training loss: 0.6871614688584784
Epoch: 15 | Iteration number: [2390/4518] 52% | Training loss: 0.6871632651803883
Epoch: 15 | Iteration number: [2400/4518] 53% | Training loss: 0.6871587914725145
Epoch: 15 | Iteration number: [2410/4518] 53% | Training loss: 0.6871592235515721
Epoch: 15 | Iteration number: [2420/4518] 53% | Training loss: 0.6871541304036606
Epoch: 15 | Iteration number: [2430/4518] 53% | Training loss: 0.6871467741183293
Epoch: 15 | Iteration number: [2440/4518] 54% | Training loss: 0.6871465066173038
Epoch: 15 | Iteration number: [2450/4518] 54% | Training loss: 0.6871450013043929
Epoch: 15 | Iteration number: [2460/4518] 54% | Training loss: 0.6871469102254728
Epoch: 15 | Iteration number: [2470/4518] 54% | Training loss: 0.6871426898940854
Epoch: 15 | Iteration number: [2480/4518] 54% | Training loss: 0.6871421991577071
Epoch: 15 | Iteration number: [2490/4518] 55% | Training loss: 0.6871383716782413
Epoch: 15 | Iteration number: [2500/4518] 55% | Training loss: 0.6871376289367676
Epoch: 15 | Iteration number: [2510/4518] 55% | Training loss: 0.6871399241377159
Epoch: 15 | Iteration number: [2520/4518] 55% | Training loss: 0.6871355114002077
Epoch: 15 | Iteration number: [2530/4518] 55% | Training loss: 0.6871358948733967
Epoch: 15 | Iteration number: [2540/4518] 56% | Training loss: 0.6871349780343649
Epoch: 15 | Iteration number: [2550/4518] 56% | Training loss: 0.6871317042790207
Epoch: 15 | Iteration number: [2560/4518] 56% | Training loss: 0.6871333049144596
Epoch: 15 | Iteration number: [2570/4518] 56% | Training loss: 0.6871381013773759
Epoch: 15 | Iteration number: [2580/4518] 57% | Training loss: 0.6871428367472434
Epoch: 15 | Iteration number: [2590/4518] 57% | Training loss: 0.6871460379320682
Epoch: 15 | Iteration number: [2600/4518] 57% | Training loss: 0.6871447233511851
Epoch: 15 | Iteration number: [2610/4518] 57% | Training loss: 0.6871462239387849
Epoch: 15 | Iteration number: [2620/4518] 57% | Training loss: 0.6871455961738834
Epoch: 15 | Iteration number: [2630/4518] 58% | Training loss: 0.6871523083616119
Epoch: 15 | Iteration number: [2640/4518] 58% | Training loss: 0.6871519330098773
Epoch: 15 | Iteration number: [2650/4518] 58% | Training loss: 0.6871452653183128
Epoch: 15 | Iteration number: [2660/4518] 58% | Training loss: 0.6871422812454683
Epoch: 15 | Iteration number: [2670/4518] 59% | Training loss: 0.687137893076693
Epoch: 15 | Iteration number: [2680/4518] 59% | Training loss: 0.6871370029983236
Epoch: 15 | Iteration number: [2690/4518] 59% | Training loss: 0.6871375162583745
Epoch: 15 | Iteration number: [2700/4518] 59% | Training loss: 0.6871398451151671
Epoch: 15 | Iteration number: [2710/4518] 59% | Training loss: 0.6871402679334268
Epoch: 15 | Iteration number: [2720/4518] 60% | Training loss: 0.6871386287624345
Epoch: 15 | Iteration number: [2730/4518] 60% | Training loss: 0.6871393200242039
Epoch: 15 | Iteration number: [2740/4518] 60% | Training loss: 0.6871408743362357
Epoch: 15 | Iteration number: [2750/4518] 60% | Training loss: 0.6871423179669813
Epoch: 15 | Iteration number: [2760/4518] 61% | Training loss: 0.6871391340658285
Epoch: 15 | Iteration number: [2770/4518] 61% | Training loss: 0.6871405227950333
Epoch: 15 | Iteration number: [2780/4518] 61% | Training loss: 0.6871440685910286
Epoch: 15 | Iteration number: [2790/4518] 61% | Training loss: 0.6871426311231429
Epoch: 15 | Iteration number: [2800/4518] 61% | Training loss: 0.6871436337275164
Epoch: 15 | Iteration number: [2810/4518] 62% | Training loss: 0.6871353487951476
Epoch: 15 | Iteration number: [2820/4518] 62% | Training loss: 0.6871331348909554
Epoch: 15 | Iteration number: [2830/4518] 62% | Training loss: 0.6871365782650115
Epoch: 15 | Iteration number: [2840/4518] 62% | Training loss: 0.6871303247943731
Epoch: 15 | Iteration number: [2850/4518] 63% | Training loss: 0.6871313357144071
Epoch: 15 | Iteration number: [2860/4518] 63% | Training loss: 0.6871308396954636
Epoch: 15 | Iteration number: [2870/4518] 63% | Training loss: 0.6871309881010953
Epoch: 15 | Iteration number: [2880/4518] 63% | Training loss: 0.6871294060101112
Epoch: 15 | Iteration number: [2890/4518] 63% | Training loss: 0.6871280628092149
Epoch: 15 | Iteration number: [2900/4518] 64% | Training loss: 0.6871288471797417
Epoch: 15 | Iteration number: [2910/4518] 64% | Training loss: 0.6871314272438128
Epoch: 15 | Iteration number: [2920/4518] 64% | Training loss: 0.6871308645769342
Epoch: 15 | Iteration number: [2930/4518] 64% | Training loss: 0.6871305953317128
Epoch: 15 | Iteration number: [2940/4518] 65% | Training loss: 0.6871297971326478
Epoch: 15 | Iteration number: [2950/4518] 65% | Training loss: 0.6871309353537479
Epoch: 15 | Iteration number: [2960/4518] 65% | Training loss: 0.6871295268068442
Epoch: 15 | Iteration number: [2970/4518] 65% | Training loss: 0.6871256254136763
Epoch: 15 | Iteration number: [2980/4518] 65% | Training loss: 0.6871273138179075
Epoch: 15 | Iteration number: [2990/4518] 66% | Training loss: 0.6871214753010599
Epoch: 15 | Iteration number: [3000/4518] 66% | Training loss: 0.6871228801409404
Epoch: 15 | Iteration number: [3010/4518] 66% | Training loss: 0.687121351157312
Epoch: 15 | Iteration number: [3020/4518] 66% | Training loss: 0.6871198038194353
Epoch: 15 | Iteration number: [3030/4518] 67% | Training loss: 0.6871168369900669
Epoch: 15 | Iteration number: [3040/4518] 67% | Training loss: 0.6871202683174297
Epoch: 15 | Iteration number: [3050/4518] 67% | Training loss: 0.6871177187317707
Epoch: 15 | Iteration number: [3060/4518] 67% | Training loss: 0.687115644941143
Epoch: 15 | Iteration number: [3070/4518] 67% | Training loss: 0.6871152978378321
Epoch: 15 | Iteration number: [3080/4518] 68% | Training loss: 0.6871167471075987
Epoch: 15 | Iteration number: [3090/4518] 68% | Training loss: 0.6871192166913289
Epoch: 15 | Iteration number: [3100/4518] 68% | Training loss: 0.6871209648924489
Epoch: 15 | Iteration number: [3110/4518] 68% | Training loss: 0.6871223254219129
Epoch: 15 | Iteration number: [3120/4518] 69% | Training loss: 0.6871290107377065
Epoch: 15 | Iteration number: [3130/4518] 69% | Training loss: 0.6871257535756206
Epoch: 15 | Iteration number: [3140/4518] 69% | Training loss: 0.6871255094458343
Epoch: 15 | Iteration number: [3150/4518] 69% | Training loss: 0.6871209283480568
Epoch: 15 | Iteration number: [3160/4518] 69% | Training loss: 0.6871212504709823
Epoch: 15 | Iteration number: [3170/4518] 70% | Training loss: 0.6871217925465821
Epoch: 15 | Iteration number: [3180/4518] 70% | Training loss: 0.6871233703580293
Epoch: 15 | Iteration number: [3190/4518] 70% | Training loss: 0.6871223054709479
Epoch: 15 | Iteration number: [3200/4518] 70% | Training loss: 0.6871220987290144
Epoch: 15 | Iteration number: [3210/4518] 71% | Training loss: 0.6871217575957099
Epoch: 15 | Iteration number: [3220/4518] 71% | Training loss: 0.6871203775361457
Epoch: 15 | Iteration number: [3230/4518] 71% | Training loss: 0.6871204607073368
Epoch: 15 | Iteration number: [3240/4518] 71% | Training loss: 0.6871182190967194
Epoch: 15 | Iteration number: [3250/4518] 71% | Training loss: 0.6871184396376977
Epoch: 15 | Iteration number: [3260/4518] 72% | Training loss: 0.6871186189307757
Epoch: 15 | Iteration number: [3270/4518] 72% | Training loss: 0.6871149831773309
Epoch: 15 | Iteration number: [3280/4518] 72% | Training loss: 0.6871131909511439
Epoch: 15 | Iteration number: [3290/4518] 72% | Training loss: 0.6871131385169855
Epoch: 15 | Iteration number: [3300/4518] 73% | Training loss: 0.6871116291934793
Epoch: 15 | Iteration number: [3310/4518] 73% | Training loss: 0.6871123227648145
Epoch: 15 | Iteration number: [3320/4518] 73% | Training loss: 0.6871153879237463
Epoch: 15 | Iteration number: [3330/4518] 73% | Training loss: 0.6871139872897495
Epoch: 15 | Iteration number: [3340/4518] 73% | Training loss: 0.6871098811219553
Epoch: 15 | Iteration number: [3350/4518] 74% | Training loss: 0.6871113514722283
Epoch: 15 | Iteration number: [3360/4518] 74% | Training loss: 0.6871143661262024
Epoch: 15 | Iteration number: [3370/4518] 74% | Training loss: 0.6871141306724322
Epoch: 15 | Iteration number: [3380/4518] 74% | Training loss: 0.6871163775405941
Epoch: 15 | Iteration number: [3390/4518] 75% | Training loss: 0.68711007982932
Epoch: 15 | Iteration number: [3400/4518] 75% | Training loss: 0.6871087555850254
Epoch: 15 | Iteration number: [3410/4518] 75% | Training loss: 0.687109062958323
Epoch: 15 | Iteration number: [3420/4518] 75% | Training loss: 0.687111396346873
Epoch: 15 | Iteration number: [3430/4518] 75% | Training loss: 0.6871082656932642
Epoch: 15 | Iteration number: [3440/4518] 76% | Training loss: 0.6871088228253431
Epoch: 15 | Iteration number: [3450/4518] 76% | Training loss: 0.6871049285280532
Epoch: 15 | Iteration number: [3460/4518] 76% | Training loss: 0.6871067619737173
Epoch: 15 | Iteration number: [3470/4518] 76% | Training loss: 0.6871085284422729
Epoch: 15 | Iteration number: [3480/4518] 77% | Training loss: 0.6871080035450815
Epoch: 15 | Iteration number: [3490/4518] 77% | Training loss: 0.6871091370425456
Epoch: 15 | Iteration number: [3500/4518] 77% | Training loss: 0.6871102777889797
Epoch: 15 | Iteration number: [3510/4518] 77% | Training loss: 0.687109629533909
Epoch: 15 | Iteration number: [3520/4518] 77% | Training loss: 0.687109187990427
Epoch: 15 | Iteration number: [3530/4518] 78% | Training loss: 0.68710899067668
Epoch: 15 | Iteration number: [3540/4518] 78% | Training loss: 0.6871093236793906
Epoch: 15 | Iteration number: [3550/4518] 78% | Training loss: 0.6871100435626339
Epoch: 15 | Iteration number: [3560/4518] 78% | Training loss: 0.6871106982733427
Epoch: 15 | Iteration number: [3570/4518] 79% | Training loss: 0.6871096923070795
Epoch: 15 | Iteration number: [3580/4518] 79% | Training loss: 0.6871081684055275
Epoch: 15 | Iteration number: [3590/4518] 79% | Training loss: 0.6871082031793249
Epoch: 15 | Iteration number: [3600/4518] 79% | Training loss: 0.6871085906028748
Epoch: 15 | Iteration number: [3610/4518] 79% | Training loss: 0.6871095348097941
Epoch: 15 | Iteration number: [3620/4518] 80% | Training loss: 0.6871063326274492
Epoch: 15 | Iteration number: [3630/4518] 80% | Training loss: 0.6871091568765562
Epoch: 15 | Iteration number: [3640/4518] 80% | Training loss: 0.6871093021971839
Epoch: 15 | Iteration number: [3650/4518] 80% | Training loss: 0.6871129258201547
Epoch: 15 | Iteration number: [3660/4518] 81% | Training loss: 0.6871126092033959
Epoch: 15 | Iteration number: [3670/4518] 81% | Training loss: 0.6871120726380101
Epoch: 15 | Iteration number: [3680/4518] 81% | Training loss: 0.6871111935247546
Epoch: 15 | Iteration number: [3690/4518] 81% | Training loss: 0.6871116568725607
Epoch: 15 | Iteration number: [3700/4518] 81% | Training loss: 0.687107882193617
Epoch: 15 | Iteration number: [3710/4518] 82% | Training loss: 0.6871078795821197
Epoch: 15 | Iteration number: [3720/4518] 82% | Training loss: 0.6871093491873433
Epoch: 15 | Iteration number: [3730/4518] 82% | Training loss: 0.6871104076145161
Epoch: 15 | Iteration number: [3740/4518] 82% | Training loss: 0.6871103652020827
Epoch: 15 | Iteration number: [3750/4518] 83% | Training loss: 0.6871112616697947
Epoch: 15 | Iteration number: [3760/4518] 83% | Training loss: 0.6871119759342772
Epoch: 15 | Iteration number: [3770/4518] 83% | Training loss: 0.6871097468570943
Epoch: 15 | Iteration number: [3780/4518] 83% | Training loss: 0.6871065949006055
Epoch: 15 | Iteration number: [3790/4518] 83% | Training loss: 0.6871047081135823
Epoch: 15 | Iteration number: [3800/4518] 84% | Training loss: 0.6871054250001908
Epoch: 15 | Iteration number: [3810/4518] 84% | Training loss: 0.6871062132473693
Epoch: 15 | Iteration number: [3820/4518] 84% | Training loss: 0.687105506502521
Epoch: 15 | Iteration number: [3830/4518] 84% | Training loss: 0.687106291852483
Epoch: 15 | Iteration number: [3840/4518] 84% | Training loss: 0.687107184017077
Epoch: 15 | Iteration number: [3850/4518] 85% | Training loss: 0.6871055038563617
Epoch: 15 | Iteration number: [3860/4518] 85% | Training loss: 0.6871057884217544
Epoch: 15 | Iteration number: [3870/4518] 85% | Training loss: 0.6871023049804283
Epoch: 15 | Iteration number: [3880/4518] 85% | Training loss: 0.6871047777767034
Epoch: 15 | Iteration number: [3890/4518] 86% | Training loss: 0.6871031797790282
Epoch: 15 | Iteration number: [3900/4518] 86% | Training loss: 0.6871017261193348
Epoch: 15 | Iteration number: [3910/4518] 86% | Training loss: 0.6871027870556278
Epoch: 15 | Iteration number: [3920/4518] 86% | Training loss: 0.6871012521793648
Epoch: 15 | Iteration number: [3930/4518] 86% | Training loss: 0.6870968388995444
Epoch: 15 | Iteration number: [3940/4518] 87% | Training loss: 0.6870952994539048
Epoch: 15 | Iteration number: [3950/4518] 87% | Training loss: 0.6870966908599757
Epoch: 15 | Iteration number: [3960/4518] 87% | Training loss: 0.6870966773442547
Epoch: 15 | Iteration number: [3970/4518] 87% | Training loss: 0.687097038339908
Epoch: 15 | Iteration number: [3980/4518] 88% | Training loss: 0.6870972892447332
Epoch: 15 | Iteration number: [3990/4518] 88% | Training loss: 0.6870932337036706
Epoch: 15 | Iteration number: [4000/4518] 88% | Training loss: 0.6870948542356491
Epoch: 15 | Iteration number: [4010/4518] 88% | Training loss: 0.6870947869341273
Epoch: 15 | Iteration number: [4020/4518] 88% | Training loss: 0.6870962132713688
Epoch: 15 | Iteration number: [4030/4518] 89% | Training loss: 0.6870958398204879
Epoch: 15 | Iteration number: [4040/4518] 89% | Training loss: 0.6870978634251226
Epoch: 15 | Iteration number: [4050/4518] 89% | Training loss: 0.6871000542611252
Epoch: 15 | Iteration number: [4060/4518] 89% | Training loss: 0.6870973252163732
Epoch: 15 | Iteration number: [4070/4518] 90% | Training loss: 0.6870984340036238
Epoch: 15 | Iteration number: [4080/4518] 90% | Training loss: 0.6870984409515765
Epoch: 15 | Iteration number: [4090/4518] 90% | Training loss: 0.6871011834127104
Epoch: 15 | Iteration number: [4100/4518] 90% | Training loss: 0.6870968588241717
Epoch: 15 | Iteration number: [4110/4518] 90% | Training loss: 0.6870977974576091
Epoch: 15 | Iteration number: [4120/4518] 91% | Training loss: 0.6870992104839353
Epoch: 15 | Iteration number: [4130/4518] 91% | Training loss: 0.687099263584354
Epoch: 15 | Iteration number: [4140/4518] 91% | Training loss: 0.6870993132032635
Epoch: 15 | Iteration number: [4150/4518] 91% | Training loss: 0.6870981826265175
Epoch: 15 | Iteration number: [4160/4518] 92% | Training loss: 0.6870985462258642
Epoch: 15 | Iteration number: [4170/4518] 92% | Training loss: 0.687098426327145
Epoch: 15 | Iteration number: [4180/4518] 92% | Training loss: 0.6870963827132038
Epoch: 15 | Iteration number: [4190/4518] 92% | Training loss: 0.6870980257208421
Epoch: 15 | Iteration number: [4200/4518] 92% | Training loss: 0.6870988400351433
Epoch: 15 | Iteration number: [4210/4518] 93% | Training loss: 0.6870975569421491
Epoch: 15 | Iteration number: [4220/4518] 93% | Training loss: 0.6870979785212973
Epoch: 15 | Iteration number: [4230/4518] 93% | Training loss: 0.6870957096417745
Epoch: 15 | Iteration number: [4240/4518] 93% | Training loss: 0.6870954718370482
Epoch: 15 | Iteration number: [4250/4518] 94% | Training loss: 0.6870973355489619
Epoch: 15 | Iteration number: [4260/4518] 94% | Training loss: 0.6870970845502307
Epoch: 15 | Iteration number: [4270/4518] 94% | Training loss: 0.6870947327072224
Epoch: 15 | Iteration number: [4280/4518] 94% | Training loss: 0.6870946328773677
Epoch: 15 | Iteration number: [4290/4518] 94% | Training loss: 0.6870922903358797
Epoch: 15 | Iteration number: [4300/4518] 95% | Training loss: 0.6870935780087183
Epoch: 15 | Iteration number: [4310/4518] 95% | Training loss: 0.6870942619449855
Epoch: 15 | Iteration number: [4320/4518] 95% | Training loss: 0.6870939087812548
Epoch: 15 | Iteration number: [4330/4518] 95% | Training loss: 0.6870939012900786
Epoch: 15 | Iteration number: [4340/4518] 96% | Training loss: 0.6870945257799966
Epoch: 15 | Iteration number: [4350/4518] 96% | Training loss: 0.6870943470658927
Epoch: 15 | Iteration number: [4360/4518] 96% | Training loss: 0.6870947902765843
Epoch: 15 | Iteration number: [4370/4518] 96% | Training loss: 0.6870941154607646
Epoch: 15 | Iteration number: [4380/4518] 96% | Training loss: 0.6870938681848517
Epoch: 15 | Iteration number: [4390/4518] 97% | Training loss: 0.6870940627704177
Epoch: 15 | Iteration number: [4400/4518] 97% | Training loss: 0.6870949174057354
Epoch: 15 | Iteration number: [4410/4518] 97% | Training loss: 0.6870931436956064
Epoch: 15 | Iteration number: [4420/4518] 97% | Training loss: 0.6870902596555684
Epoch: 15 | Iteration number: [4430/4518] 98% | Training loss: 0.6870917189336523
Epoch: 15 | Iteration number: [4440/4518] 98% | Training loss: 0.6870911282730532
Epoch: 15 | Iteration number: [4450/4518] 98% | Training loss: 0.6870910862724433
Epoch: 15 | Iteration number: [4460/4518] 98% | Training loss: 0.6870907885477682
Epoch: 15 | Iteration number: [4470/4518] 98% | Training loss: 0.6870904117089257
Epoch: 15 | Iteration number: [4480/4518] 99% | Training loss: 0.68708982157654
Epoch: 15 | Iteration number: [4490/4518] 99% | Training loss: 0.6870878398683926
Epoch: 15 | Iteration number: [4500/4518] 99% | Training loss: 0.6870890244113075
Epoch: 15 | Iteration number: [4510/4518] 99% | Training loss: 0.6870919286411776

 End of epoch: 15 | Train Loss: 0.6869403670429391 | Training Time: 641 

 End of epoch: 15 | Eval Loss: 0.690131206901706 | Evaluating Time: 17 
Epoch: 16 | Iteration number: [10/4518] 0% | Training loss: 0.7549392104148864
Epoch: 16 | Iteration number: [20/4518] 0% | Training loss: 0.7214681833982468
Epoch: 16 | Iteration number: [30/4518] 0% | Training loss: 0.7099976201852163
Epoch: 16 | Iteration number: [40/4518] 0% | Training loss: 0.7043025314807891
Epoch: 16 | Iteration number: [50/4518] 1% | Training loss: 0.7007088196277619
Epoch: 16 | Iteration number: [60/4518] 1% | Training loss: 0.6986191083987554
Epoch: 16 | Iteration number: [70/4518] 1% | Training loss: 0.6971388033458165
Epoch: 16 | Iteration number: [80/4518] 1% | Training loss: 0.6958839476108551
Epoch: 16 | Iteration number: [90/4518] 1% | Training loss: 0.6948137601216634
Epoch: 16 | Iteration number: [100/4518] 2% | Training loss: 0.6939957123994828
Epoch: 16 | Iteration number: [110/4518] 2% | Training loss: 0.6934732258319855
Epoch: 16 | Iteration number: [120/4518] 2% | Training loss: 0.6929857090115548
Epoch: 16 | Iteration number: [130/4518] 2% | Training loss: 0.6925753171627338
Epoch: 16 | Iteration number: [140/4518] 3% | Training loss: 0.6922128788062505
Epoch: 16 | Iteration number: [150/4518] 3% | Training loss: 0.6918435823917389
Epoch: 16 | Iteration number: [160/4518] 3% | Training loss: 0.6915167838335037
Epoch: 16 | Iteration number: [170/4518] 3% | Training loss: 0.6912617620299845
Epoch: 16 | Iteration number: [180/4518] 3% | Training loss: 0.6910120639536116
Epoch: 16 | Iteration number: [190/4518] 4% | Training loss: 0.690790698716515
Epoch: 16 | Iteration number: [200/4518] 4% | Training loss: 0.6905871745944023
Epoch: 16 | Iteration number: [210/4518] 4% | Training loss: 0.690353356656574
Epoch: 16 | Iteration number: [220/4518] 4% | Training loss: 0.6902429361235012
Epoch: 16 | Iteration number: [230/4518] 5% | Training loss: 0.6901188964429109
Epoch: 16 | Iteration number: [240/4518] 5% | Training loss: 0.6900215754906337
Epoch: 16 | Iteration number: [250/4518] 5% | Training loss: 0.6899275548458099
Epoch: 16 | Iteration number: [260/4518] 5% | Training loss: 0.6898464888334275
Epoch: 16 | Iteration number: [270/4518] 5% | Training loss: 0.6898021854736187
Epoch: 16 | Iteration number: [280/4518] 6% | Training loss: 0.6896960034966468
Epoch: 16 | Iteration number: [290/4518] 6% | Training loss: 0.6896440440210803
Epoch: 16 | Iteration number: [300/4518] 6% | Training loss: 0.6895336373647054
Epoch: 16 | Iteration number: [310/4518] 6% | Training loss: 0.6894319611210977
Epoch: 16 | Iteration number: [320/4518] 7% | Training loss: 0.6893615936860442
Epoch: 16 | Iteration number: [330/4518] 7% | Training loss: 0.6892642978465918
Epoch: 16 | Iteration number: [340/4518] 7% | Training loss: 0.6892206698656083
Epoch: 16 | Iteration number: [350/4518] 7% | Training loss: 0.6891599699429103
Epoch: 16 | Iteration number: [360/4518] 7% | Training loss: 0.6890984396139781
Epoch: 16 | Iteration number: [370/4518] 8% | Training loss: 0.6890181032386986
Epoch: 16 | Iteration number: [380/4518] 8% | Training loss: 0.6889502781002145
Epoch: 16 | Iteration number: [390/4518] 8% | Training loss: 0.6889021998796707
Epoch: 16 | Iteration number: [400/4518] 8% | Training loss: 0.6888282532989979
Epoch: 16 | Iteration number: [410/4518] 9% | Training loss: 0.6887792821337537
Epoch: 16 | Iteration number: [420/4518] 9% | Training loss: 0.6886962409530367
Epoch: 16 | Iteration number: [430/4518] 9% | Training loss: 0.6886610810146775
Epoch: 16 | Iteration number: [440/4518] 9% | Training loss: 0.6886201989921656
Epoch: 16 | Iteration number: [450/4518] 9% | Training loss: 0.6885755740271674
Epoch: 16 | Iteration number: [460/4518] 10% | Training loss: 0.6885340440532436
Epoch: 16 | Iteration number: [470/4518] 10% | Training loss: 0.6885139609905
Epoch: 16 | Iteration number: [480/4518] 10% | Training loss: 0.6884558625519276
Epoch: 16 | Iteration number: [490/4518] 10% | Training loss: 0.6884300454538695
Epoch: 16 | Iteration number: [500/4518] 11% | Training loss: 0.6883925762176514
Epoch: 16 | Iteration number: [510/4518] 11% | Training loss: 0.6883710411249423
Epoch: 16 | Iteration number: [520/4518] 11% | Training loss: 0.688325941333404
Epoch: 16 | Iteration number: [530/4518] 11% | Training loss: 0.6882849821504556
Epoch: 16 | Iteration number: [540/4518] 11% | Training loss: 0.6882619117145186
Epoch: 16 | Iteration number: [550/4518] 12% | Training loss: 0.6882365647229282
Epoch: 16 | Iteration number: [560/4518] 12% | Training loss: 0.6882219042096819
Epoch: 16 | Iteration number: [570/4518] 12% | Training loss: 0.6881982593159927
Epoch: 16 | Iteration number: [580/4518] 12% | Training loss: 0.6881752955502477
Epoch: 16 | Iteration number: [590/4518] 13% | Training loss: 0.6881488746505673
Epoch: 16 | Iteration number: [600/4518] 13% | Training loss: 0.6881470037500064
Epoch: 16 | Iteration number: [610/4518] 13% | Training loss: 0.6881086641647777
Epoch: 16 | Iteration number: [620/4518] 13% | Training loss: 0.6880770432372247
Epoch: 16 | Iteration number: [630/4518] 13% | Training loss: 0.6880665930490645
Epoch: 16 | Iteration number: [640/4518] 14% | Training loss: 0.6880421280860901
Epoch: 16 | Iteration number: [650/4518] 14% | Training loss: 0.6880189440800594
Epoch: 16 | Iteration number: [660/4518] 14% | Training loss: 0.6880136649716985
Epoch: 16 | Iteration number: [670/4518] 14% | Training loss: 0.6880125834870694
Epoch: 16 | Iteration number: [680/4518] 15% | Training loss: 0.6880126783952993
Epoch: 16 | Iteration number: [690/4518] 15% | Training loss: 0.6880002173824586
Epoch: 16 | Iteration number: [700/4518] 15% | Training loss: 0.6879673626593181
Epoch: 16 | Iteration number: [710/4518] 15% | Training loss: 0.6879540829591348
Epoch: 16 | Iteration number: [720/4518] 15% | Training loss: 0.6879540570908123
Epoch: 16 | Iteration number: [730/4518] 16% | Training loss: 0.6879368679164207
Epoch: 16 | Iteration number: [740/4518] 16% | Training loss: 0.6879263225439433
Epoch: 16 | Iteration number: [750/4518] 16% | Training loss: 0.6879106315771739
Epoch: 16 | Iteration number: [760/4518] 16% | Training loss: 0.6878877686826806
Epoch: 16 | Iteration number: [770/4518] 17% | Training loss: 0.6878665962002494
Epoch: 16 | Iteration number: [780/4518] 17% | Training loss: 0.6878627562370055
Epoch: 16 | Iteration number: [790/4518] 17% | Training loss: 0.6878537250470511
Epoch: 16 | Iteration number: [800/4518] 17% | Training loss: 0.687829508855939
Epoch: 16 | Iteration number: [810/4518] 17% | Training loss: 0.687798222715472
Epoch: 16 | Iteration number: [820/4518] 18% | Training loss: 0.6878012841067663
Epoch: 16 | Iteration number: [830/4518] 18% | Training loss: 0.6877905350133597
Epoch: 16 | Iteration number: [840/4518] 18% | Training loss: 0.6877767721102351
Epoch: 16 | Iteration number: [850/4518] 18% | Training loss: 0.6877712904004489
Epoch: 16 | Iteration number: [860/4518] 19% | Training loss: 0.6877642630144607
Epoch: 16 | Iteration number: [870/4518] 19% | Training loss: 0.6877633791545342
Epoch: 16 | Iteration number: [880/4518] 19% | Training loss: 0.687742508541454
Epoch: 16 | Iteration number: [890/4518] 19% | Training loss: 0.6877309965953399
Epoch: 16 | Iteration number: [900/4518] 19% | Training loss: 0.687730018099149
Epoch: 16 | Iteration number: [910/4518] 20% | Training loss: 0.6877161203504919
Epoch: 16 | Iteration number: [920/4518] 20% | Training loss: 0.687715888671253
Epoch: 16 | Iteration number: [930/4518] 20% | Training loss: 0.6877143152939376
Epoch: 16 | Iteration number: [940/4518] 20% | Training loss: 0.6877123815582153
Epoch: 16 | Iteration number: [950/4518] 21% | Training loss: 0.6877029946603274
Epoch: 16 | Iteration number: [960/4518] 21% | Training loss: 0.6876940626651049
Epoch: 16 | Iteration number: [970/4518] 21% | Training loss: 0.6876888849071621
Epoch: 16 | Iteration number: [980/4518] 21% | Training loss: 0.6876709618130509
Epoch: 16 | Iteration number: [990/4518] 21% | Training loss: 0.6876520481976596
Epoch: 16 | Iteration number: [1000/4518] 22% | Training loss: 0.6876281108260155
Epoch: 16 | Iteration number: [1010/4518] 22% | Training loss: 0.6876139756476525
Epoch: 16 | Iteration number: [1020/4518] 22% | Training loss: 0.6875989859010659
Epoch: 16 | Iteration number: [1030/4518] 22% | Training loss: 0.6875894166890857
Epoch: 16 | Iteration number: [1040/4518] 23% | Training loss: 0.6875882172813782
Epoch: 16 | Iteration number: [1050/4518] 23% | Training loss: 0.6875881138869694
Epoch: 16 | Iteration number: [1060/4518] 23% | Training loss: 0.6875756696710047
Epoch: 16 | Iteration number: [1070/4518] 23% | Training loss: 0.6875736841531558
Epoch: 16 | Iteration number: [1080/4518] 23% | Training loss: 0.6875677352150281
Epoch: 16 | Iteration number: [1090/4518] 24% | Training loss: 0.6875705977645489
Epoch: 16 | Iteration number: [1100/4518] 24% | Training loss: 0.6875567816604268
Epoch: 16 | Iteration number: [1110/4518] 24% | Training loss: 0.6875611680584985
Epoch: 16 | Iteration number: [1120/4518] 24% | Training loss: 0.6875521641224622
Epoch: 16 | Iteration number: [1130/4518] 25% | Training loss: 0.6875504888791953
Epoch: 16 | Iteration number: [1140/4518] 25% | Training loss: 0.6875471906180968
Epoch: 16 | Iteration number: [1150/4518] 25% | Training loss: 0.6875370512837949
Epoch: 16 | Iteration number: [1160/4518] 25% | Training loss: 0.6875395285672155
Epoch: 16 | Iteration number: [1170/4518] 25% | Training loss: 0.6875246704134167
Epoch: 16 | Iteration number: [1180/4518] 26% | Training loss: 0.6875272122480102
Epoch: 16 | Iteration number: [1190/4518] 26% | Training loss: 0.6875234744628939
Epoch: 16 | Iteration number: [1200/4518] 26% | Training loss: 0.6875259200731914
Epoch: 16 | Iteration number: [1210/4518] 26% | Training loss: 0.6875099714629906
Epoch: 16 | Iteration number: [1220/4518] 27% | Training loss: 0.6875030028038338
Epoch: 16 | Iteration number: [1230/4518] 27% | Training loss: 0.6875134328516518
Epoch: 16 | Iteration number: [1240/4518] 27% | Training loss: 0.6875239578466261
Epoch: 16 | Iteration number: [1250/4518] 27% | Training loss: 0.6875247642040253
Epoch: 16 | Iteration number: [1260/4518] 27% | Training loss: 0.6875113382698997
Epoch: 16 | Iteration number: [1270/4518] 28% | Training loss: 0.6875016875623718
Epoch: 16 | Iteration number: [1280/4518] 28% | Training loss: 0.6875023807398974
Epoch: 16 | Iteration number: [1290/4518] 28% | Training loss: 0.6875066242014715
Epoch: 16 | Iteration number: [1300/4518] 28% | Training loss: 0.6875040203791398
Epoch: 16 | Iteration number: [1310/4518] 28% | Training loss: 0.6874980402356796
Epoch: 16 | Iteration number: [1320/4518] 29% | Training loss: 0.6874977909254305
Epoch: 16 | Iteration number: [1330/4518] 29% | Training loss: 0.6874874011914532
Epoch: 16 | Iteration number: [1340/4518] 29% | Training loss: 0.6874814540592592
Epoch: 16 | Iteration number: [1350/4518] 29% | Training loss: 0.6874802841963591
Epoch: 16 | Iteration number: [1360/4518] 30% | Training loss: 0.6874757497187923
Epoch: 16 | Iteration number: [1370/4518] 30% | Training loss: 0.6874682621799246
Epoch: 16 | Iteration number: [1380/4518] 30% | Training loss: 0.6874648316182952
Epoch: 16 | Iteration number: [1390/4518] 30% | Training loss: 0.6874606404373114
Epoch: 16 | Iteration number: [1400/4518] 30% | Training loss: 0.6874565924065453
Epoch: 16 | Iteration number: [1410/4518] 31% | Training loss: 0.6874467251571358
Epoch: 16 | Iteration number: [1420/4518] 31% | Training loss: 0.6874325141100817
Epoch: 16 | Iteration number: [1430/4518] 31% | Training loss: 0.6874311565102397
Epoch: 16 | Iteration number: [1440/4518] 31% | Training loss: 0.6874319161391921
Epoch: 16 | Iteration number: [1450/4518] 32% | Training loss: 0.6874232778055914
Epoch: 16 | Iteration number: [1460/4518] 32% | Training loss: 0.687426031983062
Epoch: 16 | Iteration number: [1470/4518] 32% | Training loss: 0.6874221887312779
Epoch: 16 | Iteration number: [1480/4518] 32% | Training loss: 0.6874201274401432
Epoch: 16 | Iteration number: [1490/4518] 32% | Training loss: 0.6874121183516996
Epoch: 16 | Iteration number: [1500/4518] 33% | Training loss: 0.6874007291793823
Epoch: 16 | Iteration number: [1510/4518] 33% | Training loss: 0.6873951147328939
Epoch: 16 | Iteration number: [1520/4518] 33% | Training loss: 0.6873864512302373
Epoch: 16 | Iteration number: [1530/4518] 33% | Training loss: 0.6873842688557369
Epoch: 16 | Iteration number: [1540/4518] 34% | Training loss: 0.687376455478854
Epoch: 16 | Iteration number: [1550/4518] 34% | Training loss: 0.6873703131368083
Epoch: 16 | Iteration number: [1560/4518] 34% | Training loss: 0.6873688677182564
Epoch: 16 | Iteration number: [1570/4518] 34% | Training loss: 0.6873606745604497
Epoch: 16 | Iteration number: [1580/4518] 34% | Training loss: 0.6873534936316406
Epoch: 16 | Iteration number: [1590/4518] 35% | Training loss: 0.6873493265430882
Epoch: 16 | Iteration number: [1600/4518] 35% | Training loss: 0.6873416267707944
Epoch: 16 | Iteration number: [1610/4518] 35% | Training loss: 0.6873406392817172
Epoch: 16 | Iteration number: [1620/4518] 35% | Training loss: 0.6873389814003015
Epoch: 16 | Iteration number: [1630/4518] 36% | Training loss: 0.6873319157427805
Epoch: 16 | Iteration number: [1640/4518] 36% | Training loss: 0.6873250444851271
Epoch: 16 | Iteration number: [1650/4518] 36% | Training loss: 0.6873296199061654
Epoch: 16 | Iteration number: [1660/4518] 36% | Training loss: 0.6873203681175968
Epoch: 16 | Iteration number: [1670/4518] 36% | Training loss: 0.6873157852424119
Epoch: 16 | Iteration number: [1680/4518] 37% | Training loss: 0.6873087325266429
Epoch: 16 | Iteration number: [1690/4518] 37% | Training loss: 0.6873033737995216
Epoch: 16 | Iteration number: [1700/4518] 37% | Training loss: 0.6873067258035436
Epoch: 16 | Iteration number: [1710/4518] 37% | Training loss: 0.6873046622290249
Epoch: 16 | Iteration number: [1720/4518] 38% | Training loss: 0.6873121481302172
Epoch: 16 | Iteration number: [1730/4518] 38% | Training loss: 0.6873166282052938
Epoch: 16 | Iteration number: [1740/4518] 38% | Training loss: 0.6873230966685833
Epoch: 16 | Iteration number: [1750/4518] 38% | Training loss: 0.6873243375846317
Epoch: 16 | Iteration number: [1760/4518] 38% | Training loss: 0.687313350662589
Epoch: 16 | Iteration number: [1770/4518] 39% | Training loss: 0.6873069066449073
Epoch: 16 | Iteration number: [1780/4518] 39% | Training loss: 0.6873023925202616
Epoch: 16 | Iteration number: [1790/4518] 39% | Training loss: 0.6873046907965698
Epoch: 16 | Iteration number: [1800/4518] 39% | Training loss: 0.6873070376780298
Epoch: 16 | Iteration number: [1810/4518] 40% | Training loss: 0.6873057353233105
Epoch: 16 | Iteration number: [1820/4518] 40% | Training loss: 0.6873068921841108
Epoch: 16 | Iteration number: [1830/4518] 40% | Training loss: 0.6873023454608813
Epoch: 16 | Iteration number: [1840/4518] 40% | Training loss: 0.6873031468819017
Epoch: 16 | Iteration number: [1850/4518] 40% | Training loss: 0.6873009911098996
Epoch: 16 | Iteration number: [1860/4518] 41% | Training loss: 0.6873035043157557
Epoch: 16 | Iteration number: [1870/4518] 41% | Training loss: 0.6872992526719914
Epoch: 16 | Iteration number: [1880/4518] 41% | Training loss: 0.6872901650502327
Epoch: 16 | Iteration number: [1890/4518] 41% | Training loss: 0.6872961847870438
Epoch: 16 | Iteration number: [1900/4518] 42% | Training loss: 0.6872947456021058
Epoch: 16 | Iteration number: [1910/4518] 42% | Training loss: 0.6872910708032978
Epoch: 16 | Iteration number: [1920/4518] 42% | Training loss: 0.687295779834191
Epoch: 16 | Iteration number: [1930/4518] 42% | Training loss: 0.6872890912189384
Epoch: 16 | Iteration number: [1940/4518] 42% | Training loss: 0.6872893156771808
Epoch: 16 | Iteration number: [1950/4518] 43% | Training loss: 0.6872931904976185
Epoch: 16 | Iteration number: [1960/4518] 43% | Training loss: 0.6872951621911964
Epoch: 16 | Iteration number: [1970/4518] 43% | Training loss: 0.6872888827081864
Epoch: 16 | Iteration number: [1980/4518] 43% | Training loss: 0.687286237664897
Epoch: 16 | Iteration number: [1990/4518] 44% | Training loss: 0.6872837154709514
Epoch: 16 | Iteration number: [2000/4518] 44% | Training loss: 0.6872806179225445
Epoch: 16 | Iteration number: [2010/4518] 44% | Training loss: 0.6872800951276845
Epoch: 16 | Iteration number: [2020/4518] 44% | Training loss: 0.6872811036829901
Epoch: 16 | Iteration number: [2030/4518] 44% | Training loss: 0.6872790405609338
Epoch: 16 | Iteration number: [2040/4518] 45% | Training loss: 0.6872734591072681
Epoch: 16 | Iteration number: [2050/4518] 45% | Training loss: 0.6872687728521301
Epoch: 16 | Iteration number: [2060/4518] 45% | Training loss: 0.6872679814262298
Epoch: 16 | Iteration number: [2070/4518] 45% | Training loss: 0.6872656967328943
Epoch: 16 | Iteration number: [2080/4518] 46% | Training loss: 0.6872670998940101
Epoch: 16 | Iteration number: [2090/4518] 46% | Training loss: 0.6872716438256953
Epoch: 16 | Iteration number: [2100/4518] 46% | Training loss: 0.6872700354598817
Epoch: 16 | Iteration number: [2110/4518] 46% | Training loss: 0.6872688177920065
Epoch: 16 | Iteration number: [2120/4518] 46% | Training loss: 0.6872664248605944
Epoch: 16 | Iteration number: [2130/4518] 47% | Training loss: 0.6872671102693942
Epoch: 16 | Iteration number: [2140/4518] 47% | Training loss: 0.687264279338801
Epoch: 16 | Iteration number: [2150/4518] 47% | Training loss: 0.6872571034764134
Epoch: 16 | Iteration number: [2160/4518] 47% | Training loss: 0.6872507566655124
Epoch: 16 | Iteration number: [2170/4518] 48% | Training loss: 0.6872519127784237
Epoch: 16 | Iteration number: [2180/4518] 48% | Training loss: 0.6872515508067717
Epoch: 16 | Iteration number: [2190/4518] 48% | Training loss: 0.6872428544852287
Epoch: 16 | Iteration number: [2200/4518] 48% | Training loss: 0.6872357327287847
Epoch: 16 | Iteration number: [2210/4518] 48% | Training loss: 0.6872350238027616
Epoch: 16 | Iteration number: [2220/4518] 49% | Training loss: 0.6872370981418334
Epoch: 16 | Iteration number: [2230/4518] 49% | Training loss: 0.6872382647253473
Epoch: 16 | Iteration number: [2240/4518] 49% | Training loss: 0.6872382902673313
Epoch: 16 | Iteration number: [2250/4518] 49% | Training loss: 0.6872346569697062
Epoch: 16 | Iteration number: [2260/4518] 50% | Training loss: 0.6872360531207734
Epoch: 16 | Iteration number: [2270/4518] 50% | Training loss: 0.6872373009043118
Epoch: 16 | Iteration number: [2280/4518] 50% | Training loss: 0.6872350147680233
Epoch: 16 | Iteration number: [2290/4518] 50% | Training loss: 0.6872368447124698
Epoch: 16 | Iteration number: [2300/4518] 50% | Training loss: 0.6872351635539014
Epoch: 16 | Iteration number: [2310/4518] 51% | Training loss: 0.6872360634855378
Epoch: 16 | Iteration number: [2320/4518] 51% | Training loss: 0.6872340722073769
Epoch: 16 | Iteration number: [2330/4518] 51% | Training loss: 0.6872390163814561
Epoch: 16 | Iteration number: [2340/4518] 51% | Training loss: 0.6872355552820059
Epoch: 16 | Iteration number: [2350/4518] 52% | Training loss: 0.6872356761262772
Epoch: 16 | Iteration number: [2360/4518] 52% | Training loss: 0.6872349752207934
Epoch: 16 | Iteration number: [2370/4518] 52% | Training loss: 0.6872316123815528
Epoch: 16 | Iteration number: [2380/4518] 52% | Training loss: 0.6872289491801703
Epoch: 16 | Iteration number: [2390/4518] 52% | Training loss: 0.6872287639763565
Epoch: 16 | Iteration number: [2400/4518] 53% | Training loss: 0.687228678887089
Epoch: 16 | Iteration number: [2410/4518] 53% | Training loss: 0.6872246654449162
Epoch: 16 | Iteration number: [2420/4518] 53% | Training loss: 0.6872228427859377
Epoch: 16 | Iteration number: [2430/4518] 53% | Training loss: 0.6872192476266696
Epoch: 16 | Iteration number: [2440/4518] 54% | Training loss: 0.6872219777498089
Epoch: 16 | Iteration number: [2450/4518] 54% | Training loss: 0.6872207369366471
Epoch: 16 | Iteration number: [2460/4518] 54% | Training loss: 0.6872168132202412
Epoch: 16 | Iteration number: [2470/4518] 54% | Training loss: 0.6872133941061583
Epoch: 16 | Iteration number: [2480/4518] 54% | Training loss: 0.687217176729633
Epoch: 16 | Iteration number: [2490/4518] 55% | Training loss: 0.6872177791164582
Epoch: 16 | Iteration number: [2500/4518] 55% | Training loss: 0.6872160853385926
Epoch: 16 | Iteration number: [2510/4518] 55% | Training loss: 0.6872171946493278
Epoch: 16 | Iteration number: [2520/4518] 55% | Training loss: 0.6872130775735492
Epoch: 16 | Iteration number: [2530/4518] 55% | Training loss: 0.6872152202449768
Epoch: 16 | Iteration number: [2540/4518] 56% | Training loss: 0.6872153965272303
Epoch: 16 | Iteration number: [2550/4518] 56% | Training loss: 0.6872118512088177
Epoch: 16 | Iteration number: [2560/4518] 56% | Training loss: 0.6872125862399117
Epoch: 16 | Iteration number: [2570/4518] 56% | Training loss: 0.6872180458868524
Epoch: 16 | Iteration number: [2580/4518] 57% | Training loss: 0.6872151183989621
Epoch: 16 | Iteration number: [2590/4518] 57% | Training loss: 0.687220552759281
Epoch: 16 | Iteration number: [2600/4518] 57% | Training loss: 0.6872185046168474
Epoch: 16 | Iteration number: [2610/4518] 57% | Training loss: 0.6872186168857004
Epoch: 16 | Iteration number: [2620/4518] 57% | Training loss: 0.6872214568935278
Epoch: 16 | Iteration number: [2630/4518] 58% | Training loss: 0.6872196741883746
Epoch: 16 | Iteration number: [2640/4518] 58% | Training loss: 0.6872193890313307
Epoch: 16 | Iteration number: [2650/4518] 58% | Training loss: 0.6872142546131925
Epoch: 16 | Iteration number: [2660/4518] 58% | Training loss: 0.6872133021740089
Epoch: 16 | Iteration number: [2670/4518] 59% | Training loss: 0.6872132761424847
Epoch: 16 | Iteration number: [2680/4518] 59% | Training loss: 0.6872099236098688
Epoch: 16 | Iteration number: [2690/4518] 59% | Training loss: 0.6872102055186232
Epoch: 16 | Iteration number: [2700/4518] 59% | Training loss: 0.6872106956552576
Epoch: 16 | Iteration number: [2710/4518] 59% | Training loss: 0.687205927068457
Epoch: 16 | Iteration number: [2720/4518] 60% | Training loss: 0.6872031783575521
Epoch: 16 | Iteration number: [2730/4518] 60% | Training loss: 0.687200042223319
Epoch: 16 | Iteration number: [2740/4518] 60% | Training loss: 0.6871970002233547
Epoch: 16 | Iteration number: [2750/4518] 60% | Training loss: 0.6871985478617928
Epoch: 16 | Iteration number: [2760/4518] 61% | Training loss: 0.687195110321045
Epoch: 16 | Iteration number: [2770/4518] 61% | Training loss: 0.6871948393888853
Epoch: 16 | Iteration number: [2780/4518] 61% | Training loss: 0.6871943616395374
Epoch: 16 | Iteration number: [2790/4518] 61% | Training loss: 0.6871947666436541
Epoch: 16 | Iteration number: [2800/4518] 61% | Training loss: 0.6871932128710406
Epoch: 16 | Iteration number: [2810/4518] 62% | Training loss: 0.6871865891689083
Epoch: 16 | Iteration number: [2820/4518] 62% | Training loss: 0.6871816151742394
Epoch: 16 | Iteration number: [2830/4518] 62% | Training loss: 0.687185144382315
Epoch: 16 | Iteration number: [2840/4518] 62% | Training loss: 0.6871843341790455
Epoch: 16 | Iteration number: [2850/4518] 63% | Training loss: 0.6871852651813574
Epoch: 16 | Iteration number: [2860/4518] 63% | Training loss: 0.6871777927125251
Epoch: 16 | Iteration number: [2870/4518] 63% | Training loss: 0.6871776674059625
Epoch: 16 | Iteration number: [2880/4518] 63% | Training loss: 0.6871742081311014
Epoch: 16 | Iteration number: [2890/4518] 63% | Training loss: 0.6871747361541207
Epoch: 16 | Iteration number: [2900/4518] 64% | Training loss: 0.6871728046803639
Epoch: 16 | Iteration number: [2910/4518] 64% | Training loss: 0.6871750518013932
Epoch: 16 | Iteration number: [2920/4518] 64% | Training loss: 0.6871716537908332
Epoch: 16 | Iteration number: [2930/4518] 64% | Training loss: 0.6871716460880566
Epoch: 16 | Iteration number: [2940/4518] 65% | Training loss: 0.6871684890215088
Epoch: 16 | Iteration number: [2950/4518] 65% | Training loss: 0.6871686316546747
Epoch: 16 | Iteration number: [2960/4518] 65% | Training loss: 0.6871715107076877
Epoch: 16 | Iteration number: [2970/4518] 65% | Training loss: 0.6871690246793959
Epoch: 16 | Iteration number: [2980/4518] 65% | Training loss: 0.6871729058507304
Epoch: 16 | Iteration number: [2990/4518] 66% | Training loss: 0.687169632923643
Epoch: 16 | Iteration number: [3000/4518] 66% | Training loss: 0.6871660578250885
Epoch: 16 | Iteration number: [3010/4518] 66% | Training loss: 0.6871660438486904
Epoch: 16 | Iteration number: [3020/4518] 66% | Training loss: 0.6871661491938774
Epoch: 16 | Iteration number: [3030/4518] 67% | Training loss: 0.6871615846951803
Epoch: 16 | Iteration number: [3040/4518] 67% | Training loss: 0.6871609513892939
Epoch: 16 | Iteration number: [3050/4518] 67% | Training loss: 0.68715878320522
Epoch: 16 | Iteration number: [3060/4518] 67% | Training loss: 0.6871551702030344
Epoch: 16 | Iteration number: [3070/4518] 67% | Training loss: 0.6871514869241062
Epoch: 16 | Iteration number: [3080/4518] 68% | Training loss: 0.6871526383153804
Epoch: 16 | Iteration number: [3090/4518] 68% | Training loss: 0.6871529180255137
Epoch: 16 | Iteration number: [3100/4518] 68% | Training loss: 0.6871562205783782
Epoch: 16 | Iteration number: [3110/4518] 68% | Training loss: 0.6871574530455844
Epoch: 16 | Iteration number: [3120/4518] 69% | Training loss: 0.6871546676907784
Epoch: 16 | Iteration number: [3130/4518] 69% | Training loss: 0.6871535021466569
Epoch: 16 | Iteration number: [3140/4518] 69% | Training loss: 0.687155391285374
Epoch: 16 | Iteration number: [3150/4518] 69% | Training loss: 0.6871504308306982
Epoch: 16 | Iteration number: [3160/4518] 69% | Training loss: 0.6871492961539498
Epoch: 16 | Iteration number: [3170/4518] 70% | Training loss: 0.6871505922511549
Epoch: 16 | Iteration number: [3180/4518] 70% | Training loss: 0.6871516710557278
Epoch: 16 | Iteration number: [3190/4518] 70% | Training loss: 0.6871471237239419
Epoch: 16 | Iteration number: [3200/4518] 70% | Training loss: 0.6871447594091297
Epoch: 16 | Iteration number: [3210/4518] 71% | Training loss: 0.6871433426472257
Epoch: 16 | Iteration number: [3220/4518] 71% | Training loss: 0.6871448318595471
Epoch: 16 | Iteration number: [3230/4518] 71% | Training loss: 0.6871409387042279
Epoch: 16 | Iteration number: [3240/4518] 71% | Training loss: 0.6871404968294097
Epoch: 16 | Iteration number: [3250/4518] 71% | Training loss: 0.6871421333276309
Epoch: 16 | Iteration number: [3260/4518] 72% | Training loss: 0.6871407635738513
Epoch: 16 | Iteration number: [3270/4518] 72% | Training loss: 0.687137200416775
Epoch: 16 | Iteration number: [3280/4518] 72% | Training loss: 0.6871387265440895
Epoch: 16 | Iteration number: [3290/4518] 72% | Training loss: 0.6871389204970246
Epoch: 16 | Iteration number: [3300/4518] 73% | Training loss: 0.68714336290504
Epoch: 16 | Iteration number: [3310/4518] 73% | Training loss: 0.6871428925285167
Epoch: 16 | Iteration number: [3320/4518] 73% | Training loss: 0.6871421674109367
Epoch: 16 | Iteration number: [3330/4518] 73% | Training loss: 0.6871422670803986
Epoch: 16 | Iteration number: [3340/4518] 73% | Training loss: 0.6871424246690945
Epoch: 16 | Iteration number: [3350/4518] 74% | Training loss: 0.6871404860802551
Epoch: 16 | Iteration number: [3360/4518] 74% | Training loss: 0.6871394105787788
Epoch: 16 | Iteration number: [3370/4518] 74% | Training loss: 0.6871351479953404
Epoch: 16 | Iteration number: [3380/4518] 74% | Training loss: 0.6871355868655549
Epoch: 16 | Iteration number: [3390/4518] 75% | Training loss: 0.6871356465471881
Epoch: 16 | Iteration number: [3400/4518] 75% | Training loss: 0.6871377576624645
Epoch: 16 | Iteration number: [3410/4518] 75% | Training loss: 0.6871352484673698
Epoch: 16 | Iteration number: [3420/4518] 75% | Training loss: 0.687133058400182
Epoch: 16 | Iteration number: [3430/4518] 75% | Training loss: 0.6871308814158592
Epoch: 16 | Iteration number: [3440/4518] 76% | Training loss: 0.6871305243913517
Epoch: 16 | Iteration number: [3450/4518] 76% | Training loss: 0.6871322205446768
Epoch: 16 | Iteration number: [3460/4518] 76% | Training loss: 0.6871338832068306
Epoch: 16 | Iteration number: [3470/4518] 76% | Training loss: 0.6871333866023193
Epoch: 16 | Iteration number: [3480/4518] 77% | Training loss: 0.6871280981035068
Epoch: 16 | Iteration number: [3490/4518] 77% | Training loss: 0.6871227297024604
Epoch: 16 | Iteration number: [3500/4518] 77% | Training loss: 0.6871233068874905
Epoch: 16 | Iteration number: [3510/4518] 77% | Training loss: 0.6871247131600339
Epoch: 16 | Iteration number: [3520/4518] 77% | Training loss: 0.6871263577010144
Epoch: 16 | Iteration number: [3530/4518] 78% | Training loss: 0.6871252436813484
Epoch: 16 | Iteration number: [3540/4518] 78% | Training loss: 0.6871268504083493
Epoch: 16 | Iteration number: [3550/4518] 78% | Training loss: 0.6871222976395781
Epoch: 16 | Iteration number: [3560/4518] 78% | Training loss: 0.6871181455388498
Epoch: 16 | Iteration number: [3570/4518] 79% | Training loss: 0.6871177087811863
Epoch: 16 | Iteration number: [3580/4518] 79% | Training loss: 0.6871193091962591
Epoch: 16 | Iteration number: [3590/4518] 79% | Training loss: 0.6871186764459424
Epoch: 16 | Iteration number: [3600/4518] 79% | Training loss: 0.6871186053752899
Epoch: 16 | Iteration number: [3610/4518] 79% | Training loss: 0.6871194124386911
Epoch: 16 | Iteration number: [3620/4518] 80% | Training loss: 0.6871191930046398
Epoch: 16 | Iteration number: [3630/4518] 80% | Training loss: 0.6871179602362892
Epoch: 16 | Iteration number: [3640/4518] 80% | Training loss: 0.6871157486523901
Epoch: 16 | Iteration number: [3650/4518] 80% | Training loss: 0.6871152582070599
Epoch: 16 | Iteration number: [3660/4518] 81% | Training loss: 0.6871142938163111
Epoch: 16 | Iteration number: [3670/4518] 81% | Training loss: 0.6871188860823089
Epoch: 16 | Iteration number: [3680/4518] 81% | Training loss: 0.6871173403185347
Epoch: 16 | Iteration number: [3690/4518] 81% | Training loss: 0.6871160024711434
Epoch: 16 | Iteration number: [3700/4518] 81% | Training loss: 0.6871176248949927
Epoch: 16 | Iteration number: [3710/4518] 82% | Training loss: 0.6871186840084363
Epoch: 16 | Iteration number: [3720/4518] 82% | Training loss: 0.6871211277060612
Epoch: 16 | Iteration number: [3730/4518] 82% | Training loss: 0.6871230072054723
Epoch: 16 | Iteration number: [3740/4518] 82% | Training loss: 0.6871209701114798
Epoch: 16 | Iteration number: [3750/4518] 83% | Training loss: 0.6871183244069418
Epoch: 16 | Iteration number: [3760/4518] 83% | Training loss: 0.6871204002423489
Epoch: 16 | Iteration number: [3770/4518] 83% | Training loss: 0.6871183413567531
Epoch: 16 | Iteration number: [3780/4518] 83% | Training loss: 0.6871214912524299
Epoch: 16 | Iteration number: [3790/4518] 83% | Training loss: 0.6871167218622243
Epoch: 16 | Iteration number: [3800/4518] 84% | Training loss: 0.6871153444522305
Epoch: 16 | Iteration number: [3810/4518] 84% | Training loss: 0.6871148190629763
Epoch: 16 | Iteration number: [3820/4518] 84% | Training loss: 0.687114134914588
Epoch: 16 | Iteration number: [3830/4518] 84% | Training loss: 0.687113924406216
Epoch: 16 | Iteration number: [3840/4518] 84% | Training loss: 0.6871109031916907
Epoch: 16 | Iteration number: [3850/4518] 85% | Training loss: 0.6871094697946077
Epoch: 16 | Iteration number: [3860/4518] 85% | Training loss: 0.6871094893451799
Epoch: 16 | Iteration number: [3870/4518] 85% | Training loss: 0.6871096814787665
Epoch: 16 | Iteration number: [3880/4518] 85% | Training loss: 0.687107864759632
Epoch: 16 | Iteration number: [3890/4518] 86% | Training loss: 0.6871048634187115
Epoch: 16 | Iteration number: [3900/4518] 86% | Training loss: 0.6871069447963666
Epoch: 16 | Iteration number: [3910/4518] 86% | Training loss: 0.6871050291811414
Epoch: 16 | Iteration number: [3920/4518] 86% | Training loss: 0.6871047038660973
Epoch: 16 | Iteration number: [3930/4518] 86% | Training loss: 0.6871053739965114
Epoch: 16 | Iteration number: [3940/4518] 87% | Training loss: 0.6871031679175227
Epoch: 16 | Iteration number: [3950/4518] 87% | Training loss: 0.6871028364459171
Epoch: 16 | Iteration number: [3960/4518] 87% | Training loss: 0.6871024663249652
Epoch: 16 | Iteration number: [3970/4518] 87% | Training loss: 0.6871008616700881
Epoch: 16 | Iteration number: [3980/4518] 88% | Training loss: 0.6871003257868877
Epoch: 16 | Iteration number: [3990/4518] 88% | Training loss: 0.6871017844007726
Epoch: 16 | Iteration number: [4000/4518] 88% | Training loss: 0.6871015368103981
Epoch: 16 | Iteration number: [4010/4518] 88% | Training loss: 0.6871022069989298
Epoch: 16 | Iteration number: [4020/4518] 88% | Training loss: 0.6871009268719166
Epoch: 16 | Iteration number: [4030/4518] 89% | Training loss: 0.687100468705369
Epoch: 16 | Iteration number: [4040/4518] 89% | Training loss: 0.6871003292132132
Epoch: 16 | Iteration number: [4050/4518] 89% | Training loss: 0.6871003733740912
Epoch: 16 | Iteration number: [4060/4518] 89% | Training loss: 0.6870981252986222
Epoch: 16 | Iteration number: [4070/4518] 90% | Training loss: 0.6870970167604067
Epoch: 16 | Iteration number: [4080/4518] 90% | Training loss: 0.6870986085750309
Epoch: 16 | Iteration number: [4090/4518] 90% | Training loss: 0.6870983858271741
Epoch: 16 | Iteration number: [4100/4518] 90% | Training loss: 0.6870980534902433
Epoch: 16 | Iteration number: [4110/4518] 90% | Training loss: 0.6870923952464639
Epoch: 16 | Iteration number: [4120/4518] 91% | Training loss: 0.6870944926894984
Epoch: 16 | Iteration number: [4130/4518] 91% | Training loss: 0.6870938520598932
Epoch: 16 | Iteration number: [4140/4518] 91% | Training loss: 0.6870959356499179
Epoch: 16 | Iteration number: [4150/4518] 91% | Training loss: 0.6870986478587231
Epoch: 16 | Iteration number: [4160/4518] 92% | Training loss: 0.687098486864796
Epoch: 16 | Iteration number: [4170/4518] 92% | Training loss: 0.6871014756836193
Epoch: 16 | Iteration number: [4180/4518] 92% | Training loss: 0.6871014573499917
Epoch: 16 | Iteration number: [4190/4518] 92% | Training loss: 0.6871045262972894
Epoch: 16 | Iteration number: [4200/4518] 92% | Training loss: 0.6871081093521345
Epoch: 16 | Iteration number: [4210/4518] 93% | Training loss: 0.6871098631634565
Epoch: 16 | Iteration number: [4220/4518] 93% | Training loss: 0.6871100371906542
Epoch: 16 | Iteration number: [4230/4518] 93% | Training loss: 0.6871138375560725
Epoch: 16 | Iteration number: [4240/4518] 93% | Training loss: 0.6871126892009995
Epoch: 16 | Iteration number: [4250/4518] 94% | Training loss: 0.6871101155281066
Epoch: 16 | Iteration number: [4260/4518] 94% | Training loss: 0.6871075688253546
Epoch: 16 | Iteration number: [4270/4518] 94% | Training loss: 0.6871055258520873
Epoch: 16 | Iteration number: [4280/4518] 94% | Training loss: 0.6871048196871704
Epoch: 16 | Iteration number: [4290/4518] 94% | Training loss: 0.6871045443144712
Epoch: 16 | Iteration number: [4300/4518] 95% | Training loss: 0.6871015697163205
Epoch: 16 | Iteration number: [4310/4518] 95% | Training loss: 0.6870963535563298
Epoch: 16 | Iteration number: [4320/4518] 95% | Training loss: 0.6870934326891546
Epoch: 16 | Iteration number: [4330/4518] 95% | Training loss: 0.6870925369218646
Epoch: 16 | Iteration number: [4340/4518] 96% | Training loss: 0.6870913668162263
Epoch: 16 | Iteration number: [4350/4518] 96% | Training loss: 0.6870904010054709
Epoch: 16 | Iteration number: [4360/4518] 96% | Training loss: 0.6870899327030969
Epoch: 16 | Iteration number: [4370/4518] 96% | Training loss: 0.6870899911466943
Epoch: 16 | Iteration number: [4380/4518] 96% | Training loss: 0.6870869735060218
Epoch: 16 | Iteration number: [4390/4518] 97% | Training loss: 0.6870863886791916
Epoch: 16 | Iteration number: [4400/4518] 97% | Training loss: 0.6870875365625728
Epoch: 16 | Iteration number: [4410/4518] 97% | Training loss: 0.6870890576552913
Epoch: 16 | Iteration number: [4420/4518] 97% | Training loss: 0.6870875529708905
Epoch: 16 | Iteration number: [4430/4518] 98% | Training loss: 0.6870870424178062
Epoch: 16 | Iteration number: [4440/4518] 98% | Training loss: 0.6870887658617518
Epoch: 16 | Iteration number: [4450/4518] 98% | Training loss: 0.6870891675252593
Epoch: 16 | Iteration number: [4460/4518] 98% | Training loss: 0.6870886844369862
Epoch: 16 | Iteration number: [4470/4518] 98% | Training loss: 0.6870846908631207
Epoch: 16 | Iteration number: [4480/4518] 99% | Training loss: 0.6870843918727977
Epoch: 16 | Iteration number: [4490/4518] 99% | Training loss: 0.6870835387627107
Epoch: 16 | Iteration number: [4500/4518] 99% | Training loss: 0.6870831937789917
Epoch: 16 | Iteration number: [4510/4518] 99% | Training loss: 0.6870816788625823

 End of epoch: 16 | Train Loss: 0.6869287943882244 | Training Time: 641 

 End of epoch: 16 | Eval Loss: 0.6901570935638583 | Evaluating Time: 17 
Epoch: 17 | Iteration number: [10/4518] 0% | Training loss: 0.7561948776245118
Epoch: 17 | Iteration number: [20/4518] 0% | Training loss: 0.7215479552745819
Epoch: 17 | Iteration number: [30/4518] 0% | Training loss: 0.7098146220048268
Epoch: 17 | Iteration number: [40/4518] 0% | Training loss: 0.7041800826787948
Epoch: 17 | Iteration number: [50/4518] 1% | Training loss: 0.7009511876106262
Epoch: 17 | Iteration number: [60/4518] 1% | Training loss: 0.6986817648013433
Epoch: 17 | Iteration number: [70/4518] 1% | Training loss: 0.6970451142106737
Epoch: 17 | Iteration number: [80/4518] 1% | Training loss: 0.695740707218647
Epoch: 17 | Iteration number: [90/4518] 1% | Training loss: 0.6945253299342261
Epoch: 17 | Iteration number: [100/4518] 2% | Training loss: 0.6937215137481689
Epoch: 17 | Iteration number: [110/4518] 2% | Training loss: 0.693050599640066
Epoch: 17 | Iteration number: [120/4518] 2% | Training loss: 0.6925649225711823
Epoch: 17 | Iteration number: [130/4518] 2% | Training loss: 0.6922071534853715
Epoch: 17 | Iteration number: [140/4518] 3% | Training loss: 0.691831391624042
Epoch: 17 | Iteration number: [150/4518] 3% | Training loss: 0.6914569131533305
Epoch: 17 | Iteration number: [160/4518] 3% | Training loss: 0.691245099902153
Epoch: 17 | Iteration number: [170/4518] 3% | Training loss: 0.6910086621256436
Epoch: 17 | Iteration number: [180/4518] 3% | Training loss: 0.690712547633383
Epoch: 17 | Iteration number: [190/4518] 4% | Training loss: 0.6905402390580428
Epoch: 17 | Iteration number: [200/4518] 4% | Training loss: 0.6902422794699669
Epoch: 17 | Iteration number: [210/4518] 4% | Training loss: 0.6900709489981334
Epoch: 17 | Iteration number: [220/4518] 4% | Training loss: 0.6899061853235419
Epoch: 17 | Iteration number: [230/4518] 5% | Training loss: 0.689791000407675
Epoch: 17 | Iteration number: [240/4518] 5% | Training loss: 0.6896479082604249
Epoch: 17 | Iteration number: [250/4518] 5% | Training loss: 0.6895707957744598
Epoch: 17 | Iteration number: [260/4518] 5% | Training loss: 0.6894049791189341
Epoch: 17 | Iteration number: [270/4518] 5% | Training loss: 0.6893017877031256
Epoch: 17 | Iteration number: [280/4518] 6% | Training loss: 0.6892558485269547
Epoch: 17 | Iteration number: [290/4518] 6% | Training loss: 0.689208310020381
Epoch: 17 | Iteration number: [300/4518] 6% | Training loss: 0.6891108491023381
Epoch: 17 | Iteration number: [310/4518] 6% | Training loss: 0.6890569308111745
Epoch: 17 | Iteration number: [320/4518] 7% | Training loss: 0.6890004856511951
Epoch: 17 | Iteration number: [330/4518] 7% | Training loss: 0.6889725659832809
Epoch: 17 | Iteration number: [340/4518] 7% | Training loss: 0.6889592786045635
Epoch: 17 | Iteration number: [350/4518] 7% | Training loss: 0.6889020533221109
Epoch: 17 | Iteration number: [360/4518] 7% | Training loss: 0.6888259169128206
Epoch: 17 | Iteration number: [370/4518] 8% | Training loss: 0.688784308046908
Epoch: 17 | Iteration number: [380/4518] 8% | Training loss: 0.6887414075826344
Epoch: 17 | Iteration number: [390/4518] 8% | Training loss: 0.6886853904296191
Epoch: 17 | Iteration number: [400/4518] 8% | Training loss: 0.6886359655857086
Epoch: 17 | Iteration number: [410/4518] 9% | Training loss: 0.6886034222637735
Epoch: 17 | Iteration number: [420/4518] 9% | Training loss: 0.6885676463445027
Epoch: 17 | Iteration number: [430/4518] 9% | Training loss: 0.6885252576927806
Epoch: 17 | Iteration number: [440/4518] 9% | Training loss: 0.6884809400547635
Epoch: 17 | Iteration number: [450/4518] 9% | Training loss: 0.6884431835015615
Epoch: 17 | Iteration number: [460/4518] 10% | Training loss: 0.6884025324945865
Epoch: 17 | Iteration number: [470/4518] 10% | Training loss: 0.6883886751976419
Epoch: 17 | Iteration number: [480/4518] 10% | Training loss: 0.6883969583859046
Epoch: 17 | Iteration number: [490/4518] 10% | Training loss: 0.6883585847153956
Epoch: 17 | Iteration number: [500/4518] 11% | Training loss: 0.6883432314395904
Epoch: 17 | Iteration number: [510/4518] 11% | Training loss: 0.6883144363468768
Epoch: 17 | Iteration number: [520/4518] 11% | Training loss: 0.68828102430472
Epoch: 17 | Iteration number: [530/4518] 11% | Training loss: 0.6882694130798556
Epoch: 17 | Iteration number: [540/4518] 11% | Training loss: 0.6882399373584324
Epoch: 17 | Iteration number: [550/4518] 12% | Training loss: 0.6882247346097773
Epoch: 17 | Iteration number: [560/4518] 12% | Training loss: 0.6882238941533225
Epoch: 17 | Iteration number: [570/4518] 12% | Training loss: 0.6881719186640622
Epoch: 17 | Iteration number: [580/4518] 12% | Training loss: 0.6881322485619578
Epoch: 17 | Iteration number: [590/4518] 13% | Training loss: 0.6881067774053348
Epoch: 17 | Iteration number: [600/4518] 13% | Training loss: 0.6880880142251651
Epoch: 17 | Iteration number: [610/4518] 13% | Training loss: 0.6880957058218659
Epoch: 17 | Iteration number: [620/4518] 13% | Training loss: 0.6880828415193866
Epoch: 17 | Iteration number: [630/4518] 13% | Training loss: 0.6880525348678468
Epoch: 17 | Iteration number: [640/4518] 14% | Training loss: 0.6880566652864217
Epoch: 17 | Iteration number: [650/4518] 14% | Training loss: 0.6880517372718225
Epoch: 17 | Iteration number: [660/4518] 14% | Training loss: 0.6880439003308614
Epoch: 17 | Iteration number: [670/4518] 14% | Training loss: 0.6880346177229241
Epoch: 17 | Iteration number: [680/4518] 15% | Training loss: 0.6880143677487093
Epoch: 17 | Iteration number: [690/4518] 15% | Training loss: 0.6879836337289948
Epoch: 17 | Iteration number: [700/4518] 15% | Training loss: 0.6879706807647432
Epoch: 17 | Iteration number: [710/4518] 15% | Training loss: 0.6879406588178285
Epoch: 17 | Iteration number: [720/4518] 15% | Training loss: 0.6879169796903928
Epoch: 17 | Iteration number: [730/4518] 16% | Training loss: 0.6878904271615695
Epoch: 17 | Iteration number: [740/4518] 16% | Training loss: 0.6878685794166617
Epoch: 17 | Iteration number: [750/4518] 16% | Training loss: 0.6878402714729309
Epoch: 17 | Iteration number: [760/4518] 16% | Training loss: 0.687815381272843
Epoch: 17 | Iteration number: [770/4518] 17% | Training loss: 0.687795362534461
Epoch: 17 | Iteration number: [780/4518] 17% | Training loss: 0.687791717510957
Epoch: 17 | Iteration number: [790/4518] 17% | Training loss: 0.6877716824978213
Epoch: 17 | Iteration number: [800/4518] 17% | Training loss: 0.6877587839961052
Epoch: 17 | Iteration number: [810/4518] 17% | Training loss: 0.687747840380963
Epoch: 17 | Iteration number: [820/4518] 18% | Training loss: 0.6877484035201189
Epoch: 17 | Iteration number: [830/4518] 18% | Training loss: 0.68771930789373
Epoch: 17 | Iteration number: [840/4518] 18% | Training loss: 0.6877094548372995
Epoch: 17 | Iteration number: [850/4518] 18% | Training loss: 0.687703550563139
Epoch: 17 | Iteration number: [860/4518] 19% | Training loss: 0.6877099190340485
Epoch: 17 | Iteration number: [870/4518] 19% | Training loss: 0.6877018503073988
Epoch: 17 | Iteration number: [880/4518] 19% | Training loss: 0.6876926079392434
Epoch: 17 | Iteration number: [890/4518] 19% | Training loss: 0.6876808915245399
Epoch: 17 | Iteration number: [900/4518] 19% | Training loss: 0.6876783278253343
Epoch: 17 | Iteration number: [910/4518] 20% | Training loss: 0.6876699586491009
Epoch: 17 | Iteration number: [920/4518] 20% | Training loss: 0.6876725016080815
Epoch: 17 | Iteration number: [930/4518] 20% | Training loss: 0.6876512998534787
Epoch: 17 | Iteration number: [940/4518] 20% | Training loss: 0.6876473016561346
Epoch: 17 | Iteration number: [950/4518] 21% | Training loss: 0.6876327690952703
Epoch: 17 | Iteration number: [960/4518] 21% | Training loss: 0.687623176102837
Epoch: 17 | Iteration number: [970/4518] 21% | Training loss: 0.6876118856607024
Epoch: 17 | Iteration number: [980/4518] 21% | Training loss: 0.6876085167636676
Epoch: 17 | Iteration number: [990/4518] 21% | Training loss: 0.6875952142055588
Epoch: 17 | Iteration number: [1000/4518] 22% | Training loss: 0.68758388453722
Epoch: 17 | Iteration number: [1010/4518] 22% | Training loss: 0.6875694287295389
Epoch: 17 | Iteration number: [1020/4518] 22% | Training loss: 0.6875659150235793
Epoch: 17 | Iteration number: [1030/4518] 22% | Training loss: 0.6875771380165249
Epoch: 17 | Iteration number: [1040/4518] 23% | Training loss: 0.6875690350165734
Epoch: 17 | Iteration number: [1050/4518] 23% | Training loss: 0.6875681773821513
Epoch: 17 | Iteration number: [1060/4518] 23% | Training loss: 0.6875665130480281
Epoch: 17 | Iteration number: [1070/4518] 23% | Training loss: 0.6875718161324474
Epoch: 17 | Iteration number: [1080/4518] 23% | Training loss: 0.6875633328049271
Epoch: 17 | Iteration number: [1090/4518] 24% | Training loss: 0.6875698904378699
Epoch: 17 | Iteration number: [1100/4518] 24% | Training loss: 0.6875654837760058
Epoch: 17 | Iteration number: [1110/4518] 24% | Training loss: 0.6875628779063354
Epoch: 17 | Iteration number: [1120/4518] 24% | Training loss: 0.6875609009925808
Epoch: 17 | Iteration number: [1130/4518] 25% | Training loss: 0.6875488921076851
Epoch: 17 | Iteration number: [1140/4518] 25% | Training loss: 0.687548914760874
Epoch: 17 | Iteration number: [1150/4518] 25% | Training loss: 0.6875428518005039
Epoch: 17 | Iteration number: [1160/4518] 25% | Training loss: 0.6875376222462489
Epoch: 17 | Iteration number: [1170/4518] 25% | Training loss: 0.6875325084242047
Epoch: 17 | Iteration number: [1180/4518] 26% | Training loss: 0.6875271015248057
Epoch: 17 | Iteration number: [1190/4518] 26% | Training loss: 0.6875263526660054
Epoch: 17 | Iteration number: [1200/4518] 26% | Training loss: 0.6875231988728047
Epoch: 17 | Iteration number: [1210/4518] 26% | Training loss: 0.6875177233672339
Epoch: 17 | Iteration number: [1220/4518] 27% | Training loss: 0.6875281327572025
Epoch: 17 | Iteration number: [1230/4518] 27% | Training loss: 0.6875346355806521
Epoch: 17 | Iteration number: [1240/4518] 27% | Training loss: 0.6875262034035499
Epoch: 17 | Iteration number: [1250/4518] 27% | Training loss: 0.6875248753070832
Epoch: 17 | Iteration number: [1260/4518] 27% | Training loss: 0.6875341855817371
Epoch: 17 | Iteration number: [1270/4518] 28% | Training loss: 0.687532404417128
Epoch: 17 | Iteration number: [1280/4518] 28% | Training loss: 0.6875429659616202
Epoch: 17 | Iteration number: [1290/4518] 28% | Training loss: 0.6875358807024106
Epoch: 17 | Iteration number: [1300/4518] 28% | Training loss: 0.6875326732947277
Epoch: 17 | Iteration number: [1310/4518] 28% | Training loss: 0.6875439849518638
Epoch: 17 | Iteration number: [1320/4518] 29% | Training loss: 0.6875407949993104
Epoch: 17 | Iteration number: [1330/4518] 29% | Training loss: 0.6875309538572354
Epoch: 17 | Iteration number: [1340/4518] 29% | Training loss: 0.6875300527063768
Epoch: 17 | Iteration number: [1350/4518] 29% | Training loss: 0.6875149944093493
Epoch: 17 | Iteration number: [1360/4518] 30% | Training loss: 0.6875045028679511
Epoch: 17 | Iteration number: [1370/4518] 30% | Training loss: 0.6874969311004138
Epoch: 17 | Iteration number: [1380/4518] 30% | Training loss: 0.6874910093735958
Epoch: 17 | Iteration number: [1390/4518] 30% | Training loss: 0.6874927197857726
Epoch: 17 | Iteration number: [1400/4518] 30% | Training loss: 0.687484424837998
Epoch: 17 | Iteration number: [1410/4518] 31% | Training loss: 0.6874804841711166
Epoch: 17 | Iteration number: [1420/4518] 31% | Training loss: 0.6874779336889025
Epoch: 17 | Iteration number: [1430/4518] 31% | Training loss: 0.6874709410267277
Epoch: 17 | Iteration number: [1440/4518] 31% | Training loss: 0.6874542796777354
Epoch: 17 | Iteration number: [1450/4518] 32% | Training loss: 0.6874465259190263
Epoch: 17 | Iteration number: [1460/4518] 32% | Training loss: 0.6874496270124226
Epoch: 17 | Iteration number: [1470/4518] 32% | Training loss: 0.6874420213861531
Epoch: 17 | Iteration number: [1480/4518] 32% | Training loss: 0.6874332919314101
Epoch: 17 | Iteration number: [1490/4518] 32% | Training loss: 0.6874146135861442
Epoch: 17 | Iteration number: [1500/4518] 33% | Training loss: 0.6874057480891546
Epoch: 17 | Iteration number: [1510/4518] 33% | Training loss: 0.6874051038003126
Epoch: 17 | Iteration number: [1520/4518] 33% | Training loss: 0.6873961118098937
Epoch: 17 | Iteration number: [1530/4518] 33% | Training loss: 0.6873936523409451
Epoch: 17 | Iteration number: [1540/4518] 34% | Training loss: 0.6873887066330229
Epoch: 17 | Iteration number: [1550/4518] 34% | Training loss: 0.687384117995539
Epoch: 17 | Iteration number: [1560/4518] 34% | Training loss: 0.6873856308368537
Epoch: 17 | Iteration number: [1570/4518] 34% | Training loss: 0.6873899923008718
Epoch: 17 | Iteration number: [1580/4518] 34% | Training loss: 0.6873888424680202
Epoch: 17 | Iteration number: [1590/4518] 35% | Training loss: 0.6873864053930127
Epoch: 17 | Iteration number: [1600/4518] 35% | Training loss: 0.6873773948103189
Epoch: 17 | Iteration number: [1610/4518] 35% | Training loss: 0.6873761786437182
Epoch: 17 | Iteration number: [1620/4518] 35% | Training loss: 0.6873705258707942
Epoch: 17 | Iteration number: [1630/4518] 36% | Training loss: 0.6873721452944118
Epoch: 17 | Iteration number: [1640/4518] 36% | Training loss: 0.6873664569927425
Epoch: 17 | Iteration number: [1650/4518] 36% | Training loss: 0.687363888278152
Epoch: 17 | Iteration number: [1660/4518] 36% | Training loss: 0.687363836528307
Epoch: 17 | Iteration number: [1670/4518] 36% | Training loss: 0.6873601015099509
Epoch: 17 | Iteration number: [1680/4518] 37% | Training loss: 0.6873593559577351
Epoch: 17 | Iteration number: [1690/4518] 37% | Training loss: 0.687354888542164
Epoch: 17 | Iteration number: [1700/4518] 37% | Training loss: 0.6873572250674752
Epoch: 17 | Iteration number: [1710/4518] 37% | Training loss: 0.6873526252849758
Epoch: 17 | Iteration number: [1720/4518] 38% | Training loss: 0.6873553700225298
Epoch: 17 | Iteration number: [1730/4518] 38% | Training loss: 0.6873551212294253
Epoch: 17 | Iteration number: [1740/4518] 38% | Training loss: 0.6873460340431367
Epoch: 17 | Iteration number: [1750/4518] 38% | Training loss: 0.6873390847614833
Epoch: 17 | Iteration number: [1760/4518] 38% | Training loss: 0.68733258606358
Epoch: 17 | Iteration number: [1770/4518] 39% | Training loss: 0.68732683012041
Epoch: 17 | Iteration number: [1780/4518] 39% | Training loss: 0.6873238891028286
Epoch: 17 | Iteration number: [1790/4518] 39% | Training loss: 0.687318576614284
Epoch: 17 | Iteration number: [1800/4518] 39% | Training loss: 0.6873199210564296
Epoch: 17 | Iteration number: [1810/4518] 40% | Training loss: 0.6873242748047107
Epoch: 17 | Iteration number: [1820/4518] 40% | Training loss: 0.6873193229292776
Epoch: 17 | Iteration number: [1830/4518] 40% | Training loss: 0.6873115611532347
Epoch: 17 | Iteration number: [1840/4518] 40% | Training loss: 0.6873101134663043
Epoch: 17 | Iteration number: [1850/4518] 40% | Training loss: 0.6873129622034124
Epoch: 17 | Iteration number: [1860/4518] 41% | Training loss: 0.6873065127800869
Epoch: 17 | Iteration number: [1870/4518] 41% | Training loss: 0.6873111683735873
Epoch: 17 | Iteration number: [1880/4518] 41% | Training loss: 0.6873099734174445
Epoch: 17 | Iteration number: [1890/4518] 41% | Training loss: 0.6873040056102491
Epoch: 17 | Iteration number: [1900/4518] 42% | Training loss: 0.6873013323545456
Epoch: 17 | Iteration number: [1910/4518] 42% | Training loss: 0.687303010206572
Epoch: 17 | Iteration number: [1920/4518] 42% | Training loss: 0.6872997178385655
Epoch: 17 | Iteration number: [1930/4518] 42% | Training loss: 0.687301297138392
Epoch: 17 | Iteration number: [1940/4518] 42% | Training loss: 0.6872987684208093
Epoch: 17 | Iteration number: [1950/4518] 43% | Training loss: 0.6873016904867613
Epoch: 17 | Iteration number: [1960/4518] 43% | Training loss: 0.6873031021685017
Epoch: 17 | Iteration number: [1970/4518] 43% | Training loss: 0.6873050903003228
Epoch: 17 | Iteration number: [1980/4518] 43% | Training loss: 0.6873057958453592
Epoch: 17 | Iteration number: [1990/4518] 44% | Training loss: 0.6873082617119928
Epoch: 17 | Iteration number: [2000/4518] 44% | Training loss: 0.6873121562600136
Epoch: 17 | Iteration number: [2010/4518] 44% | Training loss: 0.6873137785724146
Epoch: 17 | Iteration number: [2020/4518] 44% | Training loss: 0.6873144202303179
Epoch: 17 | Iteration number: [2030/4518] 44% | Training loss: 0.6873145362426495
Epoch: 17 | Iteration number: [2040/4518] 45% | Training loss: 0.6873146960256147
Epoch: 17 | Iteration number: [2050/4518] 45% | Training loss: 0.6873117618153735
Epoch: 17 | Iteration number: [2060/4518] 45% | Training loss: 0.687307036009807
Epoch: 17 | Iteration number: [2070/4518] 45% | Training loss: 0.6873076974193831
Epoch: 17 | Iteration number: [2080/4518] 46% | Training loss: 0.6873062849617921
Epoch: 17 | Iteration number: [2090/4518] 46% | Training loss: 0.687305775869406
Epoch: 17 | Iteration number: [2100/4518] 46% | Training loss: 0.6873081947792145
Epoch: 17 | Iteration number: [2110/4518] 46% | Training loss: 0.6873101278503925
Epoch: 17 | Iteration number: [2120/4518] 46% | Training loss: 0.6873086895020503
Epoch: 17 | Iteration number: [2130/4518] 47% | Training loss: 0.6873086274229865
Epoch: 17 | Iteration number: [2140/4518] 47% | Training loss: 0.6873055476451588
Epoch: 17 | Iteration number: [2150/4518] 47% | Training loss: 0.687303891542346
Epoch: 17 | Iteration number: [2160/4518] 47% | Training loss: 0.6873061508216239
Epoch: 17 | Iteration number: [2170/4518] 48% | Training loss: 0.6873038144430257
Epoch: 17 | Iteration number: [2180/4518] 48% | Training loss: 0.6873015208528677
Epoch: 17 | Iteration number: [2190/4518] 48% | Training loss: 0.6872936549252027
Epoch: 17 | Iteration number: [2200/4518] 48% | Training loss: 0.6872921402616934
Epoch: 17 | Iteration number: [2210/4518] 48% | Training loss: 0.6872834613420306
Epoch: 17 | Iteration number: [2220/4518] 49% | Training loss: 0.6872845034341555
Epoch: 17 | Iteration number: [2230/4518] 49% | Training loss: 0.6872775665045854
Epoch: 17 | Iteration number: [2240/4518] 49% | Training loss: 0.6872783078679017
Epoch: 17 | Iteration number: [2250/4518] 49% | Training loss: 0.6872741415235731
Epoch: 17 | Iteration number: [2260/4518] 50% | Training loss: 0.6872748606236635
Epoch: 17 | Iteration number: [2270/4518] 50% | Training loss: 0.6872774557920279
Epoch: 17 | Iteration number: [2280/4518] 50% | Training loss: 0.6872708850785305
Epoch: 17 | Iteration number: [2290/4518] 50% | Training loss: 0.6872674872260948
Epoch: 17 | Iteration number: [2300/4518] 50% | Training loss: 0.6872699011408765
Epoch: 17 | Iteration number: [2310/4518] 51% | Training loss: 0.6872658643371615
Epoch: 17 | Iteration number: [2320/4518] 51% | Training loss: 0.6872707139058359
Epoch: 17 | Iteration number: [2330/4518] 51% | Training loss: 0.687269183213107
Epoch: 17 | Iteration number: [2340/4518] 51% | Training loss: 0.6872738047542735
Epoch: 17 | Iteration number: [2350/4518] 52% | Training loss: 0.6872687420439213
Epoch: 17 | Iteration number: [2360/4518] 52% | Training loss: 0.6872714180562456
Epoch: 17 | Iteration number: [2370/4518] 52% | Training loss: 0.6872666999509063
Epoch: 17 | Iteration number: [2380/4518] 52% | Training loss: 0.6872688390627628
Epoch: 17 | Iteration number: [2390/4518] 52% | Training loss: 0.6872680398460213
Epoch: 17 | Iteration number: [2400/4518] 53% | Training loss: 0.6872663778066636
Epoch: 17 | Iteration number: [2410/4518] 53% | Training loss: 0.6872654585422817
Epoch: 17 | Iteration number: [2420/4518] 53% | Training loss: 0.6872598365811277
Epoch: 17 | Iteration number: [2430/4518] 53% | Training loss: 0.6872613785198196
Epoch: 17 | Iteration number: [2440/4518] 54% | Training loss: 0.6872515636145091
Epoch: 17 | Iteration number: [2450/4518] 54% | Training loss: 0.687254637528439
Epoch: 17 | Iteration number: [2460/4518] 54% | Training loss: 0.6872561452592292
Epoch: 17 | Iteration number: [2470/4518] 54% | Training loss: 0.6872534875927666
Epoch: 17 | Iteration number: [2480/4518] 54% | Training loss: 0.6872510213284723
Epoch: 17 | Iteration number: [2490/4518] 55% | Training loss: 0.687246232722179
Epoch: 17 | Iteration number: [2500/4518] 55% | Training loss: 0.6872408438205719
Epoch: 17 | Iteration number: [2510/4518] 55% | Training loss: 0.6872408024818298
Epoch: 17 | Iteration number: [2520/4518] 55% | Training loss: 0.6872402112162302
Epoch: 17 | Iteration number: [2530/4518] 55% | Training loss: 0.6872379016970457
Epoch: 17 | Iteration number: [2540/4518] 56% | Training loss: 0.6872394879033247
Epoch: 17 | Iteration number: [2550/4518] 56% | Training loss: 0.6872386411825816
Epoch: 17 | Iteration number: [2560/4518] 56% | Training loss: 0.6872361446497962
Epoch: 17 | Iteration number: [2570/4518] 56% | Training loss: 0.6872324719503232
Epoch: 17 | Iteration number: [2580/4518] 57% | Training loss: 0.6872305028891379
Epoch: 17 | Iteration number: [2590/4518] 57% | Training loss: 0.6872275875111804
Epoch: 17 | Iteration number: [2600/4518] 57% | Training loss: 0.6872265727474139
Epoch: 17 | Iteration number: [2610/4518] 57% | Training loss: 0.6872220974315628
Epoch: 17 | Iteration number: [2620/4518] 57% | Training loss: 0.6872205537011605
Epoch: 17 | Iteration number: [2630/4518] 58% | Training loss: 0.6872194845866795
Epoch: 17 | Iteration number: [2640/4518] 58% | Training loss: 0.6872168808498166
Epoch: 17 | Iteration number: [2650/4518] 58% | Training loss: 0.6872176092975545
Epoch: 17 | Iteration number: [2660/4518] 58% | Training loss: 0.6872240248031186
Epoch: 17 | Iteration number: [2670/4518] 59% | Training loss: 0.6872240720393505
Epoch: 17 | Iteration number: [2680/4518] 59% | Training loss: 0.6872245982289314
Epoch: 17 | Iteration number: [2690/4518] 59% | Training loss: 0.6872226192162383
Epoch: 17 | Iteration number: [2700/4518] 59% | Training loss: 0.6872207901433662
Epoch: 17 | Iteration number: [2710/4518] 59% | Training loss: 0.687218454865072
Epoch: 17 | Iteration number: [2720/4518] 60% | Training loss: 0.6872215442797717
Epoch: 17 | Iteration number: [2730/4518] 60% | Training loss: 0.6872176062929761
Epoch: 17 | Iteration number: [2740/4518] 60% | Training loss: 0.6872206754928087
Epoch: 17 | Iteration number: [2750/4518] 60% | Training loss: 0.6872199384949425
Epoch: 17 | Iteration number: [2760/4518] 61% | Training loss: 0.6872158812224001
Epoch: 17 | Iteration number: [2770/4518] 61% | Training loss: 0.6872160424179119
Epoch: 17 | Iteration number: [2780/4518] 61% | Training loss: 0.6872140620037807
Epoch: 17 | Iteration number: [2790/4518] 61% | Training loss: 0.6872090022196479
Epoch: 17 | Iteration number: [2800/4518] 61% | Training loss: 0.6872010440485818
Epoch: 17 | Iteration number: [2810/4518] 62% | Training loss: 0.6872025711044298
Epoch: 17 | Iteration number: [2820/4518] 62% | Training loss: 0.6872036594025632
Epoch: 17 | Iteration number: [2830/4518] 62% | Training loss: 0.6872041500499307
Epoch: 17 | Iteration number: [2840/4518] 62% | Training loss: 0.6872020172611089
Epoch: 17 | Iteration number: [2850/4518] 63% | Training loss: 0.6871966241535388
Epoch: 17 | Iteration number: [2860/4518] 63% | Training loss: 0.687196717604057
Epoch: 17 | Iteration number: [2870/4518] 63% | Training loss: 0.6871912903902008
Epoch: 17 | Iteration number: [2880/4518] 63% | Training loss: 0.6871885379155477
Epoch: 17 | Iteration number: [2890/4518] 63% | Training loss: 0.6871806975054493
Epoch: 17 | Iteration number: [2900/4518] 64% | Training loss: 0.6871816848269824
Epoch: 17 | Iteration number: [2910/4518] 64% | Training loss: 0.687182882274549
Epoch: 17 | Iteration number: [2920/4518] 64% | Training loss: 0.6871783855026715
Epoch: 17 | Iteration number: [2930/4518] 64% | Training loss: 0.6871786628973768
Epoch: 17 | Iteration number: [2940/4518] 65% | Training loss: 0.6871766391457343
Epoch: 17 | Iteration number: [2950/4518] 65% | Training loss: 0.6871767242480132
Epoch: 17 | Iteration number: [2960/4518] 65% | Training loss: 0.6871732614733077
Epoch: 17 | Iteration number: [2970/4518] 65% | Training loss: 0.6871775694567748
Epoch: 17 | Iteration number: [2980/4518] 65% | Training loss: 0.687174861203104
Epoch: 17 | Iteration number: [2990/4518] 66% | Training loss: 0.6871746061836995
Epoch: 17 | Iteration number: [3000/4518] 66% | Training loss: 0.6871760823329289
Epoch: 17 | Iteration number: [3010/4518] 66% | Training loss: 0.6871723367526286
Epoch: 17 | Iteration number: [3020/4518] 66% | Training loss: 0.6871728507296139
Epoch: 17 | Iteration number: [3030/4518] 67% | Training loss: 0.6871746066773292
Epoch: 17 | Iteration number: [3040/4518] 67% | Training loss: 0.6871760477753062
Epoch: 17 | Iteration number: [3050/4518] 67% | Training loss: 0.6871758426212874
Epoch: 17 | Iteration number: [3060/4518] 67% | Training loss: 0.6871749398949879
Epoch: 17 | Iteration number: [3070/4518] 67% | Training loss: 0.6871688434083609
Epoch: 17 | Iteration number: [3080/4518] 68% | Training loss: 0.6871695991653901
Epoch: 17 | Iteration number: [3090/4518] 68% | Training loss: 0.6871657773514781
Epoch: 17 | Iteration number: [3100/4518] 68% | Training loss: 0.6871648419864717
Epoch: 17 | Iteration number: [3110/4518] 68% | Training loss: 0.6871672807207445
Epoch: 17 | Iteration number: [3120/4518] 69% | Training loss: 0.6871686690892929
Epoch: 17 | Iteration number: [3130/4518] 69% | Training loss: 0.6871659238308002
Epoch: 17 | Iteration number: [3140/4518] 69% | Training loss: 0.6871665708198669
Epoch: 17 | Iteration number: [3150/4518] 69% | Training loss: 0.6871682403958033
Epoch: 17 | Iteration number: [3160/4518] 69% | Training loss: 0.6871663791658004
Epoch: 17 | Iteration number: [3170/4518] 70% | Training loss: 0.6871669422940877
Epoch: 17 | Iteration number: [3180/4518] 70% | Training loss: 0.6871642760323279
Epoch: 17 | Iteration number: [3190/4518] 70% | Training loss: 0.6871578446936831
Epoch: 17 | Iteration number: [3200/4518] 70% | Training loss: 0.6871561158820987
Epoch: 17 | Iteration number: [3210/4518] 71% | Training loss: 0.6871559998885122
Epoch: 17 | Iteration number: [3220/4518] 71% | Training loss: 0.6871549023234326
Epoch: 17 | Iteration number: [3230/4518] 71% | Training loss: 0.687152580081863
Epoch: 17 | Iteration number: [3240/4518] 71% | Training loss: 0.687144557395835
Epoch: 17 | Iteration number: [3250/4518] 71% | Training loss: 0.6871431935750522
Epoch: 17 | Iteration number: [3260/4518] 72% | Training loss: 0.6871445866633047
Epoch: 17 | Iteration number: [3270/4518] 72% | Training loss: 0.6871374007758744
Epoch: 17 | Iteration number: [3280/4518] 72% | Training loss: 0.6871396987358245
Epoch: 17 | Iteration number: [3290/4518] 72% | Training loss: 0.6871423800846725
Epoch: 17 | Iteration number: [3300/4518] 73% | Training loss: 0.6871423761049906
Epoch: 17 | Iteration number: [3310/4518] 73% | Training loss: 0.6871445440993929
Epoch: 17 | Iteration number: [3320/4518] 73% | Training loss: 0.6871429711400744
Epoch: 17 | Iteration number: [3330/4518] 73% | Training loss: 0.6871391292627868
Epoch: 17 | Iteration number: [3340/4518] 73% | Training loss: 0.6871405375039507
Epoch: 17 | Iteration number: [3350/4518] 74% | Training loss: 0.6871437816655458
Epoch: 17 | Iteration number: [3360/4518] 74% | Training loss: 0.6871400659992581
Epoch: 17 | Iteration number: [3370/4518] 74% | Training loss: 0.6871387026076501
Epoch: 17 | Iteration number: [3380/4518] 74% | Training loss: 0.6871364630361986
Epoch: 17 | Iteration number: [3390/4518] 75% | Training loss: 0.6871384929766697
Epoch: 17 | Iteration number: [3400/4518] 75% | Training loss: 0.6871376892924309
Epoch: 17 | Iteration number: [3410/4518] 75% | Training loss: 0.6871339893585776
Epoch: 17 | Iteration number: [3420/4518] 75% | Training loss: 0.6871360090915223
Epoch: 17 | Iteration number: [3430/4518] 75% | Training loss: 0.6871340516878635
Epoch: 17 | Iteration number: [3440/4518] 76% | Training loss: 0.6871315917996473
Epoch: 17 | Iteration number: [3450/4518] 76% | Training loss: 0.6871300001766371
Epoch: 17 | Iteration number: [3460/4518] 76% | Training loss: 0.687130348289633
Epoch: 17 | Iteration number: [3470/4518] 76% | Training loss: 0.6871344664426633
Epoch: 17 | Iteration number: [3480/4518] 77% | Training loss: 0.6871324082044349
Epoch: 17 | Iteration number: [3490/4518] 77% | Training loss: 0.687131264933884
Epoch: 17 | Iteration number: [3500/4518] 77% | Training loss: 0.6871314258064543
Epoch: 17 | Iteration number: [3510/4518] 77% | Training loss: 0.6871343332478124
Epoch: 17 | Iteration number: [3520/4518] 77% | Training loss: 0.6871366165747697
Epoch: 17 | Iteration number: [3530/4518] 78% | Training loss: 0.6871347648901575
Epoch: 17 | Iteration number: [3540/4518] 78% | Training loss: 0.6871342342957265
Epoch: 17 | Iteration number: [3550/4518] 78% | Training loss: 0.6871318068134953
Epoch: 17 | Iteration number: [3560/4518] 78% | Training loss: 0.687132550608576
Epoch: 17 | Iteration number: [3570/4518] 79% | Training loss: 0.6871343800500661
Epoch: 17 | Iteration number: [3580/4518] 79% | Training loss: 0.6871373889832523
Epoch: 17 | Iteration number: [3590/4518] 79% | Training loss: 0.6871352615296674
Epoch: 17 | Iteration number: [3600/4518] 79% | Training loss: 0.6871366491251522
Epoch: 17 | Iteration number: [3610/4518] 79% | Training loss: 0.6871339337812566
Epoch: 17 | Iteration number: [3620/4518] 80% | Training loss: 0.6871335461159438
Epoch: 17 | Iteration number: [3630/4518] 80% | Training loss: 0.6871297562746306
Epoch: 17 | Iteration number: [3640/4518] 80% | Training loss: 0.6871286366667066
Epoch: 17 | Iteration number: [3650/4518] 80% | Training loss: 0.687129825990494
Epoch: 17 | Iteration number: [3660/4518] 81% | Training loss: 0.6871285804145323
Epoch: 17 | Iteration number: [3670/4518] 81% | Training loss: 0.6871303929944779
Epoch: 17 | Iteration number: [3680/4518] 81% | Training loss: 0.6871302209470583
Epoch: 17 | Iteration number: [3690/4518] 81% | Training loss: 0.687129302916488
Epoch: 17 | Iteration number: [3700/4518] 81% | Training loss: 0.6871294735734527
Epoch: 17 | Iteration number: [3710/4518] 82% | Training loss: 0.6871277018216743
Epoch: 17 | Iteration number: [3720/4518] 82% | Training loss: 0.6871259691253785
Epoch: 17 | Iteration number: [3730/4518] 82% | Training loss: 0.6871252516479339
Epoch: 17 | Iteration number: [3740/4518] 82% | Training loss: 0.687126177278432
Epoch: 17 | Iteration number: [3750/4518] 83% | Training loss: 0.6871259551684061
Epoch: 17 | Iteration number: [3760/4518] 83% | Training loss: 0.6871251999222218
Epoch: 17 | Iteration number: [3770/4518] 83% | Training loss: 0.6871254417877298
Epoch: 17 | Iteration number: [3780/4518] 83% | Training loss: 0.6871227006117503
Epoch: 17 | Iteration number: [3790/4518] 83% | Training loss: 0.6871232963017234
Epoch: 17 | Iteration number: [3800/4518] 84% | Training loss: 0.6871222351726732
Epoch: 17 | Iteration number: [3810/4518] 84% | Training loss: 0.6871217106896749
Epoch: 17 | Iteration number: [3820/4518] 84% | Training loss: 0.6871169085746036
Epoch: 17 | Iteration number: [3830/4518] 84% | Training loss: 0.6871169698144998
Epoch: 17 | Iteration number: [3840/4518] 84% | Training loss: 0.6871184709016234
Epoch: 17 | Iteration number: [3850/4518] 85% | Training loss: 0.6871160226054006
Epoch: 17 | Iteration number: [3860/4518] 85% | Training loss: 0.6871161781135618
Epoch: 17 | Iteration number: [3870/4518] 85% | Training loss: 0.6871153426724811
Epoch: 17 | Iteration number: [3880/4518] 85% | Training loss: 0.687116320123992
Epoch: 17 | Iteration number: [3890/4518] 86% | Training loss: 0.6871166511335839
Epoch: 17 | Iteration number: [3900/4518] 86% | Training loss: 0.6871172648362625
Epoch: 17 | Iteration number: [3910/4518] 86% | Training loss: 0.6871166404250942
Epoch: 17 | Iteration number: [3920/4518] 86% | Training loss: 0.6871177768676865
Epoch: 17 | Iteration number: [3930/4518] 86% | Training loss: 0.6871161251577712
Epoch: 17 | Iteration number: [3940/4518] 87% | Training loss: 0.6871190675321569
Epoch: 17 | Iteration number: [3950/4518] 87% | Training loss: 0.6871147805075102
Epoch: 17 | Iteration number: [3960/4518] 87% | Training loss: 0.6871111923847536
Epoch: 17 | Iteration number: [3970/4518] 87% | Training loss: 0.6871098530682869
Epoch: 17 | Iteration number: [3980/4518] 88% | Training loss: 0.6871096833716684
Epoch: 17 | Iteration number: [3990/4518] 88% | Training loss: 0.6871058421774316
Epoch: 17 | Iteration number: [4000/4518] 88% | Training loss: 0.6871032516658306
Epoch: 17 | Iteration number: [4010/4518] 88% | Training loss: 0.6871038328828359
Epoch: 17 | Iteration number: [4020/4518] 88% | Training loss: 0.6871049758658481
Epoch: 17 | Iteration number: [4030/4518] 89% | Training loss: 0.6871020966073124
Epoch: 17 | Iteration number: [4040/4518] 89% | Training loss: 0.6871013677798875
Epoch: 17 | Iteration number: [4050/4518] 89% | Training loss: 0.6870973244419805
Epoch: 17 | Iteration number: [4060/4518] 89% | Training loss: 0.6870977605358133
Epoch: 17 | Iteration number: [4070/4518] 90% | Training loss: 0.6870972771316547
Epoch: 17 | Iteration number: [4080/4518] 90% | Training loss: 0.6870991605169633
Epoch: 17 | Iteration number: [4090/4518] 90% | Training loss: 0.6870980998560385
Epoch: 17 | Iteration number: [4100/4518] 90% | Training loss: 0.6870966327917285
Epoch: 17 | Iteration number: [4110/4518] 90% | Training loss: 0.6870980027963355
Epoch: 17 | Iteration number: [4120/4518] 91% | Training loss: 0.6870957315546795
Epoch: 17 | Iteration number: [4130/4518] 91% | Training loss: 0.6870947532878949
Epoch: 17 | Iteration number: [4140/4518] 91% | Training loss: 0.6870915725611259
Epoch: 17 | Iteration number: [4150/4518] 91% | Training loss: 0.6870922246611262
Epoch: 17 | Iteration number: [4160/4518] 92% | Training loss: 0.6870950428768993
Epoch: 17 | Iteration number: [4170/4518] 92% | Training loss: 0.6870983189387287
Epoch: 17 | Iteration number: [4180/4518] 92% | Training loss: 0.6870986017456465
Epoch: 17 | Iteration number: [4190/4518] 92% | Training loss: 0.6870984983899429
Epoch: 17 | Iteration number: [4200/4518] 92% | Training loss: 0.6870971817345847
Epoch: 17 | Iteration number: [4210/4518] 93% | Training loss: 0.6870948347796171
Epoch: 17 | Iteration number: [4220/4518] 93% | Training loss: 0.6870956983752725
Epoch: 17 | Iteration number: [4230/4518] 93% | Training loss: 0.6870966938652328
Epoch: 17 | Iteration number: [4240/4518] 93% | Training loss: 0.6870963320276647
Epoch: 17 | Iteration number: [4250/4518] 94% | Training loss: 0.6870971993839039
Epoch: 17 | Iteration number: [4260/4518] 94% | Training loss: 0.6870970079036945
Epoch: 17 | Iteration number: [4270/4518] 94% | Training loss: 0.6870953671267775
Epoch: 17 | Iteration number: [4280/4518] 94% | Training loss: 0.687094540128084
Epoch: 17 | Iteration number: [4290/4518] 94% | Training loss: 0.6870972567921751
Epoch: 17 | Iteration number: [4300/4518] 95% | Training loss: 0.6870959601568621
Epoch: 17 | Iteration number: [4310/4518] 95% | Training loss: 0.6870957174599862
Epoch: 17 | Iteration number: [4320/4518] 95% | Training loss: 0.6870951343465734
Epoch: 17 | Iteration number: [4330/4518] 95% | Training loss: 0.6870948801552726
Epoch: 17 | Iteration number: [4340/4518] 96% | Training loss: 0.6870950032763766
Epoch: 17 | Iteration number: [4350/4518] 96% | Training loss: 0.6870921155228011
Epoch: 17 | Iteration number: [4360/4518] 96% | Training loss: 0.6870908035187546
Epoch: 17 | Iteration number: [4370/4518] 96% | Training loss: 0.687088312914497
Epoch: 17 | Iteration number: [4380/4518] 96% | Training loss: 0.6870894569512371
Epoch: 17 | Iteration number: [4390/4518] 97% | Training loss: 0.6870888916533737
Epoch: 17 | Iteration number: [4400/4518] 97% | Training loss: 0.6870879283005541
Epoch: 17 | Iteration number: [4410/4518] 97% | Training loss: 0.6870866348143337
Epoch: 17 | Iteration number: [4420/4518] 97% | Training loss: 0.687085405019074
Epoch: 17 | Iteration number: [4430/4518] 98% | Training loss: 0.6870847573667832
Epoch: 17 | Iteration number: [4440/4518] 98% | Training loss: 0.6870829849495544
Epoch: 17 | Iteration number: [4450/4518] 98% | Training loss: 0.6870843689763144
Epoch: 17 | Iteration number: [4460/4518] 98% | Training loss: 0.6870831648998731
Epoch: 17 | Iteration number: [4470/4518] 98% | Training loss: 0.6870816169035782
Epoch: 17 | Iteration number: [4480/4518] 99% | Training loss: 0.6870819438781057
Epoch: 17 | Iteration number: [4490/4518] 99% | Training loss: 0.6870813482986526
Epoch: 17 | Iteration number: [4500/4518] 99% | Training loss: 0.6870822787284852
Epoch: 17 | Iteration number: [4510/4518] 99% | Training loss: 0.6870829400625038

 End of epoch: 17 | Train Loss: 0.6869287699949114 | Training Time: 640 

 End of epoch: 17 | Eval Loss: 0.6902147081433511 | Evaluating Time: 17 
Epoch: 18 | Iteration number: [10/4518] 0% | Training loss: 0.7542798638343811
Epoch: 18 | Iteration number: [20/4518] 0% | Training loss: 0.7202147483825684
Epoch: 18 | Iteration number: [30/4518] 0% | Training loss: 0.7092064996560414
Epoch: 18 | Iteration number: [40/4518] 0% | Training loss: 0.7034634336829185
Epoch: 18 | Iteration number: [50/4518] 1% | Training loss: 0.7002552306652069
Epoch: 18 | Iteration number: [60/4518] 1% | Training loss: 0.6980329145987828
Epoch: 18 | Iteration number: [70/4518] 1% | Training loss: 0.6964897240911211
Epoch: 18 | Iteration number: [80/4518] 1% | Training loss: 0.6952196329832077
Epoch: 18 | Iteration number: [90/4518] 1% | Training loss: 0.6943210204442342
Epoch: 18 | Iteration number: [100/4518] 2% | Training loss: 0.6935484206676483
Epoch: 18 | Iteration number: [110/4518] 2% | Training loss: 0.6928188627416437
Epoch: 18 | Iteration number: [120/4518] 2% | Training loss: 0.6923596834143003
Epoch: 18 | Iteration number: [130/4518] 2% | Training loss: 0.6920321707542126
Epoch: 18 | Iteration number: [140/4518] 3% | Training loss: 0.6916264942714146
Epoch: 18 | Iteration number: [150/4518] 3% | Training loss: 0.6912478562196096
Epoch: 18 | Iteration number: [160/4518] 3% | Training loss: 0.6910347525030375
Epoch: 18 | Iteration number: [170/4518] 3% | Training loss: 0.6908744100262137
Epoch: 18 | Iteration number: [180/4518] 3% | Training loss: 0.6906833423508538
Epoch: 18 | Iteration number: [190/4518] 4% | Training loss: 0.6904881336187062
Epoch: 18 | Iteration number: [200/4518] 4% | Training loss: 0.6903046628832817
Epoch: 18 | Iteration number: [210/4518] 4% | Training loss: 0.6901622269834791
Epoch: 18 | Iteration number: [220/4518] 4% | Training loss: 0.6899864622137764
Epoch: 18 | Iteration number: [230/4518] 5% | Training loss: 0.6898823408976845
Epoch: 18 | Iteration number: [240/4518] 5% | Training loss: 0.6897465405364831
Epoch: 18 | Iteration number: [250/4518] 5% | Training loss: 0.6896225905418396
Epoch: 18 | Iteration number: [260/4518] 5% | Training loss: 0.6895804668848331
Epoch: 18 | Iteration number: [270/4518] 5% | Training loss: 0.689454232763361
Epoch: 18 | Iteration number: [280/4518] 6% | Training loss: 0.6893261370914323
Epoch: 18 | Iteration number: [290/4518] 6% | Training loss: 0.6892796845271669
Epoch: 18 | Iteration number: [300/4518] 6% | Training loss: 0.689201280872027
Epoch: 18 | Iteration number: [310/4518] 6% | Training loss: 0.689080427154418
Epoch: 18 | Iteration number: [320/4518] 7% | Training loss: 0.6890152331441641
Epoch: 18 | Iteration number: [330/4518] 7% | Training loss: 0.6889665610862501
Epoch: 18 | Iteration number: [340/4518] 7% | Training loss: 0.6888622809858883
Epoch: 18 | Iteration number: [350/4518] 7% | Training loss: 0.688828787463052
Epoch: 18 | Iteration number: [360/4518] 7% | Training loss: 0.6887300135360823
Epoch: 18 | Iteration number: [370/4518] 8% | Training loss: 0.6886649329920073
Epoch: 18 | Iteration number: [380/4518] 8% | Training loss: 0.6886135217390562
Epoch: 18 | Iteration number: [390/4518] 8% | Training loss: 0.6885666856398949
Epoch: 18 | Iteration number: [400/4518] 8% | Training loss: 0.688502583950758
Epoch: 18 | Iteration number: [410/4518] 9% | Training loss: 0.6884666679835901
Epoch: 18 | Iteration number: [420/4518] 9% | Training loss: 0.6884429139750344
Epoch: 18 | Iteration number: [430/4518] 9% | Training loss: 0.6884083855983822
Epoch: 18 | Iteration number: [440/4518] 9% | Training loss: 0.6883648984811522
Epoch: 18 | Iteration number: [450/4518] 9% | Training loss: 0.6883273543251885
Epoch: 18 | Iteration number: [460/4518] 10% | Training loss: 0.6882872078729713
Epoch: 18 | Iteration number: [470/4518] 10% | Training loss: 0.688268767138745
Epoch: 18 | Iteration number: [480/4518] 10% | Training loss: 0.688260938723882
Epoch: 18 | Iteration number: [490/4518] 10% | Training loss: 0.6882150556359973
Epoch: 18 | Iteration number: [500/4518] 11% | Training loss: 0.6882148624658585
Epoch: 18 | Iteration number: [510/4518] 11% | Training loss: 0.6881789078899458
Epoch: 18 | Iteration number: [520/4518] 11% | Training loss: 0.6881574677733274
Epoch: 18 | Iteration number: [530/4518] 11% | Training loss: 0.6881401489365776
Epoch: 18 | Iteration number: [540/4518] 11% | Training loss: 0.6881011739925101
Epoch: 18 | Iteration number: [550/4518] 12% | Training loss: 0.6880803250182759
Epoch: 18 | Iteration number: [560/4518] 12% | Training loss: 0.6880267708429268
Epoch: 18 | Iteration number: [570/4518] 12% | Training loss: 0.6880099083247938
Epoch: 18 | Iteration number: [580/4518] 12% | Training loss: 0.6880048557602126
Epoch: 18 | Iteration number: [590/4518] 13% | Training loss: 0.6879961102695789
Epoch: 18 | Iteration number: [600/4518] 13% | Training loss: 0.6879847051699957
Epoch: 18 | Iteration number: [610/4518] 13% | Training loss: 0.6879880354052684
Epoch: 18 | Iteration number: [620/4518] 13% | Training loss: 0.687964024659126
Epoch: 18 | Iteration number: [630/4518] 13% | Training loss: 0.6879482081958226
Epoch: 18 | Iteration number: [640/4518] 14% | Training loss: 0.6879488087259233
Epoch: 18 | Iteration number: [650/4518] 14% | Training loss: 0.6879412273260264
Epoch: 18 | Iteration number: [660/4518] 14% | Training loss: 0.6879188126686847
Epoch: 18 | Iteration number: [670/4518] 14% | Training loss: 0.6878997573212011
Epoch: 18 | Iteration number: [680/4518] 15% | Training loss: 0.6879055281772333
Epoch: 18 | Iteration number: [690/4518] 15% | Training loss: 0.687891434845717
Epoch: 18 | Iteration number: [700/4518] 15% | Training loss: 0.6878604259661266
Epoch: 18 | Iteration number: [710/4518] 15% | Training loss: 0.6878550952589008
Epoch: 18 | Iteration number: [720/4518] 15% | Training loss: 0.6878453198406431
Epoch: 18 | Iteration number: [730/4518] 16% | Training loss: 0.687844230867412
Epoch: 18 | Iteration number: [740/4518] 16% | Training loss: 0.6878385058125934
Epoch: 18 | Iteration number: [750/4518] 16% | Training loss: 0.6878246157169342
Epoch: 18 | Iteration number: [760/4518] 16% | Training loss: 0.6878138281797108
Epoch: 18 | Iteration number: [770/4518] 17% | Training loss: 0.6878090932771757
Epoch: 18 | Iteration number: [780/4518] 17% | Training loss: 0.687805447822962
Epoch: 18 | Iteration number: [790/4518] 17% | Training loss: 0.6877923827382583
Epoch: 18 | Iteration number: [800/4518] 17% | Training loss: 0.6877902004122735
Epoch: 18 | Iteration number: [810/4518] 17% | Training loss: 0.687760501805647
Epoch: 18 | Iteration number: [820/4518] 18% | Training loss: 0.6877518659684716
Epoch: 18 | Iteration number: [830/4518] 18% | Training loss: 0.6877423575843673
Epoch: 18 | Iteration number: [840/4518] 18% | Training loss: 0.6877300435588474
Epoch: 18 | Iteration number: [850/4518] 18% | Training loss: 0.6877209848516128
Epoch: 18 | Iteration number: [860/4518] 19% | Training loss: 0.6877139569021935
Epoch: 18 | Iteration number: [870/4518] 19% | Training loss: 0.687702404425062
Epoch: 18 | Iteration number: [880/4518] 19% | Training loss: 0.6876836465163665
Epoch: 18 | Iteration number: [890/4518] 19% | Training loss: 0.6876539869924609
Epoch: 18 | Iteration number: [900/4518] 19% | Training loss: 0.6876556120978461
Epoch: 18 | Iteration number: [910/4518] 20% | Training loss: 0.6876487534779768
Epoch: 18 | Iteration number: [920/4518] 20% | Training loss: 0.687649252233298
Epoch: 18 | Iteration number: [930/4518] 20% | Training loss: 0.6876362746120781
Epoch: 18 | Iteration number: [940/4518] 20% | Training loss: 0.6876156944543758
Epoch: 18 | Iteration number: [950/4518] 21% | Training loss: 0.687608274284162
Epoch: 18 | Iteration number: [960/4518] 21% | Training loss: 0.6876068788270155
Epoch: 18 | Iteration number: [970/4518] 21% | Training loss: 0.6876019372768009
Epoch: 18 | Iteration number: [980/4518] 21% | Training loss: 0.6875899391514915
Epoch: 18 | Iteration number: [990/4518] 21% | Training loss: 0.6875723050098227
Epoch: 18 | Iteration number: [1000/4518] 22% | Training loss: 0.6875723024010658
Epoch: 18 | Iteration number: [1010/4518] 22% | Training loss: 0.6875695042090841
Epoch: 18 | Iteration number: [1020/4518] 22% | Training loss: 0.6875636923546885
Epoch: 18 | Iteration number: [1030/4518] 22% | Training loss: 0.6875427927785707
Epoch: 18 | Iteration number: [1040/4518] 23% | Training loss: 0.6875291203077023
Epoch: 18 | Iteration number: [1050/4518] 23% | Training loss: 0.6875258618877047
Epoch: 18 | Iteration number: [1060/4518] 23% | Training loss: 0.6875245870846622
Epoch: 18 | Iteration number: [1070/4518] 23% | Training loss: 0.6875227885268559
Epoch: 18 | Iteration number: [1080/4518] 23% | Training loss: 0.6875156667497423
Epoch: 18 | Iteration number: [1090/4518] 24% | Training loss: 0.6875176345536468
Epoch: 18 | Iteration number: [1100/4518] 24% | Training loss: 0.6875011590935968
Epoch: 18 | Iteration number: [1110/4518] 24% | Training loss: 0.6874885928523433
Epoch: 18 | Iteration number: [1120/4518] 24% | Training loss: 0.6874775675790651
Epoch: 18 | Iteration number: [1130/4518] 25% | Training loss: 0.6874716206461983
Epoch: 18 | Iteration number: [1140/4518] 25% | Training loss: 0.6874607300026375
Epoch: 18 | Iteration number: [1150/4518] 25% | Training loss: 0.687466434136681
Epoch: 18 | Iteration number: [1160/4518] 25% | Training loss: 0.6874652361561512
Epoch: 18 | Iteration number: [1170/4518] 25% | Training loss: 0.687459527172594
Epoch: 18 | Iteration number: [1180/4518] 26% | Training loss: 0.6874513802386947
Epoch: 18 | Iteration number: [1190/4518] 26% | Training loss: 0.6874419202824601
Epoch: 18 | Iteration number: [1200/4518] 26% | Training loss: 0.6874536608656248
Epoch: 18 | Iteration number: [1210/4518] 26% | Training loss: 0.687446882754318
Epoch: 18 | Iteration number: [1220/4518] 27% | Training loss: 0.6874426250086456
Epoch: 18 | Iteration number: [1230/4518] 27% | Training loss: 0.6874281904561733
Epoch: 18 | Iteration number: [1240/4518] 27% | Training loss: 0.6874323604087675
Epoch: 18 | Iteration number: [1250/4518] 27% | Training loss: 0.6874302062034607
Epoch: 18 | Iteration number: [1260/4518] 27% | Training loss: 0.6874198712999858
Epoch: 18 | Iteration number: [1270/4518] 28% | Training loss: 0.6874307519338262
Epoch: 18 | Iteration number: [1280/4518] 28% | Training loss: 0.6874321356415749
Epoch: 18 | Iteration number: [1290/4518] 28% | Training loss: 0.6874285346315813
Epoch: 18 | Iteration number: [1300/4518] 28% | Training loss: 0.6874239677190781
Epoch: 18 | Iteration number: [1310/4518] 28% | Training loss: 0.6874173848683598
Epoch: 18 | Iteration number: [1320/4518] 29% | Training loss: 0.6874105206041625
Epoch: 18 | Iteration number: [1330/4518] 29% | Training loss: 0.68741131994061
Epoch: 18 | Iteration number: [1340/4518] 29% | Training loss: 0.6874104987774322
Epoch: 18 | Iteration number: [1350/4518] 29% | Training loss: 0.6874127935038673
Epoch: 18 | Iteration number: [1360/4518] 30% | Training loss: 0.6874147933195619
Epoch: 18 | Iteration number: [1370/4518] 30% | Training loss: 0.6874165612850746
Epoch: 18 | Iteration number: [1380/4518] 30% | Training loss: 0.6874065458774566
Epoch: 18 | Iteration number: [1390/4518] 30% | Training loss: 0.6874001165516943
Epoch: 18 | Iteration number: [1400/4518] 30% | Training loss: 0.6873945679834911
Epoch: 18 | Iteration number: [1410/4518] 31% | Training loss: 0.687395212075389
Epoch: 18 | Iteration number: [1420/4518] 31% | Training loss: 0.6873775003241821
Epoch: 18 | Iteration number: [1430/4518] 31% | Training loss: 0.6873764910898008
Epoch: 18 | Iteration number: [1440/4518] 31% | Training loss: 0.6873698064850436
Epoch: 18 | Iteration number: [1450/4518] 32% | Training loss: 0.6873617852967361
Epoch: 18 | Iteration number: [1460/4518] 32% | Training loss: 0.6873526804251213
Epoch: 18 | Iteration number: [1470/4518] 32% | Training loss: 0.687350808154969
Epoch: 18 | Iteration number: [1480/4518] 32% | Training loss: 0.6873492489795427
Epoch: 18 | Iteration number: [1490/4518] 32% | Training loss: 0.6873468708271948
Epoch: 18 | Iteration number: [1500/4518] 33% | Training loss: 0.6873349109093349
Epoch: 18 | Iteration number: [1510/4518] 33% | Training loss: 0.6873217731516882
Epoch: 18 | Iteration number: [1520/4518] 33% | Training loss: 0.6873324089144406
Epoch: 18 | Iteration number: [1530/4518] 33% | Training loss: 0.6873344420997146
Epoch: 18 | Iteration number: [1540/4518] 34% | Training loss: 0.6873385751402223
Epoch: 18 | Iteration number: [1550/4518] 34% | Training loss: 0.6873385806237498
Epoch: 18 | Iteration number: [1560/4518] 34% | Training loss: 0.6873344278106323
Epoch: 18 | Iteration number: [1570/4518] 34% | Training loss: 0.6873304286580176
Epoch: 18 | Iteration number: [1580/4518] 34% | Training loss: 0.6873233136496967
Epoch: 18 | Iteration number: [1590/4518] 35% | Training loss: 0.6873270723804737
Epoch: 18 | Iteration number: [1600/4518] 35% | Training loss: 0.6873253209143877
Epoch: 18 | Iteration number: [1610/4518] 35% | Training loss: 0.6873285088479889
Epoch: 18 | Iteration number: [1620/4518] 35% | Training loss: 0.6873266870960777
Epoch: 18 | Iteration number: [1630/4518] 36% | Training loss: 0.6873182731903403
Epoch: 18 | Iteration number: [1640/4518] 36% | Training loss: 0.6873150444975713
Epoch: 18 | Iteration number: [1650/4518] 36% | Training loss: 0.6873178209680499
Epoch: 18 | Iteration number: [1660/4518] 36% | Training loss: 0.6873110639761729
Epoch: 18 | Iteration number: [1670/4518] 36% | Training loss: 0.6873043069939413
Epoch: 18 | Iteration number: [1680/4518] 37% | Training loss: 0.6873052973477614
Epoch: 18 | Iteration number: [1690/4518] 37% | Training loss: 0.687299411889364
Epoch: 18 | Iteration number: [1700/4518] 37% | Training loss: 0.6872991253698574
Epoch: 18 | Iteration number: [1710/4518] 37% | Training loss: 0.6872928331121366
Epoch: 18 | Iteration number: [1720/4518] 38% | Training loss: 0.6872996330261231
Epoch: 18 | Iteration number: [1730/4518] 38% | Training loss: 0.6873049354277594
Epoch: 18 | Iteration number: [1740/4518] 38% | Training loss: 0.6872950293894472
Epoch: 18 | Iteration number: [1750/4518] 38% | Training loss: 0.6872976211139133
Epoch: 18 | Iteration number: [1760/4518] 38% | Training loss: 0.6873024234717543
Epoch: 18 | Iteration number: [1770/4518] 39% | Training loss: 0.6873063297931757
Epoch: 18 | Iteration number: [1780/4518] 39% | Training loss: 0.6873108514574137
Epoch: 18 | Iteration number: [1790/4518] 39% | Training loss: 0.6873144703870379
Epoch: 18 | Iteration number: [1800/4518] 39% | Training loss: 0.6873101579480702
Epoch: 18 | Iteration number: [1810/4518] 40% | Training loss: 0.6873002795553997
Epoch: 18 | Iteration number: [1820/4518] 40% | Training loss: 0.687297704226368
Epoch: 18 | Iteration number: [1830/4518] 40% | Training loss: 0.687288554672335
Epoch: 18 | Iteration number: [1840/4518] 40% | Training loss: 0.687289841408315
Epoch: 18 | Iteration number: [1850/4518] 40% | Training loss: 0.6872854423522949
Epoch: 18 | Iteration number: [1860/4518] 41% | Training loss: 0.6872858612768111
Epoch: 18 | Iteration number: [1870/4518] 41% | Training loss: 0.6872837246420549
Epoch: 18 | Iteration number: [1880/4518] 41% | Training loss: 0.6872784666241484
Epoch: 18 | Iteration number: [1890/4518] 41% | Training loss: 0.6872804870996526
Epoch: 18 | Iteration number: [1900/4518] 42% | Training loss: 0.6872785963510212
Epoch: 18 | Iteration number: [1910/4518] 42% | Training loss: 0.6872864281319823
Epoch: 18 | Iteration number: [1920/4518] 42% | Training loss: 0.6872879326653977
Epoch: 18 | Iteration number: [1930/4518] 42% | Training loss: 0.687290794985282
Epoch: 18 | Iteration number: [1940/4518] 42% | Training loss: 0.6872928799120421
Epoch: 18 | Iteration number: [1950/4518] 43% | Training loss: 0.6872966232972267
Epoch: 18 | Iteration number: [1960/4518] 43% | Training loss: 0.6872854005317299
Epoch: 18 | Iteration number: [1970/4518] 43% | Training loss: 0.6872890232783284
Epoch: 18 | Iteration number: [1980/4518] 43% | Training loss: 0.6872930516197224
Epoch: 18 | Iteration number: [1990/4518] 44% | Training loss: 0.6872933163714768
Epoch: 18 | Iteration number: [2000/4518] 44% | Training loss: 0.6872886300981045
Epoch: 18 | Iteration number: [2010/4518] 44% | Training loss: 0.6872876121333582
Epoch: 18 | Iteration number: [2020/4518] 44% | Training loss: 0.6872839999080884
Epoch: 18 | Iteration number: [2030/4518] 44% | Training loss: 0.6872738110314449
Epoch: 18 | Iteration number: [2040/4518] 45% | Training loss: 0.6872631977878365
Epoch: 18 | Iteration number: [2050/4518] 45% | Training loss: 0.6872665796338058
Epoch: 18 | Iteration number: [2060/4518] 45% | Training loss: 0.6872694828556579
Epoch: 18 | Iteration number: [2070/4518] 45% | Training loss: 0.6872644807405518
Epoch: 18 | Iteration number: [2080/4518] 46% | Training loss: 0.6872688038704488
Epoch: 18 | Iteration number: [2090/4518] 46% | Training loss: 0.6872688022526827
Epoch: 18 | Iteration number: [2100/4518] 46% | Training loss: 0.6872709201063428
Epoch: 18 | Iteration number: [2110/4518] 46% | Training loss: 0.6872696309575538
Epoch: 18 | Iteration number: [2120/4518] 46% | Training loss: 0.6872710253832475
Epoch: 18 | Iteration number: [2130/4518] 47% | Training loss: 0.6872728398987945
Epoch: 18 | Iteration number: [2140/4518] 47% | Training loss: 0.6872670134651326
Epoch: 18 | Iteration number: [2150/4518] 47% | Training loss: 0.6872649151502653
Epoch: 18 | Iteration number: [2160/4518] 47% | Training loss: 0.6872670598880009
Epoch: 18 | Iteration number: [2170/4518] 48% | Training loss: 0.6872693817187014
Epoch: 18 | Iteration number: [2180/4518] 48% | Training loss: 0.6872733540491227
Epoch: 18 | Iteration number: [2190/4518] 48% | Training loss: 0.6872737673047471
Epoch: 18 | Iteration number: [2200/4518] 48% | Training loss: 0.6872707857327027
Epoch: 18 | Iteration number: [2210/4518] 48% | Training loss: 0.6872673700837528
Epoch: 18 | Iteration number: [2220/4518] 49% | Training loss: 0.6872676981998993
Epoch: 18 | Iteration number: [2230/4518] 49% | Training loss: 0.6872650998590238
Epoch: 18 | Iteration number: [2240/4518] 49% | Training loss: 0.6872623911393541
Epoch: 18 | Iteration number: [2250/4518] 49% | Training loss: 0.6872665500640869
Epoch: 18 | Iteration number: [2260/4518] 50% | Training loss: 0.6872637050341716
Epoch: 18 | Iteration number: [2270/4518] 50% | Training loss: 0.6872673462928655
Epoch: 18 | Iteration number: [2280/4518] 50% | Training loss: 0.6872662460071999
Epoch: 18 | Iteration number: [2290/4518] 50% | Training loss: 0.6872695814053564
Epoch: 18 | Iteration number: [2300/4518] 50% | Training loss: 0.6872717238509136
Epoch: 18 | Iteration number: [2310/4518] 51% | Training loss: 0.6872709268873388
Epoch: 18 | Iteration number: [2320/4518] 51% | Training loss: 0.6872715291278115
Epoch: 18 | Iteration number: [2330/4518] 51% | Training loss: 0.6872749426334201
Epoch: 18 | Iteration number: [2340/4518] 51% | Training loss: 0.6872769672646482
Epoch: 18 | Iteration number: [2350/4518] 52% | Training loss: 0.6872756848436721
Epoch: 18 | Iteration number: [2360/4518] 52% | Training loss: 0.6872723203846964
Epoch: 18 | Iteration number: [2370/4518] 52% | Training loss: 0.6872639109816733
Epoch: 18 | Iteration number: [2380/4518] 52% | Training loss: 0.6872623161608431
Epoch: 18 | Iteration number: [2390/4518] 52% | Training loss: 0.6872614720376465
Epoch: 18 | Iteration number: [2400/4518] 53% | Training loss: 0.6872609599928061
Epoch: 18 | Iteration number: [2410/4518] 53% | Training loss: 0.6872574839107228
Epoch: 18 | Iteration number: [2420/4518] 53% | Training loss: 0.687253339403917
Epoch: 18 | Iteration number: [2430/4518] 53% | Training loss: 0.6872506051642414
Epoch: 18 | Iteration number: [2440/4518] 54% | Training loss: 0.6872453788509134
Epoch: 18 | Iteration number: [2450/4518] 54% | Training loss: 0.6872425545478353
Epoch: 18 | Iteration number: [2460/4518] 54% | Training loss: 0.6872390995422999
Epoch: 18 | Iteration number: [2470/4518] 54% | Training loss: 0.6872407626043929
Epoch: 18 | Iteration number: [2480/4518] 54% | Training loss: 0.6872369597275411
Epoch: 18 | Iteration number: [2490/4518] 55% | Training loss: 0.6872328359439192
Epoch: 18 | Iteration number: [2500/4518] 55% | Training loss: 0.6872324964046478
Epoch: 18 | Iteration number: [2510/4518] 55% | Training loss: 0.6872311270094488
Epoch: 18 | Iteration number: [2520/4518] 55% | Training loss: 0.6872312987844149
Epoch: 18 | Iteration number: [2530/4518] 55% | Training loss: 0.6872257704791345
Epoch: 18 | Iteration number: [2540/4518] 56% | Training loss: 0.6872252411025715
Epoch: 18 | Iteration number: [2550/4518] 56% | Training loss: 0.6872283412662207
Epoch: 18 | Iteration number: [2560/4518] 56% | Training loss: 0.6872245315462351
Epoch: 18 | Iteration number: [2570/4518] 56% | Training loss: 0.6872206750314988
Epoch: 18 | Iteration number: [2580/4518] 57% | Training loss: 0.6872113119955211
Epoch: 18 | Iteration number: [2590/4518] 57% | Training loss: 0.6872126851993178
Epoch: 18 | Iteration number: [2600/4518] 57% | Training loss: 0.6872097816375585
Epoch: 18 | Iteration number: [2610/4518] 57% | Training loss: 0.6872083529887072
Epoch: 18 | Iteration number: [2620/4518] 57% | Training loss: 0.6872062317742647
Epoch: 18 | Iteration number: [2630/4518] 58% | Training loss: 0.6872028076603386
Epoch: 18 | Iteration number: [2640/4518] 58% | Training loss: 0.6871991348537532
Epoch: 18 | Iteration number: [2650/4518] 58% | Training loss: 0.687193874952928
Epoch: 18 | Iteration number: [2660/4518] 58% | Training loss: 0.687193531111667
Epoch: 18 | Iteration number: [2670/4518] 59% | Training loss: 0.6871873508008678
Epoch: 18 | Iteration number: [2680/4518] 59% | Training loss: 0.6871888979157406
Epoch: 18 | Iteration number: [2690/4518] 59% | Training loss: 0.687190291739751
Epoch: 18 | Iteration number: [2700/4518] 59% | Training loss: 0.6871927536637695
Epoch: 18 | Iteration number: [2710/4518] 59% | Training loss: 0.6871928053808388
Epoch: 18 | Iteration number: [2720/4518] 60% | Training loss: 0.6871946850024602
Epoch: 18 | Iteration number: [2730/4518] 60% | Training loss: 0.6871932425778428
Epoch: 18 | Iteration number: [2740/4518] 60% | Training loss: 0.6871946407495624
Epoch: 18 | Iteration number: [2750/4518] 60% | Training loss: 0.6871922731833024
Epoch: 18 | Iteration number: [2760/4518] 61% | Training loss: 0.6871918658415477
Epoch: 18 | Iteration number: [2770/4518] 61% | Training loss: 0.6871979810916129
Epoch: 18 | Iteration number: [2780/4518] 61% | Training loss: 0.6871955787964005
Epoch: 18 | Iteration number: [2790/4518] 61% | Training loss: 0.6872008116228179
Epoch: 18 | Iteration number: [2800/4518] 61% | Training loss: 0.6871962761878967
Epoch: 18 | Iteration number: [2810/4518] 62% | Training loss: 0.6871939513394841
Epoch: 18 | Iteration number: [2820/4518] 62% | Training loss: 0.6871930103141365
Epoch: 18 | Iteration number: [2830/4518] 62% | Training loss: 0.6871909707679345
Epoch: 18 | Iteration number: [2840/4518] 62% | Training loss: 0.6871860486520848
Epoch: 18 | Iteration number: [2850/4518] 63% | Training loss: 0.6871818690132676
Epoch: 18 | Iteration number: [2860/4518] 63% | Training loss: 0.6871759671848137
Epoch: 18 | Iteration number: [2870/4518] 63% | Training loss: 0.6871691571918515
Epoch: 18 | Iteration number: [2880/4518] 63% | Training loss: 0.687167385696537
Epoch: 18 | Iteration number: [2890/4518] 63% | Training loss: 0.6871666751105893
Epoch: 18 | Iteration number: [2900/4518] 64% | Training loss: 0.6871585968650621
Epoch: 18 | Iteration number: [2910/4518] 64% | Training loss: 0.6871540897490642
Epoch: 18 | Iteration number: [2920/4518] 64% | Training loss: 0.6871518942183011
Epoch: 18 | Iteration number: [2930/4518] 64% | Training loss: 0.6871546966630852
Epoch: 18 | Iteration number: [2940/4518] 65% | Training loss: 0.687155518381774
Epoch: 18 | Iteration number: [2950/4518] 65% | Training loss: 0.68715835037878
Epoch: 18 | Iteration number: [2960/4518] 65% | Training loss: 0.6871581406206698
Epoch: 18 | Iteration number: [2970/4518] 65% | Training loss: 0.687158779463784
Epoch: 18 | Iteration number: [2980/4518] 65% | Training loss: 0.6871588049518982
Epoch: 18 | Iteration number: [2990/4518] 66% | Training loss: 0.6871609649729968
Epoch: 18 | Iteration number: [3000/4518] 66% | Training loss: 0.6871587197383244
Epoch: 18 | Iteration number: [3010/4518] 66% | Training loss: 0.6871591954730277
Epoch: 18 | Iteration number: [3020/4518] 66% | Training loss: 0.6871592158513353
Epoch: 18 | Iteration number: [3030/4518] 67% | Training loss: 0.6871569504242132
Epoch: 18 | Iteration number: [3040/4518] 67% | Training loss: 0.6871548902439444
Epoch: 18 | Iteration number: [3050/4518] 67% | Training loss: 0.6871569594594299
Epoch: 18 | Iteration number: [3060/4518] 67% | Training loss: 0.6871552616163017
Epoch: 18 | Iteration number: [3070/4518] 67% | Training loss: 0.6871595262122077
Epoch: 18 | Iteration number: [3080/4518] 68% | Training loss: 0.6871618497487787
Epoch: 18 | Iteration number: [3090/4518] 68% | Training loss: 0.6871602013273147
Epoch: 18 | Iteration number: [3100/4518] 68% | Training loss: 0.6871556802911143
Epoch: 18 | Iteration number: [3110/4518] 68% | Training loss: 0.6871522157330222
Epoch: 18 | Iteration number: [3120/4518] 69% | Training loss: 0.6871495687999787
Epoch: 18 | Iteration number: [3130/4518] 69% | Training loss: 0.687147066787409
Epoch: 18 | Iteration number: [3140/4518] 69% | Training loss: 0.6871493570174382
Epoch: 18 | Iteration number: [3150/4518] 69% | Training loss: 0.687149593186757
Epoch: 18 | Iteration number: [3160/4518] 69% | Training loss: 0.687148284553727
Epoch: 18 | Iteration number: [3170/4518] 70% | Training loss: 0.6871441467891356
Epoch: 18 | Iteration number: [3180/4518] 70% | Training loss: 0.6871395924556181
Epoch: 18 | Iteration number: [3190/4518] 70% | Training loss: 0.6871390842158219
Epoch: 18 | Iteration number: [3200/4518] 70% | Training loss: 0.6871396167203784
Epoch: 18 | Iteration number: [3210/4518] 71% | Training loss: 0.6871417457255248
Epoch: 18 | Iteration number: [3220/4518] 71% | Training loss: 0.6871372218457809
Epoch: 18 | Iteration number: [3230/4518] 71% | Training loss: 0.6871342618952595
Epoch: 18 | Iteration number: [3240/4518] 71% | Training loss: 0.687134116207376
Epoch: 18 | Iteration number: [3250/4518] 71% | Training loss: 0.6871336249938378
Epoch: 18 | Iteration number: [3260/4518] 72% | Training loss: 0.6871344067933369
Epoch: 18 | Iteration number: [3270/4518] 72% | Training loss: 0.6871346297978626
Epoch: 18 | Iteration number: [3280/4518] 72% | Training loss: 0.687131524503958
Epoch: 18 | Iteration number: [3290/4518] 72% | Training loss: 0.6871306082397971
Epoch: 18 | Iteration number: [3300/4518] 73% | Training loss: 0.6871278297720533
Epoch: 18 | Iteration number: [3310/4518] 73% | Training loss: 0.6871277349052832
Epoch: 18 | Iteration number: [3320/4518] 73% | Training loss: 0.6871295347450728
Epoch: 18 | Iteration number: [3330/4518] 73% | Training loss: 0.6871290574739645
Epoch: 18 | Iteration number: [3340/4518] 73% | Training loss: 0.6871246885932134
Epoch: 18 | Iteration number: [3350/4518] 74% | Training loss: 0.6871208909376344
Epoch: 18 | Iteration number: [3360/4518] 74% | Training loss: 0.6871222180270014
Epoch: 18 | Iteration number: [3370/4518] 74% | Training loss: 0.687124310367539
Epoch: 18 | Iteration number: [3380/4518] 74% | Training loss: 0.6871228558601007
Epoch: 18 | Iteration number: [3390/4518] 75% | Training loss: 0.6871247636885066
Epoch: 18 | Iteration number: [3400/4518] 75% | Training loss: 0.6871261325478554
Epoch: 18 | Iteration number: [3410/4518] 75% | Training loss: 0.6871258500209652
Epoch: 18 | Iteration number: [3420/4518] 75% | Training loss: 0.6871280757307309
Epoch: 18 | Iteration number: [3430/4518] 75% | Training loss: 0.6871293518008018
Epoch: 18 | Iteration number: [3440/4518] 76% | Training loss: 0.6871301592435948
Epoch: 18 | Iteration number: [3450/4518] 76% | Training loss: 0.6871295686044555
Epoch: 18 | Iteration number: [3460/4518] 76% | Training loss: 0.6871268345785968
Epoch: 18 | Iteration number: [3470/4518] 76% | Training loss: 0.6871224482739693
Epoch: 18 | Iteration number: [3480/4518] 77% | Training loss: 0.6871238841065045
Epoch: 18 | Iteration number: [3490/4518] 77% | Training loss: 0.6871231726725668
Epoch: 18 | Iteration number: [3500/4518] 77% | Training loss: 0.6871189287560326
Epoch: 18 | Iteration number: [3510/4518] 77% | Training loss: 0.6871180641175675
Epoch: 18 | Iteration number: [3520/4518] 77% | Training loss: 0.6871159365570003
Epoch: 18 | Iteration number: [3530/4518] 78% | Training loss: 0.6871140938980383
Epoch: 18 | Iteration number: [3540/4518] 78% | Training loss: 0.6871139835334767
Epoch: 18 | Iteration number: [3550/4518] 78% | Training loss: 0.6871159195060461
Epoch: 18 | Iteration number: [3560/4518] 78% | Training loss: 0.6871178480011694
Epoch: 18 | Iteration number: [3570/4518] 79% | Training loss: 0.6871153686560837
Epoch: 18 | Iteration number: [3580/4518] 79% | Training loss: 0.6871169840490352
Epoch: 18 | Iteration number: [3590/4518] 79% | Training loss: 0.6871171085283285
Epoch: 18 | Iteration number: [3600/4518] 79% | Training loss: 0.6871176199615001
Epoch: 18 | Iteration number: [3610/4518] 79% | Training loss: 0.6871152684298909
Epoch: 18 | Iteration number: [3620/4518] 80% | Training loss: 0.6871132993072436
Epoch: 18 | Iteration number: [3630/4518] 80% | Training loss: 0.6871171333737282
Epoch: 18 | Iteration number: [3640/4518] 80% | Training loss: 0.6871183846023057
Epoch: 18 | Iteration number: [3650/4518] 80% | Training loss: 0.6871190144264535
Epoch: 18 | Iteration number: [3660/4518] 81% | Training loss: 0.6871205872688138
Epoch: 18 | Iteration number: [3670/4518] 81% | Training loss: 0.6871189281141401
Epoch: 18 | Iteration number: [3680/4518] 81% | Training loss: 0.6871199656277895
Epoch: 18 | Iteration number: [3690/4518] 81% | Training loss: 0.6871190207437448
Epoch: 18 | Iteration number: [3700/4518] 81% | Training loss: 0.687119041520196
Epoch: 18 | Iteration number: [3710/4518] 82% | Training loss: 0.687117053202863
Epoch: 18 | Iteration number: [3720/4518] 82% | Training loss: 0.6871157376035567
Epoch: 18 | Iteration number: [3730/4518] 82% | Training loss: 0.687116264274229
Epoch: 18 | Iteration number: [3740/4518] 82% | Training loss: 0.6871147519126933
Epoch: 18 | Iteration number: [3750/4518] 83% | Training loss: 0.6871163195451101
Epoch: 18 | Iteration number: [3760/4518] 83% | Training loss: 0.6871134258172613
Epoch: 18 | Iteration number: [3770/4518] 83% | Training loss: 0.6871137995460621
Epoch: 18 | Iteration number: [3780/4518] 83% | Training loss: 0.6871123316269072
Epoch: 18 | Iteration number: [3790/4518] 83% | Training loss: 0.6871117909067853
Epoch: 18 | Iteration number: [3800/4518] 84% | Training loss: 0.6871138372860457
Epoch: 18 | Iteration number: [3810/4518] 84% | Training loss: 0.6871145594777085
Epoch: 18 | Iteration number: [3820/4518] 84% | Training loss: 0.6871148372039745
Epoch: 18 | Iteration number: [3830/4518] 84% | Training loss: 0.6871150321188546
Epoch: 18 | Iteration number: [3840/4518] 84% | Training loss: 0.687115537142381
Epoch: 18 | Iteration number: [3850/4518] 85% | Training loss: 0.6871133231187796
Epoch: 18 | Iteration number: [3860/4518] 85% | Training loss: 0.6871127482831787
Epoch: 18 | Iteration number: [3870/4518] 85% | Training loss: 0.6871104773162872
Epoch: 18 | Iteration number: [3880/4518] 85% | Training loss: 0.6871121214683523
Epoch: 18 | Iteration number: [3890/4518] 86% | Training loss: 0.6871120787984608
Epoch: 18 | Iteration number: [3900/4518] 86% | Training loss: 0.6871079229697203
Epoch: 18 | Iteration number: [3910/4518] 86% | Training loss: 0.6871059143177384
Epoch: 18 | Iteration number: [3920/4518] 86% | Training loss: 0.6871050951736314
Epoch: 18 | Iteration number: [3930/4518] 86% | Training loss: 0.6871050872420537
Epoch: 18 | Iteration number: [3940/4518] 87% | Training loss: 0.6871061300868311
Epoch: 18 | Iteration number: [3950/4518] 87% | Training loss: 0.6871015527127664
Epoch: 18 | Iteration number: [3960/4518] 87% | Training loss: 0.6871034203454701
Epoch: 18 | Iteration number: [3970/4518] 87% | Training loss: 0.6871071725558274
Epoch: 18 | Iteration number: [3980/4518] 88% | Training loss: 0.687108233016939
Epoch: 18 | Iteration number: [3990/4518] 88% | Training loss: 0.6871024125948885
Epoch: 18 | Iteration number: [4000/4518] 88% | Training loss: 0.6870953846126795
Epoch: 18 | Iteration number: [4010/4518] 88% | Training loss: 0.6870941689930057
Epoch: 18 | Iteration number: [4020/4518] 88% | Training loss: 0.6870958337588097
Epoch: 18 | Iteration number: [4030/4518] 89% | Training loss: 0.6870972641200641
Epoch: 18 | Iteration number: [4040/4518] 89% | Training loss: 0.6870960819396642
Epoch: 18 | Iteration number: [4050/4518] 89% | Training loss: 0.6870933406882815
Epoch: 18 | Iteration number: [4060/4518] 89% | Training loss: 0.6870962777895293
Epoch: 18 | Iteration number: [4070/4518] 90% | Training loss: 0.687096789266905
Epoch: 18 | Iteration number: [4080/4518] 90% | Training loss: 0.6870955003973316
Epoch: 18 | Iteration number: [4090/4518] 90% | Training loss: 0.6870911468212062
Epoch: 18 | Iteration number: [4100/4518] 90% | Training loss: 0.6870926854087085
Epoch: 18 | Iteration number: [4110/4518] 90% | Training loss: 0.6870913507729551
Epoch: 18 | Iteration number: [4120/4518] 91% | Training loss: 0.6870933647439318
Epoch: 18 | Iteration number: [4130/4518] 91% | Training loss: 0.6870900563985903
Epoch: 18 | Iteration number: [4140/4518] 91% | Training loss: 0.687089587510496
Epoch: 18 | Iteration number: [4150/4518] 91% | Training loss: 0.6870892203141408
Epoch: 18 | Iteration number: [4160/4518] 92% | Training loss: 0.6870893478393555
Epoch: 18 | Iteration number: [4170/4518] 92% | Training loss: 0.6870908828376294
Epoch: 18 | Iteration number: [4180/4518] 92% | Training loss: 0.6870882367403314
Epoch: 18 | Iteration number: [4190/4518] 92% | Training loss: 0.6870926018830984
Epoch: 18 | Iteration number: [4200/4518] 92% | Training loss: 0.6870943532387416
Epoch: 18 | Iteration number: [4210/4518] 93% | Training loss: 0.6870931715551861
Epoch: 18 | Iteration number: [4220/4518] 93% | Training loss: 0.6870955105500198
Epoch: 18 | Iteration number: [4230/4518] 93% | Training loss: 0.6870935420195262
Epoch: 18 | Iteration number: [4240/4518] 93% | Training loss: 0.6870923106259895
Epoch: 18 | Iteration number: [4250/4518] 94% | Training loss: 0.6870924159078037
Epoch: 18 | Iteration number: [4260/4518] 94% | Training loss: 0.6870911827249706
Epoch: 18 | Iteration number: [4270/4518] 94% | Training loss: 0.6870926650681596
Epoch: 18 | Iteration number: [4280/4518] 94% | Training loss: 0.6870908059249414
Epoch: 18 | Iteration number: [4290/4518] 94% | Training loss: 0.6870897503165933
Epoch: 18 | Iteration number: [4300/4518] 95% | Training loss: 0.6870878895077595
Epoch: 18 | Iteration number: [4310/4518] 95% | Training loss: 0.6870872441964471
Epoch: 18 | Iteration number: [4320/4518] 95% | Training loss: 0.6870848684399217
Epoch: 18 | Iteration number: [4330/4518] 95% | Training loss: 0.6870843032491124
Epoch: 18 | Iteration number: [4340/4518] 96% | Training loss: 0.687085453939328
Epoch: 18 | Iteration number: [4350/4518] 96% | Training loss: 0.6870801172722345
Epoch: 18 | Iteration number: [4360/4518] 96% | Training loss: 0.687077055721108
Epoch: 18 | Iteration number: [4370/4518] 96% | Training loss: 0.6870757675416409
Epoch: 18 | Iteration number: [4380/4518] 96% | Training loss: 0.6870749028306029
Epoch: 18 | Iteration number: [4390/4518] 97% | Training loss: 0.6870744373505099
Epoch: 18 | Iteration number: [4400/4518] 97% | Training loss: 0.687074123011394
Epoch: 18 | Iteration number: [4410/4518] 97% | Training loss: 0.6870745731454317
Epoch: 18 | Iteration number: [4420/4518] 97% | Training loss: 0.687072084850855
Epoch: 18 | Iteration number: [4430/4518] 98% | Training loss: 0.6870714055630747
Epoch: 18 | Iteration number: [4440/4518] 98% | Training loss: 0.6870719916111714
Epoch: 18 | Iteration number: [4450/4518] 98% | Training loss: 0.6870710100886527
Epoch: 18 | Iteration number: [4460/4518] 98% | Training loss: 0.687069862319215
Epoch: 18 | Iteration number: [4470/4518] 98% | Training loss: 0.6870716619411571
Epoch: 18 | Iteration number: [4480/4518] 99% | Training loss: 0.6870696491827922
Epoch: 18 | Iteration number: [4490/4518] 99% | Training loss: 0.6870694277944969
Epoch: 18 | Iteration number: [4500/4518] 99% | Training loss: 0.6870716121859021
Epoch: 18 | Iteration number: [4510/4518] 99% | Training loss: 0.6870709768948693

 End of epoch: 18 | Train Loss: 0.6869167595930256 | Training Time: 641 

 End of epoch: 18 | Eval Loss: 0.6902476342356935 | Evaluating Time: 16 
Epoch: 19 | Iteration number: [10/4518] 0% | Training loss: 0.7557187974452972
Epoch: 19 | Iteration number: [20/4518] 0% | Training loss: 0.7217167854309082
Epoch: 19 | Iteration number: [30/4518] 0% | Training loss: 0.7097661197185516
Epoch: 19 | Iteration number: [40/4518] 0% | Training loss: 0.7038972735404968
Epoch: 19 | Iteration number: [50/4518] 1% | Training loss: 0.7005659055709839
Epoch: 19 | Iteration number: [60/4518] 1% | Training loss: 0.69839781721433
Epoch: 19 | Iteration number: [70/4518] 1% | Training loss: 0.6966376159872327
Epoch: 19 | Iteration number: [80/4518] 1% | Training loss: 0.6955113187432289
Epoch: 19 | Iteration number: [90/4518] 1% | Training loss: 0.6945311586062114
Epoch: 19 | Iteration number: [100/4518] 2% | Training loss: 0.6937298309803009
Epoch: 19 | Iteration number: [110/4518] 2% | Training loss: 0.6931500667875463
Epoch: 19 | Iteration number: [120/4518] 2% | Training loss: 0.6925924728314082
Epoch: 19 | Iteration number: [130/4518] 2% | Training loss: 0.6921741238007179
Epoch: 19 | Iteration number: [140/4518] 3% | Training loss: 0.6918173564331872
Epoch: 19 | Iteration number: [150/4518] 3% | Training loss: 0.6913845948378246
Epoch: 19 | Iteration number: [160/4518] 3% | Training loss: 0.6911381497979164
Epoch: 19 | Iteration number: [170/4518] 3% | Training loss: 0.6908958224689259
Epoch: 19 | Iteration number: [180/4518] 3% | Training loss: 0.6907657729254828
Epoch: 19 | Iteration number: [190/4518] 4% | Training loss: 0.6905536450837788
Epoch: 19 | Iteration number: [200/4518] 4% | Training loss: 0.6903353795409203
Epoch: 19 | Iteration number: [210/4518] 4% | Training loss: 0.6901444395383199
Epoch: 19 | Iteration number: [220/4518] 4% | Training loss: 0.6899321244521575
Epoch: 19 | Iteration number: [230/4518] 5% | Training loss: 0.6898097325926241
Epoch: 19 | Iteration number: [240/4518] 5% | Training loss: 0.6897035837173462
Epoch: 19 | Iteration number: [250/4518] 5% | Training loss: 0.6896037034988404
Epoch: 19 | Iteration number: [260/4518] 5% | Training loss: 0.6894613194924134
Epoch: 19 | Iteration number: [270/4518] 5% | Training loss: 0.689394932323032
Epoch: 19 | Iteration number: [280/4518] 6% | Training loss: 0.6892731543098177
Epoch: 19 | Iteration number: [290/4518] 6% | Training loss: 0.6891442699679013
Epoch: 19 | Iteration number: [300/4518] 6% | Training loss: 0.6891053150097529
Epoch: 19 | Iteration number: [310/4518] 6% | Training loss: 0.6890608816377578
Epoch: 19 | Iteration number: [320/4518] 7% | Training loss: 0.6889864372089505
Epoch: 19 | Iteration number: [330/4518] 7% | Training loss: 0.6889461150675109
Epoch: 19 | Iteration number: [340/4518] 7% | Training loss: 0.6888957514482386
Epoch: 19 | Iteration number: [350/4518] 7% | Training loss: 0.6888013894217355
Epoch: 19 | Iteration number: [360/4518] 7% | Training loss: 0.6887229992283715
Epoch: 19 | Iteration number: [370/4518] 8% | Training loss: 0.6886477470397949
Epoch: 19 | Iteration number: [380/4518] 8% | Training loss: 0.6885876617933574
Epoch: 19 | Iteration number: [390/4518] 8% | Training loss: 0.6885519580963331
Epoch: 19 | Iteration number: [400/4518] 8% | Training loss: 0.6885418286919593
Epoch: 19 | Iteration number: [410/4518] 9% | Training loss: 0.6884971016790808
Epoch: 19 | Iteration number: [420/4518] 9% | Training loss: 0.6884667792490551
Epoch: 19 | Iteration number: [430/4518] 9% | Training loss: 0.6884590161401172
Epoch: 19 | Iteration number: [440/4518] 9% | Training loss: 0.6884274553168904
Epoch: 19 | Iteration number: [450/4518] 9% | Training loss: 0.688369193871816
Epoch: 19 | Iteration number: [460/4518] 10% | Training loss: 0.6883194885824038
Epoch: 19 | Iteration number: [470/4518] 10% | Training loss: 0.6882814503730612
Epoch: 19 | Iteration number: [480/4518] 10% | Training loss: 0.6882570707549651
Epoch: 19 | Iteration number: [490/4518] 10% | Training loss: 0.6882286973145544
Epoch: 19 | Iteration number: [500/4518] 11% | Training loss: 0.6881908683776855
Epoch: 19 | Iteration number: [510/4518] 11% | Training loss: 0.6881704070988823
Epoch: 19 | Iteration number: [520/4518] 11% | Training loss: 0.6881603340689952
Epoch: 19 | Iteration number: [530/4518] 11% | Training loss: 0.6881307141960792
Epoch: 19 | Iteration number: [540/4518] 11% | Training loss: 0.6881324514194771
Epoch: 19 | Iteration number: [550/4518] 12% | Training loss: 0.6880948253111406
Epoch: 19 | Iteration number: [560/4518] 12% | Training loss: 0.6880706332623958
Epoch: 19 | Iteration number: [570/4518] 12% | Training loss: 0.6880433876263468
Epoch: 19 | Iteration number: [580/4518] 12% | Training loss: 0.688039295015664
Epoch: 19 | Iteration number: [590/4518] 13% | Training loss: 0.6880382311546196
Epoch: 19 | Iteration number: [600/4518] 13% | Training loss: 0.6880129678050677
Epoch: 19 | Iteration number: [610/4518] 13% | Training loss: 0.6879812909931433
Epoch: 19 | Iteration number: [620/4518] 13% | Training loss: 0.6879611273927073
Epoch: 19 | Iteration number: [630/4518] 13% | Training loss: 0.6879342059294383
Epoch: 19 | Iteration number: [640/4518] 14% | Training loss: 0.6879285586066544
Epoch: 19 | Iteration number: [650/4518] 14% | Training loss: 0.6878951948422652
Epoch: 19 | Iteration number: [660/4518] 14% | Training loss: 0.6878736336122859
Epoch: 19 | Iteration number: [670/4518] 14% | Training loss: 0.6878731371751472
Epoch: 19 | Iteration number: [680/4518] 15% | Training loss: 0.6878597118398723
Epoch: 19 | Iteration number: [690/4518] 15% | Training loss: 0.6878668717716051
Epoch: 19 | Iteration number: [700/4518] 15% | Training loss: 0.6878756782838277
Epoch: 19 | Iteration number: [710/4518] 15% | Training loss: 0.6878301477768052
Epoch: 19 | Iteration number: [720/4518] 15% | Training loss: 0.6878254102336036
Epoch: 19 | Iteration number: [730/4518] 16% | Training loss: 0.6878028646723865
Epoch: 19 | Iteration number: [740/4518] 16% | Training loss: 0.6877878404146917
Epoch: 19 | Iteration number: [750/4518] 16% | Training loss: 0.6877743748823801
Epoch: 19 | Iteration number: [760/4518] 16% | Training loss: 0.6877559388154432
Epoch: 19 | Iteration number: [770/4518] 17% | Training loss: 0.6877459743580261
Epoch: 19 | Iteration number: [780/4518] 17% | Training loss: 0.6877267143665216
Epoch: 19 | Iteration number: [790/4518] 17% | Training loss: 0.6877401529988156
Epoch: 19 | Iteration number: [800/4518] 17% | Training loss: 0.6877314326912165
Epoch: 19 | Iteration number: [810/4518] 17% | Training loss: 0.6877292304863164
Epoch: 19 | Iteration number: [820/4518] 18% | Training loss: 0.6877281750847654
Epoch: 19 | Iteration number: [830/4518] 18% | Training loss: 0.6877113512481552
Epoch: 19 | Iteration number: [840/4518] 18% | Training loss: 0.6877164653369359
Epoch: 19 | Iteration number: [850/4518] 18% | Training loss: 0.6876977126037374
Epoch: 19 | Iteration number: [860/4518] 19% | Training loss: 0.6877035712086877
Epoch: 19 | Iteration number: [870/4518] 19% | Training loss: 0.6876938256039017
Epoch: 19 | Iteration number: [880/4518] 19% | Training loss: 0.6876720064065673
Epoch: 19 | Iteration number: [890/4518] 19% | Training loss: 0.6876530314429422
Epoch: 19 | Iteration number: [900/4518] 19% | Training loss: 0.6876503238413069
Epoch: 19 | Iteration number: [910/4518] 20% | Training loss: 0.6876533700869634
Epoch: 19 | Iteration number: [920/4518] 20% | Training loss: 0.6876463381492574
Epoch: 19 | Iteration number: [930/4518] 20% | Training loss: 0.6876342986860583
Epoch: 19 | Iteration number: [940/4518] 20% | Training loss: 0.6876153337194565
Epoch: 19 | Iteration number: [950/4518] 21% | Training loss: 0.6876113296182532
Epoch: 19 | Iteration number: [960/4518] 21% | Training loss: 0.6875865318501989
Epoch: 19 | Iteration number: [970/4518] 21% | Training loss: 0.6875850529400344
Epoch: 19 | Iteration number: [980/4518] 21% | Training loss: 0.6875699909365907
Epoch: 19 | Iteration number: [990/4518] 21% | Training loss: 0.6875686057288237
Epoch: 19 | Iteration number: [1000/4518] 22% | Training loss: 0.6875741481184959
Epoch: 19 | Iteration number: [1010/4518] 22% | Training loss: 0.6875644801276746
Epoch: 19 | Iteration number: [1020/4518] 22% | Training loss: 0.687571409519981
Epoch: 19 | Iteration number: [1030/4518] 22% | Training loss: 0.6875714368033178
Epoch: 19 | Iteration number: [1040/4518] 23% | Training loss: 0.6875839406481156
Epoch: 19 | Iteration number: [1050/4518] 23% | Training loss: 0.6875811890761058
Epoch: 19 | Iteration number: [1060/4518] 23% | Training loss: 0.6875740864929163
Epoch: 19 | Iteration number: [1070/4518] 23% | Training loss: 0.6875677427955877
Epoch: 19 | Iteration number: [1080/4518] 23% | Training loss: 0.6875718995928765
Epoch: 19 | Iteration number: [1090/4518] 24% | Training loss: 0.6875686693082163
Epoch: 19 | Iteration number: [1100/4518] 24% | Training loss: 0.687570467970588
Epoch: 19 | Iteration number: [1110/4518] 24% | Training loss: 0.6875645754036602
Epoch: 19 | Iteration number: [1120/4518] 24% | Training loss: 0.6875581334744181
Epoch: 19 | Iteration number: [1130/4518] 25% | Training loss: 0.6875464123962199
Epoch: 19 | Iteration number: [1140/4518] 25% | Training loss: 0.687542264764769
Epoch: 19 | Iteration number: [1150/4518] 25% | Training loss: 0.6875375361546227
Epoch: 19 | Iteration number: [1160/4518] 25% | Training loss: 0.6875398375350853
Epoch: 19 | Iteration number: [1170/4518] 25% | Training loss: 0.6875354783657269
Epoch: 19 | Iteration number: [1180/4518] 26% | Training loss: 0.6875344163785546
Epoch: 19 | Iteration number: [1190/4518] 26% | Training loss: 0.6875372598652079
Epoch: 19 | Iteration number: [1200/4518] 26% | Training loss: 0.6875309576094151
Epoch: 19 | Iteration number: [1210/4518] 26% | Training loss: 0.6875301803439117
Epoch: 19 | Iteration number: [1220/4518] 27% | Training loss: 0.6875341614250277
Epoch: 19 | Iteration number: [1230/4518] 27% | Training loss: 0.6875211612480443
Epoch: 19 | Iteration number: [1240/4518] 27% | Training loss: 0.6875198986261122
Epoch: 19 | Iteration number: [1250/4518] 27% | Training loss: 0.6875130610466004
Epoch: 19 | Iteration number: [1260/4518] 27% | Training loss: 0.6875020276459437
Epoch: 19 | Iteration number: [1270/4518] 28% | Training loss: 0.6874984304735979
Epoch: 19 | Iteration number: [1280/4518] 28% | Training loss: 0.6874914041254669
Epoch: 19 | Iteration number: [1290/4518] 28% | Training loss: 0.6874872206255447
Epoch: 19 | Iteration number: [1300/4518] 28% | Training loss: 0.6874724500912887
Epoch: 19 | Iteration number: [1310/4518] 28% | Training loss: 0.6874652845258932
Epoch: 19 | Iteration number: [1320/4518] 29% | Training loss: 0.6874574245828571
Epoch: 19 | Iteration number: [1330/4518] 29% | Training loss: 0.6874525396447433
Epoch: 19 | Iteration number: [1340/4518] 29% | Training loss: 0.6874357859145349
Epoch: 19 | Iteration number: [1350/4518] 29% | Training loss: 0.687430415197655
Epoch: 19 | Iteration number: [1360/4518] 30% | Training loss: 0.6874234336702263
Epoch: 19 | Iteration number: [1370/4518] 30% | Training loss: 0.6874255954784199
Epoch: 19 | Iteration number: [1380/4518] 30% | Training loss: 0.6874204176923503
Epoch: 19 | Iteration number: [1390/4518] 30% | Training loss: 0.687416356073009
Epoch: 19 | Iteration number: [1400/4518] 30% | Training loss: 0.6874074660028731
Epoch: 19 | Iteration number: [1410/4518] 31% | Training loss: 0.6873911137699236
Epoch: 19 | Iteration number: [1420/4518] 31% | Training loss: 0.6873873611571084
Epoch: 19 | Iteration number: [1430/4518] 31% | Training loss: 0.6873860605529972
Epoch: 19 | Iteration number: [1440/4518] 31% | Training loss: 0.6873902496778302
Epoch: 19 | Iteration number: [1450/4518] 32% | Training loss: 0.6873897961501417
Epoch: 19 | Iteration number: [1460/4518] 32% | Training loss: 0.6873886638308224
Epoch: 19 | Iteration number: [1470/4518] 32% | Training loss: 0.6873857162436661
Epoch: 19 | Iteration number: [1480/4518] 32% | Training loss: 0.6873933214190844
Epoch: 19 | Iteration number: [1490/4518] 32% | Training loss: 0.6873891598826287
Epoch: 19 | Iteration number: [1500/4518] 33% | Training loss: 0.6873878926038742
Epoch: 19 | Iteration number: [1510/4518] 33% | Training loss: 0.687377003368163
Epoch: 19 | Iteration number: [1520/4518] 33% | Training loss: 0.6873755134642124
Epoch: 19 | Iteration number: [1530/4518] 33% | Training loss: 0.6873586526493621
Epoch: 19 | Iteration number: [1540/4518] 34% | Training loss: 0.6873459903063712
Epoch: 19 | Iteration number: [1550/4518] 34% | Training loss: 0.6873429221876206
Epoch: 19 | Iteration number: [1560/4518] 34% | Training loss: 0.6873348787044867
Epoch: 19 | Iteration number: [1570/4518] 34% | Training loss: 0.6873329776487532
Epoch: 19 | Iteration number: [1580/4518] 34% | Training loss: 0.6873305090997792
Epoch: 19 | Iteration number: [1590/4518] 35% | Training loss: 0.6873348628949819
Epoch: 19 | Iteration number: [1600/4518] 35% | Training loss: 0.6873388669639826
Epoch: 19 | Iteration number: [1610/4518] 35% | Training loss: 0.6873390113715059
Epoch: 19 | Iteration number: [1620/4518] 35% | Training loss: 0.687337091969855
Epoch: 19 | Iteration number: [1630/4518] 36% | Training loss: 0.6873347953419012
Epoch: 19 | Iteration number: [1640/4518] 36% | Training loss: 0.6873327761161618
Epoch: 19 | Iteration number: [1650/4518] 36% | Training loss: 0.6873328334634954
Epoch: 19 | Iteration number: [1660/4518] 36% | Training loss: 0.6873326662075089
Epoch: 19 | Iteration number: [1670/4518] 36% | Training loss: 0.687331603315776
Epoch: 19 | Iteration number: [1680/4518] 37% | Training loss: 0.6873373878144082
Epoch: 19 | Iteration number: [1690/4518] 37% | Training loss: 0.6873360627501673
Epoch: 19 | Iteration number: [1700/4518] 37% | Training loss: 0.6873334388522541
Epoch: 19 | Iteration number: [1710/4518] 37% | Training loss: 0.6873276560975794
Epoch: 19 | Iteration number: [1720/4518] 38% | Training loss: 0.6873231801529264
Epoch: 19 | Iteration number: [1730/4518] 38% | Training loss: 0.687322097465482
Epoch: 19 | Iteration number: [1740/4518] 38% | Training loss: 0.6873201016722055
Epoch: 19 | Iteration number: [1750/4518] 38% | Training loss: 0.6873180879524776
Epoch: 19 | Iteration number: [1760/4518] 38% | Training loss: 0.6873192596503279
Epoch: 19 | Iteration number: [1770/4518] 39% | Training loss: 0.687313511075273
Epoch: 19 | Iteration number: [1780/4518] 39% | Training loss: 0.6873169362210156
Epoch: 19 | Iteration number: [1790/4518] 39% | Training loss: 0.6873144494754642
Epoch: 19 | Iteration number: [1800/4518] 39% | Training loss: 0.6873078720106018
Epoch: 19 | Iteration number: [1810/4518] 40% | Training loss: 0.6872975661609713
Epoch: 19 | Iteration number: [1820/4518] 40% | Training loss: 0.6872955742773119
Epoch: 19 | Iteration number: [1830/4518] 40% | Training loss: 0.687285643881136
Epoch: 19 | Iteration number: [1840/4518] 40% | Training loss: 0.6872811938109605
Epoch: 19 | Iteration number: [1850/4518] 40% | Training loss: 0.6872786940110697
Epoch: 19 | Iteration number: [1860/4518] 41% | Training loss: 0.6872824947680196
Epoch: 19 | Iteration number: [1870/4518] 41% | Training loss: 0.6872840410885326
Epoch: 19 | Iteration number: [1880/4518] 41% | Training loss: 0.6872767659894964
Epoch: 19 | Iteration number: [1890/4518] 41% | Training loss: 0.68728602169052
Epoch: 19 | Iteration number: [1900/4518] 42% | Training loss: 0.6872833148115559
Epoch: 19 | Iteration number: [1910/4518] 42% | Training loss: 0.6872825755498796
Epoch: 19 | Iteration number: [1920/4518] 42% | Training loss: 0.6872820927761495
Epoch: 19 | Iteration number: [1930/4518] 42% | Training loss: 0.6872764317791696
Epoch: 19 | Iteration number: [1940/4518] 42% | Training loss: 0.6872815490997943
Epoch: 19 | Iteration number: [1950/4518] 43% | Training loss: 0.6872796132014348
Epoch: 19 | Iteration number: [1960/4518] 43% | Training loss: 0.6872757642548911
Epoch: 19 | Iteration number: [1970/4518] 43% | Training loss: 0.6872737012538813
Epoch: 19 | Iteration number: [1980/4518] 43% | Training loss: 0.6872716907900993
Epoch: 19 | Iteration number: [1990/4518] 44% | Training loss: 0.6872699931338804
Epoch: 19 | Iteration number: [2000/4518] 44% | Training loss: 0.6872691765129566
Epoch: 19 | Iteration number: [2010/4518] 44% | Training loss: 0.687267141437056
Epoch: 19 | Iteration number: [2020/4518] 44% | Training loss: 0.6872616031972488
Epoch: 19 | Iteration number: [2030/4518] 44% | Training loss: 0.6872604433538878
Epoch: 19 | Iteration number: [2040/4518] 45% | Training loss: 0.6872603246394325
Epoch: 19 | Iteration number: [2050/4518] 45% | Training loss: 0.6872559043837757
Epoch: 19 | Iteration number: [2060/4518] 45% | Training loss: 0.6872564867283534
Epoch: 19 | Iteration number: [2070/4518] 45% | Training loss: 0.6872569818715543
Epoch: 19 | Iteration number: [2080/4518] 46% | Training loss: 0.6872525597994145
Epoch: 19 | Iteration number: [2090/4518] 46% | Training loss: 0.6872441799446727
Epoch: 19 | Iteration number: [2100/4518] 46% | Training loss: 0.6872405582950228
Epoch: 19 | Iteration number: [2110/4518] 46% | Training loss: 0.6872409155583494
Epoch: 19 | Iteration number: [2120/4518] 46% | Training loss: 0.6872390595528315
Epoch: 19 | Iteration number: [2130/4518] 47% | Training loss: 0.6872367649850711
Epoch: 19 | Iteration number: [2140/4518] 47% | Training loss: 0.6872348543360969
Epoch: 19 | Iteration number: [2150/4518] 47% | Training loss: 0.6872347539801931
Epoch: 19 | Iteration number: [2160/4518] 47% | Training loss: 0.6872286781392716
Epoch: 19 | Iteration number: [2170/4518] 48% | Training loss: 0.6872243689776566
Epoch: 19 | Iteration number: [2180/4518] 48% | Training loss: 0.6872234950371838
Epoch: 19 | Iteration number: [2190/4518] 48% | Training loss: 0.6872222381367531
Epoch: 19 | Iteration number: [2200/4518] 48% | Training loss: 0.6872210500728
Epoch: 19 | Iteration number: [2210/4518] 48% | Training loss: 0.6872204786242403
Epoch: 19 | Iteration number: [2220/4518] 49% | Training loss: 0.6872217028527646
Epoch: 19 | Iteration number: [2230/4518] 49% | Training loss: 0.6872216699102
Epoch: 19 | Iteration number: [2240/4518] 49% | Training loss: 0.6872243512687939
Epoch: 19 | Iteration number: [2250/4518] 49% | Training loss: 0.6872260112232632
Epoch: 19 | Iteration number: [2260/4518] 50% | Training loss: 0.6872248502431718
Epoch: 19 | Iteration number: [2270/4518] 50% | Training loss: 0.6872285158623683
Epoch: 19 | Iteration number: [2280/4518] 50% | Training loss: 0.6872309668806561
Epoch: 19 | Iteration number: [2290/4518] 50% | Training loss: 0.6872342687767146
Epoch: 19 | Iteration number: [2300/4518] 50% | Training loss: 0.6872325102920117
Epoch: 19 | Iteration number: [2310/4518] 51% | Training loss: 0.6872309423628308
Epoch: 19 | Iteration number: [2320/4518] 51% | Training loss: 0.6872334024001812
Epoch: 19 | Iteration number: [2330/4518] 51% | Training loss: 0.6872358566957482
Epoch: 19 | Iteration number: [2340/4518] 51% | Training loss: 0.6872411599016597
Epoch: 19 | Iteration number: [2350/4518] 52% | Training loss: 0.6872408410336109
Epoch: 19 | Iteration number: [2360/4518] 52% | Training loss: 0.6872371311915123
Epoch: 19 | Iteration number: [2370/4518] 52% | Training loss: 0.6872376866229979
Epoch: 19 | Iteration number: [2380/4518] 52% | Training loss: 0.6872404834803413
Epoch: 19 | Iteration number: [2390/4518] 52% | Training loss: 0.6872393663208853
Epoch: 19 | Iteration number: [2400/4518] 53% | Training loss: 0.6872422941525778
Epoch: 19 | Iteration number: [2410/4518] 53% | Training loss: 0.6872407741071772
Epoch: 19 | Iteration number: [2420/4518] 53% | Training loss: 0.6872356528585607
Epoch: 19 | Iteration number: [2430/4518] 53% | Training loss: 0.6872351289531331
Epoch: 19 | Iteration number: [2440/4518] 54% | Training loss: 0.6872321770816553
Epoch: 19 | Iteration number: [2450/4518] 54% | Training loss: 0.6872266177985134
Epoch: 19 | Iteration number: [2460/4518] 54% | Training loss: 0.6872232329554674
Epoch: 19 | Iteration number: [2470/4518] 54% | Training loss: 0.6872195728877295
Epoch: 19 | Iteration number: [2480/4518] 54% | Training loss: 0.6872144863970818
Epoch: 19 | Iteration number: [2490/4518] 55% | Training loss: 0.6872096690068762
Epoch: 19 | Iteration number: [2500/4518] 55% | Training loss: 0.6872066125869751
Epoch: 19 | Iteration number: [2510/4518] 55% | Training loss: 0.6872069395870801
Epoch: 19 | Iteration number: [2520/4518] 55% | Training loss: 0.68720846485997
Epoch: 19 | Iteration number: [2530/4518] 55% | Training loss: 0.6872063473279297
Epoch: 19 | Iteration number: [2540/4518] 56% | Training loss: 0.6872053184377865
Epoch: 19 | Iteration number: [2550/4518] 56% | Training loss: 0.6872087110725104
Epoch: 19 | Iteration number: [2560/4518] 56% | Training loss: 0.6872039063135162
Epoch: 19 | Iteration number: [2570/4518] 56% | Training loss: 0.6872066268429218
Epoch: 19 | Iteration number: [2580/4518] 57% | Training loss: 0.687203535922738
Epoch: 19 | Iteration number: [2590/4518] 57% | Training loss: 0.6872044993183327
Epoch: 19 | Iteration number: [2600/4518] 57% | Training loss: 0.6872052386632332
Epoch: 19 | Iteration number: [2610/4518] 57% | Training loss: 0.6872031082138704
Epoch: 19 | Iteration number: [2620/4518] 57% | Training loss: 0.6872046179216327
Epoch: 19 | Iteration number: [2630/4518] 58% | Training loss: 0.6872024526387567
Epoch: 19 | Iteration number: [2640/4518] 58% | Training loss: 0.6872004717588425
Epoch: 19 | Iteration number: [2650/4518] 58% | Training loss: 0.6871939595465391
Epoch: 19 | Iteration number: [2660/4518] 58% | Training loss: 0.6871905107023124
Epoch: 19 | Iteration number: [2670/4518] 59% | Training loss: 0.6871911261858565
Epoch: 19 | Iteration number: [2680/4518] 59% | Training loss: 0.6871878345955663
Epoch: 19 | Iteration number: [2690/4518] 59% | Training loss: 0.6871907488564133
Epoch: 19 | Iteration number: [2700/4518] 59% | Training loss: 0.6871901601111448
Epoch: 19 | Iteration number: [2710/4518] 59% | Training loss: 0.6871863186139462
Epoch: 19 | Iteration number: [2720/4518] 60% | Training loss: 0.6871894484057146
Epoch: 19 | Iteration number: [2730/4518] 60% | Training loss: 0.68718640989873
Epoch: 19 | Iteration number: [2740/4518] 60% | Training loss: 0.6871872080938659
Epoch: 19 | Iteration number: [2750/4518] 60% | Training loss: 0.6871840697201815
Epoch: 19 | Iteration number: [2760/4518] 61% | Training loss: 0.6871841257896976
Epoch: 19 | Iteration number: [2770/4518] 61% | Training loss: 0.6871845991387694
Epoch: 19 | Iteration number: [2780/4518] 61% | Training loss: 0.687182126456885
Epoch: 19 | Iteration number: [2790/4518] 61% | Training loss: 0.6871796092679424
Epoch: 19 | Iteration number: [2800/4518] 61% | Training loss: 0.6871824572341783
Epoch: 19 | Iteration number: [2810/4518] 62% | Training loss: 0.6871811435740189
Epoch: 19 | Iteration number: [2820/4518] 62% | Training loss: 0.6871779683633898
Epoch: 19 | Iteration number: [2830/4518] 62% | Training loss: 0.6871760622562031
Epoch: 19 | Iteration number: [2840/4518] 62% | Training loss: 0.6871718077172696
Epoch: 19 | Iteration number: [2850/4518] 63% | Training loss: 0.6871694206354911
Epoch: 19 | Iteration number: [2860/4518] 63% | Training loss: 0.6871681716475453
Epoch: 19 | Iteration number: [2870/4518] 63% | Training loss: 0.6871637576340798
Epoch: 19 | Iteration number: [2880/4518] 63% | Training loss: 0.6871662445159422
Epoch: 19 | Iteration number: [2890/4518] 63% | Training loss: 0.6871689182870528
Epoch: 19 | Iteration number: [2900/4518] 64% | Training loss: 0.6871725912751823
Epoch: 19 | Iteration number: [2910/4518] 64% | Training loss: 0.6871740349379601
Epoch: 19 | Iteration number: [2920/4518] 64% | Training loss: 0.687175623786776
Epoch: 19 | Iteration number: [2930/4518] 64% | Training loss: 0.6871711643889495
Epoch: 19 | Iteration number: [2940/4518] 65% | Training loss: 0.6871696013171656
Epoch: 19 | Iteration number: [2950/4518] 65% | Training loss: 0.6871701402987463
Epoch: 19 | Iteration number: [2960/4518] 65% | Training loss: 0.6871710707609718
Epoch: 19 | Iteration number: [2970/4518] 65% | Training loss: 0.687167152451345
Epoch: 19 | Iteration number: [2980/4518] 65% | Training loss: 0.6871643985677885
Epoch: 19 | Iteration number: [2990/4518] 66% | Training loss: 0.687165268288807
Epoch: 19 | Iteration number: [3000/4518] 66% | Training loss: 0.6871669761339824
Epoch: 19 | Iteration number: [3010/4518] 66% | Training loss: 0.6871663448422454
Epoch: 19 | Iteration number: [3020/4518] 66% | Training loss: 0.6871639096579015
Epoch: 19 | Iteration number: [3030/4518] 67% | Training loss: 0.6871663162417144
Epoch: 19 | Iteration number: [3040/4518] 67% | Training loss: 0.6871633100862565
Epoch: 19 | Iteration number: [3050/4518] 67% | Training loss: 0.6871631274262413
Epoch: 19 | Iteration number: [3060/4518] 67% | Training loss: 0.6871643266646691
Epoch: 19 | Iteration number: [3070/4518] 67% | Training loss: 0.6871658083864455
Epoch: 19 | Iteration number: [3080/4518] 68% | Training loss: 0.687163935814585
Epoch: 19 | Iteration number: [3090/4518] 68% | Training loss: 0.6871604234269522
Epoch: 19 | Iteration number: [3100/4518] 68% | Training loss: 0.6871586093402678
Epoch: 19 | Iteration number: [3110/4518] 68% | Training loss: 0.6871559330121497
Epoch: 19 | Iteration number: [3120/4518] 69% | Training loss: 0.6871590843758522
Epoch: 19 | Iteration number: [3130/4518] 69% | Training loss: 0.6871576705870156
Epoch: 19 | Iteration number: [3140/4518] 69% | Training loss: 0.6871573932231612
Epoch: 19 | Iteration number: [3150/4518] 69% | Training loss: 0.6871558054288228
Epoch: 19 | Iteration number: [3160/4518] 69% | Training loss: 0.6871578963308395
Epoch: 19 | Iteration number: [3170/4518] 70% | Training loss: 0.6871593228273963
Epoch: 19 | Iteration number: [3180/4518] 70% | Training loss: 0.6871570822577806
Epoch: 19 | Iteration number: [3190/4518] 70% | Training loss: 0.6871554748952202
Epoch: 19 | Iteration number: [3200/4518] 70% | Training loss: 0.6871504277549684
Epoch: 19 | Iteration number: [3210/4518] 71% | Training loss: 0.6871507580220885
Epoch: 19 | Iteration number: [3220/4518] 71% | Training loss: 0.6871512834699998
Epoch: 19 | Iteration number: [3230/4518] 71% | Training loss: 0.68714933803207
Epoch: 19 | Iteration number: [3240/4518] 71% | Training loss: 0.6871499395664827
Epoch: 19 | Iteration number: [3250/4518] 71% | Training loss: 0.687147816327902
Epoch: 19 | Iteration number: [3260/4518] 72% | Training loss: 0.6871460068993773
Epoch: 19 | Iteration number: [3270/4518] 72% | Training loss: 0.6871454486788595
Epoch: 19 | Iteration number: [3280/4518] 72% | Training loss: 0.6871439706443286
Epoch: 19 | Iteration number: [3290/4518] 72% | Training loss: 0.6871428427544046
Epoch: 19 | Iteration number: [3300/4518] 73% | Training loss: 0.6871421062404459
Epoch: 19 | Iteration number: [3310/4518] 73% | Training loss: 0.6871421619484431
Epoch: 19 | Iteration number: [3320/4518] 73% | Training loss: 0.6871451435139381
Epoch: 19 | Iteration number: [3330/4518] 73% | Training loss: 0.6871478449116956
Epoch: 19 | Iteration number: [3340/4518] 73% | Training loss: 0.687147153780132
Epoch: 19 | Iteration number: [3350/4518] 74% | Training loss: 0.6871489102271066
Epoch: 19 | Iteration number: [3360/4518] 74% | Training loss: 0.6871536585191885
Epoch: 19 | Iteration number: [3370/4518] 74% | Training loss: 0.6871502672883099
Epoch: 19 | Iteration number: [3380/4518] 74% | Training loss: 0.6871470043645103
Epoch: 19 | Iteration number: [3390/4518] 75% | Training loss: 0.6871445188655966
Epoch: 19 | Iteration number: [3400/4518] 75% | Training loss: 0.6871401196192293
Epoch: 19 | Iteration number: [3410/4518] 75% | Training loss: 0.6871372938855302
Epoch: 19 | Iteration number: [3420/4518] 75% | Training loss: 0.6871375431442819
Epoch: 19 | Iteration number: [3430/4518] 75% | Training loss: 0.6871372933811766
Epoch: 19 | Iteration number: [3440/4518] 76% | Training loss: 0.6871378660895103
Epoch: 19 | Iteration number: [3450/4518] 76% | Training loss: 0.6871341549140819
Epoch: 19 | Iteration number: [3460/4518] 76% | Training loss: 0.6871354041588789
Epoch: 19 | Iteration number: [3470/4518] 76% | Training loss: 0.6871363145989025
Epoch: 19 | Iteration number: [3480/4518] 77% | Training loss: 0.6871373831883244
Epoch: 19 | Iteration number: [3490/4518] 77% | Training loss: 0.6871346889901639
Epoch: 19 | Iteration number: [3500/4518] 77% | Training loss: 0.687134239912033
Epoch: 19 | Iteration number: [3510/4518] 77% | Training loss: 0.6871342810810122
Epoch: 19 | Iteration number: [3520/4518] 77% | Training loss: 0.687137048674578
Epoch: 19 | Iteration number: [3530/4518] 78% | Training loss: 0.6871388516919134
Epoch: 19 | Iteration number: [3540/4518] 78% | Training loss: 0.6871341651105611
Epoch: 19 | Iteration number: [3550/4518] 78% | Training loss: 0.687128710679605
Epoch: 19 | Iteration number: [3560/4518] 78% | Training loss: 0.6871289091331235
Epoch: 19 | Iteration number: [3570/4518] 79% | Training loss: 0.6871266589946106
Epoch: 19 | Iteration number: [3580/4518] 79% | Training loss: 0.6871281326316588
Epoch: 19 | Iteration number: [3590/4518] 79% | Training loss: 0.6871279558763531
Epoch: 19 | Iteration number: [3600/4518] 79% | Training loss: 0.6871278253859944
Epoch: 19 | Iteration number: [3610/4518] 79% | Training loss: 0.6871283020174074
Epoch: 19 | Iteration number: [3620/4518] 80% | Training loss: 0.6871313780710842
Epoch: 19 | Iteration number: [3630/4518] 80% | Training loss: 0.6871328503796549
Epoch: 19 | Iteration number: [3640/4518] 80% | Training loss: 0.6871337958253347
Epoch: 19 | Iteration number: [3650/4518] 80% | Training loss: 0.6871311941375471
Epoch: 19 | Iteration number: [3660/4518] 81% | Training loss: 0.6871307479879244
Epoch: 19 | Iteration number: [3670/4518] 81% | Training loss: 0.6871324229630202
Epoch: 19 | Iteration number: [3680/4518] 81% | Training loss: 0.6871315043581568
Epoch: 19 | Iteration number: [3690/4518] 81% | Training loss: 0.6871302957457256
Epoch: 19 | Iteration number: [3700/4518] 81% | Training loss: 0.6871293970378669
Epoch: 19 | Iteration number: [3710/4518] 82% | Training loss: 0.6871282783319366
Epoch: 19 | Iteration number: [3720/4518] 82% | Training loss: 0.68712801534322
Epoch: 19 | Iteration number: [3730/4518] 82% | Training loss: 0.6871269739505114
Epoch: 19 | Iteration number: [3740/4518] 82% | Training loss: 0.6871270039502312
Epoch: 19 | Iteration number: [3750/4518] 83% | Training loss: 0.6871217829704285
Epoch: 19 | Iteration number: [3760/4518] 83% | Training loss: 0.6871227108734719
Epoch: 19 | Iteration number: [3770/4518] 83% | Training loss: 0.6871195121374307
Epoch: 19 | Iteration number: [3780/4518] 83% | Training loss: 0.6871182285761707
Epoch: 19 | Iteration number: [3790/4518] 83% | Training loss: 0.687119939396438
Epoch: 19 | Iteration number: [3800/4518] 84% | Training loss: 0.6871182767811574
Epoch: 19 | Iteration number: [3810/4518] 84% | Training loss: 0.6871158215317513
Epoch: 19 | Iteration number: [3820/4518] 84% | Training loss: 0.6871148760094068
Epoch: 19 | Iteration number: [3830/4518] 84% | Training loss: 0.6871160214625824
Epoch: 19 | Iteration number: [3840/4518] 84% | Training loss: 0.6871158611805489
Epoch: 19 | Iteration number: [3850/4518] 85% | Training loss: 0.6871149180307017
Epoch: 19 | Iteration number: [3860/4518] 85% | Training loss: 0.6871142517717391
Epoch: 19 | Iteration number: [3870/4518] 85% | Training loss: 0.6871120551605865
Epoch: 19 | Iteration number: [3880/4518] 85% | Training loss: 0.6871108574197464
Epoch: 19 | Iteration number: [3890/4518] 86% | Training loss: 0.6871101544418188
Epoch: 19 | Iteration number: [3900/4518] 86% | Training loss: 0.6871120785597044
Epoch: 19 | Iteration number: [3910/4518] 86% | Training loss: 0.6871104129592476
Epoch: 19 | Iteration number: [3920/4518] 86% | Training loss: 0.6871118460990945
Epoch: 19 | Iteration number: [3930/4518] 86% | Training loss: 0.6871097549985686
Epoch: 19 | Iteration number: [3940/4518] 87% | Training loss: 0.6871099059503091
Epoch: 19 | Iteration number: [3950/4518] 87% | Training loss: 0.6871048650258704
Epoch: 19 | Iteration number: [3960/4518] 87% | Training loss: 0.6871025168684998
Epoch: 19 | Iteration number: [3970/4518] 87% | Training loss: 0.6870975515404035
Epoch: 19 | Iteration number: [3980/4518] 88% | Training loss: 0.6870948082388346
Epoch: 19 | Iteration number: [3990/4518] 88% | Training loss: 0.6870906579315215
Epoch: 19 | Iteration number: [4000/4518] 88% | Training loss: 0.6870878873467445
Epoch: 19 | Iteration number: [4010/4518] 88% | Training loss: 0.6870890880017506
Epoch: 19 | Iteration number: [4020/4518] 88% | Training loss: 0.6870890865575022
Epoch: 19 | Iteration number: [4030/4518] 89% | Training loss: 0.6870853242596089
Epoch: 19 | Iteration number: [4040/4518] 89% | Training loss: 0.6870811245671593
Epoch: 19 | Iteration number: [4050/4518] 89% | Training loss: 0.6870809224799828
Epoch: 19 | Iteration number: [4060/4518] 89% | Training loss: 0.6870793950675156
Epoch: 19 | Iteration number: [4070/4518] 90% | Training loss: 0.6870808605187062
Epoch: 19 | Iteration number: [4080/4518] 90% | Training loss: 0.68707936686628
Epoch: 19 | Iteration number: [4090/4518] 90% | Training loss: 0.6870761327026526
Epoch: 19 | Iteration number: [4100/4518] 90% | Training loss: 0.6870764587855921
Epoch: 19 | Iteration number: [4110/4518] 90% | Training loss: 0.6870774766244447
Epoch: 19 | Iteration number: [4120/4518] 91% | Training loss: 0.6870755687934681
Epoch: 19 | Iteration number: [4130/4518] 91% | Training loss: 0.6870774987390486
Epoch: 19 | Iteration number: [4140/4518] 91% | Training loss: 0.6870778596775543
Epoch: 19 | Iteration number: [4150/4518] 91% | Training loss: 0.6870779414780168
Epoch: 19 | Iteration number: [4160/4518] 92% | Training loss: 0.6870817225712996
Epoch: 19 | Iteration number: [4170/4518] 92% | Training loss: 0.687082509614295
Epoch: 19 | Iteration number: [4180/4518] 92% | Training loss: 0.6870791993215324
Epoch: 19 | Iteration number: [4190/4518] 92% | Training loss: 0.6870778474147679
Epoch: 19 | Iteration number: [4200/4518] 92% | Training loss: 0.6870790441263289
Epoch: 19 | Iteration number: [4210/4518] 93% | Training loss: 0.6870813513311808
Epoch: 19 | Iteration number: [4220/4518] 93% | Training loss: 0.6870832945357002
Epoch: 19 | Iteration number: [4230/4518] 93% | Training loss: 0.6870819312883607
Epoch: 19 | Iteration number: [4240/4518] 93% | Training loss: 0.6870842340138723
Epoch: 19 | Iteration number: [4250/4518] 94% | Training loss: 0.6870830637146444
Epoch: 19 | Iteration number: [4260/4518] 94% | Training loss: 0.6870816061054597
Epoch: 19 | Iteration number: [4270/4518] 94% | Training loss: 0.6870833930561637
Epoch: 19 | Iteration number: [4280/4518] 94% | Training loss: 0.6870804462895215
Epoch: 19 | Iteration number: [4290/4518] 94% | Training loss: 0.687080618551561
Epoch: 19 | Iteration number: [4300/4518] 95% | Training loss: 0.6870803744987
Epoch: 19 | Iteration number: [4310/4518] 95% | Training loss: 0.6870800507179269
Epoch: 19 | Iteration number: [4320/4518] 95% | Training loss: 0.6870784404515117
Epoch: 19 | Iteration number: [4330/4518] 95% | Training loss: 0.6870795673641267
Epoch: 19 | Iteration number: [4340/4518] 96% | Training loss: 0.6870772801099285
Epoch: 19 | Iteration number: [4350/4518] 96% | Training loss: 0.6870746093782886
Epoch: 19 | Iteration number: [4360/4518] 96% | Training loss: 0.6870721351662907
Epoch: 19 | Iteration number: [4370/4518] 96% | Training loss: 0.6870693041749077
Epoch: 19 | Iteration number: [4380/4518] 96% | Training loss: 0.687067448834306
Epoch: 19 | Iteration number: [4390/4518] 97% | Training loss: 0.6870647815609847
Epoch: 19 | Iteration number: [4400/4518] 97% | Training loss: 0.6870651728050275
Epoch: 19 | Iteration number: [4410/4518] 97% | Training loss: 0.68706451940969
Epoch: 19 | Iteration number: [4420/4518] 97% | Training loss: 0.6870622751804498
Epoch: 19 | Iteration number: [4430/4518] 98% | Training loss: 0.6870601238838437
Epoch: 19 | Iteration number: [4440/4518] 98% | Training loss: 0.6870572032020973
Epoch: 19 | Iteration number: [4450/4518] 98% | Training loss: 0.6870548236236144
Epoch: 19 | Iteration number: [4460/4518] 98% | Training loss: 0.6870545646133979
Epoch: 19 | Iteration number: [4470/4518] 98% | Training loss: 0.6870539441471398
Epoch: 19 | Iteration number: [4480/4518] 99% | Training loss: 0.6870556268574936
Epoch: 19 | Iteration number: [4490/4518] 99% | Training loss: 0.6870553034583816
Epoch: 19 | Iteration number: [4500/4518] 99% | Training loss: 0.6870571590662002
Epoch: 19 | Iteration number: [4510/4518] 99% | Training loss: 0.6870584340158957

 End of epoch: 19 | Train Loss: 0.6869051914238307 | Training Time: 642 

 End of epoch: 19 | Eval Loss: 0.6901231639239253 | Evaluating Time: 17 
Epoch: 20 | Iteration number: [10/4518] 0% | Training loss: 0.7556111633777618
Epoch: 20 | Iteration number: [20/4518] 0% | Training loss: 0.7215683281421661
Epoch: 20 | Iteration number: [30/4518] 0% | Training loss: 0.7101185699303945
Epoch: 20 | Iteration number: [40/4518] 0% | Training loss: 0.7044730380177497
Epoch: 20 | Iteration number: [50/4518] 1% | Training loss: 0.7010778844356537
Epoch: 20 | Iteration number: [60/4518] 1% | Training loss: 0.6986574441194534
Epoch: 20 | Iteration number: [70/4518] 1% | Training loss: 0.6970864083085742
Epoch: 20 | Iteration number: [80/4518] 1% | Training loss: 0.6958283521234989
Epoch: 20 | Iteration number: [90/4518] 1% | Training loss: 0.6947187456819747
Epoch: 20 | Iteration number: [100/4518] 2% | Training loss: 0.6938983207941055
Epoch: 20 | Iteration number: [110/4518] 2% | Training loss: 0.6932684892957861
Epoch: 20 | Iteration number: [120/4518] 2% | Training loss: 0.692630073428154
Epoch: 20 | Iteration number: [130/4518] 2% | Training loss: 0.6923128265600939
Epoch: 20 | Iteration number: [140/4518] 3% | Training loss: 0.6920183168990272
Epoch: 20 | Iteration number: [150/4518] 3% | Training loss: 0.6917042505741119
Epoch: 20 | Iteration number: [160/4518] 3% | Training loss: 0.6914058234542608
Epoch: 20 | Iteration number: [170/4518] 3% | Training loss: 0.6911552309989929
Epoch: 20 | Iteration number: [180/4518] 3% | Training loss: 0.6908951431512833
Epoch: 20 | Iteration number: [190/4518] 4% | Training loss: 0.6906607784722981
Epoch: 20 | Iteration number: [200/4518] 4% | Training loss: 0.690467204451561
Epoch: 20 | Iteration number: [210/4518] 4% | Training loss: 0.6902957195327395
Epoch: 20 | Iteration number: [220/4518] 4% | Training loss: 0.6901694744825363
Epoch: 20 | Iteration number: [230/4518] 5% | Training loss: 0.6900023110534834
Epoch: 20 | Iteration number: [240/4518] 5% | Training loss: 0.6898265036443869
Epoch: 20 | Iteration number: [250/4518] 5% | Training loss: 0.6897644901275635
Epoch: 20 | Iteration number: [260/4518] 5% | Training loss: 0.689667082291383
Epoch: 20 | Iteration number: [270/4518] 5% | Training loss: 0.6895609676837922
Epoch: 20 | Iteration number: [280/4518] 6% | Training loss: 0.6894209491355079
Epoch: 20 | Iteration number: [290/4518] 6% | Training loss: 0.6893577164617078
Epoch: 20 | Iteration number: [300/4518] 6% | Training loss: 0.6892791004975637
Epoch: 20 | Iteration number: [310/4518] 6% | Training loss: 0.6892488673810035
Epoch: 20 | Iteration number: [320/4518] 7% | Training loss: 0.689161136560142
Epoch: 20 | Iteration number: [330/4518] 7% | Training loss: 0.6891296021866076
Epoch: 20 | Iteration number: [340/4518] 7% | Training loss: 0.6890689231017056
Epoch: 20 | Iteration number: [350/4518] 7% | Training loss: 0.6890028188909804
Epoch: 20 | Iteration number: [360/4518] 7% | Training loss: 0.6889614800612132
Epoch: 20 | Iteration number: [370/4518] 8% | Training loss: 0.6889022153777045
Epoch: 20 | Iteration number: [380/4518] 8% | Training loss: 0.6888123968714162
Epoch: 20 | Iteration number: [390/4518] 8% | Training loss: 0.6887695071024772
Epoch: 20 | Iteration number: [400/4518] 8% | Training loss: 0.6887228685617447
Epoch: 20 | Iteration number: [410/4518] 9% | Training loss: 0.6886695581238444
Epoch: 20 | Iteration number: [420/4518] 9% | Training loss: 0.6886285954997653
Epoch: 20 | Iteration number: [430/4518] 9% | Training loss: 0.6885817660841831
Epoch: 20 | Iteration number: [440/4518] 9% | Training loss: 0.6885397308252075
Epoch: 20 | Iteration number: [450/4518] 9% | Training loss: 0.6885019348727333
Epoch: 20 | Iteration number: [460/4518] 10% | Training loss: 0.6884390326945679
Epoch: 20 | Iteration number: [470/4518] 10% | Training loss: 0.6884086452900096
Epoch: 20 | Iteration number: [480/4518] 10% | Training loss: 0.6883879117667675
Epoch: 20 | Iteration number: [490/4518] 10% | Training loss: 0.6883484863505072
Epoch: 20 | Iteration number: [500/4518] 11% | Training loss: 0.688331447839737
Epoch: 20 | Iteration number: [510/4518] 11% | Training loss: 0.6882929243293463
Epoch: 20 | Iteration number: [520/4518] 11% | Training loss: 0.6882594102850327
Epoch: 20 | Iteration number: [530/4518] 11% | Training loss: 0.6882506325559796
Epoch: 20 | Iteration number: [540/4518] 11% | Training loss: 0.6882226483689414
Epoch: 20 | Iteration number: [550/4518] 12% | Training loss: 0.6881855428218842
Epoch: 20 | Iteration number: [560/4518] 12% | Training loss: 0.688170455715486
Epoch: 20 | Iteration number: [570/4518] 12% | Training loss: 0.6881341851594155
Epoch: 20 | Iteration number: [580/4518] 12% | Training loss: 0.6881404094654938
Epoch: 20 | Iteration number: [590/4518] 13% | Training loss: 0.6881147354336108
Epoch: 20 | Iteration number: [600/4518] 13% | Training loss: 0.688105836113294
Epoch: 20 | Iteration number: [610/4518] 13% | Training loss: 0.6880711481219433
Epoch: 20 | Iteration number: [620/4518] 13% | Training loss: 0.6880430694549314
Epoch: 20 | Iteration number: [630/4518] 13% | Training loss: 0.6880401648226239
Epoch: 20 | Iteration number: [640/4518] 14% | Training loss: 0.68802728401497
Epoch: 20 | Iteration number: [650/4518] 14% | Training loss: 0.6880252697834601
Epoch: 20 | Iteration number: [660/4518] 14% | Training loss: 0.6879869279536334
Epoch: 20 | Iteration number: [670/4518] 14% | Training loss: 0.6879532980385111
Epoch: 20 | Iteration number: [680/4518] 15% | Training loss: 0.6879372113767792
Epoch: 20 | Iteration number: [690/4518] 15% | Training loss: 0.6879247020984042
Epoch: 20 | Iteration number: [700/4518] 15% | Training loss: 0.6879039199011666
Epoch: 20 | Iteration number: [710/4518] 15% | Training loss: 0.6879037955277403
Epoch: 20 | Iteration number: [720/4518] 15% | Training loss: 0.6878922507166862
Epoch: 20 | Iteration number: [730/4518] 16% | Training loss: 0.687863741100651
Epoch: 20 | Iteration number: [740/4518] 16% | Training loss: 0.6878556468196817
Epoch: 20 | Iteration number: [750/4518] 16% | Training loss: 0.6878510993321737
Epoch: 20 | Iteration number: [760/4518] 16% | Training loss: 0.6878555664890691
Epoch: 20 | Iteration number: [770/4518] 17% | Training loss: 0.6878396024177601
Epoch: 20 | Iteration number: [780/4518] 17% | Training loss: 0.6878339875202912
Epoch: 20 | Iteration number: [790/4518] 17% | Training loss: 0.6878228158135957
Epoch: 20 | Iteration number: [800/4518] 17% | Training loss: 0.6877955342829227
Epoch: 20 | Iteration number: [810/4518] 17% | Training loss: 0.6877878116972652
Epoch: 20 | Iteration number: [820/4518] 18% | Training loss: 0.6877810667200787
Epoch: 20 | Iteration number: [830/4518] 18% | Training loss: 0.6877573804682996
Epoch: 20 | Iteration number: [840/4518] 18% | Training loss: 0.6877461552619935
Epoch: 20 | Iteration number: [850/4518] 18% | Training loss: 0.6877380937688491
Epoch: 20 | Iteration number: [860/4518] 19% | Training loss: 0.6877256685911223
Epoch: 20 | Iteration number: [870/4518] 19% | Training loss: 0.6877178409318815
Epoch: 20 | Iteration number: [880/4518] 19% | Training loss: 0.6877082764425061
Epoch: 20 | Iteration number: [890/4518] 19% | Training loss: 0.6876969289913606
Epoch: 20 | Iteration number: [900/4518] 19% | Training loss: 0.6876967806286282
Epoch: 20 | Iteration number: [910/4518] 20% | Training loss: 0.6876773543410248
Epoch: 20 | Iteration number: [920/4518] 20% | Training loss: 0.687663515948731
Epoch: 20 | Iteration number: [930/4518] 20% | Training loss: 0.6876525569346643
Epoch: 20 | Iteration number: [940/4518] 20% | Training loss: 0.6876547852729229
Epoch: 20 | Iteration number: [950/4518] 21% | Training loss: 0.6876437935076262
Epoch: 20 | Iteration number: [960/4518] 21% | Training loss: 0.6876532490675648
Epoch: 20 | Iteration number: [970/4518] 21% | Training loss: 0.6876488940617473
Epoch: 20 | Iteration number: [980/4518] 21% | Training loss: 0.6876477038981963
Epoch: 20 | Iteration number: [990/4518] 21% | Training loss: 0.6876423883317697
Epoch: 20 | Iteration number: [1000/4518] 22% | Training loss: 0.6876212524175644
Epoch: 20 | Iteration number: [1010/4518] 22% | Training loss: 0.6876111113789058
Epoch: 20 | Iteration number: [1020/4518] 22% | Training loss: 0.6875864916572384
Epoch: 20 | Iteration number: [1030/4518] 22% | Training loss: 0.6875919690988597
Epoch: 20 | Iteration number: [1040/4518] 23% | Training loss: 0.6875733455213217
Epoch: 20 | Iteration number: [1050/4518] 23% | Training loss: 0.6875617934408642
Epoch: 20 | Iteration number: [1060/4518] 23% | Training loss: 0.6875495305601156
Epoch: 20 | Iteration number: [1070/4518] 23% | Training loss: 0.687531184648799
Epoch: 20 | Iteration number: [1080/4518] 23% | Training loss: 0.6875235568594049
Epoch: 20 | Iteration number: [1090/4518] 24% | Training loss: 0.6875252332709251
Epoch: 20 | Iteration number: [1100/4518] 24% | Training loss: 0.6875219429622997
Epoch: 20 | Iteration number: [1110/4518] 24% | Training loss: 0.6875152825772225
Epoch: 20 | Iteration number: [1120/4518] 24% | Training loss: 0.6875127995120628
Epoch: 20 | Iteration number: [1130/4518] 25% | Training loss: 0.6875009539380538
Epoch: 20 | Iteration number: [1140/4518] 25% | Training loss: 0.6874926102788825
Epoch: 20 | Iteration number: [1150/4518] 25% | Training loss: 0.6874869350246761
Epoch: 20 | Iteration number: [1160/4518] 25% | Training loss: 0.6874797530215362
Epoch: 20 | Iteration number: [1170/4518] 25% | Training loss: 0.6874762811212458
Epoch: 20 | Iteration number: [1180/4518] 26% | Training loss: 0.6874660594988677
Epoch: 20 | Iteration number: [1190/4518] 26% | Training loss: 0.6874571026373311
Epoch: 20 | Iteration number: [1200/4518] 26% | Training loss: 0.6874446770548821
Epoch: 20 | Iteration number: [1210/4518] 26% | Training loss: 0.687447348705008
Epoch: 20 | Iteration number: [1220/4518] 27% | Training loss: 0.6874394368441379
Epoch: 20 | Iteration number: [1230/4518] 27% | Training loss: 0.6874282064476633
Epoch: 20 | Iteration number: [1240/4518] 27% | Training loss: 0.6874342557403349
Epoch: 20 | Iteration number: [1250/4518] 27% | Training loss: 0.6874222686290741
Epoch: 20 | Iteration number: [1260/4518] 27% | Training loss: 0.6874173319528973
Epoch: 20 | Iteration number: [1270/4518] 28% | Training loss: 0.6874207487256508
Epoch: 20 | Iteration number: [1280/4518] 28% | Training loss: 0.6874220247380436
Epoch: 20 | Iteration number: [1290/4518] 28% | Training loss: 0.687430158557818
Epoch: 20 | Iteration number: [1300/4518] 28% | Training loss: 0.6874259642454295
Epoch: 20 | Iteration number: [1310/4518] 28% | Training loss: 0.6874206053846665
Epoch: 20 | Iteration number: [1320/4518] 29% | Training loss: 0.6874150135300376
Epoch: 20 | Iteration number: [1330/4518] 29% | Training loss: 0.6874048317285408
Epoch: 20 | Iteration number: [1340/4518] 29% | Training loss: 0.6874005683767261
Epoch: 20 | Iteration number: [1350/4518] 29% | Training loss: 0.6873910151146077
Epoch: 20 | Iteration number: [1360/4518] 30% | Training loss: 0.6873901917215656
Epoch: 20 | Iteration number: [1370/4518] 30% | Training loss: 0.6873911038367417
Epoch: 20 | Iteration number: [1380/4518] 30% | Training loss: 0.6873914489279622
Epoch: 20 | Iteration number: [1390/4518] 30% | Training loss: 0.687390309657982
Epoch: 20 | Iteration number: [1400/4518] 30% | Training loss: 0.6873941500697817
Epoch: 20 | Iteration number: [1410/4518] 31% | Training loss: 0.6873937994453079
Epoch: 20 | Iteration number: [1420/4518] 31% | Training loss: 0.687391333135081
Epoch: 20 | Iteration number: [1430/4518] 31% | Training loss: 0.6873878979182744
Epoch: 20 | Iteration number: [1440/4518] 31% | Training loss: 0.6873827074964841
Epoch: 20 | Iteration number: [1450/4518] 32% | Training loss: 0.6873703580067075
Epoch: 20 | Iteration number: [1460/4518] 32% | Training loss: 0.6873645859630141
Epoch: 20 | Iteration number: [1470/4518] 32% | Training loss: 0.6873614174168126
Epoch: 20 | Iteration number: [1480/4518] 32% | Training loss: 0.687360506645731
Epoch: 20 | Iteration number: [1490/4518] 32% | Training loss: 0.6873628315509566
Epoch: 20 | Iteration number: [1500/4518] 33% | Training loss: 0.6873585337003072
Epoch: 20 | Iteration number: [1510/4518] 33% | Training loss: 0.687351416554672
Epoch: 20 | Iteration number: [1520/4518] 33% | Training loss: 0.6873529385187124
Epoch: 20 | Iteration number: [1530/4518] 33% | Training loss: 0.6873454685694252
Epoch: 20 | Iteration number: [1540/4518] 34% | Training loss: 0.68734145121915
Epoch: 20 | Iteration number: [1550/4518] 34% | Training loss: 0.6873389701689443
Epoch: 20 | Iteration number: [1560/4518] 34% | Training loss: 0.6873386405217342
Epoch: 20 | Iteration number: [1570/4518] 34% | Training loss: 0.687340898802326
Epoch: 20 | Iteration number: [1580/4518] 34% | Training loss: 0.6873432794326468
Epoch: 20 | Iteration number: [1590/4518] 35% | Training loss: 0.687344650352526
Epoch: 20 | Iteration number: [1600/4518] 35% | Training loss: 0.6873486821725965
Epoch: 20 | Iteration number: [1610/4518] 35% | Training loss: 0.6873388960124543
Epoch: 20 | Iteration number: [1620/4518] 35% | Training loss: 0.6873330468012963
Epoch: 20 | Iteration number: [1630/4518] 36% | Training loss: 0.6873209202947792
Epoch: 20 | Iteration number: [1640/4518] 36% | Training loss: 0.6873170358742156
Epoch: 20 | Iteration number: [1650/4518] 36% | Training loss: 0.6873233301711805
Epoch: 20 | Iteration number: [1660/4518] 36% | Training loss: 0.6873254790722606
Epoch: 20 | Iteration number: [1670/4518] 36% | Training loss: 0.687319136058499
Epoch: 20 | Iteration number: [1680/4518] 37% | Training loss: 0.6873124982984293
Epoch: 20 | Iteration number: [1690/4518] 37% | Training loss: 0.6873064259452932
Epoch: 20 | Iteration number: [1700/4518] 37% | Training loss: 0.6872960899857914
Epoch: 20 | Iteration number: [1710/4518] 37% | Training loss: 0.6872945804693545
Epoch: 20 | Iteration number: [1720/4518] 38% | Training loss: 0.6872881835283235
Epoch: 20 | Iteration number: [1730/4518] 38% | Training loss: 0.6872849590516504
Epoch: 20 | Iteration number: [1740/4518] 38% | Training loss: 0.6872854582194624
Epoch: 20 | Iteration number: [1750/4518] 38% | Training loss: 0.6872813004425594
Epoch: 20 | Iteration number: [1760/4518] 38% | Training loss: 0.6872905006462877
Epoch: 20 | Iteration number: [1770/4518] 39% | Training loss: 0.6872858780925557
Epoch: 20 | Iteration number: [1780/4518] 39% | Training loss: 0.6872764914558175
Epoch: 20 | Iteration number: [1790/4518] 39% | Training loss: 0.6872714012361771
Epoch: 20 | Iteration number: [1800/4518] 39% | Training loss: 0.6872661521699693
Epoch: 20 | Iteration number: [1810/4518] 40% | Training loss: 0.6872577161420116
Epoch: 20 | Iteration number: [1820/4518] 40% | Training loss: 0.6872545926452993
Epoch: 20 | Iteration number: [1830/4518] 40% | Training loss: 0.6872553202623878
Epoch: 20 | Iteration number: [1840/4518] 40% | Training loss: 0.6872593768912812
Epoch: 20 | Iteration number: [1850/4518] 40% | Training loss: 0.6872587970140818
Epoch: 20 | Iteration number: [1860/4518] 41% | Training loss: 0.6872534752212545
Epoch: 20 | Iteration number: [1870/4518] 41% | Training loss: 0.6872525897574298
Epoch: 20 | Iteration number: [1880/4518] 41% | Training loss: 0.6872589823730448
Epoch: 20 | Iteration number: [1890/4518] 41% | Training loss: 0.6872546759232011
Epoch: 20 | Iteration number: [1900/4518] 42% | Training loss: 0.6872579944761176
Epoch: 20 | Iteration number: [1910/4518] 42% | Training loss: 0.6872550378607206
Epoch: 20 | Iteration number: [1920/4518] 42% | Training loss: 0.687246312511464
Epoch: 20 | Iteration number: [1930/4518] 42% | Training loss: 0.6872483337790237
Epoch: 20 | Iteration number: [1940/4518] 42% | Training loss: 0.6872474606811386
Epoch: 20 | Iteration number: [1950/4518] 43% | Training loss: 0.6872464971970289
Epoch: 20 | Iteration number: [1960/4518] 43% | Training loss: 0.687251817997621
Epoch: 20 | Iteration number: [1970/4518] 43% | Training loss: 0.6872515372213374
Epoch: 20 | Iteration number: [1980/4518] 43% | Training loss: 0.6872507759416946
Epoch: 20 | Iteration number: [1990/4518] 44% | Training loss: 0.6872478327858987
Epoch: 20 | Iteration number: [2000/4518] 44% | Training loss: 0.6872513628900051
Epoch: 20 | Iteration number: [2010/4518] 44% | Training loss: 0.6872552405542403
Epoch: 20 | Iteration number: [2020/4518] 44% | Training loss: 0.6872630273646647
Epoch: 20 | Iteration number: [2030/4518] 44% | Training loss: 0.6872556409812326
Epoch: 20 | Iteration number: [2040/4518] 45% | Training loss: 0.6872497800810664
Epoch: 20 | Iteration number: [2050/4518] 45% | Training loss: 0.6872478251340912
Epoch: 20 | Iteration number: [2060/4518] 45% | Training loss: 0.6872452906902554
Epoch: 20 | Iteration number: [2070/4518] 45% | Training loss: 0.6872455246494588
Epoch: 20 | Iteration number: [2080/4518] 46% | Training loss: 0.6872435208696586
Epoch: 20 | Iteration number: [2090/4518] 46% | Training loss: 0.6872429073142092
Epoch: 20 | Iteration number: [2100/4518] 46% | Training loss: 0.6872422492787952
Epoch: 20 | Iteration number: [2110/4518] 46% | Training loss: 0.6872431173991252
Epoch: 20 | Iteration number: [2120/4518] 46% | Training loss: 0.687240044632048
Epoch: 20 | Iteration number: [2130/4518] 47% | Training loss: 0.6872404082280369
Epoch: 20 | Iteration number: [2140/4518] 47% | Training loss: 0.6872381370479815
Epoch: 20 | Iteration number: [2150/4518] 47% | Training loss: 0.687233636406965
Epoch: 20 | Iteration number: [2160/4518] 47% | Training loss: 0.6872297163362856
Epoch: 20 | Iteration number: [2170/4518] 48% | Training loss: 0.687223718600339
Epoch: 20 | Iteration number: [2180/4518] 48% | Training loss: 0.6872252616860451
Epoch: 20 | Iteration number: [2190/4518] 48% | Training loss: 0.6872268168349245
Epoch: 20 | Iteration number: [2200/4518] 48% | Training loss: 0.6872309683398767
Epoch: 20 | Iteration number: [2210/4518] 48% | Training loss: 0.687230208961133
Epoch: 20 | Iteration number: [2220/4518] 49% | Training loss: 0.6872316247439599
Epoch: 20 | Iteration number: [2230/4518] 49% | Training loss: 0.6872327458698119
Epoch: 20 | Iteration number: [2240/4518] 49% | Training loss: 0.687236461921462
Epoch: 20 | Iteration number: [2250/4518] 49% | Training loss: 0.6872369590600331
Epoch: 20 | Iteration number: [2260/4518] 50% | Training loss: 0.6872366756200791
Epoch: 20 | Iteration number: [2270/4518] 50% | Training loss: 0.6872376975246463
Epoch: 20 | Iteration number: [2280/4518] 50% | Training loss: 0.6872392958193495
Epoch: 20 | Iteration number: [2290/4518] 50% | Training loss: 0.687238377514885
Epoch: 20 | Iteration number: [2300/4518] 50% | Training loss: 0.6872345221560935
Epoch: 20 | Iteration number: [2310/4518] 51% | Training loss: 0.6872318873931835
Epoch: 20 | Iteration number: [2320/4518] 51% | Training loss: 0.6872352451086045
Epoch: 20 | Iteration number: [2330/4518] 51% | Training loss: 0.6872337639331818
Epoch: 20 | Iteration number: [2340/4518] 51% | Training loss: 0.6872317459848192
Epoch: 20 | Iteration number: [2350/4518] 52% | Training loss: 0.6872252482049008
Epoch: 20 | Iteration number: [2360/4518] 52% | Training loss: 0.6872245472366527
Epoch: 20 | Iteration number: [2370/4518] 52% | Training loss: 0.6872228865633534
Epoch: 20 | Iteration number: [2380/4518] 52% | Training loss: 0.6872236993883838
Epoch: 20 | Iteration number: [2390/4518] 52% | Training loss: 0.6872251400139542
Epoch: 20 | Iteration number: [2400/4518] 53% | Training loss: 0.6872209046781063
Epoch: 20 | Iteration number: [2410/4518] 53% | Training loss: 0.6872181332210288
Epoch: 20 | Iteration number: [2420/4518] 53% | Training loss: 0.6872135506188574
Epoch: 20 | Iteration number: [2430/4518] 53% | Training loss: 0.6872143127054835
Epoch: 20 | Iteration number: [2440/4518] 54% | Training loss: 0.6872093426155262
Epoch: 20 | Iteration number: [2450/4518] 54% | Training loss: 0.6872011361073475
Epoch: 20 | Iteration number: [2460/4518] 54% | Training loss: 0.6871966223891188
Epoch: 20 | Iteration number: [2470/4518] 54% | Training loss: 0.687193287263515
Epoch: 20 | Iteration number: [2480/4518] 54% | Training loss: 0.6871940336640804
Epoch: 20 | Iteration number: [2490/4518] 55% | Training loss: 0.687188170999887
Epoch: 20 | Iteration number: [2500/4518] 55% | Training loss: 0.6871896896600723
Epoch: 20 | Iteration number: [2510/4518] 55% | Training loss: 0.6871892365801382
Epoch: 20 | Iteration number: [2520/4518] 55% | Training loss: 0.6871923270679655
Epoch: 20 | Iteration number: [2530/4518] 55% | Training loss: 0.6871897517928022
Epoch: 20 | Iteration number: [2540/4518] 56% | Training loss: 0.6871863451529675
Epoch: 20 | Iteration number: [2550/4518] 56% | Training loss: 0.6871874411900838
Epoch: 20 | Iteration number: [2560/4518] 56% | Training loss: 0.6871841344516725
Epoch: 20 | Iteration number: [2570/4518] 56% | Training loss: 0.6871793382594558
Epoch: 20 | Iteration number: [2580/4518] 57% | Training loss: 0.6871771308109742
Epoch: 20 | Iteration number: [2590/4518] 57% | Training loss: 0.6871725037521377
Epoch: 20 | Iteration number: [2600/4518] 57% | Training loss: 0.6871738831355022
Epoch: 20 | Iteration number: [2610/4518] 57% | Training loss: 0.6871716020664492
Epoch: 20 | Iteration number: [2620/4518] 57% | Training loss: 0.6871725730313599
Epoch: 20 | Iteration number: [2630/4518] 58% | Training loss: 0.6871698430509169
Epoch: 20 | Iteration number: [2640/4518] 58% | Training loss: 0.6871707536957481
Epoch: 20 | Iteration number: [2650/4518] 58% | Training loss: 0.6871659867043766
Epoch: 20 | Iteration number: [2660/4518] 58% | Training loss: 0.6871617585868763
Epoch: 20 | Iteration number: [2670/4518] 59% | Training loss: 0.6871601470847255
Epoch: 20 | Iteration number: [2680/4518] 59% | Training loss: 0.6871588828403559
Epoch: 20 | Iteration number: [2690/4518] 59% | Training loss: 0.6871546004119858
Epoch: 20 | Iteration number: [2700/4518] 59% | Training loss: 0.687154857163076
Epoch: 20 | Iteration number: [2710/4518] 59% | Training loss: 0.6871512726004273
Epoch: 20 | Iteration number: [2720/4518] 60% | Training loss: 0.6871497754445848
Epoch: 20 | Iteration number: [2730/4518] 60% | Training loss: 0.6871548679067102
Epoch: 20 | Iteration number: [2740/4518] 60% | Training loss: 0.6871522571266132
Epoch: 20 | Iteration number: [2750/4518] 60% | Training loss: 0.6871485724232413
Epoch: 20 | Iteration number: [2760/4518] 61% | Training loss: 0.6871499116653982
Epoch: 20 | Iteration number: [2770/4518] 61% | Training loss: 0.6871492907458694
Epoch: 20 | Iteration number: [2780/4518] 61% | Training loss: 0.6871485404616637
Epoch: 20 | Iteration number: [2790/4518] 61% | Training loss: 0.6871416643315319
Epoch: 20 | Iteration number: [2800/4518] 61% | Training loss: 0.687138538658619
Epoch: 20 | Iteration number: [2810/4518] 62% | Training loss: 0.687139156131982
Epoch: 20 | Iteration number: [2820/4518] 62% | Training loss: 0.6871372321818737
Epoch: 20 | Iteration number: [2830/4518] 62% | Training loss: 0.6871355314347433
Epoch: 20 | Iteration number: [2840/4518] 62% | Training loss: 0.6871378121451592
Epoch: 20 | Iteration number: [2850/4518] 63% | Training loss: 0.6871351567276737
Epoch: 20 | Iteration number: [2860/4518] 63% | Training loss: 0.6871353892388044
Epoch: 20 | Iteration number: [2870/4518] 63% | Training loss: 0.687133201344088
Epoch: 20 | Iteration number: [2880/4518] 63% | Training loss: 0.687132108791007
Epoch: 20 | Iteration number: [2890/4518] 63% | Training loss: 0.6871329881534445
Epoch: 20 | Iteration number: [2900/4518] 64% | Training loss: 0.6871351255630624
Epoch: 20 | Iteration number: [2910/4518] 64% | Training loss: 0.6871331401911798
Epoch: 20 | Iteration number: [2920/4518] 64% | Training loss: 0.6871329500658871
Epoch: 20 | Iteration number: [2930/4518] 64% | Training loss: 0.6871352171531716
Epoch: 20 | Iteration number: [2940/4518] 65% | Training loss: 0.6871344682918925
Epoch: 20 | Iteration number: [2950/4518] 65% | Training loss: 0.687132520776684
Epoch: 20 | Iteration number: [2960/4518] 65% | Training loss: 0.6871340358176747
Epoch: 20 | Iteration number: [2970/4518] 65% | Training loss: 0.6871316271197515
Epoch: 20 | Iteration number: [2980/4518] 65% | Training loss: 0.6871294064809812
Epoch: 20 | Iteration number: [2990/4518] 66% | Training loss: 0.6871312672079207
Epoch: 20 | Iteration number: [3000/4518] 66% | Training loss: 0.6871332588593165
Epoch: 20 | Iteration number: [3010/4518] 66% | Training loss: 0.6871323385904001
Epoch: 20 | Iteration number: [3020/4518] 66% | Training loss: 0.6871292118599873
Epoch: 20 | Iteration number: [3030/4518] 67% | Training loss: 0.687129923711122
Epoch: 20 | Iteration number: [3040/4518] 67% | Training loss: 0.6871282770249404
Epoch: 20 | Iteration number: [3050/4518] 67% | Training loss: 0.6871310939749733
Epoch: 20 | Iteration number: [3060/4518] 67% | Training loss: 0.6871329760239795
Epoch: 20 | Iteration number: [3070/4518] 67% | Training loss: 0.6871306522855541
Epoch: 20 | Iteration number: [3080/4518] 68% | Training loss: 0.6871309341354803
Epoch: 20 | Iteration number: [3090/4518] 68% | Training loss: 0.6871307066536259
Epoch: 20 | Iteration number: [3100/4518] 68% | Training loss: 0.6871294453259438
Epoch: 20 | Iteration number: [3110/4518] 68% | Training loss: 0.6871289109493759
Epoch: 20 | Iteration number: [3120/4518] 69% | Training loss: 0.6871300256023041
Epoch: 20 | Iteration number: [3130/4518] 69% | Training loss: 0.6871302755305562
Epoch: 20 | Iteration number: [3140/4518] 69% | Training loss: 0.687122234891934
Epoch: 20 | Iteration number: [3150/4518] 69% | Training loss: 0.687123699112544
Epoch: 20 | Iteration number: [3160/4518] 69% | Training loss: 0.687122795872296
Epoch: 20 | Iteration number: [3170/4518] 70% | Training loss: 0.6871225780117023
Epoch: 20 | Iteration number: [3180/4518] 70% | Training loss: 0.6871247979829896
Epoch: 20 | Iteration number: [3190/4518] 70% | Training loss: 0.6871250370639992
Epoch: 20 | Iteration number: [3200/4518] 70% | Training loss: 0.6871269299462438
Epoch: 20 | Iteration number: [3210/4518] 71% | Training loss: 0.6871220741316537
Epoch: 20 | Iteration number: [3220/4518] 71% | Training loss: 0.6871209233629038
Epoch: 20 | Iteration number: [3230/4518] 71% | Training loss: 0.6871180909705974
Epoch: 20 | Iteration number: [3240/4518] 71% | Training loss: 0.6871180729365644
Epoch: 20 | Iteration number: [3250/4518] 71% | Training loss: 0.6871169828268198
Epoch: 20 | Iteration number: [3260/4518] 72% | Training loss: 0.6871217089562328
Epoch: 20 | Iteration number: [3270/4518] 72% | Training loss: 0.6871204740775105
Epoch: 20 | Iteration number: [3280/4518] 72% | Training loss: 0.6871204090736261
Epoch: 20 | Iteration number: [3290/4518] 72% | Training loss: 0.6871215725923382
Epoch: 20 | Iteration number: [3300/4518] 73% | Training loss: 0.6871230218446616
Epoch: 20 | Iteration number: [3310/4518] 73% | Training loss: 0.6871248771776965
Epoch: 20 | Iteration number: [3320/4518] 73% | Training loss: 0.6871251660477684
Epoch: 20 | Iteration number: [3330/4518] 73% | Training loss: 0.6871236567919676
Epoch: 20 | Iteration number: [3340/4518] 73% | Training loss: 0.6871238718846601
Epoch: 20 | Iteration number: [3350/4518] 74% | Training loss: 0.6871230158521169
Epoch: 20 | Iteration number: [3360/4518] 74% | Training loss: 0.6871222334958258
Epoch: 20 | Iteration number: [3370/4518] 74% | Training loss: 0.6871254697928443
Epoch: 20 | Iteration number: [3380/4518] 74% | Training loss: 0.6871235415074952
Epoch: 20 | Iteration number: [3390/4518] 75% | Training loss: 0.6871240575404997
Epoch: 20 | Iteration number: [3400/4518] 75% | Training loss: 0.6871201772900188
Epoch: 20 | Iteration number: [3410/4518] 75% | Training loss: 0.68712111271022
Epoch: 20 | Iteration number: [3420/4518] 75% | Training loss: 0.6871233477055678
Epoch: 20 | Iteration number: [3430/4518] 75% | Training loss: 0.6871246692043004
Epoch: 20 | Iteration number: [3440/4518] 76% | Training loss: 0.6871204983356387
Epoch: 20 | Iteration number: [3450/4518] 76% | Training loss: 0.6871198883609495
Epoch: 20 | Iteration number: [3460/4518] 76% | Training loss: 0.687122745717192
Epoch: 20 | Iteration number: [3470/4518] 76% | Training loss: 0.6871201576520112
Epoch: 20 | Iteration number: [3480/4518] 77% | Training loss: 0.687117453536083
Epoch: 20 | Iteration number: [3490/4518] 77% | Training loss: 0.687120251583848
Epoch: 20 | Iteration number: [3500/4518] 77% | Training loss: 0.6871163843359266
Epoch: 20 | Iteration number: [3510/4518] 77% | Training loss: 0.6871161972016011
Epoch: 20 | Iteration number: [3520/4518] 77% | Training loss: 0.6871161097660661
Epoch: 20 | Iteration number: [3530/4518] 78% | Training loss: 0.6871148374870883
Epoch: 20 | Iteration number: [3540/4518] 78% | Training loss: 0.6871126393140372
Epoch: 20 | Iteration number: [3550/4518] 78% | Training loss: 0.6871124239874558
Epoch: 20 | Iteration number: [3560/4518] 78% | Training loss: 0.68711192092199
Epoch: 20 | Iteration number: [3570/4518] 79% | Training loss: 0.6871117884538421
Epoch: 20 | Iteration number: [3580/4518] 79% | Training loss: 0.6871092606023703
Epoch: 20 | Iteration number: [3590/4518] 79% | Training loss: 0.6871081243484465
Epoch: 20 | Iteration number: [3600/4518] 79% | Training loss: 0.6871029444535574
Epoch: 20 | Iteration number: [3610/4518] 79% | Training loss: 0.6871016425769415
Epoch: 20 | Iteration number: [3620/4518] 80% | Training loss: 0.6871031675055541
Epoch: 20 | Iteration number: [3630/4518] 80% | Training loss: 0.6871031967897389
Epoch: 20 | Iteration number: [3640/4518] 80% | Training loss: 0.6871034442559704
Epoch: 20 | Iteration number: [3650/4518] 80% | Training loss: 0.6871024172600001
Epoch: 20 | Iteration number: [3660/4518] 81% | Training loss: 0.6871016099153321
Epoch: 20 | Iteration number: [3670/4518] 81% | Training loss: 0.6871009993130894
Epoch: 20 | Iteration number: [3680/4518] 81% | Training loss: 0.687102916755754
Epoch: 20 | Iteration number: [3690/4518] 81% | Training loss: 0.6871015504446779
Epoch: 20 | Iteration number: [3700/4518] 81% | Training loss: 0.687101911870209
Epoch: 20 | Iteration number: [3710/4518] 82% | Training loss: 0.6871035799343952
Epoch: 20 | Iteration number: [3720/4518] 82% | Training loss: 0.6871008281906446
Epoch: 20 | Iteration number: [3730/4518] 82% | Training loss: 0.6870983333274443
Epoch: 20 | Iteration number: [3740/4518] 82% | Training loss: 0.6870993330676288
Epoch: 20 | Iteration number: [3750/4518] 83% | Training loss: 0.6870961971759796
Epoch: 20 | Iteration number: [3760/4518] 83% | Training loss: 0.6870971959005011
Epoch: 20 | Iteration number: [3770/4518] 83% | Training loss: 0.6870957411884945
Epoch: 20 | Iteration number: [3780/4518] 83% | Training loss: 0.6870989520083028
Epoch: 20 | Iteration number: [3790/4518] 83% | Training loss: 0.6870964528073736
Epoch: 20 | Iteration number: [3800/4518] 84% | Training loss: 0.6870952594437097
Epoch: 20 | Iteration number: [3810/4518] 84% | Training loss: 0.6870965241290766
Epoch: 20 | Iteration number: [3820/4518] 84% | Training loss: 0.687095465975282
Epoch: 20 | Iteration number: [3830/4518] 84% | Training loss: 0.687092207150422
Epoch: 20 | Iteration number: [3840/4518] 84% | Training loss: 0.6870888757053762
Epoch: 20 | Iteration number: [3850/4518] 85% | Training loss: 0.687088689076436
Epoch: 20 | Iteration number: [3860/4518] 85% | Training loss: 0.6870887384976748
Epoch: 20 | Iteration number: [3870/4518] 85% | Training loss: 0.6870853610895092
Epoch: 20 | Iteration number: [3880/4518] 85% | Training loss: 0.6870832776439558
Epoch: 20 | Iteration number: [3890/4518] 86% | Training loss: 0.6870824175965816
Epoch: 20 | Iteration number: [3900/4518] 86% | Training loss: 0.6870820230398422
Epoch: 20 | Iteration number: [3910/4518] 86% | Training loss: 0.6870823073112752
Epoch: 20 | Iteration number: [3920/4518] 86% | Training loss: 0.6870787719834824
Epoch: 20 | Iteration number: [3930/4518] 86% | Training loss: 0.6870802052148426
Epoch: 20 | Iteration number: [3940/4518] 87% | Training loss: 0.6870811320047088
Epoch: 20 | Iteration number: [3950/4518] 87% | Training loss: 0.6870812280268609
Epoch: 20 | Iteration number: [3960/4518] 87% | Training loss: 0.6870808697258584
Epoch: 20 | Iteration number: [3970/4518] 87% | Training loss: 0.6870807773370287
Epoch: 20 | Iteration number: [3980/4518] 88% | Training loss: 0.6870808086503091
Epoch: 20 | Iteration number: [3990/4518] 88% | Training loss: 0.6870822658216147
Epoch: 20 | Iteration number: [4000/4518] 88% | Training loss: 0.6870789970457554
Epoch: 20 | Iteration number: [4010/4518] 88% | Training loss: 0.6870734337856644
Epoch: 20 | Iteration number: [4020/4518] 88% | Training loss: 0.6870714906584564
Epoch: 20 | Iteration number: [4030/4518] 89% | Training loss: 0.6870714970025472
Epoch: 20 | Iteration number: [4040/4518] 89% | Training loss: 0.6870710897416171
Epoch: 20 | Iteration number: [4050/4518] 89% | Training loss: 0.6870697957203712
Epoch: 20 | Iteration number: [4060/4518] 89% | Training loss: 0.6870658511158281
Epoch: 20 | Iteration number: [4070/4518] 90% | Training loss: 0.6870661125429139
Epoch: 20 | Iteration number: [4080/4518] 90% | Training loss: 0.6870702599339625
Epoch: 20 | Iteration number: [4090/4518] 90% | Training loss: 0.6870711109457506
Epoch: 20 | Iteration number: [4100/4518] 90% | Training loss: 0.6870707726623954
Epoch: 20 | Iteration number: [4110/4518] 90% | Training loss: 0.6870723248833287
Epoch: 20 | Iteration number: [4120/4518] 91% | Training loss: 0.6870717064124866
Epoch: 20 | Iteration number: [4130/4518] 91% | Training loss: 0.6870731526800853
Epoch: 20 | Iteration number: [4140/4518] 91% | Training loss: 0.6870703633136795
Epoch: 20 | Iteration number: [4150/4518] 91% | Training loss: 0.6870698906571032
Epoch: 20 | Iteration number: [4160/4518] 92% | Training loss: 0.687072472833097
Epoch: 20 | Iteration number: [4170/4518] 92% | Training loss: 0.6870690820171392
Epoch: 20 | Iteration number: [4180/4518] 92% | Training loss: 0.6870688639616852
Epoch: 20 | Iteration number: [4190/4518] 92% | Training loss: 0.687068138700112
Epoch: 20 | Iteration number: [4200/4518] 92% | Training loss: 0.6870674468222119
Epoch: 20 | Iteration number: [4210/4518] 93% | Training loss: 0.6870641817531223
Epoch: 20 | Iteration number: [4220/4518] 93% | Training loss: 0.6870668515209903
Epoch: 20 | Iteration number: [4230/4518] 93% | Training loss: 0.6870651191289825
Epoch: 20 | Iteration number: [4240/4518] 93% | Training loss: 0.6870664017802139
Epoch: 20 | Iteration number: [4250/4518] 94% | Training loss: 0.6870678441103767
Epoch: 20 | Iteration number: [4260/4518] 94% | Training loss: 0.6870693676488501
Epoch: 20 | Iteration number: [4270/4518] 94% | Training loss: 0.6870689583885586
Epoch: 20 | Iteration number: [4280/4518] 94% | Training loss: 0.6870683616288354
Epoch: 20 | Iteration number: [4290/4518] 94% | Training loss: 0.6870670226765123
Epoch: 20 | Iteration number: [4300/4518] 95% | Training loss: 0.6870661781416383
Epoch: 20 | Iteration number: [4310/4518] 95% | Training loss: 0.6870657610782614
Epoch: 20 | Iteration number: [4320/4518] 95% | Training loss: 0.6870660750264371
Epoch: 20 | Iteration number: [4330/4518] 95% | Training loss: 0.6870648669453195
Epoch: 20 | Iteration number: [4340/4518] 96% | Training loss: 0.6870615114264774
Epoch: 20 | Iteration number: [4350/4518] 96% | Training loss: 0.6870577787393811
Epoch: 20 | Iteration number: [4360/4518] 96% | Training loss: 0.6870535724480218
Epoch: 20 | Iteration number: [4370/4518] 96% | Training loss: 0.6870515422635548
Epoch: 20 | Iteration number: [4380/4518] 96% | Training loss: 0.6870516211338783
Epoch: 20 | Iteration number: [4390/4518] 97% | Training loss: 0.6870549379149983
Epoch: 20 | Iteration number: [4400/4518] 97% | Training loss: 0.6870547155629505
Epoch: 20 | Iteration number: [4410/4518] 97% | Training loss: 0.6870540406022753
Epoch: 20 | Iteration number: [4420/4518] 97% | Training loss: 0.6870570225143864
Epoch: 20 | Iteration number: [4430/4518] 98% | Training loss: 0.6870572084901564
Epoch: 20 | Iteration number: [4440/4518] 98% | Training loss: 0.6870590508923874
Epoch: 20 | Iteration number: [4450/4518] 98% | Training loss: 0.6870583417308465
Epoch: 20 | Iteration number: [4460/4518] 98% | Training loss: 0.6870599203847448
Epoch: 20 | Iteration number: [4470/4518] 98% | Training loss: 0.6870576671039231
Epoch: 20 | Iteration number: [4480/4518] 99% | Training loss: 0.6870569691993296
Epoch: 20 | Iteration number: [4490/4518] 99% | Training loss: 0.6870534856229158
Epoch: 20 | Iteration number: [4500/4518] 99% | Training loss: 0.6870536286830902
Epoch: 20 | Iteration number: [4510/4518] 99% | Training loss: 0.6870542682988152

 End of epoch: 20 | Train Loss: 0.6869020248578153 | Training Time: 640 

 End of epoch: 20 | Eval Loss: 0.6901216604271714 | Evaluating Time: 17 
Epoch: 21 | Iteration number: [10/4518] 0% | Training loss: 0.7541760444641114
Epoch: 21 | Iteration number: [20/4518] 0% | Training loss: 0.7205036103725433
Epoch: 21 | Iteration number: [30/4518] 0% | Training loss: 0.7096711317698161
Epoch: 21 | Iteration number: [40/4518] 0% | Training loss: 0.7041663497686386
Epoch: 21 | Iteration number: [50/4518] 1% | Training loss: 0.7007799959182739
Epoch: 21 | Iteration number: [60/4518] 1% | Training loss: 0.6985364655653635
Epoch: 21 | Iteration number: [70/4518] 1% | Training loss: 0.6968874045780726
Epoch: 21 | Iteration number: [80/4518] 1% | Training loss: 0.6956941828131675
Epoch: 21 | Iteration number: [90/4518] 1% | Training loss: 0.6946935918596056
Epoch: 21 | Iteration number: [100/4518] 2% | Training loss: 0.6938586670160294
Epoch: 21 | Iteration number: [110/4518] 2% | Training loss: 0.6933458929712122
Epoch: 21 | Iteration number: [120/4518] 2% | Training loss: 0.6927794203162193
Epoch: 21 | Iteration number: [130/4518] 2% | Training loss: 0.6923203601286961
Epoch: 21 | Iteration number: [140/4518] 3% | Training loss: 0.6919179558753967
Epoch: 21 | Iteration number: [150/4518] 3% | Training loss: 0.6915052076180775
Epoch: 21 | Iteration number: [160/4518] 3% | Training loss: 0.6911919925361871
Epoch: 21 | Iteration number: [170/4518] 3% | Training loss: 0.690887466949575
Epoch: 21 | Iteration number: [180/4518] 3% | Training loss: 0.690675022204717
Epoch: 21 | Iteration number: [190/4518] 4% | Training loss: 0.6904711641763386
Epoch: 21 | Iteration number: [200/4518] 4% | Training loss: 0.6902749240398407
Epoch: 21 | Iteration number: [210/4518] 4% | Training loss: 0.6901316236881982
Epoch: 21 | Iteration number: [220/4518] 4% | Training loss: 0.6899801395156167
Epoch: 21 | Iteration number: [230/4518] 5% | Training loss: 0.6898095408211584
Epoch: 21 | Iteration number: [240/4518] 5% | Training loss: 0.6896683625876904
Epoch: 21 | Iteration number: [250/4518] 5% | Training loss: 0.6895780272483826
Epoch: 21 | Iteration number: [260/4518] 5% | Training loss: 0.689460888504982
Epoch: 21 | Iteration number: [270/4518] 5% | Training loss: 0.6893874119829249
Epoch: 21 | Iteration number: [280/4518] 6% | Training loss: 0.6892945523772921
Epoch: 21 | Iteration number: [290/4518] 6% | Training loss: 0.6892179380203115
Epoch: 21 | Iteration number: [300/4518] 6% | Training loss: 0.6891255219777425
Epoch: 21 | Iteration number: [310/4518] 6% | Training loss: 0.689043455162356
Epoch: 21 | Iteration number: [320/4518] 7% | Training loss: 0.6889334125444293
Epoch: 21 | Iteration number: [330/4518] 7% | Training loss: 0.6888389334534154
Epoch: 21 | Iteration number: [340/4518] 7% | Training loss: 0.6887476793106865
Epoch: 21 | Iteration number: [350/4518] 7% | Training loss: 0.6886708821569171
Epoch: 21 | Iteration number: [360/4518] 7% | Training loss: 0.6886380712191263
Epoch: 21 | Iteration number: [370/4518] 8% | Training loss: 0.6886002677517968
Epoch: 21 | Iteration number: [380/4518] 8% | Training loss: 0.6885523319244384
Epoch: 21 | Iteration number: [390/4518] 8% | Training loss: 0.6885226815174788
Epoch: 21 | Iteration number: [400/4518] 8% | Training loss: 0.6884872540831566
Epoch: 21 | Iteration number: [410/4518] 9% | Training loss: 0.6884703259642532
Epoch: 21 | Iteration number: [420/4518] 9% | Training loss: 0.6884418880655652
Epoch: 21 | Iteration number: [430/4518] 9% | Training loss: 0.6883965155412984
Epoch: 21 | Iteration number: [440/4518] 9% | Training loss: 0.6883579683574763
Epoch: 21 | Iteration number: [450/4518] 9% | Training loss: 0.6883155744605595
Epoch: 21 | Iteration number: [460/4518] 10% | Training loss: 0.6883139476827953
Epoch: 21 | Iteration number: [470/4518] 10% | Training loss: 0.6883129535837377
Epoch: 21 | Iteration number: [480/4518] 10% | Training loss: 0.6882561882336934
Epoch: 21 | Iteration number: [490/4518] 10% | Training loss: 0.6882171439881227
Epoch: 21 | Iteration number: [500/4518] 11% | Training loss: 0.6881737602949143
Epoch: 21 | Iteration number: [510/4518] 11% | Training loss: 0.6881350535972446
Epoch: 21 | Iteration number: [520/4518] 11% | Training loss: 0.6881047983582204
Epoch: 21 | Iteration number: [530/4518] 11% | Training loss: 0.688082584007731
Epoch: 21 | Iteration number: [540/4518] 11% | Training loss: 0.688047077258428
Epoch: 21 | Iteration number: [550/4518] 12% | Training loss: 0.6880283067443154
Epoch: 21 | Iteration number: [560/4518] 12% | Training loss: 0.6879960971219199
Epoch: 21 | Iteration number: [570/4518] 12% | Training loss: 0.6879575990793998
Epoch: 21 | Iteration number: [580/4518] 12% | Training loss: 0.6879257409737027
Epoch: 21 | Iteration number: [590/4518] 13% | Training loss: 0.6879076636443704
Epoch: 21 | Iteration number: [600/4518] 13% | Training loss: 0.6878829159339269
Epoch: 21 | Iteration number: [610/4518] 13% | Training loss: 0.6878429757767036
Epoch: 21 | Iteration number: [620/4518] 13% | Training loss: 0.6878435037789806
Epoch: 21 | Iteration number: [630/4518] 13% | Training loss: 0.6878172456272065
Epoch: 21 | Iteration number: [640/4518] 14% | Training loss: 0.6878082558512688
Epoch: 21 | Iteration number: [650/4518] 14% | Training loss: 0.6878020361753611
Epoch: 21 | Iteration number: [660/4518] 14% | Training loss: 0.6877846937287938
Epoch: 21 | Iteration number: [670/4518] 14% | Training loss: 0.6877760102499777
Epoch: 21 | Iteration number: [680/4518] 15% | Training loss: 0.687771798582638
Epoch: 21 | Iteration number: [690/4518] 15% | Training loss: 0.6877678279427515
Epoch: 21 | Iteration number: [700/4518] 15% | Training loss: 0.6877570746626173
Epoch: 21 | Iteration number: [710/4518] 15% | Training loss: 0.6877474766382029
Epoch: 21 | Iteration number: [720/4518] 15% | Training loss: 0.6877415181034141
Epoch: 21 | Iteration number: [730/4518] 16% | Training loss: 0.6877274990898289
Epoch: 21 | Iteration number: [740/4518] 16% | Training loss: 0.6877229474686287
Epoch: 21 | Iteration number: [750/4518] 16% | Training loss: 0.6877148357232412
Epoch: 21 | Iteration number: [760/4518] 16% | Training loss: 0.6877058411115095
Epoch: 21 | Iteration number: [770/4518] 17% | Training loss: 0.6876986526049577
Epoch: 21 | Iteration number: [780/4518] 17% | Training loss: 0.6876930649463947
Epoch: 21 | Iteration number: [790/4518] 17% | Training loss: 0.6876911290838749
Epoch: 21 | Iteration number: [800/4518] 17% | Training loss: 0.687676013559103
Epoch: 21 | Iteration number: [810/4518] 17% | Training loss: 0.6876725647184584
Epoch: 21 | Iteration number: [820/4518] 18% | Training loss: 0.6876650068091184
Epoch: 21 | Iteration number: [830/4518] 18% | Training loss: 0.6876816900379686
Epoch: 21 | Iteration number: [840/4518] 18% | Training loss: 0.6876670273286956
Epoch: 21 | Iteration number: [850/4518] 18% | Training loss: 0.68765461360707
Epoch: 21 | Iteration number: [860/4518] 19% | Training loss: 0.6876563844292662
Epoch: 21 | Iteration number: [870/4518] 19% | Training loss: 0.6876450617423002
Epoch: 21 | Iteration number: [880/4518] 19% | Training loss: 0.6876450949094512
Epoch: 21 | Iteration number: [890/4518] 19% | Training loss: 0.6876386909672384
Epoch: 21 | Iteration number: [900/4518] 19% | Training loss: 0.6876182120376163
Epoch: 21 | Iteration number: [910/4518] 20% | Training loss: 0.6876046609092544
Epoch: 21 | Iteration number: [920/4518] 20% | Training loss: 0.6875950388286425
Epoch: 21 | Iteration number: [930/4518] 20% | Training loss: 0.6875931867989161
Epoch: 21 | Iteration number: [940/4518] 20% | Training loss: 0.6875868489133551
Epoch: 21 | Iteration number: [950/4518] 21% | Training loss: 0.6875722714474327
Epoch: 21 | Iteration number: [960/4518] 21% | Training loss: 0.6875541336834431
Epoch: 21 | Iteration number: [970/4518] 21% | Training loss: 0.687555393545898
Epoch: 21 | Iteration number: [980/4518] 21% | Training loss: 0.687546641790137
Epoch: 21 | Iteration number: [990/4518] 21% | Training loss: 0.687543035155595
Epoch: 21 | Iteration number: [1000/4518] 22% | Training loss: 0.6875375236868858
Epoch: 21 | Iteration number: [1010/4518] 22% | Training loss: 0.6875167068868581
Epoch: 21 | Iteration number: [1020/4518] 22% | Training loss: 0.6875125799693313
Epoch: 21 | Iteration number: [1030/4518] 22% | Training loss: 0.687505693227342
Epoch: 21 | Iteration number: [1040/4518] 23% | Training loss: 0.687477496266365
Epoch: 21 | Iteration number: [1050/4518] 23% | Training loss: 0.6874690775644211
Epoch: 21 | Iteration number: [1060/4518] 23% | Training loss: 0.6874652845117281
Epoch: 21 | Iteration number: [1070/4518] 23% | Training loss: 0.6874523853587213
Epoch: 21 | Iteration number: [1080/4518] 23% | Training loss: 0.6874483408751311
Epoch: 21 | Iteration number: [1090/4518] 24% | Training loss: 0.6874511361122131
Epoch: 21 | Iteration number: [1100/4518] 24% | Training loss: 0.6874475642225959
Epoch: 21 | Iteration number: [1110/4518] 24% | Training loss: 0.6874450363017417
Epoch: 21 | Iteration number: [1120/4518] 24% | Training loss: 0.6874388013035059
Epoch: 21 | Iteration number: [1130/4518] 25% | Training loss: 0.6874201215473952
Epoch: 21 | Iteration number: [1140/4518] 25% | Training loss: 0.6874157711602094
Epoch: 21 | Iteration number: [1150/4518] 25% | Training loss: 0.6874058438384014
Epoch: 21 | Iteration number: [1160/4518] 25% | Training loss: 0.6874001495283225
Epoch: 21 | Iteration number: [1170/4518] 25% | Training loss: 0.6873873276588244
Epoch: 21 | Iteration number: [1180/4518] 26% | Training loss: 0.6873753286014169
Epoch: 21 | Iteration number: [1190/4518] 26% | Training loss: 0.687379662529761
Epoch: 21 | Iteration number: [1200/4518] 26% | Training loss: 0.6873801758388678
Epoch: 21 | Iteration number: [1210/4518] 26% | Training loss: 0.6873685427441084
Epoch: 21 | Iteration number: [1220/4518] 27% | Training loss: 0.6873638596202506
Epoch: 21 | Iteration number: [1230/4518] 27% | Training loss: 0.6873554771024037
Epoch: 21 | Iteration number: [1240/4518] 27% | Training loss: 0.6873603068532482
Epoch: 21 | Iteration number: [1250/4518] 27% | Training loss: 0.6873565000534058
Epoch: 21 | Iteration number: [1260/4518] 27% | Training loss: 0.6873557442710513
Epoch: 21 | Iteration number: [1270/4518] 28% | Training loss: 0.6873544588333039
Epoch: 21 | Iteration number: [1280/4518] 28% | Training loss: 0.6873563048429787
Epoch: 21 | Iteration number: [1290/4518] 28% | Training loss: 0.6873605226823526
Epoch: 21 | Iteration number: [1300/4518] 28% | Training loss: 0.6873521389869544
Epoch: 21 | Iteration number: [1310/4518] 28% | Training loss: 0.6873449283246775
Epoch: 21 | Iteration number: [1320/4518] 29% | Training loss: 0.6873317460219065
Epoch: 21 | Iteration number: [1330/4518] 29% | Training loss: 0.6873322422791245
Epoch: 21 | Iteration number: [1340/4518] 29% | Training loss: 0.6873400901680562
Epoch: 21 | Iteration number: [1350/4518] 29% | Training loss: 0.6873356502585941
Epoch: 21 | Iteration number: [1360/4518] 30% | Training loss: 0.6873279108282397
Epoch: 21 | Iteration number: [1370/4518] 30% | Training loss: 0.6873180525581332
Epoch: 21 | Iteration number: [1380/4518] 30% | Training loss: 0.6873149316811907
Epoch: 21 | Iteration number: [1390/4518] 30% | Training loss: 0.6873172553323156
Epoch: 21 | Iteration number: [1400/4518] 30% | Training loss: 0.6873186769230025
Epoch: 21 | Iteration number: [1410/4518] 31% | Training loss: 0.6873098562372492
Epoch: 21 | Iteration number: [1420/4518] 31% | Training loss: 0.6873144513284656
Epoch: 21 | Iteration number: [1430/4518] 31% | Training loss: 0.6873118338468192
Epoch: 21 | Iteration number: [1440/4518] 31% | Training loss: 0.6873080458905961
Epoch: 21 | Iteration number: [1450/4518] 32% | Training loss: 0.687299435426449
Epoch: 21 | Iteration number: [1460/4518] 32% | Training loss: 0.6872944474220276
Epoch: 21 | Iteration number: [1470/4518] 32% | Training loss: 0.6872924792117813
Epoch: 21 | Iteration number: [1480/4518] 32% | Training loss: 0.6872999544481974
Epoch: 21 | Iteration number: [1490/4518] 32% | Training loss: 0.6872983738079967
Epoch: 21 | Iteration number: [1500/4518] 33% | Training loss: 0.6872936944961547
Epoch: 21 | Iteration number: [1510/4518] 33% | Training loss: 0.6872995586190003
Epoch: 21 | Iteration number: [1520/4518] 33% | Training loss: 0.6872960139654185
Epoch: 21 | Iteration number: [1530/4518] 33% | Training loss: 0.6873002945597655
Epoch: 21 | Iteration number: [1540/4518] 34% | Training loss: 0.6873007959359652
Epoch: 21 | Iteration number: [1550/4518] 34% | Training loss: 0.6872997689631677
Epoch: 21 | Iteration number: [1560/4518] 34% | Training loss: 0.6873000043707016
Epoch: 21 | Iteration number: [1570/4518] 34% | Training loss: 0.6873033136319203
Epoch: 21 | Iteration number: [1580/4518] 34% | Training loss: 0.687300428106815
Epoch: 21 | Iteration number: [1590/4518] 35% | Training loss: 0.68730493139171
Epoch: 21 | Iteration number: [1600/4518] 35% | Training loss: 0.6872946435585618
Epoch: 21 | Iteration number: [1610/4518] 35% | Training loss: 0.6872948180074278
Epoch: 21 | Iteration number: [1620/4518] 35% | Training loss: 0.6872938341196673
Epoch: 21 | Iteration number: [1630/4518] 36% | Training loss: 0.6872938546666338
Epoch: 21 | Iteration number: [1640/4518] 36% | Training loss: 0.6872849950339736
Epoch: 21 | Iteration number: [1650/4518] 36% | Training loss: 0.6872779449549589
Epoch: 21 | Iteration number: [1660/4518] 36% | Training loss: 0.6872814660330853
Epoch: 21 | Iteration number: [1670/4518] 36% | Training loss: 0.6872824931216097
Epoch: 21 | Iteration number: [1680/4518] 37% | Training loss: 0.6872834139281795
Epoch: 21 | Iteration number: [1690/4518] 37% | Training loss: 0.6872886080008287
Epoch: 21 | Iteration number: [1700/4518] 37% | Training loss: 0.6872826888280756
Epoch: 21 | Iteration number: [1710/4518] 37% | Training loss: 0.6872769831216823
Epoch: 21 | Iteration number: [1720/4518] 38% | Training loss: 0.687278913446637
Epoch: 21 | Iteration number: [1730/4518] 38% | Training loss: 0.6872830279989739
Epoch: 21 | Iteration number: [1740/4518] 38% | Training loss: 0.6872797403184847
Epoch: 21 | Iteration number: [1750/4518] 38% | Training loss: 0.6872761810166496
Epoch: 21 | Iteration number: [1760/4518] 38% | Training loss: 0.687276771969416
Epoch: 21 | Iteration number: [1770/4518] 39% | Training loss: 0.6872745781968542
Epoch: 21 | Iteration number: [1780/4518] 39% | Training loss: 0.6872735201977612
Epoch: 21 | Iteration number: [1790/4518] 39% | Training loss: 0.6872706896765938
Epoch: 21 | Iteration number: [1800/4518] 39% | Training loss: 0.6872680669691827
Epoch: 21 | Iteration number: [1810/4518] 40% | Training loss: 0.6872657002335754
Epoch: 21 | Iteration number: [1820/4518] 40% | Training loss: 0.6872639352803702
Epoch: 21 | Iteration number: [1830/4518] 40% | Training loss: 0.6872593091485278
Epoch: 21 | Iteration number: [1840/4518] 40% | Training loss: 0.6872566105878871
Epoch: 21 | Iteration number: [1850/4518] 40% | Training loss: 0.6872504637692426
Epoch: 21 | Iteration number: [1860/4518] 41% | Training loss: 0.6872439975379616
Epoch: 21 | Iteration number: [1870/4518] 41% | Training loss: 0.6872384992194048
Epoch: 21 | Iteration number: [1880/4518] 41% | Training loss: 0.6872372021383427
Epoch: 21 | Iteration number: [1890/4518] 41% | Training loss: 0.6872380110006484
Epoch: 21 | Iteration number: [1900/4518] 42% | Training loss: 0.6872294124176628
Epoch: 21 | Iteration number: [1910/4518] 42% | Training loss: 0.6872277647100818
Epoch: 21 | Iteration number: [1920/4518] 42% | Training loss: 0.6872259225075443
Epoch: 21 | Iteration number: [1930/4518] 42% | Training loss: 0.6872256844154911
Epoch: 21 | Iteration number: [1940/4518] 42% | Training loss: 0.687226674083582
Epoch: 21 | Iteration number: [1950/4518] 43% | Training loss: 0.6872240378306462
Epoch: 21 | Iteration number: [1960/4518] 43% | Training loss: 0.6872237203984845
Epoch: 21 | Iteration number: [1970/4518] 43% | Training loss: 0.6872206832249153
Epoch: 21 | Iteration number: [1980/4518] 43% | Training loss: 0.687213727530807
Epoch: 21 | Iteration number: [1990/4518] 44% | Training loss: 0.6872164198202104
Epoch: 21 | Iteration number: [2000/4518] 44% | Training loss: 0.6872162889242173
Epoch: 21 | Iteration number: [2010/4518] 44% | Training loss: 0.6872199820641854
Epoch: 21 | Iteration number: [2020/4518] 44% | Training loss: 0.6872186648668629
Epoch: 21 | Iteration number: [2030/4518] 44% | Training loss: 0.6872140087223992
Epoch: 21 | Iteration number: [2040/4518] 45% | Training loss: 0.6872111830056883
Epoch: 21 | Iteration number: [2050/4518] 45% | Training loss: 0.6872030240442695
Epoch: 21 | Iteration number: [2060/4518] 45% | Training loss: 0.6871991026748732
Epoch: 21 | Iteration number: [2070/4518] 45% | Training loss: 0.6871962529449647
Epoch: 21 | Iteration number: [2080/4518] 46% | Training loss: 0.6871893163197316
Epoch: 21 | Iteration number: [2090/4518] 46% | Training loss: 0.6871878144558536
Epoch: 21 | Iteration number: [2100/4518] 46% | Training loss: 0.6871867501451856
Epoch: 21 | Iteration number: [2110/4518] 46% | Training loss: 0.687192049721406
Epoch: 21 | Iteration number: [2120/4518] 46% | Training loss: 0.6871896948454514
Epoch: 21 | Iteration number: [2130/4518] 47% | Training loss: 0.6871851412343307
Epoch: 21 | Iteration number: [2140/4518] 47% | Training loss: 0.6871866787705466
Epoch: 21 | Iteration number: [2150/4518] 47% | Training loss: 0.6871857136349345
Epoch: 21 | Iteration number: [2160/4518] 47% | Training loss: 0.687187998659081
Epoch: 21 | Iteration number: [2170/4518] 48% | Training loss: 0.6871819609595883
Epoch: 21 | Iteration number: [2180/4518] 48% | Training loss: 0.6871829503993375
Epoch: 21 | Iteration number: [2190/4518] 48% | Training loss: 0.6871877933746059
Epoch: 21 | Iteration number: [2200/4518] 48% | Training loss: 0.6871790371157906
Epoch: 21 | Iteration number: [2210/4518] 48% | Training loss: 0.6871751314644361
Epoch: 21 | Iteration number: [2220/4518] 49% | Training loss: 0.6871710800104313
Epoch: 21 | Iteration number: [2230/4518] 49% | Training loss: 0.687175548637929
Epoch: 21 | Iteration number: [2240/4518] 49% | Training loss: 0.6871786855959466
Epoch: 21 | Iteration number: [2250/4518] 49% | Training loss: 0.6871798217826419
Epoch: 21 | Iteration number: [2260/4518] 50% | Training loss: 0.6871756450792329
Epoch: 21 | Iteration number: [2270/4518] 50% | Training loss: 0.6871734482338775
Epoch: 21 | Iteration number: [2280/4518] 50% | Training loss: 0.6871626205873071
Epoch: 21 | Iteration number: [2290/4518] 50% | Training loss: 0.6871641747035314
Epoch: 21 | Iteration number: [2300/4518] 50% | Training loss: 0.6871622603872548
Epoch: 21 | Iteration number: [2310/4518] 51% | Training loss: 0.6871618653272653
Epoch: 21 | Iteration number: [2320/4518] 51% | Training loss: 0.6871663455305428
Epoch: 21 | Iteration number: [2330/4518] 51% | Training loss: 0.6871718086142397
Epoch: 21 | Iteration number: [2340/4518] 51% | Training loss: 0.6871765179766549
Epoch: 21 | Iteration number: [2350/4518] 52% | Training loss: 0.687173406469061
Epoch: 21 | Iteration number: [2360/4518] 52% | Training loss: 0.6871715694413347
Epoch: 21 | Iteration number: [2370/4518] 52% | Training loss: 0.6871700275044904
Epoch: 21 | Iteration number: [2380/4518] 52% | Training loss: 0.6871710492783234
Epoch: 21 | Iteration number: [2390/4518] 52% | Training loss: 0.6871656490918483
Epoch: 21 | Iteration number: [2400/4518] 53% | Training loss: 0.6871580218027036
Epoch: 21 | Iteration number: [2410/4518] 53% | Training loss: 0.6871550546394839
Epoch: 21 | Iteration number: [2420/4518] 53% | Training loss: 0.6871519187511491
Epoch: 21 | Iteration number: [2430/4518] 53% | Training loss: 0.6871535652213626
Epoch: 21 | Iteration number: [2440/4518] 54% | Training loss: 0.6871529508809574
Epoch: 21 | Iteration number: [2450/4518] 54% | Training loss: 0.6871528619892743
Epoch: 21 | Iteration number: [2460/4518] 54% | Training loss: 0.6871536061046569
Epoch: 21 | Iteration number: [2470/4518] 54% | Training loss: 0.6871462541794487
Epoch: 21 | Iteration number: [2480/4518] 54% | Training loss: 0.6871469430625439
Epoch: 21 | Iteration number: [2490/4518] 55% | Training loss: 0.6871497476675424
Epoch: 21 | Iteration number: [2500/4518] 55% | Training loss: 0.6871478460788727
Epoch: 21 | Iteration number: [2510/4518] 55% | Training loss: 0.6871495744621611
Epoch: 21 | Iteration number: [2520/4518] 55% | Training loss: 0.6871394062799121
Epoch: 21 | Iteration number: [2530/4518] 55% | Training loss: 0.6871391167518178
Epoch: 21 | Iteration number: [2540/4518] 56% | Training loss: 0.687137477369759
Epoch: 21 | Iteration number: [2550/4518] 56% | Training loss: 0.6871337959579393
Epoch: 21 | Iteration number: [2560/4518] 56% | Training loss: 0.6871325147338212
Epoch: 21 | Iteration number: [2570/4518] 56% | Training loss: 0.6871334515193093
Epoch: 21 | Iteration number: [2580/4518] 57% | Training loss: 0.6871273239453634
Epoch: 21 | Iteration number: [2590/4518] 57% | Training loss: 0.6871312795688747
Epoch: 21 | Iteration number: [2600/4518] 57% | Training loss: 0.687130125761032
Epoch: 21 | Iteration number: [2610/4518] 57% | Training loss: 0.6871294207499858
Epoch: 21 | Iteration number: [2620/4518] 57% | Training loss: 0.6871281387696739
Epoch: 21 | Iteration number: [2630/4518] 58% | Training loss: 0.6871294646435364
Epoch: 21 | Iteration number: [2640/4518] 58% | Training loss: 0.6871300799151262
Epoch: 21 | Iteration number: [2650/4518] 58% | Training loss: 0.6871321458186743
Epoch: 21 | Iteration number: [2660/4518] 58% | Training loss: 0.6871323124806684
Epoch: 21 | Iteration number: [2670/4518] 59% | Training loss: 0.6871310419134433
Epoch: 21 | Iteration number: [2680/4518] 59% | Training loss: 0.6871316081552363
Epoch: 21 | Iteration number: [2690/4518] 59% | Training loss: 0.6871299658344581
Epoch: 21 | Iteration number: [2700/4518] 59% | Training loss: 0.6871328715704106
Epoch: 21 | Iteration number: [2710/4518] 59% | Training loss: 0.6871326294992243
Epoch: 21 | Iteration number: [2720/4518] 60% | Training loss: 0.6871325885110041
Epoch: 21 | Iteration number: [2730/4518] 60% | Training loss: 0.6871307322393844
Epoch: 21 | Iteration number: [2740/4518] 60% | Training loss: 0.6871286204479037
Epoch: 21 | Iteration number: [2750/4518] 60% | Training loss: 0.6871307632706382
Epoch: 21 | Iteration number: [2760/4518] 61% | Training loss: 0.6871327083611833
Epoch: 21 | Iteration number: [2770/4518] 61% | Training loss: 0.6871321856545197
Epoch: 21 | Iteration number: [2780/4518] 61% | Training loss: 0.6871315460410907
Epoch: 21 | Iteration number: [2790/4518] 61% | Training loss: 0.6871312979301671
Epoch: 21 | Iteration number: [2800/4518] 61% | Training loss: 0.6871359205884593
Epoch: 21 | Iteration number: [2810/4518] 62% | Training loss: 0.6871312265930651
Epoch: 21 | Iteration number: [2820/4518] 62% | Training loss: 0.6871315811965483
Epoch: 21 | Iteration number: [2830/4518] 62% | Training loss: 0.6871331938795824
Epoch: 21 | Iteration number: [2840/4518] 62% | Training loss: 0.687130691614789
Epoch: 21 | Iteration number: [2850/4518] 63% | Training loss: 0.687125457587995
Epoch: 21 | Iteration number: [2860/4518] 63% | Training loss: 0.6871264881812609
Epoch: 21 | Iteration number: [2870/4518] 63% | Training loss: 0.6871274684779736
Epoch: 21 | Iteration number: [2880/4518] 63% | Training loss: 0.6871264454805188
Epoch: 21 | Iteration number: [2890/4518] 63% | Training loss: 0.6871278290930092
Epoch: 21 | Iteration number: [2900/4518] 64% | Training loss: 0.6871257676749394
Epoch: 21 | Iteration number: [2910/4518] 64% | Training loss: 0.6871291653397157
Epoch: 21 | Iteration number: [2920/4518] 64% | Training loss: 0.6871303363818012
Epoch: 21 | Iteration number: [2930/4518] 64% | Training loss: 0.687129636368247
Epoch: 21 | Iteration number: [2940/4518] 65% | Training loss: 0.6871209763750739
Epoch: 21 | Iteration number: [2950/4518] 65% | Training loss: 0.6871254825794091
Epoch: 21 | Iteration number: [2960/4518] 65% | Training loss: 0.6871223097113339
Epoch: 21 | Iteration number: [2970/4518] 65% | Training loss: 0.6871238104020706
Epoch: 21 | Iteration number: [2980/4518] 65% | Training loss: 0.6871205468905852
Epoch: 21 | Iteration number: [2990/4518] 66% | Training loss: 0.6871206739475098
Epoch: 21 | Iteration number: [3000/4518] 66% | Training loss: 0.6871188023686409
Epoch: 21 | Iteration number: [3010/4518] 66% | Training loss: 0.6871132546683086
Epoch: 21 | Iteration number: [3020/4518] 66% | Training loss: 0.6871097391606956
Epoch: 21 | Iteration number: [3030/4518] 67% | Training loss: 0.6871115862536352
Epoch: 21 | Iteration number: [3040/4518] 67% | Training loss: 0.6871105822293382
Epoch: 21 | Iteration number: [3050/4518] 67% | Training loss: 0.6871107927697604
Epoch: 21 | Iteration number: [3060/4518] 67% | Training loss: 0.6871068083967259
Epoch: 21 | Iteration number: [3070/4518] 67% | Training loss: 0.6871074848920592
Epoch: 21 | Iteration number: [3080/4518] 68% | Training loss: 0.6871066388178181
Epoch: 21 | Iteration number: [3090/4518] 68% | Training loss: 0.6871109534621624
Epoch: 21 | Iteration number: [3100/4518] 68% | Training loss: 0.6871067934459255
Epoch: 21 | Iteration number: [3110/4518] 68% | Training loss: 0.6871069439354434
Epoch: 21 | Iteration number: [3120/4518] 69% | Training loss: 0.6871042980215488
Epoch: 21 | Iteration number: [3130/4518] 69% | Training loss: 0.6871030263436108
Epoch: 21 | Iteration number: [3140/4518] 69% | Training loss: 0.6871019842518363
Epoch: 21 | Iteration number: [3150/4518] 69% | Training loss: 0.6870980783114358
Epoch: 21 | Iteration number: [3160/4518] 69% | Training loss: 0.6871021068548855
Epoch: 21 | Iteration number: [3170/4518] 70% | Training loss: 0.6871011893831969
Epoch: 21 | Iteration number: [3180/4518] 70% | Training loss: 0.6870984254205752
Epoch: 21 | Iteration number: [3190/4518] 70% | Training loss: 0.6870986820762061
Epoch: 21 | Iteration number: [3200/4518] 70% | Training loss: 0.6870998500101269
Epoch: 21 | Iteration number: [3210/4518] 71% | Training loss: 0.6870980295808145
Epoch: 21 | Iteration number: [3220/4518] 71% | Training loss: 0.6870975995471018
Epoch: 21 | Iteration number: [3230/4518] 71% | Training loss: 0.6870956325494099
Epoch: 21 | Iteration number: [3240/4518] 71% | Training loss: 0.6870937046997341
Epoch: 21 | Iteration number: [3250/4518] 71% | Training loss: 0.6870933514558352
Epoch: 21 | Iteration number: [3260/4518] 72% | Training loss: 0.6870938972461443
Epoch: 21 | Iteration number: [3270/4518] 72% | Training loss: 0.6870939138285611
Epoch: 21 | Iteration number: [3280/4518] 72% | Training loss: 0.6870949365562056
Epoch: 21 | Iteration number: [3290/4518] 72% | Training loss: 0.687091930441581
Epoch: 21 | Iteration number: [3300/4518] 73% | Training loss: 0.687092700528376
Epoch: 21 | Iteration number: [3310/4518] 73% | Training loss: 0.6870966037414585
Epoch: 21 | Iteration number: [3320/4518] 73% | Training loss: 0.687092648374747
Epoch: 21 | Iteration number: [3330/4518] 73% | Training loss: 0.6870911368020662
Epoch: 21 | Iteration number: [3340/4518] 73% | Training loss: 0.6870898656323998
Epoch: 21 | Iteration number: [3350/4518] 74% | Training loss: 0.6870860452438469
Epoch: 21 | Iteration number: [3360/4518] 74% | Training loss: 0.6870836927777245
Epoch: 21 | Iteration number: [3370/4518] 74% | Training loss: 0.6870836017570439
Epoch: 21 | Iteration number: [3380/4518] 74% | Training loss: 0.6870843193587467
Epoch: 21 | Iteration number: [3390/4518] 75% | Training loss: 0.6870882365731715
Epoch: 21 | Iteration number: [3400/4518] 75% | Training loss: 0.6870885606898981
Epoch: 21 | Iteration number: [3410/4518] 75% | Training loss: 0.6870862199064574
Epoch: 21 | Iteration number: [3420/4518] 75% | Training loss: 0.687087279436184
Epoch: 21 | Iteration number: [3430/4518] 75% | Training loss: 0.687089912032942
Epoch: 21 | Iteration number: [3440/4518] 76% | Training loss: 0.6870885141020597
Epoch: 21 | Iteration number: [3450/4518] 76% | Training loss: 0.6870907880257869
Epoch: 21 | Iteration number: [3460/4518] 76% | Training loss: 0.6870897943401613
Epoch: 21 | Iteration number: [3470/4518] 76% | Training loss: 0.6870878753813268
Epoch: 21 | Iteration number: [3480/4518] 77% | Training loss: 0.6870848249429944
Epoch: 21 | Iteration number: [3490/4518] 77% | Training loss: 0.6870890116452487
Epoch: 21 | Iteration number: [3500/4518] 77% | Training loss: 0.6870838615213122
Epoch: 21 | Iteration number: [3510/4518] 77% | Training loss: 0.6870808069352751
Epoch: 21 | Iteration number: [3520/4518] 77% | Training loss: 0.6870787484063343
Epoch: 21 | Iteration number: [3530/4518] 78% | Training loss: 0.6870822793532363
Epoch: 21 | Iteration number: [3540/4518] 78% | Training loss: 0.6870820223443252
Epoch: 21 | Iteration number: [3550/4518] 78% | Training loss: 0.6870794405903615
Epoch: 21 | Iteration number: [3560/4518] 78% | Training loss: 0.68707893698403
Epoch: 21 | Iteration number: [3570/4518] 79% | Training loss: 0.6870805219775822
Epoch: 21 | Iteration number: [3580/4518] 79% | Training loss: 0.6870781946448641
Epoch: 21 | Iteration number: [3590/4518] 79% | Training loss: 0.6870789843017344
Epoch: 21 | Iteration number: [3600/4518] 79% | Training loss: 0.6870807126661141
Epoch: 21 | Iteration number: [3610/4518] 79% | Training loss: 0.6870778862128958
Epoch: 21 | Iteration number: [3620/4518] 80% | Training loss: 0.6870775295719916
Epoch: 21 | Iteration number: [3630/4518] 80% | Training loss: 0.6870797079785139
Epoch: 21 | Iteration number: [3640/4518] 80% | Training loss: 0.6870799671490114
Epoch: 21 | Iteration number: [3650/4518] 80% | Training loss: 0.6870839232941196
Epoch: 21 | Iteration number: [3660/4518] 81% | Training loss: 0.6870824842342262
Epoch: 21 | Iteration number: [3670/4518] 81% | Training loss: 0.6870836521526773
Epoch: 21 | Iteration number: [3680/4518] 81% | Training loss: 0.6870852036482614
Epoch: 21 | Iteration number: [3690/4518] 81% | Training loss: 0.6870819537297174
Epoch: 21 | Iteration number: [3700/4518] 81% | Training loss: 0.6870825220282013
Epoch: 21 | Iteration number: [3710/4518] 82% | Training loss: 0.6870842446856743
Epoch: 21 | Iteration number: [3720/4518] 82% | Training loss: 0.6870855072973877
Epoch: 21 | Iteration number: [3730/4518] 82% | Training loss: 0.6870853380127823
Epoch: 21 | Iteration number: [3740/4518] 82% | Training loss: 0.6870870908154524
Epoch: 21 | Iteration number: [3750/4518] 83% | Training loss: 0.6870853387355804
Epoch: 21 | Iteration number: [3760/4518] 83% | Training loss: 0.6870870249068484
Epoch: 21 | Iteration number: [3770/4518] 83% | Training loss: 0.6870862817100252
Epoch: 21 | Iteration number: [3780/4518] 83% | Training loss: 0.6870857125867611
Epoch: 21 | Iteration number: [3790/4518] 83% | Training loss: 0.6870838356835861
Epoch: 21 | Iteration number: [3800/4518] 84% | Training loss: 0.6870819143401949
Epoch: 21 | Iteration number: [3810/4518] 84% | Training loss: 0.6870798637391389
Epoch: 21 | Iteration number: [3820/4518] 84% | Training loss: 0.6870810735444124
Epoch: 21 | Iteration number: [3830/4518] 84% | Training loss: 0.6870827426953976
Epoch: 21 | Iteration number: [3840/4518] 84% | Training loss: 0.6870824633631856
Epoch: 21 | Iteration number: [3850/4518] 85% | Training loss: 0.6870842497534566
Epoch: 21 | Iteration number: [3860/4518] 85% | Training loss: 0.6870801765375186
Epoch: 21 | Iteration number: [3870/4518] 85% | Training loss: 0.6870817949605542
Epoch: 21 | Iteration number: [3880/4518] 85% | Training loss: 0.6870801556048934
Epoch: 21 | Iteration number: [3890/4518] 86% | Training loss: 0.6870812771559375
Epoch: 21 | Iteration number: [3900/4518] 86% | Training loss: 0.6870822487121974
Epoch: 21 | Iteration number: [3910/4518] 86% | Training loss: 0.6870813271883504
Epoch: 21 | Iteration number: [3920/4518] 86% | Training loss: 0.6870818153175773
Epoch: 21 | Iteration number: [3930/4518] 86% | Training loss: 0.6870822043060953
Epoch: 21 | Iteration number: [3940/4518] 87% | Training loss: 0.6870821798815945
Epoch: 21 | Iteration number: [3950/4518] 87% | Training loss: 0.6870822732508937
Epoch: 21 | Iteration number: [3960/4518] 87% | Training loss: 0.6870793102365551
Epoch: 21 | Iteration number: [3970/4518] 87% | Training loss: 0.6870753145338006
Epoch: 21 | Iteration number: [3980/4518] 88% | Training loss: 0.6870744025287916
Epoch: 21 | Iteration number: [3990/4518] 88% | Training loss: 0.6870735692350488
Epoch: 21 | Iteration number: [4000/4518] 88% | Training loss: 0.6870708795189857
Epoch: 21 | Iteration number: [4010/4518] 88% | Training loss: 0.6870698748235393
Epoch: 21 | Iteration number: [4020/4518] 88% | Training loss: 0.687070023820768
Epoch: 21 | Iteration number: [4030/4518] 89% | Training loss: 0.6870669847682451
Epoch: 21 | Iteration number: [4040/4518] 89% | Training loss: 0.6870683650716697
Epoch: 21 | Iteration number: [4050/4518] 89% | Training loss: 0.6870676160447391
Epoch: 21 | Iteration number: [4060/4518] 89% | Training loss: 0.687066740399511
Epoch: 21 | Iteration number: [4070/4518] 90% | Training loss: 0.6870652919172948
Epoch: 21 | Iteration number: [4080/4518] 90% | Training loss: 0.6870657308428896
Epoch: 21 | Iteration number: [4090/4518] 90% | Training loss: 0.6870666848709648
Epoch: 21 | Iteration number: [4100/4518] 90% | Training loss: 0.6870656108274692
Epoch: 21 | Iteration number: [4110/4518] 90% | Training loss: 0.687069023322595
Epoch: 21 | Iteration number: [4120/4518] 91% | Training loss: 0.6870706698848206
Epoch: 21 | Iteration number: [4130/4518] 91% | Training loss: 0.6870704137528492
Epoch: 21 | Iteration number: [4140/4518] 91% | Training loss: 0.6870699467434399
Epoch: 21 | Iteration number: [4150/4518] 91% | Training loss: 0.6870735442351146
Epoch: 21 | Iteration number: [4160/4518] 92% | Training loss: 0.6870713294555362
Epoch: 21 | Iteration number: [4170/4518] 92% | Training loss: 0.6870717865957631
Epoch: 21 | Iteration number: [4180/4518] 92% | Training loss: 0.6870696246623993
Epoch: 21 | Iteration number: [4190/4518] 92% | Training loss: 0.6870671302578045
Epoch: 21 | Iteration number: [4200/4518] 92% | Training loss: 0.687068648026103
Epoch: 21 | Iteration number: [4210/4518] 93% | Training loss: 0.6870672362434043
Epoch: 21 | Iteration number: [4220/4518] 93% | Training loss: 0.6870670864791102
Epoch: 21 | Iteration number: [4230/4518] 93% | Training loss: 0.6870679491518801
Epoch: 21 | Iteration number: [4240/4518] 93% | Training loss: 0.6870630917262356
Epoch: 21 | Iteration number: [4250/4518] 94% | Training loss: 0.6870629908477559
Epoch: 21 | Iteration number: [4260/4518] 94% | Training loss: 0.6870623516364837
Epoch: 21 | Iteration number: [4270/4518] 94% | Training loss: 0.6870626315020845
Epoch: 21 | Iteration number: [4280/4518] 94% | Training loss: 0.6870612159371376
Epoch: 21 | Iteration number: [4290/4518] 94% | Training loss: 0.6870609788211075
Epoch: 21 | Iteration number: [4300/4518] 95% | Training loss: 0.6870619590199271
Epoch: 21 | Iteration number: [4310/4518] 95% | Training loss: 0.6870623127490352
Epoch: 21 | Iteration number: [4320/4518] 95% | Training loss: 0.6870603217156949
Epoch: 21 | Iteration number: [4330/4518] 95% | Training loss: 0.6870611629915567
Epoch: 21 | Iteration number: [4340/4518] 96% | Training loss: 0.6870617027518936
Epoch: 21 | Iteration number: [4350/4518] 96% | Training loss: 0.6870631608606755
Epoch: 21 | Iteration number: [4360/4518] 96% | Training loss: 0.6870611451907989
Epoch: 21 | Iteration number: [4370/4518] 96% | Training loss: 0.6870634087435986
Epoch: 21 | Iteration number: [4380/4518] 96% | Training loss: 0.6870599142492634
Epoch: 21 | Iteration number: [4390/4518] 97% | Training loss: 0.687061799522956
Epoch: 21 | Iteration number: [4400/4518] 97% | Training loss: 0.6870596489852125
Epoch: 21 | Iteration number: [4410/4518] 97% | Training loss: 0.6870568550227721
Epoch: 21 | Iteration number: [4420/4518] 97% | Training loss: 0.6870543274135071
Epoch: 21 | Iteration number: [4430/4518] 98% | Training loss: 0.6870546926225012
Epoch: 21 | Iteration number: [4440/4518] 98% | Training loss: 0.6870556578308612
Epoch: 21 | Iteration number: [4450/4518] 98% | Training loss: 0.6870572311690684
Epoch: 21 | Iteration number: [4460/4518] 98% | Training loss: 0.6870569354883759
Epoch: 21 | Iteration number: [4470/4518] 98% | Training loss: 0.6870533493541231
Epoch: 21 | Iteration number: [4480/4518] 99% | Training loss: 0.6870539794276868
Epoch: 21 | Iteration number: [4490/4518] 99% | Training loss: 0.6870558477987956
Epoch: 21 | Iteration number: [4500/4518] 99% | Training loss: 0.6870537821981642
Epoch: 21 | Iteration number: [4510/4518] 99% | Training loss: 0.6870519738107457

 End of epoch: 21 | Train Loss: 0.6868986447018931 | Training Time: 640 

 End of epoch: 21 | Eval Loss: 0.6901094572884696 | Evaluating Time: 17 
Epoch: 22 | Iteration number: [10/4518] 0% | Training loss: 0.7552658677101135
Epoch: 22 | Iteration number: [20/4518] 0% | Training loss: 0.7208907425403595
Epoch: 22 | Iteration number: [30/4518] 0% | Training loss: 0.7093287646770478
Epoch: 22 | Iteration number: [40/4518] 0% | Training loss: 0.7035814851522446
Epoch: 22 | Iteration number: [50/4518] 1% | Training loss: 0.7001860511302948
Epoch: 22 | Iteration number: [60/4518] 1% | Training loss: 0.6977520893017451
Epoch: 22 | Iteration number: [70/4518] 1% | Training loss: 0.696009909255164
Epoch: 22 | Iteration number: [80/4518] 1% | Training loss: 0.6948279470205307
Epoch: 22 | Iteration number: [90/4518] 1% | Training loss: 0.6938654085000356
Epoch: 22 | Iteration number: [100/4518] 2% | Training loss: 0.6932871288061142
Epoch: 22 | Iteration number: [110/4518] 2% | Training loss: 0.6927019010890614
Epoch: 22 | Iteration number: [120/4518] 2% | Training loss: 0.6922486995657285
Epoch: 22 | Iteration number: [130/4518] 2% | Training loss: 0.6918796218358554
Epoch: 22 | Iteration number: [140/4518] 3% | Training loss: 0.6914927163294383
Epoch: 22 | Iteration number: [150/4518] 3% | Training loss: 0.6912196918328604
Epoch: 22 | Iteration number: [160/4518] 3% | Training loss: 0.6909556075930595
Epoch: 22 | Iteration number: [170/4518] 3% | Training loss: 0.6907427303931293
Epoch: 22 | Iteration number: [180/4518] 3% | Training loss: 0.690519267320633
Epoch: 22 | Iteration number: [190/4518] 4% | Training loss: 0.6902697218091864
Epoch: 22 | Iteration number: [200/4518] 4% | Training loss: 0.6901230040192604
Epoch: 22 | Iteration number: [210/4518] 4% | Training loss: 0.6899433320476895
Epoch: 22 | Iteration number: [220/4518] 4% | Training loss: 0.6898443138057535
Epoch: 22 | Iteration number: [230/4518] 5% | Training loss: 0.6896908384302388
Epoch: 22 | Iteration number: [240/4518] 5% | Training loss: 0.6895835980772972
Epoch: 22 | Iteration number: [250/4518] 5% | Training loss: 0.6894477093219757
Epoch: 22 | Iteration number: [260/4518] 5% | Training loss: 0.6893502829166559
Epoch: 22 | Iteration number: [270/4518] 5% | Training loss: 0.6892569530893256
Epoch: 22 | Iteration number: [280/4518] 6% | Training loss: 0.6891927674412728
Epoch: 22 | Iteration number: [290/4518] 6% | Training loss: 0.6890894793230912
Epoch: 22 | Iteration number: [300/4518] 6% | Training loss: 0.6890604945023855
Epoch: 22 | Iteration number: [310/4518] 6% | Training loss: 0.6889489589198943
Epoch: 22 | Iteration number: [320/4518] 7% | Training loss: 0.6888848386704922
Epoch: 22 | Iteration number: [330/4518] 7% | Training loss: 0.6887847356724016
Epoch: 22 | Iteration number: [340/4518] 7% | Training loss: 0.688717773732017
Epoch: 22 | Iteration number: [350/4518] 7% | Training loss: 0.6886704388686589
Epoch: 22 | Iteration number: [360/4518] 7% | Training loss: 0.6886315923598078
Epoch: 22 | Iteration number: [370/4518] 8% | Training loss: 0.6885923000606331
Epoch: 22 | Iteration number: [380/4518] 8% | Training loss: 0.6884874091336601
Epoch: 22 | Iteration number: [390/4518] 8% | Training loss: 0.688471132516861
Epoch: 22 | Iteration number: [400/4518] 8% | Training loss: 0.6884160515666008
Epoch: 22 | Iteration number: [410/4518] 9% | Training loss: 0.6883448001815051
Epoch: 22 | Iteration number: [420/4518] 9% | Training loss: 0.6882982651392618
Epoch: 22 | Iteration number: [430/4518] 9% | Training loss: 0.6882581981115563
Epoch: 22 | Iteration number: [440/4518] 9% | Training loss: 0.6882385115731846
Epoch: 22 | Iteration number: [450/4518] 9% | Training loss: 0.6881877023643918
Epoch: 22 | Iteration number: [460/4518] 10% | Training loss: 0.6881742408742075
Epoch: 22 | Iteration number: [470/4518] 10% | Training loss: 0.6881557878027571
Epoch: 22 | Iteration number: [480/4518] 10% | Training loss: 0.6881096333265304
Epoch: 22 | Iteration number: [490/4518] 10% | Training loss: 0.6880760223281627
Epoch: 22 | Iteration number: [500/4518] 11% | Training loss: 0.6880539302825928
Epoch: 22 | Iteration number: [510/4518] 11% | Training loss: 0.6880172015405168
Epoch: 22 | Iteration number: [520/4518] 11% | Training loss: 0.6879970353383285
Epoch: 22 | Iteration number: [530/4518] 11% | Training loss: 0.6879809574136194
Epoch: 22 | Iteration number: [540/4518] 11% | Training loss: 0.6879749062988493
Epoch: 22 | Iteration number: [550/4518] 12% | Training loss: 0.6879603230953216
Epoch: 22 | Iteration number: [560/4518] 12% | Training loss: 0.6879791373653071
Epoch: 22 | Iteration number: [570/4518] 12% | Training loss: 0.6879668119706606
Epoch: 22 | Iteration number: [580/4518] 12% | Training loss: 0.6879668970560205
Epoch: 22 | Iteration number: [590/4518] 13% | Training loss: 0.687940774630692
Epoch: 22 | Iteration number: [600/4518] 13% | Training loss: 0.6879219753543536
Epoch: 22 | Iteration number: [610/4518] 13% | Training loss: 0.6879104500911275
Epoch: 22 | Iteration number: [620/4518] 13% | Training loss: 0.687874587601231
Epoch: 22 | Iteration number: [630/4518] 13% | Training loss: 0.6878511815790146
Epoch: 22 | Iteration number: [640/4518] 14% | Training loss: 0.6878169381991028
Epoch: 22 | Iteration number: [650/4518] 14% | Training loss: 0.6878107836613289
Epoch: 22 | Iteration number: [660/4518] 14% | Training loss: 0.6877701910156192
Epoch: 22 | Iteration number: [670/4518] 14% | Training loss: 0.6877811930962463
Epoch: 22 | Iteration number: [680/4518] 15% | Training loss: 0.6877708023085314
Epoch: 22 | Iteration number: [690/4518] 15% | Training loss: 0.6877390937528749
Epoch: 22 | Iteration number: [700/4518] 15% | Training loss: 0.6877376254967281
Epoch: 22 | Iteration number: [710/4518] 15% | Training loss: 0.6877188403001974
Epoch: 22 | Iteration number: [720/4518] 15% | Training loss: 0.6877077171372042
Epoch: 22 | Iteration number: [730/4518] 16% | Training loss: 0.6876941696421741
Epoch: 22 | Iteration number: [740/4518] 16% | Training loss: 0.6876835776341929
Epoch: 22 | Iteration number: [750/4518] 16% | Training loss: 0.6876582469145457
Epoch: 22 | Iteration number: [760/4518] 16% | Training loss: 0.6876481179344026
Epoch: 22 | Iteration number: [770/4518] 17% | Training loss: 0.6876415748100776
Epoch: 22 | Iteration number: [780/4518] 17% | Training loss: 0.6876267641018599
Epoch: 22 | Iteration number: [790/4518] 17% | Training loss: 0.6876157108741471
Epoch: 22 | Iteration number: [800/4518] 17% | Training loss: 0.6876098894327879
Epoch: 22 | Iteration number: [810/4518] 17% | Training loss: 0.6876006537749444
Epoch: 22 | Iteration number: [820/4518] 18% | Training loss: 0.687606565181802
Epoch: 22 | Iteration number: [830/4518] 18% | Training loss: 0.6875994782849967
Epoch: 22 | Iteration number: [840/4518] 18% | Training loss: 0.6875963670157251
Epoch: 22 | Iteration number: [850/4518] 18% | Training loss: 0.6875793714383069
Epoch: 22 | Iteration number: [860/4518] 19% | Training loss: 0.6875726823196855
Epoch: 22 | Iteration number: [870/4518] 19% | Training loss: 0.687587026686504
Epoch: 22 | Iteration number: [880/4518] 19% | Training loss: 0.6875879782167348
Epoch: 22 | Iteration number: [890/4518] 19% | Training loss: 0.6875815779305576
Epoch: 22 | Iteration number: [900/4518] 19% | Training loss: 0.6875782275862165
Epoch: 22 | Iteration number: [910/4518] 20% | Training loss: 0.6875632154417562
Epoch: 22 | Iteration number: [920/4518] 20% | Training loss: 0.6875718834607497
Epoch: 22 | Iteration number: [930/4518] 20% | Training loss: 0.6875504975677819
Epoch: 22 | Iteration number: [940/4518] 20% | Training loss: 0.6875371050961474
Epoch: 22 | Iteration number: [950/4518] 21% | Training loss: 0.6875402559104719
Epoch: 22 | Iteration number: [960/4518] 21% | Training loss: 0.6875327806919813
Epoch: 22 | Iteration number: [970/4518] 21% | Training loss: 0.6875308743457205
Epoch: 22 | Iteration number: [980/4518] 21% | Training loss: 0.6875223102010026
Epoch: 22 | Iteration number: [990/4518] 21% | Training loss: 0.6875231550197408
Epoch: 22 | Iteration number: [1000/4518] 22% | Training loss: 0.68751127409935
Epoch: 22 | Iteration number: [1010/4518] 22% | Training loss: 0.6875161452458637
Epoch: 22 | Iteration number: [1020/4518] 22% | Training loss: 0.6875151193609425
Epoch: 22 | Iteration number: [1030/4518] 22% | Training loss: 0.6875034986190426
Epoch: 22 | Iteration number: [1040/4518] 23% | Training loss: 0.687510383874178
Epoch: 22 | Iteration number: [1050/4518] 23% | Training loss: 0.6875004913693382
Epoch: 22 | Iteration number: [1060/4518] 23% | Training loss: 0.6874842175897562
Epoch: 22 | Iteration number: [1070/4518] 23% | Training loss: 0.6874806636961821
Epoch: 22 | Iteration number: [1080/4518] 23% | Training loss: 0.6874782246572
Epoch: 22 | Iteration number: [1090/4518] 24% | Training loss: 0.6874730739571633
Epoch: 22 | Iteration number: [1100/4518] 24% | Training loss: 0.6874631799892946
Epoch: 22 | Iteration number: [1110/4518] 24% | Training loss: 0.6874595548118557
Epoch: 22 | Iteration number: [1120/4518] 24% | Training loss: 0.6874634888023138
Epoch: 22 | Iteration number: [1130/4518] 25% | Training loss: 0.6874601080354336
Epoch: 22 | Iteration number: [1140/4518] 25% | Training loss: 0.687457248307111
Epoch: 22 | Iteration number: [1150/4518] 25% | Training loss: 0.6874435660113459
Epoch: 22 | Iteration number: [1160/4518] 25% | Training loss: 0.6874458967611707
Epoch: 22 | Iteration number: [1170/4518] 25% | Training loss: 0.6874435731488415
Epoch: 22 | Iteration number: [1180/4518] 26% | Training loss: 0.6874481842174368
Epoch: 22 | Iteration number: [1190/4518] 26% | Training loss: 0.6874397666013541
Epoch: 22 | Iteration number: [1200/4518] 26% | Training loss: 0.6874389240145683
Epoch: 22 | Iteration number: [1210/4518] 26% | Training loss: 0.6874402355556646
Epoch: 22 | Iteration number: [1220/4518] 27% | Training loss: 0.6874290210301759
Epoch: 22 | Iteration number: [1230/4518] 27% | Training loss: 0.687433958198966
Epoch: 22 | Iteration number: [1240/4518] 27% | Training loss: 0.6874300921155561
Epoch: 22 | Iteration number: [1250/4518] 27% | Training loss: 0.6874307806968689
Epoch: 22 | Iteration number: [1260/4518] 27% | Training loss: 0.6874204260016245
Epoch: 22 | Iteration number: [1270/4518] 28% | Training loss: 0.6874134822154608
Epoch: 22 | Iteration number: [1280/4518] 28% | Training loss: 0.687409208342433
Epoch: 22 | Iteration number: [1290/4518] 28% | Training loss: 0.6874114583629046
Epoch: 22 | Iteration number: [1300/4518] 28% | Training loss: 0.6874001591022199
Epoch: 22 | Iteration number: [1310/4518] 28% | Training loss: 0.6873965777968633
Epoch: 22 | Iteration number: [1320/4518] 29% | Training loss: 0.6873966480294863
Epoch: 22 | Iteration number: [1330/4518] 29% | Training loss: 0.6873945367515535
Epoch: 22 | Iteration number: [1340/4518] 29% | Training loss: 0.6873912027077889
Epoch: 22 | Iteration number: [1350/4518] 29% | Training loss: 0.6873862512023361
Epoch: 22 | Iteration number: [1360/4518] 30% | Training loss: 0.6873864929903956
Epoch: 22 | Iteration number: [1370/4518] 30% | Training loss: 0.6873850858559574
Epoch: 22 | Iteration number: [1380/4518] 30% | Training loss: 0.6873909086420916
Epoch: 22 | Iteration number: [1390/4518] 30% | Training loss: 0.6873956984324421
Epoch: 22 | Iteration number: [1400/4518] 30% | Training loss: 0.6873938475336347
Epoch: 22 | Iteration number: [1410/4518] 31% | Training loss: 0.68738603456646
Epoch: 22 | Iteration number: [1420/4518] 31% | Training loss: 0.6873863200486546
Epoch: 22 | Iteration number: [1430/4518] 31% | Training loss: 0.6873798397037533
Epoch: 22 | Iteration number: [1440/4518] 31% | Training loss: 0.6873750007814832
Epoch: 22 | Iteration number: [1450/4518] 32% | Training loss: 0.6873686312395951
Epoch: 22 | Iteration number: [1460/4518] 32% | Training loss: 0.6873706350179568
Epoch: 22 | Iteration number: [1470/4518] 32% | Training loss: 0.6873753017714235
Epoch: 22 | Iteration number: [1480/4518] 32% | Training loss: 0.6873727559237867
Epoch: 22 | Iteration number: [1490/4518] 32% | Training loss: 0.6873764977759163
Epoch: 22 | Iteration number: [1500/4518] 33% | Training loss: 0.6873642454544703
Epoch: 22 | Iteration number: [1510/4518] 33% | Training loss: 0.6873692720536365
Epoch: 22 | Iteration number: [1520/4518] 33% | Training loss: 0.6873692175275401
Epoch: 22 | Iteration number: [1530/4518] 33% | Training loss: 0.6873687798680823
Epoch: 22 | Iteration number: [1540/4518] 34% | Training loss: 0.6873548914472778
Epoch: 22 | Iteration number: [1550/4518] 34% | Training loss: 0.6873518017030531
Epoch: 22 | Iteration number: [1560/4518] 34% | Training loss: 0.6873520896220818
Epoch: 22 | Iteration number: [1570/4518] 34% | Training loss: 0.6873455867266199
Epoch: 22 | Iteration number: [1580/4518] 34% | Training loss: 0.6873313844203949
Epoch: 22 | Iteration number: [1590/4518] 35% | Training loss: 0.6873286235632386
Epoch: 22 | Iteration number: [1600/4518] 35% | Training loss: 0.6873344193026424
Epoch: 22 | Iteration number: [1610/4518] 35% | Training loss: 0.6873316599715571
Epoch: 22 | Iteration number: [1620/4518] 35% | Training loss: 0.6873299420983703
Epoch: 22 | Iteration number: [1630/4518] 36% | Training loss: 0.6873279860414611
Epoch: 22 | Iteration number: [1640/4518] 36% | Training loss: 0.6873313237617655
Epoch: 22 | Iteration number: [1650/4518] 36% | Training loss: 0.6873313106190074
Epoch: 22 | Iteration number: [1660/4518] 36% | Training loss: 0.6873338290725846
Epoch: 22 | Iteration number: [1670/4518] 36% | Training loss: 0.6873263834479326
Epoch: 22 | Iteration number: [1680/4518] 37% | Training loss: 0.6873268752580597
Epoch: 22 | Iteration number: [1690/4518] 37% | Training loss: 0.6873168625069793
Epoch: 22 | Iteration number: [1700/4518] 37% | Training loss: 0.6873115894373726
Epoch: 22 | Iteration number: [1710/4518] 37% | Training loss: 0.687306623291551
Epoch: 22 | Iteration number: [1720/4518] 38% | Training loss: 0.6873009768336318
Epoch: 22 | Iteration number: [1730/4518] 38% | Training loss: 0.6872996700636913
Epoch: 22 | Iteration number: [1740/4518] 38% | Training loss: 0.6873016287540568
Epoch: 22 | Iteration number: [1750/4518] 38% | Training loss: 0.6873005215781076
Epoch: 22 | Iteration number: [1760/4518] 38% | Training loss: 0.6872950373048132
Epoch: 22 | Iteration number: [1770/4518] 39% | Training loss: 0.6872925407805686
Epoch: 22 | Iteration number: [1780/4518] 39% | Training loss: 0.6872868823536327
Epoch: 22 | Iteration number: [1790/4518] 39% | Training loss: 0.6872788911092215
Epoch: 22 | Iteration number: [1800/4518] 39% | Training loss: 0.6872785858644379
Epoch: 22 | Iteration number: [1810/4518] 40% | Training loss: 0.6872788676240826
Epoch: 22 | Iteration number: [1820/4518] 40% | Training loss: 0.6872706874058797
Epoch: 22 | Iteration number: [1830/4518] 40% | Training loss: 0.6872700759947625
Epoch: 22 | Iteration number: [1840/4518] 40% | Training loss: 0.6872613239223543
Epoch: 22 | Iteration number: [1850/4518] 40% | Training loss: 0.6872605781941801
Epoch: 22 | Iteration number: [1860/4518] 41% | Training loss: 0.6872693636725026
Epoch: 22 | Iteration number: [1870/4518] 41% | Training loss: 0.6872701878216178
Epoch: 22 | Iteration number: [1880/4518] 41% | Training loss: 0.6872754082083702
Epoch: 22 | Iteration number: [1890/4518] 41% | Training loss: 0.6872661409870027
Epoch: 22 | Iteration number: [1900/4518] 42% | Training loss: 0.6872606658621838
Epoch: 22 | Iteration number: [1910/4518] 42% | Training loss: 0.6872570035033201
Epoch: 22 | Iteration number: [1920/4518] 42% | Training loss: 0.6872467511333525
Epoch: 22 | Iteration number: [1930/4518] 42% | Training loss: 0.6872442700084627
Epoch: 22 | Iteration number: [1940/4518] 42% | Training loss: 0.687241644373874
Epoch: 22 | Iteration number: [1950/4518] 43% | Training loss: 0.6872414401555673
Epoch: 22 | Iteration number: [1960/4518] 43% | Training loss: 0.6872349122349097
Epoch: 22 | Iteration number: [1970/4518] 43% | Training loss: 0.6872270787730435
Epoch: 22 | Iteration number: [1980/4518] 43% | Training loss: 0.6872209513729269
Epoch: 22 | Iteration number: [1990/4518] 44% | Training loss: 0.6872235642905211
Epoch: 22 | Iteration number: [2000/4518] 44% | Training loss: 0.687215662151575
Epoch: 22 | Iteration number: [2010/4518] 44% | Training loss: 0.68721814033997
Epoch: 22 | Iteration number: [2020/4518] 44% | Training loss: 0.687220635538054
Epoch: 22 | Iteration number: [2030/4518] 44% | Training loss: 0.6872166299173985
Epoch: 22 | Iteration number: [2040/4518] 45% | Training loss: 0.6872102555106668
Epoch: 22 | Iteration number: [2050/4518] 45% | Training loss: 0.6872104344716886
Epoch: 22 | Iteration number: [2060/4518] 45% | Training loss: 0.6872148567322388
Epoch: 22 | Iteration number: [2070/4518] 45% | Training loss: 0.6872091469845334
Epoch: 22 | Iteration number: [2080/4518] 46% | Training loss: 0.6872083361905355
Epoch: 22 | Iteration number: [2090/4518] 46% | Training loss: 0.6872114236560164
Epoch: 22 | Iteration number: [2100/4518] 46% | Training loss: 0.6872101111355282
Epoch: 22 | Iteration number: [2110/4518] 46% | Training loss: 0.6872010696555766
Epoch: 22 | Iteration number: [2120/4518] 46% | Training loss: 0.6872072007015066
Epoch: 22 | Iteration number: [2130/4518] 47% | Training loss: 0.6872027242687386
Epoch: 22 | Iteration number: [2140/4518] 47% | Training loss: 0.6872009652797307
Epoch: 22 | Iteration number: [2150/4518] 47% | Training loss: 0.6872001725851103
Epoch: 22 | Iteration number: [2160/4518] 47% | Training loss: 0.6871910683258816
Epoch: 22 | Iteration number: [2170/4518] 48% | Training loss: 0.6871887774786092
Epoch: 22 | Iteration number: [2180/4518] 48% | Training loss: 0.6871865123510361
Epoch: 22 | Iteration number: [2190/4518] 48% | Training loss: 0.6871847637984306
Epoch: 22 | Iteration number: [2200/4518] 48% | Training loss: 0.6871848090670326
Epoch: 22 | Iteration number: [2210/4518] 48% | Training loss: 0.6871923102782322
Epoch: 22 | Iteration number: [2220/4518] 49% | Training loss: 0.6871978871725701
Epoch: 22 | Iteration number: [2230/4518] 49% | Training loss: 0.6871985844967077
Epoch: 22 | Iteration number: [2240/4518] 49% | Training loss: 0.6871952614347849
Epoch: 22 | Iteration number: [2250/4518] 49% | Training loss: 0.6871892382038964
Epoch: 22 | Iteration number: [2260/4518] 50% | Training loss: 0.6871863242799202
Epoch: 22 | Iteration number: [2270/4518] 50% | Training loss: 0.6871822957950542
Epoch: 22 | Iteration number: [2280/4518] 50% | Training loss: 0.68718420933736
Epoch: 22 | Iteration number: [2290/4518] 50% | Training loss: 0.6871892373374456
Epoch: 22 | Iteration number: [2300/4518] 50% | Training loss: 0.6871852051175159
Epoch: 22 | Iteration number: [2310/4518] 51% | Training loss: 0.6871886010293836
Epoch: 22 | Iteration number: [2320/4518] 51% | Training loss: 0.6871840124757126
Epoch: 22 | Iteration number: [2330/4518] 51% | Training loss: 0.6871811671318414
Epoch: 22 | Iteration number: [2340/4518] 51% | Training loss: 0.6871860821787109
Epoch: 22 | Iteration number: [2350/4518] 52% | Training loss: 0.6871797357214258
Epoch: 22 | Iteration number: [2360/4518] 52% | Training loss: 0.6871789822133921
Epoch: 22 | Iteration number: [2370/4518] 52% | Training loss: 0.6871823486145036
Epoch: 22 | Iteration number: [2380/4518] 52% | Training loss: 0.6871815068631613
Epoch: 22 | Iteration number: [2390/4518] 52% | Training loss: 0.6871795039296649
Epoch: 22 | Iteration number: [2400/4518] 53% | Training loss: 0.687178677842021
Epoch: 22 | Iteration number: [2410/4518] 53% | Training loss: 0.6871808205650061
Epoch: 22 | Iteration number: [2420/4518] 53% | Training loss: 0.6871812346799314
Epoch: 22 | Iteration number: [2430/4518] 53% | Training loss: 0.6871817102402816
Epoch: 22 | Iteration number: [2440/4518] 54% | Training loss: 0.6871815435221937
Epoch: 22 | Iteration number: [2450/4518] 54% | Training loss: 0.6871801288517154
Epoch: 22 | Iteration number: [2460/4518] 54% | Training loss: 0.6871735315012738
Epoch: 22 | Iteration number: [2470/4518] 54% | Training loss: 0.6871734601524677
Epoch: 22 | Iteration number: [2480/4518] 54% | Training loss: 0.6871743904246438
Epoch: 22 | Iteration number: [2490/4518] 55% | Training loss: 0.6871739844481151
Epoch: 22 | Iteration number: [2500/4518] 55% | Training loss: 0.6871756026029586
Epoch: 22 | Iteration number: [2510/4518] 55% | Training loss: 0.6871797413465036
Epoch: 22 | Iteration number: [2520/4518] 55% | Training loss: 0.6871774504582088
Epoch: 22 | Iteration number: [2530/4518] 55% | Training loss: 0.6871745776753181
Epoch: 22 | Iteration number: [2540/4518] 56% | Training loss: 0.6871735649315391
Epoch: 22 | Iteration number: [2550/4518] 56% | Training loss: 0.6871700462173013
Epoch: 22 | Iteration number: [2560/4518] 56% | Training loss: 0.6871689082589001
Epoch: 22 | Iteration number: [2570/4518] 56% | Training loss: 0.6871664409275648
Epoch: 22 | Iteration number: [2580/4518] 57% | Training loss: 0.6871636788974437
Epoch: 22 | Iteration number: [2590/4518] 57% | Training loss: 0.6871620169707707
Epoch: 22 | Iteration number: [2600/4518] 57% | Training loss: 0.6871580404043197
Epoch: 22 | Iteration number: [2610/4518] 57% | Training loss: 0.6871578722164549
Epoch: 22 | Iteration number: [2620/4518] 57% | Training loss: 0.6871536798377074
Epoch: 22 | Iteration number: [2630/4518] 58% | Training loss: 0.6871538231581337
Epoch: 22 | Iteration number: [2640/4518] 58% | Training loss: 0.6871486652755376
Epoch: 22 | Iteration number: [2650/4518] 58% | Training loss: 0.687145654525397
Epoch: 22 | Iteration number: [2660/4518] 58% | Training loss: 0.6871422900965339
Epoch: 22 | Iteration number: [2670/4518] 59% | Training loss: 0.6871405420231909
Epoch: 22 | Iteration number: [2680/4518] 59% | Training loss: 0.6871382490467669
Epoch: 22 | Iteration number: [2690/4518] 59% | Training loss: 0.687134507531127
Epoch: 22 | Iteration number: [2700/4518] 59% | Training loss: 0.6871324646031415
Epoch: 22 | Iteration number: [2710/4518] 59% | Training loss: 0.6871329783293594
Epoch: 22 | Iteration number: [2720/4518] 60% | Training loss: 0.6871359083363239
Epoch: 22 | Iteration number: [2730/4518] 60% | Training loss: 0.6871328788144248
Epoch: 22 | Iteration number: [2740/4518] 60% | Training loss: 0.6871284393498497
Epoch: 22 | Iteration number: [2750/4518] 60% | Training loss: 0.6871313355185769
Epoch: 22 | Iteration number: [2760/4518] 61% | Training loss: 0.6871307192289311
Epoch: 22 | Iteration number: [2770/4518] 61% | Training loss: 0.68712701231564
Epoch: 22 | Iteration number: [2780/4518] 61% | Training loss: 0.6871224271736557
Epoch: 22 | Iteration number: [2790/4518] 61% | Training loss: 0.6871199785808508
Epoch: 22 | Iteration number: [2800/4518] 61% | Training loss: 0.687123271120446
Epoch: 22 | Iteration number: [2810/4518] 62% | Training loss: 0.6871187945277666
Epoch: 22 | Iteration number: [2820/4518] 62% | Training loss: 0.6871178734387067
Epoch: 22 | Iteration number: [2830/4518] 62% | Training loss: 0.6871119517951466
Epoch: 22 | Iteration number: [2840/4518] 62% | Training loss: 0.6871159105023867
Epoch: 22 | Iteration number: [2850/4518] 63% | Training loss: 0.6871153142996002
Epoch: 22 | Iteration number: [2860/4518] 63% | Training loss: 0.6871157742880442
Epoch: 22 | Iteration number: [2870/4518] 63% | Training loss: 0.687117167653107
Epoch: 22 | Iteration number: [2880/4518] 63% | Training loss: 0.6871150818136004
Epoch: 22 | Iteration number: [2890/4518] 63% | Training loss: 0.6871115190966319
Epoch: 22 | Iteration number: [2900/4518] 64% | Training loss: 0.6871119662194416
Epoch: 22 | Iteration number: [2910/4518] 64% | Training loss: 0.6871066801531618
Epoch: 22 | Iteration number: [2920/4518] 64% | Training loss: 0.6871067508851012
Epoch: 22 | Iteration number: [2930/4518] 64% | Training loss: 0.6871072664602624
Epoch: 22 | Iteration number: [2940/4518] 65% | Training loss: 0.6871093088469538
Epoch: 22 | Iteration number: [2950/4518] 65% | Training loss: 0.6871089896913302
Epoch: 22 | Iteration number: [2960/4518] 65% | Training loss: 0.6871099533462847
Epoch: 22 | Iteration number: [2970/4518] 65% | Training loss: 0.6871059913025159
Epoch: 22 | Iteration number: [2980/4518] 65% | Training loss: 0.6871038207271755
Epoch: 22 | Iteration number: [2990/4518] 66% | Training loss: 0.6871007573644453
Epoch: 22 | Iteration number: [3000/4518] 66% | Training loss: 0.6871049929261207
Epoch: 22 | Iteration number: [3010/4518] 66% | Training loss: 0.6871042778325636
Epoch: 22 | Iteration number: [3020/4518] 66% | Training loss: 0.687099344860639
Epoch: 22 | Iteration number: [3030/4518] 67% | Training loss: 0.687099533742017
Epoch: 22 | Iteration number: [3040/4518] 67% | Training loss: 0.6871013603320247
Epoch: 22 | Iteration number: [3050/4518] 67% | Training loss: 0.6870974637250431
Epoch: 22 | Iteration number: [3060/4518] 67% | Training loss: 0.6870964022828083
Epoch: 22 | Iteration number: [3070/4518] 67% | Training loss: 0.6870971865685056
Epoch: 22 | Iteration number: [3080/4518] 68% | Training loss: 0.6870978657881935
Epoch: 22 | Iteration number: [3090/4518] 68% | Training loss: 0.6870970077692112
Epoch: 22 | Iteration number: [3100/4518] 68% | Training loss: 0.6870946920687152
Epoch: 22 | Iteration number: [3110/4518] 68% | Training loss: 0.6870939834708186
Epoch: 22 | Iteration number: [3120/4518] 69% | Training loss: 0.687092695862819
Epoch: 22 | Iteration number: [3130/4518] 69% | Training loss: 0.6870912235194502
Epoch: 22 | Iteration number: [3140/4518] 69% | Training loss: 0.6870906343505641
Epoch: 22 | Iteration number: [3150/4518] 69% | Training loss: 0.6870906078626239
Epoch: 22 | Iteration number: [3160/4518] 69% | Training loss: 0.6870929417542264
Epoch: 22 | Iteration number: [3170/4518] 70% | Training loss: 0.6870916425617711
Epoch: 22 | Iteration number: [3180/4518] 70% | Training loss: 0.6870882975605299
Epoch: 22 | Iteration number: [3190/4518] 70% | Training loss: 0.6870911803551976
Epoch: 22 | Iteration number: [3200/4518] 70% | Training loss: 0.6870867620408535
Epoch: 22 | Iteration number: [3210/4518] 71% | Training loss: 0.6870824796388454
Epoch: 22 | Iteration number: [3220/4518] 71% | Training loss: 0.6870818222716728
Epoch: 22 | Iteration number: [3230/4518] 71% | Training loss: 0.6870829328294878
Epoch: 22 | Iteration number: [3240/4518] 71% | Training loss: 0.6870815788706144
Epoch: 22 | Iteration number: [3250/4518] 71% | Training loss: 0.6870803561027233
Epoch: 22 | Iteration number: [3260/4518] 72% | Training loss: 0.6870765099679034
Epoch: 22 | Iteration number: [3270/4518] 72% | Training loss: 0.687076611438658
Epoch: 22 | Iteration number: [3280/4518] 72% | Training loss: 0.6870770034993567
Epoch: 22 | Iteration number: [3290/4518] 72% | Training loss: 0.6870787431766197
Epoch: 22 | Iteration number: [3300/4518] 73% | Training loss: 0.6870757011211279
Epoch: 22 | Iteration number: [3310/4518] 73% | Training loss: 0.6870771347395963
Epoch: 22 | Iteration number: [3320/4518] 73% | Training loss: 0.6870764850133873
Epoch: 22 | Iteration number: [3330/4518] 73% | Training loss: 0.6870784668056098
Epoch: 22 | Iteration number: [3340/4518] 73% | Training loss: 0.6870813808576789
Epoch: 22 | Iteration number: [3350/4518] 74% | Training loss: 0.6870842695058281
Epoch: 22 | Iteration number: [3360/4518] 74% | Training loss: 0.6870827913639092
Epoch: 22 | Iteration number: [3370/4518] 74% | Training loss: 0.6870822014370022
Epoch: 22 | Iteration number: [3380/4518] 74% | Training loss: 0.6870801119938404
Epoch: 22 | Iteration number: [3390/4518] 75% | Training loss: 0.6870810397606684
Epoch: 22 | Iteration number: [3400/4518] 75% | Training loss: 0.6870810544315507
Epoch: 22 | Iteration number: [3410/4518] 75% | Training loss: 0.6870760159583386
Epoch: 22 | Iteration number: [3420/4518] 75% | Training loss: 0.6870731043188195
Epoch: 22 | Iteration number: [3430/4518] 75% | Training loss: 0.6870720604592092
Epoch: 22 | Iteration number: [3440/4518] 76% | Training loss: 0.6870707916658978
Epoch: 22 | Iteration number: [3450/4518] 76% | Training loss: 0.6870705682298411
Epoch: 22 | Iteration number: [3460/4518] 76% | Training loss: 0.6870706182856091
Epoch: 22 | Iteration number: [3470/4518] 76% | Training loss: 0.6870691076994629
Epoch: 22 | Iteration number: [3480/4518] 77% | Training loss: 0.6870637347985958
Epoch: 22 | Iteration number: [3490/4518] 77% | Training loss: 0.6870625434256556
Epoch: 22 | Iteration number: [3500/4518] 77% | Training loss: 0.6870630849770137
Epoch: 22 | Iteration number: [3510/4518] 77% | Training loss: 0.6870641855432776
Epoch: 22 | Iteration number: [3520/4518] 77% | Training loss: 0.687064442394132
Epoch: 22 | Iteration number: [3530/4518] 78% | Training loss: 0.6870641467591521
Epoch: 22 | Iteration number: [3540/4518] 78% | Training loss: 0.6870676107494171
Epoch: 22 | Iteration number: [3550/4518] 78% | Training loss: 0.6870650291778672
Epoch: 22 | Iteration number: [3560/4518] 78% | Training loss: 0.6870652823300843
Epoch: 22 | Iteration number: [3570/4518] 79% | Training loss: 0.6870692062277753
Epoch: 22 | Iteration number: [3580/4518] 79% | Training loss: 0.6870651178353325
Epoch: 22 | Iteration number: [3590/4518] 79% | Training loss: 0.6870645339110436
Epoch: 22 | Iteration number: [3600/4518] 79% | Training loss: 0.6870664666924212
Epoch: 22 | Iteration number: [3610/4518] 79% | Training loss: 0.6870664468597507
Epoch: 22 | Iteration number: [3620/4518] 80% | Training loss: 0.6870657229127146
Epoch: 22 | Iteration number: [3630/4518] 80% | Training loss: 0.6870680595889236
Epoch: 22 | Iteration number: [3640/4518] 80% | Training loss: 0.6870637783146166
Epoch: 22 | Iteration number: [3650/4518] 80% | Training loss: 0.6870643760570108
Epoch: 22 | Iteration number: [3660/4518] 81% | Training loss: 0.6870654103697323
Epoch: 22 | Iteration number: [3670/4518] 81% | Training loss: 0.6870635655010754
Epoch: 22 | Iteration number: [3680/4518] 81% | Training loss: 0.6870623379459847
Epoch: 22 | Iteration number: [3690/4518] 81% | Training loss: 0.6870652089920147
Epoch: 22 | Iteration number: [3700/4518] 81% | Training loss: 0.6870650355719231
Epoch: 22 | Iteration number: [3710/4518] 82% | Training loss: 0.6870662944336143
Epoch: 22 | Iteration number: [3720/4518] 82% | Training loss: 0.6870634235521799
Epoch: 22 | Iteration number: [3730/4518] 82% | Training loss: 0.6870619422468999
Epoch: 22 | Iteration number: [3740/4518] 82% | Training loss: 0.6870599224924404
Epoch: 22 | Iteration number: [3750/4518] 83% | Training loss: 0.6870572752157847
Epoch: 22 | Iteration number: [3760/4518] 83% | Training loss: 0.6870566688002424
Epoch: 22 | Iteration number: [3770/4518] 83% | Training loss: 0.6870588889488807
Epoch: 22 | Iteration number: [3780/4518] 83% | Training loss: 0.6870577143771308
Epoch: 22 | Iteration number: [3790/4518] 83% | Training loss: 0.6870582356459233
Epoch: 22 | Iteration number: [3800/4518] 84% | Training loss: 0.6870522730601462
Epoch: 22 | Iteration number: [3810/4518] 84% | Training loss: 0.6870518981628218
Epoch: 22 | Iteration number: [3820/4518] 84% | Training loss: 0.6870570633579923
Epoch: 22 | Iteration number: [3830/4518] 84% | Training loss: 0.6870553193297773
Epoch: 22 | Iteration number: [3840/4518] 84% | Training loss: 0.6870530751378586
Epoch: 22 | Iteration number: [3850/4518] 85% | Training loss: 0.6870526713210267
Epoch: 22 | Iteration number: [3860/4518] 85% | Training loss: 0.6870505578005253
Epoch: 22 | Iteration number: [3870/4518] 85% | Training loss: 0.6870471535727035
Epoch: 22 | Iteration number: [3880/4518] 85% | Training loss: 0.6870433868206653
Epoch: 22 | Iteration number: [3890/4518] 86% | Training loss: 0.6870407937118511
Epoch: 22 | Iteration number: [3900/4518] 86% | Training loss: 0.6870408574740092
Epoch: 22 | Iteration number: [3910/4518] 86% | Training loss: 0.6870404444234756
Epoch: 22 | Iteration number: [3920/4518] 86% | Training loss: 0.6870399699375338
Epoch: 22 | Iteration number: [3930/4518] 86% | Training loss: 0.687039347413842
Epoch: 22 | Iteration number: [3940/4518] 87% | Training loss: 0.6870377437263576
Epoch: 22 | Iteration number: [3950/4518] 87% | Training loss: 0.6870323502112039
Epoch: 22 | Iteration number: [3960/4518] 87% | Training loss: 0.6870319648222489
Epoch: 22 | Iteration number: [3970/4518] 87% | Training loss: 0.6870330763553792
Epoch: 22 | Iteration number: [3980/4518] 88% | Training loss: 0.6870338487714979
Epoch: 22 | Iteration number: [3990/4518] 88% | Training loss: 0.6870347289513227
Epoch: 22 | Iteration number: [4000/4518] 88% | Training loss: 0.6870363100469112
Epoch: 22 | Iteration number: [4010/4518] 88% | Training loss: 0.6870373531172698
Epoch: 22 | Iteration number: [4020/4518] 88% | Training loss: 0.6870377966717108
Epoch: 22 | Iteration number: [4030/4518] 89% | Training loss: 0.6870396350364827
Epoch: 22 | Iteration number: [4040/4518] 89% | Training loss: 0.687038901049902
Epoch: 22 | Iteration number: [4050/4518] 89% | Training loss: 0.6870372232390038
Epoch: 22 | Iteration number: [4060/4518] 89% | Training loss: 0.6870369762475854
Epoch: 22 | Iteration number: [4070/4518] 90% | Training loss: 0.6870370072726828
Epoch: 22 | Iteration number: [4080/4518] 90% | Training loss: 0.6870352978945947
Epoch: 22 | Iteration number: [4090/4518] 90% | Training loss: 0.6870382275587189
Epoch: 22 | Iteration number: [4100/4518] 90% | Training loss: 0.687039183509059
Epoch: 22 | Iteration number: [4110/4518] 90% | Training loss: 0.6870381110631056
Epoch: 22 | Iteration number: [4120/4518] 91% | Training loss: 0.6870415411238532
Epoch: 22 | Iteration number: [4130/4518] 91% | Training loss: 0.6870439140762025
Epoch: 22 | Iteration number: [4140/4518] 91% | Training loss: 0.6870463101472256
Epoch: 22 | Iteration number: [4150/4518] 91% | Training loss: 0.6870459311985108
Epoch: 22 | Iteration number: [4160/4518] 92% | Training loss: 0.6870481625056037
Epoch: 22 | Iteration number: [4170/4518] 92% | Training loss: 0.6870512039255467
Epoch: 22 | Iteration number: [4180/4518] 92% | Training loss: 0.6870511175200129
Epoch: 22 | Iteration number: [4190/4518] 92% | Training loss: 0.6870508746770799
Epoch: 22 | Iteration number: [4200/4518] 92% | Training loss: 0.6870528841160592
Epoch: 22 | Iteration number: [4210/4518] 93% | Training loss: 0.6870540999743264
Epoch: 22 | Iteration number: [4220/4518] 93% | Training loss: 0.6870547068910011
Epoch: 22 | Iteration number: [4230/4518] 93% | Training loss: 0.6870530850357479
Epoch: 22 | Iteration number: [4240/4518] 93% | Training loss: 0.6870524478689679
Epoch: 22 | Iteration number: [4250/4518] 94% | Training loss: 0.6870527349780587
Epoch: 22 | Iteration number: [4260/4518] 94% | Training loss: 0.6870520251737514
Epoch: 22 | Iteration number: [4270/4518] 94% | Training loss: 0.6870500497851495
Epoch: 22 | Iteration number: [4280/4518] 94% | Training loss: 0.6870514612888622
Epoch: 22 | Iteration number: [4290/4518] 94% | Training loss: 0.6870506968809452
Epoch: 22 | Iteration number: [4300/4518] 95% | Training loss: 0.6870506780507952
Epoch: 22 | Iteration number: [4310/4518] 95% | Training loss: 0.6870485855227557
Epoch: 22 | Iteration number: [4320/4518] 95% | Training loss: 0.6870451255804962
Epoch: 22 | Iteration number: [4330/4518] 95% | Training loss: 0.6870439785870338
Epoch: 22 | Iteration number: [4340/4518] 96% | Training loss: 0.6870430549168917
Epoch: 22 | Iteration number: [4350/4518] 96% | Training loss: 0.6870453970459686
Epoch: 22 | Iteration number: [4360/4518] 96% | Training loss: 0.6870455197648171
Epoch: 22 | Iteration number: [4370/4518] 96% | Training loss: 0.6870446143215799
Epoch: 22 | Iteration number: [4380/4518] 96% | Training loss: 0.6870432652294908
Epoch: 22 | Iteration number: [4390/4518] 97% | Training loss: 0.6870436886041202
Epoch: 22 | Iteration number: [4400/4518] 97% | Training loss: 0.6870397857237945
Epoch: 22 | Iteration number: [4410/4518] 97% | Training loss: 0.687039911855105
Epoch: 22 | Iteration number: [4420/4518] 97% | Training loss: 0.6870401410630386
Epoch: 22 | Iteration number: [4430/4518] 98% | Training loss: 0.687041817171579
Epoch: 22 | Iteration number: [4440/4518] 98% | Training loss: 0.6870451090840606
Epoch: 22 | Iteration number: [4450/4518] 98% | Training loss: 0.6870418807495846
Epoch: 22 | Iteration number: [4460/4518] 98% | Training loss: 0.6870423872107347
Epoch: 22 | Iteration number: [4470/4518] 98% | Training loss: 0.6870437213371797
Epoch: 22 | Iteration number: [4480/4518] 99% | Training loss: 0.6870459571746843
Epoch: 22 | Iteration number: [4490/4518] 99% | Training loss: 0.6870461467512466
Epoch: 22 | Iteration number: [4500/4518] 99% | Training loss: 0.6870464674896664
Epoch: 22 | Iteration number: [4510/4518] 99% | Training loss: 0.6870455126540359

 End of epoch: 22 | Train Loss: 0.6868911712451443 | Training Time: 641 

 End of epoch: 22 | Eval Loss: 0.6901344352838944 | Evaluating Time: 17 
Epoch: 23 | Iteration number: [10/4518] 0% | Training loss: 0.7560282528400422
Epoch: 23 | Iteration number: [20/4518] 0% | Training loss: 0.721596097946167
Epoch: 23 | Iteration number: [30/4518] 0% | Training loss: 0.7098677059014639
Epoch: 23 | Iteration number: [40/4518] 0% | Training loss: 0.7038419649004937
Epoch: 23 | Iteration number: [50/4518] 1% | Training loss: 0.7004119908809662
Epoch: 23 | Iteration number: [60/4518] 1% | Training loss: 0.6982189883788427
Epoch: 23 | Iteration number: [70/4518] 1% | Training loss: 0.6966566681861878
Epoch: 23 | Iteration number: [80/4518] 1% | Training loss: 0.6955308958888053
Epoch: 23 | Iteration number: [90/4518] 1% | Training loss: 0.694447433286243
Epoch: 23 | Iteration number: [100/4518] 2% | Training loss: 0.6937709349393845
Epoch: 23 | Iteration number: [110/4518] 2% | Training loss: 0.6931279014457356
Epoch: 23 | Iteration number: [120/4518] 2% | Training loss: 0.6926346510648728
Epoch: 23 | Iteration number: [130/4518] 2% | Training loss: 0.6921906425402715
Epoch: 23 | Iteration number: [140/4518] 3% | Training loss: 0.691897457412311
Epoch: 23 | Iteration number: [150/4518] 3% | Training loss: 0.6914880307515462
Epoch: 23 | Iteration number: [160/4518] 3% | Training loss: 0.6911991138011218
Epoch: 23 | Iteration number: [170/4518] 3% | Training loss: 0.6909843080184039
Epoch: 23 | Iteration number: [180/4518] 3% | Training loss: 0.6906879898574617
Epoch: 23 | Iteration number: [190/4518] 4% | Training loss: 0.6904999990212289
Epoch: 23 | Iteration number: [200/4518] 4% | Training loss: 0.6903490483760834
Epoch: 23 | Iteration number: [210/4518] 4% | Training loss: 0.6901862289224352
Epoch: 23 | Iteration number: [220/4518] 4% | Training loss: 0.6899758333509619
Epoch: 23 | Iteration number: [230/4518] 5% | Training loss: 0.6898717066516047
Epoch: 23 | Iteration number: [240/4518] 5% | Training loss: 0.6897854814926784
Epoch: 23 | Iteration number: [250/4518] 5% | Training loss: 0.6897082390785217
Epoch: 23 | Iteration number: [260/4518] 5% | Training loss: 0.6896347114673027
Epoch: 23 | Iteration number: [270/4518] 5% | Training loss: 0.6895345286086754
Epoch: 23 | Iteration number: [280/4518] 6% | Training loss: 0.6894214943051338
Epoch: 23 | Iteration number: [290/4518] 6% | Training loss: 0.6893637309814321
Epoch: 23 | Iteration number: [300/4518] 6% | Training loss: 0.6892750712235769
Epoch: 23 | Iteration number: [310/4518] 6% | Training loss: 0.6891960072901941
Epoch: 23 | Iteration number: [320/4518] 7% | Training loss: 0.6891197752207517
Epoch: 23 | Iteration number: [330/4518] 7% | Training loss: 0.6890356941656632
Epoch: 23 | Iteration number: [340/4518] 7% | Training loss: 0.6890159592908971
Epoch: 23 | Iteration number: [350/4518] 7% | Training loss: 0.6889569791725704
Epoch: 23 | Iteration number: [360/4518] 7% | Training loss: 0.6889144195450677
Epoch: 23 | Iteration number: [370/4518] 8% | Training loss: 0.6888031241056082
Epoch: 23 | Iteration number: [380/4518] 8% | Training loss: 0.6887230372742603
Epoch: 23 | Iteration number: [390/4518] 8% | Training loss: 0.6886723642165844
Epoch: 23 | Iteration number: [400/4518] 8% | Training loss: 0.6886461259424687
Epoch: 23 | Iteration number: [410/4518] 9% | Training loss: 0.688639285797026
Epoch: 23 | Iteration number: [420/4518] 9% | Training loss: 0.6885915290741693
Epoch: 23 | Iteration number: [430/4518] 9% | Training loss: 0.6885526894136916
Epoch: 23 | Iteration number: [440/4518] 9% | Training loss: 0.688527258282358
Epoch: 23 | Iteration number: [450/4518] 9% | Training loss: 0.6884640039338006
Epoch: 23 | Iteration number: [460/4518] 10% | Training loss: 0.6884049006130384
Epoch: 23 | Iteration number: [470/4518] 10% | Training loss: 0.6883428947722658
Epoch: 23 | Iteration number: [480/4518] 10% | Training loss: 0.6882792015870413
Epoch: 23 | Iteration number: [490/4518] 10% | Training loss: 0.6882490588694202
Epoch: 23 | Iteration number: [500/4518] 11% | Training loss: 0.6882192126512527
Epoch: 23 | Iteration number: [510/4518] 11% | Training loss: 0.6882094537510591
Epoch: 23 | Iteration number: [520/4518] 11% | Training loss: 0.6881604961477793
Epoch: 23 | Iteration number: [530/4518] 11% | Training loss: 0.6881335647601001
Epoch: 23 | Iteration number: [540/4518] 11% | Training loss: 0.6881279304071709
Epoch: 23 | Iteration number: [550/4518] 12% | Training loss: 0.688117285750129
Epoch: 23 | Iteration number: [560/4518] 12% | Training loss: 0.6881023445299693
Epoch: 23 | Iteration number: [570/4518] 12% | Training loss: 0.6880710212807907
Epoch: 23 | Iteration number: [580/4518] 12% | Training loss: 0.6880420748529763
Epoch: 23 | Iteration number: [590/4518] 13% | Training loss: 0.6880451321601868
Epoch: 23 | Iteration number: [600/4518] 13% | Training loss: 0.6880404100815455
Epoch: 23 | Iteration number: [610/4518] 13% | Training loss: 0.6880243035613514
Epoch: 23 | Iteration number: [620/4518] 13% | Training loss: 0.6880072282206627
Epoch: 23 | Iteration number: [630/4518] 13% | Training loss: 0.687985637736699
Epoch: 23 | Iteration number: [640/4518] 14% | Training loss: 0.6879788554273546
Epoch: 23 | Iteration number: [650/4518] 14% | Training loss: 0.6879445782991556
Epoch: 23 | Iteration number: [660/4518] 14% | Training loss: 0.6879344270987944
Epoch: 23 | Iteration number: [670/4518] 14% | Training loss: 0.6879194057699459
Epoch: 23 | Iteration number: [680/4518] 15% | Training loss: 0.6879038697656463
Epoch: 23 | Iteration number: [690/4518] 15% | Training loss: 0.6879100610380587
Epoch: 23 | Iteration number: [700/4518] 15% | Training loss: 0.6879222201449531
Epoch: 23 | Iteration number: [710/4518] 15% | Training loss: 0.6879109176111893
Epoch: 23 | Iteration number: [720/4518] 15% | Training loss: 0.687911004324754
Epoch: 23 | Iteration number: [730/4518] 16% | Training loss: 0.6879041767283661
Epoch: 23 | Iteration number: [740/4518] 16% | Training loss: 0.6878882408947558
Epoch: 23 | Iteration number: [750/4518] 16% | Training loss: 0.6878823835055033
Epoch: 23 | Iteration number: [760/4518] 16% | Training loss: 0.6878646267872107
Epoch: 23 | Iteration number: [770/4518] 17% | Training loss: 0.6878591697711449
Epoch: 23 | Iteration number: [780/4518] 17% | Training loss: 0.6878554654427064
Epoch: 23 | Iteration number: [790/4518] 17% | Training loss: 0.6878517510015754
Epoch: 23 | Iteration number: [800/4518] 17% | Training loss: 0.6878529196977615
Epoch: 23 | Iteration number: [810/4518] 17% | Training loss: 0.6878471870481232
Epoch: 23 | Iteration number: [820/4518] 18% | Training loss: 0.687844678904952
Epoch: 23 | Iteration number: [830/4518] 18% | Training loss: 0.6878353052110557
Epoch: 23 | Iteration number: [840/4518] 18% | Training loss: 0.6878233257503736
Epoch: 23 | Iteration number: [850/4518] 18% | Training loss: 0.68779658184332
Epoch: 23 | Iteration number: [860/4518] 19% | Training loss: 0.6877716329901717
Epoch: 23 | Iteration number: [870/4518] 19% | Training loss: 0.6877565903910275
Epoch: 23 | Iteration number: [880/4518] 19% | Training loss: 0.687751837007024
Epoch: 23 | Iteration number: [890/4518] 19% | Training loss: 0.6877582713459315
Epoch: 23 | Iteration number: [900/4518] 19% | Training loss: 0.6877434310648176
Epoch: 23 | Iteration number: [910/4518] 20% | Training loss: 0.6877333121640342
Epoch: 23 | Iteration number: [920/4518] 20% | Training loss: 0.6877065615809482
Epoch: 23 | Iteration number: [930/4518] 20% | Training loss: 0.6876990109361628
Epoch: 23 | Iteration number: [940/4518] 20% | Training loss: 0.6876885561866963
Epoch: 23 | Iteration number: [950/4518] 21% | Training loss: 0.6876759786982285
Epoch: 23 | Iteration number: [960/4518] 21% | Training loss: 0.6876673687870304
Epoch: 23 | Iteration number: [970/4518] 21% | Training loss: 0.6876616258596636
Epoch: 23 | Iteration number: [980/4518] 21% | Training loss: 0.687637110632293
Epoch: 23 | Iteration number: [990/4518] 21% | Training loss: 0.6876372061594568
Epoch: 23 | Iteration number: [1000/4518] 22% | Training loss: 0.687628232061863
Epoch: 23 | Iteration number: [1010/4518] 22% | Training loss: 0.6876220037441443
Epoch: 23 | Iteration number: [1020/4518] 22% | Training loss: 0.6876166547045989
Epoch: 23 | Iteration number: [1030/4518] 22% | Training loss: 0.6876139326002991
Epoch: 23 | Iteration number: [1040/4518] 23% | Training loss: 0.6876079033200557
Epoch: 23 | Iteration number: [1050/4518] 23% | Training loss: 0.687609087228775
Epoch: 23 | Iteration number: [1060/4518] 23% | Training loss: 0.6876011580791114
Epoch: 23 | Iteration number: [1070/4518] 23% | Training loss: 0.6875967610105176
Epoch: 23 | Iteration number: [1080/4518] 23% | Training loss: 0.6875885779658953
Epoch: 23 | Iteration number: [1090/4518] 24% | Training loss: 0.6875880752681592
Epoch: 23 | Iteration number: [1100/4518] 24% | Training loss: 0.6875919433615424
Epoch: 23 | Iteration number: [1110/4518] 24% | Training loss: 0.6875978307681041
Epoch: 23 | Iteration number: [1120/4518] 24% | Training loss: 0.6875903789486204
Epoch: 23 | Iteration number: [1130/4518] 25% | Training loss: 0.6875898941955735
Epoch: 23 | Iteration number: [1140/4518] 25% | Training loss: 0.6875813556344885
Epoch: 23 | Iteration number: [1150/4518] 25% | Training loss: 0.687578906805619
Epoch: 23 | Iteration number: [1160/4518] 25% | Training loss: 0.687565481457217
Epoch: 23 | Iteration number: [1170/4518] 25% | Training loss: 0.687559831295258
Epoch: 23 | Iteration number: [1180/4518] 26% | Training loss: 0.6875472159203836
Epoch: 23 | Iteration number: [1190/4518] 26% | Training loss: 0.6875392662877796
Epoch: 23 | Iteration number: [1200/4518] 26% | Training loss: 0.6875171925624212
Epoch: 23 | Iteration number: [1210/4518] 26% | Training loss: 0.6875177819374179
Epoch: 23 | Iteration number: [1220/4518] 27% | Training loss: 0.6875230379280497
Epoch: 23 | Iteration number: [1230/4518] 27% | Training loss: 0.6875114743787099
Epoch: 23 | Iteration number: [1240/4518] 27% | Training loss: 0.6875155695023075
Epoch: 23 | Iteration number: [1250/4518] 27% | Training loss: 0.687508836889267
Epoch: 23 | Iteration number: [1260/4518] 27% | Training loss: 0.6875109595911844
Epoch: 23 | Iteration number: [1270/4518] 28% | Training loss: 0.6875144951925503
Epoch: 23 | Iteration number: [1280/4518] 28% | Training loss: 0.6875019371509552
Epoch: 23 | Iteration number: [1290/4518] 28% | Training loss: 0.6875069730503615
Epoch: 23 | Iteration number: [1300/4518] 28% | Training loss: 0.6875098960216228
Epoch: 23 | Iteration number: [1310/4518] 28% | Training loss: 0.6875159985691537
Epoch: 23 | Iteration number: [1320/4518] 29% | Training loss: 0.6875087384924744
Epoch: 23 | Iteration number: [1330/4518] 29% | Training loss: 0.6875089349155139
Epoch: 23 | Iteration number: [1340/4518] 29% | Training loss: 0.6875094333691384
Epoch: 23 | Iteration number: [1350/4518] 29% | Training loss: 0.6875062822412561
Epoch: 23 | Iteration number: [1360/4518] 30% | Training loss: 0.6874974781099488
Epoch: 23 | Iteration number: [1370/4518] 30% | Training loss: 0.6874936291771213
Epoch: 23 | Iteration number: [1380/4518] 30% | Training loss: 0.6874883297992789
Epoch: 23 | Iteration number: [1390/4518] 30% | Training loss: 0.68747955882292
Epoch: 23 | Iteration number: [1400/4518] 30% | Training loss: 0.6874757707970482
Epoch: 23 | Iteration number: [1410/4518] 31% | Training loss: 0.6874652493507304
Epoch: 23 | Iteration number: [1420/4518] 31% | Training loss: 0.687461271798107
Epoch: 23 | Iteration number: [1430/4518] 31% | Training loss: 0.6874470628641702
Epoch: 23 | Iteration number: [1440/4518] 31% | Training loss: 0.6874418418854475
Epoch: 23 | Iteration number: [1450/4518] 32% | Training loss: 0.6874346290374624
Epoch: 23 | Iteration number: [1460/4518] 32% | Training loss: 0.6874340924089902
Epoch: 23 | Iteration number: [1470/4518] 32% | Training loss: 0.6874372557312453
Epoch: 23 | Iteration number: [1480/4518] 32% | Training loss: 0.6874349565522091
Epoch: 23 | Iteration number: [1490/4518] 32% | Training loss: 0.6874318111262866
Epoch: 23 | Iteration number: [1500/4518] 33% | Training loss: 0.6874302091995875
Epoch: 23 | Iteration number: [1510/4518] 33% | Training loss: 0.6874293229832554
Epoch: 23 | Iteration number: [1520/4518] 33% | Training loss: 0.6874240197633442
Epoch: 23 | Iteration number: [1530/4518] 33% | Training loss: 0.6874218186132269
Epoch: 23 | Iteration number: [1540/4518] 34% | Training loss: 0.6874190639365804
Epoch: 23 | Iteration number: [1550/4518] 34% | Training loss: 0.6874143614307526
Epoch: 23 | Iteration number: [1560/4518] 34% | Training loss: 0.6874093373234456
Epoch: 23 | Iteration number: [1570/4518] 34% | Training loss: 0.6874073078677913
Epoch: 23 | Iteration number: [1580/4518] 34% | Training loss: 0.6874102884455572
Epoch: 23 | Iteration number: [1590/4518] 35% | Training loss: 0.6874150406264659
Epoch: 23 | Iteration number: [1600/4518] 35% | Training loss: 0.6874211324378848
Epoch: 23 | Iteration number: [1610/4518] 35% | Training loss: 0.687411214883283
Epoch: 23 | Iteration number: [1620/4518] 35% | Training loss: 0.6874064963540913
Epoch: 23 | Iteration number: [1630/4518] 36% | Training loss: 0.6874079125790509
Epoch: 23 | Iteration number: [1640/4518] 36% | Training loss: 0.6874023722075835
Epoch: 23 | Iteration number: [1650/4518] 36% | Training loss: 0.6873950237577612
Epoch: 23 | Iteration number: [1660/4518] 36% | Training loss: 0.687399383697165
Epoch: 23 | Iteration number: [1670/4518] 36% | Training loss: 0.6873980900127731
Epoch: 23 | Iteration number: [1680/4518] 37% | Training loss: 0.6873947685318333
Epoch: 23 | Iteration number: [1690/4518] 37% | Training loss: 0.6873987020120113
Epoch: 23 | Iteration number: [1700/4518] 37% | Training loss: 0.6873978466496748
Epoch: 23 | Iteration number: [1710/4518] 37% | Training loss: 0.6873920166004471
Epoch: 23 | Iteration number: [1720/4518] 38% | Training loss: 0.6873923602838848
Epoch: 23 | Iteration number: [1730/4518] 38% | Training loss: 0.687385695965993
Epoch: 23 | Iteration number: [1740/4518] 38% | Training loss: 0.6873787436677121
Epoch: 23 | Iteration number: [1750/4518] 38% | Training loss: 0.6873778500216348
Epoch: 23 | Iteration number: [1760/4518] 38% | Training loss: 0.6873766635967926
Epoch: 23 | Iteration number: [1770/4518] 39% | Training loss: 0.687381377698338
Epoch: 23 | Iteration number: [1780/4518] 39% | Training loss: 0.6873694754718395
Epoch: 23 | Iteration number: [1790/4518] 39% | Training loss: 0.6873628913357271
Epoch: 23 | Iteration number: [1800/4518] 39% | Training loss: 0.6873629973663224
Epoch: 23 | Iteration number: [1810/4518] 40% | Training loss: 0.6873543274666064
Epoch: 23 | Iteration number: [1820/4518] 40% | Training loss: 0.6873435723585087
Epoch: 23 | Iteration number: [1830/4518] 40% | Training loss: 0.6873459150556658
Epoch: 23 | Iteration number: [1840/4518] 40% | Training loss: 0.6873398312407991
Epoch: 23 | Iteration number: [1850/4518] 40% | Training loss: 0.6873292471911456
Epoch: 23 | Iteration number: [1860/4518] 41% | Training loss: 0.6873249447794371
Epoch: 23 | Iteration number: [1870/4518] 41% | Training loss: 0.6873280335875118
Epoch: 23 | Iteration number: [1880/4518] 41% | Training loss: 0.6873265918264998
Epoch: 23 | Iteration number: [1890/4518] 41% | Training loss: 0.6873228893393561
Epoch: 23 | Iteration number: [1900/4518] 42% | Training loss: 0.687318642547256
Epoch: 23 | Iteration number: [1910/4518] 42% | Training loss: 0.6873189582250505
Epoch: 23 | Iteration number: [1920/4518] 42% | Training loss: 0.687317132546256
Epoch: 23 | Iteration number: [1930/4518] 42% | Training loss: 0.6873142530881061
Epoch: 23 | Iteration number: [1940/4518] 42% | Training loss: 0.6873176906526703
Epoch: 23 | Iteration number: [1950/4518] 43% | Training loss: 0.6873123483780103
Epoch: 23 | Iteration number: [1960/4518] 43% | Training loss: 0.6873126196313878
Epoch: 23 | Iteration number: [1970/4518] 43% | Training loss: 0.6873115301434763
Epoch: 23 | Iteration number: [1980/4518] 43% | Training loss: 0.6873104283303926
Epoch: 23 | Iteration number: [1990/4518] 44% | Training loss: 0.6873174988744247
Epoch: 23 | Iteration number: [2000/4518] 44% | Training loss: 0.6873171999156475
Epoch: 23 | Iteration number: [2010/4518] 44% | Training loss: 0.6873146504312012
Epoch: 23 | Iteration number: [2020/4518] 44% | Training loss: 0.6873092413538754
Epoch: 23 | Iteration number: [2030/4518] 44% | Training loss: 0.687301625935315
Epoch: 23 | Iteration number: [2040/4518] 45% | Training loss: 0.6872967126322728
Epoch: 23 | Iteration number: [2050/4518] 45% | Training loss: 0.6872915151351836
Epoch: 23 | Iteration number: [2060/4518] 45% | Training loss: 0.6872860555509919
Epoch: 23 | Iteration number: [2070/4518] 45% | Training loss: 0.6872852949992471
Epoch: 23 | Iteration number: [2080/4518] 46% | Training loss: 0.687285750101392
Epoch: 23 | Iteration number: [2090/4518] 46% | Training loss: 0.687284419468145
Epoch: 23 | Iteration number: [2100/4518] 46% | Training loss: 0.6872862286794753
Epoch: 23 | Iteration number: [2110/4518] 46% | Training loss: 0.6872817652485382
Epoch: 23 | Iteration number: [2120/4518] 46% | Training loss: 0.6872804440136225
Epoch: 23 | Iteration number: [2130/4518] 47% | Training loss: 0.6872737793855264
Epoch: 23 | Iteration number: [2140/4518] 47% | Training loss: 0.687267816289563
Epoch: 23 | Iteration number: [2150/4518] 47% | Training loss: 0.6872547538613164
Epoch: 23 | Iteration number: [2160/4518] 47% | Training loss: 0.6872550095121066
Epoch: 23 | Iteration number: [2170/4518] 48% | Training loss: 0.6872505659606599
Epoch: 23 | Iteration number: [2180/4518] 48% | Training loss: 0.68724530875136
Epoch: 23 | Iteration number: [2190/4518] 48% | Training loss: 0.6872353592964068
Epoch: 23 | Iteration number: [2200/4518] 48% | Training loss: 0.6872336428544739
Epoch: 23 | Iteration number: [2210/4518] 48% | Training loss: 0.6872367848637956
Epoch: 23 | Iteration number: [2220/4518] 49% | Training loss: 0.6872341910192559
Epoch: 23 | Iteration number: [2230/4518] 49% | Training loss: 0.6872293866268723
Epoch: 23 | Iteration number: [2240/4518] 49% | Training loss: 0.6872297705550279
Epoch: 23 | Iteration number: [2250/4518] 49% | Training loss: 0.6872306946118673
Epoch: 23 | Iteration number: [2260/4518] 50% | Training loss: 0.6872321707748734
Epoch: 23 | Iteration number: [2270/4518] 50% | Training loss: 0.6872343851606226
Epoch: 23 | Iteration number: [2280/4518] 50% | Training loss: 0.6872378383289304
Epoch: 23 | Iteration number: [2290/4518] 50% | Training loss: 0.6872371511688399
Epoch: 23 | Iteration number: [2300/4518] 50% | Training loss: 0.6872376539396203
Epoch: 23 | Iteration number: [2310/4518] 51% | Training loss: 0.6872410586127987
Epoch: 23 | Iteration number: [2320/4518] 51% | Training loss: 0.6872352585196495
Epoch: 23 | Iteration number: [2330/4518] 51% | Training loss: 0.6872339089796778
Epoch: 23 | Iteration number: [2340/4518] 51% | Training loss: 0.6872360241718781
Epoch: 23 | Iteration number: [2350/4518] 52% | Training loss: 0.6872327023617765
Epoch: 23 | Iteration number: [2360/4518] 52% | Training loss: 0.6872247536303633
Epoch: 23 | Iteration number: [2370/4518] 52% | Training loss: 0.6872217005063713
Epoch: 23 | Iteration number: [2380/4518] 52% | Training loss: 0.6872236943295023
Epoch: 23 | Iteration number: [2390/4518] 52% | Training loss: 0.687216497789367
Epoch: 23 | Iteration number: [2400/4518] 53% | Training loss: 0.6872147927433252
Epoch: 23 | Iteration number: [2410/4518] 53% | Training loss: 0.6872147042721634
Epoch: 23 | Iteration number: [2420/4518] 53% | Training loss: 0.6872152637844243
Epoch: 23 | Iteration number: [2430/4518] 53% | Training loss: 0.6872131755322586
Epoch: 23 | Iteration number: [2440/4518] 54% | Training loss: 0.687211377503442
Epoch: 23 | Iteration number: [2450/4518] 54% | Training loss: 0.6872089497653805
Epoch: 23 | Iteration number: [2460/4518] 54% | Training loss: 0.6872027032501329
Epoch: 23 | Iteration number: [2470/4518] 54% | Training loss: 0.687202672099295
Epoch: 23 | Iteration number: [2480/4518] 54% | Training loss: 0.6872019986952504
Epoch: 23 | Iteration number: [2490/4518] 55% | Training loss: 0.6871968489334765
Epoch: 23 | Iteration number: [2500/4518] 55% | Training loss: 0.687197030043602
Epoch: 23 | Iteration number: [2510/4518] 55% | Training loss: 0.6871954200039821
Epoch: 23 | Iteration number: [2520/4518] 55% | Training loss: 0.6871964759296841
Epoch: 23 | Iteration number: [2530/4518] 55% | Training loss: 0.6871975643125918
Epoch: 23 | Iteration number: [2540/4518] 56% | Training loss: 0.6871971189741074
Epoch: 23 | Iteration number: [2550/4518] 56% | Training loss: 0.6871933929592955
Epoch: 23 | Iteration number: [2560/4518] 56% | Training loss: 0.6871883721556514
Epoch: 23 | Iteration number: [2570/4518] 56% | Training loss: 0.6871870167988283
Epoch: 23 | Iteration number: [2580/4518] 57% | Training loss: 0.6871876925230026
Epoch: 23 | Iteration number: [2590/4518] 57% | Training loss: 0.6871828888373945
Epoch: 23 | Iteration number: [2600/4518] 57% | Training loss: 0.687178799372453
Epoch: 23 | Iteration number: [2610/4518] 57% | Training loss: 0.687175203945445
Epoch: 23 | Iteration number: [2620/4518] 57% | Training loss: 0.6871706119930471
Epoch: 23 | Iteration number: [2630/4518] 58% | Training loss: 0.6871712979481701
Epoch: 23 | Iteration number: [2640/4518] 58% | Training loss: 0.6871656993121812
Epoch: 23 | Iteration number: [2650/4518] 58% | Training loss: 0.6871680068070034
Epoch: 23 | Iteration number: [2660/4518] 58% | Training loss: 0.6871684318646453
Epoch: 23 | Iteration number: [2670/4518] 59% | Training loss: 0.6871671509653442
Epoch: 23 | Iteration number: [2680/4518] 59% | Training loss: 0.6871631411029332
Epoch: 23 | Iteration number: [2690/4518] 59% | Training loss: 0.6871656158378133
Epoch: 23 | Iteration number: [2700/4518] 59% | Training loss: 0.6871605502896839
Epoch: 23 | Iteration number: [2710/4518] 59% | Training loss: 0.6871564130061667
Epoch: 23 | Iteration number: [2720/4518] 60% | Training loss: 0.6871605707222924
Epoch: 23 | Iteration number: [2730/4518] 60% | Training loss: 0.687162734584494
Epoch: 23 | Iteration number: [2740/4518] 60% | Training loss: 0.6871641917167789
Epoch: 23 | Iteration number: [2750/4518] 60% | Training loss: 0.6871604259664362
Epoch: 23 | Iteration number: [2760/4518] 61% | Training loss: 0.6871581237385238
Epoch: 23 | Iteration number: [2770/4518] 61% | Training loss: 0.6871600960566249
Epoch: 23 | Iteration number: [2780/4518] 61% | Training loss: 0.6871556909178659
Epoch: 23 | Iteration number: [2790/4518] 61% | Training loss: 0.6871565280635724
Epoch: 23 | Iteration number: [2800/4518] 61% | Training loss: 0.6871540480639253
Epoch: 23 | Iteration number: [2810/4518] 62% | Training loss: 0.6871524898607112
Epoch: 23 | Iteration number: [2820/4518] 62% | Training loss: 0.687149056834532
Epoch: 23 | Iteration number: [2830/4518] 62% | Training loss: 0.6871486124849151
Epoch: 23 | Iteration number: [2840/4518] 62% | Training loss: 0.6871502885726136
Epoch: 23 | Iteration number: [2850/4518] 63% | Training loss: 0.6871540251949377
Epoch: 23 | Iteration number: [2860/4518] 63% | Training loss: 0.6871494532465101
Epoch: 23 | Iteration number: [2870/4518] 63% | Training loss: 0.6871496916855669
Epoch: 23 | Iteration number: [2880/4518] 63% | Training loss: 0.687142775600983
Epoch: 23 | Iteration number: [2890/4518] 63% | Training loss: 0.6871416958145616
Epoch: 23 | Iteration number: [2900/4518] 64% | Training loss: 0.6871394271891692
Epoch: 23 | Iteration number: [2910/4518] 64% | Training loss: 0.6871395749324786
Epoch: 23 | Iteration number: [2920/4518] 64% | Training loss: 0.6871404323879987
Epoch: 23 | Iteration number: [2930/4518] 64% | Training loss: 0.6871358835046202
Epoch: 23 | Iteration number: [2940/4518] 65% | Training loss: 0.6871358771510676
Epoch: 23 | Iteration number: [2950/4518] 65% | Training loss: 0.6871322791455156
Epoch: 23 | Iteration number: [2960/4518] 65% | Training loss: 0.6871318592614418
Epoch: 23 | Iteration number: [2970/4518] 65% | Training loss: 0.6871300804494608
Epoch: 23 | Iteration number: [2980/4518] 65% | Training loss: 0.6871273768428188
Epoch: 23 | Iteration number: [2990/4518] 66% | Training loss: 0.6871288889825942
Epoch: 23 | Iteration number: [3000/4518] 66% | Training loss: 0.6871259522438049
Epoch: 23 | Iteration number: [3010/4518] 66% | Training loss: 0.6871224993289111
Epoch: 23 | Iteration number: [3020/4518] 66% | Training loss: 0.6871224963901849
Epoch: 23 | Iteration number: [3030/4518] 67% | Training loss: 0.6871219057847958
Epoch: 23 | Iteration number: [3040/4518] 67% | Training loss: 0.6871220016361852
Epoch: 23 | Iteration number: [3050/4518] 67% | Training loss: 0.6871252797666143
Epoch: 23 | Iteration number: [3060/4518] 67% | Training loss: 0.6871244930169161
Epoch: 23 | Iteration number: [3070/4518] 67% | Training loss: 0.6871255589230442
Epoch: 23 | Iteration number: [3080/4518] 68% | Training loss: 0.6871264986403577
Epoch: 23 | Iteration number: [3090/4518] 68% | Training loss: 0.6871271310114938
Epoch: 23 | Iteration number: [3100/4518] 68% | Training loss: 0.687127959228331
Epoch: 23 | Iteration number: [3110/4518] 68% | Training loss: 0.68712108717854
Epoch: 23 | Iteration number: [3120/4518] 69% | Training loss: 0.687119124046503
Epoch: 23 | Iteration number: [3130/4518] 69% | Training loss: 0.6871194101751041
Epoch: 23 | Iteration number: [3140/4518] 69% | Training loss: 0.6871198535345162
Epoch: 23 | Iteration number: [3150/4518] 69% | Training loss: 0.6871183440231141
Epoch: 23 | Iteration number: [3160/4518] 69% | Training loss: 0.6871193703216842
Epoch: 23 | Iteration number: [3170/4518] 70% | Training loss: 0.6871190165119593
Epoch: 23 | Iteration number: [3180/4518] 70% | Training loss: 0.6871181589814852
Epoch: 23 | Iteration number: [3190/4518] 70% | Training loss: 0.6871208030041482
Epoch: 23 | Iteration number: [3200/4518] 70% | Training loss: 0.6871226479113102
Epoch: 23 | Iteration number: [3210/4518] 71% | Training loss: 0.6871241725865183
Epoch: 23 | Iteration number: [3220/4518] 71% | Training loss: 0.6871246161112874
Epoch: 23 | Iteration number: [3230/4518] 71% | Training loss: 0.6871218096361071
Epoch: 23 | Iteration number: [3240/4518] 71% | Training loss: 0.687118911853543
Epoch: 23 | Iteration number: [3250/4518] 71% | Training loss: 0.6871191073380983
Epoch: 23 | Iteration number: [3260/4518] 72% | Training loss: 0.6871151575830086
Epoch: 23 | Iteration number: [3270/4518] 72% | Training loss: 0.6871186298332448
Epoch: 23 | Iteration number: [3280/4518] 72% | Training loss: 0.6871177282093501
Epoch: 23 | Iteration number: [3290/4518] 72% | Training loss: 0.6871187883851013
Epoch: 23 | Iteration number: [3300/4518] 73% | Training loss: 0.6871190786181074
Epoch: 23 | Iteration number: [3310/4518] 73% | Training loss: 0.687116600829669
Epoch: 23 | Iteration number: [3320/4518] 73% | Training loss: 0.6871162072003606
Epoch: 23 | Iteration number: [3330/4518] 73% | Training loss: 0.6871122489641378
Epoch: 23 | Iteration number: [3340/4518] 73% | Training loss: 0.6871150293928421
Epoch: 23 | Iteration number: [3350/4518] 74% | Training loss: 0.6871141671066854
Epoch: 23 | Iteration number: [3360/4518] 74% | Training loss: 0.6871146694712695
Epoch: 23 | Iteration number: [3370/4518] 74% | Training loss: 0.6871139283526899
Epoch: 23 | Iteration number: [3380/4518] 74% | Training loss: 0.6871114081884983
Epoch: 23 | Iteration number: [3390/4518] 75% | Training loss: 0.6871073067012438
Epoch: 23 | Iteration number: [3400/4518] 75% | Training loss: 0.6871050886546864
Epoch: 23 | Iteration number: [3410/4518] 75% | Training loss: 0.6871005284471595
Epoch: 23 | Iteration number: [3420/4518] 75% | Training loss: 0.6870975920505691
Epoch: 23 | Iteration number: [3430/4518] 75% | Training loss: 0.6870973167544551
Epoch: 23 | Iteration number: [3440/4518] 76% | Training loss: 0.6870983664726102
Epoch: 23 | Iteration number: [3450/4518] 76% | Training loss: 0.6870936287486035
Epoch: 23 | Iteration number: [3460/4518] 76% | Training loss: 0.6870977105605119
Epoch: 23 | Iteration number: [3470/4518] 76% | Training loss: 0.6870958017169226
Epoch: 23 | Iteration number: [3480/4518] 77% | Training loss: 0.6870975826320977
Epoch: 23 | Iteration number: [3490/4518] 77% | Training loss: 0.6870962427304604
Epoch: 23 | Iteration number: [3500/4518] 77% | Training loss: 0.6870928690263203
Epoch: 23 | Iteration number: [3510/4518] 77% | Training loss: 0.6870918920576742
Epoch: 23 | Iteration number: [3520/4518] 77% | Training loss: 0.6870896751738408
Epoch: 23 | Iteration number: [3530/4518] 78% | Training loss: 0.6870932307189315
Epoch: 23 | Iteration number: [3540/4518] 78% | Training loss: 0.6870916496057294
Epoch: 23 | Iteration number: [3550/4518] 78% | Training loss: 0.687093497649045
Epoch: 23 | Iteration number: [3560/4518] 78% | Training loss: 0.6870901223313942
Epoch: 23 | Iteration number: [3570/4518] 79% | Training loss: 0.6870908065837305
Epoch: 23 | Iteration number: [3580/4518] 79% | Training loss: 0.6870872732147825
Epoch: 23 | Iteration number: [3590/4518] 79% | Training loss: 0.6870830899659638
Epoch: 23 | Iteration number: [3600/4518] 79% | Training loss: 0.6870809105204211
Epoch: 23 | Iteration number: [3610/4518] 79% | Training loss: 0.6870794831715793
Epoch: 23 | Iteration number: [3620/4518] 80% | Training loss: 0.6870789387772755
Epoch: 23 | Iteration number: [3630/4518] 80% | Training loss: 0.6870803155682303
Epoch: 23 | Iteration number: [3640/4518] 80% | Training loss: 0.6870813209113183
Epoch: 23 | Iteration number: [3650/4518] 80% | Training loss: 0.6870795176290486
Epoch: 23 | Iteration number: [3660/4518] 81% | Training loss: 0.6870789988607656
Epoch: 23 | Iteration number: [3670/4518] 81% | Training loss: 0.6870780444437542
Epoch: 23 | Iteration number: [3680/4518] 81% | Training loss: 0.6870807194191476
Epoch: 23 | Iteration number: [3690/4518] 81% | Training loss: 0.6870799858395646
Epoch: 23 | Iteration number: [3700/4518] 81% | Training loss: 0.6870820699511347
Epoch: 23 | Iteration number: [3710/4518] 82% | Training loss: 0.6870868001665388
Epoch: 23 | Iteration number: [3720/4518] 82% | Training loss: 0.6870817711917303
Epoch: 23 | Iteration number: [3730/4518] 82% | Training loss: 0.687079151562008
Epoch: 23 | Iteration number: [3740/4518] 82% | Training loss: 0.6870791642582991
Epoch: 23 | Iteration number: [3750/4518] 83% | Training loss: 0.6870788119633993
Epoch: 23 | Iteration number: [3760/4518] 83% | Training loss: 0.6870756583327943
Epoch: 23 | Iteration number: [3770/4518] 83% | Training loss: 0.687072807850825
Epoch: 23 | Iteration number: [3780/4518] 83% | Training loss: 0.6870708409598265
Epoch: 23 | Iteration number: [3790/4518] 83% | Training loss: 0.6870712662749681
Epoch: 23 | Iteration number: [3800/4518] 84% | Training loss: 0.6870715106788434
Epoch: 23 | Iteration number: [3810/4518] 84% | Training loss: 0.6870701417209595
Epoch: 23 | Iteration number: [3820/4518] 84% | Training loss: 0.6870689801988802
Epoch: 23 | Iteration number: [3830/4518] 84% | Training loss: 0.6870699225922478
Epoch: 23 | Iteration number: [3840/4518] 84% | Training loss: 0.6870668107954164
Epoch: 23 | Iteration number: [3850/4518] 85% | Training loss: 0.687066855771201
Epoch: 23 | Iteration number: [3860/4518] 85% | Training loss: 0.6870635292536237
Epoch: 23 | Iteration number: [3870/4518] 85% | Training loss: 0.6870654737456516
Epoch: 23 | Iteration number: [3880/4518] 85% | Training loss: 0.6870626373696573
Epoch: 23 | Iteration number: [3890/4518] 86% | Training loss: 0.6870588061282444
Epoch: 23 | Iteration number: [3900/4518] 86% | Training loss: 0.6870574485644316
Epoch: 23 | Iteration number: [3910/4518] 86% | Training loss: 0.6870546740034352
Epoch: 23 | Iteration number: [3920/4518] 86% | Training loss: 0.6870531638970181
Epoch: 23 | Iteration number: [3930/4518] 86% | Training loss: 0.6870548229332796
Epoch: 23 | Iteration number: [3940/4518] 87% | Training loss: 0.6870551854372025
Epoch: 23 | Iteration number: [3950/4518] 87% | Training loss: 0.6870533079738859
Epoch: 23 | Iteration number: [3960/4518] 87% | Training loss: 0.687047353386879
Epoch: 23 | Iteration number: [3970/4518] 87% | Training loss: 0.6870486471755078
Epoch: 23 | Iteration number: [3980/4518] 88% | Training loss: 0.6870481453199483
Epoch: 23 | Iteration number: [3990/4518] 88% | Training loss: 0.687051641896255
Epoch: 23 | Iteration number: [4000/4518] 88% | Training loss: 0.6870526373237371
Epoch: 23 | Iteration number: [4010/4518] 88% | Training loss: 0.6870501917199303
Epoch: 23 | Iteration number: [4020/4518] 88% | Training loss: 0.6870512999705414
Epoch: 23 | Iteration number: [4030/4518] 89% | Training loss: 0.6870513694014206
Epoch: 23 | Iteration number: [4040/4518] 89% | Training loss: 0.6870511589073899
Epoch: 23 | Iteration number: [4050/4518] 89% | Training loss: 0.6870553925596637
Epoch: 23 | Iteration number: [4060/4518] 89% | Training loss: 0.6870533593476112
Epoch: 23 | Iteration number: [4070/4518] 90% | Training loss: 0.6870537688310375
Epoch: 23 | Iteration number: [4080/4518] 90% | Training loss: 0.687053139989867
Epoch: 23 | Iteration number: [4090/4518] 90% | Training loss: 0.687051367949157
Epoch: 23 | Iteration number: [4100/4518] 90% | Training loss: 0.6870491979180313
Epoch: 23 | Iteration number: [4110/4518] 90% | Training loss: 0.6870508865283353
Epoch: 23 | Iteration number: [4120/4518] 91% | Training loss: 0.6870508075773137
Epoch: 23 | Iteration number: [4130/4518] 91% | Training loss: 0.6870517054712513
Epoch: 23 | Iteration number: [4140/4518] 91% | Training loss: 0.6870518425092605
Epoch: 23 | Iteration number: [4150/4518] 91% | Training loss: 0.6870505871542965
Epoch: 23 | Iteration number: [4160/4518] 92% | Training loss: 0.6870484633514514
Epoch: 23 | Iteration number: [4170/4518] 92% | Training loss: 0.6870486446993528
Epoch: 23 | Iteration number: [4180/4518] 92% | Training loss: 0.6870471807758204
Epoch: 23 | Iteration number: [4190/4518] 92% | Training loss: 0.6870458071015615
Epoch: 23 | Iteration number: [4200/4518] 92% | Training loss: 0.6870406976200285
Epoch: 23 | Iteration number: [4210/4518] 93% | Training loss: 0.6870397139756527
Epoch: 23 | Iteration number: [4220/4518] 93% | Training loss: 0.6870395110399237
Epoch: 23 | Iteration number: [4230/4518] 93% | Training loss: 0.687040278674863
Epoch: 23 | Iteration number: [4240/4518] 93% | Training loss: 0.6870399541871728
Epoch: 23 | Iteration number: [4250/4518] 94% | Training loss: 0.6870411268542794
Epoch: 23 | Iteration number: [4260/4518] 94% | Training loss: 0.6870394325592148
Epoch: 23 | Iteration number: [4270/4518] 94% | Training loss: 0.6870410150331412
Epoch: 23 | Iteration number: [4280/4518] 94% | Training loss: 0.6870416871158876
Epoch: 23 | Iteration number: [4290/4518] 94% | Training loss: 0.6870413450928001
Epoch: 23 | Iteration number: [4300/4518] 95% | Training loss: 0.6870427466824998
Epoch: 23 | Iteration number: [4310/4518] 95% | Training loss: 0.6870431349753228
Epoch: 23 | Iteration number: [4320/4518] 95% | Training loss: 0.6870429437883474
Epoch: 23 | Iteration number: [4330/4518] 95% | Training loss: 0.6870405086744189
Epoch: 23 | Iteration number: [4340/4518] 96% | Training loss: 0.6870395895248185
Epoch: 23 | Iteration number: [4350/4518] 96% | Training loss: 0.6870396488562398
Epoch: 23 | Iteration number: [4360/4518] 96% | Training loss: 0.687037777230827
Epoch: 23 | Iteration number: [4370/4518] 96% | Training loss: 0.6870350019609901
Epoch: 23 | Iteration number: [4380/4518] 96% | Training loss: 0.6870375829200223
Epoch: 23 | Iteration number: [4390/4518] 97% | Training loss: 0.687036860532261
Epoch: 23 | Iteration number: [4400/4518] 97% | Training loss: 0.6870393388786099
Epoch: 23 | Iteration number: [4410/4518] 97% | Training loss: 0.687040127621216
Epoch: 23 | Iteration number: [4420/4518] 97% | Training loss: 0.687041940381624
Epoch: 23 | Iteration number: [4430/4518] 98% | Training loss: 0.6870418765205831
Epoch: 23 | Iteration number: [4440/4518] 98% | Training loss: 0.6870425436813552
Epoch: 23 | Iteration number: [4450/4518] 98% | Training loss: 0.6870416376296055
Epoch: 23 | Iteration number: [4460/4518] 98% | Training loss: 0.6870423007038142
Epoch: 23 | Iteration number: [4470/4518] 98% | Training loss: 0.6870441043936967
Epoch: 23 | Iteration number: [4480/4518] 99% | Training loss: 0.6870423583579915
Epoch: 23 | Iteration number: [4490/4518] 99% | Training loss: 0.6870431553813026
Epoch: 23 | Iteration number: [4500/4518] 99% | Training loss: 0.687043621049987
Epoch: 23 | Iteration number: [4510/4518] 99% | Training loss: 0.6870426646489526

 End of epoch: 23 | Train Loss: 0.6868909367975696 | Training Time: 640 

 End of epoch: 23 | Eval Loss: 0.6901251552056293 | Evaluating Time: 17 
Epoch: 24 | Iteration number: [10/4518] 0% | Training loss: 0.7549958527088165
Epoch: 24 | Iteration number: [20/4518] 0% | Training loss: 0.7215935409069061
Epoch: 24 | Iteration number: [30/4518] 0% | Training loss: 0.7098144193490347
Epoch: 24 | Iteration number: [40/4518] 0% | Training loss: 0.7040027037262917
Epoch: 24 | Iteration number: [50/4518] 1% | Training loss: 0.7003989613056183
Epoch: 24 | Iteration number: [60/4518] 1% | Training loss: 0.6980994721253713
Epoch: 24 | Iteration number: [70/4518] 1% | Training loss: 0.6966185527188438
Epoch: 24 | Iteration number: [80/4518] 1% | Training loss: 0.6954487055540085
Epoch: 24 | Iteration number: [90/4518] 1% | Training loss: 0.6944565329286787
Epoch: 24 | Iteration number: [100/4518] 2% | Training loss: 0.6936082428693772
Epoch: 24 | Iteration number: [110/4518] 2% | Training loss: 0.693002773956819
Epoch: 24 | Iteration number: [120/4518] 2% | Training loss: 0.6925701076785723
Epoch: 24 | Iteration number: [130/4518] 2% | Training loss: 0.6920823147663704
Epoch: 24 | Iteration number: [140/4518] 3% | Training loss: 0.6918027081659862
Epoch: 24 | Iteration number: [150/4518] 3% | Training loss: 0.6913988153139751
Epoch: 24 | Iteration number: [160/4518] 3% | Training loss: 0.6910876959562302
Epoch: 24 | Iteration number: [170/4518] 3% | Training loss: 0.6907981125747457
Epoch: 24 | Iteration number: [180/4518] 3% | Training loss: 0.6906238241328133
Epoch: 24 | Iteration number: [190/4518] 4% | Training loss: 0.6904435151501706
Epoch: 24 | Iteration number: [200/4518] 4% | Training loss: 0.6902095064520836
Epoch: 24 | Iteration number: [210/4518] 4% | Training loss: 0.6900280424526759
Epoch: 24 | Iteration number: [220/4518] 4% | Training loss: 0.6898666669021953
Epoch: 24 | Iteration number: [230/4518] 5% | Training loss: 0.689679802759834
Epoch: 24 | Iteration number: [240/4518] 5% | Training loss: 0.6895840120812257
Epoch: 24 | Iteration number: [250/4518] 5% | Training loss: 0.689425457239151
Epoch: 24 | Iteration number: [260/4518] 5% | Training loss: 0.6894069793132636
Epoch: 24 | Iteration number: [270/4518] 5% | Training loss: 0.6893128856464669
Epoch: 24 | Iteration number: [280/4518] 6% | Training loss: 0.6892456148351942
Epoch: 24 | Iteration number: [290/4518] 6% | Training loss: 0.6891678764902313
Epoch: 24 | Iteration number: [300/4518] 6% | Training loss: 0.6891023115317026
Epoch: 24 | Iteration number: [310/4518] 6% | Training loss: 0.6890399917479484
Epoch: 24 | Iteration number: [320/4518] 7% | Training loss: 0.6889807131141424
Epoch: 24 | Iteration number: [330/4518] 7% | Training loss: 0.6889520354343183
Epoch: 24 | Iteration number: [340/4518] 7% | Training loss: 0.6889421182520249
Epoch: 24 | Iteration number: [350/4518] 7% | Training loss: 0.688890392610005
Epoch: 24 | Iteration number: [360/4518] 7% | Training loss: 0.6888239312503073
Epoch: 24 | Iteration number: [370/4518] 8% | Training loss: 0.6887661270193152
Epoch: 24 | Iteration number: [380/4518] 8% | Training loss: 0.6887174927874615
Epoch: 24 | Iteration number: [390/4518] 8% | Training loss: 0.6886910256667015
Epoch: 24 | Iteration number: [400/4518] 8% | Training loss: 0.6886869445443153
Epoch: 24 | Iteration number: [410/4518] 9% | Training loss: 0.6886319096495466
Epoch: 24 | Iteration number: [420/4518] 9% | Training loss: 0.6886053701241811
Epoch: 24 | Iteration number: [430/4518] 9% | Training loss: 0.6885895909265031
Epoch: 24 | Iteration number: [440/4518] 9% | Training loss: 0.6885611456903544
Epoch: 24 | Iteration number: [450/4518] 9% | Training loss: 0.6885331624084049
Epoch: 24 | Iteration number: [460/4518] 10% | Training loss: 0.6884906684574874
Epoch: 24 | Iteration number: [470/4518] 10% | Training loss: 0.688453138762332
Epoch: 24 | Iteration number: [480/4518] 10% | Training loss: 0.688432831938068
Epoch: 24 | Iteration number: [490/4518] 10% | Training loss: 0.6883998991275321
Epoch: 24 | Iteration number: [500/4518] 11% | Training loss: 0.6883760670423508
Epoch: 24 | Iteration number: [510/4518] 11% | Training loss: 0.6883332120437248
Epoch: 24 | Iteration number: [520/4518] 11% | Training loss: 0.6883301550379166
Epoch: 24 | Iteration number: [530/4518] 11% | Training loss: 0.6883067190647125
Epoch: 24 | Iteration number: [540/4518] 11% | Training loss: 0.6882819967137442
Epoch: 24 | Iteration number: [550/4518] 12% | Training loss: 0.6882581126689911
Epoch: 24 | Iteration number: [560/4518] 12% | Training loss: 0.6882411535297122
Epoch: 24 | Iteration number: [570/4518] 12% | Training loss: 0.688235415596711
Epoch: 24 | Iteration number: [580/4518] 12% | Training loss: 0.6882109230962293
Epoch: 24 | Iteration number: [590/4518] 13% | Training loss: 0.6881867652222261
Epoch: 24 | Iteration number: [600/4518] 13% | Training loss: 0.6881832287708918
Epoch: 24 | Iteration number: [610/4518] 13% | Training loss: 0.688140647430889
Epoch: 24 | Iteration number: [620/4518] 13% | Training loss: 0.6881225251382397
Epoch: 24 | Iteration number: [630/4518] 13% | Training loss: 0.6880800596305302
Epoch: 24 | Iteration number: [640/4518] 14% | Training loss: 0.6880472750402987
Epoch: 24 | Iteration number: [650/4518] 14% | Training loss: 0.6880439035709087
Epoch: 24 | Iteration number: [660/4518] 14% | Training loss: 0.6880251002131086
Epoch: 24 | Iteration number: [670/4518] 14% | Training loss: 0.6880119523005699
Epoch: 24 | Iteration number: [680/4518] 15% | Training loss: 0.6880058157969924
Epoch: 24 | Iteration number: [690/4518] 15% | Training loss: 0.6879874511041503
Epoch: 24 | Iteration number: [700/4518] 15% | Training loss: 0.6879793473652431
Epoch: 24 | Iteration number: [710/4518] 15% | Training loss: 0.6879484210215824
Epoch: 24 | Iteration number: [720/4518] 15% | Training loss: 0.6879349020620187
Epoch: 24 | Iteration number: [730/4518] 16% | Training loss: 0.687918183248337
Epoch: 24 | Iteration number: [740/4518] 16% | Training loss: 0.6878971528362583
Epoch: 24 | Iteration number: [750/4518] 16% | Training loss: 0.6878942840099335
Epoch: 24 | Iteration number: [760/4518] 16% | Training loss: 0.687862183937901
Epoch: 24 | Iteration number: [770/4518] 17% | Training loss: 0.6878368366848339
Epoch: 24 | Iteration number: [780/4518] 17% | Training loss: 0.6878272917026128
Epoch: 24 | Iteration number: [790/4518] 17% | Training loss: 0.6878028223786173
Epoch: 24 | Iteration number: [800/4518] 17% | Training loss: 0.6877757987380028
Epoch: 24 | Iteration number: [810/4518] 17% | Training loss: 0.687780840161406
Epoch: 24 | Iteration number: [820/4518] 18% | Training loss: 0.6877663755562248
Epoch: 24 | Iteration number: [830/4518] 18% | Training loss: 0.687769445310156
Epoch: 24 | Iteration number: [840/4518] 18% | Training loss: 0.6877631529456093
Epoch: 24 | Iteration number: [850/4518] 18% | Training loss: 0.6877515451347127
Epoch: 24 | Iteration number: [860/4518] 19% | Training loss: 0.6877489826706953
Epoch: 24 | Iteration number: [870/4518] 19% | Training loss: 0.6877325834214002
Epoch: 24 | Iteration number: [880/4518] 19% | Training loss: 0.6877135066823525
Epoch: 24 | Iteration number: [890/4518] 19% | Training loss: 0.6876972996117023
Epoch: 24 | Iteration number: [900/4518] 19% | Training loss: 0.6876733876599206
Epoch: 24 | Iteration number: [910/4518] 20% | Training loss: 0.6876626612065913
Epoch: 24 | Iteration number: [920/4518] 20% | Training loss: 0.6876489780519319
Epoch: 24 | Iteration number: [930/4518] 20% | Training loss: 0.6876406174193146
Epoch: 24 | Iteration number: [940/4518] 20% | Training loss: 0.687630492512216
Epoch: 24 | Iteration number: [950/4518] 21% | Training loss: 0.6876087461019817
Epoch: 24 | Iteration number: [960/4518] 21% | Training loss: 0.6876092060158651
Epoch: 24 | Iteration number: [970/4518] 21% | Training loss: 0.6876057012793944
Epoch: 24 | Iteration number: [980/4518] 21% | Training loss: 0.6875939986535481
Epoch: 24 | Iteration number: [990/4518] 21% | Training loss: 0.6875788948752664
Epoch: 24 | Iteration number: [1000/4518] 22% | Training loss: 0.6875721611380577
Epoch: 24 | Iteration number: [1010/4518] 22% | Training loss: 0.6875559989178535
Epoch: 24 | Iteration number: [1020/4518] 22% | Training loss: 0.6875452111749089
Epoch: 24 | Iteration number: [1030/4518] 22% | Training loss: 0.6875377258050789
Epoch: 24 | Iteration number: [1040/4518] 23% | Training loss: 0.6875386275351048
Epoch: 24 | Iteration number: [1050/4518] 23% | Training loss: 0.6875360765343621
Epoch: 24 | Iteration number: [1060/4518] 23% | Training loss: 0.6875300411908132
Epoch: 24 | Iteration number: [1070/4518] 23% | Training loss: 0.6875149847748123
Epoch: 24 | Iteration number: [1080/4518] 23% | Training loss: 0.687521477650713
Epoch: 24 | Iteration number: [1090/4518] 24% | Training loss: 0.6875202569939675
Epoch: 24 | Iteration number: [1100/4518] 24% | Training loss: 0.6875229687582363
Epoch: 24 | Iteration number: [1110/4518] 24% | Training loss: 0.6875098686497491
Epoch: 24 | Iteration number: [1120/4518] 24% | Training loss: 0.6875051373349769
Epoch: 24 | Iteration number: [1130/4518] 25% | Training loss: 0.687502114013233
Epoch: 24 | Iteration number: [1140/4518] 25% | Training loss: 0.687507298536468
Epoch: 24 | Iteration number: [1150/4518] 25% | Training loss: 0.6874945052292036
Epoch: 24 | Iteration number: [1160/4518] 25% | Training loss: 0.6874835653551694
Epoch: 24 | Iteration number: [1170/4518] 25% | Training loss: 0.6874753838420933
Epoch: 24 | Iteration number: [1180/4518] 26% | Training loss: 0.6874605370780169
Epoch: 24 | Iteration number: [1190/4518] 26% | Training loss: 0.6874551017244322
Epoch: 24 | Iteration number: [1200/4518] 26% | Training loss: 0.6874454865356286
Epoch: 24 | Iteration number: [1210/4518] 26% | Training loss: 0.6874403537797534
Epoch: 24 | Iteration number: [1220/4518] 27% | Training loss: 0.687433436854941
Epoch: 24 | Iteration number: [1230/4518] 27% | Training loss: 0.6874356395345393
Epoch: 24 | Iteration number: [1240/4518] 27% | Training loss: 0.6874232374852703
Epoch: 24 | Iteration number: [1250/4518] 27% | Training loss: 0.6874177296638488
Epoch: 24 | Iteration number: [1260/4518] 27% | Training loss: 0.6874174513041027
Epoch: 24 | Iteration number: [1270/4518] 28% | Training loss: 0.687423078938732
Epoch: 24 | Iteration number: [1280/4518] 28% | Training loss: 0.6874073568265885
Epoch: 24 | Iteration number: [1290/4518] 28% | Training loss: 0.6873922999977141
Epoch: 24 | Iteration number: [1300/4518] 28% | Training loss: 0.6873875728020301
Epoch: 24 | Iteration number: [1310/4518] 28% | Training loss: 0.6873780147264932
Epoch: 24 | Iteration number: [1320/4518] 29% | Training loss: 0.6873786492329655
Epoch: 24 | Iteration number: [1330/4518] 29% | Training loss: 0.6873671727521079
Epoch: 24 | Iteration number: [1340/4518] 29% | Training loss: 0.68736718185802
Epoch: 24 | Iteration number: [1350/4518] 29% | Training loss: 0.687362572617001
Epoch: 24 | Iteration number: [1360/4518] 30% | Training loss: 0.6873659862753223
Epoch: 24 | Iteration number: [1370/4518] 30% | Training loss: 0.6873549354772498
Epoch: 24 | Iteration number: [1380/4518] 30% | Training loss: 0.6873514467391415
Epoch: 24 | Iteration number: [1390/4518] 30% | Training loss: 0.6873483529193796
Epoch: 24 | Iteration number: [1400/4518] 30% | Training loss: 0.6873471977881023
Epoch: 24 | Iteration number: [1410/4518] 31% | Training loss: 0.6873449971489872
Epoch: 24 | Iteration number: [1420/4518] 31% | Training loss: 0.6873516861821564
Epoch: 24 | Iteration number: [1430/4518] 31% | Training loss: 0.6873417342042589
Epoch: 24 | Iteration number: [1440/4518] 31% | Training loss: 0.6873331654402944
Epoch: 24 | Iteration number: [1450/4518] 32% | Training loss: 0.6873272467481679
Epoch: 24 | Iteration number: [1460/4518] 32% | Training loss: 0.6873174191337742
Epoch: 24 | Iteration number: [1470/4518] 32% | Training loss: 0.6873159730515512
Epoch: 24 | Iteration number: [1480/4518] 32% | Training loss: 0.6873179058368142
Epoch: 24 | Iteration number: [1490/4518] 32% | Training loss: 0.6873144823432769
Epoch: 24 | Iteration number: [1500/4518] 33% | Training loss: 0.6873147791226705
Epoch: 24 | Iteration number: [1510/4518] 33% | Training loss: 0.6873034066317097
Epoch: 24 | Iteration number: [1520/4518] 33% | Training loss: 0.6872993323755892
Epoch: 24 | Iteration number: [1530/4518] 33% | Training loss: 0.6873028888032328
Epoch: 24 | Iteration number: [1540/4518] 34% | Training loss: 0.6873023715112117
Epoch: 24 | Iteration number: [1550/4518] 34% | Training loss: 0.6872920230896242
Epoch: 24 | Iteration number: [1560/4518] 34% | Training loss: 0.6872910823577489
Epoch: 24 | Iteration number: [1570/4518] 34% | Training loss: 0.687290954551879
Epoch: 24 | Iteration number: [1580/4518] 34% | Training loss: 0.6872884007948863
Epoch: 24 | Iteration number: [1590/4518] 35% | Training loss: 0.6872774785044808
Epoch: 24 | Iteration number: [1600/4518] 35% | Training loss: 0.6872780740261077
Epoch: 24 | Iteration number: [1610/4518] 35% | Training loss: 0.6872814719721397
Epoch: 24 | Iteration number: [1620/4518] 35% | Training loss: 0.6872742867764131
Epoch: 24 | Iteration number: [1630/4518] 36% | Training loss: 0.6872669908532336
Epoch: 24 | Iteration number: [1640/4518] 36% | Training loss: 0.6872629127851346
Epoch: 24 | Iteration number: [1650/4518] 36% | Training loss: 0.6872592595851783
Epoch: 24 | Iteration number: [1660/4518] 36% | Training loss: 0.6872547342475638
Epoch: 24 | Iteration number: [1670/4518] 36% | Training loss: 0.687251803403843
Epoch: 24 | Iteration number: [1680/4518] 37% | Training loss: 0.6872455612889358
Epoch: 24 | Iteration number: [1690/4518] 37% | Training loss: 0.6872505412299252
Epoch: 24 | Iteration number: [1700/4518] 37% | Training loss: 0.6872469558435328
Epoch: 24 | Iteration number: [1710/4518] 37% | Training loss: 0.6872434036424983
Epoch: 24 | Iteration number: [1720/4518] 38% | Training loss: 0.6872435713576716
Epoch: 24 | Iteration number: [1730/4518] 38% | Training loss: 0.6872401406310197
Epoch: 24 | Iteration number: [1740/4518] 38% | Training loss: 0.6872456109729307
Epoch: 24 | Iteration number: [1750/4518] 38% | Training loss: 0.6872416438034603
Epoch: 24 | Iteration number: [1760/4518] 38% | Training loss: 0.6872395668856123
Epoch: 24 | Iteration number: [1770/4518] 39% | Training loss: 0.687237636079896
Epoch: 24 | Iteration number: [1780/4518] 39% | Training loss: 0.6872369673814667
Epoch: 24 | Iteration number: [1790/4518] 39% | Training loss: 0.6872401565812819
Epoch: 24 | Iteration number: [1800/4518] 39% | Training loss: 0.6872392905751864
Epoch: 24 | Iteration number: [1810/4518] 40% | Training loss: 0.6872378804736374
Epoch: 24 | Iteration number: [1820/4518] 40% | Training loss: 0.6872355668099372
Epoch: 24 | Iteration number: [1830/4518] 40% | Training loss: 0.6872374797127937
Epoch: 24 | Iteration number: [1840/4518] 40% | Training loss: 0.6872370751007744
Epoch: 24 | Iteration number: [1850/4518] 40% | Training loss: 0.687235737652392
Epoch: 24 | Iteration number: [1860/4518] 41% | Training loss: 0.6872375366828775
Epoch: 24 | Iteration number: [1870/4518] 41% | Training loss: 0.6872375370346926
Epoch: 24 | Iteration number: [1880/4518] 41% | Training loss: 0.6872352656214795
Epoch: 24 | Iteration number: [1890/4518] 41% | Training loss: 0.6872359467561914
Epoch: 24 | Iteration number: [1900/4518] 42% | Training loss: 0.6872335402589095
Epoch: 24 | Iteration number: [1910/4518] 42% | Training loss: 0.6872269750889684
Epoch: 24 | Iteration number: [1920/4518] 42% | Training loss: 0.68722905209288
Epoch: 24 | Iteration number: [1930/4518] 42% | Training loss: 0.6872314816620684
Epoch: 24 | Iteration number: [1940/4518] 42% | Training loss: 0.6872369015339723
Epoch: 24 | Iteration number: [1950/4518] 43% | Training loss: 0.6872349156783177
Epoch: 24 | Iteration number: [1960/4518] 43% | Training loss: 0.6872365544036944
Epoch: 24 | Iteration number: [1970/4518] 43% | Training loss: 0.6872362215506849
Epoch: 24 | Iteration number: [1980/4518] 43% | Training loss: 0.687236171479177
Epoch: 24 | Iteration number: [1990/4518] 44% | Training loss: 0.6872347715511993
Epoch: 24 | Iteration number: [2000/4518] 44% | Training loss: 0.687228658080101
Epoch: 24 | Iteration number: [2010/4518] 44% | Training loss: 0.6872232780231172
Epoch: 24 | Iteration number: [2020/4518] 44% | Training loss: 0.6872221422077406
Epoch: 24 | Iteration number: [2030/4518] 44% | Training loss: 0.6872272963594334
Epoch: 24 | Iteration number: [2040/4518] 45% | Training loss: 0.6872245549279101
Epoch: 24 | Iteration number: [2050/4518] 45% | Training loss: 0.6872251610930373
Epoch: 24 | Iteration number: [2060/4518] 45% | Training loss: 0.6872292111220869
Epoch: 24 | Iteration number: [2070/4518] 45% | Training loss: 0.6872267457310128
Epoch: 24 | Iteration number: [2080/4518] 46% | Training loss: 0.6872222583454389
Epoch: 24 | Iteration number: [2090/4518] 46% | Training loss: 0.6872202239538494
Epoch: 24 | Iteration number: [2100/4518] 46% | Training loss: 0.687215052701178
Epoch: 24 | Iteration number: [2110/4518] 46% | Training loss: 0.6872054015855653
Epoch: 24 | Iteration number: [2120/4518] 46% | Training loss: 0.6872041130122148
Epoch: 24 | Iteration number: [2130/4518] 47% | Training loss: 0.6872021433333276
Epoch: 24 | Iteration number: [2140/4518] 47% | Training loss: 0.6871995426226999
Epoch: 24 | Iteration number: [2150/4518] 47% | Training loss: 0.6871945801723836
Epoch: 24 | Iteration number: [2160/4518] 47% | Training loss: 0.6871872867699023
Epoch: 24 | Iteration number: [2170/4518] 48% | Training loss: 0.6871858488854176
Epoch: 24 | Iteration number: [2180/4518] 48% | Training loss: 0.6871778925897878
Epoch: 24 | Iteration number: [2190/4518] 48% | Training loss: 0.6871759410590341
Epoch: 24 | Iteration number: [2200/4518] 48% | Training loss: 0.6871745298125527
Epoch: 24 | Iteration number: [2210/4518] 48% | Training loss: 0.6871769392382505
Epoch: 24 | Iteration number: [2220/4518] 49% | Training loss: 0.6871729303050685
Epoch: 24 | Iteration number: [2230/4518] 49% | Training loss: 0.6871737626635975
Epoch: 24 | Iteration number: [2240/4518] 49% | Training loss: 0.6871709667678391
Epoch: 24 | Iteration number: [2250/4518] 49% | Training loss: 0.6871743954022725
Epoch: 24 | Iteration number: [2260/4518] 50% | Training loss: 0.6871705240380448
Epoch: 24 | Iteration number: [2270/4518] 50% | Training loss: 0.687172560203443
Epoch: 24 | Iteration number: [2280/4518] 50% | Training loss: 0.6871739097593124
Epoch: 24 | Iteration number: [2290/4518] 50% | Training loss: 0.6871724684946402
Epoch: 24 | Iteration number: [2300/4518] 50% | Training loss: 0.6871739698752113
Epoch: 24 | Iteration number: [2310/4518] 51% | Training loss: 0.6871760161408098
Epoch: 24 | Iteration number: [2320/4518] 51% | Training loss: 0.6871722501156659
Epoch: 24 | Iteration number: [2330/4518] 51% | Training loss: 0.687169273933116
Epoch: 24 | Iteration number: [2340/4518] 51% | Training loss: 0.6871636032294004
Epoch: 24 | Iteration number: [2350/4518] 52% | Training loss: 0.6871650500246819
Epoch: 24 | Iteration number: [2360/4518] 52% | Training loss: 0.687159919915563
Epoch: 24 | Iteration number: [2370/4518] 52% | Training loss: 0.687157963448939
Epoch: 24 | Iteration number: [2380/4518] 52% | Training loss: 0.6871509248969936
Epoch: 24 | Iteration number: [2390/4518] 52% | Training loss: 0.6871492810079742
Epoch: 24 | Iteration number: [2400/4518] 53% | Training loss: 0.6871505078921716
Epoch: 24 | Iteration number: [2410/4518] 53% | Training loss: 0.6871500179233393
Epoch: 24 | Iteration number: [2420/4518] 53% | Training loss: 0.6871464977825968
Epoch: 24 | Iteration number: [2430/4518] 53% | Training loss: 0.6871500641475489
Epoch: 24 | Iteration number: [2440/4518] 54% | Training loss: 0.6871498434514296
Epoch: 24 | Iteration number: [2450/4518] 54% | Training loss: 0.6871472103011852
Epoch: 24 | Iteration number: [2460/4518] 54% | Training loss: 0.6871478024294706
Epoch: 24 | Iteration number: [2470/4518] 54% | Training loss: 0.6871524547517058
Epoch: 24 | Iteration number: [2480/4518] 54% | Training loss: 0.6871546380221843
Epoch: 24 | Iteration number: [2490/4518] 55% | Training loss: 0.6871512387172285
Epoch: 24 | Iteration number: [2500/4518] 55% | Training loss: 0.6871531738519668
Epoch: 24 | Iteration number: [2510/4518] 55% | Training loss: 0.6871532102505049
Epoch: 24 | Iteration number: [2520/4518] 55% | Training loss: 0.6871553733235314
Epoch: 24 | Iteration number: [2530/4518] 55% | Training loss: 0.68715542371094
Epoch: 24 | Iteration number: [2540/4518] 56% | Training loss: 0.6871572988005135
Epoch: 24 | Iteration number: [2550/4518] 56% | Training loss: 0.6871532409097634
Epoch: 24 | Iteration number: [2560/4518] 56% | Training loss: 0.6871480070985854
Epoch: 24 | Iteration number: [2570/4518] 56% | Training loss: 0.6871429374013893
Epoch: 24 | Iteration number: [2580/4518] 57% | Training loss: 0.6871426753064459
Epoch: 24 | Iteration number: [2590/4518] 57% | Training loss: 0.6871391573007503
Epoch: 24 | Iteration number: [2600/4518] 57% | Training loss: 0.6871394704855406
Epoch: 24 | Iteration number: [2610/4518] 57% | Training loss: 0.687139119316335
Epoch: 24 | Iteration number: [2620/4518] 57% | Training loss: 0.6871376559707044
Epoch: 24 | Iteration number: [2630/4518] 58% | Training loss: 0.6871441636701954
Epoch: 24 | Iteration number: [2640/4518] 58% | Training loss: 0.6871363588129029
Epoch: 24 | Iteration number: [2650/4518] 58% | Training loss: 0.6871343226702709
Epoch: 24 | Iteration number: [2660/4518] 58% | Training loss: 0.6871341573116475
Epoch: 24 | Iteration number: [2670/4518] 59% | Training loss: 0.687140125259478
Epoch: 24 | Iteration number: [2680/4518] 59% | Training loss: 0.6871386101664002
Epoch: 24 | Iteration number: [2690/4518] 59% | Training loss: 0.6871381634008485
Epoch: 24 | Iteration number: [2700/4518] 59% | Training loss: 0.6871336027648713
Epoch: 24 | Iteration number: [2710/4518] 59% | Training loss: 0.6871308866242201
Epoch: 24 | Iteration number: [2720/4518] 60% | Training loss: 0.6871325016898268
Epoch: 24 | Iteration number: [2730/4518] 60% | Training loss: 0.6871274166928106
Epoch: 24 | Iteration number: [2740/4518] 60% | Training loss: 0.6871206609654601
Epoch: 24 | Iteration number: [2750/4518] 60% | Training loss: 0.687115094054829
Epoch: 24 | Iteration number: [2760/4518] 61% | Training loss: 0.6871129888123361
Epoch: 24 | Iteration number: [2770/4518] 61% | Training loss: 0.6871202379357514
Epoch: 24 | Iteration number: [2780/4518] 61% | Training loss: 0.6871213893024184
Epoch: 24 | Iteration number: [2790/4518] 61% | Training loss: 0.6871214595533186
Epoch: 24 | Iteration number: [2800/4518] 61% | Training loss: 0.6871210095499243
Epoch: 24 | Iteration number: [2810/4518] 62% | Training loss: 0.6871215211539082
Epoch: 24 | Iteration number: [2820/4518] 62% | Training loss: 0.6871250348310944
Epoch: 24 | Iteration number: [2830/4518] 62% | Training loss: 0.6871276406643668
Epoch: 24 | Iteration number: [2840/4518] 62% | Training loss: 0.6871285708017753
Epoch: 24 | Iteration number: [2850/4518] 63% | Training loss: 0.687131217111621
Epoch: 24 | Iteration number: [2860/4518] 63% | Training loss: 0.6871325962818586
Epoch: 24 | Iteration number: [2870/4518] 63% | Training loss: 0.6871291915506436
Epoch: 24 | Iteration number: [2880/4518] 63% | Training loss: 0.6871269392263558
Epoch: 24 | Iteration number: [2890/4518] 63% | Training loss: 0.687128093849004
Epoch: 24 | Iteration number: [2900/4518] 64% | Training loss: 0.68712559358827
Epoch: 24 | Iteration number: [2910/4518] 64% | Training loss: 0.687128360697494
Epoch: 24 | Iteration number: [2920/4518] 64% | Training loss: 0.6871259050826504
Epoch: 24 | Iteration number: [2930/4518] 64% | Training loss: 0.6871257986224959
Epoch: 24 | Iteration number: [2940/4518] 65% | Training loss: 0.6871236418380219
Epoch: 24 | Iteration number: [2950/4518] 65% | Training loss: 0.6871227514945855
Epoch: 24 | Iteration number: [2960/4518] 65% | Training loss: 0.6871246164916335
Epoch: 24 | Iteration number: [2970/4518] 65% | Training loss: 0.6871287878715631
Epoch: 24 | Iteration number: [2980/4518] 65% | Training loss: 0.6871268792640443
Epoch: 24 | Iteration number: [2990/4518] 66% | Training loss: 0.687126747441531
Epoch: 24 | Iteration number: [3000/4518] 66% | Training loss: 0.687124876777331
Epoch: 24 | Iteration number: [3010/4518] 66% | Training loss: 0.6871257048904698
Epoch: 24 | Iteration number: [3020/4518] 66% | Training loss: 0.6871247797414957
Epoch: 24 | Iteration number: [3030/4518] 67% | Training loss: 0.6871258832440518
Epoch: 24 | Iteration number: [3040/4518] 67% | Training loss: 0.6871284709557106
Epoch: 24 | Iteration number: [3050/4518] 67% | Training loss: 0.6871303624012431
Epoch: 24 | Iteration number: [3060/4518] 67% | Training loss: 0.6871311995328642
Epoch: 24 | Iteration number: [3070/4518] 67% | Training loss: 0.6871298458172367
Epoch: 24 | Iteration number: [3080/4518] 68% | Training loss: 0.6871266226102779
Epoch: 24 | Iteration number: [3090/4518] 68% | Training loss: 0.6871238709653466
Epoch: 24 | Iteration number: [3100/4518] 68% | Training loss: 0.6871251879007586
Epoch: 24 | Iteration number: [3110/4518] 68% | Training loss: 0.6871264539539239
Epoch: 24 | Iteration number: [3120/4518] 69% | Training loss: 0.6871297870691006
Epoch: 24 | Iteration number: [3130/4518] 69% | Training loss: 0.687133657360991
Epoch: 24 | Iteration number: [3140/4518] 69% | Training loss: 0.6871354415348381
Epoch: 24 | Iteration number: [3150/4518] 69% | Training loss: 0.6871361348364088
Epoch: 24 | Iteration number: [3160/4518] 69% | Training loss: 0.687141479947899
Epoch: 24 | Iteration number: [3170/4518] 70% | Training loss: 0.6871382737385362
Epoch: 24 | Iteration number: [3180/4518] 70% | Training loss: 0.6871371717010654
Epoch: 24 | Iteration number: [3190/4518] 70% | Training loss: 0.6871338746017049
Epoch: 24 | Iteration number: [3200/4518] 70% | Training loss: 0.6871321196109057
Epoch: 24 | Iteration number: [3210/4518] 71% | Training loss: 0.6871297533638381
Epoch: 24 | Iteration number: [3220/4518] 71% | Training loss: 0.6871300300270874
Epoch: 24 | Iteration number: [3230/4518] 71% | Training loss: 0.6871310812954563
Epoch: 24 | Iteration number: [3240/4518] 71% | Training loss: 0.6871283340969203
Epoch: 24 | Iteration number: [3250/4518] 71% | Training loss: 0.6871264008742113
Epoch: 24 | Iteration number: [3260/4518] 72% | Training loss: 0.6871273829527428
Epoch: 24 | Iteration number: [3270/4518] 72% | Training loss: 0.6871274053868168
Epoch: 24 | Iteration number: [3280/4518] 72% | Training loss: 0.687128122895956
Epoch: 24 | Iteration number: [3290/4518] 72% | Training loss: 0.6871262875190259
Epoch: 24 | Iteration number: [3300/4518] 73% | Training loss: 0.6871275172269705
Epoch: 24 | Iteration number: [3310/4518] 73% | Training loss: 0.6871294362667464
Epoch: 24 | Iteration number: [3320/4518] 73% | Training loss: 0.6871268785143473
Epoch: 24 | Iteration number: [3330/4518] 73% | Training loss: 0.6871264933465837
Epoch: 24 | Iteration number: [3340/4518] 73% | Training loss: 0.6871272440620525
Epoch: 24 | Iteration number: [3350/4518] 74% | Training loss: 0.687126243879546
Epoch: 24 | Iteration number: [3360/4518] 74% | Training loss: 0.6871253175749665
Epoch: 24 | Iteration number: [3370/4518] 74% | Training loss: 0.6871219312578705
Epoch: 24 | Iteration number: [3380/4518] 74% | Training loss: 0.6871219414754732
Epoch: 24 | Iteration number: [3390/4518] 75% | Training loss: 0.6871223597575781
Epoch: 24 | Iteration number: [3400/4518] 75% | Training loss: 0.687120603621006
Epoch: 24 | Iteration number: [3410/4518] 75% | Training loss: 0.6871182789900435
Epoch: 24 | Iteration number: [3420/4518] 75% | Training loss: 0.6871147511821044
Epoch: 24 | Iteration number: [3430/4518] 75% | Training loss: 0.687116163273942
Epoch: 24 | Iteration number: [3440/4518] 76% | Training loss: 0.6871134502769902
Epoch: 24 | Iteration number: [3450/4518] 76% | Training loss: 0.687112588364145
Epoch: 24 | Iteration number: [3460/4518] 76% | Training loss: 0.6871100458278822
Epoch: 24 | Iteration number: [3470/4518] 76% | Training loss: 0.6871069422029281
Epoch: 24 | Iteration number: [3480/4518] 77% | Training loss: 0.6871040183065952
Epoch: 24 | Iteration number: [3490/4518] 77% | Training loss: 0.6871061903357847
Epoch: 24 | Iteration number: [3500/4518] 77% | Training loss: 0.6871038849694389
Epoch: 24 | Iteration number: [3510/4518] 77% | Training loss: 0.6871019172023165
Epoch: 24 | Iteration number: [3520/4518] 77% | Training loss: 0.6871001302010634
Epoch: 24 | Iteration number: [3530/4518] 78% | Training loss: 0.6870988856631703
Epoch: 24 | Iteration number: [3540/4518] 78% | Training loss: 0.6870978002831087
Epoch: 24 | Iteration number: [3550/4518] 78% | Training loss: 0.6870954324158145
Epoch: 24 | Iteration number: [3560/4518] 78% | Training loss: 0.6870956849013822
Epoch: 24 | Iteration number: [3570/4518] 79% | Training loss: 0.6870960169479626
Epoch: 24 | Iteration number: [3580/4518] 79% | Training loss: 0.6870946371355536
Epoch: 24 | Iteration number: [3590/4518] 79% | Training loss: 0.6870909520676541
Epoch: 24 | Iteration number: [3600/4518] 79% | Training loss: 0.6870927285816935
Epoch: 24 | Iteration number: [3610/4518] 79% | Training loss: 0.6870901683526026
Epoch: 24 | Iteration number: [3620/4518] 80% | Training loss: 0.6870844453902535
Epoch: 24 | Iteration number: [3630/4518] 80% | Training loss: 0.6870778914161293
Epoch: 24 | Iteration number: [3640/4518] 80% | Training loss: 0.6870784564168899
Epoch: 24 | Iteration number: [3650/4518] 80% | Training loss: 0.6870794299367357
Epoch: 24 | Iteration number: [3660/4518] 81% | Training loss: 0.6870752047157027
Epoch: 24 | Iteration number: [3670/4518] 81% | Training loss: 0.6870759914616473
Epoch: 24 | Iteration number: [3680/4518] 81% | Training loss: 0.6870755165329446
Epoch: 24 | Iteration number: [3690/4518] 81% | Training loss: 0.6870767827441052
Epoch: 24 | Iteration number: [3700/4518] 81% | Training loss: 0.6870751619500083
Epoch: 24 | Iteration number: [3710/4518] 82% | Training loss: 0.6870739456456948
Epoch: 24 | Iteration number: [3720/4518] 82% | Training loss: 0.6870726721581593
Epoch: 24 | Iteration number: [3730/4518] 82% | Training loss: 0.6870689737413268
Epoch: 24 | Iteration number: [3740/4518] 82% | Training loss: 0.6870719433468293
Epoch: 24 | Iteration number: [3750/4518] 83% | Training loss: 0.6870706048647562
Epoch: 24 | Iteration number: [3760/4518] 83% | Training loss: 0.6870700287692091
Epoch: 24 | Iteration number: [3770/4518] 83% | Training loss: 0.6870733308697253
Epoch: 24 | Iteration number: [3780/4518] 83% | Training loss: 0.6870693032546018
Epoch: 24 | Iteration number: [3790/4518] 83% | Training loss: 0.6870690810806204
Epoch: 24 | Iteration number: [3800/4518] 84% | Training loss: 0.6870663487911224
Epoch: 24 | Iteration number: [3810/4518] 84% | Training loss: 0.6870658019239821
Epoch: 24 | Iteration number: [3820/4518] 84% | Training loss: 0.6870640948804886
Epoch: 24 | Iteration number: [3830/4518] 84% | Training loss: 0.6870631517069147
Epoch: 24 | Iteration number: [3840/4518] 84% | Training loss: 0.6870584512595087
Epoch: 24 | Iteration number: [3850/4518] 85% | Training loss: 0.6870594524563133
Epoch: 24 | Iteration number: [3860/4518] 85% | Training loss: 0.6870592219996329
Epoch: 24 | Iteration number: [3870/4518] 85% | Training loss: 0.6870598001689566
Epoch: 24 | Iteration number: [3880/4518] 85% | Training loss: 0.6870565288152891
Epoch: 24 | Iteration number: [3890/4518] 86% | Training loss: 0.687056949221383
Epoch: 24 | Iteration number: [3900/4518] 86% | Training loss: 0.6870553634869747
Epoch: 24 | Iteration number: [3910/4518] 86% | Training loss: 0.6870573312272806
Epoch: 24 | Iteration number: [3920/4518] 86% | Training loss: 0.6870582702360591
Epoch: 24 | Iteration number: [3930/4518] 86% | Training loss: 0.6870547610384817
Epoch: 24 | Iteration number: [3940/4518] 87% | Training loss: 0.687055665451258
Epoch: 24 | Iteration number: [3950/4518] 87% | Training loss: 0.68705538807036
Epoch: 24 | Iteration number: [3960/4518] 87% | Training loss: 0.6870560607374316
Epoch: 24 | Iteration number: [3970/4518] 87% | Training loss: 0.6870569817064992
Epoch: 24 | Iteration number: [3980/4518] 88% | Training loss: 0.6870576649754491
Epoch: 24 | Iteration number: [3990/4518] 88% | Training loss: 0.6870587431846704
Epoch: 24 | Iteration number: [4000/4518] 88% | Training loss: 0.6870612228661775
Epoch: 24 | Iteration number: [4010/4518] 88% | Training loss: 0.6870625003763565
Epoch: 24 | Iteration number: [4020/4518] 88% | Training loss: 0.6870618648048658
Epoch: 24 | Iteration number: [4030/4518] 89% | Training loss: 0.6870666267114597
Epoch: 24 | Iteration number: [4040/4518] 89% | Training loss: 0.6870671054514328
Epoch: 24 | Iteration number: [4050/4518] 89% | Training loss: 0.6870669203628729
Epoch: 24 | Iteration number: [4060/4518] 89% | Training loss: 0.6870652128763387
Epoch: 24 | Iteration number: [4070/4518] 90% | Training loss: 0.6870658514833567
Epoch: 24 | Iteration number: [4080/4518] 90% | Training loss: 0.6870637111511885
Epoch: 24 | Iteration number: [4090/4518] 90% | Training loss: 0.6870648188083854
Epoch: 24 | Iteration number: [4100/4518] 90% | Training loss: 0.6870645526124209
Epoch: 24 | Iteration number: [4110/4518] 90% | Training loss: 0.6870626214936992
Epoch: 24 | Iteration number: [4120/4518] 91% | Training loss: 0.6870609039820513
Epoch: 24 | Iteration number: [4130/4518] 91% | Training loss: 0.6870609487806048
Epoch: 24 | Iteration number: [4140/4518] 91% | Training loss: 0.6870607048417059
Epoch: 24 | Iteration number: [4150/4518] 91% | Training loss: 0.6870544219447906
Epoch: 24 | Iteration number: [4160/4518] 92% | Training loss: 0.687052959175064
Epoch: 24 | Iteration number: [4170/4518] 92% | Training loss: 0.687053009831934
Epoch: 24 | Iteration number: [4180/4518] 92% | Training loss: 0.6870545161968213
Epoch: 24 | Iteration number: [4190/4518] 92% | Training loss: 0.6870549793175126
Epoch: 24 | Iteration number: [4200/4518] 92% | Training loss: 0.6870535171883447
Epoch: 24 | Iteration number: [4210/4518] 93% | Training loss: 0.6870484745559103
Epoch: 24 | Iteration number: [4220/4518] 93% | Training loss: 0.6870470511546067
Epoch: 24 | Iteration number: [4230/4518] 93% | Training loss: 0.687045301148232
Epoch: 24 | Iteration number: [4240/4518] 93% | Training loss: 0.6870476457589078
Epoch: 24 | Iteration number: [4250/4518] 94% | Training loss: 0.6870489557490629
Epoch: 24 | Iteration number: [4260/4518] 94% | Training loss: 0.6870477385644062
Epoch: 24 | Iteration number: [4270/4518] 94% | Training loss: 0.6870485358132132
Epoch: 24 | Iteration number: [4280/4518] 94% | Training loss: 0.6870501521591829
Epoch: 24 | Iteration number: [4290/4518] 94% | Training loss: 0.6870479757135565
Epoch: 24 | Iteration number: [4300/4518] 95% | Training loss: 0.6870481549861819
Epoch: 24 | Iteration number: [4310/4518] 95% | Training loss: 0.687048211147503
Epoch: 24 | Iteration number: [4320/4518] 95% | Training loss: 0.6870492906896053
Epoch: 24 | Iteration number: [4330/4518] 95% | Training loss: 0.6870473894593897
Epoch: 24 | Iteration number: [4340/4518] 96% | Training loss: 0.6870460061021664
Epoch: 24 | Iteration number: [4350/4518] 96% | Training loss: 0.6870449616854218
Epoch: 24 | Iteration number: [4360/4518] 96% | Training loss: 0.6870446589014946
Epoch: 24 | Iteration number: [4370/4518] 96% | Training loss: 0.6870431547988743
Epoch: 24 | Iteration number: [4380/4518] 96% | Training loss: 0.6870434391716299
Epoch: 24 | Iteration number: [4390/4518] 97% | Training loss: 0.6870428141537451
Epoch: 24 | Iteration number: [4400/4518] 97% | Training loss: 0.6870423757217147
Epoch: 24 | Iteration number: [4410/4518] 97% | Training loss: 0.6870394272869136
Epoch: 24 | Iteration number: [4420/4518] 97% | Training loss: 0.6870392064837848
Epoch: 24 | Iteration number: [4430/4518] 98% | Training loss: 0.6870401501655579
Epoch: 24 | Iteration number: [4440/4518] 98% | Training loss: 0.6870401283507949
Epoch: 24 | Iteration number: [4450/4518] 98% | Training loss: 0.6870413692881552
Epoch: 24 | Iteration number: [4460/4518] 98% | Training loss: 0.687038043288372
Epoch: 24 | Iteration number: [4470/4518] 98% | Training loss: 0.6870339443752963
Epoch: 24 | Iteration number: [4480/4518] 99% | Training loss: 0.6870338502473065
Epoch: 24 | Iteration number: [4490/4518] 99% | Training loss: 0.6870329360388435
Epoch: 24 | Iteration number: [4500/4518] 99% | Training loss: 0.6870332044760387
Epoch: 24 | Iteration number: [4510/4518] 99% | Training loss: 0.687031241002474

 End of epoch: 24 | Train Loss: 0.6868793745914779 | Training Time: 640 

 End of epoch: 24 | Eval Loss: 0.6901303395933035 | Evaluating Time: 17 
Epoch: 25 | Iteration number: [10/4518] 0% | Training loss: 0.7555355966091156
Epoch: 25 | Iteration number: [20/4518] 0% | Training loss: 0.721155372262001
Epoch: 25 | Iteration number: [30/4518] 0% | Training loss: 0.709532246987025
Epoch: 25 | Iteration number: [40/4518] 0% | Training loss: 0.7037941828370095
Epoch: 25 | Iteration number: [50/4518] 1% | Training loss: 0.7005474948883057
Epoch: 25 | Iteration number: [60/4518] 1% | Training loss: 0.6981484125057856
Epoch: 25 | Iteration number: [70/4518] 1% | Training loss: 0.6964022091456822
Epoch: 25 | Iteration number: [80/4518] 1% | Training loss: 0.6953408099710942
Epoch: 25 | Iteration number: [90/4518] 1% | Training loss: 0.6944021019670699
Epoch: 25 | Iteration number: [100/4518] 2% | Training loss: 0.6937405663728714
Epoch: 25 | Iteration number: [110/4518] 2% | Training loss: 0.693091467293826
Epoch: 25 | Iteration number: [120/4518] 2% | Training loss: 0.6925903956095377
Epoch: 25 | Iteration number: [130/4518] 2% | Training loss: 0.6921970184032734
Epoch: 25 | Iteration number: [140/4518] 3% | Training loss: 0.6917785257101059
Epoch: 25 | Iteration number: [150/4518] 3% | Training loss: 0.6915260910987854
Epoch: 25 | Iteration number: [160/4518] 3% | Training loss: 0.6913490731269121
Epoch: 25 | Iteration number: [170/4518] 3% | Training loss: 0.6910841748994939
Epoch: 25 | Iteration number: [180/4518] 3% | Training loss: 0.6908008399936888
Epoch: 25 | Iteration number: [190/4518] 4% | Training loss: 0.6906001304325304
Epoch: 25 | Iteration number: [200/4518] 4% | Training loss: 0.6903096014261245
Epoch: 25 | Iteration number: [210/4518] 4% | Training loss: 0.6901303487164634
Epoch: 25 | Iteration number: [220/4518] 4% | Training loss: 0.6900302160869946
Epoch: 25 | Iteration number: [230/4518] 5% | Training loss: 0.6899440208207006
Epoch: 25 | Iteration number: [240/4518] 5% | Training loss: 0.6897832942505677
Epoch: 25 | Iteration number: [250/4518] 5% | Training loss: 0.6896577789783478
Epoch: 25 | Iteration number: [260/4518] 5% | Training loss: 0.6895044633975396
Epoch: 25 | Iteration number: [270/4518] 5% | Training loss: 0.6894541894948041
Epoch: 25 | Iteration number: [280/4518] 6% | Training loss: 0.6893362932971545
Epoch: 25 | Iteration number: [290/4518] 6% | Training loss: 0.6892756020200663
Epoch: 25 | Iteration number: [300/4518] 6% | Training loss: 0.6892250263690949
Epoch: 25 | Iteration number: [310/4518] 6% | Training loss: 0.6891230275554042
Epoch: 25 | Iteration number: [320/4518] 7% | Training loss: 0.6890251060947776
Epoch: 25 | Iteration number: [330/4518] 7% | Training loss: 0.688945413719524
Epoch: 25 | Iteration number: [340/4518] 7% | Training loss: 0.6888809719506432
Epoch: 25 | Iteration number: [350/4518] 7% | Training loss: 0.6888139344964709
Epoch: 25 | Iteration number: [360/4518] 7% | Training loss: 0.6887483802106645
Epoch: 25 | Iteration number: [370/4518] 8% | Training loss: 0.688700337667723
Epoch: 25 | Iteration number: [380/4518] 8% | Training loss: 0.6886668313490717
Epoch: 25 | Iteration number: [390/4518] 8% | Training loss: 0.6885947071588956
Epoch: 25 | Iteration number: [400/4518] 8% | Training loss: 0.6885589301586151
Epoch: 25 | Iteration number: [410/4518] 9% | Training loss: 0.6885147859410542
Epoch: 25 | Iteration number: [420/4518] 9% | Training loss: 0.6884569290138426
Epoch: 25 | Iteration number: [430/4518] 9% | Training loss: 0.6883830496045046
Epoch: 25 | Iteration number: [440/4518] 9% | Training loss: 0.6883678602901372
Epoch: 25 | Iteration number: [450/4518] 9% | Training loss: 0.6883115969763862
Epoch: 25 | Iteration number: [460/4518] 10% | Training loss: 0.6882816442976827
Epoch: 25 | Iteration number: [470/4518] 10% | Training loss: 0.6882515166668182
Epoch: 25 | Iteration number: [480/4518] 10% | Training loss: 0.6882105723023415
Epoch: 25 | Iteration number: [490/4518] 10% | Training loss: 0.6881696192585692
Epoch: 25 | Iteration number: [500/4518] 11% | Training loss: 0.6881743420362473
Epoch: 25 | Iteration number: [510/4518] 11% | Training loss: 0.6881426743432587
Epoch: 25 | Iteration number: [520/4518] 11% | Training loss: 0.6881158709526062
Epoch: 25 | Iteration number: [530/4518] 11% | Training loss: 0.6881010008308123
Epoch: 25 | Iteration number: [540/4518] 11% | Training loss: 0.688055780309218
Epoch: 25 | Iteration number: [550/4518] 12% | Training loss: 0.688015572049401
Epoch: 25 | Iteration number: [560/4518] 12% | Training loss: 0.6880007131823471
Epoch: 25 | Iteration number: [570/4518] 12% | Training loss: 0.6879891648627164
Epoch: 25 | Iteration number: [580/4518] 12% | Training loss: 0.6879682914964084
Epoch: 25 | Iteration number: [590/4518] 13% | Training loss: 0.6879569480984898
Epoch: 25 | Iteration number: [600/4518] 13% | Training loss: 0.6879395297169686
Epoch: 25 | Iteration number: [610/4518] 13% | Training loss: 0.6879201403406799
Epoch: 25 | Iteration number: [620/4518] 13% | Training loss: 0.6878894662664783
Epoch: 25 | Iteration number: [630/4518] 13% | Training loss: 0.6878573832057772
Epoch: 25 | Iteration number: [640/4518] 14% | Training loss: 0.6878286836668849
Epoch: 25 | Iteration number: [650/4518] 14% | Training loss: 0.6878207832116348
Epoch: 25 | Iteration number: [660/4518] 14% | Training loss: 0.687810347387285
Epoch: 25 | Iteration number: [670/4518] 14% | Training loss: 0.6877711109261014
Epoch: 25 | Iteration number: [680/4518] 15% | Training loss: 0.687747264872579
Epoch: 25 | Iteration number: [690/4518] 15% | Training loss: 0.6877302772756936
Epoch: 25 | Iteration number: [700/4518] 15% | Training loss: 0.6877232356582369
Epoch: 25 | Iteration number: [710/4518] 15% | Training loss: 0.6877016421774743
Epoch: 25 | Iteration number: [720/4518] 15% | Training loss: 0.6876861478719446
Epoch: 25 | Iteration number: [730/4518] 16% | Training loss: 0.687675122937111
Epoch: 25 | Iteration number: [740/4518] 16% | Training loss: 0.6876567911457371
Epoch: 25 | Iteration number: [750/4518] 16% | Training loss: 0.6876675085226694
Epoch: 25 | Iteration number: [760/4518] 16% | Training loss: 0.6876584484388953
Epoch: 25 | Iteration number: [770/4518] 17% | Training loss: 0.6876622844052005
Epoch: 25 | Iteration number: [780/4518] 17% | Training loss: 0.6876464252288524
Epoch: 25 | Iteration number: [790/4518] 17% | Training loss: 0.6876507227933859
Epoch: 25 | Iteration number: [800/4518] 17% | Training loss: 0.6876205544173718
Epoch: 25 | Iteration number: [810/4518] 17% | Training loss: 0.6876136667934465
Epoch: 25 | Iteration number: [820/4518] 18% | Training loss: 0.6876022427547269
Epoch: 25 | Iteration number: [830/4518] 18% | Training loss: 0.6876141915120274
Epoch: 25 | Iteration number: [840/4518] 18% | Training loss: 0.6875974802034241
Epoch: 25 | Iteration number: [850/4518] 18% | Training loss: 0.6875861952585333
Epoch: 25 | Iteration number: [860/4518] 19% | Training loss: 0.6875860989786858
Epoch: 25 | Iteration number: [870/4518] 19% | Training loss: 0.6875734578603986
Epoch: 25 | Iteration number: [880/4518] 19% | Training loss: 0.687574734471061
Epoch: 25 | Iteration number: [890/4518] 19% | Training loss: 0.6875549731629618
Epoch: 25 | Iteration number: [900/4518] 19% | Training loss: 0.6875471894608604
Epoch: 25 | Iteration number: [910/4518] 20% | Training loss: 0.687535525219781
Epoch: 25 | Iteration number: [920/4518] 20% | Training loss: 0.6875268123720003
Epoch: 25 | Iteration number: [930/4518] 20% | Training loss: 0.6875339076724104
Epoch: 25 | Iteration number: [940/4518] 20% | Training loss: 0.6875352325591635
Epoch: 25 | Iteration number: [950/4518] 21% | Training loss: 0.687522350298731
Epoch: 25 | Iteration number: [960/4518] 21% | Training loss: 0.6875192929680148
Epoch: 25 | Iteration number: [970/4518] 21% | Training loss: 0.6875117392884087
Epoch: 25 | Iteration number: [980/4518] 21% | Training loss: 0.6875017422194384
Epoch: 25 | Iteration number: [990/4518] 21% | Training loss: 0.6874875140912605
Epoch: 25 | Iteration number: [1000/4518] 22% | Training loss: 0.6874853200912475
Epoch: 25 | Iteration number: [1010/4518] 22% | Training loss: 0.6874800865602966
Epoch: 25 | Iteration number: [1020/4518] 22% | Training loss: 0.6874739343629164
Epoch: 25 | Iteration number: [1030/4518] 22% | Training loss: 0.6874747662289629
Epoch: 25 | Iteration number: [1040/4518] 23% | Training loss: 0.6874820119486406
Epoch: 25 | Iteration number: [1050/4518] 23% | Training loss: 0.6874728274345397
Epoch: 25 | Iteration number: [1060/4518] 23% | Training loss: 0.6874718440591164
Epoch: 25 | Iteration number: [1070/4518] 23% | Training loss: 0.687474140998359
Epoch: 25 | Iteration number: [1080/4518] 23% | Training loss: 0.6874702567855517
Epoch: 25 | Iteration number: [1090/4518] 24% | Training loss: 0.6874591994723048
Epoch: 25 | Iteration number: [1100/4518] 24% | Training loss: 0.6874614790352908
Epoch: 25 | Iteration number: [1110/4518] 24% | Training loss: 0.6874543381166888
Epoch: 25 | Iteration number: [1120/4518] 24% | Training loss: 0.6874451941677502
Epoch: 25 | Iteration number: [1130/4518] 25% | Training loss: 0.6874501724158768
Epoch: 25 | Iteration number: [1140/4518] 25% | Training loss: 0.6874492245807983
Epoch: 25 | Iteration number: [1150/4518] 25% | Training loss: 0.6874511354902516
Epoch: 25 | Iteration number: [1160/4518] 25% | Training loss: 0.6874349106488556
Epoch: 25 | Iteration number: [1170/4518] 25% | Training loss: 0.6874294921373709
Epoch: 25 | Iteration number: [1180/4518] 26% | Training loss: 0.6874299422664157
Epoch: 25 | Iteration number: [1190/4518] 26% | Training loss: 0.6874183026682429
Epoch: 25 | Iteration number: [1200/4518] 26% | Training loss: 0.6874088512857756
Epoch: 25 | Iteration number: [1210/4518] 26% | Training loss: 0.6874008633381079
Epoch: 25 | Iteration number: [1220/4518] 27% | Training loss: 0.6874010644975256
Epoch: 25 | Iteration number: [1230/4518] 27% | Training loss: 0.6873948849313627
Epoch: 25 | Iteration number: [1240/4518] 27% | Training loss: 0.6873960589208911
Epoch: 25 | Iteration number: [1250/4518] 27% | Training loss: 0.6873880069255829
Epoch: 25 | Iteration number: [1260/4518] 27% | Training loss: 0.6873889447677703
Epoch: 25 | Iteration number: [1270/4518] 28% | Training loss: 0.6873729253847768
Epoch: 25 | Iteration number: [1280/4518] 28% | Training loss: 0.6873739384114742
Epoch: 25 | Iteration number: [1290/4518] 28% | Training loss: 0.68735952733099
Epoch: 25 | Iteration number: [1300/4518] 28% | Training loss: 0.6873633879423141
Epoch: 25 | Iteration number: [1310/4518] 28% | Training loss: 0.6873519652217399
Epoch: 25 | Iteration number: [1320/4518] 29% | Training loss: 0.6873493425322301
Epoch: 25 | Iteration number: [1330/4518] 29% | Training loss: 0.6873485327663278
Epoch: 25 | Iteration number: [1340/4518] 29% | Training loss: 0.6873407654353042
Epoch: 25 | Iteration number: [1350/4518] 29% | Training loss: 0.6873434716242331
Epoch: 25 | Iteration number: [1360/4518] 30% | Training loss: 0.6873439088902052
Epoch: 25 | Iteration number: [1370/4518] 30% | Training loss: 0.6873408171382264
Epoch: 25 | Iteration number: [1380/4518] 30% | Training loss: 0.6873480049164399
Epoch: 25 | Iteration number: [1390/4518] 30% | Training loss: 0.6873484236302135
Epoch: 25 | Iteration number: [1400/4518] 30% | Training loss: 0.6873549245510783
Epoch: 25 | Iteration number: [1410/4518] 31% | Training loss: 0.687343001281116
Epoch: 25 | Iteration number: [1420/4518] 31% | Training loss: 0.6873426254786236
Epoch: 25 | Iteration number: [1430/4518] 31% | Training loss: 0.687333794657167
Epoch: 25 | Iteration number: [1440/4518] 31% | Training loss: 0.6873283811741405
Epoch: 25 | Iteration number: [1450/4518] 32% | Training loss: 0.6873261886629565
Epoch: 25 | Iteration number: [1460/4518] 32% | Training loss: 0.687331879751323
Epoch: 25 | Iteration number: [1470/4518] 32% | Training loss: 0.6873344168371084
Epoch: 25 | Iteration number: [1480/4518] 32% | Training loss: 0.6873217635058068
Epoch: 25 | Iteration number: [1490/4518] 32% | Training loss: 0.6873102827360166
Epoch: 25 | Iteration number: [1500/4518] 33% | Training loss: 0.687306782801946
Epoch: 25 | Iteration number: [1510/4518] 33% | Training loss: 0.6873075721674408
Epoch: 25 | Iteration number: [1520/4518] 33% | Training loss: 0.6873048150617825
Epoch: 25 | Iteration number: [1530/4518] 33% | Training loss: 0.6873076922753278
Epoch: 25 | Iteration number: [1540/4518] 34% | Training loss: 0.6873008695902763
Epoch: 25 | Iteration number: [1550/4518] 34% | Training loss: 0.687291910840619
Epoch: 25 | Iteration number: [1560/4518] 34% | Training loss: 0.6872908620116038
Epoch: 25 | Iteration number: [1570/4518] 34% | Training loss: 0.6872933492539035
Epoch: 25 | Iteration number: [1580/4518] 34% | Training loss: 0.6872972060985203
Epoch: 25 | Iteration number: [1590/4518] 35% | Training loss: 0.6872913925152905
Epoch: 25 | Iteration number: [1600/4518] 35% | Training loss: 0.6872868577390909
Epoch: 25 | Iteration number: [1610/4518] 35% | Training loss: 0.6872824797719161
Epoch: 25 | Iteration number: [1620/4518] 35% | Training loss: 0.6872825801740458
Epoch: 25 | Iteration number: [1630/4518] 36% | Training loss: 0.6872823103073916
Epoch: 25 | Iteration number: [1640/4518] 36% | Training loss: 0.6872806116938591
Epoch: 25 | Iteration number: [1650/4518] 36% | Training loss: 0.6872787502678958
Epoch: 25 | Iteration number: [1660/4518] 36% | Training loss: 0.6872755873993218
Epoch: 25 | Iteration number: [1670/4518] 36% | Training loss: 0.6872764160176237
Epoch: 25 | Iteration number: [1680/4518] 37% | Training loss: 0.6872750404689993
Epoch: 25 | Iteration number: [1690/4518] 37% | Training loss: 0.6872694423565497
Epoch: 25 | Iteration number: [1700/4518] 37% | Training loss: 0.687269113870228
Epoch: 25 | Iteration number: [1710/4518] 37% | Training loss: 0.6872657879402763
Epoch: 25 | Iteration number: [1720/4518] 38% | Training loss: 0.6872649145334266
Epoch: 25 | Iteration number: [1730/4518] 38% | Training loss: 0.6872504135776807
Epoch: 25 | Iteration number: [1740/4518] 38% | Training loss: 0.6872514151978767
Epoch: 25 | Iteration number: [1750/4518] 38% | Training loss: 0.6872519727775028
Epoch: 25 | Iteration number: [1760/4518] 38% | Training loss: 0.6872510517185385
Epoch: 25 | Iteration number: [1770/4518] 39% | Training loss: 0.6872449588640935
Epoch: 25 | Iteration number: [1780/4518] 39% | Training loss: 0.6872369520784763
Epoch: 25 | Iteration number: [1790/4518] 39% | Training loss: 0.687232920177822
Epoch: 25 | Iteration number: [1800/4518] 39% | Training loss: 0.6872323007716072
Epoch: 25 | Iteration number: [1810/4518] 40% | Training loss: 0.6872356308428622
Epoch: 25 | Iteration number: [1820/4518] 40% | Training loss: 0.6872278700490574
Epoch: 25 | Iteration number: [1830/4518] 40% | Training loss: 0.6872211557268445
Epoch: 25 | Iteration number: [1840/4518] 40% | Training loss: 0.6872190006725166
Epoch: 25 | Iteration number: [1850/4518] 40% | Training loss: 0.6872177105014389
Epoch: 25 | Iteration number: [1860/4518] 41% | Training loss: 0.6872162729501724
Epoch: 25 | Iteration number: [1870/4518] 41% | Training loss: 0.6872051172396716
Epoch: 25 | Iteration number: [1880/4518] 41% | Training loss: 0.6872049409658351
Epoch: 25 | Iteration number: [1890/4518] 41% | Training loss: 0.6872007729199828
Epoch: 25 | Iteration number: [1900/4518] 42% | Training loss: 0.6871987068025689
Epoch: 25 | Iteration number: [1910/4518] 42% | Training loss: 0.6872040696793201
Epoch: 25 | Iteration number: [1920/4518] 42% | Training loss: 0.6872081893185774
Epoch: 25 | Iteration number: [1930/4518] 42% | Training loss: 0.6872079812492113
Epoch: 25 | Iteration number: [1940/4518] 42% | Training loss: 0.6872044005344824
Epoch: 25 | Iteration number: [1950/4518] 43% | Training loss: 0.6872019256383944
Epoch: 25 | Iteration number: [1960/4518] 43% | Training loss: 0.6872001312825144
Epoch: 25 | Iteration number: [1970/4518] 43% | Training loss: 0.6871953506760186
Epoch: 25 | Iteration number: [1980/4518] 43% | Training loss: 0.687196422977881
Epoch: 25 | Iteration number: [1990/4518] 44% | Training loss: 0.6871901912904864
Epoch: 25 | Iteration number: [2000/4518] 44% | Training loss: 0.6871845464110374
Epoch: 25 | Iteration number: [2010/4518] 44% | Training loss: 0.6871871470218868
Epoch: 25 | Iteration number: [2020/4518] 44% | Training loss: 0.687182954661917
Epoch: 25 | Iteration number: [2030/4518] 44% | Training loss: 0.6871829630706111
Epoch: 25 | Iteration number: [2040/4518] 45% | Training loss: 0.6871807994795781
Epoch: 25 | Iteration number: [2050/4518] 45% | Training loss: 0.6871790629479944
Epoch: 25 | Iteration number: [2060/4518] 45% | Training loss: 0.6871779628749033
Epoch: 25 | Iteration number: [2070/4518] 45% | Training loss: 0.6871807631375133
Epoch: 25 | Iteration number: [2080/4518] 46% | Training loss: 0.6871759081116089
Epoch: 25 | Iteration number: [2090/4518] 46% | Training loss: 0.687178726943486
Epoch: 25 | Iteration number: [2100/4518] 46% | Training loss: 0.6871737289996375
Epoch: 25 | Iteration number: [2110/4518] 46% | Training loss: 0.6871728267997362
Epoch: 25 | Iteration number: [2120/4518] 46% | Training loss: 0.6871672266215648
Epoch: 25 | Iteration number: [2130/4518] 47% | Training loss: 0.6871674739139181
Epoch: 25 | Iteration number: [2140/4518] 47% | Training loss: 0.6871608312163398
Epoch: 25 | Iteration number: [2150/4518] 47% | Training loss: 0.6871512700513351
Epoch: 25 | Iteration number: [2160/4518] 47% | Training loss: 0.6871533840894699
Epoch: 25 | Iteration number: [2170/4518] 48% | Training loss: 0.6871526696165586
Epoch: 25 | Iteration number: [2180/4518] 48% | Training loss: 0.6871500492642779
Epoch: 25 | Iteration number: [2190/4518] 48% | Training loss: 0.687139294109388
Epoch: 25 | Iteration number: [2200/4518] 48% | Training loss: 0.6871393890001557
Epoch: 25 | Iteration number: [2210/4518] 48% | Training loss: 0.6871315718236553
Epoch: 25 | Iteration number: [2220/4518] 49% | Training loss: 0.6871352895423098
Epoch: 25 | Iteration number: [2230/4518] 49% | Training loss: 0.6871359844111541
Epoch: 25 | Iteration number: [2240/4518] 49% | Training loss: 0.6871390818485192
Epoch: 25 | Iteration number: [2250/4518] 49% | Training loss: 0.687142287545734
Epoch: 25 | Iteration number: [2260/4518] 50% | Training loss: 0.6871410449521731
Epoch: 25 | Iteration number: [2270/4518] 50% | Training loss: 0.6871315742116668
Epoch: 25 | Iteration number: [2280/4518] 50% | Training loss: 0.6871300806340418
Epoch: 25 | Iteration number: [2290/4518] 50% | Training loss: 0.6871294075745162
Epoch: 25 | Iteration number: [2300/4518] 50% | Training loss: 0.6871294420180113
Epoch: 25 | Iteration number: [2310/4518] 51% | Training loss: 0.6871316900501003
Epoch: 25 | Iteration number: [2320/4518] 51% | Training loss: 0.6871318466961384
Epoch: 25 | Iteration number: [2330/4518] 51% | Training loss: 0.6871332411090704
Epoch: 25 | Iteration number: [2340/4518] 51% | Training loss: 0.6871312900995596
Epoch: 25 | Iteration number: [2350/4518] 52% | Training loss: 0.6871288134696636
Epoch: 25 | Iteration number: [2360/4518] 52% | Training loss: 0.6871259135209908
Epoch: 25 | Iteration number: [2370/4518] 52% | Training loss: 0.687124567469464
Epoch: 25 | Iteration number: [2380/4518] 52% | Training loss: 0.6871180769776096
Epoch: 25 | Iteration number: [2390/4518] 52% | Training loss: 0.6871174715552869
Epoch: 25 | Iteration number: [2400/4518] 53% | Training loss: 0.6871186520904302
Epoch: 25 | Iteration number: [2410/4518] 53% | Training loss: 0.6871165344329295
Epoch: 25 | Iteration number: [2420/4518] 53% | Training loss: 0.687112806798998
Epoch: 25 | Iteration number: [2430/4518] 53% | Training loss: 0.6871165728618088
Epoch: 25 | Iteration number: [2440/4518] 54% | Training loss: 0.6871154631259011
Epoch: 25 | Iteration number: [2450/4518] 54% | Training loss: 0.6871188418962517
Epoch: 25 | Iteration number: [2460/4518] 54% | Training loss: 0.687119211462455
Epoch: 25 | Iteration number: [2470/4518] 54% | Training loss: 0.687123513125215
Epoch: 25 | Iteration number: [2480/4518] 54% | Training loss: 0.6871252897285646
Epoch: 25 | Iteration number: [2490/4518] 55% | Training loss: 0.6871199484331062
Epoch: 25 | Iteration number: [2500/4518] 55% | Training loss: 0.6871235616445541
Epoch: 25 | Iteration number: [2510/4518] 55% | Training loss: 0.6871187591457747
Epoch: 25 | Iteration number: [2520/4518] 55% | Training loss: 0.6871234368946817
Epoch: 25 | Iteration number: [2530/4518] 55% | Training loss: 0.6871156497670727
Epoch: 25 | Iteration number: [2540/4518] 56% | Training loss: 0.6871197318702232
Epoch: 25 | Iteration number: [2550/4518] 56% | Training loss: 0.6871187629886703
Epoch: 25 | Iteration number: [2560/4518] 56% | Training loss: 0.6871167436242104
Epoch: 25 | Iteration number: [2570/4518] 56% | Training loss: 0.6871182301165065
Epoch: 25 | Iteration number: [2580/4518] 57% | Training loss: 0.6871181019054827
Epoch: 25 | Iteration number: [2590/4518] 57% | Training loss: 0.6871167582204443
Epoch: 25 | Iteration number: [2600/4518] 57% | Training loss: 0.6871109382235087
Epoch: 25 | Iteration number: [2610/4518] 57% | Training loss: 0.6871085434124388
Epoch: 25 | Iteration number: [2620/4518] 57% | Training loss: 0.6871083481393697
Epoch: 25 | Iteration number: [2630/4518] 58% | Training loss: 0.6871076660237838
Epoch: 25 | Iteration number: [2640/4518] 58% | Training loss: 0.6871044664671927
Epoch: 25 | Iteration number: [2650/4518] 58% | Training loss: 0.6871034057185335
Epoch: 25 | Iteration number: [2660/4518] 58% | Training loss: 0.6871053374351416
Epoch: 25 | Iteration number: [2670/4518] 59% | Training loss: 0.6871052262488376
Epoch: 25 | Iteration number: [2680/4518] 59% | Training loss: 0.687104562280783
Epoch: 25 | Iteration number: [2690/4518] 59% | Training loss: 0.6871025063291358
Epoch: 25 | Iteration number: [2700/4518] 59% | Training loss: 0.6871012717926944
Epoch: 25 | Iteration number: [2710/4518] 59% | Training loss: 0.6871014581395252
Epoch: 25 | Iteration number: [2720/4518] 60% | Training loss: 0.6871014207820682
Epoch: 25 | Iteration number: [2730/4518] 60% | Training loss: 0.6871025997640449
Epoch: 25 | Iteration number: [2740/4518] 60% | Training loss: 0.6870989955254715
Epoch: 25 | Iteration number: [2750/4518] 60% | Training loss: 0.6871003714908253
Epoch: 25 | Iteration number: [2760/4518] 61% | Training loss: 0.687099918420764
Epoch: 25 | Iteration number: [2770/4518] 61% | Training loss: 0.6870992543895322
Epoch: 25 | Iteration number: [2780/4518] 61% | Training loss: 0.6870966260596145
Epoch: 25 | Iteration number: [2790/4518] 61% | Training loss: 0.6870947321042365
Epoch: 25 | Iteration number: [2800/4518] 61% | Training loss: 0.6870952714128153
Epoch: 25 | Iteration number: [2810/4518] 62% | Training loss: 0.687096293816787
Epoch: 25 | Iteration number: [2820/4518] 62% | Training loss: 0.6870943608224814
Epoch: 25 | Iteration number: [2830/4518] 62% | Training loss: 0.6870924613711691
Epoch: 25 | Iteration number: [2840/4518] 62% | Training loss: 0.6870917467374197
Epoch: 25 | Iteration number: [2850/4518] 63% | Training loss: 0.6870938211784028
Epoch: 25 | Iteration number: [2860/4518] 63% | Training loss: 0.6870924645370536
Epoch: 25 | Iteration number: [2870/4518] 63% | Training loss: 0.6870892127839531
Epoch: 25 | Iteration number: [2880/4518] 63% | Training loss: 0.6870865676138136
Epoch: 25 | Iteration number: [2890/4518] 63% | Training loss: 0.6870820985533375
Epoch: 25 | Iteration number: [2900/4518] 64% | Training loss: 0.6870848121519747
Epoch: 25 | Iteration number: [2910/4518] 64% | Training loss: 0.687085349780997
Epoch: 25 | Iteration number: [2920/4518] 64% | Training loss: 0.687086205306935
Epoch: 25 | Iteration number: [2930/4518] 64% | Training loss: 0.6870866013468329
Epoch: 25 | Iteration number: [2940/4518] 65% | Training loss: 0.6870867675056263
Epoch: 25 | Iteration number: [2950/4518] 65% | Training loss: 0.687087935956858
Epoch: 25 | Iteration number: [2960/4518] 65% | Training loss: 0.6870869127077025
Epoch: 25 | Iteration number: [2970/4518] 65% | Training loss: 0.6870863881576743
Epoch: 25 | Iteration number: [2980/4518] 65% | Training loss: 0.6870859745564877
Epoch: 25 | Iteration number: [2990/4518] 66% | Training loss: 0.6870815024726765
Epoch: 25 | Iteration number: [3000/4518] 66% | Training loss: 0.6870839908123016
Epoch: 25 | Iteration number: [3010/4518] 66% | Training loss: 0.6870866281051572
Epoch: 25 | Iteration number: [3020/4518] 66% | Training loss: 0.6870851684287684
Epoch: 25 | Iteration number: [3030/4518] 67% | Training loss: 0.6870838125546773
Epoch: 25 | Iteration number: [3040/4518] 67% | Training loss: 0.6870839632459377
Epoch: 25 | Iteration number: [3050/4518] 67% | Training loss: 0.6870881932485299
Epoch: 25 | Iteration number: [3060/4518] 67% | Training loss: 0.6870825783100003
Epoch: 25 | Iteration number: [3070/4518] 67% | Training loss: 0.6870825963610546
Epoch: 25 | Iteration number: [3080/4518] 68% | Training loss: 0.6870810363586847
Epoch: 25 | Iteration number: [3090/4518] 68% | Training loss: 0.687082462885619
Epoch: 25 | Iteration number: [3100/4518] 68% | Training loss: 0.6870800893729733
Epoch: 25 | Iteration number: [3110/4518] 68% | Training loss: 0.6870715995310204
Epoch: 25 | Iteration number: [3120/4518] 69% | Training loss: 0.6870706881468113
Epoch: 25 | Iteration number: [3130/4518] 69% | Training loss: 0.6870729169525658
Epoch: 25 | Iteration number: [3140/4518] 69% | Training loss: 0.6870717914620782
Epoch: 25 | Iteration number: [3150/4518] 69% | Training loss: 0.6870736226770613
Epoch: 25 | Iteration number: [3160/4518] 69% | Training loss: 0.6870736816827255
Epoch: 25 | Iteration number: [3170/4518] 70% | Training loss: 0.6870771648943989
Epoch: 25 | Iteration number: [3180/4518] 70% | Training loss: 0.6870784930837979
Epoch: 25 | Iteration number: [3190/4518] 70% | Training loss: 0.6870790177565009
Epoch: 25 | Iteration number: [3200/4518] 70% | Training loss: 0.6870771630853415
Epoch: 25 | Iteration number: [3210/4518] 71% | Training loss: 0.6870774581610599
Epoch: 25 | Iteration number: [3220/4518] 71% | Training loss: 0.6870752802361613
Epoch: 25 | Iteration number: [3230/4518] 71% | Training loss: 0.6870738492661586
Epoch: 25 | Iteration number: [3240/4518] 71% | Training loss: 0.6870710872389653
Epoch: 25 | Iteration number: [3250/4518] 71% | Training loss: 0.6870689006401942
Epoch: 25 | Iteration number: [3260/4518] 72% | Training loss: 0.6870674990437513
Epoch: 25 | Iteration number: [3270/4518] 72% | Training loss: 0.6870670593477535
Epoch: 25 | Iteration number: [3280/4518] 72% | Training loss: 0.687064912460926
Epoch: 25 | Iteration number: [3290/4518] 72% | Training loss: 0.6870647537490879
Epoch: 25 | Iteration number: [3300/4518] 73% | Training loss: 0.6870668749737017
Epoch: 25 | Iteration number: [3310/4518] 73% | Training loss: 0.6870632801171156
Epoch: 25 | Iteration number: [3320/4518] 73% | Training loss: 0.6870629715632244
Epoch: 25 | Iteration number: [3330/4518] 73% | Training loss: 0.6870648627703613
Epoch: 25 | Iteration number: [3340/4518] 73% | Training loss: 0.6870640678141645
Epoch: 25 | Iteration number: [3350/4518] 74% | Training loss: 0.6870645306359476
Epoch: 25 | Iteration number: [3360/4518] 74% | Training loss: 0.6870629916056281
Epoch: 25 | Iteration number: [3370/4518] 74% | Training loss: 0.6870645644933604
Epoch: 25 | Iteration number: [3380/4518] 74% | Training loss: 0.6870679196874065
Epoch: 25 | Iteration number: [3390/4518] 75% | Training loss: 0.6870697912389199
Epoch: 25 | Iteration number: [3400/4518] 75% | Training loss: 0.6870664380578434
Epoch: 25 | Iteration number: [3410/4518] 75% | Training loss: 0.6870659819446351
Epoch: 25 | Iteration number: [3420/4518] 75% | Training loss: 0.6870629882603361
Epoch: 25 | Iteration number: [3430/4518] 75% | Training loss: 0.6870598405512707
Epoch: 25 | Iteration number: [3440/4518] 76% | Training loss: 0.68705923960999
Epoch: 25 | Iteration number: [3450/4518] 76% | Training loss: 0.6870610240922458
Epoch: 25 | Iteration number: [3460/4518] 76% | Training loss: 0.6870586552716405
Epoch: 25 | Iteration number: [3470/4518] 76% | Training loss: 0.6870583502291259
Epoch: 25 | Iteration number: [3480/4518] 77% | Training loss: 0.6870580196209337
Epoch: 25 | Iteration number: [3490/4518] 77% | Training loss: 0.6870557018029997
Epoch: 25 | Iteration number: [3500/4518] 77% | Training loss: 0.6870532603263855
Epoch: 25 | Iteration number: [3510/4518] 77% | Training loss: 0.6870547094745854
Epoch: 25 | Iteration number: [3520/4518] 77% | Training loss: 0.6870540233328939
Epoch: 25 | Iteration number: [3530/4518] 78% | Training loss: 0.6870549652123924
Epoch: 25 | Iteration number: [3540/4518] 78% | Training loss: 0.6870549903077594
Epoch: 25 | Iteration number: [3550/4518] 78% | Training loss: 0.6870572293140519
Epoch: 25 | Iteration number: [3560/4518] 78% | Training loss: 0.6870548057924496
Epoch: 25 | Iteration number: [3570/4518] 79% | Training loss: 0.6870540470636192
Epoch: 25 | Iteration number: [3580/4518] 79% | Training loss: 0.6870510659237814
Epoch: 25 | Iteration number: [3590/4518] 79% | Training loss: 0.6870507261879265
Epoch: 25 | Iteration number: [3600/4518] 79% | Training loss: 0.6870521503355768
Epoch: 25 | Iteration number: [3610/4518] 79% | Training loss: 0.6870500635572417
Epoch: 25 | Iteration number: [3620/4518] 80% | Training loss: 0.6870500674893184
Epoch: 25 | Iteration number: [3630/4518] 80% | Training loss: 0.6870497987618459
Epoch: 25 | Iteration number: [3640/4518] 80% | Training loss: 0.6870520910882688
Epoch: 25 | Iteration number: [3650/4518] 80% | Training loss: 0.6870496897664788
Epoch: 25 | Iteration number: [3660/4518] 81% | Training loss: 0.6870498698917243
Epoch: 25 | Iteration number: [3670/4518] 81% | Training loss: 0.6870505041744793
Epoch: 25 | Iteration number: [3680/4518] 81% | Training loss: 0.6870482315997715
Epoch: 25 | Iteration number: [3690/4518] 81% | Training loss: 0.687047450264618
Epoch: 25 | Iteration number: [3700/4518] 81% | Training loss: 0.6870437709544156
Epoch: 25 | Iteration number: [3710/4518] 82% | Training loss: 0.6870464896256069
Epoch: 25 | Iteration number: [3720/4518] 82% | Training loss: 0.6870473055429356
Epoch: 25 | Iteration number: [3730/4518] 82% | Training loss: 0.6870445965921591
Epoch: 25 | Iteration number: [3740/4518] 82% | Training loss: 0.6870467371003514
Epoch: 25 | Iteration number: [3750/4518] 83% | Training loss: 0.687048893181483
Epoch: 25 | Iteration number: [3760/4518] 83% | Training loss: 0.687046799031978
Epoch: 25 | Iteration number: [3770/4518] 83% | Training loss: 0.687047359133905
Epoch: 25 | Iteration number: [3780/4518] 83% | Training loss: 0.6870470669061418
Epoch: 25 | Iteration number: [3790/4518] 83% | Training loss: 0.6870475949586853
Epoch: 25 | Iteration number: [3800/4518] 84% | Training loss: 0.6870479224386968
Epoch: 25 | Iteration number: [3810/4518] 84% | Training loss: 0.6870473155042943
Epoch: 25 | Iteration number: [3820/4518] 84% | Training loss: 0.6870449294906636
Epoch: 25 | Iteration number: [3830/4518] 84% | Training loss: 0.6870430534564483
Epoch: 25 | Iteration number: [3840/4518] 84% | Training loss: 0.6870436247438192
Epoch: 25 | Iteration number: [3850/4518] 85% | Training loss: 0.6870452540880674
Epoch: 25 | Iteration number: [3860/4518] 85% | Training loss: 0.6870436454220757
Epoch: 25 | Iteration number: [3870/4518] 85% | Training loss: 0.6870433118608262
Epoch: 25 | Iteration number: [3880/4518] 85% | Training loss: 0.6870455214196873
Epoch: 25 | Iteration number: [3890/4518] 86% | Training loss: 0.6870433412971104
Epoch: 25 | Iteration number: [3900/4518] 86% | Training loss: 0.6870404437566415
Epoch: 25 | Iteration number: [3910/4518] 86% | Training loss: 0.6870420067206673
Epoch: 25 | Iteration number: [3920/4518] 86% | Training loss: 0.6870412064906286
Epoch: 25 | Iteration number: [3930/4518] 86% | Training loss: 0.6870381674087078
Epoch: 25 | Iteration number: [3940/4518] 87% | Training loss: 0.6870389034754129
Epoch: 25 | Iteration number: [3950/4518] 87% | Training loss: 0.6870382925981208
Epoch: 25 | Iteration number: [3960/4518] 87% | Training loss: 0.6870384412732992
Epoch: 25 | Iteration number: [3970/4518] 87% | Training loss: 0.6870381514581685
Epoch: 25 | Iteration number: [3980/4518] 88% | Training loss: 0.6870417764288697
Epoch: 25 | Iteration number: [3990/4518] 88% | Training loss: 0.6870413626943316
Epoch: 25 | Iteration number: [4000/4518] 88% | Training loss: 0.6870409291982651
Epoch: 25 | Iteration number: [4010/4518] 88% | Training loss: 0.6870436032811306
Epoch: 25 | Iteration number: [4020/4518] 88% | Training loss: 0.6870401117783874
Epoch: 25 | Iteration number: [4030/4518] 89% | Training loss: 0.6870397649391118
Epoch: 25 | Iteration number: [4040/4518] 89% | Training loss: 0.6870399921984955
Epoch: 25 | Iteration number: [4050/4518] 89% | Training loss: 0.6870408242720145
Epoch: 25 | Iteration number: [4060/4518] 89% | Training loss: 0.6870380807099083
Epoch: 25 | Iteration number: [4070/4518] 90% | Training loss: 0.687035036687476
Epoch: 25 | Iteration number: [4080/4518] 90% | Training loss: 0.6870330471764593
Epoch: 25 | Iteration number: [4090/4518] 90% | Training loss: 0.6870302800735809
Epoch: 25 | Iteration number: [4100/4518] 90% | Training loss: 0.6870322034271752
Epoch: 25 | Iteration number: [4110/4518] 90% | Training loss: 0.6870337740493226
Epoch: 25 | Iteration number: [4120/4518] 91% | Training loss: 0.6870350141548416
Epoch: 25 | Iteration number: [4130/4518] 91% | Training loss: 0.6870369421223462
Epoch: 25 | Iteration number: [4140/4518] 91% | Training loss: 0.6870331995729088
Epoch: 25 | Iteration number: [4150/4518] 91% | Training loss: 0.6870330179743019
Epoch: 25 | Iteration number: [4160/4518] 92% | Training loss: 0.6870337481825397
Epoch: 25 | Iteration number: [4170/4518] 92% | Training loss: 0.6870334606805294
Epoch: 25 | Iteration number: [4180/4518] 92% | Training loss: 0.6870328579080162
Epoch: 25 | Iteration number: [4190/4518] 92% | Training loss: 0.6870368547826508
Epoch: 25 | Iteration number: [4200/4518] 92% | Training loss: 0.687038025657336
Epoch: 25 | Iteration number: [4210/4518] 93% | Training loss: 0.6870376346796538
Epoch: 25 | Iteration number: [4220/4518] 93% | Training loss: 0.6870406602090003
Epoch: 25 | Iteration number: [4230/4518] 93% | Training loss: 0.6870401630023975
Epoch: 25 | Iteration number: [4240/4518] 93% | Training loss: 0.6870411778114877
Epoch: 25 | Iteration number: [4250/4518] 94% | Training loss: 0.6870409749535953
Epoch: 25 | Iteration number: [4260/4518] 94% | Training loss: 0.6870431247311579
Epoch: 25 | Iteration number: [4270/4518] 94% | Training loss: 0.6870414276452478
Epoch: 25 | Iteration number: [4280/4518] 94% | Training loss: 0.6870395221582083
Epoch: 25 | Iteration number: [4290/4518] 94% | Training loss: 0.6870415608921807
Epoch: 25 | Iteration number: [4300/4518] 95% | Training loss: 0.6870406592723936
Epoch: 25 | Iteration number: [4310/4518] 95% | Training loss: 0.6870413797360838
Epoch: 25 | Iteration number: [4320/4518] 95% | Training loss: 0.6870391471104489
Epoch: 25 | Iteration number: [4330/4518] 95% | Training loss: 0.6870401280994504
Epoch: 25 | Iteration number: [4340/4518] 96% | Training loss: 0.6870436487659332
Epoch: 25 | Iteration number: [4350/4518] 96% | Training loss: 0.6870434303256286
Epoch: 25 | Iteration number: [4360/4518] 96% | Training loss: 0.6870431039174762
Epoch: 25 | Iteration number: [4370/4518] 96% | Training loss: 0.6870415475739494
Epoch: 25 | Iteration number: [4380/4518] 96% | Training loss: 0.6870396672318515
Epoch: 25 | Iteration number: [4390/4518] 97% | Training loss: 0.6870393206426929
Epoch: 25 | Iteration number: [4400/4518] 97% | Training loss: 0.6870436939055269
Epoch: 25 | Iteration number: [4410/4518] 97% | Training loss: 0.6870455710120212
Epoch: 25 | Iteration number: [4420/4518] 97% | Training loss: 0.6870443066995069
Epoch: 25 | Iteration number: [4430/4518] 98% | Training loss: 0.6870423955250001
Epoch: 25 | Iteration number: [4440/4518] 98% | Training loss: 0.6870428279579223
Epoch: 25 | Iteration number: [4450/4518] 98% | Training loss: 0.6870450410816107
Epoch: 25 | Iteration number: [4460/4518] 98% | Training loss: 0.6870447731606094
Epoch: 25 | Iteration number: [4470/4518] 98% | Training loss: 0.6870431120230314
Epoch: 25 | Iteration number: [4480/4518] 99% | Training loss: 0.6870423014408775
Epoch: 25 | Iteration number: [4490/4518] 99% | Training loss: 0.6870406749917564
Epoch: 25 | Iteration number: [4500/4518] 99% | Training loss: 0.6870361685090595
Epoch: 25 | Iteration number: [4510/4518] 99% | Training loss: 0.6870349815177283

 End of epoch: 25 | Train Loss: 0.6868829291549706 | Training Time: 641 

 End of epoch: 25 | Eval Loss: 0.6901173932211739 | Evaluating Time: 17 
Epoch: 26 | Iteration number: [10/4518] 0% | Training loss: 0.7565098166465759
Epoch: 26 | Iteration number: [20/4518] 0% | Training loss: 0.721710616350174
Epoch: 26 | Iteration number: [30/4518] 0% | Training loss: 0.7103313604990641
Epoch: 26 | Iteration number: [40/4518] 0% | Training loss: 0.7041736736893653
Epoch: 26 | Iteration number: [50/4518] 1% | Training loss: 0.7007011723518372
Epoch: 26 | Iteration number: [60/4518] 1% | Training loss: 0.6985057651996612
Epoch: 26 | Iteration number: [70/4518] 1% | Training loss: 0.6969118331159864
Epoch: 26 | Iteration number: [80/4518] 1% | Training loss: 0.6956588245928288
Epoch: 26 | Iteration number: [90/4518] 1% | Training loss: 0.6946575972768996
Epoch: 26 | Iteration number: [100/4518] 2% | Training loss: 0.6938663321733475
Epoch: 26 | Iteration number: [110/4518] 2% | Training loss: 0.6931889024647799
Epoch: 26 | Iteration number: [120/4518] 2% | Training loss: 0.6927604426940283
Epoch: 26 | Iteration number: [130/4518] 2% | Training loss: 0.6923419677294218
Epoch: 26 | Iteration number: [140/4518] 3% | Training loss: 0.6919466644525528
Epoch: 26 | Iteration number: [150/4518] 3% | Training loss: 0.691637032032013
Epoch: 26 | Iteration number: [160/4518] 3% | Training loss: 0.691285989806056
Epoch: 26 | Iteration number: [170/4518] 3% | Training loss: 0.691004097812316
Epoch: 26 | Iteration number: [180/4518] 3% | Training loss: 0.6908042093118032
Epoch: 26 | Iteration number: [190/4518] 4% | Training loss: 0.6906126301539571
Epoch: 26 | Iteration number: [200/4518] 4% | Training loss: 0.6903764566779137
Epoch: 26 | Iteration number: [210/4518] 4% | Training loss: 0.6901858264491672
Epoch: 26 | Iteration number: [220/4518] 4% | Training loss: 0.6899900514971126
Epoch: 26 | Iteration number: [230/4518] 5% | Training loss: 0.689888638517131
Epoch: 26 | Iteration number: [240/4518] 5% | Training loss: 0.6897822491824627
Epoch: 26 | Iteration number: [250/4518] 5% | Training loss: 0.6896791739463806
Epoch: 26 | Iteration number: [260/4518] 5% | Training loss: 0.6896099081406226
Epoch: 26 | Iteration number: [270/4518] 5% | Training loss: 0.6895532665429291
Epoch: 26 | Iteration number: [280/4518] 6% | Training loss: 0.6894317746162415
Epoch: 26 | Iteration number: [290/4518] 6% | Training loss: 0.689329822310086
Epoch: 26 | Iteration number: [300/4518] 6% | Training loss: 0.6892572544018427
Epoch: 26 | Iteration number: [310/4518] 6% | Training loss: 0.689198878888161
Epoch: 26 | Iteration number: [320/4518] 7% | Training loss: 0.6891518384218216
Epoch: 26 | Iteration number: [330/4518] 7% | Training loss: 0.6891089361725431
Epoch: 26 | Iteration number: [340/4518] 7% | Training loss: 0.6890521135400324
Epoch: 26 | Iteration number: [350/4518] 7% | Training loss: 0.6889828365189689
Epoch: 26 | Iteration number: [360/4518] 7% | Training loss: 0.6889505161179437
Epoch: 26 | Iteration number: [370/4518] 8% | Training loss: 0.6888983794160791
Epoch: 26 | Iteration number: [380/4518] 8% | Training loss: 0.6888448047010522
Epoch: 26 | Iteration number: [390/4518] 8% | Training loss: 0.6887653737496107
Epoch: 26 | Iteration number: [400/4518] 8% | Training loss: 0.6887046347558499
Epoch: 26 | Iteration number: [410/4518] 9% | Training loss: 0.6886597560673225
Epoch: 26 | Iteration number: [420/4518] 9% | Training loss: 0.6886347908349264
Epoch: 26 | Iteration number: [430/4518] 9% | Training loss: 0.6886242521363636
Epoch: 26 | Iteration number: [440/4518] 9% | Training loss: 0.6885759047486565
Epoch: 26 | Iteration number: [450/4518] 9% | Training loss: 0.6885494699743059
Epoch: 26 | Iteration number: [460/4518] 10% | Training loss: 0.688519482249799
Epoch: 26 | Iteration number: [470/4518] 10% | Training loss: 0.688462702264177
Epoch: 26 | Iteration number: [480/4518] 10% | Training loss: 0.688416833182176
Epoch: 26 | Iteration number: [490/4518] 10% | Training loss: 0.6884040754668567
Epoch: 26 | Iteration number: [500/4518] 11% | Training loss: 0.6883886690139771
Epoch: 26 | Iteration number: [510/4518] 11% | Training loss: 0.6883834513963437
Epoch: 26 | Iteration number: [520/4518] 11% | Training loss: 0.6883843026482142
Epoch: 26 | Iteration number: [530/4518] 11% | Training loss: 0.688358344446938
Epoch: 26 | Iteration number: [540/4518] 11% | Training loss: 0.6883465070415427
Epoch: 26 | Iteration number: [550/4518] 12% | Training loss: 0.6883282088149678
Epoch: 26 | Iteration number: [560/4518] 12% | Training loss: 0.6883308837456362
Epoch: 26 | Iteration number: [570/4518] 12% | Training loss: 0.6883176236821894
Epoch: 26 | Iteration number: [580/4518] 12% | Training loss: 0.6882968273656122
Epoch: 26 | Iteration number: [590/4518] 13% | Training loss: 0.6882637414891841
Epoch: 26 | Iteration number: [600/4518] 13% | Training loss: 0.688247311313947
Epoch: 26 | Iteration number: [610/4518] 13% | Training loss: 0.6882185777679819
Epoch: 26 | Iteration number: [620/4518] 13% | Training loss: 0.6881848506389125
Epoch: 26 | Iteration number: [630/4518] 13% | Training loss: 0.6881555933800955
Epoch: 26 | Iteration number: [640/4518] 14% | Training loss: 0.6881174734793604
Epoch: 26 | Iteration number: [650/4518] 14% | Training loss: 0.6881077319842118
Epoch: 26 | Iteration number: [660/4518] 14% | Training loss: 0.6880718673720504
Epoch: 26 | Iteration number: [670/4518] 14% | Training loss: 0.6880435631346347
Epoch: 26 | Iteration number: [680/4518] 15% | Training loss: 0.6880538582801818
Epoch: 26 | Iteration number: [690/4518] 15% | Training loss: 0.6880347460940264
Epoch: 26 | Iteration number: [700/4518] 15% | Training loss: 0.6880243918725423
Epoch: 26 | Iteration number: [710/4518] 15% | Training loss: 0.6880145392787289
Epoch: 26 | Iteration number: [720/4518] 15% | Training loss: 0.6880132671859529
Epoch: 26 | Iteration number: [730/4518] 16% | Training loss: 0.6880045347834287
Epoch: 26 | Iteration number: [740/4518] 16% | Training loss: 0.6879758910552876
Epoch: 26 | Iteration number: [750/4518] 16% | Training loss: 0.6879601105848948
Epoch: 26 | Iteration number: [760/4518] 16% | Training loss: 0.6879404451501997
Epoch: 26 | Iteration number: [770/4518] 17% | Training loss: 0.6879370665395415
Epoch: 26 | Iteration number: [780/4518] 17% | Training loss: 0.6879338454741698
Epoch: 26 | Iteration number: [790/4518] 17% | Training loss: 0.6879303306718416
Epoch: 26 | Iteration number: [800/4518] 17% | Training loss: 0.6879222278296947
Epoch: 26 | Iteration number: [810/4518] 17% | Training loss: 0.6879017105808964
Epoch: 26 | Iteration number: [820/4518] 18% | Training loss: 0.687894341494979
Epoch: 26 | Iteration number: [830/4518] 18% | Training loss: 0.6878820916256273
Epoch: 26 | Iteration number: [840/4518] 18% | Training loss: 0.6878524137394769
Epoch: 26 | Iteration number: [850/4518] 18% | Training loss: 0.687834426725612
Epoch: 26 | Iteration number: [860/4518] 19% | Training loss: 0.6878130183663479
Epoch: 26 | Iteration number: [870/4518] 19% | Training loss: 0.6877896924813588
Epoch: 26 | Iteration number: [880/4518] 19% | Training loss: 0.6877624239433896
Epoch: 26 | Iteration number: [890/4518] 19% | Training loss: 0.6877552593691966
Epoch: 26 | Iteration number: [900/4518] 19% | Training loss: 0.6877426946825451
Epoch: 26 | Iteration number: [910/4518] 20% | Training loss: 0.6877356243002546
Epoch: 26 | Iteration number: [920/4518] 20% | Training loss: 0.6877362775413887
Epoch: 26 | Iteration number: [930/4518] 20% | Training loss: 0.6877387619146736
Epoch: 26 | Iteration number: [940/4518] 20% | Training loss: 0.6877241449787261
Epoch: 26 | Iteration number: [950/4518] 21% | Training loss: 0.6877088729958786
Epoch: 26 | Iteration number: [960/4518] 21% | Training loss: 0.687691547224919
Epoch: 26 | Iteration number: [970/4518] 21% | Training loss: 0.6876835749321377
Epoch: 26 | Iteration number: [980/4518] 21% | Training loss: 0.68768112981806
Epoch: 26 | Iteration number: [990/4518] 21% | Training loss: 0.6876726501517826
Epoch: 26 | Iteration number: [1000/4518] 22% | Training loss: 0.6876791461110116
Epoch: 26 | Iteration number: [1010/4518] 22% | Training loss: 0.6876718557707154
Epoch: 26 | Iteration number: [1020/4518] 22% | Training loss: 0.6876476140583263
Epoch: 26 | Iteration number: [1030/4518] 22% | Training loss: 0.687643596963975
Epoch: 26 | Iteration number: [1040/4518] 23% | Training loss: 0.6876418138925846
Epoch: 26 | Iteration number: [1050/4518] 23% | Training loss: 0.6876351328690847
Epoch: 26 | Iteration number: [1060/4518] 23% | Training loss: 0.6876215578250165
Epoch: 26 | Iteration number: [1070/4518] 23% | Training loss: 0.6876079684105989
Epoch: 26 | Iteration number: [1080/4518] 23% | Training loss: 0.6875923486771407
Epoch: 26 | Iteration number: [1090/4518] 24% | Training loss: 0.6875822822435187
Epoch: 26 | Iteration number: [1100/4518] 24% | Training loss: 0.687576233365319
Epoch: 26 | Iteration number: [1110/4518] 24% | Training loss: 0.6875691324203937
Epoch: 26 | Iteration number: [1120/4518] 24% | Training loss: 0.6875543159033571
Epoch: 26 | Iteration number: [1130/4518] 25% | Training loss: 0.6875368806640659
Epoch: 26 | Iteration number: [1140/4518] 25% | Training loss: 0.6875467780912131
Epoch: 26 | Iteration number: [1150/4518] 25% | Training loss: 0.6875386614384859
Epoch: 26 | Iteration number: [1160/4518] 25% | Training loss: 0.6875322183658337
Epoch: 26 | Iteration number: [1170/4518] 25% | Training loss: 0.687532250646852
Epoch: 26 | Iteration number: [1180/4518] 26% | Training loss: 0.6875308438377865
Epoch: 26 | Iteration number: [1190/4518] 26% | Training loss: 0.6875265117452926
Epoch: 26 | Iteration number: [1200/4518] 26% | Training loss: 0.6875187800824643
Epoch: 26 | Iteration number: [1210/4518] 26% | Training loss: 0.6875231854186571
Epoch: 26 | Iteration number: [1220/4518] 27% | Training loss: 0.687510476933151
Epoch: 26 | Iteration number: [1230/4518] 27% | Training loss: 0.6875012194722648
Epoch: 26 | Iteration number: [1240/4518] 27% | Training loss: 0.6875018775463104
Epoch: 26 | Iteration number: [1250/4518] 27% | Training loss: 0.6875066555976868
Epoch: 26 | Iteration number: [1260/4518] 27% | Training loss: 0.6875079772302083
Epoch: 26 | Iteration number: [1270/4518] 28% | Training loss: 0.687493061362289
Epoch: 26 | Iteration number: [1280/4518] 28% | Training loss: 0.687481069425121
Epoch: 26 | Iteration number: [1290/4518] 28% | Training loss: 0.6874712499537209
Epoch: 26 | Iteration number: [1300/4518] 28% | Training loss: 0.6874715490524586
Epoch: 26 | Iteration number: [1310/4518] 28% | Training loss: 0.6874681334914142
Epoch: 26 | Iteration number: [1320/4518] 29% | Training loss: 0.6874602330001918
Epoch: 26 | Iteration number: [1330/4518] 29% | Training loss: 0.6874639557268386
Epoch: 26 | Iteration number: [1340/4518] 29% | Training loss: 0.6874465670603425
Epoch: 26 | Iteration number: [1350/4518] 29% | Training loss: 0.6874513709986652
Epoch: 26 | Iteration number: [1360/4518] 30% | Training loss: 0.6874514703364933
Epoch: 26 | Iteration number: [1370/4518] 30% | Training loss: 0.687446729893232
Epoch: 26 | Iteration number: [1380/4518] 30% | Training loss: 0.6874447708544524
Epoch: 26 | Iteration number: [1390/4518] 30% | Training loss: 0.6874393340066183
Epoch: 26 | Iteration number: [1400/4518] 30% | Training loss: 0.6874373547519956
Epoch: 26 | Iteration number: [1410/4518] 31% | Training loss: 0.6874319922839496
Epoch: 26 | Iteration number: [1420/4518] 31% | Training loss: 0.6874263640440685
Epoch: 26 | Iteration number: [1430/4518] 31% | Training loss: 0.6874196573987708
Epoch: 26 | Iteration number: [1440/4518] 31% | Training loss: 0.6874087649501033
Epoch: 26 | Iteration number: [1450/4518] 32% | Training loss: 0.6874110634162508
Epoch: 26 | Iteration number: [1460/4518] 32% | Training loss: 0.687411121677046
Epoch: 26 | Iteration number: [1470/4518] 32% | Training loss: 0.6874124567524916
Epoch: 26 | Iteration number: [1480/4518] 32% | Training loss: 0.6873999958505501
Epoch: 26 | Iteration number: [1490/4518] 32% | Training loss: 0.687397546056133
Epoch: 26 | Iteration number: [1500/4518] 33% | Training loss: 0.6874090111255646
Epoch: 26 | Iteration number: [1510/4518] 33% | Training loss: 0.6874119526503102
Epoch: 26 | Iteration number: [1520/4518] 33% | Training loss: 0.6874040176993922
Epoch: 26 | Iteration number: [1530/4518] 33% | Training loss: 0.6874034447997224
Epoch: 26 | Iteration number: [1540/4518] 34% | Training loss: 0.6873972871860901
Epoch: 26 | Iteration number: [1550/4518] 34% | Training loss: 0.6873991892414708
Epoch: 26 | Iteration number: [1560/4518] 34% | Training loss: 0.6873941138004646
Epoch: 26 | Iteration number: [1570/4518] 34% | Training loss: 0.6873923959246107
Epoch: 26 | Iteration number: [1580/4518] 34% | Training loss: 0.6873876271368582
Epoch: 26 | Iteration number: [1590/4518] 35% | Training loss: 0.6873815966102312
Epoch: 26 | Iteration number: [1600/4518] 35% | Training loss: 0.6873766174539924
Epoch: 26 | Iteration number: [1610/4518] 35% | Training loss: 0.6873685770893689
Epoch: 26 | Iteration number: [1620/4518] 35% | Training loss: 0.6873602865286815
Epoch: 26 | Iteration number: [1630/4518] 36% | Training loss: 0.6873573326625707
Epoch: 26 | Iteration number: [1640/4518] 36% | Training loss: 0.6873465227644618
Epoch: 26 | Iteration number: [1650/4518] 36% | Training loss: 0.6873397141875642
Epoch: 26 | Iteration number: [1660/4518] 36% | Training loss: 0.6873332175145667
Epoch: 26 | Iteration number: [1670/4518] 36% | Training loss: 0.6873330787270369
Epoch: 26 | Iteration number: [1680/4518] 37% | Training loss: 0.6873257169411295
Epoch: 26 | Iteration number: [1690/4518] 37% | Training loss: 0.6873226424646095
Epoch: 26 | Iteration number: [1700/4518] 37% | Training loss: 0.6873240102739895
Epoch: 26 | Iteration number: [1710/4518] 37% | Training loss: 0.6873245805327656
Epoch: 26 | Iteration number: [1720/4518] 38% | Training loss: 0.6873178971021674
Epoch: 26 | Iteration number: [1730/4518] 38% | Training loss: 0.6873142182826996
Epoch: 26 | Iteration number: [1740/4518] 38% | Training loss: 0.6873085011695993
Epoch: 26 | Iteration number: [1750/4518] 38% | Training loss: 0.687305721282959
Epoch: 26 | Iteration number: [1760/4518] 38% | Training loss: 0.6873051315546036
Epoch: 26 | Iteration number: [1770/4518] 39% | Training loss: 0.687301156244709
Epoch: 26 | Iteration number: [1780/4518] 39% | Training loss: 0.6872941460837139
Epoch: 26 | Iteration number: [1790/4518] 39% | Training loss: 0.687293273576811
Epoch: 26 | Iteration number: [1800/4518] 39% | Training loss: 0.6872888419032097
Epoch: 26 | Iteration number: [1810/4518] 40% | Training loss: 0.6872871016270548
Epoch: 26 | Iteration number: [1820/4518] 40% | Training loss: 0.6872861735113375
Epoch: 26 | Iteration number: [1830/4518] 40% | Training loss: 0.68728177785222
Epoch: 26 | Iteration number: [1840/4518] 40% | Training loss: 0.6872808871709782
Epoch: 26 | Iteration number: [1850/4518] 40% | Training loss: 0.6872774439889031
Epoch: 26 | Iteration number: [1860/4518] 41% | Training loss: 0.6872800651416984
Epoch: 26 | Iteration number: [1870/4518] 41% | Training loss: 0.6872776304018051
Epoch: 26 | Iteration number: [1880/4518] 41% | Training loss: 0.68727802136477
Epoch: 26 | Iteration number: [1890/4518] 41% | Training loss: 0.6872713693550655
Epoch: 26 | Iteration number: [1900/4518] 42% | Training loss: 0.6872684097290039
Epoch: 26 | Iteration number: [1910/4518] 42% | Training loss: 0.6872670950377798
Epoch: 26 | Iteration number: [1920/4518] 42% | Training loss: 0.6872598586293558
Epoch: 26 | Iteration number: [1930/4518] 42% | Training loss: 0.6872559662618786
Epoch: 26 | Iteration number: [1940/4518] 42% | Training loss: 0.687253372509455
Epoch: 26 | Iteration number: [1950/4518] 43% | Training loss: 0.6872537004641998
Epoch: 26 | Iteration number: [1960/4518] 43% | Training loss: 0.687253728204844
Epoch: 26 | Iteration number: [1970/4518] 43% | Training loss: 0.6872492332143832
Epoch: 26 | Iteration number: [1980/4518] 43% | Training loss: 0.6872512817984879
Epoch: 26 | Iteration number: [1990/4518] 44% | Training loss: 0.6872550729830661
Epoch: 26 | Iteration number: [2000/4518] 44% | Training loss: 0.6872556935250759
Epoch: 26 | Iteration number: [2010/4518] 44% | Training loss: 0.6872477609423262
Epoch: 26 | Iteration number: [2020/4518] 44% | Training loss: 0.6872391479145182
Epoch: 26 | Iteration number: [2030/4518] 44% | Training loss: 0.6872362177653853
Epoch: 26 | Iteration number: [2040/4518] 45% | Training loss: 0.6872337673809014
Epoch: 26 | Iteration number: [2050/4518] 45% | Training loss: 0.6872310435190433
Epoch: 26 | Iteration number: [2060/4518] 45% | Training loss: 0.6872290889614994
Epoch: 26 | Iteration number: [2070/4518] 45% | Training loss: 0.6872290169847184
Epoch: 26 | Iteration number: [2080/4518] 46% | Training loss: 0.6872256224258588
Epoch: 26 | Iteration number: [2090/4518] 46% | Training loss: 0.6872252428930913
Epoch: 26 | Iteration number: [2100/4518] 46% | Training loss: 0.6872259285904112
Epoch: 26 | Iteration number: [2110/4518] 46% | Training loss: 0.6872185428843114
Epoch: 26 | Iteration number: [2120/4518] 46% | Training loss: 0.6872141075865278
Epoch: 26 | Iteration number: [2130/4518] 47% | Training loss: 0.6872151457927597
Epoch: 26 | Iteration number: [2140/4518] 47% | Training loss: 0.6872055938589239
Epoch: 26 | Iteration number: [2150/4518] 47% | Training loss: 0.6871991571437481
Epoch: 26 | Iteration number: [2160/4518] 47% | Training loss: 0.6871979530486796
Epoch: 26 | Iteration number: [2170/4518] 48% | Training loss: 0.687191882358718
Epoch: 26 | Iteration number: [2180/4518] 48% | Training loss: 0.6871933227011917
Epoch: 26 | Iteration number: [2190/4518] 48% | Training loss: 0.6871886353786677
Epoch: 26 | Iteration number: [2200/4518] 48% | Training loss: 0.6871824937516993
Epoch: 26 | Iteration number: [2210/4518] 48% | Training loss: 0.6871806872646193
Epoch: 26 | Iteration number: [2220/4518] 49% | Training loss: 0.6871802082469871
Epoch: 26 | Iteration number: [2230/4518] 49% | Training loss: 0.6871796561196246
Epoch: 26 | Iteration number: [2240/4518] 49% | Training loss: 0.6871802912226745
Epoch: 26 | Iteration number: [2250/4518] 49% | Training loss: 0.6871775081422594
Epoch: 26 | Iteration number: [2260/4518] 50% | Training loss: 0.6871743869465009
Epoch: 26 | Iteration number: [2270/4518] 50% | Training loss: 0.6871735163197118
Epoch: 26 | Iteration number: [2280/4518] 50% | Training loss: 0.6871701059111378
Epoch: 26 | Iteration number: [2290/4518] 50% | Training loss: 0.6871618192268771
Epoch: 26 | Iteration number: [2300/4518] 50% | Training loss: 0.6871596221301867
Epoch: 26 | Iteration number: [2310/4518] 51% | Training loss: 0.6871554952679259
Epoch: 26 | Iteration number: [2320/4518] 51% | Training loss: 0.6871590459911988
Epoch: 26 | Iteration number: [2330/4518] 51% | Training loss: 0.6871563665344992
Epoch: 26 | Iteration number: [2340/4518] 51% | Training loss: 0.6871594468497823
Epoch: 26 | Iteration number: [2350/4518] 52% | Training loss: 0.6871566268231006
Epoch: 26 | Iteration number: [2360/4518] 52% | Training loss: 0.6871548258904684
Epoch: 26 | Iteration number: [2370/4518] 52% | Training loss: 0.687153978086222
Epoch: 26 | Iteration number: [2380/4518] 52% | Training loss: 0.6871600739595269
Epoch: 26 | Iteration number: [2390/4518] 52% | Training loss: 0.6871558169690136
Epoch: 26 | Iteration number: [2400/4518] 53% | Training loss: 0.6871564222872257
Epoch: 26 | Iteration number: [2410/4518] 53% | Training loss: 0.6871568840321663
Epoch: 26 | Iteration number: [2420/4518] 53% | Training loss: 0.6871560164719573
Epoch: 26 | Iteration number: [2430/4518] 53% | Training loss: 0.6871554179691974
Epoch: 26 | Iteration number: [2440/4518] 54% | Training loss: 0.6871532839096961
Epoch: 26 | Iteration number: [2450/4518] 54% | Training loss: 0.6871511171302017
Epoch: 26 | Iteration number: [2460/4518] 54% | Training loss: 0.6871497682439602
Epoch: 26 | Iteration number: [2470/4518] 54% | Training loss: 0.6871477445851454
Epoch: 26 | Iteration number: [2480/4518] 54% | Training loss: 0.6871421010023163
Epoch: 26 | Iteration number: [2490/4518] 55% | Training loss: 0.6871383591109969
Epoch: 26 | Iteration number: [2500/4518] 55% | Training loss: 0.68713731777668
Epoch: 26 | Iteration number: [2510/4518] 55% | Training loss: 0.687135891016736
Epoch: 26 | Iteration number: [2520/4518] 55% | Training loss: 0.6871358813984053
Epoch: 26 | Iteration number: [2530/4518] 55% | Training loss: 0.6871339189912019
Epoch: 26 | Iteration number: [2540/4518] 56% | Training loss: 0.6871327263633097
Epoch: 26 | Iteration number: [2550/4518] 56% | Training loss: 0.6871336239225724
Epoch: 26 | Iteration number: [2560/4518] 56% | Training loss: 0.6871387896826491
Epoch: 26 | Iteration number: [2570/4518] 56% | Training loss: 0.6871388529525193
Epoch: 26 | Iteration number: [2580/4518] 57% | Training loss: 0.6871363660854887
Epoch: 26 | Iteration number: [2590/4518] 57% | Training loss: 0.6871307810991427
Epoch: 26 | Iteration number: [2600/4518] 57% | Training loss: 0.6871255588989992
Epoch: 26 | Iteration number: [2610/4518] 57% | Training loss: 0.6871252669685188
Epoch: 26 | Iteration number: [2620/4518] 57% | Training loss: 0.6871194462512286
Epoch: 26 | Iteration number: [2630/4518] 58% | Training loss: 0.6871160605334511
Epoch: 26 | Iteration number: [2640/4518] 58% | Training loss: 0.6871192555761698
Epoch: 26 | Iteration number: [2650/4518] 58% | Training loss: 0.6871199464797973
Epoch: 26 | Iteration number: [2660/4518] 58% | Training loss: 0.6871187031044996
Epoch: 26 | Iteration number: [2670/4518] 59% | Training loss: 0.6871155858039856
Epoch: 26 | Iteration number: [2680/4518] 59% | Training loss: 0.6871137204010095
Epoch: 26 | Iteration number: [2690/4518] 59% | Training loss: 0.6871135968701104
Epoch: 26 | Iteration number: [2700/4518] 59% | Training loss: 0.687113271024492
Epoch: 26 | Iteration number: [2710/4518] 59% | Training loss: 0.6871114760527312
Epoch: 26 | Iteration number: [2720/4518] 60% | Training loss: 0.6871124007903477
Epoch: 26 | Iteration number: [2730/4518] 60% | Training loss: 0.6871142660960173
Epoch: 26 | Iteration number: [2740/4518] 60% | Training loss: 0.6871144100914907
Epoch: 26 | Iteration number: [2750/4518] 60% | Training loss: 0.687117348020727
Epoch: 26 | Iteration number: [2760/4518] 61% | Training loss: 0.6871167717420537
Epoch: 26 | Iteration number: [2770/4518] 61% | Training loss: 0.6871206933840948
Epoch: 26 | Iteration number: [2780/4518] 61% | Training loss: 0.6871199884646231
Epoch: 26 | Iteration number: [2790/4518] 61% | Training loss: 0.6871198641997511
Epoch: 26 | Iteration number: [2800/4518] 61% | Training loss: 0.6871213360982282
Epoch: 26 | Iteration number: [2810/4518] 62% | Training loss: 0.6871198638690325
Epoch: 26 | Iteration number: [2820/4518] 62% | Training loss: 0.68712059838552
Epoch: 26 | Iteration number: [2830/4518] 62% | Training loss: 0.6871175610977011
Epoch: 26 | Iteration number: [2840/4518] 62% | Training loss: 0.6871199078962836
Epoch: 26 | Iteration number: [2850/4518] 63% | Training loss: 0.6871209077667771
Epoch: 26 | Iteration number: [2860/4518] 63% | Training loss: 0.6871162087142051
Epoch: 26 | Iteration number: [2870/4518] 63% | Training loss: 0.6871157795917697
Epoch: 26 | Iteration number: [2880/4518] 63% | Training loss: 0.6871124053166973
Epoch: 26 | Iteration number: [2890/4518] 63% | Training loss: 0.6871064298705659
Epoch: 26 | Iteration number: [2900/4518] 64% | Training loss: 0.6871053075379339
Epoch: 26 | Iteration number: [2910/4518] 64% | Training loss: 0.687106834736067
Epoch: 26 | Iteration number: [2920/4518] 64% | Training loss: 0.68710790209166
Epoch: 26 | Iteration number: [2930/4518] 64% | Training loss: 0.6871049469851797
Epoch: 26 | Iteration number: [2940/4518] 65% | Training loss: 0.6871075791363813
Epoch: 26 | Iteration number: [2950/4518] 65% | Training loss: 0.6871039385916823
Epoch: 26 | Iteration number: [2960/4518] 65% | Training loss: 0.6870988876231618
Epoch: 26 | Iteration number: [2970/4518] 65% | Training loss: 0.6870997966941358
Epoch: 26 | Iteration number: [2980/4518] 65% | Training loss: 0.6870950826462483
Epoch: 26 | Iteration number: [2990/4518] 66% | Training loss: 0.6870910733838543
Epoch: 26 | Iteration number: [3000/4518] 66% | Training loss: 0.6870893496274948
Epoch: 26 | Iteration number: [3010/4518] 66% | Training loss: 0.6870863408543343
Epoch: 26 | Iteration number: [3020/4518] 66% | Training loss: 0.6870879956625945
Epoch: 26 | Iteration number: [3030/4518] 67% | Training loss: 0.6870878015217607
Epoch: 26 | Iteration number: [3040/4518] 67% | Training loss: 0.6870835040744983
Epoch: 26 | Iteration number: [3050/4518] 67% | Training loss: 0.687085484031771
Epoch: 26 | Iteration number: [3060/4518] 67% | Training loss: 0.6870870458144768
Epoch: 26 | Iteration number: [3070/4518] 67% | Training loss: 0.6870865776406826
Epoch: 26 | Iteration number: [3080/4518] 68% | Training loss: 0.6870850571564265
Epoch: 26 | Iteration number: [3090/4518] 68% | Training loss: 0.687082946898482
Epoch: 26 | Iteration number: [3100/4518] 68% | Training loss: 0.6870856711749107
Epoch: 26 | Iteration number: [3110/4518] 68% | Training loss: 0.6870868060558172
Epoch: 26 | Iteration number: [3120/4518] 69% | Training loss: 0.6870846982376698
Epoch: 26 | Iteration number: [3130/4518] 69% | Training loss: 0.6870804147788891
Epoch: 26 | Iteration number: [3140/4518] 69% | Training loss: 0.6870790872604224
Epoch: 26 | Iteration number: [3150/4518] 69% | Training loss: 0.6870792521181561
Epoch: 26 | Iteration number: [3160/4518] 69% | Training loss: 0.6870816349417348
Epoch: 26 | Iteration number: [3170/4518] 70% | Training loss: 0.6870869894133005
Epoch: 26 | Iteration number: [3180/4518] 70% | Training loss: 0.6870849685848884
Epoch: 26 | Iteration number: [3190/4518] 70% | Training loss: 0.6870847198096188
Epoch: 26 | Iteration number: [3200/4518] 70% | Training loss: 0.6870856695622206
Epoch: 26 | Iteration number: [3210/4518] 71% | Training loss: 0.6870845446334078
Epoch: 26 | Iteration number: [3220/4518] 71% | Training loss: 0.6870859503560925
Epoch: 26 | Iteration number: [3230/4518] 71% | Training loss: 0.6870873064079521
Epoch: 26 | Iteration number: [3240/4518] 71% | Training loss: 0.6870841546007145
Epoch: 26 | Iteration number: [3250/4518] 71% | Training loss: 0.6870870105303251
Epoch: 26 | Iteration number: [3260/4518] 72% | Training loss: 0.6870857699334256
Epoch: 26 | Iteration number: [3270/4518] 72% | Training loss: 0.6870859836401925
Epoch: 26 | Iteration number: [3280/4518] 72% | Training loss: 0.6870813862761346
Epoch: 26 | Iteration number: [3290/4518] 72% | Training loss: 0.687079641268246
Epoch: 26 | Iteration number: [3300/4518] 73% | Training loss: 0.6870763145974188
Epoch: 26 | Iteration number: [3310/4518] 73% | Training loss: 0.6870756987718657
Epoch: 26 | Iteration number: [3320/4518] 73% | Training loss: 0.6870750019349248
Epoch: 26 | Iteration number: [3330/4518] 73% | Training loss: 0.6870768360368482
Epoch: 26 | Iteration number: [3340/4518] 73% | Training loss: 0.687075906313822
Epoch: 26 | Iteration number: [3350/4518] 74% | Training loss: 0.6870757894373651
Epoch: 26 | Iteration number: [3360/4518] 74% | Training loss: 0.6870777774956964
Epoch: 26 | Iteration number: [3370/4518] 74% | Training loss: 0.687076202450591
Epoch: 26 | Iteration number: [3380/4518] 74% | Training loss: 0.6870779582029264
Epoch: 26 | Iteration number: [3390/4518] 75% | Training loss: 0.6870776165727317
Epoch: 26 | Iteration number: [3400/4518] 75% | Training loss: 0.6870800336494165
Epoch: 26 | Iteration number: [3410/4518] 75% | Training loss: 0.6870775391279428
Epoch: 26 | Iteration number: [3420/4518] 75% | Training loss: 0.6870767331262778
Epoch: 26 | Iteration number: [3430/4518] 75% | Training loss: 0.6870731748054049
Epoch: 26 | Iteration number: [3440/4518] 76% | Training loss: 0.6870766941717891
Epoch: 26 | Iteration number: [3450/4518] 76% | Training loss: 0.6870736735627271
Epoch: 26 | Iteration number: [3460/4518] 76% | Training loss: 0.687077051883488
Epoch: 26 | Iteration number: [3470/4518] 76% | Training loss: 0.6870768827560656
Epoch: 26 | Iteration number: [3480/4518] 77% | Training loss: 0.6870771583298158
Epoch: 26 | Iteration number: [3490/4518] 77% | Training loss: 0.6870790917244887
Epoch: 26 | Iteration number: [3500/4518] 77% | Training loss: 0.6870774819510324
Epoch: 26 | Iteration number: [3510/4518] 77% | Training loss: 0.6870754155677947
Epoch: 26 | Iteration number: [3520/4518] 77% | Training loss: 0.6870724683627486
Epoch: 26 | Iteration number: [3530/4518] 78% | Training loss: 0.687070606129703
Epoch: 26 | Iteration number: [3540/4518] 78% | Training loss: 0.6870691307520462
Epoch: 26 | Iteration number: [3550/4518] 78% | Training loss: 0.6870702757801808
Epoch: 26 | Iteration number: [3560/4518] 78% | Training loss: 0.6870723368244225
Epoch: 26 | Iteration number: [3570/4518] 79% | Training loss: 0.687071501123471
Epoch: 26 | Iteration number: [3580/4518] 79% | Training loss: 0.6870700679178344
Epoch: 26 | Iteration number: [3590/4518] 79% | Training loss: 0.6870730972887745
Epoch: 26 | Iteration number: [3600/4518] 79% | Training loss: 0.6870729955368572
Epoch: 26 | Iteration number: [3610/4518] 79% | Training loss: 0.6870698785352575
Epoch: 26 | Iteration number: [3620/4518] 80% | Training loss: 0.6870712357331376
Epoch: 26 | Iteration number: [3630/4518] 80% | Training loss: 0.6870728939361151
Epoch: 26 | Iteration number: [3640/4518] 80% | Training loss: 0.6870712806562801
Epoch: 26 | Iteration number: [3650/4518] 80% | Training loss: 0.6870690354908983
Epoch: 26 | Iteration number: [3660/4518] 81% | Training loss: 0.6870694834026483
Epoch: 26 | Iteration number: [3670/4518] 81% | Training loss: 0.6870685824256502
Epoch: 26 | Iteration number: [3680/4518] 81% | Training loss: 0.6870710307975179
Epoch: 26 | Iteration number: [3690/4518] 81% | Training loss: 0.6870720829582473
Epoch: 26 | Iteration number: [3700/4518] 81% | Training loss: 0.6870714524146673
Epoch: 26 | Iteration number: [3710/4518] 82% | Training loss: 0.6870694676499483
Epoch: 26 | Iteration number: [3720/4518] 82% | Training loss: 0.6870686538437362
Epoch: 26 | Iteration number: [3730/4518] 82% | Training loss: 0.6870656521166937
Epoch: 26 | Iteration number: [3740/4518] 82% | Training loss: 0.6870655911332145
Epoch: 26 | Iteration number: [3750/4518] 83% | Training loss: 0.6870656888802846
Epoch: 26 | Iteration number: [3760/4518] 83% | Training loss: 0.6870679779572689
Epoch: 26 | Iteration number: [3770/4518] 83% | Training loss: 0.6870661198302352
Epoch: 26 | Iteration number: [3780/4518] 83% | Training loss: 0.6870659752182229
Epoch: 26 | Iteration number: [3790/4518] 83% | Training loss: 0.6870665870272704
Epoch: 26 | Iteration number: [3800/4518] 84% | Training loss: 0.6870656870070256
Epoch: 26 | Iteration number: [3810/4518] 84% | Training loss: 0.6870654763512098
Epoch: 26 | Iteration number: [3820/4518] 84% | Training loss: 0.6870645809392031
Epoch: 26 | Iteration number: [3830/4518] 84% | Training loss: 0.6870684469181937
Epoch: 26 | Iteration number: [3840/4518] 84% | Training loss: 0.687064164954548
Epoch: 26 | Iteration number: [3850/4518] 85% | Training loss: 0.6870690832974075
Epoch: 26 | Iteration number: [3860/4518] 85% | Training loss: 0.6870717666618564
Epoch: 26 | Iteration number: [3870/4518] 85% | Training loss: 0.6870705418192447
Epoch: 26 | Iteration number: [3880/4518] 85% | Training loss: 0.6870719689683816
Epoch: 26 | Iteration number: [3890/4518] 86% | Training loss: 0.6870724494475632
Epoch: 26 | Iteration number: [3900/4518] 86% | Training loss: 0.6870678352698302
Epoch: 26 | Iteration number: [3910/4518] 86% | Training loss: 0.6870667801336254
Epoch: 26 | Iteration number: [3920/4518] 86% | Training loss: 0.6870666481250403
Epoch: 26 | Iteration number: [3930/4518] 86% | Training loss: 0.6870683757706756
Epoch: 26 | Iteration number: [3940/4518] 87% | Training loss: 0.6870663533658545
Epoch: 26 | Iteration number: [3950/4518] 87% | Training loss: 0.6870672624473331
Epoch: 26 | Iteration number: [3960/4518] 87% | Training loss: 0.6870670848723613
Epoch: 26 | Iteration number: [3970/4518] 87% | Training loss: 0.6870645871390624
Epoch: 26 | Iteration number: [3980/4518] 88% | Training loss: 0.6870635826683523
Epoch: 26 | Iteration number: [3990/4518] 88% | Training loss: 0.6870620224260746
Epoch: 26 | Iteration number: [4000/4518] 88% | Training loss: 0.6870632084906101
Epoch: 26 | Iteration number: [4010/4518] 88% | Training loss: 0.6870630117128614
Epoch: 26 | Iteration number: [4020/4518] 88% | Training loss: 0.6870615201061638
Epoch: 26 | Iteration number: [4030/4518] 89% | Training loss: 0.6870595763989773
Epoch: 26 | Iteration number: [4040/4518] 89% | Training loss: 0.6870577565219143
Epoch: 26 | Iteration number: [4050/4518] 89% | Training loss: 0.6870555170965783
Epoch: 26 | Iteration number: [4060/4518] 89% | Training loss: 0.6870552241508596
Epoch: 26 | Iteration number: [4070/4518] 90% | Training loss: 0.6870552127718632
Epoch: 26 | Iteration number: [4080/4518] 90% | Training loss: 0.6870556785779841
Epoch: 26 | Iteration number: [4090/4518] 90% | Training loss: 0.6870569885214267
Epoch: 26 | Iteration number: [4100/4518] 90% | Training loss: 0.6870539670310369
Epoch: 26 | Iteration number: [4110/4518] 90% | Training loss: 0.6870513014984827
Epoch: 26 | Iteration number: [4120/4518] 91% | Training loss: 0.687048163330092
Epoch: 26 | Iteration number: [4130/4518] 91% | Training loss: 0.6870461125783712
Epoch: 26 | Iteration number: [4140/4518] 91% | Training loss: 0.6870447071710071
Epoch: 26 | Iteration number: [4150/4518] 91% | Training loss: 0.687042659320027
Epoch: 26 | Iteration number: [4160/4518] 92% | Training loss: 0.6870437753888277
Epoch: 26 | Iteration number: [4170/4518] 92% | Training loss: 0.6870423930726177
Epoch: 26 | Iteration number: [4180/4518] 92% | Training loss: 0.6870400456435373
Epoch: 26 | Iteration number: [4190/4518] 92% | Training loss: 0.6870398655142591
Epoch: 26 | Iteration number: [4200/4518] 92% | Training loss: 0.6870370228091875
Epoch: 26 | Iteration number: [4210/4518] 93% | Training loss: 0.6870365720463478
Epoch: 26 | Iteration number: [4220/4518] 93% | Training loss: 0.6870334296147406
Epoch: 26 | Iteration number: [4230/4518] 93% | Training loss: 0.6870318618226559
Epoch: 26 | Iteration number: [4240/4518] 93% | Training loss: 0.6870299428420247
Epoch: 26 | Iteration number: [4250/4518] 94% | Training loss: 0.6870289171022528
Epoch: 26 | Iteration number: [4260/4518] 94% | Training loss: 0.6870309643762212
Epoch: 26 | Iteration number: [4270/4518] 94% | Training loss: 0.6870271573301221
Epoch: 26 | Iteration number: [4280/4518] 94% | Training loss: 0.6870313451251137
Epoch: 26 | Iteration number: [4290/4518] 94% | Training loss: 0.6870302796085953
Epoch: 26 | Iteration number: [4300/4518] 95% | Training loss: 0.6870301351574964
Epoch: 26 | Iteration number: [4310/4518] 95% | Training loss: 0.6870310736366325
Epoch: 26 | Iteration number: [4320/4518] 95% | Training loss: 0.6870274300652521
Epoch: 26 | Iteration number: [4330/4518] 95% | Training loss: 0.6870282859780221
Epoch: 26 | Iteration number: [4340/4518] 96% | Training loss: 0.6870277528389258
Epoch: 26 | Iteration number: [4350/4518] 96% | Training loss: 0.6870283867983983
Epoch: 26 | Iteration number: [4360/4518] 96% | Training loss: 0.6870295227257484
Epoch: 26 | Iteration number: [4370/4518] 96% | Training loss: 0.6870270184712225
Epoch: 26 | Iteration number: [4380/4518] 96% | Training loss: 0.6870276795946844
Epoch: 26 | Iteration number: [4390/4518] 97% | Training loss: 0.6870282916517627
Epoch: 26 | Iteration number: [4400/4518] 97% | Training loss: 0.6870272407613017
Epoch: 26 | Iteration number: [4410/4518] 97% | Training loss: 0.687028301059524
Epoch: 26 | Iteration number: [4420/4518] 97% | Training loss: 0.6870276383819623
Epoch: 26 | Iteration number: [4430/4518] 98% | Training loss: 0.6870305354250742
Epoch: 26 | Iteration number: [4440/4518] 98% | Training loss: 0.6870311542539983
Epoch: 26 | Iteration number: [4450/4518] 98% | Training loss: 0.6870270044750042
Epoch: 26 | Iteration number: [4460/4518] 98% | Training loss: 0.6870290554291464
Epoch: 26 | Iteration number: [4470/4518] 98% | Training loss: 0.6870313714147948
Epoch: 26 | Iteration number: [4480/4518] 99% | Training loss: 0.6870322095762406
Epoch: 26 | Iteration number: [4490/4518] 99% | Training loss: 0.6870290372578763
Epoch: 26 | Iteration number: [4500/4518] 99% | Training loss: 0.6870279087490505
Epoch: 26 | Iteration number: [4510/4518] 99% | Training loss: 0.6870279973467808

 End of epoch: 26 | Train Loss: 0.686877367334484 | Training Time: 641 

 End of epoch: 26 | Eval Loss: 0.6901235008726314 | Evaluating Time: 17 
Epoch: 27 | Iteration number: [10/4518] 0% | Training loss: 0.756156712770462
Epoch: 27 | Iteration number: [20/4518] 0% | Training loss: 0.7218899369239807
Epoch: 27 | Iteration number: [30/4518] 0% | Training loss: 0.7099777539571126
Epoch: 27 | Iteration number: [40/4518] 0% | Training loss: 0.7041991919279098
Epoch: 27 | Iteration number: [50/4518] 1% | Training loss: 0.7006963407993316
Epoch: 27 | Iteration number: [60/4518] 1% | Training loss: 0.6985382676124573
Epoch: 27 | Iteration number: [70/4518] 1% | Training loss: 0.697146657535008
Epoch: 27 | Iteration number: [80/4518] 1% | Training loss: 0.6957466751337051
Epoch: 27 | Iteration number: [90/4518] 1% | Training loss: 0.6949404815832774
Epoch: 27 | Iteration number: [100/4518] 2% | Training loss: 0.6942203938961029
Epoch: 27 | Iteration number: [110/4518] 2% | Training loss: 0.6935910539193587
Epoch: 27 | Iteration number: [120/4518] 2% | Training loss: 0.6929858932892482
Epoch: 27 | Iteration number: [130/4518] 2% | Training loss: 0.6925044898803417
Epoch: 27 | Iteration number: [140/4518] 3% | Training loss: 0.6921454008136477
Epoch: 27 | Iteration number: [150/4518] 3% | Training loss: 0.6918460102876027
Epoch: 27 | Iteration number: [160/4518] 3% | Training loss: 0.6914977442473174
Epoch: 27 | Iteration number: [170/4518] 3% | Training loss: 0.6911948018214282
Epoch: 27 | Iteration number: [180/4518] 3% | Training loss: 0.690902751021915
Epoch: 27 | Iteration number: [190/4518] 4% | Training loss: 0.6906646035219494
Epoch: 27 | Iteration number: [200/4518] 4% | Training loss: 0.6904688313603401
Epoch: 27 | Iteration number: [210/4518] 4% | Training loss: 0.6902979944433485
Epoch: 27 | Iteration number: [220/4518] 4% | Training loss: 0.690120527419177
Epoch: 27 | Iteration number: [230/4518] 5% | Training loss: 0.689960758841556
Epoch: 27 | Iteration number: [240/4518] 5% | Training loss: 0.6898834968606631
Epoch: 27 | Iteration number: [250/4518] 5% | Training loss: 0.6897299172878265
Epoch: 27 | Iteration number: [260/4518] 5% | Training loss: 0.6896332600942024
Epoch: 27 | Iteration number: [270/4518] 5% | Training loss: 0.689521770565598
Epoch: 27 | Iteration number: [280/4518] 6% | Training loss: 0.6894030492220606
Epoch: 27 | Iteration number: [290/4518] 6% | Training loss: 0.6893888471455409
Epoch: 27 | Iteration number: [300/4518] 6% | Training loss: 0.6893259241183599
Epoch: 27 | Iteration number: [310/4518] 6% | Training loss: 0.6892441099689853
Epoch: 27 | Iteration number: [320/4518] 7% | Training loss: 0.6891451871022582
Epoch: 27 | Iteration number: [330/4518] 7% | Training loss: 0.6891024856856375
Epoch: 27 | Iteration number: [340/4518] 7% | Training loss: 0.6890451731050715
Epoch: 27 | Iteration number: [350/4518] 7% | Training loss: 0.6890096798964909
Epoch: 27 | Iteration number: [360/4518] 7% | Training loss: 0.6889399551683002
Epoch: 27 | Iteration number: [370/4518] 8% | Training loss: 0.6888378992274001
Epoch: 27 | Iteration number: [380/4518] 8% | Training loss: 0.6888000855320379
Epoch: 27 | Iteration number: [390/4518] 8% | Training loss: 0.6887328481062864
Epoch: 27 | Iteration number: [400/4518] 8% | Training loss: 0.6887033638358117
Epoch: 27 | Iteration number: [410/4518] 9% | Training loss: 0.6886332344718096
Epoch: 27 | Iteration number: [420/4518] 9% | Training loss: 0.6885931293169657
Epoch: 27 | Iteration number: [430/4518] 9% | Training loss: 0.6885780976262204
Epoch: 27 | Iteration number: [440/4518] 9% | Training loss: 0.6885509710420262
Epoch: 27 | Iteration number: [450/4518] 9% | Training loss: 0.6884819610913595
Epoch: 27 | Iteration number: [460/4518] 10% | Training loss: 0.6884575157061867
Epoch: 27 | Iteration number: [470/4518] 10% | Training loss: 0.6884234928070231
Epoch: 27 | Iteration number: [480/4518] 10% | Training loss: 0.6883774518966674
Epoch: 27 | Iteration number: [490/4518] 10% | Training loss: 0.688337223262203
Epoch: 27 | Iteration number: [500/4518] 11% | Training loss: 0.6882996323108673
Epoch: 27 | Iteration number: [510/4518] 11% | Training loss: 0.6882960341724695
Epoch: 27 | Iteration number: [520/4518] 11% | Training loss: 0.6882656596027887
Epoch: 27 | Iteration number: [530/4518] 11% | Training loss: 0.6882534632142985
Epoch: 27 | Iteration number: [540/4518] 11% | Training loss: 0.6882631278700299
Epoch: 27 | Iteration number: [550/4518] 12% | Training loss: 0.6882463884353638
Epoch: 27 | Iteration number: [560/4518] 12% | Training loss: 0.6882043521319117
Epoch: 27 | Iteration number: [570/4518] 12% | Training loss: 0.6881826716556884
Epoch: 27 | Iteration number: [580/4518] 12% | Training loss: 0.6881410032510757
Epoch: 27 | Iteration number: [590/4518] 13% | Training loss: 0.6881127428200285
Epoch: 27 | Iteration number: [600/4518] 13% | Training loss: 0.6880946039160093
Epoch: 27 | Iteration number: [610/4518] 13% | Training loss: 0.6880775779974265
Epoch: 27 | Iteration number: [620/4518] 13% | Training loss: 0.6880694870025881
Epoch: 27 | Iteration number: [630/4518] 13% | Training loss: 0.688037926053244
Epoch: 27 | Iteration number: [640/4518] 14% | Training loss: 0.6880105637945235
Epoch: 27 | Iteration number: [650/4518] 14% | Training loss: 0.6880188368833982
Epoch: 27 | Iteration number: [660/4518] 14% | Training loss: 0.6879986434271841
Epoch: 27 | Iteration number: [670/4518] 14% | Training loss: 0.6879902339693326
Epoch: 27 | Iteration number: [680/4518] 15% | Training loss: 0.6879899841897628
Epoch: 27 | Iteration number: [690/4518] 15% | Training loss: 0.687987864881322
Epoch: 27 | Iteration number: [700/4518] 15% | Training loss: 0.6879794693844659
Epoch: 27 | Iteration number: [710/4518] 15% | Training loss: 0.6879422199558204
Epoch: 27 | Iteration number: [720/4518] 15% | Training loss: 0.6879231398304303
Epoch: 27 | Iteration number: [730/4518] 16% | Training loss: 0.6879191633773176
Epoch: 27 | Iteration number: [740/4518] 16% | Training loss: 0.6878924836983552
Epoch: 27 | Iteration number: [750/4518] 16% | Training loss: 0.6878732007344563
Epoch: 27 | Iteration number: [760/4518] 16% | Training loss: 0.6878654731731666
Epoch: 27 | Iteration number: [770/4518] 17% | Training loss: 0.6878521342556198
Epoch: 27 | Iteration number: [780/4518] 17% | Training loss: 0.6878339829353186
Epoch: 27 | Iteration number: [790/4518] 17% | Training loss: 0.687828160614907
Epoch: 27 | Iteration number: [800/4518] 17% | Training loss: 0.6878103996068239
Epoch: 27 | Iteration number: [810/4518] 17% | Training loss: 0.6878058325361323
Epoch: 27 | Iteration number: [820/4518] 18% | Training loss: 0.6877899103775257
Epoch: 27 | Iteration number: [830/4518] 18% | Training loss: 0.6877817084990352
Epoch: 27 | Iteration number: [840/4518] 18% | Training loss: 0.6877692576675188
Epoch: 27 | Iteration number: [850/4518] 18% | Training loss: 0.6877621870882371
Epoch: 27 | Iteration number: [860/4518] 19% | Training loss: 0.6877508727617042
Epoch: 27 | Iteration number: [870/4518] 19% | Training loss: 0.6877450364759599
Epoch: 27 | Iteration number: [880/4518] 19% | Training loss: 0.687719777836041
Epoch: 27 | Iteration number: [890/4518] 19% | Training loss: 0.6877072101898407
Epoch: 27 | Iteration number: [900/4518] 19% | Training loss: 0.6877001282241609
Epoch: 27 | Iteration number: [910/4518] 20% | Training loss: 0.6876772903479063
Epoch: 27 | Iteration number: [920/4518] 20% | Training loss: 0.6876685478765031
Epoch: 27 | Iteration number: [930/4518] 20% | Training loss: 0.6876567783535168
Epoch: 27 | Iteration number: [940/4518] 20% | Training loss: 0.6876369363449989
Epoch: 27 | Iteration number: [950/4518] 21% | Training loss: 0.6876266410476283
Epoch: 27 | Iteration number: [960/4518] 21% | Training loss: 0.6876240961874525
Epoch: 27 | Iteration number: [970/4518] 21% | Training loss: 0.6876165007807545
Epoch: 27 | Iteration number: [980/4518] 21% | Training loss: 0.6876042671957795
Epoch: 27 | Iteration number: [990/4518] 21% | Training loss: 0.6875938702111293
Epoch: 27 | Iteration number: [1000/4518] 22% | Training loss: 0.6875822965502739
Epoch: 27 | Iteration number: [1010/4518] 22% | Training loss: 0.6875689579118597
Epoch: 27 | Iteration number: [1020/4518] 22% | Training loss: 0.6875635816770441
Epoch: 27 | Iteration number: [1030/4518] 22% | Training loss: 0.6875436268385174
Epoch: 27 | Iteration number: [1040/4518] 23% | Training loss: 0.6875429074924726
Epoch: 27 | Iteration number: [1050/4518] 23% | Training loss: 0.6875343851248423
Epoch: 27 | Iteration number: [1060/4518] 23% | Training loss: 0.6875204991619542
Epoch: 27 | Iteration number: [1070/4518] 23% | Training loss: 0.6875288844665635
Epoch: 27 | Iteration number: [1080/4518] 23% | Training loss: 0.6875233921187895
Epoch: 27 | Iteration number: [1090/4518] 24% | Training loss: 0.6875307469739826
Epoch: 27 | Iteration number: [1100/4518] 24% | Training loss: 0.6875267733768984
Epoch: 27 | Iteration number: [1110/4518] 24% | Training loss: 0.6875139071060731
Epoch: 27 | Iteration number: [1120/4518] 24% | Training loss: 0.6875116379665477
Epoch: 27 | Iteration number: [1130/4518] 25% | Training loss: 0.6875065999220957
Epoch: 27 | Iteration number: [1140/4518] 25% | Training loss: 0.6874964942011916
Epoch: 27 | Iteration number: [1150/4518] 25% | Training loss: 0.6874906980991363
Epoch: 27 | Iteration number: [1160/4518] 25% | Training loss: 0.6874753828192579
Epoch: 27 | Iteration number: [1170/4518] 25% | Training loss: 0.6874751032927098
Epoch: 27 | Iteration number: [1180/4518] 26% | Training loss: 0.6874592510320372
Epoch: 27 | Iteration number: [1190/4518] 26% | Training loss: 0.6874382668182629
Epoch: 27 | Iteration number: [1200/4518] 26% | Training loss: 0.6874339543282986
Epoch: 27 | Iteration number: [1210/4518] 26% | Training loss: 0.6874422894036474
Epoch: 27 | Iteration number: [1220/4518] 27% | Training loss: 0.6874412123297081
Epoch: 27 | Iteration number: [1230/4518] 27% | Training loss: 0.6874396786457155
Epoch: 27 | Iteration number: [1240/4518] 27% | Training loss: 0.6874333919056
Epoch: 27 | Iteration number: [1250/4518] 27% | Training loss: 0.6874336742401123
Epoch: 27 | Iteration number: [1260/4518] 27% | Training loss: 0.6874308328306864
Epoch: 27 | Iteration number: [1270/4518] 28% | Training loss: 0.6874257221935303
Epoch: 27 | Iteration number: [1280/4518] 28% | Training loss: 0.687430988624692
Epoch: 27 | Iteration number: [1290/4518] 28% | Training loss: 0.6874246947987135
Epoch: 27 | Iteration number: [1300/4518] 28% | Training loss: 0.6874209947769458
Epoch: 27 | Iteration number: [1310/4518] 28% | Training loss: 0.6874136569845768
Epoch: 27 | Iteration number: [1320/4518] 29% | Training loss: 0.6873963254870791
Epoch: 27 | Iteration number: [1330/4518] 29% | Training loss: 0.687385403437722
Epoch: 27 | Iteration number: [1340/4518] 29% | Training loss: 0.6873790303717798
Epoch: 27 | Iteration number: [1350/4518] 29% | Training loss: 0.6873783340277495
Epoch: 27 | Iteration number: [1360/4518] 30% | Training loss: 0.6873755545738865
Epoch: 27 | Iteration number: [1370/4518] 30% | Training loss: 0.6873660396050363
Epoch: 27 | Iteration number: [1380/4518] 30% | Training loss: 0.6873602626548297
Epoch: 27 | Iteration number: [1390/4518] 30% | Training loss: 0.687362894523058
Epoch: 27 | Iteration number: [1400/4518] 30% | Training loss: 0.6873590422102384
Epoch: 27 | Iteration number: [1410/4518] 31% | Training loss: 0.6873440288905557
Epoch: 27 | Iteration number: [1420/4518] 31% | Training loss: 0.6873397470360071
Epoch: 27 | Iteration number: [1430/4518] 31% | Training loss: 0.6873314753278986
Epoch: 27 | Iteration number: [1440/4518] 31% | Training loss: 0.6873289163327879
Epoch: 27 | Iteration number: [1450/4518] 32% | Training loss: 0.687328106904852
Epoch: 27 | Iteration number: [1460/4518] 32% | Training loss: 0.6873239429029699
Epoch: 27 | Iteration number: [1470/4518] 32% | Training loss: 0.6873238945088419
Epoch: 27 | Iteration number: [1480/4518] 32% | Training loss: 0.6873242125720591
Epoch: 27 | Iteration number: [1490/4518] 32% | Training loss: 0.6873182952404022
Epoch: 27 | Iteration number: [1500/4518] 33% | Training loss: 0.687313044945399
Epoch: 27 | Iteration number: [1510/4518] 33% | Training loss: 0.6873084322111496
Epoch: 27 | Iteration number: [1520/4518] 33% | Training loss: 0.6873030685280499
Epoch: 27 | Iteration number: [1530/4518] 33% | Training loss: 0.6872985087578593
Epoch: 27 | Iteration number: [1540/4518] 34% | Training loss: 0.6872935088423939
Epoch: 27 | Iteration number: [1550/4518] 34% | Training loss: 0.6872881825124064
Epoch: 27 | Iteration number: [1560/4518] 34% | Training loss: 0.6872904557066086
Epoch: 27 | Iteration number: [1570/4518] 34% | Training loss: 0.6872908259652982
Epoch: 27 | Iteration number: [1580/4518] 34% | Training loss: 0.6872901692043377
Epoch: 27 | Iteration number: [1590/4518] 35% | Training loss: 0.6872826853638175
Epoch: 27 | Iteration number: [1600/4518] 35% | Training loss: 0.6872818917036057
Epoch: 27 | Iteration number: [1610/4518] 35% | Training loss: 0.6872884902894867
Epoch: 27 | Iteration number: [1620/4518] 35% | Training loss: 0.68727691438463
Epoch: 27 | Iteration number: [1630/4518] 36% | Training loss: 0.6872680202217921
Epoch: 27 | Iteration number: [1640/4518] 36% | Training loss: 0.6872587272306768
Epoch: 27 | Iteration number: [1650/4518] 36% | Training loss: 0.6872625454989346
Epoch: 27 | Iteration number: [1660/4518] 36% | Training loss: 0.6872647469661322
Epoch: 27 | Iteration number: [1670/4518] 36% | Training loss: 0.6872649723541236
Epoch: 27 | Iteration number: [1680/4518] 37% | Training loss: 0.6872668329803716
Epoch: 27 | Iteration number: [1690/4518] 37% | Training loss: 0.6872692220309782
Epoch: 27 | Iteration number: [1700/4518] 37% | Training loss: 0.6872727622354732
Epoch: 27 | Iteration number: [1710/4518] 37% | Training loss: 0.6872652407278095
Epoch: 27 | Iteration number: [1720/4518] 38% | Training loss: 0.6872550993464713
Epoch: 27 | Iteration number: [1730/4518] 38% | Training loss: 0.6872557091575138
Epoch: 27 | Iteration number: [1740/4518] 38% | Training loss: 0.687252100617036
Epoch: 27 | Iteration number: [1750/4518] 38% | Training loss: 0.6872475255898067
Epoch: 27 | Iteration number: [1760/4518] 38% | Training loss: 0.6872512365268035
Epoch: 27 | Iteration number: [1770/4518] 39% | Training loss: 0.6872529414750762
Epoch: 27 | Iteration number: [1780/4518] 39% | Training loss: 0.687249716279212
Epoch: 27 | Iteration number: [1790/4518] 39% | Training loss: 0.6872551290016601
Epoch: 27 | Iteration number: [1800/4518] 39% | Training loss: 0.6872536604271995
Epoch: 27 | Iteration number: [1810/4518] 40% | Training loss: 0.6872518920766715
Epoch: 27 | Iteration number: [1820/4518] 40% | Training loss: 0.6872452713631012
Epoch: 27 | Iteration number: [1830/4518] 40% | Training loss: 0.6872420494347974
Epoch: 27 | Iteration number: [1840/4518] 40% | Training loss: 0.687234642389028
Epoch: 27 | Iteration number: [1850/4518] 40% | Training loss: 0.6872242849581951
Epoch: 27 | Iteration number: [1860/4518] 41% | Training loss: 0.6872247087058201
Epoch: 27 | Iteration number: [1870/4518] 41% | Training loss: 0.6872232664077678
Epoch: 27 | Iteration number: [1880/4518] 41% | Training loss: 0.6872209435130687
Epoch: 27 | Iteration number: [1890/4518] 41% | Training loss: 0.687221607423964
Epoch: 27 | Iteration number: [1900/4518] 42% | Training loss: 0.6872189579198235
Epoch: 27 | Iteration number: [1910/4518] 42% | Training loss: 0.6872253232601425
Epoch: 27 | Iteration number: [1920/4518] 42% | Training loss: 0.6872268112686774
Epoch: 27 | Iteration number: [1930/4518] 42% | Training loss: 0.6872270613136687
Epoch: 27 | Iteration number: [1940/4518] 42% | Training loss: 0.6872232302562478
Epoch: 27 | Iteration number: [1950/4518] 43% | Training loss: 0.6872205943939014
Epoch: 27 | Iteration number: [1960/4518] 43% | Training loss: 0.6872134064533273
Epoch: 27 | Iteration number: [1970/4518] 43% | Training loss: 0.6872100590146738
Epoch: 27 | Iteration number: [1980/4518] 43% | Training loss: 0.687207440324504
Epoch: 27 | Iteration number: [1990/4518] 44% | Training loss: 0.6872071107428278
Epoch: 27 | Iteration number: [2000/4518] 44% | Training loss: 0.6872078474462032
Epoch: 27 | Iteration number: [2010/4518] 44% | Training loss: 0.6872014627527835
Epoch: 27 | Iteration number: [2020/4518] 44% | Training loss: 0.6871996173174074
Epoch: 27 | Iteration number: [2030/4518] 44% | Training loss: 0.6872021060859042
Epoch: 27 | Iteration number: [2040/4518] 45% | Training loss: 0.6872063803614354
Epoch: 27 | Iteration number: [2050/4518] 45% | Training loss: 0.6872086276949906
Epoch: 27 | Iteration number: [2060/4518] 45% | Training loss: 0.6872033652750034
Epoch: 27 | Iteration number: [2070/4518] 45% | Training loss: 0.6872012954115292
Epoch: 27 | Iteration number: [2080/4518] 46% | Training loss: 0.6871982917476159
Epoch: 27 | Iteration number: [2090/4518] 46% | Training loss: 0.6871982238224249
Epoch: 27 | Iteration number: [2100/4518] 46% | Training loss: 0.6872008671647026
Epoch: 27 | Iteration number: [2110/4518] 46% | Training loss: 0.6871990121371373
Epoch: 27 | Iteration number: [2120/4518] 46% | Training loss: 0.6872007952546174
Epoch: 27 | Iteration number: [2130/4518] 47% | Training loss: 0.6871998827782035
Epoch: 27 | Iteration number: [2140/4518] 47% | Training loss: 0.6872023753195166
Epoch: 27 | Iteration number: [2150/4518] 47% | Training loss: 0.6872029554566672
Epoch: 27 | Iteration number: [2160/4518] 47% | Training loss: 0.6872054004834758
Epoch: 27 | Iteration number: [2170/4518] 48% | Training loss: 0.6872075274518009
Epoch: 27 | Iteration number: [2180/4518] 48% | Training loss: 0.6872062769778278
Epoch: 27 | Iteration number: [2190/4518] 48% | Training loss: 0.6872000937592493
Epoch: 27 | Iteration number: [2200/4518] 48% | Training loss: 0.6872004209594293
Epoch: 27 | Iteration number: [2210/4518] 48% | Training loss: 0.6871941379292519
Epoch: 27 | Iteration number: [2220/4518] 49% | Training loss: 0.6871950826666376
Epoch: 27 | Iteration number: [2230/4518] 49% | Training loss: 0.6871939321804474
Epoch: 27 | Iteration number: [2240/4518] 49% | Training loss: 0.6871912838625056
Epoch: 27 | Iteration number: [2250/4518] 49% | Training loss: 0.6871878610981835
Epoch: 27 | Iteration number: [2260/4518] 50% | Training loss: 0.6871846573278967
Epoch: 27 | Iteration number: [2270/4518] 50% | Training loss: 0.6871782886299268
Epoch: 27 | Iteration number: [2280/4518] 50% | Training loss: 0.6871775104549893
Epoch: 27 | Iteration number: [2290/4518] 50% | Training loss: 0.6871798337286736
Epoch: 27 | Iteration number: [2300/4518] 50% | Training loss: 0.6871824493615524
Epoch: 27 | Iteration number: [2310/4518] 51% | Training loss: 0.6871815574375582
Epoch: 27 | Iteration number: [2320/4518] 51% | Training loss: 0.6871766281538996
Epoch: 27 | Iteration number: [2330/4518] 51% | Training loss: 0.687180385083088
Epoch: 27 | Iteration number: [2340/4518] 51% | Training loss: 0.6871807904579701
Epoch: 27 | Iteration number: [2350/4518] 52% | Training loss: 0.6871859774437357
Epoch: 27 | Iteration number: [2360/4518] 52% | Training loss: 0.6871855526152304
Epoch: 27 | Iteration number: [2370/4518] 52% | Training loss: 0.6871885557969412
Epoch: 27 | Iteration number: [2380/4518] 52% | Training loss: 0.6871899485838513
Epoch: 27 | Iteration number: [2390/4518] 52% | Training loss: 0.6871864056487462
Epoch: 27 | Iteration number: [2400/4518] 53% | Training loss: 0.6871776626010736
Epoch: 27 | Iteration number: [2410/4518] 53% | Training loss: 0.6871739180503544
Epoch: 27 | Iteration number: [2420/4518] 53% | Training loss: 0.6871699287625384
Epoch: 27 | Iteration number: [2430/4518] 53% | Training loss: 0.6871686778686664
Epoch: 27 | Iteration number: [2440/4518] 54% | Training loss: 0.6871638190306602
Epoch: 27 | Iteration number: [2450/4518] 54% | Training loss: 0.6871585010509101
Epoch: 27 | Iteration number: [2460/4518] 54% | Training loss: 0.6871497224986068
Epoch: 27 | Iteration number: [2470/4518] 54% | Training loss: 0.6871472254938442
Epoch: 27 | Iteration number: [2480/4518] 54% | Training loss: 0.687140793689797
Epoch: 27 | Iteration number: [2490/4518] 55% | Training loss: 0.6871422809051223
Epoch: 27 | Iteration number: [2500/4518] 55% | Training loss: 0.6871392016649246
Epoch: 27 | Iteration number: [2510/4518] 55% | Training loss: 0.6871343333407702
Epoch: 27 | Iteration number: [2520/4518] 55% | Training loss: 0.687136674518623
Epoch: 27 | Iteration number: [2530/4518] 55% | Training loss: 0.6871333293292834
Epoch: 27 | Iteration number: [2540/4518] 56% | Training loss: 0.6871331526069191
Epoch: 27 | Iteration number: [2550/4518] 56% | Training loss: 0.6871347501231175
Epoch: 27 | Iteration number: [2560/4518] 56% | Training loss: 0.6871332561364397
Epoch: 27 | Iteration number: [2570/4518] 56% | Training loss: 0.6871330136223062
Epoch: 27 | Iteration number: [2580/4518] 57% | Training loss: 0.6871396880510241
Epoch: 27 | Iteration number: [2590/4518] 57% | Training loss: 0.6871390176555825
Epoch: 27 | Iteration number: [2600/4518] 57% | Training loss: 0.687139076934411
Epoch: 27 | Iteration number: [2610/4518] 57% | Training loss: 0.687137489323415
Epoch: 27 | Iteration number: [2620/4518] 57% | Training loss: 0.6871358442170019
Epoch: 27 | Iteration number: [2630/4518] 58% | Training loss: 0.6871319303267809
Epoch: 27 | Iteration number: [2640/4518] 58% | Training loss: 0.687131549305085
Epoch: 27 | Iteration number: [2650/4518] 58% | Training loss: 0.687129792514837
Epoch: 27 | Iteration number: [2660/4518] 58% | Training loss: 0.6871290076944164
Epoch: 27 | Iteration number: [2670/4518] 59% | Training loss: 0.6871337988403406
Epoch: 27 | Iteration number: [2680/4518] 59% | Training loss: 0.6871329605579376
Epoch: 27 | Iteration number: [2690/4518] 59% | Training loss: 0.6871313168435291
Epoch: 27 | Iteration number: [2700/4518] 59% | Training loss: 0.6871332369910346
Epoch: 27 | Iteration number: [2710/4518] 59% | Training loss: 0.6871351299030755
Epoch: 27 | Iteration number: [2720/4518] 60% | Training loss: 0.6871301722000627
Epoch: 27 | Iteration number: [2730/4518] 60% | Training loss: 0.6871322681178976
Epoch: 27 | Iteration number: [2740/4518] 60% | Training loss: 0.6871298958785342
Epoch: 27 | Iteration number: [2750/4518] 60% | Training loss: 0.6871284671696749
Epoch: 27 | Iteration number: [2760/4518] 61% | Training loss: 0.6871309386215348
Epoch: 27 | Iteration number: [2770/4518] 61% | Training loss: 0.6871306387526034
Epoch: 27 | Iteration number: [2780/4518] 61% | Training loss: 0.6871296255279788
Epoch: 27 | Iteration number: [2790/4518] 61% | Training loss: 0.6871292241585297
Epoch: 27 | Iteration number: [2800/4518] 61% | Training loss: 0.6871264637368066
Epoch: 27 | Iteration number: [2810/4518] 62% | Training loss: 0.687121694452822
Epoch: 27 | Iteration number: [2820/4518] 62% | Training loss: 0.6871219296404656
Epoch: 27 | Iteration number: [2830/4518] 62% | Training loss: 0.6871185717228866
Epoch: 27 | Iteration number: [2840/4518] 62% | Training loss: 0.6871176791233076
Epoch: 27 | Iteration number: [2850/4518] 63% | Training loss: 0.687118813907891
Epoch: 27 | Iteration number: [2860/4518] 63% | Training loss: 0.6871161642399701
Epoch: 27 | Iteration number: [2870/4518] 63% | Training loss: 0.687114487022473
Epoch: 27 | Iteration number: [2880/4518] 63% | Training loss: 0.6871095867620574
Epoch: 27 | Iteration number: [2890/4518] 63% | Training loss: 0.6871113869558156
Epoch: 27 | Iteration number: [2900/4518] 64% | Training loss: 0.6871031148474792
Epoch: 27 | Iteration number: [2910/4518] 64% | Training loss: 0.6871026730414518
Epoch: 27 | Iteration number: [2920/4518] 64% | Training loss: 0.6870974651142342
Epoch: 27 | Iteration number: [2930/4518] 64% | Training loss: 0.6870990924664325
Epoch: 27 | Iteration number: [2940/4518] 65% | Training loss: 0.687103508605438
Epoch: 27 | Iteration number: [2950/4518] 65% | Training loss: 0.687103134939226
Epoch: 27 | Iteration number: [2960/4518] 65% | Training loss: 0.6871049249091664
Epoch: 27 | Iteration number: [2970/4518] 65% | Training loss: 0.6871012037651306
Epoch: 27 | Iteration number: [2980/4518] 65% | Training loss: 0.6871053957299098
Epoch: 27 | Iteration number: [2990/4518] 66% | Training loss: 0.6870997717747321
Epoch: 27 | Iteration number: [3000/4518] 66% | Training loss: 0.6870969732999802
Epoch: 27 | Iteration number: [3010/4518] 66% | Training loss: 0.6870990780104831
Epoch: 27 | Iteration number: [3020/4518] 66% | Training loss: 0.6871016928099638
Epoch: 27 | Iteration number: [3030/4518] 67% | Training loss: 0.6871003213298597
Epoch: 27 | Iteration number: [3040/4518] 67% | Training loss: 0.6870978405797168
Epoch: 27 | Iteration number: [3050/4518] 67% | Training loss: 0.6870942248672736
Epoch: 27 | Iteration number: [3060/4518] 67% | Training loss: 0.6870947327489167
Epoch: 27 | Iteration number: [3070/4518] 67% | Training loss: 0.6870928358371561
Epoch: 27 | Iteration number: [3080/4518] 68% | Training loss: 0.6870901444902667
Epoch: 27 | Iteration number: [3090/4518] 68% | Training loss: 0.6870897144947237
Epoch: 27 | Iteration number: [3100/4518] 68% | Training loss: 0.6870902483501742
Epoch: 27 | Iteration number: [3110/4518] 68% | Training loss: 0.6870882797662852
Epoch: 27 | Iteration number: [3120/4518] 69% | Training loss: 0.687089554220438
Epoch: 27 | Iteration number: [3130/4518] 69% | Training loss: 0.6870928564962868
Epoch: 27 | Iteration number: [3140/4518] 69% | Training loss: 0.6870946459139988
Epoch: 27 | Iteration number: [3150/4518] 69% | Training loss: 0.6870944837161473
Epoch: 27 | Iteration number: [3160/4518] 69% | Training loss: 0.6870963405393347
Epoch: 27 | Iteration number: [3170/4518] 70% | Training loss: 0.6870928536642237
Epoch: 27 | Iteration number: [3180/4518] 70% | Training loss: 0.6870944639984167
Epoch: 27 | Iteration number: [3190/4518] 70% | Training loss: 0.6870973843205311
Epoch: 27 | Iteration number: [3200/4518] 70% | Training loss: 0.6870945345051587
Epoch: 27 | Iteration number: [3210/4518] 71% | Training loss: 0.6870928710866198
Epoch: 27 | Iteration number: [3220/4518] 71% | Training loss: 0.6870915347930067
Epoch: 27 | Iteration number: [3230/4518] 71% | Training loss: 0.6870912265297798
Epoch: 27 | Iteration number: [3240/4518] 71% | Training loss: 0.6870917351709471
Epoch: 27 | Iteration number: [3250/4518] 71% | Training loss: 0.6870939952043387
Epoch: 27 | Iteration number: [3260/4518] 72% | Training loss: 0.6870926054525961
Epoch: 27 | Iteration number: [3270/4518] 72% | Training loss: 0.6870938202656737
Epoch: 27 | Iteration number: [3280/4518] 72% | Training loss: 0.6870943151777837
Epoch: 27 | Iteration number: [3290/4518] 72% | Training loss: 0.6870932251124396
Epoch: 27 | Iteration number: [3300/4518] 73% | Training loss: 0.687092761704416
Epoch: 27 | Iteration number: [3310/4518] 73% | Training loss: 0.6870929109906142
Epoch: 27 | Iteration number: [3320/4518] 73% | Training loss: 0.6870937350464155
Epoch: 27 | Iteration number: [3330/4518] 73% | Training loss: 0.6870946034654841
Epoch: 27 | Iteration number: [3340/4518] 73% | Training loss: 0.6870931909648245
Epoch: 27 | Iteration number: [3350/4518] 74% | Training loss: 0.68708918160467
Epoch: 27 | Iteration number: [3360/4518] 74% | Training loss: 0.6870893250086478
Epoch: 27 | Iteration number: [3370/4518] 74% | Training loss: 0.6870893712567293
Epoch: 27 | Iteration number: [3380/4518] 74% | Training loss: 0.6870862203765903
Epoch: 27 | Iteration number: [3390/4518] 75% | Training loss: 0.6870829868633135
Epoch: 27 | Iteration number: [3400/4518] 75% | Training loss: 0.6870845788541962
Epoch: 27 | Iteration number: [3410/4518] 75% | Training loss: 0.687084997416941
Epoch: 27 | Iteration number: [3420/4518] 75% | Training loss: 0.6870855248462387
Epoch: 27 | Iteration number: [3430/4518] 75% | Training loss: 0.6870854629024472
Epoch: 27 | Iteration number: [3440/4518] 76% | Training loss: 0.6870900160698004
Epoch: 27 | Iteration number: [3450/4518] 76% | Training loss: 0.687089414993922
Epoch: 27 | Iteration number: [3460/4518] 76% | Training loss: 0.6870905871163903
Epoch: 27 | Iteration number: [3470/4518] 76% | Training loss: 0.6870881014667258
Epoch: 27 | Iteration number: [3480/4518] 77% | Training loss: 0.6870868337565454
Epoch: 27 | Iteration number: [3490/4518] 77% | Training loss: 0.687085982567943
Epoch: 27 | Iteration number: [3500/4518] 77% | Training loss: 0.6870869696480887
Epoch: 27 | Iteration number: [3510/4518] 77% | Training loss: 0.6870838389946864
Epoch: 27 | Iteration number: [3520/4518] 77% | Training loss: 0.6870827559043061
Epoch: 27 | Iteration number: [3530/4518] 78% | Training loss: 0.6870846425169926
Epoch: 27 | Iteration number: [3540/4518] 78% | Training loss: 0.6870827643211278
Epoch: 27 | Iteration number: [3550/4518] 78% | Training loss: 0.6870874465519273
Epoch: 27 | Iteration number: [3560/4518] 78% | Training loss: 0.6870844785584492
Epoch: 27 | Iteration number: [3570/4518] 79% | Training loss: 0.6870873244703651
Epoch: 27 | Iteration number: [3580/4518] 79% | Training loss: 0.6870859112985973
Epoch: 27 | Iteration number: [3590/4518] 79% | Training loss: 0.6870838606257956
Epoch: 27 | Iteration number: [3600/4518] 79% | Training loss: 0.6870795594155789
Epoch: 27 | Iteration number: [3610/4518] 79% | Training loss: 0.6870731021558809
Epoch: 27 | Iteration number: [3620/4518] 80% | Training loss: 0.6870727353991725
Epoch: 27 | Iteration number: [3630/4518] 80% | Training loss: 0.687068251949368
Epoch: 27 | Iteration number: [3640/4518] 80% | Training loss: 0.6870630041583554
Epoch: 27 | Iteration number: [3650/4518] 80% | Training loss: 0.6870620600328053
Epoch: 27 | Iteration number: [3660/4518] 81% | Training loss: 0.6870620723467707
Epoch: 27 | Iteration number: [3670/4518] 81% | Training loss: 0.6870612919005776
Epoch: 27 | Iteration number: [3680/4518] 81% | Training loss: 0.6870599019138709
Epoch: 27 | Iteration number: [3690/4518] 81% | Training loss: 0.6870629553064744
Epoch: 27 | Iteration number: [3700/4518] 81% | Training loss: 0.6870627051591873
Epoch: 27 | Iteration number: [3710/4518] 82% | Training loss: 0.6870638443935271
Epoch: 27 | Iteration number: [3720/4518] 82% | Training loss: 0.687060701158098
Epoch: 27 | Iteration number: [3730/4518] 82% | Training loss: 0.687061536647679
Epoch: 27 | Iteration number: [3740/4518] 82% | Training loss: 0.6870624873886771
Epoch: 27 | Iteration number: [3750/4518] 83% | Training loss: 0.6870605433146159
Epoch: 27 | Iteration number: [3760/4518] 83% | Training loss: 0.6870577088061799
Epoch: 27 | Iteration number: [3770/4518] 83% | Training loss: 0.6870574558761455
Epoch: 27 | Iteration number: [3780/4518] 83% | Training loss: 0.6870562560659237
Epoch: 27 | Iteration number: [3790/4518] 83% | Training loss: 0.6870573041778756
Epoch: 27 | Iteration number: [3800/4518] 84% | Training loss: 0.6870578997072421
Epoch: 27 | Iteration number: [3810/4518] 84% | Training loss: 0.6870563760673593
Epoch: 27 | Iteration number: [3820/4518] 84% | Training loss: 0.6870574370416671
Epoch: 27 | Iteration number: [3830/4518] 84% | Training loss: 0.6870571925963808
Epoch: 27 | Iteration number: [3840/4518] 84% | Training loss: 0.687055660939465
Epoch: 27 | Iteration number: [3850/4518] 85% | Training loss: 0.6870571950194123
Epoch: 27 | Iteration number: [3860/4518] 85% | Training loss: 0.6870567652382381
Epoch: 27 | Iteration number: [3870/4518] 85% | Training loss: 0.6870610838250596
Epoch: 27 | Iteration number: [3880/4518] 85% | Training loss: 0.687062016359924
Epoch: 27 | Iteration number: [3890/4518] 86% | Training loss: 0.6870640169379031
Epoch: 27 | Iteration number: [3900/4518] 86% | Training loss: 0.6870617934832206
Epoch: 27 | Iteration number: [3910/4518] 86% | Training loss: 0.6870615617545974
Epoch: 27 | Iteration number: [3920/4518] 86% | Training loss: 0.6870646810045048
Epoch: 27 | Iteration number: [3930/4518] 86% | Training loss: 0.6870664479774979
Epoch: 27 | Iteration number: [3940/4518] 87% | Training loss: 0.68706464941429
Epoch: 27 | Iteration number: [3950/4518] 87% | Training loss: 0.6870631496513946
Epoch: 27 | Iteration number: [3960/4518] 87% | Training loss: 0.6870576094948884
Epoch: 27 | Iteration number: [3970/4518] 87% | Training loss: 0.6870545722525426
Epoch: 27 | Iteration number: [3980/4518] 88% | Training loss: 0.6870545091041967
Epoch: 27 | Iteration number: [3990/4518] 88% | Training loss: 0.6870518550090025
Epoch: 27 | Iteration number: [4000/4518] 88% | Training loss: 0.6870504260212184
Epoch: 27 | Iteration number: [4010/4518] 88% | Training loss: 0.6870500522064152
Epoch: 27 | Iteration number: [4020/4518] 88% | Training loss: 0.6870526563617128
Epoch: 27 | Iteration number: [4030/4518] 89% | Training loss: 0.6870520856924743
Epoch: 27 | Iteration number: [4040/4518] 89% | Training loss: 0.6870528848011895
Epoch: 27 | Iteration number: [4050/4518] 89% | Training loss: 0.6870536182692022
Epoch: 27 | Iteration number: [4060/4518] 89% | Training loss: 0.6870542117527553
Epoch: 27 | Iteration number: [4070/4518] 90% | Training loss: 0.6870539932637602
Epoch: 27 | Iteration number: [4080/4518] 90% | Training loss: 0.6870540207361474
Epoch: 27 | Iteration number: [4090/4518] 90% | Training loss: 0.6870516306759384
Epoch: 27 | Iteration number: [4100/4518] 90% | Training loss: 0.6870492959022522
Epoch: 27 | Iteration number: [4110/4518] 90% | Training loss: 0.6870509981819023
Epoch: 27 | Iteration number: [4120/4518] 91% | Training loss: 0.6870487530254623
Epoch: 27 | Iteration number: [4130/4518] 91% | Training loss: 0.6870467628029876
Epoch: 27 | Iteration number: [4140/4518] 91% | Training loss: 0.6870475723403664
Epoch: 27 | Iteration number: [4150/4518] 91% | Training loss: 0.6870489016067551
Epoch: 27 | Iteration number: [4160/4518] 92% | Training loss: 0.6870477468205186
Epoch: 27 | Iteration number: [4170/4518] 92% | Training loss: 0.687047421060306
Epoch: 27 | Iteration number: [4180/4518] 92% | Training loss: 0.6870455200734892
Epoch: 27 | Iteration number: [4190/4518] 92% | Training loss: 0.6870409633350828
Epoch: 27 | Iteration number: [4200/4518] 92% | Training loss: 0.6870398736283893
Epoch: 27 | Iteration number: [4210/4518] 93% | Training loss: 0.6870399414926697
Epoch: 27 | Iteration number: [4220/4518] 93% | Training loss: 0.6870419514122732
Epoch: 27 | Iteration number: [4230/4518] 93% | Training loss: 0.6870422496722381
Epoch: 27 | Iteration number: [4240/4518] 93% | Training loss: 0.6870439512127975
Epoch: 27 | Iteration number: [4250/4518] 94% | Training loss: 0.6870442528864916
Epoch: 27 | Iteration number: [4260/4518] 94% | Training loss: 0.6870430756342802
Epoch: 27 | Iteration number: [4270/4518] 94% | Training loss: 0.6870429290541441
Epoch: 27 | Iteration number: [4280/4518] 94% | Training loss: 0.6870441978779909
Epoch: 27 | Iteration number: [4290/4518] 94% | Training loss: 0.687042113867673
Epoch: 27 | Iteration number: [4300/4518] 95% | Training loss: 0.6870409652798675
Epoch: 27 | Iteration number: [4310/4518] 95% | Training loss: 0.6870423659924288
Epoch: 27 | Iteration number: [4320/4518] 95% | Training loss: 0.6870425653126505
Epoch: 27 | Iteration number: [4330/4518] 95% | Training loss: 0.6870409599352654
Epoch: 27 | Iteration number: [4340/4518] 96% | Training loss: 0.6870431808969392
Epoch: 27 | Iteration number: [4350/4518] 96% | Training loss: 0.6870419598584888
Epoch: 27 | Iteration number: [4360/4518] 96% | Training loss: 0.6870407471689609
Epoch: 27 | Iteration number: [4370/4518] 96% | Training loss: 0.6870380136595711
Epoch: 27 | Iteration number: [4380/4518] 96% | Training loss: 0.6870396773292594
Epoch: 27 | Iteration number: [4390/4518] 97% | Training loss: 0.6870372243785641
Epoch: 27 | Iteration number: [4400/4518] 97% | Training loss: 0.6870358907228167
Epoch: 27 | Iteration number: [4410/4518] 97% | Training loss: 0.6870366083115947
Epoch: 27 | Iteration number: [4420/4518] 97% | Training loss: 0.6870326964294209
Epoch: 27 | Iteration number: [4430/4518] 98% | Training loss: 0.6870322705391567
Epoch: 27 | Iteration number: [4440/4518] 98% | Training loss: 0.6870326328787718
Epoch: 27 | Iteration number: [4450/4518] 98% | Training loss: 0.6870300408695521
Epoch: 27 | Iteration number: [4460/4518] 98% | Training loss: 0.6870314231501566
Epoch: 27 | Iteration number: [4470/4518] 98% | Training loss: 0.6870299338227683
Epoch: 27 | Iteration number: [4480/4518] 99% | Training loss: 0.6870253400611026
Epoch: 27 | Iteration number: [4490/4518] 99% | Training loss: 0.6870253190033154
Epoch: 27 | Iteration number: [4500/4518] 99% | Training loss: 0.6870246248510149
Epoch: 27 | Iteration number: [4510/4518] 99% | Training loss: 0.6870243843008832

 End of epoch: 27 | Train Loss: 0.6868719670454873 | Training Time: 640 

 End of epoch: 27 | Eval Loss: 0.6901223598694315 | Evaluating Time: 17 
Epoch: 28 | Iteration number: [10/4518] 0% | Training loss: 0.753990250825882
Epoch: 28 | Iteration number: [20/4518] 0% | Training loss: 0.7204923391342163
Epoch: 28 | Iteration number: [30/4518] 0% | Training loss: 0.709125276406606
Epoch: 28 | Iteration number: [40/4518] 0% | Training loss: 0.7040288880467415
Epoch: 28 | Iteration number: [50/4518] 1% | Training loss: 0.7006865298748016
Epoch: 28 | Iteration number: [60/4518] 1% | Training loss: 0.6983743727207183
Epoch: 28 | Iteration number: [70/4518] 1% | Training loss: 0.6967771640845708
Epoch: 28 | Iteration number: [80/4518] 1% | Training loss: 0.6956684686243534
Epoch: 28 | Iteration number: [90/4518] 1% | Training loss: 0.6948022954993778
Epoch: 28 | Iteration number: [100/4518] 2% | Training loss: 0.6940358728170395
Epoch: 28 | Iteration number: [110/4518] 2% | Training loss: 0.693291898207231
Epoch: 28 | Iteration number: [120/4518] 2% | Training loss: 0.6927076667547226
Epoch: 28 | Iteration number: [130/4518] 2% | Training loss: 0.6922790609873258
Epoch: 28 | Iteration number: [140/4518] 3% | Training loss: 0.6918945380619594
Epoch: 28 | Iteration number: [150/4518] 3% | Training loss: 0.6915581870079041
Epoch: 28 | Iteration number: [160/4518] 3% | Training loss: 0.691296610236168
Epoch: 28 | Iteration number: [170/4518] 3% | Training loss: 0.6910811981734107
Epoch: 28 | Iteration number: [180/4518] 3% | Training loss: 0.6908325423796972
Epoch: 28 | Iteration number: [190/4518] 4% | Training loss: 0.6906169292173887
Epoch: 28 | Iteration number: [200/4518] 4% | Training loss: 0.6904522287845611
Epoch: 28 | Iteration number: [210/4518] 4% | Training loss: 0.6902878596669152
Epoch: 28 | Iteration number: [220/4518] 4% | Training loss: 0.690145296942104
Epoch: 28 | Iteration number: [230/4518] 5% | Training loss: 0.6900188653365426
Epoch: 28 | Iteration number: [240/4518] 5% | Training loss: 0.6898639984428883
Epoch: 28 | Iteration number: [250/4518] 5% | Training loss: 0.6897719230651855
Epoch: 28 | Iteration number: [260/4518] 5% | Training loss: 0.6896106513646932
Epoch: 28 | Iteration number: [270/4518] 5% | Training loss: 0.6894753829196647
Epoch: 28 | Iteration number: [280/4518] 6% | Training loss: 0.689384465771062
Epoch: 28 | Iteration number: [290/4518] 6% | Training loss: 0.6892835849318011
Epoch: 28 | Iteration number: [300/4518] 6% | Training loss: 0.689156605998675
Epoch: 28 | Iteration number: [310/4518] 6% | Training loss: 0.6890765840007412
Epoch: 28 | Iteration number: [320/4518] 7% | Training loss: 0.6889884928241372
Epoch: 28 | Iteration number: [330/4518] 7% | Training loss: 0.6889074477282437
Epoch: 28 | Iteration number: [340/4518] 7% | Training loss: 0.6888440600212883
Epoch: 28 | Iteration number: [350/4518] 7% | Training loss: 0.688761180298669
Epoch: 28 | Iteration number: [360/4518] 7% | Training loss: 0.6887103445000119
Epoch: 28 | Iteration number: [370/4518] 8% | Training loss: 0.6886268796147527
Epoch: 28 | Iteration number: [380/4518] 8% | Training loss: 0.6885486885120994
Epoch: 28 | Iteration number: [390/4518] 8% | Training loss: 0.6884761377786979
Epoch: 28 | Iteration number: [400/4518] 8% | Training loss: 0.6884302069246769
Epoch: 28 | Iteration number: [410/4518] 9% | Training loss: 0.6884049844451067
Epoch: 28 | Iteration number: [420/4518] 9% | Training loss: 0.6883793222052711
Epoch: 28 | Iteration number: [430/4518] 9% | Training loss: 0.6883033914621486
Epoch: 28 | Iteration number: [440/4518] 9% | Training loss: 0.6882648011500185
Epoch: 28 | Iteration number: [450/4518] 9% | Training loss: 0.6882083861033121
Epoch: 28 | Iteration number: [460/4518] 10% | Training loss: 0.6881961415643277
Epoch: 28 | Iteration number: [470/4518] 10% | Training loss: 0.6881919933126328
Epoch: 28 | Iteration number: [480/4518] 10% | Training loss: 0.6881563998758793
Epoch: 28 | Iteration number: [490/4518] 10% | Training loss: 0.6881339568264631
Epoch: 28 | Iteration number: [500/4518] 11% | Training loss: 0.6881088935136795
Epoch: 28 | Iteration number: [510/4518] 11% | Training loss: 0.6880775450491438
Epoch: 28 | Iteration number: [520/4518] 11% | Training loss: 0.688051155782663
Epoch: 28 | Iteration number: [530/4518] 11% | Training loss: 0.6880303308648883
Epoch: 28 | Iteration number: [540/4518] 11% | Training loss: 0.6880016283856498
Epoch: 28 | Iteration number: [550/4518] 12% | Training loss: 0.6879767685586756
Epoch: 28 | Iteration number: [560/4518] 12% | Training loss: 0.6879413059779576
Epoch: 28 | Iteration number: [570/4518] 12% | Training loss: 0.687888436986689
Epoch: 28 | Iteration number: [580/4518] 12% | Training loss: 0.6878763141303227
Epoch: 28 | Iteration number: [590/4518] 13% | Training loss: 0.6878455677274931
Epoch: 28 | Iteration number: [600/4518] 13% | Training loss: 0.6878353703022003
Epoch: 28 | Iteration number: [610/4518] 13% | Training loss: 0.6878021411231307
Epoch: 28 | Iteration number: [620/4518] 13% | Training loss: 0.6877888611247462
Epoch: 28 | Iteration number: [630/4518] 13% | Training loss: 0.6877662594356234
Epoch: 28 | Iteration number: [640/4518] 14% | Training loss: 0.6877618138678372
Epoch: 28 | Iteration number: [650/4518] 14% | Training loss: 0.6877359128915347
Epoch: 28 | Iteration number: [660/4518] 14% | Training loss: 0.6877224765943758
Epoch: 28 | Iteration number: [670/4518] 14% | Training loss: 0.6877027463557115
Epoch: 28 | Iteration number: [680/4518] 15% | Training loss: 0.6876837263212484
Epoch: 28 | Iteration number: [690/4518] 15% | Training loss: 0.6876767504042474
Epoch: 28 | Iteration number: [700/4518] 15% | Training loss: 0.6876489668233055
Epoch: 28 | Iteration number: [710/4518] 15% | Training loss: 0.687635293393068
Epoch: 28 | Iteration number: [720/4518] 15% | Training loss: 0.6876334541373783
Epoch: 28 | Iteration number: [730/4518] 16% | Training loss: 0.6876141283610095
Epoch: 28 | Iteration number: [740/4518] 16% | Training loss: 0.6876151166252188
Epoch: 28 | Iteration number: [750/4518] 16% | Training loss: 0.6876113693714142
Epoch: 28 | Iteration number: [760/4518] 16% | Training loss: 0.6876078652708154
Epoch: 28 | Iteration number: [770/4518] 17% | Training loss: 0.6875850994865615
Epoch: 28 | Iteration number: [780/4518] 17% | Training loss: 0.6875589316472029
Epoch: 28 | Iteration number: [790/4518] 17% | Training loss: 0.687541537496108
Epoch: 28 | Iteration number: [800/4518] 17% | Training loss: 0.687540105059743
Epoch: 28 | Iteration number: [810/4518] 17% | Training loss: 0.687526982434002
Epoch: 28 | Iteration number: [820/4518] 18% | Training loss: 0.6875121158797567
Epoch: 28 | Iteration number: [830/4518] 18% | Training loss: 0.6874977509659457
Epoch: 28 | Iteration number: [840/4518] 18% | Training loss: 0.6874872182096754
Epoch: 28 | Iteration number: [850/4518] 18% | Training loss: 0.6874760250484242
Epoch: 28 | Iteration number: [860/4518] 19% | Training loss: 0.6874860125225644
Epoch: 28 | Iteration number: [870/4518] 19% | Training loss: 0.6874664524505878
Epoch: 28 | Iteration number: [880/4518] 19% | Training loss: 0.6874595767395063
Epoch: 28 | Iteration number: [890/4518] 19% | Training loss: 0.6874600368269373
Epoch: 28 | Iteration number: [900/4518] 19% | Training loss: 0.6874587551752727
Epoch: 28 | Iteration number: [910/4518] 20% | Training loss: 0.6874524504928798
Epoch: 28 | Iteration number: [920/4518] 20% | Training loss: 0.6874448480165523
Epoch: 28 | Iteration number: [930/4518] 20% | Training loss: 0.6874350536254145
Epoch: 28 | Iteration number: [940/4518] 20% | Training loss: 0.6874363825042197
Epoch: 28 | Iteration number: [950/4518] 21% | Training loss: 0.6874267507226843
Epoch: 28 | Iteration number: [960/4518] 21% | Training loss: 0.6874073795353373
Epoch: 28 | Iteration number: [970/4518] 21% | Training loss: 0.6873982454083629
Epoch: 28 | Iteration number: [980/4518] 21% | Training loss: 0.6874001115560532
Epoch: 28 | Iteration number: [990/4518] 21% | Training loss: 0.6873952294840957
Epoch: 28 | Iteration number: [1000/4518] 22% | Training loss: 0.6873971820473671
Epoch: 28 | Iteration number: [1010/4518] 22% | Training loss: 0.6873928854371062
Epoch: 28 | Iteration number: [1020/4518] 22% | Training loss: 0.6873842548505933
Epoch: 28 | Iteration number: [1030/4518] 22% | Training loss: 0.6873824332524272
Epoch: 28 | Iteration number: [1040/4518] 23% | Training loss: 0.687378403200553
Epoch: 28 | Iteration number: [1050/4518] 23% | Training loss: 0.6873825157824017
Epoch: 28 | Iteration number: [1060/4518] 23% | Training loss: 0.6873593839834321
Epoch: 28 | Iteration number: [1070/4518] 23% | Training loss: 0.6873528461589992
Epoch: 28 | Iteration number: [1080/4518] 23% | Training loss: 0.6873508542776108
Epoch: 28 | Iteration number: [1090/4518] 24% | Training loss: 0.6873395310082567
Epoch: 28 | Iteration number: [1100/4518] 24% | Training loss: 0.6873474088040266
Epoch: 28 | Iteration number: [1110/4518] 24% | Training loss: 0.6873323684340125
Epoch: 28 | Iteration number: [1120/4518] 24% | Training loss: 0.6873245865106583
Epoch: 28 | Iteration number: [1130/4518] 25% | Training loss: 0.6873129028134641
Epoch: 28 | Iteration number: [1140/4518] 25% | Training loss: 0.6873178156321509
Epoch: 28 | Iteration number: [1150/4518] 25% | Training loss: 0.6873140956007916
Epoch: 28 | Iteration number: [1160/4518] 25% | Training loss: 0.6873159283194049
Epoch: 28 | Iteration number: [1170/4518] 25% | Training loss: 0.687313652344239
Epoch: 28 | Iteration number: [1180/4518] 26% | Training loss: 0.6873015387078463
Epoch: 28 | Iteration number: [1190/4518] 26% | Training loss: 0.6872972697770896
Epoch: 28 | Iteration number: [1200/4518] 26% | Training loss: 0.6872878850499788
Epoch: 28 | Iteration number: [1210/4518] 26% | Training loss: 0.6872849064425004
Epoch: 28 | Iteration number: [1220/4518] 27% | Training loss: 0.6872820823407564
Epoch: 28 | Iteration number: [1230/4518] 27% | Training loss: 0.6872752265716956
Epoch: 28 | Iteration number: [1240/4518] 27% | Training loss: 0.6872720427570804
Epoch: 28 | Iteration number: [1250/4518] 27% | Training loss: 0.6872697014808655
Epoch: 28 | Iteration number: [1260/4518] 27% | Training loss: 0.6872685718630988
Epoch: 28 | Iteration number: [1270/4518] 28% | Training loss: 0.6872677380175103
Epoch: 28 | Iteration number: [1280/4518] 28% | Training loss: 0.6872585387434811
Epoch: 28 | Iteration number: [1290/4518] 28% | Training loss: 0.6872548115345859
Epoch: 28 | Iteration number: [1300/4518] 28% | Training loss: 0.6872556416346477
Epoch: 28 | Iteration number: [1310/4518] 28% | Training loss: 0.6872572936629521
Epoch: 28 | Iteration number: [1320/4518] 29% | Training loss: 0.6872568212223775
Epoch: 28 | Iteration number: [1330/4518] 29% | Training loss: 0.68724479634959
Epoch: 28 | Iteration number: [1340/4518] 29% | Training loss: 0.6872414117428793
Epoch: 28 | Iteration number: [1350/4518] 29% | Training loss: 0.6872416863176558
Epoch: 28 | Iteration number: [1360/4518] 30% | Training loss: 0.6872382306439035
Epoch: 28 | Iteration number: [1370/4518] 30% | Training loss: 0.6872382129195833
Epoch: 28 | Iteration number: [1380/4518] 30% | Training loss: 0.6872410367364469
Epoch: 28 | Iteration number: [1390/4518] 30% | Training loss: 0.6872406422663078
Epoch: 28 | Iteration number: [1400/4518] 30% | Training loss: 0.6872372936776706
Epoch: 28 | Iteration number: [1410/4518] 31% | Training loss: 0.6872394601926736
Epoch: 28 | Iteration number: [1420/4518] 31% | Training loss: 0.6872373820610449
Epoch: 28 | Iteration number: [1430/4518] 31% | Training loss: 0.6872425589944933
Epoch: 28 | Iteration number: [1440/4518] 31% | Training loss: 0.6872437871578667
Epoch: 28 | Iteration number: [1450/4518] 32% | Training loss: 0.6872435401636978
Epoch: 28 | Iteration number: [1460/4518] 32% | Training loss: 0.6872464580895149
Epoch: 28 | Iteration number: [1470/4518] 32% | Training loss: 0.6872432349895944
Epoch: 28 | Iteration number: [1480/4518] 32% | Training loss: 0.6872448348918476
Epoch: 28 | Iteration number: [1490/4518] 32% | Training loss: 0.687243962007881
Epoch: 28 | Iteration number: [1500/4518] 33% | Training loss: 0.6872437030871709
Epoch: 28 | Iteration number: [1510/4518] 33% | Training loss: 0.6872474364492277
Epoch: 28 | Iteration number: [1520/4518] 33% | Training loss: 0.6872365362942219
Epoch: 28 | Iteration number: [1530/4518] 33% | Training loss: 0.6872355834331387
Epoch: 28 | Iteration number: [1540/4518] 34% | Training loss: 0.6872279155563998
Epoch: 28 | Iteration number: [1550/4518] 34% | Training loss: 0.6872269391629003
Epoch: 28 | Iteration number: [1560/4518] 34% | Training loss: 0.6872232070718056
Epoch: 28 | Iteration number: [1570/4518] 34% | Training loss: 0.6872197462874613
Epoch: 28 | Iteration number: [1580/4518] 34% | Training loss: 0.6872239959390858
Epoch: 28 | Iteration number: [1590/4518] 35% | Training loss: 0.6872049257815259
Epoch: 28 | Iteration number: [1600/4518] 35% | Training loss: 0.6872035941854119
Epoch: 28 | Iteration number: [1610/4518] 35% | Training loss: 0.6872029506271671
Epoch: 28 | Iteration number: [1620/4518] 35% | Training loss: 0.6872077614436914
Epoch: 28 | Iteration number: [1630/4518] 36% | Training loss: 0.6872096468700222
Epoch: 28 | Iteration number: [1640/4518] 36% | Training loss: 0.6872094168895628
Epoch: 28 | Iteration number: [1650/4518] 36% | Training loss: 0.687208519559918
Epoch: 28 | Iteration number: [1660/4518] 36% | Training loss: 0.6872029385652887
Epoch: 28 | Iteration number: [1670/4518] 36% | Training loss: 0.6872063483663662
Epoch: 28 | Iteration number: [1680/4518] 37% | Training loss: 0.6871993337003958
Epoch: 28 | Iteration number: [1690/4518] 37% | Training loss: 0.6871980921051206
Epoch: 28 | Iteration number: [1700/4518] 37% | Training loss: 0.6871938388137256
Epoch: 28 | Iteration number: [1710/4518] 37% | Training loss: 0.6871929143953045
Epoch: 28 | Iteration number: [1720/4518] 38% | Training loss: 0.6871924373992654
Epoch: 28 | Iteration number: [1730/4518] 38% | Training loss: 0.6871920170467024
Epoch: 28 | Iteration number: [1740/4518] 38% | Training loss: 0.6871883348144334
Epoch: 28 | Iteration number: [1750/4518] 38% | Training loss: 0.6871971487998962
Epoch: 28 | Iteration number: [1760/4518] 38% | Training loss: 0.6871813778850165
Epoch: 28 | Iteration number: [1770/4518] 39% | Training loss: 0.6871791398457888
Epoch: 28 | Iteration number: [1780/4518] 39% | Training loss: 0.6871689325638032
Epoch: 28 | Iteration number: [1790/4518] 39% | Training loss: 0.6871750543570385
Epoch: 28 | Iteration number: [1800/4518] 39% | Training loss: 0.687166481481658
Epoch: 28 | Iteration number: [1810/4518] 40% | Training loss: 0.6871680190220723
Epoch: 28 | Iteration number: [1820/4518] 40% | Training loss: 0.6871646256564737
Epoch: 28 | Iteration number: [1830/4518] 40% | Training loss: 0.6871647184012366
Epoch: 28 | Iteration number: [1840/4518] 40% | Training loss: 0.6871610935939395
Epoch: 28 | Iteration number: [1850/4518] 40% | Training loss: 0.6871526387575511
Epoch: 28 | Iteration number: [1860/4518] 41% | Training loss: 0.6871544987283728
Epoch: 28 | Iteration number: [1870/4518] 41% | Training loss: 0.6871531577671275
Epoch: 28 | Iteration number: [1880/4518] 41% | Training loss: 0.6871559774304958
Epoch: 28 | Iteration number: [1890/4518] 41% | Training loss: 0.6871568635027244
Epoch: 28 | Iteration number: [1900/4518] 42% | Training loss: 0.6871588069200516
Epoch: 28 | Iteration number: [1910/4518] 42% | Training loss: 0.6871572686115485
Epoch: 28 | Iteration number: [1920/4518] 42% | Training loss: 0.6871410364595553
Epoch: 28 | Iteration number: [1930/4518] 42% | Training loss: 0.6871355545644315
Epoch: 28 | Iteration number: [1940/4518] 42% | Training loss: 0.6871331455781288
Epoch: 28 | Iteration number: [1950/4518] 43% | Training loss: 0.6871245541939368
Epoch: 28 | Iteration number: [1960/4518] 43% | Training loss: 0.6871247885178546
Epoch: 28 | Iteration number: [1970/4518] 43% | Training loss: 0.6871254939113172
Epoch: 28 | Iteration number: [1980/4518] 43% | Training loss: 0.6871262142754564
Epoch: 28 | Iteration number: [1990/4518] 44% | Training loss: 0.6871205777978179
Epoch: 28 | Iteration number: [2000/4518] 44% | Training loss: 0.6871194649934769
Epoch: 28 | Iteration number: [2010/4518] 44% | Training loss: 0.6871155998006983
Epoch: 28 | Iteration number: [2020/4518] 44% | Training loss: 0.6871096750592242
Epoch: 28 | Iteration number: [2030/4518] 44% | Training loss: 0.6871100615691669
Epoch: 28 | Iteration number: [2040/4518] 45% | Training loss: 0.6871151729249487
Epoch: 28 | Iteration number: [2050/4518] 45% | Training loss: 0.68711407928932
Epoch: 28 | Iteration number: [2060/4518] 45% | Training loss: 0.6871182719769987
Epoch: 28 | Iteration number: [2070/4518] 45% | Training loss: 0.6871269795629713
Epoch: 28 | Iteration number: [2080/4518] 46% | Training loss: 0.6871221762723647
Epoch: 28 | Iteration number: [2090/4518] 46% | Training loss: 0.6871221508706016
Epoch: 28 | Iteration number: [2100/4518] 46% | Training loss: 0.6871199310109729
Epoch: 28 | Iteration number: [2110/4518] 46% | Training loss: 0.6871182847926967
Epoch: 28 | Iteration number: [2120/4518] 46% | Training loss: 0.6871182530837239
Epoch: 28 | Iteration number: [2130/4518] 47% | Training loss: 0.6871242446518839
Epoch: 28 | Iteration number: [2140/4518] 47% | Training loss: 0.6871237396636856
Epoch: 28 | Iteration number: [2150/4518] 47% | Training loss: 0.6871255021317061
Epoch: 28 | Iteration number: [2160/4518] 47% | Training loss: 0.6871214837939651
Epoch: 28 | Iteration number: [2170/4518] 48% | Training loss: 0.6871192729692854
Epoch: 28 | Iteration number: [2180/4518] 48% | Training loss: 0.6871180308247925
Epoch: 28 | Iteration number: [2190/4518] 48% | Training loss: 0.6871127949729902
Epoch: 28 | Iteration number: [2200/4518] 48% | Training loss: 0.6871067584644664
Epoch: 28 | Iteration number: [2210/4518] 48% | Training loss: 0.6871007557907794
Epoch: 28 | Iteration number: [2220/4518] 49% | Training loss: 0.687101360215797
Epoch: 28 | Iteration number: [2230/4518] 49% | Training loss: 0.687097488363762
Epoch: 28 | Iteration number: [2240/4518] 49% | Training loss: 0.687094237868275
Epoch: 28 | Iteration number: [2250/4518] 49% | Training loss: 0.6870950806405809
Epoch: 28 | Iteration number: [2260/4518] 50% | Training loss: 0.6870905328640896
Epoch: 28 | Iteration number: [2270/4518] 50% | Training loss: 0.6870840001999019
Epoch: 28 | Iteration number: [2280/4518] 50% | Training loss: 0.687085918219466
Epoch: 28 | Iteration number: [2290/4518] 50% | Training loss: 0.6870779368814943
Epoch: 28 | Iteration number: [2300/4518] 50% | Training loss: 0.6870824384430181
Epoch: 28 | Iteration number: [2310/4518] 51% | Training loss: 0.6870844381712216
Epoch: 28 | Iteration number: [2320/4518] 51% | Training loss: 0.6870821804835878
Epoch: 28 | Iteration number: [2330/4518] 51% | Training loss: 0.6870827723470369
Epoch: 28 | Iteration number: [2340/4518] 51% | Training loss: 0.6870792635230937
Epoch: 28 | Iteration number: [2350/4518] 52% | Training loss: 0.6870806810450046
Epoch: 28 | Iteration number: [2360/4518] 52% | Training loss: 0.6870756111155122
Epoch: 28 | Iteration number: [2370/4518] 52% | Training loss: 0.6870758923548687
Epoch: 28 | Iteration number: [2380/4518] 52% | Training loss: 0.6870777086049569
Epoch: 28 | Iteration number: [2390/4518] 52% | Training loss: 0.6870753425683935
Epoch: 28 | Iteration number: [2400/4518] 53% | Training loss: 0.6870732411990563
Epoch: 28 | Iteration number: [2410/4518] 53% | Training loss: 0.6870695296659509
Epoch: 28 | Iteration number: [2420/4518] 53% | Training loss: 0.6870697323448401
Epoch: 28 | Iteration number: [2430/4518] 53% | Training loss: 0.6870646316328166
Epoch: 28 | Iteration number: [2440/4518] 54% | Training loss: 0.6870652200990036
Epoch: 28 | Iteration number: [2450/4518] 54% | Training loss: 0.6870647198813302
Epoch: 28 | Iteration number: [2460/4518] 54% | Training loss: 0.6870581279440624
Epoch: 28 | Iteration number: [2470/4518] 54% | Training loss: 0.6870561578737097
Epoch: 28 | Iteration number: [2480/4518] 54% | Training loss: 0.6870521686971187
Epoch: 28 | Iteration number: [2490/4518] 55% | Training loss: 0.6870528818852452
Epoch: 28 | Iteration number: [2500/4518] 55% | Training loss: 0.68705762860775
Epoch: 28 | Iteration number: [2510/4518] 55% | Training loss: 0.6870570357814728
Epoch: 28 | Iteration number: [2520/4518] 55% | Training loss: 0.687063170851223
Epoch: 28 | Iteration number: [2530/4518] 55% | Training loss: 0.6870643011666098
Epoch: 28 | Iteration number: [2540/4518] 56% | Training loss: 0.687065842254894
Epoch: 28 | Iteration number: [2550/4518] 56% | Training loss: 0.6870622564297096
Epoch: 28 | Iteration number: [2560/4518] 56% | Training loss: 0.687065607868135
Epoch: 28 | Iteration number: [2570/4518] 56% | Training loss: 0.6870681547237277
Epoch: 28 | Iteration number: [2580/4518] 57% | Training loss: 0.6870711396830951
Epoch: 28 | Iteration number: [2590/4518] 57% | Training loss: 0.687067756298426
Epoch: 28 | Iteration number: [2600/4518] 57% | Training loss: 0.6870700021661245
Epoch: 28 | Iteration number: [2610/4518] 57% | Training loss: 0.6870630401989509
Epoch: 28 | Iteration number: [2620/4518] 57% | Training loss: 0.6870638863958475
Epoch: 28 | Iteration number: [2630/4518] 58% | Training loss: 0.687069840893546
Epoch: 28 | Iteration number: [2640/4518] 58% | Training loss: 0.6870694557599949
Epoch: 28 | Iteration number: [2650/4518] 58% | Training loss: 0.6870667881335852
Epoch: 28 | Iteration number: [2660/4518] 58% | Training loss: 0.6870669234516029
Epoch: 28 | Iteration number: [2670/4518] 59% | Training loss: 0.6870659428812591
Epoch: 28 | Iteration number: [2680/4518] 59% | Training loss: 0.6870720613581031
Epoch: 28 | Iteration number: [2690/4518] 59% | Training loss: 0.6870726138907294
Epoch: 28 | Iteration number: [2700/4518] 59% | Training loss: 0.6870743655054657
Epoch: 28 | Iteration number: [2710/4518] 59% | Training loss: 0.6870734009135693
Epoch: 28 | Iteration number: [2720/4518] 60% | Training loss: 0.6870730720022146
Epoch: 28 | Iteration number: [2730/4518] 60% | Training loss: 0.6870706612810548
Epoch: 28 | Iteration number: [2740/4518] 60% | Training loss: 0.68707199753636
Epoch: 28 | Iteration number: [2750/4518] 60% | Training loss: 0.6870636155822061
Epoch: 28 | Iteration number: [2760/4518] 61% | Training loss: 0.6870612595176351
Epoch: 28 | Iteration number: [2770/4518] 61% | Training loss: 0.6870599421568295
Epoch: 28 | Iteration number: [2780/4518] 61% | Training loss: 0.687054188109988
Epoch: 28 | Iteration number: [2790/4518] 61% | Training loss: 0.6870533305043388
Epoch: 28 | Iteration number: [2800/4518] 61% | Training loss: 0.6870598826663835
Epoch: 28 | Iteration number: [2810/4518] 62% | Training loss: 0.6870588125283184
Epoch: 28 | Iteration number: [2820/4518] 62% | Training loss: 0.6870615150277496
Epoch: 28 | Iteration number: [2830/4518] 62% | Training loss: 0.6870582344885849
Epoch: 28 | Iteration number: [2840/4518] 62% | Training loss: 0.687058236586376
Epoch: 28 | Iteration number: [2850/4518] 63% | Training loss: 0.6870607040012092
Epoch: 28 | Iteration number: [2860/4518] 63% | Training loss: 0.6870619899743087
Epoch: 28 | Iteration number: [2870/4518] 63% | Training loss: 0.6870627697751912
Epoch: 28 | Iteration number: [2880/4518] 63% | Training loss: 0.6870647315763765
Epoch: 28 | Iteration number: [2890/4518] 63% | Training loss: 0.6870667757666234
Epoch: 28 | Iteration number: [2900/4518] 64% | Training loss: 0.6870645606312259
Epoch: 28 | Iteration number: [2910/4518] 64% | Training loss: 0.6870617890276041
Epoch: 28 | Iteration number: [2920/4518] 64% | Training loss: 0.687062213253485
Epoch: 28 | Iteration number: [2930/4518] 64% | Training loss: 0.6870649599174591
Epoch: 28 | Iteration number: [2940/4518] 65% | Training loss: 0.6870678109984819
Epoch: 28 | Iteration number: [2950/4518] 65% | Training loss: 0.68706011919652
Epoch: 28 | Iteration number: [2960/4518] 65% | Training loss: 0.6870621914396415
Epoch: 28 | Iteration number: [2970/4518] 65% | Training loss: 0.687063107004872
Epoch: 28 | Iteration number: [2980/4518] 65% | Training loss: 0.6870660801261863
Epoch: 28 | Iteration number: [2990/4518] 66% | Training loss: 0.6870681569727767
Epoch: 28 | Iteration number: [3000/4518] 66% | Training loss: 0.6870700935721398
Epoch: 28 | Iteration number: [3010/4518] 66% | Training loss: 0.6870686794238233
Epoch: 28 | Iteration number: [3020/4518] 66% | Training loss: 0.6870713843809848
Epoch: 28 | Iteration number: [3030/4518] 67% | Training loss: 0.6870703423574026
Epoch: 28 | Iteration number: [3040/4518] 67% | Training loss: 0.68706998050605
Epoch: 28 | Iteration number: [3050/4518] 67% | Training loss: 0.687071974570634
Epoch: 28 | Iteration number: [3060/4518] 67% | Training loss: 0.6870707315362357
Epoch: 28 | Iteration number: [3070/4518] 67% | Training loss: 0.6870724317693555
Epoch: 28 | Iteration number: [3080/4518] 68% | Training loss: 0.6870721090923656
Epoch: 28 | Iteration number: [3090/4518] 68% | Training loss: 0.6870729973593962
Epoch: 28 | Iteration number: [3100/4518] 68% | Training loss: 0.68707199337021
Epoch: 28 | Iteration number: [3110/4518] 68% | Training loss: 0.6870687606250359
Epoch: 28 | Iteration number: [3120/4518] 69% | Training loss: 0.6870692234581862
Epoch: 28 | Iteration number: [3130/4518] 69% | Training loss: 0.6870709110563175
Epoch: 28 | Iteration number: [3140/4518] 69% | Training loss: 0.6870692343089231
Epoch: 28 | Iteration number: [3150/4518] 69% | Training loss: 0.6870698538469889
Epoch: 28 | Iteration number: [3160/4518] 69% | Training loss: 0.6870730732626553
Epoch: 28 | Iteration number: [3170/4518] 70% | Training loss: 0.6870742338876995
Epoch: 28 | Iteration number: [3180/4518] 70% | Training loss: 0.6870715139984335
Epoch: 28 | Iteration number: [3190/4518] 70% | Training loss: 0.6870699645583532
Epoch: 28 | Iteration number: [3200/4518] 70% | Training loss: 0.687071176841855
Epoch: 28 | Iteration number: [3210/4518] 71% | Training loss: 0.6870716971400371
Epoch: 28 | Iteration number: [3220/4518] 71% | Training loss: 0.6870687147475177
Epoch: 28 | Iteration number: [3230/4518] 71% | Training loss: 0.6870633230120774
Epoch: 28 | Iteration number: [3240/4518] 71% | Training loss: 0.6870628639503762
Epoch: 28 | Iteration number: [3250/4518] 71% | Training loss: 0.6870627692112556
Epoch: 28 | Iteration number: [3260/4518] 72% | Training loss: 0.6870620332064072
Epoch: 28 | Iteration number: [3270/4518] 72% | Training loss: 0.6870624422480207
Epoch: 28 | Iteration number: [3280/4518] 72% | Training loss: 0.687065027036318
Epoch: 28 | Iteration number: [3290/4518] 72% | Training loss: 0.6870662302231716
Epoch: 28 | Iteration number: [3300/4518] 73% | Training loss: 0.6870665841210972
Epoch: 28 | Iteration number: [3310/4518] 73% | Training loss: 0.6870667017658671
Epoch: 28 | Iteration number: [3320/4518] 73% | Training loss: 0.6870660235723817
Epoch: 28 | Iteration number: [3330/4518] 73% | Training loss: 0.6870645047845068
Epoch: 28 | Iteration number: [3340/4518] 73% | Training loss: 0.6870585256529426
Epoch: 28 | Iteration number: [3350/4518] 74% | Training loss: 0.6870587044687414
Epoch: 28 | Iteration number: [3360/4518] 74% | Training loss: 0.6870549969729923
Epoch: 28 | Iteration number: [3370/4518] 74% | Training loss: 0.6870500225518507
Epoch: 28 | Iteration number: [3380/4518] 74% | Training loss: 0.6870528569940985
Epoch: 28 | Iteration number: [3390/4518] 75% | Training loss: 0.6870491308624413
Epoch: 28 | Iteration number: [3400/4518] 75% | Training loss: 0.6870462596241166
Epoch: 28 | Iteration number: [3410/4518] 75% | Training loss: 0.6870448556813327
Epoch: 28 | Iteration number: [3420/4518] 75% | Training loss: 0.6870421510516551
Epoch: 28 | Iteration number: [3430/4518] 75% | Training loss: 0.6870448216578703
Epoch: 28 | Iteration number: [3440/4518] 76% | Training loss: 0.6870434018241804
Epoch: 28 | Iteration number: [3450/4518] 76% | Training loss: 0.6870427317204683
Epoch: 28 | Iteration number: [3460/4518] 76% | Training loss: 0.6870465680870707
Epoch: 28 | Iteration number: [3470/4518] 76% | Training loss: 0.6870457548744741
Epoch: 28 | Iteration number: [3480/4518] 77% | Training loss: 0.6870462291713418
Epoch: 28 | Iteration number: [3490/4518] 77% | Training loss: 0.6870451158473007
Epoch: 28 | Iteration number: [3500/4518] 77% | Training loss: 0.6870485074520111
Epoch: 28 | Iteration number: [3510/4518] 77% | Training loss: 0.6870450896245462
Epoch: 28 | Iteration number: [3520/4518] 77% | Training loss: 0.6870467914437706
Epoch: 28 | Iteration number: [3530/4518] 78% | Training loss: 0.6870457159561071
Epoch: 28 | Iteration number: [3540/4518] 78% | Training loss: 0.687044723626584
Epoch: 28 | Iteration number: [3550/4518] 78% | Training loss: 0.6870459404629721
Epoch: 28 | Iteration number: [3560/4518] 78% | Training loss: 0.6870456691873208
Epoch: 28 | Iteration number: [3570/4518] 79% | Training loss: 0.6870437946974063
Epoch: 28 | Iteration number: [3580/4518] 79% | Training loss: 0.6870472392722881
Epoch: 28 | Iteration number: [3590/4518] 79% | Training loss: 0.6870438680675368
Epoch: 28 | Iteration number: [3600/4518] 79% | Training loss: 0.6870455943048001
Epoch: 28 | Iteration number: [3610/4518] 79% | Training loss: 0.687047432449716
Epoch: 28 | Iteration number: [3620/4518] 80% | Training loss: 0.687043135913696
Epoch: 28 | Iteration number: [3630/4518] 80% | Training loss: 0.6870446927948103
Epoch: 28 | Iteration number: [3640/4518] 80% | Training loss: 0.68704665602891
Epoch: 28 | Iteration number: [3650/4518] 80% | Training loss: 0.687045135171446
Epoch: 28 | Iteration number: [3660/4518] 81% | Training loss: 0.6870444206592163
Epoch: 28 | Iteration number: [3670/4518] 81% | Training loss: 0.6870433993333042
Epoch: 28 | Iteration number: [3680/4518] 81% | Training loss: 0.6870400418082009
Epoch: 28 | Iteration number: [3690/4518] 81% | Training loss: 0.6870420203783971
Epoch: 28 | Iteration number: [3700/4518] 81% | Training loss: 0.6870423899792336
Epoch: 28 | Iteration number: [3710/4518] 82% | Training loss: 0.6870412923576376
Epoch: 28 | Iteration number: [3720/4518] 82% | Training loss: 0.6870396907291104
Epoch: 28 | Iteration number: [3730/4518] 82% | Training loss: 0.6870420252989189
Epoch: 28 | Iteration number: [3740/4518] 82% | Training loss: 0.6870457499900604
Epoch: 28 | Iteration number: [3750/4518] 83% | Training loss: 0.6870465285936992
Epoch: 28 | Iteration number: [3760/4518] 83% | Training loss: 0.6870464789265014
Epoch: 28 | Iteration number: [3770/4518] 83% | Training loss: 0.6870489190680911
Epoch: 28 | Iteration number: [3780/4518] 83% | Training loss: 0.6870482189787759
Epoch: 28 | Iteration number: [3790/4518] 83% | Training loss: 0.687046782967283
Epoch: 28 | Iteration number: [3800/4518] 84% | Training loss: 0.6870440240753325
Epoch: 28 | Iteration number: [3810/4518] 84% | Training loss: 0.6870467455055457
Epoch: 28 | Iteration number: [3820/4518] 84% | Training loss: 0.6870464150506165
Epoch: 28 | Iteration number: [3830/4518] 84% | Training loss: 0.687048181089969
Epoch: 28 | Iteration number: [3840/4518] 84% | Training loss: 0.6870489698058615
Epoch: 28 | Iteration number: [3850/4518] 85% | Training loss: 0.6870468856916799
Epoch: 28 | Iteration number: [3860/4518] 85% | Training loss: 0.6870458156333686
Epoch: 28 | Iteration number: [3870/4518] 85% | Training loss: 0.6870426104358308
Epoch: 28 | Iteration number: [3880/4518] 85% | Training loss: 0.6870452991619552
Epoch: 28 | Iteration number: [3890/4518] 86% | Training loss: 0.6870447568078274
Epoch: 28 | Iteration number: [3900/4518] 86% | Training loss: 0.6870436419890477
Epoch: 28 | Iteration number: [3910/4518] 86% | Training loss: 0.6870442139523109
Epoch: 28 | Iteration number: [3920/4518] 86% | Training loss: 0.6870450425512936
Epoch: 28 | Iteration number: [3930/4518] 86% | Training loss: 0.6870462384539403
Epoch: 28 | Iteration number: [3940/4518] 87% | Training loss: 0.6870461142759032
Epoch: 28 | Iteration number: [3950/4518] 87% | Training loss: 0.687044230925886
Epoch: 28 | Iteration number: [3960/4518] 87% | Training loss: 0.6870434716945947
Epoch: 28 | Iteration number: [3970/4518] 87% | Training loss: 0.6870455053050812
Epoch: 28 | Iteration number: [3980/4518] 88% | Training loss: 0.687043889787928
Epoch: 28 | Iteration number: [3990/4518] 88% | Training loss: 0.6870429068430325
Epoch: 28 | Iteration number: [4000/4518] 88% | Training loss: 0.6870414448976516
Epoch: 28 | Iteration number: [4010/4518] 88% | Training loss: 0.6870417546750304
Epoch: 28 | Iteration number: [4020/4518] 88% | Training loss: 0.6870393244484764
Epoch: 28 | Iteration number: [4030/4518] 89% | Training loss: 0.6870383472803508
Epoch: 28 | Iteration number: [4040/4518] 89% | Training loss: 0.6870431340862029
Epoch: 28 | Iteration number: [4050/4518] 89% | Training loss: 0.6870435151641752
Epoch: 28 | Iteration number: [4060/4518] 89% | Training loss: 0.6870434848252188
Epoch: 28 | Iteration number: [4070/4518] 90% | Training loss: 0.6870430433193647
Epoch: 28 | Iteration number: [4080/4518] 90% | Training loss: 0.6870444871631323
Epoch: 28 | Iteration number: [4090/4518] 90% | Training loss: 0.6870426105695132
Epoch: 28 | Iteration number: [4100/4518] 90% | Training loss: 0.6870405061797398
Epoch: 28 | Iteration number: [4110/4518] 90% | Training loss: 0.6870387820721833
Epoch: 28 | Iteration number: [4120/4518] 91% | Training loss: 0.6870378068783908
Epoch: 28 | Iteration number: [4130/4518] 91% | Training loss: 0.6870369885793322
Epoch: 28 | Iteration number: [4140/4518] 91% | Training loss: 0.6870380896733003
Epoch: 28 | Iteration number: [4150/4518] 91% | Training loss: 0.687038262565452
Epoch: 28 | Iteration number: [4160/4518] 92% | Training loss: 0.6870351954291646
Epoch: 28 | Iteration number: [4170/4518] 92% | Training loss: 0.687036039689176
Epoch: 28 | Iteration number: [4180/4518] 92% | Training loss: 0.6870363256720264
Epoch: 28 | Iteration number: [4190/4518] 92% | Training loss: 0.6870351837330047
Epoch: 28 | Iteration number: [4200/4518] 92% | Training loss: 0.6870325725419181
Epoch: 28 | Iteration number: [4210/4518] 93% | Training loss: 0.6870341698659004
Epoch: 28 | Iteration number: [4220/4518] 93% | Training loss: 0.687034289828409
Epoch: 28 | Iteration number: [4230/4518] 93% | Training loss: 0.6870349983092459
Epoch: 28 | Iteration number: [4240/4518] 93% | Training loss: 0.6870363778663131
Epoch: 28 | Iteration number: [4250/4518] 94% | Training loss: 0.687036246846704
Epoch: 28 | Iteration number: [4260/4518] 94% | Training loss: 0.6870328134913959
Epoch: 28 | Iteration number: [4270/4518] 94% | Training loss: 0.6870359293470897
Epoch: 28 | Iteration number: [4280/4518] 94% | Training loss: 0.687039497731445
Epoch: 28 | Iteration number: [4290/4518] 94% | Training loss: 0.6870383398099379
Epoch: 28 | Iteration number: [4300/4518] 95% | Training loss: 0.6870366205309713
Epoch: 28 | Iteration number: [4310/4518] 95% | Training loss: 0.6870360452724996
Epoch: 28 | Iteration number: [4320/4518] 95% | Training loss: 0.6870355414847533
Epoch: 28 | Iteration number: [4330/4518] 95% | Training loss: 0.6870341509374129
Epoch: 28 | Iteration number: [4340/4518] 96% | Training loss: 0.6870357355214484
Epoch: 28 | Iteration number: [4350/4518] 96% | Training loss: 0.6870347339531471
Epoch: 28 | Iteration number: [4360/4518] 96% | Training loss: 0.687032227874349
Epoch: 28 | Iteration number: [4370/4518] 96% | Training loss: 0.6870318211052456
Epoch: 28 | Iteration number: [4380/4518] 96% | Training loss: 0.6870297482568923
Epoch: 28 | Iteration number: [4390/4518] 97% | Training loss: 0.6870277726976095
Epoch: 28 | Iteration number: [4400/4518] 97% | Training loss: 0.6870291325991804
Epoch: 28 | Iteration number: [4410/4518] 97% | Training loss: 0.687029684454946
Epoch: 28 | Iteration number: [4420/4518] 97% | Training loss: 0.6870280214024884
Epoch: 28 | Iteration number: [4430/4518] 98% | Training loss: 0.6870260522946816
Epoch: 28 | Iteration number: [4440/4518] 98% | Training loss: 0.6870244175329938
Epoch: 28 | Iteration number: [4450/4518] 98% | Training loss: 0.6870224884118926
Epoch: 28 | Iteration number: [4460/4518] 98% | Training loss: 0.6870203649516597
Epoch: 28 | Iteration number: [4470/4518] 98% | Training loss: 0.6870190585086277
Epoch: 28 | Iteration number: [4480/4518] 99% | Training loss: 0.6870178292106305
Epoch: 28 | Iteration number: [4490/4518] 99% | Training loss: 0.6870187579390732
Epoch: 28 | Iteration number: [4500/4518] 99% | Training loss: 0.687018228371938
Epoch: 28 | Iteration number: [4510/4518] 99% | Training loss: 0.6870165279461381

 End of epoch: 28 | Train Loss: 0.6868622854859917 | Training Time: 640 

 End of epoch: 28 | Eval Loss: 0.6901040162358966 | Evaluating Time: 16 
Epoch: 29 | Iteration number: [10/4518] 0% | Training loss: 0.755289489030838
Epoch: 29 | Iteration number: [20/4518] 0% | Training loss: 0.7212515592575073
Epoch: 29 | Iteration number: [30/4518] 0% | Training loss: 0.7099960645039877
Epoch: 29 | Iteration number: [40/4518] 0% | Training loss: 0.7041593790054321
Epoch: 29 | Iteration number: [50/4518] 1% | Training loss: 0.700609849691391
Epoch: 29 | Iteration number: [60/4518] 1% | Training loss: 0.6980417122443517
Epoch: 29 | Iteration number: [70/4518] 1% | Training loss: 0.6963549384049007
Epoch: 29 | Iteration number: [80/4518] 1% | Training loss: 0.6950151309370994
Epoch: 29 | Iteration number: [90/4518] 1% | Training loss: 0.6941482894950443
Epoch: 29 | Iteration number: [100/4518] 2% | Training loss: 0.6933867901563644
Epoch: 29 | Iteration number: [110/4518] 2% | Training loss: 0.6928235032341697
Epoch: 29 | Iteration number: [120/4518] 2% | Training loss: 0.6922909984985988
Epoch: 29 | Iteration number: [130/4518] 2% | Training loss: 0.6918929320115309
Epoch: 29 | Iteration number: [140/4518] 3% | Training loss: 0.6914229375975472
Epoch: 29 | Iteration number: [150/4518] 3% | Training loss: 0.6909892896811167
Epoch: 29 | Iteration number: [160/4518] 3% | Training loss: 0.6907105553895235
Epoch: 29 | Iteration number: [170/4518] 3% | Training loss: 0.6905255342231077
Epoch: 29 | Iteration number: [180/4518] 3% | Training loss: 0.6902262247271008
Epoch: 29 | Iteration number: [190/4518] 4% | Training loss: 0.6900336453789159
Epoch: 29 | Iteration number: [200/4518] 4% | Training loss: 0.6898561781644821
Epoch: 29 | Iteration number: [210/4518] 4% | Training loss: 0.6897338892732348
Epoch: 29 | Iteration number: [220/4518] 4% | Training loss: 0.6895277378233996
Epoch: 29 | Iteration number: [230/4518] 5% | Training loss: 0.689393138885498
Epoch: 29 | Iteration number: [240/4518] 5% | Training loss: 0.6893019487460454
Epoch: 29 | Iteration number: [250/4518] 5% | Training loss: 0.6892194867134094
Epoch: 29 | Iteration number: [260/4518] 5% | Training loss: 0.6891185350142992
Epoch: 29 | Iteration number: [270/4518] 5% | Training loss: 0.6890172636067425
Epoch: 29 | Iteration number: [280/4518] 6% | Training loss: 0.688957988364356
Epoch: 29 | Iteration number: [290/4518] 6% | Training loss: 0.6888644138286854
Epoch: 29 | Iteration number: [300/4518] 6% | Training loss: 0.6888595598936081
Epoch: 29 | Iteration number: [310/4518] 6% | Training loss: 0.6888422358420587
Epoch: 29 | Iteration number: [320/4518] 7% | Training loss: 0.688802196085453
Epoch: 29 | Iteration number: [330/4518] 7% | Training loss: 0.6887077763225093
Epoch: 29 | Iteration number: [340/4518] 7% | Training loss: 0.6886701441863003
Epoch: 29 | Iteration number: [350/4518] 7% | Training loss: 0.6886032629013061
Epoch: 29 | Iteration number: [360/4518] 7% | Training loss: 0.6885820986496077
Epoch: 29 | Iteration number: [370/4518] 8% | Training loss: 0.6885479002385526
Epoch: 29 | Iteration number: [380/4518] 8% | Training loss: 0.6884965802493849
Epoch: 29 | Iteration number: [390/4518] 8% | Training loss: 0.6884721303597475
Epoch: 29 | Iteration number: [400/4518] 8% | Training loss: 0.6884243831038475
Epoch: 29 | Iteration number: [410/4518] 9% | Training loss: 0.6883932379687705
Epoch: 29 | Iteration number: [420/4518] 9% | Training loss: 0.6883616954088211
Epoch: 29 | Iteration number: [430/4518] 9% | Training loss: 0.6883126807767291
Epoch: 29 | Iteration number: [440/4518] 9% | Training loss: 0.6882737677205693
Epoch: 29 | Iteration number: [450/4518] 9% | Training loss: 0.6882387249999576
Epoch: 29 | Iteration number: [460/4518] 10% | Training loss: 0.6882496705521708
Epoch: 29 | Iteration number: [470/4518] 10% | Training loss: 0.6882309951680772
Epoch: 29 | Iteration number: [480/4518] 10% | Training loss: 0.6882152249415715
Epoch: 29 | Iteration number: [490/4518] 10% | Training loss: 0.6881943062860139
Epoch: 29 | Iteration number: [500/4518] 11% | Training loss: 0.6881399083137513
Epoch: 29 | Iteration number: [510/4518] 11% | Training loss: 0.6881157508083419
Epoch: 29 | Iteration number: [520/4518] 11% | Training loss: 0.6880894997945198
Epoch: 29 | Iteration number: [530/4518] 11% | Training loss: 0.6880730956230523
Epoch: 29 | Iteration number: [540/4518] 11% | Training loss: 0.688069889611668
Epoch: 29 | Iteration number: [550/4518] 12% | Training loss: 0.6880387524041263
Epoch: 29 | Iteration number: [560/4518] 12% | Training loss: 0.6880082648779665
Epoch: 29 | Iteration number: [570/4518] 12% | Training loss: 0.6879886411783988
Epoch: 29 | Iteration number: [580/4518] 12% | Training loss: 0.6879587248481553
Epoch: 29 | Iteration number: [590/4518] 13% | Training loss: 0.6879366559497381
Epoch: 29 | Iteration number: [600/4518] 13% | Training loss: 0.6879334855079651
Epoch: 29 | Iteration number: [610/4518] 13% | Training loss: 0.6879348399209194
Epoch: 29 | Iteration number: [620/4518] 13% | Training loss: 0.6879102479065619
Epoch: 29 | Iteration number: [630/4518] 13% | Training loss: 0.6878899270579928
Epoch: 29 | Iteration number: [640/4518] 14% | Training loss: 0.6878707935102284
Epoch: 29 | Iteration number: [650/4518] 14% | Training loss: 0.6878431460490594
Epoch: 29 | Iteration number: [660/4518] 14% | Training loss: 0.6878427105419563
Epoch: 29 | Iteration number: [670/4518] 14% | Training loss: 0.6878282287227574
Epoch: 29 | Iteration number: [680/4518] 15% | Training loss: 0.6878042936325073
Epoch: 29 | Iteration number: [690/4518] 15% | Training loss: 0.6877845207850138
Epoch: 29 | Iteration number: [700/4518] 15% | Training loss: 0.6877819311618805
Epoch: 29 | Iteration number: [710/4518] 15% | Training loss: 0.6877786582624409
Epoch: 29 | Iteration number: [720/4518] 15% | Training loss: 0.6877664885587162
Epoch: 29 | Iteration number: [730/4518] 16% | Training loss: 0.6877583696417613
Epoch: 29 | Iteration number: [740/4518] 16% | Training loss: 0.6877554576139192
Epoch: 29 | Iteration number: [750/4518] 16% | Training loss: 0.6877512400945027
Epoch: 29 | Iteration number: [760/4518] 16% | Training loss: 0.6877251935632606
Epoch: 29 | Iteration number: [770/4518] 17% | Training loss: 0.6877162670934355
Epoch: 29 | Iteration number: [780/4518] 17% | Training loss: 0.6876793060547266
Epoch: 29 | Iteration number: [790/4518] 17% | Training loss: 0.6876706805410264
Epoch: 29 | Iteration number: [800/4518] 17% | Training loss: 0.6876598453521728
Epoch: 29 | Iteration number: [810/4518] 17% | Training loss: 0.68764022073628
Epoch: 29 | Iteration number: [820/4518] 18% | Training loss: 0.6876408912786623
Epoch: 29 | Iteration number: [830/4518] 18% | Training loss: 0.6876427205212144
Epoch: 29 | Iteration number: [840/4518] 18% | Training loss: 0.6876389653200194
Epoch: 29 | Iteration number: [850/4518] 18% | Training loss: 0.6876257625046899
Epoch: 29 | Iteration number: [860/4518] 19% | Training loss: 0.6876085324342861
Epoch: 29 | Iteration number: [870/4518] 19% | Training loss: 0.6875916894139915
Epoch: 29 | Iteration number: [880/4518] 19% | Training loss: 0.6875916949049993
Epoch: 29 | Iteration number: [890/4518] 19% | Training loss: 0.6875911063022828
Epoch: 29 | Iteration number: [900/4518] 19% | Training loss: 0.6875770683421029
Epoch: 29 | Iteration number: [910/4518] 20% | Training loss: 0.6875798258152637
Epoch: 29 | Iteration number: [920/4518] 20% | Training loss: 0.6875693563533866
Epoch: 29 | Iteration number: [930/4518] 20% | Training loss: 0.6875608233354424
Epoch: 29 | Iteration number: [940/4518] 20% | Training loss: 0.6875643361756142
Epoch: 29 | Iteration number: [950/4518] 21% | Training loss: 0.6875646102428437
Epoch: 29 | Iteration number: [960/4518] 21% | Training loss: 0.6875516924386224
Epoch: 29 | Iteration number: [970/4518] 21% | Training loss: 0.6875541738628113
Epoch: 29 | Iteration number: [980/4518] 21% | Training loss: 0.6875351209421547
Epoch: 29 | Iteration number: [990/4518] 21% | Training loss: 0.6875233361215303
Epoch: 29 | Iteration number: [1000/4518] 22% | Training loss: 0.6875208718180656
Epoch: 29 | Iteration number: [1010/4518] 22% | Training loss: 0.6875134187169595
Epoch: 29 | Iteration number: [1020/4518] 22% | Training loss: 0.6874927150268181
Epoch: 29 | Iteration number: [1030/4518] 22% | Training loss: 0.6874840180850723
Epoch: 29 | Iteration number: [1040/4518] 23% | Training loss: 0.6874800020685563
Epoch: 29 | Iteration number: [1050/4518] 23% | Training loss: 0.6874756605852218
Epoch: 29 | Iteration number: [1060/4518] 23% | Training loss: 0.6874745519656056
Epoch: 29 | Iteration number: [1070/4518] 23% | Training loss: 0.6874704974276997
Epoch: 29 | Iteration number: [1080/4518] 23% | Training loss: 0.6874658752922659
Epoch: 29 | Iteration number: [1090/4518] 24% | Training loss: 0.6874723666304842
Epoch: 29 | Iteration number: [1100/4518] 24% | Training loss: 0.6874796251275322
Epoch: 29 | Iteration number: [1110/4518] 24% | Training loss: 0.6874716180938858
Epoch: 29 | Iteration number: [1120/4518] 24% | Training loss: 0.6874732473066875
Epoch: 29 | Iteration number: [1130/4518] 25% | Training loss: 0.6874637801035316
Epoch: 29 | Iteration number: [1140/4518] 25% | Training loss: 0.6874582952051832
Epoch: 29 | Iteration number: [1150/4518] 25% | Training loss: 0.687454768522926
Epoch: 29 | Iteration number: [1160/4518] 25% | Training loss: 0.6874473771658437
Epoch: 29 | Iteration number: [1170/4518] 25% | Training loss: 0.6874484239989875
Epoch: 29 | Iteration number: [1180/4518] 26% | Training loss: 0.6874383030806558
Epoch: 29 | Iteration number: [1190/4518] 26% | Training loss: 0.687427349651561
Epoch: 29 | Iteration number: [1200/4518] 26% | Training loss: 0.6874036445220312
Epoch: 29 | Iteration number: [1210/4518] 26% | Training loss: 0.6873949185875822
Epoch: 29 | Iteration number: [1220/4518] 27% | Training loss: 0.6873939170700605
Epoch: 29 | Iteration number: [1230/4518] 27% | Training loss: 0.6873987137786741
Epoch: 29 | Iteration number: [1240/4518] 27% | Training loss: 0.687384998173483
Epoch: 29 | Iteration number: [1250/4518] 27% | Training loss: 0.6873876366615296
Epoch: 29 | Iteration number: [1260/4518] 27% | Training loss: 0.6873894310659833
Epoch: 29 | Iteration number: [1270/4518] 28% | Training loss: 0.6873994796294866
Epoch: 29 | Iteration number: [1280/4518] 28% | Training loss: 0.6873883773107081
Epoch: 29 | Iteration number: [1290/4518] 28% | Training loss: 0.6873786675375562
Epoch: 29 | Iteration number: [1300/4518] 28% | Training loss: 0.6873864039090963
Epoch: 29 | Iteration number: [1310/4518] 28% | Training loss: 0.6873820071911994
Epoch: 29 | Iteration number: [1320/4518] 29% | Training loss: 0.6873877217823808
Epoch: 29 | Iteration number: [1330/4518] 29% | Training loss: 0.6873849396418809
Epoch: 29 | Iteration number: [1340/4518] 29% | Training loss: 0.68737315108527
Epoch: 29 | Iteration number: [1350/4518] 29% | Training loss: 0.6873612529260141
Epoch: 29 | Iteration number: [1360/4518] 30% | Training loss: 0.6873529860202003
Epoch: 29 | Iteration number: [1370/4518] 30% | Training loss: 0.6873500274480694
Epoch: 29 | Iteration number: [1380/4518] 30% | Training loss: 0.6873427902874739
Epoch: 29 | Iteration number: [1390/4518] 30% | Training loss: 0.6873444610791241
Epoch: 29 | Iteration number: [1400/4518] 30% | Training loss: 0.6873400032094547
Epoch: 29 | Iteration number: [1410/4518] 31% | Training loss: 0.6873409494863334
Epoch: 29 | Iteration number: [1420/4518] 31% | Training loss: 0.6873346530215841
Epoch: 29 | Iteration number: [1430/4518] 31% | Training loss: 0.6873325000692915
Epoch: 29 | Iteration number: [1440/4518] 31% | Training loss: 0.6873224919454919
Epoch: 29 | Iteration number: [1450/4518] 32% | Training loss: 0.6873219744912509
Epoch: 29 | Iteration number: [1460/4518] 32% | Training loss: 0.6873175105819963
Epoch: 29 | Iteration number: [1470/4518] 32% | Training loss: 0.6873118243249906
Epoch: 29 | Iteration number: [1480/4518] 32% | Training loss: 0.68730747764175
Epoch: 29 | Iteration number: [1490/4518] 32% | Training loss: 0.6873034425629866
Epoch: 29 | Iteration number: [1500/4518] 33% | Training loss: 0.6873037638266881
Epoch: 29 | Iteration number: [1510/4518] 33% | Training loss: 0.68729927835875
Epoch: 29 | Iteration number: [1520/4518] 33% | Training loss: 0.6872970953583717
Epoch: 29 | Iteration number: [1530/4518] 33% | Training loss: 0.6872930270784041
Epoch: 29 | Iteration number: [1540/4518] 34% | Training loss: 0.6872906465809067
Epoch: 29 | Iteration number: [1550/4518] 34% | Training loss: 0.6872845570118197
Epoch: 29 | Iteration number: [1560/4518] 34% | Training loss: 0.6872874018473503
Epoch: 29 | Iteration number: [1570/4518] 34% | Training loss: 0.6872846538853493
Epoch: 29 | Iteration number: [1580/4518] 34% | Training loss: 0.6872835642174829
Epoch: 29 | Iteration number: [1590/4518] 35% | Training loss: 0.6872814792881972
Epoch: 29 | Iteration number: [1600/4518] 35% | Training loss: 0.6872819834575057
Epoch: 29 | Iteration number: [1610/4518] 35% | Training loss: 0.6872724621932699
Epoch: 29 | Iteration number: [1620/4518] 35% | Training loss: 0.6872645879601255
Epoch: 29 | Iteration number: [1630/4518] 36% | Training loss: 0.6872622664720734
Epoch: 29 | Iteration number: [1640/4518] 36% | Training loss: 0.6872493179469574
Epoch: 29 | Iteration number: [1650/4518] 36% | Training loss: 0.6872456608035348
Epoch: 29 | Iteration number: [1660/4518] 36% | Training loss: 0.6872461946972881
Epoch: 29 | Iteration number: [1670/4518] 36% | Training loss: 0.6872426004466896
Epoch: 29 | Iteration number: [1680/4518] 37% | Training loss: 0.6872327175523554
Epoch: 29 | Iteration number: [1690/4518] 37% | Training loss: 0.6872302312822737
Epoch: 29 | Iteration number: [1700/4518] 37% | Training loss: 0.6872342999191845
Epoch: 29 | Iteration number: [1710/4518] 37% | Training loss: 0.6872321382949227
Epoch: 29 | Iteration number: [1720/4518] 38% | Training loss: 0.6872308691573698
Epoch: 29 | Iteration number: [1730/4518] 38% | Training loss: 0.6872268377356446
Epoch: 29 | Iteration number: [1740/4518] 38% | Training loss: 0.6872202799923118
Epoch: 29 | Iteration number: [1750/4518] 38% | Training loss: 0.6872161678246089
Epoch: 29 | Iteration number: [1760/4518] 38% | Training loss: 0.6872072449123318
Epoch: 29 | Iteration number: [1770/4518] 39% | Training loss: 0.6872036171161522
Epoch: 29 | Iteration number: [1780/4518] 39% | Training loss: 0.6871978150659732
Epoch: 29 | Iteration number: [1790/4518] 39% | Training loss: 0.6871979825989494
Epoch: 29 | Iteration number: [1800/4518] 39% | Training loss: 0.6871840792563226
Epoch: 29 | Iteration number: [1810/4518] 40% | Training loss: 0.6871779478715928
Epoch: 29 | Iteration number: [1820/4518] 40% | Training loss: 0.6871786206305682
Epoch: 29 | Iteration number: [1830/4518] 40% | Training loss: 0.6871776909450364
Epoch: 29 | Iteration number: [1840/4518] 40% | Training loss: 0.687179362255594
Epoch: 29 | Iteration number: [1850/4518] 40% | Training loss: 0.6871890253956253
Epoch: 29 | Iteration number: [1860/4518] 41% | Training loss: 0.687195651505583
Epoch: 29 | Iteration number: [1870/4518] 41% | Training loss: 0.6872013005662092
Epoch: 29 | Iteration number: [1880/4518] 41% | Training loss: 0.6872074184582588
Epoch: 29 | Iteration number: [1890/4518] 41% | Training loss: 0.6872024301183287
Epoch: 29 | Iteration number: [1900/4518] 42% | Training loss: 0.687202163150436
Epoch: 29 | Iteration number: [1910/4518] 42% | Training loss: 0.6872025873648558
Epoch: 29 | Iteration number: [1920/4518] 42% | Training loss: 0.6872067596763373
Epoch: 29 | Iteration number: [1930/4518] 42% | Training loss: 0.6872098517232609
Epoch: 29 | Iteration number: [1940/4518] 42% | Training loss: 0.6872147927271951
Epoch: 29 | Iteration number: [1950/4518] 43% | Training loss: 0.6872151311849937
Epoch: 29 | Iteration number: [1960/4518] 43% | Training loss: 0.6872146034727291
Epoch: 29 | Iteration number: [1970/4518] 43% | Training loss: 0.6872113380032747
Epoch: 29 | Iteration number: [1980/4518] 43% | Training loss: 0.6872032816662933
Epoch: 29 | Iteration number: [1990/4518] 44% | Training loss: 0.6872036813491553
Epoch: 29 | Iteration number: [2000/4518] 44% | Training loss: 0.6872033109962941
Epoch: 29 | Iteration number: [2010/4518] 44% | Training loss: 0.6872041626949216
Epoch: 29 | Iteration number: [2020/4518] 44% | Training loss: 0.6872049655949716
Epoch: 29 | Iteration number: [2030/4518] 44% | Training loss: 0.6872032403358685
Epoch: 29 | Iteration number: [2040/4518] 45% | Training loss: 0.6871937640157401
Epoch: 29 | Iteration number: [2050/4518] 45% | Training loss: 0.6871953164658895
Epoch: 29 | Iteration number: [2060/4518] 45% | Training loss: 0.6871920473367266
Epoch: 29 | Iteration number: [2070/4518] 45% | Training loss: 0.6871906409804948
Epoch: 29 | Iteration number: [2080/4518] 46% | Training loss: 0.6871901593529262
Epoch: 29 | Iteration number: [2090/4518] 46% | Training loss: 0.6871918916987461
Epoch: 29 | Iteration number: [2100/4518] 46% | Training loss: 0.6871922821657999
Epoch: 29 | Iteration number: [2110/4518] 46% | Training loss: 0.687185551176704
Epoch: 29 | Iteration number: [2120/4518] 46% | Training loss: 0.6871822364768891
Epoch: 29 | Iteration number: [2130/4518] 47% | Training loss: 0.6871796159117435
Epoch: 29 | Iteration number: [2140/4518] 47% | Training loss: 0.6871762397133301
Epoch: 29 | Iteration number: [2150/4518] 47% | Training loss: 0.6871766335187957
Epoch: 29 | Iteration number: [2160/4518] 47% | Training loss: 0.6871771219151991
Epoch: 29 | Iteration number: [2170/4518] 48% | Training loss: 0.6871724123229629
Epoch: 29 | Iteration number: [2180/4518] 48% | Training loss: 0.6871661801950647
Epoch: 29 | Iteration number: [2190/4518] 48% | Training loss: 0.6871605697559984
Epoch: 29 | Iteration number: [2200/4518] 48% | Training loss: 0.6871582666581327
Epoch: 29 | Iteration number: [2210/4518] 48% | Training loss: 0.6871631734511432
Epoch: 29 | Iteration number: [2220/4518] 49% | Training loss: 0.68716242009992
Epoch: 29 | Iteration number: [2230/4518] 49% | Training loss: 0.6871652632016237
Epoch: 29 | Iteration number: [2240/4518] 49% | Training loss: 0.6871658289272871
Epoch: 29 | Iteration number: [2250/4518] 49% | Training loss: 0.6871636910703447
Epoch: 29 | Iteration number: [2260/4518] 50% | Training loss: 0.6871619859100443
Epoch: 29 | Iteration number: [2270/4518] 50% | Training loss: 0.6871650731248478
Epoch: 29 | Iteration number: [2280/4518] 50% | Training loss: 0.6871654015884064
Epoch: 29 | Iteration number: [2290/4518] 50% | Training loss: 0.6871658353826364
Epoch: 29 | Iteration number: [2300/4518] 50% | Training loss: 0.687160151289857
Epoch: 29 | Iteration number: [2310/4518] 51% | Training loss: 0.6871627699245106
Epoch: 29 | Iteration number: [2320/4518] 51% | Training loss: 0.6871616897911861
Epoch: 29 | Iteration number: [2330/4518] 51% | Training loss: 0.6871523199163281
Epoch: 29 | Iteration number: [2340/4518] 51% | Training loss: 0.6871471817422117
Epoch: 29 | Iteration number: [2350/4518] 52% | Training loss: 0.6871477532894054
Epoch: 29 | Iteration number: [2360/4518] 52% | Training loss: 0.687143180102615
Epoch: 29 | Iteration number: [2370/4518] 52% | Training loss: 0.6871425726997198
Epoch: 29 | Iteration number: [2380/4518] 52% | Training loss: 0.6871390890173551
Epoch: 29 | Iteration number: [2390/4518] 52% | Training loss: 0.6871383350015186
Epoch: 29 | Iteration number: [2400/4518] 53% | Training loss: 0.6871371272206307
Epoch: 29 | Iteration number: [2410/4518] 53% | Training loss: 0.6871327582731287
Epoch: 29 | Iteration number: [2420/4518] 53% | Training loss: 0.6871312677367659
Epoch: 29 | Iteration number: [2430/4518] 53% | Training loss: 0.6871335964634585
Epoch: 29 | Iteration number: [2440/4518] 54% | Training loss: 0.6871370068583332
Epoch: 29 | Iteration number: [2450/4518] 54% | Training loss: 0.6871374949387141
Epoch: 29 | Iteration number: [2460/4518] 54% | Training loss: 0.6871358419821514
Epoch: 29 | Iteration number: [2470/4518] 54% | Training loss: 0.6871373897380675
Epoch: 29 | Iteration number: [2480/4518] 54% | Training loss: 0.687138243980946
Epoch: 29 | Iteration number: [2490/4518] 55% | Training loss: 0.6871369153141497
Epoch: 29 | Iteration number: [2500/4518] 55% | Training loss: 0.6871347704410553
Epoch: 29 | Iteration number: [2510/4518] 55% | Training loss: 0.6871313585703116
Epoch: 29 | Iteration number: [2520/4518] 55% | Training loss: 0.687134022726899
Epoch: 29 | Iteration number: [2530/4518] 55% | Training loss: 0.6871354773110552
Epoch: 29 | Iteration number: [2540/4518] 56% | Training loss: 0.6871351042601067
Epoch: 29 | Iteration number: [2550/4518] 56% | Training loss: 0.6871356220105115
Epoch: 29 | Iteration number: [2560/4518] 56% | Training loss: 0.6871390768326819
Epoch: 29 | Iteration number: [2570/4518] 56% | Training loss: 0.6871427949068611
Epoch: 29 | Iteration number: [2580/4518] 57% | Training loss: 0.6871462317169175
Epoch: 29 | Iteration number: [2590/4518] 57% | Training loss: 0.6871496761397505
Epoch: 29 | Iteration number: [2600/4518] 57% | Training loss: 0.6871509832143784
Epoch: 29 | Iteration number: [2610/4518] 57% | Training loss: 0.6871502576888293
Epoch: 29 | Iteration number: [2620/4518] 57% | Training loss: 0.6871478396972627
Epoch: 29 | Iteration number: [2630/4518] 58% | Training loss: 0.6871422537606026
Epoch: 29 | Iteration number: [2640/4518] 58% | Training loss: 0.6871440574075236
Epoch: 29 | Iteration number: [2650/4518] 58% | Training loss: 0.6871449189141111
Epoch: 29 | Iteration number: [2660/4518] 58% | Training loss: 0.6871437935452712
Epoch: 29 | Iteration number: [2670/4518] 59% | Training loss: 0.6871397098798431
Epoch: 29 | Iteration number: [2680/4518] 59% | Training loss: 0.6871373558222358
Epoch: 29 | Iteration number: [2690/4518] 59% | Training loss: 0.6871360546815795
Epoch: 29 | Iteration number: [2700/4518] 59% | Training loss: 0.6871379330864659
Epoch: 29 | Iteration number: [2710/4518] 59% | Training loss: 0.6871400663113683
Epoch: 29 | Iteration number: [2720/4518] 60% | Training loss: 0.6871381280176779
Epoch: 29 | Iteration number: [2730/4518] 60% | Training loss: 0.6871413514727638
Epoch: 29 | Iteration number: [2740/4518] 60% | Training loss: 0.6871420979499817
Epoch: 29 | Iteration number: [2750/4518] 60% | Training loss: 0.6871376522887837
Epoch: 29 | Iteration number: [2760/4518] 61% | Training loss: 0.6871374109301014
Epoch: 29 | Iteration number: [2770/4518] 61% | Training loss: 0.6871345228666863
Epoch: 29 | Iteration number: [2780/4518] 61% | Training loss: 0.6871349688914182
Epoch: 29 | Iteration number: [2790/4518] 61% | Training loss: 0.6871366763414021
Epoch: 29 | Iteration number: [2800/4518] 61% | Training loss: 0.6871360213841711
Epoch: 29 | Iteration number: [2810/4518] 62% | Training loss: 0.6871290087912006
Epoch: 29 | Iteration number: [2820/4518] 62% | Training loss: 0.6871283076967754
Epoch: 29 | Iteration number: [2830/4518] 62% | Training loss: 0.6871278100215925
Epoch: 29 | Iteration number: [2840/4518] 62% | Training loss: 0.687125427559228
Epoch: 29 | Iteration number: [2850/4518] 63% | Training loss: 0.6871241567009374
Epoch: 29 | Iteration number: [2860/4518] 63% | Training loss: 0.6871253041954307
Epoch: 29 | Iteration number: [2870/4518] 63% | Training loss: 0.6871212616614764
Epoch: 29 | Iteration number: [2880/4518] 63% | Training loss: 0.6871174096440276
Epoch: 29 | Iteration number: [2890/4518] 63% | Training loss: 0.6871192926766551
Epoch: 29 | Iteration number: [2900/4518] 64% | Training loss: 0.6871210641902069
Epoch: 29 | Iteration number: [2910/4518] 64% | Training loss: 0.6871197858217246
Epoch: 29 | Iteration number: [2920/4518] 64% | Training loss: 0.6871162005279162
Epoch: 29 | Iteration number: [2930/4518] 64% | Training loss: 0.6871174795025444
Epoch: 29 | Iteration number: [2940/4518] 65% | Training loss: 0.687113923118228
Epoch: 29 | Iteration number: [2950/4518] 65% | Training loss: 0.6871188428846456
Epoch: 29 | Iteration number: [2960/4518] 65% | Training loss: 0.6871146073615229
Epoch: 29 | Iteration number: [2970/4518] 65% | Training loss: 0.6871166436158447
Epoch: 29 | Iteration number: [2980/4518] 65% | Training loss: 0.6871166532071645
Epoch: 29 | Iteration number: [2990/4518] 66% | Training loss: 0.6871191986627802
Epoch: 29 | Iteration number: [3000/4518] 66% | Training loss: 0.6871190889279047
Epoch: 29 | Iteration number: [3010/4518] 66% | Training loss: 0.6871195488593903
Epoch: 29 | Iteration number: [3020/4518] 66% | Training loss: 0.6871156852371645
Epoch: 29 | Iteration number: [3030/4518] 67% | Training loss: 0.6871161294849005
Epoch: 29 | Iteration number: [3040/4518] 67% | Training loss: 0.6871150733216813
Epoch: 29 | Iteration number: [3050/4518] 67% | Training loss: 0.6871136514866938
Epoch: 29 | Iteration number: [3060/4518] 67% | Training loss: 0.6871135391051473
Epoch: 29 | Iteration number: [3070/4518] 67% | Training loss: 0.6871107439264801
Epoch: 29 | Iteration number: [3080/4518] 68% | Training loss: 0.6871103674560398
Epoch: 29 | Iteration number: [3090/4518] 68% | Training loss: 0.6871081598368277
Epoch: 29 | Iteration number: [3100/4518] 68% | Training loss: 0.6871059596538543
Epoch: 29 | Iteration number: [3110/4518] 68% | Training loss: 0.6871046939846787
Epoch: 29 | Iteration number: [3120/4518] 69% | Training loss: 0.6870978018603264
Epoch: 29 | Iteration number: [3130/4518] 69% | Training loss: 0.6870981623379948
Epoch: 29 | Iteration number: [3140/4518] 69% | Training loss: 0.6870977506136439
Epoch: 29 | Iteration number: [3150/4518] 69% | Training loss: 0.6870927681430937
Epoch: 29 | Iteration number: [3160/4518] 69% | Training loss: 0.6870905412148826
Epoch: 29 | Iteration number: [3170/4518] 70% | Training loss: 0.6870889604655727
Epoch: 29 | Iteration number: [3180/4518] 70% | Training loss: 0.6870864437436158
Epoch: 29 | Iteration number: [3190/4518] 70% | Training loss: 0.6870842174115973
Epoch: 29 | Iteration number: [3200/4518] 70% | Training loss: 0.6870803075097501
Epoch: 29 | Iteration number: [3210/4518] 71% | Training loss: 0.687079190520854
Epoch: 29 | Iteration number: [3220/4518] 71% | Training loss: 0.6870767563581467
Epoch: 29 | Iteration number: [3230/4518] 71% | Training loss: 0.6870751400665602
Epoch: 29 | Iteration number: [3240/4518] 71% | Training loss: 0.6870766606595781
Epoch: 29 | Iteration number: [3250/4518] 71% | Training loss: 0.6870790660564716
Epoch: 29 | Iteration number: [3260/4518] 72% | Training loss: 0.6870786329354245
Epoch: 29 | Iteration number: [3270/4518] 72% | Training loss: 0.687080927307088
Epoch: 29 | Iteration number: [3280/4518] 72% | Training loss: 0.6870792470872402
Epoch: 29 | Iteration number: [3290/4518] 72% | Training loss: 0.6870771938906615
Epoch: 29 | Iteration number: [3300/4518] 73% | Training loss: 0.6870777250600584
Epoch: 29 | Iteration number: [3310/4518] 73% | Training loss: 0.6870775995477809
Epoch: 29 | Iteration number: [3320/4518] 73% | Training loss: 0.6870720407151314
Epoch: 29 | Iteration number: [3330/4518] 73% | Training loss: 0.6870698295556031
Epoch: 29 | Iteration number: [3340/4518] 73% | Training loss: 0.6870687935702101
Epoch: 29 | Iteration number: [3350/4518] 74% | Training loss: 0.6870683838360345
Epoch: 29 | Iteration number: [3360/4518] 74% | Training loss: 0.6870660500334842
Epoch: 29 | Iteration number: [3370/4518] 74% | Training loss: 0.6870670177285678
Epoch: 29 | Iteration number: [3380/4518] 74% | Training loss: 0.6870701413711853
Epoch: 29 | Iteration number: [3390/4518] 75% | Training loss: 0.6870693330216197
Epoch: 29 | Iteration number: [3400/4518] 75% | Training loss: 0.6870676277665531
Epoch: 29 | Iteration number: [3410/4518] 75% | Training loss: 0.687070637871443
Epoch: 29 | Iteration number: [3420/4518] 75% | Training loss: 0.687066067798793
Epoch: 29 | Iteration number: [3430/4518] 75% | Training loss: 0.6870676849222044
Epoch: 29 | Iteration number: [3440/4518] 76% | Training loss: 0.6870667607111987
Epoch: 29 | Iteration number: [3450/4518] 76% | Training loss: 0.6870637227659641
Epoch: 29 | Iteration number: [3460/4518] 76% | Training loss: 0.6870644342692601
Epoch: 29 | Iteration number: [3470/4518] 76% | Training loss: 0.6870637151109382
Epoch: 29 | Iteration number: [3480/4518] 77% | Training loss: 0.6870641459678781
Epoch: 29 | Iteration number: [3490/4518] 77% | Training loss: 0.6870675204134944
Epoch: 29 | Iteration number: [3500/4518] 77% | Training loss: 0.6870712505068097
Epoch: 29 | Iteration number: [3510/4518] 77% | Training loss: 0.6870675674700669
Epoch: 29 | Iteration number: [3520/4518] 77% | Training loss: 0.6870697751471943
Epoch: 29 | Iteration number: [3530/4518] 78% | Training loss: 0.687072177277746
Epoch: 29 | Iteration number: [3540/4518] 78% | Training loss: 0.6870697233299751
Epoch: 29 | Iteration number: [3550/4518] 78% | Training loss: 0.6870677448326433
Epoch: 29 | Iteration number: [3560/4518] 78% | Training loss: 0.6870662610182602
Epoch: 29 | Iteration number: [3570/4518] 79% | Training loss: 0.6870682124831096
Epoch: 29 | Iteration number: [3580/4518] 79% | Training loss: 0.6870673721729044
Epoch: 29 | Iteration number: [3590/4518] 79% | Training loss: 0.6870664186298349
Epoch: 29 | Iteration number: [3600/4518] 79% | Training loss: 0.6870653962592284
Epoch: 29 | Iteration number: [3610/4518] 79% | Training loss: 0.6870649592367896
Epoch: 29 | Iteration number: [3620/4518] 80% | Training loss: 0.6870651282493581
Epoch: 29 | Iteration number: [3630/4518] 80% | Training loss: 0.6870647879014659
Epoch: 29 | Iteration number: [3640/4518] 80% | Training loss: 0.6870627542445947
Epoch: 29 | Iteration number: [3650/4518] 80% | Training loss: 0.6870623808527646
Epoch: 29 | Iteration number: [3660/4518] 81% | Training loss: 0.6870592700490534
Epoch: 29 | Iteration number: [3670/4518] 81% | Training loss: 0.687058299796133
Epoch: 29 | Iteration number: [3680/4518] 81% | Training loss: 0.6870531192130369
Epoch: 29 | Iteration number: [3690/4518] 81% | Training loss: 0.6870506205371402
Epoch: 29 | Iteration number: [3700/4518] 81% | Training loss: 0.6870482327003736
Epoch: 29 | Iteration number: [3710/4518] 82% | Training loss: 0.6870460097519857
Epoch: 29 | Iteration number: [3720/4518] 82% | Training loss: 0.6870472258938256
Epoch: 29 | Iteration number: [3730/4518] 82% | Training loss: 0.6870508848821829
Epoch: 29 | Iteration number: [3740/4518] 82% | Training loss: 0.6870481806005386
Epoch: 29 | Iteration number: [3750/4518] 83% | Training loss: 0.6870459357738495
Epoch: 29 | Iteration number: [3760/4518] 83% | Training loss: 0.68704675388463
Epoch: 29 | Iteration number: [3770/4518] 83% | Training loss: 0.6870516395221022
Epoch: 29 | Iteration number: [3780/4518] 83% | Training loss: 0.687052117485218
Epoch: 29 | Iteration number: [3790/4518] 83% | Training loss: 0.6870541414358999
Epoch: 29 | Iteration number: [3800/4518] 84% | Training loss: 0.6870561386409558
Epoch: 29 | Iteration number: [3810/4518] 84% | Training loss: 0.6870549497641917
Epoch: 29 | Iteration number: [3820/4518] 84% | Training loss: 0.6870538872105914
Epoch: 29 | Iteration number: [3830/4518] 84% | Training loss: 0.6870534072345604
Epoch: 29 | Iteration number: [3840/4518] 84% | Training loss: 0.6870500995467107
Epoch: 29 | Iteration number: [3850/4518] 85% | Training loss: 0.6870529951677694
Epoch: 29 | Iteration number: [3860/4518] 85% | Training loss: 0.6870521145317838
Epoch: 29 | Iteration number: [3870/4518] 85% | Training loss: 0.6870474775016154
Epoch: 29 | Iteration number: [3880/4518] 85% | Training loss: 0.687049691855293
Epoch: 29 | Iteration number: [3890/4518] 86% | Training loss: 0.6870494322022926
Epoch: 29 | Iteration number: [3900/4518] 86% | Training loss: 0.6870491079642222
Epoch: 29 | Iteration number: [3910/4518] 86% | Training loss: 0.6870510105129398
Epoch: 29 | Iteration number: [3920/4518] 86% | Training loss: 0.6870469084199594
Epoch: 29 | Iteration number: [3930/4518] 86% | Training loss: 0.6870446888393421
Epoch: 29 | Iteration number: [3940/4518] 87% | Training loss: 0.687050650809622
Epoch: 29 | Iteration number: [3950/4518] 87% | Training loss: 0.6870519798315025
Epoch: 29 | Iteration number: [3960/4518] 87% | Training loss: 0.687050854437279
Epoch: 29 | Iteration number: [3970/4518] 87% | Training loss: 0.6870499523070357
Epoch: 29 | Iteration number: [3980/4518] 88% | Training loss: 0.6870499878223217
Epoch: 29 | Iteration number: [3990/4518] 88% | Training loss: 0.6870516256580974
Epoch: 29 | Iteration number: [4000/4518] 88% | Training loss: 0.6870530977994204
Epoch: 29 | Iteration number: [4010/4518] 88% | Training loss: 0.6870514642122083
Epoch: 29 | Iteration number: [4020/4518] 88% | Training loss: 0.6870509126886206
Epoch: 29 | Iteration number: [4030/4518] 89% | Training loss: 0.687052452726932
Epoch: 29 | Iteration number: [4040/4518] 89% | Training loss: 0.6870511110171234
Epoch: 29 | Iteration number: [4050/4518] 89% | Training loss: 0.6870453721799968
Epoch: 29 | Iteration number: [4060/4518] 89% | Training loss: 0.6870449868475862
Epoch: 29 | Iteration number: [4070/4518] 90% | Training loss: 0.687046108316145
Epoch: 29 | Iteration number: [4080/4518] 90% | Training loss: 0.687048793890897
Epoch: 29 | Iteration number: [4090/4518] 90% | Training loss: 0.6870493718056341
Epoch: 29 | Iteration number: [4100/4518] 90% | Training loss: 0.6870481673246477
Epoch: 29 | Iteration number: [4110/4518] 90% | Training loss: 0.6870505156743265
Epoch: 29 | Iteration number: [4120/4518] 91% | Training loss: 0.6870521542950742
Epoch: 29 | Iteration number: [4130/4518] 91% | Training loss: 0.6870507297302274
Epoch: 29 | Iteration number: [4140/4518] 91% | Training loss: 0.687049187525459
Epoch: 29 | Iteration number: [4150/4518] 91% | Training loss: 0.687050152327641
Epoch: 29 | Iteration number: [4160/4518] 92% | Training loss: 0.6870489460344498
Epoch: 29 | Iteration number: [4170/4518] 92% | Training loss: 0.6870504366836959
Epoch: 29 | Iteration number: [4180/4518] 92% | Training loss: 0.6870492469751094
Epoch: 29 | Iteration number: [4190/4518] 92% | Training loss: 0.6870459808085585
Epoch: 29 | Iteration number: [4200/4518] 92% | Training loss: 0.6870458131744748
Epoch: 29 | Iteration number: [4210/4518] 93% | Training loss: 0.6870478923983359
Epoch: 29 | Iteration number: [4220/4518] 93% | Training loss: 0.6870489173449611
Epoch: 29 | Iteration number: [4230/4518] 93% | Training loss: 0.6870481641580027
Epoch: 29 | Iteration number: [4240/4518] 93% | Training loss: 0.6870464938569744
Epoch: 29 | Iteration number: [4250/4518] 94% | Training loss: 0.6870463134400985
Epoch: 29 | Iteration number: [4260/4518] 94% | Training loss: 0.6870437718053379
Epoch: 29 | Iteration number: [4270/4518] 94% | Training loss: 0.6870436013582439
Epoch: 29 | Iteration number: [4280/4518] 94% | Training loss: 0.6870414489619086
Epoch: 29 | Iteration number: [4290/4518] 94% | Training loss: 0.6870392176932666
Epoch: 29 | Iteration number: [4300/4518] 95% | Training loss: 0.6870385167210601
Epoch: 29 | Iteration number: [4310/4518] 95% | Training loss: 0.6870391181062933
Epoch: 29 | Iteration number: [4320/4518] 95% | Training loss: 0.6870369514243471
Epoch: 29 | Iteration number: [4330/4518] 95% | Training loss: 0.6870378483663255
Epoch: 29 | Iteration number: [4340/4518] 96% | Training loss: 0.6870369700242847
Epoch: 29 | Iteration number: [4350/4518] 96% | Training loss: 0.6870371391855438
Epoch: 29 | Iteration number: [4360/4518] 96% | Training loss: 0.6870366802729598
Epoch: 29 | Iteration number: [4370/4518] 96% | Training loss: 0.6870380002246569
Epoch: 29 | Iteration number: [4380/4518] 96% | Training loss: 0.6870354517137623
Epoch: 29 | Iteration number: [4390/4518] 97% | Training loss: 0.6870340037182958
Epoch: 29 | Iteration number: [4400/4518] 97% | Training loss: 0.6870337101817131
Epoch: 29 | Iteration number: [4410/4518] 97% | Training loss: 0.6870335067616028
Epoch: 29 | Iteration number: [4420/4518] 97% | Training loss: 0.6870305047180858
Epoch: 29 | Iteration number: [4430/4518] 98% | Training loss: 0.687029304299882
Epoch: 29 | Iteration number: [4440/4518] 98% | Training loss: 0.6870311303315936
Epoch: 29 | Iteration number: [4450/4518] 98% | Training loss: 0.6870285381895772
Epoch: 29 | Iteration number: [4460/4518] 98% | Training loss: 0.687025920211467
Epoch: 29 | Iteration number: [4470/4518] 98% | Training loss: 0.6870228971544261
Epoch: 29 | Iteration number: [4480/4518] 99% | Training loss: 0.6870241301001183
Epoch: 29 | Iteration number: [4490/4518] 99% | Training loss: 0.6870215753138995
Epoch: 29 | Iteration number: [4500/4518] 99% | Training loss: 0.6870212526718775
Epoch: 29 | Iteration number: [4510/4518] 99% | Training loss: 0.6870195345180791

 End of epoch: 29 | Train Loss: 0.6868700031529174 | Training Time: 641 

 End of epoch: 29 | Eval Loss: 0.6900733405229996 | Evaluating Time: 17 
Epoch: 30 | Iteration number: [10/4518] 0% | Training loss: 0.7562561273574829
Epoch: 30 | Iteration number: [20/4518] 0% | Training loss: 0.7216446816921234
Epoch: 30 | Iteration number: [30/4518] 0% | Training loss: 0.7099327385425568
Epoch: 30 | Iteration number: [40/4518] 0% | Training loss: 0.7041403755545617
Epoch: 30 | Iteration number: [50/4518] 1% | Training loss: 0.7003289258480072
Epoch: 30 | Iteration number: [60/4518] 1% | Training loss: 0.6978363951047262
Epoch: 30 | Iteration number: [70/4518] 1% | Training loss: 0.6962427454335349
Epoch: 30 | Iteration number: [80/4518] 1% | Training loss: 0.6951653592288494
Epoch: 30 | Iteration number: [90/4518] 1% | Training loss: 0.694215350680881
Epoch: 30 | Iteration number: [100/4518] 2% | Training loss: 0.6934420502185822
Epoch: 30 | Iteration number: [110/4518] 2% | Training loss: 0.6928280684080991
Epoch: 30 | Iteration number: [120/4518] 2% | Training loss: 0.6922891929745674
Epoch: 30 | Iteration number: [130/4518] 2% | Training loss: 0.6918484022984138
Epoch: 30 | Iteration number: [140/4518] 3% | Training loss: 0.6915799592222486
Epoch: 30 | Iteration number: [150/4518] 3% | Training loss: 0.6911924397945404
Epoch: 30 | Iteration number: [160/4518] 3% | Training loss: 0.690809291601181
Epoch: 30 | Iteration number: [170/4518] 3% | Training loss: 0.6905596080948325
Epoch: 30 | Iteration number: [180/4518] 3% | Training loss: 0.6902631613943312
Epoch: 30 | Iteration number: [190/4518] 4% | Training loss: 0.6900207143080862
Epoch: 30 | Iteration number: [200/4518] 4% | Training loss: 0.6898260435461998
Epoch: 30 | Iteration number: [210/4518] 4% | Training loss: 0.6896625635169801
Epoch: 30 | Iteration number: [220/4518] 4% | Training loss: 0.6895776786587455
Epoch: 30 | Iteration number: [230/4518] 5% | Training loss: 0.6894923173862955
Epoch: 30 | Iteration number: [240/4518] 5% | Training loss: 0.689392627030611
Epoch: 30 | Iteration number: [250/4518] 5% | Training loss: 0.6893249609470368
Epoch: 30 | Iteration number: [260/4518] 5% | Training loss: 0.6892731130123139
Epoch: 30 | Iteration number: [270/4518] 5% | Training loss: 0.6892031150835531
Epoch: 30 | Iteration number: [280/4518] 6% | Training loss: 0.6891072158302579
Epoch: 30 | Iteration number: [290/4518] 6% | Training loss: 0.6889986786349066
Epoch: 30 | Iteration number: [300/4518] 6% | Training loss: 0.6889384424686432
Epoch: 30 | Iteration number: [310/4518] 6% | Training loss: 0.6888492368882703
Epoch: 30 | Iteration number: [320/4518] 7% | Training loss: 0.6887899737805128
Epoch: 30 | Iteration number: [330/4518] 7% | Training loss: 0.6887556952057463
Epoch: 30 | Iteration number: [340/4518] 7% | Training loss: 0.6887157706653371
Epoch: 30 | Iteration number: [350/4518] 7% | Training loss: 0.6886684838363103
Epoch: 30 | Iteration number: [360/4518] 7% | Training loss: 0.6886219412088395
Epoch: 30 | Iteration number: [370/4518] 8% | Training loss: 0.688566416018718
Epoch: 30 | Iteration number: [380/4518] 8% | Training loss: 0.6885233428917433
Epoch: 30 | Iteration number: [390/4518] 8% | Training loss: 0.6884970671091324
Epoch: 30 | Iteration number: [400/4518] 8% | Training loss: 0.6884408508241177
Epoch: 30 | Iteration number: [410/4518] 9% | Training loss: 0.6883891246667723
Epoch: 30 | Iteration number: [420/4518] 9% | Training loss: 0.6883756106808072
Epoch: 30 | Iteration number: [430/4518] 9% | Training loss: 0.6883689251056937
Epoch: 30 | Iteration number: [440/4518] 9% | Training loss: 0.6883562384681268
Epoch: 30 | Iteration number: [450/4518] 9% | Training loss: 0.6883384291330973
Epoch: 30 | Iteration number: [460/4518] 10% | Training loss: 0.6883141769015271
Epoch: 30 | Iteration number: [470/4518] 10% | Training loss: 0.6882809272471895
Epoch: 30 | Iteration number: [480/4518] 10% | Training loss: 0.6882333269963662
Epoch: 30 | Iteration number: [490/4518] 10% | Training loss: 0.6882364185488954
Epoch: 30 | Iteration number: [500/4518] 11% | Training loss: 0.6882127045392991
Epoch: 30 | Iteration number: [510/4518] 11% | Training loss: 0.6881843319126204
Epoch: 30 | Iteration number: [520/4518] 11% | Training loss: 0.6881828140753966
Epoch: 30 | Iteration number: [530/4518] 11% | Training loss: 0.6881827344309609
Epoch: 30 | Iteration number: [540/4518] 11% | Training loss: 0.6881643453130015
Epoch: 30 | Iteration number: [550/4518] 12% | Training loss: 0.6881411280415275
Epoch: 30 | Iteration number: [560/4518] 12% | Training loss: 0.6881100220339639
Epoch: 30 | Iteration number: [570/4518] 12% | Training loss: 0.6880737866225995
Epoch: 30 | Iteration number: [580/4518] 12% | Training loss: 0.6880569099352277
Epoch: 30 | Iteration number: [590/4518] 13% | Training loss: 0.6880195637880746
Epoch: 30 | Iteration number: [600/4518] 13% | Training loss: 0.6879813566803932
Epoch: 30 | Iteration number: [610/4518] 13% | Training loss: 0.6879785230902374
Epoch: 30 | Iteration number: [620/4518] 13% | Training loss: 0.6879374867485416
Epoch: 30 | Iteration number: [630/4518] 13% | Training loss: 0.6879072968921964
Epoch: 30 | Iteration number: [640/4518] 14% | Training loss: 0.6879143688827754
Epoch: 30 | Iteration number: [650/4518] 14% | Training loss: 0.6878918492794037
Epoch: 30 | Iteration number: [660/4518] 14% | Training loss: 0.6878731449445089
Epoch: 30 | Iteration number: [670/4518] 14% | Training loss: 0.6878599067232503
Epoch: 30 | Iteration number: [680/4518] 15% | Training loss: 0.6878787129240878
Epoch: 30 | Iteration number: [690/4518] 15% | Training loss: 0.6878652459469394
Epoch: 30 | Iteration number: [700/4518] 15% | Training loss: 0.6878486599240984
Epoch: 30 | Iteration number: [710/4518] 15% | Training loss: 0.6878267185788759
Epoch: 30 | Iteration number: [720/4518] 15% | Training loss: 0.6878107171091769
Epoch: 30 | Iteration number: [730/4518] 16% | Training loss: 0.6878010240319657
Epoch: 30 | Iteration number: [740/4518] 16% | Training loss: 0.6878034495824092
Epoch: 30 | Iteration number: [750/4518] 16% | Training loss: 0.6878041229248046
Epoch: 30 | Iteration number: [760/4518] 16% | Training loss: 0.6878023617361722
Epoch: 30 | Iteration number: [770/4518] 17% | Training loss: 0.6877963481011329
Epoch: 30 | Iteration number: [780/4518] 17% | Training loss: 0.6877894147084309
Epoch: 30 | Iteration number: [790/4518] 17% | Training loss: 0.6877683886244327
Epoch: 30 | Iteration number: [800/4518] 17% | Training loss: 0.6877684728056193
Epoch: 30 | Iteration number: [810/4518] 17% | Training loss: 0.6877544339792228
Epoch: 30 | Iteration number: [820/4518] 18% | Training loss: 0.6877259972618848
Epoch: 30 | Iteration number: [830/4518] 18% | Training loss: 0.687713665344629
Epoch: 30 | Iteration number: [840/4518] 18% | Training loss: 0.6876832705168497
Epoch: 30 | Iteration number: [850/4518] 18% | Training loss: 0.6876636857144973
Epoch: 30 | Iteration number: [860/4518] 19% | Training loss: 0.68765769760276
Epoch: 30 | Iteration number: [870/4518] 19% | Training loss: 0.6876327072066822
Epoch: 30 | Iteration number: [880/4518] 19% | Training loss: 0.6876318024640734
Epoch: 30 | Iteration number: [890/4518] 19% | Training loss: 0.6876259955797303
Epoch: 30 | Iteration number: [900/4518] 19% | Training loss: 0.6876336507002513
Epoch: 30 | Iteration number: [910/4518] 20% | Training loss: 0.6876317253479591
Epoch: 30 | Iteration number: [920/4518] 20% | Training loss: 0.6876339480928753
Epoch: 30 | Iteration number: [930/4518] 20% | Training loss: 0.6876348368583187
Epoch: 30 | Iteration number: [940/4518] 20% | Training loss: 0.6876183048841801
Epoch: 30 | Iteration number: [950/4518] 21% | Training loss: 0.6876104476577357
Epoch: 30 | Iteration number: [960/4518] 21% | Training loss: 0.6875963885957996
Epoch: 30 | Iteration number: [970/4518] 21% | Training loss: 0.687571652464031
Epoch: 30 | Iteration number: [980/4518] 21% | Training loss: 0.6875774949789047
Epoch: 30 | Iteration number: [990/4518] 21% | Training loss: 0.6875682884394521
Epoch: 30 | Iteration number: [1000/4518] 22% | Training loss: 0.6875628898739815
Epoch: 30 | Iteration number: [1010/4518] 22% | Training loss: 0.6875627435079895
Epoch: 30 | Iteration number: [1020/4518] 22% | Training loss: 0.6875503647561166
Epoch: 30 | Iteration number: [1030/4518] 22% | Training loss: 0.6875519148354391
Epoch: 30 | Iteration number: [1040/4518] 23% | Training loss: 0.6875417098402977
Epoch: 30 | Iteration number: [1050/4518] 23% | Training loss: 0.6875284957885742
Epoch: 30 | Iteration number: [1060/4518] 23% | Training loss: 0.6875267773304345
Epoch: 30 | Iteration number: [1070/4518] 23% | Training loss: 0.6875223487894112
Epoch: 30 | Iteration number: [1080/4518] 23% | Training loss: 0.6875279588279901
Epoch: 30 | Iteration number: [1090/4518] 24% | Training loss: 0.6875173893543558
Epoch: 30 | Iteration number: [1100/4518] 24% | Training loss: 0.6875137212601575
Epoch: 30 | Iteration number: [1110/4518] 24% | Training loss: 0.6875087750387622
Epoch: 30 | Iteration number: [1120/4518] 24% | Training loss: 0.6874959524720907
Epoch: 30 | Iteration number: [1130/4518] 25% | Training loss: 0.6874907724625241
Epoch: 30 | Iteration number: [1140/4518] 25% | Training loss: 0.6874815559178068
Epoch: 30 | Iteration number: [1150/4518] 25% | Training loss: 0.687480178086654
Epoch: 30 | Iteration number: [1160/4518] 25% | Training loss: 0.6874682445464463
Epoch: 30 | Iteration number: [1170/4518] 25% | Training loss: 0.6874578926298354
Epoch: 30 | Iteration number: [1180/4518] 26% | Training loss: 0.6874526278447297
Epoch: 30 | Iteration number: [1190/4518] 26% | Training loss: 0.6874484108275726
Epoch: 30 | Iteration number: [1200/4518] 26% | Training loss: 0.6874456874529521
Epoch: 30 | Iteration number: [1210/4518] 26% | Training loss: 0.6874501638176027
Epoch: 30 | Iteration number: [1220/4518] 27% | Training loss: 0.6874387409843382
Epoch: 30 | Iteration number: [1230/4518] 27% | Training loss: 0.6874294450612572
Epoch: 30 | Iteration number: [1240/4518] 27% | Training loss: 0.6874256419558679
Epoch: 30 | Iteration number: [1250/4518] 27% | Training loss: 0.6874243527889252
Epoch: 30 | Iteration number: [1260/4518] 27% | Training loss: 0.6874210814634959
Epoch: 30 | Iteration number: [1270/4518] 28% | Training loss: 0.6874134748000799
Epoch: 30 | Iteration number: [1280/4518] 28% | Training loss: 0.6874026673380286
Epoch: 30 | Iteration number: [1290/4518] 28% | Training loss: 0.6873994310696919
Epoch: 30 | Iteration number: [1300/4518] 28% | Training loss: 0.6873902478126379
Epoch: 30 | Iteration number: [1310/4518] 28% | Training loss: 0.6873946949725843
Epoch: 30 | Iteration number: [1320/4518] 29% | Training loss: 0.6873861340862332
Epoch: 30 | Iteration number: [1330/4518] 29% | Training loss: 0.6873825345720563
Epoch: 30 | Iteration number: [1340/4518] 29% | Training loss: 0.687380802497935
Epoch: 30 | Iteration number: [1350/4518] 29% | Training loss: 0.6873680520499195
Epoch: 30 | Iteration number: [1360/4518] 30% | Training loss: 0.6873688017620759
Epoch: 30 | Iteration number: [1370/4518] 30% | Training loss: 0.687360934793514
Epoch: 30 | Iteration number: [1380/4518] 30% | Training loss: 0.6873604425917501
Epoch: 30 | Iteration number: [1390/4518] 30% | Training loss: 0.6873642638861704
Epoch: 30 | Iteration number: [1400/4518] 30% | Training loss: 0.6873607402188437
Epoch: 30 | Iteration number: [1410/4518] 31% | Training loss: 0.6873611053253742
Epoch: 30 | Iteration number: [1420/4518] 31% | Training loss: 0.6873613109890844
Epoch: 30 | Iteration number: [1430/4518] 31% | Training loss: 0.6873601775069337
Epoch: 30 | Iteration number: [1440/4518] 31% | Training loss: 0.6873576049175527
Epoch: 30 | Iteration number: [1450/4518] 32% | Training loss: 0.6873489241764463
Epoch: 30 | Iteration number: [1460/4518] 32% | Training loss: 0.6873436596295605
Epoch: 30 | Iteration number: [1470/4518] 32% | Training loss: 0.6873491198027215
Epoch: 30 | Iteration number: [1480/4518] 32% | Training loss: 0.687345301017568
Epoch: 30 | Iteration number: [1490/4518] 32% | Training loss: 0.6873371168271007
Epoch: 30 | Iteration number: [1500/4518] 33% | Training loss: 0.6873302272160848
Epoch: 30 | Iteration number: [1510/4518] 33% | Training loss: 0.6873308490443704
Epoch: 30 | Iteration number: [1520/4518] 33% | Training loss: 0.6873276631298818
Epoch: 30 | Iteration number: [1530/4518] 33% | Training loss: 0.6873116761640785
Epoch: 30 | Iteration number: [1540/4518] 34% | Training loss: 0.6873211185653488
Epoch: 30 | Iteration number: [1550/4518] 34% | Training loss: 0.6873238850408985
Epoch: 30 | Iteration number: [1560/4518] 34% | Training loss: 0.6873310751257798
Epoch: 30 | Iteration number: [1570/4518] 34% | Training loss: 0.6873230466417446
Epoch: 30 | Iteration number: [1580/4518] 34% | Training loss: 0.6873203783472882
Epoch: 30 | Iteration number: [1590/4518] 35% | Training loss: 0.6873092065442283
Epoch: 30 | Iteration number: [1600/4518] 35% | Training loss: 0.6872983439639211
Epoch: 30 | Iteration number: [1610/4518] 35% | Training loss: 0.6873020507163883
Epoch: 30 | Iteration number: [1620/4518] 35% | Training loss: 0.6873068324945592
Epoch: 30 | Iteration number: [1630/4518] 36% | Training loss: 0.6873070271468601
Epoch: 30 | Iteration number: [1640/4518] 36% | Training loss: 0.6873041661047354
Epoch: 30 | Iteration number: [1650/4518] 36% | Training loss: 0.6872936464078498
Epoch: 30 | Iteration number: [1660/4518] 36% | Training loss: 0.687288636759103
Epoch: 30 | Iteration number: [1670/4518] 36% | Training loss: 0.6872878451190308
Epoch: 30 | Iteration number: [1680/4518] 37% | Training loss: 0.6872943086638337
Epoch: 30 | Iteration number: [1690/4518] 37% | Training loss: 0.6872949751876515
Epoch: 30 | Iteration number: [1700/4518] 37% | Training loss: 0.6872927807359135
Epoch: 30 | Iteration number: [1710/4518] 37% | Training loss: 0.6872885421702736
Epoch: 30 | Iteration number: [1720/4518] 38% | Training loss: 0.687289617123992
Epoch: 30 | Iteration number: [1730/4518] 38% | Training loss: 0.687282237668947
Epoch: 30 | Iteration number: [1740/4518] 38% | Training loss: 0.6872801719383261
Epoch: 30 | Iteration number: [1750/4518] 38% | Training loss: 0.6872745600087302
Epoch: 30 | Iteration number: [1760/4518] 38% | Training loss: 0.6872714345089413
Epoch: 30 | Iteration number: [1770/4518] 39% | Training loss: 0.6872594726287713
Epoch: 30 | Iteration number: [1780/4518] 39% | Training loss: 0.6872535380419721
Epoch: 30 | Iteration number: [1790/4518] 39% | Training loss: 0.6872513889267458
Epoch: 30 | Iteration number: [1800/4518] 39% | Training loss: 0.6872535945309532
Epoch: 30 | Iteration number: [1810/4518] 40% | Training loss: 0.6872543200932814
Epoch: 30 | Iteration number: [1820/4518] 40% | Training loss: 0.687250771005075
Epoch: 30 | Iteration number: [1830/4518] 40% | Training loss: 0.6872360691346757
Epoch: 30 | Iteration number: [1840/4518] 40% | Training loss: 0.6872279474592727
Epoch: 30 | Iteration number: [1850/4518] 40% | Training loss: 0.6872223302480337
Epoch: 30 | Iteration number: [1860/4518] 41% | Training loss: 0.6872248566919757
Epoch: 30 | Iteration number: [1870/4518] 41% | Training loss: 0.6872236700937709
Epoch: 30 | Iteration number: [1880/4518] 41% | Training loss: 0.6872101276478869
Epoch: 30 | Iteration number: [1890/4518] 41% | Training loss: 0.6872089387878539
Epoch: 30 | Iteration number: [1900/4518] 42% | Training loss: 0.6872097161255385
Epoch: 30 | Iteration number: [1910/4518] 42% | Training loss: 0.6872156324186874
Epoch: 30 | Iteration number: [1920/4518] 42% | Training loss: 0.6872084810708959
Epoch: 30 | Iteration number: [1930/4518] 42% | Training loss: 0.687204605773323
Epoch: 30 | Iteration number: [1940/4518] 42% | Training loss: 0.6872042187403158
Epoch: 30 | Iteration number: [1950/4518] 43% | Training loss: 0.6872001006664374
Epoch: 30 | Iteration number: [1960/4518] 43% | Training loss: 0.6871965904625095
Epoch: 30 | Iteration number: [1970/4518] 43% | Training loss: 0.6871993891478795
Epoch: 30 | Iteration number: [1980/4518] 43% | Training loss: 0.6872036306544987
Epoch: 30 | Iteration number: [1990/4518] 44% | Training loss: 0.6872033052708036
Epoch: 30 | Iteration number: [2000/4518] 44% | Training loss: 0.6872049624025822
Epoch: 30 | Iteration number: [2010/4518] 44% | Training loss: 0.6871989800562313
Epoch: 30 | Iteration number: [2020/4518] 44% | Training loss: 0.6871961560874882
Epoch: 30 | Iteration number: [2030/4518] 44% | Training loss: 0.6871879929685828
Epoch: 30 | Iteration number: [2040/4518] 45% | Training loss: 0.6871769751403846
Epoch: 30 | Iteration number: [2050/4518] 45% | Training loss: 0.6871743630199898
Epoch: 30 | Iteration number: [2060/4518] 45% | Training loss: 0.6871721919589829
Epoch: 30 | Iteration number: [2070/4518] 45% | Training loss: 0.6871673401427154
Epoch: 30 | Iteration number: [2080/4518] 46% | Training loss: 0.6871687529751888
Epoch: 30 | Iteration number: [2090/4518] 46% | Training loss: 0.6871741656766553
Epoch: 30 | Iteration number: [2100/4518] 46% | Training loss: 0.6871732430514835
Epoch: 30 | Iteration number: [2110/4518] 46% | Training loss: 0.687164341753693
Epoch: 30 | Iteration number: [2120/4518] 46% | Training loss: 0.6871606951614596
Epoch: 30 | Iteration number: [2130/4518] 47% | Training loss: 0.6871590260888489
Epoch: 30 | Iteration number: [2140/4518] 47% | Training loss: 0.687161046712198
Epoch: 30 | Iteration number: [2150/4518] 47% | Training loss: 0.6871604478636454
Epoch: 30 | Iteration number: [2160/4518] 47% | Training loss: 0.6871596562089743
Epoch: 30 | Iteration number: [2170/4518] 48% | Training loss: 0.6871563759267605
Epoch: 30 | Iteration number: [2180/4518] 48% | Training loss: 0.6871531832655635
Epoch: 30 | Iteration number: [2190/4518] 48% | Training loss: 0.6871511423152331
Epoch: 30 | Iteration number: [2200/4518] 48% | Training loss: 0.6871471526135098
Epoch: 30 | Iteration number: [2210/4518] 48% | Training loss: 0.6871398873728325
Epoch: 30 | Iteration number: [2220/4518] 49% | Training loss: 0.687137127566982
Epoch: 30 | Iteration number: [2230/4518] 49% | Training loss: 0.6871340309825179
Epoch: 30 | Iteration number: [2240/4518] 49% | Training loss: 0.6871327317718948
Epoch: 30 | Iteration number: [2250/4518] 49% | Training loss: 0.6871339790026347
Epoch: 30 | Iteration number: [2260/4518] 50% | Training loss: 0.6871338045702572
Epoch: 30 | Iteration number: [2270/4518] 50% | Training loss: 0.6871284753478046
Epoch: 30 | Iteration number: [2280/4518] 50% | Training loss: 0.6871294741306389
Epoch: 30 | Iteration number: [2290/4518] 50% | Training loss: 0.6871273492361261
Epoch: 30 | Iteration number: [2300/4518] 50% | Training loss: 0.6871264336420142
Epoch: 30 | Iteration number: [2310/4518] 51% | Training loss: 0.6871167790064048
Epoch: 30 | Iteration number: [2320/4518] 51% | Training loss: 0.6871142645077458
Epoch: 30 | Iteration number: [2330/4518] 51% | Training loss: 0.6871165284527218
Epoch: 30 | Iteration number: [2340/4518] 51% | Training loss: 0.6871167076449108
Epoch: 30 | Iteration number: [2350/4518] 52% | Training loss: 0.6871148586019556
Epoch: 30 | Iteration number: [2360/4518] 52% | Training loss: 0.687112882000915
Epoch: 30 | Iteration number: [2370/4518] 52% | Training loss: 0.6871150296951648
Epoch: 30 | Iteration number: [2380/4518] 52% | Training loss: 0.6871151058864193
Epoch: 30 | Iteration number: [2390/4518] 52% | Training loss: 0.6871163314605857
Epoch: 30 | Iteration number: [2400/4518] 53% | Training loss: 0.6871177819619576
Epoch: 30 | Iteration number: [2410/4518] 53% | Training loss: 0.6871055973021322
Epoch: 30 | Iteration number: [2420/4518] 53% | Training loss: 0.6871055207222947
Epoch: 30 | Iteration number: [2430/4518] 53% | Training loss: 0.6871058880546946
Epoch: 30 | Iteration number: [2440/4518] 54% | Training loss: 0.6871011836606948
Epoch: 30 | Iteration number: [2450/4518] 54% | Training loss: 0.6870973945637139
Epoch: 30 | Iteration number: [2460/4518] 54% | Training loss: 0.6870972384766835
Epoch: 30 | Iteration number: [2470/4518] 54% | Training loss: 0.687097975044598
Epoch: 30 | Iteration number: [2480/4518] 54% | Training loss: 0.6870996455752081
Epoch: 30 | Iteration number: [2490/4518] 55% | Training loss: 0.687102073431015
Epoch: 30 | Iteration number: [2500/4518] 55% | Training loss: 0.6870999930143357
Epoch: 30 | Iteration number: [2510/4518] 55% | Training loss: 0.6871032556689592
Epoch: 30 | Iteration number: [2520/4518] 55% | Training loss: 0.6871014347388631
Epoch: 30 | Iteration number: [2530/4518] 55% | Training loss: 0.6871037553892776
Epoch: 30 | Iteration number: [2540/4518] 56% | Training loss: 0.687105825801534
Epoch: 30 | Iteration number: [2550/4518] 56% | Training loss: 0.6870993050874449
Epoch: 30 | Iteration number: [2560/4518] 56% | Training loss: 0.6870935306884348
Epoch: 30 | Iteration number: [2570/4518] 56% | Training loss: 0.6870946130168113
Epoch: 30 | Iteration number: [2580/4518] 57% | Training loss: 0.6870962078950201
Epoch: 30 | Iteration number: [2590/4518] 57% | Training loss: 0.6870912950011294
Epoch: 30 | Iteration number: [2600/4518] 57% | Training loss: 0.6870852705836296
Epoch: 30 | Iteration number: [2610/4518] 57% | Training loss: 0.6870857795536289
Epoch: 30 | Iteration number: [2620/4518] 57% | Training loss: 0.6870876406440298
Epoch: 30 | Iteration number: [2630/4518] 58% | Training loss: 0.6870852993015101
Epoch: 30 | Iteration number: [2640/4518] 58% | Training loss: 0.687081770756931
Epoch: 30 | Iteration number: [2650/4518] 58% | Training loss: 0.6870823826429979
Epoch: 30 | Iteration number: [2660/4518] 58% | Training loss: 0.6870858489122605
Epoch: 30 | Iteration number: [2670/4518] 59% | Training loss: 0.6870911700002263
Epoch: 30 | Iteration number: [2680/4518] 59% | Training loss: 0.6870881163807058
Epoch: 30 | Iteration number: [2690/4518] 59% | Training loss: 0.6870899599502521
Epoch: 30 | Iteration number: [2700/4518] 59% | Training loss: 0.6870903263489405
Epoch: 30 | Iteration number: [2710/4518] 59% | Training loss: 0.687087993362293
Epoch: 30 | Iteration number: [2720/4518] 60% | Training loss: 0.6870862101369044
Epoch: 30 | Iteration number: [2730/4518] 60% | Training loss: 0.6870830526282062
Epoch: 30 | Iteration number: [2740/4518] 60% | Training loss: 0.6870810893547796
Epoch: 30 | Iteration number: [2750/4518] 60% | Training loss: 0.6870781734856692
Epoch: 30 | Iteration number: [2760/4518] 61% | Training loss: 0.6870763986654903
Epoch: 30 | Iteration number: [2770/4518] 61% | Training loss: 0.6870768420747901
Epoch: 30 | Iteration number: [2780/4518] 61% | Training loss: 0.6870764186270804
Epoch: 30 | Iteration number: [2790/4518] 61% | Training loss: 0.6870759927243743
Epoch: 30 | Iteration number: [2800/4518] 61% | Training loss: 0.6870777139493397
Epoch: 30 | Iteration number: [2810/4518] 62% | Training loss: 0.6870761885125442
Epoch: 30 | Iteration number: [2820/4518] 62% | Training loss: 0.6870782770163624
Epoch: 30 | Iteration number: [2830/4518] 62% | Training loss: 0.6870826484457764
Epoch: 30 | Iteration number: [2840/4518] 62% | Training loss: 0.6870788426466391
Epoch: 30 | Iteration number: [2850/4518] 63% | Training loss: 0.6870817638907516
Epoch: 30 | Iteration number: [2860/4518] 63% | Training loss: 0.6870813855341265
Epoch: 30 | Iteration number: [2870/4518] 63% | Training loss: 0.6870851752650031
Epoch: 30 | Iteration number: [2880/4518] 63% | Training loss: 0.6870852924055524
Epoch: 30 | Iteration number: [2890/4518] 63% | Training loss: 0.6870845313096954
Epoch: 30 | Iteration number: [2900/4518] 64% | Training loss: 0.6870896009330092
Epoch: 30 | Iteration number: [2910/4518] 64% | Training loss: 0.6870912414236167
Epoch: 30 | Iteration number: [2920/4518] 64% | Training loss: 0.6870874328564291
Epoch: 30 | Iteration number: [2930/4518] 64% | Training loss: 0.6870887694505294
Epoch: 30 | Iteration number: [2940/4518] 65% | Training loss: 0.687087463521633
Epoch: 30 | Iteration number: [2950/4518] 65% | Training loss: 0.6870857927152666
Epoch: 30 | Iteration number: [2960/4518] 65% | Training loss: 0.687082111473019
Epoch: 30 | Iteration number: [2970/4518] 65% | Training loss: 0.6870783119490652
Epoch: 30 | Iteration number: [2980/4518] 65% | Training loss: 0.6870790886198914
Epoch: 30 | Iteration number: [2990/4518] 66% | Training loss: 0.6870779736384899
Epoch: 30 | Iteration number: [3000/4518] 66% | Training loss: 0.6870775515039762
Epoch: 30 | Iteration number: [3010/4518] 66% | Training loss: 0.6870795707171937
Epoch: 30 | Iteration number: [3020/4518] 66% | Training loss: 0.6870768991921912
Epoch: 30 | Iteration number: [3030/4518] 67% | Training loss: 0.6870761346108842
Epoch: 30 | Iteration number: [3040/4518] 67% | Training loss: 0.6870714420746816
Epoch: 30 | Iteration number: [3050/4518] 67% | Training loss: 0.6870717305433555
Epoch: 30 | Iteration number: [3060/4518] 67% | Training loss: 0.6870676512032553
Epoch: 30 | Iteration number: [3070/4518] 67% | Training loss: 0.6870683041962428
Epoch: 30 | Iteration number: [3080/4518] 68% | Training loss: 0.6870686718395778
Epoch: 30 | Iteration number: [3090/4518] 68% | Training loss: 0.687065413507443
Epoch: 30 | Iteration number: [3100/4518] 68% | Training loss: 0.6870683452775401
Epoch: 30 | Iteration number: [3110/4518] 68% | Training loss: 0.6870653407366712
Epoch: 30 | Iteration number: [3120/4518] 69% | Training loss: 0.6870603015216498
Epoch: 30 | Iteration number: [3130/4518] 69% | Training loss: 0.6870599595312112
Epoch: 30 | Iteration number: [3140/4518] 69% | Training loss: 0.6870522989019466
Epoch: 30 | Iteration number: [3150/4518] 69% | Training loss: 0.6870506312355162
Epoch: 30 | Iteration number: [3160/4518] 69% | Training loss: 0.687052284426327
Epoch: 30 | Iteration number: [3170/4518] 70% | Training loss: 0.6870525169823825
Epoch: 30 | Iteration number: [3180/4518] 70% | Training loss: 0.6870549795575112
Epoch: 30 | Iteration number: [3190/4518] 70% | Training loss: 0.6870586840523448
Epoch: 30 | Iteration number: [3200/4518] 70% | Training loss: 0.6870610329695046
Epoch: 30 | Iteration number: [3210/4518] 71% | Training loss: 0.687058712760236
Epoch: 30 | Iteration number: [3220/4518] 71% | Training loss: 0.6870599035705839
Epoch: 30 | Iteration number: [3230/4518] 71% | Training loss: 0.6870566362197923
Epoch: 30 | Iteration number: [3240/4518] 71% | Training loss: 0.6870571109983656
Epoch: 30 | Iteration number: [3250/4518] 71% | Training loss: 0.687055483341217
Epoch: 30 | Iteration number: [3260/4518] 72% | Training loss: 0.6870557129383087
Epoch: 30 | Iteration number: [3270/4518] 72% | Training loss: 0.6870577117171857
Epoch: 30 | Iteration number: [3280/4518] 72% | Training loss: 0.6870573346571225
Epoch: 30 | Iteration number: [3290/4518] 72% | Training loss: 0.6870568934726136
Epoch: 30 | Iteration number: [3300/4518] 73% | Training loss: 0.6870583362109733
Epoch: 30 | Iteration number: [3310/4518] 73% | Training loss: 0.6870559970057623
Epoch: 30 | Iteration number: [3320/4518] 73% | Training loss: 0.687057310719806
Epoch: 30 | Iteration number: [3330/4518] 73% | Training loss: 0.6870559858488249
Epoch: 30 | Iteration number: [3340/4518] 73% | Training loss: 0.6870545171335072
Epoch: 30 | Iteration number: [3350/4518] 74% | Training loss: 0.6870544076855503
Epoch: 30 | Iteration number: [3360/4518] 74% | Training loss: 0.6870523969154982
Epoch: 30 | Iteration number: [3370/4518] 74% | Training loss: 0.6870584461207914
Epoch: 30 | Iteration number: [3380/4518] 74% | Training loss: 0.6870580530907275
Epoch: 30 | Iteration number: [3390/4518] 75% | Training loss: 0.6870578531846184
Epoch: 30 | Iteration number: [3400/4518] 75% | Training loss: 0.6870591658704421
Epoch: 30 | Iteration number: [3410/4518] 75% | Training loss: 0.6870603848063002
Epoch: 30 | Iteration number: [3420/4518] 75% | Training loss: 0.6870642923646503
Epoch: 30 | Iteration number: [3430/4518] 75% | Training loss: 0.687064034702479
Epoch: 30 | Iteration number: [3440/4518] 76% | Training loss: 0.6870655699524768
Epoch: 30 | Iteration number: [3450/4518] 76% | Training loss: 0.6870640480172807
Epoch: 30 | Iteration number: [3460/4518] 76% | Training loss: 0.6870619905649582
Epoch: 30 | Iteration number: [3470/4518] 76% | Training loss: 0.687061569309372
Epoch: 30 | Iteration number: [3480/4518] 77% | Training loss: 0.6870608990904928
Epoch: 30 | Iteration number: [3490/4518] 77% | Training loss: 0.6870589148007696
Epoch: 30 | Iteration number: [3500/4518] 77% | Training loss: 0.6870582983493805
Epoch: 30 | Iteration number: [3510/4518] 77% | Training loss: 0.6870600618867793
Epoch: 30 | Iteration number: [3520/4518] 77% | Training loss: 0.6870586323128505
Epoch: 30 | Iteration number: [3530/4518] 78% | Training loss: 0.6870601613190627
Epoch: 30 | Iteration number: [3540/4518] 78% | Training loss: 0.6870610598958818
Epoch: 30 | Iteration number: [3550/4518] 78% | Training loss: 0.6870618373071644
Epoch: 30 | Iteration number: [3560/4518] 78% | Training loss: 0.6870630213551308
Epoch: 30 | Iteration number: [3570/4518] 79% | Training loss: 0.6870594379447755
Epoch: 30 | Iteration number: [3580/4518] 79% | Training loss: 0.6870535534520389
Epoch: 30 | Iteration number: [3590/4518] 79% | Training loss: 0.6870546288310984
Epoch: 30 | Iteration number: [3600/4518] 79% | Training loss: 0.6870503867831496
Epoch: 30 | Iteration number: [3610/4518] 79% | Training loss: 0.6870501696733227
Epoch: 30 | Iteration number: [3620/4518] 80% | Training loss: 0.6870517203162388
Epoch: 30 | Iteration number: [3630/4518] 80% | Training loss: 0.6870490064141508
Epoch: 30 | Iteration number: [3640/4518] 80% | Training loss: 0.68705018054653
Epoch: 30 | Iteration number: [3650/4518] 80% | Training loss: 0.687049598824488
Epoch: 30 | Iteration number: [3660/4518] 81% | Training loss: 0.6870477475429493
Epoch: 30 | Iteration number: [3670/4518] 81% | Training loss: 0.6870472819181489
Epoch: 30 | Iteration number: [3680/4518] 81% | Training loss: 0.6870512796808844
Epoch: 30 | Iteration number: [3690/4518] 81% | Training loss: 0.687052437025034
Epoch: 30 | Iteration number: [3700/4518] 81% | Training loss: 0.6870478110377853
Epoch: 30 | Iteration number: [3710/4518] 82% | Training loss: 0.6870464852396048
Epoch: 30 | Iteration number: [3720/4518] 82% | Training loss: 0.6870459153607328
Epoch: 30 | Iteration number: [3730/4518] 82% | Training loss: 0.6870479660762858
Epoch: 30 | Iteration number: [3740/4518] 82% | Training loss: 0.6870481752138087
Epoch: 30 | Iteration number: [3750/4518] 83% | Training loss: 0.6870493674914042
Epoch: 30 | Iteration number: [3760/4518] 83% | Training loss: 0.6870483032724959
Epoch: 30 | Iteration number: [3770/4518] 83% | Training loss: 0.6870514528188528
Epoch: 30 | Iteration number: [3780/4518] 83% | Training loss: 0.6870500334671565
Epoch: 30 | Iteration number: [3790/4518] 83% | Training loss: 0.687053011055043
Epoch: 30 | Iteration number: [3800/4518] 84% | Training loss: 0.6870535068919784
Epoch: 30 | Iteration number: [3810/4518] 84% | Training loss: 0.6870524644382356
Epoch: 30 | Iteration number: [3820/4518] 84% | Training loss: 0.6870500390442255
Epoch: 30 | Iteration number: [3830/4518] 84% | Training loss: 0.6870511845571254
Epoch: 30 | Iteration number: [3840/4518] 84% | Training loss: 0.6870518058693658
Epoch: 30 | Iteration number: [3850/4518] 85% | Training loss: 0.6870526623725891
Epoch: 30 | Iteration number: [3860/4518] 85% | Training loss: 0.6870499324613285
Epoch: 30 | Iteration number: [3870/4518] 85% | Training loss: 0.6870460813513714
Epoch: 30 | Iteration number: [3880/4518] 85% | Training loss: 0.6870467965135869
Epoch: 30 | Iteration number: [3890/4518] 86% | Training loss: 0.6870440014377045
Epoch: 30 | Iteration number: [3900/4518] 86% | Training loss: 0.6870388885339102
Epoch: 30 | Iteration number: [3910/4518] 86% | Training loss: 0.6870370682243191
Epoch: 30 | Iteration number: [3920/4518] 86% | Training loss: 0.687037509086789
Epoch: 30 | Iteration number: [3930/4518] 86% | Training loss: 0.6870381731720068
Epoch: 30 | Iteration number: [3940/4518] 87% | Training loss: 0.687040392804872
Epoch: 30 | Iteration number: [3950/4518] 87% | Training loss: 0.6870426232452634
Epoch: 30 | Iteration number: [3960/4518] 87% | Training loss: 0.687040625648065
Epoch: 30 | Iteration number: [3970/4518] 87% | Training loss: 0.6870393507126297
Epoch: 30 | Iteration number: [3980/4518] 88% | Training loss: 0.6870381178867877
Epoch: 30 | Iteration number: [3990/4518] 88% | Training loss: 0.6870369153960905
Epoch: 30 | Iteration number: [4000/4518] 88% | Training loss: 0.6870362885445357
Epoch: 30 | Iteration number: [4010/4518] 88% | Training loss: 0.687038243143933
Epoch: 30 | Iteration number: [4020/4518] 88% | Training loss: 0.6870367731176206
Epoch: 30 | Iteration number: [4030/4518] 89% | Training loss: 0.687042368183065
Epoch: 30 | Iteration number: [4040/4518] 89% | Training loss: 0.687041474052585
Epoch: 30 | Iteration number: [4050/4518] 89% | Training loss: 0.6870408756791809
Epoch: 30 | Iteration number: [4060/4518] 89% | Training loss: 0.6870410016311214
Epoch: 30 | Iteration number: [4070/4518] 90% | Training loss: 0.6870424492060406
Epoch: 30 | Iteration number: [4080/4518] 90% | Training loss: 0.6870412103831768
Epoch: 30 | Iteration number: [4090/4518] 90% | Training loss: 0.6870389266964276
Epoch: 30 | Iteration number: [4100/4518] 90% | Training loss: 0.6870435220003128
Epoch: 30 | Iteration number: [4110/4518] 90% | Training loss: 0.6870417538495539
Epoch: 30 | Iteration number: [4120/4518] 91% | Training loss: 0.6870415191771915
Epoch: 30 | Iteration number: [4130/4518] 91% | Training loss: 0.6870424782392766
Epoch: 30 | Iteration number: [4140/4518] 91% | Training loss: 0.6870411585926434
Epoch: 30 | Iteration number: [4150/4518] 91% | Training loss: 0.6870422550856349
Epoch: 30 | Iteration number: [4160/4518] 92% | Training loss: 0.6870418258727743
Epoch: 30 | Iteration number: [4170/4518] 92% | Training loss: 0.6870416658959515
Epoch: 30 | Iteration number: [4180/4518] 92% | Training loss: 0.6870429680820858
Epoch: 30 | Iteration number: [4190/4518] 92% | Training loss: 0.6870440492624315
Epoch: 30 | Iteration number: [4200/4518] 92% | Training loss: 0.687040708504972
Epoch: 30 | Iteration number: [4210/4518] 93% | Training loss: 0.6870432511502943
Epoch: 30 | Iteration number: [4220/4518] 93% | Training loss: 0.6870440219250901
Epoch: 30 | Iteration number: [4230/4518] 93% | Training loss: 0.6870426964393462
Epoch: 30 | Iteration number: [4240/4518] 93% | Training loss: 0.6870432165855507
Epoch: 30 | Iteration number: [4250/4518] 94% | Training loss: 0.6870432227639591
Epoch: 30 | Iteration number: [4260/4518] 94% | Training loss: 0.6870440816375571
Epoch: 30 | Iteration number: [4270/4518] 94% | Training loss: 0.6870434047606288
Epoch: 30 | Iteration number: [4280/4518] 94% | Training loss: 0.6870420080757587
Epoch: 30 | Iteration number: [4290/4518] 94% | Training loss: 0.6870416559539475
Epoch: 30 | Iteration number: [4300/4518] 95% | Training loss: 0.6870417107676351
Epoch: 30 | Iteration number: [4310/4518] 95% | Training loss: 0.6870409912963478
Epoch: 30 | Iteration number: [4320/4518] 95% | Training loss: 0.6870410490919042
Epoch: 30 | Iteration number: [4330/4518] 95% | Training loss: 0.6870401740074158
Epoch: 30 | Iteration number: [4340/4518] 96% | Training loss: 0.6870375379851337
Epoch: 30 | Iteration number: [4350/4518] 96% | Training loss: 0.6870350405676612
Epoch: 30 | Iteration number: [4360/4518] 96% | Training loss: 0.6870343590001448
Epoch: 30 | Iteration number: [4370/4518] 96% | Training loss: 0.6870308358554709
Epoch: 30 | Iteration number: [4380/4518] 96% | Training loss: 0.6870300914462842
Epoch: 30 | Iteration number: [4390/4518] 97% | Training loss: 0.6870297854066166
Epoch: 30 | Iteration number: [4400/4518] 97% | Training loss: 0.6870266981964761
Epoch: 30 | Iteration number: [4410/4518] 97% | Training loss: 0.6870239103867624
Epoch: 30 | Iteration number: [4420/4518] 97% | Training loss: 0.6870242625340077
Epoch: 30 | Iteration number: [4430/4518] 98% | Training loss: 0.6870214453400123
Epoch: 30 | Iteration number: [4440/4518] 98% | Training loss: 0.6870180932788161
Epoch: 30 | Iteration number: [4450/4518] 98% | Training loss: 0.6870186235663596
Epoch: 30 | Iteration number: [4460/4518] 98% | Training loss: 0.6870190820886415
Epoch: 30 | Iteration number: [4470/4518] 98% | Training loss: 0.6870170934754997
Epoch: 30 | Iteration number: [4480/4518] 99% | Training loss: 0.6870161279503788
Epoch: 30 | Iteration number: [4490/4518] 99% | Training loss: 0.6870135255539603
Epoch: 30 | Iteration number: [4500/4518] 99% | Training loss: 0.6870117124981351
Epoch: 30 | Iteration number: [4510/4518] 99% | Training loss: 0.6870133761159597

 End of epoch: 30 | Train Loss: 0.6868635321703037 | Training Time: 640 

 End of epoch: 30 | Eval Loss: 0.6900632807186672 | Evaluating Time: 17 
Epoch: 31 | Iteration number: [10/4518] 0% | Training loss: 0.7560874640941619
Epoch: 31 | Iteration number: [20/4518] 0% | Training loss: 0.7217286258935929
Epoch: 31 | Iteration number: [30/4518] 0% | Training loss: 0.7103674133618673
Epoch: 31 | Iteration number: [40/4518] 0% | Training loss: 0.7046036809682846
Epoch: 31 | Iteration number: [50/4518] 1% | Training loss: 0.7009671235084534
Epoch: 31 | Iteration number: [60/4518] 1% | Training loss: 0.6984858254591624
Epoch: 31 | Iteration number: [70/4518] 1% | Training loss: 0.6969087541103363
Epoch: 31 | Iteration number: [80/4518] 1% | Training loss: 0.695647494494915
Epoch: 31 | Iteration number: [90/4518] 1% | Training loss: 0.6945399092303381
Epoch: 31 | Iteration number: [100/4518] 2% | Training loss: 0.6936688047647476
Epoch: 31 | Iteration number: [110/4518] 2% | Training loss: 0.6930909043008631
Epoch: 31 | Iteration number: [120/4518] 2% | Training loss: 0.692520928879579
Epoch: 31 | Iteration number: [130/4518] 2% | Training loss: 0.6920762057487782
Epoch: 31 | Iteration number: [140/4518] 3% | Training loss: 0.6916186911719185
Epoch: 31 | Iteration number: [150/4518] 3% | Training loss: 0.6912689069906871
Epoch: 31 | Iteration number: [160/4518] 3% | Training loss: 0.6910429894924164
Epoch: 31 | Iteration number: [170/4518] 3% | Training loss: 0.6908818153774037
Epoch: 31 | Iteration number: [180/4518] 3% | Training loss: 0.6906874534156587
Epoch: 31 | Iteration number: [190/4518] 4% | Training loss: 0.6904710098316795
Epoch: 31 | Iteration number: [200/4518] 4% | Training loss: 0.6903562980890274
Epoch: 31 | Iteration number: [210/4518] 4% | Training loss: 0.6902639701252892
Epoch: 31 | Iteration number: [220/4518] 4% | Training loss: 0.6900742522694848
Epoch: 31 | Iteration number: [230/4518] 5% | Training loss: 0.6899370048357093
Epoch: 31 | Iteration number: [240/4518] 5% | Training loss: 0.6898346814016502
Epoch: 31 | Iteration number: [250/4518] 5% | Training loss: 0.6897508363723754
Epoch: 31 | Iteration number: [260/4518] 5% | Training loss: 0.689648194037951
Epoch: 31 | Iteration number: [270/4518] 5% | Training loss: 0.6895738610514888
Epoch: 31 | Iteration number: [280/4518] 6% | Training loss: 0.6894887851817267
Epoch: 31 | Iteration number: [290/4518] 6% | Training loss: 0.6893828091950253
Epoch: 31 | Iteration number: [300/4518] 6% | Training loss: 0.6893417870998383
Epoch: 31 | Iteration number: [310/4518] 6% | Training loss: 0.689228376265495
Epoch: 31 | Iteration number: [320/4518] 7% | Training loss: 0.6891464110463857
Epoch: 31 | Iteration number: [330/4518] 7% | Training loss: 0.6890862154238152
Epoch: 31 | Iteration number: [340/4518] 7% | Training loss: 0.6890368551015854
Epoch: 31 | Iteration number: [350/4518] 7% | Training loss: 0.6889548054763249
Epoch: 31 | Iteration number: [360/4518] 7% | Training loss: 0.6888679809040493
Epoch: 31 | Iteration number: [370/4518] 8% | Training loss: 0.6887611150741577
Epoch: 31 | Iteration number: [380/4518] 8% | Training loss: 0.6887249397604089
Epoch: 31 | Iteration number: [390/4518] 8% | Training loss: 0.6886930182958261
Epoch: 31 | Iteration number: [400/4518] 8% | Training loss: 0.6886375154554844
Epoch: 31 | Iteration number: [410/4518] 9% | Training loss: 0.6885938074530624
Epoch: 31 | Iteration number: [420/4518] 9% | Training loss: 0.6885631944452013
Epoch: 31 | Iteration number: [430/4518] 9% | Training loss: 0.6885146545809369
Epoch: 31 | Iteration number: [440/4518] 9% | Training loss: 0.6884784671393308
Epoch: 31 | Iteration number: [450/4518] 9% | Training loss: 0.6884729331069522
Epoch: 31 | Iteration number: [460/4518] 10% | Training loss: 0.6884176536746647
Epoch: 31 | Iteration number: [470/4518] 10% | Training loss: 0.6884144004355086
Epoch: 31 | Iteration number: [480/4518] 10% | Training loss: 0.6883915485193332
Epoch: 31 | Iteration number: [490/4518] 10% | Training loss: 0.6883624824942375
Epoch: 31 | Iteration number: [500/4518] 11% | Training loss: 0.6883201370239258
Epoch: 31 | Iteration number: [510/4518] 11% | Training loss: 0.6882751692743863
Epoch: 31 | Iteration number: [520/4518] 11% | Training loss: 0.6882525486441758
Epoch: 31 | Iteration number: [530/4518] 11% | Training loss: 0.6882255869091681
Epoch: 31 | Iteration number: [540/4518] 11% | Training loss: 0.6881943263389446
Epoch: 31 | Iteration number: [550/4518] 12% | Training loss: 0.6881844876029275
Epoch: 31 | Iteration number: [560/4518] 12% | Training loss: 0.6881483031170709
Epoch: 31 | Iteration number: [570/4518] 12% | Training loss: 0.6881329754988352
Epoch: 31 | Iteration number: [580/4518] 12% | Training loss: 0.6881192249470743
Epoch: 31 | Iteration number: [590/4518] 13% | Training loss: 0.6880953551348993
Epoch: 31 | Iteration number: [600/4518] 13% | Training loss: 0.6880594953894615
Epoch: 31 | Iteration number: [610/4518] 13% | Training loss: 0.6880468994867607
Epoch: 31 | Iteration number: [620/4518] 13% | Training loss: 0.6880387065872069
Epoch: 31 | Iteration number: [630/4518] 13% | Training loss: 0.6880159179369608
Epoch: 31 | Iteration number: [640/4518] 14% | Training loss: 0.6879882609471679
Epoch: 31 | Iteration number: [650/4518] 14% | Training loss: 0.6879676912381099
Epoch: 31 | Iteration number: [660/4518] 14% | Training loss: 0.6879484928015507
Epoch: 31 | Iteration number: [670/4518] 14% | Training loss: 0.687917307152677
Epoch: 31 | Iteration number: [680/4518] 15% | Training loss: 0.6879198034020031
Epoch: 31 | Iteration number: [690/4518] 15% | Training loss: 0.6879133378250012
Epoch: 31 | Iteration number: [700/4518] 15% | Training loss: 0.6878836071491241
Epoch: 31 | Iteration number: [710/4518] 15% | Training loss: 0.6878737275869073
Epoch: 31 | Iteration number: [720/4518] 15% | Training loss: 0.6878743418388896
Epoch: 31 | Iteration number: [730/4518] 16% | Training loss: 0.687863718075295
Epoch: 31 | Iteration number: [740/4518] 16% | Training loss: 0.687852533926835
Epoch: 31 | Iteration number: [750/4518] 16% | Training loss: 0.6878390584786733
Epoch: 31 | Iteration number: [760/4518] 16% | Training loss: 0.6878276114401064
Epoch: 31 | Iteration number: [770/4518] 17% | Training loss: 0.6878294169128715
Epoch: 31 | Iteration number: [780/4518] 17% | Training loss: 0.687822183355307
Epoch: 31 | Iteration number: [790/4518] 17% | Training loss: 0.6878164332124251
Epoch: 31 | Iteration number: [800/4518] 17% | Training loss: 0.687817243412137
Epoch: 31 | Iteration number: [810/4518] 17% | Training loss: 0.6878219721493898
Epoch: 31 | Iteration number: [820/4518] 18% | Training loss: 0.6878088001797839
Epoch: 31 | Iteration number: [830/4518] 18% | Training loss: 0.6877921882164048
Epoch: 31 | Iteration number: [840/4518] 18% | Training loss: 0.6877797810804276
Epoch: 31 | Iteration number: [850/4518] 18% | Training loss: 0.6877829265594483
Epoch: 31 | Iteration number: [860/4518] 19% | Training loss: 0.6877830540024957
Epoch: 31 | Iteration number: [870/4518] 19% | Training loss: 0.687774273239333
Epoch: 31 | Iteration number: [880/4518] 19% | Training loss: 0.6877758599140428
Epoch: 31 | Iteration number: [890/4518] 19% | Training loss: 0.6877911678860696
Epoch: 31 | Iteration number: [900/4518] 19% | Training loss: 0.687779796520869
Epoch: 31 | Iteration number: [910/4518] 20% | Training loss: 0.6877899332360907
Epoch: 31 | Iteration number: [920/4518] 20% | Training loss: 0.687777688127497
Epoch: 31 | Iteration number: [930/4518] 20% | Training loss: 0.6877663138092205
Epoch: 31 | Iteration number: [940/4518] 20% | Training loss: 0.6877450338703521
Epoch: 31 | Iteration number: [950/4518] 21% | Training loss: 0.6877387898219259
Epoch: 31 | Iteration number: [960/4518] 21% | Training loss: 0.6877425312995911
Epoch: 31 | Iteration number: [970/4518] 21% | Training loss: 0.6877223500271433
Epoch: 31 | Iteration number: [980/4518] 21% | Training loss: 0.6877070139257275
Epoch: 31 | Iteration number: [990/4518] 21% | Training loss: 0.6877085881401794
Epoch: 31 | Iteration number: [1000/4518] 22% | Training loss: 0.6876978108882904
Epoch: 31 | Iteration number: [1010/4518] 22% | Training loss: 0.6876802201908414
Epoch: 31 | Iteration number: [1020/4518] 22% | Training loss: 0.6876823855381385
Epoch: 31 | Iteration number: [1030/4518] 22% | Training loss: 0.687672548676
Epoch: 31 | Iteration number: [1040/4518] 23% | Training loss: 0.6876549388353641
Epoch: 31 | Iteration number: [1050/4518] 23% | Training loss: 0.6876517990657262
Epoch: 31 | Iteration number: [1060/4518] 23% | Training loss: 0.6876414351305872
Epoch: 31 | Iteration number: [1070/4518] 23% | Training loss: 0.6876405075331715
Epoch: 31 | Iteration number: [1080/4518] 23% | Training loss: 0.6876309009061919
Epoch: 31 | Iteration number: [1090/4518] 24% | Training loss: 0.6876190268118447
Epoch: 31 | Iteration number: [1100/4518] 24% | Training loss: 0.6876004323092374
Epoch: 31 | Iteration number: [1110/4518] 24% | Training loss: 0.6876062016766351
Epoch: 31 | Iteration number: [1120/4518] 24% | Training loss: 0.6876005279166358
Epoch: 31 | Iteration number: [1130/4518] 25% | Training loss: 0.6876062530331907
Epoch: 31 | Iteration number: [1140/4518] 25% | Training loss: 0.6876011549380787
Epoch: 31 | Iteration number: [1150/4518] 25% | Training loss: 0.687590086615604
Epoch: 31 | Iteration number: [1160/4518] 25% | Training loss: 0.687575780626001
Epoch: 31 | Iteration number: [1170/4518] 25% | Training loss: 0.6875649575494294
Epoch: 31 | Iteration number: [1180/4518] 26% | Training loss: 0.6875693375781431
Epoch: 31 | Iteration number: [1190/4518] 26% | Training loss: 0.687554594098019
Epoch: 31 | Iteration number: [1200/4518] 26% | Training loss: 0.6875445578495661
Epoch: 31 | Iteration number: [1210/4518] 26% | Training loss: 0.6875470836793096
Epoch: 31 | Iteration number: [1220/4518] 27% | Training loss: 0.6875400403972531
Epoch: 31 | Iteration number: [1230/4518] 27% | Training loss: 0.6875300083218552
Epoch: 31 | Iteration number: [1240/4518] 27% | Training loss: 0.687533831692511
Epoch: 31 | Iteration number: [1250/4518] 27% | Training loss: 0.6875213078498841
Epoch: 31 | Iteration number: [1260/4518] 27% | Training loss: 0.6875195807407772
Epoch: 31 | Iteration number: [1270/4518] 28% | Training loss: 0.6875070381352282
Epoch: 31 | Iteration number: [1280/4518] 28% | Training loss: 0.6874969718512147
Epoch: 31 | Iteration number: [1290/4518] 28% | Training loss: 0.6874949026015378
Epoch: 31 | Iteration number: [1300/4518] 28% | Training loss: 0.6874845024714104
Epoch: 31 | Iteration number: [1310/4518] 28% | Training loss: 0.687475823855582
Epoch: 31 | Iteration number: [1320/4518] 29% | Training loss: 0.687470954746911
Epoch: 31 | Iteration number: [1330/4518] 29% | Training loss: 0.6874695744281425
Epoch: 31 | Iteration number: [1340/4518] 29% | Training loss: 0.6874655695548698
Epoch: 31 | Iteration number: [1350/4518] 29% | Training loss: 0.6874535846268689
Epoch: 31 | Iteration number: [1360/4518] 30% | Training loss: 0.6874488710480577
Epoch: 31 | Iteration number: [1370/4518] 30% | Training loss: 0.6874494573060613
Epoch: 31 | Iteration number: [1380/4518] 30% | Training loss: 0.6874351710513018
Epoch: 31 | Iteration number: [1390/4518] 30% | Training loss: 0.6874311112671447
Epoch: 31 | Iteration number: [1400/4518] 30% | Training loss: 0.6874343946150371
Epoch: 31 | Iteration number: [1410/4518] 31% | Training loss: 0.6874294763338481
Epoch: 31 | Iteration number: [1420/4518] 31% | Training loss: 0.6874290663591573
Epoch: 31 | Iteration number: [1430/4518] 31% | Training loss: 0.6874256986421305
Epoch: 31 | Iteration number: [1440/4518] 31% | Training loss: 0.6874115337100294
Epoch: 31 | Iteration number: [1450/4518] 32% | Training loss: 0.6874010084415304
Epoch: 31 | Iteration number: [1460/4518] 32% | Training loss: 0.6873979222692855
Epoch: 31 | Iteration number: [1470/4518] 32% | Training loss: 0.6873833150279766
Epoch: 31 | Iteration number: [1480/4518] 32% | Training loss: 0.6873825829576802
Epoch: 31 | Iteration number: [1490/4518] 32% | Training loss: 0.6873802144255414
Epoch: 31 | Iteration number: [1500/4518] 33% | Training loss: 0.6873752679427465
Epoch: 31 | Iteration number: [1510/4518] 33% | Training loss: 0.6873690108589778
Epoch: 31 | Iteration number: [1520/4518] 33% | Training loss: 0.6873715943411777
Epoch: 31 | Iteration number: [1530/4518] 33% | Training loss: 0.687368059547898
Epoch: 31 | Iteration number: [1540/4518] 34% | Training loss: 0.6873573080672846
Epoch: 31 | Iteration number: [1550/4518] 34% | Training loss: 0.6873455538288239
Epoch: 31 | Iteration number: [1560/4518] 34% | Training loss: 0.6873442708681792
Epoch: 31 | Iteration number: [1570/4518] 34% | Training loss: 0.6873424594189711
Epoch: 31 | Iteration number: [1580/4518] 34% | Training loss: 0.6873365672706049
Epoch: 31 | Iteration number: [1590/4518] 35% | Training loss: 0.6873380309755697
Epoch: 31 | Iteration number: [1600/4518] 35% | Training loss: 0.6873394909873605
Epoch: 31 | Iteration number: [1610/4518] 35% | Training loss: 0.6873350712083142
Epoch: 31 | Iteration number: [1620/4518] 35% | Training loss: 0.6873239389908167
Epoch: 31 | Iteration number: [1630/4518] 36% | Training loss: 0.6873322274421622
Epoch: 31 | Iteration number: [1640/4518] 36% | Training loss: 0.6873309920473797
Epoch: 31 | Iteration number: [1650/4518] 36% | Training loss: 0.687317047661001
Epoch: 31 | Iteration number: [1660/4518] 36% | Training loss: 0.6873074125812715
Epoch: 31 | Iteration number: [1670/4518] 36% | Training loss: 0.6873020202456834
Epoch: 31 | Iteration number: [1680/4518] 37% | Training loss: 0.6872977215974104
Epoch: 31 | Iteration number: [1690/4518] 37% | Training loss: 0.687295546757399
Epoch: 31 | Iteration number: [1700/4518] 37% | Training loss: 0.6872919267065385
Epoch: 31 | Iteration number: [1710/4518] 37% | Training loss: 0.6872929674491548
Epoch: 31 | Iteration number: [1720/4518] 38% | Training loss: 0.6872905873975088
Epoch: 31 | Iteration number: [1730/4518] 38% | Training loss: 0.6872823955695753
Epoch: 31 | Iteration number: [1740/4518] 38% | Training loss: 0.6872789875529278
Epoch: 31 | Iteration number: [1750/4518] 38% | Training loss: 0.6872785832200732
Epoch: 31 | Iteration number: [1760/4518] 38% | Training loss: 0.6872798560356552
Epoch: 31 | Iteration number: [1770/4518] 39% | Training loss: 0.6872733713880097
Epoch: 31 | Iteration number: [1780/4518] 39% | Training loss: 0.6872765274530046
Epoch: 31 | Iteration number: [1790/4518] 39% | Training loss: 0.6872739921401999
Epoch: 31 | Iteration number: [1800/4518] 39% | Training loss: 0.6872756256328689
Epoch: 31 | Iteration number: [1810/4518] 40% | Training loss: 0.6872784081743567
Epoch: 31 | Iteration number: [1820/4518] 40% | Training loss: 0.6872811191029601
Epoch: 31 | Iteration number: [1830/4518] 40% | Training loss: 0.6872827107789087
Epoch: 31 | Iteration number: [1840/4518] 40% | Training loss: 0.6872866357474223
Epoch: 31 | Iteration number: [1850/4518] 40% | Training loss: 0.6872873668735092
Epoch: 31 | Iteration number: [1860/4518] 41% | Training loss: 0.6872907135114875
Epoch: 31 | Iteration number: [1870/4518] 41% | Training loss: 0.6872871401475713
Epoch: 31 | Iteration number: [1880/4518] 41% | Training loss: 0.6872910808058496
Epoch: 31 | Iteration number: [1890/4518] 41% | Training loss: 0.6872936705432872
Epoch: 31 | Iteration number: [1900/4518] 42% | Training loss: 0.6872926562397104
Epoch: 31 | Iteration number: [1910/4518] 42% | Training loss: 0.6872921322652806
Epoch: 31 | Iteration number: [1920/4518] 42% | Training loss: 0.6872928952177365
Epoch: 31 | Iteration number: [1930/4518] 42% | Training loss: 0.6872915289253768
Epoch: 31 | Iteration number: [1940/4518] 42% | Training loss: 0.6872913242000894
Epoch: 31 | Iteration number: [1950/4518] 43% | Training loss: 0.6872929798639738
Epoch: 31 | Iteration number: [1960/4518] 43% | Training loss: 0.6872985311308686
Epoch: 31 | Iteration number: [1970/4518] 43% | Training loss: 0.6872959757516832
Epoch: 31 | Iteration number: [1980/4518] 43% | Training loss: 0.6872929600453136
Epoch: 31 | Iteration number: [1990/4518] 44% | Training loss: 0.687287895523723
Epoch: 31 | Iteration number: [2000/4518] 44% | Training loss: 0.6872840751707554
Epoch: 31 | Iteration number: [2010/4518] 44% | Training loss: 0.6872837780719966
Epoch: 31 | Iteration number: [2020/4518] 44% | Training loss: 0.6872786227134194
Epoch: 31 | Iteration number: [2030/4518] 44% | Training loss: 0.6872779714650121
Epoch: 31 | Iteration number: [2040/4518] 45% | Training loss: 0.687273278569474
Epoch: 31 | Iteration number: [2050/4518] 45% | Training loss: 0.687268473549587
Epoch: 31 | Iteration number: [2060/4518] 45% | Training loss: 0.687274341704776
Epoch: 31 | Iteration number: [2070/4518] 45% | Training loss: 0.6872736807318701
Epoch: 31 | Iteration number: [2080/4518] 46% | Training loss: 0.6872766114198244
Epoch: 31 | Iteration number: [2090/4518] 46% | Training loss: 0.687271413791693
Epoch: 31 | Iteration number: [2100/4518] 46% | Training loss: 0.68727221483276
Epoch: 31 | Iteration number: [2110/4518] 46% | Training loss: 0.687268378101819
Epoch: 31 | Iteration number: [2120/4518] 46% | Training loss: 0.6872728282269441
Epoch: 31 | Iteration number: [2130/4518] 47% | Training loss: 0.687276609962535
Epoch: 31 | Iteration number: [2140/4518] 47% | Training loss: 0.687278532257704
Epoch: 31 | Iteration number: [2150/4518] 47% | Training loss: 0.6872755709914274
Epoch: 31 | Iteration number: [2160/4518] 47% | Training loss: 0.6872760315736135
Epoch: 31 | Iteration number: [2170/4518] 48% | Training loss: 0.6872686818722755
Epoch: 31 | Iteration number: [2180/4518] 48% | Training loss: 0.6872660609833691
Epoch: 31 | Iteration number: [2190/4518] 48% | Training loss: 0.6872647761754249
Epoch: 31 | Iteration number: [2200/4518] 48% | Training loss: 0.6872629780660976
Epoch: 31 | Iteration number: [2210/4518] 48% | Training loss: 0.6872558660097252
Epoch: 31 | Iteration number: [2220/4518] 49% | Training loss: 0.6872568065787221
Epoch: 31 | Iteration number: [2230/4518] 49% | Training loss: 0.6872555135344176
Epoch: 31 | Iteration number: [2240/4518] 49% | Training loss: 0.6872554431536368
Epoch: 31 | Iteration number: [2250/4518] 49% | Training loss: 0.687251478486591
Epoch: 31 | Iteration number: [2260/4518] 50% | Training loss: 0.6872523939451285
Epoch: 31 | Iteration number: [2270/4518] 50% | Training loss: 0.687248749092287
Epoch: 31 | Iteration number: [2280/4518] 50% | Training loss: 0.6872474233309428
Epoch: 31 | Iteration number: [2290/4518] 50% | Training loss: 0.6872481006201698
Epoch: 31 | Iteration number: [2300/4518] 50% | Training loss: 0.6872465125633322
Epoch: 31 | Iteration number: [2310/4518] 51% | Training loss: 0.6872481944499078
Epoch: 31 | Iteration number: [2320/4518] 51% | Training loss: 0.687243249549948
Epoch: 31 | Iteration number: [2330/4518] 51% | Training loss: 0.6872351525423352
Epoch: 31 | Iteration number: [2340/4518] 51% | Training loss: 0.6872303437982868
Epoch: 31 | Iteration number: [2350/4518] 52% | Training loss: 0.6872285136263421
Epoch: 31 | Iteration number: [2360/4518] 52% | Training loss: 0.6872273345872507
Epoch: 31 | Iteration number: [2370/4518] 52% | Training loss: 0.6872214036903301
Epoch: 31 | Iteration number: [2380/4518] 52% | Training loss: 0.6872164595277369
Epoch: 31 | Iteration number: [2390/4518] 52% | Training loss: 0.6872121920645486
Epoch: 31 | Iteration number: [2400/4518] 53% | Training loss: 0.6872186544537544
Epoch: 31 | Iteration number: [2410/4518] 53% | Training loss: 0.6872145603801205
Epoch: 31 | Iteration number: [2420/4518] 53% | Training loss: 0.6872101037462881
Epoch: 31 | Iteration number: [2430/4518] 53% | Training loss: 0.6872125219170448
Epoch: 31 | Iteration number: [2440/4518] 54% | Training loss: 0.6872110446457003
Epoch: 31 | Iteration number: [2450/4518] 54% | Training loss: 0.6872044507581361
Epoch: 31 | Iteration number: [2460/4518] 54% | Training loss: 0.687203682946965
Epoch: 31 | Iteration number: [2470/4518] 54% | Training loss: 0.6872014848809493
Epoch: 31 | Iteration number: [2480/4518] 54% | Training loss: 0.6872021585222213
Epoch: 31 | Iteration number: [2490/4518] 55% | Training loss: 0.6871996117643563
Epoch: 31 | Iteration number: [2500/4518] 55% | Training loss: 0.6872001395463944
Epoch: 31 | Iteration number: [2510/4518] 55% | Training loss: 0.6871975550376087
Epoch: 31 | Iteration number: [2520/4518] 55% | Training loss: 0.6871939751127409
Epoch: 31 | Iteration number: [2530/4518] 55% | Training loss: 0.6871937827394885
Epoch: 31 | Iteration number: [2540/4518] 56% | Training loss: 0.687193461196629
Epoch: 31 | Iteration number: [2550/4518] 56% | Training loss: 0.6871954178342632
Epoch: 31 | Iteration number: [2560/4518] 56% | Training loss: 0.6871964532881976
Epoch: 31 | Iteration number: [2570/4518] 56% | Training loss: 0.6871973598977471
Epoch: 31 | Iteration number: [2580/4518] 57% | Training loss: 0.6871891044138014
Epoch: 31 | Iteration number: [2590/4518] 57% | Training loss: 0.6871887242471849
Epoch: 31 | Iteration number: [2600/4518] 57% | Training loss: 0.687180554660467
Epoch: 31 | Iteration number: [2610/4518] 57% | Training loss: 0.6871820331304923
Epoch: 31 | Iteration number: [2620/4518] 57% | Training loss: 0.6871803680449041
Epoch: 31 | Iteration number: [2630/4518] 58% | Training loss: 0.6871810439874917
Epoch: 31 | Iteration number: [2640/4518] 58% | Training loss: 0.6871779808040821
Epoch: 31 | Iteration number: [2650/4518] 58% | Training loss: 0.687172577381134
Epoch: 31 | Iteration number: [2660/4518] 58% | Training loss: 0.6871740283598577
Epoch: 31 | Iteration number: [2670/4518] 59% | Training loss: 0.6871742269073087
Epoch: 31 | Iteration number: [2680/4518] 59% | Training loss: 0.6871735869948544
Epoch: 31 | Iteration number: [2690/4518] 59% | Training loss: 0.6871683981781999
Epoch: 31 | Iteration number: [2700/4518] 59% | Training loss: 0.6871720545159445
Epoch: 31 | Iteration number: [2710/4518] 59% | Training loss: 0.6871684126308484
Epoch: 31 | Iteration number: [2720/4518] 60% | Training loss: 0.6871690590811126
Epoch: 31 | Iteration number: [2730/4518] 60% | Training loss: 0.6871697255106636
Epoch: 31 | Iteration number: [2740/4518] 60% | Training loss: 0.6871673818704855
Epoch: 31 | Iteration number: [2750/4518] 60% | Training loss: 0.6871652464866638
Epoch: 31 | Iteration number: [2760/4518] 61% | Training loss: 0.6871638408389644
Epoch: 31 | Iteration number: [2770/4518] 61% | Training loss: 0.6871658205340485
Epoch: 31 | Iteration number: [2780/4518] 61% | Training loss: 0.6871636949211574
Epoch: 31 | Iteration number: [2790/4518] 61% | Training loss: 0.6871608580953331
Epoch: 31 | Iteration number: [2800/4518] 61% | Training loss: 0.6871588281435626
Epoch: 31 | Iteration number: [2810/4518] 62% | Training loss: 0.687153592186042
Epoch: 31 | Iteration number: [2820/4518] 62% | Training loss: 0.6871477387686993
Epoch: 31 | Iteration number: [2830/4518] 62% | Training loss: 0.6871434524707997
Epoch: 31 | Iteration number: [2840/4518] 62% | Training loss: 0.6871367132579776
Epoch: 31 | Iteration number: [2850/4518] 63% | Training loss: 0.6871337627318868
Epoch: 31 | Iteration number: [2860/4518] 63% | Training loss: 0.6871351767461616
Epoch: 31 | Iteration number: [2870/4518] 63% | Training loss: 0.6871378265399135
Epoch: 31 | Iteration number: [2880/4518] 63% | Training loss: 0.6871363001358178
Epoch: 31 | Iteration number: [2890/4518] 63% | Training loss: 0.6871350284472468
Epoch: 31 | Iteration number: [2900/4518] 64% | Training loss: 0.6871349105752748
Epoch: 31 | Iteration number: [2910/4518] 64% | Training loss: 0.6871307483653433
Epoch: 31 | Iteration number: [2920/4518] 64% | Training loss: 0.6871322535896954
Epoch: 31 | Iteration number: [2930/4518] 64% | Training loss: 0.687134172871658
Epoch: 31 | Iteration number: [2940/4518] 65% | Training loss: 0.6871347897312268
Epoch: 31 | Iteration number: [2950/4518] 65% | Training loss: 0.6871377769971297
Epoch: 31 | Iteration number: [2960/4518] 65% | Training loss: 0.6871394207348694
Epoch: 31 | Iteration number: [2970/4518] 65% | Training loss: 0.687140328514857
Epoch: 31 | Iteration number: [2980/4518] 65% | Training loss: 0.6871362805766548
Epoch: 31 | Iteration number: [2990/4518] 66% | Training loss: 0.6871333907280479
Epoch: 31 | Iteration number: [3000/4518] 66% | Training loss: 0.6871351510485013
Epoch: 31 | Iteration number: [3010/4518] 66% | Training loss: 0.6871315052937036
Epoch: 31 | Iteration number: [3020/4518] 66% | Training loss: 0.6871287127796388
Epoch: 31 | Iteration number: [3030/4518] 67% | Training loss: 0.6871282528532614
Epoch: 31 | Iteration number: [3040/4518] 67% | Training loss: 0.687125479449567
Epoch: 31 | Iteration number: [3050/4518] 67% | Training loss: 0.687127674700784
Epoch: 31 | Iteration number: [3060/4518] 67% | Training loss: 0.6871182110574511
Epoch: 31 | Iteration number: [3070/4518] 67% | Training loss: 0.6871147768893537
Epoch: 31 | Iteration number: [3080/4518] 68% | Training loss: 0.6871122074204606
Epoch: 31 | Iteration number: [3090/4518] 68% | Training loss: 0.6871118368261454
Epoch: 31 | Iteration number: [3100/4518] 68% | Training loss: 0.6871118411902458
Epoch: 31 | Iteration number: [3110/4518] 68% | Training loss: 0.6871111015798195
Epoch: 31 | Iteration number: [3120/4518] 69% | Training loss: 0.6871068056959372
Epoch: 31 | Iteration number: [3130/4518] 69% | Training loss: 0.6871076836563147
Epoch: 31 | Iteration number: [3140/4518] 69% | Training loss: 0.6871101929313818
Epoch: 31 | Iteration number: [3150/4518] 69% | Training loss: 0.6871132476367647
Epoch: 31 | Iteration number: [3160/4518] 69% | Training loss: 0.6871157814996152
Epoch: 31 | Iteration number: [3170/4518] 70% | Training loss: 0.6871134625624407
Epoch: 31 | Iteration number: [3180/4518] 70% | Training loss: 0.6871113048034644
Epoch: 31 | Iteration number: [3190/4518] 70% | Training loss: 0.6871102515246054
Epoch: 31 | Iteration number: [3200/4518] 70% | Training loss: 0.687106748856604
Epoch: 31 | Iteration number: [3210/4518] 71% | Training loss: 0.6871048667163492
Epoch: 31 | Iteration number: [3220/4518] 71% | Training loss: 0.6871051839789989
Epoch: 31 | Iteration number: [3230/4518] 71% | Training loss: 0.6871047610284374
Epoch: 31 | Iteration number: [3240/4518] 71% | Training loss: 0.6871042501595285
Epoch: 31 | Iteration number: [3250/4518] 71% | Training loss: 0.6871051819507892
Epoch: 31 | Iteration number: [3260/4518] 72% | Training loss: 0.6871032251353644
Epoch: 31 | Iteration number: [3270/4518] 72% | Training loss: 0.6871047429535367
Epoch: 31 | Iteration number: [3280/4518] 72% | Training loss: 0.6871036784859692
Epoch: 31 | Iteration number: [3290/4518] 72% | Training loss: 0.6871026617234238
Epoch: 31 | Iteration number: [3300/4518] 73% | Training loss: 0.6870968158497955
Epoch: 31 | Iteration number: [3310/4518] 73% | Training loss: 0.6870976852326235
Epoch: 31 | Iteration number: [3320/4518] 73% | Training loss: 0.6870970297649682
Epoch: 31 | Iteration number: [3330/4518] 73% | Training loss: 0.6870961743969101
Epoch: 31 | Iteration number: [3340/4518] 73% | Training loss: 0.6870955872678471
Epoch: 31 | Iteration number: [3350/4518] 74% | Training loss: 0.6870926445633618
Epoch: 31 | Iteration number: [3360/4518] 74% | Training loss: 0.6870933771843002
Epoch: 31 | Iteration number: [3370/4518] 74% | Training loss: 0.6870930765609006
Epoch: 31 | Iteration number: [3380/4518] 74% | Training loss: 0.6870934268779303
Epoch: 31 | Iteration number: [3390/4518] 75% | Training loss: 0.6870892002343428
Epoch: 31 | Iteration number: [3400/4518] 75% | Training loss: 0.6870893560963518
Epoch: 31 | Iteration number: [3410/4518] 75% | Training loss: 0.6870854768235662
Epoch: 31 | Iteration number: [3420/4518] 75% | Training loss: 0.6870834685034222
Epoch: 31 | Iteration number: [3430/4518] 75% | Training loss: 0.6870843579922056
Epoch: 31 | Iteration number: [3440/4518] 76% | Training loss: 0.6870838844672192
Epoch: 31 | Iteration number: [3450/4518] 76% | Training loss: 0.687081651514855
Epoch: 31 | Iteration number: [3460/4518] 76% | Training loss: 0.6870791776676398
Epoch: 31 | Iteration number: [3470/4518] 76% | Training loss: 0.6870812368667778
Epoch: 31 | Iteration number: [3480/4518] 77% | Training loss: 0.6870824479166119
Epoch: 31 | Iteration number: [3490/4518] 77% | Training loss: 0.6870814640235081
Epoch: 31 | Iteration number: [3500/4518] 77% | Training loss: 0.6870806870290211
Epoch: 31 | Iteration number: [3510/4518] 77% | Training loss: 0.6870797073739207
Epoch: 31 | Iteration number: [3520/4518] 77% | Training loss: 0.6870798200876875
Epoch: 31 | Iteration number: [3530/4518] 78% | Training loss: 0.6870780939420965
Epoch: 31 | Iteration number: [3540/4518] 78% | Training loss: 0.6870785607288112
Epoch: 31 | Iteration number: [3550/4518] 78% | Training loss: 0.6870810662524801
Epoch: 31 | Iteration number: [3560/4518] 78% | Training loss: 0.6870829568317767
Epoch: 31 | Iteration number: [3570/4518] 79% | Training loss: 0.6870812008694774
Epoch: 31 | Iteration number: [3580/4518] 79% | Training loss: 0.6870789120483665
Epoch: 31 | Iteration number: [3590/4518] 79% | Training loss: 0.6870801588452958
Epoch: 31 | Iteration number: [3600/4518] 79% | Training loss: 0.6870763704842991
Epoch: 31 | Iteration number: [3610/4518] 79% | Training loss: 0.6870748072614961
Epoch: 31 | Iteration number: [3620/4518] 80% | Training loss: 0.6870768341734923
Epoch: 31 | Iteration number: [3630/4518] 80% | Training loss: 0.6870728772041226
Epoch: 31 | Iteration number: [3640/4518] 80% | Training loss: 0.6870710029543101
Epoch: 31 | Iteration number: [3650/4518] 80% | Training loss: 0.6870723120970269
Epoch: 31 | Iteration number: [3660/4518] 81% | Training loss: 0.6870722209983836
Epoch: 31 | Iteration number: [3670/4518] 81% | Training loss: 0.6870692468306674
Epoch: 31 | Iteration number: [3680/4518] 81% | Training loss: 0.6870680104617192
Epoch: 31 | Iteration number: [3690/4518] 81% | Training loss: 0.6870694599985108
Epoch: 31 | Iteration number: [3700/4518] 81% | Training loss: 0.6870678850927868
Epoch: 31 | Iteration number: [3710/4518] 82% | Training loss: 0.6870662934857238
Epoch: 31 | Iteration number: [3720/4518] 82% | Training loss: 0.6870706712847114
Epoch: 31 | Iteration number: [3730/4518] 82% | Training loss: 0.6870709324170693
Epoch: 31 | Iteration number: [3740/4518] 82% | Training loss: 0.6870702985614379
Epoch: 31 | Iteration number: [3750/4518] 83% | Training loss: 0.6870707044760386
Epoch: 31 | Iteration number: [3760/4518] 83% | Training loss: 0.6870696905128499
Epoch: 31 | Iteration number: [3770/4518] 83% | Training loss: 0.6870673265159921
Epoch: 31 | Iteration number: [3780/4518] 83% | Training loss: 0.6870661317986786
Epoch: 31 | Iteration number: [3790/4518] 83% | Training loss: 0.6870656636585346
Epoch: 31 | Iteration number: [3800/4518] 84% | Training loss: 0.687063524723053
Epoch: 31 | Iteration number: [3810/4518] 84% | Training loss: 0.6870633646572043
Epoch: 31 | Iteration number: [3820/4518] 84% | Training loss: 0.687064902913508
Epoch: 31 | Iteration number: [3830/4518] 84% | Training loss: 0.6870626679444126
Epoch: 31 | Iteration number: [3840/4518] 84% | Training loss: 0.6870649586276462
Epoch: 31 | Iteration number: [3850/4518] 85% | Training loss: 0.6870648256834452
Epoch: 31 | Iteration number: [3860/4518] 85% | Training loss: 0.6870659331892438
Epoch: 31 | Iteration number: [3870/4518] 85% | Training loss: 0.6870627945553732
Epoch: 31 | Iteration number: [3880/4518] 85% | Training loss: 0.6870585130508413
Epoch: 31 | Iteration number: [3890/4518] 86% | Training loss: 0.6870549055328712
Epoch: 31 | Iteration number: [3900/4518] 86% | Training loss: 0.6870571842101904
Epoch: 31 | Iteration number: [3910/4518] 86% | Training loss: 0.6870593570229953
Epoch: 31 | Iteration number: [3920/4518] 86% | Training loss: 0.6870586848076509
Epoch: 31 | Iteration number: [3930/4518] 86% | Training loss: 0.6870587872943199
Epoch: 31 | Iteration number: [3940/4518] 87% | Training loss: 0.6870584623462658
Epoch: 31 | Iteration number: [3950/4518] 87% | Training loss: 0.6870583412315272
Epoch: 31 | Iteration number: [3960/4518] 87% | Training loss: 0.6870541322712946
Epoch: 31 | Iteration number: [3970/4518] 87% | Training loss: 0.6870516955402095
Epoch: 31 | Iteration number: [3980/4518] 88% | Training loss: 0.687049759647355
Epoch: 31 | Iteration number: [3990/4518] 88% | Training loss: 0.6870491490178837
Epoch: 31 | Iteration number: [4000/4518] 88% | Training loss: 0.6870475704520941
Epoch: 31 | Iteration number: [4010/4518] 88% | Training loss: 0.6870467386786777
Epoch: 31 | Iteration number: [4020/4518] 88% | Training loss: 0.6870441004856309
Epoch: 31 | Iteration number: [4030/4518] 89% | Training loss: 0.6870438407727566
Epoch: 31 | Iteration number: [4040/4518] 89% | Training loss: 0.6870411709246069
Epoch: 31 | Iteration number: [4050/4518] 89% | Training loss: 0.687040139157095
Epoch: 31 | Iteration number: [4060/4518] 89% | Training loss: 0.687041111400562
Epoch: 31 | Iteration number: [4070/4518] 90% | Training loss: 0.6870393302721824
Epoch: 31 | Iteration number: [4080/4518] 90% | Training loss: 0.6870368096758338
Epoch: 31 | Iteration number: [4090/4518] 90% | Training loss: 0.6870362108960419
Epoch: 31 | Iteration number: [4100/4518] 90% | Training loss: 0.6870330959558487
Epoch: 31 | Iteration number: [4110/4518] 90% | Training loss: 0.6870351242322992
Epoch: 31 | Iteration number: [4120/4518] 91% | Training loss: 0.6870329735348526
Epoch: 31 | Iteration number: [4130/4518] 91% | Training loss: 0.6870314190664822
Epoch: 31 | Iteration number: [4140/4518] 91% | Training loss: 0.687033734690164
Epoch: 31 | Iteration number: [4150/4518] 91% | Training loss: 0.6870323151709086
Epoch: 31 | Iteration number: [4160/4518] 92% | Training loss: 0.6870345396777758
Epoch: 31 | Iteration number: [4170/4518] 92% | Training loss: 0.6870364591515036
Epoch: 31 | Iteration number: [4180/4518] 92% | Training loss: 0.6870371883137945
Epoch: 31 | Iteration number: [4190/4518] 92% | Training loss: 0.6870380495926076
Epoch: 31 | Iteration number: [4200/4518] 92% | Training loss: 0.6870350040992101
Epoch: 31 | Iteration number: [4210/4518] 93% | Training loss: 0.6870362100720122
Epoch: 31 | Iteration number: [4220/4518] 93% | Training loss: 0.6870368522349127
Epoch: 31 | Iteration number: [4230/4518] 93% | Training loss: 0.6870381490840416
Epoch: 31 | Iteration number: [4240/4518] 93% | Training loss: 0.6870393624986117
Epoch: 31 | Iteration number: [4250/4518] 94% | Training loss: 0.6870410464931936
Epoch: 31 | Iteration number: [4260/4518] 94% | Training loss: 0.687040043870608
Epoch: 31 | Iteration number: [4270/4518] 94% | Training loss: 0.6870371390701178
Epoch: 31 | Iteration number: [4280/4518] 94% | Training loss: 0.6870363536560646
Epoch: 31 | Iteration number: [4290/4518] 94% | Training loss: 0.6870338805905589
Epoch: 31 | Iteration number: [4300/4518] 95% | Training loss: 0.6870319743766341
Epoch: 31 | Iteration number: [4310/4518] 95% | Training loss: 0.6870304032710755
Epoch: 31 | Iteration number: [4320/4518] 95% | Training loss: 0.6870275881279397
Epoch: 31 | Iteration number: [4330/4518] 95% | Training loss: 0.6870260760360172
Epoch: 31 | Iteration number: [4340/4518] 96% | Training loss: 0.6870256107935707
Epoch: 31 | Iteration number: [4350/4518] 96% | Training loss: 0.6870257817328661
Epoch: 31 | Iteration number: [4360/4518] 96% | Training loss: 0.687025689258488
Epoch: 31 | Iteration number: [4370/4518] 96% | Training loss: 0.6870231333122646
Epoch: 31 | Iteration number: [4380/4518] 96% | Training loss: 0.6870216608863987
Epoch: 31 | Iteration number: [4390/4518] 97% | Training loss: 0.6870203283218697
Epoch: 31 | Iteration number: [4400/4518] 97% | Training loss: 0.6870166686177254
Epoch: 31 | Iteration number: [4410/4518] 97% | Training loss: 0.6870155793739284
Epoch: 31 | Iteration number: [4420/4518] 97% | Training loss: 0.6870143161505056
Epoch: 31 | Iteration number: [4430/4518] 98% | Training loss: 0.687013626798281
Epoch: 31 | Iteration number: [4440/4518] 98% | Training loss: 0.6870133991848241
Epoch: 31 | Iteration number: [4450/4518] 98% | Training loss: 0.6870110167680161
Epoch: 31 | Iteration number: [4460/4518] 98% | Training loss: 0.6870102547075716
Epoch: 31 | Iteration number: [4470/4518] 98% | Training loss: 0.687008009980989
Epoch: 31 | Iteration number: [4480/4518] 99% | Training loss: 0.6870057579396026
Epoch: 31 | Iteration number: [4490/4518] 99% | Training loss: 0.6870047135846917
Epoch: 31 | Iteration number: [4500/4518] 99% | Training loss: 0.6870055930482016
Epoch: 31 | Iteration number: [4510/4518] 99% | Training loss: 0.6870078327121861

 End of epoch: 31 | Train Loss: 0.6868547255378638 | Training Time: 641 

 End of epoch: 31 | Eval Loss: 0.6900669287662117 | Evaluating Time: 17 
Epoch: 32 | Iteration number: [10/4518] 0% | Training loss: 0.7573032975196838
Epoch: 32 | Iteration number: [20/4518] 0% | Training loss: 0.7226078331470489
Epoch: 32 | Iteration number: [30/4518] 0% | Training loss: 0.7108629246552786
Epoch: 32 | Iteration number: [40/4518] 0% | Training loss: 0.7048363745212555
Epoch: 32 | Iteration number: [50/4518] 1% | Training loss: 0.7013336288928985
Epoch: 32 | Iteration number: [60/4518] 1% | Training loss: 0.6988966385523478
Epoch: 32 | Iteration number: [70/4518] 1% | Training loss: 0.6970945588179998
Epoch: 32 | Iteration number: [80/4518] 1% | Training loss: 0.695866645872593
Epoch: 32 | Iteration number: [90/4518] 1% | Training loss: 0.6948413868745168
Epoch: 32 | Iteration number: [100/4518] 2% | Training loss: 0.6941031789779664
Epoch: 32 | Iteration number: [110/4518] 2% | Training loss: 0.6933678058060733
Epoch: 32 | Iteration number: [120/4518] 2% | Training loss: 0.6927781159679095
Epoch: 32 | Iteration number: [130/4518] 2% | Training loss: 0.6922785901106321
Epoch: 32 | Iteration number: [140/4518] 3% | Training loss: 0.6918563766138894
Epoch: 32 | Iteration number: [150/4518] 3% | Training loss: 0.6915653304258982
Epoch: 32 | Iteration number: [160/4518] 3% | Training loss: 0.691367457434535
Epoch: 32 | Iteration number: [170/4518] 3% | Training loss: 0.6911095766460195
Epoch: 32 | Iteration number: [180/4518] 3% | Training loss: 0.690960572163264
Epoch: 32 | Iteration number: [190/4518] 4% | Training loss: 0.6906976668458236
Epoch: 32 | Iteration number: [200/4518] 4% | Training loss: 0.6905763602256775
Epoch: 32 | Iteration number: [210/4518] 4% | Training loss: 0.6904491401854016
Epoch: 32 | Iteration number: [220/4518] 4% | Training loss: 0.6901945371519436
Epoch: 32 | Iteration number: [230/4518] 5% | Training loss: 0.6900762866372647
Epoch: 32 | Iteration number: [240/4518] 5% | Training loss: 0.6899232802291712
Epoch: 32 | Iteration number: [250/4518] 5% | Training loss: 0.6897431683540344
Epoch: 32 | Iteration number: [260/4518] 5% | Training loss: 0.6896593070947207
Epoch: 32 | Iteration number: [270/4518] 5% | Training loss: 0.6895853009488847
Epoch: 32 | Iteration number: [280/4518] 6% | Training loss: 0.6894610326204981
Epoch: 32 | Iteration number: [290/4518] 6% | Training loss: 0.6893493177561925
Epoch: 32 | Iteration number: [300/4518] 6% | Training loss: 0.6892827902237574
Epoch: 32 | Iteration number: [310/4518] 6% | Training loss: 0.6891546905040741
Epoch: 32 | Iteration number: [320/4518] 7% | Training loss: 0.6891091421246529
Epoch: 32 | Iteration number: [330/4518] 7% | Training loss: 0.6889977191433762
Epoch: 32 | Iteration number: [340/4518] 7% | Training loss: 0.6889114833929959
Epoch: 32 | Iteration number: [350/4518] 7% | Training loss: 0.6888420331478119
Epoch: 32 | Iteration number: [360/4518] 7% | Training loss: 0.6887675777077675
Epoch: 32 | Iteration number: [370/4518] 8% | Training loss: 0.6887298231189315
Epoch: 32 | Iteration number: [380/4518] 8% | Training loss: 0.6886730551719665
Epoch: 32 | Iteration number: [390/4518] 8% | Training loss: 0.6886553039917579
Epoch: 32 | Iteration number: [400/4518] 8% | Training loss: 0.6886133672297001
Epoch: 32 | Iteration number: [410/4518] 9% | Training loss: 0.6885782520945479
Epoch: 32 | Iteration number: [420/4518] 9% | Training loss: 0.6885130506186258
Epoch: 32 | Iteration number: [430/4518] 9% | Training loss: 0.6884805047234823
Epoch: 32 | Iteration number: [440/4518] 9% | Training loss: 0.6884606648575176
Epoch: 32 | Iteration number: [450/4518] 9% | Training loss: 0.6884507499800788
Epoch: 32 | Iteration number: [460/4518] 10% | Training loss: 0.6884512248246566
Epoch: 32 | Iteration number: [470/4518] 10% | Training loss: 0.6884363109761096
Epoch: 32 | Iteration number: [480/4518] 10% | Training loss: 0.688422808671991
Epoch: 32 | Iteration number: [490/4518] 10% | Training loss: 0.6883805529195435
Epoch: 32 | Iteration number: [500/4518] 11% | Training loss: 0.6883410102128983
Epoch: 32 | Iteration number: [510/4518] 11% | Training loss: 0.6882887971167471
Epoch: 32 | Iteration number: [520/4518] 11% | Training loss: 0.6882663467755684
Epoch: 32 | Iteration number: [530/4518] 11% | Training loss: 0.6882411818459349
Epoch: 32 | Iteration number: [540/4518] 11% | Training loss: 0.688211699547591
Epoch: 32 | Iteration number: [550/4518] 12% | Training loss: 0.6881824291836132
Epoch: 32 | Iteration number: [560/4518] 12% | Training loss: 0.6881665857774871
Epoch: 32 | Iteration number: [570/4518] 12% | Training loss: 0.6881468599302727
Epoch: 32 | Iteration number: [580/4518] 12% | Training loss: 0.6881443344313523
Epoch: 32 | Iteration number: [590/4518] 13% | Training loss: 0.6881243574417244
Epoch: 32 | Iteration number: [600/4518] 13% | Training loss: 0.688108069896698
Epoch: 32 | Iteration number: [610/4518] 13% | Training loss: 0.6880949679945336
Epoch: 32 | Iteration number: [620/4518] 13% | Training loss: 0.6880835911919994
Epoch: 32 | Iteration number: [630/4518] 13% | Training loss: 0.6880554622127897
Epoch: 32 | Iteration number: [640/4518] 14% | Training loss: 0.6880270424298942
Epoch: 32 | Iteration number: [650/4518] 14% | Training loss: 0.6880015485103314
Epoch: 32 | Iteration number: [660/4518] 14% | Training loss: 0.6879844175143676
Epoch: 32 | Iteration number: [670/4518] 14% | Training loss: 0.6879812430089979
Epoch: 32 | Iteration number: [680/4518] 15% | Training loss: 0.6879693574765149
Epoch: 32 | Iteration number: [690/4518] 15% | Training loss: 0.6879373928774958
Epoch: 32 | Iteration number: [700/4518] 15% | Training loss: 0.6879178074428013
Epoch: 32 | Iteration number: [710/4518] 15% | Training loss: 0.6879113072240857
Epoch: 32 | Iteration number: [720/4518] 15% | Training loss: 0.687893527911769
Epoch: 32 | Iteration number: [730/4518] 16% | Training loss: 0.6878849173245365
Epoch: 32 | Iteration number: [740/4518] 16% | Training loss: 0.6878716902152912
Epoch: 32 | Iteration number: [750/4518] 16% | Training loss: 0.6878589321772257
Epoch: 32 | Iteration number: [760/4518] 16% | Training loss: 0.6878275748146208
Epoch: 32 | Iteration number: [770/4518] 17% | Training loss: 0.6878077779497419
Epoch: 32 | Iteration number: [780/4518] 17% | Training loss: 0.6878021439680686
Epoch: 32 | Iteration number: [790/4518] 17% | Training loss: 0.6877953861333147
Epoch: 32 | Iteration number: [800/4518] 17% | Training loss: 0.6877987153083086
Epoch: 32 | Iteration number: [810/4518] 17% | Training loss: 0.6877856512864431
Epoch: 32 | Iteration number: [820/4518] 18% | Training loss: 0.6877793945190384
Epoch: 32 | Iteration number: [830/4518] 18% | Training loss: 0.6877781470137906
Epoch: 32 | Iteration number: [840/4518] 18% | Training loss: 0.6877731069212868
Epoch: 32 | Iteration number: [850/4518] 18% | Training loss: 0.6877670966176426
Epoch: 32 | Iteration number: [860/4518] 19% | Training loss: 0.6877450568038364
Epoch: 32 | Iteration number: [870/4518] 19% | Training loss: 0.6877424477845773
Epoch: 32 | Iteration number: [880/4518] 19% | Training loss: 0.6877355922352184
Epoch: 32 | Iteration number: [890/4518] 19% | Training loss: 0.6877315567450577
Epoch: 32 | Iteration number: [900/4518] 19% | Training loss: 0.6877236953708861
Epoch: 32 | Iteration number: [910/4518] 20% | Training loss: 0.6877222271410973
Epoch: 32 | Iteration number: [920/4518] 20% | Training loss: 0.6877140722197035
Epoch: 32 | Iteration number: [930/4518] 20% | Training loss: 0.6877017029511031
Epoch: 32 | Iteration number: [940/4518] 20% | Training loss: 0.6876855821051496
Epoch: 32 | Iteration number: [950/4518] 21% | Training loss: 0.687674967364261
Epoch: 32 | Iteration number: [960/4518] 21% | Training loss: 0.6876605415095886
Epoch: 32 | Iteration number: [970/4518] 21% | Training loss: 0.6876453639305744
Epoch: 32 | Iteration number: [980/4518] 21% | Training loss: 0.6876409978890906
Epoch: 32 | Iteration number: [990/4518] 21% | Training loss: 0.687636590064174
Epoch: 32 | Iteration number: [1000/4518] 22% | Training loss: 0.687621945142746
Epoch: 32 | Iteration number: [1010/4518] 22% | Training loss: 0.6876231833849803
Epoch: 32 | Iteration number: [1020/4518] 22% | Training loss: 0.6876181780123243
Epoch: 32 | Iteration number: [1030/4518] 22% | Training loss: 0.6876085188203644
Epoch: 32 | Iteration number: [1040/4518] 23% | Training loss: 0.6876062232141311
Epoch: 32 | Iteration number: [1050/4518] 23% | Training loss: 0.6875910076640901
Epoch: 32 | Iteration number: [1060/4518] 23% | Training loss: 0.687583500934097
Epoch: 32 | Iteration number: [1070/4518] 23% | Training loss: 0.6875793989016631
Epoch: 32 | Iteration number: [1080/4518] 23% | Training loss: 0.687570822901196
Epoch: 32 | Iteration number: [1090/4518] 24% | Training loss: 0.6875658631324768
Epoch: 32 | Iteration number: [1100/4518] 24% | Training loss: 0.6875633880766955
Epoch: 32 | Iteration number: [1110/4518] 24% | Training loss: 0.68755640693613
Epoch: 32 | Iteration number: [1120/4518] 24% | Training loss: 0.687552258638399
Epoch: 32 | Iteration number: [1130/4518] 25% | Training loss: 0.6875438196996672
Epoch: 32 | Iteration number: [1140/4518] 25% | Training loss: 0.6875415754422807
Epoch: 32 | Iteration number: [1150/4518] 25% | Training loss: 0.6875311023256053
Epoch: 32 | Iteration number: [1160/4518] 25% | Training loss: 0.6875310111662437
Epoch: 32 | Iteration number: [1170/4518] 25% | Training loss: 0.6875291137613802
Epoch: 32 | Iteration number: [1180/4518] 26% | Training loss: 0.6875238976236117
Epoch: 32 | Iteration number: [1190/4518] 26% | Training loss: 0.687517684547841
Epoch: 32 | Iteration number: [1200/4518] 26% | Training loss: 0.687510682195425
Epoch: 32 | Iteration number: [1210/4518] 26% | Training loss: 0.6874890142235874
Epoch: 32 | Iteration number: [1220/4518] 27% | Training loss: 0.6874798987732559
Epoch: 32 | Iteration number: [1230/4518] 27% | Training loss: 0.6874642229177118
Epoch: 32 | Iteration number: [1240/4518] 27% | Training loss: 0.6874641266080641
Epoch: 32 | Iteration number: [1250/4518] 27% | Training loss: 0.6874556749343872
Epoch: 32 | Iteration number: [1260/4518] 27% | Training loss: 0.6874525283537214
Epoch: 32 | Iteration number: [1270/4518] 28% | Training loss: 0.6874478005518124
Epoch: 32 | Iteration number: [1280/4518] 28% | Training loss: 0.6874492518603802
Epoch: 32 | Iteration number: [1290/4518] 28% | Training loss: 0.6874297664609066
Epoch: 32 | Iteration number: [1300/4518] 28% | Training loss: 0.6874239620795617
Epoch: 32 | Iteration number: [1310/4518] 28% | Training loss: 0.6874266619445714
Epoch: 32 | Iteration number: [1320/4518] 29% | Training loss: 0.6874249651124983
Epoch: 32 | Iteration number: [1330/4518] 29% | Training loss: 0.6874178975596463
Epoch: 32 | Iteration number: [1340/4518] 29% | Training loss: 0.6874095672991738
Epoch: 32 | Iteration number: [1350/4518] 29% | Training loss: 0.687410670739633
Epoch: 32 | Iteration number: [1360/4518] 30% | Training loss: 0.6874028040205731
Epoch: 32 | Iteration number: [1370/4518] 30% | Training loss: 0.6874065927345387
Epoch: 32 | Iteration number: [1380/4518] 30% | Training loss: 0.6873982777630073
Epoch: 32 | Iteration number: [1390/4518] 30% | Training loss: 0.6873876137699154
Epoch: 32 | Iteration number: [1400/4518] 30% | Training loss: 0.6873828692521368
Epoch: 32 | Iteration number: [1410/4518] 31% | Training loss: 0.6873860361728262
Epoch: 32 | Iteration number: [1420/4518] 31% | Training loss: 0.6873822037602814
Epoch: 32 | Iteration number: [1430/4518] 31% | Training loss: 0.6873778424479745
Epoch: 32 | Iteration number: [1440/4518] 31% | Training loss: 0.6873790339463287
Epoch: 32 | Iteration number: [1450/4518] 32% | Training loss: 0.6873791287685262
Epoch: 32 | Iteration number: [1460/4518] 32% | Training loss: 0.6873776524034265
Epoch: 32 | Iteration number: [1470/4518] 32% | Training loss: 0.6873759569359474
Epoch: 32 | Iteration number: [1480/4518] 32% | Training loss: 0.687371500440546
Epoch: 32 | Iteration number: [1490/4518] 32% | Training loss: 0.687368527674835
Epoch: 32 | Iteration number: [1500/4518] 33% | Training loss: 0.6873693426847458
Epoch: 32 | Iteration number: [1510/4518] 33% | Training loss: 0.6873701879915023
Epoch: 32 | Iteration number: [1520/4518] 33% | Training loss: 0.6873742261607396
Epoch: 32 | Iteration number: [1530/4518] 33% | Training loss: 0.6873718933342329
Epoch: 32 | Iteration number: [1540/4518] 34% | Training loss: 0.6873723961316146
Epoch: 32 | Iteration number: [1550/4518] 34% | Training loss: 0.6873676873407056
Epoch: 32 | Iteration number: [1560/4518] 34% | Training loss: 0.6873663648580893
Epoch: 32 | Iteration number: [1570/4518] 34% | Training loss: 0.6873721508843125
Epoch: 32 | Iteration number: [1580/4518] 34% | Training loss: 0.6873713067438029
Epoch: 32 | Iteration number: [1590/4518] 35% | Training loss: 0.6873714421155318
Epoch: 32 | Iteration number: [1600/4518] 35% | Training loss: 0.6873661549016833
Epoch: 32 | Iteration number: [1610/4518] 35% | Training loss: 0.6873685059340103
Epoch: 32 | Iteration number: [1620/4518] 35% | Training loss: 0.6873575641417209
Epoch: 32 | Iteration number: [1630/4518] 36% | Training loss: 0.6873492051121647
Epoch: 32 | Iteration number: [1640/4518] 36% | Training loss: 0.6873448509268645
Epoch: 32 | Iteration number: [1650/4518] 36% | Training loss: 0.6873508713100895
Epoch: 32 | Iteration number: [1660/4518] 36% | Training loss: 0.687351928310222
Epoch: 32 | Iteration number: [1670/4518] 36% | Training loss: 0.6873475230382589
Epoch: 32 | Iteration number: [1680/4518] 37% | Training loss: 0.6873479636652129
Epoch: 32 | Iteration number: [1690/4518] 37% | Training loss: 0.6873518149880968
Epoch: 32 | Iteration number: [1700/4518] 37% | Training loss: 0.6873516807135414
Epoch: 32 | Iteration number: [1710/4518] 37% | Training loss: 0.6873371910282046
Epoch: 32 | Iteration number: [1720/4518] 38% | Training loss: 0.6873414991553439
Epoch: 32 | Iteration number: [1730/4518] 38% | Training loss: 0.6873440038606611
Epoch: 32 | Iteration number: [1740/4518] 38% | Training loss: 0.6873374991033269
Epoch: 32 | Iteration number: [1750/4518] 38% | Training loss: 0.6873384580612183
Epoch: 32 | Iteration number: [1760/4518] 38% | Training loss: 0.6873353666202588
Epoch: 32 | Iteration number: [1770/4518] 39% | Training loss: 0.687326949599099
Epoch: 32 | Iteration number: [1780/4518] 39% | Training loss: 0.6873248434133744
Epoch: 32 | Iteration number: [1790/4518] 39% | Training loss: 0.6873235905636622
Epoch: 32 | Iteration number: [1800/4518] 39% | Training loss: 0.6873138317134645
Epoch: 32 | Iteration number: [1810/4518] 40% | Training loss: 0.687307342277706
Epoch: 32 | Iteration number: [1820/4518] 40% | Training loss: 0.6872981959319376
Epoch: 32 | Iteration number: [1830/4518] 40% | Training loss: 0.6872991107200664
Epoch: 32 | Iteration number: [1840/4518] 40% | Training loss: 0.6872914434127185
Epoch: 32 | Iteration number: [1850/4518] 40% | Training loss: 0.6872900231786676
Epoch: 32 | Iteration number: [1860/4518] 41% | Training loss: 0.6872844297398804
Epoch: 32 | Iteration number: [1870/4518] 41% | Training loss: 0.6872816412525381
Epoch: 32 | Iteration number: [1880/4518] 41% | Training loss: 0.6872839540243149
Epoch: 32 | Iteration number: [1890/4518] 41% | Training loss: 0.6872796424166866
Epoch: 32 | Iteration number: [1900/4518] 42% | Training loss: 0.6872773519315217
Epoch: 32 | Iteration number: [1910/4518] 42% | Training loss: 0.6872731223780447
Epoch: 32 | Iteration number: [1920/4518] 42% | Training loss: 0.6872639424167574
Epoch: 32 | Iteration number: [1930/4518] 42% | Training loss: 0.6872636526359795
Epoch: 32 | Iteration number: [1940/4518] 42% | Training loss: 0.6872629234164032
Epoch: 32 | Iteration number: [1950/4518] 43% | Training loss: 0.6872612633766272
Epoch: 32 | Iteration number: [1960/4518] 43% | Training loss: 0.6872615897533845
Epoch: 32 | Iteration number: [1970/4518] 43% | Training loss: 0.6872533783392253
Epoch: 32 | Iteration number: [1980/4518] 43% | Training loss: 0.687251770887712
Epoch: 32 | Iteration number: [1990/4518] 44% | Training loss: 0.6872487885269088
Epoch: 32 | Iteration number: [2000/4518] 44% | Training loss: 0.6872459105551243
Epoch: 32 | Iteration number: [2010/4518] 44% | Training loss: 0.6872455748159494
Epoch: 32 | Iteration number: [2020/4518] 44% | Training loss: 0.6872390703104511
Epoch: 32 | Iteration number: [2030/4518] 44% | Training loss: 0.6872326599259682
Epoch: 32 | Iteration number: [2040/4518] 45% | Training loss: 0.6872239499699836
Epoch: 32 | Iteration number: [2050/4518] 45% | Training loss: 0.687217501256524
Epoch: 32 | Iteration number: [2060/4518] 45% | Training loss: 0.6872157058958869
Epoch: 32 | Iteration number: [2070/4518] 45% | Training loss: 0.6872130865348134
Epoch: 32 | Iteration number: [2080/4518] 46% | Training loss: 0.6872090601290648
Epoch: 32 | Iteration number: [2090/4518] 46% | Training loss: 0.6872076812828557
Epoch: 32 | Iteration number: [2100/4518] 46% | Training loss: 0.6872158542133513
Epoch: 32 | Iteration number: [2110/4518] 46% | Training loss: 0.6872192176314892
Epoch: 32 | Iteration number: [2120/4518] 46% | Training loss: 0.6872195744570696
Epoch: 32 | Iteration number: [2130/4518] 47% | Training loss: 0.6872193144240849
Epoch: 32 | Iteration number: [2140/4518] 47% | Training loss: 0.6872158824561913
Epoch: 32 | Iteration number: [2150/4518] 47% | Training loss: 0.6872169290864191
Epoch: 32 | Iteration number: [2160/4518] 47% | Training loss: 0.6872135713144585
Epoch: 32 | Iteration number: [2170/4518] 48% | Training loss: 0.6872111073012726
Epoch: 32 | Iteration number: [2180/4518] 48% | Training loss: 0.6872096950034483
Epoch: 32 | Iteration number: [2190/4518] 48% | Training loss: 0.6872081792790051
Epoch: 32 | Iteration number: [2200/4518] 48% | Training loss: 0.6872034158760851
Epoch: 32 | Iteration number: [2210/4518] 48% | Training loss: 0.6871983282166908
Epoch: 32 | Iteration number: [2220/4518] 49% | Training loss: 0.6871949877287891
Epoch: 32 | Iteration number: [2230/4518] 49% | Training loss: 0.6871941799540157
Epoch: 32 | Iteration number: [2240/4518] 49% | Training loss: 0.687194591840463
Epoch: 32 | Iteration number: [2250/4518] 49% | Training loss: 0.6871844528516133
Epoch: 32 | Iteration number: [2260/4518] 50% | Training loss: 0.6871804880621158
Epoch: 32 | Iteration number: [2270/4518] 50% | Training loss: 0.6871811903783404
Epoch: 32 | Iteration number: [2280/4518] 50% | Training loss: 0.6871761495084093
Epoch: 32 | Iteration number: [2290/4518] 50% | Training loss: 0.6871704309788333
Epoch: 32 | Iteration number: [2300/4518] 50% | Training loss: 0.6871710123445677
Epoch: 32 | Iteration number: [2310/4518] 51% | Training loss: 0.6871653244350896
Epoch: 32 | Iteration number: [2320/4518] 51% | Training loss: 0.68716275458192
Epoch: 32 | Iteration number: [2330/4518] 51% | Training loss: 0.6871632867105018
Epoch: 32 | Iteration number: [2340/4518] 51% | Training loss: 0.6871669518132495
Epoch: 32 | Iteration number: [2350/4518] 52% | Training loss: 0.6871603544468575
Epoch: 32 | Iteration number: [2360/4518] 52% | Training loss: 0.687156456203784
Epoch: 32 | Iteration number: [2370/4518] 52% | Training loss: 0.6871558644097565
Epoch: 32 | Iteration number: [2380/4518] 52% | Training loss: 0.6871552100201614
Epoch: 32 | Iteration number: [2390/4518] 52% | Training loss: 0.6871532261122221
Epoch: 32 | Iteration number: [2400/4518] 53% | Training loss: 0.6871542139103015
Epoch: 32 | Iteration number: [2410/4518] 53% | Training loss: 0.6871487089459827
Epoch: 32 | Iteration number: [2420/4518] 53% | Training loss: 0.6871462894372704
Epoch: 32 | Iteration number: [2430/4518] 53% | Training loss: 0.6871448758943581
Epoch: 32 | Iteration number: [2440/4518] 54% | Training loss: 0.6871433719015513
Epoch: 32 | Iteration number: [2450/4518] 54% | Training loss: 0.6871450895435957
Epoch: 32 | Iteration number: [2460/4518] 54% | Training loss: 0.6871453230216251
Epoch: 32 | Iteration number: [2470/4518] 54% | Training loss: 0.6871389220359354
Epoch: 32 | Iteration number: [2480/4518] 54% | Training loss: 0.6871421288819083
Epoch: 32 | Iteration number: [2490/4518] 55% | Training loss: 0.6871457069035036
Epoch: 32 | Iteration number: [2500/4518] 55% | Training loss: 0.6871466300010681
Epoch: 32 | Iteration number: [2510/4518] 55% | Training loss: 0.6871450759737615
Epoch: 32 | Iteration number: [2520/4518] 55% | Training loss: 0.6871485850167653
Epoch: 32 | Iteration number: [2530/4518] 55% | Training loss: 0.6871490638246649
Epoch: 32 | Iteration number: [2540/4518] 56% | Training loss: 0.6871526199532306
Epoch: 32 | Iteration number: [2550/4518] 56% | Training loss: 0.6871499867299024
Epoch: 32 | Iteration number: [2560/4518] 56% | Training loss: 0.6871470108628273
Epoch: 32 | Iteration number: [2570/4518] 56% | Training loss: 0.687143781653638
Epoch: 32 | Iteration number: [2580/4518] 57% | Training loss: 0.6871417314969293
Epoch: 32 | Iteration number: [2590/4518] 57% | Training loss: 0.6871310022807029
Epoch: 32 | Iteration number: [2600/4518] 57% | Training loss: 0.687127607694039
Epoch: 32 | Iteration number: [2610/4518] 57% | Training loss: 0.6871250386210693
Epoch: 32 | Iteration number: [2620/4518] 57% | Training loss: 0.68712228509306
Epoch: 32 | Iteration number: [2630/4518] 58% | Training loss: 0.6871208004625124
Epoch: 32 | Iteration number: [2640/4518] 58% | Training loss: 0.687122047331297
Epoch: 32 | Iteration number: [2650/4518] 58% | Training loss: 0.6871238859644476
Epoch: 32 | Iteration number: [2660/4518] 58% | Training loss: 0.687125249195816
Epoch: 32 | Iteration number: [2670/4518] 59% | Training loss: 0.6871234656719679
Epoch: 32 | Iteration number: [2680/4518] 59% | Training loss: 0.6871244852667424
Epoch: 32 | Iteration number: [2690/4518] 59% | Training loss: 0.6871244140717176
Epoch: 32 | Iteration number: [2700/4518] 59% | Training loss: 0.6871279145170142
Epoch: 32 | Iteration number: [2710/4518] 59% | Training loss: 0.6871326926889455
Epoch: 32 | Iteration number: [2720/4518] 60% | Training loss: 0.6871257754590582
Epoch: 32 | Iteration number: [2730/4518] 60% | Training loss: 0.6871230068224253
Epoch: 32 | Iteration number: [2740/4518] 60% | Training loss: 0.6871199123833301
Epoch: 32 | Iteration number: [2750/4518] 60% | Training loss: 0.6871132067116824
Epoch: 32 | Iteration number: [2760/4518] 61% | Training loss: 0.6871074278069579
Epoch: 32 | Iteration number: [2770/4518] 61% | Training loss: 0.6871022014196169
Epoch: 32 | Iteration number: [2780/4518] 61% | Training loss: 0.6871015086662855
Epoch: 32 | Iteration number: [2790/4518] 61% | Training loss: 0.6871002199829266
Epoch: 32 | Iteration number: [2800/4518] 61% | Training loss: 0.6870972623356751
Epoch: 32 | Iteration number: [2810/4518] 62% | Training loss: 0.6870923887156083
Epoch: 32 | Iteration number: [2820/4518] 62% | Training loss: 0.6870928976552706
Epoch: 32 | Iteration number: [2830/4518] 62% | Training loss: 0.6870957485778593
Epoch: 32 | Iteration number: [2840/4518] 62% | Training loss: 0.6870957950890904
Epoch: 32 | Iteration number: [2850/4518] 63% | Training loss: 0.6870934279550586
Epoch: 32 | Iteration number: [2860/4518] 63% | Training loss: 0.6870940814901899
Epoch: 32 | Iteration number: [2870/4518] 63% | Training loss: 0.6870941515375928
Epoch: 32 | Iteration number: [2880/4518] 63% | Training loss: 0.6870962885104948
Epoch: 32 | Iteration number: [2890/4518] 63% | Training loss: 0.6870969359231243
Epoch: 32 | Iteration number: [2900/4518] 64% | Training loss: 0.687099249260179
Epoch: 32 | Iteration number: [2910/4518] 64% | Training loss: 0.6870994551894591
Epoch: 32 | Iteration number: [2920/4518] 64% | Training loss: 0.6871010326767621
Epoch: 32 | Iteration number: [2930/4518] 64% | Training loss: 0.6871008230150764
Epoch: 32 | Iteration number: [2940/4518] 65% | Training loss: 0.6871029479163033
Epoch: 32 | Iteration number: [2950/4518] 65% | Training loss: 0.687102462053299
Epoch: 32 | Iteration number: [2960/4518] 65% | Training loss: 0.6870979855592186
Epoch: 32 | Iteration number: [2970/4518] 65% | Training loss: 0.687094948247627
Epoch: 32 | Iteration number: [2980/4518] 65% | Training loss: 0.6870907903717668
Epoch: 32 | Iteration number: [2990/4518] 66% | Training loss: 0.6870922308701736
Epoch: 32 | Iteration number: [3000/4518] 66% | Training loss: 0.6870926937262217
Epoch: 32 | Iteration number: [3010/4518] 66% | Training loss: 0.6870922684867516
Epoch: 32 | Iteration number: [3020/4518] 66% | Training loss: 0.6870892508140463
Epoch: 32 | Iteration number: [3030/4518] 67% | Training loss: 0.6870882325636671
Epoch: 32 | Iteration number: [3040/4518] 67% | Training loss: 0.6870873899444153
Epoch: 32 | Iteration number: [3050/4518] 67% | Training loss: 0.6870864349505941
Epoch: 32 | Iteration number: [3060/4518] 67% | Training loss: 0.6870861980844947
Epoch: 32 | Iteration number: [3070/4518] 67% | Training loss: 0.6870839668019199
Epoch: 32 | Iteration number: [3080/4518] 68% | Training loss: 0.6870837155100588
Epoch: 32 | Iteration number: [3090/4518] 68% | Training loss: 0.6870767190425527
Epoch: 32 | Iteration number: [3100/4518] 68% | Training loss: 0.6870759009738122
Epoch: 32 | Iteration number: [3110/4518] 68% | Training loss: 0.6870759465686761
Epoch: 32 | Iteration number: [3120/4518] 69% | Training loss: 0.6870740274206186
Epoch: 32 | Iteration number: [3130/4518] 69% | Training loss: 0.6870713072272535
Epoch: 32 | Iteration number: [3140/4518] 69% | Training loss: 0.6870724295924424
Epoch: 32 | Iteration number: [3150/4518] 69% | Training loss: 0.6870690584750403
Epoch: 32 | Iteration number: [3160/4518] 69% | Training loss: 0.687071182154402
Epoch: 32 | Iteration number: [3170/4518] 70% | Training loss: 0.6870705620347514
Epoch: 32 | Iteration number: [3180/4518] 70% | Training loss: 0.6870669833144302
Epoch: 32 | Iteration number: [3190/4518] 70% | Training loss: 0.6870671053852033
Epoch: 32 | Iteration number: [3200/4518] 70% | Training loss: 0.6870648830384016
Epoch: 32 | Iteration number: [3210/4518] 71% | Training loss: 0.6870631907030801
Epoch: 32 | Iteration number: [3220/4518] 71% | Training loss: 0.6870577670957732
Epoch: 32 | Iteration number: [3230/4518] 71% | Training loss: 0.6870595466241748
Epoch: 32 | Iteration number: [3240/4518] 71% | Training loss: 0.6870611134870552
Epoch: 32 | Iteration number: [3250/4518] 71% | Training loss: 0.6870630761109866
Epoch: 32 | Iteration number: [3260/4518] 72% | Training loss: 0.6870641495735368
Epoch: 32 | Iteration number: [3270/4518] 72% | Training loss: 0.6870627257619794
Epoch: 32 | Iteration number: [3280/4518] 72% | Training loss: 0.6870632621573238
Epoch: 32 | Iteration number: [3290/4518] 72% | Training loss: 0.6870640928440905
Epoch: 32 | Iteration number: [3300/4518] 73% | Training loss: 0.6870583913723628
Epoch: 32 | Iteration number: [3310/4518] 73% | Training loss: 0.6870567567218827
Epoch: 32 | Iteration number: [3320/4518] 73% | Training loss: 0.68705497387662
Epoch: 32 | Iteration number: [3330/4518] 73% | Training loss: 0.6870537759663464
Epoch: 32 | Iteration number: [3340/4518] 73% | Training loss: 0.6870502878984291
Epoch: 32 | Iteration number: [3350/4518] 74% | Training loss: 0.6870465353175775
Epoch: 32 | Iteration number: [3360/4518] 74% | Training loss: 0.687045556306839
Epoch: 32 | Iteration number: [3370/4518] 74% | Training loss: 0.6870462620647442
Epoch: 32 | Iteration number: [3380/4518] 74% | Training loss: 0.6870488919626326
Epoch: 32 | Iteration number: [3390/4518] 75% | Training loss: 0.6870452479802753
Epoch: 32 | Iteration number: [3400/4518] 75% | Training loss: 0.6870454086976893
Epoch: 32 | Iteration number: [3410/4518] 75% | Training loss: 0.6870398402388844
Epoch: 32 | Iteration number: [3420/4518] 75% | Training loss: 0.6870407517541919
Epoch: 32 | Iteration number: [3430/4518] 75% | Training loss: 0.6870405824816956
Epoch: 32 | Iteration number: [3440/4518] 76% | Training loss: 0.68703971782396
Epoch: 32 | Iteration number: [3450/4518] 76% | Training loss: 0.6870415184636047
Epoch: 32 | Iteration number: [3460/4518] 76% | Training loss: 0.6870417936516635
Epoch: 32 | Iteration number: [3470/4518] 76% | Training loss: 0.6870375474694826
Epoch: 32 | Iteration number: [3480/4518] 77% | Training loss: 0.6870373295127661
Epoch: 32 | Iteration number: [3490/4518] 77% | Training loss: 0.6870369337691277
Epoch: 32 | Iteration number: [3500/4518] 77% | Training loss: 0.6870357244185039
Epoch: 32 | Iteration number: [3510/4518] 77% | Training loss: 0.6870338309524405
Epoch: 32 | Iteration number: [3520/4518] 77% | Training loss: 0.6870342665267262
Epoch: 32 | Iteration number: [3530/4518] 78% | Training loss: 0.6870360945844786
Epoch: 32 | Iteration number: [3540/4518] 78% | Training loss: 0.6870338850102182
Epoch: 32 | Iteration number: [3550/4518] 78% | Training loss: 0.6870368877095235
Epoch: 32 | Iteration number: [3560/4518] 78% | Training loss: 0.6870357049650021
Epoch: 32 | Iteration number: [3570/4518] 79% | Training loss: 0.687032958606378
Epoch: 32 | Iteration number: [3580/4518] 79% | Training loss: 0.6870343152537692
Epoch: 32 | Iteration number: [3590/4518] 79% | Training loss: 0.6870279250536788
Epoch: 32 | Iteration number: [3600/4518] 79% | Training loss: 0.6870277563399739
Epoch: 32 | Iteration number: [3610/4518] 79% | Training loss: 0.6870290252805746
Epoch: 32 | Iteration number: [3620/4518] 80% | Training loss: 0.6870317819204119
Epoch: 32 | Iteration number: [3630/4518] 80% | Training loss: 0.6870306183319775
Epoch: 32 | Iteration number: [3640/4518] 80% | Training loss: 0.6870285711609401
Epoch: 32 | Iteration number: [3650/4518] 80% | Training loss: 0.6870311010373782
Epoch: 32 | Iteration number: [3660/4518] 81% | Training loss: 0.6870314399238493
Epoch: 32 | Iteration number: [3670/4518] 81% | Training loss: 0.6870302321638009
Epoch: 32 | Iteration number: [3680/4518] 81% | Training loss: 0.687031031837282
Epoch: 32 | Iteration number: [3690/4518] 81% | Training loss: 0.6870308529555313
Epoch: 32 | Iteration number: [3700/4518] 81% | Training loss: 0.6870292807108647
Epoch: 32 | Iteration number: [3710/4518] 82% | Training loss: 0.6870317955383394
Epoch: 32 | Iteration number: [3720/4518] 82% | Training loss: 0.6870277610517317
Epoch: 32 | Iteration number: [3730/4518] 82% | Training loss: 0.6870267296924029
Epoch: 32 | Iteration number: [3740/4518] 82% | Training loss: 0.6870270873614174
Epoch: 32 | Iteration number: [3750/4518] 83% | Training loss: 0.6870279907067617
Epoch: 32 | Iteration number: [3760/4518] 83% | Training loss: 0.6870284784505976
Epoch: 32 | Iteration number: [3770/4518] 83% | Training loss: 0.6870284911017835
Epoch: 32 | Iteration number: [3780/4518] 83% | Training loss: 0.687029248349881
Epoch: 32 | Iteration number: [3790/4518] 83% | Training loss: 0.6870294884358358
Epoch: 32 | Iteration number: [3800/4518] 84% | Training loss: 0.68702988053623
Epoch: 32 | Iteration number: [3810/4518] 84% | Training loss: 0.6870256797848098
Epoch: 32 | Iteration number: [3820/4518] 84% | Training loss: 0.6870257251549766
Epoch: 32 | Iteration number: [3830/4518] 84% | Training loss: 0.6870227249577525
Epoch: 32 | Iteration number: [3840/4518] 84% | Training loss: 0.6870218998442094
Epoch: 32 | Iteration number: [3850/4518] 85% | Training loss: 0.6870215540118032
Epoch: 32 | Iteration number: [3860/4518] 85% | Training loss: 0.6870231136293609
Epoch: 32 | Iteration number: [3870/4518] 85% | Training loss: 0.687021404011921
Epoch: 32 | Iteration number: [3880/4518] 85% | Training loss: 0.687017846829498
Epoch: 32 | Iteration number: [3890/4518] 86% | Training loss: 0.6870166840467478
Epoch: 32 | Iteration number: [3900/4518] 86% | Training loss: 0.6870178765517014
Epoch: 32 | Iteration number: [3910/4518] 86% | Training loss: 0.6870141355887703
Epoch: 32 | Iteration number: [3920/4518] 86% | Training loss: 0.687010630174559
Epoch: 32 | Iteration number: [3930/4518] 86% | Training loss: 0.6870074009015663
Epoch: 32 | Iteration number: [3940/4518] 87% | Training loss: 0.6870091094432144
Epoch: 32 | Iteration number: [3950/4518] 87% | Training loss: 0.6870094385931763
Epoch: 32 | Iteration number: [3960/4518] 87% | Training loss: 0.6870085545561531
Epoch: 32 | Iteration number: [3970/4518] 87% | Training loss: 0.6870106365428463
Epoch: 32 | Iteration number: [3980/4518] 88% | Training loss: 0.6870068205511151
Epoch: 32 | Iteration number: [3990/4518] 88% | Training loss: 0.6870076316042353
Epoch: 32 | Iteration number: [4000/4518] 88% | Training loss: 0.6870056492239237
Epoch: 32 | Iteration number: [4010/4518] 88% | Training loss: 0.6870035506246096
Epoch: 32 | Iteration number: [4020/4518] 88% | Training loss: 0.6870052168173576
Epoch: 32 | Iteration number: [4030/4518] 89% | Training loss: 0.6870052931622299
Epoch: 32 | Iteration number: [4040/4518] 89% | Training loss: 0.6870035422467949
Epoch: 32 | Iteration number: [4050/4518] 89% | Training loss: 0.6869995806099456
Epoch: 32 | Iteration number: [4060/4518] 89% | Training loss: 0.6870007746618957
Epoch: 32 | Iteration number: [4070/4518] 90% | Training loss: 0.6870016789699948
Epoch: 32 | Iteration number: [4080/4518] 90% | Training loss: 0.6870034559100282
Epoch: 32 | Iteration number: [4090/4518] 90% | Training loss: 0.6870018881224187
Epoch: 32 | Iteration number: [4100/4518] 90% | Training loss: 0.6870030404881733
Epoch: 32 | Iteration number: [4110/4518] 90% | Training loss: 0.6870012213858955
Epoch: 32 | Iteration number: [4120/4518] 91% | Training loss: 0.6870029324756085
Epoch: 32 | Iteration number: [4130/4518] 91% | Training loss: 0.6870031879831457
Epoch: 32 | Iteration number: [4140/4518] 91% | Training loss: 0.6870017968946033
Epoch: 32 | Iteration number: [4150/4518] 91% | Training loss: 0.6870003884671683
Epoch: 32 | Iteration number: [4160/4518] 92% | Training loss: 0.6870007630437612
Epoch: 32 | Iteration number: [4170/4518] 92% | Training loss: 0.687000683743319
Epoch: 32 | Iteration number: [4180/4518] 92% | Training loss: 0.687000607945132
Epoch: 32 | Iteration number: [4190/4518] 92% | Training loss: 0.6870008957129958
Epoch: 32 | Iteration number: [4200/4518] 92% | Training loss: 0.6870008048840931
Epoch: 32 | Iteration number: [4210/4518] 93% | Training loss: 0.6870033869409221
Epoch: 32 | Iteration number: [4220/4518] 93% | Training loss: 0.6870046369837358
Epoch: 32 | Iteration number: [4230/4518] 93% | Training loss: 0.687005787622844
Epoch: 32 | Iteration number: [4240/4518] 93% | Training loss: 0.6870044199925549
Epoch: 32 | Iteration number: [4250/4518] 94% | Training loss: 0.6870054209512823
Epoch: 32 | Iteration number: [4260/4518] 94% | Training loss: 0.6870069761511306
Epoch: 32 | Iteration number: [4270/4518] 94% | Training loss: 0.6870081612600376
Epoch: 32 | Iteration number: [4280/4518] 94% | Training loss: 0.6870099699664338
Epoch: 32 | Iteration number: [4290/4518] 94% | Training loss: 0.6870089837165424
Epoch: 32 | Iteration number: [4300/4518] 95% | Training loss: 0.68700792473416
Epoch: 32 | Iteration number: [4310/4518] 95% | Training loss: 0.6870077015352359
Epoch: 32 | Iteration number: [4320/4518] 95% | Training loss: 0.687004731402353
Epoch: 32 | Iteration number: [4330/4518] 95% | Training loss: 0.6870042519398705
Epoch: 32 | Iteration number: [4340/4518] 96% | Training loss: 0.687003623560277
Epoch: 32 | Iteration number: [4350/4518] 96% | Training loss: 0.6870028451667435
Epoch: 32 | Iteration number: [4360/4518] 96% | Training loss: 0.687004362087731
Epoch: 32 | Iteration number: [4370/4518] 96% | Training loss: 0.6870018135491989
Epoch: 32 | Iteration number: [4380/4518] 96% | Training loss: 0.6870015274852378
Epoch: 32 | Iteration number: [4390/4518] 97% | Training loss: 0.6870015442914463
Epoch: 32 | Iteration number: [4400/4518] 97% | Training loss: 0.6870004425671967
Epoch: 32 | Iteration number: [4410/4518] 97% | Training loss: 0.6870032852604275
Epoch: 32 | Iteration number: [4420/4518] 97% | Training loss: 0.6870037154374619
Epoch: 32 | Iteration number: [4430/4518] 98% | Training loss: 0.6870033706014904
Epoch: 32 | Iteration number: [4440/4518] 98% | Training loss: 0.6870062647370605
Epoch: 32 | Iteration number: [4450/4518] 98% | Training loss: 0.687002447856946
Epoch: 32 | Iteration number: [4460/4518] 98% | Training loss: 0.6869990526560711
Epoch: 32 | Iteration number: [4470/4518] 98% | Training loss: 0.6870001527553703
Epoch: 32 | Iteration number: [4480/4518] 99% | Training loss: 0.6870002492330969
Epoch: 32 | Iteration number: [4490/4518] 99% | Training loss: 0.687003568073689
Epoch: 32 | Iteration number: [4500/4518] 99% | Training loss: 0.6870025947226418
Epoch: 32 | Iteration number: [4510/4518] 99% | Training loss: 0.6870024058876968

 End of epoch: 32 | Train Loss: 0.6868519518506269 | Training Time: 641 

 End of epoch: 32 | Eval Loss: 0.6900692095561903 | Evaluating Time: 17 
Epoch: 33 | Iteration number: [10/4518] 0% | Training loss: 0.7555894792079926
Epoch: 33 | Iteration number: [20/4518] 0% | Training loss: 0.7209715664386749
Epoch: 33 | Iteration number: [30/4518] 0% | Training loss: 0.7097805658976237
Epoch: 33 | Iteration number: [40/4518] 0% | Training loss: 0.7040725305676461
Epoch: 33 | Iteration number: [50/4518] 1% | Training loss: 0.7007349145412445
Epoch: 33 | Iteration number: [60/4518] 1% | Training loss: 0.6983149131139119
Epoch: 33 | Iteration number: [70/4518] 1% | Training loss: 0.6967785945960454
Epoch: 33 | Iteration number: [80/4518] 1% | Training loss: 0.6955296441912651
Epoch: 33 | Iteration number: [90/4518] 1% | Training loss: 0.6944563064310286
Epoch: 33 | Iteration number: [100/4518] 2% | Training loss: 0.6936917108297348
Epoch: 33 | Iteration number: [110/4518] 2% | Training loss: 0.693139846758409
Epoch: 33 | Iteration number: [120/4518] 2% | Training loss: 0.6926850423216819
Epoch: 33 | Iteration number: [130/4518] 2% | Training loss: 0.6922266189868633
Epoch: 33 | Iteration number: [140/4518] 3% | Training loss: 0.6918629561151777
Epoch: 33 | Iteration number: [150/4518] 3% | Training loss: 0.6915147642294566
Epoch: 33 | Iteration number: [160/4518] 3% | Training loss: 0.691224642470479
Epoch: 33 | Iteration number: [170/4518] 3% | Training loss: 0.6909634891678306
Epoch: 33 | Iteration number: [180/4518] 3% | Training loss: 0.6907315529055066
Epoch: 33 | Iteration number: [190/4518] 4% | Training loss: 0.6905224210337588
Epoch: 33 | Iteration number: [200/4518] 4% | Training loss: 0.6903123149275779
Epoch: 33 | Iteration number: [210/4518] 4% | Training loss: 0.6900511943158649
Epoch: 33 | Iteration number: [220/4518] 4% | Training loss: 0.6898689234798605
Epoch: 33 | Iteration number: [230/4518] 5% | Training loss: 0.6897430603918822
Epoch: 33 | Iteration number: [240/4518] 5% | Training loss: 0.6896643015245597
Epoch: 33 | Iteration number: [250/4518] 5% | Training loss: 0.6895081951618195
Epoch: 33 | Iteration number: [260/4518] 5% | Training loss: 0.6894020250210395
Epoch: 33 | Iteration number: [270/4518] 5% | Training loss: 0.689308007116671
Epoch: 33 | Iteration number: [280/4518] 6% | Training loss: 0.6891914910503796
Epoch: 33 | Iteration number: [290/4518] 6% | Training loss: 0.6891058188060234
Epoch: 33 | Iteration number: [300/4518] 6% | Training loss: 0.6890671863158544
Epoch: 33 | Iteration number: [310/4518] 6% | Training loss: 0.6890075060629075
Epoch: 33 | Iteration number: [320/4518] 7% | Training loss: 0.68892891574651
Epoch: 33 | Iteration number: [330/4518] 7% | Training loss: 0.6889070241740256
Epoch: 33 | Iteration number: [340/4518] 7% | Training loss: 0.6888270038015702
Epoch: 33 | Iteration number: [350/4518] 7% | Training loss: 0.6887457055704934
Epoch: 33 | Iteration number: [360/4518] 7% | Training loss: 0.68868727253543
Epoch: 33 | Iteration number: [370/4518] 8% | Training loss: 0.6886344738908716
Epoch: 33 | Iteration number: [380/4518] 8% | Training loss: 0.6885908646018881
Epoch: 33 | Iteration number: [390/4518] 8% | Training loss: 0.688541421523461
Epoch: 33 | Iteration number: [400/4518] 8% | Training loss: 0.6885006259381771
Epoch: 33 | Iteration number: [410/4518] 9% | Training loss: 0.6884648429184426
Epoch: 33 | Iteration number: [420/4518] 9% | Training loss: 0.6884113587084271
Epoch: 33 | Iteration number: [430/4518] 9% | Training loss: 0.6883997678756714
Epoch: 33 | Iteration number: [440/4518] 9% | Training loss: 0.6883465506813743
Epoch: 33 | Iteration number: [450/4518] 9% | Training loss: 0.6883263708485498
Epoch: 33 | Iteration number: [460/4518] 10% | Training loss: 0.6882988782032676
Epoch: 33 | Iteration number: [470/4518] 10% | Training loss: 0.6882727116980452
Epoch: 33 | Iteration number: [480/4518] 10% | Training loss: 0.6882166451464097
Epoch: 33 | Iteration number: [490/4518] 10% | Training loss: 0.6882143048607573
Epoch: 33 | Iteration number: [500/4518] 11% | Training loss: 0.6881866503953934
Epoch: 33 | Iteration number: [510/4518] 11% | Training loss: 0.6881742896986943
Epoch: 33 | Iteration number: [520/4518] 11% | Training loss: 0.6881515928185903
Epoch: 33 | Iteration number: [530/4518] 11% | Training loss: 0.6881169168454296
Epoch: 33 | Iteration number: [540/4518] 11% | Training loss: 0.6880654262171851
Epoch: 33 | Iteration number: [550/4518] 12% | Training loss: 0.6880096370523626
Epoch: 33 | Iteration number: [560/4518] 12% | Training loss: 0.6879899246352059
Epoch: 33 | Iteration number: [570/4518] 12% | Training loss: 0.6879699382865638
Epoch: 33 | Iteration number: [580/4518] 12% | Training loss: 0.687966993862185
Epoch: 33 | Iteration number: [590/4518] 13% | Training loss: 0.6879558822866213
Epoch: 33 | Iteration number: [600/4518] 13% | Training loss: 0.6879583637913068
Epoch: 33 | Iteration number: [610/4518] 13% | Training loss: 0.6879447853956067
Epoch: 33 | Iteration number: [620/4518] 13% | Training loss: 0.6879291014325234
Epoch: 33 | Iteration number: [630/4518] 13% | Training loss: 0.6879258427355025
Epoch: 33 | Iteration number: [640/4518] 14% | Training loss: 0.6879168463870883
Epoch: 33 | Iteration number: [650/4518] 14% | Training loss: 0.6878921776551467
Epoch: 33 | Iteration number: [660/4518] 14% | Training loss: 0.6878881544777842
Epoch: 33 | Iteration number: [670/4518] 14% | Training loss: 0.6878689346028798
Epoch: 33 | Iteration number: [680/4518] 15% | Training loss: 0.687842786487411
Epoch: 33 | Iteration number: [690/4518] 15% | Training loss: 0.6878307658693065
Epoch: 33 | Iteration number: [700/4518] 15% | Training loss: 0.6878021557841982
Epoch: 33 | Iteration number: [710/4518] 15% | Training loss: 0.687780564519721
Epoch: 33 | Iteration number: [720/4518] 15% | Training loss: 0.6877635082436933
Epoch: 33 | Iteration number: [730/4518] 16% | Training loss: 0.6877634305660039
Epoch: 33 | Iteration number: [740/4518] 16% | Training loss: 0.6877539523549983
Epoch: 33 | Iteration number: [750/4518] 16% | Training loss: 0.6877229564189911
Epoch: 33 | Iteration number: [760/4518] 16% | Training loss: 0.6877020870384417
Epoch: 33 | Iteration number: [770/4518] 17% | Training loss: 0.687680335942801
Epoch: 33 | Iteration number: [780/4518] 17% | Training loss: 0.6876822756651121
Epoch: 33 | Iteration number: [790/4518] 17% | Training loss: 0.6876651013199288
Epoch: 33 | Iteration number: [800/4518] 17% | Training loss: 0.6876783875375986
Epoch: 33 | Iteration number: [810/4518] 17% | Training loss: 0.6876784223833202
Epoch: 33 | Iteration number: [820/4518] 18% | Training loss: 0.687658095941311
Epoch: 33 | Iteration number: [830/4518] 18% | Training loss: 0.6876544087048037
Epoch: 33 | Iteration number: [840/4518] 18% | Training loss: 0.6876521202070373
Epoch: 33 | Iteration number: [850/4518] 18% | Training loss: 0.6876390485903796
Epoch: 33 | Iteration number: [860/4518] 19% | Training loss: 0.6876313301712967
Epoch: 33 | Iteration number: [870/4518] 19% | Training loss: 0.6876213623189378
Epoch: 33 | Iteration number: [880/4518] 19% | Training loss: 0.6876196270639247
Epoch: 33 | Iteration number: [890/4518] 19% | Training loss: 0.6876128021920664
Epoch: 33 | Iteration number: [900/4518] 19% | Training loss: 0.6876195643345515
Epoch: 33 | Iteration number: [910/4518] 20% | Training loss: 0.6876076538484175
Epoch: 33 | Iteration number: [920/4518] 20% | Training loss: 0.6875993288081625
Epoch: 33 | Iteration number: [930/4518] 20% | Training loss: 0.6875887243337528
Epoch: 33 | Iteration number: [940/4518] 20% | Training loss: 0.6875771729235953
Epoch: 33 | Iteration number: [950/4518] 21% | Training loss: 0.687548458889911
Epoch: 33 | Iteration number: [960/4518] 21% | Training loss: 0.6875345184778173
Epoch: 33 | Iteration number: [970/4518] 21% | Training loss: 0.6875311318132066
Epoch: 33 | Iteration number: [980/4518] 21% | Training loss: 0.6875237894909723
Epoch: 33 | Iteration number: [990/4518] 21% | Training loss: 0.687521626973393
Epoch: 33 | Iteration number: [1000/4518] 22% | Training loss: 0.6875050755739212
Epoch: 33 | Iteration number: [1010/4518] 22% | Training loss: 0.6875020253776324
Epoch: 33 | Iteration number: [1020/4518] 22% | Training loss: 0.6874847053897147
Epoch: 33 | Iteration number: [1030/4518] 22% | Training loss: 0.6874703602304736
Epoch: 33 | Iteration number: [1040/4518] 23% | Training loss: 0.6874660558998584
Epoch: 33 | Iteration number: [1050/4518] 23% | Training loss: 0.6874435630866459
Epoch: 33 | Iteration number: [1060/4518] 23% | Training loss: 0.6874230629992935
Epoch: 33 | Iteration number: [1070/4518] 23% | Training loss: 0.6874189190218382
Epoch: 33 | Iteration number: [1080/4518] 23% | Training loss: 0.6874058047378505
Epoch: 33 | Iteration number: [1090/4518] 24% | Training loss: 0.6874002904520122
Epoch: 33 | Iteration number: [1100/4518] 24% | Training loss: 0.6874068342555653
Epoch: 33 | Iteration number: [1110/4518] 24% | Training loss: 0.6874043583869934
Epoch: 33 | Iteration number: [1120/4518] 24% | Training loss: 0.6873960191117866
Epoch: 33 | Iteration number: [1130/4518] 25% | Training loss: 0.6873843655122065
Epoch: 33 | Iteration number: [1140/4518] 25% | Training loss: 0.6873658125337802
Epoch: 33 | Iteration number: [1150/4518] 25% | Training loss: 0.687357751649359
Epoch: 33 | Iteration number: [1160/4518] 25% | Training loss: 0.6873377737813983
Epoch: 33 | Iteration number: [1170/4518] 25% | Training loss: 0.6873343015328431
Epoch: 33 | Iteration number: [1180/4518] 26% | Training loss: 0.6873355258319338
Epoch: 33 | Iteration number: [1190/4518] 26% | Training loss: 0.6873278002278144
Epoch: 33 | Iteration number: [1200/4518] 26% | Training loss: 0.6873182733853658
Epoch: 33 | Iteration number: [1210/4518] 26% | Training loss: 0.6873123808340593
Epoch: 33 | Iteration number: [1220/4518] 27% | Training loss: 0.6873184701458352
Epoch: 33 | Iteration number: [1230/4518] 27% | Training loss: 0.6873111436037513
Epoch: 33 | Iteration number: [1240/4518] 27% | Training loss: 0.6873092899399419
Epoch: 33 | Iteration number: [1250/4518] 27% | Training loss: 0.6872997484207153
Epoch: 33 | Iteration number: [1260/4518] 27% | Training loss: 0.6872852967845069
Epoch: 33 | Iteration number: [1270/4518] 28% | Training loss: 0.6872921340108856
Epoch: 33 | Iteration number: [1280/4518] 28% | Training loss: 0.6872869124170393
Epoch: 33 | Iteration number: [1290/4518] 28% | Training loss: 0.6872815090556478
Epoch: 33 | Iteration number: [1300/4518] 28% | Training loss: 0.6872850047166531
Epoch: 33 | Iteration number: [1310/4518] 28% | Training loss: 0.687275574362005
Epoch: 33 | Iteration number: [1320/4518] 29% | Training loss: 0.6872743943875487
Epoch: 33 | Iteration number: [1330/4518] 29% | Training loss: 0.6872762874553078
Epoch: 33 | Iteration number: [1340/4518] 29% | Training loss: 0.6872668066131535
Epoch: 33 | Iteration number: [1350/4518] 29% | Training loss: 0.687263907900563
Epoch: 33 | Iteration number: [1360/4518] 30% | Training loss: 0.6872689769548528
Epoch: 33 | Iteration number: [1370/4518] 30% | Training loss: 0.6872652635087062
Epoch: 33 | Iteration number: [1380/4518] 30% | Training loss: 0.6872624364452086
Epoch: 33 | Iteration number: [1390/4518] 30% | Training loss: 0.6872523556510322
Epoch: 33 | Iteration number: [1400/4518] 30% | Training loss: 0.6872444836156709
Epoch: 33 | Iteration number: [1410/4518] 31% | Training loss: 0.6872413730367701
Epoch: 33 | Iteration number: [1420/4518] 31% | Training loss: 0.6872538475923136
Epoch: 33 | Iteration number: [1430/4518] 31% | Training loss: 0.6872478234601187
Epoch: 33 | Iteration number: [1440/4518] 31% | Training loss: 0.6872556393759118
Epoch: 33 | Iteration number: [1450/4518] 32% | Training loss: 0.6872482957922179
Epoch: 33 | Iteration number: [1460/4518] 32% | Training loss: 0.687244829413009
Epoch: 33 | Iteration number: [1470/4518] 32% | Training loss: 0.6872393526998507
Epoch: 33 | Iteration number: [1480/4518] 32% | Training loss: 0.6872409176584836
Epoch: 33 | Iteration number: [1490/4518] 32% | Training loss: 0.6872353644179018
Epoch: 33 | Iteration number: [1500/4518] 33% | Training loss: 0.6872318953673044
Epoch: 33 | Iteration number: [1510/4518] 33% | Training loss: 0.687229682514999
Epoch: 33 | Iteration number: [1520/4518] 33% | Training loss: 0.687228067258471
Epoch: 33 | Iteration number: [1530/4518] 33% | Training loss: 0.6872260829592063
Epoch: 33 | Iteration number: [1540/4518] 34% | Training loss: 0.6872247513238485
Epoch: 33 | Iteration number: [1550/4518] 34% | Training loss: 0.6872230312132066
Epoch: 33 | Iteration number: [1560/4518] 34% | Training loss: 0.6872206129706823
Epoch: 33 | Iteration number: [1570/4518] 34% | Training loss: 0.6872174703771141
Epoch: 33 | Iteration number: [1580/4518] 34% | Training loss: 0.6872085152170326
Epoch: 33 | Iteration number: [1590/4518] 35% | Training loss: 0.6872014978021945
Epoch: 33 | Iteration number: [1600/4518] 35% | Training loss: 0.6871995869651437
Epoch: 33 | Iteration number: [1610/4518] 35% | Training loss: 0.6871982492645334
Epoch: 33 | Iteration number: [1620/4518] 35% | Training loss: 0.6871971956741663
Epoch: 33 | Iteration number: [1630/4518] 36% | Training loss: 0.6871944303892873
Epoch: 33 | Iteration number: [1640/4518] 36% | Training loss: 0.6871905833846186
Epoch: 33 | Iteration number: [1650/4518] 36% | Training loss: 0.6871913132161805
Epoch: 33 | Iteration number: [1660/4518] 36% | Training loss: 0.6871879688946597
Epoch: 33 | Iteration number: [1670/4518] 36% | Training loss: 0.6871827656280495
Epoch: 33 | Iteration number: [1680/4518] 37% | Training loss: 0.6871871843579269
Epoch: 33 | Iteration number: [1690/4518] 37% | Training loss: 0.6871941305476533
Epoch: 33 | Iteration number: [1700/4518] 37% | Training loss: 0.6871894883758881
Epoch: 33 | Iteration number: [1710/4518] 37% | Training loss: 0.6871854996123509
Epoch: 33 | Iteration number: [1720/4518] 38% | Training loss: 0.6871822504803192
Epoch: 33 | Iteration number: [1730/4518] 38% | Training loss: 0.68717613085846
Epoch: 33 | Iteration number: [1740/4518] 38% | Training loss: 0.6871740125376603
Epoch: 33 | Iteration number: [1750/4518] 38% | Training loss: 0.6871755254949842
Epoch: 33 | Iteration number: [1760/4518] 38% | Training loss: 0.6871741276911714
Epoch: 33 | Iteration number: [1770/4518] 39% | Training loss: 0.6871772355279007
Epoch: 33 | Iteration number: [1780/4518] 39% | Training loss: 0.6871788770630118
Epoch: 33 | Iteration number: [1790/4518] 39% | Training loss: 0.6871838824043061
Epoch: 33 | Iteration number: [1800/4518] 39% | Training loss: 0.6871792179014947
Epoch: 33 | Iteration number: [1810/4518] 40% | Training loss: 0.687182263445459
Epoch: 33 | Iteration number: [1820/4518] 40% | Training loss: 0.6871832191944123
Epoch: 33 | Iteration number: [1830/4518] 40% | Training loss: 0.6871749341162177
Epoch: 33 | Iteration number: [1840/4518] 40% | Training loss: 0.6871795230261658
Epoch: 33 | Iteration number: [1850/4518] 40% | Training loss: 0.6871744651729996
Epoch: 33 | Iteration number: [1860/4518] 41% | Training loss: 0.6871749450122157
Epoch: 33 | Iteration number: [1870/4518] 41% | Training loss: 0.6871792732713057
Epoch: 33 | Iteration number: [1880/4518] 41% | Training loss: 0.68718622555124
Epoch: 33 | Iteration number: [1890/4518] 41% | Training loss: 0.6871964011873518
Epoch: 33 | Iteration number: [1900/4518] 42% | Training loss: 0.6872020078960218
Epoch: 33 | Iteration number: [1910/4518] 42% | Training loss: 0.6872042650951765
Epoch: 33 | Iteration number: [1920/4518] 42% | Training loss: 0.6872033717731635
Epoch: 33 | Iteration number: [1930/4518] 42% | Training loss: 0.6872026753549131
Epoch: 33 | Iteration number: [1940/4518] 42% | Training loss: 0.6872057048008614
Epoch: 33 | Iteration number: [1950/4518] 43% | Training loss: 0.6872087120704162
Epoch: 33 | Iteration number: [1960/4518] 43% | Training loss: 0.6872107936107382
Epoch: 33 | Iteration number: [1970/4518] 43% | Training loss: 0.6872021200693198
Epoch: 33 | Iteration number: [1980/4518] 43% | Training loss: 0.68719596450377
Epoch: 33 | Iteration number: [1990/4518] 44% | Training loss: 0.6871971897743455
Epoch: 33 | Iteration number: [2000/4518] 44% | Training loss: 0.6872002568244934
Epoch: 33 | Iteration number: [2010/4518] 44% | Training loss: 0.6871981150475307
Epoch: 33 | Iteration number: [2020/4518] 44% | Training loss: 0.6872007980205045
Epoch: 33 | Iteration number: [2030/4518] 44% | Training loss: 0.6871993310052186
Epoch: 33 | Iteration number: [2040/4518] 45% | Training loss: 0.6871985606410924
Epoch: 33 | Iteration number: [2050/4518] 45% | Training loss: 0.6871965132980812
Epoch: 33 | Iteration number: [2060/4518] 45% | Training loss: 0.6871938553539295
Epoch: 33 | Iteration number: [2070/4518] 45% | Training loss: 0.6871934206013518
Epoch: 33 | Iteration number: [2080/4518] 46% | Training loss: 0.6871909026343089
Epoch: 33 | Iteration number: [2090/4518] 46% | Training loss: 0.6871916000637711
Epoch: 33 | Iteration number: [2100/4518] 46% | Training loss: 0.6871945684296744
Epoch: 33 | Iteration number: [2110/4518] 46% | Training loss: 0.687191682997473
Epoch: 33 | Iteration number: [2120/4518] 46% | Training loss: 0.6871872575777882
Epoch: 33 | Iteration number: [2130/4518] 47% | Training loss: 0.6871840831819275
Epoch: 33 | Iteration number: [2140/4518] 47% | Training loss: 0.6871820472946791
Epoch: 33 | Iteration number: [2150/4518] 47% | Training loss: 0.6871799592916356
Epoch: 33 | Iteration number: [2160/4518] 47% | Training loss: 0.6871777036399753
Epoch: 33 | Iteration number: [2170/4518] 48% | Training loss: 0.6871729040475485
Epoch: 33 | Iteration number: [2180/4518] 48% | Training loss: 0.6871682631860085
Epoch: 33 | Iteration number: [2190/4518] 48% | Training loss: 0.687163289986789
Epoch: 33 | Iteration number: [2200/4518] 48% | Training loss: 0.6871614194187251
Epoch: 33 | Iteration number: [2210/4518] 48% | Training loss: 0.6871610301112697
Epoch: 33 | Iteration number: [2220/4518] 49% | Training loss: 0.6871647457818727
Epoch: 33 | Iteration number: [2230/4518] 49% | Training loss: 0.6871634114483547
Epoch: 33 | Iteration number: [2240/4518] 49% | Training loss: 0.6871652681912694
Epoch: 33 | Iteration number: [2250/4518] 49% | Training loss: 0.6871649154027303
Epoch: 33 | Iteration number: [2260/4518] 50% | Training loss: 0.6871679091348057
Epoch: 33 | Iteration number: [2270/4518] 50% | Training loss: 0.6871658013255586
Epoch: 33 | Iteration number: [2280/4518] 50% | Training loss: 0.6871707614053759
Epoch: 33 | Iteration number: [2290/4518] 50% | Training loss: 0.6871700974531049
Epoch: 33 | Iteration number: [2300/4518] 50% | Training loss: 0.68717022286809
Epoch: 33 | Iteration number: [2310/4518] 51% | Training loss: 0.687169003976888
Epoch: 33 | Iteration number: [2320/4518] 51% | Training loss: 0.6871716107787758
Epoch: 33 | Iteration number: [2330/4518] 51% | Training loss: 0.6871720927467674
Epoch: 33 | Iteration number: [2340/4518] 51% | Training loss: 0.6871694708736534
Epoch: 33 | Iteration number: [2350/4518] 52% | Training loss: 0.6871690977634267
Epoch: 33 | Iteration number: [2360/4518] 52% | Training loss: 0.6871637324155387
Epoch: 33 | Iteration number: [2370/4518] 52% | Training loss: 0.6871643427052075
Epoch: 33 | Iteration number: [2380/4518] 52% | Training loss: 0.6871605882875058
Epoch: 33 | Iteration number: [2390/4518] 52% | Training loss: 0.6871586774931792
Epoch: 33 | Iteration number: [2400/4518] 53% | Training loss: 0.6871548105031252
Epoch: 33 | Iteration number: [2410/4518] 53% | Training loss: 0.6871483244836578
Epoch: 33 | Iteration number: [2420/4518] 53% | Training loss: 0.6871442925831504
Epoch: 33 | Iteration number: [2430/4518] 53% | Training loss: 0.687142662746916
Epoch: 33 | Iteration number: [2440/4518] 54% | Training loss: 0.6871385473941193
Epoch: 33 | Iteration number: [2450/4518] 54% | Training loss: 0.6871435642485716
Epoch: 33 | Iteration number: [2460/4518] 54% | Training loss: 0.6871449832024613
Epoch: 33 | Iteration number: [2470/4518] 54% | Training loss: 0.6871425035511434
Epoch: 33 | Iteration number: [2480/4518] 54% | Training loss: 0.6871421334003248
Epoch: 33 | Iteration number: [2490/4518] 55% | Training loss: 0.6871382947188305
Epoch: 33 | Iteration number: [2500/4518] 55% | Training loss: 0.6871313056468964
Epoch: 33 | Iteration number: [2510/4518] 55% | Training loss: 0.6871264038332905
Epoch: 33 | Iteration number: [2520/4518] 55% | Training loss: 0.6871185761359003
Epoch: 33 | Iteration number: [2530/4518] 55% | Training loss: 0.6871155123701209
Epoch: 33 | Iteration number: [2540/4518] 56% | Training loss: 0.6871130564316051
Epoch: 33 | Iteration number: [2550/4518] 56% | Training loss: 0.6871105810240203
Epoch: 33 | Iteration number: [2560/4518] 56% | Training loss: 0.6871072116540745
Epoch: 33 | Iteration number: [2570/4518] 56% | Training loss: 0.6871061336205627
Epoch: 33 | Iteration number: [2580/4518] 57% | Training loss: 0.6871088669743649
Epoch: 33 | Iteration number: [2590/4518] 57% | Training loss: 0.6871074544186758
Epoch: 33 | Iteration number: [2600/4518] 57% | Training loss: 0.6871026767217195
Epoch: 33 | Iteration number: [2610/4518] 57% | Training loss: 0.687099906882107
Epoch: 33 | Iteration number: [2620/4518] 57% | Training loss: 0.6870955623060693
Epoch: 33 | Iteration number: [2630/4518] 58% | Training loss: 0.6870946129465284
Epoch: 33 | Iteration number: [2640/4518] 58% | Training loss: 0.6870927535449014
Epoch: 33 | Iteration number: [2650/4518] 58% | Training loss: 0.687092824139685
Epoch: 33 | Iteration number: [2660/4518] 58% | Training loss: 0.687091970779842
Epoch: 33 | Iteration number: [2670/4518] 59% | Training loss: 0.6870906047606736
Epoch: 33 | Iteration number: [2680/4518] 59% | Training loss: 0.6870868754253459
Epoch: 33 | Iteration number: [2690/4518] 59% | Training loss: 0.687085852414702
Epoch: 33 | Iteration number: [2700/4518] 59% | Training loss: 0.6870841657673871
Epoch: 33 | Iteration number: [2710/4518] 59% | Training loss: 0.6870886855679684
Epoch: 33 | Iteration number: [2720/4518] 60% | Training loss: 0.6870863987023339
Epoch: 33 | Iteration number: [2730/4518] 60% | Training loss: 0.6870822537294674
Epoch: 33 | Iteration number: [2740/4518] 60% | Training loss: 0.6870802299384653
Epoch: 33 | Iteration number: [2750/4518] 60% | Training loss: 0.6870781985846433
Epoch: 33 | Iteration number: [2760/4518] 61% | Training loss: 0.68708135958599
Epoch: 33 | Iteration number: [2770/4518] 61% | Training loss: 0.6870817857313672
Epoch: 33 | Iteration number: [2780/4518] 61% | Training loss: 0.6870836813672841
Epoch: 33 | Iteration number: [2790/4518] 61% | Training loss: 0.6870793944832244
Epoch: 33 | Iteration number: [2800/4518] 61% | Training loss: 0.6870838982718331
Epoch: 33 | Iteration number: [2810/4518] 62% | Training loss: 0.6870799519413306
Epoch: 33 | Iteration number: [2820/4518] 62% | Training loss: 0.6870770745877679
Epoch: 33 | Iteration number: [2830/4518] 62% | Training loss: 0.6870764096928991
Epoch: 33 | Iteration number: [2840/4518] 62% | Training loss: 0.6870747225805067
Epoch: 33 | Iteration number: [2850/4518] 63% | Training loss: 0.6870753487787749
Epoch: 33 | Iteration number: [2860/4518] 63% | Training loss: 0.6870729099203656
Epoch: 33 | Iteration number: [2870/4518] 63% | Training loss: 0.6870728762930693
Epoch: 33 | Iteration number: [2880/4518] 63% | Training loss: 0.6870700865570042
Epoch: 33 | Iteration number: [2890/4518] 63% | Training loss: 0.6870709704486556
Epoch: 33 | Iteration number: [2900/4518] 64% | Training loss: 0.6870699148753594
Epoch: 33 | Iteration number: [2910/4518] 64% | Training loss: 0.6870681207204602
Epoch: 33 | Iteration number: [2920/4518] 64% | Training loss: 0.6870671076725607
Epoch: 33 | Iteration number: [2930/4518] 64% | Training loss: 0.6870672553065694
Epoch: 33 | Iteration number: [2940/4518] 65% | Training loss: 0.687065209417927
Epoch: 33 | Iteration number: [2950/4518] 65% | Training loss: 0.6870649467686475
Epoch: 33 | Iteration number: [2960/4518] 65% | Training loss: 0.6870673375556597
Epoch: 33 | Iteration number: [2970/4518] 65% | Training loss: 0.6870635356565918
Epoch: 33 | Iteration number: [2980/4518] 65% | Training loss: 0.687063415338529
Epoch: 33 | Iteration number: [2990/4518] 66% | Training loss: 0.6870651843755141
Epoch: 33 | Iteration number: [3000/4518] 66% | Training loss: 0.6870622360706329
Epoch: 33 | Iteration number: [3010/4518] 66% | Training loss: 0.6870650388077644
Epoch: 33 | Iteration number: [3020/4518] 66% | Training loss: 0.6870645124391215
Epoch: 33 | Iteration number: [3030/4518] 67% | Training loss: 0.687062909500827
Epoch: 33 | Iteration number: [3040/4518] 67% | Training loss: 0.6870591879087059
Epoch: 33 | Iteration number: [3050/4518] 67% | Training loss: 0.6870588292841051
Epoch: 33 | Iteration number: [3060/4518] 67% | Training loss: 0.687055274279289
Epoch: 33 | Iteration number: [3070/4518] 67% | Training loss: 0.6870504369759016
Epoch: 33 | Iteration number: [3080/4518] 68% | Training loss: 0.6870509355679735
Epoch: 33 | Iteration number: [3090/4518] 68% | Training loss: 0.6870476374348391
Epoch: 33 | Iteration number: [3100/4518] 68% | Training loss: 0.6870458560220657
Epoch: 33 | Iteration number: [3110/4518] 68% | Training loss: 0.6870443209382882
Epoch: 33 | Iteration number: [3120/4518] 69% | Training loss: 0.6870411965900507
Epoch: 33 | Iteration number: [3130/4518] 69% | Training loss: 0.6870422780132903
Epoch: 33 | Iteration number: [3140/4518] 69% | Training loss: 0.6870441833878779
Epoch: 33 | Iteration number: [3150/4518] 69% | Training loss: 0.6870416561951713
Epoch: 33 | Iteration number: [3160/4518] 69% | Training loss: 0.6870356963216504
Epoch: 33 | Iteration number: [3170/4518] 70% | Training loss: 0.6870337054180422
Epoch: 33 | Iteration number: [3180/4518] 70% | Training loss: 0.6870354982667
Epoch: 33 | Iteration number: [3190/4518] 70% | Training loss: 0.6870341106268306
Epoch: 33 | Iteration number: [3200/4518] 70% | Training loss: 0.6870300808735191
Epoch: 33 | Iteration number: [3210/4518] 71% | Training loss: 0.6870263447457013
Epoch: 33 | Iteration number: [3220/4518] 71% | Training loss: 0.6870226924648937
Epoch: 33 | Iteration number: [3230/4518] 71% | Training loss: 0.6870241393983918
Epoch: 33 | Iteration number: [3240/4518] 71% | Training loss: 0.6870201798684803
Epoch: 33 | Iteration number: [3250/4518] 71% | Training loss: 0.6870142582196456
Epoch: 33 | Iteration number: [3260/4518] 72% | Training loss: 0.6870186511907109
Epoch: 33 | Iteration number: [3270/4518] 72% | Training loss: 0.6870204266240473
Epoch: 33 | Iteration number: [3280/4518] 72% | Training loss: 0.6870215569690961
Epoch: 33 | Iteration number: [3290/4518] 72% | Training loss: 0.6870194492550245
Epoch: 33 | Iteration number: [3300/4518] 73% | Training loss: 0.6870201634999478
Epoch: 33 | Iteration number: [3310/4518] 73% | Training loss: 0.6870161747104092
Epoch: 33 | Iteration number: [3320/4518] 73% | Training loss: 0.6870184221720121
Epoch: 33 | Iteration number: [3330/4518] 73% | Training loss: 0.6870199120080507
Epoch: 33 | Iteration number: [3340/4518] 73% | Training loss: 0.6870224100565482
Epoch: 33 | Iteration number: [3350/4518] 74% | Training loss: 0.6870220336451459
Epoch: 33 | Iteration number: [3360/4518] 74% | Training loss: 0.6870183852102075
Epoch: 33 | Iteration number: [3370/4518] 74% | Training loss: 0.6870152833730602
Epoch: 33 | Iteration number: [3380/4518] 74% | Training loss: 0.6870159339093598
Epoch: 33 | Iteration number: [3390/4518] 75% | Training loss: 0.6870129017351652
Epoch: 33 | Iteration number: [3400/4518] 75% | Training loss: 0.6870098313163309
Epoch: 33 | Iteration number: [3410/4518] 75% | Training loss: 0.6870108708957773
Epoch: 33 | Iteration number: [3420/4518] 75% | Training loss: 0.6870094838198165
Epoch: 33 | Iteration number: [3430/4518] 75% | Training loss: 0.6870131893686233
Epoch: 33 | Iteration number: [3440/4518] 76% | Training loss: 0.6870096156936746
Epoch: 33 | Iteration number: [3450/4518] 76% | Training loss: 0.6870083269520082
Epoch: 33 | Iteration number: [3460/4518] 76% | Training loss: 0.687011809087213
Epoch: 33 | Iteration number: [3470/4518] 76% | Training loss: 0.6870132007928678
Epoch: 33 | Iteration number: [3480/4518] 77% | Training loss: 0.6870163458859784
Epoch: 33 | Iteration number: [3490/4518] 77% | Training loss: 0.6870161744789954
Epoch: 33 | Iteration number: [3500/4518] 77% | Training loss: 0.6870187524897712
Epoch: 33 | Iteration number: [3510/4518] 77% | Training loss: 0.6870182923272125
Epoch: 33 | Iteration number: [3520/4518] 77% | Training loss: 0.6870214544067329
Epoch: 33 | Iteration number: [3530/4518] 78% | Training loss: 0.6870211499608609
Epoch: 33 | Iteration number: [3540/4518] 78% | Training loss: 0.6870200995503173
Epoch: 33 | Iteration number: [3550/4518] 78% | Training loss: 0.6870242851552829
Epoch: 33 | Iteration number: [3560/4518] 78% | Training loss: 0.6870239269867372
Epoch: 33 | Iteration number: [3570/4518] 79% | Training loss: 0.6870228915154433
Epoch: 33 | Iteration number: [3580/4518] 79% | Training loss: 0.6870197526069993
Epoch: 33 | Iteration number: [3590/4518] 79% | Training loss: 0.6870191673216381
Epoch: 33 | Iteration number: [3600/4518] 79% | Training loss: 0.6870175130334165
Epoch: 33 | Iteration number: [3610/4518] 79% | Training loss: 0.6870170383572248
Epoch: 33 | Iteration number: [3620/4518] 80% | Training loss: 0.6870183134276564
Epoch: 33 | Iteration number: [3630/4518] 80% | Training loss: 0.687019447616966
Epoch: 33 | Iteration number: [3640/4518] 80% | Training loss: 0.6870206051639148
Epoch: 33 | Iteration number: [3650/4518] 80% | Training loss: 0.6870220840140565
Epoch: 33 | Iteration number: [3660/4518] 81% | Training loss: 0.687021525505462
Epoch: 33 | Iteration number: [3670/4518] 81% | Training loss: 0.6870197345028132
Epoch: 33 | Iteration number: [3680/4518] 81% | Training loss: 0.6870222214771353
Epoch: 33 | Iteration number: [3690/4518] 81% | Training loss: 0.68702069503182
Epoch: 33 | Iteration number: [3700/4518] 81% | Training loss: 0.6870201352158108
Epoch: 33 | Iteration number: [3710/4518] 82% | Training loss: 0.6870157523617911
Epoch: 33 | Iteration number: [3720/4518] 82% | Training loss: 0.6870128076723827
Epoch: 33 | Iteration number: [3730/4518] 82% | Training loss: 0.6870103742098361
Epoch: 33 | Iteration number: [3740/4518] 82% | Training loss: 0.6870124753305619
Epoch: 33 | Iteration number: [3750/4518] 83% | Training loss: 0.6870125531196595
Epoch: 33 | Iteration number: [3760/4518] 83% | Training loss: 0.6870124801517801
Epoch: 33 | Iteration number: [3770/4518] 83% | Training loss: 0.6870130641865161
Epoch: 33 | Iteration number: [3780/4518] 83% | Training loss: 0.6870109562835996
Epoch: 33 | Iteration number: [3790/4518] 83% | Training loss: 0.6870093474759276
Epoch: 33 | Iteration number: [3800/4518] 84% | Training loss: 0.6870081392714852
Epoch: 33 | Iteration number: [3810/4518] 84% | Training loss: 0.687008482953069
Epoch: 33 | Iteration number: [3820/4518] 84% | Training loss: 0.6870072062258945
Epoch: 33 | Iteration number: [3830/4518] 84% | Training loss: 0.6870076841847392
Epoch: 33 | Iteration number: [3840/4518] 84% | Training loss: 0.6870094818373521
Epoch: 33 | Iteration number: [3850/4518] 85% | Training loss: 0.6870110181554572
Epoch: 33 | Iteration number: [3860/4518] 85% | Training loss: 0.6870133048975406
Epoch: 33 | Iteration number: [3870/4518] 85% | Training loss: 0.687012000062361
Epoch: 33 | Iteration number: [3880/4518] 85% | Training loss: 0.6870091855833211
Epoch: 33 | Iteration number: [3890/4518] 86% | Training loss: 0.6870087199468539
Epoch: 33 | Iteration number: [3900/4518] 86% | Training loss: 0.6870084022864317
Epoch: 33 | Iteration number: [3910/4518] 86% | Training loss: 0.6870109229898819
Epoch: 33 | Iteration number: [3920/4518] 86% | Training loss: 0.687011517705966
Epoch: 33 | Iteration number: [3930/4518] 86% | Training loss: 0.6870115466700255
Epoch: 33 | Iteration number: [3940/4518] 87% | Training loss: 0.6870134814287805
Epoch: 33 | Iteration number: [3950/4518] 87% | Training loss: 0.6870135173767428
Epoch: 33 | Iteration number: [3960/4518] 87% | Training loss: 0.6870104976826243
Epoch: 33 | Iteration number: [3970/4518] 87% | Training loss: 0.6870094342105635
Epoch: 33 | Iteration number: [3980/4518] 88% | Training loss: 0.6870092758581267
Epoch: 33 | Iteration number: [3990/4518] 88% | Training loss: 0.6870100714060896
Epoch: 33 | Iteration number: [4000/4518] 88% | Training loss: 0.6870084481686354
Epoch: 33 | Iteration number: [4010/4518] 88% | Training loss: 0.6870072033191262
Epoch: 33 | Iteration number: [4020/4518] 88% | Training loss: 0.68700822071353
Epoch: 33 | Iteration number: [4030/4518] 89% | Training loss: 0.6870103473107217
Epoch: 33 | Iteration number: [4040/4518] 89% | Training loss: 0.6870106884453556
Epoch: 33 | Iteration number: [4050/4518] 89% | Training loss: 0.6870102851626314
Epoch: 33 | Iteration number: [4060/4518] 89% | Training loss: 0.6870104330073437
Epoch: 33 | Iteration number: [4070/4518] 90% | Training loss: 0.6870125500956683
Epoch: 33 | Iteration number: [4080/4518] 90% | Training loss: 0.6870129658895381
Epoch: 33 | Iteration number: [4090/4518] 90% | Training loss: 0.6870137921901087
Epoch: 33 | Iteration number: [4100/4518] 90% | Training loss: 0.6870150390194684
Epoch: 33 | Iteration number: [4110/4518] 90% | Training loss: 0.6870153501521061
Epoch: 33 | Iteration number: [4120/4518] 91% | Training loss: 0.6870131190540721
Epoch: 33 | Iteration number: [4130/4518] 91% | Training loss: 0.6870124938412959
Epoch: 33 | Iteration number: [4140/4518] 91% | Training loss: 0.6870078000613457
Epoch: 33 | Iteration number: [4150/4518] 91% | Training loss: 0.6870057647630393
Epoch: 33 | Iteration number: [4160/4518] 92% | Training loss: 0.6870065246923611
Epoch: 33 | Iteration number: [4170/4518] 92% | Training loss: 0.6870095944804825
Epoch: 33 | Iteration number: [4180/4518] 92% | Training loss: 0.6870108000114203
Epoch: 33 | Iteration number: [4190/4518] 92% | Training loss: 0.6870114662055469
Epoch: 33 | Iteration number: [4200/4518] 92% | Training loss: 0.6870123280371938
Epoch: 33 | Iteration number: [4210/4518] 93% | Training loss: 0.6870126288463837
Epoch: 33 | Iteration number: [4220/4518] 93% | Training loss: 0.6870110344689039
Epoch: 33 | Iteration number: [4230/4518] 93% | Training loss: 0.6870096061669343
Epoch: 33 | Iteration number: [4240/4518] 93% | Training loss: 0.6870042954835127
Epoch: 33 | Iteration number: [4250/4518] 94% | Training loss: 0.687005146040636
Epoch: 33 | Iteration number: [4260/4518] 94% | Training loss: 0.6870043865811657
Epoch: 33 | Iteration number: [4270/4518] 94% | Training loss: 0.6870053069094584
Epoch: 33 | Iteration number: [4280/4518] 94% | Training loss: 0.6870052087112007
Epoch: 33 | Iteration number: [4290/4518] 94% | Training loss: 0.687004103680035
Epoch: 33 | Iteration number: [4300/4518] 95% | Training loss: 0.6870073573533879
Epoch: 33 | Iteration number: [4310/4518] 95% | Training loss: 0.6870070176168827
Epoch: 33 | Iteration number: [4320/4518] 95% | Training loss: 0.6870044347036768
Epoch: 33 | Iteration number: [4330/4518] 95% | Training loss: 0.6870044825809382
Epoch: 33 | Iteration number: [4340/4518] 96% | Training loss: 0.6870032990720415
Epoch: 33 | Iteration number: [4350/4518] 96% | Training loss: 0.687003885589797
Epoch: 33 | Iteration number: [4360/4518] 96% | Training loss: 0.687003820437357
Epoch: 33 | Iteration number: [4370/4518] 96% | Training loss: 0.6870034429656013
Epoch: 33 | Iteration number: [4380/4518] 96% | Training loss: 0.6870044296462786
Epoch: 33 | Iteration number: [4390/4518] 97% | Training loss: 0.6870055686232712
Epoch: 33 | Iteration number: [4400/4518] 97% | Training loss: 0.6870070377534087
Epoch: 33 | Iteration number: [4410/4518] 97% | Training loss: 0.687007115014286
Epoch: 33 | Iteration number: [4420/4518] 97% | Training loss: 0.6870094888485395
Epoch: 33 | Iteration number: [4430/4518] 98% | Training loss: 0.6870101111737116
Epoch: 33 | Iteration number: [4440/4518] 98% | Training loss: 0.6870106744336653
Epoch: 33 | Iteration number: [4450/4518] 98% | Training loss: 0.6870116911309488
Epoch: 33 | Iteration number: [4460/4518] 98% | Training loss: 0.6870103425241907
Epoch: 33 | Iteration number: [4470/4518] 98% | Training loss: 0.6870096116791369
Epoch: 33 | Iteration number: [4480/4518] 99% | Training loss: 0.6870067844965628
Epoch: 33 | Iteration number: [4490/4518] 99% | Training loss: 0.6870059887523906
Epoch: 33 | Iteration number: [4500/4518] 99% | Training loss: 0.6870076989862653
Epoch: 33 | Iteration number: [4510/4518] 99% | Training loss: 0.6870037202031544

 End of epoch: 33 | Train Loss: 0.6868497933128758 | Training Time: 640 

 End of epoch: 33 | Eval Loss: 0.6900909117289952 | Evaluating Time: 17 
Epoch: 34 | Iteration number: [10/4518] 0% | Training loss: 0.7556826829910278
Epoch: 34 | Iteration number: [20/4518] 0% | Training loss: 0.7209354400634765
Epoch: 34 | Iteration number: [30/4518] 0% | Training loss: 0.7099225580692291
Epoch: 34 | Iteration number: [40/4518] 0% | Training loss: 0.7044117793440818
Epoch: 34 | Iteration number: [50/4518] 1% | Training loss: 0.7009094381332397
Epoch: 34 | Iteration number: [60/4518] 1% | Training loss: 0.6985234230756759
Epoch: 34 | Iteration number: [70/4518] 1% | Training loss: 0.6966769405773707
Epoch: 34 | Iteration number: [80/4518] 1% | Training loss: 0.6955057747662068
Epoch: 34 | Iteration number: [90/4518] 1% | Training loss: 0.6945938501093123
Epoch: 34 | Iteration number: [100/4518] 2% | Training loss: 0.6939536583423614
Epoch: 34 | Iteration number: [110/4518] 2% | Training loss: 0.6933739255775105
Epoch: 34 | Iteration number: [120/4518] 2% | Training loss: 0.6928132971127828
Epoch: 34 | Iteration number: [130/4518] 2% | Training loss: 0.6923362360550807
Epoch: 34 | Iteration number: [140/4518] 3% | Training loss: 0.6920533529349736
Epoch: 34 | Iteration number: [150/4518] 3% | Training loss: 0.6917374527454376
Epoch: 34 | Iteration number: [160/4518] 3% | Training loss: 0.6913403578102588
Epoch: 34 | Iteration number: [170/4518] 3% | Training loss: 0.6910613165182226
Epoch: 34 | Iteration number: [180/4518] 3% | Training loss: 0.6908090472221374
Epoch: 34 | Iteration number: [190/4518] 4% | Training loss: 0.6905366954050566
Epoch: 34 | Iteration number: [200/4518] 4% | Training loss: 0.6903057900071145
Epoch: 34 | Iteration number: [210/4518] 4% | Training loss: 0.6901264176482246
Epoch: 34 | Iteration number: [220/4518] 4% | Training loss: 0.689966961199587
Epoch: 34 | Iteration number: [230/4518] 5% | Training loss: 0.6898228526115417
Epoch: 34 | Iteration number: [240/4518] 5% | Training loss: 0.6896871514618397
Epoch: 34 | Iteration number: [250/4518] 5% | Training loss: 0.689549259185791
Epoch: 34 | Iteration number: [260/4518] 5% | Training loss: 0.6894487266357129
Epoch: 34 | Iteration number: [270/4518] 5% | Training loss: 0.6893395412851263
Epoch: 34 | Iteration number: [280/4518] 6% | Training loss: 0.689239288015025
Epoch: 34 | Iteration number: [290/4518] 6% | Training loss: 0.6891890065423374
Epoch: 34 | Iteration number: [300/4518] 6% | Training loss: 0.6891045993566514
Epoch: 34 | Iteration number: [310/4518] 6% | Training loss: 0.6890421225178627
Epoch: 34 | Iteration number: [320/4518] 7% | Training loss: 0.6890054080635309
Epoch: 34 | Iteration number: [330/4518] 7% | Training loss: 0.6889557984742252
Epoch: 34 | Iteration number: [340/4518] 7% | Training loss: 0.6888999626916997
Epoch: 34 | Iteration number: [350/4518] 7% | Training loss: 0.6888193775926318
Epoch: 34 | Iteration number: [360/4518] 7% | Training loss: 0.6887735169794824
Epoch: 34 | Iteration number: [370/4518] 8% | Training loss: 0.6887044507103998
Epoch: 34 | Iteration number: [380/4518] 8% | Training loss: 0.688655801980119
Epoch: 34 | Iteration number: [390/4518] 8% | Training loss: 0.6885878679079888
Epoch: 34 | Iteration number: [400/4518] 8% | Training loss: 0.6885189190506935
Epoch: 34 | Iteration number: [410/4518] 9% | Training loss: 0.6884680968959157
Epoch: 34 | Iteration number: [420/4518] 9% | Training loss: 0.6884640272174563
Epoch: 34 | Iteration number: [430/4518] 9% | Training loss: 0.6884030533391375
Epoch: 34 | Iteration number: [440/4518] 9% | Training loss: 0.6883860432288863
Epoch: 34 | Iteration number: [450/4518] 9% | Training loss: 0.6883650514814589
Epoch: 34 | Iteration number: [460/4518] 10% | Training loss: 0.6882987000372098
Epoch: 34 | Iteration number: [470/4518] 10% | Training loss: 0.6882606702916165
Epoch: 34 | Iteration number: [480/4518] 10% | Training loss: 0.6882247270395359
Epoch: 34 | Iteration number: [490/4518] 10% | Training loss: 0.6882254449688658
Epoch: 34 | Iteration number: [500/4518] 11% | Training loss: 0.6881948664188385
Epoch: 34 | Iteration number: [510/4518] 11% | Training loss: 0.6881741416220571
Epoch: 34 | Iteration number: [520/4518] 11% | Training loss: 0.6881652739185553
Epoch: 34 | Iteration number: [530/4518] 11% | Training loss: 0.6881347369472935
Epoch: 34 | Iteration number: [540/4518] 11% | Training loss: 0.6881014217933019
Epoch: 34 | Iteration number: [550/4518] 12% | Training loss: 0.6880700393156571
Epoch: 34 | Iteration number: [560/4518] 12% | Training loss: 0.6880538396537303
Epoch: 34 | Iteration number: [570/4518] 12% | Training loss: 0.6880155617730659
Epoch: 34 | Iteration number: [580/4518] 12% | Training loss: 0.6880056588814176
Epoch: 34 | Iteration number: [590/4518] 13% | Training loss: 0.6879912579463701
Epoch: 34 | Iteration number: [600/4518] 13% | Training loss: 0.6879896965622901
Epoch: 34 | Iteration number: [610/4518] 13% | Training loss: 0.6879716760799534
Epoch: 34 | Iteration number: [620/4518] 13% | Training loss: 0.6879551191483775
Epoch: 34 | Iteration number: [630/4518] 13% | Training loss: 0.6879300030450972
Epoch: 34 | Iteration number: [640/4518] 14% | Training loss: 0.6879144264385104
Epoch: 34 | Iteration number: [650/4518] 14% | Training loss: 0.6879059795232919
Epoch: 34 | Iteration number: [660/4518] 14% | Training loss: 0.6878841715328621
Epoch: 34 | Iteration number: [670/4518] 14% | Training loss: 0.6878474529109784
Epoch: 34 | Iteration number: [680/4518] 15% | Training loss: 0.6878398007329772
Epoch: 34 | Iteration number: [690/4518] 15% | Training loss: 0.6878211656342382
Epoch: 34 | Iteration number: [700/4518] 15% | Training loss: 0.6878038652454104
Epoch: 34 | Iteration number: [710/4518] 15% | Training loss: 0.6878026503072658
Epoch: 34 | Iteration number: [720/4518] 15% | Training loss: 0.6877780176699162
Epoch: 34 | Iteration number: [730/4518] 16% | Training loss: 0.6877634632260832
Epoch: 34 | Iteration number: [740/4518] 16% | Training loss: 0.6877454942948109
Epoch: 34 | Iteration number: [750/4518] 16% | Training loss: 0.6877473592758179
Epoch: 34 | Iteration number: [760/4518] 16% | Training loss: 0.6877373352646827
Epoch: 34 | Iteration number: [770/4518] 17% | Training loss: 0.6877290042189809
Epoch: 34 | Iteration number: [780/4518] 17% | Training loss: 0.6877030674463663
Epoch: 34 | Iteration number: [790/4518] 17% | Training loss: 0.68769121305852
Epoch: 34 | Iteration number: [800/4518] 17% | Training loss: 0.6876800652593374
Epoch: 34 | Iteration number: [810/4518] 17% | Training loss: 0.6876723137166765
Epoch: 34 | Iteration number: [820/4518] 18% | Training loss: 0.6876771496563423
Epoch: 34 | Iteration number: [830/4518] 18% | Training loss: 0.687669830078102
Epoch: 34 | Iteration number: [840/4518] 18% | Training loss: 0.6876583954408055
Epoch: 34 | Iteration number: [850/4518] 18% | Training loss: 0.6876473737464232
Epoch: 34 | Iteration number: [860/4518] 19% | Training loss: 0.6876510286053946
Epoch: 34 | Iteration number: [870/4518] 19% | Training loss: 0.6876387981847785
Epoch: 34 | Iteration number: [880/4518] 19% | Training loss: 0.6876276891339909
Epoch: 34 | Iteration number: [890/4518] 19% | Training loss: 0.6876340162888002
Epoch: 34 | Iteration number: [900/4518] 19% | Training loss: 0.6876232877042558
Epoch: 34 | Iteration number: [910/4518] 20% | Training loss: 0.6875956231421166
Epoch: 34 | Iteration number: [920/4518] 20% | Training loss: 0.6875970741976862
Epoch: 34 | Iteration number: [930/4518] 20% | Training loss: 0.6875953970416899
Epoch: 34 | Iteration number: [940/4518] 20% | Training loss: 0.687588055019683
Epoch: 34 | Iteration number: [950/4518] 21% | Training loss: 0.6875813156680057
Epoch: 34 | Iteration number: [960/4518] 21% | Training loss: 0.6875716552138329
Epoch: 34 | Iteration number: [970/4518] 21% | Training loss: 0.6875492898459287
Epoch: 34 | Iteration number: [980/4518] 21% | Training loss: 0.6875283235189866
Epoch: 34 | Iteration number: [990/4518] 21% | Training loss: 0.6875161502096389
Epoch: 34 | Iteration number: [1000/4518] 22% | Training loss: 0.6875039094686508
Epoch: 34 | Iteration number: [1010/4518] 22% | Training loss: 0.6875075308403166
Epoch: 34 | Iteration number: [1020/4518] 22% | Training loss: 0.687501996697164
Epoch: 34 | Iteration number: [1030/4518] 22% | Training loss: 0.6874971408288456
Epoch: 34 | Iteration number: [1040/4518] 23% | Training loss: 0.6874964542686939
Epoch: 34 | Iteration number: [1050/4518] 23% | Training loss: 0.6874938746861049
Epoch: 34 | Iteration number: [1060/4518] 23% | Training loss: 0.6874929712628418
Epoch: 34 | Iteration number: [1070/4518] 23% | Training loss: 0.6874901323674996
Epoch: 34 | Iteration number: [1080/4518] 23% | Training loss: 0.6874917344914542
Epoch: 34 | Iteration number: [1090/4518] 24% | Training loss: 0.687486722108421
Epoch: 34 | Iteration number: [1100/4518] 24% | Training loss: 0.6874900449947877
Epoch: 34 | Iteration number: [1110/4518] 24% | Training loss: 0.6874756654640576
Epoch: 34 | Iteration number: [1120/4518] 24% | Training loss: 0.6874467428241458
Epoch: 34 | Iteration number: [1130/4518] 25% | Training loss: 0.6874371514911145
Epoch: 34 | Iteration number: [1140/4518] 25% | Training loss: 0.6874306484795454
Epoch: 34 | Iteration number: [1150/4518] 25% | Training loss: 0.6874373079382855
Epoch: 34 | Iteration number: [1160/4518] 25% | Training loss: 0.687421282252361
Epoch: 34 | Iteration number: [1170/4518] 25% | Training loss: 0.687421264913347
Epoch: 34 | Iteration number: [1180/4518] 26% | Training loss: 0.6874193877991983
Epoch: 34 | Iteration number: [1190/4518] 26% | Training loss: 0.6874175955768392
Epoch: 34 | Iteration number: [1200/4518] 26% | Training loss: 0.6874159982303778
Epoch: 34 | Iteration number: [1210/4518] 26% | Training loss: 0.6874191053642714
Epoch: 34 | Iteration number: [1220/4518] 27% | Training loss: 0.6874132676691306
Epoch: 34 | Iteration number: [1230/4518] 27% | Training loss: 0.6874003247032321
Epoch: 34 | Iteration number: [1240/4518] 27% | Training loss: 0.6874014477095296
Epoch: 34 | Iteration number: [1250/4518] 27% | Training loss: 0.6873839390277863
Epoch: 34 | Iteration number: [1260/4518] 27% | Training loss: 0.6873838928010728
Epoch: 34 | Iteration number: [1270/4518] 28% | Training loss: 0.6873725095133143
Epoch: 34 | Iteration number: [1280/4518] 28% | Training loss: 0.6873645006213337
Epoch: 34 | Iteration number: [1290/4518] 28% | Training loss: 0.6873641735823579
Epoch: 34 | Iteration number: [1300/4518] 28% | Training loss: 0.687351678609848
Epoch: 34 | Iteration number: [1310/4518] 28% | Training loss: 0.6873531372947548
Epoch: 34 | Iteration number: [1320/4518] 29% | Training loss: 0.6873636205991109
Epoch: 34 | Iteration number: [1330/4518] 29% | Training loss: 0.6873624360651002
Epoch: 34 | Iteration number: [1340/4518] 29% | Training loss: 0.6873636328462345
Epoch: 34 | Iteration number: [1350/4518] 29% | Training loss: 0.6873609118108396
Epoch: 34 | Iteration number: [1360/4518] 30% | Training loss: 0.6873537682873361
Epoch: 34 | Iteration number: [1370/4518] 30% | Training loss: 0.687353015032998
Epoch: 34 | Iteration number: [1380/4518] 30% | Training loss: 0.687349527987881
Epoch: 34 | Iteration number: [1390/4518] 30% | Training loss: 0.6873477492829878
Epoch: 34 | Iteration number: [1400/4518] 30% | Training loss: 0.6873363001431738
Epoch: 34 | Iteration number: [1410/4518] 31% | Training loss: 0.687331364129452
Epoch: 34 | Iteration number: [1420/4518] 31% | Training loss: 0.6873280371998397
Epoch: 34 | Iteration number: [1430/4518] 31% | Training loss: 0.6873252266353661
Epoch: 34 | Iteration number: [1440/4518] 31% | Training loss: 0.6873156559964021
Epoch: 34 | Iteration number: [1450/4518] 32% | Training loss: 0.6873101509850601
Epoch: 34 | Iteration number: [1460/4518] 32% | Training loss: 0.6873060247669481
Epoch: 34 | Iteration number: [1470/4518] 32% | Training loss: 0.6873051527406082
Epoch: 34 | Iteration number: [1480/4518] 32% | Training loss: 0.6873039022088051
Epoch: 34 | Iteration number: [1490/4518] 32% | Training loss: 0.6873037871898421
Epoch: 34 | Iteration number: [1500/4518] 33% | Training loss: 0.6872959812879562
Epoch: 34 | Iteration number: [1510/4518] 33% | Training loss: 0.6872888182567445
Epoch: 34 | Iteration number: [1520/4518] 33% | Training loss: 0.6872828976104134
Epoch: 34 | Iteration number: [1530/4518] 33% | Training loss: 0.6872767264157339
Epoch: 34 | Iteration number: [1540/4518] 34% | Training loss: 0.6872670626872546
Epoch: 34 | Iteration number: [1550/4518] 34% | Training loss: 0.6872619510081507
Epoch: 34 | Iteration number: [1560/4518] 34% | Training loss: 0.6872586868130244
Epoch: 34 | Iteration number: [1570/4518] 34% | Training loss: 0.6872573103874352
Epoch: 34 | Iteration number: [1580/4518] 34% | Training loss: 0.6872583896676197
Epoch: 34 | Iteration number: [1590/4518] 35% | Training loss: 0.6872556470849979
Epoch: 34 | Iteration number: [1600/4518] 35% | Training loss: 0.68725570846349
Epoch: 34 | Iteration number: [1610/4518] 35% | Training loss: 0.6872611258711133
Epoch: 34 | Iteration number: [1620/4518] 35% | Training loss: 0.687256607118948
Epoch: 34 | Iteration number: [1630/4518] 36% | Training loss: 0.6872504589747798
Epoch: 34 | Iteration number: [1640/4518] 36% | Training loss: 0.6872380939198703
Epoch: 34 | Iteration number: [1650/4518] 36% | Training loss: 0.6872348556012818
Epoch: 34 | Iteration number: [1660/4518] 36% | Training loss: 0.6872350507112871
Epoch: 34 | Iteration number: [1670/4518] 36% | Training loss: 0.6872308852429876
Epoch: 34 | Iteration number: [1680/4518] 37% | Training loss: 0.6872255194045248
Epoch: 34 | Iteration number: [1690/4518] 37% | Training loss: 0.6872278197277227
Epoch: 34 | Iteration number: [1700/4518] 37% | Training loss: 0.6872287585805444
Epoch: 34 | Iteration number: [1710/4518] 37% | Training loss: 0.6872234591615131
Epoch: 34 | Iteration number: [1720/4518] 38% | Training loss: 0.6872215006933656
Epoch: 34 | Iteration number: [1730/4518] 38% | Training loss: 0.6872223163271226
Epoch: 34 | Iteration number: [1740/4518] 38% | Training loss: 0.6872217978211655
Epoch: 34 | Iteration number: [1750/4518] 38% | Training loss: 0.6872225058419363
Epoch: 34 | Iteration number: [1760/4518] 38% | Training loss: 0.6872228400612419
Epoch: 34 | Iteration number: [1770/4518] 39% | Training loss: 0.6872191243252512
Epoch: 34 | Iteration number: [1780/4518] 39% | Training loss: 0.6872143089771271
Epoch: 34 | Iteration number: [1790/4518] 39% | Training loss: 0.687209046453071
Epoch: 34 | Iteration number: [1800/4518] 39% | Training loss: 0.6872086771329244
Epoch: 34 | Iteration number: [1810/4518] 40% | Training loss: 0.6872055460076306
Epoch: 34 | Iteration number: [1820/4518] 40% | Training loss: 0.6872035415945472
Epoch: 34 | Iteration number: [1830/4518] 40% | Training loss: 0.6872043908293781
Epoch: 34 | Iteration number: [1840/4518] 40% | Training loss: 0.6872030582440936
Epoch: 34 | Iteration number: [1850/4518] 40% | Training loss: 0.6872023447139843
Epoch: 34 | Iteration number: [1860/4518] 41% | Training loss: 0.6871977738795741
Epoch: 34 | Iteration number: [1870/4518] 41% | Training loss: 0.6871986940264064
Epoch: 34 | Iteration number: [1880/4518] 41% | Training loss: 0.6871974435258419
Epoch: 34 | Iteration number: [1890/4518] 41% | Training loss: 0.6871971515120653
Epoch: 34 | Iteration number: [1900/4518] 42% | Training loss: 0.687196899432885
Epoch: 34 | Iteration number: [1910/4518] 42% | Training loss: 0.687194751569738
Epoch: 34 | Iteration number: [1920/4518] 42% | Training loss: 0.6871925207786262
Epoch: 34 | Iteration number: [1930/4518] 42% | Training loss: 0.6871963111230128
Epoch: 34 | Iteration number: [1940/4518] 42% | Training loss: 0.6871942256836547
Epoch: 34 | Iteration number: [1950/4518] 43% | Training loss: 0.6871932039505396
Epoch: 34 | Iteration number: [1960/4518] 43% | Training loss: 0.6871907943365525
Epoch: 34 | Iteration number: [1970/4518] 43% | Training loss: 0.687192203096932
Epoch: 34 | Iteration number: [1980/4518] 43% | Training loss: 0.6871883039221619
Epoch: 34 | Iteration number: [1990/4518] 44% | Training loss: 0.6871863506846692
Epoch: 34 | Iteration number: [2000/4518] 44% | Training loss: 0.6871798192262649
Epoch: 34 | Iteration number: [2010/4518] 44% | Training loss: 0.6871799471366464
Epoch: 34 | Iteration number: [2020/4518] 44% | Training loss: 0.6871758696466389
Epoch: 34 | Iteration number: [2030/4518] 44% | Training loss: 0.6871767446912568
Epoch: 34 | Iteration number: [2040/4518] 45% | Training loss: 0.6871813942988714
Epoch: 34 | Iteration number: [2050/4518] 45% | Training loss: 0.687185187630537
Epoch: 34 | Iteration number: [2060/4518] 45% | Training loss: 0.6871774336088051
Epoch: 34 | Iteration number: [2070/4518] 45% | Training loss: 0.6871759186620298
Epoch: 34 | Iteration number: [2080/4518] 46% | Training loss: 0.6871801703881759
Epoch: 34 | Iteration number: [2090/4518] 46% | Training loss: 0.6871753770768928
Epoch: 34 | Iteration number: [2100/4518] 46% | Training loss: 0.687173491744768
Epoch: 34 | Iteration number: [2110/4518] 46% | Training loss: 0.6871676919867077
Epoch: 34 | Iteration number: [2120/4518] 46% | Training loss: 0.6871671511036045
Epoch: 34 | Iteration number: [2130/4518] 47% | Training loss: 0.687165049208162
Epoch: 34 | Iteration number: [2140/4518] 47% | Training loss: 0.687164111421487
Epoch: 34 | Iteration number: [2150/4518] 47% | Training loss: 0.6871602893707364
Epoch: 34 | Iteration number: [2160/4518] 47% | Training loss: 0.6871631949588105
Epoch: 34 | Iteration number: [2170/4518] 48% | Training loss: 0.6871571082123963
Epoch: 34 | Iteration number: [2180/4518] 48% | Training loss: 0.6871562689816186
Epoch: 34 | Iteration number: [2190/4518] 48% | Training loss: 0.6871587649327979
Epoch: 34 | Iteration number: [2200/4518] 48% | Training loss: 0.6871588462591172
Epoch: 34 | Iteration number: [2210/4518] 48% | Training loss: 0.6871529285454642
Epoch: 34 | Iteration number: [2220/4518] 49% | Training loss: 0.6871532584095861
Epoch: 34 | Iteration number: [2230/4518] 49% | Training loss: 0.6871525843314525
Epoch: 34 | Iteration number: [2240/4518] 49% | Training loss: 0.6871507903294903
Epoch: 34 | Iteration number: [2250/4518] 49% | Training loss: 0.6871452458964454
Epoch: 34 | Iteration number: [2260/4518] 50% | Training loss: 0.6871382353580103
Epoch: 34 | Iteration number: [2270/4518] 50% | Training loss: 0.687138911989817
Epoch: 34 | Iteration number: [2280/4518] 50% | Training loss: 0.687138944184571
Epoch: 34 | Iteration number: [2290/4518] 50% | Training loss: 0.6871370853815537
Epoch: 34 | Iteration number: [2300/4518] 50% | Training loss: 0.6871372861447541
Epoch: 34 | Iteration number: [2310/4518] 51% | Training loss: 0.6871291068983284
Epoch: 34 | Iteration number: [2320/4518] 51% | Training loss: 0.6871287890292447
Epoch: 34 | Iteration number: [2330/4518] 51% | Training loss: 0.6871221463567709
Epoch: 34 | Iteration number: [2340/4518] 51% | Training loss: 0.6871197543592534
Epoch: 34 | Iteration number: [2350/4518] 52% | Training loss: 0.6871173439888244
Epoch: 34 | Iteration number: [2360/4518] 52% | Training loss: 0.6871177548069065
Epoch: 34 | Iteration number: [2370/4518] 52% | Training loss: 0.6871218207767744
Epoch: 34 | Iteration number: [2380/4518] 52% | Training loss: 0.6871228034506325
Epoch: 34 | Iteration number: [2390/4518] 52% | Training loss: 0.6871184224862933
Epoch: 34 | Iteration number: [2400/4518] 53% | Training loss: 0.6871205080548922
Epoch: 34 | Iteration number: [2410/4518] 53% | Training loss: 0.6871213051046079
Epoch: 34 | Iteration number: [2420/4518] 53% | Training loss: 0.6871222368449219
Epoch: 34 | Iteration number: [2430/4518] 53% | Training loss: 0.6871223183571066
Epoch: 34 | Iteration number: [2440/4518] 54% | Training loss: 0.6871165198869392
Epoch: 34 | Iteration number: [2450/4518] 54% | Training loss: 0.6871173006904369
Epoch: 34 | Iteration number: [2460/4518] 54% | Training loss: 0.6871198397584077
Epoch: 34 | Iteration number: [2470/4518] 54% | Training loss: 0.6871195269017084
Epoch: 34 | Iteration number: [2480/4518] 54% | Training loss: 0.6871149822348549
Epoch: 34 | Iteration number: [2490/4518] 55% | Training loss: 0.687110713016556
Epoch: 34 | Iteration number: [2500/4518] 55% | Training loss: 0.6871172056436539
Epoch: 34 | Iteration number: [2510/4518] 55% | Training loss: 0.6871203926454977
Epoch: 34 | Iteration number: [2520/4518] 55% | Training loss: 0.6871195087593699
Epoch: 34 | Iteration number: [2530/4518] 55% | Training loss: 0.6871161953262661
Epoch: 34 | Iteration number: [2540/4518] 56% | Training loss: 0.6871144329469036
Epoch: 34 | Iteration number: [2550/4518] 56% | Training loss: 0.6871177293272579
Epoch: 34 | Iteration number: [2560/4518] 56% | Training loss: 0.6871187920682132
Epoch: 34 | Iteration number: [2570/4518] 56% | Training loss: 0.6871104133732124
Epoch: 34 | Iteration number: [2580/4518] 57% | Training loss: 0.6871081984551378
Epoch: 34 | Iteration number: [2590/4518] 57% | Training loss: 0.6871059249957095
Epoch: 34 | Iteration number: [2600/4518] 57% | Training loss: 0.6870988211035729
Epoch: 34 | Iteration number: [2610/4518] 57% | Training loss: 0.687100204197383
Epoch: 34 | Iteration number: [2620/4518] 57% | Training loss: 0.6870961491388219
Epoch: 34 | Iteration number: [2630/4518] 58% | Training loss: 0.6870951488444107
Epoch: 34 | Iteration number: [2640/4518] 58% | Training loss: 0.6870982407168909
Epoch: 34 | Iteration number: [2650/4518] 58% | Training loss: 0.6870987705464633
Epoch: 34 | Iteration number: [2660/4518] 58% | Training loss: 0.6870985779547154
Epoch: 34 | Iteration number: [2670/4518] 59% | Training loss: 0.6870912278189641
Epoch: 34 | Iteration number: [2680/4518] 59% | Training loss: 0.6870927413008107
Epoch: 34 | Iteration number: [2690/4518] 59% | Training loss: 0.6870925851914076
Epoch: 34 | Iteration number: [2700/4518] 59% | Training loss: 0.6870906839105818
Epoch: 34 | Iteration number: [2710/4518] 59% | Training loss: 0.6870890582179672
Epoch: 34 | Iteration number: [2720/4518] 60% | Training loss: 0.6870881430585595
Epoch: 34 | Iteration number: [2730/4518] 60% | Training loss: 0.6870902552709475
Epoch: 34 | Iteration number: [2740/4518] 60% | Training loss: 0.6870915607596836
Epoch: 34 | Iteration number: [2750/4518] 60% | Training loss: 0.6870912552963604
Epoch: 34 | Iteration number: [2760/4518] 61% | Training loss: 0.6870943368345067
Epoch: 34 | Iteration number: [2770/4518] 61% | Training loss: 0.6870890168076388
Epoch: 34 | Iteration number: [2780/4518] 61% | Training loss: 0.6870894308999288
Epoch: 34 | Iteration number: [2790/4518] 61% | Training loss: 0.687089013775617
Epoch: 34 | Iteration number: [2800/4518] 61% | Training loss: 0.6870860110223294
Epoch: 34 | Iteration number: [2810/4518] 62% | Training loss: 0.6870884536636257
Epoch: 34 | Iteration number: [2820/4518] 62% | Training loss: 0.6870939303163096
Epoch: 34 | Iteration number: [2830/4518] 62% | Training loss: 0.687097801799909
Epoch: 34 | Iteration number: [2840/4518] 62% | Training loss: 0.6870958554073119
Epoch: 34 | Iteration number: [2850/4518] 63% | Training loss: 0.6870931409534655
Epoch: 34 | Iteration number: [2860/4518] 63% | Training loss: 0.6870937653771647
Epoch: 34 | Iteration number: [2870/4518] 63% | Training loss: 0.6870856444594752
Epoch: 34 | Iteration number: [2880/4518] 63% | Training loss: 0.6870844576300846
Epoch: 34 | Iteration number: [2890/4518] 63% | Training loss: 0.6870822853076829
Epoch: 34 | Iteration number: [2900/4518] 64% | Training loss: 0.6870832949876785
Epoch: 34 | Iteration number: [2910/4518] 64% | Training loss: 0.6870847122161249
Epoch: 34 | Iteration number: [2920/4518] 64% | Training loss: 0.6870841004872975
Epoch: 34 | Iteration number: [2930/4518] 64% | Training loss: 0.6870792961568148
Epoch: 34 | Iteration number: [2940/4518] 65% | Training loss: 0.6870772887452119
Epoch: 34 | Iteration number: [2950/4518] 65% | Training loss: 0.6870776084722099
Epoch: 34 | Iteration number: [2960/4518] 65% | Training loss: 0.6870821343885886
Epoch: 34 | Iteration number: [2970/4518] 65% | Training loss: 0.6870769657069183
Epoch: 34 | Iteration number: [2980/4518] 65% | Training loss: 0.6870738499716624
Epoch: 34 | Iteration number: [2990/4518] 66% | Training loss: 0.6870672260638463
Epoch: 34 | Iteration number: [3000/4518] 66% | Training loss: 0.6870639638304711
Epoch: 34 | Iteration number: [3010/4518] 66% | Training loss: 0.6870615733422314
Epoch: 34 | Iteration number: [3020/4518] 66% | Training loss: 0.6870582954575684
Epoch: 34 | Iteration number: [3030/4518] 67% | Training loss: 0.6870552201082211
Epoch: 34 | Iteration number: [3040/4518] 67% | Training loss: 0.6870576966946063
Epoch: 34 | Iteration number: [3050/4518] 67% | Training loss: 0.6870600246601417
Epoch: 34 | Iteration number: [3060/4518] 67% | Training loss: 0.6870588102956223
Epoch: 34 | Iteration number: [3070/4518] 67% | Training loss: 0.6870613716518452
Epoch: 34 | Iteration number: [3080/4518] 68% | Training loss: 0.6870606668583759
Epoch: 34 | Iteration number: [3090/4518] 68% | Training loss: 0.6870574840064188
Epoch: 34 | Iteration number: [3100/4518] 68% | Training loss: 0.6870554174723164
Epoch: 34 | Iteration number: [3110/4518] 68% | Training loss: 0.6870562499742416
Epoch: 34 | Iteration number: [3120/4518] 69% | Training loss: 0.6870538109770188
Epoch: 34 | Iteration number: [3130/4518] 69% | Training loss: 0.6870523004295727
Epoch: 34 | Iteration number: [3140/4518] 69% | Training loss: 0.6870504867309218
Epoch: 34 | Iteration number: [3150/4518] 69% | Training loss: 0.6870491658127497
Epoch: 34 | Iteration number: [3160/4518] 69% | Training loss: 0.6870522344036948
Epoch: 34 | Iteration number: [3170/4518] 70% | Training loss: 0.6870511039010357
Epoch: 34 | Iteration number: [3180/4518] 70% | Training loss: 0.6870500673288069
Epoch: 34 | Iteration number: [3190/4518] 70% | Training loss: 0.6870445599189746
Epoch: 34 | Iteration number: [3200/4518] 70% | Training loss: 0.6870412577502429
Epoch: 34 | Iteration number: [3210/4518] 71% | Training loss: 0.6870399990371454
Epoch: 34 | Iteration number: [3220/4518] 71% | Training loss: 0.687034005352429
Epoch: 34 | Iteration number: [3230/4518] 71% | Training loss: 0.6870329702601713
Epoch: 34 | Iteration number: [3240/4518] 71% | Training loss: 0.6870338391558624
Epoch: 34 | Iteration number: [3250/4518] 71% | Training loss: 0.6870364927145151
Epoch: 34 | Iteration number: [3260/4518] 72% | Training loss: 0.687035207294979
Epoch: 34 | Iteration number: [3270/4518] 72% | Training loss: 0.687035155150504
Epoch: 34 | Iteration number: [3280/4518] 72% | Training loss: 0.6870362313600575
Epoch: 34 | Iteration number: [3290/4518] 72% | Training loss: 0.6870362514239314
Epoch: 34 | Iteration number: [3300/4518] 73% | Training loss: 0.6870369413946614
Epoch: 34 | Iteration number: [3310/4518] 73% | Training loss: 0.6870393812836477
Epoch: 34 | Iteration number: [3320/4518] 73% | Training loss: 0.6870374980461167
Epoch: 34 | Iteration number: [3330/4518] 73% | Training loss: 0.6870392554873103
Epoch: 34 | Iteration number: [3340/4518] 73% | Training loss: 0.6870374400637107
Epoch: 34 | Iteration number: [3350/4518] 74% | Training loss: 0.6870388002537969
Epoch: 34 | Iteration number: [3360/4518] 74% | Training loss: 0.6870390217928659
Epoch: 34 | Iteration number: [3370/4518] 74% | Training loss: 0.6870401200271855
Epoch: 34 | Iteration number: [3380/4518] 74% | Training loss: 0.6870364067822519
Epoch: 34 | Iteration number: [3390/4518] 75% | Training loss: 0.6870332205014242
Epoch: 34 | Iteration number: [3400/4518] 75% | Training loss: 0.6870318726055762
Epoch: 34 | Iteration number: [3410/4518] 75% | Training loss: 0.6870345156038961
Epoch: 34 | Iteration number: [3420/4518] 75% | Training loss: 0.6870346044762092
Epoch: 34 | Iteration number: [3430/4518] 75% | Training loss: 0.6870346380218473
Epoch: 34 | Iteration number: [3440/4518] 76% | Training loss: 0.6870351549151332
Epoch: 34 | Iteration number: [3450/4518] 76% | Training loss: 0.6870373748696369
Epoch: 34 | Iteration number: [3460/4518] 76% | Training loss: 0.6870371376847946
Epoch: 34 | Iteration number: [3470/4518] 76% | Training loss: 0.6870395989857764
Epoch: 34 | Iteration number: [3480/4518] 77% | Training loss: 0.6870389110226741
Epoch: 34 | Iteration number: [3490/4518] 77% | Training loss: 0.687037963153298
Epoch: 34 | Iteration number: [3500/4518] 77% | Training loss: 0.6870383158240999
Epoch: 34 | Iteration number: [3510/4518] 77% | Training loss: 0.6870348185385734
Epoch: 34 | Iteration number: [3520/4518] 77% | Training loss: 0.6870314681563865
Epoch: 34 | Iteration number: [3530/4518] 78% | Training loss: 0.6870338549695001
Epoch: 34 | Iteration number: [3540/4518] 78% | Training loss: 0.6870352384902663
Epoch: 34 | Iteration number: [3550/4518] 78% | Training loss: 0.6870338662241546
Epoch: 34 | Iteration number: [3560/4518] 78% | Training loss: 0.6870351384529907
Epoch: 34 | Iteration number: [3570/4518] 79% | Training loss: 0.6870322450703266
Epoch: 34 | Iteration number: [3580/4518] 79% | Training loss: 0.6870290879430717
Epoch: 34 | Iteration number: [3590/4518] 79% | Training loss: 0.6870257229526063
Epoch: 34 | Iteration number: [3600/4518] 79% | Training loss: 0.6870251888699002
Epoch: 34 | Iteration number: [3610/4518] 79% | Training loss: 0.6870243043780657
Epoch: 34 | Iteration number: [3620/4518] 80% | Training loss: 0.6870224362084879
Epoch: 34 | Iteration number: [3630/4518] 80% | Training loss: 0.687022204487777
Epoch: 34 | Iteration number: [3640/4518] 80% | Training loss: 0.6870254402304744
Epoch: 34 | Iteration number: [3650/4518] 80% | Training loss: 0.6870247402909684
Epoch: 34 | Iteration number: [3660/4518] 81% | Training loss: 0.6870235322440257
Epoch: 34 | Iteration number: [3670/4518] 81% | Training loss: 0.6870220346087006
Epoch: 34 | Iteration number: [3680/4518] 81% | Training loss: 0.6870236560702324
Epoch: 34 | Iteration number: [3690/4518] 81% | Training loss: 0.6870259643893255
Epoch: 34 | Iteration number: [3700/4518] 81% | Training loss: 0.6870260233331371
Epoch: 34 | Iteration number: [3710/4518] 82% | Training loss: 0.6870255998042073
Epoch: 34 | Iteration number: [3720/4518] 82% | Training loss: 0.6870259173775232
Epoch: 34 | Iteration number: [3730/4518] 82% | Training loss: 0.6870260614652097
Epoch: 34 | Iteration number: [3740/4518] 82% | Training loss: 0.6870240860284968
Epoch: 34 | Iteration number: [3750/4518] 83% | Training loss: 0.6870222619374593
Epoch: 34 | Iteration number: [3760/4518] 83% | Training loss: 0.6870198589690188
Epoch: 34 | Iteration number: [3770/4518] 83% | Training loss: 0.6870205442848509
Epoch: 34 | Iteration number: [3780/4518] 83% | Training loss: 0.6870243781615817
Epoch: 34 | Iteration number: [3790/4518] 83% | Training loss: 0.6870204779592227
Epoch: 34 | Iteration number: [3800/4518] 84% | Training loss: 0.6870202571781058
Epoch: 34 | Iteration number: [3810/4518] 84% | Training loss: 0.6870189166288051
Epoch: 34 | Iteration number: [3820/4518] 84% | Training loss: 0.6870177294571362
Epoch: 34 | Iteration number: [3830/4518] 84% | Training loss: 0.6870154194981248
Epoch: 34 | Iteration number: [3840/4518] 84% | Training loss: 0.687013267694662
Epoch: 34 | Iteration number: [3850/4518] 85% | Training loss: 0.6870109888795134
Epoch: 34 | Iteration number: [3860/4518] 85% | Training loss: 0.687012676238396
Epoch: 34 | Iteration number: [3870/4518] 85% | Training loss: 0.6870125158658631
Epoch: 34 | Iteration number: [3880/4518] 85% | Training loss: 0.6870105477030745
Epoch: 34 | Iteration number: [3890/4518] 86% | Training loss: 0.6870091356317918
Epoch: 34 | Iteration number: [3900/4518] 86% | Training loss: 0.6870094107970214
Epoch: 34 | Iteration number: [3910/4518] 86% | Training loss: 0.6870132427081428
Epoch: 34 | Iteration number: [3920/4518] 86% | Training loss: 0.6870128807820836
Epoch: 34 | Iteration number: [3930/4518] 86% | Training loss: 0.687008620764463
Epoch: 34 | Iteration number: [3940/4518] 87% | Training loss: 0.6870078019230499
Epoch: 34 | Iteration number: [3950/4518] 87% | Training loss: 0.6870072742655308
Epoch: 34 | Iteration number: [3960/4518] 87% | Training loss: 0.6870065288561763
Epoch: 34 | Iteration number: [3970/4518] 87% | Training loss: 0.6870061023859894
Epoch: 34 | Iteration number: [3980/4518] 88% | Training loss: 0.6870078025750779
Epoch: 34 | Iteration number: [3990/4518] 88% | Training loss: 0.6870088933255141
Epoch: 34 | Iteration number: [4000/4518] 88% | Training loss: 0.6870092754513025
Epoch: 34 | Iteration number: [4010/4518] 88% | Training loss: 0.6870121140729757
Epoch: 34 | Iteration number: [4020/4518] 88% | Training loss: 0.6870116138636176
Epoch: 34 | Iteration number: [4030/4518] 89% | Training loss: 0.6870126450623827
Epoch: 34 | Iteration number: [4040/4518] 89% | Training loss: 0.6870149584099798
Epoch: 34 | Iteration number: [4050/4518] 89% | Training loss: 0.6870126280814042
Epoch: 34 | Iteration number: [4060/4518] 89% | Training loss: 0.6870113718392227
Epoch: 34 | Iteration number: [4070/4518] 90% | Training loss: 0.6870101777575819
Epoch: 34 | Iteration number: [4080/4518] 90% | Training loss: 0.6870105859841786
Epoch: 34 | Iteration number: [4090/4518] 90% | Training loss: 0.6870110547484279
Epoch: 34 | Iteration number: [4100/4518] 90% | Training loss: 0.6870093115364633
Epoch: 34 | Iteration number: [4110/4518] 90% | Training loss: 0.6870104134227818
Epoch: 34 | Iteration number: [4120/4518] 91% | Training loss: 0.687010580228949
Epoch: 34 | Iteration number: [4130/4518] 91% | Training loss: 0.687011594691519
Epoch: 34 | Iteration number: [4140/4518] 91% | Training loss: 0.6870111889165381
Epoch: 34 | Iteration number: [4150/4518] 91% | Training loss: 0.687009639912341
Epoch: 34 | Iteration number: [4160/4518] 92% | Training loss: 0.6870096728205681
Epoch: 34 | Iteration number: [4170/4518] 92% | Training loss: 0.6870107010828791
Epoch: 34 | Iteration number: [4180/4518] 92% | Training loss: 0.6870126241987402
Epoch: 34 | Iteration number: [4190/4518] 92% | Training loss: 0.6870129655539847
Epoch: 34 | Iteration number: [4200/4518] 92% | Training loss: 0.6870154612688791
Epoch: 34 | Iteration number: [4210/4518] 93% | Training loss: 0.6870123151928682
Epoch: 34 | Iteration number: [4220/4518] 93% | Training loss: 0.6870128459981267
Epoch: 34 | Iteration number: [4230/4518] 93% | Training loss: 0.6870081649745328
Epoch: 34 | Iteration number: [4240/4518] 93% | Training loss: 0.6870080642683326
Epoch: 34 | Iteration number: [4250/4518] 94% | Training loss: 0.6870077167959774
Epoch: 34 | Iteration number: [4260/4518] 94% | Training loss: 0.6870064435990204
Epoch: 34 | Iteration number: [4270/4518] 94% | Training loss: 0.6870071168526554
Epoch: 34 | Iteration number: [4280/4518] 94% | Training loss: 0.6870052267736364
Epoch: 34 | Iteration number: [4290/4518] 94% | Training loss: 0.6870049112326615
Epoch: 34 | Iteration number: [4300/4518] 95% | Training loss: 0.6870040256616681
Epoch: 34 | Iteration number: [4310/4518] 95% | Training loss: 0.687002214353765
Epoch: 34 | Iteration number: [4320/4518] 95% | Training loss: 0.6870026280206663
Epoch: 34 | Iteration number: [4330/4518] 95% | Training loss: 0.6870022456447742
Epoch: 34 | Iteration number: [4340/4518] 96% | Training loss: 0.6870039462905875
Epoch: 34 | Iteration number: [4350/4518] 96% | Training loss: 0.6870049637898632
Epoch: 34 | Iteration number: [4360/4518] 96% | Training loss: 0.6870040238860551
Epoch: 34 | Iteration number: [4370/4518] 96% | Training loss: 0.6870050688220926
Epoch: 34 | Iteration number: [4380/4518] 96% | Training loss: 0.6870028470340929
Epoch: 34 | Iteration number: [4390/4518] 97% | Training loss: 0.6870028573722665
Epoch: 34 | Iteration number: [4400/4518] 97% | Training loss: 0.6870067024501887
Epoch: 34 | Iteration number: [4410/4518] 97% | Training loss: 0.6870028394149815
Epoch: 34 | Iteration number: [4420/4518] 97% | Training loss: 0.6870030393562705
Epoch: 34 | Iteration number: [4430/4518] 98% | Training loss: 0.6870014956115869
Epoch: 34 | Iteration number: [4440/4518] 98% | Training loss: 0.6870046464038325
Epoch: 34 | Iteration number: [4450/4518] 98% | Training loss: 0.6870027216230885
Epoch: 34 | Iteration number: [4460/4518] 98% | Training loss: 0.6870010921506069
Epoch: 34 | Iteration number: [4470/4518] 98% | Training loss: 0.6869994949307751
Epoch: 34 | Iteration number: [4480/4518] 99% | Training loss: 0.6870014237506049
Epoch: 34 | Iteration number: [4490/4518] 99% | Training loss: 0.6870012436518425
Epoch: 34 | Iteration number: [4500/4518] 99% | Training loss: 0.6870020731555091
Epoch: 34 | Iteration number: [4510/4518] 99% | Training loss: 0.6870017208571974

 End of epoch: 34 | Train Loss: 0.6868494775190771 | Training Time: 640 

 End of epoch: 34 | Eval Loss: 0.6900784032685416 | Evaluating Time: 17 
Epoch: 35 | Iteration number: [10/4518] 0% | Training loss: 0.7551591336727143
Epoch: 35 | Iteration number: [20/4518] 0% | Training loss: 0.7212851911783218
Epoch: 35 | Iteration number: [30/4518] 0% | Training loss: 0.7095864494641622
Epoch: 35 | Iteration number: [40/4518] 0% | Training loss: 0.7039526656270028
Epoch: 35 | Iteration number: [50/4518] 1% | Training loss: 0.7004617714881897
Epoch: 35 | Iteration number: [60/4518] 1% | Training loss: 0.6983944594860076
Epoch: 35 | Iteration number: [70/4518] 1% | Training loss: 0.6967919375215258
Epoch: 35 | Iteration number: [80/4518] 1% | Training loss: 0.6954708218574523
Epoch: 35 | Iteration number: [90/4518] 1% | Training loss: 0.6945304526223077
Epoch: 35 | Iteration number: [100/4518] 2% | Training loss: 0.6937854743003845
Epoch: 35 | Iteration number: [110/4518] 2% | Training loss: 0.6931420521302657
Epoch: 35 | Iteration number: [120/4518] 2% | Training loss: 0.6926085030039152
Epoch: 35 | Iteration number: [130/4518] 2% | Training loss: 0.6921994236799387
Epoch: 35 | Iteration number: [140/4518] 3% | Training loss: 0.6917998599154609
Epoch: 35 | Iteration number: [150/4518] 3% | Training loss: 0.6914436332384746
Epoch: 35 | Iteration number: [160/4518] 3% | Training loss: 0.6912005063146353
Epoch: 35 | Iteration number: [170/4518] 3% | Training loss: 0.6910310496302212
Epoch: 35 | Iteration number: [180/4518] 3% | Training loss: 0.6908297237422731
Epoch: 35 | Iteration number: [190/4518] 4% | Training loss: 0.6906299136186901
Epoch: 35 | Iteration number: [200/4518] 4% | Training loss: 0.6904455351829529
Epoch: 35 | Iteration number: [210/4518] 4% | Training loss: 0.6903454970745814
Epoch: 35 | Iteration number: [220/4518] 4% | Training loss: 0.6901069830764424
Epoch: 35 | Iteration number: [230/4518] 5% | Training loss: 0.6900344799394192
Epoch: 35 | Iteration number: [240/4518] 5% | Training loss: 0.6899723432958126
Epoch: 35 | Iteration number: [250/4518] 5% | Training loss: 0.6898795990943909
Epoch: 35 | Iteration number: [260/4518] 5% | Training loss: 0.6898017321641629
Epoch: 35 | Iteration number: [270/4518] 5% | Training loss: 0.6896377980709076
Epoch: 35 | Iteration number: [280/4518] 6% | Training loss: 0.6895083953227316
Epoch: 35 | Iteration number: [290/4518] 6% | Training loss: 0.6894223373511742
Epoch: 35 | Iteration number: [300/4518] 6% | Training loss: 0.6893340669075648
Epoch: 35 | Iteration number: [310/4518] 6% | Training loss: 0.6892359368262753
Epoch: 35 | Iteration number: [320/4518] 7% | Training loss: 0.6891211792826653
Epoch: 35 | Iteration number: [330/4518] 7% | Training loss: 0.6891005750858422
Epoch: 35 | Iteration number: [340/4518] 7% | Training loss: 0.6890189014813479
Epoch: 35 | Iteration number: [350/4518] 7% | Training loss: 0.6889569452830724
Epoch: 35 | Iteration number: [360/4518] 7% | Training loss: 0.6888763914505641
Epoch: 35 | Iteration number: [370/4518] 8% | Training loss: 0.6888047045952564
Epoch: 35 | Iteration number: [380/4518] 8% | Training loss: 0.6887557412448683
Epoch: 35 | Iteration number: [390/4518] 8% | Training loss: 0.6887476086616516
Epoch: 35 | Iteration number: [400/4518] 8% | Training loss: 0.6887278445065022
Epoch: 35 | Iteration number: [410/4518] 9% | Training loss: 0.688691114216316
Epoch: 35 | Iteration number: [420/4518] 9% | Training loss: 0.6886370894454774
Epoch: 35 | Iteration number: [430/4518] 9% | Training loss: 0.6886057547358579
Epoch: 35 | Iteration number: [440/4518] 9% | Training loss: 0.6885639430447058
Epoch: 35 | Iteration number: [450/4518] 9% | Training loss: 0.6885232840643989
Epoch: 35 | Iteration number: [460/4518] 10% | Training loss: 0.6884761788274931
Epoch: 35 | Iteration number: [470/4518] 10% | Training loss: 0.6884292526448027
Epoch: 35 | Iteration number: [480/4518] 10% | Training loss: 0.6883849299202363
Epoch: 35 | Iteration number: [490/4518] 10% | Training loss: 0.6883475185657034
Epoch: 35 | Iteration number: [500/4518] 11% | Training loss: 0.6883290777206421
Epoch: 35 | Iteration number: [510/4518] 11% | Training loss: 0.6882971159383362
Epoch: 35 | Iteration number: [520/4518] 11% | Training loss: 0.6882525166639915
Epoch: 35 | Iteration number: [530/4518] 11% | Training loss: 0.688219853729572
Epoch: 35 | Iteration number: [540/4518] 11% | Training loss: 0.6882031174721541
Epoch: 35 | Iteration number: [550/4518] 12% | Training loss: 0.688173965215683
Epoch: 35 | Iteration number: [560/4518] 12% | Training loss: 0.6881296825196062
Epoch: 35 | Iteration number: [570/4518] 12% | Training loss: 0.6881091391831113
Epoch: 35 | Iteration number: [580/4518] 12% | Training loss: 0.688092011932669
Epoch: 35 | Iteration number: [590/4518] 13% | Training loss: 0.688067484205052
Epoch: 35 | Iteration number: [600/4518] 13% | Training loss: 0.6880489826202393
Epoch: 35 | Iteration number: [610/4518] 13% | Training loss: 0.6880282563264253
Epoch: 35 | Iteration number: [620/4518] 13% | Training loss: 0.688015206879185
Epoch: 35 | Iteration number: [630/4518] 13% | Training loss: 0.6880170410587674
Epoch: 35 | Iteration number: [640/4518] 14% | Training loss: 0.68798534180969
Epoch: 35 | Iteration number: [650/4518] 14% | Training loss: 0.687976076052739
Epoch: 35 | Iteration number: [660/4518] 14% | Training loss: 0.6879641389304941
Epoch: 35 | Iteration number: [670/4518] 14% | Training loss: 0.6879560379839655
Epoch: 35 | Iteration number: [680/4518] 15% | Training loss: 0.687937063417014
Epoch: 35 | Iteration number: [690/4518] 15% | Training loss: 0.687922818073328
Epoch: 35 | Iteration number: [700/4518] 15% | Training loss: 0.6879041859933308
Epoch: 35 | Iteration number: [710/4518] 15% | Training loss: 0.68787991656384
Epoch: 35 | Iteration number: [720/4518] 15% | Training loss: 0.6878683918880092
Epoch: 35 | Iteration number: [730/4518] 16% | Training loss: 0.6878572286808328
Epoch: 35 | Iteration number: [740/4518] 16% | Training loss: 0.687839288808204
Epoch: 35 | Iteration number: [750/4518] 16% | Training loss: 0.6878259742259979
Epoch: 35 | Iteration number: [760/4518] 16% | Training loss: 0.6878212544478868
Epoch: 35 | Iteration number: [770/4518] 17% | Training loss: 0.6878178100307266
Epoch: 35 | Iteration number: [780/4518] 17% | Training loss: 0.687785856005473
Epoch: 35 | Iteration number: [790/4518] 17% | Training loss: 0.6877714755414407
Epoch: 35 | Iteration number: [800/4518] 17% | Training loss: 0.6877707843482495
Epoch: 35 | Iteration number: [810/4518] 17% | Training loss: 0.687761621269179
Epoch: 35 | Iteration number: [820/4518] 18% | Training loss: 0.6877503423429117
Epoch: 35 | Iteration number: [830/4518] 18% | Training loss: 0.6877449667597392
Epoch: 35 | Iteration number: [840/4518] 18% | Training loss: 0.6877350572319257
Epoch: 35 | Iteration number: [850/4518] 18% | Training loss: 0.6877257506987627
Epoch: 35 | Iteration number: [860/4518] 19% | Training loss: 0.6877200453780418
Epoch: 35 | Iteration number: [870/4518] 19% | Training loss: 0.6877138437210828
Epoch: 35 | Iteration number: [880/4518] 19% | Training loss: 0.6876912378452041
Epoch: 35 | Iteration number: [890/4518] 19% | Training loss: 0.6876820594407199
Epoch: 35 | Iteration number: [900/4518] 19% | Training loss: 0.6876922696166569
Epoch: 35 | Iteration number: [910/4518] 20% | Training loss: 0.6876851179442562
Epoch: 35 | Iteration number: [920/4518] 20% | Training loss: 0.6876663865602535
Epoch: 35 | Iteration number: [930/4518] 20% | Training loss: 0.6876420136420958
Epoch: 35 | Iteration number: [940/4518] 20% | Training loss: 0.6876178296322518
Epoch: 35 | Iteration number: [950/4518] 21% | Training loss: 0.6876112766014902
Epoch: 35 | Iteration number: [960/4518] 21% | Training loss: 0.6876094890137513
Epoch: 35 | Iteration number: [970/4518] 21% | Training loss: 0.687600131133168
Epoch: 35 | Iteration number: [980/4518] 21% | Training loss: 0.6875945670264108
Epoch: 35 | Iteration number: [990/4518] 21% | Training loss: 0.6875837015985239
Epoch: 35 | Iteration number: [1000/4518] 22% | Training loss: 0.6875833189487457
Epoch: 35 | Iteration number: [1010/4518] 22% | Training loss: 0.6875714970107126
Epoch: 35 | Iteration number: [1020/4518] 22% | Training loss: 0.6875781569995132
Epoch: 35 | Iteration number: [1030/4518] 22% | Training loss: 0.6875769667833754
Epoch: 35 | Iteration number: [1040/4518] 23% | Training loss: 0.6875777746622379
Epoch: 35 | Iteration number: [1050/4518] 23% | Training loss: 0.6875654744534265
Epoch: 35 | Iteration number: [1060/4518] 23% | Training loss: 0.6875674301723265
Epoch: 35 | Iteration number: [1070/4518] 23% | Training loss: 0.6875601063264865
Epoch: 35 | Iteration number: [1080/4518] 23% | Training loss: 0.6875574270884196
Epoch: 35 | Iteration number: [1090/4518] 24% | Training loss: 0.687543289377055
Epoch: 35 | Iteration number: [1100/4518] 24% | Training loss: 0.6875374217466874
Epoch: 35 | Iteration number: [1110/4518] 24% | Training loss: 0.6875339538664431
Epoch: 35 | Iteration number: [1120/4518] 24% | Training loss: 0.6875251340546779
Epoch: 35 | Iteration number: [1130/4518] 25% | Training loss: 0.6875314303204022
Epoch: 35 | Iteration number: [1140/4518] 25% | Training loss: 0.6875157502136733
Epoch: 35 | Iteration number: [1150/4518] 25% | Training loss: 0.6875074656113335
Epoch: 35 | Iteration number: [1160/4518] 25% | Training loss: 0.6874787987820034
Epoch: 35 | Iteration number: [1170/4518] 25% | Training loss: 0.6874748150507609
Epoch: 35 | Iteration number: [1180/4518] 26% | Training loss: 0.6874715993465004
Epoch: 35 | Iteration number: [1190/4518] 26% | Training loss: 0.6874695029078411
Epoch: 35 | Iteration number: [1200/4518] 26% | Training loss: 0.6874625314275423
Epoch: 35 | Iteration number: [1210/4518] 26% | Training loss: 0.6874595561303383
Epoch: 35 | Iteration number: [1220/4518] 27% | Training loss: 0.6874485296792672
Epoch: 35 | Iteration number: [1230/4518] 27% | Training loss: 0.6874410904035335
Epoch: 35 | Iteration number: [1240/4518] 27% | Training loss: 0.6874391728351193
Epoch: 35 | Iteration number: [1250/4518] 27% | Training loss: 0.6874320572376251
Epoch: 35 | Iteration number: [1260/4518] 27% | Training loss: 0.6874232258588548
Epoch: 35 | Iteration number: [1270/4518] 28% | Training loss: 0.6874239636687782
Epoch: 35 | Iteration number: [1280/4518] 28% | Training loss: 0.687417779257521
Epoch: 35 | Iteration number: [1290/4518] 28% | Training loss: 0.687418890738672
Epoch: 35 | Iteration number: [1300/4518] 28% | Training loss: 0.6874083488721114
Epoch: 35 | Iteration number: [1310/4518] 28% | Training loss: 0.6874001256382193
Epoch: 35 | Iteration number: [1320/4518] 29% | Training loss: 0.687391477236242
Epoch: 35 | Iteration number: [1330/4518] 29% | Training loss: 0.6873857200145721
Epoch: 35 | Iteration number: [1340/4518] 29% | Training loss: 0.6873842248720909
Epoch: 35 | Iteration number: [1350/4518] 29% | Training loss: 0.6873789778462163
Epoch: 35 | Iteration number: [1360/4518] 30% | Training loss: 0.6873776574783466
Epoch: 35 | Iteration number: [1370/4518] 30% | Training loss: 0.6873761459423677
Epoch: 35 | Iteration number: [1380/4518] 30% | Training loss: 0.6873839963605438
Epoch: 35 | Iteration number: [1390/4518] 30% | Training loss: 0.6873759316454688
Epoch: 35 | Iteration number: [1400/4518] 30% | Training loss: 0.6873661661999566
Epoch: 35 | Iteration number: [1410/4518] 31% | Training loss: 0.687362243435907
Epoch: 35 | Iteration number: [1420/4518] 31% | Training loss: 0.687356858648045
Epoch: 35 | Iteration number: [1430/4518] 31% | Training loss: 0.6873526226390492
Epoch: 35 | Iteration number: [1440/4518] 31% | Training loss: 0.6873537306156423
Epoch: 35 | Iteration number: [1450/4518] 32% | Training loss: 0.6873567535137308
Epoch: 35 | Iteration number: [1460/4518] 32% | Training loss: 0.6873537098299967
Epoch: 35 | Iteration number: [1470/4518] 32% | Training loss: 0.6873545593144942
Epoch: 35 | Iteration number: [1480/4518] 32% | Training loss: 0.6873460319799346
Epoch: 35 | Iteration number: [1490/4518] 32% | Training loss: 0.6873388183196919
Epoch: 35 | Iteration number: [1500/4518] 33% | Training loss: 0.6873433494170507
Epoch: 35 | Iteration number: [1510/4518] 33% | Training loss: 0.6873424672527818
Epoch: 35 | Iteration number: [1520/4518] 33% | Training loss: 0.6873418626032377
Epoch: 35 | Iteration number: [1530/4518] 33% | Training loss: 0.6873381036169389
Epoch: 35 | Iteration number: [1540/4518] 34% | Training loss: 0.687336477637291
Epoch: 35 | Iteration number: [1550/4518] 34% | Training loss: 0.6873273947931106
Epoch: 35 | Iteration number: [1560/4518] 34% | Training loss: 0.6873230709861486
Epoch: 35 | Iteration number: [1570/4518] 34% | Training loss: 0.6873249259344332
Epoch: 35 | Iteration number: [1580/4518] 34% | Training loss: 0.687320352506034
Epoch: 35 | Iteration number: [1590/4518] 35% | Training loss: 0.6873180824255793
Epoch: 35 | Iteration number: [1600/4518] 35% | Training loss: 0.6873176756501198
Epoch: 35 | Iteration number: [1610/4518] 35% | Training loss: 0.6873042504979957
Epoch: 35 | Iteration number: [1620/4518] 35% | Training loss: 0.6873021715217167
Epoch: 35 | Iteration number: [1630/4518] 36% | Training loss: 0.6872891388787814
Epoch: 35 | Iteration number: [1640/4518] 36% | Training loss: 0.6872831999528699
Epoch: 35 | Iteration number: [1650/4518] 36% | Training loss: 0.6872882929354003
Epoch: 35 | Iteration number: [1660/4518] 36% | Training loss: 0.6872867110981998
Epoch: 35 | Iteration number: [1670/4518] 36% | Training loss: 0.6872774582423136
Epoch: 35 | Iteration number: [1680/4518] 37% | Training loss: 0.6872772426122711
Epoch: 35 | Iteration number: [1690/4518] 37% | Training loss: 0.6872678595887133
Epoch: 35 | Iteration number: [1700/4518] 37% | Training loss: 0.6872677956959781
Epoch: 35 | Iteration number: [1710/4518] 37% | Training loss: 0.6872652305497063
Epoch: 35 | Iteration number: [1720/4518] 38% | Training loss: 0.6872521840555723
Epoch: 35 | Iteration number: [1730/4518] 38% | Training loss: 0.6872516246200296
Epoch: 35 | Iteration number: [1740/4518] 38% | Training loss: 0.6872417796959822
Epoch: 35 | Iteration number: [1750/4518] 38% | Training loss: 0.6872285509109497
Epoch: 35 | Iteration number: [1760/4518] 38% | Training loss: 0.6872252681715922
Epoch: 35 | Iteration number: [1770/4518] 39% | Training loss: 0.6872215044700494
Epoch: 35 | Iteration number: [1780/4518] 39% | Training loss: 0.6872286985764343
Epoch: 35 | Iteration number: [1790/4518] 39% | Training loss: 0.6872272234389236
Epoch: 35 | Iteration number: [1800/4518] 39% | Training loss: 0.6872167198194398
Epoch: 35 | Iteration number: [1810/4518] 40% | Training loss: 0.6872154789076326
Epoch: 35 | Iteration number: [1820/4518] 40% | Training loss: 0.6872165687791594
Epoch: 35 | Iteration number: [1830/4518] 40% | Training loss: 0.6872115118256032
Epoch: 35 | Iteration number: [1840/4518] 40% | Training loss: 0.6872076310541319
Epoch: 35 | Iteration number: [1850/4518] 40% | Training loss: 0.6872040484402631
Epoch: 35 | Iteration number: [1860/4518] 41% | Training loss: 0.6872097225278937
Epoch: 35 | Iteration number: [1870/4518] 41% | Training loss: 0.6872101603663542
Epoch: 35 | Iteration number: [1880/4518] 41% | Training loss: 0.687210799595143
Epoch: 35 | Iteration number: [1890/4518] 41% | Training loss: 0.6872080794402531
Epoch: 35 | Iteration number: [1900/4518] 42% | Training loss: 0.6872058549366499
Epoch: 35 | Iteration number: [1910/4518] 42% | Training loss: 0.6872024707769224
Epoch: 35 | Iteration number: [1920/4518] 42% | Training loss: 0.6871975249921282
Epoch: 35 | Iteration number: [1930/4518] 42% | Training loss: 0.6871950735082281
Epoch: 35 | Iteration number: [1940/4518] 42% | Training loss: 0.6871932460475214
Epoch: 35 | Iteration number: [1950/4518] 43% | Training loss: 0.6871903314040257
Epoch: 35 | Iteration number: [1960/4518] 43% | Training loss: 0.6871988604567489
Epoch: 35 | Iteration number: [1970/4518] 43% | Training loss: 0.687194553153769
Epoch: 35 | Iteration number: [1980/4518] 43% | Training loss: 0.6871895438191866
Epoch: 35 | Iteration number: [1990/4518] 44% | Training loss: 0.687191135619753
Epoch: 35 | Iteration number: [2000/4518] 44% | Training loss: 0.6871918809115887
Epoch: 35 | Iteration number: [2010/4518] 44% | Training loss: 0.6871907188821195
Epoch: 35 | Iteration number: [2020/4518] 44% | Training loss: 0.6871925322431149
Epoch: 35 | Iteration number: [2030/4518] 44% | Training loss: 0.6871891320632596
Epoch: 35 | Iteration number: [2040/4518] 45% | Training loss: 0.6871842388428894
Epoch: 35 | Iteration number: [2050/4518] 45% | Training loss: 0.6871810144912905
Epoch: 35 | Iteration number: [2060/4518] 45% | Training loss: 0.6871824718505434
Epoch: 35 | Iteration number: [2070/4518] 45% | Training loss: 0.6871841795202615
Epoch: 35 | Iteration number: [2080/4518] 46% | Training loss: 0.6871808624038329
Epoch: 35 | Iteration number: [2090/4518] 46% | Training loss: 0.6871818770061839
Epoch: 35 | Iteration number: [2100/4518] 46% | Training loss: 0.6871777864864894
Epoch: 35 | Iteration number: [2110/4518] 46% | Training loss: 0.687177730595331
Epoch: 35 | Iteration number: [2120/4518] 46% | Training loss: 0.6871739520498041
Epoch: 35 | Iteration number: [2130/4518] 47% | Training loss: 0.687173005840588
Epoch: 35 | Iteration number: [2140/4518] 47% | Training loss: 0.6871761091958697
Epoch: 35 | Iteration number: [2150/4518] 47% | Training loss: 0.687173197657563
Epoch: 35 | Iteration number: [2160/4518] 47% | Training loss: 0.6871763706207276
Epoch: 35 | Iteration number: [2170/4518] 48% | Training loss: 0.6871746449426572
Epoch: 35 | Iteration number: [2180/4518] 48% | Training loss: 0.6871714241734338
Epoch: 35 | Iteration number: [2190/4518] 48% | Training loss: 0.6871675012862846
Epoch: 35 | Iteration number: [2200/4518] 48% | Training loss: 0.6871650795232166
Epoch: 35 | Iteration number: [2210/4518] 48% | Training loss: 0.6871612648079298
Epoch: 35 | Iteration number: [2220/4518] 49% | Training loss: 0.6871593418422046
Epoch: 35 | Iteration number: [2230/4518] 49% | Training loss: 0.6871591234420982
Epoch: 35 | Iteration number: [2240/4518] 49% | Training loss: 0.6871603659753288
Epoch: 35 | Iteration number: [2250/4518] 49% | Training loss: 0.6871588206026289
Epoch: 35 | Iteration number: [2260/4518] 50% | Training loss: 0.6871539926370688
Epoch: 35 | Iteration number: [2270/4518] 50% | Training loss: 0.6871498872004942
Epoch: 35 | Iteration number: [2280/4518] 50% | Training loss: 0.6871508303180075
Epoch: 35 | Iteration number: [2290/4518] 50% | Training loss: 0.6871461413312687
Epoch: 35 | Iteration number: [2300/4518] 50% | Training loss: 0.6871429305750391
Epoch: 35 | Iteration number: [2310/4518] 51% | Training loss: 0.6871403228926968
Epoch: 35 | Iteration number: [2320/4518] 51% | Training loss: 0.6871365898898963
Epoch: 35 | Iteration number: [2330/4518] 51% | Training loss: 0.6871372077342267
Epoch: 35 | Iteration number: [2340/4518] 51% | Training loss: 0.6871345951261684
Epoch: 35 | Iteration number: [2350/4518] 52% | Training loss: 0.687137552981681
Epoch: 35 | Iteration number: [2360/4518] 52% | Training loss: 0.6871373643056821
Epoch: 35 | Iteration number: [2370/4518] 52% | Training loss: 0.687140913879821
Epoch: 35 | Iteration number: [2380/4518] 52% | Training loss: 0.6871396404855391
Epoch: 35 | Iteration number: [2390/4518] 52% | Training loss: 0.6871351654310107
Epoch: 35 | Iteration number: [2400/4518] 53% | Training loss: 0.6871370514978965
Epoch: 35 | Iteration number: [2410/4518] 53% | Training loss: 0.6871390104541145
Epoch: 35 | Iteration number: [2420/4518] 53% | Training loss: 0.6871414032110498
Epoch: 35 | Iteration number: [2430/4518] 53% | Training loss: 0.687137952164858
Epoch: 35 | Iteration number: [2440/4518] 54% | Training loss: 0.6871405638143665
Epoch: 35 | Iteration number: [2450/4518] 54% | Training loss: 0.6871418857817747
Epoch: 35 | Iteration number: [2460/4518] 54% | Training loss: 0.687140283206614
Epoch: 35 | Iteration number: [2470/4518] 54% | Training loss: 0.6871387684634822
Epoch: 35 | Iteration number: [2480/4518] 54% | Training loss: 0.6871369969460273
Epoch: 35 | Iteration number: [2490/4518] 55% | Training loss: 0.6871380507706638
Epoch: 35 | Iteration number: [2500/4518] 55% | Training loss: 0.6871445646762848
Epoch: 35 | Iteration number: [2510/4518] 55% | Training loss: 0.6871420041973373
Epoch: 35 | Iteration number: [2520/4518] 55% | Training loss: 0.6871395253709385
Epoch: 35 | Iteration number: [2530/4518] 55% | Training loss: 0.6871418614632527
Epoch: 35 | Iteration number: [2540/4518] 56% | Training loss: 0.6871401646475154
Epoch: 35 | Iteration number: [2550/4518] 56% | Training loss: 0.6871398002727359
Epoch: 35 | Iteration number: [2560/4518] 56% | Training loss: 0.6871391583932563
Epoch: 35 | Iteration number: [2570/4518] 56% | Training loss: 0.6871379432975087
Epoch: 35 | Iteration number: [2580/4518] 57% | Training loss: 0.6871403778708258
Epoch: 35 | Iteration number: [2590/4518] 57% | Training loss: 0.6871357721711678
Epoch: 35 | Iteration number: [2600/4518] 57% | Training loss: 0.687133045058984
Epoch: 35 | Iteration number: [2610/4518] 57% | Training loss: 0.6871290847031093
Epoch: 35 | Iteration number: [2620/4518] 57% | Training loss: 0.6871273116756031
Epoch: 35 | Iteration number: [2630/4518] 58% | Training loss: 0.6871280234349545
Epoch: 35 | Iteration number: [2640/4518] 58% | Training loss: 0.6871282515652252
Epoch: 35 | Iteration number: [2650/4518] 58% | Training loss: 0.6871233876246327
Epoch: 35 | Iteration number: [2660/4518] 58% | Training loss: 0.6871248157848989
Epoch: 35 | Iteration number: [2670/4518] 59% | Training loss: 0.6871243496512652
Epoch: 35 | Iteration number: [2680/4518] 59% | Training loss: 0.6871214817931403
Epoch: 35 | Iteration number: [2690/4518] 59% | Training loss: 0.6871205292448235
Epoch: 35 | Iteration number: [2700/4518] 59% | Training loss: 0.687119608366931
Epoch: 35 | Iteration number: [2710/4518] 59% | Training loss: 0.6871203178409281
Epoch: 35 | Iteration number: [2720/4518] 60% | Training loss: 0.6871201971436248
Epoch: 35 | Iteration number: [2730/4518] 60% | Training loss: 0.6871174851834992
Epoch: 35 | Iteration number: [2740/4518] 60% | Training loss: 0.6871197197559106
Epoch: 35 | Iteration number: [2750/4518] 60% | Training loss: 0.6871150214888833
Epoch: 35 | Iteration number: [2760/4518] 61% | Training loss: 0.6871156540253888
Epoch: 35 | Iteration number: [2770/4518] 61% | Training loss: 0.6871054596849296
Epoch: 35 | Iteration number: [2780/4518] 61% | Training loss: 0.6871005666984928
Epoch: 35 | Iteration number: [2790/4518] 61% | Training loss: 0.6870996384424121
Epoch: 35 | Iteration number: [2800/4518] 61% | Training loss: 0.6870934385274138
Epoch: 35 | Iteration number: [2810/4518] 62% | Training loss: 0.6870941341135426
Epoch: 35 | Iteration number: [2820/4518] 62% | Training loss: 0.6870885517368925
Epoch: 35 | Iteration number: [2830/4518] 62% | Training loss: 0.6870911609157656
Epoch: 35 | Iteration number: [2840/4518] 62% | Training loss: 0.6870899651881675
Epoch: 35 | Iteration number: [2850/4518] 63% | Training loss: 0.6870899849607234
Epoch: 35 | Iteration number: [2860/4518] 63% | Training loss: 0.687088193134828
Epoch: 35 | Iteration number: [2870/4518] 63% | Training loss: 0.6870881953513581
Epoch: 35 | Iteration number: [2880/4518] 63% | Training loss: 0.6870810316461656
Epoch: 35 | Iteration number: [2890/4518] 63% | Training loss: 0.6870794702566206
Epoch: 35 | Iteration number: [2900/4518] 64% | Training loss: 0.6870779633933101
Epoch: 35 | Iteration number: [2910/4518] 64% | Training loss: 0.687077674587158
Epoch: 35 | Iteration number: [2920/4518] 64% | Training loss: 0.6870804843224891
Epoch: 35 | Iteration number: [2930/4518] 64% | Training loss: 0.687082239039522
Epoch: 35 | Iteration number: [2940/4518] 65% | Training loss: 0.6870874054375149
Epoch: 35 | Iteration number: [2950/4518] 65% | Training loss: 0.6870903323868573
Epoch: 35 | Iteration number: [2960/4518] 65% | Training loss: 0.6870913109465225
Epoch: 35 | Iteration number: [2970/4518] 65% | Training loss: 0.6870899022026897
Epoch: 35 | Iteration number: [2980/4518] 65% | Training loss: 0.6870891458036116
Epoch: 35 | Iteration number: [2990/4518] 66% | Training loss: 0.6870841602417936
Epoch: 35 | Iteration number: [3000/4518] 66% | Training loss: 0.6870862255891164
Epoch: 35 | Iteration number: [3010/4518] 66% | Training loss: 0.6870857878578858
Epoch: 35 | Iteration number: [3020/4518] 66% | Training loss: 0.6870833573159792
Epoch: 35 | Iteration number: [3030/4518] 67% | Training loss: 0.6870838659431281
Epoch: 35 | Iteration number: [3040/4518] 67% | Training loss: 0.6870858286752513
Epoch: 35 | Iteration number: [3050/4518] 67% | Training loss: 0.6870844174799372
Epoch: 35 | Iteration number: [3060/4518] 67% | Training loss: 0.6870830646527359
Epoch: 35 | Iteration number: [3070/4518] 67% | Training loss: 0.6870879787963843
Epoch: 35 | Iteration number: [3080/4518] 68% | Training loss: 0.6870895344715614
Epoch: 35 | Iteration number: [3090/4518] 68% | Training loss: 0.6870884980198635
Epoch: 35 | Iteration number: [3100/4518] 68% | Training loss: 0.6870867544989432
Epoch: 35 | Iteration number: [3110/4518] 68% | Training loss: 0.6870835418103209
Epoch: 35 | Iteration number: [3120/4518] 69% | Training loss: 0.6870819831123719
Epoch: 35 | Iteration number: [3130/4518] 69% | Training loss: 0.6870818236765389
Epoch: 35 | Iteration number: [3140/4518] 69% | Training loss: 0.6870793611950176
Epoch: 35 | Iteration number: [3150/4518] 69% | Training loss: 0.6870784368779924
Epoch: 35 | Iteration number: [3160/4518] 69% | Training loss: 0.6870789882314357
Epoch: 35 | Iteration number: [3170/4518] 70% | Training loss: 0.6870771376868527
Epoch: 35 | Iteration number: [3180/4518] 70% | Training loss: 0.6870822347185147
Epoch: 35 | Iteration number: [3190/4518] 70% | Training loss: 0.6870783059574593
Epoch: 35 | Iteration number: [3200/4518] 70% | Training loss: 0.6870761404186487
Epoch: 35 | Iteration number: [3210/4518] 71% | Training loss: 0.6870719441000918
Epoch: 35 | Iteration number: [3220/4518] 71% | Training loss: 0.6870726342897238
Epoch: 35 | Iteration number: [3230/4518] 71% | Training loss: 0.6870709849584952
Epoch: 35 | Iteration number: [3240/4518] 71% | Training loss: 0.6870681948131985
Epoch: 35 | Iteration number: [3250/4518] 71% | Training loss: 0.6870694856460278
Epoch: 35 | Iteration number: [3260/4518] 72% | Training loss: 0.6870677704825723
Epoch: 35 | Iteration number: [3270/4518] 72% | Training loss: 0.687066540914938
Epoch: 35 | Iteration number: [3280/4518] 72% | Training loss: 0.6870617119640838
Epoch: 35 | Iteration number: [3290/4518] 72% | Training loss: 0.6870662943389279
Epoch: 35 | Iteration number: [3300/4518] 73% | Training loss: 0.6870621284752181
Epoch: 35 | Iteration number: [3310/4518] 73% | Training loss: 0.6870599393758169
Epoch: 35 | Iteration number: [3320/4518] 73% | Training loss: 0.6870585340333272
Epoch: 35 | Iteration number: [3330/4518] 73% | Training loss: 0.6870529531537591
Epoch: 35 | Iteration number: [3340/4518] 73% | Training loss: 0.6870537282999404
Epoch: 35 | Iteration number: [3350/4518] 74% | Training loss: 0.6870529608584162
Epoch: 35 | Iteration number: [3360/4518] 74% | Training loss: 0.6870555340711559
Epoch: 35 | Iteration number: [3370/4518] 74% | Training loss: 0.6870567705581733
Epoch: 35 | Iteration number: [3380/4518] 74% | Training loss: 0.6870555509476972
Epoch: 35 | Iteration number: [3390/4518] 75% | Training loss: 0.6870543577326435
Epoch: 35 | Iteration number: [3400/4518] 75% | Training loss: 0.6870492699041086
Epoch: 35 | Iteration number: [3410/4518] 75% | Training loss: 0.6870486476728993
Epoch: 35 | Iteration number: [3420/4518] 75% | Training loss: 0.6870459986186167
Epoch: 35 | Iteration number: [3430/4518] 75% | Training loss: 0.6870435973819421
Epoch: 35 | Iteration number: [3440/4518] 76% | Training loss: 0.6870444741533246
Epoch: 35 | Iteration number: [3450/4518] 76% | Training loss: 0.6870435479240141
Epoch: 35 | Iteration number: [3460/4518] 76% | Training loss: 0.6870384876955451
Epoch: 35 | Iteration number: [3470/4518] 76% | Training loss: 0.6870389578665368
Epoch: 35 | Iteration number: [3480/4518] 77% | Training loss: 0.687037934088844
Epoch: 35 | Iteration number: [3490/4518] 77% | Training loss: 0.6870340126633303
Epoch: 35 | Iteration number: [3500/4518] 77% | Training loss: 0.6870309223617826
Epoch: 35 | Iteration number: [3510/4518] 77% | Training loss: 0.6870287016925649
Epoch: 35 | Iteration number: [3520/4518] 77% | Training loss: 0.6870296683162451
Epoch: 35 | Iteration number: [3530/4518] 78% | Training loss: 0.6870258798004886
Epoch: 35 | Iteration number: [3540/4518] 78% | Training loss: 0.6870249207073685
Epoch: 35 | Iteration number: [3550/4518] 78% | Training loss: 0.6870283415116055
Epoch: 35 | Iteration number: [3560/4518] 78% | Training loss: 0.6870284315240517
Epoch: 35 | Iteration number: [3570/4518] 79% | Training loss: 0.6870285428872629
Epoch: 35 | Iteration number: [3580/4518] 79% | Training loss: 0.6870274438205378
Epoch: 35 | Iteration number: [3590/4518] 79% | Training loss: 0.6870267919013096
Epoch: 35 | Iteration number: [3600/4518] 79% | Training loss: 0.6870282056762113
Epoch: 35 | Iteration number: [3610/4518] 79% | Training loss: 0.6870292206880458
Epoch: 35 | Iteration number: [3620/4518] 80% | Training loss: 0.6870288238011671
Epoch: 35 | Iteration number: [3630/4518] 80% | Training loss: 0.6870301084577545
Epoch: 35 | Iteration number: [3640/4518] 80% | Training loss: 0.6870288561169918
Epoch: 35 | Iteration number: [3650/4518] 80% | Training loss: 0.6870300337549758
Epoch: 35 | Iteration number: [3660/4518] 81% | Training loss: 0.6870292347148468
Epoch: 35 | Iteration number: [3670/4518] 81% | Training loss: 0.6870232515179169
Epoch: 35 | Iteration number: [3680/4518] 81% | Training loss: 0.6870234154002822
Epoch: 35 | Iteration number: [3690/4518] 81% | Training loss: 0.6870243231293954
Epoch: 35 | Iteration number: [3700/4518] 81% | Training loss: 0.6870265382689399
Epoch: 35 | Iteration number: [3710/4518] 82% | Training loss: 0.6870245271776564
Epoch: 35 | Iteration number: [3720/4518] 82% | Training loss: 0.6870257981041427
Epoch: 35 | Iteration number: [3730/4518] 82% | Training loss: 0.6870263568517669
Epoch: 35 | Iteration number: [3740/4518] 82% | Training loss: 0.6870278303635949
Epoch: 35 | Iteration number: [3750/4518] 83% | Training loss: 0.6870301673730215
Epoch: 35 | Iteration number: [3760/4518] 83% | Training loss: 0.6870326519963589
Epoch: 35 | Iteration number: [3770/4518] 83% | Training loss: 0.6870347248306325
Epoch: 35 | Iteration number: [3780/4518] 83% | Training loss: 0.6870352678355717
Epoch: 35 | Iteration number: [3790/4518] 83% | Training loss: 0.6870346420987615
Epoch: 35 | Iteration number: [3800/4518] 84% | Training loss: 0.6870312108648451
Epoch: 35 | Iteration number: [3810/4518] 84% | Training loss: 0.6870327040435761
Epoch: 35 | Iteration number: [3820/4518] 84% | Training loss: 0.6870364205219359
Epoch: 35 | Iteration number: [3830/4518] 84% | Training loss: 0.6870376812571334
Epoch: 35 | Iteration number: [3840/4518] 84% | Training loss: 0.6870411991917839
Epoch: 35 | Iteration number: [3850/4518] 85% | Training loss: 0.6870399069940889
Epoch: 35 | Iteration number: [3860/4518] 85% | Training loss: 0.6870415028821619
Epoch: 35 | Iteration number: [3870/4518] 85% | Training loss: 0.6870392237676822
Epoch: 35 | Iteration number: [3880/4518] 85% | Training loss: 0.6870373354437425
Epoch: 35 | Iteration number: [3890/4518] 86% | Training loss: 0.6870336082263594
Epoch: 35 | Iteration number: [3900/4518] 86% | Training loss: 0.6870372926730376
Epoch: 35 | Iteration number: [3910/4518] 86% | Training loss: 0.6870309694648704
Epoch: 35 | Iteration number: [3920/4518] 86% | Training loss: 0.6870300538229699
Epoch: 35 | Iteration number: [3930/4518] 86% | Training loss: 0.6870252737562165
Epoch: 35 | Iteration number: [3940/4518] 87% | Training loss: 0.6870274611082173
Epoch: 35 | Iteration number: [3950/4518] 87% | Training loss: 0.687026821389983
Epoch: 35 | Iteration number: [3960/4518] 87% | Training loss: 0.6870271435139155
Epoch: 35 | Iteration number: [3970/4518] 87% | Training loss: 0.6870280475099981
Epoch: 35 | Iteration number: [3980/4518] 88% | Training loss: 0.687026474553736
Epoch: 35 | Iteration number: [3990/4518] 88% | Training loss: 0.6870261115687234
Epoch: 35 | Iteration number: [4000/4518] 88% | Training loss: 0.6870267812907696
Epoch: 35 | Iteration number: [4010/4518] 88% | Training loss: 0.6870282161562817
Epoch: 35 | Iteration number: [4020/4518] 88% | Training loss: 0.6870260265780919
Epoch: 35 | Iteration number: [4030/4518] 89% | Training loss: 0.6870253465311699
Epoch: 35 | Iteration number: [4040/4518] 89% | Training loss: 0.6870233184482791
Epoch: 35 | Iteration number: [4050/4518] 89% | Training loss: 0.6870235207934439
Epoch: 35 | Iteration number: [4060/4518] 89% | Training loss: 0.6870216105812289
Epoch: 35 | Iteration number: [4070/4518] 90% | Training loss: 0.6870201833418019
Epoch: 35 | Iteration number: [4080/4518] 90% | Training loss: 0.6870215219902057
Epoch: 35 | Iteration number: [4090/4518] 90% | Training loss: 0.6870190419019871
Epoch: 35 | Iteration number: [4100/4518] 90% | Training loss: 0.6870188441945285
Epoch: 35 | Iteration number: [4110/4518] 90% | Training loss: 0.6870163009839626
Epoch: 35 | Iteration number: [4120/4518] 91% | Training loss: 0.6870131267216599
Epoch: 35 | Iteration number: [4130/4518] 91% | Training loss: 0.6870128017938166
Epoch: 35 | Iteration number: [4140/4518] 91% | Training loss: 0.6870095139972253
Epoch: 35 | Iteration number: [4150/4518] 91% | Training loss: 0.687009206521942
Epoch: 35 | Iteration number: [4160/4518] 92% | Training loss: 0.6870111350399943
Epoch: 35 | Iteration number: [4170/4518] 92% | Training loss: 0.6870109127579833
Epoch: 35 | Iteration number: [4180/4518] 92% | Training loss: 0.6870102361343694
Epoch: 35 | Iteration number: [4190/4518] 92% | Training loss: 0.6870134085203412
Epoch: 35 | Iteration number: [4200/4518] 92% | Training loss: 0.6870138749905995
Epoch: 35 | Iteration number: [4210/4518] 93% | Training loss: 0.6870120889075861
Epoch: 35 | Iteration number: [4220/4518] 93% | Training loss: 0.687009834099155
Epoch: 35 | Iteration number: [4230/4518] 93% | Training loss: 0.6870125883437218
Epoch: 35 | Iteration number: [4240/4518] 93% | Training loss: 0.6870112530887127
Epoch: 35 | Iteration number: [4250/4518] 94% | Training loss: 0.6870083151003894
Epoch: 35 | Iteration number: [4260/4518] 94% | Training loss: 0.6870064043662918
Epoch: 35 | Iteration number: [4270/4518] 94% | Training loss: 0.6870055798205614
Epoch: 35 | Iteration number: [4280/4518] 94% | Training loss: 0.6870067306768114
Epoch: 35 | Iteration number: [4290/4518] 94% | Training loss: 0.687005122002466
Epoch: 35 | Iteration number: [4300/4518] 95% | Training loss: 0.6870038227840911
Epoch: 35 | Iteration number: [4310/4518] 95% | Training loss: 0.6870031283377495
Epoch: 35 | Iteration number: [4320/4518] 95% | Training loss: 0.6870021141237683
Epoch: 35 | Iteration number: [4330/4518] 95% | Training loss: 0.6870025801465913
Epoch: 35 | Iteration number: [4340/4518] 96% | Training loss: 0.6870031104796493
Epoch: 35 | Iteration number: [4350/4518] 96% | Training loss: 0.6870053529191291
Epoch: 35 | Iteration number: [4360/4518] 96% | Training loss: 0.6870029663547463
Epoch: 35 | Iteration number: [4370/4518] 96% | Training loss: 0.6870018409646076
Epoch: 35 | Iteration number: [4380/4518] 96% | Training loss: 0.6870023420820498
Epoch: 35 | Iteration number: [4390/4518] 97% | Training loss: 0.6870011482939362
Epoch: 35 | Iteration number: [4400/4518] 97% | Training loss: 0.6869988110796972
Epoch: 35 | Iteration number: [4410/4518] 97% | Training loss: 0.6869980752738425
Epoch: 35 | Iteration number: [4420/4518] 97% | Training loss: 0.6869972850941964
Epoch: 35 | Iteration number: [4430/4518] 98% | Training loss: 0.6869967485389107
Epoch: 35 | Iteration number: [4440/4518] 98% | Training loss: 0.6869959067116986
Epoch: 35 | Iteration number: [4450/4518] 98% | Training loss: 0.686995088049535
Epoch: 35 | Iteration number: [4460/4518] 98% | Training loss: 0.6869960840774758
Epoch: 35 | Iteration number: [4470/4518] 98% | Training loss: 0.6869962307564097
Epoch: 35 | Iteration number: [4480/4518] 99% | Training loss: 0.6869969770445356
Epoch: 35 | Iteration number: [4490/4518] 99% | Training loss: 0.686995491577947
Epoch: 35 | Iteration number: [4500/4518] 99% | Training loss: 0.6869905522664388
Epoch: 35 | Iteration number: [4510/4518] 99% | Training loss: 0.6869919615679992

 End of epoch: 35 | Train Loss: 0.6868388404119009 | Training Time: 641 

 End of epoch: 35 | Eval Loss: 0.6900400981611136 | Evaluating Time: 17 
Epoch: 36 | Iteration number: [10/4518] 0% | Training loss: 0.756470239162445
Epoch: 36 | Iteration number: [20/4518] 0% | Training loss: 0.7216985672712326
Epoch: 36 | Iteration number: [30/4518] 0% | Training loss: 0.7101946234703064
Epoch: 36 | Iteration number: [40/4518] 0% | Training loss: 0.7043649896979332
Epoch: 36 | Iteration number: [50/4518] 1% | Training loss: 0.7005321860313416
Epoch: 36 | Iteration number: [60/4518] 1% | Training loss: 0.6979932645956676
Epoch: 36 | Iteration number: [70/4518] 1% | Training loss: 0.6966306499072483
Epoch: 36 | Iteration number: [80/4518] 1% | Training loss: 0.6954731531441212
Epoch: 36 | Iteration number: [90/4518] 1% | Training loss: 0.6945127791828579
Epoch: 36 | Iteration number: [100/4518] 2% | Training loss: 0.6935330909490586
Epoch: 36 | Iteration number: [110/4518] 2% | Training loss: 0.6929060914299705
Epoch: 36 | Iteration number: [120/4518] 2% | Training loss: 0.6923656642436982
Epoch: 36 | Iteration number: [130/4518] 2% | Training loss: 0.6918381842283102
Epoch: 36 | Iteration number: [140/4518] 3% | Training loss: 0.6915495995964323
Epoch: 36 | Iteration number: [150/4518] 3% | Training loss: 0.6912392834822337
Epoch: 36 | Iteration number: [160/4518] 3% | Training loss: 0.690946851670742
Epoch: 36 | Iteration number: [170/4518] 3% | Training loss: 0.6906672631993013
Epoch: 36 | Iteration number: [180/4518] 3% | Training loss: 0.6904223243395488
Epoch: 36 | Iteration number: [190/4518] 4% | Training loss: 0.6902533860583054
Epoch: 36 | Iteration number: [200/4518] 4% | Training loss: 0.6899724572896957
Epoch: 36 | Iteration number: [210/4518] 4% | Training loss: 0.6898064567929223
Epoch: 36 | Iteration number: [220/4518] 4% | Training loss: 0.6897087021307512
Epoch: 36 | Iteration number: [230/4518] 5% | Training loss: 0.6895191832729007
Epoch: 36 | Iteration number: [240/4518] 5% | Training loss: 0.6894320391118527
Epoch: 36 | Iteration number: [250/4518] 5% | Training loss: 0.6893402917385101
Epoch: 36 | Iteration number: [260/4518] 5% | Training loss: 0.6891835247094814
Epoch: 36 | Iteration number: [270/4518] 5% | Training loss: 0.6891127577534428
Epoch: 36 | Iteration number: [280/4518] 6% | Training loss: 0.6890448548964092
Epoch: 36 | Iteration number: [290/4518] 6% | Training loss: 0.6889959343548478
Epoch: 36 | Iteration number: [300/4518] 6% | Training loss: 0.6889069674412409
Epoch: 36 | Iteration number: [310/4518] 6% | Training loss: 0.6888154095219028
Epoch: 36 | Iteration number: [320/4518] 7% | Training loss: 0.6887583818286658
Epoch: 36 | Iteration number: [330/4518] 7% | Training loss: 0.6886877796866677
Epoch: 36 | Iteration number: [340/4518] 7% | Training loss: 0.6886390267049565
Epoch: 36 | Iteration number: [350/4518] 7% | Training loss: 0.6886226269177028
Epoch: 36 | Iteration number: [360/4518] 7% | Training loss: 0.6885813905133141
Epoch: 36 | Iteration number: [370/4518] 8% | Training loss: 0.6885484874248504
Epoch: 36 | Iteration number: [380/4518] 8% | Training loss: 0.6885025032256779
Epoch: 36 | Iteration number: [390/4518] 8% | Training loss: 0.6884544604863876
Epoch: 36 | Iteration number: [400/4518] 8% | Training loss: 0.6883938597142696
Epoch: 36 | Iteration number: [410/4518] 9% | Training loss: 0.688329280295023
Epoch: 36 | Iteration number: [420/4518] 9% | Training loss: 0.6883154795283363
Epoch: 36 | Iteration number: [430/4518] 9% | Training loss: 0.6882732796114545
Epoch: 36 | Iteration number: [440/4518] 9% | Training loss: 0.688244748792865
Epoch: 36 | Iteration number: [450/4518] 9% | Training loss: 0.6882111610306634
Epoch: 36 | Iteration number: [460/4518] 10% | Training loss: 0.6881793280010639
Epoch: 36 | Iteration number: [470/4518] 10% | Training loss: 0.6881639996741681
Epoch: 36 | Iteration number: [480/4518] 10% | Training loss: 0.6881299489488204
Epoch: 36 | Iteration number: [490/4518] 10% | Training loss: 0.6881244535348854
Epoch: 36 | Iteration number: [500/4518] 11% | Training loss: 0.6880702315568924
Epoch: 36 | Iteration number: [510/4518] 11% | Training loss: 0.6880537253968856
Epoch: 36 | Iteration number: [520/4518] 11% | Training loss: 0.688046727845302
Epoch: 36 | Iteration number: [530/4518] 11% | Training loss: 0.6879978455462545
Epoch: 36 | Iteration number: [540/4518] 11% | Training loss: 0.6879755645990372
Epoch: 36 | Iteration number: [550/4518] 12% | Training loss: 0.6879693070324985
Epoch: 36 | Iteration number: [560/4518] 12% | Training loss: 0.687981609574386
Epoch: 36 | Iteration number: [570/4518] 12% | Training loss: 0.6879530407880482
Epoch: 36 | Iteration number: [580/4518] 12% | Training loss: 0.6879394337021071
Epoch: 36 | Iteration number: [590/4518] 13% | Training loss: 0.6878948387453112
Epoch: 36 | Iteration number: [600/4518] 13% | Training loss: 0.6878805845975876
Epoch: 36 | Iteration number: [610/4518] 13% | Training loss: 0.6878703420279456
Epoch: 36 | Iteration number: [620/4518] 13% | Training loss: 0.6878503528333479
Epoch: 36 | Iteration number: [630/4518] 13% | Training loss: 0.6878582012085688
Epoch: 36 | Iteration number: [640/4518] 14% | Training loss: 0.6878507891669869
Epoch: 36 | Iteration number: [650/4518] 14% | Training loss: 0.687854207937534
Epoch: 36 | Iteration number: [660/4518] 14% | Training loss: 0.6878368293697183
Epoch: 36 | Iteration number: [670/4518] 14% | Training loss: 0.6878054188258612
Epoch: 36 | Iteration number: [680/4518] 15% | Training loss: 0.6877995417398565
Epoch: 36 | Iteration number: [690/4518] 15% | Training loss: 0.6877844067587369
Epoch: 36 | Iteration number: [700/4518] 15% | Training loss: 0.6877624704156603
Epoch: 36 | Iteration number: [710/4518] 15% | Training loss: 0.6877475644501162
Epoch: 36 | Iteration number: [720/4518] 15% | Training loss: 0.6877099487516615
Epoch: 36 | Iteration number: [730/4518] 16% | Training loss: 0.6877065095182967
Epoch: 36 | Iteration number: [740/4518] 16% | Training loss: 0.6877054059022182
Epoch: 36 | Iteration number: [750/4518] 16% | Training loss: 0.68770614139239
Epoch: 36 | Iteration number: [760/4518] 16% | Training loss: 0.6876987430610155
Epoch: 36 | Iteration number: [770/4518] 17% | Training loss: 0.6876718973184561
Epoch: 36 | Iteration number: [780/4518] 17% | Training loss: 0.6876564848881501
Epoch: 36 | Iteration number: [790/4518] 17% | Training loss: 0.6876574787912489
Epoch: 36 | Iteration number: [800/4518] 17% | Training loss: 0.6876413897424937
Epoch: 36 | Iteration number: [810/4518] 17% | Training loss: 0.6876225587026572
Epoch: 36 | Iteration number: [820/4518] 18% | Training loss: 0.6876255382124971
Epoch: 36 | Iteration number: [830/4518] 18% | Training loss: 0.6875984592610095
Epoch: 36 | Iteration number: [840/4518] 18% | Training loss: 0.6875712792788233
Epoch: 36 | Iteration number: [850/4518] 18% | Training loss: 0.687573015759973
Epoch: 36 | Iteration number: [860/4518] 19% | Training loss: 0.6875716257927029
Epoch: 36 | Iteration number: [870/4518] 19% | Training loss: 0.6875759111053642
Epoch: 36 | Iteration number: [880/4518] 19% | Training loss: 0.687580472569574
Epoch: 36 | Iteration number: [890/4518] 19% | Training loss: 0.6875967281588008
Epoch: 36 | Iteration number: [900/4518] 19% | Training loss: 0.6875783048735724
Epoch: 36 | Iteration number: [910/4518] 20% | Training loss: 0.6875792457507207
Epoch: 36 | Iteration number: [920/4518] 20% | Training loss: 0.6875659927077915
Epoch: 36 | Iteration number: [930/4518] 20% | Training loss: 0.6875565846120157
Epoch: 36 | Iteration number: [940/4518] 20% | Training loss: 0.6875412285962004
Epoch: 36 | Iteration number: [950/4518] 21% | Training loss: 0.6875348613136693
Epoch: 36 | Iteration number: [960/4518] 21% | Training loss: 0.6875303477669755
Epoch: 36 | Iteration number: [970/4518] 21% | Training loss: 0.6875282395131809
Epoch: 36 | Iteration number: [980/4518] 21% | Training loss: 0.6875232050613481
Epoch: 36 | Iteration number: [990/4518] 21% | Training loss: 0.6875142828382627
Epoch: 36 | Iteration number: [1000/4518] 22% | Training loss: 0.6875045965313912
Epoch: 36 | Iteration number: [1010/4518] 22% | Training loss: 0.6874926094371494
Epoch: 36 | Iteration number: [1020/4518] 22% | Training loss: 0.6874879827102025
Epoch: 36 | Iteration number: [1030/4518] 22% | Training loss: 0.6874776689751634
Epoch: 36 | Iteration number: [1040/4518] 23% | Training loss: 0.6874582474048321
Epoch: 36 | Iteration number: [1050/4518] 23% | Training loss: 0.6874635330268315
Epoch: 36 | Iteration number: [1060/4518] 23% | Training loss: 0.6874516360602289
Epoch: 36 | Iteration number: [1070/4518] 23% | Training loss: 0.6874479748935343
Epoch: 36 | Iteration number: [1080/4518] 23% | Training loss: 0.6874347220968318
Epoch: 36 | Iteration number: [1090/4518] 24% | Training loss: 0.687429644645901
Epoch: 36 | Iteration number: [1100/4518] 24% | Training loss: 0.6874184383587404
Epoch: 36 | Iteration number: [1110/4518] 24% | Training loss: 0.6874066114425659
Epoch: 36 | Iteration number: [1120/4518] 24% | Training loss: 0.687396804722292
Epoch: 36 | Iteration number: [1130/4518] 25% | Training loss: 0.6874020367069582
Epoch: 36 | Iteration number: [1140/4518] 25% | Training loss: 0.687392193497273
Epoch: 36 | Iteration number: [1150/4518] 25% | Training loss: 0.6873810408944669
Epoch: 36 | Iteration number: [1160/4518] 25% | Training loss: 0.6873766093932349
Epoch: 36 | Iteration number: [1170/4518] 25% | Training loss: 0.6873780751839662
Epoch: 36 | Iteration number: [1180/4518] 26% | Training loss: 0.6873842631356191
Epoch: 36 | Iteration number: [1190/4518] 26% | Training loss: 0.6873885462764933
Epoch: 36 | Iteration number: [1200/4518] 26% | Training loss: 0.6873935564359029
Epoch: 36 | Iteration number: [1210/4518] 26% | Training loss: 0.6873851404209768
Epoch: 36 | Iteration number: [1220/4518] 27% | Training loss: 0.6873749836057913
Epoch: 36 | Iteration number: [1230/4518] 27% | Training loss: 0.6873795030562858
Epoch: 36 | Iteration number: [1240/4518] 27% | Training loss: 0.6873862215107487
Epoch: 36 | Iteration number: [1250/4518] 27% | Training loss: 0.6873836265087128
Epoch: 36 | Iteration number: [1260/4518] 27% | Training loss: 0.6873793335661056
Epoch: 36 | Iteration number: [1270/4518] 28% | Training loss: 0.6873743885145412
Epoch: 36 | Iteration number: [1280/4518] 28% | Training loss: 0.687373659433797
Epoch: 36 | Iteration number: [1290/4518] 28% | Training loss: 0.687359177557997
Epoch: 36 | Iteration number: [1300/4518] 28% | Training loss: 0.6873500423706494
Epoch: 36 | Iteration number: [1310/4518] 28% | Training loss: 0.6873461918066476
Epoch: 36 | Iteration number: [1320/4518] 29% | Training loss: 0.6873475977868745
Epoch: 36 | Iteration number: [1330/4518] 29% | Training loss: 0.687343205321104
Epoch: 36 | Iteration number: [1340/4518] 29% | Training loss: 0.6873334812584208
Epoch: 36 | Iteration number: [1350/4518] 29% | Training loss: 0.6873317457128454
Epoch: 36 | Iteration number: [1360/4518] 30% | Training loss: 0.6873364119407008
Epoch: 36 | Iteration number: [1370/4518] 30% | Training loss: 0.6873436210799391
Epoch: 36 | Iteration number: [1380/4518] 30% | Training loss: 0.6873423312021338
Epoch: 36 | Iteration number: [1390/4518] 30% | Training loss: 0.6873337368742167
Epoch: 36 | Iteration number: [1400/4518] 30% | Training loss: 0.6873391589096615
Epoch: 36 | Iteration number: [1410/4518] 31% | Training loss: 0.6873339681337911
Epoch: 36 | Iteration number: [1420/4518] 31% | Training loss: 0.6873191569052951
Epoch: 36 | Iteration number: [1430/4518] 31% | Training loss: 0.687315404081678
Epoch: 36 | Iteration number: [1440/4518] 31% | Training loss: 0.6873034490479364
Epoch: 36 | Iteration number: [1450/4518] 32% | Training loss: 0.6873034218673049
Epoch: 36 | Iteration number: [1460/4518] 32% | Training loss: 0.6873022651427413
Epoch: 36 | Iteration number: [1470/4518] 32% | Training loss: 0.687302234018741
Epoch: 36 | Iteration number: [1480/4518] 32% | Training loss: 0.6872994419690724
Epoch: 36 | Iteration number: [1490/4518] 32% | Training loss: 0.6872946542381441
Epoch: 36 | Iteration number: [1500/4518] 33% | Training loss: 0.6872956121762593
Epoch: 36 | Iteration number: [1510/4518] 33% | Training loss: 0.6872917116083057
Epoch: 36 | Iteration number: [1520/4518] 33% | Training loss: 0.6873017813422178
Epoch: 36 | Iteration number: [1530/4518] 33% | Training loss: 0.6872996317794899
Epoch: 36 | Iteration number: [1540/4518] 34% | Training loss: 0.6872940531798771
Epoch: 36 | Iteration number: [1550/4518] 34% | Training loss: 0.6872853859009281
Epoch: 36 | Iteration number: [1560/4518] 34% | Training loss: 0.6872878212577257
Epoch: 36 | Iteration number: [1570/4518] 34% | Training loss: 0.6872906002269429
Epoch: 36 | Iteration number: [1580/4518] 34% | Training loss: 0.6872821260479433
Epoch: 36 | Iteration number: [1590/4518] 35% | Training loss: 0.687286824212884
Epoch: 36 | Iteration number: [1600/4518] 35% | Training loss: 0.6872853481024503
Epoch: 36 | Iteration number: [1610/4518] 35% | Training loss: 0.6872859270306108
Epoch: 36 | Iteration number: [1620/4518] 35% | Training loss: 0.6872856785485774
Epoch: 36 | Iteration number: [1630/4518] 36% | Training loss: 0.6872842161567665
Epoch: 36 | Iteration number: [1640/4518] 36% | Training loss: 0.6872677362910131
Epoch: 36 | Iteration number: [1650/4518] 36% | Training loss: 0.6872661719900189
Epoch: 36 | Iteration number: [1660/4518] 36% | Training loss: 0.6872630994722068
Epoch: 36 | Iteration number: [1670/4518] 36% | Training loss: 0.6872616241435091
Epoch: 36 | Iteration number: [1680/4518] 37% | Training loss: 0.6872595475543113
Epoch: 36 | Iteration number: [1690/4518] 37% | Training loss: 0.6872575026292067
Epoch: 36 | Iteration number: [1700/4518] 37% | Training loss: 0.6872510662850212
Epoch: 36 | Iteration number: [1710/4518] 37% | Training loss: 0.687242441358622
Epoch: 36 | Iteration number: [1720/4518] 38% | Training loss: 0.6872411790628766
Epoch: 36 | Iteration number: [1730/4518] 38% | Training loss: 0.6872456169197325
Epoch: 36 | Iteration number: [1740/4518] 38% | Training loss: 0.687247755061621
Epoch: 36 | Iteration number: [1750/4518] 38% | Training loss: 0.687247937134334
Epoch: 36 | Iteration number: [1760/4518] 38% | Training loss: 0.6872452242807908
Epoch: 36 | Iteration number: [1770/4518] 39% | Training loss: 0.6872525408779834
Epoch: 36 | Iteration number: [1780/4518] 39% | Training loss: 0.6872507398048143
Epoch: 36 | Iteration number: [1790/4518] 39% | Training loss: 0.687251498579313
Epoch: 36 | Iteration number: [1800/4518] 39% | Training loss: 0.6872510792480575
Epoch: 36 | Iteration number: [1810/4518] 40% | Training loss: 0.687252804357044
Epoch: 36 | Iteration number: [1820/4518] 40% | Training loss: 0.6872511493963199
Epoch: 36 | Iteration number: [1830/4518] 40% | Training loss: 0.6872476634757766
Epoch: 36 | Iteration number: [1840/4518] 40% | Training loss: 0.687247200925713
Epoch: 36 | Iteration number: [1850/4518] 40% | Training loss: 0.6872472938975772
Epoch: 36 | Iteration number: [1860/4518] 41% | Training loss: 0.6872469818720254
Epoch: 36 | Iteration number: [1870/4518] 41% | Training loss: 0.687243504224614
Epoch: 36 | Iteration number: [1880/4518] 41% | Training loss: 0.687244738162832
Epoch: 36 | Iteration number: [1890/4518] 41% | Training loss: 0.6872334742672229
Epoch: 36 | Iteration number: [1900/4518] 42% | Training loss: 0.6872256577328631
Epoch: 36 | Iteration number: [1910/4518] 42% | Training loss: 0.6872239774122288
Epoch: 36 | Iteration number: [1920/4518] 42% | Training loss: 0.6872235163735847
Epoch: 36 | Iteration number: [1930/4518] 42% | Training loss: 0.6872255193754799
Epoch: 36 | Iteration number: [1940/4518] 42% | Training loss: 0.6872141151391353
Epoch: 36 | Iteration number: [1950/4518] 43% | Training loss: 0.6872148714004419
Epoch: 36 | Iteration number: [1960/4518] 43% | Training loss: 0.6872085059175685
Epoch: 36 | Iteration number: [1970/4518] 43% | Training loss: 0.6872065738978119
Epoch: 36 | Iteration number: [1980/4518] 43% | Training loss: 0.6872092289153976
Epoch: 36 | Iteration number: [1990/4518] 44% | Training loss: 0.6872074356330699
Epoch: 36 | Iteration number: [2000/4518] 44% | Training loss: 0.6872054997980594
Epoch: 36 | Iteration number: [2010/4518] 44% | Training loss: 0.6872080928354121
Epoch: 36 | Iteration number: [2020/4518] 44% | Training loss: 0.6872073768094035
Epoch: 36 | Iteration number: [2030/4518] 44% | Training loss: 0.6872093835781361
Epoch: 36 | Iteration number: [2040/4518] 45% | Training loss: 0.6872148138927479
Epoch: 36 | Iteration number: [2050/4518] 45% | Training loss: 0.687209341293428
Epoch: 36 | Iteration number: [2060/4518] 45% | Training loss: 0.6872067791455
Epoch: 36 | Iteration number: [2070/4518] 45% | Training loss: 0.6872097820187536
Epoch: 36 | Iteration number: [2080/4518] 46% | Training loss: 0.6872087286068843
Epoch: 36 | Iteration number: [2090/4518] 46% | Training loss: 0.6872063925962129
Epoch: 36 | Iteration number: [2100/4518] 46% | Training loss: 0.6872097889014653
Epoch: 36 | Iteration number: [2110/4518] 46% | Training loss: 0.687205456642178
Epoch: 36 | Iteration number: [2120/4518] 46% | Training loss: 0.6872080660091257
Epoch: 36 | Iteration number: [2130/4518] 47% | Training loss: 0.6872059027633757
Epoch: 36 | Iteration number: [2140/4518] 47% | Training loss: 0.6872054351824466
Epoch: 36 | Iteration number: [2150/4518] 47% | Training loss: 0.6872040061340775
Epoch: 36 | Iteration number: [2160/4518] 47% | Training loss: 0.6872067672234995
Epoch: 36 | Iteration number: [2170/4518] 48% | Training loss: 0.6872016724078885
Epoch: 36 | Iteration number: [2180/4518] 48% | Training loss: 0.6871988727958924
Epoch: 36 | Iteration number: [2190/4518] 48% | Training loss: 0.6871970814112659
Epoch: 36 | Iteration number: [2200/4518] 48% | Training loss: 0.6871997618675232
Epoch: 36 | Iteration number: [2210/4518] 48% | Training loss: 0.6871983824272501
Epoch: 36 | Iteration number: [2220/4518] 49% | Training loss: 0.6871925931524586
Epoch: 36 | Iteration number: [2230/4518] 49% | Training loss: 0.6871948180177286
Epoch: 36 | Iteration number: [2240/4518] 49% | Training loss: 0.6871952213613051
Epoch: 36 | Iteration number: [2250/4518] 49% | Training loss: 0.6871952110131582
Epoch: 36 | Iteration number: [2260/4518] 50% | Training loss: 0.6871937496999724
Epoch: 36 | Iteration number: [2270/4518] 50% | Training loss: 0.6871841236620747
Epoch: 36 | Iteration number: [2280/4518] 50% | Training loss: 0.6871853914700057
Epoch: 36 | Iteration number: [2290/4518] 50% | Training loss: 0.6871922898240485
Epoch: 36 | Iteration number: [2300/4518] 50% | Training loss: 0.6871873511697935
Epoch: 36 | Iteration number: [2310/4518] 51% | Training loss: 0.6871846907582634
Epoch: 36 | Iteration number: [2320/4518] 51% | Training loss: 0.687182699786178
Epoch: 36 | Iteration number: [2330/4518] 51% | Training loss: 0.6871880692473809
Epoch: 36 | Iteration number: [2340/4518] 51% | Training loss: 0.6871806781770836
Epoch: 36 | Iteration number: [2350/4518] 52% | Training loss: 0.6871774849485843
Epoch: 36 | Iteration number: [2360/4518] 52% | Training loss: 0.6871776588892533
Epoch: 36 | Iteration number: [2370/4518] 52% | Training loss: 0.6871748020628836
Epoch: 36 | Iteration number: [2380/4518] 52% | Training loss: 0.6871725831462555
Epoch: 36 | Iteration number: [2390/4518] 52% | Training loss: 0.6871760099004003
Epoch: 36 | Iteration number: [2400/4518] 53% | Training loss: 0.6871739429483811
Epoch: 36 | Iteration number: [2410/4518] 53% | Training loss: 0.6871778298710391
Epoch: 36 | Iteration number: [2420/4518] 53% | Training loss: 0.6871806112941632
Epoch: 36 | Iteration number: [2430/4518] 53% | Training loss: 0.6871807973816562
Epoch: 36 | Iteration number: [2440/4518] 54% | Training loss: 0.6871788924590486
Epoch: 36 | Iteration number: [2450/4518] 54% | Training loss: 0.6871759102052571
Epoch: 36 | Iteration number: [2460/4518] 54% | Training loss: 0.6871768528368415
Epoch: 36 | Iteration number: [2470/4518] 54% | Training loss: 0.6871800055388014
Epoch: 36 | Iteration number: [2480/4518] 54% | Training loss: 0.6871732762504008
Epoch: 36 | Iteration number: [2490/4518] 55% | Training loss: 0.6871724736977772
Epoch: 36 | Iteration number: [2500/4518] 55% | Training loss: 0.6871710212469101
Epoch: 36 | Iteration number: [2510/4518] 55% | Training loss: 0.6871708736239202
Epoch: 36 | Iteration number: [2520/4518] 55% | Training loss: 0.6871684835780234
Epoch: 36 | Iteration number: [2530/4518] 55% | Training loss: 0.6871662380902663
Epoch: 36 | Iteration number: [2540/4518] 56% | Training loss: 0.6871639626701985
Epoch: 36 | Iteration number: [2550/4518] 56% | Training loss: 0.6871642294117049
Epoch: 36 | Iteration number: [2560/4518] 56% | Training loss: 0.6871613797033206
Epoch: 36 | Iteration number: [2570/4518] 56% | Training loss: 0.687159925699234
Epoch: 36 | Iteration number: [2580/4518] 57% | Training loss: 0.6871583877376808
Epoch: 36 | Iteration number: [2590/4518] 57% | Training loss: 0.6871611860037771
Epoch: 36 | Iteration number: [2600/4518] 57% | Training loss: 0.6871647376739062
Epoch: 36 | Iteration number: [2610/4518] 57% | Training loss: 0.6871651924432922
Epoch: 36 | Iteration number: [2620/4518] 57% | Training loss: 0.6871618801628361
Epoch: 36 | Iteration number: [2630/4518] 58% | Training loss: 0.6871584985419371
Epoch: 36 | Iteration number: [2640/4518] 58% | Training loss: 0.6871579797882023
Epoch: 36 | Iteration number: [2650/4518] 58% | Training loss: 0.6871538144012667
Epoch: 36 | Iteration number: [2660/4518] 58% | Training loss: 0.6871510492679768
Epoch: 36 | Iteration number: [2670/4518] 59% | Training loss: 0.6871511560924044
Epoch: 36 | Iteration number: [2680/4518] 59% | Training loss: 0.6871459331975054
Epoch: 36 | Iteration number: [2690/4518] 59% | Training loss: 0.6871430591579707
Epoch: 36 | Iteration number: [2700/4518] 59% | Training loss: 0.687137507001559
Epoch: 36 | Iteration number: [2710/4518] 59% | Training loss: 0.6871382028194372
Epoch: 36 | Iteration number: [2720/4518] 60% | Training loss: 0.687136790090624
Epoch: 36 | Iteration number: [2730/4518] 60% | Training loss: 0.6871377700414413
Epoch: 36 | Iteration number: [2740/4518] 60% | Training loss: 0.6871322560049321
Epoch: 36 | Iteration number: [2750/4518] 60% | Training loss: 0.6871328675530174
Epoch: 36 | Iteration number: [2760/4518] 61% | Training loss: 0.6871268855488819
Epoch: 36 | Iteration number: [2770/4518] 61% | Training loss: 0.687123755750243
Epoch: 36 | Iteration number: [2780/4518] 61% | Training loss: 0.687126364060443
Epoch: 36 | Iteration number: [2790/4518] 61% | Training loss: 0.6871265487217989
Epoch: 36 | Iteration number: [2800/4518] 61% | Training loss: 0.6871253647761686
Epoch: 36 | Iteration number: [2810/4518] 62% | Training loss: 0.6871265518071389
Epoch: 36 | Iteration number: [2820/4518] 62% | Training loss: 0.6871219889492007
Epoch: 36 | Iteration number: [2830/4518] 62% | Training loss: 0.6871228579708207
Epoch: 36 | Iteration number: [2840/4518] 62% | Training loss: 0.6871229868119871
Epoch: 36 | Iteration number: [2850/4518] 63% | Training loss: 0.6871247635598768
Epoch: 36 | Iteration number: [2860/4518] 63% | Training loss: 0.687123681490238
Epoch: 36 | Iteration number: [2870/4518] 63% | Training loss: 0.6871273538376812
Epoch: 36 | Iteration number: [2880/4518] 63% | Training loss: 0.687127181287441
Epoch: 36 | Iteration number: [2890/4518] 63% | Training loss: 0.6871247900604789
Epoch: 36 | Iteration number: [2900/4518] 64% | Training loss: 0.6871319284110233
Epoch: 36 | Iteration number: [2910/4518] 64% | Training loss: 0.6871326625961618
Epoch: 36 | Iteration number: [2920/4518] 64% | Training loss: 0.6871341980483434
Epoch: 36 | Iteration number: [2930/4518] 64% | Training loss: 0.6871330052512498
Epoch: 36 | Iteration number: [2940/4518] 65% | Training loss: 0.6871316350033494
Epoch: 36 | Iteration number: [2950/4518] 65% | Training loss: 0.6871333558074498
Epoch: 36 | Iteration number: [2960/4518] 65% | Training loss: 0.6871334103716387
Epoch: 36 | Iteration number: [2970/4518] 65% | Training loss: 0.6871324010368951
Epoch: 36 | Iteration number: [2980/4518] 65% | Training loss: 0.6871294435838725
Epoch: 36 | Iteration number: [2990/4518] 66% | Training loss: 0.6871271282733483
Epoch: 36 | Iteration number: [3000/4518] 66% | Training loss: 0.6871275855302811
Epoch: 36 | Iteration number: [3010/4518] 66% | Training loss: 0.6871258213868568
Epoch: 36 | Iteration number: [3020/4518] 66% | Training loss: 0.6871241645899829
Epoch: 36 | Iteration number: [3030/4518] 67% | Training loss: 0.6871250966201128
Epoch: 36 | Iteration number: [3040/4518] 67% | Training loss: 0.6871297471617398
Epoch: 36 | Iteration number: [3050/4518] 67% | Training loss: 0.6871269740432989
Epoch: 36 | Iteration number: [3060/4518] 67% | Training loss: 0.6871265185229919
Epoch: 36 | Iteration number: [3070/4518] 67% | Training loss: 0.687124071136748
Epoch: 36 | Iteration number: [3080/4518] 68% | Training loss: 0.6871203111170174
Epoch: 36 | Iteration number: [3090/4518] 68% | Training loss: 0.6871119480688596
Epoch: 36 | Iteration number: [3100/4518] 68% | Training loss: 0.6871124927074679
Epoch: 36 | Iteration number: [3110/4518] 68% | Training loss: 0.6871103843117067
Epoch: 36 | Iteration number: [3120/4518] 69% | Training loss: 0.6871128625021531
Epoch: 36 | Iteration number: [3130/4518] 69% | Training loss: 0.6871128507696401
Epoch: 36 | Iteration number: [3140/4518] 69% | Training loss: 0.6871130627431687
Epoch: 36 | Iteration number: [3150/4518] 69% | Training loss: 0.6871130795327444
Epoch: 36 | Iteration number: [3160/4518] 69% | Training loss: 0.6871053928815866
Epoch: 36 | Iteration number: [3170/4518] 70% | Training loss: 0.6871030460396775
Epoch: 36 | Iteration number: [3180/4518] 70% | Training loss: 0.6870997570595652
Epoch: 36 | Iteration number: [3190/4518] 70% | Training loss: 0.6870959128518837
Epoch: 36 | Iteration number: [3200/4518] 70% | Training loss: 0.6870994345657527
Epoch: 36 | Iteration number: [3210/4518] 71% | Training loss: 0.6871023471110335
Epoch: 36 | Iteration number: [3220/4518] 71% | Training loss: 0.6870992003205401
Epoch: 36 | Iteration number: [3230/4518] 71% | Training loss: 0.6870963024465662
Epoch: 36 | Iteration number: [3240/4518] 71% | Training loss: 0.687098603134538
Epoch: 36 | Iteration number: [3250/4518] 71% | Training loss: 0.6870985850737645
Epoch: 36 | Iteration number: [3260/4518] 72% | Training loss: 0.6870987643310629
Epoch: 36 | Iteration number: [3270/4518] 72% | Training loss: 0.687095392187801
Epoch: 36 | Iteration number: [3280/4518] 72% | Training loss: 0.6870938836619621
Epoch: 36 | Iteration number: [3290/4518] 72% | Training loss: 0.6870960928205299
Epoch: 36 | Iteration number: [3300/4518] 73% | Training loss: 0.6870955813292301
Epoch: 36 | Iteration number: [3310/4518] 73% | Training loss: 0.6870952039867009
Epoch: 36 | Iteration number: [3320/4518] 73% | Training loss: 0.6870912189225117
Epoch: 36 | Iteration number: [3330/4518] 73% | Training loss: 0.6870903950911742
Epoch: 36 | Iteration number: [3340/4518] 73% | Training loss: 0.68709283751285
Epoch: 36 | Iteration number: [3350/4518] 74% | Training loss: 0.6870933763304753
Epoch: 36 | Iteration number: [3360/4518] 74% | Training loss: 0.6870970883539744
Epoch: 36 | Iteration number: [3370/4518] 74% | Training loss: 0.6870983744941055
Epoch: 36 | Iteration number: [3380/4518] 74% | Training loss: 0.6870955519422272
Epoch: 36 | Iteration number: [3390/4518] 75% | Training loss: 0.6870944808190551
Epoch: 36 | Iteration number: [3400/4518] 75% | Training loss: 0.6870966882565442
Epoch: 36 | Iteration number: [3410/4518] 75% | Training loss: 0.6870934594761241
Epoch: 36 | Iteration number: [3420/4518] 75% | Training loss: 0.6870932355610251
Epoch: 36 | Iteration number: [3430/4518] 75% | Training loss: 0.6870930640760038
Epoch: 36 | Iteration number: [3440/4518] 76% | Training loss: 0.6870931395264559
Epoch: 36 | Iteration number: [3450/4518] 76% | Training loss: 0.687089794114016
Epoch: 36 | Iteration number: [3460/4518] 76% | Training loss: 0.6870885389905445
Epoch: 36 | Iteration number: [3470/4518] 76% | Training loss: 0.6870918477990098
Epoch: 36 | Iteration number: [3480/4518] 77% | Training loss: 0.6870901860553643
Epoch: 36 | Iteration number: [3490/4518] 77% | Training loss: 0.687088727438689
Epoch: 36 | Iteration number: [3500/4518] 77% | Training loss: 0.6870872359957014
Epoch: 36 | Iteration number: [3510/4518] 77% | Training loss: 0.6870817565170788
Epoch: 36 | Iteration number: [3520/4518] 77% | Training loss: 0.6870840179479935
Epoch: 36 | Iteration number: [3530/4518] 78% | Training loss: 0.6870833951420554
Epoch: 36 | Iteration number: [3540/4518] 78% | Training loss: 0.6870817432969304
Epoch: 36 | Iteration number: [3550/4518] 78% | Training loss: 0.6870779286975592
Epoch: 36 | Iteration number: [3560/4518] 78% | Training loss: 0.6870765552929278
Epoch: 36 | Iteration number: [3570/4518] 79% | Training loss: 0.6870750245092964
Epoch: 36 | Iteration number: [3580/4518] 79% | Training loss: 0.6870718968647153
Epoch: 36 | Iteration number: [3590/4518] 79% | Training loss: 0.6870714326588888
Epoch: 36 | Iteration number: [3600/4518] 79% | Training loss: 0.6870664251347383
Epoch: 36 | Iteration number: [3610/4518] 79% | Training loss: 0.6870615181830451
Epoch: 36 | Iteration number: [3620/4518] 80% | Training loss: 0.6870636905754469
Epoch: 36 | Iteration number: [3630/4518] 80% | Training loss: 0.6870635001455785
Epoch: 36 | Iteration number: [3640/4518] 80% | Training loss: 0.6870620916505437
Epoch: 36 | Iteration number: [3650/4518] 80% | Training loss: 0.6870620646215465
Epoch: 36 | Iteration number: [3660/4518] 81% | Training loss: 0.6870580246539715
Epoch: 36 | Iteration number: [3670/4518] 81% | Training loss: 0.687056035647925
Epoch: 36 | Iteration number: [3680/4518] 81% | Training loss: 0.6870566220873076
Epoch: 36 | Iteration number: [3690/4518] 81% | Training loss: 0.6870557263937745
Epoch: 36 | Iteration number: [3700/4518] 81% | Training loss: 0.6870529986394418
Epoch: 36 | Iteration number: [3710/4518] 82% | Training loss: 0.6870510650612915
Epoch: 36 | Iteration number: [3720/4518] 82% | Training loss: 0.6870493822360552
Epoch: 36 | Iteration number: [3730/4518] 82% | Training loss: 0.6870461600555492
Epoch: 36 | Iteration number: [3740/4518] 82% | Training loss: 0.6870441179065143
Epoch: 36 | Iteration number: [3750/4518] 83% | Training loss: 0.6870441188176473
Epoch: 36 | Iteration number: [3760/4518] 83% | Training loss: 0.687041222208992
Epoch: 36 | Iteration number: [3770/4518] 83% | Training loss: 0.6870369660443273
Epoch: 36 | Iteration number: [3780/4518] 83% | Training loss: 0.6870353754235323
Epoch: 36 | Iteration number: [3790/4518] 83% | Training loss: 0.6870353487833823
Epoch: 36 | Iteration number: [3800/4518] 84% | Training loss: 0.6870308074041417
Epoch: 36 | Iteration number: [3810/4518] 84% | Training loss: 0.6870277981745603
Epoch: 36 | Iteration number: [3820/4518] 84% | Training loss: 0.6870263340585518
Epoch: 36 | Iteration number: [3830/4518] 84% | Training loss: 0.687024152901403
Epoch: 36 | Iteration number: [3840/4518] 84% | Training loss: 0.687024082414185
Epoch: 36 | Iteration number: [3850/4518] 85% | Training loss: 0.6870225006728977
Epoch: 36 | Iteration number: [3860/4518] 85% | Training loss: 0.6870239272173204
Epoch: 36 | Iteration number: [3870/4518] 85% | Training loss: 0.6870225616665774
Epoch: 36 | Iteration number: [3880/4518] 85% | Training loss: 0.6870226066444338
Epoch: 36 | Iteration number: [3890/4518] 86% | Training loss: 0.6870211214669872
Epoch: 36 | Iteration number: [3900/4518] 86% | Training loss: 0.6870216389649954
Epoch: 36 | Iteration number: [3910/4518] 86% | Training loss: 0.6870227122093405
Epoch: 36 | Iteration number: [3920/4518] 86% | Training loss: 0.6870234246612812
Epoch: 36 | Iteration number: [3930/4518] 86% | Training loss: 0.6870240833316443
Epoch: 36 | Iteration number: [3940/4518] 87% | Training loss: 0.6870254069718007
Epoch: 36 | Iteration number: [3950/4518] 87% | Training loss: 0.6870250661312779
Epoch: 36 | Iteration number: [3960/4518] 87% | Training loss: 0.6870256131496092
Epoch: 36 | Iteration number: [3970/4518] 87% | Training loss: 0.6870252031973687
Epoch: 36 | Iteration number: [3980/4518] 88% | Training loss: 0.6870242099366596
Epoch: 36 | Iteration number: [3990/4518] 88% | Training loss: 0.6870258248390112
Epoch: 36 | Iteration number: [4000/4518] 88% | Training loss: 0.6870234546661377
Epoch: 36 | Iteration number: [4010/4518] 88% | Training loss: 0.6870237213269136
Epoch: 36 | Iteration number: [4020/4518] 88% | Training loss: 0.6870232290741223
Epoch: 36 | Iteration number: [4030/4518] 89% | Training loss: 0.6870219488889349
Epoch: 36 | Iteration number: [4040/4518] 89% | Training loss: 0.6870193277845288
Epoch: 36 | Iteration number: [4050/4518] 89% | Training loss: 0.6870235085928882
Epoch: 36 | Iteration number: [4060/4518] 89% | Training loss: 0.6870242296034479
Epoch: 36 | Iteration number: [4070/4518] 90% | Training loss: 0.6870223055600534
Epoch: 36 | Iteration number: [4080/4518] 90% | Training loss: 0.6870170353236151
Epoch: 36 | Iteration number: [4090/4518] 90% | Training loss: 0.6870168803810782
Epoch: 36 | Iteration number: [4100/4518] 90% | Training loss: 0.6870143017245502
Epoch: 36 | Iteration number: [4110/4518] 90% | Training loss: 0.6870128352566647
Epoch: 36 | Iteration number: [4120/4518] 91% | Training loss: 0.6870107112868318
Epoch: 36 | Iteration number: [4130/4518] 91% | Training loss: 0.6870084235800958
Epoch: 36 | Iteration number: [4140/4518] 91% | Training loss: 0.6870106202536735
Epoch: 36 | Iteration number: [4150/4518] 91% | Training loss: 0.6870115412143339
Epoch: 36 | Iteration number: [4160/4518] 92% | Training loss: 0.6870097398328093
Epoch: 36 | Iteration number: [4170/4518] 92% | Training loss: 0.6870081062511288
Epoch: 36 | Iteration number: [4180/4518] 92% | Training loss: 0.6870097964289086
Epoch: 36 | Iteration number: [4190/4518] 92% | Training loss: 0.6870066978481902
Epoch: 36 | Iteration number: [4200/4518] 92% | Training loss: 0.6870075518176669
Epoch: 36 | Iteration number: [4210/4518] 93% | Training loss: 0.687006483097824
Epoch: 36 | Iteration number: [4220/4518] 93% | Training loss: 0.6870067694034622
Epoch: 36 | Iteration number: [4230/4518] 93% | Training loss: 0.687007419944655
Epoch: 36 | Iteration number: [4240/4518] 93% | Training loss: 0.6870082003890343
Epoch: 36 | Iteration number: [4250/4518] 94% | Training loss: 0.6870049048031077
Epoch: 36 | Iteration number: [4260/4518] 94% | Training loss: 0.6870025027945568
Epoch: 36 | Iteration number: [4270/4518] 94% | Training loss: 0.6870022849539683
Epoch: 36 | Iteration number: [4280/4518] 94% | Training loss: 0.6870011418779319
Epoch: 36 | Iteration number: [4290/4518] 94% | Training loss: 0.686999487015473
Epoch: 36 | Iteration number: [4300/4518] 95% | Training loss: 0.6869991324945938
Epoch: 36 | Iteration number: [4310/4518] 95% | Training loss: 0.6869969684397261
Epoch: 36 | Iteration number: [4320/4518] 95% | Training loss: 0.6869954790506098
Epoch: 36 | Iteration number: [4330/4518] 95% | Training loss: 0.6869978073287506
Epoch: 36 | Iteration number: [4340/4518] 96% | Training loss: 0.6869999379743629
Epoch: 36 | Iteration number: [4350/4518] 96% | Training loss: 0.6869985840512418
Epoch: 36 | Iteration number: [4360/4518] 96% | Training loss: 0.6869989948261769
Epoch: 36 | Iteration number: [4370/4518] 96% | Training loss: 0.6870002089703383
Epoch: 36 | Iteration number: [4380/4518] 96% | Training loss: 0.6870001750585696
Epoch: 36 | Iteration number: [4390/4518] 97% | Training loss: 0.6869970441271884
Epoch: 36 | Iteration number: [4400/4518] 97% | Training loss: 0.6869970509951765
Epoch: 36 | Iteration number: [4410/4518] 97% | Training loss: 0.6869977218629011
Epoch: 36 | Iteration number: [4420/4518] 97% | Training loss: 0.686996793989682
Epoch: 36 | Iteration number: [4430/4518] 98% | Training loss: 0.6869986759351554
Epoch: 36 | Iteration number: [4440/4518] 98% | Training loss: 0.6869962967730857
Epoch: 36 | Iteration number: [4450/4518] 98% | Training loss: 0.6869950345125091
Epoch: 36 | Iteration number: [4460/4518] 98% | Training loss: 0.6869950439363317
Epoch: 36 | Iteration number: [4470/4518] 98% | Training loss: 0.6869953408203936
Epoch: 36 | Iteration number: [4480/4518] 99% | Training loss: 0.6869961445219814
Epoch: 36 | Iteration number: [4490/4518] 99% | Training loss: 0.6869983769206534
Epoch: 36 | Iteration number: [4500/4518] 99% | Training loss: 0.6869965365727743
Epoch: 36 | Iteration number: [4510/4518] 99% | Training loss: 0.6869971406169054

 End of epoch: 36 | Train Loss: 0.6868470190055816 | Training Time: 640 

 End of epoch: 36 | Eval Loss: 0.690089728151049 | Evaluating Time: 17 
Epoch: 37 | Iteration number: [10/4518] 0% | Training loss: 0.7556073904037476
Epoch: 37 | Iteration number: [20/4518] 0% | Training loss: 0.7209172040224076
Epoch: 37 | Iteration number: [30/4518] 0% | Training loss: 0.7094250877698263
Epoch: 37 | Iteration number: [40/4518] 0% | Training loss: 0.7036995872855186
Epoch: 37 | Iteration number: [50/4518] 1% | Training loss: 0.7003218948841095
Epoch: 37 | Iteration number: [60/4518] 1% | Training loss: 0.6981899460156759
Epoch: 37 | Iteration number: [70/4518] 1% | Training loss: 0.6964169893945966
Epoch: 37 | Iteration number: [80/4518] 1% | Training loss: 0.6951728239655495
Epoch: 37 | Iteration number: [90/4518] 1% | Training loss: 0.6940465887387594
Epoch: 37 | Iteration number: [100/4518] 2% | Training loss: 0.6932048952579498
Epoch: 37 | Iteration number: [110/4518] 2% | Training loss: 0.6926231563091279
Epoch: 37 | Iteration number: [120/4518] 2% | Training loss: 0.6921162754297256
Epoch: 37 | Iteration number: [130/4518] 2% | Training loss: 0.6918054759502411
Epoch: 37 | Iteration number: [140/4518] 3% | Training loss: 0.691489862544196
Epoch: 37 | Iteration number: [150/4518] 3% | Training loss: 0.6912285999457042
Epoch: 37 | Iteration number: [160/4518] 3% | Training loss: 0.6909445855766535
Epoch: 37 | Iteration number: [170/4518] 3% | Training loss: 0.6907053649425506
Epoch: 37 | Iteration number: [180/4518] 3% | Training loss: 0.6904753065771527
Epoch: 37 | Iteration number: [190/4518] 4% | Training loss: 0.69026771721087
Epoch: 37 | Iteration number: [200/4518] 4% | Training loss: 0.6901438009738922
Epoch: 37 | Iteration number: [210/4518] 4% | Training loss: 0.6899674554665883
Epoch: 37 | Iteration number: [220/4518] 4% | Training loss: 0.6898695309053767
Epoch: 37 | Iteration number: [230/4518] 5% | Training loss: 0.6897109112013942
Epoch: 37 | Iteration number: [240/4518] 5% | Training loss: 0.6895757978161176
Epoch: 37 | Iteration number: [250/4518] 5% | Training loss: 0.6894400899410248
Epoch: 37 | Iteration number: [260/4518] 5% | Training loss: 0.6893129156186031
Epoch: 37 | Iteration number: [270/4518] 5% | Training loss: 0.6892317961763452
Epoch: 37 | Iteration number: [280/4518] 6% | Training loss: 0.6891247819576944
Epoch: 37 | Iteration number: [290/4518] 6% | Training loss: 0.6890207580451307
Epoch: 37 | Iteration number: [300/4518] 6% | Training loss: 0.6889558863639832
Epoch: 37 | Iteration number: [310/4518] 6% | Training loss: 0.6889004332403983
Epoch: 37 | Iteration number: [320/4518] 7% | Training loss: 0.6888559751212597
Epoch: 37 | Iteration number: [330/4518] 7% | Training loss: 0.6888433880878218
Epoch: 37 | Iteration number: [340/4518] 7% | Training loss: 0.6888017174075631
Epoch: 37 | Iteration number: [350/4518] 7% | Training loss: 0.6887587649481637
Epoch: 37 | Iteration number: [360/4518] 7% | Training loss: 0.6887368943956164
Epoch: 37 | Iteration number: [370/4518] 8% | Training loss: 0.6887177227316676
Epoch: 37 | Iteration number: [380/4518] 8% | Training loss: 0.6886593374766802
Epoch: 37 | Iteration number: [390/4518] 8% | Training loss: 0.6886460194220909
Epoch: 37 | Iteration number: [400/4518] 8% | Training loss: 0.6886085560917854
Epoch: 37 | Iteration number: [410/4518] 9% | Training loss: 0.6885783019589214
Epoch: 37 | Iteration number: [420/4518] 9% | Training loss: 0.6885226932309922
Epoch: 37 | Iteration number: [430/4518] 9% | Training loss: 0.6885027307410573
Epoch: 37 | Iteration number: [440/4518] 9% | Training loss: 0.688443363932046
Epoch: 37 | Iteration number: [450/4518] 9% | Training loss: 0.6883983763058981
Epoch: 37 | Iteration number: [460/4518] 10% | Training loss: 0.6883310172868812
Epoch: 37 | Iteration number: [470/4518] 10% | Training loss: 0.6882974341828773
Epoch: 37 | Iteration number: [480/4518] 10% | Training loss: 0.6882594410330057
Epoch: 37 | Iteration number: [490/4518] 10% | Training loss: 0.6882297540197567
Epoch: 37 | Iteration number: [500/4518] 11% | Training loss: 0.6882058625221252
Epoch: 37 | Iteration number: [510/4518] 11% | Training loss: 0.688191542672176
Epoch: 37 | Iteration number: [520/4518] 11% | Training loss: 0.6881819375432454
Epoch: 37 | Iteration number: [530/4518] 11% | Training loss: 0.6881192650435106
Epoch: 37 | Iteration number: [540/4518] 11% | Training loss: 0.6881070708786999
Epoch: 37 | Iteration number: [550/4518] 12% | Training loss: 0.6880869048291987
Epoch: 37 | Iteration number: [560/4518] 12% | Training loss: 0.6880813764674323
Epoch: 37 | Iteration number: [570/4518] 12% | Training loss: 0.6880420903364818
Epoch: 37 | Iteration number: [580/4518] 12% | Training loss: 0.6880206398922821
Epoch: 37 | Iteration number: [590/4518] 13% | Training loss: 0.6879929076817076
Epoch: 37 | Iteration number: [600/4518] 13% | Training loss: 0.6879923744002978
Epoch: 37 | Iteration number: [610/4518] 13% | Training loss: 0.6879689906464248
Epoch: 37 | Iteration number: [620/4518] 13% | Training loss: 0.6879644263175226
Epoch: 37 | Iteration number: [630/4518] 13% | Training loss: 0.6879474465809171
Epoch: 37 | Iteration number: [640/4518] 14% | Training loss: 0.6879523711279034
Epoch: 37 | Iteration number: [650/4518] 14% | Training loss: 0.6879261519358708
Epoch: 37 | Iteration number: [660/4518] 14% | Training loss: 0.6879205906933005
Epoch: 37 | Iteration number: [670/4518] 14% | Training loss: 0.6879167060353862
Epoch: 37 | Iteration number: [680/4518] 15% | Training loss: 0.6878940247437533
Epoch: 37 | Iteration number: [690/4518] 15% | Training loss: 0.6878747691278873
Epoch: 37 | Iteration number: [700/4518] 15% | Training loss: 0.6878462851047515
Epoch: 37 | Iteration number: [710/4518] 15% | Training loss: 0.6878312617120609
Epoch: 37 | Iteration number: [720/4518] 15% | Training loss: 0.687814016557402
Epoch: 37 | Iteration number: [730/4518] 16% | Training loss: 0.6878039778911904
Epoch: 37 | Iteration number: [740/4518] 16% | Training loss: 0.6878011569783494
Epoch: 37 | Iteration number: [750/4518] 16% | Training loss: 0.6877974813779195
Epoch: 37 | Iteration number: [760/4518] 16% | Training loss: 0.6877798517283641
Epoch: 37 | Iteration number: [770/4518] 17% | Training loss: 0.6877745721247289
Epoch: 37 | Iteration number: [780/4518] 17% | Training loss: 0.6877580844438993
Epoch: 37 | Iteration number: [790/4518] 17% | Training loss: 0.6877510180956201
Epoch: 37 | Iteration number: [800/4518] 17% | Training loss: 0.6877338477969169
Epoch: 37 | Iteration number: [810/4518] 17% | Training loss: 0.6877272732463884
Epoch: 37 | Iteration number: [820/4518] 18% | Training loss: 0.6877286896473024
Epoch: 37 | Iteration number: [830/4518] 18% | Training loss: 0.6877163721854428
Epoch: 37 | Iteration number: [840/4518] 18% | Training loss: 0.6876908347720192
Epoch: 37 | Iteration number: [850/4518] 18% | Training loss: 0.6876968955292421
Epoch: 37 | Iteration number: [860/4518] 19% | Training loss: 0.6876943954894709
Epoch: 37 | Iteration number: [870/4518] 19% | Training loss: 0.68768211938869
Epoch: 37 | Iteration number: [880/4518] 19% | Training loss: 0.6876804349774664
Epoch: 37 | Iteration number: [890/4518] 19% | Training loss: 0.6876671564043237
Epoch: 37 | Iteration number: [900/4518] 19% | Training loss: 0.687660113506847
Epoch: 37 | Iteration number: [910/4518] 20% | Training loss: 0.6876425748997992
Epoch: 37 | Iteration number: [920/4518] 20% | Training loss: 0.6876295259465341
Epoch: 37 | Iteration number: [930/4518] 20% | Training loss: 0.6876214268387005
Epoch: 37 | Iteration number: [940/4518] 20% | Training loss: 0.6876035237565954
Epoch: 37 | Iteration number: [950/4518] 21% | Training loss: 0.687593444397575
Epoch: 37 | Iteration number: [960/4518] 21% | Training loss: 0.6875941480199496
Epoch: 37 | Iteration number: [970/4518] 21% | Training loss: 0.6875874868987761
Epoch: 37 | Iteration number: [980/4518] 21% | Training loss: 0.6876002027063953
Epoch: 37 | Iteration number: [990/4518] 21% | Training loss: 0.6875932887347057
Epoch: 37 | Iteration number: [1000/4518] 22% | Training loss: 0.6875816850662232
Epoch: 37 | Iteration number: [1010/4518] 22% | Training loss: 0.6875698574108653
Epoch: 37 | Iteration number: [1020/4518] 22% | Training loss: 0.6875727603248522
Epoch: 37 | Iteration number: [1030/4518] 22% | Training loss: 0.68756538091354
Epoch: 37 | Iteration number: [1040/4518] 23% | Training loss: 0.687560343513122
Epoch: 37 | Iteration number: [1050/4518] 23% | Training loss: 0.6875552750201452
Epoch: 37 | Iteration number: [1060/4518] 23% | Training loss: 0.6875409924196747
Epoch: 37 | Iteration number: [1070/4518] 23% | Training loss: 0.6875429545607522
Epoch: 37 | Iteration number: [1080/4518] 23% | Training loss: 0.6875449984161942
Epoch: 37 | Iteration number: [1090/4518] 24% | Training loss: 0.6875334449317477
Epoch: 37 | Iteration number: [1100/4518] 24% | Training loss: 0.6875339350375262
Epoch: 37 | Iteration number: [1110/4518] 24% | Training loss: 0.6875348570110562
Epoch: 37 | Iteration number: [1120/4518] 24% | Training loss: 0.687530147124614
Epoch: 37 | Iteration number: [1130/4518] 25% | Training loss: 0.6875274886599684
Epoch: 37 | Iteration number: [1140/4518] 25% | Training loss: 0.6875245375068564
Epoch: 37 | Iteration number: [1150/4518] 25% | Training loss: 0.6875095757194187
Epoch: 37 | Iteration number: [1160/4518] 25% | Training loss: 0.6874975763004402
Epoch: 37 | Iteration number: [1170/4518] 25% | Training loss: 0.6874911827409369
Epoch: 37 | Iteration number: [1180/4518] 26% | Training loss: 0.6874911301216837
Epoch: 37 | Iteration number: [1190/4518] 26% | Training loss: 0.6874856362823679
Epoch: 37 | Iteration number: [1200/4518] 26% | Training loss: 0.6874697171151638
Epoch: 37 | Iteration number: [1210/4518] 26% | Training loss: 0.6874656071347639
Epoch: 37 | Iteration number: [1220/4518] 27% | Training loss: 0.6874655970295922
Epoch: 37 | Iteration number: [1230/4518] 27% | Training loss: 0.6874626457206602
Epoch: 37 | Iteration number: [1240/4518] 27% | Training loss: 0.687460047919904
Epoch: 37 | Iteration number: [1250/4518] 27% | Training loss: 0.6874477310657501
Epoch: 37 | Iteration number: [1260/4518] 27% | Training loss: 0.687441092824179
Epoch: 37 | Iteration number: [1270/4518] 28% | Training loss: 0.6874338799104915
Epoch: 37 | Iteration number: [1280/4518] 28% | Training loss: 0.6874274979811161
Epoch: 37 | Iteration number: [1290/4518] 28% | Training loss: 0.6874254794545877
Epoch: 37 | Iteration number: [1300/4518] 28% | Training loss: 0.687417733164934
Epoch: 37 | Iteration number: [1310/4518] 28% | Training loss: 0.6874143194151289
Epoch: 37 | Iteration number: [1320/4518] 29% | Training loss: 0.687397507510402
Epoch: 37 | Iteration number: [1330/4518] 29% | Training loss: 0.6873970744305087
Epoch: 37 | Iteration number: [1340/4518] 29% | Training loss: 0.6873996530006181
Epoch: 37 | Iteration number: [1350/4518] 29% | Training loss: 0.6873920807132015
Epoch: 37 | Iteration number: [1360/4518] 30% | Training loss: 0.6873933271450154
Epoch: 37 | Iteration number: [1370/4518] 30% | Training loss: 0.6873917624463131
Epoch: 37 | Iteration number: [1380/4518] 30% | Training loss: 0.6873880913292152
Epoch: 37 | Iteration number: [1390/4518] 30% | Training loss: 0.6873793970766685
Epoch: 37 | Iteration number: [1400/4518] 30% | Training loss: 0.6873828695927348
Epoch: 37 | Iteration number: [1410/4518] 31% | Training loss: 0.6873732401546857
Epoch: 37 | Iteration number: [1420/4518] 31% | Training loss: 0.687379408134541
Epoch: 37 | Iteration number: [1430/4518] 31% | Training loss: 0.6873772252272893
Epoch: 37 | Iteration number: [1440/4518] 31% | Training loss: 0.6873691336976158
Epoch: 37 | Iteration number: [1450/4518] 32% | Training loss: 0.6873696944631379
Epoch: 37 | Iteration number: [1460/4518] 32% | Training loss: 0.6873581768306968
Epoch: 37 | Iteration number: [1470/4518] 32% | Training loss: 0.687356986885979
Epoch: 37 | Iteration number: [1480/4518] 32% | Training loss: 0.6873472198038488
Epoch: 37 | Iteration number: [1490/4518] 32% | Training loss: 0.687348589361114
Epoch: 37 | Iteration number: [1500/4518] 33% | Training loss: 0.687346033612887
Epoch: 37 | Iteration number: [1510/4518] 33% | Training loss: 0.6873375554353196
Epoch: 37 | Iteration number: [1520/4518] 33% | Training loss: 0.6873363944260698
Epoch: 37 | Iteration number: [1530/4518] 33% | Training loss: 0.6873407320649016
Epoch: 37 | Iteration number: [1540/4518] 34% | Training loss: 0.6873492328764557
Epoch: 37 | Iteration number: [1550/4518] 34% | Training loss: 0.6873454390033599
Epoch: 37 | Iteration number: [1560/4518] 34% | Training loss: 0.6873384984257894
Epoch: 37 | Iteration number: [1570/4518] 34% | Training loss: 0.6873307441070581
Epoch: 37 | Iteration number: [1580/4518] 34% | Training loss: 0.6873165202291706
Epoch: 37 | Iteration number: [1590/4518] 35% | Training loss: 0.6873160346499029
Epoch: 37 | Iteration number: [1600/4518] 35% | Training loss: 0.6873103208839894
Epoch: 37 | Iteration number: [1610/4518] 35% | Training loss: 0.687305429300166
Epoch: 37 | Iteration number: [1620/4518] 35% | Training loss: 0.6873002328254558
Epoch: 37 | Iteration number: [1630/4518] 36% | Training loss: 0.687302656883111
Epoch: 37 | Iteration number: [1640/4518] 36% | Training loss: 0.6872979295689885
Epoch: 37 | Iteration number: [1650/4518] 36% | Training loss: 0.687300949494044
Epoch: 37 | Iteration number: [1660/4518] 36% | Training loss: 0.6873000399175897
Epoch: 37 | Iteration number: [1670/4518] 36% | Training loss: 0.6872920246538288
Epoch: 37 | Iteration number: [1680/4518] 37% | Training loss: 0.6872911198153382
Epoch: 37 | Iteration number: [1690/4518] 37% | Training loss: 0.6872904876632804
Epoch: 37 | Iteration number: [1700/4518] 37% | Training loss: 0.6872904744919609
Epoch: 37 | Iteration number: [1710/4518] 37% | Training loss: 0.6872880342062454
Epoch: 37 | Iteration number: [1720/4518] 38% | Training loss: 0.6872785655218502
Epoch: 37 | Iteration number: [1730/4518] 38% | Training loss: 0.6872831986818699
Epoch: 37 | Iteration number: [1740/4518] 38% | Training loss: 0.6872835588866266
Epoch: 37 | Iteration number: [1750/4518] 38% | Training loss: 0.6872764348302569
Epoch: 37 | Iteration number: [1760/4518] 38% | Training loss: 0.6872720661827109
Epoch: 37 | Iteration number: [1770/4518] 39% | Training loss: 0.6872722198734176
Epoch: 37 | Iteration number: [1780/4518] 39% | Training loss: 0.6872637470116776
Epoch: 37 | Iteration number: [1790/4518] 39% | Training loss: 0.6872647797595189
Epoch: 37 | Iteration number: [1800/4518] 39% | Training loss: 0.6872693603899744
Epoch: 37 | Iteration number: [1810/4518] 40% | Training loss: 0.6872587895854402
Epoch: 37 | Iteration number: [1820/4518] 40% | Training loss: 0.6872550640132401
Epoch: 37 | Iteration number: [1830/4518] 40% | Training loss: 0.6872493325361138
Epoch: 37 | Iteration number: [1840/4518] 40% | Training loss: 0.6872442835698958
Epoch: 37 | Iteration number: [1850/4518] 40% | Training loss: 0.687238720913191
Epoch: 37 | Iteration number: [1860/4518] 41% | Training loss: 0.6872376430098729
Epoch: 37 | Iteration number: [1870/4518] 41% | Training loss: 0.6872293766488365
Epoch: 37 | Iteration number: [1880/4518] 41% | Training loss: 0.6872241231038215
Epoch: 37 | Iteration number: [1890/4518] 41% | Training loss: 0.687228710468484
Epoch: 37 | Iteration number: [1900/4518] 42% | Training loss: 0.6872293503660905
Epoch: 37 | Iteration number: [1910/4518] 42% | Training loss: 0.687229375907888
Epoch: 37 | Iteration number: [1920/4518] 42% | Training loss: 0.6872221694638332
Epoch: 37 | Iteration number: [1930/4518] 42% | Training loss: 0.6872199389601
Epoch: 37 | Iteration number: [1940/4518] 42% | Training loss: 0.6872175842216335
Epoch: 37 | Iteration number: [1950/4518] 43% | Training loss: 0.6872176309732291
Epoch: 37 | Iteration number: [1960/4518] 43% | Training loss: 0.6872136733969864
Epoch: 37 | Iteration number: [1970/4518] 43% | Training loss: 0.6872086996051866
Epoch: 37 | Iteration number: [1980/4518] 43% | Training loss: 0.6872039431273335
Epoch: 37 | Iteration number: [1990/4518] 44% | Training loss: 0.6872019289426469
Epoch: 37 | Iteration number: [2000/4518] 44% | Training loss: 0.6871988850831986
Epoch: 37 | Iteration number: [2010/4518] 44% | Training loss: 0.6871989342407208
Epoch: 37 | Iteration number: [2020/4518] 44% | Training loss: 0.6871962571793263
Epoch: 37 | Iteration number: [2030/4518] 44% | Training loss: 0.6871913388738491
Epoch: 37 | Iteration number: [2040/4518] 45% | Training loss: 0.6871832640732036
Epoch: 37 | Iteration number: [2050/4518] 45% | Training loss: 0.6871798421406164
Epoch: 37 | Iteration number: [2060/4518] 45% | Training loss: 0.6871787799504196
Epoch: 37 | Iteration number: [2070/4518] 45% | Training loss: 0.6871736191033165
Epoch: 37 | Iteration number: [2080/4518] 46% | Training loss: 0.6871706672299367
Epoch: 37 | Iteration number: [2090/4518] 46% | Training loss: 0.6871668721215006
Epoch: 37 | Iteration number: [2100/4518] 46% | Training loss: 0.6871652183362416
Epoch: 37 | Iteration number: [2110/4518] 46% | Training loss: 0.6871625364109238
Epoch: 37 | Iteration number: [2120/4518] 46% | Training loss: 0.6871626766503982
Epoch: 37 | Iteration number: [2130/4518] 47% | Training loss: 0.6871626523738735
Epoch: 37 | Iteration number: [2140/4518] 47% | Training loss: 0.6871612065863386
Epoch: 37 | Iteration number: [2150/4518] 47% | Training loss: 0.6871598252307537
Epoch: 37 | Iteration number: [2160/4518] 47% | Training loss: 0.6871611354803597
Epoch: 37 | Iteration number: [2170/4518] 48% | Training loss: 0.6871628191064579
Epoch: 37 | Iteration number: [2180/4518] 48% | Training loss: 0.687156423625596
Epoch: 37 | Iteration number: [2190/4518] 48% | Training loss: 0.6871538524213991
Epoch: 37 | Iteration number: [2200/4518] 48% | Training loss: 0.6871455532041463
Epoch: 37 | Iteration number: [2210/4518] 48% | Training loss: 0.6871410572420957
Epoch: 37 | Iteration number: [2220/4518] 49% | Training loss: 0.6871395732636925
Epoch: 37 | Iteration number: [2230/4518] 49% | Training loss: 0.687138806731177
Epoch: 37 | Iteration number: [2240/4518] 49% | Training loss: 0.6871344579915916
Epoch: 37 | Iteration number: [2250/4518] 49% | Training loss: 0.6871358685493469
Epoch: 37 | Iteration number: [2260/4518] 50% | Training loss: 0.6871291297990664
Epoch: 37 | Iteration number: [2270/4518] 50% | Training loss: 0.6871282199668464
Epoch: 37 | Iteration number: [2280/4518] 50% | Training loss: 0.6871235680946133
Epoch: 37 | Iteration number: [2290/4518] 50% | Training loss: 0.6871218429382191
Epoch: 37 | Iteration number: [2300/4518] 50% | Training loss: 0.68712168701317
Epoch: 37 | Iteration number: [2310/4518] 51% | Training loss: 0.6871198464781691
Epoch: 37 | Iteration number: [2320/4518] 51% | Training loss: 0.6871176362037659
Epoch: 37 | Iteration number: [2330/4518] 51% | Training loss: 0.6871154601737665
Epoch: 37 | Iteration number: [2340/4518] 51% | Training loss: 0.6871124097424695
Epoch: 37 | Iteration number: [2350/4518] 52% | Training loss: 0.6871086966737788
Epoch: 37 | Iteration number: [2360/4518] 52% | Training loss: 0.6871089188729302
Epoch: 37 | Iteration number: [2370/4518] 52% | Training loss: 0.6871043043046058
Epoch: 37 | Iteration number: [2380/4518] 52% | Training loss: 0.6871044615236651
Epoch: 37 | Iteration number: [2390/4518] 52% | Training loss: 0.687101672433909
Epoch: 37 | Iteration number: [2400/4518] 53% | Training loss: 0.6870964694271485
Epoch: 37 | Iteration number: [2410/4518] 53% | Training loss: 0.6870930733027795
Epoch: 37 | Iteration number: [2420/4518] 53% | Training loss: 0.6870872002987822
Epoch: 37 | Iteration number: [2430/4518] 53% | Training loss: 0.6870850568200335
Epoch: 37 | Iteration number: [2440/4518] 54% | Training loss: 0.6870816610875677
Epoch: 37 | Iteration number: [2450/4518] 54% | Training loss: 0.6870812683932636
Epoch: 37 | Iteration number: [2460/4518] 54% | Training loss: 0.6870841345166773
Epoch: 37 | Iteration number: [2470/4518] 54% | Training loss: 0.6870832755498075
Epoch: 37 | Iteration number: [2480/4518] 54% | Training loss: 0.6870815377802618
Epoch: 37 | Iteration number: [2490/4518] 55% | Training loss: 0.6870849710631083
Epoch: 37 | Iteration number: [2500/4518] 55% | Training loss: 0.6870920985937119
Epoch: 37 | Iteration number: [2510/4518] 55% | Training loss: 0.687094964496643
Epoch: 37 | Iteration number: [2520/4518] 55% | Training loss: 0.6870969499150912
Epoch: 37 | Iteration number: [2530/4518] 55% | Training loss: 0.6870950023647353
Epoch: 37 | Iteration number: [2540/4518] 56% | Training loss: 0.6870986280244167
Epoch: 37 | Iteration number: [2550/4518] 56% | Training loss: 0.6870937816068238
Epoch: 37 | Iteration number: [2560/4518] 56% | Training loss: 0.6870955544523895
Epoch: 37 | Iteration number: [2570/4518] 56% | Training loss: 0.6870963341531122
Epoch: 37 | Iteration number: [2580/4518] 57% | Training loss: 0.6870935986439387
Epoch: 37 | Iteration number: [2590/4518] 57% | Training loss: 0.6870904710532155
Epoch: 37 | Iteration number: [2600/4518] 57% | Training loss: 0.6870913531230046
Epoch: 37 | Iteration number: [2610/4518] 57% | Training loss: 0.687099266737357
Epoch: 37 | Iteration number: [2620/4518] 57% | Training loss: 0.6870991639963543
Epoch: 37 | Iteration number: [2630/4518] 58% | Training loss: 0.6871008387989871
Epoch: 37 | Iteration number: [2640/4518] 58% | Training loss: 0.687098165736957
Epoch: 37 | Iteration number: [2650/4518] 58% | Training loss: 0.6871041994049863
Epoch: 37 | Iteration number: [2660/4518] 58% | Training loss: 0.6871030849173553
Epoch: 37 | Iteration number: [2670/4518] 59% | Training loss: 0.6871005922667542
Epoch: 37 | Iteration number: [2680/4518] 59% | Training loss: 0.6870977664616571
Epoch: 37 | Iteration number: [2690/4518] 59% | Training loss: 0.6870996261174794
Epoch: 37 | Iteration number: [2700/4518] 59% | Training loss: 0.6871021067213129
Epoch: 37 | Iteration number: [2710/4518] 59% | Training loss: 0.6871020540760012
Epoch: 37 | Iteration number: [2720/4518] 60% | Training loss: 0.6871048083857578
Epoch: 37 | Iteration number: [2730/4518] 60% | Training loss: 0.6871027528366327
Epoch: 37 | Iteration number: [2740/4518] 60% | Training loss: 0.6871032295000814
Epoch: 37 | Iteration number: [2750/4518] 60% | Training loss: 0.68709841819243
Epoch: 37 | Iteration number: [2760/4518] 61% | Training loss: 0.6871004178256228
Epoch: 37 | Iteration number: [2770/4518] 61% | Training loss: 0.6871001823068956
Epoch: 37 | Iteration number: [2780/4518] 61% | Training loss: 0.6871048207120072
Epoch: 37 | Iteration number: [2790/4518] 61% | Training loss: 0.6871029607070389
Epoch: 37 | Iteration number: [2800/4518] 61% | Training loss: 0.6871022234431335
Epoch: 37 | Iteration number: [2810/4518] 62% | Training loss: 0.6870976222367473
Epoch: 37 | Iteration number: [2820/4518] 62% | Training loss: 0.6870955159055426
Epoch: 37 | Iteration number: [2830/4518] 62% | Training loss: 0.6870983586926342
Epoch: 37 | Iteration number: [2840/4518] 62% | Training loss: 0.6870937016018679
Epoch: 37 | Iteration number: [2850/4518] 63% | Training loss: 0.6870968687325193
Epoch: 37 | Iteration number: [2860/4518] 63% | Training loss: 0.687098571220478
Epoch: 37 | Iteration number: [2870/4518] 63% | Training loss: 0.6871012175747742
Epoch: 37 | Iteration number: [2880/4518] 63% | Training loss: 0.6870967471351226
Epoch: 37 | Iteration number: [2890/4518] 63% | Training loss: 0.6870958641119894
Epoch: 37 | Iteration number: [2900/4518] 64% | Training loss: 0.6870930740751069
Epoch: 37 | Iteration number: [2910/4518] 64% | Training loss: 0.6870967347392511
Epoch: 37 | Iteration number: [2920/4518] 64% | Training loss: 0.6870972641935087
Epoch: 37 | Iteration number: [2930/4518] 64% | Training loss: 0.687095638590868
Epoch: 37 | Iteration number: [2940/4518] 65% | Training loss: 0.6870940642900207
Epoch: 37 | Iteration number: [2950/4518] 65% | Training loss: 0.6870965990777743
Epoch: 37 | Iteration number: [2960/4518] 65% | Training loss: 0.6870972852247792
Epoch: 37 | Iteration number: [2970/4518] 65% | Training loss: 0.6870958283292725
Epoch: 37 | Iteration number: [2980/4518] 65% | Training loss: 0.6870985785586722
Epoch: 37 | Iteration number: [2990/4518] 66% | Training loss: 0.687099097305317
Epoch: 37 | Iteration number: [3000/4518] 66% | Training loss: 0.6870971522728602
Epoch: 37 | Iteration number: [3010/4518] 66% | Training loss: 0.6870925989657938
Epoch: 37 | Iteration number: [3020/4518] 66% | Training loss: 0.687097144403205
Epoch: 37 | Iteration number: [3030/4518] 67% | Training loss: 0.6870948819240721
Epoch: 37 | Iteration number: [3040/4518] 67% | Training loss: 0.6870969630777836
Epoch: 37 | Iteration number: [3050/4518] 67% | Training loss: 0.6870964617221081
Epoch: 37 | Iteration number: [3060/4518] 67% | Training loss: 0.687095835980247
Epoch: 37 | Iteration number: [3070/4518] 67% | Training loss: 0.6870921503449108
Epoch: 37 | Iteration number: [3080/4518] 68% | Training loss: 0.6870875373289183
Epoch: 37 | Iteration number: [3090/4518] 68% | Training loss: 0.6870911616144828
Epoch: 37 | Iteration number: [3100/4518] 68% | Training loss: 0.687089234186757
Epoch: 37 | Iteration number: [3110/4518] 68% | Training loss: 0.6870899820826061
Epoch: 37 | Iteration number: [3120/4518] 69% | Training loss: 0.6870905844829022
Epoch: 37 | Iteration number: [3130/4518] 69% | Training loss: 0.687089833702904
Epoch: 37 | Iteration number: [3140/4518] 69% | Training loss: 0.6870899196832803
Epoch: 37 | Iteration number: [3150/4518] 69% | Training loss: 0.6870859660231878
Epoch: 37 | Iteration number: [3160/4518] 69% | Training loss: 0.6870850445349005
Epoch: 37 | Iteration number: [3170/4518] 70% | Training loss: 0.6870855011210457
Epoch: 37 | Iteration number: [3180/4518] 70% | Training loss: 0.6870853335789915
Epoch: 37 | Iteration number: [3190/4518] 70% | Training loss: 0.6870842454949143
Epoch: 37 | Iteration number: [3200/4518] 70% | Training loss: 0.6870869226008653
Epoch: 37 | Iteration number: [3210/4518] 71% | Training loss: 0.6870852820041395
Epoch: 37 | Iteration number: [3220/4518] 71% | Training loss: 0.6870819663038905
Epoch: 37 | Iteration number: [3230/4518] 71% | Training loss: 0.6870786730165452
Epoch: 37 | Iteration number: [3240/4518] 71% | Training loss: 0.6870782712359488
Epoch: 37 | Iteration number: [3250/4518] 71% | Training loss: 0.6870801027004535
Epoch: 37 | Iteration number: [3260/4518] 72% | Training loss: 0.6870787424361048
Epoch: 37 | Iteration number: [3270/4518] 72% | Training loss: 0.6870763543366657
Epoch: 37 | Iteration number: [3280/4518] 72% | Training loss: 0.6870776216976526
Epoch: 37 | Iteration number: [3290/4518] 72% | Training loss: 0.6870758874256923
Epoch: 37 | Iteration number: [3300/4518] 73% | Training loss: 0.6870772772304939
Epoch: 37 | Iteration number: [3310/4518] 73% | Training loss: 0.6870752143535729
Epoch: 37 | Iteration number: [3320/4518] 73% | Training loss: 0.6870720046650932
Epoch: 37 | Iteration number: [3330/4518] 73% | Training loss: 0.6870712780379676
Epoch: 37 | Iteration number: [3340/4518] 73% | Training loss: 0.6870719777966687
Epoch: 37 | Iteration number: [3350/4518] 74% | Training loss: 0.6870703470529015
Epoch: 37 | Iteration number: [3360/4518] 74% | Training loss: 0.6870703527083
Epoch: 37 | Iteration number: [3370/4518] 74% | Training loss: 0.6870735231599043
Epoch: 37 | Iteration number: [3380/4518] 74% | Training loss: 0.687071236156853
Epoch: 37 | Iteration number: [3390/4518] 75% | Training loss: 0.6870711557808878
Epoch: 37 | Iteration number: [3400/4518] 75% | Training loss: 0.687068933791974
Epoch: 37 | Iteration number: [3410/4518] 75% | Training loss: 0.6870684684721255
Epoch: 37 | Iteration number: [3420/4518] 75% | Training loss: 0.6870696353633501
Epoch: 37 | Iteration number: [3430/4518] 75% | Training loss: 0.6870642412508194
Epoch: 37 | Iteration number: [3440/4518] 76% | Training loss: 0.6870620247756326
Epoch: 37 | Iteration number: [3450/4518] 76% | Training loss: 0.6870607581864233
Epoch: 37 | Iteration number: [3460/4518] 76% | Training loss: 0.687058661766135
Epoch: 37 | Iteration number: [3470/4518] 76% | Training loss: 0.6870574852575143
Epoch: 37 | Iteration number: [3480/4518] 77% | Training loss: 0.6870527815544742
Epoch: 37 | Iteration number: [3490/4518] 77% | Training loss: 0.6870521135009121
Epoch: 37 | Iteration number: [3500/4518] 77% | Training loss: 0.6870515892675945
Epoch: 37 | Iteration number: [3510/4518] 77% | Training loss: 0.6870505903181527
Epoch: 37 | Iteration number: [3520/4518] 77% | Training loss: 0.6870448749851097
Epoch: 37 | Iteration number: [3530/4518] 78% | Training loss: 0.6870411443305083
Epoch: 37 | Iteration number: [3540/4518] 78% | Training loss: 0.6870420052843579
Epoch: 37 | Iteration number: [3550/4518] 78% | Training loss: 0.6870439174141683
Epoch: 37 | Iteration number: [3560/4518] 78% | Training loss: 0.6870418769757399
Epoch: 37 | Iteration number: [3570/4518] 79% | Training loss: 0.6870370552152478
Epoch: 37 | Iteration number: [3580/4518] 79% | Training loss: 0.6870331459205243
Epoch: 37 | Iteration number: [3590/4518] 79% | Training loss: 0.6870305364676504
Epoch: 37 | Iteration number: [3600/4518] 79% | Training loss: 0.6870276241170036
Epoch: 37 | Iteration number: [3610/4518] 79% | Training loss: 0.6870280355792957
Epoch: 37 | Iteration number: [3620/4518] 80% | Training loss: 0.6870276964995083
Epoch: 37 | Iteration number: [3630/4518] 80% | Training loss: 0.6870258918314269
Epoch: 37 | Iteration number: [3640/4518] 80% | Training loss: 0.6870295333174559
Epoch: 37 | Iteration number: [3650/4518] 80% | Training loss: 0.687028893803897
Epoch: 37 | Iteration number: [3660/4518] 81% | Training loss: 0.6870299203474014
Epoch: 37 | Iteration number: [3670/4518] 81% | Training loss: 0.6870306623404292
Epoch: 37 | Iteration number: [3680/4518] 81% | Training loss: 0.6870298650439667
Epoch: 37 | Iteration number: [3690/4518] 81% | Training loss: 0.6870342010728065
Epoch: 37 | Iteration number: [3700/4518] 81% | Training loss: 0.6870347778056118
Epoch: 37 | Iteration number: [3710/4518] 82% | Training loss: 0.6870337822205936
Epoch: 37 | Iteration number: [3720/4518] 82% | Training loss: 0.6870303639481145
Epoch: 37 | Iteration number: [3730/4518] 82% | Training loss: 0.6870300010286132
Epoch: 37 | Iteration number: [3740/4518] 82% | Training loss: 0.6870296528791999
Epoch: 37 | Iteration number: [3750/4518] 83% | Training loss: 0.6870290478865305
Epoch: 37 | Iteration number: [3760/4518] 83% | Training loss: 0.6870255493737282
Epoch: 37 | Iteration number: [3770/4518] 83% | Training loss: 0.6870225556333122
Epoch: 37 | Iteration number: [3780/4518] 83% | Training loss: 0.6870223738844432
Epoch: 37 | Iteration number: [3790/4518] 83% | Training loss: 0.6870199110073905
Epoch: 37 | Iteration number: [3800/4518] 84% | Training loss: 0.6870202106864829
Epoch: 37 | Iteration number: [3810/4518] 84% | Training loss: 0.6870188971829853
Epoch: 37 | Iteration number: [3820/4518] 84% | Training loss: 0.6870165760916566
Epoch: 37 | Iteration number: [3830/4518] 84% | Training loss: 0.6870178228570026
Epoch: 37 | Iteration number: [3840/4518] 84% | Training loss: 0.6870193040619293
Epoch: 37 | Iteration number: [3850/4518] 85% | Training loss: 0.6870186718717798
Epoch: 37 | Iteration number: [3860/4518] 85% | Training loss: 0.6870144405667646
Epoch: 37 | Iteration number: [3870/4518] 85% | Training loss: 0.6870115483145998
Epoch: 37 | Iteration number: [3880/4518] 85% | Training loss: 0.6870111582973568
Epoch: 37 | Iteration number: [3890/4518] 86% | Training loss: 0.687015097444652
Epoch: 37 | Iteration number: [3900/4518] 86% | Training loss: 0.6870145758604392
Epoch: 37 | Iteration number: [3910/4518] 86% | Training loss: 0.6870124911103407
Epoch: 37 | Iteration number: [3920/4518] 86% | Training loss: 0.68701294304765
Epoch: 37 | Iteration number: [3930/4518] 86% | Training loss: 0.6870103921447395
Epoch: 37 | Iteration number: [3940/4518] 87% | Training loss: 0.6870102331874334
Epoch: 37 | Iteration number: [3950/4518] 87% | Training loss: 0.6870062948782233
Epoch: 37 | Iteration number: [3960/4518] 87% | Training loss: 0.6870071975570736
Epoch: 37 | Iteration number: [3970/4518] 87% | Training loss: 0.687006507622505
Epoch: 37 | Iteration number: [3980/4518] 88% | Training loss: 0.6870050538874152
Epoch: 37 | Iteration number: [3990/4518] 88% | Training loss: 0.6870068828563642
Epoch: 37 | Iteration number: [4000/4518] 88% | Training loss: 0.6870056138187647
Epoch: 37 | Iteration number: [4010/4518] 88% | Training loss: 0.6870055001572778
Epoch: 37 | Iteration number: [4020/4518] 88% | Training loss: 0.6870043014412496
Epoch: 37 | Iteration number: [4030/4518] 89% | Training loss: 0.6870036508250177
Epoch: 37 | Iteration number: [4040/4518] 89% | Training loss: 0.6870027213846103
Epoch: 37 | Iteration number: [4050/4518] 89% | Training loss: 0.6870045062789211
Epoch: 37 | Iteration number: [4060/4518] 89% | Training loss: 0.6870030891278694
Epoch: 37 | Iteration number: [4070/4518] 90% | Training loss: 0.6870043205541241
Epoch: 37 | Iteration number: [4080/4518] 90% | Training loss: 0.687001970381129
Epoch: 37 | Iteration number: [4090/4518] 90% | Training loss: 0.6870020484283093
Epoch: 37 | Iteration number: [4100/4518] 90% | Training loss: 0.6870038855221213
Epoch: 37 | Iteration number: [4110/4518] 90% | Training loss: 0.6870053019981894
Epoch: 37 | Iteration number: [4120/4518] 91% | Training loss: 0.6870054316752165
Epoch: 37 | Iteration number: [4130/4518] 91% | Training loss: 0.6870038070343886
Epoch: 37 | Iteration number: [4140/4518] 91% | Training loss: 0.6870042675503211
Epoch: 37 | Iteration number: [4150/4518] 91% | Training loss: 0.6870038637482976
Epoch: 37 | Iteration number: [4160/4518] 92% | Training loss: 0.6870082947927025
Epoch: 37 | Iteration number: [4170/4518] 92% | Training loss: 0.6870048947471509
Epoch: 37 | Iteration number: [4180/4518] 92% | Training loss: 0.6870035119033886
Epoch: 37 | Iteration number: [4190/4518] 92% | Training loss: 0.6870037694961757
Epoch: 37 | Iteration number: [4200/4518] 92% | Training loss: 0.6870026860066822
Epoch: 37 | Iteration number: [4210/4518] 93% | Training loss: 0.6870058339310372
Epoch: 37 | Iteration number: [4220/4518] 93% | Training loss: 0.6870029327005007
Epoch: 37 | Iteration number: [4230/4518] 93% | Training loss: 0.6870040328085564
Epoch: 37 | Iteration number: [4240/4518] 93% | Training loss: 0.6870008632540703
Epoch: 37 | Iteration number: [4250/4518] 94% | Training loss: 0.6870017000226414
Epoch: 37 | Iteration number: [4260/4518] 94% | Training loss: 0.687002599631117
Epoch: 37 | Iteration number: [4270/4518] 94% | Training loss: 0.6870031293437967
Epoch: 37 | Iteration number: [4280/4518] 94% | Training loss: 0.6870006407811263
Epoch: 37 | Iteration number: [4290/4518] 94% | Training loss: 0.6870005161890061
Epoch: 37 | Iteration number: [4300/4518] 95% | Training loss: 0.6870042913459068
Epoch: 37 | Iteration number: [4310/4518] 95% | Training loss: 0.687003822780264
Epoch: 37 | Iteration number: [4320/4518] 95% | Training loss: 0.687000540478362
Epoch: 37 | Iteration number: [4330/4518] 95% | Training loss: 0.6869999723814376
Epoch: 37 | Iteration number: [4340/4518] 96% | Training loss: 0.6869994611372047
Epoch: 37 | Iteration number: [4350/4518] 96% | Training loss: 0.6870003983481177
Epoch: 37 | Iteration number: [4360/4518] 96% | Training loss: 0.6869989816065228
Epoch: 37 | Iteration number: [4370/4518] 96% | Training loss: 0.686997621023955
Epoch: 37 | Iteration number: [4380/4518] 96% | Training loss: 0.6869955099880968
Epoch: 37 | Iteration number: [4390/4518] 97% | Training loss: 0.6869988919933727
Epoch: 37 | Iteration number: [4400/4518] 97% | Training loss: 0.6869995960999619
Epoch: 37 | Iteration number: [4410/4518] 97% | Training loss: 0.687001277016404
Epoch: 37 | Iteration number: [4420/4518] 97% | Training loss: 0.6870015796493082
Epoch: 37 | Iteration number: [4430/4518] 98% | Training loss: 0.6869979077214312
Epoch: 37 | Iteration number: [4440/4518] 98% | Training loss: 0.6869975846629959
Epoch: 37 | Iteration number: [4450/4518] 98% | Training loss: 0.6869953222221203
Epoch: 37 | Iteration number: [4460/4518] 98% | Training loss: 0.6869953743679107
Epoch: 37 | Iteration number: [4470/4518] 98% | Training loss: 0.6869901321878369
Epoch: 37 | Iteration number: [4480/4518] 99% | Training loss: 0.6869886711505907
Epoch: 37 | Iteration number: [4490/4518] 99% | Training loss: 0.6869897208128847
Epoch: 37 | Iteration number: [4500/4518] 99% | Training loss: 0.6869874446524514
Epoch: 37 | Iteration number: [4510/4518] 99% | Training loss: 0.6869888255707176

 End of epoch: 37 | Train Loss: 0.6868363825844261 | Training Time: 641 

 End of epoch: 37 | Eval Loss: 0.6900178413001858 | Evaluating Time: 17 
Epoch: 38 | Iteration number: [10/4518] 0% | Training loss: 0.7557091236114502
Epoch: 38 | Iteration number: [20/4518] 0% | Training loss: 0.7216466516256332
Epoch: 38 | Iteration number: [30/4518] 0% | Training loss: 0.7101148585478465
Epoch: 38 | Iteration number: [40/4518] 0% | Training loss: 0.7041605919599533
Epoch: 38 | Iteration number: [50/4518] 1% | Training loss: 0.700803439617157
Epoch: 38 | Iteration number: [60/4518] 1% | Training loss: 0.698227130373319
Epoch: 38 | Iteration number: [70/4518] 1% | Training loss: 0.6966659273420062
Epoch: 38 | Iteration number: [80/4518] 1% | Training loss: 0.6954921320080757
Epoch: 38 | Iteration number: [90/4518] 1% | Training loss: 0.6944689479139116
Epoch: 38 | Iteration number: [100/4518] 2% | Training loss: 0.6936950260400772
Epoch: 38 | Iteration number: [110/4518] 2% | Training loss: 0.6930739619515159
Epoch: 38 | Iteration number: [120/4518] 2% | Training loss: 0.6925394584735235
Epoch: 38 | Iteration number: [130/4518] 2% | Training loss: 0.6920902353066665
Epoch: 38 | Iteration number: [140/4518] 3% | Training loss: 0.6917205252817699
Epoch: 38 | Iteration number: [150/4518] 3% | Training loss: 0.6914580428600311
Epoch: 38 | Iteration number: [160/4518] 3% | Training loss: 0.691233467310667
Epoch: 38 | Iteration number: [170/4518] 3% | Training loss: 0.6909356499419493
Epoch: 38 | Iteration number: [180/4518] 3% | Training loss: 0.6906984213325712
Epoch: 38 | Iteration number: [190/4518] 4% | Training loss: 0.6903911192166178
Epoch: 38 | Iteration number: [200/4518] 4% | Training loss: 0.690210942029953
Epoch: 38 | Iteration number: [210/4518] 4% | Training loss: 0.6900400263922555
Epoch: 38 | Iteration number: [220/4518] 4% | Training loss: 0.6899012589996512
Epoch: 38 | Iteration number: [230/4518] 5% | Training loss: 0.6897491333277329
Epoch: 38 | Iteration number: [240/4518] 5% | Training loss: 0.6896666516860326
Epoch: 38 | Iteration number: [250/4518] 5% | Training loss: 0.6895318500995636
Epoch: 38 | Iteration number: [260/4518] 5% | Training loss: 0.6894246546121744
Epoch: 38 | Iteration number: [270/4518] 5% | Training loss: 0.6893119469836906
Epoch: 38 | Iteration number: [280/4518] 6% | Training loss: 0.6892313312206949
Epoch: 38 | Iteration number: [290/4518] 6% | Training loss: 0.6890917506711236
Epoch: 38 | Iteration number: [300/4518] 6% | Training loss: 0.689003787835439
Epoch: 38 | Iteration number: [310/4518] 6% | Training loss: 0.6889650191030194
Epoch: 38 | Iteration number: [320/4518] 7% | Training loss: 0.6888885190710425
Epoch: 38 | Iteration number: [330/4518] 7% | Training loss: 0.6888268246795192
Epoch: 38 | Iteration number: [340/4518] 7% | Training loss: 0.6887507882188348
Epoch: 38 | Iteration number: [350/4518] 7% | Training loss: 0.6886864825657436
Epoch: 38 | Iteration number: [360/4518] 7% | Training loss: 0.6886719531483121
Epoch: 38 | Iteration number: [370/4518] 8% | Training loss: 0.6886035327975815
Epoch: 38 | Iteration number: [380/4518] 8% | Training loss: 0.6885665557886425
Epoch: 38 | Iteration number: [390/4518] 8% | Training loss: 0.6885311264258165
Epoch: 38 | Iteration number: [400/4518] 8% | Training loss: 0.6884985445439815
Epoch: 38 | Iteration number: [410/4518] 9% | Training loss: 0.6884501998017474
Epoch: 38 | Iteration number: [420/4518] 9% | Training loss: 0.6884134915612993
Epoch: 38 | Iteration number: [430/4518] 9% | Training loss: 0.6883833610734275
Epoch: 38 | Iteration number: [440/4518] 9% | Training loss: 0.6883427335457368
Epoch: 38 | Iteration number: [450/4518] 9% | Training loss: 0.6882981945408715
Epoch: 38 | Iteration number: [460/4518] 10% | Training loss: 0.6882718186015668
Epoch: 38 | Iteration number: [470/4518] 10% | Training loss: 0.6882476006416565
Epoch: 38 | Iteration number: [480/4518] 10% | Training loss: 0.6882192437847455
Epoch: 38 | Iteration number: [490/4518] 10% | Training loss: 0.6882042416504451
Epoch: 38 | Iteration number: [500/4518] 11% | Training loss: 0.688168070435524
Epoch: 38 | Iteration number: [510/4518] 11% | Training loss: 0.6881329309706594
Epoch: 38 | Iteration number: [520/4518] 11% | Training loss: 0.6880778854856124
Epoch: 38 | Iteration number: [530/4518] 11% | Training loss: 0.6880584660566078
Epoch: 38 | Iteration number: [540/4518] 11% | Training loss: 0.6880392171718456
Epoch: 38 | Iteration number: [550/4518] 12% | Training loss: 0.6880213939059865
Epoch: 38 | Iteration number: [560/4518] 12% | Training loss: 0.6880011003996644
Epoch: 38 | Iteration number: [570/4518] 12% | Training loss: 0.6879976871766542
Epoch: 38 | Iteration number: [580/4518] 12% | Training loss: 0.6879663874363077
Epoch: 38 | Iteration number: [590/4518] 13% | Training loss: 0.6879498019056806
Epoch: 38 | Iteration number: [600/4518] 13% | Training loss: 0.6879316202799479
Epoch: 38 | Iteration number: [610/4518] 13% | Training loss: 0.6879136701099208
Epoch: 38 | Iteration number: [620/4518] 13% | Training loss: 0.6878996064586024
Epoch: 38 | Iteration number: [630/4518] 13% | Training loss: 0.6878777581547934
Epoch: 38 | Iteration number: [640/4518] 14% | Training loss: 0.6878651521168649
Epoch: 38 | Iteration number: [650/4518] 14% | Training loss: 0.6878365832108718
Epoch: 38 | Iteration number: [660/4518] 14% | Training loss: 0.6878232304797028
Epoch: 38 | Iteration number: [670/4518] 14% | Training loss: 0.6877942995348973
Epoch: 38 | Iteration number: [680/4518] 15% | Training loss: 0.687767639493241
Epoch: 38 | Iteration number: [690/4518] 15% | Training loss: 0.6877598914547243
Epoch: 38 | Iteration number: [700/4518] 15% | Training loss: 0.6877404274259294
Epoch: 38 | Iteration number: [710/4518] 15% | Training loss: 0.6877213330336021
Epoch: 38 | Iteration number: [720/4518] 15% | Training loss: 0.6877229111889999
Epoch: 38 | Iteration number: [730/4518] 16% | Training loss: 0.6877074667035716
Epoch: 38 | Iteration number: [740/4518] 16% | Training loss: 0.6876754132477013
Epoch: 38 | Iteration number: [750/4518] 16% | Training loss: 0.687658071756363
Epoch: 38 | Iteration number: [760/4518] 16% | Training loss: 0.6876546479369464
Epoch: 38 | Iteration number: [770/4518] 17% | Training loss: 0.6876419129309717
Epoch: 38 | Iteration number: [780/4518] 17% | Training loss: 0.6876380127209883
Epoch: 38 | Iteration number: [790/4518] 17% | Training loss: 0.6876289299017266
Epoch: 38 | Iteration number: [800/4518] 17% | Training loss: 0.6876133160293102
Epoch: 38 | Iteration number: [810/4518] 17% | Training loss: 0.6876101481325833
Epoch: 38 | Iteration number: [820/4518] 18% | Training loss: 0.6875801960869533
Epoch: 38 | Iteration number: [830/4518] 18% | Training loss: 0.687585748031915
Epoch: 38 | Iteration number: [840/4518] 18% | Training loss: 0.6875895901804878
Epoch: 38 | Iteration number: [850/4518] 18% | Training loss: 0.6875744335791644
Epoch: 38 | Iteration number: [860/4518] 19% | Training loss: 0.6875594223654548
Epoch: 38 | Iteration number: [870/4518] 19% | Training loss: 0.6875589564613912
Epoch: 38 | Iteration number: [880/4518] 19% | Training loss: 0.6875359756025401
Epoch: 38 | Iteration number: [890/4518] 19% | Training loss: 0.6875125979439596
Epoch: 38 | Iteration number: [900/4518] 19% | Training loss: 0.6875101964341269
Epoch: 38 | Iteration number: [910/4518] 20% | Training loss: 0.6874939395176185
Epoch: 38 | Iteration number: [920/4518] 20% | Training loss: 0.6874849178868792
Epoch: 38 | Iteration number: [930/4518] 20% | Training loss: 0.6874851981798807
Epoch: 38 | Iteration number: [940/4518] 20% | Training loss: 0.687475546877435
Epoch: 38 | Iteration number: [950/4518] 21% | Training loss: 0.6874742854268927
Epoch: 38 | Iteration number: [960/4518] 21% | Training loss: 0.6874843896677096
Epoch: 38 | Iteration number: [970/4518] 21% | Training loss: 0.687473324156299
Epoch: 38 | Iteration number: [980/4518] 21% | Training loss: 0.6874621672897923
Epoch: 38 | Iteration number: [990/4518] 21% | Training loss: 0.6874461902512444
Epoch: 38 | Iteration number: [1000/4518] 22% | Training loss: 0.6874517492055893
Epoch: 38 | Iteration number: [1010/4518] 22% | Training loss: 0.6874360072140646
Epoch: 38 | Iteration number: [1020/4518] 22% | Training loss: 0.6874298343471452
Epoch: 38 | Iteration number: [1030/4518] 22% | Training loss: 0.6874351051825921
Epoch: 38 | Iteration number: [1040/4518] 23% | Training loss: 0.6874180645323716
Epoch: 38 | Iteration number: [1050/4518] 23% | Training loss: 0.6874033636706216
Epoch: 38 | Iteration number: [1060/4518] 23% | Training loss: 0.6873967671169425
Epoch: 38 | Iteration number: [1070/4518] 23% | Training loss: 0.6873868510544857
Epoch: 38 | Iteration number: [1080/4518] 23% | Training loss: 0.6873815938278481
Epoch: 38 | Iteration number: [1090/4518] 24% | Training loss: 0.687361247933239
Epoch: 38 | Iteration number: [1100/4518] 24% | Training loss: 0.6873533294959502
Epoch: 38 | Iteration number: [1110/4518] 24% | Training loss: 0.6873641448514956
Epoch: 38 | Iteration number: [1120/4518] 24% | Training loss: 0.6873541387064116
Epoch: 38 | Iteration number: [1130/4518] 25% | Training loss: 0.6873429941392578
Epoch: 38 | Iteration number: [1140/4518] 25% | Training loss: 0.6873373119454634
Epoch: 38 | Iteration number: [1150/4518] 25% | Training loss: 0.6873343197677446
Epoch: 38 | Iteration number: [1160/4518] 25% | Training loss: 0.6873265830093417
Epoch: 38 | Iteration number: [1170/4518] 25% | Training loss: 0.6873335203553876
Epoch: 38 | Iteration number: [1180/4518] 26% | Training loss: 0.6873287094851671
Epoch: 38 | Iteration number: [1190/4518] 26% | Training loss: 0.6873215872700474
Epoch: 38 | Iteration number: [1200/4518] 26% | Training loss: 0.687327087521553
Epoch: 38 | Iteration number: [1210/4518] 26% | Training loss: 0.6873196712702759
Epoch: 38 | Iteration number: [1220/4518] 27% | Training loss: 0.6873142952313188
Epoch: 38 | Iteration number: [1230/4518] 27% | Training loss: 0.6873208719540418
Epoch: 38 | Iteration number: [1240/4518] 27% | Training loss: 0.6873144087291533
Epoch: 38 | Iteration number: [1250/4518] 27% | Training loss: 0.6873106847286224
Epoch: 38 | Iteration number: [1260/4518] 27% | Training loss: 0.6873023552553994
Epoch: 38 | Iteration number: [1270/4518] 28% | Training loss: 0.6873020784122738
Epoch: 38 | Iteration number: [1280/4518] 28% | Training loss: 0.6872998175211251
Epoch: 38 | Iteration number: [1290/4518] 28% | Training loss: 0.6872942383437194
Epoch: 38 | Iteration number: [1300/4518] 28% | Training loss: 0.687288960997875
Epoch: 38 | Iteration number: [1310/4518] 28% | Training loss: 0.6872836777272116
Epoch: 38 | Iteration number: [1320/4518] 29% | Training loss: 0.6872830336292585
Epoch: 38 | Iteration number: [1330/4518] 29% | Training loss: 0.6872784300406176
Epoch: 38 | Iteration number: [1340/4518] 29% | Training loss: 0.6872800642429893
Epoch: 38 | Iteration number: [1350/4518] 29% | Training loss: 0.6872745025599445
Epoch: 38 | Iteration number: [1360/4518] 30% | Training loss: 0.687269409439143
Epoch: 38 | Iteration number: [1370/4518] 30% | Training loss: 0.6872639503357184
Epoch: 38 | Iteration number: [1380/4518] 30% | Training loss: 0.6872621851122898
Epoch: 38 | Iteration number: [1390/4518] 30% | Training loss: 0.6872587964689131
Epoch: 38 | Iteration number: [1400/4518] 30% | Training loss: 0.6872526651195118
Epoch: 38 | Iteration number: [1410/4518] 31% | Training loss: 0.6872511872585784
Epoch: 38 | Iteration number: [1420/4518] 31% | Training loss: 0.6872508046072974
Epoch: 38 | Iteration number: [1430/4518] 31% | Training loss: 0.6872382008946025
Epoch: 38 | Iteration number: [1440/4518] 31% | Training loss: 0.6872339371591807
Epoch: 38 | Iteration number: [1450/4518] 32% | Training loss: 0.6872331234504436
Epoch: 38 | Iteration number: [1460/4518] 32% | Training loss: 0.68723405142353
Epoch: 38 | Iteration number: [1470/4518] 32% | Training loss: 0.6872251597391504
Epoch: 38 | Iteration number: [1480/4518] 32% | Training loss: 0.6872223190761901
Epoch: 38 | Iteration number: [1490/4518] 32% | Training loss: 0.6872184380588916
Epoch: 38 | Iteration number: [1500/4518] 33% | Training loss: 0.6872130641937256
Epoch: 38 | Iteration number: [1510/4518] 33% | Training loss: 0.6871992921592384
Epoch: 38 | Iteration number: [1520/4518] 33% | Training loss: 0.6871914416943726
Epoch: 38 | Iteration number: [1530/4518] 33% | Training loss: 0.6871951286699257
Epoch: 38 | Iteration number: [1540/4518] 34% | Training loss: 0.6871859488936214
Epoch: 38 | Iteration number: [1550/4518] 34% | Training loss: 0.6871859277448347
Epoch: 38 | Iteration number: [1560/4518] 34% | Training loss: 0.6871735418072114
Epoch: 38 | Iteration number: [1570/4518] 34% | Training loss: 0.6871707647469393
Epoch: 38 | Iteration number: [1580/4518] 34% | Training loss: 0.6871804437305354
Epoch: 38 | Iteration number: [1590/4518] 35% | Training loss: 0.6871769006897068
Epoch: 38 | Iteration number: [1600/4518] 35% | Training loss: 0.6871738157421351
Epoch: 38 | Iteration number: [1610/4518] 35% | Training loss: 0.6871716496366892
Epoch: 38 | Iteration number: [1620/4518] 35% | Training loss: 0.6871735979377488
Epoch: 38 | Iteration number: [1630/4518] 36% | Training loss: 0.6871721377036323
Epoch: 38 | Iteration number: [1640/4518] 36% | Training loss: 0.6871726714256333
Epoch: 38 | Iteration number: [1650/4518] 36% | Training loss: 0.6871725540088884
Epoch: 38 | Iteration number: [1660/4518] 36% | Training loss: 0.6871771032192621
Epoch: 38 | Iteration number: [1670/4518] 36% | Training loss: 0.6871767593001177
Epoch: 38 | Iteration number: [1680/4518] 37% | Training loss: 0.687175275278943
Epoch: 38 | Iteration number: [1690/4518] 37% | Training loss: 0.6871680182112745
Epoch: 38 | Iteration number: [1700/4518] 37% | Training loss: 0.6871675970624475
Epoch: 38 | Iteration number: [1710/4518] 37% | Training loss: 0.6871600659270035
Epoch: 38 | Iteration number: [1720/4518] 38% | Training loss: 0.6871580576480821
Epoch: 38 | Iteration number: [1730/4518] 38% | Training loss: 0.6871569822633886
Epoch: 38 | Iteration number: [1740/4518] 38% | Training loss: 0.6871579383639084
Epoch: 38 | Iteration number: [1750/4518] 38% | Training loss: 0.687151633296694
Epoch: 38 | Iteration number: [1760/4518] 38% | Training loss: 0.6871553228660063
Epoch: 38 | Iteration number: [1770/4518] 39% | Training loss: 0.6871594378166953
Epoch: 38 | Iteration number: [1780/4518] 39% | Training loss: 0.6871541664171754
Epoch: 38 | Iteration number: [1790/4518] 39% | Training loss: 0.6871573229741784
Epoch: 38 | Iteration number: [1800/4518] 39% | Training loss: 0.6871548872192701
Epoch: 38 | Iteration number: [1810/4518] 40% | Training loss: 0.6871571846759121
Epoch: 38 | Iteration number: [1820/4518] 40% | Training loss: 0.6871538930541866
Epoch: 38 | Iteration number: [1830/4518] 40% | Training loss: 0.6871568069106243
Epoch: 38 | Iteration number: [1840/4518] 40% | Training loss: 0.6871518937789876
Epoch: 38 | Iteration number: [1850/4518] 40% | Training loss: 0.6871504049687772
Epoch: 38 | Iteration number: [1860/4518] 41% | Training loss: 0.6871482266533759
Epoch: 38 | Iteration number: [1870/4518] 41% | Training loss: 0.6871434147345191
Epoch: 38 | Iteration number: [1880/4518] 41% | Training loss: 0.6871430233120919
Epoch: 38 | Iteration number: [1890/4518] 41% | Training loss: 0.6871396709686864
Epoch: 38 | Iteration number: [1900/4518] 42% | Training loss: 0.6871391155531532
Epoch: 38 | Iteration number: [1910/4518] 42% | Training loss: 0.6871345961281142
Epoch: 38 | Iteration number: [1920/4518] 42% | Training loss: 0.6871344614773989
Epoch: 38 | Iteration number: [1930/4518] 42% | Training loss: 0.6871326448077365
Epoch: 38 | Iteration number: [1940/4518] 42% | Training loss: 0.6871408605083977
Epoch: 38 | Iteration number: [1950/4518] 43% | Training loss: 0.6871424040427575
Epoch: 38 | Iteration number: [1960/4518] 43% | Training loss: 0.6871472558500815
Epoch: 38 | Iteration number: [1970/4518] 43% | Training loss: 0.6871518898131278
Epoch: 38 | Iteration number: [1980/4518] 43% | Training loss: 0.6871569778582063
Epoch: 38 | Iteration number: [1990/4518] 44% | Training loss: 0.6871529864905468
Epoch: 38 | Iteration number: [2000/4518] 44% | Training loss: 0.6871539770960807
Epoch: 38 | Iteration number: [2010/4518] 44% | Training loss: 0.6871456479551781
Epoch: 38 | Iteration number: [2020/4518] 44% | Training loss: 0.6871492768278217
Epoch: 38 | Iteration number: [2030/4518] 44% | Training loss: 0.687146961248567
Epoch: 38 | Iteration number: [2040/4518] 45% | Training loss: 0.6871426255971778
Epoch: 38 | Iteration number: [2050/4518] 45% | Training loss: 0.6871440759810006
Epoch: 38 | Iteration number: [2060/4518] 45% | Training loss: 0.6871421151080178
Epoch: 38 | Iteration number: [2070/4518] 45% | Training loss: 0.6871392016825468
Epoch: 38 | Iteration number: [2080/4518] 46% | Training loss: 0.6871326599270106
Epoch: 38 | Iteration number: [2090/4518] 46% | Training loss: 0.6871315522627397
Epoch: 38 | Iteration number: [2100/4518] 46% | Training loss: 0.6871281439633596
Epoch: 38 | Iteration number: [2110/4518] 46% | Training loss: 0.6871263685949606
Epoch: 38 | Iteration number: [2120/4518] 46% | Training loss: 0.6871291674814134
Epoch: 38 | Iteration number: [2130/4518] 47% | Training loss: 0.6871276631881373
Epoch: 38 | Iteration number: [2140/4518] 47% | Training loss: 0.6871251403728378
Epoch: 38 | Iteration number: [2150/4518] 47% | Training loss: 0.6871261782978856
Epoch: 38 | Iteration number: [2160/4518] 47% | Training loss: 0.6871303771656972
Epoch: 38 | Iteration number: [2170/4518] 48% | Training loss: 0.6871299061357701
Epoch: 38 | Iteration number: [2180/4518] 48% | Training loss: 0.6871305053113798
Epoch: 38 | Iteration number: [2190/4518] 48% | Training loss: 0.6871305132021098
Epoch: 38 | Iteration number: [2200/4518] 48% | Training loss: 0.6871279659596357
Epoch: 38 | Iteration number: [2210/4518] 48% | Training loss: 0.6871291860735794
Epoch: 38 | Iteration number: [2220/4518] 49% | Training loss: 0.6871212432781856
Epoch: 38 | Iteration number: [2230/4518] 49% | Training loss: 0.6871183890131022
Epoch: 38 | Iteration number: [2240/4518] 49% | Training loss: 0.6871135315990874
Epoch: 38 | Iteration number: [2250/4518] 49% | Training loss: 0.687112795803282
Epoch: 38 | Iteration number: [2260/4518] 50% | Training loss: 0.6871071384807603
Epoch: 38 | Iteration number: [2270/4518] 50% | Training loss: 0.6871142838494894
Epoch: 38 | Iteration number: [2280/4518] 50% | Training loss: 0.6871123243580785
Epoch: 38 | Iteration number: [2290/4518] 50% | Training loss: 0.6871112594958476
Epoch: 38 | Iteration number: [2300/4518] 50% | Training loss: 0.6871088933426401
Epoch: 38 | Iteration number: [2310/4518] 51% | Training loss: 0.6871068308105717
Epoch: 38 | Iteration number: [2320/4518] 51% | Training loss: 0.687100718350246
Epoch: 38 | Iteration number: [2330/4518] 51% | Training loss: 0.6871045271214498
Epoch: 38 | Iteration number: [2340/4518] 51% | Training loss: 0.6871062367899805
Epoch: 38 | Iteration number: [2350/4518] 52% | Training loss: 0.6871086117054553
Epoch: 38 | Iteration number: [2360/4518] 52% | Training loss: 0.6871062048410965
Epoch: 38 | Iteration number: [2370/4518] 52% | Training loss: 0.687108276338014
Epoch: 38 | Iteration number: [2380/4518] 52% | Training loss: 0.6871040002888992
Epoch: 38 | Iteration number: [2390/4518] 52% | Training loss: 0.6871002141152466
Epoch: 38 | Iteration number: [2400/4518] 53% | Training loss: 0.6870989009737969
Epoch: 38 | Iteration number: [2410/4518] 53% | Training loss: 0.6870992631833088
Epoch: 38 | Iteration number: [2420/4518] 53% | Training loss: 0.6870910394290262
Epoch: 38 | Iteration number: [2430/4518] 53% | Training loss: 0.6870903831695824
Epoch: 38 | Iteration number: [2440/4518] 54% | Training loss: 0.6870884038385797
Epoch: 38 | Iteration number: [2450/4518] 54% | Training loss: 0.6870915448908903
Epoch: 38 | Iteration number: [2460/4518] 54% | Training loss: 0.687094581732905
Epoch: 38 | Iteration number: [2470/4518] 54% | Training loss: 0.6870921078963801
Epoch: 38 | Iteration number: [2480/4518] 54% | Training loss: 0.6870903128577817
Epoch: 38 | Iteration number: [2490/4518] 55% | Training loss: 0.687092743939664
Epoch: 38 | Iteration number: [2500/4518] 55% | Training loss: 0.6870891263484955
Epoch: 38 | Iteration number: [2510/4518] 55% | Training loss: 0.6870856804439271
Epoch: 38 | Iteration number: [2520/4518] 55% | Training loss: 0.6870916796109033
Epoch: 38 | Iteration number: [2530/4518] 55% | Training loss: 0.6870929721315859
Epoch: 38 | Iteration number: [2540/4518] 56% | Training loss: 0.687090420464831
Epoch: 38 | Iteration number: [2550/4518] 56% | Training loss: 0.6870911210424759
Epoch: 38 | Iteration number: [2560/4518] 56% | Training loss: 0.6870886016869917
Epoch: 38 | Iteration number: [2570/4518] 56% | Training loss: 0.6870887792064058
Epoch: 38 | Iteration number: [2580/4518] 57% | Training loss: 0.6870908451172733
Epoch: 38 | Iteration number: [2590/4518] 57% | Training loss: 0.6870907623795469
Epoch: 38 | Iteration number: [2600/4518] 57% | Training loss: 0.687089256988122
Epoch: 38 | Iteration number: [2610/4518] 57% | Training loss: 0.6870843255428519
Epoch: 38 | Iteration number: [2620/4518] 57% | Training loss: 0.6870849883965864
Epoch: 38 | Iteration number: [2630/4518] 58% | Training loss: 0.6870844724740366
Epoch: 38 | Iteration number: [2640/4518] 58% | Training loss: 0.6870842357250777
Epoch: 38 | Iteration number: [2650/4518] 58% | Training loss: 0.687081571952352
Epoch: 38 | Iteration number: [2660/4518] 58% | Training loss: 0.687074909241576
Epoch: 38 | Iteration number: [2670/4518] 59% | Training loss: 0.6870746035254404
Epoch: 38 | Iteration number: [2680/4518] 59% | Training loss: 0.6870753685485071
Epoch: 38 | Iteration number: [2690/4518] 59% | Training loss: 0.6870785293747501
Epoch: 38 | Iteration number: [2700/4518] 59% | Training loss: 0.6870768842432234
Epoch: 38 | Iteration number: [2710/4518] 59% | Training loss: 0.6870792778215725
Epoch: 38 | Iteration number: [2720/4518] 60% | Training loss: 0.6870835606666172
Epoch: 38 | Iteration number: [2730/4518] 60% | Training loss: 0.6870884093609485
Epoch: 38 | Iteration number: [2740/4518] 60% | Training loss: 0.6870865487704312
Epoch: 38 | Iteration number: [2750/4518] 60% | Training loss: 0.6870897671309384
Epoch: 38 | Iteration number: [2760/4518] 61% | Training loss: 0.6870885836257451
Epoch: 38 | Iteration number: [2770/4518] 61% | Training loss: 0.6870875235283849
Epoch: 38 | Iteration number: [2780/4518] 61% | Training loss: 0.6870862607046855
Epoch: 38 | Iteration number: [2790/4518] 61% | Training loss: 0.6870856205408719
Epoch: 38 | Iteration number: [2800/4518] 61% | Training loss: 0.6870858022783484
Epoch: 38 | Iteration number: [2810/4518] 62% | Training loss: 0.687082404852762
Epoch: 38 | Iteration number: [2820/4518] 62% | Training loss: 0.687082214389287
Epoch: 38 | Iteration number: [2830/4518] 62% | Training loss: 0.6870772406827435
Epoch: 38 | Iteration number: [2840/4518] 62% | Training loss: 0.6870773317738318
Epoch: 38 | Iteration number: [2850/4518] 63% | Training loss: 0.6870742358450304
Epoch: 38 | Iteration number: [2860/4518] 63% | Training loss: 0.6870719125846049
Epoch: 38 | Iteration number: [2870/4518] 63% | Training loss: 0.6870752200432355
Epoch: 38 | Iteration number: [2880/4518] 63% | Training loss: 0.6870763596147299
Epoch: 38 | Iteration number: [2890/4518] 63% | Training loss: 0.6870751246242787
Epoch: 38 | Iteration number: [2900/4518] 64% | Training loss: 0.6870763160648017
Epoch: 38 | Iteration number: [2910/4518] 64% | Training loss: 0.6870747775761122
Epoch: 38 | Iteration number: [2920/4518] 64% | Training loss: 0.6870755154588452
Epoch: 38 | Iteration number: [2930/4518] 64% | Training loss: 0.6870760682296427
Epoch: 38 | Iteration number: [2940/4518] 65% | Training loss: 0.6870707106225344
Epoch: 38 | Iteration number: [2950/4518] 65% | Training loss: 0.6870753417984914
Epoch: 38 | Iteration number: [2960/4518] 65% | Training loss: 0.6870775171631092
Epoch: 38 | Iteration number: [2970/4518] 65% | Training loss: 0.6870733269537338
Epoch: 38 | Iteration number: [2980/4518] 65% | Training loss: 0.6870724952060905
Epoch: 38 | Iteration number: [2990/4518] 66% | Training loss: 0.6870708888589738
Epoch: 38 | Iteration number: [3000/4518] 66% | Training loss: 0.6870714293122292
Epoch: 38 | Iteration number: [3010/4518] 66% | Training loss: 0.6870714487823537
Epoch: 38 | Iteration number: [3020/4518] 66% | Training loss: 0.6870709817338464
Epoch: 38 | Iteration number: [3030/4518] 67% | Training loss: 0.6870704239154413
Epoch: 38 | Iteration number: [3040/4518] 67% | Training loss: 0.687069953762387
Epoch: 38 | Iteration number: [3050/4518] 67% | Training loss: 0.6870719378111793
Epoch: 38 | Iteration number: [3060/4518] 67% | Training loss: 0.6870665141375236
Epoch: 38 | Iteration number: [3070/4518] 67% | Training loss: 0.6870619438370198
Epoch: 38 | Iteration number: [3080/4518] 68% | Training loss: 0.687057973463814
Epoch: 38 | Iteration number: [3090/4518] 68% | Training loss: 0.6870539339614917
Epoch: 38 | Iteration number: [3100/4518] 68% | Training loss: 0.6870513206528079
Epoch: 38 | Iteration number: [3110/4518] 68% | Training loss: 0.6870478745633766
Epoch: 38 | Iteration number: [3120/4518] 69% | Training loss: 0.6870443908640972
Epoch: 38 | Iteration number: [3130/4518] 69% | Training loss: 0.6870441126366393
Epoch: 38 | Iteration number: [3140/4518] 69% | Training loss: 0.6870376791354198
Epoch: 38 | Iteration number: [3150/4518] 69% | Training loss: 0.6870414274079459
Epoch: 38 | Iteration number: [3160/4518] 69% | Training loss: 0.6870440336722362
Epoch: 38 | Iteration number: [3170/4518] 70% | Training loss: 0.6870448912167775
Epoch: 38 | Iteration number: [3180/4518] 70% | Training loss: 0.6870465017152283
Epoch: 38 | Iteration number: [3190/4518] 70% | Training loss: 0.6870434257304033
Epoch: 38 | Iteration number: [3200/4518] 70% | Training loss: 0.6870425517484545
Epoch: 38 | Iteration number: [3210/4518] 71% | Training loss: 0.6870422391876625
Epoch: 38 | Iteration number: [3220/4518] 71% | Training loss: 0.6870407503954372
Epoch: 38 | Iteration number: [3230/4518] 71% | Training loss: 0.68704348141933
Epoch: 38 | Iteration number: [3240/4518] 71% | Training loss: 0.6870446651806066
Epoch: 38 | Iteration number: [3250/4518] 71% | Training loss: 0.6870417614900148
Epoch: 38 | Iteration number: [3260/4518] 72% | Training loss: 0.6870398317743664
Epoch: 38 | Iteration number: [3270/4518] 72% | Training loss: 0.6870375335945631
Epoch: 38 | Iteration number: [3280/4518] 72% | Training loss: 0.6870402767527394
Epoch: 38 | Iteration number: [3290/4518] 72% | Training loss: 0.6870420355564918
Epoch: 38 | Iteration number: [3300/4518] 73% | Training loss: 0.6870460596229091
Epoch: 38 | Iteration number: [3310/4518] 73% | Training loss: 0.6870463860359076
Epoch: 38 | Iteration number: [3320/4518] 73% | Training loss: 0.687043757144227
Epoch: 38 | Iteration number: [3330/4518] 73% | Training loss: 0.6870447756112875
Epoch: 38 | Iteration number: [3340/4518] 73% | Training loss: 0.6870426696396159
Epoch: 38 | Iteration number: [3350/4518] 74% | Training loss: 0.6870423601634467
Epoch: 38 | Iteration number: [3360/4518] 74% | Training loss: 0.6870423159429005
Epoch: 38 | Iteration number: [3370/4518] 74% | Training loss: 0.6870401960098425
Epoch: 38 | Iteration number: [3380/4518] 74% | Training loss: 0.6870410309388087
Epoch: 38 | Iteration number: [3390/4518] 75% | Training loss: 0.6870383580701541
Epoch: 38 | Iteration number: [3400/4518] 75% | Training loss: 0.6870353912080035
Epoch: 38 | Iteration number: [3410/4518] 75% | Training loss: 0.687032792505281
Epoch: 38 | Iteration number: [3420/4518] 75% | Training loss: 0.6870316176386605
Epoch: 38 | Iteration number: [3430/4518] 75% | Training loss: 0.6870345986966837
Epoch: 38 | Iteration number: [3440/4518] 76% | Training loss: 0.6870344833579174
Epoch: 38 | Iteration number: [3450/4518] 76% | Training loss: 0.6870309801032578
Epoch: 38 | Iteration number: [3460/4518] 76% | Training loss: 0.6870309139262734
Epoch: 38 | Iteration number: [3470/4518] 76% | Training loss: 0.6870265651676771
Epoch: 38 | Iteration number: [3480/4518] 77% | Training loss: 0.6870234959598245
Epoch: 38 | Iteration number: [3490/4518] 77% | Training loss: 0.6870245417926919
Epoch: 38 | Iteration number: [3500/4518] 77% | Training loss: 0.6870252408300127
Epoch: 38 | Iteration number: [3510/4518] 77% | Training loss: 0.687026844574855
Epoch: 38 | Iteration number: [3520/4518] 77% | Training loss: 0.6870264663107016
Epoch: 38 | Iteration number: [3530/4518] 78% | Training loss: 0.6870250616803047
Epoch: 38 | Iteration number: [3540/4518] 78% | Training loss: 0.6870241720797652
Epoch: 38 | Iteration number: [3550/4518] 78% | Training loss: 0.6870232512917317
Epoch: 38 | Iteration number: [3560/4518] 78% | Training loss: 0.6870214524731207
Epoch: 38 | Iteration number: [3570/4518] 79% | Training loss: 0.6870181259153938
Epoch: 38 | Iteration number: [3580/4518] 79% | Training loss: 0.6870173053535004
Epoch: 38 | Iteration number: [3590/4518] 79% | Training loss: 0.6870156478582983
Epoch: 38 | Iteration number: [3600/4518] 79% | Training loss: 0.687016792645057
Epoch: 38 | Iteration number: [3610/4518] 79% | Training loss: 0.6870157027673853
Epoch: 38 | Iteration number: [3620/4518] 80% | Training loss: 0.6870155841112137
Epoch: 38 | Iteration number: [3630/4518] 80% | Training loss: 0.6870142297639663
Epoch: 38 | Iteration number: [3640/4518] 80% | Training loss: 0.6870168067924269
Epoch: 38 | Iteration number: [3650/4518] 80% | Training loss: 0.6870170153493751
Epoch: 38 | Iteration number: [3660/4518] 81% | Training loss: 0.6870153820905529
Epoch: 38 | Iteration number: [3670/4518] 81% | Training loss: 0.6870157554948687
Epoch: 38 | Iteration number: [3680/4518] 81% | Training loss: 0.6870143750439519
Epoch: 38 | Iteration number: [3690/4518] 81% | Training loss: 0.687012433811901
Epoch: 38 | Iteration number: [3700/4518] 81% | Training loss: 0.6870143818694192
Epoch: 38 | Iteration number: [3710/4518] 82% | Training loss: 0.6870154702438498
Epoch: 38 | Iteration number: [3720/4518] 82% | Training loss: 0.6870118204944877
Epoch: 38 | Iteration number: [3730/4518] 82% | Training loss: 0.6870158293291966
Epoch: 38 | Iteration number: [3740/4518] 82% | Training loss: 0.6870162481292684
Epoch: 38 | Iteration number: [3750/4518] 83% | Training loss: 0.687014957523346
Epoch: 38 | Iteration number: [3760/4518] 83% | Training loss: 0.687016031542357
Epoch: 38 | Iteration number: [3770/4518] 83% | Training loss: 0.6870185550549303
Epoch: 38 | Iteration number: [3780/4518] 83% | Training loss: 0.6870175087262713
Epoch: 38 | Iteration number: [3790/4518] 83% | Training loss: 0.6870151911530457
Epoch: 38 | Iteration number: [3800/4518] 84% | Training loss: 0.6870177679783419
Epoch: 38 | Iteration number: [3810/4518] 84% | Training loss: 0.6870135605804564
Epoch: 38 | Iteration number: [3820/4518] 84% | Training loss: 0.687013049369083
Epoch: 38 | Iteration number: [3830/4518] 84% | Training loss: 0.6870125297622333
Epoch: 38 | Iteration number: [3840/4518] 84% | Training loss: 0.6870110037736594
Epoch: 38 | Iteration number: [3850/4518] 85% | Training loss: 0.6870099680145065
Epoch: 38 | Iteration number: [3860/4518] 85% | Training loss: 0.6870076692783771
Epoch: 38 | Iteration number: [3870/4518] 85% | Training loss: 0.6870044738285301
Epoch: 38 | Iteration number: [3880/4518] 85% | Training loss: 0.6870041564875042
Epoch: 38 | Iteration number: [3890/4518] 86% | Training loss: 0.68700565134958
Epoch: 38 | Iteration number: [3900/4518] 86% | Training loss: 0.6870102017659407
Epoch: 38 | Iteration number: [3910/4518] 86% | Training loss: 0.6870120847316654
Epoch: 38 | Iteration number: [3920/4518] 86% | Training loss: 0.6870115645685975
Epoch: 38 | Iteration number: [3930/4518] 86% | Training loss: 0.6870099686939298
Epoch: 38 | Iteration number: [3940/4518] 87% | Training loss: 0.6870074056278025
Epoch: 38 | Iteration number: [3950/4518] 87% | Training loss: 0.6870048279701909
Epoch: 38 | Iteration number: [3960/4518] 87% | Training loss: 0.68700144864393
Epoch: 38 | Iteration number: [3970/4518] 87% | Training loss: 0.6870002392557466
Epoch: 38 | Iteration number: [3980/4518] 88% | Training loss: 0.6869958209182749
Epoch: 38 | Iteration number: [3990/4518] 88% | Training loss: 0.6869967709806629
Epoch: 38 | Iteration number: [4000/4518] 88% | Training loss: 0.6869947669506073
Epoch: 38 | Iteration number: [4010/4518] 88% | Training loss: 0.6869950846692273
Epoch: 38 | Iteration number: [4020/4518] 88% | Training loss: 0.6869943185825254
Epoch: 38 | Iteration number: [4030/4518] 89% | Training loss: 0.6869953796526339
Epoch: 38 | Iteration number: [4040/4518] 89% | Training loss: 0.6869993067171314
Epoch: 38 | Iteration number: [4050/4518] 89% | Training loss: 0.6869993029111697
Epoch: 38 | Iteration number: [4060/4518] 89% | Training loss: 0.6870008596352168
Epoch: 38 | Iteration number: [4070/4518] 90% | Training loss: 0.6869981729574227
Epoch: 38 | Iteration number: [4080/4518] 90% | Training loss: 0.6869959819404517
Epoch: 38 | Iteration number: [4090/4518] 90% | Training loss: 0.6869982496887664
Epoch: 38 | Iteration number: [4100/4518] 90% | Training loss: 0.686998227500334
Epoch: 38 | Iteration number: [4110/4518] 90% | Training loss: 0.686996254071122
Epoch: 38 | Iteration number: [4120/4518] 91% | Training loss: 0.6869979028707569
Epoch: 38 | Iteration number: [4130/4518] 91% | Training loss: 0.6869946672321809
Epoch: 38 | Iteration number: [4140/4518] 91% | Training loss: 0.6869896175204844
Epoch: 38 | Iteration number: [4150/4518] 91% | Training loss: 0.6869914324886828
Epoch: 38 | Iteration number: [4160/4518] 92% | Training loss: 0.686991538393956
Epoch: 38 | Iteration number: [4170/4518] 92% | Training loss: 0.6869905441642093
Epoch: 38 | Iteration number: [4180/4518] 92% | Training loss: 0.6869893674074747
Epoch: 38 | Iteration number: [4190/4518] 92% | Training loss: 0.6869889377694142
Epoch: 38 | Iteration number: [4200/4518] 92% | Training loss: 0.6869891006747881
Epoch: 38 | Iteration number: [4210/4518] 93% | Training loss: 0.6869856272202489
Epoch: 38 | Iteration number: [4220/4518] 93% | Training loss: 0.686987493882812
Epoch: 38 | Iteration number: [4230/4518] 93% | Training loss: 0.6869853057055326
Epoch: 38 | Iteration number: [4240/4518] 93% | Training loss: 0.6869836824541946
Epoch: 38 | Iteration number: [4250/4518] 94% | Training loss: 0.6869814850582796
Epoch: 38 | Iteration number: [4260/4518] 94% | Training loss: 0.6869827968413841
Epoch: 38 | Iteration number: [4270/4518] 94% | Training loss: 0.6869808802280828
Epoch: 38 | Iteration number: [4280/4518] 94% | Training loss: 0.6869811189508884
Epoch: 38 | Iteration number: [4290/4518] 94% | Training loss: 0.6869810412813734
Epoch: 38 | Iteration number: [4300/4518] 95% | Training loss: 0.6869810819625854
Epoch: 38 | Iteration number: [4310/4518] 95% | Training loss: 0.6869806938132664
Epoch: 38 | Iteration number: [4320/4518] 95% | Training loss: 0.6869831819501188
Epoch: 38 | Iteration number: [4330/4518] 95% | Training loss: 0.6869812401144939
Epoch: 38 | Iteration number: [4340/4518] 96% | Training loss: 0.6869824020955969
Epoch: 38 | Iteration number: [4350/4518] 96% | Training loss: 0.6869838608955515
Epoch: 38 | Iteration number: [4360/4518] 96% | Training loss: 0.6869860877547789
Epoch: 38 | Iteration number: [4370/4518] 96% | Training loss: 0.6869893044710705
Epoch: 38 | Iteration number: [4380/4518] 96% | Training loss: 0.6869895570082207
Epoch: 38 | Iteration number: [4390/4518] 97% | Training loss: 0.6869895209348283
Epoch: 38 | Iteration number: [4400/4518] 97% | Training loss: 0.686990398276936
Epoch: 38 | Iteration number: [4410/4518] 97% | Training loss: 0.6869912894945296
Epoch: 38 | Iteration number: [4420/4518] 97% | Training loss: 0.6869923950859864
Epoch: 38 | Iteration number: [4430/4518] 98% | Training loss: 0.6869906944426672
Epoch: 38 | Iteration number: [4440/4518] 98% | Training loss: 0.6869891745952873
Epoch: 38 | Iteration number: [4450/4518] 98% | Training loss: 0.6869900098007716
Epoch: 38 | Iteration number: [4460/4518] 98% | Training loss: 0.6869891490503277
Epoch: 38 | Iteration number: [4470/4518] 98% | Training loss: 0.68698918150042
Epoch: 38 | Iteration number: [4480/4518] 99% | Training loss: 0.6869890310934612
Epoch: 38 | Iteration number: [4490/4518] 99% | Training loss: 0.6869874009045301
Epoch: 38 | Iteration number: [4500/4518] 99% | Training loss: 0.6869886038833194
Epoch: 38 | Iteration number: [4510/4518] 99% | Training loss: 0.6869899702574356

 End of epoch: 38 | Train Loss: 0.686836011750659 | Training Time: 641 

 End of epoch: 38 | Eval Loss: 0.6902078098180343 | Evaluating Time: 17 
Epoch: 39 | Iteration number: [10/4518] 0% | Training loss: 0.7541292428970336
Epoch: 39 | Iteration number: [20/4518] 0% | Training loss: 0.7194865554571152
Epoch: 39 | Iteration number: [30/4518] 0% | Training loss: 0.7089067180951436
Epoch: 39 | Iteration number: [40/4518] 0% | Training loss: 0.7036537960171699
Epoch: 39 | Iteration number: [50/4518] 1% | Training loss: 0.7001351702213288
Epoch: 39 | Iteration number: [60/4518] 1% | Training loss: 0.697985702753067
Epoch: 39 | Iteration number: [70/4518] 1% | Training loss: 0.6966699472495488
Epoch: 39 | Iteration number: [80/4518] 1% | Training loss: 0.6953248657286167
Epoch: 39 | Iteration number: [90/4518] 1% | Training loss: 0.6944041821691725
Epoch: 39 | Iteration number: [100/4518] 2% | Training loss: 0.6936620259284973
Epoch: 39 | Iteration number: [110/4518] 2% | Training loss: 0.6930279081517999
Epoch: 39 | Iteration number: [120/4518] 2% | Training loss: 0.6924324209491411
Epoch: 39 | Iteration number: [130/4518] 2% | Training loss: 0.6919534275164971
Epoch: 39 | Iteration number: [140/4518] 3% | Training loss: 0.6915189564228058
Epoch: 39 | Iteration number: [150/4518] 3% | Training loss: 0.691239876349767
Epoch: 39 | Iteration number: [160/4518] 3% | Training loss: 0.6909888230264187
Epoch: 39 | Iteration number: [170/4518] 3% | Training loss: 0.6908197490607991
Epoch: 39 | Iteration number: [180/4518] 3% | Training loss: 0.6905901349253125
Epoch: 39 | Iteration number: [190/4518] 4% | Training loss: 0.6903907383743085
Epoch: 39 | Iteration number: [200/4518] 4% | Training loss: 0.6902653175592423
Epoch: 39 | Iteration number: [210/4518] 4% | Training loss: 0.6901137891269865
Epoch: 39 | Iteration number: [220/4518] 4% | Training loss: 0.6899736000732942
Epoch: 39 | Iteration number: [230/4518] 5% | Training loss: 0.6898263936457427
Epoch: 39 | Iteration number: [240/4518] 5% | Training loss: 0.6897533242901166
Epoch: 39 | Iteration number: [250/4518] 5% | Training loss: 0.6895962362289428
Epoch: 39 | Iteration number: [260/4518] 5% | Training loss: 0.6894952178001403
Epoch: 39 | Iteration number: [270/4518] 5% | Training loss: 0.6894077462178689
Epoch: 39 | Iteration number: [280/4518] 6% | Training loss: 0.6893695744020598
Epoch: 39 | Iteration number: [290/4518] 6% | Training loss: 0.6892383400736184
Epoch: 39 | Iteration number: [300/4518] 6% | Training loss: 0.6891299116611481
Epoch: 39 | Iteration number: [310/4518] 6% | Training loss: 0.6890701338168114
Epoch: 39 | Iteration number: [320/4518] 7% | Training loss: 0.6889389816671609
Epoch: 39 | Iteration number: [330/4518] 7% | Training loss: 0.6888719477436759
Epoch: 39 | Iteration number: [340/4518] 7% | Training loss: 0.6888138045282924
Epoch: 39 | Iteration number: [350/4518] 7% | Training loss: 0.6887805088928768
Epoch: 39 | Iteration number: [360/4518] 7% | Training loss: 0.6887291699647904
Epoch: 39 | Iteration number: [370/4518] 8% | Training loss: 0.6886689041111921
Epoch: 39 | Iteration number: [380/4518] 8% | Training loss: 0.6885986445765746
Epoch: 39 | Iteration number: [390/4518] 8% | Training loss: 0.6885732465829605
Epoch: 39 | Iteration number: [400/4518] 8% | Training loss: 0.6885126687586307
Epoch: 39 | Iteration number: [410/4518] 9% | Training loss: 0.6884542760325641
Epoch: 39 | Iteration number: [420/4518] 9% | Training loss: 0.6884308194830304
Epoch: 39 | Iteration number: [430/4518] 9% | Training loss: 0.6883864846340445
Epoch: 39 | Iteration number: [440/4518] 9% | Training loss: 0.6883193322203376
Epoch: 39 | Iteration number: [450/4518] 9% | Training loss: 0.6882759642601013
Epoch: 39 | Iteration number: [460/4518] 10% | Training loss: 0.6882412594297658
Epoch: 39 | Iteration number: [470/4518] 10% | Training loss: 0.6882174023922454
Epoch: 39 | Iteration number: [480/4518] 10% | Training loss: 0.6881916468342145
Epoch: 39 | Iteration number: [490/4518] 10% | Training loss: 0.6881589916287636
Epoch: 39 | Iteration number: [500/4518] 11% | Training loss: 0.6881333109140396
Epoch: 39 | Iteration number: [510/4518] 11% | Training loss: 0.6880960025039373
Epoch: 39 | Iteration number: [520/4518] 11% | Training loss: 0.6880762198796639
Epoch: 39 | Iteration number: [530/4518] 11% | Training loss: 0.688035270740401
Epoch: 39 | Iteration number: [540/4518] 11% | Training loss: 0.6880059842710142
Epoch: 39 | Iteration number: [550/4518] 12% | Training loss: 0.6880000113357198
Epoch: 39 | Iteration number: [560/4518] 12% | Training loss: 0.6879808084240981
Epoch: 39 | Iteration number: [570/4518] 12% | Training loss: 0.6879622316151335
Epoch: 39 | Iteration number: [580/4518] 12% | Training loss: 0.6879305468551044
Epoch: 39 | Iteration number: [590/4518] 13% | Training loss: 0.6878999023114221
Epoch: 39 | Iteration number: [600/4518] 13% | Training loss: 0.6878819018602371
Epoch: 39 | Iteration number: [610/4518] 13% | Training loss: 0.6878603074394288
Epoch: 39 | Iteration number: [620/4518] 13% | Training loss: 0.6878483093553974
Epoch: 39 | Iteration number: [630/4518] 13% | Training loss: 0.6878271741526467
Epoch: 39 | Iteration number: [640/4518] 14% | Training loss: 0.6878090334124863
Epoch: 39 | Iteration number: [650/4518] 14% | Training loss: 0.6877949158961957
Epoch: 39 | Iteration number: [660/4518] 14% | Training loss: 0.6878055828990358
Epoch: 39 | Iteration number: [670/4518] 14% | Training loss: 0.6878034453783463
Epoch: 39 | Iteration number: [680/4518] 15% | Training loss: 0.6877804760547245
Epoch: 39 | Iteration number: [690/4518] 15% | Training loss: 0.6877618110698203
Epoch: 39 | Iteration number: [700/4518] 15% | Training loss: 0.6877421723093305
Epoch: 39 | Iteration number: [710/4518] 15% | Training loss: 0.6877389758405551
Epoch: 39 | Iteration number: [720/4518] 15% | Training loss: 0.6877370067768627
Epoch: 39 | Iteration number: [730/4518] 16% | Training loss: 0.6877168683156575
Epoch: 39 | Iteration number: [740/4518] 16% | Training loss: 0.6876885232087728
Epoch: 39 | Iteration number: [750/4518] 16% | Training loss: 0.6876692808469137
Epoch: 39 | Iteration number: [760/4518] 16% | Training loss: 0.6876626777021508
Epoch: 39 | Iteration number: [770/4518] 17% | Training loss: 0.6876414456924835
Epoch: 39 | Iteration number: [780/4518] 17% | Training loss: 0.6876308679580688
Epoch: 39 | Iteration number: [790/4518] 17% | Training loss: 0.6876391456851476
Epoch: 39 | Iteration number: [800/4518] 17% | Training loss: 0.6876303903758526
Epoch: 39 | Iteration number: [810/4518] 17% | Training loss: 0.6876163481930155
Epoch: 39 | Iteration number: [820/4518] 18% | Training loss: 0.6876090589819885
Epoch: 39 | Iteration number: [830/4518] 18% | Training loss: 0.6876053252852107
Epoch: 39 | Iteration number: [840/4518] 18% | Training loss: 0.6875992281805902
Epoch: 39 | Iteration number: [850/4518] 18% | Training loss: 0.68759130246499
Epoch: 39 | Iteration number: [860/4518] 19% | Training loss: 0.687589346669441
Epoch: 39 | Iteration number: [870/4518] 19% | Training loss: 0.6875659348635837
Epoch: 39 | Iteration number: [880/4518] 19% | Training loss: 0.6875517052682963
Epoch: 39 | Iteration number: [890/4518] 19% | Training loss: 0.6875523112463148
Epoch: 39 | Iteration number: [900/4518] 19% | Training loss: 0.6875452027055953
Epoch: 39 | Iteration number: [910/4518] 20% | Training loss: 0.6875312843820551
Epoch: 39 | Iteration number: [920/4518] 20% | Training loss: 0.6875283821121506
Epoch: 39 | Iteration number: [930/4518] 20% | Training loss: 0.6875174970396103
Epoch: 39 | Iteration number: [940/4518] 20% | Training loss: 0.6875024493070359
Epoch: 39 | Iteration number: [950/4518] 21% | Training loss: 0.6874993191267315
Epoch: 39 | Iteration number: [960/4518] 21% | Training loss: 0.6874990285063783
Epoch: 39 | Iteration number: [970/4518] 21% | Training loss: 0.6874860683667291
Epoch: 39 | Iteration number: [980/4518] 21% | Training loss: 0.6874814374714482
Epoch: 39 | Iteration number: [990/4518] 21% | Training loss: 0.6874799745251434
Epoch: 39 | Iteration number: [1000/4518] 22% | Training loss: 0.6874900133609771
Epoch: 39 | Iteration number: [1010/4518] 22% | Training loss: 0.6874927949197221
Epoch: 39 | Iteration number: [1020/4518] 22% | Training loss: 0.687484283599199
Epoch: 39 | Iteration number: [1030/4518] 22% | Training loss: 0.6874805865935909
Epoch: 39 | Iteration number: [1040/4518] 23% | Training loss: 0.6874782715852444
Epoch: 39 | Iteration number: [1050/4518] 23% | Training loss: 0.6874664378166199
Epoch: 39 | Iteration number: [1060/4518] 23% | Training loss: 0.6874774094460145
Epoch: 39 | Iteration number: [1070/4518] 23% | Training loss: 0.6874676477129215
Epoch: 39 | Iteration number: [1080/4518] 23% | Training loss: 0.6874578483126782
Epoch: 39 | Iteration number: [1090/4518] 24% | Training loss: 0.6874695021078128
Epoch: 39 | Iteration number: [1100/4518] 24% | Training loss: 0.6874725717847997
Epoch: 39 | Iteration number: [1110/4518] 24% | Training loss: 0.6874710652205321
Epoch: 39 | Iteration number: [1120/4518] 24% | Training loss: 0.6874663908034563
Epoch: 39 | Iteration number: [1130/4518] 25% | Training loss: 0.687458145196459
Epoch: 39 | Iteration number: [1140/4518] 25% | Training loss: 0.6874563355717742
Epoch: 39 | Iteration number: [1150/4518] 25% | Training loss: 0.6874573101686394
Epoch: 39 | Iteration number: [1160/4518] 25% | Training loss: 0.6874525101534251
Epoch: 39 | Iteration number: [1170/4518] 25% | Training loss: 0.6874434780361306
Epoch: 39 | Iteration number: [1180/4518] 26% | Training loss: 0.6874423816547556
Epoch: 39 | Iteration number: [1190/4518] 26% | Training loss: 0.6874379009258847
Epoch: 39 | Iteration number: [1200/4518] 26% | Training loss: 0.6874325256546339
Epoch: 39 | Iteration number: [1210/4518] 26% | Training loss: 0.6874311352071684
Epoch: 39 | Iteration number: [1220/4518] 27% | Training loss: 0.6874350020631415
Epoch: 39 | Iteration number: [1230/4518] 27% | Training loss: 0.6874454992573436
Epoch: 39 | Iteration number: [1240/4518] 27% | Training loss: 0.6874398117584567
Epoch: 39 | Iteration number: [1250/4518] 27% | Training loss: 0.6874327956199646
Epoch: 39 | Iteration number: [1260/4518] 27% | Training loss: 0.6874287554669002
Epoch: 39 | Iteration number: [1270/4518] 28% | Training loss: 0.6874187129219685
Epoch: 39 | Iteration number: [1280/4518] 28% | Training loss: 0.6874043331481516
Epoch: 39 | Iteration number: [1290/4518] 28% | Training loss: 0.6874011660269065
Epoch: 39 | Iteration number: [1300/4518] 28% | Training loss: 0.687403845832898
Epoch: 39 | Iteration number: [1310/4518] 28% | Training loss: 0.6873985437491468
Epoch: 39 | Iteration number: [1320/4518] 29% | Training loss: 0.687378451453917
Epoch: 39 | Iteration number: [1330/4518] 29% | Training loss: 0.6873828574678952
Epoch: 39 | Iteration number: [1340/4518] 29% | Training loss: 0.6873766659355875
Epoch: 39 | Iteration number: [1350/4518] 29% | Training loss: 0.6873720100190904
Epoch: 39 | Iteration number: [1360/4518] 30% | Training loss: 0.6873599813264959
Epoch: 39 | Iteration number: [1370/4518] 30% | Training loss: 0.6873548634730986
Epoch: 39 | Iteration number: [1380/4518] 30% | Training loss: 0.6873468827078308
Epoch: 39 | Iteration number: [1390/4518] 30% | Training loss: 0.6873449983356668
Epoch: 39 | Iteration number: [1400/4518] 30% | Training loss: 0.6873340476836477
Epoch: 39 | Iteration number: [1410/4518] 31% | Training loss: 0.687323637507486
Epoch: 39 | Iteration number: [1420/4518] 31% | Training loss: 0.6873148745214436
Epoch: 39 | Iteration number: [1430/4518] 31% | Training loss: 0.6873164795912229
Epoch: 39 | Iteration number: [1440/4518] 31% | Training loss: 0.6873205268548594
Epoch: 39 | Iteration number: [1450/4518] 32% | Training loss: 0.6873213425175897
Epoch: 39 | Iteration number: [1460/4518] 32% | Training loss: 0.6873090895887923
Epoch: 39 | Iteration number: [1470/4518] 32% | Training loss: 0.6873064487564321
Epoch: 39 | Iteration number: [1480/4518] 32% | Training loss: 0.6872990576802074
Epoch: 39 | Iteration number: [1490/4518] 32% | Training loss: 0.6872941471586291
Epoch: 39 | Iteration number: [1500/4518] 33% | Training loss: 0.6872951163450877
Epoch: 39 | Iteration number: [1510/4518] 33% | Training loss: 0.68729461403872
Epoch: 39 | Iteration number: [1520/4518] 33% | Training loss: 0.6872851269417688
Epoch: 39 | Iteration number: [1530/4518] 33% | Training loss: 0.687294494638256
Epoch: 39 | Iteration number: [1540/4518] 34% | Training loss: 0.687291290891635
Epoch: 39 | Iteration number: [1550/4518] 34% | Training loss: 0.6872927540348422
Epoch: 39 | Iteration number: [1560/4518] 34% | Training loss: 0.6872862590429111
Epoch: 39 | Iteration number: [1570/4518] 34% | Training loss: 0.687282219889817
Epoch: 39 | Iteration number: [1580/4518] 34% | Training loss: 0.687277665394771
Epoch: 39 | Iteration number: [1590/4518] 35% | Training loss: 0.6872788935712298
Epoch: 39 | Iteration number: [1600/4518] 35% | Training loss: 0.6872727025300265
Epoch: 39 | Iteration number: [1610/4518] 35% | Training loss: 0.6872696799891336
Epoch: 39 | Iteration number: [1620/4518] 35% | Training loss: 0.6872590517556226
Epoch: 39 | Iteration number: [1630/4518] 36% | Training loss: 0.6872620320027591
Epoch: 39 | Iteration number: [1640/4518] 36% | Training loss: 0.6872619316708751
Epoch: 39 | Iteration number: [1650/4518] 36% | Training loss: 0.6872542262077331
Epoch: 39 | Iteration number: [1660/4518] 36% | Training loss: 0.6872559159635061
Epoch: 39 | Iteration number: [1670/4518] 36% | Training loss: 0.6872546962635245
Epoch: 39 | Iteration number: [1680/4518] 37% | Training loss: 0.6872465020843914
Epoch: 39 | Iteration number: [1690/4518] 37% | Training loss: 0.6872400104646852
Epoch: 39 | Iteration number: [1700/4518] 37% | Training loss: 0.6872376223872689
Epoch: 39 | Iteration number: [1710/4518] 37% | Training loss: 0.6872420001796812
Epoch: 39 | Iteration number: [1720/4518] 38% | Training loss: 0.6872389296459597
Epoch: 39 | Iteration number: [1730/4518] 38% | Training loss: 0.6872392578621132
Epoch: 39 | Iteration number: [1740/4518] 38% | Training loss: 0.6872405793817564
Epoch: 39 | Iteration number: [1750/4518] 38% | Training loss: 0.687245912040983
Epoch: 39 | Iteration number: [1760/4518] 38% | Training loss: 0.6872455220330845
Epoch: 39 | Iteration number: [1770/4518] 39% | Training loss: 0.687246128899903
Epoch: 39 | Iteration number: [1780/4518] 39% | Training loss: 0.6872537015529161
Epoch: 39 | Iteration number: [1790/4518] 39% | Training loss: 0.6872519194746817
Epoch: 39 | Iteration number: [1800/4518] 39% | Training loss: 0.687253108686871
Epoch: 39 | Iteration number: [1810/4518] 40% | Training loss: 0.687257024761063
Epoch: 39 | Iteration number: [1820/4518] 40% | Training loss: 0.6872550776699087
Epoch: 39 | Iteration number: [1830/4518] 40% | Training loss: 0.6872542583877271
Epoch: 39 | Iteration number: [1840/4518] 40% | Training loss: 0.6872554799136908
Epoch: 39 | Iteration number: [1850/4518] 40% | Training loss: 0.6872533124846381
Epoch: 39 | Iteration number: [1860/4518] 41% | Training loss: 0.6872457293733474
Epoch: 39 | Iteration number: [1870/4518] 41% | Training loss: 0.687243317824634
Epoch: 39 | Iteration number: [1880/4518] 41% | Training loss: 0.6872378489438523
Epoch: 39 | Iteration number: [1890/4518] 41% | Training loss: 0.6872371769456006
Epoch: 39 | Iteration number: [1900/4518] 42% | Training loss: 0.687238281431951
Epoch: 39 | Iteration number: [1910/4518] 42% | Training loss: 0.6872385932512932
Epoch: 39 | Iteration number: [1920/4518] 42% | Training loss: 0.6872304746881127
Epoch: 39 | Iteration number: [1930/4518] 42% | Training loss: 0.6872197876631287
Epoch: 39 | Iteration number: [1940/4518] 42% | Training loss: 0.6872199922800064
Epoch: 39 | Iteration number: [1950/4518] 43% | Training loss: 0.6872187553919279
Epoch: 39 | Iteration number: [1960/4518] 43% | Training loss: 0.6872197343074545
Epoch: 39 | Iteration number: [1970/4518] 43% | Training loss: 0.6872104845071202
Epoch: 39 | Iteration number: [1980/4518] 43% | Training loss: 0.6872071804422321
Epoch: 39 | Iteration number: [1990/4518] 44% | Training loss: 0.687206562080575
Epoch: 39 | Iteration number: [2000/4518] 44% | Training loss: 0.6872084530293942
Epoch: 39 | Iteration number: [2010/4518] 44% | Training loss: 0.687206319612057
Epoch: 39 | Iteration number: [2020/4518] 44% | Training loss: 0.687211796906915
Epoch: 39 | Iteration number: [2030/4518] 44% | Training loss: 0.6872048526268287
Epoch: 39 | Iteration number: [2040/4518] 45% | Training loss: 0.6872021661085241
Epoch: 39 | Iteration number: [2050/4518] 45% | Training loss: 0.6872019095827894
Epoch: 39 | Iteration number: [2060/4518] 45% | Training loss: 0.6871918260761835
Epoch: 39 | Iteration number: [2070/4518] 45% | Training loss: 0.6871894500393798
Epoch: 39 | Iteration number: [2080/4518] 46% | Training loss: 0.6871858536910552
Epoch: 39 | Iteration number: [2090/4518] 46% | Training loss: 0.6871836037156684
Epoch: 39 | Iteration number: [2100/4518] 46% | Training loss: 0.6871816669475465
Epoch: 39 | Iteration number: [2110/4518] 46% | Training loss: 0.687178697264025
Epoch: 39 | Iteration number: [2120/4518] 46% | Training loss: 0.6871846771746312
Epoch: 39 | Iteration number: [2130/4518] 47% | Training loss: 0.6871807437267662
Epoch: 39 | Iteration number: [2140/4518] 47% | Training loss: 0.6871800720691681
Epoch: 39 | Iteration number: [2150/4518] 47% | Training loss: 0.6871811542677325
Epoch: 39 | Iteration number: [2160/4518] 47% | Training loss: 0.6871845747861597
Epoch: 39 | Iteration number: [2170/4518] 48% | Training loss: 0.6871805130336691
Epoch: 39 | Iteration number: [2180/4518] 48% | Training loss: 0.6871779351879698
Epoch: 39 | Iteration number: [2190/4518] 48% | Training loss: 0.6871742327191513
Epoch: 39 | Iteration number: [2200/4518] 48% | Training loss: 0.6871725586598569
Epoch: 39 | Iteration number: [2210/4518] 48% | Training loss: 0.68717285610432
Epoch: 39 | Iteration number: [2220/4518] 49% | Training loss: 0.6871678490896482
Epoch: 39 | Iteration number: [2230/4518] 49% | Training loss: 0.6871666511612623
Epoch: 39 | Iteration number: [2240/4518] 49% | Training loss: 0.6871645676504289
Epoch: 39 | Iteration number: [2250/4518] 49% | Training loss: 0.6871669832865397
Epoch: 39 | Iteration number: [2260/4518] 50% | Training loss: 0.687167373273225
Epoch: 39 | Iteration number: [2270/4518] 50% | Training loss: 0.6871632209433333
Epoch: 39 | Iteration number: [2280/4518] 50% | Training loss: 0.6871659380824943
Epoch: 39 | Iteration number: [2290/4518] 50% | Training loss: 0.6871655559435682
Epoch: 39 | Iteration number: [2300/4518] 50% | Training loss: 0.687161893222643
Epoch: 39 | Iteration number: [2310/4518] 51% | Training loss: 0.6871585975219677
Epoch: 39 | Iteration number: [2320/4518] 51% | Training loss: 0.6871590090722873
Epoch: 39 | Iteration number: [2330/4518] 51% | Training loss: 0.6871567339600412
Epoch: 39 | Iteration number: [2340/4518] 51% | Training loss: 0.6871563435110272
Epoch: 39 | Iteration number: [2350/4518] 52% | Training loss: 0.6871555825497242
Epoch: 39 | Iteration number: [2360/4518] 52% | Training loss: 0.6871527484665483
Epoch: 39 | Iteration number: [2370/4518] 52% | Training loss: 0.6871586783525813
Epoch: 39 | Iteration number: [2380/4518] 52% | Training loss: 0.687157750630579
Epoch: 39 | Iteration number: [2390/4518] 52% | Training loss: 0.6871504845479542
Epoch: 39 | Iteration number: [2400/4518] 53% | Training loss: 0.6871505639702081
Epoch: 39 | Iteration number: [2410/4518] 53% | Training loss: 0.6871508537486382
Epoch: 39 | Iteration number: [2420/4518] 53% | Training loss: 0.6871470387316932
Epoch: 39 | Iteration number: [2430/4518] 53% | Training loss: 0.6871473685704141
Epoch: 39 | Iteration number: [2440/4518] 54% | Training loss: 0.6871442302328641
Epoch: 39 | Iteration number: [2450/4518] 54% | Training loss: 0.6871444994089555
Epoch: 39 | Iteration number: [2460/4518] 54% | Training loss: 0.6871478136477431
Epoch: 39 | Iteration number: [2470/4518] 54% | Training loss: 0.6871424283817229
Epoch: 39 | Iteration number: [2480/4518] 54% | Training loss: 0.6871435945553165
Epoch: 39 | Iteration number: [2490/4518] 55% | Training loss: 0.6871392977285576
Epoch: 39 | Iteration number: [2500/4518] 55% | Training loss: 0.6871382061243058
Epoch: 39 | Iteration number: [2510/4518] 55% | Training loss: 0.6871377553835333
Epoch: 39 | Iteration number: [2520/4518] 55% | Training loss: 0.6871320207440664
Epoch: 39 | Iteration number: [2530/4518] 55% | Training loss: 0.6871290204788857
Epoch: 39 | Iteration number: [2540/4518] 56% | Training loss: 0.6871269739049626
Epoch: 39 | Iteration number: [2550/4518] 56% | Training loss: 0.6871250738817103
Epoch: 39 | Iteration number: [2560/4518] 56% | Training loss: 0.6871249939315021
Epoch: 39 | Iteration number: [2570/4518] 56% | Training loss: 0.6871284177794994
Epoch: 39 | Iteration number: [2580/4518] 57% | Training loss: 0.6871271687653637
Epoch: 39 | Iteration number: [2590/4518] 57% | Training loss: 0.6871230131870991
Epoch: 39 | Iteration number: [2600/4518] 57% | Training loss: 0.6871201498691852
Epoch: 39 | Iteration number: [2610/4518] 57% | Training loss: 0.6871177026823563
Epoch: 39 | Iteration number: [2620/4518] 57% | Training loss: 0.6871133911018154
Epoch: 39 | Iteration number: [2630/4518] 58% | Training loss: 0.6871110477148353
Epoch: 39 | Iteration number: [2640/4518] 58% | Training loss: 0.6871147974196709
Epoch: 39 | Iteration number: [2650/4518] 58% | Training loss: 0.6871161450080152
Epoch: 39 | Iteration number: [2660/4518] 58% | Training loss: 0.6871098737071332
Epoch: 39 | Iteration number: [2670/4518] 59% | Training loss: 0.6871125454090061
Epoch: 39 | Iteration number: [2680/4518] 59% | Training loss: 0.6871072608365941
Epoch: 39 | Iteration number: [2690/4518] 59% | Training loss: 0.6871084823484315
Epoch: 39 | Iteration number: [2700/4518] 59% | Training loss: 0.6871084117447889
Epoch: 39 | Iteration number: [2710/4518] 59% | Training loss: 0.6871113939478829
Epoch: 39 | Iteration number: [2720/4518] 60% | Training loss: 0.6871092089616201
Epoch: 39 | Iteration number: [2730/4518] 60% | Training loss: 0.6871112638995761
Epoch: 39 | Iteration number: [2740/4518] 60% | Training loss: 0.6871092823952654
Epoch: 39 | Iteration number: [2750/4518] 60% | Training loss: 0.6871112039089203
Epoch: 39 | Iteration number: [2760/4518] 61% | Training loss: 0.6871158881463866
Epoch: 39 | Iteration number: [2770/4518] 61% | Training loss: 0.6871176660276062
Epoch: 39 | Iteration number: [2780/4518] 61% | Training loss: 0.6871157033194741
Epoch: 39 | Iteration number: [2790/4518] 61% | Training loss: 0.6871135074605224
Epoch: 39 | Iteration number: [2800/4518] 61% | Training loss: 0.6871086491431508
Epoch: 39 | Iteration number: [2810/4518] 62% | Training loss: 0.6871124074340291
Epoch: 39 | Iteration number: [2820/4518] 62% | Training loss: 0.6871151356620991
Epoch: 39 | Iteration number: [2830/4518] 62% | Training loss: 0.6871158183884705
Epoch: 39 | Iteration number: [2840/4518] 62% | Training loss: 0.6871147910893803
Epoch: 39 | Iteration number: [2850/4518] 63% | Training loss: 0.6871137915577805
Epoch: 39 | Iteration number: [2860/4518] 63% | Training loss: 0.6871163478264442
Epoch: 39 | Iteration number: [2870/4518] 63% | Training loss: 0.6871152354865124
Epoch: 39 | Iteration number: [2880/4518] 63% | Training loss: 0.6871134007349611
Epoch: 39 | Iteration number: [2890/4518] 63% | Training loss: 0.6871168104422546
Epoch: 39 | Iteration number: [2900/4518] 64% | Training loss: 0.6871172833648221
Epoch: 39 | Iteration number: [2910/4518] 64% | Training loss: 0.6871161927677102
Epoch: 39 | Iteration number: [2920/4518] 64% | Training loss: 0.6871168015550261
Epoch: 39 | Iteration number: [2930/4518] 64% | Training loss: 0.6871124871354868
Epoch: 39 | Iteration number: [2940/4518] 65% | Training loss: 0.6871110249336074
Epoch: 39 | Iteration number: [2950/4518] 65% | Training loss: 0.6871097011485342
Epoch: 39 | Iteration number: [2960/4518] 65% | Training loss: 0.6871095860729346
Epoch: 39 | Iteration number: [2970/4518] 65% | Training loss: 0.6871073090668881
Epoch: 39 | Iteration number: [2980/4518] 65% | Training loss: 0.6871031628159069
Epoch: 39 | Iteration number: [2990/4518] 66% | Training loss: 0.6871025354168487
Epoch: 39 | Iteration number: [3000/4518] 66% | Training loss: 0.6870981947779655
Epoch: 39 | Iteration number: [3010/4518] 66% | Training loss: 0.6870963185530564
Epoch: 39 | Iteration number: [3020/4518] 66% | Training loss: 0.6870982173657575
Epoch: 39 | Iteration number: [3030/4518] 67% | Training loss: 0.6870952551907832
Epoch: 39 | Iteration number: [3040/4518] 67% | Training loss: 0.6870947418636397
Epoch: 39 | Iteration number: [3050/4518] 67% | Training loss: 0.6870918369097788
Epoch: 39 | Iteration number: [3060/4518] 67% | Training loss: 0.6870894522059198
Epoch: 39 | Iteration number: [3070/4518] 67% | Training loss: 0.6870893707492841
Epoch: 39 | Iteration number: [3080/4518] 68% | Training loss: 0.6870887904778703
Epoch: 39 | Iteration number: [3090/4518] 68% | Training loss: 0.6870876091004962
Epoch: 39 | Iteration number: [3100/4518] 68% | Training loss: 0.6870883053348911
Epoch: 39 | Iteration number: [3110/4518] 68% | Training loss: 0.6870870532521864
Epoch: 39 | Iteration number: [3120/4518] 69% | Training loss: 0.6870910370961214
Epoch: 39 | Iteration number: [3130/4518] 69% | Training loss: 0.6870897856764139
Epoch: 39 | Iteration number: [3140/4518] 69% | Training loss: 0.6870870435313814
Epoch: 39 | Iteration number: [3150/4518] 69% | Training loss: 0.6870851973503355
Epoch: 39 | Iteration number: [3160/4518] 69% | Training loss: 0.6870825512876994
Epoch: 39 | Iteration number: [3170/4518] 70% | Training loss: 0.6870828427538886
Epoch: 39 | Iteration number: [3180/4518] 70% | Training loss: 0.6870820137502263
Epoch: 39 | Iteration number: [3190/4518] 70% | Training loss: 0.6870791919739643
Epoch: 39 | Iteration number: [3200/4518] 70% | Training loss: 0.6870740803331137
Epoch: 39 | Iteration number: [3210/4518] 71% | Training loss: 0.6870716009184579
Epoch: 39 | Iteration number: [3220/4518] 71% | Training loss: 0.6870696873213193
Epoch: 39 | Iteration number: [3230/4518] 71% | Training loss: 0.6870711024700673
Epoch: 39 | Iteration number: [3240/4518] 71% | Training loss: 0.6870686499424923
Epoch: 39 | Iteration number: [3250/4518] 71% | Training loss: 0.6870659007842724
Epoch: 39 | Iteration number: [3260/4518] 72% | Training loss: 0.6870654502894981
Epoch: 39 | Iteration number: [3270/4518] 72% | Training loss: 0.6870637702467974
Epoch: 39 | Iteration number: [3280/4518] 72% | Training loss: 0.6870619585783017
Epoch: 39 | Iteration number: [3290/4518] 72% | Training loss: 0.6870587302921028
Epoch: 39 | Iteration number: [3300/4518] 73% | Training loss: 0.6870612079085726
Epoch: 39 | Iteration number: [3310/4518] 73% | Training loss: 0.6870647209468564
Epoch: 39 | Iteration number: [3320/4518] 73% | Training loss: 0.6870652350137033
Epoch: 39 | Iteration number: [3330/4518] 73% | Training loss: 0.687064582521135
Epoch: 39 | Iteration number: [3340/4518] 73% | Training loss: 0.6870582244174923
Epoch: 39 | Iteration number: [3350/4518] 74% | Training loss: 0.6870540528866782
Epoch: 39 | Iteration number: [3360/4518] 74% | Training loss: 0.6870545182022311
Epoch: 39 | Iteration number: [3370/4518] 74% | Training loss: 0.6870530506446737
Epoch: 39 | Iteration number: [3380/4518] 74% | Training loss: 0.6870542811395148
Epoch: 39 | Iteration number: [3390/4518] 75% | Training loss: 0.6870511345103779
Epoch: 39 | Iteration number: [3400/4518] 75% | Training loss: 0.6870523118972778
Epoch: 39 | Iteration number: [3410/4518] 75% | Training loss: 0.6870529050701175
Epoch: 39 | Iteration number: [3420/4518] 75% | Training loss: 0.6870517570024345
Epoch: 39 | Iteration number: [3430/4518] 75% | Training loss: 0.6870556602672655
Epoch: 39 | Iteration number: [3440/4518] 76% | Training loss: 0.6870559512702532
Epoch: 39 | Iteration number: [3450/4518] 76% | Training loss: 0.6870536376773447
Epoch: 39 | Iteration number: [3460/4518] 76% | Training loss: 0.6870579126253293
Epoch: 39 | Iteration number: [3470/4518] 76% | Training loss: 0.6870566847860298
Epoch: 39 | Iteration number: [3480/4518] 77% | Training loss: 0.6870577860323862
Epoch: 39 | Iteration number: [3490/4518] 77% | Training loss: 0.687056794139239
Epoch: 39 | Iteration number: [3500/4518] 77% | Training loss: 0.6870573629651751
Epoch: 39 | Iteration number: [3510/4518] 77% | Training loss: 0.6870582233636807
Epoch: 39 | Iteration number: [3520/4518] 77% | Training loss: 0.6870523143729026
Epoch: 39 | Iteration number: [3530/4518] 78% | Training loss: 0.6870508597525253
Epoch: 39 | Iteration number: [3540/4518] 78% | Training loss: 0.6870526714681906
Epoch: 39 | Iteration number: [3550/4518] 78% | Training loss: 0.6870526710698303
Epoch: 39 | Iteration number: [3560/4518] 78% | Training loss: 0.6870533625563878
Epoch: 39 | Iteration number: [3570/4518] 79% | Training loss: 0.6870550758197528
Epoch: 39 | Iteration number: [3580/4518] 79% | Training loss: 0.687053709140037
Epoch: 39 | Iteration number: [3590/4518] 79% | Training loss: 0.687055533393844
Epoch: 39 | Iteration number: [3600/4518] 79% | Training loss: 0.6870518584383859
Epoch: 39 | Iteration number: [3610/4518] 79% | Training loss: 0.6870515838059031
Epoch: 39 | Iteration number: [3620/4518] 80% | Training loss: 0.6870520778617806
Epoch: 39 | Iteration number: [3630/4518] 80% | Training loss: 0.6870527375335536
Epoch: 39 | Iteration number: [3640/4518] 80% | Training loss: 0.6870535915697014
Epoch: 39 | Iteration number: [3650/4518] 80% | Training loss: 0.6870513197493879
Epoch: 39 | Iteration number: [3660/4518] 81% | Training loss: 0.6870470270107353
Epoch: 39 | Iteration number: [3670/4518] 81% | Training loss: 0.687047641072676
Epoch: 39 | Iteration number: [3680/4518] 81% | Training loss: 0.6870462079734906
Epoch: 39 | Iteration number: [3690/4518] 81% | Training loss: 0.6870449673677201
Epoch: 39 | Iteration number: [3700/4518] 81% | Training loss: 0.6870401556588508
Epoch: 39 | Iteration number: [3710/4518] 82% | Training loss: 0.6870398200747138
Epoch: 39 | Iteration number: [3720/4518] 82% | Training loss: 0.6870409317394739
Epoch: 39 | Iteration number: [3730/4518] 82% | Training loss: 0.6870417474102398
Epoch: 39 | Iteration number: [3740/4518] 82% | Training loss: 0.6870436260088242
Epoch: 39 | Iteration number: [3750/4518] 83% | Training loss: 0.687043145386378
Epoch: 39 | Iteration number: [3760/4518] 83% | Training loss: 0.6870448670013154
Epoch: 39 | Iteration number: [3770/4518] 83% | Training loss: 0.6870442742694278
Epoch: 39 | Iteration number: [3780/4518] 83% | Training loss: 0.6870455687796628
Epoch: 39 | Iteration number: [3790/4518] 83% | Training loss: 0.6870435429908984
Epoch: 39 | Iteration number: [3800/4518] 84% | Training loss: 0.6870435439756042
Epoch: 39 | Iteration number: [3810/4518] 84% | Training loss: 0.6870355423041216
Epoch: 39 | Iteration number: [3820/4518] 84% | Training loss: 0.6870358343679868
Epoch: 39 | Iteration number: [3830/4518] 84% | Training loss: 0.687033122264374
Epoch: 39 | Iteration number: [3840/4518] 84% | Training loss: 0.6870328408510734
Epoch: 39 | Iteration number: [3850/4518] 85% | Training loss: 0.6870303765365056
Epoch: 39 | Iteration number: [3860/4518] 85% | Training loss: 0.6870284962221749
Epoch: 39 | Iteration number: [3870/4518] 85% | Training loss: 0.6870308402588817
Epoch: 39 | Iteration number: [3880/4518] 85% | Training loss: 0.6870325938174405
Epoch: 39 | Iteration number: [3890/4518] 86% | Training loss: 0.687032935291452
Epoch: 39 | Iteration number: [3900/4518] 86% | Training loss: 0.687032089019433
Epoch: 39 | Iteration number: [3910/4518] 86% | Training loss: 0.6870317043093465
Epoch: 39 | Iteration number: [3920/4518] 86% | Training loss: 0.6870315215569369
Epoch: 39 | Iteration number: [3930/4518] 86% | Training loss: 0.6870300731282805
Epoch: 39 | Iteration number: [3940/4518] 87% | Training loss: 0.6870307823274341
Epoch: 39 | Iteration number: [3950/4518] 87% | Training loss: 0.6870264664480957
Epoch: 39 | Iteration number: [3960/4518] 87% | Training loss: 0.687028292513857
Epoch: 39 | Iteration number: [3970/4518] 87% | Training loss: 0.6870280690097088
Epoch: 39 | Iteration number: [3980/4518] 88% | Training loss: 0.6870252136908583
Epoch: 39 | Iteration number: [3990/4518] 88% | Training loss: 0.6870227034378769
Epoch: 39 | Iteration number: [4000/4518] 88% | Training loss: 0.6870189005881548
Epoch: 39 | Iteration number: [4010/4518] 88% | Training loss: 0.6870194305951458
Epoch: 39 | Iteration number: [4020/4518] 88% | Training loss: 0.6870199926457001
Epoch: 39 | Iteration number: [4030/4518] 89% | Training loss: 0.6870190464533292
Epoch: 39 | Iteration number: [4040/4518] 89% | Training loss: 0.6870168553720607
Epoch: 39 | Iteration number: [4050/4518] 89% | Training loss: 0.6870160462238171
Epoch: 39 | Iteration number: [4060/4518] 89% | Training loss: 0.6870152561829008
Epoch: 39 | Iteration number: [4070/4518] 90% | Training loss: 0.6870178625683234
Epoch: 39 | Iteration number: [4080/4518] 90% | Training loss: 0.687017654349991
Epoch: 39 | Iteration number: [4090/4518] 90% | Training loss: 0.6870191085600911
Epoch: 39 | Iteration number: [4100/4518] 90% | Training loss: 0.687018829307905
Epoch: 39 | Iteration number: [4110/4518] 90% | Training loss: 0.6870180871219821
Epoch: 39 | Iteration number: [4120/4518] 91% | Training loss: 0.687019316779757
Epoch: 39 | Iteration number: [4130/4518] 91% | Training loss: 0.6870172432202115
Epoch: 39 | Iteration number: [4140/4518] 91% | Training loss: 0.6870166506456292
Epoch: 39 | Iteration number: [4150/4518] 91% | Training loss: 0.6870168075216821
Epoch: 39 | Iteration number: [4160/4518] 92% | Training loss: 0.6870178062038926
Epoch: 39 | Iteration number: [4170/4518] 92% | Training loss: 0.687016595553437
Epoch: 39 | Iteration number: [4180/4518] 92% | Training loss: 0.6870176913920772
Epoch: 39 | Iteration number: [4190/4518] 92% | Training loss: 0.6870149403454865
Epoch: 39 | Iteration number: [4200/4518] 92% | Training loss: 0.6870121467255411
Epoch: 39 | Iteration number: [4210/4518] 93% | Training loss: 0.6870096716490041
Epoch: 39 | Iteration number: [4220/4518] 93% | Training loss: 0.687008182499646
Epoch: 39 | Iteration number: [4230/4518] 93% | Training loss: 0.6870099181542724
Epoch: 39 | Iteration number: [4240/4518] 93% | Training loss: 0.6870071753016058
Epoch: 39 | Iteration number: [4250/4518] 94% | Training loss: 0.6870074063749875
Epoch: 39 | Iteration number: [4260/4518] 94% | Training loss: 0.6870092783035807
Epoch: 39 | Iteration number: [4270/4518] 94% | Training loss: 0.6870090466193349
Epoch: 39 | Iteration number: [4280/4518] 94% | Training loss: 0.6870057725182204
Epoch: 39 | Iteration number: [4290/4518] 94% | Training loss: 0.687007527501433
Epoch: 39 | Iteration number: [4300/4518] 95% | Training loss: 0.6870049688150717
Epoch: 39 | Iteration number: [4310/4518] 95% | Training loss: 0.6870044966861433
Epoch: 39 | Iteration number: [4320/4518] 95% | Training loss: 0.6870026266685239
Epoch: 39 | Iteration number: [4330/4518] 95% | Training loss: 0.6870008234339002
Epoch: 39 | Iteration number: [4340/4518] 96% | Training loss: 0.686998920245654
Epoch: 39 | Iteration number: [4350/4518] 96% | Training loss: 0.6869996209665277
Epoch: 39 | Iteration number: [4360/4518] 96% | Training loss: 0.6870003758493913
Epoch: 39 | Iteration number: [4370/4518] 96% | Training loss: 0.6869988362358146
Epoch: 39 | Iteration number: [4380/4518] 96% | Training loss: 0.6869964551980092
Epoch: 39 | Iteration number: [4390/4518] 97% | Training loss: 0.6869949679439866
Epoch: 39 | Iteration number: [4400/4518] 97% | Training loss: 0.6869957201995632
Epoch: 39 | Iteration number: [4410/4518] 97% | Training loss: 0.6869922999892375
Epoch: 39 | Iteration number: [4420/4518] 97% | Training loss: 0.6869913736484708
Epoch: 39 | Iteration number: [4430/4518] 98% | Training loss: 0.68699380102868
Epoch: 39 | Iteration number: [4440/4518] 98% | Training loss: 0.6869906805522807
Epoch: 39 | Iteration number: [4450/4518] 98% | Training loss: 0.6869901418418027
Epoch: 39 | Iteration number: [4460/4518] 98% | Training loss: 0.6869878847235521
Epoch: 39 | Iteration number: [4470/4518] 98% | Training loss: 0.6869856424379669
Epoch: 39 | Iteration number: [4480/4518] 99% | Training loss: 0.6869856909715704
Epoch: 39 | Iteration number: [4490/4518] 99% | Training loss: 0.6869837940668476
Epoch: 39 | Iteration number: [4500/4518] 99% | Training loss: 0.6869858428239822
Epoch: 39 | Iteration number: [4510/4518] 99% | Training loss: 0.686984048027157

 End of epoch: 39 | Train Loss: 0.6868334053205463 | Training Time: 639 

 End of epoch: 39 | Eval Loss: 0.6900307195527213 | Evaluating Time: 17 
Epoch: 40 | Iteration number: [10/4518] 0% | Training loss: 0.7560910165309906
Epoch: 40 | Iteration number: [20/4518] 0% | Training loss: 0.7217823028564453
Epoch: 40 | Iteration number: [30/4518] 0% | Training loss: 0.7099503338336944
Epoch: 40 | Iteration number: [40/4518] 0% | Training loss: 0.7042440205812455
Epoch: 40 | Iteration number: [50/4518] 1% | Training loss: 0.700880184173584
Epoch: 40 | Iteration number: [60/4518] 1% | Training loss: 0.6983584572871526
Epoch: 40 | Iteration number: [70/4518] 1% | Training loss: 0.6965451487473079
Epoch: 40 | Iteration number: [80/4518] 1% | Training loss: 0.6951999694108963
Epoch: 40 | Iteration number: [90/4518] 1% | Training loss: 0.6942676716380649
Epoch: 40 | Iteration number: [100/4518] 2% | Training loss: 0.6936571705341339
Epoch: 40 | Iteration number: [110/4518] 2% | Training loss: 0.6929706551811912
Epoch: 40 | Iteration number: [120/4518] 2% | Training loss: 0.6924334734678268
Epoch: 40 | Iteration number: [130/4518] 2% | Training loss: 0.6919253330964309
Epoch: 40 | Iteration number: [140/4518] 3% | Training loss: 0.6916311774935041
Epoch: 40 | Iteration number: [150/4518] 3% | Training loss: 0.6913652312755585
Epoch: 40 | Iteration number: [160/4518] 3% | Training loss: 0.6910628821700812
Epoch: 40 | Iteration number: [170/4518] 3% | Training loss: 0.6908121526241302
Epoch: 40 | Iteration number: [180/4518] 3% | Training loss: 0.6905459052986569
Epoch: 40 | Iteration number: [190/4518] 4% | Training loss: 0.6903363886632418
Epoch: 40 | Iteration number: [200/4518] 4% | Training loss: 0.6901419565081597
Epoch: 40 | Iteration number: [210/4518] 4% | Training loss: 0.6899819226492019
Epoch: 40 | Iteration number: [220/4518] 4% | Training loss: 0.6898504809899764
Epoch: 40 | Iteration number: [230/4518] 5% | Training loss: 0.6896610503611358
Epoch: 40 | Iteration number: [240/4518] 5% | Training loss: 0.6895051593581836
Epoch: 40 | Iteration number: [250/4518] 5% | Training loss: 0.6894109561443329
Epoch: 40 | Iteration number: [260/4518] 5% | Training loss: 0.689310018145121
Epoch: 40 | Iteration number: [270/4518] 5% | Training loss: 0.6892428910290753
Epoch: 40 | Iteration number: [280/4518] 6% | Training loss: 0.6891607058899744
Epoch: 40 | Iteration number: [290/4518] 6% | Training loss: 0.689116666440306
Epoch: 40 | Iteration number: [300/4518] 6% | Training loss: 0.6890501632293066
Epoch: 40 | Iteration number: [310/4518] 6% | Training loss: 0.6890074051195575
Epoch: 40 | Iteration number: [320/4518] 7% | Training loss: 0.6889338785782456
Epoch: 40 | Iteration number: [330/4518] 7% | Training loss: 0.6888709886507555
Epoch: 40 | Iteration number: [340/4518] 7% | Training loss: 0.6887852498713661
Epoch: 40 | Iteration number: [350/4518] 7% | Training loss: 0.6887222840104784
Epoch: 40 | Iteration number: [360/4518] 7% | Training loss: 0.6886733333269756
Epoch: 40 | Iteration number: [370/4518] 8% | Training loss: 0.6886325196639912
Epoch: 40 | Iteration number: [380/4518] 8% | Training loss: 0.6885834278244721
Epoch: 40 | Iteration number: [390/4518] 8% | Training loss: 0.6885469309794597
Epoch: 40 | Iteration number: [400/4518] 8% | Training loss: 0.688488207012415
Epoch: 40 | Iteration number: [410/4518] 9% | Training loss: 0.6884817230992201
Epoch: 40 | Iteration number: [420/4518] 9% | Training loss: 0.6884397789126351
Epoch: 40 | Iteration number: [430/4518] 9% | Training loss: 0.6883983528891275
Epoch: 40 | Iteration number: [440/4518] 9% | Training loss: 0.6883938419547948
Epoch: 40 | Iteration number: [450/4518] 9% | Training loss: 0.6883758890628815
Epoch: 40 | Iteration number: [460/4518] 10% | Training loss: 0.6883367902558782
Epoch: 40 | Iteration number: [470/4518] 10% | Training loss: 0.688301839219763
Epoch: 40 | Iteration number: [480/4518] 10% | Training loss: 0.6882685467600822
Epoch: 40 | Iteration number: [490/4518] 10% | Training loss: 0.6882645356411836
Epoch: 40 | Iteration number: [500/4518] 11% | Training loss: 0.6882400854825973
Epoch: 40 | Iteration number: [510/4518] 11% | Training loss: 0.6882101205049777
Epoch: 40 | Iteration number: [520/4518] 11% | Training loss: 0.6881721921838246
Epoch: 40 | Iteration number: [530/4518] 11% | Training loss: 0.6881554663181305
Epoch: 40 | Iteration number: [540/4518] 11% | Training loss: 0.6881528258323669
Epoch: 40 | Iteration number: [550/4518] 12% | Training loss: 0.6881088070435958
Epoch: 40 | Iteration number: [560/4518] 12% | Training loss: 0.6880909821816853
Epoch: 40 | Iteration number: [570/4518] 12% | Training loss: 0.6880270069105583
Epoch: 40 | Iteration number: [580/4518] 12% | Training loss: 0.6880178732090982
Epoch: 40 | Iteration number: [590/4518] 13% | Training loss: 0.6879811752650697
Epoch: 40 | Iteration number: [600/4518] 13% | Training loss: 0.6879734430710475
Epoch: 40 | Iteration number: [610/4518] 13% | Training loss: 0.6879418783500546
Epoch: 40 | Iteration number: [620/4518] 13% | Training loss: 0.6879095624531469
Epoch: 40 | Iteration number: [630/4518] 13% | Training loss: 0.6878850813895937
Epoch: 40 | Iteration number: [640/4518] 14% | Training loss: 0.6878617705777288
Epoch: 40 | Iteration number: [650/4518] 14% | Training loss: 0.6878718500870925
Epoch: 40 | Iteration number: [660/4518] 14% | Training loss: 0.6878642283605807
Epoch: 40 | Iteration number: [670/4518] 14% | Training loss: 0.6878178842032133
Epoch: 40 | Iteration number: [680/4518] 15% | Training loss: 0.6878084138912313
Epoch: 40 | Iteration number: [690/4518] 15% | Training loss: 0.6878096025923024
Epoch: 40 | Iteration number: [700/4518] 15% | Training loss: 0.6877972826787404
Epoch: 40 | Iteration number: [710/4518] 15% | Training loss: 0.6877944608809243
Epoch: 40 | Iteration number: [720/4518] 15% | Training loss: 0.6877931045161353
Epoch: 40 | Iteration number: [730/4518] 16% | Training loss: 0.6877797793035638
Epoch: 40 | Iteration number: [740/4518] 16% | Training loss: 0.6877963640399881
Epoch: 40 | Iteration number: [750/4518] 16% | Training loss: 0.6877879757086436
Epoch: 40 | Iteration number: [760/4518] 16% | Training loss: 0.6877676912828495
Epoch: 40 | Iteration number: [770/4518] 17% | Training loss: 0.6877569539206368
Epoch: 40 | Iteration number: [780/4518] 17% | Training loss: 0.6877429256072412
Epoch: 40 | Iteration number: [790/4518] 17% | Training loss: 0.6877338987362536
Epoch: 40 | Iteration number: [800/4518] 17% | Training loss: 0.6877175806462765
Epoch: 40 | Iteration number: [810/4518] 17% | Training loss: 0.6877044039008058
Epoch: 40 | Iteration number: [820/4518] 18% | Training loss: 0.6876841110427205
Epoch: 40 | Iteration number: [830/4518] 18% | Training loss: 0.6876613699528108
Epoch: 40 | Iteration number: [840/4518] 18% | Training loss: 0.6876418565000807
Epoch: 40 | Iteration number: [850/4518] 18% | Training loss: 0.6876407516703886
Epoch: 40 | Iteration number: [860/4518] 19% | Training loss: 0.6876335981280305
Epoch: 40 | Iteration number: [870/4518] 19% | Training loss: 0.6876334550736964
Epoch: 40 | Iteration number: [880/4518] 19% | Training loss: 0.6876300514421679
Epoch: 40 | Iteration number: [890/4518] 19% | Training loss: 0.6876287291558941
Epoch: 40 | Iteration number: [900/4518] 19% | Training loss: 0.6876022800472048
Epoch: 40 | Iteration number: [910/4518] 20% | Training loss: 0.6875964840034862
Epoch: 40 | Iteration number: [920/4518] 20% | Training loss: 0.6875786632947299
Epoch: 40 | Iteration number: [930/4518] 20% | Training loss: 0.6875658512115479
Epoch: 40 | Iteration number: [940/4518] 20% | Training loss: 0.6875564300633491
Epoch: 40 | Iteration number: [950/4518] 21% | Training loss: 0.6875442114629243
Epoch: 40 | Iteration number: [960/4518] 21% | Training loss: 0.6875419872502486
Epoch: 40 | Iteration number: [970/4518] 21% | Training loss: 0.6875306272015129
Epoch: 40 | Iteration number: [980/4518] 21% | Training loss: 0.6875206867651064
Epoch: 40 | Iteration number: [990/4518] 21% | Training loss: 0.6875230037804806
Epoch: 40 | Iteration number: [1000/4518] 22% | Training loss: 0.6875219712853432
Epoch: 40 | Iteration number: [1010/4518] 22% | Training loss: 0.6875178397882102
Epoch: 40 | Iteration number: [1020/4518] 22% | Training loss: 0.6875157279711144
Epoch: 40 | Iteration number: [1030/4518] 22% | Training loss: 0.6875228641102615
Epoch: 40 | Iteration number: [1040/4518] 23% | Training loss: 0.6875100530110873
Epoch: 40 | Iteration number: [1050/4518] 23% | Training loss: 0.6875087609177544
Epoch: 40 | Iteration number: [1060/4518] 23% | Training loss: 0.6875170786425753
Epoch: 40 | Iteration number: [1070/4518] 23% | Training loss: 0.6875023913160663
Epoch: 40 | Iteration number: [1080/4518] 23% | Training loss: 0.6875006441164899
Epoch: 40 | Iteration number: [1090/4518] 24% | Training loss: 0.6874910833091911
Epoch: 40 | Iteration number: [1100/4518] 24% | Training loss: 0.687491593577645
Epoch: 40 | Iteration number: [1110/4518] 24% | Training loss: 0.6874907258394602
Epoch: 40 | Iteration number: [1120/4518] 24% | Training loss: 0.6874699978956155
Epoch: 40 | Iteration number: [1130/4518] 25% | Training loss: 0.6874724202451453
Epoch: 40 | Iteration number: [1140/4518] 25% | Training loss: 0.6874651645882088
Epoch: 40 | Iteration number: [1150/4518] 25% | Training loss: 0.6874589038413504
Epoch: 40 | Iteration number: [1160/4518] 25% | Training loss: 0.6874547474857035
Epoch: 40 | Iteration number: [1170/4518] 25% | Training loss: 0.6874436670898372
Epoch: 40 | Iteration number: [1180/4518] 26% | Training loss: 0.6874302519580066
Epoch: 40 | Iteration number: [1190/4518] 26% | Training loss: 0.6874201116942558
Epoch: 40 | Iteration number: [1200/4518] 26% | Training loss: 0.6874180554350218
Epoch: 40 | Iteration number: [1210/4518] 26% | Training loss: 0.6874103895888841
Epoch: 40 | Iteration number: [1220/4518] 27% | Training loss: 0.6874034878660421
Epoch: 40 | Iteration number: [1230/4518] 27% | Training loss: 0.68739173412323
Epoch: 40 | Iteration number: [1240/4518] 27% | Training loss: 0.6873889430396019
Epoch: 40 | Iteration number: [1250/4518] 27% | Training loss: 0.6873855111598969
Epoch: 40 | Iteration number: [1260/4518] 27% | Training loss: 0.6873814817931917
Epoch: 40 | Iteration number: [1270/4518] 28% | Training loss: 0.6873691558368563
Epoch: 40 | Iteration number: [1280/4518] 28% | Training loss: 0.687359712086618
Epoch: 40 | Iteration number: [1290/4518] 28% | Training loss: 0.6873601587243783
Epoch: 40 | Iteration number: [1300/4518] 28% | Training loss: 0.6873530904146341
Epoch: 40 | Iteration number: [1310/4518] 28% | Training loss: 0.6873415093385536
Epoch: 40 | Iteration number: [1320/4518] 29% | Training loss: 0.6873409508304162
Epoch: 40 | Iteration number: [1330/4518] 29% | Training loss: 0.687341896080433
Epoch: 40 | Iteration number: [1340/4518] 29% | Training loss: 0.6873351592626145
Epoch: 40 | Iteration number: [1350/4518] 29% | Training loss: 0.6873382216471213
Epoch: 40 | Iteration number: [1360/4518] 30% | Training loss: 0.6873414110611467
Epoch: 40 | Iteration number: [1370/4518] 30% | Training loss: 0.687334998332671
Epoch: 40 | Iteration number: [1380/4518] 30% | Training loss: 0.6873322419498278
Epoch: 40 | Iteration number: [1390/4518] 30% | Training loss: 0.687331262766886
Epoch: 40 | Iteration number: [1400/4518] 30% | Training loss: 0.6873278078436852
Epoch: 40 | Iteration number: [1410/4518] 31% | Training loss: 0.6873277018678949
Epoch: 40 | Iteration number: [1420/4518] 31% | Training loss: 0.6873314216103352
Epoch: 40 | Iteration number: [1430/4518] 31% | Training loss: 0.6873337891551998
Epoch: 40 | Iteration number: [1440/4518] 31% | Training loss: 0.6873319127079514
Epoch: 40 | Iteration number: [1450/4518] 32% | Training loss: 0.6873361051904744
Epoch: 40 | Iteration number: [1460/4518] 32% | Training loss: 0.6873275513926598
Epoch: 40 | Iteration number: [1470/4518] 32% | Training loss: 0.687328844248843
Epoch: 40 | Iteration number: [1480/4518] 32% | Training loss: 0.6873217358379751
Epoch: 40 | Iteration number: [1490/4518] 32% | Training loss: 0.687320428326626
Epoch: 40 | Iteration number: [1500/4518] 33% | Training loss: 0.6873123595714569
Epoch: 40 | Iteration number: [1510/4518] 33% | Training loss: 0.6873053032436118
Epoch: 40 | Iteration number: [1520/4518] 33% | Training loss: 0.6873015574718776
Epoch: 40 | Iteration number: [1530/4518] 33% | Training loss: 0.6873014967036403
Epoch: 40 | Iteration number: [1540/4518] 34% | Training loss: 0.6873049868391706
Epoch: 40 | Iteration number: [1550/4518] 34% | Training loss: 0.687296181186553
Epoch: 40 | Iteration number: [1560/4518] 34% | Training loss: 0.6872945101979452
Epoch: 40 | Iteration number: [1570/4518] 34% | Training loss: 0.6872943434365996
Epoch: 40 | Iteration number: [1580/4518] 34% | Training loss: 0.6872903362482409
Epoch: 40 | Iteration number: [1590/4518] 35% | Training loss: 0.6872827572642632
Epoch: 40 | Iteration number: [1600/4518] 35% | Training loss: 0.6872824787721038
Epoch: 40 | Iteration number: [1610/4518] 35% | Training loss: 0.687282362376681
Epoch: 40 | Iteration number: [1620/4518] 35% | Training loss: 0.6872794834184058
Epoch: 40 | Iteration number: [1630/4518] 36% | Training loss: 0.6872806063458964
Epoch: 40 | Iteration number: [1640/4518] 36% | Training loss: 0.6872771165719846
Epoch: 40 | Iteration number: [1650/4518] 36% | Training loss: 0.6872727579781504
Epoch: 40 | Iteration number: [1660/4518] 36% | Training loss: 0.6872693020895303
Epoch: 40 | Iteration number: [1670/4518] 36% | Training loss: 0.6872614556086991
Epoch: 40 | Iteration number: [1680/4518] 37% | Training loss: 0.6872643456217788
Epoch: 40 | Iteration number: [1690/4518] 37% | Training loss: 0.6872622058236387
Epoch: 40 | Iteration number: [1700/4518] 37% | Training loss: 0.687250730325194
Epoch: 40 | Iteration number: [1710/4518] 37% | Training loss: 0.6872493129724647
Epoch: 40 | Iteration number: [1720/4518] 38% | Training loss: 0.6872484120518663
Epoch: 40 | Iteration number: [1730/4518] 38% | Training loss: 0.6872450779972737
Epoch: 40 | Iteration number: [1740/4518] 38% | Training loss: 0.6872430736648625
Epoch: 40 | Iteration number: [1750/4518] 38% | Training loss: 0.6872439982209887
Epoch: 40 | Iteration number: [1760/4518] 38% | Training loss: 0.6872390688481655
Epoch: 40 | Iteration number: [1770/4518] 39% | Training loss: 0.6872369730539915
Epoch: 40 | Iteration number: [1780/4518] 39% | Training loss: 0.6872359361876262
Epoch: 40 | Iteration number: [1790/4518] 39% | Training loss: 0.6872287105248627
Epoch: 40 | Iteration number: [1800/4518] 39% | Training loss: 0.6872252200709449
Epoch: 40 | Iteration number: [1810/4518] 40% | Training loss: 0.6872189683150192
Epoch: 40 | Iteration number: [1820/4518] 40% | Training loss: 0.6872155966012032
Epoch: 40 | Iteration number: [1830/4518] 40% | Training loss: 0.6872103365718342
Epoch: 40 | Iteration number: [1840/4518] 40% | Training loss: 0.687205789886091
Epoch: 40 | Iteration number: [1850/4518] 40% | Training loss: 0.687210363504049
Epoch: 40 | Iteration number: [1860/4518] 41% | Training loss: 0.68720846714512
Epoch: 40 | Iteration number: [1870/4518] 41% | Training loss: 0.6872028993094031
Epoch: 40 | Iteration number: [1880/4518] 41% | Training loss: 0.6872059590638953
Epoch: 40 | Iteration number: [1890/4518] 41% | Training loss: 0.6872081786236435
Epoch: 40 | Iteration number: [1900/4518] 42% | Training loss: 0.687210711334881
Epoch: 40 | Iteration number: [1910/4518] 42% | Training loss: 0.6872015192558628
Epoch: 40 | Iteration number: [1920/4518] 42% | Training loss: 0.6871976299832264
Epoch: 40 | Iteration number: [1930/4518] 42% | Training loss: 0.687187406003784
Epoch: 40 | Iteration number: [1940/4518] 42% | Training loss: 0.6871872327684128
Epoch: 40 | Iteration number: [1950/4518] 43% | Training loss: 0.6871852860389611
Epoch: 40 | Iteration number: [1960/4518] 43% | Training loss: 0.6871882129080441
Epoch: 40 | Iteration number: [1970/4518] 43% | Training loss: 0.6871880422691403
Epoch: 40 | Iteration number: [1980/4518] 43% | Training loss: 0.6871854129764768
Epoch: 40 | Iteration number: [1990/4518] 44% | Training loss: 0.6871879900220651
Epoch: 40 | Iteration number: [2000/4518] 44% | Training loss: 0.6871815549731255
Epoch: 40 | Iteration number: [2010/4518] 44% | Training loss: 0.6871753016811105
Epoch: 40 | Iteration number: [2020/4518] 44% | Training loss: 0.6871719510543465
Epoch: 40 | Iteration number: [2030/4518] 44% | Training loss: 0.6871734580089306
Epoch: 40 | Iteration number: [2040/4518] 45% | Training loss: 0.6871726568423066
Epoch: 40 | Iteration number: [2050/4518] 45% | Training loss: 0.6871740124283767
Epoch: 40 | Iteration number: [2060/4518] 45% | Training loss: 0.6871706811259094
Epoch: 40 | Iteration number: [2070/4518] 45% | Training loss: 0.6871708709836583
Epoch: 40 | Iteration number: [2080/4518] 46% | Training loss: 0.6871718388910477
Epoch: 40 | Iteration number: [2090/4518] 46% | Training loss: 0.687168637303074
Epoch: 40 | Iteration number: [2100/4518] 46% | Training loss: 0.6871678622563681
Epoch: 40 | Iteration number: [2110/4518] 46% | Training loss: 0.6871772663005721
Epoch: 40 | Iteration number: [2120/4518] 46% | Training loss: 0.6871713099052321
Epoch: 40 | Iteration number: [2130/4518] 47% | Training loss: 0.6871689369700884
Epoch: 40 | Iteration number: [2140/4518] 47% | Training loss: 0.6871685294625915
Epoch: 40 | Iteration number: [2150/4518] 47% | Training loss: 0.6871641831065333
Epoch: 40 | Iteration number: [2160/4518] 47% | Training loss: 0.6871632013607908
Epoch: 40 | Iteration number: [2170/4518] 48% | Training loss: 0.6871627083571825
Epoch: 40 | Iteration number: [2180/4518] 48% | Training loss: 0.6871617395943458
Epoch: 40 | Iteration number: [2190/4518] 48% | Training loss: 0.6871609930578432
Epoch: 40 | Iteration number: [2200/4518] 48% | Training loss: 0.6871575754068114
Epoch: 40 | Iteration number: [2210/4518] 48% | Training loss: 0.6871546780092145
Epoch: 40 | Iteration number: [2220/4518] 49% | Training loss: 0.6871482486928906
Epoch: 40 | Iteration number: [2230/4518] 49% | Training loss: 0.6871489786781003
Epoch: 40 | Iteration number: [2240/4518] 49% | Training loss: 0.6871409349941782
Epoch: 40 | Iteration number: [2250/4518] 49% | Training loss: 0.6871352792580923
Epoch: 40 | Iteration number: [2260/4518] 50% | Training loss: 0.6871372600044824
Epoch: 40 | Iteration number: [2270/4518] 50% | Training loss: 0.6871340184747385
Epoch: 40 | Iteration number: [2280/4518] 50% | Training loss: 0.6871363464938967
Epoch: 40 | Iteration number: [2290/4518] 50% | Training loss: 0.687137395612017
Epoch: 40 | Iteration number: [2300/4518] 50% | Training loss: 0.687138782635979
Epoch: 40 | Iteration number: [2310/4518] 51% | Training loss: 0.6871350231108727
Epoch: 40 | Iteration number: [2320/4518] 51% | Training loss: 0.6871312997721393
Epoch: 40 | Iteration number: [2330/4518] 51% | Training loss: 0.6871302538419486
Epoch: 40 | Iteration number: [2340/4518] 51% | Training loss: 0.6871294256458934
Epoch: 40 | Iteration number: [2350/4518] 52% | Training loss: 0.6871297345516529
Epoch: 40 | Iteration number: [2360/4518] 52% | Training loss: 0.6871308547207865
Epoch: 40 | Iteration number: [2370/4518] 52% | Training loss: 0.6871299516802599
Epoch: 40 | Iteration number: [2380/4518] 52% | Training loss: 0.6871281045324662
Epoch: 40 | Iteration number: [2390/4518] 52% | Training loss: 0.6871244184641658
Epoch: 40 | Iteration number: [2400/4518] 53% | Training loss: 0.687124650105834
Epoch: 40 | Iteration number: [2410/4518] 53% | Training loss: 0.6871222189600537
Epoch: 40 | Iteration number: [2420/4518] 53% | Training loss: 0.6871245809823028
Epoch: 40 | Iteration number: [2430/4518] 53% | Training loss: 0.687119038580867
Epoch: 40 | Iteration number: [2440/4518] 54% | Training loss: 0.6871158982886643
Epoch: 40 | Iteration number: [2450/4518] 54% | Training loss: 0.68711622364667
Epoch: 40 | Iteration number: [2460/4518] 54% | Training loss: 0.6871154138712379
Epoch: 40 | Iteration number: [2470/4518] 54% | Training loss: 0.6871181889101561
Epoch: 40 | Iteration number: [2480/4518] 54% | Training loss: 0.6871179925337915
Epoch: 40 | Iteration number: [2490/4518] 55% | Training loss: 0.6871202727876993
Epoch: 40 | Iteration number: [2500/4518] 55% | Training loss: 0.6871208091974258
Epoch: 40 | Iteration number: [2510/4518] 55% | Training loss: 0.6871202521115185
Epoch: 40 | Iteration number: [2520/4518] 55% | Training loss: 0.6871218534452574
Epoch: 40 | Iteration number: [2530/4518] 55% | Training loss: 0.6871210020757004
Epoch: 40 | Iteration number: [2540/4518] 56% | Training loss: 0.6871229774369968
Epoch: 40 | Iteration number: [2550/4518] 56% | Training loss: 0.6871215099680658
Epoch: 40 | Iteration number: [2560/4518] 56% | Training loss: 0.6871138964081183
Epoch: 40 | Iteration number: [2570/4518] 56% | Training loss: 0.6871083162174151
Epoch: 40 | Iteration number: [2580/4518] 57% | Training loss: 0.6871125630630079
Epoch: 40 | Iteration number: [2590/4518] 57% | Training loss: 0.6871127386581023
Epoch: 40 | Iteration number: [2600/4518] 57% | Training loss: 0.6871166753310424
Epoch: 40 | Iteration number: [2610/4518] 57% | Training loss: 0.6871116204051679
Epoch: 40 | Iteration number: [2620/4518] 57% | Training loss: 0.687104907313376
Epoch: 40 | Iteration number: [2630/4518] 58% | Training loss: 0.6871026855911139
Epoch: 40 | Iteration number: [2640/4518] 58% | Training loss: 0.6870983470118407
Epoch: 40 | Iteration number: [2650/4518] 58% | Training loss: 0.6870894364815838
Epoch: 40 | Iteration number: [2660/4518] 58% | Training loss: 0.687086835996549
Epoch: 40 | Iteration number: [2670/4518] 59% | Training loss: 0.6870880710498224
Epoch: 40 | Iteration number: [2680/4518] 59% | Training loss: 0.6870841442426638
Epoch: 40 | Iteration number: [2690/4518] 59% | Training loss: 0.687082354043053
Epoch: 40 | Iteration number: [2700/4518] 59% | Training loss: 0.687081445256869
Epoch: 40 | Iteration number: [2710/4518] 59% | Training loss: 0.6870815257964539
Epoch: 40 | Iteration number: [2720/4518] 60% | Training loss: 0.6870813211754841
Epoch: 40 | Iteration number: [2730/4518] 60% | Training loss: 0.6870830695271055
Epoch: 40 | Iteration number: [2740/4518] 60% | Training loss: 0.6870811027767014
Epoch: 40 | Iteration number: [2750/4518] 60% | Training loss: 0.6870770489952781
Epoch: 40 | Iteration number: [2760/4518] 61% | Training loss: 0.6870745531242827
Epoch: 40 | Iteration number: [2770/4518] 61% | Training loss: 0.6870705740116133
Epoch: 40 | Iteration number: [2780/4518] 61% | Training loss: 0.687072608153597
Epoch: 40 | Iteration number: [2790/4518] 61% | Training loss: 0.6870715685642749
Epoch: 40 | Iteration number: [2800/4518] 61% | Training loss: 0.68707316290055
Epoch: 40 | Iteration number: [2810/4518] 62% | Training loss: 0.6870722685844448
Epoch: 40 | Iteration number: [2820/4518] 62% | Training loss: 0.6870732782368965
Epoch: 40 | Iteration number: [2830/4518] 62% | Training loss: 0.687068758204632
Epoch: 40 | Iteration number: [2840/4518] 62% | Training loss: 0.6870677651443952
Epoch: 40 | Iteration number: [2850/4518] 63% | Training loss: 0.6870686147087499
Epoch: 40 | Iteration number: [2860/4518] 63% | Training loss: 0.6870699393165695
Epoch: 40 | Iteration number: [2870/4518] 63% | Training loss: 0.6870694613622872
Epoch: 40 | Iteration number: [2880/4518] 63% | Training loss: 0.6870661629570856
Epoch: 40 | Iteration number: [2890/4518] 63% | Training loss: 0.6870658847493697
Epoch: 40 | Iteration number: [2900/4518] 64% | Training loss: 0.6870624143090741
Epoch: 40 | Iteration number: [2910/4518] 64% | Training loss: 0.6870612829616389
Epoch: 40 | Iteration number: [2920/4518] 64% | Training loss: 0.6870643813520262
Epoch: 40 | Iteration number: [2930/4518] 64% | Training loss: 0.6870663197984468
Epoch: 40 | Iteration number: [2940/4518] 65% | Training loss: 0.6870695234561454
Epoch: 40 | Iteration number: [2950/4518] 65% | Training loss: 0.6870710656602503
Epoch: 40 | Iteration number: [2960/4518] 65% | Training loss: 0.6870699944327007
Epoch: 40 | Iteration number: [2970/4518] 65% | Training loss: 0.6870694337469159
Epoch: 40 | Iteration number: [2980/4518] 65% | Training loss: 0.6870664041314349
Epoch: 40 | Iteration number: [2990/4518] 66% | Training loss: 0.687066132866818
Epoch: 40 | Iteration number: [3000/4518] 66% | Training loss: 0.6870653091669082
Epoch: 40 | Iteration number: [3010/4518] 66% | Training loss: 0.6870662340294087
Epoch: 40 | Iteration number: [3020/4518] 66% | Training loss: 0.687063997036574
Epoch: 40 | Iteration number: [3030/4518] 67% | Training loss: 0.6870612004802565
Epoch: 40 | Iteration number: [3040/4518] 67% | Training loss: 0.6870629601180553
Epoch: 40 | Iteration number: [3050/4518] 67% | Training loss: 0.6870681684525286
Epoch: 40 | Iteration number: [3060/4518] 67% | Training loss: 0.6870664517474331
Epoch: 40 | Iteration number: [3070/4518] 67% | Training loss: 0.6870659978071331
Epoch: 40 | Iteration number: [3080/4518] 68% | Training loss: 0.6870636316088887
Epoch: 40 | Iteration number: [3090/4518] 68% | Training loss: 0.6870666211284094
Epoch: 40 | Iteration number: [3100/4518] 68% | Training loss: 0.687069849621865
Epoch: 40 | Iteration number: [3110/4518] 68% | Training loss: 0.6870704708375348
Epoch: 40 | Iteration number: [3120/4518] 69% | Training loss: 0.6870662592542477
Epoch: 40 | Iteration number: [3130/4518] 69% | Training loss: 0.6870643100609033
Epoch: 40 | Iteration number: [3140/4518] 69% | Training loss: 0.6870662294755316
Epoch: 40 | Iteration number: [3150/4518] 69% | Training loss: 0.6870614086635529
Epoch: 40 | Iteration number: [3160/4518] 69% | Training loss: 0.6870627111649211
Epoch: 40 | Iteration number: [3170/4518] 70% | Training loss: 0.6870624498614001
Epoch: 40 | Iteration number: [3180/4518] 70% | Training loss: 0.6870604950302052
Epoch: 40 | Iteration number: [3190/4518] 70% | Training loss: 0.687056035345251
Epoch: 40 | Iteration number: [3200/4518] 70% | Training loss: 0.6870528136566282
Epoch: 40 | Iteration number: [3210/4518] 71% | Training loss: 0.6870539991655082
Epoch: 40 | Iteration number: [3220/4518] 71% | Training loss: 0.687049225120811
Epoch: 40 | Iteration number: [3230/4518] 71% | Training loss: 0.6870522257713342
Epoch: 40 | Iteration number: [3240/4518] 71% | Training loss: 0.6870496400160554
Epoch: 40 | Iteration number: [3250/4518] 71% | Training loss: 0.6870474410240467
Epoch: 40 | Iteration number: [3260/4518] 72% | Training loss: 0.6870465721272252
Epoch: 40 | Iteration number: [3270/4518] 72% | Training loss: 0.6870469784517901
Epoch: 40 | Iteration number: [3280/4518] 72% | Training loss: 0.6870460032508141
Epoch: 40 | Iteration number: [3290/4518] 72% | Training loss: 0.687047335097855
Epoch: 40 | Iteration number: [3300/4518] 73% | Training loss: 0.6870507977225564
Epoch: 40 | Iteration number: [3310/4518] 73% | Training loss: 0.6870479737523819
Epoch: 40 | Iteration number: [3320/4518] 73% | Training loss: 0.6870455404721111
Epoch: 40 | Iteration number: [3330/4518] 73% | Training loss: 0.6870476132219618
Epoch: 40 | Iteration number: [3340/4518] 73% | Training loss: 0.687041529798936
Epoch: 40 | Iteration number: [3350/4518] 74% | Training loss: 0.6870414308647611
Epoch: 40 | Iteration number: [3360/4518] 74% | Training loss: 0.687037211230823
Epoch: 40 | Iteration number: [3370/4518] 74% | Training loss: 0.687036454323845
Epoch: 40 | Iteration number: [3380/4518] 74% | Training loss: 0.6870340643726157
Epoch: 40 | Iteration number: [3390/4518] 75% | Training loss: 0.6870310830683132
Epoch: 40 | Iteration number: [3400/4518] 75% | Training loss: 0.6870287873990395
Epoch: 40 | Iteration number: [3410/4518] 75% | Training loss: 0.6870309935112503
Epoch: 40 | Iteration number: [3420/4518] 75% | Training loss: 0.6870316668560631
Epoch: 40 | Iteration number: [3430/4518] 75% | Training loss: 0.6870232941805448
Epoch: 40 | Iteration number: [3440/4518] 76% | Training loss: 0.6870227146807105
Epoch: 40 | Iteration number: [3450/4518] 76% | Training loss: 0.687020499187967
Epoch: 40 | Iteration number: [3460/4518] 76% | Training loss: 0.6870202107408833
Epoch: 40 | Iteration number: [3470/4518] 76% | Training loss: 0.6870172763076914
Epoch: 40 | Iteration number: [3480/4518] 77% | Training loss: 0.6870177633974744
Epoch: 40 | Iteration number: [3490/4518] 77% | Training loss: 0.6870187965368473
Epoch: 40 | Iteration number: [3500/4518] 77% | Training loss: 0.6870211689642497
Epoch: 40 | Iteration number: [3510/4518] 77% | Training loss: 0.6870221807746126
Epoch: 40 | Iteration number: [3520/4518] 77% | Training loss: 0.6870219022374261
Epoch: 40 | Iteration number: [3530/4518] 78% | Training loss: 0.6870182256860706
Epoch: 40 | Iteration number: [3540/4518] 78% | Training loss: 0.6870147956798306
Epoch: 40 | Iteration number: [3550/4518] 78% | Training loss: 0.6870143272003657
Epoch: 40 | Iteration number: [3560/4518] 78% | Training loss: 0.6870133102442442
Epoch: 40 | Iteration number: [3570/4518] 79% | Training loss: 0.6870141062082029
Epoch: 40 | Iteration number: [3580/4518] 79% | Training loss: 0.6870166570281183
Epoch: 40 | Iteration number: [3590/4518] 79% | Training loss: 0.6870137403270328
Epoch: 40 | Iteration number: [3600/4518] 79% | Training loss: 0.6870107870631748
Epoch: 40 | Iteration number: [3610/4518] 79% | Training loss: 0.6870111941465711
Epoch: 40 | Iteration number: [3620/4518] 80% | Training loss: 0.6870076666056122
Epoch: 40 | Iteration number: [3630/4518] 80% | Training loss: 0.6870031310342889
Epoch: 40 | Iteration number: [3640/4518] 80% | Training loss: 0.6870053036527319
Epoch: 40 | Iteration number: [3650/4518] 80% | Training loss: 0.687004392473665
Epoch: 40 | Iteration number: [3660/4518] 81% | Training loss: 0.6870048908099451
Epoch: 40 | Iteration number: [3670/4518] 81% | Training loss: 0.6870032284337754
Epoch: 40 | Iteration number: [3680/4518] 81% | Training loss: 0.6869992302163788
Epoch: 40 | Iteration number: [3690/4518] 81% | Training loss: 0.6869996442865873
Epoch: 40 | Iteration number: [3700/4518] 81% | Training loss: 0.6869987147563212
Epoch: 40 | Iteration number: [3710/4518] 82% | Training loss: 0.6869995885139527
Epoch: 40 | Iteration number: [3720/4518] 82% | Training loss: 0.6869987358329117
Epoch: 40 | Iteration number: [3730/4518] 82% | Training loss: 0.6870009974084654
Epoch: 40 | Iteration number: [3740/4518] 82% | Training loss: 0.6870005945470882
Epoch: 40 | Iteration number: [3750/4518] 83% | Training loss: 0.6870001714706421
Epoch: 40 | Iteration number: [3760/4518] 83% | Training loss: 0.6869966695283322
Epoch: 40 | Iteration number: [3770/4518] 83% | Training loss: 0.686996178174841
Epoch: 40 | Iteration number: [3780/4518] 83% | Training loss: 0.6869989162715023
Epoch: 40 | Iteration number: [3790/4518] 83% | Training loss: 0.6869991575665084
Epoch: 40 | Iteration number: [3800/4518] 84% | Training loss: 0.6869967387538207
Epoch: 40 | Iteration number: [3810/4518] 84% | Training loss: 0.6869945442895564
Epoch: 40 | Iteration number: [3820/4518] 84% | Training loss: 0.686993409763456
Epoch: 40 | Iteration number: [3830/4518] 84% | Training loss: 0.686991158244504
Epoch: 40 | Iteration number: [3840/4518] 84% | Training loss: 0.6869922482719024
Epoch: 40 | Iteration number: [3850/4518] 85% | Training loss: 0.686992016860417
Epoch: 40 | Iteration number: [3860/4518] 85% | Training loss: 0.6869925776602691
Epoch: 40 | Iteration number: [3870/4518] 85% | Training loss: 0.6869931103647218
Epoch: 40 | Iteration number: [3880/4518] 85% | Training loss: 0.6869923946322855
Epoch: 40 | Iteration number: [3890/4518] 86% | Training loss: 0.6869923135768479
Epoch: 40 | Iteration number: [3900/4518] 86% | Training loss: 0.6869914782200104
Epoch: 40 | Iteration number: [3910/4518] 86% | Training loss: 0.6869950612030371
Epoch: 40 | Iteration number: [3920/4518] 86% | Training loss: 0.686995278937476
Epoch: 40 | Iteration number: [3930/4518] 86% | Training loss: 0.6869955810730087
Epoch: 40 | Iteration number: [3940/4518] 87% | Training loss: 0.6869980129947517
Epoch: 40 | Iteration number: [3950/4518] 87% | Training loss: 0.686997864276548
Epoch: 40 | Iteration number: [3960/4518] 87% | Training loss: 0.6869983074640987
Epoch: 40 | Iteration number: [3970/4518] 87% | Training loss: 0.686997682967174
Epoch: 40 | Iteration number: [3980/4518] 88% | Training loss: 0.6869996844224594
Epoch: 40 | Iteration number: [3990/4518] 88% | Training loss: 0.6870016309103572
Epoch: 40 | Iteration number: [4000/4518] 88% | Training loss: 0.6870010494887829
Epoch: 40 | Iteration number: [4010/4518] 88% | Training loss: 0.6870025897263886
Epoch: 40 | Iteration number: [4020/4518] 88% | Training loss: 0.6870042932270771
Epoch: 40 | Iteration number: [4030/4518] 89% | Training loss: 0.6870043533759437
Epoch: 40 | Iteration number: [4040/4518] 89% | Training loss: 0.6870041080778188
Epoch: 40 | Iteration number: [4050/4518] 89% | Training loss: 0.6870010784820274
Epoch: 40 | Iteration number: [4060/4518] 89% | Training loss: 0.6870003417941737
Epoch: 40 | Iteration number: [4070/4518] 90% | Training loss: 0.6869992421944545
Epoch: 40 | Iteration number: [4080/4518] 90% | Training loss: 0.6870009050941934
Epoch: 40 | Iteration number: [4090/4518] 90% | Training loss: 0.6870021272550877
Epoch: 40 | Iteration number: [4100/4518] 90% | Training loss: 0.6869948833453946
Epoch: 40 | Iteration number: [4110/4518] 90% | Training loss: 0.6869931678412314
Epoch: 40 | Iteration number: [4120/4518] 91% | Training loss: 0.6869925500264445
Epoch: 40 | Iteration number: [4130/4518] 91% | Training loss: 0.6869919648903623
Epoch: 40 | Iteration number: [4140/4518] 91% | Training loss: 0.686992751573019
Epoch: 40 | Iteration number: [4150/4518] 91% | Training loss: 0.6869922147888735
Epoch: 40 | Iteration number: [4160/4518] 92% | Training loss: 0.6869923707957452
Epoch: 40 | Iteration number: [4170/4518] 92% | Training loss: 0.686988670805947
Epoch: 40 | Iteration number: [4180/4518] 92% | Training loss: 0.6869891649798343
Epoch: 40 | Iteration number: [4190/4518] 92% | Training loss: 0.6869898677583526
Epoch: 40 | Iteration number: [4200/4518] 92% | Training loss: 0.6869878006265276
Epoch: 40 | Iteration number: [4210/4518] 93% | Training loss: 0.6869856163328447
Epoch: 40 | Iteration number: [4220/4518] 93% | Training loss: 0.6869858554471725
Epoch: 40 | Iteration number: [4230/4518] 93% | Training loss: 0.6869880741510549
Epoch: 40 | Iteration number: [4240/4518] 93% | Training loss: 0.6869873374419392
Epoch: 40 | Iteration number: [4250/4518] 94% | Training loss: 0.6869848695081823
Epoch: 40 | Iteration number: [4260/4518] 94% | Training loss: 0.6869843974919386
Epoch: 40 | Iteration number: [4270/4518] 94% | Training loss: 0.6869816238483724
Epoch: 40 | Iteration number: [4280/4518] 94% | Training loss: 0.6869826448994262
Epoch: 40 | Iteration number: [4290/4518] 94% | Training loss: 0.6869859906482252
Epoch: 40 | Iteration number: [4300/4518] 95% | Training loss: 0.686987568930138
Epoch: 40 | Iteration number: [4310/4518] 95% | Training loss: 0.6869869830436883
Epoch: 40 | Iteration number: [4320/4518] 95% | Training loss: 0.6869847707174442
Epoch: 40 | Iteration number: [4330/4518] 95% | Training loss: 0.6869859069379317
Epoch: 40 | Iteration number: [4340/4518] 96% | Training loss: 0.6869880305045212
Epoch: 40 | Iteration number: [4350/4518] 96% | Training loss: 0.6869878524062277
Epoch: 40 | Iteration number: [4360/4518] 96% | Training loss: 0.686984802427095
Epoch: 40 | Iteration number: [4370/4518] 96% | Training loss: 0.6869825688461417
Epoch: 40 | Iteration number: [4380/4518] 96% | Training loss: 0.6869819502852279
Epoch: 40 | Iteration number: [4390/4518] 97% | Training loss: 0.6869800011090645
Epoch: 40 | Iteration number: [4400/4518] 97% | Training loss: 0.6869813353906978
Epoch: 40 | Iteration number: [4410/4518] 97% | Training loss: 0.6869793151241311
Epoch: 40 | Iteration number: [4420/4518] 97% | Training loss: 0.6869799380523587
Epoch: 40 | Iteration number: [4430/4518] 98% | Training loss: 0.6869815638452835
Epoch: 40 | Iteration number: [4440/4518] 98% | Training loss: 0.6869816412796845
Epoch: 40 | Iteration number: [4450/4518] 98% | Training loss: 0.6869810749707597
Epoch: 40 | Iteration number: [4460/4518] 98% | Training loss: 0.6869818752923889
Epoch: 40 | Iteration number: [4470/4518] 98% | Training loss: 0.6869833464990526
Epoch: 40 | Iteration number: [4480/4518] 99% | Training loss: 0.6869807668030262
Epoch: 40 | Iteration number: [4490/4518] 99% | Training loss: 0.6869810422571305
Epoch: 40 | Iteration number: [4500/4518] 99% | Training loss: 0.6869805054002338
Epoch: 40 | Iteration number: [4510/4518] 99% | Training loss: 0.6869816875246306

 End of epoch: 40 | Train Loss: 0.6868295174961124 | Training Time: 641 

 End of epoch: 40 | Eval Loss: 0.6900095185455011 | Evaluating Time: 17 
Epoch: 41 | Iteration number: [10/4518] 0% | Training loss: 0.7552674651145935
Epoch: 41 | Iteration number: [20/4518] 0% | Training loss: 0.7205998778343201
Epoch: 41 | Iteration number: [30/4518] 0% | Training loss: 0.7092726012070973
Epoch: 41 | Iteration number: [40/4518] 0% | Training loss: 0.7036391288042069
Epoch: 41 | Iteration number: [50/4518] 1% | Training loss: 0.7002211284637451
Epoch: 41 | Iteration number: [60/4518] 1% | Training loss: 0.6980169872442882
Epoch: 41 | Iteration number: [70/4518] 1% | Training loss: 0.696468540600368
Epoch: 41 | Iteration number: [80/4518] 1% | Training loss: 0.6952380754053593
Epoch: 41 | Iteration number: [90/4518] 1% | Training loss: 0.6943756759166717
Epoch: 41 | Iteration number: [100/4518] 2% | Training loss: 0.6936835837364197
Epoch: 41 | Iteration number: [110/4518] 2% | Training loss: 0.6930931996215474
Epoch: 41 | Iteration number: [120/4518] 2% | Training loss: 0.6926417236526807
Epoch: 41 | Iteration number: [130/4518] 2% | Training loss: 0.6921865289027874
Epoch: 41 | Iteration number: [140/4518] 3% | Training loss: 0.6917920231819152
Epoch: 41 | Iteration number: [150/4518] 3% | Training loss: 0.6914149804910024
Epoch: 41 | Iteration number: [160/4518] 3% | Training loss: 0.6910840712487698
Epoch: 41 | Iteration number: [170/4518] 3% | Training loss: 0.6909043939674602
Epoch: 41 | Iteration number: [180/4518] 3% | Training loss: 0.6906711250543595
Epoch: 41 | Iteration number: [190/4518] 4% | Training loss: 0.6904800650320555
Epoch: 41 | Iteration number: [200/4518] 4% | Training loss: 0.690275274515152
Epoch: 41 | Iteration number: [210/4518] 4% | Training loss: 0.6901468711239951
Epoch: 41 | Iteration number: [220/4518] 4% | Training loss: 0.6900131287899884
Epoch: 41 | Iteration number: [230/4518] 5% | Training loss: 0.6898246060247006
Epoch: 41 | Iteration number: [240/4518] 5% | Training loss: 0.6896737391750017
Epoch: 41 | Iteration number: [250/4518] 5% | Training loss: 0.6895365109443664
Epoch: 41 | Iteration number: [260/4518] 5% | Training loss: 0.6894370514612932
Epoch: 41 | Iteration number: [270/4518] 5% | Training loss: 0.6893541355927785
Epoch: 41 | Iteration number: [280/4518] 6% | Training loss: 0.6892553293279239
Epoch: 41 | Iteration number: [290/4518] 6% | Training loss: 0.6891768459616037
Epoch: 41 | Iteration number: [300/4518] 6% | Training loss: 0.6890939895311992
Epoch: 41 | Iteration number: [310/4518] 6% | Training loss: 0.6890159076259982
Epoch: 41 | Iteration number: [320/4518] 7% | Training loss: 0.6889326160773634
Epoch: 41 | Iteration number: [330/4518] 7% | Training loss: 0.6889180277333115
Epoch: 41 | Iteration number: [340/4518] 7% | Training loss: 0.688834823755657
Epoch: 41 | Iteration number: [350/4518] 7% | Training loss: 0.6887883033071246
Epoch: 41 | Iteration number: [360/4518] 7% | Training loss: 0.6887607337699996
Epoch: 41 | Iteration number: [370/4518] 8% | Training loss: 0.6886855901898564
Epoch: 41 | Iteration number: [380/4518] 8% | Training loss: 0.6886629873200467
Epoch: 41 | Iteration number: [390/4518] 8% | Training loss: 0.6886105196598249
Epoch: 41 | Iteration number: [400/4518] 8% | Training loss: 0.6885557314753532
Epoch: 41 | Iteration number: [410/4518] 9% | Training loss: 0.6884632462408484
Epoch: 41 | Iteration number: [420/4518] 9% | Training loss: 0.6884326074804579
Epoch: 41 | Iteration number: [430/4518] 9% | Training loss: 0.6883639342563097
Epoch: 41 | Iteration number: [440/4518] 9% | Training loss: 0.6883250820365819
Epoch: 41 | Iteration number: [450/4518] 9% | Training loss: 0.6882906957467397
Epoch: 41 | Iteration number: [460/4518] 10% | Training loss: 0.6882381511771161
Epoch: 41 | Iteration number: [470/4518] 10% | Training loss: 0.6882094062389211
Epoch: 41 | Iteration number: [480/4518] 10% | Training loss: 0.6881442190458377
Epoch: 41 | Iteration number: [490/4518] 10% | Training loss: 0.6880936112939094
Epoch: 41 | Iteration number: [500/4518] 11% | Training loss: 0.6880701874494553
Epoch: 41 | Iteration number: [510/4518] 11% | Training loss: 0.6880182553740108
Epoch: 41 | Iteration number: [520/4518] 11% | Training loss: 0.6880056557747034
Epoch: 41 | Iteration number: [530/4518] 11% | Training loss: 0.6880015658882429
Epoch: 41 | Iteration number: [540/4518] 11% | Training loss: 0.6879806347467281
Epoch: 41 | Iteration number: [550/4518] 12% | Training loss: 0.6879679538986899
Epoch: 41 | Iteration number: [560/4518] 12% | Training loss: 0.6879287074719157
Epoch: 41 | Iteration number: [570/4518] 12% | Training loss: 0.6879036418178626
Epoch: 41 | Iteration number: [580/4518] 12% | Training loss: 0.6878763523595086
Epoch: 41 | Iteration number: [590/4518] 13% | Training loss: 0.6878599400237455
Epoch: 41 | Iteration number: [600/4518] 13% | Training loss: 0.6878404782215755
Epoch: 41 | Iteration number: [610/4518] 13% | Training loss: 0.6878312991290796
Epoch: 41 | Iteration number: [620/4518] 13% | Training loss: 0.6878276766307893
Epoch: 41 | Iteration number: [630/4518] 13% | Training loss: 0.6878255203602806
Epoch: 41 | Iteration number: [640/4518] 14% | Training loss: 0.6878057910129428
Epoch: 41 | Iteration number: [650/4518] 14% | Training loss: 0.6877859604358673
Epoch: 41 | Iteration number: [660/4518] 14% | Training loss: 0.6877809997760889
Epoch: 41 | Iteration number: [670/4518] 14% | Training loss: 0.6877423368283172
Epoch: 41 | Iteration number: [680/4518] 15% | Training loss: 0.6877370000762097
Epoch: 41 | Iteration number: [690/4518] 15% | Training loss: 0.6877294831517814
Epoch: 41 | Iteration number: [700/4518] 15% | Training loss: 0.6877258633715766
Epoch: 41 | Iteration number: [710/4518] 15% | Training loss: 0.6877102926583357
Epoch: 41 | Iteration number: [720/4518] 15% | Training loss: 0.6877004842791292
Epoch: 41 | Iteration number: [730/4518] 16% | Training loss: 0.6876744796968486
Epoch: 41 | Iteration number: [740/4518] 16% | Training loss: 0.6876544824323139
Epoch: 41 | Iteration number: [750/4518] 16% | Training loss: 0.6876414965788523
Epoch: 41 | Iteration number: [760/4518] 16% | Training loss: 0.687628563611131
Epoch: 41 | Iteration number: [770/4518] 17% | Training loss: 0.6876284469257702
Epoch: 41 | Iteration number: [780/4518] 17% | Training loss: 0.6876176110444925
Epoch: 41 | Iteration number: [790/4518] 17% | Training loss: 0.6876014052312586
Epoch: 41 | Iteration number: [800/4518] 17% | Training loss: 0.6875989601016045
Epoch: 41 | Iteration number: [810/4518] 17% | Training loss: 0.6875857102282253
Epoch: 41 | Iteration number: [820/4518] 18% | Training loss: 0.6875979362464533
Epoch: 41 | Iteration number: [830/4518] 18% | Training loss: 0.6875848081456609
Epoch: 41 | Iteration number: [840/4518] 18% | Training loss: 0.6875613173558599
Epoch: 41 | Iteration number: [850/4518] 18% | Training loss: 0.6875537985212663
Epoch: 41 | Iteration number: [860/4518] 19% | Training loss: 0.6875250374854998
Epoch: 41 | Iteration number: [870/4518] 19% | Training loss: 0.6875089207599903
Epoch: 41 | Iteration number: [880/4518] 19% | Training loss: 0.6875043076547709
Epoch: 41 | Iteration number: [890/4518] 19% | Training loss: 0.6874985494640437
Epoch: 41 | Iteration number: [900/4518] 19% | Training loss: 0.6874770331382751
Epoch: 41 | Iteration number: [910/4518] 20% | Training loss: 0.6874640629186735
Epoch: 41 | Iteration number: [920/4518] 20% | Training loss: 0.68745527656182
Epoch: 41 | Iteration number: [930/4518] 20% | Training loss: 0.6874526946134465
Epoch: 41 | Iteration number: [940/4518] 20% | Training loss: 0.6874503895323327
Epoch: 41 | Iteration number: [950/4518] 21% | Training loss: 0.6874408145327318
Epoch: 41 | Iteration number: [960/4518] 21% | Training loss: 0.6874251502876481
Epoch: 41 | Iteration number: [970/4518] 21% | Training loss: 0.6874258273041125
Epoch: 41 | Iteration number: [980/4518] 21% | Training loss: 0.6874220371246338
Epoch: 41 | Iteration number: [990/4518] 21% | Training loss: 0.6874105957421389
Epoch: 41 | Iteration number: [1000/4518] 22% | Training loss: 0.68741768181324
Epoch: 41 | Iteration number: [1010/4518] 22% | Training loss: 0.6874117416320461
Epoch: 41 | Iteration number: [1020/4518] 22% | Training loss: 0.6874106453914268
Epoch: 41 | Iteration number: [1030/4518] 22% | Training loss: 0.687408219205523
Epoch: 41 | Iteration number: [1040/4518] 23% | Training loss: 0.6873932343262893
Epoch: 41 | Iteration number: [1050/4518] 23% | Training loss: 0.6873861640407926
Epoch: 41 | Iteration number: [1060/4518] 23% | Training loss: 0.6873875285656947
Epoch: 41 | Iteration number: [1070/4518] 23% | Training loss: 0.6873805465542268
Epoch: 41 | Iteration number: [1080/4518] 23% | Training loss: 0.687374202851896
Epoch: 41 | Iteration number: [1090/4518] 24% | Training loss: 0.6873683076932889
Epoch: 41 | Iteration number: [1100/4518] 24% | Training loss: 0.6873514434424314
Epoch: 41 | Iteration number: [1110/4518] 24% | Training loss: 0.6873462646394163
Epoch: 41 | Iteration number: [1120/4518] 24% | Training loss: 0.6873454796416419
Epoch: 41 | Iteration number: [1130/4518] 25% | Training loss: 0.6873571286686754
Epoch: 41 | Iteration number: [1140/4518] 25% | Training loss: 0.6873528835020567
Epoch: 41 | Iteration number: [1150/4518] 25% | Training loss: 0.6873571006111476
Epoch: 41 | Iteration number: [1160/4518] 25% | Training loss: 0.6873424390780515
Epoch: 41 | Iteration number: [1170/4518] 25% | Training loss: 0.6873431395261715
Epoch: 41 | Iteration number: [1180/4518] 26% | Training loss: 0.6873362422999689
Epoch: 41 | Iteration number: [1190/4518] 26% | Training loss: 0.6873317314296209
Epoch: 41 | Iteration number: [1200/4518] 26% | Training loss: 0.6873158892989158
Epoch: 41 | Iteration number: [1210/4518] 26% | Training loss: 0.6873112018935936
Epoch: 41 | Iteration number: [1220/4518] 27% | Training loss: 0.6873090199759749
Epoch: 41 | Iteration number: [1230/4518] 27% | Training loss: 0.6873094240339791
Epoch: 41 | Iteration number: [1240/4518] 27% | Training loss: 0.6873118373655503
Epoch: 41 | Iteration number: [1250/4518] 27% | Training loss: 0.6873041292667389
Epoch: 41 | Iteration number: [1260/4518] 27% | Training loss: 0.6872929332748292
Epoch: 41 | Iteration number: [1270/4518] 28% | Training loss: 0.6872953763158303
Epoch: 41 | Iteration number: [1280/4518] 28% | Training loss: 0.6872810005676001
Epoch: 41 | Iteration number: [1290/4518] 28% | Training loss: 0.6872740103292835
Epoch: 41 | Iteration number: [1300/4518] 28% | Training loss: 0.6872626347725208
Epoch: 41 | Iteration number: [1310/4518] 28% | Training loss: 0.6872576356389141
Epoch: 41 | Iteration number: [1320/4518] 29% | Training loss: 0.6872516358892123
Epoch: 41 | Iteration number: [1330/4518] 29% | Training loss: 0.6872501927210872
Epoch: 41 | Iteration number: [1340/4518] 29% | Training loss: 0.6872504414017521
Epoch: 41 | Iteration number: [1350/4518] 29% | Training loss: 0.687251713320061
Epoch: 41 | Iteration number: [1360/4518] 30% | Training loss: 0.6872548653798944
Epoch: 41 | Iteration number: [1370/4518] 30% | Training loss: 0.6872582083200887
Epoch: 41 | Iteration number: [1380/4518] 30% | Training loss: 0.6872480182975963
Epoch: 41 | Iteration number: [1390/4518] 30% | Training loss: 0.6872541621863413
Epoch: 41 | Iteration number: [1400/4518] 30% | Training loss: 0.687238396533898
Epoch: 41 | Iteration number: [1410/4518] 31% | Training loss: 0.68723863967767
Epoch: 41 | Iteration number: [1420/4518] 31% | Training loss: 0.6872313904930168
Epoch: 41 | Iteration number: [1430/4518] 31% | Training loss: 0.6872396612500811
Epoch: 41 | Iteration number: [1440/4518] 31% | Training loss: 0.6872338209301233
Epoch: 41 | Iteration number: [1450/4518] 32% | Training loss: 0.6872314942294153
Epoch: 41 | Iteration number: [1460/4518] 32% | Training loss: 0.6872345145842801
Epoch: 41 | Iteration number: [1470/4518] 32% | Training loss: 0.6872254439357187
Epoch: 41 | Iteration number: [1480/4518] 32% | Training loss: 0.6872305263538618
Epoch: 41 | Iteration number: [1490/4518] 32% | Training loss: 0.6872242564722996
Epoch: 41 | Iteration number: [1500/4518] 33% | Training loss: 0.6872182494401932
Epoch: 41 | Iteration number: [1510/4518] 33% | Training loss: 0.6872177318231949
Epoch: 41 | Iteration number: [1520/4518] 33% | Training loss: 0.6872061648259037
Epoch: 41 | Iteration number: [1530/4518] 33% | Training loss: 0.6872041301400054
Epoch: 41 | Iteration number: [1540/4518] 34% | Training loss: 0.6871997116061
Epoch: 41 | Iteration number: [1550/4518] 34% | Training loss: 0.6871981651936808
Epoch: 41 | Iteration number: [1560/4518] 34% | Training loss: 0.68719624655369
Epoch: 41 | Iteration number: [1570/4518] 34% | Training loss: 0.687194750377327
Epoch: 41 | Iteration number: [1580/4518] 34% | Training loss: 0.6871967865319192
Epoch: 41 | Iteration number: [1590/4518] 35% | Training loss: 0.6871924649619456
Epoch: 41 | Iteration number: [1600/4518] 35% | Training loss: 0.687191767692566
Epoch: 41 | Iteration number: [1610/4518] 35% | Training loss: 0.687191234908489
Epoch: 41 | Iteration number: [1620/4518] 35% | Training loss: 0.687182155398675
Epoch: 41 | Iteration number: [1630/4518] 36% | Training loss: 0.6871815690599337
Epoch: 41 | Iteration number: [1640/4518] 36% | Training loss: 0.6871816649306112
Epoch: 41 | Iteration number: [1650/4518] 36% | Training loss: 0.6871761388128454
Epoch: 41 | Iteration number: [1660/4518] 36% | Training loss: 0.6871688054986747
Epoch: 41 | Iteration number: [1670/4518] 36% | Training loss: 0.687170787164551
Epoch: 41 | Iteration number: [1680/4518] 37% | Training loss: 0.6871665185760885
Epoch: 41 | Iteration number: [1690/4518] 37% | Training loss: 0.6871678610877878
Epoch: 41 | Iteration number: [1700/4518] 37% | Training loss: 0.6871677387812558
Epoch: 41 | Iteration number: [1710/4518] 37% | Training loss: 0.6871616980137184
Epoch: 41 | Iteration number: [1720/4518] 38% | Training loss: 0.6871544137597084
Epoch: 41 | Iteration number: [1730/4518] 38% | Training loss: 0.6871457138847065
Epoch: 41 | Iteration number: [1740/4518] 38% | Training loss: 0.6871433246752311
Epoch: 41 | Iteration number: [1750/4518] 38% | Training loss: 0.6871425813606807
Epoch: 41 | Iteration number: [1760/4518] 38% | Training loss: 0.6871434334665537
Epoch: 41 | Iteration number: [1770/4518] 39% | Training loss: 0.6871389738583968
Epoch: 41 | Iteration number: [1780/4518] 39% | Training loss: 0.6871431089519116
Epoch: 41 | Iteration number: [1790/4518] 39% | Training loss: 0.6871462299504094
Epoch: 41 | Iteration number: [1800/4518] 39% | Training loss: 0.687155732843611
Epoch: 41 | Iteration number: [1810/4518] 40% | Training loss: 0.6871588762293863
Epoch: 41 | Iteration number: [1820/4518] 40% | Training loss: 0.6871557385384381
Epoch: 41 | Iteration number: [1830/4518] 40% | Training loss: 0.6871536756473813
Epoch: 41 | Iteration number: [1840/4518] 40% | Training loss: 0.6871506112425224
Epoch: 41 | Iteration number: [1850/4518] 40% | Training loss: 0.6871496247600865
Epoch: 41 | Iteration number: [1860/4518] 41% | Training loss: 0.6871525319353227
Epoch: 41 | Iteration number: [1870/4518] 41% | Training loss: 0.6871564912923517
Epoch: 41 | Iteration number: [1880/4518] 41% | Training loss: 0.6871597198412773
Epoch: 41 | Iteration number: [1890/4518] 41% | Training loss: 0.687159500235603
Epoch: 41 | Iteration number: [1900/4518] 42% | Training loss: 0.6871561841588272
Epoch: 41 | Iteration number: [1910/4518] 42% | Training loss: 0.6871502298647196
Epoch: 41 | Iteration number: [1920/4518] 42% | Training loss: 0.6871459041722119
Epoch: 41 | Iteration number: [1930/4518] 42% | Training loss: 0.6871466967417168
Epoch: 41 | Iteration number: [1940/4518] 42% | Training loss: 0.6871540115358903
Epoch: 41 | Iteration number: [1950/4518] 43% | Training loss: 0.6871469297775855
Epoch: 41 | Iteration number: [1960/4518] 43% | Training loss: 0.6871472612023354
Epoch: 41 | Iteration number: [1970/4518] 43% | Training loss: 0.6871395691699788
Epoch: 41 | Iteration number: [1980/4518] 43% | Training loss: 0.6871364328295293
Epoch: 41 | Iteration number: [1990/4518] 44% | Training loss: 0.6871280602773829
Epoch: 41 | Iteration number: [2000/4518] 44% | Training loss: 0.6871297171711922
Epoch: 41 | Iteration number: [2010/4518] 44% | Training loss: 0.6871302974461323
Epoch: 41 | Iteration number: [2020/4518] 44% | Training loss: 0.687122894631754
Epoch: 41 | Iteration number: [2030/4518] 44% | Training loss: 0.6871190162715066
Epoch: 41 | Iteration number: [2040/4518] 45% | Training loss: 0.6871167641352205
Epoch: 41 | Iteration number: [2050/4518] 45% | Training loss: 0.6871194883672203
Epoch: 41 | Iteration number: [2060/4518] 45% | Training loss: 0.6871209671485772
Epoch: 41 | Iteration number: [2070/4518] 45% | Training loss: 0.6871128737638538
Epoch: 41 | Iteration number: [2080/4518] 46% | Training loss: 0.6871121193067385
Epoch: 41 | Iteration number: [2090/4518] 46% | Training loss: 0.6871065039954117
Epoch: 41 | Iteration number: [2100/4518] 46% | Training loss: 0.6871060337906792
Epoch: 41 | Iteration number: [2110/4518] 46% | Training loss: 0.6871100270352657
Epoch: 41 | Iteration number: [2120/4518] 46% | Training loss: 0.687112575881886
Epoch: 41 | Iteration number: [2130/4518] 47% | Training loss: 0.6871065627801026
Epoch: 41 | Iteration number: [2140/4518] 47% | Training loss: 0.6871099591812241
Epoch: 41 | Iteration number: [2150/4518] 47% | Training loss: 0.6871083216611729
Epoch: 41 | Iteration number: [2160/4518] 47% | Training loss: 0.6871130314690096
Epoch: 41 | Iteration number: [2170/4518] 48% | Training loss: 0.6871045609498354
Epoch: 41 | Iteration number: [2180/4518] 48% | Training loss: 0.6871029149228279
Epoch: 41 | Iteration number: [2190/4518] 48% | Training loss: 0.6871038708240474
Epoch: 41 | Iteration number: [2200/4518] 48% | Training loss: 0.6871090402928266
Epoch: 41 | Iteration number: [2210/4518] 48% | Training loss: 0.6871138124444366
Epoch: 41 | Iteration number: [2220/4518] 49% | Training loss: 0.687116690664678
Epoch: 41 | Iteration number: [2230/4518] 49% | Training loss: 0.6871214563803822
Epoch: 41 | Iteration number: [2240/4518] 49% | Training loss: 0.6871270355369363
Epoch: 41 | Iteration number: [2250/4518] 49% | Training loss: 0.6871239535808563
Epoch: 41 | Iteration number: [2260/4518] 50% | Training loss: 0.6871207092715576
Epoch: 41 | Iteration number: [2270/4518] 50% | Training loss: 0.6871215984947355
Epoch: 41 | Iteration number: [2280/4518] 50% | Training loss: 0.6871234310562151
Epoch: 41 | Iteration number: [2290/4518] 50% | Training loss: 0.6871193619534438
Epoch: 41 | Iteration number: [2300/4518] 50% | Training loss: 0.6871186350739521
Epoch: 41 | Iteration number: [2310/4518] 51% | Training loss: 0.6871172346077956
Epoch: 41 | Iteration number: [2320/4518] 51% | Training loss: 0.6871236893894344
Epoch: 41 | Iteration number: [2330/4518] 51% | Training loss: 0.6871230743729505
Epoch: 41 | Iteration number: [2340/4518] 51% | Training loss: 0.6871189621014473
Epoch: 41 | Iteration number: [2350/4518] 52% | Training loss: 0.6871227583986648
Epoch: 41 | Iteration number: [2360/4518] 52% | Training loss: 0.6871261975017645
Epoch: 41 | Iteration number: [2370/4518] 52% | Training loss: 0.6871212394680152
Epoch: 41 | Iteration number: [2380/4518] 52% | Training loss: 0.687121929891971
Epoch: 41 | Iteration number: [2390/4518] 52% | Training loss: 0.687121927788068
Epoch: 41 | Iteration number: [2400/4518] 53% | Training loss: 0.6871160273750623
Epoch: 41 | Iteration number: [2410/4518] 53% | Training loss: 0.6871132354271362
Epoch: 41 | Iteration number: [2420/4518] 53% | Training loss: 0.6871123958963993
Epoch: 41 | Iteration number: [2430/4518] 53% | Training loss: 0.687110708991196
Epoch: 41 | Iteration number: [2440/4518] 54% | Training loss: 0.6871106235463111
Epoch: 41 | Iteration number: [2450/4518] 54% | Training loss: 0.6871110945088523
Epoch: 41 | Iteration number: [2460/4518] 54% | Training loss: 0.6871103623775932
Epoch: 41 | Iteration number: [2470/4518] 54% | Training loss: 0.6871093791264754
Epoch: 41 | Iteration number: [2480/4518] 54% | Training loss: 0.6871063458583048
Epoch: 41 | Iteration number: [2490/4518] 55% | Training loss: 0.6871045675622411
Epoch: 41 | Iteration number: [2500/4518] 55% | Training loss: 0.6871026652812958
Epoch: 41 | Iteration number: [2510/4518] 55% | Training loss: 0.687100882335488
Epoch: 41 | Iteration number: [2520/4518] 55% | Training loss: 0.6870967086108904
Epoch: 41 | Iteration number: [2530/4518] 55% | Training loss: 0.6870972964132256
Epoch: 41 | Iteration number: [2540/4518] 56% | Training loss: 0.6871027549655419
Epoch: 41 | Iteration number: [2550/4518] 56% | Training loss: 0.6871012916751936
Epoch: 41 | Iteration number: [2560/4518] 56% | Training loss: 0.6870984116569161
Epoch: 41 | Iteration number: [2570/4518] 56% | Training loss: 0.6870959899072981
Epoch: 41 | Iteration number: [2580/4518] 57% | Training loss: 0.6870952468740847
Epoch: 41 | Iteration number: [2590/4518] 57% | Training loss: 0.6870997702753222
Epoch: 41 | Iteration number: [2600/4518] 57% | Training loss: 0.6871007676766469
Epoch: 41 | Iteration number: [2610/4518] 57% | Training loss: 0.6870975519277127
Epoch: 41 | Iteration number: [2620/4518] 57% | Training loss: 0.6870956994877517
Epoch: 41 | Iteration number: [2630/4518] 58% | Training loss: 0.6870970974856909
Epoch: 41 | Iteration number: [2640/4518] 58% | Training loss: 0.6871026466290157
Epoch: 41 | Iteration number: [2650/4518] 58% | Training loss: 0.6871021499948682
Epoch: 41 | Iteration number: [2660/4518] 58% | Training loss: 0.6871015089571028
Epoch: 41 | Iteration number: [2670/4518] 59% | Training loss: 0.6870965303553178
Epoch: 41 | Iteration number: [2680/4518] 59% | Training loss: 0.6870974257365982
Epoch: 41 | Iteration number: [2690/4518] 59% | Training loss: 0.6870976755831765
Epoch: 41 | Iteration number: [2700/4518] 59% | Training loss: 0.6870980178868329
Epoch: 41 | Iteration number: [2710/4518] 59% | Training loss: 0.6870989952360133
Epoch: 41 | Iteration number: [2720/4518] 60% | Training loss: 0.6870973006329115
Epoch: 41 | Iteration number: [2730/4518] 60% | Training loss: 0.6870937942585229
Epoch: 41 | Iteration number: [2740/4518] 60% | Training loss: 0.6870936845775938
Epoch: 41 | Iteration number: [2750/4518] 60% | Training loss: 0.6870927967158231
Epoch: 41 | Iteration number: [2760/4518] 61% | Training loss: 0.6870897117084351
Epoch: 41 | Iteration number: [2770/4518] 61% | Training loss: 0.6870891734365953
Epoch: 41 | Iteration number: [2780/4518] 61% | Training loss: 0.6870885475505171
Epoch: 41 | Iteration number: [2790/4518] 61% | Training loss: 0.6870835316437547
Epoch: 41 | Iteration number: [2800/4518] 61% | Training loss: 0.6870867777509349
Epoch: 41 | Iteration number: [2810/4518] 62% | Training loss: 0.6870865569844364
Epoch: 41 | Iteration number: [2820/4518] 62% | Training loss: 0.6870860840200532
Epoch: 41 | Iteration number: [2830/4518] 62% | Training loss: 0.6870869691506712
Epoch: 41 | Iteration number: [2840/4518] 62% | Training loss: 0.6870803733526821
Epoch: 41 | Iteration number: [2850/4518] 63% | Training loss: 0.6870833079020182
Epoch: 41 | Iteration number: [2860/4518] 63% | Training loss: 0.6870829310658928
Epoch: 41 | Iteration number: [2870/4518] 63% | Training loss: 0.687077840363107
Epoch: 41 | Iteration number: [2880/4518] 63% | Training loss: 0.6870817496337824
Epoch: 41 | Iteration number: [2890/4518] 63% | Training loss: 0.6870795841035546
Epoch: 41 | Iteration number: [2900/4518] 64% | Training loss: 0.687079974721218
Epoch: 41 | Iteration number: [2910/4518] 64% | Training loss: 0.6870807250955261
Epoch: 41 | Iteration number: [2920/4518] 64% | Training loss: 0.6870776959478039
Epoch: 41 | Iteration number: [2930/4518] 64% | Training loss: 0.6870753439213229
Epoch: 41 | Iteration number: [2940/4518] 65% | Training loss: 0.6870765847008244
Epoch: 41 | Iteration number: [2950/4518] 65% | Training loss: 0.687075609352629
Epoch: 41 | Iteration number: [2960/4518] 65% | Training loss: 0.6870745870914008
Epoch: 41 | Iteration number: [2970/4518] 65% | Training loss: 0.6870740864814733
Epoch: 41 | Iteration number: [2980/4518] 65% | Training loss: 0.6870725332490549
Epoch: 41 | Iteration number: [2990/4518] 66% | Training loss: 0.6870736163396102
Epoch: 41 | Iteration number: [3000/4518] 66% | Training loss: 0.6870709911386172
Epoch: 41 | Iteration number: [3010/4518] 66% | Training loss: 0.6870699265470537
Epoch: 41 | Iteration number: [3020/4518] 66% | Training loss: 0.6870697274508065
Epoch: 41 | Iteration number: [3030/4518] 67% | Training loss: 0.6870706720910843
Epoch: 41 | Iteration number: [3040/4518] 67% | Training loss: 0.6870716345741561
Epoch: 41 | Iteration number: [3050/4518] 67% | Training loss: 0.6870732289650401
Epoch: 41 | Iteration number: [3060/4518] 67% | Training loss: 0.6870717695335937
Epoch: 41 | Iteration number: [3070/4518] 67% | Training loss: 0.6870731446758543
Epoch: 41 | Iteration number: [3080/4518] 68% | Training loss: 0.6870742721217019
Epoch: 41 | Iteration number: [3090/4518] 68% | Training loss: 0.6870759589386604
Epoch: 41 | Iteration number: [3100/4518] 68% | Training loss: 0.6870714799242635
Epoch: 41 | Iteration number: [3110/4518] 68% | Training loss: 0.6870704742106594
Epoch: 41 | Iteration number: [3120/4518] 69% | Training loss: 0.6870718467694062
Epoch: 41 | Iteration number: [3130/4518] 69% | Training loss: 0.6870730239743242
Epoch: 41 | Iteration number: [3140/4518] 69% | Training loss: 0.6870699735773597
Epoch: 41 | Iteration number: [3150/4518] 69% | Training loss: 0.6870676114824084
Epoch: 41 | Iteration number: [3160/4518] 69% | Training loss: 0.6870674517335771
Epoch: 41 | Iteration number: [3170/4518] 70% | Training loss: 0.6870666728974892
Epoch: 41 | Iteration number: [3180/4518] 70% | Training loss: 0.6870702218896938
Epoch: 41 | Iteration number: [3190/4518] 70% | Training loss: 0.6870698789070393
Epoch: 41 | Iteration number: [3200/4518] 70% | Training loss: 0.6870653963275254
Epoch: 41 | Iteration number: [3210/4518] 71% | Training loss: 0.6870625066051602
Epoch: 41 | Iteration number: [3220/4518] 71% | Training loss: 0.687062155274871
Epoch: 41 | Iteration number: [3230/4518] 71% | Training loss: 0.6870590935550607
Epoch: 41 | Iteration number: [3240/4518] 71% | Training loss: 0.6870588049108599
Epoch: 41 | Iteration number: [3250/4518] 71% | Training loss: 0.6870570906308981
Epoch: 41 | Iteration number: [3260/4518] 72% | Training loss: 0.6870562624711932
Epoch: 41 | Iteration number: [3270/4518] 72% | Training loss: 0.6870582842498745
Epoch: 41 | Iteration number: [3280/4518] 72% | Training loss: 0.6870546857576545
Epoch: 41 | Iteration number: [3290/4518] 72% | Training loss: 0.6870565929311387
Epoch: 41 | Iteration number: [3300/4518] 73% | Training loss: 0.6870507264317888
Epoch: 41 | Iteration number: [3310/4518] 73% | Training loss: 0.6870517285568837
Epoch: 41 | Iteration number: [3320/4518] 73% | Training loss: 0.6870528808918344
Epoch: 41 | Iteration number: [3330/4518] 73% | Training loss: 0.6870486113760207
Epoch: 41 | Iteration number: [3340/4518] 73% | Training loss: 0.6870483964503168
Epoch: 41 | Iteration number: [3350/4518] 74% | Training loss: 0.6870458650411065
Epoch: 41 | Iteration number: [3360/4518] 74% | Training loss: 0.6870477825403214
Epoch: 41 | Iteration number: [3370/4518] 74% | Training loss: 0.687051033743765
Epoch: 41 | Iteration number: [3380/4518] 74% | Training loss: 0.687047827314343
Epoch: 41 | Iteration number: [3390/4518] 75% | Training loss: 0.6870499326943648
Epoch: 41 | Iteration number: [3400/4518] 75% | Training loss: 0.6870504830689991
Epoch: 41 | Iteration number: [3410/4518] 75% | Training loss: 0.6870471772210689
Epoch: 41 | Iteration number: [3420/4518] 75% | Training loss: 0.6870465434608404
Epoch: 41 | Iteration number: [3430/4518] 75% | Training loss: 0.6870488330157088
Epoch: 41 | Iteration number: [3440/4518] 76% | Training loss: 0.687048381411059
Epoch: 41 | Iteration number: [3450/4518] 76% | Training loss: 0.687043681818506
Epoch: 41 | Iteration number: [3460/4518] 76% | Training loss: 0.6870418423862127
Epoch: 41 | Iteration number: [3470/4518] 76% | Training loss: 0.687042348907042
Epoch: 41 | Iteration number: [3480/4518] 77% | Training loss: 0.6870382023268733
Epoch: 41 | Iteration number: [3490/4518] 77% | Training loss: 0.6870362464541351
Epoch: 41 | Iteration number: [3500/4518] 77% | Training loss: 0.687035529937063
Epoch: 41 | Iteration number: [3510/4518] 77% | Training loss: 0.687034714204973
Epoch: 41 | Iteration number: [3520/4518] 77% | Training loss: 0.6870360799641771
Epoch: 41 | Iteration number: [3530/4518] 78% | Training loss: 0.6870339807640055
Epoch: 41 | Iteration number: [3540/4518] 78% | Training loss: 0.6870300670969958
Epoch: 41 | Iteration number: [3550/4518] 78% | Training loss: 0.68702907621021
Epoch: 41 | Iteration number: [3560/4518] 78% | Training loss: 0.6870295477884539
Epoch: 41 | Iteration number: [3570/4518] 79% | Training loss: 0.6870318645856628
Epoch: 41 | Iteration number: [3580/4518] 79% | Training loss: 0.687030388939314
Epoch: 41 | Iteration number: [3590/4518] 79% | Training loss: 0.687030348721321
Epoch: 41 | Iteration number: [3600/4518] 79% | Training loss: 0.6870317376818922
Epoch: 41 | Iteration number: [3610/4518] 79% | Training loss: 0.6870287867794407
Epoch: 41 | Iteration number: [3620/4518] 80% | Training loss: 0.6870290938167941
Epoch: 41 | Iteration number: [3630/4518] 80% | Training loss: 0.687028519755881
Epoch: 41 | Iteration number: [3640/4518] 80% | Training loss: 0.6870277826438893
Epoch: 41 | Iteration number: [3650/4518] 80% | Training loss: 0.6870288152074161
Epoch: 41 | Iteration number: [3660/4518] 81% | Training loss: 0.6870288942355276
Epoch: 41 | Iteration number: [3670/4518] 81% | Training loss: 0.6870269829635725
Epoch: 41 | Iteration number: [3680/4518] 81% | Training loss: 0.6870278453697329
Epoch: 41 | Iteration number: [3690/4518] 81% | Training loss: 0.6870298170623418
Epoch: 41 | Iteration number: [3700/4518] 81% | Training loss: 0.6870311005373259
Epoch: 41 | Iteration number: [3710/4518] 82% | Training loss: 0.6870344280232638
Epoch: 41 | Iteration number: [3720/4518] 82% | Training loss: 0.6870333983532844
Epoch: 41 | Iteration number: [3730/4518] 82% | Training loss: 0.6870304363662372
Epoch: 41 | Iteration number: [3740/4518] 82% | Training loss: 0.6870315965802912
Epoch: 41 | Iteration number: [3750/4518] 83% | Training loss: 0.6870323333740235
Epoch: 41 | Iteration number: [3760/4518] 83% | Training loss: 0.6870305171196766
Epoch: 41 | Iteration number: [3770/4518] 83% | Training loss: 0.6870302069724713
Epoch: 41 | Iteration number: [3780/4518] 83% | Training loss: 0.6870300789831807
Epoch: 41 | Iteration number: [3790/4518] 83% | Training loss: 0.6870280571222934
Epoch: 41 | Iteration number: [3800/4518] 84% | Training loss: 0.6870247796962136
Epoch: 41 | Iteration number: [3810/4518] 84% | Training loss: 0.6870255913008542
Epoch: 41 | Iteration number: [3820/4518] 84% | Training loss: 0.6870229316631536
Epoch: 41 | Iteration number: [3830/4518] 84% | Training loss: 0.6870252642868082
Epoch: 41 | Iteration number: [3840/4518] 84% | Training loss: 0.6870216456862788
Epoch: 41 | Iteration number: [3850/4518] 85% | Training loss: 0.6870210714928515
Epoch: 41 | Iteration number: [3860/4518] 85% | Training loss: 0.6870211058947706
Epoch: 41 | Iteration number: [3870/4518] 85% | Training loss: 0.6870220016293439
Epoch: 41 | Iteration number: [3880/4518] 85% | Training loss: 0.6870213773908075
Epoch: 41 | Iteration number: [3890/4518] 86% | Training loss: 0.6870261329458428
Epoch: 41 | Iteration number: [3900/4518] 86% | Training loss: 0.6870263252350001
Epoch: 41 | Iteration number: [3910/4518] 86% | Training loss: 0.687027911609396
Epoch: 41 | Iteration number: [3920/4518] 86% | Training loss: 0.6870254872556851
Epoch: 41 | Iteration number: [3930/4518] 86% | Training loss: 0.6870250890576506
Epoch: 41 | Iteration number: [3940/4518] 87% | Training loss: 0.6870255832896015
Epoch: 41 | Iteration number: [3950/4518] 87% | Training loss: 0.6870254115515118
Epoch: 41 | Iteration number: [3960/4518] 87% | Training loss: 0.6870247822819334
Epoch: 41 | Iteration number: [3970/4518] 87% | Training loss: 0.6870268478351517
Epoch: 41 | Iteration number: [3980/4518] 88% | Training loss: 0.687025496782969
Epoch: 41 | Iteration number: [3990/4518] 88% | Training loss: 0.6870250934496858
Epoch: 41 | Iteration number: [4000/4518] 88% | Training loss: 0.6870224313437938
Epoch: 41 | Iteration number: [4010/4518] 88% | Training loss: 0.6870241776814782
Epoch: 41 | Iteration number: [4020/4518] 88% | Training loss: 0.6870229616242262
Epoch: 41 | Iteration number: [4030/4518] 89% | Training loss: 0.687022354940031
Epoch: 41 | Iteration number: [4040/4518] 89% | Training loss: 0.687022127166833
Epoch: 41 | Iteration number: [4050/4518] 89% | Training loss: 0.6870198305889412
Epoch: 41 | Iteration number: [4060/4518] 89% | Training loss: 0.6870205279347932
Epoch: 41 | Iteration number: [4070/4518] 90% | Training loss: 0.6870198986307702
Epoch: 41 | Iteration number: [4080/4518] 90% | Training loss: 0.6870209848325627
Epoch: 41 | Iteration number: [4090/4518] 90% | Training loss: 0.6870181317288602
Epoch: 41 | Iteration number: [4100/4518] 90% | Training loss: 0.6870148932206921
Epoch: 41 | Iteration number: [4110/4518] 90% | Training loss: 0.6870172251169989
Epoch: 41 | Iteration number: [4120/4518] 91% | Training loss: 0.6870176348871397
Epoch: 41 | Iteration number: [4130/4518] 91% | Training loss: 0.6870195792315947
Epoch: 41 | Iteration number: [4140/4518] 91% | Training loss: 0.6870169969140619
Epoch: 41 | Iteration number: [4150/4518] 91% | Training loss: 0.6870148036997002
Epoch: 41 | Iteration number: [4160/4518] 92% | Training loss: 0.6870140017941594
Epoch: 41 | Iteration number: [4170/4518] 92% | Training loss: 0.6870137680634606
Epoch: 41 | Iteration number: [4180/4518] 92% | Training loss: 0.6870131431441558
Epoch: 41 | Iteration number: [4190/4518] 92% | Training loss: 0.6870105292888131
Epoch: 41 | Iteration number: [4200/4518] 92% | Training loss: 0.6870106024543444
Epoch: 41 | Iteration number: [4210/4518] 93% | Training loss: 0.6870066577776593
Epoch: 41 | Iteration number: [4220/4518] 93% | Training loss: 0.687001876949699
Epoch: 41 | Iteration number: [4230/4518] 93% | Training loss: 0.6870023669503259
Epoch: 41 | Iteration number: [4240/4518] 93% | Training loss: 0.687002768269125
Epoch: 41 | Iteration number: [4250/4518] 94% | Training loss: 0.6870006655384513
Epoch: 41 | Iteration number: [4260/4518] 94% | Training loss: 0.6870011156153791
Epoch: 41 | Iteration number: [4270/4518] 94% | Training loss: 0.6869975524568446
Epoch: 41 | Iteration number: [4280/4518] 94% | Training loss: 0.6869964166222332
Epoch: 41 | Iteration number: [4290/4518] 94% | Training loss: 0.6869956544507078
Epoch: 41 | Iteration number: [4300/4518] 95% | Training loss: 0.6869948978479519
Epoch: 41 | Iteration number: [4310/4518] 95% | Training loss: 0.686993709614548
Epoch: 41 | Iteration number: [4320/4518] 95% | Training loss: 0.6869912527777531
Epoch: 41 | Iteration number: [4330/4518] 95% | Training loss: 0.6869899486008748
Epoch: 41 | Iteration number: [4340/4518] 96% | Training loss: 0.6869893128284111
Epoch: 41 | Iteration number: [4350/4518] 96% | Training loss: 0.686988325776725
Epoch: 41 | Iteration number: [4360/4518] 96% | Training loss: 0.6869865573464183
Epoch: 41 | Iteration number: [4370/4518] 96% | Training loss: 0.6869884892104692
Epoch: 41 | Iteration number: [4380/4518] 96% | Training loss: 0.6869900911774265
Epoch: 41 | Iteration number: [4390/4518] 97% | Training loss: 0.6869910145539087
Epoch: 41 | Iteration number: [4400/4518] 97% | Training loss: 0.6869905162670396
Epoch: 41 | Iteration number: [4410/4518] 97% | Training loss: 0.6869904228754324
Epoch: 41 | Iteration number: [4420/4518] 97% | Training loss: 0.6869895205643382
Epoch: 41 | Iteration number: [4430/4518] 98% | Training loss: 0.686989772010334
Epoch: 41 | Iteration number: [4440/4518] 98% | Training loss: 0.6869900385404493
Epoch: 41 | Iteration number: [4450/4518] 98% | Training loss: 0.686988952575105
Epoch: 41 | Iteration number: [4460/4518] 98% | Training loss: 0.6869870000890552
Epoch: 41 | Iteration number: [4470/4518] 98% | Training loss: 0.6869883051254605
Epoch: 41 | Iteration number: [4480/4518] 99% | Training loss: 0.6869846858616386
Epoch: 41 | Iteration number: [4490/4518] 99% | Training loss: 0.6869835974246197
Epoch: 41 | Iteration number: [4500/4518] 99% | Training loss: 0.6869831097920736
Epoch: 41 | Iteration number: [4510/4518] 99% | Training loss: 0.6869832438270163

 End of epoch: 41 | Train Loss: 0.6868317788182343 | Training Time: 642 

 End of epoch: 41 | Eval Loss: 0.6900101243233194 | Evaluating Time: 17 
Epoch: 42 | Iteration number: [10/4518] 0% | Training loss: 0.7557698309421539
Epoch: 42 | Iteration number: [20/4518] 0% | Training loss: 0.7217729419469834
Epoch: 42 | Iteration number: [30/4518] 0% | Training loss: 0.7095840692520141
Epoch: 42 | Iteration number: [40/4518] 0% | Training loss: 0.7037838131189347
Epoch: 42 | Iteration number: [50/4518] 1% | Training loss: 0.7002742874622345
Epoch: 42 | Iteration number: [60/4518] 1% | Training loss: 0.6981391439835231
Epoch: 42 | Iteration number: [70/4518] 1% | Training loss: 0.6965569078922271
Epoch: 42 | Iteration number: [80/4518] 1% | Training loss: 0.6952882885932923
Epoch: 42 | Iteration number: [90/4518] 1% | Training loss: 0.6944070233239068
Epoch: 42 | Iteration number: [100/4518] 2% | Training loss: 0.6935071980953217
Epoch: 42 | Iteration number: [110/4518] 2% | Training loss: 0.6928724012591622
Epoch: 42 | Iteration number: [120/4518] 2% | Training loss: 0.692468173801899
Epoch: 42 | Iteration number: [130/4518] 2% | Training loss: 0.6920717161435347
Epoch: 42 | Iteration number: [140/4518] 3% | Training loss: 0.6916563834462847
Epoch: 42 | Iteration number: [150/4518] 3% | Training loss: 0.6912130943934123
Epoch: 42 | Iteration number: [160/4518] 3% | Training loss: 0.6909698318690062
Epoch: 42 | Iteration number: [170/4518] 3% | Training loss: 0.690740637919482
Epoch: 42 | Iteration number: [180/4518] 3% | Training loss: 0.6904919601149029
Epoch: 42 | Iteration number: [190/4518] 4% | Training loss: 0.6902375814161803
Epoch: 42 | Iteration number: [200/4518] 4% | Training loss: 0.6901134577393532
Epoch: 42 | Iteration number: [210/4518] 4% | Training loss: 0.6899951415402549
Epoch: 42 | Iteration number: [220/4518] 4% | Training loss: 0.6898896526206624
Epoch: 42 | Iteration number: [230/4518] 5% | Training loss: 0.6897399544715881
Epoch: 42 | Iteration number: [240/4518] 5% | Training loss: 0.6895864712695281
Epoch: 42 | Iteration number: [250/4518] 5% | Training loss: 0.6894492361545562
Epoch: 42 | Iteration number: [260/4518] 5% | Training loss: 0.6893884282845717
Epoch: 42 | Iteration number: [270/4518] 5% | Training loss: 0.6892762870700271
Epoch: 42 | Iteration number: [280/4518] 6% | Training loss: 0.6892052243862833
Epoch: 42 | Iteration number: [290/4518] 6% | Training loss: 0.6891058494304788
Epoch: 42 | Iteration number: [300/4518] 6% | Training loss: 0.6890204918384552
Epoch: 42 | Iteration number: [310/4518] 6% | Training loss: 0.6889883124059246
Epoch: 42 | Iteration number: [320/4518] 7% | Training loss: 0.688901343382895
Epoch: 42 | Iteration number: [330/4518] 7% | Training loss: 0.6888809269124812
Epoch: 42 | Iteration number: [340/4518] 7% | Training loss: 0.6888427636202644
Epoch: 42 | Iteration number: [350/4518] 7% | Training loss: 0.6887869254180363
Epoch: 42 | Iteration number: [360/4518] 7% | Training loss: 0.6886721688840124
Epoch: 42 | Iteration number: [370/4518] 8% | Training loss: 0.6886496253915735
Epoch: 42 | Iteration number: [380/4518] 8% | Training loss: 0.6885876589699795
Epoch: 42 | Iteration number: [390/4518] 8% | Training loss: 0.6885471305786035
Epoch: 42 | Iteration number: [400/4518] 8% | Training loss: 0.6885175327956676
Epoch: 42 | Iteration number: [410/4518] 9% | Training loss: 0.6884689741018342
Epoch: 42 | Iteration number: [420/4518] 9% | Training loss: 0.6884213531301135
Epoch: 42 | Iteration number: [430/4518] 9% | Training loss: 0.68840181009714
Epoch: 42 | Iteration number: [440/4518] 9% | Training loss: 0.6883613131263039
Epoch: 42 | Iteration number: [450/4518] 9% | Training loss: 0.6883113594849904
Epoch: 42 | Iteration number: [460/4518] 10% | Training loss: 0.688297768779423
Epoch: 42 | Iteration number: [470/4518] 10% | Training loss: 0.6882532638438205
Epoch: 42 | Iteration number: [480/4518] 10% | Training loss: 0.6882255646089713
Epoch: 42 | Iteration number: [490/4518] 10% | Training loss: 0.6882045306721513
Epoch: 42 | Iteration number: [500/4518] 11% | Training loss: 0.6881751217842103
Epoch: 42 | Iteration number: [510/4518] 11% | Training loss: 0.6881450567759719
Epoch: 42 | Iteration number: [520/4518] 11% | Training loss: 0.6881198897957802
Epoch: 42 | Iteration number: [530/4518] 11% | Training loss: 0.6881008625030518
Epoch: 42 | Iteration number: [540/4518] 11% | Training loss: 0.688068159531664
Epoch: 42 | Iteration number: [550/4518] 12% | Training loss: 0.6880443887277083
Epoch: 42 | Iteration number: [560/4518] 12% | Training loss: 0.6880039980368955
Epoch: 42 | Iteration number: [570/4518] 12% | Training loss: 0.6880082673148105
Epoch: 42 | Iteration number: [580/4518] 12% | Training loss: 0.6879720415534645
Epoch: 42 | Iteration number: [590/4518] 13% | Training loss: 0.6879565232891147
Epoch: 42 | Iteration number: [600/4518] 13% | Training loss: 0.6879483053088188
Epoch: 42 | Iteration number: [610/4518] 13% | Training loss: 0.6879161352994012
Epoch: 42 | Iteration number: [620/4518] 13% | Training loss: 0.6879107350303281
Epoch: 42 | Iteration number: [630/4518] 13% | Training loss: 0.6879080416664245
Epoch: 42 | Iteration number: [640/4518] 14% | Training loss: 0.6878953448496758
Epoch: 42 | Iteration number: [650/4518] 14% | Training loss: 0.687879373568755
Epoch: 42 | Iteration number: [660/4518] 14% | Training loss: 0.6878531782012998
Epoch: 42 | Iteration number: [670/4518] 14% | Training loss: 0.6878479944236243
Epoch: 42 | Iteration number: [680/4518] 15% | Training loss: 0.687846497928395
Epoch: 42 | Iteration number: [690/4518] 15% | Training loss: 0.6878482302029928
Epoch: 42 | Iteration number: [700/4518] 15% | Training loss: 0.6878167397635324
Epoch: 42 | Iteration number: [710/4518] 15% | Training loss: 0.6878242910747797
Epoch: 42 | Iteration number: [720/4518] 15% | Training loss: 0.6878072374396854
Epoch: 42 | Iteration number: [730/4518] 16% | Training loss: 0.6877777698105328
Epoch: 42 | Iteration number: [740/4518] 16% | Training loss: 0.6877631132667129
Epoch: 42 | Iteration number: [750/4518] 16% | Training loss: 0.6877571341196695
Epoch: 42 | Iteration number: [760/4518] 16% | Training loss: 0.6877244650533325
Epoch: 42 | Iteration number: [770/4518] 17% | Training loss: 0.6877212025128402
Epoch: 42 | Iteration number: [780/4518] 17% | Training loss: 0.687702185756121
Epoch: 42 | Iteration number: [790/4518] 17% | Training loss: 0.6876925973952571
Epoch: 42 | Iteration number: [800/4518] 17% | Training loss: 0.6876896733045578
Epoch: 42 | Iteration number: [810/4518] 17% | Training loss: 0.6876750510415913
Epoch: 42 | Iteration number: [820/4518] 18% | Training loss: 0.6876606425134147
Epoch: 42 | Iteration number: [830/4518] 18% | Training loss: 0.6876567727830036
Epoch: 42 | Iteration number: [840/4518] 18% | Training loss: 0.6876530349254608
Epoch: 42 | Iteration number: [850/4518] 18% | Training loss: 0.687655029296875
Epoch: 42 | Iteration number: [860/4518] 19% | Training loss: 0.6876464739095333
Epoch: 42 | Iteration number: [870/4518] 19% | Training loss: 0.6876162508438374
Epoch: 42 | Iteration number: [880/4518] 19% | Training loss: 0.6876084301959384
Epoch: 42 | Iteration number: [890/4518] 19% | Training loss: 0.6875840598277831
Epoch: 42 | Iteration number: [900/4518] 19% | Training loss: 0.6875576114654541
Epoch: 42 | Iteration number: [910/4518] 20% | Training loss: 0.6875389266800095
Epoch: 42 | Iteration number: [920/4518] 20% | Training loss: 0.6875328145597293
Epoch: 42 | Iteration number: [930/4518] 20% | Training loss: 0.6875196553045704
Epoch: 42 | Iteration number: [940/4518] 20% | Training loss: 0.6875123365762386
Epoch: 42 | Iteration number: [950/4518] 21% | Training loss: 0.6875085874607688
Epoch: 42 | Iteration number: [960/4518] 21% | Training loss: 0.6874864220619201
Epoch: 42 | Iteration number: [970/4518] 21% | Training loss: 0.687478791315531
Epoch: 42 | Iteration number: [980/4518] 21% | Training loss: 0.6874703511899831
Epoch: 42 | Iteration number: [990/4518] 21% | Training loss: 0.6874685708922569
Epoch: 42 | Iteration number: [1000/4518] 22% | Training loss: 0.6874561637043953
Epoch: 42 | Iteration number: [1010/4518] 22% | Training loss: 0.6874545235445003
Epoch: 42 | Iteration number: [1020/4518] 22% | Training loss: 0.6874427735221152
Epoch: 42 | Iteration number: [1030/4518] 22% | Training loss: 0.6874393832336352
Epoch: 42 | Iteration number: [1040/4518] 23% | Training loss: 0.6874221038932984
Epoch: 42 | Iteration number: [1050/4518] 23% | Training loss: 0.6874318193254016
Epoch: 42 | Iteration number: [1060/4518] 23% | Training loss: 0.6874299644861581
Epoch: 42 | Iteration number: [1070/4518] 23% | Training loss: 0.6874345066391419
Epoch: 42 | Iteration number: [1080/4518] 23% | Training loss: 0.6874369962347878
Epoch: 42 | Iteration number: [1090/4518] 24% | Training loss: 0.6874222484750485
Epoch: 42 | Iteration number: [1100/4518] 24% | Training loss: 0.687414335120808
Epoch: 42 | Iteration number: [1110/4518] 24% | Training loss: 0.6874156960495957
Epoch: 42 | Iteration number: [1120/4518] 24% | Training loss: 0.6874155888600009
Epoch: 42 | Iteration number: [1130/4518] 25% | Training loss: 0.6874137182151322
Epoch: 42 | Iteration number: [1140/4518] 25% | Training loss: 0.6874005029076025
Epoch: 42 | Iteration number: [1150/4518] 25% | Training loss: 0.6873897828744805
Epoch: 42 | Iteration number: [1160/4518] 25% | Training loss: 0.6873793025982791
Epoch: 42 | Iteration number: [1170/4518] 25% | Training loss: 0.6873754506946629
Epoch: 42 | Iteration number: [1180/4518] 26% | Training loss: 0.6873841075068813
Epoch: 42 | Iteration number: [1190/4518] 26% | Training loss: 0.6873781447150126
Epoch: 42 | Iteration number: [1200/4518] 26% | Training loss: 0.6873715862135092
Epoch: 42 | Iteration number: [1210/4518] 26% | Training loss: 0.687365818516282
Epoch: 42 | Iteration number: [1220/4518] 27% | Training loss: 0.6873665459331919
Epoch: 42 | Iteration number: [1230/4518] 27% | Training loss: 0.6873639146486918
Epoch: 42 | Iteration number: [1240/4518] 27% | Training loss: 0.6873606328522005
Epoch: 42 | Iteration number: [1250/4518] 27% | Training loss: 0.6873501777648926
Epoch: 42 | Iteration number: [1260/4518] 27% | Training loss: 0.6873437082010602
Epoch: 42 | Iteration number: [1270/4518] 28% | Training loss: 0.6873445547941163
Epoch: 42 | Iteration number: [1280/4518] 28% | Training loss: 0.6873414488509297
Epoch: 42 | Iteration number: [1290/4518] 28% | Training loss: 0.6873433082140693
Epoch: 42 | Iteration number: [1300/4518] 28% | Training loss: 0.6873362083159961
Epoch: 42 | Iteration number: [1310/4518] 28% | Training loss: 0.6873429824832742
Epoch: 42 | Iteration number: [1320/4518] 29% | Training loss: 0.6873351345911171
Epoch: 42 | Iteration number: [1330/4518] 29% | Training loss: 0.6873229319439795
Epoch: 42 | Iteration number: [1340/4518] 29% | Training loss: 0.6873258382971607
Epoch: 42 | Iteration number: [1350/4518] 29% | Training loss: 0.6873181762518706
Epoch: 42 | Iteration number: [1360/4518] 30% | Training loss: 0.6873168887899203
Epoch: 42 | Iteration number: [1370/4518] 30% | Training loss: 0.6873110452272596
Epoch: 42 | Iteration number: [1380/4518] 30% | Training loss: 0.6873039658518805
Epoch: 42 | Iteration number: [1390/4518] 30% | Training loss: 0.6872924624587134
Epoch: 42 | Iteration number: [1400/4518] 30% | Training loss: 0.6872736935956137
Epoch: 42 | Iteration number: [1410/4518] 31% | Training loss: 0.6872765984518309
Epoch: 42 | Iteration number: [1420/4518] 31% | Training loss: 0.687273707985878
Epoch: 42 | Iteration number: [1430/4518] 31% | Training loss: 0.687269631257424
Epoch: 42 | Iteration number: [1440/4518] 31% | Training loss: 0.6872710295021534
Epoch: 42 | Iteration number: [1450/4518] 32% | Training loss: 0.6872675915011044
Epoch: 42 | Iteration number: [1460/4518] 32% | Training loss: 0.6872542695231634
Epoch: 42 | Iteration number: [1470/4518] 32% | Training loss: 0.6872546022846585
Epoch: 42 | Iteration number: [1480/4518] 32% | Training loss: 0.6872502810246236
Epoch: 42 | Iteration number: [1490/4518] 32% | Training loss: 0.6872456480192658
Epoch: 42 | Iteration number: [1500/4518] 33% | Training loss: 0.6872473851044972
Epoch: 42 | Iteration number: [1510/4518] 33% | Training loss: 0.6872481987176352
Epoch: 42 | Iteration number: [1520/4518] 33% | Training loss: 0.6872468202521926
Epoch: 42 | Iteration number: [1530/4518] 33% | Training loss: 0.6872464197523453
Epoch: 42 | Iteration number: [1540/4518] 34% | Training loss: 0.6872434472882902
Epoch: 42 | Iteration number: [1550/4518] 34% | Training loss: 0.6872439639029965
Epoch: 42 | Iteration number: [1560/4518] 34% | Training loss: 0.6872485327797059
Epoch: 42 | Iteration number: [1570/4518] 34% | Training loss: 0.6872419150012314
Epoch: 42 | Iteration number: [1580/4518] 34% | Training loss: 0.6872257786838314
Epoch: 42 | Iteration number: [1590/4518] 35% | Training loss: 0.6872283619154924
Epoch: 42 | Iteration number: [1600/4518] 35% | Training loss: 0.6872253767773508
Epoch: 42 | Iteration number: [1610/4518] 35% | Training loss: 0.6872253047753565
Epoch: 42 | Iteration number: [1620/4518] 35% | Training loss: 0.6872325484767372
Epoch: 42 | Iteration number: [1630/4518] 36% | Training loss: 0.6872313962026608
Epoch: 42 | Iteration number: [1640/4518] 36% | Training loss: 0.6872307402695098
Epoch: 42 | Iteration number: [1650/4518] 36% | Training loss: 0.6872285574132746
Epoch: 42 | Iteration number: [1660/4518] 36% | Training loss: 0.6872234562075282
Epoch: 42 | Iteration number: [1670/4518] 36% | Training loss: 0.6872149362892448
Epoch: 42 | Iteration number: [1680/4518] 37% | Training loss: 0.6872136059616293
Epoch: 42 | Iteration number: [1690/4518] 37% | Training loss: 0.6872187288907858
Epoch: 42 | Iteration number: [1700/4518] 37% | Training loss: 0.6872149408214232
Epoch: 42 | Iteration number: [1710/4518] 37% | Training loss: 0.6872131938822785
Epoch: 42 | Iteration number: [1720/4518] 38% | Training loss: 0.6872055206881013
Epoch: 42 | Iteration number: [1730/4518] 38% | Training loss: 0.6871946994968922
Epoch: 42 | Iteration number: [1740/4518] 38% | Training loss: 0.6871921307396615
Epoch: 42 | Iteration number: [1750/4518] 38% | Training loss: 0.687190963608878
Epoch: 42 | Iteration number: [1760/4518] 38% | Training loss: 0.6871957718987357
Epoch: 42 | Iteration number: [1770/4518] 39% | Training loss: 0.6871911994481491
Epoch: 42 | Iteration number: [1780/4518] 39% | Training loss: 0.6871945740466707
Epoch: 42 | Iteration number: [1790/4518] 39% | Training loss: 0.6872011125420725
Epoch: 42 | Iteration number: [1800/4518] 39% | Training loss: 0.6871992226772838
Epoch: 42 | Iteration number: [1810/4518] 40% | Training loss: 0.6871990182123131
Epoch: 42 | Iteration number: [1820/4518] 40% | Training loss: 0.6871985850753365
Epoch: 42 | Iteration number: [1830/4518] 40% | Training loss: 0.6871945206259118
Epoch: 42 | Iteration number: [1840/4518] 40% | Training loss: 0.6871908643647381
Epoch: 42 | Iteration number: [1850/4518] 40% | Training loss: 0.6871910569796691
Epoch: 42 | Iteration number: [1860/4518] 41% | Training loss: 0.6871832037484774
Epoch: 42 | Iteration number: [1870/4518] 41% | Training loss: 0.6871817976714456
Epoch: 42 | Iteration number: [1880/4518] 41% | Training loss: 0.6871804538876453
Epoch: 42 | Iteration number: [1890/4518] 41% | Training loss: 0.6871763693907904
Epoch: 42 | Iteration number: [1900/4518] 42% | Training loss: 0.6871741226786061
Epoch: 42 | Iteration number: [1910/4518] 42% | Training loss: 0.6871795491086251
Epoch: 42 | Iteration number: [1920/4518] 42% | Training loss: 0.6871768588200211
Epoch: 42 | Iteration number: [1930/4518] 42% | Training loss: 0.6871801628041144
Epoch: 42 | Iteration number: [1940/4518] 42% | Training loss: 0.6871819403675413
Epoch: 42 | Iteration number: [1950/4518] 43% | Training loss: 0.6871808263888726
Epoch: 42 | Iteration number: [1960/4518] 43% | Training loss: 0.6871794505082831
Epoch: 42 | Iteration number: [1970/4518] 43% | Training loss: 0.6871772295629918
Epoch: 42 | Iteration number: [1980/4518] 43% | Training loss: 0.6871784524484115
Epoch: 42 | Iteration number: [1990/4518] 44% | Training loss: 0.6871747869642536
Epoch: 42 | Iteration number: [2000/4518] 44% | Training loss: 0.6871734710931778
Epoch: 42 | Iteration number: [2010/4518] 44% | Training loss: 0.6871695457702846
Epoch: 42 | Iteration number: [2020/4518] 44% | Training loss: 0.6871677921845181
Epoch: 42 | Iteration number: [2030/4518] 44% | Training loss: 0.6871703511094812
Epoch: 42 | Iteration number: [2040/4518] 45% | Training loss: 0.6871624805179297
Epoch: 42 | Iteration number: [2050/4518] 45% | Training loss: 0.687157451583118
Epoch: 42 | Iteration number: [2060/4518] 45% | Training loss: 0.6871468980046151
Epoch: 42 | Iteration number: [2070/4518] 45% | Training loss: 0.6871498712882903
Epoch: 42 | Iteration number: [2080/4518] 46% | Training loss: 0.6871451583905862
Epoch: 42 | Iteration number: [2090/4518] 46% | Training loss: 0.6871451990456102
Epoch: 42 | Iteration number: [2100/4518] 46% | Training loss: 0.6871444127957026
Epoch: 42 | Iteration number: [2110/4518] 46% | Training loss: 0.6871384920384647
Epoch: 42 | Iteration number: [2120/4518] 46% | Training loss: 0.6871344085853055
Epoch: 42 | Iteration number: [2130/4518] 47% | Training loss: 0.6871369999339323
Epoch: 42 | Iteration number: [2140/4518] 47% | Training loss: 0.6871352161202475
Epoch: 42 | Iteration number: [2150/4518] 47% | Training loss: 0.6871301891360172
Epoch: 42 | Iteration number: [2160/4518] 47% | Training loss: 0.6871229392510874
Epoch: 42 | Iteration number: [2170/4518] 48% | Training loss: 0.687115810790919
Epoch: 42 | Iteration number: [2180/4518] 48% | Training loss: 0.6871136548322275
Epoch: 42 | Iteration number: [2190/4518] 48% | Training loss: 0.6871087929973864
Epoch: 42 | Iteration number: [2200/4518] 48% | Training loss: 0.687115051150322
Epoch: 42 | Iteration number: [2210/4518] 48% | Training loss: 0.6871154348235324
Epoch: 42 | Iteration number: [2220/4518] 49% | Training loss: 0.6871175164037997
Epoch: 42 | Iteration number: [2230/4518] 49% | Training loss: 0.687121070767732
Epoch: 42 | Iteration number: [2240/4518] 49% | Training loss: 0.6871233868279627
Epoch: 42 | Iteration number: [2250/4518] 49% | Training loss: 0.6871199737654792
Epoch: 42 | Iteration number: [2260/4518] 50% | Training loss: 0.6871198077908659
Epoch: 42 | Iteration number: [2270/4518] 50% | Training loss: 0.6871219233006632
Epoch: 42 | Iteration number: [2280/4518] 50% | Training loss: 0.6871228484208124
Epoch: 42 | Iteration number: [2290/4518] 50% | Training loss: 0.6871177089266381
Epoch: 42 | Iteration number: [2300/4518] 50% | Training loss: 0.6871132036913996
Epoch: 42 | Iteration number: [2310/4518] 51% | Training loss: 0.6871070034318156
Epoch: 42 | Iteration number: [2320/4518] 51% | Training loss: 0.6871063922242872
Epoch: 42 | Iteration number: [2330/4518] 51% | Training loss: 0.6871040854587064
Epoch: 42 | Iteration number: [2340/4518] 51% | Training loss: 0.6871069092016954
Epoch: 42 | Iteration number: [2350/4518] 52% | Training loss: 0.6871008514597061
Epoch: 42 | Iteration number: [2360/4518] 52% | Training loss: 0.6871047051276191
Epoch: 42 | Iteration number: [2370/4518] 52% | Training loss: 0.6871037838579733
Epoch: 42 | Iteration number: [2380/4518] 52% | Training loss: 0.6871024726318712
Epoch: 42 | Iteration number: [2390/4518] 52% | Training loss: 0.6871028601873869
Epoch: 42 | Iteration number: [2400/4518] 53% | Training loss: 0.6871001725643873
Epoch: 42 | Iteration number: [2410/4518] 53% | Training loss: 0.6871025059727712
Epoch: 42 | Iteration number: [2420/4518] 53% | Training loss: 0.6870989341627468
Epoch: 42 | Iteration number: [2430/4518] 53% | Training loss: 0.687096663021747
Epoch: 42 | Iteration number: [2440/4518] 54% | Training loss: 0.6870948539161291
Epoch: 42 | Iteration number: [2450/4518] 54% | Training loss: 0.6870945538793292
Epoch: 42 | Iteration number: [2460/4518] 54% | Training loss: 0.6870943527396133
Epoch: 42 | Iteration number: [2470/4518] 54% | Training loss: 0.6870920486778382
Epoch: 42 | Iteration number: [2480/4518] 54% | Training loss: 0.6870938259507379
Epoch: 42 | Iteration number: [2490/4518] 55% | Training loss: 0.6870951693938918
Epoch: 42 | Iteration number: [2500/4518] 55% | Training loss: 0.6870956736326218
Epoch: 42 | Iteration number: [2510/4518] 55% | Training loss: 0.6870926501503979
Epoch: 42 | Iteration number: [2520/4518] 55% | Training loss: 0.6870898563000891
Epoch: 42 | Iteration number: [2530/4518] 55% | Training loss: 0.6870896829682377
Epoch: 42 | Iteration number: [2540/4518] 56% | Training loss: 0.6870919213285597
Epoch: 42 | Iteration number: [2550/4518] 56% | Training loss: 0.6870874871225918
Epoch: 42 | Iteration number: [2560/4518] 56% | Training loss: 0.6870881390059367
Epoch: 42 | Iteration number: [2570/4518] 56% | Training loss: 0.6870856751727686
Epoch: 42 | Iteration number: [2580/4518] 57% | Training loss: 0.6870835878359255
Epoch: 42 | Iteration number: [2590/4518] 57% | Training loss: 0.6870871770566035
Epoch: 42 | Iteration number: [2600/4518] 57% | Training loss: 0.6870809161204559
Epoch: 42 | Iteration number: [2610/4518] 57% | Training loss: 0.687081494345062
Epoch: 42 | Iteration number: [2620/4518] 57% | Training loss: 0.6870732954212727
Epoch: 42 | Iteration number: [2630/4518] 58% | Training loss: 0.6870719699578594
Epoch: 42 | Iteration number: [2640/4518] 58% | Training loss: 0.6870700562767911
Epoch: 42 | Iteration number: [2650/4518] 58% | Training loss: 0.6870690815178853
Epoch: 42 | Iteration number: [2660/4518] 58% | Training loss: 0.6870665469788071
Epoch: 42 | Iteration number: [2670/4518] 59% | Training loss: 0.6870631457044837
Epoch: 42 | Iteration number: [2680/4518] 59% | Training loss: 0.6870627900112921
Epoch: 42 | Iteration number: [2690/4518] 59% | Training loss: 0.687064486852809
Epoch: 42 | Iteration number: [2700/4518] 59% | Training loss: 0.6870682896287353
Epoch: 42 | Iteration number: [2710/4518] 59% | Training loss: 0.6870670088102897
Epoch: 42 | Iteration number: [2720/4518] 60% | Training loss: 0.6870635696193751
Epoch: 42 | Iteration number: [2730/4518] 60% | Training loss: 0.6870640126340118
Epoch: 42 | Iteration number: [2740/4518] 60% | Training loss: 0.6870665888499169
Epoch: 42 | Iteration number: [2750/4518] 60% | Training loss: 0.6870684581236406
Epoch: 42 | Iteration number: [2760/4518] 61% | Training loss: 0.6870611178702203
Epoch: 42 | Iteration number: [2770/4518] 61% | Training loss: 0.6870565660163384
Epoch: 42 | Iteration number: [2780/4518] 61% | Training loss: 0.6870566521831554
Epoch: 42 | Iteration number: [2790/4518] 61% | Training loss: 0.6870572172185426
Epoch: 42 | Iteration number: [2800/4518] 61% | Training loss: 0.6870532913718905
Epoch: 42 | Iteration number: [2810/4518] 62% | Training loss: 0.6870539799703822
Epoch: 42 | Iteration number: [2820/4518] 62% | Training loss: 0.6870543046623258
Epoch: 42 | Iteration number: [2830/4518] 62% | Training loss: 0.687057464451335
Epoch: 42 | Iteration number: [2840/4518] 62% | Training loss: 0.6870595413404451
Epoch: 42 | Iteration number: [2850/4518] 63% | Training loss: 0.6870593110929456
Epoch: 42 | Iteration number: [2860/4518] 63% | Training loss: 0.6870601023410584
Epoch: 42 | Iteration number: [2870/4518] 63% | Training loss: 0.6870658256035649
Epoch: 42 | Iteration number: [2880/4518] 63% | Training loss: 0.6870627496184574
Epoch: 42 | Iteration number: [2890/4518] 63% | Training loss: 0.6870588088943059
Epoch: 42 | Iteration number: [2900/4518] 64% | Training loss: 0.6870579892807993
Epoch: 42 | Iteration number: [2910/4518] 64% | Training loss: 0.6870568059973701
Epoch: 42 | Iteration number: [2920/4518] 64% | Training loss: 0.6870573327761806
Epoch: 42 | Iteration number: [2930/4518] 64% | Training loss: 0.687055057490645
Epoch: 42 | Iteration number: [2940/4518] 65% | Training loss: 0.6870595834084919
Epoch: 42 | Iteration number: [2950/4518] 65% | Training loss: 0.6870581227641994
Epoch: 42 | Iteration number: [2960/4518] 65% | Training loss: 0.6870569126428785
Epoch: 42 | Iteration number: [2970/4518] 65% | Training loss: 0.6870546258659876
Epoch: 42 | Iteration number: [2980/4518] 65% | Training loss: 0.6870520151701549
Epoch: 42 | Iteration number: [2990/4518] 66% | Training loss: 0.6870509164787854
Epoch: 42 | Iteration number: [3000/4518] 66% | Training loss: 0.6870490723450978
Epoch: 42 | Iteration number: [3010/4518] 66% | Training loss: 0.6870460644116829
Epoch: 42 | Iteration number: [3020/4518] 66% | Training loss: 0.6870411602669204
Epoch: 42 | Iteration number: [3030/4518] 67% | Training loss: 0.6870432015692833
Epoch: 42 | Iteration number: [3040/4518] 67% | Training loss: 0.6870462076836511
Epoch: 42 | Iteration number: [3050/4518] 67% | Training loss: 0.6870476525924245
Epoch: 42 | Iteration number: [3060/4518] 67% | Training loss: 0.6870438685409384
Epoch: 42 | Iteration number: [3070/4518] 67% | Training loss: 0.6870439319152397
Epoch: 42 | Iteration number: [3080/4518] 68% | Training loss: 0.687041925861464
Epoch: 42 | Iteration number: [3090/4518] 68% | Training loss: 0.6870446823175671
Epoch: 42 | Iteration number: [3100/4518] 68% | Training loss: 0.6870407251581069
Epoch: 42 | Iteration number: [3110/4518] 68% | Training loss: 0.6870360379433709
Epoch: 42 | Iteration number: [3120/4518] 69% | Training loss: 0.6870300627289674
Epoch: 42 | Iteration number: [3130/4518] 69% | Training loss: 0.6870272290592376
Epoch: 42 | Iteration number: [3140/4518] 69% | Training loss: 0.6870285564547132
Epoch: 42 | Iteration number: [3150/4518] 69% | Training loss: 0.6870285407512907
Epoch: 42 | Iteration number: [3160/4518] 69% | Training loss: 0.687025107556506
Epoch: 42 | Iteration number: [3170/4518] 70% | Training loss: 0.6870241912945588
Epoch: 42 | Iteration number: [3180/4518] 70% | Training loss: 0.6870194703715402
Epoch: 42 | Iteration number: [3190/4518] 70% | Training loss: 0.6870183708899447
Epoch: 42 | Iteration number: [3200/4518] 70% | Training loss: 0.6870193160325289
Epoch: 42 | Iteration number: [3210/4518] 71% | Training loss: 0.6870178047741685
Epoch: 42 | Iteration number: [3220/4518] 71% | Training loss: 0.6870186971211285
Epoch: 42 | Iteration number: [3230/4518] 71% | Training loss: 0.6870165114432296
Epoch: 42 | Iteration number: [3240/4518] 71% | Training loss: 0.6870142456558016
Epoch: 42 | Iteration number: [3250/4518] 71% | Training loss: 0.6870135431106273
Epoch: 42 | Iteration number: [3260/4518] 72% | Training loss: 0.6870114838418785
Epoch: 42 | Iteration number: [3270/4518] 72% | Training loss: 0.68701159474682
Epoch: 42 | Iteration number: [3280/4518] 72% | Training loss: 0.6870122030377388
Epoch: 42 | Iteration number: [3290/4518] 72% | Training loss: 0.6870135265643111
Epoch: 42 | Iteration number: [3300/4518] 73% | Training loss: 0.6870115844228051
Epoch: 42 | Iteration number: [3310/4518] 73% | Training loss: 0.6870117141581014
Epoch: 42 | Iteration number: [3320/4518] 73% | Training loss: 0.6870131109493325
Epoch: 42 | Iteration number: [3330/4518] 73% | Training loss: 0.687012754886358
Epoch: 42 | Iteration number: [3340/4518] 73% | Training loss: 0.6870131213686423
Epoch: 42 | Iteration number: [3350/4518] 74% | Training loss: 0.6870086766890625
Epoch: 42 | Iteration number: [3360/4518] 74% | Training loss: 0.6870088796885241
Epoch: 42 | Iteration number: [3370/4518] 74% | Training loss: 0.6870086707417972
Epoch: 42 | Iteration number: [3380/4518] 74% | Training loss: 0.6870103510173821
Epoch: 42 | Iteration number: [3390/4518] 75% | Training loss: 0.6870078410898338
Epoch: 42 | Iteration number: [3400/4518] 75% | Training loss: 0.687010972131701
Epoch: 42 | Iteration number: [3410/4518] 75% | Training loss: 0.6870118053427889
Epoch: 42 | Iteration number: [3420/4518] 75% | Training loss: 0.6870132359670617
Epoch: 42 | Iteration number: [3430/4518] 75% | Training loss: 0.6870146247110284
Epoch: 42 | Iteration number: [3440/4518] 76% | Training loss: 0.6870151325020679
Epoch: 42 | Iteration number: [3450/4518] 76% | Training loss: 0.6870152842825737
Epoch: 42 | Iteration number: [3460/4518] 76% | Training loss: 0.6870132567393298
Epoch: 42 | Iteration number: [3470/4518] 76% | Training loss: 0.6870085262599527
Epoch: 42 | Iteration number: [3480/4518] 77% | Training loss: 0.6870100873126381
Epoch: 42 | Iteration number: [3490/4518] 77% | Training loss: 0.6870105748531812
Epoch: 42 | Iteration number: [3500/4518] 77% | Training loss: 0.6870057984760829
Epoch: 42 | Iteration number: [3510/4518] 77% | Training loss: 0.6870052782728462
Epoch: 42 | Iteration number: [3520/4518] 77% | Training loss: 0.687007408639924
Epoch: 42 | Iteration number: [3530/4518] 78% | Training loss: 0.6870076934102575
Epoch: 42 | Iteration number: [3540/4518] 78% | Training loss: 0.6870058948542439
Epoch: 42 | Iteration number: [3550/4518] 78% | Training loss: 0.687006147159657
Epoch: 42 | Iteration number: [3560/4518] 78% | Training loss: 0.687004445526707
Epoch: 42 | Iteration number: [3570/4518] 79% | Training loss: 0.6870066976680809
Epoch: 42 | Iteration number: [3580/4518] 79% | Training loss: 0.6870074988743446
Epoch: 42 | Iteration number: [3590/4518] 79% | Training loss: 0.6870045615105907
Epoch: 42 | Iteration number: [3600/4518] 79% | Training loss: 0.6870053402251668
Epoch: 42 | Iteration number: [3610/4518] 79% | Training loss: 0.6870040368670571
Epoch: 42 | Iteration number: [3620/4518] 80% | Training loss: 0.6870067592648511
Epoch: 42 | Iteration number: [3630/4518] 80% | Training loss: 0.687003876699889
Epoch: 42 | Iteration number: [3640/4518] 80% | Training loss: 0.6870038601559597
Epoch: 42 | Iteration number: [3650/4518] 80% | Training loss: 0.6870056966069626
Epoch: 42 | Iteration number: [3660/4518] 81% | Training loss: 0.6870044050809464
Epoch: 42 | Iteration number: [3670/4518] 81% | Training loss: 0.6870042393090614
Epoch: 42 | Iteration number: [3680/4518] 81% | Training loss: 0.6870063043968833
Epoch: 42 | Iteration number: [3690/4518] 81% | Training loss: 0.6870066994897073
Epoch: 42 | Iteration number: [3700/4518] 81% | Training loss: 0.6870014641091631
Epoch: 42 | Iteration number: [3710/4518] 82% | Training loss: 0.6869988807288784
Epoch: 42 | Iteration number: [3720/4518] 82% | Training loss: 0.687000956987181
Epoch: 42 | Iteration number: [3730/4518] 82% | Training loss: 0.6870005533298922
Epoch: 42 | Iteration number: [3740/4518] 82% | Training loss: 0.6870048401030627
Epoch: 42 | Iteration number: [3750/4518] 83% | Training loss: 0.6870087839285532
Epoch: 42 | Iteration number: [3760/4518] 83% | Training loss: 0.687011024546116
Epoch: 42 | Iteration number: [3770/4518] 83% | Training loss: 0.6870114217860629
Epoch: 42 | Iteration number: [3780/4518] 83% | Training loss: 0.6870096356938125
Epoch: 42 | Iteration number: [3790/4518] 83% | Training loss: 0.687009195727849
Epoch: 42 | Iteration number: [3800/4518] 84% | Training loss: 0.6870104932941888
Epoch: 42 | Iteration number: [3810/4518] 84% | Training loss: 0.6870089901870317
Epoch: 42 | Iteration number: [3820/4518] 84% | Training loss: 0.6870106185137913
Epoch: 42 | Iteration number: [3830/4518] 84% | Training loss: 0.6870116931651342
Epoch: 42 | Iteration number: [3840/4518] 84% | Training loss: 0.6870102162472904
Epoch: 42 | Iteration number: [3850/4518] 85% | Training loss: 0.6870105348004923
Epoch: 42 | Iteration number: [3860/4518] 85% | Training loss: 0.6870073568017989
Epoch: 42 | Iteration number: [3870/4518] 85% | Training loss: 0.6870053896454261
Epoch: 42 | Iteration number: [3880/4518] 85% | Training loss: 0.6870060960502968
Epoch: 42 | Iteration number: [3890/4518] 86% | Training loss: 0.6870090611796146
Epoch: 42 | Iteration number: [3900/4518] 86% | Training loss: 0.6870077408582737
Epoch: 42 | Iteration number: [3910/4518] 86% | Training loss: 0.6870099789956037
Epoch: 42 | Iteration number: [3920/4518] 86% | Training loss: 0.6870100632005808
Epoch: 42 | Iteration number: [3930/4518] 86% | Training loss: 0.6870056540608103
Epoch: 42 | Iteration number: [3940/4518] 87% | Training loss: 0.6870046281269965
Epoch: 42 | Iteration number: [3950/4518] 87% | Training loss: 0.6870038443728338
Epoch: 42 | Iteration number: [3960/4518] 87% | Training loss: 0.6870052464682647
Epoch: 42 | Iteration number: [3970/4518] 87% | Training loss: 0.687002678166709
Epoch: 42 | Iteration number: [3980/4518] 88% | Training loss: 0.6870003700555869
Epoch: 42 | Iteration number: [3990/4518] 88% | Training loss: 0.6870022138706724
Epoch: 42 | Iteration number: [4000/4518] 88% | Training loss: 0.6870013435184955
Epoch: 42 | Iteration number: [4010/4518] 88% | Training loss: 0.686999424303559
Epoch: 42 | Iteration number: [4020/4518] 88% | Training loss: 0.6869977850670839
Epoch: 42 | Iteration number: [4030/4518] 89% | Training loss: 0.6869985794015321
Epoch: 42 | Iteration number: [4040/4518] 89% | Training loss: 0.6869958340974137
Epoch: 42 | Iteration number: [4050/4518] 89% | Training loss: 0.6869972671844341
Epoch: 42 | Iteration number: [4060/4518] 89% | Training loss: 0.6869951596401008
Epoch: 42 | Iteration number: [4070/4518] 90% | Training loss: 0.6869958809464803
Epoch: 42 | Iteration number: [4080/4518] 90% | Training loss: 0.6869946047663689
Epoch: 42 | Iteration number: [4090/4518] 90% | Training loss: 0.6869936237416815
Epoch: 42 | Iteration number: [4100/4518] 90% | Training loss: 0.6869936258036916
Epoch: 42 | Iteration number: [4110/4518] 90% | Training loss: 0.686991870200257
Epoch: 42 | Iteration number: [4120/4518] 91% | Training loss: 0.6869935323746459
Epoch: 42 | Iteration number: [4130/4518] 91% | Training loss: 0.686990345188261
Epoch: 42 | Iteration number: [4140/4518] 91% | Training loss: 0.6869876867187196
Epoch: 42 | Iteration number: [4150/4518] 91% | Training loss: 0.68698535541454
Epoch: 42 | Iteration number: [4160/4518] 92% | Training loss: 0.6869848702962582
Epoch: 42 | Iteration number: [4170/4518] 92% | Training loss: 0.6869855767102551
Epoch: 42 | Iteration number: [4180/4518] 92% | Training loss: 0.6869844124647989
Epoch: 42 | Iteration number: [4190/4518] 92% | Training loss: 0.686983984993295
Epoch: 42 | Iteration number: [4200/4518] 92% | Training loss: 0.6869844491566931
Epoch: 42 | Iteration number: [4210/4518] 93% | Training loss: 0.6869834404943108
Epoch: 42 | Iteration number: [4220/4518] 93% | Training loss: 0.6869838188751048
Epoch: 42 | Iteration number: [4230/4518] 93% | Training loss: 0.6869829163765513
Epoch: 42 | Iteration number: [4240/4518] 93% | Training loss: 0.6869838594968589
Epoch: 42 | Iteration number: [4250/4518] 94% | Training loss: 0.686983171785579
Epoch: 42 | Iteration number: [4260/4518] 94% | Training loss: 0.6869823965947952
Epoch: 42 | Iteration number: [4270/4518] 94% | Training loss: 0.6869815686966273
Epoch: 42 | Iteration number: [4280/4518] 94% | Training loss: 0.6869808507856922
Epoch: 42 | Iteration number: [4290/4518] 94% | Training loss: 0.6869770430740498
Epoch: 42 | Iteration number: [4300/4518] 95% | Training loss: 0.6869798795705618
Epoch: 42 | Iteration number: [4310/4518] 95% | Training loss: 0.6869799820425339
Epoch: 42 | Iteration number: [4320/4518] 95% | Training loss: 0.6869810700554538
Epoch: 42 | Iteration number: [4330/4518] 95% | Training loss: 0.6869789477308683
Epoch: 42 | Iteration number: [4340/4518] 96% | Training loss: 0.6869791067140992
Epoch: 42 | Iteration number: [4350/4518] 96% | Training loss: 0.6869802402490857
Epoch: 42 | Iteration number: [4360/4518] 96% | Training loss: 0.6869825725435117
Epoch: 42 | Iteration number: [4370/4518] 96% | Training loss: 0.6869833075754702
Epoch: 42 | Iteration number: [4380/4518] 96% | Training loss: 0.6869849522364194
Epoch: 42 | Iteration number: [4390/4518] 97% | Training loss: 0.6869855727584595
Epoch: 42 | Iteration number: [4400/4518] 97% | Training loss: 0.6869843155145645
Epoch: 42 | Iteration number: [4410/4518] 97% | Training loss: 0.6869848465297769
Epoch: 42 | Iteration number: [4420/4518] 97% | Training loss: 0.6869865126334704
Epoch: 42 | Iteration number: [4430/4518] 98% | Training loss: 0.6869891069139907
Epoch: 42 | Iteration number: [4440/4518] 98% | Training loss: 0.6869856052704759
Epoch: 42 | Iteration number: [4450/4518] 98% | Training loss: 0.6869881413625867
Epoch: 42 | Iteration number: [4460/4518] 98% | Training loss: 0.6869864074638606
Epoch: 42 | Iteration number: [4470/4518] 98% | Training loss: 0.6869857855291175
Epoch: 42 | Iteration number: [4480/4518] 99% | Training loss: 0.6869850143790245
Epoch: 42 | Iteration number: [4490/4518] 99% | Training loss: 0.6869812806358847
Epoch: 42 | Iteration number: [4500/4518] 99% | Training loss: 0.6869815913836161
Epoch: 42 | Iteration number: [4510/4518] 99% | Training loss: 0.6869823474445258

 End of epoch: 42 | Train Loss: 0.6868294066905765 | Training Time: 642 

 End of epoch: 42 | Eval Loss: 0.6899796006630878 | Evaluating Time: 17 
Epoch: 43 | Iteration number: [10/4518] 0% | Training loss: 0.7557804465293885
Epoch: 43 | Iteration number: [20/4518] 0% | Training loss: 0.7216893762350083
Epoch: 43 | Iteration number: [30/4518] 0% | Training loss: 0.7102967580159505
Epoch: 43 | Iteration number: [40/4518] 0% | Training loss: 0.7043945491313934
Epoch: 43 | Iteration number: [50/4518] 1% | Training loss: 0.7009753084182739
Epoch: 43 | Iteration number: [60/4518] 1% | Training loss: 0.6985195606946946
Epoch: 43 | Iteration number: [70/4518] 1% | Training loss: 0.6968735601220812
Epoch: 43 | Iteration number: [80/4518] 1% | Training loss: 0.695658890902996
Epoch: 43 | Iteration number: [90/4518] 1% | Training loss: 0.6945803370740679
Epoch: 43 | Iteration number: [100/4518] 2% | Training loss: 0.693881893157959
Epoch: 43 | Iteration number: [110/4518] 2% | Training loss: 0.6932582882317629
Epoch: 43 | Iteration number: [120/4518] 2% | Training loss: 0.6927616521716118
Epoch: 43 | Iteration number: [130/4518] 2% | Training loss: 0.6923046772296612
Epoch: 43 | Iteration number: [140/4518] 3% | Training loss: 0.6919162929058075
Epoch: 43 | Iteration number: [150/4518] 3% | Training loss: 0.6915359540780386
Epoch: 43 | Iteration number: [160/4518] 3% | Training loss: 0.691233566403389
Epoch: 43 | Iteration number: [170/4518] 3% | Training loss: 0.6909816240563112
Epoch: 43 | Iteration number: [180/4518] 3% | Training loss: 0.6907800734043121
Epoch: 43 | Iteration number: [190/4518] 4% | Training loss: 0.6906149233642377
Epoch: 43 | Iteration number: [200/4518] 4% | Training loss: 0.6904534476995469
Epoch: 43 | Iteration number: [210/4518] 4% | Training loss: 0.690366700717381
Epoch: 43 | Iteration number: [220/4518] 4% | Training loss: 0.6901801916685971
Epoch: 43 | Iteration number: [230/4518] 5% | Training loss: 0.6899870491546133
Epoch: 43 | Iteration number: [240/4518] 5% | Training loss: 0.689880516876777
Epoch: 43 | Iteration number: [250/4518] 5% | Training loss: 0.6897407598495483
Epoch: 43 | Iteration number: [260/4518] 5% | Training loss: 0.6896606708948428
Epoch: 43 | Iteration number: [270/4518] 5% | Training loss: 0.6895649057847483
Epoch: 43 | Iteration number: [280/4518] 6% | Training loss: 0.6894782323922429
Epoch: 43 | Iteration number: [290/4518] 6% | Training loss: 0.6893765778377139
Epoch: 43 | Iteration number: [300/4518] 6% | Training loss: 0.6892787325382232
Epoch: 43 | Iteration number: [310/4518] 6% | Training loss: 0.6892147189186465
Epoch: 43 | Iteration number: [320/4518] 7% | Training loss: 0.6891495268791914
Epoch: 43 | Iteration number: [330/4518] 7% | Training loss: 0.6891317519274625
Epoch: 43 | Iteration number: [340/4518] 7% | Training loss: 0.689048464158002
Epoch: 43 | Iteration number: [350/4518] 7% | Training loss: 0.6889989374365125
Epoch: 43 | Iteration number: [360/4518] 7% | Training loss: 0.6889440541466078
Epoch: 43 | Iteration number: [370/4518] 8% | Training loss: 0.6888742321246379
Epoch: 43 | Iteration number: [380/4518] 8% | Training loss: 0.6888233547147952
Epoch: 43 | Iteration number: [390/4518] 8% | Training loss: 0.6887868124705094
Epoch: 43 | Iteration number: [400/4518] 8% | Training loss: 0.6887304691970348
Epoch: 43 | Iteration number: [410/4518] 9% | Training loss: 0.6886899442207522
Epoch: 43 | Iteration number: [420/4518] 9% | Training loss: 0.6886196636018299
Epoch: 43 | Iteration number: [430/4518] 9% | Training loss: 0.688577142427134
Epoch: 43 | Iteration number: [440/4518] 9% | Training loss: 0.6885421824726191
Epoch: 43 | Iteration number: [450/4518] 9% | Training loss: 0.6885057539410061
Epoch: 43 | Iteration number: [460/4518] 10% | Training loss: 0.6884683382251988
Epoch: 43 | Iteration number: [470/4518] 10% | Training loss: 0.6884247479286599
Epoch: 43 | Iteration number: [480/4518] 10% | Training loss: 0.688364480684201
Epoch: 43 | Iteration number: [490/4518] 10% | Training loss: 0.6883548683049727
Epoch: 43 | Iteration number: [500/4518] 11% | Training loss: 0.6883282568454743
Epoch: 43 | Iteration number: [510/4518] 11% | Training loss: 0.688305453225678
Epoch: 43 | Iteration number: [520/4518] 11% | Training loss: 0.688281542979754
Epoch: 43 | Iteration number: [530/4518] 11% | Training loss: 0.6882495171618912
Epoch: 43 | Iteration number: [540/4518] 11% | Training loss: 0.6882347265879313
Epoch: 43 | Iteration number: [550/4518] 12% | Training loss: 0.6882361700318076
Epoch: 43 | Iteration number: [560/4518] 12% | Training loss: 0.6882180594972201
Epoch: 43 | Iteration number: [570/4518] 12% | Training loss: 0.6882010671130397
Epoch: 43 | Iteration number: [580/4518] 12% | Training loss: 0.6881832677742531
Epoch: 43 | Iteration number: [590/4518] 13% | Training loss: 0.6881602193339397
Epoch: 43 | Iteration number: [600/4518] 13% | Training loss: 0.6881405810515085
Epoch: 43 | Iteration number: [610/4518] 13% | Training loss: 0.6881198619232803
Epoch: 43 | Iteration number: [620/4518] 13% | Training loss: 0.688110914057301
Epoch: 43 | Iteration number: [630/4518] 13% | Training loss: 0.6880983985605694
Epoch: 43 | Iteration number: [640/4518] 14% | Training loss: 0.688066346757114
Epoch: 43 | Iteration number: [650/4518] 14% | Training loss: 0.6880482758925511
Epoch: 43 | Iteration number: [660/4518] 14% | Training loss: 0.6880154889641386
Epoch: 43 | Iteration number: [670/4518] 14% | Training loss: 0.688019323882772
Epoch: 43 | Iteration number: [680/4518] 15% | Training loss: 0.6880054687752443
Epoch: 43 | Iteration number: [690/4518] 15% | Training loss: 0.6879808633223824
Epoch: 43 | Iteration number: [700/4518] 15% | Training loss: 0.687955515554973
Epoch: 43 | Iteration number: [710/4518] 15% | Training loss: 0.6879509151821405
Epoch: 43 | Iteration number: [720/4518] 15% | Training loss: 0.6879372998244233
Epoch: 43 | Iteration number: [730/4518] 16% | Training loss: 0.6879351108041528
Epoch: 43 | Iteration number: [740/4518] 16% | Training loss: 0.6879277687620472
Epoch: 43 | Iteration number: [750/4518] 16% | Training loss: 0.6879274350007375
Epoch: 43 | Iteration number: [760/4518] 16% | Training loss: 0.6879154661768361
Epoch: 43 | Iteration number: [770/4518] 17% | Training loss: 0.6879023764040563
Epoch: 43 | Iteration number: [780/4518] 17% | Training loss: 0.6879003592026539
Epoch: 43 | Iteration number: [790/4518] 17% | Training loss: 0.6878748614576798
Epoch: 43 | Iteration number: [800/4518] 17% | Training loss: 0.6878648675978184
Epoch: 43 | Iteration number: [810/4518] 17% | Training loss: 0.6878616651635111
Epoch: 43 | Iteration number: [820/4518] 18% | Training loss: 0.687854528427124
Epoch: 43 | Iteration number: [830/4518] 18% | Training loss: 0.6878319518393781
Epoch: 43 | Iteration number: [840/4518] 18% | Training loss: 0.6878271534329369
Epoch: 43 | Iteration number: [850/4518] 18% | Training loss: 0.6878037990542019
Epoch: 43 | Iteration number: [860/4518] 19% | Training loss: 0.6877792355626129
Epoch: 43 | Iteration number: [870/4518] 19% | Training loss: 0.6877738912900289
Epoch: 43 | Iteration number: [880/4518] 19% | Training loss: 0.6877523975616152
Epoch: 43 | Iteration number: [890/4518] 19% | Training loss: 0.6877416139238336
Epoch: 43 | Iteration number: [900/4518] 19% | Training loss: 0.6877379310131073
Epoch: 43 | Iteration number: [910/4518] 20% | Training loss: 0.6877414240941897
Epoch: 43 | Iteration number: [920/4518] 20% | Training loss: 0.6877344798782598
Epoch: 43 | Iteration number: [930/4518] 20% | Training loss: 0.6877322623165705
Epoch: 43 | Iteration number: [940/4518] 20% | Training loss: 0.6877300779236124
Epoch: 43 | Iteration number: [950/4518] 21% | Training loss: 0.6877202119952754
Epoch: 43 | Iteration number: [960/4518] 21% | Training loss: 0.6877081918219725
Epoch: 43 | Iteration number: [970/4518] 21% | Training loss: 0.6876917327187725
Epoch: 43 | Iteration number: [980/4518] 21% | Training loss: 0.6876795942686043
Epoch: 43 | Iteration number: [990/4518] 21% | Training loss: 0.687685330829235
Epoch: 43 | Iteration number: [1000/4518] 22% | Training loss: 0.6876740877628327
Epoch: 43 | Iteration number: [1010/4518] 22% | Training loss: 0.6876707953981834
Epoch: 43 | Iteration number: [1020/4518] 22% | Training loss: 0.687648874930307
Epoch: 43 | Iteration number: [1030/4518] 22% | Training loss: 0.6876412289813885
Epoch: 43 | Iteration number: [1040/4518] 23% | Training loss: 0.6876134573840178
Epoch: 43 | Iteration number: [1050/4518] 23% | Training loss: 0.6876185876982552
Epoch: 43 | Iteration number: [1060/4518] 23% | Training loss: 0.6876128280500196
Epoch: 43 | Iteration number: [1070/4518] 23% | Training loss: 0.6876069904487824
Epoch: 43 | Iteration number: [1080/4518] 23% | Training loss: 0.687592964205477
Epoch: 43 | Iteration number: [1090/4518] 24% | Training loss: 0.6875831057172302
Epoch: 43 | Iteration number: [1100/4518] 24% | Training loss: 0.6875663795254447
Epoch: 43 | Iteration number: [1110/4518] 24% | Training loss: 0.687552119429047
Epoch: 43 | Iteration number: [1120/4518] 24% | Training loss: 0.6875509373311486
Epoch: 43 | Iteration number: [1130/4518] 25% | Training loss: 0.6875327946865453
Epoch: 43 | Iteration number: [1140/4518] 25% | Training loss: 0.6875288033171704
Epoch: 43 | Iteration number: [1150/4518] 25% | Training loss: 0.6875134744851485
Epoch: 43 | Iteration number: [1160/4518] 25% | Training loss: 0.6875013565708851
Epoch: 43 | Iteration number: [1170/4518] 25% | Training loss: 0.6874930139280792
Epoch: 43 | Iteration number: [1180/4518] 26% | Training loss: 0.6874902959092188
Epoch: 43 | Iteration number: [1190/4518] 26% | Training loss: 0.6874846197476908
Epoch: 43 | Iteration number: [1200/4518] 26% | Training loss: 0.6874800199270248
Epoch: 43 | Iteration number: [1210/4518] 26% | Training loss: 0.6874850337662972
Epoch: 43 | Iteration number: [1220/4518] 27% | Training loss: 0.6874743824122382
Epoch: 43 | Iteration number: [1230/4518] 27% | Training loss: 0.6874675459008875
Epoch: 43 | Iteration number: [1240/4518] 27% | Training loss: 0.6874614521861077
Epoch: 43 | Iteration number: [1250/4518] 27% | Training loss: 0.687460387802124
Epoch: 43 | Iteration number: [1260/4518] 27% | Training loss: 0.6874357506396278
Epoch: 43 | Iteration number: [1270/4518] 28% | Training loss: 0.6874342689363975
Epoch: 43 | Iteration number: [1280/4518] 28% | Training loss: 0.6874311889056116
Epoch: 43 | Iteration number: [1290/4518] 28% | Training loss: 0.6874212547328121
Epoch: 43 | Iteration number: [1300/4518] 28% | Training loss: 0.687419587465433
Epoch: 43 | Iteration number: [1310/4518] 28% | Training loss: 0.6874130441032293
Epoch: 43 | Iteration number: [1320/4518] 29% | Training loss: 0.6874081186272881
Epoch: 43 | Iteration number: [1330/4518] 29% | Training loss: 0.6874031049864633
Epoch: 43 | Iteration number: [1340/4518] 29% | Training loss: 0.6873965149495139
Epoch: 43 | Iteration number: [1350/4518] 29% | Training loss: 0.6873964157810918
Epoch: 43 | Iteration number: [1360/4518] 30% | Training loss: 0.6873900347772767
Epoch: 43 | Iteration number: [1370/4518] 30% | Training loss: 0.6873902918213476
Epoch: 43 | Iteration number: [1380/4518] 30% | Training loss: 0.6873803968446842
Epoch: 43 | Iteration number: [1390/4518] 30% | Training loss: 0.6873819960107048
Epoch: 43 | Iteration number: [1400/4518] 30% | Training loss: 0.6873834746650287
Epoch: 43 | Iteration number: [1410/4518] 31% | Training loss: 0.6873889627186119
Epoch: 43 | Iteration number: [1420/4518] 31% | Training loss: 0.6873803158461208
Epoch: 43 | Iteration number: [1430/4518] 31% | Training loss: 0.6873733915232279
Epoch: 43 | Iteration number: [1440/4518] 31% | Training loss: 0.6873751812097099
Epoch: 43 | Iteration number: [1450/4518] 32% | Training loss: 0.6873675900903241
Epoch: 43 | Iteration number: [1460/4518] 32% | Training loss: 0.6873598794822824
Epoch: 43 | Iteration number: [1470/4518] 32% | Training loss: 0.6873553028317536
Epoch: 43 | Iteration number: [1480/4518] 32% | Training loss: 0.6873498986701707
Epoch: 43 | Iteration number: [1490/4518] 32% | Training loss: 0.6873508674186348
Epoch: 43 | Iteration number: [1500/4518] 33% | Training loss: 0.6873504780530929
Epoch: 43 | Iteration number: [1510/4518] 33% | Training loss: 0.6873406801397437
Epoch: 43 | Iteration number: [1520/4518] 33% | Training loss: 0.6873402685319122
Epoch: 43 | Iteration number: [1530/4518] 33% | Training loss: 0.6873291819703345
Epoch: 43 | Iteration number: [1540/4518] 34% | Training loss: 0.6873222754373178
Epoch: 43 | Iteration number: [1550/4518] 34% | Training loss: 0.687318401528943
Epoch: 43 | Iteration number: [1560/4518] 34% | Training loss: 0.6873205317900731
Epoch: 43 | Iteration number: [1570/4518] 34% | Training loss: 0.6873149236296393
Epoch: 43 | Iteration number: [1580/4518] 34% | Training loss: 0.6873129980096334
Epoch: 43 | Iteration number: [1590/4518] 35% | Training loss: 0.6873122731469712
Epoch: 43 | Iteration number: [1600/4518] 35% | Training loss: 0.6873093124106526
Epoch: 43 | Iteration number: [1610/4518] 35% | Training loss: 0.6873068707700102
Epoch: 43 | Iteration number: [1620/4518] 35% | Training loss: 0.6872995727224115
Epoch: 43 | Iteration number: [1630/4518] 36% | Training loss: 0.6872917684674994
Epoch: 43 | Iteration number: [1640/4518] 36% | Training loss: 0.6872958035730734
Epoch: 43 | Iteration number: [1650/4518] 36% | Training loss: 0.6872905378991907
Epoch: 43 | Iteration number: [1660/4518] 36% | Training loss: 0.6872889878520047
Epoch: 43 | Iteration number: [1670/4518] 36% | Training loss: 0.687282272941338
Epoch: 43 | Iteration number: [1680/4518] 37% | Training loss: 0.6872799153838839
Epoch: 43 | Iteration number: [1690/4518] 37% | Training loss: 0.6872838716887864
Epoch: 43 | Iteration number: [1700/4518] 37% | Training loss: 0.6872790663733201
Epoch: 43 | Iteration number: [1710/4518] 37% | Training loss: 0.6872733820251554
Epoch: 43 | Iteration number: [1720/4518] 38% | Training loss: 0.6872700882859009
Epoch: 43 | Iteration number: [1730/4518] 38% | Training loss: 0.6872700189234894
Epoch: 43 | Iteration number: [1740/4518] 38% | Training loss: 0.6872585432625365
Epoch: 43 | Iteration number: [1750/4518] 38% | Training loss: 0.6872476064818246
Epoch: 43 | Iteration number: [1760/4518] 38% | Training loss: 0.6872410128739748
Epoch: 43 | Iteration number: [1770/4518] 39% | Training loss: 0.6872442528352899
Epoch: 43 | Iteration number: [1780/4518] 39% | Training loss: 0.6872364369670997
Epoch: 43 | Iteration number: [1790/4518] 39% | Training loss: 0.6872321206431149
Epoch: 43 | Iteration number: [1800/4518] 39% | Training loss: 0.6872284665372637
Epoch: 43 | Iteration number: [1810/4518] 40% | Training loss: 0.6872290622134235
Epoch: 43 | Iteration number: [1820/4518] 40% | Training loss: 0.6872226701987969
Epoch: 43 | Iteration number: [1830/4518] 40% | Training loss: 0.687214525280103
Epoch: 43 | Iteration number: [1840/4518] 40% | Training loss: 0.6872188518228738
Epoch: 43 | Iteration number: [1850/4518] 40% | Training loss: 0.6872193103545421
Epoch: 43 | Iteration number: [1860/4518] 41% | Training loss: 0.6872163497312095
Epoch: 43 | Iteration number: [1870/4518] 41% | Training loss: 0.6872127506503447
Epoch: 43 | Iteration number: [1880/4518] 41% | Training loss: 0.6872061900953029
Epoch: 43 | Iteration number: [1890/4518] 41% | Training loss: 0.6872104109595062
Epoch: 43 | Iteration number: [1900/4518] 42% | Training loss: 0.6872046781527369
Epoch: 43 | Iteration number: [1910/4518] 42% | Training loss: 0.6872042146964847
Epoch: 43 | Iteration number: [1920/4518] 42% | Training loss: 0.6871994830357532
Epoch: 43 | Iteration number: [1930/4518] 42% | Training loss: 0.687199323381167
Epoch: 43 | Iteration number: [1940/4518] 42% | Training loss: 0.6871970596387215
Epoch: 43 | Iteration number: [1950/4518] 43% | Training loss: 0.6871961572537055
Epoch: 43 | Iteration number: [1960/4518] 43% | Training loss: 0.687192515907239
Epoch: 43 | Iteration number: [1970/4518] 43% | Training loss: 0.6871935845329071
Epoch: 43 | Iteration number: [1980/4518] 43% | Training loss: 0.6871893637409114
Epoch: 43 | Iteration number: [1990/4518] 44% | Training loss: 0.6871811488465448
Epoch: 43 | Iteration number: [2000/4518] 44% | Training loss: 0.687182093590498
Epoch: 43 | Iteration number: [2010/4518] 44% | Training loss: 0.6871839852475409
Epoch: 43 | Iteration number: [2020/4518] 44% | Training loss: 0.6871837193718051
Epoch: 43 | Iteration number: [2030/4518] 44% | Training loss: 0.6871793117429236
Epoch: 43 | Iteration number: [2040/4518] 45% | Training loss: 0.6871775630642386
Epoch: 43 | Iteration number: [2050/4518] 45% | Training loss: 0.6871716328074292
Epoch: 43 | Iteration number: [2060/4518] 45% | Training loss: 0.6871699268378101
Epoch: 43 | Iteration number: [2070/4518] 45% | Training loss: 0.687163136690711
Epoch: 43 | Iteration number: [2080/4518] 46% | Training loss: 0.6871643864478056
Epoch: 43 | Iteration number: [2090/4518] 46% | Training loss: 0.6871625021884316
Epoch: 43 | Iteration number: [2100/4518] 46% | Training loss: 0.6871642593258903
Epoch: 43 | Iteration number: [2110/4518] 46% | Training loss: 0.6871634568930802
Epoch: 43 | Iteration number: [2120/4518] 46% | Training loss: 0.6871614089833116
Epoch: 43 | Iteration number: [2130/4518] 47% | Training loss: 0.6871633315590066
Epoch: 43 | Iteration number: [2140/4518] 47% | Training loss: 0.6871620946398406
Epoch: 43 | Iteration number: [2150/4518] 47% | Training loss: 0.6871564402413922
Epoch: 43 | Iteration number: [2160/4518] 47% | Training loss: 0.687155654364162
Epoch: 43 | Iteration number: [2170/4518] 48% | Training loss: 0.6871602474544455
Epoch: 43 | Iteration number: [2180/4518] 48% | Training loss: 0.6871574362483593
Epoch: 43 | Iteration number: [2190/4518] 48% | Training loss: 0.6871557759367712
Epoch: 43 | Iteration number: [2200/4518] 48% | Training loss: 0.6871541736884551
Epoch: 43 | Iteration number: [2210/4518] 48% | Training loss: 0.6871455198769116
Epoch: 43 | Iteration number: [2220/4518] 49% | Training loss: 0.6871420631806056
Epoch: 43 | Iteration number: [2230/4518] 49% | Training loss: 0.6871393468615186
Epoch: 43 | Iteration number: [2240/4518] 49% | Training loss: 0.6871338099507349
Epoch: 43 | Iteration number: [2250/4518] 49% | Training loss: 0.687132287952635
Epoch: 43 | Iteration number: [2260/4518] 50% | Training loss: 0.6871343390076561
Epoch: 43 | Iteration number: [2270/4518] 50% | Training loss: 0.6871287580103601
Epoch: 43 | Iteration number: [2280/4518] 50% | Training loss: 0.687123164011721
Epoch: 43 | Iteration number: [2290/4518] 50% | Training loss: 0.687126201156966
Epoch: 43 | Iteration number: [2300/4518] 50% | Training loss: 0.6871209098204323
Epoch: 43 | Iteration number: [2310/4518] 51% | Training loss: 0.6871145291761919
Epoch: 43 | Iteration number: [2320/4518] 51% | Training loss: 0.6871114835913839
Epoch: 43 | Iteration number: [2330/4518] 51% | Training loss: 0.6871095393092848
Epoch: 43 | Iteration number: [2340/4518] 51% | Training loss: 0.687117486478936
Epoch: 43 | Iteration number: [2350/4518] 52% | Training loss: 0.6871191180005987
Epoch: 43 | Iteration number: [2360/4518] 52% | Training loss: 0.6871195578221547
Epoch: 43 | Iteration number: [2370/4518] 52% | Training loss: 0.6871141347704054
Epoch: 43 | Iteration number: [2380/4518] 52% | Training loss: 0.687116221745475
Epoch: 43 | Iteration number: [2390/4518] 52% | Training loss: 0.6871171249754758
Epoch: 43 | Iteration number: [2400/4518] 53% | Training loss: 0.6871136754751206
Epoch: 43 | Iteration number: [2410/4518] 53% | Training loss: 0.6871079500780066
Epoch: 43 | Iteration number: [2420/4518] 53% | Training loss: 0.6871043040486406
Epoch: 43 | Iteration number: [2430/4518] 53% | Training loss: 0.6871000691205876
Epoch: 43 | Iteration number: [2440/4518] 54% | Training loss: 0.6870979457849362
Epoch: 43 | Iteration number: [2450/4518] 54% | Training loss: 0.6870935904249853
Epoch: 43 | Iteration number: [2460/4518] 54% | Training loss: 0.6870989815975592
Epoch: 43 | Iteration number: [2470/4518] 54% | Training loss: 0.6870989353550591
Epoch: 43 | Iteration number: [2480/4518] 54% | Training loss: 0.6870983737611002
Epoch: 43 | Iteration number: [2490/4518] 55% | Training loss: 0.6870931881259245
Epoch: 43 | Iteration number: [2500/4518] 55% | Training loss: 0.687086698937416
Epoch: 43 | Iteration number: [2510/4518] 55% | Training loss: 0.6870893279394781
Epoch: 43 | Iteration number: [2520/4518] 55% | Training loss: 0.6870882008047331
Epoch: 43 | Iteration number: [2530/4518] 55% | Training loss: 0.6870892488909333
Epoch: 43 | Iteration number: [2540/4518] 56% | Training loss: 0.6870910180600609
Epoch: 43 | Iteration number: [2550/4518] 56% | Training loss: 0.6870918895450293
Epoch: 43 | Iteration number: [2560/4518] 56% | Training loss: 0.687088139471598
Epoch: 43 | Iteration number: [2570/4518] 56% | Training loss: 0.6870857580858446
Epoch: 43 | Iteration number: [2580/4518] 57% | Training loss: 0.6870831400156021
Epoch: 43 | Iteration number: [2590/4518] 57% | Training loss: 0.6870787936057824
Epoch: 43 | Iteration number: [2600/4518] 57% | Training loss: 0.6870785124026813
Epoch: 43 | Iteration number: [2610/4518] 57% | Training loss: 0.6870806946379928
Epoch: 43 | Iteration number: [2620/4518] 57% | Training loss: 0.6870777475469895
Epoch: 43 | Iteration number: [2630/4518] 58% | Training loss: 0.687073147138262
Epoch: 43 | Iteration number: [2640/4518] 58% | Training loss: 0.687077200706258
Epoch: 43 | Iteration number: [2650/4518] 58% | Training loss: 0.6870745880873698
Epoch: 43 | Iteration number: [2660/4518] 58% | Training loss: 0.6870813633714403
Epoch: 43 | Iteration number: [2670/4518] 59% | Training loss: 0.6870818916554755
Epoch: 43 | Iteration number: [2680/4518] 59% | Training loss: 0.687081689598845
Epoch: 43 | Iteration number: [2690/4518] 59% | Training loss: 0.6870808519395311
Epoch: 43 | Iteration number: [2700/4518] 59% | Training loss: 0.687076310382949
Epoch: 43 | Iteration number: [2710/4518] 59% | Training loss: 0.6870795118412848
Epoch: 43 | Iteration number: [2720/4518] 60% | Training loss: 0.6870781121885076
Epoch: 43 | Iteration number: [2730/4518] 60% | Training loss: 0.6870718526752877
Epoch: 43 | Iteration number: [2740/4518] 60% | Training loss: 0.6870727609108834
Epoch: 43 | Iteration number: [2750/4518] 60% | Training loss: 0.6870801307071339
Epoch: 43 | Iteration number: [2760/4518] 61% | Training loss: 0.6870813647905986
Epoch: 43 | Iteration number: [2770/4518] 61% | Training loss: 0.6870842846076841
Epoch: 43 | Iteration number: [2780/4518] 61% | Training loss: 0.6870839792404243
Epoch: 43 | Iteration number: [2790/4518] 61% | Training loss: 0.6870749809835974
Epoch: 43 | Iteration number: [2800/4518] 61% | Training loss: 0.6870732974580356
Epoch: 43 | Iteration number: [2810/4518] 62% | Training loss: 0.6870735340695364
Epoch: 43 | Iteration number: [2820/4518] 62% | Training loss: 0.6870726834586326
Epoch: 43 | Iteration number: [2830/4518] 62% | Training loss: 0.687072157291136
Epoch: 43 | Iteration number: [2840/4518] 62% | Training loss: 0.6870668740339683
Epoch: 43 | Iteration number: [2850/4518] 63% | Training loss: 0.6870635061724144
Epoch: 43 | Iteration number: [2860/4518] 63% | Training loss: 0.6870627514549069
Epoch: 43 | Iteration number: [2870/4518] 63% | Training loss: 0.6870640577131862
Epoch: 43 | Iteration number: [2880/4518] 63% | Training loss: 0.6870625643473532
Epoch: 43 | Iteration number: [2890/4518] 63% | Training loss: 0.6870595534573789
Epoch: 43 | Iteration number: [2900/4518] 64% | Training loss: 0.6870612321023283
Epoch: 43 | Iteration number: [2910/4518] 64% | Training loss: 0.6870600222517125
Epoch: 43 | Iteration number: [2920/4518] 64% | Training loss: 0.6870603426066163
Epoch: 43 | Iteration number: [2930/4518] 64% | Training loss: 0.687063756005349
Epoch: 43 | Iteration number: [2940/4518] 65% | Training loss: 0.6870623363726804
Epoch: 43 | Iteration number: [2950/4518] 65% | Training loss: 0.6870601103871555
Epoch: 43 | Iteration number: [2960/4518] 65% | Training loss: 0.6870602194521879
Epoch: 43 | Iteration number: [2970/4518] 65% | Training loss: 0.6870573282241821
Epoch: 43 | Iteration number: [2980/4518] 65% | Training loss: 0.6870509112641315
Epoch: 43 | Iteration number: [2990/4518] 66% | Training loss: 0.6870505909058562
Epoch: 43 | Iteration number: [3000/4518] 66% | Training loss: 0.6870534616311391
Epoch: 43 | Iteration number: [3010/4518] 66% | Training loss: 0.6870520384010682
Epoch: 43 | Iteration number: [3020/4518] 66% | Training loss: 0.6870498372624252
Epoch: 43 | Iteration number: [3030/4518] 67% | Training loss: 0.6870485487157362
Epoch: 43 | Iteration number: [3040/4518] 67% | Training loss: 0.6870489062251229
Epoch: 43 | Iteration number: [3050/4518] 67% | Training loss: 0.6870495481764683
Epoch: 43 | Iteration number: [3060/4518] 67% | Training loss: 0.6870465955703087
Epoch: 43 | Iteration number: [3070/4518] 67% | Training loss: 0.687044165945985
Epoch: 43 | Iteration number: [3080/4518] 68% | Training loss: 0.6870437444804551
Epoch: 43 | Iteration number: [3090/4518] 68% | Training loss: 0.6870418807835255
Epoch: 43 | Iteration number: [3100/4518] 68% | Training loss: 0.6870436676663737
Epoch: 43 | Iteration number: [3110/4518] 68% | Training loss: 0.6870455073965324
Epoch: 43 | Iteration number: [3120/4518] 69% | Training loss: 0.687047051714781
Epoch: 43 | Iteration number: [3130/4518] 69% | Training loss: 0.6870433881640815
Epoch: 43 | Iteration number: [3140/4518] 69% | Training loss: 0.687042562502205
Epoch: 43 | Iteration number: [3150/4518] 69% | Training loss: 0.6870450578038655
Epoch: 43 | Iteration number: [3160/4518] 69% | Training loss: 0.6870423906966101
Epoch: 43 | Iteration number: [3170/4518] 70% | Training loss: 0.6870437626018885
Epoch: 43 | Iteration number: [3180/4518] 70% | Training loss: 0.687046321026934
Epoch: 43 | Iteration number: [3190/4518] 70% | Training loss: 0.687047051299702
Epoch: 43 | Iteration number: [3200/4518] 70% | Training loss: 0.6870441768318415
Epoch: 43 | Iteration number: [3210/4518] 71% | Training loss: 0.6870443903768545
Epoch: 43 | Iteration number: [3220/4518] 71% | Training loss: 0.6870462565873721
Epoch: 43 | Iteration number: [3230/4518] 71% | Training loss: 0.687050567064492
Epoch: 43 | Iteration number: [3240/4518] 71% | Training loss: 0.6870540158064277
Epoch: 43 | Iteration number: [3250/4518] 71% | Training loss: 0.6870571246330555
Epoch: 43 | Iteration number: [3260/4518] 72% | Training loss: 0.6870562823455026
Epoch: 43 | Iteration number: [3270/4518] 72% | Training loss: 0.6870541807343836
Epoch: 43 | Iteration number: [3280/4518] 72% | Training loss: 0.6870499428089072
Epoch: 43 | Iteration number: [3290/4518] 72% | Training loss: 0.6870479745343101
Epoch: 43 | Iteration number: [3300/4518] 73% | Training loss: 0.6870442993351907
Epoch: 43 | Iteration number: [3310/4518] 73% | Training loss: 0.687040063801849
Epoch: 43 | Iteration number: [3320/4518] 73% | Training loss: 0.6870400320693671
Epoch: 43 | Iteration number: [3330/4518] 73% | Training loss: 0.6870382012010695
Epoch: 43 | Iteration number: [3340/4518] 73% | Training loss: 0.6870385417324341
Epoch: 43 | Iteration number: [3350/4518] 74% | Training loss: 0.6870383517066044
Epoch: 43 | Iteration number: [3360/4518] 74% | Training loss: 0.6870362467531647
Epoch: 43 | Iteration number: [3370/4518] 74% | Training loss: 0.6870389611324854
Epoch: 43 | Iteration number: [3380/4518] 74% | Training loss: 0.687038959201271
Epoch: 43 | Iteration number: [3390/4518] 75% | Training loss: 0.6870402760386115
Epoch: 43 | Iteration number: [3400/4518] 75% | Training loss: 0.687039733441437
Epoch: 43 | Iteration number: [3410/4518] 75% | Training loss: 0.687039874900471
Epoch: 43 | Iteration number: [3420/4518] 75% | Training loss: 0.6870406512454239
Epoch: 43 | Iteration number: [3430/4518] 75% | Training loss: 0.6870380941181071
Epoch: 43 | Iteration number: [3440/4518] 76% | Training loss: 0.6870336928166623
Epoch: 43 | Iteration number: [3450/4518] 76% | Training loss: 0.68703231084174
Epoch: 43 | Iteration number: [3460/4518] 76% | Training loss: 0.6870314306261912
Epoch: 43 | Iteration number: [3470/4518] 76% | Training loss: 0.687029448812908
Epoch: 43 | Iteration number: [3480/4518] 77% | Training loss: 0.6870309625548878
Epoch: 43 | Iteration number: [3490/4518] 77% | Training loss: 0.6870322807299715
Epoch: 43 | Iteration number: [3500/4518] 77% | Training loss: 0.6870363574028016
Epoch: 43 | Iteration number: [3510/4518] 77% | Training loss: 0.6870369831551174
Epoch: 43 | Iteration number: [3520/4518] 77% | Training loss: 0.6870370815423402
Epoch: 43 | Iteration number: [3530/4518] 78% | Training loss: 0.6870353468247918
Epoch: 43 | Iteration number: [3540/4518] 78% | Training loss: 0.6870350694925772
Epoch: 43 | Iteration number: [3550/4518] 78% | Training loss: 0.6870349186407009
Epoch: 43 | Iteration number: [3560/4518] 78% | Training loss: 0.6870330649982678
Epoch: 43 | Iteration number: [3570/4518] 79% | Training loss: 0.6870295827128307
Epoch: 43 | Iteration number: [3580/4518] 79% | Training loss: 0.6870281005538376
Epoch: 43 | Iteration number: [3590/4518] 79% | Training loss: 0.6870302338952141
Epoch: 43 | Iteration number: [3600/4518] 79% | Training loss: 0.6870274715291129
Epoch: 43 | Iteration number: [3610/4518] 79% | Training loss: 0.6870289461104163
Epoch: 43 | Iteration number: [3620/4518] 80% | Training loss: 0.6870208438424116
Epoch: 43 | Iteration number: [3630/4518] 80% | Training loss: 0.6870210363352595
Epoch: 43 | Iteration number: [3640/4518] 80% | Training loss: 0.6870230490526
Epoch: 43 | Iteration number: [3650/4518] 80% | Training loss: 0.6870205717870634
Epoch: 43 | Iteration number: [3660/4518] 81% | Training loss: 0.6870211341016279
Epoch: 43 | Iteration number: [3670/4518] 81% | Training loss: 0.6870225014413734
Epoch: 43 | Iteration number: [3680/4518] 81% | Training loss: 0.6870247485521047
Epoch: 43 | Iteration number: [3690/4518] 81% | Training loss: 0.6870233539643327
Epoch: 43 | Iteration number: [3700/4518] 81% | Training loss: 0.6870221729697408
Epoch: 43 | Iteration number: [3710/4518] 82% | Training loss: 0.6870200246010186
Epoch: 43 | Iteration number: [3720/4518] 82% | Training loss: 0.6870191408421403
Epoch: 43 | Iteration number: [3730/4518] 82% | Training loss: 0.6870157226320885
Epoch: 43 | Iteration number: [3740/4518] 82% | Training loss: 0.6870160360706044
Epoch: 43 | Iteration number: [3750/4518] 83% | Training loss: 0.6870157325267792
Epoch: 43 | Iteration number: [3760/4518] 83% | Training loss: 0.6870145557408637
Epoch: 43 | Iteration number: [3770/4518] 83% | Training loss: 0.6870130420521653
Epoch: 43 | Iteration number: [3780/4518] 83% | Training loss: 0.6870107091293133
Epoch: 43 | Iteration number: [3790/4518] 83% | Training loss: 0.6870117116414777
Epoch: 43 | Iteration number: [3800/4518] 84% | Training loss: 0.6870102585930573
Epoch: 43 | Iteration number: [3810/4518] 84% | Training loss: 0.6870127868777498
Epoch: 43 | Iteration number: [3820/4518] 84% | Training loss: 0.6870130175539336
Epoch: 43 | Iteration number: [3830/4518] 84% | Training loss: 0.6870111467477236
Epoch: 43 | Iteration number: [3840/4518] 84% | Training loss: 0.6870108818790565
Epoch: 43 | Iteration number: [3850/4518] 85% | Training loss: 0.6870082813578766
Epoch: 43 | Iteration number: [3860/4518] 85% | Training loss: 0.6870071193869249
Epoch: 43 | Iteration number: [3870/4518] 85% | Training loss: 0.6870021598129618
Epoch: 43 | Iteration number: [3880/4518] 85% | Training loss: 0.687002895664923
Epoch: 43 | Iteration number: [3890/4518] 86% | Training loss: 0.6870009113706476
Epoch: 43 | Iteration number: [3900/4518] 86% | Training loss: 0.6870025233733348
Epoch: 43 | Iteration number: [3910/4518] 86% | Training loss: 0.6869997600612738
Epoch: 43 | Iteration number: [3920/4518] 86% | Training loss: 0.6869979616330595
Epoch: 43 | Iteration number: [3930/4518] 86% | Training loss: 0.686996022223213
Epoch: 43 | Iteration number: [3940/4518] 87% | Training loss: 0.6869949599207961
Epoch: 43 | Iteration number: [3950/4518] 87% | Training loss: 0.6869946170004109
Epoch: 43 | Iteration number: [3960/4518] 87% | Training loss: 0.6869962496137378
Epoch: 43 | Iteration number: [3970/4518] 87% | Training loss: 0.6869975256979916
Epoch: 43 | Iteration number: [3980/4518] 88% | Training loss: 0.6869990021289892
Epoch: 43 | Iteration number: [3990/4518] 88% | Training loss: 0.6869968741908109
Epoch: 43 | Iteration number: [4000/4518] 88% | Training loss: 0.6869930386543274
Epoch: 43 | Iteration number: [4010/4518] 88% | Training loss: 0.6869942714745861
Epoch: 43 | Iteration number: [4020/4518] 88% | Training loss: 0.6869944343964259
Epoch: 43 | Iteration number: [4030/4518] 89% | Training loss: 0.686993928745426
Epoch: 43 | Iteration number: [4040/4518] 89% | Training loss: 0.6869902302280511
Epoch: 43 | Iteration number: [4050/4518] 89% | Training loss: 0.6869917149602631
Epoch: 43 | Iteration number: [4060/4518] 89% | Training loss: 0.6869882410823418
Epoch: 43 | Iteration number: [4070/4518] 90% | Training loss: 0.6869885537343178
Epoch: 43 | Iteration number: [4080/4518] 90% | Training loss: 0.6869894502794042
Epoch: 43 | Iteration number: [4090/4518] 90% | Training loss: 0.6869870889157713
Epoch: 43 | Iteration number: [4100/4518] 90% | Training loss: 0.6869889010307265
Epoch: 43 | Iteration number: [4110/4518] 90% | Training loss: 0.686989099802472
Epoch: 43 | Iteration number: [4120/4518] 91% | Training loss: 0.6869870275114347
Epoch: 43 | Iteration number: [4130/4518] 91% | Training loss: 0.6869848638845125
Epoch: 43 | Iteration number: [4140/4518] 91% | Training loss: 0.6869849567971944
Epoch: 43 | Iteration number: [4150/4518] 91% | Training loss: 0.6869859798988665
Epoch: 43 | Iteration number: [4160/4518] 92% | Training loss: 0.6869865703754701
Epoch: 43 | Iteration number: [4170/4518] 92% | Training loss: 0.6869867321112745
Epoch: 43 | Iteration number: [4180/4518] 92% | Training loss: 0.6869887085622578
Epoch: 43 | Iteration number: [4190/4518] 92% | Training loss: 0.6869889408278863
Epoch: 43 | Iteration number: [4200/4518] 92% | Training loss: 0.6869888554016749
Epoch: 43 | Iteration number: [4210/4518] 93% | Training loss: 0.6869894434890385
Epoch: 43 | Iteration number: [4220/4518] 93% | Training loss: 0.686989584141433
Epoch: 43 | Iteration number: [4230/4518] 93% | Training loss: 0.6869878855861953
Epoch: 43 | Iteration number: [4240/4518] 93% | Training loss: 0.6869915932557493
Epoch: 43 | Iteration number: [4250/4518] 94% | Training loss: 0.6869920450519112
Epoch: 43 | Iteration number: [4260/4518] 94% | Training loss: 0.68698904343614
Epoch: 43 | Iteration number: [4270/4518] 94% | Training loss: 0.6869865456705071
Epoch: 43 | Iteration number: [4280/4518] 94% | Training loss: 0.6869849617932444
Epoch: 43 | Iteration number: [4290/4518] 94% | Training loss: 0.686982734053285
Epoch: 43 | Iteration number: [4300/4518] 95% | Training loss: 0.6869846204962842
Epoch: 43 | Iteration number: [4310/4518] 95% | Training loss: 0.6869804886543557
Epoch: 43 | Iteration number: [4320/4518] 95% | Training loss: 0.6869790986318279
Epoch: 43 | Iteration number: [4330/4518] 95% | Training loss: 0.6869755596128952
Epoch: 43 | Iteration number: [4340/4518] 96% | Training loss: 0.6869771675717447
Epoch: 43 | Iteration number: [4350/4518] 96% | Training loss: 0.6869761038785693
Epoch: 43 | Iteration number: [4360/4518] 96% | Training loss: 0.6869773544849606
Epoch: 43 | Iteration number: [4370/4518] 96% | Training loss: 0.6869793630300998
Epoch: 43 | Iteration number: [4380/4518] 96% | Training loss: 0.6869799601296857
Epoch: 43 | Iteration number: [4390/4518] 97% | Training loss: 0.6869774703555879
Epoch: 43 | Iteration number: [4400/4518] 97% | Training loss: 0.6869787409359759
Epoch: 43 | Iteration number: [4410/4518] 97% | Training loss: 0.6869774091946566
Epoch: 43 | Iteration number: [4420/4518] 97% | Training loss: 0.6869743511552724
Epoch: 43 | Iteration number: [4430/4518] 98% | Training loss: 0.6869756533787428
Epoch: 43 | Iteration number: [4440/4518] 98% | Training loss: 0.6869769544483305
Epoch: 43 | Iteration number: [4450/4518] 98% | Training loss: 0.6869771796130062
Epoch: 43 | Iteration number: [4460/4518] 98% | Training loss: 0.686977340394606
Epoch: 43 | Iteration number: [4470/4518] 98% | Training loss: 0.6869767082884274
Epoch: 43 | Iteration number: [4480/4518] 99% | Training loss: 0.6869751811426665
Epoch: 43 | Iteration number: [4490/4518] 99% | Training loss: 0.6869762992938536
Epoch: 43 | Iteration number: [4500/4518] 99% | Training loss: 0.6869749731090333
Epoch: 43 | Iteration number: [4510/4518] 99% | Training loss: 0.6869747340679169

 End of epoch: 43 | Train Loss: 0.6868216914115305 | Training Time: 641 

 End of epoch: 43 | Eval Loss: 0.6900239343545875 | Evaluating Time: 17 
Epoch: 44 | Iteration number: [10/4518] 0% | Training loss: 0.7552941620349884
Epoch: 44 | Iteration number: [20/4518] 0% | Training loss: 0.721280038356781
Epoch: 44 | Iteration number: [30/4518] 0% | Training loss: 0.7095608095328013
Epoch: 44 | Iteration number: [40/4518] 0% | Training loss: 0.7037908524274826
Epoch: 44 | Iteration number: [50/4518] 1% | Training loss: 0.7005380547046661
Epoch: 44 | Iteration number: [60/4518] 1% | Training loss: 0.6983120918273926
Epoch: 44 | Iteration number: [70/4518] 1% | Training loss: 0.6966587832995823
Epoch: 44 | Iteration number: [80/4518] 1% | Training loss: 0.6955365337431431
Epoch: 44 | Iteration number: [90/4518] 1% | Training loss: 0.6946308659182654
Epoch: 44 | Iteration number: [100/4518] 2% | Training loss: 0.6938107597827912
Epoch: 44 | Iteration number: [110/4518] 2% | Training loss: 0.6933168974789706
Epoch: 44 | Iteration number: [120/4518] 2% | Training loss: 0.692783169945081
Epoch: 44 | Iteration number: [130/4518] 2% | Training loss: 0.6923612557924711
Epoch: 44 | Iteration number: [140/4518] 3% | Training loss: 0.6919415993349892
Epoch: 44 | Iteration number: [150/4518] 3% | Training loss: 0.6915705148379008
Epoch: 44 | Iteration number: [160/4518] 3% | Training loss: 0.6913154989480972
Epoch: 44 | Iteration number: [170/4518] 3% | Training loss: 0.6910983737777261
Epoch: 44 | Iteration number: [180/4518] 3% | Training loss: 0.6908030420541763
Epoch: 44 | Iteration number: [190/4518] 4% | Training loss: 0.690605261137611
Epoch: 44 | Iteration number: [200/4518] 4% | Training loss: 0.6904202583432197
Epoch: 44 | Iteration number: [210/4518] 4% | Training loss: 0.6902717053890228
Epoch: 44 | Iteration number: [220/4518] 4% | Training loss: 0.6901359755884517
Epoch: 44 | Iteration number: [230/4518] 5% | Training loss: 0.6900274634361268
Epoch: 44 | Iteration number: [240/4518] 5% | Training loss: 0.6898346019287904
Epoch: 44 | Iteration number: [250/4518] 5% | Training loss: 0.6896759257316589
Epoch: 44 | Iteration number: [260/4518] 5% | Training loss: 0.6895529224322392
Epoch: 44 | Iteration number: [270/4518] 5% | Training loss: 0.6894543257024554
Epoch: 44 | Iteration number: [280/4518] 6% | Training loss: 0.6894082931535584
Epoch: 44 | Iteration number: [290/4518] 6% | Training loss: 0.6892722526500965
Epoch: 44 | Iteration number: [300/4518] 6% | Training loss: 0.6891731204589208
Epoch: 44 | Iteration number: [310/4518] 6% | Training loss: 0.6890551972773767
Epoch: 44 | Iteration number: [320/4518] 7% | Training loss: 0.6889703659340739
Epoch: 44 | Iteration number: [330/4518] 7% | Training loss: 0.6889212678779255
Epoch: 44 | Iteration number: [340/4518] 7% | Training loss: 0.6888698749682483
Epoch: 44 | Iteration number: [350/4518] 7% | Training loss: 0.6888035426821028
Epoch: 44 | Iteration number: [360/4518] 7% | Training loss: 0.6887779964341058
Epoch: 44 | Iteration number: [370/4518] 8% | Training loss: 0.6886898812409994
Epoch: 44 | Iteration number: [380/4518] 8% | Training loss: 0.6886272226509295
Epoch: 44 | Iteration number: [390/4518] 8% | Training loss: 0.6885942987906627
Epoch: 44 | Iteration number: [400/4518] 8% | Training loss: 0.6885470780730247
Epoch: 44 | Iteration number: [410/4518] 9% | Training loss: 0.6885053532879527
Epoch: 44 | Iteration number: [420/4518] 9% | Training loss: 0.6884589900573095
Epoch: 44 | Iteration number: [430/4518] 9% | Training loss: 0.6884215554525686
Epoch: 44 | Iteration number: [440/4518] 9% | Training loss: 0.6883517729965123
Epoch: 44 | Iteration number: [450/4518] 9% | Training loss: 0.6883335281742944
Epoch: 44 | Iteration number: [460/4518] 10% | Training loss: 0.6882911272670912
Epoch: 44 | Iteration number: [470/4518] 10% | Training loss: 0.688277430990909
Epoch: 44 | Iteration number: [480/4518] 10% | Training loss: 0.6882636020580928
Epoch: 44 | Iteration number: [490/4518] 10% | Training loss: 0.6882297648459065
Epoch: 44 | Iteration number: [500/4518] 11% | Training loss: 0.6882061988115311
Epoch: 44 | Iteration number: [510/4518] 11% | Training loss: 0.6881801635611291
Epoch: 44 | Iteration number: [520/4518] 11% | Training loss: 0.6881654558273462
Epoch: 44 | Iteration number: [530/4518] 11% | Training loss: 0.6881299377612348
Epoch: 44 | Iteration number: [540/4518] 11% | Training loss: 0.6880947724536614
Epoch: 44 | Iteration number: [550/4518] 12% | Training loss: 0.6881000191515142
Epoch: 44 | Iteration number: [560/4518] 12% | Training loss: 0.6880732254258224
Epoch: 44 | Iteration number: [570/4518] 12% | Training loss: 0.6880466482095551
Epoch: 44 | Iteration number: [580/4518] 12% | Training loss: 0.6880108954577611
Epoch: 44 | Iteration number: [590/4518] 13% | Training loss: 0.6880100702835341
Epoch: 44 | Iteration number: [600/4518] 13% | Training loss: 0.6879859508077304
Epoch: 44 | Iteration number: [610/4518] 13% | Training loss: 0.6879689821454346
Epoch: 44 | Iteration number: [620/4518] 13% | Training loss: 0.6879329607371361
Epoch: 44 | Iteration number: [630/4518] 13% | Training loss: 0.687907764457521
Epoch: 44 | Iteration number: [640/4518] 14% | Training loss: 0.6878821047022938
Epoch: 44 | Iteration number: [650/4518] 14% | Training loss: 0.687859691473154
Epoch: 44 | Iteration number: [660/4518] 14% | Training loss: 0.6878333267840472
Epoch: 44 | Iteration number: [670/4518] 14% | Training loss: 0.6878106846738218
Epoch: 44 | Iteration number: [680/4518] 15% | Training loss: 0.6877997248488315
Epoch: 44 | Iteration number: [690/4518] 15% | Training loss: 0.6877880048060763
Epoch: 44 | Iteration number: [700/4518] 15% | Training loss: 0.6877777175392423
Epoch: 44 | Iteration number: [710/4518] 15% | Training loss: 0.6877641161562691
Epoch: 44 | Iteration number: [720/4518] 15% | Training loss: 0.6877440800269444
Epoch: 44 | Iteration number: [730/4518] 16% | Training loss: 0.6877451470453445
Epoch: 44 | Iteration number: [740/4518] 16% | Training loss: 0.687732260211094
Epoch: 44 | Iteration number: [750/4518] 16% | Training loss: 0.6877163462638854
Epoch: 44 | Iteration number: [760/4518] 16% | Training loss: 0.6877172231674195
Epoch: 44 | Iteration number: [770/4518] 17% | Training loss: 0.6876948917840983
Epoch: 44 | Iteration number: [780/4518] 17% | Training loss: 0.6876847457427245
Epoch: 44 | Iteration number: [790/4518] 17% | Training loss: 0.687676184916798
Epoch: 44 | Iteration number: [800/4518] 17% | Training loss: 0.6876665546745062
Epoch: 44 | Iteration number: [810/4518] 17% | Training loss: 0.6876701385886581
Epoch: 44 | Iteration number: [820/4518] 18% | Training loss: 0.6876580308850219
Epoch: 44 | Iteration number: [830/4518] 18% | Training loss: 0.687664368856384
Epoch: 44 | Iteration number: [840/4518] 18% | Training loss: 0.6876450579081262
Epoch: 44 | Iteration number: [850/4518] 18% | Training loss: 0.6876433855645797
Epoch: 44 | Iteration number: [860/4518] 19% | Training loss: 0.6876287892807361
Epoch: 44 | Iteration number: [870/4518] 19% | Training loss: 0.6876163214102559
Epoch: 44 | Iteration number: [880/4518] 19% | Training loss: 0.6876121023161845
Epoch: 44 | Iteration number: [890/4518] 19% | Training loss: 0.6876133568501205
Epoch: 44 | Iteration number: [900/4518] 19% | Training loss: 0.6875993204779095
Epoch: 44 | Iteration number: [910/4518] 20% | Training loss: 0.6875941181575859
Epoch: 44 | Iteration number: [920/4518] 20% | Training loss: 0.6875843920137571
Epoch: 44 | Iteration number: [930/4518] 20% | Training loss: 0.6875770973902877
Epoch: 44 | Iteration number: [940/4518] 20% | Training loss: 0.6875683561918583
Epoch: 44 | Iteration number: [950/4518] 21% | Training loss: 0.6875621190824007
Epoch: 44 | Iteration number: [960/4518] 21% | Training loss: 0.6875599961106976
Epoch: 44 | Iteration number: [970/4518] 21% | Training loss: 0.6875547090756524
Epoch: 44 | Iteration number: [980/4518] 21% | Training loss: 0.6875430524957423
Epoch: 44 | Iteration number: [990/4518] 21% | Training loss: 0.6875357987302723
Epoch: 44 | Iteration number: [1000/4518] 22% | Training loss: 0.6875458778738975
Epoch: 44 | Iteration number: [1010/4518] 22% | Training loss: 0.6875430615821687
Epoch: 44 | Iteration number: [1020/4518] 22% | Training loss: 0.6875404630221572
Epoch: 44 | Iteration number: [1030/4518] 22% | Training loss: 0.6875279575875662
Epoch: 44 | Iteration number: [1040/4518] 23% | Training loss: 0.6875225501564833
Epoch: 44 | Iteration number: [1050/4518] 23% | Training loss: 0.6875170828614916
Epoch: 44 | Iteration number: [1060/4518] 23% | Training loss: 0.6874884448523791
Epoch: 44 | Iteration number: [1070/4518] 23% | Training loss: 0.6874859972534892
Epoch: 44 | Iteration number: [1080/4518] 23% | Training loss: 0.6874808240819861
Epoch: 44 | Iteration number: [1090/4518] 24% | Training loss: 0.6874772458448323
Epoch: 44 | Iteration number: [1100/4518] 24% | Training loss: 0.6874686672470787
Epoch: 44 | Iteration number: [1110/4518] 24% | Training loss: 0.6874630974756705
Epoch: 44 | Iteration number: [1120/4518] 24% | Training loss: 0.6874577171036176
Epoch: 44 | Iteration number: [1130/4518] 25% | Training loss: 0.68745680224579
Epoch: 44 | Iteration number: [1140/4518] 25% | Training loss: 0.6874565579912119
Epoch: 44 | Iteration number: [1150/4518] 25% | Training loss: 0.6874467528902966
Epoch: 44 | Iteration number: [1160/4518] 25% | Training loss: 0.6874446411584986
Epoch: 44 | Iteration number: [1170/4518] 25% | Training loss: 0.6874417265765688
Epoch: 44 | Iteration number: [1180/4518] 26% | Training loss: 0.6874293026782698
Epoch: 44 | Iteration number: [1190/4518] 26% | Training loss: 0.6874207895343043
Epoch: 44 | Iteration number: [1200/4518] 26% | Training loss: 0.6874126703540484
Epoch: 44 | Iteration number: [1210/4518] 26% | Training loss: 0.6874105560878092
Epoch: 44 | Iteration number: [1220/4518] 27% | Training loss: 0.6874104116783768
Epoch: 44 | Iteration number: [1230/4518] 27% | Training loss: 0.6874148394518751
Epoch: 44 | Iteration number: [1240/4518] 27% | Training loss: 0.6874109530641187
Epoch: 44 | Iteration number: [1250/4518] 27% | Training loss: 0.6874057106018067
Epoch: 44 | Iteration number: [1260/4518] 27% | Training loss: 0.687399278935932
Epoch: 44 | Iteration number: [1270/4518] 28% | Training loss: 0.6873830746947311
Epoch: 44 | Iteration number: [1280/4518] 28% | Training loss: 0.6873691166285425
Epoch: 44 | Iteration number: [1290/4518] 28% | Training loss: 0.6873731717120769
Epoch: 44 | Iteration number: [1300/4518] 28% | Training loss: 0.6873687528188412
Epoch: 44 | Iteration number: [1310/4518] 28% | Training loss: 0.687366462117843
Epoch: 44 | Iteration number: [1320/4518] 29% | Training loss: 0.687364134463397
Epoch: 44 | Iteration number: [1330/4518] 29% | Training loss: 0.6873569817471324
Epoch: 44 | Iteration number: [1340/4518] 29% | Training loss: 0.6873626160977492
Epoch: 44 | Iteration number: [1350/4518] 29% | Training loss: 0.6873617036695834
Epoch: 44 | Iteration number: [1360/4518] 30% | Training loss: 0.6873648940202068
Epoch: 44 | Iteration number: [1370/4518] 30% | Training loss: 0.6873704708405655
Epoch: 44 | Iteration number: [1380/4518] 30% | Training loss: 0.6873700108217157
Epoch: 44 | Iteration number: [1390/4518] 30% | Training loss: 0.6873710800417894
Epoch: 44 | Iteration number: [1400/4518] 30% | Training loss: 0.6873615041375161
Epoch: 44 | Iteration number: [1410/4518] 31% | Training loss: 0.6873524210977217
Epoch: 44 | Iteration number: [1420/4518] 31% | Training loss: 0.6873385835701311
Epoch: 44 | Iteration number: [1430/4518] 31% | Training loss: 0.6873403422065548
Epoch: 44 | Iteration number: [1440/4518] 31% | Training loss: 0.687351780757308
Epoch: 44 | Iteration number: [1450/4518] 32% | Training loss: 0.6873498875519325
Epoch: 44 | Iteration number: [1460/4518] 32% | Training loss: 0.6873518426940866
Epoch: 44 | Iteration number: [1470/4518] 32% | Training loss: 0.6873442528199176
Epoch: 44 | Iteration number: [1480/4518] 32% | Training loss: 0.6873413368656829
Epoch: 44 | Iteration number: [1490/4518] 32% | Training loss: 0.6873359067328024
Epoch: 44 | Iteration number: [1500/4518] 33% | Training loss: 0.6873383233149847
Epoch: 44 | Iteration number: [1510/4518] 33% | Training loss: 0.6873445748493371
Epoch: 44 | Iteration number: [1520/4518] 33% | Training loss: 0.6873457856084171
Epoch: 44 | Iteration number: [1530/4518] 33% | Training loss: 0.6873379982374852
Epoch: 44 | Iteration number: [1540/4518] 34% | Training loss: 0.6873383590153286
Epoch: 44 | Iteration number: [1550/4518] 34% | Training loss: 0.6873360855733195
Epoch: 44 | Iteration number: [1560/4518] 34% | Training loss: 0.6873411212594082
Epoch: 44 | Iteration number: [1570/4518] 34% | Training loss: 0.6873322765918294
Epoch: 44 | Iteration number: [1580/4518] 34% | Training loss: 0.6873307520830179
Epoch: 44 | Iteration number: [1590/4518] 35% | Training loss: 0.6873312176023639
Epoch: 44 | Iteration number: [1600/4518] 35% | Training loss: 0.6873164292052388
Epoch: 44 | Iteration number: [1610/4518] 35% | Training loss: 0.687318431886827
Epoch: 44 | Iteration number: [1620/4518] 35% | Training loss: 0.687317043285311
Epoch: 44 | Iteration number: [1630/4518] 36% | Training loss: 0.6873168712379011
Epoch: 44 | Iteration number: [1640/4518] 36% | Training loss: 0.6873141284396008
Epoch: 44 | Iteration number: [1650/4518] 36% | Training loss: 0.6873161574204762
Epoch: 44 | Iteration number: [1660/4518] 36% | Training loss: 0.6873074076261865
Epoch: 44 | Iteration number: [1670/4518] 36% | Training loss: 0.6873080783618425
Epoch: 44 | Iteration number: [1680/4518] 37% | Training loss: 0.6873051108703727
Epoch: 44 | Iteration number: [1690/4518] 37% | Training loss: 0.6873069628808626
Epoch: 44 | Iteration number: [1700/4518] 37% | Training loss: 0.6873108177325304
Epoch: 44 | Iteration number: [1710/4518] 37% | Training loss: 0.6873131028741424
Epoch: 44 | Iteration number: [1720/4518] 38% | Training loss: 0.6873149801825368
Epoch: 44 | Iteration number: [1730/4518] 38% | Training loss: 0.6873183595307301
Epoch: 44 | Iteration number: [1740/4518] 38% | Training loss: 0.6873180799443146
Epoch: 44 | Iteration number: [1750/4518] 38% | Training loss: 0.6873146541118622
Epoch: 44 | Iteration number: [1760/4518] 38% | Training loss: 0.6873135024851019
Epoch: 44 | Iteration number: [1770/4518] 39% | Training loss: 0.6873089804150964
Epoch: 44 | Iteration number: [1780/4518] 39% | Training loss: 0.6873058058907476
Epoch: 44 | Iteration number: [1790/4518] 39% | Training loss: 0.687303783973502
Epoch: 44 | Iteration number: [1800/4518] 39% | Training loss: 0.6872983752687772
Epoch: 44 | Iteration number: [1810/4518] 40% | Training loss: 0.6872942149309822
Epoch: 44 | Iteration number: [1820/4518] 40% | Training loss: 0.6872918150254659
Epoch: 44 | Iteration number: [1830/4518] 40% | Training loss: 0.6872946047717756
Epoch: 44 | Iteration number: [1840/4518] 40% | Training loss: 0.6872926534194014
Epoch: 44 | Iteration number: [1850/4518] 40% | Training loss: 0.6872883156505791
Epoch: 44 | Iteration number: [1860/4518] 41% | Training loss: 0.6872873281599373
Epoch: 44 | Iteration number: [1870/4518] 41% | Training loss: 0.6872853939864725
Epoch: 44 | Iteration number: [1880/4518] 41% | Training loss: 0.6872831661016383
Epoch: 44 | Iteration number: [1890/4518] 41% | Training loss: 0.6872779925664266
Epoch: 44 | Iteration number: [1900/4518] 42% | Training loss: 0.6872802106643978
Epoch: 44 | Iteration number: [1910/4518] 42% | Training loss: 0.6872827909691795
Epoch: 44 | Iteration number: [1920/4518] 42% | Training loss: 0.6872816616979738
Epoch: 44 | Iteration number: [1930/4518] 42% | Training loss: 0.6872844335946394
Epoch: 44 | Iteration number: [1940/4518] 42% | Training loss: 0.6872868224517586
Epoch: 44 | Iteration number: [1950/4518] 43% | Training loss: 0.6872870927896255
Epoch: 44 | Iteration number: [1960/4518] 43% | Training loss: 0.6872919956640321
Epoch: 44 | Iteration number: [1970/4518] 43% | Training loss: 0.6872823287690352
Epoch: 44 | Iteration number: [1980/4518] 43% | Training loss: 0.6872781622891474
Epoch: 44 | Iteration number: [1990/4518] 44% | Training loss: 0.6872707998632785
Epoch: 44 | Iteration number: [2000/4518] 44% | Training loss: 0.6872709471583366
Epoch: 44 | Iteration number: [2010/4518] 44% | Training loss: 0.6872693143080716
Epoch: 44 | Iteration number: [2020/4518] 44% | Training loss: 0.6872712734312114
Epoch: 44 | Iteration number: [2030/4518] 44% | Training loss: 0.687268985022465
Epoch: 44 | Iteration number: [2040/4518] 45% | Training loss: 0.6872640165920351
Epoch: 44 | Iteration number: [2050/4518] 45% | Training loss: 0.6872634910083398
Epoch: 44 | Iteration number: [2060/4518] 45% | Training loss: 0.6872625324332599
Epoch: 44 | Iteration number: [2070/4518] 45% | Training loss: 0.687259540523308
Epoch: 44 | Iteration number: [2080/4518] 46% | Training loss: 0.6872626083974654
Epoch: 44 | Iteration number: [2090/4518] 46% | Training loss: 0.6872555772368417
Epoch: 44 | Iteration number: [2100/4518] 46% | Training loss: 0.6872527623460406
Epoch: 44 | Iteration number: [2110/4518] 46% | Training loss: 0.6872565457323716
Epoch: 44 | Iteration number: [2120/4518] 46% | Training loss: 0.6872551006809721
Epoch: 44 | Iteration number: [2130/4518] 47% | Training loss: 0.6872504754805229
Epoch: 44 | Iteration number: [2140/4518] 47% | Training loss: 0.6872478065089644
Epoch: 44 | Iteration number: [2150/4518] 47% | Training loss: 0.6872422114638395
Epoch: 44 | Iteration number: [2160/4518] 47% | Training loss: 0.6872409399736811
Epoch: 44 | Iteration number: [2170/4518] 48% | Training loss: 0.6872361497120923
Epoch: 44 | Iteration number: [2180/4518] 48% | Training loss: 0.687230012941798
Epoch: 44 | Iteration number: [2190/4518] 48% | Training loss: 0.6872293171272975
Epoch: 44 | Iteration number: [2200/4518] 48% | Training loss: 0.687234291353009
Epoch: 44 | Iteration number: [2210/4518] 48% | Training loss: 0.6872280818304864
Epoch: 44 | Iteration number: [2220/4518] 49% | Training loss: 0.6872207275382033
Epoch: 44 | Iteration number: [2230/4518] 49% | Training loss: 0.6872133871365022
Epoch: 44 | Iteration number: [2240/4518] 49% | Training loss: 0.6872110927211387
Epoch: 44 | Iteration number: [2250/4518] 49% | Training loss: 0.6872054807874891
Epoch: 44 | Iteration number: [2260/4518] 50% | Training loss: 0.6871995173988089
Epoch: 44 | Iteration number: [2270/4518] 50% | Training loss: 0.6872018652602965
Epoch: 44 | Iteration number: [2280/4518] 50% | Training loss: 0.6872017517947314
Epoch: 44 | Iteration number: [2290/4518] 50% | Training loss: 0.6871977007284956
Epoch: 44 | Iteration number: [2300/4518] 50% | Training loss: 0.687197282521621
Epoch: 44 | Iteration number: [2310/4518] 51% | Training loss: 0.68719323623232
Epoch: 44 | Iteration number: [2320/4518] 51% | Training loss: 0.687192486277942
Epoch: 44 | Iteration number: [2330/4518] 51% | Training loss: 0.6871929077887228
Epoch: 44 | Iteration number: [2340/4518] 51% | Training loss: 0.6871916189407691
Epoch: 44 | Iteration number: [2350/4518] 52% | Training loss: 0.6871904786089633
Epoch: 44 | Iteration number: [2360/4518] 52% | Training loss: 0.687189460381613
Epoch: 44 | Iteration number: [2370/4518] 52% | Training loss: 0.6871919414162133
Epoch: 44 | Iteration number: [2380/4518] 52% | Training loss: 0.6871865419780507
Epoch: 44 | Iteration number: [2390/4518] 52% | Training loss: 0.6871798864218979
Epoch: 44 | Iteration number: [2400/4518] 53% | Training loss: 0.6871754202495018
Epoch: 44 | Iteration number: [2410/4518] 53% | Training loss: 0.6871720392179687
Epoch: 44 | Iteration number: [2420/4518] 53% | Training loss: 0.6871686373860383
Epoch: 44 | Iteration number: [2430/4518] 53% | Training loss: 0.6871653848224216
Epoch: 44 | Iteration number: [2440/4518] 54% | Training loss: 0.6871618964633004
Epoch: 44 | Iteration number: [2450/4518] 54% | Training loss: 0.687164443731308
Epoch: 44 | Iteration number: [2460/4518] 54% | Training loss: 0.6871623066382679
Epoch: 44 | Iteration number: [2470/4518] 54% | Training loss: 0.687162492342806
Epoch: 44 | Iteration number: [2480/4518] 54% | Training loss: 0.687162117371636
Epoch: 44 | Iteration number: [2490/4518] 55% | Training loss: 0.6871574706581223
Epoch: 44 | Iteration number: [2500/4518] 55% | Training loss: 0.6871606714725494
Epoch: 44 | Iteration number: [2510/4518] 55% | Training loss: 0.6871596730325327
Epoch: 44 | Iteration number: [2520/4518] 55% | Training loss: 0.6871661951381063
Epoch: 44 | Iteration number: [2530/4518] 55% | Training loss: 0.6871643680122059
Epoch: 44 | Iteration number: [2540/4518] 56% | Training loss: 0.6871675783254969
Epoch: 44 | Iteration number: [2550/4518] 56% | Training loss: 0.6871649279781417
Epoch: 44 | Iteration number: [2560/4518] 56% | Training loss: 0.6871588631300256
Epoch: 44 | Iteration number: [2570/4518] 56% | Training loss: 0.6871508925573371
Epoch: 44 | Iteration number: [2580/4518] 57% | Training loss: 0.6871482123931248
Epoch: 44 | Iteration number: [2590/4518] 57% | Training loss: 0.6871442861308462
Epoch: 44 | Iteration number: [2600/4518] 57% | Training loss: 0.6871440319143809
Epoch: 44 | Iteration number: [2610/4518] 57% | Training loss: 0.6871469506815475
Epoch: 44 | Iteration number: [2620/4518] 57% | Training loss: 0.6871439294278167
Epoch: 44 | Iteration number: [2630/4518] 58% | Training loss: 0.6871431481022345
Epoch: 44 | Iteration number: [2640/4518] 58% | Training loss: 0.6871404714656598
Epoch: 44 | Iteration number: [2650/4518] 58% | Training loss: 0.6871340737702711
Epoch: 44 | Iteration number: [2660/4518] 58% | Training loss: 0.6871314581399574
Epoch: 44 | Iteration number: [2670/4518] 59% | Training loss: 0.6871295060111342
Epoch: 44 | Iteration number: [2680/4518] 59% | Training loss: 0.6871313405125888
Epoch: 44 | Iteration number: [2690/4518] 59% | Training loss: 0.687127888246983
Epoch: 44 | Iteration number: [2700/4518] 59% | Training loss: 0.6871264193234621
Epoch: 44 | Iteration number: [2710/4518] 59% | Training loss: 0.6871268194100074
Epoch: 44 | Iteration number: [2720/4518] 60% | Training loss: 0.6871258363785112
Epoch: 44 | Iteration number: [2730/4518] 60% | Training loss: 0.6871258027387626
Epoch: 44 | Iteration number: [2740/4518] 60% | Training loss: 0.6871210691050021
Epoch: 44 | Iteration number: [2750/4518] 60% | Training loss: 0.6871244891123338
Epoch: 44 | Iteration number: [2760/4518] 61% | Training loss: 0.6871213771726774
Epoch: 44 | Iteration number: [2770/4518] 61% | Training loss: 0.6871232126378841
Epoch: 44 | Iteration number: [2780/4518] 61% | Training loss: 0.68712482263716
Epoch: 44 | Iteration number: [2790/4518] 61% | Training loss: 0.6871262650122352
Epoch: 44 | Iteration number: [2800/4518] 61% | Training loss: 0.687124827674457
Epoch: 44 | Iteration number: [2810/4518] 62% | Training loss: 0.6871216926922578
Epoch: 44 | Iteration number: [2820/4518] 62% | Training loss: 0.6871221777606518
Epoch: 44 | Iteration number: [2830/4518] 62% | Training loss: 0.6871238965027745
Epoch: 44 | Iteration number: [2840/4518] 62% | Training loss: 0.6871244062420349
Epoch: 44 | Iteration number: [2850/4518] 63% | Training loss: 0.6871244313842372
Epoch: 44 | Iteration number: [2860/4518] 63% | Training loss: 0.6871219835498116
Epoch: 44 | Iteration number: [2870/4518] 63% | Training loss: 0.6871186879661441
Epoch: 44 | Iteration number: [2880/4518] 63% | Training loss: 0.687117334227595
Epoch: 44 | Iteration number: [2890/4518] 63% | Training loss: 0.6871173825024733
Epoch: 44 | Iteration number: [2900/4518] 64% | Training loss: 0.6871123376385919
Epoch: 44 | Iteration number: [2910/4518] 64% | Training loss: 0.6871112458075035
Epoch: 44 | Iteration number: [2920/4518] 64% | Training loss: 0.687108082273235
Epoch: 44 | Iteration number: [2930/4518] 64% | Training loss: 0.687102939122366
Epoch: 44 | Iteration number: [2940/4518] 65% | Training loss: 0.6871059714936886
Epoch: 44 | Iteration number: [2950/4518] 65% | Training loss: 0.6871063577320616
Epoch: 44 | Iteration number: [2960/4518] 65% | Training loss: 0.6871077164202123
Epoch: 44 | Iteration number: [2970/4518] 65% | Training loss: 0.6871053306944042
Epoch: 44 | Iteration number: [2980/4518] 65% | Training loss: 0.6871097644903515
Epoch: 44 | Iteration number: [2990/4518] 66% | Training loss: 0.6871112933725019
Epoch: 44 | Iteration number: [3000/4518] 66% | Training loss: 0.6871085332433383
Epoch: 44 | Iteration number: [3010/4518] 66% | Training loss: 0.6871091854136647
Epoch: 44 | Iteration number: [3020/4518] 66% | Training loss: 0.6870987699323932
Epoch: 44 | Iteration number: [3030/4518] 67% | Training loss: 0.6870998966615193
Epoch: 44 | Iteration number: [3040/4518] 67% | Training loss: 0.687096996919105
Epoch: 44 | Iteration number: [3050/4518] 67% | Training loss: 0.6870922181059103
Epoch: 44 | Iteration number: [3060/4518] 67% | Training loss: 0.687091416782803
Epoch: 44 | Iteration number: [3070/4518] 67% | Training loss: 0.6870905551537628
Epoch: 44 | Iteration number: [3080/4518] 68% | Training loss: 0.6870881569075894
Epoch: 44 | Iteration number: [3090/4518] 68% | Training loss: 0.6870882249380007
Epoch: 44 | Iteration number: [3100/4518] 68% | Training loss: 0.6870888280099438
Epoch: 44 | Iteration number: [3110/4518] 68% | Training loss: 0.6870897316856016
Epoch: 44 | Iteration number: [3120/4518] 69% | Training loss: 0.6870884329080582
Epoch: 44 | Iteration number: [3130/4518] 69% | Training loss: 0.6870868004358615
Epoch: 44 | Iteration number: [3140/4518] 69% | Training loss: 0.6870870794080625
Epoch: 44 | Iteration number: [3150/4518] 69% | Training loss: 0.6870877557898325
Epoch: 44 | Iteration number: [3160/4518] 69% | Training loss: 0.6870837517177002
Epoch: 44 | Iteration number: [3170/4518] 70% | Training loss: 0.6870831085868438
Epoch: 44 | Iteration number: [3180/4518] 70% | Training loss: 0.6870833433461639
Epoch: 44 | Iteration number: [3190/4518] 70% | Training loss: 0.6870786923412993
Epoch: 44 | Iteration number: [3200/4518] 70% | Training loss: 0.6870755607262253
Epoch: 44 | Iteration number: [3210/4518] 71% | Training loss: 0.6870746907044051
Epoch: 44 | Iteration number: [3220/4518] 71% | Training loss: 0.6870736714475644
Epoch: 44 | Iteration number: [3230/4518] 71% | Training loss: 0.6870709556544159
Epoch: 44 | Iteration number: [3240/4518] 71% | Training loss: 0.6870721970995267
Epoch: 44 | Iteration number: [3250/4518] 71% | Training loss: 0.6870707636429714
Epoch: 44 | Iteration number: [3260/4518] 72% | Training loss: 0.6870775179446109
Epoch: 44 | Iteration number: [3270/4518] 72% | Training loss: 0.6870747763447076
Epoch: 44 | Iteration number: [3280/4518] 72% | Training loss: 0.6870764817951656
Epoch: 44 | Iteration number: [3290/4518] 72% | Training loss: 0.68707126913462
Epoch: 44 | Iteration number: [3300/4518] 73% | Training loss: 0.6870748606414506
Epoch: 44 | Iteration number: [3310/4518] 73% | Training loss: 0.6870772443509174
Epoch: 44 | Iteration number: [3320/4518] 73% | Training loss: 0.6870755283229323
Epoch: 44 | Iteration number: [3330/4518] 73% | Training loss: 0.6870750749791349
Epoch: 44 | Iteration number: [3340/4518] 73% | Training loss: 0.6870768463897134
Epoch: 44 | Iteration number: [3350/4518] 74% | Training loss: 0.6870787992762096
Epoch: 44 | Iteration number: [3360/4518] 74% | Training loss: 0.687077830518995
Epoch: 44 | Iteration number: [3370/4518] 74% | Training loss: 0.6870781004428863
Epoch: 44 | Iteration number: [3380/4518] 74% | Training loss: 0.6870793018820723
Epoch: 44 | Iteration number: [3390/4518] 75% | Training loss: 0.6870779613653819
Epoch: 44 | Iteration number: [3400/4518] 75% | Training loss: 0.6870768272701432
Epoch: 44 | Iteration number: [3410/4518] 75% | Training loss: 0.6870777612557509
Epoch: 44 | Iteration number: [3420/4518] 75% | Training loss: 0.6870804357249835
Epoch: 44 | Iteration number: [3430/4518] 75% | Training loss: 0.687079893760709
Epoch: 44 | Iteration number: [3440/4518] 76% | Training loss: 0.6870810640239439
Epoch: 44 | Iteration number: [3450/4518] 76% | Training loss: 0.6870803031886833
Epoch: 44 | Iteration number: [3460/4518] 76% | Training loss: 0.6870830706606021
Epoch: 44 | Iteration number: [3470/4518] 76% | Training loss: 0.6870822185913492
Epoch: 44 | Iteration number: [3480/4518] 77% | Training loss: 0.6870795271519957
Epoch: 44 | Iteration number: [3490/4518] 77% | Training loss: 0.6870789016898519
Epoch: 44 | Iteration number: [3500/4518] 77% | Training loss: 0.6870790460450309
Epoch: 44 | Iteration number: [3510/4518] 77% | Training loss: 0.6870782334410567
Epoch: 44 | Iteration number: [3520/4518] 77% | Training loss: 0.6870762927796353
Epoch: 44 | Iteration number: [3530/4518] 78% | Training loss: 0.6870734365904972
Epoch: 44 | Iteration number: [3540/4518] 78% | Training loss: 0.6870718465686518
Epoch: 44 | Iteration number: [3550/4518] 78% | Training loss: 0.6870677872778664
Epoch: 44 | Iteration number: [3560/4518] 78% | Training loss: 0.6870671099826191
Epoch: 44 | Iteration number: [3570/4518] 79% | Training loss: 0.687064568919628
Epoch: 44 | Iteration number: [3580/4518] 79% | Training loss: 0.6870609513041693
Epoch: 44 | Iteration number: [3590/4518] 79% | Training loss: 0.687059305072827
Epoch: 44 | Iteration number: [3600/4518] 79% | Training loss: 0.6870613750649823
Epoch: 44 | Iteration number: [3610/4518] 79% | Training loss: 0.6870580339035499
Epoch: 44 | Iteration number: [3620/4518] 80% | Training loss: 0.6870561492706531
Epoch: 44 | Iteration number: [3630/4518] 80% | Training loss: 0.687054993265588
Epoch: 44 | Iteration number: [3640/4518] 80% | Training loss: 0.6870488935119503
Epoch: 44 | Iteration number: [3650/4518] 80% | Training loss: 0.6870482899718089
Epoch: 44 | Iteration number: [3660/4518] 81% | Training loss: 0.6870454722740611
Epoch: 44 | Iteration number: [3670/4518] 81% | Training loss: 0.6870451937579329
Epoch: 44 | Iteration number: [3680/4518] 81% | Training loss: 0.6870457047029682
Epoch: 44 | Iteration number: [3690/4518] 81% | Training loss: 0.68704385841442
Epoch: 44 | Iteration number: [3700/4518] 81% | Training loss: 0.6870449258024628
Epoch: 44 | Iteration number: [3710/4518] 82% | Training loss: 0.6870453761915634
Epoch: 44 | Iteration number: [3720/4518] 82% | Training loss: 0.6870453422268231
Epoch: 44 | Iteration number: [3730/4518] 82% | Training loss: 0.6870451610305673
Epoch: 44 | Iteration number: [3740/4518] 82% | Training loss: 0.6870436064221642
Epoch: 44 | Iteration number: [3750/4518] 83% | Training loss: 0.6870436132589977
Epoch: 44 | Iteration number: [3760/4518] 83% | Training loss: 0.6870395619342936
Epoch: 44 | Iteration number: [3770/4518] 83% | Training loss: 0.6870382676548288
Epoch: 44 | Iteration number: [3780/4518] 83% | Training loss: 0.6870367662931877
Epoch: 44 | Iteration number: [3790/4518] 83% | Training loss: 0.6870354694552661
Epoch: 44 | Iteration number: [3800/4518] 84% | Training loss: 0.6870365706713576
Epoch: 44 | Iteration number: [3810/4518] 84% | Training loss: 0.6870334045467728
Epoch: 44 | Iteration number: [3820/4518] 84% | Training loss: 0.6870325894880045
Epoch: 44 | Iteration number: [3830/4518] 84% | Training loss: 0.6870309182620236
Epoch: 44 | Iteration number: [3840/4518] 84% | Training loss: 0.6870315524283797
Epoch: 44 | Iteration number: [3850/4518] 85% | Training loss: 0.687027868001492
Epoch: 44 | Iteration number: [3860/4518] 85% | Training loss: 0.687027660907859
Epoch: 44 | Iteration number: [3870/4518] 85% | Training loss: 0.6870251441186712
Epoch: 44 | Iteration number: [3880/4518] 85% | Training loss: 0.6870242345118031
Epoch: 44 | Iteration number: [3890/4518] 86% | Training loss: 0.6870229654416327
Epoch: 44 | Iteration number: [3900/4518] 86% | Training loss: 0.6870242944436196
Epoch: 44 | Iteration number: [3910/4518] 86% | Training loss: 0.6870225955458248
Epoch: 44 | Iteration number: [3920/4518] 86% | Training loss: 0.687020530840572
Epoch: 44 | Iteration number: [3930/4518] 86% | Training loss: 0.6870172875376451
Epoch: 44 | Iteration number: [3940/4518] 87% | Training loss: 0.6870138872698479
Epoch: 44 | Iteration number: [3950/4518] 87% | Training loss: 0.6870116932935353
Epoch: 44 | Iteration number: [3960/4518] 87% | Training loss: 0.6870123347549727
Epoch: 44 | Iteration number: [3970/4518] 87% | Training loss: 0.6870104936718641
Epoch: 44 | Iteration number: [3980/4518] 88% | Training loss: 0.6870078466645437
Epoch: 44 | Iteration number: [3990/4518] 88% | Training loss: 0.6870017822224992
Epoch: 44 | Iteration number: [4000/4518] 88% | Training loss: 0.6869991172850132
Epoch: 44 | Iteration number: [4010/4518] 88% | Training loss: 0.6869992055649174
Epoch: 44 | Iteration number: [4020/4518] 88% | Training loss: 0.6869987500544211
Epoch: 44 | Iteration number: [4030/4518] 89% | Training loss: 0.6869976641374546
Epoch: 44 | Iteration number: [4040/4518] 89% | Training loss: 0.6869946720133914
Epoch: 44 | Iteration number: [4050/4518] 89% | Training loss: 0.6869930899290391
Epoch: 44 | Iteration number: [4060/4518] 89% | Training loss: 0.6869966714399789
Epoch: 44 | Iteration number: [4070/4518] 90% | Training loss: 0.6869991385087334
Epoch: 44 | Iteration number: [4080/4518] 90% | Training loss: 0.6869950652560767
Epoch: 44 | Iteration number: [4090/4518] 90% | Training loss: 0.6869939243006531
Epoch: 44 | Iteration number: [4100/4518] 90% | Training loss: 0.6869953185029146
Epoch: 44 | Iteration number: [4110/4518] 90% | Training loss: 0.6869956907419683
Epoch: 44 | Iteration number: [4120/4518] 91% | Training loss: 0.6869974479802604
Epoch: 44 | Iteration number: [4130/4518] 91% | Training loss: 0.6869964010634665
Epoch: 44 | Iteration number: [4140/4518] 91% | Training loss: 0.686994895051067
Epoch: 44 | Iteration number: [4150/4518] 91% | Training loss: 0.6869956078586809
Epoch: 44 | Iteration number: [4160/4518] 92% | Training loss: 0.6869957093865826
Epoch: 44 | Iteration number: [4170/4518] 92% | Training loss: 0.68699646226222
Epoch: 44 | Iteration number: [4180/4518] 92% | Training loss: 0.6869965328696812
Epoch: 44 | Iteration number: [4190/4518] 92% | Training loss: 0.686993257114597
Epoch: 44 | Iteration number: [4200/4518] 92% | Training loss: 0.6869962943025998
Epoch: 44 | Iteration number: [4210/4518] 93% | Training loss: 0.6869975590366083
Epoch: 44 | Iteration number: [4220/4518] 93% | Training loss: 0.6869968569532955
Epoch: 44 | Iteration number: [4230/4518] 93% | Training loss: 0.6869934842237062
Epoch: 44 | Iteration number: [4240/4518] 93% | Training loss: 0.686992521021726
Epoch: 44 | Iteration number: [4250/4518] 94% | Training loss: 0.6869907698070302
Epoch: 44 | Iteration number: [4260/4518] 94% | Training loss: 0.6869898394519734
Epoch: 44 | Iteration number: [4270/4518] 94% | Training loss: 0.6869864900441582
Epoch: 44 | Iteration number: [4280/4518] 94% | Training loss: 0.686986390424666
Epoch: 44 | Iteration number: [4290/4518] 94% | Training loss: 0.6869840316422335
Epoch: 44 | Iteration number: [4300/4518] 95% | Training loss: 0.6869862780875938
Epoch: 44 | Iteration number: [4310/4518] 95% | Training loss: 0.6869874402016332
Epoch: 44 | Iteration number: [4320/4518] 95% | Training loss: 0.6869824333047425
Epoch: 44 | Iteration number: [4330/4518] 95% | Training loss: 0.686982447294385
Epoch: 44 | Iteration number: [4340/4518] 96% | Training loss: 0.6869845563914919
Epoch: 44 | Iteration number: [4350/4518] 96% | Training loss: 0.6869840999170281
Epoch: 44 | Iteration number: [4360/4518] 96% | Training loss: 0.686986674532431
Epoch: 44 | Iteration number: [4370/4518] 96% | Training loss: 0.6869863442752673
Epoch: 44 | Iteration number: [4380/4518] 96% | Training loss: 0.6869846487426322
Epoch: 44 | Iteration number: [4390/4518] 97% | Training loss: 0.6869802135405616
Epoch: 44 | Iteration number: [4400/4518] 97% | Training loss: 0.6869828079099005
Epoch: 44 | Iteration number: [4410/4518] 97% | Training loss: 0.6869826182351361
Epoch: 44 | Iteration number: [4420/4518] 97% | Training loss: 0.6869815210411452
Epoch: 44 | Iteration number: [4430/4518] 98% | Training loss: 0.6869815338007752
Epoch: 44 | Iteration number: [4440/4518] 98% | Training loss: 0.6869802938925254
Epoch: 44 | Iteration number: [4450/4518] 98% | Training loss: 0.6869797490955738
Epoch: 44 | Iteration number: [4460/4518] 98% | Training loss: 0.6869803035205789
Epoch: 44 | Iteration number: [4470/4518] 98% | Training loss: 0.686976757145568
Epoch: 44 | Iteration number: [4480/4518] 99% | Training loss: 0.6869782368120338
Epoch: 44 | Iteration number: [4490/4518] 99% | Training loss: 0.6869780390857323
Epoch: 44 | Iteration number: [4500/4518] 99% | Training loss: 0.6869738728205363
Epoch: 44 | Iteration number: [4510/4518] 99% | Training loss: 0.6869715520257167

 End of epoch: 44 | Train Loss: 0.6868206711668207 | Training Time: 640 

 End of epoch: 44 | Eval Loss: 0.6899559777610156 | Evaluating Time: 17 
Epoch: 45 | Iteration number: [10/4518] 0% | Training loss: 0.7556397974491119
Epoch: 45 | Iteration number: [20/4518] 0% | Training loss: 0.7215868413448334
Epoch: 45 | Iteration number: [30/4518] 0% | Training loss: 0.7101685643196106
Epoch: 45 | Iteration number: [40/4518] 0% | Training loss: 0.7045787453651429
Epoch: 45 | Iteration number: [50/4518] 1% | Training loss: 0.7008027994632721
Epoch: 45 | Iteration number: [60/4518] 1% | Training loss: 0.6987160235643387
Epoch: 45 | Iteration number: [70/4518] 1% | Training loss: 0.6970618997301374
Epoch: 45 | Iteration number: [80/4518] 1% | Training loss: 0.6956704467535019
Epoch: 45 | Iteration number: [90/4518] 1% | Training loss: 0.6945980058776008
Epoch: 45 | Iteration number: [100/4518] 2% | Training loss: 0.6938727474212647
Epoch: 45 | Iteration number: [110/4518] 2% | Training loss: 0.6932785288854079
Epoch: 45 | Iteration number: [120/4518] 2% | Training loss: 0.6927009423573812
Epoch: 45 | Iteration number: [130/4518] 2% | Training loss: 0.692314338684082
Epoch: 45 | Iteration number: [140/4518] 3% | Training loss: 0.6919384424175535
Epoch: 45 | Iteration number: [150/4518] 3% | Training loss: 0.6915664752324422
Epoch: 45 | Iteration number: [160/4518] 3% | Training loss: 0.6913103401660919
Epoch: 45 | Iteration number: [170/4518] 3% | Training loss: 0.6910699335967794
Epoch: 45 | Iteration number: [180/4518] 3% | Training loss: 0.6908599098523458
Epoch: 45 | Iteration number: [190/4518] 4% | Training loss: 0.6906396304306232
Epoch: 45 | Iteration number: [200/4518] 4% | Training loss: 0.690429727435112
Epoch: 45 | Iteration number: [210/4518] 4% | Training loss: 0.6902713066055661
Epoch: 45 | Iteration number: [220/4518] 4% | Training loss: 0.6901446927677501
Epoch: 45 | Iteration number: [230/4518] 5% | Training loss: 0.6899805535440859
Epoch: 45 | Iteration number: [240/4518] 5% | Training loss: 0.6898433044552803
Epoch: 45 | Iteration number: [250/4518] 5% | Training loss: 0.6897717306613922
Epoch: 45 | Iteration number: [260/4518] 5% | Training loss: 0.6896389906223004
Epoch: 45 | Iteration number: [270/4518] 5% | Training loss: 0.6894649401859001
Epoch: 45 | Iteration number: [280/4518] 6% | Training loss: 0.6893442398735455
Epoch: 45 | Iteration number: [290/4518] 6% | Training loss: 0.6892784217308308
Epoch: 45 | Iteration number: [300/4518] 6% | Training loss: 0.6892218699057897
Epoch: 45 | Iteration number: [310/4518] 6% | Training loss: 0.6891418730058978
Epoch: 45 | Iteration number: [320/4518] 7% | Training loss: 0.6890685301274061
Epoch: 45 | Iteration number: [330/4518] 7% | Training loss: 0.6889938020344937
Epoch: 45 | Iteration number: [340/4518] 7% | Training loss: 0.6889668057946597
Epoch: 45 | Iteration number: [350/4518] 7% | Training loss: 0.6889001682826451
Epoch: 45 | Iteration number: [360/4518] 7% | Training loss: 0.6888793518145879
Epoch: 45 | Iteration number: [370/4518] 8% | Training loss: 0.6887961916021399
Epoch: 45 | Iteration number: [380/4518] 8% | Training loss: 0.6887163314380144
Epoch: 45 | Iteration number: [390/4518] 8% | Training loss: 0.6886603509768462
Epoch: 45 | Iteration number: [400/4518] 8% | Training loss: 0.6886043086647987
Epoch: 45 | Iteration number: [410/4518] 9% | Training loss: 0.6885527186277436
Epoch: 45 | Iteration number: [420/4518] 9% | Training loss: 0.6884931636708124
Epoch: 45 | Iteration number: [430/4518] 9% | Training loss: 0.6884650708631027
Epoch: 45 | Iteration number: [440/4518] 9% | Training loss: 0.6883997886018319
Epoch: 45 | Iteration number: [450/4518] 9% | Training loss: 0.688370887570911
Epoch: 45 | Iteration number: [460/4518] 10% | Training loss: 0.6883461229179216
Epoch: 45 | Iteration number: [470/4518] 10% | Training loss: 0.688300891505911
Epoch: 45 | Iteration number: [480/4518] 10% | Training loss: 0.6882796651373307
Epoch: 45 | Iteration number: [490/4518] 10% | Training loss: 0.6882335726095705
Epoch: 45 | Iteration number: [500/4518] 11% | Training loss: 0.6882151789665222
Epoch: 45 | Iteration number: [510/4518] 11% | Training loss: 0.6881918910671683
Epoch: 45 | Iteration number: [520/4518] 11% | Training loss: 0.6881598006074245
Epoch: 45 | Iteration number: [530/4518] 11% | Training loss: 0.6881066289712798
Epoch: 45 | Iteration number: [540/4518] 11% | Training loss: 0.6880852997303009
Epoch: 45 | Iteration number: [550/4518] 12% | Training loss: 0.6880681135437705
Epoch: 45 | Iteration number: [560/4518] 12% | Training loss: 0.688060685885804
Epoch: 45 | Iteration number: [570/4518] 12% | Training loss: 0.6880112687746683
Epoch: 45 | Iteration number: [580/4518] 12% | Training loss: 0.6880181536592286
Epoch: 45 | Iteration number: [590/4518] 13% | Training loss: 0.6879720091819763
Epoch: 45 | Iteration number: [600/4518] 13% | Training loss: 0.6879484830300013
Epoch: 45 | Iteration number: [610/4518] 13% | Training loss: 0.6879189371085558
Epoch: 45 | Iteration number: [620/4518] 13% | Training loss: 0.6879220407816672
Epoch: 45 | Iteration number: [630/4518] 13% | Training loss: 0.6879084638186863
Epoch: 45 | Iteration number: [640/4518] 14% | Training loss: 0.6878870833665133
Epoch: 45 | Iteration number: [650/4518] 14% | Training loss: 0.6878555902150961
Epoch: 45 | Iteration number: [660/4518] 14% | Training loss: 0.6878220128290581
Epoch: 45 | Iteration number: [670/4518] 14% | Training loss: 0.6878008446586665
Epoch: 45 | Iteration number: [680/4518] 15% | Training loss: 0.6877775333383505
Epoch: 45 | Iteration number: [690/4518] 15% | Training loss: 0.6877686085908309
Epoch: 45 | Iteration number: [700/4518] 15% | Training loss: 0.6877478778362274
Epoch: 45 | Iteration number: [710/4518] 15% | Training loss: 0.6877497711651762
Epoch: 45 | Iteration number: [720/4518] 15% | Training loss: 0.687731846753094
Epoch: 45 | Iteration number: [730/4518] 16% | Training loss: 0.6877209346588343
Epoch: 45 | Iteration number: [740/4518] 16% | Training loss: 0.6877177124087875
Epoch: 45 | Iteration number: [750/4518] 16% | Training loss: 0.6877145253022512
Epoch: 45 | Iteration number: [760/4518] 16% | Training loss: 0.6876885429808968
Epoch: 45 | Iteration number: [770/4518] 17% | Training loss: 0.6876722413224059
Epoch: 45 | Iteration number: [780/4518] 17% | Training loss: 0.6876695439601556
Epoch: 45 | Iteration number: [790/4518] 17% | Training loss: 0.6876664311070986
Epoch: 45 | Iteration number: [800/4518] 17% | Training loss: 0.687632420361042
Epoch: 45 | Iteration number: [810/4518] 17% | Training loss: 0.6876176558894875
Epoch: 45 | Iteration number: [820/4518] 18% | Training loss: 0.6876077960904051
Epoch: 45 | Iteration number: [830/4518] 18% | Training loss: 0.6875945697347802
Epoch: 45 | Iteration number: [840/4518] 18% | Training loss: 0.6875816554540679
Epoch: 45 | Iteration number: [850/4518] 18% | Training loss: 0.6875781694580527
Epoch: 45 | Iteration number: [860/4518] 19% | Training loss: 0.6875691950321198
Epoch: 45 | Iteration number: [870/4518] 19% | Training loss: 0.6875608474358745
Epoch: 45 | Iteration number: [880/4518] 19% | Training loss: 0.6875406214459376
Epoch: 45 | Iteration number: [890/4518] 19% | Training loss: 0.6875249612867163
Epoch: 45 | Iteration number: [900/4518] 19% | Training loss: 0.6875180633862813
Epoch: 45 | Iteration number: [910/4518] 20% | Training loss: 0.6875072633172129
Epoch: 45 | Iteration number: [920/4518] 20% | Training loss: 0.6874972356402356
Epoch: 45 | Iteration number: [930/4518] 20% | Training loss: 0.6874978165472707
Epoch: 45 | Iteration number: [940/4518] 20% | Training loss: 0.6874924716163189
Epoch: 45 | Iteration number: [950/4518] 21% | Training loss: 0.6874931917692486
Epoch: 45 | Iteration number: [960/4518] 21% | Training loss: 0.6874764960880081
Epoch: 45 | Iteration number: [970/4518] 21% | Training loss: 0.687471064341437
Epoch: 45 | Iteration number: [980/4518] 21% | Training loss: 0.687469273562334
Epoch: 45 | Iteration number: [990/4518] 21% | Training loss: 0.6874551876024766
Epoch: 45 | Iteration number: [1000/4518] 22% | Training loss: 0.6874444036483764
Epoch: 45 | Iteration number: [1010/4518] 22% | Training loss: 0.6874356716576189
Epoch: 45 | Iteration number: [1020/4518] 22% | Training loss: 0.6874269998541065
Epoch: 45 | Iteration number: [1030/4518] 22% | Training loss: 0.6874304931719326
Epoch: 45 | Iteration number: [1040/4518] 23% | Training loss: 0.6874166939121026
Epoch: 45 | Iteration number: [1050/4518] 23% | Training loss: 0.6874272432781401
Epoch: 45 | Iteration number: [1060/4518] 23% | Training loss: 0.6874199776716952
Epoch: 45 | Iteration number: [1070/4518] 23% | Training loss: 0.6874187338575024
Epoch: 45 | Iteration number: [1080/4518] 23% | Training loss: 0.6874113203750716
Epoch: 45 | Iteration number: [1090/4518] 24% | Training loss: 0.6873982041800788
Epoch: 45 | Iteration number: [1100/4518] 24% | Training loss: 0.6873977988416499
Epoch: 45 | Iteration number: [1110/4518] 24% | Training loss: 0.6873827601338292
Epoch: 45 | Iteration number: [1120/4518] 24% | Training loss: 0.6873712485922234
Epoch: 45 | Iteration number: [1130/4518] 25% | Training loss: 0.6873484392081741
Epoch: 45 | Iteration number: [1140/4518] 25% | Training loss: 0.6873561889456029
Epoch: 45 | Iteration number: [1150/4518] 25% | Training loss: 0.6873544912752898
Epoch: 45 | Iteration number: [1160/4518] 25% | Training loss: 0.6873476125043014
Epoch: 45 | Iteration number: [1170/4518] 25% | Training loss: 0.6873501570306273
Epoch: 45 | Iteration number: [1180/4518] 26% | Training loss: 0.6873377332747993
Epoch: 45 | Iteration number: [1190/4518] 26% | Training loss: 0.6873269837443569
Epoch: 45 | Iteration number: [1200/4518] 26% | Training loss: 0.6873148794968923
Epoch: 45 | Iteration number: [1210/4518] 26% | Training loss: 0.687320028159244
Epoch: 45 | Iteration number: [1220/4518] 27% | Training loss: 0.6873244949051591
Epoch: 45 | Iteration number: [1230/4518] 27% | Training loss: 0.6873231330053593
Epoch: 45 | Iteration number: [1240/4518] 27% | Training loss: 0.6873148819131236
Epoch: 45 | Iteration number: [1250/4518] 27% | Training loss: 0.6873056285381317
Epoch: 45 | Iteration number: [1260/4518] 27% | Training loss: 0.6873019271899783
Epoch: 45 | Iteration number: [1270/4518] 28% | Training loss: 0.687310134801339
Epoch: 45 | Iteration number: [1280/4518] 28% | Training loss: 0.6872985592577606
Epoch: 45 | Iteration number: [1290/4518] 28% | Training loss: 0.6873047054738037
Epoch: 45 | Iteration number: [1300/4518] 28% | Training loss: 0.6873118609189988
Epoch: 45 | Iteration number: [1310/4518] 28% | Training loss: 0.6872979756985002
Epoch: 45 | Iteration number: [1320/4518] 29% | Training loss: 0.6872937700062087
Epoch: 45 | Iteration number: [1330/4518] 29% | Training loss: 0.6873024969620812
Epoch: 45 | Iteration number: [1340/4518] 29% | Training loss: 0.6872967006555244
Epoch: 45 | Iteration number: [1350/4518] 29% | Training loss: 0.68728961803295
Epoch: 45 | Iteration number: [1360/4518] 30% | Training loss: 0.6872835336800884
Epoch: 45 | Iteration number: [1370/4518] 30% | Training loss: 0.6872867058228402
Epoch: 45 | Iteration number: [1380/4518] 30% | Training loss: 0.6872941459866537
Epoch: 45 | Iteration number: [1390/4518] 30% | Training loss: 0.6872954408899485
Epoch: 45 | Iteration number: [1400/4518] 30% | Training loss: 0.6873009135893413
Epoch: 45 | Iteration number: [1410/4518] 31% | Training loss: 0.6872937357172053
Epoch: 45 | Iteration number: [1420/4518] 31% | Training loss: 0.687289646309866
Epoch: 45 | Iteration number: [1430/4518] 31% | Training loss: 0.6872826702111251
Epoch: 45 | Iteration number: [1440/4518] 31% | Training loss: 0.6872815796070628
Epoch: 45 | Iteration number: [1450/4518] 32% | Training loss: 0.6872848091043275
Epoch: 45 | Iteration number: [1460/4518] 32% | Training loss: 0.6872769673393198
Epoch: 45 | Iteration number: [1470/4518] 32% | Training loss: 0.6872717185085323
Epoch: 45 | Iteration number: [1480/4518] 32% | Training loss: 0.6872769466928533
Epoch: 45 | Iteration number: [1490/4518] 32% | Training loss: 0.6872709722726937
Epoch: 45 | Iteration number: [1500/4518] 33% | Training loss: 0.6872691281239192
Epoch: 45 | Iteration number: [1510/4518] 33% | Training loss: 0.6872596141913079
Epoch: 45 | Iteration number: [1520/4518] 33% | Training loss: 0.6872601218913731
Epoch: 45 | Iteration number: [1530/4518] 33% | Training loss: 0.6872556568750369
Epoch: 45 | Iteration number: [1540/4518] 34% | Training loss: 0.68724724847775
Epoch: 45 | Iteration number: [1550/4518] 34% | Training loss: 0.6872447852165469
Epoch: 45 | Iteration number: [1560/4518] 34% | Training loss: 0.6872385263060912
Epoch: 45 | Iteration number: [1570/4518] 34% | Training loss: 0.6872335616190722
Epoch: 45 | Iteration number: [1580/4518] 34% | Training loss: 0.687232859979702
Epoch: 45 | Iteration number: [1590/4518] 35% | Training loss: 0.6872344071760118
Epoch: 45 | Iteration number: [1600/4518] 35% | Training loss: 0.6872392583638429
Epoch: 45 | Iteration number: [1610/4518] 35% | Training loss: 0.6872333995303752
Epoch: 45 | Iteration number: [1620/4518] 35% | Training loss: 0.6872314826205924
Epoch: 45 | Iteration number: [1630/4518] 36% | Training loss: 0.6872301391297323
Epoch: 45 | Iteration number: [1640/4518] 36% | Training loss: 0.6872242201755686
Epoch: 45 | Iteration number: [1650/4518] 36% | Training loss: 0.6872290558887251
Epoch: 45 | Iteration number: [1660/4518] 36% | Training loss: 0.6872253621917173
Epoch: 45 | Iteration number: [1670/4518] 36% | Training loss: 0.687218327044013
Epoch: 45 | Iteration number: [1680/4518] 37% | Training loss: 0.6872163048102742
Epoch: 45 | Iteration number: [1690/4518] 37% | Training loss: 0.6872197740882106
Epoch: 45 | Iteration number: [1700/4518] 37% | Training loss: 0.6872180663838106
Epoch: 45 | Iteration number: [1710/4518] 37% | Training loss: 0.6872147616238622
Epoch: 45 | Iteration number: [1720/4518] 38% | Training loss: 0.6872090943677481
Epoch: 45 | Iteration number: [1730/4518] 38% | Training loss: 0.6872061251215852
Epoch: 45 | Iteration number: [1740/4518] 38% | Training loss: 0.687198207090641
Epoch: 45 | Iteration number: [1750/4518] 38% | Training loss: 0.6871937552860805
Epoch: 45 | Iteration number: [1760/4518] 38% | Training loss: 0.6871939022432674
Epoch: 45 | Iteration number: [1770/4518] 39% | Training loss: 0.6871921137564599
Epoch: 45 | Iteration number: [1780/4518] 39% | Training loss: 0.6871901711051384
Epoch: 45 | Iteration number: [1790/4518] 39% | Training loss: 0.6871842417637063
Epoch: 45 | Iteration number: [1800/4518] 39% | Training loss: 0.68718779951334
Epoch: 45 | Iteration number: [1810/4518] 40% | Training loss: 0.6871819935121589
Epoch: 45 | Iteration number: [1820/4518] 40% | Training loss: 0.6871819716233474
Epoch: 45 | Iteration number: [1830/4518] 40% | Training loss: 0.6871802684062166
Epoch: 45 | Iteration number: [1840/4518] 40% | Training loss: 0.6871805738495744
Epoch: 45 | Iteration number: [1850/4518] 40% | Training loss: 0.6871827854981294
Epoch: 45 | Iteration number: [1860/4518] 41% | Training loss: 0.6871804895260001
Epoch: 45 | Iteration number: [1870/4518] 41% | Training loss: 0.6871742677879843
Epoch: 45 | Iteration number: [1880/4518] 41% | Training loss: 0.6871790209349166
Epoch: 45 | Iteration number: [1890/4518] 41% | Training loss: 0.6871825758742277
Epoch: 45 | Iteration number: [1900/4518] 42% | Training loss: 0.6871845058704678
Epoch: 45 | Iteration number: [1910/4518] 42% | Training loss: 0.6871773573428549
Epoch: 45 | Iteration number: [1920/4518] 42% | Training loss: 0.6871772166651984
Epoch: 45 | Iteration number: [1930/4518] 42% | Training loss: 0.6871664780100393
Epoch: 45 | Iteration number: [1940/4518] 42% | Training loss: 0.6871590437041115
Epoch: 45 | Iteration number: [1950/4518] 43% | Training loss: 0.6871580034341568
Epoch: 45 | Iteration number: [1960/4518] 43% | Training loss: 0.6871496566400236
Epoch: 45 | Iteration number: [1970/4518] 43% | Training loss: 0.6871496130367221
Epoch: 45 | Iteration number: [1980/4518] 43% | Training loss: 0.6871489893306385
Epoch: 45 | Iteration number: [1990/4518] 44% | Training loss: 0.6871482535822308
Epoch: 45 | Iteration number: [2000/4518] 44% | Training loss: 0.6871466360986233
Epoch: 45 | Iteration number: [2010/4518] 44% | Training loss: 0.6871479395610183
Epoch: 45 | Iteration number: [2020/4518] 44% | Training loss: 0.6871466891010208
Epoch: 45 | Iteration number: [2030/4518] 44% | Training loss: 0.6871460921365052
Epoch: 45 | Iteration number: [2040/4518] 45% | Training loss: 0.6871484248661528
Epoch: 45 | Iteration number: [2050/4518] 45% | Training loss: 0.6871491644149873
Epoch: 45 | Iteration number: [2060/4518] 45% | Training loss: 0.6871433137400637
Epoch: 45 | Iteration number: [2070/4518] 45% | Training loss: 0.6871366494807645
Epoch: 45 | Iteration number: [2080/4518] 46% | Training loss: 0.6871372704035961
Epoch: 45 | Iteration number: [2090/4518] 46% | Training loss: 0.687134563951401
Epoch: 45 | Iteration number: [2100/4518] 46% | Training loss: 0.6871253275871276
Epoch: 45 | Iteration number: [2110/4518] 46% | Training loss: 0.6871275532019647
Epoch: 45 | Iteration number: [2120/4518] 46% | Training loss: 0.6871173387990808
Epoch: 45 | Iteration number: [2130/4518] 47% | Training loss: 0.6871156037413458
Epoch: 45 | Iteration number: [2140/4518] 47% | Training loss: 0.6871122821469173
Epoch: 45 | Iteration number: [2150/4518] 47% | Training loss: 0.6871084187474362
Epoch: 45 | Iteration number: [2160/4518] 47% | Training loss: 0.6871060864516982
Epoch: 45 | Iteration number: [2170/4518] 48% | Training loss: 0.6871065737465011
Epoch: 45 | Iteration number: [2180/4518] 48% | Training loss: 0.6871071750691178
Epoch: 45 | Iteration number: [2190/4518] 48% | Training loss: 0.6871046456572127
Epoch: 45 | Iteration number: [2200/4518] 48% | Training loss: 0.6871067669445818
Epoch: 45 | Iteration number: [2210/4518] 48% | Training loss: 0.6871014419184551
Epoch: 45 | Iteration number: [2220/4518] 49% | Training loss: 0.6870934403425938
Epoch: 45 | Iteration number: [2230/4518] 49% | Training loss: 0.6870969038907723
Epoch: 45 | Iteration number: [2240/4518] 49% | Training loss: 0.6870930743270687
Epoch: 45 | Iteration number: [2250/4518] 49% | Training loss: 0.6870892992549472
Epoch: 45 | Iteration number: [2260/4518] 50% | Training loss: 0.6870886293396485
Epoch: 45 | Iteration number: [2270/4518] 50% | Training loss: 0.6870828304521838
Epoch: 45 | Iteration number: [2280/4518] 50% | Training loss: 0.6870827288219803
Epoch: 45 | Iteration number: [2290/4518] 50% | Training loss: 0.68707891614156
Epoch: 45 | Iteration number: [2300/4518] 50% | Training loss: 0.6870766532680262
Epoch: 45 | Iteration number: [2310/4518] 51% | Training loss: 0.6870818071293109
Epoch: 45 | Iteration number: [2320/4518] 51% | Training loss: 0.6870812765483199
Epoch: 45 | Iteration number: [2330/4518] 51% | Training loss: 0.6870807769472507
Epoch: 45 | Iteration number: [2340/4518] 51% | Training loss: 0.6870805458380626
Epoch: 45 | Iteration number: [2350/4518] 52% | Training loss: 0.6870810615001841
Epoch: 45 | Iteration number: [2360/4518] 52% | Training loss: 0.6870762747223095
Epoch: 45 | Iteration number: [2370/4518] 52% | Training loss: 0.687078370952405
Epoch: 45 | Iteration number: [2380/4518] 52% | Training loss: 0.6870827018212872
Epoch: 45 | Iteration number: [2390/4518] 52% | Training loss: 0.6870836517052671
Epoch: 45 | Iteration number: [2400/4518] 53% | Training loss: 0.6870841701080401
Epoch: 45 | Iteration number: [2410/4518] 53% | Training loss: 0.6870836846808674
Epoch: 45 | Iteration number: [2420/4518] 53% | Training loss: 0.687081077842673
Epoch: 45 | Iteration number: [2430/4518] 53% | Training loss: 0.6870777832137214
Epoch: 45 | Iteration number: [2440/4518] 54% | Training loss: 0.687078015579552
Epoch: 45 | Iteration number: [2450/4518] 54% | Training loss: 0.687074839776876
Epoch: 45 | Iteration number: [2460/4518] 54% | Training loss: 0.6870718323360614
Epoch: 45 | Iteration number: [2470/4518] 54% | Training loss: 0.687069792520662
Epoch: 45 | Iteration number: [2480/4518] 54% | Training loss: 0.6870669505769207
Epoch: 45 | Iteration number: [2490/4518] 55% | Training loss: 0.6870685998933861
Epoch: 45 | Iteration number: [2500/4518] 55% | Training loss: 0.6870661571025848
Epoch: 45 | Iteration number: [2510/4518] 55% | Training loss: 0.6870662373850545
Epoch: 45 | Iteration number: [2520/4518] 55% | Training loss: 0.6870678317452233
Epoch: 45 | Iteration number: [2530/4518] 55% | Training loss: 0.6870667355569455
Epoch: 45 | Iteration number: [2540/4518] 56% | Training loss: 0.6870700271814827
Epoch: 45 | Iteration number: [2550/4518] 56% | Training loss: 0.6870740908734939
Epoch: 45 | Iteration number: [2560/4518] 56% | Training loss: 0.6870707483962178
Epoch: 45 | Iteration number: [2570/4518] 56% | Training loss: 0.6870677461651976
Epoch: 45 | Iteration number: [2580/4518] 57% | Training loss: 0.6870658359324285
Epoch: 45 | Iteration number: [2590/4518] 57% | Training loss: 0.6870655581297561
Epoch: 45 | Iteration number: [2600/4518] 57% | Training loss: 0.6870628995391038
Epoch: 45 | Iteration number: [2610/4518] 57% | Training loss: 0.6870621270831974
Epoch: 45 | Iteration number: [2620/4518] 57% | Training loss: 0.6870671536858756
Epoch: 45 | Iteration number: [2630/4518] 58% | Training loss: 0.6870676529498154
Epoch: 45 | Iteration number: [2640/4518] 58% | Training loss: 0.6870650618816867
Epoch: 45 | Iteration number: [2650/4518] 58% | Training loss: 0.6870638552251852
Epoch: 45 | Iteration number: [2660/4518] 58% | Training loss: 0.6870602109378442
Epoch: 45 | Iteration number: [2670/4518] 59% | Training loss: 0.6870580061767878
Epoch: 45 | Iteration number: [2680/4518] 59% | Training loss: 0.6870596599000603
Epoch: 45 | Iteration number: [2690/4518] 59% | Training loss: 0.6870549537656919
Epoch: 45 | Iteration number: [2700/4518] 59% | Training loss: 0.687053024702602
Epoch: 45 | Iteration number: [2710/4518] 59% | Training loss: 0.6870521599296274
Epoch: 45 | Iteration number: [2720/4518] 60% | Training loss: 0.6870509204838205
Epoch: 45 | Iteration number: [2730/4518] 60% | Training loss: 0.6870496953800048
Epoch: 45 | Iteration number: [2740/4518] 60% | Training loss: 0.6870440033012933
Epoch: 45 | Iteration number: [2750/4518] 60% | Training loss: 0.6870447798208756
Epoch: 45 | Iteration number: [2760/4518] 61% | Training loss: 0.6870411244207534
Epoch: 45 | Iteration number: [2770/4518] 61% | Training loss: 0.6870411047866628
Epoch: 45 | Iteration number: [2780/4518] 61% | Training loss: 0.6870418249917545
Epoch: 45 | Iteration number: [2790/4518] 61% | Training loss: 0.6870412815856249
Epoch: 45 | Iteration number: [2800/4518] 61% | Training loss: 0.6870395021779196
Epoch: 45 | Iteration number: [2810/4518] 62% | Training loss: 0.6870364025182147
Epoch: 45 | Iteration number: [2820/4518] 62% | Training loss: 0.687032739701846
Epoch: 45 | Iteration number: [2830/4518] 62% | Training loss: 0.6870369485957883
Epoch: 45 | Iteration number: [2840/4518] 62% | Training loss: 0.687038120690366
Epoch: 45 | Iteration number: [2850/4518] 63% | Training loss: 0.6870366131004534
Epoch: 45 | Iteration number: [2860/4518] 63% | Training loss: 0.6870365920600358
Epoch: 45 | Iteration number: [2870/4518] 63% | Training loss: 0.687035129876087
Epoch: 45 | Iteration number: [2880/4518] 63% | Training loss: 0.6870328984740708
Epoch: 45 | Iteration number: [2890/4518] 63% | Training loss: 0.6870291666794813
Epoch: 45 | Iteration number: [2900/4518] 64% | Training loss: 0.6870310776192566
Epoch: 45 | Iteration number: [2910/4518] 64% | Training loss: 0.68703205351977
Epoch: 45 | Iteration number: [2920/4518] 64% | Training loss: 0.6870315060223618
Epoch: 45 | Iteration number: [2930/4518] 64% | Training loss: 0.687030488211954
Epoch: 45 | Iteration number: [2940/4518] 65% | Training loss: 0.6870307287594088
Epoch: 45 | Iteration number: [2950/4518] 65% | Training loss: 0.6870288276470313
Epoch: 45 | Iteration number: [2960/4518] 65% | Training loss: 0.6870249989467698
Epoch: 45 | Iteration number: [2970/4518] 65% | Training loss: 0.6870255678992481
Epoch: 45 | Iteration number: [2980/4518] 65% | Training loss: 0.6870277603000603
Epoch: 45 | Iteration number: [2990/4518] 66% | Training loss: 0.6870307125375422
Epoch: 45 | Iteration number: [3000/4518] 66% | Training loss: 0.6870283133586248
Epoch: 45 | Iteration number: [3010/4518] 66% | Training loss: 0.6870298922854009
Epoch: 45 | Iteration number: [3020/4518] 66% | Training loss: 0.6870281857173175
Epoch: 45 | Iteration number: [3030/4518] 67% | Training loss: 0.6870271097905565
Epoch: 45 | Iteration number: [3040/4518] 67% | Training loss: 0.6870315518034132
Epoch: 45 | Iteration number: [3050/4518] 67% | Training loss: 0.6870315340698743
Epoch: 45 | Iteration number: [3060/4518] 67% | Training loss: 0.6870324483299567
Epoch: 45 | Iteration number: [3070/4518] 67% | Training loss: 0.6870306210331497
Epoch: 45 | Iteration number: [3080/4518] 68% | Training loss: 0.6870312404903498
Epoch: 45 | Iteration number: [3090/4518] 68% | Training loss: 0.6870285280506974
Epoch: 45 | Iteration number: [3100/4518] 68% | Training loss: 0.6870285366042967
Epoch: 45 | Iteration number: [3110/4518] 68% | Training loss: 0.6870249964608257
Epoch: 45 | Iteration number: [3120/4518] 69% | Training loss: 0.6870259567331045
Epoch: 45 | Iteration number: [3130/4518] 69% | Training loss: 0.6870254316459449
Epoch: 45 | Iteration number: [3140/4518] 69% | Training loss: 0.6870286052394066
Epoch: 45 | Iteration number: [3150/4518] 69% | Training loss: 0.6870259557640742
Epoch: 45 | Iteration number: [3160/4518] 69% | Training loss: 0.6870250282974183
Epoch: 45 | Iteration number: [3170/4518] 70% | Training loss: 0.6870257660981608
Epoch: 45 | Iteration number: [3180/4518] 70% | Training loss: 0.6870251441151841
Epoch: 45 | Iteration number: [3190/4518] 70% | Training loss: 0.6870265025703884
Epoch: 45 | Iteration number: [3200/4518] 70% | Training loss: 0.687027676794678
Epoch: 45 | Iteration number: [3210/4518] 71% | Training loss: 0.6870254204837704
Epoch: 45 | Iteration number: [3220/4518] 71% | Training loss: 0.6870227475344024
Epoch: 45 | Iteration number: [3230/4518] 71% | Training loss: 0.687022918167498
Epoch: 45 | Iteration number: [3240/4518] 71% | Training loss: 0.6870184389161474
Epoch: 45 | Iteration number: [3250/4518] 71% | Training loss: 0.6870152195967161
Epoch: 45 | Iteration number: [3260/4518] 72% | Training loss: 0.6870156176251137
Epoch: 45 | Iteration number: [3270/4518] 72% | Training loss: 0.6870157768055569
Epoch: 45 | Iteration number: [3280/4518] 72% | Training loss: 0.6870145300357807
Epoch: 45 | Iteration number: [3290/4518] 72% | Training loss: 0.6870158046574578
Epoch: 45 | Iteration number: [3300/4518] 73% | Training loss: 0.6870160880594542
Epoch: 45 | Iteration number: [3310/4518] 73% | Training loss: 0.6870198857208033
Epoch: 45 | Iteration number: [3320/4518] 73% | Training loss: 0.6870185211121318
Epoch: 45 | Iteration number: [3330/4518] 73% | Training loss: 0.6870168012720687
Epoch: 45 | Iteration number: [3340/4518] 73% | Training loss: 0.687012088156032
Epoch: 45 | Iteration number: [3350/4518] 74% | Training loss: 0.6870082584067957
Epoch: 45 | Iteration number: [3360/4518] 74% | Training loss: 0.6870075591440712
Epoch: 45 | Iteration number: [3370/4518] 74% | Training loss: 0.6870071072429861
Epoch: 45 | Iteration number: [3380/4518] 74% | Training loss: 0.6870104628730808
Epoch: 45 | Iteration number: [3390/4518] 75% | Training loss: 0.6870076998672654
Epoch: 45 | Iteration number: [3400/4518] 75% | Training loss: 0.6870094913594863
Epoch: 45 | Iteration number: [3410/4518] 75% | Training loss: 0.6870103511642501
Epoch: 45 | Iteration number: [3420/4518] 75% | Training loss: 0.6870079167927915
Epoch: 45 | Iteration number: [3430/4518] 75% | Training loss: 0.6870064787371165
Epoch: 45 | Iteration number: [3440/4518] 76% | Training loss: 0.6870071411652621
Epoch: 45 | Iteration number: [3450/4518] 76% | Training loss: 0.6870046682634215
Epoch: 45 | Iteration number: [3460/4518] 76% | Training loss: 0.6870054591081046
Epoch: 45 | Iteration number: [3470/4518] 76% | Training loss: 0.6870083860945633
Epoch: 45 | Iteration number: [3480/4518] 77% | Training loss: 0.6870087023781634
Epoch: 45 | Iteration number: [3490/4518] 77% | Training loss: 0.6870095720093025
Epoch: 45 | Iteration number: [3500/4518] 77% | Training loss: 0.687008833357266
Epoch: 45 | Iteration number: [3510/4518] 77% | Training loss: 0.6870105348591111
Epoch: 45 | Iteration number: [3520/4518] 77% | Training loss: 0.6870105794376947
Epoch: 45 | Iteration number: [3530/4518] 78% | Training loss: 0.6870099427510928
Epoch: 45 | Iteration number: [3540/4518] 78% | Training loss: 0.6870071404734573
Epoch: 45 | Iteration number: [3550/4518] 78% | Training loss: 0.6870083097336998
Epoch: 45 | Iteration number: [3560/4518] 78% | Training loss: 0.6870076368531485
Epoch: 45 | Iteration number: [3570/4518] 79% | Training loss: 0.6870081133034383
Epoch: 45 | Iteration number: [3580/4518] 79% | Training loss: 0.6870110314984561
Epoch: 45 | Iteration number: [3590/4518] 79% | Training loss: 0.6870133470027892
Epoch: 45 | Iteration number: [3600/4518] 79% | Training loss: 0.6870122524764802
Epoch: 45 | Iteration number: [3610/4518] 79% | Training loss: 0.6870134662558167
Epoch: 45 | Iteration number: [3620/4518] 80% | Training loss: 0.6870138060816086
Epoch: 45 | Iteration number: [3630/4518] 80% | Training loss: 0.6870116271427512
Epoch: 45 | Iteration number: [3640/4518] 80% | Training loss: 0.6870132403714316
Epoch: 45 | Iteration number: [3650/4518] 80% | Training loss: 0.687010530592644
Epoch: 45 | Iteration number: [3660/4518] 81% | Training loss: 0.6870122213669814
Epoch: 45 | Iteration number: [3670/4518] 81% | Training loss: 0.6870107631429989
Epoch: 45 | Iteration number: [3680/4518] 81% | Training loss: 0.6870103578528632
Epoch: 45 | Iteration number: [3690/4518] 81% | Training loss: 0.6870089410281763
Epoch: 45 | Iteration number: [3700/4518] 81% | Training loss: 0.6870082769522796
Epoch: 45 | Iteration number: [3710/4518] 82% | Training loss: 0.687009414042424
Epoch: 45 | Iteration number: [3720/4518] 82% | Training loss: 0.6870098534771191
Epoch: 45 | Iteration number: [3730/4518] 82% | Training loss: 0.6870111773864194
Epoch: 45 | Iteration number: [3740/4518] 82% | Training loss: 0.68700826234996
Epoch: 45 | Iteration number: [3750/4518] 83% | Training loss: 0.6870107901414235
Epoch: 45 | Iteration number: [3760/4518] 83% | Training loss: 0.6870098787260817
Epoch: 45 | Iteration number: [3770/4518] 83% | Training loss: 0.6870086665495004
Epoch: 45 | Iteration number: [3780/4518] 83% | Training loss: 0.6870071267640149
Epoch: 45 | Iteration number: [3790/4518] 83% | Training loss: 0.6870053863462483
Epoch: 45 | Iteration number: [3800/4518] 84% | Training loss: 0.6870042631500646
Epoch: 45 | Iteration number: [3810/4518] 84% | Training loss: 0.6870070655671318
Epoch: 45 | Iteration number: [3820/4518] 84% | Training loss: 0.6870048680230585
Epoch: 45 | Iteration number: [3830/4518] 84% | Training loss: 0.6870043103284064
Epoch: 45 | Iteration number: [3840/4518] 84% | Training loss: 0.6870048466914643
Epoch: 45 | Iteration number: [3850/4518] 85% | Training loss: 0.6870080511446123
Epoch: 45 | Iteration number: [3860/4518] 85% | Training loss: 0.6870113929627473
Epoch: 45 | Iteration number: [3870/4518] 85% | Training loss: 0.6870075816331908
Epoch: 45 | Iteration number: [3880/4518] 85% | Training loss: 0.6870086102295168
Epoch: 45 | Iteration number: [3890/4518] 86% | Training loss: 0.6870062406234693
Epoch: 45 | Iteration number: [3900/4518] 86% | Training loss: 0.6870044920383356
Epoch: 45 | Iteration number: [3910/4518] 86% | Training loss: 0.6870001261039158
Epoch: 45 | Iteration number: [3920/4518] 86% | Training loss: 0.686998116954857
Epoch: 45 | Iteration number: [3930/4518] 86% | Training loss: 0.6869957043317741
Epoch: 45 | Iteration number: [3940/4518] 87% | Training loss: 0.6869958432646572
Epoch: 45 | Iteration number: [3950/4518] 87% | Training loss: 0.6869953934452202
Epoch: 45 | Iteration number: [3960/4518] 87% | Training loss: 0.686994088885158
Epoch: 45 | Iteration number: [3970/4518] 87% | Training loss: 0.6869940761354768
Epoch: 45 | Iteration number: [3980/4518] 88% | Training loss: 0.6869974736442518
Epoch: 45 | Iteration number: [3990/4518] 88% | Training loss: 0.68699881210363
Epoch: 45 | Iteration number: [4000/4518] 88% | Training loss: 0.6870011397600174
Epoch: 45 | Iteration number: [4010/4518] 88% | Training loss: 0.6869987223065107
Epoch: 45 | Iteration number: [4020/4518] 88% | Training loss: 0.6870001358920662
Epoch: 45 | Iteration number: [4030/4518] 89% | Training loss: 0.6869996154278739
Epoch: 45 | Iteration number: [4040/4518] 89% | Training loss: 0.6870015004631316
Epoch: 45 | Iteration number: [4050/4518] 89% | Training loss: 0.6869979813363817
Epoch: 45 | Iteration number: [4060/4518] 89% | Training loss: 0.6869981636261118
Epoch: 45 | Iteration number: [4070/4518] 90% | Training loss: 0.6869956057692629
Epoch: 45 | Iteration number: [4080/4518] 90% | Training loss: 0.6869966414044885
Epoch: 45 | Iteration number: [4090/4518] 90% | Training loss: 0.6869964394855033
Epoch: 45 | Iteration number: [4100/4518] 90% | Training loss: 0.6869938398715927
Epoch: 45 | Iteration number: [4110/4518] 90% | Training loss: 0.6869937348249765
Epoch: 45 | Iteration number: [4120/4518] 91% | Training loss: 0.686991929848796
Epoch: 45 | Iteration number: [4130/4518] 91% | Training loss: 0.6869911137995361
Epoch: 45 | Iteration number: [4140/4518] 91% | Training loss: 0.686993038409574
Epoch: 45 | Iteration number: [4150/4518] 91% | Training loss: 0.6869918853978076
Epoch: 45 | Iteration number: [4160/4518] 92% | Training loss: 0.6869939976013624
Epoch: 45 | Iteration number: [4170/4518] 92% | Training loss: 0.6869944939653364
Epoch: 45 | Iteration number: [4180/4518] 92% | Training loss: 0.6869930484648527
Epoch: 45 | Iteration number: [4190/4518] 92% | Training loss: 0.6869939257677529
Epoch: 45 | Iteration number: [4200/4518] 92% | Training loss: 0.6869958624243736
Epoch: 45 | Iteration number: [4210/4518] 93% | Training loss: 0.686992529438114
Epoch: 45 | Iteration number: [4220/4518] 93% | Training loss: 0.6869954797752661
Epoch: 45 | Iteration number: [4230/4518] 93% | Training loss: 0.6869972685409212
Epoch: 45 | Iteration number: [4240/4518] 93% | Training loss: 0.6869952526716692
Epoch: 45 | Iteration number: [4250/4518] 94% | Training loss: 0.6869937600388246
Epoch: 45 | Iteration number: [4260/4518] 94% | Training loss: 0.6869884265420583
Epoch: 45 | Iteration number: [4270/4518] 94% | Training loss: 0.6869877864521616
Epoch: 45 | Iteration number: [4280/4518] 94% | Training loss: 0.6869864227894311
Epoch: 45 | Iteration number: [4290/4518] 94% | Training loss: 0.6869868615151563
Epoch: 45 | Iteration number: [4300/4518] 95% | Training loss: 0.6869863689638848
Epoch: 45 | Iteration number: [4310/4518] 95% | Training loss: 0.6869866914926162
Epoch: 45 | Iteration number: [4320/4518] 95% | Training loss: 0.6869890383962128
Epoch: 45 | Iteration number: [4330/4518] 95% | Training loss: 0.6869878624245421
Epoch: 45 | Iteration number: [4340/4518] 96% | Training loss: 0.6869832398704669
Epoch: 45 | Iteration number: [4350/4518] 96% | Training loss: 0.6869799599839354
Epoch: 45 | Iteration number: [4360/4518] 96% | Training loss: 0.6869767658754227
Epoch: 45 | Iteration number: [4370/4518] 96% | Training loss: 0.6869780735102071
Epoch: 45 | Iteration number: [4380/4518] 96% | Training loss: 0.6869784577252114
Epoch: 45 | Iteration number: [4390/4518] 97% | Training loss: 0.6869782132684235
Epoch: 45 | Iteration number: [4400/4518] 97% | Training loss: 0.6869795471429825
Epoch: 45 | Iteration number: [4410/4518] 97% | Training loss: 0.6869776005106989
Epoch: 45 | Iteration number: [4420/4518] 97% | Training loss: 0.6869742547494794
Epoch: 45 | Iteration number: [4430/4518] 98% | Training loss: 0.6869735818011496
Epoch: 45 | Iteration number: [4440/4518] 98% | Training loss: 0.686975357715074
Epoch: 45 | Iteration number: [4450/4518] 98% | Training loss: 0.6869753897056151
Epoch: 45 | Iteration number: [4460/4518] 98% | Training loss: 0.686972408417629
Epoch: 45 | Iteration number: [4470/4518] 98% | Training loss: 0.6869692951240796
Epoch: 45 | Iteration number: [4480/4518] 99% | Training loss: 0.6869716993533075
Epoch: 45 | Iteration number: [4490/4518] 99% | Training loss: 0.6869696255383353
Epoch: 45 | Iteration number: [4500/4518] 99% | Training loss: 0.6869699380927615
Epoch: 45 | Iteration number: [4510/4518] 99% | Training loss: 0.6869693902009343

 End of epoch: 45 | Train Loss: 0.6868194099705321 | Training Time: 640 

 End of epoch: 45 | Eval Loss: 0.6899573316379469 | Evaluating Time: 17 
Epoch: 46 | Iteration number: [10/4518] 0% | Training loss: 0.7552572369575501
Epoch: 46 | Iteration number: [20/4518] 0% | Training loss: 0.7202069014310837
Epoch: 46 | Iteration number: [30/4518] 0% | Training loss: 0.7093598624070485
Epoch: 46 | Iteration number: [40/4518] 0% | Training loss: 0.7038936153054237
Epoch: 46 | Iteration number: [50/4518] 1% | Training loss: 0.700673371553421
Epoch: 46 | Iteration number: [60/4518] 1% | Training loss: 0.6985369225343069
Epoch: 46 | Iteration number: [70/4518] 1% | Training loss: 0.69694898383958
Epoch: 46 | Iteration number: [80/4518] 1% | Training loss: 0.6958063639700413
Epoch: 46 | Iteration number: [90/4518] 1% | Training loss: 0.6949058989683787
Epoch: 46 | Iteration number: [100/4518] 2% | Training loss: 0.6941371077299118
Epoch: 46 | Iteration number: [110/4518] 2% | Training loss: 0.6935577414252542
Epoch: 46 | Iteration number: [120/4518] 2% | Training loss: 0.693052539229393
Epoch: 46 | Iteration number: [130/4518] 2% | Training loss: 0.6924939283957848
Epoch: 46 | Iteration number: [140/4518] 3% | Training loss: 0.692083369408335
Epoch: 46 | Iteration number: [150/4518] 3% | Training loss: 0.691747161547343
Epoch: 46 | Iteration number: [160/4518] 3% | Training loss: 0.691445168480277
Epoch: 46 | Iteration number: [170/4518] 3% | Training loss: 0.691212794710608
Epoch: 46 | Iteration number: [180/4518] 3% | Training loss: 0.6909627808464898
Epoch: 46 | Iteration number: [190/4518] 4% | Training loss: 0.6906778150483182
Epoch: 46 | Iteration number: [200/4518] 4% | Training loss: 0.6905132606625557
Epoch: 46 | Iteration number: [210/4518] 4% | Training loss: 0.6903233230113983
Epoch: 46 | Iteration number: [220/4518] 4% | Training loss: 0.6901929126544433
Epoch: 46 | Iteration number: [230/4518] 5% | Training loss: 0.6900443693865901
Epoch: 46 | Iteration number: [240/4518] 5% | Training loss: 0.6899039747814337
Epoch: 46 | Iteration number: [250/4518] 5% | Training loss: 0.6898207428455353
Epoch: 46 | Iteration number: [260/4518] 5% | Training loss: 0.6897111099499923
Epoch: 46 | Iteration number: [270/4518] 5% | Training loss: 0.689588330410145
Epoch: 46 | Iteration number: [280/4518] 6% | Training loss: 0.6894543354000364
Epoch: 46 | Iteration number: [290/4518] 6% | Training loss: 0.6893794405049292
Epoch: 46 | Iteration number: [300/4518] 6% | Training loss: 0.6893126618862152
Epoch: 46 | Iteration number: [310/4518] 6% | Training loss: 0.6892998883801121
Epoch: 46 | Iteration number: [320/4518] 7% | Training loss: 0.6892140774056316
Epoch: 46 | Iteration number: [330/4518] 7% | Training loss: 0.6890917619069418
Epoch: 46 | Iteration number: [340/4518] 7% | Training loss: 0.6890466239522485
Epoch: 46 | Iteration number: [350/4518] 7% | Training loss: 0.6890129458904266
Epoch: 46 | Iteration number: [360/4518] 7% | Training loss: 0.6889390773243375
Epoch: 46 | Iteration number: [370/4518] 8% | Training loss: 0.688882334973361
Epoch: 46 | Iteration number: [380/4518] 8% | Training loss: 0.6888464645335549
Epoch: 46 | Iteration number: [390/4518] 8% | Training loss: 0.688792468339969
Epoch: 46 | Iteration number: [400/4518] 8% | Training loss: 0.6887011770904065
Epoch: 46 | Iteration number: [410/4518] 9% | Training loss: 0.6886517175814001
Epoch: 46 | Iteration number: [420/4518] 9% | Training loss: 0.6886374299015318
Epoch: 46 | Iteration number: [430/4518] 9% | Training loss: 0.688595407369525
Epoch: 46 | Iteration number: [440/4518] 9% | Training loss: 0.6885494783520698
Epoch: 46 | Iteration number: [450/4518] 9% | Training loss: 0.6884991141160329
Epoch: 46 | Iteration number: [460/4518] 10% | Training loss: 0.6884562813717386
Epoch: 46 | Iteration number: [470/4518] 10% | Training loss: 0.6884190451591573
Epoch: 46 | Iteration number: [480/4518] 10% | Training loss: 0.688364460815986
Epoch: 46 | Iteration number: [490/4518] 10% | Training loss: 0.6883115859664216
Epoch: 46 | Iteration number: [500/4518] 11% | Training loss: 0.6883008083105088
Epoch: 46 | Iteration number: [510/4518] 11% | Training loss: 0.6882576792847876
Epoch: 46 | Iteration number: [520/4518] 11% | Training loss: 0.6882102202910644
Epoch: 46 | Iteration number: [530/4518] 11% | Training loss: 0.6881602574069545
Epoch: 46 | Iteration number: [540/4518] 11% | Training loss: 0.6881187548240025
Epoch: 46 | Iteration number: [550/4518] 12% | Training loss: 0.6880795835364949
Epoch: 46 | Iteration number: [560/4518] 12% | Training loss: 0.6880531446209975
Epoch: 46 | Iteration number: [570/4518] 12% | Training loss: 0.6880398429276651
Epoch: 46 | Iteration number: [580/4518] 12% | Training loss: 0.6880037892481377
Epoch: 46 | Iteration number: [590/4518] 13% | Training loss: 0.6879937197192241
Epoch: 46 | Iteration number: [600/4518] 13% | Training loss: 0.6879830321669579
Epoch: 46 | Iteration number: [610/4518] 13% | Training loss: 0.6879673686183867
Epoch: 46 | Iteration number: [620/4518] 13% | Training loss: 0.6879571079246459
Epoch: 46 | Iteration number: [630/4518] 13% | Training loss: 0.6879372653507051
Epoch: 46 | Iteration number: [640/4518] 14% | Training loss: 0.6879162893630564
Epoch: 46 | Iteration number: [650/4518] 14% | Training loss: 0.6878930393549112
Epoch: 46 | Iteration number: [660/4518] 14% | Training loss: 0.6878837912371665
Epoch: 46 | Iteration number: [670/4518] 14% | Training loss: 0.6878587907819605
Epoch: 46 | Iteration number: [680/4518] 15% | Training loss: 0.6878428034046117
Epoch: 46 | Iteration number: [690/4518] 15% | Training loss: 0.6878193132255388
Epoch: 46 | Iteration number: [700/4518] 15% | Training loss: 0.687801097546305
Epoch: 46 | Iteration number: [710/4518] 15% | Training loss: 0.6877893352172744
Epoch: 46 | Iteration number: [720/4518] 15% | Training loss: 0.6877802211377356
Epoch: 46 | Iteration number: [730/4518] 16% | Training loss: 0.6877649269691886
Epoch: 46 | Iteration number: [740/4518] 16% | Training loss: 0.6877594487087146
Epoch: 46 | Iteration number: [750/4518] 16% | Training loss: 0.687739573876063
Epoch: 46 | Iteration number: [760/4518] 16% | Training loss: 0.6877310337988953
Epoch: 46 | Iteration number: [770/4518] 17% | Training loss: 0.687714901760027
Epoch: 46 | Iteration number: [780/4518] 17% | Training loss: 0.6876943364357337
Epoch: 46 | Iteration number: [790/4518] 17% | Training loss: 0.6876614981059787
Epoch: 46 | Iteration number: [800/4518] 17% | Training loss: 0.6876625242084264
Epoch: 46 | Iteration number: [810/4518] 17% | Training loss: 0.6876542695510535
Epoch: 46 | Iteration number: [820/4518] 18% | Training loss: 0.6876462807015675
Epoch: 46 | Iteration number: [830/4518] 18% | Training loss: 0.6876385716070612
Epoch: 46 | Iteration number: [840/4518] 18% | Training loss: 0.6876239555222647
Epoch: 46 | Iteration number: [850/4518] 18% | Training loss: 0.6876208890185637
Epoch: 46 | Iteration number: [860/4518] 19% | Training loss: 0.6876078561987988
Epoch: 46 | Iteration number: [870/4518] 19% | Training loss: 0.6875843598239724
Epoch: 46 | Iteration number: [880/4518] 19% | Training loss: 0.6875692687251351
Epoch: 46 | Iteration number: [890/4518] 19% | Training loss: 0.6875682290350453
Epoch: 46 | Iteration number: [900/4518] 19% | Training loss: 0.6875644450055228
Epoch: 46 | Iteration number: [910/4518] 20% | Training loss: 0.6875527776204623
Epoch: 46 | Iteration number: [920/4518] 20% | Training loss: 0.6875388730479324
Epoch: 46 | Iteration number: [930/4518] 20% | Training loss: 0.6875390573214459
Epoch: 46 | Iteration number: [940/4518] 20% | Training loss: 0.6875297352354577
Epoch: 46 | Iteration number: [950/4518] 21% | Training loss: 0.6875353829484236
Epoch: 46 | Iteration number: [960/4518] 21% | Training loss: 0.6875366466119885
Epoch: 46 | Iteration number: [970/4518] 21% | Training loss: 0.6875350624630132
Epoch: 46 | Iteration number: [980/4518] 21% | Training loss: 0.6875317223218023
Epoch: 46 | Iteration number: [990/4518] 21% | Training loss: 0.6875224691448789
Epoch: 46 | Iteration number: [1000/4518] 22% | Training loss: 0.6875295708179474
Epoch: 46 | Iteration number: [1010/4518] 22% | Training loss: 0.6875321627843498
Epoch: 46 | Iteration number: [1020/4518] 22% | Training loss: 0.6875206445362053
Epoch: 46 | Iteration number: [1030/4518] 22% | Training loss: 0.687523785378169
Epoch: 46 | Iteration number: [1040/4518] 23% | Training loss: 0.687519978101437
Epoch: 46 | Iteration number: [1050/4518] 23% | Training loss: 0.687519557362511
Epoch: 46 | Iteration number: [1060/4518] 23% | Training loss: 0.6875081076374594
Epoch: 46 | Iteration number: [1070/4518] 23% | Training loss: 0.6875055319794985
Epoch: 46 | Iteration number: [1080/4518] 23% | Training loss: 0.6875044869052039
Epoch: 46 | Iteration number: [1090/4518] 24% | Training loss: 0.6874925259603273
Epoch: 46 | Iteration number: [1100/4518] 24% | Training loss: 0.6874794892831282
Epoch: 46 | Iteration number: [1110/4518] 24% | Training loss: 0.6874711341686077
Epoch: 46 | Iteration number: [1120/4518] 24% | Training loss: 0.6874609483139855
Epoch: 46 | Iteration number: [1130/4518] 25% | Training loss: 0.6874502775943385
Epoch: 46 | Iteration number: [1140/4518] 25% | Training loss: 0.6874477691817702
Epoch: 46 | Iteration number: [1150/4518] 25% | Training loss: 0.6874379467964172
Epoch: 46 | Iteration number: [1160/4518] 25% | Training loss: 0.6874348219612549
Epoch: 46 | Iteration number: [1170/4518] 25% | Training loss: 0.6874390585809691
Epoch: 46 | Iteration number: [1180/4518] 26% | Training loss: 0.6874346121387966
Epoch: 46 | Iteration number: [1190/4518] 26% | Training loss: 0.6874344082940527
Epoch: 46 | Iteration number: [1200/4518] 26% | Training loss: 0.6874366302788257
Epoch: 46 | Iteration number: [1210/4518] 26% | Training loss: 0.6874243692425657
Epoch: 46 | Iteration number: [1220/4518] 27% | Training loss: 0.6874183889295234
Epoch: 46 | Iteration number: [1230/4518] 27% | Training loss: 0.6874117236311843
Epoch: 46 | Iteration number: [1240/4518] 27% | Training loss: 0.6874018473971275
Epoch: 46 | Iteration number: [1250/4518] 27% | Training loss: 0.687387073802948
Epoch: 46 | Iteration number: [1260/4518] 27% | Training loss: 0.6873830595659831
Epoch: 46 | Iteration number: [1270/4518] 28% | Training loss: 0.6873718568189876
Epoch: 46 | Iteration number: [1280/4518] 28% | Training loss: 0.687369648180902
Epoch: 46 | Iteration number: [1290/4518] 28% | Training loss: 0.6873657502869303
Epoch: 46 | Iteration number: [1300/4518] 28% | Training loss: 0.687350652217865
Epoch: 46 | Iteration number: [1310/4518] 28% | Training loss: 0.6873473682931361
Epoch: 46 | Iteration number: [1320/4518] 29% | Training loss: 0.6873501263784639
Epoch: 46 | Iteration number: [1330/4518] 29% | Training loss: 0.6873442068135828
Epoch: 46 | Iteration number: [1340/4518] 29% | Training loss: 0.6873332042302658
Epoch: 46 | Iteration number: [1350/4518] 29% | Training loss: 0.6873439153918514
Epoch: 46 | Iteration number: [1360/4518] 30% | Training loss: 0.6873400819652221
Epoch: 46 | Iteration number: [1370/4518] 30% | Training loss: 0.6873413402668751
Epoch: 46 | Iteration number: [1380/4518] 30% | Training loss: 0.6873502553805061
Epoch: 46 | Iteration number: [1390/4518] 30% | Training loss: 0.6873497923072294
Epoch: 46 | Iteration number: [1400/4518] 30% | Training loss: 0.6873441269568035
Epoch: 46 | Iteration number: [1410/4518] 31% | Training loss: 0.6873408550911762
Epoch: 46 | Iteration number: [1420/4518] 31% | Training loss: 0.6873398424873889
Epoch: 46 | Iteration number: [1430/4518] 31% | Training loss: 0.687338917238729
Epoch: 46 | Iteration number: [1440/4518] 31% | Training loss: 0.6873343818717532
Epoch: 46 | Iteration number: [1450/4518] 32% | Training loss: 0.6873258524516533
Epoch: 46 | Iteration number: [1460/4518] 32% | Training loss: 0.6873269359542898
Epoch: 46 | Iteration number: [1470/4518] 32% | Training loss: 0.6873294805588366
Epoch: 46 | Iteration number: [1480/4518] 32% | Training loss: 0.6873265639350221
Epoch: 46 | Iteration number: [1490/4518] 32% | Training loss: 0.6873285765215854
Epoch: 46 | Iteration number: [1500/4518] 33% | Training loss: 0.6873256126244863
Epoch: 46 | Iteration number: [1510/4518] 33% | Training loss: 0.6873198841976014
Epoch: 46 | Iteration number: [1520/4518] 33% | Training loss: 0.6873148609933101
Epoch: 46 | Iteration number: [1530/4518] 33% | Training loss: 0.6873099582647186
Epoch: 46 | Iteration number: [1540/4518] 34% | Training loss: 0.6872985376553102
Epoch: 46 | Iteration number: [1550/4518] 34% | Training loss: 0.6873066299576913
Epoch: 46 | Iteration number: [1560/4518] 34% | Training loss: 0.6873057263019757
Epoch: 46 | Iteration number: [1570/4518] 34% | Training loss: 0.687304401853282
Epoch: 46 | Iteration number: [1580/4518] 34% | Training loss: 0.6872987116439433
Epoch: 46 | Iteration number: [1590/4518] 35% | Training loss: 0.6872973372351449
Epoch: 46 | Iteration number: [1600/4518] 35% | Training loss: 0.687289594002068
Epoch: 46 | Iteration number: [1610/4518] 35% | Training loss: 0.6872925972716408
Epoch: 46 | Iteration number: [1620/4518] 35% | Training loss: 0.6872867862383525
Epoch: 46 | Iteration number: [1630/4518] 36% | Training loss: 0.6872766465497163
Epoch: 46 | Iteration number: [1640/4518] 36% | Training loss: 0.6872793624313867
Epoch: 46 | Iteration number: [1650/4518] 36% | Training loss: 0.6872757305520953
Epoch: 46 | Iteration number: [1660/4518] 36% | Training loss: 0.6872750549072243
Epoch: 46 | Iteration number: [1670/4518] 36% | Training loss: 0.6872774632391102
Epoch: 46 | Iteration number: [1680/4518] 37% | Training loss: 0.6872712219754855
Epoch: 46 | Iteration number: [1690/4518] 37% | Training loss: 0.6872701255174783
Epoch: 46 | Iteration number: [1700/4518] 37% | Training loss: 0.6872720371625003
Epoch: 46 | Iteration number: [1710/4518] 37% | Training loss: 0.6872713269197452
Epoch: 46 | Iteration number: [1720/4518] 38% | Training loss: 0.6872670756176461
Epoch: 46 | Iteration number: [1730/4518] 38% | Training loss: 0.6872589375242333
Epoch: 46 | Iteration number: [1740/4518] 38% | Training loss: 0.6872580078141443
Epoch: 46 | Iteration number: [1750/4518] 38% | Training loss: 0.6872533929007394
Epoch: 46 | Iteration number: [1760/4518] 38% | Training loss: 0.6872593916613947
Epoch: 46 | Iteration number: [1770/4518] 39% | Training loss: 0.6872602897848786
Epoch: 46 | Iteration number: [1780/4518] 39% | Training loss: 0.687263972370812
Epoch: 46 | Iteration number: [1790/4518] 39% | Training loss: 0.687264709732386
Epoch: 46 | Iteration number: [1800/4518] 39% | Training loss: 0.687269088294771
Epoch: 46 | Iteration number: [1810/4518] 40% | Training loss: 0.6872715193922349
Epoch: 46 | Iteration number: [1820/4518] 40% | Training loss: 0.6872721021319483
Epoch: 46 | Iteration number: [1830/4518] 40% | Training loss: 0.6872752182144937
Epoch: 46 | Iteration number: [1840/4518] 40% | Training loss: 0.6872738174446251
Epoch: 46 | Iteration number: [1850/4518] 40% | Training loss: 0.6872691958981592
Epoch: 46 | Iteration number: [1860/4518] 41% | Training loss: 0.6872618356699585
Epoch: 46 | Iteration number: [1870/4518] 41% | Training loss: 0.6872563108722156
Epoch: 46 | Iteration number: [1880/4518] 41% | Training loss: 0.687253465170556
Epoch: 46 | Iteration number: [1890/4518] 41% | Training loss: 0.6872447019846982
Epoch: 46 | Iteration number: [1900/4518] 42% | Training loss: 0.6872384038410688
Epoch: 46 | Iteration number: [1910/4518] 42% | Training loss: 0.6872403118622865
Epoch: 46 | Iteration number: [1920/4518] 42% | Training loss: 0.6872350986115634
Epoch: 46 | Iteration number: [1930/4518] 42% | Training loss: 0.6872339388558284
Epoch: 46 | Iteration number: [1940/4518] 42% | Training loss: 0.687235566820066
Epoch: 46 | Iteration number: [1950/4518] 43% | Training loss: 0.6872361932045374
Epoch: 46 | Iteration number: [1960/4518] 43% | Training loss: 0.6872361451995616
Epoch: 46 | Iteration number: [1970/4518] 43% | Training loss: 0.6872355610283498
Epoch: 46 | Iteration number: [1980/4518] 43% | Training loss: 0.6872370949598274
Epoch: 46 | Iteration number: [1990/4518] 44% | Training loss: 0.6872388989482093
Epoch: 46 | Iteration number: [2000/4518] 44% | Training loss: 0.687238774061203
Epoch: 46 | Iteration number: [2010/4518] 44% | Training loss: 0.6872341562562914
Epoch: 46 | Iteration number: [2020/4518] 44% | Training loss: 0.6872342385868034
Epoch: 46 | Iteration number: [2030/4518] 44% | Training loss: 0.6872284804952555
Epoch: 46 | Iteration number: [2040/4518] 45% | Training loss: 0.6872214135293867
Epoch: 46 | Iteration number: [2050/4518] 45% | Training loss: 0.6872188225897347
Epoch: 46 | Iteration number: [2060/4518] 45% | Training loss: 0.6872116727447046
Epoch: 46 | Iteration number: [2070/4518] 45% | Training loss: 0.687203152715296
Epoch: 46 | Iteration number: [2080/4518] 46% | Training loss: 0.6872054074532711
Epoch: 46 | Iteration number: [2090/4518] 46% | Training loss: 0.6872015495619705
Epoch: 46 | Iteration number: [2100/4518] 46% | Training loss: 0.6871983175050644
Epoch: 46 | Iteration number: [2110/4518] 46% | Training loss: 0.6871988748204652
Epoch: 46 | Iteration number: [2120/4518] 46% | Training loss: 0.6871903802145202
Epoch: 46 | Iteration number: [2130/4518] 47% | Training loss: 0.6871931458023233
Epoch: 46 | Iteration number: [2140/4518] 47% | Training loss: 0.6871852076777788
Epoch: 46 | Iteration number: [2150/4518] 47% | Training loss: 0.6871833259560342
Epoch: 46 | Iteration number: [2160/4518] 47% | Training loss: 0.6871862370106909
Epoch: 46 | Iteration number: [2170/4518] 48% | Training loss: 0.6871790177811126
Epoch: 46 | Iteration number: [2180/4518] 48% | Training loss: 0.6871731355376199
Epoch: 46 | Iteration number: [2190/4518] 48% | Training loss: 0.6871723584932824
Epoch: 46 | Iteration number: [2200/4518] 48% | Training loss: 0.6871704117276451
Epoch: 46 | Iteration number: [2210/4518] 48% | Training loss: 0.6871736012972318
Epoch: 46 | Iteration number: [2220/4518] 49% | Training loss: 0.6871679126410871
Epoch: 46 | Iteration number: [2230/4518] 49% | Training loss: 0.687171058510451
Epoch: 46 | Iteration number: [2240/4518] 49% | Training loss: 0.6871654987335205
Epoch: 46 | Iteration number: [2250/4518] 49% | Training loss: 0.6871669335895114
Epoch: 46 | Iteration number: [2260/4518] 50% | Training loss: 0.6871706171900825
Epoch: 46 | Iteration number: [2270/4518] 50% | Training loss: 0.6871668836618835
Epoch: 46 | Iteration number: [2280/4518] 50% | Training loss: 0.6871723067603613
Epoch: 46 | Iteration number: [2290/4518] 50% | Training loss: 0.6871704020094143
Epoch: 46 | Iteration number: [2300/4518] 50% | Training loss: 0.6871694366828255
Epoch: 46 | Iteration number: [2310/4518] 51% | Training loss: 0.6871660993728803
Epoch: 46 | Iteration number: [2320/4518] 51% | Training loss: 0.6871559163619732
Epoch: 46 | Iteration number: [2330/4518] 51% | Training loss: 0.6871546859904932
Epoch: 46 | Iteration number: [2340/4518] 51% | Training loss: 0.6871522473983276
Epoch: 46 | Iteration number: [2350/4518] 52% | Training loss: 0.6871484490658375
Epoch: 46 | Iteration number: [2360/4518] 52% | Training loss: 0.6871492148708489
Epoch: 46 | Iteration number: [2370/4518] 52% | Training loss: 0.6871436159319012
Epoch: 46 | Iteration number: [2380/4518] 52% | Training loss: 0.687131067334103
Epoch: 46 | Iteration number: [2390/4518] 52% | Training loss: 0.687130379701758
Epoch: 46 | Iteration number: [2400/4518] 53% | Training loss: 0.6871335838238398
Epoch: 46 | Iteration number: [2410/4518] 53% | Training loss: 0.6871306764386996
Epoch: 46 | Iteration number: [2420/4518] 53% | Training loss: 0.687131036116072
Epoch: 46 | Iteration number: [2430/4518] 53% | Training loss: 0.6871293104725119
Epoch: 46 | Iteration number: [2440/4518] 54% | Training loss: 0.6871270479237447
Epoch: 46 | Iteration number: [2450/4518] 54% | Training loss: 0.6871287595982454
Epoch: 46 | Iteration number: [2460/4518] 54% | Training loss: 0.6871243927052351
Epoch: 46 | Iteration number: [2470/4518] 54% | Training loss: 0.6871224771385733
Epoch: 46 | Iteration number: [2480/4518] 54% | Training loss: 0.6871221847351521
Epoch: 46 | Iteration number: [2490/4518] 55% | Training loss: 0.6871178917137973
Epoch: 46 | Iteration number: [2500/4518] 55% | Training loss: 0.6871231250762939
Epoch: 46 | Iteration number: [2510/4518] 55% | Training loss: 0.687121362823889
Epoch: 46 | Iteration number: [2520/4518] 55% | Training loss: 0.687118374071424
Epoch: 46 | Iteration number: [2530/4518] 55% | Training loss: 0.6871104890414378
Epoch: 46 | Iteration number: [2540/4518] 56% | Training loss: 0.6871112317785504
Epoch: 46 | Iteration number: [2550/4518] 56% | Training loss: 0.6871136512943342
Epoch: 46 | Iteration number: [2560/4518] 56% | Training loss: 0.6871091575361788
Epoch: 46 | Iteration number: [2570/4518] 56% | Training loss: 0.6871069608495393
Epoch: 46 | Iteration number: [2580/4518] 57% | Training loss: 0.6871101677879806
Epoch: 46 | Iteration number: [2590/4518] 57% | Training loss: 0.6871126315998755
Epoch: 46 | Iteration number: [2600/4518] 57% | Training loss: 0.6871123169477169
Epoch: 46 | Iteration number: [2610/4518] 57% | Training loss: 0.6871168150298896
Epoch: 46 | Iteration number: [2620/4518] 57% | Training loss: 0.6871164257972295
Epoch: 46 | Iteration number: [2630/4518] 58% | Training loss: 0.6871165502887262
Epoch: 46 | Iteration number: [2640/4518] 58% | Training loss: 0.6871150741522962
Epoch: 46 | Iteration number: [2650/4518] 58% | Training loss: 0.6871178979918642
Epoch: 46 | Iteration number: [2660/4518] 58% | Training loss: 0.6871121752306931
Epoch: 46 | Iteration number: [2670/4518] 59% | Training loss: 0.6871132365326756
Epoch: 46 | Iteration number: [2680/4518] 59% | Training loss: 0.6871075048820297
Epoch: 46 | Iteration number: [2690/4518] 59% | Training loss: 0.6871095102072649
Epoch: 46 | Iteration number: [2700/4518] 59% | Training loss: 0.6871019898299817
Epoch: 46 | Iteration number: [2710/4518] 59% | Training loss: 0.6871030157562551
Epoch: 46 | Iteration number: [2720/4518] 60% | Training loss: 0.6871050885275883
Epoch: 46 | Iteration number: [2730/4518] 60% | Training loss: 0.6871075293301663
Epoch: 46 | Iteration number: [2740/4518] 60% | Training loss: 0.6871073772654916
Epoch: 46 | Iteration number: [2750/4518] 60% | Training loss: 0.6871050985292955
Epoch: 46 | Iteration number: [2760/4518] 61% | Training loss: 0.6871056884743165
Epoch: 46 | Iteration number: [2770/4518] 61% | Training loss: 0.6871021180807038
Epoch: 46 | Iteration number: [2780/4518] 61% | Training loss: 0.6871025936637851
Epoch: 46 | Iteration number: [2790/4518] 61% | Training loss: 0.6870995892632392
Epoch: 46 | Iteration number: [2800/4518] 61% | Training loss: 0.6870942195185593
Epoch: 46 | Iteration number: [2810/4518] 62% | Training loss: 0.687092626879648
Epoch: 46 | Iteration number: [2820/4518] 62% | Training loss: 0.6870866596910125
Epoch: 46 | Iteration number: [2830/4518] 62% | Training loss: 0.6870816293537827
Epoch: 46 | Iteration number: [2840/4518] 62% | Training loss: 0.6870798001406898
Epoch: 46 | Iteration number: [2850/4518] 63% | Training loss: 0.6870809391088653
Epoch: 46 | Iteration number: [2860/4518] 63% | Training loss: 0.6870817351174521
Epoch: 46 | Iteration number: [2870/4518] 63% | Training loss: 0.6870802570510824
Epoch: 46 | Iteration number: [2880/4518] 63% | Training loss: 0.6870792505020896
Epoch: 46 | Iteration number: [2890/4518] 63% | Training loss: 0.6870718581659984
Epoch: 46 | Iteration number: [2900/4518] 64% | Training loss: 0.6870720109240762
Epoch: 46 | Iteration number: [2910/4518] 64% | Training loss: 0.687072473866833
Epoch: 46 | Iteration number: [2920/4518] 64% | Training loss: 0.6870630118740748
Epoch: 46 | Iteration number: [2930/4518] 64% | Training loss: 0.6870543030138309
Epoch: 46 | Iteration number: [2940/4518] 65% | Training loss: 0.6870561466127837
Epoch: 46 | Iteration number: [2950/4518] 65% | Training loss: 0.6870568979392617
Epoch: 46 | Iteration number: [2960/4518] 65% | Training loss: 0.687054515207136
Epoch: 46 | Iteration number: [2970/4518] 65% | Training loss: 0.6870582223941982
Epoch: 46 | Iteration number: [2980/4518] 65% | Training loss: 0.687054430578379
Epoch: 46 | Iteration number: [2990/4518] 66% | Training loss: 0.687051302154726
Epoch: 46 | Iteration number: [3000/4518] 66% | Training loss: 0.6870577827890714
Epoch: 46 | Iteration number: [3010/4518] 66% | Training loss: 0.687058490296931
Epoch: 46 | Iteration number: [3020/4518] 66% | Training loss: 0.6870520067925485
Epoch: 46 | Iteration number: [3030/4518] 67% | Training loss: 0.687055375532742
Epoch: 46 | Iteration number: [3040/4518] 67% | Training loss: 0.6870574830001906
Epoch: 46 | Iteration number: [3050/4518] 67% | Training loss: 0.6870586494930455
Epoch: 46 | Iteration number: [3060/4518] 67% | Training loss: 0.6870568036253936
Epoch: 46 | Iteration number: [3070/4518] 67% | Training loss: 0.6870544628716447
Epoch: 46 | Iteration number: [3080/4518] 68% | Training loss: 0.6870559054729226
Epoch: 46 | Iteration number: [3090/4518] 68% | Training loss: 0.6870515634519768
Epoch: 46 | Iteration number: [3100/4518] 68% | Training loss: 0.6870482984281355
Epoch: 46 | Iteration number: [3110/4518] 68% | Training loss: 0.6870442074019809
Epoch: 46 | Iteration number: [3120/4518] 69% | Training loss: 0.6870452247368983
Epoch: 46 | Iteration number: [3130/4518] 69% | Training loss: 0.6870429543070138
Epoch: 46 | Iteration number: [3140/4518] 69% | Training loss: 0.6870448135836109
Epoch: 46 | Iteration number: [3150/4518] 69% | Training loss: 0.687046001127788
Epoch: 46 | Iteration number: [3160/4518] 69% | Training loss: 0.6870456062162978
Epoch: 46 | Iteration number: [3170/4518] 70% | Training loss: 0.6870385170735019
Epoch: 46 | Iteration number: [3180/4518] 70% | Training loss: 0.6870355650313995
Epoch: 46 | Iteration number: [3190/4518] 70% | Training loss: 0.687037358351262
Epoch: 46 | Iteration number: [3200/4518] 70% | Training loss: 0.6870392300188541
Epoch: 46 | Iteration number: [3210/4518] 71% | Training loss: 0.6870378998766807
Epoch: 46 | Iteration number: [3220/4518] 71% | Training loss: 0.687037000633915
Epoch: 46 | Iteration number: [3230/4518] 71% | Training loss: 0.687034634355421
Epoch: 46 | Iteration number: [3240/4518] 71% | Training loss: 0.6870340709333067
Epoch: 46 | Iteration number: [3250/4518] 71% | Training loss: 0.6870335579652053
Epoch: 46 | Iteration number: [3260/4518] 72% | Training loss: 0.6870307672974522
Epoch: 46 | Iteration number: [3270/4518] 72% | Training loss: 0.6870331649568832
Epoch: 46 | Iteration number: [3280/4518] 72% | Training loss: 0.6870320553278051
Epoch: 46 | Iteration number: [3290/4518] 72% | Training loss: 0.6870328024346778
Epoch: 46 | Iteration number: [3300/4518] 73% | Training loss: 0.6870326816855055
Epoch: 46 | Iteration number: [3310/4518] 73% | Training loss: 0.6870323970058534
Epoch: 46 | Iteration number: [3320/4518] 73% | Training loss: 0.6870349880981158
Epoch: 46 | Iteration number: [3330/4518] 73% | Training loss: 0.6870344232331526
Epoch: 46 | Iteration number: [3340/4518] 73% | Training loss: 0.6870324996774068
Epoch: 46 | Iteration number: [3350/4518] 74% | Training loss: 0.6870289956633724
Epoch: 46 | Iteration number: [3360/4518] 74% | Training loss: 0.6870282686714615
Epoch: 46 | Iteration number: [3370/4518] 74% | Training loss: 0.6870266932408251
Epoch: 46 | Iteration number: [3380/4518] 74% | Training loss: 0.6870245898087349
Epoch: 46 | Iteration number: [3390/4518] 75% | Training loss: 0.687023458333142
Epoch: 46 | Iteration number: [3400/4518] 75% | Training loss: 0.6870189417986309
Epoch: 46 | Iteration number: [3410/4518] 75% | Training loss: 0.6870150901879732
Epoch: 46 | Iteration number: [3420/4518] 75% | Training loss: 0.6870157953939939
Epoch: 46 | Iteration number: [3430/4518] 75% | Training loss: 0.6870119210582433
Epoch: 46 | Iteration number: [3440/4518] 76% | Training loss: 0.6870133969153083
Epoch: 46 | Iteration number: [3450/4518] 76% | Training loss: 0.687007779021194
Epoch: 46 | Iteration number: [3460/4518] 76% | Training loss: 0.6870109051121452
Epoch: 46 | Iteration number: [3470/4518] 76% | Training loss: 0.6870097653666559
Epoch: 46 | Iteration number: [3480/4518] 77% | Training loss: 0.6870077282532878
Epoch: 46 | Iteration number: [3490/4518] 77% | Training loss: 0.6870103650755732
Epoch: 46 | Iteration number: [3500/4518] 77% | Training loss: 0.6870121183906283
Epoch: 46 | Iteration number: [3510/4518] 77% | Training loss: 0.6870095887754717
Epoch: 46 | Iteration number: [3520/4518] 77% | Training loss: 0.6870138054544276
Epoch: 46 | Iteration number: [3530/4518] 78% | Training loss: 0.6870135574941932
Epoch: 46 | Iteration number: [3540/4518] 78% | Training loss: 0.687009078533636
Epoch: 46 | Iteration number: [3550/4518] 78% | Training loss: 0.6870110994157657
Epoch: 46 | Iteration number: [3560/4518] 78% | Training loss: 0.6870090851623021
Epoch: 46 | Iteration number: [3570/4518] 79% | Training loss: 0.6870049728565857
Epoch: 46 | Iteration number: [3580/4518] 79% | Training loss: 0.6869996218042
Epoch: 46 | Iteration number: [3590/4518] 79% | Training loss: 0.6869973686080125
Epoch: 46 | Iteration number: [3600/4518] 79% | Training loss: 0.6869973623587026
Epoch: 46 | Iteration number: [3610/4518] 79% | Training loss: 0.68699722894341
Epoch: 46 | Iteration number: [3620/4518] 80% | Training loss: 0.6869957512913488
Epoch: 46 | Iteration number: [3630/4518] 80% | Training loss: 0.6869938405420498
Epoch: 46 | Iteration number: [3640/4518] 80% | Training loss: 0.6869883027050522
Epoch: 46 | Iteration number: [3650/4518] 80% | Training loss: 0.6869898854053184
Epoch: 46 | Iteration number: [3660/4518] 81% | Training loss: 0.6869884326972596
Epoch: 46 | Iteration number: [3670/4518] 81% | Training loss: 0.6869913926403919
Epoch: 46 | Iteration number: [3680/4518] 81% | Training loss: 0.6869942252726658
Epoch: 46 | Iteration number: [3690/4518] 81% | Training loss: 0.6869931272051845
Epoch: 46 | Iteration number: [3700/4518] 81% | Training loss: 0.6869927497328938
Epoch: 46 | Iteration number: [3710/4518] 82% | Training loss: 0.6869955230915964
Epoch: 46 | Iteration number: [3720/4518] 82% | Training loss: 0.6869920586225807
Epoch: 46 | Iteration number: [3730/4518] 82% | Training loss: 0.6869928165511215
Epoch: 46 | Iteration number: [3740/4518] 82% | Training loss: 0.6869927562175587
Epoch: 46 | Iteration number: [3750/4518] 83% | Training loss: 0.6869913187344869
Epoch: 46 | Iteration number: [3760/4518] 83% | Training loss: 0.6869947529853658
Epoch: 46 | Iteration number: [3770/4518] 83% | Training loss: 0.6869979018083618
Epoch: 46 | Iteration number: [3780/4518] 83% | Training loss: 0.686993698578663
Epoch: 46 | Iteration number: [3790/4518] 83% | Training loss: 0.6869909998923933
Epoch: 46 | Iteration number: [3800/4518] 84% | Training loss: 0.6869947510487155
Epoch: 46 | Iteration number: [3810/4518] 84% | Training loss: 0.6869902031002395
Epoch: 46 | Iteration number: [3820/4518] 84% | Training loss: 0.6869899149184452
Epoch: 46 | Iteration number: [3830/4518] 84% | Training loss: 0.6869887124931844
Epoch: 46 | Iteration number: [3840/4518] 84% | Training loss: 0.6869926184571038
Epoch: 46 | Iteration number: [3850/4518] 85% | Training loss: 0.6869933064262588
Epoch: 46 | Iteration number: [3860/4518] 85% | Training loss: 0.6869932877121812
Epoch: 46 | Iteration number: [3870/4518] 85% | Training loss: 0.6869925628952894
Epoch: 46 | Iteration number: [3880/4518] 85% | Training loss: 0.6869933065372644
Epoch: 46 | Iteration number: [3890/4518] 86% | Training loss: 0.686992665443445
Epoch: 46 | Iteration number: [3900/4518] 86% | Training loss: 0.6869924380687567
Epoch: 46 | Iteration number: [3910/4518] 86% | Training loss: 0.686991810005949
Epoch: 46 | Iteration number: [3920/4518] 86% | Training loss: 0.6869903244990475
Epoch: 46 | Iteration number: [3930/4518] 86% | Training loss: 0.6869915398174267
Epoch: 46 | Iteration number: [3940/4518] 87% | Training loss: 0.6869913891638596
Epoch: 46 | Iteration number: [3950/4518] 87% | Training loss: 0.6869908420949042
Epoch: 46 | Iteration number: [3960/4518] 87% | Training loss: 0.6869915836989278
Epoch: 46 | Iteration number: [3970/4518] 87% | Training loss: 0.6869894127701632
Epoch: 46 | Iteration number: [3980/4518] 88% | Training loss: 0.6869871231329501
Epoch: 46 | Iteration number: [3990/4518] 88% | Training loss: 0.6869855653671991
Epoch: 46 | Iteration number: [4000/4518] 88% | Training loss: 0.6869850426018238
Epoch: 46 | Iteration number: [4010/4518] 88% | Training loss: 0.6869829546483674
Epoch: 46 | Iteration number: [4020/4518] 88% | Training loss: 0.6869808650580211
Epoch: 46 | Iteration number: [4030/4518] 89% | Training loss: 0.6869819716247673
Epoch: 46 | Iteration number: [4040/4518] 89% | Training loss: 0.6869798335993644
Epoch: 46 | Iteration number: [4050/4518] 89% | Training loss: 0.6869755844127985
Epoch: 46 | Iteration number: [4060/4518] 89% | Training loss: 0.6869759682804493
Epoch: 46 | Iteration number: [4070/4518] 90% | Training loss: 0.6869740104646003
Epoch: 46 | Iteration number: [4080/4518] 90% | Training loss: 0.6869726032456931
Epoch: 46 | Iteration number: [4090/4518] 90% | Training loss: 0.686971748341558
Epoch: 46 | Iteration number: [4100/4518] 90% | Training loss: 0.6869717890460316
Epoch: 46 | Iteration number: [4110/4518] 90% | Training loss: 0.6869739657625955
Epoch: 46 | Iteration number: [4120/4518] 91% | Training loss: 0.6869762723307008
Epoch: 46 | Iteration number: [4130/4518] 91% | Training loss: 0.6869782713077259
Epoch: 46 | Iteration number: [4140/4518] 91% | Training loss: 0.6869761859737157
Epoch: 46 | Iteration number: [4150/4518] 91% | Training loss: 0.6869769628220294
Epoch: 46 | Iteration number: [4160/4518] 92% | Training loss: 0.6869761541915628
Epoch: 46 | Iteration number: [4170/4518] 92% | Training loss: 0.6869768668135865
Epoch: 46 | Iteration number: [4180/4518] 92% | Training loss: 0.6869778813072369
Epoch: 46 | Iteration number: [4190/4518] 92% | Training loss: 0.6869791666334739
Epoch: 46 | Iteration number: [4200/4518] 92% | Training loss: 0.6869793329636256
Epoch: 46 | Iteration number: [4210/4518] 93% | Training loss: 0.6869789140241446
Epoch: 46 | Iteration number: [4220/4518] 93% | Training loss: 0.6869768244395323
Epoch: 46 | Iteration number: [4230/4518] 93% | Training loss: 0.6869732451917996
Epoch: 46 | Iteration number: [4240/4518] 93% | Training loss: 0.6869729787251859
Epoch: 46 | Iteration number: [4250/4518] 94% | Training loss: 0.6869745501910939
Epoch: 46 | Iteration number: [4260/4518] 94% | Training loss: 0.6869711272733312
Epoch: 46 | Iteration number: [4270/4518] 94% | Training loss: 0.6869713907917434
Epoch: 46 | Iteration number: [4280/4518] 94% | Training loss: 0.6869714490721159
Epoch: 46 | Iteration number: [4290/4518] 94% | Training loss: 0.686970109456069
Epoch: 46 | Iteration number: [4300/4518] 95% | Training loss: 0.6869657230654428
Epoch: 46 | Iteration number: [4310/4518] 95% | Training loss: 0.6869681201512189
Epoch: 46 | Iteration number: [4320/4518] 95% | Training loss: 0.686968305044704
Epoch: 46 | Iteration number: [4330/4518] 95% | Training loss: 0.6869682177109752
Epoch: 46 | Iteration number: [4340/4518] 96% | Training loss: 0.686968854907471
Epoch: 46 | Iteration number: [4350/4518] 96% | Training loss: 0.6869685002579086
Epoch: 46 | Iteration number: [4360/4518] 96% | Training loss: 0.6869684279648536
Epoch: 46 | Iteration number: [4370/4518] 96% | Training loss: 0.6869677466986108
Epoch: 46 | Iteration number: [4380/4518] 96% | Training loss: 0.6869689646921201
Epoch: 46 | Iteration number: [4390/4518] 97% | Training loss: 0.6869692295721832
Epoch: 46 | Iteration number: [4400/4518] 97% | Training loss: 0.6869708393243226
Epoch: 46 | Iteration number: [4410/4518] 97% | Training loss: 0.6869703042804519
Epoch: 46 | Iteration number: [4420/4518] 97% | Training loss: 0.6869696339735618
Epoch: 46 | Iteration number: [4430/4518] 98% | Training loss: 0.6869707348653479
Epoch: 46 | Iteration number: [4440/4518] 98% | Training loss: 0.6869677196617598
Epoch: 46 | Iteration number: [4450/4518] 98% | Training loss: 0.6869665066981584
Epoch: 46 | Iteration number: [4460/4518] 98% | Training loss: 0.6869674089243594
Epoch: 46 | Iteration number: [4470/4518] 98% | Training loss: 0.6869665716451819
Epoch: 46 | Iteration number: [4480/4518] 99% | Training loss: 0.686970220719065
Epoch: 46 | Iteration number: [4490/4518] 99% | Training loss: 0.6869726140276096
Epoch: 46 | Iteration number: [4500/4518] 99% | Training loss: 0.6869725900093714
Epoch: 46 | Iteration number: [4510/4518] 99% | Training loss: 0.686973170364511

 End of epoch: 46 | Train Loss: 0.6868192119348255 | Training Time: 640 

 End of epoch: 46 | Eval Loss: 0.689969464224212 | Evaluating Time: 17 
Epoch: 47 | Iteration number: [10/4518] 0% | Training loss: 0.7553958475589753
Epoch: 47 | Iteration number: [20/4518] 0% | Training loss: 0.7208759039640427
Epoch: 47 | Iteration number: [30/4518] 0% | Training loss: 0.709270320336024
Epoch: 47 | Iteration number: [40/4518] 0% | Training loss: 0.7035349547863007
Epoch: 47 | Iteration number: [50/4518] 1% | Training loss: 0.7000333571434021
Epoch: 47 | Iteration number: [60/4518] 1% | Training loss: 0.6976949900388718
Epoch: 47 | Iteration number: [70/4518] 1% | Training loss: 0.695992739711489
Epoch: 47 | Iteration number: [80/4518] 1% | Training loss: 0.6947719030082226
Epoch: 47 | Iteration number: [90/4518] 1% | Training loss: 0.6938791851202647
Epoch: 47 | Iteration number: [100/4518] 2% | Training loss: 0.6931914430856705
Epoch: 47 | Iteration number: [110/4518] 2% | Training loss: 0.6926504032178359
Epoch: 47 | Iteration number: [120/4518] 2% | Training loss: 0.6921720077594121
Epoch: 47 | Iteration number: [130/4518] 2% | Training loss: 0.6917213384921734
Epoch: 47 | Iteration number: [140/4518] 3% | Training loss: 0.6914653658866883
Epoch: 47 | Iteration number: [150/4518] 3% | Training loss: 0.6912030824025472
Epoch: 47 | Iteration number: [160/4518] 3% | Training loss: 0.6909178145229816
Epoch: 47 | Iteration number: [170/4518] 3% | Training loss: 0.6905938916346606
Epoch: 47 | Iteration number: [180/4518] 3% | Training loss: 0.6904152257574929
Epoch: 47 | Iteration number: [190/4518] 4% | Training loss: 0.6900932114375266
Epoch: 47 | Iteration number: [200/4518] 4% | Training loss: 0.6899538198113442
Epoch: 47 | Iteration number: [210/4518] 4% | Training loss: 0.6897753760928199
Epoch: 47 | Iteration number: [220/4518] 4% | Training loss: 0.6896580994129181
Epoch: 47 | Iteration number: [230/4518] 5% | Training loss: 0.6895792621633281
Epoch: 47 | Iteration number: [240/4518] 5% | Training loss: 0.6895000370840232
Epoch: 47 | Iteration number: [250/4518] 5% | Training loss: 0.6893932793140412
Epoch: 47 | Iteration number: [260/4518] 5% | Training loss: 0.6892684212097755
Epoch: 47 | Iteration number: [270/4518] 5% | Training loss: 0.6892047111634855
Epoch: 47 | Iteration number: [280/4518] 6% | Training loss: 0.6890883994953972
Epoch: 47 | Iteration number: [290/4518] 6% | Training loss: 0.6890035148324638
Epoch: 47 | Iteration number: [300/4518] 6% | Training loss: 0.6889135632912318
Epoch: 47 | Iteration number: [310/4518] 6% | Training loss: 0.6888163535825668
Epoch: 47 | Iteration number: [320/4518] 7% | Training loss: 0.6887828061357141
Epoch: 47 | Iteration number: [330/4518] 7% | Training loss: 0.6887229077743762
Epoch: 47 | Iteration number: [340/4518] 7% | Training loss: 0.6886561604107128
Epoch: 47 | Iteration number: [350/4518] 7% | Training loss: 0.6885827767848969
Epoch: 47 | Iteration number: [360/4518] 7% | Training loss: 0.6884903230600887
Epoch: 47 | Iteration number: [370/4518] 8% | Training loss: 0.6884320407300382
Epoch: 47 | Iteration number: [380/4518] 8% | Training loss: 0.6883783500445516
Epoch: 47 | Iteration number: [390/4518] 8% | Training loss: 0.6883646350640517
Epoch: 47 | Iteration number: [400/4518] 8% | Training loss: 0.6883105427026749
Epoch: 47 | Iteration number: [410/4518] 9% | Training loss: 0.6882956352175735
Epoch: 47 | Iteration number: [420/4518] 9% | Training loss: 0.6882407107523509
Epoch: 47 | Iteration number: [430/4518] 9% | Training loss: 0.6882110793923223
Epoch: 47 | Iteration number: [440/4518] 9% | Training loss: 0.6881839822639119
Epoch: 47 | Iteration number: [450/4518] 9% | Training loss: 0.6881800079345703
Epoch: 47 | Iteration number: [460/4518] 10% | Training loss: 0.6881643179966056
Epoch: 47 | Iteration number: [470/4518] 10% | Training loss: 0.6881417512893677
Epoch: 47 | Iteration number: [480/4518] 10% | Training loss: 0.6881093351791302
Epoch: 47 | Iteration number: [490/4518] 10% | Training loss: 0.6880848020923381
Epoch: 47 | Iteration number: [500/4518] 11% | Training loss: 0.6880559222698212
Epoch: 47 | Iteration number: [510/4518] 11% | Training loss: 0.6880218753627703
Epoch: 47 | Iteration number: [520/4518] 11% | Training loss: 0.6879865948970502
Epoch: 47 | Iteration number: [530/4518] 11% | Training loss: 0.6879634435446758
Epoch: 47 | Iteration number: [540/4518] 11% | Training loss: 0.6879334255501076
Epoch: 47 | Iteration number: [550/4518] 12% | Training loss: 0.6879159358414737
Epoch: 47 | Iteration number: [560/4518] 12% | Training loss: 0.6879156414951597
Epoch: 47 | Iteration number: [570/4518] 12% | Training loss: 0.6878900399333552
Epoch: 47 | Iteration number: [580/4518] 12% | Training loss: 0.6878764942802232
Epoch: 47 | Iteration number: [590/4518] 13% | Training loss: 0.6878633552688663
Epoch: 47 | Iteration number: [600/4518] 13% | Training loss: 0.6878544692198435
Epoch: 47 | Iteration number: [610/4518] 13% | Training loss: 0.6878358135457898
Epoch: 47 | Iteration number: [620/4518] 13% | Training loss: 0.6878091713113169
Epoch: 47 | Iteration number: [630/4518] 13% | Training loss: 0.6877891856526571
Epoch: 47 | Iteration number: [640/4518] 14% | Training loss: 0.6877936649136245
Epoch: 47 | Iteration number: [650/4518] 14% | Training loss: 0.6877907660374275
Epoch: 47 | Iteration number: [660/4518] 14% | Training loss: 0.6877749057430209
Epoch: 47 | Iteration number: [670/4518] 14% | Training loss: 0.6877508097620153
Epoch: 47 | Iteration number: [680/4518] 15% | Training loss: 0.6877101005000227
Epoch: 47 | Iteration number: [690/4518] 15% | Training loss: 0.6877081382965696
Epoch: 47 | Iteration number: [700/4518] 15% | Training loss: 0.6876999912091664
Epoch: 47 | Iteration number: [710/4518] 15% | Training loss: 0.687692228421359
Epoch: 47 | Iteration number: [720/4518] 15% | Training loss: 0.6876840425862206
Epoch: 47 | Iteration number: [730/4518] 16% | Training loss: 0.6876772611108545
Epoch: 47 | Iteration number: [740/4518] 16% | Training loss: 0.6876516081191398
Epoch: 47 | Iteration number: [750/4518] 16% | Training loss: 0.6876582206090291
Epoch: 47 | Iteration number: [760/4518] 16% | Training loss: 0.6876534669807083
Epoch: 47 | Iteration number: [770/4518] 17% | Training loss: 0.6876559475025573
Epoch: 47 | Iteration number: [780/4518] 17% | Training loss: 0.687642586001983
Epoch: 47 | Iteration number: [790/4518] 17% | Training loss: 0.6876183629790439
Epoch: 47 | Iteration number: [800/4518] 17% | Training loss: 0.6875960016250611
Epoch: 47 | Iteration number: [810/4518] 17% | Training loss: 0.6875856052210302
Epoch: 47 | Iteration number: [820/4518] 18% | Training loss: 0.6875811713497814
Epoch: 47 | Iteration number: [830/4518] 18% | Training loss: 0.6875887271869614
Epoch: 47 | Iteration number: [840/4518] 18% | Training loss: 0.6875757210311435
Epoch: 47 | Iteration number: [850/4518] 18% | Training loss: 0.6875662760874804
Epoch: 47 | Iteration number: [860/4518] 19% | Training loss: 0.6875529962916707
Epoch: 47 | Iteration number: [870/4518] 19% | Training loss: 0.6875458335054332
Epoch: 47 | Iteration number: [880/4518] 19% | Training loss: 0.6875218171964992
Epoch: 47 | Iteration number: [890/4518] 19% | Training loss: 0.6875042051411746
Epoch: 47 | Iteration number: [900/4518] 19% | Training loss: 0.6874882506661945
Epoch: 47 | Iteration number: [910/4518] 20% | Training loss: 0.6874876372106783
Epoch: 47 | Iteration number: [920/4518] 20% | Training loss: 0.6874692743239196
Epoch: 47 | Iteration number: [930/4518] 20% | Training loss: 0.6874654722470109
Epoch: 47 | Iteration number: [940/4518] 20% | Training loss: 0.6874611463952571
Epoch: 47 | Iteration number: [950/4518] 21% | Training loss: 0.6874587789334748
Epoch: 47 | Iteration number: [960/4518] 21% | Training loss: 0.6874593418091536
Epoch: 47 | Iteration number: [970/4518] 21% | Training loss: 0.687442413494759
Epoch: 47 | Iteration number: [980/4518] 21% | Training loss: 0.6874411784872717
Epoch: 47 | Iteration number: [990/4518] 21% | Training loss: 0.6874350628467522
Epoch: 47 | Iteration number: [1000/4518] 22% | Training loss: 0.6874212446808815
Epoch: 47 | Iteration number: [1010/4518] 22% | Training loss: 0.6874102450833462
Epoch: 47 | Iteration number: [1020/4518] 22% | Training loss: 0.6874046621369381
Epoch: 47 | Iteration number: [1030/4518] 22% | Training loss: 0.687394060266828
Epoch: 47 | Iteration number: [1040/4518] 23% | Training loss: 0.6873875471834953
Epoch: 47 | Iteration number: [1050/4518] 23% | Training loss: 0.6873947259357998
Epoch: 47 | Iteration number: [1060/4518] 23% | Training loss: 0.6873952793062857
Epoch: 47 | Iteration number: [1070/4518] 23% | Training loss: 0.6873822860628644
Epoch: 47 | Iteration number: [1080/4518] 23% | Training loss: 0.6873752189455209
Epoch: 47 | Iteration number: [1090/4518] 24% | Training loss: 0.6873921060234035
Epoch: 47 | Iteration number: [1100/4518] 24% | Training loss: 0.6873774810812691
Epoch: 47 | Iteration number: [1110/4518] 24% | Training loss: 0.68737458683349
Epoch: 47 | Iteration number: [1120/4518] 24% | Training loss: 0.6873643208827291
Epoch: 47 | Iteration number: [1130/4518] 25% | Training loss: 0.6873577988780706
Epoch: 47 | Iteration number: [1140/4518] 25% | Training loss: 0.6873503102022305
Epoch: 47 | Iteration number: [1150/4518] 25% | Training loss: 0.6873509682779727
Epoch: 47 | Iteration number: [1160/4518] 25% | Training loss: 0.687338892550304
Epoch: 47 | Iteration number: [1170/4518] 25% | Training loss: 0.6873415906205137
Epoch: 47 | Iteration number: [1180/4518] 26% | Training loss: 0.687332904995498
Epoch: 47 | Iteration number: [1190/4518] 26% | Training loss: 0.6873271552454524
Epoch: 47 | Iteration number: [1200/4518] 26% | Training loss: 0.6873305576543013
Epoch: 47 | Iteration number: [1210/4518] 26% | Training loss: 0.6873226627830632
Epoch: 47 | Iteration number: [1220/4518] 27% | Training loss: 0.6873194186413875
Epoch: 47 | Iteration number: [1230/4518] 27% | Training loss: 0.68732096388088
Epoch: 47 | Iteration number: [1240/4518] 27% | Training loss: 0.687315504877798
Epoch: 47 | Iteration number: [1250/4518] 27% | Training loss: 0.6873031984806061
Epoch: 47 | Iteration number: [1260/4518] 27% | Training loss: 0.6872954192615691
Epoch: 47 | Iteration number: [1270/4518] 28% | Training loss: 0.687279614078717
Epoch: 47 | Iteration number: [1280/4518] 28% | Training loss: 0.6872721046674997
Epoch: 47 | Iteration number: [1290/4518] 28% | Training loss: 0.6872674690198529
Epoch: 47 | Iteration number: [1300/4518] 28% | Training loss: 0.6872549589322163
Epoch: 47 | Iteration number: [1310/4518] 28% | Training loss: 0.6872539583508295
Epoch: 47 | Iteration number: [1320/4518] 29% | Training loss: 0.6872504112846923
Epoch: 47 | Iteration number: [1330/4518] 29% | Training loss: 0.6872517932178382
Epoch: 47 | Iteration number: [1340/4518] 29% | Training loss: 0.6872485441058429
Epoch: 47 | Iteration number: [1350/4518] 29% | Training loss: 0.6872467959810187
Epoch: 47 | Iteration number: [1360/4518] 30% | Training loss: 0.6872425843687618
Epoch: 47 | Iteration number: [1370/4518] 30% | Training loss: 0.6872378910545015
Epoch: 47 | Iteration number: [1380/4518] 30% | Training loss: 0.6872248352005862
Epoch: 47 | Iteration number: [1390/4518] 30% | Training loss: 0.6872144436664719
Epoch: 47 | Iteration number: [1400/4518] 30% | Training loss: 0.687210783617837
Epoch: 47 | Iteration number: [1410/4518] 31% | Training loss: 0.6872050551657981
Epoch: 47 | Iteration number: [1420/4518] 31% | Training loss: 0.6871991850960423
Epoch: 47 | Iteration number: [1430/4518] 31% | Training loss: 0.6871976451857107
Epoch: 47 | Iteration number: [1440/4518] 31% | Training loss: 0.6872005006505384
Epoch: 47 | Iteration number: [1450/4518] 32% | Training loss: 0.6871982806304405
Epoch: 47 | Iteration number: [1460/4518] 32% | Training loss: 0.6871950191177734
Epoch: 47 | Iteration number: [1470/4518] 32% | Training loss: 0.6871958266310141
Epoch: 47 | Iteration number: [1480/4518] 32% | Training loss: 0.6871941916443206
Epoch: 47 | Iteration number: [1490/4518] 32% | Training loss: 0.687183101465238
Epoch: 47 | Iteration number: [1500/4518] 33% | Training loss: 0.687178405046463
Epoch: 47 | Iteration number: [1510/4518] 33% | Training loss: 0.6871780457875587
Epoch: 47 | Iteration number: [1520/4518] 33% | Training loss: 0.6871815416373704
Epoch: 47 | Iteration number: [1530/4518] 33% | Training loss: 0.6871740070433399
Epoch: 47 | Iteration number: [1540/4518] 34% | Training loss: 0.6871706433884509
Epoch: 47 | Iteration number: [1550/4518] 34% | Training loss: 0.6871676695346832
Epoch: 47 | Iteration number: [1560/4518] 34% | Training loss: 0.6871659370951163
Epoch: 47 | Iteration number: [1570/4518] 34% | Training loss: 0.687158846209763
Epoch: 47 | Iteration number: [1580/4518] 34% | Training loss: 0.6871563534193401
Epoch: 47 | Iteration number: [1590/4518] 35% | Training loss: 0.6871551426701575
Epoch: 47 | Iteration number: [1600/4518] 35% | Training loss: 0.6871532282978297
Epoch: 47 | Iteration number: [1610/4518] 35% | Training loss: 0.687147469550186
Epoch: 47 | Iteration number: [1620/4518] 35% | Training loss: 0.6871482597089108
Epoch: 47 | Iteration number: [1630/4518] 36% | Training loss: 0.6871430233578009
Epoch: 47 | Iteration number: [1640/4518] 36% | Training loss: 0.6871381670236587
Epoch: 47 | Iteration number: [1650/4518] 36% | Training loss: 0.6871442939657153
Epoch: 47 | Iteration number: [1660/4518] 36% | Training loss: 0.6871492213154413
Epoch: 47 | Iteration number: [1670/4518] 36% | Training loss: 0.6871460760781865
Epoch: 47 | Iteration number: [1680/4518] 37% | Training loss: 0.6871470933513982
Epoch: 47 | Iteration number: [1690/4518] 37% | Training loss: 0.6871484564253565
Epoch: 47 | Iteration number: [1700/4518] 37% | Training loss: 0.6871485923668917
Epoch: 47 | Iteration number: [1710/4518] 37% | Training loss: 0.6871489406677714
Epoch: 47 | Iteration number: [1720/4518] 38% | Training loss: 0.6871470453780751
Epoch: 47 | Iteration number: [1730/4518] 38% | Training loss: 0.6871501066781193
Epoch: 47 | Iteration number: [1740/4518] 38% | Training loss: 0.6871433597529072
Epoch: 47 | Iteration number: [1750/4518] 38% | Training loss: 0.6871498411042349
Epoch: 47 | Iteration number: [1760/4518] 38% | Training loss: 0.6871479115702889
Epoch: 47 | Iteration number: [1770/4518] 39% | Training loss: 0.6871416417218871
Epoch: 47 | Iteration number: [1780/4518] 39% | Training loss: 0.6871378879868583
Epoch: 47 | Iteration number: [1790/4518] 39% | Training loss: 0.687135109754914
Epoch: 47 | Iteration number: [1800/4518] 39% | Training loss: 0.6871322969264454
Epoch: 47 | Iteration number: [1810/4518] 40% | Training loss: 0.6871260620612466
Epoch: 47 | Iteration number: [1820/4518] 40% | Training loss: 0.6871236361317582
Epoch: 47 | Iteration number: [1830/4518] 40% | Training loss: 0.6871204143990585
Epoch: 47 | Iteration number: [1840/4518] 40% | Training loss: 0.6871177848266519
Epoch: 47 | Iteration number: [1850/4518] 40% | Training loss: 0.6871152188326861
Epoch: 47 | Iteration number: [1860/4518] 41% | Training loss: 0.6871120947663502
Epoch: 47 | Iteration number: [1870/4518] 41% | Training loss: 0.6871170013664878
Epoch: 47 | Iteration number: [1880/4518] 41% | Training loss: 0.687111960288058
Epoch: 47 | Iteration number: [1890/4518] 41% | Training loss: 0.68710245982049
Epoch: 47 | Iteration number: [1900/4518] 42% | Training loss: 0.6871026968955993
Epoch: 47 | Iteration number: [1910/4518] 42% | Training loss: 0.6871094486164173
Epoch: 47 | Iteration number: [1920/4518] 42% | Training loss: 0.68710402570044
Epoch: 47 | Iteration number: [1930/4518] 42% | Training loss: 0.687105408480748
Epoch: 47 | Iteration number: [1940/4518] 42% | Training loss: 0.6870996552029836
Epoch: 47 | Iteration number: [1950/4518] 43% | Training loss: 0.6870917654037476
Epoch: 47 | Iteration number: [1960/4518] 43% | Training loss: 0.6870839497568656
Epoch: 47 | Iteration number: [1970/4518] 43% | Training loss: 0.6870800000459409
Epoch: 47 | Iteration number: [1980/4518] 43% | Training loss: 0.6870823523913971
Epoch: 47 | Iteration number: [1990/4518] 44% | Training loss: 0.6870846287689018
Epoch: 47 | Iteration number: [2000/4518] 44% | Training loss: 0.6870883246362209
Epoch: 47 | Iteration number: [2010/4518] 44% | Training loss: 0.6870901493883844
Epoch: 47 | Iteration number: [2020/4518] 44% | Training loss: 0.687093812787887
Epoch: 47 | Iteration number: [2030/4518] 44% | Training loss: 0.6871043971606663
Epoch: 47 | Iteration number: [2040/4518] 45% | Training loss: 0.6870971604305155
Epoch: 47 | Iteration number: [2050/4518] 45% | Training loss: 0.6870966083247487
Epoch: 47 | Iteration number: [2060/4518] 45% | Training loss: 0.6870944522248889
Epoch: 47 | Iteration number: [2070/4518] 45% | Training loss: 0.6870917673560156
Epoch: 47 | Iteration number: [2080/4518] 46% | Training loss: 0.6870857990991611
Epoch: 47 | Iteration number: [2090/4518] 46% | Training loss: 0.6870851343043113
Epoch: 47 | Iteration number: [2100/4518] 46% | Training loss: 0.6870863032624835
Epoch: 47 | Iteration number: [2110/4518] 46% | Training loss: 0.6870873576374416
Epoch: 47 | Iteration number: [2120/4518] 46% | Training loss: 0.6870859241991673
Epoch: 47 | Iteration number: [2130/4518] 47% | Training loss: 0.6870863215184547
Epoch: 47 | Iteration number: [2140/4518] 47% | Training loss: 0.6870868800956512
Epoch: 47 | Iteration number: [2150/4518] 47% | Training loss: 0.6870881227559822
Epoch: 47 | Iteration number: [2160/4518] 47% | Training loss: 0.6870885648937137
Epoch: 47 | Iteration number: [2170/4518] 48% | Training loss: 0.6870908733611832
Epoch: 47 | Iteration number: [2180/4518] 48% | Training loss: 0.6870901595015044
Epoch: 47 | Iteration number: [2190/4518] 48% | Training loss: 0.6870937135665929
Epoch: 47 | Iteration number: [2200/4518] 48% | Training loss: 0.6870945273746144
Epoch: 47 | Iteration number: [2210/4518] 48% | Training loss: 0.6871003208926361
Epoch: 47 | Iteration number: [2220/4518] 49% | Training loss: 0.6870947413347863
Epoch: 47 | Iteration number: [2230/4518] 49% | Training loss: 0.6870987424401425
Epoch: 47 | Iteration number: [2240/4518] 49% | Training loss: 0.6870975317699569
Epoch: 47 | Iteration number: [2250/4518] 49% | Training loss: 0.6870935005611843
Epoch: 47 | Iteration number: [2260/4518] 50% | Training loss: 0.6870895609918949
Epoch: 47 | Iteration number: [2270/4518] 50% | Training loss: 0.6870903806276784
Epoch: 47 | Iteration number: [2280/4518] 50% | Training loss: 0.6870904925622439
Epoch: 47 | Iteration number: [2290/4518] 50% | Training loss: 0.6870921825217368
Epoch: 47 | Iteration number: [2300/4518] 50% | Training loss: 0.6870864939171335
Epoch: 47 | Iteration number: [2310/4518] 51% | Training loss: 0.6870843157881782
Epoch: 47 | Iteration number: [2320/4518] 51% | Training loss: 0.6870846731395557
Epoch: 47 | Iteration number: [2330/4518] 51% | Training loss: 0.6870867175349862
Epoch: 47 | Iteration number: [2340/4518] 51% | Training loss: 0.6870855833984848
Epoch: 47 | Iteration number: [2350/4518] 52% | Training loss: 0.6870864156712877
Epoch: 47 | Iteration number: [2360/4518] 52% | Training loss: 0.6870829499374002
Epoch: 47 | Iteration number: [2370/4518] 52% | Training loss: 0.6870763018664429
Epoch: 47 | Iteration number: [2380/4518] 52% | Training loss: 0.6870717704045672
Epoch: 47 | Iteration number: [2390/4518] 52% | Training loss: 0.6870690078166738
Epoch: 47 | Iteration number: [2400/4518] 53% | Training loss: 0.6870743677020072
Epoch: 47 | Iteration number: [2410/4518] 53% | Training loss: 0.6870753799483984
Epoch: 47 | Iteration number: [2420/4518] 53% | Training loss: 0.687081666229185
Epoch: 47 | Iteration number: [2430/4518] 53% | Training loss: 0.6870784769578235
Epoch: 47 | Iteration number: [2440/4518] 54% | Training loss: 0.6870759024483258
Epoch: 47 | Iteration number: [2450/4518] 54% | Training loss: 0.6870771311010633
Epoch: 47 | Iteration number: [2460/4518] 54% | Training loss: 0.6870775462892966
Epoch: 47 | Iteration number: [2470/4518] 54% | Training loss: 0.6870759069195643
Epoch: 47 | Iteration number: [2480/4518] 54% | Training loss: 0.6870744613149474
Epoch: 47 | Iteration number: [2490/4518] 55% | Training loss: 0.6870661482274771
Epoch: 47 | Iteration number: [2500/4518] 55% | Training loss: 0.6870623301029205
Epoch: 47 | Iteration number: [2510/4518] 55% | Training loss: 0.6870646033866472
Epoch: 47 | Iteration number: [2520/4518] 55% | Training loss: 0.6870598616581115
Epoch: 47 | Iteration number: [2530/4518] 55% | Training loss: 0.6870640529474251
Epoch: 47 | Iteration number: [2540/4518] 56% | Training loss: 0.6870636730916857
Epoch: 47 | Iteration number: [2550/4518] 56% | Training loss: 0.6870622177451264
Epoch: 47 | Iteration number: [2560/4518] 56% | Training loss: 0.6870549368206411
Epoch: 47 | Iteration number: [2570/4518] 56% | Training loss: 0.6870509502488815
Epoch: 47 | Iteration number: [2580/4518] 57% | Training loss: 0.6870530198017756
Epoch: 47 | Iteration number: [2590/4518] 57% | Training loss: 0.6870501407094904
Epoch: 47 | Iteration number: [2600/4518] 57% | Training loss: 0.6870573491316575
Epoch: 47 | Iteration number: [2610/4518] 57% | Training loss: 0.6870529399977789
Epoch: 47 | Iteration number: [2620/4518] 57% | Training loss: 0.6870546133918617
Epoch: 47 | Iteration number: [2630/4518] 58% | Training loss: 0.687051241932713
Epoch: 47 | Iteration number: [2640/4518] 58% | Training loss: 0.6870508314533668
Epoch: 47 | Iteration number: [2650/4518] 58% | Training loss: 0.6870515927053847
Epoch: 47 | Iteration number: [2660/4518] 58% | Training loss: 0.6870534268088807
Epoch: 47 | Iteration number: [2670/4518] 59% | Training loss: 0.6870532228928826
Epoch: 47 | Iteration number: [2680/4518] 59% | Training loss: 0.6870571938023639
Epoch: 47 | Iteration number: [2690/4518] 59% | Training loss: 0.6870560610826131
Epoch: 47 | Iteration number: [2700/4518] 59% | Training loss: 0.6870586999257405
Epoch: 47 | Iteration number: [2710/4518] 59% | Training loss: 0.6870565628213636
Epoch: 47 | Iteration number: [2720/4518] 60% | Training loss: 0.6870551392216893
Epoch: 47 | Iteration number: [2730/4518] 60% | Training loss: 0.6870493093908051
Epoch: 47 | Iteration number: [2740/4518] 60% | Training loss: 0.6870466098080587
Epoch: 47 | Iteration number: [2750/4518] 60% | Training loss: 0.6870424264561046
Epoch: 47 | Iteration number: [2760/4518] 61% | Training loss: 0.6870421096034672
Epoch: 47 | Iteration number: [2770/4518] 61% | Training loss: 0.6870374167654059
Epoch: 47 | Iteration number: [2780/4518] 61% | Training loss: 0.6870400701280978
Epoch: 47 | Iteration number: [2790/4518] 61% | Training loss: 0.6870410135783602
Epoch: 47 | Iteration number: [2800/4518] 61% | Training loss: 0.6870426199691636
Epoch: 47 | Iteration number: [2810/4518] 62% | Training loss: 0.6870353819000339
Epoch: 47 | Iteration number: [2820/4518] 62% | Training loss: 0.687038957417434
Epoch: 47 | Iteration number: [2830/4518] 62% | Training loss: 0.6870402934483841
Epoch: 47 | Iteration number: [2840/4518] 62% | Training loss: 0.6870366872196466
Epoch: 47 | Iteration number: [2850/4518] 63% | Training loss: 0.6870383040946827
Epoch: 47 | Iteration number: [2860/4518] 63% | Training loss: 0.6870378347126754
Epoch: 47 | Iteration number: [2870/4518] 63% | Training loss: 0.6870380988519782
Epoch: 47 | Iteration number: [2880/4518] 63% | Training loss: 0.687040875520971
Epoch: 47 | Iteration number: [2890/4518] 63% | Training loss: 0.6870405175075399
Epoch: 47 | Iteration number: [2900/4518] 64% | Training loss: 0.6870332010655568
Epoch: 47 | Iteration number: [2910/4518] 64% | Training loss: 0.6870314063689963
Epoch: 47 | Iteration number: [2920/4518] 64% | Training loss: 0.6870293369031932
Epoch: 47 | Iteration number: [2930/4518] 64% | Training loss: 0.6870295709107109
Epoch: 47 | Iteration number: [2940/4518] 65% | Training loss: 0.6870277671384163
Epoch: 47 | Iteration number: [2950/4518] 65% | Training loss: 0.6870295885659881
Epoch: 47 | Iteration number: [2960/4518] 65% | Training loss: 0.6870319924241788
Epoch: 47 | Iteration number: [2970/4518] 65% | Training loss: 0.6870289004210269
Epoch: 47 | Iteration number: [2980/4518] 65% | Training loss: 0.6870298597636639
Epoch: 47 | Iteration number: [2990/4518] 66% | Training loss: 0.6870305553327835
Epoch: 47 | Iteration number: [3000/4518] 66% | Training loss: 0.6870298390587171
Epoch: 47 | Iteration number: [3010/4518] 66% | Training loss: 0.6870309343171674
Epoch: 47 | Iteration number: [3020/4518] 66% | Training loss: 0.6870337203835809
Epoch: 47 | Iteration number: [3030/4518] 67% | Training loss: 0.6870378146667292
Epoch: 47 | Iteration number: [3040/4518] 67% | Training loss: 0.6870382120146563
Epoch: 47 | Iteration number: [3050/4518] 67% | Training loss: 0.6870368519962811
Epoch: 47 | Iteration number: [3060/4518] 67% | Training loss: 0.6870405821434034
Epoch: 47 | Iteration number: [3070/4518] 67% | Training loss: 0.6870412411829547
Epoch: 47 | Iteration number: [3080/4518] 68% | Training loss: 0.6870437665225624
Epoch: 47 | Iteration number: [3090/4518] 68% | Training loss: 0.6870437937068322
Epoch: 47 | Iteration number: [3100/4518] 68% | Training loss: 0.6870413250500156
Epoch: 47 | Iteration number: [3110/4518] 68% | Training loss: 0.6870404231011676
Epoch: 47 | Iteration number: [3120/4518] 69% | Training loss: 0.6870421840403325
Epoch: 47 | Iteration number: [3130/4518] 69% | Training loss: 0.68704175648217
Epoch: 47 | Iteration number: [3140/4518] 69% | Training loss: 0.6870375181649141
Epoch: 47 | Iteration number: [3150/4518] 69% | Training loss: 0.6870358364733439
Epoch: 47 | Iteration number: [3160/4518] 69% | Training loss: 0.6870391722344145
Epoch: 47 | Iteration number: [3170/4518] 70% | Training loss: 0.6870378357942925
Epoch: 47 | Iteration number: [3180/4518] 70% | Training loss: 0.6870363425908599
Epoch: 47 | Iteration number: [3190/4518] 70% | Training loss: 0.6870356253135167
Epoch: 47 | Iteration number: [3200/4518] 70% | Training loss: 0.6870377962291241
Epoch: 47 | Iteration number: [3210/4518] 71% | Training loss: 0.6870357564490903
Epoch: 47 | Iteration number: [3220/4518] 71% | Training loss: 0.6870329687128897
Epoch: 47 | Iteration number: [3230/4518] 71% | Training loss: 0.6870343138558945
Epoch: 47 | Iteration number: [3240/4518] 71% | Training loss: 0.6870326646500163
Epoch: 47 | Iteration number: [3250/4518] 71% | Training loss: 0.6870342222360464
Epoch: 47 | Iteration number: [3260/4518] 72% | Training loss: 0.6870367742937766
Epoch: 47 | Iteration number: [3270/4518] 72% | Training loss: 0.6870353247776673
Epoch: 47 | Iteration number: [3280/4518] 72% | Training loss: 0.687031245540555
Epoch: 47 | Iteration number: [3290/4518] 72% | Training loss: 0.6870332300844163
Epoch: 47 | Iteration number: [3300/4518] 73% | Training loss: 0.6870322854229898
Epoch: 47 | Iteration number: [3310/4518] 73% | Training loss: 0.6870316601411813
Epoch: 47 | Iteration number: [3320/4518] 73% | Training loss: 0.687027746869857
Epoch: 47 | Iteration number: [3330/4518] 73% | Training loss: 0.6870238122281369
Epoch: 47 | Iteration number: [3340/4518] 73% | Training loss: 0.687024059213564
Epoch: 47 | Iteration number: [3350/4518] 74% | Training loss: 0.6870249084216445
Epoch: 47 | Iteration number: [3360/4518] 74% | Training loss: 0.6870224094816617
Epoch: 47 | Iteration number: [3370/4518] 74% | Training loss: 0.6870249918200496
Epoch: 47 | Iteration number: [3380/4518] 74% | Training loss: 0.6870265419137549
Epoch: 47 | Iteration number: [3390/4518] 75% | Training loss: 0.687029879283061
Epoch: 47 | Iteration number: [3400/4518] 75% | Training loss: 0.6870288850104107
Epoch: 47 | Iteration number: [3410/4518] 75% | Training loss: 0.6870267638188303
Epoch: 47 | Iteration number: [3420/4518] 75% | Training loss: 0.6870276205023826
Epoch: 47 | Iteration number: [3430/4518] 75% | Training loss: 0.6870274693208255
Epoch: 47 | Iteration number: [3440/4518] 76% | Training loss: 0.6870275139462116
Epoch: 47 | Iteration number: [3450/4518] 76% | Training loss: 0.6870244076632072
Epoch: 47 | Iteration number: [3460/4518] 76% | Training loss: 0.687024907087315
Epoch: 47 | Iteration number: [3470/4518] 76% | Training loss: 0.6870249823122272
Epoch: 47 | Iteration number: [3480/4518] 77% | Training loss: 0.6870236702348994
Epoch: 47 | Iteration number: [3490/4518] 77% | Training loss: 0.6870252980885329
Epoch: 47 | Iteration number: [3500/4518] 77% | Training loss: 0.6870225150925773
Epoch: 47 | Iteration number: [3510/4518] 77% | Training loss: 0.687018636369977
Epoch: 47 | Iteration number: [3520/4518] 77% | Training loss: 0.687020928802138
Epoch: 47 | Iteration number: [3530/4518] 78% | Training loss: 0.6870169678592142
Epoch: 47 | Iteration number: [3540/4518] 78% | Training loss: 0.6870146567707008
Epoch: 47 | Iteration number: [3550/4518] 78% | Training loss: 0.6870131356783317
Epoch: 47 | Iteration number: [3560/4518] 78% | Training loss: 0.6870118473855297
Epoch: 47 | Iteration number: [3570/4518] 79% | Training loss: 0.6870124481973194
Epoch: 47 | Iteration number: [3580/4518] 79% | Training loss: 0.6870129280250166
Epoch: 47 | Iteration number: [3590/4518] 79% | Training loss: 0.6870114784054769
Epoch: 47 | Iteration number: [3600/4518] 79% | Training loss: 0.687011189825005
Epoch: 47 | Iteration number: [3610/4518] 79% | Training loss: 0.6870110101812104
Epoch: 47 | Iteration number: [3620/4518] 80% | Training loss: 0.6870087384354344
Epoch: 47 | Iteration number: [3630/4518] 80% | Training loss: 0.6870045964382897
Epoch: 47 | Iteration number: [3640/4518] 80% | Training loss: 0.6870029708186348
Epoch: 47 | Iteration number: [3650/4518] 80% | Training loss: 0.6870031336072373
Epoch: 47 | Iteration number: [3660/4518] 81% | Training loss: 0.6870001842415397
Epoch: 47 | Iteration number: [3670/4518] 81% | Training loss: 0.6869994390075798
Epoch: 47 | Iteration number: [3680/4518] 81% | Training loss: 0.6869928370837284
Epoch: 47 | Iteration number: [3690/4518] 81% | Training loss: 0.6869921100171924
Epoch: 47 | Iteration number: [3700/4518] 81% | Training loss: 0.6869941093631693
Epoch: 47 | Iteration number: [3710/4518] 82% | Training loss: 0.6869928725003553
Epoch: 47 | Iteration number: [3720/4518] 82% | Training loss: 0.686990917866589
Epoch: 47 | Iteration number: [3730/4518] 82% | Training loss: 0.6869908848173177
Epoch: 47 | Iteration number: [3740/4518] 82% | Training loss: 0.686990409914185
Epoch: 47 | Iteration number: [3750/4518] 83% | Training loss: 0.6869895741303762
Epoch: 47 | Iteration number: [3760/4518] 83% | Training loss: 0.6869832227046185
Epoch: 47 | Iteration number: [3770/4518] 83% | Training loss: 0.6869818000641679
Epoch: 47 | Iteration number: [3780/4518] 83% | Training loss: 0.6869814636846068
Epoch: 47 | Iteration number: [3790/4518] 83% | Training loss: 0.686983539686983
Epoch: 47 | Iteration number: [3800/4518] 84% | Training loss: 0.6869806399941445
Epoch: 47 | Iteration number: [3810/4518] 84% | Training loss: 0.6869796650929088
Epoch: 47 | Iteration number: [3820/4518] 84% | Training loss: 0.6869813300240102
Epoch: 47 | Iteration number: [3830/4518] 84% | Training loss: 0.6869823924399543
Epoch: 47 | Iteration number: [3840/4518] 84% | Training loss: 0.6869802335742861
Epoch: 47 | Iteration number: [3850/4518] 85% | Training loss: 0.6869809339108405
Epoch: 47 | Iteration number: [3860/4518] 85% | Training loss: 0.6869847724011525
Epoch: 47 | Iteration number: [3870/4518] 85% | Training loss: 0.686983205982573
Epoch: 47 | Iteration number: [3880/4518] 85% | Training loss: 0.6869836463756168
Epoch: 47 | Iteration number: [3890/4518] 86% | Training loss: 0.6869831221269151
Epoch: 47 | Iteration number: [3900/4518] 86% | Training loss: 0.6869815025726954
Epoch: 47 | Iteration number: [3910/4518] 86% | Training loss: 0.6869814184163232
Epoch: 47 | Iteration number: [3920/4518] 86% | Training loss: 0.686978251791122
Epoch: 47 | Iteration number: [3930/4518] 86% | Training loss: 0.6869758136551496
Epoch: 47 | Iteration number: [3940/4518] 87% | Training loss: 0.6869750680505927
Epoch: 47 | Iteration number: [3950/4518] 87% | Training loss: 0.6869773947136312
Epoch: 47 | Iteration number: [3960/4518] 87% | Training loss: 0.6869759266123627
Epoch: 47 | Iteration number: [3970/4518] 87% | Training loss: 0.6869736838851227
Epoch: 47 | Iteration number: [3980/4518] 88% | Training loss: 0.6869731508607242
Epoch: 47 | Iteration number: [3990/4518] 88% | Training loss: 0.6869733724827157
Epoch: 47 | Iteration number: [4000/4518] 88% | Training loss: 0.6869731723368168
Epoch: 47 | Iteration number: [4010/4518] 88% | Training loss: 0.6869725004544579
Epoch: 47 | Iteration number: [4020/4518] 88% | Training loss: 0.6869743681813947
Epoch: 47 | Iteration number: [4030/4518] 89% | Training loss: 0.6869751542880577
Epoch: 47 | Iteration number: [4040/4518] 89% | Training loss: 0.6869803109381458
Epoch: 47 | Iteration number: [4050/4518] 89% | Training loss: 0.6869802731201973
Epoch: 47 | Iteration number: [4060/4518] 89% | Training loss: 0.6869808182340538
Epoch: 47 | Iteration number: [4070/4518] 90% | Training loss: 0.6869793842699955
Epoch: 47 | Iteration number: [4080/4518] 90% | Training loss: 0.6869773687246967
Epoch: 47 | Iteration number: [4090/4518] 90% | Training loss: 0.6869761348353621
Epoch: 47 | Iteration number: [4100/4518] 90% | Training loss: 0.6869790102359725
Epoch: 47 | Iteration number: [4110/4518] 90% | Training loss: 0.6869791941921206
Epoch: 47 | Iteration number: [4120/4518] 91% | Training loss: 0.6869809297971355
Epoch: 47 | Iteration number: [4130/4518] 91% | Training loss: 0.6869779611326592
Epoch: 47 | Iteration number: [4140/4518] 91% | Training loss: 0.6869769594951528
Epoch: 47 | Iteration number: [4150/4518] 91% | Training loss: 0.6869765176686896
Epoch: 47 | Iteration number: [4160/4518] 92% | Training loss: 0.6869733792371475
Epoch: 47 | Iteration number: [4170/4518] 92% | Training loss: 0.6869723031274992
Epoch: 47 | Iteration number: [4180/4518] 92% | Training loss: 0.6869743227673489
Epoch: 47 | Iteration number: [4190/4518] 92% | Training loss: 0.6869743698394384
Epoch: 47 | Iteration number: [4200/4518] 92% | Training loss: 0.6869750548118637
Epoch: 47 | Iteration number: [4210/4518] 93% | Training loss: 0.6869763416094338
Epoch: 47 | Iteration number: [4220/4518] 93% | Training loss: 0.6869784282282065
Epoch: 47 | Iteration number: [4230/4518] 93% | Training loss: 0.6869752362405719
Epoch: 47 | Iteration number: [4240/4518] 93% | Training loss: 0.6869740015071518
Epoch: 47 | Iteration number: [4250/4518] 94% | Training loss: 0.6869762004824246
Epoch: 47 | Iteration number: [4260/4518] 94% | Training loss: 0.6869757355378827
Epoch: 47 | Iteration number: [4270/4518] 94% | Training loss: 0.6869749717885493
Epoch: 47 | Iteration number: [4280/4518] 94% | Training loss: 0.6869734697113528
Epoch: 47 | Iteration number: [4290/4518] 94% | Training loss: 0.6869713350331589
Epoch: 47 | Iteration number: [4300/4518] 95% | Training loss: 0.686972699719806
Epoch: 47 | Iteration number: [4310/4518] 95% | Training loss: 0.6869724062368654
Epoch: 47 | Iteration number: [4320/4518] 95% | Training loss: 0.6869722749210067
Epoch: 47 | Iteration number: [4330/4518] 95% | Training loss: 0.6869721983789572
Epoch: 47 | Iteration number: [4340/4518] 96% | Training loss: 0.6869732031624438
Epoch: 47 | Iteration number: [4350/4518] 96% | Training loss: 0.6869752635763979
Epoch: 47 | Iteration number: [4360/4518] 96% | Training loss: 0.6869743395425858
Epoch: 47 | Iteration number: [4370/4518] 96% | Training loss: 0.6869736465354805
Epoch: 47 | Iteration number: [4380/4518] 96% | Training loss: 0.6869720658074775
Epoch: 47 | Iteration number: [4390/4518] 97% | Training loss: 0.6869704246385222
Epoch: 47 | Iteration number: [4400/4518] 97% | Training loss: 0.6869709715247154
Epoch: 47 | Iteration number: [4410/4518] 97% | Training loss: 0.6869713068278739
Epoch: 47 | Iteration number: [4420/4518] 97% | Training loss: 0.6869719797939197
Epoch: 47 | Iteration number: [4430/4518] 98% | Training loss: 0.6869716778027554
Epoch: 47 | Iteration number: [4440/4518] 98% | Training loss: 0.6869687976466643
Epoch: 47 | Iteration number: [4450/4518] 98% | Training loss: 0.6869682312681434
Epoch: 47 | Iteration number: [4460/4518] 98% | Training loss: 0.686971500970323
Epoch: 47 | Iteration number: [4470/4518] 98% | Training loss: 0.6869709275712903
Epoch: 47 | Iteration number: [4480/4518] 99% | Training loss: 0.6869706159989749
Epoch: 47 | Iteration number: [4490/4518] 99% | Training loss: 0.6869711681038871
Epoch: 47 | Iteration number: [4500/4518] 99% | Training loss: 0.6869679860141542
Epoch: 47 | Iteration number: [4510/4518] 99% | Training loss: 0.6869657236033692

 End of epoch: 47 | Train Loss: 0.6868137561309227 | Training Time: 640 

 End of epoch: 47 | Eval Loss: 0.689984320377817 | Evaluating Time: 17 
Epoch: 48 | Iteration number: [10/4518] 0% | Training loss: 0.7561442613601684
Epoch: 48 | Iteration number: [20/4518] 0% | Training loss: 0.7211705684661865
Epoch: 48 | Iteration number: [30/4518] 0% | Training loss: 0.7098855237166087
Epoch: 48 | Iteration number: [40/4518] 0% | Training loss: 0.7042483627796173
Epoch: 48 | Iteration number: [50/4518] 1% | Training loss: 0.7004611730575562
Epoch: 48 | Iteration number: [60/4518] 1% | Training loss: 0.6979411909977595
Epoch: 48 | Iteration number: [70/4518] 1% | Training loss: 0.6963599256106785
Epoch: 48 | Iteration number: [80/4518] 1% | Training loss: 0.6952809117734432
Epoch: 48 | Iteration number: [90/4518] 1% | Training loss: 0.6942600104543898
Epoch: 48 | Iteration number: [100/4518] 2% | Training loss: 0.6933336675167083
Epoch: 48 | Iteration number: [110/4518] 2% | Training loss: 0.6926644867116755
Epoch: 48 | Iteration number: [120/4518] 2% | Training loss: 0.6921895921230317
Epoch: 48 | Iteration number: [130/4518] 2% | Training loss: 0.6918417476690732
Epoch: 48 | Iteration number: [140/4518] 3% | Training loss: 0.6914324475186212
Epoch: 48 | Iteration number: [150/4518] 3% | Training loss: 0.6911726450920105
Epoch: 48 | Iteration number: [160/4518] 3% | Training loss: 0.6908974010497332
Epoch: 48 | Iteration number: [170/4518] 3% | Training loss: 0.6905632997260375
Epoch: 48 | Iteration number: [180/4518] 3% | Training loss: 0.6903033276398977
Epoch: 48 | Iteration number: [190/4518] 4% | Training loss: 0.6901765622590718
Epoch: 48 | Iteration number: [200/4518] 4% | Training loss: 0.6899903798103333
Epoch: 48 | Iteration number: [210/4518] 4% | Training loss: 0.6898660716556367
Epoch: 48 | Iteration number: [220/4518] 4% | Training loss: 0.6897134672511708
Epoch: 48 | Iteration number: [230/4518] 5% | Training loss: 0.6895881341851275
Epoch: 48 | Iteration number: [240/4518] 5% | Training loss: 0.6894474613169829
Epoch: 48 | Iteration number: [250/4518] 5% | Training loss: 0.6893952467441559
Epoch: 48 | Iteration number: [260/4518] 5% | Training loss: 0.6892575229589756
Epoch: 48 | Iteration number: [270/4518] 5% | Training loss: 0.6892207132445441
Epoch: 48 | Iteration number: [280/4518] 6% | Training loss: 0.6891433737107686
Epoch: 48 | Iteration number: [290/4518] 6% | Training loss: 0.6890577022371621
Epoch: 48 | Iteration number: [300/4518] 6% | Training loss: 0.6889497963587443
Epoch: 48 | Iteration number: [310/4518] 6% | Training loss: 0.6889186084270478
Epoch: 48 | Iteration number: [320/4518] 7% | Training loss: 0.6888636043295264
Epoch: 48 | Iteration number: [330/4518] 7% | Training loss: 0.6888139441157832
Epoch: 48 | Iteration number: [340/4518] 7% | Training loss: 0.6887693306979011
Epoch: 48 | Iteration number: [350/4518] 7% | Training loss: 0.6887198851789746
Epoch: 48 | Iteration number: [360/4518] 7% | Training loss: 0.6886739474203851
Epoch: 48 | Iteration number: [370/4518] 8% | Training loss: 0.6886143541013873
Epoch: 48 | Iteration number: [380/4518] 8% | Training loss: 0.6885470184840654
Epoch: 48 | Iteration number: [390/4518] 8% | Training loss: 0.6885036037518428
Epoch: 48 | Iteration number: [400/4518] 8% | Training loss: 0.6884393122792244
Epoch: 48 | Iteration number: [410/4518] 9% | Training loss: 0.6884064542084205
Epoch: 48 | Iteration number: [420/4518] 9% | Training loss: 0.6883578497739066
Epoch: 48 | Iteration number: [430/4518] 9% | Training loss: 0.6883017777010452
Epoch: 48 | Iteration number: [440/4518] 9% | Training loss: 0.6882842248136347
Epoch: 48 | Iteration number: [450/4518] 9% | Training loss: 0.6882429981231689
Epoch: 48 | Iteration number: [460/4518] 10% | Training loss: 0.6882127752770548
Epoch: 48 | Iteration number: [470/4518] 10% | Training loss: 0.6881720506130381
Epoch: 48 | Iteration number: [480/4518] 10% | Training loss: 0.6881420218696197
Epoch: 48 | Iteration number: [490/4518] 10% | Training loss: 0.6881292065795587
Epoch: 48 | Iteration number: [500/4518] 11% | Training loss: 0.6881139794588089
Epoch: 48 | Iteration number: [510/4518] 11% | Training loss: 0.6880752107676338
Epoch: 48 | Iteration number: [520/4518] 11% | Training loss: 0.688057694870692
Epoch: 48 | Iteration number: [530/4518] 11% | Training loss: 0.6880508494826982
Epoch: 48 | Iteration number: [540/4518] 11% | Training loss: 0.688029522034857
Epoch: 48 | Iteration number: [550/4518] 12% | Training loss: 0.6879827737808227
Epoch: 48 | Iteration number: [560/4518] 12% | Training loss: 0.687957673413413
Epoch: 48 | Iteration number: [570/4518] 12% | Training loss: 0.6879697878109782
Epoch: 48 | Iteration number: [580/4518] 12% | Training loss: 0.6879571872538534
Epoch: 48 | Iteration number: [590/4518] 13% | Training loss: 0.687967868578636
Epoch: 48 | Iteration number: [600/4518] 13% | Training loss: 0.6879349552591641
Epoch: 48 | Iteration number: [610/4518] 13% | Training loss: 0.6879134907097113
Epoch: 48 | Iteration number: [620/4518] 13% | Training loss: 0.6879122445660253
Epoch: 48 | Iteration number: [630/4518] 13% | Training loss: 0.6878788377557482
Epoch: 48 | Iteration number: [640/4518] 14% | Training loss: 0.6878679590299726
Epoch: 48 | Iteration number: [650/4518] 14% | Training loss: 0.6878386123363789
Epoch: 48 | Iteration number: [660/4518] 14% | Training loss: 0.687823467633941
Epoch: 48 | Iteration number: [670/4518] 14% | Training loss: 0.687789913255777
Epoch: 48 | Iteration number: [680/4518] 15% | Training loss: 0.6877746825709062
Epoch: 48 | Iteration number: [690/4518] 15% | Training loss: 0.6877604782581329
Epoch: 48 | Iteration number: [700/4518] 15% | Training loss: 0.6877414808103016
Epoch: 48 | Iteration number: [710/4518] 15% | Training loss: 0.6877006703699139
Epoch: 48 | Iteration number: [720/4518] 15% | Training loss: 0.6876808809737365
Epoch: 48 | Iteration number: [730/4518] 16% | Training loss: 0.6876650513034978
Epoch: 48 | Iteration number: [740/4518] 16% | Training loss: 0.6876636340811446
Epoch: 48 | Iteration number: [750/4518] 16% | Training loss: 0.6876355583667755
Epoch: 48 | Iteration number: [760/4518] 16% | Training loss: 0.6876187968410944
Epoch: 48 | Iteration number: [770/4518] 17% | Training loss: 0.6875933073557816
Epoch: 48 | Iteration number: [780/4518] 17% | Training loss: 0.6875814489829235
Epoch: 48 | Iteration number: [790/4518] 17% | Training loss: 0.6875818425341498
Epoch: 48 | Iteration number: [800/4518] 17% | Training loss: 0.6875617197901011
Epoch: 48 | Iteration number: [810/4518] 17% | Training loss: 0.6875508371694589
Epoch: 48 | Iteration number: [820/4518] 18% | Training loss: 0.6875398876463494
Epoch: 48 | Iteration number: [830/4518] 18% | Training loss: 0.6875238946403366
Epoch: 48 | Iteration number: [840/4518] 18% | Training loss: 0.687516515879404
Epoch: 48 | Iteration number: [850/4518] 18% | Training loss: 0.6875232270184686
Epoch: 48 | Iteration number: [860/4518] 19% | Training loss: 0.6874993864880051
Epoch: 48 | Iteration number: [870/4518] 19% | Training loss: 0.6875028586935723
Epoch: 48 | Iteration number: [880/4518] 19% | Training loss: 0.6874935112216256
Epoch: 48 | Iteration number: [890/4518] 19% | Training loss: 0.6874879188082191
Epoch: 48 | Iteration number: [900/4518] 19% | Training loss: 0.6874736505084568
Epoch: 48 | Iteration number: [910/4518] 20% | Training loss: 0.6874609916419774
Epoch: 48 | Iteration number: [920/4518] 20% | Training loss: 0.6874591273458107
Epoch: 48 | Iteration number: [930/4518] 20% | Training loss: 0.6874718011707388
Epoch: 48 | Iteration number: [940/4518] 20% | Training loss: 0.6874624648626815
Epoch: 48 | Iteration number: [950/4518] 21% | Training loss: 0.6874602982872411
Epoch: 48 | Iteration number: [960/4518] 21% | Training loss: 0.6874551629026731
Epoch: 48 | Iteration number: [970/4518] 21% | Training loss: 0.6874475606323518
Epoch: 48 | Iteration number: [980/4518] 21% | Training loss: 0.6874404153045343
Epoch: 48 | Iteration number: [990/4518] 21% | Training loss: 0.6874283240901099
Epoch: 48 | Iteration number: [1000/4518] 22% | Training loss: 0.6874298684000969
Epoch: 48 | Iteration number: [1010/4518] 22% | Training loss: 0.6874302836928037
Epoch: 48 | Iteration number: [1020/4518] 22% | Training loss: 0.6874085456717248
Epoch: 48 | Iteration number: [1030/4518] 22% | Training loss: 0.6874045124910411
Epoch: 48 | Iteration number: [1040/4518] 23% | Training loss: 0.6873922039683048
Epoch: 48 | Iteration number: [1050/4518] 23% | Training loss: 0.6873857164382935
Epoch: 48 | Iteration number: [1060/4518] 23% | Training loss: 0.6873732237321026
Epoch: 48 | Iteration number: [1070/4518] 23% | Training loss: 0.6873605008994308
Epoch: 48 | Iteration number: [1080/4518] 23% | Training loss: 0.6873652562499046
Epoch: 48 | Iteration number: [1090/4518] 24% | Training loss: 0.6873668106870914
Epoch: 48 | Iteration number: [1100/4518] 24% | Training loss: 0.6873655230348761
Epoch: 48 | Iteration number: [1110/4518] 24% | Training loss: 0.6873614224227699
Epoch: 48 | Iteration number: [1120/4518] 24% | Training loss: 0.6873498778258051
Epoch: 48 | Iteration number: [1130/4518] 25% | Training loss: 0.6873521512061094
Epoch: 48 | Iteration number: [1140/4518] 25% | Training loss: 0.6873444207927637
Epoch: 48 | Iteration number: [1150/4518] 25% | Training loss: 0.6873473508461662
Epoch: 48 | Iteration number: [1160/4518] 25% | Training loss: 0.6873329743742943
Epoch: 48 | Iteration number: [1170/4518] 25% | Training loss: 0.6873266223149422
Epoch: 48 | Iteration number: [1180/4518] 26% | Training loss: 0.687320809243089
Epoch: 48 | Iteration number: [1190/4518] 26% | Training loss: 0.6873297646766952
Epoch: 48 | Iteration number: [1200/4518] 26% | Training loss: 0.6873294507960478
Epoch: 48 | Iteration number: [1210/4518] 26% | Training loss: 0.687330390155808
Epoch: 48 | Iteration number: [1220/4518] 27% | Training loss: 0.6873257757698903
Epoch: 48 | Iteration number: [1230/4518] 27% | Training loss: 0.6873230637089024
Epoch: 48 | Iteration number: [1240/4518] 27% | Training loss: 0.6873149590146157
Epoch: 48 | Iteration number: [1250/4518] 27% | Training loss: 0.687311758184433
Epoch: 48 | Iteration number: [1260/4518] 27% | Training loss: 0.6873025894638092
Epoch: 48 | Iteration number: [1270/4518] 28% | Training loss: 0.6873005804583783
Epoch: 48 | Iteration number: [1280/4518] 28% | Training loss: 0.687311933701858
Epoch: 48 | Iteration number: [1290/4518] 28% | Training loss: 0.6872993712277375
Epoch: 48 | Iteration number: [1300/4518] 28% | Training loss: 0.687298129934531
Epoch: 48 | Iteration number: [1310/4518] 28% | Training loss: 0.6873025267633773
Epoch: 48 | Iteration number: [1320/4518] 29% | Training loss: 0.6872977876753518
Epoch: 48 | Iteration number: [1330/4518] 29% | Training loss: 0.6873036675883415
Epoch: 48 | Iteration number: [1340/4518] 29% | Training loss: 0.6873111627884765
Epoch: 48 | Iteration number: [1350/4518] 29% | Training loss: 0.6873049667587987
Epoch: 48 | Iteration number: [1360/4518] 30% | Training loss: 0.68729754436542
Epoch: 48 | Iteration number: [1370/4518] 30% | Training loss: 0.687295646954627
Epoch: 48 | Iteration number: [1380/4518] 30% | Training loss: 0.687290864362233
Epoch: 48 | Iteration number: [1390/4518] 30% | Training loss: 0.6872961103916169
Epoch: 48 | Iteration number: [1400/4518] 30% | Training loss: 0.6872919708916119
Epoch: 48 | Iteration number: [1410/4518] 31% | Training loss: 0.6872915339808092
Epoch: 48 | Iteration number: [1420/4518] 31% | Training loss: 0.6872820241770274
Epoch: 48 | Iteration number: [1430/4518] 31% | Training loss: 0.6872803394611066
Epoch: 48 | Iteration number: [1440/4518] 31% | Training loss: 0.6872723198599285
Epoch: 48 | Iteration number: [1450/4518] 32% | Training loss: 0.6872675716465917
Epoch: 48 | Iteration number: [1460/4518] 32% | Training loss: 0.68726851515574
Epoch: 48 | Iteration number: [1470/4518] 32% | Training loss: 0.6872595210870107
Epoch: 48 | Iteration number: [1480/4518] 32% | Training loss: 0.6872535974190042
Epoch: 48 | Iteration number: [1490/4518] 32% | Training loss: 0.6872487479808347
Epoch: 48 | Iteration number: [1500/4518] 33% | Training loss: 0.6872426126400629
Epoch: 48 | Iteration number: [1510/4518] 33% | Training loss: 0.6872387713549153
Epoch: 48 | Iteration number: [1520/4518] 33% | Training loss: 0.687233861222079
Epoch: 48 | Iteration number: [1530/4518] 33% | Training loss: 0.6872292092812606
Epoch: 48 | Iteration number: [1540/4518] 34% | Training loss: 0.6872230193444661
Epoch: 48 | Iteration number: [1550/4518] 34% | Training loss: 0.6872186152012117
Epoch: 48 | Iteration number: [1560/4518] 34% | Training loss: 0.6872162172045463
Epoch: 48 | Iteration number: [1570/4518] 34% | Training loss: 0.6872079808241243
Epoch: 48 | Iteration number: [1580/4518] 34% | Training loss: 0.6871930342309083
Epoch: 48 | Iteration number: [1590/4518] 35% | Training loss: 0.6871911970324486
Epoch: 48 | Iteration number: [1600/4518] 35% | Training loss: 0.6871916785091162
Epoch: 48 | Iteration number: [1610/4518] 35% | Training loss: 0.6871863519553072
Epoch: 48 | Iteration number: [1620/4518] 35% | Training loss: 0.6871920949515001
Epoch: 48 | Iteration number: [1630/4518] 36% | Training loss: 0.6871963842149161
Epoch: 48 | Iteration number: [1640/4518] 36% | Training loss: 0.6871930480730243
Epoch: 48 | Iteration number: [1650/4518] 36% | Training loss: 0.6871911232399218
Epoch: 48 | Iteration number: [1660/4518] 36% | Training loss: 0.6871947222086321
Epoch: 48 | Iteration number: [1670/4518] 36% | Training loss: 0.6871980797030969
Epoch: 48 | Iteration number: [1680/4518] 37% | Training loss: 0.6871974970967997
Epoch: 48 | Iteration number: [1690/4518] 37% | Training loss: 0.68719096935007
Epoch: 48 | Iteration number: [1700/4518] 37% | Training loss: 0.687191915266654
Epoch: 48 | Iteration number: [1710/4518] 37% | Training loss: 0.6871920778388866
Epoch: 48 | Iteration number: [1720/4518] 38% | Training loss: 0.687192129118498
Epoch: 48 | Iteration number: [1730/4518] 38% | Training loss: 0.6871936525223572
Epoch: 48 | Iteration number: [1740/4518] 38% | Training loss: 0.6871891491029455
Epoch: 48 | Iteration number: [1750/4518] 38% | Training loss: 0.6871824124200003
Epoch: 48 | Iteration number: [1760/4518] 38% | Training loss: 0.6871892368251628
Epoch: 48 | Iteration number: [1770/4518] 39% | Training loss: 0.6871864964733017
Epoch: 48 | Iteration number: [1780/4518] 39% | Training loss: 0.68717935390017
Epoch: 48 | Iteration number: [1790/4518] 39% | Training loss: 0.6871839253929074
Epoch: 48 | Iteration number: [1800/4518] 39% | Training loss: 0.6871833213501506
Epoch: 48 | Iteration number: [1810/4518] 40% | Training loss: 0.6871809677524461
Epoch: 48 | Iteration number: [1820/4518] 40% | Training loss: 0.6871824986987062
Epoch: 48 | Iteration number: [1830/4518] 40% | Training loss: 0.6871794801592176
Epoch: 48 | Iteration number: [1840/4518] 40% | Training loss: 0.6871698320235895
Epoch: 48 | Iteration number: [1850/4518] 40% | Training loss: 0.6871728118368097
Epoch: 48 | Iteration number: [1860/4518] 41% | Training loss: 0.6871713630614742
Epoch: 48 | Iteration number: [1870/4518] 41% | Training loss: 0.6871633733338851
Epoch: 48 | Iteration number: [1880/4518] 41% | Training loss: 0.6871669497895748
Epoch: 48 | Iteration number: [1890/4518] 41% | Training loss: 0.6871635205215878
Epoch: 48 | Iteration number: [1900/4518] 42% | Training loss: 0.6871601476794795
Epoch: 48 | Iteration number: [1910/4518] 42% | Training loss: 0.6871546811458328
Epoch: 48 | Iteration number: [1920/4518] 42% | Training loss: 0.6871568401654561
Epoch: 48 | Iteration number: [1930/4518] 42% | Training loss: 0.6871449846986661
Epoch: 48 | Iteration number: [1940/4518] 42% | Training loss: 0.6871468686873151
Epoch: 48 | Iteration number: [1950/4518] 43% | Training loss: 0.6871438940977439
Epoch: 48 | Iteration number: [1960/4518] 43% | Training loss: 0.6871498936597182
Epoch: 48 | Iteration number: [1970/4518] 43% | Training loss: 0.6871530386699638
Epoch: 48 | Iteration number: [1980/4518] 43% | Training loss: 0.6871528819353894
Epoch: 48 | Iteration number: [1990/4518] 44% | Training loss: 0.6871522413126787
Epoch: 48 | Iteration number: [2000/4518] 44% | Training loss: 0.6871548710167408
Epoch: 48 | Iteration number: [2010/4518] 44% | Training loss: 0.6871501783233377
Epoch: 48 | Iteration number: [2020/4518] 44% | Training loss: 0.6871447383472234
Epoch: 48 | Iteration number: [2030/4518] 44% | Training loss: 0.687149885194055
Epoch: 48 | Iteration number: [2040/4518] 45% | Training loss: 0.6871504142003901
Epoch: 48 | Iteration number: [2050/4518] 45% | Training loss: 0.6871457811099727
Epoch: 48 | Iteration number: [2060/4518] 45% | Training loss: 0.6871452853517624
Epoch: 48 | Iteration number: [2070/4518] 45% | Training loss: 0.6871413544756203
Epoch: 48 | Iteration number: [2080/4518] 46% | Training loss: 0.6871375630967892
Epoch: 48 | Iteration number: [2090/4518] 46% | Training loss: 0.687138510862606
Epoch: 48 | Iteration number: [2100/4518] 46% | Training loss: 0.6871336288963046
Epoch: 48 | Iteration number: [2110/4518] 46% | Training loss: 0.6871307125023756
Epoch: 48 | Iteration number: [2120/4518] 46% | Training loss: 0.6871265314659982
Epoch: 48 | Iteration number: [2130/4518] 47% | Training loss: 0.6871262106257425
Epoch: 48 | Iteration number: [2140/4518] 47% | Training loss: 0.6871292124841815
Epoch: 48 | Iteration number: [2150/4518] 47% | Training loss: 0.6871273560024971
Epoch: 48 | Iteration number: [2160/4518] 47% | Training loss: 0.6871274782275713
Epoch: 48 | Iteration number: [2170/4518] 48% | Training loss: 0.6871283101870717
Epoch: 48 | Iteration number: [2180/4518] 48% | Training loss: 0.6871226985520179
Epoch: 48 | Iteration number: [2190/4518] 48% | Training loss: 0.6871231983785759
Epoch: 48 | Iteration number: [2200/4518] 48% | Training loss: 0.6871130534193732
Epoch: 48 | Iteration number: [2210/4518] 48% | Training loss: 0.6871044695107645
Epoch: 48 | Iteration number: [2220/4518] 49% | Training loss: 0.6871078908443451
Epoch: 48 | Iteration number: [2230/4518] 49% | Training loss: 0.6871043195371671
Epoch: 48 | Iteration number: [2240/4518] 49% | Training loss: 0.6871066367519754
Epoch: 48 | Iteration number: [2250/4518] 49% | Training loss: 0.687105052418179
Epoch: 48 | Iteration number: [2260/4518] 50% | Training loss: 0.687100651570126
Epoch: 48 | Iteration number: [2270/4518] 50% | Training loss: 0.687094059468366
Epoch: 48 | Iteration number: [2280/4518] 50% | Training loss: 0.6871008916905051
Epoch: 48 | Iteration number: [2290/4518] 50% | Training loss: 0.6871004784471604
Epoch: 48 | Iteration number: [2300/4518] 50% | Training loss: 0.6871006333568822
Epoch: 48 | Iteration number: [2310/4518] 51% | Training loss: 0.6870986690768948
Epoch: 48 | Iteration number: [2320/4518] 51% | Training loss: 0.6870984976661616
Epoch: 48 | Iteration number: [2330/4518] 51% | Training loss: 0.6870995338638453
Epoch: 48 | Iteration number: [2340/4518] 51% | Training loss: 0.6870999224420287
Epoch: 48 | Iteration number: [2350/4518] 52% | Training loss: 0.6870949530347865
Epoch: 48 | Iteration number: [2360/4518] 52% | Training loss: 0.687093832129139
Epoch: 48 | Iteration number: [2370/4518] 52% | Training loss: 0.6870968827466925
Epoch: 48 | Iteration number: [2380/4518] 52% | Training loss: 0.6870966113665524
Epoch: 48 | Iteration number: [2390/4518] 52% | Training loss: 0.68709549557215
Epoch: 48 | Iteration number: [2400/4518] 53% | Training loss: 0.6870975515494744
Epoch: 48 | Iteration number: [2410/4518] 53% | Training loss: 0.6870910812215686
Epoch: 48 | Iteration number: [2420/4518] 53% | Training loss: 0.6870941567026879
Epoch: 48 | Iteration number: [2430/4518] 53% | Training loss: 0.6870929912529855
Epoch: 48 | Iteration number: [2440/4518] 54% | Training loss: 0.687091575929376
Epoch: 48 | Iteration number: [2450/4518] 54% | Training loss: 0.6870889529160091
Epoch: 48 | Iteration number: [2460/4518] 54% | Training loss: 0.6870941461828666
Epoch: 48 | Iteration number: [2470/4518] 54% | Training loss: 0.6870944451706612
Epoch: 48 | Iteration number: [2480/4518] 54% | Training loss: 0.6870923197077167
Epoch: 48 | Iteration number: [2490/4518] 55% | Training loss: 0.687088013581004
Epoch: 48 | Iteration number: [2500/4518] 55% | Training loss: 0.6870885071277618
Epoch: 48 | Iteration number: [2510/4518] 55% | Training loss: 0.6870877953877013
Epoch: 48 | Iteration number: [2520/4518] 55% | Training loss: 0.6870859263671769
Epoch: 48 | Iteration number: [2530/4518] 55% | Training loss: 0.6870855762788901
Epoch: 48 | Iteration number: [2540/4518] 56% | Training loss: 0.6870863985358261
Epoch: 48 | Iteration number: [2550/4518] 56% | Training loss: 0.6870814469047621
Epoch: 48 | Iteration number: [2560/4518] 56% | Training loss: 0.6870800492819399
Epoch: 48 | Iteration number: [2570/4518] 56% | Training loss: 0.6870778416381272
Epoch: 48 | Iteration number: [2580/4518] 57% | Training loss: 0.6870716913957005
Epoch: 48 | Iteration number: [2590/4518] 57% | Training loss: 0.6870700027951863
Epoch: 48 | Iteration number: [2600/4518] 57% | Training loss: 0.6870676046609878
Epoch: 48 | Iteration number: [2610/4518] 57% | Training loss: 0.6870638727685044
Epoch: 48 | Iteration number: [2620/4518] 57% | Training loss: 0.6870652875827469
Epoch: 48 | Iteration number: [2630/4518] 58% | Training loss: 0.6870652519024824
Epoch: 48 | Iteration number: [2640/4518] 58% | Training loss: 0.6870613382169695
Epoch: 48 | Iteration number: [2650/4518] 58% | Training loss: 0.6870614027752067
Epoch: 48 | Iteration number: [2660/4518] 58% | Training loss: 0.68705197754211
Epoch: 48 | Iteration number: [2670/4518] 59% | Training loss: 0.6870509610417184
Epoch: 48 | Iteration number: [2680/4518] 59% | Training loss: 0.6870518386363983
Epoch: 48 | Iteration number: [2690/4518] 59% | Training loss: 0.6870511721057962
Epoch: 48 | Iteration number: [2700/4518] 59% | Training loss: 0.6870492721266217
Epoch: 48 | Iteration number: [2710/4518] 59% | Training loss: 0.6870559347951544
Epoch: 48 | Iteration number: [2720/4518] 60% | Training loss: 0.6870551641592209
Epoch: 48 | Iteration number: [2730/4518] 60% | Training loss: 0.6870535488530393
Epoch: 48 | Iteration number: [2740/4518] 60% | Training loss: 0.6870541012417661
Epoch: 48 | Iteration number: [2750/4518] 60% | Training loss: 0.6870501529736952
Epoch: 48 | Iteration number: [2760/4518] 61% | Training loss: 0.6870500311255455
Epoch: 48 | Iteration number: [2770/4518] 61% | Training loss: 0.6870543515424006
Epoch: 48 | Iteration number: [2780/4518] 61% | Training loss: 0.6870559024725029
Epoch: 48 | Iteration number: [2790/4518] 61% | Training loss: 0.6870569617303897
Epoch: 48 | Iteration number: [2800/4518] 61% | Training loss: 0.6870593424567154
Epoch: 48 | Iteration number: [2810/4518] 62% | Training loss: 0.6870574360640448
Epoch: 48 | Iteration number: [2820/4518] 62% | Training loss: 0.687046658231857
Epoch: 48 | Iteration number: [2830/4518] 62% | Training loss: 0.6870434437750085
Epoch: 48 | Iteration number: [2840/4518] 62% | Training loss: 0.6870389945280384
Epoch: 48 | Iteration number: [2850/4518] 63% | Training loss: 0.6870387998798437
Epoch: 48 | Iteration number: [2860/4518] 63% | Training loss: 0.6870383912866765
Epoch: 48 | Iteration number: [2870/4518] 63% | Training loss: 0.6870358313002237
Epoch: 48 | Iteration number: [2880/4518] 63% | Training loss: 0.6870308355738719
Epoch: 48 | Iteration number: [2890/4518] 63% | Training loss: 0.6870319111536943
Epoch: 48 | Iteration number: [2900/4518] 64% | Training loss: 0.6870277355662707
Epoch: 48 | Iteration number: [2910/4518] 64% | Training loss: 0.6870273709706834
Epoch: 48 | Iteration number: [2920/4518] 64% | Training loss: 0.6870270858072255
Epoch: 48 | Iteration number: [2930/4518] 64% | Training loss: 0.6870203069859397
Epoch: 48 | Iteration number: [2940/4518] 65% | Training loss: 0.6870222402064978
Epoch: 48 | Iteration number: [2950/4518] 65% | Training loss: 0.6870280870946787
Epoch: 48 | Iteration number: [2960/4518] 65% | Training loss: 0.6870279101705229
Epoch: 48 | Iteration number: [2970/4518] 65% | Training loss: 0.6870212044980791
Epoch: 48 | Iteration number: [2980/4518] 65% | Training loss: 0.687023986645993
Epoch: 48 | Iteration number: [2990/4518] 66% | Training loss: 0.6870217270476363
Epoch: 48 | Iteration number: [3000/4518] 66% | Training loss: 0.687023297170798
Epoch: 48 | Iteration number: [3010/4518] 66% | Training loss: 0.6870213477912536
Epoch: 48 | Iteration number: [3020/4518] 66% | Training loss: 0.6870196990816798
Epoch: 48 | Iteration number: [3030/4518] 67% | Training loss: 0.6870200333618882
Epoch: 48 | Iteration number: [3040/4518] 67% | Training loss: 0.6870184149200979
Epoch: 48 | Iteration number: [3050/4518] 67% | Training loss: 0.6870175907455507
Epoch: 48 | Iteration number: [3060/4518] 67% | Training loss: 0.6870213734558205
Epoch: 48 | Iteration number: [3070/4518] 67% | Training loss: 0.687023148028004
Epoch: 48 | Iteration number: [3080/4518] 68% | Training loss: 0.6870271223512563
Epoch: 48 | Iteration number: [3090/4518] 68% | Training loss: 0.6870295874509225
Epoch: 48 | Iteration number: [3100/4518] 68% | Training loss: 0.6870258682966233
Epoch: 48 | Iteration number: [3110/4518] 68% | Training loss: 0.687023264687161
Epoch: 48 | Iteration number: [3120/4518] 69% | Training loss: 0.6870199056198963
Epoch: 48 | Iteration number: [3130/4518] 69% | Training loss: 0.6870180166377047
Epoch: 48 | Iteration number: [3140/4518] 69% | Training loss: 0.6870159726993293
Epoch: 48 | Iteration number: [3150/4518] 69% | Training loss: 0.6870157737958998
Epoch: 48 | Iteration number: [3160/4518] 69% | Training loss: 0.6870149145209337
Epoch: 48 | Iteration number: [3170/4518] 70% | Training loss: 0.687020519761257
Epoch: 48 | Iteration number: [3180/4518] 70% | Training loss: 0.6870211983064436
Epoch: 48 | Iteration number: [3190/4518] 70% | Training loss: 0.6870243328492096
Epoch: 48 | Iteration number: [3200/4518] 70% | Training loss: 0.6870182522945106
Epoch: 48 | Iteration number: [3210/4518] 71% | Training loss: 0.6870214989809232
Epoch: 48 | Iteration number: [3220/4518] 71% | Training loss: 0.6870226673272826
Epoch: 48 | Iteration number: [3230/4518] 71% | Training loss: 0.6870242465760317
Epoch: 48 | Iteration number: [3240/4518] 71% | Training loss: 0.6870251873577082
Epoch: 48 | Iteration number: [3250/4518] 71% | Training loss: 0.6870269920092362
Epoch: 48 | Iteration number: [3260/4518] 72% | Training loss: 0.6870280040188069
Epoch: 48 | Iteration number: [3270/4518] 72% | Training loss: 0.6870272014483764
Epoch: 48 | Iteration number: [3280/4518] 72% | Training loss: 0.6870236636298459
Epoch: 48 | Iteration number: [3290/4518] 72% | Training loss: 0.6870211598539787
Epoch: 48 | Iteration number: [3300/4518] 73% | Training loss: 0.6870220056085875
Epoch: 48 | Iteration number: [3310/4518] 73% | Training loss: 0.6870203391122673
Epoch: 48 | Iteration number: [3320/4518] 73% | Training loss: 0.6870197869388454
Epoch: 48 | Iteration number: [3330/4518] 73% | Training loss: 0.6870177691942221
Epoch: 48 | Iteration number: [3340/4518] 73% | Training loss: 0.6870168617920961
Epoch: 48 | Iteration number: [3350/4518] 74% | Training loss: 0.6870169683534708
Epoch: 48 | Iteration number: [3360/4518] 74% | Training loss: 0.6870166663790033
Epoch: 48 | Iteration number: [3370/4518] 74% | Training loss: 0.6870173891680177
Epoch: 48 | Iteration number: [3380/4518] 74% | Training loss: 0.6870208353685909
Epoch: 48 | Iteration number: [3390/4518] 75% | Training loss: 0.6870218774210387
Epoch: 48 | Iteration number: [3400/4518] 75% | Training loss: 0.6870203894026139
Epoch: 48 | Iteration number: [3410/4518] 75% | Training loss: 0.6870198929239928
Epoch: 48 | Iteration number: [3420/4518] 75% | Training loss: 0.6870195753915965
Epoch: 48 | Iteration number: [3430/4518] 75% | Training loss: 0.6870159762246268
Epoch: 48 | Iteration number: [3440/4518] 76% | Training loss: 0.6870156891644001
Epoch: 48 | Iteration number: [3450/4518] 76% | Training loss: 0.6870156186559926
Epoch: 48 | Iteration number: [3460/4518] 76% | Training loss: 0.687016706401213
Epoch: 48 | Iteration number: [3470/4518] 76% | Training loss: 0.6870168837415382
Epoch: 48 | Iteration number: [3480/4518] 77% | Training loss: 0.6870196421256011
Epoch: 48 | Iteration number: [3490/4518] 77% | Training loss: 0.687018210310649
Epoch: 48 | Iteration number: [3500/4518] 77% | Training loss: 0.6870172801017761
Epoch: 48 | Iteration number: [3510/4518] 77% | Training loss: 0.6870175249895819
Epoch: 48 | Iteration number: [3520/4518] 77% | Training loss: 0.6870204312049529
Epoch: 48 | Iteration number: [3530/4518] 78% | Training loss: 0.6870195871540913
Epoch: 48 | Iteration number: [3540/4518] 78% | Training loss: 0.6870175052665721
Epoch: 48 | Iteration number: [3550/4518] 78% | Training loss: 0.6870159271569319
Epoch: 48 | Iteration number: [3560/4518] 78% | Training loss: 0.6870155994476898
Epoch: 48 | Iteration number: [3570/4518] 79% | Training loss: 0.6870146068538271
Epoch: 48 | Iteration number: [3580/4518] 79% | Training loss: 0.6870134503981254
Epoch: 48 | Iteration number: [3590/4518] 79% | Training loss: 0.6870125843289835
Epoch: 48 | Iteration number: [3600/4518] 79% | Training loss: 0.6870098290509647
Epoch: 48 | Iteration number: [3610/4518] 79% | Training loss: 0.6870080791351868
Epoch: 48 | Iteration number: [3620/4518] 80% | Training loss: 0.6870066652640453
Epoch: 48 | Iteration number: [3630/4518] 80% | Training loss: 0.6870054525448928
Epoch: 48 | Iteration number: [3640/4518] 80% | Training loss: 0.6870046467080221
Epoch: 48 | Iteration number: [3650/4518] 80% | Training loss: 0.6870059752790896
Epoch: 48 | Iteration number: [3660/4518] 81% | Training loss: 0.6870096643602913
Epoch: 48 | Iteration number: [3670/4518] 81% | Training loss: 0.6870063235064618
Epoch: 48 | Iteration number: [3680/4518] 81% | Training loss: 0.6870072036981583
Epoch: 48 | Iteration number: [3690/4518] 81% | Training loss: 0.6870064549975925
Epoch: 48 | Iteration number: [3700/4518] 81% | Training loss: 0.6870069918600289
Epoch: 48 | Iteration number: [3710/4518] 82% | Training loss: 0.6870059931856602
Epoch: 48 | Iteration number: [3720/4518] 82% | Training loss: 0.6870085982385502
Epoch: 48 | Iteration number: [3730/4518] 82% | Training loss: 0.6870075533600979
Epoch: 48 | Iteration number: [3740/4518] 82% | Training loss: 0.687002590155219
Epoch: 48 | Iteration number: [3750/4518] 83% | Training loss: 0.6870018300215404
Epoch: 48 | Iteration number: [3760/4518] 83% | Training loss: 0.6869993434465946
Epoch: 48 | Iteration number: [3770/4518] 83% | Training loss: 0.6869997672756407
Epoch: 48 | Iteration number: [3780/4518] 83% | Training loss: 0.6870026063509088
Epoch: 48 | Iteration number: [3790/4518] 83% | Training loss: 0.6869996496744081
Epoch: 48 | Iteration number: [3800/4518] 84% | Training loss: 0.6869986435457279
Epoch: 48 | Iteration number: [3810/4518] 84% | Training loss: 0.6869988655950141
Epoch: 48 | Iteration number: [3820/4518] 84% | Training loss: 0.6869971982939705
Epoch: 48 | Iteration number: [3830/4518] 84% | Training loss: 0.6869993666911561
Epoch: 48 | Iteration number: [3840/4518] 84% | Training loss: 0.6869994781600932
Epoch: 48 | Iteration number: [3850/4518] 85% | Training loss: 0.6869999565861442
Epoch: 48 | Iteration number: [3860/4518] 85% | Training loss: 0.6869987823184908
Epoch: 48 | Iteration number: [3870/4518] 85% | Training loss: 0.6869969153127005
Epoch: 48 | Iteration number: [3880/4518] 85% | Training loss: 0.6869956374014776
Epoch: 48 | Iteration number: [3890/4518] 86% | Training loss: 0.6869957523817881
Epoch: 48 | Iteration number: [3900/4518] 86% | Training loss: 0.6869949694933035
Epoch: 48 | Iteration number: [3910/4518] 86% | Training loss: 0.6869910579660664
Epoch: 48 | Iteration number: [3920/4518] 86% | Training loss: 0.6869898666076514
Epoch: 48 | Iteration number: [3930/4518] 86% | Training loss: 0.6869900136503555
Epoch: 48 | Iteration number: [3940/4518] 87% | Training loss: 0.6869886256111455
Epoch: 48 | Iteration number: [3950/4518] 87% | Training loss: 0.6869903035103521
Epoch: 48 | Iteration number: [3960/4518] 87% | Training loss: 0.6869890654327894
Epoch: 48 | Iteration number: [3970/4518] 87% | Training loss: 0.6869878098556317
Epoch: 48 | Iteration number: [3980/4518] 88% | Training loss: 0.68698486083716
Epoch: 48 | Iteration number: [3990/4518] 88% | Training loss: 0.6869836883736135
Epoch: 48 | Iteration number: [4000/4518] 88% | Training loss: 0.6869814743697643
Epoch: 48 | Iteration number: [4010/4518] 88% | Training loss: 0.686978117842924
Epoch: 48 | Iteration number: [4020/4518] 88% | Training loss: 0.6869796823506331
Epoch: 48 | Iteration number: [4030/4518] 89% | Training loss: 0.6869813818789593
Epoch: 48 | Iteration number: [4040/4518] 89% | Training loss: 0.6869798041806363
Epoch: 48 | Iteration number: [4050/4518] 89% | Training loss: 0.6869806536774576
Epoch: 48 | Iteration number: [4060/4518] 89% | Training loss: 0.6869834852776504
Epoch: 48 | Iteration number: [4070/4518] 90% | Training loss: 0.6869832255037762
Epoch: 48 | Iteration number: [4080/4518] 90% | Training loss: 0.6869784394315644
Epoch: 48 | Iteration number: [4090/4518] 90% | Training loss: 0.6869743045355696
Epoch: 48 | Iteration number: [4100/4518] 90% | Training loss: 0.686974092576562
Epoch: 48 | Iteration number: [4110/4518] 90% | Training loss: 0.6869740861320728
Epoch: 48 | Iteration number: [4120/4518] 91% | Training loss: 0.6869734369001342
Epoch: 48 | Iteration number: [4130/4518] 91% | Training loss: 0.6869728003229414
Epoch: 48 | Iteration number: [4140/4518] 91% | Training loss: 0.6869708075759492
Epoch: 48 | Iteration number: [4150/4518] 91% | Training loss: 0.6869710259408836
Epoch: 48 | Iteration number: [4160/4518] 92% | Training loss: 0.6869727812850704
Epoch: 48 | Iteration number: [4170/4518] 92% | Training loss: 0.686971718172947
Epoch: 48 | Iteration number: [4180/4518] 92% | Training loss: 0.6869716947301153
Epoch: 48 | Iteration number: [4190/4518] 92% | Training loss: 0.6869726431255978
Epoch: 48 | Iteration number: [4200/4518] 92% | Training loss: 0.6869723455820764
Epoch: 48 | Iteration number: [4210/4518] 93% | Training loss: 0.6869716670762331
Epoch: 48 | Iteration number: [4220/4518] 93% | Training loss: 0.6869711431705556
Epoch: 48 | Iteration number: [4230/4518] 93% | Training loss: 0.6869695618220255
Epoch: 48 | Iteration number: [4240/4518] 93% | Training loss: 0.6869690602258691
Epoch: 48 | Iteration number: [4250/4518] 94% | Training loss: 0.6869693561582004
Epoch: 48 | Iteration number: [4260/4518] 94% | Training loss: 0.6869678701313449
Epoch: 48 | Iteration number: [4270/4518] 94% | Training loss: 0.6869658868541763
Epoch: 48 | Iteration number: [4280/4518] 94% | Training loss: 0.6869652313606761
Epoch: 48 | Iteration number: [4290/4518] 94% | Training loss: 0.6869661190154114
Epoch: 48 | Iteration number: [4300/4518] 95% | Training loss: 0.6869676044791244
Epoch: 48 | Iteration number: [4310/4518] 95% | Training loss: 0.6869693729136217
Epoch: 48 | Iteration number: [4320/4518] 95% | Training loss: 0.6869694507922287
Epoch: 48 | Iteration number: [4330/4518] 95% | Training loss: 0.6869697429153715
Epoch: 48 | Iteration number: [4340/4518] 96% | Training loss: 0.6869675762642364
Epoch: 48 | Iteration number: [4350/4518] 96% | Training loss: 0.6869672031101139
Epoch: 48 | Iteration number: [4360/4518] 96% | Training loss: 0.6869650900227214
Epoch: 48 | Iteration number: [4370/4518] 96% | Training loss: 0.68696521371944
Epoch: 48 | Iteration number: [4380/4518] 96% | Training loss: 0.686965744136131
Epoch: 48 | Iteration number: [4390/4518] 97% | Training loss: 0.6869660858141262
Epoch: 48 | Iteration number: [4400/4518] 97% | Training loss: 0.6869666102393107
Epoch: 48 | Iteration number: [4410/4518] 97% | Training loss: 0.6869689934918669
Epoch: 48 | Iteration number: [4420/4518] 97% | Training loss: 0.6869718774816029
Epoch: 48 | Iteration number: [4430/4518] 98% | Training loss: 0.686971611470724
Epoch: 48 | Iteration number: [4440/4518] 98% | Training loss: 0.68697139467742
Epoch: 48 | Iteration number: [4450/4518] 98% | Training loss: 0.6869729180550307
Epoch: 48 | Iteration number: [4460/4518] 98% | Training loss: 0.6869711875915527
Epoch: 48 | Iteration number: [4470/4518] 98% | Training loss: 0.6869690359038795
Epoch: 48 | Iteration number: [4480/4518] 99% | Training loss: 0.6869701332279614
Epoch: 48 | Iteration number: [4490/4518] 99% | Training loss: 0.6869681179788968
Epoch: 48 | Iteration number: [4500/4518] 99% | Training loss: 0.6869664455784692
Epoch: 48 | Iteration number: [4510/4518] 99% | Training loss: 0.6869691700734479

 End of epoch: 48 | Train Loss: 0.6868163368616446 | Training Time: 640 

 End of epoch: 48 | Eval Loss: 0.6900160762728477 | Evaluating Time: 17 
Epoch: 49 | Iteration number: [10/4518] 0% | Training loss: 0.7564181864261628
Epoch: 49 | Iteration number: [20/4518] 0% | Training loss: 0.7208587914705277
Epoch: 49 | Iteration number: [30/4518] 0% | Training loss: 0.7094710965951284
Epoch: 49 | Iteration number: [40/4518] 0% | Training loss: 0.7034836411476135
Epoch: 49 | Iteration number: [50/4518] 1% | Training loss: 0.6998441863059998
Epoch: 49 | Iteration number: [60/4518] 1% | Training loss: 0.697624558210373
Epoch: 49 | Iteration number: [70/4518] 1% | Training loss: 0.6960412928036281
Epoch: 49 | Iteration number: [80/4518] 1% | Training loss: 0.69483727440238
Epoch: 49 | Iteration number: [90/4518] 1% | Training loss: 0.693940544128418
Epoch: 49 | Iteration number: [100/4518] 2% | Training loss: 0.6932111024856568
Epoch: 49 | Iteration number: [110/4518] 2% | Training loss: 0.6925012973221866
Epoch: 49 | Iteration number: [120/4518] 2% | Training loss: 0.6921206856767337
Epoch: 49 | Iteration number: [130/4518] 2% | Training loss: 0.6916930102385007
Epoch: 49 | Iteration number: [140/4518] 3% | Training loss: 0.6913973880665643
Epoch: 49 | Iteration number: [150/4518] 3% | Training loss: 0.6909863932927449
Epoch: 49 | Iteration number: [160/4518] 3% | Training loss: 0.6907366834580898
Epoch: 49 | Iteration number: [170/4518] 3% | Training loss: 0.6904694420449874
Epoch: 49 | Iteration number: [180/4518] 3% | Training loss: 0.6902226934830348
Epoch: 49 | Iteration number: [190/4518] 4% | Training loss: 0.690108649354232
Epoch: 49 | Iteration number: [200/4518] 4% | Training loss: 0.6899409806728363
Epoch: 49 | Iteration number: [210/4518] 4% | Training loss: 0.6898125787576039
Epoch: 49 | Iteration number: [220/4518] 4% | Training loss: 0.6897209663282741
Epoch: 49 | Iteration number: [230/4518] 5% | Training loss: 0.6895617938559988
Epoch: 49 | Iteration number: [240/4518] 5% | Training loss: 0.6894829044739406
Epoch: 49 | Iteration number: [250/4518] 5% | Training loss: 0.6893376610279083
Epoch: 49 | Iteration number: [260/4518] 5% | Training loss: 0.6892300216051248
Epoch: 49 | Iteration number: [270/4518] 5% | Training loss: 0.6891334226837864
Epoch: 49 | Iteration number: [280/4518] 6% | Training loss: 0.6890521236828395
Epoch: 49 | Iteration number: [290/4518] 6% | Training loss: 0.6889956170114978
Epoch: 49 | Iteration number: [300/4518] 6% | Training loss: 0.6889464890956879
Epoch: 49 | Iteration number: [310/4518] 6% | Training loss: 0.6888962703366434
Epoch: 49 | Iteration number: [320/4518] 7% | Training loss: 0.6888523027300835
Epoch: 49 | Iteration number: [330/4518] 7% | Training loss: 0.6888227675900315
Epoch: 49 | Iteration number: [340/4518] 7% | Training loss: 0.6887791109435698
Epoch: 49 | Iteration number: [350/4518] 7% | Training loss: 0.6887159390108926
Epoch: 49 | Iteration number: [360/4518] 7% | Training loss: 0.6886571415596539
Epoch: 49 | Iteration number: [370/4518] 8% | Training loss: 0.6886284826575099
Epoch: 49 | Iteration number: [380/4518] 8% | Training loss: 0.6886138900330192
Epoch: 49 | Iteration number: [390/4518] 8% | Training loss: 0.6885818392802507
Epoch: 49 | Iteration number: [400/4518] 8% | Training loss: 0.6885668577253818
Epoch: 49 | Iteration number: [410/4518] 9% | Training loss: 0.688499053949263
Epoch: 49 | Iteration number: [420/4518] 9% | Training loss: 0.6884807507197063
Epoch: 49 | Iteration number: [430/4518] 9% | Training loss: 0.6884688342726508
Epoch: 49 | Iteration number: [440/4518] 9% | Training loss: 0.6884382566267794
Epoch: 49 | Iteration number: [450/4518] 9% | Training loss: 0.688389732837677
Epoch: 49 | Iteration number: [460/4518] 10% | Training loss: 0.6883701599162558
Epoch: 49 | Iteration number: [470/4518] 10% | Training loss: 0.6883534288152735
Epoch: 49 | Iteration number: [480/4518] 10% | Training loss: 0.6883219620833795
Epoch: 49 | Iteration number: [490/4518] 10% | Training loss: 0.6882936460631234
Epoch: 49 | Iteration number: [500/4518] 11% | Training loss: 0.6882626438140869
Epoch: 49 | Iteration number: [510/4518] 11% | Training loss: 0.6882338293627197
Epoch: 49 | Iteration number: [520/4518] 11% | Training loss: 0.6882099874890768
Epoch: 49 | Iteration number: [530/4518] 11% | Training loss: 0.6881878192694681
Epoch: 49 | Iteration number: [540/4518] 11% | Training loss: 0.6881449853932416
Epoch: 49 | Iteration number: [550/4518] 12% | Training loss: 0.6881143886392767
Epoch: 49 | Iteration number: [560/4518] 12% | Training loss: 0.688100388433252
Epoch: 49 | Iteration number: [570/4518] 12% | Training loss: 0.6880960062930458
Epoch: 49 | Iteration number: [580/4518] 12% | Training loss: 0.6880635531811878
Epoch: 49 | Iteration number: [590/4518] 13% | Training loss: 0.6880311749749265
Epoch: 49 | Iteration number: [600/4518] 13% | Training loss: 0.6880357719461123
Epoch: 49 | Iteration number: [610/4518] 13% | Training loss: 0.688000996288706
Epoch: 49 | Iteration number: [620/4518] 13% | Training loss: 0.6879890743763216
Epoch: 49 | Iteration number: [630/4518] 13% | Training loss: 0.6879683179514748
Epoch: 49 | Iteration number: [640/4518] 14% | Training loss: 0.6879295024089516
Epoch: 49 | Iteration number: [650/4518] 14% | Training loss: 0.6879060497650733
Epoch: 49 | Iteration number: [660/4518] 14% | Training loss: 0.6878936399113048
Epoch: 49 | Iteration number: [670/4518] 14% | Training loss: 0.6878842238169998
Epoch: 49 | Iteration number: [680/4518] 15% | Training loss: 0.6878662425805541
Epoch: 49 | Iteration number: [690/4518] 15% | Training loss: 0.6878665497337563
Epoch: 49 | Iteration number: [700/4518] 15% | Training loss: 0.687859536239079
Epoch: 49 | Iteration number: [710/4518] 15% | Training loss: 0.6878535373949669
Epoch: 49 | Iteration number: [720/4518] 15% | Training loss: 0.6878253574172656
Epoch: 49 | Iteration number: [730/4518] 16% | Training loss: 0.6878074571694414
Epoch: 49 | Iteration number: [740/4518] 16% | Training loss: 0.6877987400100037
Epoch: 49 | Iteration number: [750/4518] 16% | Training loss: 0.687783341884613
Epoch: 49 | Iteration number: [760/4518] 16% | Training loss: 0.6877752886790979
Epoch: 49 | Iteration number: [770/4518] 17% | Training loss: 0.6877679510550065
Epoch: 49 | Iteration number: [780/4518] 17% | Training loss: 0.6877613481802818
Epoch: 49 | Iteration number: [790/4518] 17% | Training loss: 0.6877606608445131
Epoch: 49 | Iteration number: [800/4518] 17% | Training loss: 0.687724560201168
Epoch: 49 | Iteration number: [810/4518] 17% | Training loss: 0.687699208068259
Epoch: 49 | Iteration number: [820/4518] 18% | Training loss: 0.6876935279950863
Epoch: 49 | Iteration number: [830/4518] 18% | Training loss: 0.6876745333872646
Epoch: 49 | Iteration number: [840/4518] 18% | Training loss: 0.6876562002868879
Epoch: 49 | Iteration number: [850/4518] 18% | Training loss: 0.6876390794445487
Epoch: 49 | Iteration number: [860/4518] 19% | Training loss: 0.6876274348691452
Epoch: 49 | Iteration number: [870/4518] 19% | Training loss: 0.68761624344464
Epoch: 49 | Iteration number: [880/4518] 19% | Training loss: 0.6875951969488101
Epoch: 49 | Iteration number: [890/4518] 19% | Training loss: 0.6875922861393918
Epoch: 49 | Iteration number: [900/4518] 19% | Training loss: 0.6875818055868149
Epoch: 49 | Iteration number: [910/4518] 20% | Training loss: 0.6875592237645454
Epoch: 49 | Iteration number: [920/4518] 20% | Training loss: 0.6875415711299233
Epoch: 49 | Iteration number: [930/4518] 20% | Training loss: 0.6875334087238517
Epoch: 49 | Iteration number: [940/4518] 20% | Training loss: 0.687541600427729
Epoch: 49 | Iteration number: [950/4518] 21% | Training loss: 0.6875338260123605
Epoch: 49 | Iteration number: [960/4518] 21% | Training loss: 0.6875235379983982
Epoch: 49 | Iteration number: [970/4518] 21% | Training loss: 0.687518778105372
Epoch: 49 | Iteration number: [980/4518] 21% | Training loss: 0.6875149808976115
Epoch: 49 | Iteration number: [990/4518] 21% | Training loss: 0.687494051336038
Epoch: 49 | Iteration number: [1000/4518] 22% | Training loss: 0.6874700745940209
Epoch: 49 | Iteration number: [1010/4518] 22% | Training loss: 0.6874643435572634
Epoch: 49 | Iteration number: [1020/4518] 22% | Training loss: 0.6874513420988532
Epoch: 49 | Iteration number: [1030/4518] 22% | Training loss: 0.687450163341263
Epoch: 49 | Iteration number: [1040/4518] 23% | Training loss: 0.6874384939670563
Epoch: 49 | Iteration number: [1050/4518] 23% | Training loss: 0.6874337897981916
Epoch: 49 | Iteration number: [1060/4518] 23% | Training loss: 0.6874168778365513
Epoch: 49 | Iteration number: [1070/4518] 23% | Training loss: 0.6874078704932025
Epoch: 49 | Iteration number: [1080/4518] 23% | Training loss: 0.6874013863779881
Epoch: 49 | Iteration number: [1090/4518] 24% | Training loss: 0.687410956949269
Epoch: 49 | Iteration number: [1100/4518] 24% | Training loss: 0.6874096745252609
Epoch: 49 | Iteration number: [1110/4518] 24% | Training loss: 0.6874093121236509
Epoch: 49 | Iteration number: [1120/4518] 24% | Training loss: 0.6874101371637412
Epoch: 49 | Iteration number: [1130/4518] 25% | Training loss: 0.6874056056009985
Epoch: 49 | Iteration number: [1140/4518] 25% | Training loss: 0.6873915280689273
Epoch: 49 | Iteration number: [1150/4518] 25% | Training loss: 0.6873742512516353
Epoch: 49 | Iteration number: [1160/4518] 25% | Training loss: 0.6873677658623663
Epoch: 49 | Iteration number: [1170/4518] 25% | Training loss: 0.6873633569122379
Epoch: 49 | Iteration number: [1180/4518] 26% | Training loss: 0.6873487804400719
Epoch: 49 | Iteration number: [1190/4518] 26% | Training loss: 0.6873408106194825
Epoch: 49 | Iteration number: [1200/4518] 26% | Training loss: 0.6873326675097148
Epoch: 49 | Iteration number: [1210/4518] 26% | Training loss: 0.6873256811425705
Epoch: 49 | Iteration number: [1220/4518] 27% | Training loss: 0.6873180067441502
Epoch: 49 | Iteration number: [1230/4518] 27% | Training loss: 0.6873169802553285
Epoch: 49 | Iteration number: [1240/4518] 27% | Training loss: 0.6873126141005946
Epoch: 49 | Iteration number: [1250/4518] 27% | Training loss: 0.6873062739372253
Epoch: 49 | Iteration number: [1260/4518] 27% | Training loss: 0.6873003524920297
Epoch: 49 | Iteration number: [1270/4518] 28% | Training loss: 0.6873073575064892
Epoch: 49 | Iteration number: [1280/4518] 28% | Training loss: 0.6873022404499352
Epoch: 49 | Iteration number: [1290/4518] 28% | Training loss: 0.6872850764629452
Epoch: 49 | Iteration number: [1300/4518] 28% | Training loss: 0.6872759817196773
Epoch: 49 | Iteration number: [1310/4518] 28% | Training loss: 0.6872715871752674
Epoch: 49 | Iteration number: [1320/4518] 29% | Training loss: 0.6872766627506777
Epoch: 49 | Iteration number: [1330/4518] 29% | Training loss: 0.6872835498107107
Epoch: 49 | Iteration number: [1340/4518] 29% | Training loss: 0.687276988109546
Epoch: 49 | Iteration number: [1350/4518] 29% | Training loss: 0.6872706399140535
Epoch: 49 | Iteration number: [1360/4518] 30% | Training loss: 0.6872776237042512
Epoch: 49 | Iteration number: [1370/4518] 30% | Training loss: 0.6872841302495803
Epoch: 49 | Iteration number: [1380/4518] 30% | Training loss: 0.6872739387163217
Epoch: 49 | Iteration number: [1390/4518] 30% | Training loss: 0.6872673943317194
Epoch: 49 | Iteration number: [1400/4518] 30% | Training loss: 0.6872658133506775
Epoch: 49 | Iteration number: [1410/4518] 31% | Training loss: 0.6872716804345449
Epoch: 49 | Iteration number: [1420/4518] 31% | Training loss: 0.6872805534953802
Epoch: 49 | Iteration number: [1430/4518] 31% | Training loss: 0.6872884353974482
Epoch: 49 | Iteration number: [1440/4518] 31% | Training loss: 0.6872757137235668
Epoch: 49 | Iteration number: [1450/4518] 32% | Training loss: 0.6872744302091928
Epoch: 49 | Iteration number: [1460/4518] 32% | Training loss: 0.6872746719481194
Epoch: 49 | Iteration number: [1470/4518] 32% | Training loss: 0.6872744250054262
Epoch: 49 | Iteration number: [1480/4518] 32% | Training loss: 0.6872631753215919
Epoch: 49 | Iteration number: [1490/4518] 32% | Training loss: 0.6872656190955398
Epoch: 49 | Iteration number: [1500/4518] 33% | Training loss: 0.6872629781961441
Epoch: 49 | Iteration number: [1510/4518] 33% | Training loss: 0.6872588635675165
Epoch: 49 | Iteration number: [1520/4518] 33% | Training loss: 0.6872522445885758
Epoch: 49 | Iteration number: [1530/4518] 33% | Training loss: 0.6872486917022007
Epoch: 49 | Iteration number: [1540/4518] 34% | Training loss: 0.6872516238457197
Epoch: 49 | Iteration number: [1550/4518] 34% | Training loss: 0.6872480243252169
Epoch: 49 | Iteration number: [1560/4518] 34% | Training loss: 0.687240881109849
Epoch: 49 | Iteration number: [1570/4518] 34% | Training loss: 0.687231383240147
Epoch: 49 | Iteration number: [1580/4518] 34% | Training loss: 0.6872190188003492
Epoch: 49 | Iteration number: [1590/4518] 35% | Training loss: 0.687220890791911
Epoch: 49 | Iteration number: [1600/4518] 35% | Training loss: 0.6872194379195571
Epoch: 49 | Iteration number: [1610/4518] 35% | Training loss: 0.6872186894372383
Epoch: 49 | Iteration number: [1620/4518] 35% | Training loss: 0.6872185716658463
Epoch: 49 | Iteration number: [1630/4518] 36% | Training loss: 0.6872083508529546
Epoch: 49 | Iteration number: [1640/4518] 36% | Training loss: 0.6872040760226366
Epoch: 49 | Iteration number: [1650/4518] 36% | Training loss: 0.6872089856682402
Epoch: 49 | Iteration number: [1660/4518] 36% | Training loss: 0.6872071510337922
Epoch: 49 | Iteration number: [1670/4518] 36% | Training loss: 0.6872068077861192
Epoch: 49 | Iteration number: [1680/4518] 37% | Training loss: 0.6872038834861347
Epoch: 49 | Iteration number: [1690/4518] 37% | Training loss: 0.6872005255264644
Epoch: 49 | Iteration number: [1700/4518] 37% | Training loss: 0.6871926498062471
Epoch: 49 | Iteration number: [1710/4518] 37% | Training loss: 0.6871859088627218
Epoch: 49 | Iteration number: [1720/4518] 38% | Training loss: 0.6871882904754129
Epoch: 49 | Iteration number: [1730/4518] 38% | Training loss: 0.6871903810542442
Epoch: 49 | Iteration number: [1740/4518] 38% | Training loss: 0.6871907881964212
Epoch: 49 | Iteration number: [1750/4518] 38% | Training loss: 0.687194340808051
Epoch: 49 | Iteration number: [1760/4518] 38% | Training loss: 0.6871869120746851
Epoch: 49 | Iteration number: [1770/4518] 39% | Training loss: 0.6871891595549503
Epoch: 49 | Iteration number: [1780/4518] 39% | Training loss: 0.6871879575962431
Epoch: 49 | Iteration number: [1790/4518] 39% | Training loss: 0.6871912537673333
Epoch: 49 | Iteration number: [1800/4518] 39% | Training loss: 0.6871882186995613
Epoch: 49 | Iteration number: [1810/4518] 40% | Training loss: 0.6871928466288424
Epoch: 49 | Iteration number: [1820/4518] 40% | Training loss: 0.6871952434162517
Epoch: 49 | Iteration number: [1830/4518] 40% | Training loss: 0.687192457588644
Epoch: 49 | Iteration number: [1840/4518] 40% | Training loss: 0.6871911703892376
Epoch: 49 | Iteration number: [1850/4518] 40% | Training loss: 0.6871829000679223
Epoch: 49 | Iteration number: [1860/4518] 41% | Training loss: 0.6871818798203622
Epoch: 49 | Iteration number: [1870/4518] 41% | Training loss: 0.6871829617788447
Epoch: 49 | Iteration number: [1880/4518] 41% | Training loss: 0.687182563828661
Epoch: 49 | Iteration number: [1890/4518] 41% | Training loss: 0.6871803634381168
Epoch: 49 | Iteration number: [1900/4518] 42% | Training loss: 0.6871771105967069
Epoch: 49 | Iteration number: [1910/4518] 42% | Training loss: 0.6871786102886599
Epoch: 49 | Iteration number: [1920/4518] 42% | Training loss: 0.6871759416845937
Epoch: 49 | Iteration number: [1930/4518] 42% | Training loss: 0.6871764021833944
Epoch: 49 | Iteration number: [1940/4518] 42% | Training loss: 0.687173321628079
Epoch: 49 | Iteration number: [1950/4518] 43% | Training loss: 0.687172561669961
Epoch: 49 | Iteration number: [1960/4518] 43% | Training loss: 0.6871696368772157
Epoch: 49 | Iteration number: [1970/4518] 43% | Training loss: 0.6871657763035769
Epoch: 49 | Iteration number: [1980/4518] 43% | Training loss: 0.6871637536720796
Epoch: 49 | Iteration number: [1990/4518] 44% | Training loss: 0.687166010794328
Epoch: 49 | Iteration number: [2000/4518] 44% | Training loss: 0.6871663417220115
Epoch: 49 | Iteration number: [2010/4518] 44% | Training loss: 0.687169562524824
Epoch: 49 | Iteration number: [2020/4518] 44% | Training loss: 0.68716085287604
Epoch: 49 | Iteration number: [2030/4518] 44% | Training loss: 0.6871565075930703
Epoch: 49 | Iteration number: [2040/4518] 45% | Training loss: 0.6871550339986296
Epoch: 49 | Iteration number: [2050/4518] 45% | Training loss: 0.6871569929762584
Epoch: 49 | Iteration number: [2060/4518] 45% | Training loss: 0.6871539060930604
Epoch: 49 | Iteration number: [2070/4518] 45% | Training loss: 0.6871504584660276
Epoch: 49 | Iteration number: [2080/4518] 46% | Training loss: 0.687155464434853
Epoch: 49 | Iteration number: [2090/4518] 46% | Training loss: 0.6871505383669474
Epoch: 49 | Iteration number: [2100/4518] 46% | Training loss: 0.6871446287348157
Epoch: 49 | Iteration number: [2110/4518] 46% | Training loss: 0.6871407639358846
Epoch: 49 | Iteration number: [2120/4518] 46% | Training loss: 0.6871405651265721
Epoch: 49 | Iteration number: [2130/4518] 47% | Training loss: 0.6871440788389931
Epoch: 49 | Iteration number: [2140/4518] 47% | Training loss: 0.6871375099520817
Epoch: 49 | Iteration number: [2150/4518] 47% | Training loss: 0.6871382723852646
Epoch: 49 | Iteration number: [2160/4518] 47% | Training loss: 0.6871387942797608
Epoch: 49 | Iteration number: [2170/4518] 48% | Training loss: 0.6871429540319927
Epoch: 49 | Iteration number: [2180/4518] 48% | Training loss: 0.6871379131024037
Epoch: 49 | Iteration number: [2190/4518] 48% | Training loss: 0.687136312570746
Epoch: 49 | Iteration number: [2200/4518] 48% | Training loss: 0.6871391344070434
Epoch: 49 | Iteration number: [2210/4518] 48% | Training loss: 0.6871340649160325
Epoch: 49 | Iteration number: [2220/4518] 49% | Training loss: 0.6871309155816431
Epoch: 49 | Iteration number: [2230/4518] 49% | Training loss: 0.6871265450133337
Epoch: 49 | Iteration number: [2240/4518] 49% | Training loss: 0.6871245838967818
Epoch: 49 | Iteration number: [2250/4518] 49% | Training loss: 0.6871238180266487
Epoch: 49 | Iteration number: [2260/4518] 50% | Training loss: 0.6871198404679256
Epoch: 49 | Iteration number: [2270/4518] 50% | Training loss: 0.6871140101145018
Epoch: 49 | Iteration number: [2280/4518] 50% | Training loss: 0.6871179907206904
Epoch: 49 | Iteration number: [2290/4518] 50% | Training loss: 0.6871168456223333
Epoch: 49 | Iteration number: [2300/4518] 50% | Training loss: 0.6871149509108585
Epoch: 49 | Iteration number: [2310/4518] 51% | Training loss: 0.6871218484975559
Epoch: 49 | Iteration number: [2320/4518] 51% | Training loss: 0.687118469898043
Epoch: 49 | Iteration number: [2330/4518] 51% | Training loss: 0.6871145312366568
Epoch: 49 | Iteration number: [2340/4518] 51% | Training loss: 0.6871176441001077
Epoch: 49 | Iteration number: [2350/4518] 52% | Training loss: 0.6871174155904891
Epoch: 49 | Iteration number: [2360/4518] 52% | Training loss: 0.6871150673951133
Epoch: 49 | Iteration number: [2370/4518] 52% | Training loss: 0.6871085485828576
Epoch: 49 | Iteration number: [2380/4518] 52% | Training loss: 0.6871104411968664
Epoch: 49 | Iteration number: [2390/4518] 52% | Training loss: 0.687106474248934
Epoch: 49 | Iteration number: [2400/4518] 53% | Training loss: 0.6871054969231287
Epoch: 49 | Iteration number: [2410/4518] 53% | Training loss: 0.6871013019094824
Epoch: 49 | Iteration number: [2420/4518] 53% | Training loss: 0.6871022715795139
Epoch: 49 | Iteration number: [2430/4518] 53% | Training loss: 0.6870947823112393
Epoch: 49 | Iteration number: [2440/4518] 54% | Training loss: 0.6870869308710098
Epoch: 49 | Iteration number: [2450/4518] 54% | Training loss: 0.6870861516680036
Epoch: 49 | Iteration number: [2460/4518] 54% | Training loss: 0.6870864595824141
Epoch: 49 | Iteration number: [2470/4518] 54% | Training loss: 0.6870790214432396
Epoch: 49 | Iteration number: [2480/4518] 54% | Training loss: 0.6870730071538879
Epoch: 49 | Iteration number: [2490/4518] 55% | Training loss: 0.6870750222579542
Epoch: 49 | Iteration number: [2500/4518] 55% | Training loss: 0.6870737270116806
Epoch: 49 | Iteration number: [2510/4518] 55% | Training loss: 0.687069611340405
Epoch: 49 | Iteration number: [2520/4518] 55% | Training loss: 0.6870661193416232
Epoch: 49 | Iteration number: [2530/4518] 55% | Training loss: 0.6870581038855752
Epoch: 49 | Iteration number: [2540/4518] 56% | Training loss: 0.6870562070232676
Epoch: 49 | Iteration number: [2550/4518] 56% | Training loss: 0.687056649315591
Epoch: 49 | Iteration number: [2560/4518] 56% | Training loss: 0.6870554753579199
Epoch: 49 | Iteration number: [2570/4518] 56% | Training loss: 0.6870567011462111
Epoch: 49 | Iteration number: [2580/4518] 57% | Training loss: 0.6870533269736194
Epoch: 49 | Iteration number: [2590/4518] 57% | Training loss: 0.6870489293083721
Epoch: 49 | Iteration number: [2600/4518] 57% | Training loss: 0.6870465716948876
Epoch: 49 | Iteration number: [2610/4518] 57% | Training loss: 0.6870484752901669
Epoch: 49 | Iteration number: [2620/4518] 57% | Training loss: 0.6870406679752219
Epoch: 49 | Iteration number: [2630/4518] 58% | Training loss: 0.6870368158409351
Epoch: 49 | Iteration number: [2640/4518] 58% | Training loss: 0.6870364177859191
Epoch: 49 | Iteration number: [2650/4518] 58% | Training loss: 0.6870417256625193
Epoch: 49 | Iteration number: [2660/4518] 58% | Training loss: 0.6870425589774785
Epoch: 49 | Iteration number: [2670/4518] 59% | Training loss: 0.6870399357674274
Epoch: 49 | Iteration number: [2680/4518] 59% | Training loss: 0.6870386777306671
Epoch: 49 | Iteration number: [2690/4518] 59% | Training loss: 0.6870398067851935
Epoch: 49 | Iteration number: [2700/4518] 59% | Training loss: 0.6870427401639797
Epoch: 49 | Iteration number: [2710/4518] 59% | Training loss: 0.6870382836164144
Epoch: 49 | Iteration number: [2720/4518] 60% | Training loss: 0.6870317480800783
Epoch: 49 | Iteration number: [2730/4518] 60% | Training loss: 0.6870360673565568
Epoch: 49 | Iteration number: [2740/4518] 60% | Training loss: 0.6870329217971677
Epoch: 49 | Iteration number: [2750/4518] 60% | Training loss: 0.687032332832163
Epoch: 49 | Iteration number: [2760/4518] 61% | Training loss: 0.687035339768382
Epoch: 49 | Iteration number: [2770/4518] 61% | Training loss: 0.6870325559313116
Epoch: 49 | Iteration number: [2780/4518] 61% | Training loss: 0.6870354826072995
Epoch: 49 | Iteration number: [2790/4518] 61% | Training loss: 0.6870309582106956
Epoch: 49 | Iteration number: [2800/4518] 61% | Training loss: 0.6870343153604439
Epoch: 49 | Iteration number: [2810/4518] 62% | Training loss: 0.6870359380262178
Epoch: 49 | Iteration number: [2820/4518] 62% | Training loss: 0.6870385280314912
Epoch: 49 | Iteration number: [2830/4518] 62% | Training loss: 0.6870385708530884
Epoch: 49 | Iteration number: [2840/4518] 62% | Training loss: 0.6870342021466981
Epoch: 49 | Iteration number: [2850/4518] 63% | Training loss: 0.6870335503000962
Epoch: 49 | Iteration number: [2860/4518] 63% | Training loss: 0.6870335038516905
Epoch: 49 | Iteration number: [2870/4518] 63% | Training loss: 0.687029594536027
Epoch: 49 | Iteration number: [2880/4518] 63% | Training loss: 0.6870231531974342
Epoch: 49 | Iteration number: [2890/4518] 63% | Training loss: 0.687027859955923
Epoch: 49 | Iteration number: [2900/4518] 64% | Training loss: 0.687030060147417
Epoch: 49 | Iteration number: [2910/4518] 64% | Training loss: 0.6870266551619133
Epoch: 49 | Iteration number: [2920/4518] 64% | Training loss: 0.6870245911691287
Epoch: 49 | Iteration number: [2930/4518] 64% | Training loss: 0.6870217208976225
Epoch: 49 | Iteration number: [2940/4518] 65% | Training loss: 0.6870221381892964
Epoch: 49 | Iteration number: [2950/4518] 65% | Training loss: 0.6870176889532703
Epoch: 49 | Iteration number: [2960/4518] 65% | Training loss: 0.6870182607624982
Epoch: 49 | Iteration number: [2970/4518] 65% | Training loss: 0.6870192312632346
Epoch: 49 | Iteration number: [2980/4518] 65% | Training loss: 0.6870161209730494
Epoch: 49 | Iteration number: [2990/4518] 66% | Training loss: 0.6870154225507309
Epoch: 49 | Iteration number: [3000/4518] 66% | Training loss: 0.6870152051051458
Epoch: 49 | Iteration number: [3010/4518] 66% | Training loss: 0.6870161807616287
Epoch: 49 | Iteration number: [3020/4518] 66% | Training loss: 0.6870126847597148
Epoch: 49 | Iteration number: [3030/4518] 67% | Training loss: 0.6870095727860731
Epoch: 49 | Iteration number: [3040/4518] 67% | Training loss: 0.6870073997072483
Epoch: 49 | Iteration number: [3050/4518] 67% | Training loss: 0.6870083349063748
Epoch: 49 | Iteration number: [3060/4518] 67% | Training loss: 0.6870065374312058
Epoch: 49 | Iteration number: [3070/4518] 67% | Training loss: 0.6870042847305633
Epoch: 49 | Iteration number: [3080/4518] 68% | Training loss: 0.6870051177291127
Epoch: 49 | Iteration number: [3090/4518] 68% | Training loss: 0.6870069814731388
Epoch: 49 | Iteration number: [3100/4518] 68% | Training loss: 0.6870055875662835
Epoch: 49 | Iteration number: [3110/4518] 68% | Training loss: 0.6870082071931416
Epoch: 49 | Iteration number: [3120/4518] 69% | Training loss: 0.6870091704030832
Epoch: 49 | Iteration number: [3130/4518] 69% | Training loss: 0.687007296428132
Epoch: 49 | Iteration number: [3140/4518] 69% | Training loss: 0.6870024588836986
Epoch: 49 | Iteration number: [3150/4518] 69% | Training loss: 0.6870032323920537
Epoch: 49 | Iteration number: [3160/4518] 69% | Training loss: 0.687001377136647
Epoch: 49 | Iteration number: [3170/4518] 70% | Training loss: 0.6870034435570052
Epoch: 49 | Iteration number: [3180/4518] 70% | Training loss: 0.6870079340612364
Epoch: 49 | Iteration number: [3190/4518] 70% | Training loss: 0.6870048438120038
Epoch: 49 | Iteration number: [3200/4518] 70% | Training loss: 0.6870058357156813
Epoch: 49 | Iteration number: [3210/4518] 71% | Training loss: 0.6870061988399779
Epoch: 49 | Iteration number: [3220/4518] 71% | Training loss: 0.6870060106241925
Epoch: 49 | Iteration number: [3230/4518] 71% | Training loss: 0.6870053709106918
Epoch: 49 | Iteration number: [3240/4518] 71% | Training loss: 0.6870067443192741
Epoch: 49 | Iteration number: [3250/4518] 71% | Training loss: 0.6870117620321421
Epoch: 49 | Iteration number: [3260/4518] 72% | Training loss: 0.6870121361287825
Epoch: 49 | Iteration number: [3270/4518] 72% | Training loss: 0.6870104309433461
Epoch: 49 | Iteration number: [3280/4518] 72% | Training loss: 0.6870147362169696
Epoch: 49 | Iteration number: [3290/4518] 72% | Training loss: 0.687013255535288
Epoch: 49 | Iteration number: [3300/4518] 73% | Training loss: 0.687016949021455
Epoch: 49 | Iteration number: [3310/4518] 73% | Training loss: 0.6870153997960048
Epoch: 49 | Iteration number: [3320/4518] 73% | Training loss: 0.6870133283626603
Epoch: 49 | Iteration number: [3330/4518] 73% | Training loss: 0.6870148231496324
Epoch: 49 | Iteration number: [3340/4518] 73% | Training loss: 0.6870121336804179
Epoch: 49 | Iteration number: [3350/4518] 74% | Training loss: 0.6870128909331649
Epoch: 49 | Iteration number: [3360/4518] 74% | Training loss: 0.6870126619225456
Epoch: 49 | Iteration number: [3370/4518] 74% | Training loss: 0.6870117124181119
Epoch: 49 | Iteration number: [3380/4518] 74% | Training loss: 0.687013304991835
Epoch: 49 | Iteration number: [3390/4518] 75% | Training loss: 0.6870139318054053
Epoch: 49 | Iteration number: [3400/4518] 75% | Training loss: 0.6870142903923988
Epoch: 49 | Iteration number: [3410/4518] 75% | Training loss: 0.6870150825494895
Epoch: 49 | Iteration number: [3420/4518] 75% | Training loss: 0.6870141467678617
Epoch: 49 | Iteration number: [3430/4518] 75% | Training loss: 0.6870135485257074
Epoch: 49 | Iteration number: [3440/4518] 76% | Training loss: 0.6870135322732981
Epoch: 49 | Iteration number: [3450/4518] 76% | Training loss: 0.6870165961548902
Epoch: 49 | Iteration number: [3460/4518] 76% | Training loss: 0.6870130054868026
Epoch: 49 | Iteration number: [3470/4518] 76% | Training loss: 0.6870106662212944
Epoch: 49 | Iteration number: [3480/4518] 77% | Training loss: 0.6870076067146214
Epoch: 49 | Iteration number: [3490/4518] 77% | Training loss: 0.6870083160420885
Epoch: 49 | Iteration number: [3500/4518] 77% | Training loss: 0.6870078695842198
Epoch: 49 | Iteration number: [3510/4518] 77% | Training loss: 0.687008576990872
Epoch: 49 | Iteration number: [3520/4518] 77% | Training loss: 0.6870069167492064
Epoch: 49 | Iteration number: [3530/4518] 78% | Training loss: 0.6870076659212031
Epoch: 49 | Iteration number: [3540/4518] 78% | Training loss: 0.6870024596903958
Epoch: 49 | Iteration number: [3550/4518] 78% | Training loss: 0.6870025511694626
Epoch: 49 | Iteration number: [3560/4518] 78% | Training loss: 0.6870009471358878
Epoch: 49 | Iteration number: [3570/4518] 79% | Training loss: 0.6870024818332255
Epoch: 49 | Iteration number: [3580/4518] 79% | Training loss: 0.6870026917763928
Epoch: 49 | Iteration number: [3590/4518] 79% | Training loss: 0.6870004955274481
Epoch: 49 | Iteration number: [3600/4518] 79% | Training loss: 0.6870026009612613
Epoch: 49 | Iteration number: [3610/4518] 79% | Training loss: 0.6870045107652606
Epoch: 49 | Iteration number: [3620/4518] 80% | Training loss: 0.6870048599019235
Epoch: 49 | Iteration number: [3630/4518] 80% | Training loss: 0.6870088549356487
Epoch: 49 | Iteration number: [3640/4518] 80% | Training loss: 0.6870094999670983
Epoch: 49 | Iteration number: [3650/4518] 80% | Training loss: 0.6870095828134719
Epoch: 49 | Iteration number: [3660/4518] 81% | Training loss: 0.6870102744610583
Epoch: 49 | Iteration number: [3670/4518] 81% | Training loss: 0.687009088366168
Epoch: 49 | Iteration number: [3680/4518] 81% | Training loss: 0.6870099252980688
Epoch: 49 | Iteration number: [3690/4518] 81% | Training loss: 0.6870103469386011
Epoch: 49 | Iteration number: [3700/4518] 81% | Training loss: 0.6870080839459961
Epoch: 49 | Iteration number: [3710/4518] 82% | Training loss: 0.6870076279755872
Epoch: 49 | Iteration number: [3720/4518] 82% | Training loss: 0.6870055320602592
Epoch: 49 | Iteration number: [3730/4518] 82% | Training loss: 0.6870065008986731
Epoch: 49 | Iteration number: [3740/4518] 82% | Training loss: 0.6870047240333761
Epoch: 49 | Iteration number: [3750/4518] 83% | Training loss: 0.6870032043933868
Epoch: 49 | Iteration number: [3760/4518] 83% | Training loss: 0.6870017527582798
Epoch: 49 | Iteration number: [3770/4518] 83% | Training loss: 0.6869987385184443
Epoch: 49 | Iteration number: [3780/4518] 83% | Training loss: 0.6869986892692627
Epoch: 49 | Iteration number: [3790/4518] 83% | Training loss: 0.6869994042416676
Epoch: 49 | Iteration number: [3800/4518] 84% | Training loss: 0.6870000592815249
Epoch: 49 | Iteration number: [3810/4518] 84% | Training loss: 0.6870004298805877
Epoch: 49 | Iteration number: [3820/4518] 84% | Training loss: 0.6869980994787516
Epoch: 49 | Iteration number: [3830/4518] 84% | Training loss: 0.6869968867333066
Epoch: 49 | Iteration number: [3840/4518] 84% | Training loss: 0.6869937461490433
Epoch: 49 | Iteration number: [3850/4518] 85% | Training loss: 0.6869915256871806
Epoch: 49 | Iteration number: [3860/4518] 85% | Training loss: 0.6869897257169911
Epoch: 49 | Iteration number: [3870/4518] 85% | Training loss: 0.6869860026417468
Epoch: 49 | Iteration number: [3880/4518] 85% | Training loss: 0.6869897044964672
Epoch: 49 | Iteration number: [3890/4518] 86% | Training loss: 0.6869875473350976
Epoch: 49 | Iteration number: [3900/4518] 86% | Training loss: 0.6869838506594682
Epoch: 49 | Iteration number: [3910/4518] 86% | Training loss: 0.6869847117634991
Epoch: 49 | Iteration number: [3920/4518] 86% | Training loss: 0.6869843493766931
Epoch: 49 | Iteration number: [3930/4518] 86% | Training loss: 0.6869836577932343
Epoch: 49 | Iteration number: [3940/4518] 87% | Training loss: 0.6869847344716793
Epoch: 49 | Iteration number: [3950/4518] 87% | Training loss: 0.686985874900335
Epoch: 49 | Iteration number: [3960/4518] 87% | Training loss: 0.6869820610290825
Epoch: 49 | Iteration number: [3970/4518] 87% | Training loss: 0.6869807894644269
Epoch: 49 | Iteration number: [3980/4518] 88% | Training loss: 0.6869791381922199
Epoch: 49 | Iteration number: [3990/4518] 88% | Training loss: 0.6869798284574857
Epoch: 49 | Iteration number: [4000/4518] 88% | Training loss: 0.6869807792007923
Epoch: 49 | Iteration number: [4010/4518] 88% | Training loss: 0.6869798611821677
Epoch: 49 | Iteration number: [4020/4518] 88% | Training loss: 0.6869791011015575
Epoch: 49 | Iteration number: [4030/4518] 89% | Training loss: 0.6869796712256543
Epoch: 49 | Iteration number: [4040/4518] 89% | Training loss: 0.6869811591830584
Epoch: 49 | Iteration number: [4050/4518] 89% | Training loss: 0.6869814517027066
Epoch: 49 | Iteration number: [4060/4518] 89% | Training loss: 0.6869797225215752
Epoch: 49 | Iteration number: [4070/4518] 90% | Training loss: 0.6869745014926433
Epoch: 49 | Iteration number: [4080/4518] 90% | Training loss: 0.6869727093361172
Epoch: 49 | Iteration number: [4090/4518] 90% | Training loss: 0.6869722827431042
Epoch: 49 | Iteration number: [4100/4518] 90% | Training loss: 0.6869753112734818
Epoch: 49 | Iteration number: [4110/4518] 90% | Training loss: 0.6869794098710201
Epoch: 49 | Iteration number: [4120/4518] 91% | Training loss: 0.6869809349040383
Epoch: 49 | Iteration number: [4130/4518] 91% | Training loss: 0.6869797730416998
Epoch: 49 | Iteration number: [4140/4518] 91% | Training loss: 0.6869771725313675
Epoch: 49 | Iteration number: [4150/4518] 91% | Training loss: 0.6869776758946569
Epoch: 49 | Iteration number: [4160/4518] 92% | Training loss: 0.6869778122179784
Epoch: 49 | Iteration number: [4170/4518] 92% | Training loss: 0.6869745815543534
Epoch: 49 | Iteration number: [4180/4518] 92% | Training loss: 0.6869730985335756
Epoch: 49 | Iteration number: [4190/4518] 92% | Training loss: 0.686971343943498
Epoch: 49 | Iteration number: [4200/4518] 92% | Training loss: 0.6869734956395058
Epoch: 49 | Iteration number: [4210/4518] 93% | Training loss: 0.6869721785293905
Epoch: 49 | Iteration number: [4220/4518] 93% | Training loss: 0.6869724949954246
Epoch: 49 | Iteration number: [4230/4518] 93% | Training loss: 0.6869722503578691
Epoch: 49 | Iteration number: [4240/4518] 93% | Training loss: 0.6869711551182675
Epoch: 49 | Iteration number: [4250/4518] 94% | Training loss: 0.68696964078791
Epoch: 49 | Iteration number: [4260/4518] 94% | Training loss: 0.6869718369323883
Epoch: 49 | Iteration number: [4270/4518] 94% | Training loss: 0.686969190151965
Epoch: 49 | Iteration number: [4280/4518] 94% | Training loss: 0.6869685573416335
Epoch: 49 | Iteration number: [4290/4518] 94% | Training loss: 0.686969413054295
Epoch: 49 | Iteration number: [4300/4518] 95% | Training loss: 0.6869684140626774
Epoch: 49 | Iteration number: [4310/4518] 95% | Training loss: 0.6869677083536533
Epoch: 49 | Iteration number: [4320/4518] 95% | Training loss: 0.6869675983571344
Epoch: 49 | Iteration number: [4330/4518] 95% | Training loss: 0.6869688627488618
Epoch: 49 | Iteration number: [4340/4518] 96% | Training loss: 0.6869689746523783
Epoch: 49 | Iteration number: [4350/4518] 96% | Training loss: 0.6869693402723335
Epoch: 49 | Iteration number: [4360/4518] 96% | Training loss: 0.6869726570511083
Epoch: 49 | Iteration number: [4370/4518] 96% | Training loss: 0.6869712149524034
Epoch: 49 | Iteration number: [4380/4518] 96% | Training loss: 0.686969797932394
Epoch: 49 | Iteration number: [4390/4518] 97% | Training loss: 0.6869697419684677
Epoch: 49 | Iteration number: [4400/4518] 97% | Training loss: 0.6869658035175367
Epoch: 49 | Iteration number: [4410/4518] 97% | Training loss: 0.6869664508604408
Epoch: 49 | Iteration number: [4420/4518] 97% | Training loss: 0.6869644556110261
Epoch: 49 | Iteration number: [4430/4518] 98% | Training loss: 0.6869639073080188
Epoch: 49 | Iteration number: [4440/4518] 98% | Training loss: 0.6869623463567313
Epoch: 49 | Iteration number: [4450/4518] 98% | Training loss: 0.6869642823599698
Epoch: 49 | Iteration number: [4460/4518] 98% | Training loss: 0.6869642022612918
Epoch: 49 | Iteration number: [4470/4518] 98% | Training loss: 0.6869644809755969
Epoch: 49 | Iteration number: [4480/4518] 99% | Training loss: 0.6869646707283599
Epoch: 49 | Iteration number: [4490/4518] 99% | Training loss: 0.6869647755521974
Epoch: 49 | Iteration number: [4500/4518] 99% | Training loss: 0.6869620101981693
Epoch: 49 | Iteration number: [4510/4518] 99% | Training loss: 0.6869595988494593

 End of epoch: 49 | Train Loss: 0.6868079007463468 | Training Time: 641 

 End of epoch: 49 | Eval Loss: 0.6900208555922216 | Evaluating Time: 17 
Epoch: 50 | Iteration number: [10/4518] 0% | Training loss: 0.7569322645664215
Epoch: 50 | Iteration number: [20/4518] 0% | Training loss: 0.7220497816801071
Epoch: 50 | Iteration number: [30/4518] 0% | Training loss: 0.7103402992089589
Epoch: 50 | Iteration number: [40/4518] 0% | Training loss: 0.7047983393073082
Epoch: 50 | Iteration number: [50/4518] 1% | Training loss: 0.7011721038818359
Epoch: 50 | Iteration number: [60/4518] 1% | Training loss: 0.698843264579773
Epoch: 50 | Iteration number: [70/4518] 1% | Training loss: 0.6971380429608481
Epoch: 50 | Iteration number: [80/4518] 1% | Training loss: 0.695630905777216
Epoch: 50 | Iteration number: [90/4518] 1% | Training loss: 0.6945193621847364
Epoch: 50 | Iteration number: [100/4518] 2% | Training loss: 0.6936564332246781
Epoch: 50 | Iteration number: [110/4518] 2% | Training loss: 0.6930725509470159
Epoch: 50 | Iteration number: [120/4518] 2% | Training loss: 0.6925180504719416
Epoch: 50 | Iteration number: [130/4518] 2% | Training loss: 0.6920084623190073
Epoch: 50 | Iteration number: [140/4518] 3% | Training loss: 0.6916531217949731
Epoch: 50 | Iteration number: [150/4518] 3% | Training loss: 0.69130388657252
Epoch: 50 | Iteration number: [160/4518] 3% | Training loss: 0.6909877095371485
Epoch: 50 | Iteration number: [170/4518] 3% | Training loss: 0.6907467179438647
Epoch: 50 | Iteration number: [180/4518] 3% | Training loss: 0.6904988961087333
Epoch: 50 | Iteration number: [190/4518] 4% | Training loss: 0.6902867414449391
Epoch: 50 | Iteration number: [200/4518] 4% | Training loss: 0.6900908520817757
Epoch: 50 | Iteration number: [210/4518] 4% | Training loss: 0.6899610587528774
Epoch: 50 | Iteration number: [220/4518] 4% | Training loss: 0.6898070931434631
Epoch: 50 | Iteration number: [230/4518] 5% | Training loss: 0.6896494500015093
Epoch: 50 | Iteration number: [240/4518] 5% | Training loss: 0.6895371414721012
Epoch: 50 | Iteration number: [250/4518] 5% | Training loss: 0.689475201368332
Epoch: 50 | Iteration number: [260/4518] 5% | Training loss: 0.6893775442471871
Epoch: 50 | Iteration number: [270/4518] 5% | Training loss: 0.6893082289784043
Epoch: 50 | Iteration number: [280/4518] 6% | Training loss: 0.6892256421702249
Epoch: 50 | Iteration number: [290/4518] 6% | Training loss: 0.6891655660908798
Epoch: 50 | Iteration number: [300/4518] 6% | Training loss: 0.6891267653306326
Epoch: 50 | Iteration number: [310/4518] 6% | Training loss: 0.6890481016328258
Epoch: 50 | Iteration number: [320/4518] 7% | Training loss: 0.6889930279925466
Epoch: 50 | Iteration number: [330/4518] 7% | Training loss: 0.6889099460659605
Epoch: 50 | Iteration number: [340/4518] 7% | Training loss: 0.6888577005442451
Epoch: 50 | Iteration number: [350/4518] 7% | Training loss: 0.6888003012112208
Epoch: 50 | Iteration number: [360/4518] 7% | Training loss: 0.6887438098589579
Epoch: 50 | Iteration number: [370/4518] 8% | Training loss: 0.6886525005907626
Epoch: 50 | Iteration number: [380/4518] 8% | Training loss: 0.6886114277337727
Epoch: 50 | Iteration number: [390/4518] 8% | Training loss: 0.6885366627803216
Epoch: 50 | Iteration number: [400/4518] 8% | Training loss: 0.6885139265656471
Epoch: 50 | Iteration number: [410/4518] 9% | Training loss: 0.6884822806207145
Epoch: 50 | Iteration number: [420/4518] 9% | Training loss: 0.6884102020944868
Epoch: 50 | Iteration number: [430/4518] 9% | Training loss: 0.6883636886297271
Epoch: 50 | Iteration number: [440/4518] 9% | Training loss: 0.6883371928876096
Epoch: 50 | Iteration number: [450/4518] 9% | Training loss: 0.6883292996883392
Epoch: 50 | Iteration number: [460/4518] 10% | Training loss: 0.6882859894762868
Epoch: 50 | Iteration number: [470/4518] 10% | Training loss: 0.6882373679191508
Epoch: 50 | Iteration number: [480/4518] 10% | Training loss: 0.688197611644864
Epoch: 50 | Iteration number: [490/4518] 10% | Training loss: 0.6881286810855476
Epoch: 50 | Iteration number: [500/4518] 11% | Training loss: 0.688097287774086
Epoch: 50 | Iteration number: [510/4518] 11% | Training loss: 0.6880540757786994
Epoch: 50 | Iteration number: [520/4518] 11% | Training loss: 0.6880299263275587
Epoch: 50 | Iteration number: [530/4518] 11% | Training loss: 0.6880163543629196
Epoch: 50 | Iteration number: [540/4518] 11% | Training loss: 0.6879966219266256
Epoch: 50 | Iteration number: [550/4518] 12% | Training loss: 0.6879942701079629
Epoch: 50 | Iteration number: [560/4518] 12% | Training loss: 0.6879810586571693
Epoch: 50 | Iteration number: [570/4518] 12% | Training loss: 0.6879609072417544
Epoch: 50 | Iteration number: [580/4518] 12% | Training loss: 0.6879141502339264
Epoch: 50 | Iteration number: [590/4518] 13% | Training loss: 0.6878900171336481
Epoch: 50 | Iteration number: [600/4518] 13% | Training loss: 0.6878822922706604
Epoch: 50 | Iteration number: [610/4518] 13% | Training loss: 0.6878486965523392
Epoch: 50 | Iteration number: [620/4518] 13% | Training loss: 0.6878320175793863
Epoch: 50 | Iteration number: [630/4518] 13% | Training loss: 0.6878187193757012
Epoch: 50 | Iteration number: [640/4518] 14% | Training loss: 0.6878199546597898
Epoch: 50 | Iteration number: [650/4518] 14% | Training loss: 0.6878180331450242
Epoch: 50 | Iteration number: [660/4518] 14% | Training loss: 0.6877886139082187
Epoch: 50 | Iteration number: [670/4518] 14% | Training loss: 0.6877830492026771
Epoch: 50 | Iteration number: [680/4518] 15% | Training loss: 0.6877722450038966
Epoch: 50 | Iteration number: [690/4518] 15% | Training loss: 0.6877442156059155
Epoch: 50 | Iteration number: [700/4518] 15% | Training loss: 0.6877295223304204
Epoch: 50 | Iteration number: [710/4518] 15% | Training loss: 0.687711102190152
Epoch: 50 | Iteration number: [720/4518] 15% | Training loss: 0.6877087117069297
Epoch: 50 | Iteration number: [730/4518] 16% | Training loss: 0.6877128248345362
Epoch: 50 | Iteration number: [740/4518] 16% | Training loss: 0.6877055992145796
Epoch: 50 | Iteration number: [750/4518] 16% | Training loss: 0.687703041712443
Epoch: 50 | Iteration number: [760/4518] 16% | Training loss: 0.687693107912415
Epoch: 50 | Iteration number: [770/4518] 17% | Training loss: 0.6876755335114219
Epoch: 50 | Iteration number: [780/4518] 17% | Training loss: 0.6876600523789723
Epoch: 50 | Iteration number: [790/4518] 17% | Training loss: 0.687641378746757
Epoch: 50 | Iteration number: [800/4518] 17% | Training loss: 0.6876159705221653
Epoch: 50 | Iteration number: [810/4518] 17% | Training loss: 0.6876208012486682
Epoch: 50 | Iteration number: [820/4518] 18% | Training loss: 0.6876037439195121
Epoch: 50 | Iteration number: [830/4518] 18% | Training loss: 0.6875746030405343
Epoch: 50 | Iteration number: [840/4518] 18% | Training loss: 0.687564042139621
Epoch: 50 | Iteration number: [850/4518] 18% | Training loss: 0.6875513181966894
Epoch: 50 | Iteration number: [860/4518] 19% | Training loss: 0.6875424310218456
Epoch: 50 | Iteration number: [870/4518] 19% | Training loss: 0.6875288392620525
Epoch: 50 | Iteration number: [880/4518] 19% | Training loss: 0.6875168550420891
Epoch: 50 | Iteration number: [890/4518] 19% | Training loss: 0.6874983838434969
Epoch: 50 | Iteration number: [900/4518] 19% | Training loss: 0.6874855568673875
Epoch: 50 | Iteration number: [910/4518] 20% | Training loss: 0.6874877863532894
Epoch: 50 | Iteration number: [920/4518] 20% | Training loss: 0.6874808273885561
Epoch: 50 | Iteration number: [930/4518] 20% | Training loss: 0.6874610645155753
Epoch: 50 | Iteration number: [940/4518] 20% | Training loss: 0.6874421366351716
Epoch: 50 | Iteration number: [950/4518] 21% | Training loss: 0.6874244530577409
Epoch: 50 | Iteration number: [960/4518] 21% | Training loss: 0.6874219962085287
Epoch: 50 | Iteration number: [970/4518] 21% | Training loss: 0.6874098711407062
Epoch: 50 | Iteration number: [980/4518] 21% | Training loss: 0.6874118975838837
Epoch: 50 | Iteration number: [990/4518] 21% | Training loss: 0.6874125556512313
Epoch: 50 | Iteration number: [1000/4518] 22% | Training loss: 0.6874067982435227
Epoch: 50 | Iteration number: [1010/4518] 22% | Training loss: 0.6874059115305986
Epoch: 50 | Iteration number: [1020/4518] 22% | Training loss: 0.6874001805688821
Epoch: 50 | Iteration number: [1030/4518] 22% | Training loss: 0.6873863680270111
Epoch: 50 | Iteration number: [1040/4518] 23% | Training loss: 0.6873844636174349
Epoch: 50 | Iteration number: [1050/4518] 23% | Training loss: 0.6873860655512128
Epoch: 50 | Iteration number: [1060/4518] 23% | Training loss: 0.6873799710903528
Epoch: 50 | Iteration number: [1070/4518] 23% | Training loss: 0.6873891273948634
Epoch: 50 | Iteration number: [1080/4518] 23% | Training loss: 0.6873730799114263
Epoch: 50 | Iteration number: [1090/4518] 24% | Training loss: 0.6873714803555689
Epoch: 50 | Iteration number: [1100/4518] 24% | Training loss: 0.6873776370286941
Epoch: 50 | Iteration number: [1110/4518] 24% | Training loss: 0.6873833207396773
Epoch: 50 | Iteration number: [1120/4518] 24% | Training loss: 0.6873833695160491
Epoch: 50 | Iteration number: [1130/4518] 25% | Training loss: 0.6873800905404893
Epoch: 50 | Iteration number: [1140/4518] 25% | Training loss: 0.6873765764006398
Epoch: 50 | Iteration number: [1150/4518] 25% | Training loss: 0.687374807337056
Epoch: 50 | Iteration number: [1160/4518] 25% | Training loss: 0.6873661359322483
Epoch: 50 | Iteration number: [1170/4518] 25% | Training loss: 0.6873506053390666
Epoch: 50 | Iteration number: [1180/4518] 26% | Training loss: 0.6873335367037078
Epoch: 50 | Iteration number: [1190/4518] 26% | Training loss: 0.6873215962357881
Epoch: 50 | Iteration number: [1200/4518] 26% | Training loss: 0.6873157685498397
Epoch: 50 | Iteration number: [1210/4518] 26% | Training loss: 0.6873133794335294
Epoch: 50 | Iteration number: [1220/4518] 27% | Training loss: 0.6872994590001028
Epoch: 50 | Iteration number: [1230/4518] 27% | Training loss: 0.6873003547269154
Epoch: 50 | Iteration number: [1240/4518] 27% | Training loss: 0.687300138992648
Epoch: 50 | Iteration number: [1250/4518] 27% | Training loss: 0.6872941851615906
Epoch: 50 | Iteration number: [1260/4518] 27% | Training loss: 0.6872898761715208
Epoch: 50 | Iteration number: [1270/4518] 28% | Training loss: 0.6872875837359841
Epoch: 50 | Iteration number: [1280/4518] 28% | Training loss: 0.6872902441304177
Epoch: 50 | Iteration number: [1290/4518] 28% | Training loss: 0.6872897528862768
Epoch: 50 | Iteration number: [1300/4518] 28% | Training loss: 0.6872840470075607
Epoch: 50 | Iteration number: [1310/4518] 28% | Training loss: 0.6872784844791616
Epoch: 50 | Iteration number: [1320/4518] 29% | Training loss: 0.6872697440512252
Epoch: 50 | Iteration number: [1330/4518] 29% | Training loss: 0.6872567881767014
Epoch: 50 | Iteration number: [1340/4518] 29% | Training loss: 0.6872615462808467
Epoch: 50 | Iteration number: [1350/4518] 29% | Training loss: 0.6872601862748464
Epoch: 50 | Iteration number: [1360/4518] 30% | Training loss: 0.6872623585164547
Epoch: 50 | Iteration number: [1370/4518] 30% | Training loss: 0.6872611496570337
Epoch: 50 | Iteration number: [1380/4518] 30% | Training loss: 0.6872621024864307
Epoch: 50 | Iteration number: [1390/4518] 30% | Training loss: 0.6872577458834477
Epoch: 50 | Iteration number: [1400/4518] 30% | Training loss: 0.687255473945822
Epoch: 50 | Iteration number: [1410/4518] 31% | Training loss: 0.6872515733360399
Epoch: 50 | Iteration number: [1420/4518] 31% | Training loss: 0.6872502463804164
Epoch: 50 | Iteration number: [1430/4518] 31% | Training loss: 0.6872473378698309
Epoch: 50 | Iteration number: [1440/4518] 31% | Training loss: 0.6872453826997015
Epoch: 50 | Iteration number: [1450/4518] 32% | Training loss: 0.6872443066794297
Epoch: 50 | Iteration number: [1460/4518] 32% | Training loss: 0.6872457389145681
Epoch: 50 | Iteration number: [1470/4518] 32% | Training loss: 0.6872392877429521
Epoch: 50 | Iteration number: [1480/4518] 32% | Training loss: 0.6872379296132036
Epoch: 50 | Iteration number: [1490/4518] 32% | Training loss: 0.6872300758857856
Epoch: 50 | Iteration number: [1500/4518] 33% | Training loss: 0.6872339213689168
Epoch: 50 | Iteration number: [1510/4518] 33% | Training loss: 0.6872248275785257
Epoch: 50 | Iteration number: [1520/4518] 33% | Training loss: 0.6872268965761913
Epoch: 50 | Iteration number: [1530/4518] 33% | Training loss: 0.6872277719133041
Epoch: 50 | Iteration number: [1540/4518] 34% | Training loss: 0.6872275948911518
Epoch: 50 | Iteration number: [1550/4518] 34% | Training loss: 0.6872188235867408
Epoch: 50 | Iteration number: [1560/4518] 34% | Training loss: 0.6872119867266753
Epoch: 50 | Iteration number: [1570/4518] 34% | Training loss: 0.6872126307457116
Epoch: 50 | Iteration number: [1580/4518] 34% | Training loss: 0.6872048569253728
Epoch: 50 | Iteration number: [1590/4518] 35% | Training loss: 0.6872060080744186
Epoch: 50 | Iteration number: [1600/4518] 35% | Training loss: 0.6872067067027092
Epoch: 50 | Iteration number: [1610/4518] 35% | Training loss: 0.6872081459679219
Epoch: 50 | Iteration number: [1620/4518] 35% | Training loss: 0.6872029076755782
Epoch: 50 | Iteration number: [1630/4518] 36% | Training loss: 0.6871907217370952
Epoch: 50 | Iteration number: [1640/4518] 36% | Training loss: 0.6871904816932795
Epoch: 50 | Iteration number: [1650/4518] 36% | Training loss: 0.6871869393912229
Epoch: 50 | Iteration number: [1660/4518] 36% | Training loss: 0.6871938435428114
Epoch: 50 | Iteration number: [1670/4518] 36% | Training loss: 0.6871956179955763
Epoch: 50 | Iteration number: [1680/4518] 37% | Training loss: 0.6871888899022625
Epoch: 50 | Iteration number: [1690/4518] 37% | Training loss: 0.6871842480622805
Epoch: 50 | Iteration number: [1700/4518] 37% | Training loss: 0.6871782513576395
Epoch: 50 | Iteration number: [1710/4518] 37% | Training loss: 0.6871795351742304
Epoch: 50 | Iteration number: [1720/4518] 38% | Training loss: 0.6871786689688993
Epoch: 50 | Iteration number: [1730/4518] 38% | Training loss: 0.6871784787646608
Epoch: 50 | Iteration number: [1740/4518] 38% | Training loss: 0.6871777850320969
Epoch: 50 | Iteration number: [1750/4518] 38% | Training loss: 0.6871733570439474
Epoch: 50 | Iteration number: [1760/4518] 38% | Training loss: 0.6871743431145495
Epoch: 50 | Iteration number: [1770/4518] 39% | Training loss: 0.6871686337357861
Epoch: 50 | Iteration number: [1780/4518] 39% | Training loss: 0.6871675299794486
Epoch: 50 | Iteration number: [1790/4518] 39% | Training loss: 0.6871640118473735
Epoch: 50 | Iteration number: [1800/4518] 39% | Training loss: 0.6871661703454124
Epoch: 50 | Iteration number: [1810/4518] 40% | Training loss: 0.6871631890700008
Epoch: 50 | Iteration number: [1820/4518] 40% | Training loss: 0.687156417278143
Epoch: 50 | Iteration number: [1830/4518] 40% | Training loss: 0.6871572386371634
Epoch: 50 | Iteration number: [1840/4518] 40% | Training loss: 0.6871461406350136
Epoch: 50 | Iteration number: [1850/4518] 40% | Training loss: 0.6871406355419675
Epoch: 50 | Iteration number: [1860/4518] 41% | Training loss: 0.6871405508569491
Epoch: 50 | Iteration number: [1870/4518] 41% | Training loss: 0.6871430928375631
Epoch: 50 | Iteration number: [1880/4518] 41% | Training loss: 0.6871477876571899
Epoch: 50 | Iteration number: [1890/4518] 41% | Training loss: 0.687149143250531
Epoch: 50 | Iteration number: [1900/4518] 42% | Training loss: 0.6871474809709348
Epoch: 50 | Iteration number: [1910/4518] 42% | Training loss: 0.6871491200636819
Epoch: 50 | Iteration number: [1920/4518] 42% | Training loss: 0.6871479709632695
Epoch: 50 | Iteration number: [1930/4518] 42% | Training loss: 0.6871406651531476
Epoch: 50 | Iteration number: [1940/4518] 42% | Training loss: 0.6871446915508546
Epoch: 50 | Iteration number: [1950/4518] 43% | Training loss: 0.6871449823562915
Epoch: 50 | Iteration number: [1960/4518] 43% | Training loss: 0.6871443777972338
Epoch: 50 | Iteration number: [1970/4518] 43% | Training loss: 0.6871388503137579
Epoch: 50 | Iteration number: [1980/4518] 43% | Training loss: 0.6871385210090213
Epoch: 50 | Iteration number: [1990/4518] 44% | Training loss: 0.6871374606187619
Epoch: 50 | Iteration number: [2000/4518] 44% | Training loss: 0.6871373659968376
Epoch: 50 | Iteration number: [2010/4518] 44% | Training loss: 0.6871302332451095
Epoch: 50 | Iteration number: [2020/4518] 44% | Training loss: 0.68712501159989
Epoch: 50 | Iteration number: [2030/4518] 44% | Training loss: 0.687125294431677
Epoch: 50 | Iteration number: [2040/4518] 45% | Training loss: 0.6871288120162253
Epoch: 50 | Iteration number: [2050/4518] 45% | Training loss: 0.6871240438775318
Epoch: 50 | Iteration number: [2060/4518] 45% | Training loss: 0.6871226692662655
Epoch: 50 | Iteration number: [2070/4518] 45% | Training loss: 0.6871205737913288
Epoch: 50 | Iteration number: [2080/4518] 46% | Training loss: 0.6871118174436001
Epoch: 50 | Iteration number: [2090/4518] 46% | Training loss: 0.6871125269734688
Epoch: 50 | Iteration number: [2100/4518] 46% | Training loss: 0.6871043775478999
Epoch: 50 | Iteration number: [2110/4518] 46% | Training loss: 0.6871035005244034
Epoch: 50 | Iteration number: [2120/4518] 46% | Training loss: 0.6871027627081241
Epoch: 50 | Iteration number: [2130/4518] 47% | Training loss: 0.6871037083892195
Epoch: 50 | Iteration number: [2140/4518] 47% | Training loss: 0.6871004305431776
Epoch: 50 | Iteration number: [2150/4518] 47% | Training loss: 0.6870937620761782
Epoch: 50 | Iteration number: [2160/4518] 47% | Training loss: 0.6870875151345024
Epoch: 50 | Iteration number: [2170/4518] 48% | Training loss: 0.6870859407060157
Epoch: 50 | Iteration number: [2180/4518] 48% | Training loss: 0.6870855817007362
Epoch: 50 | Iteration number: [2190/4518] 48% | Training loss: 0.6870874803088027
Epoch: 50 | Iteration number: [2200/4518] 48% | Training loss: 0.6870936203815721
Epoch: 50 | Iteration number: [2210/4518] 48% | Training loss: 0.687093088718561
Epoch: 50 | Iteration number: [2220/4518] 49% | Training loss: 0.687093745292844
Epoch: 50 | Iteration number: [2230/4518] 49% | Training loss: 0.6870988685453954
Epoch: 50 | Iteration number: [2240/4518] 49% | Training loss: 0.6870949843366231
Epoch: 50 | Iteration number: [2250/4518] 49% | Training loss: 0.6870944466325972
Epoch: 50 | Iteration number: [2260/4518] 50% | Training loss: 0.6870913095178858
Epoch: 50 | Iteration number: [2270/4518] 50% | Training loss: 0.6870959832017117
Epoch: 50 | Iteration number: [2280/4518] 50% | Training loss: 0.687094039038608
Epoch: 50 | Iteration number: [2290/4518] 50% | Training loss: 0.6870940405729036
Epoch: 50 | Iteration number: [2300/4518] 50% | Training loss: 0.6870913894798445
Epoch: 50 | Iteration number: [2310/4518] 51% | Training loss: 0.6870890279868981
Epoch: 50 | Iteration number: [2320/4518] 51% | Training loss: 0.6870901714368113
Epoch: 50 | Iteration number: [2330/4518] 51% | Training loss: 0.6870892161719278
Epoch: 50 | Iteration number: [2340/4518] 51% | Training loss: 0.687086741740887
Epoch: 50 | Iteration number: [2350/4518] 52% | Training loss: 0.6870897055179515
Epoch: 50 | Iteration number: [2360/4518] 52% | Training loss: 0.6870886110653311
Epoch: 50 | Iteration number: [2370/4518] 52% | Training loss: 0.6870898357172053
Epoch: 50 | Iteration number: [2380/4518] 52% | Training loss: 0.6870924637097271
Epoch: 50 | Iteration number: [2390/4518] 52% | Training loss: 0.6870911746094915
Epoch: 50 | Iteration number: [2400/4518] 53% | Training loss: 0.687088831414779
Epoch: 50 | Iteration number: [2410/4518] 53% | Training loss: 0.6870881997698075
Epoch: 50 | Iteration number: [2420/4518] 53% | Training loss: 0.6870872963312243
Epoch: 50 | Iteration number: [2430/4518] 53% | Training loss: 0.6870884820267006
Epoch: 50 | Iteration number: [2440/4518] 54% | Training loss: 0.687082168215611
Epoch: 50 | Iteration number: [2450/4518] 54% | Training loss: 0.6870771579353177
Epoch: 50 | Iteration number: [2460/4518] 54% | Training loss: 0.6870762012111462
Epoch: 50 | Iteration number: [2470/4518] 54% | Training loss: 0.687080383059467
Epoch: 50 | Iteration number: [2480/4518] 54% | Training loss: 0.6870819193220907
Epoch: 50 | Iteration number: [2490/4518] 55% | Training loss: 0.6870813252935448
Epoch: 50 | Iteration number: [2500/4518] 55% | Training loss: 0.6870779401779175
Epoch: 50 | Iteration number: [2510/4518] 55% | Training loss: 0.6870745580984776
Epoch: 50 | Iteration number: [2520/4518] 55% | Training loss: 0.6870755883436355
Epoch: 50 | Iteration number: [2530/4518] 55% | Training loss: 0.6870673140282687
Epoch: 50 | Iteration number: [2540/4518] 56% | Training loss: 0.6870652517465156
Epoch: 50 | Iteration number: [2550/4518] 56% | Training loss: 0.6870643811599881
Epoch: 50 | Iteration number: [2560/4518] 56% | Training loss: 0.6870676498627291
Epoch: 50 | Iteration number: [2570/4518] 56% | Training loss: 0.6870633284869361
Epoch: 50 | Iteration number: [2580/4518] 57% | Training loss: 0.6870617629252663
Epoch: 50 | Iteration number: [2590/4518] 57% | Training loss: 0.6870581282151712
Epoch: 50 | Iteration number: [2600/4518] 57% | Training loss: 0.6870563488969436
Epoch: 50 | Iteration number: [2610/4518] 57% | Training loss: 0.6870533875578665
Epoch: 50 | Iteration number: [2620/4518] 57% | Training loss: 0.6870561136771705
Epoch: 50 | Iteration number: [2630/4518] 58% | Training loss: 0.6870555987376223
Epoch: 50 | Iteration number: [2640/4518] 58% | Training loss: 0.6870560083876956
Epoch: 50 | Iteration number: [2650/4518] 58% | Training loss: 0.6870541832806929
Epoch: 50 | Iteration number: [2660/4518] 58% | Training loss: 0.6870564846616042
Epoch: 50 | Iteration number: [2670/4518] 59% | Training loss: 0.6870562175909678
Epoch: 50 | Iteration number: [2680/4518] 59% | Training loss: 0.6870585328162606
Epoch: 50 | Iteration number: [2690/4518] 59% | Training loss: 0.6870547500463223
Epoch: 50 | Iteration number: [2700/4518] 59% | Training loss: 0.6870603310620343
Epoch: 50 | Iteration number: [2710/4518] 59% | Training loss: 0.6870617251114651
Epoch: 50 | Iteration number: [2720/4518] 60% | Training loss: 0.6870601361946148
Epoch: 50 | Iteration number: [2730/4518] 60% | Training loss: 0.6870619851154286
Epoch: 50 | Iteration number: [2740/4518] 60% | Training loss: 0.6870657652834036
Epoch: 50 | Iteration number: [2750/4518] 60% | Training loss: 0.6870663333589381
Epoch: 50 | Iteration number: [2760/4518] 61% | Training loss: 0.6870674249486647
Epoch: 50 | Iteration number: [2770/4518] 61% | Training loss: 0.6870663713677265
Epoch: 50 | Iteration number: [2780/4518] 61% | Training loss: 0.6870659358424248
Epoch: 50 | Iteration number: [2790/4518] 61% | Training loss: 0.6870685830338454
Epoch: 50 | Iteration number: [2800/4518] 61% | Training loss: 0.6870627596548625
Epoch: 50 | Iteration number: [2810/4518] 62% | Training loss: 0.6870623754224743
Epoch: 50 | Iteration number: [2820/4518] 62% | Training loss: 0.6870602377763031
Epoch: 50 | Iteration number: [2830/4518] 62% | Training loss: 0.6870573297616871
Epoch: 50 | Iteration number: [2840/4518] 62% | Training loss: 0.6870575270392525
Epoch: 50 | Iteration number: [2850/4518] 63% | Training loss: 0.6870566806249451
Epoch: 50 | Iteration number: [2860/4518] 63% | Training loss: 0.6870574540608413
Epoch: 50 | Iteration number: [2870/4518] 63% | Training loss: 0.6870524262717377
Epoch: 50 | Iteration number: [2880/4518] 63% | Training loss: 0.6870535465371278
Epoch: 50 | Iteration number: [2890/4518] 63% | Training loss: 0.6870532874005063
Epoch: 50 | Iteration number: [2900/4518] 64% | Training loss: 0.6870519814820125
Epoch: 50 | Iteration number: [2910/4518] 64% | Training loss: 0.6870509443823825
Epoch: 50 | Iteration number: [2920/4518] 64% | Training loss: 0.6870506545043972
Epoch: 50 | Iteration number: [2930/4518] 64% | Training loss: 0.6870443389684266
Epoch: 50 | Iteration number: [2940/4518] 65% | Training loss: 0.6870434581219744
Epoch: 50 | Iteration number: [2950/4518] 65% | Training loss: 0.6870444410938328
Epoch: 50 | Iteration number: [2960/4518] 65% | Training loss: 0.6870441426900593
Epoch: 50 | Iteration number: [2970/4518] 65% | Training loss: 0.6870393821085342
Epoch: 50 | Iteration number: [2980/4518] 65% | Training loss: 0.6870389227299082
Epoch: 50 | Iteration number: [2990/4518] 66% | Training loss: 0.6870360281156457
Epoch: 50 | Iteration number: [3000/4518] 66% | Training loss: 0.6870358540217082
Epoch: 50 | Iteration number: [3010/4518] 66% | Training loss: 0.6870344607933019
Epoch: 50 | Iteration number: [3020/4518] 66% | Training loss: 0.6870316296815873
Epoch: 50 | Iteration number: [3030/4518] 67% | Training loss: 0.6870315884993021
Epoch: 50 | Iteration number: [3040/4518] 67% | Training loss: 0.6870320049751746
Epoch: 50 | Iteration number: [3050/4518] 67% | Training loss: 0.6870314683093399
Epoch: 50 | Iteration number: [3060/4518] 67% | Training loss: 0.6870291190794091
Epoch: 50 | Iteration number: [3070/4518] 67% | Training loss: 0.6870245447182112
Epoch: 50 | Iteration number: [3080/4518] 68% | Training loss: 0.6870248092459393
Epoch: 50 | Iteration number: [3090/4518] 68% | Training loss: 0.6870247250428864
Epoch: 50 | Iteration number: [3100/4518] 68% | Training loss: 0.6870236133952294
Epoch: 50 | Iteration number: [3110/4518] 68% | Training loss: 0.6870222910999102
Epoch: 50 | Iteration number: [3120/4518] 69% | Training loss: 0.6870235350078497
Epoch: 50 | Iteration number: [3130/4518] 69% | Training loss: 0.6870227454188532
Epoch: 50 | Iteration number: [3140/4518] 69% | Training loss: 0.6870235382751295
Epoch: 50 | Iteration number: [3150/4518] 69% | Training loss: 0.6870225863229661
Epoch: 50 | Iteration number: [3160/4518] 69% | Training loss: 0.6870225504606585
Epoch: 50 | Iteration number: [3170/4518] 70% | Training loss: 0.6870191105720749
Epoch: 50 | Iteration number: [3180/4518] 70% | Training loss: 0.6870214894695102
Epoch: 50 | Iteration number: [3190/4518] 70% | Training loss: 0.6870175798671746
Epoch: 50 | Iteration number: [3200/4518] 70% | Training loss: 0.6870185496844351
Epoch: 50 | Iteration number: [3210/4518] 71% | Training loss: 0.687023556956621
Epoch: 50 | Iteration number: [3220/4518] 71% | Training loss: 0.6870246191387591
Epoch: 50 | Iteration number: [3230/4518] 71% | Training loss: 0.687022317802943
Epoch: 50 | Iteration number: [3240/4518] 71% | Training loss: 0.6870252657635713
Epoch: 50 | Iteration number: [3250/4518] 71% | Training loss: 0.6870241824296804
Epoch: 50 | Iteration number: [3260/4518] 72% | Training loss: 0.6870226348470325
Epoch: 50 | Iteration number: [3270/4518] 72% | Training loss: 0.68701932712797
Epoch: 50 | Iteration number: [3280/4518] 72% | Training loss: 0.6870200509705194
Epoch: 50 | Iteration number: [3290/4518] 72% | Training loss: 0.6870221544725192
Epoch: 50 | Iteration number: [3300/4518] 73% | Training loss: 0.6870244775577025
Epoch: 50 | Iteration number: [3310/4518] 73% | Training loss: 0.6870257414899924
Epoch: 50 | Iteration number: [3320/4518] 73% | Training loss: 0.687026009053351
Epoch: 50 | Iteration number: [3330/4518] 73% | Training loss: 0.6870261010106977
Epoch: 50 | Iteration number: [3340/4518] 73% | Training loss: 0.6870296323727705
Epoch: 50 | Iteration number: [3350/4518] 74% | Training loss: 0.6870322646667708
Epoch: 50 | Iteration number: [3360/4518] 74% | Training loss: 0.6870321629125448
Epoch: 50 | Iteration number: [3370/4518] 74% | Training loss: 0.6870307684298439
Epoch: 50 | Iteration number: [3380/4518] 74% | Training loss: 0.6870321361447227
Epoch: 50 | Iteration number: [3390/4518] 75% | Training loss: 0.6870282700455645
Epoch: 50 | Iteration number: [3400/4518] 75% | Training loss: 0.6870272012493189
Epoch: 50 | Iteration number: [3410/4518] 75% | Training loss: 0.6870263944797852
Epoch: 50 | Iteration number: [3420/4518] 75% | Training loss: 0.687023175111291
Epoch: 50 | Iteration number: [3430/4518] 75% | Training loss: 0.6870210876965315
Epoch: 50 | Iteration number: [3440/4518] 76% | Training loss: 0.6870240563916605
Epoch: 50 | Iteration number: [3450/4518] 76% | Training loss: 0.6870292091542396
Epoch: 50 | Iteration number: [3460/4518] 76% | Training loss: 0.6870304022048939
Epoch: 50 | Iteration number: [3470/4518] 76% | Training loss: 0.6870293164631132
Epoch: 50 | Iteration number: [3480/4518] 77% | Training loss: 0.6870277430134258
Epoch: 50 | Iteration number: [3490/4518] 77% | Training loss: 0.6870263878971253
Epoch: 50 | Iteration number: [3500/4518] 77% | Training loss: 0.687026213169098
Epoch: 50 | Iteration number: [3510/4518] 77% | Training loss: 0.6870281964115947
Epoch: 50 | Iteration number: [3520/4518] 77% | Training loss: 0.6870271146805449
Epoch: 50 | Iteration number: [3530/4518] 78% | Training loss: 0.6870289495747758
Epoch: 50 | Iteration number: [3540/4518] 78% | Training loss: 0.6870259153809251
Epoch: 50 | Iteration number: [3550/4518] 78% | Training loss: 0.6870247795380338
Epoch: 50 | Iteration number: [3560/4518] 78% | Training loss: 0.6870224930429727
Epoch: 50 | Iteration number: [3570/4518] 79% | Training loss: 0.6870248286830944
Epoch: 50 | Iteration number: [3580/4518] 79% | Training loss: 0.6870239011901716
Epoch: 50 | Iteration number: [3590/4518] 79% | Training loss: 0.6870217820063939
Epoch: 50 | Iteration number: [3600/4518] 79% | Training loss: 0.6870232117507192
Epoch: 50 | Iteration number: [3610/4518] 79% | Training loss: 0.6870234037535342
Epoch: 50 | Iteration number: [3620/4518] 80% | Training loss: 0.6870205382451168
Epoch: 50 | Iteration number: [3630/4518] 80% | Training loss: 0.6870192263244598
Epoch: 50 | Iteration number: [3640/4518] 80% | Training loss: 0.6870186906266998
Epoch: 50 | Iteration number: [3650/4518] 80% | Training loss: 0.6870181329446297
Epoch: 50 | Iteration number: [3660/4518] 81% | Training loss: 0.687015748300839
Epoch: 50 | Iteration number: [3670/4518] 81% | Training loss: 0.6870154109410435
Epoch: 50 | Iteration number: [3680/4518] 81% | Training loss: 0.6870115665637928
Epoch: 50 | Iteration number: [3690/4518] 81% | Training loss: 0.6870094685858181
Epoch: 50 | Iteration number: [3700/4518] 81% | Training loss: 0.6870090271170075
Epoch: 50 | Iteration number: [3710/4518] 82% | Training loss: 0.6870040913315796
Epoch: 50 | Iteration number: [3720/4518] 82% | Training loss: 0.687002876048447
Epoch: 50 | Iteration number: [3730/4518] 82% | Training loss: 0.6870006146763349
Epoch: 50 | Iteration number: [3740/4518] 82% | Training loss: 0.6870001789242188
Epoch: 50 | Iteration number: [3750/4518] 83% | Training loss: 0.6870007900238038
Epoch: 50 | Iteration number: [3760/4518] 83% | Training loss: 0.686997376017748
Epoch: 50 | Iteration number: [3770/4518] 83% | Training loss: 0.6869967112648708
Epoch: 50 | Iteration number: [3780/4518] 83% | Training loss: 0.6869953993924711
Epoch: 50 | Iteration number: [3790/4518] 83% | Training loss: 0.6869956862957937
Epoch: 50 | Iteration number: [3800/4518] 84% | Training loss: 0.6869926510359111
Epoch: 50 | Iteration number: [3810/4518] 84% | Training loss: 0.6869882659805728
Epoch: 50 | Iteration number: [3820/4518] 84% | Training loss: 0.6869892749798859
Epoch: 50 | Iteration number: [3830/4518] 84% | Training loss: 0.6869864080344417
Epoch: 50 | Iteration number: [3840/4518] 84% | Training loss: 0.6869875524503489
Epoch: 50 | Iteration number: [3850/4518] 85% | Training loss: 0.6869883680343628
Epoch: 50 | Iteration number: [3860/4518] 85% | Training loss: 0.6869918775373173
Epoch: 50 | Iteration number: [3870/4518] 85% | Training loss: 0.6869897005631942
Epoch: 50 | Iteration number: [3880/4518] 85% | Training loss: 0.6869860139243381
Epoch: 50 | Iteration number: [3890/4518] 86% | Training loss: 0.6869854346798747
Epoch: 50 | Iteration number: [3900/4518] 86% | Training loss: 0.6869822038289828
Epoch: 50 | Iteration number: [3910/4518] 86% | Training loss: 0.6869813944830004
Epoch: 50 | Iteration number: [3920/4518] 86% | Training loss: 0.6869826368683455
Epoch: 50 | Iteration number: [3930/4518] 86% | Training loss: 0.6869812911703387
Epoch: 50 | Iteration number: [3940/4518] 87% | Training loss: 0.6869803044245327
Epoch: 50 | Iteration number: [3950/4518] 87% | Training loss: 0.6869788103163997
Epoch: 50 | Iteration number: [3960/4518] 87% | Training loss: 0.6869787524745922
Epoch: 50 | Iteration number: [3970/4518] 87% | Training loss: 0.6869802716697193
Epoch: 50 | Iteration number: [3980/4518] 88% | Training loss: 0.686980013961169
Epoch: 50 | Iteration number: [3990/4518] 88% | Training loss: 0.6869790620522989
Epoch: 50 | Iteration number: [4000/4518] 88% | Training loss: 0.6869810333549976
Epoch: 50 | Iteration number: [4010/4518] 88% | Training loss: 0.6869794341840054
Epoch: 50 | Iteration number: [4020/4518] 88% | Training loss: 0.6869756993073136
Epoch: 50 | Iteration number: [4030/4518] 89% | Training loss: 0.6869763418107707
Epoch: 50 | Iteration number: [4040/4518] 89% | Training loss: 0.6869783226068658
Epoch: 50 | Iteration number: [4050/4518] 89% | Training loss: 0.6869784595936905
Epoch: 50 | Iteration number: [4060/4518] 89% | Training loss: 0.6869782013699339
Epoch: 50 | Iteration number: [4070/4518] 90% | Training loss: 0.6869768536940254
Epoch: 50 | Iteration number: [4080/4518] 90% | Training loss: 0.6869790400360145
Epoch: 50 | Iteration number: [4090/4518] 90% | Training loss: 0.6869776448439853
Epoch: 50 | Iteration number: [4100/4518] 90% | Training loss: 0.6869803812881795
Epoch: 50 | Iteration number: [4110/4518] 90% | Training loss: 0.6869783405549915
Epoch: 50 | Iteration number: [4120/4518] 91% | Training loss: 0.6869740820046767
Epoch: 50 | Iteration number: [4130/4518] 91% | Training loss: 0.686972710771653
Epoch: 50 | Iteration number: [4140/4518] 91% | Training loss: 0.6869736153290468
Epoch: 50 | Iteration number: [4150/4518] 91% | Training loss: 0.6869721862494227
Epoch: 50 | Iteration number: [4160/4518] 92% | Training loss: 0.6869728446579897
Epoch: 50 | Iteration number: [4170/4518] 92% | Training loss: 0.6869666361408554
Epoch: 50 | Iteration number: [4180/4518] 92% | Training loss: 0.686966673423799
Epoch: 50 | Iteration number: [4190/4518] 92% | Training loss: 0.6869686715358198
Epoch: 50 | Iteration number: [4200/4518] 92% | Training loss: 0.6869664626887867
Epoch: 50 | Iteration number: [4210/4518] 93% | Training loss: 0.6869643884288443
Epoch: 50 | Iteration number: [4220/4518] 93% | Training loss: 0.6869671592073983
Epoch: 50 | Iteration number: [4230/4518] 93% | Training loss: 0.6869679079269968
Epoch: 50 | Iteration number: [4240/4518] 93% | Training loss: 0.6869679327702747
Epoch: 50 | Iteration number: [4250/4518] 94% | Training loss: 0.6869672584673938
Epoch: 50 | Iteration number: [4260/4518] 94% | Training loss: 0.6869673597280967
Epoch: 50 | Iteration number: [4270/4518] 94% | Training loss: 0.686968312260697
Epoch: 50 | Iteration number: [4280/4518] 94% | Training loss: 0.6869677533473924
Epoch: 50 | Iteration number: [4290/4518] 94% | Training loss: 0.6869666183884049
Epoch: 50 | Iteration number: [4300/4518] 95% | Training loss: 0.6869665957744732
Epoch: 50 | Iteration number: [4310/4518] 95% | Training loss: 0.6869686822603585
Epoch: 50 | Iteration number: [4320/4518] 95% | Training loss: 0.6869702226033917
Epoch: 50 | Iteration number: [4330/4518] 95% | Training loss: 0.6869709406796559
Epoch: 50 | Iteration number: [4340/4518] 96% | Training loss: 0.6869682682686687
Epoch: 50 | Iteration number: [4350/4518] 96% | Training loss: 0.6869698455689968
Epoch: 50 | Iteration number: [4360/4518] 96% | Training loss: 0.6869727745788907
Epoch: 50 | Iteration number: [4370/4518] 96% | Training loss: 0.6869727417451567
Epoch: 50 | Iteration number: [4380/4518] 96% | Training loss: 0.6869725941659108
Epoch: 50 | Iteration number: [4390/4518] 97% | Training loss: 0.6869698691884043
Epoch: 50 | Iteration number: [4400/4518] 97% | Training loss: 0.6869695690545169
Epoch: 50 | Iteration number: [4410/4518] 97% | Training loss: 0.6869660409670028
Epoch: 50 | Iteration number: [4420/4518] 97% | Training loss: 0.6869676411960999
Epoch: 50 | Iteration number: [4430/4518] 98% | Training loss: 0.6869702042629164
Epoch: 50 | Iteration number: [4440/4518] 98% | Training loss: 0.686971013825219
Epoch: 50 | Iteration number: [4450/4518] 98% | Training loss: 0.686970972546031
Epoch: 50 | Iteration number: [4460/4518] 98% | Training loss: 0.6869692914154497
Epoch: 50 | Iteration number: [4470/4518] 98% | Training loss: 0.6869704694822597
Epoch: 50 | Iteration number: [4480/4518] 99% | Training loss: 0.6869674590815391
Epoch: 50 | Iteration number: [4490/4518] 99% | Training loss: 0.6869657176374593
Epoch: 50 | Iteration number: [4500/4518] 99% | Training loss: 0.6869638407097922
Epoch: 50 | Iteration number: [4510/4518] 99% | Training loss: 0.6869604868661537

 End of epoch: 50 | Train Loss: 0.6868075774327059 | Training Time: 641 

 End of epoch: 50 | Eval Loss: 0.6899435629650038 | Evaluating Time: 17 
Epoch: 51 | Iteration number: [10/4518] 0% | Training loss: 0.7543317198753356
Epoch: 51 | Iteration number: [20/4518] 0% | Training loss: 0.7209299027919769
Epoch: 51 | Iteration number: [30/4518] 0% | Training loss: 0.7092962344487508
Epoch: 51 | Iteration number: [40/4518] 0% | Training loss: 0.7037363588809967
Epoch: 51 | Iteration number: [50/4518] 1% | Training loss: 0.7002033126354218
Epoch: 51 | Iteration number: [60/4518] 1% | Training loss: 0.6978465437889099
Epoch: 51 | Iteration number: [70/4518] 1% | Training loss: 0.6964374550751278
Epoch: 51 | Iteration number: [80/4518] 1% | Training loss: 0.6953489072620869
Epoch: 51 | Iteration number: [90/4518] 1% | Training loss: 0.6942903763718076
Epoch: 51 | Iteration number: [100/4518] 2% | Training loss: 0.6935432380437851
Epoch: 51 | Iteration number: [110/4518] 2% | Training loss: 0.692937911640514
Epoch: 51 | Iteration number: [120/4518] 2% | Training loss: 0.6923799460132917
Epoch: 51 | Iteration number: [130/4518] 2% | Training loss: 0.6919332646406614
Epoch: 51 | Iteration number: [140/4518] 3% | Training loss: 0.6914586224726268
Epoch: 51 | Iteration number: [150/4518] 3% | Training loss: 0.6911472841103872
Epoch: 51 | Iteration number: [160/4518] 3% | Training loss: 0.6909068111330271
Epoch: 51 | Iteration number: [170/4518] 3% | Training loss: 0.6906571451355429
Epoch: 51 | Iteration number: [180/4518] 3% | Training loss: 0.690417018201616
Epoch: 51 | Iteration number: [190/4518] 4% | Training loss: 0.6902555594318791
Epoch: 51 | Iteration number: [200/4518] 4% | Training loss: 0.6901206889748573
Epoch: 51 | Iteration number: [210/4518] 4% | Training loss: 0.6899493756748382
Epoch: 51 | Iteration number: [220/4518] 4% | Training loss: 0.6898611903190612
Epoch: 51 | Iteration number: [230/4518] 5% | Training loss: 0.6897613530573637
Epoch: 51 | Iteration number: [240/4518] 5% | Training loss: 0.6896414689719677
Epoch: 51 | Iteration number: [250/4518] 5% | Training loss: 0.6895358979701995
Epoch: 51 | Iteration number: [260/4518] 5% | Training loss: 0.6893969412033375
Epoch: 51 | Iteration number: [270/4518] 5% | Training loss: 0.689304792660254
Epoch: 51 | Iteration number: [280/4518] 6% | Training loss: 0.6892433728490557
Epoch: 51 | Iteration number: [290/4518] 6% | Training loss: 0.6891652138068758
Epoch: 51 | Iteration number: [300/4518] 6% | Training loss: 0.6890271832545598
Epoch: 51 | Iteration number: [310/4518] 6% | Training loss: 0.6889488210601191
Epoch: 51 | Iteration number: [320/4518] 7% | Training loss: 0.688865278288722
Epoch: 51 | Iteration number: [330/4518] 7% | Training loss: 0.688809482979052
Epoch: 51 | Iteration number: [340/4518] 7% | Training loss: 0.6887472752262565
Epoch: 51 | Iteration number: [350/4518] 7% | Training loss: 0.6886919634682792
Epoch: 51 | Iteration number: [360/4518] 7% | Training loss: 0.6886708676815033
Epoch: 51 | Iteration number: [370/4518] 8% | Training loss: 0.6886280910388843
Epoch: 51 | Iteration number: [380/4518] 8% | Training loss: 0.6885704139345571
Epoch: 51 | Iteration number: [390/4518] 8% | Training loss: 0.6885523062485915
Epoch: 51 | Iteration number: [400/4518] 8% | Training loss: 0.6885419715940952
Epoch: 51 | Iteration number: [410/4518] 9% | Training loss: 0.6885061700169633
Epoch: 51 | Iteration number: [420/4518] 9% | Training loss: 0.6884776149477277
Epoch: 51 | Iteration number: [430/4518] 9% | Training loss: 0.6884275092635044
Epoch: 51 | Iteration number: [440/4518] 9% | Training loss: 0.68840341351249
Epoch: 51 | Iteration number: [450/4518] 9% | Training loss: 0.6883723362286885
Epoch: 51 | Iteration number: [460/4518] 10% | Training loss: 0.6883570314749428
Epoch: 51 | Iteration number: [470/4518] 10% | Training loss: 0.6883110842806228
Epoch: 51 | Iteration number: [480/4518] 10% | Training loss: 0.6882939758400123
Epoch: 51 | Iteration number: [490/4518] 10% | Training loss: 0.6882614016532898
Epoch: 51 | Iteration number: [500/4518] 11% | Training loss: 0.6882407648563384
Epoch: 51 | Iteration number: [510/4518] 11% | Training loss: 0.6882143871456969
Epoch: 51 | Iteration number: [520/4518] 11% | Training loss: 0.688183802137008
Epoch: 51 | Iteration number: [530/4518] 11% | Training loss: 0.6881651220456609
Epoch: 51 | Iteration number: [540/4518] 11% | Training loss: 0.6881431979161722
Epoch: 51 | Iteration number: [550/4518] 12% | Training loss: 0.6881218991496346
Epoch: 51 | Iteration number: [560/4518] 12% | Training loss: 0.6881100951560906
Epoch: 51 | Iteration number: [570/4518] 12% | Training loss: 0.688109753947509
Epoch: 51 | Iteration number: [580/4518] 12% | Training loss: 0.6880841090761382
Epoch: 51 | Iteration number: [590/4518] 13% | Training loss: 0.688071003000615
Epoch: 51 | Iteration number: [600/4518] 13% | Training loss: 0.6880528909961382
Epoch: 51 | Iteration number: [610/4518] 13% | Training loss: 0.6880259333086796
Epoch: 51 | Iteration number: [620/4518] 13% | Training loss: 0.6879819671953878
Epoch: 51 | Iteration number: [630/4518] 13% | Training loss: 0.6879791065814003
Epoch: 51 | Iteration number: [640/4518] 14% | Training loss: 0.6879654718562961
Epoch: 51 | Iteration number: [650/4518] 14% | Training loss: 0.6879599117315732
Epoch: 51 | Iteration number: [660/4518] 14% | Training loss: 0.6879448781410853
Epoch: 51 | Iteration number: [670/4518] 14% | Training loss: 0.6879276712438953
Epoch: 51 | Iteration number: [680/4518] 15% | Training loss: 0.6878972814363592
Epoch: 51 | Iteration number: [690/4518] 15% | Training loss: 0.6879044311634008
Epoch: 51 | Iteration number: [700/4518] 15% | Training loss: 0.6878895312547684
Epoch: 51 | Iteration number: [710/4518] 15% | Training loss: 0.687863033422282
Epoch: 51 | Iteration number: [720/4518] 15% | Training loss: 0.6878316020800008
Epoch: 51 | Iteration number: [730/4518] 16% | Training loss: 0.6878159532808278
Epoch: 51 | Iteration number: [740/4518] 16% | Training loss: 0.6878183267406515
Epoch: 51 | Iteration number: [750/4518] 16% | Training loss: 0.687815601905187
Epoch: 51 | Iteration number: [760/4518] 16% | Training loss: 0.6877945010599337
Epoch: 51 | Iteration number: [770/4518] 17% | Training loss: 0.6877722231598643
Epoch: 51 | Iteration number: [780/4518] 17% | Training loss: 0.6877613279299858
Epoch: 51 | Iteration number: [790/4518] 17% | Training loss: 0.687763349466686
Epoch: 51 | Iteration number: [800/4518] 17% | Training loss: 0.6877456302940845
Epoch: 51 | Iteration number: [810/4518] 17% | Training loss: 0.6877280902715377
Epoch: 51 | Iteration number: [820/4518] 18% | Training loss: 0.6877065998025057
Epoch: 51 | Iteration number: [830/4518] 18% | Training loss: 0.6876978585518987
Epoch: 51 | Iteration number: [840/4518] 18% | Training loss: 0.6876731431200391
Epoch: 51 | Iteration number: [850/4518] 18% | Training loss: 0.6876783790307887
Epoch: 51 | Iteration number: [860/4518] 19% | Training loss: 0.6876750322275383
Epoch: 51 | Iteration number: [870/4518] 19% | Training loss: 0.6876773272437611
Epoch: 51 | Iteration number: [880/4518] 19% | Training loss: 0.6876874640583992
Epoch: 51 | Iteration number: [890/4518] 19% | Training loss: 0.6876788595419252
Epoch: 51 | Iteration number: [900/4518] 19% | Training loss: 0.6876623371574614
Epoch: 51 | Iteration number: [910/4518] 20% | Training loss: 0.6876536876290709
Epoch: 51 | Iteration number: [920/4518] 20% | Training loss: 0.6876282301933869
Epoch: 51 | Iteration number: [930/4518] 20% | Training loss: 0.6876263399918874
Epoch: 51 | Iteration number: [940/4518] 20% | Training loss: 0.6876320017779127
Epoch: 51 | Iteration number: [950/4518] 21% | Training loss: 0.6876250615872835
Epoch: 51 | Iteration number: [960/4518] 21% | Training loss: 0.6876184909914931
Epoch: 51 | Iteration number: [970/4518] 21% | Training loss: 0.6876124249291174
Epoch: 51 | Iteration number: [980/4518] 21% | Training loss: 0.6875888622536951
Epoch: 51 | Iteration number: [990/4518] 21% | Training loss: 0.6875798811214139
Epoch: 51 | Iteration number: [1000/4518] 22% | Training loss: 0.6875829455852509
Epoch: 51 | Iteration number: [1010/4518] 22% | Training loss: 0.6875781464104606
Epoch: 51 | Iteration number: [1020/4518] 22% | Training loss: 0.6875606644971698
Epoch: 51 | Iteration number: [1030/4518] 22% | Training loss: 0.6875394542240402
Epoch: 51 | Iteration number: [1040/4518] 23% | Training loss: 0.687525469236649
Epoch: 51 | Iteration number: [1050/4518] 23% | Training loss: 0.6875069393430437
Epoch: 51 | Iteration number: [1060/4518] 23% | Training loss: 0.6874991671656663
Epoch: 51 | Iteration number: [1070/4518] 23% | Training loss: 0.6875020621535934
Epoch: 51 | Iteration number: [1080/4518] 23% | Training loss: 0.6874858560937422
Epoch: 51 | Iteration number: [1090/4518] 24% | Training loss: 0.6874868958368214
Epoch: 51 | Iteration number: [1100/4518] 24% | Training loss: 0.6874910999428142
Epoch: 51 | Iteration number: [1110/4518] 24% | Training loss: 0.6874783105141408
Epoch: 51 | Iteration number: [1120/4518] 24% | Training loss: 0.6874688154884747
Epoch: 51 | Iteration number: [1130/4518] 25% | Training loss: 0.6874651944742793
Epoch: 51 | Iteration number: [1140/4518] 25% | Training loss: 0.6874579796665593
Epoch: 51 | Iteration number: [1150/4518] 25% | Training loss: 0.6874490688158118
Epoch: 51 | Iteration number: [1160/4518] 25% | Training loss: 0.6874367487327806
Epoch: 51 | Iteration number: [1170/4518] 25% | Training loss: 0.6874299872634757
Epoch: 51 | Iteration number: [1180/4518] 26% | Training loss: 0.6874196276826373
Epoch: 51 | Iteration number: [1190/4518] 26% | Training loss: 0.6874061720711845
Epoch: 51 | Iteration number: [1200/4518] 26% | Training loss: 0.6873969722290834
Epoch: 51 | Iteration number: [1210/4518] 26% | Training loss: 0.6873940963390445
Epoch: 51 | Iteration number: [1220/4518] 27% | Training loss: 0.687387685013599
Epoch: 51 | Iteration number: [1230/4518] 27% | Training loss: 0.6873799739814386
Epoch: 51 | Iteration number: [1240/4518] 27% | Training loss: 0.6873782942371983
Epoch: 51 | Iteration number: [1250/4518] 27% | Training loss: 0.6873786171913147
Epoch: 51 | Iteration number: [1260/4518] 27% | Training loss: 0.6873709055639449
Epoch: 51 | Iteration number: [1270/4518] 28% | Training loss: 0.687367998755823
Epoch: 51 | Iteration number: [1280/4518] 28% | Training loss: 0.6873629819601774
Epoch: 51 | Iteration number: [1290/4518] 28% | Training loss: 0.6873497484266295
Epoch: 51 | Iteration number: [1300/4518] 28% | Training loss: 0.6873501612131412
Epoch: 51 | Iteration number: [1310/4518] 28% | Training loss: 0.6873418737913816
Epoch: 51 | Iteration number: [1320/4518] 29% | Training loss: 0.6873330556985103
Epoch: 51 | Iteration number: [1330/4518] 29% | Training loss: 0.6873344730613823
Epoch: 51 | Iteration number: [1340/4518] 29% | Training loss: 0.6873327204095784
Epoch: 51 | Iteration number: [1350/4518] 29% | Training loss: 0.6873223597032052
Epoch: 51 | Iteration number: [1360/4518] 30% | Training loss: 0.6873120531001512
Epoch: 51 | Iteration number: [1370/4518] 30% | Training loss: 0.6873052091494094
Epoch: 51 | Iteration number: [1380/4518] 30% | Training loss: 0.6873033452725065
Epoch: 51 | Iteration number: [1390/4518] 30% | Training loss: 0.6872909749583375
Epoch: 51 | Iteration number: [1400/4518] 30% | Training loss: 0.6872859530363764
Epoch: 51 | Iteration number: [1410/4518] 31% | Training loss: 0.6872835503402331
Epoch: 51 | Iteration number: [1420/4518] 31% | Training loss: 0.6872840114462544
Epoch: 51 | Iteration number: [1430/4518] 31% | Training loss: 0.687269353783214
Epoch: 51 | Iteration number: [1440/4518] 31% | Training loss: 0.687274914359053
Epoch: 51 | Iteration number: [1450/4518] 32% | Training loss: 0.6872654757006414
Epoch: 51 | Iteration number: [1460/4518] 32% | Training loss: 0.6872606753078225
Epoch: 51 | Iteration number: [1470/4518] 32% | Training loss: 0.6872528331620352
Epoch: 51 | Iteration number: [1480/4518] 32% | Training loss: 0.6872484391202798
Epoch: 51 | Iteration number: [1490/4518] 32% | Training loss: 0.6872430172942628
Epoch: 51 | Iteration number: [1500/4518] 33% | Training loss: 0.6872441111803055
Epoch: 51 | Iteration number: [1510/4518] 33% | Training loss: 0.6872443092974606
Epoch: 51 | Iteration number: [1520/4518] 33% | Training loss: 0.6872477900432913
Epoch: 51 | Iteration number: [1530/4518] 33% | Training loss: 0.6872411367160822
Epoch: 51 | Iteration number: [1540/4518] 34% | Training loss: 0.6872368701479652
Epoch: 51 | Iteration number: [1550/4518] 34% | Training loss: 0.6872291247306331
Epoch: 51 | Iteration number: [1560/4518] 34% | Training loss: 0.6872262827096841
Epoch: 51 | Iteration number: [1570/4518] 34% | Training loss: 0.6872291288937733
Epoch: 51 | Iteration number: [1580/4518] 34% | Training loss: 0.6872241808266579
Epoch: 51 | Iteration number: [1590/4518] 35% | Training loss: 0.6872207945247866
Epoch: 51 | Iteration number: [1600/4518] 35% | Training loss: 0.6872246055677533
Epoch: 51 | Iteration number: [1610/4518] 35% | Training loss: 0.6872263424144769
Epoch: 51 | Iteration number: [1620/4518] 35% | Training loss: 0.687222702782831
Epoch: 51 | Iteration number: [1630/4518] 36% | Training loss: 0.687220026159579
Epoch: 51 | Iteration number: [1640/4518] 36% | Training loss: 0.6872100221674616
Epoch: 51 | Iteration number: [1650/4518] 36% | Training loss: 0.6872112180608692
Epoch: 51 | Iteration number: [1660/4518] 36% | Training loss: 0.6872110437556922
Epoch: 51 | Iteration number: [1670/4518] 36% | Training loss: 0.6872113235696348
Epoch: 51 | Iteration number: [1680/4518] 37% | Training loss: 0.6872142505432878
Epoch: 51 | Iteration number: [1690/4518] 37% | Training loss: 0.6872151928893208
Epoch: 51 | Iteration number: [1700/4518] 37% | Training loss: 0.6872111623427447
Epoch: 51 | Iteration number: [1710/4518] 37% | Training loss: 0.687203063532623
Epoch: 51 | Iteration number: [1720/4518] 38% | Training loss: 0.6871962523737619
Epoch: 51 | Iteration number: [1730/4518] 38% | Training loss: 0.6871977413665352
Epoch: 51 | Iteration number: [1740/4518] 38% | Training loss: 0.6871931874889067
Epoch: 51 | Iteration number: [1750/4518] 38% | Training loss: 0.6871889180796487
Epoch: 51 | Iteration number: [1760/4518] 38% | Training loss: 0.6871904337609356
Epoch: 51 | Iteration number: [1770/4518] 39% | Training loss: 0.6871851125679447
Epoch: 51 | Iteration number: [1780/4518] 39% | Training loss: 0.687187351872412
Epoch: 51 | Iteration number: [1790/4518] 39% | Training loss: 0.6871880322528285
Epoch: 51 | Iteration number: [1800/4518] 39% | Training loss: 0.687192307445738
Epoch: 51 | Iteration number: [1810/4518] 40% | Training loss: 0.6871978817394425
Epoch: 51 | Iteration number: [1820/4518] 40% | Training loss: 0.6871962671096509
Epoch: 51 | Iteration number: [1830/4518] 40% | Training loss: 0.687192652557717
Epoch: 51 | Iteration number: [1840/4518] 40% | Training loss: 0.6871902973431608
Epoch: 51 | Iteration number: [1850/4518] 40% | Training loss: 0.6871925560848133
Epoch: 51 | Iteration number: [1860/4518] 41% | Training loss: 0.6871903978047832
Epoch: 51 | Iteration number: [1870/4518] 41% | Training loss: 0.6871913887600211
Epoch: 51 | Iteration number: [1880/4518] 41% | Training loss: 0.6871929182017104
Epoch: 51 | Iteration number: [1890/4518] 41% | Training loss: 0.6871873545268226
Epoch: 51 | Iteration number: [1900/4518] 42% | Training loss: 0.6871887196051447
Epoch: 51 | Iteration number: [1910/4518] 42% | Training loss: 0.6871885262546739
Epoch: 51 | Iteration number: [1920/4518] 42% | Training loss: 0.6871864024239281
Epoch: 51 | Iteration number: [1930/4518] 42% | Training loss: 0.687180874292097
Epoch: 51 | Iteration number: [1940/4518] 42% | Training loss: 0.6871802969691679
Epoch: 51 | Iteration number: [1950/4518] 43% | Training loss: 0.6871738395324121
Epoch: 51 | Iteration number: [1960/4518] 43% | Training loss: 0.6871714556399657
Epoch: 51 | Iteration number: [1970/4518] 43% | Training loss: 0.6871744386435765
Epoch: 51 | Iteration number: [1980/4518] 43% | Training loss: 0.6871701513576989
Epoch: 51 | Iteration number: [1990/4518] 44% | Training loss: 0.6871716573310258
Epoch: 51 | Iteration number: [2000/4518] 44% | Training loss: 0.6871651722192764
Epoch: 51 | Iteration number: [2010/4518] 44% | Training loss: 0.6871631307091879
Epoch: 51 | Iteration number: [2020/4518] 44% | Training loss: 0.6871632382716283
Epoch: 51 | Iteration number: [2030/4518] 44% | Training loss: 0.6871610765093066
Epoch: 51 | Iteration number: [2040/4518] 45% | Training loss: 0.6871634860249126
Epoch: 51 | Iteration number: [2050/4518] 45% | Training loss: 0.6871646309480435
Epoch: 51 | Iteration number: [2060/4518] 45% | Training loss: 0.6871658251702207
Epoch: 51 | Iteration number: [2070/4518] 45% | Training loss: 0.6871642558758961
Epoch: 51 | Iteration number: [2080/4518] 46% | Training loss: 0.6871649839557135
Epoch: 51 | Iteration number: [2090/4518] 46% | Training loss: 0.6871688736112495
Epoch: 51 | Iteration number: [2100/4518] 46% | Training loss: 0.687171753417878
Epoch: 51 | Iteration number: [2110/4518] 46% | Training loss: 0.687170588913687
Epoch: 51 | Iteration number: [2120/4518] 46% | Training loss: 0.6871644358589964
Epoch: 51 | Iteration number: [2130/4518] 47% | Training loss: 0.6871608728254345
Epoch: 51 | Iteration number: [2140/4518] 47% | Training loss: 0.6871559067585757
Epoch: 51 | Iteration number: [2150/4518] 47% | Training loss: 0.6871545646356982
Epoch: 51 | Iteration number: [2160/4518] 47% | Training loss: 0.6871548230173411
Epoch: 51 | Iteration number: [2170/4518] 48% | Training loss: 0.6871500160836954
Epoch: 51 | Iteration number: [2180/4518] 48% | Training loss: 0.687147358852789
Epoch: 51 | Iteration number: [2190/4518] 48% | Training loss: 0.6871458302349804
Epoch: 51 | Iteration number: [2200/4518] 48% | Training loss: 0.6871440678022125
Epoch: 51 | Iteration number: [2210/4518] 48% | Training loss: 0.6871447970964251
Epoch: 51 | Iteration number: [2220/4518] 49% | Training loss: 0.687141979277671
Epoch: 51 | Iteration number: [2230/4518] 49% | Training loss: 0.6871467651005818
Epoch: 51 | Iteration number: [2240/4518] 49% | Training loss: 0.6871410304946559
Epoch: 51 | Iteration number: [2250/4518] 49% | Training loss: 0.6871344224082099
Epoch: 51 | Iteration number: [2260/4518] 50% | Training loss: 0.6871336118046162
Epoch: 51 | Iteration number: [2270/4518] 50% | Training loss: 0.6871307792379993
Epoch: 51 | Iteration number: [2280/4518] 50% | Training loss: 0.687132921370498
Epoch: 51 | Iteration number: [2290/4518] 50% | Training loss: 0.6871322172958257
Epoch: 51 | Iteration number: [2300/4518] 50% | Training loss: 0.6871292453226836
Epoch: 51 | Iteration number: [2310/4518] 51% | Training loss: 0.6871234386514276
Epoch: 51 | Iteration number: [2320/4518] 51% | Training loss: 0.6871223681188863
Epoch: 51 | Iteration number: [2330/4518] 51% | Training loss: 0.6871176431107419
Epoch: 51 | Iteration number: [2340/4518] 51% | Training loss: 0.6871233790348737
Epoch: 51 | Iteration number: [2350/4518] 52% | Training loss: 0.6871273262957309
Epoch: 51 | Iteration number: [2360/4518] 52% | Training loss: 0.6871270166362746
Epoch: 51 | Iteration number: [2370/4518] 52% | Training loss: 0.6871322851392287
Epoch: 51 | Iteration number: [2380/4518] 52% | Training loss: 0.687131045170191
Epoch: 51 | Iteration number: [2390/4518] 52% | Training loss: 0.6871313506838667
Epoch: 51 | Iteration number: [2400/4518] 53% | Training loss: 0.6871301399171352
Epoch: 51 | Iteration number: [2410/4518] 53% | Training loss: 0.6871337960864499
Epoch: 51 | Iteration number: [2420/4518] 53% | Training loss: 0.6871292718432166
Epoch: 51 | Iteration number: [2430/4518] 53% | Training loss: 0.6871314486358392
Epoch: 51 | Iteration number: [2440/4518] 54% | Training loss: 0.6871336091492997
Epoch: 51 | Iteration number: [2450/4518] 54% | Training loss: 0.6871310659574003
Epoch: 51 | Iteration number: [2460/4518] 54% | Training loss: 0.687129498569946
Epoch: 51 | Iteration number: [2470/4518] 54% | Training loss: 0.6871310935570644
Epoch: 51 | Iteration number: [2480/4518] 54% | Training loss: 0.6871292112815764
Epoch: 51 | Iteration number: [2490/4518] 55% | Training loss: 0.6871254601631778
Epoch: 51 | Iteration number: [2500/4518] 55% | Training loss: 0.6871213785886765
Epoch: 51 | Iteration number: [2510/4518] 55% | Training loss: 0.6871204432025849
Epoch: 51 | Iteration number: [2520/4518] 55% | Training loss: 0.6871160196879553
Epoch: 51 | Iteration number: [2530/4518] 55% | Training loss: 0.6871131586227492
Epoch: 51 | Iteration number: [2540/4518] 56% | Training loss: 0.6871095094155139
Epoch: 51 | Iteration number: [2550/4518] 56% | Training loss: 0.6871120656237882
Epoch: 51 | Iteration number: [2560/4518] 56% | Training loss: 0.6871107147540897
Epoch: 51 | Iteration number: [2570/4518] 56% | Training loss: 0.6871060972315792
Epoch: 51 | Iteration number: [2580/4518] 57% | Training loss: 0.6871062691359557
Epoch: 51 | Iteration number: [2590/4518] 57% | Training loss: 0.6871066366153334
Epoch: 51 | Iteration number: [2600/4518] 57% | Training loss: 0.6871088212040755
Epoch: 51 | Iteration number: [2610/4518] 57% | Training loss: 0.687108095669655
Epoch: 51 | Iteration number: [2620/4518] 57% | Training loss: 0.6871052846426272
Epoch: 51 | Iteration number: [2630/4518] 58% | Training loss: 0.68710386293016
Epoch: 51 | Iteration number: [2640/4518] 58% | Training loss: 0.6871029827856656
Epoch: 51 | Iteration number: [2650/4518] 58% | Training loss: 0.6871025528997745
Epoch: 51 | Iteration number: [2660/4518] 58% | Training loss: 0.6871017320039577
Epoch: 51 | Iteration number: [2670/4518] 59% | Training loss: 0.6871002026041795
Epoch: 51 | Iteration number: [2680/4518] 59% | Training loss: 0.6870965562427221
Epoch: 51 | Iteration number: [2690/4518] 59% | Training loss: 0.6870965250141116
Epoch: 51 | Iteration number: [2700/4518] 59% | Training loss: 0.6870990373690923
Epoch: 51 | Iteration number: [2710/4518] 59% | Training loss: 0.687093048496
Epoch: 51 | Iteration number: [2720/4518] 60% | Training loss: 0.687089695255546
Epoch: 51 | Iteration number: [2730/4518] 60% | Training loss: 0.6870923339010595
Epoch: 51 | Iteration number: [2740/4518] 60% | Training loss: 0.6870917839943057
Epoch: 51 | Iteration number: [2750/4518] 60% | Training loss: 0.6870918139761144
Epoch: 51 | Iteration number: [2760/4518] 61% | Training loss: 0.6870878005589264
Epoch: 51 | Iteration number: [2770/4518] 61% | Training loss: 0.6870882855425673
Epoch: 51 | Iteration number: [2780/4518] 61% | Training loss: 0.6870884319217943
Epoch: 51 | Iteration number: [2790/4518] 61% | Training loss: 0.6870876982647885
Epoch: 51 | Iteration number: [2800/4518] 61% | Training loss: 0.6870830040105752
Epoch: 51 | Iteration number: [2810/4518] 62% | Training loss: 0.6870826799886507
Epoch: 51 | Iteration number: [2820/4518] 62% | Training loss: 0.6870820915022641
Epoch: 51 | Iteration number: [2830/4518] 62% | Training loss: 0.687082417651537
Epoch: 51 | Iteration number: [2840/4518] 62% | Training loss: 0.6870862600249303
Epoch: 51 | Iteration number: [2850/4518] 63% | Training loss: 0.6870817348204161
Epoch: 51 | Iteration number: [2860/4518] 63% | Training loss: 0.687079137313616
Epoch: 51 | Iteration number: [2870/4518] 63% | Training loss: 0.6870783354970221
Epoch: 51 | Iteration number: [2880/4518] 63% | Training loss: 0.6870745112291641
Epoch: 51 | Iteration number: [2890/4518] 63% | Training loss: 0.6870774980441097
Epoch: 51 | Iteration number: [2900/4518] 64% | Training loss: 0.6870757647012842
Epoch: 51 | Iteration number: [2910/4518] 64% | Training loss: 0.6870702004104955
Epoch: 51 | Iteration number: [2920/4518] 64% | Training loss: 0.6870669356355928
Epoch: 51 | Iteration number: [2930/4518] 64% | Training loss: 0.6870700113602466
Epoch: 51 | Iteration number: [2940/4518] 65% | Training loss: 0.6870702777387333
Epoch: 51 | Iteration number: [2950/4518] 65% | Training loss: 0.6870658796520557
Epoch: 51 | Iteration number: [2960/4518] 65% | Training loss: 0.6870608001746036
Epoch: 51 | Iteration number: [2970/4518] 65% | Training loss: 0.6870583260902251
Epoch: 51 | Iteration number: [2980/4518] 65% | Training loss: 0.6870542185818589
Epoch: 51 | Iteration number: [2990/4518] 66% | Training loss: 0.6870491581816338
Epoch: 51 | Iteration number: [3000/4518] 66% | Training loss: 0.6870493494669596
Epoch: 51 | Iteration number: [3010/4518] 66% | Training loss: 0.687045539039314
Epoch: 51 | Iteration number: [3020/4518] 66% | Training loss: 0.6870477946191434
Epoch: 51 | Iteration number: [3030/4518] 67% | Training loss: 0.6870450512410784
Epoch: 51 | Iteration number: [3040/4518] 67% | Training loss: 0.6870429895622165
Epoch: 51 | Iteration number: [3050/4518] 67% | Training loss: 0.6870415183559793
Epoch: 51 | Iteration number: [3060/4518] 67% | Training loss: 0.6870419818396661
Epoch: 51 | Iteration number: [3070/4518] 67% | Training loss: 0.687045487557638
Epoch: 51 | Iteration number: [3080/4518] 68% | Training loss: 0.6870449097125562
Epoch: 51 | Iteration number: [3090/4518] 68% | Training loss: 0.6870426275004847
Epoch: 51 | Iteration number: [3100/4518] 68% | Training loss: 0.6870383613917136
Epoch: 51 | Iteration number: [3110/4518] 68% | Training loss: 0.6870358167928898
Epoch: 51 | Iteration number: [3120/4518] 69% | Training loss: 0.6870321268836658
Epoch: 51 | Iteration number: [3130/4518] 69% | Training loss: 0.6870348841427995
Epoch: 51 | Iteration number: [3140/4518] 69% | Training loss: 0.6870324004797419
Epoch: 51 | Iteration number: [3150/4518] 69% | Training loss: 0.6870296390094455
Epoch: 51 | Iteration number: [3160/4518] 69% | Training loss: 0.6870285808096959
Epoch: 51 | Iteration number: [3170/4518] 70% | Training loss: 0.6870264310001951
Epoch: 51 | Iteration number: [3180/4518] 70% | Training loss: 0.6870274125030206
Epoch: 51 | Iteration number: [3190/4518] 70% | Training loss: 0.6870260389994678
Epoch: 51 | Iteration number: [3200/4518] 70% | Training loss: 0.6870266004651785
Epoch: 51 | Iteration number: [3210/4518] 71% | Training loss: 0.6870252189977889
Epoch: 51 | Iteration number: [3220/4518] 71% | Training loss: 0.6870186021609336
Epoch: 51 | Iteration number: [3230/4518] 71% | Training loss: 0.6870176863190559
Epoch: 51 | Iteration number: [3240/4518] 71% | Training loss: 0.6870106155121768
Epoch: 51 | Iteration number: [3250/4518] 71% | Training loss: 0.6870116199530087
Epoch: 51 | Iteration number: [3260/4518] 72% | Training loss: 0.687008265867555
Epoch: 51 | Iteration number: [3270/4518] 72% | Training loss: 0.6870027864744904
Epoch: 51 | Iteration number: [3280/4518] 72% | Training loss: 0.6870071215782224
Epoch: 51 | Iteration number: [3290/4518] 72% | Training loss: 0.6870069044158089
Epoch: 51 | Iteration number: [3300/4518] 73% | Training loss: 0.6870092224894148
Epoch: 51 | Iteration number: [3310/4518] 73% | Training loss: 0.687008271944847
Epoch: 51 | Iteration number: [3320/4518] 73% | Training loss: 0.6870088438671755
Epoch: 51 | Iteration number: [3330/4518] 73% | Training loss: 0.6870089101003813
Epoch: 51 | Iteration number: [3340/4518] 73% | Training loss: 0.6870047420084834
Epoch: 51 | Iteration number: [3350/4518] 74% | Training loss: 0.6870021996213429
Epoch: 51 | Iteration number: [3360/4518] 74% | Training loss: 0.6870000157682669
Epoch: 51 | Iteration number: [3370/4518] 74% | Training loss: 0.6869980161020239
Epoch: 51 | Iteration number: [3380/4518] 74% | Training loss: 0.6869965875113504
Epoch: 51 | Iteration number: [3390/4518] 75% | Training loss: 0.6869967697644304
Epoch: 51 | Iteration number: [3400/4518] 75% | Training loss: 0.6869938249447767
Epoch: 51 | Iteration number: [3410/4518] 75% | Training loss: 0.6869981887403471
Epoch: 51 | Iteration number: [3420/4518] 75% | Training loss: 0.6869983657584553
Epoch: 51 | Iteration number: [3430/4518] 75% | Training loss: 0.6869974394060084
Epoch: 51 | Iteration number: [3440/4518] 76% | Training loss: 0.6869972091081531
Epoch: 51 | Iteration number: [3450/4518] 76% | Training loss: 0.6869921158189359
Epoch: 51 | Iteration number: [3460/4518] 76% | Training loss: 0.6869859562788395
Epoch: 51 | Iteration number: [3470/4518] 76% | Training loss: 0.6869870758194058
Epoch: 51 | Iteration number: [3480/4518] 77% | Training loss: 0.6869852573193352
Epoch: 51 | Iteration number: [3490/4518] 77% | Training loss: 0.6869866614013825
Epoch: 51 | Iteration number: [3500/4518] 77% | Training loss: 0.6869891832726343
Epoch: 51 | Iteration number: [3510/4518] 77% | Training loss: 0.6869873064026194
Epoch: 51 | Iteration number: [3520/4518] 77% | Training loss: 0.6869866839525375
Epoch: 51 | Iteration number: [3530/4518] 78% | Training loss: 0.6869921223468889
Epoch: 51 | Iteration number: [3540/4518] 78% | Training loss: 0.6869891510676529
Epoch: 51 | Iteration number: [3550/4518] 78% | Training loss: 0.686987990560666
Epoch: 51 | Iteration number: [3560/4518] 78% | Training loss: 0.6869885587123002
Epoch: 51 | Iteration number: [3570/4518] 79% | Training loss: 0.6869858254905509
Epoch: 51 | Iteration number: [3580/4518] 79% | Training loss: 0.686984659606518
Epoch: 51 | Iteration number: [3590/4518] 79% | Training loss: 0.6869832376417675
Epoch: 51 | Iteration number: [3600/4518] 79% | Training loss: 0.686981637676557
Epoch: 51 | Iteration number: [3610/4518] 79% | Training loss: 0.6869777563040936
Epoch: 51 | Iteration number: [3620/4518] 80% | Training loss: 0.6869742756719748
Epoch: 51 | Iteration number: [3630/4518] 80% | Training loss: 0.6869726750312101
Epoch: 51 | Iteration number: [3640/4518] 80% | Training loss: 0.6869707825747166
Epoch: 51 | Iteration number: [3650/4518] 80% | Training loss: 0.686968294676036
Epoch: 51 | Iteration number: [3660/4518] 81% | Training loss: 0.686967159327262
Epoch: 51 | Iteration number: [3670/4518] 81% | Training loss: 0.6869681602765169
Epoch: 51 | Iteration number: [3680/4518] 81% | Training loss: 0.68696963665602
Epoch: 51 | Iteration number: [3690/4518] 81% | Training loss: 0.6869676002803534
Epoch: 51 | Iteration number: [3700/4518] 81% | Training loss: 0.6869702381378896
Epoch: 51 | Iteration number: [3710/4518] 82% | Training loss: 0.6869713592722089
Epoch: 51 | Iteration number: [3720/4518] 82% | Training loss: 0.686969866371283
Epoch: 51 | Iteration number: [3730/4518] 82% | Training loss: 0.6869728225485568
Epoch: 51 | Iteration number: [3740/4518] 82% | Training loss: 0.6869775678862863
Epoch: 51 | Iteration number: [3750/4518] 83% | Training loss: 0.6869755451043447
Epoch: 51 | Iteration number: [3760/4518] 83% | Training loss: 0.6869759725446397
Epoch: 51 | Iteration number: [3770/4518] 83% | Training loss: 0.6869729217705107
Epoch: 51 | Iteration number: [3780/4518] 83% | Training loss: 0.6869761764372467
Epoch: 51 | Iteration number: [3790/4518] 83% | Training loss: 0.6869786517601214
Epoch: 51 | Iteration number: [3800/4518] 84% | Training loss: 0.6869790945555034
Epoch: 51 | Iteration number: [3810/4518] 84% | Training loss: 0.686977916549197
Epoch: 51 | Iteration number: [3820/4518] 84% | Training loss: 0.6869760462906972
Epoch: 51 | Iteration number: [3830/4518] 84% | Training loss: 0.6869758978680593
Epoch: 51 | Iteration number: [3840/4518] 84% | Training loss: 0.6869706939905882
Epoch: 51 | Iteration number: [3850/4518] 85% | Training loss: 0.6869705037327556
Epoch: 51 | Iteration number: [3860/4518] 85% | Training loss: 0.6869702501618182
Epoch: 51 | Iteration number: [3870/4518] 85% | Training loss: 0.6869685619992495
Epoch: 51 | Iteration number: [3880/4518] 85% | Training loss: 0.6869692282271139
Epoch: 51 | Iteration number: [3890/4518] 86% | Training loss: 0.6869697450365689
Epoch: 51 | Iteration number: [3900/4518] 86% | Training loss: 0.6869706194981551
Epoch: 51 | Iteration number: [3910/4518] 86% | Training loss: 0.6869688827820751
Epoch: 51 | Iteration number: [3920/4518] 86% | Training loss: 0.6869720731766856
Epoch: 51 | Iteration number: [3930/4518] 86% | Training loss: 0.6869689871033337
Epoch: 51 | Iteration number: [3940/4518] 87% | Training loss: 0.6869676557440443
Epoch: 51 | Iteration number: [3950/4518] 87% | Training loss: 0.6869664124748375
Epoch: 51 | Iteration number: [3960/4518] 87% | Training loss: 0.6869679076653539
Epoch: 51 | Iteration number: [3970/4518] 87% | Training loss: 0.6869704444252274
Epoch: 51 | Iteration number: [3980/4518] 88% | Training loss: 0.6869705592567598
Epoch: 51 | Iteration number: [3990/4518] 88% | Training loss: 0.6869744771405271
Epoch: 51 | Iteration number: [4000/4518] 88% | Training loss: 0.6869742022752762
Epoch: 51 | Iteration number: [4010/4518] 88% | Training loss: 0.6869723566601104
Epoch: 51 | Iteration number: [4020/4518] 88% | Training loss: 0.6869699647177511
Epoch: 51 | Iteration number: [4030/4518] 89% | Training loss: 0.6869709178472571
Epoch: 51 | Iteration number: [4040/4518] 89% | Training loss: 0.6869695000129171
Epoch: 51 | Iteration number: [4050/4518] 89% | Training loss: 0.6869708795459182
Epoch: 51 | Iteration number: [4060/4518] 89% | Training loss: 0.6869721379039323
Epoch: 51 | Iteration number: [4070/4518] 90% | Training loss: 0.6869718846144196
Epoch: 51 | Iteration number: [4080/4518] 90% | Training loss: 0.6869728559664652
Epoch: 51 | Iteration number: [4090/4518] 90% | Training loss: 0.6869691269904885
Epoch: 51 | Iteration number: [4100/4518] 90% | Training loss: 0.6869710626834776
Epoch: 51 | Iteration number: [4110/4518] 90% | Training loss: 0.6869739309424612
Epoch: 51 | Iteration number: [4120/4518] 91% | Training loss: 0.6869736258989398
Epoch: 51 | Iteration number: [4130/4518] 91% | Training loss: 0.6869746416446372
Epoch: 51 | Iteration number: [4140/4518] 91% | Training loss: 0.6869722520239687
Epoch: 51 | Iteration number: [4150/4518] 91% | Training loss: 0.6869727296714323
Epoch: 51 | Iteration number: [4160/4518] 92% | Training loss: 0.6869738359577381
Epoch: 51 | Iteration number: [4170/4518] 92% | Training loss: 0.6869710261730267
Epoch: 51 | Iteration number: [4180/4518] 92% | Training loss: 0.6869673568951457
Epoch: 51 | Iteration number: [4190/4518] 92% | Training loss: 0.6869677476922765
Epoch: 51 | Iteration number: [4200/4518] 92% | Training loss: 0.6869690476996558
Epoch: 51 | Iteration number: [4210/4518] 93% | Training loss: 0.6869689971987255
Epoch: 51 | Iteration number: [4220/4518] 93% | Training loss: 0.686968036906979
Epoch: 51 | Iteration number: [4230/4518] 93% | Training loss: 0.6869688863590817
Epoch: 51 | Iteration number: [4240/4518] 93% | Training loss: 0.6869713948582703
Epoch: 51 | Iteration number: [4250/4518] 94% | Training loss: 0.6869717807769775
Epoch: 51 | Iteration number: [4260/4518] 94% | Training loss: 0.6869722863038381
Epoch: 51 | Iteration number: [4270/4518] 94% | Training loss: 0.6869713608498317
Epoch: 51 | Iteration number: [4280/4518] 94% | Training loss: 0.6869707035684139
Epoch: 51 | Iteration number: [4290/4518] 94% | Training loss: 0.6869709590376119
Epoch: 51 | Iteration number: [4300/4518] 95% | Training loss: 0.6869710534256558
Epoch: 51 | Iteration number: [4310/4518] 95% | Training loss: 0.6869690331948053
Epoch: 51 | Iteration number: [4320/4518] 95% | Training loss: 0.6869674012892776
Epoch: 51 | Iteration number: [4330/4518] 95% | Training loss: 0.6869691477636818
Epoch: 51 | Iteration number: [4340/4518] 96% | Training loss: 0.6869688831578751
Epoch: 51 | Iteration number: [4350/4518] 96% | Training loss: 0.6869684750321268
Epoch: 51 | Iteration number: [4360/4518] 96% | Training loss: 0.686968397779749
Epoch: 51 | Iteration number: [4370/4518] 96% | Training loss: 0.6869694490318168
Epoch: 51 | Iteration number: [4380/4518] 96% | Training loss: 0.6869697651906644
Epoch: 51 | Iteration number: [4390/4518] 97% | Training loss: 0.686970518756836
Epoch: 51 | Iteration number: [4400/4518] 97% | Training loss: 0.6869721420651133
Epoch: 51 | Iteration number: [4410/4518] 97% | Training loss: 0.6869685602296237
Epoch: 51 | Iteration number: [4420/4518] 97% | Training loss: 0.6869685731861925
Epoch: 51 | Iteration number: [4430/4518] 98% | Training loss: 0.6869706204728672
Epoch: 51 | Iteration number: [4440/4518] 98% | Training loss: 0.68696685148789
Epoch: 51 | Iteration number: [4450/4518] 98% | Training loss: 0.6869653242223718
Epoch: 51 | Iteration number: [4460/4518] 98% | Training loss: 0.6869659092928797
Epoch: 51 | Iteration number: [4470/4518] 98% | Training loss: 0.6869650839292496
Epoch: 51 | Iteration number: [4480/4518] 99% | Training loss: 0.6869638539451574
Epoch: 51 | Iteration number: [4490/4518] 99% | Training loss: 0.6869607535130728
Epoch: 51 | Iteration number: [4500/4518] 99% | Training loss: 0.6869609151416355
Epoch: 51 | Iteration number: [4510/4518] 99% | Training loss: 0.6869608947680953

 End of epoch: 51 | Train Loss: 0.6868105070313398 | Training Time: 641 

 End of epoch: 51 | Eval Loss: 0.6899835017262673 | Evaluating Time: 17 
Epoch: 52 | Iteration number: [10/4518] 0% | Training loss: 0.7558916091918946
Epoch: 52 | Iteration number: [20/4518] 0% | Training loss: 0.7216908901929855
Epoch: 52 | Iteration number: [30/4518] 0% | Training loss: 0.7097741762797037
Epoch: 52 | Iteration number: [40/4518] 0% | Training loss: 0.7040556207299232
Epoch: 52 | Iteration number: [50/4518] 1% | Training loss: 0.700678493976593
Epoch: 52 | Iteration number: [60/4518] 1% | Training loss: 0.6984559188286463
Epoch: 52 | Iteration number: [70/4518] 1% | Training loss: 0.6969621002674102
Epoch: 52 | Iteration number: [80/4518] 1% | Training loss: 0.6956483207643032
Epoch: 52 | Iteration number: [90/4518] 1% | Training loss: 0.6947237074375152
Epoch: 52 | Iteration number: [100/4518] 2% | Training loss: 0.6940658295154571
Epoch: 52 | Iteration number: [110/4518] 2% | Training loss: 0.6933009044690566
Epoch: 52 | Iteration number: [120/4518] 2% | Training loss: 0.6926484773556392
Epoch: 52 | Iteration number: [130/4518] 2% | Training loss: 0.692217971269901
Epoch: 52 | Iteration number: [140/4518] 3% | Training loss: 0.6918736227921077
Epoch: 52 | Iteration number: [150/4518] 3% | Training loss: 0.6914724826812744
Epoch: 52 | Iteration number: [160/4518] 3% | Training loss: 0.6911949075758457
Epoch: 52 | Iteration number: [170/4518] 3% | Training loss: 0.6909861631253187
Epoch: 52 | Iteration number: [180/4518] 3% | Training loss: 0.6907233681943682
Epoch: 52 | Iteration number: [190/4518] 4% | Training loss: 0.6905035658886558
Epoch: 52 | Iteration number: [200/4518] 4% | Training loss: 0.6902548196911812
Epoch: 52 | Iteration number: [210/4518] 4% | Training loss: 0.6900391695045289
Epoch: 52 | Iteration number: [220/4518] 4% | Training loss: 0.6899297817186876
Epoch: 52 | Iteration number: [230/4518] 5% | Training loss: 0.6898253588572792
Epoch: 52 | Iteration number: [240/4518] 5% | Training loss: 0.6897087313234807
Epoch: 52 | Iteration number: [250/4518] 5% | Training loss: 0.689672886133194
Epoch: 52 | Iteration number: [260/4518] 5% | Training loss: 0.6895291475149301
Epoch: 52 | Iteration number: [270/4518] 5% | Training loss: 0.6894674404903695
Epoch: 52 | Iteration number: [280/4518] 6% | Training loss: 0.6894291792597089
Epoch: 52 | Iteration number: [290/4518] 6% | Training loss: 0.6893381303754346
Epoch: 52 | Iteration number: [300/4518] 6% | Training loss: 0.6892766584952672
Epoch: 52 | Iteration number: [310/4518] 6% | Training loss: 0.6891731615989439
Epoch: 52 | Iteration number: [320/4518] 7% | Training loss: 0.6890820370987057
Epoch: 52 | Iteration number: [330/4518] 7% | Training loss: 0.689010333292412
Epoch: 52 | Iteration number: [340/4518] 7% | Training loss: 0.6889252238413867
Epoch: 52 | Iteration number: [350/4518] 7% | Training loss: 0.6888403557028089
Epoch: 52 | Iteration number: [360/4518] 7% | Training loss: 0.6887642022636201
Epoch: 52 | Iteration number: [370/4518] 8% | Training loss: 0.6887276546375172
Epoch: 52 | Iteration number: [380/4518] 8% | Training loss: 0.6886711412354519
Epoch: 52 | Iteration number: [390/4518] 8% | Training loss: 0.6886292468278836
Epoch: 52 | Iteration number: [400/4518] 8% | Training loss: 0.6886108100414277
Epoch: 52 | Iteration number: [410/4518] 9% | Training loss: 0.6885781810051057
Epoch: 52 | Iteration number: [420/4518] 9% | Training loss: 0.6885303284440721
Epoch: 52 | Iteration number: [430/4518] 9% | Training loss: 0.6884672431058662
Epoch: 52 | Iteration number: [440/4518] 9% | Training loss: 0.6884040572426536
Epoch: 52 | Iteration number: [450/4518] 9% | Training loss: 0.6883687958452437
Epoch: 52 | Iteration number: [460/4518] 10% | Training loss: 0.6883160383804985
Epoch: 52 | Iteration number: [470/4518] 10% | Training loss: 0.6883090206917296
Epoch: 52 | Iteration number: [480/4518] 10% | Training loss: 0.6882718365639449
Epoch: 52 | Iteration number: [490/4518] 10% | Training loss: 0.6882249431950705
Epoch: 52 | Iteration number: [500/4518] 11% | Training loss: 0.6882057740688324
Epoch: 52 | Iteration number: [510/4518] 11% | Training loss: 0.688187229048972
Epoch: 52 | Iteration number: [520/4518] 11% | Training loss: 0.6881163048056456
Epoch: 52 | Iteration number: [530/4518] 11% | Training loss: 0.6880832811571517
Epoch: 52 | Iteration number: [540/4518] 11% | Training loss: 0.6880803479088677
Epoch: 52 | Iteration number: [550/4518] 12% | Training loss: 0.6880627868392251
Epoch: 52 | Iteration number: [560/4518] 12% | Training loss: 0.6880298399499485
Epoch: 52 | Iteration number: [570/4518] 12% | Training loss: 0.6880049889547784
Epoch: 52 | Iteration number: [580/4518] 12% | Training loss: 0.6879786260169128
Epoch: 52 | Iteration number: [590/4518] 13% | Training loss: 0.6879613035816258
Epoch: 52 | Iteration number: [600/4518] 13% | Training loss: 0.6879226380586624
Epoch: 52 | Iteration number: [610/4518] 13% | Training loss: 0.6879023556826545
Epoch: 52 | Iteration number: [620/4518] 13% | Training loss: 0.6879033532834822
Epoch: 52 | Iteration number: [630/4518] 13% | Training loss: 0.6878660207703
Epoch: 52 | Iteration number: [640/4518] 14% | Training loss: 0.6878501139581203
Epoch: 52 | Iteration number: [650/4518] 14% | Training loss: 0.6878428379388956
Epoch: 52 | Iteration number: [660/4518] 14% | Training loss: 0.6878425326311227
Epoch: 52 | Iteration number: [670/4518] 14% | Training loss: 0.6878350051481332
Epoch: 52 | Iteration number: [680/4518] 15% | Training loss: 0.6878332023234929
Epoch: 52 | Iteration number: [690/4518] 15% | Training loss: 0.6878058521643929
Epoch: 52 | Iteration number: [700/4518] 15% | Training loss: 0.687794776388577
Epoch: 52 | Iteration number: [710/4518] 15% | Training loss: 0.6877881741020041
Epoch: 52 | Iteration number: [720/4518] 15% | Training loss: 0.6877876395152674
Epoch: 52 | Iteration number: [730/4518] 16% | Training loss: 0.6877695922165701
Epoch: 52 | Iteration number: [740/4518] 16% | Training loss: 0.6877590095674669
Epoch: 52 | Iteration number: [750/4518] 16% | Training loss: 0.6877296096483866
Epoch: 52 | Iteration number: [760/4518] 16% | Training loss: 0.6877050340175629
Epoch: 52 | Iteration number: [770/4518] 17% | Training loss: 0.6876983481568175
Epoch: 52 | Iteration number: [780/4518] 17% | Training loss: 0.6876844033216819
Epoch: 52 | Iteration number: [790/4518] 17% | Training loss: 0.687661604715299
Epoch: 52 | Iteration number: [800/4518] 17% | Training loss: 0.6876412338018417
Epoch: 52 | Iteration number: [810/4518] 17% | Training loss: 0.6876366710957186
Epoch: 52 | Iteration number: [820/4518] 18% | Training loss: 0.6876307499844854
Epoch: 52 | Iteration number: [830/4518] 18% | Training loss: 0.6876229505941093
Epoch: 52 | Iteration number: [840/4518] 18% | Training loss: 0.6876312179224832
Epoch: 52 | Iteration number: [850/4518] 18% | Training loss: 0.6876212131275851
Epoch: 52 | Iteration number: [860/4518] 19% | Training loss: 0.6876256404921066
Epoch: 52 | Iteration number: [870/4518] 19% | Training loss: 0.6876164156815101
Epoch: 52 | Iteration number: [880/4518] 19% | Training loss: 0.687619338794188
Epoch: 52 | Iteration number: [890/4518] 19% | Training loss: 0.6876112791259638
Epoch: 52 | Iteration number: [900/4518] 19% | Training loss: 0.6876013796197044
Epoch: 52 | Iteration number: [910/4518] 20% | Training loss: 0.6875827619662651
Epoch: 52 | Iteration number: [920/4518] 20% | Training loss: 0.6875821266485297
Epoch: 52 | Iteration number: [930/4518] 20% | Training loss: 0.6875620392061049
Epoch: 52 | Iteration number: [940/4518] 20% | Training loss: 0.6875574047895188
Epoch: 52 | Iteration number: [950/4518] 21% | Training loss: 0.6875599550573449
Epoch: 52 | Iteration number: [960/4518] 21% | Training loss: 0.6875515017658472
Epoch: 52 | Iteration number: [970/4518] 21% | Training loss: 0.6875416964599766
Epoch: 52 | Iteration number: [980/4518] 21% | Training loss: 0.6875442137523573
Epoch: 52 | Iteration number: [990/4518] 21% | Training loss: 0.6875447854249165
Epoch: 52 | Iteration number: [1000/4518] 22% | Training loss: 0.6875303542017936
Epoch: 52 | Iteration number: [1010/4518] 22% | Training loss: 0.6875141044064323
Epoch: 52 | Iteration number: [1020/4518] 22% | Training loss: 0.6875062389701021
Epoch: 52 | Iteration number: [1030/4518] 22% | Training loss: 0.6874981337959326
Epoch: 52 | Iteration number: [1040/4518] 23% | Training loss: 0.687492258904072
Epoch: 52 | Iteration number: [1050/4518] 23% | Training loss: 0.687488728421075
Epoch: 52 | Iteration number: [1060/4518] 23% | Training loss: 0.6874966395351122
Epoch: 52 | Iteration number: [1070/4518] 23% | Training loss: 0.6874898106138283
Epoch: 52 | Iteration number: [1080/4518] 23% | Training loss: 0.6874822099451665
Epoch: 52 | Iteration number: [1090/4518] 24% | Training loss: 0.687476507786217
Epoch: 52 | Iteration number: [1100/4518] 24% | Training loss: 0.687471536397934
Epoch: 52 | Iteration number: [1110/4518] 24% | Training loss: 0.687467723225688
Epoch: 52 | Iteration number: [1120/4518] 24% | Training loss: 0.6874567679528679
Epoch: 52 | Iteration number: [1130/4518] 25% | Training loss: 0.6874492721747508
Epoch: 52 | Iteration number: [1140/4518] 25% | Training loss: 0.6874412547078049
Epoch: 52 | Iteration number: [1150/4518] 25% | Training loss: 0.6874347459751626
Epoch: 52 | Iteration number: [1160/4518] 25% | Training loss: 0.6874274171631912
Epoch: 52 | Iteration number: [1170/4518] 25% | Training loss: 0.687426184436195
Epoch: 52 | Iteration number: [1180/4518] 26% | Training loss: 0.6874194083072371
Epoch: 52 | Iteration number: [1190/4518] 26% | Training loss: 0.6874144662829006
Epoch: 52 | Iteration number: [1200/4518] 26% | Training loss: 0.6874067282676697
Epoch: 52 | Iteration number: [1210/4518] 26% | Training loss: 0.6874033745162743
Epoch: 52 | Iteration number: [1220/4518] 27% | Training loss: 0.6873943492037351
Epoch: 52 | Iteration number: [1230/4518] 27% | Training loss: 0.6873947146946822
Epoch: 52 | Iteration number: [1240/4518] 27% | Training loss: 0.6873908972547901
Epoch: 52 | Iteration number: [1250/4518] 27% | Training loss: 0.6873817981719971
Epoch: 52 | Iteration number: [1260/4518] 27% | Training loss: 0.6873892176245886
Epoch: 52 | Iteration number: [1270/4518] 28% | Training loss: 0.6873892918815763
Epoch: 52 | Iteration number: [1280/4518] 28% | Training loss: 0.6873868788126856
Epoch: 52 | Iteration number: [1290/4518] 28% | Training loss: 0.6873830495416656
Epoch: 52 | Iteration number: [1300/4518] 28% | Training loss: 0.6873881738002484
Epoch: 52 | Iteration number: [1310/4518] 28% | Training loss: 0.6873732543628635
Epoch: 52 | Iteration number: [1320/4518] 29% | Training loss: 0.6873582078651949
Epoch: 52 | Iteration number: [1330/4518] 29% | Training loss: 0.6873576243569081
Epoch: 52 | Iteration number: [1340/4518] 29% | Training loss: 0.6873601485988987
Epoch: 52 | Iteration number: [1350/4518] 29% | Training loss: 0.6873569445256834
Epoch: 52 | Iteration number: [1360/4518] 30% | Training loss: 0.6873535096207086
Epoch: 52 | Iteration number: [1370/4518] 30% | Training loss: 0.6873417119910247
Epoch: 52 | Iteration number: [1380/4518] 30% | Training loss: 0.6873429538547129
Epoch: 52 | Iteration number: [1390/4518] 30% | Training loss: 0.6873433332649066
Epoch: 52 | Iteration number: [1400/4518] 30% | Training loss: 0.6873444395831653
Epoch: 52 | Iteration number: [1410/4518] 31% | Training loss: 0.6873372010728146
Epoch: 52 | Iteration number: [1420/4518] 31% | Training loss: 0.6873295752515256
Epoch: 52 | Iteration number: [1430/4518] 31% | Training loss: 0.6873254569260391
Epoch: 52 | Iteration number: [1440/4518] 31% | Training loss: 0.6873301516390509
Epoch: 52 | Iteration number: [1450/4518] 32% | Training loss: 0.6873253824381993
Epoch: 52 | Iteration number: [1460/4518] 32% | Training loss: 0.6873188993702196
Epoch: 52 | Iteration number: [1470/4518] 32% | Training loss: 0.687310302703559
Epoch: 52 | Iteration number: [1480/4518] 32% | Training loss: 0.6873080603576995
Epoch: 52 | Iteration number: [1490/4518] 32% | Training loss: 0.6873045622502397
Epoch: 52 | Iteration number: [1500/4518] 33% | Training loss: 0.687298925002416
Epoch: 52 | Iteration number: [1510/4518] 33% | Training loss: 0.6872940690312165
Epoch: 52 | Iteration number: [1520/4518] 33% | Training loss: 0.6872930835736425
Epoch: 52 | Iteration number: [1530/4518] 33% | Training loss: 0.6872886820556292
Epoch: 52 | Iteration number: [1540/4518] 34% | Training loss: 0.6872866896065799
Epoch: 52 | Iteration number: [1550/4518] 34% | Training loss: 0.6872846339594934
Epoch: 52 | Iteration number: [1560/4518] 34% | Training loss: 0.6872810525389818
Epoch: 52 | Iteration number: [1570/4518] 34% | Training loss: 0.6872835700678978
Epoch: 52 | Iteration number: [1580/4518] 34% | Training loss: 0.687276679692389
Epoch: 52 | Iteration number: [1590/4518] 35% | Training loss: 0.6872667778587941
Epoch: 52 | Iteration number: [1600/4518] 35% | Training loss: 0.6872654641419649
Epoch: 52 | Iteration number: [1610/4518] 35% | Training loss: 0.6872633948459388
Epoch: 52 | Iteration number: [1620/4518] 35% | Training loss: 0.6872604646064617
Epoch: 52 | Iteration number: [1630/4518] 36% | Training loss: 0.6872587293203622
Epoch: 52 | Iteration number: [1640/4518] 36% | Training loss: 0.6872577653788938
Epoch: 52 | Iteration number: [1650/4518] 36% | Training loss: 0.6872564673062527
Epoch: 52 | Iteration number: [1660/4518] 36% | Training loss: 0.6872557112969548
Epoch: 52 | Iteration number: [1670/4518] 36% | Training loss: 0.6872381147153364
Epoch: 52 | Iteration number: [1680/4518] 37% | Training loss: 0.6872309874920618
Epoch: 52 | Iteration number: [1690/4518] 37% | Training loss: 0.6872305576265211
Epoch: 52 | Iteration number: [1700/4518] 37% | Training loss: 0.6872316651484546
Epoch: 52 | Iteration number: [1710/4518] 37% | Training loss: 0.6872332568057099
Epoch: 52 | Iteration number: [1720/4518] 38% | Training loss: 0.6872310354266056
Epoch: 52 | Iteration number: [1730/4518] 38% | Training loss: 0.6872304589762164
Epoch: 52 | Iteration number: [1740/4518] 38% | Training loss: 0.6872283685823967
Epoch: 52 | Iteration number: [1750/4518] 38% | Training loss: 0.6872270594664982
Epoch: 52 | Iteration number: [1760/4518] 38% | Training loss: 0.6872284095395695
Epoch: 52 | Iteration number: [1770/4518] 39% | Training loss: 0.6872205022027937
Epoch: 52 | Iteration number: [1780/4518] 39% | Training loss: 0.6872201125943259
Epoch: 52 | Iteration number: [1790/4518] 39% | Training loss: 0.6872228093986404
Epoch: 52 | Iteration number: [1800/4518] 39% | Training loss: 0.6872247225377295
Epoch: 52 | Iteration number: [1810/4518] 40% | Training loss: 0.6872300809918188
Epoch: 52 | Iteration number: [1820/4518] 40% | Training loss: 0.6872270228443565
Epoch: 52 | Iteration number: [1830/4518] 40% | Training loss: 0.6872242770885509
Epoch: 52 | Iteration number: [1840/4518] 40% | Training loss: 0.6872214535656183
Epoch: 52 | Iteration number: [1850/4518] 40% | Training loss: 0.6872213771858731
Epoch: 52 | Iteration number: [1860/4518] 41% | Training loss: 0.6872207308007825
Epoch: 52 | Iteration number: [1870/4518] 41% | Training loss: 0.6872216910601937
Epoch: 52 | Iteration number: [1880/4518] 41% | Training loss: 0.687217970224137
Epoch: 52 | Iteration number: [1890/4518] 41% | Training loss: 0.6872184721881119
Epoch: 52 | Iteration number: [1900/4518] 42% | Training loss: 0.6872134812568363
Epoch: 52 | Iteration number: [1910/4518] 42% | Training loss: 0.6872166526255183
Epoch: 52 | Iteration number: [1920/4518] 42% | Training loss: 0.6872156605434915
Epoch: 52 | Iteration number: [1930/4518] 42% | Training loss: 0.6872052201026462
Epoch: 52 | Iteration number: [1940/4518] 42% | Training loss: 0.6872156570867165
Epoch: 52 | Iteration number: [1950/4518] 43% | Training loss: 0.6872181529876513
Epoch: 52 | Iteration number: [1960/4518] 43% | Training loss: 0.6872184774401237
Epoch: 52 | Iteration number: [1970/4518] 43% | Training loss: 0.687219018046626
Epoch: 52 | Iteration number: [1980/4518] 43% | Training loss: 0.6872152906174611
Epoch: 52 | Iteration number: [1990/4518] 44% | Training loss: 0.6872124786352991
Epoch: 52 | Iteration number: [2000/4518] 44% | Training loss: 0.687209585428238
Epoch: 52 | Iteration number: [2010/4518] 44% | Training loss: 0.6872140569769921
Epoch: 52 | Iteration number: [2020/4518] 44% | Training loss: 0.6872111027193541
Epoch: 52 | Iteration number: [2030/4518] 44% | Training loss: 0.6872116376907368
Epoch: 52 | Iteration number: [2040/4518] 45% | Training loss: 0.687207454384542
Epoch: 52 | Iteration number: [2050/4518] 45% | Training loss: 0.6872056758694532
Epoch: 52 | Iteration number: [2060/4518] 45% | Training loss: 0.68720825572037
Epoch: 52 | Iteration number: [2070/4518] 45% | Training loss: 0.6872136618492108
Epoch: 52 | Iteration number: [2080/4518] 46% | Training loss: 0.6872095739325652
Epoch: 52 | Iteration number: [2090/4518] 46% | Training loss: 0.6872087780653575
Epoch: 52 | Iteration number: [2100/4518] 46% | Training loss: 0.6872021618059704
Epoch: 52 | Iteration number: [2110/4518] 46% | Training loss: 0.6872021392905882
Epoch: 52 | Iteration number: [2120/4518] 46% | Training loss: 0.6872032560548692
Epoch: 52 | Iteration number: [2130/4518] 47% | Training loss: 0.6872021705891604
Epoch: 52 | Iteration number: [2140/4518] 47% | Training loss: 0.6871984113599653
Epoch: 52 | Iteration number: [2150/4518] 47% | Training loss: 0.687194598996362
Epoch: 52 | Iteration number: [2160/4518] 47% | Training loss: 0.6871903716414063
Epoch: 52 | Iteration number: [2170/4518] 48% | Training loss: 0.6871881915402303
Epoch: 52 | Iteration number: [2180/4518] 48% | Training loss: 0.68719099352666
Epoch: 52 | Iteration number: [2190/4518] 48% | Training loss: 0.6871882121584731
Epoch: 52 | Iteration number: [2200/4518] 48% | Training loss: 0.687188141671094
Epoch: 52 | Iteration number: [2210/4518] 48% | Training loss: 0.6871838990110078
Epoch: 52 | Iteration number: [2220/4518] 49% | Training loss: 0.6871830129677111
Epoch: 52 | Iteration number: [2230/4518] 49% | Training loss: 0.6871791814207496
Epoch: 52 | Iteration number: [2240/4518] 49% | Training loss: 0.68718062756317
Epoch: 52 | Iteration number: [2250/4518] 49% | Training loss: 0.6871780617502
Epoch: 52 | Iteration number: [2260/4518] 50% | Training loss: 0.6871753163042321
Epoch: 52 | Iteration number: [2270/4518] 50% | Training loss: 0.687173221578682
Epoch: 52 | Iteration number: [2280/4518] 50% | Training loss: 0.6871671632455106
Epoch: 52 | Iteration number: [2290/4518] 50% | Training loss: 0.6871710650004674
Epoch: 52 | Iteration number: [2300/4518] 50% | Training loss: 0.6871711171969124
Epoch: 52 | Iteration number: [2310/4518] 51% | Training loss: 0.6871672811446252
Epoch: 52 | Iteration number: [2320/4518] 51% | Training loss: 0.6871690865734528
Epoch: 52 | Iteration number: [2330/4518] 51% | Training loss: 0.6871629446361198
Epoch: 52 | Iteration number: [2340/4518] 51% | Training loss: 0.6871557482032694
Epoch: 52 | Iteration number: [2350/4518] 52% | Training loss: 0.6871576805064019
Epoch: 52 | Iteration number: [2360/4518] 52% | Training loss: 0.6871546874359503
Epoch: 52 | Iteration number: [2370/4518] 52% | Training loss: 0.6871558778899631
Epoch: 52 | Iteration number: [2380/4518] 52% | Training loss: 0.6871530746461965
Epoch: 52 | Iteration number: [2390/4518] 52% | Training loss: 0.68715646670952
Epoch: 52 | Iteration number: [2400/4518] 53% | Training loss: 0.6871488621085882
Epoch: 52 | Iteration number: [2410/4518] 53% | Training loss: 0.6871476879753018
Epoch: 52 | Iteration number: [2420/4518] 53% | Training loss: 0.6871450766305293
Epoch: 52 | Iteration number: [2430/4518] 53% | Training loss: 0.6871470661075026
Epoch: 52 | Iteration number: [2440/4518] 54% | Training loss: 0.6871466112674259
Epoch: 52 | Iteration number: [2450/4518] 54% | Training loss: 0.6871428695260262
Epoch: 52 | Iteration number: [2460/4518] 54% | Training loss: 0.687143029599655
Epoch: 52 | Iteration number: [2470/4518] 54% | Training loss: 0.6871374282518379
Epoch: 52 | Iteration number: [2480/4518] 54% | Training loss: 0.6871378451105087
Epoch: 52 | Iteration number: [2490/4518] 55% | Training loss: 0.6871395220000103
Epoch: 52 | Iteration number: [2500/4518] 55% | Training loss: 0.6871350862979889
Epoch: 52 | Iteration number: [2510/4518] 55% | Training loss: 0.6871360937200219
Epoch: 52 | Iteration number: [2520/4518] 55% | Training loss: 0.6871373503690674
Epoch: 52 | Iteration number: [2530/4518] 55% | Training loss: 0.6871358801960474
Epoch: 52 | Iteration number: [2540/4518] 56% | Training loss: 0.6871353790046661
Epoch: 52 | Iteration number: [2550/4518] 56% | Training loss: 0.6871338453947329
Epoch: 52 | Iteration number: [2560/4518] 56% | Training loss: 0.6871304349740968
Epoch: 52 | Iteration number: [2570/4518] 56% | Training loss: 0.687131135241067
Epoch: 52 | Iteration number: [2580/4518] 57% | Training loss: 0.687131000466125
Epoch: 52 | Iteration number: [2590/4518] 57% | Training loss: 0.6871255788103494
Epoch: 52 | Iteration number: [2600/4518] 57% | Training loss: 0.6871227853114789
Epoch: 52 | Iteration number: [2610/4518] 57% | Training loss: 0.6871204220700537
Epoch: 52 | Iteration number: [2620/4518] 57% | Training loss: 0.6871173114722011
Epoch: 52 | Iteration number: [2630/4518] 58% | Training loss: 0.6871128010659163
Epoch: 52 | Iteration number: [2640/4518] 58% | Training loss: 0.6871182524345137
Epoch: 52 | Iteration number: [2650/4518] 58% | Training loss: 0.687114764339519
Epoch: 52 | Iteration number: [2660/4518] 58% | Training loss: 0.6871110900228184
Epoch: 52 | Iteration number: [2670/4518] 59% | Training loss: 0.6871103962708949
Epoch: 52 | Iteration number: [2680/4518] 59% | Training loss: 0.6871154009851057
Epoch: 52 | Iteration number: [2690/4518] 59% | Training loss: 0.687111542038758
Epoch: 52 | Iteration number: [2700/4518] 59% | Training loss: 0.6871083145450663
Epoch: 52 | Iteration number: [2710/4518] 59% | Training loss: 0.68710903045876
Epoch: 52 | Iteration number: [2720/4518] 60% | Training loss: 0.6871097373173517
Epoch: 52 | Iteration number: [2730/4518] 60% | Training loss: 0.6871096573251507
Epoch: 52 | Iteration number: [2740/4518] 60% | Training loss: 0.6871097730241553
Epoch: 52 | Iteration number: [2750/4518] 60% | Training loss: 0.6871061700257388
Epoch: 52 | Iteration number: [2760/4518] 61% | Training loss: 0.6871062365778978
Epoch: 52 | Iteration number: [2770/4518] 61% | Training loss: 0.6870981938787316
Epoch: 52 | Iteration number: [2780/4518] 61% | Training loss: 0.6870907067823753
Epoch: 52 | Iteration number: [2790/4518] 61% | Training loss: 0.6870901009728831
Epoch: 52 | Iteration number: [2800/4518] 61% | Training loss: 0.6870876084480967
Epoch: 52 | Iteration number: [2810/4518] 62% | Training loss: 0.6870879054069519
Epoch: 52 | Iteration number: [2820/4518] 62% | Training loss: 0.6870903546928514
Epoch: 52 | Iteration number: [2830/4518] 62% | Training loss: 0.6870919430424384
Epoch: 52 | Iteration number: [2840/4518] 62% | Training loss: 0.6870924459796556
Epoch: 52 | Iteration number: [2850/4518] 63% | Training loss: 0.687090462404385
Epoch: 52 | Iteration number: [2860/4518] 63% | Training loss: 0.6870866785099456
Epoch: 52 | Iteration number: [2870/4518] 63% | Training loss: 0.6870856722265171
Epoch: 52 | Iteration number: [2880/4518] 63% | Training loss: 0.6870851528727346
Epoch: 52 | Iteration number: [2890/4518] 63% | Training loss: 0.6870842897355762
Epoch: 52 | Iteration number: [2900/4518] 64% | Training loss: 0.6870837398233085
Epoch: 52 | Iteration number: [2910/4518] 64% | Training loss: 0.6870810002600615
Epoch: 52 | Iteration number: [2920/4518] 64% | Training loss: 0.6870837343678082
Epoch: 52 | Iteration number: [2930/4518] 64% | Training loss: 0.6870855172746417
Epoch: 52 | Iteration number: [2940/4518] 65% | Training loss: 0.6870846791332271
Epoch: 52 | Iteration number: [2950/4518] 65% | Training loss: 0.6870857128248377
Epoch: 52 | Iteration number: [2960/4518] 65% | Training loss: 0.6870868586406514
Epoch: 52 | Iteration number: [2970/4518] 65% | Training loss: 0.6870805360853471
Epoch: 52 | Iteration number: [2980/4518] 65% | Training loss: 0.6870801731644061
Epoch: 52 | Iteration number: [2990/4518] 66% | Training loss: 0.6870795262497803
Epoch: 52 | Iteration number: [3000/4518] 66% | Training loss: 0.6870794415473938
Epoch: 52 | Iteration number: [3010/4518] 66% | Training loss: 0.6870810916257459
Epoch: 52 | Iteration number: [3020/4518] 66% | Training loss: 0.6870785512868932
Epoch: 52 | Iteration number: [3030/4518] 67% | Training loss: 0.6870737817027781
Epoch: 52 | Iteration number: [3040/4518] 67% | Training loss: 0.6870705128304269
Epoch: 52 | Iteration number: [3050/4518] 67% | Training loss: 0.6870688437047552
Epoch: 52 | Iteration number: [3060/4518] 67% | Training loss: 0.6870727289346309
Epoch: 52 | Iteration number: [3070/4518] 67% | Training loss: 0.6870717783898407
Epoch: 52 | Iteration number: [3080/4518] 68% | Training loss: 0.6870718367301024
Epoch: 52 | Iteration number: [3090/4518] 68% | Training loss: 0.6870681700390133
Epoch: 52 | Iteration number: [3100/4518] 68% | Training loss: 0.6870663821504962
Epoch: 52 | Iteration number: [3110/4518] 68% | Training loss: 0.6870646603812742
Epoch: 52 | Iteration number: [3120/4518] 69% | Training loss: 0.6870642208136045
Epoch: 52 | Iteration number: [3130/4518] 69% | Training loss: 0.6870638010981746
Epoch: 52 | Iteration number: [3140/4518] 69% | Training loss: 0.6870645908223596
Epoch: 52 | Iteration number: [3150/4518] 69% | Training loss: 0.687060157912118
Epoch: 52 | Iteration number: [3160/4518] 69% | Training loss: 0.6870557336490366
Epoch: 52 | Iteration number: [3170/4518] 70% | Training loss: 0.6870509841276644
Epoch: 52 | Iteration number: [3180/4518] 70% | Training loss: 0.6870520535130171
Epoch: 52 | Iteration number: [3190/4518] 70% | Training loss: 0.6870542386108806
Epoch: 52 | Iteration number: [3200/4518] 70% | Training loss: 0.6870560298115015
Epoch: 52 | Iteration number: [3210/4518] 71% | Training loss: 0.6870565967396413
Epoch: 52 | Iteration number: [3220/4518] 71% | Training loss: 0.6870568288038976
Epoch: 52 | Iteration number: [3230/4518] 71% | Training loss: 0.6870560494000698
Epoch: 52 | Iteration number: [3240/4518] 71% | Training loss: 0.6870520253240326
Epoch: 52 | Iteration number: [3250/4518] 71% | Training loss: 0.6870484853341029
Epoch: 52 | Iteration number: [3260/4518] 72% | Training loss: 0.6870467380877653
Epoch: 52 | Iteration number: [3270/4518] 72% | Training loss: 0.6870405940834535
Epoch: 52 | Iteration number: [3280/4518] 72% | Training loss: 0.687033446042276
Epoch: 52 | Iteration number: [3290/4518] 72% | Training loss: 0.6870320896971914
Epoch: 52 | Iteration number: [3300/4518] 73% | Training loss: 0.6870300603454763
Epoch: 52 | Iteration number: [3310/4518] 73% | Training loss: 0.6870311376011263
Epoch: 52 | Iteration number: [3320/4518] 73% | Training loss: 0.687027757480202
Epoch: 52 | Iteration number: [3330/4518] 73% | Training loss: 0.6870278104826495
Epoch: 52 | Iteration number: [3340/4518] 73% | Training loss: 0.6870261020824581
Epoch: 52 | Iteration number: [3350/4518] 74% | Training loss: 0.6870228173483663
Epoch: 52 | Iteration number: [3360/4518] 74% | Training loss: 0.6870254347189552
Epoch: 52 | Iteration number: [3370/4518] 74% | Training loss: 0.6870280768644916
Epoch: 52 | Iteration number: [3380/4518] 74% | Training loss: 0.6870275069094268
Epoch: 52 | Iteration number: [3390/4518] 75% | Training loss: 0.6870280237851945
Epoch: 52 | Iteration number: [3400/4518] 75% | Training loss: 0.6870254764662069
Epoch: 52 | Iteration number: [3410/4518] 75% | Training loss: 0.6870203609865082
Epoch: 52 | Iteration number: [3420/4518] 75% | Training loss: 0.6870187800530104
Epoch: 52 | Iteration number: [3430/4518] 75% | Training loss: 0.6870225416501826
Epoch: 52 | Iteration number: [3440/4518] 76% | Training loss: 0.6870198807744092
Epoch: 52 | Iteration number: [3450/4518] 76% | Training loss: 0.6870196423323258
Epoch: 52 | Iteration number: [3460/4518] 76% | Training loss: 0.6870188743565124
Epoch: 52 | Iteration number: [3470/4518] 76% | Training loss: 0.6870136181627983
Epoch: 52 | Iteration number: [3480/4518] 77% | Training loss: 0.6870099892732741
Epoch: 52 | Iteration number: [3490/4518] 77% | Training loss: 0.6870138297962254
Epoch: 52 | Iteration number: [3500/4518] 77% | Training loss: 0.6870132045064654
Epoch: 52 | Iteration number: [3510/4518] 77% | Training loss: 0.6870174104331905
Epoch: 52 | Iteration number: [3520/4518] 77% | Training loss: 0.6870172619142315
Epoch: 52 | Iteration number: [3530/4518] 78% | Training loss: 0.687011573638862
Epoch: 52 | Iteration number: [3540/4518] 78% | Training loss: 0.6870118414951583
Epoch: 52 | Iteration number: [3550/4518] 78% | Training loss: 0.6870122137204022
Epoch: 52 | Iteration number: [3560/4518] 78% | Training loss: 0.6870076413234968
Epoch: 52 | Iteration number: [3570/4518] 79% | Training loss: 0.6870079693840999
Epoch: 52 | Iteration number: [3580/4518] 79% | Training loss: 0.6870068262076244
Epoch: 52 | Iteration number: [3590/4518] 79% | Training loss: 0.6870075369777786
Epoch: 52 | Iteration number: [3600/4518] 79% | Training loss: 0.6870033130546411
Epoch: 52 | Iteration number: [3610/4518] 79% | Training loss: 0.6870045740023214
Epoch: 52 | Iteration number: [3620/4518] 80% | Training loss: 0.687002909529275
Epoch: 52 | Iteration number: [3630/4518] 80% | Training loss: 0.6870010068758132
Epoch: 52 | Iteration number: [3640/4518] 80% | Training loss: 0.68700022651599
Epoch: 52 | Iteration number: [3650/4518] 80% | Training loss: 0.6870004838460112
Epoch: 52 | Iteration number: [3660/4518] 81% | Training loss: 0.6869988667671798
Epoch: 52 | Iteration number: [3670/4518] 81% | Training loss: 0.6869963770016663
Epoch: 52 | Iteration number: [3680/4518] 81% | Training loss: 0.686995578346693
Epoch: 52 | Iteration number: [3690/4518] 81% | Training loss: 0.6869960863738849
Epoch: 52 | Iteration number: [3700/4518] 81% | Training loss: 0.6869928802509565
Epoch: 52 | Iteration number: [3710/4518] 82% | Training loss: 0.6869919591836853
Epoch: 52 | Iteration number: [3720/4518] 82% | Training loss: 0.6869910164866396
Epoch: 52 | Iteration number: [3730/4518] 82% | Training loss: 0.686989982629909
Epoch: 52 | Iteration number: [3740/4518] 82% | Training loss: 0.6869942165472929
Epoch: 52 | Iteration number: [3750/4518] 83% | Training loss: 0.686995254500707
Epoch: 52 | Iteration number: [3760/4518] 83% | Training loss: 0.6869936837002318
Epoch: 52 | Iteration number: [3770/4518] 83% | Training loss: 0.6869947331811769
Epoch: 52 | Iteration number: [3780/4518] 83% | Training loss: 0.6869961154208613
Epoch: 52 | Iteration number: [3790/4518] 83% | Training loss: 0.686992429696161
Epoch: 52 | Iteration number: [3800/4518] 84% | Training loss: 0.6869923366684663
Epoch: 52 | Iteration number: [3810/4518] 84% | Training loss: 0.6869905001378748
Epoch: 52 | Iteration number: [3820/4518] 84% | Training loss: 0.6869932534807015
Epoch: 52 | Iteration number: [3830/4518] 84% | Training loss: 0.6869896195420397
Epoch: 52 | Iteration number: [3840/4518] 84% | Training loss: 0.6869870706616591
Epoch: 52 | Iteration number: [3850/4518] 85% | Training loss: 0.6869842108503564
Epoch: 52 | Iteration number: [3860/4518] 85% | Training loss: 0.6869836966608472
Epoch: 52 | Iteration number: [3870/4518] 85% | Training loss: 0.6869852107778692
Epoch: 52 | Iteration number: [3880/4518] 85% | Training loss: 0.6869874053855533
Epoch: 52 | Iteration number: [3890/4518] 86% | Training loss: 0.6869829965281302
Epoch: 52 | Iteration number: [3900/4518] 86% | Training loss: 0.6869827433580007
Epoch: 52 | Iteration number: [3910/4518] 86% | Training loss: 0.6869854109671415
Epoch: 52 | Iteration number: [3920/4518] 86% | Training loss: 0.686986213998527
Epoch: 52 | Iteration number: [3930/4518] 86% | Training loss: 0.6869836751134645
Epoch: 52 | Iteration number: [3940/4518] 87% | Training loss: 0.6869828970299154
Epoch: 52 | Iteration number: [3950/4518] 87% | Training loss: 0.6869852597351316
Epoch: 52 | Iteration number: [3960/4518] 87% | Training loss: 0.6869852754353273
Epoch: 52 | Iteration number: [3970/4518] 87% | Training loss: 0.6869846604783229
Epoch: 52 | Iteration number: [3980/4518] 88% | Training loss: 0.6869821802605337
Epoch: 52 | Iteration number: [3990/4518] 88% | Training loss: 0.68698202674849
Epoch: 52 | Iteration number: [4000/4518] 88% | Training loss: 0.6869812670946122
Epoch: 52 | Iteration number: [4010/4518] 88% | Training loss: 0.6869822169033963
Epoch: 52 | Iteration number: [4020/4518] 88% | Training loss: 0.6869844131208771
Epoch: 52 | Iteration number: [4030/4518] 89% | Training loss: 0.686983995875413
Epoch: 52 | Iteration number: [4040/4518] 89% | Training loss: 0.6869813583127343
Epoch: 52 | Iteration number: [4050/4518] 89% | Training loss: 0.6869771967552326
Epoch: 52 | Iteration number: [4060/4518] 89% | Training loss: 0.6869787556637684
Epoch: 52 | Iteration number: [4070/4518] 90% | Training loss: 0.686974999857769
Epoch: 52 | Iteration number: [4080/4518] 90% | Training loss: 0.6869747691148637
Epoch: 52 | Iteration number: [4090/4518] 90% | Training loss: 0.6869759739173945
Epoch: 52 | Iteration number: [4100/4518] 90% | Training loss: 0.6869766157865524
Epoch: 52 | Iteration number: [4110/4518] 90% | Training loss: 0.686977847431698
Epoch: 52 | Iteration number: [4120/4518] 91% | Training loss: 0.6869789363111107
Epoch: 52 | Iteration number: [4130/4518] 91% | Training loss: 0.6869784577562503
Epoch: 52 | Iteration number: [4140/4518] 91% | Training loss: 0.6869804266138353
Epoch: 52 | Iteration number: [4150/4518] 91% | Training loss: 0.6869801876200251
Epoch: 52 | Iteration number: [4160/4518] 92% | Training loss: 0.6869797684968664
Epoch: 52 | Iteration number: [4170/4518] 92% | Training loss: 0.6869790803757218
Epoch: 52 | Iteration number: [4180/4518] 92% | Training loss: 0.6869796199233908
Epoch: 52 | Iteration number: [4190/4518] 92% | Training loss: 0.6869814931350562
Epoch: 52 | Iteration number: [4200/4518] 92% | Training loss: 0.6869826764294079
Epoch: 52 | Iteration number: [4210/4518] 93% | Training loss: 0.6869806958349187
Epoch: 52 | Iteration number: [4220/4518] 93% | Training loss: 0.6869798772566691
Epoch: 52 | Iteration number: [4230/4518] 93% | Training loss: 0.6869790201914225
Epoch: 52 | Iteration number: [4240/4518] 93% | Training loss: 0.6869773333083908
Epoch: 52 | Iteration number: [4250/4518] 94% | Training loss: 0.6869784440433278
Epoch: 52 | Iteration number: [4260/4518] 94% | Training loss: 0.6869782642579414
Epoch: 52 | Iteration number: [4270/4518] 94% | Training loss: 0.6869780032081961
Epoch: 52 | Iteration number: [4280/4518] 94% | Training loss: 0.6869745188645113
Epoch: 52 | Iteration number: [4290/4518] 94% | Training loss: 0.6869754208551421
Epoch: 52 | Iteration number: [4300/4518] 95% | Training loss: 0.6869755662180657
Epoch: 52 | Iteration number: [4310/4518] 95% | Training loss: 0.6869736846666048
Epoch: 52 | Iteration number: [4320/4518] 95% | Training loss: 0.6869723283996184
Epoch: 52 | Iteration number: [4330/4518] 95% | Training loss: 0.686972840567384
Epoch: 52 | Iteration number: [4340/4518] 96% | Training loss: 0.6869705980686548
Epoch: 52 | Iteration number: [4350/4518] 96% | Training loss: 0.6869671866400489
Epoch: 52 | Iteration number: [4360/4518] 96% | Training loss: 0.6869677742413425
Epoch: 52 | Iteration number: [4370/4518] 96% | Training loss: 0.6869686535212214
Epoch: 52 | Iteration number: [4380/4518] 96% | Training loss: 0.6869668208436879
Epoch: 52 | Iteration number: [4390/4518] 97% | Training loss: 0.6869671396894172
Epoch: 52 | Iteration number: [4400/4518] 97% | Training loss: 0.6869669953259555
Epoch: 52 | Iteration number: [4410/4518] 97% | Training loss: 0.6869689461730776
Epoch: 52 | Iteration number: [4420/4518] 97% | Training loss: 0.6869674154266513
Epoch: 52 | Iteration number: [4430/4518] 98% | Training loss: 0.6869656510062465
Epoch: 52 | Iteration number: [4440/4518] 98% | Training loss: 0.6869643844596974
Epoch: 52 | Iteration number: [4450/4518] 98% | Training loss: 0.6869640411419815
Epoch: 52 | Iteration number: [4460/4518] 98% | Training loss: 0.6869652573303257
Epoch: 52 | Iteration number: [4470/4518] 98% | Training loss: 0.6869644437593635
Epoch: 52 | Iteration number: [4480/4518] 99% | Training loss: 0.6869634764801179
Epoch: 52 | Iteration number: [4490/4518] 99% | Training loss: 0.6869621612845126
Epoch: 52 | Iteration number: [4500/4518] 99% | Training loss: 0.6869617807600233
Epoch: 52 | Iteration number: [4510/4518] 99% | Training loss: 0.6869610593879302

 End of epoch: 52 | Train Loss: 0.6868097865908691 | Training Time: 640 

 End of epoch: 52 | Eval Loss: 0.68994525257422 | Evaluating Time: 17 
Epoch: 53 | Iteration number: [10/4518] 0% | Training loss: 0.7554518222808838
Epoch: 53 | Iteration number: [20/4518] 0% | Training loss: 0.7207750916481018
Epoch: 53 | Iteration number: [30/4518] 0% | Training loss: 0.7092521409193675
Epoch: 53 | Iteration number: [40/4518] 0% | Training loss: 0.70380669683218
Epoch: 53 | Iteration number: [50/4518] 1% | Training loss: 0.7004835486412049
Epoch: 53 | Iteration number: [60/4518] 1% | Training loss: 0.6982255796591441
Epoch: 53 | Iteration number: [70/4518] 1% | Training loss: 0.6966200530529022
Epoch: 53 | Iteration number: [80/4518] 1% | Training loss: 0.6954775646328926
Epoch: 53 | Iteration number: [90/4518] 1% | Training loss: 0.6944828318225013
Epoch: 53 | Iteration number: [100/4518] 2% | Training loss: 0.6937969940900802
Epoch: 53 | Iteration number: [110/4518] 2% | Training loss: 0.6931325587359342
Epoch: 53 | Iteration number: [120/4518] 2% | Training loss: 0.692575549085935
Epoch: 53 | Iteration number: [130/4518] 2% | Training loss: 0.6921296986249778
Epoch: 53 | Iteration number: [140/4518] 3% | Training loss: 0.6917628458568028
Epoch: 53 | Iteration number: [150/4518] 3% | Training loss: 0.6913961084683736
Epoch: 53 | Iteration number: [160/4518] 3% | Training loss: 0.6911303922533989
Epoch: 53 | Iteration number: [170/4518] 3% | Training loss: 0.6909668740104227
Epoch: 53 | Iteration number: [180/4518] 3% | Training loss: 0.6906841781404284
Epoch: 53 | Iteration number: [190/4518] 4% | Training loss: 0.6904768837125678
Epoch: 53 | Iteration number: [200/4518] 4% | Training loss: 0.6902487757802009
Epoch: 53 | Iteration number: [210/4518] 4% | Training loss: 0.6900723130930038
Epoch: 53 | Iteration number: [220/4518] 4% | Training loss: 0.6898909883065657
Epoch: 53 | Iteration number: [230/4518] 5% | Training loss: 0.6897436180840368
Epoch: 53 | Iteration number: [240/4518] 5% | Training loss: 0.68964820454518
Epoch: 53 | Iteration number: [250/4518] 5% | Training loss: 0.6895340323448181
Epoch: 53 | Iteration number: [260/4518] 5% | Training loss: 0.6894124780709927
Epoch: 53 | Iteration number: [270/4518] 5% | Training loss: 0.6893080011562065
Epoch: 53 | Iteration number: [280/4518] 6% | Training loss: 0.6892292957220759
Epoch: 53 | Iteration number: [290/4518] 6% | Training loss: 0.6891651737278905
Epoch: 53 | Iteration number: [300/4518] 6% | Training loss: 0.6890996026992798
Epoch: 53 | Iteration number: [310/4518] 6% | Training loss: 0.6890043235594226
Epoch: 53 | Iteration number: [320/4518] 7% | Training loss: 0.6889348797500133
Epoch: 53 | Iteration number: [330/4518] 7% | Training loss: 0.6888497757189201
Epoch: 53 | Iteration number: [340/4518] 7% | Training loss: 0.68880835035268
Epoch: 53 | Iteration number: [350/4518] 7% | Training loss: 0.6887639118943896
Epoch: 53 | Iteration number: [360/4518] 7% | Training loss: 0.68873327622811
Epoch: 53 | Iteration number: [370/4518] 8% | Training loss: 0.6886883867753518
Epoch: 53 | Iteration number: [380/4518] 8% | Training loss: 0.6886099660082867
Epoch: 53 | Iteration number: [390/4518] 8% | Training loss: 0.6886077790688245
Epoch: 53 | Iteration number: [400/4518] 8% | Training loss: 0.6885524059832097
Epoch: 53 | Iteration number: [410/4518] 9% | Training loss: 0.6884965012713177
Epoch: 53 | Iteration number: [420/4518] 9% | Training loss: 0.6884631855147225
Epoch: 53 | Iteration number: [430/4518] 9% | Training loss: 0.6884535388891087
Epoch: 53 | Iteration number: [440/4518] 9% | Training loss: 0.6884431347250939
Epoch: 53 | Iteration number: [450/4518] 9% | Training loss: 0.6884080749087863
Epoch: 53 | Iteration number: [460/4518] 10% | Training loss: 0.688398971894513
Epoch: 53 | Iteration number: [470/4518] 10% | Training loss: 0.688367556003814
Epoch: 53 | Iteration number: [480/4518] 10% | Training loss: 0.6883528529355923
Epoch: 53 | Iteration number: [490/4518] 10% | Training loss: 0.6883055981324644
Epoch: 53 | Iteration number: [500/4518] 11% | Training loss: 0.6882814223766327
Epoch: 53 | Iteration number: [510/4518] 11% | Training loss: 0.6882602773460688
Epoch: 53 | Iteration number: [520/4518] 11% | Training loss: 0.6882175667927816
Epoch: 53 | Iteration number: [530/4518] 11% | Training loss: 0.6881793541728326
Epoch: 53 | Iteration number: [540/4518] 11% | Training loss: 0.688150222102801
Epoch: 53 | Iteration number: [550/4518] 12% | Training loss: 0.6881609033454549
Epoch: 53 | Iteration number: [560/4518] 12% | Training loss: 0.6881430990993976
Epoch: 53 | Iteration number: [570/4518] 12% | Training loss: 0.6881016946675484
Epoch: 53 | Iteration number: [580/4518] 12% | Training loss: 0.6880694279382968
Epoch: 53 | Iteration number: [590/4518] 13% | Training loss: 0.6880444591328249
Epoch: 53 | Iteration number: [600/4518] 13% | Training loss: 0.6880235174298286
Epoch: 53 | Iteration number: [610/4518] 13% | Training loss: 0.6880016822306836
Epoch: 53 | Iteration number: [620/4518] 13% | Training loss: 0.6879670121977406
Epoch: 53 | Iteration number: [630/4518] 13% | Training loss: 0.6879433652711293
Epoch: 53 | Iteration number: [640/4518] 14% | Training loss: 0.6879232068546116
Epoch: 53 | Iteration number: [650/4518] 14% | Training loss: 0.6878972658744225
Epoch: 53 | Iteration number: [660/4518] 14% | Training loss: 0.6878851267424497
Epoch: 53 | Iteration number: [670/4518] 14% | Training loss: 0.6878689046226331
Epoch: 53 | Iteration number: [680/4518] 15% | Training loss: 0.6878513223108124
Epoch: 53 | Iteration number: [690/4518] 15% | Training loss: 0.6878356189831444
Epoch: 53 | Iteration number: [700/4518] 15% | Training loss: 0.6878208491631916
Epoch: 53 | Iteration number: [710/4518] 15% | Training loss: 0.6878140222858375
Epoch: 53 | Iteration number: [720/4518] 15% | Training loss: 0.6877985087533792
Epoch: 53 | Iteration number: [730/4518] 16% | Training loss: 0.6877835431327558
Epoch: 53 | Iteration number: [740/4518] 16% | Training loss: 0.6877690328939541
Epoch: 53 | Iteration number: [750/4518] 16% | Training loss: 0.6877571679751078
Epoch: 53 | Iteration number: [760/4518] 16% | Training loss: 0.6877514267438336
Epoch: 53 | Iteration number: [770/4518] 17% | Training loss: 0.6877479671657859
Epoch: 53 | Iteration number: [780/4518] 17% | Training loss: 0.6877477315755991
Epoch: 53 | Iteration number: [790/4518] 17% | Training loss: 0.6877277829979039
Epoch: 53 | Iteration number: [800/4518] 17% | Training loss: 0.6877042850106955
Epoch: 53 | Iteration number: [810/4518] 17% | Training loss: 0.6876966289532037
Epoch: 53 | Iteration number: [820/4518] 18% | Training loss: 0.6876905336612609
Epoch: 53 | Iteration number: [830/4518] 18% | Training loss: 0.6876713033182075
Epoch: 53 | Iteration number: [840/4518] 18% | Training loss: 0.6876570641284897
Epoch: 53 | Iteration number: [850/4518] 18% | Training loss: 0.6876539881790386
Epoch: 53 | Iteration number: [860/4518] 19% | Training loss: 0.6876513217077699
Epoch: 53 | Iteration number: [870/4518] 19% | Training loss: 0.6876420208777504
Epoch: 53 | Iteration number: [880/4518] 19% | Training loss: 0.6876554666595025
Epoch: 53 | Iteration number: [890/4518] 19% | Training loss: 0.6876365716537732
Epoch: 53 | Iteration number: [900/4518] 19% | Training loss: 0.687621948255433
Epoch: 53 | Iteration number: [910/4518] 20% | Training loss: 0.6876012492965866
Epoch: 53 | Iteration number: [920/4518] 20% | Training loss: 0.6876031420800996
Epoch: 53 | Iteration number: [930/4518] 20% | Training loss: 0.6875909705315867
Epoch: 53 | Iteration number: [940/4518] 20% | Training loss: 0.6875701573300869
Epoch: 53 | Iteration number: [950/4518] 21% | Training loss: 0.687561912787588
Epoch: 53 | Iteration number: [960/4518] 21% | Training loss: 0.6875378971919417
Epoch: 53 | Iteration number: [970/4518] 21% | Training loss: 0.6875297974679888
Epoch: 53 | Iteration number: [980/4518] 21% | Training loss: 0.6875063017314794
Epoch: 53 | Iteration number: [990/4518] 21% | Training loss: 0.6874838789906165
Epoch: 53 | Iteration number: [1000/4518] 22% | Training loss: 0.6874749943017959
Epoch: 53 | Iteration number: [1010/4518] 22% | Training loss: 0.6874633367108827
Epoch: 53 | Iteration number: [1020/4518] 22% | Training loss: 0.6874488993018282
Epoch: 53 | Iteration number: [1030/4518] 22% | Training loss: 0.6874336395448851
Epoch: 53 | Iteration number: [1040/4518] 23% | Training loss: 0.6874405452265189
Epoch: 53 | Iteration number: [1050/4518] 23% | Training loss: 0.6874315289088658
Epoch: 53 | Iteration number: [1060/4518] 23% | Training loss: 0.6874254245240733
Epoch: 53 | Iteration number: [1070/4518] 23% | Training loss: 0.6874187951333055
Epoch: 53 | Iteration number: [1080/4518] 23% | Training loss: 0.6874223106437259
Epoch: 53 | Iteration number: [1090/4518] 24% | Training loss: 0.6874156210947474
Epoch: 53 | Iteration number: [1100/4518] 24% | Training loss: 0.6874044140902432
Epoch: 53 | Iteration number: [1110/4518] 24% | Training loss: 0.6874011293187872
Epoch: 53 | Iteration number: [1120/4518] 24% | Training loss: 0.6873980078314031
Epoch: 53 | Iteration number: [1130/4518] 25% | Training loss: 0.6873984801558267
Epoch: 53 | Iteration number: [1140/4518] 25% | Training loss: 0.6873812564632349
Epoch: 53 | Iteration number: [1150/4518] 25% | Training loss: 0.6873803104006726
Epoch: 53 | Iteration number: [1160/4518] 25% | Training loss: 0.6873809969630734
Epoch: 53 | Iteration number: [1170/4518] 25% | Training loss: 0.6873732966235561
Epoch: 53 | Iteration number: [1180/4518] 26% | Training loss: 0.6873711445068909
Epoch: 53 | Iteration number: [1190/4518] 26% | Training loss: 0.6873550403017957
Epoch: 53 | Iteration number: [1200/4518] 26% | Training loss: 0.6873438907663028
Epoch: 53 | Iteration number: [1210/4518] 26% | Training loss: 0.6873471970893135
Epoch: 53 | Iteration number: [1220/4518] 27% | Training loss: 0.6873430036619061
Epoch: 53 | Iteration number: [1230/4518] 27% | Training loss: 0.6873405416806538
Epoch: 53 | Iteration number: [1240/4518] 27% | Training loss: 0.6873406680360917
Epoch: 53 | Iteration number: [1250/4518] 27% | Training loss: 0.6873517134189606
Epoch: 53 | Iteration number: [1260/4518] 27% | Training loss: 0.687352947535969
Epoch: 53 | Iteration number: [1270/4518] 28% | Training loss: 0.6873501124813801
Epoch: 53 | Iteration number: [1280/4518] 28% | Training loss: 0.6873467749450356
Epoch: 53 | Iteration number: [1290/4518] 28% | Training loss: 0.687341381736504
Epoch: 53 | Iteration number: [1300/4518] 28% | Training loss: 0.6873350266309884
Epoch: 53 | Iteration number: [1310/4518] 28% | Training loss: 0.6873285205309627
Epoch: 53 | Iteration number: [1320/4518] 29% | Training loss: 0.6873242470802683
Epoch: 53 | Iteration number: [1330/4518] 29% | Training loss: 0.6873182347842626
Epoch: 53 | Iteration number: [1340/4518] 29% | Training loss: 0.6873185143541934
Epoch: 53 | Iteration number: [1350/4518] 29% | Training loss: 0.6873151934588397
Epoch: 53 | Iteration number: [1360/4518] 30% | Training loss: 0.6873071197201224
Epoch: 53 | Iteration number: [1370/4518] 30% | Training loss: 0.687308852951022
Epoch: 53 | Iteration number: [1380/4518] 30% | Training loss: 0.687297248106072
Epoch: 53 | Iteration number: [1390/4518] 30% | Training loss: 0.6872840886922191
Epoch: 53 | Iteration number: [1400/4518] 30% | Training loss: 0.6872803340213639
Epoch: 53 | Iteration number: [1410/4518] 31% | Training loss: 0.6872879046920344
Epoch: 53 | Iteration number: [1420/4518] 31% | Training loss: 0.6872808393038494
Epoch: 53 | Iteration number: [1430/4518] 31% | Training loss: 0.6872813717885451
Epoch: 53 | Iteration number: [1440/4518] 31% | Training loss: 0.6872775987204578
Epoch: 53 | Iteration number: [1450/4518] 32% | Training loss: 0.6872668100636581
Epoch: 53 | Iteration number: [1460/4518] 32% | Training loss: 0.6872669101986166
Epoch: 53 | Iteration number: [1470/4518] 32% | Training loss: 0.6872745286039754
Epoch: 53 | Iteration number: [1480/4518] 32% | Training loss: 0.6872781101916288
Epoch: 53 | Iteration number: [1490/4518] 32% | Training loss: 0.6872703308227078
Epoch: 53 | Iteration number: [1500/4518] 33% | Training loss: 0.6872648136218389
Epoch: 53 | Iteration number: [1510/4518] 33% | Training loss: 0.6872557903757158
Epoch: 53 | Iteration number: [1520/4518] 33% | Training loss: 0.6872520083267438
Epoch: 53 | Iteration number: [1530/4518] 33% | Training loss: 0.6872443969732795
Epoch: 53 | Iteration number: [1540/4518] 34% | Training loss: 0.6872411631918572
Epoch: 53 | Iteration number: [1550/4518] 34% | Training loss: 0.6872373115247296
Epoch: 53 | Iteration number: [1560/4518] 34% | Training loss: 0.6872414345160509
Epoch: 53 | Iteration number: [1570/4518] 34% | Training loss: 0.6872443062484644
Epoch: 53 | Iteration number: [1580/4518] 34% | Training loss: 0.6872364049093633
Epoch: 53 | Iteration number: [1590/4518] 35% | Training loss: 0.6872295075242625
Epoch: 53 | Iteration number: [1600/4518] 35% | Training loss: 0.68722821213305
Epoch: 53 | Iteration number: [1610/4518] 35% | Training loss: 0.6872220852730437
Epoch: 53 | Iteration number: [1620/4518] 35% | Training loss: 0.6872254685855206
Epoch: 53 | Iteration number: [1630/4518] 36% | Training loss: 0.687222343573541
Epoch: 53 | Iteration number: [1640/4518] 36% | Training loss: 0.6872199136672951
Epoch: 53 | Iteration number: [1650/4518] 36% | Training loss: 0.6872104746283907
Epoch: 53 | Iteration number: [1660/4518] 36% | Training loss: 0.687214360502829
Epoch: 53 | Iteration number: [1670/4518] 36% | Training loss: 0.6872113153963032
Epoch: 53 | Iteration number: [1680/4518] 37% | Training loss: 0.6872138517598311
Epoch: 53 | Iteration number: [1690/4518] 37% | Training loss: 0.6872139702181844
Epoch: 53 | Iteration number: [1700/4518] 37% | Training loss: 0.6872161206077126
Epoch: 53 | Iteration number: [1710/4518] 37% | Training loss: 0.687209361268763
Epoch: 53 | Iteration number: [1720/4518] 38% | Training loss: 0.6872063243804976
Epoch: 53 | Iteration number: [1730/4518] 38% | Training loss: 0.6871999714071351
Epoch: 53 | Iteration number: [1740/4518] 38% | Training loss: 0.6871971249237828
Epoch: 53 | Iteration number: [1750/4518] 38% | Training loss: 0.687197889157704
Epoch: 53 | Iteration number: [1760/4518] 38% | Training loss: 0.6871974444186145
Epoch: 53 | Iteration number: [1770/4518] 39% | Training loss: 0.6871913788345574
Epoch: 53 | Iteration number: [1780/4518] 39% | Training loss: 0.687195319573531
Epoch: 53 | Iteration number: [1790/4518] 39% | Training loss: 0.6871943027946537
Epoch: 53 | Iteration number: [1800/4518] 39% | Training loss: 0.6871941200560994
Epoch: 53 | Iteration number: [1810/4518] 40% | Training loss: 0.6871894193617678
Epoch: 53 | Iteration number: [1820/4518] 40% | Training loss: 0.6871815719774791
Epoch: 53 | Iteration number: [1830/4518] 40% | Training loss: 0.6871815398091176
Epoch: 53 | Iteration number: [1840/4518] 40% | Training loss: 0.687184979248306
Epoch: 53 | Iteration number: [1850/4518] 40% | Training loss: 0.6871805180085672
Epoch: 53 | Iteration number: [1860/4518] 41% | Training loss: 0.687176610705673
Epoch: 53 | Iteration number: [1870/4518] 41% | Training loss: 0.6871785584936805
Epoch: 53 | Iteration number: [1880/4518] 41% | Training loss: 0.6871743875932186
Epoch: 53 | Iteration number: [1890/4518] 41% | Training loss: 0.6871744574377776
Epoch: 53 | Iteration number: [1900/4518] 42% | Training loss: 0.6871685226653752
Epoch: 53 | Iteration number: [1910/4518] 42% | Training loss: 0.6871705879091592
Epoch: 53 | Iteration number: [1920/4518] 42% | Training loss: 0.6871699227330585
Epoch: 53 | Iteration number: [1930/4518] 42% | Training loss: 0.6871627617376456
Epoch: 53 | Iteration number: [1940/4518] 42% | Training loss: 0.6871532073647706
Epoch: 53 | Iteration number: [1950/4518] 43% | Training loss: 0.6871528880107097
Epoch: 53 | Iteration number: [1960/4518] 43% | Training loss: 0.6871506021034961
Epoch: 53 | Iteration number: [1970/4518] 43% | Training loss: 0.6871472636757768
Epoch: 53 | Iteration number: [1980/4518] 43% | Training loss: 0.6871474526446275
Epoch: 53 | Iteration number: [1990/4518] 44% | Training loss: 0.6871457031324281
Epoch: 53 | Iteration number: [2000/4518] 44% | Training loss: 0.6871426258385182
Epoch: 53 | Iteration number: [2010/4518] 44% | Training loss: 0.687143022029554
Epoch: 53 | Iteration number: [2020/4518] 44% | Training loss: 0.6871442838765607
Epoch: 53 | Iteration number: [2030/4518] 44% | Training loss: 0.6871424265095754
Epoch: 53 | Iteration number: [2040/4518] 45% | Training loss: 0.6871387894539273
Epoch: 53 | Iteration number: [2050/4518] 45% | Training loss: 0.6871331753091114
Epoch: 53 | Iteration number: [2060/4518] 45% | Training loss: 0.687124053338199
Epoch: 53 | Iteration number: [2070/4518] 45% | Training loss: 0.6871253898754212
Epoch: 53 | Iteration number: [2080/4518] 46% | Training loss: 0.6871294248562593
Epoch: 53 | Iteration number: [2090/4518] 46% | Training loss: 0.6871249826330887
Epoch: 53 | Iteration number: [2100/4518] 46% | Training loss: 0.6871295482487906
Epoch: 53 | Iteration number: [2110/4518] 46% | Training loss: 0.6871273376365409
Epoch: 53 | Iteration number: [2120/4518] 46% | Training loss: 0.6871207511368788
Epoch: 53 | Iteration number: [2130/4518] 47% | Training loss: 0.6871175710304243
Epoch: 53 | Iteration number: [2140/4518] 47% | Training loss: 0.6871205251907634
Epoch: 53 | Iteration number: [2150/4518] 47% | Training loss: 0.6871247050928515
Epoch: 53 | Iteration number: [2160/4518] 47% | Training loss: 0.687122422594715
Epoch: 53 | Iteration number: [2170/4518] 48% | Training loss: 0.6871158001884338
Epoch: 53 | Iteration number: [2180/4518] 48% | Training loss: 0.6871083361566613
Epoch: 53 | Iteration number: [2190/4518] 48% | Training loss: 0.6871116068537377
Epoch: 53 | Iteration number: [2200/4518] 48% | Training loss: 0.6871155848015439
Epoch: 53 | Iteration number: [2210/4518] 48% | Training loss: 0.6871026823693271
Epoch: 53 | Iteration number: [2220/4518] 49% | Training loss: 0.6871064606819067
Epoch: 53 | Iteration number: [2230/4518] 49% | Training loss: 0.6871112700267757
Epoch: 53 | Iteration number: [2240/4518] 49% | Training loss: 0.6871079811028071
Epoch: 53 | Iteration number: [2250/4518] 49% | Training loss: 0.6871074826982286
Epoch: 53 | Iteration number: [2260/4518] 50% | Training loss: 0.6870992507027314
Epoch: 53 | Iteration number: [2270/4518] 50% | Training loss: 0.6871011119582054
Epoch: 53 | Iteration number: [2280/4518] 50% | Training loss: 0.6871026413482532
Epoch: 53 | Iteration number: [2290/4518] 50% | Training loss: 0.6871061497640402
Epoch: 53 | Iteration number: [2300/4518] 50% | Training loss: 0.6871029439957246
Epoch: 53 | Iteration number: [2310/4518] 51% | Training loss: 0.6871058421475547
Epoch: 53 | Iteration number: [2320/4518] 51% | Training loss: 0.687106619415612
Epoch: 53 | Iteration number: [2330/4518] 51% | Training loss: 0.6871014459706172
Epoch: 53 | Iteration number: [2340/4518] 51% | Training loss: 0.6871009190367837
Epoch: 53 | Iteration number: [2350/4518] 52% | Training loss: 0.6871018466543644
Epoch: 53 | Iteration number: [2360/4518] 52% | Training loss: 0.6871025848691746
Epoch: 53 | Iteration number: [2370/4518] 52% | Training loss: 0.6871001051699562
Epoch: 53 | Iteration number: [2380/4518] 52% | Training loss: 0.6870995051219684
Epoch: 53 | Iteration number: [2390/4518] 52% | Training loss: 0.687095127070798
Epoch: 53 | Iteration number: [2400/4518] 53% | Training loss: 0.6870915374904871
Epoch: 53 | Iteration number: [2410/4518] 53% | Training loss: 0.6870928748514642
Epoch: 53 | Iteration number: [2420/4518] 53% | Training loss: 0.6870918633031451
Epoch: 53 | Iteration number: [2430/4518] 53% | Training loss: 0.6870927297774656
Epoch: 53 | Iteration number: [2440/4518] 54% | Training loss: 0.6870932604934349
Epoch: 53 | Iteration number: [2450/4518] 54% | Training loss: 0.6870953593205432
Epoch: 53 | Iteration number: [2460/4518] 54% | Training loss: 0.6870929055582217
Epoch: 53 | Iteration number: [2470/4518] 54% | Training loss: 0.6870843894809846
Epoch: 53 | Iteration number: [2480/4518] 54% | Training loss: 0.687085150158213
Epoch: 53 | Iteration number: [2490/4518] 55% | Training loss: 0.6870836048241121
Epoch: 53 | Iteration number: [2500/4518] 55% | Training loss: 0.6870849949359894
Epoch: 53 | Iteration number: [2510/4518] 55% | Training loss: 0.6870844476963894
Epoch: 53 | Iteration number: [2520/4518] 55% | Training loss: 0.6870809478419168
Epoch: 53 | Iteration number: [2530/4518] 55% | Training loss: 0.6870834734128869
Epoch: 53 | Iteration number: [2540/4518] 56% | Training loss: 0.6870785682454823
Epoch: 53 | Iteration number: [2550/4518] 56% | Training loss: 0.6870767043384851
Epoch: 53 | Iteration number: [2560/4518] 56% | Training loss: 0.6870789501816035
Epoch: 53 | Iteration number: [2570/4518] 56% | Training loss: 0.6870722862765019
Epoch: 53 | Iteration number: [2580/4518] 57% | Training loss: 0.6870682796997617
Epoch: 53 | Iteration number: [2590/4518] 57% | Training loss: 0.6870678025092858
Epoch: 53 | Iteration number: [2600/4518] 57% | Training loss: 0.6870718873922641
Epoch: 53 | Iteration number: [2610/4518] 57% | Training loss: 0.6870726472344891
Epoch: 53 | Iteration number: [2620/4518] 57% | Training loss: 0.687068080993099
Epoch: 53 | Iteration number: [2630/4518] 58% | Training loss: 0.687069876543016
Epoch: 53 | Iteration number: [2640/4518] 58% | Training loss: 0.6870684929869392
Epoch: 53 | Iteration number: [2650/4518] 58% | Training loss: 0.6870690568663039
Epoch: 53 | Iteration number: [2660/4518] 58% | Training loss: 0.6870684573300799
Epoch: 53 | Iteration number: [2670/4518] 59% | Training loss: 0.6870650389890992
Epoch: 53 | Iteration number: [2680/4518] 59% | Training loss: 0.6870674705327446
Epoch: 53 | Iteration number: [2690/4518] 59% | Training loss: 0.6870680953711825
Epoch: 53 | Iteration number: [2700/4518] 59% | Training loss: 0.6870689885925364
Epoch: 53 | Iteration number: [2710/4518] 59% | Training loss: 0.6870671587896523
Epoch: 53 | Iteration number: [2720/4518] 60% | Training loss: 0.6870657868025934
Epoch: 53 | Iteration number: [2730/4518] 60% | Training loss: 0.6870617855599511
Epoch: 53 | Iteration number: [2740/4518] 60% | Training loss: 0.6870631720897925
Epoch: 53 | Iteration number: [2750/4518] 60% | Training loss: 0.6870663009773601
Epoch: 53 | Iteration number: [2760/4518] 61% | Training loss: 0.6870651716123457
Epoch: 53 | Iteration number: [2770/4518] 61% | Training loss: 0.687066783586564
Epoch: 53 | Iteration number: [2780/4518] 61% | Training loss: 0.6870660109485653
Epoch: 53 | Iteration number: [2790/4518] 61% | Training loss: 0.6870639930061969
Epoch: 53 | Iteration number: [2800/4518] 61% | Training loss: 0.6870586861670017
Epoch: 53 | Iteration number: [2810/4518] 62% | Training loss: 0.6870613880216864
Epoch: 53 | Iteration number: [2820/4518] 62% | Training loss: 0.6870616254442973
Epoch: 53 | Iteration number: [2830/4518] 62% | Training loss: 0.6870624480736129
Epoch: 53 | Iteration number: [2840/4518] 62% | Training loss: 0.6870614426866384
Epoch: 53 | Iteration number: [2850/4518] 63% | Training loss: 0.6870580136357692
Epoch: 53 | Iteration number: [2860/4518] 63% | Training loss: 0.6870561957567722
Epoch: 53 | Iteration number: [2870/4518] 63% | Training loss: 0.687053787770587
Epoch: 53 | Iteration number: [2880/4518] 63% | Training loss: 0.6870505847036839
Epoch: 53 | Iteration number: [2890/4518] 63% | Training loss: 0.6870546604522785
Epoch: 53 | Iteration number: [2900/4518] 64% | Training loss: 0.6870472855609039
Epoch: 53 | Iteration number: [2910/4518] 64% | Training loss: 0.6870482618661271
Epoch: 53 | Iteration number: [2920/4518] 64% | Training loss: 0.6870447092064439
Epoch: 53 | Iteration number: [2930/4518] 64% | Training loss: 0.6870428588203196
Epoch: 53 | Iteration number: [2940/4518] 65% | Training loss: 0.687042360849121
Epoch: 53 | Iteration number: [2950/4518] 65% | Training loss: 0.6870389575473332
Epoch: 53 | Iteration number: [2960/4518] 65% | Training loss: 0.6870351102303814
Epoch: 53 | Iteration number: [2970/4518] 65% | Training loss: 0.6870275275675135
Epoch: 53 | Iteration number: [2980/4518] 65% | Training loss: 0.6870282739400864
Epoch: 53 | Iteration number: [2990/4518] 66% | Training loss: 0.6870318481954045
Epoch: 53 | Iteration number: [3000/4518] 66% | Training loss: 0.6870327133337657
Epoch: 53 | Iteration number: [3010/4518] 66% | Training loss: 0.6870295221029326
Epoch: 53 | Iteration number: [3020/4518] 66% | Training loss: 0.6870301869531341
Epoch: 53 | Iteration number: [3030/4518] 67% | Training loss: 0.6870299689840562
Epoch: 53 | Iteration number: [3040/4518] 67% | Training loss: 0.6870313054832973
Epoch: 53 | Iteration number: [3050/4518] 67% | Training loss: 0.6870320415692251
Epoch: 53 | Iteration number: [3060/4518] 67% | Training loss: 0.687033317330616
Epoch: 53 | Iteration number: [3070/4518] 67% | Training loss: 0.6870349778802853
Epoch: 53 | Iteration number: [3080/4518] 68% | Training loss: 0.6870329910865077
Epoch: 53 | Iteration number: [3090/4518] 68% | Training loss: 0.6870346316049014
Epoch: 53 | Iteration number: [3100/4518] 68% | Training loss: 0.6870341105230393
Epoch: 53 | Iteration number: [3110/4518] 68% | Training loss: 0.6870324932877274
Epoch: 53 | Iteration number: [3120/4518] 69% | Training loss: 0.6870251324696418
Epoch: 53 | Iteration number: [3130/4518] 69% | Training loss: 0.6870238123800808
Epoch: 53 | Iteration number: [3140/4518] 69% | Training loss: 0.6870193826544816
Epoch: 53 | Iteration number: [3150/4518] 69% | Training loss: 0.6870165609745752
Epoch: 53 | Iteration number: [3160/4518] 69% | Training loss: 0.6870163021962854
Epoch: 53 | Iteration number: [3170/4518] 70% | Training loss: 0.6870111149192233
Epoch: 53 | Iteration number: [3180/4518] 70% | Training loss: 0.6870095232560199
Epoch: 53 | Iteration number: [3190/4518] 70% | Training loss: 0.6870122046306215
Epoch: 53 | Iteration number: [3200/4518] 70% | Training loss: 0.6870086765661836
Epoch: 53 | Iteration number: [3210/4518] 71% | Training loss: 0.6870054726474382
Epoch: 53 | Iteration number: [3220/4518] 71% | Training loss: 0.6870060153999684
Epoch: 53 | Iteration number: [3230/4518] 71% | Training loss: 0.6870054523642218
Epoch: 53 | Iteration number: [3240/4518] 71% | Training loss: 0.6870077902888074
Epoch: 53 | Iteration number: [3250/4518] 71% | Training loss: 0.6870061623866741
Epoch: 53 | Iteration number: [3260/4518] 72% | Training loss: 0.6870045122376249
Epoch: 53 | Iteration number: [3270/4518] 72% | Training loss: 0.6870045617632909
Epoch: 53 | Iteration number: [3280/4518] 72% | Training loss: 0.687004924856308
Epoch: 53 | Iteration number: [3290/4518] 72% | Training loss: 0.6870041068020563
Epoch: 53 | Iteration number: [3300/4518] 73% | Training loss: 0.6870039241422307
Epoch: 53 | Iteration number: [3310/4518] 73% | Training loss: 0.6870022838929629
Epoch: 53 | Iteration number: [3320/4518] 73% | Training loss: 0.6870025291500321
Epoch: 53 | Iteration number: [3330/4518] 73% | Training loss: 0.6870007768944577
Epoch: 53 | Iteration number: [3340/4518] 73% | Training loss: 0.6870023792553804
Epoch: 53 | Iteration number: [3350/4518] 74% | Training loss: 0.687002963592757
Epoch: 53 | Iteration number: [3360/4518] 74% | Training loss: 0.6870024770498275
Epoch: 53 | Iteration number: [3370/4518] 74% | Training loss: 0.6869988232231989
Epoch: 53 | Iteration number: [3380/4518] 74% | Training loss: 0.6869996777300299
Epoch: 53 | Iteration number: [3390/4518] 75% | Training loss: 0.6869968722703534
Epoch: 53 | Iteration number: [3400/4518] 75% | Training loss: 0.6869953169892816
Epoch: 53 | Iteration number: [3410/4518] 75% | Training loss: 0.6869961820739455
Epoch: 53 | Iteration number: [3420/4518] 75% | Training loss: 0.6869919732474444
Epoch: 53 | Iteration number: [3430/4518] 75% | Training loss: 0.6869909384855376
Epoch: 53 | Iteration number: [3440/4518] 76% | Training loss: 0.6869909267785937
Epoch: 53 | Iteration number: [3450/4518] 76% | Training loss: 0.6869901710835056
Epoch: 53 | Iteration number: [3460/4518] 76% | Training loss: 0.6869923537866228
Epoch: 53 | Iteration number: [3470/4518] 76% | Training loss: 0.6869945980801706
Epoch: 53 | Iteration number: [3480/4518] 77% | Training loss: 0.6870003519558359
Epoch: 53 | Iteration number: [3490/4518] 77% | Training loss: 0.6870000870145836
Epoch: 53 | Iteration number: [3500/4518] 77% | Training loss: 0.6870035548039845
Epoch: 53 | Iteration number: [3510/4518] 77% | Training loss: 0.68700236795295
Epoch: 53 | Iteration number: [3520/4518] 77% | Training loss: 0.6870044295760718
Epoch: 53 | Iteration number: [3530/4518] 78% | Training loss: 0.6870049592624643
Epoch: 53 | Iteration number: [3540/4518] 78% | Training loss: 0.687005964999145
Epoch: 53 | Iteration number: [3550/4518] 78% | Training loss: 0.687004928085166
Epoch: 53 | Iteration number: [3560/4518] 78% | Training loss: 0.6870040609595481
Epoch: 53 | Iteration number: [3570/4518] 79% | Training loss: 0.687005306225197
Epoch: 53 | Iteration number: [3580/4518] 79% | Training loss: 0.687007334595286
Epoch: 53 | Iteration number: [3590/4518] 79% | Training loss: 0.6870039464205421
Epoch: 53 | Iteration number: [3600/4518] 79% | Training loss: 0.6870049251119296
Epoch: 53 | Iteration number: [3610/4518] 79% | Training loss: 0.6870059148921861
Epoch: 53 | Iteration number: [3620/4518] 80% | Training loss: 0.6870032811527094
Epoch: 53 | Iteration number: [3630/4518] 80% | Training loss: 0.6870006730569624
Epoch: 53 | Iteration number: [3640/4518] 80% | Training loss: 0.6869993826681441
Epoch: 53 | Iteration number: [3650/4518] 80% | Training loss: 0.686999575520215
Epoch: 53 | Iteration number: [3660/4518] 81% | Training loss: 0.6869973057280473
Epoch: 53 | Iteration number: [3670/4518] 81% | Training loss: 0.6869972343016061
Epoch: 53 | Iteration number: [3680/4518] 81% | Training loss: 0.6869966019916793
Epoch: 53 | Iteration number: [3690/4518] 81% | Training loss: 0.6869978839304389
Epoch: 53 | Iteration number: [3700/4518] 81% | Training loss: 0.6869958058724532
Epoch: 53 | Iteration number: [3710/4518] 82% | Training loss: 0.6869967055931245
Epoch: 53 | Iteration number: [3720/4518] 82% | Training loss: 0.6870001785697476
Epoch: 53 | Iteration number: [3730/4518] 82% | Training loss: 0.6869989740305228
Epoch: 53 | Iteration number: [3740/4518] 82% | Training loss: 0.6869982400839342
Epoch: 53 | Iteration number: [3750/4518] 83% | Training loss: 0.6869914382139841
Epoch: 53 | Iteration number: [3760/4518] 83% | Training loss: 0.6869897230349956
Epoch: 53 | Iteration number: [3770/4518] 83% | Training loss: 0.686986497526776
Epoch: 53 | Iteration number: [3780/4518] 83% | Training loss: 0.6869852952225498
Epoch: 53 | Iteration number: [3790/4518] 83% | Training loss: 0.6869856461056933
Epoch: 53 | Iteration number: [3800/4518] 84% | Training loss: 0.6869859620144493
Epoch: 53 | Iteration number: [3810/4518] 84% | Training loss: 0.686982074857071
Epoch: 53 | Iteration number: [3820/4518] 84% | Training loss: 0.686987719127021
Epoch: 53 | Iteration number: [3830/4518] 84% | Training loss: 0.6869849884012038
Epoch: 53 | Iteration number: [3840/4518] 84% | Training loss: 0.6869865733819703
Epoch: 53 | Iteration number: [3850/4518] 85% | Training loss: 0.686987168618611
Epoch: 53 | Iteration number: [3860/4518] 85% | Training loss: 0.6869880536831723
Epoch: 53 | Iteration number: [3870/4518] 85% | Training loss: 0.6869867098115827
Epoch: 53 | Iteration number: [3880/4518] 85% | Training loss: 0.6869871305436203
Epoch: 53 | Iteration number: [3890/4518] 86% | Training loss: 0.686988442753152
Epoch: 53 | Iteration number: [3900/4518] 86% | Training loss: 0.6869885710722361
Epoch: 53 | Iteration number: [3910/4518] 86% | Training loss: 0.6869870002922195
Epoch: 53 | Iteration number: [3920/4518] 86% | Training loss: 0.6869887883565864
Epoch: 53 | Iteration number: [3930/4518] 86% | Training loss: 0.68698882098113
Epoch: 53 | Iteration number: [3940/4518] 87% | Training loss: 0.6869900870141644
Epoch: 53 | Iteration number: [3950/4518] 87% | Training loss: 0.686989706649056
Epoch: 53 | Iteration number: [3960/4518] 87% | Training loss: 0.6869907260091618
Epoch: 53 | Iteration number: [3970/4518] 87% | Training loss: 0.6869920682997187
Epoch: 53 | Iteration number: [3980/4518] 88% | Training loss: 0.686992595737903
Epoch: 53 | Iteration number: [3990/4518] 88% | Training loss: 0.6869902150672779
Epoch: 53 | Iteration number: [4000/4518] 88% | Training loss: 0.6869925916045904
Epoch: 53 | Iteration number: [4010/4518] 88% | Training loss: 0.6869909815508826
Epoch: 53 | Iteration number: [4020/4518] 88% | Training loss: 0.686992436588107
Epoch: 53 | Iteration number: [4030/4518] 89% | Training loss: 0.6869911489652345
Epoch: 53 | Iteration number: [4040/4518] 89% | Training loss: 0.6869922781934833
Epoch: 53 | Iteration number: [4050/4518] 89% | Training loss: 0.6869948894300578
Epoch: 53 | Iteration number: [4060/4518] 89% | Training loss: 0.6869901805382057
Epoch: 53 | Iteration number: [4070/4518] 90% | Training loss: 0.6869848148389296
Epoch: 53 | Iteration number: [4080/4518] 90% | Training loss: 0.6869822310466392
Epoch: 53 | Iteration number: [4090/4518] 90% | Training loss: 0.6869795043631696
Epoch: 53 | Iteration number: [4100/4518] 90% | Training loss: 0.6869766030805867
Epoch: 53 | Iteration number: [4110/4518] 90% | Training loss: 0.6869762574524195
Epoch: 53 | Iteration number: [4120/4518] 91% | Training loss: 0.6869754623296191
Epoch: 53 | Iteration number: [4130/4518] 91% | Training loss: 0.6869748761954089
Epoch: 53 | Iteration number: [4140/4518] 91% | Training loss: 0.6869800765445266
Epoch: 53 | Iteration number: [4150/4518] 91% | Training loss: 0.686980260165341
Epoch: 53 | Iteration number: [4160/4518] 92% | Training loss: 0.6869826916891795
Epoch: 53 | Iteration number: [4170/4518] 92% | Training loss: 0.6869814827430735
Epoch: 53 | Iteration number: [4180/4518] 92% | Training loss: 0.6869799270299063
Epoch: 53 | Iteration number: [4190/4518] 92% | Training loss: 0.6869782680543339
Epoch: 53 | Iteration number: [4200/4518] 92% | Training loss: 0.6869772919586726
Epoch: 53 | Iteration number: [4210/4518] 93% | Training loss: 0.6869758233888132
Epoch: 53 | Iteration number: [4220/4518] 93% | Training loss: 0.6869766575747757
Epoch: 53 | Iteration number: [4230/4518] 93% | Training loss: 0.6869759570481365
Epoch: 53 | Iteration number: [4240/4518] 93% | Training loss: 0.6869783218739167
Epoch: 53 | Iteration number: [4250/4518] 94% | Training loss: 0.6869770954917459
Epoch: 53 | Iteration number: [4260/4518] 94% | Training loss: 0.6869754068588427
Epoch: 53 | Iteration number: [4270/4518] 94% | Training loss: 0.686974032715277
Epoch: 53 | Iteration number: [4280/4518] 94% | Training loss: 0.6869712205272969
Epoch: 53 | Iteration number: [4290/4518] 94% | Training loss: 0.6869694044123162
Epoch: 53 | Iteration number: [4300/4518] 95% | Training loss: 0.6869698684437331
Epoch: 53 | Iteration number: [4310/4518] 95% | Training loss: 0.6869711818938465
Epoch: 53 | Iteration number: [4320/4518] 95% | Training loss: 0.6869707244827792
Epoch: 53 | Iteration number: [4330/4518] 95% | Training loss: 0.6869666562895301
Epoch: 53 | Iteration number: [4340/4518] 96% | Training loss: 0.6869691080349382
Epoch: 53 | Iteration number: [4350/4518] 96% | Training loss: 0.6869677129285089
Epoch: 53 | Iteration number: [4360/4518] 96% | Training loss: 0.6869659109399953
Epoch: 53 | Iteration number: [4370/4518] 96% | Training loss: 0.686965386763863
Epoch: 53 | Iteration number: [4380/4518] 96% | Training loss: 0.6869630470531716
Epoch: 53 | Iteration number: [4390/4518] 97% | Training loss: 0.6869616180590453
Epoch: 53 | Iteration number: [4400/4518] 97% | Training loss: 0.6869615768438035
Epoch: 53 | Iteration number: [4410/4518] 97% | Training loss: 0.6869630079555944
Epoch: 53 | Iteration number: [4420/4518] 97% | Training loss: 0.6869588962777168
Epoch: 53 | Iteration number: [4430/4518] 98% | Training loss: 0.6869561950051758
Epoch: 53 | Iteration number: [4440/4518] 98% | Training loss: 0.6869559264934815
Epoch: 53 | Iteration number: [4450/4518] 98% | Training loss: 0.6869565818684824
Epoch: 53 | Iteration number: [4460/4518] 98% | Training loss: 0.6869596306518589
Epoch: 53 | Iteration number: [4470/4518] 98% | Training loss: 0.6869569595361449
Epoch: 53 | Iteration number: [4480/4518] 99% | Training loss: 0.6869547507725656
Epoch: 53 | Iteration number: [4490/4518] 99% | Training loss: 0.6869576711298894
Epoch: 53 | Iteration number: [4500/4518] 99% | Training loss: 0.6869587822490268
Epoch: 53 | Iteration number: [4510/4518] 99% | Training loss: 0.6869585329043099

 End of epoch: 53 | Train Loss: 0.6868052784717943 | Training Time: 640 

 End of epoch: 53 | Eval Loss: 0.6899474226698583 | Evaluating Time: 17 
Epoch: 54 | Iteration number: [10/4518] 0% | Training loss: 0.7559063076972962
Epoch: 54 | Iteration number: [20/4518] 0% | Training loss: 0.7213970273733139
Epoch: 54 | Iteration number: [30/4518] 0% | Training loss: 0.7099253495534261
Epoch: 54 | Iteration number: [40/4518] 0% | Training loss: 0.7041248887777328
Epoch: 54 | Iteration number: [50/4518] 1% | Training loss: 0.70080002784729
Epoch: 54 | Iteration number: [60/4518] 1% | Training loss: 0.698336786031723
Epoch: 54 | Iteration number: [70/4518] 1% | Training loss: 0.69677802835192
Epoch: 54 | Iteration number: [80/4518] 1% | Training loss: 0.6954275809228421
Epoch: 54 | Iteration number: [90/4518] 1% | Training loss: 0.694538864824507
Epoch: 54 | Iteration number: [100/4518] 2% | Training loss: 0.6937448483705521
Epoch: 54 | Iteration number: [110/4518] 2% | Training loss: 0.6931014510718259
Epoch: 54 | Iteration number: [120/4518] 2% | Training loss: 0.6925116717815399
Epoch: 54 | Iteration number: [130/4518] 2% | Training loss: 0.6919760236373315
Epoch: 54 | Iteration number: [140/4518] 3% | Training loss: 0.6916097325938089
Epoch: 54 | Iteration number: [150/4518] 3% | Training loss: 0.6913427734375
Epoch: 54 | Iteration number: [160/4518] 3% | Training loss: 0.6911144625395537
Epoch: 54 | Iteration number: [170/4518] 3% | Training loss: 0.6908307759200826
Epoch: 54 | Iteration number: [180/4518] 3% | Training loss: 0.6906428313917584
Epoch: 54 | Iteration number: [190/4518] 4% | Training loss: 0.6904669143651662
Epoch: 54 | Iteration number: [200/4518] 4% | Training loss: 0.6903509420156478
Epoch: 54 | Iteration number: [210/4518] 4% | Training loss: 0.6901855565252758
Epoch: 54 | Iteration number: [220/4518] 4% | Training loss: 0.6900458731434562
Epoch: 54 | Iteration number: [230/4518] 5% | Training loss: 0.6898784243542215
Epoch: 54 | Iteration number: [240/4518] 5% | Training loss: 0.6897254166503747
Epoch: 54 | Iteration number: [250/4518] 5% | Training loss: 0.6896371173858643
Epoch: 54 | Iteration number: [260/4518] 5% | Training loss: 0.6895043022357501
Epoch: 54 | Iteration number: [270/4518] 5% | Training loss: 0.6894456938461021
Epoch: 54 | Iteration number: [280/4518] 6% | Training loss: 0.6893673792481423
Epoch: 54 | Iteration number: [290/4518] 6% | Training loss: 0.6892322433405909
Epoch: 54 | Iteration number: [300/4518] 6% | Training loss: 0.6891607509056727
Epoch: 54 | Iteration number: [310/4518] 6% | Training loss: 0.6890552605352094
Epoch: 54 | Iteration number: [320/4518] 7% | Training loss: 0.6889941392466425
Epoch: 54 | Iteration number: [330/4518] 7% | Training loss: 0.6889495800841938
Epoch: 54 | Iteration number: [340/4518] 7% | Training loss: 0.6888926465721691
Epoch: 54 | Iteration number: [350/4518] 7% | Training loss: 0.68880182828222
Epoch: 54 | Iteration number: [360/4518] 7% | Training loss: 0.6887513243489796
Epoch: 54 | Iteration number: [370/4518] 8% | Training loss: 0.6886803027745839
Epoch: 54 | Iteration number: [380/4518] 8% | Training loss: 0.6886238816537356
Epoch: 54 | Iteration number: [390/4518] 8% | Training loss: 0.6885515870192112
Epoch: 54 | Iteration number: [400/4518] 8% | Training loss: 0.6884931088984012
Epoch: 54 | Iteration number: [410/4518] 9% | Training loss: 0.6884548784756079
Epoch: 54 | Iteration number: [420/4518] 9% | Training loss: 0.6884446418001539
Epoch: 54 | Iteration number: [430/4518] 9% | Training loss: 0.6883971114491307
Epoch: 54 | Iteration number: [440/4518] 9% | Training loss: 0.6883417921987447
Epoch: 54 | Iteration number: [450/4518] 9% | Training loss: 0.6882833352353838
Epoch: 54 | Iteration number: [460/4518] 10% | Training loss: 0.6882330317860065
Epoch: 54 | Iteration number: [470/4518] 10% | Training loss: 0.6882061174575319
Epoch: 54 | Iteration number: [480/4518] 10% | Training loss: 0.6881671164184808
Epoch: 54 | Iteration number: [490/4518] 10% | Training loss: 0.6881331795332383
Epoch: 54 | Iteration number: [500/4518] 11% | Training loss: 0.6880990215539933
Epoch: 54 | Iteration number: [510/4518] 11% | Training loss: 0.6880943056415109
Epoch: 54 | Iteration number: [520/4518] 11% | Training loss: 0.6880722436767358
Epoch: 54 | Iteration number: [530/4518] 11% | Training loss: 0.6880199175960613
Epoch: 54 | Iteration number: [540/4518] 11% | Training loss: 0.6880167620049582
Epoch: 54 | Iteration number: [550/4518] 12% | Training loss: 0.6879970626397567
Epoch: 54 | Iteration number: [560/4518] 12% | Training loss: 0.6879595101944038
Epoch: 54 | Iteration number: [570/4518] 12% | Training loss: 0.6879384332581571
Epoch: 54 | Iteration number: [580/4518] 12% | Training loss: 0.6879212053685353
Epoch: 54 | Iteration number: [590/4518] 13% | Training loss: 0.6878881528215893
Epoch: 54 | Iteration number: [600/4518] 13% | Training loss: 0.6878546358148256
Epoch: 54 | Iteration number: [610/4518] 13% | Training loss: 0.6878399600748156
Epoch: 54 | Iteration number: [620/4518] 13% | Training loss: 0.6878276318311691
Epoch: 54 | Iteration number: [630/4518] 13% | Training loss: 0.6877828741830493
Epoch: 54 | Iteration number: [640/4518] 14% | Training loss: 0.68776885997504
Epoch: 54 | Iteration number: [650/4518] 14% | Training loss: 0.6877638709545135
Epoch: 54 | Iteration number: [660/4518] 14% | Training loss: 0.6877460072437922
Epoch: 54 | Iteration number: [670/4518] 14% | Training loss: 0.6877286219774787
Epoch: 54 | Iteration number: [680/4518] 15% | Training loss: 0.6876997994149432
Epoch: 54 | Iteration number: [690/4518] 15% | Training loss: 0.687676718701487
Epoch: 54 | Iteration number: [700/4518] 15% | Training loss: 0.6876754457609994
Epoch: 54 | Iteration number: [710/4518] 15% | Training loss: 0.6876760617108412
Epoch: 54 | Iteration number: [720/4518] 15% | Training loss: 0.6876601150466336
Epoch: 54 | Iteration number: [730/4518] 16% | Training loss: 0.6876525712339845
Epoch: 54 | Iteration number: [740/4518] 16% | Training loss: 0.6876454062558509
Epoch: 54 | Iteration number: [750/4518] 16% | Training loss: 0.6876275548934937
Epoch: 54 | Iteration number: [760/4518] 16% | Training loss: 0.6876180182946355
Epoch: 54 | Iteration number: [770/4518] 17% | Training loss: 0.6876072740399992
Epoch: 54 | Iteration number: [780/4518] 17% | Training loss: 0.6875796460188353
Epoch: 54 | Iteration number: [790/4518] 17% | Training loss: 0.6875864658174635
Epoch: 54 | Iteration number: [800/4518] 17% | Training loss: 0.6875780713558197
Epoch: 54 | Iteration number: [810/4518] 17% | Training loss: 0.6875714974638857
Epoch: 54 | Iteration number: [820/4518] 18% | Training loss: 0.6875712671657888
Epoch: 54 | Iteration number: [830/4518] 18% | Training loss: 0.6875774363437331
Epoch: 54 | Iteration number: [840/4518] 18% | Training loss: 0.6875798255914733
Epoch: 54 | Iteration number: [850/4518] 18% | Training loss: 0.6875673909748302
Epoch: 54 | Iteration number: [860/4518] 19% | Training loss: 0.6875693869452144
Epoch: 54 | Iteration number: [870/4518] 19% | Training loss: 0.6875771094327685
Epoch: 54 | Iteration number: [880/4518] 19% | Training loss: 0.6875775817443024
Epoch: 54 | Iteration number: [890/4518] 19% | Training loss: 0.6875709180081828
Epoch: 54 | Iteration number: [900/4518] 19% | Training loss: 0.6875659714142481
Epoch: 54 | Iteration number: [910/4518] 20% | Training loss: 0.6875386416257083
Epoch: 54 | Iteration number: [920/4518] 20% | Training loss: 0.6875289898203767
Epoch: 54 | Iteration number: [930/4518] 20% | Training loss: 0.6875252108420095
Epoch: 54 | Iteration number: [940/4518] 20% | Training loss: 0.6875088761461542
Epoch: 54 | Iteration number: [950/4518] 21% | Training loss: 0.6875024153684315
Epoch: 54 | Iteration number: [960/4518] 21% | Training loss: 0.6875101526578268
Epoch: 54 | Iteration number: [970/4518] 21% | Training loss: 0.687507000719149
Epoch: 54 | Iteration number: [980/4518] 21% | Training loss: 0.6875191566895466
Epoch: 54 | Iteration number: [990/4518] 21% | Training loss: 0.6875095269896767
Epoch: 54 | Iteration number: [1000/4518] 22% | Training loss: 0.6875128698945046
Epoch: 54 | Iteration number: [1010/4518] 22% | Training loss: 0.6874969363212585
Epoch: 54 | Iteration number: [1020/4518] 22% | Training loss: 0.6874892645022448
Epoch: 54 | Iteration number: [1030/4518] 22% | Training loss: 0.687483818380578
Epoch: 54 | Iteration number: [1040/4518] 23% | Training loss: 0.6874695917734733
Epoch: 54 | Iteration number: [1050/4518] 23% | Training loss: 0.6874576414199103
Epoch: 54 | Iteration number: [1060/4518] 23% | Training loss: 0.6874499574022473
Epoch: 54 | Iteration number: [1070/4518] 23% | Training loss: 0.6874428377530285
Epoch: 54 | Iteration number: [1080/4518] 23% | Training loss: 0.6874335773565151
Epoch: 54 | Iteration number: [1090/4518] 24% | Training loss: 0.68742322057759
Epoch: 54 | Iteration number: [1100/4518] 24% | Training loss: 0.6874160220406272
Epoch: 54 | Iteration number: [1110/4518] 24% | Training loss: 0.6874021096272511
Epoch: 54 | Iteration number: [1120/4518] 24% | Training loss: 0.6873941627464124
Epoch: 54 | Iteration number: [1130/4518] 25% | Training loss: 0.6873817722354315
Epoch: 54 | Iteration number: [1140/4518] 25% | Training loss: 0.6873772376462033
Epoch: 54 | Iteration number: [1150/4518] 25% | Training loss: 0.6873770699293718
Epoch: 54 | Iteration number: [1160/4518] 25% | Training loss: 0.6873773957634794
Epoch: 54 | Iteration number: [1170/4518] 25% | Training loss: 0.6873710774967813
Epoch: 54 | Iteration number: [1180/4518] 26% | Training loss: 0.6873699227126978
Epoch: 54 | Iteration number: [1190/4518] 26% | Training loss: 0.6873540288760882
Epoch: 54 | Iteration number: [1200/4518] 26% | Training loss: 0.6873543924093246
Epoch: 54 | Iteration number: [1210/4518] 26% | Training loss: 0.6873468992138697
Epoch: 54 | Iteration number: [1220/4518] 27% | Training loss: 0.6873315734941451
Epoch: 54 | Iteration number: [1230/4518] 27% | Training loss: 0.6873213869284808
Epoch: 54 | Iteration number: [1240/4518] 27% | Training loss: 0.6873101135896098
Epoch: 54 | Iteration number: [1250/4518] 27% | Training loss: 0.6873195594787598
Epoch: 54 | Iteration number: [1260/4518] 27% | Training loss: 0.6873153530416034
Epoch: 54 | Iteration number: [1270/4518] 28% | Training loss: 0.6873122374373158
Epoch: 54 | Iteration number: [1280/4518] 28% | Training loss: 0.6872963870409876
Epoch: 54 | Iteration number: [1290/4518] 28% | Training loss: 0.6872944902079974
Epoch: 54 | Iteration number: [1300/4518] 28% | Training loss: 0.6872919493913651
Epoch: 54 | Iteration number: [1310/4518] 28% | Training loss: 0.68729758644832
Epoch: 54 | Iteration number: [1320/4518] 29% | Training loss: 0.6872953610438289
Epoch: 54 | Iteration number: [1330/4518] 29% | Training loss: 0.6872874781601411
Epoch: 54 | Iteration number: [1340/4518] 29% | Training loss: 0.6872839513999313
Epoch: 54 | Iteration number: [1350/4518] 29% | Training loss: 0.6872704960240258
Epoch: 54 | Iteration number: [1360/4518] 30% | Training loss: 0.6872672956217738
Epoch: 54 | Iteration number: [1370/4518] 30% | Training loss: 0.6872634637094762
Epoch: 54 | Iteration number: [1380/4518] 30% | Training loss: 0.687255000161088
Epoch: 54 | Iteration number: [1390/4518] 30% | Training loss: 0.6872445939256133
Epoch: 54 | Iteration number: [1400/4518] 30% | Training loss: 0.6872425259011132
Epoch: 54 | Iteration number: [1410/4518] 31% | Training loss: 0.6872355795921163
Epoch: 54 | Iteration number: [1420/4518] 31% | Training loss: 0.6872384919666908
Epoch: 54 | Iteration number: [1430/4518] 31% | Training loss: 0.6872360914737194
Epoch: 54 | Iteration number: [1440/4518] 31% | Training loss: 0.6872362424102094
Epoch: 54 | Iteration number: [1450/4518] 32% | Training loss: 0.6872311548529
Epoch: 54 | Iteration number: [1460/4518] 32% | Training loss: 0.6872253011759013
Epoch: 54 | Iteration number: [1470/4518] 32% | Training loss: 0.6872275894596463
Epoch: 54 | Iteration number: [1480/4518] 32% | Training loss: 0.6872201698454651
Epoch: 54 | Iteration number: [1490/4518] 32% | Training loss: 0.6872197320397269
Epoch: 54 | Iteration number: [1500/4518] 33% | Training loss: 0.6872168107032776
Epoch: 54 | Iteration number: [1510/4518] 33% | Training loss: 0.6872116202550218
Epoch: 54 | Iteration number: [1520/4518] 33% | Training loss: 0.687206606566906
Epoch: 54 | Iteration number: [1530/4518] 33% | Training loss: 0.6871995827341392
Epoch: 54 | Iteration number: [1540/4518] 34% | Training loss: 0.6871994912237316
Epoch: 54 | Iteration number: [1550/4518] 34% | Training loss: 0.6872004022136812
Epoch: 54 | Iteration number: [1560/4518] 34% | Training loss: 0.6871981113767013
Epoch: 54 | Iteration number: [1570/4518] 34% | Training loss: 0.6871958340049549
Epoch: 54 | Iteration number: [1580/4518] 34% | Training loss: 0.6871947415267365
Epoch: 54 | Iteration number: [1590/4518] 35% | Training loss: 0.6871930083763674
Epoch: 54 | Iteration number: [1600/4518] 35% | Training loss: 0.6871968376263976
Epoch: 54 | Iteration number: [1610/4518] 35% | Training loss: 0.6871986779366961
Epoch: 54 | Iteration number: [1620/4518] 35% | Training loss: 0.687202427232707
Epoch: 54 | Iteration number: [1630/4518] 36% | Training loss: 0.6871964809719039
Epoch: 54 | Iteration number: [1640/4518] 36% | Training loss: 0.6872016181306141
Epoch: 54 | Iteration number: [1650/4518] 36% | Training loss: 0.6872022954261664
Epoch: 54 | Iteration number: [1660/4518] 36% | Training loss: 0.6872073281601251
Epoch: 54 | Iteration number: [1670/4518] 36% | Training loss: 0.687203621614479
Epoch: 54 | Iteration number: [1680/4518] 37% | Training loss: 0.6872021901465598
Epoch: 54 | Iteration number: [1690/4518] 37% | Training loss: 0.6871971682331266
Epoch: 54 | Iteration number: [1700/4518] 37% | Training loss: 0.687185385332388
Epoch: 54 | Iteration number: [1710/4518] 37% | Training loss: 0.6871858692657181
Epoch: 54 | Iteration number: [1720/4518] 38% | Training loss: 0.6871891456981037
Epoch: 54 | Iteration number: [1730/4518] 38% | Training loss: 0.6871867586422518
Epoch: 54 | Iteration number: [1740/4518] 38% | Training loss: 0.687176149466942
Epoch: 54 | Iteration number: [1750/4518] 38% | Training loss: 0.6871783051490784
Epoch: 54 | Iteration number: [1760/4518] 38% | Training loss: 0.6871731185438958
Epoch: 54 | Iteration number: [1770/4518] 39% | Training loss: 0.6871671447982896
Epoch: 54 | Iteration number: [1780/4518] 39% | Training loss: 0.687167710166299
Epoch: 54 | Iteration number: [1790/4518] 39% | Training loss: 0.6871768831873739
Epoch: 54 | Iteration number: [1800/4518] 39% | Training loss: 0.6871772673063808
Epoch: 54 | Iteration number: [1810/4518] 40% | Training loss: 0.6871761575258898
Epoch: 54 | Iteration number: [1820/4518] 40% | Training loss: 0.6871761633472129
Epoch: 54 | Iteration number: [1830/4518] 40% | Training loss: 0.6871772875877026
Epoch: 54 | Iteration number: [1840/4518] 40% | Training loss: 0.6871718964822914
Epoch: 54 | Iteration number: [1850/4518] 40% | Training loss: 0.6871635294604946
Epoch: 54 | Iteration number: [1860/4518] 41% | Training loss: 0.6871635028431492
Epoch: 54 | Iteration number: [1870/4518] 41% | Training loss: 0.6871556071355381
Epoch: 54 | Iteration number: [1880/4518] 41% | Training loss: 0.687156255860278
Epoch: 54 | Iteration number: [1890/4518] 41% | Training loss: 0.6871426308596575
Epoch: 54 | Iteration number: [1900/4518] 42% | Training loss: 0.6871320924947136
Epoch: 54 | Iteration number: [1910/4518] 42% | Training loss: 0.6871316855178453
Epoch: 54 | Iteration number: [1920/4518] 42% | Training loss: 0.6871307351936896
Epoch: 54 | Iteration number: [1930/4518] 42% | Training loss: 0.6871330192669686
Epoch: 54 | Iteration number: [1940/4518] 42% | Training loss: 0.6871295114460679
Epoch: 54 | Iteration number: [1950/4518] 43% | Training loss: 0.6871258704478924
Epoch: 54 | Iteration number: [1960/4518] 43% | Training loss: 0.687122349410641
Epoch: 54 | Iteration number: [1970/4518] 43% | Training loss: 0.6871196534427895
Epoch: 54 | Iteration number: [1980/4518] 43% | Training loss: 0.6871180456094067
Epoch: 54 | Iteration number: [1990/4518] 44% | Training loss: 0.6871123963564485
Epoch: 54 | Iteration number: [2000/4518] 44% | Training loss: 0.6871165509819984
Epoch: 54 | Iteration number: [2010/4518] 44% | Training loss: 0.68711753048707
Epoch: 54 | Iteration number: [2020/4518] 44% | Training loss: 0.6871149049241944
Epoch: 54 | Iteration number: [2030/4518] 44% | Training loss: 0.6871123429589671
Epoch: 54 | Iteration number: [2040/4518] 45% | Training loss: 0.6871094456782528
Epoch: 54 | Iteration number: [2050/4518] 45% | Training loss: 0.6871058637921403
Epoch: 54 | Iteration number: [2060/4518] 45% | Training loss: 0.6871006597882335
Epoch: 54 | Iteration number: [2070/4518] 45% | Training loss: 0.6870973749149248
Epoch: 54 | Iteration number: [2080/4518] 46% | Training loss: 0.6870885307972248
Epoch: 54 | Iteration number: [2090/4518] 46% | Training loss: 0.6870887565270566
Epoch: 54 | Iteration number: [2100/4518] 46% | Training loss: 0.6870876794485818
Epoch: 54 | Iteration number: [2110/4518] 46% | Training loss: 0.6870796830450754
Epoch: 54 | Iteration number: [2120/4518] 46% | Training loss: 0.6870824935020141
Epoch: 54 | Iteration number: [2130/4518] 47% | Training loss: 0.6870859423713505
Epoch: 54 | Iteration number: [2140/4518] 47% | Training loss: 0.6870898513593406
Epoch: 54 | Iteration number: [2150/4518] 47% | Training loss: 0.6870888493504635
Epoch: 54 | Iteration number: [2160/4518] 47% | Training loss: 0.6870918549597264
Epoch: 54 | Iteration number: [2170/4518] 48% | Training loss: 0.6870909030811029
Epoch: 54 | Iteration number: [2180/4518] 48% | Training loss: 0.687092884582117
Epoch: 54 | Iteration number: [2190/4518] 48% | Training loss: 0.6870953380245052
Epoch: 54 | Iteration number: [2200/4518] 48% | Training loss: 0.6870972955497828
Epoch: 54 | Iteration number: [2210/4518] 48% | Training loss: 0.6871035036188445
Epoch: 54 | Iteration number: [2220/4518] 49% | Training loss: 0.6871011393027263
Epoch: 54 | Iteration number: [2230/4518] 49% | Training loss: 0.6870955555161019
Epoch: 54 | Iteration number: [2240/4518] 49% | Training loss: 0.6870975206206952
Epoch: 54 | Iteration number: [2250/4518] 49% | Training loss: 0.6870991508165996
Epoch: 54 | Iteration number: [2260/4518] 50% | Training loss: 0.6870951115557578
Epoch: 54 | Iteration number: [2270/4518] 50% | Training loss: 0.6870988423341171
Epoch: 54 | Iteration number: [2280/4518] 50% | Training loss: 0.6870981969070016
Epoch: 54 | Iteration number: [2290/4518] 50% | Training loss: 0.6870997716766257
Epoch: 54 | Iteration number: [2300/4518] 50% | Training loss: 0.6871009077714837
Epoch: 54 | Iteration number: [2310/4518] 51% | Training loss: 0.6870953851447993
Epoch: 54 | Iteration number: [2320/4518] 51% | Training loss: 0.6870914060493996
Epoch: 54 | Iteration number: [2330/4518] 51% | Training loss: 0.6870877640441764
Epoch: 54 | Iteration number: [2340/4518] 51% | Training loss: 0.6870846401931893
Epoch: 54 | Iteration number: [2350/4518] 52% | Training loss: 0.6870849791486212
Epoch: 54 | Iteration number: [2360/4518] 52% | Training loss: 0.6870845536811877
Epoch: 54 | Iteration number: [2370/4518] 52% | Training loss: 0.68708500693619
Epoch: 54 | Iteration number: [2380/4518] 52% | Training loss: 0.6870864708633984
Epoch: 54 | Iteration number: [2390/4518] 52% | Training loss: 0.687085788569191
Epoch: 54 | Iteration number: [2400/4518] 53% | Training loss: 0.6870883939415217
Epoch: 54 | Iteration number: [2410/4518] 53% | Training loss: 0.6870838864710321
Epoch: 54 | Iteration number: [2420/4518] 53% | Training loss: 0.6870829007596024
Epoch: 54 | Iteration number: [2430/4518] 53% | Training loss: 0.6870803130261692
Epoch: 54 | Iteration number: [2440/4518] 54% | Training loss: 0.6870786794384972
Epoch: 54 | Iteration number: [2450/4518] 54% | Training loss: 0.6870778140729787
Epoch: 54 | Iteration number: [2460/4518] 54% | Training loss: 0.687078876563204
Epoch: 54 | Iteration number: [2470/4518] 54% | Training loss: 0.6870768022440705
Epoch: 54 | Iteration number: [2480/4518] 54% | Training loss: 0.6870735906785534
Epoch: 54 | Iteration number: [2490/4518] 55% | Training loss: 0.6870752355420445
Epoch: 54 | Iteration number: [2500/4518] 55% | Training loss: 0.6870719959259033
Epoch: 54 | Iteration number: [2510/4518] 55% | Training loss: 0.6870721042393688
Epoch: 54 | Iteration number: [2520/4518] 55% | Training loss: 0.6870743224781657
Epoch: 54 | Iteration number: [2530/4518] 55% | Training loss: 0.6870691965455594
Epoch: 54 | Iteration number: [2540/4518] 56% | Training loss: 0.6870650402673586
Epoch: 54 | Iteration number: [2550/4518] 56% | Training loss: 0.6870651469511144
Epoch: 54 | Iteration number: [2560/4518] 56% | Training loss: 0.6870688639348372
Epoch: 54 | Iteration number: [2570/4518] 56% | Training loss: 0.6870628538066775
Epoch: 54 | Iteration number: [2580/4518] 57% | Training loss: 0.6870604423358458
Epoch: 54 | Iteration number: [2590/4518] 57% | Training loss: 0.6870623632747694
Epoch: 54 | Iteration number: [2600/4518] 57% | Training loss: 0.6870631808730272
Epoch: 54 | Iteration number: [2610/4518] 57% | Training loss: 0.6870614485950762
Epoch: 54 | Iteration number: [2620/4518] 57% | Training loss: 0.6870589287453935
Epoch: 54 | Iteration number: [2630/4518] 58% | Training loss: 0.6870578721675583
Epoch: 54 | Iteration number: [2640/4518] 58% | Training loss: 0.6870528090180773
Epoch: 54 | Iteration number: [2650/4518] 58% | Training loss: 0.6870546601628358
Epoch: 54 | Iteration number: [2660/4518] 58% | Training loss: 0.687057333781307
Epoch: 54 | Iteration number: [2670/4518] 59% | Training loss: 0.6870537304253167
Epoch: 54 | Iteration number: [2680/4518] 59% | Training loss: 0.6870559161278739
Epoch: 54 | Iteration number: [2690/4518] 59% | Training loss: 0.6870473092594997
Epoch: 54 | Iteration number: [2700/4518] 59% | Training loss: 0.6870488697511179
Epoch: 54 | Iteration number: [2710/4518] 59% | Training loss: 0.6870441322177099
Epoch: 54 | Iteration number: [2720/4518] 60% | Training loss: 0.6870439728393274
Epoch: 54 | Iteration number: [2730/4518] 60% | Training loss: 0.6870457306667999
Epoch: 54 | Iteration number: [2740/4518] 60% | Training loss: 0.6870429133629277
Epoch: 54 | Iteration number: [2750/4518] 60% | Training loss: 0.6870461353605444
Epoch: 54 | Iteration number: [2760/4518] 61% | Training loss: 0.6870482418416203
Epoch: 54 | Iteration number: [2770/4518] 61% | Training loss: 0.687049854726998
Epoch: 54 | Iteration number: [2780/4518] 61% | Training loss: 0.6870486771674464
Epoch: 54 | Iteration number: [2790/4518] 61% | Training loss: 0.6870450179209419
Epoch: 54 | Iteration number: [2800/4518] 61% | Training loss: 0.6870466649745192
Epoch: 54 | Iteration number: [2810/4518] 62% | Training loss: 0.6870476642325255
Epoch: 54 | Iteration number: [2820/4518] 62% | Training loss: 0.687046443295817
Epoch: 54 | Iteration number: [2830/4518] 62% | Training loss: 0.6870434561171717
Epoch: 54 | Iteration number: [2840/4518] 62% | Training loss: 0.6870496382385912
Epoch: 54 | Iteration number: [2850/4518] 63% | Training loss: 0.6870521077775119
Epoch: 54 | Iteration number: [2860/4518] 63% | Training loss: 0.6870477923980126
Epoch: 54 | Iteration number: [2870/4518] 63% | Training loss: 0.6870448474684658
Epoch: 54 | Iteration number: [2880/4518] 63% | Training loss: 0.6870471668947075
Epoch: 54 | Iteration number: [2890/4518] 63% | Training loss: 0.6870479758635524
Epoch: 54 | Iteration number: [2900/4518] 64% | Training loss: 0.6870479708087855
Epoch: 54 | Iteration number: [2910/4518] 64% | Training loss: 0.6870479068805262
Epoch: 54 | Iteration number: [2920/4518] 64% | Training loss: 0.6870460103431794
Epoch: 54 | Iteration number: [2930/4518] 64% | Training loss: 0.6870466986207018
Epoch: 54 | Iteration number: [2940/4518] 65% | Training loss: 0.6870454291705371
Epoch: 54 | Iteration number: [2950/4518] 65% | Training loss: 0.6870427000724663
Epoch: 54 | Iteration number: [2960/4518] 65% | Training loss: 0.687038023870539
Epoch: 54 | Iteration number: [2970/4518] 65% | Training loss: 0.6870333628421681
Epoch: 54 | Iteration number: [2980/4518] 65% | Training loss: 0.6870323651989034
Epoch: 54 | Iteration number: [2990/4518] 66% | Training loss: 0.6870306880179058
Epoch: 54 | Iteration number: [3000/4518] 66% | Training loss: 0.6870322043895721
Epoch: 54 | Iteration number: [3010/4518] 66% | Training loss: 0.6870343300393253
Epoch: 54 | Iteration number: [3020/4518] 66% | Training loss: 0.687037119269371
Epoch: 54 | Iteration number: [3030/4518] 67% | Training loss: 0.6870408279864308
Epoch: 54 | Iteration number: [3040/4518] 67% | Training loss: 0.6870396791320098
Epoch: 54 | Iteration number: [3050/4518] 67% | Training loss: 0.6870352041916769
Epoch: 54 | Iteration number: [3060/4518] 67% | Training loss: 0.687035060746997
Epoch: 54 | Iteration number: [3070/4518] 67% | Training loss: 0.6870370977864592
Epoch: 54 | Iteration number: [3080/4518] 68% | Training loss: 0.687032298395386
Epoch: 54 | Iteration number: [3090/4518] 68% | Training loss: 0.6870337931662316
Epoch: 54 | Iteration number: [3100/4518] 68% | Training loss: 0.6870357500353167
Epoch: 54 | Iteration number: [3110/4518] 68% | Training loss: 0.6870387125628554
Epoch: 54 | Iteration number: [3120/4518] 69% | Training loss: 0.6870372352691797
Epoch: 54 | Iteration number: [3130/4518] 69% | Training loss: 0.6870403249995015
Epoch: 54 | Iteration number: [3140/4518] 69% | Training loss: 0.6870396262521197
Epoch: 54 | Iteration number: [3150/4518] 69% | Training loss: 0.687037416601938
Epoch: 54 | Iteration number: [3160/4518] 69% | Training loss: 0.6870395552319817
Epoch: 54 | Iteration number: [3170/4518] 70% | Training loss: 0.6870384769296797
Epoch: 54 | Iteration number: [3180/4518] 70% | Training loss: 0.6870323728652871
Epoch: 54 | Iteration number: [3190/4518] 70% | Training loss: 0.6870304955957826
Epoch: 54 | Iteration number: [3200/4518] 70% | Training loss: 0.6870293871313333
Epoch: 54 | Iteration number: [3210/4518] 71% | Training loss: 0.687028160681977
Epoch: 54 | Iteration number: [3220/4518] 71% | Training loss: 0.6870278349018986
Epoch: 54 | Iteration number: [3230/4518] 71% | Training loss: 0.6870237280894359
Epoch: 54 | Iteration number: [3240/4518] 71% | Training loss: 0.6870195278231008
Epoch: 54 | Iteration number: [3250/4518] 71% | Training loss: 0.6870197042685289
Epoch: 54 | Iteration number: [3260/4518] 72% | Training loss: 0.6870212696446963
Epoch: 54 | Iteration number: [3270/4518] 72% | Training loss: 0.6870230127912049
Epoch: 54 | Iteration number: [3280/4518] 72% | Training loss: 0.6870220887224848
Epoch: 54 | Iteration number: [3290/4518] 72% | Training loss: 0.687024802639854
Epoch: 54 | Iteration number: [3300/4518] 73% | Training loss: 0.6870228453296604
Epoch: 54 | Iteration number: [3310/4518] 73% | Training loss: 0.6870200960297599
Epoch: 54 | Iteration number: [3320/4518] 73% | Training loss: 0.6870192805866161
Epoch: 54 | Iteration number: [3330/4518] 73% | Training loss: 0.6870170403887201
Epoch: 54 | Iteration number: [3340/4518] 73% | Training loss: 0.6870157328194487
Epoch: 54 | Iteration number: [3350/4518] 74% | Training loss: 0.6870152674148332
Epoch: 54 | Iteration number: [3360/4518] 74% | Training loss: 0.6870198086436305
Epoch: 54 | Iteration number: [3370/4518] 74% | Training loss: 0.68702483239089
Epoch: 54 | Iteration number: [3380/4518] 74% | Training loss: 0.6870221880060681
Epoch: 54 | Iteration number: [3390/4518] 75% | Training loss: 0.6870217446556485
Epoch: 54 | Iteration number: [3400/4518] 75% | Training loss: 0.6870177776673261
Epoch: 54 | Iteration number: [3410/4518] 75% | Training loss: 0.687016760114351
Epoch: 54 | Iteration number: [3420/4518] 75% | Training loss: 0.6870131952546493
Epoch: 54 | Iteration number: [3430/4518] 75% | Training loss: 0.6870119571338242
Epoch: 54 | Iteration number: [3440/4518] 76% | Training loss: 0.687012433589891
Epoch: 54 | Iteration number: [3450/4518] 76% | Training loss: 0.6870153085909028
Epoch: 54 | Iteration number: [3460/4518] 76% | Training loss: 0.6870135156577722
Epoch: 54 | Iteration number: [3470/4518] 76% | Training loss: 0.6870109258364532
Epoch: 54 | Iteration number: [3480/4518] 77% | Training loss: 0.6870112533541931
Epoch: 54 | Iteration number: [3490/4518] 77% | Training loss: 0.6870101354183645
Epoch: 54 | Iteration number: [3500/4518] 77% | Training loss: 0.6870108193329403
Epoch: 54 | Iteration number: [3510/4518] 77% | Training loss: 0.6870106070809215
Epoch: 54 | Iteration number: [3520/4518] 77% | Training loss: 0.6870117478411306
Epoch: 54 | Iteration number: [3530/4518] 78% | Training loss: 0.687009754464579
Epoch: 54 | Iteration number: [3540/4518] 78% | Training loss: 0.68701020913609
Epoch: 54 | Iteration number: [3550/4518] 78% | Training loss: 0.6870080730612849
Epoch: 54 | Iteration number: [3560/4518] 78% | Training loss: 0.6870076045059086
Epoch: 54 | Iteration number: [3570/4518] 79% | Training loss: 0.6870051267601195
Epoch: 54 | Iteration number: [3580/4518] 79% | Training loss: 0.687005595571502
Epoch: 54 | Iteration number: [3590/4518] 79% | Training loss: 0.6870098437439432
Epoch: 54 | Iteration number: [3600/4518] 79% | Training loss: 0.6870093612704012
Epoch: 54 | Iteration number: [3610/4518] 79% | Training loss: 0.6870074115136323
Epoch: 54 | Iteration number: [3620/4518] 80% | Training loss: 0.6870083106321524
Epoch: 54 | Iteration number: [3630/4518] 80% | Training loss: 0.6870085314614057
Epoch: 54 | Iteration number: [3640/4518] 80% | Training loss: 0.6870053132811745
Epoch: 54 | Iteration number: [3650/4518] 80% | Training loss: 0.6870091546888221
Epoch: 54 | Iteration number: [3660/4518] 81% | Training loss: 0.6870094616067866
Epoch: 54 | Iteration number: [3670/4518] 81% | Training loss: 0.6870099123882013
Epoch: 54 | Iteration number: [3680/4518] 81% | Training loss: 0.6870082685804886
Epoch: 54 | Iteration number: [3690/4518] 81% | Training loss: 0.6870099063972793
Epoch: 54 | Iteration number: [3700/4518] 81% | Training loss: 0.6870114668962117
Epoch: 54 | Iteration number: [3710/4518] 82% | Training loss: 0.6870093993260211
Epoch: 54 | Iteration number: [3720/4518] 82% | Training loss: 0.6870130147184095
Epoch: 54 | Iteration number: [3730/4518] 82% | Training loss: 0.6870089807714918
Epoch: 54 | Iteration number: [3740/4518] 82% | Training loss: 0.6870067658590123
Epoch: 54 | Iteration number: [3750/4518] 83% | Training loss: 0.6870071773211162
Epoch: 54 | Iteration number: [3760/4518] 83% | Training loss: 0.6870081998724886
Epoch: 54 | Iteration number: [3770/4518] 83% | Training loss: 0.6870088889364855
Epoch: 54 | Iteration number: [3780/4518] 83% | Training loss: 0.687010883055036
Epoch: 54 | Iteration number: [3790/4518] 83% | Training loss: 0.6870072393587208
Epoch: 54 | Iteration number: [3800/4518] 84% | Training loss: 0.6870054276836546
Epoch: 54 | Iteration number: [3810/4518] 84% | Training loss: 0.6870040293597174
Epoch: 54 | Iteration number: [3820/4518] 84% | Training loss: 0.6870041028055222
Epoch: 54 | Iteration number: [3830/4518] 84% | Training loss: 0.6870019036391385
Epoch: 54 | Iteration number: [3840/4518] 84% | Training loss: 0.686999467946589
Epoch: 54 | Iteration number: [3850/4518] 85% | Training loss: 0.6870006149000936
Epoch: 54 | Iteration number: [3860/4518] 85% | Training loss: 0.6870019770656842
Epoch: 54 | Iteration number: [3870/4518] 85% | Training loss: 0.6869992893795634
Epoch: 54 | Iteration number: [3880/4518] 85% | Training loss: 0.686995909785487
Epoch: 54 | Iteration number: [3890/4518] 86% | Training loss: 0.6869938918434869
Epoch: 54 | Iteration number: [3900/4518] 86% | Training loss: 0.6869905936412323
Epoch: 54 | Iteration number: [3910/4518] 86% | Training loss: 0.686989895645005
Epoch: 54 | Iteration number: [3920/4518] 86% | Training loss: 0.6869911224106137
Epoch: 54 | Iteration number: [3930/4518] 86% | Training loss: 0.6869900154096783
Epoch: 54 | Iteration number: [3940/4518] 87% | Training loss: 0.6869932109934425
Epoch: 54 | Iteration number: [3950/4518] 87% | Training loss: 0.6869917387901983
Epoch: 54 | Iteration number: [3960/4518] 87% | Training loss: 0.6869917644394768
Epoch: 54 | Iteration number: [3970/4518] 87% | Training loss: 0.6869892916991669
Epoch: 54 | Iteration number: [3980/4518] 88% | Training loss: 0.686988171051495
Epoch: 54 | Iteration number: [3990/4518] 88% | Training loss: 0.6869867748037018
Epoch: 54 | Iteration number: [4000/4518] 88% | Training loss: 0.6869854499101639
Epoch: 54 | Iteration number: [4010/4518] 88% | Training loss: 0.6869818489747749
Epoch: 54 | Iteration number: [4020/4518] 88% | Training loss: 0.6869840218356593
Epoch: 54 | Iteration number: [4030/4518] 89% | Training loss: 0.6869825056409717
Epoch: 54 | Iteration number: [4040/4518] 89% | Training loss: 0.6869836026341608
Epoch: 54 | Iteration number: [4050/4518] 89% | Training loss: 0.6869839830751773
Epoch: 54 | Iteration number: [4060/4518] 89% | Training loss: 0.686983455754266
Epoch: 54 | Iteration number: [4070/4518] 90% | Training loss: 0.6869818576723703
Epoch: 54 | Iteration number: [4080/4518] 90% | Training loss: 0.686980052233911
Epoch: 54 | Iteration number: [4090/4518] 90% | Training loss: 0.6869803445263422
Epoch: 54 | Iteration number: [4100/4518] 90% | Training loss: 0.6869766142164788
Epoch: 54 | Iteration number: [4110/4518] 90% | Training loss: 0.6869761681324664
Epoch: 54 | Iteration number: [4120/4518] 91% | Training loss: 0.6869731448229077
Epoch: 54 | Iteration number: [4130/4518] 91% | Training loss: 0.6869731610104189
Epoch: 54 | Iteration number: [4140/4518] 91% | Training loss: 0.686974501710583
Epoch: 54 | Iteration number: [4150/4518] 91% | Training loss: 0.6869745554981461
Epoch: 54 | Iteration number: [4160/4518] 92% | Training loss: 0.6869727754249022
Epoch: 54 | Iteration number: [4170/4518] 92% | Training loss: 0.6869704924756103
Epoch: 54 | Iteration number: [4180/4518] 92% | Training loss: 0.6869708566574388
Epoch: 54 | Iteration number: [4190/4518] 92% | Training loss: 0.6869694629688536
Epoch: 54 | Iteration number: [4200/4518] 92% | Training loss: 0.686967506181626
Epoch: 54 | Iteration number: [4210/4518] 93% | Training loss: 0.6869676387225081
Epoch: 54 | Iteration number: [4220/4518] 93% | Training loss: 0.6869691901014879
Epoch: 54 | Iteration number: [4230/4518] 93% | Training loss: 0.6869680541063313
Epoch: 54 | Iteration number: [4240/4518] 93% | Training loss: 0.6869707696139813
Epoch: 54 | Iteration number: [4250/4518] 94% | Training loss: 0.6869707838787752
Epoch: 54 | Iteration number: [4260/4518] 94% | Training loss: 0.6869712761590179
Epoch: 54 | Iteration number: [4270/4518] 94% | Training loss: 0.6869746525337881
Epoch: 54 | Iteration number: [4280/4518] 94% | Training loss: 0.6869756335410002
Epoch: 54 | Iteration number: [4290/4518] 94% | Training loss: 0.686973265209398
Epoch: 54 | Iteration number: [4300/4518] 95% | Training loss: 0.6869755055599435
Epoch: 54 | Iteration number: [4310/4518] 95% | Training loss: 0.6869745629016318
Epoch: 54 | Iteration number: [4320/4518] 95% | Training loss: 0.6869692470326468
Epoch: 54 | Iteration number: [4330/4518] 95% | Training loss: 0.6869710696762208
Epoch: 54 | Iteration number: [4340/4518] 96% | Training loss: 0.6869684918684893
Epoch: 54 | Iteration number: [4350/4518] 96% | Training loss: 0.6869684762379219
Epoch: 54 | Iteration number: [4360/4518] 96% | Training loss: 0.6869643888342272
Epoch: 54 | Iteration number: [4370/4518] 96% | Training loss: 0.6869630835694633
Epoch: 54 | Iteration number: [4380/4518] 96% | Training loss: 0.6869600483815964
Epoch: 54 | Iteration number: [4390/4518] 97% | Training loss: 0.6869582595613388
Epoch: 54 | Iteration number: [4400/4518] 97% | Training loss: 0.6869594124095006
Epoch: 54 | Iteration number: [4410/4518] 97% | Training loss: 0.6869589564346131
Epoch: 54 | Iteration number: [4420/4518] 97% | Training loss: 0.6869592561576161
Epoch: 54 | Iteration number: [4430/4518] 98% | Training loss: 0.6869601952303075
Epoch: 54 | Iteration number: [4440/4518] 98% | Training loss: 0.6869585753158406
Epoch: 54 | Iteration number: [4450/4518] 98% | Training loss: 0.686959217170651
Epoch: 54 | Iteration number: [4460/4518] 98% | Training loss: 0.6869594014278977
Epoch: 54 | Iteration number: [4470/4518] 98% | Training loss: 0.6869615594145969
Epoch: 54 | Iteration number: [4480/4518] 99% | Training loss: 0.6869625170715153
Epoch: 54 | Iteration number: [4490/4518] 99% | Training loss: 0.6869640222503772
Epoch: 54 | Iteration number: [4500/4518] 99% | Training loss: 0.686961675590939
Epoch: 54 | Iteration number: [4510/4518] 99% | Training loss: 0.6869608156300437

 End of epoch: 54 | Train Loss: 0.6868069740511137 | Training Time: 640 

 End of epoch: 54 | Eval Loss: 0.6899302395022645 | Evaluating Time: 17 
Epoch: 55 | Iteration number: [10/4518] 0% | Training loss: 0.7567357659339905
Epoch: 55 | Iteration number: [20/4518] 0% | Training loss: 0.7221199959516525
Epoch: 55 | Iteration number: [30/4518] 0% | Training loss: 0.710692435503006
Epoch: 55 | Iteration number: [40/4518] 0% | Training loss: 0.7045903190970421
Epoch: 55 | Iteration number: [50/4518] 1% | Training loss: 0.7008346748352051
Epoch: 55 | Iteration number: [60/4518] 1% | Training loss: 0.6984007974465688
Epoch: 55 | Iteration number: [70/4518] 1% | Training loss: 0.6967525933470045
Epoch: 55 | Iteration number: [80/4518] 1% | Training loss: 0.6954902119934558
Epoch: 55 | Iteration number: [90/4518] 1% | Training loss: 0.6945368614461687
Epoch: 55 | Iteration number: [100/4518] 2% | Training loss: 0.6937102574110031
Epoch: 55 | Iteration number: [110/4518] 2% | Training loss: 0.6930104678327387
Epoch: 55 | Iteration number: [120/4518] 2% | Training loss: 0.6925006101528803
Epoch: 55 | Iteration number: [130/4518] 2% | Training loss: 0.6920708041924697
Epoch: 55 | Iteration number: [140/4518] 3% | Training loss: 0.6917496825967516
Epoch: 55 | Iteration number: [150/4518] 3% | Training loss: 0.691473724047343
Epoch: 55 | Iteration number: [160/4518] 3% | Training loss: 0.691143899038434
Epoch: 55 | Iteration number: [170/4518] 3% | Training loss: 0.6908722705700818
Epoch: 55 | Iteration number: [180/4518] 3% | Training loss: 0.6906226714452107
Epoch: 55 | Iteration number: [190/4518] 4% | Training loss: 0.6904521901356546
Epoch: 55 | Iteration number: [200/4518] 4% | Training loss: 0.6902160772681236
Epoch: 55 | Iteration number: [210/4518] 4% | Training loss: 0.690078040815535
Epoch: 55 | Iteration number: [220/4518] 4% | Training loss: 0.6899397890676152
Epoch: 55 | Iteration number: [230/4518] 5% | Training loss: 0.6897773773773856
Epoch: 55 | Iteration number: [240/4518] 5% | Training loss: 0.6896314710378647
Epoch: 55 | Iteration number: [250/4518] 5% | Training loss: 0.6894970197677612
Epoch: 55 | Iteration number: [260/4518] 5% | Training loss: 0.6894130894770989
Epoch: 55 | Iteration number: [270/4518] 5% | Training loss: 0.6893418429074464
Epoch: 55 | Iteration number: [280/4518] 6% | Training loss: 0.6892246520945005
Epoch: 55 | Iteration number: [290/4518] 6% | Training loss: 0.6891692603456563
Epoch: 55 | Iteration number: [300/4518] 6% | Training loss: 0.6890933203697205
Epoch: 55 | Iteration number: [310/4518] 6% | Training loss: 0.6889964955468332
Epoch: 55 | Iteration number: [320/4518] 7% | Training loss: 0.6889274757355451
Epoch: 55 | Iteration number: [330/4518] 7% | Training loss: 0.6888416976639719
Epoch: 55 | Iteration number: [340/4518] 7% | Training loss: 0.6887677841326769
Epoch: 55 | Iteration number: [350/4518] 7% | Training loss: 0.6887215512139456
Epoch: 55 | Iteration number: [360/4518] 7% | Training loss: 0.6886560178465313
Epoch: 55 | Iteration number: [370/4518] 8% | Training loss: 0.6886335219885852
Epoch: 55 | Iteration number: [380/4518] 8% | Training loss: 0.6885980598236385
Epoch: 55 | Iteration number: [390/4518] 8% | Training loss: 0.6885716740901654
Epoch: 55 | Iteration number: [400/4518] 8% | Training loss: 0.688501142859459
Epoch: 55 | Iteration number: [410/4518] 9% | Training loss: 0.6884477023671313
Epoch: 55 | Iteration number: [420/4518] 9% | Training loss: 0.6884154870396568
Epoch: 55 | Iteration number: [430/4518] 9% | Training loss: 0.6884029794571012
Epoch: 55 | Iteration number: [440/4518] 9% | Training loss: 0.6883390199054371
Epoch: 55 | Iteration number: [450/4518] 9% | Training loss: 0.6882831029097239
Epoch: 55 | Iteration number: [460/4518] 10% | Training loss: 0.6882331078467162
Epoch: 55 | Iteration number: [470/4518] 10% | Training loss: 0.6881718594977196
Epoch: 55 | Iteration number: [480/4518] 10% | Training loss: 0.688125541806221
Epoch: 55 | Iteration number: [490/4518] 10% | Training loss: 0.6880945136352461
Epoch: 55 | Iteration number: [500/4518] 11% | Training loss: 0.6880548650026321
Epoch: 55 | Iteration number: [510/4518] 11% | Training loss: 0.6880436257988799
Epoch: 55 | Iteration number: [520/4518] 11% | Training loss: 0.6880137144373013
Epoch: 55 | Iteration number: [530/4518] 11% | Training loss: 0.6879848128219821
Epoch: 55 | Iteration number: [540/4518] 11% | Training loss: 0.6879696389039357
Epoch: 55 | Iteration number: [550/4518] 12% | Training loss: 0.6879456019401551
Epoch: 55 | Iteration number: [560/4518] 12% | Training loss: 0.687937147383179
Epoch: 55 | Iteration number: [570/4518] 12% | Training loss: 0.6879288788427387
Epoch: 55 | Iteration number: [580/4518] 12% | Training loss: 0.687937865688883
Epoch: 55 | Iteration number: [590/4518] 13% | Training loss: 0.6879246532917023
Epoch: 55 | Iteration number: [600/4518] 13% | Training loss: 0.6878997725248337
Epoch: 55 | Iteration number: [610/4518] 13% | Training loss: 0.6878809751057234
Epoch: 55 | Iteration number: [620/4518] 13% | Training loss: 0.6878681987524032
Epoch: 55 | Iteration number: [630/4518] 13% | Training loss: 0.6878465079125904
Epoch: 55 | Iteration number: [640/4518] 14% | Training loss: 0.6878310969099403
Epoch: 55 | Iteration number: [650/4518] 14% | Training loss: 0.6878120255470276
Epoch: 55 | Iteration number: [660/4518] 14% | Training loss: 0.6877998237356995
Epoch: 55 | Iteration number: [670/4518] 14% | Training loss: 0.6877812676465334
Epoch: 55 | Iteration number: [680/4518] 15% | Training loss: 0.6877844769288511
Epoch: 55 | Iteration number: [690/4518] 15% | Training loss: 0.6877890324247056
Epoch: 55 | Iteration number: [700/4518] 15% | Training loss: 0.6877685337407249
Epoch: 55 | Iteration number: [710/4518] 15% | Training loss: 0.6877606090525507
Epoch: 55 | Iteration number: [720/4518] 15% | Training loss: 0.6877276739312543
Epoch: 55 | Iteration number: [730/4518] 16% | Training loss: 0.6877216420761526
Epoch: 55 | Iteration number: [740/4518] 16% | Training loss: 0.6877008219023009
Epoch: 55 | Iteration number: [750/4518] 16% | Training loss: 0.6876991322835286
Epoch: 55 | Iteration number: [760/4518] 16% | Training loss: 0.6876835732867843
Epoch: 55 | Iteration number: [770/4518] 17% | Training loss: 0.6876632233718774
Epoch: 55 | Iteration number: [780/4518] 17% | Training loss: 0.68764411065823
Epoch: 55 | Iteration number: [790/4518] 17% | Training loss: 0.6876159213766267
Epoch: 55 | Iteration number: [800/4518] 17% | Training loss: 0.6876138277351856
Epoch: 55 | Iteration number: [810/4518] 17% | Training loss: 0.6875834632067033
Epoch: 55 | Iteration number: [820/4518] 18% | Training loss: 0.6875745750781966
Epoch: 55 | Iteration number: [830/4518] 18% | Training loss: 0.6875606793955148
Epoch: 55 | Iteration number: [840/4518] 18% | Training loss: 0.6875578798708462
Epoch: 55 | Iteration number: [850/4518] 18% | Training loss: 0.6875455643850215
Epoch: 55 | Iteration number: [860/4518] 19% | Training loss: 0.6875354333672412
Epoch: 55 | Iteration number: [870/4518] 19% | Training loss: 0.6875213980674744
Epoch: 55 | Iteration number: [880/4518] 19% | Training loss: 0.6874975451014259
Epoch: 55 | Iteration number: [890/4518] 19% | Training loss: 0.6874914441215858
Epoch: 55 | Iteration number: [900/4518] 19% | Training loss: 0.6874788059128656
Epoch: 55 | Iteration number: [910/4518] 20% | Training loss: 0.6874729706690862
Epoch: 55 | Iteration number: [920/4518] 20% | Training loss: 0.6874770685382511
Epoch: 55 | Iteration number: [930/4518] 20% | Training loss: 0.6874869206900238
Epoch: 55 | Iteration number: [940/4518] 20% | Training loss: 0.6874824373011893
Epoch: 55 | Iteration number: [950/4518] 21% | Training loss: 0.687462633910932
Epoch: 55 | Iteration number: [960/4518] 21% | Training loss: 0.6874549643447002
Epoch: 55 | Iteration number: [970/4518] 21% | Training loss: 0.6874489274836079
Epoch: 55 | Iteration number: [980/4518] 21% | Training loss: 0.6874370116360333
Epoch: 55 | Iteration number: [990/4518] 21% | Training loss: 0.6874348137113783
Epoch: 55 | Iteration number: [1000/4518] 22% | Training loss: 0.6874253046512604
Epoch: 55 | Iteration number: [1010/4518] 22% | Training loss: 0.6874183894974171
Epoch: 55 | Iteration number: [1020/4518] 22% | Training loss: 0.6874204471999523
Epoch: 55 | Iteration number: [1030/4518] 22% | Training loss: 0.6874044150403402
Epoch: 55 | Iteration number: [1040/4518] 23% | Training loss: 0.6873825725454551
Epoch: 55 | Iteration number: [1050/4518] 23% | Training loss: 0.6873698109672183
Epoch: 55 | Iteration number: [1060/4518] 23% | Training loss: 0.6873657074739348
Epoch: 55 | Iteration number: [1070/4518] 23% | Training loss: 0.6873510379100515
Epoch: 55 | Iteration number: [1080/4518] 23% | Training loss: 0.6873547954139886
Epoch: 55 | Iteration number: [1090/4518] 24% | Training loss: 0.687350910792657
Epoch: 55 | Iteration number: [1100/4518] 24% | Training loss: 0.6873378464308652
Epoch: 55 | Iteration number: [1110/4518] 24% | Training loss: 0.6873336093919771
Epoch: 55 | Iteration number: [1120/4518] 24% | Training loss: 0.687330806681088
Epoch: 55 | Iteration number: [1130/4518] 25% | Training loss: 0.6873252361221651
Epoch: 55 | Iteration number: [1140/4518] 25% | Training loss: 0.6873189770338828
Epoch: 55 | Iteration number: [1150/4518] 25% | Training loss: 0.6873118720883908
Epoch: 55 | Iteration number: [1160/4518] 25% | Training loss: 0.6873101810956823
Epoch: 55 | Iteration number: [1170/4518] 25% | Training loss: 0.6873037710149064
Epoch: 55 | Iteration number: [1180/4518] 26% | Training loss: 0.6873022149680025
Epoch: 55 | Iteration number: [1190/4518] 26% | Training loss: 0.6872894607171292
Epoch: 55 | Iteration number: [1200/4518] 26% | Training loss: 0.6872743912537893
Epoch: 55 | Iteration number: [1210/4518] 26% | Training loss: 0.6872697057802815
Epoch: 55 | Iteration number: [1220/4518] 27% | Training loss: 0.6872531367129967
Epoch: 55 | Iteration number: [1230/4518] 27% | Training loss: 0.6872514858963044
Epoch: 55 | Iteration number: [1240/4518] 27% | Training loss: 0.6872486263513565
Epoch: 55 | Iteration number: [1250/4518] 27% | Training loss: 0.6872516547679901
Epoch: 55 | Iteration number: [1260/4518] 27% | Training loss: 0.6872361026586048
Epoch: 55 | Iteration number: [1270/4518] 28% | Training loss: 0.6872365493474044
Epoch: 55 | Iteration number: [1280/4518] 28% | Training loss: 0.6872305475175381
Epoch: 55 | Iteration number: [1290/4518] 28% | Training loss: 0.6872209626112797
Epoch: 55 | Iteration number: [1300/4518] 28% | Training loss: 0.6872132455844145
Epoch: 55 | Iteration number: [1310/4518] 28% | Training loss: 0.6872161825194614
Epoch: 55 | Iteration number: [1320/4518] 29% | Training loss: 0.6872123717358618
Epoch: 55 | Iteration number: [1330/4518] 29% | Training loss: 0.6872030131350783
Epoch: 55 | Iteration number: [1340/4518] 29% | Training loss: 0.6872001221375679
Epoch: 55 | Iteration number: [1350/4518] 29% | Training loss: 0.6871996517976126
Epoch: 55 | Iteration number: [1360/4518] 30% | Training loss: 0.6872075744849794
Epoch: 55 | Iteration number: [1370/4518] 30% | Training loss: 0.6872126083739483
Epoch: 55 | Iteration number: [1380/4518] 30% | Training loss: 0.6872136420529822
Epoch: 55 | Iteration number: [1390/4518] 30% | Training loss: 0.6872035179206794
Epoch: 55 | Iteration number: [1400/4518] 30% | Training loss: 0.6872018017087664
Epoch: 55 | Iteration number: [1410/4518] 31% | Training loss: 0.6871967743474541
Epoch: 55 | Iteration number: [1420/4518] 31% | Training loss: 0.687201849927365
Epoch: 55 | Iteration number: [1430/4518] 31% | Training loss: 0.6871951136972521
Epoch: 55 | Iteration number: [1440/4518] 31% | Training loss: 0.6871898106402821
Epoch: 55 | Iteration number: [1450/4518] 32% | Training loss: 0.6871865397075126
Epoch: 55 | Iteration number: [1460/4518] 32% | Training loss: 0.6871798343854407
Epoch: 55 | Iteration number: [1470/4518] 32% | Training loss: 0.6871653435587072
Epoch: 55 | Iteration number: [1480/4518] 32% | Training loss: 0.6871658737997751
Epoch: 55 | Iteration number: [1490/4518] 32% | Training loss: 0.6871715670864054
Epoch: 55 | Iteration number: [1500/4518] 33% | Training loss: 0.6871631596088409
Epoch: 55 | Iteration number: [1510/4518] 33% | Training loss: 0.6871630416800644
Epoch: 55 | Iteration number: [1520/4518] 33% | Training loss: 0.6871652227091162
Epoch: 55 | Iteration number: [1530/4518] 33% | Training loss: 0.687168288503597
Epoch: 55 | Iteration number: [1540/4518] 34% | Training loss: 0.6871574529192664
Epoch: 55 | Iteration number: [1550/4518] 34% | Training loss: 0.6871489619824194
Epoch: 55 | Iteration number: [1560/4518] 34% | Training loss: 0.6871535021525162
Epoch: 55 | Iteration number: [1570/4518] 34% | Training loss: 0.6871534227565596
Epoch: 55 | Iteration number: [1580/4518] 34% | Training loss: 0.6871431261678286
Epoch: 55 | Iteration number: [1590/4518] 35% | Training loss: 0.6871433569575256
Epoch: 55 | Iteration number: [1600/4518] 35% | Training loss: 0.6871421544626355
Epoch: 55 | Iteration number: [1610/4518] 35% | Training loss: 0.6871384874634121
Epoch: 55 | Iteration number: [1620/4518] 35% | Training loss: 0.6871334440178342
Epoch: 55 | Iteration number: [1630/4518] 36% | Training loss: 0.687124655656288
Epoch: 55 | Iteration number: [1640/4518] 36% | Training loss: 0.6871255297849818
Epoch: 55 | Iteration number: [1650/4518] 36% | Training loss: 0.6871293213873199
Epoch: 55 | Iteration number: [1660/4518] 36% | Training loss: 0.6871242958379079
Epoch: 55 | Iteration number: [1670/4518] 36% | Training loss: 0.6871303526227346
Epoch: 55 | Iteration number: [1680/4518] 37% | Training loss: 0.6871264179192839
Epoch: 55 | Iteration number: [1690/4518] 37% | Training loss: 0.6871268193749986
Epoch: 55 | Iteration number: [1700/4518] 37% | Training loss: 0.6871196437933865
Epoch: 55 | Iteration number: [1710/4518] 37% | Training loss: 0.6871245358073921
Epoch: 55 | Iteration number: [1720/4518] 38% | Training loss: 0.6871296956442123
Epoch: 55 | Iteration number: [1730/4518] 38% | Training loss: 0.6871294961499341
Epoch: 55 | Iteration number: [1740/4518] 38% | Training loss: 0.6871234169294094
Epoch: 55 | Iteration number: [1750/4518] 38% | Training loss: 0.6871220163958414
Epoch: 55 | Iteration number: [1760/4518] 38% | Training loss: 0.6871298500421372
Epoch: 55 | Iteration number: [1770/4518] 39% | Training loss: 0.6871241433809032
Epoch: 55 | Iteration number: [1780/4518] 39% | Training loss: 0.6871208444405138
Epoch: 55 | Iteration number: [1790/4518] 39% | Training loss: 0.687113487354204
Epoch: 55 | Iteration number: [1800/4518] 39% | Training loss: 0.6871020504501131
Epoch: 55 | Iteration number: [1810/4518] 40% | Training loss: 0.6871002895068069
Epoch: 55 | Iteration number: [1820/4518] 40% | Training loss: 0.6870900670250694
Epoch: 55 | Iteration number: [1830/4518] 40% | Training loss: 0.6870849113321044
Epoch: 55 | Iteration number: [1840/4518] 40% | Training loss: 0.6870885642650335
Epoch: 55 | Iteration number: [1850/4518] 40% | Training loss: 0.6870912556390505
Epoch: 55 | Iteration number: [1860/4518] 41% | Training loss: 0.6870855195547945
Epoch: 55 | Iteration number: [1870/4518] 41% | Training loss: 0.6870863827473339
Epoch: 55 | Iteration number: [1880/4518] 41% | Training loss: 0.6870773195903352
Epoch: 55 | Iteration number: [1890/4518] 41% | Training loss: 0.6870739607899278
Epoch: 55 | Iteration number: [1900/4518] 42% | Training loss: 0.6870731287567239
Epoch: 55 | Iteration number: [1910/4518] 42% | Training loss: 0.6870711570322826
Epoch: 55 | Iteration number: [1920/4518] 42% | Training loss: 0.6870786070513228
Epoch: 55 | Iteration number: [1930/4518] 42% | Training loss: 0.6870815551342742
Epoch: 55 | Iteration number: [1940/4518] 42% | Training loss: 0.6870752686999507
Epoch: 55 | Iteration number: [1950/4518] 43% | Training loss: 0.6870752433630136
Epoch: 55 | Iteration number: [1960/4518] 43% | Training loss: 0.6870797800774477
Epoch: 55 | Iteration number: [1970/4518] 43% | Training loss: 0.6870803596102042
Epoch: 55 | Iteration number: [1980/4518] 43% | Training loss: 0.6870800269974603
Epoch: 55 | Iteration number: [1990/4518] 44% | Training loss: 0.6870749560432817
Epoch: 55 | Iteration number: [2000/4518] 44% | Training loss: 0.6870718312561512
Epoch: 55 | Iteration number: [2010/4518] 44% | Training loss: 0.6870730700480997
Epoch: 55 | Iteration number: [2020/4518] 44% | Training loss: 0.6870751160796326
Epoch: 55 | Iteration number: [2030/4518] 44% | Training loss: 0.687077603698364
Epoch: 55 | Iteration number: [2040/4518] 45% | Training loss: 0.6870687627032691
Epoch: 55 | Iteration number: [2050/4518] 45% | Training loss: 0.6870665255407008
Epoch: 55 | Iteration number: [2060/4518] 45% | Training loss: 0.6870624417529523
Epoch: 55 | Iteration number: [2070/4518] 45% | Training loss: 0.68706766847827
Epoch: 55 | Iteration number: [2080/4518] 46% | Training loss: 0.6870710785285785
Epoch: 55 | Iteration number: [2090/4518] 46% | Training loss: 0.6870578938694092
Epoch: 55 | Iteration number: [2100/4518] 46% | Training loss: 0.6870592064516885
Epoch: 55 | Iteration number: [2110/4518] 46% | Training loss: 0.6870600466197135
Epoch: 55 | Iteration number: [2120/4518] 46% | Training loss: 0.6870528548955918
Epoch: 55 | Iteration number: [2130/4518] 47% | Training loss: 0.6870543407722258
Epoch: 55 | Iteration number: [2140/4518] 47% | Training loss: 0.6870535360597004
Epoch: 55 | Iteration number: [2150/4518] 47% | Training loss: 0.6870447428836379
Epoch: 55 | Iteration number: [2160/4518] 47% | Training loss: 0.6870446731370908
Epoch: 55 | Iteration number: [2170/4518] 48% | Training loss: 0.6870505494456137
Epoch: 55 | Iteration number: [2180/4518] 48% | Training loss: 0.6870552883509102
Epoch: 55 | Iteration number: [2190/4518] 48% | Training loss: 0.6870535985792064
Epoch: 55 | Iteration number: [2200/4518] 48% | Training loss: 0.6870563876357946
Epoch: 55 | Iteration number: [2210/4518] 48% | Training loss: 0.6870554274833041
Epoch: 55 | Iteration number: [2220/4518] 49% | Training loss: 0.6870549073358914
Epoch: 55 | Iteration number: [2230/4518] 49% | Training loss: 0.6870498539620985
Epoch: 55 | Iteration number: [2240/4518] 49% | Training loss: 0.6870514122769237
Epoch: 55 | Iteration number: [2250/4518] 49% | Training loss: 0.6870510504245758
Epoch: 55 | Iteration number: [2260/4518] 50% | Training loss: 0.6870513845070273
Epoch: 55 | Iteration number: [2270/4518] 50% | Training loss: 0.6870472234513791
Epoch: 55 | Iteration number: [2280/4518] 50% | Training loss: 0.687053219503478
Epoch: 55 | Iteration number: [2290/4518] 50% | Training loss: 0.6870542065285179
Epoch: 55 | Iteration number: [2300/4518] 50% | Training loss: 0.6870543895337893
Epoch: 55 | Iteration number: [2310/4518] 51% | Training loss: 0.6870535409553743
Epoch: 55 | Iteration number: [2320/4518] 51% | Training loss: 0.6870549144672936
Epoch: 55 | Iteration number: [2330/4518] 51% | Training loss: 0.6870588551263441
Epoch: 55 | Iteration number: [2340/4518] 51% | Training loss: 0.6870596850020254
Epoch: 55 | Iteration number: [2350/4518] 52% | Training loss: 0.687057903117322
Epoch: 55 | Iteration number: [2360/4518] 52% | Training loss: 0.6870612441230628
Epoch: 55 | Iteration number: [2370/4518] 52% | Training loss: 0.6870586462413208
Epoch: 55 | Iteration number: [2380/4518] 52% | Training loss: 0.6870585411035715
Epoch: 55 | Iteration number: [2390/4518] 52% | Training loss: 0.6870538386590311
Epoch: 55 | Iteration number: [2400/4518] 53% | Training loss: 0.6870515709122021
Epoch: 55 | Iteration number: [2410/4518] 53% | Training loss: 0.6870478239296878
Epoch: 55 | Iteration number: [2420/4518] 53% | Training loss: 0.6870472593740984
Epoch: 55 | Iteration number: [2430/4518] 53% | Training loss: 0.6870448511078524
Epoch: 55 | Iteration number: [2440/4518] 54% | Training loss: 0.6870413628757978
Epoch: 55 | Iteration number: [2450/4518] 54% | Training loss: 0.6870367827220839
Epoch: 55 | Iteration number: [2460/4518] 54% | Training loss: 0.6870409101490083
Epoch: 55 | Iteration number: [2470/4518] 54% | Training loss: 0.6870423872702518
Epoch: 55 | Iteration number: [2480/4518] 54% | Training loss: 0.6870382428890275
Epoch: 55 | Iteration number: [2490/4518] 55% | Training loss: 0.6870360519991342
Epoch: 55 | Iteration number: [2500/4518] 55% | Training loss: 0.6870379333257676
Epoch: 55 | Iteration number: [2510/4518] 55% | Training loss: 0.6870377714890408
Epoch: 55 | Iteration number: [2520/4518] 55% | Training loss: 0.6870398606572833
Epoch: 55 | Iteration number: [2530/4518] 55% | Training loss: 0.6870404436418661
Epoch: 55 | Iteration number: [2540/4518] 56% | Training loss: 0.6870402884295607
Epoch: 55 | Iteration number: [2550/4518] 56% | Training loss: 0.6870416549140331
Epoch: 55 | Iteration number: [2560/4518] 56% | Training loss: 0.687040252564475
Epoch: 55 | Iteration number: [2570/4518] 56% | Training loss: 0.6870411806997159
Epoch: 55 | Iteration number: [2580/4518] 57% | Training loss: 0.6870396595823672
Epoch: 55 | Iteration number: [2590/4518] 57% | Training loss: 0.687037474929596
Epoch: 55 | Iteration number: [2600/4518] 57% | Training loss: 0.6870403721699347
Epoch: 55 | Iteration number: [2610/4518] 57% | Training loss: 0.6870408715644559
Epoch: 55 | Iteration number: [2620/4518] 57% | Training loss: 0.6870428663173704
Epoch: 55 | Iteration number: [2630/4518] 58% | Training loss: 0.6870402906784087
Epoch: 55 | Iteration number: [2640/4518] 58% | Training loss: 0.6870388252491301
Epoch: 55 | Iteration number: [2650/4518] 58% | Training loss: 0.6870381187492947
Epoch: 55 | Iteration number: [2660/4518] 58% | Training loss: 0.6870415832987405
Epoch: 55 | Iteration number: [2670/4518] 59% | Training loss: 0.6870391232020846
Epoch: 55 | Iteration number: [2680/4518] 59% | Training loss: 0.6870338850724164
Epoch: 55 | Iteration number: [2690/4518] 59% | Training loss: 0.687038390875749
Epoch: 55 | Iteration number: [2700/4518] 59% | Training loss: 0.6870365325609843
Epoch: 55 | Iteration number: [2710/4518] 59% | Training loss: 0.6870381136002136
Epoch: 55 | Iteration number: [2720/4518] 60% | Training loss: 0.687041080217151
Epoch: 55 | Iteration number: [2730/4518] 60% | Training loss: 0.687038839431036
Epoch: 55 | Iteration number: [2740/4518] 60% | Training loss: 0.687040938121559
Epoch: 55 | Iteration number: [2750/4518] 60% | Training loss: 0.6870420143821022
Epoch: 55 | Iteration number: [2760/4518] 61% | Training loss: 0.6870413028891535
Epoch: 55 | Iteration number: [2770/4518] 61% | Training loss: 0.6870396562431693
Epoch: 55 | Iteration number: [2780/4518] 61% | Training loss: 0.6870403758270277
Epoch: 55 | Iteration number: [2790/4518] 61% | Training loss: 0.6870425179654125
Epoch: 55 | Iteration number: [2800/4518] 61% | Training loss: 0.6870372642789568
Epoch: 55 | Iteration number: [2810/4518] 62% | Training loss: 0.6870346530476499
Epoch: 55 | Iteration number: [2820/4518] 62% | Training loss: 0.6870381679940731
Epoch: 55 | Iteration number: [2830/4518] 62% | Training loss: 0.6870407077743813
Epoch: 55 | Iteration number: [2840/4518] 62% | Training loss: 0.6870359520886985
Epoch: 55 | Iteration number: [2850/4518] 63% | Training loss: 0.6870364750686445
Epoch: 55 | Iteration number: [2860/4518] 63% | Training loss: 0.6870313575842998
Epoch: 55 | Iteration number: [2870/4518] 63% | Training loss: 0.6870293645700927
Epoch: 55 | Iteration number: [2880/4518] 63% | Training loss: 0.6870288434334927
Epoch: 55 | Iteration number: [2890/4518] 63% | Training loss: 0.6870356689068685
Epoch: 55 | Iteration number: [2900/4518] 64% | Training loss: 0.6870306774460037
Epoch: 55 | Iteration number: [2910/4518] 64% | Training loss: 0.6870309669332406
Epoch: 55 | Iteration number: [2920/4518] 64% | Training loss: 0.6870358063545946
Epoch: 55 | Iteration number: [2930/4518] 64% | Training loss: 0.6870380532212632
Epoch: 55 | Iteration number: [2940/4518] 65% | Training loss: 0.6870369992288602
Epoch: 55 | Iteration number: [2950/4518] 65% | Training loss: 0.6870367834527614
Epoch: 55 | Iteration number: [2960/4518] 65% | Training loss: 0.6870365331905919
Epoch: 55 | Iteration number: [2970/4518] 65% | Training loss: 0.687035967926385
Epoch: 55 | Iteration number: [2980/4518] 65% | Training loss: 0.6870307879159915
Epoch: 55 | Iteration number: [2990/4518] 66% | Training loss: 0.6870345036521006
Epoch: 55 | Iteration number: [3000/4518] 66% | Training loss: 0.6870322197675705
Epoch: 55 | Iteration number: [3010/4518] 66% | Training loss: 0.6870389416566323
Epoch: 55 | Iteration number: [3020/4518] 66% | Training loss: 0.6870393518975239
Epoch: 55 | Iteration number: [3030/4518] 67% | Training loss: 0.6870394877671409
Epoch: 55 | Iteration number: [3040/4518] 67% | Training loss: 0.6870400243683865
Epoch: 55 | Iteration number: [3050/4518] 67% | Training loss: 0.6870399420574063
Epoch: 55 | Iteration number: [3060/4518] 67% | Training loss: 0.6870393263553483
Epoch: 55 | Iteration number: [3070/4518] 67% | Training loss: 0.6870431095458785
Epoch: 55 | Iteration number: [3080/4518] 68% | Training loss: 0.6870390055435044
Epoch: 55 | Iteration number: [3090/4518] 68% | Training loss: 0.6870391894891424
Epoch: 55 | Iteration number: [3100/4518] 68% | Training loss: 0.6870373045436797
Epoch: 55 | Iteration number: [3110/4518] 68% | Training loss: 0.6870391822321239
Epoch: 55 | Iteration number: [3120/4518] 69% | Training loss: 0.6870376085050595
Epoch: 55 | Iteration number: [3130/4518] 69% | Training loss: 0.687034199203546
Epoch: 55 | Iteration number: [3140/4518] 69% | Training loss: 0.6870369746426868
Epoch: 55 | Iteration number: [3150/4518] 69% | Training loss: 0.687034878579397
Epoch: 55 | Iteration number: [3160/4518] 69% | Training loss: 0.6870327256714241
Epoch: 55 | Iteration number: [3170/4518] 70% | Training loss: 0.6870341704470878
Epoch: 55 | Iteration number: [3180/4518] 70% | Training loss: 0.687031747335158
Epoch: 55 | Iteration number: [3190/4518] 70% | Training loss: 0.6870282691661094
Epoch: 55 | Iteration number: [3200/4518] 70% | Training loss: 0.6870255332998931
Epoch: 55 | Iteration number: [3210/4518] 71% | Training loss: 0.6870255315600897
Epoch: 55 | Iteration number: [3220/4518] 71% | Training loss: 0.6870214403230951
Epoch: 55 | Iteration number: [3230/4518] 71% | Training loss: 0.6870230057475737
Epoch: 55 | Iteration number: [3240/4518] 71% | Training loss: 0.6870241857789181
Epoch: 55 | Iteration number: [3250/4518] 71% | Training loss: 0.687020053771826
Epoch: 55 | Iteration number: [3260/4518] 72% | Training loss: 0.6870209053067342
Epoch: 55 | Iteration number: [3270/4518] 72% | Training loss: 0.687020907726492
Epoch: 55 | Iteration number: [3280/4518] 72% | Training loss: 0.6870218342942436
Epoch: 55 | Iteration number: [3290/4518] 72% | Training loss: 0.68702509665924
Epoch: 55 | Iteration number: [3300/4518] 73% | Training loss: 0.6870264208316803
Epoch: 55 | Iteration number: [3310/4518] 73% | Training loss: 0.6870218049543502
Epoch: 55 | Iteration number: [3320/4518] 73% | Training loss: 0.6870264204690255
Epoch: 55 | Iteration number: [3330/4518] 73% | Training loss: 0.6870217286072694
Epoch: 55 | Iteration number: [3340/4518] 73% | Training loss: 0.6870200468751485
Epoch: 55 | Iteration number: [3350/4518] 74% | Training loss: 0.6870195402494117
Epoch: 55 | Iteration number: [3360/4518] 74% | Training loss: 0.687019746927988
Epoch: 55 | Iteration number: [3370/4518] 74% | Training loss: 0.6870218689965212
Epoch: 55 | Iteration number: [3380/4518] 74% | Training loss: 0.6870196855279821
Epoch: 55 | Iteration number: [3390/4518] 75% | Training loss: 0.6870224608080928
Epoch: 55 | Iteration number: [3400/4518] 75% | Training loss: 0.6870186082229894
Epoch: 55 | Iteration number: [3410/4518] 75% | Training loss: 0.687021782810737
Epoch: 55 | Iteration number: [3420/4518] 75% | Training loss: 0.6870212195212381
Epoch: 55 | Iteration number: [3430/4518] 75% | Training loss: 0.6870213767703699
Epoch: 55 | Iteration number: [3440/4518] 76% | Training loss: 0.6870214025295058
Epoch: 55 | Iteration number: [3450/4518] 76% | Training loss: 0.6870221740784852
Epoch: 55 | Iteration number: [3460/4518] 76% | Training loss: 0.687020313860364
Epoch: 55 | Iteration number: [3470/4518] 76% | Training loss: 0.687020309462671
Epoch: 55 | Iteration number: [3480/4518] 77% | Training loss: 0.6870166807852942
Epoch: 55 | Iteration number: [3490/4518] 77% | Training loss: 0.6870157449327431
Epoch: 55 | Iteration number: [3500/4518] 77% | Training loss: 0.6870133063282285
Epoch: 55 | Iteration number: [3510/4518] 77% | Training loss: 0.6870111491605427
Epoch: 55 | Iteration number: [3520/4518] 77% | Training loss: 0.6870083066550168
Epoch: 55 | Iteration number: [3530/4518] 78% | Training loss: 0.6870037749536314
Epoch: 55 | Iteration number: [3540/4518] 78% | Training loss: 0.6869991502687756
Epoch: 55 | Iteration number: [3550/4518] 78% | Training loss: 0.6869986207048658
Epoch: 55 | Iteration number: [3560/4518] 78% | Training loss: 0.6869958602477996
Epoch: 55 | Iteration number: [3570/4518] 79% | Training loss: 0.6869947861723539
Epoch: 55 | Iteration number: [3580/4518] 79% | Training loss: 0.686993128227788
Epoch: 55 | Iteration number: [3590/4518] 79% | Training loss: 0.6869937094473241
Epoch: 55 | Iteration number: [3600/4518] 79% | Training loss: 0.6869934888680777
Epoch: 55 | Iteration number: [3610/4518] 79% | Training loss: 0.6869937236949678
Epoch: 55 | Iteration number: [3620/4518] 80% | Training loss: 0.6869955731195639
Epoch: 55 | Iteration number: [3630/4518] 80% | Training loss: 0.6869938245817978
Epoch: 55 | Iteration number: [3640/4518] 80% | Training loss: 0.6869921352837112
Epoch: 55 | Iteration number: [3650/4518] 80% | Training loss: 0.6869924015704899
Epoch: 55 | Iteration number: [3660/4518] 81% | Training loss: 0.686991578405672
Epoch: 55 | Iteration number: [3670/4518] 81% | Training loss: 0.6869894595496986
Epoch: 55 | Iteration number: [3680/4518] 81% | Training loss: 0.6869913556977458
Epoch: 55 | Iteration number: [3690/4518] 81% | Training loss: 0.6869906388162598
Epoch: 55 | Iteration number: [3700/4518] 81% | Training loss: 0.6869853722082602
Epoch: 55 | Iteration number: [3710/4518] 82% | Training loss: 0.6869830130245487
Epoch: 55 | Iteration number: [3720/4518] 82% | Training loss: 0.6869789245948996
Epoch: 55 | Iteration number: [3730/4518] 82% | Training loss: 0.6869791151850856
Epoch: 55 | Iteration number: [3740/4518] 82% | Training loss: 0.6869773080004727
Epoch: 55 | Iteration number: [3750/4518] 83% | Training loss: 0.6869804179668426
Epoch: 55 | Iteration number: [3760/4518] 83% | Training loss: 0.686977345274484
Epoch: 55 | Iteration number: [3770/4518] 83% | Training loss: 0.6869737744805667
Epoch: 55 | Iteration number: [3780/4518] 83% | Training loss: 0.6869735819479775
Epoch: 55 | Iteration number: [3790/4518] 83% | Training loss: 0.6869707604511432
Epoch: 55 | Iteration number: [3800/4518] 84% | Training loss: 0.6869701779359265
Epoch: 55 | Iteration number: [3810/4518] 84% | Training loss: 0.686969762649436
Epoch: 55 | Iteration number: [3820/4518] 84% | Training loss: 0.686969388155413
Epoch: 55 | Iteration number: [3830/4518] 84% | Training loss: 0.6869703778398877
Epoch: 55 | Iteration number: [3840/4518] 84% | Training loss: 0.6869686164117108
Epoch: 55 | Iteration number: [3850/4518] 85% | Training loss: 0.6869686676929524
Epoch: 55 | Iteration number: [3860/4518] 85% | Training loss: 0.6869695753167948
Epoch: 55 | Iteration number: [3870/4518] 85% | Training loss: 0.6869668377000232
Epoch: 55 | Iteration number: [3880/4518] 85% | Training loss: 0.6869672095345468
Epoch: 55 | Iteration number: [3890/4518] 86% | Training loss: 0.6869677045811111
Epoch: 55 | Iteration number: [3900/4518] 86% | Training loss: 0.6869664030808669
Epoch: 55 | Iteration number: [3910/4518] 86% | Training loss: 0.6869676205050915
Epoch: 55 | Iteration number: [3920/4518] 86% | Training loss: 0.6869635814610793
Epoch: 55 | Iteration number: [3930/4518] 86% | Training loss: 0.6869660906057625
Epoch: 55 | Iteration number: [3940/4518] 87% | Training loss: 0.6869655338792027
Epoch: 55 | Iteration number: [3950/4518] 87% | Training loss: 0.6869681591474557
Epoch: 55 | Iteration number: [3960/4518] 87% | Training loss: 0.6869705857351572
Epoch: 55 | Iteration number: [3970/4518] 87% | Training loss: 0.6869704714800309
Epoch: 55 | Iteration number: [3980/4518] 88% | Training loss: 0.6869721443659097
Epoch: 55 | Iteration number: [3990/4518] 88% | Training loss: 0.6869712416838882
Epoch: 55 | Iteration number: [4000/4518] 88% | Training loss: 0.6869716814756394
Epoch: 55 | Iteration number: [4010/4518] 88% | Training loss: 0.6869737453888777
Epoch: 55 | Iteration number: [4020/4518] 88% | Training loss: 0.6869749391998224
Epoch: 55 | Iteration number: [4030/4518] 89% | Training loss: 0.6869751728498019
Epoch: 55 | Iteration number: [4040/4518] 89% | Training loss: 0.6869753732687176
Epoch: 55 | Iteration number: [4050/4518] 89% | Training loss: 0.6869756165257207
Epoch: 55 | Iteration number: [4060/4518] 89% | Training loss: 0.686978245368732
Epoch: 55 | Iteration number: [4070/4518] 90% | Training loss: 0.6869784520064877
Epoch: 55 | Iteration number: [4080/4518] 90% | Training loss: 0.6869791837737841
Epoch: 55 | Iteration number: [4090/4518] 90% | Training loss: 0.6869797337754723
Epoch: 55 | Iteration number: [4100/4518] 90% | Training loss: 0.6869765810559436
Epoch: 55 | Iteration number: [4110/4518] 90% | Training loss: 0.6869765391895081
Epoch: 55 | Iteration number: [4120/4518] 91% | Training loss: 0.686975256331916
Epoch: 55 | Iteration number: [4130/4518] 91% | Training loss: 0.6869727271665383
Epoch: 55 | Iteration number: [4140/4518] 91% | Training loss: 0.6869702870863071
Epoch: 55 | Iteration number: [4150/4518] 91% | Training loss: 0.686968386115798
Epoch: 55 | Iteration number: [4160/4518] 92% | Training loss: 0.6869694487120096
Epoch: 55 | Iteration number: [4170/4518] 92% | Training loss: 0.6869680221846921
Epoch: 55 | Iteration number: [4180/4518] 92% | Training loss: 0.6869698745639701
Epoch: 55 | Iteration number: [4190/4518] 92% | Training loss: 0.6869701252916832
Epoch: 55 | Iteration number: [4200/4518] 92% | Training loss: 0.6869684963283085
Epoch: 55 | Iteration number: [4210/4518] 93% | Training loss: 0.68697080503167
Epoch: 55 | Iteration number: [4220/4518] 93% | Training loss: 0.6869711067580498
Epoch: 55 | Iteration number: [4230/4518] 93% | Training loss: 0.6869692661238055
Epoch: 55 | Iteration number: [4240/4518] 93% | Training loss: 0.6869678980337
Epoch: 55 | Iteration number: [4250/4518] 94% | Training loss: 0.6869695969469407
Epoch: 55 | Iteration number: [4260/4518] 94% | Training loss: 0.6869718026387299
Epoch: 55 | Iteration number: [4270/4518] 94% | Training loss: 0.6869703625348469
Epoch: 55 | Iteration number: [4280/4518] 94% | Training loss: 0.6869713933529141
Epoch: 55 | Iteration number: [4290/4518] 94% | Training loss: 0.6869729320486109
Epoch: 55 | Iteration number: [4300/4518] 95% | Training loss: 0.6869699599715167
Epoch: 55 | Iteration number: [4310/4518] 95% | Training loss: 0.686967532347084
Epoch: 55 | Iteration number: [4320/4518] 95% | Training loss: 0.6869650922439716
Epoch: 55 | Iteration number: [4330/4518] 95% | Training loss: 0.6869644307512058
Epoch: 55 | Iteration number: [4340/4518] 96% | Training loss: 0.6869643090507401
Epoch: 55 | Iteration number: [4350/4518] 96% | Training loss: 0.686967632058023
Epoch: 55 | Iteration number: [4360/4518] 96% | Training loss: 0.6869679589610581
Epoch: 55 | Iteration number: [4370/4518] 96% | Training loss: 0.6869688346947903
Epoch: 55 | Iteration number: [4380/4518] 96% | Training loss: 0.686964089903113
Epoch: 55 | Iteration number: [4390/4518] 97% | Training loss: 0.6869668244500909
Epoch: 55 | Iteration number: [4400/4518] 97% | Training loss: 0.6869651265442371
Epoch: 55 | Iteration number: [4410/4518] 97% | Training loss: 0.6869634287968244
Epoch: 55 | Iteration number: [4420/4518] 97% | Training loss: 0.6869598780821891
Epoch: 55 | Iteration number: [4430/4518] 98% | Training loss: 0.6869592903026339
Epoch: 55 | Iteration number: [4440/4518] 98% | Training loss: 0.6869582782054806
Epoch: 55 | Iteration number: [4450/4518] 98% | Training loss: 0.686955671055933
Epoch: 55 | Iteration number: [4460/4518] 98% | Training loss: 0.686953172167855
Epoch: 55 | Iteration number: [4470/4518] 98% | Training loss: 0.686951952105934
Epoch: 55 | Iteration number: [4480/4518] 99% | Training loss: 0.6869546564428934
Epoch: 55 | Iteration number: [4490/4518] 99% | Training loss: 0.6869547615470759
Epoch: 55 | Iteration number: [4500/4518] 99% | Training loss: 0.6869557532336977
Epoch: 55 | Iteration number: [4510/4518] 99% | Training loss: 0.6869518413908465

 End of epoch: 55 | Train Loss: 0.6868003107320423 | Training Time: 640 

 End of epoch: 55 | Eval Loss: 0.6899221259720472 | Evaluating Time: 17 
Epoch: 56 | Iteration number: [10/4518] 0% | Training loss: 0.75477334856987
Epoch: 56 | Iteration number: [20/4518] 0% | Training loss: 0.721486634016037
Epoch: 56 | Iteration number: [30/4518] 0% | Training loss: 0.7102353692054748
Epoch: 56 | Iteration number: [40/4518] 0% | Training loss: 0.7040617570281029
Epoch: 56 | Iteration number: [50/4518] 1% | Training loss: 0.7005267536640167
Epoch: 56 | Iteration number: [60/4518] 1% | Training loss: 0.6981527547041575
Epoch: 56 | Iteration number: [70/4518] 1% | Training loss: 0.6965075203350612
Epoch: 56 | Iteration number: [80/4518] 1% | Training loss: 0.6954077735543251
Epoch: 56 | Iteration number: [90/4518] 1% | Training loss: 0.6946088949839274
Epoch: 56 | Iteration number: [100/4518] 2% | Training loss: 0.6938142806291581
Epoch: 56 | Iteration number: [110/4518] 2% | Training loss: 0.6932657474821264
Epoch: 56 | Iteration number: [120/4518] 2% | Training loss: 0.6927335624893506
Epoch: 56 | Iteration number: [130/4518] 2% | Training loss: 0.6923032806469844
Epoch: 56 | Iteration number: [140/4518] 3% | Training loss: 0.6918439946004322
Epoch: 56 | Iteration number: [150/4518] 3% | Training loss: 0.6915327827135722
Epoch: 56 | Iteration number: [160/4518] 3% | Training loss: 0.6913041908293962
Epoch: 56 | Iteration number: [170/4518] 3% | Training loss: 0.691087275392869
Epoch: 56 | Iteration number: [180/4518] 3% | Training loss: 0.6908815152115292
Epoch: 56 | Iteration number: [190/4518] 4% | Training loss: 0.6907155962366807
Epoch: 56 | Iteration number: [200/4518] 4% | Training loss: 0.6905533194541931
Epoch: 56 | Iteration number: [210/4518] 4% | Training loss: 0.690370070650464
Epoch: 56 | Iteration number: [220/4518] 4% | Training loss: 0.6902348586104133
Epoch: 56 | Iteration number: [230/4518] 5% | Training loss: 0.6900246778260106
Epoch: 56 | Iteration number: [240/4518] 5% | Training loss: 0.6899017602205276
Epoch: 56 | Iteration number: [250/4518] 5% | Training loss: 0.6897872190475464
Epoch: 56 | Iteration number: [260/4518] 5% | Training loss: 0.6896702019067911
Epoch: 56 | Iteration number: [270/4518] 5% | Training loss: 0.6895110763885357
Epoch: 56 | Iteration number: [280/4518] 6% | Training loss: 0.6894454002380371
Epoch: 56 | Iteration number: [290/4518] 6% | Training loss: 0.6892999509285236
Epoch: 56 | Iteration number: [300/4518] 6% | Training loss: 0.689236164689064
Epoch: 56 | Iteration number: [310/4518] 6% | Training loss: 0.6891346677657096
Epoch: 56 | Iteration number: [320/4518] 7% | Training loss: 0.6890853255987167
Epoch: 56 | Iteration number: [330/4518] 7% | Training loss: 0.6890291804617101
Epoch: 56 | Iteration number: [340/4518] 7% | Training loss: 0.6889508003697676
Epoch: 56 | Iteration number: [350/4518] 7% | Training loss: 0.6888757971354893
Epoch: 56 | Iteration number: [360/4518] 7% | Training loss: 0.6888248701890309
Epoch: 56 | Iteration number: [370/4518] 8% | Training loss: 0.6887814560452024
Epoch: 56 | Iteration number: [380/4518] 8% | Training loss: 0.6887119569276509
Epoch: 56 | Iteration number: [390/4518] 8% | Training loss: 0.6886737063909188
Epoch: 56 | Iteration number: [400/4518] 8% | Training loss: 0.6886378276348114
Epoch: 56 | Iteration number: [410/4518] 9% | Training loss: 0.6885612580834366
Epoch: 56 | Iteration number: [420/4518] 9% | Training loss: 0.688462871455011
Epoch: 56 | Iteration number: [430/4518] 9% | Training loss: 0.6884311318397522
Epoch: 56 | Iteration number: [440/4518] 9% | Training loss: 0.6884160792285746
Epoch: 56 | Iteration number: [450/4518] 9% | Training loss: 0.688369425535202
Epoch: 56 | Iteration number: [460/4518] 10% | Training loss: 0.6883257159720296
Epoch: 56 | Iteration number: [470/4518] 10% | Training loss: 0.6882821434355797
Epoch: 56 | Iteration number: [480/4518] 10% | Training loss: 0.6882700378696124
Epoch: 56 | Iteration number: [490/4518] 10% | Training loss: 0.6882481807348679
Epoch: 56 | Iteration number: [500/4518] 11% | Training loss: 0.6882133922576904
Epoch: 56 | Iteration number: [510/4518] 11% | Training loss: 0.6881850966051513
Epoch: 56 | Iteration number: [520/4518] 11% | Training loss: 0.6881544722960545
Epoch: 56 | Iteration number: [530/4518] 11% | Training loss: 0.6881418989514405
Epoch: 56 | Iteration number: [540/4518] 11% | Training loss: 0.6881257351901796
Epoch: 56 | Iteration number: [550/4518] 12% | Training loss: 0.6881104130094702
Epoch: 56 | Iteration number: [560/4518] 12% | Training loss: 0.6880651046122823
Epoch: 56 | Iteration number: [570/4518] 12% | Training loss: 0.6880118974468165
Epoch: 56 | Iteration number: [580/4518] 12% | Training loss: 0.6879722418456242
Epoch: 56 | Iteration number: [590/4518] 13% | Training loss: 0.6879481699507115
Epoch: 56 | Iteration number: [600/4518] 13% | Training loss: 0.6879035433133444
Epoch: 56 | Iteration number: [610/4518] 13% | Training loss: 0.6878696466078523
Epoch: 56 | Iteration number: [620/4518] 13% | Training loss: 0.6878713107878162
Epoch: 56 | Iteration number: [630/4518] 13% | Training loss: 0.6878563328394814
Epoch: 56 | Iteration number: [640/4518] 14% | Training loss: 0.6878536963835359
Epoch: 56 | Iteration number: [650/4518] 14% | Training loss: 0.6878401271196513
Epoch: 56 | Iteration number: [660/4518] 14% | Training loss: 0.6878137928969932
Epoch: 56 | Iteration number: [670/4518] 14% | Training loss: 0.6878133456208813
Epoch: 56 | Iteration number: [680/4518] 15% | Training loss: 0.6878025139955913
Epoch: 56 | Iteration number: [690/4518] 15% | Training loss: 0.687812122054722
Epoch: 56 | Iteration number: [700/4518] 15% | Training loss: 0.6877874542134149
Epoch: 56 | Iteration number: [710/4518] 15% | Training loss: 0.6877615249492752
Epoch: 56 | Iteration number: [720/4518] 15% | Training loss: 0.687740970402956
Epoch: 56 | Iteration number: [730/4518] 16% | Training loss: 0.6877204656600953
Epoch: 56 | Iteration number: [740/4518] 16% | Training loss: 0.6877208552650503
Epoch: 56 | Iteration number: [750/4518] 16% | Training loss: 0.6876988713741302
Epoch: 56 | Iteration number: [760/4518] 16% | Training loss: 0.6876862464766753
Epoch: 56 | Iteration number: [770/4518] 17% | Training loss: 0.6876900475520592
Epoch: 56 | Iteration number: [780/4518] 17% | Training loss: 0.6876802043272898
Epoch: 56 | Iteration number: [790/4518] 17% | Training loss: 0.6876641935185541
Epoch: 56 | Iteration number: [800/4518] 17% | Training loss: 0.6876626057177782
Epoch: 56 | Iteration number: [810/4518] 17% | Training loss: 0.6876520719793108
Epoch: 56 | Iteration number: [820/4518] 18% | Training loss: 0.6876423522466566
Epoch: 56 | Iteration number: [830/4518] 18% | Training loss: 0.6876374842172646
Epoch: 56 | Iteration number: [840/4518] 18% | Training loss: 0.687619118037678
Epoch: 56 | Iteration number: [850/4518] 18% | Training loss: 0.6875923455462736
Epoch: 56 | Iteration number: [860/4518] 19% | Training loss: 0.6875863528528879
Epoch: 56 | Iteration number: [870/4518] 19% | Training loss: 0.6875671366850535
Epoch: 56 | Iteration number: [880/4518] 19% | Training loss: 0.6875494048676708
Epoch: 56 | Iteration number: [890/4518] 19% | Training loss: 0.6875455795379167
Epoch: 56 | Iteration number: [900/4518] 19% | Training loss: 0.6875306714905632
Epoch: 56 | Iteration number: [910/4518] 20% | Training loss: 0.6875221863552764
Epoch: 56 | Iteration number: [920/4518] 20% | Training loss: 0.6875101907097775
Epoch: 56 | Iteration number: [930/4518] 20% | Training loss: 0.687497942486117
Epoch: 56 | Iteration number: [940/4518] 20% | Training loss: 0.6874757177018105
Epoch: 56 | Iteration number: [950/4518] 21% | Training loss: 0.6874753216693276
Epoch: 56 | Iteration number: [960/4518] 21% | Training loss: 0.6874724822739761
Epoch: 56 | Iteration number: [970/4518] 21% | Training loss: 0.6874526523437696
Epoch: 56 | Iteration number: [980/4518] 21% | Training loss: 0.6874619618970521
Epoch: 56 | Iteration number: [990/4518] 21% | Training loss: 0.6874599459797445
Epoch: 56 | Iteration number: [1000/4518] 22% | Training loss: 0.6874618423581124
Epoch: 56 | Iteration number: [1010/4518] 22% | Training loss: 0.6874516513087962
Epoch: 56 | Iteration number: [1020/4518] 22% | Training loss: 0.6874355438877554
Epoch: 56 | Iteration number: [1030/4518] 22% | Training loss: 0.6874446585919093
Epoch: 56 | Iteration number: [1040/4518] 23% | Training loss: 0.6874326254885931
Epoch: 56 | Iteration number: [1050/4518] 23% | Training loss: 0.6874354031540099
Epoch: 56 | Iteration number: [1060/4518] 23% | Training loss: 0.6874394870029306
Epoch: 56 | Iteration number: [1070/4518] 23% | Training loss: 0.6874394072550479
Epoch: 56 | Iteration number: [1080/4518] 23% | Training loss: 0.6874315607878897
Epoch: 56 | Iteration number: [1090/4518] 24% | Training loss: 0.6874180685489549
Epoch: 56 | Iteration number: [1100/4518] 24% | Training loss: 0.6874127385291187
Epoch: 56 | Iteration number: [1110/4518] 24% | Training loss: 0.6873953537898021
Epoch: 56 | Iteration number: [1120/4518] 24% | Training loss: 0.6873852312032666
Epoch: 56 | Iteration number: [1130/4518] 25% | Training loss: 0.687377723497627
Epoch: 56 | Iteration number: [1140/4518] 25% | Training loss: 0.6873642301350309
Epoch: 56 | Iteration number: [1150/4518] 25% | Training loss: 0.6873388049395188
Epoch: 56 | Iteration number: [1160/4518] 25% | Training loss: 0.6873378247536462
Epoch: 56 | Iteration number: [1170/4518] 25% | Training loss: 0.6873227456696013
Epoch: 56 | Iteration number: [1180/4518] 26% | Training loss: 0.6873211192377543
Epoch: 56 | Iteration number: [1190/4518] 26% | Training loss: 0.6873185594041809
Epoch: 56 | Iteration number: [1200/4518] 26% | Training loss: 0.6873140414059162
Epoch: 56 | Iteration number: [1210/4518] 26% | Training loss: 0.6873105991970409
Epoch: 56 | Iteration number: [1220/4518] 27% | Training loss: 0.6873088773156776
Epoch: 56 | Iteration number: [1230/4518] 27% | Training loss: 0.6873053202784158
Epoch: 56 | Iteration number: [1240/4518] 27% | Training loss: 0.6873045321433775
Epoch: 56 | Iteration number: [1250/4518] 27% | Training loss: 0.6873008787631989
Epoch: 56 | Iteration number: [1260/4518] 27% | Training loss: 0.6872980090360793
Epoch: 56 | Iteration number: [1270/4518] 28% | Training loss: 0.6872966469742182
Epoch: 56 | Iteration number: [1280/4518] 28% | Training loss: 0.687295358767733
Epoch: 56 | Iteration number: [1290/4518] 28% | Training loss: 0.6873001489066338
Epoch: 56 | Iteration number: [1300/4518] 28% | Training loss: 0.6872975111466187
Epoch: 56 | Iteration number: [1310/4518] 28% | Training loss: 0.6872958196028498
Epoch: 56 | Iteration number: [1320/4518] 29% | Training loss: 0.6872916863723235
Epoch: 56 | Iteration number: [1330/4518] 29% | Training loss: 0.6872828047974665
Epoch: 56 | Iteration number: [1340/4518] 29% | Training loss: 0.6872806913817107
Epoch: 56 | Iteration number: [1350/4518] 29% | Training loss: 0.6872729520886033
Epoch: 56 | Iteration number: [1360/4518] 30% | Training loss: 0.6872694414328127
Epoch: 56 | Iteration number: [1370/4518] 30% | Training loss: 0.6872638483552167
Epoch: 56 | Iteration number: [1380/4518] 30% | Training loss: 0.6872464082811189
Epoch: 56 | Iteration number: [1390/4518] 30% | Training loss: 0.6872464926551571
Epoch: 56 | Iteration number: [1400/4518] 30% | Training loss: 0.6872473548139845
Epoch: 56 | Iteration number: [1410/4518] 31% | Training loss: 0.6872438412186102
Epoch: 56 | Iteration number: [1420/4518] 31% | Training loss: 0.6872478846093298
Epoch: 56 | Iteration number: [1430/4518] 31% | Training loss: 0.6872428650205785
Epoch: 56 | Iteration number: [1440/4518] 31% | Training loss: 0.6872415112124549
Epoch: 56 | Iteration number: [1450/4518] 32% | Training loss: 0.6872352558991005
Epoch: 56 | Iteration number: [1460/4518] 32% | Training loss: 0.6872276929959859
Epoch: 56 | Iteration number: [1470/4518] 32% | Training loss: 0.687206939288548
Epoch: 56 | Iteration number: [1480/4518] 32% | Training loss: 0.687204178523373
Epoch: 56 | Iteration number: [1490/4518] 32% | Training loss: 0.687206881518332
Epoch: 56 | Iteration number: [1500/4518] 33% | Training loss: 0.6872012453079224
Epoch: 56 | Iteration number: [1510/4518] 33% | Training loss: 0.6871941649361162
Epoch: 56 | Iteration number: [1520/4518] 33% | Training loss: 0.6871862766774077
Epoch: 56 | Iteration number: [1530/4518] 33% | Training loss: 0.6871908257599749
Epoch: 56 | Iteration number: [1540/4518] 34% | Training loss: 0.6871870481348658
Epoch: 56 | Iteration number: [1550/4518] 34% | Training loss: 0.6871857683889327
Epoch: 56 | Iteration number: [1560/4518] 34% | Training loss: 0.6871807483526376
Epoch: 56 | Iteration number: [1570/4518] 34% | Training loss: 0.6871858425960419
Epoch: 56 | Iteration number: [1580/4518] 34% | Training loss: 0.6871866971631594
Epoch: 56 | Iteration number: [1590/4518] 35% | Training loss: 0.6871840857859678
Epoch: 56 | Iteration number: [1600/4518] 35% | Training loss: 0.6871787187829613
Epoch: 56 | Iteration number: [1610/4518] 35% | Training loss: 0.6871817452566964
Epoch: 56 | Iteration number: [1620/4518] 35% | Training loss: 0.6871752993928062
Epoch: 56 | Iteration number: [1630/4518] 36% | Training loss: 0.6871726914417524
Epoch: 56 | Iteration number: [1640/4518] 36% | Training loss: 0.6871659672478351
Epoch: 56 | Iteration number: [1650/4518] 36% | Training loss: 0.6871685160651352
Epoch: 56 | Iteration number: [1660/4518] 36% | Training loss: 0.6871640245598483
Epoch: 56 | Iteration number: [1670/4518] 36% | Training loss: 0.6871540318706079
Epoch: 56 | Iteration number: [1680/4518] 37% | Training loss: 0.6871548921579407
Epoch: 56 | Iteration number: [1690/4518] 37% | Training loss: 0.6871511549286589
Epoch: 56 | Iteration number: [1700/4518] 37% | Training loss: 0.6871495141702539
Epoch: 56 | Iteration number: [1710/4518] 37% | Training loss: 0.687151565119537
Epoch: 56 | Iteration number: [1720/4518] 38% | Training loss: 0.6871422493180563
Epoch: 56 | Iteration number: [1730/4518] 38% | Training loss: 0.687139113479956
Epoch: 56 | Iteration number: [1740/4518] 38% | Training loss: 0.6871268738275287
Epoch: 56 | Iteration number: [1750/4518] 38% | Training loss: 0.6871190434864589
Epoch: 56 | Iteration number: [1760/4518] 38% | Training loss: 0.6871159831569953
Epoch: 56 | Iteration number: [1770/4518] 39% | Training loss: 0.6871177485433676
Epoch: 56 | Iteration number: [1780/4518] 39% | Training loss: 0.6871157756347335
Epoch: 56 | Iteration number: [1790/4518] 39% | Training loss: 0.6871161903748965
Epoch: 56 | Iteration number: [1800/4518] 39% | Training loss: 0.6871124865611394
Epoch: 56 | Iteration number: [1810/4518] 40% | Training loss: 0.6871073816033358
Epoch: 56 | Iteration number: [1820/4518] 40% | Training loss: 0.6871091496813428
Epoch: 56 | Iteration number: [1830/4518] 40% | Training loss: 0.6871135444914709
Epoch: 56 | Iteration number: [1840/4518] 40% | Training loss: 0.6871188218826833
Epoch: 56 | Iteration number: [1850/4518] 40% | Training loss: 0.6871175650003795
Epoch: 56 | Iteration number: [1860/4518] 41% | Training loss: 0.6871162257848248
Epoch: 56 | Iteration number: [1870/4518] 41% | Training loss: 0.6871102624398502
Epoch: 56 | Iteration number: [1880/4518] 41% | Training loss: 0.6871010244209715
Epoch: 56 | Iteration number: [1890/4518] 41% | Training loss: 0.687103717446958
Epoch: 56 | Iteration number: [1900/4518] 42% | Training loss: 0.6870988240053779
Epoch: 56 | Iteration number: [1910/4518] 42% | Training loss: 0.687097173554735
Epoch: 56 | Iteration number: [1920/4518] 42% | Training loss: 0.6870985573468109
Epoch: 56 | Iteration number: [1930/4518] 42% | Training loss: 0.687103612651479
Epoch: 56 | Iteration number: [1940/4518] 42% | Training loss: 0.6871070092793592
Epoch: 56 | Iteration number: [1950/4518] 43% | Training loss: 0.6871094515996101
Epoch: 56 | Iteration number: [1960/4518] 43% | Training loss: 0.6871079320810279
Epoch: 56 | Iteration number: [1970/4518] 43% | Training loss: 0.6871040470406489
Epoch: 56 | Iteration number: [1980/4518] 43% | Training loss: 0.6871071574362841
Epoch: 56 | Iteration number: [1990/4518] 44% | Training loss: 0.6871052871097871
Epoch: 56 | Iteration number: [2000/4518] 44% | Training loss: 0.6871068802773952
Epoch: 56 | Iteration number: [2010/4518] 44% | Training loss: 0.6871058679338712
Epoch: 56 | Iteration number: [2020/4518] 44% | Training loss: 0.6871035057424318
Epoch: 56 | Iteration number: [2030/4518] 44% | Training loss: 0.6871021264292336
Epoch: 56 | Iteration number: [2040/4518] 45% | Training loss: 0.6870984562471801
Epoch: 56 | Iteration number: [2050/4518] 45% | Training loss: 0.6871059160406997
Epoch: 56 | Iteration number: [2060/4518] 45% | Training loss: 0.6871078789523505
Epoch: 56 | Iteration number: [2070/4518] 45% | Training loss: 0.6871088529554542
Epoch: 56 | Iteration number: [2080/4518] 46% | Training loss: 0.6871073650626036
Epoch: 56 | Iteration number: [2090/4518] 46% | Training loss: 0.6871041208648225
Epoch: 56 | Iteration number: [2100/4518] 46% | Training loss: 0.6871004644462041
Epoch: 56 | Iteration number: [2110/4518] 46% | Training loss: 0.687097535088164
Epoch: 56 | Iteration number: [2120/4518] 46% | Training loss: 0.6871001076585842
Epoch: 56 | Iteration number: [2130/4518] 47% | Training loss: 0.6871008185993338
Epoch: 56 | Iteration number: [2140/4518] 47% | Training loss: 0.6871049347881959
Epoch: 56 | Iteration number: [2150/4518] 47% | Training loss: 0.6871016873592554
Epoch: 56 | Iteration number: [2160/4518] 47% | Training loss: 0.6870929761341324
Epoch: 56 | Iteration number: [2170/4518] 48% | Training loss: 0.6870905844297277
Epoch: 56 | Iteration number: [2180/4518] 48% | Training loss: 0.6870932046699961
Epoch: 56 | Iteration number: [2190/4518] 48% | Training loss: 0.6870952981519917
Epoch: 56 | Iteration number: [2200/4518] 48% | Training loss: 0.687086937861009
Epoch: 56 | Iteration number: [2210/4518] 48% | Training loss: 0.6870864628396962
Epoch: 56 | Iteration number: [2220/4518] 49% | Training loss: 0.6870884274845724
Epoch: 56 | Iteration number: [2230/4518] 49% | Training loss: 0.6870827609113513
Epoch: 56 | Iteration number: [2240/4518] 49% | Training loss: 0.687084034856941
Epoch: 56 | Iteration number: [2250/4518] 49% | Training loss: 0.6870817033714718
Epoch: 56 | Iteration number: [2260/4518] 50% | Training loss: 0.6870822552294857
Epoch: 56 | Iteration number: [2270/4518] 50% | Training loss: 0.6870827841601183
Epoch: 56 | Iteration number: [2280/4518] 50% | Training loss: 0.687081330805494
Epoch: 56 | Iteration number: [2290/4518] 50% | Training loss: 0.6870819549112861
Epoch: 56 | Iteration number: [2300/4518] 50% | Training loss: 0.6870794470413871
Epoch: 56 | Iteration number: [2310/4518] 51% | Training loss: 0.6870745819110375
Epoch: 56 | Iteration number: [2320/4518] 51% | Training loss: 0.6870731365834845
Epoch: 56 | Iteration number: [2330/4518] 51% | Training loss: 0.6870702187134984
Epoch: 56 | Iteration number: [2340/4518] 51% | Training loss: 0.6870681482757258
Epoch: 56 | Iteration number: [2350/4518] 52% | Training loss: 0.6870663292610899
Epoch: 56 | Iteration number: [2360/4518] 52% | Training loss: 0.6870615395701538
Epoch: 56 | Iteration number: [2370/4518] 52% | Training loss: 0.6870567069274967
Epoch: 56 | Iteration number: [2380/4518] 52% | Training loss: 0.6870513817843269
Epoch: 56 | Iteration number: [2390/4518] 52% | Training loss: 0.6870495725625728
Epoch: 56 | Iteration number: [2400/4518] 53% | Training loss: 0.6870404967665672
Epoch: 56 | Iteration number: [2410/4518] 53% | Training loss: 0.6870370125869498
Epoch: 56 | Iteration number: [2420/4518] 53% | Training loss: 0.6870381680401889
Epoch: 56 | Iteration number: [2430/4518] 53% | Training loss: 0.6870411090154216
Epoch: 56 | Iteration number: [2440/4518] 54% | Training loss: 0.6870437717584313
Epoch: 56 | Iteration number: [2450/4518] 54% | Training loss: 0.6870419942359535
Epoch: 56 | Iteration number: [2460/4518] 54% | Training loss: 0.6870410832447734
Epoch: 56 | Iteration number: [2470/4518] 54% | Training loss: 0.687042889228234
Epoch: 56 | Iteration number: [2480/4518] 54% | Training loss: 0.6870360482363932
Epoch: 56 | Iteration number: [2490/4518] 55% | Training loss: 0.687033565575818
Epoch: 56 | Iteration number: [2500/4518] 55% | Training loss: 0.687037740111351
Epoch: 56 | Iteration number: [2510/4518] 55% | Training loss: 0.6870356232996481
Epoch: 56 | Iteration number: [2520/4518] 55% | Training loss: 0.6870395360958008
Epoch: 56 | Iteration number: [2530/4518] 55% | Training loss: 0.6870326529614068
Epoch: 56 | Iteration number: [2540/4518] 56% | Training loss: 0.6870354130746812
Epoch: 56 | Iteration number: [2550/4518] 56% | Training loss: 0.6870357258880839
Epoch: 56 | Iteration number: [2560/4518] 56% | Training loss: 0.6870359080377966
Epoch: 56 | Iteration number: [2570/4518] 56% | Training loss: 0.6870329444046614
Epoch: 56 | Iteration number: [2580/4518] 57% | Training loss: 0.6870309909184774
Epoch: 56 | Iteration number: [2590/4518] 57% | Training loss: 0.6870286147336702
Epoch: 56 | Iteration number: [2600/4518] 57% | Training loss: 0.687024812056468
Epoch: 56 | Iteration number: [2610/4518] 57% | Training loss: 0.6870229875676019
Epoch: 56 | Iteration number: [2620/4518] 57% | Training loss: 0.6870190521687952
Epoch: 56 | Iteration number: [2630/4518] 58% | Training loss: 0.6870216290080502
Epoch: 56 | Iteration number: [2640/4518] 58% | Training loss: 0.6870181944334146
Epoch: 56 | Iteration number: [2650/4518] 58% | Training loss: 0.6870143946386733
Epoch: 56 | Iteration number: [2660/4518] 58% | Training loss: 0.6870133399739301
Epoch: 56 | Iteration number: [2670/4518] 59% | Training loss: 0.6870143645934844
Epoch: 56 | Iteration number: [2680/4518] 59% | Training loss: 0.6870100062284896
Epoch: 56 | Iteration number: [2690/4518] 59% | Training loss: 0.687012674728734
Epoch: 56 | Iteration number: [2700/4518] 59% | Training loss: 0.687014292522713
Epoch: 56 | Iteration number: [2710/4518] 59% | Training loss: 0.6870128960846975
Epoch: 56 | Iteration number: [2720/4518] 60% | Training loss: 0.687009264419184
Epoch: 56 | Iteration number: [2730/4518] 60% | Training loss: 0.6870048926863478
Epoch: 56 | Iteration number: [2740/4518] 60% | Training loss: 0.6870032052489092
Epoch: 56 | Iteration number: [2750/4518] 60% | Training loss: 0.6870060840303248
Epoch: 56 | Iteration number: [2760/4518] 61% | Training loss: 0.6870095457287803
Epoch: 56 | Iteration number: [2770/4518] 61% | Training loss: 0.6870057784693335
Epoch: 56 | Iteration number: [2780/4518] 61% | Training loss: 0.6870083430902564
Epoch: 56 | Iteration number: [2790/4518] 61% | Training loss: 0.6870059722854245
Epoch: 56 | Iteration number: [2800/4518] 61% | Training loss: 0.687000984698534
Epoch: 56 | Iteration number: [2810/4518] 62% | Training loss: 0.687001381416762
Epoch: 56 | Iteration number: [2820/4518] 62% | Training loss: 0.6869993035040849
Epoch: 56 | Iteration number: [2830/4518] 62% | Training loss: 0.6869955937559108
Epoch: 56 | Iteration number: [2840/4518] 62% | Training loss: 0.6869944254907084
Epoch: 56 | Iteration number: [2850/4518] 63% | Training loss: 0.6869921183167842
Epoch: 56 | Iteration number: [2860/4518] 63% | Training loss: 0.6869925283885502
Epoch: 56 | Iteration number: [2870/4518] 63% | Training loss: 0.686993232753634
Epoch: 56 | Iteration number: [2880/4518] 63% | Training loss: 0.6869951994054847
Epoch: 56 | Iteration number: [2890/4518] 63% | Training loss: 0.6869907601481903
Epoch: 56 | Iteration number: [2900/4518] 64% | Training loss: 0.6869905012845993
Epoch: 56 | Iteration number: [2910/4518] 64% | Training loss: 0.6869900817723619
Epoch: 56 | Iteration number: [2920/4518] 64% | Training loss: 0.6869871238118982
Epoch: 56 | Iteration number: [2930/4518] 64% | Training loss: 0.6869855982858574
Epoch: 56 | Iteration number: [2940/4518] 65% | Training loss: 0.6869830966401262
Epoch: 56 | Iteration number: [2950/4518] 65% | Training loss: 0.6869817440994715
Epoch: 56 | Iteration number: [2960/4518] 65% | Training loss: 0.68698427924836
Epoch: 56 | Iteration number: [2970/4518] 65% | Training loss: 0.6869839250640034
Epoch: 56 | Iteration number: [2980/4518] 65% | Training loss: 0.6869841079183873
Epoch: 56 | Iteration number: [2990/4518] 66% | Training loss: 0.6869796054817761
Epoch: 56 | Iteration number: [3000/4518] 66% | Training loss: 0.6869749149084091
Epoch: 56 | Iteration number: [3010/4518] 66% | Training loss: 0.6869755115619925
Epoch: 56 | Iteration number: [3020/4518] 66% | Training loss: 0.6869767676915554
Epoch: 56 | Iteration number: [3030/4518] 67% | Training loss: 0.6869822985464984
Epoch: 56 | Iteration number: [3040/4518] 67% | Training loss: 0.686984051234628
Epoch: 56 | Iteration number: [3050/4518] 67% | Training loss: 0.6869786278732487
Epoch: 56 | Iteration number: [3060/4518] 67% | Training loss: 0.6869799429295109
Epoch: 56 | Iteration number: [3070/4518] 67% | Training loss: 0.6869764497691723
Epoch: 56 | Iteration number: [3080/4518] 68% | Training loss: 0.6869766063697926
Epoch: 56 | Iteration number: [3090/4518] 68% | Training loss: 0.6869759141048567
Epoch: 56 | Iteration number: [3100/4518] 68% | Training loss: 0.6869791852274248
Epoch: 56 | Iteration number: [3110/4518] 68% | Training loss: 0.6869744144451964
Epoch: 56 | Iteration number: [3120/4518] 69% | Training loss: 0.6869777004306133
Epoch: 56 | Iteration number: [3130/4518] 69% | Training loss: 0.6869779085770201
Epoch: 56 | Iteration number: [3140/4518] 69% | Training loss: 0.6869760428264642
Epoch: 56 | Iteration number: [3150/4518] 69% | Training loss: 0.6869804594251845
Epoch: 56 | Iteration number: [3160/4518] 69% | Training loss: 0.6869806641642051
Epoch: 56 | Iteration number: [3170/4518] 70% | Training loss: 0.6869768264729894
Epoch: 56 | Iteration number: [3180/4518] 70% | Training loss: 0.6869751656955143
Epoch: 56 | Iteration number: [3190/4518] 70% | Training loss: 0.6869751498990672
Epoch: 56 | Iteration number: [3200/4518] 70% | Training loss: 0.6869762305729091
Epoch: 56 | Iteration number: [3210/4518] 71% | Training loss: 0.6869767274254951
Epoch: 56 | Iteration number: [3220/4518] 71% | Training loss: 0.6869781426391246
Epoch: 56 | Iteration number: [3230/4518] 71% | Training loss: 0.6869779145200924
Epoch: 56 | Iteration number: [3240/4518] 71% | Training loss: 0.6869781173489712
Epoch: 56 | Iteration number: [3250/4518] 71% | Training loss: 0.6869788940869845
Epoch: 56 | Iteration number: [3260/4518] 72% | Training loss: 0.6869796499884202
Epoch: 56 | Iteration number: [3270/4518] 72% | Training loss: 0.686980117351637
Epoch: 56 | Iteration number: [3280/4518] 72% | Training loss: 0.6869789927470975
Epoch: 56 | Iteration number: [3290/4518] 72% | Training loss: 0.6869749421406662
Epoch: 56 | Iteration number: [3300/4518] 73% | Training loss: 0.6869764852704424
Epoch: 56 | Iteration number: [3310/4518] 73% | Training loss: 0.686979047481387
Epoch: 56 | Iteration number: [3320/4518] 73% | Training loss: 0.6869805042104549
Epoch: 56 | Iteration number: [3330/4518] 73% | Training loss: 0.6869729855218091
Epoch: 56 | Iteration number: [3340/4518] 73% | Training loss: 0.6869700005489909
Epoch: 56 | Iteration number: [3350/4518] 74% | Training loss: 0.6869703583575006
Epoch: 56 | Iteration number: [3360/4518] 74% | Training loss: 0.686967502073163
Epoch: 56 | Iteration number: [3370/4518] 74% | Training loss: 0.6869659479187928
Epoch: 56 | Iteration number: [3380/4518] 74% | Training loss: 0.6869673771618386
Epoch: 56 | Iteration number: [3390/4518] 75% | Training loss: 0.6869674180812892
Epoch: 56 | Iteration number: [3400/4518] 75% | Training loss: 0.6869698843885871
Epoch: 56 | Iteration number: [3410/4518] 75% | Training loss: 0.6869702157736524
Epoch: 56 | Iteration number: [3420/4518] 75% | Training loss: 0.6869718755720652
Epoch: 56 | Iteration number: [3430/4518] 75% | Training loss: 0.6869763736474618
Epoch: 56 | Iteration number: [3440/4518] 76% | Training loss: 0.6869767723215181
Epoch: 56 | Iteration number: [3450/4518] 76% | Training loss: 0.6869731223410455
Epoch: 56 | Iteration number: [3460/4518] 76% | Training loss: 0.6869713553286702
Epoch: 56 | Iteration number: [3470/4518] 76% | Training loss: 0.6869659648161457
Epoch: 56 | Iteration number: [3480/4518] 77% | Training loss: 0.6869676782653249
Epoch: 56 | Iteration number: [3490/4518] 77% | Training loss: 0.6869677857034185
Epoch: 56 | Iteration number: [3500/4518] 77% | Training loss: 0.6869662144354411
Epoch: 56 | Iteration number: [3510/4518] 77% | Training loss: 0.6869631010582644
Epoch: 56 | Iteration number: [3520/4518] 77% | Training loss: 0.6869614154947075
Epoch: 56 | Iteration number: [3530/4518] 78% | Training loss: 0.6869622537333296
Epoch: 56 | Iteration number: [3540/4518] 78% | Training loss: 0.686959529293459
Epoch: 56 | Iteration number: [3550/4518] 78% | Training loss: 0.6869589723835529
Epoch: 56 | Iteration number: [3560/4518] 78% | Training loss: 0.6869580954815565
Epoch: 56 | Iteration number: [3570/4518] 79% | Training loss: 0.6869600818103769
Epoch: 56 | Iteration number: [3580/4518] 79% | Training loss: 0.6869579456538462
Epoch: 56 | Iteration number: [3590/4518] 79% | Training loss: 0.6869557278235975
Epoch: 56 | Iteration number: [3600/4518] 79% | Training loss: 0.6869560456110372
Epoch: 56 | Iteration number: [3610/4518] 79% | Training loss: 0.6869537242726936
Epoch: 56 | Iteration number: [3620/4518] 80% | Training loss: 0.6869531122689748
Epoch: 56 | Iteration number: [3630/4518] 80% | Training loss: 0.6869536944985718
Epoch: 56 | Iteration number: [3640/4518] 80% | Training loss: 0.6869517375807186
Epoch: 56 | Iteration number: [3650/4518] 80% | Training loss: 0.6869503460355001
Epoch: 56 | Iteration number: [3660/4518] 81% | Training loss: 0.6869496401216163
Epoch: 56 | Iteration number: [3670/4518] 81% | Training loss: 0.6869516703023573
Epoch: 56 | Iteration number: [3680/4518] 81% | Training loss: 0.6869533582550028
Epoch: 56 | Iteration number: [3690/4518] 81% | Training loss: 0.6869466759001983
Epoch: 56 | Iteration number: [3700/4518] 81% | Training loss: 0.6869494545459748
Epoch: 56 | Iteration number: [3710/4518] 82% | Training loss: 0.6869462874861098
Epoch: 56 | Iteration number: [3720/4518] 82% | Training loss: 0.686947385758482
Epoch: 56 | Iteration number: [3730/4518] 82% | Training loss: 0.68694682583093
Epoch: 56 | Iteration number: [3740/4518] 82% | Training loss: 0.6869493442582574
Epoch: 56 | Iteration number: [3750/4518] 83% | Training loss: 0.6869487308820089
Epoch: 56 | Iteration number: [3760/4518] 83% | Training loss: 0.6869494116369714
Epoch: 56 | Iteration number: [3770/4518] 83% | Training loss: 0.686952334436877
Epoch: 56 | Iteration number: [3780/4518] 83% | Training loss: 0.6869527454256381
Epoch: 56 | Iteration number: [3790/4518] 83% | Training loss: 0.6869547072532624
Epoch: 56 | Iteration number: [3800/4518] 84% | Training loss: 0.6869565915590838
Epoch: 56 | Iteration number: [3810/4518] 84% | Training loss: 0.6869539059991912
Epoch: 56 | Iteration number: [3820/4518] 84% | Training loss: 0.6869535495473452
Epoch: 56 | Iteration number: [3830/4518] 84% | Training loss: 0.6869555130639836
Epoch: 56 | Iteration number: [3840/4518] 84% | Training loss: 0.6869550509688754
Epoch: 56 | Iteration number: [3850/4518] 85% | Training loss: 0.686957124889671
Epoch: 56 | Iteration number: [3860/4518] 85% | Training loss: 0.6869592813475762
Epoch: 56 | Iteration number: [3870/4518] 85% | Training loss: 0.6869586255199225
Epoch: 56 | Iteration number: [3880/4518] 85% | Training loss: 0.6869589949545172
Epoch: 56 | Iteration number: [3890/4518] 86% | Training loss: 0.6869605040335717
Epoch: 56 | Iteration number: [3900/4518] 86% | Training loss: 0.6869577538355803
Epoch: 56 | Iteration number: [3910/4518] 86% | Training loss: 0.6869586021241629
Epoch: 56 | Iteration number: [3920/4518] 86% | Training loss: 0.6869582626892596
Epoch: 56 | Iteration number: [3930/4518] 86% | Training loss: 0.6869589304499347
Epoch: 56 | Iteration number: [3940/4518] 87% | Training loss: 0.6869594156893377
Epoch: 56 | Iteration number: [3950/4518] 87% | Training loss: 0.6869568811489057
Epoch: 56 | Iteration number: [3960/4518] 87% | Training loss: 0.6869603905412885
Epoch: 56 | Iteration number: [3970/4518] 87% | Training loss: 0.6869603038284581
Epoch: 56 | Iteration number: [3980/4518] 88% | Training loss: 0.6869623553363522
Epoch: 56 | Iteration number: [3990/4518] 88% | Training loss: 0.6869611500498645
Epoch: 56 | Iteration number: [4000/4518] 88% | Training loss: 0.6869563220441341
Epoch: 56 | Iteration number: [4010/4518] 88% | Training loss: 0.6869601309299469
Epoch: 56 | Iteration number: [4020/4518] 88% | Training loss: 0.6869612989140981
Epoch: 56 | Iteration number: [4030/4518] 89% | Training loss: 0.6869559192184184
Epoch: 56 | Iteration number: [4040/4518] 89% | Training loss: 0.6869585897367779
Epoch: 56 | Iteration number: [4050/4518] 89% | Training loss: 0.6869600520163407
Epoch: 56 | Iteration number: [4060/4518] 89% | Training loss: 0.6869570333675797
Epoch: 56 | Iteration number: [4070/4518] 90% | Training loss: 0.6869588790273784
Epoch: 56 | Iteration number: [4080/4518] 90% | Training loss: 0.6869584201451611
Epoch: 56 | Iteration number: [4090/4518] 90% | Training loss: 0.6869581140923908
Epoch: 56 | Iteration number: [4100/4518] 90% | Training loss: 0.6869578706636661
Epoch: 56 | Iteration number: [4110/4518] 90% | Training loss: 0.6869587237672504
Epoch: 56 | Iteration number: [4120/4518] 91% | Training loss: 0.6869578436306379
Epoch: 56 | Iteration number: [4130/4518] 91% | Training loss: 0.6869558632229489
Epoch: 56 | Iteration number: [4140/4518] 91% | Training loss: 0.6869538897909404
Epoch: 56 | Iteration number: [4150/4518] 91% | Training loss: 0.6869508786086577
Epoch: 56 | Iteration number: [4160/4518] 92% | Training loss: 0.6869523308741359
Epoch: 56 | Iteration number: [4170/4518] 92% | Training loss: 0.6869528970558294
Epoch: 56 | Iteration number: [4180/4518] 92% | Training loss: 0.686955229474597
Epoch: 56 | Iteration number: [4190/4518] 92% | Training loss: 0.6869578176722606
Epoch: 56 | Iteration number: [4200/4518] 92% | Training loss: 0.6869584185026941
Epoch: 56 | Iteration number: [4210/4518] 93% | Training loss: 0.6869607123371541
Epoch: 56 | Iteration number: [4220/4518] 93% | Training loss: 0.6869616131788181
Epoch: 56 | Iteration number: [4230/4518] 93% | Training loss: 0.6869643594919931
Epoch: 56 | Iteration number: [4240/4518] 93% | Training loss: 0.6869620756720597
Epoch: 56 | Iteration number: [4250/4518] 94% | Training loss: 0.6869637576551998
Epoch: 56 | Iteration number: [4260/4518] 94% | Training loss: 0.6869644183927859
Epoch: 56 | Iteration number: [4270/4518] 94% | Training loss: 0.6869638372640141
Epoch: 56 | Iteration number: [4280/4518] 94% | Training loss: 0.6869627379089872
Epoch: 56 | Iteration number: [4290/4518] 94% | Training loss: 0.6869621108322989
Epoch: 56 | Iteration number: [4300/4518] 95% | Training loss: 0.6869605524456778
Epoch: 56 | Iteration number: [4310/4518] 95% | Training loss: 0.6869569242830343
Epoch: 56 | Iteration number: [4320/4518] 95% | Training loss: 0.686957442443128
Epoch: 56 | Iteration number: [4330/4518] 95% | Training loss: 0.6869578254002622
Epoch: 56 | Iteration number: [4340/4518] 96% | Training loss: 0.6869555520297196
Epoch: 56 | Iteration number: [4350/4518] 96% | Training loss: 0.6869572665636566
Epoch: 56 | Iteration number: [4360/4518] 96% | Training loss: 0.6869582599456158
Epoch: 56 | Iteration number: [4370/4518] 96% | Training loss: 0.686956940349234
Epoch: 56 | Iteration number: [4380/4518] 96% | Training loss: 0.6869582329710869
Epoch: 56 | Iteration number: [4390/4518] 97% | Training loss: 0.6869563362049893
Epoch: 56 | Iteration number: [4400/4518] 97% | Training loss: 0.6869544153863734
Epoch: 56 | Iteration number: [4410/4518] 97% | Training loss: 0.6869550998383909
Epoch: 56 | Iteration number: [4420/4518] 97% | Training loss: 0.6869531997053872
Epoch: 56 | Iteration number: [4430/4518] 98% | Training loss: 0.6869557713950999
Epoch: 56 | Iteration number: [4440/4518] 98% | Training loss: 0.6869567359755705
Epoch: 56 | Iteration number: [4450/4518] 98% | Training loss: 0.6869553544816006
Epoch: 56 | Iteration number: [4460/4518] 98% | Training loss: 0.6869554783864941
Epoch: 56 | Iteration number: [4470/4518] 98% | Training loss: 0.6869560662131982
Epoch: 56 | Iteration number: [4480/4518] 99% | Training loss: 0.6869541218770402
Epoch: 56 | Iteration number: [4490/4518] 99% | Training loss: 0.6869539523443294
Epoch: 56 | Iteration number: [4500/4518] 99% | Training loss: 0.6869531088007821
Epoch: 56 | Iteration number: [4510/4518] 99% | Training loss: 0.6869551422194208

 End of epoch: 56 | Train Loss: 0.6868019832241266 | Training Time: 640 

 End of epoch: 56 | Eval Loss: 0.6899049792970929 | Evaluating Time: 17 
Epoch: 57 | Iteration number: [10/4518] 0% | Training loss: 0.7553676962852478
Epoch: 57 | Iteration number: [20/4518] 0% | Training loss: 0.7211361199617385
Epoch: 57 | Iteration number: [30/4518] 0% | Training loss: 0.7098451832930247
Epoch: 57 | Iteration number: [40/4518] 0% | Training loss: 0.7041511371731758
Epoch: 57 | Iteration number: [50/4518] 1% | Training loss: 0.7007447385787964
Epoch: 57 | Iteration number: [60/4518] 1% | Training loss: 0.6983885347843171
Epoch: 57 | Iteration number: [70/4518] 1% | Training loss: 0.6968403007302966
Epoch: 57 | Iteration number: [80/4518] 1% | Training loss: 0.6954922936856747
Epoch: 57 | Iteration number: [90/4518] 1% | Training loss: 0.6945945309268103
Epoch: 57 | Iteration number: [100/4518] 2% | Training loss: 0.6938532674312592
Epoch: 57 | Iteration number: [110/4518] 2% | Training loss: 0.6932882173494859
Epoch: 57 | Iteration number: [120/4518] 2% | Training loss: 0.6927380601565043
Epoch: 57 | Iteration number: [130/4518] 2% | Training loss: 0.6922671258449554
Epoch: 57 | Iteration number: [140/4518] 3% | Training loss: 0.6918196759053639
Epoch: 57 | Iteration number: [150/4518] 3% | Training loss: 0.6914652733008066
Epoch: 57 | Iteration number: [160/4518] 3% | Training loss: 0.691116550937295
Epoch: 57 | Iteration number: [170/4518] 3% | Training loss: 0.6908188150209539
Epoch: 57 | Iteration number: [180/4518] 3% | Training loss: 0.6906623704565896
Epoch: 57 | Iteration number: [190/4518] 4% | Training loss: 0.6905075264604468
Epoch: 57 | Iteration number: [200/4518] 4% | Training loss: 0.6903359466791152
Epoch: 57 | Iteration number: [210/4518] 4% | Training loss: 0.6902149078391847
Epoch: 57 | Iteration number: [220/4518] 4% | Training loss: 0.6900528466159647
Epoch: 57 | Iteration number: [230/4518] 5% | Training loss: 0.6899238472399505
Epoch: 57 | Iteration number: [240/4518] 5% | Training loss: 0.6897632745405038
Epoch: 57 | Iteration number: [250/4518] 5% | Training loss: 0.6896343669891357
Epoch: 57 | Iteration number: [260/4518] 5% | Training loss: 0.689532742362756
Epoch: 57 | Iteration number: [270/4518] 5% | Training loss: 0.6893879877196418
Epoch: 57 | Iteration number: [280/4518] 6% | Training loss: 0.6892930697117533
Epoch: 57 | Iteration number: [290/4518] 6% | Training loss: 0.6891809948559465
Epoch: 57 | Iteration number: [300/4518] 6% | Training loss: 0.6891038463513056
Epoch: 57 | Iteration number: [310/4518] 6% | Training loss: 0.6890349805355072
Epoch: 57 | Iteration number: [320/4518] 7% | Training loss: 0.6889693550765514
Epoch: 57 | Iteration number: [330/4518] 7% | Training loss: 0.6889048455339489
Epoch: 57 | Iteration number: [340/4518] 7% | Training loss: 0.6888624685652116
Epoch: 57 | Iteration number: [350/4518] 7% | Training loss: 0.6888091548851558
Epoch: 57 | Iteration number: [360/4518] 7% | Training loss: 0.6887226715683937
Epoch: 57 | Iteration number: [370/4518] 8% | Training loss: 0.6886693563010241
Epoch: 57 | Iteration number: [380/4518] 8% | Training loss: 0.6886263604226865
Epoch: 57 | Iteration number: [390/4518] 8% | Training loss: 0.6885591508486332
Epoch: 57 | Iteration number: [400/4518] 8% | Training loss: 0.6885179144144058
Epoch: 57 | Iteration number: [410/4518] 9% | Training loss: 0.6885248566546092
Epoch: 57 | Iteration number: [420/4518] 9% | Training loss: 0.6885165873027983
Epoch: 57 | Iteration number: [430/4518] 9% | Training loss: 0.6884758677593498
Epoch: 57 | Iteration number: [440/4518] 9% | Training loss: 0.6883942727338184
Epoch: 57 | Iteration number: [450/4518] 9% | Training loss: 0.6883529759777917
Epoch: 57 | Iteration number: [460/4518] 10% | Training loss: 0.688293252431828
Epoch: 57 | Iteration number: [470/4518] 10% | Training loss: 0.688273616166825
Epoch: 57 | Iteration number: [480/4518] 10% | Training loss: 0.6882189717143774
Epoch: 57 | Iteration number: [490/4518] 10% | Training loss: 0.6881961599904663
Epoch: 57 | Iteration number: [500/4518] 11% | Training loss: 0.6881644208431243
Epoch: 57 | Iteration number: [510/4518] 11% | Training loss: 0.6881343268880658
Epoch: 57 | Iteration number: [520/4518] 11% | Training loss: 0.6881067293194624
Epoch: 57 | Iteration number: [530/4518] 11% | Training loss: 0.6880670334932939
Epoch: 57 | Iteration number: [540/4518] 11% | Training loss: 0.6880451966215063
Epoch: 57 | Iteration number: [550/4518] 12% | Training loss: 0.6880280963941053
Epoch: 57 | Iteration number: [560/4518] 12% | Training loss: 0.6880319376076971
Epoch: 57 | Iteration number: [570/4518] 12% | Training loss: 0.6879860335274747
Epoch: 57 | Iteration number: [580/4518] 12% | Training loss: 0.687982867298455
Epoch: 57 | Iteration number: [590/4518] 13% | Training loss: 0.6879650293770483
Epoch: 57 | Iteration number: [600/4518] 13% | Training loss: 0.6879344672958057
Epoch: 57 | Iteration number: [610/4518] 13% | Training loss: 0.6879335166000929
Epoch: 57 | Iteration number: [620/4518] 13% | Training loss: 0.68791849411303
Epoch: 57 | Iteration number: [630/4518] 13% | Training loss: 0.6878853616260346
Epoch: 57 | Iteration number: [640/4518] 14% | Training loss: 0.6878650409169496
Epoch: 57 | Iteration number: [650/4518] 14% | Training loss: 0.6878371135088114
Epoch: 57 | Iteration number: [660/4518] 14% | Training loss: 0.687826710487857
Epoch: 57 | Iteration number: [670/4518] 14% | Training loss: 0.6878128573076049
Epoch: 57 | Iteration number: [680/4518] 15% | Training loss: 0.6877596154808998
Epoch: 57 | Iteration number: [690/4518] 15% | Training loss: 0.6877368162507597
Epoch: 57 | Iteration number: [700/4518] 15% | Training loss: 0.6877230364935739
Epoch: 57 | Iteration number: [710/4518] 15% | Training loss: 0.6877028878306
Epoch: 57 | Iteration number: [720/4518] 15% | Training loss: 0.6876733668148518
Epoch: 57 | Iteration number: [730/4518] 16% | Training loss: 0.6876740568304716
Epoch: 57 | Iteration number: [740/4518] 16% | Training loss: 0.6876597251441028
Epoch: 57 | Iteration number: [750/4518] 16% | Training loss: 0.6876554310321807
Epoch: 57 | Iteration number: [760/4518] 16% | Training loss: 0.6876377970764511
Epoch: 57 | Iteration number: [770/4518] 17% | Training loss: 0.6876165367566146
Epoch: 57 | Iteration number: [780/4518] 17% | Training loss: 0.687605791978347
Epoch: 57 | Iteration number: [790/4518] 17% | Training loss: 0.6876128693170185
Epoch: 57 | Iteration number: [800/4518] 17% | Training loss: 0.6875946128368378
Epoch: 57 | Iteration number: [810/4518] 17% | Training loss: 0.6875765031502571
Epoch: 57 | Iteration number: [820/4518] 18% | Training loss: 0.6875629278217874
Epoch: 57 | Iteration number: [830/4518] 18% | Training loss: 0.6875525267727404
Epoch: 57 | Iteration number: [840/4518] 18% | Training loss: 0.6875486944402968
Epoch: 57 | Iteration number: [850/4518] 18% | Training loss: 0.687523151846493
Epoch: 57 | Iteration number: [860/4518] 19% | Training loss: 0.6875285614368527
Epoch: 57 | Iteration number: [870/4518] 19% | Training loss: 0.687518943383776
Epoch: 57 | Iteration number: [880/4518] 19% | Training loss: 0.6875318916683847
Epoch: 57 | Iteration number: [890/4518] 19% | Training loss: 0.6875044336479701
Epoch: 57 | Iteration number: [900/4518] 19% | Training loss: 0.6875041523244646
Epoch: 57 | Iteration number: [910/4518] 20% | Training loss: 0.6874907416956765
Epoch: 57 | Iteration number: [920/4518] 20% | Training loss: 0.6874814516176349
Epoch: 57 | Iteration number: [930/4518] 20% | Training loss: 0.6874718667999391
Epoch: 57 | Iteration number: [940/4518] 20% | Training loss: 0.687457054092529
Epoch: 57 | Iteration number: [950/4518] 21% | Training loss: 0.6874445292824193
Epoch: 57 | Iteration number: [960/4518] 21% | Training loss: 0.6874372081831097
Epoch: 57 | Iteration number: [970/4518] 21% | Training loss: 0.6874345209795175
Epoch: 57 | Iteration number: [980/4518] 21% | Training loss: 0.6874166915611345
Epoch: 57 | Iteration number: [990/4518] 21% | Training loss: 0.6873905221019129
Epoch: 57 | Iteration number: [1000/4518] 22% | Training loss: 0.6873719995617866
Epoch: 57 | Iteration number: [1010/4518] 22% | Training loss: 0.6873522866480422
Epoch: 57 | Iteration number: [1020/4518] 22% | Training loss: 0.6873533220267763
Epoch: 57 | Iteration number: [1030/4518] 22% | Training loss: 0.6873430640373415
Epoch: 57 | Iteration number: [1040/4518] 23% | Training loss: 0.6873337551378287
Epoch: 57 | Iteration number: [1050/4518] 23% | Training loss: 0.6873369001774561
Epoch: 57 | Iteration number: [1060/4518] 23% | Training loss: 0.6873268767347875
Epoch: 57 | Iteration number: [1070/4518] 23% | Training loss: 0.6873239742261227
Epoch: 57 | Iteration number: [1080/4518] 23% | Training loss: 0.6873165104676175
Epoch: 57 | Iteration number: [1090/4518] 24% | Training loss: 0.6873000812639883
Epoch: 57 | Iteration number: [1100/4518] 24% | Training loss: 0.6872925178571181
Epoch: 57 | Iteration number: [1110/4518] 24% | Training loss: 0.6872755893178888
Epoch: 57 | Iteration number: [1120/4518] 24% | Training loss: 0.6872817303985357
Epoch: 57 | Iteration number: [1130/4518] 25% | Training loss: 0.6872704128775976
Epoch: 57 | Iteration number: [1140/4518] 25% | Training loss: 0.6872653332718631
Epoch: 57 | Iteration number: [1150/4518] 25% | Training loss: 0.6872685305450273
Epoch: 57 | Iteration number: [1160/4518] 25% | Training loss: 0.6872639055395948
Epoch: 57 | Iteration number: [1170/4518] 25% | Training loss: 0.6872693450532408
Epoch: 57 | Iteration number: [1180/4518] 26% | Training loss: 0.6872684585340952
Epoch: 57 | Iteration number: [1190/4518] 26% | Training loss: 0.6872692125685075
Epoch: 57 | Iteration number: [1200/4518] 26% | Training loss: 0.6872781385978063
Epoch: 57 | Iteration number: [1210/4518] 26% | Training loss: 0.6872884877949706
Epoch: 57 | Iteration number: [1220/4518] 27% | Training loss: 0.6872808832614148
Epoch: 57 | Iteration number: [1230/4518] 27% | Training loss: 0.6872815215006107
Epoch: 57 | Iteration number: [1240/4518] 27% | Training loss: 0.6872785209167388
Epoch: 57 | Iteration number: [1250/4518] 27% | Training loss: 0.6872806632518769
Epoch: 57 | Iteration number: [1260/4518] 27% | Training loss: 0.6872640064784459
Epoch: 57 | Iteration number: [1270/4518] 28% | Training loss: 0.6872680438315775
Epoch: 57 | Iteration number: [1280/4518] 28% | Training loss: 0.6872694183606655
Epoch: 57 | Iteration number: [1290/4518] 28% | Training loss: 0.6872688268044198
Epoch: 57 | Iteration number: [1300/4518] 28% | Training loss: 0.6872658435656475
Epoch: 57 | Iteration number: [1310/4518] 28% | Training loss: 0.6872703418476891
Epoch: 57 | Iteration number: [1320/4518] 29% | Training loss: 0.6872712330384688
Epoch: 57 | Iteration number: [1330/4518] 29% | Training loss: 0.6872626822245749
Epoch: 57 | Iteration number: [1340/4518] 29% | Training loss: 0.6872513947202199
Epoch: 57 | Iteration number: [1350/4518] 29% | Training loss: 0.6872511038073787
Epoch: 57 | Iteration number: [1360/4518] 30% | Training loss: 0.6872548997840461
Epoch: 57 | Iteration number: [1370/4518] 30% | Training loss: 0.6872541458067233
Epoch: 57 | Iteration number: [1380/4518] 30% | Training loss: 0.6872518961844237
Epoch: 57 | Iteration number: [1390/4518] 30% | Training loss: 0.6872455909097795
Epoch: 57 | Iteration number: [1400/4518] 30% | Training loss: 0.6872453347699983
Epoch: 57 | Iteration number: [1410/4518] 31% | Training loss: 0.6872358666666856
Epoch: 57 | Iteration number: [1420/4518] 31% | Training loss: 0.68723818491882
Epoch: 57 | Iteration number: [1430/4518] 31% | Training loss: 0.687240191022833
Epoch: 57 | Iteration number: [1440/4518] 31% | Training loss: 0.687240955978632
Epoch: 57 | Iteration number: [1450/4518] 32% | Training loss: 0.6872367080326738
Epoch: 57 | Iteration number: [1460/4518] 32% | Training loss: 0.6872305615307533
Epoch: 57 | Iteration number: [1470/4518] 32% | Training loss: 0.6872310027784231
Epoch: 57 | Iteration number: [1480/4518] 32% | Training loss: 0.6872241635580321
Epoch: 57 | Iteration number: [1490/4518] 32% | Training loss: 0.68722255898002
Epoch: 57 | Iteration number: [1500/4518] 33% | Training loss: 0.6872197746435801
Epoch: 57 | Iteration number: [1510/4518] 33% | Training loss: 0.6872195937775618
Epoch: 57 | Iteration number: [1520/4518] 33% | Training loss: 0.6872199948681028
Epoch: 57 | Iteration number: [1530/4518] 33% | Training loss: 0.6872229722979801
Epoch: 57 | Iteration number: [1540/4518] 34% | Training loss: 0.6872207710882285
Epoch: 57 | Iteration number: [1550/4518] 34% | Training loss: 0.6872175765422083
Epoch: 57 | Iteration number: [1560/4518] 34% | Training loss: 0.6872100863319177
Epoch: 57 | Iteration number: [1570/4518] 34% | Training loss: 0.6872008243563829
Epoch: 57 | Iteration number: [1580/4518] 34% | Training loss: 0.6871985578084294
Epoch: 57 | Iteration number: [1590/4518] 35% | Training loss: 0.6871914609798095
Epoch: 57 | Iteration number: [1600/4518] 35% | Training loss: 0.687190948575735
Epoch: 57 | Iteration number: [1610/4518] 35% | Training loss: 0.6871825438108503
Epoch: 57 | Iteration number: [1620/4518] 35% | Training loss: 0.6871776762935851
Epoch: 57 | Iteration number: [1630/4518] 36% | Training loss: 0.6871745667574596
Epoch: 57 | Iteration number: [1640/4518] 36% | Training loss: 0.6871724664438061
Epoch: 57 | Iteration number: [1650/4518] 36% | Training loss: 0.6871688271291329
Epoch: 57 | Iteration number: [1660/4518] 36% | Training loss: 0.6871679072279528
Epoch: 57 | Iteration number: [1670/4518] 36% | Training loss: 0.687160410031587
Epoch: 57 | Iteration number: [1680/4518] 37% | Training loss: 0.6871568739769005
Epoch: 57 | Iteration number: [1690/4518] 37% | Training loss: 0.6871530982869617
Epoch: 57 | Iteration number: [1700/4518] 37% | Training loss: 0.6871384636444204
Epoch: 57 | Iteration number: [1710/4518] 37% | Training loss: 0.6871465186975155
Epoch: 57 | Iteration number: [1720/4518] 38% | Training loss: 0.6871440693042999
Epoch: 57 | Iteration number: [1730/4518] 38% | Training loss: 0.6871452899337503
Epoch: 57 | Iteration number: [1740/4518] 38% | Training loss: 0.6871419968276188
Epoch: 57 | Iteration number: [1750/4518] 38% | Training loss: 0.687141909973962
Epoch: 57 | Iteration number: [1760/4518] 38% | Training loss: 0.6871395304121755
Epoch: 57 | Iteration number: [1770/4518] 39% | Training loss: 0.6871351785242221
Epoch: 57 | Iteration number: [1780/4518] 39% | Training loss: 0.6871448756268855
Epoch: 57 | Iteration number: [1790/4518] 39% | Training loss: 0.687149640767934
Epoch: 57 | Iteration number: [1800/4518] 39% | Training loss: 0.6871458960572878
Epoch: 57 | Iteration number: [1810/4518] 40% | Training loss: 0.6871454759855955
Epoch: 57 | Iteration number: [1820/4518] 40% | Training loss: 0.68713405921564
Epoch: 57 | Iteration number: [1830/4518] 40% | Training loss: 0.6871366504111577
Epoch: 57 | Iteration number: [1840/4518] 40% | Training loss: 0.687124386559362
Epoch: 57 | Iteration number: [1850/4518] 40% | Training loss: 0.6871211259429519
Epoch: 57 | Iteration number: [1860/4518] 41% | Training loss: 0.6871202815604466
Epoch: 57 | Iteration number: [1870/4518] 41% | Training loss: 0.6871156189212188
Epoch: 57 | Iteration number: [1880/4518] 41% | Training loss: 0.6871135625433414
Epoch: 57 | Iteration number: [1890/4518] 41% | Training loss: 0.6871142054045641
Epoch: 57 | Iteration number: [1900/4518] 42% | Training loss: 0.6871164807834124
Epoch: 57 | Iteration number: [1910/4518] 42% | Training loss: 0.6871114348865929
Epoch: 57 | Iteration number: [1920/4518] 42% | Training loss: 0.6871142187776665
Epoch: 57 | Iteration number: [1930/4518] 42% | Training loss: 0.6871083252170543
Epoch: 57 | Iteration number: [1940/4518] 42% | Training loss: 0.6871051994181171
Epoch: 57 | Iteration number: [1950/4518] 43% | Training loss: 0.6871100328518794
Epoch: 57 | Iteration number: [1960/4518] 43% | Training loss: 0.6871107597436223
Epoch: 57 | Iteration number: [1970/4518] 43% | Training loss: 0.6871098630924515
Epoch: 57 | Iteration number: [1980/4518] 43% | Training loss: 0.6871059334037279
Epoch: 57 | Iteration number: [1990/4518] 44% | Training loss: 0.6871066118904094
Epoch: 57 | Iteration number: [2000/4518] 44% | Training loss: 0.6871047988235951
Epoch: 57 | Iteration number: [2010/4518] 44% | Training loss: 0.6870991595052368
Epoch: 57 | Iteration number: [2020/4518] 44% | Training loss: 0.6870968673193809
Epoch: 57 | Iteration number: [2030/4518] 44% | Training loss: 0.6870937647784284
Epoch: 57 | Iteration number: [2040/4518] 45% | Training loss: 0.6870972846068588
Epoch: 57 | Iteration number: [2050/4518] 45% | Training loss: 0.6870926605782858
Epoch: 57 | Iteration number: [2060/4518] 45% | Training loss: 0.6870976658990082
Epoch: 57 | Iteration number: [2070/4518] 45% | Training loss: 0.6870972509545404
Epoch: 57 | Iteration number: [2080/4518] 46% | Training loss: 0.6870952366063228
Epoch: 57 | Iteration number: [2090/4518] 46% | Training loss: 0.6870931971871682
Epoch: 57 | Iteration number: [2100/4518] 46% | Training loss: 0.6870876018773941
Epoch: 57 | Iteration number: [2110/4518] 46% | Training loss: 0.687084977575953
Epoch: 57 | Iteration number: [2120/4518] 46% | Training loss: 0.6870863311695603
Epoch: 57 | Iteration number: [2130/4518] 47% | Training loss: 0.6870874641366967
Epoch: 57 | Iteration number: [2140/4518] 47% | Training loss: 0.6870862497626063
Epoch: 57 | Iteration number: [2150/4518] 47% | Training loss: 0.6870867663206056
Epoch: 57 | Iteration number: [2160/4518] 47% | Training loss: 0.6870868640917319
Epoch: 57 | Iteration number: [2170/4518] 48% | Training loss: 0.6870890861832052
Epoch: 57 | Iteration number: [2180/4518] 48% | Training loss: 0.6870918088823283
Epoch: 57 | Iteration number: [2190/4518] 48% | Training loss: 0.6870841743739228
Epoch: 57 | Iteration number: [2200/4518] 48% | Training loss: 0.6870812892101028
Epoch: 57 | Iteration number: [2210/4518] 48% | Training loss: 0.6870839694236738
Epoch: 57 | Iteration number: [2220/4518] 49% | Training loss: 0.6870855788658331
Epoch: 57 | Iteration number: [2230/4518] 49% | Training loss: 0.687078732252121
Epoch: 57 | Iteration number: [2240/4518] 49% | Training loss: 0.6870739958914263
Epoch: 57 | Iteration number: [2250/4518] 49% | Training loss: 0.6870818621582455
Epoch: 57 | Iteration number: [2260/4518] 50% | Training loss: 0.6870808940018173
Epoch: 57 | Iteration number: [2270/4518] 50% | Training loss: 0.6870808846362362
Epoch: 57 | Iteration number: [2280/4518] 50% | Training loss: 0.6870719910975088
Epoch: 57 | Iteration number: [2290/4518] 50% | Training loss: 0.6870750312721885
Epoch: 57 | Iteration number: [2300/4518] 50% | Training loss: 0.6870747270791427
Epoch: 57 | Iteration number: [2310/4518] 51% | Training loss: 0.6870732769821629
Epoch: 57 | Iteration number: [2320/4518] 51% | Training loss: 0.6870780763184202
Epoch: 57 | Iteration number: [2330/4518] 51% | Training loss: 0.6870752303897055
Epoch: 57 | Iteration number: [2340/4518] 51% | Training loss: 0.6870727071140567
Epoch: 57 | Iteration number: [2350/4518] 52% | Training loss: 0.6870689250560517
Epoch: 57 | Iteration number: [2360/4518] 52% | Training loss: 0.687064380059808
Epoch: 57 | Iteration number: [2370/4518] 52% | Training loss: 0.687065231473134
Epoch: 57 | Iteration number: [2380/4518] 52% | Training loss: 0.6870640307414432
Epoch: 57 | Iteration number: [2390/4518] 52% | Training loss: 0.687065338963744
Epoch: 57 | Iteration number: [2400/4518] 53% | Training loss: 0.6870636903246243
Epoch: 57 | Iteration number: [2410/4518] 53% | Training loss: 0.6870611342899038
Epoch: 57 | Iteration number: [2420/4518] 53% | Training loss: 0.6870626094666394
Epoch: 57 | Iteration number: [2430/4518] 53% | Training loss: 0.6870634315435779
Epoch: 57 | Iteration number: [2440/4518] 54% | Training loss: 0.6870634118064505
Epoch: 57 | Iteration number: [2450/4518] 54% | Training loss: 0.6870613673268532
Epoch: 57 | Iteration number: [2460/4518] 54% | Training loss: 0.6870651328224476
Epoch: 57 | Iteration number: [2470/4518] 54% | Training loss: 0.6870641758326094
Epoch: 57 | Iteration number: [2480/4518] 54% | Training loss: 0.6870664839061998
Epoch: 57 | Iteration number: [2490/4518] 55% | Training loss: 0.6870631409936162
Epoch: 57 | Iteration number: [2500/4518] 55% | Training loss: 0.6870622501850128
Epoch: 57 | Iteration number: [2510/4518] 55% | Training loss: 0.6870570110609807
Epoch: 57 | Iteration number: [2520/4518] 55% | Training loss: 0.6870511572275843
Epoch: 57 | Iteration number: [2530/4518] 55% | Training loss: 0.6870495064927655
Epoch: 57 | Iteration number: [2540/4518] 56% | Training loss: 0.687052688518847
Epoch: 57 | Iteration number: [2550/4518] 56% | Training loss: 0.6870536864505095
Epoch: 57 | Iteration number: [2560/4518] 56% | Training loss: 0.6870517401723191
Epoch: 57 | Iteration number: [2570/4518] 56% | Training loss: 0.6870516366068027
Epoch: 57 | Iteration number: [2580/4518] 57% | Training loss: 0.6870507406171902
Epoch: 57 | Iteration number: [2590/4518] 57% | Training loss: 0.6870450425332117
Epoch: 57 | Iteration number: [2600/4518] 57% | Training loss: 0.6870431911945343
Epoch: 57 | Iteration number: [2610/4518] 57% | Training loss: 0.6870460679247918
Epoch: 57 | Iteration number: [2620/4518] 57% | Training loss: 0.6870456555872473
Epoch: 57 | Iteration number: [2630/4518] 58% | Training loss: 0.6870422353536004
Epoch: 57 | Iteration number: [2640/4518] 58% | Training loss: 0.6870423997667703
Epoch: 57 | Iteration number: [2650/4518] 58% | Training loss: 0.6870456818589624
Epoch: 57 | Iteration number: [2660/4518] 58% | Training loss: 0.6870424455942068
Epoch: 57 | Iteration number: [2670/4518] 59% | Training loss: 0.6870451212599037
Epoch: 57 | Iteration number: [2680/4518] 59% | Training loss: 0.6870418153814415
Epoch: 57 | Iteration number: [2690/4518] 59% | Training loss: 0.6870431266531182
Epoch: 57 | Iteration number: [2700/4518] 59% | Training loss: 0.687042513931239
Epoch: 57 | Iteration number: [2710/4518] 59% | Training loss: 0.6870437789887079
Epoch: 57 | Iteration number: [2720/4518] 60% | Training loss: 0.687042078266249
Epoch: 57 | Iteration number: [2730/4518] 60% | Training loss: 0.687040374720053
Epoch: 57 | Iteration number: [2740/4518] 60% | Training loss: 0.6870362983785406
Epoch: 57 | Iteration number: [2750/4518] 60% | Training loss: 0.6870363758043809
Epoch: 57 | Iteration number: [2760/4518] 61% | Training loss: 0.687038066983223
Epoch: 57 | Iteration number: [2770/4518] 61% | Training loss: 0.6870375369645197
Epoch: 57 | Iteration number: [2780/4518] 61% | Training loss: 0.6870417229992023
Epoch: 57 | Iteration number: [2790/4518] 61% | Training loss: 0.6870443777585115
Epoch: 57 | Iteration number: [2800/4518] 61% | Training loss: 0.6870422031198229
Epoch: 57 | Iteration number: [2810/4518] 62% | Training loss: 0.6870419654769829
Epoch: 57 | Iteration number: [2820/4518] 62% | Training loss: 0.6870351479408588
Epoch: 57 | Iteration number: [2830/4518] 62% | Training loss: 0.6870317103163514
Epoch: 57 | Iteration number: [2840/4518] 62% | Training loss: 0.6870247762807657
Epoch: 57 | Iteration number: [2850/4518] 63% | Training loss: 0.6870189241986525
Epoch: 57 | Iteration number: [2860/4518] 63% | Training loss: 0.6870178199106163
Epoch: 57 | Iteration number: [2870/4518] 63% | Training loss: 0.6870181219918388
Epoch: 57 | Iteration number: [2880/4518] 63% | Training loss: 0.6870162586991986
Epoch: 57 | Iteration number: [2890/4518] 63% | Training loss: 0.687018238920654
Epoch: 57 | Iteration number: [2900/4518] 64% | Training loss: 0.6870202554916514
Epoch: 57 | Iteration number: [2910/4518] 64% | Training loss: 0.687019447751881
Epoch: 57 | Iteration number: [2920/4518] 64% | Training loss: 0.6870235735422945
Epoch: 57 | Iteration number: [2930/4518] 64% | Training loss: 0.6870226536797989
Epoch: 57 | Iteration number: [2940/4518] 65% | Training loss: 0.6870225394055957
Epoch: 57 | Iteration number: [2950/4518] 65% | Training loss: 0.6870186234126656
Epoch: 57 | Iteration number: [2960/4518] 65% | Training loss: 0.687017984144591
Epoch: 57 | Iteration number: [2970/4518] 65% | Training loss: 0.6870173602593869
Epoch: 57 | Iteration number: [2980/4518] 65% | Training loss: 0.6870203553230171
Epoch: 57 | Iteration number: [2990/4518] 66% | Training loss: 0.6870166135870892
Epoch: 57 | Iteration number: [3000/4518] 66% | Training loss: 0.6870141408840815
Epoch: 57 | Iteration number: [3010/4518] 66% | Training loss: 0.6870127106821814
Epoch: 57 | Iteration number: [3020/4518] 66% | Training loss: 0.6870128386660127
Epoch: 57 | Iteration number: [3030/4518] 67% | Training loss: 0.6870163392902601
Epoch: 57 | Iteration number: [3040/4518] 67% | Training loss: 0.6870112725974697
Epoch: 57 | Iteration number: [3050/4518] 67% | Training loss: 0.6870120811071552
Epoch: 57 | Iteration number: [3060/4518] 67% | Training loss: 0.6870113374361025
Epoch: 57 | Iteration number: [3070/4518] 67% | Training loss: 0.6870125704168885
Epoch: 57 | Iteration number: [3080/4518] 68% | Training loss: 0.6870134516389339
Epoch: 57 | Iteration number: [3090/4518] 68% | Training loss: 0.6870105922029243
Epoch: 57 | Iteration number: [3100/4518] 68% | Training loss: 0.6870101828344407
Epoch: 57 | Iteration number: [3110/4518] 68% | Training loss: 0.687009848237421
Epoch: 57 | Iteration number: [3120/4518] 69% | Training loss: 0.6870060150439923
Epoch: 57 | Iteration number: [3130/4518] 69% | Training loss: 0.6870011317844208
Epoch: 57 | Iteration number: [3140/4518] 69% | Training loss: 0.6870023295757877
Epoch: 57 | Iteration number: [3150/4518] 69% | Training loss: 0.687001804264765
Epoch: 57 | Iteration number: [3160/4518] 69% | Training loss: 0.687003654166113
Epoch: 57 | Iteration number: [3170/4518] 70% | Training loss: 0.68700310670615
Epoch: 57 | Iteration number: [3180/4518] 70% | Training loss: 0.6870007554690043
Epoch: 57 | Iteration number: [3190/4518] 70% | Training loss: 0.6869980464347851
Epoch: 57 | Iteration number: [3200/4518] 70% | Training loss: 0.6869997190870345
Epoch: 57 | Iteration number: [3210/4518] 71% | Training loss: 0.686998880633684
Epoch: 57 | Iteration number: [3220/4518] 71% | Training loss: 0.6869997604293112
Epoch: 57 | Iteration number: [3230/4518] 71% | Training loss: 0.6869992640180853
Epoch: 57 | Iteration number: [3240/4518] 71% | Training loss: 0.6869969162860035
Epoch: 57 | Iteration number: [3250/4518] 71% | Training loss: 0.6869983256780184
Epoch: 57 | Iteration number: [3260/4518] 72% | Training loss: 0.6869975518960895
Epoch: 57 | Iteration number: [3270/4518] 72% | Training loss: 0.6869982356872034
Epoch: 57 | Iteration number: [3280/4518] 72% | Training loss: 0.6869963154196739
Epoch: 57 | Iteration number: [3290/4518] 72% | Training loss: 0.6869938107609387
Epoch: 57 | Iteration number: [3300/4518] 73% | Training loss: 0.6869976032863964
Epoch: 57 | Iteration number: [3310/4518] 73% | Training loss: 0.6869972089446204
Epoch: 57 | Iteration number: [3320/4518] 73% | Training loss: 0.6869985849562897
Epoch: 57 | Iteration number: [3330/4518] 73% | Training loss: 0.6869998497289939
Epoch: 57 | Iteration number: [3340/4518] 73% | Training loss: 0.6869970286320783
Epoch: 57 | Iteration number: [3350/4518] 74% | Training loss: 0.6869914551635287
Epoch: 57 | Iteration number: [3360/4518] 74% | Training loss: 0.6869896204521259
Epoch: 57 | Iteration number: [3370/4518] 74% | Training loss: 0.686989746267081
Epoch: 57 | Iteration number: [3380/4518] 74% | Training loss: 0.6869905915133346
Epoch: 57 | Iteration number: [3390/4518] 75% | Training loss: 0.686990081349657
Epoch: 57 | Iteration number: [3400/4518] 75% | Training loss: 0.6869886289624607
Epoch: 57 | Iteration number: [3410/4518] 75% | Training loss: 0.6869879463550982
Epoch: 57 | Iteration number: [3420/4518] 75% | Training loss: 0.68698873004021
Epoch: 57 | Iteration number: [3430/4518] 75% | Training loss: 0.6869897631966337
Epoch: 57 | Iteration number: [3440/4518] 76% | Training loss: 0.6869908550797507
Epoch: 57 | Iteration number: [3450/4518] 76% | Training loss: 0.6869894179053928
Epoch: 57 | Iteration number: [3460/4518] 76% | Training loss: 0.6869913527558994
Epoch: 57 | Iteration number: [3470/4518] 76% | Training loss: 0.6869903853028927
Epoch: 57 | Iteration number: [3480/4518] 77% | Training loss: 0.6869874319810977
Epoch: 57 | Iteration number: [3490/4518] 77% | Training loss: 0.6869875400660714
Epoch: 57 | Iteration number: [3500/4518] 77% | Training loss: 0.6869852309226989
Epoch: 57 | Iteration number: [3510/4518] 77% | Training loss: 0.6869868564639675
Epoch: 57 | Iteration number: [3520/4518] 77% | Training loss: 0.6869822413745251
Epoch: 57 | Iteration number: [3530/4518] 78% | Training loss: 0.6869840286777648
Epoch: 57 | Iteration number: [3540/4518] 78% | Training loss: 0.6869816810902902
Epoch: 57 | Iteration number: [3550/4518] 78% | Training loss: 0.6869832591943338
Epoch: 57 | Iteration number: [3560/4518] 78% | Training loss: 0.6869807156451633
Epoch: 57 | Iteration number: [3570/4518] 79% | Training loss: 0.686984936346193
Epoch: 57 | Iteration number: [3580/4518] 79% | Training loss: 0.686983946315403
Epoch: 57 | Iteration number: [3590/4518] 79% | Training loss: 0.6869852051429429
Epoch: 57 | Iteration number: [3600/4518] 79% | Training loss: 0.68698353673021
Epoch: 57 | Iteration number: [3610/4518] 79% | Training loss: 0.6869855897248287
Epoch: 57 | Iteration number: [3620/4518] 80% | Training loss: 0.6869841024526575
Epoch: 57 | Iteration number: [3630/4518] 80% | Training loss: 0.6869823002782407
Epoch: 57 | Iteration number: [3640/4518] 80% | Training loss: 0.6869791119144513
Epoch: 57 | Iteration number: [3650/4518] 80% | Training loss: 0.6869780428115636
Epoch: 57 | Iteration number: [3660/4518] 81% | Training loss: 0.6869761273834875
Epoch: 57 | Iteration number: [3670/4518] 81% | Training loss: 0.6869750294276089
Epoch: 57 | Iteration number: [3680/4518] 81% | Training loss: 0.6869737976757081
Epoch: 57 | Iteration number: [3690/4518] 81% | Training loss: 0.6869708265715498
Epoch: 57 | Iteration number: [3700/4518] 81% | Training loss: 0.6869703292685586
Epoch: 57 | Iteration number: [3710/4518] 82% | Training loss: 0.6869688955760709
Epoch: 57 | Iteration number: [3720/4518] 82% | Training loss: 0.6869655554333041
Epoch: 57 | Iteration number: [3730/4518] 82% | Training loss: 0.6869674511313758
Epoch: 57 | Iteration number: [3740/4518] 82% | Training loss: 0.6869705837359403
Epoch: 57 | Iteration number: [3750/4518] 83% | Training loss: 0.6869656639099121
Epoch: 57 | Iteration number: [3760/4518] 83% | Training loss: 0.6869650037998849
Epoch: 57 | Iteration number: [3770/4518] 83% | Training loss: 0.6869664265401167
Epoch: 57 | Iteration number: [3780/4518] 83% | Training loss: 0.6869651925469201
Epoch: 57 | Iteration number: [3790/4518] 83% | Training loss: 0.6869631098725865
Epoch: 57 | Iteration number: [3800/4518] 84% | Training loss: 0.6869629819769608
Epoch: 57 | Iteration number: [3810/4518] 84% | Training loss: 0.6869624405395327
Epoch: 57 | Iteration number: [3820/4518] 84% | Training loss: 0.6869619902515911
Epoch: 57 | Iteration number: [3830/4518] 84% | Training loss: 0.6869619711260883
Epoch: 57 | Iteration number: [3840/4518] 84% | Training loss: 0.6869611017095546
Epoch: 57 | Iteration number: [3850/4518] 85% | Training loss: 0.6869629675536961
Epoch: 57 | Iteration number: [3860/4518] 85% | Training loss: 0.6869582863823738
Epoch: 57 | Iteration number: [3870/4518] 85% | Training loss: 0.6869593935727457
Epoch: 57 | Iteration number: [3880/4518] 85% | Training loss: 0.6869589257486087
Epoch: 57 | Iteration number: [3890/4518] 86% | Training loss: 0.6869563623994666
Epoch: 57 | Iteration number: [3900/4518] 86% | Training loss: 0.6869564074736375
Epoch: 57 | Iteration number: [3910/4518] 86% | Training loss: 0.6869513344734222
Epoch: 57 | Iteration number: [3920/4518] 86% | Training loss: 0.6869506815106284
Epoch: 57 | Iteration number: [3930/4518] 86% | Training loss: 0.6869477130832866
Epoch: 57 | Iteration number: [3940/4518] 87% | Training loss: 0.6869494911377805
Epoch: 57 | Iteration number: [3950/4518] 87% | Training loss: 0.6869485590729533
Epoch: 57 | Iteration number: [3960/4518] 87% | Training loss: 0.6869480072849928
Epoch: 57 | Iteration number: [3970/4518] 87% | Training loss: 0.6869488240489431
Epoch: 57 | Iteration number: [3980/4518] 88% | Training loss: 0.6869508278429808
Epoch: 57 | Iteration number: [3990/4518] 88% | Training loss: 0.6869495631907518
Epoch: 57 | Iteration number: [4000/4518] 88% | Training loss: 0.6869492151588201
Epoch: 57 | Iteration number: [4010/4518] 88% | Training loss: 0.6869474342339057
Epoch: 57 | Iteration number: [4020/4518] 88% | Training loss: 0.6869466450528718
Epoch: 57 | Iteration number: [4030/4518] 89% | Training loss: 0.6869486414912912
Epoch: 57 | Iteration number: [4040/4518] 89% | Training loss: 0.6869459599108979
Epoch: 57 | Iteration number: [4050/4518] 89% | Training loss: 0.6869459017853679
Epoch: 57 | Iteration number: [4060/4518] 89% | Training loss: 0.6869473766957598
Epoch: 57 | Iteration number: [4070/4518] 90% | Training loss: 0.6869477401055047
Epoch: 57 | Iteration number: [4080/4518] 90% | Training loss: 0.6869484824877159
Epoch: 57 | Iteration number: [4090/4518] 90% | Training loss: 0.6869500892669472
Epoch: 57 | Iteration number: [4100/4518] 90% | Training loss: 0.6869548474143191
Epoch: 57 | Iteration number: [4110/4518] 90% | Training loss: 0.686952516820889
Epoch: 57 | Iteration number: [4120/4518] 91% | Training loss: 0.6869520536614854
Epoch: 57 | Iteration number: [4130/4518] 91% | Training loss: 0.6869544926047614
Epoch: 57 | Iteration number: [4140/4518] 91% | Training loss: 0.686954719144941
Epoch: 57 | Iteration number: [4150/4518] 91% | Training loss: 0.6869546953023198
Epoch: 57 | Iteration number: [4160/4518] 92% | Training loss: 0.6869528925476166
Epoch: 57 | Iteration number: [4170/4518] 92% | Training loss: 0.6869495288359462
Epoch: 57 | Iteration number: [4180/4518] 92% | Training loss: 0.6869504406121358
Epoch: 57 | Iteration number: [4190/4518] 92% | Training loss: 0.6869495433668532
Epoch: 57 | Iteration number: [4200/4518] 92% | Training loss: 0.6869539271791776
Epoch: 57 | Iteration number: [4210/4518] 93% | Training loss: 0.6869554296525244
Epoch: 57 | Iteration number: [4220/4518] 93% | Training loss: 0.6869541784598364
Epoch: 57 | Iteration number: [4230/4518] 93% | Training loss: 0.6869511375472337
Epoch: 57 | Iteration number: [4240/4518] 93% | Training loss: 0.6869530181980358
Epoch: 57 | Iteration number: [4250/4518] 94% | Training loss: 0.6869481004827163
Epoch: 57 | Iteration number: [4260/4518] 94% | Training loss: 0.6869504959230691
Epoch: 57 | Iteration number: [4270/4518] 94% | Training loss: 0.6869482838437485
Epoch: 57 | Iteration number: [4280/4518] 94% | Training loss: 0.6869477120097552
Epoch: 57 | Iteration number: [4290/4518] 94% | Training loss: 0.686946898295885
Epoch: 57 | Iteration number: [4300/4518] 95% | Training loss: 0.6869485131945721
Epoch: 57 | Iteration number: [4310/4518] 95% | Training loss: 0.6869490364588053
Epoch: 57 | Iteration number: [4320/4518] 95% | Training loss: 0.6869495368390172
Epoch: 57 | Iteration number: [4330/4518] 95% | Training loss: 0.6869519481620392
Epoch: 57 | Iteration number: [4340/4518] 96% | Training loss: 0.6869512016734769
Epoch: 57 | Iteration number: [4350/4518] 96% | Training loss: 0.6869511740235077
Epoch: 57 | Iteration number: [4360/4518] 96% | Training loss: 0.6869506426087213
Epoch: 57 | Iteration number: [4370/4518] 96% | Training loss: 0.6869503467934083
Epoch: 57 | Iteration number: [4380/4518] 96% | Training loss: 0.6869517944991317
Epoch: 57 | Iteration number: [4390/4518] 97% | Training loss: 0.68695414446481
Epoch: 57 | Iteration number: [4400/4518] 97% | Training loss: 0.6869554739106786
Epoch: 57 | Iteration number: [4410/4518] 97% | Training loss: 0.686955799213072
Epoch: 57 | Iteration number: [4420/4518] 97% | Training loss: 0.6869551504224674
Epoch: 57 | Iteration number: [4430/4518] 98% | Training loss: 0.6869514710074354
Epoch: 57 | Iteration number: [4440/4518] 98% | Training loss: 0.6869522353818824
Epoch: 57 | Iteration number: [4450/4518] 98% | Training loss: 0.6869513661406014
Epoch: 57 | Iteration number: [4460/4518] 98% | Training loss: 0.6869527465693085
Epoch: 57 | Iteration number: [4470/4518] 98% | Training loss: 0.6869517333688885
Epoch: 57 | Iteration number: [4480/4518] 99% | Training loss: 0.6869500941996064
Epoch: 57 | Iteration number: [4490/4518] 99% | Training loss: 0.6869487693819543
Epoch: 57 | Iteration number: [4500/4518] 99% | Training loss: 0.6869468578630024
Epoch: 57 | Iteration number: [4510/4518] 99% | Training loss: 0.6869450565848805

 End of epoch: 57 | Train Loss: 0.6867934471740824 | Training Time: 641 

 End of epoch: 57 | Eval Loss: 0.6899062273453693 | Evaluating Time: 17 
Epoch: 58 | Iteration number: [10/4518] 0% | Training loss: 0.7549966156482697
Epoch: 58 | Iteration number: [20/4518] 0% | Training loss: 0.7209497362375259
Epoch: 58 | Iteration number: [30/4518] 0% | Training loss: 0.709556112686793
Epoch: 58 | Iteration number: [40/4518] 0% | Training loss: 0.7037851125001907
Epoch: 58 | Iteration number: [50/4518] 1% | Training loss: 0.7005452132225036
Epoch: 58 | Iteration number: [60/4518] 1% | Training loss: 0.6982093354066213
Epoch: 58 | Iteration number: [70/4518] 1% | Training loss: 0.6966067160878863
Epoch: 58 | Iteration number: [80/4518] 1% | Training loss: 0.6954012162983417
Epoch: 58 | Iteration number: [90/4518] 1% | Training loss: 0.6945052590635088
Epoch: 58 | Iteration number: [100/4518] 2% | Training loss: 0.6936090314388275
Epoch: 58 | Iteration number: [110/4518] 2% | Training loss: 0.6929283033717762
Epoch: 58 | Iteration number: [120/4518] 2% | Training loss: 0.6924662480751673
Epoch: 58 | Iteration number: [130/4518] 2% | Training loss: 0.6921480939938471
Epoch: 58 | Iteration number: [140/4518] 3% | Training loss: 0.6918396690062114
Epoch: 58 | Iteration number: [150/4518] 3% | Training loss: 0.6913927817344665
Epoch: 58 | Iteration number: [160/4518] 3% | Training loss: 0.6910577215254307
Epoch: 58 | Iteration number: [170/4518] 3% | Training loss: 0.6908306097283082
Epoch: 58 | Iteration number: [180/4518] 3% | Training loss: 0.6906131277481715
Epoch: 58 | Iteration number: [190/4518] 4% | Training loss: 0.6904059683021746
Epoch: 58 | Iteration number: [200/4518] 4% | Training loss: 0.6902130845189095
Epoch: 58 | Iteration number: [210/4518] 4% | Training loss: 0.6900209600017184
Epoch: 58 | Iteration number: [220/4518] 4% | Training loss: 0.689785065705126
Epoch: 58 | Iteration number: [230/4518] 5% | Training loss: 0.6895988625028859
Epoch: 58 | Iteration number: [240/4518] 5% | Training loss: 0.6894504586855571
Epoch: 58 | Iteration number: [250/4518] 5% | Training loss: 0.6894024860858917
Epoch: 58 | Iteration number: [260/4518] 5% | Training loss: 0.6892419627079597
Epoch: 58 | Iteration number: [270/4518] 5% | Training loss: 0.6891404178407458
Epoch: 58 | Iteration number: [280/4518] 6% | Training loss: 0.6890690837587629
Epoch: 58 | Iteration number: [290/4518] 6% | Training loss: 0.688933454916395
Epoch: 58 | Iteration number: [300/4518] 6% | Training loss: 0.6888462777932485
Epoch: 58 | Iteration number: [310/4518] 6% | Training loss: 0.6887811216615861
Epoch: 58 | Iteration number: [320/4518] 7% | Training loss: 0.6887032523751259
Epoch: 58 | Iteration number: [330/4518] 7% | Training loss: 0.6886428047310222
Epoch: 58 | Iteration number: [340/4518] 7% | Training loss: 0.6885644311414045
Epoch: 58 | Iteration number: [350/4518] 7% | Training loss: 0.6885282935414996
Epoch: 58 | Iteration number: [360/4518] 7% | Training loss: 0.688502636551857
Epoch: 58 | Iteration number: [370/4518] 8% | Training loss: 0.6884756436219086
Epoch: 58 | Iteration number: [380/4518] 8% | Training loss: 0.6884073172744952
Epoch: 58 | Iteration number: [390/4518] 8% | Training loss: 0.6883723951303042
Epoch: 58 | Iteration number: [400/4518] 8% | Training loss: 0.6883063986897469
Epoch: 58 | Iteration number: [410/4518] 9% | Training loss: 0.6882568192191241
Epoch: 58 | Iteration number: [420/4518] 9% | Training loss: 0.6882204749754497
Epoch: 58 | Iteration number: [430/4518] 9% | Training loss: 0.6881887349971505
Epoch: 58 | Iteration number: [440/4518] 9% | Training loss: 0.6881422833962874
Epoch: 58 | Iteration number: [450/4518] 9% | Training loss: 0.6880969525708093
Epoch: 58 | Iteration number: [460/4518] 10% | Training loss: 0.6880486743605655
Epoch: 58 | Iteration number: [470/4518] 10% | Training loss: 0.6880197788806672
Epoch: 58 | Iteration number: [480/4518] 10% | Training loss: 0.6880080038060744
Epoch: 58 | Iteration number: [490/4518] 10% | Training loss: 0.687978653518521
Epoch: 58 | Iteration number: [500/4518] 11% | Training loss: 0.6879515106678009
Epoch: 58 | Iteration number: [510/4518] 11% | Training loss: 0.6879281823541604
Epoch: 58 | Iteration number: [520/4518] 11% | Training loss: 0.6878842222002837
Epoch: 58 | Iteration number: [530/4518] 11% | Training loss: 0.6878807311912752
Epoch: 58 | Iteration number: [540/4518] 11% | Training loss: 0.6878757434862631
Epoch: 58 | Iteration number: [550/4518] 12% | Training loss: 0.6878627930987965
Epoch: 58 | Iteration number: [560/4518] 12% | Training loss: 0.6878553626792772
Epoch: 58 | Iteration number: [570/4518] 12% | Training loss: 0.6878429807069009
Epoch: 58 | Iteration number: [580/4518] 12% | Training loss: 0.6878295817251863
Epoch: 58 | Iteration number: [590/4518] 13% | Training loss: 0.6878009719363714
Epoch: 58 | Iteration number: [600/4518] 13% | Training loss: 0.6877828107277553
Epoch: 58 | Iteration number: [610/4518] 13% | Training loss: 0.6877813724220776
Epoch: 58 | Iteration number: [620/4518] 13% | Training loss: 0.6877843207889988
Epoch: 58 | Iteration number: [630/4518] 13% | Training loss: 0.6877662705050575
Epoch: 58 | Iteration number: [640/4518] 14% | Training loss: 0.6877623401582241
Epoch: 58 | Iteration number: [650/4518] 14% | Training loss: 0.6877474910479325
Epoch: 58 | Iteration number: [660/4518] 14% | Training loss: 0.6877529090101069
Epoch: 58 | Iteration number: [670/4518] 14% | Training loss: 0.6877522118055999
Epoch: 58 | Iteration number: [680/4518] 15% | Training loss: 0.6877379576072974
Epoch: 58 | Iteration number: [690/4518] 15% | Training loss: 0.6877248425414597
Epoch: 58 | Iteration number: [700/4518] 15% | Training loss: 0.6876976261820112
Epoch: 58 | Iteration number: [710/4518] 15% | Training loss: 0.6876837517174197
Epoch: 58 | Iteration number: [720/4518] 15% | Training loss: 0.6876718901925617
Epoch: 58 | Iteration number: [730/4518] 16% | Training loss: 0.6876655057685016
Epoch: 58 | Iteration number: [740/4518] 16% | Training loss: 0.687668467051274
Epoch: 58 | Iteration number: [750/4518] 16% | Training loss: 0.68764737311999
Epoch: 58 | Iteration number: [760/4518] 16% | Training loss: 0.6876297688797901
Epoch: 58 | Iteration number: [770/4518] 17% | Training loss: 0.6876212533418234
Epoch: 58 | Iteration number: [780/4518] 17% | Training loss: 0.6875959561421321
Epoch: 58 | Iteration number: [790/4518] 17% | Training loss: 0.6875767697261859
Epoch: 58 | Iteration number: [800/4518] 17% | Training loss: 0.6875622782856226
Epoch: 58 | Iteration number: [810/4518] 17% | Training loss: 0.6875465125213435
Epoch: 58 | Iteration number: [820/4518] 18% | Training loss: 0.6875378400087356
Epoch: 58 | Iteration number: [830/4518] 18% | Training loss: 0.6875403629009982
Epoch: 58 | Iteration number: [840/4518] 18% | Training loss: 0.6875311494583175
Epoch: 58 | Iteration number: [850/4518] 18% | Training loss: 0.6875158422834733
Epoch: 58 | Iteration number: [860/4518] 19% | Training loss: 0.6875094257121862
Epoch: 58 | Iteration number: [870/4518] 19% | Training loss: 0.6874920151014438
Epoch: 58 | Iteration number: [880/4518] 19% | Training loss: 0.6874693908474662
Epoch: 58 | Iteration number: [890/4518] 19% | Training loss: 0.6874702328376556
Epoch: 58 | Iteration number: [900/4518] 19% | Training loss: 0.6874606889486313
Epoch: 58 | Iteration number: [910/4518] 20% | Training loss: 0.6874383307420291
Epoch: 58 | Iteration number: [920/4518] 20% | Training loss: 0.687436882438867
Epoch: 58 | Iteration number: [930/4518] 20% | Training loss: 0.6874440025898718
Epoch: 58 | Iteration number: [940/4518] 20% | Training loss: 0.6874410238037718
Epoch: 58 | Iteration number: [950/4518] 21% | Training loss: 0.6874292656622435
Epoch: 58 | Iteration number: [960/4518] 21% | Training loss: 0.6874295356372992
Epoch: 58 | Iteration number: [970/4518] 21% | Training loss: 0.6874241984996599
Epoch: 58 | Iteration number: [980/4518] 21% | Training loss: 0.6874114903868461
Epoch: 58 | Iteration number: [990/4518] 21% | Training loss: 0.6874060233434042
Epoch: 58 | Iteration number: [1000/4518] 22% | Training loss: 0.6874023302793503
Epoch: 58 | Iteration number: [1010/4518] 22% | Training loss: 0.6873890241774002
Epoch: 58 | Iteration number: [1020/4518] 22% | Training loss: 0.6873788933543598
Epoch: 58 | Iteration number: [1030/4518] 22% | Training loss: 0.6873645273227136
Epoch: 58 | Iteration number: [1040/4518] 23% | Training loss: 0.6873634630097792
Epoch: 58 | Iteration number: [1050/4518] 23% | Training loss: 0.6873648758161636
Epoch: 58 | Iteration number: [1060/4518] 23% | Training loss: 0.687365914853114
Epoch: 58 | Iteration number: [1070/4518] 23% | Training loss: 0.687365950546532
Epoch: 58 | Iteration number: [1080/4518] 23% | Training loss: 0.6873666427201695
Epoch: 58 | Iteration number: [1090/4518] 24% | Training loss: 0.68737279400913
Epoch: 58 | Iteration number: [1100/4518] 24% | Training loss: 0.6873806133053519
Epoch: 58 | Iteration number: [1110/4518] 24% | Training loss: 0.6873786755510278
Epoch: 58 | Iteration number: [1120/4518] 24% | Training loss: 0.6873685967709336
Epoch: 58 | Iteration number: [1130/4518] 25% | Training loss: 0.6873690826175487
Epoch: 58 | Iteration number: [1140/4518] 25% | Training loss: 0.6873634018918924
Epoch: 58 | Iteration number: [1150/4518] 25% | Training loss: 0.6873584466913472
Epoch: 58 | Iteration number: [1160/4518] 25% | Training loss: 0.6873426939906745
Epoch: 58 | Iteration number: [1170/4518] 25% | Training loss: 0.6873381474588671
Epoch: 58 | Iteration number: [1180/4518] 26% | Training loss: 0.6873265658899889
Epoch: 58 | Iteration number: [1190/4518] 26% | Training loss: 0.6873206021905948
Epoch: 58 | Iteration number: [1200/4518] 26% | Training loss: 0.6873095276455085
Epoch: 58 | Iteration number: [1210/4518] 26% | Training loss: 0.6873119069032433
Epoch: 58 | Iteration number: [1220/4518] 27% | Training loss: 0.6873077801993636
Epoch: 58 | Iteration number: [1230/4518] 27% | Training loss: 0.6872973039382841
Epoch: 58 | Iteration number: [1240/4518] 27% | Training loss: 0.6872895934889394
Epoch: 58 | Iteration number: [1250/4518] 27% | Training loss: 0.6872847378253937
Epoch: 58 | Iteration number: [1260/4518] 27% | Training loss: 0.6872688016248127
Epoch: 58 | Iteration number: [1270/4518] 28% | Training loss: 0.6872616488633193
Epoch: 58 | Iteration number: [1280/4518] 28% | Training loss: 0.687248497782275
Epoch: 58 | Iteration number: [1290/4518] 28% | Training loss: 0.6872525592182958
Epoch: 58 | Iteration number: [1300/4518] 28% | Training loss: 0.6872495991908587
Epoch: 58 | Iteration number: [1310/4518] 28% | Training loss: 0.6872429224371001
Epoch: 58 | Iteration number: [1320/4518] 29% | Training loss: 0.6872431156761718
Epoch: 58 | Iteration number: [1330/4518] 29% | Training loss: 0.6872351031554372
Epoch: 58 | Iteration number: [1340/4518] 29% | Training loss: 0.6872327488304963
Epoch: 58 | Iteration number: [1350/4518] 29% | Training loss: 0.6872332627684982
Epoch: 58 | Iteration number: [1360/4518] 30% | Training loss: 0.6872205492328195
Epoch: 58 | Iteration number: [1370/4518] 30% | Training loss: 0.6872116251148447
Epoch: 58 | Iteration number: [1380/4518] 30% | Training loss: 0.6872045318285624
Epoch: 58 | Iteration number: [1390/4518] 30% | Training loss: 0.6871974440787336
Epoch: 58 | Iteration number: [1400/4518] 30% | Training loss: 0.6871852610792433
Epoch: 58 | Iteration number: [1410/4518] 31% | Training loss: 0.6871884397158387
Epoch: 58 | Iteration number: [1420/4518] 31% | Training loss: 0.6871941716318399
Epoch: 58 | Iteration number: [1430/4518] 31% | Training loss: 0.6871987922208292
Epoch: 58 | Iteration number: [1440/4518] 31% | Training loss: 0.6871980021397273
Epoch: 58 | Iteration number: [1450/4518] 32% | Training loss: 0.6872025408415959
Epoch: 58 | Iteration number: [1460/4518] 32% | Training loss: 0.6872038225196813
Epoch: 58 | Iteration number: [1470/4518] 32% | Training loss: 0.6871980931888633
Epoch: 58 | Iteration number: [1480/4518] 32% | Training loss: 0.6872028023004532
Epoch: 58 | Iteration number: [1490/4518] 32% | Training loss: 0.6871942483338733
Epoch: 58 | Iteration number: [1500/4518] 33% | Training loss: 0.6871865771214167
Epoch: 58 | Iteration number: [1510/4518] 33% | Training loss: 0.6871900688733487
Epoch: 58 | Iteration number: [1520/4518] 33% | Training loss: 0.6871911990799402
Epoch: 58 | Iteration number: [1530/4518] 33% | Training loss: 0.6871857756103565
Epoch: 58 | Iteration number: [1540/4518] 34% | Training loss: 0.6871827754881474
Epoch: 58 | Iteration number: [1550/4518] 34% | Training loss: 0.6871806018583236
Epoch: 58 | Iteration number: [1560/4518] 34% | Training loss: 0.6871733845426486
Epoch: 58 | Iteration number: [1570/4518] 34% | Training loss: 0.6871705576113075
Epoch: 58 | Iteration number: [1580/4518] 34% | Training loss: 0.6871557256466225
Epoch: 58 | Iteration number: [1590/4518] 35% | Training loss: 0.6871554956871009
Epoch: 58 | Iteration number: [1600/4518] 35% | Training loss: 0.6871467304229736
Epoch: 58 | Iteration number: [1610/4518] 35% | Training loss: 0.6871408509911958
Epoch: 58 | Iteration number: [1620/4518] 35% | Training loss: 0.6871370019368184
Epoch: 58 | Iteration number: [1630/4518] 36% | Training loss: 0.6871407700096903
Epoch: 58 | Iteration number: [1640/4518] 36% | Training loss: 0.6871468407351796
Epoch: 58 | Iteration number: [1650/4518] 36% | Training loss: 0.687136426188729
Epoch: 58 | Iteration number: [1660/4518] 36% | Training loss: 0.6871318357536592
Epoch: 58 | Iteration number: [1670/4518] 36% | Training loss: 0.6871427568133006
Epoch: 58 | Iteration number: [1680/4518] 37% | Training loss: 0.6871392251125403
Epoch: 58 | Iteration number: [1690/4518] 37% | Training loss: 0.6871431816259079
Epoch: 58 | Iteration number: [1700/4518] 37% | Training loss: 0.6871301655909594
Epoch: 58 | Iteration number: [1710/4518] 37% | Training loss: 0.6871258632481446
Epoch: 58 | Iteration number: [1720/4518] 38% | Training loss: 0.6871266026136487
Epoch: 58 | Iteration number: [1730/4518] 38% | Training loss: 0.6871305622117367
Epoch: 58 | Iteration number: [1740/4518] 38% | Training loss: 0.6871321104723832
Epoch: 58 | Iteration number: [1750/4518] 38% | Training loss: 0.6871350869791848
Epoch: 58 | Iteration number: [1760/4518] 38% | Training loss: 0.6871364574202082
Epoch: 58 | Iteration number: [1770/4518] 39% | Training loss: 0.6871329758463607
Epoch: 58 | Iteration number: [1780/4518] 39% | Training loss: 0.6871290705177221
Epoch: 58 | Iteration number: [1790/4518] 39% | Training loss: 0.6871331283833062
Epoch: 58 | Iteration number: [1800/4518] 39% | Training loss: 0.687130153046714
Epoch: 58 | Iteration number: [1810/4518] 40% | Training loss: 0.687118542260228
Epoch: 58 | Iteration number: [1820/4518] 40% | Training loss: 0.6871286833024287
Epoch: 58 | Iteration number: [1830/4518] 40% | Training loss: 0.68712638929242
Epoch: 58 | Iteration number: [1840/4518] 40% | Training loss: 0.6871254413024239
Epoch: 58 | Iteration number: [1850/4518] 40% | Training loss: 0.6871269083667446
Epoch: 58 | Iteration number: [1860/4518] 41% | Training loss: 0.6871296133405419
Epoch: 58 | Iteration number: [1870/4518] 41% | Training loss: 0.6871291944368638
Epoch: 58 | Iteration number: [1880/4518] 41% | Training loss: 0.6871250642106889
Epoch: 58 | Iteration number: [1890/4518] 41% | Training loss: 0.6871240710455274
Epoch: 58 | Iteration number: [1900/4518] 42% | Training loss: 0.687121369274039
Epoch: 58 | Iteration number: [1910/4518] 42% | Training loss: 0.6871185846977833
Epoch: 58 | Iteration number: [1920/4518] 42% | Training loss: 0.687113804059724
Epoch: 58 | Iteration number: [1930/4518] 42% | Training loss: 0.6871158263843912
Epoch: 58 | Iteration number: [1940/4518] 42% | Training loss: 0.6871172185103918
Epoch: 58 | Iteration number: [1950/4518] 43% | Training loss: 0.6871156117243644
Epoch: 58 | Iteration number: [1960/4518] 43% | Training loss: 0.6871133921705946
Epoch: 58 | Iteration number: [1970/4518] 43% | Training loss: 0.6871163591515594
Epoch: 58 | Iteration number: [1980/4518] 43% | Training loss: 0.687114517435883
Epoch: 58 | Iteration number: [1990/4518] 44% | Training loss: 0.6871179609442476
Epoch: 58 | Iteration number: [2000/4518] 44% | Training loss: 0.687121779769659
Epoch: 58 | Iteration number: [2010/4518] 44% | Training loss: 0.6871207357935645
Epoch: 58 | Iteration number: [2020/4518] 44% | Training loss: 0.6871100625779369
Epoch: 58 | Iteration number: [2030/4518] 44% | Training loss: 0.6871080241473437
Epoch: 58 | Iteration number: [2040/4518] 45% | Training loss: 0.6871073933793049
Epoch: 58 | Iteration number: [2050/4518] 45% | Training loss: 0.68710275155742
Epoch: 58 | Iteration number: [2060/4518] 45% | Training loss: 0.6870994809472445
Epoch: 58 | Iteration number: [2070/4518] 45% | Training loss: 0.6870996631861885
Epoch: 58 | Iteration number: [2080/4518] 46% | Training loss: 0.6871072979500661
Epoch: 58 | Iteration number: [2090/4518] 46% | Training loss: 0.6871011469637949
Epoch: 58 | Iteration number: [2100/4518] 46% | Training loss: 0.6870979048524584
Epoch: 58 | Iteration number: [2110/4518] 46% | Training loss: 0.6870973305114637
Epoch: 58 | Iteration number: [2120/4518] 46% | Training loss: 0.6870953108342188
Epoch: 58 | Iteration number: [2130/4518] 47% | Training loss: 0.687093674213114
Epoch: 58 | Iteration number: [2140/4518] 47% | Training loss: 0.6870863294490029
Epoch: 58 | Iteration number: [2150/4518] 47% | Training loss: 0.6870870209571928
Epoch: 58 | Iteration number: [2160/4518] 47% | Training loss: 0.6870830053808512
Epoch: 58 | Iteration number: [2170/4518] 48% | Training loss: 0.6870842658429651
Epoch: 58 | Iteration number: [2180/4518] 48% | Training loss: 0.6870822613392401
Epoch: 58 | Iteration number: [2190/4518] 48% | Training loss: 0.6870821707324895
Epoch: 58 | Iteration number: [2200/4518] 48% | Training loss: 0.6870785834030672
Epoch: 58 | Iteration number: [2210/4518] 48% | Training loss: 0.6870755499304689
Epoch: 58 | Iteration number: [2220/4518] 49% | Training loss: 0.6870803948995229
Epoch: 58 | Iteration number: [2230/4518] 49% | Training loss: 0.6870815369045787
Epoch: 58 | Iteration number: [2240/4518] 49% | Training loss: 0.6870816670890365
Epoch: 58 | Iteration number: [2250/4518] 49% | Training loss: 0.6870807358158959
Epoch: 58 | Iteration number: [2260/4518] 50% | Training loss: 0.6870826386244951
Epoch: 58 | Iteration number: [2270/4518] 50% | Training loss: 0.6870808102223317
Epoch: 58 | Iteration number: [2280/4518] 50% | Training loss: 0.6870813146756406
Epoch: 58 | Iteration number: [2290/4518] 50% | Training loss: 0.6870792500577119
Epoch: 58 | Iteration number: [2300/4518] 50% | Training loss: 0.6870746825052344
Epoch: 58 | Iteration number: [2310/4518] 51% | Training loss: 0.6870771827119769
Epoch: 58 | Iteration number: [2320/4518] 51% | Training loss: 0.6870745348005459
Epoch: 58 | Iteration number: [2330/4518] 51% | Training loss: 0.687070547997184
Epoch: 58 | Iteration number: [2340/4518] 51% | Training loss: 0.687071024097948
Epoch: 58 | Iteration number: [2350/4518] 52% | Training loss: 0.6870625879916739
Epoch: 58 | Iteration number: [2360/4518] 52% | Training loss: 0.6870682390312017
Epoch: 58 | Iteration number: [2370/4518] 52% | Training loss: 0.6870686316791969
Epoch: 58 | Iteration number: [2380/4518] 52% | Training loss: 0.6870687210760197
Epoch: 58 | Iteration number: [2390/4518] 52% | Training loss: 0.6870700269563428
Epoch: 58 | Iteration number: [2400/4518] 53% | Training loss: 0.6870743644982577
Epoch: 58 | Iteration number: [2410/4518] 53% | Training loss: 0.6870779661469439
Epoch: 58 | Iteration number: [2420/4518] 53% | Training loss: 0.6870808531922742
Epoch: 58 | Iteration number: [2430/4518] 53% | Training loss: 0.6870828128891227
Epoch: 58 | Iteration number: [2440/4518] 54% | Training loss: 0.687081842637453
Epoch: 58 | Iteration number: [2450/4518] 54% | Training loss: 0.6870753841010891
Epoch: 58 | Iteration number: [2460/4518] 54% | Training loss: 0.6870753818168873
Epoch: 58 | Iteration number: [2470/4518] 54% | Training loss: 0.6870733854259073
Epoch: 58 | Iteration number: [2480/4518] 54% | Training loss: 0.6870688026470523
Epoch: 58 | Iteration number: [2490/4518] 55% | Training loss: 0.6870707026925911
Epoch: 58 | Iteration number: [2500/4518] 55% | Training loss: 0.6870707801580429
Epoch: 58 | Iteration number: [2510/4518] 55% | Training loss: 0.6870717245269107
Epoch: 58 | Iteration number: [2520/4518] 55% | Training loss: 0.6870685842775163
Epoch: 58 | Iteration number: [2530/4518] 55% | Training loss: 0.6870743417221566
Epoch: 58 | Iteration number: [2540/4518] 56% | Training loss: 0.6870710234238406
Epoch: 58 | Iteration number: [2550/4518] 56% | Training loss: 0.6870697297301946
Epoch: 58 | Iteration number: [2560/4518] 56% | Training loss: 0.6870678724953905
Epoch: 58 | Iteration number: [2570/4518] 56% | Training loss: 0.6870631547521524
Epoch: 58 | Iteration number: [2580/4518] 57% | Training loss: 0.6870620473410732
Epoch: 58 | Iteration number: [2590/4518] 57% | Training loss: 0.6870617646508236
Epoch: 58 | Iteration number: [2600/4518] 57% | Training loss: 0.6870585841398973
Epoch: 58 | Iteration number: [2610/4518] 57% | Training loss: 0.6870561799783816
Epoch: 58 | Iteration number: [2620/4518] 57% | Training loss: 0.687048060634664
Epoch: 58 | Iteration number: [2630/4518] 58% | Training loss: 0.6870475353170257
Epoch: 58 | Iteration number: [2640/4518] 58% | Training loss: 0.687042167805361
Epoch: 58 | Iteration number: [2650/4518] 58% | Training loss: 0.6870445778459873
Epoch: 58 | Iteration number: [2660/4518] 58% | Training loss: 0.6870453820192725
Epoch: 58 | Iteration number: [2670/4518] 59% | Training loss: 0.6870476370893615
Epoch: 58 | Iteration number: [2680/4518] 59% | Training loss: 0.6870459417798626
Epoch: 58 | Iteration number: [2690/4518] 59% | Training loss: 0.6870477138841905
Epoch: 58 | Iteration number: [2700/4518] 59% | Training loss: 0.6870441145146334
Epoch: 58 | Iteration number: [2710/4518] 59% | Training loss: 0.6870438352502141
Epoch: 58 | Iteration number: [2720/4518] 60% | Training loss: 0.6870413671959849
Epoch: 58 | Iteration number: [2730/4518] 60% | Training loss: 0.6870404314208817
Epoch: 58 | Iteration number: [2740/4518] 60% | Training loss: 0.6870391350375474
Epoch: 58 | Iteration number: [2750/4518] 60% | Training loss: 0.6870357024886391
Epoch: 58 | Iteration number: [2760/4518] 61% | Training loss: 0.6870367649240771
Epoch: 58 | Iteration number: [2770/4518] 61% | Training loss: 0.6870363694235736
Epoch: 58 | Iteration number: [2780/4518] 61% | Training loss: 0.6870333982028549
Epoch: 58 | Iteration number: [2790/4518] 61% | Training loss: 0.6870325460442506
Epoch: 58 | Iteration number: [2800/4518] 61% | Training loss: 0.6870362129381725
Epoch: 58 | Iteration number: [2810/4518] 62% | Training loss: 0.6870359488441427
Epoch: 58 | Iteration number: [2820/4518] 62% | Training loss: 0.687039349032632
Epoch: 58 | Iteration number: [2830/4518] 62% | Training loss: 0.6870353155127684
Epoch: 58 | Iteration number: [2840/4518] 62% | Training loss: 0.6870335621733061
Epoch: 58 | Iteration number: [2850/4518] 63% | Training loss: 0.6870346626273373
Epoch: 58 | Iteration number: [2860/4518] 63% | Training loss: 0.687034819467918
Epoch: 58 | Iteration number: [2870/4518] 63% | Training loss: 0.6870392898026244
Epoch: 58 | Iteration number: [2880/4518] 63% | Training loss: 0.6870413583599859
Epoch: 58 | Iteration number: [2890/4518] 63% | Training loss: 0.6870448000703303
Epoch: 58 | Iteration number: [2900/4518] 64% | Training loss: 0.6870407372302022
Epoch: 58 | Iteration number: [2910/4518] 64% | Training loss: 0.6870410322323698
Epoch: 58 | Iteration number: [2920/4518] 64% | Training loss: 0.6870426909972543
Epoch: 58 | Iteration number: [2930/4518] 64% | Training loss: 0.6870446336757607
Epoch: 58 | Iteration number: [2940/4518] 65% | Training loss: 0.687046465784514
Epoch: 58 | Iteration number: [2950/4518] 65% | Training loss: 0.6870460142119457
Epoch: 58 | Iteration number: [2960/4518] 65% | Training loss: 0.6870430712965695
Epoch: 58 | Iteration number: [2970/4518] 65% | Training loss: 0.687046161484638
Epoch: 58 | Iteration number: [2980/4518] 65% | Training loss: 0.6870471965346561
Epoch: 58 | Iteration number: [2990/4518] 66% | Training loss: 0.6870449586456835
Epoch: 58 | Iteration number: [3000/4518] 66% | Training loss: 0.6870463729302089
Epoch: 58 | Iteration number: [3010/4518] 66% | Training loss: 0.6870485905396978
Epoch: 58 | Iteration number: [3020/4518] 66% | Training loss: 0.6870495738572632
Epoch: 58 | Iteration number: [3030/4518] 67% | Training loss: 0.6870479806421613
Epoch: 58 | Iteration number: [3040/4518] 67% | Training loss: 0.6870472618427715
Epoch: 58 | Iteration number: [3050/4518] 67% | Training loss: 0.6870420446552215
Epoch: 58 | Iteration number: [3060/4518] 67% | Training loss: 0.6870425471682954
Epoch: 58 | Iteration number: [3070/4518] 67% | Training loss: 0.6870411849759689
Epoch: 58 | Iteration number: [3080/4518] 68% | Training loss: 0.6870432640631478
Epoch: 58 | Iteration number: [3090/4518] 68% | Training loss: 0.6870452175248403
Epoch: 58 | Iteration number: [3100/4518] 68% | Training loss: 0.6870425909373068
Epoch: 58 | Iteration number: [3110/4518] 68% | Training loss: 0.6870432719157057
Epoch: 58 | Iteration number: [3120/4518] 69% | Training loss: 0.6870440068153235
Epoch: 58 | Iteration number: [3130/4518] 69% | Training loss: 0.6870442259616364
Epoch: 58 | Iteration number: [3140/4518] 69% | Training loss: 0.6870431587384764
Epoch: 58 | Iteration number: [3150/4518] 69% | Training loss: 0.6870425345216479
Epoch: 58 | Iteration number: [3160/4518] 69% | Training loss: 0.6870408992224102
Epoch: 58 | Iteration number: [3170/4518] 70% | Training loss: 0.6870370627953803
Epoch: 58 | Iteration number: [3180/4518] 70% | Training loss: 0.6870314571092714
Epoch: 58 | Iteration number: [3190/4518] 70% | Training loss: 0.6870361139221252
Epoch: 58 | Iteration number: [3200/4518] 70% | Training loss: 0.6870382787846029
Epoch: 58 | Iteration number: [3210/4518] 71% | Training loss: 0.6870365320150726
Epoch: 58 | Iteration number: [3220/4518] 71% | Training loss: 0.687033293076924
Epoch: 58 | Iteration number: [3230/4518] 71% | Training loss: 0.6870313848135272
Epoch: 58 | Iteration number: [3240/4518] 71% | Training loss: 0.6870293588366038
Epoch: 58 | Iteration number: [3250/4518] 71% | Training loss: 0.6870255112097814
Epoch: 58 | Iteration number: [3260/4518] 72% | Training loss: 0.6870250568799446
Epoch: 58 | Iteration number: [3270/4518] 72% | Training loss: 0.6870264192786786
Epoch: 58 | Iteration number: [3280/4518] 72% | Training loss: 0.6870236575966928
Epoch: 58 | Iteration number: [3290/4518] 72% | Training loss: 0.6870228698731918
Epoch: 58 | Iteration number: [3300/4518] 73% | Training loss: 0.687023892511021
Epoch: 58 | Iteration number: [3310/4518] 73% | Training loss: 0.6870268722495284
Epoch: 58 | Iteration number: [3320/4518] 73% | Training loss: 0.6870258470615709
Epoch: 58 | Iteration number: [3330/4518] 73% | Training loss: 0.68702595745837
Epoch: 58 | Iteration number: [3340/4518] 73% | Training loss: 0.6870266184121548
Epoch: 58 | Iteration number: [3350/4518] 74% | Training loss: 0.6870315980555406
Epoch: 58 | Iteration number: [3360/4518] 74% | Training loss: 0.6870320511006174
Epoch: 58 | Iteration number: [3370/4518] 74% | Training loss: 0.687030954707624
Epoch: 58 | Iteration number: [3380/4518] 74% | Training loss: 0.6870315772365536
Epoch: 58 | Iteration number: [3390/4518] 75% | Training loss: 0.6870262391975144
Epoch: 58 | Iteration number: [3400/4518] 75% | Training loss: 0.6870257430742769
Epoch: 58 | Iteration number: [3410/4518] 75% | Training loss: 0.6870242250979471
Epoch: 58 | Iteration number: [3420/4518] 75% | Training loss: 0.6870241405148255
Epoch: 58 | Iteration number: [3430/4518] 75% | Training loss: 0.6870235272990024
Epoch: 58 | Iteration number: [3440/4518] 76% | Training loss: 0.6870237823142562
Epoch: 58 | Iteration number: [3450/4518] 76% | Training loss: 0.6870226529197416
Epoch: 58 | Iteration number: [3460/4518] 76% | Training loss: 0.6870172613962537
Epoch: 58 | Iteration number: [3470/4518] 76% | Training loss: 0.6870166452886048
Epoch: 58 | Iteration number: [3480/4518] 77% | Training loss: 0.6870159718497046
Epoch: 58 | Iteration number: [3490/4518] 77% | Training loss: 0.6870171156004712
Epoch: 58 | Iteration number: [3500/4518] 77% | Training loss: 0.6870142502103533
Epoch: 58 | Iteration number: [3510/4518] 77% | Training loss: 0.687016716828713
Epoch: 58 | Iteration number: [3520/4518] 77% | Training loss: 0.6870144551450555
Epoch: 58 | Iteration number: [3530/4518] 78% | Training loss: 0.6870148619072295
Epoch: 58 | Iteration number: [3540/4518] 78% | Training loss: 0.6870119895133595
Epoch: 58 | Iteration number: [3550/4518] 78% | Training loss: 0.6870118930809934
Epoch: 58 | Iteration number: [3560/4518] 78% | Training loss: 0.6870138563132018
Epoch: 58 | Iteration number: [3570/4518] 79% | Training loss: 0.6870114846389834
Epoch: 58 | Iteration number: [3580/4518] 79% | Training loss: 0.6870101355141102
Epoch: 58 | Iteration number: [3590/4518] 79% | Training loss: 0.6870091844568014
Epoch: 58 | Iteration number: [3600/4518] 79% | Training loss: 0.687010594126251
Epoch: 58 | Iteration number: [3610/4518] 79% | Training loss: 0.6870126832059876
Epoch: 58 | Iteration number: [3620/4518] 80% | Training loss: 0.6870153208793197
Epoch: 58 | Iteration number: [3630/4518] 80% | Training loss: 0.6870154547789865
Epoch: 58 | Iteration number: [3640/4518] 80% | Training loss: 0.6870161026224986
Epoch: 58 | Iteration number: [3650/4518] 80% | Training loss: 0.687017604471886
Epoch: 58 | Iteration number: [3660/4518] 81% | Training loss: 0.6870144953330358
Epoch: 58 | Iteration number: [3670/4518] 81% | Training loss: 0.6870116078561268
Epoch: 58 | Iteration number: [3680/4518] 81% | Training loss: 0.6870076694404301
Epoch: 58 | Iteration number: [3690/4518] 81% | Training loss: 0.6870072873788797
Epoch: 58 | Iteration number: [3700/4518] 81% | Training loss: 0.6870056895629779
Epoch: 58 | Iteration number: [3710/4518] 82% | Training loss: 0.687004586403582
Epoch: 58 | Iteration number: [3720/4518] 82% | Training loss: 0.6870041134216452
Epoch: 58 | Iteration number: [3730/4518] 82% | Training loss: 0.6870068178899167
Epoch: 58 | Iteration number: [3740/4518] 82% | Training loss: 0.6870043173671406
Epoch: 58 | Iteration number: [3750/4518] 83% | Training loss: 0.6870058458328248
Epoch: 58 | Iteration number: [3760/4518] 83% | Training loss: 0.687004072726407
Epoch: 58 | Iteration number: [3770/4518] 83% | Training loss: 0.687002707413084
Epoch: 58 | Iteration number: [3780/4518] 83% | Training loss: 0.687000455868938
Epoch: 58 | Iteration number: [3790/4518] 83% | Training loss: 0.6869986759798508
Epoch: 58 | Iteration number: [3800/4518] 84% | Training loss: 0.6869962066411972
Epoch: 58 | Iteration number: [3810/4518] 84% | Training loss: 0.686996466515884
Epoch: 58 | Iteration number: [3820/4518] 84% | Training loss: 0.6869953869056952
Epoch: 58 | Iteration number: [3830/4518] 84% | Training loss: 0.6869961430914409
Epoch: 58 | Iteration number: [3840/4518] 84% | Training loss: 0.6869976054566602
Epoch: 58 | Iteration number: [3850/4518] 85% | Training loss: 0.6869956123364436
Epoch: 58 | Iteration number: [3860/4518] 85% | Training loss: 0.6869951315185566
Epoch: 58 | Iteration number: [3870/4518] 85% | Training loss: 0.6869930766657649
Epoch: 58 | Iteration number: [3880/4518] 85% | Training loss: 0.6869952072187797
Epoch: 58 | Iteration number: [3890/4518] 86% | Training loss: 0.686994105638759
Epoch: 58 | Iteration number: [3900/4518] 86% | Training loss: 0.6869964388394967
Epoch: 58 | Iteration number: [3910/4518] 86% | Training loss: 0.6869958252400693
Epoch: 58 | Iteration number: [3920/4518] 86% | Training loss: 0.6869966961443424
Epoch: 58 | Iteration number: [3930/4518] 86% | Training loss: 0.6869993188453994
Epoch: 58 | Iteration number: [3940/4518] 87% | Training loss: 0.686996767469469
Epoch: 58 | Iteration number: [3950/4518] 87% | Training loss: 0.6869991019254998
Epoch: 58 | Iteration number: [3960/4518] 87% | Training loss: 0.6869968025822832
Epoch: 58 | Iteration number: [3970/4518] 87% | Training loss: 0.6869987743026964
Epoch: 58 | Iteration number: [3980/4518] 88% | Training loss: 0.6869933619720852
Epoch: 58 | Iteration number: [3990/4518] 88% | Training loss: 0.6869912631678999
Epoch: 58 | Iteration number: [4000/4518] 88% | Training loss: 0.6869923862069846
Epoch: 58 | Iteration number: [4010/4518] 88% | Training loss: 0.6869951710588023
Epoch: 58 | Iteration number: [4020/4518] 88% | Training loss: 0.6869966105442142
Epoch: 58 | Iteration number: [4030/4518] 89% | Training loss: 0.6869958553805244
Epoch: 58 | Iteration number: [4040/4518] 89% | Training loss: 0.6869931926969255
Epoch: 58 | Iteration number: [4050/4518] 89% | Training loss: 0.686994132509938
Epoch: 58 | Iteration number: [4060/4518] 89% | Training loss: 0.6869931360770916
Epoch: 58 | Iteration number: [4070/4518] 90% | Training loss: 0.6869932164431204
Epoch: 58 | Iteration number: [4080/4518] 90% | Training loss: 0.686994034154158
Epoch: 58 | Iteration number: [4090/4518] 90% | Training loss: 0.6869955649294305
Epoch: 58 | Iteration number: [4100/4518] 90% | Training loss: 0.6869956196081347
Epoch: 58 | Iteration number: [4110/4518] 90% | Training loss: 0.6869932362488006
Epoch: 58 | Iteration number: [4120/4518] 91% | Training loss: 0.6869930834156796
Epoch: 58 | Iteration number: [4130/4518] 91% | Training loss: 0.6869887194968309
Epoch: 58 | Iteration number: [4140/4518] 91% | Training loss: 0.6869905258722352
Epoch: 58 | Iteration number: [4150/4518] 91% | Training loss: 0.6869875044995044
Epoch: 58 | Iteration number: [4160/4518] 92% | Training loss: 0.6869859927262251
Epoch: 58 | Iteration number: [4170/4518] 92% | Training loss: 0.6869854626466902
Epoch: 58 | Iteration number: [4180/4518] 92% | Training loss: 0.6869837692337173
Epoch: 58 | Iteration number: [4190/4518] 92% | Training loss: 0.6869827071209227
Epoch: 58 | Iteration number: [4200/4518] 92% | Training loss: 0.6869806458126931
Epoch: 58 | Iteration number: [4210/4518] 93% | Training loss: 0.6869804835659308
Epoch: 58 | Iteration number: [4220/4518] 93% | Training loss: 0.6869826643105367
Epoch: 58 | Iteration number: [4230/4518] 93% | Training loss: 0.6869829076119912
Epoch: 58 | Iteration number: [4240/4518] 93% | Training loss: 0.6869807430876875
Epoch: 58 | Iteration number: [4250/4518] 94% | Training loss: 0.6869825716439415
Epoch: 58 | Iteration number: [4260/4518] 94% | Training loss: 0.6869800204682238
Epoch: 58 | Iteration number: [4270/4518] 94% | Training loss: 0.6869781431744194
Epoch: 58 | Iteration number: [4280/4518] 94% | Training loss: 0.6869772864000819
Epoch: 58 | Iteration number: [4290/4518] 94% | Training loss: 0.6869707059888017
Epoch: 58 | Iteration number: [4300/4518] 95% | Training loss: 0.6869656409219254
Epoch: 58 | Iteration number: [4310/4518] 95% | Training loss: 0.6869658502376274
Epoch: 58 | Iteration number: [4320/4518] 95% | Training loss: 0.6869676537121887
Epoch: 58 | Iteration number: [4330/4518] 95% | Training loss: 0.6869655746785928
Epoch: 58 | Iteration number: [4340/4518] 96% | Training loss: 0.6869639555704758
Epoch: 58 | Iteration number: [4350/4518] 96% | Training loss: 0.6869659248850811
Epoch: 58 | Iteration number: [4360/4518] 96% | Training loss: 0.6869674237906386
Epoch: 58 | Iteration number: [4370/4518] 96% | Training loss: 0.686965978486587
Epoch: 58 | Iteration number: [4380/4518] 96% | Training loss: 0.6869635971305578
Epoch: 58 | Iteration number: [4390/4518] 97% | Training loss: 0.6869631335241105
Epoch: 58 | Iteration number: [4400/4518] 97% | Training loss: 0.6869618066197092
Epoch: 58 | Iteration number: [4410/4518] 97% | Training loss: 0.6869599666590053
Epoch: 58 | Iteration number: [4420/4518] 97% | Training loss: 0.6869605667046292
Epoch: 58 | Iteration number: [4430/4518] 98% | Training loss: 0.6869589227585976
Epoch: 58 | Iteration number: [4440/4518] 98% | Training loss: 0.6869535923138395
Epoch: 58 | Iteration number: [4450/4518] 98% | Training loss: 0.6869554119967343
Epoch: 58 | Iteration number: [4460/4518] 98% | Training loss: 0.686955604839218
Epoch: 58 | Iteration number: [4470/4518] 98% | Training loss: 0.6869538905503233
Epoch: 58 | Iteration number: [4480/4518] 99% | Training loss: 0.6869518000898617
Epoch: 58 | Iteration number: [4490/4518] 99% | Training loss: 0.6869505726680458
Epoch: 58 | Iteration number: [4500/4518] 99% | Training loss: 0.6869487826956643
Epoch: 58 | Iteration number: [4510/4518] 99% | Training loss: 0.6869471182315683

 End of epoch: 58 | Train Loss: 0.6867956587465108 | Training Time: 641 

 End of epoch: 58 | Eval Loss: 0.6898999627755613 | Evaluating Time: 17 
Epoch: 59 | Iteration number: [10/4518] 0% | Training loss: 0.7545444667339325
Epoch: 59 | Iteration number: [20/4518] 0% | Training loss: 0.7206248819828034
Epoch: 59 | Iteration number: [30/4518] 0% | Training loss: 0.7093325952688853
Epoch: 59 | Iteration number: [40/4518] 0% | Training loss: 0.7038188368082047
Epoch: 59 | Iteration number: [50/4518] 1% | Training loss: 0.7003829944133758
Epoch: 59 | Iteration number: [60/4518] 1% | Training loss: 0.6982433050870895
Epoch: 59 | Iteration number: [70/4518] 1% | Training loss: 0.6968323460647038
Epoch: 59 | Iteration number: [80/4518] 1% | Training loss: 0.6956237033009529
Epoch: 59 | Iteration number: [90/4518] 1% | Training loss: 0.6946103625827366
Epoch: 59 | Iteration number: [100/4518] 2% | Training loss: 0.693799557685852
Epoch: 59 | Iteration number: [110/4518] 2% | Training loss: 0.693178901347247
Epoch: 59 | Iteration number: [120/4518] 2% | Training loss: 0.6925238445401192
Epoch: 59 | Iteration number: [130/4518] 2% | Training loss: 0.692105814585319
Epoch: 59 | Iteration number: [140/4518] 3% | Training loss: 0.6916458998407636
Epoch: 59 | Iteration number: [150/4518] 3% | Training loss: 0.6912876447041829
Epoch: 59 | Iteration number: [160/4518] 3% | Training loss: 0.691077470779419
Epoch: 59 | Iteration number: [170/4518] 3% | Training loss: 0.6908128023147583
Epoch: 59 | Iteration number: [180/4518] 3% | Training loss: 0.6905564682351218
Epoch: 59 | Iteration number: [190/4518] 4% | Training loss: 0.6903956993630058
Epoch: 59 | Iteration number: [200/4518] 4% | Training loss: 0.69025366127491
Epoch: 59 | Iteration number: [210/4518] 4% | Training loss: 0.6901564192204248
Epoch: 59 | Iteration number: [220/4518] 4% | Training loss: 0.6900568959387866
Epoch: 59 | Iteration number: [230/4518] 5% | Training loss: 0.6899432573629463
Epoch: 59 | Iteration number: [240/4518] 5% | Training loss: 0.6898410876592
Epoch: 59 | Iteration number: [250/4518] 5% | Training loss: 0.6896954917907715
Epoch: 59 | Iteration number: [260/4518] 5% | Training loss: 0.6895350153629597
Epoch: 59 | Iteration number: [270/4518] 5% | Training loss: 0.6894368827342987
Epoch: 59 | Iteration number: [280/4518] 6% | Training loss: 0.6893123822552817
Epoch: 59 | Iteration number: [290/4518] 6% | Training loss: 0.6892279201540453
Epoch: 59 | Iteration number: [300/4518] 6% | Training loss: 0.689130639831225
Epoch: 59 | Iteration number: [310/4518] 6% | Training loss: 0.6890486734528696
Epoch: 59 | Iteration number: [320/4518] 7% | Training loss: 0.6889673229306936
Epoch: 59 | Iteration number: [330/4518] 7% | Training loss: 0.6888740380605062
Epoch: 59 | Iteration number: [340/4518] 7% | Training loss: 0.6887981909162858
Epoch: 59 | Iteration number: [350/4518] 7% | Training loss: 0.6887739748614174
Epoch: 59 | Iteration number: [360/4518] 7% | Training loss: 0.6887269023391935
Epoch: 59 | Iteration number: [370/4518] 8% | Training loss: 0.6886420383646682
Epoch: 59 | Iteration number: [380/4518] 8% | Training loss: 0.6885963897956046
Epoch: 59 | Iteration number: [390/4518] 8% | Training loss: 0.6885470232902429
Epoch: 59 | Iteration number: [400/4518] 8% | Training loss: 0.6884918911755085
Epoch: 59 | Iteration number: [410/4518] 9% | Training loss: 0.6884628047303456
Epoch: 59 | Iteration number: [420/4518] 9% | Training loss: 0.6884219409454436
Epoch: 59 | Iteration number: [430/4518] 9% | Training loss: 0.6883824762909911
Epoch: 59 | Iteration number: [440/4518] 9% | Training loss: 0.6883536265654997
Epoch: 59 | Iteration number: [450/4518] 9% | Training loss: 0.6883174097537994
Epoch: 59 | Iteration number: [460/4518] 10% | Training loss: 0.6882707297801971
Epoch: 59 | Iteration number: [470/4518] 10% | Training loss: 0.6882544877681326
Epoch: 59 | Iteration number: [480/4518] 10% | Training loss: 0.6882190385212501
Epoch: 59 | Iteration number: [490/4518] 10% | Training loss: 0.6881717977475147
Epoch: 59 | Iteration number: [500/4518] 11% | Training loss: 0.6881397767066956
Epoch: 59 | Iteration number: [510/4518] 11% | Training loss: 0.6881196140074263
Epoch: 59 | Iteration number: [520/4518] 11% | Training loss: 0.6880992605135992
Epoch: 59 | Iteration number: [530/4518] 11% | Training loss: 0.6880618391171941
Epoch: 59 | Iteration number: [540/4518] 11% | Training loss: 0.6880394988589816
Epoch: 59 | Iteration number: [550/4518] 12% | Training loss: 0.6880130706050179
Epoch: 59 | Iteration number: [560/4518] 12% | Training loss: 0.6879978404513427
Epoch: 59 | Iteration number: [570/4518] 12% | Training loss: 0.6879803458849589
Epoch: 59 | Iteration number: [580/4518] 12% | Training loss: 0.6879620536647993
Epoch: 59 | Iteration number: [590/4518] 13% | Training loss: 0.6879416438482575
Epoch: 59 | Iteration number: [600/4518] 13% | Training loss: 0.6878922987977664
Epoch: 59 | Iteration number: [610/4518] 13% | Training loss: 0.6878985526131802
Epoch: 59 | Iteration number: [620/4518] 13% | Training loss: 0.6878851293556152
Epoch: 59 | Iteration number: [630/4518] 13% | Training loss: 0.6878457844257355
Epoch: 59 | Iteration number: [640/4518] 14% | Training loss: 0.6878107558935881
Epoch: 59 | Iteration number: [650/4518] 14% | Training loss: 0.6877684716077951
Epoch: 59 | Iteration number: [660/4518] 14% | Training loss: 0.6877518084013101
Epoch: 59 | Iteration number: [670/4518] 14% | Training loss: 0.6877360923076743
Epoch: 59 | Iteration number: [680/4518] 15% | Training loss: 0.6877250365474645
Epoch: 59 | Iteration number: [690/4518] 15% | Training loss: 0.6877244782620582
Epoch: 59 | Iteration number: [700/4518] 15% | Training loss: 0.6877077578646796
Epoch: 59 | Iteration number: [710/4518] 15% | Training loss: 0.6876988328678507
Epoch: 59 | Iteration number: [720/4518] 15% | Training loss: 0.6876946701771683
Epoch: 59 | Iteration number: [730/4518] 16% | Training loss: 0.6877067116841878
Epoch: 59 | Iteration number: [740/4518] 16% | Training loss: 0.6876950843108667
Epoch: 59 | Iteration number: [750/4518] 16% | Training loss: 0.6876734380722046
Epoch: 59 | Iteration number: [760/4518] 16% | Training loss: 0.6876696413284854
Epoch: 59 | Iteration number: [770/4518] 17% | Training loss: 0.68765105798647
Epoch: 59 | Iteration number: [780/4518] 17% | Training loss: 0.6876462950920448
Epoch: 59 | Iteration number: [790/4518] 17% | Training loss: 0.687629557334924
Epoch: 59 | Iteration number: [800/4518] 17% | Training loss: 0.6876198409497738
Epoch: 59 | Iteration number: [810/4518] 17% | Training loss: 0.6875998805334539
Epoch: 59 | Iteration number: [820/4518] 18% | Training loss: 0.6875963045329583
Epoch: 59 | Iteration number: [830/4518] 18% | Training loss: 0.6875779285488358
Epoch: 59 | Iteration number: [840/4518] 18% | Training loss: 0.6875648475828625
Epoch: 59 | Iteration number: [850/4518] 18% | Training loss: 0.6875632744676926
Epoch: 59 | Iteration number: [860/4518] 19% | Training loss: 0.6875447021667347
Epoch: 59 | Iteration number: [870/4518] 19% | Training loss: 0.6875353199997167
Epoch: 59 | Iteration number: [880/4518] 19% | Training loss: 0.6875339300795035
Epoch: 59 | Iteration number: [890/4518] 19% | Training loss: 0.6875366464089812
Epoch: 59 | Iteration number: [900/4518] 19% | Training loss: 0.6875405167208778
Epoch: 59 | Iteration number: [910/4518] 20% | Training loss: 0.6875234007180392
Epoch: 59 | Iteration number: [920/4518] 20% | Training loss: 0.6875253889223804
Epoch: 59 | Iteration number: [930/4518] 20% | Training loss: 0.6875036924756983
Epoch: 59 | Iteration number: [940/4518] 20% | Training loss: 0.6874995015403058
Epoch: 59 | Iteration number: [950/4518] 21% | Training loss: 0.6875029015541076
Epoch: 59 | Iteration number: [960/4518] 21% | Training loss: 0.6874928227315347
Epoch: 59 | Iteration number: [970/4518] 21% | Training loss: 0.68748076914512
Epoch: 59 | Iteration number: [980/4518] 21% | Training loss: 0.6874742347975167
Epoch: 59 | Iteration number: [990/4518] 21% | Training loss: 0.6874769377588021
Epoch: 59 | Iteration number: [1000/4518] 22% | Training loss: 0.6874722817540169
Epoch: 59 | Iteration number: [1010/4518] 22% | Training loss: 0.6874598439377133
Epoch: 59 | Iteration number: [1020/4518] 22% | Training loss: 0.6874450268698674
Epoch: 59 | Iteration number: [1030/4518] 22% | Training loss: 0.6874400527731886
Epoch: 59 | Iteration number: [1040/4518] 23% | Training loss: 0.6874380553571078
Epoch: 59 | Iteration number: [1050/4518] 23% | Training loss: 0.6874258791832697
Epoch: 59 | Iteration number: [1060/4518] 23% | Training loss: 0.6874156423897113
Epoch: 59 | Iteration number: [1070/4518] 23% | Training loss: 0.687425304573273
Epoch: 59 | Iteration number: [1080/4518] 23% | Training loss: 0.6874242892971745
Epoch: 59 | Iteration number: [1090/4518] 24% | Training loss: 0.6874246114437733
Epoch: 59 | Iteration number: [1100/4518] 24% | Training loss: 0.6874316722154618
Epoch: 59 | Iteration number: [1110/4518] 24% | Training loss: 0.6874275445401131
Epoch: 59 | Iteration number: [1120/4518] 24% | Training loss: 0.6874308647321803
Epoch: 59 | Iteration number: [1130/4518] 25% | Training loss: 0.6874165803985258
Epoch: 59 | Iteration number: [1140/4518] 25% | Training loss: 0.687417616446813
Epoch: 59 | Iteration number: [1150/4518] 25% | Training loss: 0.6874083205409672
Epoch: 59 | Iteration number: [1160/4518] 25% | Training loss: 0.6873952437063743
Epoch: 59 | Iteration number: [1170/4518] 25% | Training loss: 0.6873891026036352
Epoch: 59 | Iteration number: [1180/4518] 26% | Training loss: 0.6873935896461293
Epoch: 59 | Iteration number: [1190/4518] 26% | Training loss: 0.6873947049890246
Epoch: 59 | Iteration number: [1200/4518] 26% | Training loss: 0.6873897677163283
Epoch: 59 | Iteration number: [1210/4518] 26% | Training loss: 0.6873916191503036
Epoch: 59 | Iteration number: [1220/4518] 27% | Training loss: 0.6873805743260462
Epoch: 59 | Iteration number: [1230/4518] 27% | Training loss: 0.6873741055407175
Epoch: 59 | Iteration number: [1240/4518] 27% | Training loss: 0.6873738364346565
Epoch: 59 | Iteration number: [1250/4518] 27% | Training loss: 0.6873712289333344
Epoch: 59 | Iteration number: [1260/4518] 27% | Training loss: 0.6873652424131121
Epoch: 59 | Iteration number: [1270/4518] 28% | Training loss: 0.6873461289199319
Epoch: 59 | Iteration number: [1280/4518] 28% | Training loss: 0.6873414399567992
Epoch: 59 | Iteration number: [1290/4518] 28% | Training loss: 0.6873332443625428
Epoch: 59 | Iteration number: [1300/4518] 28% | Training loss: 0.687322831428968
Epoch: 59 | Iteration number: [1310/4518] 28% | Training loss: 0.6873154823561661
Epoch: 59 | Iteration number: [1320/4518] 29% | Training loss: 0.6873152591513865
Epoch: 59 | Iteration number: [1330/4518] 29% | Training loss: 0.687320505766044
Epoch: 59 | Iteration number: [1340/4518] 29% | Training loss: 0.6873298333207173
Epoch: 59 | Iteration number: [1350/4518] 29% | Training loss: 0.6873209236286305
Epoch: 59 | Iteration number: [1360/4518] 30% | Training loss: 0.6873150442452992
Epoch: 59 | Iteration number: [1370/4518] 30% | Training loss: 0.6873136174939845
Epoch: 59 | Iteration number: [1380/4518] 30% | Training loss: 0.687305472208106
Epoch: 59 | Iteration number: [1390/4518] 30% | Training loss: 0.6873050253168285
Epoch: 59 | Iteration number: [1400/4518] 30% | Training loss: 0.6873042552386012
Epoch: 59 | Iteration number: [1410/4518] 31% | Training loss: 0.6873026491056943
Epoch: 59 | Iteration number: [1420/4518] 31% | Training loss: 0.687301717467711
Epoch: 59 | Iteration number: [1430/4518] 31% | Training loss: 0.6873000057010384
Epoch: 59 | Iteration number: [1440/4518] 31% | Training loss: 0.6872895327707131
Epoch: 59 | Iteration number: [1450/4518] 32% | Training loss: 0.6872824820567822
Epoch: 59 | Iteration number: [1460/4518] 32% | Training loss: 0.6872778858224007
Epoch: 59 | Iteration number: [1470/4518] 32% | Training loss: 0.6872764842039873
Epoch: 59 | Iteration number: [1480/4518] 32% | Training loss: 0.6872710301263912
Epoch: 59 | Iteration number: [1490/4518] 32% | Training loss: 0.6872654940057921
Epoch: 59 | Iteration number: [1500/4518] 33% | Training loss: 0.6872683949867884
Epoch: 59 | Iteration number: [1510/4518] 33% | Training loss: 0.6872580686941842
Epoch: 59 | Iteration number: [1520/4518] 33% | Training loss: 0.6872527961276079
Epoch: 59 | Iteration number: [1530/4518] 33% | Training loss: 0.6872474568731645
Epoch: 59 | Iteration number: [1540/4518] 34% | Training loss: 0.6872492646242117
Epoch: 59 | Iteration number: [1550/4518] 34% | Training loss: 0.6872464120388031
Epoch: 59 | Iteration number: [1560/4518] 34% | Training loss: 0.6872401448014455
Epoch: 59 | Iteration number: [1570/4518] 34% | Training loss: 0.6872388007534538
Epoch: 59 | Iteration number: [1580/4518] 34% | Training loss: 0.6872325401140165
Epoch: 59 | Iteration number: [1590/4518] 35% | Training loss: 0.6872320003854404
Epoch: 59 | Iteration number: [1600/4518] 35% | Training loss: 0.6872320957481861
Epoch: 59 | Iteration number: [1610/4518] 35% | Training loss: 0.6872306882224468
Epoch: 59 | Iteration number: [1620/4518] 35% | Training loss: 0.6872260207747236
Epoch: 59 | Iteration number: [1630/4518] 36% | Training loss: 0.687222212516457
Epoch: 59 | Iteration number: [1640/4518] 36% | Training loss: 0.6872157679098408
Epoch: 59 | Iteration number: [1650/4518] 36% | Training loss: 0.6872146545395706
Epoch: 59 | Iteration number: [1660/4518] 36% | Training loss: 0.6872075216597822
Epoch: 59 | Iteration number: [1670/4518] 36% | Training loss: 0.6872044118935476
Epoch: 59 | Iteration number: [1680/4518] 37% | Training loss: 0.6872030376323632
Epoch: 59 | Iteration number: [1690/4518] 37% | Training loss: 0.6871970324121284
Epoch: 59 | Iteration number: [1700/4518] 37% | Training loss: 0.6871929307895548
Epoch: 59 | Iteration number: [1710/4518] 37% | Training loss: 0.6871887224110943
Epoch: 59 | Iteration number: [1720/4518] 38% | Training loss: 0.687189062528832
Epoch: 59 | Iteration number: [1730/4518] 38% | Training loss: 0.6871850592897117
Epoch: 59 | Iteration number: [1740/4518] 38% | Training loss: 0.6871808407635525
Epoch: 59 | Iteration number: [1750/4518] 38% | Training loss: 0.6871759457247598
Epoch: 59 | Iteration number: [1760/4518] 38% | Training loss: 0.6871751734817569
Epoch: 59 | Iteration number: [1770/4518] 39% | Training loss: 0.6871709634018484
Epoch: 59 | Iteration number: [1780/4518] 39% | Training loss: 0.6871679574251175
Epoch: 59 | Iteration number: [1790/4518] 39% | Training loss: 0.6871603697371882
Epoch: 59 | Iteration number: [1800/4518] 39% | Training loss: 0.6871596128410763
Epoch: 59 | Iteration number: [1810/4518] 40% | Training loss: 0.6871526112213978
Epoch: 59 | Iteration number: [1820/4518] 40% | Training loss: 0.6871530106106957
Epoch: 59 | Iteration number: [1830/4518] 40% | Training loss: 0.6871493165610266
Epoch: 59 | Iteration number: [1840/4518] 40% | Training loss: 0.6871495088157447
Epoch: 59 | Iteration number: [1850/4518] 40% | Training loss: 0.6871431386470794
Epoch: 59 | Iteration number: [1860/4518] 41% | Training loss: 0.6871420470617151
Epoch: 59 | Iteration number: [1870/4518] 41% | Training loss: 0.68713759394253
Epoch: 59 | Iteration number: [1880/4518] 41% | Training loss: 0.6871351041375322
Epoch: 59 | Iteration number: [1890/4518] 41% | Training loss: 0.6871299790957618
Epoch: 59 | Iteration number: [1900/4518] 42% | Training loss: 0.6871273190410514
Epoch: 59 | Iteration number: [1910/4518] 42% | Training loss: 0.6871165869123649
Epoch: 59 | Iteration number: [1920/4518] 42% | Training loss: 0.6871159908672174
Epoch: 59 | Iteration number: [1930/4518] 42% | Training loss: 0.6871115552946694
Epoch: 59 | Iteration number: [1940/4518] 42% | Training loss: 0.6871078575702058
Epoch: 59 | Iteration number: [1950/4518] 43% | Training loss: 0.6870967605175116
Epoch: 59 | Iteration number: [1960/4518] 43% | Training loss: 0.6870976007714563
Epoch: 59 | Iteration number: [1970/4518] 43% | Training loss: 0.6870906270397497
Epoch: 59 | Iteration number: [1980/4518] 43% | Training loss: 0.6870912329115049
Epoch: 59 | Iteration number: [1990/4518] 44% | Training loss: 0.6870825506035407
Epoch: 59 | Iteration number: [2000/4518] 44% | Training loss: 0.6870807080566883
Epoch: 59 | Iteration number: [2010/4518] 44% | Training loss: 0.687081057278078
Epoch: 59 | Iteration number: [2020/4518] 44% | Training loss: 0.6870883217837551
Epoch: 59 | Iteration number: [2030/4518] 44% | Training loss: 0.6870788323174557
Epoch: 59 | Iteration number: [2040/4518] 45% | Training loss: 0.6870773356334836
Epoch: 59 | Iteration number: [2050/4518] 45% | Training loss: 0.6870775743519387
Epoch: 59 | Iteration number: [2060/4518] 45% | Training loss: 0.6870732550482148
Epoch: 59 | Iteration number: [2070/4518] 45% | Training loss: 0.6870699250467733
Epoch: 59 | Iteration number: [2080/4518] 46% | Training loss: 0.6870723250680245
Epoch: 59 | Iteration number: [2090/4518] 46% | Training loss: 0.6870706956637533
Epoch: 59 | Iteration number: [2100/4518] 46% | Training loss: 0.6870682244357609
Epoch: 59 | Iteration number: [2110/4518] 46% | Training loss: 0.6870631873607635
Epoch: 59 | Iteration number: [2120/4518] 46% | Training loss: 0.687067082271261
Epoch: 59 | Iteration number: [2130/4518] 47% | Training loss: 0.6870715052868839
Epoch: 59 | Iteration number: [2140/4518] 47% | Training loss: 0.687069462838574
Epoch: 59 | Iteration number: [2150/4518] 47% | Training loss: 0.6870716492519823
Epoch: 59 | Iteration number: [2160/4518] 47% | Training loss: 0.6870742215326539
Epoch: 59 | Iteration number: [2170/4518] 48% | Training loss: 0.6870766619108789
Epoch: 59 | Iteration number: [2180/4518] 48% | Training loss: 0.6870811540872679
Epoch: 59 | Iteration number: [2190/4518] 48% | Training loss: 0.6870810088773841
Epoch: 59 | Iteration number: [2200/4518] 48% | Training loss: 0.6870791309530084
Epoch: 59 | Iteration number: [2210/4518] 48% | Training loss: 0.6870699254366067
Epoch: 59 | Iteration number: [2220/4518] 49% | Training loss: 0.6870704740822852
Epoch: 59 | Iteration number: [2230/4518] 49% | Training loss: 0.6870720503843418
Epoch: 59 | Iteration number: [2240/4518] 49% | Training loss: 0.6870704778337053
Epoch: 59 | Iteration number: [2250/4518] 49% | Training loss: 0.6870710946189033
Epoch: 59 | Iteration number: [2260/4518] 50% | Training loss: 0.6870680828010086
Epoch: 59 | Iteration number: [2270/4518] 50% | Training loss: 0.6870693339125176
Epoch: 59 | Iteration number: [2280/4518] 50% | Training loss: 0.6870681359841112
Epoch: 59 | Iteration number: [2290/4518] 50% | Training loss: 0.6870682608873042
Epoch: 59 | Iteration number: [2300/4518] 50% | Training loss: 0.6870714224680611
Epoch: 59 | Iteration number: [2310/4518] 51% | Training loss: 0.687063499265935
Epoch: 59 | Iteration number: [2320/4518] 51% | Training loss: 0.6870609719948522
Epoch: 59 | Iteration number: [2330/4518] 51% | Training loss: 0.6870560796219903
Epoch: 59 | Iteration number: [2340/4518] 51% | Training loss: 0.6870547792086235
Epoch: 59 | Iteration number: [2350/4518] 52% | Training loss: 0.6870548475295939
Epoch: 59 | Iteration number: [2360/4518] 52% | Training loss: 0.6870506667737234
Epoch: 59 | Iteration number: [2370/4518] 52% | Training loss: 0.6870535847003952
Epoch: 59 | Iteration number: [2380/4518] 52% | Training loss: 0.6870583421292425
Epoch: 59 | Iteration number: [2390/4518] 52% | Training loss: 0.6870573066767289
Epoch: 59 | Iteration number: [2400/4518] 53% | Training loss: 0.687057123084863
Epoch: 59 | Iteration number: [2410/4518] 53% | Training loss: 0.6870539670910578
Epoch: 59 | Iteration number: [2420/4518] 53% | Training loss: 0.6870539072377623
Epoch: 59 | Iteration number: [2430/4518] 53% | Training loss: 0.6870536242738182
Epoch: 59 | Iteration number: [2440/4518] 54% | Training loss: 0.6870524310674824
Epoch: 59 | Iteration number: [2450/4518] 54% | Training loss: 0.687053150717093
Epoch: 59 | Iteration number: [2460/4518] 54% | Training loss: 0.6870455920696259
Epoch: 59 | Iteration number: [2470/4518] 54% | Training loss: 0.6870441997823445
Epoch: 59 | Iteration number: [2480/4518] 54% | Training loss: 0.6870447195345356
Epoch: 59 | Iteration number: [2490/4518] 55% | Training loss: 0.6870439557186571
Epoch: 59 | Iteration number: [2500/4518] 55% | Training loss: 0.6870432020187378
Epoch: 59 | Iteration number: [2510/4518] 55% | Training loss: 0.6870430090512888
Epoch: 59 | Iteration number: [2520/4518] 55% | Training loss: 0.6870440613655817
Epoch: 59 | Iteration number: [2530/4518] 55% | Training loss: 0.6870463783090764
Epoch: 59 | Iteration number: [2540/4518] 56% | Training loss: 0.6870462771945113
Epoch: 59 | Iteration number: [2550/4518] 56% | Training loss: 0.6870440935387331
Epoch: 59 | Iteration number: [2560/4518] 56% | Training loss: 0.6870401756139473
Epoch: 59 | Iteration number: [2570/4518] 56% | Training loss: 0.6870411173146986
Epoch: 59 | Iteration number: [2580/4518] 57% | Training loss: 0.6870378864596981
Epoch: 59 | Iteration number: [2590/4518] 57% | Training loss: 0.6870346913236449
Epoch: 59 | Iteration number: [2600/4518] 57% | Training loss: 0.6870317602386842
Epoch: 59 | Iteration number: [2610/4518] 57% | Training loss: 0.6870290278703317
Epoch: 59 | Iteration number: [2620/4518] 57% | Training loss: 0.6870264906692141
Epoch: 59 | Iteration number: [2630/4518] 58% | Training loss: 0.687023932149655
Epoch: 59 | Iteration number: [2640/4518] 58% | Training loss: 0.6870234686768416
Epoch: 59 | Iteration number: [2650/4518] 58% | Training loss: 0.6870243908549255
Epoch: 59 | Iteration number: [2660/4518] 58% | Training loss: 0.6870233641083079
Epoch: 59 | Iteration number: [2670/4518] 59% | Training loss: 0.6870184948605098
Epoch: 59 | Iteration number: [2680/4518] 59% | Training loss: 0.687014998095249
Epoch: 59 | Iteration number: [2690/4518] 59% | Training loss: 0.6870149679565075
Epoch: 59 | Iteration number: [2700/4518] 59% | Training loss: 0.6870090341126477
Epoch: 59 | Iteration number: [2710/4518] 59% | Training loss: 0.6870097551838499
Epoch: 59 | Iteration number: [2720/4518] 60% | Training loss: 0.6870079446583987
Epoch: 59 | Iteration number: [2730/4518] 60% | Training loss: 0.6870093921820323
Epoch: 59 | Iteration number: [2740/4518] 60% | Training loss: 0.6870077892376558
Epoch: 59 | Iteration number: [2750/4518] 60% | Training loss: 0.6870074056928808
Epoch: 59 | Iteration number: [2760/4518] 61% | Training loss: 0.6870099024712175
Epoch: 59 | Iteration number: [2770/4518] 61% | Training loss: 0.6870081986976444
Epoch: 59 | Iteration number: [2780/4518] 61% | Training loss: 0.6870090179520545
Epoch: 59 | Iteration number: [2790/4518] 61% | Training loss: 0.6870077176760602
Epoch: 59 | Iteration number: [2800/4518] 61% | Training loss: 0.6870057166048459
Epoch: 59 | Iteration number: [2810/4518] 62% | Training loss: 0.6870110451963024
Epoch: 59 | Iteration number: [2820/4518] 62% | Training loss: 0.6870057419048133
Epoch: 59 | Iteration number: [2830/4518] 62% | Training loss: 0.6870076046183758
Epoch: 59 | Iteration number: [2840/4518] 62% | Training loss: 0.6870052542904733
Epoch: 59 | Iteration number: [2850/4518] 63% | Training loss: 0.6870074620372371
Epoch: 59 | Iteration number: [2860/4518] 63% | Training loss: 0.6870075544694086
Epoch: 59 | Iteration number: [2870/4518] 63% | Training loss: 0.6870059593629338
Epoch: 59 | Iteration number: [2880/4518] 63% | Training loss: 0.6870090321948131
Epoch: 59 | Iteration number: [2890/4518] 63% | Training loss: 0.68700631609425
Epoch: 59 | Iteration number: [2900/4518] 64% | Training loss: 0.6870028567314148
Epoch: 59 | Iteration number: [2910/4518] 64% | Training loss: 0.6870024665729286
Epoch: 59 | Iteration number: [2920/4518] 64% | Training loss: 0.6870017543026846
Epoch: 59 | Iteration number: [2930/4518] 64% | Training loss: 0.6869988691888165
Epoch: 59 | Iteration number: [2940/4518] 65% | Training loss: 0.6870006437609796
Epoch: 59 | Iteration number: [2950/4518] 65% | Training loss: 0.6869967549736217
Epoch: 59 | Iteration number: [2960/4518] 65% | Training loss: 0.6869973966801489
Epoch: 59 | Iteration number: [2970/4518] 65% | Training loss: 0.686998068744486
Epoch: 59 | Iteration number: [2980/4518] 65% | Training loss: 0.6869892070757463
Epoch: 59 | Iteration number: [2990/4518] 66% | Training loss: 0.6869915321917837
Epoch: 59 | Iteration number: [3000/4518] 66% | Training loss: 0.6869892893632253
Epoch: 59 | Iteration number: [3010/4518] 66% | Training loss: 0.6869865155695285
Epoch: 59 | Iteration number: [3020/4518] 66% | Training loss: 0.6869875884016619
Epoch: 59 | Iteration number: [3030/4518] 67% | Training loss: 0.6869884719156196
Epoch: 59 | Iteration number: [3040/4518] 67% | Training loss: 0.6869801769327176
Epoch: 59 | Iteration number: [3050/4518] 67% | Training loss: 0.6869793145187566
Epoch: 59 | Iteration number: [3060/4518] 67% | Training loss: 0.6869801126858768
Epoch: 59 | Iteration number: [3070/4518] 67% | Training loss: 0.6869831591359179
Epoch: 59 | Iteration number: [3080/4518] 68% | Training loss: 0.686981719674228
Epoch: 59 | Iteration number: [3090/4518] 68% | Training loss: 0.6869781123974562
Epoch: 59 | Iteration number: [3100/4518] 68% | Training loss: 0.6869773217362742
Epoch: 59 | Iteration number: [3110/4518] 68% | Training loss: 0.686980045263407
Epoch: 59 | Iteration number: [3120/4518] 69% | Training loss: 0.686977818245307
Epoch: 59 | Iteration number: [3130/4518] 69% | Training loss: 0.6869796969448797
Epoch: 59 | Iteration number: [3140/4518] 69% | Training loss: 0.6869766226619672
Epoch: 59 | Iteration number: [3150/4518] 69% | Training loss: 0.6869797351246788
Epoch: 59 | Iteration number: [3160/4518] 69% | Training loss: 0.6869843587656564
Epoch: 59 | Iteration number: [3170/4518] 70% | Training loss: 0.6869834744215764
Epoch: 59 | Iteration number: [3180/4518] 70% | Training loss: 0.6869813562001822
Epoch: 59 | Iteration number: [3190/4518] 70% | Training loss: 0.6869782723603204
Epoch: 59 | Iteration number: [3200/4518] 70% | Training loss: 0.6869760986603797
Epoch: 59 | Iteration number: [3210/4518] 71% | Training loss: 0.6869776612873018
Epoch: 59 | Iteration number: [3220/4518] 71% | Training loss: 0.6869710576645336
Epoch: 59 | Iteration number: [3230/4518] 71% | Training loss: 0.6869716694480494
Epoch: 59 | Iteration number: [3240/4518] 71% | Training loss: 0.6869688705529695
Epoch: 59 | Iteration number: [3250/4518] 71% | Training loss: 0.6869639821052551
Epoch: 59 | Iteration number: [3260/4518] 72% | Training loss: 0.686966195793971
Epoch: 59 | Iteration number: [3270/4518] 72% | Training loss: 0.686962835395008
Epoch: 59 | Iteration number: [3280/4518] 72% | Training loss: 0.6869624663780375
Epoch: 59 | Iteration number: [3290/4518] 72% | Training loss: 0.6869637649291193
Epoch: 59 | Iteration number: [3300/4518] 73% | Training loss: 0.6869627474474185
Epoch: 59 | Iteration number: [3310/4518] 73% | Training loss: 0.6869597829180542
Epoch: 59 | Iteration number: [3320/4518] 73% | Training loss: 0.6869619499128985
Epoch: 59 | Iteration number: [3330/4518] 73% | Training loss: 0.6869639349771334
Epoch: 59 | Iteration number: [3340/4518] 73% | Training loss: 0.6869617215173687
Epoch: 59 | Iteration number: [3350/4518] 74% | Training loss: 0.6869615829346785
Epoch: 59 | Iteration number: [3360/4518] 74% | Training loss: 0.6869611215378557
Epoch: 59 | Iteration number: [3370/4518] 74% | Training loss: 0.6869642468163805
Epoch: 59 | Iteration number: [3380/4518] 74% | Training loss: 0.6869665235986371
Epoch: 59 | Iteration number: [3390/4518] 75% | Training loss: 0.68696610505602
Epoch: 59 | Iteration number: [3400/4518] 75% | Training loss: 0.686968095758382
Epoch: 59 | Iteration number: [3410/4518] 75% | Training loss: 0.6869641077833092
Epoch: 59 | Iteration number: [3420/4518] 75% | Training loss: 0.6869613840566045
Epoch: 59 | Iteration number: [3430/4518] 75% | Training loss: 0.6869593652274796
Epoch: 59 | Iteration number: [3440/4518] 76% | Training loss: 0.6869593104304269
Epoch: 59 | Iteration number: [3450/4518] 76% | Training loss: 0.6869573051860367
Epoch: 59 | Iteration number: [3460/4518] 76% | Training loss: 0.6869587897737591
Epoch: 59 | Iteration number: [3470/4518] 76% | Training loss: 0.6869580470175839
Epoch: 59 | Iteration number: [3480/4518] 77% | Training loss: 0.6869576571145277
Epoch: 59 | Iteration number: [3490/4518] 77% | Training loss: 0.686959287686471
Epoch: 59 | Iteration number: [3500/4518] 77% | Training loss: 0.6869628742081778
Epoch: 59 | Iteration number: [3510/4518] 77% | Training loss: 0.6869631354625408
Epoch: 59 | Iteration number: [3520/4518] 77% | Training loss: 0.6869638292118907
Epoch: 59 | Iteration number: [3530/4518] 78% | Training loss: 0.6869611719343548
Epoch: 59 | Iteration number: [3540/4518] 78% | Training loss: 0.6869622808728515
Epoch: 59 | Iteration number: [3550/4518] 78% | Training loss: 0.686957471773658
Epoch: 59 | Iteration number: [3560/4518] 78% | Training loss: 0.6869577562541105
Epoch: 59 | Iteration number: [3570/4518] 79% | Training loss: 0.6869569397106224
Epoch: 59 | Iteration number: [3580/4518] 79% | Training loss: 0.6869544834731012
Epoch: 59 | Iteration number: [3590/4518] 79% | Training loss: 0.6869519552812603
Epoch: 59 | Iteration number: [3600/4518] 79% | Training loss: 0.6869491517212656
Epoch: 59 | Iteration number: [3610/4518] 79% | Training loss: 0.6869453456758462
Epoch: 59 | Iteration number: [3620/4518] 80% | Training loss: 0.6869451726668447
Epoch: 59 | Iteration number: [3630/4518] 80% | Training loss: 0.6869458252076603
Epoch: 59 | Iteration number: [3640/4518] 80% | Training loss: 0.6869451988529373
Epoch: 59 | Iteration number: [3650/4518] 80% | Training loss: 0.6869460292548349
Epoch: 59 | Iteration number: [3660/4518] 81% | Training loss: 0.6869502072451544
Epoch: 59 | Iteration number: [3670/4518] 81% | Training loss: 0.686949216458713
Epoch: 59 | Iteration number: [3680/4518] 81% | Training loss: 0.6869506186603204
Epoch: 59 | Iteration number: [3690/4518] 81% | Training loss: 0.6869523543167889
Epoch: 59 | Iteration number: [3700/4518] 81% | Training loss: 0.6869487433981251
Epoch: 59 | Iteration number: [3710/4518] 82% | Training loss: 0.6869514282501611
Epoch: 59 | Iteration number: [3720/4518] 82% | Training loss: 0.6869519409473225
Epoch: 59 | Iteration number: [3730/4518] 82% | Training loss: 0.6869495449372974
Epoch: 59 | Iteration number: [3740/4518] 82% | Training loss: 0.6869488394356029
Epoch: 59 | Iteration number: [3750/4518] 83% | Training loss: 0.6869508935451507
Epoch: 59 | Iteration number: [3760/4518] 83% | Training loss: 0.6869537401072523
Epoch: 59 | Iteration number: [3770/4518] 83% | Training loss: 0.686952897060455
Epoch: 59 | Iteration number: [3780/4518] 83% | Training loss: 0.6869521699727528
Epoch: 59 | Iteration number: [3790/4518] 83% | Training loss: 0.6869520918517754
Epoch: 59 | Iteration number: [3800/4518] 84% | Training loss: 0.6869527725640097
Epoch: 59 | Iteration number: [3810/4518] 84% | Training loss: 0.6869511239797738
Epoch: 59 | Iteration number: [3820/4518] 84% | Training loss: 0.6869516108984722
Epoch: 59 | Iteration number: [3830/4518] 84% | Training loss: 0.6869497625385812
Epoch: 59 | Iteration number: [3840/4518] 84% | Training loss: 0.6869475929842641
Epoch: 59 | Iteration number: [3850/4518] 85% | Training loss: 0.6869497462062093
Epoch: 59 | Iteration number: [3860/4518] 85% | Training loss: 0.6869495982487585
Epoch: 59 | Iteration number: [3870/4518] 85% | Training loss: 0.6869475722620961
Epoch: 59 | Iteration number: [3880/4518] 85% | Training loss: 0.686947036695849
Epoch: 59 | Iteration number: [3890/4518] 86% | Training loss: 0.6869475654434116
Epoch: 59 | Iteration number: [3900/4518] 86% | Training loss: 0.6869472126166026
Epoch: 59 | Iteration number: [3910/4518] 86% | Training loss: 0.6869489234274305
Epoch: 59 | Iteration number: [3920/4518] 86% | Training loss: 0.6869515893866821
Epoch: 59 | Iteration number: [3930/4518] 86% | Training loss: 0.6869526791056907
Epoch: 59 | Iteration number: [3940/4518] 87% | Training loss: 0.6869529026413932
Epoch: 59 | Iteration number: [3950/4518] 87% | Training loss: 0.6869515288932414
Epoch: 59 | Iteration number: [3960/4518] 87% | Training loss: 0.6869511152156675
Epoch: 59 | Iteration number: [3970/4518] 87% | Training loss: 0.6869499582037217
Epoch: 59 | Iteration number: [3980/4518] 88% | Training loss: 0.6869482638398606
Epoch: 59 | Iteration number: [3990/4518] 88% | Training loss: 0.6869473283153429
Epoch: 59 | Iteration number: [4000/4518] 88% | Training loss: 0.6869521216005087
Epoch: 59 | Iteration number: [4010/4518] 88% | Training loss: 0.686951145715547
Epoch: 59 | Iteration number: [4020/4518] 88% | Training loss: 0.686945595507005
Epoch: 59 | Iteration number: [4030/4518] 89% | Training loss: 0.6869449238623342
Epoch: 59 | Iteration number: [4040/4518] 89% | Training loss: 0.686947259410183
Epoch: 59 | Iteration number: [4050/4518] 89% | Training loss: 0.6869444931877984
Epoch: 59 | Iteration number: [4060/4518] 89% | Training loss: 0.6869427499953162
Epoch: 59 | Iteration number: [4070/4518] 90% | Training loss: 0.6869432825128335
Epoch: 59 | Iteration number: [4080/4518] 90% | Training loss: 0.6869426747455316
Epoch: 59 | Iteration number: [4090/4518] 90% | Training loss: 0.6869424522943194
Epoch: 59 | Iteration number: [4100/4518] 90% | Training loss: 0.686939400899701
Epoch: 59 | Iteration number: [4110/4518] 90% | Training loss: 0.6869390274486402
Epoch: 59 | Iteration number: [4120/4518] 91% | Training loss: 0.6869426299212048
Epoch: 59 | Iteration number: [4130/4518] 91% | Training loss: 0.6869427655135748
Epoch: 59 | Iteration number: [4140/4518] 91% | Training loss: 0.6869426993356235
Epoch: 59 | Iteration number: [4150/4518] 91% | Training loss: 0.6869386984497667
Epoch: 59 | Iteration number: [4160/4518] 92% | Training loss: 0.6869385508677134
Epoch: 59 | Iteration number: [4170/4518] 92% | Training loss: 0.6869391927044455
Epoch: 59 | Iteration number: [4180/4518] 92% | Training loss: 0.68693760291241
Epoch: 59 | Iteration number: [4190/4518] 92% | Training loss: 0.6869378913558468
Epoch: 59 | Iteration number: [4200/4518] 92% | Training loss: 0.6869392532535962
Epoch: 59 | Iteration number: [4210/4518] 93% | Training loss: 0.6869364007493379
Epoch: 59 | Iteration number: [4220/4518] 93% | Training loss: 0.6869347671761897
Epoch: 59 | Iteration number: [4230/4518] 93% | Training loss: 0.6869352778785336
Epoch: 59 | Iteration number: [4240/4518] 93% | Training loss: 0.6869370576064542
Epoch: 59 | Iteration number: [4250/4518] 94% | Training loss: 0.686935132040697
Epoch: 59 | Iteration number: [4260/4518] 94% | Training loss: 0.6869359407766324
Epoch: 59 | Iteration number: [4270/4518] 94% | Training loss: 0.6869355126203363
Epoch: 59 | Iteration number: [4280/4518] 94% | Training loss: 0.6869368694653021
Epoch: 59 | Iteration number: [4290/4518] 94% | Training loss: 0.6869359637890662
Epoch: 59 | Iteration number: [4300/4518] 95% | Training loss: 0.6869369059108025
Epoch: 59 | Iteration number: [4310/4518] 95% | Training loss: 0.6869353393390948
Epoch: 59 | Iteration number: [4320/4518] 95% | Training loss: 0.686937378236541
Epoch: 59 | Iteration number: [4330/4518] 95% | Training loss: 0.6869371940439898
Epoch: 59 | Iteration number: [4340/4518] 96% | Training loss: 0.6869355615932271
Epoch: 59 | Iteration number: [4350/4518] 96% | Training loss: 0.6869359326773676
Epoch: 59 | Iteration number: [4360/4518] 96% | Training loss: 0.6869370787515553
Epoch: 59 | Iteration number: [4370/4518] 96% | Training loss: 0.686939000169527
Epoch: 59 | Iteration number: [4380/4518] 96% | Training loss: 0.6869388712731671
Epoch: 59 | Iteration number: [4390/4518] 97% | Training loss: 0.6869392739070032
Epoch: 59 | Iteration number: [4400/4518] 97% | Training loss: 0.6869383751397783
Epoch: 59 | Iteration number: [4410/4518] 97% | Training loss: 0.6869388169577333
Epoch: 59 | Iteration number: [4420/4518] 97% | Training loss: 0.6869386524231725
Epoch: 59 | Iteration number: [4430/4518] 98% | Training loss: 0.6869414872159807
Epoch: 59 | Iteration number: [4440/4518] 98% | Training loss: 0.6869422784796706
Epoch: 59 | Iteration number: [4450/4518] 98% | Training loss: 0.6869432329863645
Epoch: 59 | Iteration number: [4460/4518] 98% | Training loss: 0.6869429922558267
Epoch: 59 | Iteration number: [4470/4518] 98% | Training loss: 0.6869420751495916
Epoch: 59 | Iteration number: [4480/4518] 99% | Training loss: 0.6869415930472315
Epoch: 59 | Iteration number: [4490/4518] 99% | Training loss: 0.6869438276524533
Epoch: 59 | Iteration number: [4500/4518] 99% | Training loss: 0.6869453225135803
Epoch: 59 | Iteration number: [4510/4518] 99% | Training loss: 0.6869452782586515

 End of epoch: 59 | Train Loss: 0.6867959907409521 | Training Time: 640 

 End of epoch: 59 | Eval Loss: 0.6898757596405185 | Evaluating Time: 17 
Epoch: 60 | Iteration number: [10/4518] 0% | Training loss: 0.7563752174377442
Epoch: 60 | Iteration number: [20/4518] 0% | Training loss: 0.7215821385383606
Epoch: 60 | Iteration number: [30/4518] 0% | Training loss: 0.7101129571596781
Epoch: 60 | Iteration number: [40/4518] 0% | Training loss: 0.7043598458170891
Epoch: 60 | Iteration number: [50/4518] 1% | Training loss: 0.7008751022815705
Epoch: 60 | Iteration number: [60/4518] 1% | Training loss: 0.6984456539154053
Epoch: 60 | Iteration number: [70/4518] 1% | Training loss: 0.6968895716326577
Epoch: 60 | Iteration number: [80/4518] 1% | Training loss: 0.695695536583662
Epoch: 60 | Iteration number: [90/4518] 1% | Training loss: 0.6948177708519829
Epoch: 60 | Iteration number: [100/4518] 2% | Training loss: 0.6941390973329544
Epoch: 60 | Iteration number: [110/4518] 2% | Training loss: 0.6936003663323143
Epoch: 60 | Iteration number: [120/4518] 2% | Training loss: 0.6931134968996048
Epoch: 60 | Iteration number: [130/4518] 2% | Training loss: 0.6925522845525008
Epoch: 60 | Iteration number: [140/4518] 3% | Training loss: 0.6920680961438588
Epoch: 60 | Iteration number: [150/4518] 3% | Training loss: 0.6917240313688914
Epoch: 60 | Iteration number: [160/4518] 3% | Training loss: 0.6913412433117628
Epoch: 60 | Iteration number: [170/4518] 3% | Training loss: 0.6910458084414987
Epoch: 60 | Iteration number: [180/4518] 3% | Training loss: 0.6908070882161458
Epoch: 60 | Iteration number: [190/4518] 4% | Training loss: 0.6906331231719569
Epoch: 60 | Iteration number: [200/4518] 4% | Training loss: 0.6904457733035088
Epoch: 60 | Iteration number: [210/4518] 4% | Training loss: 0.6902626650674003
Epoch: 60 | Iteration number: [220/4518] 4% | Training loss: 0.6901242497292432
Epoch: 60 | Iteration number: [230/4518] 5% | Training loss: 0.6899605763995129
Epoch: 60 | Iteration number: [240/4518] 5% | Training loss: 0.6898559488356113
Epoch: 60 | Iteration number: [250/4518] 5% | Training loss: 0.6897068774700165
Epoch: 60 | Iteration number: [260/4518] 5% | Training loss: 0.6895918843837885
Epoch: 60 | Iteration number: [270/4518] 5% | Training loss: 0.6895538314625069
Epoch: 60 | Iteration number: [280/4518] 6% | Training loss: 0.689441727740424
Epoch: 60 | Iteration number: [290/4518] 6% | Training loss: 0.6893331817511854
Epoch: 60 | Iteration number: [300/4518] 6% | Training loss: 0.6892547313372294
Epoch: 60 | Iteration number: [310/4518] 6% | Training loss: 0.6891841607709085
Epoch: 60 | Iteration number: [320/4518] 7% | Training loss: 0.6891484737396241
Epoch: 60 | Iteration number: [330/4518] 7% | Training loss: 0.6891082135113803
Epoch: 60 | Iteration number: [340/4518] 7% | Training loss: 0.6890843873514848
Epoch: 60 | Iteration number: [350/4518] 7% | Training loss: 0.6890361196654183
Epoch: 60 | Iteration number: [360/4518] 7% | Training loss: 0.6889766643444697
Epoch: 60 | Iteration number: [370/4518] 8% | Training loss: 0.6889010862724201
Epoch: 60 | Iteration number: [380/4518] 8% | Training loss: 0.6888396253711299
Epoch: 60 | Iteration number: [390/4518] 8% | Training loss: 0.6888036005007915
Epoch: 60 | Iteration number: [400/4518] 8% | Training loss: 0.6887463320791721
Epoch: 60 | Iteration number: [410/4518] 9% | Training loss: 0.6887032399817211
Epoch: 60 | Iteration number: [420/4518] 9% | Training loss: 0.6886844091472172
Epoch: 60 | Iteration number: [430/4518] 9% | Training loss: 0.6886181974133779
Epoch: 60 | Iteration number: [440/4518] 9% | Training loss: 0.688575515286489
Epoch: 60 | Iteration number: [450/4518] 9% | Training loss: 0.688549923102061
Epoch: 60 | Iteration number: [460/4518] 10% | Training loss: 0.6885219581749128
Epoch: 60 | Iteration number: [470/4518] 10% | Training loss: 0.6884599314091053
Epoch: 60 | Iteration number: [480/4518] 10% | Training loss: 0.6884119225045046
Epoch: 60 | Iteration number: [490/4518] 10% | Training loss: 0.6883621140402191
Epoch: 60 | Iteration number: [500/4518] 11% | Training loss: 0.6883532041311264
Epoch: 60 | Iteration number: [510/4518] 11% | Training loss: 0.688311037012175
Epoch: 60 | Iteration number: [520/4518] 11% | Training loss: 0.6883112532588151
Epoch: 60 | Iteration number: [530/4518] 11% | Training loss: 0.6882763217080314
Epoch: 60 | Iteration number: [540/4518] 11% | Training loss: 0.6882589087442116
Epoch: 60 | Iteration number: [550/4518] 12% | Training loss: 0.6882157910953869
Epoch: 60 | Iteration number: [560/4518] 12% | Training loss: 0.6882139452866145
Epoch: 60 | Iteration number: [570/4518] 12% | Training loss: 0.6881908537003032
Epoch: 60 | Iteration number: [580/4518] 12% | Training loss: 0.6881530078320668
Epoch: 60 | Iteration number: [590/4518] 13% | Training loss: 0.6881228528790555
Epoch: 60 | Iteration number: [600/4518] 13% | Training loss: 0.6881154470642408
Epoch: 60 | Iteration number: [610/4518] 13% | Training loss: 0.6881078051739051
Epoch: 60 | Iteration number: [620/4518] 13% | Training loss: 0.6880762353058785
Epoch: 60 | Iteration number: [630/4518] 13% | Training loss: 0.6880480264860486
Epoch: 60 | Iteration number: [640/4518] 14% | Training loss: 0.6880545960739255
Epoch: 60 | Iteration number: [650/4518] 14% | Training loss: 0.6880339929690727
Epoch: 60 | Iteration number: [660/4518] 14% | Training loss: 0.6880162688818845
Epoch: 60 | Iteration number: [670/4518] 14% | Training loss: 0.6880009918960173
Epoch: 60 | Iteration number: [680/4518] 15% | Training loss: 0.6879816348061842
Epoch: 60 | Iteration number: [690/4518] 15% | Training loss: 0.6879502633343573
Epoch: 60 | Iteration number: [700/4518] 15% | Training loss: 0.6879267595495496
Epoch: 60 | Iteration number: [710/4518] 15% | Training loss: 0.6878937929448947
Epoch: 60 | Iteration number: [720/4518] 15% | Training loss: 0.6878688333763017
Epoch: 60 | Iteration number: [730/4518] 16% | Training loss: 0.687852905874383
Epoch: 60 | Iteration number: [740/4518] 16% | Training loss: 0.687826909487312
Epoch: 60 | Iteration number: [750/4518] 16% | Training loss: 0.6878089697360993
Epoch: 60 | Iteration number: [760/4518] 16% | Training loss: 0.6878056538732429
Epoch: 60 | Iteration number: [770/4518] 17% | Training loss: 0.6878056660875097
Epoch: 60 | Iteration number: [780/4518] 17% | Training loss: 0.6878024237278181
Epoch: 60 | Iteration number: [790/4518] 17% | Training loss: 0.6877908266797851
Epoch: 60 | Iteration number: [800/4518] 17% | Training loss: 0.6877772519737482
Epoch: 60 | Iteration number: [810/4518] 17% | Training loss: 0.6877625934135767
Epoch: 60 | Iteration number: [820/4518] 18% | Training loss: 0.6877590814741646
Epoch: 60 | Iteration number: [830/4518] 18% | Training loss: 0.6877312979066228
Epoch: 60 | Iteration number: [840/4518] 18% | Training loss: 0.6877096363476345
Epoch: 60 | Iteration number: [850/4518] 18% | Training loss: 0.6877120965368607
Epoch: 60 | Iteration number: [860/4518] 19% | Training loss: 0.6877037253490714
Epoch: 60 | Iteration number: [870/4518] 19% | Training loss: 0.687698089596869
Epoch: 60 | Iteration number: [880/4518] 19% | Training loss: 0.6876957726072181
Epoch: 60 | Iteration number: [890/4518] 19% | Training loss: 0.6876748825726884
Epoch: 60 | Iteration number: [900/4518] 19% | Training loss: 0.6876443077458275
Epoch: 60 | Iteration number: [910/4518] 20% | Training loss: 0.6876282725360368
Epoch: 60 | Iteration number: [920/4518] 20% | Training loss: 0.6876267124129378
Epoch: 60 | Iteration number: [930/4518] 20% | Training loss: 0.6876301862219328
Epoch: 60 | Iteration number: [940/4518] 20% | Training loss: 0.687622394840768
Epoch: 60 | Iteration number: [950/4518] 21% | Training loss: 0.6876062627842552
Epoch: 60 | Iteration number: [960/4518] 21% | Training loss: 0.687615406078597
Epoch: 60 | Iteration number: [970/4518] 21% | Training loss: 0.6876016717596153
Epoch: 60 | Iteration number: [980/4518] 21% | Training loss: 0.6875907037331134
Epoch: 60 | Iteration number: [990/4518] 21% | Training loss: 0.6875836008726949
Epoch: 60 | Iteration number: [1000/4518] 22% | Training loss: 0.6875939298868179
Epoch: 60 | Iteration number: [1010/4518] 22% | Training loss: 0.6875894438512254
Epoch: 60 | Iteration number: [1020/4518] 22% | Training loss: 0.687583829667054
Epoch: 60 | Iteration number: [1030/4518] 22% | Training loss: 0.6875752555513845
Epoch: 60 | Iteration number: [1040/4518] 23% | Training loss: 0.6875726622457687
Epoch: 60 | Iteration number: [1050/4518] 23% | Training loss: 0.687566488300051
Epoch: 60 | Iteration number: [1060/4518] 23% | Training loss: 0.6875648952317688
Epoch: 60 | Iteration number: [1070/4518] 23% | Training loss: 0.6875552997967908
Epoch: 60 | Iteration number: [1080/4518] 23% | Training loss: 0.6875527646806505
Epoch: 60 | Iteration number: [1090/4518] 24% | Training loss: 0.6875525545089617
Epoch: 60 | Iteration number: [1100/4518] 24% | Training loss: 0.6875493674928492
Epoch: 60 | Iteration number: [1110/4518] 24% | Training loss: 0.6875318799469922
Epoch: 60 | Iteration number: [1120/4518] 24% | Training loss: 0.6875262480761324
Epoch: 60 | Iteration number: [1130/4518] 25% | Training loss: 0.6875089576814027
Epoch: 60 | Iteration number: [1140/4518] 25% | Training loss: 0.6875062030135539
Epoch: 60 | Iteration number: [1150/4518] 25% | Training loss: 0.6874973706058833
Epoch: 60 | Iteration number: [1160/4518] 25% | Training loss: 0.6874893478278457
Epoch: 60 | Iteration number: [1170/4518] 25% | Training loss: 0.6874763267162519
Epoch: 60 | Iteration number: [1180/4518] 26% | Training loss: 0.6874729596457239
Epoch: 60 | Iteration number: [1190/4518] 26% | Training loss: 0.687479022420755
Epoch: 60 | Iteration number: [1200/4518] 26% | Training loss: 0.687470524807771
Epoch: 60 | Iteration number: [1210/4518] 26% | Training loss: 0.6874591420997272
Epoch: 60 | Iteration number: [1220/4518] 27% | Training loss: 0.6874448196321238
Epoch: 60 | Iteration number: [1230/4518] 27% | Training loss: 0.6874435882258222
Epoch: 60 | Iteration number: [1240/4518] 27% | Training loss: 0.6874488799802718
Epoch: 60 | Iteration number: [1250/4518] 27% | Training loss: 0.687442458486557
Epoch: 60 | Iteration number: [1260/4518] 27% | Training loss: 0.6874443418449826
Epoch: 60 | Iteration number: [1270/4518] 28% | Training loss: 0.6874380537374751
Epoch: 60 | Iteration number: [1280/4518] 28% | Training loss: 0.6874381552450359
Epoch: 60 | Iteration number: [1290/4518] 28% | Training loss: 0.6874326694843381
Epoch: 60 | Iteration number: [1300/4518] 28% | Training loss: 0.6874215523554729
Epoch: 60 | Iteration number: [1310/4518] 28% | Training loss: 0.6874149614163028
Epoch: 60 | Iteration number: [1320/4518] 29% | Training loss: 0.6874090933438504
Epoch: 60 | Iteration number: [1330/4518] 29% | Training loss: 0.6873966058842221
Epoch: 60 | Iteration number: [1340/4518] 29% | Training loss: 0.6874007492812712
Epoch: 60 | Iteration number: [1350/4518] 29% | Training loss: 0.6873900236023797
Epoch: 60 | Iteration number: [1360/4518] 30% | Training loss: 0.6873854813330313
Epoch: 60 | Iteration number: [1370/4518] 30% | Training loss: 0.6873849111316848
Epoch: 60 | Iteration number: [1380/4518] 30% | Training loss: 0.6873829503422199
Epoch: 60 | Iteration number: [1390/4518] 30% | Training loss: 0.6873827042768328
Epoch: 60 | Iteration number: [1400/4518] 30% | Training loss: 0.6873792649166924
Epoch: 60 | Iteration number: [1410/4518] 31% | Training loss: 0.6873775803873725
Epoch: 60 | Iteration number: [1420/4518] 31% | Training loss: 0.6873736866762941
Epoch: 60 | Iteration number: [1430/4518] 31% | Training loss: 0.6873697187100257
Epoch: 60 | Iteration number: [1440/4518] 31% | Training loss: 0.6873656193415324
Epoch: 60 | Iteration number: [1450/4518] 32% | Training loss: 0.6873645609822766
Epoch: 60 | Iteration number: [1460/4518] 32% | Training loss: 0.6873641618310589
Epoch: 60 | Iteration number: [1470/4518] 32% | Training loss: 0.6873540122898257
Epoch: 60 | Iteration number: [1480/4518] 32% | Training loss: 0.6873579147296983
Epoch: 60 | Iteration number: [1490/4518] 32% | Training loss: 0.687356785159783
Epoch: 60 | Iteration number: [1500/4518] 33% | Training loss: 0.6873418763478597
Epoch: 60 | Iteration number: [1510/4518] 33% | Training loss: 0.6873478718546052
Epoch: 60 | Iteration number: [1520/4518] 33% | Training loss: 0.6873454024132929
Epoch: 60 | Iteration number: [1530/4518] 33% | Training loss: 0.6873529102677614
Epoch: 60 | Iteration number: [1540/4518] 34% | Training loss: 0.687350150517055
Epoch: 60 | Iteration number: [1550/4518] 34% | Training loss: 0.687352650550104
Epoch: 60 | Iteration number: [1560/4518] 34% | Training loss: 0.687357203853436
Epoch: 60 | Iteration number: [1570/4518] 34% | Training loss: 0.6873531163118447
Epoch: 60 | Iteration number: [1580/4518] 34% | Training loss: 0.6873494156176531
Epoch: 60 | Iteration number: [1590/4518] 35% | Training loss: 0.6873433384130586
Epoch: 60 | Iteration number: [1600/4518] 35% | Training loss: 0.687332311719656
Epoch: 60 | Iteration number: [1610/4518] 35% | Training loss: 0.6873290663920575
Epoch: 60 | Iteration number: [1620/4518] 35% | Training loss: 0.6873166995283998
Epoch: 60 | Iteration number: [1630/4518] 36% | Training loss: 0.6873146264099635
Epoch: 60 | Iteration number: [1640/4518] 36% | Training loss: 0.6873144531031934
Epoch: 60 | Iteration number: [1650/4518] 36% | Training loss: 0.6873120343685151
Epoch: 60 | Iteration number: [1660/4518] 36% | Training loss: 0.6873100932463105
Epoch: 60 | Iteration number: [1670/4518] 36% | Training loss: 0.6873055055112895
Epoch: 60 | Iteration number: [1680/4518] 37% | Training loss: 0.6873067873929228
Epoch: 60 | Iteration number: [1690/4518] 37% | Training loss: 0.6873133118688708
Epoch: 60 | Iteration number: [1700/4518] 37% | Training loss: 0.6873188212689232
Epoch: 60 | Iteration number: [1710/4518] 37% | Training loss: 0.6873137591875087
Epoch: 60 | Iteration number: [1720/4518] 38% | Training loss: 0.6873153206220893
Epoch: 60 | Iteration number: [1730/4518] 38% | Training loss: 0.687307608747758
Epoch: 60 | Iteration number: [1740/4518] 38% | Training loss: 0.6873066017339969
Epoch: 60 | Iteration number: [1750/4518] 38% | Training loss: 0.6873112659794943
Epoch: 60 | Iteration number: [1760/4518] 38% | Training loss: 0.6873057681728493
Epoch: 60 | Iteration number: [1770/4518] 39% | Training loss: 0.6872958259730689
Epoch: 60 | Iteration number: [1780/4518] 39% | Training loss: 0.6872946873474657
Epoch: 60 | Iteration number: [1790/4518] 39% | Training loss: 0.6872926330100224
Epoch: 60 | Iteration number: [1800/4518] 39% | Training loss: 0.6872898305124707
Epoch: 60 | Iteration number: [1810/4518] 40% | Training loss: 0.6872842943800088
Epoch: 60 | Iteration number: [1820/4518] 40% | Training loss: 0.6872859842829652
Epoch: 60 | Iteration number: [1830/4518] 40% | Training loss: 0.6872837016491291
Epoch: 60 | Iteration number: [1840/4518] 40% | Training loss: 0.6872731317968472
Epoch: 60 | Iteration number: [1850/4518] 40% | Training loss: 0.6872632699399381
Epoch: 60 | Iteration number: [1860/4518] 41% | Training loss: 0.6872633690475136
Epoch: 60 | Iteration number: [1870/4518] 41% | Training loss: 0.6872585880246392
Epoch: 60 | Iteration number: [1880/4518] 41% | Training loss: 0.6872527056551995
Epoch: 60 | Iteration number: [1890/4518] 41% | Training loss: 0.6872510704729292
Epoch: 60 | Iteration number: [1900/4518] 42% | Training loss: 0.6872452862011759
Epoch: 60 | Iteration number: [1910/4518] 42% | Training loss: 0.6872397603476859
Epoch: 60 | Iteration number: [1920/4518] 42% | Training loss: 0.6872346531910201
Epoch: 60 | Iteration number: [1930/4518] 42% | Training loss: 0.6872316774308991
Epoch: 60 | Iteration number: [1940/4518] 42% | Training loss: 0.6872282403646056
Epoch: 60 | Iteration number: [1950/4518] 43% | Training loss: 0.6872284324963888
Epoch: 60 | Iteration number: [1960/4518] 43% | Training loss: 0.6872165980995918
Epoch: 60 | Iteration number: [1970/4518] 43% | Training loss: 0.6872198107278892
Epoch: 60 | Iteration number: [1980/4518] 43% | Training loss: 0.687220772769716
Epoch: 60 | Iteration number: [1990/4518] 44% | Training loss: 0.6872230513611032
Epoch: 60 | Iteration number: [2000/4518] 44% | Training loss: 0.6872241533696651
Epoch: 60 | Iteration number: [2010/4518] 44% | Training loss: 0.6872212432806765
Epoch: 60 | Iteration number: [2020/4518] 44% | Training loss: 0.6872185128750188
Epoch: 60 | Iteration number: [2030/4518] 44% | Training loss: 0.6872186227678665
Epoch: 60 | Iteration number: [2040/4518] 45% | Training loss: 0.6872209522069669
Epoch: 60 | Iteration number: [2050/4518] 45% | Training loss: 0.6872199356555939
Epoch: 60 | Iteration number: [2060/4518] 45% | Training loss: 0.6872192445021231
Epoch: 60 | Iteration number: [2070/4518] 45% | Training loss: 0.687216503781397
Epoch: 60 | Iteration number: [2080/4518] 46% | Training loss: 0.6872152915654274
Epoch: 60 | Iteration number: [2090/4518] 46% | Training loss: 0.6872155687740545
Epoch: 60 | Iteration number: [2100/4518] 46% | Training loss: 0.6872117496955963
Epoch: 60 | Iteration number: [2110/4518] 46% | Training loss: 0.6872104745058086
Epoch: 60 | Iteration number: [2120/4518] 46% | Training loss: 0.6872109667591328
Epoch: 60 | Iteration number: [2130/4518] 47% | Training loss: 0.6872098778055308
Epoch: 60 | Iteration number: [2140/4518] 47% | Training loss: 0.6872091796910651
Epoch: 60 | Iteration number: [2150/4518] 47% | Training loss: 0.6872086764213651
Epoch: 60 | Iteration number: [2160/4518] 47% | Training loss: 0.6872046215390718
Epoch: 60 | Iteration number: [2170/4518] 48% | Training loss: 0.6871949683136654
Epoch: 60 | Iteration number: [2180/4518] 48% | Training loss: 0.6871841037765556
Epoch: 60 | Iteration number: [2190/4518] 48% | Training loss: 0.6871885836940922
Epoch: 60 | Iteration number: [2200/4518] 48% | Training loss: 0.687186128876426
Epoch: 60 | Iteration number: [2210/4518] 48% | Training loss: 0.6871818356654223
Epoch: 60 | Iteration number: [2220/4518] 49% | Training loss: 0.6871780968732663
Epoch: 60 | Iteration number: [2230/4518] 49% | Training loss: 0.6871765880574026
Epoch: 60 | Iteration number: [2240/4518] 49% | Training loss: 0.6871781931391784
Epoch: 60 | Iteration number: [2250/4518] 49% | Training loss: 0.6871821495162116
Epoch: 60 | Iteration number: [2260/4518] 50% | Training loss: 0.6871828460851602
Epoch: 60 | Iteration number: [2270/4518] 50% | Training loss: 0.6871815830075269
Epoch: 60 | Iteration number: [2280/4518] 50% | Training loss: 0.6871811356460839
Epoch: 60 | Iteration number: [2290/4518] 50% | Training loss: 0.6871852783917339
Epoch: 60 | Iteration number: [2300/4518] 50% | Training loss: 0.6871859438263852
Epoch: 60 | Iteration number: [2310/4518] 51% | Training loss: 0.6871879256132877
Epoch: 60 | Iteration number: [2320/4518] 51% | Training loss: 0.6871890662816064
Epoch: 60 | Iteration number: [2330/4518] 51% | Training loss: 0.6871813773597258
Epoch: 60 | Iteration number: [2340/4518] 51% | Training loss: 0.6871782133721898
Epoch: 60 | Iteration number: [2350/4518] 52% | Training loss: 0.6871691722565509
Epoch: 60 | Iteration number: [2360/4518] 52% | Training loss: 0.687171827559754
Epoch: 60 | Iteration number: [2370/4518] 52% | Training loss: 0.6871663119974015
Epoch: 60 | Iteration number: [2380/4518] 52% | Training loss: 0.6871598738582194
Epoch: 60 | Iteration number: [2390/4518] 52% | Training loss: 0.6871562275926438
Epoch: 60 | Iteration number: [2400/4518] 53% | Training loss: 0.6871565572669108
Epoch: 60 | Iteration number: [2410/4518] 53% | Training loss: 0.6871568662002373
Epoch: 60 | Iteration number: [2420/4518] 53% | Training loss: 0.687150017658541
Epoch: 60 | Iteration number: [2430/4518] 53% | Training loss: 0.6871482103695105
Epoch: 60 | Iteration number: [2440/4518] 54% | Training loss: 0.6871523053186839
Epoch: 60 | Iteration number: [2450/4518] 54% | Training loss: 0.6871480944691872
Epoch: 60 | Iteration number: [2460/4518] 54% | Training loss: 0.6871433074881391
Epoch: 60 | Iteration number: [2470/4518] 54% | Training loss: 0.6871485512990217
Epoch: 60 | Iteration number: [2480/4518] 54% | Training loss: 0.6871457116017419
Epoch: 60 | Iteration number: [2490/4518] 55% | Training loss: 0.6871455216264151
Epoch: 60 | Iteration number: [2500/4518] 55% | Training loss: 0.6871441766500473
Epoch: 60 | Iteration number: [2510/4518] 55% | Training loss: 0.6871423605903686
Epoch: 60 | Iteration number: [2520/4518] 55% | Training loss: 0.6871390905172106
Epoch: 60 | Iteration number: [2530/4518] 55% | Training loss: 0.6871363832780966
Epoch: 60 | Iteration number: [2540/4518] 56% | Training loss: 0.6871376434414406
Epoch: 60 | Iteration number: [2550/4518] 56% | Training loss: 0.6871354456041373
Epoch: 60 | Iteration number: [2560/4518] 56% | Training loss: 0.6871349244378507
Epoch: 60 | Iteration number: [2570/4518] 56% | Training loss: 0.6871328941115146
Epoch: 60 | Iteration number: [2580/4518] 57% | Training loss: 0.687134800608768
Epoch: 60 | Iteration number: [2590/4518] 57% | Training loss: 0.6871354626642691
Epoch: 60 | Iteration number: [2600/4518] 57% | Training loss: 0.6871338002039836
Epoch: 60 | Iteration number: [2610/4518] 57% | Training loss: 0.6871399172192789
Epoch: 60 | Iteration number: [2620/4518] 57% | Training loss: 0.68713848729625
Epoch: 60 | Iteration number: [2630/4518] 58% | Training loss: 0.6871370716693284
Epoch: 60 | Iteration number: [2640/4518] 58% | Training loss: 0.6871390151255059
Epoch: 60 | Iteration number: [2650/4518] 58% | Training loss: 0.687133766907566
Epoch: 60 | Iteration number: [2660/4518] 58% | Training loss: 0.6871305132270755
Epoch: 60 | Iteration number: [2670/4518] 59% | Training loss: 0.687128892775332
Epoch: 60 | Iteration number: [2680/4518] 59% | Training loss: 0.6871304215779945
Epoch: 60 | Iteration number: [2690/4518] 59% | Training loss: 0.6871288444251376
Epoch: 60 | Iteration number: [2700/4518] 59% | Training loss: 0.6871255450116264
Epoch: 60 | Iteration number: [2710/4518] 59% | Training loss: 0.687121749364142
Epoch: 60 | Iteration number: [2720/4518] 60% | Training loss: 0.68712122786571
Epoch: 60 | Iteration number: [2730/4518] 60% | Training loss: 0.6871180111235314
Epoch: 60 | Iteration number: [2740/4518] 60% | Training loss: 0.6871142659309136
Epoch: 60 | Iteration number: [2750/4518] 60% | Training loss: 0.6871179568767548
Epoch: 60 | Iteration number: [2760/4518] 61% | Training loss: 0.6871194779225017
Epoch: 60 | Iteration number: [2770/4518] 61% | Training loss: 0.6871208699816831
Epoch: 60 | Iteration number: [2780/4518] 61% | Training loss: 0.6871193390527217
Epoch: 60 | Iteration number: [2790/4518] 61% | Training loss: 0.6871142830259056
Epoch: 60 | Iteration number: [2800/4518] 61% | Training loss: 0.6871153425957476
Epoch: 60 | Iteration number: [2810/4518] 62% | Training loss: 0.6871142119487409
Epoch: 60 | Iteration number: [2820/4518] 62% | Training loss: 0.6871141450624939
Epoch: 60 | Iteration number: [2830/4518] 62% | Training loss: 0.6871148980337823
Epoch: 60 | Iteration number: [2840/4518] 62% | Training loss: 0.6871140105623594
Epoch: 60 | Iteration number: [2850/4518] 63% | Training loss: 0.6871162209594459
Epoch: 60 | Iteration number: [2860/4518] 63% | Training loss: 0.6871157265001243
Epoch: 60 | Iteration number: [2870/4518] 63% | Training loss: 0.6871190751678852
Epoch: 60 | Iteration number: [2880/4518] 63% | Training loss: 0.6871160335010953
Epoch: 60 | Iteration number: [2890/4518] 63% | Training loss: 0.6871185055859773
Epoch: 60 | Iteration number: [2900/4518] 64% | Training loss: 0.6871108010719562
Epoch: 60 | Iteration number: [2910/4518] 64% | Training loss: 0.6871050564079351
Epoch: 60 | Iteration number: [2920/4518] 64% | Training loss: 0.6871000305634656
Epoch: 60 | Iteration number: [2930/4518] 64% | Training loss: 0.6870978531983932
Epoch: 60 | Iteration number: [2940/4518] 65% | Training loss: 0.6870972219373093
Epoch: 60 | Iteration number: [2950/4518] 65% | Training loss: 0.687090980602523
Epoch: 60 | Iteration number: [2960/4518] 65% | Training loss: 0.6870859955412311
Epoch: 60 | Iteration number: [2970/4518] 65% | Training loss: 0.6870836088553021
Epoch: 60 | Iteration number: [2980/4518] 65% | Training loss: 0.6870794594887919
Epoch: 60 | Iteration number: [2990/4518] 66% | Training loss: 0.6870780244718826
Epoch: 60 | Iteration number: [3000/4518] 66% | Training loss: 0.687076580842336
Epoch: 60 | Iteration number: [3010/4518] 66% | Training loss: 0.6870756621970687
Epoch: 60 | Iteration number: [3020/4518] 66% | Training loss: 0.6870758227559904
Epoch: 60 | Iteration number: [3030/4518] 67% | Training loss: 0.6870761885698086
Epoch: 60 | Iteration number: [3040/4518] 67% | Training loss: 0.6870711645405544
Epoch: 60 | Iteration number: [3050/4518] 67% | Training loss: 0.6870665089615056
Epoch: 60 | Iteration number: [3060/4518] 67% | Training loss: 0.6870650694455975
Epoch: 60 | Iteration number: [3070/4518] 67% | Training loss: 0.6870661559827165
Epoch: 60 | Iteration number: [3080/4518] 68% | Training loss: 0.6870637668417646
Epoch: 60 | Iteration number: [3090/4518] 68% | Training loss: 0.6870613609509947
Epoch: 60 | Iteration number: [3100/4518] 68% | Training loss: 0.6870617150299011
Epoch: 60 | Iteration number: [3110/4518] 68% | Training loss: 0.6870601655394318
Epoch: 60 | Iteration number: [3120/4518] 69% | Training loss: 0.687063799225367
Epoch: 60 | Iteration number: [3130/4518] 69% | Training loss: 0.6870596685348608
Epoch: 60 | Iteration number: [3140/4518] 69% | Training loss: 0.6870595422519999
Epoch: 60 | Iteration number: [3150/4518] 69% | Training loss: 0.6870575748360346
Epoch: 60 | Iteration number: [3160/4518] 69% | Training loss: 0.687056850406188
Epoch: 60 | Iteration number: [3170/4518] 70% | Training loss: 0.6870544733685274
Epoch: 60 | Iteration number: [3180/4518] 70% | Training loss: 0.6870554494595378
Epoch: 60 | Iteration number: [3190/4518] 70% | Training loss: 0.6870574601017942
Epoch: 60 | Iteration number: [3200/4518] 70% | Training loss: 0.6870542493648827
Epoch: 60 | Iteration number: [3210/4518] 71% | Training loss: 0.6870520013700765
Epoch: 60 | Iteration number: [3220/4518] 71% | Training loss: 0.6870562785345575
Epoch: 60 | Iteration number: [3230/4518] 71% | Training loss: 0.6870545842514688
Epoch: 60 | Iteration number: [3240/4518] 71% | Training loss: 0.6870533677714842
Epoch: 60 | Iteration number: [3250/4518] 71% | Training loss: 0.6870489314336043
Epoch: 60 | Iteration number: [3260/4518] 72% | Training loss: 0.6870451755136069
Epoch: 60 | Iteration number: [3270/4518] 72% | Training loss: 0.6870455587128981
Epoch: 60 | Iteration number: [3280/4518] 72% | Training loss: 0.6870438729844442
Epoch: 60 | Iteration number: [3290/4518] 72% | Training loss: 0.6870377383514741
Epoch: 60 | Iteration number: [3300/4518] 73% | Training loss: 0.6870368372490911
Epoch: 60 | Iteration number: [3310/4518] 73% | Training loss: 0.6870378318510026
Epoch: 60 | Iteration number: [3320/4518] 73% | Training loss: 0.6870399721415646
Epoch: 60 | Iteration number: [3330/4518] 73% | Training loss: 0.6870353344324472
Epoch: 60 | Iteration number: [3340/4518] 73% | Training loss: 0.6870350298945775
Epoch: 60 | Iteration number: [3350/4518] 74% | Training loss: 0.6870347788618572
Epoch: 60 | Iteration number: [3360/4518] 74% | Training loss: 0.6870342265104964
Epoch: 60 | Iteration number: [3370/4518] 74% | Training loss: 0.6870329172745656
Epoch: 60 | Iteration number: [3380/4518] 74% | Training loss: 0.687031673115386
Epoch: 60 | Iteration number: [3390/4518] 75% | Training loss: 0.6870284500375258
Epoch: 60 | Iteration number: [3400/4518] 75% | Training loss: 0.6870254403002122
Epoch: 60 | Iteration number: [3410/4518] 75% | Training loss: 0.6870243004515024
Epoch: 60 | Iteration number: [3420/4518] 75% | Training loss: 0.6870200834253378
Epoch: 60 | Iteration number: [3430/4518] 75% | Training loss: 0.6870161227512638
Epoch: 60 | Iteration number: [3440/4518] 76% | Training loss: 0.6870150291469208
Epoch: 60 | Iteration number: [3450/4518] 76% | Training loss: 0.6870093971231709
Epoch: 60 | Iteration number: [3460/4518] 76% | Training loss: 0.6870047584262198
Epoch: 60 | Iteration number: [3470/4518] 76% | Training loss: 0.6870060468956786
Epoch: 60 | Iteration number: [3480/4518] 77% | Training loss: 0.6870027970822378
Epoch: 60 | Iteration number: [3490/4518] 77% | Training loss: 0.6870021622980221
Epoch: 60 | Iteration number: [3500/4518] 77% | Training loss: 0.6870011928081512
Epoch: 60 | Iteration number: [3510/4518] 77% | Training loss: 0.6870005627812823
Epoch: 60 | Iteration number: [3520/4518] 77% | Training loss: 0.6869978305121714
Epoch: 60 | Iteration number: [3530/4518] 78% | Training loss: 0.686992899419228
Epoch: 60 | Iteration number: [3540/4518] 78% | Training loss: 0.6869927525520325
Epoch: 60 | Iteration number: [3550/4518] 78% | Training loss: 0.6869921992026584
Epoch: 60 | Iteration number: [3560/4518] 78% | Training loss: 0.6869946276538828
Epoch: 60 | Iteration number: [3570/4518] 79% | Training loss: 0.6869950760312441
Epoch: 60 | Iteration number: [3580/4518] 79% | Training loss: 0.6869987159967422
Epoch: 60 | Iteration number: [3590/4518] 79% | Training loss: 0.6869970854776484
Epoch: 60 | Iteration number: [3600/4518] 79% | Training loss: 0.6869968163635995
Epoch: 60 | Iteration number: [3610/4518] 79% | Training loss: 0.686997483872971
Epoch: 60 | Iteration number: [3620/4518] 80% | Training loss: 0.6869962564324805
Epoch: 60 | Iteration number: [3630/4518] 80% | Training loss: 0.6869947240043934
Epoch: 60 | Iteration number: [3640/4518] 80% | Training loss: 0.6869916824194101
Epoch: 60 | Iteration number: [3650/4518] 80% | Training loss: 0.6869913574440839
Epoch: 60 | Iteration number: [3660/4518] 81% | Training loss: 0.6869910293589524
Epoch: 60 | Iteration number: [3670/4518] 81% | Training loss: 0.6869866644816438
Epoch: 60 | Iteration number: [3680/4518] 81% | Training loss: 0.6869851601674505
Epoch: 60 | Iteration number: [3690/4518] 81% | Training loss: 0.6869833727516133
Epoch: 60 | Iteration number: [3700/4518] 81% | Training loss: 0.6869813096684378
Epoch: 60 | Iteration number: [3710/4518] 82% | Training loss: 0.6869808122475514
Epoch: 60 | Iteration number: [3720/4518] 82% | Training loss: 0.6869810175991827
Epoch: 60 | Iteration number: [3730/4518] 82% | Training loss: 0.686978556771061
Epoch: 60 | Iteration number: [3740/4518] 82% | Training loss: 0.6869786136131235
Epoch: 60 | Iteration number: [3750/4518] 83% | Training loss: 0.6869771372159322
Epoch: 60 | Iteration number: [3760/4518] 83% | Training loss: 0.6869773258078605
Epoch: 60 | Iteration number: [3770/4518] 83% | Training loss: 0.6869764943495986
Epoch: 60 | Iteration number: [3780/4518] 83% | Training loss: 0.6869771299065737
Epoch: 60 | Iteration number: [3790/4518] 83% | Training loss: 0.6869773269328718
Epoch: 60 | Iteration number: [3800/4518] 84% | Training loss: 0.6869752292727169
Epoch: 60 | Iteration number: [3810/4518] 84% | Training loss: 0.6869765015411877
Epoch: 60 | Iteration number: [3820/4518] 84% | Training loss: 0.6869782329853916
Epoch: 60 | Iteration number: [3830/4518] 84% | Training loss: 0.686977534303466
Epoch: 60 | Iteration number: [3840/4518] 84% | Training loss: 0.6869785923200349
Epoch: 60 | Iteration number: [3850/4518] 85% | Training loss: 0.6869775603034279
Epoch: 60 | Iteration number: [3860/4518] 85% | Training loss: 0.6869764868613969
Epoch: 60 | Iteration number: [3870/4518] 85% | Training loss: 0.6869754001767753
Epoch: 60 | Iteration number: [3880/4518] 85% | Training loss: 0.6869729174012991
Epoch: 60 | Iteration number: [3890/4518] 86% | Training loss: 0.6869734658680109
Epoch: 60 | Iteration number: [3900/4518] 86% | Training loss: 0.6869735389183729
Epoch: 60 | Iteration number: [3910/4518] 86% | Training loss: 0.6869719818729879
Epoch: 60 | Iteration number: [3920/4518] 86% | Training loss: 0.6869679150532703
Epoch: 60 | Iteration number: [3930/4518] 86% | Training loss: 0.6869726735216971
Epoch: 60 | Iteration number: [3940/4518] 87% | Training loss: 0.6869707297250099
Epoch: 60 | Iteration number: [3950/4518] 87% | Training loss: 0.6869688816764686
Epoch: 60 | Iteration number: [3960/4518] 87% | Training loss: 0.6869671595819069
Epoch: 60 | Iteration number: [3970/4518] 87% | Training loss: 0.6869645760251533
Epoch: 60 | Iteration number: [3980/4518] 88% | Training loss: 0.6869611403301134
Epoch: 60 | Iteration number: [3990/4518] 88% | Training loss: 0.6869593488692042
Epoch: 60 | Iteration number: [4000/4518] 88% | Training loss: 0.686962155714631
Epoch: 60 | Iteration number: [4010/4518] 88% | Training loss: 0.686963090724184
Epoch: 60 | Iteration number: [4020/4518] 88% | Training loss: 0.6869622017465421
Epoch: 60 | Iteration number: [4030/4518] 89% | Training loss: 0.6869634571945106
Epoch: 60 | Iteration number: [4040/4518] 89% | Training loss: 0.6869644738217392
Epoch: 60 | Iteration number: [4050/4518] 89% | Training loss: 0.6869655760570809
Epoch: 60 | Iteration number: [4060/4518] 89% | Training loss: 0.6869654212385563
Epoch: 60 | Iteration number: [4070/4518] 90% | Training loss: 0.6869677576005312
Epoch: 60 | Iteration number: [4080/4518] 90% | Training loss: 0.6869686891635259
Epoch: 60 | Iteration number: [4090/4518] 90% | Training loss: 0.6869701819635545
Epoch: 60 | Iteration number: [4100/4518] 90% | Training loss: 0.6869711504912958
Epoch: 60 | Iteration number: [4110/4518] 90% | Training loss: 0.6869689120428406
Epoch: 60 | Iteration number: [4120/4518] 91% | Training loss: 0.6869675555709497
Epoch: 60 | Iteration number: [4130/4518] 91% | Training loss: 0.6869678012828273
Epoch: 60 | Iteration number: [4140/4518] 91% | Training loss: 0.68696529014387
Epoch: 60 | Iteration number: [4150/4518] 91% | Training loss: 0.6869680427930441
Epoch: 60 | Iteration number: [4160/4518] 92% | Training loss: 0.6869671545492915
Epoch: 60 | Iteration number: [4170/4518] 92% | Training loss: 0.6869648099660302
Epoch: 60 | Iteration number: [4180/4518] 92% | Training loss: 0.6869646148961126
Epoch: 60 | Iteration number: [4190/4518] 92% | Training loss: 0.6869616203063428
Epoch: 60 | Iteration number: [4200/4518] 92% | Training loss: 0.6869617540779568
Epoch: 60 | Iteration number: [4210/4518] 93% | Training loss: 0.6869609407178013
Epoch: 60 | Iteration number: [4220/4518] 93% | Training loss: 0.6869606373575626
Epoch: 60 | Iteration number: [4230/4518] 93% | Training loss: 0.6869600445948031
Epoch: 60 | Iteration number: [4240/4518] 93% | Training loss: 0.6869597535650686
Epoch: 60 | Iteration number: [4250/4518] 94% | Training loss: 0.686960691578248
Epoch: 60 | Iteration number: [4260/4518] 94% | Training loss: 0.6869608947788606
Epoch: 60 | Iteration number: [4270/4518] 94% | Training loss: 0.6869629335626786
Epoch: 60 | Iteration number: [4280/4518] 94% | Training loss: 0.6869621833768961
Epoch: 60 | Iteration number: [4290/4518] 94% | Training loss: 0.6869612192218398
Epoch: 60 | Iteration number: [4300/4518] 95% | Training loss: 0.6869581984364709
Epoch: 60 | Iteration number: [4310/4518] 95% | Training loss: 0.6869564216679044
Epoch: 60 | Iteration number: [4320/4518] 95% | Training loss: 0.6869536680617818
Epoch: 60 | Iteration number: [4330/4518] 95% | Training loss: 0.6869513465680922
Epoch: 60 | Iteration number: [4340/4518] 96% | Training loss: 0.6869513798693907
Epoch: 60 | Iteration number: [4350/4518] 96% | Training loss: 0.6869499654057383
Epoch: 60 | Iteration number: [4360/4518] 96% | Training loss: 0.6869498580284075
Epoch: 60 | Iteration number: [4370/4518] 96% | Training loss: 0.6869503201418119
Epoch: 60 | Iteration number: [4380/4518] 96% | Training loss: 0.6869490314155953
Epoch: 60 | Iteration number: [4390/4518] 97% | Training loss: 0.6869489235188261
Epoch: 60 | Iteration number: [4400/4518] 97% | Training loss: 0.686948899762197
Epoch: 60 | Iteration number: [4410/4518] 97% | Training loss: 0.6869470780804043
Epoch: 60 | Iteration number: [4420/4518] 97% | Training loss: 0.6869415962857898
Epoch: 60 | Iteration number: [4430/4518] 98% | Training loss: 0.6869406164365213
Epoch: 60 | Iteration number: [4440/4518] 98% | Training loss: 0.6869392920453269
Epoch: 60 | Iteration number: [4450/4518] 98% | Training loss: 0.686940811283133
Epoch: 60 | Iteration number: [4460/4518] 98% | Training loss: 0.6869424111773615
Epoch: 60 | Iteration number: [4470/4518] 98% | Training loss: 0.6869405446703268
Epoch: 60 | Iteration number: [4480/4518] 99% | Training loss: 0.6869411149461354
Epoch: 60 | Iteration number: [4490/4518] 99% | Training loss: 0.6869416088595953
Epoch: 60 | Iteration number: [4500/4518] 99% | Training loss: 0.6869419451024797
Epoch: 60 | Iteration number: [4510/4518] 99% | Training loss: 0.6869433082128047

 End of epoch: 60 | Train Loss: 0.6867924212037383 | Training Time: 640 

 End of epoch: 60 | Eval Loss: 0.6898984033234266 | Evaluating Time: 17 
Epoch: 61 | Iteration number: [10/4518] 0% | Training loss: 0.7552004337310791
Epoch: 61 | Iteration number: [20/4518] 0% | Training loss: 0.7215865284204483
Epoch: 61 | Iteration number: [30/4518] 0% | Training loss: 0.7097500264644623
Epoch: 61 | Iteration number: [40/4518] 0% | Training loss: 0.704102173447609
Epoch: 61 | Iteration number: [50/4518] 1% | Training loss: 0.7005730545520783
Epoch: 61 | Iteration number: [60/4518] 1% | Training loss: 0.698432073990504
Epoch: 61 | Iteration number: [70/4518] 1% | Training loss: 0.6967989649091448
Epoch: 61 | Iteration number: [80/4518] 1% | Training loss: 0.6955301947891712
Epoch: 61 | Iteration number: [90/4518] 1% | Training loss: 0.6944675379329257
Epoch: 61 | Iteration number: [100/4518] 2% | Training loss: 0.6936255323886872
Epoch: 61 | Iteration number: [110/4518] 2% | Training loss: 0.6928931268778714
Epoch: 61 | Iteration number: [120/4518] 2% | Training loss: 0.6923711637655894
Epoch: 61 | Iteration number: [130/4518] 2% | Training loss: 0.6919460892677307
Epoch: 61 | Iteration number: [140/4518] 3% | Training loss: 0.6915922616209302
Epoch: 61 | Iteration number: [150/4518] 3% | Training loss: 0.6912468274434408
Epoch: 61 | Iteration number: [160/4518] 3% | Training loss: 0.6910109564661979
Epoch: 61 | Iteration number: [170/4518] 3% | Training loss: 0.6907621362630059
Epoch: 61 | Iteration number: [180/4518] 3% | Training loss: 0.6905857082870271
Epoch: 61 | Iteration number: [190/4518] 4% | Training loss: 0.6903504246159604
Epoch: 61 | Iteration number: [200/4518] 4% | Training loss: 0.6902193626761437
Epoch: 61 | Iteration number: [210/4518] 4% | Training loss: 0.6900546190284548
Epoch: 61 | Iteration number: [220/4518] 4% | Training loss: 0.6899630408395421
Epoch: 61 | Iteration number: [230/4518] 5% | Training loss: 0.6898492077122564
Epoch: 61 | Iteration number: [240/4518] 5% | Training loss: 0.6897355906665326
Epoch: 61 | Iteration number: [250/4518] 5% | Training loss: 0.6896116559505463
Epoch: 61 | Iteration number: [260/4518] 5% | Training loss: 0.6895255609200551
Epoch: 61 | Iteration number: [270/4518] 5% | Training loss: 0.6894273153057805
Epoch: 61 | Iteration number: [280/4518] 6% | Training loss: 0.6893502290759768
Epoch: 61 | Iteration number: [290/4518] 6% | Training loss: 0.6892744606938855
Epoch: 61 | Iteration number: [300/4518] 6% | Training loss: 0.6891754843791326
Epoch: 61 | Iteration number: [310/4518] 6% | Training loss: 0.6890970243561653
Epoch: 61 | Iteration number: [320/4518] 7% | Training loss: 0.6890156673267483
Epoch: 61 | Iteration number: [330/4518] 7% | Training loss: 0.6889119545618693
Epoch: 61 | Iteration number: [340/4518] 7% | Training loss: 0.6888576004435034
Epoch: 61 | Iteration number: [350/4518] 7% | Training loss: 0.6887844833305904
Epoch: 61 | Iteration number: [360/4518] 7% | Training loss: 0.688755734430419
Epoch: 61 | Iteration number: [370/4518] 8% | Training loss: 0.6886998814505499
Epoch: 61 | Iteration number: [380/4518] 8% | Training loss: 0.6886669232657081
Epoch: 61 | Iteration number: [390/4518] 8% | Training loss: 0.6886354874341916
Epoch: 61 | Iteration number: [400/4518] 8% | Training loss: 0.6885877041518689
Epoch: 61 | Iteration number: [410/4518] 9% | Training loss: 0.6885222224200644
Epoch: 61 | Iteration number: [420/4518] 9% | Training loss: 0.6885041493745078
Epoch: 61 | Iteration number: [430/4518] 9% | Training loss: 0.6884816559248192
Epoch: 61 | Iteration number: [440/4518] 9% | Training loss: 0.688432351025668
Epoch: 61 | Iteration number: [450/4518] 9% | Training loss: 0.688383957809872
Epoch: 61 | Iteration number: [460/4518] 10% | Training loss: 0.6883354713087496
Epoch: 61 | Iteration number: [470/4518] 10% | Training loss: 0.6883036826519255
Epoch: 61 | Iteration number: [480/4518] 10% | Training loss: 0.6882751688361168
Epoch: 61 | Iteration number: [490/4518] 10% | Training loss: 0.6882135106592763
Epoch: 61 | Iteration number: [500/4518] 11% | Training loss: 0.6882063151597977
Epoch: 61 | Iteration number: [510/4518] 11% | Training loss: 0.6881538600313897
Epoch: 61 | Iteration number: [520/4518] 11% | Training loss: 0.6881211876869202
Epoch: 61 | Iteration number: [530/4518] 11% | Training loss: 0.6880716607255756
Epoch: 61 | Iteration number: [540/4518] 11% | Training loss: 0.6880625267823537
Epoch: 61 | Iteration number: [550/4518] 12% | Training loss: 0.6880481482635845
Epoch: 61 | Iteration number: [560/4518] 12% | Training loss: 0.6880156170044627
Epoch: 61 | Iteration number: [570/4518] 12% | Training loss: 0.6879919037484286
Epoch: 61 | Iteration number: [580/4518] 12% | Training loss: 0.6879605022997691
Epoch: 61 | Iteration number: [590/4518] 13% | Training loss: 0.6879417425495084
Epoch: 61 | Iteration number: [600/4518] 13% | Training loss: 0.6879195146759352
Epoch: 61 | Iteration number: [610/4518] 13% | Training loss: 0.6878802274094253
Epoch: 61 | Iteration number: [620/4518] 13% | Training loss: 0.6878565315277346
Epoch: 61 | Iteration number: [630/4518] 13% | Training loss: 0.6878439333703783
Epoch: 61 | Iteration number: [640/4518] 14% | Training loss: 0.6878482650965452
Epoch: 61 | Iteration number: [650/4518] 14% | Training loss: 0.6878243575646327
Epoch: 61 | Iteration number: [660/4518] 14% | Training loss: 0.6878155002991359
Epoch: 61 | Iteration number: [670/4518] 14% | Training loss: 0.6877944595778166
Epoch: 61 | Iteration number: [680/4518] 15% | Training loss: 0.6877781242132187
Epoch: 61 | Iteration number: [690/4518] 15% | Training loss: 0.6877663722072822
Epoch: 61 | Iteration number: [700/4518] 15% | Training loss: 0.6877658716269902
Epoch: 61 | Iteration number: [710/4518] 15% | Training loss: 0.6877448542856834
Epoch: 61 | Iteration number: [720/4518] 15% | Training loss: 0.6877291472421752
Epoch: 61 | Iteration number: [730/4518] 16% | Training loss: 0.6877225798286803
Epoch: 61 | Iteration number: [740/4518] 16% | Training loss: 0.6877078930268417
Epoch: 61 | Iteration number: [750/4518] 16% | Training loss: 0.6877085835138956
Epoch: 61 | Iteration number: [760/4518] 16% | Training loss: 0.6876763435570817
Epoch: 61 | Iteration number: [770/4518] 17% | Training loss: 0.6876756921991125
Epoch: 61 | Iteration number: [780/4518] 17% | Training loss: 0.6876702510393583
Epoch: 61 | Iteration number: [790/4518] 17% | Training loss: 0.6876613841026644
Epoch: 61 | Iteration number: [800/4518] 17% | Training loss: 0.6876457524299622
Epoch: 61 | Iteration number: [810/4518] 17% | Training loss: 0.6876429330419611
Epoch: 61 | Iteration number: [820/4518] 18% | Training loss: 0.6876291510535449
Epoch: 61 | Iteration number: [830/4518] 18% | Training loss: 0.6876188627208571
Epoch: 61 | Iteration number: [840/4518] 18% | Training loss: 0.6876131218813715
Epoch: 61 | Iteration number: [850/4518] 18% | Training loss: 0.6876085084326127
Epoch: 61 | Iteration number: [860/4518] 19% | Training loss: 0.68760499912639
Epoch: 61 | Iteration number: [870/4518] 19% | Training loss: 0.687593646022095
Epoch: 61 | Iteration number: [880/4518] 19% | Training loss: 0.6875847000290047
Epoch: 61 | Iteration number: [890/4518] 19% | Training loss: 0.6875739817538958
Epoch: 61 | Iteration number: [900/4518] 19% | Training loss: 0.687581034567621
Epoch: 61 | Iteration number: [910/4518] 20% | Training loss: 0.6875711139741835
Epoch: 61 | Iteration number: [920/4518] 20% | Training loss: 0.687574405449888
Epoch: 61 | Iteration number: [930/4518] 20% | Training loss: 0.6875758152495148
Epoch: 61 | Iteration number: [940/4518] 20% | Training loss: 0.6875628200617242
Epoch: 61 | Iteration number: [950/4518] 21% | Training loss: 0.6875449470469827
Epoch: 61 | Iteration number: [960/4518] 21% | Training loss: 0.6875470589846373
Epoch: 61 | Iteration number: [970/4518] 21% | Training loss: 0.6875311019494361
Epoch: 61 | Iteration number: [980/4518] 21% | Training loss: 0.6875278157847268
Epoch: 61 | Iteration number: [990/4518] 21% | Training loss: 0.6875237269835038
Epoch: 61 | Iteration number: [1000/4518] 22% | Training loss: 0.6875128982067108
Epoch: 61 | Iteration number: [1010/4518] 22% | Training loss: 0.6875132125793117
Epoch: 61 | Iteration number: [1020/4518] 22% | Training loss: 0.6875130243161145
Epoch: 61 | Iteration number: [1030/4518] 22% | Training loss: 0.6874933419875728
Epoch: 61 | Iteration number: [1040/4518] 23% | Training loss: 0.6874943647247095
Epoch: 61 | Iteration number: [1050/4518] 23% | Training loss: 0.6875053045863196
Epoch: 61 | Iteration number: [1060/4518] 23% | Training loss: 0.687497564587953
Epoch: 61 | Iteration number: [1070/4518] 23% | Training loss: 0.6874737374693434
Epoch: 61 | Iteration number: [1080/4518] 23% | Training loss: 0.6874682284615657
Epoch: 61 | Iteration number: [1090/4518] 24% | Training loss: 0.6874581017625441
Epoch: 61 | Iteration number: [1100/4518] 24% | Training loss: 0.6874561183560979
Epoch: 61 | Iteration number: [1110/4518] 24% | Training loss: 0.687459831946605
Epoch: 61 | Iteration number: [1120/4518] 24% | Training loss: 0.6874511237123183
Epoch: 61 | Iteration number: [1130/4518] 25% | Training loss: 0.6874549745458417
Epoch: 61 | Iteration number: [1140/4518] 25% | Training loss: 0.6874383207998778
Epoch: 61 | Iteration number: [1150/4518] 25% | Training loss: 0.6874395739513894
Epoch: 61 | Iteration number: [1160/4518] 25% | Training loss: 0.6874439376181569
Epoch: 61 | Iteration number: [1170/4518] 25% | Training loss: 0.6874388618346973
Epoch: 61 | Iteration number: [1180/4518] 26% | Training loss: 0.6874367295180337
Epoch: 61 | Iteration number: [1190/4518] 26% | Training loss: 0.6874282809866576
Epoch: 61 | Iteration number: [1200/4518] 26% | Training loss: 0.6874234888950984
Epoch: 61 | Iteration number: [1210/4518] 26% | Training loss: 0.6874005484679514
Epoch: 61 | Iteration number: [1220/4518] 27% | Training loss: 0.6873916563440542
Epoch: 61 | Iteration number: [1230/4518] 27% | Training loss: 0.6873858217785999
Epoch: 61 | Iteration number: [1240/4518] 27% | Training loss: 0.6873734249222663
Epoch: 61 | Iteration number: [1250/4518] 27% | Training loss: 0.6873620983123779
Epoch: 61 | Iteration number: [1260/4518] 27% | Training loss: 0.6873478009587243
Epoch: 61 | Iteration number: [1270/4518] 28% | Training loss: 0.6873400850558844
Epoch: 61 | Iteration number: [1280/4518] 28% | Training loss: 0.6873327808920294
Epoch: 61 | Iteration number: [1290/4518] 28% | Training loss: 0.6873250253440798
Epoch: 61 | Iteration number: [1300/4518] 28% | Training loss: 0.687316185098428
Epoch: 61 | Iteration number: [1310/4518] 28% | Training loss: 0.6873037727279517
Epoch: 61 | Iteration number: [1320/4518] 29% | Training loss: 0.6873012307015333
Epoch: 61 | Iteration number: [1330/4518] 29% | Training loss: 0.6872922963217685
Epoch: 61 | Iteration number: [1340/4518] 29% | Training loss: 0.6872897354969337
Epoch: 61 | Iteration number: [1350/4518] 29% | Training loss: 0.6872992306285435
Epoch: 61 | Iteration number: [1360/4518] 30% | Training loss: 0.6872918207417517
Epoch: 61 | Iteration number: [1370/4518] 30% | Training loss: 0.6872927006578794
Epoch: 61 | Iteration number: [1380/4518] 30% | Training loss: 0.6872860358677049
Epoch: 61 | Iteration number: [1390/4518] 30% | Training loss: 0.6872897152849239
Epoch: 61 | Iteration number: [1400/4518] 30% | Training loss: 0.6872862659607615
Epoch: 61 | Iteration number: [1410/4518] 31% | Training loss: 0.6872807311673537
Epoch: 61 | Iteration number: [1420/4518] 31% | Training loss: 0.6872824343157486
Epoch: 61 | Iteration number: [1430/4518] 31% | Training loss: 0.6872889801755652
Epoch: 61 | Iteration number: [1440/4518] 31% | Training loss: 0.6872915743125809
Epoch: 61 | Iteration number: [1450/4518] 32% | Training loss: 0.6872885522349127
Epoch: 61 | Iteration number: [1460/4518] 32% | Training loss: 0.6872847170862433
Epoch: 61 | Iteration number: [1470/4518] 32% | Training loss: 0.6872822639082565
Epoch: 61 | Iteration number: [1480/4518] 32% | Training loss: 0.6872755688589972
Epoch: 61 | Iteration number: [1490/4518] 32% | Training loss: 0.6872717039697123
Epoch: 61 | Iteration number: [1500/4518] 33% | Training loss: 0.6872688374519348
Epoch: 61 | Iteration number: [1510/4518] 33% | Training loss: 0.6872757250504777
Epoch: 61 | Iteration number: [1520/4518] 33% | Training loss: 0.6872708145332964
Epoch: 61 | Iteration number: [1530/4518] 33% | Training loss: 0.6872645794955734
Epoch: 61 | Iteration number: [1540/4518] 34% | Training loss: 0.6872622221708298
Epoch: 61 | Iteration number: [1550/4518] 34% | Training loss: 0.6872622354184428
Epoch: 61 | Iteration number: [1560/4518] 34% | Training loss: 0.6872624117594499
Epoch: 61 | Iteration number: [1570/4518] 34% | Training loss: 0.6872593998149702
Epoch: 61 | Iteration number: [1580/4518] 34% | Training loss: 0.6872497197570681
Epoch: 61 | Iteration number: [1590/4518] 35% | Training loss: 0.6872535105021494
Epoch: 61 | Iteration number: [1600/4518] 35% | Training loss: 0.6872587410360574
Epoch: 61 | Iteration number: [1610/4518] 35% | Training loss: 0.6872567005409217
Epoch: 61 | Iteration number: [1620/4518] 35% | Training loss: 0.6872484584649404
Epoch: 61 | Iteration number: [1630/4518] 36% | Training loss: 0.6872450349886725
Epoch: 61 | Iteration number: [1640/4518] 36% | Training loss: 0.6872500509750552
Epoch: 61 | Iteration number: [1650/4518] 36% | Training loss: 0.6872420444633022
Epoch: 61 | Iteration number: [1660/4518] 36% | Training loss: 0.6872324343187263
Epoch: 61 | Iteration number: [1670/4518] 36% | Training loss: 0.6872373075185422
Epoch: 61 | Iteration number: [1680/4518] 37% | Training loss: 0.6872301378420421
Epoch: 61 | Iteration number: [1690/4518] 37% | Training loss: 0.6872402972370916
Epoch: 61 | Iteration number: [1700/4518] 37% | Training loss: 0.6872433486054925
Epoch: 61 | Iteration number: [1710/4518] 37% | Training loss: 0.6872435107565763
Epoch: 61 | Iteration number: [1720/4518] 38% | Training loss: 0.687227375528147
Epoch: 61 | Iteration number: [1730/4518] 38% | Training loss: 0.6872294341208618
Epoch: 61 | Iteration number: [1740/4518] 38% | Training loss: 0.6872235188196445
Epoch: 61 | Iteration number: [1750/4518] 38% | Training loss: 0.6872212076187134
Epoch: 61 | Iteration number: [1760/4518] 38% | Training loss: 0.687216321717609
Epoch: 61 | Iteration number: [1770/4518] 39% | Training loss: 0.6872107503777843
Epoch: 61 | Iteration number: [1780/4518] 39% | Training loss: 0.6872062934583493
Epoch: 61 | Iteration number: [1790/4518] 39% | Training loss: 0.6872004522291641
Epoch: 61 | Iteration number: [1800/4518] 39% | Training loss: 0.6871961719791094
Epoch: 61 | Iteration number: [1810/4518] 40% | Training loss: 0.6871896098331852
Epoch: 61 | Iteration number: [1820/4518] 40% | Training loss: 0.6871913772690427
Epoch: 61 | Iteration number: [1830/4518] 40% | Training loss: 0.687194715138993
Epoch: 61 | Iteration number: [1840/4518] 40% | Training loss: 0.6871912039492442
Epoch: 61 | Iteration number: [1850/4518] 40% | Training loss: 0.6871982464597032
Epoch: 61 | Iteration number: [1860/4518] 41% | Training loss: 0.6871973018171966
Epoch: 61 | Iteration number: [1870/4518] 41% | Training loss: 0.687188671393828
Epoch: 61 | Iteration number: [1880/4518] 41% | Training loss: 0.6871899320407117
Epoch: 61 | Iteration number: [1890/4518] 41% | Training loss: 0.6871976364857305
Epoch: 61 | Iteration number: [1900/4518] 42% | Training loss: 0.6872007701271459
Epoch: 61 | Iteration number: [1910/4518] 42% | Training loss: 0.6872028738416303
Epoch: 61 | Iteration number: [1920/4518] 42% | Training loss: 0.687205455545336
Epoch: 61 | Iteration number: [1930/4518] 42% | Training loss: 0.687201120260466
Epoch: 61 | Iteration number: [1940/4518] 42% | Training loss: 0.687192090639134
Epoch: 61 | Iteration number: [1950/4518] 43% | Training loss: 0.6871903587915958
Epoch: 61 | Iteration number: [1960/4518] 43% | Training loss: 0.6871875314992302
Epoch: 61 | Iteration number: [1970/4518] 43% | Training loss: 0.6871799760058447
Epoch: 61 | Iteration number: [1980/4518] 43% | Training loss: 0.6871843039688438
Epoch: 61 | Iteration number: [1990/4518] 44% | Training loss: 0.6871782379234257
Epoch: 61 | Iteration number: [2000/4518] 44% | Training loss: 0.6871746380031108
Epoch: 61 | Iteration number: [2010/4518] 44% | Training loss: 0.6871701033850808
Epoch: 61 | Iteration number: [2020/4518] 44% | Training loss: 0.6871696610556971
Epoch: 61 | Iteration number: [2030/4518] 44% | Training loss: 0.6871712982654572
Epoch: 61 | Iteration number: [2040/4518] 45% | Training loss: 0.6871684827933124
Epoch: 61 | Iteration number: [2050/4518] 45% | Training loss: 0.6871672115093325
Epoch: 61 | Iteration number: [2060/4518] 45% | Training loss: 0.6871651933899203
Epoch: 61 | Iteration number: [2070/4518] 45% | Training loss: 0.6871637672617815
Epoch: 61 | Iteration number: [2080/4518] 46% | Training loss: 0.6871605917524833
Epoch: 61 | Iteration number: [2090/4518] 46% | Training loss: 0.687159530027061
Epoch: 61 | Iteration number: [2100/4518] 46% | Training loss: 0.6871560649928592
Epoch: 61 | Iteration number: [2110/4518] 46% | Training loss: 0.6871551448982474
Epoch: 61 | Iteration number: [2120/4518] 46% | Training loss: 0.6871595501899719
Epoch: 61 | Iteration number: [2130/4518] 47% | Training loss: 0.6871549520134366
Epoch: 61 | Iteration number: [2140/4518] 47% | Training loss: 0.6871533832817435
Epoch: 61 | Iteration number: [2150/4518] 47% | Training loss: 0.6871579650113749
Epoch: 61 | Iteration number: [2160/4518] 47% | Training loss: 0.6871587729288472
Epoch: 61 | Iteration number: [2170/4518] 48% | Training loss: 0.6871632238961585
Epoch: 61 | Iteration number: [2180/4518] 48% | Training loss: 0.687156821418246
Epoch: 61 | Iteration number: [2190/4518] 48% | Training loss: 0.6871630287333711
Epoch: 61 | Iteration number: [2200/4518] 48% | Training loss: 0.6871631333231926
Epoch: 61 | Iteration number: [2210/4518] 48% | Training loss: 0.6871625162897067
Epoch: 61 | Iteration number: [2220/4518] 49% | Training loss: 0.6871640875532821
Epoch: 61 | Iteration number: [2230/4518] 49% | Training loss: 0.6871670095108016
Epoch: 61 | Iteration number: [2240/4518] 49% | Training loss: 0.6871617987485868
Epoch: 61 | Iteration number: [2250/4518] 49% | Training loss: 0.6871588110393948
Epoch: 61 | Iteration number: [2260/4518] 50% | Training loss: 0.6871581708435464
Epoch: 61 | Iteration number: [2270/4518] 50% | Training loss: 0.6871600636039011
Epoch: 61 | Iteration number: [2280/4518] 50% | Training loss: 0.6871631454480321
Epoch: 61 | Iteration number: [2290/4518] 50% | Training loss: 0.6871652978216196
Epoch: 61 | Iteration number: [2300/4518] 50% | Training loss: 0.6871640204346698
Epoch: 61 | Iteration number: [2310/4518] 51% | Training loss: 0.6871610342424154
Epoch: 61 | Iteration number: [2320/4518] 51% | Training loss: 0.6871553531751551
Epoch: 61 | Iteration number: [2330/4518] 51% | Training loss: 0.6871514434466546
Epoch: 61 | Iteration number: [2340/4518] 51% | Training loss: 0.6871536832334649
Epoch: 61 | Iteration number: [2350/4518] 52% | Training loss: 0.6871533073009328
Epoch: 61 | Iteration number: [2360/4518] 52% | Training loss: 0.6871530496973103
Epoch: 61 | Iteration number: [2370/4518] 52% | Training loss: 0.6871535137987338
Epoch: 61 | Iteration number: [2380/4518] 52% | Training loss: 0.6871440585170473
Epoch: 61 | Iteration number: [2390/4518] 52% | Training loss: 0.6871391022055717
Epoch: 61 | Iteration number: [2400/4518] 53% | Training loss: 0.6871361914028724
Epoch: 61 | Iteration number: [2410/4518] 53% | Training loss: 0.6871348074362981
Epoch: 61 | Iteration number: [2420/4518] 53% | Training loss: 0.6871378680891241
Epoch: 61 | Iteration number: [2430/4518] 53% | Training loss: 0.6871391586560771
Epoch: 61 | Iteration number: [2440/4518] 54% | Training loss: 0.6871363836722296
Epoch: 61 | Iteration number: [2450/4518] 54% | Training loss: 0.6871330634185246
Epoch: 61 | Iteration number: [2460/4518] 54% | Training loss: 0.6871337400219305
Epoch: 61 | Iteration number: [2470/4518] 54% | Training loss: 0.6871367068667161
Epoch: 61 | Iteration number: [2480/4518] 54% | Training loss: 0.6871394363622512
Epoch: 61 | Iteration number: [2490/4518] 55% | Training loss: 0.687133493241536
Epoch: 61 | Iteration number: [2500/4518] 55% | Training loss: 0.6871385364294053
Epoch: 61 | Iteration number: [2510/4518] 55% | Training loss: 0.6871362967320173
Epoch: 61 | Iteration number: [2520/4518] 55% | Training loss: 0.6871327441126581
Epoch: 61 | Iteration number: [2530/4518] 55% | Training loss: 0.6871297058851823
Epoch: 61 | Iteration number: [2540/4518] 56% | Training loss: 0.6871278400026907
Epoch: 61 | Iteration number: [2550/4518] 56% | Training loss: 0.6871295548887814
Epoch: 61 | Iteration number: [2560/4518] 56% | Training loss: 0.6871298985090106
Epoch: 61 | Iteration number: [2570/4518] 56% | Training loss: 0.6871308057920478
Epoch: 61 | Iteration number: [2580/4518] 57% | Training loss: 0.6871302628470946
Epoch: 61 | Iteration number: [2590/4518] 57% | Training loss: 0.6871337800412565
Epoch: 61 | Iteration number: [2600/4518] 57% | Training loss: 0.6871322489243288
Epoch: 61 | Iteration number: [2610/4518] 57% | Training loss: 0.6871315009520885
Epoch: 61 | Iteration number: [2620/4518] 57% | Training loss: 0.6871307681307538
Epoch: 61 | Iteration number: [2630/4518] 58% | Training loss: 0.6871339271503709
Epoch: 61 | Iteration number: [2640/4518] 58% | Training loss: 0.6871364675236471
Epoch: 61 | Iteration number: [2650/4518] 58% | Training loss: 0.6871328588926567
Epoch: 61 | Iteration number: [2660/4518] 58% | Training loss: 0.6871351265817657
Epoch: 61 | Iteration number: [2670/4518] 59% | Training loss: 0.687138125356217
Epoch: 61 | Iteration number: [2680/4518] 59% | Training loss: 0.6871394500581186
Epoch: 61 | Iteration number: [2690/4518] 59% | Training loss: 0.6871305958045902
Epoch: 61 | Iteration number: [2700/4518] 59% | Training loss: 0.6871284740942496
Epoch: 61 | Iteration number: [2710/4518] 59% | Training loss: 0.6871253599100008
Epoch: 61 | Iteration number: [2720/4518] 60% | Training loss: 0.6871204440865446
Epoch: 61 | Iteration number: [2730/4518] 60% | Training loss: 0.6871218137907021
Epoch: 61 | Iteration number: [2740/4518] 60% | Training loss: 0.6871179892416418
Epoch: 61 | Iteration number: [2750/4518] 60% | Training loss: 0.6871196148612283
Epoch: 61 | Iteration number: [2760/4518] 61% | Training loss: 0.687113924410896
Epoch: 61 | Iteration number: [2770/4518] 61% | Training loss: 0.6871103612739687
Epoch: 61 | Iteration number: [2780/4518] 61% | Training loss: 0.6871110343247009
Epoch: 61 | Iteration number: [2790/4518] 61% | Training loss: 0.6871108062592032
Epoch: 61 | Iteration number: [2800/4518] 61% | Training loss: 0.6871093414510999
Epoch: 61 | Iteration number: [2810/4518] 62% | Training loss: 0.6871108227353079
Epoch: 61 | Iteration number: [2820/4518] 62% | Training loss: 0.687103370212494
Epoch: 61 | Iteration number: [2830/4518] 62% | Training loss: 0.6871019558856007
Epoch: 61 | Iteration number: [2840/4518] 62% | Training loss: 0.6871030350596132
Epoch: 61 | Iteration number: [2850/4518] 63% | Training loss: 0.6871025547855779
Epoch: 61 | Iteration number: [2860/4518] 63% | Training loss: 0.6871023879809813
Epoch: 61 | Iteration number: [2870/4518] 63% | Training loss: 0.6871013483519338
Epoch: 61 | Iteration number: [2880/4518] 63% | Training loss: 0.6870990418311622
Epoch: 61 | Iteration number: [2890/4518] 63% | Training loss: 0.6870976743194883
Epoch: 61 | Iteration number: [2900/4518] 64% | Training loss: 0.6870971665916772
Epoch: 61 | Iteration number: [2910/4518] 64% | Training loss: 0.6871028339330273
Epoch: 61 | Iteration number: [2920/4518] 64% | Training loss: 0.6870999049650479
Epoch: 61 | Iteration number: [2930/4518] 64% | Training loss: 0.6870966614716696
Epoch: 61 | Iteration number: [2940/4518] 65% | Training loss: 0.6870998538067552
Epoch: 61 | Iteration number: [2950/4518] 65% | Training loss: 0.6870998961036489
Epoch: 61 | Iteration number: [2960/4518] 65% | Training loss: 0.6870961405538224
Epoch: 61 | Iteration number: [2970/4518] 65% | Training loss: 0.6870979106988169
Epoch: 61 | Iteration number: [2980/4518] 65% | Training loss: 0.6871019932447664
Epoch: 61 | Iteration number: [2990/4518] 66% | Training loss: 0.6870983649655727
Epoch: 61 | Iteration number: [3000/4518] 66% | Training loss: 0.6870941792329153
Epoch: 61 | Iteration number: [3010/4518] 66% | Training loss: 0.6870938881687152
Epoch: 61 | Iteration number: [3020/4518] 66% | Training loss: 0.6870930563337756
Epoch: 61 | Iteration number: [3030/4518] 67% | Training loss: 0.6870911623975231
Epoch: 61 | Iteration number: [3040/4518] 67% | Training loss: 0.6870872806561621
Epoch: 61 | Iteration number: [3050/4518] 67% | Training loss: 0.6870865860923392
Epoch: 61 | Iteration number: [3060/4518] 67% | Training loss: 0.6870796080313477
Epoch: 61 | Iteration number: [3070/4518] 67% | Training loss: 0.6870795095199871
Epoch: 61 | Iteration number: [3080/4518] 68% | Training loss: 0.6870794098292078
Epoch: 61 | Iteration number: [3090/4518] 68% | Training loss: 0.6870769488001333
Epoch: 61 | Iteration number: [3100/4518] 68% | Training loss: 0.6870743770560911
Epoch: 61 | Iteration number: [3110/4518] 68% | Training loss: 0.6870723862931659
Epoch: 61 | Iteration number: [3120/4518] 69% | Training loss: 0.6870736873493745
Epoch: 61 | Iteration number: [3130/4518] 69% | Training loss: 0.6870734632967379
Epoch: 61 | Iteration number: [3140/4518] 69% | Training loss: 0.6870764425036254
Epoch: 61 | Iteration number: [3150/4518] 69% | Training loss: 0.6870762887455168
Epoch: 61 | Iteration number: [3160/4518] 69% | Training loss: 0.6870763782270347
Epoch: 61 | Iteration number: [3170/4518] 70% | Training loss: 0.6870735072375096
Epoch: 61 | Iteration number: [3180/4518] 70% | Training loss: 0.6870740125014347
Epoch: 61 | Iteration number: [3190/4518] 70% | Training loss: 0.6870745476323609
Epoch: 61 | Iteration number: [3200/4518] 70% | Training loss: 0.6870737539418041
Epoch: 61 | Iteration number: [3210/4518] 71% | Training loss: 0.6870731814442393
Epoch: 61 | Iteration number: [3220/4518] 71% | Training loss: 0.6870697995890742
Epoch: 61 | Iteration number: [3230/4518] 71% | Training loss: 0.6870674909821974
Epoch: 61 | Iteration number: [3240/4518] 71% | Training loss: 0.6870658633701595
Epoch: 61 | Iteration number: [3250/4518] 71% | Training loss: 0.6870651861704313
Epoch: 61 | Iteration number: [3260/4518] 72% | Training loss: 0.6870640297060364
Epoch: 61 | Iteration number: [3270/4518] 72% | Training loss: 0.6870630397709138
Epoch: 61 | Iteration number: [3280/4518] 72% | Training loss: 0.6870541257465758
Epoch: 61 | Iteration number: [3290/4518] 72% | Training loss: 0.687048193151103
Epoch: 61 | Iteration number: [3300/4518] 73% | Training loss: 0.687047344121066
Epoch: 61 | Iteration number: [3310/4518] 73% | Training loss: 0.6870466907579013
Epoch: 61 | Iteration number: [3320/4518] 73% | Training loss: 0.687044685360897
Epoch: 61 | Iteration number: [3330/4518] 73% | Training loss: 0.6870409722621734
Epoch: 61 | Iteration number: [3340/4518] 73% | Training loss: 0.6870380468532711
Epoch: 61 | Iteration number: [3350/4518] 74% | Training loss: 0.6870393857671254
Epoch: 61 | Iteration number: [3360/4518] 74% | Training loss: 0.6870382803891386
Epoch: 61 | Iteration number: [3370/4518] 74% | Training loss: 0.6870344734510258
Epoch: 61 | Iteration number: [3380/4518] 74% | Training loss: 0.6870315536063099
Epoch: 61 | Iteration number: [3390/4518] 75% | Training loss: 0.687031725163305
Epoch: 61 | Iteration number: [3400/4518] 75% | Training loss: 0.6870317608994596
Epoch: 61 | Iteration number: [3410/4518] 75% | Training loss: 0.687032768278877
Epoch: 61 | Iteration number: [3420/4518] 75% | Training loss: 0.687031271269447
Epoch: 61 | Iteration number: [3430/4518] 75% | Training loss: 0.6870331437525179
Epoch: 61 | Iteration number: [3440/4518] 76% | Training loss: 0.6870328632898108
Epoch: 61 | Iteration number: [3450/4518] 76% | Training loss: 0.6870297122692717
Epoch: 61 | Iteration number: [3460/4518] 76% | Training loss: 0.6870240281599794
Epoch: 61 | Iteration number: [3470/4518] 76% | Training loss: 0.6870203026948813
Epoch: 61 | Iteration number: [3480/4518] 77% | Training loss: 0.6870170693459182
Epoch: 61 | Iteration number: [3490/4518] 77% | Training loss: 0.6870136245103142
Epoch: 61 | Iteration number: [3500/4518] 77% | Training loss: 0.6870115740128926
Epoch: 61 | Iteration number: [3510/4518] 77% | Training loss: 0.6870063473356416
Epoch: 61 | Iteration number: [3520/4518] 77% | Training loss: 0.687009971097789
Epoch: 61 | Iteration number: [3530/4518] 78% | Training loss: 0.6870104026017716
Epoch: 61 | Iteration number: [3540/4518] 78% | Training loss: 0.6870079504231276
Epoch: 61 | Iteration number: [3550/4518] 78% | Training loss: 0.6870081360575179
Epoch: 61 | Iteration number: [3560/4518] 78% | Training loss: 0.6870071213901713
Epoch: 61 | Iteration number: [3570/4518] 79% | Training loss: 0.6870024386407281
Epoch: 61 | Iteration number: [3580/4518] 79% | Training loss: 0.6870038865331831
Epoch: 61 | Iteration number: [3590/4518] 79% | Training loss: 0.6870018910564752
Epoch: 61 | Iteration number: [3600/4518] 79% | Training loss: 0.6869995883438322
Epoch: 61 | Iteration number: [3610/4518] 79% | Training loss: 0.6869962599799243
Epoch: 61 | Iteration number: [3620/4518] 80% | Training loss: 0.6869925583759066
Epoch: 61 | Iteration number: [3630/4518] 80% | Training loss: 0.686993176516751
Epoch: 61 | Iteration number: [3640/4518] 80% | Training loss: 0.6869934220562924
Epoch: 61 | Iteration number: [3650/4518] 80% | Training loss: 0.686991153726839
Epoch: 61 | Iteration number: [3660/4518] 81% | Training loss: 0.6869920022663523
Epoch: 61 | Iteration number: [3670/4518] 81% | Training loss: 0.6869940294394377
Epoch: 61 | Iteration number: [3680/4518] 81% | Training loss: 0.6869920813195084
Epoch: 61 | Iteration number: [3690/4518] 81% | Training loss: 0.6869885939085063
Epoch: 61 | Iteration number: [3700/4518] 81% | Training loss: 0.6869893326791557
Epoch: 61 | Iteration number: [3710/4518] 82% | Training loss: 0.6869882914897888
Epoch: 61 | Iteration number: [3720/4518] 82% | Training loss: 0.6869880770964008
Epoch: 61 | Iteration number: [3730/4518] 82% | Training loss: 0.6869909412739423
Epoch: 61 | Iteration number: [3740/4518] 82% | Training loss: 0.6869903866619987
Epoch: 61 | Iteration number: [3750/4518] 83% | Training loss: 0.6869901997407277
Epoch: 61 | Iteration number: [3760/4518] 83% | Training loss: 0.6869881422754298
Epoch: 61 | Iteration number: [3770/4518] 83% | Training loss: 0.6869867452101619
Epoch: 61 | Iteration number: [3780/4518] 83% | Training loss: 0.6869867241887189
Epoch: 61 | Iteration number: [3790/4518] 83% | Training loss: 0.6869820333250595
Epoch: 61 | Iteration number: [3800/4518] 84% | Training loss: 0.6869846082988538
Epoch: 61 | Iteration number: [3810/4518] 84% | Training loss: 0.6869860667569118
Epoch: 61 | Iteration number: [3820/4518] 84% | Training loss: 0.6869825234275838
Epoch: 61 | Iteration number: [3830/4518] 84% | Training loss: 0.6869810378738234
Epoch: 61 | Iteration number: [3840/4518] 84% | Training loss: 0.6869807763646046
Epoch: 61 | Iteration number: [3850/4518] 85% | Training loss: 0.68697907681589
Epoch: 61 | Iteration number: [3860/4518] 85% | Training loss: 0.6869816810664735
Epoch: 61 | Iteration number: [3870/4518] 85% | Training loss: 0.6869798832623534
Epoch: 61 | Iteration number: [3880/4518] 85% | Training loss: 0.6869783133575597
Epoch: 61 | Iteration number: [3890/4518] 86% | Training loss: 0.6869773115780788
Epoch: 61 | Iteration number: [3900/4518] 86% | Training loss: 0.6869763637047548
Epoch: 61 | Iteration number: [3910/4518] 86% | Training loss: 0.686976590790712
Epoch: 61 | Iteration number: [3920/4518] 86% | Training loss: 0.6869783133420408
Epoch: 61 | Iteration number: [3930/4518] 86% | Training loss: 0.6869790232363548
Epoch: 61 | Iteration number: [3940/4518] 87% | Training loss: 0.6869752714476609
Epoch: 61 | Iteration number: [3950/4518] 87% | Training loss: 0.6869749330116224
Epoch: 61 | Iteration number: [3960/4518] 87% | Training loss: 0.6869714405952078
Epoch: 61 | Iteration number: [3970/4518] 87% | Training loss: 0.68697153994959
Epoch: 61 | Iteration number: [3980/4518] 88% | Training loss: 0.6869729885953155
Epoch: 61 | Iteration number: [3990/4518] 88% | Training loss: 0.6869730970166381
Epoch: 61 | Iteration number: [4000/4518] 88% | Training loss: 0.6869704574644565
Epoch: 61 | Iteration number: [4010/4518] 88% | Training loss: 0.6869688691343749
Epoch: 61 | Iteration number: [4020/4518] 88% | Training loss: 0.6869704989355002
Epoch: 61 | Iteration number: [4030/4518] 89% | Training loss: 0.6869694919651259
Epoch: 61 | Iteration number: [4040/4518] 89% | Training loss: 0.6869709596480473
Epoch: 61 | Iteration number: [4050/4518] 89% | Training loss: 0.6869703318601773
Epoch: 61 | Iteration number: [4060/4518] 89% | Training loss: 0.68696746099465
Epoch: 61 | Iteration number: [4070/4518] 90% | Training loss: 0.6869664960616344
Epoch: 61 | Iteration number: [4080/4518] 90% | Training loss: 0.6869697289723976
Epoch: 61 | Iteration number: [4090/4518] 90% | Training loss: 0.6869676440589877
Epoch: 61 | Iteration number: [4100/4518] 90% | Training loss: 0.6869696893924621
Epoch: 61 | Iteration number: [4110/4518] 90% | Training loss: 0.6869711502625124
Epoch: 61 | Iteration number: [4120/4518] 91% | Training loss: 0.6869710580382532
Epoch: 61 | Iteration number: [4130/4518] 91% | Training loss: 0.6869664674088106
Epoch: 61 | Iteration number: [4140/4518] 91% | Training loss: 0.6869664099337398
Epoch: 61 | Iteration number: [4150/4518] 91% | Training loss: 0.6869665708168443
Epoch: 61 | Iteration number: [4160/4518] 92% | Training loss: 0.6869648195803165
Epoch: 61 | Iteration number: [4170/4518] 92% | Training loss: 0.6869627225027382
Epoch: 61 | Iteration number: [4180/4518] 92% | Training loss: 0.6869621830979032
Epoch: 61 | Iteration number: [4190/4518] 92% | Training loss: 0.6869631768410985
Epoch: 61 | Iteration number: [4200/4518] 92% | Training loss: 0.6869598955767495
Epoch: 61 | Iteration number: [4210/4518] 93% | Training loss: 0.6869550666729798
Epoch: 61 | Iteration number: [4220/4518] 93% | Training loss: 0.6869539759170388
Epoch: 61 | Iteration number: [4230/4518] 93% | Training loss: 0.6869565343884994
Epoch: 61 | Iteration number: [4240/4518] 93% | Training loss: 0.6869569630274233
Epoch: 61 | Iteration number: [4250/4518] 94% | Training loss: 0.6869552692245035
Epoch: 61 | Iteration number: [4260/4518] 94% | Training loss: 0.686955196294986
Epoch: 61 | Iteration number: [4270/4518] 94% | Training loss: 0.6869547124350099
Epoch: 61 | Iteration number: [4280/4518] 94% | Training loss: 0.686953085772345
Epoch: 61 | Iteration number: [4290/4518] 94% | Training loss: 0.6869491994658828
Epoch: 61 | Iteration number: [4300/4518] 95% | Training loss: 0.6869486662537553
Epoch: 61 | Iteration number: [4310/4518] 95% | Training loss: 0.6869494456702762
Epoch: 61 | Iteration number: [4320/4518] 95% | Training loss: 0.686945961429565
Epoch: 61 | Iteration number: [4330/4518] 95% | Training loss: 0.686945782261137
Epoch: 61 | Iteration number: [4340/4518] 96% | Training loss: 0.6869441365316716
Epoch: 61 | Iteration number: [4350/4518] 96% | Training loss: 0.6869398299715985
Epoch: 61 | Iteration number: [4360/4518] 96% | Training loss: 0.6869410675600034
Epoch: 61 | Iteration number: [4370/4518] 96% | Training loss: 0.6869414319844759
Epoch: 61 | Iteration number: [4380/4518] 96% | Training loss: 0.6869442859060688
Epoch: 61 | Iteration number: [4390/4518] 97% | Training loss: 0.6869476598460473
Epoch: 61 | Iteration number: [4400/4518] 97% | Training loss: 0.6869463069330562
Epoch: 61 | Iteration number: [4410/4518] 97% | Training loss: 0.6869419914930045
Epoch: 61 | Iteration number: [4420/4518] 97% | Training loss: 0.6869424132874649
Epoch: 61 | Iteration number: [4430/4518] 98% | Training loss: 0.6869451177174027
Epoch: 61 | Iteration number: [4440/4518] 98% | Training loss: 0.6869465550860843
Epoch: 61 | Iteration number: [4450/4518] 98% | Training loss: 0.6869461570428999
Epoch: 61 | Iteration number: [4460/4518] 98% | Training loss: 0.6869447235836577
Epoch: 61 | Iteration number: [4470/4518] 98% | Training loss: 0.686942721559964
Epoch: 61 | Iteration number: [4480/4518] 99% | Training loss: 0.6869426259904036
Epoch: 61 | Iteration number: [4490/4518] 99% | Training loss: 0.6869419009356297
Epoch: 61 | Iteration number: [4500/4518] 99% | Training loss: 0.6869405886862013
Epoch: 61 | Iteration number: [4510/4518] 99% | Training loss: 0.6869389439237091

 End of epoch: 61 | Train Loss: 0.686788147532238 | Training Time: 641 

 End of epoch: 61 | Eval Loss: 0.6898999907532517 | Evaluating Time: 17 
Epoch: 62 | Iteration number: [10/4518] 0% | Training loss: 0.7560530483722687
Epoch: 62 | Iteration number: [20/4518] 0% | Training loss: 0.7216558039188385
Epoch: 62 | Iteration number: [30/4518] 0% | Training loss: 0.7102042655150096
Epoch: 62 | Iteration number: [40/4518] 0% | Training loss: 0.7040849760174751
Epoch: 62 | Iteration number: [50/4518] 1% | Training loss: 0.7006697750091553
Epoch: 62 | Iteration number: [60/4518] 1% | Training loss: 0.698538734515508
Epoch: 62 | Iteration number: [70/4518] 1% | Training loss: 0.6967726196561541
Epoch: 62 | Iteration number: [80/4518] 1% | Training loss: 0.695582078397274
Epoch: 62 | Iteration number: [90/4518] 1% | Training loss: 0.6945291797320048
Epoch: 62 | Iteration number: [100/4518] 2% | Training loss: 0.6937184125185013
Epoch: 62 | Iteration number: [110/4518] 2% | Training loss: 0.6931432713161815
Epoch: 62 | Iteration number: [120/4518] 2% | Training loss: 0.692540721098582
Epoch: 62 | Iteration number: [130/4518] 2% | Training loss: 0.6921816596618066
Epoch: 62 | Iteration number: [140/4518] 3% | Training loss: 0.691789213674409
Epoch: 62 | Iteration number: [150/4518] 3% | Training loss: 0.6914213383197785
Epoch: 62 | Iteration number: [160/4518] 3% | Training loss: 0.6911376811563968
Epoch: 62 | Iteration number: [170/4518] 3% | Training loss: 0.6908377871793859
Epoch: 62 | Iteration number: [180/4518] 3% | Training loss: 0.6906295872396893
Epoch: 62 | Iteration number: [190/4518] 4% | Training loss: 0.6904064479627108
Epoch: 62 | Iteration number: [200/4518] 4% | Training loss: 0.6902032139897346
Epoch: 62 | Iteration number: [210/4518] 4% | Training loss: 0.6899959093048459
Epoch: 62 | Iteration number: [220/4518] 4% | Training loss: 0.6898274703459306
Epoch: 62 | Iteration number: [230/4518] 5% | Training loss: 0.6897062519322271
Epoch: 62 | Iteration number: [240/4518] 5% | Training loss: 0.6895479895174503
Epoch: 62 | Iteration number: [250/4518] 5% | Training loss: 0.6894435727596283
Epoch: 62 | Iteration number: [260/4518] 5% | Training loss: 0.6892824454949452
Epoch: 62 | Iteration number: [270/4518] 5% | Training loss: 0.689218478291123
Epoch: 62 | Iteration number: [280/4518] 6% | Training loss: 0.6891472256609372
Epoch: 62 | Iteration number: [290/4518] 6% | Training loss: 0.6891066226465948
Epoch: 62 | Iteration number: [300/4518] 6% | Training loss: 0.6890101957321167
Epoch: 62 | Iteration number: [310/4518] 6% | Training loss: 0.6889231572228093
Epoch: 62 | Iteration number: [320/4518] 7% | Training loss: 0.6888537626713515
Epoch: 62 | Iteration number: [330/4518] 7% | Training loss: 0.6888168750387249
Epoch: 62 | Iteration number: [340/4518] 7% | Training loss: 0.6887373198481167
Epoch: 62 | Iteration number: [350/4518] 7% | Training loss: 0.6886839098589761
Epoch: 62 | Iteration number: [360/4518] 7% | Training loss: 0.6886385939187474
Epoch: 62 | Iteration number: [370/4518] 8% | Training loss: 0.6886254392765664
Epoch: 62 | Iteration number: [380/4518] 8% | Training loss: 0.6885644268048438
Epoch: 62 | Iteration number: [390/4518] 8% | Training loss: 0.6885164351035387
Epoch: 62 | Iteration number: [400/4518] 8% | Training loss: 0.6884560883045197
Epoch: 62 | Iteration number: [410/4518] 9% | Training loss: 0.6884337574970432
Epoch: 62 | Iteration number: [420/4518] 9% | Training loss: 0.6883599400520325
Epoch: 62 | Iteration number: [430/4518] 9% | Training loss: 0.6882781824400258
Epoch: 62 | Iteration number: [440/4518] 9% | Training loss: 0.6882533035495064
Epoch: 62 | Iteration number: [450/4518] 9% | Training loss: 0.6882263877656725
Epoch: 62 | Iteration number: [460/4518] 10% | Training loss: 0.6881937416999236
Epoch: 62 | Iteration number: [470/4518] 10% | Training loss: 0.688164965142595
Epoch: 62 | Iteration number: [480/4518] 10% | Training loss: 0.6881380245089531
Epoch: 62 | Iteration number: [490/4518] 10% | Training loss: 0.6880983675012783
Epoch: 62 | Iteration number: [500/4518] 11% | Training loss: 0.6880452820062637
Epoch: 62 | Iteration number: [510/4518] 11% | Training loss: 0.6880589573991065
Epoch: 62 | Iteration number: [520/4518] 11% | Training loss: 0.6880255232636745
Epoch: 62 | Iteration number: [530/4518] 11% | Training loss: 0.6880397456996846
Epoch: 62 | Iteration number: [540/4518] 11% | Training loss: 0.688042218376089
Epoch: 62 | Iteration number: [550/4518] 12% | Training loss: 0.6880129143324766
Epoch: 62 | Iteration number: [560/4518] 12% | Training loss: 0.6880091239299093
Epoch: 62 | Iteration number: [570/4518] 12% | Training loss: 0.6879649343197806
Epoch: 62 | Iteration number: [580/4518] 12% | Training loss: 0.6879575553639182
Epoch: 62 | Iteration number: [590/4518] 13% | Training loss: 0.6879536199367653
Epoch: 62 | Iteration number: [600/4518] 13% | Training loss: 0.6879446719090144
Epoch: 62 | Iteration number: [610/4518] 13% | Training loss: 0.6879535727813596
Epoch: 62 | Iteration number: [620/4518] 13% | Training loss: 0.6879375441420463
Epoch: 62 | Iteration number: [630/4518] 13% | Training loss: 0.6879285913611215
Epoch: 62 | Iteration number: [640/4518] 14% | Training loss: 0.6879193658940495
Epoch: 62 | Iteration number: [650/4518] 14% | Training loss: 0.6879108202457428
Epoch: 62 | Iteration number: [660/4518] 14% | Training loss: 0.6878809208219702
Epoch: 62 | Iteration number: [670/4518] 14% | Training loss: 0.6878635617334451
Epoch: 62 | Iteration number: [680/4518] 15% | Training loss: 0.6878725491025869
Epoch: 62 | Iteration number: [690/4518] 15% | Training loss: 0.6878598638202833
Epoch: 62 | Iteration number: [700/4518] 15% | Training loss: 0.687870682477951
Epoch: 62 | Iteration number: [710/4518] 15% | Training loss: 0.6878599884644361
Epoch: 62 | Iteration number: [720/4518] 15% | Training loss: 0.6878565593726105
Epoch: 62 | Iteration number: [730/4518] 16% | Training loss: 0.6878739025494823
Epoch: 62 | Iteration number: [740/4518] 16% | Training loss: 0.6878383040428162
Epoch: 62 | Iteration number: [750/4518] 16% | Training loss: 0.6878107322057089
Epoch: 62 | Iteration number: [760/4518] 16% | Training loss: 0.6878119591819613
Epoch: 62 | Iteration number: [770/4518] 17% | Training loss: 0.6877960974519903
Epoch: 62 | Iteration number: [780/4518] 17% | Training loss: 0.6877823231311945
Epoch: 62 | Iteration number: [790/4518] 17% | Training loss: 0.6877754501904113
Epoch: 62 | Iteration number: [800/4518] 17% | Training loss: 0.6877706193178892
Epoch: 62 | Iteration number: [810/4518] 17% | Training loss: 0.6877673761344251
Epoch: 62 | Iteration number: [820/4518] 18% | Training loss: 0.6877571899716447
Epoch: 62 | Iteration number: [830/4518] 18% | Training loss: 0.687737740378782
Epoch: 62 | Iteration number: [840/4518] 18% | Training loss: 0.6877354703488804
Epoch: 62 | Iteration number: [850/4518] 18% | Training loss: 0.6877446441089405
Epoch: 62 | Iteration number: [860/4518] 19% | Training loss: 0.6877265826907268
Epoch: 62 | Iteration number: [870/4518] 19% | Training loss: 0.6877136829255641
Epoch: 62 | Iteration number: [880/4518] 19% | Training loss: 0.6876974248073318
Epoch: 62 | Iteration number: [890/4518] 19% | Training loss: 0.6876809209920047
Epoch: 62 | Iteration number: [900/4518] 19% | Training loss: 0.687674312988917
Epoch: 62 | Iteration number: [910/4518] 20% | Training loss: 0.6876546568267948
Epoch: 62 | Iteration number: [920/4518] 20% | Training loss: 0.6876402839370396
Epoch: 62 | Iteration number: [930/4518] 20% | Training loss: 0.6876370903625283
Epoch: 62 | Iteration number: [940/4518] 20% | Training loss: 0.6876214730612775
Epoch: 62 | Iteration number: [950/4518] 21% | Training loss: 0.6876289284229279
Epoch: 62 | Iteration number: [960/4518] 21% | Training loss: 0.687617396004498
Epoch: 62 | Iteration number: [970/4518] 21% | Training loss: 0.6876051349123729
Epoch: 62 | Iteration number: [980/4518] 21% | Training loss: 0.6875988558238867
Epoch: 62 | Iteration number: [990/4518] 21% | Training loss: 0.6875856751745397
Epoch: 62 | Iteration number: [1000/4518] 22% | Training loss: 0.6875732085704803
Epoch: 62 | Iteration number: [1010/4518] 22% | Training loss: 0.6875671001354067
Epoch: 62 | Iteration number: [1020/4518] 22% | Training loss: 0.6875565870719798
Epoch: 62 | Iteration number: [1030/4518] 22% | Training loss: 0.6875444442323111
Epoch: 62 | Iteration number: [1040/4518] 23% | Training loss: 0.6875194978255492
Epoch: 62 | Iteration number: [1050/4518] 23% | Training loss: 0.687509966350737
Epoch: 62 | Iteration number: [1060/4518] 23% | Training loss: 0.6875064367955586
Epoch: 62 | Iteration number: [1070/4518] 23% | Training loss: 0.6874980540476112
Epoch: 62 | Iteration number: [1080/4518] 23% | Training loss: 0.6874940050972833
Epoch: 62 | Iteration number: [1090/4518] 24% | Training loss: 0.6874850532877336
Epoch: 62 | Iteration number: [1100/4518] 24% | Training loss: 0.6874712125821547
Epoch: 62 | Iteration number: [1110/4518] 24% | Training loss: 0.687460669901994
Epoch: 62 | Iteration number: [1120/4518] 24% | Training loss: 0.687469893693924
Epoch: 62 | Iteration number: [1130/4518] 25% | Training loss: 0.6874569573761088
Epoch: 62 | Iteration number: [1140/4518] 25% | Training loss: 0.6874593493708393
Epoch: 62 | Iteration number: [1150/4518] 25% | Training loss: 0.6874449909251669
Epoch: 62 | Iteration number: [1160/4518] 25% | Training loss: 0.6874304909644455
Epoch: 62 | Iteration number: [1170/4518] 25% | Training loss: 0.6874223216986045
Epoch: 62 | Iteration number: [1180/4518] 26% | Training loss: 0.6874110206203946
Epoch: 62 | Iteration number: [1190/4518] 26% | Training loss: 0.6873932468290088
Epoch: 62 | Iteration number: [1200/4518] 26% | Training loss: 0.6873898580173652
Epoch: 62 | Iteration number: [1210/4518] 26% | Training loss: 0.6873856167162745
Epoch: 62 | Iteration number: [1220/4518] 27% | Training loss: 0.6873830539769814
Epoch: 62 | Iteration number: [1230/4518] 27% | Training loss: 0.6873689107778596
Epoch: 62 | Iteration number: [1240/4518] 27% | Training loss: 0.6873640020528148
Epoch: 62 | Iteration number: [1250/4518] 27% | Training loss: 0.6873517139434815
Epoch: 62 | Iteration number: [1260/4518] 27% | Training loss: 0.6873460936167883
Epoch: 62 | Iteration number: [1270/4518] 28% | Training loss: 0.687343003759234
Epoch: 62 | Iteration number: [1280/4518] 28% | Training loss: 0.6873434803448617
Epoch: 62 | Iteration number: [1290/4518] 28% | Training loss: 0.6873187937939814
Epoch: 62 | Iteration number: [1300/4518] 28% | Training loss: 0.6873156190835512
Epoch: 62 | Iteration number: [1310/4518] 28% | Training loss: 0.6872961032481594
Epoch: 62 | Iteration number: [1320/4518] 29% | Training loss: 0.687296478043903
Epoch: 62 | Iteration number: [1330/4518] 29% | Training loss: 0.6873074518558674
Epoch: 62 | Iteration number: [1340/4518] 29% | Training loss: 0.6872998226489594
Epoch: 62 | Iteration number: [1350/4518] 29% | Training loss: 0.6872940481150592
Epoch: 62 | Iteration number: [1360/4518] 30% | Training loss: 0.6872913654236232
Epoch: 62 | Iteration number: [1370/4518] 30% | Training loss: 0.6872857693338046
Epoch: 62 | Iteration number: [1380/4518] 30% | Training loss: 0.6872843909954679
Epoch: 62 | Iteration number: [1390/4518] 30% | Training loss: 0.6872808993291512
Epoch: 62 | Iteration number: [1400/4518] 30% | Training loss: 0.687280119912965
Epoch: 62 | Iteration number: [1410/4518] 31% | Training loss: 0.6872803970008877
Epoch: 62 | Iteration number: [1420/4518] 31% | Training loss: 0.6872800128560671
Epoch: 62 | Iteration number: [1430/4518] 31% | Training loss: 0.6872762976409672
Epoch: 62 | Iteration number: [1440/4518] 31% | Training loss: 0.6872709300369024
Epoch: 62 | Iteration number: [1450/4518] 32% | Training loss: 0.6872667666139274
Epoch: 62 | Iteration number: [1460/4518] 32% | Training loss: 0.6872546841428705
Epoch: 62 | Iteration number: [1470/4518] 32% | Training loss: 0.6872480199856013
Epoch: 62 | Iteration number: [1480/4518] 32% | Training loss: 0.6872421575559152
Epoch: 62 | Iteration number: [1490/4518] 32% | Training loss: 0.6872350405926673
Epoch: 62 | Iteration number: [1500/4518] 33% | Training loss: 0.6872265512148539
Epoch: 62 | Iteration number: [1510/4518] 33% | Training loss: 0.6872188641140793
Epoch: 62 | Iteration number: [1520/4518] 33% | Training loss: 0.687222944945097
Epoch: 62 | Iteration number: [1530/4518] 33% | Training loss: 0.6872270382307714
Epoch: 62 | Iteration number: [1540/4518] 34% | Training loss: 0.6872205490028703
Epoch: 62 | Iteration number: [1550/4518] 34% | Training loss: 0.6872260016010654
Epoch: 62 | Iteration number: [1560/4518] 34% | Training loss: 0.6872284788351792
Epoch: 62 | Iteration number: [1570/4518] 34% | Training loss: 0.687224304220479
Epoch: 62 | Iteration number: [1580/4518] 34% | Training loss: 0.6872269757563555
Epoch: 62 | Iteration number: [1590/4518] 35% | Training loss: 0.6872211771566163
Epoch: 62 | Iteration number: [1600/4518] 35% | Training loss: 0.6872197671234608
Epoch: 62 | Iteration number: [1610/4518] 35% | Training loss: 0.6872175168176615
Epoch: 62 | Iteration number: [1620/4518] 35% | Training loss: 0.6872223837508096
Epoch: 62 | Iteration number: [1630/4518] 36% | Training loss: 0.6872233429203736
Epoch: 62 | Iteration number: [1640/4518] 36% | Training loss: 0.6872261744810314
Epoch: 62 | Iteration number: [1650/4518] 36% | Training loss: 0.6872251356370521
Epoch: 62 | Iteration number: [1660/4518] 36% | Training loss: 0.6872179998331759
Epoch: 62 | Iteration number: [1670/4518] 36% | Training loss: 0.6872199860518564
Epoch: 62 | Iteration number: [1680/4518] 37% | Training loss: 0.6872170371313889
Epoch: 62 | Iteration number: [1690/4518] 37% | Training loss: 0.6872126559181326
Epoch: 62 | Iteration number: [1700/4518] 37% | Training loss: 0.6872154764568105
Epoch: 62 | Iteration number: [1710/4518] 37% | Training loss: 0.6872142040241531
Epoch: 62 | Iteration number: [1720/4518] 38% | Training loss: 0.6872155693034793
Epoch: 62 | Iteration number: [1730/4518] 38% | Training loss: 0.6872075594574041
Epoch: 62 | Iteration number: [1740/4518] 38% | Training loss: 0.6872052415349018
Epoch: 62 | Iteration number: [1750/4518] 38% | Training loss: 0.6872033952304295
Epoch: 62 | Iteration number: [1760/4518] 38% | Training loss: 0.6872012774036689
Epoch: 62 | Iteration number: [1770/4518] 39% | Training loss: 0.6871950988042153
Epoch: 62 | Iteration number: [1780/4518] 39% | Training loss: 0.687194897485583
Epoch: 62 | Iteration number: [1790/4518] 39% | Training loss: 0.6871909239771646
Epoch: 62 | Iteration number: [1800/4518] 39% | Training loss: 0.6871836551361614
Epoch: 62 | Iteration number: [1810/4518] 40% | Training loss: 0.6871842705083815
Epoch: 62 | Iteration number: [1820/4518] 40% | Training loss: 0.6871755790251952
Epoch: 62 | Iteration number: [1830/4518] 40% | Training loss: 0.6871793557060221
Epoch: 62 | Iteration number: [1840/4518] 40% | Training loss: 0.6871775541940461
Epoch: 62 | Iteration number: [1850/4518] 40% | Training loss: 0.6871772443926012
Epoch: 62 | Iteration number: [1860/4518] 41% | Training loss: 0.6871752252181371
Epoch: 62 | Iteration number: [1870/4518] 41% | Training loss: 0.687176448170514
Epoch: 62 | Iteration number: [1880/4518] 41% | Training loss: 0.6871711133325353
Epoch: 62 | Iteration number: [1890/4518] 41% | Training loss: 0.6871675110052502
Epoch: 62 | Iteration number: [1900/4518] 42% | Training loss: 0.6871666464993829
Epoch: 62 | Iteration number: [1910/4518] 42% | Training loss: 0.6871594270486482
Epoch: 62 | Iteration number: [1920/4518] 42% | Training loss: 0.6871585912071169
Epoch: 62 | Iteration number: [1930/4518] 42% | Training loss: 0.6871620542336004
Epoch: 62 | Iteration number: [1940/4518] 42% | Training loss: 0.68716563481031
Epoch: 62 | Iteration number: [1950/4518] 43% | Training loss: 0.6871651759514442
Epoch: 62 | Iteration number: [1960/4518] 43% | Training loss: 0.6871616477868995
Epoch: 62 | Iteration number: [1970/4518] 43% | Training loss: 0.6871576611463188
Epoch: 62 | Iteration number: [1980/4518] 43% | Training loss: 0.687156349119514
Epoch: 62 | Iteration number: [1990/4518] 44% | Training loss: 0.6871559394663902
Epoch: 62 | Iteration number: [2000/4518] 44% | Training loss: 0.6871543776094914
Epoch: 62 | Iteration number: [2010/4518] 44% | Training loss: 0.6871536579001603
Epoch: 62 | Iteration number: [2020/4518] 44% | Training loss: 0.6871596786055234
Epoch: 62 | Iteration number: [2030/4518] 44% | Training loss: 0.6871552260638458
Epoch: 62 | Iteration number: [2040/4518] 45% | Training loss: 0.6871559366876003
Epoch: 62 | Iteration number: [2050/4518] 45% | Training loss: 0.6871463028105294
Epoch: 62 | Iteration number: [2060/4518] 45% | Training loss: 0.6871384382537268
Epoch: 62 | Iteration number: [2070/4518] 45% | Training loss: 0.6871357713920483
Epoch: 62 | Iteration number: [2080/4518] 46% | Training loss: 0.6871303117045989
Epoch: 62 | Iteration number: [2090/4518] 46% | Training loss: 0.6871268043392583
Epoch: 62 | Iteration number: [2100/4518] 46% | Training loss: 0.6871323074045635
Epoch: 62 | Iteration number: [2110/4518] 46% | Training loss: 0.687135494518054
Epoch: 62 | Iteration number: [2120/4518] 46% | Training loss: 0.6871279785374426
Epoch: 62 | Iteration number: [2130/4518] 47% | Training loss: 0.6871262900426354
Epoch: 62 | Iteration number: [2140/4518] 47% | Training loss: 0.6871236484184443
Epoch: 62 | Iteration number: [2150/4518] 47% | Training loss: 0.6871258104401965
Epoch: 62 | Iteration number: [2160/4518] 47% | Training loss: 0.6871256539391146
Epoch: 62 | Iteration number: [2170/4518] 48% | Training loss: 0.6871271832747393
Epoch: 62 | Iteration number: [2180/4518] 48% | Training loss: 0.687123440520479
Epoch: 62 | Iteration number: [2190/4518] 48% | Training loss: 0.6871273480049551
Epoch: 62 | Iteration number: [2200/4518] 48% | Training loss: 0.6871239655126224
Epoch: 62 | Iteration number: [2210/4518] 48% | Training loss: 0.6871250554716964
Epoch: 62 | Iteration number: [2220/4518] 49% | Training loss: 0.6871298285217973
Epoch: 62 | Iteration number: [2230/4518] 49% | Training loss: 0.6871268147043048
Epoch: 62 | Iteration number: [2240/4518] 49% | Training loss: 0.6871292864903807
Epoch: 62 | Iteration number: [2250/4518] 49% | Training loss: 0.6871328968207041
Epoch: 62 | Iteration number: [2260/4518] 50% | Training loss: 0.6871365197200691
Epoch: 62 | Iteration number: [2270/4518] 50% | Training loss: 0.6871323928959044
Epoch: 62 | Iteration number: [2280/4518] 50% | Training loss: 0.6871364585140295
Epoch: 62 | Iteration number: [2290/4518] 50% | Training loss: 0.6871368749953773
Epoch: 62 | Iteration number: [2300/4518] 50% | Training loss: 0.6871407536060914
Epoch: 62 | Iteration number: [2310/4518] 51% | Training loss: 0.68714124173313
Epoch: 62 | Iteration number: [2320/4518] 51% | Training loss: 0.6871377899472055
Epoch: 62 | Iteration number: [2330/4518] 51% | Training loss: 0.6871307882116587
Epoch: 62 | Iteration number: [2340/4518] 51% | Training loss: 0.6871357245577706
Epoch: 62 | Iteration number: [2350/4518] 52% | Training loss: 0.6871338914303069
Epoch: 62 | Iteration number: [2360/4518] 52% | Training loss: 0.6871355466923471
Epoch: 62 | Iteration number: [2370/4518] 52% | Training loss: 0.6871338675293741
Epoch: 62 | Iteration number: [2380/4518] 52% | Training loss: 0.6871359242361132
Epoch: 62 | Iteration number: [2390/4518] 52% | Training loss: 0.6871354545260074
Epoch: 62 | Iteration number: [2400/4518] 53% | Training loss: 0.6871329952528079
Epoch: 62 | Iteration number: [2410/4518] 53% | Training loss: 0.687118755559209
Epoch: 62 | Iteration number: [2420/4518] 53% | Training loss: 0.6871149298573328
Epoch: 62 | Iteration number: [2430/4518] 53% | Training loss: 0.6871164068518352
Epoch: 62 | Iteration number: [2440/4518] 54% | Training loss: 0.6871145090363064
Epoch: 62 | Iteration number: [2450/4518] 54% | Training loss: 0.6871135250646241
Epoch: 62 | Iteration number: [2460/4518] 54% | Training loss: 0.6871095377255262
Epoch: 62 | Iteration number: [2470/4518] 54% | Training loss: 0.6871041889615387
Epoch: 62 | Iteration number: [2480/4518] 54% | Training loss: 0.6871065361605536
Epoch: 62 | Iteration number: [2490/4518] 55% | Training loss: 0.6871050297974582
Epoch: 62 | Iteration number: [2500/4518] 55% | Training loss: 0.6871012974262237
Epoch: 62 | Iteration number: [2510/4518] 55% | Training loss: 0.6871039597636674
Epoch: 62 | Iteration number: [2520/4518] 55% | Training loss: 0.687100881953088
Epoch: 62 | Iteration number: [2530/4518] 55% | Training loss: 0.6870981913781449
Epoch: 62 | Iteration number: [2540/4518] 56% | Training loss: 0.6870979357892134
Epoch: 62 | Iteration number: [2550/4518] 56% | Training loss: 0.6870944825808207
Epoch: 62 | Iteration number: [2560/4518] 56% | Training loss: 0.6870963552501053
Epoch: 62 | Iteration number: [2570/4518] 56% | Training loss: 0.6870883491484572
Epoch: 62 | Iteration number: [2580/4518] 57% | Training loss: 0.6870838331390721
Epoch: 62 | Iteration number: [2590/4518] 57% | Training loss: 0.6870824076264062
Epoch: 62 | Iteration number: [2600/4518] 57% | Training loss: 0.6870807502590693
Epoch: 62 | Iteration number: [2610/4518] 57% | Training loss: 0.6870785471351667
Epoch: 62 | Iteration number: [2620/4518] 57% | Training loss: 0.6870774909967684
Epoch: 62 | Iteration number: [2630/4518] 58% | Training loss: 0.68707592074862
Epoch: 62 | Iteration number: [2640/4518] 58% | Training loss: 0.6870741692004781
Epoch: 62 | Iteration number: [2650/4518] 58% | Training loss: 0.6870726398477015
Epoch: 62 | Iteration number: [2660/4518] 58% | Training loss: 0.6870774402878338
Epoch: 62 | Iteration number: [2670/4518] 59% | Training loss: 0.6870799746406212
Epoch: 62 | Iteration number: [2680/4518] 59% | Training loss: 0.6870783042996677
Epoch: 62 | Iteration number: [2690/4518] 59% | Training loss: 0.6870774187784656
Epoch: 62 | Iteration number: [2700/4518] 59% | Training loss: 0.6870776766759378
Epoch: 62 | Iteration number: [2710/4518] 59% | Training loss: 0.6870733507005051
Epoch: 62 | Iteration number: [2720/4518] 60% | Training loss: 0.6870675086975098
Epoch: 62 | Iteration number: [2730/4518] 60% | Training loss: 0.6870635225004329
Epoch: 62 | Iteration number: [2740/4518] 60% | Training loss: 0.6870591015928853
Epoch: 62 | Iteration number: [2750/4518] 60% | Training loss: 0.6870586498217149
Epoch: 62 | Iteration number: [2760/4518] 61% | Training loss: 0.6870527021694874
Epoch: 62 | Iteration number: [2770/4518] 61% | Training loss: 0.6870525281136647
Epoch: 62 | Iteration number: [2780/4518] 61% | Training loss: 0.6870547326348668
Epoch: 62 | Iteration number: [2790/4518] 61% | Training loss: 0.6870569324407954
Epoch: 62 | Iteration number: [2800/4518] 61% | Training loss: 0.6870533183642796
Epoch: 62 | Iteration number: [2810/4518] 62% | Training loss: 0.6870567127691045
Epoch: 62 | Iteration number: [2820/4518] 62% | Training loss: 0.6870543613501474
Epoch: 62 | Iteration number: [2830/4518] 62% | Training loss: 0.6870481668639099
Epoch: 62 | Iteration number: [2840/4518] 62% | Training loss: 0.6870504765023648
Epoch: 62 | Iteration number: [2850/4518] 63% | Training loss: 0.6870434115853226
Epoch: 62 | Iteration number: [2860/4518] 63% | Training loss: 0.6870450974552782
Epoch: 62 | Iteration number: [2870/4518] 63% | Training loss: 0.6870432362739217
Epoch: 62 | Iteration number: [2880/4518] 63% | Training loss: 0.6870451217517257
Epoch: 62 | Iteration number: [2890/4518] 63% | Training loss: 0.6870451955440547
Epoch: 62 | Iteration number: [2900/4518] 64% | Training loss: 0.6870416750373511
Epoch: 62 | Iteration number: [2910/4518] 64% | Training loss: 0.6870423050475694
Epoch: 62 | Iteration number: [2920/4518] 64% | Training loss: 0.6870378077642558
Epoch: 62 | Iteration number: [2930/4518] 64% | Training loss: 0.68703087271277
Epoch: 62 | Iteration number: [2940/4518] 65% | Training loss: 0.6870280375894235
Epoch: 62 | Iteration number: [2950/4518] 65% | Training loss: 0.6870272304850109
Epoch: 62 | Iteration number: [2960/4518] 65% | Training loss: 0.6870229364649669
Epoch: 62 | Iteration number: [2970/4518] 65% | Training loss: 0.6870243621795667
Epoch: 62 | Iteration number: [2980/4518] 65% | Training loss: 0.6870235384710683
Epoch: 62 | Iteration number: [2990/4518] 66% | Training loss: 0.6870273522110687
Epoch: 62 | Iteration number: [3000/4518] 66% | Training loss: 0.6870270893971125
Epoch: 62 | Iteration number: [3010/4518] 66% | Training loss: 0.6870221091069256
Epoch: 62 | Iteration number: [3020/4518] 66% | Training loss: 0.6870164035369228
Epoch: 62 | Iteration number: [3030/4518] 67% | Training loss: 0.6870169411988148
Epoch: 62 | Iteration number: [3040/4518] 67% | Training loss: 0.6870166219770908
Epoch: 62 | Iteration number: [3050/4518] 67% | Training loss: 0.6870161237873015
Epoch: 62 | Iteration number: [3060/4518] 67% | Training loss: 0.6870133423727323
Epoch: 62 | Iteration number: [3070/4518] 67% | Training loss: 0.6870099096810779
Epoch: 62 | Iteration number: [3080/4518] 68% | Training loss: 0.687007031657479
Epoch: 62 | Iteration number: [3090/4518] 68% | Training loss: 0.6870062867221709
Epoch: 62 | Iteration number: [3100/4518] 68% | Training loss: 0.687007177375978
Epoch: 62 | Iteration number: [3110/4518] 68% | Training loss: 0.6870075939360922
Epoch: 62 | Iteration number: [3120/4518] 69% | Training loss: 0.6870046525429456
Epoch: 62 | Iteration number: [3130/4518] 69% | Training loss: 0.686999212571988
Epoch: 62 | Iteration number: [3140/4518] 69% | Training loss: 0.6870000869225544
Epoch: 62 | Iteration number: [3150/4518] 69% | Training loss: 0.6869978401774451
Epoch: 62 | Iteration number: [3160/4518] 69% | Training loss: 0.6869975562714323
Epoch: 62 | Iteration number: [3170/4518] 70% | Training loss: 0.6869983834799156
Epoch: 62 | Iteration number: [3180/4518] 70% | Training loss: 0.6869955474663081
Epoch: 62 | Iteration number: [3190/4518] 70% | Training loss: 0.6869969632184617
Epoch: 62 | Iteration number: [3200/4518] 70% | Training loss: 0.6869946643523872
Epoch: 62 | Iteration number: [3210/4518] 71% | Training loss: 0.6869947797412813
Epoch: 62 | Iteration number: [3220/4518] 71% | Training loss: 0.6869957186975835
Epoch: 62 | Iteration number: [3230/4518] 71% | Training loss: 0.6869905270105545
Epoch: 62 | Iteration number: [3240/4518] 71% | Training loss: 0.6869918318074426
Epoch: 62 | Iteration number: [3250/4518] 71% | Training loss: 0.6869972009842212
Epoch: 62 | Iteration number: [3260/4518] 72% | Training loss: 0.6870006676649023
Epoch: 62 | Iteration number: [3270/4518] 72% | Training loss: 0.6869990891637423
Epoch: 62 | Iteration number: [3280/4518] 72% | Training loss: 0.6869984121766032
Epoch: 62 | Iteration number: [3290/4518] 72% | Training loss: 0.6869988232579275
Epoch: 62 | Iteration number: [3300/4518] 73% | Training loss: 0.686998161872228
Epoch: 62 | Iteration number: [3310/4518] 73% | Training loss: 0.6869969593074027
Epoch: 62 | Iteration number: [3320/4518] 73% | Training loss: 0.6869979764323637
Epoch: 62 | Iteration number: [3330/4518] 73% | Training loss: 0.6869967227225547
Epoch: 62 | Iteration number: [3340/4518] 73% | Training loss: 0.6869972964425287
Epoch: 62 | Iteration number: [3350/4518] 74% | Training loss: 0.6870012199522844
Epoch: 62 | Iteration number: [3360/4518] 74% | Training loss: 0.6869988502136298
Epoch: 62 | Iteration number: [3370/4518] 74% | Training loss: 0.6869970127630658
Epoch: 62 | Iteration number: [3380/4518] 74% | Training loss: 0.6869971072180031
Epoch: 62 | Iteration number: [3390/4518] 75% | Training loss: 0.6869983421490256
Epoch: 62 | Iteration number: [3400/4518] 75% | Training loss: 0.6869976150638917
Epoch: 62 | Iteration number: [3410/4518] 75% | Training loss: 0.6869944716478723
Epoch: 62 | Iteration number: [3420/4518] 75% | Training loss: 0.6869926845818235
Epoch: 62 | Iteration number: [3430/4518] 75% | Training loss: 0.6869912723931905
Epoch: 62 | Iteration number: [3440/4518] 76% | Training loss: 0.6869891994221266
Epoch: 62 | Iteration number: [3450/4518] 76% | Training loss: 0.686985120859699
Epoch: 62 | Iteration number: [3460/4518] 76% | Training loss: 0.6869826782128714
Epoch: 62 | Iteration number: [3470/4518] 76% | Training loss: 0.6869848528581669
Epoch: 62 | Iteration number: [3480/4518] 77% | Training loss: 0.6869848906822589
Epoch: 62 | Iteration number: [3490/4518] 77% | Training loss: 0.686988260120922
Epoch: 62 | Iteration number: [3500/4518] 77% | Training loss: 0.6869867344072886
Epoch: 62 | Iteration number: [3510/4518] 77% | Training loss: 0.6869828226219895
Epoch: 62 | Iteration number: [3520/4518] 77% | Training loss: 0.6869808740236543
Epoch: 62 | Iteration number: [3530/4518] 78% | Training loss: 0.686982134769726
Epoch: 62 | Iteration number: [3540/4518] 78% | Training loss: 0.6869824442486305
Epoch: 62 | Iteration number: [3550/4518] 78% | Training loss: 0.6869845973605841
Epoch: 62 | Iteration number: [3560/4518] 78% | Training loss: 0.6869852544049199
Epoch: 62 | Iteration number: [3570/4518] 79% | Training loss: 0.6869830396662907
Epoch: 62 | Iteration number: [3580/4518] 79% | Training loss: 0.6869796236134108
Epoch: 62 | Iteration number: [3590/4518] 79% | Training loss: 0.6869823439705671
Epoch: 62 | Iteration number: [3600/4518] 79% | Training loss: 0.6869789436293973
Epoch: 62 | Iteration number: [3610/4518] 79% | Training loss: 0.686980813725173
Epoch: 62 | Iteration number: [3620/4518] 80% | Training loss: 0.6869794960344694
Epoch: 62 | Iteration number: [3630/4518] 80% | Training loss: 0.6869761960237151
Epoch: 62 | Iteration number: [3640/4518] 80% | Training loss: 0.6869752353200546
Epoch: 62 | Iteration number: [3650/4518] 80% | Training loss: 0.6869739213218428
Epoch: 62 | Iteration number: [3660/4518] 81% | Training loss: 0.686977678700223
Epoch: 62 | Iteration number: [3670/4518] 81% | Training loss: 0.6869790532770859
Epoch: 62 | Iteration number: [3680/4518] 81% | Training loss: 0.68697856190088
Epoch: 62 | Iteration number: [3690/4518] 81% | Training loss: 0.6869820641469826
Epoch: 62 | Iteration number: [3700/4518] 81% | Training loss: 0.6869806815321381
Epoch: 62 | Iteration number: [3710/4518] 82% | Training loss: 0.6869793444148935
Epoch: 62 | Iteration number: [3720/4518] 82% | Training loss: 0.6869806249936422
Epoch: 62 | Iteration number: [3730/4518] 82% | Training loss: 0.6869785282631022
Epoch: 62 | Iteration number: [3740/4518] 82% | Training loss: 0.6869820940303293
Epoch: 62 | Iteration number: [3750/4518] 83% | Training loss: 0.6869808449427287
Epoch: 62 | Iteration number: [3760/4518] 83% | Training loss: 0.6869785983828788
Epoch: 62 | Iteration number: [3770/4518] 83% | Training loss: 0.6869784669155151
Epoch: 62 | Iteration number: [3780/4518] 83% | Training loss: 0.6869776651815132
Epoch: 62 | Iteration number: [3790/4518] 83% | Training loss: 0.6869758101440672
Epoch: 62 | Iteration number: [3800/4518] 84% | Training loss: 0.6869769377928031
Epoch: 62 | Iteration number: [3810/4518] 84% | Training loss: 0.6869812213686195
Epoch: 62 | Iteration number: [3820/4518] 84% | Training loss: 0.6869829223106044
Epoch: 62 | Iteration number: [3830/4518] 84% | Training loss: 0.6869793342392376
Epoch: 62 | Iteration number: [3840/4518] 84% | Training loss: 0.6869802556931972
Epoch: 62 | Iteration number: [3850/4518] 85% | Training loss: 0.6869791061073155
Epoch: 62 | Iteration number: [3860/4518] 85% | Training loss: 0.686978555775677
Epoch: 62 | Iteration number: [3870/4518] 85% | Training loss: 0.6869824656836439
Epoch: 62 | Iteration number: [3880/4518] 85% | Training loss: 0.6869788493845881
Epoch: 62 | Iteration number: [3890/4518] 86% | Training loss: 0.6869752068446044
Epoch: 62 | Iteration number: [3900/4518] 86% | Training loss: 0.6869752278389075
Epoch: 62 | Iteration number: [3910/4518] 86% | Training loss: 0.6869728555459805
Epoch: 62 | Iteration number: [3920/4518] 86% | Training loss: 0.6869709960508104
Epoch: 62 | Iteration number: [3930/4518] 86% | Training loss: 0.6869695957532063
Epoch: 62 | Iteration number: [3940/4518] 87% | Training loss: 0.6869653686956706
Epoch: 62 | Iteration number: [3950/4518] 87% | Training loss: 0.6869650439069241
Epoch: 62 | Iteration number: [3960/4518] 87% | Training loss: 0.6869629904025732
Epoch: 62 | Iteration number: [3970/4518] 87% | Training loss: 0.6869606241471221
Epoch: 62 | Iteration number: [3980/4518] 88% | Training loss: 0.6869588292124283
Epoch: 62 | Iteration number: [3990/4518] 88% | Training loss: 0.6869585205737809
Epoch: 62 | Iteration number: [4000/4518] 88% | Training loss: 0.6869563788473606
Epoch: 62 | Iteration number: [4010/4518] 88% | Training loss: 0.6869563072845526
Epoch: 62 | Iteration number: [4020/4518] 88% | Training loss: 0.6869579270852739
Epoch: 62 | Iteration number: [4030/4518] 89% | Training loss: 0.6869594051731431
Epoch: 62 | Iteration number: [4040/4518] 89% | Training loss: 0.6869589351338915
Epoch: 62 | Iteration number: [4050/4518] 89% | Training loss: 0.686958994983155
Epoch: 62 | Iteration number: [4060/4518] 89% | Training loss: 0.6869565782729041
Epoch: 62 | Iteration number: [4070/4518] 90% | Training loss: 0.6869550978375887
Epoch: 62 | Iteration number: [4080/4518] 90% | Training loss: 0.6869572621058015
Epoch: 62 | Iteration number: [4090/4518] 90% | Training loss: 0.6869586838049527
Epoch: 62 | Iteration number: [4100/4518] 90% | Training loss: 0.6869563494513674
Epoch: 62 | Iteration number: [4110/4518] 90% | Training loss: 0.6869571702613738
Epoch: 62 | Iteration number: [4120/4518] 91% | Training loss: 0.6869546954492921
Epoch: 62 | Iteration number: [4130/4518] 91% | Training loss: 0.6869549924755789
Epoch: 62 | Iteration number: [4140/4518] 91% | Training loss: 0.6869539239556317
Epoch: 62 | Iteration number: [4150/4518] 91% | Training loss: 0.6869525851111814
Epoch: 62 | Iteration number: [4160/4518] 92% | Training loss: 0.6869522552937269
Epoch: 62 | Iteration number: [4170/4518] 92% | Training loss: 0.6869530236549515
Epoch: 62 | Iteration number: [4180/4518] 92% | Training loss: 0.6869528926588131
Epoch: 62 | Iteration number: [4190/4518] 92% | Training loss: 0.6869533481205278
Epoch: 62 | Iteration number: [4200/4518] 92% | Training loss: 0.686952304527873
Epoch: 62 | Iteration number: [4210/4518] 93% | Training loss: 0.6869515030797474
Epoch: 62 | Iteration number: [4220/4518] 93% | Training loss: 0.6869522492891239
Epoch: 62 | Iteration number: [4230/4518] 93% | Training loss: 0.6869528525828188
Epoch: 62 | Iteration number: [4240/4518] 93% | Training loss: 0.6869509378553561
Epoch: 62 | Iteration number: [4250/4518] 94% | Training loss: 0.6869504831257989
Epoch: 62 | Iteration number: [4260/4518] 94% | Training loss: 0.686952143347879
Epoch: 62 | Iteration number: [4270/4518] 94% | Training loss: 0.6869509055547468
Epoch: 62 | Iteration number: [4280/4518] 94% | Training loss: 0.6869522956765701
Epoch: 62 | Iteration number: [4290/4518] 94% | Training loss: 0.6869525477185949
Epoch: 62 | Iteration number: [4300/4518] 95% | Training loss: 0.6869520739621894
Epoch: 62 | Iteration number: [4310/4518] 95% | Training loss: 0.6869513992781983
Epoch: 62 | Iteration number: [4320/4518] 95% | Training loss: 0.6869517383062177
Epoch: 62 | Iteration number: [4330/4518] 95% | Training loss: 0.6869515661003959
Epoch: 62 | Iteration number: [4340/4518] 96% | Training loss: 0.6869533628087988
Epoch: 62 | Iteration number: [4350/4518] 96% | Training loss: 0.6869523697063841
Epoch: 62 | Iteration number: [4360/4518] 96% | Training loss: 0.686949591694075
Epoch: 62 | Iteration number: [4370/4518] 96% | Training loss: 0.686949351218527
Epoch: 62 | Iteration number: [4380/4518] 96% | Training loss: 0.6869495683336911
Epoch: 62 | Iteration number: [4390/4518] 97% | Training loss: 0.6869477610653245
Epoch: 62 | Iteration number: [4400/4518] 97% | Training loss: 0.6869448994371024
Epoch: 62 | Iteration number: [4410/4518] 97% | Training loss: 0.6869434524825911
Epoch: 62 | Iteration number: [4420/4518] 97% | Training loss: 0.6869412073047991
Epoch: 62 | Iteration number: [4430/4518] 98% | Training loss: 0.6869439836683984
Epoch: 62 | Iteration number: [4440/4518] 98% | Training loss: 0.6869439503228342
Epoch: 62 | Iteration number: [4450/4518] 98% | Training loss: 0.6869441610239865
Epoch: 62 | Iteration number: [4460/4518] 98% | Training loss: 0.6869407083822473
Epoch: 62 | Iteration number: [4470/4518] 98% | Training loss: 0.686942536958912
Epoch: 62 | Iteration number: [4480/4518] 99% | Training loss: 0.6869431564850467
Epoch: 62 | Iteration number: [4490/4518] 99% | Training loss: 0.6869441299634946
Epoch: 62 | Iteration number: [4500/4518] 99% | Training loss: 0.6869462994204627
Epoch: 62 | Iteration number: [4510/4518] 99% | Training loss: 0.6869443155445175

 End of epoch: 62 | Train Loss: 0.6867915004320301 | Training Time: 641 

 End of epoch: 62 | Eval Loss: 0.6898969241550991 | Evaluating Time: 17 
Epoch: 63 | Iteration number: [10/4518] 0% | Training loss: 0.7550496697425843
Epoch: 63 | Iteration number: [20/4518] 0% | Training loss: 0.720736312866211
Epoch: 63 | Iteration number: [30/4518] 0% | Training loss: 0.7092461268107096
Epoch: 63 | Iteration number: [40/4518] 0% | Training loss: 0.7038903698325157
Epoch: 63 | Iteration number: [50/4518] 1% | Training loss: 0.7007543182373047
Epoch: 63 | Iteration number: [60/4518] 1% | Training loss: 0.698307724793752
Epoch: 63 | Iteration number: [70/4518] 1% | Training loss: 0.6966301492282323
Epoch: 63 | Iteration number: [80/4518] 1% | Training loss: 0.6953590631484985
Epoch: 63 | Iteration number: [90/4518] 1% | Training loss: 0.694463845094045
Epoch: 63 | Iteration number: [100/4518] 2% | Training loss: 0.6936849647760391
Epoch: 63 | Iteration number: [110/4518] 2% | Training loss: 0.6930452471429651
Epoch: 63 | Iteration number: [120/4518] 2% | Training loss: 0.6925807957847913
Epoch: 63 | Iteration number: [130/4518] 2% | Training loss: 0.6920644581317902
Epoch: 63 | Iteration number: [140/4518] 3% | Training loss: 0.6917766617877142
Epoch: 63 | Iteration number: [150/4518] 3% | Training loss: 0.6913974837462107
Epoch: 63 | Iteration number: [160/4518] 3% | Training loss: 0.6910293344408274
Epoch: 63 | Iteration number: [170/4518] 3% | Training loss: 0.6907884955406189
Epoch: 63 | Iteration number: [180/4518] 3% | Training loss: 0.6906623933050368
Epoch: 63 | Iteration number: [190/4518] 4% | Training loss: 0.690462327003479
Epoch: 63 | Iteration number: [200/4518] 4% | Training loss: 0.6902802959084511
Epoch: 63 | Iteration number: [210/4518] 4% | Training loss: 0.690143947374253
Epoch: 63 | Iteration number: [220/4518] 4% | Training loss: 0.6899782649495385
Epoch: 63 | Iteration number: [230/4518] 5% | Training loss: 0.6898584591305774
Epoch: 63 | Iteration number: [240/4518] 5% | Training loss: 0.6897664686044057
Epoch: 63 | Iteration number: [250/4518] 5% | Training loss: 0.6896466963291168
Epoch: 63 | Iteration number: [260/4518] 5% | Training loss: 0.6895581600757745
Epoch: 63 | Iteration number: [270/4518] 5% | Training loss: 0.6894208307619448
Epoch: 63 | Iteration number: [280/4518] 6% | Training loss: 0.6893440204007285
Epoch: 63 | Iteration number: [290/4518] 6% | Training loss: 0.6892815676228753
Epoch: 63 | Iteration number: [300/4518] 6% | Training loss: 0.6891538633902867
Epoch: 63 | Iteration number: [310/4518] 6% | Training loss: 0.6890600173704086
Epoch: 63 | Iteration number: [320/4518] 7% | Training loss: 0.6889850491657853
Epoch: 63 | Iteration number: [330/4518] 7% | Training loss: 0.688931839393847
Epoch: 63 | Iteration number: [340/4518] 7% | Training loss: 0.6888747486998054
Epoch: 63 | Iteration number: [350/4518] 7% | Training loss: 0.6887879593031747
Epoch: 63 | Iteration number: [360/4518] 7% | Training loss: 0.6887311999996503
Epoch: 63 | Iteration number: [370/4518] 8% | Training loss: 0.6886979376947557
Epoch: 63 | Iteration number: [380/4518] 8% | Training loss: 0.6886743420048764
Epoch: 63 | Iteration number: [390/4518] 8% | Training loss: 0.6886541096063761
Epoch: 63 | Iteration number: [400/4518] 8% | Training loss: 0.6885887390375137
Epoch: 63 | Iteration number: [410/4518] 9% | Training loss: 0.6885462396028565
Epoch: 63 | Iteration number: [420/4518] 9% | Training loss: 0.6885030857154302
Epoch: 63 | Iteration number: [430/4518] 9% | Training loss: 0.6884705551834993
Epoch: 63 | Iteration number: [440/4518] 9% | Training loss: 0.6884356227788058
Epoch: 63 | Iteration number: [450/4518] 9% | Training loss: 0.6883847374386257
Epoch: 63 | Iteration number: [460/4518] 10% | Training loss: 0.6883578045212704
Epoch: 63 | Iteration number: [470/4518] 10% | Training loss: 0.6883519597510074
Epoch: 63 | Iteration number: [480/4518] 10% | Training loss: 0.6883178075154622
Epoch: 63 | Iteration number: [490/4518] 10% | Training loss: 0.6883089421963206
Epoch: 63 | Iteration number: [500/4518] 11% | Training loss: 0.6882716003656387
Epoch: 63 | Iteration number: [510/4518] 11% | Training loss: 0.6882673993998882
Epoch: 63 | Iteration number: [520/4518] 11% | Training loss: 0.6882280870125844
Epoch: 63 | Iteration number: [530/4518] 11% | Training loss: 0.6882110163850604
Epoch: 63 | Iteration number: [540/4518] 11% | Training loss: 0.6881786315529435
Epoch: 63 | Iteration number: [550/4518] 12% | Training loss: 0.6881447145071896
Epoch: 63 | Iteration number: [560/4518] 12% | Training loss: 0.6881315932742187
Epoch: 63 | Iteration number: [570/4518] 12% | Training loss: 0.6880981187025706
Epoch: 63 | Iteration number: [580/4518] 12% | Training loss: 0.6880792251948653
Epoch: 63 | Iteration number: [590/4518] 13% | Training loss: 0.6880566293910398
Epoch: 63 | Iteration number: [600/4518] 13% | Training loss: 0.6880464479327202
Epoch: 63 | Iteration number: [610/4518] 13% | Training loss: 0.6880297646170757
Epoch: 63 | Iteration number: [620/4518] 13% | Training loss: 0.6879983798150093
Epoch: 63 | Iteration number: [630/4518] 13% | Training loss: 0.6879505765816522
Epoch: 63 | Iteration number: [640/4518] 14% | Training loss: 0.6879295994527638
Epoch: 63 | Iteration number: [650/4518] 14% | Training loss: 0.6878932599837964
Epoch: 63 | Iteration number: [660/4518] 14% | Training loss: 0.6878657899119637
Epoch: 63 | Iteration number: [670/4518] 14% | Training loss: 0.6878609369939832
Epoch: 63 | Iteration number: [680/4518] 15% | Training loss: 0.6878441932446816
Epoch: 63 | Iteration number: [690/4518] 15% | Training loss: 0.6878446508144986
Epoch: 63 | Iteration number: [700/4518] 15% | Training loss: 0.6878446584088461
Epoch: 63 | Iteration number: [710/4518] 15% | Training loss: 0.6878177628550731
Epoch: 63 | Iteration number: [720/4518] 15% | Training loss: 0.6878027612964313
Epoch: 63 | Iteration number: [730/4518] 16% | Training loss: 0.6877699900979866
Epoch: 63 | Iteration number: [740/4518] 16% | Training loss: 0.6877687923811577
Epoch: 63 | Iteration number: [750/4518] 16% | Training loss: 0.6877679889202117
Epoch: 63 | Iteration number: [760/4518] 16% | Training loss: 0.6877490701644045
Epoch: 63 | Iteration number: [770/4518] 17% | Training loss: 0.6877500102891551
Epoch: 63 | Iteration number: [780/4518] 17% | Training loss: 0.6877464185158412
Epoch: 63 | Iteration number: [790/4518] 17% | Training loss: 0.687748443854006
Epoch: 63 | Iteration number: [800/4518] 17% | Training loss: 0.6877138610929251
Epoch: 63 | Iteration number: [810/4518] 17% | Training loss: 0.6877048635924304
Epoch: 63 | Iteration number: [820/4518] 18% | Training loss: 0.6877075541310194
Epoch: 63 | Iteration number: [830/4518] 18% | Training loss: 0.6877132904098695
Epoch: 63 | Iteration number: [840/4518] 18% | Training loss: 0.6877084998857408
Epoch: 63 | Iteration number: [850/4518] 18% | Training loss: 0.6876778031096739
Epoch: 63 | Iteration number: [860/4518] 19% | Training loss: 0.6876553111298139
Epoch: 63 | Iteration number: [870/4518] 19% | Training loss: 0.6876506726632173
Epoch: 63 | Iteration number: [880/4518] 19% | Training loss: 0.6876354116607796
Epoch: 63 | Iteration number: [890/4518] 19% | Training loss: 0.6876330310039306
Epoch: 63 | Iteration number: [900/4518] 19% | Training loss: 0.6876208612653945
Epoch: 63 | Iteration number: [910/4518] 20% | Training loss: 0.6876144788422427
Epoch: 63 | Iteration number: [920/4518] 20% | Training loss: 0.687599956470987
Epoch: 63 | Iteration number: [930/4518] 20% | Training loss: 0.6875881976337843
Epoch: 63 | Iteration number: [940/4518] 20% | Training loss: 0.6875765929196743
Epoch: 63 | Iteration number: [950/4518] 21% | Training loss: 0.6875638494993511
Epoch: 63 | Iteration number: [960/4518] 21% | Training loss: 0.6875392713273565
Epoch: 63 | Iteration number: [970/4518] 21% | Training loss: 0.6875333867736698
Epoch: 63 | Iteration number: [980/4518] 21% | Training loss: 0.6875378776569756
Epoch: 63 | Iteration number: [990/4518] 21% | Training loss: 0.6875275284954996
Epoch: 63 | Iteration number: [1000/4518] 22% | Training loss: 0.6875061587691307
Epoch: 63 | Iteration number: [1010/4518] 22% | Training loss: 0.6874962224818693
Epoch: 63 | Iteration number: [1020/4518] 22% | Training loss: 0.6875033028569876
Epoch: 63 | Iteration number: [1030/4518] 22% | Training loss: 0.6875036726877527
Epoch: 63 | Iteration number: [1040/4518] 23% | Training loss: 0.687499909905287
Epoch: 63 | Iteration number: [1050/4518] 23% | Training loss: 0.6874907931827363
Epoch: 63 | Iteration number: [1060/4518] 23% | Training loss: 0.6874722424543129
Epoch: 63 | Iteration number: [1070/4518] 23% | Training loss: 0.6874660753201102
Epoch: 63 | Iteration number: [1080/4518] 23% | Training loss: 0.6874602275314154
Epoch: 63 | Iteration number: [1090/4518] 24% | Training loss: 0.6874602965805509
Epoch: 63 | Iteration number: [1100/4518] 24% | Training loss: 0.6874560437961058
Epoch: 63 | Iteration number: [1110/4518] 24% | Training loss: 0.6874610398803745
Epoch: 63 | Iteration number: [1120/4518] 24% | Training loss: 0.6874642761690276
Epoch: 63 | Iteration number: [1130/4518] 25% | Training loss: 0.687462434093509
Epoch: 63 | Iteration number: [1140/4518] 25% | Training loss: 0.6874545815743898
Epoch: 63 | Iteration number: [1150/4518] 25% | Training loss: 0.6874500906985739
Epoch: 63 | Iteration number: [1160/4518] 25% | Training loss: 0.6874486365708812
Epoch: 63 | Iteration number: [1170/4518] 25% | Training loss: 0.6874409929299966
Epoch: 63 | Iteration number: [1180/4518] 26% | Training loss: 0.687420768151849
Epoch: 63 | Iteration number: [1190/4518] 26% | Training loss: 0.6874126862077152
Epoch: 63 | Iteration number: [1200/4518] 26% | Training loss: 0.6874072659015655
Epoch: 63 | Iteration number: [1210/4518] 26% | Training loss: 0.6874097819170676
Epoch: 63 | Iteration number: [1220/4518] 27% | Training loss: 0.6874083313297052
Epoch: 63 | Iteration number: [1230/4518] 27% | Training loss: 0.6874083814097613
Epoch: 63 | Iteration number: [1240/4518] 27% | Training loss: 0.6874078101688815
Epoch: 63 | Iteration number: [1250/4518] 27% | Training loss: 0.6874062013626099
Epoch: 63 | Iteration number: [1260/4518] 27% | Training loss: 0.6874141086661626
Epoch: 63 | Iteration number: [1270/4518] 28% | Training loss: 0.6874135926483185
Epoch: 63 | Iteration number: [1280/4518] 28% | Training loss: 0.6874070036690683
Epoch: 63 | Iteration number: [1290/4518] 28% | Training loss: 0.6874036317185838
Epoch: 63 | Iteration number: [1300/4518] 28% | Training loss: 0.6873956060409546
Epoch: 63 | Iteration number: [1310/4518] 28% | Training loss: 0.6873964535371038
Epoch: 63 | Iteration number: [1320/4518] 29% | Training loss: 0.6873969165213181
Epoch: 63 | Iteration number: [1330/4518] 29% | Training loss: 0.6873933631226532
Epoch: 63 | Iteration number: [1340/4518] 29% | Training loss: 0.6873825169766127
Epoch: 63 | Iteration number: [1350/4518] 29% | Training loss: 0.6873757636105573
Epoch: 63 | Iteration number: [1360/4518] 30% | Training loss: 0.6873712893356295
Epoch: 63 | Iteration number: [1370/4518] 30% | Training loss: 0.6873654248070543
Epoch: 63 | Iteration number: [1380/4518] 30% | Training loss: 0.6873589983021003
Epoch: 63 | Iteration number: [1390/4518] 30% | Training loss: 0.6873594618100914
Epoch: 63 | Iteration number: [1400/4518] 30% | Training loss: 0.6873475860272135
Epoch: 63 | Iteration number: [1410/4518] 31% | Training loss: 0.6873482992463078
Epoch: 63 | Iteration number: [1420/4518] 31% | Training loss: 0.6873325409603791
Epoch: 63 | Iteration number: [1430/4518] 31% | Training loss: 0.6873211297121915
Epoch: 63 | Iteration number: [1440/4518] 31% | Training loss: 0.6873205444879003
Epoch: 63 | Iteration number: [1450/4518] 32% | Training loss: 0.6873206290294385
Epoch: 63 | Iteration number: [1460/4518] 32% | Training loss: 0.6873250442416701
Epoch: 63 | Iteration number: [1470/4518] 32% | Training loss: 0.6873216558475883
Epoch: 63 | Iteration number: [1480/4518] 32% | Training loss: 0.6873198696487659
Epoch: 63 | Iteration number: [1490/4518] 32% | Training loss: 0.6873145774306867
Epoch: 63 | Iteration number: [1500/4518] 33% | Training loss: 0.6873168871005376
Epoch: 63 | Iteration number: [1510/4518] 33% | Training loss: 0.6873141097706674
Epoch: 63 | Iteration number: [1520/4518] 33% | Training loss: 0.6873043740266248
Epoch: 63 | Iteration number: [1530/4518] 33% | Training loss: 0.687300493826274
Epoch: 63 | Iteration number: [1540/4518] 34% | Training loss: 0.6873002328655936
Epoch: 63 | Iteration number: [1550/4518] 34% | Training loss: 0.6872882260430244
Epoch: 63 | Iteration number: [1560/4518] 34% | Training loss: 0.6872801979000752
Epoch: 63 | Iteration number: [1570/4518] 34% | Training loss: 0.6872754917402936
Epoch: 63 | Iteration number: [1580/4518] 34% | Training loss: 0.6872624870342544
Epoch: 63 | Iteration number: [1590/4518] 35% | Training loss: 0.6872583235584715
Epoch: 63 | Iteration number: [1600/4518] 35% | Training loss: 0.6872553800791502
Epoch: 63 | Iteration number: [1610/4518] 35% | Training loss: 0.687246223673317
Epoch: 63 | Iteration number: [1620/4518] 35% | Training loss: 0.6872449932274995
Epoch: 63 | Iteration number: [1630/4518] 36% | Training loss: 0.6872426989254045
Epoch: 63 | Iteration number: [1640/4518] 36% | Training loss: 0.6872530776189595
Epoch: 63 | Iteration number: [1650/4518] 36% | Training loss: 0.687252018993551
Epoch: 63 | Iteration number: [1660/4518] 36% | Training loss: 0.6872407515364957
Epoch: 63 | Iteration number: [1670/4518] 36% | Training loss: 0.6872324032697849
Epoch: 63 | Iteration number: [1680/4518] 37% | Training loss: 0.6872220517623993
Epoch: 63 | Iteration number: [1690/4518] 37% | Training loss: 0.6872220678442329
Epoch: 63 | Iteration number: [1700/4518] 37% | Training loss: 0.6872245873423184
Epoch: 63 | Iteration number: [1710/4518] 37% | Training loss: 0.6872256674613172
Epoch: 63 | Iteration number: [1720/4518] 38% | Training loss: 0.6872153553158737
Epoch: 63 | Iteration number: [1730/4518] 38% | Training loss: 0.6872060631396454
Epoch: 63 | Iteration number: [1740/4518] 38% | Training loss: 0.6871996684663597
Epoch: 63 | Iteration number: [1750/4518] 38% | Training loss: 0.6871998796803611
Epoch: 63 | Iteration number: [1760/4518] 38% | Training loss: 0.6871944368901578
Epoch: 63 | Iteration number: [1770/4518] 39% | Training loss: 0.6871956736691254
Epoch: 63 | Iteration number: [1780/4518] 39% | Training loss: 0.6871922467196925
Epoch: 63 | Iteration number: [1790/4518] 39% | Training loss: 0.687190291002476
Epoch: 63 | Iteration number: [1800/4518] 39% | Training loss: 0.6871828670303027
Epoch: 63 | Iteration number: [1810/4518] 40% | Training loss: 0.6871787324794748
Epoch: 63 | Iteration number: [1820/4518] 40% | Training loss: 0.687177826480551
Epoch: 63 | Iteration number: [1830/4518] 40% | Training loss: 0.687177721138209
Epoch: 63 | Iteration number: [1840/4518] 40% | Training loss: 0.6871771507289098
Epoch: 63 | Iteration number: [1850/4518] 40% | Training loss: 0.6871732043575596
Epoch: 63 | Iteration number: [1860/4518] 41% | Training loss: 0.6871760140183152
Epoch: 63 | Iteration number: [1870/4518] 41% | Training loss: 0.6871658453648103
Epoch: 63 | Iteration number: [1880/4518] 41% | Training loss: 0.6871628513995637
Epoch: 63 | Iteration number: [1890/4518] 41% | Training loss: 0.6871574640904785
Epoch: 63 | Iteration number: [1900/4518] 42% | Training loss: 0.6871543911256288
Epoch: 63 | Iteration number: [1910/4518] 42% | Training loss: 0.6871552765681481
Epoch: 63 | Iteration number: [1920/4518] 42% | Training loss: 0.6871563433669508
Epoch: 63 | Iteration number: [1930/4518] 42% | Training loss: 0.6871503991166544
Epoch: 63 | Iteration number: [1940/4518] 42% | Training loss: 0.6871537019297019
Epoch: 63 | Iteration number: [1950/4518] 43% | Training loss: 0.6871563381109482
Epoch: 63 | Iteration number: [1960/4518] 43% | Training loss: 0.687154598351644
Epoch: 63 | Iteration number: [1970/4518] 43% | Training loss: 0.6871559479817522
Epoch: 63 | Iteration number: [1980/4518] 43% | Training loss: 0.6871552524843602
Epoch: 63 | Iteration number: [1990/4518] 44% | Training loss: 0.6871562773857883
Epoch: 63 | Iteration number: [2000/4518] 44% | Training loss: 0.6871524443924427
Epoch: 63 | Iteration number: [2010/4518] 44% | Training loss: 0.687153762994121
Epoch: 63 | Iteration number: [2020/4518] 44% | Training loss: 0.6871535051872234
Epoch: 63 | Iteration number: [2030/4518] 44% | Training loss: 0.6871551668702676
Epoch: 63 | Iteration number: [2040/4518] 45% | Training loss: 0.6871538666241309
Epoch: 63 | Iteration number: [2050/4518] 45% | Training loss: 0.6871507532131381
Epoch: 63 | Iteration number: [2060/4518] 45% | Training loss: 0.6871502422013329
Epoch: 63 | Iteration number: [2070/4518] 45% | Training loss: 0.6871478732945262
Epoch: 63 | Iteration number: [2080/4518] 46% | Training loss: 0.6871446182234929
Epoch: 63 | Iteration number: [2090/4518] 46% | Training loss: 0.6871432540234196
Epoch: 63 | Iteration number: [2100/4518] 46% | Training loss: 0.6871398196901594
Epoch: 63 | Iteration number: [2110/4518] 46% | Training loss: 0.6871389694405958
Epoch: 63 | Iteration number: [2120/4518] 46% | Training loss: 0.6871400427143529
Epoch: 63 | Iteration number: [2130/4518] 47% | Training loss: 0.6871406245399528
Epoch: 63 | Iteration number: [2140/4518] 47% | Training loss: 0.6871424008195646
Epoch: 63 | Iteration number: [2150/4518] 47% | Training loss: 0.6871362021357514
Epoch: 63 | Iteration number: [2160/4518] 47% | Training loss: 0.6871355143410188
Epoch: 63 | Iteration number: [2170/4518] 48% | Training loss: 0.6871383634580445
Epoch: 63 | Iteration number: [2180/4518] 48% | Training loss: 0.6871379590362584
Epoch: 63 | Iteration number: [2190/4518] 48% | Training loss: 0.6871369103862814
Epoch: 63 | Iteration number: [2200/4518] 48% | Training loss: 0.6871368115598505
Epoch: 63 | Iteration number: [2210/4518] 48% | Training loss: 0.6871325472631066
Epoch: 63 | Iteration number: [2220/4518] 49% | Training loss: 0.687134982685785
Epoch: 63 | Iteration number: [2230/4518] 49% | Training loss: 0.6871363137602271
Epoch: 63 | Iteration number: [2240/4518] 49% | Training loss: 0.6871358695040856
Epoch: 63 | Iteration number: [2250/4518] 49% | Training loss: 0.6871348317464193
Epoch: 63 | Iteration number: [2260/4518] 50% | Training loss: 0.687135561799581
Epoch: 63 | Iteration number: [2270/4518] 50% | Training loss: 0.6871363952296421
Epoch: 63 | Iteration number: [2280/4518] 50% | Training loss: 0.6871374427226552
Epoch: 63 | Iteration number: [2290/4518] 50% | Training loss: 0.6871366152076221
Epoch: 63 | Iteration number: [2300/4518] 50% | Training loss: 0.6871377506463424
Epoch: 63 | Iteration number: [2310/4518] 51% | Training loss: 0.6871394083097384
Epoch: 63 | Iteration number: [2320/4518] 51% | Training loss: 0.6871375872914134
Epoch: 63 | Iteration number: [2330/4518] 51% | Training loss: 0.6871343824996458
Epoch: 63 | Iteration number: [2340/4518] 51% | Training loss: 0.6871353427314351
Epoch: 63 | Iteration number: [2350/4518] 52% | Training loss: 0.6871389953126299
Epoch: 63 | Iteration number: [2360/4518] 52% | Training loss: 0.687141651167708
Epoch: 63 | Iteration number: [2370/4518] 52% | Training loss: 0.687139077075926
Epoch: 63 | Iteration number: [2380/4518] 52% | Training loss: 0.6871338664984503
Epoch: 63 | Iteration number: [2390/4518] 52% | Training loss: 0.687133304569013
Epoch: 63 | Iteration number: [2400/4518] 53% | Training loss: 0.6871274865915378
Epoch: 63 | Iteration number: [2410/4518] 53% | Training loss: 0.6871189950660057
Epoch: 63 | Iteration number: [2420/4518] 53% | Training loss: 0.6871204764882395
Epoch: 63 | Iteration number: [2430/4518] 53% | Training loss: 0.6871161821938346
Epoch: 63 | Iteration number: [2440/4518] 54% | Training loss: 0.6871190898975388
Epoch: 63 | Iteration number: [2450/4518] 54% | Training loss: 0.6871173392996496
Epoch: 63 | Iteration number: [2460/4518] 54% | Training loss: 0.6871179586503564
Epoch: 63 | Iteration number: [2470/4518] 54% | Training loss: 0.6871106256598886
Epoch: 63 | Iteration number: [2480/4518] 54% | Training loss: 0.6871124910491128
Epoch: 63 | Iteration number: [2490/4518] 55% | Training loss: 0.6871142707196585
Epoch: 63 | Iteration number: [2500/4518] 55% | Training loss: 0.6871103702545166
Epoch: 63 | Iteration number: [2510/4518] 55% | Training loss: 0.6871060822114526
Epoch: 63 | Iteration number: [2520/4518] 55% | Training loss: 0.6871117830749542
Epoch: 63 | Iteration number: [2530/4518] 55% | Training loss: 0.6871071398022618
Epoch: 63 | Iteration number: [2540/4518] 56% | Training loss: 0.6871047877185926
Epoch: 63 | Iteration number: [2550/4518] 56% | Training loss: 0.6871086802435856
Epoch: 63 | Iteration number: [2560/4518] 56% | Training loss: 0.6871118036331609
Epoch: 63 | Iteration number: [2570/4518] 56% | Training loss: 0.6871096811173955
Epoch: 63 | Iteration number: [2580/4518] 57% | Training loss: 0.6871048370766085
Epoch: 63 | Iteration number: [2590/4518] 57% | Training loss: 0.6871062487709015
Epoch: 63 | Iteration number: [2600/4518] 57% | Training loss: 0.6871010640263557
Epoch: 63 | Iteration number: [2610/4518] 57% | Training loss: 0.6870968521783178
Epoch: 63 | Iteration number: [2620/4518] 57% | Training loss: 0.6870956607447326
Epoch: 63 | Iteration number: [2630/4518] 58% | Training loss: 0.6870947588985864
Epoch: 63 | Iteration number: [2640/4518] 58% | Training loss: 0.6870908632422938
Epoch: 63 | Iteration number: [2650/4518] 58% | Training loss: 0.6870883281050988
Epoch: 63 | Iteration number: [2660/4518] 58% | Training loss: 0.6870882076428348
Epoch: 63 | Iteration number: [2670/4518] 59% | Training loss: 0.6870868840244378
Epoch: 63 | Iteration number: [2680/4518] 59% | Training loss: 0.6870863528616393
Epoch: 63 | Iteration number: [2690/4518] 59% | Training loss: 0.6870854551021052
Epoch: 63 | Iteration number: [2700/4518] 59% | Training loss: 0.6870828404691485
Epoch: 63 | Iteration number: [2710/4518] 59% | Training loss: 0.687081734962569
Epoch: 63 | Iteration number: [2720/4518] 60% | Training loss: 0.6870838173610323
Epoch: 63 | Iteration number: [2730/4518] 60% | Training loss: 0.687079417923868
Epoch: 63 | Iteration number: [2740/4518] 60% | Training loss: 0.6870825703126671
Epoch: 63 | Iteration number: [2750/4518] 60% | Training loss: 0.6870830995169553
Epoch: 63 | Iteration number: [2760/4518] 61% | Training loss: 0.6870768171505651
Epoch: 63 | Iteration number: [2770/4518] 61% | Training loss: 0.687073560613157
Epoch: 63 | Iteration number: [2780/4518] 61% | Training loss: 0.687074666379167
Epoch: 63 | Iteration number: [2790/4518] 61% | Training loss: 0.6870742361178107
Epoch: 63 | Iteration number: [2800/4518] 61% | Training loss: 0.687074056076152
Epoch: 63 | Iteration number: [2810/4518] 62% | Training loss: 0.6870740884987909
Epoch: 63 | Iteration number: [2820/4518] 62% | Training loss: 0.6870733727377357
Epoch: 63 | Iteration number: [2830/4518] 62% | Training loss: 0.6870762478547046
Epoch: 63 | Iteration number: [2840/4518] 62% | Training loss: 0.6870700540676923
Epoch: 63 | Iteration number: [2850/4518] 63% | Training loss: 0.6870663193861644
Epoch: 63 | Iteration number: [2860/4518] 63% | Training loss: 0.6870668162624319
Epoch: 63 | Iteration number: [2870/4518] 63% | Training loss: 0.687060091325215
Epoch: 63 | Iteration number: [2880/4518] 63% | Training loss: 0.687058754844798
Epoch: 63 | Iteration number: [2890/4518] 63% | Training loss: 0.6870586606045496
Epoch: 63 | Iteration number: [2900/4518] 64% | Training loss: 0.6870590933438006
Epoch: 63 | Iteration number: [2910/4518] 64% | Training loss: 0.6870536094064156
Epoch: 63 | Iteration number: [2920/4518] 64% | Training loss: 0.687053784830113
Epoch: 63 | Iteration number: [2930/4518] 64% | Training loss: 0.6870477420478144
Epoch: 63 | Iteration number: [2940/4518] 65% | Training loss: 0.6870465805741395
Epoch: 63 | Iteration number: [2950/4518] 65% | Training loss: 0.6870449505822134
Epoch: 63 | Iteration number: [2960/4518] 65% | Training loss: 0.6870443552732468
Epoch: 63 | Iteration number: [2970/4518] 65% | Training loss: 0.6870378226342827
Epoch: 63 | Iteration number: [2980/4518] 65% | Training loss: 0.6870316124802468
Epoch: 63 | Iteration number: [2990/4518] 66% | Training loss: 0.687028407053804
Epoch: 63 | Iteration number: [3000/4518] 66% | Training loss: 0.6870283245444297
Epoch: 63 | Iteration number: [3010/4518] 66% | Training loss: 0.6870295917472966
Epoch: 63 | Iteration number: [3020/4518] 66% | Training loss: 0.6870317544368718
Epoch: 63 | Iteration number: [3030/4518] 67% | Training loss: 0.6870346836917864
Epoch: 63 | Iteration number: [3040/4518] 67% | Training loss: 0.6870289941759486
Epoch: 63 | Iteration number: [3050/4518] 67% | Training loss: 0.687029209527813
Epoch: 63 | Iteration number: [3060/4518] 67% | Training loss: 0.6870321155957926
Epoch: 63 | Iteration number: [3070/4518] 67% | Training loss: 0.687029535840311
Epoch: 63 | Iteration number: [3080/4518] 68% | Training loss: 0.687029897605444
Epoch: 63 | Iteration number: [3090/4518] 68% | Training loss: 0.6870292378089189
Epoch: 63 | Iteration number: [3100/4518] 68% | Training loss: 0.6870330481375417
Epoch: 63 | Iteration number: [3110/4518] 68% | Training loss: 0.6870296375352853
Epoch: 63 | Iteration number: [3120/4518] 69% | Training loss: 0.6870286787931735
Epoch: 63 | Iteration number: [3130/4518] 69% | Training loss: 0.687026438393151
Epoch: 63 | Iteration number: [3140/4518] 69% | Training loss: 0.6870249563341687
Epoch: 63 | Iteration number: [3150/4518] 69% | Training loss: 0.6870216340110415
Epoch: 63 | Iteration number: [3160/4518] 69% | Training loss: 0.6870169397207755
Epoch: 63 | Iteration number: [3170/4518] 70% | Training loss: 0.6870151381575347
Epoch: 63 | Iteration number: [3180/4518] 70% | Training loss: 0.6870175645598825
Epoch: 63 | Iteration number: [3190/4518] 70% | Training loss: 0.6870157477437142
Epoch: 63 | Iteration number: [3200/4518] 70% | Training loss: 0.6870162756182253
Epoch: 63 | Iteration number: [3210/4518] 71% | Training loss: 0.6870159106462544
Epoch: 63 | Iteration number: [3220/4518] 71% | Training loss: 0.6870160375322615
Epoch: 63 | Iteration number: [3230/4518] 71% | Training loss: 0.6870119694401237
Epoch: 63 | Iteration number: [3240/4518] 71% | Training loss: 0.687006001064071
Epoch: 63 | Iteration number: [3250/4518] 71% | Training loss: 0.6870093743067521
Epoch: 63 | Iteration number: [3260/4518] 72% | Training loss: 0.6870093723564792
Epoch: 63 | Iteration number: [3270/4518] 72% | Training loss: 0.6870075104251185
Epoch: 63 | Iteration number: [3280/4518] 72% | Training loss: 0.6870055395473794
Epoch: 63 | Iteration number: [3290/4518] 72% | Training loss: 0.6870037866580813
Epoch: 63 | Iteration number: [3300/4518] 73% | Training loss: 0.6870056883132819
Epoch: 63 | Iteration number: [3310/4518] 73% | Training loss: 0.6870045226146088
Epoch: 63 | Iteration number: [3320/4518] 73% | Training loss: 0.6870059192360166
Epoch: 63 | Iteration number: [3330/4518] 73% | Training loss: 0.6870011859290951
Epoch: 63 | Iteration number: [3340/4518] 73% | Training loss: 0.6869972109437703
Epoch: 63 | Iteration number: [3350/4518] 74% | Training loss: 0.6869975352821065
Epoch: 63 | Iteration number: [3360/4518] 74% | Training loss: 0.6869945472195035
Epoch: 63 | Iteration number: [3370/4518] 74% | Training loss: 0.6869957088893528
Epoch: 63 | Iteration number: [3380/4518] 74% | Training loss: 0.6869994948248891
Epoch: 63 | Iteration number: [3390/4518] 75% | Training loss: 0.6869983306149114
Epoch: 63 | Iteration number: [3400/4518] 75% | Training loss: 0.686997161858222
Epoch: 63 | Iteration number: [3410/4518] 75% | Training loss: 0.6869975151554231
Epoch: 63 | Iteration number: [3420/4518] 75% | Training loss: 0.6869993012725262
Epoch: 63 | Iteration number: [3430/4518] 75% | Training loss: 0.6870007948868476
Epoch: 63 | Iteration number: [3440/4518] 76% | Training loss: 0.6870001343793647
Epoch: 63 | Iteration number: [3450/4518] 76% | Training loss: 0.6869985997849617
Epoch: 63 | Iteration number: [3460/4518] 76% | Training loss: 0.6869990644082857
Epoch: 63 | Iteration number: [3470/4518] 76% | Training loss: 0.6869995941002706
Epoch: 63 | Iteration number: [3480/4518] 77% | Training loss: 0.6869977151525432
Epoch: 63 | Iteration number: [3490/4518] 77% | Training loss: 0.6869983248860925
Epoch: 63 | Iteration number: [3500/4518] 77% | Training loss: 0.6869981005872999
Epoch: 63 | Iteration number: [3510/4518] 77% | Training loss: 0.6869968955842858
Epoch: 63 | Iteration number: [3520/4518] 77% | Training loss: 0.6869976901872592
Epoch: 63 | Iteration number: [3530/4518] 78% | Training loss: 0.6869971516956351
Epoch: 63 | Iteration number: [3540/4518] 78% | Training loss: 0.6869969242541804
Epoch: 63 | Iteration number: [3550/4518] 78% | Training loss: 0.6869939571535083
Epoch: 63 | Iteration number: [3560/4518] 78% | Training loss: 0.6869932858294315
Epoch: 63 | Iteration number: [3570/4518] 79% | Training loss: 0.6869924070287485
Epoch: 63 | Iteration number: [3580/4518] 79% | Training loss: 0.6869913136492894
Epoch: 63 | Iteration number: [3590/4518] 79% | Training loss: 0.6869887600370105
Epoch: 63 | Iteration number: [3600/4518] 79% | Training loss: 0.6869883074528641
Epoch: 63 | Iteration number: [3610/4518] 79% | Training loss: 0.6869893447018727
Epoch: 63 | Iteration number: [3620/4518] 80% | Training loss: 0.686990677322472
Epoch: 63 | Iteration number: [3630/4518] 80% | Training loss: 0.6869910096169831
Epoch: 63 | Iteration number: [3640/4518] 80% | Training loss: 0.6869904416603047
Epoch: 63 | Iteration number: [3650/4518] 80% | Training loss: 0.6869876448585562
Epoch: 63 | Iteration number: [3660/4518] 81% | Training loss: 0.6869863789752533
Epoch: 63 | Iteration number: [3670/4518] 81% | Training loss: 0.6869850132056088
Epoch: 63 | Iteration number: [3680/4518] 81% | Training loss: 0.6869783577549716
Epoch: 63 | Iteration number: [3690/4518] 81% | Training loss: 0.6869779637512475
Epoch: 63 | Iteration number: [3700/4518] 81% | Training loss: 0.6869755513764716
Epoch: 63 | Iteration number: [3710/4518] 82% | Training loss: 0.6869746845526836
Epoch: 63 | Iteration number: [3720/4518] 82% | Training loss: 0.6869703488644733
Epoch: 63 | Iteration number: [3730/4518] 82% | Training loss: 0.6869684367652873
Epoch: 63 | Iteration number: [3740/4518] 82% | Training loss: 0.6869657028008272
Epoch: 63 | Iteration number: [3750/4518] 83% | Training loss: 0.6869663194179535
Epoch: 63 | Iteration number: [3760/4518] 83% | Training loss: 0.6869678856844598
Epoch: 63 | Iteration number: [3770/4518] 83% | Training loss: 0.6869662881688035
Epoch: 63 | Iteration number: [3780/4518] 83% | Training loss: 0.6869673480117132
Epoch: 63 | Iteration number: [3790/4518] 83% | Training loss: 0.6869673135098178
Epoch: 63 | Iteration number: [3800/4518] 84% | Training loss: 0.6869671528747208
Epoch: 63 | Iteration number: [3810/4518] 84% | Training loss: 0.6869638014340338
Epoch: 63 | Iteration number: [3820/4518] 84% | Training loss: 0.6869637385088736
Epoch: 63 | Iteration number: [3830/4518] 84% | Training loss: 0.6869627151881434
Epoch: 63 | Iteration number: [3840/4518] 84% | Training loss: 0.686963401734829
Epoch: 63 | Iteration number: [3850/4518] 85% | Training loss: 0.6869644775483515
Epoch: 63 | Iteration number: [3860/4518] 85% | Training loss: 0.6869671128728847
Epoch: 63 | Iteration number: [3870/4518] 85% | Training loss: 0.6869679764875762
Epoch: 63 | Iteration number: [3880/4518] 85% | Training loss: 0.6869680422483031
Epoch: 63 | Iteration number: [3890/4518] 86% | Training loss: 0.6869695872911145
Epoch: 63 | Iteration number: [3900/4518] 86% | Training loss: 0.6869705034219301
Epoch: 63 | Iteration number: [3910/4518] 86% | Training loss: 0.6869699765196846
Epoch: 63 | Iteration number: [3920/4518] 86% | Training loss: 0.6869700221991052
Epoch: 63 | Iteration number: [3930/4518] 86% | Training loss: 0.6869662900159074
Epoch: 63 | Iteration number: [3940/4518] 87% | Training loss: 0.6869618309179538
Epoch: 63 | Iteration number: [3950/4518] 87% | Training loss: 0.6869615706310996
Epoch: 63 | Iteration number: [3960/4518] 87% | Training loss: 0.6869597704874144
Epoch: 63 | Iteration number: [3970/4518] 87% | Training loss: 0.6869596430726856
Epoch: 63 | Iteration number: [3980/4518] 88% | Training loss: 0.6869570277593843
Epoch: 63 | Iteration number: [3990/4518] 88% | Training loss: 0.6869570181035158
Epoch: 63 | Iteration number: [4000/4518] 88% | Training loss: 0.6869554498791695
Epoch: 63 | Iteration number: [4010/4518] 88% | Training loss: 0.6869574676279415
Epoch: 63 | Iteration number: [4020/4518] 88% | Training loss: 0.686954740268081
Epoch: 63 | Iteration number: [4030/4518] 89% | Training loss: 0.6869552207200166
Epoch: 63 | Iteration number: [4040/4518] 89% | Training loss: 0.6869565756014078
Epoch: 63 | Iteration number: [4050/4518] 89% | Training loss: 0.6869553874304265
Epoch: 63 | Iteration number: [4060/4518] 89% | Training loss: 0.6869544794994035
Epoch: 63 | Iteration number: [4070/4518] 90% | Training loss: 0.6869558409625248
Epoch: 63 | Iteration number: [4080/4518] 90% | Training loss: 0.6869541526863387
Epoch: 63 | Iteration number: [4090/4518] 90% | Training loss: 0.686956192155922
Epoch: 63 | Iteration number: [4100/4518] 90% | Training loss: 0.6869533697424866
Epoch: 63 | Iteration number: [4110/4518] 90% | Training loss: 0.686954275708999
Epoch: 63 | Iteration number: [4120/4518] 91% | Training loss: 0.6869569290465521
Epoch: 63 | Iteration number: [4130/4518] 91% | Training loss: 0.6869538695846863
Epoch: 63 | Iteration number: [4140/4518] 91% | Training loss: 0.6869542242536222
Epoch: 63 | Iteration number: [4150/4518] 91% | Training loss: 0.6869503686801497
Epoch: 63 | Iteration number: [4160/4518] 92% | Training loss: 0.6869481812159602
Epoch: 63 | Iteration number: [4170/4518] 92% | Training loss: 0.6869495031073225
Epoch: 63 | Iteration number: [4180/4518] 92% | Training loss: 0.6869490428832159
Epoch: 63 | Iteration number: [4190/4518] 92% | Training loss: 0.6869462436309578
Epoch: 63 | Iteration number: [4200/4518] 92% | Training loss: 0.6869480738753364
Epoch: 63 | Iteration number: [4210/4518] 93% | Training loss: 0.6869469667557017
Epoch: 63 | Iteration number: [4220/4518] 93% | Training loss: 0.6869473231206008
Epoch: 63 | Iteration number: [4230/4518] 93% | Training loss: 0.6869441823615532
Epoch: 63 | Iteration number: [4240/4518] 93% | Training loss: 0.6869428227532585
Epoch: 63 | Iteration number: [4250/4518] 94% | Training loss: 0.6869413070818957
Epoch: 63 | Iteration number: [4260/4518] 94% | Training loss: 0.6869411326350181
Epoch: 63 | Iteration number: [4270/4518] 94% | Training loss: 0.686940648851685
Epoch: 63 | Iteration number: [4280/4518] 94% | Training loss: 0.6869401128910412
Epoch: 63 | Iteration number: [4290/4518] 94% | Training loss: 0.6869394080483274
Epoch: 63 | Iteration number: [4300/4518] 95% | Training loss: 0.6869380811203358
Epoch: 63 | Iteration number: [4310/4518] 95% | Training loss: 0.6869338272619137
Epoch: 63 | Iteration number: [4320/4518] 95% | Training loss: 0.6869355037946392
Epoch: 63 | Iteration number: [4330/4518] 95% | Training loss: 0.686931249107004
Epoch: 63 | Iteration number: [4340/4518] 96% | Training loss: 0.6869326843781405
Epoch: 63 | Iteration number: [4350/4518] 96% | Training loss: 0.6869322964240765
Epoch: 63 | Iteration number: [4360/4518] 96% | Training loss: 0.6869338035036664
Epoch: 63 | Iteration number: [4370/4518] 96% | Training loss: 0.6869339338292791
Epoch: 63 | Iteration number: [4380/4518] 96% | Training loss: 0.6869354112779713
Epoch: 63 | Iteration number: [4390/4518] 97% | Training loss: 0.68693660154158
Epoch: 63 | Iteration number: [4400/4518] 97% | Training loss: 0.6869383164427497
Epoch: 63 | Iteration number: [4410/4518] 97% | Training loss: 0.686939278197667
Epoch: 63 | Iteration number: [4420/4518] 97% | Training loss: 0.6869389900659544
Epoch: 63 | Iteration number: [4430/4518] 98% | Training loss: 0.6869388738012207
Epoch: 63 | Iteration number: [4440/4518] 98% | Training loss: 0.6869374363540529
Epoch: 63 | Iteration number: [4450/4518] 98% | Training loss: 0.6869370060020619
Epoch: 63 | Iteration number: [4460/4518] 98% | Training loss: 0.68693806869834
Epoch: 63 | Iteration number: [4470/4518] 98% | Training loss: 0.68693802515399
Epoch: 63 | Iteration number: [4480/4518] 99% | Training loss: 0.686935072605099
Epoch: 63 | Iteration number: [4490/4518] 99% | Training loss: 0.686938176933004
Epoch: 63 | Iteration number: [4500/4518] 99% | Training loss: 0.6869376471042633
Epoch: 63 | Iteration number: [4510/4518] 99% | Training loss: 0.6869350913622956

 End of epoch: 63 | Train Loss: 0.6867847786033084 | Training Time: 641 

 End of epoch: 63 | Eval Loss: 0.6898797154426575 | Evaluating Time: 17 
Epoch: 64 | Iteration number: [10/4518] 0% | Training loss: 0.7559571504592896
Epoch: 64 | Iteration number: [20/4518] 0% | Training loss: 0.7206691801548004
Epoch: 64 | Iteration number: [30/4518] 0% | Training loss: 0.7095149040222168
Epoch: 64 | Iteration number: [40/4518] 0% | Training loss: 0.7041382819414139
Epoch: 64 | Iteration number: [50/4518] 1% | Training loss: 0.700887359380722
Epoch: 64 | Iteration number: [60/4518] 1% | Training loss: 0.6985269000132879
Epoch: 64 | Iteration number: [70/4518] 1% | Training loss: 0.6969313774790082
Epoch: 64 | Iteration number: [80/4518] 1% | Training loss: 0.695606516301632
Epoch: 64 | Iteration number: [90/4518] 1% | Training loss: 0.6945829742484623
Epoch: 64 | Iteration number: [100/4518] 2% | Training loss: 0.6937382060289383
Epoch: 64 | Iteration number: [110/4518] 2% | Training loss: 0.6930180126970464
Epoch: 64 | Iteration number: [120/4518] 2% | Training loss: 0.6925425181786219
Epoch: 64 | Iteration number: [130/4518] 2% | Training loss: 0.6919935029286605
Epoch: 64 | Iteration number: [140/4518] 3% | Training loss: 0.6916026132447379
Epoch: 64 | Iteration number: [150/4518] 3% | Training loss: 0.6913348996639251
Epoch: 64 | Iteration number: [160/4518] 3% | Training loss: 0.6910714939236641
Epoch: 64 | Iteration number: [170/4518] 3% | Training loss: 0.6907976981471566
Epoch: 64 | Iteration number: [180/4518] 3% | Training loss: 0.6905932684739431
Epoch: 64 | Iteration number: [190/4518] 4% | Training loss: 0.6904806607647946
Epoch: 64 | Iteration number: [200/4518] 4% | Training loss: 0.6902912679314613
Epoch: 64 | Iteration number: [210/4518] 4% | Training loss: 0.6901639268511818
Epoch: 64 | Iteration number: [220/4518] 4% | Training loss: 0.6900285728953102
Epoch: 64 | Iteration number: [230/4518] 5% | Training loss: 0.6898696899414063
Epoch: 64 | Iteration number: [240/4518] 5% | Training loss: 0.6897538187603156
Epoch: 64 | Iteration number: [250/4518] 5% | Training loss: 0.689594301700592
Epoch: 64 | Iteration number: [260/4518] 5% | Training loss: 0.6895190383379276
Epoch: 64 | Iteration number: [270/4518] 5% | Training loss: 0.6894083683137541
Epoch: 64 | Iteration number: [280/4518] 6% | Training loss: 0.6893249292458806
Epoch: 64 | Iteration number: [290/4518] 6% | Training loss: 0.6892282648333188
Epoch: 64 | Iteration number: [300/4518] 6% | Training loss: 0.6891242049137751
Epoch: 64 | Iteration number: [310/4518] 6% | Training loss: 0.6890697375420601
Epoch: 64 | Iteration number: [320/4518] 7% | Training loss: 0.6889895802363754
Epoch: 64 | Iteration number: [330/4518] 7% | Training loss: 0.6888695924571067
Epoch: 64 | Iteration number: [340/4518] 7% | Training loss: 0.6888158454614527
Epoch: 64 | Iteration number: [350/4518] 7% | Training loss: 0.6887654556546893
Epoch: 64 | Iteration number: [360/4518] 7% | Training loss: 0.6887011662125587
Epoch: 64 | Iteration number: [370/4518] 8% | Training loss: 0.6886169084020564
Epoch: 64 | Iteration number: [380/4518] 8% | Training loss: 0.6885545939207077
Epoch: 64 | Iteration number: [390/4518] 8% | Training loss: 0.6884864507577358
Epoch: 64 | Iteration number: [400/4518] 8% | Training loss: 0.6884603588283063
Epoch: 64 | Iteration number: [410/4518] 9% | Training loss: 0.688424635224226
Epoch: 64 | Iteration number: [420/4518] 9% | Training loss: 0.6883907180456889
Epoch: 64 | Iteration number: [430/4518] 9% | Training loss: 0.6883425420106843
Epoch: 64 | Iteration number: [440/4518] 9% | Training loss: 0.6883137169209393
Epoch: 64 | Iteration number: [450/4518] 9% | Training loss: 0.6882898736000062
Epoch: 64 | Iteration number: [460/4518] 10% | Training loss: 0.6882881252661995
Epoch: 64 | Iteration number: [470/4518] 10% | Training loss: 0.6882627805496784
Epoch: 64 | Iteration number: [480/4518] 10% | Training loss: 0.688241924593846
Epoch: 64 | Iteration number: [490/4518] 10% | Training loss: 0.6882224562216778
Epoch: 64 | Iteration number: [500/4518] 11% | Training loss: 0.6881783835887909
Epoch: 64 | Iteration number: [510/4518] 11% | Training loss: 0.6881633184704126
Epoch: 64 | Iteration number: [520/4518] 11% | Training loss: 0.6881425021932676
Epoch: 64 | Iteration number: [530/4518] 11% | Training loss: 0.6881288601542419
Epoch: 64 | Iteration number: [540/4518] 11% | Training loss: 0.6881127637845499
Epoch: 64 | Iteration number: [550/4518] 12% | Training loss: 0.6880696332454681
Epoch: 64 | Iteration number: [560/4518] 12% | Training loss: 0.6880493728177888
Epoch: 64 | Iteration number: [570/4518] 12% | Training loss: 0.6880220298181501
Epoch: 64 | Iteration number: [580/4518] 12% | Training loss: 0.6879849076271057
Epoch: 64 | Iteration number: [590/4518] 13% | Training loss: 0.6880035339775732
Epoch: 64 | Iteration number: [600/4518] 13% | Training loss: 0.6879651745160421
Epoch: 64 | Iteration number: [610/4518] 13% | Training loss: 0.6879512282668567
Epoch: 64 | Iteration number: [620/4518] 13% | Training loss: 0.6879226941254831
Epoch: 64 | Iteration number: [630/4518] 13% | Training loss: 0.6879209615881481
Epoch: 64 | Iteration number: [640/4518] 14% | Training loss: 0.6879123686812818
Epoch: 64 | Iteration number: [650/4518] 14% | Training loss: 0.6878935937698071
Epoch: 64 | Iteration number: [660/4518] 14% | Training loss: 0.6878872155240088
Epoch: 64 | Iteration number: [670/4518] 14% | Training loss: 0.6878666366214183
Epoch: 64 | Iteration number: [680/4518] 15% | Training loss: 0.687857183638741
Epoch: 64 | Iteration number: [690/4518] 15% | Training loss: 0.687840189450029
Epoch: 64 | Iteration number: [700/4518] 15% | Training loss: 0.6878229342188154
Epoch: 64 | Iteration number: [710/4518] 15% | Training loss: 0.6878008462173838
Epoch: 64 | Iteration number: [720/4518] 15% | Training loss: 0.6877799831330776
Epoch: 64 | Iteration number: [730/4518] 16% | Training loss: 0.6877508804406205
Epoch: 64 | Iteration number: [740/4518] 16% | Training loss: 0.6877588180271355
Epoch: 64 | Iteration number: [750/4518] 16% | Training loss: 0.6877393314838409
Epoch: 64 | Iteration number: [760/4518] 16% | Training loss: 0.6877249885546534
Epoch: 64 | Iteration number: [770/4518] 17% | Training loss: 0.6877182958187995
Epoch: 64 | Iteration number: [780/4518] 17% | Training loss: 0.6876949651883199
Epoch: 64 | Iteration number: [790/4518] 17% | Training loss: 0.6876793415486058
Epoch: 64 | Iteration number: [800/4518] 17% | Training loss: 0.6876718275249004
Epoch: 64 | Iteration number: [810/4518] 17% | Training loss: 0.687664595356694
Epoch: 64 | Iteration number: [820/4518] 18% | Training loss: 0.6876638307077129
Epoch: 64 | Iteration number: [830/4518] 18% | Training loss: 0.687665926907436
Epoch: 64 | Iteration number: [840/4518] 18% | Training loss: 0.6876399579502287
Epoch: 64 | Iteration number: [850/4518] 18% | Training loss: 0.6876413460338817
Epoch: 64 | Iteration number: [860/4518] 19% | Training loss: 0.6876201780729516
Epoch: 64 | Iteration number: [870/4518] 19% | Training loss: 0.6876122281469148
Epoch: 64 | Iteration number: [880/4518] 19% | Training loss: 0.6876163700764829
Epoch: 64 | Iteration number: [890/4518] 19% | Training loss: 0.6876073367809982
Epoch: 64 | Iteration number: [900/4518] 19% | Training loss: 0.6875952004724079
Epoch: 64 | Iteration number: [910/4518] 20% | Training loss: 0.6875777706995115
Epoch: 64 | Iteration number: [920/4518] 20% | Training loss: 0.6875593145904334
Epoch: 64 | Iteration number: [930/4518] 20% | Training loss: 0.6875499952864903
Epoch: 64 | Iteration number: [940/4518] 20% | Training loss: 0.6875479452787562
Epoch: 64 | Iteration number: [950/4518] 21% | Training loss: 0.6875411031120702
Epoch: 64 | Iteration number: [960/4518] 21% | Training loss: 0.6875266574944059
Epoch: 64 | Iteration number: [970/4518] 21% | Training loss: 0.6875184022274214
Epoch: 64 | Iteration number: [980/4518] 21% | Training loss: 0.6875045228369382
Epoch: 64 | Iteration number: [990/4518] 21% | Training loss: 0.6875100205040942
Epoch: 64 | Iteration number: [1000/4518] 22% | Training loss: 0.6875019284486771
Epoch: 64 | Iteration number: [1010/4518] 22% | Training loss: 0.687497876304211
Epoch: 64 | Iteration number: [1020/4518] 22% | Training loss: 0.6874935844949648
Epoch: 64 | Iteration number: [1030/4518] 22% | Training loss: 0.6874799450624336
Epoch: 64 | Iteration number: [1040/4518] 23% | Training loss: 0.6874779527003948
Epoch: 64 | Iteration number: [1050/4518] 23% | Training loss: 0.6874882853598822
Epoch: 64 | Iteration number: [1060/4518] 23% | Training loss: 0.687482131708343
Epoch: 64 | Iteration number: [1070/4518] 23% | Training loss: 0.6874819804574842
Epoch: 64 | Iteration number: [1080/4518] 23% | Training loss: 0.6874813224982332
Epoch: 64 | Iteration number: [1090/4518] 24% | Training loss: 0.6874760863431003
Epoch: 64 | Iteration number: [1100/4518] 24% | Training loss: 0.6874637899615548
Epoch: 64 | Iteration number: [1110/4518] 24% | Training loss: 0.6874643940646369
Epoch: 64 | Iteration number: [1120/4518] 24% | Training loss: 0.6874671998832907
Epoch: 64 | Iteration number: [1130/4518] 25% | Training loss: 0.687455950163107
Epoch: 64 | Iteration number: [1140/4518] 25% | Training loss: 0.687447462583843
Epoch: 64 | Iteration number: [1150/4518] 25% | Training loss: 0.6874403784586036
Epoch: 64 | Iteration number: [1160/4518] 25% | Training loss: 0.6874331673157626
Epoch: 64 | Iteration number: [1170/4518] 25% | Training loss: 0.6874299878238612
Epoch: 64 | Iteration number: [1180/4518] 26% | Training loss: 0.6874200948214126
Epoch: 64 | Iteration number: [1190/4518] 26% | Training loss: 0.6874143086060757
Epoch: 64 | Iteration number: [1200/4518] 26% | Training loss: 0.6874080197513104
Epoch: 64 | Iteration number: [1210/4518] 26% | Training loss: 0.6873969984448646
Epoch: 64 | Iteration number: [1220/4518] 27% | Training loss: 0.6873891251009019
Epoch: 64 | Iteration number: [1230/4518] 27% | Training loss: 0.6873725226254968
Epoch: 64 | Iteration number: [1240/4518] 27% | Training loss: 0.687372228455159
Epoch: 64 | Iteration number: [1250/4518] 27% | Training loss: 0.6873774492740631
Epoch: 64 | Iteration number: [1260/4518] 27% | Training loss: 0.6873719806708987
Epoch: 64 | Iteration number: [1270/4518] 28% | Training loss: 0.687367847726101
Epoch: 64 | Iteration number: [1280/4518] 28% | Training loss: 0.6873694005422294
Epoch: 64 | Iteration number: [1290/4518] 28% | Training loss: 0.6873655355715936
Epoch: 64 | Iteration number: [1300/4518] 28% | Training loss: 0.68735855281353
Epoch: 64 | Iteration number: [1310/4518] 28% | Training loss: 0.6873545061540968
Epoch: 64 | Iteration number: [1320/4518] 29% | Training loss: 0.6873516877040718
Epoch: 64 | Iteration number: [1330/4518] 29% | Training loss: 0.6873584186672268
Epoch: 64 | Iteration number: [1340/4518] 29% | Training loss: 0.6873553279620498
Epoch: 64 | Iteration number: [1350/4518] 29% | Training loss: 0.6873530297367662
Epoch: 64 | Iteration number: [1360/4518] 30% | Training loss: 0.6873471827191465
Epoch: 64 | Iteration number: [1370/4518] 30% | Training loss: 0.6873440992223085
Epoch: 64 | Iteration number: [1380/4518] 30% | Training loss: 0.6873401524796002
Epoch: 64 | Iteration number: [1390/4518] 30% | Training loss: 0.6873335364911196
Epoch: 64 | Iteration number: [1400/4518] 30% | Training loss: 0.6873355194074767
Epoch: 64 | Iteration number: [1410/4518] 31% | Training loss: 0.6873400005888431
Epoch: 64 | Iteration number: [1420/4518] 31% | Training loss: 0.6873368702304196
Epoch: 64 | Iteration number: [1430/4518] 31% | Training loss: 0.6873244282665786
Epoch: 64 | Iteration number: [1440/4518] 31% | Training loss: 0.6873225008034044
Epoch: 64 | Iteration number: [1450/4518] 32% | Training loss: 0.6873241804386008
Epoch: 64 | Iteration number: [1460/4518] 32% | Training loss: 0.6873124365528969
Epoch: 64 | Iteration number: [1470/4518] 32% | Training loss: 0.6873102587907493
Epoch: 64 | Iteration number: [1480/4518] 32% | Training loss: 0.6872988983183294
Epoch: 64 | Iteration number: [1490/4518] 32% | Training loss: 0.6872877594608588
Epoch: 64 | Iteration number: [1500/4518] 33% | Training loss: 0.6872851773500442
Epoch: 64 | Iteration number: [1510/4518] 33% | Training loss: 0.6872855187251868
Epoch: 64 | Iteration number: [1520/4518] 33% | Training loss: 0.6872794241889527
Epoch: 64 | Iteration number: [1530/4518] 33% | Training loss: 0.6872762828870537
Epoch: 64 | Iteration number: [1540/4518] 34% | Training loss: 0.6872782056594824
Epoch: 64 | Iteration number: [1550/4518] 34% | Training loss: 0.6872790830366073
Epoch: 64 | Iteration number: [1560/4518] 34% | Training loss: 0.6872729373283876
Epoch: 64 | Iteration number: [1570/4518] 34% | Training loss: 0.6872694463866531
Epoch: 64 | Iteration number: [1580/4518] 34% | Training loss: 0.6872646260110638
Epoch: 64 | Iteration number: [1590/4518] 35% | Training loss: 0.6872562803187461
Epoch: 64 | Iteration number: [1600/4518] 35% | Training loss: 0.6872540700808167
Epoch: 64 | Iteration number: [1610/4518] 35% | Training loss: 0.6872596126535665
Epoch: 64 | Iteration number: [1620/4518] 35% | Training loss: 0.6872517913212011
Epoch: 64 | Iteration number: [1630/4518] 36% | Training loss: 0.6872497721318087
Epoch: 64 | Iteration number: [1640/4518] 36% | Training loss: 0.6872474941538601
Epoch: 64 | Iteration number: [1650/4518] 36% | Training loss: 0.6872412357185826
Epoch: 64 | Iteration number: [1660/4518] 36% | Training loss: 0.687232027104102
Epoch: 64 | Iteration number: [1670/4518] 36% | Training loss: 0.687231599891971
Epoch: 64 | Iteration number: [1680/4518] 37% | Training loss: 0.6872357438362781
Epoch: 64 | Iteration number: [1690/4518] 37% | Training loss: 0.6872358649440066
Epoch: 64 | Iteration number: [1700/4518] 37% | Training loss: 0.6872296215856777
Epoch: 64 | Iteration number: [1710/4518] 37% | Training loss: 0.6872276886513359
Epoch: 64 | Iteration number: [1720/4518] 38% | Training loss: 0.6872289516898089
Epoch: 64 | Iteration number: [1730/4518] 38% | Training loss: 0.6872343338638371
Epoch: 64 | Iteration number: [1740/4518] 38% | Training loss: 0.6872295611891254
Epoch: 64 | Iteration number: [1750/4518] 38% | Training loss: 0.6872290785993849
Epoch: 64 | Iteration number: [1760/4518] 38% | Training loss: 0.6872189317237247
Epoch: 64 | Iteration number: [1770/4518] 39% | Training loss: 0.6872081852902127
Epoch: 64 | Iteration number: [1780/4518] 39% | Training loss: 0.6872080641850996
Epoch: 64 | Iteration number: [1790/4518] 39% | Training loss: 0.6871996886903348
Epoch: 64 | Iteration number: [1800/4518] 39% | Training loss: 0.6871932803591092
Epoch: 64 | Iteration number: [1810/4518] 40% | Training loss: 0.6871849171035198
Epoch: 64 | Iteration number: [1820/4518] 40% | Training loss: 0.6871846326759883
Epoch: 64 | Iteration number: [1830/4518] 40% | Training loss: 0.687180751887827
Epoch: 64 | Iteration number: [1840/4518] 40% | Training loss: 0.6871767230007959
Epoch: 64 | Iteration number: [1850/4518] 40% | Training loss: 0.6871660208057713
Epoch: 64 | Iteration number: [1860/4518] 41% | Training loss: 0.68716684374758
Epoch: 64 | Iteration number: [1870/4518] 41% | Training loss: 0.6871632473991517
Epoch: 64 | Iteration number: [1880/4518] 41% | Training loss: 0.6871586366853816
Epoch: 64 | Iteration number: [1890/4518] 41% | Training loss: 0.6871549935567947
Epoch: 64 | Iteration number: [1900/4518] 42% | Training loss: 0.6871472539086091
Epoch: 64 | Iteration number: [1910/4518] 42% | Training loss: 0.687141589344484
Epoch: 64 | Iteration number: [1920/4518] 42% | Training loss: 0.6871387690926591
Epoch: 64 | Iteration number: [1930/4518] 42% | Training loss: 0.6871409246340935
Epoch: 64 | Iteration number: [1940/4518] 42% | Training loss: 0.6871434046128362
Epoch: 64 | Iteration number: [1950/4518] 43% | Training loss: 0.6871338880979098
Epoch: 64 | Iteration number: [1960/4518] 43% | Training loss: 0.6871382485847084
Epoch: 64 | Iteration number: [1970/4518] 43% | Training loss: 0.6871349326547632
Epoch: 64 | Iteration number: [1980/4518] 43% | Training loss: 0.687126374335
Epoch: 64 | Iteration number: [1990/4518] 44% | Training loss: 0.6871299150601105
Epoch: 64 | Iteration number: [2000/4518] 44% | Training loss: 0.6871280492842198
Epoch: 64 | Iteration number: [2010/4518] 44% | Training loss: 0.6871323909925584
Epoch: 64 | Iteration number: [2020/4518] 44% | Training loss: 0.687135884195271
Epoch: 64 | Iteration number: [2030/4518] 44% | Training loss: 0.6871370654681633
Epoch: 64 | Iteration number: [2040/4518] 45% | Training loss: 0.6871349311926785
Epoch: 64 | Iteration number: [2050/4518] 45% | Training loss: 0.6871266372029374
Epoch: 64 | Iteration number: [2060/4518] 45% | Training loss: 0.6871210888172816
Epoch: 64 | Iteration number: [2070/4518] 45% | Training loss: 0.6871250922553205
Epoch: 64 | Iteration number: [2080/4518] 46% | Training loss: 0.6871207910088393
Epoch: 64 | Iteration number: [2090/4518] 46% | Training loss: 0.6871205884018583
Epoch: 64 | Iteration number: [2100/4518] 46% | Training loss: 0.687113871432486
Epoch: 64 | Iteration number: [2110/4518] 46% | Training loss: 0.6871090810163326
Epoch: 64 | Iteration number: [2120/4518] 46% | Training loss: 0.6871076404204909
Epoch: 64 | Iteration number: [2130/4518] 47% | Training loss: 0.6871076439747787
Epoch: 64 | Iteration number: [2140/4518] 47% | Training loss: 0.6871083060714686
Epoch: 64 | Iteration number: [2150/4518] 47% | Training loss: 0.6871082740883494
Epoch: 64 | Iteration number: [2160/4518] 47% | Training loss: 0.6871000278879095
Epoch: 64 | Iteration number: [2170/4518] 48% | Training loss: 0.6871012389934558
Epoch: 64 | Iteration number: [2180/4518] 48% | Training loss: 0.6870996208092488
Epoch: 64 | Iteration number: [2190/4518] 48% | Training loss: 0.687094189396732
Epoch: 64 | Iteration number: [2200/4518] 48% | Training loss: 0.6870996000279079
Epoch: 64 | Iteration number: [2210/4518] 48% | Training loss: 0.6870925403558291
Epoch: 64 | Iteration number: [2220/4518] 49% | Training loss: 0.6870867908806414
Epoch: 64 | Iteration number: [2230/4518] 49% | Training loss: 0.6870817424470533
Epoch: 64 | Iteration number: [2240/4518] 49% | Training loss: 0.6870885548048786
Epoch: 64 | Iteration number: [2250/4518] 49% | Training loss: 0.6870887188646528
Epoch: 64 | Iteration number: [2260/4518] 50% | Training loss: 0.6870892273377528
Epoch: 64 | Iteration number: [2270/4518] 50% | Training loss: 0.6870846349499824
Epoch: 64 | Iteration number: [2280/4518] 50% | Training loss: 0.6870844380635964
Epoch: 64 | Iteration number: [2290/4518] 50% | Training loss: 0.6870846110660437
Epoch: 64 | Iteration number: [2300/4518] 50% | Training loss: 0.6870800442540127
Epoch: 64 | Iteration number: [2310/4518] 51% | Training loss: 0.6870803676642381
Epoch: 64 | Iteration number: [2320/4518] 51% | Training loss: 0.6870741103743685
Epoch: 64 | Iteration number: [2330/4518] 51% | Training loss: 0.6870776824429311
Epoch: 64 | Iteration number: [2340/4518] 51% | Training loss: 0.6870735523537693
Epoch: 64 | Iteration number: [2350/4518] 52% | Training loss: 0.6870705188588894
Epoch: 64 | Iteration number: [2360/4518] 52% | Training loss: 0.6870680806495375
Epoch: 64 | Iteration number: [2370/4518] 52% | Training loss: 0.6870591517239181
Epoch: 64 | Iteration number: [2380/4518] 52% | Training loss: 0.6870564273175072
Epoch: 64 | Iteration number: [2390/4518] 52% | Training loss: 0.6870576299134658
Epoch: 64 | Iteration number: [2400/4518] 53% | Training loss: 0.6870545094460249
Epoch: 64 | Iteration number: [2410/4518] 53% | Training loss: 0.6870604867509786
Epoch: 64 | Iteration number: [2420/4518] 53% | Training loss: 0.6870581417783233
Epoch: 64 | Iteration number: [2430/4518] 53% | Training loss: 0.6870604261204049
Epoch: 64 | Iteration number: [2440/4518] 54% | Training loss: 0.6870613746955746
Epoch: 64 | Iteration number: [2450/4518] 54% | Training loss: 0.6870561543046212
Epoch: 64 | Iteration number: [2460/4518] 54% | Training loss: 0.6870518687537046
Epoch: 64 | Iteration number: [2470/4518] 54% | Training loss: 0.6870517818068685
Epoch: 64 | Iteration number: [2480/4518] 54% | Training loss: 0.6870537703796741
Epoch: 64 | Iteration number: [2490/4518] 55% | Training loss: 0.6870545742262798
Epoch: 64 | Iteration number: [2500/4518] 55% | Training loss: 0.6870549669981003
Epoch: 64 | Iteration number: [2510/4518] 55% | Training loss: 0.6870521775992268
Epoch: 64 | Iteration number: [2520/4518] 55% | Training loss: 0.6870461751071234
Epoch: 64 | Iteration number: [2530/4518] 55% | Training loss: 0.687045905712565
Epoch: 64 | Iteration number: [2540/4518] 56% | Training loss: 0.6870447105310095
Epoch: 64 | Iteration number: [2550/4518] 56% | Training loss: 0.6870419177822038
Epoch: 64 | Iteration number: [2560/4518] 56% | Training loss: 0.6870462726801634
Epoch: 64 | Iteration number: [2570/4518] 56% | Training loss: 0.6870483040345782
Epoch: 64 | Iteration number: [2580/4518] 57% | Training loss: 0.6870426396759906
Epoch: 64 | Iteration number: [2590/4518] 57% | Training loss: 0.6870459743448206
Epoch: 64 | Iteration number: [2600/4518] 57% | Training loss: 0.6870419078377576
Epoch: 64 | Iteration number: [2610/4518] 57% | Training loss: 0.6870444768004947
Epoch: 64 | Iteration number: [2620/4518] 57% | Training loss: 0.6870444939564203
Epoch: 64 | Iteration number: [2630/4518] 58% | Training loss: 0.6870413619982426
Epoch: 64 | Iteration number: [2640/4518] 58% | Training loss: 0.6870432868599892
Epoch: 64 | Iteration number: [2650/4518] 58% | Training loss: 0.687044274717007
Epoch: 64 | Iteration number: [2660/4518] 58% | Training loss: 0.687045173380608
Epoch: 64 | Iteration number: [2670/4518] 59% | Training loss: 0.6870439717608892
Epoch: 64 | Iteration number: [2680/4518] 59% | Training loss: 0.68704096545924
Epoch: 64 | Iteration number: [2690/4518] 59% | Training loss: 0.6870402027018452
Epoch: 64 | Iteration number: [2700/4518] 59% | Training loss: 0.6870436276550647
Epoch: 64 | Iteration number: [2710/4518] 59% | Training loss: 0.6870418338538096
Epoch: 64 | Iteration number: [2720/4518] 60% | Training loss: 0.6870427930618034
Epoch: 64 | Iteration number: [2730/4518] 60% | Training loss: 0.6870443883832994
Epoch: 64 | Iteration number: [2740/4518] 60% | Training loss: 0.6870458797599277
Epoch: 64 | Iteration number: [2750/4518] 60% | Training loss: 0.6870463579351251
Epoch: 64 | Iteration number: [2760/4518] 61% | Training loss: 0.6870472915362621
Epoch: 64 | Iteration number: [2770/4518] 61% | Training loss: 0.6870469257504501
Epoch: 64 | Iteration number: [2780/4518] 61% | Training loss: 0.6870455681848869
Epoch: 64 | Iteration number: [2790/4518] 61% | Training loss: 0.6870400061530452
Epoch: 64 | Iteration number: [2800/4518] 61% | Training loss: 0.6870393113153321
Epoch: 64 | Iteration number: [2810/4518] 62% | Training loss: 0.6870392830982751
Epoch: 64 | Iteration number: [2820/4518] 62% | Training loss: 0.6870363605149249
Epoch: 64 | Iteration number: [2830/4518] 62% | Training loss: 0.6870367827137451
Epoch: 64 | Iteration number: [2840/4518] 62% | Training loss: 0.6870295338437591
Epoch: 64 | Iteration number: [2850/4518] 63% | Training loss: 0.6870264973138508
Epoch: 64 | Iteration number: [2860/4518] 63% | Training loss: 0.6870294733480974
Epoch: 64 | Iteration number: [2870/4518] 63% | Training loss: 0.687025361007099
Epoch: 64 | Iteration number: [2880/4518] 63% | Training loss: 0.6870279770137535
Epoch: 64 | Iteration number: [2890/4518] 63% | Training loss: 0.6870286365900072
Epoch: 64 | Iteration number: [2900/4518] 64% | Training loss: 0.6870261072290355
Epoch: 64 | Iteration number: [2910/4518] 64% | Training loss: 0.6870249666913678
Epoch: 64 | Iteration number: [2920/4518] 64% | Training loss: 0.687026407947279
Epoch: 64 | Iteration number: [2930/4518] 64% | Training loss: 0.6870218445213174
Epoch: 64 | Iteration number: [2940/4518] 65% | Training loss: 0.6870208392337877
Epoch: 64 | Iteration number: [2950/4518] 65% | Training loss: 0.687015274419623
Epoch: 64 | Iteration number: [2960/4518] 65% | Training loss: 0.6870148259240227
Epoch: 64 | Iteration number: [2970/4518] 65% | Training loss: 0.6870137913259191
Epoch: 64 | Iteration number: [2980/4518] 65% | Training loss: 0.6870161098721843
Epoch: 64 | Iteration number: [2990/4518] 66% | Training loss: 0.6870136041106987
Epoch: 64 | Iteration number: [3000/4518] 66% | Training loss: 0.687010053773721
Epoch: 64 | Iteration number: [3010/4518] 66% | Training loss: 0.6870115498767738
Epoch: 64 | Iteration number: [3020/4518] 66% | Training loss: 0.6870153175481898
Epoch: 64 | Iteration number: [3030/4518] 67% | Training loss: 0.6870183835328609
Epoch: 64 | Iteration number: [3040/4518] 67% | Training loss: 0.6870135552004764
Epoch: 64 | Iteration number: [3050/4518] 67% | Training loss: 0.6870146896409207
Epoch: 64 | Iteration number: [3060/4518] 67% | Training loss: 0.6870162570982977
Epoch: 64 | Iteration number: [3070/4518] 67% | Training loss: 0.6870151182921779
Epoch: 64 | Iteration number: [3080/4518] 68% | Training loss: 0.6870124007393787
Epoch: 64 | Iteration number: [3090/4518] 68% | Training loss: 0.6870083222883033
Epoch: 64 | Iteration number: [3100/4518] 68% | Training loss: 0.687008851997314
Epoch: 64 | Iteration number: [3110/4518] 68% | Training loss: 0.687008538813453
Epoch: 64 | Iteration number: [3120/4518] 69% | Training loss: 0.6870088164431927
Epoch: 64 | Iteration number: [3130/4518] 69% | Training loss: 0.6870084789995188
Epoch: 64 | Iteration number: [3140/4518] 69% | Training loss: 0.6870091679939039
Epoch: 64 | Iteration number: [3150/4518] 69% | Training loss: 0.6870100336415427
Epoch: 64 | Iteration number: [3160/4518] 69% | Training loss: 0.6870123661582983
Epoch: 64 | Iteration number: [3170/4518] 70% | Training loss: 0.6870134758084354
Epoch: 64 | Iteration number: [3180/4518] 70% | Training loss: 0.6870138944507395
Epoch: 64 | Iteration number: [3190/4518] 70% | Training loss: 0.6870134224338591
Epoch: 64 | Iteration number: [3200/4518] 70% | Training loss: 0.6870138023793697
Epoch: 64 | Iteration number: [3210/4518] 71% | Training loss: 0.6870095428648024
Epoch: 64 | Iteration number: [3220/4518] 71% | Training loss: 0.6870075757273976
Epoch: 64 | Iteration number: [3230/4518] 71% | Training loss: 0.6870083863336605
Epoch: 64 | Iteration number: [3240/4518] 71% | Training loss: 0.6870107608812827
Epoch: 64 | Iteration number: [3250/4518] 71% | Training loss: 0.6870116261518918
Epoch: 64 | Iteration number: [3260/4518] 72% | Training loss: 0.6870098367424831
Epoch: 64 | Iteration number: [3270/4518] 72% | Training loss: 0.6870083441245811
Epoch: 64 | Iteration number: [3280/4518] 72% | Training loss: 0.6870061871482105
Epoch: 64 | Iteration number: [3290/4518] 72% | Training loss: 0.687006528453624
Epoch: 64 | Iteration number: [3300/4518] 73% | Training loss: 0.6870065954237273
Epoch: 64 | Iteration number: [3310/4518] 73% | Training loss: 0.6870052743534307
Epoch: 64 | Iteration number: [3320/4518] 73% | Training loss: 0.6869999197592218
Epoch: 64 | Iteration number: [3330/4518] 73% | Training loss: 0.6869980733494859
Epoch: 64 | Iteration number: [3340/4518] 73% | Training loss: 0.686998855621515
Epoch: 64 | Iteration number: [3350/4518] 74% | Training loss: 0.6869968315202798
Epoch: 64 | Iteration number: [3360/4518] 74% | Training loss: 0.6869954805288996
Epoch: 64 | Iteration number: [3370/4518] 74% | Training loss: 0.686995361219174
Epoch: 64 | Iteration number: [3380/4518] 74% | Training loss: 0.6869950144777637
Epoch: 64 | Iteration number: [3390/4518] 75% | Training loss: 0.6869880573939433
Epoch: 64 | Iteration number: [3400/4518] 75% | Training loss: 0.6869908713593202
Epoch: 64 | Iteration number: [3410/4518] 75% | Training loss: 0.6869923866739022
Epoch: 64 | Iteration number: [3420/4518] 75% | Training loss: 0.6869957971816871
Epoch: 64 | Iteration number: [3430/4518] 75% | Training loss: 0.6869945354781415
Epoch: 64 | Iteration number: [3440/4518] 76% | Training loss: 0.6869936040147793
Epoch: 64 | Iteration number: [3450/4518] 76% | Training loss: 0.686989561803099
Epoch: 64 | Iteration number: [3460/4518] 76% | Training loss: 0.6869900648132224
Epoch: 64 | Iteration number: [3470/4518] 76% | Training loss: 0.6869909777421429
Epoch: 64 | Iteration number: [3480/4518] 77% | Training loss: 0.6869908753140219
Epoch: 64 | Iteration number: [3490/4518] 77% | Training loss: 0.6869852451335393
Epoch: 64 | Iteration number: [3500/4518] 77% | Training loss: 0.6869831424951554
Epoch: 64 | Iteration number: [3510/4518] 77% | Training loss: 0.6869812578047783
Epoch: 64 | Iteration number: [3520/4518] 77% | Training loss: 0.6869851922108369
Epoch: 64 | Iteration number: [3530/4518] 78% | Training loss: 0.6869841825691904
Epoch: 64 | Iteration number: [3540/4518] 78% | Training loss: 0.686981278758938
Epoch: 64 | Iteration number: [3550/4518] 78% | Training loss: 0.6869784365741299
Epoch: 64 | Iteration number: [3560/4518] 78% | Training loss: 0.6869781293728379
Epoch: 64 | Iteration number: [3570/4518] 79% | Training loss: 0.6869746493525198
Epoch: 64 | Iteration number: [3580/4518] 79% | Training loss: 0.6869744563235917
Epoch: 64 | Iteration number: [3590/4518] 79% | Training loss: 0.6869721331304163
Epoch: 64 | Iteration number: [3600/4518] 79% | Training loss: 0.6869689856800768
Epoch: 64 | Iteration number: [3610/4518] 79% | Training loss: 0.686970427888252
Epoch: 64 | Iteration number: [3620/4518] 80% | Training loss: 0.6869700056083953
Epoch: 64 | Iteration number: [3630/4518] 80% | Training loss: 0.6869692999961947
Epoch: 64 | Iteration number: [3640/4518] 80% | Training loss: 0.686969311617233
Epoch: 64 | Iteration number: [3650/4518] 80% | Training loss: 0.6869713364725244
Epoch: 64 | Iteration number: [3660/4518] 81% | Training loss: 0.6869723263334055
Epoch: 64 | Iteration number: [3670/4518] 81% | Training loss: 0.6869728480275386
Epoch: 64 | Iteration number: [3680/4518] 81% | Training loss: 0.6869751008308452
Epoch: 64 | Iteration number: [3690/4518] 81% | Training loss: 0.6869774516520462
Epoch: 64 | Iteration number: [3700/4518] 81% | Training loss: 0.6869785285640407
Epoch: 64 | Iteration number: [3710/4518] 82% | Training loss: 0.6869781128961764
Epoch: 64 | Iteration number: [3720/4518] 82% | Training loss: 0.6869828316953874
Epoch: 64 | Iteration number: [3730/4518] 82% | Training loss: 0.6869835768883733
Epoch: 64 | Iteration number: [3740/4518] 82% | Training loss: 0.6869832739473026
Epoch: 64 | Iteration number: [3750/4518] 83% | Training loss: 0.6869805996259054
Epoch: 64 | Iteration number: [3760/4518] 83% | Training loss: 0.686978752387965
Epoch: 64 | Iteration number: [3770/4518] 83% | Training loss: 0.6869767356298331
Epoch: 64 | Iteration number: [3780/4518] 83% | Training loss: 0.6869754297550393
Epoch: 64 | Iteration number: [3790/4518] 83% | Training loss: 0.6869752886427424
Epoch: 64 | Iteration number: [3800/4518] 84% | Training loss: 0.6869736923355805
Epoch: 64 | Iteration number: [3810/4518] 84% | Training loss: 0.6869702163017953
Epoch: 64 | Iteration number: [3820/4518] 84% | Training loss: 0.6869709889614145
Epoch: 64 | Iteration number: [3830/4518] 84% | Training loss: 0.6869700771087766
Epoch: 64 | Iteration number: [3840/4518] 84% | Training loss: 0.686970345194762
Epoch: 64 | Iteration number: [3850/4518] 85% | Training loss: 0.686969200821666
Epoch: 64 | Iteration number: [3860/4518] 85% | Training loss: 0.6869709098277315
Epoch: 64 | Iteration number: [3870/4518] 85% | Training loss: 0.6869734925047064
Epoch: 64 | Iteration number: [3880/4518] 85% | Training loss: 0.6869706847464916
Epoch: 64 | Iteration number: [3890/4518] 86% | Training loss: 0.6869715799096311
Epoch: 64 | Iteration number: [3900/4518] 86% | Training loss: 0.6869722768740776
Epoch: 64 | Iteration number: [3910/4518] 86% | Training loss: 0.6869717574332986
Epoch: 64 | Iteration number: [3920/4518] 86% | Training loss: 0.6869707335622943
Epoch: 64 | Iteration number: [3930/4518] 86% | Training loss: 0.6869690963633491
Epoch: 64 | Iteration number: [3940/4518] 87% | Training loss: 0.6869682484471858
Epoch: 64 | Iteration number: [3950/4518] 87% | Training loss: 0.6869673444953146
Epoch: 64 | Iteration number: [3960/4518] 87% | Training loss: 0.6869649016646424
Epoch: 64 | Iteration number: [3970/4518] 87% | Training loss: 0.6869621028677942
Epoch: 64 | Iteration number: [3980/4518] 88% | Training loss: 0.6869630882937704
Epoch: 64 | Iteration number: [3990/4518] 88% | Training loss: 0.6869607272602263
Epoch: 64 | Iteration number: [4000/4518] 88% | Training loss: 0.6869581125974655
Epoch: 64 | Iteration number: [4010/4518] 88% | Training loss: 0.6869584545827566
Epoch: 64 | Iteration number: [4020/4518] 88% | Training loss: 0.6869556822883549
Epoch: 64 | Iteration number: [4030/4518] 89% | Training loss: 0.686952486981825
Epoch: 64 | Iteration number: [4040/4518] 89% | Training loss: 0.6869546579104839
Epoch: 64 | Iteration number: [4050/4518] 89% | Training loss: 0.6869529858047579
Epoch: 64 | Iteration number: [4060/4518] 89% | Training loss: 0.686952692255598
Epoch: 64 | Iteration number: [4070/4518] 90% | Training loss: 0.6869510718294092
Epoch: 64 | Iteration number: [4080/4518] 90% | Training loss: 0.6869529344871932
Epoch: 64 | Iteration number: [4090/4518] 90% | Training loss: 0.6869532292075728
Epoch: 64 | Iteration number: [4100/4518] 90% | Training loss: 0.6869530017492248
Epoch: 64 | Iteration number: [4110/4518] 90% | Training loss: 0.6869531163624023
Epoch: 64 | Iteration number: [4120/4518] 91% | Training loss: 0.6869517373228536
Epoch: 64 | Iteration number: [4130/4518] 91% | Training loss: 0.6869521273539083
Epoch: 64 | Iteration number: [4140/4518] 91% | Training loss: 0.6869469624786562
Epoch: 64 | Iteration number: [4150/4518] 91% | Training loss: 0.686944852607796
Epoch: 64 | Iteration number: [4160/4518] 92% | Training loss: 0.6869468931968395
Epoch: 64 | Iteration number: [4170/4518] 92% | Training loss: 0.6869478182541094
Epoch: 64 | Iteration number: [4180/4518] 92% | Training loss: 0.6869479603601985
Epoch: 64 | Iteration number: [4190/4518] 92% | Training loss: 0.686945233353567
Epoch: 64 | Iteration number: [4200/4518] 92% | Training loss: 0.6869446112854141
Epoch: 64 | Iteration number: [4210/4518] 93% | Training loss: 0.6869475826514871
Epoch: 64 | Iteration number: [4220/4518] 93% | Training loss: 0.6869455289925445
Epoch: 64 | Iteration number: [4230/4518] 93% | Training loss: 0.6869435105763428
Epoch: 64 | Iteration number: [4240/4518] 93% | Training loss: 0.686946230255208
Epoch: 64 | Iteration number: [4250/4518] 94% | Training loss: 0.6869457455242381
Epoch: 64 | Iteration number: [4260/4518] 94% | Training loss: 0.6869446857714318
Epoch: 64 | Iteration number: [4270/4518] 94% | Training loss: 0.6869445461997942
Epoch: 64 | Iteration number: [4280/4518] 94% | Training loss: 0.686942948387048
Epoch: 64 | Iteration number: [4290/4518] 94% | Training loss: 0.6869448053253281
Epoch: 64 | Iteration number: [4300/4518] 95% | Training loss: 0.6869421652999035
Epoch: 64 | Iteration number: [4310/4518] 95% | Training loss: 0.686942944670498
Epoch: 64 | Iteration number: [4320/4518] 95% | Training loss: 0.6869441926341366
Epoch: 64 | Iteration number: [4330/4518] 95% | Training loss: 0.6869422732682481
Epoch: 64 | Iteration number: [4340/4518] 96% | Training loss: 0.6869418498557833
Epoch: 64 | Iteration number: [4350/4518] 96% | Training loss: 0.6869430367151896
Epoch: 64 | Iteration number: [4360/4518] 96% | Training loss: 0.6869436215233365
Epoch: 64 | Iteration number: [4370/4518] 96% | Training loss: 0.6869433352821752
Epoch: 64 | Iteration number: [4380/4518] 96% | Training loss: 0.6869424986104443
Epoch: 64 | Iteration number: [4390/4518] 97% | Training loss: 0.6869411025747895
Epoch: 64 | Iteration number: [4400/4518] 97% | Training loss: 0.6869391460039399
Epoch: 64 | Iteration number: [4410/4518] 97% | Training loss: 0.6869395725716269
Epoch: 64 | Iteration number: [4420/4518] 97% | Training loss: 0.6869378858427116
Epoch: 64 | Iteration number: [4430/4518] 98% | Training loss: 0.6869362742179672
Epoch: 64 | Iteration number: [4440/4518] 98% | Training loss: 0.6869382268673665
Epoch: 64 | Iteration number: [4450/4518] 98% | Training loss: 0.6869390940532256
Epoch: 64 | Iteration number: [4460/4518] 98% | Training loss: 0.6869386593055298
Epoch: 64 | Iteration number: [4470/4518] 98% | Training loss: 0.6869368636234762
Epoch: 64 | Iteration number: [4480/4518] 99% | Training loss: 0.6869368715477842
Epoch: 64 | Iteration number: [4490/4518] 99% | Training loss: 0.6869339214401415
Epoch: 64 | Iteration number: [4500/4518] 99% | Training loss: 0.6869352625608445
Epoch: 64 | Iteration number: [4510/4518] 99% | Training loss: 0.6869357880361857

 End of epoch: 64 | Train Loss: 0.6867826622954086 | Training Time: 640 

 End of epoch: 64 | Eval Loss: 0.6898559599506612 | Evaluating Time: 17 
Epoch: 65 | Iteration number: [10/4518] 0% | Training loss: 0.7559838116168975
Epoch: 65 | Iteration number: [20/4518] 0% | Training loss: 0.7211286425590515
Epoch: 65 | Iteration number: [30/4518] 0% | Training loss: 0.7092811942100525
Epoch: 65 | Iteration number: [40/4518] 0% | Training loss: 0.7030232146382331
Epoch: 65 | Iteration number: [50/4518] 1% | Training loss: 0.6998801422119141
Epoch: 65 | Iteration number: [60/4518] 1% | Training loss: 0.6976343115170797
Epoch: 65 | Iteration number: [70/4518] 1% | Training loss: 0.6960702555520194
Epoch: 65 | Iteration number: [80/4518] 1% | Training loss: 0.6948870211839676
Epoch: 65 | Iteration number: [90/4518] 1% | Training loss: 0.6938925855689578
Epoch: 65 | Iteration number: [100/4518] 2% | Training loss: 0.693192555308342
Epoch: 65 | Iteration number: [110/4518] 2% | Training loss: 0.6926341658288783
Epoch: 65 | Iteration number: [120/4518] 2% | Training loss: 0.6922262479861577
Epoch: 65 | Iteration number: [130/4518] 2% | Training loss: 0.6917472953979785
Epoch: 65 | Iteration number: [140/4518] 3% | Training loss: 0.6914560471262251
Epoch: 65 | Iteration number: [150/4518] 3% | Training loss: 0.691178103685379
Epoch: 65 | Iteration number: [160/4518] 3% | Training loss: 0.6909392479807138
Epoch: 65 | Iteration number: [170/4518] 3% | Training loss: 0.6906758150633644
Epoch: 65 | Iteration number: [180/4518] 3% | Training loss: 0.690446898010042
Epoch: 65 | Iteration number: [190/4518] 4% | Training loss: 0.6902706732875422
Epoch: 65 | Iteration number: [200/4518] 4% | Training loss: 0.6901133030652999
Epoch: 65 | Iteration number: [210/4518] 4% | Training loss: 0.6899560885769981
Epoch: 65 | Iteration number: [220/4518] 4% | Training loss: 0.6897986715490168
Epoch: 65 | Iteration number: [230/4518] 5% | Training loss: 0.6896240420963453
Epoch: 65 | Iteration number: [240/4518] 5% | Training loss: 0.6895151612659295
Epoch: 65 | Iteration number: [250/4518] 5% | Training loss: 0.6894237439632416
Epoch: 65 | Iteration number: [260/4518] 5% | Training loss: 0.6892973723319861
Epoch: 65 | Iteration number: [270/4518] 5% | Training loss: 0.689164752430386
Epoch: 65 | Iteration number: [280/4518] 6% | Training loss: 0.689049743115902
Epoch: 65 | Iteration number: [290/4518] 6% | Training loss: 0.6889709435660264
Epoch: 65 | Iteration number: [300/4518] 6% | Training loss: 0.6888635305563608
Epoch: 65 | Iteration number: [310/4518] 6% | Training loss: 0.6888288538302144
Epoch: 65 | Iteration number: [320/4518] 7% | Training loss: 0.688767921924591
Epoch: 65 | Iteration number: [330/4518] 7% | Training loss: 0.6887045116135568
Epoch: 65 | Iteration number: [340/4518] 7% | Training loss: 0.6886475345667671
Epoch: 65 | Iteration number: [350/4518] 7% | Training loss: 0.6886003974505833
Epoch: 65 | Iteration number: [360/4518] 7% | Training loss: 0.6885065191321903
Epoch: 65 | Iteration number: [370/4518] 8% | Training loss: 0.6884727792159931
Epoch: 65 | Iteration number: [380/4518] 8% | Training loss: 0.6883998613608511
Epoch: 65 | Iteration number: [390/4518] 8% | Training loss: 0.688389079234539
Epoch: 65 | Iteration number: [400/4518] 8% | Training loss: 0.6883589346706868
Epoch: 65 | Iteration number: [410/4518] 9% | Training loss: 0.6883052540988457
Epoch: 65 | Iteration number: [420/4518] 9% | Training loss: 0.6882600015118009
Epoch: 65 | Iteration number: [430/4518] 9% | Training loss: 0.6882053122964016
Epoch: 65 | Iteration number: [440/4518] 9% | Training loss: 0.6881568129767072
Epoch: 65 | Iteration number: [450/4518] 9% | Training loss: 0.6881081207593283
Epoch: 65 | Iteration number: [460/4518] 10% | Training loss: 0.6880305882381357
Epoch: 65 | Iteration number: [470/4518] 10% | Training loss: 0.6880191882874104
Epoch: 65 | Iteration number: [480/4518] 10% | Training loss: 0.6880111993600925
Epoch: 65 | Iteration number: [490/4518] 10% | Training loss: 0.6879705446107047
Epoch: 65 | Iteration number: [500/4518] 11% | Training loss: 0.6879574090242386
Epoch: 65 | Iteration number: [510/4518] 11% | Training loss: 0.6879420061906178
Epoch: 65 | Iteration number: [520/4518] 11% | Training loss: 0.6879341572523117
Epoch: 65 | Iteration number: [530/4518] 11% | Training loss: 0.6879274693300139
Epoch: 65 | Iteration number: [540/4518] 11% | Training loss: 0.6878947947864179
Epoch: 65 | Iteration number: [550/4518] 12% | Training loss: 0.6878763074224645
Epoch: 65 | Iteration number: [560/4518] 12% | Training loss: 0.6878765079591955
Epoch: 65 | Iteration number: [570/4518] 12% | Training loss: 0.6878834686781231
Epoch: 65 | Iteration number: [580/4518] 12% | Training loss: 0.6878590987674121
Epoch: 65 | Iteration number: [590/4518] 13% | Training loss: 0.6878574486506187
Epoch: 65 | Iteration number: [600/4518] 13% | Training loss: 0.6878516197204589
Epoch: 65 | Iteration number: [610/4518] 13% | Training loss: 0.687817599929747
Epoch: 65 | Iteration number: [620/4518] 13% | Training loss: 0.6878066712810147
Epoch: 65 | Iteration number: [630/4518] 13% | Training loss: 0.6877842583353557
Epoch: 65 | Iteration number: [640/4518] 14% | Training loss: 0.687751357909292
Epoch: 65 | Iteration number: [650/4518] 14% | Training loss: 0.6877434538877928
Epoch: 65 | Iteration number: [660/4518] 14% | Training loss: 0.6877232976935127
Epoch: 65 | Iteration number: [670/4518] 14% | Training loss: 0.687712597402174
Epoch: 65 | Iteration number: [680/4518] 15% | Training loss: 0.6876898816403221
Epoch: 65 | Iteration number: [690/4518] 15% | Training loss: 0.687667049791502
Epoch: 65 | Iteration number: [700/4518] 15% | Training loss: 0.6876345832007272
Epoch: 65 | Iteration number: [710/4518] 15% | Training loss: 0.6876364535848859
Epoch: 65 | Iteration number: [720/4518] 15% | Training loss: 0.6876366786658764
Epoch: 65 | Iteration number: [730/4518] 16% | Training loss: 0.6876305500938468
Epoch: 65 | Iteration number: [740/4518] 16% | Training loss: 0.6876272572053446
Epoch: 65 | Iteration number: [750/4518] 16% | Training loss: 0.6876132542292277
Epoch: 65 | Iteration number: [760/4518] 16% | Training loss: 0.6875842093637116
Epoch: 65 | Iteration number: [770/4518] 17% | Training loss: 0.6875769867525472
Epoch: 65 | Iteration number: [780/4518] 17% | Training loss: 0.6875621886589588
Epoch: 65 | Iteration number: [790/4518] 17% | Training loss: 0.6875348561926733
Epoch: 65 | Iteration number: [800/4518] 17% | Training loss: 0.6875267855077982
Epoch: 65 | Iteration number: [810/4518] 17% | Training loss: 0.6875196763026862
Epoch: 65 | Iteration number: [820/4518] 18% | Training loss: 0.6874998613828566
Epoch: 65 | Iteration number: [830/4518] 18% | Training loss: 0.6874845524150205
Epoch: 65 | Iteration number: [840/4518] 18% | Training loss: 0.6874875070793288
Epoch: 65 | Iteration number: [850/4518] 18% | Training loss: 0.687481202658485
Epoch: 65 | Iteration number: [860/4518] 19% | Training loss: 0.6874699359716371
Epoch: 65 | Iteration number: [870/4518] 19% | Training loss: 0.6874495898170033
Epoch: 65 | Iteration number: [880/4518] 19% | Training loss: 0.6874456656250086
Epoch: 65 | Iteration number: [890/4518] 19% | Training loss: 0.6874473255002097
Epoch: 65 | Iteration number: [900/4518] 19% | Training loss: 0.6874430416027705
Epoch: 65 | Iteration number: [910/4518] 20% | Training loss: 0.6874331615783356
Epoch: 65 | Iteration number: [920/4518] 20% | Training loss: 0.6874186307839726
Epoch: 65 | Iteration number: [930/4518] 20% | Training loss: 0.6874280189955106
Epoch: 65 | Iteration number: [940/4518] 20% | Training loss: 0.6874267437356584
Epoch: 65 | Iteration number: [950/4518] 21% | Training loss: 0.6874281490476508
Epoch: 65 | Iteration number: [960/4518] 21% | Training loss: 0.6874228419115146
Epoch: 65 | Iteration number: [970/4518] 21% | Training loss: 0.6874208243237329
Epoch: 65 | Iteration number: [980/4518] 21% | Training loss: 0.6874089363886385
Epoch: 65 | Iteration number: [990/4518] 21% | Training loss: 0.6874021056324544
Epoch: 65 | Iteration number: [1000/4518] 22% | Training loss: 0.6873720792531968
Epoch: 65 | Iteration number: [1010/4518] 22% | Training loss: 0.6873594009050048
Epoch: 65 | Iteration number: [1020/4518] 22% | Training loss: 0.6873486831492068
Epoch: 65 | Iteration number: [1030/4518] 22% | Training loss: 0.6873380004780963
Epoch: 65 | Iteration number: [1040/4518] 23% | Training loss: 0.6873366041252247
Epoch: 65 | Iteration number: [1050/4518] 23% | Training loss: 0.6873123863765171
Epoch: 65 | Iteration number: [1060/4518] 23% | Training loss: 0.6872998849963242
Epoch: 65 | Iteration number: [1070/4518] 23% | Training loss: 0.6872858012948081
Epoch: 65 | Iteration number: [1080/4518] 23% | Training loss: 0.6872874231250198
Epoch: 65 | Iteration number: [1090/4518] 24% | Training loss: 0.6872945525230618
Epoch: 65 | Iteration number: [1100/4518] 24% | Training loss: 0.6872888265956532
Epoch: 65 | Iteration number: [1110/4518] 24% | Training loss: 0.6872813156059197
Epoch: 65 | Iteration number: [1120/4518] 24% | Training loss: 0.6872815744153091
Epoch: 65 | Iteration number: [1130/4518] 25% | Training loss: 0.6872788093786324
Epoch: 65 | Iteration number: [1140/4518] 25% | Training loss: 0.6872791974690923
Epoch: 65 | Iteration number: [1150/4518] 25% | Training loss: 0.6872627279032831
Epoch: 65 | Iteration number: [1160/4518] 25% | Training loss: 0.687250308641072
Epoch: 65 | Iteration number: [1170/4518] 25% | Training loss: 0.6872380221501375
Epoch: 65 | Iteration number: [1180/4518] 26% | Training loss: 0.6872431803557832
Epoch: 65 | Iteration number: [1190/4518] 26% | Training loss: 0.6872431892306865
Epoch: 65 | Iteration number: [1200/4518] 26% | Training loss: 0.6872430315117041
Epoch: 65 | Iteration number: [1210/4518] 26% | Training loss: 0.6872404475842626
Epoch: 65 | Iteration number: [1220/4518] 27% | Training loss: 0.6872384889203994
Epoch: 65 | Iteration number: [1230/4518] 27% | Training loss: 0.6872477426276944
Epoch: 65 | Iteration number: [1240/4518] 27% | Training loss: 0.6872484757534919
Epoch: 65 | Iteration number: [1250/4518] 27% | Training loss: 0.6872380913257599
Epoch: 65 | Iteration number: [1260/4518] 27% | Training loss: 0.6872206842615491
Epoch: 65 | Iteration number: [1270/4518] 28% | Training loss: 0.6872099603254964
Epoch: 65 | Iteration number: [1280/4518] 28% | Training loss: 0.6872085275128483
Epoch: 65 | Iteration number: [1290/4518] 28% | Training loss: 0.6872003968371901
Epoch: 65 | Iteration number: [1300/4518] 28% | Training loss: 0.6871882694042646
Epoch: 65 | Iteration number: [1310/4518] 28% | Training loss: 0.6871966589953153
Epoch: 65 | Iteration number: [1320/4518] 29% | Training loss: 0.6871898290334326
Epoch: 65 | Iteration number: [1330/4518] 29% | Training loss: 0.6871884324048695
Epoch: 65 | Iteration number: [1340/4518] 29% | Training loss: 0.6871872175540497
Epoch: 65 | Iteration number: [1350/4518] 29% | Training loss: 0.6871867976365266
Epoch: 65 | Iteration number: [1360/4518] 30% | Training loss: 0.6871872192358269
Epoch: 65 | Iteration number: [1370/4518] 30% | Training loss: 0.6871885877891178
Epoch: 65 | Iteration number: [1380/4518] 30% | Training loss: 0.6871911177600639
Epoch: 65 | Iteration number: [1390/4518] 30% | Training loss: 0.6871859855789075
Epoch: 65 | Iteration number: [1400/4518] 30% | Training loss: 0.6871798572795732
Epoch: 65 | Iteration number: [1410/4518] 31% | Training loss: 0.6871770795355452
Epoch: 65 | Iteration number: [1420/4518] 31% | Training loss: 0.6871729682868635
Epoch: 65 | Iteration number: [1430/4518] 31% | Training loss: 0.6871766162918997
Epoch: 65 | Iteration number: [1440/4518] 31% | Training loss: 0.6871759949872891
Epoch: 65 | Iteration number: [1450/4518] 32% | Training loss: 0.6871734083520955
Epoch: 65 | Iteration number: [1460/4518] 32% | Training loss: 0.687161476603926
Epoch: 65 | Iteration number: [1470/4518] 32% | Training loss: 0.6871611042493054
Epoch: 65 | Iteration number: [1480/4518] 32% | Training loss: 0.6871572969330324
Epoch: 65 | Iteration number: [1490/4518] 32% | Training loss: 0.6871615794281032
Epoch: 65 | Iteration number: [1500/4518] 33% | Training loss: 0.6871684378782908
Epoch: 65 | Iteration number: [1510/4518] 33% | Training loss: 0.6871670916775204
Epoch: 65 | Iteration number: [1520/4518] 33% | Training loss: 0.6871681419642348
Epoch: 65 | Iteration number: [1530/4518] 33% | Training loss: 0.687161637443343
Epoch: 65 | Iteration number: [1540/4518] 34% | Training loss: 0.6871550811188561
Epoch: 65 | Iteration number: [1550/4518] 34% | Training loss: 0.6871479633546644
Epoch: 65 | Iteration number: [1560/4518] 34% | Training loss: 0.6871481231007821
Epoch: 65 | Iteration number: [1570/4518] 34% | Training loss: 0.687140424160441
Epoch: 65 | Iteration number: [1580/4518] 34% | Training loss: 0.68714366758926
Epoch: 65 | Iteration number: [1590/4518] 35% | Training loss: 0.6871435986000037
Epoch: 65 | Iteration number: [1600/4518] 35% | Training loss: 0.6871393096074462
Epoch: 65 | Iteration number: [1610/4518] 35% | Training loss: 0.6871378000478566
Epoch: 65 | Iteration number: [1620/4518] 35% | Training loss: 0.6871278818374799
Epoch: 65 | Iteration number: [1630/4518] 36% | Training loss: 0.6871180157719946
Epoch: 65 | Iteration number: [1640/4518] 36% | Training loss: 0.6871134096165983
Epoch: 65 | Iteration number: [1650/4518] 36% | Training loss: 0.6871176668730649
Epoch: 65 | Iteration number: [1660/4518] 36% | Training loss: 0.6871126947991819
Epoch: 65 | Iteration number: [1670/4518] 36% | Training loss: 0.6871046942865063
Epoch: 65 | Iteration number: [1680/4518] 37% | Training loss: 0.6870977065392903
Epoch: 65 | Iteration number: [1690/4518] 37% | Training loss: 0.6870934137225857
Epoch: 65 | Iteration number: [1700/4518] 37% | Training loss: 0.6870902825804318
Epoch: 65 | Iteration number: [1710/4518] 37% | Training loss: 0.6870913866319155
Epoch: 65 | Iteration number: [1720/4518] 38% | Training loss: 0.6870826277275418
Epoch: 65 | Iteration number: [1730/4518] 38% | Training loss: 0.6870822863427201
Epoch: 65 | Iteration number: [1740/4518] 38% | Training loss: 0.6870868348184673
Epoch: 65 | Iteration number: [1750/4518] 38% | Training loss: 0.6870864241463798
Epoch: 65 | Iteration number: [1760/4518] 38% | Training loss: 0.6870817949826067
Epoch: 65 | Iteration number: [1770/4518] 39% | Training loss: 0.6870787286152273
Epoch: 65 | Iteration number: [1780/4518] 39% | Training loss: 0.6870707733242699
Epoch: 65 | Iteration number: [1790/4518] 39% | Training loss: 0.68707355007779
Epoch: 65 | Iteration number: [1800/4518] 39% | Training loss: 0.6870677511228456
Epoch: 65 | Iteration number: [1810/4518] 40% | Training loss: 0.6870582391543941
Epoch: 65 | Iteration number: [1820/4518] 40% | Training loss: 0.6870551262583051
Epoch: 65 | Iteration number: [1830/4518] 40% | Training loss: 0.6870552540802565
Epoch: 65 | Iteration number: [1840/4518] 40% | Training loss: 0.6870553221715533
Epoch: 65 | Iteration number: [1850/4518] 40% | Training loss: 0.6870575378070006
Epoch: 65 | Iteration number: [1860/4518] 41% | Training loss: 0.6870618220618976
Epoch: 65 | Iteration number: [1870/4518] 41% | Training loss: 0.6870575553593151
Epoch: 65 | Iteration number: [1880/4518] 41% | Training loss: 0.6870577514805692
Epoch: 65 | Iteration number: [1890/4518] 41% | Training loss: 0.6870594607143806
Epoch: 65 | Iteration number: [1900/4518] 42% | Training loss: 0.6870662509140215
Epoch: 65 | Iteration number: [1910/4518] 42% | Training loss: 0.687068850394943
Epoch: 65 | Iteration number: [1920/4518] 42% | Training loss: 0.6870667279077073
Epoch: 65 | Iteration number: [1930/4518] 42% | Training loss: 0.6870735919537322
Epoch: 65 | Iteration number: [1940/4518] 42% | Training loss: 0.6870768587921083
Epoch: 65 | Iteration number: [1950/4518] 43% | Training loss: 0.6870725702628111
Epoch: 65 | Iteration number: [1960/4518] 43% | Training loss: 0.6870796788711937
Epoch: 65 | Iteration number: [1970/4518] 43% | Training loss: 0.6870776180083377
Epoch: 65 | Iteration number: [1980/4518] 43% | Training loss: 0.6870776191504314
Epoch: 65 | Iteration number: [1990/4518] 44% | Training loss: 0.6870765450911306
Epoch: 65 | Iteration number: [2000/4518] 44% | Training loss: 0.6870691648125649
Epoch: 65 | Iteration number: [2010/4518] 44% | Training loss: 0.6870666798074447
Epoch: 65 | Iteration number: [2020/4518] 44% | Training loss: 0.6870537005438663
Epoch: 65 | Iteration number: [2030/4518] 44% | Training loss: 0.6870444430212669
Epoch: 65 | Iteration number: [2040/4518] 45% | Training loss: 0.6870447374149865
Epoch: 65 | Iteration number: [2050/4518] 45% | Training loss: 0.6870443902655345
Epoch: 65 | Iteration number: [2060/4518] 45% | Training loss: 0.6870454729760734
Epoch: 65 | Iteration number: [2070/4518] 45% | Training loss: 0.6870446349975567
Epoch: 65 | Iteration number: [2080/4518] 46% | Training loss: 0.6870479268523363
Epoch: 65 | Iteration number: [2090/4518] 46% | Training loss: 0.6870488684428365
Epoch: 65 | Iteration number: [2100/4518] 46% | Training loss: 0.6870531550759361
Epoch: 65 | Iteration number: [2110/4518] 46% | Training loss: 0.68705575570676
Epoch: 65 | Iteration number: [2120/4518] 46% | Training loss: 0.6870539904484209
Epoch: 65 | Iteration number: [2130/4518] 47% | Training loss: 0.6870518876073506
Epoch: 65 | Iteration number: [2140/4518] 47% | Training loss: 0.6870436440282893
Epoch: 65 | Iteration number: [2150/4518] 47% | Training loss: 0.6870437209273493
Epoch: 65 | Iteration number: [2160/4518] 47% | Training loss: 0.6870440645626298
Epoch: 65 | Iteration number: [2170/4518] 48% | Training loss: 0.6870473369475334
Epoch: 65 | Iteration number: [2180/4518] 48% | Training loss: 0.6870510100498112
Epoch: 65 | Iteration number: [2190/4518] 48% | Training loss: 0.6870578044625723
Epoch: 65 | Iteration number: [2200/4518] 48% | Training loss: 0.6870548989014192
Epoch: 65 | Iteration number: [2210/4518] 48% | Training loss: 0.6870486304231359
Epoch: 65 | Iteration number: [2220/4518] 49% | Training loss: 0.6870479414323428
Epoch: 65 | Iteration number: [2230/4518] 49% | Training loss: 0.6870458846936845
Epoch: 65 | Iteration number: [2240/4518] 49% | Training loss: 0.6870414257847837
Epoch: 65 | Iteration number: [2250/4518] 49% | Training loss: 0.6870425402323405
Epoch: 65 | Iteration number: [2260/4518] 50% | Training loss: 0.6870408639971134
Epoch: 65 | Iteration number: [2270/4518] 50% | Training loss: 0.6870412923428456
Epoch: 65 | Iteration number: [2280/4518] 50% | Training loss: 0.6870362067954582
Epoch: 65 | Iteration number: [2290/4518] 50% | Training loss: 0.6870299117794203
Epoch: 65 | Iteration number: [2300/4518] 50% | Training loss: 0.6870202985017196
Epoch: 65 | Iteration number: [2310/4518] 51% | Training loss: 0.6870196353821527
Epoch: 65 | Iteration number: [2320/4518] 51% | Training loss: 0.6870177956490681
Epoch: 65 | Iteration number: [2330/4518] 51% | Training loss: 0.6870184705748579
Epoch: 65 | Iteration number: [2340/4518] 51% | Training loss: 0.6870208355351392
Epoch: 65 | Iteration number: [2350/4518] 52% | Training loss: 0.6870258362749789
Epoch: 65 | Iteration number: [2360/4518] 52% | Training loss: 0.6870213107789978
Epoch: 65 | Iteration number: [2370/4518] 52% | Training loss: 0.6870137293127518
Epoch: 65 | Iteration number: [2380/4518] 52% | Training loss: 0.687012560252382
Epoch: 65 | Iteration number: [2390/4518] 52% | Training loss: 0.6870074867952818
Epoch: 65 | Iteration number: [2400/4518] 53% | Training loss: 0.6870030084004005
Epoch: 65 | Iteration number: [2410/4518] 53% | Training loss: 0.6870022953545899
Epoch: 65 | Iteration number: [2420/4518] 53% | Training loss: 0.6870020292760912
Epoch: 65 | Iteration number: [2430/4518] 53% | Training loss: 0.6869986928784798
Epoch: 65 | Iteration number: [2440/4518] 54% | Training loss: 0.6869992654098839
Epoch: 65 | Iteration number: [2450/4518] 54% | Training loss: 0.6869919335355564
Epoch: 65 | Iteration number: [2460/4518] 54% | Training loss: 0.6869888399432346
Epoch: 65 | Iteration number: [2470/4518] 54% | Training loss: 0.6869875133520196
Epoch: 65 | Iteration number: [2480/4518] 54% | Training loss: 0.6869792160247603
Epoch: 65 | Iteration number: [2490/4518] 55% | Training loss: 0.68697943807127
Epoch: 65 | Iteration number: [2500/4518] 55% | Training loss: 0.6869813513040542
Epoch: 65 | Iteration number: [2510/4518] 55% | Training loss: 0.6869823243513525
Epoch: 65 | Iteration number: [2520/4518] 55% | Training loss: 0.6869805467980249
Epoch: 65 | Iteration number: [2530/4518] 55% | Training loss: 0.6869843004249301
Epoch: 65 | Iteration number: [2540/4518] 56% | Training loss: 0.6869823148635429
Epoch: 65 | Iteration number: [2550/4518] 56% | Training loss: 0.686984741080041
Epoch: 65 | Iteration number: [2560/4518] 56% | Training loss: 0.6869770913617685
Epoch: 65 | Iteration number: [2570/4518] 56% | Training loss: 0.6869770970325989
Epoch: 65 | Iteration number: [2580/4518] 57% | Training loss: 0.6869806194952292
Epoch: 65 | Iteration number: [2590/4518] 57% | Training loss: 0.6869753711472146
Epoch: 65 | Iteration number: [2600/4518] 57% | Training loss: 0.6869794229360727
Epoch: 65 | Iteration number: [2610/4518] 57% | Training loss: 0.6869765400429795
Epoch: 65 | Iteration number: [2620/4518] 57% | Training loss: 0.6869737711344056
Epoch: 65 | Iteration number: [2630/4518] 58% | Training loss: 0.6869704578312631
Epoch: 65 | Iteration number: [2640/4518] 58% | Training loss: 0.6869708400332566
Epoch: 65 | Iteration number: [2650/4518] 58% | Training loss: 0.6869698190239241
Epoch: 65 | Iteration number: [2660/4518] 58% | Training loss: 0.6869700363031903
Epoch: 65 | Iteration number: [2670/4518] 59% | Training loss: 0.686969516607706
Epoch: 65 | Iteration number: [2680/4518] 59% | Training loss: 0.6869679688072916
Epoch: 65 | Iteration number: [2690/4518] 59% | Training loss: 0.6869682918915518
Epoch: 65 | Iteration number: [2700/4518] 59% | Training loss: 0.6869674925450926
Epoch: 65 | Iteration number: [2710/4518] 59% | Training loss: 0.68696864860964
Epoch: 65 | Iteration number: [2720/4518] 60% | Training loss: 0.6869720862630535
Epoch: 65 | Iteration number: [2730/4518] 60% | Training loss: 0.6869733840554625
Epoch: 65 | Iteration number: [2740/4518] 60% | Training loss: 0.6869755243732981
Epoch: 65 | Iteration number: [2750/4518] 60% | Training loss: 0.6869754187844016
Epoch: 65 | Iteration number: [2760/4518] 61% | Training loss: 0.6869755554890287
Epoch: 65 | Iteration number: [2770/4518] 61% | Training loss: 0.6869742608888054
Epoch: 65 | Iteration number: [2780/4518] 61% | Training loss: 0.6869753236822087
Epoch: 65 | Iteration number: [2790/4518] 61% | Training loss: 0.686976041396459
Epoch: 65 | Iteration number: [2800/4518] 61% | Training loss: 0.6869745309863772
Epoch: 65 | Iteration number: [2810/4518] 62% | Training loss: 0.6869738667036714
Epoch: 65 | Iteration number: [2820/4518] 62% | Training loss: 0.6869765798462198
Epoch: 65 | Iteration number: [2830/4518] 62% | Training loss: 0.6869777283061941
Epoch: 65 | Iteration number: [2840/4518] 62% | Training loss: 0.6869754761247567
Epoch: 65 | Iteration number: [2850/4518] 63% | Training loss: 0.6869736201512187
Epoch: 65 | Iteration number: [2860/4518] 63% | Training loss: 0.6869736297564073
Epoch: 65 | Iteration number: [2870/4518] 63% | Training loss: 0.6869727324110291
Epoch: 65 | Iteration number: [2880/4518] 63% | Training loss: 0.686973209410078
Epoch: 65 | Iteration number: [2890/4518] 63% | Training loss: 0.6869724521999954
Epoch: 65 | Iteration number: [2900/4518] 64% | Training loss: 0.6869733238631281
Epoch: 65 | Iteration number: [2910/4518] 64% | Training loss: 0.6869682111690953
Epoch: 65 | Iteration number: [2920/4518] 64% | Training loss: 0.6869669390255457
Epoch: 65 | Iteration number: [2930/4518] 64% | Training loss: 0.6869651355434196
Epoch: 65 | Iteration number: [2940/4518] 65% | Training loss: 0.6869686469131586
Epoch: 65 | Iteration number: [2950/4518] 65% | Training loss: 0.6869671870692302
Epoch: 65 | Iteration number: [2960/4518] 65% | Training loss: 0.6869715188403387
Epoch: 65 | Iteration number: [2970/4518] 65% | Training loss: 0.6869697923210735
Epoch: 65 | Iteration number: [2980/4518] 65% | Training loss: 0.6869715654409971
Epoch: 65 | Iteration number: [2990/4518] 66% | Training loss: 0.6869731866795084
Epoch: 65 | Iteration number: [3000/4518] 66% | Training loss: 0.6869748539129893
Epoch: 65 | Iteration number: [3010/4518] 66% | Training loss: 0.6869744387773976
Epoch: 65 | Iteration number: [3020/4518] 66% | Training loss: 0.6869703099032901
Epoch: 65 | Iteration number: [3030/4518] 67% | Training loss: 0.6869710420814678
Epoch: 65 | Iteration number: [3040/4518] 67% | Training loss: 0.6869699244240397
Epoch: 65 | Iteration number: [3050/4518] 67% | Training loss: 0.6869746564841661
Epoch: 65 | Iteration number: [3060/4518] 67% | Training loss: 0.6869726929204916
Epoch: 65 | Iteration number: [3070/4518] 67% | Training loss: 0.6869752122835538
Epoch: 65 | Iteration number: [3080/4518] 68% | Training loss: 0.6869773100529398
Epoch: 65 | Iteration number: [3090/4518] 68% | Training loss: 0.6869740882544841
Epoch: 65 | Iteration number: [3100/4518] 68% | Training loss: 0.6869739506321568
Epoch: 65 | Iteration number: [3110/4518] 68% | Training loss: 0.686975303934318
Epoch: 65 | Iteration number: [3120/4518] 69% | Training loss: 0.6869732561783913
Epoch: 65 | Iteration number: [3130/4518] 69% | Training loss: 0.6869706302786026
Epoch: 65 | Iteration number: [3140/4518] 69% | Training loss: 0.6869702351890552
Epoch: 65 | Iteration number: [3150/4518] 69% | Training loss: 0.6869690294682034
Epoch: 65 | Iteration number: [3160/4518] 69% | Training loss: 0.6869655395799046
Epoch: 65 | Iteration number: [3170/4518] 70% | Training loss: 0.6869637520343347
Epoch: 65 | Iteration number: [3180/4518] 70% | Training loss: 0.6869650523242711
Epoch: 65 | Iteration number: [3190/4518] 70% | Training loss: 0.686961630164269
Epoch: 65 | Iteration number: [3200/4518] 70% | Training loss: 0.6869621858559549
Epoch: 65 | Iteration number: [3210/4518] 71% | Training loss: 0.6869640217577557
Epoch: 65 | Iteration number: [3220/4518] 71% | Training loss: 0.6869663477314185
Epoch: 65 | Iteration number: [3230/4518] 71% | Training loss: 0.686965072247266
Epoch: 65 | Iteration number: [3240/4518] 71% | Training loss: 0.6869631234510445
Epoch: 65 | Iteration number: [3250/4518] 71% | Training loss: 0.6869626839344318
Epoch: 65 | Iteration number: [3260/4518] 72% | Training loss: 0.686964731988
Epoch: 65 | Iteration number: [3270/4518] 72% | Training loss: 0.6869658433151536
Epoch: 65 | Iteration number: [3280/4518] 72% | Training loss: 0.6869652728481991
Epoch: 65 | Iteration number: [3290/4518] 72% | Training loss: 0.6869646148478731
Epoch: 65 | Iteration number: [3300/4518] 73% | Training loss: 0.6869654814763503
Epoch: 65 | Iteration number: [3310/4518] 73% | Training loss: 0.6869642771262777
Epoch: 65 | Iteration number: [3320/4518] 73% | Training loss: 0.6869647026959672
Epoch: 65 | Iteration number: [3330/4518] 73% | Training loss: 0.6869638002670563
Epoch: 65 | Iteration number: [3340/4518] 73% | Training loss: 0.6869615394198252
Epoch: 65 | Iteration number: [3350/4518] 74% | Training loss: 0.6869606648808095
Epoch: 65 | Iteration number: [3360/4518] 74% | Training loss: 0.6869554973606552
Epoch: 65 | Iteration number: [3370/4518] 74% | Training loss: 0.6869537635620695
Epoch: 65 | Iteration number: [3380/4518] 74% | Training loss: 0.6869523642683876
Epoch: 65 | Iteration number: [3390/4518] 75% | Training loss: 0.6869523731129008
Epoch: 65 | Iteration number: [3400/4518] 75% | Training loss: 0.6869548344612122
Epoch: 65 | Iteration number: [3410/4518] 75% | Training loss: 0.6869525577315837
Epoch: 65 | Iteration number: [3420/4518] 75% | Training loss: 0.6869525333245595
Epoch: 65 | Iteration number: [3430/4518] 75% | Training loss: 0.6869508739463095
Epoch: 65 | Iteration number: [3440/4518] 76% | Training loss: 0.686950602001229
Epoch: 65 | Iteration number: [3450/4518] 76% | Training loss: 0.6869512155954388
Epoch: 65 | Iteration number: [3460/4518] 76% | Training loss: 0.6869517734285034
Epoch: 65 | Iteration number: [3470/4518] 76% | Training loss: 0.6869493173590998
Epoch: 65 | Iteration number: [3480/4518] 77% | Training loss: 0.6869502711398848
Epoch: 65 | Iteration number: [3490/4518] 77% | Training loss: 0.6869448611592837
Epoch: 65 | Iteration number: [3500/4518] 77% | Training loss: 0.6869451234510967
Epoch: 65 | Iteration number: [3510/4518] 77% | Training loss: 0.6869452878280923
Epoch: 65 | Iteration number: [3520/4518] 77% | Training loss: 0.6869419841265136
Epoch: 65 | Iteration number: [3530/4518] 78% | Training loss: 0.6869447540797863
Epoch: 65 | Iteration number: [3540/4518] 78% | Training loss: 0.6869469068649798
Epoch: 65 | Iteration number: [3550/4518] 78% | Training loss: 0.6869523735449348
Epoch: 65 | Iteration number: [3560/4518] 78% | Training loss: 0.6869526091418909
Epoch: 65 | Iteration number: [3570/4518] 79% | Training loss: 0.6869505734002891
Epoch: 65 | Iteration number: [3580/4518] 79% | Training loss: 0.6869507768966632
Epoch: 65 | Iteration number: [3590/4518] 79% | Training loss: 0.6869505771355376
Epoch: 65 | Iteration number: [3600/4518] 79% | Training loss: 0.686953379859527
Epoch: 65 | Iteration number: [3610/4518] 79% | Training loss: 0.6869534329859504
Epoch: 65 | Iteration number: [3620/4518] 80% | Training loss: 0.686952523401429
Epoch: 65 | Iteration number: [3630/4518] 80% | Training loss: 0.6869503083964682
Epoch: 65 | Iteration number: [3640/4518] 80% | Training loss: 0.6869501945081647
Epoch: 65 | Iteration number: [3650/4518] 80% | Training loss: 0.6869513408615164
Epoch: 65 | Iteration number: [3660/4518] 81% | Training loss: 0.6869532141692
Epoch: 65 | Iteration number: [3670/4518] 81% | Training loss: 0.6869498815133721
Epoch: 65 | Iteration number: [3680/4518] 81% | Training loss: 0.6869501058822093
Epoch: 65 | Iteration number: [3690/4518] 81% | Training loss: 0.6869524789050343
Epoch: 65 | Iteration number: [3700/4518] 81% | Training loss: 0.6869529311560296
Epoch: 65 | Iteration number: [3710/4518] 82% | Training loss: 0.6869551717592378
Epoch: 65 | Iteration number: [3720/4518] 82% | Training loss: 0.6869588967773222
Epoch: 65 | Iteration number: [3730/4518] 82% | Training loss: 0.6869576191294928
Epoch: 65 | Iteration number: [3740/4518] 82% | Training loss: 0.6869570734029148
Epoch: 65 | Iteration number: [3750/4518] 83% | Training loss: 0.6869581397215525
Epoch: 65 | Iteration number: [3760/4518] 83% | Training loss: 0.6869574043979036
Epoch: 65 | Iteration number: [3770/4518] 83% | Training loss: 0.6869527053295459
Epoch: 65 | Iteration number: [3780/4518] 83% | Training loss: 0.6869503408197373
Epoch: 65 | Iteration number: [3790/4518] 83% | Training loss: 0.6869511942278427
Epoch: 65 | Iteration number: [3800/4518] 84% | Training loss: 0.6869509038956542
Epoch: 65 | Iteration number: [3810/4518] 84% | Training loss: 0.68694917256125
Epoch: 65 | Iteration number: [3820/4518] 84% | Training loss: 0.6869518709120326
Epoch: 65 | Iteration number: [3830/4518] 84% | Training loss: 0.6869496123286514
Epoch: 65 | Iteration number: [3840/4518] 84% | Training loss: 0.6869516734033823
Epoch: 65 | Iteration number: [3850/4518] 85% | Training loss: 0.686947792164691
Epoch: 65 | Iteration number: [3860/4518] 85% | Training loss: 0.6869461368093837
Epoch: 65 | Iteration number: [3870/4518] 85% | Training loss: 0.6869486260013679
Epoch: 65 | Iteration number: [3880/4518] 85% | Training loss: 0.6869451231716834
Epoch: 65 | Iteration number: [3890/4518] 86% | Training loss: 0.6869456267295583
Epoch: 65 | Iteration number: [3900/4518] 86% | Training loss: 0.6869454554563914
Epoch: 65 | Iteration number: [3910/4518] 86% | Training loss: 0.6869415263690607
Epoch: 65 | Iteration number: [3920/4518] 86% | Training loss: 0.6869420655831999
Epoch: 65 | Iteration number: [3930/4518] 86% | Training loss: 0.6869405493178137
Epoch: 65 | Iteration number: [3940/4518] 87% | Training loss: 0.6869399314453154
Epoch: 65 | Iteration number: [3950/4518] 87% | Training loss: 0.6869431147545199
Epoch: 65 | Iteration number: [3960/4518] 87% | Training loss: 0.6869382075589112
Epoch: 65 | Iteration number: [3970/4518] 87% | Training loss: 0.6869366425410927
Epoch: 65 | Iteration number: [3980/4518] 88% | Training loss: 0.6869359281194869
Epoch: 65 | Iteration number: [3990/4518] 88% | Training loss: 0.6869378599307889
Epoch: 65 | Iteration number: [4000/4518] 88% | Training loss: 0.6869358204156161
Epoch: 65 | Iteration number: [4010/4518] 88% | Training loss: 0.6869361759123956
Epoch: 65 | Iteration number: [4020/4518] 88% | Training loss: 0.6869352256184194
Epoch: 65 | Iteration number: [4030/4518] 89% | Training loss: 0.686934966499693
Epoch: 65 | Iteration number: [4040/4518] 89% | Training loss: 0.6869356793637323
Epoch: 65 | Iteration number: [4050/4518] 89% | Training loss: 0.6869338287689067
Epoch: 65 | Iteration number: [4060/4518] 89% | Training loss: 0.6869354920727866
Epoch: 65 | Iteration number: [4070/4518] 90% | Training loss: 0.6869338032654521
Epoch: 65 | Iteration number: [4080/4518] 90% | Training loss: 0.686936998776361
Epoch: 65 | Iteration number: [4090/4518] 90% | Training loss: 0.6869378310252519
Epoch: 65 | Iteration number: [4100/4518] 90% | Training loss: 0.6869390500027959
Epoch: 65 | Iteration number: [4110/4518] 90% | Training loss: 0.6869431355138764
Epoch: 65 | Iteration number: [4120/4518] 91% | Training loss: 0.6869427265328111
Epoch: 65 | Iteration number: [4130/4518] 91% | Training loss: 0.6869406223008476
Epoch: 65 | Iteration number: [4140/4518] 91% | Training loss: 0.6869380219259124
Epoch: 65 | Iteration number: [4150/4518] 91% | Training loss: 0.6869401095286909
Epoch: 65 | Iteration number: [4160/4518] 92% | Training loss: 0.6869419805132426
Epoch: 65 | Iteration number: [4170/4518] 92% | Training loss: 0.6869433953607683
Epoch: 65 | Iteration number: [4180/4518] 92% | Training loss: 0.6869439779856559
Epoch: 65 | Iteration number: [4190/4518] 92% | Training loss: 0.6869446826863118
Epoch: 65 | Iteration number: [4200/4518] 92% | Training loss: 0.6869469944494111
Epoch: 65 | Iteration number: [4210/4518] 93% | Training loss: 0.6869502230381456
Epoch: 65 | Iteration number: [4220/4518] 93% | Training loss: 0.6869517757429331
Epoch: 65 | Iteration number: [4230/4518] 93% | Training loss: 0.686951800145156
Epoch: 65 | Iteration number: [4240/4518] 93% | Training loss: 0.6869531247975691
Epoch: 65 | Iteration number: [4250/4518] 94% | Training loss: 0.6869496378898621
Epoch: 65 | Iteration number: [4260/4518] 94% | Training loss: 0.686947450881273
Epoch: 65 | Iteration number: [4270/4518] 94% | Training loss: 0.6869483540432235
Epoch: 65 | Iteration number: [4280/4518] 94% | Training loss: 0.6869486003835624
Epoch: 65 | Iteration number: [4290/4518] 94% | Training loss: 0.6869470525593746
Epoch: 65 | Iteration number: [4300/4518] 95% | Training loss: 0.6869488830344621
Epoch: 65 | Iteration number: [4310/4518] 95% | Training loss: 0.686947752414336
Epoch: 65 | Iteration number: [4320/4518] 95% | Training loss: 0.6869494243076554
Epoch: 65 | Iteration number: [4330/4518] 95% | Training loss: 0.6869496469134271
Epoch: 65 | Iteration number: [4340/4518] 96% | Training loss: 0.6869471229578493
Epoch: 65 | Iteration number: [4350/4518] 96% | Training loss: 0.6869504288695324
Epoch: 65 | Iteration number: [4360/4518] 96% | Training loss: 0.6869500911837324
Epoch: 65 | Iteration number: [4370/4518] 96% | Training loss: 0.6869467186300378
Epoch: 65 | Iteration number: [4380/4518] 96% | Training loss: 0.6869492137404881
Epoch: 65 | Iteration number: [4390/4518] 97% | Training loss: 0.6869442836841853
Epoch: 65 | Iteration number: [4400/4518] 97% | Training loss: 0.6869435296139934
Epoch: 65 | Iteration number: [4410/4518] 97% | Training loss: 0.6869434486441061
Epoch: 65 | Iteration number: [4420/4518] 97% | Training loss: 0.6869420838976338
Epoch: 65 | Iteration number: [4430/4518] 98% | Training loss: 0.6869422134777224
Epoch: 65 | Iteration number: [4440/4518] 98% | Training loss: 0.6869425726232228
Epoch: 65 | Iteration number: [4450/4518] 98% | Training loss: 0.686942671698131
Epoch: 65 | Iteration number: [4460/4518] 98% | Training loss: 0.6869391633924348
Epoch: 65 | Iteration number: [4470/4518] 98% | Training loss: 0.6869395443923788
Epoch: 65 | Iteration number: [4480/4518] 99% | Training loss: 0.6869393749162555
Epoch: 65 | Iteration number: [4490/4518] 99% | Training loss: 0.6869382903809537
Epoch: 65 | Iteration number: [4500/4518] 99% | Training loss: 0.6869377627505197
Epoch: 65 | Iteration number: [4510/4518] 99% | Training loss: 0.6869359754670221

 End of epoch: 65 | Train Loss: 0.686784989739372 | Training Time: 640 

 End of epoch: 65 | Eval Loss: 0.6898594814903882 | Evaluating Time: 17 
Epoch: 66 | Iteration number: [10/4518] 0% | Training loss: 0.7549302875995636
Epoch: 66 | Iteration number: [20/4518] 0% | Training loss: 0.7205954819917679
Epoch: 66 | Iteration number: [30/4518] 0% | Training loss: 0.7091403643290202
Epoch: 66 | Iteration number: [40/4518] 0% | Training loss: 0.7032849550247192
Epoch: 66 | Iteration number: [50/4518] 1% | Training loss: 0.7002655518054962
Epoch: 66 | Iteration number: [60/4518] 1% | Training loss: 0.6980745693047842
Epoch: 66 | Iteration number: [70/4518] 1% | Training loss: 0.6964162230491638
Epoch: 66 | Iteration number: [80/4518] 1% | Training loss: 0.6951726742088795
Epoch: 66 | Iteration number: [90/4518] 1% | Training loss: 0.694269800848431
Epoch: 66 | Iteration number: [100/4518] 2% | Training loss: 0.6935780626535416
Epoch: 66 | Iteration number: [110/4518] 2% | Training loss: 0.6928652985529467
Epoch: 66 | Iteration number: [120/4518] 2% | Training loss: 0.6922797212998072
Epoch: 66 | Iteration number: [130/4518] 2% | Training loss: 0.6918878202254956
Epoch: 66 | Iteration number: [140/4518] 3% | Training loss: 0.6915164279086249
Epoch: 66 | Iteration number: [150/4518] 3% | Training loss: 0.6911592813332875
Epoch: 66 | Iteration number: [160/4518] 3% | Training loss: 0.6908294603228569
Epoch: 66 | Iteration number: [170/4518] 3% | Training loss: 0.6905871664776522
Epoch: 66 | Iteration number: [180/4518] 3% | Training loss: 0.6904307120376163
Epoch: 66 | Iteration number: [190/4518] 4% | Training loss: 0.6902423833545885
Epoch: 66 | Iteration number: [200/4518] 4% | Training loss: 0.690105463564396
Epoch: 66 | Iteration number: [210/4518] 4% | Training loss: 0.6899522534438542
Epoch: 66 | Iteration number: [220/4518] 4% | Training loss: 0.6897571712732316
Epoch: 66 | Iteration number: [230/4518] 5% | Training loss: 0.6896465433680493
Epoch: 66 | Iteration number: [240/4518] 5% | Training loss: 0.689548329760631
Epoch: 66 | Iteration number: [250/4518] 5% | Training loss: 0.6894489698410035
Epoch: 66 | Iteration number: [260/4518] 5% | Training loss: 0.6893351607597791
Epoch: 66 | Iteration number: [270/4518] 5% | Training loss: 0.689242978228463
Epoch: 66 | Iteration number: [280/4518] 6% | Training loss: 0.6891032868197986
Epoch: 66 | Iteration number: [290/4518] 6% | Training loss: 0.688976272015736
Epoch: 66 | Iteration number: [300/4518] 6% | Training loss: 0.6889046227931976
Epoch: 66 | Iteration number: [310/4518] 6% | Training loss: 0.6887939489656879
Epoch: 66 | Iteration number: [320/4518] 7% | Training loss: 0.6887405099347234
Epoch: 66 | Iteration number: [330/4518] 7% | Training loss: 0.6887371751395139
Epoch: 66 | Iteration number: [340/4518] 7% | Training loss: 0.6886803562150282
Epoch: 66 | Iteration number: [350/4518] 7% | Training loss: 0.6886469187055315
Epoch: 66 | Iteration number: [360/4518] 7% | Training loss: 0.6885915506217215
Epoch: 66 | Iteration number: [370/4518] 8% | Training loss: 0.6885402550568451
Epoch: 66 | Iteration number: [380/4518] 8% | Training loss: 0.6885377167086852
Epoch: 66 | Iteration number: [390/4518] 8% | Training loss: 0.6884611834318209
Epoch: 66 | Iteration number: [400/4518] 8% | Training loss: 0.6884154938161373
Epoch: 66 | Iteration number: [410/4518] 9% | Training loss: 0.6883948061524368
Epoch: 66 | Iteration number: [420/4518] 9% | Training loss: 0.6883508301916577
Epoch: 66 | Iteration number: [430/4518] 9% | Training loss: 0.6882819329583367
Epoch: 66 | Iteration number: [440/4518] 9% | Training loss: 0.6882409974932671
Epoch: 66 | Iteration number: [450/4518] 9% | Training loss: 0.6881968171066708
Epoch: 66 | Iteration number: [460/4518] 10% | Training loss: 0.6881600477125334
Epoch: 66 | Iteration number: [470/4518] 10% | Training loss: 0.6881156301244776
Epoch: 66 | Iteration number: [480/4518] 10% | Training loss: 0.6880767799913883
Epoch: 66 | Iteration number: [490/4518] 10% | Training loss: 0.6880125064022687
Epoch: 66 | Iteration number: [500/4518] 11% | Training loss: 0.687970467209816
Epoch: 66 | Iteration number: [510/4518] 11% | Training loss: 0.6879372219244639
Epoch: 66 | Iteration number: [520/4518] 11% | Training loss: 0.6879048629448964
Epoch: 66 | Iteration number: [530/4518] 11% | Training loss: 0.6879148341574759
Epoch: 66 | Iteration number: [540/4518] 11% | Training loss: 0.6878970944219165
Epoch: 66 | Iteration number: [550/4518] 12% | Training loss: 0.6878861497748981
Epoch: 66 | Iteration number: [560/4518] 12% | Training loss: 0.6878782253180231
Epoch: 66 | Iteration number: [570/4518] 12% | Training loss: 0.6878579346757187
Epoch: 66 | Iteration number: [580/4518] 12% | Training loss: 0.6878464221954346
Epoch: 66 | Iteration number: [590/4518] 13% | Training loss: 0.6878455669192944
Epoch: 66 | Iteration number: [600/4518] 13% | Training loss: 0.6878213563561439
Epoch: 66 | Iteration number: [610/4518] 13% | Training loss: 0.687824557746043
Epoch: 66 | Iteration number: [620/4518] 13% | Training loss: 0.6878006276584441
Epoch: 66 | Iteration number: [630/4518] 13% | Training loss: 0.6877863932223547
Epoch: 66 | Iteration number: [640/4518] 14% | Training loss: 0.68779858937487
Epoch: 66 | Iteration number: [650/4518] 14% | Training loss: 0.6877639065339015
Epoch: 66 | Iteration number: [660/4518] 14% | Training loss: 0.6877451837965937
Epoch: 66 | Iteration number: [670/4518] 14% | Training loss: 0.6877125436690317
Epoch: 66 | Iteration number: [680/4518] 15% | Training loss: 0.6877037761842504
Epoch: 66 | Iteration number: [690/4518] 15% | Training loss: 0.6876755498457646
Epoch: 66 | Iteration number: [700/4518] 15% | Training loss: 0.6876791740315301
Epoch: 66 | Iteration number: [710/4518] 15% | Training loss: 0.6876663079564
Epoch: 66 | Iteration number: [720/4518] 15% | Training loss: 0.6876481631563769
Epoch: 66 | Iteration number: [730/4518] 16% | Training loss: 0.68762844760124
Epoch: 66 | Iteration number: [740/4518] 16% | Training loss: 0.6876206225640065
Epoch: 66 | Iteration number: [750/4518] 16% | Training loss: 0.6876019988059997
Epoch: 66 | Iteration number: [760/4518] 16% | Training loss: 0.6875928894469613
Epoch: 66 | Iteration number: [770/4518] 17% | Training loss: 0.687589953472088
Epoch: 66 | Iteration number: [780/4518] 17% | Training loss: 0.6875750922239744
Epoch: 66 | Iteration number: [790/4518] 17% | Training loss: 0.6875607937951631
Epoch: 66 | Iteration number: [800/4518] 17% | Training loss: 0.6875536207854748
Epoch: 66 | Iteration number: [810/4518] 17% | Training loss: 0.6875500963058001
Epoch: 66 | Iteration number: [820/4518] 18% | Training loss: 0.6875215733923563
Epoch: 66 | Iteration number: [830/4518] 18% | Training loss: 0.6875186402395547
Epoch: 66 | Iteration number: [840/4518] 18% | Training loss: 0.687508087569759
Epoch: 66 | Iteration number: [850/4518] 18% | Training loss: 0.6875086201639736
Epoch: 66 | Iteration number: [860/4518] 19% | Training loss: 0.6874844129002371
Epoch: 66 | Iteration number: [870/4518] 19% | Training loss: 0.6874699655620531
Epoch: 66 | Iteration number: [880/4518] 19% | Training loss: 0.6874758022752675
Epoch: 66 | Iteration number: [890/4518] 19% | Training loss: 0.6874701329161612
Epoch: 66 | Iteration number: [900/4518] 19% | Training loss: 0.6874680443604787
Epoch: 66 | Iteration number: [910/4518] 20% | Training loss: 0.6874517089062995
Epoch: 66 | Iteration number: [920/4518] 20% | Training loss: 0.6874441414423611
Epoch: 66 | Iteration number: [930/4518] 20% | Training loss: 0.6874354920079632
Epoch: 66 | Iteration number: [940/4518] 20% | Training loss: 0.6874360977335179
Epoch: 66 | Iteration number: [950/4518] 21% | Training loss: 0.6874242483314715
Epoch: 66 | Iteration number: [960/4518] 21% | Training loss: 0.6874067220836878
Epoch: 66 | Iteration number: [970/4518] 21% | Training loss: 0.6874001911006022
Epoch: 66 | Iteration number: [980/4518] 21% | Training loss: 0.6873986506340455
Epoch: 66 | Iteration number: [990/4518] 21% | Training loss: 0.6873962902059458
Epoch: 66 | Iteration number: [1000/4518] 22% | Training loss: 0.687403143286705
Epoch: 66 | Iteration number: [1010/4518] 22% | Training loss: 0.6873975066855402
Epoch: 66 | Iteration number: [1020/4518] 22% | Training loss: 0.6873935633430294
Epoch: 66 | Iteration number: [1030/4518] 22% | Training loss: 0.6873719019797242
Epoch: 66 | Iteration number: [1040/4518] 23% | Training loss: 0.687374845204445
Epoch: 66 | Iteration number: [1050/4518] 23% | Training loss: 0.687371552671705
Epoch: 66 | Iteration number: [1060/4518] 23% | Training loss: 0.6873715698156717
Epoch: 66 | Iteration number: [1070/4518] 23% | Training loss: 0.6873559332896616
Epoch: 66 | Iteration number: [1080/4518] 23% | Training loss: 0.6873541758568199
Epoch: 66 | Iteration number: [1090/4518] 24% | Training loss: 0.6873381342909751
Epoch: 66 | Iteration number: [1100/4518] 24% | Training loss: 0.6873362280022014
Epoch: 66 | Iteration number: [1110/4518] 24% | Training loss: 0.6873365514987224
Epoch: 66 | Iteration number: [1120/4518] 24% | Training loss: 0.6873363112764699
Epoch: 66 | Iteration number: [1130/4518] 25% | Training loss: 0.6873320659704968
Epoch: 66 | Iteration number: [1140/4518] 25% | Training loss: 0.6873363038426952
Epoch: 66 | Iteration number: [1150/4518] 25% | Training loss: 0.6873412977094235
Epoch: 66 | Iteration number: [1160/4518] 25% | Training loss: 0.6873403910419037
Epoch: 66 | Iteration number: [1170/4518] 25% | Training loss: 0.6873270336379352
Epoch: 66 | Iteration number: [1180/4518] 26% | Training loss: 0.6873176493382049
Epoch: 66 | Iteration number: [1190/4518] 26% | Training loss: 0.6873080636272911
Epoch: 66 | Iteration number: [1200/4518] 26% | Training loss: 0.6873022630314032
Epoch: 66 | Iteration number: [1210/4518] 26% | Training loss: 0.6872874065371585
Epoch: 66 | Iteration number: [1220/4518] 27% | Training loss: 0.6872981800407659
Epoch: 66 | Iteration number: [1230/4518] 27% | Training loss: 0.687287541569733
Epoch: 66 | Iteration number: [1240/4518] 27% | Training loss: 0.6872836000496342
Epoch: 66 | Iteration number: [1250/4518] 27% | Training loss: 0.687271119594574
Epoch: 66 | Iteration number: [1260/4518] 27% | Training loss: 0.6872610394916837
Epoch: 66 | Iteration number: [1270/4518] 28% | Training loss: 0.6872593764714369
Epoch: 66 | Iteration number: [1280/4518] 28% | Training loss: 0.6872617390472442
Epoch: 66 | Iteration number: [1290/4518] 28% | Training loss: 0.6872581713883452
Epoch: 66 | Iteration number: [1300/4518] 28% | Training loss: 0.6872566732993493
Epoch: 66 | Iteration number: [1310/4518] 28% | Training loss: 0.6872507854727389
Epoch: 66 | Iteration number: [1320/4518] 29% | Training loss: 0.6872529213175629
Epoch: 66 | Iteration number: [1330/4518] 29% | Training loss: 0.6872476959587039
Epoch: 66 | Iteration number: [1340/4518] 29% | Training loss: 0.6872463356203108
Epoch: 66 | Iteration number: [1350/4518] 29% | Training loss: 0.6872448211246066
Epoch: 66 | Iteration number: [1360/4518] 30% | Training loss: 0.6872540407321033
Epoch: 66 | Iteration number: [1370/4518] 30% | Training loss: 0.6872549321094569
Epoch: 66 | Iteration number: [1380/4518] 30% | Training loss: 0.6872525025105131
Epoch: 66 | Iteration number: [1390/4518] 30% | Training loss: 0.6872552590833293
Epoch: 66 | Iteration number: [1400/4518] 30% | Training loss: 0.687257978618145
Epoch: 66 | Iteration number: [1410/4518] 31% | Training loss: 0.6872557047833787
Epoch: 66 | Iteration number: [1420/4518] 31% | Training loss: 0.6872649113896867
Epoch: 66 | Iteration number: [1430/4518] 31% | Training loss: 0.6872637926281749
Epoch: 66 | Iteration number: [1440/4518] 31% | Training loss: 0.6872551853872008
Epoch: 66 | Iteration number: [1450/4518] 32% | Training loss: 0.6872389586218473
Epoch: 66 | Iteration number: [1460/4518] 32% | Training loss: 0.6872341397282196
Epoch: 66 | Iteration number: [1470/4518] 32% | Training loss: 0.6872367864563351
Epoch: 66 | Iteration number: [1480/4518] 32% | Training loss: 0.6872406392081364
Epoch: 66 | Iteration number: [1490/4518] 32% | Training loss: 0.6872405449416014
Epoch: 66 | Iteration number: [1500/4518] 33% | Training loss: 0.6872345488866171
Epoch: 66 | Iteration number: [1510/4518] 33% | Training loss: 0.6872358675429363
Epoch: 66 | Iteration number: [1520/4518] 33% | Training loss: 0.6872371903767711
Epoch: 66 | Iteration number: [1530/4518] 33% | Training loss: 0.6872396607804142
Epoch: 66 | Iteration number: [1540/4518] 34% | Training loss: 0.6872413380192471
Epoch: 66 | Iteration number: [1550/4518] 34% | Training loss: 0.687231375978839
Epoch: 66 | Iteration number: [1560/4518] 34% | Training loss: 0.6872338822254768
Epoch: 66 | Iteration number: [1570/4518] 34% | Training loss: 0.6872319942826678
Epoch: 66 | Iteration number: [1580/4518] 34% | Training loss: 0.6872341570974906
Epoch: 66 | Iteration number: [1590/4518] 35% | Training loss: 0.6872309689251882
Epoch: 66 | Iteration number: [1600/4518] 35% | Training loss: 0.6872152022644877
Epoch: 66 | Iteration number: [1610/4518] 35% | Training loss: 0.6872123481694216
Epoch: 66 | Iteration number: [1620/4518] 35% | Training loss: 0.6872196238349986
Epoch: 66 | Iteration number: [1630/4518] 36% | Training loss: 0.6872279336116065
Epoch: 66 | Iteration number: [1640/4518] 36% | Training loss: 0.6872317324324352
Epoch: 66 | Iteration number: [1650/4518] 36% | Training loss: 0.687230532133218
Epoch: 66 | Iteration number: [1660/4518] 36% | Training loss: 0.6872304464679166
Epoch: 66 | Iteration number: [1670/4518] 36% | Training loss: 0.6872250785013873
Epoch: 66 | Iteration number: [1680/4518] 37% | Training loss: 0.687223703201328
Epoch: 66 | Iteration number: [1690/4518] 37% | Training loss: 0.6872128649223486
Epoch: 66 | Iteration number: [1700/4518] 37% | Training loss: 0.687211508785977
Epoch: 66 | Iteration number: [1710/4518] 37% | Training loss: 0.6872107578648461
Epoch: 66 | Iteration number: [1720/4518] 38% | Training loss: 0.6872045913754508
Epoch: 66 | Iteration number: [1730/4518] 38% | Training loss: 0.687203774631368
Epoch: 66 | Iteration number: [1740/4518] 38% | Training loss: 0.6872014412249642
Epoch: 66 | Iteration number: [1750/4518] 38% | Training loss: 0.6871958820819855
Epoch: 66 | Iteration number: [1760/4518] 38% | Training loss: 0.68719691908495
Epoch: 66 | Iteration number: [1770/4518] 39% | Training loss: 0.6871968146097862
Epoch: 66 | Iteration number: [1780/4518] 39% | Training loss: 0.6871921533948919
Epoch: 66 | Iteration number: [1790/4518] 39% | Training loss: 0.6871930631179384
Epoch: 66 | Iteration number: [1800/4518] 39% | Training loss: 0.6871885183784697
Epoch: 66 | Iteration number: [1810/4518] 40% | Training loss: 0.687195758727374
Epoch: 66 | Iteration number: [1820/4518] 40% | Training loss: 0.6871903897314281
Epoch: 66 | Iteration number: [1830/4518] 40% | Training loss: 0.6871887263378811
Epoch: 66 | Iteration number: [1840/4518] 40% | Training loss: 0.6871814476407092
Epoch: 66 | Iteration number: [1850/4518] 40% | Training loss: 0.6871783680207021
Epoch: 66 | Iteration number: [1860/4518] 41% | Training loss: 0.6871793220440546
Epoch: 66 | Iteration number: [1870/4518] 41% | Training loss: 0.687181802293196
Epoch: 66 | Iteration number: [1880/4518] 41% | Training loss: 0.6871771968742635
Epoch: 66 | Iteration number: [1890/4518] 41% | Training loss: 0.6871821748831916
Epoch: 66 | Iteration number: [1900/4518] 42% | Training loss: 0.6871751233778501
Epoch: 66 | Iteration number: [1910/4518] 42% | Training loss: 0.6871668731042851
Epoch: 66 | Iteration number: [1920/4518] 42% | Training loss: 0.6871619358037909
Epoch: 66 | Iteration number: [1930/4518] 42% | Training loss: 0.687156989475606
Epoch: 66 | Iteration number: [1940/4518] 42% | Training loss: 0.6871517837354817
Epoch: 66 | Iteration number: [1950/4518] 43% | Training loss: 0.6871438729457366
Epoch: 66 | Iteration number: [1960/4518] 43% | Training loss: 0.6871395445295743
Epoch: 66 | Iteration number: [1970/4518] 43% | Training loss: 0.6871410957447769
Epoch: 66 | Iteration number: [1980/4518] 43% | Training loss: 0.6871424470586006
Epoch: 66 | Iteration number: [1990/4518] 44% | Training loss: 0.687137417937044
Epoch: 66 | Iteration number: [2000/4518] 44% | Training loss: 0.6871375804543495
Epoch: 66 | Iteration number: [2010/4518] 44% | Training loss: 0.6871341278600456
Epoch: 66 | Iteration number: [2020/4518] 44% | Training loss: 0.6871379046156855
Epoch: 66 | Iteration number: [2030/4518] 44% | Training loss: 0.687134477833809
Epoch: 66 | Iteration number: [2040/4518] 45% | Training loss: 0.6871338768332612
Epoch: 66 | Iteration number: [2050/4518] 45% | Training loss: 0.6871263895965204
Epoch: 66 | Iteration number: [2060/4518] 45% | Training loss: 0.6871291305544307
Epoch: 66 | Iteration number: [2070/4518] 45% | Training loss: 0.6871266194587744
Epoch: 66 | Iteration number: [2080/4518] 46% | Training loss: 0.6871247401031164
Epoch: 66 | Iteration number: [2090/4518] 46% | Training loss: 0.6871267124511409
Epoch: 66 | Iteration number: [2100/4518] 46% | Training loss: 0.6871137680610021
Epoch: 66 | Iteration number: [2110/4518] 46% | Training loss: 0.6871120571242689
Epoch: 66 | Iteration number: [2120/4518] 46% | Training loss: 0.6871050935590042
Epoch: 66 | Iteration number: [2130/4518] 47% | Training loss: 0.6871077360121857
Epoch: 66 | Iteration number: [2140/4518] 47% | Training loss: 0.6871101089170046
Epoch: 66 | Iteration number: [2150/4518] 47% | Training loss: 0.687103864564452
Epoch: 66 | Iteration number: [2160/4518] 47% | Training loss: 0.687105215313258
Epoch: 66 | Iteration number: [2170/4518] 48% | Training loss: 0.6871003939534113
Epoch: 66 | Iteration number: [2180/4518] 48% | Training loss: 0.6871032326866727
Epoch: 66 | Iteration number: [2190/4518] 48% | Training loss: 0.6870982230526127
Epoch: 66 | Iteration number: [2200/4518] 48% | Training loss: 0.6870967940037901
Epoch: 66 | Iteration number: [2210/4518] 48% | Training loss: 0.6870998722395746
Epoch: 66 | Iteration number: [2220/4518] 49% | Training loss: 0.6871026307881415
Epoch: 66 | Iteration number: [2230/4518] 49% | Training loss: 0.6871029213672262
Epoch: 66 | Iteration number: [2240/4518] 49% | Training loss: 0.6871050619653293
Epoch: 66 | Iteration number: [2250/4518] 49% | Training loss: 0.6871004169782002
Epoch: 66 | Iteration number: [2260/4518] 50% | Training loss: 0.687102984986474
Epoch: 66 | Iteration number: [2270/4518] 50% | Training loss: 0.6871032059455233
Epoch: 66 | Iteration number: [2280/4518] 50% | Training loss: 0.687100693217495
Epoch: 66 | Iteration number: [2290/4518] 50% | Training loss: 0.6871025643754735
Epoch: 66 | Iteration number: [2300/4518] 50% | Training loss: 0.6871024372266686
Epoch: 66 | Iteration number: [2310/4518] 51% | Training loss: 0.687105104391709
Epoch: 66 | Iteration number: [2320/4518] 51% | Training loss: 0.6871058007766461
Epoch: 66 | Iteration number: [2330/4518] 51% | Training loss: 0.6871011178125128
Epoch: 66 | Iteration number: [2340/4518] 51% | Training loss: 0.6870996574815522
Epoch: 66 | Iteration number: [2350/4518] 52% | Training loss: 0.6871006879907974
Epoch: 66 | Iteration number: [2360/4518] 52% | Training loss: 0.6871012426533941
Epoch: 66 | Iteration number: [2370/4518] 52% | Training loss: 0.6870968887323066
Epoch: 66 | Iteration number: [2380/4518] 52% | Training loss: 0.687093469250102
Epoch: 66 | Iteration number: [2390/4518] 52% | Training loss: 0.6870917218748994
Epoch: 66 | Iteration number: [2400/4518] 53% | Training loss: 0.6870940526078144
Epoch: 66 | Iteration number: [2410/4518] 53% | Training loss: 0.6870928091132295
Epoch: 66 | Iteration number: [2420/4518] 53% | Training loss: 0.6870920699736304
Epoch: 66 | Iteration number: [2430/4518] 53% | Training loss: 0.6870886031492257
Epoch: 66 | Iteration number: [2440/4518] 54% | Training loss: 0.687089011708244
Epoch: 66 | Iteration number: [2450/4518] 54% | Training loss: 0.6870855672992006
Epoch: 66 | Iteration number: [2460/4518] 54% | Training loss: 0.6870830330422254
Epoch: 66 | Iteration number: [2470/4518] 54% | Training loss: 0.6870800343843607
Epoch: 66 | Iteration number: [2480/4518] 54% | Training loss: 0.6870796597052005
Epoch: 66 | Iteration number: [2490/4518] 55% | Training loss: 0.6870833149157375
Epoch: 66 | Iteration number: [2500/4518] 55% | Training loss: 0.687085722732544
Epoch: 66 | Iteration number: [2510/4518] 55% | Training loss: 0.6870836176482805
Epoch: 66 | Iteration number: [2520/4518] 55% | Training loss: 0.6870814752484125
Epoch: 66 | Iteration number: [2530/4518] 55% | Training loss: 0.6870803816045226
Epoch: 66 | Iteration number: [2540/4518] 56% | Training loss: 0.687081395664553
Epoch: 66 | Iteration number: [2550/4518] 56% | Training loss: 0.6870800851373111
Epoch: 66 | Iteration number: [2560/4518] 56% | Training loss: 0.6870801371522248
Epoch: 66 | Iteration number: [2570/4518] 56% | Training loss: 0.6870811748365484
Epoch: 66 | Iteration number: [2580/4518] 57% | Training loss: 0.6870780054681985
Epoch: 66 | Iteration number: [2590/4518] 57% | Training loss: 0.6870776777792161
Epoch: 66 | Iteration number: [2600/4518] 57% | Training loss: 0.6870769695823009
Epoch: 66 | Iteration number: [2610/4518] 57% | Training loss: 0.6870756554649251
Epoch: 66 | Iteration number: [2620/4518] 57% | Training loss: 0.6870753242314317
Epoch: 66 | Iteration number: [2630/4518] 58% | Training loss: 0.6870769073754662
Epoch: 66 | Iteration number: [2640/4518] 58% | Training loss: 0.6870706358642289
Epoch: 66 | Iteration number: [2650/4518] 58% | Training loss: 0.6870694095458625
Epoch: 66 | Iteration number: [2660/4518] 58% | Training loss: 0.6870677571995814
Epoch: 66 | Iteration number: [2670/4518] 59% | Training loss: 0.687068716439415
Epoch: 66 | Iteration number: [2680/4518] 59% | Training loss: 0.6870677649752418
Epoch: 66 | Iteration number: [2690/4518] 59% | Training loss: 0.6870632018076887
Epoch: 66 | Iteration number: [2700/4518] 59% | Training loss: 0.6870596803559197
Epoch: 66 | Iteration number: [2710/4518] 59% | Training loss: 0.6870638533052044
Epoch: 66 | Iteration number: [2720/4518] 60% | Training loss: 0.687061906518305
Epoch: 66 | Iteration number: [2730/4518] 60% | Training loss: 0.6870624850957822
Epoch: 66 | Iteration number: [2740/4518] 60% | Training loss: 0.6870654625396659
Epoch: 66 | Iteration number: [2750/4518] 60% | Training loss: 0.6870650755058635
Epoch: 66 | Iteration number: [2760/4518] 61% | Training loss: 0.6870635065479554
Epoch: 66 | Iteration number: [2770/4518] 61% | Training loss: 0.6870625129245248
Epoch: 66 | Iteration number: [2780/4518] 61% | Training loss: 0.6870608480928613
Epoch: 66 | Iteration number: [2790/4518] 61% | Training loss: 0.6870614184700887
Epoch: 66 | Iteration number: [2800/4518] 61% | Training loss: 0.6870649174707276
Epoch: 66 | Iteration number: [2810/4518] 62% | Training loss: 0.6870605585413896
Epoch: 66 | Iteration number: [2820/4518] 62% | Training loss: 0.6870627467936657
Epoch: 66 | Iteration number: [2830/4518] 62% | Training loss: 0.6870675325393677
Epoch: 66 | Iteration number: [2840/4518] 62% | Training loss: 0.6870655085419265
Epoch: 66 | Iteration number: [2850/4518] 63% | Training loss: 0.6870645250772175
Epoch: 66 | Iteration number: [2860/4518] 63% | Training loss: 0.6870657752027045
Epoch: 66 | Iteration number: [2870/4518] 63% | Training loss: 0.6870643656012904
Epoch: 66 | Iteration number: [2880/4518] 63% | Training loss: 0.6870658651408222
Epoch: 66 | Iteration number: [2890/4518] 63% | Training loss: 0.6870608431038971
Epoch: 66 | Iteration number: [2900/4518] 64% | Training loss: 0.6870628653312552
Epoch: 66 | Iteration number: [2910/4518] 64% | Training loss: 0.6870595858473958
Epoch: 66 | Iteration number: [2920/4518] 64% | Training loss: 0.6870612159575502
Epoch: 66 | Iteration number: [2930/4518] 64% | Training loss: 0.6870556360218713
Epoch: 66 | Iteration number: [2940/4518] 65% | Training loss: 0.6870464216689675
Epoch: 66 | Iteration number: [2950/4518] 65% | Training loss: 0.6870498148061461
Epoch: 66 | Iteration number: [2960/4518] 65% | Training loss: 0.6870521208925827
Epoch: 66 | Iteration number: [2970/4518] 65% | Training loss: 0.6870509009971362
Epoch: 66 | Iteration number: [2980/4518] 65% | Training loss: 0.6870490445586659
Epoch: 66 | Iteration number: [2990/4518] 66% | Training loss: 0.6870471486877837
Epoch: 66 | Iteration number: [3000/4518] 66% | Training loss: 0.6870442014336586
Epoch: 66 | Iteration number: [3010/4518] 66% | Training loss: 0.6870410243340109
Epoch: 66 | Iteration number: [3020/4518] 66% | Training loss: 0.6870396578154027
Epoch: 66 | Iteration number: [3030/4518] 67% | Training loss: 0.6870394369753281
Epoch: 66 | Iteration number: [3040/4518] 67% | Training loss: 0.6870348121774824
Epoch: 66 | Iteration number: [3050/4518] 67% | Training loss: 0.687030535486878
Epoch: 66 | Iteration number: [3060/4518] 67% | Training loss: 0.6870303645827411
Epoch: 66 | Iteration number: [3070/4518] 67% | Training loss: 0.687031202790015
Epoch: 66 | Iteration number: [3080/4518] 68% | Training loss: 0.6870340392961131
Epoch: 66 | Iteration number: [3090/4518] 68% | Training loss: 0.6870316535523794
Epoch: 66 | Iteration number: [3100/4518] 68% | Training loss: 0.6870309961803498
Epoch: 66 | Iteration number: [3110/4518] 68% | Training loss: 0.6870273270407674
Epoch: 66 | Iteration number: [3120/4518] 69% | Training loss: 0.6870279575769718
Epoch: 66 | Iteration number: [3130/4518] 69% | Training loss: 0.6870234090680132
Epoch: 66 | Iteration number: [3140/4518] 69% | Training loss: 0.6870206838580454
Epoch: 66 | Iteration number: [3150/4518] 69% | Training loss: 0.6870192937623887
Epoch: 66 | Iteration number: [3160/4518] 69% | Training loss: 0.6870178931310207
Epoch: 66 | Iteration number: [3170/4518] 70% | Training loss: 0.6870120256669138
Epoch: 66 | Iteration number: [3180/4518] 70% | Training loss: 0.6870179936008634
Epoch: 66 | Iteration number: [3190/4518] 70% | Training loss: 0.6870235550366225
Epoch: 66 | Iteration number: [3200/4518] 70% | Training loss: 0.6870216839201748
Epoch: 66 | Iteration number: [3210/4518] 71% | Training loss: 0.6870217717696573
Epoch: 66 | Iteration number: [3220/4518] 71% | Training loss: 0.6870213761092713
Epoch: 66 | Iteration number: [3230/4518] 71% | Training loss: 0.6870127585834763
Epoch: 66 | Iteration number: [3240/4518] 71% | Training loss: 0.6870079523435345
Epoch: 66 | Iteration number: [3250/4518] 71% | Training loss: 0.6870030620464912
Epoch: 66 | Iteration number: [3260/4518] 72% | Training loss: 0.6869978973287746
Epoch: 66 | Iteration number: [3270/4518] 72% | Training loss: 0.686998421318305
Epoch: 66 | Iteration number: [3280/4518] 72% | Training loss: 0.686994379286359
Epoch: 66 | Iteration number: [3290/4518] 72% | Training loss: 0.6869913519515817
Epoch: 66 | Iteration number: [3300/4518] 73% | Training loss: 0.6869968513467095
Epoch: 66 | Iteration number: [3310/4518] 73% | Training loss: 0.6869944002873227
Epoch: 66 | Iteration number: [3320/4518] 73% | Training loss: 0.6869947885353881
Epoch: 66 | Iteration number: [3330/4518] 73% | Training loss: 0.6869958075317176
Epoch: 66 | Iteration number: [3340/4518] 73% | Training loss: 0.6869913887121006
Epoch: 66 | Iteration number: [3350/4518] 74% | Training loss: 0.686992283045356
Epoch: 66 | Iteration number: [3360/4518] 74% | Training loss: 0.6869952398041884
Epoch: 66 | Iteration number: [3370/4518] 74% | Training loss: 0.6869970421762778
Epoch: 66 | Iteration number: [3380/4518] 74% | Training loss: 0.6869966778353122
Epoch: 66 | Iteration number: [3390/4518] 75% | Training loss: 0.6869953639563557
Epoch: 66 | Iteration number: [3400/4518] 75% | Training loss: 0.6869941066293156
Epoch: 66 | Iteration number: [3410/4518] 75% | Training loss: 0.6869965487036886
Epoch: 66 | Iteration number: [3420/4518] 75% | Training loss: 0.6869958252934685
Epoch: 66 | Iteration number: [3430/4518] 75% | Training loss: 0.6869940860799728
Epoch: 66 | Iteration number: [3440/4518] 76% | Training loss: 0.6869931063506493
Epoch: 66 | Iteration number: [3450/4518] 76% | Training loss: 0.6869927382123643
Epoch: 66 | Iteration number: [3460/4518] 76% | Training loss: 0.6869913343577027
Epoch: 66 | Iteration number: [3470/4518] 76% | Training loss: 0.6869911729602374
Epoch: 66 | Iteration number: [3480/4518] 77% | Training loss: 0.6869948756934583
Epoch: 66 | Iteration number: [3490/4518] 77% | Training loss: 0.6869903534565409
Epoch: 66 | Iteration number: [3500/4518] 77% | Training loss: 0.6869918448073523
Epoch: 66 | Iteration number: [3510/4518] 77% | Training loss: 0.6869949008324887
Epoch: 66 | Iteration number: [3520/4518] 77% | Training loss: 0.6869962778281081
Epoch: 66 | Iteration number: [3530/4518] 78% | Training loss: 0.6869969500698382
Epoch: 66 | Iteration number: [3540/4518] 78% | Training loss: 0.6869953664009181
Epoch: 66 | Iteration number: [3550/4518] 78% | Training loss: 0.6869947935158098
Epoch: 66 | Iteration number: [3560/4518] 78% | Training loss: 0.686993372591024
Epoch: 66 | Iteration number: [3570/4518] 79% | Training loss: 0.6869962954554572
Epoch: 66 | Iteration number: [3580/4518] 79% | Training loss: 0.6869963264332137
Epoch: 66 | Iteration number: [3590/4518] 79% | Training loss: 0.6869939423371159
Epoch: 66 | Iteration number: [3600/4518] 79% | Training loss: 0.6869920187360711
Epoch: 66 | Iteration number: [3610/4518] 79% | Training loss: 0.6869911461325564
Epoch: 66 | Iteration number: [3620/4518] 80% | Training loss: 0.6869892558504863
Epoch: 66 | Iteration number: [3630/4518] 80% | Training loss: 0.6869846699651608
Epoch: 66 | Iteration number: [3640/4518] 80% | Training loss: 0.6869836584388554
Epoch: 66 | Iteration number: [3650/4518] 80% | Training loss: 0.6869828168986595
Epoch: 66 | Iteration number: [3660/4518] 81% | Training loss: 0.686984432981314
Epoch: 66 | Iteration number: [3670/4518] 81% | Training loss: 0.686985406482577
Epoch: 66 | Iteration number: [3680/4518] 81% | Training loss: 0.6869883107102436
Epoch: 66 | Iteration number: [3690/4518] 81% | Training loss: 0.686988384839965
Epoch: 66 | Iteration number: [3700/4518] 81% | Training loss: 0.6869894454124812
Epoch: 66 | Iteration number: [3710/4518] 82% | Training loss: 0.6869912925274224
Epoch: 66 | Iteration number: [3720/4518] 82% | Training loss: 0.6869869746027454
Epoch: 66 | Iteration number: [3730/4518] 82% | Training loss: 0.6869888519473754
Epoch: 66 | Iteration number: [3740/4518] 82% | Training loss: 0.6869866828548717
Epoch: 66 | Iteration number: [3750/4518] 83% | Training loss: 0.6869865986982981
Epoch: 66 | Iteration number: [3760/4518] 83% | Training loss: 0.686987003953533
Epoch: 66 | Iteration number: [3770/4518] 83% | Training loss: 0.6869890335858343
Epoch: 66 | Iteration number: [3780/4518] 83% | Training loss: 0.6869913488941849
Epoch: 66 | Iteration number: [3790/4518] 83% | Training loss: 0.6869894775362946
Epoch: 66 | Iteration number: [3800/4518] 84% | Training loss: 0.6869890820823218
Epoch: 66 | Iteration number: [3810/4518] 84% | Training loss: 0.6869872748538891
Epoch: 66 | Iteration number: [3820/4518] 84% | Training loss: 0.6869886324199707
Epoch: 66 | Iteration number: [3830/4518] 84% | Training loss: 0.6869875481016642
Epoch: 66 | Iteration number: [3840/4518] 84% | Training loss: 0.6869858513120561
Epoch: 66 | Iteration number: [3850/4518] 85% | Training loss: 0.686987090048852
Epoch: 66 | Iteration number: [3860/4518] 85% | Training loss: 0.6869878834393358
Epoch: 66 | Iteration number: [3870/4518] 85% | Training loss: 0.6869881444661192
Epoch: 66 | Iteration number: [3880/4518] 85% | Training loss: 0.6869912659999021
Epoch: 66 | Iteration number: [3890/4518] 86% | Training loss: 0.6869899867586121
Epoch: 66 | Iteration number: [3900/4518] 86% | Training loss: 0.6869881555361625
Epoch: 66 | Iteration number: [3910/4518] 86% | Training loss: 0.6869869484925819
Epoch: 66 | Iteration number: [3920/4518] 86% | Training loss: 0.6869888707843362
Epoch: 66 | Iteration number: [3930/4518] 86% | Training loss: 0.6869878351840051
Epoch: 66 | Iteration number: [3940/4518] 87% | Training loss: 0.686988930351238
Epoch: 66 | Iteration number: [3950/4518] 87% | Training loss: 0.6869859702677666
Epoch: 66 | Iteration number: [3960/4518] 87% | Training loss: 0.6869811449388061
Epoch: 66 | Iteration number: [3970/4518] 87% | Training loss: 0.6869773349323561
Epoch: 66 | Iteration number: [3980/4518] 88% | Training loss: 0.6869798102570539
Epoch: 66 | Iteration number: [3990/4518] 88% | Training loss: 0.6869785947010929
Epoch: 66 | Iteration number: [4000/4518] 88% | Training loss: 0.6869784077256917
Epoch: 66 | Iteration number: [4010/4518] 88% | Training loss: 0.6869804860201857
Epoch: 66 | Iteration number: [4020/4518] 88% | Training loss: 0.6869804270973253
Epoch: 66 | Iteration number: [4030/4518] 89% | Training loss: 0.6869788292176079
Epoch: 66 | Iteration number: [4040/4518] 89% | Training loss: 0.6869803073382613
Epoch: 66 | Iteration number: [4050/4518] 89% | Training loss: 0.6869802268640495
Epoch: 66 | Iteration number: [4060/4518] 89% | Training loss: 0.6869808715699341
Epoch: 66 | Iteration number: [4070/4518] 90% | Training loss: 0.6869810144350629
Epoch: 66 | Iteration number: [4080/4518] 90% | Training loss: 0.6869825620423345
Epoch: 66 | Iteration number: [4090/4518] 90% | Training loss: 0.6869846541170386
Epoch: 66 | Iteration number: [4100/4518] 90% | Training loss: 0.6869837251959777
Epoch: 66 | Iteration number: [4110/4518] 90% | Training loss: 0.6869824860797892
Epoch: 66 | Iteration number: [4120/4518] 91% | Training loss: 0.6869846838915232
Epoch: 66 | Iteration number: [4130/4518] 91% | Training loss: 0.6869837676353086
Epoch: 66 | Iteration number: [4140/4518] 91% | Training loss: 0.6869837193097469
Epoch: 66 | Iteration number: [4150/4518] 91% | Training loss: 0.6869829245504127
Epoch: 66 | Iteration number: [4160/4518] 92% | Training loss: 0.6869855549616309
Epoch: 66 | Iteration number: [4170/4518] 92% | Training loss: 0.6869820878945953
Epoch: 66 | Iteration number: [4180/4518] 92% | Training loss: 0.6869810633111798
Epoch: 66 | Iteration number: [4190/4518] 92% | Training loss: 0.6869797940754947
Epoch: 66 | Iteration number: [4200/4518] 92% | Training loss: 0.686979580777032
Epoch: 66 | Iteration number: [4210/4518] 93% | Training loss: 0.686977443191048
Epoch: 66 | Iteration number: [4220/4518] 93% | Training loss: 0.6869727519592402
Epoch: 66 | Iteration number: [4230/4518] 93% | Training loss: 0.6869725377988026
Epoch: 66 | Iteration number: [4240/4518] 93% | Training loss: 0.6869747586126598
Epoch: 66 | Iteration number: [4250/4518] 94% | Training loss: 0.6869706226797665
Epoch: 66 | Iteration number: [4260/4518] 94% | Training loss: 0.6869694447573362
Epoch: 66 | Iteration number: [4270/4518] 94% | Training loss: 0.6869690115753325
Epoch: 66 | Iteration number: [4280/4518] 94% | Training loss: 0.6869677360230517
Epoch: 66 | Iteration number: [4290/4518] 94% | Training loss: 0.6869647038149667
Epoch: 66 | Iteration number: [4300/4518] 95% | Training loss: 0.6869667942302171
Epoch: 66 | Iteration number: [4310/4518] 95% | Training loss: 0.686964383825072
Epoch: 66 | Iteration number: [4320/4518] 95% | Training loss: 0.6869623294307126
Epoch: 66 | Iteration number: [4330/4518] 95% | Training loss: 0.68696010331634
Epoch: 66 | Iteration number: [4340/4518] 96% | Training loss: 0.6869570652872736
Epoch: 66 | Iteration number: [4350/4518] 96% | Training loss: 0.6869570295564059
Epoch: 66 | Iteration number: [4360/4518] 96% | Training loss: 0.6869565650137193
Epoch: 66 | Iteration number: [4370/4518] 96% | Training loss: 0.6869574645700389
Epoch: 66 | Iteration number: [4380/4518] 96% | Training loss: 0.686955840320892
Epoch: 66 | Iteration number: [4390/4518] 97% | Training loss: 0.686956145687364
Epoch: 66 | Iteration number: [4400/4518] 97% | Training loss: 0.6869569309733131
Epoch: 66 | Iteration number: [4410/4518] 97% | Training loss: 0.6869525459077623
Epoch: 66 | Iteration number: [4420/4518] 97% | Training loss: 0.6869528123561074
Epoch: 66 | Iteration number: [4430/4518] 98% | Training loss: 0.6869524277359853
Epoch: 66 | Iteration number: [4440/4518] 98% | Training loss: 0.6869508965863838
Epoch: 66 | Iteration number: [4450/4518] 98% | Training loss: 0.6869481250945102
Epoch: 66 | Iteration number: [4460/4518] 98% | Training loss: 0.6869467077634794
Epoch: 66 | Iteration number: [4470/4518] 98% | Training loss: 0.6869458204414487
Epoch: 66 | Iteration number: [4480/4518] 99% | Training loss: 0.6869418691577656
Epoch: 66 | Iteration number: [4490/4518] 99% | Training loss: 0.6869403234436146
Epoch: 66 | Iteration number: [4500/4518] 99% | Training loss: 0.6869397408829795
Epoch: 66 | Iteration number: [4510/4518] 99% | Training loss: 0.6869351369314342

 End of epoch: 66 | Train Loss: 0.6867815175115561 | Training Time: 641 

 End of epoch: 66 | Eval Loss: 0.689847356202651 | Evaluating Time: 17 
Epoch: 67 | Iteration number: [10/4518] 0% | Training loss: 0.7567758560180664
Epoch: 67 | Iteration number: [20/4518] 0% | Training loss: 0.7213110953569413
Epoch: 67 | Iteration number: [30/4518] 0% | Training loss: 0.7092735429604848
Epoch: 67 | Iteration number: [40/4518] 0% | Training loss: 0.7034118801355362
Epoch: 67 | Iteration number: [50/4518] 1% | Training loss: 0.7000916683673859
Epoch: 67 | Iteration number: [60/4518] 1% | Training loss: 0.6978887250026067
Epoch: 67 | Iteration number: [70/4518] 1% | Training loss: 0.6962465950420924
Epoch: 67 | Iteration number: [80/4518] 1% | Training loss: 0.6951636649668217
Epoch: 67 | Iteration number: [90/4518] 1% | Training loss: 0.6942511452568902
Epoch: 67 | Iteration number: [100/4518] 2% | Training loss: 0.6935734099149704
Epoch: 67 | Iteration number: [110/4518] 2% | Training loss: 0.6929844639518045
Epoch: 67 | Iteration number: [120/4518] 2% | Training loss: 0.6925207739075024
Epoch: 67 | Iteration number: [130/4518] 2% | Training loss: 0.692060735133978
Epoch: 67 | Iteration number: [140/4518] 3% | Training loss: 0.6917120950562613
Epoch: 67 | Iteration number: [150/4518] 3% | Training loss: 0.6914321605364482
Epoch: 67 | Iteration number: [160/4518] 3% | Training loss: 0.6911522146314383
Epoch: 67 | Iteration number: [170/4518] 3% | Training loss: 0.6908512809697319
Epoch: 67 | Iteration number: [180/4518] 3% | Training loss: 0.6905709505081177
Epoch: 67 | Iteration number: [190/4518] 4% | Training loss: 0.6903617661250265
Epoch: 67 | Iteration number: [200/4518] 4% | Training loss: 0.690186782181263
Epoch: 67 | Iteration number: [210/4518] 4% | Training loss: 0.6900479753812154
Epoch: 67 | Iteration number: [220/4518] 4% | Training loss: 0.689914606647058
Epoch: 67 | Iteration number: [230/4518] 5% | Training loss: 0.689744515263516
Epoch: 67 | Iteration number: [240/4518] 5% | Training loss: 0.6896339212854703
Epoch: 67 | Iteration number: [250/4518] 5% | Training loss: 0.6895061175823212
Epoch: 67 | Iteration number: [260/4518] 5% | Training loss: 0.6893990486860275
Epoch: 67 | Iteration number: [270/4518] 5% | Training loss: 0.6893255915906694
Epoch: 67 | Iteration number: [280/4518] 6% | Training loss: 0.6891990731869425
Epoch: 67 | Iteration number: [290/4518] 6% | Training loss: 0.6891439402925557
Epoch: 67 | Iteration number: [300/4518] 6% | Training loss: 0.6890196311473846
Epoch: 67 | Iteration number: [310/4518] 6% | Training loss: 0.6889565621652911
Epoch: 67 | Iteration number: [320/4518] 7% | Training loss: 0.688859205134213
Epoch: 67 | Iteration number: [330/4518] 7% | Training loss: 0.6887677889881711
Epoch: 67 | Iteration number: [340/4518] 7% | Training loss: 0.6887309903607649
Epoch: 67 | Iteration number: [350/4518] 7% | Training loss: 0.6886973624570029
Epoch: 67 | Iteration number: [360/4518] 7% | Training loss: 0.6886266971627871
Epoch: 67 | Iteration number: [370/4518] 8% | Training loss: 0.6885805183165782
Epoch: 67 | Iteration number: [380/4518] 8% | Training loss: 0.6885253945463582
Epoch: 67 | Iteration number: [390/4518] 8% | Training loss: 0.6884828153329018
Epoch: 67 | Iteration number: [400/4518] 8% | Training loss: 0.6884477335214615
Epoch: 67 | Iteration number: [410/4518] 9% | Training loss: 0.6884069486362178
Epoch: 67 | Iteration number: [420/4518] 9% | Training loss: 0.6883477184034529
Epoch: 67 | Iteration number: [430/4518] 9% | Training loss: 0.6883130384045978
Epoch: 67 | Iteration number: [440/4518] 9% | Training loss: 0.6882916980169036
Epoch: 67 | Iteration number: [450/4518] 9% | Training loss: 0.6882692503929139
Epoch: 67 | Iteration number: [460/4518] 10% | Training loss: 0.6882492016191067
Epoch: 67 | Iteration number: [470/4518] 10% | Training loss: 0.6882440356498069
Epoch: 67 | Iteration number: [480/4518] 10% | Training loss: 0.6882300237814586
Epoch: 67 | Iteration number: [490/4518] 10% | Training loss: 0.6881919680809488
Epoch: 67 | Iteration number: [500/4518] 11% | Training loss: 0.6881535887718201
Epoch: 67 | Iteration number: [510/4518] 11% | Training loss: 0.688116586558959
Epoch: 67 | Iteration number: [520/4518] 11% | Training loss: 0.6881239325954364
Epoch: 67 | Iteration number: [530/4518] 11% | Training loss: 0.6881003076175474
Epoch: 67 | Iteration number: [540/4518] 11% | Training loss: 0.6880876873378401
Epoch: 67 | Iteration number: [550/4518] 12% | Training loss: 0.6880648699673739
Epoch: 67 | Iteration number: [560/4518] 12% | Training loss: 0.6880358338356019
Epoch: 67 | Iteration number: [570/4518] 12% | Training loss: 0.6880012916891198
Epoch: 67 | Iteration number: [580/4518] 12% | Training loss: 0.6879869216474993
Epoch: 67 | Iteration number: [590/4518] 13% | Training loss: 0.687970705961777
Epoch: 67 | Iteration number: [600/4518] 13% | Training loss: 0.6879313522577286
Epoch: 67 | Iteration number: [610/4518] 13% | Training loss: 0.6879031375783389
Epoch: 67 | Iteration number: [620/4518] 13% | Training loss: 0.687891946011974
Epoch: 67 | Iteration number: [630/4518] 13% | Training loss: 0.6878807773665776
Epoch: 67 | Iteration number: [640/4518] 14% | Training loss: 0.6878734066151082
Epoch: 67 | Iteration number: [650/4518] 14% | Training loss: 0.6878794726958641
Epoch: 67 | Iteration number: [660/4518] 14% | Training loss: 0.6878834273779031
Epoch: 67 | Iteration number: [670/4518] 14% | Training loss: 0.6878684255614209
Epoch: 67 | Iteration number: [680/4518] 15% | Training loss: 0.6878532537642648
Epoch: 67 | Iteration number: [690/4518] 15% | Training loss: 0.6878554185231527
Epoch: 67 | Iteration number: [700/4518] 15% | Training loss: 0.6878542856659208
Epoch: 67 | Iteration number: [710/4518] 15% | Training loss: 0.6878412872133121
Epoch: 67 | Iteration number: [720/4518] 15% | Training loss: 0.6878298581474357
Epoch: 67 | Iteration number: [730/4518] 16% | Training loss: 0.6878174027351484
Epoch: 67 | Iteration number: [740/4518] 16% | Training loss: 0.6878042180795927
Epoch: 67 | Iteration number: [750/4518] 16% | Training loss: 0.6877839891115824
Epoch: 67 | Iteration number: [760/4518] 16% | Training loss: 0.6877959756474746
Epoch: 67 | Iteration number: [770/4518] 17% | Training loss: 0.6877868540875324
Epoch: 67 | Iteration number: [780/4518] 17% | Training loss: 0.687765290034123
Epoch: 67 | Iteration number: [790/4518] 17% | Training loss: 0.6877460490299176
Epoch: 67 | Iteration number: [800/4518] 17% | Training loss: 0.6877384495735168
Epoch: 67 | Iteration number: [810/4518] 17% | Training loss: 0.6877146912209782
Epoch: 67 | Iteration number: [820/4518] 18% | Training loss: 0.6877042115461536
Epoch: 67 | Iteration number: [830/4518] 18% | Training loss: 0.687690591309444
Epoch: 67 | Iteration number: [840/4518] 18% | Training loss: 0.6876735939156442
Epoch: 67 | Iteration number: [850/4518] 18% | Training loss: 0.6876461842480828
Epoch: 67 | Iteration number: [860/4518] 19% | Training loss: 0.6876443469247152
Epoch: 67 | Iteration number: [870/4518] 19% | Training loss: 0.6876471879153416
Epoch: 67 | Iteration number: [880/4518] 19% | Training loss: 0.6876466879113154
Epoch: 67 | Iteration number: [890/4518] 19% | Training loss: 0.6876379632548
Epoch: 67 | Iteration number: [900/4518] 19% | Training loss: 0.6876212457153532
Epoch: 67 | Iteration number: [910/4518] 20% | Training loss: 0.6876136270198193
Epoch: 67 | Iteration number: [920/4518] 20% | Training loss: 0.6876109728994577
Epoch: 67 | Iteration number: [930/4518] 20% | Training loss: 0.6875978312825644
Epoch: 67 | Iteration number: [940/4518] 20% | Training loss: 0.6876003890595538
Epoch: 67 | Iteration number: [950/4518] 21% | Training loss: 0.6875841721108086
Epoch: 67 | Iteration number: [960/4518] 21% | Training loss: 0.687575192625324
Epoch: 67 | Iteration number: [970/4518] 21% | Training loss: 0.6875747989747942
Epoch: 67 | Iteration number: [980/4518] 21% | Training loss: 0.6875576800837808
Epoch: 67 | Iteration number: [990/4518] 21% | Training loss: 0.6875525931517283
Epoch: 67 | Iteration number: [1000/4518] 22% | Training loss: 0.68754838514328
Epoch: 67 | Iteration number: [1010/4518] 22% | Training loss: 0.6875404015035913
Epoch: 67 | Iteration number: [1020/4518] 22% | Training loss: 0.6875410217280481
Epoch: 67 | Iteration number: [1030/4518] 22% | Training loss: 0.6875201611842924
Epoch: 67 | Iteration number: [1040/4518] 23% | Training loss: 0.6875062131537841
Epoch: 67 | Iteration number: [1050/4518] 23% | Training loss: 0.6874989242213113
Epoch: 67 | Iteration number: [1060/4518] 23% | Training loss: 0.6875057624758415
Epoch: 67 | Iteration number: [1070/4518] 23% | Training loss: 0.6874978093900413
Epoch: 67 | Iteration number: [1080/4518] 23% | Training loss: 0.6874971220338786
Epoch: 67 | Iteration number: [1090/4518] 24% | Training loss: 0.6874863120394016
Epoch: 67 | Iteration number: [1100/4518] 24% | Training loss: 0.6874793688817458
Epoch: 67 | Iteration number: [1110/4518] 24% | Training loss: 0.6874746776378906
Epoch: 67 | Iteration number: [1120/4518] 24% | Training loss: 0.6874743520681347
Epoch: 67 | Iteration number: [1130/4518] 25% | Training loss: 0.6874743498532118
Epoch: 67 | Iteration number: [1140/4518] 25% | Training loss: 0.6874717933566947
Epoch: 67 | Iteration number: [1150/4518] 25% | Training loss: 0.6874685927577641
Epoch: 67 | Iteration number: [1160/4518] 25% | Training loss: 0.6874517134551344
Epoch: 67 | Iteration number: [1170/4518] 25% | Training loss: 0.6874384923877879
Epoch: 67 | Iteration number: [1180/4518] 26% | Training loss: 0.6874214767399481
Epoch: 67 | Iteration number: [1190/4518] 26% | Training loss: 0.6874185486000125
Epoch: 67 | Iteration number: [1200/4518] 26% | Training loss: 0.6874088843166828
Epoch: 67 | Iteration number: [1210/4518] 26% | Training loss: 0.6873976981836902
Epoch: 67 | Iteration number: [1220/4518] 27% | Training loss: 0.6873952454719388
Epoch: 67 | Iteration number: [1230/4518] 27% | Training loss: 0.6873980987847336
Epoch: 67 | Iteration number: [1240/4518] 27% | Training loss: 0.6873943582177162
Epoch: 67 | Iteration number: [1250/4518] 27% | Training loss: 0.6873853676319123
Epoch: 67 | Iteration number: [1260/4518] 27% | Training loss: 0.6873831144401006
Epoch: 67 | Iteration number: [1270/4518] 28% | Training loss: 0.6873841843267126
Epoch: 67 | Iteration number: [1280/4518] 28% | Training loss: 0.6873937342315912
Epoch: 67 | Iteration number: [1290/4518] 28% | Training loss: 0.6873990875343944
Epoch: 67 | Iteration number: [1300/4518] 28% | Training loss: 0.6874050144507334
Epoch: 67 | Iteration number: [1310/4518] 28% | Training loss: 0.6873975164562691
Epoch: 67 | Iteration number: [1320/4518] 29% | Training loss: 0.6873934922344757
Epoch: 67 | Iteration number: [1330/4518] 29% | Training loss: 0.6873888469728312
Epoch: 67 | Iteration number: [1340/4518] 29% | Training loss: 0.6873819621196434
Epoch: 67 | Iteration number: [1350/4518] 29% | Training loss: 0.687373890346951
Epoch: 67 | Iteration number: [1360/4518] 30% | Training loss: 0.6873829664991182
Epoch: 67 | Iteration number: [1370/4518] 30% | Training loss: 0.6873829293860136
Epoch: 67 | Iteration number: [1380/4518] 30% | Training loss: 0.6873787433772848
Epoch: 67 | Iteration number: [1390/4518] 30% | Training loss: 0.6873736467721651
Epoch: 67 | Iteration number: [1400/4518] 30% | Training loss: 0.6873714140909059
Epoch: 67 | Iteration number: [1410/4518] 31% | Training loss: 0.6873598076773028
Epoch: 67 | Iteration number: [1420/4518] 31% | Training loss: 0.6873598925664391
Epoch: 67 | Iteration number: [1430/4518] 31% | Training loss: 0.6873525787900377
Epoch: 67 | Iteration number: [1440/4518] 31% | Training loss: 0.687344796417488
Epoch: 67 | Iteration number: [1450/4518] 32% | Training loss: 0.6873431759045042
Epoch: 67 | Iteration number: [1460/4518] 32% | Training loss: 0.6873385579210438
Epoch: 67 | Iteration number: [1470/4518] 32% | Training loss: 0.6873252935960991
Epoch: 67 | Iteration number: [1480/4518] 32% | Training loss: 0.687329448195728
Epoch: 67 | Iteration number: [1490/4518] 32% | Training loss: 0.6873293985856459
Epoch: 67 | Iteration number: [1500/4518] 33% | Training loss: 0.687316513578097
Epoch: 67 | Iteration number: [1510/4518] 33% | Training loss: 0.6873153914284232
Epoch: 67 | Iteration number: [1520/4518] 33% | Training loss: 0.6873162798191371
Epoch: 67 | Iteration number: [1530/4518] 33% | Training loss: 0.687303923625572
Epoch: 67 | Iteration number: [1540/4518] 34% | Training loss: 0.6872968917156195
Epoch: 67 | Iteration number: [1550/4518] 34% | Training loss: 0.6872958066386561
Epoch: 67 | Iteration number: [1560/4518] 34% | Training loss: 0.6872909977650031
Epoch: 67 | Iteration number: [1570/4518] 34% | Training loss: 0.6872884858186078
Epoch: 67 | Iteration number: [1580/4518] 34% | Training loss: 0.6872828297599961
Epoch: 67 | Iteration number: [1590/4518] 35% | Training loss: 0.6872671176052694
Epoch: 67 | Iteration number: [1600/4518] 35% | Training loss: 0.687270545065403
Epoch: 67 | Iteration number: [1610/4518] 35% | Training loss: 0.6872686091046896
Epoch: 67 | Iteration number: [1620/4518] 35% | Training loss: 0.6872621928100233
Epoch: 67 | Iteration number: [1630/4518] 36% | Training loss: 0.6872675841205691
Epoch: 67 | Iteration number: [1640/4518] 36% | Training loss: 0.6872692505034005
Epoch: 67 | Iteration number: [1650/4518] 36% | Training loss: 0.6872527628233939
Epoch: 67 | Iteration number: [1660/4518] 36% | Training loss: 0.6872506199112858
Epoch: 67 | Iteration number: [1670/4518] 36% | Training loss: 0.6872537913793575
Epoch: 67 | Iteration number: [1680/4518] 37% | Training loss: 0.6872609749436378
Epoch: 67 | Iteration number: [1690/4518] 37% | Training loss: 0.6872576465620797
Epoch: 67 | Iteration number: [1700/4518] 37% | Training loss: 0.6872589390768724
Epoch: 67 | Iteration number: [1710/4518] 37% | Training loss: 0.6872527519164727
Epoch: 67 | Iteration number: [1720/4518] 38% | Training loss: 0.6872524395931598
Epoch: 67 | Iteration number: [1730/4518] 38% | Training loss: 0.6872482012117529
Epoch: 67 | Iteration number: [1740/4518] 38% | Training loss: 0.6872463034487318
Epoch: 67 | Iteration number: [1750/4518] 38% | Training loss: 0.6872456060137068
Epoch: 67 | Iteration number: [1760/4518] 38% | Training loss: 0.6872463618489829
Epoch: 67 | Iteration number: [1770/4518] 39% | Training loss: 0.6872346698227575
Epoch: 67 | Iteration number: [1780/4518] 39% | Training loss: 0.6872249142172632
Epoch: 67 | Iteration number: [1790/4518] 39% | Training loss: 0.6872281063202373
Epoch: 67 | Iteration number: [1800/4518] 39% | Training loss: 0.6872294390532705
Epoch: 67 | Iteration number: [1810/4518] 40% | Training loss: 0.687228705474685
Epoch: 67 | Iteration number: [1820/4518] 40% | Training loss: 0.6872274563862727
Epoch: 67 | Iteration number: [1830/4518] 40% | Training loss: 0.6872282855497683
Epoch: 67 | Iteration number: [1840/4518] 40% | Training loss: 0.6872229303354802
Epoch: 67 | Iteration number: [1850/4518] 40% | Training loss: 0.6872160665408985
Epoch: 67 | Iteration number: [1860/4518] 41% | Training loss: 0.6872050659310434
Epoch: 67 | Iteration number: [1870/4518] 41% | Training loss: 0.6871964765105018
Epoch: 67 | Iteration number: [1880/4518] 41% | Training loss: 0.6871828516112998
Epoch: 67 | Iteration number: [1890/4518] 41% | Training loss: 0.6871780866983707
Epoch: 67 | Iteration number: [1900/4518] 42% | Training loss: 0.6871814589751394
Epoch: 67 | Iteration number: [1910/4518] 42% | Training loss: 0.6871771359630904
Epoch: 67 | Iteration number: [1920/4518] 42% | Training loss: 0.6871783565108974
Epoch: 67 | Iteration number: [1930/4518] 42% | Training loss: 0.6871801681160309
Epoch: 67 | Iteration number: [1940/4518] 42% | Training loss: 0.687176077759143
Epoch: 67 | Iteration number: [1950/4518] 43% | Training loss: 0.6871715129033114
Epoch: 67 | Iteration number: [1960/4518] 43% | Training loss: 0.6871705041552076
Epoch: 67 | Iteration number: [1970/4518] 43% | Training loss: 0.6871701140694206
Epoch: 67 | Iteration number: [1980/4518] 43% | Training loss: 0.6871699771495781
Epoch: 67 | Iteration number: [1990/4518] 44% | Training loss: 0.6871678854951906
Epoch: 67 | Iteration number: [2000/4518] 44% | Training loss: 0.6871588662266731
Epoch: 67 | Iteration number: [2010/4518] 44% | Training loss: 0.6871609095910295
Epoch: 67 | Iteration number: [2020/4518] 44% | Training loss: 0.6871621478312087
Epoch: 67 | Iteration number: [2030/4518] 44% | Training loss: 0.6871602948369651
Epoch: 67 | Iteration number: [2040/4518] 45% | Training loss: 0.6871632424639721
Epoch: 67 | Iteration number: [2050/4518] 45% | Training loss: 0.6871695321362193
Epoch: 67 | Iteration number: [2060/4518] 45% | Training loss: 0.6871687956226682
Epoch: 67 | Iteration number: [2070/4518] 45% | Training loss: 0.6871723957395784
Epoch: 67 | Iteration number: [2080/4518] 46% | Training loss: 0.6871711754741577
Epoch: 67 | Iteration number: [2090/4518] 46% | Training loss: 0.6871704774039784
Epoch: 67 | Iteration number: [2100/4518] 46% | Training loss: 0.6871721539327077
Epoch: 67 | Iteration number: [2110/4518] 46% | Training loss: 0.6871694693915652
Epoch: 67 | Iteration number: [2120/4518] 46% | Training loss: 0.6871705069856824
Epoch: 67 | Iteration number: [2130/4518] 47% | Training loss: 0.6871666392809909
Epoch: 67 | Iteration number: [2140/4518] 47% | Training loss: 0.6871689503716532
Epoch: 67 | Iteration number: [2150/4518] 47% | Training loss: 0.6871653387158416
Epoch: 67 | Iteration number: [2160/4518] 47% | Training loss: 0.6871565369820153
Epoch: 67 | Iteration number: [2170/4518] 48% | Training loss: 0.6871549728553965
Epoch: 67 | Iteration number: [2180/4518] 48% | Training loss: 0.6871478288545521
Epoch: 67 | Iteration number: [2190/4518] 48% | Training loss: 0.6871541395307131
Epoch: 67 | Iteration number: [2200/4518] 48% | Training loss: 0.6871610106663271
Epoch: 67 | Iteration number: [2210/4518] 48% | Training loss: 0.6871601573212653
Epoch: 67 | Iteration number: [2220/4518] 49% | Training loss: 0.6871616912586195
Epoch: 67 | Iteration number: [2230/4518] 49% | Training loss: 0.6871585173724478
Epoch: 67 | Iteration number: [2240/4518] 49% | Training loss: 0.687156072950789
Epoch: 67 | Iteration number: [2250/4518] 49% | Training loss: 0.6871538121435378
Epoch: 67 | Iteration number: [2260/4518] 50% | Training loss: 0.6871576227445518
Epoch: 67 | Iteration number: [2270/4518] 50% | Training loss: 0.6871583965381337
Epoch: 67 | Iteration number: [2280/4518] 50% | Training loss: 0.6871542605914568
Epoch: 67 | Iteration number: [2290/4518] 50% | Training loss: 0.6871553044652314
Epoch: 67 | Iteration number: [2300/4518] 50% | Training loss: 0.687153691649437
Epoch: 67 | Iteration number: [2310/4518] 51% | Training loss: 0.6871542090719397
Epoch: 67 | Iteration number: [2320/4518] 51% | Training loss: 0.6871530016434604
Epoch: 67 | Iteration number: [2330/4518] 51% | Training loss: 0.68715306336276
Epoch: 67 | Iteration number: [2340/4518] 51% | Training loss: 0.6871502905574619
Epoch: 67 | Iteration number: [2350/4518] 52% | Training loss: 0.6871451600308114
Epoch: 67 | Iteration number: [2360/4518] 52% | Training loss: 0.6871381737670657
Epoch: 67 | Iteration number: [2370/4518] 52% | Training loss: 0.6871350616845401
Epoch: 67 | Iteration number: [2380/4518] 52% | Training loss: 0.6871322476312893
Epoch: 67 | Iteration number: [2390/4518] 52% | Training loss: 0.6871275584069256
Epoch: 67 | Iteration number: [2400/4518] 53% | Training loss: 0.687124061609308
Epoch: 67 | Iteration number: [2410/4518] 53% | Training loss: 0.6871218805985827
Epoch: 67 | Iteration number: [2420/4518] 53% | Training loss: 0.6871128431036453
Epoch: 67 | Iteration number: [2430/4518] 53% | Training loss: 0.6871074184468744
Epoch: 67 | Iteration number: [2440/4518] 54% | Training loss: 0.6871071798879592
Epoch: 67 | Iteration number: [2450/4518] 54% | Training loss: 0.6870995763613253
Epoch: 67 | Iteration number: [2460/4518] 54% | Training loss: 0.6870966187095254
Epoch: 67 | Iteration number: [2470/4518] 54% | Training loss: 0.6870972722889441
Epoch: 67 | Iteration number: [2480/4518] 54% | Training loss: 0.6870979545097198
Epoch: 67 | Iteration number: [2490/4518] 55% | Training loss: 0.6870965277334773
Epoch: 67 | Iteration number: [2500/4518] 55% | Training loss: 0.6870946277618408
Epoch: 67 | Iteration number: [2510/4518] 55% | Training loss: 0.6870980961626745
Epoch: 67 | Iteration number: [2520/4518] 55% | Training loss: 0.6870941825092785
Epoch: 67 | Iteration number: [2530/4518] 55% | Training loss: 0.6870954814635718
Epoch: 67 | Iteration number: [2540/4518] 56% | Training loss: 0.687095665063445
Epoch: 67 | Iteration number: [2550/4518] 56% | Training loss: 0.6870999069774852
Epoch: 67 | Iteration number: [2560/4518] 56% | Training loss: 0.6871018811129034
Epoch: 67 | Iteration number: [2570/4518] 56% | Training loss: 0.6870971375634234
Epoch: 67 | Iteration number: [2580/4518] 57% | Training loss: 0.6870941835318425
Epoch: 67 | Iteration number: [2590/4518] 57% | Training loss: 0.6870901197540253
Epoch: 67 | Iteration number: [2600/4518] 57% | Training loss: 0.6870903988297169
Epoch: 67 | Iteration number: [2610/4518] 57% | Training loss: 0.6870894578224854
Epoch: 67 | Iteration number: [2620/4518] 57% | Training loss: 0.6870854502643338
Epoch: 67 | Iteration number: [2630/4518] 58% | Training loss: 0.6870861976772207
Epoch: 67 | Iteration number: [2640/4518] 58% | Training loss: 0.6870901435839407
Epoch: 67 | Iteration number: [2650/4518] 58% | Training loss: 0.6870903401104909
Epoch: 67 | Iteration number: [2660/4518] 58% | Training loss: 0.6870865304443173
Epoch: 67 | Iteration number: [2670/4518] 59% | Training loss: 0.6870886734362399
Epoch: 67 | Iteration number: [2680/4518] 59% | Training loss: 0.6870897852885189
Epoch: 67 | Iteration number: [2690/4518] 59% | Training loss: 0.6870875907431748
Epoch: 67 | Iteration number: [2700/4518] 59% | Training loss: 0.687086597636894
Epoch: 67 | Iteration number: [2710/4518] 59% | Training loss: 0.687083140466486
Epoch: 67 | Iteration number: [2720/4518] 60% | Training loss: 0.687079196927302
Epoch: 67 | Iteration number: [2730/4518] 60% | Training loss: 0.6870712662791157
Epoch: 67 | Iteration number: [2740/4518] 60% | Training loss: 0.6870676876419652
Epoch: 67 | Iteration number: [2750/4518] 60% | Training loss: 0.687067895672538
Epoch: 67 | Iteration number: [2760/4518] 61% | Training loss: 0.6870688666252123
Epoch: 67 | Iteration number: [2770/4518] 61% | Training loss: 0.687067424433326
Epoch: 67 | Iteration number: [2780/4518] 61% | Training loss: 0.6870657090660479
Epoch: 67 | Iteration number: [2790/4518] 61% | Training loss: 0.6870647572274704
Epoch: 67 | Iteration number: [2800/4518] 61% | Training loss: 0.6870664627850056
Epoch: 67 | Iteration number: [2810/4518] 62% | Training loss: 0.6870681710938966
Epoch: 67 | Iteration number: [2820/4518] 62% | Training loss: 0.6870667766594718
Epoch: 67 | Iteration number: [2830/4518] 62% | Training loss: 0.6870640821465334
Epoch: 67 | Iteration number: [2840/4518] 62% | Training loss: 0.687067401514087
Epoch: 67 | Iteration number: [2850/4518] 63% | Training loss: 0.6870689194035112
Epoch: 67 | Iteration number: [2860/4518] 63% | Training loss: 0.6870646312937037
Epoch: 67 | Iteration number: [2870/4518] 63% | Training loss: 0.6870632933199613
Epoch: 67 | Iteration number: [2880/4518] 63% | Training loss: 0.6870643284585741
Epoch: 67 | Iteration number: [2890/4518] 63% | Training loss: 0.6870629146437331
Epoch: 67 | Iteration number: [2900/4518] 64% | Training loss: 0.6870579101299418
Epoch: 67 | Iteration number: [2910/4518] 64% | Training loss: 0.6870584005547553
Epoch: 67 | Iteration number: [2920/4518] 64% | Training loss: 0.6870562848775355
Epoch: 67 | Iteration number: [2930/4518] 64% | Training loss: 0.6870535431054672
Epoch: 67 | Iteration number: [2940/4518] 65% | Training loss: 0.6870534586257675
Epoch: 67 | Iteration number: [2950/4518] 65% | Training loss: 0.6870519537238752
Epoch: 67 | Iteration number: [2960/4518] 65% | Training loss: 0.6870485114286075
Epoch: 67 | Iteration number: [2970/4518] 65% | Training loss: 0.6870498526176619
Epoch: 67 | Iteration number: [2980/4518] 65% | Training loss: 0.687049350182482
Epoch: 67 | Iteration number: [2990/4518] 66% | Training loss: 0.6870469091528634
Epoch: 67 | Iteration number: [3000/4518] 66% | Training loss: 0.6870486486554146
Epoch: 67 | Iteration number: [3010/4518] 66% | Training loss: 0.6870468302818628
Epoch: 67 | Iteration number: [3020/4518] 66% | Training loss: 0.6870415279604741
Epoch: 67 | Iteration number: [3030/4518] 67% | Training loss: 0.687038636896083
Epoch: 67 | Iteration number: [3040/4518] 67% | Training loss: 0.6870386132088147
Epoch: 67 | Iteration number: [3050/4518] 67% | Training loss: 0.6870383651725581
Epoch: 67 | Iteration number: [3060/4518] 67% | Training loss: 0.6870362959071702
Epoch: 67 | Iteration number: [3070/4518] 67% | Training loss: 0.6870390957652164
Epoch: 67 | Iteration number: [3080/4518] 68% | Training loss: 0.6870396433519078
Epoch: 67 | Iteration number: [3090/4518] 68% | Training loss: 0.6870427965924963
Epoch: 67 | Iteration number: [3100/4518] 68% | Training loss: 0.6870462446635769
Epoch: 67 | Iteration number: [3110/4518] 68% | Training loss: 0.6870442060412318
Epoch: 67 | Iteration number: [3120/4518] 69% | Training loss: 0.6870465378730725
Epoch: 67 | Iteration number: [3130/4518] 69% | Training loss: 0.6870445180624819
Epoch: 67 | Iteration number: [3140/4518] 69% | Training loss: 0.6870432004617278
Epoch: 67 | Iteration number: [3150/4518] 69% | Training loss: 0.6870405037440951
Epoch: 67 | Iteration number: [3160/4518] 69% | Training loss: 0.6870385666436787
Epoch: 67 | Iteration number: [3170/4518] 70% | Training loss: 0.6870382510337167
Epoch: 67 | Iteration number: [3180/4518] 70% | Training loss: 0.6870382417860271
Epoch: 67 | Iteration number: [3190/4518] 70% | Training loss: 0.6870343718409164
Epoch: 67 | Iteration number: [3200/4518] 70% | Training loss: 0.6870321543142199
Epoch: 67 | Iteration number: [3210/4518] 71% | Training loss: 0.6870333930970723
Epoch: 67 | Iteration number: [3220/4518] 71% | Training loss: 0.6870307153056127
Epoch: 67 | Iteration number: [3230/4518] 71% | Training loss: 0.6870314781141724
Epoch: 67 | Iteration number: [3240/4518] 71% | Training loss: 0.6870308018392987
Epoch: 67 | Iteration number: [3250/4518] 71% | Training loss: 0.6870312773814569
Epoch: 67 | Iteration number: [3260/4518] 72% | Training loss: 0.6870263188894541
Epoch: 67 | Iteration number: [3270/4518] 72% | Training loss: 0.6870239772198762
Epoch: 67 | Iteration number: [3280/4518] 72% | Training loss: 0.6870245477048362
Epoch: 67 | Iteration number: [3290/4518] 72% | Training loss: 0.6870212184078425
Epoch: 67 | Iteration number: [3300/4518] 73% | Training loss: 0.6870185059489626
Epoch: 67 | Iteration number: [3310/4518] 73% | Training loss: 0.687019958740995
Epoch: 67 | Iteration number: [3320/4518] 73% | Training loss: 0.6870188473218894
Epoch: 67 | Iteration number: [3330/4518] 73% | Training loss: 0.6870159809295837
Epoch: 67 | Iteration number: [3340/4518] 73% | Training loss: 0.6870181510191478
Epoch: 67 | Iteration number: [3350/4518] 74% | Training loss: 0.6870184756214939
Epoch: 67 | Iteration number: [3360/4518] 74% | Training loss: 0.6870179135707163
Epoch: 67 | Iteration number: [3370/4518] 74% | Training loss: 0.6870174908319637
Epoch: 67 | Iteration number: [3380/4518] 74% | Training loss: 0.6870149756324362
Epoch: 67 | Iteration number: [3390/4518] 75% | Training loss: 0.6870135850962636
Epoch: 67 | Iteration number: [3400/4518] 75% | Training loss: 0.6870134561202106
Epoch: 67 | Iteration number: [3410/4518] 75% | Training loss: 0.687014387709654
Epoch: 67 | Iteration number: [3420/4518] 75% | Training loss: 0.6870125008082529
Epoch: 67 | Iteration number: [3430/4518] 75% | Training loss: 0.6870098769838539
Epoch: 67 | Iteration number: [3440/4518] 76% | Training loss: 0.6870083883231463
Epoch: 67 | Iteration number: [3450/4518] 76% | Training loss: 0.6870066612181456
Epoch: 67 | Iteration number: [3460/4518] 76% | Training loss: 0.6870020560274235
Epoch: 67 | Iteration number: [3470/4518] 76% | Training loss: 0.6870051977785588
Epoch: 67 | Iteration number: [3480/4518] 77% | Training loss: 0.6870020408568711
Epoch: 67 | Iteration number: [3490/4518] 77% | Training loss: 0.6870000663664416
Epoch: 67 | Iteration number: [3500/4518] 77% | Training loss: 0.686997625197683
Epoch: 67 | Iteration number: [3510/4518] 77% | Training loss: 0.6869994898467322
Epoch: 67 | Iteration number: [3520/4518] 77% | Training loss: 0.6870005295696584
Epoch: 67 | Iteration number: [3530/4518] 78% | Training loss: 0.6869968596497609
Epoch: 67 | Iteration number: [3540/4518] 78% | Training loss: 0.6869952818936548
Epoch: 67 | Iteration number: [3550/4518] 78% | Training loss: 0.6869935084732486
Epoch: 67 | Iteration number: [3560/4518] 78% | Training loss: 0.6869949094030294
Epoch: 67 | Iteration number: [3570/4518] 79% | Training loss: 0.6869954806249015
Epoch: 67 | Iteration number: [3580/4518] 79% | Training loss: 0.6869954016954539
Epoch: 67 | Iteration number: [3590/4518] 79% | Training loss: 0.6869941808221068
Epoch: 67 | Iteration number: [3600/4518] 79% | Training loss: 0.6869920942849583
Epoch: 67 | Iteration number: [3610/4518] 79% | Training loss: 0.6869925049038145
Epoch: 67 | Iteration number: [3620/4518] 80% | Training loss: 0.6869893879521618
Epoch: 67 | Iteration number: [3630/4518] 80% | Training loss: 0.6869924565977301
Epoch: 67 | Iteration number: [3640/4518] 80% | Training loss: 0.6869894342108087
Epoch: 67 | Iteration number: [3650/4518] 80% | Training loss: 0.686987620477807
Epoch: 67 | Iteration number: [3660/4518] 81% | Training loss: 0.6869864056182038
Epoch: 67 | Iteration number: [3670/4518] 81% | Training loss: 0.6869879253391349
Epoch: 67 | Iteration number: [3680/4518] 81% | Training loss: 0.6869881319448999
Epoch: 67 | Iteration number: [3690/4518] 81% | Training loss: 0.6869902195646188
Epoch: 67 | Iteration number: [3700/4518] 81% | Training loss: 0.6869888248959103
Epoch: 67 | Iteration number: [3710/4518] 82% | Training loss: 0.6869889444900009
Epoch: 67 | Iteration number: [3720/4518] 82% | Training loss: 0.6869872435767164
Epoch: 67 | Iteration number: [3730/4518] 82% | Training loss: 0.6869873538413572
Epoch: 67 | Iteration number: [3740/4518] 82% | Training loss: 0.6869874203109486
Epoch: 67 | Iteration number: [3750/4518] 83% | Training loss: 0.6869867835839589
Epoch: 67 | Iteration number: [3760/4518] 83% | Training loss: 0.6869861319819663
Epoch: 67 | Iteration number: [3770/4518] 83% | Training loss: 0.6869833276347709
Epoch: 67 | Iteration number: [3780/4518] 83% | Training loss: 0.6869814544600784
Epoch: 67 | Iteration number: [3790/4518] 83% | Training loss: 0.6869812817875502
Epoch: 67 | Iteration number: [3800/4518] 84% | Training loss: 0.6869817335354654
Epoch: 67 | Iteration number: [3810/4518] 84% | Training loss: 0.6869838348523838
Epoch: 67 | Iteration number: [3820/4518] 84% | Training loss: 0.6869824870094579
Epoch: 67 | Iteration number: [3830/4518] 84% | Training loss: 0.6869826491134285
Epoch: 67 | Iteration number: [3840/4518] 84% | Training loss: 0.6869827876177926
Epoch: 67 | Iteration number: [3850/4518] 85% | Training loss: 0.6869839250112508
Epoch: 67 | Iteration number: [3860/4518] 85% | Training loss: 0.686987060323898
Epoch: 67 | Iteration number: [3870/4518] 85% | Training loss: 0.68698483206505
Epoch: 67 | Iteration number: [3880/4518] 85% | Training loss: 0.6869842761724265
Epoch: 67 | Iteration number: [3890/4518] 86% | Training loss: 0.686983694071022
Epoch: 67 | Iteration number: [3900/4518] 86% | Training loss: 0.6869802878300348
Epoch: 67 | Iteration number: [3910/4518] 86% | Training loss: 0.6869799412729795
Epoch: 67 | Iteration number: [3920/4518] 86% | Training loss: 0.6869777324400386
Epoch: 67 | Iteration number: [3930/4518] 86% | Training loss: 0.6869744454631369
Epoch: 67 | Iteration number: [3940/4518] 87% | Training loss: 0.6869743596932609
Epoch: 67 | Iteration number: [3950/4518] 87% | Training loss: 0.6869752118104621
Epoch: 67 | Iteration number: [3960/4518] 87% | Training loss: 0.6869769433833132
Epoch: 67 | Iteration number: [3970/4518] 87% | Training loss: 0.6869762566437949
Epoch: 67 | Iteration number: [3980/4518] 88% | Training loss: 0.6869776066523701
Epoch: 67 | Iteration number: [3990/4518] 88% | Training loss: 0.6869771771711813
Epoch: 67 | Iteration number: [4000/4518] 88% | Training loss: 0.6869776726216078
Epoch: 67 | Iteration number: [4010/4518] 88% | Training loss: 0.6869761748058243
Epoch: 67 | Iteration number: [4020/4518] 88% | Training loss: 0.686977054630939
Epoch: 67 | Iteration number: [4030/4518] 89% | Training loss: 0.6869737426932929
Epoch: 67 | Iteration number: [4040/4518] 89% | Training loss: 0.6869736646661664
Epoch: 67 | Iteration number: [4050/4518] 89% | Training loss: 0.6869712270042043
Epoch: 67 | Iteration number: [4060/4518] 89% | Training loss: 0.686972681333866
Epoch: 67 | Iteration number: [4070/4518] 90% | Training loss: 0.686973403156243
Epoch: 67 | Iteration number: [4080/4518] 90% | Training loss: 0.6869715568189527
Epoch: 67 | Iteration number: [4090/4518] 90% | Training loss: 0.6869732804578208
Epoch: 67 | Iteration number: [4100/4518] 90% | Training loss: 0.6869722125006885
Epoch: 67 | Iteration number: [4110/4518] 90% | Training loss: 0.6869724713682839
Epoch: 67 | Iteration number: [4120/4518] 91% | Training loss: 0.6869716602911069
Epoch: 67 | Iteration number: [4130/4518] 91% | Training loss: 0.686972132404549
Epoch: 67 | Iteration number: [4140/4518] 91% | Training loss: 0.6869724577751712
Epoch: 67 | Iteration number: [4150/4518] 91% | Training loss: 0.6869729054979531
Epoch: 67 | Iteration number: [4160/4518] 92% | Training loss: 0.6869699945530066
Epoch: 67 | Iteration number: [4170/4518] 92% | Training loss: 0.686971873788239
Epoch: 67 | Iteration number: [4180/4518] 92% | Training loss: 0.6869712913720801
Epoch: 67 | Iteration number: [4190/4518] 92% | Training loss: 0.6869708647449148
Epoch: 67 | Iteration number: [4200/4518] 92% | Training loss: 0.6869714418337458
Epoch: 67 | Iteration number: [4210/4518] 93% | Training loss: 0.6869706494649629
Epoch: 67 | Iteration number: [4220/4518] 93% | Training loss: 0.6869672666652508
Epoch: 67 | Iteration number: [4230/4518] 93% | Training loss: 0.6869700410546422
Epoch: 67 | Iteration number: [4240/4518] 93% | Training loss: 0.6869684160880323
Epoch: 67 | Iteration number: [4250/4518] 94% | Training loss: 0.6869664483491112
Epoch: 67 | Iteration number: [4260/4518] 94% | Training loss: 0.6869662983736522
Epoch: 67 | Iteration number: [4270/4518] 94% | Training loss: 0.6869641134973432
Epoch: 67 | Iteration number: [4280/4518] 94% | Training loss: 0.6869623207182528
Epoch: 67 | Iteration number: [4290/4518] 94% | Training loss: 0.6869627293312188
Epoch: 67 | Iteration number: [4300/4518] 95% | Training loss: 0.6869598262393197
Epoch: 67 | Iteration number: [4310/4518] 95% | Training loss: 0.6869568691591099
Epoch: 67 | Iteration number: [4320/4518] 95% | Training loss: 0.6869533199678969
Epoch: 67 | Iteration number: [4330/4518] 95% | Training loss: 0.6869486527134585
Epoch: 67 | Iteration number: [4340/4518] 96% | Training loss: 0.686945916128598
Epoch: 67 | Iteration number: [4350/4518] 96% | Training loss: 0.6869441001031591
Epoch: 67 | Iteration number: [4360/4518] 96% | Training loss: 0.6869412770101784
Epoch: 67 | Iteration number: [4370/4518] 96% | Training loss: 0.6869421193610612
Epoch: 67 | Iteration number: [4380/4518] 96% | Training loss: 0.6869430389850651
Epoch: 67 | Iteration number: [4390/4518] 97% | Training loss: 0.686943442226814
Epoch: 67 | Iteration number: [4400/4518] 97% | Training loss: 0.6869430250606754
Epoch: 67 | Iteration number: [4410/4518] 97% | Training loss: 0.686941269019834
Epoch: 67 | Iteration number: [4420/4518] 97% | Training loss: 0.6869398885587761
Epoch: 67 | Iteration number: [4430/4518] 98% | Training loss: 0.6869371187606191
Epoch: 67 | Iteration number: [4440/4518] 98% | Training loss: 0.6869345010803627
Epoch: 67 | Iteration number: [4450/4518] 98% | Training loss: 0.6869340393650398
Epoch: 67 | Iteration number: [4460/4518] 98% | Training loss: 0.6869360033172128
Epoch: 67 | Iteration number: [4470/4518] 98% | Training loss: 0.6869365168097835
Epoch: 67 | Iteration number: [4480/4518] 99% | Training loss: 0.6869369762018323
Epoch: 67 | Iteration number: [4490/4518] 99% | Training loss: 0.6869364443892626
Epoch: 67 | Iteration number: [4500/4518] 99% | Training loss: 0.6869373340474235
Epoch: 67 | Iteration number: [4510/4518] 99% | Training loss: 0.686935550146251

 End of epoch: 67 | Train Loss: 0.6867825663580521 | Training Time: 640 

 End of epoch: 67 | Eval Loss: 0.6898855262873124 | Evaluating Time: 17 
Epoch: 68 | Iteration number: [10/4518] 0% | Training loss: 0.7549412071704864
Epoch: 68 | Iteration number: [20/4518] 0% | Training loss: 0.7208753615617752
Epoch: 68 | Iteration number: [30/4518] 0% | Training loss: 0.7097180783748627
Epoch: 68 | Iteration number: [40/4518] 0% | Training loss: 0.7037772327661515
Epoch: 68 | Iteration number: [50/4518] 1% | Training loss: 0.7002577769756317
Epoch: 68 | Iteration number: [60/4518] 1% | Training loss: 0.6981182078520457
Epoch: 68 | Iteration number: [70/4518] 1% | Training loss: 0.6963558145931789
Epoch: 68 | Iteration number: [80/4518] 1% | Training loss: 0.6951362185180188
Epoch: 68 | Iteration number: [90/4518] 1% | Training loss: 0.6941660132673052
Epoch: 68 | Iteration number: [100/4518] 2% | Training loss: 0.6934276473522186
Epoch: 68 | Iteration number: [110/4518] 2% | Training loss: 0.6928012842481787
Epoch: 68 | Iteration number: [120/4518] 2% | Training loss: 0.6924407203992208
Epoch: 68 | Iteration number: [130/4518] 2% | Training loss: 0.6919447050644801
Epoch: 68 | Iteration number: [140/4518] 3% | Training loss: 0.6914601807083403
Epoch: 68 | Iteration number: [150/4518] 3% | Training loss: 0.6911377664407095
Epoch: 68 | Iteration number: [160/4518] 3% | Training loss: 0.6908163968473673
Epoch: 68 | Iteration number: [170/4518] 3% | Training loss: 0.690580406259088
Epoch: 68 | Iteration number: [180/4518] 3% | Training loss: 0.6903666790988711
Epoch: 68 | Iteration number: [190/4518] 4% | Training loss: 0.690201913683038
Epoch: 68 | Iteration number: [200/4518] 4% | Training loss: 0.6900653627514839
Epoch: 68 | Iteration number: [210/4518] 4% | Training loss: 0.6899667305605752
Epoch: 68 | Iteration number: [220/4518] 4% | Training loss: 0.6897885905070739
Epoch: 68 | Iteration number: [230/4518] 5% | Training loss: 0.6895924827326899
Epoch: 68 | Iteration number: [240/4518] 5% | Training loss: 0.6894692415992419
Epoch: 68 | Iteration number: [250/4518] 5% | Training loss: 0.6893728287220001
Epoch: 68 | Iteration number: [260/4518] 5% | Training loss: 0.6893125093900241
Epoch: 68 | Iteration number: [270/4518] 5% | Training loss: 0.6892212254029734
Epoch: 68 | Iteration number: [280/4518] 6% | Training loss: 0.6891208167587007
Epoch: 68 | Iteration number: [290/4518] 6% | Training loss: 0.6890506411420888
Epoch: 68 | Iteration number: [300/4518] 6% | Training loss: 0.6889699008067449
Epoch: 68 | Iteration number: [310/4518] 6% | Training loss: 0.6888668412162412
Epoch: 68 | Iteration number: [320/4518] 7% | Training loss: 0.6888053465634585
Epoch: 68 | Iteration number: [330/4518] 7% | Training loss: 0.6887218921473532
Epoch: 68 | Iteration number: [340/4518] 7% | Training loss: 0.6886827139293447
Epoch: 68 | Iteration number: [350/4518] 7% | Training loss: 0.6886131334304809
Epoch: 68 | Iteration number: [360/4518] 7% | Training loss: 0.688562393354045
Epoch: 68 | Iteration number: [370/4518] 8% | Training loss: 0.688489622038764
Epoch: 68 | Iteration number: [380/4518] 8% | Training loss: 0.6884275863045141
Epoch: 68 | Iteration number: [390/4518] 8% | Training loss: 0.6884185068118267
Epoch: 68 | Iteration number: [400/4518] 8% | Training loss: 0.6883720457553864
Epoch: 68 | Iteration number: [410/4518] 9% | Training loss: 0.6883474752670381
Epoch: 68 | Iteration number: [420/4518] 9% | Training loss: 0.6883339304299582
Epoch: 68 | Iteration number: [430/4518] 9% | Training loss: 0.6882937446583149
Epoch: 68 | Iteration number: [440/4518] 9% | Training loss: 0.6882134841247038
Epoch: 68 | Iteration number: [450/4518] 9% | Training loss: 0.6881921013196309
Epoch: 68 | Iteration number: [460/4518] 10% | Training loss: 0.6881664204856623
Epoch: 68 | Iteration number: [470/4518] 10% | Training loss: 0.6881359450360562
Epoch: 68 | Iteration number: [480/4518] 10% | Training loss: 0.6881208036094904
Epoch: 68 | Iteration number: [490/4518] 10% | Training loss: 0.6881138009684427
Epoch: 68 | Iteration number: [500/4518] 11% | Training loss: 0.6880811287164688
Epoch: 68 | Iteration number: [510/4518] 11% | Training loss: 0.688037043576147
Epoch: 68 | Iteration number: [520/4518] 11% | Training loss: 0.6880136661804639
Epoch: 68 | Iteration number: [530/4518] 11% | Training loss: 0.6879477094929173
Epoch: 68 | Iteration number: [540/4518] 11% | Training loss: 0.6879301072270781
Epoch: 68 | Iteration number: [550/4518] 12% | Training loss: 0.687897601777857
Epoch: 68 | Iteration number: [560/4518] 12% | Training loss: 0.6878786250948906
Epoch: 68 | Iteration number: [570/4518] 12% | Training loss: 0.6878749243000097
Epoch: 68 | Iteration number: [580/4518] 12% | Training loss: 0.6878689052729771
Epoch: 68 | Iteration number: [590/4518] 13% | Training loss: 0.6878438719248368
Epoch: 68 | Iteration number: [600/4518] 13% | Training loss: 0.6878307066361109
Epoch: 68 | Iteration number: [610/4518] 13% | Training loss: 0.687814886843572
Epoch: 68 | Iteration number: [620/4518] 13% | Training loss: 0.6877930677706195
Epoch: 68 | Iteration number: [630/4518] 13% | Training loss: 0.6877731432990423
Epoch: 68 | Iteration number: [640/4518] 14% | Training loss: 0.6877464583143592
Epoch: 68 | Iteration number: [650/4518] 14% | Training loss: 0.687734445975377
Epoch: 68 | Iteration number: [660/4518] 14% | Training loss: 0.6877273469260244
Epoch: 68 | Iteration number: [670/4518] 14% | Training loss: 0.6877135857717315
Epoch: 68 | Iteration number: [680/4518] 15% | Training loss: 0.68770281137789
Epoch: 68 | Iteration number: [690/4518] 15% | Training loss: 0.6876726799253104
Epoch: 68 | Iteration number: [700/4518] 15% | Training loss: 0.6876336153915951
Epoch: 68 | Iteration number: [710/4518] 15% | Training loss: 0.6876299787575091
Epoch: 68 | Iteration number: [720/4518] 15% | Training loss: 0.6876223998765151
Epoch: 68 | Iteration number: [730/4518] 16% | Training loss: 0.6876146318977826
Epoch: 68 | Iteration number: [740/4518] 16% | Training loss: 0.6876019213650678
Epoch: 68 | Iteration number: [750/4518] 16% | Training loss: 0.6875989000002544
Epoch: 68 | Iteration number: [760/4518] 16% | Training loss: 0.6875953016312499
Epoch: 68 | Iteration number: [770/4518] 17% | Training loss: 0.6875881788018462
Epoch: 68 | Iteration number: [780/4518] 17% | Training loss: 0.6875938380375887
Epoch: 68 | Iteration number: [790/4518] 17% | Training loss: 0.6875911429713044
Epoch: 68 | Iteration number: [800/4518] 17% | Training loss: 0.6875802931189537
Epoch: 68 | Iteration number: [810/4518] 17% | Training loss: 0.6875667162883429
Epoch: 68 | Iteration number: [820/4518] 18% | Training loss: 0.6875645685486678
Epoch: 68 | Iteration number: [830/4518] 18% | Training loss: 0.687543721945889
Epoch: 68 | Iteration number: [840/4518] 18% | Training loss: 0.6875247540928069
Epoch: 68 | Iteration number: [850/4518] 18% | Training loss: 0.6874987522994771
Epoch: 68 | Iteration number: [860/4518] 19% | Training loss: 0.687474692976752
Epoch: 68 | Iteration number: [870/4518] 19% | Training loss: 0.6874676003538329
Epoch: 68 | Iteration number: [880/4518] 19% | Training loss: 0.6874642093073238
Epoch: 68 | Iteration number: [890/4518] 19% | Training loss: 0.6874481217914753
Epoch: 68 | Iteration number: [900/4518] 19% | Training loss: 0.6874376961257722
Epoch: 68 | Iteration number: [910/4518] 20% | Training loss: 0.6874439675074357
Epoch: 68 | Iteration number: [920/4518] 20% | Training loss: 0.6874350562043812
Epoch: 68 | Iteration number: [930/4518] 20% | Training loss: 0.6874212303469258
Epoch: 68 | Iteration number: [940/4518] 20% | Training loss: 0.6874217055579449
Epoch: 68 | Iteration number: [950/4518] 21% | Training loss: 0.6874032419606259
Epoch: 68 | Iteration number: [960/4518] 21% | Training loss: 0.687404731909434
Epoch: 68 | Iteration number: [970/4518] 21% | Training loss: 0.6874036259257916
Epoch: 68 | Iteration number: [980/4518] 21% | Training loss: 0.6873869102828357
Epoch: 68 | Iteration number: [990/4518] 21% | Training loss: 0.6873906738228268
Epoch: 68 | Iteration number: [1000/4518] 22% | Training loss: 0.6873921125531196
Epoch: 68 | Iteration number: [1010/4518] 22% | Training loss: 0.6873934916930624
Epoch: 68 | Iteration number: [1020/4518] 22% | Training loss: 0.6873869129840066
Epoch: 68 | Iteration number: [1030/4518] 22% | Training loss: 0.6873801540981219
Epoch: 68 | Iteration number: [1040/4518] 23% | Training loss: 0.6873854979299582
Epoch: 68 | Iteration number: [1050/4518] 23% | Training loss: 0.6873711892536708
Epoch: 68 | Iteration number: [1060/4518] 23% | Training loss: 0.6873476404626414
Epoch: 68 | Iteration number: [1070/4518] 23% | Training loss: 0.6873443834135465
Epoch: 68 | Iteration number: [1080/4518] 23% | Training loss: 0.6873457778935079
Epoch: 68 | Iteration number: [1090/4518] 24% | Training loss: 0.687343244322943
Epoch: 68 | Iteration number: [1100/4518] 24% | Training loss: 0.6873436722430316
Epoch: 68 | Iteration number: [1110/4518] 24% | Training loss: 0.6873489053399713
Epoch: 68 | Iteration number: [1120/4518] 24% | Training loss: 0.6873519538236516
Epoch: 68 | Iteration number: [1130/4518] 25% | Training loss: 0.6873423190770951
Epoch: 68 | Iteration number: [1140/4518] 25% | Training loss: 0.6873347569453089
Epoch: 68 | Iteration number: [1150/4518] 25% | Training loss: 0.6873280910823656
Epoch: 68 | Iteration number: [1160/4518] 25% | Training loss: 0.6873232030149163
Epoch: 68 | Iteration number: [1170/4518] 25% | Training loss: 0.6873067245524154
Epoch: 68 | Iteration number: [1180/4518] 26% | Training loss: 0.6872937554525117
Epoch: 68 | Iteration number: [1190/4518] 26% | Training loss: 0.6872905730199413
Epoch: 68 | Iteration number: [1200/4518] 26% | Training loss: 0.6872857156892618
Epoch: 68 | Iteration number: [1210/4518] 26% | Training loss: 0.687280063195662
Epoch: 68 | Iteration number: [1220/4518] 27% | Training loss: 0.687275842565005
Epoch: 68 | Iteration number: [1230/4518] 27% | Training loss: 0.687261460709378
Epoch: 68 | Iteration number: [1240/4518] 27% | Training loss: 0.6872502392338168
Epoch: 68 | Iteration number: [1250/4518] 27% | Training loss: 0.6872436021327972
Epoch: 68 | Iteration number: [1260/4518] 27% | Training loss: 0.6872372937580896
Epoch: 68 | Iteration number: [1270/4518] 28% | Training loss: 0.6872399075763432
Epoch: 68 | Iteration number: [1280/4518] 28% | Training loss: 0.6872353272512555
Epoch: 68 | Iteration number: [1290/4518] 28% | Training loss: 0.6872225756793059
Epoch: 68 | Iteration number: [1300/4518] 28% | Training loss: 0.6872196793097716
Epoch: 68 | Iteration number: [1310/4518] 28% | Training loss: 0.6872167051293467
Epoch: 68 | Iteration number: [1320/4518] 29% | Training loss: 0.6872123329476877
Epoch: 68 | Iteration number: [1330/4518] 29% | Training loss: 0.6872178982971306
Epoch: 68 | Iteration number: [1340/4518] 29% | Training loss: 0.6872220367193222
Epoch: 68 | Iteration number: [1350/4518] 29% | Training loss: 0.6872111483414968
Epoch: 68 | Iteration number: [1360/4518] 30% | Training loss: 0.6872088181621888
Epoch: 68 | Iteration number: [1370/4518] 30% | Training loss: 0.6872059163385934
Epoch: 68 | Iteration number: [1380/4518] 30% | Training loss: 0.6871966668229172
Epoch: 68 | Iteration number: [1390/4518] 30% | Training loss: 0.687192492219184
Epoch: 68 | Iteration number: [1400/4518] 30% | Training loss: 0.6871899173089436
Epoch: 68 | Iteration number: [1410/4518] 31% | Training loss: 0.687181882232639
Epoch: 68 | Iteration number: [1420/4518] 31% | Training loss: 0.6871773643392912
Epoch: 68 | Iteration number: [1430/4518] 31% | Training loss: 0.6871651175138833
Epoch: 68 | Iteration number: [1440/4518] 31% | Training loss: 0.6871645415408744
Epoch: 68 | Iteration number: [1450/4518] 32% | Training loss: 0.6871652881441446
Epoch: 68 | Iteration number: [1460/4518] 32% | Training loss: 0.6871597724418118
Epoch: 68 | Iteration number: [1470/4518] 32% | Training loss: 0.6871634332095685
Epoch: 68 | Iteration number: [1480/4518] 32% | Training loss: 0.6871529688303535
Epoch: 68 | Iteration number: [1490/4518] 32% | Training loss: 0.6871473198769077
Epoch: 68 | Iteration number: [1500/4518] 33% | Training loss: 0.6871479665835698
Epoch: 68 | Iteration number: [1510/4518] 33% | Training loss: 0.6871396131073402
Epoch: 68 | Iteration number: [1520/4518] 33% | Training loss: 0.6871371830372434
Epoch: 68 | Iteration number: [1530/4518] 33% | Training loss: 0.6871387998652614
Epoch: 68 | Iteration number: [1540/4518] 34% | Training loss: 0.6871321271379273
Epoch: 68 | Iteration number: [1550/4518] 34% | Training loss: 0.687127995567937
Epoch: 68 | Iteration number: [1560/4518] 34% | Training loss: 0.6871242085328468
Epoch: 68 | Iteration number: [1570/4518] 34% | Training loss: 0.6871238005009427
Epoch: 68 | Iteration number: [1580/4518] 34% | Training loss: 0.6871185762218283
Epoch: 68 | Iteration number: [1590/4518] 35% | Training loss: 0.6871131778887982
Epoch: 68 | Iteration number: [1600/4518] 35% | Training loss: 0.6871106776222586
Epoch: 68 | Iteration number: [1610/4518] 35% | Training loss: 0.6871077541979204
Epoch: 68 | Iteration number: [1620/4518] 35% | Training loss: 0.6871124523657339
Epoch: 68 | Iteration number: [1630/4518] 36% | Training loss: 0.6871123070731485
Epoch: 68 | Iteration number: [1640/4518] 36% | Training loss: 0.6871177786734046
Epoch: 68 | Iteration number: [1650/4518] 36% | Training loss: 0.6871163508747563
Epoch: 68 | Iteration number: [1660/4518] 36% | Training loss: 0.6871112576091146
Epoch: 68 | Iteration number: [1670/4518] 36% | Training loss: 0.6871133880700894
Epoch: 68 | Iteration number: [1680/4518] 37% | Training loss: 0.6871112737627256
Epoch: 68 | Iteration number: [1690/4518] 37% | Training loss: 0.6871048479390568
Epoch: 68 | Iteration number: [1700/4518] 37% | Training loss: 0.6871006987024756
Epoch: 68 | Iteration number: [1710/4518] 37% | Training loss: 0.6870943976773156
Epoch: 68 | Iteration number: [1720/4518] 38% | Training loss: 0.6870840875561848
Epoch: 68 | Iteration number: [1730/4518] 38% | Training loss: 0.6870866394800947
Epoch: 68 | Iteration number: [1740/4518] 38% | Training loss: 0.6870805861963623
Epoch: 68 | Iteration number: [1750/4518] 38% | Training loss: 0.6870726734910693
Epoch: 68 | Iteration number: [1760/4518] 38% | Training loss: 0.6870742532678625
Epoch: 68 | Iteration number: [1770/4518] 39% | Training loss: 0.6870721856753031
Epoch: 68 | Iteration number: [1780/4518] 39% | Training loss: 0.6870720519108718
Epoch: 68 | Iteration number: [1790/4518] 39% | Training loss: 0.6870705602555301
Epoch: 68 | Iteration number: [1800/4518] 39% | Training loss: 0.6870717575483852
Epoch: 68 | Iteration number: [1810/4518] 40% | Training loss: 0.6870741807294813
Epoch: 68 | Iteration number: [1820/4518] 40% | Training loss: 0.6870767216106037
Epoch: 68 | Iteration number: [1830/4518] 40% | Training loss: 0.6870722681446805
Epoch: 68 | Iteration number: [1840/4518] 40% | Training loss: 0.6870709828708483
Epoch: 68 | Iteration number: [1850/4518] 40% | Training loss: 0.6870723292956481
Epoch: 68 | Iteration number: [1860/4518] 41% | Training loss: 0.6870667680296847
Epoch: 68 | Iteration number: [1870/4518] 41% | Training loss: 0.6870654732467019
Epoch: 68 | Iteration number: [1880/4518] 41% | Training loss: 0.6870716568954447
Epoch: 68 | Iteration number: [1890/4518] 41% | Training loss: 0.687072250483528
Epoch: 68 | Iteration number: [1900/4518] 42% | Training loss: 0.6870727475065934
Epoch: 68 | Iteration number: [1910/4518] 42% | Training loss: 0.68706754664476
Epoch: 68 | Iteration number: [1920/4518] 42% | Training loss: 0.6870597206676999
Epoch: 68 | Iteration number: [1930/4518] 42% | Training loss: 0.68705984724618
Epoch: 68 | Iteration number: [1940/4518] 42% | Training loss: 0.6870546609777766
Epoch: 68 | Iteration number: [1950/4518] 43% | Training loss: 0.6870549006951161
Epoch: 68 | Iteration number: [1960/4518] 43% | Training loss: 0.6870484304063175
Epoch: 68 | Iteration number: [1970/4518] 43% | Training loss: 0.6870475690074378
Epoch: 68 | Iteration number: [1980/4518] 43% | Training loss: 0.6870467003246751
Epoch: 68 | Iteration number: [1990/4518] 44% | Training loss: 0.6870421789399344
Epoch: 68 | Iteration number: [2000/4518] 44% | Training loss: 0.6870351687073708
Epoch: 68 | Iteration number: [2010/4518] 44% | Training loss: 0.6870368477420428
Epoch: 68 | Iteration number: [2020/4518] 44% | Training loss: 0.6870309743845817
Epoch: 68 | Iteration number: [2030/4518] 44% | Training loss: 0.6870382091681946
Epoch: 68 | Iteration number: [2040/4518] 45% | Training loss: 0.6870327931993148
Epoch: 68 | Iteration number: [2050/4518] 45% | Training loss: 0.6870307077140343
Epoch: 68 | Iteration number: [2060/4518] 45% | Training loss: 0.6870313032159527
Epoch: 68 | Iteration number: [2070/4518] 45% | Training loss: 0.6870280668067471
Epoch: 68 | Iteration number: [2080/4518] 46% | Training loss: 0.6870310355550968
Epoch: 68 | Iteration number: [2090/4518] 46% | Training loss: 0.687026386683067
Epoch: 68 | Iteration number: [2100/4518] 46% | Training loss: 0.6870261081627437
Epoch: 68 | Iteration number: [2110/4518] 46% | Training loss: 0.6870185696683224
Epoch: 68 | Iteration number: [2120/4518] 46% | Training loss: 0.6870182245688619
Epoch: 68 | Iteration number: [2130/4518] 47% | Training loss: 0.6870221160667044
Epoch: 68 | Iteration number: [2140/4518] 47% | Training loss: 0.6870196743824771
Epoch: 68 | Iteration number: [2150/4518] 47% | Training loss: 0.6870123668049657
Epoch: 68 | Iteration number: [2160/4518] 47% | Training loss: 0.6870139710881092
Epoch: 68 | Iteration number: [2170/4518] 48% | Training loss: 0.6870192511839801
Epoch: 68 | Iteration number: [2180/4518] 48% | Training loss: 0.6870202616267248
Epoch: 68 | Iteration number: [2190/4518] 48% | Training loss: 0.6870241699697764
Epoch: 68 | Iteration number: [2200/4518] 48% | Training loss: 0.6870225223357027
Epoch: 68 | Iteration number: [2210/4518] 48% | Training loss: 0.6870231789431421
Epoch: 68 | Iteration number: [2220/4518] 49% | Training loss: 0.6870267662379119
Epoch: 68 | Iteration number: [2230/4518] 49% | Training loss: 0.6870219676216621
Epoch: 68 | Iteration number: [2240/4518] 49% | Training loss: 0.6870203866490296
Epoch: 68 | Iteration number: [2250/4518] 49% | Training loss: 0.6870195523897806
Epoch: 68 | Iteration number: [2260/4518] 50% | Training loss: 0.6870181985133517
Epoch: 68 | Iteration number: [2270/4518] 50% | Training loss: 0.6870088960368202
Epoch: 68 | Iteration number: [2280/4518] 50% | Training loss: 0.6870091888988227
Epoch: 68 | Iteration number: [2290/4518] 50% | Training loss: 0.687009455413277
Epoch: 68 | Iteration number: [2300/4518] 50% | Training loss: 0.6870089886758638
Epoch: 68 | Iteration number: [2310/4518] 51% | Training loss: 0.6869961582737052
Epoch: 68 | Iteration number: [2320/4518] 51% | Training loss: 0.6869936626019149
Epoch: 68 | Iteration number: [2330/4518] 51% | Training loss: 0.6869859456248549
Epoch: 68 | Iteration number: [2340/4518] 51% | Training loss: 0.6869816685588951
Epoch: 68 | Iteration number: [2350/4518] 52% | Training loss: 0.6869808699475958
Epoch: 68 | Iteration number: [2360/4518] 52% | Training loss: 0.6869789392513744
Epoch: 68 | Iteration number: [2370/4518] 52% | Training loss: 0.6869710415475982
Epoch: 68 | Iteration number: [2380/4518] 52% | Training loss: 0.6869751103785859
Epoch: 68 | Iteration number: [2390/4518] 52% | Training loss: 0.6869750421915094
Epoch: 68 | Iteration number: [2400/4518] 53% | Training loss: 0.6869749321540197
Epoch: 68 | Iteration number: [2410/4518] 53% | Training loss: 0.6869749164185583
Epoch: 68 | Iteration number: [2420/4518] 53% | Training loss: 0.6869775295257569
Epoch: 68 | Iteration number: [2430/4518] 53% | Training loss: 0.6869775734075303
Epoch: 68 | Iteration number: [2440/4518] 54% | Training loss: 0.6869812572344405
Epoch: 68 | Iteration number: [2450/4518] 54% | Training loss: 0.6869837200398348
Epoch: 68 | Iteration number: [2460/4518] 54% | Training loss: 0.6869844703412638
Epoch: 68 | Iteration number: [2470/4518] 54% | Training loss: 0.6869844437128136
Epoch: 68 | Iteration number: [2480/4518] 54% | Training loss: 0.6869819187108548
Epoch: 68 | Iteration number: [2490/4518] 55% | Training loss: 0.6869830118125702
Epoch: 68 | Iteration number: [2500/4518] 55% | Training loss: 0.6869885739326477
Epoch: 68 | Iteration number: [2510/4518] 55% | Training loss: 0.6869854897141932
Epoch: 68 | Iteration number: [2520/4518] 55% | Training loss: 0.686981262976215
Epoch: 68 | Iteration number: [2530/4518] 55% | Training loss: 0.6869815553365489
Epoch: 68 | Iteration number: [2540/4518] 56% | Training loss: 0.6869834484781806
Epoch: 68 | Iteration number: [2550/4518] 56% | Training loss: 0.6869805479984658
Epoch: 68 | Iteration number: [2560/4518] 56% | Training loss: 0.686974978283979
Epoch: 68 | Iteration number: [2570/4518] 56% | Training loss: 0.6869746097098992
Epoch: 68 | Iteration number: [2580/4518] 57% | Training loss: 0.6869789733443149
Epoch: 68 | Iteration number: [2590/4518] 57% | Training loss: 0.6869752672418205
Epoch: 68 | Iteration number: [2600/4518] 57% | Training loss: 0.6869743969119512
Epoch: 68 | Iteration number: [2610/4518] 57% | Training loss: 0.6869694552659075
Epoch: 68 | Iteration number: [2620/4518] 57% | Training loss: 0.6869669256547025
Epoch: 68 | Iteration number: [2630/4518] 58% | Training loss: 0.6869656265461853
Epoch: 68 | Iteration number: [2640/4518] 58% | Training loss: 0.6869705305406542
Epoch: 68 | Iteration number: [2650/4518] 58% | Training loss: 0.6869695194037455
Epoch: 68 | Iteration number: [2660/4518] 58% | Training loss: 0.6869702770073611
Epoch: 68 | Iteration number: [2670/4518] 59% | Training loss: 0.686969905689861
Epoch: 68 | Iteration number: [2680/4518] 59% | Training loss: 0.6869715239352254
Epoch: 68 | Iteration number: [2690/4518] 59% | Training loss: 0.6869720956206765
Epoch: 68 | Iteration number: [2700/4518] 59% | Training loss: 0.6869749961296717
Epoch: 68 | Iteration number: [2710/4518] 59% | Training loss: 0.6869707365537482
Epoch: 68 | Iteration number: [2720/4518] 60% | Training loss: 0.6869669453843551
Epoch: 68 | Iteration number: [2730/4518] 60% | Training loss: 0.6869669041572473
Epoch: 68 | Iteration number: [2740/4518] 60% | Training loss: 0.6869638620719423
Epoch: 68 | Iteration number: [2750/4518] 60% | Training loss: 0.6869675281914798
Epoch: 68 | Iteration number: [2760/4518] 61% | Training loss: 0.6869639439643294
Epoch: 68 | Iteration number: [2770/4518] 61% | Training loss: 0.6869659296011666
Epoch: 68 | Iteration number: [2780/4518] 61% | Training loss: 0.6869664571696906
Epoch: 68 | Iteration number: [2790/4518] 61% | Training loss: 0.6869637507264332
Epoch: 68 | Iteration number: [2800/4518] 61% | Training loss: 0.686965763334717
Epoch: 68 | Iteration number: [2810/4518] 62% | Training loss: 0.6869680680201995
Epoch: 68 | Iteration number: [2820/4518] 62% | Training loss: 0.6869669032435045
Epoch: 68 | Iteration number: [2830/4518] 62% | Training loss: 0.6869646710978801
Epoch: 68 | Iteration number: [2840/4518] 62% | Training loss: 0.6869670981252697
Epoch: 68 | Iteration number: [2850/4518] 63% | Training loss: 0.686966593391017
Epoch: 68 | Iteration number: [2860/4518] 63% | Training loss: 0.6869697611023496
Epoch: 68 | Iteration number: [2870/4518] 63% | Training loss: 0.6869705447336523
Epoch: 68 | Iteration number: [2880/4518] 63% | Training loss: 0.6869719209356441
Epoch: 68 | Iteration number: [2890/4518] 63% | Training loss: 0.6869706383007208
Epoch: 68 | Iteration number: [2900/4518] 64% | Training loss: 0.6869709574354106
Epoch: 68 | Iteration number: [2910/4518] 64% | Training loss: 0.6869666299869105
Epoch: 68 | Iteration number: [2920/4518] 64% | Training loss: 0.6869658943112582
Epoch: 68 | Iteration number: [2930/4518] 64% | Training loss: 0.6869648947447233
Epoch: 68 | Iteration number: [2940/4518] 65% | Training loss: 0.6869634810961833
Epoch: 68 | Iteration number: [2950/4518] 65% | Training loss: 0.6869659382609998
Epoch: 68 | Iteration number: [2960/4518] 65% | Training loss: 0.6869632490583368
Epoch: 68 | Iteration number: [2970/4518] 65% | Training loss: 0.6869614698469438
Epoch: 68 | Iteration number: [2980/4518] 65% | Training loss: 0.6869615982242878
Epoch: 68 | Iteration number: [2990/4518] 66% | Training loss: 0.6869596355535513
Epoch: 68 | Iteration number: [3000/4518] 66% | Training loss: 0.6869598978360494
Epoch: 68 | Iteration number: [3010/4518] 66% | Training loss: 0.6869643329781947
Epoch: 68 | Iteration number: [3020/4518] 66% | Training loss: 0.6869650392934976
Epoch: 68 | Iteration number: [3030/4518] 67% | Training loss: 0.6869641952782181
Epoch: 68 | Iteration number: [3040/4518] 67% | Training loss: 0.6869601164013147
Epoch: 68 | Iteration number: [3050/4518] 67% | Training loss: 0.6869638411138879
Epoch: 68 | Iteration number: [3060/4518] 67% | Training loss: 0.6869637761630264
Epoch: 68 | Iteration number: [3070/4518] 67% | Training loss: 0.68696302591007
Epoch: 68 | Iteration number: [3080/4518] 68% | Training loss: 0.6869652784683488
Epoch: 68 | Iteration number: [3090/4518] 68% | Training loss: 0.6869644536941183
Epoch: 68 | Iteration number: [3100/4518] 68% | Training loss: 0.6869655926573661
Epoch: 68 | Iteration number: [3110/4518] 68% | Training loss: 0.686966681729559
Epoch: 68 | Iteration number: [3120/4518] 69% | Training loss: 0.6869615320975964
Epoch: 68 | Iteration number: [3130/4518] 69% | Training loss: 0.6869627841745322
Epoch: 68 | Iteration number: [3140/4518] 69% | Training loss: 0.6869673160420862
Epoch: 68 | Iteration number: [3150/4518] 69% | Training loss: 0.6869694432568929
Epoch: 68 | Iteration number: [3160/4518] 69% | Training loss: 0.6869688663301589
Epoch: 68 | Iteration number: [3170/4518] 70% | Training loss: 0.686964259801979
Epoch: 68 | Iteration number: [3180/4518] 70% | Training loss: 0.6869653698408379
Epoch: 68 | Iteration number: [3190/4518] 70% | Training loss: 0.6869642690057665
Epoch: 68 | Iteration number: [3200/4518] 70% | Training loss: 0.6869628075137735
Epoch: 68 | Iteration number: [3210/4518] 71% | Training loss: 0.6869635892434284
Epoch: 68 | Iteration number: [3220/4518] 71% | Training loss: 0.6869611293262576
Epoch: 68 | Iteration number: [3230/4518] 71% | Training loss: 0.6869632590665906
Epoch: 68 | Iteration number: [3240/4518] 71% | Training loss: 0.6869617581551457
Epoch: 68 | Iteration number: [3250/4518] 71% | Training loss: 0.6869601659958179
Epoch: 68 | Iteration number: [3260/4518] 72% | Training loss: 0.6869572727958118
Epoch: 68 | Iteration number: [3270/4518] 72% | Training loss: 0.6869565473966278
Epoch: 68 | Iteration number: [3280/4518] 72% | Training loss: 0.686956386904164
Epoch: 68 | Iteration number: [3290/4518] 72% | Training loss: 0.6869585341233251
Epoch: 68 | Iteration number: [3300/4518] 73% | Training loss: 0.6869571841846813
Epoch: 68 | Iteration number: [3310/4518] 73% | Training loss: 0.6869557732001532
Epoch: 68 | Iteration number: [3320/4518] 73% | Training loss: 0.6869580962392221
Epoch: 68 | Iteration number: [3330/4518] 73% | Training loss: 0.6869539859058621
Epoch: 68 | Iteration number: [3340/4518] 73% | Training loss: 0.6869541245841695
Epoch: 68 | Iteration number: [3350/4518] 74% | Training loss: 0.6869540198347461
Epoch: 68 | Iteration number: [3360/4518] 74% | Training loss: 0.6869517405118261
Epoch: 68 | Iteration number: [3370/4518] 74% | Training loss: 0.6869530754379419
Epoch: 68 | Iteration number: [3380/4518] 74% | Training loss: 0.6869515678586339
Epoch: 68 | Iteration number: [3390/4518] 75% | Training loss: 0.6869517713169784
Epoch: 68 | Iteration number: [3400/4518] 75% | Training loss: 0.6869519723864163
Epoch: 68 | Iteration number: [3410/4518] 75% | Training loss: 0.6869524508102898
Epoch: 68 | Iteration number: [3420/4518] 75% | Training loss: 0.6869523021038513
Epoch: 68 | Iteration number: [3430/4518] 75% | Training loss: 0.6869541031973703
Epoch: 68 | Iteration number: [3440/4518] 76% | Training loss: 0.6869567085144132
Epoch: 68 | Iteration number: [3450/4518] 76% | Training loss: 0.6869550072974053
Epoch: 68 | Iteration number: [3460/4518] 76% | Training loss: 0.6869524752990359
Epoch: 68 | Iteration number: [3470/4518] 76% | Training loss: 0.6869500507538875
Epoch: 68 | Iteration number: [3480/4518] 77% | Training loss: 0.6869485180097065
Epoch: 68 | Iteration number: [3490/4518] 77% | Training loss: 0.686943613116584
Epoch: 68 | Iteration number: [3500/4518] 77% | Training loss: 0.6869387811592647
Epoch: 68 | Iteration number: [3510/4518] 77% | Training loss: 0.6869376483805838
Epoch: 68 | Iteration number: [3520/4518] 77% | Training loss: 0.6869357715276154
Epoch: 68 | Iteration number: [3530/4518] 78% | Training loss: 0.6869346619665454
Epoch: 68 | Iteration number: [3540/4518] 78% | Training loss: 0.6869362433077926
Epoch: 68 | Iteration number: [3550/4518] 78% | Training loss: 0.6869352787984928
Epoch: 68 | Iteration number: [3560/4518] 78% | Training loss: 0.6869334943676263
Epoch: 68 | Iteration number: [3570/4518] 79% | Training loss: 0.686934753359199
Epoch: 68 | Iteration number: [3580/4518] 79% | Training loss: 0.6869379641456977
Epoch: 68 | Iteration number: [3590/4518] 79% | Training loss: 0.6869374725313904
Epoch: 68 | Iteration number: [3600/4518] 79% | Training loss: 0.686933601482047
Epoch: 68 | Iteration number: [3610/4518] 79% | Training loss: 0.686928799112748
Epoch: 68 | Iteration number: [3620/4518] 80% | Training loss: 0.6869250964064625
Epoch: 68 | Iteration number: [3630/4518] 80% | Training loss: 0.6869262013389388
Epoch: 68 | Iteration number: [3640/4518] 80% | Training loss: 0.6869249194369211
Epoch: 68 | Iteration number: [3650/4518] 80% | Training loss: 0.6869268354977647
Epoch: 68 | Iteration number: [3660/4518] 81% | Training loss: 0.6869300748806834
Epoch: 68 | Iteration number: [3670/4518] 81% | Training loss: 0.6869266964759099
Epoch: 68 | Iteration number: [3680/4518] 81% | Training loss: 0.6869267277743505
Epoch: 68 | Iteration number: [3690/4518] 81% | Training loss: 0.6869285552966885
Epoch: 68 | Iteration number: [3700/4518] 81% | Training loss: 0.6869273026086189
Epoch: 68 | Iteration number: [3710/4518] 82% | Training loss: 0.6869291825435875
Epoch: 68 | Iteration number: [3720/4518] 82% | Training loss: 0.6869287056307639
Epoch: 68 | Iteration number: [3730/4518] 82% | Training loss: 0.6869275597401023
Epoch: 68 | Iteration number: [3740/4518] 82% | Training loss: 0.686927383628121
Epoch: 68 | Iteration number: [3750/4518] 83% | Training loss: 0.6869272272745768
Epoch: 68 | Iteration number: [3760/4518] 83% | Training loss: 0.6869276140440017
Epoch: 68 | Iteration number: [3770/4518] 83% | Training loss: 0.6869281636308928
Epoch: 68 | Iteration number: [3780/4518] 83% | Training loss: 0.6869255368514036
Epoch: 68 | Iteration number: [3790/4518] 83% | Training loss: 0.6869259624179246
Epoch: 68 | Iteration number: [3800/4518] 84% | Training loss: 0.6869228394094267
Epoch: 68 | Iteration number: [3810/4518] 84% | Training loss: 0.6869222249728175
Epoch: 68 | Iteration number: [3820/4518] 84% | Training loss: 0.6869211141195597
Epoch: 68 | Iteration number: [3830/4518] 84% | Training loss: 0.6869231769061276
Epoch: 68 | Iteration number: [3840/4518] 84% | Training loss: 0.6869247830783327
Epoch: 68 | Iteration number: [3850/4518] 85% | Training loss: 0.6869250102941092
Epoch: 68 | Iteration number: [3860/4518] 85% | Training loss: 0.6869238241040028
Epoch: 68 | Iteration number: [3870/4518] 85% | Training loss: 0.6869207667441947
Epoch: 68 | Iteration number: [3880/4518] 85% | Training loss: 0.6869189048704413
Epoch: 68 | Iteration number: [3890/4518] 86% | Training loss: 0.6869142079874299
Epoch: 68 | Iteration number: [3900/4518] 86% | Training loss: 0.6869091576032149
Epoch: 68 | Iteration number: [3910/4518] 86% | Training loss: 0.686909184431481
Epoch: 68 | Iteration number: [3920/4518] 86% | Training loss: 0.6869062728571649
Epoch: 68 | Iteration number: [3930/4518] 86% | Training loss: 0.6869025574992328
Epoch: 68 | Iteration number: [3940/4518] 87% | Training loss: 0.6869024592456479
Epoch: 68 | Iteration number: [3950/4518] 87% | Training loss: 0.6869020491461211
Epoch: 68 | Iteration number: [3960/4518] 87% | Training loss: 0.6869051555943008
Epoch: 68 | Iteration number: [3970/4518] 87% | Training loss: 0.6869071106015885
Epoch: 68 | Iteration number: [3980/4518] 88% | Training loss: 0.6869089843639776
Epoch: 68 | Iteration number: [3990/4518] 88% | Training loss: 0.6869106528753027
Epoch: 68 | Iteration number: [4000/4518] 88% | Training loss: 0.6869081462472677
Epoch: 68 | Iteration number: [4010/4518] 88% | Training loss: 0.6869092351331972
Epoch: 68 | Iteration number: [4020/4518] 88% | Training loss: 0.6869081722414909
Epoch: 68 | Iteration number: [4030/4518] 89% | Training loss: 0.6869101660718989
Epoch: 68 | Iteration number: [4040/4518] 89% | Training loss: 0.6869091335499641
Epoch: 68 | Iteration number: [4050/4518] 89% | Training loss: 0.6869109744495816
Epoch: 68 | Iteration number: [4060/4518] 89% | Training loss: 0.6869092166423798
Epoch: 68 | Iteration number: [4070/4518] 90% | Training loss: 0.6869128738779401
Epoch: 68 | Iteration number: [4080/4518] 90% | Training loss: 0.6869148227660095
Epoch: 68 | Iteration number: [4090/4518] 90% | Training loss: 0.6869129643026366
Epoch: 68 | Iteration number: [4100/4518] 90% | Training loss: 0.6869121548606129
Epoch: 68 | Iteration number: [4110/4518] 90% | Training loss: 0.6869140435164283
Epoch: 68 | Iteration number: [4120/4518] 91% | Training loss: 0.6869135003790114
Epoch: 68 | Iteration number: [4130/4518] 91% | Training loss: 0.6869131918103585
Epoch: 68 | Iteration number: [4140/4518] 91% | Training loss: 0.686913639638159
Epoch: 68 | Iteration number: [4150/4518] 91% | Training loss: 0.6869143105271351
Epoch: 68 | Iteration number: [4160/4518] 92% | Training loss: 0.6869132480942286
Epoch: 68 | Iteration number: [4170/4518] 92% | Training loss: 0.6869127973664007
Epoch: 68 | Iteration number: [4180/4518] 92% | Training loss: 0.6869117693610168
Epoch: 68 | Iteration number: [4190/4518] 92% | Training loss: 0.6869130427057817
Epoch: 68 | Iteration number: [4200/4518] 92% | Training loss: 0.6869130824861073
Epoch: 68 | Iteration number: [4210/4518] 93% | Training loss: 0.6869130903071858
Epoch: 68 | Iteration number: [4220/4518] 93% | Training loss: 0.6869127734859973
Epoch: 68 | Iteration number: [4230/4518] 93% | Training loss: 0.6869125619706814
Epoch: 68 | Iteration number: [4240/4518] 93% | Training loss: 0.6869114045124008
Epoch: 68 | Iteration number: [4250/4518] 94% | Training loss: 0.6869106427921968
Epoch: 68 | Iteration number: [4260/4518] 94% | Training loss: 0.686912146602438
Epoch: 68 | Iteration number: [4270/4518] 94% | Training loss: 0.6869148965323
Epoch: 68 | Iteration number: [4280/4518] 94% | Training loss: 0.6869132815398903
Epoch: 68 | Iteration number: [4290/4518] 94% | Training loss: 0.6869123969183657
Epoch: 68 | Iteration number: [4300/4518] 95% | Training loss: 0.6869123546051424
Epoch: 68 | Iteration number: [4310/4518] 95% | Training loss: 0.6869128240510095
Epoch: 68 | Iteration number: [4320/4518] 95% | Training loss: 0.6869137465401932
Epoch: 68 | Iteration number: [4330/4518] 95% | Training loss: 0.6869158545212162
Epoch: 68 | Iteration number: [4340/4518] 96% | Training loss: 0.6869185494113078
Epoch: 68 | Iteration number: [4350/4518] 96% | Training loss: 0.6869195289584412
Epoch: 68 | Iteration number: [4360/4518] 96% | Training loss: 0.6869203007822736
Epoch: 68 | Iteration number: [4370/4518] 96% | Training loss: 0.6869174371049388
Epoch: 68 | Iteration number: [4380/4518] 96% | Training loss: 0.6869181423562847
Epoch: 68 | Iteration number: [4390/4518] 97% | Training loss: 0.6869171107412743
Epoch: 68 | Iteration number: [4400/4518] 97% | Training loss: 0.6869163189422001
Epoch: 68 | Iteration number: [4410/4518] 97% | Training loss: 0.6869196243702419
Epoch: 68 | Iteration number: [4420/4518] 97% | Training loss: 0.6869199569543563
Epoch: 68 | Iteration number: [4430/4518] 98% | Training loss: 0.6869200017597552
Epoch: 68 | Iteration number: [4440/4518] 98% | Training loss: 0.6869216724290504
Epoch: 68 | Iteration number: [4450/4518] 98% | Training loss: 0.6869258426012618
Epoch: 68 | Iteration number: [4460/4518] 98% | Training loss: 0.6869253318406007
Epoch: 68 | Iteration number: [4470/4518] 98% | Training loss: 0.6869258817676996
Epoch: 68 | Iteration number: [4480/4518] 99% | Training loss: 0.6869289114273021
Epoch: 68 | Iteration number: [4490/4518] 99% | Training loss: 0.6869286374684697
Epoch: 68 | Iteration number: [4500/4518] 99% | Training loss: 0.6869287812312445
Epoch: 68 | Iteration number: [4510/4518] 99% | Training loss: 0.6869270124615164

 End of epoch: 68 | Train Loss: 0.6867780680939285 | Training Time: 641 

 End of epoch: 68 | Eval Loss: 0.6898746989211257 | Evaluating Time: 17 
Epoch: 69 | Iteration number: [10/4518] 0% | Training loss: 0.7559623181819916
Epoch: 69 | Iteration number: [20/4518] 0% | Training loss: 0.7215867280960083
Epoch: 69 | Iteration number: [30/4518] 0% | Training loss: 0.7100334664185842
Epoch: 69 | Iteration number: [40/4518] 0% | Training loss: 0.7042812168598175
Epoch: 69 | Iteration number: [50/4518] 1% | Training loss: 0.7008847451210022
Epoch: 69 | Iteration number: [60/4518] 1% | Training loss: 0.6983947783708573
Epoch: 69 | Iteration number: [70/4518] 1% | Training loss: 0.6966494534696851
Epoch: 69 | Iteration number: [80/4518] 1% | Training loss: 0.6953676663339138
Epoch: 69 | Iteration number: [90/4518] 1% | Training loss: 0.6944628477096557
Epoch: 69 | Iteration number: [100/4518] 2% | Training loss: 0.6936551451683044
Epoch: 69 | Iteration number: [110/4518] 2% | Training loss: 0.693126132813367
Epoch: 69 | Iteration number: [120/4518] 2% | Training loss: 0.6925519143541654
Epoch: 69 | Iteration number: [130/4518] 2% | Training loss: 0.6921442233599149
Epoch: 69 | Iteration number: [140/4518] 3% | Training loss: 0.6916873135737011
Epoch: 69 | Iteration number: [150/4518] 3% | Training loss: 0.6914198927084605
Epoch: 69 | Iteration number: [160/4518] 3% | Training loss: 0.6910200554877519
Epoch: 69 | Iteration number: [170/4518] 3% | Training loss: 0.6908880987588097
Epoch: 69 | Iteration number: [180/4518] 3% | Training loss: 0.6906976974672742
Epoch: 69 | Iteration number: [190/4518] 4% | Training loss: 0.6904051937555012
Epoch: 69 | Iteration number: [200/4518] 4% | Training loss: 0.6902154761552811
Epoch: 69 | Iteration number: [210/4518] 4% | Training loss: 0.6900836059025356
Epoch: 69 | Iteration number: [220/4518] 4% | Training loss: 0.6899218082427978
Epoch: 69 | Iteration number: [230/4518] 5% | Training loss: 0.6898003236107204
Epoch: 69 | Iteration number: [240/4518] 5% | Training loss: 0.6896294943988324
Epoch: 69 | Iteration number: [250/4518] 5% | Training loss: 0.6894803125858306
Epoch: 69 | Iteration number: [260/4518] 5% | Training loss: 0.6893995587642376
Epoch: 69 | Iteration number: [270/4518] 5% | Training loss: 0.6892765495512221
Epoch: 69 | Iteration number: [280/4518] 6% | Training loss: 0.6891467158283506
Epoch: 69 | Iteration number: [290/4518] 6% | Training loss: 0.6891031474902712
Epoch: 69 | Iteration number: [300/4518] 6% | Training loss: 0.6889708403746287
Epoch: 69 | Iteration number: [310/4518] 6% | Training loss: 0.6889279009834413
Epoch: 69 | Iteration number: [320/4518] 7% | Training loss: 0.6888594437390566
Epoch: 69 | Iteration number: [330/4518] 7% | Training loss: 0.68878321593458
Epoch: 69 | Iteration number: [340/4518] 7% | Training loss: 0.6886417676420773
Epoch: 69 | Iteration number: [350/4518] 7% | Training loss: 0.6886167028972081
Epoch: 69 | Iteration number: [360/4518] 7% | Training loss: 0.6885393364561929
Epoch: 69 | Iteration number: [370/4518] 8% | Training loss: 0.6884882733628557
Epoch: 69 | Iteration number: [380/4518] 8% | Training loss: 0.6884297162294388
Epoch: 69 | Iteration number: [390/4518] 8% | Training loss: 0.6884065336141831
Epoch: 69 | Iteration number: [400/4518] 8% | Training loss: 0.6883807633817196
Epoch: 69 | Iteration number: [410/4518] 9% | Training loss: 0.6883340002560034
Epoch: 69 | Iteration number: [420/4518] 9% | Training loss: 0.6883096578575316
Epoch: 69 | Iteration number: [430/4518] 9% | Training loss: 0.6882509848406149
Epoch: 69 | Iteration number: [440/4518] 9% | Training loss: 0.6882360364903103
Epoch: 69 | Iteration number: [450/4518] 9% | Training loss: 0.6881976082589891
Epoch: 69 | Iteration number: [460/4518] 10% | Training loss: 0.6881469444088314
Epoch: 69 | Iteration number: [470/4518] 10% | Training loss: 0.688128099542983
Epoch: 69 | Iteration number: [480/4518] 10% | Training loss: 0.6880883678793908
Epoch: 69 | Iteration number: [490/4518] 10% | Training loss: 0.6880565292981207
Epoch: 69 | Iteration number: [500/4518] 11% | Training loss: 0.6880386718511582
Epoch: 69 | Iteration number: [510/4518] 11% | Training loss: 0.688005472982631
Epoch: 69 | Iteration number: [520/4518] 11% | Training loss: 0.6879525204117481
Epoch: 69 | Iteration number: [530/4518] 11% | Training loss: 0.687933167084208
Epoch: 69 | Iteration number: [540/4518] 11% | Training loss: 0.6879138053567321
Epoch: 69 | Iteration number: [550/4518] 12% | Training loss: 0.6878723871707916
Epoch: 69 | Iteration number: [560/4518] 12% | Training loss: 0.6878628742481981
Epoch: 69 | Iteration number: [570/4518] 12% | Training loss: 0.6878494539804626
Epoch: 69 | Iteration number: [580/4518] 12% | Training loss: 0.687843651298819
Epoch: 69 | Iteration number: [590/4518] 13% | Training loss: 0.6878362250530113
Epoch: 69 | Iteration number: [600/4518] 13% | Training loss: 0.6878279796242714
Epoch: 69 | Iteration number: [610/4518] 13% | Training loss: 0.6878191148648497
Epoch: 69 | Iteration number: [620/4518] 13% | Training loss: 0.6877993369294751
Epoch: 69 | Iteration number: [630/4518] 13% | Training loss: 0.68778861392112
Epoch: 69 | Iteration number: [640/4518] 14% | Training loss: 0.6877753141336143
Epoch: 69 | Iteration number: [650/4518] 14% | Training loss: 0.6877753190810864
Epoch: 69 | Iteration number: [660/4518] 14% | Training loss: 0.6877531947511615
Epoch: 69 | Iteration number: [670/4518] 14% | Training loss: 0.687758828543905
Epoch: 69 | Iteration number: [680/4518] 15% | Training loss: 0.6877480159787571
Epoch: 69 | Iteration number: [690/4518] 15% | Training loss: 0.6877456373926522
Epoch: 69 | Iteration number: [700/4518] 15% | Training loss: 0.6877164494991302
Epoch: 69 | Iteration number: [710/4518] 15% | Training loss: 0.6877172302192366
Epoch: 69 | Iteration number: [720/4518] 15% | Training loss: 0.6877181846234534
Epoch: 69 | Iteration number: [730/4518] 16% | Training loss: 0.687704483205325
Epoch: 69 | Iteration number: [740/4518] 16% | Training loss: 0.6876903701472927
Epoch: 69 | Iteration number: [750/4518] 16% | Training loss: 0.6876820429166158
Epoch: 69 | Iteration number: [760/4518] 16% | Training loss: 0.6876820200367978
Epoch: 69 | Iteration number: [770/4518] 17% | Training loss: 0.6876675739690855
Epoch: 69 | Iteration number: [780/4518] 17% | Training loss: 0.6876597009408169
Epoch: 69 | Iteration number: [790/4518] 17% | Training loss: 0.6876459822624544
Epoch: 69 | Iteration number: [800/4518] 17% | Training loss: 0.6876340080797673
Epoch: 69 | Iteration number: [810/4518] 17% | Training loss: 0.6876117850527351
Epoch: 69 | Iteration number: [820/4518] 18% | Training loss: 0.6876005275947291
Epoch: 69 | Iteration number: [830/4518] 18% | Training loss: 0.6875827636345323
Epoch: 69 | Iteration number: [840/4518] 18% | Training loss: 0.6875702537241436
Epoch: 69 | Iteration number: [850/4518] 18% | Training loss: 0.6875697195529937
Epoch: 69 | Iteration number: [860/4518] 19% | Training loss: 0.6875500100989674
Epoch: 69 | Iteration number: [870/4518] 19% | Training loss: 0.687545283361413
Epoch: 69 | Iteration number: [880/4518] 19% | Training loss: 0.687528482214971
Epoch: 69 | Iteration number: [890/4518] 19% | Training loss: 0.6875171779246813
Epoch: 69 | Iteration number: [900/4518] 19% | Training loss: 0.6874965132607354
Epoch: 69 | Iteration number: [910/4518] 20% | Training loss: 0.6874779093396532
Epoch: 69 | Iteration number: [920/4518] 20% | Training loss: 0.6874826490231182
Epoch: 69 | Iteration number: [930/4518] 20% | Training loss: 0.6874730543423725
Epoch: 69 | Iteration number: [940/4518] 20% | Training loss: 0.6874686782030349
Epoch: 69 | Iteration number: [950/4518] 21% | Training loss: 0.6874629203896774
Epoch: 69 | Iteration number: [960/4518] 21% | Training loss: 0.6874570300802588
Epoch: 69 | Iteration number: [970/4518] 21% | Training loss: 0.6874496583471593
Epoch: 69 | Iteration number: [980/4518] 21% | Training loss: 0.6874409040018004
Epoch: 69 | Iteration number: [990/4518] 21% | Training loss: 0.6874271028571659
Epoch: 69 | Iteration number: [1000/4518] 22% | Training loss: 0.6874158006310463
Epoch: 69 | Iteration number: [1010/4518] 22% | Training loss: 0.6874089583902075
Epoch: 69 | Iteration number: [1020/4518] 22% | Training loss: 0.6874125077443964
Epoch: 69 | Iteration number: [1030/4518] 22% | Training loss: 0.687412130427592
Epoch: 69 | Iteration number: [1040/4518] 23% | Training loss: 0.6874129262681191
Epoch: 69 | Iteration number: [1050/4518] 23% | Training loss: 0.6874254116557893
Epoch: 69 | Iteration number: [1060/4518] 23% | Training loss: 0.6874180646437519
Epoch: 69 | Iteration number: [1070/4518] 23% | Training loss: 0.6874010154020006
Epoch: 69 | Iteration number: [1080/4518] 23% | Training loss: 0.6874065201039667
Epoch: 69 | Iteration number: [1090/4518] 24% | Training loss: 0.6873914862991473
Epoch: 69 | Iteration number: [1100/4518] 24% | Training loss: 0.6873890114372427
Epoch: 69 | Iteration number: [1110/4518] 24% | Training loss: 0.6873811889876117
Epoch: 69 | Iteration number: [1120/4518] 24% | Training loss: 0.6873765357903072
Epoch: 69 | Iteration number: [1130/4518] 25% | Training loss: 0.6873668225993097
Epoch: 69 | Iteration number: [1140/4518] 25% | Training loss: 0.6873607776144095
Epoch: 69 | Iteration number: [1150/4518] 25% | Training loss: 0.6873524869006613
Epoch: 69 | Iteration number: [1160/4518] 25% | Training loss: 0.6873372665767012
Epoch: 69 | Iteration number: [1170/4518] 25% | Training loss: 0.6873433413668576
Epoch: 69 | Iteration number: [1180/4518] 26% | Training loss: 0.6873528967974549
Epoch: 69 | Iteration number: [1190/4518] 26% | Training loss: 0.6873453286515564
Epoch: 69 | Iteration number: [1200/4518] 26% | Training loss: 0.6873411432405313
Epoch: 69 | Iteration number: [1210/4518] 26% | Training loss: 0.687337971226243
Epoch: 69 | Iteration number: [1220/4518] 27% | Training loss: 0.687330381840956
Epoch: 69 | Iteration number: [1230/4518] 27% | Training loss: 0.6873217342345695
Epoch: 69 | Iteration number: [1240/4518] 27% | Training loss: 0.6873112689102849
Epoch: 69 | Iteration number: [1250/4518] 27% | Training loss: 0.6873004159450531
Epoch: 69 | Iteration number: [1260/4518] 27% | Training loss: 0.6872966219981511
Epoch: 69 | Iteration number: [1270/4518] 28% | Training loss: 0.6872876685904705
Epoch: 69 | Iteration number: [1280/4518] 28% | Training loss: 0.6872880559880287
Epoch: 69 | Iteration number: [1290/4518] 28% | Training loss: 0.6873005066731179
Epoch: 69 | Iteration number: [1300/4518] 28% | Training loss: 0.6872913743899419
Epoch: 69 | Iteration number: [1310/4518] 28% | Training loss: 0.6872856582849081
Epoch: 69 | Iteration number: [1320/4518] 29% | Training loss: 0.6872888523972396
Epoch: 69 | Iteration number: [1330/4518] 29% | Training loss: 0.6872788550710319
Epoch: 69 | Iteration number: [1340/4518] 29% | Training loss: 0.687272069614325
Epoch: 69 | Iteration number: [1350/4518] 29% | Training loss: 0.6872618172786854
Epoch: 69 | Iteration number: [1360/4518] 30% | Training loss: 0.6872495756868053
Epoch: 69 | Iteration number: [1370/4518] 30% | Training loss: 0.6872464347059709
Epoch: 69 | Iteration number: [1380/4518] 30% | Training loss: 0.687231294616409
Epoch: 69 | Iteration number: [1390/4518] 30% | Training loss: 0.6872290856117825
Epoch: 69 | Iteration number: [1400/4518] 30% | Training loss: 0.6872247172253473
Epoch: 69 | Iteration number: [1410/4518] 31% | Training loss: 0.6872182509577867
Epoch: 69 | Iteration number: [1420/4518] 31% | Training loss: 0.6872210270502198
Epoch: 69 | Iteration number: [1430/4518] 31% | Training loss: 0.6872127911010822
Epoch: 69 | Iteration number: [1440/4518] 31% | Training loss: 0.6872109214050902
Epoch: 69 | Iteration number: [1450/4518] 32% | Training loss: 0.6872056115084682
Epoch: 69 | Iteration number: [1460/4518] 32% | Training loss: 0.6871977065115759
Epoch: 69 | Iteration number: [1470/4518] 32% | Training loss: 0.6872027227262251
Epoch: 69 | Iteration number: [1480/4518] 32% | Training loss: 0.6871969325719653
Epoch: 69 | Iteration number: [1490/4518] 32% | Training loss: 0.6871882265046139
Epoch: 69 | Iteration number: [1500/4518] 33% | Training loss: 0.6871843803326289
Epoch: 69 | Iteration number: [1510/4518] 33% | Training loss: 0.6871876041226039
Epoch: 69 | Iteration number: [1520/4518] 33% | Training loss: 0.6871873779124336
Epoch: 69 | Iteration number: [1530/4518] 33% | Training loss: 0.6871784649643243
Epoch: 69 | Iteration number: [1540/4518] 34% | Training loss: 0.6871724066409197
Epoch: 69 | Iteration number: [1550/4518] 34% | Training loss: 0.6871689415362573
Epoch: 69 | Iteration number: [1560/4518] 34% | Training loss: 0.6871741535953987
Epoch: 69 | Iteration number: [1570/4518] 34% | Training loss: 0.6871721505739127
Epoch: 69 | Iteration number: [1580/4518] 34% | Training loss: 0.6871818155804766
Epoch: 69 | Iteration number: [1590/4518] 35% | Training loss: 0.6871762350670196
Epoch: 69 | Iteration number: [1600/4518] 35% | Training loss: 0.6871807328611612
Epoch: 69 | Iteration number: [1610/4518] 35% | Training loss: 0.6871791945110937
Epoch: 69 | Iteration number: [1620/4518] 35% | Training loss: 0.6871835952187761
Epoch: 69 | Iteration number: [1630/4518] 36% | Training loss: 0.6871837030524857
Epoch: 69 | Iteration number: [1640/4518] 36% | Training loss: 0.6871822414238279
Epoch: 69 | Iteration number: [1650/4518] 36% | Training loss: 0.6871833058198293
Epoch: 69 | Iteration number: [1660/4518] 36% | Training loss: 0.6871734603700868
Epoch: 69 | Iteration number: [1670/4518] 36% | Training loss: 0.6871723779304298
Epoch: 69 | Iteration number: [1680/4518] 37% | Training loss: 0.6871739255530493
Epoch: 69 | Iteration number: [1690/4518] 37% | Training loss: 0.6871759782528736
Epoch: 69 | Iteration number: [1700/4518] 37% | Training loss: 0.6871699754981434
Epoch: 69 | Iteration number: [1710/4518] 37% | Training loss: 0.6871709114278269
Epoch: 69 | Iteration number: [1720/4518] 38% | Training loss: 0.6871684157917666
Epoch: 69 | Iteration number: [1730/4518] 38% | Training loss: 0.6871725137867679
Epoch: 69 | Iteration number: [1740/4518] 38% | Training loss: 0.6871604610791151
Epoch: 69 | Iteration number: [1750/4518] 38% | Training loss: 0.687152551480702
Epoch: 69 | Iteration number: [1760/4518] 38% | Training loss: 0.6871480263769627
Epoch: 69 | Iteration number: [1770/4518] 39% | Training loss: 0.6871454131468541
Epoch: 69 | Iteration number: [1780/4518] 39% | Training loss: 0.6871451437808155
Epoch: 69 | Iteration number: [1790/4518] 39% | Training loss: 0.6871380095375317
Epoch: 69 | Iteration number: [1800/4518] 39% | Training loss: 0.687138623032305
Epoch: 69 | Iteration number: [1810/4518] 40% | Training loss: 0.6871378978313003
Epoch: 69 | Iteration number: [1820/4518] 40% | Training loss: 0.6871363647363998
Epoch: 69 | Iteration number: [1830/4518] 40% | Training loss: 0.687133476447538
Epoch: 69 | Iteration number: [1840/4518] 40% | Training loss: 0.6871362656030966
Epoch: 69 | Iteration number: [1850/4518] 40% | Training loss: 0.6871327380231909
Epoch: 69 | Iteration number: [1860/4518] 41% | Training loss: 0.6871301777901188
Epoch: 69 | Iteration number: [1870/4518] 41% | Training loss: 0.6871271818398155
Epoch: 69 | Iteration number: [1880/4518] 41% | Training loss: 0.687127420052569
Epoch: 69 | Iteration number: [1890/4518] 41% | Training loss: 0.687121585153398
Epoch: 69 | Iteration number: [1900/4518] 42% | Training loss: 0.6871218776389172
Epoch: 69 | Iteration number: [1910/4518] 42% | Training loss: 0.6871233680797497
Epoch: 69 | Iteration number: [1920/4518] 42% | Training loss: 0.6871167746372521
Epoch: 69 | Iteration number: [1930/4518] 42% | Training loss: 0.6871179341343401
Epoch: 69 | Iteration number: [1940/4518] 42% | Training loss: 0.6871131654252711
Epoch: 69 | Iteration number: [1950/4518] 43% | Training loss: 0.6871155733328599
Epoch: 69 | Iteration number: [1960/4518] 43% | Training loss: 0.6871162556872076
Epoch: 69 | Iteration number: [1970/4518] 43% | Training loss: 0.6871078741126859
Epoch: 69 | Iteration number: [1980/4518] 43% | Training loss: 0.6870986524856452
Epoch: 69 | Iteration number: [1990/4518] 44% | Training loss: 0.6870963116686548
Epoch: 69 | Iteration number: [2000/4518] 44% | Training loss: 0.6870951454639435
Epoch: 69 | Iteration number: [2010/4518] 44% | Training loss: 0.6871022225908973
Epoch: 69 | Iteration number: [2020/4518] 44% | Training loss: 0.6870985815725704
Epoch: 69 | Iteration number: [2030/4518] 44% | Training loss: 0.6871002376079559
Epoch: 69 | Iteration number: [2040/4518] 45% | Training loss: 0.6871013645155757
Epoch: 69 | Iteration number: [2050/4518] 45% | Training loss: 0.6870971846580506
Epoch: 69 | Iteration number: [2060/4518] 45% | Training loss: 0.6870941557351825
Epoch: 69 | Iteration number: [2070/4518] 45% | Training loss: 0.6870828858608209
Epoch: 69 | Iteration number: [2080/4518] 46% | Training loss: 0.6870773797424939
Epoch: 69 | Iteration number: [2090/4518] 46% | Training loss: 0.6870771973041826
Epoch: 69 | Iteration number: [2100/4518] 46% | Training loss: 0.6870703215826125
Epoch: 69 | Iteration number: [2110/4518] 46% | Training loss: 0.6870664634975777
Epoch: 69 | Iteration number: [2120/4518] 46% | Training loss: 0.6870657315512874
Epoch: 69 | Iteration number: [2130/4518] 47% | Training loss: 0.6870587052313935
Epoch: 69 | Iteration number: [2140/4518] 47% | Training loss: 0.6870609740230524
Epoch: 69 | Iteration number: [2150/4518] 47% | Training loss: 0.6870646135751591
Epoch: 69 | Iteration number: [2160/4518] 47% | Training loss: 0.6870602842558313
Epoch: 69 | Iteration number: [2170/4518] 48% | Training loss: 0.6870589553760493
Epoch: 69 | Iteration number: [2180/4518] 48% | Training loss: 0.6870523402723697
Epoch: 69 | Iteration number: [2190/4518] 48% | Training loss: 0.6870466321570688
Epoch: 69 | Iteration number: [2200/4518] 48% | Training loss: 0.6870471895553849
Epoch: 69 | Iteration number: [2210/4518] 48% | Training loss: 0.6870479247149299
Epoch: 69 | Iteration number: [2220/4518] 49% | Training loss: 0.6870468991833765
Epoch: 69 | Iteration number: [2230/4518] 49% | Training loss: 0.687039593891178
Epoch: 69 | Iteration number: [2240/4518] 49% | Training loss: 0.6870356561349971
Epoch: 69 | Iteration number: [2250/4518] 49% | Training loss: 0.6870372226503161
Epoch: 69 | Iteration number: [2260/4518] 50% | Training loss: 0.6870404499294483
Epoch: 69 | Iteration number: [2270/4518] 50% | Training loss: 0.687036911847833
Epoch: 69 | Iteration number: [2280/4518] 50% | Training loss: 0.6870366940895717
Epoch: 69 | Iteration number: [2290/4518] 50% | Training loss: 0.6870381700419963
Epoch: 69 | Iteration number: [2300/4518] 50% | Training loss: 0.6870359427514283
Epoch: 69 | Iteration number: [2310/4518] 51% | Training loss: 0.687034281094869
Epoch: 69 | Iteration number: [2320/4518] 51% | Training loss: 0.6870333421589999
Epoch: 69 | Iteration number: [2330/4518] 51% | Training loss: 0.6870305628991434
Epoch: 69 | Iteration number: [2340/4518] 51% | Training loss: 0.6870336782219063
Epoch: 69 | Iteration number: [2350/4518] 52% | Training loss: 0.6870332827720236
Epoch: 69 | Iteration number: [2360/4518] 52% | Training loss: 0.6870373436960123
Epoch: 69 | Iteration number: [2370/4518] 52% | Training loss: 0.6870394897611836
Epoch: 69 | Iteration number: [2380/4518] 52% | Training loss: 0.6870378869421342
Epoch: 69 | Iteration number: [2390/4518] 52% | Training loss: 0.6870337227148989
Epoch: 69 | Iteration number: [2400/4518] 53% | Training loss: 0.6870322615156571
Epoch: 69 | Iteration number: [2410/4518] 53% | Training loss: 0.6870324935903193
Epoch: 69 | Iteration number: [2420/4518] 53% | Training loss: 0.6870261747482395
Epoch: 69 | Iteration number: [2430/4518] 53% | Training loss: 0.6870251829732102
Epoch: 69 | Iteration number: [2440/4518] 54% | Training loss: 0.6870250905390646
Epoch: 69 | Iteration number: [2450/4518] 54% | Training loss: 0.6870249187459752
Epoch: 69 | Iteration number: [2460/4518] 54% | Training loss: 0.6870260775089264
Epoch: 69 | Iteration number: [2470/4518] 54% | Training loss: 0.6870195810852746
Epoch: 69 | Iteration number: [2480/4518] 54% | Training loss: 0.6870168353521054
Epoch: 69 | Iteration number: [2490/4518] 55% | Training loss: 0.6870122957899867
Epoch: 69 | Iteration number: [2500/4518] 55% | Training loss: 0.6870108813524246
Epoch: 69 | Iteration number: [2510/4518] 55% | Training loss: 0.6870076625470621
Epoch: 69 | Iteration number: [2520/4518] 55% | Training loss: 0.6870055339875676
Epoch: 69 | Iteration number: [2530/4518] 55% | Training loss: 0.6870029405407284
Epoch: 69 | Iteration number: [2540/4518] 56% | Training loss: 0.6870031935258174
Epoch: 69 | Iteration number: [2550/4518] 56% | Training loss: 0.6870004572587854
Epoch: 69 | Iteration number: [2560/4518] 56% | Training loss: 0.6870036445790901
Epoch: 69 | Iteration number: [2570/4518] 56% | Training loss: 0.6870058604019625
Epoch: 69 | Iteration number: [2580/4518] 57% | Training loss: 0.6870125143333923
Epoch: 69 | Iteration number: [2590/4518] 57% | Training loss: 0.6870131392506559
Epoch: 69 | Iteration number: [2600/4518] 57% | Training loss: 0.6870184817222449
Epoch: 69 | Iteration number: [2610/4518] 57% | Training loss: 0.6870148045349852
Epoch: 69 | Iteration number: [2620/4518] 57% | Training loss: 0.687015122470965
Epoch: 69 | Iteration number: [2630/4518] 58% | Training loss: 0.6870137929689748
Epoch: 69 | Iteration number: [2640/4518] 58% | Training loss: 0.6870151190595193
Epoch: 69 | Iteration number: [2650/4518] 58% | Training loss: 0.6870119079553856
Epoch: 69 | Iteration number: [2660/4518] 58% | Training loss: 0.6870115212031773
Epoch: 69 | Iteration number: [2670/4518] 59% | Training loss: 0.6870118642567695
Epoch: 69 | Iteration number: [2680/4518] 59% | Training loss: 0.6870121752370649
Epoch: 69 | Iteration number: [2690/4518] 59% | Training loss: 0.6870117776012775
Epoch: 69 | Iteration number: [2700/4518] 59% | Training loss: 0.6870100905056353
Epoch: 69 | Iteration number: [2710/4518] 59% | Training loss: 0.687012916341479
Epoch: 69 | Iteration number: [2720/4518] 60% | Training loss: 0.687014453901964
Epoch: 69 | Iteration number: [2730/4518] 60% | Training loss: 0.6870156672848013
Epoch: 69 | Iteration number: [2740/4518] 60% | Training loss: 0.6870122578239789
Epoch: 69 | Iteration number: [2750/4518] 60% | Training loss: 0.687012511881915
Epoch: 69 | Iteration number: [2760/4518] 61% | Training loss: 0.6870090405794157
Epoch: 69 | Iteration number: [2770/4518] 61% | Training loss: 0.6870065404189623
Epoch: 69 | Iteration number: [2780/4518] 61% | Training loss: 0.687009624054106
Epoch: 69 | Iteration number: [2790/4518] 61% | Training loss: 0.687008456474564
Epoch: 69 | Iteration number: [2800/4518] 61% | Training loss: 0.6870096631348133
Epoch: 69 | Iteration number: [2810/4518] 62% | Training loss: 0.6870100789647086
Epoch: 69 | Iteration number: [2820/4518] 62% | Training loss: 0.6870061736580327
Epoch: 69 | Iteration number: [2830/4518] 62% | Training loss: 0.6870091482312435
Epoch: 69 | Iteration number: [2840/4518] 62% | Training loss: 0.6870081549798939
Epoch: 69 | Iteration number: [2850/4518] 63% | Training loss: 0.6870018512742562
Epoch: 69 | Iteration number: [2860/4518] 63% | Training loss: 0.687005394051125
Epoch: 69 | Iteration number: [2870/4518] 63% | Training loss: 0.6870034065811477
Epoch: 69 | Iteration number: [2880/4518] 63% | Training loss: 0.6870055189563169
Epoch: 69 | Iteration number: [2890/4518] 63% | Training loss: 0.6870028060200305
Epoch: 69 | Iteration number: [2900/4518] 64% | Training loss: 0.6870049953666226
Epoch: 69 | Iteration number: [2910/4518] 64% | Training loss: 0.6870052566438196
Epoch: 69 | Iteration number: [2920/4518] 64% | Training loss: 0.6870085002624825
Epoch: 69 | Iteration number: [2930/4518] 64% | Training loss: 0.6870095362232
Epoch: 69 | Iteration number: [2940/4518] 65% | Training loss: 0.6870075467695185
Epoch: 69 | Iteration number: [2950/4518] 65% | Training loss: 0.6870069465798847
Epoch: 69 | Iteration number: [2960/4518] 65% | Training loss: 0.6870061904594705
Epoch: 69 | Iteration number: [2970/4518] 65% | Training loss: 0.6870017951787121
Epoch: 69 | Iteration number: [2980/4518] 65% | Training loss: 0.686994347256302
Epoch: 69 | Iteration number: [2990/4518] 66% | Training loss: 0.6869984386756667
Epoch: 69 | Iteration number: [3000/4518] 66% | Training loss: 0.6869958247343699
Epoch: 69 | Iteration number: [3010/4518] 66% | Training loss: 0.6869959006475848
Epoch: 69 | Iteration number: [3020/4518] 66% | Training loss: 0.6869942432207777
Epoch: 69 | Iteration number: [3030/4518] 67% | Training loss: 0.6869941453729133
Epoch: 69 | Iteration number: [3040/4518] 67% | Training loss: 0.6869953469030167
Epoch: 69 | Iteration number: [3050/4518] 67% | Training loss: 0.6869936587185156
Epoch: 69 | Iteration number: [3060/4518] 67% | Training loss: 0.6869886843597188
Epoch: 69 | Iteration number: [3070/4518] 67% | Training loss: 0.6869875553764816
Epoch: 69 | Iteration number: [3080/4518] 68% | Training loss: 0.6869851448706218
Epoch: 69 | Iteration number: [3090/4518] 68% | Training loss: 0.6869883623902466
Epoch: 69 | Iteration number: [3100/4518] 68% | Training loss: 0.6869848798359594
Epoch: 69 | Iteration number: [3110/4518] 68% | Training loss: 0.6869845376520678
Epoch: 69 | Iteration number: [3120/4518] 69% | Training loss: 0.6869837428323734
Epoch: 69 | Iteration number: [3130/4518] 69% | Training loss: 0.6869820786550784
Epoch: 69 | Iteration number: [3140/4518] 69% | Training loss: 0.6869771229043887
Epoch: 69 | Iteration number: [3150/4518] 69% | Training loss: 0.6869796484235733
Epoch: 69 | Iteration number: [3160/4518] 69% | Training loss: 0.6869786934007572
Epoch: 69 | Iteration number: [3170/4518] 70% | Training loss: 0.6869794832419146
Epoch: 69 | Iteration number: [3180/4518] 70% | Training loss: 0.6869776787435483
Epoch: 69 | Iteration number: [3190/4518] 70% | Training loss: 0.686978317110516
Epoch: 69 | Iteration number: [3200/4518] 70% | Training loss: 0.6869804555550217
Epoch: 69 | Iteration number: [3210/4518] 71% | Training loss: 0.6869821375032823
Epoch: 69 | Iteration number: [3220/4518] 71% | Training loss: 0.6869785870454326
Epoch: 69 | Iteration number: [3230/4518] 71% | Training loss: 0.6869751566334774
Epoch: 69 | Iteration number: [3240/4518] 71% | Training loss: 0.6869730728827876
Epoch: 69 | Iteration number: [3250/4518] 71% | Training loss: 0.6869712924590478
Epoch: 69 | Iteration number: [3260/4518] 72% | Training loss: 0.6869697603345649
Epoch: 69 | Iteration number: [3270/4518] 72% | Training loss: 0.6869691556382252
Epoch: 69 | Iteration number: [3280/4518] 72% | Training loss: 0.6869710493923687
Epoch: 69 | Iteration number: [3290/4518] 72% | Training loss: 0.6869713430890196
Epoch: 69 | Iteration number: [3300/4518] 73% | Training loss: 0.6869727523579742
Epoch: 69 | Iteration number: [3310/4518] 73% | Training loss: 0.6869748592376709
Epoch: 69 | Iteration number: [3320/4518] 73% | Training loss: 0.686971968735557
Epoch: 69 | Iteration number: [3330/4518] 73% | Training loss: 0.6869658145460639
Epoch: 69 | Iteration number: [3340/4518] 73% | Training loss: 0.6869666527309818
Epoch: 69 | Iteration number: [3350/4518] 74% | Training loss: 0.6869673416685702
Epoch: 69 | Iteration number: [3360/4518] 74% | Training loss: 0.6869637779536701
Epoch: 69 | Iteration number: [3370/4518] 74% | Training loss: 0.6869597410059116
Epoch: 69 | Iteration number: [3380/4518] 74% | Training loss: 0.6869591518266667
Epoch: 69 | Iteration number: [3390/4518] 75% | Training loss: 0.6869608775001008
Epoch: 69 | Iteration number: [3400/4518] 75% | Training loss: 0.6869593463049215
Epoch: 69 | Iteration number: [3410/4518] 75% | Training loss: 0.6869611986571393
Epoch: 69 | Iteration number: [3420/4518] 75% | Training loss: 0.6869621916472564
Epoch: 69 | Iteration number: [3430/4518] 75% | Training loss: 0.6869633775063229
Epoch: 69 | Iteration number: [3440/4518] 76% | Training loss: 0.6869589560946753
Epoch: 69 | Iteration number: [3450/4518] 76% | Training loss: 0.6869556317813155
Epoch: 69 | Iteration number: [3460/4518] 76% | Training loss: 0.6869551802990753
Epoch: 69 | Iteration number: [3470/4518] 76% | Training loss: 0.6869583620805219
Epoch: 69 | Iteration number: [3480/4518] 77% | Training loss: 0.6869526549659927
Epoch: 69 | Iteration number: [3490/4518] 77% | Training loss: 0.6869534192932369
Epoch: 69 | Iteration number: [3500/4518] 77% | Training loss: 0.6869545883110592
Epoch: 69 | Iteration number: [3510/4518] 77% | Training loss: 0.686957243619821
Epoch: 69 | Iteration number: [3520/4518] 77% | Training loss: 0.6869562585584142
Epoch: 69 | Iteration number: [3530/4518] 78% | Training loss: 0.6869562265217811
Epoch: 69 | Iteration number: [3540/4518] 78% | Training loss: 0.686953824051356
Epoch: 69 | Iteration number: [3550/4518] 78% | Training loss: 0.6869562378231908
Epoch: 69 | Iteration number: [3560/4518] 78% | Training loss: 0.6869562927256809
Epoch: 69 | Iteration number: [3570/4518] 79% | Training loss: 0.686954744423137
Epoch: 69 | Iteration number: [3580/4518] 79% | Training loss: 0.6869563707925754
Epoch: 69 | Iteration number: [3590/4518] 79% | Training loss: 0.6869580373790602
Epoch: 69 | Iteration number: [3600/4518] 79% | Training loss: 0.6869536119865046
Epoch: 69 | Iteration number: [3610/4518] 79% | Training loss: 0.6869514233682955
Epoch: 69 | Iteration number: [3620/4518] 80% | Training loss: 0.6869519390124642
Epoch: 69 | Iteration number: [3630/4518] 80% | Training loss: 0.6869525450977084
Epoch: 69 | Iteration number: [3640/4518] 80% | Training loss: 0.6869505518412852
Epoch: 69 | Iteration number: [3650/4518] 80% | Training loss: 0.6869506170161783
Epoch: 69 | Iteration number: [3660/4518] 81% | Training loss: 0.6869518271398023
Epoch: 69 | Iteration number: [3670/4518] 81% | Training loss: 0.6869501743232197
Epoch: 69 | Iteration number: [3680/4518] 81% | Training loss: 0.6869526787944462
Epoch: 69 | Iteration number: [3690/4518] 81% | Training loss: 0.6869506074484125
Epoch: 69 | Iteration number: [3700/4518] 81% | Training loss: 0.6869459214403822
Epoch: 69 | Iteration number: [3710/4518] 82% | Training loss: 0.6869468349652149
Epoch: 69 | Iteration number: [3720/4518] 82% | Training loss: 0.686943961904254
Epoch: 69 | Iteration number: [3730/4518] 82% | Training loss: 0.6869410296227912
Epoch: 69 | Iteration number: [3740/4518] 82% | Training loss: 0.6869431215811541
Epoch: 69 | Iteration number: [3750/4518] 83% | Training loss: 0.6869417822678884
Epoch: 69 | Iteration number: [3760/4518] 83% | Training loss: 0.6869429201997341
Epoch: 69 | Iteration number: [3770/4518] 83% | Training loss: 0.686942609251336
Epoch: 69 | Iteration number: [3780/4518] 83% | Training loss: 0.6869456044580571
Epoch: 69 | Iteration number: [3790/4518] 83% | Training loss: 0.686948284876378
Epoch: 69 | Iteration number: [3800/4518] 84% | Training loss: 0.6869472759962082
Epoch: 69 | Iteration number: [3810/4518] 84% | Training loss: 0.686947055438685
Epoch: 69 | Iteration number: [3820/4518] 84% | Training loss: 0.6869504890828857
Epoch: 69 | Iteration number: [3830/4518] 84% | Training loss: 0.6869514162951288
Epoch: 69 | Iteration number: [3840/4518] 84% | Training loss: 0.6869511255839219
Epoch: 69 | Iteration number: [3850/4518] 85% | Training loss: 0.6869502808211686
Epoch: 69 | Iteration number: [3860/4518] 85% | Training loss: 0.6869500103392132
Epoch: 69 | Iteration number: [3870/4518] 85% | Training loss: 0.6869471166947091
Epoch: 69 | Iteration number: [3880/4518] 85% | Training loss: 0.6869444611299899
Epoch: 69 | Iteration number: [3890/4518] 86% | Training loss: 0.6869447570227105
Epoch: 69 | Iteration number: [3900/4518] 86% | Training loss: 0.6869463507487223
Epoch: 69 | Iteration number: [3910/4518] 86% | Training loss: 0.6869469912765581
Epoch: 69 | Iteration number: [3920/4518] 86% | Training loss: 0.6869480527633307
Epoch: 69 | Iteration number: [3930/4518] 86% | Training loss: 0.6869516932175663
Epoch: 69 | Iteration number: [3940/4518] 87% | Training loss: 0.6869512371756704
Epoch: 69 | Iteration number: [3950/4518] 87% | Training loss: 0.6869508082806309
Epoch: 69 | Iteration number: [3960/4518] 87% | Training loss: 0.6869459327724244
Epoch: 69 | Iteration number: [3970/4518] 87% | Training loss: 0.6869416148746644
Epoch: 69 | Iteration number: [3980/4518] 88% | Training loss: 0.686942656420583
Epoch: 69 | Iteration number: [3990/4518] 88% | Training loss: 0.686942589357682
Epoch: 69 | Iteration number: [4000/4518] 88% | Training loss: 0.6869417356997728
Epoch: 69 | Iteration number: [4010/4518] 88% | Training loss: 0.6869373921741572
Epoch: 69 | Iteration number: [4020/4518] 88% | Training loss: 0.6869385050896981
Epoch: 69 | Iteration number: [4030/4518] 89% | Training loss: 0.6869390755374142
Epoch: 69 | Iteration number: [4040/4518] 89% | Training loss: 0.6869374317550423
Epoch: 69 | Iteration number: [4050/4518] 89% | Training loss: 0.6869372644395004
Epoch: 69 | Iteration number: [4060/4518] 89% | Training loss: 0.6869359931628692
Epoch: 69 | Iteration number: [4070/4518] 90% | Training loss: 0.6869359387958958
Epoch: 69 | Iteration number: [4080/4518] 90% | Training loss: 0.6869366562103524
Epoch: 69 | Iteration number: [4090/4518] 90% | Training loss: 0.6869396031777258
Epoch: 69 | Iteration number: [4100/4518] 90% | Training loss: 0.6869371247146188
Epoch: 69 | Iteration number: [4110/4518] 90% | Training loss: 0.6869371506999589
Epoch: 69 | Iteration number: [4120/4518] 91% | Training loss: 0.6869366273717973
Epoch: 69 | Iteration number: [4130/4518] 91% | Training loss: 0.6869343501170668
Epoch: 69 | Iteration number: [4140/4518] 91% | Training loss: 0.6869362579451667
Epoch: 69 | Iteration number: [4150/4518] 91% | Training loss: 0.6869355302690023
Epoch: 69 | Iteration number: [4160/4518] 92% | Training loss: 0.6869351459380526
Epoch: 69 | Iteration number: [4170/4518] 92% | Training loss: 0.6869369635621992
Epoch: 69 | Iteration number: [4180/4518] 92% | Training loss: 0.6869374815927168
Epoch: 69 | Iteration number: [4190/4518] 92% | Training loss: 0.6869360635274919
Epoch: 69 | Iteration number: [4200/4518] 92% | Training loss: 0.6869385111757688
Epoch: 69 | Iteration number: [4210/4518] 93% | Training loss: 0.6869406930766027
Epoch: 69 | Iteration number: [4220/4518] 93% | Training loss: 0.6869419821206992
Epoch: 69 | Iteration number: [4230/4518] 93% | Training loss: 0.6869420093988414
Epoch: 69 | Iteration number: [4240/4518] 93% | Training loss: 0.6869408656825434
Epoch: 69 | Iteration number: [4250/4518] 94% | Training loss: 0.6869399376055774
Epoch: 69 | Iteration number: [4260/4518] 94% | Training loss: 0.68694240902791
Epoch: 69 | Iteration number: [4270/4518] 94% | Training loss: 0.6869405013336789
Epoch: 69 | Iteration number: [4280/4518] 94% | Training loss: 0.6869405065045179
Epoch: 69 | Iteration number: [4290/4518] 94% | Training loss: 0.6869401979140747
Epoch: 69 | Iteration number: [4300/4518] 95% | Training loss: 0.6869409524008285
Epoch: 69 | Iteration number: [4310/4518] 95% | Training loss: 0.6869396522675756
Epoch: 69 | Iteration number: [4320/4518] 95% | Training loss: 0.686936887326064
Epoch: 69 | Iteration number: [4330/4518] 95% | Training loss: 0.6869346112769966
Epoch: 69 | Iteration number: [4340/4518] 96% | Training loss: 0.6869342143497159
Epoch: 69 | Iteration number: [4350/4518] 96% | Training loss: 0.6869351581321366
Epoch: 69 | Iteration number: [4360/4518] 96% | Training loss: 0.6869339599795298
Epoch: 69 | Iteration number: [4370/4518] 96% | Training loss: 0.6869351096911616
Epoch: 69 | Iteration number: [4380/4518] 96% | Training loss: 0.6869347254979556
Epoch: 69 | Iteration number: [4390/4518] 97% | Training loss: 0.6869363702375416
Epoch: 69 | Iteration number: [4400/4518] 97% | Training loss: 0.6869370725073598
Epoch: 69 | Iteration number: [4410/4518] 97% | Training loss: 0.6869382004889231
Epoch: 69 | Iteration number: [4420/4518] 97% | Training loss: 0.6869381971623563
Epoch: 69 | Iteration number: [4430/4518] 98% | Training loss: 0.6869398164829874
Epoch: 69 | Iteration number: [4440/4518] 98% | Training loss: 0.6869404705392348
Epoch: 69 | Iteration number: [4450/4518] 98% | Training loss: 0.686937376461672
Epoch: 69 | Iteration number: [4460/4518] 98% | Training loss: 0.6869367319639488
Epoch: 69 | Iteration number: [4470/4518] 98% | Training loss: 0.6869328070673634
Epoch: 69 | Iteration number: [4480/4518] 99% | Training loss: 0.686932612010943
Epoch: 69 | Iteration number: [4490/4518] 99% | Training loss: 0.6869293061954141
Epoch: 69 | Iteration number: [4500/4518] 99% | Training loss: 0.6869288291533788
Epoch: 69 | Iteration number: [4510/4518] 99% | Training loss: 0.686929094130607

 End of epoch: 69 | Train Loss: 0.6867768633360354 | Training Time: 642 

 End of epoch: 69 | Eval Loss: 0.6898391952320021 | Evaluating Time: 17 
Epoch: 70 | Iteration number: [10/4518] 0% | Training loss: 0.7541332125663758
Epoch: 70 | Iteration number: [20/4518] 0% | Training loss: 0.7201749980449677
Epoch: 70 | Iteration number: [30/4518] 0% | Training loss: 0.7092857917149862
Epoch: 70 | Iteration number: [40/4518] 0% | Training loss: 0.7034093394875527
Epoch: 70 | Iteration number: [50/4518] 1% | Training loss: 0.7000368452072143
Epoch: 70 | Iteration number: [60/4518] 1% | Training loss: 0.6980098058780034
Epoch: 70 | Iteration number: [70/4518] 1% | Training loss: 0.6964895035539355
Epoch: 70 | Iteration number: [80/4518] 1% | Training loss: 0.6952420316636563
Epoch: 70 | Iteration number: [90/4518] 1% | Training loss: 0.6942503035068512
Epoch: 70 | Iteration number: [100/4518] 2% | Training loss: 0.6934590667486191
Epoch: 70 | Iteration number: [110/4518] 2% | Training loss: 0.6928180494091728
Epoch: 70 | Iteration number: [120/4518] 2% | Training loss: 0.6923720027009647
Epoch: 70 | Iteration number: [130/4518] 2% | Training loss: 0.6920169931191664
Epoch: 70 | Iteration number: [140/4518] 3% | Training loss: 0.6916857353278569
Epoch: 70 | Iteration number: [150/4518] 3% | Training loss: 0.691385718981425
Epoch: 70 | Iteration number: [160/4518] 3% | Training loss: 0.6910902060568332
Epoch: 70 | Iteration number: [170/4518] 3% | Training loss: 0.6907823678325204
Epoch: 70 | Iteration number: [180/4518] 3% | Training loss: 0.6904826243718465
Epoch: 70 | Iteration number: [190/4518] 4% | Training loss: 0.6903043461473365
Epoch: 70 | Iteration number: [200/4518] 4% | Training loss: 0.690095422565937
Epoch: 70 | Iteration number: [210/4518] 4% | Training loss: 0.6899312845298222
Epoch: 70 | Iteration number: [220/4518] 4% | Training loss: 0.689813614433462
Epoch: 70 | Iteration number: [230/4518] 5% | Training loss: 0.6896831105584683
Epoch: 70 | Iteration number: [240/4518] 5% | Training loss: 0.6895586570103963
Epoch: 70 | Iteration number: [250/4518] 5% | Training loss: 0.6893994483947754
Epoch: 70 | Iteration number: [260/4518] 5% | Training loss: 0.6893114539293143
Epoch: 70 | Iteration number: [270/4518] 5% | Training loss: 0.6891763960873639
Epoch: 70 | Iteration number: [280/4518] 6% | Training loss: 0.6890903462256704
Epoch: 70 | Iteration number: [290/4518] 6% | Training loss: 0.6889507347139819
Epoch: 70 | Iteration number: [300/4518] 6% | Training loss: 0.688895493944486
Epoch: 70 | Iteration number: [310/4518] 6% | Training loss: 0.6887887706679683
Epoch: 70 | Iteration number: [320/4518] 7% | Training loss: 0.6887376882135868
Epoch: 70 | Iteration number: [330/4518] 7% | Training loss: 0.6887180044795528
Epoch: 70 | Iteration number: [340/4518] 7% | Training loss: 0.6886657152105781
Epoch: 70 | Iteration number: [350/4518] 7% | Training loss: 0.6885923491205488
Epoch: 70 | Iteration number: [360/4518] 7% | Training loss: 0.6885485258367326
Epoch: 70 | Iteration number: [370/4518] 8% | Training loss: 0.6885217421763652
Epoch: 70 | Iteration number: [380/4518] 8% | Training loss: 0.6884834189164011
Epoch: 70 | Iteration number: [390/4518] 8% | Training loss: 0.6884348522394131
Epoch: 70 | Iteration number: [400/4518] 8% | Training loss: 0.6883618731796741
Epoch: 70 | Iteration number: [410/4518] 9% | Training loss: 0.6883236749870021
Epoch: 70 | Iteration number: [420/4518] 9% | Training loss: 0.6882861372970399
Epoch: 70 | Iteration number: [430/4518] 9% | Training loss: 0.6882749453533528
Epoch: 70 | Iteration number: [440/4518] 9% | Training loss: 0.6882590762593529
Epoch: 70 | Iteration number: [450/4518] 9% | Training loss: 0.6882127377721998
Epoch: 70 | Iteration number: [460/4518] 10% | Training loss: 0.6881656359071316
Epoch: 70 | Iteration number: [470/4518] 10% | Training loss: 0.6881377822541176
Epoch: 70 | Iteration number: [480/4518] 10% | Training loss: 0.6880984415610631
Epoch: 70 | Iteration number: [490/4518] 10% | Training loss: 0.6880704222893228
Epoch: 70 | Iteration number: [500/4518] 11% | Training loss: 0.6880442252159119
Epoch: 70 | Iteration number: [510/4518] 11% | Training loss: 0.6880256700749491
Epoch: 70 | Iteration number: [520/4518] 11% | Training loss: 0.6880090123185745
Epoch: 70 | Iteration number: [530/4518] 11% | Training loss: 0.6879707641196701
Epoch: 70 | Iteration number: [540/4518] 11% | Training loss: 0.687953038458471
Epoch: 70 | Iteration number: [550/4518] 12% | Training loss: 0.6879430531371723
Epoch: 70 | Iteration number: [560/4518] 12% | Training loss: 0.6879401029220649
Epoch: 70 | Iteration number: [570/4518] 12% | Training loss: 0.6879075170608989
Epoch: 70 | Iteration number: [580/4518] 12% | Training loss: 0.687901624009527
Epoch: 70 | Iteration number: [590/4518] 13% | Training loss: 0.6878535753589565
Epoch: 70 | Iteration number: [600/4518] 13% | Training loss: 0.6878390862544378
Epoch: 70 | Iteration number: [610/4518] 13% | Training loss: 0.6878119778437692
Epoch: 70 | Iteration number: [620/4518] 13% | Training loss: 0.6878023643647471
Epoch: 70 | Iteration number: [630/4518] 13% | Training loss: 0.6878025978330582
Epoch: 70 | Iteration number: [640/4518] 14% | Training loss: 0.6877933117561043
Epoch: 70 | Iteration number: [650/4518] 14% | Training loss: 0.6877823162995852
Epoch: 70 | Iteration number: [660/4518] 14% | Training loss: 0.68777795289502
Epoch: 70 | Iteration number: [670/4518] 14% | Training loss: 0.6877697912614738
Epoch: 70 | Iteration number: [680/4518] 15% | Training loss: 0.6877500316675972
Epoch: 70 | Iteration number: [690/4518] 15% | Training loss: 0.6877265059429666
Epoch: 70 | Iteration number: [700/4518] 15% | Training loss: 0.6877055714811597
Epoch: 70 | Iteration number: [710/4518] 15% | Training loss: 0.6876802687074097
Epoch: 70 | Iteration number: [720/4518] 15% | Training loss: 0.687661084615522
Epoch: 70 | Iteration number: [730/4518] 16% | Training loss: 0.6876557048052958
Epoch: 70 | Iteration number: [740/4518] 16% | Training loss: 0.6876478276542715
Epoch: 70 | Iteration number: [750/4518] 16% | Training loss: 0.68763352338473
Epoch: 70 | Iteration number: [760/4518] 16% | Training loss: 0.6876241759250038
Epoch: 70 | Iteration number: [770/4518] 17% | Training loss: 0.6876352676323482
Epoch: 70 | Iteration number: [780/4518] 17% | Training loss: 0.6876248854093062
Epoch: 70 | Iteration number: [790/4518] 17% | Training loss: 0.687621034021619
Epoch: 70 | Iteration number: [800/4518] 17% | Training loss: 0.6876189622282982
Epoch: 70 | Iteration number: [810/4518] 17% | Training loss: 0.6876265571441179
Epoch: 70 | Iteration number: [820/4518] 18% | Training loss: 0.6876193691317628
Epoch: 70 | Iteration number: [830/4518] 18% | Training loss: 0.6876107243170221
Epoch: 70 | Iteration number: [840/4518] 18% | Training loss: 0.687606372152056
Epoch: 70 | Iteration number: [850/4518] 18% | Training loss: 0.6876007149500005
Epoch: 70 | Iteration number: [860/4518] 19% | Training loss: 0.6875734173974325
Epoch: 70 | Iteration number: [870/4518] 19% | Training loss: 0.6875674017544451
Epoch: 70 | Iteration number: [880/4518] 19% | Training loss: 0.6875557724725117
Epoch: 70 | Iteration number: [890/4518] 19% | Training loss: 0.6875451243995281
Epoch: 70 | Iteration number: [900/4518] 19% | Training loss: 0.6875457144445843
Epoch: 70 | Iteration number: [910/4518] 20% | Training loss: 0.6875440383350456
Epoch: 70 | Iteration number: [920/4518] 20% | Training loss: 0.6875269944253175
Epoch: 70 | Iteration number: [930/4518] 20% | Training loss: 0.68751938336639
Epoch: 70 | Iteration number: [940/4518] 20% | Training loss: 0.6875279647872803
Epoch: 70 | Iteration number: [950/4518] 21% | Training loss: 0.6875178008330496
Epoch: 70 | Iteration number: [960/4518] 21% | Training loss: 0.6875041611492634
Epoch: 70 | Iteration number: [970/4518] 21% | Training loss: 0.687495873515139
Epoch: 70 | Iteration number: [980/4518] 21% | Training loss: 0.6874905656795113
Epoch: 70 | Iteration number: [990/4518] 21% | Training loss: 0.6874882979826493
Epoch: 70 | Iteration number: [1000/4518] 22% | Training loss: 0.6874908828139306
Epoch: 70 | Iteration number: [1010/4518] 22% | Training loss: 0.6874758637777649
Epoch: 70 | Iteration number: [1020/4518] 22% | Training loss: 0.6874706032813764
Epoch: 70 | Iteration number: [1030/4518] 22% | Training loss: 0.6874547065461724
Epoch: 70 | Iteration number: [1040/4518] 23% | Training loss: 0.6874534067053061
Epoch: 70 | Iteration number: [1050/4518] 23% | Training loss: 0.6874414992332458
Epoch: 70 | Iteration number: [1060/4518] 23% | Training loss: 0.6874314256996479
Epoch: 70 | Iteration number: [1070/4518] 23% | Training loss: 0.6874249844350547
Epoch: 70 | Iteration number: [1080/4518] 23% | Training loss: 0.6874236228289428
Epoch: 70 | Iteration number: [1090/4518] 24% | Training loss: 0.6874157349450872
Epoch: 70 | Iteration number: [1100/4518] 24% | Training loss: 0.6874059272354299
Epoch: 70 | Iteration number: [1110/4518] 24% | Training loss: 0.6873963556311152
Epoch: 70 | Iteration number: [1120/4518] 24% | Training loss: 0.6873894466885498
Epoch: 70 | Iteration number: [1130/4518] 25% | Training loss: 0.6873907697411765
Epoch: 70 | Iteration number: [1140/4518] 25% | Training loss: 0.68738459955182
Epoch: 70 | Iteration number: [1150/4518] 25% | Training loss: 0.6873764390530793
Epoch: 70 | Iteration number: [1160/4518] 25% | Training loss: 0.687382255905661
Epoch: 70 | Iteration number: [1170/4518] 25% | Training loss: 0.6873886033001109
Epoch: 70 | Iteration number: [1180/4518] 26% | Training loss: 0.6873778494232792
Epoch: 70 | Iteration number: [1190/4518] 26% | Training loss: 0.6873743614228833
Epoch: 70 | Iteration number: [1200/4518] 26% | Training loss: 0.6873697616656621
Epoch: 70 | Iteration number: [1210/4518] 26% | Training loss: 0.6873683195961409
Epoch: 70 | Iteration number: [1220/4518] 27% | Training loss: 0.6873727982650037
Epoch: 70 | Iteration number: [1230/4518] 27% | Training loss: 0.687365520194294
Epoch: 70 | Iteration number: [1240/4518] 27% | Training loss: 0.6873598378512167
Epoch: 70 | Iteration number: [1250/4518] 27% | Training loss: 0.6873614208698273
Epoch: 70 | Iteration number: [1260/4518] 27% | Training loss: 0.6873538216428151
Epoch: 70 | Iteration number: [1270/4518] 28% | Training loss: 0.6873535967248632
Epoch: 70 | Iteration number: [1280/4518] 28% | Training loss: 0.6873557423241436
Epoch: 70 | Iteration number: [1290/4518] 28% | Training loss: 0.6873529726220656
Epoch: 70 | Iteration number: [1300/4518] 28% | Training loss: 0.6873477245752628
Epoch: 70 | Iteration number: [1310/4518] 28% | Training loss: 0.6873430595598148
Epoch: 70 | Iteration number: [1320/4518] 29% | Training loss: 0.687334193424745
Epoch: 70 | Iteration number: [1330/4518] 29% | Training loss: 0.6873391233888784
Epoch: 70 | Iteration number: [1340/4518] 29% | Training loss: 0.6873343232852309
Epoch: 70 | Iteration number: [1350/4518] 29% | Training loss: 0.6873429542559164
Epoch: 70 | Iteration number: [1360/4518] 30% | Training loss: 0.6873405097600291
Epoch: 70 | Iteration number: [1370/4518] 30% | Training loss: 0.6873362493340986
Epoch: 70 | Iteration number: [1380/4518] 30% | Training loss: 0.6873283445403195
Epoch: 70 | Iteration number: [1390/4518] 30% | Training loss: 0.6873243398374791
Epoch: 70 | Iteration number: [1400/4518] 30% | Training loss: 0.6873215606382915
Epoch: 70 | Iteration number: [1410/4518] 31% | Training loss: 0.6873190093970468
Epoch: 70 | Iteration number: [1420/4518] 31% | Training loss: 0.687312411464436
Epoch: 70 | Iteration number: [1430/4518] 31% | Training loss: 0.6873025253102496
Epoch: 70 | Iteration number: [1440/4518] 31% | Training loss: 0.687298761597938
Epoch: 70 | Iteration number: [1450/4518] 32% | Training loss: 0.6872943722790685
Epoch: 70 | Iteration number: [1460/4518] 32% | Training loss: 0.6872882579695688
Epoch: 70 | Iteration number: [1470/4518] 32% | Training loss: 0.6872846558385965
Epoch: 70 | Iteration number: [1480/4518] 32% | Training loss: 0.6872742372187408
Epoch: 70 | Iteration number: [1490/4518] 32% | Training loss: 0.6872699862758586
Epoch: 70 | Iteration number: [1500/4518] 33% | Training loss: 0.6872739102045695
Epoch: 70 | Iteration number: [1510/4518] 33% | Training loss: 0.6872710541384109
Epoch: 70 | Iteration number: [1520/4518] 33% | Training loss: 0.687267528082195
Epoch: 70 | Iteration number: [1530/4518] 33% | Training loss: 0.6872678726327186
Epoch: 70 | Iteration number: [1540/4518] 34% | Training loss: 0.6872692819926646
Epoch: 70 | Iteration number: [1550/4518] 34% | Training loss: 0.6872579879530014
Epoch: 70 | Iteration number: [1560/4518] 34% | Training loss: 0.6872571934110079
Epoch: 70 | Iteration number: [1570/4518] 34% | Training loss: 0.6872520046628964
Epoch: 70 | Iteration number: [1580/4518] 34% | Training loss: 0.6872454032490525
Epoch: 70 | Iteration number: [1590/4518] 35% | Training loss: 0.687235677429715
Epoch: 70 | Iteration number: [1600/4518] 35% | Training loss: 0.6872316108644009
Epoch: 70 | Iteration number: [1610/4518] 35% | Training loss: 0.6872289873058011
Epoch: 70 | Iteration number: [1620/4518] 35% | Training loss: 0.6872249722112844
Epoch: 70 | Iteration number: [1630/4518] 36% | Training loss: 0.6872123512388008
Epoch: 70 | Iteration number: [1640/4518] 36% | Training loss: 0.6871992016710886
Epoch: 70 | Iteration number: [1650/4518] 36% | Training loss: 0.6871946899457412
Epoch: 70 | Iteration number: [1660/4518] 36% | Training loss: 0.6871850100626429
Epoch: 70 | Iteration number: [1670/4518] 36% | Training loss: 0.6871844833482526
Epoch: 70 | Iteration number: [1680/4518] 37% | Training loss: 0.6871904385586579
Epoch: 70 | Iteration number: [1690/4518] 37% | Training loss: 0.6871802010127073
Epoch: 70 | Iteration number: [1700/4518] 37% | Training loss: 0.6871780819402021
Epoch: 70 | Iteration number: [1710/4518] 37% | Training loss: 0.6871795751197993
Epoch: 70 | Iteration number: [1720/4518] 38% | Training loss: 0.6871727794408798
Epoch: 70 | Iteration number: [1730/4518] 38% | Training loss: 0.68717221145685
Epoch: 70 | Iteration number: [1740/4518] 38% | Training loss: 0.6871772188564826
Epoch: 70 | Iteration number: [1750/4518] 38% | Training loss: 0.6871719067437309
Epoch: 70 | Iteration number: [1760/4518] 38% | Training loss: 0.6871679475022988
Epoch: 70 | Iteration number: [1770/4518] 39% | Training loss: 0.6871598564635563
Epoch: 70 | Iteration number: [1780/4518] 39% | Training loss: 0.687165061242125
Epoch: 70 | Iteration number: [1790/4518] 39% | Training loss: 0.6871669702023767
Epoch: 70 | Iteration number: [1800/4518] 39% | Training loss: 0.6871612273322212
Epoch: 70 | Iteration number: [1810/4518] 40% | Training loss: 0.6871621103247226
Epoch: 70 | Iteration number: [1820/4518] 40% | Training loss: 0.6871599820616481
Epoch: 70 | Iteration number: [1830/4518] 40% | Training loss: 0.6871578657236256
Epoch: 70 | Iteration number: [1840/4518] 40% | Training loss: 0.6871647965972838
Epoch: 70 | Iteration number: [1850/4518] 40% | Training loss: 0.6871625905745739
Epoch: 70 | Iteration number: [1860/4518] 41% | Training loss: 0.6871562601417623
Epoch: 70 | Iteration number: [1870/4518] 41% | Training loss: 0.6871571598205974
Epoch: 70 | Iteration number: [1880/4518] 41% | Training loss: 0.6871463369181816
Epoch: 70 | Iteration number: [1890/4518] 41% | Training loss: 0.6871483727737709
Epoch: 70 | Iteration number: [1900/4518] 42% | Training loss: 0.6871392184182217
Epoch: 70 | Iteration number: [1910/4518] 42% | Training loss: 0.6871365377104095
Epoch: 70 | Iteration number: [1920/4518] 42% | Training loss: 0.6871325916300217
Epoch: 70 | Iteration number: [1930/4518] 42% | Training loss: 0.6871403254684388
Epoch: 70 | Iteration number: [1940/4518] 42% | Training loss: 0.6871349448702999
Epoch: 70 | Iteration number: [1950/4518] 43% | Training loss: 0.6871386370903406
Epoch: 70 | Iteration number: [1960/4518] 43% | Training loss: 0.6871325685357561
Epoch: 70 | Iteration number: [1970/4518] 43% | Training loss: 0.6871326667403207
Epoch: 70 | Iteration number: [1980/4518] 43% | Training loss: 0.6871335750276392
Epoch: 70 | Iteration number: [1990/4518] 44% | Training loss: 0.6871289964896351
Epoch: 70 | Iteration number: [2000/4518] 44% | Training loss: 0.6871271995902062
Epoch: 70 | Iteration number: [2010/4518] 44% | Training loss: 0.6871274465648689
Epoch: 70 | Iteration number: [2020/4518] 44% | Training loss: 0.6871265856346281
Epoch: 70 | Iteration number: [2030/4518] 44% | Training loss: 0.6871184243063622
Epoch: 70 | Iteration number: [2040/4518] 45% | Training loss: 0.6871155713995297
Epoch: 70 | Iteration number: [2050/4518] 45% | Training loss: 0.6871176432400214
Epoch: 70 | Iteration number: [2060/4518] 45% | Training loss: 0.6871193230441474
Epoch: 70 | Iteration number: [2070/4518] 45% | Training loss: 0.6871198285317075
Epoch: 70 | Iteration number: [2080/4518] 46% | Training loss: 0.6871205899291314
Epoch: 70 | Iteration number: [2090/4518] 46% | Training loss: 0.6871190193737523
Epoch: 70 | Iteration number: [2100/4518] 46% | Training loss: 0.6871184814543951
Epoch: 70 | Iteration number: [2110/4518] 46% | Training loss: 0.6871128628039247
Epoch: 70 | Iteration number: [2120/4518] 46% | Training loss: 0.6871147096157074
Epoch: 70 | Iteration number: [2130/4518] 47% | Training loss: 0.6871079008903862
Epoch: 70 | Iteration number: [2140/4518] 47% | Training loss: 0.6871064778521796
Epoch: 70 | Iteration number: [2150/4518] 47% | Training loss: 0.6871066323546476
Epoch: 70 | Iteration number: [2160/4518] 47% | Training loss: 0.6871037885270737
Epoch: 70 | Iteration number: [2170/4518] 48% | Training loss: 0.6871020615375536
Epoch: 70 | Iteration number: [2180/4518] 48% | Training loss: 0.6871009701435719
Epoch: 70 | Iteration number: [2190/4518] 48% | Training loss: 0.6871059552991772
Epoch: 70 | Iteration number: [2200/4518] 48% | Training loss: 0.6871081684123386
Epoch: 70 | Iteration number: [2210/4518] 48% | Training loss: 0.6871107630600217
Epoch: 70 | Iteration number: [2220/4518] 49% | Training loss: 0.6871078642370465
Epoch: 70 | Iteration number: [2230/4518] 49% | Training loss: 0.6871118514259834
Epoch: 70 | Iteration number: [2240/4518] 49% | Training loss: 0.6871054361175214
Epoch: 70 | Iteration number: [2250/4518] 49% | Training loss: 0.6870996321572198
Epoch: 70 | Iteration number: [2260/4518] 50% | Training loss: 0.6871053086972869
Epoch: 70 | Iteration number: [2270/4518] 50% | Training loss: 0.68710394577833
Epoch: 70 | Iteration number: [2280/4518] 50% | Training loss: 0.6870966800472192
Epoch: 70 | Iteration number: [2290/4518] 50% | Training loss: 0.6870929133423551
Epoch: 70 | Iteration number: [2300/4518] 50% | Training loss: 0.6870969700554143
Epoch: 70 | Iteration number: [2310/4518] 51% | Training loss: 0.687100719915324
Epoch: 70 | Iteration number: [2320/4518] 51% | Training loss: 0.6870972615377656
Epoch: 70 | Iteration number: [2330/4518] 51% | Training loss: 0.6870927089529487
Epoch: 70 | Iteration number: [2340/4518] 51% | Training loss: 0.6870950776287633
Epoch: 70 | Iteration number: [2350/4518] 52% | Training loss: 0.6870890486494023
Epoch: 70 | Iteration number: [2360/4518] 52% | Training loss: 0.6870879033864554
Epoch: 70 | Iteration number: [2370/4518] 52% | Training loss: 0.6870913816152243
Epoch: 70 | Iteration number: [2380/4518] 52% | Training loss: 0.6870937488660092
Epoch: 70 | Iteration number: [2390/4518] 52% | Training loss: 0.6870948628152265
Epoch: 70 | Iteration number: [2400/4518] 53% | Training loss: 0.6870948705573877
Epoch: 70 | Iteration number: [2410/4518] 53% | Training loss: 0.6870909175437516
Epoch: 70 | Iteration number: [2420/4518] 53% | Training loss: 0.6870888873811596
Epoch: 70 | Iteration number: [2430/4518] 53% | Training loss: 0.687086710591375
Epoch: 70 | Iteration number: [2440/4518] 54% | Training loss: 0.6870863378536506
Epoch: 70 | Iteration number: [2450/4518] 54% | Training loss: 0.6870861709361173
Epoch: 70 | Iteration number: [2460/4518] 54% | Training loss: 0.6870845493020081
Epoch: 70 | Iteration number: [2470/4518] 54% | Training loss: 0.6870841992046186
Epoch: 70 | Iteration number: [2480/4518] 54% | Training loss: 0.6870832361280919
Epoch: 70 | Iteration number: [2490/4518] 55% | Training loss: 0.6870804918099599
Epoch: 70 | Iteration number: [2500/4518] 55% | Training loss: 0.6870801440954208
Epoch: 70 | Iteration number: [2510/4518] 55% | Training loss: 0.6870848631716344
Epoch: 70 | Iteration number: [2520/4518] 55% | Training loss: 0.6870811630809118
Epoch: 70 | Iteration number: [2530/4518] 55% | Training loss: 0.6870792931483197
Epoch: 70 | Iteration number: [2540/4518] 56% | Training loss: 0.6870740091472161
Epoch: 70 | Iteration number: [2550/4518] 56% | Training loss: 0.687078448674258
Epoch: 70 | Iteration number: [2560/4518] 56% | Training loss: 0.6870791135588661
Epoch: 70 | Iteration number: [2570/4518] 56% | Training loss: 0.6870765098106073
Epoch: 70 | Iteration number: [2580/4518] 57% | Training loss: 0.6870757394751837
Epoch: 70 | Iteration number: [2590/4518] 57% | Training loss: 0.6870762794634551
Epoch: 70 | Iteration number: [2600/4518] 57% | Training loss: 0.6870786942885472
Epoch: 70 | Iteration number: [2610/4518] 57% | Training loss: 0.6870799500595107
Epoch: 70 | Iteration number: [2620/4518] 57% | Training loss: 0.6870813468257889
Epoch: 70 | Iteration number: [2630/4518] 58% | Training loss: 0.6870805603469733
Epoch: 70 | Iteration number: [2640/4518] 58% | Training loss: 0.6870767457918687
Epoch: 70 | Iteration number: [2650/4518] 58% | Training loss: 0.6870749943886163
Epoch: 70 | Iteration number: [2660/4518] 58% | Training loss: 0.687072174867293
Epoch: 70 | Iteration number: [2670/4518] 59% | Training loss: 0.6870717251122221
Epoch: 70 | Iteration number: [2680/4518] 59% | Training loss: 0.6870667180018638
Epoch: 70 | Iteration number: [2690/4518] 59% | Training loss: 0.6870654834912169
Epoch: 70 | Iteration number: [2700/4518] 59% | Training loss: 0.6870605811366328
Epoch: 70 | Iteration number: [2710/4518] 59% | Training loss: 0.6870577620844119
Epoch: 70 | Iteration number: [2720/4518] 60% | Training loss: 0.6870538312722655
Epoch: 70 | Iteration number: [2730/4518] 60% | Training loss: 0.687057688559368
Epoch: 70 | Iteration number: [2740/4518] 60% | Training loss: 0.6870540579087543
Epoch: 70 | Iteration number: [2750/4518] 60% | Training loss: 0.687054137099873
Epoch: 70 | Iteration number: [2760/4518] 61% | Training loss: 0.6870541544496149
Epoch: 70 | Iteration number: [2770/4518] 61% | Training loss: 0.6870536494341137
Epoch: 70 | Iteration number: [2780/4518] 61% | Training loss: 0.6870523119144303
Epoch: 70 | Iteration number: [2790/4518] 61% | Training loss: 0.6870516536269992
Epoch: 70 | Iteration number: [2800/4518] 61% | Training loss: 0.6870474179514817
Epoch: 70 | Iteration number: [2810/4518] 62% | Training loss: 0.6870425311908179
Epoch: 70 | Iteration number: [2820/4518] 62% | Training loss: 0.6870372791873648
Epoch: 70 | Iteration number: [2830/4518] 62% | Training loss: 0.6870307320840788
Epoch: 70 | Iteration number: [2840/4518] 62% | Training loss: 0.68703234720398
Epoch: 70 | Iteration number: [2850/4518] 63% | Training loss: 0.6870276075497008
Epoch: 70 | Iteration number: [2860/4518] 63% | Training loss: 0.6870268564749431
Epoch: 70 | Iteration number: [2870/4518] 63% | Training loss: 0.6870255359996902
Epoch: 70 | Iteration number: [2880/4518] 63% | Training loss: 0.6870289562063084
Epoch: 70 | Iteration number: [2890/4518] 63% | Training loss: 0.6870261748563047
Epoch: 70 | Iteration number: [2900/4518] 64% | Training loss: 0.6870290180321398
Epoch: 70 | Iteration number: [2910/4518] 64% | Training loss: 0.6870340780703882
Epoch: 70 | Iteration number: [2920/4518] 64% | Training loss: 0.6870339561406881
Epoch: 70 | Iteration number: [2930/4518] 64% | Training loss: 0.6870334667150478
Epoch: 70 | Iteration number: [2940/4518] 65% | Training loss: 0.6870344252610693
Epoch: 70 | Iteration number: [2950/4518] 65% | Training loss: 0.6870323236715996
Epoch: 70 | Iteration number: [2960/4518] 65% | Training loss: 0.6870326716956254
Epoch: 70 | Iteration number: [2970/4518] 65% | Training loss: 0.6870352604774513
Epoch: 70 | Iteration number: [2980/4518] 65% | Training loss: 0.687031458568253
Epoch: 70 | Iteration number: [2990/4518] 66% | Training loss: 0.6870295349371474
Epoch: 70 | Iteration number: [3000/4518] 66% | Training loss: 0.6870333388447761
Epoch: 70 | Iteration number: [3010/4518] 66% | Training loss: 0.6870318294165538
Epoch: 70 | Iteration number: [3020/4518] 66% | Training loss: 0.6870305087984793
Epoch: 70 | Iteration number: [3030/4518] 67% | Training loss: 0.6870302327395272
Epoch: 70 | Iteration number: [3040/4518] 67% | Training loss: 0.6870270612208467
Epoch: 70 | Iteration number: [3050/4518] 67% | Training loss: 0.6870282759041083
Epoch: 70 | Iteration number: [3060/4518] 67% | Training loss: 0.6870293369480208
Epoch: 70 | Iteration number: [3070/4518] 67% | Training loss: 0.6870285860296181
Epoch: 70 | Iteration number: [3080/4518] 68% | Training loss: 0.6870290924782877
Epoch: 70 | Iteration number: [3090/4518] 68% | Training loss: 0.6870288071123142
Epoch: 70 | Iteration number: [3100/4518] 68% | Training loss: 0.6870265100271471
Epoch: 70 | Iteration number: [3110/4518] 68% | Training loss: 0.6870239038559401
Epoch: 70 | Iteration number: [3120/4518] 69% | Training loss: 0.687025516652144
Epoch: 70 | Iteration number: [3130/4518] 69% | Training loss: 0.6870259967855752
Epoch: 70 | Iteration number: [3140/4518] 69% | Training loss: 0.6870251895325958
Epoch: 70 | Iteration number: [3150/4518] 69% | Training loss: 0.6870197566539522
Epoch: 70 | Iteration number: [3160/4518] 69% | Training loss: 0.6870214597899702
Epoch: 70 | Iteration number: [3170/4518] 70% | Training loss: 0.6870231353710127
Epoch: 70 | Iteration number: [3180/4518] 70% | Training loss: 0.6870186295336898
Epoch: 70 | Iteration number: [3190/4518] 70% | Training loss: 0.6870182183282129
Epoch: 70 | Iteration number: [3200/4518] 70% | Training loss: 0.6870135924033821
Epoch: 70 | Iteration number: [3210/4518] 71% | Training loss: 0.6870095082903949
Epoch: 70 | Iteration number: [3220/4518] 71% | Training loss: 0.6870050601152159
Epoch: 70 | Iteration number: [3230/4518] 71% | Training loss: 0.6870027551894586
Epoch: 70 | Iteration number: [3240/4518] 71% | Training loss: 0.6870026250680288
Epoch: 70 | Iteration number: [3250/4518] 71% | Training loss: 0.6869987434790684
Epoch: 70 | Iteration number: [3260/4518] 72% | Training loss: 0.6869996157343402
Epoch: 70 | Iteration number: [3270/4518] 72% | Training loss: 0.6869997998625496
Epoch: 70 | Iteration number: [3280/4518] 72% | Training loss: 0.6869985723822583
Epoch: 70 | Iteration number: [3290/4518] 72% | Training loss: 0.68699851615813
Epoch: 70 | Iteration number: [3300/4518] 73% | Training loss: 0.6869983597235246
Epoch: 70 | Iteration number: [3310/4518] 73% | Training loss: 0.6869948945736957
Epoch: 70 | Iteration number: [3320/4518] 73% | Training loss: 0.6869951831289085
Epoch: 70 | Iteration number: [3330/4518] 73% | Training loss: 0.6869926969926279
Epoch: 70 | Iteration number: [3340/4518] 73% | Training loss: 0.6869919993206413
Epoch: 70 | Iteration number: [3350/4518] 74% | Training loss: 0.6869940159392001
Epoch: 70 | Iteration number: [3360/4518] 74% | Training loss: 0.6869911876640149
Epoch: 70 | Iteration number: [3370/4518] 74% | Training loss: 0.686989886311466
Epoch: 70 | Iteration number: [3380/4518] 74% | Training loss: 0.6869909188627491
Epoch: 70 | Iteration number: [3390/4518] 75% | Training loss: 0.6869910369580474
Epoch: 70 | Iteration number: [3400/4518] 75% | Training loss: 0.6869931760430336
Epoch: 70 | Iteration number: [3410/4518] 75% | Training loss: 0.6869874243687325
Epoch: 70 | Iteration number: [3420/4518] 75% | Training loss: 0.6869865192133083
Epoch: 70 | Iteration number: [3430/4518] 75% | Training loss: 0.6869893850459997
Epoch: 70 | Iteration number: [3440/4518] 76% | Training loss: 0.686985883896434
Epoch: 70 | Iteration number: [3450/4518] 76% | Training loss: 0.686982537680778
Epoch: 70 | Iteration number: [3460/4518] 76% | Training loss: 0.6869858102130063
Epoch: 70 | Iteration number: [3470/4518] 76% | Training loss: 0.6869840419429867
Epoch: 70 | Iteration number: [3480/4518] 77% | Training loss: 0.6869837857697202
Epoch: 70 | Iteration number: [3490/4518] 77% | Training loss: 0.6869852364404837
Epoch: 70 | Iteration number: [3500/4518] 77% | Training loss: 0.686986564210483
Epoch: 70 | Iteration number: [3510/4518] 77% | Training loss: 0.6869882914415452
Epoch: 70 | Iteration number: [3520/4518] 77% | Training loss: 0.6869902459904551
Epoch: 70 | Iteration number: [3530/4518] 78% | Training loss: 0.686992367587076
Epoch: 70 | Iteration number: [3540/4518] 78% | Training loss: 0.6869943947778583
Epoch: 70 | Iteration number: [3550/4518] 78% | Training loss: 0.6869947364464613
Epoch: 70 | Iteration number: [3560/4518] 78% | Training loss: 0.6869952748330791
Epoch: 70 | Iteration number: [3570/4518] 79% | Training loss: 0.6869970551558904
Epoch: 70 | Iteration number: [3580/4518] 79% | Training loss: 0.6869930080195379
Epoch: 70 | Iteration number: [3590/4518] 79% | Training loss: 0.6869913190188182
Epoch: 70 | Iteration number: [3600/4518] 79% | Training loss: 0.686988970686992
Epoch: 70 | Iteration number: [3610/4518] 79% | Training loss: 0.6869894560519348
Epoch: 70 | Iteration number: [3620/4518] 80% | Training loss: 0.6869922093594272
Epoch: 70 | Iteration number: [3630/4518] 80% | Training loss: 0.6869923455327667
Epoch: 70 | Iteration number: [3640/4518] 80% | Training loss: 0.686987737263297
Epoch: 70 | Iteration number: [3650/4518] 80% | Training loss: 0.6869853806822267
Epoch: 70 | Iteration number: [3660/4518] 81% | Training loss: 0.6869849118215791
Epoch: 70 | Iteration number: [3670/4518] 81% | Training loss: 0.6869811352332217
Epoch: 70 | Iteration number: [3680/4518] 81% | Training loss: 0.6869801037499438
Epoch: 70 | Iteration number: [3690/4518] 81% | Training loss: 0.6869782714501306
Epoch: 70 | Iteration number: [3700/4518] 81% | Training loss: 0.6869758857102007
Epoch: 70 | Iteration number: [3710/4518] 82% | Training loss: 0.6869726859013026
Epoch: 70 | Iteration number: [3720/4518] 82% | Training loss: 0.6869710588327018
Epoch: 70 | Iteration number: [3730/4518] 82% | Training loss: 0.6869727307606
Epoch: 70 | Iteration number: [3740/4518] 82% | Training loss: 0.6869702936653147
Epoch: 70 | Iteration number: [3750/4518] 83% | Training loss: 0.686971003818512
Epoch: 70 | Iteration number: [3760/4518] 83% | Training loss: 0.6869651160817197
Epoch: 70 | Iteration number: [3770/4518] 83% | Training loss: 0.686962124159861
Epoch: 70 | Iteration number: [3780/4518] 83% | Training loss: 0.6869563393018864
Epoch: 70 | Iteration number: [3790/4518] 83% | Training loss: 0.6869562060505859
Epoch: 70 | Iteration number: [3800/4518] 84% | Training loss: 0.6869530874804447
Epoch: 70 | Iteration number: [3810/4518] 84% | Training loss: 0.6869548667447147
Epoch: 70 | Iteration number: [3820/4518] 84% | Training loss: 0.6869583167174724
Epoch: 70 | Iteration number: [3830/4518] 84% | Training loss: 0.6869557097904365
Epoch: 70 | Iteration number: [3840/4518] 84% | Training loss: 0.6869584677896152
Epoch: 70 | Iteration number: [3850/4518] 85% | Training loss: 0.6869592719418662
Epoch: 70 | Iteration number: [3860/4518] 85% | Training loss: 0.686957417976671
Epoch: 70 | Iteration number: [3870/4518] 85% | Training loss: 0.6869567113483291
Epoch: 70 | Iteration number: [3880/4518] 85% | Training loss: 0.6869563687861581
Epoch: 70 | Iteration number: [3890/4518] 86% | Training loss: 0.6869563670268708
Epoch: 70 | Iteration number: [3900/4518] 86% | Training loss: 0.6869570186199286
Epoch: 70 | Iteration number: [3910/4518] 86% | Training loss: 0.686958574928591
Epoch: 70 | Iteration number: [3920/4518] 86% | Training loss: 0.6869556947022069
Epoch: 70 | Iteration number: [3930/4518] 86% | Training loss: 0.6869560717323051
Epoch: 70 | Iteration number: [3940/4518] 87% | Training loss: 0.6869573241563013
Epoch: 70 | Iteration number: [3950/4518] 87% | Training loss: 0.6869524483439289
Epoch: 70 | Iteration number: [3960/4518] 87% | Training loss: 0.6869527758672984
Epoch: 70 | Iteration number: [3970/4518] 87% | Training loss: 0.6869528981089892
Epoch: 70 | Iteration number: [3980/4518] 88% | Training loss: 0.6869494413610678
Epoch: 70 | Iteration number: [3990/4518] 88% | Training loss: 0.6869488912716246
Epoch: 70 | Iteration number: [4000/4518] 88% | Training loss: 0.686947468265891
Epoch: 70 | Iteration number: [4010/4518] 88% | Training loss: 0.6869479623964599
Epoch: 70 | Iteration number: [4020/4518] 88% | Training loss: 0.686949716486148
Epoch: 70 | Iteration number: [4030/4518] 89% | Training loss: 0.6869532605406664
Epoch: 70 | Iteration number: [4040/4518] 89% | Training loss: 0.6869557027179416
Epoch: 70 | Iteration number: [4050/4518] 89% | Training loss: 0.6869543956827234
Epoch: 70 | Iteration number: [4060/4518] 89% | Training loss: 0.6869532410000345
Epoch: 70 | Iteration number: [4070/4518] 90% | Training loss: 0.686955540098195
Epoch: 70 | Iteration number: [4080/4518] 90% | Training loss: 0.6869535723007193
Epoch: 70 | Iteration number: [4090/4518] 90% | Training loss: 0.6869557320925892
Epoch: 70 | Iteration number: [4100/4518] 90% | Training loss: 0.6869573905119082
Epoch: 70 | Iteration number: [4110/4518] 90% | Training loss: 0.6869555921740196
Epoch: 70 | Iteration number: [4120/4518] 91% | Training loss: 0.6869515210679434
Epoch: 70 | Iteration number: [4130/4518] 91% | Training loss: 0.6869511535900845
Epoch: 70 | Iteration number: [4140/4518] 91% | Training loss: 0.686947100461969
Epoch: 70 | Iteration number: [4150/4518] 91% | Training loss: 0.6869450958952846
Epoch: 70 | Iteration number: [4160/4518] 92% | Training loss: 0.6869460891072566
Epoch: 70 | Iteration number: [4170/4518] 92% | Training loss: 0.6869474530077095
Epoch: 70 | Iteration number: [4180/4518] 92% | Training loss: 0.6869463907189346
Epoch: 70 | Iteration number: [4190/4518] 92% | Training loss: 0.6869482006833206
Epoch: 70 | Iteration number: [4200/4518] 92% | Training loss: 0.6869483378103801
Epoch: 70 | Iteration number: [4210/4518] 93% | Training loss: 0.6869474101378062
Epoch: 70 | Iteration number: [4220/4518] 93% | Training loss: 0.6869453066898183
Epoch: 70 | Iteration number: [4230/4518] 93% | Training loss: 0.6869451529449887
Epoch: 70 | Iteration number: [4240/4518] 93% | Training loss: 0.6869451368754764
Epoch: 70 | Iteration number: [4250/4518] 94% | Training loss: 0.6869442041621489
Epoch: 70 | Iteration number: [4260/4518] 94% | Training loss: 0.6869441680505242
Epoch: 70 | Iteration number: [4270/4518] 94% | Training loss: 0.6869433752826003
Epoch: 70 | Iteration number: [4280/4518] 94% | Training loss: 0.6869392297117509
Epoch: 70 | Iteration number: [4290/4518] 94% | Training loss: 0.6869378352498675
Epoch: 70 | Iteration number: [4300/4518] 95% | Training loss: 0.6869381216514943
Epoch: 70 | Iteration number: [4310/4518] 95% | Training loss: 0.6869377679172082
Epoch: 70 | Iteration number: [4320/4518] 95% | Training loss: 0.6869370913202012
Epoch: 70 | Iteration number: [4330/4518] 95% | Training loss: 0.6869352529560997
Epoch: 70 | Iteration number: [4340/4518] 96% | Training loss: 0.6869338643715678
Epoch: 70 | Iteration number: [4350/4518] 96% | Training loss: 0.6869302789096174
Epoch: 70 | Iteration number: [4360/4518] 96% | Training loss: 0.6869273776991651
Epoch: 70 | Iteration number: [4370/4518] 96% | Training loss: 0.6869247879943804
Epoch: 70 | Iteration number: [4380/4518] 96% | Training loss: 0.6869224416202606
Epoch: 70 | Iteration number: [4390/4518] 97% | Training loss: 0.6869218474504345
Epoch: 70 | Iteration number: [4400/4518] 97% | Training loss: 0.6869218901206147
Epoch: 70 | Iteration number: [4410/4518] 97% | Training loss: 0.6869227678732537
Epoch: 70 | Iteration number: [4420/4518] 97% | Training loss: 0.6869225338303665
Epoch: 70 | Iteration number: [4430/4518] 98% | Training loss: 0.6869252529962337
Epoch: 70 | Iteration number: [4440/4518] 98% | Training loss: 0.6869247849862855
Epoch: 70 | Iteration number: [4450/4518] 98% | Training loss: 0.6869286051493012
Epoch: 70 | Iteration number: [4460/4518] 98% | Training loss: 0.6869291852808854
Epoch: 70 | Iteration number: [4470/4518] 98% | Training loss: 0.6869297041588982
Epoch: 70 | Iteration number: [4480/4518] 99% | Training loss: 0.6869287790597549
Epoch: 70 | Iteration number: [4490/4518] 99% | Training loss: 0.6869296654826549
Epoch: 70 | Iteration number: [4500/4518] 99% | Training loss: 0.6869269176324209
Epoch: 70 | Iteration number: [4510/4518] 99% | Training loss: 0.6869268078497403

 End of epoch: 70 | Train Loss: 0.686774075994348 | Training Time: 642 

 End of epoch: 70 | Eval Loss: 0.6898505785027329 | Evaluating Time: 16 
Epoch: 71 | Iteration number: [10/4518] 0% | Training loss: 0.7540157198905945
Epoch: 71 | Iteration number: [20/4518] 0% | Training loss: 0.7205414682626724
Epoch: 71 | Iteration number: [30/4518] 0% | Training loss: 0.7088439404964447
Epoch: 71 | Iteration number: [40/4518] 0% | Training loss: 0.7032724738121032
Epoch: 71 | Iteration number: [50/4518] 1% | Training loss: 0.699986264705658
Epoch: 71 | Iteration number: [60/4518] 1% | Training loss: 0.6977136433124542
Epoch: 71 | Iteration number: [70/4518] 1% | Training loss: 0.6960554199559348
Epoch: 71 | Iteration number: [80/4518] 1% | Training loss: 0.6947078578174114
Epoch: 71 | Iteration number: [90/4518] 1% | Training loss: 0.6938156776958042
Epoch: 71 | Iteration number: [100/4518] 2% | Training loss: 0.6931577229499817
Epoch: 71 | Iteration number: [110/4518] 2% | Training loss: 0.6926205364140597
Epoch: 71 | Iteration number: [120/4518] 2% | Training loss: 0.6921990260481834
Epoch: 71 | Iteration number: [130/4518] 2% | Training loss: 0.6916598264987652
Epoch: 71 | Iteration number: [140/4518] 3% | Training loss: 0.6912416466644832
Epoch: 71 | Iteration number: [150/4518] 3% | Training loss: 0.6910068408648173
Epoch: 71 | Iteration number: [160/4518] 3% | Training loss: 0.6908266134560108
Epoch: 71 | Iteration number: [170/4518] 3% | Training loss: 0.6905835200758541
Epoch: 71 | Iteration number: [180/4518] 3% | Training loss: 0.690323422021336
Epoch: 71 | Iteration number: [190/4518] 4% | Training loss: 0.6900998391603169
Epoch: 71 | Iteration number: [200/4518] 4% | Training loss: 0.689926455616951
Epoch: 71 | Iteration number: [210/4518] 4% | Training loss: 0.6897985188733964
Epoch: 71 | Iteration number: [220/4518] 4% | Training loss: 0.68968266248703
Epoch: 71 | Iteration number: [230/4518] 5% | Training loss: 0.6895461118739584
Epoch: 71 | Iteration number: [240/4518] 5% | Training loss: 0.6894093883534272
Epoch: 71 | Iteration number: [250/4518] 5% | Training loss: 0.6892627167701721
Epoch: 71 | Iteration number: [260/4518] 5% | Training loss: 0.6891616128958189
Epoch: 71 | Iteration number: [270/4518] 5% | Training loss: 0.6890810277726915
Epoch: 71 | Iteration number: [280/4518] 6% | Training loss: 0.6889716674174581
Epoch: 71 | Iteration number: [290/4518] 6% | Training loss: 0.6889049690345238
Epoch: 71 | Iteration number: [300/4518] 6% | Training loss: 0.6888143670558929
Epoch: 71 | Iteration number: [310/4518] 6% | Training loss: 0.6887653839203619
Epoch: 71 | Iteration number: [320/4518] 7% | Training loss: 0.6886932509019971
Epoch: 71 | Iteration number: [330/4518] 7% | Training loss: 0.6885970039801164
Epoch: 71 | Iteration number: [340/4518] 7% | Training loss: 0.6885516094810823
Epoch: 71 | Iteration number: [350/4518] 7% | Training loss: 0.688541406903948
Epoch: 71 | Iteration number: [360/4518] 7% | Training loss: 0.6884985225068199
Epoch: 71 | Iteration number: [370/4518] 8% | Training loss: 0.688463287901234
Epoch: 71 | Iteration number: [380/4518] 8% | Training loss: 0.6884139238219512
Epoch: 71 | Iteration number: [390/4518] 8% | Training loss: 0.6883765796820323
Epoch: 71 | Iteration number: [400/4518] 8% | Training loss: 0.6883400452136993
Epoch: 71 | Iteration number: [410/4518] 9% | Training loss: 0.6882965603979623
Epoch: 71 | Iteration number: [420/4518] 9% | Training loss: 0.6882887542247772
Epoch: 71 | Iteration number: [430/4518] 9% | Training loss: 0.6882337765638218
Epoch: 71 | Iteration number: [440/4518] 9% | Training loss: 0.6881895290179686
Epoch: 71 | Iteration number: [450/4518] 9% | Training loss: 0.6881847971015507
Epoch: 71 | Iteration number: [460/4518] 10% | Training loss: 0.6881545373926992
Epoch: 71 | Iteration number: [470/4518] 10% | Training loss: 0.6881235834131849
Epoch: 71 | Iteration number: [480/4518] 10% | Training loss: 0.6881063760568699
Epoch: 71 | Iteration number: [490/4518] 10% | Training loss: 0.6881137476891888
Epoch: 71 | Iteration number: [500/4518] 11% | Training loss: 0.688082535624504
Epoch: 71 | Iteration number: [510/4518] 11% | Training loss: 0.6880456710562987
Epoch: 71 | Iteration number: [520/4518] 11% | Training loss: 0.6880217395149745
Epoch: 71 | Iteration number: [530/4518] 11% | Training loss: 0.6879874904200716
Epoch: 71 | Iteration number: [540/4518] 11% | Training loss: 0.6879784064160452
Epoch: 71 | Iteration number: [550/4518] 12% | Training loss: 0.6879524266719819
Epoch: 71 | Iteration number: [560/4518] 12% | Training loss: 0.6879513176424162
Epoch: 71 | Iteration number: [570/4518] 12% | Training loss: 0.6879331190335123
Epoch: 71 | Iteration number: [580/4518] 12% | Training loss: 0.687932724274438
Epoch: 71 | Iteration number: [590/4518] 13% | Training loss: 0.6879091406272629
Epoch: 71 | Iteration number: [600/4518] 13% | Training loss: 0.6878986620903015
Epoch: 71 | Iteration number: [610/4518] 13% | Training loss: 0.6878872685745114
Epoch: 71 | Iteration number: [620/4518] 13% | Training loss: 0.6878790086315524
Epoch: 71 | Iteration number: [630/4518] 13% | Training loss: 0.687840196348372
Epoch: 71 | Iteration number: [640/4518] 14% | Training loss: 0.6878426605835557
Epoch: 71 | Iteration number: [650/4518] 14% | Training loss: 0.6878261822003585
Epoch: 71 | Iteration number: [660/4518] 14% | Training loss: 0.687806215340441
Epoch: 71 | Iteration number: [670/4518] 14% | Training loss: 0.6877811537749732
Epoch: 71 | Iteration number: [680/4518] 15% | Training loss: 0.6877587202717276
Epoch: 71 | Iteration number: [690/4518] 15% | Training loss: 0.6877491448236548
Epoch: 71 | Iteration number: [700/4518] 15% | Training loss: 0.6877376896994455
Epoch: 71 | Iteration number: [710/4518] 15% | Training loss: 0.6877158677074271
Epoch: 71 | Iteration number: [720/4518] 15% | Training loss: 0.687680717309316
Epoch: 71 | Iteration number: [730/4518] 16% | Training loss: 0.6876678879130377
Epoch: 71 | Iteration number: [740/4518] 16% | Training loss: 0.687672736032589
Epoch: 71 | Iteration number: [750/4518] 16% | Training loss: 0.687667093594869
Epoch: 71 | Iteration number: [760/4518] 16% | Training loss: 0.6876591266770112
Epoch: 71 | Iteration number: [770/4518] 17% | Training loss: 0.6876464154813197
Epoch: 71 | Iteration number: [780/4518] 17% | Training loss: 0.6876160419904269
Epoch: 71 | Iteration number: [790/4518] 17% | Training loss: 0.6876081058496162
Epoch: 71 | Iteration number: [800/4518] 17% | Training loss: 0.6875914373993873
Epoch: 71 | Iteration number: [810/4518] 17% | Training loss: 0.6875757307917983
Epoch: 71 | Iteration number: [820/4518] 18% | Training loss: 0.6875510401842071
Epoch: 71 | Iteration number: [830/4518] 18% | Training loss: 0.687546869932887
Epoch: 71 | Iteration number: [840/4518] 18% | Training loss: 0.687547845641772
Epoch: 71 | Iteration number: [850/4518] 18% | Training loss: 0.6875521766438204
Epoch: 71 | Iteration number: [860/4518] 19% | Training loss: 0.6875186053819434
Epoch: 71 | Iteration number: [870/4518] 19% | Training loss: 0.6874954275701238
Epoch: 71 | Iteration number: [880/4518] 19% | Training loss: 0.6874960139393806
Epoch: 71 | Iteration number: [890/4518] 19% | Training loss: 0.6874943020638455
Epoch: 71 | Iteration number: [900/4518] 19% | Training loss: 0.6874892803695467
Epoch: 71 | Iteration number: [910/4518] 20% | Training loss: 0.6874772891238495
Epoch: 71 | Iteration number: [920/4518] 20% | Training loss: 0.6874821596819422
Epoch: 71 | Iteration number: [930/4518] 20% | Training loss: 0.6874741573487558
Epoch: 71 | Iteration number: [940/4518] 20% | Training loss: 0.6874571464797283
Epoch: 71 | Iteration number: [950/4518] 21% | Training loss: 0.6874472904205322
Epoch: 71 | Iteration number: [960/4518] 21% | Training loss: 0.6874361963942647
Epoch: 71 | Iteration number: [970/4518] 21% | Training loss: 0.6874253794704516
Epoch: 71 | Iteration number: [980/4518] 21% | Training loss: 0.6874128646996557
Epoch: 71 | Iteration number: [990/4518] 21% | Training loss: 0.6874146518683193
Epoch: 71 | Iteration number: [1000/4518] 22% | Training loss: 0.6874170178174972
Epoch: 71 | Iteration number: [1010/4518] 22% | Training loss: 0.6874051576203639
Epoch: 71 | Iteration number: [1020/4518] 22% | Training loss: 0.6874020907224393
Epoch: 71 | Iteration number: [1030/4518] 22% | Training loss: 0.6873956636896411
Epoch: 71 | Iteration number: [1040/4518] 23% | Training loss: 0.687398183804292
Epoch: 71 | Iteration number: [1050/4518] 23% | Training loss: 0.6873860193434216
Epoch: 71 | Iteration number: [1060/4518] 23% | Training loss: 0.6873894832044277
Epoch: 71 | Iteration number: [1070/4518] 23% | Training loss: 0.6873899654250278
Epoch: 71 | Iteration number: [1080/4518] 23% | Training loss: 0.6873904285607515
Epoch: 71 | Iteration number: [1090/4518] 24% | Training loss: 0.6873780673796978
Epoch: 71 | Iteration number: [1100/4518] 24% | Training loss: 0.6873706495220011
Epoch: 71 | Iteration number: [1110/4518] 24% | Training loss: 0.6873654847746496
Epoch: 71 | Iteration number: [1120/4518] 24% | Training loss: 0.6873693502375058
Epoch: 71 | Iteration number: [1130/4518] 25% | Training loss: 0.6873738638067668
Epoch: 71 | Iteration number: [1140/4518] 25% | Training loss: 0.687359680784376
Epoch: 71 | Iteration number: [1150/4518] 25% | Training loss: 0.6873520556740139
Epoch: 71 | Iteration number: [1160/4518] 25% | Training loss: 0.6873364268705763
Epoch: 71 | Iteration number: [1170/4518] 25% | Training loss: 0.687341868928355
Epoch: 71 | Iteration number: [1180/4518] 26% | Training loss: 0.6873364759703814
Epoch: 71 | Iteration number: [1190/4518] 26% | Training loss: 0.6873377961270949
Epoch: 71 | Iteration number: [1200/4518] 26% | Training loss: 0.6873284136255582
Epoch: 71 | Iteration number: [1210/4518] 26% | Training loss: 0.6873279046421209
Epoch: 71 | Iteration number: [1220/4518] 27% | Training loss: 0.6873188568431823
Epoch: 71 | Iteration number: [1230/4518] 27% | Training loss: 0.6873250836279334
Epoch: 71 | Iteration number: [1240/4518] 27% | Training loss: 0.6873053811250195
Epoch: 71 | Iteration number: [1250/4518] 27% | Training loss: 0.6873067905426026
Epoch: 71 | Iteration number: [1260/4518] 27% | Training loss: 0.6873137511904277
Epoch: 71 | Iteration number: [1270/4518] 28% | Training loss: 0.6873005441323978
Epoch: 71 | Iteration number: [1280/4518] 28% | Training loss: 0.687292555347085
Epoch: 71 | Iteration number: [1290/4518] 28% | Training loss: 0.6872815576634665
Epoch: 71 | Iteration number: [1300/4518] 28% | Training loss: 0.6872817718982697
Epoch: 71 | Iteration number: [1310/4518] 28% | Training loss: 0.6872817727900643
Epoch: 71 | Iteration number: [1320/4518] 29% | Training loss: 0.6872813335873864
Epoch: 71 | Iteration number: [1330/4518] 29% | Training loss: 0.6872766057799633
Epoch: 71 | Iteration number: [1340/4518] 29% | Training loss: 0.6872607514929415
Epoch: 71 | Iteration number: [1350/4518] 29% | Training loss: 0.6872541175065218
Epoch: 71 | Iteration number: [1360/4518] 30% | Training loss: 0.6872345450608169
Epoch: 71 | Iteration number: [1370/4518] 30% | Training loss: 0.6872410989155735
Epoch: 71 | Iteration number: [1380/4518] 30% | Training loss: 0.6872404708810474
Epoch: 71 | Iteration number: [1390/4518] 30% | Training loss: 0.6872401933447062
Epoch: 71 | Iteration number: [1400/4518] 30% | Training loss: 0.6872417770113264
Epoch: 71 | Iteration number: [1410/4518] 31% | Training loss: 0.6872375917350146
Epoch: 71 | Iteration number: [1420/4518] 31% | Training loss: 0.6872380929933467
Epoch: 71 | Iteration number: [1430/4518] 31% | Training loss: 0.6872397608273513
Epoch: 71 | Iteration number: [1440/4518] 31% | Training loss: 0.6872390945752461
Epoch: 71 | Iteration number: [1450/4518] 32% | Training loss: 0.6872345007699111
Epoch: 71 | Iteration number: [1460/4518] 32% | Training loss: 0.6872358643437085
Epoch: 71 | Iteration number: [1470/4518] 32% | Training loss: 0.6872372783771178
Epoch: 71 | Iteration number: [1480/4518] 32% | Training loss: 0.6872267486275854
Epoch: 71 | Iteration number: [1490/4518] 32% | Training loss: 0.6872207107159916
Epoch: 71 | Iteration number: [1500/4518] 33% | Training loss: 0.6872154382864634
Epoch: 71 | Iteration number: [1510/4518] 33% | Training loss: 0.6872171570923155
Epoch: 71 | Iteration number: [1520/4518] 33% | Training loss: 0.6872194557989898
Epoch: 71 | Iteration number: [1530/4518] 33% | Training loss: 0.6872144442757749
Epoch: 71 | Iteration number: [1540/4518] 34% | Training loss: 0.6872113060254555
Epoch: 71 | Iteration number: [1550/4518] 34% | Training loss: 0.6872019591254572
Epoch: 71 | Iteration number: [1560/4518] 34% | Training loss: 0.6871988158195447
Epoch: 71 | Iteration number: [1570/4518] 34% | Training loss: 0.6872022466295085
Epoch: 71 | Iteration number: [1580/4518] 34% | Training loss: 0.687192565693131
Epoch: 71 | Iteration number: [1590/4518] 35% | Training loss: 0.6871932787715264
Epoch: 71 | Iteration number: [1600/4518] 35% | Training loss: 0.6872009052336217
Epoch: 71 | Iteration number: [1610/4518] 35% | Training loss: 0.6872032878932005
Epoch: 71 | Iteration number: [1620/4518] 35% | Training loss: 0.6871959652797676
Epoch: 71 | Iteration number: [1630/4518] 36% | Training loss: 0.6872036482658854
Epoch: 71 | Iteration number: [1640/4518] 36% | Training loss: 0.6872085203121349
Epoch: 71 | Iteration number: [1650/4518] 36% | Training loss: 0.6872072262113744
Epoch: 71 | Iteration number: [1660/4518] 36% | Training loss: 0.6872040563678167
Epoch: 71 | Iteration number: [1670/4518] 36% | Training loss: 0.6872033859084467
Epoch: 71 | Iteration number: [1680/4518] 37% | Training loss: 0.6871942221408799
Epoch: 71 | Iteration number: [1690/4518] 37% | Training loss: 0.6871833424596392
Epoch: 71 | Iteration number: [1700/4518] 37% | Training loss: 0.6871809311123456
Epoch: 71 | Iteration number: [1710/4518] 37% | Training loss: 0.6871873442541089
Epoch: 71 | Iteration number: [1720/4518] 38% | Training loss: 0.6871879680905231
Epoch: 71 | Iteration number: [1730/4518] 38% | Training loss: 0.6871863434769515
Epoch: 71 | Iteration number: [1740/4518] 38% | Training loss: 0.687190312935018
Epoch: 71 | Iteration number: [1750/4518] 38% | Training loss: 0.6871912605421884
Epoch: 71 | Iteration number: [1760/4518] 38% | Training loss: 0.6871913921765306
Epoch: 71 | Iteration number: [1770/4518] 39% | Training loss: 0.6871920733128564
Epoch: 71 | Iteration number: [1780/4518] 39% | Training loss: 0.6871865374988384
Epoch: 71 | Iteration number: [1790/4518] 39% | Training loss: 0.6871845939638894
Epoch: 71 | Iteration number: [1800/4518] 39% | Training loss: 0.6871881332331233
Epoch: 71 | Iteration number: [1810/4518] 40% | Training loss: 0.6871890676943637
Epoch: 71 | Iteration number: [1820/4518] 40% | Training loss: 0.6871935527403276
Epoch: 71 | Iteration number: [1830/4518] 40% | Training loss: 0.6871878774765411
Epoch: 71 | Iteration number: [1840/4518] 40% | Training loss: 0.6871851069447787
Epoch: 71 | Iteration number: [1850/4518] 40% | Training loss: 0.6871757924234545
Epoch: 71 | Iteration number: [1860/4518] 41% | Training loss: 0.6871766151920442
Epoch: 71 | Iteration number: [1870/4518] 41% | Training loss: 0.687175789714497
Epoch: 71 | Iteration number: [1880/4518] 41% | Training loss: 0.6871714749234787
Epoch: 71 | Iteration number: [1890/4518] 41% | Training loss: 0.6871670593029607
Epoch: 71 | Iteration number: [1900/4518] 42% | Training loss: 0.6871604351620925
Epoch: 71 | Iteration number: [1910/4518] 42% | Training loss: 0.6871590677044155
Epoch: 71 | Iteration number: [1920/4518] 42% | Training loss: 0.6871493110743662
Epoch: 71 | Iteration number: [1930/4518] 42% | Training loss: 0.6871511156077212
Epoch: 71 | Iteration number: [1940/4518] 42% | Training loss: 0.6871504982107693
Epoch: 71 | Iteration number: [1950/4518] 43% | Training loss: 0.6871459994560633
Epoch: 71 | Iteration number: [1960/4518] 43% | Training loss: 0.6871445079239047
Epoch: 71 | Iteration number: [1970/4518] 43% | Training loss: 0.6871419319646612
Epoch: 71 | Iteration number: [1980/4518] 43% | Training loss: 0.6871425048269407
Epoch: 71 | Iteration number: [1990/4518] 44% | Training loss: 0.6871399130653496
Epoch: 71 | Iteration number: [2000/4518] 44% | Training loss: 0.6871429287195205
Epoch: 71 | Iteration number: [2010/4518] 44% | Training loss: 0.6871423332252312
Epoch: 71 | Iteration number: [2020/4518] 44% | Training loss: 0.6871458278729183
Epoch: 71 | Iteration number: [2030/4518] 44% | Training loss: 0.6871389358795336
Epoch: 71 | Iteration number: [2040/4518] 45% | Training loss: 0.6871379064870816
Epoch: 71 | Iteration number: [2050/4518] 45% | Training loss: 0.6871430254273299
Epoch: 71 | Iteration number: [2060/4518] 45% | Training loss: 0.6871378194070556
Epoch: 71 | Iteration number: [2070/4518] 45% | Training loss: 0.687132333787743
Epoch: 71 | Iteration number: [2080/4518] 46% | Training loss: 0.6871348512860445
Epoch: 71 | Iteration number: [2090/4518] 46% | Training loss: 0.6871294655868311
Epoch: 71 | Iteration number: [2100/4518] 46% | Training loss: 0.6871265516962324
Epoch: 71 | Iteration number: [2110/4518] 46% | Training loss: 0.6871241948333396
Epoch: 71 | Iteration number: [2120/4518] 46% | Training loss: 0.6871236570038886
Epoch: 71 | Iteration number: [2130/4518] 47% | Training loss: 0.6871212062141705
Epoch: 71 | Iteration number: [2140/4518] 47% | Training loss: 0.6871206597190037
Epoch: 71 | Iteration number: [2150/4518] 47% | Training loss: 0.6871176519504814
Epoch: 71 | Iteration number: [2160/4518] 47% | Training loss: 0.6871166058712536
Epoch: 71 | Iteration number: [2170/4518] 48% | Training loss: 0.6871106615813647
Epoch: 71 | Iteration number: [2180/4518] 48% | Training loss: 0.6871086232705947
Epoch: 71 | Iteration number: [2190/4518] 48% | Training loss: 0.6871069597871337
Epoch: 71 | Iteration number: [2200/4518] 48% | Training loss: 0.6871073955839331
Epoch: 71 | Iteration number: [2210/4518] 48% | Training loss: 0.6871084834655485
Epoch: 71 | Iteration number: [2220/4518] 49% | Training loss: 0.6871036911601419
Epoch: 71 | Iteration number: [2230/4518] 49% | Training loss: 0.6870982780317555
Epoch: 71 | Iteration number: [2240/4518] 49% | Training loss: 0.6870917709544301
Epoch: 71 | Iteration number: [2250/4518] 49% | Training loss: 0.6870958738327027
Epoch: 71 | Iteration number: [2260/4518] 50% | Training loss: 0.687097677271978
Epoch: 71 | Iteration number: [2270/4518] 50% | Training loss: 0.6870960883632106
Epoch: 71 | Iteration number: [2280/4518] 50% | Training loss: 0.6870926396627175
Epoch: 71 | Iteration number: [2290/4518] 50% | Training loss: 0.6870900882383622
Epoch: 71 | Iteration number: [2300/4518] 50% | Training loss: 0.6870898453567339
Epoch: 71 | Iteration number: [2310/4518] 51% | Training loss: 0.6870825018459584
Epoch: 71 | Iteration number: [2320/4518] 51% | Training loss: 0.6870821598531871
Epoch: 71 | Iteration number: [2330/4518] 51% | Training loss: 0.6870848076282141
Epoch: 71 | Iteration number: [2340/4518] 51% | Training loss: 0.6870857215589947
Epoch: 71 | Iteration number: [2350/4518] 52% | Training loss: 0.6870815423448035
Epoch: 71 | Iteration number: [2360/4518] 52% | Training loss: 0.6870781598959939
Epoch: 71 | Iteration number: [2370/4518] 52% | Training loss: 0.6870820824104019
Epoch: 71 | Iteration number: [2380/4518] 52% | Training loss: 0.6870827546390165
Epoch: 71 | Iteration number: [2390/4518] 52% | Training loss: 0.6870835245902568
Epoch: 71 | Iteration number: [2400/4518] 53% | Training loss: 0.6870853618780772
Epoch: 71 | Iteration number: [2410/4518] 53% | Training loss: 0.6870879657535632
Epoch: 71 | Iteration number: [2420/4518] 53% | Training loss: 0.6870901455071347
Epoch: 71 | Iteration number: [2430/4518] 53% | Training loss: 0.6870837560651725
Epoch: 71 | Iteration number: [2440/4518] 54% | Training loss: 0.6870820401633372
Epoch: 71 | Iteration number: [2450/4518] 54% | Training loss: 0.6870769010757913
Epoch: 71 | Iteration number: [2460/4518] 54% | Training loss: 0.6870799052036874
Epoch: 71 | Iteration number: [2470/4518] 54% | Training loss: 0.6870783874139129
Epoch: 71 | Iteration number: [2480/4518] 54% | Training loss: 0.6870746676239275
Epoch: 71 | Iteration number: [2490/4518] 55% | Training loss: 0.6870748448084636
Epoch: 71 | Iteration number: [2500/4518] 55% | Training loss: 0.687075852894783
Epoch: 71 | Iteration number: [2510/4518] 55% | Training loss: 0.6870714052977315
Epoch: 71 | Iteration number: [2520/4518] 55% | Training loss: 0.6870676581348691
Epoch: 71 | Iteration number: [2530/4518] 55% | Training loss: 0.6870653199819708
Epoch: 71 | Iteration number: [2540/4518] 56% | Training loss: 0.687068397346444
Epoch: 71 | Iteration number: [2550/4518] 56% | Training loss: 0.6870692297991584
Epoch: 71 | Iteration number: [2560/4518] 56% | Training loss: 0.6870675651589409
Epoch: 71 | Iteration number: [2570/4518] 56% | Training loss: 0.6870643423920939
Epoch: 71 | Iteration number: [2580/4518] 57% | Training loss: 0.6870635767315709
Epoch: 71 | Iteration number: [2590/4518] 57% | Training loss: 0.687064877739284
Epoch: 71 | Iteration number: [2600/4518] 57% | Training loss: 0.6870640645577357
Epoch: 71 | Iteration number: [2610/4518] 57% | Training loss: 0.6870609268603197
Epoch: 71 | Iteration number: [2620/4518] 57% | Training loss: 0.6870630903098419
Epoch: 71 | Iteration number: [2630/4518] 58% | Training loss: 0.6870629411233242
Epoch: 71 | Iteration number: [2640/4518] 58% | Training loss: 0.6870588153600693
Epoch: 71 | Iteration number: [2650/4518] 58% | Training loss: 0.6870564083783132
Epoch: 71 | Iteration number: [2660/4518] 58% | Training loss: 0.687058514468652
Epoch: 71 | Iteration number: [2670/4518] 59% | Training loss: 0.6870616309428483
Epoch: 71 | Iteration number: [2680/4518] 59% | Training loss: 0.6870624272013778
Epoch: 71 | Iteration number: [2690/4518] 59% | Training loss: 0.6870638110159055
Epoch: 71 | Iteration number: [2700/4518] 59% | Training loss: 0.6870626546718456
Epoch: 71 | Iteration number: [2710/4518] 59% | Training loss: 0.6870651485295314
Epoch: 71 | Iteration number: [2720/4518] 60% | Training loss: 0.6870631677262923
Epoch: 71 | Iteration number: [2730/4518] 60% | Training loss: 0.6870642717068012
Epoch: 71 | Iteration number: [2740/4518] 60% | Training loss: 0.6870657326531237
Epoch: 71 | Iteration number: [2750/4518] 60% | Training loss: 0.6870659378658641
Epoch: 71 | Iteration number: [2760/4518] 61% | Training loss: 0.6870618133441262
Epoch: 71 | Iteration number: [2770/4518] 61% | Training loss: 0.6870590860447728
Epoch: 71 | Iteration number: [2780/4518] 61% | Training loss: 0.6870581606952406
Epoch: 71 | Iteration number: [2790/4518] 61% | Training loss: 0.687057718068468
Epoch: 71 | Iteration number: [2800/4518] 61% | Training loss: 0.6870566109674318
Epoch: 71 | Iteration number: [2810/4518] 62% | Training loss: 0.6870537641633871
Epoch: 71 | Iteration number: [2820/4518] 62% | Training loss: 0.6870554055727965
Epoch: 71 | Iteration number: [2830/4518] 62% | Training loss: 0.6870517621402605
Epoch: 71 | Iteration number: [2840/4518] 62% | Training loss: 0.6870478465313643
Epoch: 71 | Iteration number: [2850/4518] 63% | Training loss: 0.6870453267975858
Epoch: 71 | Iteration number: [2860/4518] 63% | Training loss: 0.6870485954768174
Epoch: 71 | Iteration number: [2870/4518] 63% | Training loss: 0.6870397578963835
Epoch: 71 | Iteration number: [2880/4518] 63% | Training loss: 0.6870323188395964
Epoch: 71 | Iteration number: [2890/4518] 63% | Training loss: 0.6870282556977652
Epoch: 71 | Iteration number: [2900/4518] 64% | Training loss: 0.687030669841273
Epoch: 71 | Iteration number: [2910/4518] 64% | Training loss: 0.6870285420688157
Epoch: 71 | Iteration number: [2920/4518] 64% | Training loss: 0.6870250984822234
Epoch: 71 | Iteration number: [2930/4518] 64% | Training loss: 0.6870226028429364
Epoch: 71 | Iteration number: [2940/4518] 65% | Training loss: 0.6870206283063305
Epoch: 71 | Iteration number: [2950/4518] 65% | Training loss: 0.6870207178794732
Epoch: 71 | Iteration number: [2960/4518] 65% | Training loss: 0.6870158699920048
Epoch: 71 | Iteration number: [2970/4518] 65% | Training loss: 0.6870127930384292
Epoch: 71 | Iteration number: [2980/4518] 65% | Training loss: 0.6870111510457608
Epoch: 71 | Iteration number: [2990/4518] 66% | Training loss: 0.6870073235951937
Epoch: 71 | Iteration number: [3000/4518] 66% | Training loss: 0.6870066695809365
Epoch: 71 | Iteration number: [3010/4518] 66% | Training loss: 0.6870074597902076
Epoch: 71 | Iteration number: [3020/4518] 66% | Training loss: 0.6870069297141587
Epoch: 71 | Iteration number: [3030/4518] 67% | Training loss: 0.6870059713278667
Epoch: 71 | Iteration number: [3040/4518] 67% | Training loss: 0.6869974243993822
Epoch: 71 | Iteration number: [3050/4518] 67% | Training loss: 0.6870025872207078
Epoch: 71 | Iteration number: [3060/4518] 67% | Training loss: 0.6870000772616442
Epoch: 71 | Iteration number: [3070/4518] 67% | Training loss: 0.6869999170885801
Epoch: 71 | Iteration number: [3080/4518] 68% | Training loss: 0.6869958147600099
Epoch: 71 | Iteration number: [3090/4518] 68% | Training loss: 0.6869966673233748
Epoch: 71 | Iteration number: [3100/4518] 68% | Training loss: 0.6870056263093025
Epoch: 71 | Iteration number: [3110/4518] 68% | Training loss: 0.6870059277083713
Epoch: 71 | Iteration number: [3120/4518] 69% | Training loss: 0.6870096787046164
Epoch: 71 | Iteration number: [3130/4518] 69% | Training loss: 0.6870077920226624
Epoch: 71 | Iteration number: [3140/4518] 69% | Training loss: 0.6870077453790956
Epoch: 71 | Iteration number: [3150/4518] 69% | Training loss: 0.6870067145900121
Epoch: 71 | Iteration number: [3160/4518] 69% | Training loss: 0.6870071188747129
Epoch: 71 | Iteration number: [3170/4518] 70% | Training loss: 0.6870088239009448
Epoch: 71 | Iteration number: [3180/4518] 70% | Training loss: 0.687010992079411
Epoch: 71 | Iteration number: [3190/4518] 70% | Training loss: 0.6870095953298586
Epoch: 71 | Iteration number: [3200/4518] 70% | Training loss: 0.6870062685012818
Epoch: 71 | Iteration number: [3210/4518] 71% | Training loss: 0.6870032448263554
Epoch: 71 | Iteration number: [3220/4518] 71% | Training loss: 0.6870016857333805
Epoch: 71 | Iteration number: [3230/4518] 71% | Training loss: 0.6870001060305734
Epoch: 71 | Iteration number: [3240/4518] 71% | Training loss: 0.6869993534353044
Epoch: 71 | Iteration number: [3250/4518] 71% | Training loss: 0.6869980318179497
Epoch: 71 | Iteration number: [3260/4518] 72% | Training loss: 0.6869965441936364
Epoch: 71 | Iteration number: [3270/4518] 72% | Training loss: 0.6869917794651942
Epoch: 71 | Iteration number: [3280/4518] 72% | Training loss: 0.6869913418118546
Epoch: 71 | Iteration number: [3290/4518] 72% | Training loss: 0.6869892296457726
Epoch: 71 | Iteration number: [3300/4518] 73% | Training loss: 0.6869914996443373
Epoch: 71 | Iteration number: [3310/4518] 73% | Training loss: 0.6869908028678952
Epoch: 71 | Iteration number: [3320/4518] 73% | Training loss: 0.6869910326348729
Epoch: 71 | Iteration number: [3330/4518] 73% | Training loss: 0.6869922934172747
Epoch: 71 | Iteration number: [3340/4518] 73% | Training loss: 0.6869873491768351
Epoch: 71 | Iteration number: [3350/4518] 74% | Training loss: 0.686982563093527
Epoch: 71 | Iteration number: [3360/4518] 74% | Training loss: 0.6869853855775935
Epoch: 71 | Iteration number: [3370/4518] 74% | Training loss: 0.6869863869882126
Epoch: 71 | Iteration number: [3380/4518] 74% | Training loss: 0.6869831022778912
Epoch: 71 | Iteration number: [3390/4518] 75% | Training loss: 0.6869814282497474
Epoch: 71 | Iteration number: [3400/4518] 75% | Training loss: 0.6869752914765301
Epoch: 71 | Iteration number: [3410/4518] 75% | Training loss: 0.686973509987778
Epoch: 71 | Iteration number: [3420/4518] 75% | Training loss: 0.6869683946956668
Epoch: 71 | Iteration number: [3430/4518] 75% | Training loss: 0.686964968046711
Epoch: 71 | Iteration number: [3440/4518] 76% | Training loss: 0.6869657977722412
Epoch: 71 | Iteration number: [3450/4518] 76% | Training loss: 0.6869691369671752
Epoch: 71 | Iteration number: [3460/4518] 76% | Training loss: 0.6869694628122914
Epoch: 71 | Iteration number: [3470/4518] 76% | Training loss: 0.6869647829779973
Epoch: 71 | Iteration number: [3480/4518] 77% | Training loss: 0.6869654661622541
Epoch: 71 | Iteration number: [3490/4518] 77% | Training loss: 0.6869668352569755
Epoch: 71 | Iteration number: [3500/4518] 77% | Training loss: 0.6869646628924778
Epoch: 71 | Iteration number: [3510/4518] 77% | Training loss: 0.6869648628085427
Epoch: 71 | Iteration number: [3520/4518] 77% | Training loss: 0.6869649963792075
Epoch: 71 | Iteration number: [3530/4518] 78% | Training loss: 0.6869622977867342
Epoch: 71 | Iteration number: [3540/4518] 78% | Training loss: 0.6869617589786228
Epoch: 71 | Iteration number: [3550/4518] 78% | Training loss: 0.6869614136554826
Epoch: 71 | Iteration number: [3560/4518] 78% | Training loss: 0.6869632293334168
Epoch: 71 | Iteration number: [3570/4518] 79% | Training loss: 0.6869624530400883
Epoch: 71 | Iteration number: [3580/4518] 79% | Training loss: 0.6869609213741132
Epoch: 71 | Iteration number: [3590/4518] 79% | Training loss: 0.6869559033999536
Epoch: 71 | Iteration number: [3600/4518] 79% | Training loss: 0.6869514678087499
Epoch: 71 | Iteration number: [3610/4518] 79% | Training loss: 0.6869480811327778
Epoch: 71 | Iteration number: [3620/4518] 80% | Training loss: 0.6869429807471965
Epoch: 71 | Iteration number: [3630/4518] 80% | Training loss: 0.6869417829454437
Epoch: 71 | Iteration number: [3640/4518] 80% | Training loss: 0.6869432671220748
Epoch: 71 | Iteration number: [3650/4518] 80% | Training loss: 0.6869416327999063
Epoch: 71 | Iteration number: [3660/4518] 81% | Training loss: 0.6869440685693032
Epoch: 71 | Iteration number: [3670/4518] 81% | Training loss: 0.6869385741387141
Epoch: 71 | Iteration number: [3680/4518] 81% | Training loss: 0.6869347414082807
Epoch: 71 | Iteration number: [3690/4518] 81% | Training loss: 0.686934270962144
Epoch: 71 | Iteration number: [3700/4518] 81% | Training loss: 0.686931326308766
Epoch: 71 | Iteration number: [3710/4518] 82% | Training loss: 0.6869305373362775
Epoch: 71 | Iteration number: [3720/4518] 82% | Training loss: 0.6869309996885639
Epoch: 71 | Iteration number: [3730/4518] 82% | Training loss: 0.6869299366550855
Epoch: 71 | Iteration number: [3740/4518] 82% | Training loss: 0.6869327896259685
Epoch: 71 | Iteration number: [3750/4518] 83% | Training loss: 0.6869350175380706
Epoch: 71 | Iteration number: [3760/4518] 83% | Training loss: 0.6869333001051812
Epoch: 71 | Iteration number: [3770/4518] 83% | Training loss: 0.6869284937014947
Epoch: 71 | Iteration number: [3780/4518] 83% | Training loss: 0.686927636212142
Epoch: 71 | Iteration number: [3790/4518] 83% | Training loss: 0.6869280009282296
Epoch: 71 | Iteration number: [3800/4518] 84% | Training loss: 0.6869304603181388
Epoch: 71 | Iteration number: [3810/4518] 84% | Training loss: 0.6869287019013732
Epoch: 71 | Iteration number: [3820/4518] 84% | Training loss: 0.686929522899433
Epoch: 71 | Iteration number: [3830/4518] 84% | Training loss: 0.6869284140845814
Epoch: 71 | Iteration number: [3840/4518] 84% | Training loss: 0.6869273817011465
Epoch: 71 | Iteration number: [3850/4518] 85% | Training loss: 0.6869225202133129
Epoch: 71 | Iteration number: [3860/4518] 85% | Training loss: 0.6869235774550413
Epoch: 71 | Iteration number: [3870/4518] 85% | Training loss: 0.6869242229664972
Epoch: 71 | Iteration number: [3880/4518] 85% | Training loss: 0.6869237748310738
Epoch: 71 | Iteration number: [3890/4518] 86% | Training loss: 0.6869238237029176
Epoch: 71 | Iteration number: [3900/4518] 86% | Training loss: 0.6869269193899937
Epoch: 71 | Iteration number: [3910/4518] 86% | Training loss: 0.6869262465887972
Epoch: 71 | Iteration number: [3920/4518] 86% | Training loss: 0.6869260599114457
Epoch: 71 | Iteration number: [3930/4518] 86% | Training loss: 0.6869294040379027
Epoch: 71 | Iteration number: [3940/4518] 87% | Training loss: 0.686930436485915
Epoch: 71 | Iteration number: [3950/4518] 87% | Training loss: 0.6869305066066452
Epoch: 71 | Iteration number: [3960/4518] 87% | Training loss: 0.6869328212105866
Epoch: 71 | Iteration number: [3970/4518] 87% | Training loss: 0.686929452359226
Epoch: 71 | Iteration number: [3980/4518] 88% | Training loss: 0.6869290754423668
Epoch: 71 | Iteration number: [3990/4518] 88% | Training loss: 0.6869300885308057
Epoch: 71 | Iteration number: [4000/4518] 88% | Training loss: 0.6869308874160052
Epoch: 71 | Iteration number: [4010/4518] 88% | Training loss: 0.6869312404248482
Epoch: 71 | Iteration number: [4020/4518] 88% | Training loss: 0.6869308271366565
Epoch: 71 | Iteration number: [4030/4518] 89% | Training loss: 0.6869315202715379
Epoch: 71 | Iteration number: [4040/4518] 89% | Training loss: 0.6869331872994356
Epoch: 71 | Iteration number: [4050/4518] 89% | Training loss: 0.6869327645831638
Epoch: 71 | Iteration number: [4060/4518] 89% | Training loss: 0.6869323737221985
Epoch: 71 | Iteration number: [4070/4518] 90% | Training loss: 0.6869331306116587
Epoch: 71 | Iteration number: [4080/4518] 90% | Training loss: 0.6869317857365982
Epoch: 71 | Iteration number: [4090/4518] 90% | Training loss: 0.6869288134837209
Epoch: 71 | Iteration number: [4100/4518] 90% | Training loss: 0.6869297278072776
Epoch: 71 | Iteration number: [4110/4518] 90% | Training loss: 0.6869298059429856
Epoch: 71 | Iteration number: [4120/4518] 91% | Training loss: 0.6869312753810466
Epoch: 71 | Iteration number: [4130/4518] 91% | Training loss: 0.6869326912894953
Epoch: 71 | Iteration number: [4140/4518] 91% | Training loss: 0.686929231191027
Epoch: 71 | Iteration number: [4150/4518] 91% | Training loss: 0.6869292120761182
Epoch: 71 | Iteration number: [4160/4518] 92% | Training loss: 0.6869284537549202
Epoch: 71 | Iteration number: [4170/4518] 92% | Training loss: 0.6869257371202647
Epoch: 71 | Iteration number: [4180/4518] 92% | Training loss: 0.6869267127017655
Epoch: 71 | Iteration number: [4190/4518] 92% | Training loss: 0.6869219165144217
Epoch: 71 | Iteration number: [4200/4518] 92% | Training loss: 0.6869224762490818
Epoch: 71 | Iteration number: [4210/4518] 93% | Training loss: 0.6869241374971747
Epoch: 71 | Iteration number: [4220/4518] 93% | Training loss: 0.6869236749495375
Epoch: 71 | Iteration number: [4230/4518] 93% | Training loss: 0.686923476595687
Epoch: 71 | Iteration number: [4240/4518] 93% | Training loss: 0.6869227850915126
Epoch: 71 | Iteration number: [4250/4518] 94% | Training loss: 0.6869176762104034
Epoch: 71 | Iteration number: [4260/4518] 94% | Training loss: 0.6869222788183902
Epoch: 71 | Iteration number: [4270/4518] 94% | Training loss: 0.6869234112302928
Epoch: 71 | Iteration number: [4280/4518] 94% | Training loss: 0.6869211894050937
Epoch: 71 | Iteration number: [4290/4518] 94% | Training loss: 0.6869231907220987
Epoch: 71 | Iteration number: [4300/4518] 95% | Training loss: 0.6869223637081856
Epoch: 71 | Iteration number: [4310/4518] 95% | Training loss: 0.686921195931335
Epoch: 71 | Iteration number: [4320/4518] 95% | Training loss: 0.686920225551283
Epoch: 71 | Iteration number: [4330/4518] 95% | Training loss: 0.6869204894362091
Epoch: 71 | Iteration number: [4340/4518] 96% | Training loss: 0.6869214586261231
Epoch: 71 | Iteration number: [4350/4518] 96% | Training loss: 0.6869185321495451
Epoch: 71 | Iteration number: [4360/4518] 96% | Training loss: 0.6869184401467305
Epoch: 71 | Iteration number: [4370/4518] 96% | Training loss: 0.6869189547728619
Epoch: 71 | Iteration number: [4380/4518] 96% | Training loss: 0.6869221879603111
Epoch: 71 | Iteration number: [4390/4518] 97% | Training loss: 0.6869213040434418
Epoch: 71 | Iteration number: [4400/4518] 97% | Training loss: 0.6869208265705542
Epoch: 71 | Iteration number: [4410/4518] 97% | Training loss: 0.6869226608011457
Epoch: 71 | Iteration number: [4420/4518] 97% | Training loss: 0.6869227855993072
Epoch: 71 | Iteration number: [4430/4518] 98% | Training loss: 0.6869222546942347
Epoch: 71 | Iteration number: [4440/4518] 98% | Training loss: 0.6869258229259972
Epoch: 71 | Iteration number: [4450/4518] 98% | Training loss: 0.6869247111175837
Epoch: 71 | Iteration number: [4460/4518] 98% | Training loss: 0.6869238338529262
Epoch: 71 | Iteration number: [4470/4518] 98% | Training loss: 0.6869257893204955
Epoch: 71 | Iteration number: [4480/4518] 99% | Training loss: 0.6869254672101566
Epoch: 71 | Iteration number: [4490/4518] 99% | Training loss: 0.6869247980133728
Epoch: 71 | Iteration number: [4500/4518] 99% | Training loss: 0.6869257073005041
Epoch: 71 | Iteration number: [4510/4518] 99% | Training loss: 0.6869248023715093

 End of epoch: 71 | Train Loss: 0.6867740330916688 | Training Time: 642 

 End of epoch: 71 | Eval Loss: 0.6898382026322034 | Evaluating Time: 17 
Epoch: 72 | Iteration number: [10/4518] 0% | Training loss: 0.75621577501297
Epoch: 72 | Iteration number: [20/4518] 0% | Training loss: 0.7217768222093582
Epoch: 72 | Iteration number: [30/4518] 0% | Training loss: 0.7098651429017385
Epoch: 72 | Iteration number: [40/4518] 0% | Training loss: 0.7042045727372169
Epoch: 72 | Iteration number: [50/4518] 1% | Training loss: 0.7009147524833679
Epoch: 72 | Iteration number: [60/4518] 1% | Training loss: 0.6984842876593272
Epoch: 72 | Iteration number: [70/4518] 1% | Training loss: 0.6969260249819075
Epoch: 72 | Iteration number: [80/4518] 1% | Training loss: 0.69571348503232
Epoch: 72 | Iteration number: [90/4518] 1% | Training loss: 0.6947064399719238
Epoch: 72 | Iteration number: [100/4518] 2% | Training loss: 0.6937827783823013
Epoch: 72 | Iteration number: [110/4518] 2% | Training loss: 0.6931442499160767
Epoch: 72 | Iteration number: [120/4518] 2% | Training loss: 0.692809414366881
Epoch: 72 | Iteration number: [130/4518] 2% | Training loss: 0.6923443349508139
Epoch: 72 | Iteration number: [140/4518] 3% | Training loss: 0.691919156057494
Epoch: 72 | Iteration number: [150/4518] 3% | Training loss: 0.6915102668603261
Epoch: 72 | Iteration number: [160/4518] 3% | Training loss: 0.6912466488778591
Epoch: 72 | Iteration number: [170/4518] 3% | Training loss: 0.6909945733406965
Epoch: 72 | Iteration number: [180/4518] 3% | Training loss: 0.6907266073756748
Epoch: 72 | Iteration number: [190/4518] 4% | Training loss: 0.6905226779611487
Epoch: 72 | Iteration number: [200/4518] 4% | Training loss: 0.6903625071048737
Epoch: 72 | Iteration number: [210/4518] 4% | Training loss: 0.6901448769228798
Epoch: 72 | Iteration number: [220/4518] 4% | Training loss: 0.6900153357874264
Epoch: 72 | Iteration number: [230/4518] 5% | Training loss: 0.6898515154486117
Epoch: 72 | Iteration number: [240/4518] 5% | Training loss: 0.6897375762462616
Epoch: 72 | Iteration number: [250/4518] 5% | Training loss: 0.6896263997554779
Epoch: 72 | Iteration number: [260/4518] 5% | Training loss: 0.6894878674011964
Epoch: 72 | Iteration number: [270/4518] 5% | Training loss: 0.6894242467703643
Epoch: 72 | Iteration number: [280/4518] 6% | Training loss: 0.6893279529043607
Epoch: 72 | Iteration number: [290/4518] 6% | Training loss: 0.6892181902096189
Epoch: 72 | Iteration number: [300/4518] 6% | Training loss: 0.6891177856922149
Epoch: 72 | Iteration number: [310/4518] 6% | Training loss: 0.6890210007467578
Epoch: 72 | Iteration number: [320/4518] 7% | Training loss: 0.6889367062598467
Epoch: 72 | Iteration number: [330/4518] 7% | Training loss: 0.6888621973268914
Epoch: 72 | Iteration number: [340/4518] 7% | Training loss: 0.688797986332108
Epoch: 72 | Iteration number: [350/4518] 7% | Training loss: 0.6887410967690604
Epoch: 72 | Iteration number: [360/4518] 7% | Training loss: 0.6887190110153623
Epoch: 72 | Iteration number: [370/4518] 8% | Training loss: 0.688648149451694
Epoch: 72 | Iteration number: [380/4518] 8% | Training loss: 0.6886113378562425
Epoch: 72 | Iteration number: [390/4518] 8% | Training loss: 0.6885942101478577
Epoch: 72 | Iteration number: [400/4518] 8% | Training loss: 0.6885576587915421
Epoch: 72 | Iteration number: [410/4518] 9% | Training loss: 0.6885309405443145
Epoch: 72 | Iteration number: [420/4518] 9% | Training loss: 0.6884881639764422
Epoch: 72 | Iteration number: [430/4518] 9% | Training loss: 0.6884825599748035
Epoch: 72 | Iteration number: [440/4518] 9% | Training loss: 0.6884374233809385
Epoch: 72 | Iteration number: [450/4518] 9% | Training loss: 0.6884172842237685
Epoch: 72 | Iteration number: [460/4518] 10% | Training loss: 0.6883687632239384
Epoch: 72 | Iteration number: [470/4518] 10% | Training loss: 0.6883458060152987
Epoch: 72 | Iteration number: [480/4518] 10% | Training loss: 0.688266559317708
Epoch: 72 | Iteration number: [490/4518] 10% | Training loss: 0.6882340403235688
Epoch: 72 | Iteration number: [500/4518] 11% | Training loss: 0.6881930775642395
Epoch: 72 | Iteration number: [510/4518] 11% | Training loss: 0.6881470786590203
Epoch: 72 | Iteration number: [520/4518] 11% | Training loss: 0.6881422958694972
Epoch: 72 | Iteration number: [530/4518] 11% | Training loss: 0.6881315547340321
Epoch: 72 | Iteration number: [540/4518] 11% | Training loss: 0.6880993603556245
Epoch: 72 | Iteration number: [550/4518] 12% | Training loss: 0.6880703468756242
Epoch: 72 | Iteration number: [560/4518] 12% | Training loss: 0.6880495126758303
Epoch: 72 | Iteration number: [570/4518] 12% | Training loss: 0.6880194675504115
Epoch: 72 | Iteration number: [580/4518] 12% | Training loss: 0.6880032823003571
Epoch: 72 | Iteration number: [590/4518] 13% | Training loss: 0.6879622756424597
Epoch: 72 | Iteration number: [600/4518] 13% | Training loss: 0.6879459225138028
Epoch: 72 | Iteration number: [610/4518] 13% | Training loss: 0.6879401251917979
Epoch: 72 | Iteration number: [620/4518] 13% | Training loss: 0.6879214407936219
Epoch: 72 | Iteration number: [630/4518] 13% | Training loss: 0.6878959365307339
Epoch: 72 | Iteration number: [640/4518] 14% | Training loss: 0.6878652110695839
Epoch: 72 | Iteration number: [650/4518] 14% | Training loss: 0.6878502104832576
Epoch: 72 | Iteration number: [660/4518] 14% | Training loss: 0.6878356750264313
Epoch: 72 | Iteration number: [670/4518] 14% | Training loss: 0.6878412673722453
Epoch: 72 | Iteration number: [680/4518] 15% | Training loss: 0.6878231094164007
Epoch: 72 | Iteration number: [690/4518] 15% | Training loss: 0.6878019006355949
Epoch: 72 | Iteration number: [700/4518] 15% | Training loss: 0.6877825203963689
Epoch: 72 | Iteration number: [710/4518] 15% | Training loss: 0.6877443413499376
Epoch: 72 | Iteration number: [720/4518] 15% | Training loss: 0.6877353685597579
Epoch: 72 | Iteration number: [730/4518] 16% | Training loss: 0.6877293286258227
Epoch: 72 | Iteration number: [740/4518] 16% | Training loss: 0.6876976764685399
Epoch: 72 | Iteration number: [750/4518] 16% | Training loss: 0.6876766570409139
Epoch: 72 | Iteration number: [760/4518] 16% | Training loss: 0.6876614144758174
Epoch: 72 | Iteration number: [770/4518] 17% | Training loss: 0.6876509209731957
Epoch: 72 | Iteration number: [780/4518] 17% | Training loss: 0.6876199550353563
Epoch: 72 | Iteration number: [790/4518] 17% | Training loss: 0.6876143601876271
Epoch: 72 | Iteration number: [800/4518] 17% | Training loss: 0.6875986430048943
Epoch: 72 | Iteration number: [810/4518] 17% | Training loss: 0.6875893586947595
Epoch: 72 | Iteration number: [820/4518] 18% | Training loss: 0.6875787947962924
Epoch: 72 | Iteration number: [830/4518] 18% | Training loss: 0.6875641140593104
Epoch: 72 | Iteration number: [840/4518] 18% | Training loss: 0.6875749333273797
Epoch: 72 | Iteration number: [850/4518] 18% | Training loss: 0.6875677579290727
Epoch: 72 | Iteration number: [860/4518] 19% | Training loss: 0.687557170626729
Epoch: 72 | Iteration number: [870/4518] 19% | Training loss: 0.6875401015254273
Epoch: 72 | Iteration number: [880/4518] 19% | Training loss: 0.6875216939909892
Epoch: 72 | Iteration number: [890/4518] 19% | Training loss: 0.6875282223974721
Epoch: 72 | Iteration number: [900/4518] 19% | Training loss: 0.6875114213095771
Epoch: 72 | Iteration number: [910/4518] 20% | Training loss: 0.6874910445658715
Epoch: 72 | Iteration number: [920/4518] 20% | Training loss: 0.6874589957620787
Epoch: 72 | Iteration number: [930/4518] 20% | Training loss: 0.6874515030973701
Epoch: 72 | Iteration number: [940/4518] 20% | Training loss: 0.6874486654996872
Epoch: 72 | Iteration number: [950/4518] 21% | Training loss: 0.6874377626494358
Epoch: 72 | Iteration number: [960/4518] 21% | Training loss: 0.687430804160734
Epoch: 72 | Iteration number: [970/4518] 21% | Training loss: 0.6874332012589445
Epoch: 72 | Iteration number: [980/4518] 21% | Training loss: 0.6874138013440736
Epoch: 72 | Iteration number: [990/4518] 21% | Training loss: 0.687402334357753
Epoch: 72 | Iteration number: [1000/4518] 22% | Training loss: 0.6873991240262985
Epoch: 72 | Iteration number: [1010/4518] 22% | Training loss: 0.6873852163258165
Epoch: 72 | Iteration number: [1020/4518] 22% | Training loss: 0.6873769015073776
Epoch: 72 | Iteration number: [1030/4518] 22% | Training loss: 0.687377875869714
Epoch: 72 | Iteration number: [1040/4518] 23% | Training loss: 0.6873765091483409
Epoch: 72 | Iteration number: [1050/4518] 23% | Training loss: 0.6873732280163538
Epoch: 72 | Iteration number: [1060/4518] 23% | Training loss: 0.6873684099260366
Epoch: 72 | Iteration number: [1070/4518] 23% | Training loss: 0.6873573965558382
Epoch: 72 | Iteration number: [1080/4518] 23% | Training loss: 0.6873578932550218
Epoch: 72 | Iteration number: [1090/4518] 24% | Training loss: 0.6873572396575858
Epoch: 72 | Iteration number: [1100/4518] 24% | Training loss: 0.6873516368865967
Epoch: 72 | Iteration number: [1110/4518] 24% | Training loss: 0.6873575500539831
Epoch: 72 | Iteration number: [1120/4518] 24% | Training loss: 0.6873573048838547
Epoch: 72 | Iteration number: [1130/4518] 25% | Training loss: 0.6873522310130364
Epoch: 72 | Iteration number: [1140/4518] 25% | Training loss: 0.6873471070799911
Epoch: 72 | Iteration number: [1150/4518] 25% | Training loss: 0.6873474347591401
Epoch: 72 | Iteration number: [1160/4518] 25% | Training loss: 0.6873457308473259
Epoch: 72 | Iteration number: [1170/4518] 25% | Training loss: 0.6873410530069954
Epoch: 72 | Iteration number: [1180/4518] 26% | Training loss: 0.6873322346958063
Epoch: 72 | Iteration number: [1190/4518] 26% | Training loss: 0.6873255618980952
Epoch: 72 | Iteration number: [1200/4518] 26% | Training loss: 0.68732379073898
Epoch: 72 | Iteration number: [1210/4518] 26% | Training loss: 0.6873173483147109
Epoch: 72 | Iteration number: [1220/4518] 27% | Training loss: 0.687314694973289
Epoch: 72 | Iteration number: [1230/4518] 27% | Training loss: 0.6872868957073708
Epoch: 72 | Iteration number: [1240/4518] 27% | Training loss: 0.6872912322801928
Epoch: 72 | Iteration number: [1250/4518] 27% | Training loss: 0.6872867237091065
Epoch: 72 | Iteration number: [1260/4518] 27% | Training loss: 0.6872880598382344
Epoch: 72 | Iteration number: [1270/4518] 28% | Training loss: 0.6872873885894385
Epoch: 72 | Iteration number: [1280/4518] 28% | Training loss: 0.6872823334764689
Epoch: 72 | Iteration number: [1290/4518] 28% | Training loss: 0.68726668473362
Epoch: 72 | Iteration number: [1300/4518] 28% | Training loss: 0.6872670113581878
Epoch: 72 | Iteration number: [1310/4518] 28% | Training loss: 0.6872627171396299
Epoch: 72 | Iteration number: [1320/4518] 29% | Training loss: 0.6872598619623618
Epoch: 72 | Iteration number: [1330/4518] 29% | Training loss: 0.687253340070409
Epoch: 72 | Iteration number: [1340/4518] 29% | Training loss: 0.6872466898676175
Epoch: 72 | Iteration number: [1350/4518] 29% | Training loss: 0.6872379183769226
Epoch: 72 | Iteration number: [1360/4518] 30% | Training loss: 0.6872321965063319
Epoch: 72 | Iteration number: [1370/4518] 30% | Training loss: 0.6872301703386934
Epoch: 72 | Iteration number: [1380/4518] 30% | Training loss: 0.6872227028228235
Epoch: 72 | Iteration number: [1390/4518] 30% | Training loss: 0.6872155830585699
Epoch: 72 | Iteration number: [1400/4518] 30% | Training loss: 0.6872103668536459
Epoch: 72 | Iteration number: [1410/4518] 31% | Training loss: 0.6872119812677938
Epoch: 72 | Iteration number: [1420/4518] 31% | Training loss: 0.6872100812028831
Epoch: 72 | Iteration number: [1430/4518] 31% | Training loss: 0.6872141064046979
Epoch: 72 | Iteration number: [1440/4518] 31% | Training loss: 0.687202281008164
Epoch: 72 | Iteration number: [1450/4518] 32% | Training loss: 0.6871977808968774
Epoch: 72 | Iteration number: [1460/4518] 32% | Training loss: 0.6871780681691758
Epoch: 72 | Iteration number: [1470/4518] 32% | Training loss: 0.6871846988493082
Epoch: 72 | Iteration number: [1480/4518] 32% | Training loss: 0.687191554299883
Epoch: 72 | Iteration number: [1490/4518] 32% | Training loss: 0.6871891120136184
Epoch: 72 | Iteration number: [1500/4518] 33% | Training loss: 0.6871739349365235
Epoch: 72 | Iteration number: [1510/4518] 33% | Training loss: 0.6871712390950184
Epoch: 72 | Iteration number: [1520/4518] 33% | Training loss: 0.6871720864192435
Epoch: 72 | Iteration number: [1530/4518] 33% | Training loss: 0.6871713304052166
Epoch: 72 | Iteration number: [1540/4518] 34% | Training loss: 0.6871731686514694
Epoch: 72 | Iteration number: [1550/4518] 34% | Training loss: 0.6871676038157556
Epoch: 72 | Iteration number: [1560/4518] 34% | Training loss: 0.6871643323546801
Epoch: 72 | Iteration number: [1570/4518] 34% | Training loss: 0.6871664520281895
Epoch: 72 | Iteration number: [1580/4518] 34% | Training loss: 0.6871620952705794
Epoch: 72 | Iteration number: [1590/4518] 35% | Training loss: 0.6871582840223732
Epoch: 72 | Iteration number: [1600/4518] 35% | Training loss: 0.6871579163521528
Epoch: 72 | Iteration number: [1610/4518] 35% | Training loss: 0.6871543537755931
Epoch: 72 | Iteration number: [1620/4518] 35% | Training loss: 0.6871569363791266
Epoch: 72 | Iteration number: [1630/4518] 36% | Training loss: 0.68715255147109
Epoch: 72 | Iteration number: [1640/4518] 36% | Training loss: 0.6871588763667316
Epoch: 72 | Iteration number: [1650/4518] 36% | Training loss: 0.6871557593706883
Epoch: 72 | Iteration number: [1660/4518] 36% | Training loss: 0.6871440741312073
Epoch: 72 | Iteration number: [1670/4518] 36% | Training loss: 0.6871387953529815
Epoch: 72 | Iteration number: [1680/4518] 37% | Training loss: 0.6871346399188042
Epoch: 72 | Iteration number: [1690/4518] 37% | Training loss: 0.6871364365667987
Epoch: 72 | Iteration number: [1700/4518] 37% | Training loss: 0.6871284180178362
Epoch: 72 | Iteration number: [1710/4518] 37% | Training loss: 0.6871107654613361
Epoch: 72 | Iteration number: [1720/4518] 38% | Training loss: 0.687106233142143
Epoch: 72 | Iteration number: [1730/4518] 38% | Training loss: 0.6871113084299716
Epoch: 72 | Iteration number: [1740/4518] 38% | Training loss: 0.6871117410646088
Epoch: 72 | Iteration number: [1750/4518] 38% | Training loss: 0.6871091092995235
Epoch: 72 | Iteration number: [1760/4518] 38% | Training loss: 0.6871058827096765
Epoch: 72 | Iteration number: [1770/4518] 39% | Training loss: 0.6871055122149192
Epoch: 72 | Iteration number: [1780/4518] 39% | Training loss: 0.6871060169814678
Epoch: 72 | Iteration number: [1790/4518] 39% | Training loss: 0.68710419608894
Epoch: 72 | Iteration number: [1800/4518] 39% | Training loss: 0.6871042017804252
Epoch: 72 | Iteration number: [1810/4518] 40% | Training loss: 0.6871008678035841
Epoch: 72 | Iteration number: [1820/4518] 40% | Training loss: 0.6871007503389002
Epoch: 72 | Iteration number: [1830/4518] 40% | Training loss: 0.6871030138815687
Epoch: 72 | Iteration number: [1840/4518] 40% | Training loss: 0.6870960350269857
Epoch: 72 | Iteration number: [1850/4518] 40% | Training loss: 0.6870890069330061
Epoch: 72 | Iteration number: [1860/4518] 41% | Training loss: 0.687092962412424
Epoch: 72 | Iteration number: [1870/4518] 41% | Training loss: 0.6870915475694891
Epoch: 72 | Iteration number: [1880/4518] 41% | Training loss: 0.6870879302633569
Epoch: 72 | Iteration number: [1890/4518] 41% | Training loss: 0.6870904413165239
Epoch: 72 | Iteration number: [1900/4518] 42% | Training loss: 0.687083400205562
Epoch: 72 | Iteration number: [1910/4518] 42% | Training loss: 0.687078508375827
Epoch: 72 | Iteration number: [1920/4518] 42% | Training loss: 0.6870802393183112
Epoch: 72 | Iteration number: [1930/4518] 42% | Training loss: 0.6870789005039887
Epoch: 72 | Iteration number: [1940/4518] 42% | Training loss: 0.6870733129916732
Epoch: 72 | Iteration number: [1950/4518] 43% | Training loss: 0.6870669936828124
Epoch: 72 | Iteration number: [1960/4518] 43% | Training loss: 0.6870617227590814
Epoch: 72 | Iteration number: [1970/4518] 43% | Training loss: 0.6870575030745588
Epoch: 72 | Iteration number: [1980/4518] 43% | Training loss: 0.6870580928193198
Epoch: 72 | Iteration number: [1990/4518] 44% | Training loss: 0.6870501664116155
Epoch: 72 | Iteration number: [2000/4518] 44% | Training loss: 0.6870514510273933
Epoch: 72 | Iteration number: [2010/4518] 44% | Training loss: 0.6870546243380551
Epoch: 72 | Iteration number: [2020/4518] 44% | Training loss: 0.6870575375486129
Epoch: 72 | Iteration number: [2030/4518] 44% | Training loss: 0.687052135602594
Epoch: 72 | Iteration number: [2040/4518] 45% | Training loss: 0.6870592110005079
Epoch: 72 | Iteration number: [2050/4518] 45% | Training loss: 0.6870556378364563
Epoch: 72 | Iteration number: [2060/4518] 45% | Training loss: 0.6870555148541349
Epoch: 72 | Iteration number: [2070/4518] 45% | Training loss: 0.6870533178106022
Epoch: 72 | Iteration number: [2080/4518] 46% | Training loss: 0.6870585344731808
Epoch: 72 | Iteration number: [2090/4518] 46% | Training loss: 0.687057834635511
Epoch: 72 | Iteration number: [2100/4518] 46% | Training loss: 0.68706448333604
Epoch: 72 | Iteration number: [2110/4518] 46% | Training loss: 0.6870588935946966
Epoch: 72 | Iteration number: [2120/4518] 46% | Training loss: 0.6870556342995392
Epoch: 72 | Iteration number: [2130/4518] 47% | Training loss: 0.6870583704379802
Epoch: 72 | Iteration number: [2140/4518] 47% | Training loss: 0.6870554246078028
Epoch: 72 | Iteration number: [2150/4518] 47% | Training loss: 0.6870539399357729
Epoch: 72 | Iteration number: [2160/4518] 47% | Training loss: 0.6870458335788162
Epoch: 72 | Iteration number: [2170/4518] 48% | Training loss: 0.6870401383270316
Epoch: 72 | Iteration number: [2180/4518] 48% | Training loss: 0.6870392518852829
Epoch: 72 | Iteration number: [2190/4518] 48% | Training loss: 0.6870364588417419
Epoch: 72 | Iteration number: [2200/4518] 48% | Training loss: 0.6870323689688336
Epoch: 72 | Iteration number: [2210/4518] 48% | Training loss: 0.68702965802197
Epoch: 72 | Iteration number: [2220/4518] 49% | Training loss: 0.6870302202196809
Epoch: 72 | Iteration number: [2230/4518] 49% | Training loss: 0.6870270246882075
Epoch: 72 | Iteration number: [2240/4518] 49% | Training loss: 0.6870312806484955
Epoch: 72 | Iteration number: [2250/4518] 49% | Training loss: 0.6870294502576192
Epoch: 72 | Iteration number: [2260/4518] 50% | Training loss: 0.6870276404429326
Epoch: 72 | Iteration number: [2270/4518] 50% | Training loss: 0.6870298129083827
Epoch: 72 | Iteration number: [2280/4518] 50% | Training loss: 0.6870270308695341
Epoch: 72 | Iteration number: [2290/4518] 50% | Training loss: 0.6870271897211866
Epoch: 72 | Iteration number: [2300/4518] 50% | Training loss: 0.6870204909728921
Epoch: 72 | Iteration number: [2310/4518] 51% | Training loss: 0.6870241122586387
Epoch: 72 | Iteration number: [2320/4518] 51% | Training loss: 0.6870187183906292
Epoch: 72 | Iteration number: [2330/4518] 51% | Training loss: 0.6870170546959398
Epoch: 72 | Iteration number: [2340/4518] 51% | Training loss: 0.6870179965964749
Epoch: 72 | Iteration number: [2350/4518] 52% | Training loss: 0.6870172989368438
Epoch: 72 | Iteration number: [2360/4518] 52% | Training loss: 0.6870153405908811
Epoch: 72 | Iteration number: [2370/4518] 52% | Training loss: 0.6870146275824133
Epoch: 72 | Iteration number: [2380/4518] 52% | Training loss: 0.6870139267765173
Epoch: 72 | Iteration number: [2390/4518] 52% | Training loss: 0.6870156228292936
Epoch: 72 | Iteration number: [2400/4518] 53% | Training loss: 0.6870125023027261
Epoch: 72 | Iteration number: [2410/4518] 53% | Training loss: 0.6870118657335701
Epoch: 72 | Iteration number: [2420/4518] 53% | Training loss: 0.6870103736554296
Epoch: 72 | Iteration number: [2430/4518] 53% | Training loss: 0.6870130916191227
Epoch: 72 | Iteration number: [2440/4518] 54% | Training loss: 0.6870155974001181
Epoch: 72 | Iteration number: [2450/4518] 54% | Training loss: 0.6870150636410227
Epoch: 72 | Iteration number: [2460/4518] 54% | Training loss: 0.6870159959647714
Epoch: 72 | Iteration number: [2470/4518] 54% | Training loss: 0.6870150668177045
Epoch: 72 | Iteration number: [2480/4518] 54% | Training loss: 0.6870073146397068
Epoch: 72 | Iteration number: [2490/4518] 55% | Training loss: 0.6870027935169787
Epoch: 72 | Iteration number: [2500/4518] 55% | Training loss: 0.6870019904613495
Epoch: 72 | Iteration number: [2510/4518] 55% | Training loss: 0.6870060769447768
Epoch: 72 | Iteration number: [2520/4518] 55% | Training loss: 0.6870075447691811
Epoch: 72 | Iteration number: [2530/4518] 55% | Training loss: 0.6870093687956512
Epoch: 72 | Iteration number: [2540/4518] 56% | Training loss: 0.6870104809680323
Epoch: 72 | Iteration number: [2550/4518] 56% | Training loss: 0.6870126212811938
Epoch: 72 | Iteration number: [2560/4518] 56% | Training loss: 0.6870087996125221
Epoch: 72 | Iteration number: [2570/4518] 56% | Training loss: 0.6870099082995018
Epoch: 72 | Iteration number: [2580/4518] 57% | Training loss: 0.6870085319345312
Epoch: 72 | Iteration number: [2590/4518] 57% | Training loss: 0.6869996654941308
Epoch: 72 | Iteration number: [2600/4518] 57% | Training loss: 0.6869987765642313
Epoch: 72 | Iteration number: [2610/4518] 57% | Training loss: 0.6870001249614803
Epoch: 72 | Iteration number: [2620/4518] 57% | Training loss: 0.6869989151718052
Epoch: 72 | Iteration number: [2630/4518] 58% | Training loss: 0.6869950961024136
Epoch: 72 | Iteration number: [2640/4518] 58% | Training loss: 0.6869903228951223
Epoch: 72 | Iteration number: [2650/4518] 58% | Training loss: 0.6869897665392678
Epoch: 72 | Iteration number: [2660/4518] 58% | Training loss: 0.6869860876547663
Epoch: 72 | Iteration number: [2670/4518] 59% | Training loss: 0.6869814028677422
Epoch: 72 | Iteration number: [2680/4518] 59% | Training loss: 0.6869817979745011
Epoch: 72 | Iteration number: [2690/4518] 59% | Training loss: 0.6869794573925685
Epoch: 72 | Iteration number: [2700/4518] 59% | Training loss: 0.6869795986899623
Epoch: 72 | Iteration number: [2710/4518] 59% | Training loss: 0.6869827311637217
Epoch: 72 | Iteration number: [2720/4518] 60% | Training loss: 0.6869842948282466
Epoch: 72 | Iteration number: [2730/4518] 60% | Training loss: 0.6869821336679843
Epoch: 72 | Iteration number: [2740/4518] 60% | Training loss: 0.6869822222168428
Epoch: 72 | Iteration number: [2750/4518] 60% | Training loss: 0.6869853583899411
Epoch: 72 | Iteration number: [2760/4518] 61% | Training loss: 0.6869856926410095
Epoch: 72 | Iteration number: [2770/4518] 61% | Training loss: 0.6869861205347179
Epoch: 72 | Iteration number: [2780/4518] 61% | Training loss: 0.6869837172597433
Epoch: 72 | Iteration number: [2790/4518] 61% | Training loss: 0.6869840241888518
Epoch: 72 | Iteration number: [2800/4518] 61% | Training loss: 0.6869826130356107
Epoch: 72 | Iteration number: [2810/4518] 62% | Training loss: 0.686985094118797
Epoch: 72 | Iteration number: [2820/4518] 62% | Training loss: 0.686986716207883
Epoch: 72 | Iteration number: [2830/4518] 62% | Training loss: 0.6869881669750483
Epoch: 72 | Iteration number: [2840/4518] 62% | Training loss: 0.6869931685462803
Epoch: 72 | Iteration number: [2850/4518] 63% | Training loss: 0.6869973908390915
Epoch: 72 | Iteration number: [2860/4518] 63% | Training loss: 0.6870001565326344
Epoch: 72 | Iteration number: [2870/4518] 63% | Training loss: 0.6869978866718371
Epoch: 72 | Iteration number: [2880/4518] 63% | Training loss: 0.6870006625644035
Epoch: 72 | Iteration number: [2890/4518] 63% | Training loss: 0.6870000054267038
Epoch: 72 | Iteration number: [2900/4518] 64% | Training loss: 0.6870025773706108
Epoch: 72 | Iteration number: [2910/4518] 64% | Training loss: 0.6870012333098147
Epoch: 72 | Iteration number: [2920/4518] 64% | Training loss: 0.6869989173053063
Epoch: 72 | Iteration number: [2930/4518] 64% | Training loss: 0.6869958466637257
Epoch: 72 | Iteration number: [2940/4518] 65% | Training loss: 0.6869970221300514
Epoch: 72 | Iteration number: [2950/4518] 65% | Training loss: 0.6869961273064048
Epoch: 72 | Iteration number: [2960/4518] 65% | Training loss: 0.6869947341849675
Epoch: 72 | Iteration number: [2970/4518] 65% | Training loss: 0.6869932772334577
Epoch: 72 | Iteration number: [2980/4518] 65% | Training loss: 0.6869945996159675
Epoch: 72 | Iteration number: [2990/4518] 66% | Training loss: 0.6869942084203995
Epoch: 72 | Iteration number: [3000/4518] 66% | Training loss: 0.6869944708943367
Epoch: 72 | Iteration number: [3010/4518] 66% | Training loss: 0.6869927200170054
Epoch: 72 | Iteration number: [3020/4518] 66% | Training loss: 0.6869873272267398
Epoch: 72 | Iteration number: [3030/4518] 67% | Training loss: 0.6869846440581205
Epoch: 72 | Iteration number: [3040/4518] 67% | Training loss: 0.6869847000429504
Epoch: 72 | Iteration number: [3050/4518] 67% | Training loss: 0.6869798743920248
Epoch: 72 | Iteration number: [3060/4518] 67% | Training loss: 0.6869804776377149
Epoch: 72 | Iteration number: [3070/4518] 67% | Training loss: 0.68698139157668
Epoch: 72 | Iteration number: [3080/4518] 68% | Training loss: 0.6869776727317216
Epoch: 72 | Iteration number: [3090/4518] 68% | Training loss: 0.6869746874644147
Epoch: 72 | Iteration number: [3100/4518] 68% | Training loss: 0.6869741248315381
Epoch: 72 | Iteration number: [3110/4518] 68% | Training loss: 0.6869757713612253
Epoch: 72 | Iteration number: [3120/4518] 69% | Training loss: 0.6869760825083806
Epoch: 72 | Iteration number: [3130/4518] 69% | Training loss: 0.6869778484963
Epoch: 72 | Iteration number: [3140/4518] 69% | Training loss: 0.6869741370533682
Epoch: 72 | Iteration number: [3150/4518] 69% | Training loss: 0.6869740504877908
Epoch: 72 | Iteration number: [3160/4518] 69% | Training loss: 0.6869737744519983
Epoch: 72 | Iteration number: [3170/4518] 70% | Training loss: 0.6869737385199273
Epoch: 72 | Iteration number: [3180/4518] 70% | Training loss: 0.6869757243859693
Epoch: 72 | Iteration number: [3190/4518] 70% | Training loss: 0.6869803651560062
Epoch: 72 | Iteration number: [3200/4518] 70% | Training loss: 0.6869788196869194
Epoch: 72 | Iteration number: [3210/4518] 71% | Training loss: 0.6869807818039927
Epoch: 72 | Iteration number: [3220/4518] 71% | Training loss: 0.6869823277366828
Epoch: 72 | Iteration number: [3230/4518] 71% | Training loss: 0.6869802375696022
Epoch: 72 | Iteration number: [3240/4518] 71% | Training loss: 0.6869794867288919
Epoch: 72 | Iteration number: [3250/4518] 71% | Training loss: 0.6869782368586613
Epoch: 72 | Iteration number: [3260/4518] 72% | Training loss: 0.6869786197239636
Epoch: 72 | Iteration number: [3270/4518] 72% | Training loss: 0.6869757070818443
Epoch: 72 | Iteration number: [3280/4518] 72% | Training loss: 0.6869731480210293
Epoch: 72 | Iteration number: [3290/4518] 72% | Training loss: 0.6869696529802942
Epoch: 72 | Iteration number: [3300/4518] 73% | Training loss: 0.6869710901108655
Epoch: 72 | Iteration number: [3310/4518] 73% | Training loss: 0.6869700142804229
Epoch: 72 | Iteration number: [3320/4518] 73% | Training loss: 0.6869664702788894
Epoch: 72 | Iteration number: [3330/4518] 73% | Training loss: 0.6869680467131618
Epoch: 72 | Iteration number: [3340/4518] 73% | Training loss: 0.6869657918543159
Epoch: 72 | Iteration number: [3350/4518] 74% | Training loss: 0.6869636821924751
Epoch: 72 | Iteration number: [3360/4518] 74% | Training loss: 0.6869650699730431
Epoch: 72 | Iteration number: [3370/4518] 74% | Training loss: 0.6869655845780754
Epoch: 72 | Iteration number: [3380/4518] 74% | Training loss: 0.6869686657684089
Epoch: 72 | Iteration number: [3390/4518] 75% | Training loss: 0.686965902083743
Epoch: 72 | Iteration number: [3400/4518] 75% | Training loss: 0.6869690928389044
Epoch: 72 | Iteration number: [3410/4518] 75% | Training loss: 0.6869711783449671
Epoch: 72 | Iteration number: [3420/4518] 75% | Training loss: 0.6869721538839284
Epoch: 72 | Iteration number: [3430/4518] 75% | Training loss: 0.6869715583046393
Epoch: 72 | Iteration number: [3440/4518] 76% | Training loss: 0.6869726784700572
Epoch: 72 | Iteration number: [3450/4518] 76% | Training loss: 0.6869712050755818
Epoch: 72 | Iteration number: [3460/4518] 76% | Training loss: 0.6869706905473864
Epoch: 72 | Iteration number: [3470/4518] 76% | Training loss: 0.6869709746638362
Epoch: 72 | Iteration number: [3480/4518] 77% | Training loss: 0.6869721293106846
Epoch: 72 | Iteration number: [3490/4518] 77% | Training loss: 0.6869737524016197
Epoch: 72 | Iteration number: [3500/4518] 77% | Training loss: 0.686976194688252
Epoch: 72 | Iteration number: [3510/4518] 77% | Training loss: 0.6869771691469045
Epoch: 72 | Iteration number: [3520/4518] 77% | Training loss: 0.6869755639101971
Epoch: 72 | Iteration number: [3530/4518] 78% | Training loss: 0.6869759267349081
Epoch: 72 | Iteration number: [3540/4518] 78% | Training loss: 0.6869756268916157
Epoch: 72 | Iteration number: [3550/4518] 78% | Training loss: 0.6869739392945464
Epoch: 72 | Iteration number: [3560/4518] 78% | Training loss: 0.686972219203965
Epoch: 72 | Iteration number: [3570/4518] 79% | Training loss: 0.6869704602145347
Epoch: 72 | Iteration number: [3580/4518] 79% | Training loss: 0.6869710574436454
Epoch: 72 | Iteration number: [3590/4518] 79% | Training loss: 0.6869709240028785
Epoch: 72 | Iteration number: [3600/4518] 79% | Training loss: 0.6869698528945446
Epoch: 72 | Iteration number: [3610/4518] 79% | Training loss: 0.6869713468895065
Epoch: 72 | Iteration number: [3620/4518] 80% | Training loss: 0.6869700096588767
Epoch: 72 | Iteration number: [3630/4518] 80% | Training loss: 0.6869707756298633
Epoch: 72 | Iteration number: [3640/4518] 80% | Training loss: 0.6869719734394943
Epoch: 72 | Iteration number: [3650/4518] 80% | Training loss: 0.6869695648918414
Epoch: 72 | Iteration number: [3660/4518] 81% | Training loss: 0.6869689693542126
Epoch: 72 | Iteration number: [3670/4518] 81% | Training loss: 0.6869667636925908
Epoch: 72 | Iteration number: [3680/4518] 81% | Training loss: 0.686968570769481
Epoch: 72 | Iteration number: [3690/4518] 81% | Training loss: 0.6869697256947598
Epoch: 72 | Iteration number: [3700/4518] 81% | Training loss: 0.6869689187004759
Epoch: 72 | Iteration number: [3710/4518] 82% | Training loss: 0.6869698605447445
Epoch: 72 | Iteration number: [3720/4518] 82% | Training loss: 0.6869666417439778
Epoch: 72 | Iteration number: [3730/4518] 82% | Training loss: 0.6869675448209287
Epoch: 72 | Iteration number: [3740/4518] 82% | Training loss: 0.6869669978790742
Epoch: 72 | Iteration number: [3750/4518] 83% | Training loss: 0.6869654193560283
Epoch: 72 | Iteration number: [3760/4518] 83% | Training loss: 0.6869648292819236
Epoch: 72 | Iteration number: [3770/4518] 83% | Training loss: 0.6869674405621597
Epoch: 72 | Iteration number: [3780/4518] 83% | Training loss: 0.6869701419242475
Epoch: 72 | Iteration number: [3790/4518] 83% | Training loss: 0.6869670987443748
Epoch: 72 | Iteration number: [3800/4518] 84% | Training loss: 0.6869674338321937
Epoch: 72 | Iteration number: [3810/4518] 84% | Training loss: 0.6869643862166117
Epoch: 72 | Iteration number: [3820/4518] 84% | Training loss: 0.6869648191785314
Epoch: 72 | Iteration number: [3830/4518] 84% | Training loss: 0.6869650055938851
Epoch: 72 | Iteration number: [3840/4518] 84% | Training loss: 0.6869618776564796
Epoch: 72 | Iteration number: [3850/4518] 85% | Training loss: 0.6869624037402017
Epoch: 72 | Iteration number: [3860/4518] 85% | Training loss: 0.6869593713722081
Epoch: 72 | Iteration number: [3870/4518] 85% | Training loss: 0.6869576687806644
Epoch: 72 | Iteration number: [3880/4518] 85% | Training loss: 0.6869582074358291
Epoch: 72 | Iteration number: [3890/4518] 86% | Training loss: 0.6869590828841634
Epoch: 72 | Iteration number: [3900/4518] 86% | Training loss: 0.6869589052292017
Epoch: 72 | Iteration number: [3910/4518] 86% | Training loss: 0.6869586803266764
Epoch: 72 | Iteration number: [3920/4518] 86% | Training loss: 0.686952817044696
Epoch: 72 | Iteration number: [3930/4518] 86% | Training loss: 0.6869537297247627
Epoch: 72 | Iteration number: [3940/4518] 87% | Training loss: 0.6869565760726251
Epoch: 72 | Iteration number: [3950/4518] 87% | Training loss: 0.6869570845742768
Epoch: 72 | Iteration number: [3960/4518] 87% | Training loss: 0.686956709427665
Epoch: 72 | Iteration number: [3970/4518] 87% | Training loss: 0.6869590494734814
Epoch: 72 | Iteration number: [3980/4518] 88% | Training loss: 0.6869593741606228
Epoch: 72 | Iteration number: [3990/4518] 88% | Training loss: 0.6869604951456973
Epoch: 72 | Iteration number: [4000/4518] 88% | Training loss: 0.6869592604190111
Epoch: 72 | Iteration number: [4010/4518] 88% | Training loss: 0.6869582389060993
Epoch: 72 | Iteration number: [4020/4518] 88% | Training loss: 0.6869612055927959
Epoch: 72 | Iteration number: [4030/4518] 89% | Training loss: 0.6869616043183111
Epoch: 72 | Iteration number: [4040/4518] 89% | Training loss: 0.6869560678406517
Epoch: 72 | Iteration number: [4050/4518] 89% | Training loss: 0.6869547922817277
Epoch: 72 | Iteration number: [4060/4518] 89% | Training loss: 0.6869541847940737
Epoch: 72 | Iteration number: [4070/4518] 90% | Training loss: 0.6869552030170872
Epoch: 72 | Iteration number: [4080/4518] 90% | Training loss: 0.6869537826700538
Epoch: 72 | Iteration number: [4090/4518] 90% | Training loss: 0.6869488528567597
Epoch: 72 | Iteration number: [4100/4518] 90% | Training loss: 0.6869470483646161
Epoch: 72 | Iteration number: [4110/4518] 90% | Training loss: 0.6869481446244131
Epoch: 72 | Iteration number: [4120/4518] 91% | Training loss: 0.6869458918143244
Epoch: 72 | Iteration number: [4130/4518] 91% | Training loss: 0.686944734501781
Epoch: 72 | Iteration number: [4140/4518] 91% | Training loss: 0.6869458055870544
Epoch: 72 | Iteration number: [4150/4518] 91% | Training loss: 0.6869444028297103
Epoch: 72 | Iteration number: [4160/4518] 92% | Training loss: 0.6869479889766528
Epoch: 72 | Iteration number: [4170/4518] 92% | Training loss: 0.6869464575243797
Epoch: 72 | Iteration number: [4180/4518] 92% | Training loss: 0.6869452850955525
Epoch: 72 | Iteration number: [4190/4518] 92% | Training loss: 0.6869484019023422
Epoch: 72 | Iteration number: [4200/4518] 92% | Training loss: 0.6869493780533472
Epoch: 72 | Iteration number: [4210/4518] 93% | Training loss: 0.6869473000461869
Epoch: 72 | Iteration number: [4220/4518] 93% | Training loss: 0.6869460434427759
Epoch: 72 | Iteration number: [4230/4518] 93% | Training loss: 0.6869451742786606
Epoch: 72 | Iteration number: [4240/4518] 93% | Training loss: 0.6869436339949662
Epoch: 72 | Iteration number: [4250/4518] 94% | Training loss: 0.6869435537282158
Epoch: 72 | Iteration number: [4260/4518] 94% | Training loss: 0.6869429938670055
Epoch: 72 | Iteration number: [4270/4518] 94% | Training loss: 0.6869396987648144
Epoch: 72 | Iteration number: [4280/4518] 94% | Training loss: 0.6869377139154996
Epoch: 72 | Iteration number: [4290/4518] 94% | Training loss: 0.6869364357911624
Epoch: 72 | Iteration number: [4300/4518] 95% | Training loss: 0.6869375979068667
Epoch: 72 | Iteration number: [4310/4518] 95% | Training loss: 0.686935931513315
Epoch: 72 | Iteration number: [4320/4518] 95% | Training loss: 0.6869353637375214
Epoch: 72 | Iteration number: [4330/4518] 95% | Training loss: 0.68693296548676
Epoch: 72 | Iteration number: [4340/4518] 96% | Training loss: 0.6869302900568132
Epoch: 72 | Iteration number: [4350/4518] 96% | Training loss: 0.6869302098778473
Epoch: 72 | Iteration number: [4360/4518] 96% | Training loss: 0.6869333267758746
Epoch: 72 | Iteration number: [4370/4518] 96% | Training loss: 0.6869286289067781
Epoch: 72 | Iteration number: [4380/4518] 96% | Training loss: 0.6869286387342296
Epoch: 72 | Iteration number: [4390/4518] 97% | Training loss: 0.6869269507485262
Epoch: 72 | Iteration number: [4400/4518] 97% | Training loss: 0.6869241559640927
Epoch: 72 | Iteration number: [4410/4518] 97% | Training loss: 0.6869212989498968
Epoch: 72 | Iteration number: [4420/4518] 97% | Training loss: 0.6869241051544431
Epoch: 72 | Iteration number: [4430/4518] 98% | Training loss: 0.6869264333700219
Epoch: 72 | Iteration number: [4440/4518] 98% | Training loss: 0.6869263954930477
Epoch: 72 | Iteration number: [4450/4518] 98% | Training loss: 0.6869249955321965
Epoch: 72 | Iteration number: [4460/4518] 98% | Training loss: 0.6869220212970614
Epoch: 72 | Iteration number: [4470/4518] 98% | Training loss: 0.6869235446255746
Epoch: 72 | Iteration number: [4480/4518] 99% | Training loss: 0.6869256139466805
Epoch: 72 | Iteration number: [4490/4518] 99% | Training loss: 0.6869259348823658
Epoch: 72 | Iteration number: [4500/4518] 99% | Training loss: 0.6869277311033672
Epoch: 72 | Iteration number: [4510/4518] 99% | Training loss: 0.6869263073293174

 End of epoch: 72 | Train Loss: 0.686774687054095 | Training Time: 642 

 End of epoch: 72 | Eval Loss: 0.6898679307528904 | Evaluating Time: 17 
Epoch: 73 | Iteration number: [10/4518] 0% | Training loss: 0.7541214168071747
Epoch: 73 | Iteration number: [20/4518] 0% | Training loss: 0.719585195183754
Epoch: 73 | Iteration number: [30/4518] 0% | Training loss: 0.7088925103346507
Epoch: 73 | Iteration number: [40/4518] 0% | Training loss: 0.7033449575304985
Epoch: 73 | Iteration number: [50/4518] 1% | Training loss: 0.6997742640972138
Epoch: 73 | Iteration number: [60/4518] 1% | Training loss: 0.6978032539288203
Epoch: 73 | Iteration number: [70/4518] 1% | Training loss: 0.6964610653264182
Epoch: 73 | Iteration number: [80/4518] 1% | Training loss: 0.6954968102276325
Epoch: 73 | Iteration number: [90/4518] 1% | Training loss: 0.6944324062930213
Epoch: 73 | Iteration number: [100/4518] 2% | Training loss: 0.6938087487220764
Epoch: 73 | Iteration number: [110/4518] 2% | Training loss: 0.693171253529462
Epoch: 73 | Iteration number: [120/4518] 2% | Training loss: 0.6925272539258003
Epoch: 73 | Iteration number: [130/4518] 2% | Training loss: 0.6920562900029696
Epoch: 73 | Iteration number: [140/4518] 3% | Training loss: 0.6916706246989114
Epoch: 73 | Iteration number: [150/4518] 3% | Training loss: 0.6913334850470225
Epoch: 73 | Iteration number: [160/4518] 3% | Training loss: 0.6910709496587515
Epoch: 73 | Iteration number: [170/4518] 3% | Training loss: 0.690824007286745
Epoch: 73 | Iteration number: [180/4518] 3% | Training loss: 0.6906790339284473
Epoch: 73 | Iteration number: [190/4518] 4% | Training loss: 0.6905102939982163
Epoch: 73 | Iteration number: [200/4518] 4% | Training loss: 0.6903274759650231
Epoch: 73 | Iteration number: [210/4518] 4% | Training loss: 0.6901173049495334
Epoch: 73 | Iteration number: [220/4518] 4% | Training loss: 0.6899496593258597
Epoch: 73 | Iteration number: [230/4518] 5% | Training loss: 0.6898033294988715
Epoch: 73 | Iteration number: [240/4518] 5% | Training loss: 0.6896787541608016
Epoch: 73 | Iteration number: [250/4518] 5% | Training loss: 0.6895645344257355
Epoch: 73 | Iteration number: [260/4518] 5% | Training loss: 0.6894809743532768
Epoch: 73 | Iteration number: [270/4518] 5% | Training loss: 0.6893683003054725
Epoch: 73 | Iteration number: [280/4518] 6% | Training loss: 0.6892463417989867
Epoch: 73 | Iteration number: [290/4518] 6% | Training loss: 0.689203732178129
Epoch: 73 | Iteration number: [300/4518] 6% | Training loss: 0.6890905261039734
Epoch: 73 | Iteration number: [310/4518] 6% | Training loss: 0.6890319591568362
Epoch: 73 | Iteration number: [320/4518] 7% | Training loss: 0.6889439133927227
Epoch: 73 | Iteration number: [330/4518] 7% | Training loss: 0.6888621709563515
Epoch: 73 | Iteration number: [340/4518] 7% | Training loss: 0.6887883072390276
Epoch: 73 | Iteration number: [350/4518] 7% | Training loss: 0.6887470735822405
Epoch: 73 | Iteration number: [360/4518] 7% | Training loss: 0.6887110112441911
Epoch: 73 | Iteration number: [370/4518] 8% | Training loss: 0.6886468210735837
Epoch: 73 | Iteration number: [380/4518] 8% | Training loss: 0.6885966884462457
Epoch: 73 | Iteration number: [390/4518] 8% | Training loss: 0.6885238736103743
Epoch: 73 | Iteration number: [400/4518] 8% | Training loss: 0.6885084226727486
Epoch: 73 | Iteration number: [410/4518] 9% | Training loss: 0.6884846422730423
Epoch: 73 | Iteration number: [420/4518] 9% | Training loss: 0.6884580708685375
Epoch: 73 | Iteration number: [430/4518] 9% | Training loss: 0.688402686562649
Epoch: 73 | Iteration number: [440/4518] 9% | Training loss: 0.688376355713064
Epoch: 73 | Iteration number: [450/4518] 9% | Training loss: 0.6883408068286048
Epoch: 73 | Iteration number: [460/4518] 10% | Training loss: 0.6883304571327956
Epoch: 73 | Iteration number: [470/4518] 10% | Training loss: 0.6883088229818547
Epoch: 73 | Iteration number: [480/4518] 10% | Training loss: 0.6882761901865403
Epoch: 73 | Iteration number: [490/4518] 10% | Training loss: 0.6881995979620485
Epoch: 73 | Iteration number: [500/4518] 11% | Training loss: 0.6881560788154603
Epoch: 73 | Iteration number: [510/4518] 11% | Training loss: 0.6881438415424497
Epoch: 73 | Iteration number: [520/4518] 11% | Training loss: 0.6881223991513252
Epoch: 73 | Iteration number: [530/4518] 11% | Training loss: 0.6880973454916253
Epoch: 73 | Iteration number: [540/4518] 11% | Training loss: 0.6880930545153441
Epoch: 73 | Iteration number: [550/4518] 12% | Training loss: 0.6880410992015492
Epoch: 73 | Iteration number: [560/4518] 12% | Training loss: 0.688006445978369
Epoch: 73 | Iteration number: [570/4518] 12% | Training loss: 0.6879892707916728
Epoch: 73 | Iteration number: [580/4518] 12% | Training loss: 0.687980533262779
Epoch: 73 | Iteration number: [590/4518] 13% | Training loss: 0.6879824183755002
Epoch: 73 | Iteration number: [600/4518] 13% | Training loss: 0.6879427949587504
Epoch: 73 | Iteration number: [610/4518] 13% | Training loss: 0.6879201713155527
Epoch: 73 | Iteration number: [620/4518] 13% | Training loss: 0.6879179301761812
Epoch: 73 | Iteration number: [630/4518] 13% | Training loss: 0.6878987092820424
Epoch: 73 | Iteration number: [640/4518] 14% | Training loss: 0.6878692622296512
Epoch: 73 | Iteration number: [650/4518] 14% | Training loss: 0.6878712268976065
Epoch: 73 | Iteration number: [660/4518] 14% | Training loss: 0.6878629702510256
Epoch: 73 | Iteration number: [670/4518] 14% | Training loss: 0.6878544492508049
Epoch: 73 | Iteration number: [680/4518] 15% | Training loss: 0.6878374913159538
Epoch: 73 | Iteration number: [690/4518] 15% | Training loss: 0.6878216515416684
Epoch: 73 | Iteration number: [700/4518] 15% | Training loss: 0.6878141834054674
Epoch: 73 | Iteration number: [710/4518] 15% | Training loss: 0.687811773763576
Epoch: 73 | Iteration number: [720/4518] 15% | Training loss: 0.6878137889835569
Epoch: 73 | Iteration number: [730/4518] 16% | Training loss: 0.6877949623212423
Epoch: 73 | Iteration number: [740/4518] 16% | Training loss: 0.6877643262212341
Epoch: 73 | Iteration number: [750/4518] 16% | Training loss: 0.6877376612822215
Epoch: 73 | Iteration number: [760/4518] 16% | Training loss: 0.68771340996027
Epoch: 73 | Iteration number: [770/4518] 17% | Training loss: 0.6877002071250569
Epoch: 73 | Iteration number: [780/4518] 17% | Training loss: 0.6876956699750363
Epoch: 73 | Iteration number: [790/4518] 17% | Training loss: 0.6876908973802494
Epoch: 73 | Iteration number: [800/4518] 17% | Training loss: 0.6876696287095547
Epoch: 73 | Iteration number: [810/4518] 17% | Training loss: 0.6876505343266476
Epoch: 73 | Iteration number: [820/4518] 18% | Training loss: 0.6876469804019463
Epoch: 73 | Iteration number: [830/4518] 18% | Training loss: 0.6876487668020179
Epoch: 73 | Iteration number: [840/4518] 18% | Training loss: 0.6876468129810833
Epoch: 73 | Iteration number: [850/4518] 18% | Training loss: 0.6876240562691408
Epoch: 73 | Iteration number: [860/4518] 19% | Training loss: 0.6876066085211067
Epoch: 73 | Iteration number: [870/4518] 19% | Training loss: 0.6875819117858493
Epoch: 73 | Iteration number: [880/4518] 19% | Training loss: 0.6875686628574674
Epoch: 73 | Iteration number: [890/4518] 19% | Training loss: 0.6875710854369603
Epoch: 73 | Iteration number: [900/4518] 19% | Training loss: 0.687556858393881
Epoch: 73 | Iteration number: [910/4518] 20% | Training loss: 0.6875487554859329
Epoch: 73 | Iteration number: [920/4518] 20% | Training loss: 0.6875493100155955
Epoch: 73 | Iteration number: [930/4518] 20% | Training loss: 0.6875448062214801
Epoch: 73 | Iteration number: [940/4518] 20% | Training loss: 0.687524100504023
Epoch: 73 | Iteration number: [950/4518] 21% | Training loss: 0.6875233611935063
Epoch: 73 | Iteration number: [960/4518] 21% | Training loss: 0.6875132850681742
Epoch: 73 | Iteration number: [970/4518] 21% | Training loss: 0.6875110025872889
Epoch: 73 | Iteration number: [980/4518] 21% | Training loss: 0.6875101238489151
Epoch: 73 | Iteration number: [990/4518] 21% | Training loss: 0.6874909445492908
Epoch: 73 | Iteration number: [1000/4518] 22% | Training loss: 0.6874786003828048
Epoch: 73 | Iteration number: [1010/4518] 22% | Training loss: 0.6874804656104286
Epoch: 73 | Iteration number: [1020/4518] 22% | Training loss: 0.6874794819775749
Epoch: 73 | Iteration number: [1030/4518] 22% | Training loss: 0.6874812804958196
Epoch: 73 | Iteration number: [1040/4518] 23% | Training loss: 0.6874568273814825
Epoch: 73 | Iteration number: [1050/4518] 23% | Training loss: 0.6874433275631496
Epoch: 73 | Iteration number: [1060/4518] 23% | Training loss: 0.6874372051009592
Epoch: 73 | Iteration number: [1070/4518] 23% | Training loss: 0.6874293444312621
Epoch: 73 | Iteration number: [1080/4518] 23% | Training loss: 0.6874232413040267
Epoch: 73 | Iteration number: [1090/4518] 24% | Training loss: 0.6874224870576771
Epoch: 73 | Iteration number: [1100/4518] 24% | Training loss: 0.6874207950180227
Epoch: 73 | Iteration number: [1110/4518] 24% | Training loss: 0.6874271500755
Epoch: 73 | Iteration number: [1120/4518] 24% | Training loss: 0.6874270979315042
Epoch: 73 | Iteration number: [1130/4518] 25% | Training loss: 0.6874224777242779
Epoch: 73 | Iteration number: [1140/4518] 25% | Training loss: 0.6874183909412016
Epoch: 73 | Iteration number: [1150/4518] 25% | Training loss: 0.6874141788482666
Epoch: 73 | Iteration number: [1160/4518] 25% | Training loss: 0.6874169610183815
Epoch: 73 | Iteration number: [1170/4518] 25% | Training loss: 0.6874079283486064
Epoch: 73 | Iteration number: [1180/4518] 26% | Training loss: 0.6874105833849664
Epoch: 73 | Iteration number: [1190/4518] 26% | Training loss: 0.6874063676645776
Epoch: 73 | Iteration number: [1200/4518] 26% | Training loss: 0.6873997897406419
Epoch: 73 | Iteration number: [1210/4518] 26% | Training loss: 0.6873882128680048
Epoch: 73 | Iteration number: [1220/4518] 27% | Training loss: 0.6873898232080897
Epoch: 73 | Iteration number: [1230/4518] 27% | Training loss: 0.6873905122764712
Epoch: 73 | Iteration number: [1240/4518] 27% | Training loss: 0.687376612520987
Epoch: 73 | Iteration number: [1250/4518] 27% | Training loss: 0.6873776953220367
Epoch: 73 | Iteration number: [1260/4518] 27% | Training loss: 0.68738083924566
Epoch: 73 | Iteration number: [1270/4518] 28% | Training loss: 0.6873807522255605
Epoch: 73 | Iteration number: [1280/4518] 28% | Training loss: 0.6873796470928937
Epoch: 73 | Iteration number: [1290/4518] 28% | Training loss: 0.6873721135679142
Epoch: 73 | Iteration number: [1300/4518] 28% | Training loss: 0.6873571280332712
Epoch: 73 | Iteration number: [1310/4518] 28% | Training loss: 0.687354206265384
Epoch: 73 | Iteration number: [1320/4518] 29% | Training loss: 0.6873464803804051
Epoch: 73 | Iteration number: [1330/4518] 29% | Training loss: 0.6873418876999303
Epoch: 73 | Iteration number: [1340/4518] 29% | Training loss: 0.6873404768420689
Epoch: 73 | Iteration number: [1350/4518] 29% | Training loss: 0.687322976898264
Epoch: 73 | Iteration number: [1360/4518] 30% | Training loss: 0.6873155314256163
Epoch: 73 | Iteration number: [1370/4518] 30% | Training loss: 0.6873019234542429
Epoch: 73 | Iteration number: [1380/4518] 30% | Training loss: 0.6872936498859654
Epoch: 73 | Iteration number: [1390/4518] 30% | Training loss: 0.6872990906667367
Epoch: 73 | Iteration number: [1400/4518] 30% | Training loss: 0.6872804433958871
Epoch: 73 | Iteration number: [1410/4518] 31% | Training loss: 0.6872833720758451
Epoch: 73 | Iteration number: [1420/4518] 31% | Training loss: 0.6872804004541585
Epoch: 73 | Iteration number: [1430/4518] 31% | Training loss: 0.6872702270121007
Epoch: 73 | Iteration number: [1440/4518] 31% | Training loss: 0.6872630283650425
Epoch: 73 | Iteration number: [1450/4518] 32% | Training loss: 0.6872601808350661
Epoch: 73 | Iteration number: [1460/4518] 32% | Training loss: 0.6872563617686703
Epoch: 73 | Iteration number: [1470/4518] 32% | Training loss: 0.6872468215267674
Epoch: 73 | Iteration number: [1480/4518] 32% | Training loss: 0.6872404899951574
Epoch: 73 | Iteration number: [1490/4518] 32% | Training loss: 0.6872437241493455
Epoch: 73 | Iteration number: [1500/4518] 33% | Training loss: 0.687244448184967
Epoch: 73 | Iteration number: [1510/4518] 33% | Training loss: 0.6872370331492645
Epoch: 73 | Iteration number: [1520/4518] 33% | Training loss: 0.6872363101102804
Epoch: 73 | Iteration number: [1530/4518] 33% | Training loss: 0.6872381926751604
Epoch: 73 | Iteration number: [1540/4518] 34% | Training loss: 0.6872331050309268
Epoch: 73 | Iteration number: [1550/4518] 34% | Training loss: 0.687224548016825
Epoch: 73 | Iteration number: [1560/4518] 34% | Training loss: 0.6872280322970488
Epoch: 73 | Iteration number: [1570/4518] 34% | Training loss: 0.6872294317005546
Epoch: 73 | Iteration number: [1580/4518] 34% | Training loss: 0.6872284020804151
Epoch: 73 | Iteration number: [1590/4518] 35% | Training loss: 0.6872220381250921
Epoch: 73 | Iteration number: [1600/4518] 35% | Training loss: 0.6872179269790649
Epoch: 73 | Iteration number: [1610/4518] 35% | Training loss: 0.6872179975420792
Epoch: 73 | Iteration number: [1620/4518] 35% | Training loss: 0.6872209708999705
Epoch: 73 | Iteration number: [1630/4518] 36% | Training loss: 0.6872131358260757
Epoch: 73 | Iteration number: [1640/4518] 36% | Training loss: 0.6872043276705393
Epoch: 73 | Iteration number: [1650/4518] 36% | Training loss: 0.6872045254707336
Epoch: 73 | Iteration number: [1660/4518] 36% | Training loss: 0.6872021228793156
Epoch: 73 | Iteration number: [1670/4518] 36% | Training loss: 0.6871956765651703
Epoch: 73 | Iteration number: [1680/4518] 37% | Training loss: 0.6871952688764958
Epoch: 73 | Iteration number: [1690/4518] 37% | Training loss: 0.6871931026320486
Epoch: 73 | Iteration number: [1700/4518] 37% | Training loss: 0.687187033646247
Epoch: 73 | Iteration number: [1710/4518] 37% | Training loss: 0.6871884593489574
Epoch: 73 | Iteration number: [1720/4518] 38% | Training loss: 0.6871828222344089
Epoch: 73 | Iteration number: [1730/4518] 38% | Training loss: 0.6871806012068181
Epoch: 73 | Iteration number: [1740/4518] 38% | Training loss: 0.6871694103397172
Epoch: 73 | Iteration number: [1750/4518] 38% | Training loss: 0.6871647948878152
Epoch: 73 | Iteration number: [1760/4518] 38% | Training loss: 0.6871653481301936
Epoch: 73 | Iteration number: [1770/4518] 39% | Training loss: 0.6871645831792368
Epoch: 73 | Iteration number: [1780/4518] 39% | Training loss: 0.6871629520078724
Epoch: 73 | Iteration number: [1790/4518] 39% | Training loss: 0.6871612688682599
Epoch: 73 | Iteration number: [1800/4518] 39% | Training loss: 0.6871602127287123
Epoch: 73 | Iteration number: [1810/4518] 40% | Training loss: 0.6871619108961432
Epoch: 73 | Iteration number: [1820/4518] 40% | Training loss: 0.6871646025351116
Epoch: 73 | Iteration number: [1830/4518] 40% | Training loss: 0.687165871018269
Epoch: 73 | Iteration number: [1840/4518] 40% | Training loss: 0.6871697410293247
Epoch: 73 | Iteration number: [1850/4518] 40% | Training loss: 0.6871654569780504
Epoch: 73 | Iteration number: [1860/4518] 41% | Training loss: 0.6871624828025859
Epoch: 73 | Iteration number: [1870/4518] 41% | Training loss: 0.68715586420049
Epoch: 73 | Iteration number: [1880/4518] 41% | Training loss: 0.687148402219123
Epoch: 73 | Iteration number: [1890/4518] 41% | Training loss: 0.6871495088572225
Epoch: 73 | Iteration number: [1900/4518] 42% | Training loss: 0.6871503000824075
Epoch: 73 | Iteration number: [1910/4518] 42% | Training loss: 0.6871503216121834
Epoch: 73 | Iteration number: [1920/4518] 42% | Training loss: 0.6871451784546176
Epoch: 73 | Iteration number: [1930/4518] 42% | Training loss: 0.6871419587283555
Epoch: 73 | Iteration number: [1940/4518] 42% | Training loss: 0.6871398698730568
Epoch: 73 | Iteration number: [1950/4518] 43% | Training loss: 0.6871362277177664
Epoch: 73 | Iteration number: [1960/4518] 43% | Training loss: 0.6871352352962202
Epoch: 73 | Iteration number: [1970/4518] 43% | Training loss: 0.687135250314238
Epoch: 73 | Iteration number: [1980/4518] 43% | Training loss: 0.6871340023146735
Epoch: 73 | Iteration number: [1990/4518] 44% | Training loss: 0.687130087434347
Epoch: 73 | Iteration number: [2000/4518] 44% | Training loss: 0.6871283976733684
Epoch: 73 | Iteration number: [2010/4518] 44% | Training loss: 0.6871311132291064
Epoch: 73 | Iteration number: [2020/4518] 44% | Training loss: 0.6871269289809878
Epoch: 73 | Iteration number: [2030/4518] 44% | Training loss: 0.6871209677217042
Epoch: 73 | Iteration number: [2040/4518] 45% | Training loss: 0.687116273185786
Epoch: 73 | Iteration number: [2050/4518] 45% | Training loss: 0.6871178483381504
Epoch: 73 | Iteration number: [2060/4518] 45% | Training loss: 0.6871180393452784
Epoch: 73 | Iteration number: [2070/4518] 45% | Training loss: 0.687115961831549
Epoch: 73 | Iteration number: [2080/4518] 46% | Training loss: 0.6871150378997509
Epoch: 73 | Iteration number: [2090/4518] 46% | Training loss: 0.6871159074979536
Epoch: 73 | Iteration number: [2100/4518] 46% | Training loss: 0.6871107309772855
Epoch: 73 | Iteration number: [2110/4518] 46% | Training loss: 0.6871089422307308
Epoch: 73 | Iteration number: [2120/4518] 46% | Training loss: 0.6871056039940636
Epoch: 73 | Iteration number: [2130/4518] 47% | Training loss: 0.6871017511741656
Epoch: 73 | Iteration number: [2140/4518] 47% | Training loss: 0.6870996204213561
Epoch: 73 | Iteration number: [2150/4518] 47% | Training loss: 0.6870991197852201
Epoch: 73 | Iteration number: [2160/4518] 47% | Training loss: 0.6870987712785049
Epoch: 73 | Iteration number: [2170/4518] 48% | Training loss: 0.6871023818095159
Epoch: 73 | Iteration number: [2180/4518] 48% | Training loss: 0.6871005681676602
Epoch: 73 | Iteration number: [2190/4518] 48% | Training loss: 0.6870974722790392
Epoch: 73 | Iteration number: [2200/4518] 48% | Training loss: 0.6870954883098602
Epoch: 73 | Iteration number: [2210/4518] 48% | Training loss: 0.6870934727235077
Epoch: 73 | Iteration number: [2220/4518] 49% | Training loss: 0.6870926894851633
Epoch: 73 | Iteration number: [2230/4518] 49% | Training loss: 0.6870900153579199
Epoch: 73 | Iteration number: [2240/4518] 49% | Training loss: 0.6870844065078667
Epoch: 73 | Iteration number: [2250/4518] 49% | Training loss: 0.6870831542544895
Epoch: 73 | Iteration number: [2260/4518] 50% | Training loss: 0.6870845229488558
Epoch: 73 | Iteration number: [2270/4518] 50% | Training loss: 0.6870796029788282
Epoch: 73 | Iteration number: [2280/4518] 50% | Training loss: 0.6870790511108281
Epoch: 73 | Iteration number: [2290/4518] 50% | Training loss: 0.6870791058352941
Epoch: 73 | Iteration number: [2300/4518] 50% | Training loss: 0.6870750884387804
Epoch: 73 | Iteration number: [2310/4518] 51% | Training loss: 0.6870743831514796
Epoch: 73 | Iteration number: [2320/4518] 51% | Training loss: 0.6870674740908475
Epoch: 73 | Iteration number: [2330/4518] 51% | Training loss: 0.6870620703748367
Epoch: 73 | Iteration number: [2340/4518] 51% | Training loss: 0.6870612194650193
Epoch: 73 | Iteration number: [2350/4518] 52% | Training loss: 0.6870627229518079
Epoch: 73 | Iteration number: [2360/4518] 52% | Training loss: 0.6870660507830523
Epoch: 73 | Iteration number: [2370/4518] 52% | Training loss: 0.68706518087206
Epoch: 73 | Iteration number: [2380/4518] 52% | Training loss: 0.6870635743151192
Epoch: 73 | Iteration number: [2390/4518] 52% | Training loss: 0.6870585607684307
Epoch: 73 | Iteration number: [2400/4518] 53% | Training loss: 0.6870589639494816
Epoch: 73 | Iteration number: [2410/4518] 53% | Training loss: 0.6870617914743938
Epoch: 73 | Iteration number: [2420/4518] 53% | Training loss: 0.6870652480558915
Epoch: 73 | Iteration number: [2430/4518] 53% | Training loss: 0.6870629408477266
Epoch: 73 | Iteration number: [2440/4518] 54% | Training loss: 0.6870643027737492
Epoch: 73 | Iteration number: [2450/4518] 54% | Training loss: 0.6870605859464528
Epoch: 73 | Iteration number: [2460/4518] 54% | Training loss: 0.6870540900685923
Epoch: 73 | Iteration number: [2470/4518] 54% | Training loss: 0.6870578314611304
Epoch: 73 | Iteration number: [2480/4518] 54% | Training loss: 0.6870526501007619
Epoch: 73 | Iteration number: [2490/4518] 55% | Training loss: 0.6870453484087106
Epoch: 73 | Iteration number: [2500/4518] 55% | Training loss: 0.6870448552131653
Epoch: 73 | Iteration number: [2510/4518] 55% | Training loss: 0.6870430781546817
Epoch: 73 | Iteration number: [2520/4518] 55% | Training loss: 0.6870448737390458
Epoch: 73 | Iteration number: [2530/4518] 55% | Training loss: 0.6870466506528289
Epoch: 73 | Iteration number: [2540/4518] 56% | Training loss: 0.687043790132042
Epoch: 73 | Iteration number: [2550/4518] 56% | Training loss: 0.6870452601535647
Epoch: 73 | Iteration number: [2560/4518] 56% | Training loss: 0.6870506613515317
Epoch: 73 | Iteration number: [2570/4518] 56% | Training loss: 0.6870468466662247
Epoch: 73 | Iteration number: [2580/4518] 57% | Training loss: 0.6870473129111667
Epoch: 73 | Iteration number: [2590/4518] 57% | Training loss: 0.6870487569611965
Epoch: 73 | Iteration number: [2600/4518] 57% | Training loss: 0.6870479321709047
Epoch: 73 | Iteration number: [2610/4518] 57% | Training loss: 0.6870473464558408
Epoch: 73 | Iteration number: [2620/4518] 57% | Training loss: 0.6870468868554094
Epoch: 73 | Iteration number: [2630/4518] 58% | Training loss: 0.687045243915043
Epoch: 73 | Iteration number: [2640/4518] 58% | Training loss: 0.6870425586899122
Epoch: 73 | Iteration number: [2650/4518] 58% | Training loss: 0.6870443248298933
Epoch: 73 | Iteration number: [2660/4518] 58% | Training loss: 0.687048540550067
Epoch: 73 | Iteration number: [2670/4518] 59% | Training loss: 0.6870507245206654
Epoch: 73 | Iteration number: [2680/4518] 59% | Training loss: 0.6870467830949755
Epoch: 73 | Iteration number: [2690/4518] 59% | Training loss: 0.6870436041328544
Epoch: 73 | Iteration number: [2700/4518] 59% | Training loss: 0.6870436014952483
Epoch: 73 | Iteration number: [2710/4518] 59% | Training loss: 0.6870414560351424
Epoch: 73 | Iteration number: [2720/4518] 60% | Training loss: 0.687038852975649
Epoch: 73 | Iteration number: [2730/4518] 60% | Training loss: 0.6870369208383036
Epoch: 73 | Iteration number: [2740/4518] 60% | Training loss: 0.6870304257330233
Epoch: 73 | Iteration number: [2750/4518] 60% | Training loss: 0.6870283794186332
Epoch: 73 | Iteration number: [2760/4518] 61% | Training loss: 0.6870280214193939
Epoch: 73 | Iteration number: [2770/4518] 61% | Training loss: 0.6870306957499646
Epoch: 73 | Iteration number: [2780/4518] 61% | Training loss: 0.6870323900696185
Epoch: 73 | Iteration number: [2790/4518] 61% | Training loss: 0.6870305906487195
Epoch: 73 | Iteration number: [2800/4518] 61% | Training loss: 0.6870313066669873
Epoch: 73 | Iteration number: [2810/4518] 62% | Training loss: 0.6870268103278828
Epoch: 73 | Iteration number: [2820/4518] 62% | Training loss: 0.6870250980693398
Epoch: 73 | Iteration number: [2830/4518] 62% | Training loss: 0.6870246370352621
Epoch: 73 | Iteration number: [2840/4518] 62% | Training loss: 0.6870261955219256
Epoch: 73 | Iteration number: [2850/4518] 63% | Training loss: 0.687020593212362
Epoch: 73 | Iteration number: [2860/4518] 63% | Training loss: 0.6870223481338341
Epoch: 73 | Iteration number: [2870/4518] 63% | Training loss: 0.687020343666708
Epoch: 73 | Iteration number: [2880/4518] 63% | Training loss: 0.687019629486733
Epoch: 73 | Iteration number: [2890/4518] 63% | Training loss: 0.6870206860522498
Epoch: 73 | Iteration number: [2900/4518] 64% | Training loss: 0.6870196130563473
Epoch: 73 | Iteration number: [2910/4518] 64% | Training loss: 0.6870257367997644
Epoch: 73 | Iteration number: [2920/4518] 64% | Training loss: 0.6870254862186027
Epoch: 73 | Iteration number: [2930/4518] 64% | Training loss: 0.6870253537905501
Epoch: 73 | Iteration number: [2940/4518] 65% | Training loss: 0.6870201385142852
Epoch: 73 | Iteration number: [2950/4518] 65% | Training loss: 0.6870219499175831
Epoch: 73 | Iteration number: [2960/4518] 65% | Training loss: 0.6870276773700843
Epoch: 73 | Iteration number: [2970/4518] 65% | Training loss: 0.6870264727860589
Epoch: 73 | Iteration number: [2980/4518] 65% | Training loss: 0.6870264041143775
Epoch: 73 | Iteration number: [2990/4518] 66% | Training loss: 0.6870240340862784
Epoch: 73 | Iteration number: [3000/4518] 66% | Training loss: 0.6870237397352854
Epoch: 73 | Iteration number: [3010/4518] 66% | Training loss: 0.6870184898178443
Epoch: 73 | Iteration number: [3020/4518] 66% | Training loss: 0.6870160359025791
Epoch: 73 | Iteration number: [3030/4518] 67% | Training loss: 0.6870171891187283
Epoch: 73 | Iteration number: [3040/4518] 67% | Training loss: 0.6870171579875444
Epoch: 73 | Iteration number: [3050/4518] 67% | Training loss: 0.6870174337605961
Epoch: 73 | Iteration number: [3060/4518] 67% | Training loss: 0.6870192901371351
Epoch: 73 | Iteration number: [3070/4518] 67% | Training loss: 0.6870219428104376
Epoch: 73 | Iteration number: [3080/4518] 68% | Training loss: 0.6870212790834439
Epoch: 73 | Iteration number: [3090/4518] 68% | Training loss: 0.6870207785595582
Epoch: 73 | Iteration number: [3100/4518] 68% | Training loss: 0.6870178533561768
Epoch: 73 | Iteration number: [3110/4518] 68% | Training loss: 0.6870166239822793
Epoch: 73 | Iteration number: [3120/4518] 69% | Training loss: 0.687017842191152
Epoch: 73 | Iteration number: [3130/4518] 69% | Training loss: 0.6870182382793854
Epoch: 73 | Iteration number: [3140/4518] 69% | Training loss: 0.6870159695862205
Epoch: 73 | Iteration number: [3150/4518] 69% | Training loss: 0.6870144154911949
Epoch: 73 | Iteration number: [3160/4518] 69% | Training loss: 0.6870108610089821
Epoch: 73 | Iteration number: [3170/4518] 70% | Training loss: 0.6870114469377776
Epoch: 73 | Iteration number: [3180/4518] 70% | Training loss: 0.6870086418570213
Epoch: 73 | Iteration number: [3190/4518] 70% | Training loss: 0.6870100316582802
Epoch: 73 | Iteration number: [3200/4518] 70% | Training loss: 0.6870086998865008
Epoch: 73 | Iteration number: [3210/4518] 71% | Training loss: 0.6870050755059608
Epoch: 73 | Iteration number: [3220/4518] 71% | Training loss: 0.6870032517991451
Epoch: 73 | Iteration number: [3230/4518] 71% | Training loss: 0.6870017682251177
Epoch: 73 | Iteration number: [3240/4518] 71% | Training loss: 0.6870066931770171
Epoch: 73 | Iteration number: [3250/4518] 71% | Training loss: 0.6870051112174987
Epoch: 73 | Iteration number: [3260/4518] 72% | Training loss: 0.6870060244038061
Epoch: 73 | Iteration number: [3270/4518] 72% | Training loss: 0.6870018334745996
Epoch: 73 | Iteration number: [3280/4518] 72% | Training loss: 0.6870003048057963
Epoch: 73 | Iteration number: [3290/4518] 72% | Training loss: 0.6869962668889924
Epoch: 73 | Iteration number: [3300/4518] 73% | Training loss: 0.6869933237270875
Epoch: 73 | Iteration number: [3310/4518] 73% | Training loss: 0.6869926633251398
Epoch: 73 | Iteration number: [3320/4518] 73% | Training loss: 0.6869925696627204
Epoch: 73 | Iteration number: [3330/4518] 73% | Training loss: 0.6869954341345721
Epoch: 73 | Iteration number: [3340/4518] 73% | Training loss: 0.6869981295334365
Epoch: 73 | Iteration number: [3350/4518] 74% | Training loss: 0.6869955312671946
Epoch: 73 | Iteration number: [3360/4518] 74% | Training loss: 0.6869947717125927
Epoch: 73 | Iteration number: [3370/4518] 74% | Training loss: 0.6869943208086031
Epoch: 73 | Iteration number: [3380/4518] 74% | Training loss: 0.6869966594425179
Epoch: 73 | Iteration number: [3390/4518] 75% | Training loss: 0.6869962267643582
Epoch: 73 | Iteration number: [3400/4518] 75% | Training loss: 0.6869958580416792
Epoch: 73 | Iteration number: [3410/4518] 75% | Training loss: 0.6869947264096604
Epoch: 73 | Iteration number: [3420/4518] 75% | Training loss: 0.6869902086885352
Epoch: 73 | Iteration number: [3430/4518] 75% | Training loss: 0.6869921500411743
Epoch: 73 | Iteration number: [3440/4518] 76% | Training loss: 0.6869927753369476
Epoch: 73 | Iteration number: [3450/4518] 76% | Training loss: 0.6869916116500246
Epoch: 73 | Iteration number: [3460/4518] 76% | Training loss: 0.6869898744918018
Epoch: 73 | Iteration number: [3470/4518] 76% | Training loss: 0.6869923885858025
Epoch: 73 | Iteration number: [3480/4518] 77% | Training loss: 0.6869919835493482
Epoch: 73 | Iteration number: [3490/4518] 77% | Training loss: 0.6869886648859882
Epoch: 73 | Iteration number: [3500/4518] 77% | Training loss: 0.6869872764859881
Epoch: 73 | Iteration number: [3510/4518] 77% | Training loss: 0.6869827505190488
Epoch: 73 | Iteration number: [3520/4518] 77% | Training loss: 0.6869829493320802
Epoch: 73 | Iteration number: [3530/4518] 78% | Training loss: 0.6869824430084769
Epoch: 73 | Iteration number: [3540/4518] 78% | Training loss: 0.6869833159581417
Epoch: 73 | Iteration number: [3550/4518] 78% | Training loss: 0.6869800163154871
Epoch: 73 | Iteration number: [3560/4518] 78% | Training loss: 0.6869778218731452
Epoch: 73 | Iteration number: [3570/4518] 79% | Training loss: 0.6869798977835839
Epoch: 73 | Iteration number: [3580/4518] 79% | Training loss: 0.68698237961231
Epoch: 73 | Iteration number: [3590/4518] 79% | Training loss: 0.6869805450558994
Epoch: 73 | Iteration number: [3600/4518] 79% | Training loss: 0.6869798412753476
Epoch: 73 | Iteration number: [3610/4518] 79% | Training loss: 0.6869791189058996
Epoch: 73 | Iteration number: [3620/4518] 80% | Training loss: 0.686979161952082
Epoch: 73 | Iteration number: [3630/4518] 80% | Training loss: 0.6869760050097116
Epoch: 73 | Iteration number: [3640/4518] 80% | Training loss: 0.6869775356008456
Epoch: 73 | Iteration number: [3650/4518] 80% | Training loss: 0.6869796043062864
Epoch: 73 | Iteration number: [3660/4518] 81% | Training loss: 0.6869789153500333
Epoch: 73 | Iteration number: [3670/4518] 81% | Training loss: 0.6869792338450533
Epoch: 73 | Iteration number: [3680/4518] 81% | Training loss: 0.6869787812071002
Epoch: 73 | Iteration number: [3690/4518] 81% | Training loss: 0.6869777546342473
Epoch: 73 | Iteration number: [3700/4518] 81% | Training loss: 0.6869752624872568
Epoch: 73 | Iteration number: [3710/4518] 82% | Training loss: 0.686975289290806
Epoch: 73 | Iteration number: [3720/4518] 82% | Training loss: 0.6869743292850833
Epoch: 73 | Iteration number: [3730/4518] 82% | Training loss: 0.6869724496120422
Epoch: 73 | Iteration number: [3740/4518] 82% | Training loss: 0.6869748208133932
Epoch: 73 | Iteration number: [3750/4518] 83% | Training loss: 0.6869737155278524
Epoch: 73 | Iteration number: [3760/4518] 83% | Training loss: 0.6869682578964437
Epoch: 73 | Iteration number: [3770/4518] 83% | Training loss: 0.6869667539704067
Epoch: 73 | Iteration number: [3780/4518] 83% | Training loss: 0.6869646888876718
Epoch: 73 | Iteration number: [3790/4518] 83% | Training loss: 0.6869644010287161
Epoch: 73 | Iteration number: [3800/4518] 84% | Training loss: 0.6869646499031469
Epoch: 73 | Iteration number: [3810/4518] 84% | Training loss: 0.6869638007300419
Epoch: 73 | Iteration number: [3820/4518] 84% | Training loss: 0.6869625194690614
Epoch: 73 | Iteration number: [3830/4518] 84% | Training loss: 0.6869621977638015
Epoch: 73 | Iteration number: [3840/4518] 84% | Training loss: 0.6869624940368037
Epoch: 73 | Iteration number: [3850/4518] 85% | Training loss: 0.6869627784753775
Epoch: 73 | Iteration number: [3860/4518] 85% | Training loss: 0.6869663245165286
Epoch: 73 | Iteration number: [3870/4518] 85% | Training loss: 0.6869673787007344
Epoch: 73 | Iteration number: [3880/4518] 85% | Training loss: 0.6869657487445271
Epoch: 73 | Iteration number: [3890/4518] 86% | Training loss: 0.6869656611837275
Epoch: 73 | Iteration number: [3900/4518] 86% | Training loss: 0.6869653171912218
Epoch: 73 | Iteration number: [3910/4518] 86% | Training loss: 0.6869644839288024
Epoch: 73 | Iteration number: [3920/4518] 86% | Training loss: 0.6869638372896886
Epoch: 73 | Iteration number: [3930/4518] 86% | Training loss: 0.6869626595622104
Epoch: 73 | Iteration number: [3940/4518] 87% | Training loss: 0.6869625051312035
Epoch: 73 | Iteration number: [3950/4518] 87% | Training loss: 0.6869595111321799
Epoch: 73 | Iteration number: [3960/4518] 87% | Training loss: 0.6869576500220732
Epoch: 73 | Iteration number: [3970/4518] 87% | Training loss: 0.6869562630539277
Epoch: 73 | Iteration number: [3980/4518] 88% | Training loss: 0.6869562044215561
Epoch: 73 | Iteration number: [3990/4518] 88% | Training loss: 0.6869572900889213
Epoch: 73 | Iteration number: [4000/4518] 88% | Training loss: 0.6869581650346518
Epoch: 73 | Iteration number: [4010/4518] 88% | Training loss: 0.6869608231464823
Epoch: 73 | Iteration number: [4020/4518] 88% | Training loss: 0.686960452454007
Epoch: 73 | Iteration number: [4030/4518] 89% | Training loss: 0.6869580629593681
Epoch: 73 | Iteration number: [4040/4518] 89% | Training loss: 0.68695589388066
Epoch: 73 | Iteration number: [4050/4518] 89% | Training loss: 0.6869533555743135
Epoch: 73 | Iteration number: [4060/4518] 89% | Training loss: 0.686956105003216
Epoch: 73 | Iteration number: [4070/4518] 90% | Training loss: 0.686952492294499
Epoch: 73 | Iteration number: [4080/4518] 90% | Training loss: 0.6869494325243959
Epoch: 73 | Iteration number: [4090/4518] 90% | Training loss: 0.6869437153590046
Epoch: 73 | Iteration number: [4100/4518] 90% | Training loss: 0.686944054059866
Epoch: 73 | Iteration number: [4110/4518] 90% | Training loss: 0.6869462539679813
Epoch: 73 | Iteration number: [4120/4518] 91% | Training loss: 0.6869450516781761
Epoch: 73 | Iteration number: [4130/4518] 91% | Training loss: 0.686943126157756
Epoch: 73 | Iteration number: [4140/4518] 91% | Training loss: 0.6869435609682747
Epoch: 73 | Iteration number: [4150/4518] 91% | Training loss: 0.6869456448181566
Epoch: 73 | Iteration number: [4160/4518] 92% | Training loss: 0.68694750033319
Epoch: 73 | Iteration number: [4170/4518] 92% | Training loss: 0.6869480315729869
Epoch: 73 | Iteration number: [4180/4518] 92% | Training loss: 0.6869467762526142
Epoch: 73 | Iteration number: [4190/4518] 92% | Training loss: 0.6869492207478225
Epoch: 73 | Iteration number: [4200/4518] 92% | Training loss: 0.6869426626534689
Epoch: 73 | Iteration number: [4210/4518] 93% | Training loss: 0.6869421911919202
Epoch: 73 | Iteration number: [4220/4518] 93% | Training loss: 0.6869391861685079
Epoch: 73 | Iteration number: [4230/4518] 93% | Training loss: 0.6869364881064594
Epoch: 73 | Iteration number: [4240/4518] 93% | Training loss: 0.6869345477588896
Epoch: 73 | Iteration number: [4250/4518] 94% | Training loss: 0.6869348670454586
Epoch: 73 | Iteration number: [4260/4518] 94% | Training loss: 0.686934723582626
Epoch: 73 | Iteration number: [4270/4518] 94% | Training loss: 0.6869337164127296
Epoch: 73 | Iteration number: [4280/4518] 94% | Training loss: 0.6869356740579426
Epoch: 73 | Iteration number: [4290/4518] 94% | Training loss: 0.6869363846339823
Epoch: 73 | Iteration number: [4300/4518] 95% | Training loss: 0.6869382696789365
Epoch: 73 | Iteration number: [4310/4518] 95% | Training loss: 0.6869397420479361
Epoch: 73 | Iteration number: [4320/4518] 95% | Training loss: 0.6869374820617614
Epoch: 73 | Iteration number: [4330/4518] 95% | Training loss: 0.6869363694901279
Epoch: 73 | Iteration number: [4340/4518] 96% | Training loss: 0.6869378304426571
Epoch: 73 | Iteration number: [4350/4518] 96% | Training loss: 0.6869370049306716
Epoch: 73 | Iteration number: [4360/4518] 96% | Training loss: 0.6869353219593337
Epoch: 73 | Iteration number: [4370/4518] 96% | Training loss: 0.6869341162576829
Epoch: 73 | Iteration number: [4380/4518] 96% | Training loss: 0.6869344106139658
Epoch: 73 | Iteration number: [4390/4518] 97% | Training loss: 0.6869309970756869
Epoch: 73 | Iteration number: [4400/4518] 97% | Training loss: 0.6869344111328776
Epoch: 73 | Iteration number: [4410/4518] 97% | Training loss: 0.6869322125198078
Epoch: 73 | Iteration number: [4420/4518] 97% | Training loss: 0.6869305862290827
Epoch: 73 | Iteration number: [4430/4518] 98% | Training loss: 0.6869303931635605
Epoch: 73 | Iteration number: [4440/4518] 98% | Training loss: 0.6869294972570092
Epoch: 73 | Iteration number: [4450/4518] 98% | Training loss: 0.6869276884298646
Epoch: 73 | Iteration number: [4460/4518] 98% | Training loss: 0.6869282331701886
Epoch: 73 | Iteration number: [4470/4518] 98% | Training loss: 0.6869272542479854
Epoch: 73 | Iteration number: [4480/4518] 99% | Training loss: 0.686928091331252
Epoch: 73 | Iteration number: [4490/4518] 99% | Training loss: 0.6869288813165142
Epoch: 73 | Iteration number: [4500/4518] 99% | Training loss: 0.6869265828794904
Epoch: 73 | Iteration number: [4510/4518] 99% | Training loss: 0.6869271586845297

 End of epoch: 73 | Train Loss: 0.6867739280381525 | Training Time: 641 

 End of epoch: 73 | Eval Loss: 0.6898256515970036 | Evaluating Time: 17 
Epoch: 74 | Iteration number: [10/4518] 0% | Training loss: 0.7555711507797241
Epoch: 74 | Iteration number: [20/4518] 0% | Training loss: 0.7214598834514618
Epoch: 74 | Iteration number: [30/4518] 0% | Training loss: 0.7102816502253214
Epoch: 74 | Iteration number: [40/4518] 0% | Training loss: 0.7044756457209587
Epoch: 74 | Iteration number: [50/4518] 1% | Training loss: 0.7010872220993042
Epoch: 74 | Iteration number: [60/4518] 1% | Training loss: 0.6988197296857834
Epoch: 74 | Iteration number: [70/4518] 1% | Training loss: 0.6970801080976213
Epoch: 74 | Iteration number: [80/4518] 1% | Training loss: 0.6957756884396076
Epoch: 74 | Iteration number: [90/4518] 1% | Training loss: 0.6946700705422295
Epoch: 74 | Iteration number: [100/4518] 2% | Training loss: 0.6938932341337204
Epoch: 74 | Iteration number: [110/4518] 2% | Training loss: 0.6930906897241419
Epoch: 74 | Iteration number: [120/4518] 2% | Training loss: 0.6925205116470655
Epoch: 74 | Iteration number: [130/4518] 2% | Training loss: 0.6921232196000906
Epoch: 74 | Iteration number: [140/4518] 3% | Training loss: 0.691740643126624
Epoch: 74 | Iteration number: [150/4518] 3% | Training loss: 0.6914711713790893
Epoch: 74 | Iteration number: [160/4518] 3% | Training loss: 0.6911568935960531
Epoch: 74 | Iteration number: [170/4518] 3% | Training loss: 0.6909602813860949
Epoch: 74 | Iteration number: [180/4518] 3% | Training loss: 0.6907768315739102
Epoch: 74 | Iteration number: [190/4518] 4% | Training loss: 0.6905814057902286
Epoch: 74 | Iteration number: [200/4518] 4% | Training loss: 0.6904083466529847
Epoch: 74 | Iteration number: [210/4518] 4% | Training loss: 0.6902035321508135
Epoch: 74 | Iteration number: [220/4518] 4% | Training loss: 0.6900407368486577
Epoch: 74 | Iteration number: [230/4518] 5% | Training loss: 0.689947247505188
Epoch: 74 | Iteration number: [240/4518] 5% | Training loss: 0.6898617322246233
Epoch: 74 | Iteration number: [250/4518] 5% | Training loss: 0.6896905887126923
Epoch: 74 | Iteration number: [260/4518] 5% | Training loss: 0.6895620777056768
Epoch: 74 | Iteration number: [270/4518] 5% | Training loss: 0.6894864713704144
Epoch: 74 | Iteration number: [280/4518] 6% | Training loss: 0.6893740877509117
Epoch: 74 | Iteration number: [290/4518] 6% | Training loss: 0.6892792019350775
Epoch: 74 | Iteration number: [300/4518] 6% | Training loss: 0.6891648594538371
Epoch: 74 | Iteration number: [310/4518] 6% | Training loss: 0.6891149603551434
Epoch: 74 | Iteration number: [320/4518] 7% | Training loss: 0.6890483278781175
Epoch: 74 | Iteration number: [330/4518] 7% | Training loss: 0.6890060224316337
Epoch: 74 | Iteration number: [340/4518] 7% | Training loss: 0.6889597777058096
Epoch: 74 | Iteration number: [350/4518] 7% | Training loss: 0.6889227354526519
Epoch: 74 | Iteration number: [360/4518] 7% | Training loss: 0.6888720023963186
Epoch: 74 | Iteration number: [370/4518] 8% | Training loss: 0.6888271663639997
Epoch: 74 | Iteration number: [380/4518] 8% | Training loss: 0.6887404645744123
Epoch: 74 | Iteration number: [390/4518] 8% | Training loss: 0.688682492574056
Epoch: 74 | Iteration number: [400/4518] 8% | Training loss: 0.6886269119381905
Epoch: 74 | Iteration number: [410/4518] 9% | Training loss: 0.6885762143425825
Epoch: 74 | Iteration number: [420/4518] 9% | Training loss: 0.6885271002848943
Epoch: 74 | Iteration number: [430/4518] 9% | Training loss: 0.6884864514650301
Epoch: 74 | Iteration number: [440/4518] 9% | Training loss: 0.6884314648129723
Epoch: 74 | Iteration number: [450/4518] 9% | Training loss: 0.6883804849783579
Epoch: 74 | Iteration number: [460/4518] 10% | Training loss: 0.6883380299029143
Epoch: 74 | Iteration number: [470/4518] 10% | Training loss: 0.6883283126861491
Epoch: 74 | Iteration number: [480/4518] 10% | Training loss: 0.6883069800833861
Epoch: 74 | Iteration number: [490/4518] 10% | Training loss: 0.6882677810532706
Epoch: 74 | Iteration number: [500/4518] 11% | Training loss: 0.6882218996286392
Epoch: 74 | Iteration number: [510/4518] 11% | Training loss: 0.6882053142669154
Epoch: 74 | Iteration number: [520/4518] 11% | Training loss: 0.6881665602326393
Epoch: 74 | Iteration number: [530/4518] 11% | Training loss: 0.6881574058307791
Epoch: 74 | Iteration number: [540/4518] 11% | Training loss: 0.6881402917482234
Epoch: 74 | Iteration number: [550/4518] 12% | Training loss: 0.6880841002681038
Epoch: 74 | Iteration number: [560/4518] 12% | Training loss: 0.6880600978221212
Epoch: 74 | Iteration number: [570/4518] 12% | Training loss: 0.6880404311313963
Epoch: 74 | Iteration number: [580/4518] 12% | Training loss: 0.6880189252310785
Epoch: 74 | Iteration number: [590/4518] 13% | Training loss: 0.6880108064514096
Epoch: 74 | Iteration number: [600/4518] 13% | Training loss: 0.6879970287283261
Epoch: 74 | Iteration number: [610/4518] 13% | Training loss: 0.6879818775614754
Epoch: 74 | Iteration number: [620/4518] 13% | Training loss: 0.6879504363383017
Epoch: 74 | Iteration number: [630/4518] 13% | Training loss: 0.6879230254226261
Epoch: 74 | Iteration number: [640/4518] 14% | Training loss: 0.6879198721610009
Epoch: 74 | Iteration number: [650/4518] 14% | Training loss: 0.6879030714585231
Epoch: 74 | Iteration number: [660/4518] 14% | Training loss: 0.6878948130390861
Epoch: 74 | Iteration number: [670/4518] 14% | Training loss: 0.6879036175670908
Epoch: 74 | Iteration number: [680/4518] 15% | Training loss: 0.6878943699247697
Epoch: 74 | Iteration number: [690/4518] 15% | Training loss: 0.6878769439199697
Epoch: 74 | Iteration number: [700/4518] 15% | Training loss: 0.6878441212006977
Epoch: 74 | Iteration number: [710/4518] 15% | Training loss: 0.6878166074484167
Epoch: 74 | Iteration number: [720/4518] 15% | Training loss: 0.6878217360211744
Epoch: 74 | Iteration number: [730/4518] 16% | Training loss: 0.6878169392886228
Epoch: 74 | Iteration number: [740/4518] 16% | Training loss: 0.6878071483728048
Epoch: 74 | Iteration number: [750/4518] 16% | Training loss: 0.6877917994658153
Epoch: 74 | Iteration number: [760/4518] 16% | Training loss: 0.687775556272582
Epoch: 74 | Iteration number: [770/4518] 17% | Training loss: 0.6877558592077974
Epoch: 74 | Iteration number: [780/4518] 17% | Training loss: 0.6877536349571668
Epoch: 74 | Iteration number: [790/4518] 17% | Training loss: 0.6877522405944293
Epoch: 74 | Iteration number: [800/4518] 17% | Training loss: 0.6877277687191963
Epoch: 74 | Iteration number: [810/4518] 17% | Training loss: 0.687729658830313
Epoch: 74 | Iteration number: [820/4518] 18% | Training loss: 0.687718231576245
Epoch: 74 | Iteration number: [830/4518] 18% | Training loss: 0.6877131747194083
Epoch: 74 | Iteration number: [840/4518] 18% | Training loss: 0.6876877683259192
Epoch: 74 | Iteration number: [850/4518] 18% | Training loss: 0.6876773349677815
Epoch: 74 | Iteration number: [860/4518] 19% | Training loss: 0.6876611149588296
Epoch: 74 | Iteration number: [870/4518] 19% | Training loss: 0.6876353369362053
Epoch: 74 | Iteration number: [880/4518] 19% | Training loss: 0.6876327212561261
Epoch: 74 | Iteration number: [890/4518] 19% | Training loss: 0.6876418068837584
Epoch: 74 | Iteration number: [900/4518] 19% | Training loss: 0.6876336979203754
Epoch: 74 | Iteration number: [910/4518] 20% | Training loss: 0.6876289032972775
Epoch: 74 | Iteration number: [920/4518] 20% | Training loss: 0.6876169563635536
Epoch: 74 | Iteration number: [930/4518] 20% | Training loss: 0.6876109863481213
Epoch: 74 | Iteration number: [940/4518] 20% | Training loss: 0.6876063549772222
Epoch: 74 | Iteration number: [950/4518] 21% | Training loss: 0.6875905767240023
Epoch: 74 | Iteration number: [960/4518] 21% | Training loss: 0.6875745446731647
Epoch: 74 | Iteration number: [970/4518] 21% | Training loss: 0.6875585951141475
Epoch: 74 | Iteration number: [980/4518] 21% | Training loss: 0.687551234388838
Epoch: 74 | Iteration number: [990/4518] 21% | Training loss: 0.6875481544721006
Epoch: 74 | Iteration number: [1000/4518] 22% | Training loss: 0.6875265167951584
Epoch: 74 | Iteration number: [1010/4518] 22% | Training loss: 0.6875223727509527
Epoch: 74 | Iteration number: [1020/4518] 22% | Training loss: 0.6875117085727991
Epoch: 74 | Iteration number: [1030/4518] 22% | Training loss: 0.6875123748501528
Epoch: 74 | Iteration number: [1040/4518] 23% | Training loss: 0.6875056510361341
Epoch: 74 | Iteration number: [1050/4518] 23% | Training loss: 0.6874952561514718
Epoch: 74 | Iteration number: [1060/4518] 23% | Training loss: 0.6874906127182943
Epoch: 74 | Iteration number: [1070/4518] 23% | Training loss: 0.6874864478534627
Epoch: 74 | Iteration number: [1080/4518] 23% | Training loss: 0.6874760814287044
Epoch: 74 | Iteration number: [1090/4518] 24% | Training loss: 0.6874605868934491
Epoch: 74 | Iteration number: [1100/4518] 24% | Training loss: 0.6874558134512467
Epoch: 74 | Iteration number: [1110/4518] 24% | Training loss: 0.6874582016253257
Epoch: 74 | Iteration number: [1120/4518] 24% | Training loss: 0.6874717067927122
Epoch: 74 | Iteration number: [1130/4518] 25% | Training loss: 0.6874636051401628
Epoch: 74 | Iteration number: [1140/4518] 25% | Training loss: 0.6874578926124071
Epoch: 74 | Iteration number: [1150/4518] 25% | Training loss: 0.6874558034668798
Epoch: 74 | Iteration number: [1160/4518] 25% | Training loss: 0.6874485882191822
Epoch: 74 | Iteration number: [1170/4518] 25% | Training loss: 0.6874479423730802
Epoch: 74 | Iteration number: [1180/4518] 26% | Training loss: 0.6874513610439785
Epoch: 74 | Iteration number: [1190/4518] 26% | Training loss: 0.6874410491029755
Epoch: 74 | Iteration number: [1200/4518] 26% | Training loss: 0.6874327407280604
Epoch: 74 | Iteration number: [1210/4518] 26% | Training loss: 0.6874156308075613
Epoch: 74 | Iteration number: [1220/4518] 27% | Training loss: 0.6874115984459392
Epoch: 74 | Iteration number: [1230/4518] 27% | Training loss: 0.6874024939246294
Epoch: 74 | Iteration number: [1240/4518] 27% | Training loss: 0.6873985962521645
Epoch: 74 | Iteration number: [1250/4518] 27% | Training loss: 0.6873926368236541
Epoch: 74 | Iteration number: [1260/4518] 27% | Training loss: 0.6873940208128521
Epoch: 74 | Iteration number: [1270/4518] 28% | Training loss: 0.6873857506147519
Epoch: 74 | Iteration number: [1280/4518] 28% | Training loss: 0.6873957883566618
Epoch: 74 | Iteration number: [1290/4518] 28% | Training loss: 0.6873950124711029
Epoch: 74 | Iteration number: [1300/4518] 28% | Training loss: 0.6873867506247301
Epoch: 74 | Iteration number: [1310/4518] 28% | Training loss: 0.6873854707215579
Epoch: 74 | Iteration number: [1320/4518] 29% | Training loss: 0.68737913446896
Epoch: 74 | Iteration number: [1330/4518] 29% | Training loss: 0.6873818943375035
Epoch: 74 | Iteration number: [1340/4518] 29% | Training loss: 0.687377049095595
Epoch: 74 | Iteration number: [1350/4518] 29% | Training loss: 0.687366960755101
Epoch: 74 | Iteration number: [1360/4518] 30% | Training loss: 0.6873615339836654
Epoch: 74 | Iteration number: [1370/4518] 30% | Training loss: 0.6873463504940924
Epoch: 74 | Iteration number: [1380/4518] 30% | Training loss: 0.687346444743267
Epoch: 74 | Iteration number: [1390/4518] 30% | Training loss: 0.6873408436346398
Epoch: 74 | Iteration number: [1400/4518] 30% | Training loss: 0.6873345269901412
Epoch: 74 | Iteration number: [1410/4518] 31% | Training loss: 0.6873239483816403
Epoch: 74 | Iteration number: [1420/4518] 31% | Training loss: 0.6873267661098024
Epoch: 74 | Iteration number: [1430/4518] 31% | Training loss: 0.6873160889932326
Epoch: 74 | Iteration number: [1440/4518] 31% | Training loss: 0.6873095757017533
Epoch: 74 | Iteration number: [1450/4518] 32% | Training loss: 0.6873102673579906
Epoch: 74 | Iteration number: [1460/4518] 32% | Training loss: 0.6872911020092768
Epoch: 74 | Iteration number: [1470/4518] 32% | Training loss: 0.6872879302420584
Epoch: 74 | Iteration number: [1480/4518] 32% | Training loss: 0.6872849309766614
Epoch: 74 | Iteration number: [1490/4518] 32% | Training loss: 0.6872906571666666
Epoch: 74 | Iteration number: [1500/4518] 33% | Training loss: 0.6872915658950806
Epoch: 74 | Iteration number: [1510/4518] 33% | Training loss: 0.687287551717253
Epoch: 74 | Iteration number: [1520/4518] 33% | Training loss: 0.6872797796600744
Epoch: 74 | Iteration number: [1530/4518] 33% | Training loss: 0.68727469155991
Epoch: 74 | Iteration number: [1540/4518] 34% | Training loss: 0.6872704426963608
Epoch: 74 | Iteration number: [1550/4518] 34% | Training loss: 0.6872618570250849
Epoch: 74 | Iteration number: [1560/4518] 34% | Training loss: 0.6872496931216656
Epoch: 74 | Iteration number: [1570/4518] 34% | Training loss: 0.6872436528372916
Epoch: 74 | Iteration number: [1580/4518] 34% | Training loss: 0.687247465758384
Epoch: 74 | Iteration number: [1590/4518] 35% | Training loss: 0.6872463716276037
Epoch: 74 | Iteration number: [1600/4518] 35% | Training loss: 0.6872413484379649
Epoch: 74 | Iteration number: [1610/4518] 35% | Training loss: 0.6872349492511394
Epoch: 74 | Iteration number: [1620/4518] 35% | Training loss: 0.687226743241887
Epoch: 74 | Iteration number: [1630/4518] 36% | Training loss: 0.6872216247707789
Epoch: 74 | Iteration number: [1640/4518] 36% | Training loss: 0.6872245131105912
Epoch: 74 | Iteration number: [1650/4518] 36% | Training loss: 0.6872232496377193
Epoch: 74 | Iteration number: [1660/4518] 36% | Training loss: 0.6872196699122348
Epoch: 74 | Iteration number: [1670/4518] 36% | Training loss: 0.687217083055816
Epoch: 74 | Iteration number: [1680/4518] 37% | Training loss: 0.6872159891185307
Epoch: 74 | Iteration number: [1690/4518] 37% | Training loss: 0.687212214279457
Epoch: 74 | Iteration number: [1700/4518] 37% | Training loss: 0.6872081322880352
Epoch: 74 | Iteration number: [1710/4518] 37% | Training loss: 0.6872091283226571
Epoch: 74 | Iteration number: [1720/4518] 38% | Training loss: 0.6872028222957323
Epoch: 74 | Iteration number: [1730/4518] 38% | Training loss: 0.6872055057845363
Epoch: 74 | Iteration number: [1740/4518] 38% | Training loss: 0.6872037168206839
Epoch: 74 | Iteration number: [1750/4518] 38% | Training loss: 0.6872043792179653
Epoch: 74 | Iteration number: [1760/4518] 38% | Training loss: 0.6872035052965988
Epoch: 74 | Iteration number: [1770/4518] 39% | Training loss: 0.6871980338446838
Epoch: 74 | Iteration number: [1780/4518] 39% | Training loss: 0.6871996997112638
Epoch: 74 | Iteration number: [1790/4518] 39% | Training loss: 0.6871981856876246
Epoch: 74 | Iteration number: [1800/4518] 39% | Training loss: 0.6871992915868759
Epoch: 74 | Iteration number: [1810/4518] 40% | Training loss: 0.6871954540192093
Epoch: 74 | Iteration number: [1820/4518] 40% | Training loss: 0.6871938351746444
Epoch: 74 | Iteration number: [1830/4518] 40% | Training loss: 0.6871916947469033
Epoch: 74 | Iteration number: [1840/4518] 40% | Training loss: 0.6871875744798909
Epoch: 74 | Iteration number: [1850/4518] 40% | Training loss: 0.6871897637521899
Epoch: 74 | Iteration number: [1860/4518] 41% | Training loss: 0.6871865637840763
Epoch: 74 | Iteration number: [1870/4518] 41% | Training loss: 0.6871800539965298
Epoch: 74 | Iteration number: [1880/4518] 41% | Training loss: 0.687182341674541
Epoch: 74 | Iteration number: [1890/4518] 41% | Training loss: 0.6871797957432964
Epoch: 74 | Iteration number: [1900/4518] 42% | Training loss: 0.6871806193652906
Epoch: 74 | Iteration number: [1910/4518] 42% | Training loss: 0.6871782340928522
Epoch: 74 | Iteration number: [1920/4518] 42% | Training loss: 0.6871760271179179
Epoch: 74 | Iteration number: [1930/4518] 42% | Training loss: 0.6871802929769526
Epoch: 74 | Iteration number: [1940/4518] 42% | Training loss: 0.6871808422287715
Epoch: 74 | Iteration number: [1950/4518] 43% | Training loss: 0.6871773290634156
Epoch: 74 | Iteration number: [1960/4518] 43% | Training loss: 0.6871781472040682
Epoch: 74 | Iteration number: [1970/4518] 43% | Training loss: 0.6871788642430668
Epoch: 74 | Iteration number: [1980/4518] 43% | Training loss: 0.6871827913354142
Epoch: 74 | Iteration number: [1990/4518] 44% | Training loss: 0.6871691181132542
Epoch: 74 | Iteration number: [2000/4518] 44% | Training loss: 0.6871684734225273
Epoch: 74 | Iteration number: [2010/4518] 44% | Training loss: 0.6871659022065537
Epoch: 74 | Iteration number: [2020/4518] 44% | Training loss: 0.6871663116877622
Epoch: 74 | Iteration number: [2030/4518] 44% | Training loss: 0.6871622338670815
Epoch: 74 | Iteration number: [2040/4518] 45% | Training loss: 0.6871553147832553
Epoch: 74 | Iteration number: [2050/4518] 45% | Training loss: 0.6871525254772931
Epoch: 74 | Iteration number: [2060/4518] 45% | Training loss: 0.6871452209150907
Epoch: 74 | Iteration number: [2070/4518] 45% | Training loss: 0.6871511429116346
Epoch: 74 | Iteration number: [2080/4518] 46% | Training loss: 0.687146782846405
Epoch: 74 | Iteration number: [2090/4518] 46% | Training loss: 0.6871450938961723
Epoch: 74 | Iteration number: [2100/4518] 46% | Training loss: 0.6871374775966008
Epoch: 74 | Iteration number: [2110/4518] 46% | Training loss: 0.6871339544583271
Epoch: 74 | Iteration number: [2120/4518] 46% | Training loss: 0.6871351975033868
Epoch: 74 | Iteration number: [2130/4518] 47% | Training loss: 0.6871253556208992
Epoch: 74 | Iteration number: [2140/4518] 47% | Training loss: 0.6871221295584028
Epoch: 74 | Iteration number: [2150/4518] 47% | Training loss: 0.6871168352836786
Epoch: 74 | Iteration number: [2160/4518] 47% | Training loss: 0.6871136089166006
Epoch: 74 | Iteration number: [2170/4518] 48% | Training loss: 0.6871102375643594
Epoch: 74 | Iteration number: [2180/4518] 48% | Training loss: 0.6871157752537946
Epoch: 74 | Iteration number: [2190/4518] 48% | Training loss: 0.6871197257139912
Epoch: 74 | Iteration number: [2200/4518] 48% | Training loss: 0.6871150370077653
Epoch: 74 | Iteration number: [2210/4518] 48% | Training loss: 0.6871067810382239
Epoch: 74 | Iteration number: [2220/4518] 49% | Training loss: 0.6871022414516759
Epoch: 74 | Iteration number: [2230/4518] 49% | Training loss: 0.6871020160715676
Epoch: 74 | Iteration number: [2240/4518] 49% | Training loss: 0.6870975320360491
Epoch: 74 | Iteration number: [2250/4518] 49% | Training loss: 0.6870935031308069
Epoch: 74 | Iteration number: [2260/4518] 50% | Training loss: 0.6870869399172015
Epoch: 74 | Iteration number: [2270/4518] 50% | Training loss: 0.6870874087190838
Epoch: 74 | Iteration number: [2280/4518] 50% | Training loss: 0.6870904095340193
Epoch: 74 | Iteration number: [2290/4518] 50% | Training loss: 0.6870874371330811
Epoch: 74 | Iteration number: [2300/4518] 50% | Training loss: 0.6870860187385394
Epoch: 74 | Iteration number: [2310/4518] 51% | Training loss: 0.6870827937280977
Epoch: 74 | Iteration number: [2320/4518] 51% | Training loss: 0.6870756798006338
Epoch: 74 | Iteration number: [2330/4518] 51% | Training loss: 0.6870754363454974
Epoch: 74 | Iteration number: [2340/4518] 51% | Training loss: 0.6870776655582281
Epoch: 74 | Iteration number: [2350/4518] 52% | Training loss: 0.687073516693521
Epoch: 74 | Iteration number: [2360/4518] 52% | Training loss: 0.6870674166133848
Epoch: 74 | Iteration number: [2370/4518] 52% | Training loss: 0.6870624871696601
Epoch: 74 | Iteration number: [2380/4518] 52% | Training loss: 0.6870595494238269
Epoch: 74 | Iteration number: [2390/4518] 52% | Training loss: 0.6870591382601271
Epoch: 74 | Iteration number: [2400/4518] 53% | Training loss: 0.6870553898314635
Epoch: 74 | Iteration number: [2410/4518] 53% | Training loss: 0.6870522731319997
Epoch: 74 | Iteration number: [2420/4518] 53% | Training loss: 0.6870528257582799
Epoch: 74 | Iteration number: [2430/4518] 53% | Training loss: 0.6870533779079532
Epoch: 74 | Iteration number: [2440/4518] 54% | Training loss: 0.6870514972532382
Epoch: 74 | Iteration number: [2450/4518] 54% | Training loss: 0.6870541905870243
Epoch: 74 | Iteration number: [2460/4518] 54% | Training loss: 0.6870542334347236
Epoch: 74 | Iteration number: [2470/4518] 54% | Training loss: 0.6870452654023885
Epoch: 74 | Iteration number: [2480/4518] 54% | Training loss: 0.6870488429021451
Epoch: 74 | Iteration number: [2490/4518] 55% | Training loss: 0.6870438169523415
Epoch: 74 | Iteration number: [2500/4518] 55% | Training loss: 0.6870427201509476
Epoch: 74 | Iteration number: [2510/4518] 55% | Training loss: 0.6870406492297868
Epoch: 74 | Iteration number: [2520/4518] 55% | Training loss: 0.6870337264405356
Epoch: 74 | Iteration number: [2530/4518] 55% | Training loss: 0.6870348529853368
Epoch: 74 | Iteration number: [2540/4518] 56% | Training loss: 0.6870301793879411
Epoch: 74 | Iteration number: [2550/4518] 56% | Training loss: 0.6870319217326595
Epoch: 74 | Iteration number: [2560/4518] 56% | Training loss: 0.6870367340045049
Epoch: 74 | Iteration number: [2570/4518] 56% | Training loss: 0.6870319336072944
Epoch: 74 | Iteration number: [2580/4518] 57% | Training loss: 0.6870332869448403
Epoch: 74 | Iteration number: [2590/4518] 57% | Training loss: 0.6870392143496216
Epoch: 74 | Iteration number: [2600/4518] 57% | Training loss: 0.687035991526567
Epoch: 74 | Iteration number: [2610/4518] 57% | Training loss: 0.6870336431653107
Epoch: 74 | Iteration number: [2620/4518] 57% | Training loss: 0.6870368489782319
Epoch: 74 | Iteration number: [2630/4518] 58% | Training loss: 0.6870390807267831
Epoch: 74 | Iteration number: [2640/4518] 58% | Training loss: 0.6870416428103592
Epoch: 74 | Iteration number: [2650/4518] 58% | Training loss: 0.6870403467934086
Epoch: 74 | Iteration number: [2660/4518] 58% | Training loss: 0.6870377539243914
Epoch: 74 | Iteration number: [2670/4518] 59% | Training loss: 0.6870403525311403
Epoch: 74 | Iteration number: [2680/4518] 59% | Training loss: 0.6870413611851521
Epoch: 74 | Iteration number: [2690/4518] 59% | Training loss: 0.6870408896176788
Epoch: 74 | Iteration number: [2700/4518] 59% | Training loss: 0.6870349190411744
Epoch: 74 | Iteration number: [2710/4518] 59% | Training loss: 0.6870317057050023
Epoch: 74 | Iteration number: [2720/4518] 60% | Training loss: 0.6870311347658143
Epoch: 74 | Iteration number: [2730/4518] 60% | Training loss: 0.6870316882054884
Epoch: 74 | Iteration number: [2740/4518] 60% | Training loss: 0.6870250474580013
Epoch: 74 | Iteration number: [2750/4518] 60% | Training loss: 0.6870288335410032
Epoch: 74 | Iteration number: [2760/4518] 61% | Training loss: 0.6870327195395594
Epoch: 74 | Iteration number: [2770/4518] 61% | Training loss: 0.6870325925332975
Epoch: 74 | Iteration number: [2780/4518] 61% | Training loss: 0.6870323330807171
Epoch: 74 | Iteration number: [2790/4518] 61% | Training loss: 0.687030083154692
Epoch: 74 | Iteration number: [2800/4518] 61% | Training loss: 0.6870293198738779
Epoch: 74 | Iteration number: [2810/4518] 62% | Training loss: 0.687026666131308
Epoch: 74 | Iteration number: [2820/4518] 62% | Training loss: 0.6870242534377051
Epoch: 74 | Iteration number: [2830/4518] 62% | Training loss: 0.6870244672989255
Epoch: 74 | Iteration number: [2840/4518] 62% | Training loss: 0.6870249717798032
Epoch: 74 | Iteration number: [2850/4518] 63% | Training loss: 0.6870295019317092
Epoch: 74 | Iteration number: [2860/4518] 63% | Training loss: 0.6870274930150359
Epoch: 74 | Iteration number: [2870/4518] 63% | Training loss: 0.6870286015060305
Epoch: 74 | Iteration number: [2880/4518] 63% | Training loss: 0.6870249102512995
Epoch: 74 | Iteration number: [2890/4518] 63% | Training loss: 0.6870235536750212
Epoch: 74 | Iteration number: [2900/4518] 64% | Training loss: 0.687020519499121
Epoch: 74 | Iteration number: [2910/4518] 64% | Training loss: 0.6870207936083738
Epoch: 74 | Iteration number: [2920/4518] 64% | Training loss: 0.6870174301813726
Epoch: 74 | Iteration number: [2930/4518] 64% | Training loss: 0.6870168533951756
Epoch: 74 | Iteration number: [2940/4518] 65% | Training loss: 0.6870146194891054
Epoch: 74 | Iteration number: [2950/4518] 65% | Training loss: 0.6870152598316387
Epoch: 74 | Iteration number: [2960/4518] 65% | Training loss: 0.6870163020451326
Epoch: 74 | Iteration number: [2970/4518] 65% | Training loss: 0.6870142584095901
Epoch: 74 | Iteration number: [2980/4518] 65% | Training loss: 0.6870148824965394
Epoch: 74 | Iteration number: [2990/4518] 66% | Training loss: 0.6870189107182034
Epoch: 74 | Iteration number: [3000/4518] 66% | Training loss: 0.687018222073714
Epoch: 74 | Iteration number: [3010/4518] 66% | Training loss: 0.6870139238050214
Epoch: 74 | Iteration number: [3020/4518] 66% | Training loss: 0.6870122859612205
Epoch: 74 | Iteration number: [3030/4518] 67% | Training loss: 0.6870112518272777
Epoch: 74 | Iteration number: [3040/4518] 67% | Training loss: 0.6870084923741064
Epoch: 74 | Iteration number: [3050/4518] 67% | Training loss: 0.687007954355146
Epoch: 74 | Iteration number: [3060/4518] 67% | Training loss: 0.6870066920721453
Epoch: 74 | Iteration number: [3070/4518] 67% | Training loss: 0.6870009959132353
Epoch: 74 | Iteration number: [3080/4518] 68% | Training loss: 0.6869997194061032
Epoch: 74 | Iteration number: [3090/4518] 68% | Training loss: 0.6869988614687256
Epoch: 74 | Iteration number: [3100/4518] 68% | Training loss: 0.6869953253961378
Epoch: 74 | Iteration number: [3110/4518] 68% | Training loss: 0.6869938369157613
Epoch: 74 | Iteration number: [3120/4518] 69% | Training loss: 0.6869955701896777
Epoch: 74 | Iteration number: [3130/4518] 69% | Training loss: 0.6869950232033532
Epoch: 74 | Iteration number: [3140/4518] 69% | Training loss: 0.6869954816285212
Epoch: 74 | Iteration number: [3150/4518] 69% | Training loss: 0.6869948099529932
Epoch: 74 | Iteration number: [3160/4518] 69% | Training loss: 0.6869938280386261
Epoch: 74 | Iteration number: [3170/4518] 70% | Training loss: 0.6869942789950205
Epoch: 74 | Iteration number: [3180/4518] 70% | Training loss: 0.6869917336874788
Epoch: 74 | Iteration number: [3190/4518] 70% | Training loss: 0.6869907995750164
Epoch: 74 | Iteration number: [3200/4518] 70% | Training loss: 0.6869866753928363
Epoch: 74 | Iteration number: [3210/4518] 71% | Training loss: 0.686985166644753
Epoch: 74 | Iteration number: [3220/4518] 71% | Training loss: 0.6869868774406658
Epoch: 74 | Iteration number: [3230/4518] 71% | Training loss: 0.6869893840591974
Epoch: 74 | Iteration number: [3240/4518] 71% | Training loss: 0.6869889101312484
Epoch: 74 | Iteration number: [3250/4518] 71% | Training loss: 0.6869840704661149
Epoch: 74 | Iteration number: [3260/4518] 72% | Training loss: 0.6869811829430925
Epoch: 74 | Iteration number: [3270/4518] 72% | Training loss: 0.6869773614661774
Epoch: 74 | Iteration number: [3280/4518] 72% | Training loss: 0.6869735538414339
Epoch: 74 | Iteration number: [3290/4518] 72% | Training loss: 0.6869773926705938
Epoch: 74 | Iteration number: [3300/4518] 73% | Training loss: 0.6869763310389085
Epoch: 74 | Iteration number: [3310/4518] 73% | Training loss: 0.6869820878044716
Epoch: 74 | Iteration number: [3320/4518] 73% | Training loss: 0.6869747222188007
Epoch: 74 | Iteration number: [3330/4518] 73% | Training loss: 0.686972803235412
Epoch: 74 | Iteration number: [3340/4518] 73% | Training loss: 0.6869673965398423
Epoch: 74 | Iteration number: [3350/4518] 74% | Training loss: 0.6869653559442777
Epoch: 74 | Iteration number: [3360/4518] 74% | Training loss: 0.6869656423550277
Epoch: 74 | Iteration number: [3370/4518] 74% | Training loss: 0.6869659175328048
Epoch: 74 | Iteration number: [3380/4518] 74% | Training loss: 0.6869673808298168
Epoch: 74 | Iteration number: [3390/4518] 75% | Training loss: 0.686963269246363
Epoch: 74 | Iteration number: [3400/4518] 75% | Training loss: 0.6869604394365759
Epoch: 74 | Iteration number: [3410/4518] 75% | Training loss: 0.6869589253429793
Epoch: 74 | Iteration number: [3420/4518] 75% | Training loss: 0.6869637367495319
Epoch: 74 | Iteration number: [3430/4518] 75% | Training loss: 0.6869633790007833
Epoch: 74 | Iteration number: [3440/4518] 76% | Training loss: 0.686961989295344
Epoch: 74 | Iteration number: [3450/4518] 76% | Training loss: 0.686962383000747
Epoch: 74 | Iteration number: [3460/4518] 76% | Training loss: 0.6869603319319686
Epoch: 74 | Iteration number: [3470/4518] 76% | Training loss: 0.6869575642027841
Epoch: 74 | Iteration number: [3480/4518] 77% | Training loss: 0.6869554881391854
Epoch: 74 | Iteration number: [3490/4518] 77% | Training loss: 0.6869544118045052
Epoch: 74 | Iteration number: [3500/4518] 77% | Training loss: 0.6869503424337932
Epoch: 74 | Iteration number: [3510/4518] 77% | Training loss: 0.6869470931865551
Epoch: 74 | Iteration number: [3520/4518] 77% | Training loss: 0.6869463709267702
Epoch: 74 | Iteration number: [3530/4518] 78% | Training loss: 0.6869470773438894
Epoch: 74 | Iteration number: [3540/4518] 78% | Training loss: 0.6869459221086933
Epoch: 74 | Iteration number: [3550/4518] 78% | Training loss: 0.6869449476289078
Epoch: 74 | Iteration number: [3560/4518] 78% | Training loss: 0.686947377578596
Epoch: 74 | Iteration number: [3570/4518] 79% | Training loss: 0.6869454700405858
Epoch: 74 | Iteration number: [3580/4518] 79% | Training loss: 0.6869463579115255
Epoch: 74 | Iteration number: [3590/4518] 79% | Training loss: 0.6869452924117404
Epoch: 74 | Iteration number: [3600/4518] 79% | Training loss: 0.6869432741569148
Epoch: 74 | Iteration number: [3610/4518] 79% | Training loss: 0.686942336681477
Epoch: 74 | Iteration number: [3620/4518] 80% | Training loss: 0.6869417523481569
Epoch: 74 | Iteration number: [3630/4518] 80% | Training loss: 0.686937788301263
Epoch: 74 | Iteration number: [3640/4518] 80% | Training loss: 0.6869381680593386
Epoch: 74 | Iteration number: [3650/4518] 80% | Training loss: 0.686937681534519
Epoch: 74 | Iteration number: [3660/4518] 81% | Training loss: 0.6869410761392833
Epoch: 74 | Iteration number: [3670/4518] 81% | Training loss: 0.6869405715277149
Epoch: 74 | Iteration number: [3680/4518] 81% | Training loss: 0.6869415970276231
Epoch: 74 | Iteration number: [3690/4518] 81% | Training loss: 0.686942645527806
Epoch: 74 | Iteration number: [3700/4518] 81% | Training loss: 0.6869401001446956
Epoch: 74 | Iteration number: [3710/4518] 82% | Training loss: 0.6869382183185485
Epoch: 74 | Iteration number: [3720/4518] 82% | Training loss: 0.6869358758932801
Epoch: 74 | Iteration number: [3730/4518] 82% | Training loss: 0.6869379239811015
Epoch: 74 | Iteration number: [3740/4518] 82% | Training loss: 0.6869348373005096
Epoch: 74 | Iteration number: [3750/4518] 83% | Training loss: 0.6869363331635793
Epoch: 74 | Iteration number: [3760/4518] 83% | Training loss: 0.6869362582076103
Epoch: 74 | Iteration number: [3770/4518] 83% | Training loss: 0.6869380854010898
Epoch: 74 | Iteration number: [3780/4518] 83% | Training loss: 0.6869374608078962
Epoch: 74 | Iteration number: [3790/4518] 83% | Training loss: 0.6869386499035013
Epoch: 74 | Iteration number: [3800/4518] 84% | Training loss: 0.6869383767874617
Epoch: 74 | Iteration number: [3810/4518] 84% | Training loss: 0.6869426843688244
Epoch: 74 | Iteration number: [3820/4518] 84% | Training loss: 0.6869418226455519
Epoch: 74 | Iteration number: [3830/4518] 84% | Training loss: 0.6869449312008392
Epoch: 74 | Iteration number: [3840/4518] 84% | Training loss: 0.6869434735116859
Epoch: 74 | Iteration number: [3850/4518] 85% | Training loss: 0.6869431018829346
Epoch: 74 | Iteration number: [3860/4518] 85% | Training loss: 0.6869451146051674
Epoch: 74 | Iteration number: [3870/4518] 85% | Training loss: 0.6869458465613136
Epoch: 74 | Iteration number: [3880/4518] 85% | Training loss: 0.6869446735406659
Epoch: 74 | Iteration number: [3890/4518] 86% | Training loss: 0.6869431932665082
Epoch: 74 | Iteration number: [3900/4518] 86% | Training loss: 0.6869437794349132
Epoch: 74 | Iteration number: [3910/4518] 86% | Training loss: 0.6869447920328516
Epoch: 74 | Iteration number: [3920/4518] 86% | Training loss: 0.6869438631346031
Epoch: 74 | Iteration number: [3930/4518] 86% | Training loss: 0.6869453219663703
Epoch: 74 | Iteration number: [3940/4518] 87% | Training loss: 0.6869464863224078
Epoch: 74 | Iteration number: [3950/4518] 87% | Training loss: 0.6869448792934417
Epoch: 74 | Iteration number: [3960/4518] 87% | Training loss: 0.686943461015971
Epoch: 74 | Iteration number: [3970/4518] 87% | Training loss: 0.6869435691262973
Epoch: 74 | Iteration number: [3980/4518] 88% | Training loss: 0.6869404115718812
Epoch: 74 | Iteration number: [3990/4518] 88% | Training loss: 0.6869369333549251
Epoch: 74 | Iteration number: [4000/4518] 88% | Training loss: 0.6869390378296375
Epoch: 74 | Iteration number: [4010/4518] 88% | Training loss: 0.6869392623627869
Epoch: 74 | Iteration number: [4020/4518] 88% | Training loss: 0.6869410666512019
Epoch: 74 | Iteration number: [4030/4518] 89% | Training loss: 0.6869391477137582
Epoch: 74 | Iteration number: [4040/4518] 89% | Training loss: 0.6869380000794288
Epoch: 74 | Iteration number: [4050/4518] 89% | Training loss: 0.6869361268885341
Epoch: 74 | Iteration number: [4060/4518] 89% | Training loss: 0.6869316646911828
Epoch: 74 | Iteration number: [4070/4518] 90% | Training loss: 0.6869290973249759
Epoch: 74 | Iteration number: [4080/4518] 90% | Training loss: 0.6869302418594266
Epoch: 74 | Iteration number: [4090/4518] 90% | Training loss: 0.6869273904483301
Epoch: 74 | Iteration number: [4100/4518] 90% | Training loss: 0.6869262765238925
Epoch: 74 | Iteration number: [4110/4518] 90% | Training loss: 0.6869279977759015
Epoch: 74 | Iteration number: [4120/4518] 91% | Training loss: 0.6869269335877548
Epoch: 74 | Iteration number: [4130/4518] 91% | Training loss: 0.6869270135790615
Epoch: 74 | Iteration number: [4140/4518] 91% | Training loss: 0.6869294351425723
Epoch: 74 | Iteration number: [4150/4518] 91% | Training loss: 0.6869279544755637
Epoch: 74 | Iteration number: [4160/4518] 92% | Training loss: 0.6869282609711472
Epoch: 74 | Iteration number: [4170/4518] 92% | Training loss: 0.6869270976355893
Epoch: 74 | Iteration number: [4180/4518] 92% | Training loss: 0.6869253124916953
Epoch: 74 | Iteration number: [4190/4518] 92% | Training loss: 0.6869256065113732
Epoch: 74 | Iteration number: [4200/4518] 92% | Training loss: 0.6869244223691169
Epoch: 74 | Iteration number: [4210/4518] 93% | Training loss: 0.6869243568167833
Epoch: 74 | Iteration number: [4220/4518] 93% | Training loss: 0.6869245964910182
Epoch: 74 | Iteration number: [4230/4518] 93% | Training loss: 0.6869270201975008
Epoch: 74 | Iteration number: [4240/4518] 93% | Training loss: 0.6869283580555106
Epoch: 74 | Iteration number: [4250/4518] 94% | Training loss: 0.6869299019925734
Epoch: 74 | Iteration number: [4260/4518] 94% | Training loss: 0.6869325601718795
Epoch: 74 | Iteration number: [4270/4518] 94% | Training loss: 0.6869319879757436
Epoch: 74 | Iteration number: [4280/4518] 94% | Training loss: 0.6869331041646894
Epoch: 74 | Iteration number: [4290/4518] 94% | Training loss: 0.6869310895185092
Epoch: 74 | Iteration number: [4300/4518] 95% | Training loss: 0.6869321180637493
Epoch: 74 | Iteration number: [4310/4518] 95% | Training loss: 0.6869312632664727
Epoch: 74 | Iteration number: [4320/4518] 95% | Training loss: 0.6869296933903738
Epoch: 74 | Iteration number: [4330/4518] 95% | Training loss: 0.6869328280519393
Epoch: 74 | Iteration number: [4340/4518] 96% | Training loss: 0.6869313734879692
Epoch: 74 | Iteration number: [4350/4518] 96% | Training loss: 0.6869302667009419
Epoch: 74 | Iteration number: [4360/4518] 96% | Training loss: 0.686929376026906
Epoch: 74 | Iteration number: [4370/4518] 96% | Training loss: 0.6869308725783699
Epoch: 74 | Iteration number: [4380/4518] 96% | Training loss: 0.6869302769502004
Epoch: 74 | Iteration number: [4390/4518] 97% | Training loss: 0.6869297715145798
Epoch: 74 | Iteration number: [4400/4518] 97% | Training loss: 0.6869309659031304
Epoch: 74 | Iteration number: [4410/4518] 97% | Training loss: 0.6869329847986736
Epoch: 74 | Iteration number: [4420/4518] 97% | Training loss: 0.6869317740067098
Epoch: 74 | Iteration number: [4430/4518] 98% | Training loss: 0.6869300798557144
Epoch: 74 | Iteration number: [4440/4518] 98% | Training loss: 0.6869299092137062
Epoch: 74 | Iteration number: [4450/4518] 98% | Training loss: 0.6869313658355327
Epoch: 74 | Iteration number: [4460/4518] 98% | Training loss: 0.686929860871469
Epoch: 74 | Iteration number: [4470/4518] 98% | Training loss: 0.6869295016497841
Epoch: 74 | Iteration number: [4480/4518] 99% | Training loss: 0.6869265861144024
Epoch: 74 | Iteration number: [4490/4518] 99% | Training loss: 0.6869243812322086
Epoch: 74 | Iteration number: [4500/4518] 99% | Training loss: 0.6869231578244104
Epoch: 74 | Iteration number: [4510/4518] 99% | Training loss: 0.6869212704857278

 End of epoch: 74 | Train Loss: 0.6867701328528988 | Training Time: 641 

 End of epoch: 74 | Eval Loss: 0.68986933815236 | Evaluating Time: 17 
Epoch: 75 | Iteration number: [10/4518] 0% | Training loss: 0.7570497512817382
Epoch: 75 | Iteration number: [20/4518] 0% | Training loss: 0.72210493683815
Epoch: 75 | Iteration number: [30/4518] 0% | Training loss: 0.7104788859685262
Epoch: 75 | Iteration number: [40/4518] 0% | Training loss: 0.7046908617019654
Epoch: 75 | Iteration number: [50/4518] 1% | Training loss: 0.7011731898784638
Epoch: 75 | Iteration number: [60/4518] 1% | Training loss: 0.6987509747346242
Epoch: 75 | Iteration number: [70/4518] 1% | Training loss: 0.6968814611434937
Epoch: 75 | Iteration number: [80/4518] 1% | Training loss: 0.6957766570150852
Epoch: 75 | Iteration number: [90/4518] 1% | Training loss: 0.6948184781604343
Epoch: 75 | Iteration number: [100/4518] 2% | Training loss: 0.6940238559246064
Epoch: 75 | Iteration number: [110/4518] 2% | Training loss: 0.6933949210427024
Epoch: 75 | Iteration number: [120/4518] 2% | Training loss: 0.6927201678355535
Epoch: 75 | Iteration number: [130/4518] 2% | Training loss: 0.6922304657789377
Epoch: 75 | Iteration number: [140/4518] 3% | Training loss: 0.6919004874570029
Epoch: 75 | Iteration number: [150/4518] 3% | Training loss: 0.6915947850545248
Epoch: 75 | Iteration number: [160/4518] 3% | Training loss: 0.6912555001676083
Epoch: 75 | Iteration number: [170/4518] 3% | Training loss: 0.6910794422906987
Epoch: 75 | Iteration number: [180/4518] 3% | Training loss: 0.6908488472302755
Epoch: 75 | Iteration number: [190/4518] 4% | Training loss: 0.6906428443758111
Epoch: 75 | Iteration number: [200/4518] 4% | Training loss: 0.6904475849866867
Epoch: 75 | Iteration number: [210/4518] 4% | Training loss: 0.6902580397469656
Epoch: 75 | Iteration number: [220/4518] 4% | Training loss: 0.6900682630864057
Epoch: 75 | Iteration number: [230/4518] 5% | Training loss: 0.6899254257264344
Epoch: 75 | Iteration number: [240/4518] 5% | Training loss: 0.6897860743105412
Epoch: 75 | Iteration number: [250/4518] 5% | Training loss: 0.6896281275749206
Epoch: 75 | Iteration number: [260/4518] 5% | Training loss: 0.689535005734517
Epoch: 75 | Iteration number: [270/4518] 5% | Training loss: 0.6894636242477982
Epoch: 75 | Iteration number: [280/4518] 6% | Training loss: 0.6893694388014929
Epoch: 75 | Iteration number: [290/4518] 6% | Training loss: 0.6892912221365961
Epoch: 75 | Iteration number: [300/4518] 6% | Training loss: 0.6892269806067148
Epoch: 75 | Iteration number: [310/4518] 6% | Training loss: 0.6891763431410636
Epoch: 75 | Iteration number: [320/4518] 7% | Training loss: 0.689121069945395
Epoch: 75 | Iteration number: [330/4518] 7% | Training loss: 0.6890312006979278
Epoch: 75 | Iteration number: [340/4518] 7% | Training loss: 0.6890057963483474
Epoch: 75 | Iteration number: [350/4518] 7% | Training loss: 0.6889365715639931
Epoch: 75 | Iteration number: [360/4518] 7% | Training loss: 0.6888595533039835
Epoch: 75 | Iteration number: [370/4518] 8% | Training loss: 0.6888059783626247
Epoch: 75 | Iteration number: [380/4518] 8% | Training loss: 0.6887413558207061
Epoch: 75 | Iteration number: [390/4518] 8% | Training loss: 0.6887068951741243
Epoch: 75 | Iteration number: [400/4518] 8% | Training loss: 0.6886520439386368
Epoch: 75 | Iteration number: [410/4518] 9% | Training loss: 0.6885787584432741
Epoch: 75 | Iteration number: [420/4518] 9% | Training loss: 0.6885343899329504
Epoch: 75 | Iteration number: [430/4518] 9% | Training loss: 0.688487833738327
Epoch: 75 | Iteration number: [440/4518] 9% | Training loss: 0.6884481531652538
Epoch: 75 | Iteration number: [450/4518] 9% | Training loss: 0.6884052640861935
Epoch: 75 | Iteration number: [460/4518] 10% | Training loss: 0.6883615650560545
Epoch: 75 | Iteration number: [470/4518] 10% | Training loss: 0.6883192222169106
Epoch: 75 | Iteration number: [480/4518] 10% | Training loss: 0.6882882819821438
Epoch: 75 | Iteration number: [490/4518] 10% | Training loss: 0.6882803326966811
Epoch: 75 | Iteration number: [500/4518] 11% | Training loss: 0.6882380563020706
Epoch: 75 | Iteration number: [510/4518] 11% | Training loss: 0.6882266341471205
Epoch: 75 | Iteration number: [520/4518] 11% | Training loss: 0.6881995282494104
Epoch: 75 | Iteration number: [530/4518] 11% | Training loss: 0.6881791584896592
Epoch: 75 | Iteration number: [540/4518] 11% | Training loss: 0.6881487562700555
Epoch: 75 | Iteration number: [550/4518] 12% | Training loss: 0.6881146909973838
Epoch: 75 | Iteration number: [560/4518] 12% | Training loss: 0.6880885899066925
Epoch: 75 | Iteration number: [570/4518] 12% | Training loss: 0.6880704880806437
Epoch: 75 | Iteration number: [580/4518] 12% | Training loss: 0.688041636245004
Epoch: 75 | Iteration number: [590/4518] 13% | Training loss: 0.6880038154327264
Epoch: 75 | Iteration number: [600/4518] 13% | Training loss: 0.6879844046632448
Epoch: 75 | Iteration number: [610/4518] 13% | Training loss: 0.6879509767547982
Epoch: 75 | Iteration number: [620/4518] 13% | Training loss: 0.6879326722314281
Epoch: 75 | Iteration number: [630/4518] 13% | Training loss: 0.6879087959017073
Epoch: 75 | Iteration number: [640/4518] 14% | Training loss: 0.6878924271091819
Epoch: 75 | Iteration number: [650/4518] 14% | Training loss: 0.6878614201912513
Epoch: 75 | Iteration number: [660/4518] 14% | Training loss: 0.6878338187932969
Epoch: 75 | Iteration number: [670/4518] 14% | Training loss: 0.6878317839174128
Epoch: 75 | Iteration number: [680/4518] 15% | Training loss: 0.6878170973237823
Epoch: 75 | Iteration number: [690/4518] 15% | Training loss: 0.6877796469391256
Epoch: 75 | Iteration number: [700/4518] 15% | Training loss: 0.6877857416016715
Epoch: 75 | Iteration number: [710/4518] 15% | Training loss: 0.6877908116495105
Epoch: 75 | Iteration number: [720/4518] 15% | Training loss: 0.6877650838759211
Epoch: 75 | Iteration number: [730/4518] 16% | Training loss: 0.687758080110158
Epoch: 75 | Iteration number: [740/4518] 16% | Training loss: 0.6877468422457979
Epoch: 75 | Iteration number: [750/4518] 16% | Training loss: 0.6877377768357594
Epoch: 75 | Iteration number: [760/4518] 16% | Training loss: 0.6877314403653145
Epoch: 75 | Iteration number: [770/4518] 17% | Training loss: 0.6877140229398554
Epoch: 75 | Iteration number: [780/4518] 17% | Training loss: 0.6877076671673701
Epoch: 75 | Iteration number: [790/4518] 17% | Training loss: 0.6877071051657955
Epoch: 75 | Iteration number: [800/4518] 17% | Training loss: 0.6877101323753595
Epoch: 75 | Iteration number: [810/4518] 17% | Training loss: 0.6877069733025115
Epoch: 75 | Iteration number: [820/4518] 18% | Training loss: 0.6876855566734221
Epoch: 75 | Iteration number: [830/4518] 18% | Training loss: 0.6876720807638513
Epoch: 75 | Iteration number: [840/4518] 18% | Training loss: 0.6876654730666252
Epoch: 75 | Iteration number: [850/4518] 18% | Training loss: 0.6876469154217664
Epoch: 75 | Iteration number: [860/4518] 19% | Training loss: 0.6876377539579258
Epoch: 75 | Iteration number: [870/4518] 19% | Training loss: 0.6876101761028685
Epoch: 75 | Iteration number: [880/4518] 19% | Training loss: 0.6875964565033262
Epoch: 75 | Iteration number: [890/4518] 19% | Training loss: 0.6875876337624668
Epoch: 75 | Iteration number: [900/4518] 19% | Training loss: 0.6875849952300389
Epoch: 75 | Iteration number: [910/4518] 20% | Training loss: 0.6875637848298628
Epoch: 75 | Iteration number: [920/4518] 20% | Training loss: 0.6875546128205631
Epoch: 75 | Iteration number: [930/4518] 20% | Training loss: 0.6875489602806748
Epoch: 75 | Iteration number: [940/4518] 20% | Training loss: 0.6875340581574338
Epoch: 75 | Iteration number: [950/4518] 21% | Training loss: 0.6875233625738244
Epoch: 75 | Iteration number: [960/4518] 21% | Training loss: 0.6875248200570544
Epoch: 75 | Iteration number: [970/4518] 21% | Training loss: 0.6875258289047124
Epoch: 75 | Iteration number: [980/4518] 21% | Training loss: 0.6875052903379713
Epoch: 75 | Iteration number: [990/4518] 21% | Training loss: 0.6874947391977214
Epoch: 75 | Iteration number: [1000/4518] 22% | Training loss: 0.687498428106308
Epoch: 75 | Iteration number: [1010/4518] 22% | Training loss: 0.6874932585376324
Epoch: 75 | Iteration number: [1020/4518] 22% | Training loss: 0.6874811004774243
Epoch: 75 | Iteration number: [1030/4518] 22% | Training loss: 0.6874633560481581
Epoch: 75 | Iteration number: [1040/4518] 23% | Training loss: 0.6874663695693016
Epoch: 75 | Iteration number: [1050/4518] 23% | Training loss: 0.6874614270528158
Epoch: 75 | Iteration number: [1060/4518] 23% | Training loss: 0.6874532147398534
Epoch: 75 | Iteration number: [1070/4518] 23% | Training loss: 0.6874289460828371
Epoch: 75 | Iteration number: [1080/4518] 23% | Training loss: 0.6874285005860858
Epoch: 75 | Iteration number: [1090/4518] 24% | Training loss: 0.6874284316640381
Epoch: 75 | Iteration number: [1100/4518] 24% | Training loss: 0.6874199753457849
Epoch: 75 | Iteration number: [1110/4518] 24% | Training loss: 0.6874257771818487
Epoch: 75 | Iteration number: [1120/4518] 24% | Training loss: 0.6874214453888791
Epoch: 75 | Iteration number: [1130/4518] 25% | Training loss: 0.687429722800719
Epoch: 75 | Iteration number: [1140/4518] 25% | Training loss: 0.6874191287316774
Epoch: 75 | Iteration number: [1150/4518] 25% | Training loss: 0.6874105456082718
Epoch: 75 | Iteration number: [1160/4518] 25% | Training loss: 0.6874034421711133
Epoch: 75 | Iteration number: [1170/4518] 25% | Training loss: 0.6873877323081351
Epoch: 75 | Iteration number: [1180/4518] 26% | Training loss: 0.6873863908193879
Epoch: 75 | Iteration number: [1190/4518] 26% | Training loss: 0.6873984066879049
Epoch: 75 | Iteration number: [1200/4518] 26% | Training loss: 0.6873885308206081
Epoch: 75 | Iteration number: [1210/4518] 26% | Training loss: 0.687377150837055
Epoch: 75 | Iteration number: [1220/4518] 27% | Training loss: 0.6873662414609408
Epoch: 75 | Iteration number: [1230/4518] 27% | Training loss: 0.6873605400081573
Epoch: 75 | Iteration number: [1240/4518] 27% | Training loss: 0.6873473947086642
Epoch: 75 | Iteration number: [1250/4518] 27% | Training loss: 0.6873457421779633
Epoch: 75 | Iteration number: [1260/4518] 27% | Training loss: 0.6873337044602349
Epoch: 75 | Iteration number: [1270/4518] 28% | Training loss: 0.6873313205917989
Epoch: 75 | Iteration number: [1280/4518] 28% | Training loss: 0.6873184252064675
Epoch: 75 | Iteration number: [1290/4518] 28% | Training loss: 0.687316699314487
Epoch: 75 | Iteration number: [1300/4518] 28% | Training loss: 0.6873140068696095
Epoch: 75 | Iteration number: [1310/4518] 28% | Training loss: 0.6873022337451236
Epoch: 75 | Iteration number: [1320/4518] 29% | Training loss: 0.687289462667523
Epoch: 75 | Iteration number: [1330/4518] 29% | Training loss: 0.6872836360805913
Epoch: 75 | Iteration number: [1340/4518] 29% | Training loss: 0.6872826367171843
Epoch: 75 | Iteration number: [1350/4518] 29% | Training loss: 0.6872718344352864
Epoch: 75 | Iteration number: [1360/4518] 30% | Training loss: 0.6872630260884762
Epoch: 75 | Iteration number: [1370/4518] 30% | Training loss: 0.6872605791927254
Epoch: 75 | Iteration number: [1380/4518] 30% | Training loss: 0.687256058489067
Epoch: 75 | Iteration number: [1390/4518] 30% | Training loss: 0.6872630808422033
Epoch: 75 | Iteration number: [1400/4518] 30% | Training loss: 0.6872626821058138
Epoch: 75 | Iteration number: [1410/4518] 31% | Training loss: 0.6872682296637947
Epoch: 75 | Iteration number: [1420/4518] 31% | Training loss: 0.6872690557594031
Epoch: 75 | Iteration number: [1430/4518] 31% | Training loss: 0.6872717904044198
Epoch: 75 | Iteration number: [1440/4518] 31% | Training loss: 0.6872761876218849
Epoch: 75 | Iteration number: [1450/4518] 32% | Training loss: 0.6872730858983664
Epoch: 75 | Iteration number: [1460/4518] 32% | Training loss: 0.6872684890685016
Epoch: 75 | Iteration number: [1470/4518] 32% | Training loss: 0.6872679833652211
Epoch: 75 | Iteration number: [1480/4518] 32% | Training loss: 0.6872595493052457
Epoch: 75 | Iteration number: [1490/4518] 32% | Training loss: 0.6872601009855335
Epoch: 75 | Iteration number: [1500/4518] 33% | Training loss: 0.6872692482868831
Epoch: 75 | Iteration number: [1510/4518] 33% | Training loss: 0.6872590383551768
Epoch: 75 | Iteration number: [1520/4518] 33% | Training loss: 0.6872582063863152
Epoch: 75 | Iteration number: [1530/4518] 33% | Training loss: 0.6872541992103353
Epoch: 75 | Iteration number: [1540/4518] 34% | Training loss: 0.6872578930545162
Epoch: 75 | Iteration number: [1550/4518] 34% | Training loss: 0.6872534617685503
Epoch: 75 | Iteration number: [1560/4518] 34% | Training loss: 0.687249250901051
Epoch: 75 | Iteration number: [1570/4518] 34% | Training loss: 0.6872495812974918
Epoch: 75 | Iteration number: [1580/4518] 34% | Training loss: 0.6872491243519361
Epoch: 75 | Iteration number: [1590/4518] 35% | Training loss: 0.6872485446854957
Epoch: 75 | Iteration number: [1600/4518] 35% | Training loss: 0.6872368505597115
Epoch: 75 | Iteration number: [1610/4518] 35% | Training loss: 0.6872334738695843
Epoch: 75 | Iteration number: [1620/4518] 35% | Training loss: 0.6872280460080983
Epoch: 75 | Iteration number: [1630/4518] 36% | Training loss: 0.6872280630597307
Epoch: 75 | Iteration number: [1640/4518] 36% | Training loss: 0.6872222364675707
Epoch: 75 | Iteration number: [1650/4518] 36% | Training loss: 0.6872034753813888
Epoch: 75 | Iteration number: [1660/4518] 36% | Training loss: 0.6872058549918324
Epoch: 75 | Iteration number: [1670/4518] 36% | Training loss: 0.687200087344575
Epoch: 75 | Iteration number: [1680/4518] 37% | Training loss: 0.6871999825040499
Epoch: 75 | Iteration number: [1690/4518] 37% | Training loss: 0.6871992930858093
Epoch: 75 | Iteration number: [1700/4518] 37% | Training loss: 0.6872053535545574
Epoch: 75 | Iteration number: [1710/4518] 37% | Training loss: 0.6872063795376939
Epoch: 75 | Iteration number: [1720/4518] 38% | Training loss: 0.68720382074284
Epoch: 75 | Iteration number: [1730/4518] 38% | Training loss: 0.6872046446180068
Epoch: 75 | Iteration number: [1740/4518] 38% | Training loss: 0.6872086047098555
Epoch: 75 | Iteration number: [1750/4518] 38% | Training loss: 0.6872045356546129
Epoch: 75 | Iteration number: [1760/4518] 38% | Training loss: 0.6872094814750281
Epoch: 75 | Iteration number: [1770/4518] 39% | Training loss: 0.6872060984541467
Epoch: 75 | Iteration number: [1780/4518] 39% | Training loss: 0.6872029266330634
Epoch: 75 | Iteration number: [1790/4518] 39% | Training loss: 0.687187417092936
Epoch: 75 | Iteration number: [1800/4518] 39% | Training loss: 0.6871844247645802
Epoch: 75 | Iteration number: [1810/4518] 40% | Training loss: 0.6871859356843305
Epoch: 75 | Iteration number: [1820/4518] 40% | Training loss: 0.6871756603102107
Epoch: 75 | Iteration number: [1830/4518] 40% | Training loss: 0.6871695026999615
Epoch: 75 | Iteration number: [1840/4518] 40% | Training loss: 0.6871624215465525
Epoch: 75 | Iteration number: [1850/4518] 40% | Training loss: 0.6871586663980742
Epoch: 75 | Iteration number: [1860/4518] 41% | Training loss: 0.6871561442972511
Epoch: 75 | Iteration number: [1870/4518] 41% | Training loss: 0.6871561750052447
Epoch: 75 | Iteration number: [1880/4518] 41% | Training loss: 0.6871527415006718
Epoch: 75 | Iteration number: [1890/4518] 41% | Training loss: 0.6871497273760497
Epoch: 75 | Iteration number: [1900/4518] 42% | Training loss: 0.6871491365369997
Epoch: 75 | Iteration number: [1910/4518] 42% | Training loss: 0.6871479815213468
Epoch: 75 | Iteration number: [1920/4518] 42% | Training loss: 0.6871428542770446
Epoch: 75 | Iteration number: [1930/4518] 42% | Training loss: 0.6871380019682058
Epoch: 75 | Iteration number: [1940/4518] 42% | Training loss: 0.687136937508878
Epoch: 75 | Iteration number: [1950/4518] 43% | Training loss: 0.6871326253047356
Epoch: 75 | Iteration number: [1960/4518] 43% | Training loss: 0.6871259331399081
Epoch: 75 | Iteration number: [1970/4518] 43% | Training loss: 0.6871258443079624
Epoch: 75 | Iteration number: [1980/4518] 43% | Training loss: 0.687120871622153
Epoch: 75 | Iteration number: [1990/4518] 44% | Training loss: 0.6871155479146008
Epoch: 75 | Iteration number: [2000/4518] 44% | Training loss: 0.6871099537611007
Epoch: 75 | Iteration number: [2010/4518] 44% | Training loss: 0.6871015907520085
Epoch: 75 | Iteration number: [2020/4518] 44% | Training loss: 0.6870943651636048
Epoch: 75 | Iteration number: [2030/4518] 44% | Training loss: 0.6870858610850837
Epoch: 75 | Iteration number: [2040/4518] 45% | Training loss: 0.6870806589138274
Epoch: 75 | Iteration number: [2050/4518] 45% | Training loss: 0.6870783341803202
Epoch: 75 | Iteration number: [2060/4518] 45% | Training loss: 0.6870798614707966
Epoch: 75 | Iteration number: [2070/4518] 45% | Training loss: 0.6870719105437182
Epoch: 75 | Iteration number: [2080/4518] 46% | Training loss: 0.687070711558828
Epoch: 75 | Iteration number: [2090/4518] 46% | Training loss: 0.6870685982932314
Epoch: 75 | Iteration number: [2100/4518] 46% | Training loss: 0.6870648923658189
Epoch: 75 | Iteration number: [2110/4518] 46% | Training loss: 0.687068841977142
Epoch: 75 | Iteration number: [2120/4518] 46% | Training loss: 0.6870675183129761
Epoch: 75 | Iteration number: [2130/4518] 47% | Training loss: 0.6870680778519088
Epoch: 75 | Iteration number: [2140/4518] 47% | Training loss: 0.6870684210385117
Epoch: 75 | Iteration number: [2150/4518] 47% | Training loss: 0.6870685966902002
Epoch: 75 | Iteration number: [2160/4518] 47% | Training loss: 0.6870641724103027
Epoch: 75 | Iteration number: [2170/4518] 48% | Training loss: 0.6870663618437156
Epoch: 75 | Iteration number: [2180/4518] 48% | Training loss: 0.6870634395048159
Epoch: 75 | Iteration number: [2190/4518] 48% | Training loss: 0.687065296711987
Epoch: 75 | Iteration number: [2200/4518] 48% | Training loss: 0.6870643945444714
Epoch: 75 | Iteration number: [2210/4518] 48% | Training loss: 0.6870647077107321
Epoch: 75 | Iteration number: [2220/4518] 49% | Training loss: 0.6870670663880872
Epoch: 75 | Iteration number: [2230/4518] 49% | Training loss: 0.6870671200912629
Epoch: 75 | Iteration number: [2240/4518] 49% | Training loss: 0.687067788812731
Epoch: 75 | Iteration number: [2250/4518] 49% | Training loss: 0.6870731432437897
Epoch: 75 | Iteration number: [2260/4518] 50% | Training loss: 0.6870718441969526
Epoch: 75 | Iteration number: [2270/4518] 50% | Training loss: 0.6870674343098628
Epoch: 75 | Iteration number: [2280/4518] 50% | Training loss: 0.6870653895432489
Epoch: 75 | Iteration number: [2290/4518] 50% | Training loss: 0.6870664273807575
Epoch: 75 | Iteration number: [2300/4518] 50% | Training loss: 0.6870672783903453
Epoch: 75 | Iteration number: [2310/4518] 51% | Training loss: 0.6870682982139257
Epoch: 75 | Iteration number: [2320/4518] 51% | Training loss: 0.6870672654488991
Epoch: 75 | Iteration number: [2330/4518] 51% | Training loss: 0.6870694112368407
Epoch: 75 | Iteration number: [2340/4518] 51% | Training loss: 0.6870678106943766
Epoch: 75 | Iteration number: [2350/4518] 52% | Training loss: 0.687067902975894
Epoch: 75 | Iteration number: [2360/4518] 52% | Training loss: 0.6870673968882884
Epoch: 75 | Iteration number: [2370/4518] 52% | Training loss: 0.6870672705555767
Epoch: 75 | Iteration number: [2380/4518] 52% | Training loss: 0.6870669655439232
Epoch: 75 | Iteration number: [2390/4518] 52% | Training loss: 0.6870568248267952
Epoch: 75 | Iteration number: [2400/4518] 53% | Training loss: 0.6870578278352817
Epoch: 75 | Iteration number: [2410/4518] 53% | Training loss: 0.6870516711745519
Epoch: 75 | Iteration number: [2420/4518] 53% | Training loss: 0.687054034698108
Epoch: 75 | Iteration number: [2430/4518] 53% | Training loss: 0.6870483713140213
Epoch: 75 | Iteration number: [2440/4518] 54% | Training loss: 0.6870476791360339
Epoch: 75 | Iteration number: [2450/4518] 54% | Training loss: 0.6870500571873723
Epoch: 75 | Iteration number: [2460/4518] 54% | Training loss: 0.6870496334826074
Epoch: 75 | Iteration number: [2470/4518] 54% | Training loss: 0.687046260124276
Epoch: 75 | Iteration number: [2480/4518] 54% | Training loss: 0.6870477023384264
Epoch: 75 | Iteration number: [2490/4518] 55% | Training loss: 0.6870471869367194
Epoch: 75 | Iteration number: [2500/4518] 55% | Training loss: 0.6870445735692978
Epoch: 75 | Iteration number: [2510/4518] 55% | Training loss: 0.6870440601827614
Epoch: 75 | Iteration number: [2520/4518] 55% | Training loss: 0.6870412640864887
Epoch: 75 | Iteration number: [2530/4518] 55% | Training loss: 0.6870410133256272
Epoch: 75 | Iteration number: [2540/4518] 56% | Training loss: 0.6870421930795579
Epoch: 75 | Iteration number: [2550/4518] 56% | Training loss: 0.6870388039654376
Epoch: 75 | Iteration number: [2560/4518] 56% | Training loss: 0.6870310359401628
Epoch: 75 | Iteration number: [2570/4518] 56% | Training loss: 0.6870293100056482
Epoch: 75 | Iteration number: [2580/4518] 57% | Training loss: 0.6870261448298314
Epoch: 75 | Iteration number: [2590/4518] 57% | Training loss: 0.6870237242991399
Epoch: 75 | Iteration number: [2600/4518] 57% | Training loss: 0.6870238196391326
Epoch: 75 | Iteration number: [2610/4518] 57% | Training loss: 0.6870252854750988
Epoch: 75 | Iteration number: [2620/4518] 57% | Training loss: 0.6870245057435436
Epoch: 75 | Iteration number: [2630/4518] 58% | Training loss: 0.6870222078303421
Epoch: 75 | Iteration number: [2640/4518] 58% | Training loss: 0.6870197851549495
Epoch: 75 | Iteration number: [2650/4518] 58% | Training loss: 0.6870177449595254
Epoch: 75 | Iteration number: [2660/4518] 58% | Training loss: 0.6870145802211044
Epoch: 75 | Iteration number: [2670/4518] 59% | Training loss: 0.6870133375630396
Epoch: 75 | Iteration number: [2680/4518] 59% | Training loss: 0.6870134499980443
Epoch: 75 | Iteration number: [2690/4518] 59% | Training loss: 0.6870146680498656
Epoch: 75 | Iteration number: [2700/4518] 59% | Training loss: 0.6870174335771136
Epoch: 75 | Iteration number: [2710/4518] 59% | Training loss: 0.6870106389381789
Epoch: 75 | Iteration number: [2720/4518] 60% | Training loss: 0.6870098874849432
Epoch: 75 | Iteration number: [2730/4518] 60% | Training loss: 0.6870075954185737
Epoch: 75 | Iteration number: [2740/4518] 60% | Training loss: 0.6870057062946097
Epoch: 75 | Iteration number: [2750/4518] 60% | Training loss: 0.6870071304711428
Epoch: 75 | Iteration number: [2760/4518] 61% | Training loss: 0.687001395959785
Epoch: 75 | Iteration number: [2770/4518] 61% | Training loss: 0.6869970816137128
Epoch: 75 | Iteration number: [2780/4518] 61% | Training loss: 0.6869981262109263
Epoch: 75 | Iteration number: [2790/4518] 61% | Training loss: 0.6869934530881998
Epoch: 75 | Iteration number: [2800/4518] 61% | Training loss: 0.6869916528463363
Epoch: 75 | Iteration number: [2810/4518] 62% | Training loss: 0.6869889134614069
Epoch: 75 | Iteration number: [2820/4518] 62% | Training loss: 0.6869852367022359
Epoch: 75 | Iteration number: [2830/4518] 62% | Training loss: 0.6869841972425211
Epoch: 75 | Iteration number: [2840/4518] 62% | Training loss: 0.6869804483274339
Epoch: 75 | Iteration number: [2850/4518] 63% | Training loss: 0.6869740546377081
Epoch: 75 | Iteration number: [2860/4518] 63% | Training loss: 0.686976780507948
Epoch: 75 | Iteration number: [2870/4518] 63% | Training loss: 0.6869803891780069
Epoch: 75 | Iteration number: [2880/4518] 63% | Training loss: 0.6869787815337379
Epoch: 75 | Iteration number: [2890/4518] 63% | Training loss: 0.6869759368030258
Epoch: 75 | Iteration number: [2900/4518] 64% | Training loss: 0.6869782473095533
Epoch: 75 | Iteration number: [2910/4518] 64% | Training loss: 0.6869774831119682
Epoch: 75 | Iteration number: [2920/4518] 64% | Training loss: 0.686974870607461
Epoch: 75 | Iteration number: [2930/4518] 64% | Training loss: 0.6869733933906099
Epoch: 75 | Iteration number: [2940/4518] 65% | Training loss: 0.6869735195725953
Epoch: 75 | Iteration number: [2950/4518] 65% | Training loss: 0.6869722056388855
Epoch: 75 | Iteration number: [2960/4518] 65% | Training loss: 0.6869734193827655
Epoch: 75 | Iteration number: [2970/4518] 65% | Training loss: 0.6869771179526744
Epoch: 75 | Iteration number: [2980/4518] 65% | Training loss: 0.6869723655833494
Epoch: 75 | Iteration number: [2990/4518] 66% | Training loss: 0.6869715536717188
Epoch: 75 | Iteration number: [3000/4518] 66% | Training loss: 0.6869654447436333
Epoch: 75 | Iteration number: [3010/4518] 66% | Training loss: 0.6869646398530054
Epoch: 75 | Iteration number: [3020/4518] 66% | Training loss: 0.6869635829072914
Epoch: 75 | Iteration number: [3030/4518] 67% | Training loss: 0.6869650331857574
Epoch: 75 | Iteration number: [3040/4518] 67% | Training loss: 0.686963831770577
Epoch: 75 | Iteration number: [3050/4518] 67% | Training loss: 0.6869632841719956
Epoch: 75 | Iteration number: [3060/4518] 67% | Training loss: 0.6869632974559186
Epoch: 75 | Iteration number: [3070/4518] 67% | Training loss: 0.6869638975551928
Epoch: 75 | Iteration number: [3080/4518] 68% | Training loss: 0.6869609071643321
Epoch: 75 | Iteration number: [3090/4518] 68% | Training loss: 0.6869573121703558
Epoch: 75 | Iteration number: [3100/4518] 68% | Training loss: 0.6869546151161194
Epoch: 75 | Iteration number: [3110/4518] 68% | Training loss: 0.6869540917336749
Epoch: 75 | Iteration number: [3120/4518] 69% | Training loss: 0.6869481466519527
Epoch: 75 | Iteration number: [3130/4518] 69% | Training loss: 0.686944941362253
Epoch: 75 | Iteration number: [3140/4518] 69% | Training loss: 0.6869446064636207
Epoch: 75 | Iteration number: [3150/4518] 69% | Training loss: 0.6869395038627443
Epoch: 75 | Iteration number: [3160/4518] 69% | Training loss: 0.6869369500611402
Epoch: 75 | Iteration number: [3170/4518] 70% | Training loss: 0.6869390982746701
Epoch: 75 | Iteration number: [3180/4518] 70% | Training loss: 0.6869391810968987
Epoch: 75 | Iteration number: [3190/4518] 70% | Training loss: 0.6869380082269447
Epoch: 75 | Iteration number: [3200/4518] 70% | Training loss: 0.6869406590051949
Epoch: 75 | Iteration number: [3210/4518] 71% | Training loss: 0.6869356035629165
Epoch: 75 | Iteration number: [3220/4518] 71% | Training loss: 0.6869336570271795
Epoch: 75 | Iteration number: [3230/4518] 71% | Training loss: 0.6869342632153455
Epoch: 75 | Iteration number: [3240/4518] 71% | Training loss: 0.6869339577761697
Epoch: 75 | Iteration number: [3250/4518] 71% | Training loss: 0.686936633843642
Epoch: 75 | Iteration number: [3260/4518] 72% | Training loss: 0.6869369266588995
Epoch: 75 | Iteration number: [3270/4518] 72% | Training loss: 0.6869370098325456
Epoch: 75 | Iteration number: [3280/4518] 72% | Training loss: 0.6869400698600746
Epoch: 75 | Iteration number: [3290/4518] 72% | Training loss: 0.6869395094801952
Epoch: 75 | Iteration number: [3300/4518] 73% | Training loss: 0.6869408428488356
Epoch: 75 | Iteration number: [3310/4518] 73% | Training loss: 0.6869387752700068
Epoch: 75 | Iteration number: [3320/4518] 73% | Training loss: 0.6869378120245704
Epoch: 75 | Iteration number: [3330/4518] 73% | Training loss: 0.6869392246276409
Epoch: 75 | Iteration number: [3340/4518] 73% | Training loss: 0.6869390365249383
Epoch: 75 | Iteration number: [3350/4518] 74% | Training loss: 0.6869420183772471
Epoch: 75 | Iteration number: [3360/4518] 74% | Training loss: 0.6869407069470201
Epoch: 75 | Iteration number: [3370/4518] 74% | Training loss: 0.6869372140052411
Epoch: 75 | Iteration number: [3380/4518] 74% | Training loss: 0.6869404550311128
Epoch: 75 | Iteration number: [3390/4518] 75% | Training loss: 0.6869395634066039
Epoch: 75 | Iteration number: [3400/4518] 75% | Training loss: 0.6869342239814646
Epoch: 75 | Iteration number: [3410/4518] 75% | Training loss: 0.6869332800337996
Epoch: 75 | Iteration number: [3420/4518] 75% | Training loss: 0.6869331585384949
Epoch: 75 | Iteration number: [3430/4518] 75% | Training loss: 0.6869347798059703
Epoch: 75 | Iteration number: [3440/4518] 76% | Training loss: 0.6869366256823374
Epoch: 75 | Iteration number: [3450/4518] 76% | Training loss: 0.6869354392307392
Epoch: 75 | Iteration number: [3460/4518] 76% | Training loss: 0.6869336895515464
Epoch: 75 | Iteration number: [3470/4518] 76% | Training loss: 0.6869308379438493
Epoch: 75 | Iteration number: [3480/4518] 77% | Training loss: 0.6869248527391204
Epoch: 75 | Iteration number: [3490/4518] 77% | Training loss: 0.6869216166799594
Epoch: 75 | Iteration number: [3500/4518] 77% | Training loss: 0.6869191691023963
Epoch: 75 | Iteration number: [3510/4518] 77% | Training loss: 0.6869200852012363
Epoch: 75 | Iteration number: [3520/4518] 77% | Training loss: 0.6869183294813741
Epoch: 75 | Iteration number: [3530/4518] 78% | Training loss: 0.686916537376031
Epoch: 75 | Iteration number: [3540/4518] 78% | Training loss: 0.686919674327818
Epoch: 75 | Iteration number: [3550/4518] 78% | Training loss: 0.6869213469095633
Epoch: 75 | Iteration number: [3560/4518] 78% | Training loss: 0.6869193452797578
Epoch: 75 | Iteration number: [3570/4518] 79% | Training loss: 0.6869157663580416
Epoch: 75 | Iteration number: [3580/4518] 79% | Training loss: 0.68691301983495
Epoch: 75 | Iteration number: [3590/4518] 79% | Training loss: 0.6869116221961868
Epoch: 75 | Iteration number: [3600/4518] 79% | Training loss: 0.6869113506045607
Epoch: 75 | Iteration number: [3610/4518] 79% | Training loss: 0.6869135447486285
Epoch: 75 | Iteration number: [3620/4518] 80% | Training loss: 0.6869116674305984
Epoch: 75 | Iteration number: [3630/4518] 80% | Training loss: 0.6869124719098252
Epoch: 75 | Iteration number: [3640/4518] 80% | Training loss: 0.6869153225487405
Epoch: 75 | Iteration number: [3650/4518] 80% | Training loss: 0.6869160655263352
Epoch: 75 | Iteration number: [3660/4518] 81% | Training loss: 0.6869187341524604
Epoch: 75 | Iteration number: [3670/4518] 81% | Training loss: 0.6869209017350824
Epoch: 75 | Iteration number: [3680/4518] 81% | Training loss: 0.6869189299481071
Epoch: 75 | Iteration number: [3690/4518] 81% | Training loss: 0.6869176221572286
Epoch: 75 | Iteration number: [3700/4518] 81% | Training loss: 0.6869200088365658
Epoch: 75 | Iteration number: [3710/4518] 82% | Training loss: 0.686916544720169
Epoch: 75 | Iteration number: [3720/4518] 82% | Training loss: 0.686919477309591
Epoch: 75 | Iteration number: [3730/4518] 82% | Training loss: 0.6869219984989064
Epoch: 75 | Iteration number: [3740/4518] 82% | Training loss: 0.686923548802335
Epoch: 75 | Iteration number: [3750/4518] 83% | Training loss: 0.6869269739945729
Epoch: 75 | Iteration number: [3760/4518] 83% | Training loss: 0.6869253105622657
Epoch: 75 | Iteration number: [3770/4518] 83% | Training loss: 0.6869226581854276
Epoch: 75 | Iteration number: [3780/4518] 83% | Training loss: 0.6869202633225728
Epoch: 75 | Iteration number: [3790/4518] 83% | Training loss: 0.6869225279165132
Epoch: 75 | Iteration number: [3800/4518] 84% | Training loss: 0.6869247528910637
Epoch: 75 | Iteration number: [3810/4518] 84% | Training loss: 0.6869268313793373
Epoch: 75 | Iteration number: [3820/4518] 84% | Training loss: 0.6869306279414611
Epoch: 75 | Iteration number: [3830/4518] 84% | Training loss: 0.6869311463583854
Epoch: 75 | Iteration number: [3840/4518] 84% | Training loss: 0.6869291496773561
Epoch: 75 | Iteration number: [3850/4518] 85% | Training loss: 0.6869298940509945
Epoch: 75 | Iteration number: [3860/4518] 85% | Training loss: 0.6869310936779556
Epoch: 75 | Iteration number: [3870/4518] 85% | Training loss: 0.6869321252178469
Epoch: 75 | Iteration number: [3880/4518] 85% | Training loss: 0.6869333175961504
Epoch: 75 | Iteration number: [3890/4518] 86% | Training loss: 0.6869339110612256
Epoch: 75 | Iteration number: [3900/4518] 86% | Training loss: 0.6869336658104872
Epoch: 75 | Iteration number: [3910/4518] 86% | Training loss: 0.6869346330232937
Epoch: 75 | Iteration number: [3920/4518] 86% | Training loss: 0.6869306214609925
Epoch: 75 | Iteration number: [3930/4518] 86% | Training loss: 0.68692953481929
Epoch: 75 | Iteration number: [3940/4518] 87% | Training loss: 0.6869308561389217
Epoch: 75 | Iteration number: [3950/4518] 87% | Training loss: 0.6869322499595111
Epoch: 75 | Iteration number: [3960/4518] 87% | Training loss: 0.6869315177051708
Epoch: 75 | Iteration number: [3970/4518] 87% | Training loss: 0.6869324900491411
Epoch: 75 | Iteration number: [3980/4518] 88% | Training loss: 0.6869325645455164
Epoch: 75 | Iteration number: [3990/4518] 88% | Training loss: 0.6869338406207867
Epoch: 75 | Iteration number: [4000/4518] 88% | Training loss: 0.6869344619214535
Epoch: 75 | Iteration number: [4010/4518] 88% | Training loss: 0.6869365944529412
Epoch: 75 | Iteration number: [4020/4518] 88% | Training loss: 0.6869325595412088
Epoch: 75 | Iteration number: [4030/4518] 89% | Training loss: 0.6869341511880198
Epoch: 75 | Iteration number: [4040/4518] 89% | Training loss: 0.6869321478032829
Epoch: 75 | Iteration number: [4050/4518] 89% | Training loss: 0.6869277184097855
Epoch: 75 | Iteration number: [4060/4518] 89% | Training loss: 0.6869274495270452
Epoch: 75 | Iteration number: [4070/4518] 90% | Training loss: 0.6869300269963408
Epoch: 75 | Iteration number: [4080/4518] 90% | Training loss: 0.6869281079839258
Epoch: 75 | Iteration number: [4090/4518] 90% | Training loss: 0.6869311466339456
Epoch: 75 | Iteration number: [4100/4518] 90% | Training loss: 0.6869311373989756
Epoch: 75 | Iteration number: [4110/4518] 90% | Training loss: 0.6869329049639458
Epoch: 75 | Iteration number: [4120/4518] 91% | Training loss: 0.6869282835606233
Epoch: 75 | Iteration number: [4130/4518] 91% | Training loss: 0.6869267870669792
Epoch: 75 | Iteration number: [4140/4518] 91% | Training loss: 0.6869265102821848
Epoch: 75 | Iteration number: [4150/4518] 91% | Training loss: 0.6869270486716764
Epoch: 75 | Iteration number: [4160/4518] 92% | Training loss: 0.68692655961674
Epoch: 75 | Iteration number: [4170/4518] 92% | Training loss: 0.6869253673141809
Epoch: 75 | Iteration number: [4180/4518] 92% | Training loss: 0.6869272926207365
Epoch: 75 | Iteration number: [4190/4518] 92% | Training loss: 0.6869282106937827
Epoch: 75 | Iteration number: [4200/4518] 92% | Training loss: 0.6869270011498815
Epoch: 75 | Iteration number: [4210/4518] 93% | Training loss: 0.6869255047371156
Epoch: 75 | Iteration number: [4220/4518] 93% | Training loss: 0.6869225335629631
Epoch: 75 | Iteration number: [4230/4518] 93% | Training loss: 0.6869208497217643
Epoch: 75 | Iteration number: [4240/4518] 93% | Training loss: 0.6869210719781101
Epoch: 75 | Iteration number: [4250/4518] 94% | Training loss: 0.6869200482508715
Epoch: 75 | Iteration number: [4260/4518] 94% | Training loss: 0.6869198974309393
Epoch: 75 | Iteration number: [4270/4518] 94% | Training loss: 0.6869207164442791
Epoch: 75 | Iteration number: [4280/4518] 94% | Training loss: 0.6869235989646377
Epoch: 75 | Iteration number: [4290/4518] 94% | Training loss: 0.68692261066748
Epoch: 75 | Iteration number: [4300/4518] 95% | Training loss: 0.6869209803675497
Epoch: 75 | Iteration number: [4310/4518] 95% | Training loss: 0.6869184790797134
Epoch: 75 | Iteration number: [4320/4518] 95% | Training loss: 0.686916929235061
Epoch: 75 | Iteration number: [4330/4518] 95% | Training loss: 0.6869203824506896
Epoch: 75 | Iteration number: [4340/4518] 96% | Training loss: 0.6869212549952318
Epoch: 75 | Iteration number: [4350/4518] 96% | Training loss: 0.6869235733733781
Epoch: 75 | Iteration number: [4360/4518] 96% | Training loss: 0.6869204477842795
Epoch: 75 | Iteration number: [4370/4518] 96% | Training loss: 0.6869219569374276
Epoch: 75 | Iteration number: [4380/4518] 96% | Training loss: 0.686924248335024
Epoch: 75 | Iteration number: [4390/4518] 97% | Training loss: 0.6869241041311642
Epoch: 75 | Iteration number: [4400/4518] 97% | Training loss: 0.6869252569567074
Epoch: 75 | Iteration number: [4410/4518] 97% | Training loss: 0.686924560175461
Epoch: 75 | Iteration number: [4420/4518] 97% | Training loss: 0.686924185903903
Epoch: 75 | Iteration number: [4430/4518] 98% | Training loss: 0.6869223014226616
Epoch: 75 | Iteration number: [4440/4518] 98% | Training loss: 0.6869218242463765
Epoch: 75 | Iteration number: [4450/4518] 98% | Training loss: 0.6869210898474362
Epoch: 75 | Iteration number: [4460/4518] 98% | Training loss: 0.686920726005272
Epoch: 75 | Iteration number: [4470/4518] 98% | Training loss: 0.6869204924410621
Epoch: 75 | Iteration number: [4480/4518] 99% | Training loss: 0.686921031786395
Epoch: 75 | Iteration number: [4490/4518] 99% | Training loss: 0.6869221421153614
Epoch: 75 | Iteration number: [4500/4518] 99% | Training loss: 0.6869245763354831
Epoch: 75 | Iteration number: [4510/4518] 99% | Training loss: 0.6869233433264587

 End of epoch: 75 | Train Loss: 0.686771069271156 | Training Time: 640 

 End of epoch: 75 | Eval Loss: 0.6898253414095664 | Evaluating Time: 17 
Epoch: 76 | Iteration number: [10/4518] 0% | Training loss: 0.7553398191928864
Epoch: 76 | Iteration number: [20/4518] 0% | Training loss: 0.7206714063882828
Epoch: 76 | Iteration number: [30/4518] 0% | Training loss: 0.7091660102208456
Epoch: 76 | Iteration number: [40/4518] 0% | Training loss: 0.7031888872385025
Epoch: 76 | Iteration number: [50/4518] 1% | Training loss: 0.699944316148758
Epoch: 76 | Iteration number: [60/4518] 1% | Training loss: 0.6979915459950765
Epoch: 76 | Iteration number: [70/4518] 1% | Training loss: 0.6963467870439802
Epoch: 76 | Iteration number: [80/4518] 1% | Training loss: 0.6952245444059372
Epoch: 76 | Iteration number: [90/4518] 1% | Training loss: 0.6944019615650177
Epoch: 76 | Iteration number: [100/4518] 2% | Training loss: 0.6936083567142487
Epoch: 76 | Iteration number: [110/4518] 2% | Training loss: 0.6929875249212438
Epoch: 76 | Iteration number: [120/4518] 2% | Training loss: 0.6923957680662473
Epoch: 76 | Iteration number: [130/4518] 2% | Training loss: 0.6920239902459658
Epoch: 76 | Iteration number: [140/4518] 3% | Training loss: 0.6916173053639275
Epoch: 76 | Iteration number: [150/4518] 3% | Training loss: 0.6913081463177999
Epoch: 76 | Iteration number: [160/4518] 3% | Training loss: 0.6910023856908083
Epoch: 76 | Iteration number: [170/4518] 3% | Training loss: 0.6908246766118442
Epoch: 76 | Iteration number: [180/4518] 3% | Training loss: 0.6906328880124621
Epoch: 76 | Iteration number: [190/4518] 4% | Training loss: 0.6904022103861759
Epoch: 76 | Iteration number: [200/4518] 4% | Training loss: 0.6902305400371551
Epoch: 76 | Iteration number: [210/4518] 4% | Training loss: 0.6900346778687977
Epoch: 76 | Iteration number: [220/4518] 4% | Training loss: 0.6899373853748495
Epoch: 76 | Iteration number: [230/4518] 5% | Training loss: 0.6898135029751321
Epoch: 76 | Iteration number: [240/4518] 5% | Training loss: 0.689691887050867
Epoch: 76 | Iteration number: [250/4518] 5% | Training loss: 0.689535338640213
Epoch: 76 | Iteration number: [260/4518] 5% | Training loss: 0.6893536340731841
Epoch: 76 | Iteration number: [270/4518] 5% | Training loss: 0.6892051663663652
Epoch: 76 | Iteration number: [280/4518] 6% | Training loss: 0.689077551662922
Epoch: 76 | Iteration number: [290/4518] 6% | Training loss: 0.6890274333542791
Epoch: 76 | Iteration number: [300/4518] 6% | Training loss: 0.6889371079206467
Epoch: 76 | Iteration number: [310/4518] 6% | Training loss: 0.6888650328882279
Epoch: 76 | Iteration number: [320/4518] 7% | Training loss: 0.6887841816991568
Epoch: 76 | Iteration number: [330/4518] 7% | Training loss: 0.688718992471695
Epoch: 76 | Iteration number: [340/4518] 7% | Training loss: 0.6886601788156173
Epoch: 76 | Iteration number: [350/4518] 7% | Training loss: 0.6885750818252564
Epoch: 76 | Iteration number: [360/4518] 7% | Training loss: 0.6885439993606673
Epoch: 76 | Iteration number: [370/4518] 8% | Training loss: 0.6884868288362348
Epoch: 76 | Iteration number: [380/4518] 8% | Training loss: 0.6884448848272625
Epoch: 76 | Iteration number: [390/4518] 8% | Training loss: 0.6884009975653428
Epoch: 76 | Iteration number: [400/4518] 8% | Training loss: 0.6883533132076264
Epoch: 76 | Iteration number: [410/4518] 9% | Training loss: 0.6882922717710821
Epoch: 76 | Iteration number: [420/4518] 9% | Training loss: 0.6882440971476691
Epoch: 76 | Iteration number: [430/4518] 9% | Training loss: 0.6882250060868818
Epoch: 76 | Iteration number: [440/4518] 9% | Training loss: 0.6881990371779962
Epoch: 76 | Iteration number: [450/4518] 9% | Training loss: 0.6881639689869351
Epoch: 76 | Iteration number: [460/4518] 10% | Training loss: 0.6881337612867355
Epoch: 76 | Iteration number: [470/4518] 10% | Training loss: 0.688104716133564
Epoch: 76 | Iteration number: [480/4518] 10% | Training loss: 0.688093946625789
Epoch: 76 | Iteration number: [490/4518] 10% | Training loss: 0.6880720857454806
Epoch: 76 | Iteration number: [500/4518] 11% | Training loss: 0.68807666015625
Epoch: 76 | Iteration number: [510/4518] 11% | Training loss: 0.6880328107113932
Epoch: 76 | Iteration number: [520/4518] 11% | Training loss: 0.6880079249923046
Epoch: 76 | Iteration number: [530/4518] 11% | Training loss: 0.6879925901035093
Epoch: 76 | Iteration number: [540/4518] 11% | Training loss: 0.6879636362746909
Epoch: 76 | Iteration number: [550/4518] 12% | Training loss: 0.6879353631626476
Epoch: 76 | Iteration number: [560/4518] 12% | Training loss: 0.6878990999289921
Epoch: 76 | Iteration number: [570/4518] 12% | Training loss: 0.6878524398594572
Epoch: 76 | Iteration number: [580/4518] 12% | Training loss: 0.6878371484320739
Epoch: 76 | Iteration number: [590/4518] 13% | Training loss: 0.6878262636014971
Epoch: 76 | Iteration number: [600/4518] 13% | Training loss: 0.6877788004279136
Epoch: 76 | Iteration number: [610/4518] 13% | Training loss: 0.6877719524453898
Epoch: 76 | Iteration number: [620/4518] 13% | Training loss: 0.6877606885087105
Epoch: 76 | Iteration number: [630/4518] 13% | Training loss: 0.6877603144872756
Epoch: 76 | Iteration number: [640/4518] 14% | Training loss: 0.6877439168281854
Epoch: 76 | Iteration number: [650/4518] 14% | Training loss: 0.6877282810211182
Epoch: 76 | Iteration number: [660/4518] 14% | Training loss: 0.687721023234454
Epoch: 76 | Iteration number: [670/4518] 14% | Training loss: 0.6876929530456884
Epoch: 76 | Iteration number: [680/4518] 15% | Training loss: 0.6876731539473814
Epoch: 76 | Iteration number: [690/4518] 15% | Training loss: 0.6876546798408896
Epoch: 76 | Iteration number: [700/4518] 15% | Training loss: 0.6876465096643993
Epoch: 76 | Iteration number: [710/4518] 15% | Training loss: 0.6876269987771209
Epoch: 76 | Iteration number: [720/4518] 15% | Training loss: 0.6875946289963193
Epoch: 76 | Iteration number: [730/4518] 16% | Training loss: 0.6875828152650023
Epoch: 76 | Iteration number: [740/4518] 16% | Training loss: 0.6875784029831757
Epoch: 76 | Iteration number: [750/4518] 16% | Training loss: 0.6875654663244883
Epoch: 76 | Iteration number: [760/4518] 16% | Training loss: 0.6875600444643121
Epoch: 76 | Iteration number: [770/4518] 17% | Training loss: 0.6875568029168364
Epoch: 76 | Iteration number: [780/4518] 17% | Training loss: 0.687558465737563
Epoch: 76 | Iteration number: [790/4518] 17% | Training loss: 0.6875562374350391
Epoch: 76 | Iteration number: [800/4518] 17% | Training loss: 0.6875479612499475
Epoch: 76 | Iteration number: [810/4518] 17% | Training loss: 0.6875344000480793
Epoch: 76 | Iteration number: [820/4518] 18% | Training loss: 0.6875315437229669
Epoch: 76 | Iteration number: [830/4518] 18% | Training loss: 0.6875086958867958
Epoch: 76 | Iteration number: [840/4518] 18% | Training loss: 0.6874954474823816
Epoch: 76 | Iteration number: [850/4518] 18% | Training loss: 0.6874716287500718
Epoch: 76 | Iteration number: [860/4518] 19% | Training loss: 0.6874667866978534
Epoch: 76 | Iteration number: [870/4518] 19% | Training loss: 0.6874616063189233
Epoch: 76 | Iteration number: [880/4518] 19% | Training loss: 0.6874478776346553
Epoch: 76 | Iteration number: [890/4518] 19% | Training loss: 0.6874451832155163
Epoch: 76 | Iteration number: [900/4518] 19% | Training loss: 0.6874446561601427
Epoch: 76 | Iteration number: [910/4518] 20% | Training loss: 0.6874337500923282
Epoch: 76 | Iteration number: [920/4518] 20% | Training loss: 0.6874309333770171
Epoch: 76 | Iteration number: [930/4518] 20% | Training loss: 0.687424510845574
Epoch: 76 | Iteration number: [940/4518] 20% | Training loss: 0.6874108074193305
Epoch: 76 | Iteration number: [950/4518] 21% | Training loss: 0.6874056083905069
Epoch: 76 | Iteration number: [960/4518] 21% | Training loss: 0.6874055549502373
Epoch: 76 | Iteration number: [970/4518] 21% | Training loss: 0.6873869599755278
Epoch: 76 | Iteration number: [980/4518] 21% | Training loss: 0.6873804351504968
Epoch: 76 | Iteration number: [990/4518] 21% | Training loss: 0.6873692467357173
Epoch: 76 | Iteration number: [1000/4518] 22% | Training loss: 0.6873650864362717
Epoch: 76 | Iteration number: [1010/4518] 22% | Training loss: 0.6873646422778026
Epoch: 76 | Iteration number: [1020/4518] 22% | Training loss: 0.6873507050322551
Epoch: 76 | Iteration number: [1030/4518] 22% | Training loss: 0.6873392358566951
Epoch: 76 | Iteration number: [1040/4518] 23% | Training loss: 0.6873337202920363
Epoch: 76 | Iteration number: [1050/4518] 23% | Training loss: 0.6873331953230358
Epoch: 76 | Iteration number: [1060/4518] 23% | Training loss: 0.6873270205169354
Epoch: 76 | Iteration number: [1070/4518] 23% | Training loss: 0.6873186492474279
Epoch: 76 | Iteration number: [1080/4518] 23% | Training loss: 0.6873201699720488
Epoch: 76 | Iteration number: [1090/4518] 24% | Training loss: 0.6873266009015775
Epoch: 76 | Iteration number: [1100/4518] 24% | Training loss: 0.6873220412297683
Epoch: 76 | Iteration number: [1110/4518] 24% | Training loss: 0.687317668102883
Epoch: 76 | Iteration number: [1120/4518] 24% | Training loss: 0.6873194634914398
Epoch: 76 | Iteration number: [1130/4518] 25% | Training loss: 0.6873095565665085
Epoch: 76 | Iteration number: [1140/4518] 25% | Training loss: 0.6873181909322739
Epoch: 76 | Iteration number: [1150/4518] 25% | Training loss: 0.6873235005399455
Epoch: 76 | Iteration number: [1160/4518] 25% | Training loss: 0.6873216262151455
Epoch: 76 | Iteration number: [1170/4518] 25% | Training loss: 0.6873224934961042
Epoch: 76 | Iteration number: [1180/4518] 26% | Training loss: 0.6873171905339774
Epoch: 76 | Iteration number: [1190/4518] 26% | Training loss: 0.6873114830305597
Epoch: 76 | Iteration number: [1200/4518] 26% | Training loss: 0.6873120460410913
Epoch: 76 | Iteration number: [1210/4518] 26% | Training loss: 0.6873059956988027
Epoch: 76 | Iteration number: [1220/4518] 27% | Training loss: 0.6872971041769278
Epoch: 76 | Iteration number: [1230/4518] 27% | Training loss: 0.6872966464942064
Epoch: 76 | Iteration number: [1240/4518] 27% | Training loss: 0.6872839505634
Epoch: 76 | Iteration number: [1250/4518] 27% | Training loss: 0.6872872419834137
Epoch: 76 | Iteration number: [1260/4518] 27% | Training loss: 0.687286879855489
Epoch: 76 | Iteration number: [1270/4518] 28% | Training loss: 0.6872755694107746
Epoch: 76 | Iteration number: [1280/4518] 28% | Training loss: 0.687268620962277
Epoch: 76 | Iteration number: [1290/4518] 28% | Training loss: 0.6872694732606873
Epoch: 76 | Iteration number: [1300/4518] 28% | Training loss: 0.687268992799979
Epoch: 76 | Iteration number: [1310/4518] 28% | Training loss: 0.6872694637029225
Epoch: 76 | Iteration number: [1320/4518] 29% | Training loss: 0.6872635753317313
Epoch: 76 | Iteration number: [1330/4518] 29% | Training loss: 0.687265221785782
Epoch: 76 | Iteration number: [1340/4518] 29% | Training loss: 0.6872562608167306
Epoch: 76 | Iteration number: [1350/4518] 29% | Training loss: 0.6872591521121838
Epoch: 76 | Iteration number: [1360/4518] 30% | Training loss: 0.6872570136014153
Epoch: 76 | Iteration number: [1370/4518] 30% | Training loss: 0.6872579946135082
Epoch: 76 | Iteration number: [1380/4518] 30% | Training loss: 0.6872521914001825
Epoch: 76 | Iteration number: [1390/4518] 30% | Training loss: 0.6872515156114701
Epoch: 76 | Iteration number: [1400/4518] 30% | Training loss: 0.6872516522237233
Epoch: 76 | Iteration number: [1410/4518] 31% | Training loss: 0.6872557727157647
Epoch: 76 | Iteration number: [1420/4518] 31% | Training loss: 0.6872548750588592
Epoch: 76 | Iteration number: [1430/4518] 31% | Training loss: 0.687242982020745
Epoch: 76 | Iteration number: [1440/4518] 31% | Training loss: 0.6872416591064797
Epoch: 76 | Iteration number: [1450/4518] 32% | Training loss: 0.6872339292641344
Epoch: 76 | Iteration number: [1460/4518] 32% | Training loss: 0.6872380149282821
Epoch: 76 | Iteration number: [1470/4518] 32% | Training loss: 0.6872406731251957
Epoch: 76 | Iteration number: [1480/4518] 32% | Training loss: 0.6872532678214279
Epoch: 76 | Iteration number: [1490/4518] 32% | Training loss: 0.6872385440256772
Epoch: 76 | Iteration number: [1500/4518] 33% | Training loss: 0.6872267626126607
Epoch: 76 | Iteration number: [1510/4518] 33% | Training loss: 0.6872278726258815
Epoch: 76 | Iteration number: [1520/4518] 33% | Training loss: 0.6872254841813915
Epoch: 76 | Iteration number: [1530/4518] 33% | Training loss: 0.6872222235000212
Epoch: 76 | Iteration number: [1540/4518] 34% | Training loss: 0.6872218150210071
Epoch: 76 | Iteration number: [1550/4518] 34% | Training loss: 0.6872147129812548
Epoch: 76 | Iteration number: [1560/4518] 34% | Training loss: 0.6872124014374538
Epoch: 76 | Iteration number: [1570/4518] 34% | Training loss: 0.6872114038011831
Epoch: 76 | Iteration number: [1580/4518] 34% | Training loss: 0.687208498806893
Epoch: 76 | Iteration number: [1590/4518] 35% | Training loss: 0.6871977046975549
Epoch: 76 | Iteration number: [1600/4518] 35% | Training loss: 0.6872040963545442
Epoch: 76 | Iteration number: [1610/4518] 35% | Training loss: 0.6872081448572763
Epoch: 76 | Iteration number: [1620/4518] 35% | Training loss: 0.6872011897740541
Epoch: 76 | Iteration number: [1630/4518] 36% | Training loss: 0.68720769670112
Epoch: 76 | Iteration number: [1640/4518] 36% | Training loss: 0.6872088958940855
Epoch: 76 | Iteration number: [1650/4518] 36% | Training loss: 0.687198578299898
Epoch: 76 | Iteration number: [1660/4518] 36% | Training loss: 0.6871978617576231
Epoch: 76 | Iteration number: [1670/4518] 36% | Training loss: 0.6872013392205724
Epoch: 76 | Iteration number: [1680/4518] 37% | Training loss: 0.6871986740756603
Epoch: 76 | Iteration number: [1690/4518] 37% | Training loss: 0.6871972543248058
Epoch: 76 | Iteration number: [1700/4518] 37% | Training loss: 0.6871901884149103
Epoch: 76 | Iteration number: [1710/4518] 37% | Training loss: 0.68718663171718
Epoch: 76 | Iteration number: [1720/4518] 38% | Training loss: 0.6871827277333238
Epoch: 76 | Iteration number: [1730/4518] 38% | Training loss: 0.6871772623475576
Epoch: 76 | Iteration number: [1740/4518] 38% | Training loss: 0.6871726285794686
Epoch: 76 | Iteration number: [1750/4518] 38% | Training loss: 0.687168231180736
Epoch: 76 | Iteration number: [1760/4518] 38% | Training loss: 0.6871632256629792
Epoch: 76 | Iteration number: [1770/4518] 39% | Training loss: 0.6871534123932574
Epoch: 76 | Iteration number: [1780/4518] 39% | Training loss: 0.6871517314000076
Epoch: 76 | Iteration number: [1790/4518] 39% | Training loss: 0.687150556515049
Epoch: 76 | Iteration number: [1800/4518] 39% | Training loss: 0.6871527941359414
Epoch: 76 | Iteration number: [1810/4518] 40% | Training loss: 0.6871572048953883
Epoch: 76 | Iteration number: [1820/4518] 40% | Training loss: 0.6871560418998802
Epoch: 76 | Iteration number: [1830/4518] 40% | Training loss: 0.6871497999123537
Epoch: 76 | Iteration number: [1840/4518] 40% | Training loss: 0.6871422034890755
Epoch: 76 | Iteration number: [1850/4518] 40% | Training loss: 0.6871487362642545
Epoch: 76 | Iteration number: [1860/4518] 41% | Training loss: 0.6871420124525665
Epoch: 76 | Iteration number: [1870/4518] 41% | Training loss: 0.6871397398372385
Epoch: 76 | Iteration number: [1880/4518] 41% | Training loss: 0.6871349837551726
Epoch: 76 | Iteration number: [1890/4518] 41% | Training loss: 0.6871322647604362
Epoch: 76 | Iteration number: [1900/4518] 42% | Training loss: 0.6871337675107153
Epoch: 76 | Iteration number: [1910/4518] 42% | Training loss: 0.6871315658716631
Epoch: 76 | Iteration number: [1920/4518] 42% | Training loss: 0.6871249840905269
Epoch: 76 | Iteration number: [1930/4518] 42% | Training loss: 0.6871273594816731
Epoch: 76 | Iteration number: [1940/4518] 42% | Training loss: 0.6871251848555103
Epoch: 76 | Iteration number: [1950/4518] 43% | Training loss: 0.6871198253448193
Epoch: 76 | Iteration number: [1960/4518] 43% | Training loss: 0.68712123060713
Epoch: 76 | Iteration number: [1970/4518] 43% | Training loss: 0.687126210377301
Epoch: 76 | Iteration number: [1980/4518] 43% | Training loss: 0.6871252342607036
Epoch: 76 | Iteration number: [1990/4518] 44% | Training loss: 0.6871343510534296
Epoch: 76 | Iteration number: [2000/4518] 44% | Training loss: 0.6871316624581814
Epoch: 76 | Iteration number: [2010/4518] 44% | Training loss: 0.6871338410757074
Epoch: 76 | Iteration number: [2020/4518] 44% | Training loss: 0.6871293480443482
Epoch: 76 | Iteration number: [2030/4518] 44% | Training loss: 0.6871251071615172
Epoch: 76 | Iteration number: [2040/4518] 45% | Training loss: 0.687123881484948
Epoch: 76 | Iteration number: [2050/4518] 45% | Training loss: 0.6871243150059769
Epoch: 76 | Iteration number: [2060/4518] 45% | Training loss: 0.6871218107857751
Epoch: 76 | Iteration number: [2070/4518] 45% | Training loss: 0.6871207280723369
Epoch: 76 | Iteration number: [2080/4518] 46% | Training loss: 0.6871202606421251
Epoch: 76 | Iteration number: [2090/4518] 46% | Training loss: 0.6871199247369355
Epoch: 76 | Iteration number: [2100/4518] 46% | Training loss: 0.6871202103864579
Epoch: 76 | Iteration number: [2110/4518] 46% | Training loss: 0.6871145726662676
Epoch: 76 | Iteration number: [2120/4518] 46% | Training loss: 0.6871137022690953
Epoch: 76 | Iteration number: [2130/4518] 47% | Training loss: 0.6871150913093012
Epoch: 76 | Iteration number: [2140/4518] 47% | Training loss: 0.6871134698948014
Epoch: 76 | Iteration number: [2150/4518] 47% | Training loss: 0.6871061805514402
Epoch: 76 | Iteration number: [2160/4518] 47% | Training loss: 0.6871082335710526
Epoch: 76 | Iteration number: [2170/4518] 48% | Training loss: 0.6871099920316776
Epoch: 76 | Iteration number: [2180/4518] 48% | Training loss: 0.6871047987850434
Epoch: 76 | Iteration number: [2190/4518] 48% | Training loss: 0.6871014356885327
Epoch: 76 | Iteration number: [2200/4518] 48% | Training loss: 0.6870926729657433
Epoch: 76 | Iteration number: [2210/4518] 48% | Training loss: 0.6870887088829576
Epoch: 76 | Iteration number: [2220/4518] 49% | Training loss: 0.6870914355054631
Epoch: 76 | Iteration number: [2230/4518] 49% | Training loss: 0.687092443725988
Epoch: 76 | Iteration number: [2240/4518] 49% | Training loss: 0.6870927852445415
Epoch: 76 | Iteration number: [2250/4518] 49% | Training loss: 0.6870967078208924
Epoch: 76 | Iteration number: [2260/4518] 50% | Training loss: 0.6870988715011461
Epoch: 76 | Iteration number: [2270/4518] 50% | Training loss: 0.6870967053631853
Epoch: 76 | Iteration number: [2280/4518] 50% | Training loss: 0.6870984499914604
Epoch: 76 | Iteration number: [2290/4518] 50% | Training loss: 0.6870917145341765
Epoch: 76 | Iteration number: [2300/4518] 50% | Training loss: 0.6870972907024882
Epoch: 76 | Iteration number: [2310/4518] 51% | Training loss: 0.6870923879600707
Epoch: 76 | Iteration number: [2320/4518] 51% | Training loss: 0.6870861731469631
Epoch: 76 | Iteration number: [2330/4518] 51% | Training loss: 0.6870826034331015
Epoch: 76 | Iteration number: [2340/4518] 51% | Training loss: 0.6870783750827496
Epoch: 76 | Iteration number: [2350/4518] 52% | Training loss: 0.6870725038964698
Epoch: 76 | Iteration number: [2360/4518] 52% | Training loss: 0.6870659493541313
Epoch: 76 | Iteration number: [2370/4518] 52% | Training loss: 0.6870709504759261
Epoch: 76 | Iteration number: [2380/4518] 52% | Training loss: 0.6870716364694243
Epoch: 76 | Iteration number: [2390/4518] 52% | Training loss: 0.6870685414040937
Epoch: 76 | Iteration number: [2400/4518] 53% | Training loss: 0.6870732177545626
Epoch: 76 | Iteration number: [2410/4518] 53% | Training loss: 0.6870742920028718
Epoch: 76 | Iteration number: [2420/4518] 53% | Training loss: 0.6870746672153473
Epoch: 76 | Iteration number: [2430/4518] 53% | Training loss: 0.687074327542458
Epoch: 76 | Iteration number: [2440/4518] 54% | Training loss: 0.6870755278429047
Epoch: 76 | Iteration number: [2450/4518] 54% | Training loss: 0.6870729213101523
Epoch: 76 | Iteration number: [2460/4518] 54% | Training loss: 0.6870719222760782
Epoch: 76 | Iteration number: [2470/4518] 54% | Training loss: 0.6870715229134811
Epoch: 76 | Iteration number: [2480/4518] 54% | Training loss: 0.6870713344504756
Epoch: 76 | Iteration number: [2490/4518] 55% | Training loss: 0.687073475720892
Epoch: 76 | Iteration number: [2500/4518] 55% | Training loss: 0.6870735805749894
Epoch: 76 | Iteration number: [2510/4518] 55% | Training loss: 0.6870710858310837
Epoch: 76 | Iteration number: [2520/4518] 55% | Training loss: 0.6870700719810667
Epoch: 76 | Iteration number: [2530/4518] 55% | Training loss: 0.6870683181427213
Epoch: 76 | Iteration number: [2540/4518] 56% | Training loss: 0.6870670897519494
Epoch: 76 | Iteration number: [2550/4518] 56% | Training loss: 0.6870644994810515
Epoch: 76 | Iteration number: [2560/4518] 56% | Training loss: 0.6870628662174567
Epoch: 76 | Iteration number: [2570/4518] 56% | Training loss: 0.6870551999208993
Epoch: 76 | Iteration number: [2580/4518] 57% | Training loss: 0.6870556523171506
Epoch: 76 | Iteration number: [2590/4518] 57% | Training loss: 0.6870554418177218
Epoch: 76 | Iteration number: [2600/4518] 57% | Training loss: 0.6870547234782806
Epoch: 76 | Iteration number: [2610/4518] 57% | Training loss: 0.6870509741863529
Epoch: 76 | Iteration number: [2620/4518] 57% | Training loss: 0.6870503014735593
Epoch: 76 | Iteration number: [2630/4518] 58% | Training loss: 0.6870468159818831
Epoch: 76 | Iteration number: [2640/4518] 58% | Training loss: 0.6870414843387675
Epoch: 76 | Iteration number: [2650/4518] 58% | Training loss: 0.6870454631661469
Epoch: 76 | Iteration number: [2660/4518] 58% | Training loss: 0.6870449225481291
Epoch: 76 | Iteration number: [2670/4518] 59% | Training loss: 0.6870400147268388
Epoch: 76 | Iteration number: [2680/4518] 59% | Training loss: 0.6870371130865012
Epoch: 76 | Iteration number: [2690/4518] 59% | Training loss: 0.687034812602855
Epoch: 76 | Iteration number: [2700/4518] 59% | Training loss: 0.6870318345891104
Epoch: 76 | Iteration number: [2710/4518] 59% | Training loss: 0.6870323973388249
Epoch: 76 | Iteration number: [2720/4518] 60% | Training loss: 0.687032167043756
Epoch: 76 | Iteration number: [2730/4518] 60% | Training loss: 0.6870261668285608
Epoch: 76 | Iteration number: [2740/4518] 60% | Training loss: 0.6870253640369778
Epoch: 76 | Iteration number: [2750/4518] 60% | Training loss: 0.6870260754281824
Epoch: 76 | Iteration number: [2760/4518] 61% | Training loss: 0.6870212449543718
Epoch: 76 | Iteration number: [2770/4518] 61% | Training loss: 0.6870191030984321
Epoch: 76 | Iteration number: [2780/4518] 61% | Training loss: 0.6870193301988162
Epoch: 76 | Iteration number: [2790/4518] 61% | Training loss: 0.6870186370974373
Epoch: 76 | Iteration number: [2800/4518] 61% | Training loss: 0.6870214454403946
Epoch: 76 | Iteration number: [2810/4518] 62% | Training loss: 0.6870191732971693
Epoch: 76 | Iteration number: [2820/4518] 62% | Training loss: 0.6870182620718124
Epoch: 76 | Iteration number: [2830/4518] 62% | Training loss: 0.6870172230599204
Epoch: 76 | Iteration number: [2840/4518] 62% | Training loss: 0.6870158216483156
Epoch: 76 | Iteration number: [2850/4518] 63% | Training loss: 0.6870152037185535
Epoch: 76 | Iteration number: [2860/4518] 63% | Training loss: 0.6870149880647659
Epoch: 76 | Iteration number: [2870/4518] 63% | Training loss: 0.6870121323896202
Epoch: 76 | Iteration number: [2880/4518] 63% | Training loss: 0.6870127642113302
Epoch: 76 | Iteration number: [2890/4518] 63% | Training loss: 0.6870090290543117
Epoch: 76 | Iteration number: [2900/4518] 64% | Training loss: 0.6870073715160633
Epoch: 76 | Iteration number: [2910/4518] 64% | Training loss: 0.6870050425382005
Epoch: 76 | Iteration number: [2920/4518] 64% | Training loss: 0.6870019833519034
Epoch: 76 | Iteration number: [2930/4518] 64% | Training loss: 0.6870002086252076
Epoch: 76 | Iteration number: [2940/4518] 65% | Training loss: 0.6869970426875718
Epoch: 76 | Iteration number: [2950/4518] 65% | Training loss: 0.6869922312639527
Epoch: 76 | Iteration number: [2960/4518] 65% | Training loss: 0.6869865240881572
Epoch: 76 | Iteration number: [2970/4518] 65% | Training loss: 0.6869827491667134
Epoch: 76 | Iteration number: [2980/4518] 65% | Training loss: 0.6869858062507322
Epoch: 76 | Iteration number: [2990/4518] 66% | Training loss: 0.686986034410853
Epoch: 76 | Iteration number: [3000/4518] 66% | Training loss: 0.6869868956406912
Epoch: 76 | Iteration number: [3010/4518] 66% | Training loss: 0.6869881665785843
Epoch: 76 | Iteration number: [3020/4518] 66% | Training loss: 0.6869897506687025
Epoch: 76 | Iteration number: [3030/4518] 67% | Training loss: 0.6869880473062937
Epoch: 76 | Iteration number: [3040/4518] 67% | Training loss: 0.6869888823479414
Epoch: 76 | Iteration number: [3050/4518] 67% | Training loss: 0.6869895455485485
Epoch: 76 | Iteration number: [3060/4518] 67% | Training loss: 0.6869877291660683
Epoch: 76 | Iteration number: [3070/4518] 67% | Training loss: 0.6869904118562754
Epoch: 76 | Iteration number: [3080/4518] 68% | Training loss: 0.6869862875961638
Epoch: 76 | Iteration number: [3090/4518] 68% | Training loss: 0.686986935196571
Epoch: 76 | Iteration number: [3100/4518] 68% | Training loss: 0.6869869161805799
Epoch: 76 | Iteration number: [3110/4518] 68% | Training loss: 0.6869874234943144
Epoch: 76 | Iteration number: [3120/4518] 69% | Training loss: 0.6869868596967978
Epoch: 76 | Iteration number: [3130/4518] 69% | Training loss: 0.6869842527202144
Epoch: 76 | Iteration number: [3140/4518] 69% | Training loss: 0.6869854212946194
Epoch: 76 | Iteration number: [3150/4518] 69% | Training loss: 0.68698674835856
Epoch: 76 | Iteration number: [3160/4518] 69% | Training loss: 0.6869855863761298
Epoch: 76 | Iteration number: [3170/4518] 70% | Training loss: 0.6869871711505324
Epoch: 76 | Iteration number: [3180/4518] 70% | Training loss: 0.6869837903001773
Epoch: 76 | Iteration number: [3190/4518] 70% | Training loss: 0.6869821466248611
Epoch: 76 | Iteration number: [3200/4518] 70% | Training loss: 0.6869743646867573
Epoch: 76 | Iteration number: [3210/4518] 71% | Training loss: 0.6869712722821399
Epoch: 76 | Iteration number: [3220/4518] 71% | Training loss: 0.686975873904939
Epoch: 76 | Iteration number: [3230/4518] 71% | Training loss: 0.6869754586795536
Epoch: 76 | Iteration number: [3240/4518] 71% | Training loss: 0.6869771680714172
Epoch: 76 | Iteration number: [3250/4518] 71% | Training loss: 0.6869784337557279
Epoch: 76 | Iteration number: [3260/4518] 72% | Training loss: 0.686976849155192
Epoch: 76 | Iteration number: [3270/4518] 72% | Training loss: 0.6869792592634848
Epoch: 76 | Iteration number: [3280/4518] 72% | Training loss: 0.6869773970689715
Epoch: 76 | Iteration number: [3290/4518] 72% | Training loss: 0.6869745085123462
Epoch: 76 | Iteration number: [3300/4518] 73% | Training loss: 0.6869774210272414
Epoch: 76 | Iteration number: [3310/4518] 73% | Training loss: 0.6869753812375026
Epoch: 76 | Iteration number: [3320/4518] 73% | Training loss: 0.6869714570512254
Epoch: 76 | Iteration number: [3330/4518] 73% | Training loss: 0.6869705711578106
Epoch: 76 | Iteration number: [3340/4518] 73% | Training loss: 0.6869663728211455
Epoch: 76 | Iteration number: [3350/4518] 74% | Training loss: 0.6869656983596175
Epoch: 76 | Iteration number: [3360/4518] 74% | Training loss: 0.6869641950087888
Epoch: 76 | Iteration number: [3370/4518] 74% | Training loss: 0.6869649016008179
Epoch: 76 | Iteration number: [3380/4518] 74% | Training loss: 0.6869642262451747
Epoch: 76 | Iteration number: [3390/4518] 75% | Training loss: 0.6869644799942816
Epoch: 76 | Iteration number: [3400/4518] 75% | Training loss: 0.686964581626303
Epoch: 76 | Iteration number: [3410/4518] 75% | Training loss: 0.6869635040808982
Epoch: 76 | Iteration number: [3420/4518] 75% | Training loss: 0.686965195111364
Epoch: 76 | Iteration number: [3430/4518] 75% | Training loss: 0.6869632644486496
Epoch: 76 | Iteration number: [3440/4518] 76% | Training loss: 0.6869681525715562
Epoch: 76 | Iteration number: [3450/4518] 76% | Training loss: 0.6869649380531864
Epoch: 76 | Iteration number: [3460/4518] 76% | Training loss: 0.6869638655054776
Epoch: 76 | Iteration number: [3470/4518] 76% | Training loss: 0.6869655864898341
Epoch: 76 | Iteration number: [3480/4518] 77% | Training loss: 0.6869676809543851
Epoch: 76 | Iteration number: [3490/4518] 77% | Training loss: 0.6869632946044463
Epoch: 76 | Iteration number: [3500/4518] 77% | Training loss: 0.6869632002285548
Epoch: 76 | Iteration number: [3510/4518] 77% | Training loss: 0.6869615126539159
Epoch: 76 | Iteration number: [3520/4518] 77% | Training loss: 0.6869588093324142
Epoch: 76 | Iteration number: [3530/4518] 78% | Training loss: 0.6869580506096481
Epoch: 76 | Iteration number: [3540/4518] 78% | Training loss: 0.6869561060842148
Epoch: 76 | Iteration number: [3550/4518] 78% | Training loss: 0.6869529526502314
Epoch: 76 | Iteration number: [3560/4518] 78% | Training loss: 0.6869534775949596
Epoch: 76 | Iteration number: [3570/4518] 79% | Training loss: 0.6869535237133336
Epoch: 76 | Iteration number: [3580/4518] 79% | Training loss: 0.6869538688126889
Epoch: 76 | Iteration number: [3590/4518] 79% | Training loss: 0.6869523744065117
Epoch: 76 | Iteration number: [3600/4518] 79% | Training loss: 0.6869534979760646
Epoch: 76 | Iteration number: [3610/4518] 79% | Training loss: 0.6869537340967279
Epoch: 76 | Iteration number: [3620/4518] 80% | Training loss: 0.6869520862787468
Epoch: 76 | Iteration number: [3630/4518] 80% | Training loss: 0.6869572519106641
Epoch: 76 | Iteration number: [3640/4518] 80% | Training loss: 0.686953210061068
Epoch: 76 | Iteration number: [3650/4518] 80% | Training loss: 0.6869502990866361
Epoch: 76 | Iteration number: [3660/4518] 81% | Training loss: 0.6869474469801116
Epoch: 76 | Iteration number: [3670/4518] 81% | Training loss: 0.6869491587542708
Epoch: 76 | Iteration number: [3680/4518] 81% | Training loss: 0.6869489123639854
Epoch: 76 | Iteration number: [3690/4518] 81% | Training loss: 0.6869462965788233
Epoch: 76 | Iteration number: [3700/4518] 81% | Training loss: 0.6869488717897518
Epoch: 76 | Iteration number: [3710/4518] 82% | Training loss: 0.6869470739942998
Epoch: 76 | Iteration number: [3720/4518] 82% | Training loss: 0.6869496293285842
Epoch: 76 | Iteration number: [3730/4518] 82% | Training loss: 0.6869519019893923
Epoch: 76 | Iteration number: [3740/4518] 82% | Training loss: 0.6869515994653345
Epoch: 76 | Iteration number: [3750/4518] 83% | Training loss: 0.6869484612782796
Epoch: 76 | Iteration number: [3760/4518] 83% | Training loss: 0.6869481771233233
Epoch: 76 | Iteration number: [3770/4518] 83% | Training loss: 0.6869476583813483
Epoch: 76 | Iteration number: [3780/4518] 83% | Training loss: 0.6869450750805083
Epoch: 76 | Iteration number: [3790/4518] 83% | Training loss: 0.686948852457283
Epoch: 76 | Iteration number: [3800/4518] 84% | Training loss: 0.6869494327275376
Epoch: 76 | Iteration number: [3810/4518] 84% | Training loss: 0.6869487097257079
Epoch: 76 | Iteration number: [3820/4518] 84% | Training loss: 0.6869477197917968
Epoch: 76 | Iteration number: [3830/4518] 84% | Training loss: 0.686946819532011
Epoch: 76 | Iteration number: [3840/4518] 84% | Training loss: 0.6869482148904353
Epoch: 76 | Iteration number: [3850/4518] 85% | Training loss: 0.6869509020873479
Epoch: 76 | Iteration number: [3860/4518] 85% | Training loss: 0.6869457655002416
Epoch: 76 | Iteration number: [3870/4518] 85% | Training loss: 0.686948439378763
Epoch: 76 | Iteration number: [3880/4518] 85% | Training loss: 0.6869466878550569
Epoch: 76 | Iteration number: [3890/4518] 86% | Training loss: 0.6869443306732913
Epoch: 76 | Iteration number: [3900/4518] 86% | Training loss: 0.6869425832461088
Epoch: 76 | Iteration number: [3910/4518] 86% | Training loss: 0.6869412675385584
Epoch: 76 | Iteration number: [3920/4518] 86% | Training loss: 0.6869418337789117
Epoch: 76 | Iteration number: [3930/4518] 86% | Training loss: 0.6869381613403787
Epoch: 76 | Iteration number: [3940/4518] 87% | Training loss: 0.686937602628306
Epoch: 76 | Iteration number: [3950/4518] 87% | Training loss: 0.6869392446022999
Epoch: 76 | Iteration number: [3960/4518] 87% | Training loss: 0.6869375308204179
Epoch: 76 | Iteration number: [3970/4518] 87% | Training loss: 0.686935588754995
Epoch: 76 | Iteration number: [3980/4518] 88% | Training loss: 0.6869351455464435
Epoch: 76 | Iteration number: [3990/4518] 88% | Training loss: 0.686933583110795
Epoch: 76 | Iteration number: [4000/4518] 88% | Training loss: 0.6869329677075148
Epoch: 76 | Iteration number: [4010/4518] 88% | Training loss: 0.6869350577827701
Epoch: 76 | Iteration number: [4020/4518] 88% | Training loss: 0.6869341960297295
Epoch: 76 | Iteration number: [4030/4518] 89% | Training loss: 0.6869347600428105
Epoch: 76 | Iteration number: [4040/4518] 89% | Training loss: 0.6869353612313176
Epoch: 76 | Iteration number: [4050/4518] 89% | Training loss: 0.6869329517123139
Epoch: 76 | Iteration number: [4060/4518] 89% | Training loss: 0.6869339859984779
Epoch: 76 | Iteration number: [4070/4518] 90% | Training loss: 0.6869350161247816
Epoch: 76 | Iteration number: [4080/4518] 90% | Training loss: 0.6869363222490339
Epoch: 76 | Iteration number: [4090/4518] 90% | Training loss: 0.6869391387132677
Epoch: 76 | Iteration number: [4100/4518] 90% | Training loss: 0.6869389970273506
Epoch: 76 | Iteration number: [4110/4518] 90% | Training loss: 0.6869343721228505
Epoch: 76 | Iteration number: [4120/4518] 91% | Training loss: 0.6869353756453227
Epoch: 76 | Iteration number: [4130/4518] 91% | Training loss: 0.6869384615242337
Epoch: 76 | Iteration number: [4140/4518] 91% | Training loss: 0.6869385636515087
Epoch: 76 | Iteration number: [4150/4518] 91% | Training loss: 0.6869363462924958
Epoch: 76 | Iteration number: [4160/4518] 92% | Training loss: 0.6869364147432722
Epoch: 76 | Iteration number: [4170/4518] 92% | Training loss: 0.6869308973673722
Epoch: 76 | Iteration number: [4180/4518] 92% | Training loss: 0.686929203462943
Epoch: 76 | Iteration number: [4190/4518] 92% | Training loss: 0.6869275514578762
Epoch: 76 | Iteration number: [4200/4518] 92% | Training loss: 0.6869274113007954
Epoch: 76 | Iteration number: [4210/4518] 93% | Training loss: 0.6869227266368277
Epoch: 76 | Iteration number: [4220/4518] 93% | Training loss: 0.6869234356270018
Epoch: 76 | Iteration number: [4230/4518] 93% | Training loss: 0.6869234750175025
Epoch: 76 | Iteration number: [4240/4518] 93% | Training loss: 0.6869246970651285
Epoch: 76 | Iteration number: [4250/4518] 94% | Training loss: 0.6869250756011289
Epoch: 76 | Iteration number: [4260/4518] 94% | Training loss: 0.6869238638542068
Epoch: 76 | Iteration number: [4270/4518] 94% | Training loss: 0.6869203781355739
Epoch: 76 | Iteration number: [4280/4518] 94% | Training loss: 0.6869192017990852
Epoch: 76 | Iteration number: [4290/4518] 94% | Training loss: 0.686920083083195
Epoch: 76 | Iteration number: [4300/4518] 95% | Training loss: 0.6869236701033836
Epoch: 76 | Iteration number: [4310/4518] 95% | Training loss: 0.6869259525064526
Epoch: 76 | Iteration number: [4320/4518] 95% | Training loss: 0.6869234506592706
Epoch: 76 | Iteration number: [4330/4518] 95% | Training loss: 0.6869223913612321
Epoch: 76 | Iteration number: [4340/4518] 96% | Training loss: 0.6869244215812551
Epoch: 76 | Iteration number: [4350/4518] 96% | Training loss: 0.6869228129962395
Epoch: 76 | Iteration number: [4360/4518] 96% | Training loss: 0.6869236044654059
Epoch: 76 | Iteration number: [4370/4518] 96% | Training loss: 0.686927965917631
Epoch: 76 | Iteration number: [4380/4518] 96% | Training loss: 0.6869266956500267
Epoch: 76 | Iteration number: [4390/4518] 97% | Training loss: 0.6869264312377008
Epoch: 76 | Iteration number: [4400/4518] 97% | Training loss: 0.6869252296604893
Epoch: 76 | Iteration number: [4410/4518] 97% | Training loss: 0.6869274162516302
Epoch: 76 | Iteration number: [4420/4518] 97% | Training loss: 0.6869264051925004
Epoch: 76 | Iteration number: [4430/4518] 98% | Training loss: 0.6869282480287229
Epoch: 76 | Iteration number: [4440/4518] 98% | Training loss: 0.6869295828245782
Epoch: 76 | Iteration number: [4450/4518] 98% | Training loss: 0.6869281835770339
Epoch: 76 | Iteration number: [4460/4518] 98% | Training loss: 0.6869256964579826
Epoch: 76 | Iteration number: [4470/4518] 98% | Training loss: 0.6869284435806658
Epoch: 76 | Iteration number: [4480/4518] 99% | Training loss: 0.6869271398388914
Epoch: 76 | Iteration number: [4490/4518] 99% | Training loss: 0.6869274733326748
Epoch: 76 | Iteration number: [4500/4518] 99% | Training loss: 0.6869256563716465
Epoch: 76 | Iteration number: [4510/4518] 99% | Training loss: 0.6869211434525027

 End of epoch: 76 | Train Loss: 0.686769156553092 | Training Time: 641 

 End of epoch: 76 | Eval Loss: 0.6898100838369253 | Evaluating Time: 17 
Epoch: 77 | Iteration number: [10/4518] 0% | Training loss: 0.7551532804965972
Epoch: 77 | Iteration number: [20/4518] 0% | Training loss: 0.7211181342601776
Epoch: 77 | Iteration number: [30/4518] 0% | Training loss: 0.7092556734879811
Epoch: 77 | Iteration number: [40/4518] 0% | Training loss: 0.7032514214515686
Epoch: 77 | Iteration number: [50/4518] 1% | Training loss: 0.6999295151233673
Epoch: 77 | Iteration number: [60/4518] 1% | Training loss: 0.6976240575313568
Epoch: 77 | Iteration number: [70/4518] 1% | Training loss: 0.6959942502634866
Epoch: 77 | Iteration number: [80/4518] 1% | Training loss: 0.694859754294157
Epoch: 77 | Iteration number: [90/4518] 1% | Training loss: 0.69395775463846
Epoch: 77 | Iteration number: [100/4518] 2% | Training loss: 0.6932478231191636
Epoch: 77 | Iteration number: [110/4518] 2% | Training loss: 0.6926559583707289
Epoch: 77 | Iteration number: [120/4518] 2% | Training loss: 0.6922399957974752
Epoch: 77 | Iteration number: [130/4518] 2% | Training loss: 0.6917182385921479
Epoch: 77 | Iteration number: [140/4518] 3% | Training loss: 0.6914057097264699
Epoch: 77 | Iteration number: [150/4518] 3% | Training loss: 0.6910773356755574
Epoch: 77 | Iteration number: [160/4518] 3% | Training loss: 0.6908073514699936
Epoch: 77 | Iteration number: [170/4518] 3% | Training loss: 0.6906681320246528
Epoch: 77 | Iteration number: [180/4518] 3% | Training loss: 0.6904484073321024
Epoch: 77 | Iteration number: [190/4518] 4% | Training loss: 0.6902115385783346
Epoch: 77 | Iteration number: [200/4518] 4% | Training loss: 0.690062515437603
Epoch: 77 | Iteration number: [210/4518] 4% | Training loss: 0.6899539740312667
Epoch: 77 | Iteration number: [220/4518] 4% | Training loss: 0.6898585400798104
Epoch: 77 | Iteration number: [230/4518] 5% | Training loss: 0.6897813973219499
Epoch: 77 | Iteration number: [240/4518] 5% | Training loss: 0.6896676724155744
Epoch: 77 | Iteration number: [250/4518] 5% | Training loss: 0.6895601029396057
Epoch: 77 | Iteration number: [260/4518] 5% | Training loss: 0.6894936772493215
Epoch: 77 | Iteration number: [270/4518] 5% | Training loss: 0.6894291950596704
Epoch: 77 | Iteration number: [280/4518] 6% | Training loss: 0.6893829164760453
Epoch: 77 | Iteration number: [290/4518] 6% | Training loss: 0.689272268270624
Epoch: 77 | Iteration number: [300/4518] 6% | Training loss: 0.6891910660266877
Epoch: 77 | Iteration number: [310/4518] 6% | Training loss: 0.6891540479275489
Epoch: 77 | Iteration number: [320/4518] 7% | Training loss: 0.6891089949756861
Epoch: 77 | Iteration number: [330/4518] 7% | Training loss: 0.6890309252522209
Epoch: 77 | Iteration number: [340/4518] 7% | Training loss: 0.6889344511663212
Epoch: 77 | Iteration number: [350/4518] 7% | Training loss: 0.6888979041576385
Epoch: 77 | Iteration number: [360/4518] 7% | Training loss: 0.6888440201679865
Epoch: 77 | Iteration number: [370/4518] 8% | Training loss: 0.6888009949310406
Epoch: 77 | Iteration number: [380/4518] 8% | Training loss: 0.6887545707978701
Epoch: 77 | Iteration number: [390/4518] 8% | Training loss: 0.6887142104980273
Epoch: 77 | Iteration number: [400/4518] 8% | Training loss: 0.6886644320189953
Epoch: 77 | Iteration number: [410/4518] 9% | Training loss: 0.6885923278041002
Epoch: 77 | Iteration number: [420/4518] 9% | Training loss: 0.6885498312257585
Epoch: 77 | Iteration number: [430/4518] 9% | Training loss: 0.6884918754877046
Epoch: 77 | Iteration number: [440/4518] 9% | Training loss: 0.6884415768764236
Epoch: 77 | Iteration number: [450/4518] 9% | Training loss: 0.6883973507086436
Epoch: 77 | Iteration number: [460/4518] 10% | Training loss: 0.688354805889337
Epoch: 77 | Iteration number: [470/4518] 10% | Training loss: 0.6883144060347942
Epoch: 77 | Iteration number: [480/4518] 10% | Training loss: 0.6882681045681238
Epoch: 77 | Iteration number: [490/4518] 10% | Training loss: 0.6882622502288039
Epoch: 77 | Iteration number: [500/4518] 11% | Training loss: 0.6882120780944824
Epoch: 77 | Iteration number: [510/4518] 11% | Training loss: 0.6881899916658214
Epoch: 77 | Iteration number: [520/4518] 11% | Training loss: 0.688170866897473
Epoch: 77 | Iteration number: [530/4518] 11% | Training loss: 0.6881384820308325
Epoch: 77 | Iteration number: [540/4518] 11% | Training loss: 0.6881219538273635
Epoch: 77 | Iteration number: [550/4518] 12% | Training loss: 0.6880942977558483
Epoch: 77 | Iteration number: [560/4518] 12% | Training loss: 0.6880780567015921
Epoch: 77 | Iteration number: [570/4518] 12% | Training loss: 0.6880496952617378
Epoch: 77 | Iteration number: [580/4518] 12% | Training loss: 0.6880210094410798
Epoch: 77 | Iteration number: [590/4518] 13% | Training loss: 0.6880027384071027
Epoch: 77 | Iteration number: [600/4518] 13% | Training loss: 0.6879832513133685
Epoch: 77 | Iteration number: [610/4518] 13% | Training loss: 0.6879516297676525
Epoch: 77 | Iteration number: [620/4518] 13% | Training loss: 0.6879584697946426
Epoch: 77 | Iteration number: [630/4518] 13% | Training loss: 0.6879482247526684
Epoch: 77 | Iteration number: [640/4518] 14% | Training loss: 0.6879423395730555
Epoch: 77 | Iteration number: [650/4518] 14% | Training loss: 0.6879113923586332
Epoch: 77 | Iteration number: [660/4518] 14% | Training loss: 0.6878938163771774
Epoch: 77 | Iteration number: [670/4518] 14% | Training loss: 0.6878836791906784
Epoch: 77 | Iteration number: [680/4518] 15% | Training loss: 0.6878684432191007
Epoch: 77 | Iteration number: [690/4518] 15% | Training loss: 0.6878372198429661
Epoch: 77 | Iteration number: [700/4518] 15% | Training loss: 0.6878299231188638
Epoch: 77 | Iteration number: [710/4518] 15% | Training loss: 0.6878132465020032
Epoch: 77 | Iteration number: [720/4518] 15% | Training loss: 0.6877945627603266
Epoch: 77 | Iteration number: [730/4518] 16% | Training loss: 0.6877927498458183
Epoch: 77 | Iteration number: [740/4518] 16% | Training loss: 0.6877977958402118
Epoch: 77 | Iteration number: [750/4518] 16% | Training loss: 0.6877915503978729
Epoch: 77 | Iteration number: [760/4518] 16% | Training loss: 0.687784722761104
Epoch: 77 | Iteration number: [770/4518] 17% | Training loss: 0.6877721548080444
Epoch: 77 | Iteration number: [780/4518] 17% | Training loss: 0.6877783445975719
Epoch: 77 | Iteration number: [790/4518] 17% | Training loss: 0.6877769956105872
Epoch: 77 | Iteration number: [800/4518] 17% | Training loss: 0.6877622183412313
Epoch: 77 | Iteration number: [810/4518] 17% | Training loss: 0.6877270337240196
Epoch: 77 | Iteration number: [820/4518] 18% | Training loss: 0.6877230227720447
Epoch: 77 | Iteration number: [830/4518] 18% | Training loss: 0.6877070395343275
Epoch: 77 | Iteration number: [840/4518] 18% | Training loss: 0.6876993510694731
Epoch: 77 | Iteration number: [850/4518] 18% | Training loss: 0.6876965534687042
Epoch: 77 | Iteration number: [860/4518] 19% | Training loss: 0.6876887780982395
Epoch: 77 | Iteration number: [870/4518] 19% | Training loss: 0.6876743931194832
Epoch: 77 | Iteration number: [880/4518] 19% | Training loss: 0.6876509826969016
Epoch: 77 | Iteration number: [890/4518] 19% | Training loss: 0.6876397723562262
Epoch: 77 | Iteration number: [900/4518] 19% | Training loss: 0.6876399350828595
Epoch: 77 | Iteration number: [910/4518] 20% | Training loss: 0.6876378417015075
Epoch: 77 | Iteration number: [920/4518] 20% | Training loss: 0.6876282680941664
Epoch: 77 | Iteration number: [930/4518] 20% | Training loss: 0.687624567170297
Epoch: 77 | Iteration number: [940/4518] 20% | Training loss: 0.6876132795151244
Epoch: 77 | Iteration number: [950/4518] 21% | Training loss: 0.6875888460560848
Epoch: 77 | Iteration number: [960/4518] 21% | Training loss: 0.6875682960574826
Epoch: 77 | Iteration number: [970/4518] 21% | Training loss: 0.6875554007353242
Epoch: 77 | Iteration number: [980/4518] 21% | Training loss: 0.687536444469374
Epoch: 77 | Iteration number: [990/4518] 21% | Training loss: 0.687520233127806
Epoch: 77 | Iteration number: [1000/4518] 22% | Training loss: 0.6875163693428039
Epoch: 77 | Iteration number: [1010/4518] 22% | Training loss: 0.6875158319968988
Epoch: 77 | Iteration number: [1020/4518] 22% | Training loss: 0.68750953995714
Epoch: 77 | Iteration number: [1030/4518] 22% | Training loss: 0.6874964168349516
Epoch: 77 | Iteration number: [1040/4518] 23% | Training loss: 0.6874849480505173
Epoch: 77 | Iteration number: [1050/4518] 23% | Training loss: 0.6874790859790075
Epoch: 77 | Iteration number: [1060/4518] 23% | Training loss: 0.6874754365885033
Epoch: 77 | Iteration number: [1070/4518] 23% | Training loss: 0.6874664844196533
Epoch: 77 | Iteration number: [1080/4518] 23% | Training loss: 0.6874611912502183
Epoch: 77 | Iteration number: [1090/4518] 24% | Training loss: 0.6874560700644047
Epoch: 77 | Iteration number: [1100/4518] 24% | Training loss: 0.6874468327110463
Epoch: 77 | Iteration number: [1110/4518] 24% | Training loss: 0.6874274202295252
Epoch: 77 | Iteration number: [1120/4518] 24% | Training loss: 0.6874225101832833
Epoch: 77 | Iteration number: [1130/4518] 25% | Training loss: 0.687403560528713
Epoch: 77 | Iteration number: [1140/4518] 25% | Training loss: 0.6873942153495655
Epoch: 77 | Iteration number: [1150/4518] 25% | Training loss: 0.6873932860208595
Epoch: 77 | Iteration number: [1160/4518] 25% | Training loss: 0.6873753248617567
Epoch: 77 | Iteration number: [1170/4518] 25% | Training loss: 0.6873555718324124
Epoch: 77 | Iteration number: [1180/4518] 26% | Training loss: 0.6873418675135758
Epoch: 77 | Iteration number: [1190/4518] 26% | Training loss: 0.6873294952035952
Epoch: 77 | Iteration number: [1200/4518] 26% | Training loss: 0.6873231706023216
Epoch: 77 | Iteration number: [1210/4518] 26% | Training loss: 0.6873201171228708
Epoch: 77 | Iteration number: [1220/4518] 27% | Training loss: 0.6873020792105159
Epoch: 77 | Iteration number: [1230/4518] 27% | Training loss: 0.6873006634111327
Epoch: 77 | Iteration number: [1240/4518] 27% | Training loss: 0.6872876197580369
Epoch: 77 | Iteration number: [1250/4518] 27% | Training loss: 0.6872782414913178
Epoch: 77 | Iteration number: [1260/4518] 27% | Training loss: 0.6872681840544655
Epoch: 77 | Iteration number: [1270/4518] 28% | Training loss: 0.6872722587247533
Epoch: 77 | Iteration number: [1280/4518] 28% | Training loss: 0.6872725817374885
Epoch: 77 | Iteration number: [1290/4518] 28% | Training loss: 0.6872637814329576
Epoch: 77 | Iteration number: [1300/4518] 28% | Training loss: 0.6872655722728143
Epoch: 77 | Iteration number: [1310/4518] 28% | Training loss: 0.6872663495194821
Epoch: 77 | Iteration number: [1320/4518] 29% | Training loss: 0.6872722814480464
Epoch: 77 | Iteration number: [1330/4518] 29% | Training loss: 0.6872680100731383
Epoch: 77 | Iteration number: [1340/4518] 29% | Training loss: 0.687259777223886
Epoch: 77 | Iteration number: [1350/4518] 29% | Training loss: 0.6872510479114674
Epoch: 77 | Iteration number: [1360/4518] 30% | Training loss: 0.6872494720360812
Epoch: 77 | Iteration number: [1370/4518] 30% | Training loss: 0.6872505050070965
Epoch: 77 | Iteration number: [1380/4518] 30% | Training loss: 0.6872525209533995
Epoch: 77 | Iteration number: [1390/4518] 30% | Training loss: 0.6872474626671496
Epoch: 77 | Iteration number: [1400/4518] 30% | Training loss: 0.6872526440024376
Epoch: 77 | Iteration number: [1410/4518] 31% | Training loss: 0.6872364253017074
Epoch: 77 | Iteration number: [1420/4518] 31% | Training loss: 0.6872323030317333
Epoch: 77 | Iteration number: [1430/4518] 31% | Training loss: 0.6872232771003163
Epoch: 77 | Iteration number: [1440/4518] 31% | Training loss: 0.6872218131605122
Epoch: 77 | Iteration number: [1450/4518] 32% | Training loss: 0.6872168103168751
Epoch: 77 | Iteration number: [1460/4518] 32% | Training loss: 0.6872170261324269
Epoch: 77 | Iteration number: [1470/4518] 32% | Training loss: 0.6872157423674655
Epoch: 77 | Iteration number: [1480/4518] 32% | Training loss: 0.6872146744985839
Epoch: 77 | Iteration number: [1490/4518] 32% | Training loss: 0.6872136884887746
Epoch: 77 | Iteration number: [1500/4518] 33% | Training loss: 0.6872026389837265
Epoch: 77 | Iteration number: [1510/4518] 33% | Training loss: 0.6871995316041226
Epoch: 77 | Iteration number: [1520/4518] 33% | Training loss: 0.6871865494078712
Epoch: 77 | Iteration number: [1530/4518] 33% | Training loss: 0.6871863923431222
Epoch: 77 | Iteration number: [1540/4518] 34% | Training loss: 0.6871838380764057
Epoch: 77 | Iteration number: [1550/4518] 34% | Training loss: 0.687183531407387
Epoch: 77 | Iteration number: [1560/4518] 34% | Training loss: 0.6871825986947768
Epoch: 77 | Iteration number: [1570/4518] 34% | Training loss: 0.6871825695037842
Epoch: 77 | Iteration number: [1580/4518] 34% | Training loss: 0.6871833790329438
Epoch: 77 | Iteration number: [1590/4518] 35% | Training loss: 0.6871823716463533
Epoch: 77 | Iteration number: [1600/4518] 35% | Training loss: 0.6871783142164349
Epoch: 77 | Iteration number: [1610/4518] 35% | Training loss: 0.6871724448218849
Epoch: 77 | Iteration number: [1620/4518] 35% | Training loss: 0.6871740442735178
Epoch: 77 | Iteration number: [1630/4518] 36% | Training loss: 0.6871616310137181
Epoch: 77 | Iteration number: [1640/4518] 36% | Training loss: 0.6871594737579183
Epoch: 77 | Iteration number: [1650/4518] 36% | Training loss: 0.6871535560217771
Epoch: 77 | Iteration number: [1660/4518] 36% | Training loss: 0.6871398716087801
Epoch: 77 | Iteration number: [1670/4518] 36% | Training loss: 0.6871365850557111
Epoch: 77 | Iteration number: [1680/4518] 37% | Training loss: 0.6871394759842328
Epoch: 77 | Iteration number: [1690/4518] 37% | Training loss: 0.6871388509076023
Epoch: 77 | Iteration number: [1700/4518] 37% | Training loss: 0.6871326844832476
Epoch: 77 | Iteration number: [1710/4518] 37% | Training loss: 0.6871289335844809
Epoch: 77 | Iteration number: [1720/4518] 38% | Training loss: 0.6871308159343031
Epoch: 77 | Iteration number: [1730/4518] 38% | Training loss: 0.6871298022697426
Epoch: 77 | Iteration number: [1740/4518] 38% | Training loss: 0.6871183140867058
Epoch: 77 | Iteration number: [1750/4518] 38% | Training loss: 0.6871182394368308
Epoch: 77 | Iteration number: [1760/4518] 38% | Training loss: 0.6871237983080474
Epoch: 77 | Iteration number: [1770/4518] 39% | Training loss: 0.6871267175943838
Epoch: 77 | Iteration number: [1780/4518] 39% | Training loss: 0.6871247696742583
Epoch: 77 | Iteration number: [1790/4518] 39% | Training loss: 0.687126883048585
Epoch: 77 | Iteration number: [1800/4518] 39% | Training loss: 0.6871251866883702
Epoch: 77 | Iteration number: [1810/4518] 40% | Training loss: 0.6871231952754173
Epoch: 77 | Iteration number: [1820/4518] 40% | Training loss: 0.6871249079704285
Epoch: 77 | Iteration number: [1830/4518] 40% | Training loss: 0.687126101724437
Epoch: 77 | Iteration number: [1840/4518] 40% | Training loss: 0.6871292166411876
Epoch: 77 | Iteration number: [1850/4518] 40% | Training loss: 0.6871244191479039
Epoch: 77 | Iteration number: [1860/4518] 41% | Training loss: 0.6871227552493413
Epoch: 77 | Iteration number: [1870/4518] 41% | Training loss: 0.6871255944756901
Epoch: 77 | Iteration number: [1880/4518] 41% | Training loss: 0.6871262779261204
Epoch: 77 | Iteration number: [1890/4518] 41% | Training loss: 0.6871206002891379
Epoch: 77 | Iteration number: [1900/4518] 42% | Training loss: 0.6871239166824441
Epoch: 77 | Iteration number: [1910/4518] 42% | Training loss: 0.6871277825058443
Epoch: 77 | Iteration number: [1920/4518] 42% | Training loss: 0.6871236335175733
Epoch: 77 | Iteration number: [1930/4518] 42% | Training loss: 0.6871236898429653
Epoch: 77 | Iteration number: [1940/4518] 42% | Training loss: 0.6871215636582718
Epoch: 77 | Iteration number: [1950/4518] 43% | Training loss: 0.6871185718744229
Epoch: 77 | Iteration number: [1960/4518] 43% | Training loss: 0.6871180049923001
Epoch: 77 | Iteration number: [1970/4518] 43% | Training loss: 0.6871168024346308
Epoch: 77 | Iteration number: [1980/4518] 43% | Training loss: 0.687113318027872
Epoch: 77 | Iteration number: [1990/4518] 44% | Training loss: 0.6871085503892084
Epoch: 77 | Iteration number: [2000/4518] 44% | Training loss: 0.6870986359119415
Epoch: 77 | Iteration number: [2010/4518] 44% | Training loss: 0.6870964084098589
Epoch: 77 | Iteration number: [2020/4518] 44% | Training loss: 0.6870965366316314
Epoch: 77 | Iteration number: [2030/4518] 44% | Training loss: 0.687091678410328
Epoch: 77 | Iteration number: [2040/4518] 45% | Training loss: 0.6870882152342329
Epoch: 77 | Iteration number: [2050/4518] 45% | Training loss: 0.687085578179941
Epoch: 77 | Iteration number: [2060/4518] 45% | Training loss: 0.6870902263713115
Epoch: 77 | Iteration number: [2070/4518] 45% | Training loss: 0.6870864092151899
Epoch: 77 | Iteration number: [2080/4518] 46% | Training loss: 0.6870881111576007
Epoch: 77 | Iteration number: [2090/4518] 46% | Training loss: 0.6870908543824009
Epoch: 77 | Iteration number: [2100/4518] 46% | Training loss: 0.6870923063868568
Epoch: 77 | Iteration number: [2110/4518] 46% | Training loss: 0.6870896483767089
Epoch: 77 | Iteration number: [2120/4518] 46% | Training loss: 0.6870873073361955
Epoch: 77 | Iteration number: [2130/4518] 47% | Training loss: 0.6870890630522805
Epoch: 77 | Iteration number: [2140/4518] 47% | Training loss: 0.6870797159794335
Epoch: 77 | Iteration number: [2150/4518] 47% | Training loss: 0.6870812393066495
Epoch: 77 | Iteration number: [2160/4518] 47% | Training loss: 0.68707415431186
Epoch: 77 | Iteration number: [2170/4518] 48% | Training loss: 0.6870740947086141
Epoch: 77 | Iteration number: [2180/4518] 48% | Training loss: 0.6870753350881261
Epoch: 77 | Iteration number: [2190/4518] 48% | Training loss: 0.687071953162755
Epoch: 77 | Iteration number: [2200/4518] 48% | Training loss: 0.6870692433281378
Epoch: 77 | Iteration number: [2210/4518] 48% | Training loss: 0.6870706650466402
Epoch: 77 | Iteration number: [2220/4518] 49% | Training loss: 0.6870716683767938
Epoch: 77 | Iteration number: [2230/4518] 49% | Training loss: 0.6870670153153852
Epoch: 77 | Iteration number: [2240/4518] 49% | Training loss: 0.6870660632582647
Epoch: 77 | Iteration number: [2250/4518] 49% | Training loss: 0.6870641581747267
Epoch: 77 | Iteration number: [2260/4518] 50% | Training loss: 0.6870691205284237
Epoch: 77 | Iteration number: [2270/4518] 50% | Training loss: 0.687064676767929
Epoch: 77 | Iteration number: [2280/4518] 50% | Training loss: 0.687059776328112
Epoch: 77 | Iteration number: [2290/4518] 50% | Training loss: 0.6870637745055569
Epoch: 77 | Iteration number: [2300/4518] 50% | Training loss: 0.6870553016662597
Epoch: 77 | Iteration number: [2310/4518] 51% | Training loss: 0.6870518570596521
Epoch: 77 | Iteration number: [2320/4518] 51% | Training loss: 0.6870479579115736
Epoch: 77 | Iteration number: [2330/4518] 51% | Training loss: 0.687041342693337
Epoch: 77 | Iteration number: [2340/4518] 51% | Training loss: 0.6870412038177507
Epoch: 77 | Iteration number: [2350/4518] 52% | Training loss: 0.6870392977684102
Epoch: 77 | Iteration number: [2360/4518] 52% | Training loss: 0.6870342488258572
Epoch: 77 | Iteration number: [2370/4518] 52% | Training loss: 0.6870347293117378
Epoch: 77 | Iteration number: [2380/4518] 52% | Training loss: 0.687036034539968
Epoch: 77 | Iteration number: [2390/4518] 52% | Training loss: 0.6870323097855476
Epoch: 77 | Iteration number: [2400/4518] 53% | Training loss: 0.6870321103433767
Epoch: 77 | Iteration number: [2410/4518] 53% | Training loss: 0.6870360909903198
Epoch: 77 | Iteration number: [2420/4518] 53% | Training loss: 0.687033425111416
Epoch: 77 | Iteration number: [2430/4518] 53% | Training loss: 0.6870298117767145
Epoch: 77 | Iteration number: [2440/4518] 54% | Training loss: 0.6870285046149472
Epoch: 77 | Iteration number: [2450/4518] 54% | Training loss: 0.6870264822123002
Epoch: 77 | Iteration number: [2460/4518] 54% | Training loss: 0.6870337553140594
Epoch: 77 | Iteration number: [2470/4518] 54% | Training loss: 0.6870355586050011
Epoch: 77 | Iteration number: [2480/4518] 54% | Training loss: 0.6870336756350532
Epoch: 77 | Iteration number: [2490/4518] 55% | Training loss: 0.6870333821898005
Epoch: 77 | Iteration number: [2500/4518] 55% | Training loss: 0.6870316197395324
Epoch: 77 | Iteration number: [2510/4518] 55% | Training loss: 0.6870289850282479
Epoch: 77 | Iteration number: [2520/4518] 55% | Training loss: 0.6870282349841935
Epoch: 77 | Iteration number: [2530/4518] 55% | Training loss: 0.6870261063217645
Epoch: 77 | Iteration number: [2540/4518] 56% | Training loss: 0.6870234546698923
Epoch: 77 | Iteration number: [2550/4518] 56% | Training loss: 0.687029309389638
Epoch: 77 | Iteration number: [2560/4518] 56% | Training loss: 0.6870276809670031
Epoch: 77 | Iteration number: [2570/4518] 56% | Training loss: 0.6870218398506075
Epoch: 77 | Iteration number: [2580/4518] 57% | Training loss: 0.6870198288629221
Epoch: 77 | Iteration number: [2590/4518] 57% | Training loss: 0.6870144673756191
Epoch: 77 | Iteration number: [2600/4518] 57% | Training loss: 0.6870045979435627
Epoch: 77 | Iteration number: [2610/4518] 57% | Training loss: 0.6869995443300269
Epoch: 77 | Iteration number: [2620/4518] 57% | Training loss: 0.6869980393475249
Epoch: 77 | Iteration number: [2630/4518] 58% | Training loss: 0.6870008914189647
Epoch: 77 | Iteration number: [2640/4518] 58% | Training loss: 0.6870015512135896
Epoch: 77 | Iteration number: [2650/4518] 58% | Training loss: 0.6870018817793648
Epoch: 77 | Iteration number: [2660/4518] 58% | Training loss: 0.6870033217327935
Epoch: 77 | Iteration number: [2670/4518] 59% | Training loss: 0.6870073654901668
Epoch: 77 | Iteration number: [2680/4518] 59% | Training loss: 0.6870087141866115
Epoch: 77 | Iteration number: [2690/4518] 59% | Training loss: 0.6870091551298546
Epoch: 77 | Iteration number: [2700/4518] 59% | Training loss: 0.6870111839859574
Epoch: 77 | Iteration number: [2710/4518] 59% | Training loss: 0.6870118417863036
Epoch: 77 | Iteration number: [2720/4518] 60% | Training loss: 0.6870087318122386
Epoch: 77 | Iteration number: [2730/4518] 60% | Training loss: 0.6870018799663027
Epoch: 77 | Iteration number: [2740/4518] 60% | Training loss: 0.6869992950536908
Epoch: 77 | Iteration number: [2750/4518] 60% | Training loss: 0.6869961767846888
Epoch: 77 | Iteration number: [2760/4518] 61% | Training loss: 0.6869963695173679
Epoch: 77 | Iteration number: [2770/4518] 61% | Training loss: 0.6869970547593458
Epoch: 77 | Iteration number: [2780/4518] 61% | Training loss: 0.6869981473941598
Epoch: 77 | Iteration number: [2790/4518] 61% | Training loss: 0.6869986787064528
Epoch: 77 | Iteration number: [2800/4518] 61% | Training loss: 0.6870017454241003
Epoch: 77 | Iteration number: [2810/4518] 62% | Training loss: 0.6870002745733567
Epoch: 77 | Iteration number: [2820/4518] 62% | Training loss: 0.6869968578747824
Epoch: 77 | Iteration number: [2830/4518] 62% | Training loss: 0.6869932730501195
Epoch: 77 | Iteration number: [2840/4518] 62% | Training loss: 0.6869931116280421
Epoch: 77 | Iteration number: [2850/4518] 63% | Training loss: 0.686991995991322
Epoch: 77 | Iteration number: [2860/4518] 63% | Training loss: 0.6869918123825447
Epoch: 77 | Iteration number: [2870/4518] 63% | Training loss: 0.6869939551536215
Epoch: 77 | Iteration number: [2880/4518] 63% | Training loss: 0.6869935133597918
Epoch: 77 | Iteration number: [2890/4518] 63% | Training loss: 0.6869916126596062
Epoch: 77 | Iteration number: [2900/4518] 64% | Training loss: 0.6869874264865086
Epoch: 77 | Iteration number: [2910/4518] 64% | Training loss: 0.6869868753701961
Epoch: 77 | Iteration number: [2920/4518] 64% | Training loss: 0.6869880128192575
Epoch: 77 | Iteration number: [2930/4518] 64% | Training loss: 0.6869898222005408
Epoch: 77 | Iteration number: [2940/4518] 65% | Training loss: 0.6869848882868177
Epoch: 77 | Iteration number: [2950/4518] 65% | Training loss: 0.6869836106340764
Epoch: 77 | Iteration number: [2960/4518] 65% | Training loss: 0.6869855334428516
Epoch: 77 | Iteration number: [2970/4518] 65% | Training loss: 0.6869859224417394
Epoch: 77 | Iteration number: [2980/4518] 65% | Training loss: 0.6869847741703059
Epoch: 77 | Iteration number: [2990/4518] 66% | Training loss: 0.6869828664538853
Epoch: 77 | Iteration number: [3000/4518] 66% | Training loss: 0.68698651689291
Epoch: 77 | Iteration number: [3010/4518] 66% | Training loss: 0.6869850579884361
Epoch: 77 | Iteration number: [3020/4518] 66% | Training loss: 0.6869837975659907
Epoch: 77 | Iteration number: [3030/4518] 67% | Training loss: 0.6869781480764005
Epoch: 77 | Iteration number: [3040/4518] 67% | Training loss: 0.6869799802373898
Epoch: 77 | Iteration number: [3050/4518] 67% | Training loss: 0.6869834402936403
Epoch: 77 | Iteration number: [3060/4518] 67% | Training loss: 0.6869853955078749
Epoch: 77 | Iteration number: [3070/4518] 67% | Training loss: 0.6869864857740433
Epoch: 77 | Iteration number: [3080/4518] 68% | Training loss: 0.6869814850293197
Epoch: 77 | Iteration number: [3090/4518] 68% | Training loss: 0.6869787287750676
Epoch: 77 | Iteration number: [3100/4518] 68% | Training loss: 0.6869710188527262
Epoch: 77 | Iteration number: [3110/4518] 68% | Training loss: 0.686972415964703
Epoch: 77 | Iteration number: [3120/4518] 69% | Training loss: 0.6869747357490735
Epoch: 77 | Iteration number: [3130/4518] 69% | Training loss: 0.686971746104213
Epoch: 77 | Iteration number: [3140/4518] 69% | Training loss: 0.686971672515201
Epoch: 77 | Iteration number: [3150/4518] 69% | Training loss: 0.6869750446364993
Epoch: 77 | Iteration number: [3160/4518] 69% | Training loss: 0.6869713368295114
Epoch: 77 | Iteration number: [3170/4518] 70% | Training loss: 0.6869747216205115
Epoch: 77 | Iteration number: [3180/4518] 70% | Training loss: 0.6869734054466463
Epoch: 77 | Iteration number: [3190/4518] 70% | Training loss: 0.6869722441072375
Epoch: 77 | Iteration number: [3200/4518] 70% | Training loss: 0.6869653284549713
Epoch: 77 | Iteration number: [3210/4518] 71% | Training loss: 0.6869664183101178
Epoch: 77 | Iteration number: [3220/4518] 71% | Training loss: 0.6869624723188625
Epoch: 77 | Iteration number: [3230/4518] 71% | Training loss: 0.6869601882279104
Epoch: 77 | Iteration number: [3240/4518] 71% | Training loss: 0.6869598043737588
Epoch: 77 | Iteration number: [3250/4518] 71% | Training loss: 0.6869612108744108
Epoch: 77 | Iteration number: [3260/4518] 72% | Training loss: 0.686960510626161
Epoch: 77 | Iteration number: [3270/4518] 72% | Training loss: 0.6869589807790354
Epoch: 77 | Iteration number: [3280/4518] 72% | Training loss: 0.6869593957030191
Epoch: 77 | Iteration number: [3290/4518] 72% | Training loss: 0.6869611821276076
Epoch: 77 | Iteration number: [3300/4518] 73% | Training loss: 0.6869594843821092
Epoch: 77 | Iteration number: [3310/4518] 73% | Training loss: 0.6869607319644571
Epoch: 77 | Iteration number: [3320/4518] 73% | Training loss: 0.6869586264692157
Epoch: 77 | Iteration number: [3330/4518] 73% | Training loss: 0.686954169337814
Epoch: 77 | Iteration number: [3340/4518] 73% | Training loss: 0.686954708781071
Epoch: 77 | Iteration number: [3350/4518] 74% | Training loss: 0.6869519671931196
Epoch: 77 | Iteration number: [3360/4518] 74% | Training loss: 0.6869513503852345
Epoch: 77 | Iteration number: [3370/4518] 74% | Training loss: 0.6869503180068042
Epoch: 77 | Iteration number: [3380/4518] 74% | Training loss: 0.6869517099927869
Epoch: 77 | Iteration number: [3390/4518] 75% | Training loss: 0.6869540532957488
Epoch: 77 | Iteration number: [3400/4518] 75% | Training loss: 0.6869515458976522
Epoch: 77 | Iteration number: [3410/4518] 75% | Training loss: 0.6869523839517073
Epoch: 77 | Iteration number: [3420/4518] 75% | Training loss: 0.686952012812185
Epoch: 77 | Iteration number: [3430/4518] 75% | Training loss: 0.6869518709599798
Epoch: 77 | Iteration number: [3440/4518] 76% | Training loss: 0.6869542667165746
Epoch: 77 | Iteration number: [3450/4518] 76% | Training loss: 0.6869536652599556
Epoch: 77 | Iteration number: [3460/4518] 76% | Training loss: 0.6869540320138711
Epoch: 77 | Iteration number: [3470/4518] 76% | Training loss: 0.6869519724969562
Epoch: 77 | Iteration number: [3480/4518] 77% | Training loss: 0.6869520876085621
Epoch: 77 | Iteration number: [3490/4518] 77% | Training loss: 0.6869541813787553
Epoch: 77 | Iteration number: [3500/4518] 77% | Training loss: 0.6869528623649053
Epoch: 77 | Iteration number: [3510/4518] 77% | Training loss: 0.6869542960597579
Epoch: 77 | Iteration number: [3520/4518] 77% | Training loss: 0.6869540336626497
Epoch: 77 | Iteration number: [3530/4518] 78% | Training loss: 0.6869548448084434
Epoch: 77 | Iteration number: [3540/4518] 78% | Training loss: 0.6869532942435163
Epoch: 77 | Iteration number: [3550/4518] 78% | Training loss: 0.6869556423140244
Epoch: 77 | Iteration number: [3560/4518] 78% | Training loss: 0.6869537658236
Epoch: 77 | Iteration number: [3570/4518] 79% | Training loss: 0.6869543248531865
Epoch: 77 | Iteration number: [3580/4518] 79% | Training loss: 0.6869556691726493
Epoch: 77 | Iteration number: [3590/4518] 79% | Training loss: 0.6869521583521266
Epoch: 77 | Iteration number: [3600/4518] 79% | Training loss: 0.6869507501688269
Epoch: 77 | Iteration number: [3610/4518] 79% | Training loss: 0.6869467390045895
Epoch: 77 | Iteration number: [3620/4518] 80% | Training loss: 0.6869470602899626
Epoch: 77 | Iteration number: [3630/4518] 80% | Training loss: 0.6869489741555258
Epoch: 77 | Iteration number: [3640/4518] 80% | Training loss: 0.686947984780584
Epoch: 77 | Iteration number: [3650/4518] 80% | Training loss: 0.6869463856089605
Epoch: 77 | Iteration number: [3660/4518] 81% | Training loss: 0.6869463044111845
Epoch: 77 | Iteration number: [3670/4518] 81% | Training loss: 0.6869450666274297
Epoch: 77 | Iteration number: [3680/4518] 81% | Training loss: 0.6869440245725539
Epoch: 77 | Iteration number: [3690/4518] 81% | Training loss: 0.686944965117669
Epoch: 77 | Iteration number: [3700/4518] 81% | Training loss: 0.6869458586460835
Epoch: 77 | Iteration number: [3710/4518] 82% | Training loss: 0.6869457333396387
Epoch: 77 | Iteration number: [3720/4518] 82% | Training loss: 0.6869447388315714
Epoch: 77 | Iteration number: [3730/4518] 82% | Training loss: 0.6869448044025227
Epoch: 77 | Iteration number: [3740/4518] 82% | Training loss: 0.6869455381829471
Epoch: 77 | Iteration number: [3750/4518] 83% | Training loss: 0.6869465763092041
Epoch: 77 | Iteration number: [3760/4518] 83% | Training loss: 0.6869483047343315
Epoch: 77 | Iteration number: [3770/4518] 83% | Training loss: 0.686948182633448
Epoch: 77 | Iteration number: [3780/4518] 83% | Training loss: 0.6869484430267697
Epoch: 77 | Iteration number: [3790/4518] 83% | Training loss: 0.6869473151135256
Epoch: 77 | Iteration number: [3800/4518] 84% | Training loss: 0.6869484058806771
Epoch: 77 | Iteration number: [3810/4518] 84% | Training loss: 0.6869502654538693
Epoch: 77 | Iteration number: [3820/4518] 84% | Training loss: 0.6869449158457561
Epoch: 77 | Iteration number: [3830/4518] 84% | Training loss: 0.6869470121810703
Epoch: 77 | Iteration number: [3840/4518] 84% | Training loss: 0.6869462372269481
Epoch: 77 | Iteration number: [3850/4518] 85% | Training loss: 0.6869478744810278
Epoch: 77 | Iteration number: [3860/4518] 85% | Training loss: 0.6869466738070849
Epoch: 77 | Iteration number: [3870/4518] 85% | Training loss: 0.6869473546974418
Epoch: 77 | Iteration number: [3880/4518] 85% | Training loss: 0.6869453523423253
Epoch: 77 | Iteration number: [3890/4518] 86% | Training loss: 0.6869455938474072
Epoch: 77 | Iteration number: [3900/4518] 86% | Training loss: 0.6869379662703246
Epoch: 77 | Iteration number: [3910/4518] 86% | Training loss: 0.6869420655395674
Epoch: 77 | Iteration number: [3920/4518] 86% | Training loss: 0.6869426013103553
Epoch: 77 | Iteration number: [3930/4518] 86% | Training loss: 0.6869441245500064
Epoch: 77 | Iteration number: [3940/4518] 87% | Training loss: 0.6869442007868423
Epoch: 77 | Iteration number: [3950/4518] 87% | Training loss: 0.6869417992875546
Epoch: 77 | Iteration number: [3960/4518] 87% | Training loss: 0.6869403395538378
Epoch: 77 | Iteration number: [3970/4518] 87% | Training loss: 0.6869385797671167
Epoch: 77 | Iteration number: [3980/4518] 88% | Training loss: 0.6869394314348998
Epoch: 77 | Iteration number: [3990/4518] 88% | Training loss: 0.6869359298756248
Epoch: 77 | Iteration number: [4000/4518] 88% | Training loss: 0.6869358691126108
Epoch: 77 | Iteration number: [4010/4518] 88% | Training loss: 0.6869359503660416
Epoch: 77 | Iteration number: [4020/4518] 88% | Training loss: 0.6869343284202453
Epoch: 77 | Iteration number: [4030/4518] 89% | Training loss: 0.6869374998597886
Epoch: 77 | Iteration number: [4040/4518] 89% | Training loss: 0.6869369188305174
Epoch: 77 | Iteration number: [4050/4518] 89% | Training loss: 0.6869363715766389
Epoch: 77 | Iteration number: [4060/4518] 89% | Training loss: 0.6869349180624402
Epoch: 77 | Iteration number: [4070/4518] 90% | Training loss: 0.6869338364653856
Epoch: 77 | Iteration number: [4080/4518] 90% | Training loss: 0.6869356049334302
Epoch: 77 | Iteration number: [4090/4518] 90% | Training loss: 0.6869308043517227
Epoch: 77 | Iteration number: [4100/4518] 90% | Training loss: 0.686929303102377
Epoch: 77 | Iteration number: [4110/4518] 90% | Training loss: 0.686924679363441
Epoch: 77 | Iteration number: [4120/4518] 91% | Training loss: 0.6869224511014606
Epoch: 77 | Iteration number: [4130/4518] 91% | Training loss: 0.6869252585902919
Epoch: 77 | Iteration number: [4140/4518] 91% | Training loss: 0.6869222574187938
Epoch: 77 | Iteration number: [4150/4518] 91% | Training loss: 0.6869223795885063
Epoch: 77 | Iteration number: [4160/4518] 92% | Training loss: 0.6869200673384163
Epoch: 77 | Iteration number: [4170/4518] 92% | Training loss: 0.6869204112379957
Epoch: 77 | Iteration number: [4180/4518] 92% | Training loss: 0.6869193331476604
Epoch: 77 | Iteration number: [4190/4518] 92% | Training loss: 0.6869205431465887
Epoch: 77 | Iteration number: [4200/4518] 92% | Training loss: 0.6869191572921617
Epoch: 77 | Iteration number: [4210/4518] 93% | Training loss: 0.6869230168024322
Epoch: 77 | Iteration number: [4220/4518] 93% | Training loss: 0.6869222915850545
Epoch: 77 | Iteration number: [4230/4518] 93% | Training loss: 0.6869227485594738
Epoch: 77 | Iteration number: [4240/4518] 93% | Training loss: 0.6869219246337999
Epoch: 77 | Iteration number: [4250/4518] 94% | Training loss: 0.6869213052216698
Epoch: 77 | Iteration number: [4260/4518] 94% | Training loss: 0.6869199854247446
Epoch: 77 | Iteration number: [4270/4518] 94% | Training loss: 0.6869210653757323
Epoch: 77 | Iteration number: [4280/4518] 94% | Training loss: 0.6869213631777006
Epoch: 77 | Iteration number: [4290/4518] 94% | Training loss: 0.6869195790557595
Epoch: 77 | Iteration number: [4300/4518] 95% | Training loss: 0.6869145318935084
Epoch: 77 | Iteration number: [4310/4518] 95% | Training loss: 0.6869127736014169
Epoch: 77 | Iteration number: [4320/4518] 95% | Training loss: 0.6869153274016248
Epoch: 77 | Iteration number: [4330/4518] 95% | Training loss: 0.6869157362617466
Epoch: 77 | Iteration number: [4340/4518] 96% | Training loss: 0.6869163743911251
Epoch: 77 | Iteration number: [4350/4518] 96% | Training loss: 0.6869175545511574
Epoch: 77 | Iteration number: [4360/4518] 96% | Training loss: 0.6869185986322001
Epoch: 77 | Iteration number: [4370/4518] 96% | Training loss: 0.6869200091067387
Epoch: 77 | Iteration number: [4380/4518] 96% | Training loss: 0.6869192884529018
Epoch: 77 | Iteration number: [4390/4518] 97% | Training loss: 0.6869199196814405
Epoch: 77 | Iteration number: [4400/4518] 97% | Training loss: 0.686918323581869
Epoch: 77 | Iteration number: [4410/4518] 97% | Training loss: 0.6869212417105158
Epoch: 77 | Iteration number: [4420/4518] 97% | Training loss: 0.686920891978622
Epoch: 77 | Iteration number: [4430/4518] 98% | Training loss: 0.6869202660518628
Epoch: 77 | Iteration number: [4440/4518] 98% | Training loss: 0.6869195797287666
Epoch: 77 | Iteration number: [4450/4518] 98% | Training loss: 0.6869198560045007
Epoch: 77 | Iteration number: [4460/4518] 98% | Training loss: 0.6869190497783267
Epoch: 77 | Iteration number: [4470/4518] 98% | Training loss: 0.6869152948627003
Epoch: 77 | Iteration number: [4480/4518] 99% | Training loss: 0.6869163278224213
Epoch: 77 | Iteration number: [4490/4518] 99% | Training loss: 0.6869145516563364
Epoch: 77 | Iteration number: [4500/4518] 99% | Training loss: 0.6869178892109129
Epoch: 77 | Iteration number: [4510/4518] 99% | Training loss: 0.6869197204609933

 End of epoch: 77 | Train Loss: 0.6867680944215412 | Training Time: 639 

 End of epoch: 77 | Eval Loss: 0.6898303567146769 | Evaluating Time: 17 
Epoch: 78 | Iteration number: [10/4518] 0% | Training loss: 0.7543242394924163
Epoch: 78 | Iteration number: [20/4518] 0% | Training loss: 0.7205947488546371
Epoch: 78 | Iteration number: [30/4518] 0% | Training loss: 0.7091545820236206
Epoch: 78 | Iteration number: [40/4518] 0% | Training loss: 0.7035925522446632
Epoch: 78 | Iteration number: [50/4518] 1% | Training loss: 0.7000526773929596
Epoch: 78 | Iteration number: [60/4518] 1% | Training loss: 0.6977702915668488
Epoch: 78 | Iteration number: [70/4518] 1% | Training loss: 0.6962631472519466
Epoch: 78 | Iteration number: [80/4518] 1% | Training loss: 0.6951169371604919
Epoch: 78 | Iteration number: [90/4518] 1% | Training loss: 0.6941588819026947
Epoch: 78 | Iteration number: [100/4518] 2% | Training loss: 0.6933961135149002
Epoch: 78 | Iteration number: [110/4518] 2% | Training loss: 0.6927696060050618
Epoch: 78 | Iteration number: [120/4518] 2% | Training loss: 0.6923002491394679
Epoch: 78 | Iteration number: [130/4518] 2% | Training loss: 0.6920130014419555
Epoch: 78 | Iteration number: [140/4518] 3% | Training loss: 0.6916338286229542
Epoch: 78 | Iteration number: [150/4518] 3% | Training loss: 0.6912380754947662
Epoch: 78 | Iteration number: [160/4518] 3% | Training loss: 0.6909599468111992
Epoch: 78 | Iteration number: [170/4518] 3% | Training loss: 0.6906655216918273
Epoch: 78 | Iteration number: [180/4518] 3% | Training loss: 0.6904577768511242
Epoch: 78 | Iteration number: [190/4518] 4% | Training loss: 0.6902746379375457
Epoch: 78 | Iteration number: [200/4518] 4% | Training loss: 0.690122300684452
Epoch: 78 | Iteration number: [210/4518] 4% | Training loss: 0.6899844513052986
Epoch: 78 | Iteration number: [220/4518] 4% | Training loss: 0.6898195795037529
Epoch: 78 | Iteration number: [230/4518] 5% | Training loss: 0.6896124785361083
Epoch: 78 | Iteration number: [240/4518] 5% | Training loss: 0.6895038048426311
Epoch: 78 | Iteration number: [250/4518] 5% | Training loss: 0.6893846430778503
Epoch: 78 | Iteration number: [260/4518] 5% | Training loss: 0.68935594696265
Epoch: 78 | Iteration number: [270/4518] 5% | Training loss: 0.6892624258995056
Epoch: 78 | Iteration number: [280/4518] 6% | Training loss: 0.6892033545034272
Epoch: 78 | Iteration number: [290/4518] 6% | Training loss: 0.6890602276243013
Epoch: 78 | Iteration number: [300/4518] 6% | Training loss: 0.6889532295862834
Epoch: 78 | Iteration number: [310/4518] 6% | Training loss: 0.6889001744408761
Epoch: 78 | Iteration number: [320/4518] 7% | Training loss: 0.6888266878202558
Epoch: 78 | Iteration number: [330/4518] 7% | Training loss: 0.6887687932361256
Epoch: 78 | Iteration number: [340/4518] 7% | Training loss: 0.6887256906313055
Epoch: 78 | Iteration number: [350/4518] 7% | Training loss: 0.688696243592671
Epoch: 78 | Iteration number: [360/4518] 7% | Training loss: 0.6886820644140244
Epoch: 78 | Iteration number: [370/4518] 8% | Training loss: 0.6886672435580073
Epoch: 78 | Iteration number: [380/4518] 8% | Training loss: 0.6886042861562026
Epoch: 78 | Iteration number: [390/4518] 8% | Training loss: 0.6885415167380602
Epoch: 78 | Iteration number: [400/4518] 8% | Training loss: 0.6885268801450729
Epoch: 78 | Iteration number: [410/4518] 9% | Training loss: 0.6884555086856935
Epoch: 78 | Iteration number: [420/4518] 9% | Training loss: 0.688435145219167
Epoch: 78 | Iteration number: [430/4518] 9% | Training loss: 0.6883962676968686
Epoch: 78 | Iteration number: [440/4518] 9% | Training loss: 0.6883391372182153
Epoch: 78 | Iteration number: [450/4518] 9% | Training loss: 0.6883075634638468
Epoch: 78 | Iteration number: [460/4518] 10% | Training loss: 0.6883024368597114
Epoch: 78 | Iteration number: [470/4518] 10% | Training loss: 0.688274573265238
Epoch: 78 | Iteration number: [480/4518] 10% | Training loss: 0.6882614417622487
Epoch: 78 | Iteration number: [490/4518] 10% | Training loss: 0.6882204784422504
Epoch: 78 | Iteration number: [500/4518] 11% | Training loss: 0.6882230653762818
Epoch: 78 | Iteration number: [510/4518] 11% | Training loss: 0.688183675326553
Epoch: 78 | Iteration number: [520/4518] 11% | Training loss: 0.6881241482037764
Epoch: 78 | Iteration number: [530/4518] 11% | Training loss: 0.6881130233125866
Epoch: 78 | Iteration number: [540/4518] 11% | Training loss: 0.6880893723832237
Epoch: 78 | Iteration number: [550/4518] 12% | Training loss: 0.6880688531832262
Epoch: 78 | Iteration number: [560/4518] 12% | Training loss: 0.6880619314100062
Epoch: 78 | Iteration number: [570/4518] 12% | Training loss: 0.6880429921443002
Epoch: 78 | Iteration number: [580/4518] 12% | Training loss: 0.688028073310852
Epoch: 78 | Iteration number: [590/4518] 13% | Training loss: 0.6880321199611082
Epoch: 78 | Iteration number: [600/4518] 13% | Training loss: 0.6879964076479276
Epoch: 78 | Iteration number: [610/4518] 13% | Training loss: 0.6879796074062098
Epoch: 78 | Iteration number: [620/4518] 13% | Training loss: 0.6879608781107011
Epoch: 78 | Iteration number: [630/4518] 13% | Training loss: 0.6879476988126361
Epoch: 78 | Iteration number: [640/4518] 14% | Training loss: 0.6879145616665483
Epoch: 78 | Iteration number: [650/4518] 14% | Training loss: 0.6878993765207437
Epoch: 78 | Iteration number: [660/4518] 14% | Training loss: 0.6878987122665752
Epoch: 78 | Iteration number: [670/4518] 14% | Training loss: 0.6878904941366679
Epoch: 78 | Iteration number: [680/4518] 15% | Training loss: 0.687873290654491
Epoch: 78 | Iteration number: [690/4518] 15% | Training loss: 0.6878575679184734
Epoch: 78 | Iteration number: [700/4518] 15% | Training loss: 0.6878467222622463
Epoch: 78 | Iteration number: [710/4518] 15% | Training loss: 0.6878065417350178
Epoch: 78 | Iteration number: [720/4518] 15% | Training loss: 0.6877996726168527
Epoch: 78 | Iteration number: [730/4518] 16% | Training loss: 0.6877672764536452
Epoch: 78 | Iteration number: [740/4518] 16% | Training loss: 0.6877421061734895
Epoch: 78 | Iteration number: [750/4518] 16% | Training loss: 0.6877299008369446
Epoch: 78 | Iteration number: [760/4518] 16% | Training loss: 0.6877243172965551
Epoch: 78 | Iteration number: [770/4518] 17% | Training loss: 0.6877110934876777
Epoch: 78 | Iteration number: [780/4518] 17% | Training loss: 0.6876878263858649
Epoch: 78 | Iteration number: [790/4518] 17% | Training loss: 0.6876775804954239
Epoch: 78 | Iteration number: [800/4518] 17% | Training loss: 0.6876608500629664
Epoch: 78 | Iteration number: [810/4518] 17% | Training loss: 0.6876603662231822
Epoch: 78 | Iteration number: [820/4518] 18% | Training loss: 0.6876313187727114
Epoch: 78 | Iteration number: [830/4518] 18% | Training loss: 0.6876080148909466
Epoch: 78 | Iteration number: [840/4518] 18% | Training loss: 0.6875934539096696
Epoch: 78 | Iteration number: [850/4518] 18% | Training loss: 0.6875845395817476
Epoch: 78 | Iteration number: [860/4518] 19% | Training loss: 0.6875742447237636
Epoch: 78 | Iteration number: [870/4518] 19% | Training loss: 0.6875404771717115
Epoch: 78 | Iteration number: [880/4518] 19% | Training loss: 0.6875288612463257
Epoch: 78 | Iteration number: [890/4518] 19% | Training loss: 0.6875038018387355
Epoch: 78 | Iteration number: [900/4518] 19% | Training loss: 0.687484807504548
Epoch: 78 | Iteration number: [910/4518] 20% | Training loss: 0.6874789763282944
Epoch: 78 | Iteration number: [920/4518] 20% | Training loss: 0.6874581990034684
Epoch: 78 | Iteration number: [930/4518] 20% | Training loss: 0.6874445364039431
Epoch: 78 | Iteration number: [940/4518] 20% | Training loss: 0.6874356042831502
Epoch: 78 | Iteration number: [950/4518] 21% | Training loss: 0.6874197926646785
Epoch: 78 | Iteration number: [960/4518] 21% | Training loss: 0.6874162993083398
Epoch: 78 | Iteration number: [970/4518] 21% | Training loss: 0.6873942038447587
Epoch: 78 | Iteration number: [980/4518] 21% | Training loss: 0.6873811101426883
Epoch: 78 | Iteration number: [990/4518] 21% | Training loss: 0.6873848485826242
Epoch: 78 | Iteration number: [1000/4518] 22% | Training loss: 0.6873906183242798
Epoch: 78 | Iteration number: [1010/4518] 22% | Training loss: 0.6873894224662592
Epoch: 78 | Iteration number: [1020/4518] 22% | Training loss: 0.6873936383747588
Epoch: 78 | Iteration number: [1030/4518] 22% | Training loss: 0.687395051150646
Epoch: 78 | Iteration number: [1040/4518] 23% | Training loss: 0.687391403489388
Epoch: 78 | Iteration number: [1050/4518] 23% | Training loss: 0.6873925484929766
Epoch: 78 | Iteration number: [1060/4518] 23% | Training loss: 0.6873727070835401
Epoch: 78 | Iteration number: [1070/4518] 23% | Training loss: 0.6873638394837067
Epoch: 78 | Iteration number: [1080/4518] 23% | Training loss: 0.6873519801431232
Epoch: 78 | Iteration number: [1090/4518] 24% | Training loss: 0.6873384607494424
Epoch: 78 | Iteration number: [1100/4518] 24% | Training loss: 0.6873388465426185
Epoch: 78 | Iteration number: [1110/4518] 24% | Training loss: 0.6873325483219044
Epoch: 78 | Iteration number: [1120/4518] 24% | Training loss: 0.6873308432953699
Epoch: 78 | Iteration number: [1130/4518] 25% | Training loss: 0.6873199795727182
Epoch: 78 | Iteration number: [1140/4518] 25% | Training loss: 0.6873244571058373
Epoch: 78 | Iteration number: [1150/4518] 25% | Training loss: 0.6873251752231432
Epoch: 78 | Iteration number: [1160/4518] 25% | Training loss: 0.6873204723000527
Epoch: 78 | Iteration number: [1170/4518] 25% | Training loss: 0.6873025517178397
Epoch: 78 | Iteration number: [1180/4518] 26% | Training loss: 0.6872935184987925
Epoch: 78 | Iteration number: [1190/4518] 26% | Training loss: 0.6872922756591765
Epoch: 78 | Iteration number: [1200/4518] 26% | Training loss: 0.6872882652779421
Epoch: 78 | Iteration number: [1210/4518] 26% | Training loss: 0.6872845873359806
Epoch: 78 | Iteration number: [1220/4518] 27% | Training loss: 0.687287178782166
Epoch: 78 | Iteration number: [1230/4518] 27% | Training loss: 0.6872747164431626
Epoch: 78 | Iteration number: [1240/4518] 27% | Training loss: 0.6872726389958013
Epoch: 78 | Iteration number: [1250/4518] 27% | Training loss: 0.687279517698288
Epoch: 78 | Iteration number: [1260/4518] 27% | Training loss: 0.6872754823120814
Epoch: 78 | Iteration number: [1270/4518] 28% | Training loss: 0.6872740948294092
Epoch: 78 | Iteration number: [1280/4518] 28% | Training loss: 0.6872655869461596
Epoch: 78 | Iteration number: [1290/4518] 28% | Training loss: 0.6872599794883136
Epoch: 78 | Iteration number: [1300/4518] 28% | Training loss: 0.6872619770123408
Epoch: 78 | Iteration number: [1310/4518] 28% | Training loss: 0.6872691513927838
Epoch: 78 | Iteration number: [1320/4518] 29% | Training loss: 0.6872709527160182
Epoch: 78 | Iteration number: [1330/4518] 29% | Training loss: 0.6872659726250441
Epoch: 78 | Iteration number: [1340/4518] 29% | Training loss: 0.6872536317626042
Epoch: 78 | Iteration number: [1350/4518] 29% | Training loss: 0.6872514862925918
Epoch: 78 | Iteration number: [1360/4518] 30% | Training loss: 0.6872418302823515
Epoch: 78 | Iteration number: [1370/4518] 30% | Training loss: 0.6872339695474527
Epoch: 78 | Iteration number: [1380/4518] 30% | Training loss: 0.6872389131266138
Epoch: 78 | Iteration number: [1390/4518] 30% | Training loss: 0.6872308434342309
Epoch: 78 | Iteration number: [1400/4518] 30% | Training loss: 0.6872252102834838
Epoch: 78 | Iteration number: [1410/4518] 31% | Training loss: 0.687215465053599
Epoch: 78 | Iteration number: [1420/4518] 31% | Training loss: 0.6872108265967436
Epoch: 78 | Iteration number: [1430/4518] 31% | Training loss: 0.6872068604806086
Epoch: 78 | Iteration number: [1440/4518] 31% | Training loss: 0.6872052976654636
Epoch: 78 | Iteration number: [1450/4518] 32% | Training loss: 0.6872055394896146
Epoch: 78 | Iteration number: [1460/4518] 32% | Training loss: 0.6871923426650974
Epoch: 78 | Iteration number: [1470/4518] 32% | Training loss: 0.6871874892387261
Epoch: 78 | Iteration number: [1480/4518] 32% | Training loss: 0.6871915057301521
Epoch: 78 | Iteration number: [1490/4518] 32% | Training loss: 0.6871880299292955
Epoch: 78 | Iteration number: [1500/4518] 33% | Training loss: 0.687182797074318
Epoch: 78 | Iteration number: [1510/4518] 33% | Training loss: 0.6871832411810262
Epoch: 78 | Iteration number: [1520/4518] 33% | Training loss: 0.687182316733034
Epoch: 78 | Iteration number: [1530/4518] 33% | Training loss: 0.6871782875918095
Epoch: 78 | Iteration number: [1540/4518] 34% | Training loss: 0.6871723800123511
Epoch: 78 | Iteration number: [1550/4518] 34% | Training loss: 0.6871554436222199
Epoch: 78 | Iteration number: [1560/4518] 34% | Training loss: 0.6871613500592036
Epoch: 78 | Iteration number: [1570/4518] 34% | Training loss: 0.6871570128164474
Epoch: 78 | Iteration number: [1580/4518] 34% | Training loss: 0.687155463914328
Epoch: 78 | Iteration number: [1590/4518] 35% | Training loss: 0.687156339299004
Epoch: 78 | Iteration number: [1600/4518] 35% | Training loss: 0.6871611727774143
Epoch: 78 | Iteration number: [1610/4518] 35% | Training loss: 0.6871537621717275
Epoch: 78 | Iteration number: [1620/4518] 35% | Training loss: 0.6871446264746749
Epoch: 78 | Iteration number: [1630/4518] 36% | Training loss: 0.6871495742007998
Epoch: 78 | Iteration number: [1640/4518] 36% | Training loss: 0.687150577582964
Epoch: 78 | Iteration number: [1650/4518] 36% | Training loss: 0.6871540128462242
Epoch: 78 | Iteration number: [1660/4518] 36% | Training loss: 0.6871449870517455
Epoch: 78 | Iteration number: [1670/4518] 36% | Training loss: 0.6871496859424843
Epoch: 78 | Iteration number: [1680/4518] 37% | Training loss: 0.6871419679905687
Epoch: 78 | Iteration number: [1690/4518] 37% | Training loss: 0.6871358148092349
Epoch: 78 | Iteration number: [1700/4518] 37% | Training loss: 0.687134380270453
Epoch: 78 | Iteration number: [1710/4518] 37% | Training loss: 0.6871339793442286
Epoch: 78 | Iteration number: [1720/4518] 38% | Training loss: 0.6871335699807766
Epoch: 78 | Iteration number: [1730/4518] 38% | Training loss: 0.6871342756844669
Epoch: 78 | Iteration number: [1740/4518] 38% | Training loss: 0.687133076478695
Epoch: 78 | Iteration number: [1750/4518] 38% | Training loss: 0.6871294548511505
Epoch: 78 | Iteration number: [1760/4518] 38% | Training loss: 0.6871296116912907
Epoch: 78 | Iteration number: [1770/4518] 39% | Training loss: 0.6871221250396664
Epoch: 78 | Iteration number: [1780/4518] 39% | Training loss: 0.6871246711926514
Epoch: 78 | Iteration number: [1790/4518] 39% | Training loss: 0.6871243607398518
Epoch: 78 | Iteration number: [1800/4518] 39% | Training loss: 0.6871232918235991
Epoch: 78 | Iteration number: [1810/4518] 40% | Training loss: 0.6871195230036151
Epoch: 78 | Iteration number: [1820/4518] 40% | Training loss: 0.6871163535249102
Epoch: 78 | Iteration number: [1830/4518] 40% | Training loss: 0.6871068370472538
Epoch: 78 | Iteration number: [1840/4518] 40% | Training loss: 0.6871014097786468
Epoch: 78 | Iteration number: [1850/4518] 40% | Training loss: 0.6870973845430323
Epoch: 78 | Iteration number: [1860/4518] 41% | Training loss: 0.6870934238677384
Epoch: 78 | Iteration number: [1870/4518] 41% | Training loss: 0.6870873104760991
Epoch: 78 | Iteration number: [1880/4518] 41% | Training loss: 0.6870824835084854
Epoch: 78 | Iteration number: [1890/4518] 41% | Training loss: 0.6870808855566398
Epoch: 78 | Iteration number: [1900/4518] 42% | Training loss: 0.6870789771330984
Epoch: 78 | Iteration number: [1910/4518] 42% | Training loss: 0.6870618979656259
Epoch: 78 | Iteration number: [1920/4518] 42% | Training loss: 0.6870594123688837
Epoch: 78 | Iteration number: [1930/4518] 42% | Training loss: 0.6870570277611826
Epoch: 78 | Iteration number: [1940/4518] 42% | Training loss: 0.6870577896993185
Epoch: 78 | Iteration number: [1950/4518] 43% | Training loss: 0.6870543487255389
Epoch: 78 | Iteration number: [1960/4518] 43% | Training loss: 0.6870523200351365
Epoch: 78 | Iteration number: [1970/4518] 43% | Training loss: 0.6870532503890507
Epoch: 78 | Iteration number: [1980/4518] 43% | Training loss: 0.6870564427640703
Epoch: 78 | Iteration number: [1990/4518] 44% | Training loss: 0.6870456591622913
Epoch: 78 | Iteration number: [2000/4518] 44% | Training loss: 0.6870467294454574
Epoch: 78 | Iteration number: [2010/4518] 44% | Training loss: 0.6870391760595995
Epoch: 78 | Iteration number: [2020/4518] 44% | Training loss: 0.6870320874865693
Epoch: 78 | Iteration number: [2030/4518] 44% | Training loss: 0.6870309131779694
Epoch: 78 | Iteration number: [2040/4518] 45% | Training loss: 0.6870281610710948
Epoch: 78 | Iteration number: [2050/4518] 45% | Training loss: 0.687029491052395
Epoch: 78 | Iteration number: [2060/4518] 45% | Training loss: 0.6870356129789815
Epoch: 78 | Iteration number: [2070/4518] 45% | Training loss: 0.687036313123749
Epoch: 78 | Iteration number: [2080/4518] 46% | Training loss: 0.6870317938522651
Epoch: 78 | Iteration number: [2090/4518] 46% | Training loss: 0.6870243759816913
Epoch: 78 | Iteration number: [2100/4518] 46% | Training loss: 0.6870233983652932
Epoch: 78 | Iteration number: [2110/4518] 46% | Training loss: 0.6870221058339304
Epoch: 78 | Iteration number: [2120/4518] 46% | Training loss: 0.6870210638586081
Epoch: 78 | Iteration number: [2130/4518] 47% | Training loss: 0.6870133569542791
Epoch: 78 | Iteration number: [2140/4518] 47% | Training loss: 0.6870105023138992
Epoch: 78 | Iteration number: [2150/4518] 47% | Training loss: 0.6870123712129371
Epoch: 78 | Iteration number: [2160/4518] 47% | Training loss: 0.6870103325556826
Epoch: 78 | Iteration number: [2170/4518] 48% | Training loss: 0.6870003931808032
Epoch: 78 | Iteration number: [2180/4518] 48% | Training loss: 0.6870029341737065
Epoch: 78 | Iteration number: [2190/4518] 48% | Training loss: 0.6870023531728684
Epoch: 78 | Iteration number: [2200/4518] 48% | Training loss: 0.6870098578117111
Epoch: 78 | Iteration number: [2210/4518] 48% | Training loss: 0.6870021041162413
Epoch: 78 | Iteration number: [2220/4518] 49% | Training loss: 0.6870012562017183
Epoch: 78 | Iteration number: [2230/4518] 49% | Training loss: 0.6869983933431685
Epoch: 78 | Iteration number: [2240/4518] 49% | Training loss: 0.686998345995588
Epoch: 78 | Iteration number: [2250/4518] 49% | Training loss: 0.6870062627792358
Epoch: 78 | Iteration number: [2260/4518] 50% | Training loss: 0.6870040552542273
Epoch: 78 | Iteration number: [2270/4518] 50% | Training loss: 0.6870049729221193
Epoch: 78 | Iteration number: [2280/4518] 50% | Training loss: 0.6870088339113353
Epoch: 78 | Iteration number: [2290/4518] 50% | Training loss: 0.6870065474874588
Epoch: 78 | Iteration number: [2300/4518] 50% | Training loss: 0.6870073836005253
Epoch: 78 | Iteration number: [2310/4518] 51% | Training loss: 0.6870116663959636
Epoch: 78 | Iteration number: [2320/4518] 51% | Training loss: 0.6870057806115726
Epoch: 78 | Iteration number: [2330/4518] 51% | Training loss: 0.6870028377090912
Epoch: 78 | Iteration number: [2340/4518] 51% | Training loss: 0.6870024235330077
Epoch: 78 | Iteration number: [2350/4518] 52% | Training loss: 0.6869953658225688
Epoch: 78 | Iteration number: [2360/4518] 52% | Training loss: 0.6869988230325408
Epoch: 78 | Iteration number: [2370/4518] 52% | Training loss: 0.6869997237805073
Epoch: 78 | Iteration number: [2380/4518] 52% | Training loss: 0.6870001417999508
Epoch: 78 | Iteration number: [2390/4518] 52% | Training loss: 0.686998863399777
Epoch: 78 | Iteration number: [2400/4518] 53% | Training loss: 0.6869964981079102
Epoch: 78 | Iteration number: [2410/4518] 53% | Training loss: 0.6869944880859485
Epoch: 78 | Iteration number: [2420/4518] 53% | Training loss: 0.6869956497564789
Epoch: 78 | Iteration number: [2430/4518] 53% | Training loss: 0.686993934318362
Epoch: 78 | Iteration number: [2440/4518] 54% | Training loss: 0.6869951064957946
Epoch: 78 | Iteration number: [2450/4518] 54% | Training loss: 0.6869891224102098
Epoch: 78 | Iteration number: [2460/4518] 54% | Training loss: 0.6869877023667824
Epoch: 78 | Iteration number: [2470/4518] 54% | Training loss: 0.6869883193660844
Epoch: 78 | Iteration number: [2480/4518] 54% | Training loss: 0.6869812987504467
Epoch: 78 | Iteration number: [2490/4518] 55% | Training loss: 0.6869780692948874
Epoch: 78 | Iteration number: [2500/4518] 55% | Training loss: 0.6869781602859497
Epoch: 78 | Iteration number: [2510/4518] 55% | Training loss: 0.6869777423927034
Epoch: 78 | Iteration number: [2520/4518] 55% | Training loss: 0.6869779166011584
Epoch: 78 | Iteration number: [2530/4518] 55% | Training loss: 0.68698253377153
Epoch: 78 | Iteration number: [2540/4518] 56% | Training loss: 0.686979596352014
Epoch: 78 | Iteration number: [2550/4518] 56% | Training loss: 0.6869749465876934
Epoch: 78 | Iteration number: [2560/4518] 56% | Training loss: 0.686974230944179
Epoch: 78 | Iteration number: [2570/4518] 56% | Training loss: 0.686972000951433
Epoch: 78 | Iteration number: [2580/4518] 57% | Training loss: 0.6869736994190734
Epoch: 78 | Iteration number: [2590/4518] 57% | Training loss: 0.6869737648135447
Epoch: 78 | Iteration number: [2600/4518] 57% | Training loss: 0.6869711758998724
Epoch: 78 | Iteration number: [2610/4518] 57% | Training loss: 0.6869690460491911
Epoch: 78 | Iteration number: [2620/4518] 57% | Training loss: 0.6869727892502574
Epoch: 78 | Iteration number: [2630/4518] 58% | Training loss: 0.6869752765381744
Epoch: 78 | Iteration number: [2640/4518] 58% | Training loss: 0.6869730178153877
Epoch: 78 | Iteration number: [2650/4518] 58% | Training loss: 0.6869766403369184
Epoch: 78 | Iteration number: [2660/4518] 58% | Training loss: 0.6869727829345187
Epoch: 78 | Iteration number: [2670/4518] 59% | Training loss: 0.6869709349303657
Epoch: 78 | Iteration number: [2680/4518] 59% | Training loss: 0.68696662423326
Epoch: 78 | Iteration number: [2690/4518] 59% | Training loss: 0.6869689780761762
Epoch: 78 | Iteration number: [2700/4518] 59% | Training loss: 0.6869699668884277
Epoch: 78 | Iteration number: [2710/4518] 59% | Training loss: 0.686969779404327
Epoch: 78 | Iteration number: [2720/4518] 60% | Training loss: 0.686966153497205
Epoch: 78 | Iteration number: [2730/4518] 60% | Training loss: 0.6869643378388751
Epoch: 78 | Iteration number: [2740/4518] 60% | Training loss: 0.6869629138142523
Epoch: 78 | Iteration number: [2750/4518] 60% | Training loss: 0.6869638892303813
Epoch: 78 | Iteration number: [2760/4518] 61% | Training loss: 0.6869652846153231
Epoch: 78 | Iteration number: [2770/4518] 61% | Training loss: 0.6869666050272297
Epoch: 78 | Iteration number: [2780/4518] 61% | Training loss: 0.6869657300573458
Epoch: 78 | Iteration number: [2790/4518] 61% | Training loss: 0.6869681552105907
Epoch: 78 | Iteration number: [2800/4518] 61% | Training loss: 0.6869707902840205
Epoch: 78 | Iteration number: [2810/4518] 62% | Training loss: 0.6869750403212482
Epoch: 78 | Iteration number: [2820/4518] 62% | Training loss: 0.6869751813141167
Epoch: 78 | Iteration number: [2830/4518] 62% | Training loss: 0.6869770439269265
Epoch: 78 | Iteration number: [2840/4518] 62% | Training loss: 0.6869722534863042
Epoch: 78 | Iteration number: [2850/4518] 63% | Training loss: 0.6869749233178926
Epoch: 78 | Iteration number: [2860/4518] 63% | Training loss: 0.6869747029526251
Epoch: 78 | Iteration number: [2870/4518] 63% | Training loss: 0.6869755566950875
Epoch: 78 | Iteration number: [2880/4518] 63% | Training loss: 0.6869770444308718
Epoch: 78 | Iteration number: [2890/4518] 63% | Training loss: 0.6869763453526481
Epoch: 78 | Iteration number: [2900/4518] 64% | Training loss: 0.6869794589281082
Epoch: 78 | Iteration number: [2910/4518] 64% | Training loss: 0.6869766795348465
Epoch: 78 | Iteration number: [2920/4518] 64% | Training loss: 0.6869744213272447
Epoch: 78 | Iteration number: [2930/4518] 64% | Training loss: 0.6869742668325991
Epoch: 78 | Iteration number: [2940/4518] 65% | Training loss: 0.6869750511078607
Epoch: 78 | Iteration number: [2950/4518] 65% | Training loss: 0.6869703227786694
Epoch: 78 | Iteration number: [2960/4518] 65% | Training loss: 0.6869656396677365
Epoch: 78 | Iteration number: [2970/4518] 65% | Training loss: 0.6869673358671593
Epoch: 78 | Iteration number: [2980/4518] 65% | Training loss: 0.6869717345741772
Epoch: 78 | Iteration number: [2990/4518] 66% | Training loss: 0.6869748486722991
Epoch: 78 | Iteration number: [3000/4518] 66% | Training loss: 0.6869770708084106
Epoch: 78 | Iteration number: [3010/4518] 66% | Training loss: 0.6869751841720949
Epoch: 78 | Iteration number: [3020/4518] 66% | Training loss: 0.6869744070515728
Epoch: 78 | Iteration number: [3030/4518] 67% | Training loss: 0.6869761016305918
Epoch: 78 | Iteration number: [3040/4518] 67% | Training loss: 0.6869767660961339
Epoch: 78 | Iteration number: [3050/4518] 67% | Training loss: 0.6869733322643843
Epoch: 78 | Iteration number: [3060/4518] 67% | Training loss: 0.6869692712437873
Epoch: 78 | Iteration number: [3070/4518] 67% | Training loss: 0.6869658617709281
Epoch: 78 | Iteration number: [3080/4518] 68% | Training loss: 0.686966243560438
Epoch: 78 | Iteration number: [3090/4518] 68% | Training loss: 0.6869648412014674
Epoch: 78 | Iteration number: [3100/4518] 68% | Training loss: 0.686965302190473
Epoch: 78 | Iteration number: [3110/4518] 68% | Training loss: 0.6869639112060093
Epoch: 78 | Iteration number: [3120/4518] 69% | Training loss: 0.6869644035513585
Epoch: 78 | Iteration number: [3130/4518] 69% | Training loss: 0.6869660271242404
Epoch: 78 | Iteration number: [3140/4518] 69% | Training loss: 0.6869687515649067
Epoch: 78 | Iteration number: [3150/4518] 69% | Training loss: 0.6869665347772931
Epoch: 78 | Iteration number: [3160/4518] 69% | Training loss: 0.6869644881237911
Epoch: 78 | Iteration number: [3170/4518] 70% | Training loss: 0.6869606502424656
Epoch: 78 | Iteration number: [3180/4518] 70% | Training loss: 0.6869586696227391
Epoch: 78 | Iteration number: [3190/4518] 70% | Training loss: 0.6869647394900785
Epoch: 78 | Iteration number: [3200/4518] 70% | Training loss: 0.6869637092575431
Epoch: 78 | Iteration number: [3210/4518] 71% | Training loss: 0.6869593868374453
Epoch: 78 | Iteration number: [3220/4518] 71% | Training loss: 0.6869582952364631
Epoch: 78 | Iteration number: [3230/4518] 71% | Training loss: 0.6869591463276477
Epoch: 78 | Iteration number: [3240/4518] 71% | Training loss: 0.6869581979365996
Epoch: 78 | Iteration number: [3250/4518] 71% | Training loss: 0.6869620350140792
Epoch: 78 | Iteration number: [3260/4518] 72% | Training loss: 0.6869615505260924
Epoch: 78 | Iteration number: [3270/4518] 72% | Training loss: 0.686958671327031
Epoch: 78 | Iteration number: [3280/4518] 72% | Training loss: 0.6869610703391272
Epoch: 78 | Iteration number: [3290/4518] 72% | Training loss: 0.6869614648963905
Epoch: 78 | Iteration number: [3300/4518] 73% | Training loss: 0.686961812358914
Epoch: 78 | Iteration number: [3310/4518] 73% | Training loss: 0.6869623450714296
Epoch: 78 | Iteration number: [3320/4518] 73% | Training loss: 0.6869613884263728
Epoch: 78 | Iteration number: [3330/4518] 73% | Training loss: 0.6869599274149886
Epoch: 78 | Iteration number: [3340/4518] 73% | Training loss: 0.6869624703944086
Epoch: 78 | Iteration number: [3350/4518] 74% | Training loss: 0.6869620463029662
Epoch: 78 | Iteration number: [3360/4518] 74% | Training loss: 0.6869592417386317
Epoch: 78 | Iteration number: [3370/4518] 74% | Training loss: 0.6869614892614347
Epoch: 78 | Iteration number: [3380/4518] 74% | Training loss: 0.686960369454333
Epoch: 78 | Iteration number: [3390/4518] 75% | Training loss: 0.6869606798553185
Epoch: 78 | Iteration number: [3400/4518] 75% | Training loss: 0.6869568124939414
Epoch: 78 | Iteration number: [3410/4518] 75% | Training loss: 0.6869575161388543
Epoch: 78 | Iteration number: [3420/4518] 75% | Training loss: 0.6869519199892792
Epoch: 78 | Iteration number: [3430/4518] 75% | Training loss: 0.6869545280585831
Epoch: 78 | Iteration number: [3440/4518] 76% | Training loss: 0.6869550299505854
Epoch: 78 | Iteration number: [3450/4518] 76% | Training loss: 0.6869565460301827
Epoch: 78 | Iteration number: [3460/4518] 76% | Training loss: 0.6869506562548565
Epoch: 78 | Iteration number: [3470/4518] 76% | Training loss: 0.6869496185429158
Epoch: 78 | Iteration number: [3480/4518] 77% | Training loss: 0.6869505988797923
Epoch: 78 | Iteration number: [3490/4518] 77% | Training loss: 0.6869493820434996
Epoch: 78 | Iteration number: [3500/4518] 77% | Training loss: 0.686948771408626
Epoch: 78 | Iteration number: [3510/4518] 77% | Training loss: 0.6869516253131747
Epoch: 78 | Iteration number: [3520/4518] 77% | Training loss: 0.686952680840411
Epoch: 78 | Iteration number: [3530/4518] 78% | Training loss: 0.6869507952215989
Epoch: 78 | Iteration number: [3540/4518] 78% | Training loss: 0.6869507746507892
Epoch: 78 | Iteration number: [3550/4518] 78% | Training loss: 0.6869475055412507
Epoch: 78 | Iteration number: [3560/4518] 78% | Training loss: 0.6869472958566097
Epoch: 78 | Iteration number: [3570/4518] 79% | Training loss: 0.6869471003528402
Epoch: 78 | Iteration number: [3580/4518] 79% | Training loss: 0.6869471099623089
Epoch: 78 | Iteration number: [3590/4518] 79% | Training loss: 0.6869475401211582
Epoch: 78 | Iteration number: [3600/4518] 79% | Training loss: 0.6869458228184118
Epoch: 78 | Iteration number: [3610/4518] 79% | Training loss: 0.6869469673679807
Epoch: 78 | Iteration number: [3620/4518] 80% | Training loss: 0.6869484817784135
Epoch: 78 | Iteration number: [3630/4518] 80% | Training loss: 0.6869516311762418
Epoch: 78 | Iteration number: [3640/4518] 80% | Training loss: 0.6869498252377405
Epoch: 78 | Iteration number: [3650/4518] 80% | Training loss: 0.6869515855508308
Epoch: 78 | Iteration number: [3660/4518] 81% | Training loss: 0.6869519245591972
Epoch: 78 | Iteration number: [3670/4518] 81% | Training loss: 0.6869508662730537
Epoch: 78 | Iteration number: [3680/4518] 81% | Training loss: 0.6869497340172529
Epoch: 78 | Iteration number: [3690/4518] 81% | Training loss: 0.6869497230543999
Epoch: 78 | Iteration number: [3700/4518] 81% | Training loss: 0.6869486199359636
Epoch: 78 | Iteration number: [3710/4518] 82% | Training loss: 0.6869486291935502
Epoch: 78 | Iteration number: [3720/4518] 82% | Training loss: 0.686945301935237
Epoch: 78 | Iteration number: [3730/4518] 82% | Training loss: 0.6869457408346376
Epoch: 78 | Iteration number: [3740/4518] 82% | Training loss: 0.6869453966458213
Epoch: 78 | Iteration number: [3750/4518] 83% | Training loss: 0.6869468217372894
Epoch: 78 | Iteration number: [3760/4518] 83% | Training loss: 0.6869456091618285
Epoch: 78 | Iteration number: [3770/4518] 83% | Training loss: 0.686946629892926
Epoch: 78 | Iteration number: [3780/4518] 83% | Training loss: 0.6869455686164281
Epoch: 78 | Iteration number: [3790/4518] 83% | Training loss: 0.6869422104710954
Epoch: 78 | Iteration number: [3800/4518] 84% | Training loss: 0.6869413759990742
Epoch: 78 | Iteration number: [3810/4518] 84% | Training loss: 0.6869358041624385
Epoch: 78 | Iteration number: [3820/4518] 84% | Training loss: 0.6869330501525189
Epoch: 78 | Iteration number: [3830/4518] 84% | Training loss: 0.6869382893447776
Epoch: 78 | Iteration number: [3840/4518] 84% | Training loss: 0.6869367108680308
Epoch: 78 | Iteration number: [3850/4518] 85% | Training loss: 0.6869343815376232
Epoch: 78 | Iteration number: [3860/4518] 85% | Training loss: 0.6869356861077442
Epoch: 78 | Iteration number: [3870/4518] 85% | Training loss: 0.686936320183505
Epoch: 78 | Iteration number: [3880/4518] 85% | Training loss: 0.6869381391510521
Epoch: 78 | Iteration number: [3890/4518] 86% | Training loss: 0.6869337801914902
Epoch: 78 | Iteration number: [3900/4518] 86% | Training loss: 0.6869344836931962
Epoch: 78 | Iteration number: [3910/4518] 86% | Training loss: 0.6869358233326232
Epoch: 78 | Iteration number: [3920/4518] 86% | Training loss: 0.686938032994465
Epoch: 78 | Iteration number: [3930/4518] 86% | Training loss: 0.6869388115163371
Epoch: 78 | Iteration number: [3940/4518] 87% | Training loss: 0.6869388993016354
Epoch: 78 | Iteration number: [3950/4518] 87% | Training loss: 0.6869424025620087
Epoch: 78 | Iteration number: [3960/4518] 87% | Training loss: 0.6869421902780581
Epoch: 78 | Iteration number: [3970/4518] 87% | Training loss: 0.6869420138954816
Epoch: 78 | Iteration number: [3980/4518] 88% | Training loss: 0.6869405226491804
Epoch: 78 | Iteration number: [3990/4518] 88% | Training loss: 0.6869379925697967
Epoch: 78 | Iteration number: [4000/4518] 88% | Training loss: 0.6869388491511345
Epoch: 78 | Iteration number: [4010/4518] 88% | Training loss: 0.6869343806829239
Epoch: 78 | Iteration number: [4020/4518] 88% | Training loss: 0.6869351963795239
Epoch: 78 | Iteration number: [4030/4518] 89% | Training loss: 0.6869351017268065
Epoch: 78 | Iteration number: [4040/4518] 89% | Training loss: 0.6869359519959677
Epoch: 78 | Iteration number: [4050/4518] 89% | Training loss: 0.6869354217287935
Epoch: 78 | Iteration number: [4060/4518] 89% | Training loss: 0.6869356008292419
Epoch: 78 | Iteration number: [4070/4518] 90% | Training loss: 0.6869329690786778
Epoch: 78 | Iteration number: [4080/4518] 90% | Training loss: 0.6869302667093043
Epoch: 78 | Iteration number: [4090/4518] 90% | Training loss: 0.6869344782858431
Epoch: 78 | Iteration number: [4100/4518] 90% | Training loss: 0.6869346994888492
Epoch: 78 | Iteration number: [4110/4518] 90% | Training loss: 0.6869350221615348
Epoch: 78 | Iteration number: [4120/4518] 91% | Training loss: 0.6869351405252531
Epoch: 78 | Iteration number: [4130/4518] 91% | Training loss: 0.6869350579113995
Epoch: 78 | Iteration number: [4140/4518] 91% | Training loss: 0.6869335372810779
Epoch: 78 | Iteration number: [4150/4518] 91% | Training loss: 0.68693441014692
Epoch: 78 | Iteration number: [4160/4518] 92% | Training loss: 0.6869308748210852
Epoch: 78 | Iteration number: [4170/4518] 92% | Training loss: 0.6869309540132252
Epoch: 78 | Iteration number: [4180/4518] 92% | Training loss: 0.6869301033790032
Epoch: 78 | Iteration number: [4190/4518] 92% | Training loss: 0.6869331543656124
Epoch: 78 | Iteration number: [4200/4518] 92% | Training loss: 0.6869298822397277
Epoch: 78 | Iteration number: [4210/4518] 93% | Training loss: 0.6869279886226473
Epoch: 78 | Iteration number: [4220/4518] 93% | Training loss: 0.6869258780756268
Epoch: 78 | Iteration number: [4230/4518] 93% | Training loss: 0.6869267756493661
Epoch: 78 | Iteration number: [4240/4518] 93% | Training loss: 0.6869255932012819
Epoch: 78 | Iteration number: [4250/4518] 94% | Training loss: 0.6869205659838283
Epoch: 78 | Iteration number: [4260/4518] 94% | Training loss: 0.686919147587718
Epoch: 78 | Iteration number: [4270/4518] 94% | Training loss: 0.6869218348340073
Epoch: 78 | Iteration number: [4280/4518] 94% | Training loss: 0.6869206402067826
Epoch: 78 | Iteration number: [4290/4518] 94% | Training loss: 0.686924186842147
Epoch: 78 | Iteration number: [4300/4518] 95% | Training loss: 0.6869217543269313
Epoch: 78 | Iteration number: [4310/4518] 95% | Training loss: 0.686923642031278
Epoch: 78 | Iteration number: [4320/4518] 95% | Training loss: 0.6869239318288035
Epoch: 78 | Iteration number: [4330/4518] 95% | Training loss: 0.6869216100723584
Epoch: 78 | Iteration number: [4340/4518] 96% | Training loss: 0.6869191277137
Epoch: 78 | Iteration number: [4350/4518] 96% | Training loss: 0.6869201764704167
Epoch: 78 | Iteration number: [4360/4518] 96% | Training loss: 0.6869224004652522
Epoch: 78 | Iteration number: [4370/4518] 96% | Training loss: 0.6869212754394697
Epoch: 78 | Iteration number: [4380/4518] 96% | Training loss: 0.6869227768351498
Epoch: 78 | Iteration number: [4390/4518] 97% | Training loss: 0.686921520208715
Epoch: 78 | Iteration number: [4400/4518] 97% | Training loss: 0.6869225773350759
Epoch: 78 | Iteration number: [4410/4518] 97% | Training loss: 0.6869224472921722
Epoch: 78 | Iteration number: [4420/4518] 97% | Training loss: 0.6869231686198334
Epoch: 78 | Iteration number: [4430/4518] 98% | Training loss: 0.6869222024897151
Epoch: 78 | Iteration number: [4440/4518] 98% | Training loss: 0.6869199251537924
Epoch: 78 | Iteration number: [4450/4518] 98% | Training loss: 0.6869192119528739
Epoch: 78 | Iteration number: [4460/4518] 98% | Training loss: 0.6869165631554052
Epoch: 78 | Iteration number: [4470/4518] 98% | Training loss: 0.6869188330984223
Epoch: 78 | Iteration number: [4480/4518] 99% | Training loss: 0.6869200441321092
Epoch: 78 | Iteration number: [4490/4518] 99% | Training loss: 0.6869200684179972
Epoch: 78 | Iteration number: [4500/4518] 99% | Training loss: 0.6869188992447324
Epoch: 78 | Iteration number: [4510/4518] 99% | Training loss: 0.68691967531477

 End of epoch: 78 | Train Loss: 0.6867664414942396 | Training Time: 639 

 End of epoch: 78 | Eval Loss: 0.6898113136388817 | Evaluating Time: 17 
Epoch: 79 | Iteration number: [10/4518] 0% | Training loss: 0.7553948163986206
Epoch: 79 | Iteration number: [20/4518] 0% | Training loss: 0.721242967247963
Epoch: 79 | Iteration number: [30/4518] 0% | Training loss: 0.709852530558904
Epoch: 79 | Iteration number: [40/4518] 0% | Training loss: 0.7042161390185356
Epoch: 79 | Iteration number: [50/4518] 1% | Training loss: 0.700842274427414
Epoch: 79 | Iteration number: [60/4518] 1% | Training loss: 0.6987680355707805
Epoch: 79 | Iteration number: [70/4518] 1% | Training loss: 0.6971705990178244
Epoch: 79 | Iteration number: [80/4518] 1% | Training loss: 0.6957805842161179
Epoch: 79 | Iteration number: [90/4518] 1% | Training loss: 0.6948508388466306
Epoch: 79 | Iteration number: [100/4518] 2% | Training loss: 0.6940238708257676
Epoch: 79 | Iteration number: [110/4518] 2% | Training loss: 0.6933098988099532
Epoch: 79 | Iteration number: [120/4518] 2% | Training loss: 0.6926391810178757
Epoch: 79 | Iteration number: [130/4518] 2% | Training loss: 0.6922709089059096
Epoch: 79 | Iteration number: [140/4518] 3% | Training loss: 0.6919326645987375
Epoch: 79 | Iteration number: [150/4518] 3% | Training loss: 0.691600954135259
Epoch: 79 | Iteration number: [160/4518] 3% | Training loss: 0.6913010261952877
Epoch: 79 | Iteration number: [170/4518] 3% | Training loss: 0.6910270098377677
Epoch: 79 | Iteration number: [180/4518] 3% | Training loss: 0.6907809151543511
Epoch: 79 | Iteration number: [190/4518] 4% | Training loss: 0.6905910027654547
Epoch: 79 | Iteration number: [200/4518] 4% | Training loss: 0.690405755341053
Epoch: 79 | Iteration number: [210/4518] 4% | Training loss: 0.6902270768369947
Epoch: 79 | Iteration number: [220/4518] 4% | Training loss: 0.6900511768731203
Epoch: 79 | Iteration number: [230/4518] 5% | Training loss: 0.6899226307868958
Epoch: 79 | Iteration number: [240/4518] 5% | Training loss: 0.6897965063651402
Epoch: 79 | Iteration number: [250/4518] 5% | Training loss: 0.6896881301403046
Epoch: 79 | Iteration number: [260/4518] 5% | Training loss: 0.6895799513046558
Epoch: 79 | Iteration number: [270/4518] 5% | Training loss: 0.689519441790051
Epoch: 79 | Iteration number: [280/4518] 6% | Training loss: 0.689428443142346
Epoch: 79 | Iteration number: [290/4518] 6% | Training loss: 0.6893084188987468
Epoch: 79 | Iteration number: [300/4518] 6% | Training loss: 0.6892189818620682
Epoch: 79 | Iteration number: [310/4518] 6% | Training loss: 0.6891383186463387
Epoch: 79 | Iteration number: [320/4518] 7% | Training loss: 0.6890477750450372
Epoch: 79 | Iteration number: [330/4518] 7% | Training loss: 0.6889579023375656
Epoch: 79 | Iteration number: [340/4518] 7% | Training loss: 0.6888811223647173
Epoch: 79 | Iteration number: [350/4518] 7% | Training loss: 0.6887859722546169
Epoch: 79 | Iteration number: [360/4518] 7% | Training loss: 0.6887244501047665
Epoch: 79 | Iteration number: [370/4518] 8% | Training loss: 0.688700541290077
Epoch: 79 | Iteration number: [380/4518] 8% | Training loss: 0.6886424096007097
Epoch: 79 | Iteration number: [390/4518] 8% | Training loss: 0.6885744996559926
Epoch: 79 | Iteration number: [400/4518] 8% | Training loss: 0.6885209001600743
Epoch: 79 | Iteration number: [410/4518] 9% | Training loss: 0.6884656430744543
Epoch: 79 | Iteration number: [420/4518] 9% | Training loss: 0.6884004617021198
Epoch: 79 | Iteration number: [430/4518] 9% | Training loss: 0.688358182130858
Epoch: 79 | Iteration number: [440/4518] 9% | Training loss: 0.6883152421225202
Epoch: 79 | Iteration number: [450/4518] 9% | Training loss: 0.6883042498429617
Epoch: 79 | Iteration number: [460/4518] 10% | Training loss: 0.6882909369209539
Epoch: 79 | Iteration number: [470/4518] 10% | Training loss: 0.6882678196785298
Epoch: 79 | Iteration number: [480/4518] 10% | Training loss: 0.6882325109094382
Epoch: 79 | Iteration number: [490/4518] 10% | Training loss: 0.6882146352407884
Epoch: 79 | Iteration number: [500/4518] 11% | Training loss: 0.6881992516517639
Epoch: 79 | Iteration number: [510/4518] 11% | Training loss: 0.688167951855005
Epoch: 79 | Iteration number: [520/4518] 11% | Training loss: 0.6881419681585752
Epoch: 79 | Iteration number: [530/4518] 11% | Training loss: 0.688123376414461
Epoch: 79 | Iteration number: [540/4518] 11% | Training loss: 0.6880882377977724
Epoch: 79 | Iteration number: [550/4518] 12% | Training loss: 0.6880528561635451
Epoch: 79 | Iteration number: [560/4518] 12% | Training loss: 0.6880197347274848
Epoch: 79 | Iteration number: [570/4518] 12% | Training loss: 0.6880014407007318
Epoch: 79 | Iteration number: [580/4518] 12% | Training loss: 0.6879797120546473
Epoch: 79 | Iteration number: [590/4518] 13% | Training loss: 0.6879551617775933
Epoch: 79 | Iteration number: [600/4518] 13% | Training loss: 0.6879483665029208
Epoch: 79 | Iteration number: [610/4518] 13% | Training loss: 0.6879286570627181
Epoch: 79 | Iteration number: [620/4518] 13% | Training loss: 0.6879287675503761
Epoch: 79 | Iteration number: [630/4518] 13% | Training loss: 0.6878978770876688
Epoch: 79 | Iteration number: [640/4518] 14% | Training loss: 0.6879034153185785
Epoch: 79 | Iteration number: [650/4518] 14% | Training loss: 0.6878971485908215
Epoch: 79 | Iteration number: [660/4518] 14% | Training loss: 0.6878731854937293
Epoch: 79 | Iteration number: [670/4518] 14% | Training loss: 0.6878730066676638
Epoch: 79 | Iteration number: [680/4518] 15% | Training loss: 0.687858539293794
Epoch: 79 | Iteration number: [690/4518] 15% | Training loss: 0.687827259734057
Epoch: 79 | Iteration number: [700/4518] 15% | Training loss: 0.6878233706951141
Epoch: 79 | Iteration number: [710/4518] 15% | Training loss: 0.6877891557317385
Epoch: 79 | Iteration number: [720/4518] 15% | Training loss: 0.6877679952316814
Epoch: 79 | Iteration number: [730/4518] 16% | Training loss: 0.6877545897274802
Epoch: 79 | Iteration number: [740/4518] 16% | Training loss: 0.6877355572339651
Epoch: 79 | Iteration number: [750/4518] 16% | Training loss: 0.6877150789896647
Epoch: 79 | Iteration number: [760/4518] 16% | Training loss: 0.6876845737821178
Epoch: 79 | Iteration number: [770/4518] 17% | Training loss: 0.6876856976515286
Epoch: 79 | Iteration number: [780/4518] 17% | Training loss: 0.6876699183231745
Epoch: 79 | Iteration number: [790/4518] 17% | Training loss: 0.6876587117774577
Epoch: 79 | Iteration number: [800/4518] 17% | Training loss: 0.687640903070569
Epoch: 79 | Iteration number: [810/4518] 17% | Training loss: 0.6876334766546885
Epoch: 79 | Iteration number: [820/4518] 18% | Training loss: 0.6876240576912717
Epoch: 79 | Iteration number: [830/4518] 18% | Training loss: 0.687597175606762
Epoch: 79 | Iteration number: [840/4518] 18% | Training loss: 0.6875931502807708
Epoch: 79 | Iteration number: [850/4518] 18% | Training loss: 0.6875900445264929
Epoch: 79 | Iteration number: [860/4518] 19% | Training loss: 0.6875663615243379
Epoch: 79 | Iteration number: [870/4518] 19% | Training loss: 0.6875587414050924
Epoch: 79 | Iteration number: [880/4518] 19% | Training loss: 0.6875376392494549
Epoch: 79 | Iteration number: [890/4518] 19% | Training loss: 0.6875360273913051
Epoch: 79 | Iteration number: [900/4518] 19% | Training loss: 0.687534882956081
Epoch: 79 | Iteration number: [910/4518] 20% | Training loss: 0.6875178629225427
Epoch: 79 | Iteration number: [920/4518] 20% | Training loss: 0.687512167705142
Epoch: 79 | Iteration number: [930/4518] 20% | Training loss: 0.6875118877298089
Epoch: 79 | Iteration number: [940/4518] 20% | Training loss: 0.687505265436274
Epoch: 79 | Iteration number: [950/4518] 21% | Training loss: 0.6875042200088501
Epoch: 79 | Iteration number: [960/4518] 21% | Training loss: 0.6874897986029586
Epoch: 79 | Iteration number: [970/4518] 21% | Training loss: 0.6874760930685653
Epoch: 79 | Iteration number: [980/4518] 21% | Training loss: 0.6874644649272063
Epoch: 79 | Iteration number: [990/4518] 21% | Training loss: 0.6874605548502218
Epoch: 79 | Iteration number: [1000/4518] 22% | Training loss: 0.6874424205422401
Epoch: 79 | Iteration number: [1010/4518] 22% | Training loss: 0.6874472582694328
Epoch: 79 | Iteration number: [1020/4518] 22% | Training loss: 0.6874478169516021
Epoch: 79 | Iteration number: [1030/4518] 22% | Training loss: 0.6874483243933002
Epoch: 79 | Iteration number: [1040/4518] 23% | Training loss: 0.687443954956073
Epoch: 79 | Iteration number: [1050/4518] 23% | Training loss: 0.68744549762635
Epoch: 79 | Iteration number: [1060/4518] 23% | Training loss: 0.6874445088629453
Epoch: 79 | Iteration number: [1070/4518] 23% | Training loss: 0.6874368902678801
Epoch: 79 | Iteration number: [1080/4518] 23% | Training loss: 0.6874352949636954
Epoch: 79 | Iteration number: [1090/4518] 24% | Training loss: 0.6874343283132676
Epoch: 79 | Iteration number: [1100/4518] 24% | Training loss: 0.6874362638321789
Epoch: 79 | Iteration number: [1110/4518] 24% | Training loss: 0.6874322840222368
Epoch: 79 | Iteration number: [1120/4518] 24% | Training loss: 0.6874130531613316
Epoch: 79 | Iteration number: [1130/4518] 25% | Training loss: 0.6874118622952858
Epoch: 79 | Iteration number: [1140/4518] 25% | Training loss: 0.6874024978332353
Epoch: 79 | Iteration number: [1150/4518] 25% | Training loss: 0.6873961680868398
Epoch: 79 | Iteration number: [1160/4518] 25% | Training loss: 0.6873940433407651
Epoch: 79 | Iteration number: [1170/4518] 25% | Training loss: 0.6873960218368432
Epoch: 79 | Iteration number: [1180/4518] 26% | Training loss: 0.6873944022897946
Epoch: 79 | Iteration number: [1190/4518] 26% | Training loss: 0.6873811598084554
Epoch: 79 | Iteration number: [1200/4518] 26% | Training loss: 0.6873823552330335
Epoch: 79 | Iteration number: [1210/4518] 26% | Training loss: 0.6873759034743979
Epoch: 79 | Iteration number: [1220/4518] 27% | Training loss: 0.6873663580319921
Epoch: 79 | Iteration number: [1230/4518] 27% | Training loss: 0.6873668379899932
Epoch: 79 | Iteration number: [1240/4518] 27% | Training loss: 0.6873730658523498
Epoch: 79 | Iteration number: [1250/4518] 27% | Training loss: 0.6873559607982636
Epoch: 79 | Iteration number: [1260/4518] 27% | Training loss: 0.6873445102146694
Epoch: 79 | Iteration number: [1270/4518] 28% | Training loss: 0.6873443809550578
Epoch: 79 | Iteration number: [1280/4518] 28% | Training loss: 0.687336546042934
Epoch: 79 | Iteration number: [1290/4518] 28% | Training loss: 0.6873332928779513
Epoch: 79 | Iteration number: [1300/4518] 28% | Training loss: 0.687327860731345
Epoch: 79 | Iteration number: [1310/4518] 28% | Training loss: 0.687331352024588
Epoch: 79 | Iteration number: [1320/4518] 29% | Training loss: 0.6873246471990239
Epoch: 79 | Iteration number: [1330/4518] 29% | Training loss: 0.6873120056059128
Epoch: 79 | Iteration number: [1340/4518] 29% | Training loss: 0.687310690310464
Epoch: 79 | Iteration number: [1350/4518] 29% | Training loss: 0.6872944788138071
Epoch: 79 | Iteration number: [1360/4518] 30% | Training loss: 0.6872832902214107
Epoch: 79 | Iteration number: [1370/4518] 30% | Training loss: 0.6872708191401767
Epoch: 79 | Iteration number: [1380/4518] 30% | Training loss: 0.6872803569703863
Epoch: 79 | Iteration number: [1390/4518] 30% | Training loss: 0.6872761716087945
Epoch: 79 | Iteration number: [1400/4518] 30% | Training loss: 0.6872687847699438
Epoch: 79 | Iteration number: [1410/4518] 31% | Training loss: 0.687266517700033
Epoch: 79 | Iteration number: [1420/4518] 31% | Training loss: 0.6872569090463746
Epoch: 79 | Iteration number: [1430/4518] 31% | Training loss: 0.6872511209307851
Epoch: 79 | Iteration number: [1440/4518] 31% | Training loss: 0.6872540026489231
Epoch: 79 | Iteration number: [1450/4518] 32% | Training loss: 0.6872540310333515
Epoch: 79 | Iteration number: [1460/4518] 32% | Training loss: 0.6872461839489741
Epoch: 79 | Iteration number: [1470/4518] 32% | Training loss: 0.6872447486637401
Epoch: 79 | Iteration number: [1480/4518] 32% | Training loss: 0.6872419583233627
Epoch: 79 | Iteration number: [1490/4518] 32% | Training loss: 0.6872380263853393
Epoch: 79 | Iteration number: [1500/4518] 33% | Training loss: 0.6872392302751541
Epoch: 79 | Iteration number: [1510/4518] 33% | Training loss: 0.6872394680187403
Epoch: 79 | Iteration number: [1520/4518] 33% | Training loss: 0.6872376174126801
Epoch: 79 | Iteration number: [1530/4518] 33% | Training loss: 0.6872412200067558
Epoch: 79 | Iteration number: [1540/4518] 34% | Training loss: 0.6872331390133152
Epoch: 79 | Iteration number: [1550/4518] 34% | Training loss: 0.6872218430426813
Epoch: 79 | Iteration number: [1560/4518] 34% | Training loss: 0.6872171303018545
Epoch: 79 | Iteration number: [1570/4518] 34% | Training loss: 0.6872070119259464
Epoch: 79 | Iteration number: [1580/4518] 34% | Training loss: 0.6872141151865826
Epoch: 79 | Iteration number: [1590/4518] 35% | Training loss: 0.6872167925789671
Epoch: 79 | Iteration number: [1600/4518] 35% | Training loss: 0.6872159006819129
Epoch: 79 | Iteration number: [1610/4518] 35% | Training loss: 0.6872184242150798
Epoch: 79 | Iteration number: [1620/4518] 35% | Training loss: 0.6872190223063952
Epoch: 79 | Iteration number: [1630/4518] 36% | Training loss: 0.6872143286137493
Epoch: 79 | Iteration number: [1640/4518] 36% | Training loss: 0.6872072736301074
Epoch: 79 | Iteration number: [1650/4518] 36% | Training loss: 0.6871964774348519
Epoch: 79 | Iteration number: [1660/4518] 36% | Training loss: 0.6871820044086641
Epoch: 79 | Iteration number: [1670/4518] 36% | Training loss: 0.6871827844731108
Epoch: 79 | Iteration number: [1680/4518] 37% | Training loss: 0.6871845084996451
Epoch: 79 | Iteration number: [1690/4518] 37% | Training loss: 0.6871849712182784
Epoch: 79 | Iteration number: [1700/4518] 37% | Training loss: 0.6871729678266189
Epoch: 79 | Iteration number: [1710/4518] 37% | Training loss: 0.6871693332641445
Epoch: 79 | Iteration number: [1720/4518] 38% | Training loss: 0.687162889921388
Epoch: 79 | Iteration number: [1730/4518] 38% | Training loss: 0.6871614241875665
Epoch: 79 | Iteration number: [1740/4518] 38% | Training loss: 0.6871625004828661
Epoch: 79 | Iteration number: [1750/4518] 38% | Training loss: 0.6871597814219339
Epoch: 79 | Iteration number: [1760/4518] 38% | Training loss: 0.687162387709726
Epoch: 79 | Iteration number: [1770/4518] 39% | Training loss: 0.6871626787603238
Epoch: 79 | Iteration number: [1780/4518] 39% | Training loss: 0.6871616830316822
Epoch: 79 | Iteration number: [1790/4518] 39% | Training loss: 0.6871644032068093
Epoch: 79 | Iteration number: [1800/4518] 39% | Training loss: 0.6871584326691098
Epoch: 79 | Iteration number: [1810/4518] 40% | Training loss: 0.6871527029993785
Epoch: 79 | Iteration number: [1820/4518] 40% | Training loss: 0.6871524818323471
Epoch: 79 | Iteration number: [1830/4518] 40% | Training loss: 0.6871516406861811
Epoch: 79 | Iteration number: [1840/4518] 40% | Training loss: 0.687147367356912
Epoch: 79 | Iteration number: [1850/4518] 40% | Training loss: 0.687145082370655
Epoch: 79 | Iteration number: [1860/4518] 41% | Training loss: 0.6871426662770651
Epoch: 79 | Iteration number: [1870/4518] 41% | Training loss: 0.687138581052821
Epoch: 79 | Iteration number: [1880/4518] 41% | Training loss: 0.6871428954791515
Epoch: 79 | Iteration number: [1890/4518] 41% | Training loss: 0.6871431325793897
Epoch: 79 | Iteration number: [1900/4518] 42% | Training loss: 0.6871397469545666
Epoch: 79 | Iteration number: [1910/4518] 42% | Training loss: 0.6871341946237375
Epoch: 79 | Iteration number: [1920/4518] 42% | Training loss: 0.6871335683080058
Epoch: 79 | Iteration number: [1930/4518] 42% | Training loss: 0.6871277678198148
Epoch: 79 | Iteration number: [1940/4518] 42% | Training loss: 0.687129784982229
Epoch: 79 | Iteration number: [1950/4518] 43% | Training loss: 0.6871307119650718
Epoch: 79 | Iteration number: [1960/4518] 43% | Training loss: 0.6871251656692855
Epoch: 79 | Iteration number: [1970/4518] 43% | Training loss: 0.6871297316502799
Epoch: 79 | Iteration number: [1980/4518] 43% | Training loss: 0.6871222542391883
Epoch: 79 | Iteration number: [1990/4518] 44% | Training loss: 0.6871222380717196
Epoch: 79 | Iteration number: [2000/4518] 44% | Training loss: 0.687116721957922
Epoch: 79 | Iteration number: [2010/4518] 44% | Training loss: 0.6871126276047076
Epoch: 79 | Iteration number: [2020/4518] 44% | Training loss: 0.6871053829936697
Epoch: 79 | Iteration number: [2030/4518] 44% | Training loss: 0.6871050243894455
Epoch: 79 | Iteration number: [2040/4518] 45% | Training loss: 0.6871095046985383
Epoch: 79 | Iteration number: [2050/4518] 45% | Training loss: 0.6871121438538156
Epoch: 79 | Iteration number: [2060/4518] 45% | Training loss: 0.6871167218511545
Epoch: 79 | Iteration number: [2070/4518] 45% | Training loss: 0.6871125476947729
Epoch: 79 | Iteration number: [2080/4518] 46% | Training loss: 0.6871062170141018
Epoch: 79 | Iteration number: [2090/4518] 46% | Training loss: 0.6871068408044332
Epoch: 79 | Iteration number: [2100/4518] 46% | Training loss: 0.6871035935197558
Epoch: 79 | Iteration number: [2110/4518] 46% | Training loss: 0.6871017818767312
Epoch: 79 | Iteration number: [2120/4518] 46% | Training loss: 0.687098979022143
Epoch: 79 | Iteration number: [2130/4518] 47% | Training loss: 0.6870936699316536
Epoch: 79 | Iteration number: [2140/4518] 47% | Training loss: 0.6870956384132956
Epoch: 79 | Iteration number: [2150/4518] 47% | Training loss: 0.687095869530079
Epoch: 79 | Iteration number: [2160/4518] 47% | Training loss: 0.687090126397433
Epoch: 79 | Iteration number: [2170/4518] 48% | Training loss: 0.6870917556197962
Epoch: 79 | Iteration number: [2180/4518] 48% | Training loss: 0.6870937969706474
Epoch: 79 | Iteration number: [2190/4518] 48% | Training loss: 0.6870934219937346
Epoch: 79 | Iteration number: [2200/4518] 48% | Training loss: 0.687092472829602
Epoch: 79 | Iteration number: [2210/4518] 48% | Training loss: 0.6870903891945317
Epoch: 79 | Iteration number: [2220/4518] 49% | Training loss: 0.687088700941017
Epoch: 79 | Iteration number: [2230/4518] 49% | Training loss: 0.6870799777219114
Epoch: 79 | Iteration number: [2240/4518] 49% | Training loss: 0.6870778910549623
Epoch: 79 | Iteration number: [2250/4518] 49% | Training loss: 0.6870803951952192
Epoch: 79 | Iteration number: [2260/4518] 50% | Training loss: 0.68707878341717
Epoch: 79 | Iteration number: [2270/4518] 50% | Training loss: 0.6870748088223293
Epoch: 79 | Iteration number: [2280/4518] 50% | Training loss: 0.6870676401675793
Epoch: 79 | Iteration number: [2290/4518] 50% | Training loss: 0.6870623809281395
Epoch: 79 | Iteration number: [2300/4518] 50% | Training loss: 0.6870601734907731
Epoch: 79 | Iteration number: [2310/4518] 51% | Training loss: 0.6870615636115467
Epoch: 79 | Iteration number: [2320/4518] 51% | Training loss: 0.6870636185438469
Epoch: 79 | Iteration number: [2330/4518] 51% | Training loss: 0.6870623153422524
Epoch: 79 | Iteration number: [2340/4518] 51% | Training loss: 0.687064135635001
Epoch: 79 | Iteration number: [2350/4518] 52% | Training loss: 0.687064016803782
Epoch: 79 | Iteration number: [2360/4518] 52% | Training loss: 0.6870612737485918
Epoch: 79 | Iteration number: [2370/4518] 52% | Training loss: 0.6870581122390329
Epoch: 79 | Iteration number: [2380/4518] 52% | Training loss: 0.6870610841933419
Epoch: 79 | Iteration number: [2390/4518] 52% | Training loss: 0.6870651065305686
Epoch: 79 | Iteration number: [2400/4518] 53% | Training loss: 0.6870631811022758
Epoch: 79 | Iteration number: [2410/4518] 53% | Training loss: 0.6870640960966403
Epoch: 79 | Iteration number: [2420/4518] 53% | Training loss: 0.6870563634170973
Epoch: 79 | Iteration number: [2430/4518] 53% | Training loss: 0.6870563328511431
Epoch: 79 | Iteration number: [2440/4518] 54% | Training loss: 0.6870564655690897
Epoch: 79 | Iteration number: [2450/4518] 54% | Training loss: 0.6870528975311591
Epoch: 79 | Iteration number: [2460/4518] 54% | Training loss: 0.6870519341976662
Epoch: 79 | Iteration number: [2470/4518] 54% | Training loss: 0.6870528844686655
Epoch: 79 | Iteration number: [2480/4518] 54% | Training loss: 0.6870481481234874
Epoch: 79 | Iteration number: [2490/4518] 55% | Training loss: 0.6870473163913052
Epoch: 79 | Iteration number: [2500/4518] 55% | Training loss: 0.6870452420234681
Epoch: 79 | Iteration number: [2510/4518] 55% | Training loss: 0.6870448687874463
Epoch: 79 | Iteration number: [2520/4518] 55% | Training loss: 0.6870399377885319
Epoch: 79 | Iteration number: [2530/4518] 55% | Training loss: 0.6870397907471939
Epoch: 79 | Iteration number: [2540/4518] 56% | Training loss: 0.6870366357677565
Epoch: 79 | Iteration number: [2550/4518] 56% | Training loss: 0.6870248967058519
Epoch: 79 | Iteration number: [2560/4518] 56% | Training loss: 0.6870193533599377
Epoch: 79 | Iteration number: [2570/4518] 56% | Training loss: 0.6870257108823798
Epoch: 79 | Iteration number: [2580/4518] 57% | Training loss: 0.6870208985352702
Epoch: 79 | Iteration number: [2590/4518] 57% | Training loss: 0.6870149895031019
Epoch: 79 | Iteration number: [2600/4518] 57% | Training loss: 0.6870164671769509
Epoch: 79 | Iteration number: [2610/4518] 57% | Training loss: 0.6870097651335472
Epoch: 79 | Iteration number: [2620/4518] 57% | Training loss: 0.6870102734966133
Epoch: 79 | Iteration number: [2630/4518] 58% | Training loss: 0.6870144749775585
Epoch: 79 | Iteration number: [2640/4518] 58% | Training loss: 0.6870143034241416
Epoch: 79 | Iteration number: [2650/4518] 58% | Training loss: 0.6870086796553629
Epoch: 79 | Iteration number: [2660/4518] 58% | Training loss: 0.6870092220996555
Epoch: 79 | Iteration number: [2670/4518] 59% | Training loss: 0.6870120726051402
Epoch: 79 | Iteration number: [2680/4518] 59% | Training loss: 0.6870090564685082
Epoch: 79 | Iteration number: [2690/4518] 59% | Training loss: 0.687008784628269
Epoch: 79 | Iteration number: [2700/4518] 59% | Training loss: 0.6870042578600071
Epoch: 79 | Iteration number: [2710/4518] 59% | Training loss: 0.6869983304910554
Epoch: 79 | Iteration number: [2720/4518] 60% | Training loss: 0.6870005493874058
Epoch: 79 | Iteration number: [2730/4518] 60% | Training loss: 0.6869985170635111
Epoch: 79 | Iteration number: [2740/4518] 60% | Training loss: 0.6869991504145365
Epoch: 79 | Iteration number: [2750/4518] 60% | Training loss: 0.6869988443634727
Epoch: 79 | Iteration number: [2760/4518] 61% | Training loss: 0.6869982955032501
Epoch: 79 | Iteration number: [2770/4518] 61% | Training loss: 0.6869979992239914
Epoch: 79 | Iteration number: [2780/4518] 61% | Training loss: 0.6869985026421307
Epoch: 79 | Iteration number: [2790/4518] 61% | Training loss: 0.6869957739947945
Epoch: 79 | Iteration number: [2800/4518] 61% | Training loss: 0.6869995993588652
Epoch: 79 | Iteration number: [2810/4518] 62% | Training loss: 0.6869969020746781
Epoch: 79 | Iteration number: [2820/4518] 62% | Training loss: 0.6869984593163145
Epoch: 79 | Iteration number: [2830/4518] 62% | Training loss: 0.6870013775547485
Epoch: 79 | Iteration number: [2840/4518] 62% | Training loss: 0.686999207860987
Epoch: 79 | Iteration number: [2850/4518] 63% | Training loss: 0.6869984797009251
Epoch: 79 | Iteration number: [2860/4518] 63% | Training loss: 0.6869989091908182
Epoch: 79 | Iteration number: [2870/4518] 63% | Training loss: 0.6869960464043899
Epoch: 79 | Iteration number: [2880/4518] 63% | Training loss: 0.6869938033322494
Epoch: 79 | Iteration number: [2890/4518] 63% | Training loss: 0.6869920252516195
Epoch: 79 | Iteration number: [2900/4518] 64% | Training loss: 0.6869948515809815
Epoch: 79 | Iteration number: [2910/4518] 64% | Training loss: 0.686997800184689
Epoch: 79 | Iteration number: [2920/4518] 64% | Training loss: 0.686999240844217
Epoch: 79 | Iteration number: [2930/4518] 64% | Training loss: 0.6869925307942739
Epoch: 79 | Iteration number: [2940/4518] 65% | Training loss: 0.6869936740114575
Epoch: 79 | Iteration number: [2950/4518] 65% | Training loss: 0.6869938960115788
Epoch: 79 | Iteration number: [2960/4518] 65% | Training loss: 0.686995191731163
Epoch: 79 | Iteration number: [2970/4518] 65% | Training loss: 0.686994941668077
Epoch: 79 | Iteration number: [2980/4518] 65% | Training loss: 0.6869980034012122
Epoch: 79 | Iteration number: [2990/4518] 66% | Training loss: 0.6869963329173251
Epoch: 79 | Iteration number: [3000/4518] 66% | Training loss: 0.6869968522588412
Epoch: 79 | Iteration number: [3010/4518] 66% | Training loss: 0.6869954445037335
Epoch: 79 | Iteration number: [3020/4518] 66% | Training loss: 0.6869934686959185
Epoch: 79 | Iteration number: [3030/4518] 67% | Training loss: 0.6869919964779329
Epoch: 79 | Iteration number: [3040/4518] 67% | Training loss: 0.6869940679716436
Epoch: 79 | Iteration number: [3050/4518] 67% | Training loss: 0.6869894089268856
Epoch: 79 | Iteration number: [3060/4518] 67% | Training loss: 0.686986973199969
Epoch: 79 | Iteration number: [3070/4518] 67% | Training loss: 0.6869888688337531
Epoch: 79 | Iteration number: [3080/4518] 68% | Training loss: 0.686986921069684
Epoch: 79 | Iteration number: [3090/4518] 68% | Training loss: 0.6869888471554012
Epoch: 79 | Iteration number: [3100/4518] 68% | Training loss: 0.6869906004205827
Epoch: 79 | Iteration number: [3110/4518] 68% | Training loss: 0.6869908737408004
Epoch: 79 | Iteration number: [3120/4518] 69% | Training loss: 0.6869878956522697
Epoch: 79 | Iteration number: [3130/4518] 69% | Training loss: 0.6869884311581572
Epoch: 79 | Iteration number: [3140/4518] 69% | Training loss: 0.6869892117703796
Epoch: 79 | Iteration number: [3150/4518] 69% | Training loss: 0.6869918217167021
Epoch: 79 | Iteration number: [3160/4518] 69% | Training loss: 0.6869913548796992
Epoch: 79 | Iteration number: [3170/4518] 70% | Training loss: 0.6869905895991281
Epoch: 79 | Iteration number: [3180/4518] 70% | Training loss: 0.6869893116396179
Epoch: 79 | Iteration number: [3190/4518] 70% | Training loss: 0.6869899526472002
Epoch: 79 | Iteration number: [3200/4518] 70% | Training loss: 0.6869904168136418
Epoch: 79 | Iteration number: [3210/4518] 71% | Training loss: 0.6869931236977146
Epoch: 79 | Iteration number: [3220/4518] 71% | Training loss: 0.6869956145375412
Epoch: 79 | Iteration number: [3230/4518] 71% | Training loss: 0.686995895432983
Epoch: 79 | Iteration number: [3240/4518] 71% | Training loss: 0.6869952472639672
Epoch: 79 | Iteration number: [3250/4518] 71% | Training loss: 0.686997617153021
Epoch: 79 | Iteration number: [3260/4518] 72% | Training loss: 0.6869971929152319
Epoch: 79 | Iteration number: [3270/4518] 72% | Training loss: 0.6869978659196732
Epoch: 79 | Iteration number: [3280/4518] 72% | Training loss: 0.6869965215463464
Epoch: 79 | Iteration number: [3290/4518] 72% | Training loss: 0.6869959796996827
Epoch: 79 | Iteration number: [3300/4518] 73% | Training loss: 0.6869961169091138
Epoch: 79 | Iteration number: [3310/4518] 73% | Training loss: 0.6869909740466725
Epoch: 79 | Iteration number: [3320/4518] 73% | Training loss: 0.6869907220444047
Epoch: 79 | Iteration number: [3330/4518] 73% | Training loss: 0.6869906690385607
Epoch: 79 | Iteration number: [3340/4518] 73% | Training loss: 0.6869904521696582
Epoch: 79 | Iteration number: [3350/4518] 74% | Training loss: 0.6869931169054402
Epoch: 79 | Iteration number: [3360/4518] 74% | Training loss: 0.6869902379633416
Epoch: 79 | Iteration number: [3370/4518] 74% | Training loss: 0.6869866416433091
Epoch: 79 | Iteration number: [3380/4518] 74% | Training loss: 0.6869851472462423
Epoch: 79 | Iteration number: [3390/4518] 75% | Training loss: 0.6869852783757325
Epoch: 79 | Iteration number: [3400/4518] 75% | Training loss: 0.6869866187256926
Epoch: 79 | Iteration number: [3410/4518] 75% | Training loss: 0.6869838578959714
Epoch: 79 | Iteration number: [3420/4518] 75% | Training loss: 0.6869843273832087
Epoch: 79 | Iteration number: [3430/4518] 75% | Training loss: 0.6869828311416916
Epoch: 79 | Iteration number: [3440/4518] 76% | Training loss: 0.6869834702028784
Epoch: 79 | Iteration number: [3450/4518] 76% | Training loss: 0.6869829342849013
Epoch: 79 | Iteration number: [3460/4518] 76% | Training loss: 0.6869833367925159
Epoch: 79 | Iteration number: [3470/4518] 76% | Training loss: 0.6869800031356922
Epoch: 79 | Iteration number: [3480/4518] 77% | Training loss: 0.6869796746592413
Epoch: 79 | Iteration number: [3490/4518] 77% | Training loss: 0.6869808107358337
Epoch: 79 | Iteration number: [3500/4518] 77% | Training loss: 0.6869823966877802
Epoch: 79 | Iteration number: [3510/4518] 77% | Training loss: 0.6869802114970324
Epoch: 79 | Iteration number: [3520/4518] 77% | Training loss: 0.6869803879071366
Epoch: 79 | Iteration number: [3530/4518] 78% | Training loss: 0.6869831924735655
Epoch: 79 | Iteration number: [3540/4518] 78% | Training loss: 0.6869802621966702
Epoch: 79 | Iteration number: [3550/4518] 78% | Training loss: 0.6869790399578256
Epoch: 79 | Iteration number: [3560/4518] 78% | Training loss: 0.6869776998343092
Epoch: 79 | Iteration number: [3570/4518] 79% | Training loss: 0.6869790332157071
Epoch: 79 | Iteration number: [3580/4518] 79% | Training loss: 0.6869751279580526
Epoch: 79 | Iteration number: [3590/4518] 79% | Training loss: 0.6869745373227802
Epoch: 79 | Iteration number: [3600/4518] 79% | Training loss: 0.6869706919954883
Epoch: 79 | Iteration number: [3610/4518] 79% | Training loss: 0.6869675233588655
Epoch: 79 | Iteration number: [3620/4518] 80% | Training loss: 0.686965527982343
Epoch: 79 | Iteration number: [3630/4518] 80% | Training loss: 0.6869662100782736
Epoch: 79 | Iteration number: [3640/4518] 80% | Training loss: 0.6869657044554804
Epoch: 79 | Iteration number: [3650/4518] 80% | Training loss: 0.686963613555856
Epoch: 79 | Iteration number: [3660/4518] 81% | Training loss: 0.6869629076758369
Epoch: 79 | Iteration number: [3670/4518] 81% | Training loss: 0.6869640904648753
Epoch: 79 | Iteration number: [3680/4518] 81% | Training loss: 0.686962830696417
Epoch: 79 | Iteration number: [3690/4518] 81% | Training loss: 0.686957325957978
Epoch: 79 | Iteration number: [3700/4518] 81% | Training loss: 0.6869546823888212
Epoch: 79 | Iteration number: [3710/4518] 82% | Training loss: 0.6869543767521645
Epoch: 79 | Iteration number: [3720/4518] 82% | Training loss: 0.6869487165283131
Epoch: 79 | Iteration number: [3730/4518] 82% | Training loss: 0.6869427915712464
Epoch: 79 | Iteration number: [3740/4518] 82% | Training loss: 0.6869418392366267
Epoch: 79 | Iteration number: [3750/4518] 83% | Training loss: 0.6869402404944102
Epoch: 79 | Iteration number: [3760/4518] 83% | Training loss: 0.686936833741183
Epoch: 79 | Iteration number: [3770/4518] 83% | Training loss: 0.6869379406740558
Epoch: 79 | Iteration number: [3780/4518] 83% | Training loss: 0.6869391347996141
Epoch: 79 | Iteration number: [3790/4518] 83% | Training loss: 0.6869385808627649
Epoch: 79 | Iteration number: [3800/4518] 84% | Training loss: 0.6869398101379997
Epoch: 79 | Iteration number: [3810/4518] 84% | Training loss: 0.6869381412120629
Epoch: 79 | Iteration number: [3820/4518] 84% | Training loss: 0.6869345094677042
Epoch: 79 | Iteration number: [3830/4518] 84% | Training loss: 0.6869355402011473
Epoch: 79 | Iteration number: [3840/4518] 84% | Training loss: 0.6869370311498642
Epoch: 79 | Iteration number: [3850/4518] 85% | Training loss: 0.686937399390456
Epoch: 79 | Iteration number: [3860/4518] 85% | Training loss: 0.6869377880516447
Epoch: 79 | Iteration number: [3870/4518] 85% | Training loss: 0.6869368889381103
Epoch: 79 | Iteration number: [3880/4518] 85% | Training loss: 0.6869353170708282
Epoch: 79 | Iteration number: [3890/4518] 86% | Training loss: 0.6869376675481967
Epoch: 79 | Iteration number: [3900/4518] 86% | Training loss: 0.6869377492941343
Epoch: 79 | Iteration number: [3910/4518] 86% | Training loss: 0.6869332403020786
Epoch: 79 | Iteration number: [3920/4518] 86% | Training loss: 0.6869333785103292
Epoch: 79 | Iteration number: [3930/4518] 86% | Training loss: 0.6869359134717752
Epoch: 79 | Iteration number: [3940/4518] 87% | Training loss: 0.6869392036635259
Epoch: 79 | Iteration number: [3950/4518] 87% | Training loss: 0.6869329654868646
Epoch: 79 | Iteration number: [3960/4518] 87% | Training loss: 0.6869346136547099
Epoch: 79 | Iteration number: [3970/4518] 87% | Training loss: 0.6869325925931522
Epoch: 79 | Iteration number: [3980/4518] 88% | Training loss: 0.6869289258766413
Epoch: 79 | Iteration number: [3990/4518] 88% | Training loss: 0.6869300522601096
Epoch: 79 | Iteration number: [4000/4518] 88% | Training loss: 0.6869284183979034
Epoch: 79 | Iteration number: [4010/4518] 88% | Training loss: 0.6869275453679282
Epoch: 79 | Iteration number: [4020/4518] 88% | Training loss: 0.6869258955195175
Epoch: 79 | Iteration number: [4030/4518] 89% | Training loss: 0.6869241678537269
Epoch: 79 | Iteration number: [4040/4518] 89% | Training loss: 0.686921985476914
Epoch: 79 | Iteration number: [4050/4518] 89% | Training loss: 0.686923878443094
Epoch: 79 | Iteration number: [4060/4518] 89% | Training loss: 0.686923068071821
Epoch: 79 | Iteration number: [4070/4518] 90% | Training loss: 0.6869203331136586
Epoch: 79 | Iteration number: [4080/4518] 90% | Training loss: 0.6869193439974505
Epoch: 79 | Iteration number: [4090/4518] 90% | Training loss: 0.6869191261113127
Epoch: 79 | Iteration number: [4100/4518] 90% | Training loss: 0.6869205598278744
Epoch: 79 | Iteration number: [4110/4518] 90% | Training loss: 0.686921128376847
Epoch: 79 | Iteration number: [4120/4518] 91% | Training loss: 0.6869209712425481
Epoch: 79 | Iteration number: [4130/4518] 91% | Training loss: 0.6869190290245536
Epoch: 79 | Iteration number: [4140/4518] 91% | Training loss: 0.6869205330592999
Epoch: 79 | Iteration number: [4150/4518] 91% | Training loss: 0.6869231753176953
Epoch: 79 | Iteration number: [4160/4518] 92% | Training loss: 0.6869242035425627
Epoch: 79 | Iteration number: [4170/4518] 92% | Training loss: 0.6869216392937896
Epoch: 79 | Iteration number: [4180/4518] 92% | Training loss: 0.6869183706039447
Epoch: 79 | Iteration number: [4190/4518] 92% | Training loss: 0.6869207333266593
Epoch: 79 | Iteration number: [4200/4518] 92% | Training loss: 0.6869196864678746
Epoch: 79 | Iteration number: [4210/4518] 93% | Training loss: 0.6869175061194177
Epoch: 79 | Iteration number: [4220/4518] 93% | Training loss: 0.6869165767849339
Epoch: 79 | Iteration number: [4230/4518] 93% | Training loss: 0.6869174439292709
Epoch: 79 | Iteration number: [4240/4518] 93% | Training loss: 0.6869160029123415
Epoch: 79 | Iteration number: [4250/4518] 94% | Training loss: 0.6869147626512191
Epoch: 79 | Iteration number: [4260/4518] 94% | Training loss: 0.686913875067178
Epoch: 79 | Iteration number: [4270/4518] 94% | Training loss: 0.6869129808641429
Epoch: 79 | Iteration number: [4280/4518] 94% | Training loss: 0.6869139718675168
Epoch: 79 | Iteration number: [4290/4518] 94% | Training loss: 0.6869171165919804
Epoch: 79 | Iteration number: [4300/4518] 95% | Training loss: 0.6869156498687212
Epoch: 79 | Iteration number: [4310/4518] 95% | Training loss: 0.6869167858652615
Epoch: 79 | Iteration number: [4320/4518] 95% | Training loss: 0.6869183530410131
Epoch: 79 | Iteration number: [4330/4518] 95% | Training loss: 0.6869222791310546
Epoch: 79 | Iteration number: [4340/4518] 96% | Training loss: 0.6869230038971396
Epoch: 79 | Iteration number: [4350/4518] 96% | Training loss: 0.6869229118714387
Epoch: 79 | Iteration number: [4360/4518] 96% | Training loss: 0.6869224393723208
Epoch: 79 | Iteration number: [4370/4518] 96% | Training loss: 0.6869229450787778
Epoch: 79 | Iteration number: [4380/4518] 96% | Training loss: 0.686922759239532
Epoch: 79 | Iteration number: [4390/4518] 97% | Training loss: 0.6869232474264089
Epoch: 79 | Iteration number: [4400/4518] 97% | Training loss: 0.6869238278134303
Epoch: 79 | Iteration number: [4410/4518] 97% | Training loss: 0.6869232243556285
Epoch: 79 | Iteration number: [4420/4518] 97% | Training loss: 0.6869220420111358
Epoch: 79 | Iteration number: [4430/4518] 98% | Training loss: 0.6869231710181011
Epoch: 79 | Iteration number: [4440/4518] 98% | Training loss: 0.68692270865043
Epoch: 79 | Iteration number: [4450/4518] 98% | Training loss: 0.6869233678164107
Epoch: 79 | Iteration number: [4460/4518] 98% | Training loss: 0.6869202971859363
Epoch: 79 | Iteration number: [4470/4518] 98% | Training loss: 0.6869226212736211
Epoch: 79 | Iteration number: [4480/4518] 99% | Training loss: 0.6869223621673882
Epoch: 79 | Iteration number: [4490/4518] 99% | Training loss: 0.6869221620543763
Epoch: 79 | Iteration number: [4500/4518] 99% | Training loss: 0.6869226306411955
Epoch: 79 | Iteration number: [4510/4518] 99% | Training loss: 0.6869211635409861

 End of epoch: 79 | Train Loss: 0.68676489574448 | Training Time: 641 

 End of epoch: 79 | Eval Loss: 0.6898180732921678 | Evaluating Time: 17 
Epoch: 80 | Iteration number: [10/4518] 0% | Training loss: 0.7568684637546539
Epoch: 80 | Iteration number: [20/4518] 0% | Training loss: 0.7214409679174423
Epoch: 80 | Iteration number: [30/4518] 0% | Training loss: 0.7096847812334697
Epoch: 80 | Iteration number: [40/4518] 0% | Training loss: 0.7040185645222664
Epoch: 80 | Iteration number: [50/4518] 1% | Training loss: 0.7005902755260468
Epoch: 80 | Iteration number: [60/4518] 1% | Training loss: 0.6984260459740956
Epoch: 80 | Iteration number: [70/4518] 1% | Training loss: 0.6968162613255637
Epoch: 80 | Iteration number: [80/4518] 1% | Training loss: 0.6955792292952537
Epoch: 80 | Iteration number: [90/4518] 1% | Training loss: 0.6947472936577267
Epoch: 80 | Iteration number: [100/4518] 2% | Training loss: 0.6939257210493088
Epoch: 80 | Iteration number: [110/4518] 2% | Training loss: 0.693298094922846
Epoch: 80 | Iteration number: [120/4518] 2% | Training loss: 0.6926423698663712
Epoch: 80 | Iteration number: [130/4518] 2% | Training loss: 0.692165411894138
Epoch: 80 | Iteration number: [140/4518] 3% | Training loss: 0.6917847901582718
Epoch: 80 | Iteration number: [150/4518] 3% | Training loss: 0.6914033615589141
Epoch: 80 | Iteration number: [160/4518] 3% | Training loss: 0.6910681430250406
Epoch: 80 | Iteration number: [170/4518] 3% | Training loss: 0.6908771339584799
Epoch: 80 | Iteration number: [180/4518] 3% | Training loss: 0.69067588713434
Epoch: 80 | Iteration number: [190/4518] 4% | Training loss: 0.6904856775936328
Epoch: 80 | Iteration number: [200/4518] 4% | Training loss: 0.6902608478069305
Epoch: 80 | Iteration number: [210/4518] 4% | Training loss: 0.690053744826998
Epoch: 80 | Iteration number: [220/4518] 4% | Training loss: 0.6899369982155886
Epoch: 80 | Iteration number: [230/4518] 5% | Training loss: 0.6898046729357347
Epoch: 80 | Iteration number: [240/4518] 5% | Training loss: 0.6896986064811548
Epoch: 80 | Iteration number: [250/4518] 5% | Training loss: 0.689603189945221
Epoch: 80 | Iteration number: [260/4518] 5% | Training loss: 0.689496575639798
Epoch: 80 | Iteration number: [270/4518] 5% | Training loss: 0.6894688674697169
Epoch: 80 | Iteration number: [280/4518] 6% | Training loss: 0.6893629546676363
Epoch: 80 | Iteration number: [290/4518] 6% | Training loss: 0.689285363205548
Epoch: 80 | Iteration number: [300/4518] 6% | Training loss: 0.6892028017838796
Epoch: 80 | Iteration number: [310/4518] 6% | Training loss: 0.689110101807502
Epoch: 80 | Iteration number: [320/4518] 7% | Training loss: 0.6890609856694937
Epoch: 80 | Iteration number: [330/4518] 7% | Training loss: 0.6889441024173389
Epoch: 80 | Iteration number: [340/4518] 7% | Training loss: 0.6888977326014463
Epoch: 80 | Iteration number: [350/4518] 7% | Training loss: 0.6888436872618539
Epoch: 80 | Iteration number: [360/4518] 7% | Training loss: 0.6887902196910646
Epoch: 80 | Iteration number: [370/4518] 8% | Training loss: 0.6887223913862899
Epoch: 80 | Iteration number: [380/4518] 8% | Training loss: 0.6886997420536844
Epoch: 80 | Iteration number: [390/4518] 8% | Training loss: 0.6886499834366334
Epoch: 80 | Iteration number: [400/4518] 8% | Training loss: 0.6885703249275684
Epoch: 80 | Iteration number: [410/4518] 9% | Training loss: 0.6885062685826929
Epoch: 80 | Iteration number: [420/4518] 9% | Training loss: 0.6884702913817905
Epoch: 80 | Iteration number: [430/4518] 9% | Training loss: 0.6884239029052646
Epoch: 80 | Iteration number: [440/4518] 9% | Training loss: 0.6883927796374668
Epoch: 80 | Iteration number: [450/4518] 9% | Training loss: 0.6883524635103013
Epoch: 80 | Iteration number: [460/4518] 10% | Training loss: 0.6883529043715934
Epoch: 80 | Iteration number: [470/4518] 10% | Training loss: 0.688335560991409
Epoch: 80 | Iteration number: [480/4518] 10% | Training loss: 0.6882777226467928
Epoch: 80 | Iteration number: [490/4518] 10% | Training loss: 0.6882321866191163
Epoch: 80 | Iteration number: [500/4518] 11% | Training loss: 0.688194692492485
Epoch: 80 | Iteration number: [510/4518] 11% | Training loss: 0.6881752208167431
Epoch: 80 | Iteration number: [520/4518] 11% | Training loss: 0.6881737270034276
Epoch: 80 | Iteration number: [530/4518] 11% | Training loss: 0.6881486601424667
Epoch: 80 | Iteration number: [540/4518] 11% | Training loss: 0.6881089129933604
Epoch: 80 | Iteration number: [550/4518] 12% | Training loss: 0.6880998137864199
Epoch: 80 | Iteration number: [560/4518] 12% | Training loss: 0.6880763958607401
Epoch: 80 | Iteration number: [570/4518] 12% | Training loss: 0.6880445960320924
Epoch: 80 | Iteration number: [580/4518] 12% | Training loss: 0.6880073249340057
Epoch: 80 | Iteration number: [590/4518] 13% | Training loss: 0.6879908587972997
Epoch: 80 | Iteration number: [600/4518] 13% | Training loss: 0.687977037926515
Epoch: 80 | Iteration number: [610/4518] 13% | Training loss: 0.6879473716509147
Epoch: 80 | Iteration number: [620/4518] 13% | Training loss: 0.6879478372873798
Epoch: 80 | Iteration number: [630/4518] 13% | Training loss: 0.6879479692095802
Epoch: 80 | Iteration number: [640/4518] 14% | Training loss: 0.687933596689254
Epoch: 80 | Iteration number: [650/4518] 14% | Training loss: 0.6879414247549497
Epoch: 80 | Iteration number: [660/4518] 14% | Training loss: 0.6879292051900517
Epoch: 80 | Iteration number: [670/4518] 14% | Training loss: 0.6879149380014904
Epoch: 80 | Iteration number: [680/4518] 15% | Training loss: 0.6879007919746287
Epoch: 80 | Iteration number: [690/4518] 15% | Training loss: 0.687894506558128
Epoch: 80 | Iteration number: [700/4518] 15% | Training loss: 0.6878802702256611
Epoch: 80 | Iteration number: [710/4518] 15% | Training loss: 0.6878553993265394
Epoch: 80 | Iteration number: [720/4518] 15% | Training loss: 0.6878370358712144
Epoch: 80 | Iteration number: [730/4518] 16% | Training loss: 0.6878220209520157
Epoch: 80 | Iteration number: [740/4518] 16% | Training loss: 0.6878125722343857
Epoch: 80 | Iteration number: [750/4518] 16% | Training loss: 0.6877979808648428
Epoch: 80 | Iteration number: [760/4518] 16% | Training loss: 0.6877893262003597
Epoch: 80 | Iteration number: [770/4518] 17% | Training loss: 0.6877614481108529
Epoch: 80 | Iteration number: [780/4518] 17% | Training loss: 0.687746156561069
Epoch: 80 | Iteration number: [790/4518] 17% | Training loss: 0.687745536958115
Epoch: 80 | Iteration number: [800/4518] 17% | Training loss: 0.6877332100272179
Epoch: 80 | Iteration number: [810/4518] 17% | Training loss: 0.6877143010681058
Epoch: 80 | Iteration number: [820/4518] 18% | Training loss: 0.687708633120467
Epoch: 80 | Iteration number: [830/4518] 18% | Training loss: 0.6876990993338895
Epoch: 80 | Iteration number: [840/4518] 18% | Training loss: 0.6876811709432374
Epoch: 80 | Iteration number: [850/4518] 18% | Training loss: 0.6876541579470915
Epoch: 80 | Iteration number: [860/4518] 19% | Training loss: 0.6876386349284371
Epoch: 80 | Iteration number: [870/4518] 19% | Training loss: 0.6876274448701705
Epoch: 80 | Iteration number: [880/4518] 19% | Training loss: 0.6876155694777315
Epoch: 80 | Iteration number: [890/4518] 19% | Training loss: 0.6876178816463171
Epoch: 80 | Iteration number: [900/4518] 19% | Training loss: 0.6876057566536797
Epoch: 80 | Iteration number: [910/4518] 20% | Training loss: 0.6875871741509699
Epoch: 80 | Iteration number: [920/4518] 20% | Training loss: 0.6875810817531918
Epoch: 80 | Iteration number: [930/4518] 20% | Training loss: 0.6875740566561299
Epoch: 80 | Iteration number: [940/4518] 20% | Training loss: 0.6875633209943771
Epoch: 80 | Iteration number: [950/4518] 21% | Training loss: 0.6875451311939641
Epoch: 80 | Iteration number: [960/4518] 21% | Training loss: 0.6875336553280552
Epoch: 80 | Iteration number: [970/4518] 21% | Training loss: 0.6875335861727134
Epoch: 80 | Iteration number: [980/4518] 21% | Training loss: 0.6875338252101626
Epoch: 80 | Iteration number: [990/4518] 21% | Training loss: 0.6875271567792604
Epoch: 80 | Iteration number: [1000/4518] 22% | Training loss: 0.6875256602764129
Epoch: 80 | Iteration number: [1010/4518] 22% | Training loss: 0.6875273972454637
Epoch: 80 | Iteration number: [1020/4518] 22% | Training loss: 0.6875116432414335
Epoch: 80 | Iteration number: [1030/4518] 22% | Training loss: 0.6874998084549765
Epoch: 80 | Iteration number: [1040/4518] 23% | Training loss: 0.6874959768584141
Epoch: 80 | Iteration number: [1050/4518] 23% | Training loss: 0.6874830954983121
Epoch: 80 | Iteration number: [1060/4518] 23% | Training loss: 0.687476196885109
Epoch: 80 | Iteration number: [1070/4518] 23% | Training loss: 0.6874649597662632
Epoch: 80 | Iteration number: [1080/4518] 23% | Training loss: 0.6874647370643086
Epoch: 80 | Iteration number: [1090/4518] 24% | Training loss: 0.6874635578295506
Epoch: 80 | Iteration number: [1100/4518] 24% | Training loss: 0.6874573847922412
Epoch: 80 | Iteration number: [1110/4518] 24% | Training loss: 0.6874455731194299
Epoch: 80 | Iteration number: [1120/4518] 24% | Training loss: 0.6874364106782845
Epoch: 80 | Iteration number: [1130/4518] 25% | Training loss: 0.687423063115736
Epoch: 80 | Iteration number: [1140/4518] 25% | Training loss: 0.6874191216732326
Epoch: 80 | Iteration number: [1150/4518] 25% | Training loss: 0.6874256410806076
Epoch: 80 | Iteration number: [1160/4518] 25% | Training loss: 0.687406516691734
Epoch: 80 | Iteration number: [1170/4518] 25% | Training loss: 0.6874017716982426
Epoch: 80 | Iteration number: [1180/4518] 26% | Training loss: 0.6873904014542952
Epoch: 80 | Iteration number: [1190/4518] 26% | Training loss: 0.6873853766116775
Epoch: 80 | Iteration number: [1200/4518] 26% | Training loss: 0.6873755034307639
Epoch: 80 | Iteration number: [1210/4518] 26% | Training loss: 0.6873579274031741
Epoch: 80 | Iteration number: [1220/4518] 27% | Training loss: 0.6873411587027253
Epoch: 80 | Iteration number: [1230/4518] 27% | Training loss: 0.6873420514226929
Epoch: 80 | Iteration number: [1240/4518] 27% | Training loss: 0.687330731268852
Epoch: 80 | Iteration number: [1250/4518] 27% | Training loss: 0.6873203754425049
Epoch: 80 | Iteration number: [1260/4518] 27% | Training loss: 0.687321244534992
Epoch: 80 | Iteration number: [1270/4518] 28% | Training loss: 0.6873153433086365
Epoch: 80 | Iteration number: [1280/4518] 28% | Training loss: 0.6873197027947754
Epoch: 80 | Iteration number: [1290/4518] 28% | Training loss: 0.6872984843198643
Epoch: 80 | Iteration number: [1300/4518] 28% | Training loss: 0.6872920811634797
Epoch: 80 | Iteration number: [1310/4518] 28% | Training loss: 0.6872895031029942
Epoch: 80 | Iteration number: [1320/4518] 29% | Training loss: 0.6872806289430821
Epoch: 80 | Iteration number: [1330/4518] 29% | Training loss: 0.6872701307884732
Epoch: 80 | Iteration number: [1340/4518] 29% | Training loss: 0.6872599943805097
Epoch: 80 | Iteration number: [1350/4518] 29% | Training loss: 0.6872529672251807
Epoch: 80 | Iteration number: [1360/4518] 30% | Training loss: 0.6872446767109281
Epoch: 80 | Iteration number: [1370/4518] 30% | Training loss: 0.687243161627846
Epoch: 80 | Iteration number: [1380/4518] 30% | Training loss: 0.6872373343809791
Epoch: 80 | Iteration number: [1390/4518] 30% | Training loss: 0.6872380055969568
Epoch: 80 | Iteration number: [1400/4518] 30% | Training loss: 0.6872338384389878
Epoch: 80 | Iteration number: [1410/4518] 31% | Training loss: 0.6872335690133116
Epoch: 80 | Iteration number: [1420/4518] 31% | Training loss: 0.6872284291495739
Epoch: 80 | Iteration number: [1430/4518] 31% | Training loss: 0.6872180132182328
Epoch: 80 | Iteration number: [1440/4518] 31% | Training loss: 0.6872096102684736
Epoch: 80 | Iteration number: [1450/4518] 32% | Training loss: 0.6872123596586031
Epoch: 80 | Iteration number: [1460/4518] 32% | Training loss: 0.6872035036756567
Epoch: 80 | Iteration number: [1470/4518] 32% | Training loss: 0.6872076492325789
Epoch: 80 | Iteration number: [1480/4518] 32% | Training loss: 0.6871988695215534
Epoch: 80 | Iteration number: [1490/4518] 32% | Training loss: 0.6871807965256224
Epoch: 80 | Iteration number: [1500/4518] 33% | Training loss: 0.6871793895959855
Epoch: 80 | Iteration number: [1510/4518] 33% | Training loss: 0.6871723946751348
Epoch: 80 | Iteration number: [1520/4518] 33% | Training loss: 0.6871663840977769
Epoch: 80 | Iteration number: [1530/4518] 33% | Training loss: 0.6871718086837943
Epoch: 80 | Iteration number: [1540/4518] 34% | Training loss: 0.6871708533206543
Epoch: 80 | Iteration number: [1550/4518] 34% | Training loss: 0.6871696466784324
Epoch: 80 | Iteration number: [1560/4518] 34% | Training loss: 0.6871672878662746
Epoch: 80 | Iteration number: [1570/4518] 34% | Training loss: 0.6871600641186829
Epoch: 80 | Iteration number: [1580/4518] 34% | Training loss: 0.6871554524083681
Epoch: 80 | Iteration number: [1590/4518] 35% | Training loss: 0.6871512552477279
Epoch: 80 | Iteration number: [1600/4518] 35% | Training loss: 0.6871506267786026
Epoch: 80 | Iteration number: [1610/4518] 35% | Training loss: 0.6871475382251029
Epoch: 80 | Iteration number: [1620/4518] 35% | Training loss: 0.6871454736332835
Epoch: 80 | Iteration number: [1630/4518] 36% | Training loss: 0.6871495649492814
Epoch: 80 | Iteration number: [1640/4518] 36% | Training loss: 0.6871467615046152
Epoch: 80 | Iteration number: [1650/4518] 36% | Training loss: 0.6871492793343283
Epoch: 80 | Iteration number: [1660/4518] 36% | Training loss: 0.6871471810771759
Epoch: 80 | Iteration number: [1670/4518] 36% | Training loss: 0.6871462921182553
Epoch: 80 | Iteration number: [1680/4518] 37% | Training loss: 0.6871434132258097
Epoch: 80 | Iteration number: [1690/4518] 37% | Training loss: 0.6871390024585837
Epoch: 80 | Iteration number: [1700/4518] 37% | Training loss: 0.6871428356801762
Epoch: 80 | Iteration number: [1710/4518] 37% | Training loss: 0.6871437107610424
Epoch: 80 | Iteration number: [1720/4518] 38% | Training loss: 0.6871442860642145
Epoch: 80 | Iteration number: [1730/4518] 38% | Training loss: 0.6871435683586694
Epoch: 80 | Iteration number: [1740/4518] 38% | Training loss: 0.6871418885458475
Epoch: 80 | Iteration number: [1750/4518] 38% | Training loss: 0.6871373717444283
Epoch: 80 | Iteration number: [1760/4518] 38% | Training loss: 0.6871309099210934
Epoch: 80 | Iteration number: [1770/4518] 39% | Training loss: 0.6871267809032721
Epoch: 80 | Iteration number: [1780/4518] 39% | Training loss: 0.6871196173550038
Epoch: 80 | Iteration number: [1790/4518] 39% | Training loss: 0.6871139803079254
Epoch: 80 | Iteration number: [1800/4518] 39% | Training loss: 0.6871150283349885
Epoch: 80 | Iteration number: [1810/4518] 40% | Training loss: 0.6871167213547954
Epoch: 80 | Iteration number: [1820/4518] 40% | Training loss: 0.6871124658283296
Epoch: 80 | Iteration number: [1830/4518] 40% | Training loss: 0.6871105175526415
Epoch: 80 | Iteration number: [1840/4518] 40% | Training loss: 0.6871064327009346
Epoch: 80 | Iteration number: [1850/4518] 40% | Training loss: 0.6871097103325097
Epoch: 80 | Iteration number: [1860/4518] 41% | Training loss: 0.687105903798534
Epoch: 80 | Iteration number: [1870/4518] 41% | Training loss: 0.687105941103104
Epoch: 80 | Iteration number: [1880/4518] 41% | Training loss: 0.6871037404904974
Epoch: 80 | Iteration number: [1890/4518] 41% | Training loss: 0.6871017084550606
Epoch: 80 | Iteration number: [1900/4518] 42% | Training loss: 0.6870938683497279
Epoch: 80 | Iteration number: [1910/4518] 42% | Training loss: 0.6870885947611943
Epoch: 80 | Iteration number: [1920/4518] 42% | Training loss: 0.6870891414272289
Epoch: 80 | Iteration number: [1930/4518] 42% | Training loss: 0.6870823778636715
Epoch: 80 | Iteration number: [1940/4518] 42% | Training loss: 0.6870815140377615
Epoch: 80 | Iteration number: [1950/4518] 43% | Training loss: 0.6870834957636319
Epoch: 80 | Iteration number: [1960/4518] 43% | Training loss: 0.6870840809174946
Epoch: 80 | Iteration number: [1970/4518] 43% | Training loss: 0.6870814693155628
Epoch: 80 | Iteration number: [1980/4518] 43% | Training loss: 0.6870867254457088
Epoch: 80 | Iteration number: [1990/4518] 44% | Training loss: 0.6870807670468662
Epoch: 80 | Iteration number: [2000/4518] 44% | Training loss: 0.6870777196288109
Epoch: 80 | Iteration number: [2010/4518] 44% | Training loss: 0.6870837635068751
Epoch: 80 | Iteration number: [2020/4518] 44% | Training loss: 0.6870796113616169
Epoch: 80 | Iteration number: [2030/4518] 44% | Training loss: 0.6870816774556202
Epoch: 80 | Iteration number: [2040/4518] 45% | Training loss: 0.6870780196260003
Epoch: 80 | Iteration number: [2050/4518] 45% | Training loss: 0.6870756225178881
Epoch: 80 | Iteration number: [2060/4518] 45% | Training loss: 0.6870824268431339
Epoch: 80 | Iteration number: [2070/4518] 45% | Training loss: 0.6870860032701261
Epoch: 80 | Iteration number: [2080/4518] 46% | Training loss: 0.6870847830405602
Epoch: 80 | Iteration number: [2090/4518] 46% | Training loss: 0.687081637365396
Epoch: 80 | Iteration number: [2100/4518] 46% | Training loss: 0.6870768408832096
Epoch: 80 | Iteration number: [2110/4518] 46% | Training loss: 0.6870753047590572
Epoch: 80 | Iteration number: [2120/4518] 46% | Training loss: 0.6870716453723188
Epoch: 80 | Iteration number: [2130/4518] 47% | Training loss: 0.6870688695582985
Epoch: 80 | Iteration number: [2140/4518] 47% | Training loss: 0.6870658489031213
Epoch: 80 | Iteration number: [2150/4518] 47% | Training loss: 0.6870622724987739
Epoch: 80 | Iteration number: [2160/4518] 47% | Training loss: 0.6870561244311156
Epoch: 80 | Iteration number: [2170/4518] 48% | Training loss: 0.6870620254547365
Epoch: 80 | Iteration number: [2180/4518] 48% | Training loss: 0.6870528559619133
Epoch: 80 | Iteration number: [2190/4518] 48% | Training loss: 0.6870535480377337
Epoch: 80 | Iteration number: [2200/4518] 48% | Training loss: 0.687051301842386
Epoch: 80 | Iteration number: [2210/4518] 48% | Training loss: 0.6870515448205611
Epoch: 80 | Iteration number: [2220/4518] 49% | Training loss: 0.6870486594266719
Epoch: 80 | Iteration number: [2230/4518] 49% | Training loss: 0.6870510305257121
Epoch: 80 | Iteration number: [2240/4518] 49% | Training loss: 0.6870509808883071
Epoch: 80 | Iteration number: [2250/4518] 49% | Training loss: 0.6870524375703599
Epoch: 80 | Iteration number: [2260/4518] 50% | Training loss: 0.6870562150942541
Epoch: 80 | Iteration number: [2270/4518] 50% | Training loss: 0.6870570341395912
Epoch: 80 | Iteration number: [2280/4518] 50% | Training loss: 0.6870549336337206
Epoch: 80 | Iteration number: [2290/4518] 50% | Training loss: 0.687049945421094
Epoch: 80 | Iteration number: [2300/4518] 50% | Training loss: 0.6870513705067013
Epoch: 80 | Iteration number: [2310/4518] 51% | Training loss: 0.6870487059865679
Epoch: 80 | Iteration number: [2320/4518] 51% | Training loss: 0.687050412672347
Epoch: 80 | Iteration number: [2330/4518] 51% | Training loss: 0.6870527526595562
Epoch: 80 | Iteration number: [2340/4518] 51% | Training loss: 0.6870514892614805
Epoch: 80 | Iteration number: [2350/4518] 52% | Training loss: 0.6870476648655344
Epoch: 80 | Iteration number: [2360/4518] 52% | Training loss: 0.6870426381038407
Epoch: 80 | Iteration number: [2370/4518] 52% | Training loss: 0.6870425419716896
Epoch: 80 | Iteration number: [2380/4518] 52% | Training loss: 0.6870430576951564
Epoch: 80 | Iteration number: [2390/4518] 52% | Training loss: 0.6870457459942566
Epoch: 80 | Iteration number: [2400/4518] 53% | Training loss: 0.6870435995360216
Epoch: 80 | Iteration number: [2410/4518] 53% | Training loss: 0.687046599437587
Epoch: 80 | Iteration number: [2420/4518] 53% | Training loss: 0.6870479040155726
Epoch: 80 | Iteration number: [2430/4518] 53% | Training loss: 0.6870438117549252
Epoch: 80 | Iteration number: [2440/4518] 54% | Training loss: 0.687044715954632
Epoch: 80 | Iteration number: [2450/4518] 54% | Training loss: 0.6870513275204873
Epoch: 80 | Iteration number: [2460/4518] 54% | Training loss: 0.6870493686053811
Epoch: 80 | Iteration number: [2470/4518] 54% | Training loss: 0.6870528349992234
Epoch: 80 | Iteration number: [2480/4518] 54% | Training loss: 0.6870560048808975
Epoch: 80 | Iteration number: [2490/4518] 55% | Training loss: 0.6870503609917729
Epoch: 80 | Iteration number: [2500/4518] 55% | Training loss: 0.687053562951088
Epoch: 80 | Iteration number: [2510/4518] 55% | Training loss: 0.6870568635691685
Epoch: 80 | Iteration number: [2520/4518] 55% | Training loss: 0.6870547139218875
Epoch: 80 | Iteration number: [2530/4518] 55% | Training loss: 0.6870571769744511
Epoch: 80 | Iteration number: [2540/4518] 56% | Training loss: 0.6870525733223112
Epoch: 80 | Iteration number: [2550/4518] 56% | Training loss: 0.6870512453715006
Epoch: 80 | Iteration number: [2560/4518] 56% | Training loss: 0.6870509473839774
Epoch: 80 | Iteration number: [2570/4518] 56% | Training loss: 0.6870527522109362
Epoch: 80 | Iteration number: [2580/4518] 57% | Training loss: 0.6870494369388551
Epoch: 80 | Iteration number: [2590/4518] 57% | Training loss: 0.6870475541440677
Epoch: 80 | Iteration number: [2600/4518] 57% | Training loss: 0.687043209030078
Epoch: 80 | Iteration number: [2610/4518] 57% | Training loss: 0.6870442855403798
Epoch: 80 | Iteration number: [2620/4518] 57% | Training loss: 0.6870429777462064
Epoch: 80 | Iteration number: [2630/4518] 58% | Training loss: 0.6870377556452733
Epoch: 80 | Iteration number: [2640/4518] 58% | Training loss: 0.6870361477588163
Epoch: 80 | Iteration number: [2650/4518] 58% | Training loss: 0.6870326566696167
Epoch: 80 | Iteration number: [2660/4518] 58% | Training loss: 0.6870324097181622
Epoch: 80 | Iteration number: [2670/4518] 59% | Training loss: 0.6870281391152728
Epoch: 80 | Iteration number: [2680/4518] 59% | Training loss: 0.6870297460191286
Epoch: 80 | Iteration number: [2690/4518] 59% | Training loss: 0.6870299335527598
Epoch: 80 | Iteration number: [2700/4518] 59% | Training loss: 0.6870285051178049
Epoch: 80 | Iteration number: [2710/4518] 59% | Training loss: 0.6870257881514701
Epoch: 80 | Iteration number: [2720/4518] 60% | Training loss: 0.6870254416676128
Epoch: 80 | Iteration number: [2730/4518] 60% | Training loss: 0.6870216235573039
Epoch: 80 | Iteration number: [2740/4518] 60% | Training loss: 0.6870241480369638
Epoch: 80 | Iteration number: [2750/4518] 60% | Training loss: 0.6870221796469255
Epoch: 80 | Iteration number: [2760/4518] 61% | Training loss: 0.6870240065498628
Epoch: 80 | Iteration number: [2770/4518] 61% | Training loss: 0.6870239835999072
Epoch: 80 | Iteration number: [2780/4518] 61% | Training loss: 0.687021051400857
Epoch: 80 | Iteration number: [2790/4518] 61% | Training loss: 0.6870177229245503
Epoch: 80 | Iteration number: [2800/4518] 61% | Training loss: 0.6870162168996675
Epoch: 80 | Iteration number: [2810/4518] 62% | Training loss: 0.6870162505696252
Epoch: 80 | Iteration number: [2820/4518] 62% | Training loss: 0.6870151219638527
Epoch: 80 | Iteration number: [2830/4518] 62% | Training loss: 0.6870140867182728
Epoch: 80 | Iteration number: [2840/4518] 62% | Training loss: 0.6870137573967517
Epoch: 80 | Iteration number: [2850/4518] 63% | Training loss: 0.6870141763436167
Epoch: 80 | Iteration number: [2860/4518] 63% | Training loss: 0.6870144793828884
Epoch: 80 | Iteration number: [2870/4518] 63% | Training loss: 0.6870171652022969
Epoch: 80 | Iteration number: [2880/4518] 63% | Training loss: 0.6870139794424176
Epoch: 80 | Iteration number: [2890/4518] 63% | Training loss: 0.6870165986379537
Epoch: 80 | Iteration number: [2900/4518] 64% | Training loss: 0.6870137438280829
Epoch: 80 | Iteration number: [2910/4518] 64% | Training loss: 0.6870137407197985
Epoch: 80 | Iteration number: [2920/4518] 64% | Training loss: 0.6870126013478187
Epoch: 80 | Iteration number: [2930/4518] 64% | Training loss: 0.6870098705788115
Epoch: 80 | Iteration number: [2940/4518] 65% | Training loss: 0.6870113155874266
Epoch: 80 | Iteration number: [2950/4518] 65% | Training loss: 0.6870107045820204
Epoch: 80 | Iteration number: [2960/4518] 65% | Training loss: 0.6870106127415154
Epoch: 80 | Iteration number: [2970/4518] 65% | Training loss: 0.6870137300354865
Epoch: 80 | Iteration number: [2980/4518] 65% | Training loss: 0.6870115604576649
Epoch: 80 | Iteration number: [2990/4518] 66% | Training loss: 0.6870134310379474
Epoch: 80 | Iteration number: [3000/4518] 66% | Training loss: 0.6870146603385607
Epoch: 80 | Iteration number: [3010/4518] 66% | Training loss: 0.6870114510637582
Epoch: 80 | Iteration number: [3020/4518] 66% | Training loss: 0.6870090944088058
Epoch: 80 | Iteration number: [3030/4518] 67% | Training loss: 0.6870079151868034
Epoch: 80 | Iteration number: [3040/4518] 67% | Training loss: 0.6870074580962721
Epoch: 80 | Iteration number: [3050/4518] 67% | Training loss: 0.6870084560112875
Epoch: 80 | Iteration number: [3060/4518] 67% | Training loss: 0.6870070942866257
Epoch: 80 | Iteration number: [3070/4518] 67% | Training loss: 0.6870033396183474
Epoch: 80 | Iteration number: [3080/4518] 68% | Training loss: 0.6869992416400414
Epoch: 80 | Iteration number: [3090/4518] 68% | Training loss: 0.686996870229931
Epoch: 80 | Iteration number: [3100/4518] 68% | Training loss: 0.6869965990512602
Epoch: 80 | Iteration number: [3110/4518] 68% | Training loss: 0.6869978878850722
Epoch: 80 | Iteration number: [3120/4518] 69% | Training loss: 0.6869939328768314
Epoch: 80 | Iteration number: [3130/4518] 69% | Training loss: 0.6869927863533886
Epoch: 80 | Iteration number: [3140/4518] 69% | Training loss: 0.6869877662818143
Epoch: 80 | Iteration number: [3150/4518] 69% | Training loss: 0.6869889624913533
Epoch: 80 | Iteration number: [3160/4518] 69% | Training loss: 0.6869871952488452
Epoch: 80 | Iteration number: [3170/4518] 70% | Training loss: 0.6869803090200816
Epoch: 80 | Iteration number: [3180/4518] 70% | Training loss: 0.6869817349145997
Epoch: 80 | Iteration number: [3190/4518] 70% | Training loss: 0.6869797304879909
Epoch: 80 | Iteration number: [3200/4518] 70% | Training loss: 0.6869747157022357
Epoch: 80 | Iteration number: [3210/4518] 71% | Training loss: 0.6869719473372368
Epoch: 80 | Iteration number: [3220/4518] 71% | Training loss: 0.6869681498834065
Epoch: 80 | Iteration number: [3230/4518] 71% | Training loss: 0.6869636844739825
Epoch: 80 | Iteration number: [3240/4518] 71% | Training loss: 0.6869592040041347
Epoch: 80 | Iteration number: [3250/4518] 71% | Training loss: 0.686957196015578
Epoch: 80 | Iteration number: [3260/4518] 72% | Training loss: 0.6869598441328739
Epoch: 80 | Iteration number: [3270/4518] 72% | Training loss: 0.6869613525699767
Epoch: 80 | Iteration number: [3280/4518] 72% | Training loss: 0.6869631614626908
Epoch: 80 | Iteration number: [3290/4518] 72% | Training loss: 0.6869609082723461
Epoch: 80 | Iteration number: [3300/4518] 73% | Training loss: 0.6869618551839481
Epoch: 80 | Iteration number: [3310/4518] 73% | Training loss: 0.6869595420144475
Epoch: 80 | Iteration number: [3320/4518] 73% | Training loss: 0.6869558090905109
Epoch: 80 | Iteration number: [3330/4518] 73% | Training loss: 0.6869571839724933
Epoch: 80 | Iteration number: [3340/4518] 73% | Training loss: 0.6869572509727079
Epoch: 80 | Iteration number: [3350/4518] 74% | Training loss: 0.6869570465052306
Epoch: 80 | Iteration number: [3360/4518] 74% | Training loss: 0.6869577388678278
Epoch: 80 | Iteration number: [3370/4518] 74% | Training loss: 0.6869588984756866
Epoch: 80 | Iteration number: [3380/4518] 74% | Training loss: 0.6869613749212062
Epoch: 80 | Iteration number: [3390/4518] 75% | Training loss: 0.6869615476215836
Epoch: 80 | Iteration number: [3400/4518] 75% | Training loss: 0.6869611443491543
Epoch: 80 | Iteration number: [3410/4518] 75% | Training loss: 0.686961331360501
Epoch: 80 | Iteration number: [3420/4518] 75% | Training loss: 0.6869569780010926
Epoch: 80 | Iteration number: [3430/4518] 75% | Training loss: 0.6869538208833589
Epoch: 80 | Iteration number: [3440/4518] 76% | Training loss: 0.6869525929349799
Epoch: 80 | Iteration number: [3450/4518] 76% | Training loss: 0.6869520353925401
Epoch: 80 | Iteration number: [3460/4518] 76% | Training loss: 0.686950221657753
Epoch: 80 | Iteration number: [3470/4518] 76% | Training loss: 0.6869518674759768
Epoch: 80 | Iteration number: [3480/4518] 77% | Training loss: 0.6869519570949434
Epoch: 80 | Iteration number: [3490/4518] 77% | Training loss: 0.6869493302779758
Epoch: 80 | Iteration number: [3500/4518] 77% | Training loss: 0.6869455430167062
Epoch: 80 | Iteration number: [3510/4518] 77% | Training loss: 0.6869409526685024
Epoch: 80 | Iteration number: [3520/4518] 77% | Training loss: 0.686938933587887
Epoch: 80 | Iteration number: [3530/4518] 78% | Training loss: 0.6869394013294079
Epoch: 80 | Iteration number: [3540/4518] 78% | Training loss: 0.6869318617434151
Epoch: 80 | Iteration number: [3550/4518] 78% | Training loss: 0.68693104119368
Epoch: 80 | Iteration number: [3560/4518] 78% | Training loss: 0.6869297805964277
Epoch: 80 | Iteration number: [3570/4518] 79% | Training loss: 0.6869296020820361
Epoch: 80 | Iteration number: [3580/4518] 79% | Training loss: 0.6869285326596745
Epoch: 80 | Iteration number: [3590/4518] 79% | Training loss: 0.6869294482519368
Epoch: 80 | Iteration number: [3600/4518] 79% | Training loss: 0.686933976676729
Epoch: 80 | Iteration number: [3610/4518] 79% | Training loss: 0.6869341271240625
Epoch: 80 | Iteration number: [3620/4518] 80% | Training loss: 0.6869331649489165
Epoch: 80 | Iteration number: [3630/4518] 80% | Training loss: 0.6869366325130147
Epoch: 80 | Iteration number: [3640/4518] 80% | Training loss: 0.6869378603257976
Epoch: 80 | Iteration number: [3650/4518] 80% | Training loss: 0.6869364565365935
Epoch: 80 | Iteration number: [3660/4518] 81% | Training loss: 0.6869382994259642
Epoch: 80 | Iteration number: [3670/4518] 81% | Training loss: 0.6869390915135272
Epoch: 80 | Iteration number: [3680/4518] 81% | Training loss: 0.6869372454674347
Epoch: 80 | Iteration number: [3690/4518] 81% | Training loss: 0.6869356984045447
Epoch: 80 | Iteration number: [3700/4518] 81% | Training loss: 0.6869372396533554
Epoch: 80 | Iteration number: [3710/4518] 82% | Training loss: 0.6869356397027275
Epoch: 80 | Iteration number: [3720/4518] 82% | Training loss: 0.6869362384561569
Epoch: 80 | Iteration number: [3730/4518] 82% | Training loss: 0.6869340508297366
Epoch: 80 | Iteration number: [3740/4518] 82% | Training loss: 0.6869328225678939
Epoch: 80 | Iteration number: [3750/4518] 83% | Training loss: 0.686934037955602
Epoch: 80 | Iteration number: [3760/4518] 83% | Training loss: 0.6869333167183906
Epoch: 80 | Iteration number: [3770/4518] 83% | Training loss: 0.6869324914340316
Epoch: 80 | Iteration number: [3780/4518] 83% | Training loss: 0.6869351194018409
Epoch: 80 | Iteration number: [3790/4518] 83% | Training loss: 0.6869366797262257
Epoch: 80 | Iteration number: [3800/4518] 84% | Training loss: 0.6869351435648767
Epoch: 80 | Iteration number: [3810/4518] 84% | Training loss: 0.6869356247696664
Epoch: 80 | Iteration number: [3820/4518] 84% | Training loss: 0.6869341727950811
Epoch: 80 | Iteration number: [3830/4518] 84% | Training loss: 0.6869342481187367
Epoch: 80 | Iteration number: [3840/4518] 84% | Training loss: 0.6869333775714039
Epoch: 80 | Iteration number: [3850/4518] 85% | Training loss: 0.6869328334114768
Epoch: 80 | Iteration number: [3860/4518] 85% | Training loss: 0.6869304592436459
Epoch: 80 | Iteration number: [3870/4518] 85% | Training loss: 0.6869305439697679
Epoch: 80 | Iteration number: [3880/4518] 85% | Training loss: 0.6869325320130771
Epoch: 80 | Iteration number: [3890/4518] 86% | Training loss: 0.686934552247849
Epoch: 80 | Iteration number: [3900/4518] 86% | Training loss: 0.6869365101594191
Epoch: 80 | Iteration number: [3910/4518] 86% | Training loss: 0.6869347239241881
Epoch: 80 | Iteration number: [3920/4518] 86% | Training loss: 0.6869356027975374
Epoch: 80 | Iteration number: [3930/4518] 86% | Training loss: 0.6869345230455617
Epoch: 80 | Iteration number: [3940/4518] 87% | Training loss: 0.686934059828066
Epoch: 80 | Iteration number: [3950/4518] 87% | Training loss: 0.6869359902490544
Epoch: 80 | Iteration number: [3960/4518] 87% | Training loss: 0.6869366070387339
Epoch: 80 | Iteration number: [3970/4518] 87% | Training loss: 0.6869374708204485
Epoch: 80 | Iteration number: [3980/4518] 88% | Training loss: 0.6869417320394037
Epoch: 80 | Iteration number: [3990/4518] 88% | Training loss: 0.6869432894657728
Epoch: 80 | Iteration number: [4000/4518] 88% | Training loss: 0.6869439045488834
Epoch: 80 | Iteration number: [4010/4518] 88% | Training loss: 0.6869434256506085
Epoch: 80 | Iteration number: [4020/4518] 88% | Training loss: 0.6869424591165277
Epoch: 80 | Iteration number: [4030/4518] 89% | Training loss: 0.6869422864529394
Epoch: 80 | Iteration number: [4040/4518] 89% | Training loss: 0.6869418441954226
Epoch: 80 | Iteration number: [4050/4518] 89% | Training loss: 0.6869428231392378
Epoch: 80 | Iteration number: [4060/4518] 89% | Training loss: 0.6869427028694763
Epoch: 80 | Iteration number: [4070/4518] 90% | Training loss: 0.6869427293905169
Epoch: 80 | Iteration number: [4080/4518] 90% | Training loss: 0.6869374764462312
Epoch: 80 | Iteration number: [4090/4518] 90% | Training loss: 0.6869358030974427
Epoch: 80 | Iteration number: [4100/4518] 90% | Training loss: 0.6869329406866214
Epoch: 80 | Iteration number: [4110/4518] 90% | Training loss: 0.6869300732792439
Epoch: 80 | Iteration number: [4120/4518] 91% | Training loss: 0.6869310820854984
Epoch: 80 | Iteration number: [4130/4518] 91% | Training loss: 0.6869312066720127
Epoch: 80 | Iteration number: [4140/4518] 91% | Training loss: 0.6869301327184778
Epoch: 80 | Iteration number: [4150/4518] 91% | Training loss: 0.6869300321642174
Epoch: 80 | Iteration number: [4160/4518] 92% | Training loss: 0.6869281394120592
Epoch: 80 | Iteration number: [4170/4518] 92% | Training loss: 0.6869282858548976
Epoch: 80 | Iteration number: [4180/4518] 92% | Training loss: 0.6869278767034768
Epoch: 80 | Iteration number: [4190/4518] 92% | Training loss: 0.6869284248295149
Epoch: 80 | Iteration number: [4200/4518] 92% | Training loss: 0.6869286272213573
Epoch: 80 | Iteration number: [4210/4518] 93% | Training loss: 0.686929926495654
Epoch: 80 | Iteration number: [4220/4518] 93% | Training loss: 0.6869248742317137
Epoch: 80 | Iteration number: [4230/4518] 93% | Training loss: 0.6869230230649312
Epoch: 80 | Iteration number: [4240/4518] 93% | Training loss: 0.6869204449766088
Epoch: 80 | Iteration number: [4250/4518] 94% | Training loss: 0.6869180121281567
Epoch: 80 | Iteration number: [4260/4518] 94% | Training loss: 0.6869163855700425
Epoch: 80 | Iteration number: [4270/4518] 94% | Training loss: 0.6869165337476574
Epoch: 80 | Iteration number: [4280/4518] 94% | Training loss: 0.686915665405376
Epoch: 80 | Iteration number: [4290/4518] 94% | Training loss: 0.6869149890396145
Epoch: 80 | Iteration number: [4300/4518] 95% | Training loss: 0.6869145789950393
Epoch: 80 | Iteration number: [4310/4518] 95% | Training loss: 0.6869141934089483
Epoch: 80 | Iteration number: [4320/4518] 95% | Training loss: 0.6869132708620143
Epoch: 80 | Iteration number: [4330/4518] 95% | Training loss: 0.6869122646697399
Epoch: 80 | Iteration number: [4340/4518] 96% | Training loss: 0.6869110635211391
Epoch: 80 | Iteration number: [4350/4518] 96% | Training loss: 0.68691006305574
Epoch: 80 | Iteration number: [4360/4518] 96% | Training loss: 0.686911056498322
Epoch: 80 | Iteration number: [4370/4518] 96% | Training loss: 0.6869106712821419
Epoch: 80 | Iteration number: [4380/4518] 96% | Training loss: 0.6869102802722966
Epoch: 80 | Iteration number: [4390/4518] 97% | Training loss: 0.6869089538388481
Epoch: 80 | Iteration number: [4400/4518] 97% | Training loss: 0.6869061476534063
Epoch: 80 | Iteration number: [4410/4518] 97% | Training loss: 0.6869073031575772
Epoch: 80 | Iteration number: [4420/4518] 97% | Training loss: 0.6869101267459705
Epoch: 80 | Iteration number: [4430/4518] 98% | Training loss: 0.6869116286660963
Epoch: 80 | Iteration number: [4440/4518] 98% | Training loss: 0.6869124732844465
Epoch: 80 | Iteration number: [4450/4518] 98% | Training loss: 0.6869138664743873
Epoch: 80 | Iteration number: [4460/4518] 98% | Training loss: 0.6869125026223906
Epoch: 80 | Iteration number: [4470/4518] 98% | Training loss: 0.6869141675348517
Epoch: 80 | Iteration number: [4480/4518] 99% | Training loss: 0.6869157332128712
Epoch: 80 | Iteration number: [4490/4518] 99% | Training loss: 0.6869131202554384
Epoch: 80 | Iteration number: [4500/4518] 99% | Training loss: 0.6869126686520046
Epoch: 80 | Iteration number: [4510/4518] 99% | Training loss: 0.6869121367413294

 End of epoch: 80 | Train Loss: 0.6867604615573284 | Training Time: 641 

 End of epoch: 80 | Eval Loss: 0.6897882247457698 | Evaluating Time: 17 
Epoch: 81 | Iteration number: [10/4518] 0% | Training loss: 0.7565560221672059
Epoch: 81 | Iteration number: [20/4518] 0% | Training loss: 0.7214493036270142
Epoch: 81 | Iteration number: [30/4518] 0% | Training loss: 0.7100720425446828
Epoch: 81 | Iteration number: [40/4518] 0% | Training loss: 0.7045940741896629
Epoch: 81 | Iteration number: [50/4518] 1% | Training loss: 0.7011395168304443
Epoch: 81 | Iteration number: [60/4518] 1% | Training loss: 0.6986986378828685
Epoch: 81 | Iteration number: [70/4518] 1% | Training loss: 0.6969512258257184
Epoch: 81 | Iteration number: [80/4518] 1% | Training loss: 0.6955696605145931
Epoch: 81 | Iteration number: [90/4518] 1% | Training loss: 0.6946887248092227
Epoch: 81 | Iteration number: [100/4518] 2% | Training loss: 0.694022461771965
Epoch: 81 | Iteration number: [110/4518] 2% | Training loss: 0.6933326883749529
Epoch: 81 | Iteration number: [120/4518] 2% | Training loss: 0.6928929204742114
Epoch: 81 | Iteration number: [130/4518] 2% | Training loss: 0.6924308639306288
Epoch: 81 | Iteration number: [140/4518] 3% | Training loss: 0.6920810358864921
Epoch: 81 | Iteration number: [150/4518] 3% | Training loss: 0.6916156391302745
Epoch: 81 | Iteration number: [160/4518] 3% | Training loss: 0.691239396110177
Epoch: 81 | Iteration number: [170/4518] 3% | Training loss: 0.6909350198857924
Epoch: 81 | Iteration number: [180/4518] 3% | Training loss: 0.690656276875072
Epoch: 81 | Iteration number: [190/4518] 4% | Training loss: 0.6904501149528905
Epoch: 81 | Iteration number: [200/4518] 4% | Training loss: 0.6901512184739113
Epoch: 81 | Iteration number: [210/4518] 4% | Training loss: 0.6900268182868049
Epoch: 81 | Iteration number: [220/4518] 4% | Training loss: 0.689886314760555
Epoch: 81 | Iteration number: [230/4518] 5% | Training loss: 0.6897969836774079
Epoch: 81 | Iteration number: [240/4518] 5% | Training loss: 0.6896340991059939
Epoch: 81 | Iteration number: [250/4518] 5% | Training loss: 0.6895650882720947
Epoch: 81 | Iteration number: [260/4518] 5% | Training loss: 0.6894806953576895
Epoch: 81 | Iteration number: [270/4518] 5% | Training loss: 0.6893731503574937
Epoch: 81 | Iteration number: [280/4518] 6% | Training loss: 0.6892800707902227
Epoch: 81 | Iteration number: [290/4518] 6% | Training loss: 0.6892145356227611
Epoch: 81 | Iteration number: [300/4518] 6% | Training loss: 0.6891463081041972
Epoch: 81 | Iteration number: [310/4518] 6% | Training loss: 0.6890446968616978
Epoch: 81 | Iteration number: [320/4518] 7% | Training loss: 0.6889758897945285
Epoch: 81 | Iteration number: [330/4518] 7% | Training loss: 0.6889071244182009
Epoch: 81 | Iteration number: [340/4518] 7% | Training loss: 0.6888388810788884
Epoch: 81 | Iteration number: [350/4518] 7% | Training loss: 0.6887850388458797
Epoch: 81 | Iteration number: [360/4518] 7% | Training loss: 0.6887051348884901
Epoch: 81 | Iteration number: [370/4518] 8% | Training loss: 0.6886548799437445
Epoch: 81 | Iteration number: [380/4518] 8% | Training loss: 0.6886026256962826
Epoch: 81 | Iteration number: [390/4518] 8% | Training loss: 0.6885575626140986
Epoch: 81 | Iteration number: [400/4518] 8% | Training loss: 0.6884935513138771
Epoch: 81 | Iteration number: [410/4518] 9% | Training loss: 0.6884449009488268
Epoch: 81 | Iteration number: [420/4518] 9% | Training loss: 0.6883969187736512
Epoch: 81 | Iteration number: [430/4518] 9% | Training loss: 0.6883715849976207
Epoch: 81 | Iteration number: [440/4518] 9% | Training loss: 0.6883313051678918
Epoch: 81 | Iteration number: [450/4518] 9% | Training loss: 0.6883080552683937
Epoch: 81 | Iteration number: [460/4518] 10% | Training loss: 0.6882671549268391
Epoch: 81 | Iteration number: [470/4518] 10% | Training loss: 0.6882478049460877
Epoch: 81 | Iteration number: [480/4518] 10% | Training loss: 0.6881896299620469
Epoch: 81 | Iteration number: [490/4518] 10% | Training loss: 0.6881558202967352
Epoch: 81 | Iteration number: [500/4518] 11% | Training loss: 0.6881237273216247
Epoch: 81 | Iteration number: [510/4518] 11% | Training loss: 0.688102571403279
Epoch: 81 | Iteration number: [520/4518] 11% | Training loss: 0.6880846259685663
Epoch: 81 | Iteration number: [530/4518] 11% | Training loss: 0.6880620488580668
Epoch: 81 | Iteration number: [540/4518] 11% | Training loss: 0.688051078385777
Epoch: 81 | Iteration number: [550/4518] 12% | Training loss: 0.6880297335711393
Epoch: 81 | Iteration number: [560/4518] 12% | Training loss: 0.6879854274647577
Epoch: 81 | Iteration number: [570/4518] 12% | Training loss: 0.687972406023427
Epoch: 81 | Iteration number: [580/4518] 12% | Training loss: 0.6879406787198166
Epoch: 81 | Iteration number: [590/4518] 13% | Training loss: 0.6879234864550122
Epoch: 81 | Iteration number: [600/4518] 13% | Training loss: 0.6879099732637406
Epoch: 81 | Iteration number: [610/4518] 13% | Training loss: 0.6878839828928963
Epoch: 81 | Iteration number: [620/4518] 13% | Training loss: 0.6878659415629602
Epoch: 81 | Iteration number: [630/4518] 13% | Training loss: 0.6878550747084239
Epoch: 81 | Iteration number: [640/4518] 14% | Training loss: 0.6878355454653502
Epoch: 81 | Iteration number: [650/4518] 14% | Training loss: 0.6878172509486858
Epoch: 81 | Iteration number: [660/4518] 14% | Training loss: 0.6877990827415928
Epoch: 81 | Iteration number: [670/4518] 14% | Training loss: 0.6877879890043344
Epoch: 81 | Iteration number: [680/4518] 15% | Training loss: 0.6877634895198486
Epoch: 81 | Iteration number: [690/4518] 15% | Training loss: 0.6877591024274411
Epoch: 81 | Iteration number: [700/4518] 15% | Training loss: 0.6877435294219426
Epoch: 81 | Iteration number: [710/4518] 15% | Training loss: 0.6877249326504452
Epoch: 81 | Iteration number: [720/4518] 15% | Training loss: 0.6876980665657255
Epoch: 81 | Iteration number: [730/4518] 16% | Training loss: 0.687694989328515
Epoch: 81 | Iteration number: [740/4518] 16% | Training loss: 0.6876741573617265
Epoch: 81 | Iteration number: [750/4518] 16% | Training loss: 0.687656710465749
Epoch: 81 | Iteration number: [760/4518] 16% | Training loss: 0.6876378282904625
Epoch: 81 | Iteration number: [770/4518] 17% | Training loss: 0.6876042685725472
Epoch: 81 | Iteration number: [780/4518] 17% | Training loss: 0.6875935189999067
Epoch: 81 | Iteration number: [790/4518] 17% | Training loss: 0.6875786926927446
Epoch: 81 | Iteration number: [800/4518] 17% | Training loss: 0.6875862123817206
Epoch: 81 | Iteration number: [810/4518] 17% | Training loss: 0.6875802394784527
Epoch: 81 | Iteration number: [820/4518] 18% | Training loss: 0.6875629171365645
Epoch: 81 | Iteration number: [830/4518] 18% | Training loss: 0.6875632001692991
Epoch: 81 | Iteration number: [840/4518] 18% | Training loss: 0.6875430759219896
Epoch: 81 | Iteration number: [850/4518] 18% | Training loss: 0.6875279765970567
Epoch: 81 | Iteration number: [860/4518] 19% | Training loss: 0.6875205173048862
Epoch: 81 | Iteration number: [870/4518] 19% | Training loss: 0.6875228579016938
Epoch: 81 | Iteration number: [880/4518] 19% | Training loss: 0.6875176304443316
Epoch: 81 | Iteration number: [890/4518] 19% | Training loss: 0.6875154612439403
Epoch: 81 | Iteration number: [900/4518] 19% | Training loss: 0.6875178850359387
Epoch: 81 | Iteration number: [910/4518] 20% | Training loss: 0.6875222439949329
Epoch: 81 | Iteration number: [920/4518] 20% | Training loss: 0.6875039834043254
Epoch: 81 | Iteration number: [930/4518] 20% | Training loss: 0.6874868422426204
Epoch: 81 | Iteration number: [940/4518] 20% | Training loss: 0.6874796173039903
Epoch: 81 | Iteration number: [950/4518] 21% | Training loss: 0.6874643533480794
Epoch: 81 | Iteration number: [960/4518] 21% | Training loss: 0.6874561325957378
Epoch: 81 | Iteration number: [970/4518] 21% | Training loss: 0.6874565968193959
Epoch: 81 | Iteration number: [980/4518] 21% | Training loss: 0.6874414531552062
Epoch: 81 | Iteration number: [990/4518] 21% | Training loss: 0.6874202419411052
Epoch: 81 | Iteration number: [1000/4518] 22% | Training loss: 0.6874197092652321
Epoch: 81 | Iteration number: [1010/4518] 22% | Training loss: 0.6874112617851484
Epoch: 81 | Iteration number: [1020/4518] 22% | Training loss: 0.6873855691914464
Epoch: 81 | Iteration number: [1030/4518] 22% | Training loss: 0.687376765429395
Epoch: 81 | Iteration number: [1040/4518] 23% | Training loss: 0.6873680607057535
Epoch: 81 | Iteration number: [1050/4518] 23% | Training loss: 0.6873719567911966
Epoch: 81 | Iteration number: [1060/4518] 23% | Training loss: 0.6873733839336431
Epoch: 81 | Iteration number: [1070/4518] 23% | Training loss: 0.6873694081729818
Epoch: 81 | Iteration number: [1080/4518] 23% | Training loss: 0.6873590781180947
Epoch: 81 | Iteration number: [1090/4518] 24% | Training loss: 0.6873649718564585
Epoch: 81 | Iteration number: [1100/4518] 24% | Training loss: 0.6873615218292584
Epoch: 81 | Iteration number: [1110/4518] 24% | Training loss: 0.6873561405383789
Epoch: 81 | Iteration number: [1120/4518] 24% | Training loss: 0.6873523463095937
Epoch: 81 | Iteration number: [1130/4518] 25% | Training loss: 0.6873451100513999
Epoch: 81 | Iteration number: [1140/4518] 25% | Training loss: 0.6873321561436904
Epoch: 81 | Iteration number: [1150/4518] 25% | Training loss: 0.6873227347498355
Epoch: 81 | Iteration number: [1160/4518] 25% | Training loss: 0.687322195901953
Epoch: 81 | Iteration number: [1170/4518] 25% | Training loss: 0.6873227325769571
Epoch: 81 | Iteration number: [1180/4518] 26% | Training loss: 0.68731361758911
Epoch: 81 | Iteration number: [1190/4518] 26% | Training loss: 0.6873114953021041
Epoch: 81 | Iteration number: [1200/4518] 26% | Training loss: 0.687297596981128
Epoch: 81 | Iteration number: [1210/4518] 26% | Training loss: 0.6872947943604683
Epoch: 81 | Iteration number: [1220/4518] 27% | Training loss: 0.687301151674302
Epoch: 81 | Iteration number: [1230/4518] 27% | Training loss: 0.6872950445830337
Epoch: 81 | Iteration number: [1240/4518] 27% | Training loss: 0.687289169478801
Epoch: 81 | Iteration number: [1250/4518] 27% | Training loss: 0.6872734929561615
Epoch: 81 | Iteration number: [1260/4518] 27% | Training loss: 0.6872573984047723
Epoch: 81 | Iteration number: [1270/4518] 28% | Training loss: 0.6872495178162582
Epoch: 81 | Iteration number: [1280/4518] 28% | Training loss: 0.6872457977849991
Epoch: 81 | Iteration number: [1290/4518] 28% | Training loss: 0.6872453546801279
Epoch: 81 | Iteration number: [1300/4518] 28% | Training loss: 0.6872388105667554
Epoch: 81 | Iteration number: [1310/4518] 28% | Training loss: 0.6872415146754898
Epoch: 81 | Iteration number: [1320/4518] 29% | Training loss: 0.6872500777244568
Epoch: 81 | Iteration number: [1330/4518] 29% | Training loss: 0.6872503192353069
Epoch: 81 | Iteration number: [1340/4518] 29% | Training loss: 0.6872387568897276
Epoch: 81 | Iteration number: [1350/4518] 29% | Training loss: 0.687231617503696
Epoch: 81 | Iteration number: [1360/4518] 30% | Training loss: 0.6872329305638285
Epoch: 81 | Iteration number: [1370/4518] 30% | Training loss: 0.6872402304280414
Epoch: 81 | Iteration number: [1380/4518] 30% | Training loss: 0.6872361961482227
Epoch: 81 | Iteration number: [1390/4518] 30% | Training loss: 0.6872263362081789
Epoch: 81 | Iteration number: [1400/4518] 30% | Training loss: 0.6872272117223058
Epoch: 81 | Iteration number: [1410/4518] 31% | Training loss: 0.6872227106533998
Epoch: 81 | Iteration number: [1420/4518] 31% | Training loss: 0.6872070174821665
Epoch: 81 | Iteration number: [1430/4518] 31% | Training loss: 0.6872046601939035
Epoch: 81 | Iteration number: [1440/4518] 31% | Training loss: 0.6871950570493937
Epoch: 81 | Iteration number: [1450/4518] 32% | Training loss: 0.6872006340684562
Epoch: 81 | Iteration number: [1460/4518] 32% | Training loss: 0.6871927198890138
Epoch: 81 | Iteration number: [1470/4518] 32% | Training loss: 0.6871835039586437
Epoch: 81 | Iteration number: [1480/4518] 32% | Training loss: 0.6871864529074849
Epoch: 81 | Iteration number: [1490/4518] 32% | Training loss: 0.6871842513548447
Epoch: 81 | Iteration number: [1500/4518] 33% | Training loss: 0.6871858987410864
Epoch: 81 | Iteration number: [1510/4518] 33% | Training loss: 0.6871794390757352
Epoch: 81 | Iteration number: [1520/4518] 33% | Training loss: 0.6871777691731328
Epoch: 81 | Iteration number: [1530/4518] 33% | Training loss: 0.6871791891412797
Epoch: 81 | Iteration number: [1540/4518] 34% | Training loss: 0.687171755750458
Epoch: 81 | Iteration number: [1550/4518] 34% | Training loss: 0.6871699037859517
Epoch: 81 | Iteration number: [1560/4518] 34% | Training loss: 0.6871584530060107
Epoch: 81 | Iteration number: [1570/4518] 34% | Training loss: 0.6871601777471554
Epoch: 81 | Iteration number: [1580/4518] 34% | Training loss: 0.6871631439728073
Epoch: 81 | Iteration number: [1590/4518] 35% | Training loss: 0.6871578427230787
Epoch: 81 | Iteration number: [1600/4518] 35% | Training loss: 0.6871534994989633
Epoch: 81 | Iteration number: [1610/4518] 35% | Training loss: 0.6871628449200103
Epoch: 81 | Iteration number: [1620/4518] 35% | Training loss: 0.6871657116913501
Epoch: 81 | Iteration number: [1630/4518] 36% | Training loss: 0.6871672650056383
Epoch: 81 | Iteration number: [1640/4518] 36% | Training loss: 0.6871685765501929
Epoch: 81 | Iteration number: [1650/4518] 36% | Training loss: 0.6871595403642365
Epoch: 81 | Iteration number: [1660/4518] 36% | Training loss: 0.687156861015113
Epoch: 81 | Iteration number: [1670/4518] 36% | Training loss: 0.6871620954153781
Epoch: 81 | Iteration number: [1680/4518] 37% | Training loss: 0.6871640363264652
Epoch: 81 | Iteration number: [1690/4518] 37% | Training loss: 0.6871632395411384
Epoch: 81 | Iteration number: [1700/4518] 37% | Training loss: 0.6871600688205046
Epoch: 81 | Iteration number: [1710/4518] 37% | Training loss: 0.6871653753065924
Epoch: 81 | Iteration number: [1720/4518] 38% | Training loss: 0.6871546389058579
Epoch: 81 | Iteration number: [1730/4518] 38% | Training loss: 0.6871549611835811
Epoch: 81 | Iteration number: [1740/4518] 38% | Training loss: 0.687142092229306
Epoch: 81 | Iteration number: [1750/4518] 38% | Training loss: 0.6871424916131156
Epoch: 81 | Iteration number: [1760/4518] 38% | Training loss: 0.6871345626020974
Epoch: 81 | Iteration number: [1770/4518] 39% | Training loss: 0.6871289437436788
Epoch: 81 | Iteration number: [1780/4518] 39% | Training loss: 0.6871308480085951
Epoch: 81 | Iteration number: [1790/4518] 39% | Training loss: 0.6871265882553335
Epoch: 81 | Iteration number: [1800/4518] 39% | Training loss: 0.6871233830849329
Epoch: 81 | Iteration number: [1810/4518] 40% | Training loss: 0.6871194358030077
Epoch: 81 | Iteration number: [1820/4518] 40% | Training loss: 0.687119109912233
Epoch: 81 | Iteration number: [1830/4518] 40% | Training loss: 0.6871138807854366
Epoch: 81 | Iteration number: [1840/4518] 40% | Training loss: 0.6871179112597652
Epoch: 81 | Iteration number: [1850/4518] 40% | Training loss: 0.6871155980793205
Epoch: 81 | Iteration number: [1860/4518] 41% | Training loss: 0.6871191520844736
Epoch: 81 | Iteration number: [1870/4518] 41% | Training loss: 0.6871200153853166
Epoch: 81 | Iteration number: [1880/4518] 41% | Training loss: 0.6871193279294258
Epoch: 81 | Iteration number: [1890/4518] 41% | Training loss: 0.6871201939999111
Epoch: 81 | Iteration number: [1900/4518] 42% | Training loss: 0.6871154830330296
Epoch: 81 | Iteration number: [1910/4518] 42% | Training loss: 0.6871198101505559
Epoch: 81 | Iteration number: [1920/4518] 42% | Training loss: 0.6871166362116734
Epoch: 81 | Iteration number: [1930/4518] 42% | Training loss: 0.6871166076376031
Epoch: 81 | Iteration number: [1940/4518] 42% | Training loss: 0.6871171908280285
Epoch: 81 | Iteration number: [1950/4518] 43% | Training loss: 0.687118406142944
Epoch: 81 | Iteration number: [1960/4518] 43% | Training loss: 0.6871156076387483
Epoch: 81 | Iteration number: [1970/4518] 43% | Training loss: 0.6871095860367499
Epoch: 81 | Iteration number: [1980/4518] 43% | Training loss: 0.687107203434212
Epoch: 81 | Iteration number: [1990/4518] 44% | Training loss: 0.6871067615909193
Epoch: 81 | Iteration number: [2000/4518] 44% | Training loss: 0.6871103362739086
Epoch: 81 | Iteration number: [2010/4518] 44% | Training loss: 0.6871061450213343
Epoch: 81 | Iteration number: [2020/4518] 44% | Training loss: 0.6871021374617473
Epoch: 81 | Iteration number: [2030/4518] 44% | Training loss: 0.6871038252790573
Epoch: 81 | Iteration number: [2040/4518] 45% | Training loss: 0.687103712032823
Epoch: 81 | Iteration number: [2050/4518] 45% | Training loss: 0.6871049128218395
Epoch: 81 | Iteration number: [2060/4518] 45% | Training loss: 0.6871078411352287
Epoch: 81 | Iteration number: [2070/4518] 45% | Training loss: 0.6871078830410317
Epoch: 81 | Iteration number: [2080/4518] 46% | Training loss: 0.6871097472424691
Epoch: 81 | Iteration number: [2090/4518] 46% | Training loss: 0.687104096680737
Epoch: 81 | Iteration number: [2100/4518] 46% | Training loss: 0.6871020730052676
Epoch: 81 | Iteration number: [2110/4518] 46% | Training loss: 0.6871028578959371
Epoch: 81 | Iteration number: [2120/4518] 46% | Training loss: 0.6871000813144558
Epoch: 81 | Iteration number: [2130/4518] 47% | Training loss: 0.6870961946780693
Epoch: 81 | Iteration number: [2140/4518] 47% | Training loss: 0.6870956671850703
Epoch: 81 | Iteration number: [2150/4518] 47% | Training loss: 0.6870944387136504
Epoch: 81 | Iteration number: [2160/4518] 47% | Training loss: 0.687099731216828
Epoch: 81 | Iteration number: [2170/4518] 48% | Training loss: 0.6870990683680855
Epoch: 81 | Iteration number: [2180/4518] 48% | Training loss: 0.6870974872637232
Epoch: 81 | Iteration number: [2190/4518] 48% | Training loss: 0.6870904442654353
Epoch: 81 | Iteration number: [2200/4518] 48% | Training loss: 0.6870888032425534
Epoch: 81 | Iteration number: [2210/4518] 48% | Training loss: 0.6870874833737024
Epoch: 81 | Iteration number: [2220/4518] 49% | Training loss: 0.6870818512396769
Epoch: 81 | Iteration number: [2230/4518] 49% | Training loss: 0.687082532622889
Epoch: 81 | Iteration number: [2240/4518] 49% | Training loss: 0.6870842784643173
Epoch: 81 | Iteration number: [2250/4518] 49% | Training loss: 0.6870857956674364
Epoch: 81 | Iteration number: [2260/4518] 50% | Training loss: 0.6870827761371578
Epoch: 81 | Iteration number: [2270/4518] 50% | Training loss: 0.6870790267305752
Epoch: 81 | Iteration number: [2280/4518] 50% | Training loss: 0.6870801983433857
Epoch: 81 | Iteration number: [2290/4518] 50% | Training loss: 0.6870836446899514
Epoch: 81 | Iteration number: [2300/4518] 50% | Training loss: 0.687083946881087
Epoch: 81 | Iteration number: [2310/4518] 51% | Training loss: 0.6870804632896985
Epoch: 81 | Iteration number: [2320/4518] 51% | Training loss: 0.6870766805420662
Epoch: 81 | Iteration number: [2330/4518] 51% | Training loss: 0.687081022477457
Epoch: 81 | Iteration number: [2340/4518] 51% | Training loss: 0.6870809289125296
Epoch: 81 | Iteration number: [2350/4518] 52% | Training loss: 0.6870813507222114
Epoch: 81 | Iteration number: [2360/4518] 52% | Training loss: 0.6870821378998837
Epoch: 81 | Iteration number: [2370/4518] 52% | Training loss: 0.6870811538857247
Epoch: 81 | Iteration number: [2380/4518] 52% | Training loss: 0.6870808442350195
Epoch: 81 | Iteration number: [2390/4518] 52% | Training loss: 0.6870828623801595
Epoch: 81 | Iteration number: [2400/4518] 53% | Training loss: 0.6870810895413161
Epoch: 81 | Iteration number: [2410/4518] 53% | Training loss: 0.6870823319769499
Epoch: 81 | Iteration number: [2420/4518] 53% | Training loss: 0.6870804618951702
Epoch: 81 | Iteration number: [2430/4518] 53% | Training loss: 0.6870802836163054
Epoch: 81 | Iteration number: [2440/4518] 54% | Training loss: 0.6870780013135223
Epoch: 81 | Iteration number: [2450/4518] 54% | Training loss: 0.6870781613126093
Epoch: 81 | Iteration number: [2460/4518] 54% | Training loss: 0.6870722338436096
Epoch: 81 | Iteration number: [2470/4518] 54% | Training loss: 0.6870721967596757
Epoch: 81 | Iteration number: [2480/4518] 54% | Training loss: 0.6870710711085027
Epoch: 81 | Iteration number: [2490/4518] 55% | Training loss: 0.6870585006164259
Epoch: 81 | Iteration number: [2500/4518] 55% | Training loss: 0.6870623857975006
Epoch: 81 | Iteration number: [2510/4518] 55% | Training loss: 0.6870633047415441
Epoch: 81 | Iteration number: [2520/4518] 55% | Training loss: 0.687057992579445
Epoch: 81 | Iteration number: [2530/4518] 55% | Training loss: 0.6870555566940383
Epoch: 81 | Iteration number: [2540/4518] 56% | Training loss: 0.6870558068742902
Epoch: 81 | Iteration number: [2550/4518] 56% | Training loss: 0.6870539156128378
Epoch: 81 | Iteration number: [2560/4518] 56% | Training loss: 0.6870548237115145
Epoch: 81 | Iteration number: [2570/4518] 56% | Training loss: 0.6870585202243078
Epoch: 81 | Iteration number: [2580/4518] 57% | Training loss: 0.6870589878901031
Epoch: 81 | Iteration number: [2590/4518] 57% | Training loss: 0.6870557458014102
Epoch: 81 | Iteration number: [2600/4518] 57% | Training loss: 0.6870527319724743
Epoch: 81 | Iteration number: [2610/4518] 57% | Training loss: 0.6870550178019936
Epoch: 81 | Iteration number: [2620/4518] 57% | Training loss: 0.6870534681636868
Epoch: 81 | Iteration number: [2630/4518] 58% | Training loss: 0.6870527046261632
Epoch: 81 | Iteration number: [2640/4518] 58% | Training loss: 0.6870551951681123
Epoch: 81 | Iteration number: [2650/4518] 58% | Training loss: 0.6870515109008213
Epoch: 81 | Iteration number: [2660/4518] 58% | Training loss: 0.6870493892216145
Epoch: 81 | Iteration number: [2670/4518] 59% | Training loss: 0.6870544333359722
Epoch: 81 | Iteration number: [2680/4518] 59% | Training loss: 0.6870531996239477
Epoch: 81 | Iteration number: [2690/4518] 59% | Training loss: 0.6870517496947462
Epoch: 81 | Iteration number: [2700/4518] 59% | Training loss: 0.6870481902802432
Epoch: 81 | Iteration number: [2710/4518] 59% | Training loss: 0.6870440086535422
Epoch: 81 | Iteration number: [2720/4518] 60% | Training loss: 0.6870446572189822
Epoch: 81 | Iteration number: [2730/4518] 60% | Training loss: 0.6870444295607206
Epoch: 81 | Iteration number: [2740/4518] 60% | Training loss: 0.6870441378033074
Epoch: 81 | Iteration number: [2750/4518] 60% | Training loss: 0.6870454545021057
Epoch: 81 | Iteration number: [2760/4518] 61% | Training loss: 0.6870435960698819
Epoch: 81 | Iteration number: [2770/4518] 61% | Training loss: 0.6870416549784182
Epoch: 81 | Iteration number: [2780/4518] 61% | Training loss: 0.6870412920661968
Epoch: 81 | Iteration number: [2790/4518] 61% | Training loss: 0.6870377506192867
Epoch: 81 | Iteration number: [2800/4518] 61% | Training loss: 0.6870326615018504
Epoch: 81 | Iteration number: [2810/4518] 62% | Training loss: 0.6870319474422211
Epoch: 81 | Iteration number: [2820/4518] 62% | Training loss: 0.6870282708118993
Epoch: 81 | Iteration number: [2830/4518] 62% | Training loss: 0.687027154288949
Epoch: 81 | Iteration number: [2840/4518] 62% | Training loss: 0.6870278807593063
Epoch: 81 | Iteration number: [2850/4518] 63% | Training loss: 0.6870258314776839
Epoch: 81 | Iteration number: [2860/4518] 63% | Training loss: 0.6870294312497119
Epoch: 81 | Iteration number: [2870/4518] 63% | Training loss: 0.6870290010648322
Epoch: 81 | Iteration number: [2880/4518] 63% | Training loss: 0.6870287416502834
Epoch: 81 | Iteration number: [2890/4518] 63% | Training loss: 0.6870266635937674
Epoch: 81 | Iteration number: [2900/4518] 64% | Training loss: 0.6870233016384059
Epoch: 81 | Iteration number: [2910/4518] 64% | Training loss: 0.6870232978432449
Epoch: 81 | Iteration number: [2920/4518] 64% | Training loss: 0.6870216547013962
Epoch: 81 | Iteration number: [2930/4518] 64% | Training loss: 0.687014863820613
Epoch: 81 | Iteration number: [2940/4518] 65% | Training loss: 0.687016723593887
Epoch: 81 | Iteration number: [2950/4518] 65% | Training loss: 0.6870147935818818
Epoch: 81 | Iteration number: [2960/4518] 65% | Training loss: 0.6870195159034149
Epoch: 81 | Iteration number: [2970/4518] 65% | Training loss: 0.6870167287511858
Epoch: 81 | Iteration number: [2980/4518] 65% | Training loss: 0.6870170224632993
Epoch: 81 | Iteration number: [2990/4518] 66% | Training loss: 0.6870144034109785
Epoch: 81 | Iteration number: [3000/4518] 66% | Training loss: 0.6870143701235454
Epoch: 81 | Iteration number: [3010/4518] 66% | Training loss: 0.6870120046938772
Epoch: 81 | Iteration number: [3020/4518] 66% | Training loss: 0.6870056203461641
Epoch: 81 | Iteration number: [3030/4518] 67% | Training loss: 0.6870025061538118
Epoch: 81 | Iteration number: [3040/4518] 67% | Training loss: 0.6870011718453546
Epoch: 81 | Iteration number: [3050/4518] 67% | Training loss: 0.6870035000707282
Epoch: 81 | Iteration number: [3060/4518] 67% | Training loss: 0.6870050360369526
Epoch: 81 | Iteration number: [3070/4518] 67% | Training loss: 0.68700760647606
Epoch: 81 | Iteration number: [3080/4518] 68% | Training loss: 0.6870092624580705
Epoch: 81 | Iteration number: [3090/4518] 68% | Training loss: 0.6870088700337703
Epoch: 81 | Iteration number: [3100/4518] 68% | Training loss: 0.6870082972511169
Epoch: 81 | Iteration number: [3110/4518] 68% | Training loss: 0.6870069544606654
Epoch: 81 | Iteration number: [3120/4518] 69% | Training loss: 0.68700268988808
Epoch: 81 | Iteration number: [3130/4518] 69% | Training loss: 0.6870026092178906
Epoch: 81 | Iteration number: [3140/4518] 69% | Training loss: 0.687000192312678
Epoch: 81 | Iteration number: [3150/4518] 69% | Training loss: 0.6869964505755712
Epoch: 81 | Iteration number: [3160/4518] 69% | Training loss: 0.6869952434603172
Epoch: 81 | Iteration number: [3170/4518] 70% | Training loss: 0.6869949267301649
Epoch: 81 | Iteration number: [3180/4518] 70% | Training loss: 0.6869948463245008
Epoch: 81 | Iteration number: [3190/4518] 70% | Training loss: 0.6869950086532342
Epoch: 81 | Iteration number: [3200/4518] 70% | Training loss: 0.6869924771785736
Epoch: 81 | Iteration number: [3210/4518] 71% | Training loss: 0.6869921443989715
Epoch: 81 | Iteration number: [3220/4518] 71% | Training loss: 0.6869909146742791
Epoch: 81 | Iteration number: [3230/4518] 71% | Training loss: 0.6869914042691329
Epoch: 81 | Iteration number: [3240/4518] 71% | Training loss: 0.6869922797804997
Epoch: 81 | Iteration number: [3250/4518] 71% | Training loss: 0.6869926113898938
Epoch: 81 | Iteration number: [3260/4518] 72% | Training loss: 0.6869899887248783
Epoch: 81 | Iteration number: [3270/4518] 72% | Training loss: 0.6869929569394582
Epoch: 81 | Iteration number: [3280/4518] 72% | Training loss: 0.6869944885554837
Epoch: 81 | Iteration number: [3290/4518] 72% | Training loss: 0.6869940685283812
Epoch: 81 | Iteration number: [3300/4518] 73% | Training loss: 0.6869943420995366
Epoch: 81 | Iteration number: [3310/4518] 73% | Training loss: 0.6869936590108267
Epoch: 81 | Iteration number: [3320/4518] 73% | Training loss: 0.6869915564735252
Epoch: 81 | Iteration number: [3330/4518] 73% | Training loss: 0.686987976877539
Epoch: 81 | Iteration number: [3340/4518] 73% | Training loss: 0.6869856606700463
Epoch: 81 | Iteration number: [3350/4518] 74% | Training loss: 0.686987071553273
Epoch: 81 | Iteration number: [3360/4518] 74% | Training loss: 0.6869856754583972
Epoch: 81 | Iteration number: [3370/4518] 74% | Training loss: 0.6869797487464079
Epoch: 81 | Iteration number: [3380/4518] 74% | Training loss: 0.6869813843238989
Epoch: 81 | Iteration number: [3390/4518] 75% | Training loss: 0.6869807219259155
Epoch: 81 | Iteration number: [3400/4518] 75% | Training loss: 0.6869786229203729
Epoch: 81 | Iteration number: [3410/4518] 75% | Training loss: 0.6869813817337461
Epoch: 81 | Iteration number: [3420/4518] 75% | Training loss: 0.6869799221119686
Epoch: 81 | Iteration number: [3430/4518] 75% | Training loss: 0.6869796470719941
Epoch: 81 | Iteration number: [3440/4518] 76% | Training loss: 0.6869768116709798
Epoch: 81 | Iteration number: [3450/4518] 76% | Training loss: 0.6869774526962336
Epoch: 81 | Iteration number: [3460/4518] 76% | Training loss: 0.6869792424529964
Epoch: 81 | Iteration number: [3470/4518] 76% | Training loss: 0.6869781777219744
Epoch: 81 | Iteration number: [3480/4518] 77% | Training loss: 0.6869765198436276
Epoch: 81 | Iteration number: [3490/4518] 77% | Training loss: 0.6869763151622433
Epoch: 81 | Iteration number: [3500/4518] 77% | Training loss: 0.6869766668251582
Epoch: 81 | Iteration number: [3510/4518] 77% | Training loss: 0.686974725679115
Epoch: 81 | Iteration number: [3520/4518] 77% | Training loss: 0.6869731324132193
Epoch: 81 | Iteration number: [3530/4518] 78% | Training loss: 0.6869744817866145
Epoch: 81 | Iteration number: [3540/4518] 78% | Training loss: 0.6869697899973325
Epoch: 81 | Iteration number: [3550/4518] 78% | Training loss: 0.686969401349484
Epoch: 81 | Iteration number: [3560/4518] 78% | Training loss: 0.6869674519039272
Epoch: 81 | Iteration number: [3570/4518] 79% | Training loss: 0.6869652580480282
Epoch: 81 | Iteration number: [3580/4518] 79% | Training loss: 0.6869647936947519
Epoch: 81 | Iteration number: [3590/4518] 79% | Training loss: 0.6869664791068659
Epoch: 81 | Iteration number: [3600/4518] 79% | Training loss: 0.6869616549710432
Epoch: 81 | Iteration number: [3610/4518] 79% | Training loss: 0.6869593953657018
Epoch: 81 | Iteration number: [3620/4518] 80% | Training loss: 0.686959408198931
Epoch: 81 | Iteration number: [3630/4518] 80% | Training loss: 0.6869578292547178
Epoch: 81 | Iteration number: [3640/4518] 80% | Training loss: 0.6869527328964118
Epoch: 81 | Iteration number: [3650/4518] 80% | Training loss: 0.686952311845675
Epoch: 81 | Iteration number: [3660/4518] 81% | Training loss: 0.6869499475415287
Epoch: 81 | Iteration number: [3670/4518] 81% | Training loss: 0.6869515795961063
Epoch: 81 | Iteration number: [3680/4518] 81% | Training loss: 0.6869527725583833
Epoch: 81 | Iteration number: [3690/4518] 81% | Training loss: 0.6869531814644977
Epoch: 81 | Iteration number: [3700/4518] 81% | Training loss: 0.6869523499301962
Epoch: 81 | Iteration number: [3710/4518] 82% | Training loss: 0.6869488863610835
Epoch: 81 | Iteration number: [3720/4518] 82% | Training loss: 0.6869502795639858
Epoch: 81 | Iteration number: [3730/4518] 82% | Training loss: 0.6869477042723597
Epoch: 81 | Iteration number: [3740/4518] 82% | Training loss: 0.6869438648064506
Epoch: 81 | Iteration number: [3750/4518] 83% | Training loss: 0.6869466774463654
Epoch: 81 | Iteration number: [3760/4518] 83% | Training loss: 0.6869445998300897
Epoch: 81 | Iteration number: [3770/4518] 83% | Training loss: 0.6869439706087744
Epoch: 81 | Iteration number: [3780/4518] 83% | Training loss: 0.6869440822531937
Epoch: 81 | Iteration number: [3790/4518] 83% | Training loss: 0.6869392744154917
Epoch: 81 | Iteration number: [3800/4518] 84% | Training loss: 0.6869370804962359
Epoch: 81 | Iteration number: [3810/4518] 84% | Training loss: 0.686935877518391
Epoch: 81 | Iteration number: [3820/4518] 84% | Training loss: 0.6869331435383302
Epoch: 81 | Iteration number: [3830/4518] 84% | Training loss: 0.6869300019336432
Epoch: 81 | Iteration number: [3840/4518] 84% | Training loss: 0.6869263661714892
Epoch: 81 | Iteration number: [3850/4518] 85% | Training loss: 0.6869257116008114
Epoch: 81 | Iteration number: [3860/4518] 85% | Training loss: 0.6869238683442378
Epoch: 81 | Iteration number: [3870/4518] 85% | Training loss: 0.6869233471940654
Epoch: 81 | Iteration number: [3880/4518] 85% | Training loss: 0.6869212814213075
Epoch: 81 | Iteration number: [3890/4518] 86% | Training loss: 0.6869252435805558
Epoch: 81 | Iteration number: [3900/4518] 86% | Training loss: 0.6869235361080903
Epoch: 81 | Iteration number: [3910/4518] 86% | Training loss: 0.6869244093937642
Epoch: 81 | Iteration number: [3920/4518] 86% | Training loss: 0.6869248056898312
Epoch: 81 | Iteration number: [3930/4518] 86% | Training loss: 0.6869234523852059
Epoch: 81 | Iteration number: [3940/4518] 87% | Training loss: 0.6869243416840655
Epoch: 81 | Iteration number: [3950/4518] 87% | Training loss: 0.6869235128390638
Epoch: 81 | Iteration number: [3960/4518] 87% | Training loss: 0.6869241337734039
Epoch: 81 | Iteration number: [3970/4518] 87% | Training loss: 0.6869221187508677
Epoch: 81 | Iteration number: [3980/4518] 88% | Training loss: 0.6869194610933562
Epoch: 81 | Iteration number: [3990/4518] 88% | Training loss: 0.6869186007438746
Epoch: 81 | Iteration number: [4000/4518] 88% | Training loss: 0.6869173216968775
Epoch: 81 | Iteration number: [4010/4518] 88% | Training loss: 0.6869217452562956
Epoch: 81 | Iteration number: [4020/4518] 88% | Training loss: 0.6869216781795321
Epoch: 81 | Iteration number: [4030/4518] 89% | Training loss: 0.6869176547373494
Epoch: 81 | Iteration number: [4040/4518] 89% | Training loss: 0.6869183333055808
Epoch: 81 | Iteration number: [4050/4518] 89% | Training loss: 0.6869180324489688
Epoch: 81 | Iteration number: [4060/4518] 89% | Training loss: 0.6869186678249848
Epoch: 81 | Iteration number: [4070/4518] 90% | Training loss: 0.6869194143527263
Epoch: 81 | Iteration number: [4080/4518] 90% | Training loss: 0.6869187235978305
Epoch: 81 | Iteration number: [4090/4518] 90% | Training loss: 0.6869187226213861
Epoch: 81 | Iteration number: [4100/4518] 90% | Training loss: 0.6869197186900349
Epoch: 81 | Iteration number: [4110/4518] 90% | Training loss: 0.6869184223839836
Epoch: 81 | Iteration number: [4120/4518] 91% | Training loss: 0.6869168396713664
Epoch: 81 | Iteration number: [4130/4518] 91% | Training loss: 0.6869172763304907
Epoch: 81 | Iteration number: [4140/4518] 91% | Training loss: 0.6869163334801577
Epoch: 81 | Iteration number: [4150/4518] 91% | Training loss: 0.6869164806245321
Epoch: 81 | Iteration number: [4160/4518] 92% | Training loss: 0.6869145393514863
Epoch: 81 | Iteration number: [4170/4518] 92% | Training loss: 0.6869140877569322
Epoch: 81 | Iteration number: [4180/4518] 92% | Training loss: 0.6869137196164382
Epoch: 81 | Iteration number: [4190/4518] 92% | Training loss: 0.6869088545477191
Epoch: 81 | Iteration number: [4200/4518] 92% | Training loss: 0.6869102219456719
Epoch: 81 | Iteration number: [4210/4518] 93% | Training loss: 0.686914039111194
Epoch: 81 | Iteration number: [4220/4518] 93% | Training loss: 0.6869157889442986
Epoch: 81 | Iteration number: [4230/4518] 93% | Training loss: 0.686914464162033
Epoch: 81 | Iteration number: [4240/4518] 93% | Training loss: 0.6869150765802501
Epoch: 81 | Iteration number: [4250/4518] 94% | Training loss: 0.6869155510453617
Epoch: 81 | Iteration number: [4260/4518] 94% | Training loss: 0.6869184465195651
Epoch: 81 | Iteration number: [4270/4518] 94% | Training loss: 0.6869182460201987
Epoch: 81 | Iteration number: [4280/4518] 94% | Training loss: 0.6869206863446771
Epoch: 81 | Iteration number: [4290/4518] 94% | Training loss: 0.6869229881774573
Epoch: 81 | Iteration number: [4300/4518] 95% | Training loss: 0.6869248858995216
Epoch: 81 | Iteration number: [4310/4518] 95% | Training loss: 0.6869238284098853
Epoch: 81 | Iteration number: [4320/4518] 95% | Training loss: 0.68692712030477
Epoch: 81 | Iteration number: [4330/4518] 95% | Training loss: 0.686925214542803
Epoch: 81 | Iteration number: [4340/4518] 96% | Training loss: 0.6869252381923562
Epoch: 81 | Iteration number: [4350/4518] 96% | Training loss: 0.6869222761707744
Epoch: 81 | Iteration number: [4360/4518] 96% | Training loss: 0.6869261373757223
Epoch: 81 | Iteration number: [4370/4518] 96% | Training loss: 0.6869233593242392
Epoch: 81 | Iteration number: [4380/4518] 96% | Training loss: 0.6869251359271132
Epoch: 81 | Iteration number: [4390/4518] 97% | Training loss: 0.6869244872573297
Epoch: 81 | Iteration number: [4400/4518] 97% | Training loss: 0.6869250000742348
Epoch: 81 | Iteration number: [4410/4518] 97% | Training loss: 0.686925836377133
Epoch: 81 | Iteration number: [4420/4518] 97% | Training loss: 0.6869236179336703
Epoch: 81 | Iteration number: [4430/4518] 98% | Training loss: 0.6869215597282952
Epoch: 81 | Iteration number: [4440/4518] 98% | Training loss: 0.6869176716283635
Epoch: 81 | Iteration number: [4450/4518] 98% | Training loss: 0.6869180639406268
Epoch: 81 | Iteration number: [4460/4518] 98% | Training loss: 0.6869172389731814
Epoch: 81 | Iteration number: [4470/4518] 98% | Training loss: 0.6869198771397806
Epoch: 81 | Iteration number: [4480/4518] 99% | Training loss: 0.6869204478870545
Epoch: 81 | Iteration number: [4490/4518] 99% | Training loss: 0.6869208424951557
Epoch: 81 | Iteration number: [4500/4518] 99% | Training loss: 0.6869202255805333
Epoch: 81 | Iteration number: [4510/4518] 99% | Training loss: 0.6869186209733629

 End of epoch: 81 | Train Loss: 0.6867638921753502 | Training Time: 641 

 End of epoch: 81 | Eval Loss: 0.6897872053847021 | Evaluating Time: 17 
Epoch: 82 | Iteration number: [10/4518] 0% | Training loss: 0.7562762260437011
Epoch: 82 | Iteration number: [20/4518] 0% | Training loss: 0.7211307525634766
Epoch: 82 | Iteration number: [30/4518] 0% | Training loss: 0.7099603394667308
Epoch: 82 | Iteration number: [40/4518] 0% | Training loss: 0.7043000131845474
Epoch: 82 | Iteration number: [50/4518] 1% | Training loss: 0.700577666759491
Epoch: 82 | Iteration number: [60/4518] 1% | Training loss: 0.6983745604753494
Epoch: 82 | Iteration number: [70/4518] 1% | Training loss: 0.6967216738632747
Epoch: 82 | Iteration number: [80/4518] 1% | Training loss: 0.6954405002295971
Epoch: 82 | Iteration number: [90/4518] 1% | Training loss: 0.6943943209118313
Epoch: 82 | Iteration number: [100/4518] 2% | Training loss: 0.693724952340126
Epoch: 82 | Iteration number: [110/4518] 2% | Training loss: 0.6930639180270108
Epoch: 82 | Iteration number: [120/4518] 2% | Training loss: 0.6925912320613861
Epoch: 82 | Iteration number: [130/4518] 2% | Training loss: 0.6921853106755477
Epoch: 82 | Iteration number: [140/4518] 3% | Training loss: 0.6917782945292337
Epoch: 82 | Iteration number: [150/4518] 3% | Training loss: 0.691342078447342
Epoch: 82 | Iteration number: [160/4518] 3% | Training loss: 0.6910620845854283
Epoch: 82 | Iteration number: [170/4518] 3% | Training loss: 0.6908166562809663
Epoch: 82 | Iteration number: [180/4518] 3% | Training loss: 0.6906411045127445
Epoch: 82 | Iteration number: [190/4518] 4% | Training loss: 0.6903693032892126
Epoch: 82 | Iteration number: [200/4518] 4% | Training loss: 0.690202242732048
Epoch: 82 | Iteration number: [210/4518] 4% | Training loss: 0.6900145385946547
Epoch: 82 | Iteration number: [220/4518] 4% | Training loss: 0.6898577863519842
Epoch: 82 | Iteration number: [230/4518] 5% | Training loss: 0.6897311322067095
Epoch: 82 | Iteration number: [240/4518] 5% | Training loss: 0.6896047664185365
Epoch: 82 | Iteration number: [250/4518] 5% | Training loss: 0.6894764730930328
Epoch: 82 | Iteration number: [260/4518] 5% | Training loss: 0.6894320932718424
Epoch: 82 | Iteration number: [270/4518] 5% | Training loss: 0.6893179780907102
Epoch: 82 | Iteration number: [280/4518] 6% | Training loss: 0.6892800884587424
Epoch: 82 | Iteration number: [290/4518] 6% | Training loss: 0.6891969006637048
Epoch: 82 | Iteration number: [300/4518] 6% | Training loss: 0.68913048406442
Epoch: 82 | Iteration number: [310/4518] 6% | Training loss: 0.6890201414785078
Epoch: 82 | Iteration number: [320/4518] 7% | Training loss: 0.6889441542327404
Epoch: 82 | Iteration number: [330/4518] 7% | Training loss: 0.6889024254047509
Epoch: 82 | Iteration number: [340/4518] 7% | Training loss: 0.6888596660950604
Epoch: 82 | Iteration number: [350/4518] 7% | Training loss: 0.688797516482217
Epoch: 82 | Iteration number: [360/4518] 7% | Training loss: 0.6887210147248374
Epoch: 82 | Iteration number: [370/4518] 8% | Training loss: 0.6886489692572001
Epoch: 82 | Iteration number: [380/4518] 8% | Training loss: 0.6885934821869197
Epoch: 82 | Iteration number: [390/4518] 8% | Training loss: 0.688529788225125
Epoch: 82 | Iteration number: [400/4518] 8% | Training loss: 0.6884634916484356
Epoch: 82 | Iteration number: [410/4518] 9% | Training loss: 0.6884129208762472
Epoch: 82 | Iteration number: [420/4518] 9% | Training loss: 0.6883866882040387
Epoch: 82 | Iteration number: [430/4518] 9% | Training loss: 0.6883378155009691
Epoch: 82 | Iteration number: [440/4518] 9% | Training loss: 0.6883071566169913
Epoch: 82 | Iteration number: [450/4518] 9% | Training loss: 0.6882815166314443
Epoch: 82 | Iteration number: [460/4518] 10% | Training loss: 0.6882304847240448
Epoch: 82 | Iteration number: [470/4518] 10% | Training loss: 0.6882094962799803
Epoch: 82 | Iteration number: [480/4518] 10% | Training loss: 0.6881880634774764
Epoch: 82 | Iteration number: [490/4518] 10% | Training loss: 0.6882002083622679
Epoch: 82 | Iteration number: [500/4518] 11% | Training loss: 0.6881902780532837
Epoch: 82 | Iteration number: [510/4518] 11% | Training loss: 0.6881511726800134
Epoch: 82 | Iteration number: [520/4518] 11% | Training loss: 0.6881496183001078
Epoch: 82 | Iteration number: [530/4518] 11% | Training loss: 0.6881191445971435
Epoch: 82 | Iteration number: [540/4518] 11% | Training loss: 0.688084825431859
Epoch: 82 | Iteration number: [550/4518] 12% | Training loss: 0.6880662142146717
Epoch: 82 | Iteration number: [560/4518] 12% | Training loss: 0.6880438972796713
Epoch: 82 | Iteration number: [570/4518] 12% | Training loss: 0.6880407134691874
Epoch: 82 | Iteration number: [580/4518] 12% | Training loss: 0.688032212236832
Epoch: 82 | Iteration number: [590/4518] 13% | Training loss: 0.6880047671875711
Epoch: 82 | Iteration number: [600/4518] 13% | Training loss: 0.6879663225015005
Epoch: 82 | Iteration number: [610/4518] 13% | Training loss: 0.6879657249958788
Epoch: 82 | Iteration number: [620/4518] 13% | Training loss: 0.6879378554321105
Epoch: 82 | Iteration number: [630/4518] 13% | Training loss: 0.687919674317042
Epoch: 82 | Iteration number: [640/4518] 14% | Training loss: 0.6878927226178349
Epoch: 82 | Iteration number: [650/4518] 14% | Training loss: 0.6878672983096196
Epoch: 82 | Iteration number: [660/4518] 14% | Training loss: 0.6878411784316554
Epoch: 82 | Iteration number: [670/4518] 14% | Training loss: 0.6878068701544804
Epoch: 82 | Iteration number: [680/4518] 15% | Training loss: 0.6877731814103968
Epoch: 82 | Iteration number: [690/4518] 15% | Training loss: 0.6877585282360298
Epoch: 82 | Iteration number: [700/4518] 15% | Training loss: 0.6877482741219657
Epoch: 82 | Iteration number: [710/4518] 15% | Training loss: 0.6877428388931381
Epoch: 82 | Iteration number: [720/4518] 15% | Training loss: 0.6877316547764672
Epoch: 82 | Iteration number: [730/4518] 16% | Training loss: 0.6877154616460408
Epoch: 82 | Iteration number: [740/4518] 16% | Training loss: 0.6876960942874084
Epoch: 82 | Iteration number: [750/4518] 16% | Training loss: 0.6876577288309733
Epoch: 82 | Iteration number: [760/4518] 16% | Training loss: 0.6876539834235844
Epoch: 82 | Iteration number: [770/4518] 17% | Training loss: 0.6876491904258728
Epoch: 82 | Iteration number: [780/4518] 17% | Training loss: 0.6876271025492595
Epoch: 82 | Iteration number: [790/4518] 17% | Training loss: 0.6876137055928194
Epoch: 82 | Iteration number: [800/4518] 17% | Training loss: 0.6876009549945593
Epoch: 82 | Iteration number: [810/4518] 17% | Training loss: 0.687585331628352
Epoch: 82 | Iteration number: [820/4518] 18% | Training loss: 0.6875767596611162
Epoch: 82 | Iteration number: [830/4518] 18% | Training loss: 0.6875694030738738
Epoch: 82 | Iteration number: [840/4518] 18% | Training loss: 0.6875576708997999
Epoch: 82 | Iteration number: [850/4518] 18% | Training loss: 0.6875432410660912
Epoch: 82 | Iteration number: [860/4518] 19% | Training loss: 0.6875246964914854
Epoch: 82 | Iteration number: [870/4518] 19% | Training loss: 0.6875235558241263
Epoch: 82 | Iteration number: [880/4518] 19% | Training loss: 0.687517388029532
Epoch: 82 | Iteration number: [890/4518] 19% | Training loss: 0.6875212599052472
Epoch: 82 | Iteration number: [900/4518] 19% | Training loss: 0.6875185149245792
Epoch: 82 | Iteration number: [910/4518] 20% | Training loss: 0.6875143056387429
Epoch: 82 | Iteration number: [920/4518] 20% | Training loss: 0.6875043225677117
Epoch: 82 | Iteration number: [930/4518] 20% | Training loss: 0.6874839452005201
Epoch: 82 | Iteration number: [940/4518] 20% | Training loss: 0.6874848746238871
Epoch: 82 | Iteration number: [950/4518] 21% | Training loss: 0.6874770289345792
Epoch: 82 | Iteration number: [960/4518] 21% | Training loss: 0.6874715218320488
Epoch: 82 | Iteration number: [970/4518] 21% | Training loss: 0.687478671123072
Epoch: 82 | Iteration number: [980/4518] 21% | Training loss: 0.6874743767538849
Epoch: 82 | Iteration number: [990/4518] 21% | Training loss: 0.6874698490205438
Epoch: 82 | Iteration number: [1000/4518] 22% | Training loss: 0.6874644606113434
Epoch: 82 | Iteration number: [1010/4518] 22% | Training loss: 0.687457167571134
Epoch: 82 | Iteration number: [1020/4518] 22% | Training loss: 0.6874359791769701
Epoch: 82 | Iteration number: [1030/4518] 22% | Training loss: 0.687421901827877
Epoch: 82 | Iteration number: [1040/4518] 23% | Training loss: 0.6874135772769268
Epoch: 82 | Iteration number: [1050/4518] 23% | Training loss: 0.687413717167718
Epoch: 82 | Iteration number: [1060/4518] 23% | Training loss: 0.6874017407309334
Epoch: 82 | Iteration number: [1070/4518] 23% | Training loss: 0.6873990523480923
Epoch: 82 | Iteration number: [1080/4518] 23% | Training loss: 0.6873974412127778
Epoch: 82 | Iteration number: [1090/4518] 24% | Training loss: 0.6874023912149831
Epoch: 82 | Iteration number: [1100/4518] 24% | Training loss: 0.6874020670760762
Epoch: 82 | Iteration number: [1110/4518] 24% | Training loss: 0.6873981458646757
Epoch: 82 | Iteration number: [1120/4518] 24% | Training loss: 0.6874052422919443
Epoch: 82 | Iteration number: [1130/4518] 25% | Training loss: 0.687392046652009
Epoch: 82 | Iteration number: [1140/4518] 25% | Training loss: 0.6873848436694396
Epoch: 82 | Iteration number: [1150/4518] 25% | Training loss: 0.6873821858219479
Epoch: 82 | Iteration number: [1160/4518] 25% | Training loss: 0.687383951349505
Epoch: 82 | Iteration number: [1170/4518] 25% | Training loss: 0.6873828551708123
Epoch: 82 | Iteration number: [1180/4518] 26% | Training loss: 0.6873754857960394
Epoch: 82 | Iteration number: [1190/4518] 26% | Training loss: 0.6873699883452985
Epoch: 82 | Iteration number: [1200/4518] 26% | Training loss: 0.6873539386192957
Epoch: 82 | Iteration number: [1210/4518] 26% | Training loss: 0.6873548418037162
Epoch: 82 | Iteration number: [1220/4518] 27% | Training loss: 0.6873525643446406
Epoch: 82 | Iteration number: [1230/4518] 27% | Training loss: 0.6873559121193925
Epoch: 82 | Iteration number: [1240/4518] 27% | Training loss: 0.6873422061724047
Epoch: 82 | Iteration number: [1250/4518] 27% | Training loss: 0.6873365503787995
Epoch: 82 | Iteration number: [1260/4518] 27% | Training loss: 0.687326307145376
Epoch: 82 | Iteration number: [1270/4518] 28% | Training loss: 0.6873191769667498
Epoch: 82 | Iteration number: [1280/4518] 28% | Training loss: 0.6873137424234301
Epoch: 82 | Iteration number: [1290/4518] 28% | Training loss: 0.6873033074445503
Epoch: 82 | Iteration number: [1300/4518] 28% | Training loss: 0.6872890741550005
Epoch: 82 | Iteration number: [1310/4518] 28% | Training loss: 0.6872793741808593
Epoch: 82 | Iteration number: [1320/4518] 29% | Training loss: 0.6872792065595136
Epoch: 82 | Iteration number: [1330/4518] 29% | Training loss: 0.6872685722390511
Epoch: 82 | Iteration number: [1340/4518] 29% | Training loss: 0.6872761835802846
Epoch: 82 | Iteration number: [1350/4518] 29% | Training loss: 0.6872608842231609
Epoch: 82 | Iteration number: [1360/4518] 30% | Training loss: 0.68726236145286
Epoch: 82 | Iteration number: [1370/4518] 30% | Training loss: 0.6872612036492702
Epoch: 82 | Iteration number: [1380/4518] 30% | Training loss: 0.6872546704782956
Epoch: 82 | Iteration number: [1390/4518] 30% | Training loss: 0.6872436495136014
Epoch: 82 | Iteration number: [1400/4518] 30% | Training loss: 0.6872450472627367
Epoch: 82 | Iteration number: [1410/4518] 31% | Training loss: 0.6872450517424455
Epoch: 82 | Iteration number: [1420/4518] 31% | Training loss: 0.6872477287557763
Epoch: 82 | Iteration number: [1430/4518] 31% | Training loss: 0.6872452998494768
Epoch: 82 | Iteration number: [1440/4518] 31% | Training loss: 0.6872481312602758
Epoch: 82 | Iteration number: [1450/4518] 32% | Training loss: 0.6872516101804272
Epoch: 82 | Iteration number: [1460/4518] 32% | Training loss: 0.6872529248260472
Epoch: 82 | Iteration number: [1470/4518] 32% | Training loss: 0.6872475853988103
Epoch: 82 | Iteration number: [1480/4518] 32% | Training loss: 0.6872403053013054
Epoch: 82 | Iteration number: [1490/4518] 32% | Training loss: 0.687242326080399
Epoch: 82 | Iteration number: [1500/4518] 33% | Training loss: 0.6872438592513402
Epoch: 82 | Iteration number: [1510/4518] 33% | Training loss: 0.6872444025728087
Epoch: 82 | Iteration number: [1520/4518] 33% | Training loss: 0.6872484718498431
Epoch: 82 | Iteration number: [1530/4518] 33% | Training loss: 0.6872414605679855
Epoch: 82 | Iteration number: [1540/4518] 34% | Training loss: 0.6872414625310278
Epoch: 82 | Iteration number: [1550/4518] 34% | Training loss: 0.6872402122712904
Epoch: 82 | Iteration number: [1560/4518] 34% | Training loss: 0.6872452093622623
Epoch: 82 | Iteration number: [1570/4518] 34% | Training loss: 0.6872410626927759
Epoch: 82 | Iteration number: [1580/4518] 34% | Training loss: 0.687230639782133
Epoch: 82 | Iteration number: [1590/4518] 35% | Training loss: 0.6872192145893409
Epoch: 82 | Iteration number: [1600/4518] 35% | Training loss: 0.687221304886043
Epoch: 82 | Iteration number: [1610/4518] 35% | Training loss: 0.6872236265899232
Epoch: 82 | Iteration number: [1620/4518] 35% | Training loss: 0.6872273536376011
Epoch: 82 | Iteration number: [1630/4518] 36% | Training loss: 0.6872235315709027
Epoch: 82 | Iteration number: [1640/4518] 36% | Training loss: 0.6872253550261986
Epoch: 82 | Iteration number: [1650/4518] 36% | Training loss: 0.687220806425268
Epoch: 82 | Iteration number: [1660/4518] 36% | Training loss: 0.687222342570144
Epoch: 82 | Iteration number: [1670/4518] 36% | Training loss: 0.6872112802759616
Epoch: 82 | Iteration number: [1680/4518] 37% | Training loss: 0.6872084025116194
Epoch: 82 | Iteration number: [1690/4518] 37% | Training loss: 0.6872081653958947
Epoch: 82 | Iteration number: [1700/4518] 37% | Training loss: 0.6872117104600458
Epoch: 82 | Iteration number: [1710/4518] 37% | Training loss: 0.687211969721387
Epoch: 82 | Iteration number: [1720/4518] 38% | Training loss: 0.6872112058622892
Epoch: 82 | Iteration number: [1730/4518] 38% | Training loss: 0.6872117550731395
Epoch: 82 | Iteration number: [1740/4518] 38% | Training loss: 0.6872159647530522
Epoch: 82 | Iteration number: [1750/4518] 38% | Training loss: 0.6872146451813834
Epoch: 82 | Iteration number: [1760/4518] 38% | Training loss: 0.6872111318802292
Epoch: 82 | Iteration number: [1770/4518] 39% | Training loss: 0.6872028877842897
Epoch: 82 | Iteration number: [1780/4518] 39% | Training loss: 0.6871959442837855
Epoch: 82 | Iteration number: [1790/4518] 39% | Training loss: 0.6871905866614934
Epoch: 82 | Iteration number: [1800/4518] 39% | Training loss: 0.6871935479839643
Epoch: 82 | Iteration number: [1810/4518] 40% | Training loss: 0.6871907887867142
Epoch: 82 | Iteration number: [1820/4518] 40% | Training loss: 0.6871882579483829
Epoch: 82 | Iteration number: [1830/4518] 40% | Training loss: 0.6871831483528262
Epoch: 82 | Iteration number: [1840/4518] 40% | Training loss: 0.6871884608398313
Epoch: 82 | Iteration number: [1850/4518] 40% | Training loss: 0.6871793606474593
Epoch: 82 | Iteration number: [1860/4518] 41% | Training loss: 0.6871800057990577
Epoch: 82 | Iteration number: [1870/4518] 41% | Training loss: 0.6871748355620685
Epoch: 82 | Iteration number: [1880/4518] 41% | Training loss: 0.6871766386831061
Epoch: 82 | Iteration number: [1890/4518] 41% | Training loss: 0.6871737519900004
Epoch: 82 | Iteration number: [1900/4518] 42% | Training loss: 0.687168859933552
Epoch: 82 | Iteration number: [1910/4518] 42% | Training loss: 0.687163929071726
Epoch: 82 | Iteration number: [1920/4518] 42% | Training loss: 0.6871623580964903
Epoch: 82 | Iteration number: [1930/4518] 42% | Training loss: 0.6871617768403779
Epoch: 82 | Iteration number: [1940/4518] 42% | Training loss: 0.6871554080665726
Epoch: 82 | Iteration number: [1950/4518] 43% | Training loss: 0.687150425421886
Epoch: 82 | Iteration number: [1960/4518] 43% | Training loss: 0.6871448563677924
Epoch: 82 | Iteration number: [1970/4518] 43% | Training loss: 0.6871423524950967
Epoch: 82 | Iteration number: [1980/4518] 43% | Training loss: 0.6871451246919054
Epoch: 82 | Iteration number: [1990/4518] 44% | Training loss: 0.6871431037109701
Epoch: 82 | Iteration number: [2000/4518] 44% | Training loss: 0.687142483651638
Epoch: 82 | Iteration number: [2010/4518] 44% | Training loss: 0.6871429245863387
Epoch: 82 | Iteration number: [2020/4518] 44% | Training loss: 0.6871412056212378
Epoch: 82 | Iteration number: [2030/4518] 44% | Training loss: 0.6871415052801517
Epoch: 82 | Iteration number: [2040/4518] 45% | Training loss: 0.6871403898970754
Epoch: 82 | Iteration number: [2050/4518] 45% | Training loss: 0.6871397932855094
Epoch: 82 | Iteration number: [2060/4518] 45% | Training loss: 0.6871416948374035
Epoch: 82 | Iteration number: [2070/4518] 45% | Training loss: 0.6871372628039208
Epoch: 82 | Iteration number: [2080/4518] 46% | Training loss: 0.6871380490752367
Epoch: 82 | Iteration number: [2090/4518] 46% | Training loss: 0.6871383626495252
Epoch: 82 | Iteration number: [2100/4518] 46% | Training loss: 0.6871330805335726
Epoch: 82 | Iteration number: [2110/4518] 46% | Training loss: 0.6871319017704064
Epoch: 82 | Iteration number: [2120/4518] 46% | Training loss: 0.6871348384697482
Epoch: 82 | Iteration number: [2130/4518] 47% | Training loss: 0.6871339917182923
Epoch: 82 | Iteration number: [2140/4518] 47% | Training loss: 0.6871345133703446
Epoch: 82 | Iteration number: [2150/4518] 47% | Training loss: 0.6871263075152109
Epoch: 82 | Iteration number: [2160/4518] 47% | Training loss: 0.6871261735757191
Epoch: 82 | Iteration number: [2170/4518] 48% | Training loss: 0.6871251046657563
Epoch: 82 | Iteration number: [2180/4518] 48% | Training loss: 0.6871244839845447
Epoch: 82 | Iteration number: [2190/4518] 48% | Training loss: 0.6871202497721807
Epoch: 82 | Iteration number: [2200/4518] 48% | Training loss: 0.6871189328757199
Epoch: 82 | Iteration number: [2210/4518] 48% | Training loss: 0.6871162038313318
Epoch: 82 | Iteration number: [2220/4518] 49% | Training loss: 0.687113763888677
Epoch: 82 | Iteration number: [2230/4518] 49% | Training loss: 0.6871099965989322
Epoch: 82 | Iteration number: [2240/4518] 49% | Training loss: 0.687108528214906
Epoch: 82 | Iteration number: [2250/4518] 49% | Training loss: 0.6871076830757988
Epoch: 82 | Iteration number: [2260/4518] 50% | Training loss: 0.6871095025961378
Epoch: 82 | Iteration number: [2270/4518] 50% | Training loss: 0.6871158158726629
Epoch: 82 | Iteration number: [2280/4518] 50% | Training loss: 0.6871170866123417
Epoch: 82 | Iteration number: [2290/4518] 50% | Training loss: 0.6871187224658816
Epoch: 82 | Iteration number: [2300/4518] 50% | Training loss: 0.6871202295241149
Epoch: 82 | Iteration number: [2310/4518] 51% | Training loss: 0.6871159596360608
Epoch: 82 | Iteration number: [2320/4518] 51% | Training loss: 0.6871084053197811
Epoch: 82 | Iteration number: [2330/4518] 51% | Training loss: 0.687104280772639
Epoch: 82 | Iteration number: [2340/4518] 51% | Training loss: 0.6871008284326292
Epoch: 82 | Iteration number: [2350/4518] 52% | Training loss: 0.6870949225730084
Epoch: 82 | Iteration number: [2360/4518] 52% | Training loss: 0.6871027512317996
Epoch: 82 | Iteration number: [2370/4518] 52% | Training loss: 0.6870978566161691
Epoch: 82 | Iteration number: [2380/4518] 52% | Training loss: 0.687094482704371
Epoch: 82 | Iteration number: [2390/4518] 52% | Training loss: 0.687095682840467
Epoch: 82 | Iteration number: [2400/4518] 53% | Training loss: 0.6870909044394891
Epoch: 82 | Iteration number: [2410/4518] 53% | Training loss: 0.6870912623355993
Epoch: 82 | Iteration number: [2420/4518] 53% | Training loss: 0.6870898561044173
Epoch: 82 | Iteration number: [2430/4518] 53% | Training loss: 0.687087826743538
Epoch: 82 | Iteration number: [2440/4518] 54% | Training loss: 0.6870876728511247
Epoch: 82 | Iteration number: [2450/4518] 54% | Training loss: 0.6870830840237286
Epoch: 82 | Iteration number: [2460/4518] 54% | Training loss: 0.6870815344942295
Epoch: 82 | Iteration number: [2470/4518] 54% | Training loss: 0.6870827130460546
Epoch: 82 | Iteration number: [2480/4518] 54% | Training loss: 0.6870825095042106
Epoch: 82 | Iteration number: [2490/4518] 55% | Training loss: 0.6870854590073168
Epoch: 82 | Iteration number: [2500/4518] 55% | Training loss: 0.6870881823539734
Epoch: 82 | Iteration number: [2510/4518] 55% | Training loss: 0.6870883867085218
Epoch: 82 | Iteration number: [2520/4518] 55% | Training loss: 0.6870911105284615
Epoch: 82 | Iteration number: [2530/4518] 55% | Training loss: 0.6870910125758808
Epoch: 82 | Iteration number: [2540/4518] 56% | Training loss: 0.687092255208436
Epoch: 82 | Iteration number: [2550/4518] 56% | Training loss: 0.6870893055551193
Epoch: 82 | Iteration number: [2560/4518] 56% | Training loss: 0.6870837457710877
Epoch: 82 | Iteration number: [2570/4518] 56% | Training loss: 0.6870839005778272
Epoch: 82 | Iteration number: [2580/4518] 57% | Training loss: 0.6870805330054705
Epoch: 82 | Iteration number: [2590/4518] 57% | Training loss: 0.6870746787450488
Epoch: 82 | Iteration number: [2600/4518] 57% | Training loss: 0.687071453837248
Epoch: 82 | Iteration number: [2610/4518] 57% | Training loss: 0.6870700664218815
Epoch: 82 | Iteration number: [2620/4518] 57% | Training loss: 0.6870628436558119
Epoch: 82 | Iteration number: [2630/4518] 58% | Training loss: 0.6870625810024856
Epoch: 82 | Iteration number: [2640/4518] 58% | Training loss: 0.6870642717137482
Epoch: 82 | Iteration number: [2650/4518] 58% | Training loss: 0.6870616830294987
Epoch: 82 | Iteration number: [2660/4518] 58% | Training loss: 0.6870545321837404
Epoch: 82 | Iteration number: [2670/4518] 59% | Training loss: 0.6870554224158941
Epoch: 82 | Iteration number: [2680/4518] 59% | Training loss: 0.687055156746907
Epoch: 82 | Iteration number: [2690/4518] 59% | Training loss: 0.6870519499131738
Epoch: 82 | Iteration number: [2700/4518] 59% | Training loss: 0.6870495590236452
Epoch: 82 | Iteration number: [2710/4518] 59% | Training loss: 0.6870479532273494
Epoch: 82 | Iteration number: [2720/4518] 60% | Training loss: 0.6870432506589329
Epoch: 82 | Iteration number: [2730/4518] 60% | Training loss: 0.6870423122203394
Epoch: 82 | Iteration number: [2740/4518] 60% | Training loss: 0.6870473700718288
Epoch: 82 | Iteration number: [2750/4518] 60% | Training loss: 0.6870438869649713
Epoch: 82 | Iteration number: [2760/4518] 61% | Training loss: 0.6870448998998905
Epoch: 82 | Iteration number: [2770/4518] 61% | Training loss: 0.6870469683129005
Epoch: 82 | Iteration number: [2780/4518] 61% | Training loss: 0.6870474967167531
Epoch: 82 | Iteration number: [2790/4518] 61% | Training loss: 0.6870453991983954
Epoch: 82 | Iteration number: [2800/4518] 61% | Training loss: 0.687044019486223
Epoch: 82 | Iteration number: [2810/4518] 62% | Training loss: 0.6870396189842359
Epoch: 82 | Iteration number: [2820/4518] 62% | Training loss: 0.6870344499112866
Epoch: 82 | Iteration number: [2830/4518] 62% | Training loss: 0.6870365515193333
Epoch: 82 | Iteration number: [2840/4518] 62% | Training loss: 0.6870356738567353
Epoch: 82 | Iteration number: [2850/4518] 63% | Training loss: 0.687034744421641
Epoch: 82 | Iteration number: [2860/4518] 63% | Training loss: 0.6870321795031741
Epoch: 82 | Iteration number: [2870/4518] 63% | Training loss: 0.6870319205709451
Epoch: 82 | Iteration number: [2880/4518] 63% | Training loss: 0.6870341093796822
Epoch: 82 | Iteration number: [2890/4518] 63% | Training loss: 0.6870271536099457
Epoch: 82 | Iteration number: [2900/4518] 64% | Training loss: 0.6870244955811007
Epoch: 82 | Iteration number: [2910/4518] 64% | Training loss: 0.6870206904984831
Epoch: 82 | Iteration number: [2920/4518] 64% | Training loss: 0.6870176974020592
Epoch: 82 | Iteration number: [2930/4518] 64% | Training loss: 0.6870197438746182
Epoch: 82 | Iteration number: [2940/4518] 65% | Training loss: 0.6870218615750877
Epoch: 82 | Iteration number: [2950/4518] 65% | Training loss: 0.6870199432817556
Epoch: 82 | Iteration number: [2960/4518] 65% | Training loss: 0.6870146772547349
Epoch: 82 | Iteration number: [2970/4518] 65% | Training loss: 0.6870126074412054
Epoch: 82 | Iteration number: [2980/4518] 65% | Training loss: 0.6870112071501329
Epoch: 82 | Iteration number: [2990/4518] 66% | Training loss: 0.6870101886050757
Epoch: 82 | Iteration number: [3000/4518] 66% | Training loss: 0.687009397427241
Epoch: 82 | Iteration number: [3010/4518] 66% | Training loss: 0.6870100161759957
Epoch: 82 | Iteration number: [3020/4518] 66% | Training loss: 0.6870100604777305
Epoch: 82 | Iteration number: [3030/4518] 67% | Training loss: 0.6870128450220567
Epoch: 82 | Iteration number: [3040/4518] 67% | Training loss: 0.6870093638959683
Epoch: 82 | Iteration number: [3050/4518] 67% | Training loss: 0.687012401467464
Epoch: 82 | Iteration number: [3060/4518] 67% | Training loss: 0.687010203798612
Epoch: 82 | Iteration number: [3070/4518] 67% | Training loss: 0.6870134399069249
Epoch: 82 | Iteration number: [3080/4518] 68% | Training loss: 0.6870183017153244
Epoch: 82 | Iteration number: [3090/4518] 68% | Training loss: 0.6870180383855086
Epoch: 82 | Iteration number: [3100/4518] 68% | Training loss: 0.6870165624926167
Epoch: 82 | Iteration number: [3110/4518] 68% | Training loss: 0.6870158595670841
Epoch: 82 | Iteration number: [3120/4518] 69% | Training loss: 0.6870140459866095
Epoch: 82 | Iteration number: [3130/4518] 69% | Training loss: 0.6870166475590045
Epoch: 82 | Iteration number: [3140/4518] 69% | Training loss: 0.6870143395700272
Epoch: 82 | Iteration number: [3150/4518] 69% | Training loss: 0.6870157313346863
Epoch: 82 | Iteration number: [3160/4518] 69% | Training loss: 0.6870135181123698
Epoch: 82 | Iteration number: [3170/4518] 70% | Training loss: 0.6870096078994522
Epoch: 82 | Iteration number: [3180/4518] 70% | Training loss: 0.6870074395113771
Epoch: 82 | Iteration number: [3190/4518] 70% | Training loss: 0.6870058370608148
Epoch: 82 | Iteration number: [3200/4518] 70% | Training loss: 0.6870090218633413
Epoch: 82 | Iteration number: [3210/4518] 71% | Training loss: 0.687007444725601
Epoch: 82 | Iteration number: [3220/4518] 71% | Training loss: 0.6870011207109653
Epoch: 82 | Iteration number: [3230/4518] 71% | Training loss: 0.6869980402959759
Epoch: 82 | Iteration number: [3240/4518] 71% | Training loss: 0.6869990533148801
Epoch: 82 | Iteration number: [3250/4518] 71% | Training loss: 0.6869937448684986
Epoch: 82 | Iteration number: [3260/4518] 72% | Training loss: 0.6869926004504865
Epoch: 82 | Iteration number: [3270/4518] 72% | Training loss: 0.6869916599460334
Epoch: 82 | Iteration number: [3280/4518] 72% | Training loss: 0.6869885863872564
Epoch: 82 | Iteration number: [3290/4518] 72% | Training loss: 0.6869892485960639
Epoch: 82 | Iteration number: [3300/4518] 73% | Training loss: 0.686985974745317
Epoch: 82 | Iteration number: [3310/4518] 73% | Training loss: 0.6869875047322126
Epoch: 82 | Iteration number: [3320/4518] 73% | Training loss: 0.6869836995939175
Epoch: 82 | Iteration number: [3330/4518] 73% | Training loss: 0.6869853420837505
Epoch: 82 | Iteration number: [3340/4518] 73% | Training loss: 0.6869852768625327
Epoch: 82 | Iteration number: [3350/4518] 74% | Training loss: 0.686984940180138
Epoch: 82 | Iteration number: [3360/4518] 74% | Training loss: 0.6869853465684823
Epoch: 82 | Iteration number: [3370/4518] 74% | Training loss: 0.6869890240781031
Epoch: 82 | Iteration number: [3380/4518] 74% | Training loss: 0.6869873824204213
Epoch: 82 | Iteration number: [3390/4518] 75% | Training loss: 0.6869841527270708
Epoch: 82 | Iteration number: [3400/4518] 75% | Training loss: 0.6869813621570082
Epoch: 82 | Iteration number: [3410/4518] 75% | Training loss: 0.6869754106592922
Epoch: 82 | Iteration number: [3420/4518] 75% | Training loss: 0.6869770094665171
Epoch: 82 | Iteration number: [3430/4518] 75% | Training loss: 0.6869786885841247
Epoch: 82 | Iteration number: [3440/4518] 76% | Training loss: 0.6869793071129987
Epoch: 82 | Iteration number: [3450/4518] 76% | Training loss: 0.6869776062343431
Epoch: 82 | Iteration number: [3460/4518] 76% | Training loss: 0.6869789258248544
Epoch: 82 | Iteration number: [3470/4518] 76% | Training loss: 0.6869797358595329
Epoch: 82 | Iteration number: [3480/4518] 77% | Training loss: 0.686978167363967
Epoch: 82 | Iteration number: [3490/4518] 77% | Training loss: 0.6869795533681667
Epoch: 82 | Iteration number: [3500/4518] 77% | Training loss: 0.6869788819892065
Epoch: 82 | Iteration number: [3510/4518] 77% | Training loss: 0.6869783977158049
Epoch: 82 | Iteration number: [3520/4518] 77% | Training loss: 0.6869752071289854
Epoch: 82 | Iteration number: [3530/4518] 78% | Training loss: 0.6869741425973498
Epoch: 82 | Iteration number: [3540/4518] 78% | Training loss: 0.6869762173311859
Epoch: 82 | Iteration number: [3550/4518] 78% | Training loss: 0.6869777592638848
Epoch: 82 | Iteration number: [3560/4518] 78% | Training loss: 0.686974474804455
Epoch: 82 | Iteration number: [3570/4518] 79% | Training loss: 0.6869738017143655
Epoch: 82 | Iteration number: [3580/4518] 79% | Training loss: 0.6869746429460675
Epoch: 82 | Iteration number: [3590/4518] 79% | Training loss: 0.6869720028801549
Epoch: 82 | Iteration number: [3600/4518] 79% | Training loss: 0.6869716257850329
Epoch: 82 | Iteration number: [3610/4518] 79% | Training loss: 0.6869688401592075
Epoch: 82 | Iteration number: [3620/4518] 80% | Training loss: 0.6869637787671379
Epoch: 82 | Iteration number: [3630/4518] 80% | Training loss: 0.6869661903578388
Epoch: 82 | Iteration number: [3640/4518] 80% | Training loss: 0.6869654341877162
Epoch: 82 | Iteration number: [3650/4518] 80% | Training loss: 0.6869646139667459
Epoch: 82 | Iteration number: [3660/4518] 81% | Training loss: 0.6869608678941518
Epoch: 82 | Iteration number: [3670/4518] 81% | Training loss: 0.68695990076182
Epoch: 82 | Iteration number: [3680/4518] 81% | Training loss: 0.6869577516680179
Epoch: 82 | Iteration number: [3690/4518] 81% | Training loss: 0.6869583647264051
Epoch: 82 | Iteration number: [3700/4518] 81% | Training loss: 0.6869555893298742
Epoch: 82 | Iteration number: [3710/4518] 82% | Training loss: 0.6869580972387463
Epoch: 82 | Iteration number: [3720/4518] 82% | Training loss: 0.6869552223913131
Epoch: 82 | Iteration number: [3730/4518] 82% | Training loss: 0.6869558331953616
Epoch: 82 | Iteration number: [3740/4518] 82% | Training loss: 0.6869553489321694
Epoch: 82 | Iteration number: [3750/4518] 83% | Training loss: 0.6869543100833893
Epoch: 82 | Iteration number: [3760/4518] 83% | Training loss: 0.6869535896530811
Epoch: 82 | Iteration number: [3770/4518] 83% | Training loss: 0.6869555955856486
Epoch: 82 | Iteration number: [3780/4518] 83% | Training loss: 0.6869553866367492
Epoch: 82 | Iteration number: [3790/4518] 83% | Training loss: 0.6869538243653592
Epoch: 82 | Iteration number: [3800/4518] 84% | Training loss: 0.6869558810089764
Epoch: 82 | Iteration number: [3810/4518] 84% | Training loss: 0.6869542734516574
Epoch: 82 | Iteration number: [3820/4518] 84% | Training loss: 0.6869537184999875
Epoch: 82 | Iteration number: [3830/4518] 84% | Training loss: 0.6869511193301597
Epoch: 82 | Iteration number: [3840/4518] 84% | Training loss: 0.6869494046550244
Epoch: 82 | Iteration number: [3850/4518] 85% | Training loss: 0.6869496137135989
Epoch: 82 | Iteration number: [3860/4518] 85% | Training loss: 0.686946446367496
Epoch: 82 | Iteration number: [3870/4518] 85% | Training loss: 0.6869476897925986
Epoch: 82 | Iteration number: [3880/4518] 85% | Training loss: 0.6869470513204938
Epoch: 82 | Iteration number: [3890/4518] 86% | Training loss: 0.6869462855064471
Epoch: 82 | Iteration number: [3900/4518] 86% | Training loss: 0.686945003974132
Epoch: 82 | Iteration number: [3910/4518] 86% | Training loss: 0.6869437505522042
Epoch: 82 | Iteration number: [3920/4518] 86% | Training loss: 0.6869424895668517
Epoch: 82 | Iteration number: [3930/4518] 86% | Training loss: 0.6869437628119957
Epoch: 82 | Iteration number: [3940/4518] 87% | Training loss: 0.6869423098067947
Epoch: 82 | Iteration number: [3950/4518] 87% | Training loss: 0.6869447028938728
Epoch: 82 | Iteration number: [3960/4518] 87% | Training loss: 0.6869484475164702
Epoch: 82 | Iteration number: [3970/4518] 87% | Training loss: 0.6869468506697743
Epoch: 82 | Iteration number: [3980/4518] 88% | Training loss: 0.6869440788599714
Epoch: 82 | Iteration number: [3990/4518] 88% | Training loss: 0.6869437269997178
Epoch: 82 | Iteration number: [4000/4518] 88% | Training loss: 0.6869460955709219
Epoch: 82 | Iteration number: [4010/4518] 88% | Training loss: 0.6869455522135309
Epoch: 82 | Iteration number: [4020/4518] 88% | Training loss: 0.686947137754948
Epoch: 82 | Iteration number: [4030/4518] 89% | Training loss: 0.6869449568149766
Epoch: 82 | Iteration number: [4040/4518] 89% | Training loss: 0.6869408866704101
Epoch: 82 | Iteration number: [4050/4518] 89% | Training loss: 0.6869435845333853
Epoch: 82 | Iteration number: [4060/4518] 89% | Training loss: 0.6869414715344095
Epoch: 82 | Iteration number: [4070/4518] 90% | Training loss: 0.6869434739799406
Epoch: 82 | Iteration number: [4080/4518] 90% | Training loss: 0.6869409718788138
Epoch: 82 | Iteration number: [4090/4518] 90% | Training loss: 0.6869409822310095
Epoch: 82 | Iteration number: [4100/4518] 90% | Training loss: 0.6869426398015603
Epoch: 82 | Iteration number: [4110/4518] 90% | Training loss: 0.6869442484239592
Epoch: 82 | Iteration number: [4120/4518] 91% | Training loss: 0.6869454268546937
Epoch: 82 | Iteration number: [4130/4518] 91% | Training loss: 0.6869445072680929
Epoch: 82 | Iteration number: [4140/4518] 91% | Training loss: 0.6869417329341317
Epoch: 82 | Iteration number: [4150/4518] 91% | Training loss: 0.6869447122711733
Epoch: 82 | Iteration number: [4160/4518] 92% | Training loss: 0.6869413568709906
Epoch: 82 | Iteration number: [4170/4518] 92% | Training loss: 0.6869380940636285
Epoch: 82 | Iteration number: [4180/4518] 92% | Training loss: 0.6869385688356235
Epoch: 82 | Iteration number: [4190/4518] 92% | Training loss: 0.6869358720386797
Epoch: 82 | Iteration number: [4200/4518] 92% | Training loss: 0.6869339112298829
Epoch: 82 | Iteration number: [4210/4518] 93% | Training loss: 0.6869329712453194
Epoch: 82 | Iteration number: [4220/4518] 93% | Training loss: 0.686930551729496
Epoch: 82 | Iteration number: [4230/4518] 93% | Training loss: 0.6869280942083814
Epoch: 82 | Iteration number: [4240/4518] 93% | Training loss: 0.686928641374381
Epoch: 82 | Iteration number: [4250/4518] 94% | Training loss: 0.6869302282193128
Epoch: 82 | Iteration number: [4260/4518] 94% | Training loss: 0.6869320524270546
Epoch: 82 | Iteration number: [4270/4518] 94% | Training loss: 0.6869300057374342
Epoch: 82 | Iteration number: [4280/4518] 94% | Training loss: 0.6869259659235722
Epoch: 82 | Iteration number: [4290/4518] 94% | Training loss: 0.6869271336874484
Epoch: 82 | Iteration number: [4300/4518] 95% | Training loss: 0.6869281134494515
Epoch: 82 | Iteration number: [4310/4518] 95% | Training loss: 0.686929145171858
Epoch: 82 | Iteration number: [4320/4518] 95% | Training loss: 0.686926833347038
Epoch: 82 | Iteration number: [4330/4518] 95% | Training loss: 0.6869231345334175
Epoch: 82 | Iteration number: [4340/4518] 96% | Training loss: 0.6869241566839306
Epoch: 82 | Iteration number: [4350/4518] 96% | Training loss: 0.6869259691238403
Epoch: 82 | Iteration number: [4360/4518] 96% | Training loss: 0.6869249868420286
Epoch: 82 | Iteration number: [4370/4518] 96% | Training loss: 0.6869263914957199
Epoch: 82 | Iteration number: [4380/4518] 96% | Training loss: 0.6869238757515607
Epoch: 82 | Iteration number: [4390/4518] 97% | Training loss: 0.6869251679722432
Epoch: 82 | Iteration number: [4400/4518] 97% | Training loss: 0.6869256890091029
Epoch: 82 | Iteration number: [4410/4518] 97% | Training loss: 0.6869266486762603
Epoch: 82 | Iteration number: [4420/4518] 97% | Training loss: 0.6869247892593366
Epoch: 82 | Iteration number: [4430/4518] 98% | Training loss: 0.6869218866792812
Epoch: 82 | Iteration number: [4440/4518] 98% | Training loss: 0.6869207878370542
Epoch: 82 | Iteration number: [4450/4518] 98% | Training loss: 0.6869204787993699
Epoch: 82 | Iteration number: [4460/4518] 98% | Training loss: 0.6869190848060788
Epoch: 82 | Iteration number: [4470/4518] 98% | Training loss: 0.6869192232221565
Epoch: 82 | Iteration number: [4480/4518] 99% | Training loss: 0.6869164990527289
Epoch: 82 | Iteration number: [4490/4518] 99% | Training loss: 0.6869152444640884
Epoch: 82 | Iteration number: [4500/4518] 99% | Training loss: 0.686915333920055
Epoch: 82 | Iteration number: [4510/4518] 99% | Training loss: 0.6869164666949777

 End of epoch: 82 | Train Loss: 0.6867632288592956 | Training Time: 640 

 End of epoch: 82 | Eval Loss: 0.6897974427865476 | Evaluating Time: 16 
Epoch: 83 | Iteration number: [10/4518] 0% | Training loss: 0.7540450274944306
Epoch: 83 | Iteration number: [20/4518] 0% | Training loss: 0.7202663600444794
Epoch: 83 | Iteration number: [30/4518] 0% | Training loss: 0.708921347061793
Epoch: 83 | Iteration number: [40/4518] 0% | Training loss: 0.7035097077488899
Epoch: 83 | Iteration number: [50/4518] 1% | Training loss: 0.6998640334606171
Epoch: 83 | Iteration number: [60/4518] 1% | Training loss: 0.6975815941890081
Epoch: 83 | Iteration number: [70/4518] 1% | Training loss: 0.6960821441241674
Epoch: 83 | Iteration number: [80/4518] 1% | Training loss: 0.6949524141848087
Epoch: 83 | Iteration number: [90/4518] 1% | Training loss: 0.6940967175695631
Epoch: 83 | Iteration number: [100/4518] 2% | Training loss: 0.6933223575353622
Epoch: 83 | Iteration number: [110/4518] 2% | Training loss: 0.6928286541591991
Epoch: 83 | Iteration number: [120/4518] 2% | Training loss: 0.6921684354543686
Epoch: 83 | Iteration number: [130/4518] 2% | Training loss: 0.6917397911732014
Epoch: 83 | Iteration number: [140/4518] 3% | Training loss: 0.6914299466780254
Epoch: 83 | Iteration number: [150/4518] 3% | Training loss: 0.6911768047014872
Epoch: 83 | Iteration number: [160/4518] 3% | Training loss: 0.6908890698105097
Epoch: 83 | Iteration number: [170/4518] 3% | Training loss: 0.6906876679729013
Epoch: 83 | Iteration number: [180/4518] 3% | Training loss: 0.690510732597775
Epoch: 83 | Iteration number: [190/4518] 4% | Training loss: 0.690309110440706
Epoch: 83 | Iteration number: [200/4518] 4% | Training loss: 0.6901409909129143
Epoch: 83 | Iteration number: [210/4518] 4% | Training loss: 0.6899857731092544
Epoch: 83 | Iteration number: [220/4518] 4% | Training loss: 0.689849499409849
Epoch: 83 | Iteration number: [230/4518] 5% | Training loss: 0.6898211155248725
Epoch: 83 | Iteration number: [240/4518] 5% | Training loss: 0.6896756467719872
Epoch: 83 | Iteration number: [250/4518] 5% | Training loss: 0.6895260300636291
Epoch: 83 | Iteration number: [260/4518] 5% | Training loss: 0.6893589620406811
Epoch: 83 | Iteration number: [270/4518] 5% | Training loss: 0.6892459730307261
Epoch: 83 | Iteration number: [280/4518] 6% | Training loss: 0.6891658880880901
Epoch: 83 | Iteration number: [290/4518] 6% | Training loss: 0.6891376063741487
Epoch: 83 | Iteration number: [300/4518] 6% | Training loss: 0.6890578699111939
Epoch: 83 | Iteration number: [310/4518] 6% | Training loss: 0.6889925904812352
Epoch: 83 | Iteration number: [320/4518] 7% | Training loss: 0.6888976627960801
Epoch: 83 | Iteration number: [330/4518] 7% | Training loss: 0.688798334201177
Epoch: 83 | Iteration number: [340/4518] 7% | Training loss: 0.688804703074343
Epoch: 83 | Iteration number: [350/4518] 7% | Training loss: 0.6887154396942684
Epoch: 83 | Iteration number: [360/4518] 7% | Training loss: 0.6886363244718976
Epoch: 83 | Iteration number: [370/4518] 8% | Training loss: 0.6885865768870791
Epoch: 83 | Iteration number: [380/4518] 8% | Training loss: 0.6885071371731005
Epoch: 83 | Iteration number: [390/4518] 8% | Training loss: 0.6884805908569923
Epoch: 83 | Iteration number: [400/4518] 8% | Training loss: 0.6884354357421398
Epoch: 83 | Iteration number: [410/4518] 9% | Training loss: 0.6883793380202317
Epoch: 83 | Iteration number: [420/4518] 9% | Training loss: 0.6883290357532955
Epoch: 83 | Iteration number: [430/4518] 9% | Training loss: 0.6883072810117589
Epoch: 83 | Iteration number: [440/4518] 9% | Training loss: 0.6882418774745681
Epoch: 83 | Iteration number: [450/4518] 9% | Training loss: 0.6882154785262213
Epoch: 83 | Iteration number: [460/4518] 10% | Training loss: 0.6881882930579393
Epoch: 83 | Iteration number: [470/4518] 10% | Training loss: 0.6881627853880538
Epoch: 83 | Iteration number: [480/4518] 10% | Training loss: 0.68814817070961
Epoch: 83 | Iteration number: [490/4518] 10% | Training loss: 0.6881248088515535
Epoch: 83 | Iteration number: [500/4518] 11% | Training loss: 0.6880996280908585
Epoch: 83 | Iteration number: [510/4518] 11% | Training loss: 0.6881014577313965
Epoch: 83 | Iteration number: [520/4518] 11% | Training loss: 0.688054792697613
Epoch: 83 | Iteration number: [530/4518] 11% | Training loss: 0.6880324448054691
Epoch: 83 | Iteration number: [540/4518] 11% | Training loss: 0.6880132561480558
Epoch: 83 | Iteration number: [550/4518] 12% | Training loss: 0.6879622180895372
Epoch: 83 | Iteration number: [560/4518] 12% | Training loss: 0.6879463031888008
Epoch: 83 | Iteration number: [570/4518] 12% | Training loss: 0.6879296472198084
Epoch: 83 | Iteration number: [580/4518] 12% | Training loss: 0.6878844748283255
Epoch: 83 | Iteration number: [590/4518] 13% | Training loss: 0.6878669219501948
Epoch: 83 | Iteration number: [600/4518] 13% | Training loss: 0.6878826971848806
Epoch: 83 | Iteration number: [610/4518] 13% | Training loss: 0.6878507302432764
Epoch: 83 | Iteration number: [620/4518] 13% | Training loss: 0.6878469428708477
Epoch: 83 | Iteration number: [630/4518] 13% | Training loss: 0.6878374198126415
Epoch: 83 | Iteration number: [640/4518] 14% | Training loss: 0.6878297403454781
Epoch: 83 | Iteration number: [650/4518] 14% | Training loss: 0.6878279577768766
Epoch: 83 | Iteration number: [660/4518] 14% | Training loss: 0.6877949860962954
Epoch: 83 | Iteration number: [670/4518] 14% | Training loss: 0.687785268986403
Epoch: 83 | Iteration number: [680/4518] 15% | Training loss: 0.6877733210430426
Epoch: 83 | Iteration number: [690/4518] 15% | Training loss: 0.6877639342045438
Epoch: 83 | Iteration number: [700/4518] 15% | Training loss: 0.6877507036072867
Epoch: 83 | Iteration number: [710/4518] 15% | Training loss: 0.6877336205730975
Epoch: 83 | Iteration number: [720/4518] 15% | Training loss: 0.6877247784700659
Epoch: 83 | Iteration number: [730/4518] 16% | Training loss: 0.6877144615944117
Epoch: 83 | Iteration number: [740/4518] 16% | Training loss: 0.6876868535537978
Epoch: 83 | Iteration number: [750/4518] 16% | Training loss: 0.6876693311532338
Epoch: 83 | Iteration number: [760/4518] 16% | Training loss: 0.6876335431870662
Epoch: 83 | Iteration number: [770/4518] 17% | Training loss: 0.6876092595713479
Epoch: 83 | Iteration number: [780/4518] 17% | Training loss: 0.6875920554766288
Epoch: 83 | Iteration number: [790/4518] 17% | Training loss: 0.6875760710692104
Epoch: 83 | Iteration number: [800/4518] 17% | Training loss: 0.687553479000926
Epoch: 83 | Iteration number: [810/4518] 17% | Training loss: 0.6875392629776472
Epoch: 83 | Iteration number: [820/4518] 18% | Training loss: 0.6875055664196247
Epoch: 83 | Iteration number: [830/4518] 18% | Training loss: 0.687505062229662
Epoch: 83 | Iteration number: [840/4518] 18% | Training loss: 0.6874986702487582
Epoch: 83 | Iteration number: [850/4518] 18% | Training loss: 0.6874754772466771
Epoch: 83 | Iteration number: [860/4518] 19% | Training loss: 0.6874765311562738
Epoch: 83 | Iteration number: [870/4518] 19% | Training loss: 0.6874524115831002
Epoch: 83 | Iteration number: [880/4518] 19% | Training loss: 0.6874404205517335
Epoch: 83 | Iteration number: [890/4518] 19% | Training loss: 0.6874269171377246
Epoch: 83 | Iteration number: [900/4518] 19% | Training loss: 0.6874250142441856
Epoch: 83 | Iteration number: [910/4518] 20% | Training loss: 0.6874161975724357
Epoch: 83 | Iteration number: [920/4518] 20% | Training loss: 0.6874129431403202
Epoch: 83 | Iteration number: [930/4518] 20% | Training loss: 0.6874067254604832
Epoch: 83 | Iteration number: [940/4518] 20% | Training loss: 0.687383974486209
Epoch: 83 | Iteration number: [950/4518] 21% | Training loss: 0.6873730075359344
Epoch: 83 | Iteration number: [960/4518] 21% | Training loss: 0.6873784007504582
Epoch: 83 | Iteration number: [970/4518] 21% | Training loss: 0.687364691188655
Epoch: 83 | Iteration number: [980/4518] 21% | Training loss: 0.6873619697531875
Epoch: 83 | Iteration number: [990/4518] 21% | Training loss: 0.6873587121265103
Epoch: 83 | Iteration number: [1000/4518] 22% | Training loss: 0.6873414460420608
Epoch: 83 | Iteration number: [1010/4518] 22% | Training loss: 0.6873249165492483
Epoch: 83 | Iteration number: [1020/4518] 22% | Training loss: 0.687320654181873
Epoch: 83 | Iteration number: [1030/4518] 22% | Training loss: 0.6873226117740557
Epoch: 83 | Iteration number: [1040/4518] 23% | Training loss: 0.6873215278753868
Epoch: 83 | Iteration number: [1050/4518] 23% | Training loss: 0.6873048571745555
Epoch: 83 | Iteration number: [1060/4518] 23% | Training loss: 0.6873113140182675
Epoch: 83 | Iteration number: [1070/4518] 23% | Training loss: 0.687299258129619
Epoch: 83 | Iteration number: [1080/4518] 23% | Training loss: 0.6872949127245832
Epoch: 83 | Iteration number: [1090/4518] 24% | Training loss: 0.6872803840615334
Epoch: 83 | Iteration number: [1100/4518] 24% | Training loss: 0.6872684129801664
Epoch: 83 | Iteration number: [1110/4518] 24% | Training loss: 0.6872764815618326
Epoch: 83 | Iteration number: [1120/4518] 24% | Training loss: 0.6872840066573449
Epoch: 83 | Iteration number: [1130/4518] 25% | Training loss: 0.6872793631216066
Epoch: 83 | Iteration number: [1140/4518] 25% | Training loss: 0.687279755452223
Epoch: 83 | Iteration number: [1150/4518] 25% | Training loss: 0.6872831274115521
Epoch: 83 | Iteration number: [1160/4518] 25% | Training loss: 0.68727701522153
Epoch: 83 | Iteration number: [1170/4518] 25% | Training loss: 0.6872682248934722
Epoch: 83 | Iteration number: [1180/4518] 26% | Training loss: 0.6872634149203867
Epoch: 83 | Iteration number: [1190/4518] 26% | Training loss: 0.6872651623577631
Epoch: 83 | Iteration number: [1200/4518] 26% | Training loss: 0.6872691232462724
Epoch: 83 | Iteration number: [1210/4518] 26% | Training loss: 0.6872631709437725
Epoch: 83 | Iteration number: [1220/4518] 27% | Training loss: 0.687248584774674
Epoch: 83 | Iteration number: [1230/4518] 27% | Training loss: 0.6872357864205431
Epoch: 83 | Iteration number: [1240/4518] 27% | Training loss: 0.6872185693633172
Epoch: 83 | Iteration number: [1250/4518] 27% | Training loss: 0.6872230377674102
Epoch: 83 | Iteration number: [1260/4518] 27% | Training loss: 0.6872310838529042
Epoch: 83 | Iteration number: [1270/4518] 28% | Training loss: 0.6872289681059169
Epoch: 83 | Iteration number: [1280/4518] 28% | Training loss: 0.6872376983519644
Epoch: 83 | Iteration number: [1290/4518] 28% | Training loss: 0.6872471698032793
Epoch: 83 | Iteration number: [1300/4518] 28% | Training loss: 0.6872429038469609
Epoch: 83 | Iteration number: [1310/4518] 28% | Training loss: 0.6872492386184575
Epoch: 83 | Iteration number: [1320/4518] 29% | Training loss: 0.6872480930252509
Epoch: 83 | Iteration number: [1330/4518] 29% | Training loss: 0.6872484262276413
Epoch: 83 | Iteration number: [1340/4518] 29% | Training loss: 0.6872414068054797
Epoch: 83 | Iteration number: [1350/4518] 29% | Training loss: 0.6872441858273965
Epoch: 83 | Iteration number: [1360/4518] 30% | Training loss: 0.6872407243532292
Epoch: 83 | Iteration number: [1370/4518] 30% | Training loss: 0.6872323937659716
Epoch: 83 | Iteration number: [1380/4518] 30% | Training loss: 0.6872340047705001
Epoch: 83 | Iteration number: [1390/4518] 30% | Training loss: 0.6872314151671293
Epoch: 83 | Iteration number: [1400/4518] 30% | Training loss: 0.687231801705701
Epoch: 83 | Iteration number: [1410/4518] 31% | Training loss: 0.6872254032615229
Epoch: 83 | Iteration number: [1420/4518] 31% | Training loss: 0.6872199281420506
Epoch: 83 | Iteration number: [1430/4518] 31% | Training loss: 0.6872111381350697
Epoch: 83 | Iteration number: [1440/4518] 31% | Training loss: 0.687201050337818
Epoch: 83 | Iteration number: [1450/4518] 32% | Training loss: 0.6872058648487617
Epoch: 83 | Iteration number: [1460/4518] 32% | Training loss: 0.6872020559359904
Epoch: 83 | Iteration number: [1470/4518] 32% | Training loss: 0.6871900129074953
Epoch: 83 | Iteration number: [1480/4518] 32% | Training loss: 0.6871868885449461
Epoch: 83 | Iteration number: [1490/4518] 32% | Training loss: 0.6871847787559432
Epoch: 83 | Iteration number: [1500/4518] 33% | Training loss: 0.6871715317964554
Epoch: 83 | Iteration number: [1510/4518] 33% | Training loss: 0.6871646064796195
Epoch: 83 | Iteration number: [1520/4518] 33% | Training loss: 0.6871627392737489
Epoch: 83 | Iteration number: [1530/4518] 33% | Training loss: 0.6871610269827001
Epoch: 83 | Iteration number: [1540/4518] 34% | Training loss: 0.6871625359182234
Epoch: 83 | Iteration number: [1550/4518] 34% | Training loss: 0.6871669100176904
Epoch: 83 | Iteration number: [1560/4518] 34% | Training loss: 0.6871677780380616
Epoch: 83 | Iteration number: [1570/4518] 34% | Training loss: 0.6871643649924333
Epoch: 83 | Iteration number: [1580/4518] 34% | Training loss: 0.6871649228696581
Epoch: 83 | Iteration number: [1590/4518] 35% | Training loss: 0.687168328192249
Epoch: 83 | Iteration number: [1600/4518] 35% | Training loss: 0.6871609434857965
Epoch: 83 | Iteration number: [1610/4518] 35% | Training loss: 0.6871645161083766
Epoch: 83 | Iteration number: [1620/4518] 35% | Training loss: 0.6871660446679151
Epoch: 83 | Iteration number: [1630/4518] 36% | Training loss: 0.6871612606970079
Epoch: 83 | Iteration number: [1640/4518] 36% | Training loss: 0.6871582739963764
Epoch: 83 | Iteration number: [1650/4518] 36% | Training loss: 0.6871460390090942
Epoch: 83 | Iteration number: [1660/4518] 36% | Training loss: 0.6871436957494322
Epoch: 83 | Iteration number: [1670/4518] 36% | Training loss: 0.6871425333137284
Epoch: 83 | Iteration number: [1680/4518] 37% | Training loss: 0.6871467815978186
Epoch: 83 | Iteration number: [1690/4518] 37% | Training loss: 0.6871427883410595
Epoch: 83 | Iteration number: [1700/4518] 37% | Training loss: 0.687139088195913
Epoch: 83 | Iteration number: [1710/4518] 37% | Training loss: 0.6871296609354298
Epoch: 83 | Iteration number: [1720/4518] 38% | Training loss: 0.687124792295833
Epoch: 83 | Iteration number: [1730/4518] 38% | Training loss: 0.6871248294507837
Epoch: 83 | Iteration number: [1740/4518] 38% | Training loss: 0.687120324989845
Epoch: 83 | Iteration number: [1750/4518] 38% | Training loss: 0.6871229377474104
Epoch: 83 | Iteration number: [1760/4518] 38% | Training loss: 0.687128067558462
Epoch: 83 | Iteration number: [1770/4518] 39% | Training loss: 0.6871319329671267
Epoch: 83 | Iteration number: [1780/4518] 39% | Training loss: 0.687132831503836
Epoch: 83 | Iteration number: [1790/4518] 39% | Training loss: 0.6871322393750345
Epoch: 83 | Iteration number: [1800/4518] 39% | Training loss: 0.6871289857890871
Epoch: 83 | Iteration number: [1810/4518] 40% | Training loss: 0.6871215032609128
Epoch: 83 | Iteration number: [1820/4518] 40% | Training loss: 0.6871238744193381
Epoch: 83 | Iteration number: [1830/4518] 40% | Training loss: 0.6871165786610275
Epoch: 83 | Iteration number: [1840/4518] 40% | Training loss: 0.6871085707908091
Epoch: 83 | Iteration number: [1850/4518] 40% | Training loss: 0.6871110788551537
Epoch: 83 | Iteration number: [1860/4518] 41% | Training loss: 0.687108304135261
Epoch: 83 | Iteration number: [1870/4518] 41% | Training loss: 0.6871075789239954
Epoch: 83 | Iteration number: [1880/4518] 41% | Training loss: 0.6871017318139685
Epoch: 83 | Iteration number: [1890/4518] 41% | Training loss: 0.687098748248721
Epoch: 83 | Iteration number: [1900/4518] 42% | Training loss: 0.6870935952663422
Epoch: 83 | Iteration number: [1910/4518] 42% | Training loss: 0.687091855759396
Epoch: 83 | Iteration number: [1920/4518] 42% | Training loss: 0.6870890469290316
Epoch: 83 | Iteration number: [1930/4518] 42% | Training loss: 0.6870938723260257
Epoch: 83 | Iteration number: [1940/4518] 42% | Training loss: 0.6870957337703901
Epoch: 83 | Iteration number: [1950/4518] 43% | Training loss: 0.6871000903692001
Epoch: 83 | Iteration number: [1960/4518] 43% | Training loss: 0.6870992534622854
Epoch: 83 | Iteration number: [1970/4518] 43% | Training loss: 0.6871011775459734
Epoch: 83 | Iteration number: [1980/4518] 43% | Training loss: 0.6870969522782047
Epoch: 83 | Iteration number: [1990/4518] 44% | Training loss: 0.6870919524425239
Epoch: 83 | Iteration number: [2000/4518] 44% | Training loss: 0.6870897046327591
Epoch: 83 | Iteration number: [2010/4518] 44% | Training loss: 0.687088066991882
Epoch: 83 | Iteration number: [2020/4518] 44% | Training loss: 0.6870808874321456
Epoch: 83 | Iteration number: [2030/4518] 44% | Training loss: 0.6870750636596398
Epoch: 83 | Iteration number: [2040/4518] 45% | Training loss: 0.6870728587403017
Epoch: 83 | Iteration number: [2050/4518] 45% | Training loss: 0.6870693920589075
Epoch: 83 | Iteration number: [2060/4518] 45% | Training loss: 0.6870739111043874
Epoch: 83 | Iteration number: [2070/4518] 45% | Training loss: 0.6870733924246065
Epoch: 83 | Iteration number: [2080/4518] 46% | Training loss: 0.6870759821568544
Epoch: 83 | Iteration number: [2090/4518] 46% | Training loss: 0.6870734174000589
Epoch: 83 | Iteration number: [2100/4518] 46% | Training loss: 0.6870750262623742
Epoch: 83 | Iteration number: [2110/4518] 46% | Training loss: 0.6870745264805889
Epoch: 83 | Iteration number: [2120/4518] 46% | Training loss: 0.687067897336663
Epoch: 83 | Iteration number: [2130/4518] 47% | Training loss: 0.6870681155455505
Epoch: 83 | Iteration number: [2140/4518] 47% | Training loss: 0.6870676711897984
Epoch: 83 | Iteration number: [2150/4518] 47% | Training loss: 0.6870667946893115
Epoch: 83 | Iteration number: [2160/4518] 47% | Training loss: 0.6870715118668698
Epoch: 83 | Iteration number: [2170/4518] 48% | Training loss: 0.6870686530242868
Epoch: 83 | Iteration number: [2180/4518] 48% | Training loss: 0.687058681085569
Epoch: 83 | Iteration number: [2190/4518] 48% | Training loss: 0.6870597549497265
Epoch: 83 | Iteration number: [2200/4518] 48% | Training loss: 0.6870607368241657
Epoch: 83 | Iteration number: [2210/4518] 48% | Training loss: 0.6870584454471709
Epoch: 83 | Iteration number: [2220/4518] 49% | Training loss: 0.6870558427260802
Epoch: 83 | Iteration number: [2230/4518] 49% | Training loss: 0.6870602438268105
Epoch: 83 | Iteration number: [2240/4518] 49% | Training loss: 0.6870591334466424
Epoch: 83 | Iteration number: [2250/4518] 49% | Training loss: 0.6870563242965274
Epoch: 83 | Iteration number: [2260/4518] 50% | Training loss: 0.6870570635373614
Epoch: 83 | Iteration number: [2270/4518] 50% | Training loss: 0.6870609248787296
Epoch: 83 | Iteration number: [2280/4518] 50% | Training loss: 0.6870573496609403
Epoch: 83 | Iteration number: [2290/4518] 50% | Training loss: 0.6870550380002984
Epoch: 83 | Iteration number: [2300/4518] 50% | Training loss: 0.6870495314701743
Epoch: 83 | Iteration number: [2310/4518] 51% | Training loss: 0.6870440663455368
Epoch: 83 | Iteration number: [2320/4518] 51% | Training loss: 0.6870455140440629
Epoch: 83 | Iteration number: [2330/4518] 51% | Training loss: 0.6870406090701598
Epoch: 83 | Iteration number: [2340/4518] 51% | Training loss: 0.6870362217354978
Epoch: 83 | Iteration number: [2350/4518] 52% | Training loss: 0.6870370181063388
Epoch: 83 | Iteration number: [2360/4518] 52% | Training loss: 0.6870332083964752
Epoch: 83 | Iteration number: [2370/4518] 52% | Training loss: 0.6870328489486678
Epoch: 83 | Iteration number: [2380/4518] 52% | Training loss: 0.6870312539469294
Epoch: 83 | Iteration number: [2390/4518] 52% | Training loss: 0.6870317828206338
Epoch: 83 | Iteration number: [2400/4518] 53% | Training loss: 0.6870326527704795
Epoch: 83 | Iteration number: [2410/4518] 53% | Training loss: 0.687031915994106
Epoch: 83 | Iteration number: [2420/4518] 53% | Training loss: 0.6870322476733814
Epoch: 83 | Iteration number: [2430/4518] 53% | Training loss: 0.6870266286433969
Epoch: 83 | Iteration number: [2440/4518] 54% | Training loss: 0.6870239637425688
Epoch: 83 | Iteration number: [2450/4518] 54% | Training loss: 0.6870238878045763
Epoch: 83 | Iteration number: [2460/4518] 54% | Training loss: 0.6870262258421115
Epoch: 83 | Iteration number: [2470/4518] 54% | Training loss: 0.6870245655779896
Epoch: 83 | Iteration number: [2480/4518] 54% | Training loss: 0.687020427781728
Epoch: 83 | Iteration number: [2490/4518] 55% | Training loss: 0.6870220040461146
Epoch: 83 | Iteration number: [2500/4518] 55% | Training loss: 0.6870228602647781
Epoch: 83 | Iteration number: [2510/4518] 55% | Training loss: 0.6870273016363501
Epoch: 83 | Iteration number: [2520/4518] 55% | Training loss: 0.687026279289571
Epoch: 83 | Iteration number: [2530/4518] 55% | Training loss: 0.687018537615599
Epoch: 83 | Iteration number: [2540/4518] 56% | Training loss: 0.6870142606534357
Epoch: 83 | Iteration number: [2550/4518] 56% | Training loss: 0.6870116795511807
Epoch: 83 | Iteration number: [2560/4518] 56% | Training loss: 0.6870099553605542
Epoch: 83 | Iteration number: [2570/4518] 56% | Training loss: 0.6870087785015774
Epoch: 83 | Iteration number: [2580/4518] 57% | Training loss: 0.6870076265677001
Epoch: 83 | Iteration number: [2590/4518] 57% | Training loss: 0.6870106361087225
Epoch: 83 | Iteration number: [2600/4518] 57% | Training loss: 0.6870108234423857
Epoch: 83 | Iteration number: [2610/4518] 57% | Training loss: 0.6870085564838059
Epoch: 83 | Iteration number: [2620/4518] 57% | Training loss: 0.6870107091792668
Epoch: 83 | Iteration number: [2630/4518] 58% | Training loss: 0.687012569645965
Epoch: 83 | Iteration number: [2640/4518] 58% | Training loss: 0.6870103280426878
Epoch: 83 | Iteration number: [2650/4518] 58% | Training loss: 0.687011162762372
Epoch: 83 | Iteration number: [2660/4518] 58% | Training loss: 0.6870125776170788
Epoch: 83 | Iteration number: [2670/4518] 59% | Training loss: 0.687014096640469
Epoch: 83 | Iteration number: [2680/4518] 59% | Training loss: 0.6870188130594012
Epoch: 83 | Iteration number: [2690/4518] 59% | Training loss: 0.6870202982292742
Epoch: 83 | Iteration number: [2700/4518] 59% | Training loss: 0.6870190198553933
Epoch: 83 | Iteration number: [2710/4518] 59% | Training loss: 0.6870175872341733
Epoch: 83 | Iteration number: [2720/4518] 60% | Training loss: 0.687015417524997
Epoch: 83 | Iteration number: [2730/4518] 60% | Training loss: 0.687013113738853
Epoch: 83 | Iteration number: [2740/4518] 60% | Training loss: 0.6870080686398666
Epoch: 83 | Iteration number: [2750/4518] 60% | Training loss: 0.6870102881084789
Epoch: 83 | Iteration number: [2760/4518] 61% | Training loss: 0.687007111483726
Epoch: 83 | Iteration number: [2770/4518] 61% | Training loss: 0.687002958545616
Epoch: 83 | Iteration number: [2780/4518] 61% | Training loss: 0.6870016530692149
Epoch: 83 | Iteration number: [2790/4518] 61% | Training loss: 0.6870053581225829
Epoch: 83 | Iteration number: [2800/4518] 61% | Training loss: 0.6870050553551742
Epoch: 83 | Iteration number: [2810/4518] 62% | Training loss: 0.6870038209436627
Epoch: 83 | Iteration number: [2820/4518] 62% | Training loss: 0.6870065446229692
Epoch: 83 | Iteration number: [2830/4518] 62% | Training loss: 0.6870068327487568
Epoch: 83 | Iteration number: [2840/4518] 62% | Training loss: 0.6870087890977591
Epoch: 83 | Iteration number: [2850/4518] 63% | Training loss: 0.6870055631796519
Epoch: 83 | Iteration number: [2860/4518] 63% | Training loss: 0.6870048187829397
Epoch: 83 | Iteration number: [2870/4518] 63% | Training loss: 0.6869997419339023
Epoch: 83 | Iteration number: [2880/4518] 63% | Training loss: 0.6869978069224292
Epoch: 83 | Iteration number: [2890/4518] 63% | Training loss: 0.6869913735810448
Epoch: 83 | Iteration number: [2900/4518] 64% | Training loss: 0.6869852716141733
Epoch: 83 | Iteration number: [2910/4518] 64% | Training loss: 0.6869825586215736
Epoch: 83 | Iteration number: [2920/4518] 64% | Training loss: 0.6869817291220573
Epoch: 83 | Iteration number: [2930/4518] 64% | Training loss: 0.6869794050988077
Epoch: 83 | Iteration number: [2940/4518] 65% | Training loss: 0.6869750626435897
Epoch: 83 | Iteration number: [2950/4518] 65% | Training loss: 0.6869749098713115
Epoch: 83 | Iteration number: [2960/4518] 65% | Training loss: 0.6869760367314558
Epoch: 83 | Iteration number: [2970/4518] 65% | Training loss: 0.6869776172067983
Epoch: 83 | Iteration number: [2980/4518] 65% | Training loss: 0.6869800041985992
Epoch: 83 | Iteration number: [2990/4518] 66% | Training loss: 0.6869773622340581
Epoch: 83 | Iteration number: [3000/4518] 66% | Training loss: 0.6869791444341342
Epoch: 83 | Iteration number: [3010/4518] 66% | Training loss: 0.6869801158524826
Epoch: 83 | Iteration number: [3020/4518] 66% | Training loss: 0.6869814282024144
Epoch: 83 | Iteration number: [3030/4518] 67% | Training loss: 0.6869812218859644
Epoch: 83 | Iteration number: [3040/4518] 67% | Training loss: 0.686982289623273
Epoch: 83 | Iteration number: [3050/4518] 67% | Training loss: 0.6869808160476997
Epoch: 83 | Iteration number: [3060/4518] 67% | Training loss: 0.6869796998750151
Epoch: 83 | Iteration number: [3070/4518] 67% | Training loss: 0.6869843666833076
Epoch: 83 | Iteration number: [3080/4518] 68% | Training loss: 0.6869842210953886
Epoch: 83 | Iteration number: [3090/4518] 68% | Training loss: 0.6869833460710582
Epoch: 83 | Iteration number: [3100/4518] 68% | Training loss: 0.6869817284999356
Epoch: 83 | Iteration number: [3110/4518] 68% | Training loss: 0.6869771553964094
Epoch: 83 | Iteration number: [3120/4518] 69% | Training loss: 0.6869709332210895
Epoch: 83 | Iteration number: [3130/4518] 69% | Training loss: 0.6869711438497416
Epoch: 83 | Iteration number: [3140/4518] 69% | Training loss: 0.6869653451594577
Epoch: 83 | Iteration number: [3150/4518] 69% | Training loss: 0.6869667092391423
Epoch: 83 | Iteration number: [3160/4518] 69% | Training loss: 0.6869671915339518
Epoch: 83 | Iteration number: [3170/4518] 70% | Training loss: 0.6869656828299682
Epoch: 83 | Iteration number: [3180/4518] 70% | Training loss: 0.686962987566894
Epoch: 83 | Iteration number: [3190/4518] 70% | Training loss: 0.6869632425353072
Epoch: 83 | Iteration number: [3200/4518] 70% | Training loss: 0.6869648323766887
Epoch: 83 | Iteration number: [3210/4518] 71% | Training loss: 0.6869614730557178
Epoch: 83 | Iteration number: [3220/4518] 71% | Training loss: 0.6869588647014606
Epoch: 83 | Iteration number: [3230/4518] 71% | Training loss: 0.6869559845319104
Epoch: 83 | Iteration number: [3240/4518] 71% | Training loss: 0.6869524556177634
Epoch: 83 | Iteration number: [3250/4518] 71% | Training loss: 0.6869560445638804
Epoch: 83 | Iteration number: [3260/4518] 72% | Training loss: 0.686960221287663
Epoch: 83 | Iteration number: [3270/4518] 72% | Training loss: 0.6869605859485242
Epoch: 83 | Iteration number: [3280/4518] 72% | Training loss: 0.6869607686633017
Epoch: 83 | Iteration number: [3290/4518] 72% | Training loss: 0.6869613406505991
Epoch: 83 | Iteration number: [3300/4518] 73% | Training loss: 0.6869631247267579
Epoch: 83 | Iteration number: [3310/4518] 73% | Training loss: 0.6869636292904165
Epoch: 83 | Iteration number: [3320/4518] 73% | Training loss: 0.6869628993502582
Epoch: 83 | Iteration number: [3330/4518] 73% | Training loss: 0.686962898393293
Epoch: 83 | Iteration number: [3340/4518] 73% | Training loss: 0.6869659265358291
Epoch: 83 | Iteration number: [3350/4518] 74% | Training loss: 0.686963129328258
Epoch: 83 | Iteration number: [3360/4518] 74% | Training loss: 0.6869627566387256
Epoch: 83 | Iteration number: [3370/4518] 74% | Training loss: 0.686960269541698
Epoch: 83 | Iteration number: [3380/4518] 74% | Training loss: 0.6869639453097913
Epoch: 83 | Iteration number: [3390/4518] 75% | Training loss: 0.6869654122707063
Epoch: 83 | Iteration number: [3400/4518] 75% | Training loss: 0.6869656966889606
Epoch: 83 | Iteration number: [3410/4518] 75% | Training loss: 0.6869611007202405
Epoch: 83 | Iteration number: [3420/4518] 75% | Training loss: 0.6869602737719552
Epoch: 83 | Iteration number: [3430/4518] 75% | Training loss: 0.686959832402777
Epoch: 83 | Iteration number: [3440/4518] 76% | Training loss: 0.6869581396496574
Epoch: 83 | Iteration number: [3450/4518] 76% | Training loss: 0.6869526733350063
Epoch: 83 | Iteration number: [3460/4518] 76% | Training loss: 0.6869487813614696
Epoch: 83 | Iteration number: [3470/4518] 76% | Training loss: 0.6869474072449488
Epoch: 83 | Iteration number: [3480/4518] 77% | Training loss: 0.6869475936410071
Epoch: 83 | Iteration number: [3490/4518] 77% | Training loss: 0.6869449285176559
Epoch: 83 | Iteration number: [3500/4518] 77% | Training loss: 0.6869450312512262
Epoch: 83 | Iteration number: [3510/4518] 77% | Training loss: 0.6869473826172006
Epoch: 83 | Iteration number: [3520/4518] 77% | Training loss: 0.6869474324482409
Epoch: 83 | Iteration number: [3530/4518] 78% | Training loss: 0.6869440519100546
Epoch: 83 | Iteration number: [3540/4518] 78% | Training loss: 0.6869423209779006
Epoch: 83 | Iteration number: [3550/4518] 78% | Training loss: 0.6869405525167224
Epoch: 83 | Iteration number: [3560/4518] 78% | Training loss: 0.6869390737809492
Epoch: 83 | Iteration number: [3570/4518] 79% | Training loss: 0.6869404244656656
Epoch: 83 | Iteration number: [3580/4518] 79% | Training loss: 0.6869384860859237
Epoch: 83 | Iteration number: [3590/4518] 79% | Training loss: 0.686940716518333
Epoch: 83 | Iteration number: [3600/4518] 79% | Training loss: 0.6869410269790226
Epoch: 83 | Iteration number: [3610/4518] 79% | Training loss: 0.6869445871118033
Epoch: 83 | Iteration number: [3620/4518] 80% | Training loss: 0.6869437779840185
Epoch: 83 | Iteration number: [3630/4518] 80% | Training loss: 0.686943330121106
Epoch: 83 | Iteration number: [3640/4518] 80% | Training loss: 0.6869441617484932
Epoch: 83 | Iteration number: [3650/4518] 80% | Training loss: 0.6869422200934527
Epoch: 83 | Iteration number: [3660/4518] 81% | Training loss: 0.6869416287525104
Epoch: 83 | Iteration number: [3670/4518] 81% | Training loss: 0.6869440994568027
Epoch: 83 | Iteration number: [3680/4518] 81% | Training loss: 0.6869439851492644
Epoch: 83 | Iteration number: [3690/4518] 81% | Training loss: 0.6869447492002472
Epoch: 83 | Iteration number: [3700/4518] 81% | Training loss: 0.6869473553992607
Epoch: 83 | Iteration number: [3710/4518] 82% | Training loss: 0.6869460468825626
Epoch: 83 | Iteration number: [3720/4518] 82% | Training loss: 0.6869452652431304
Epoch: 83 | Iteration number: [3730/4518] 82% | Training loss: 0.6869471421350423
Epoch: 83 | Iteration number: [3740/4518] 82% | Training loss: 0.6869471463608869
Epoch: 83 | Iteration number: [3750/4518] 83% | Training loss: 0.6869480364640553
Epoch: 83 | Iteration number: [3760/4518] 83% | Training loss: 0.6869467590559036
Epoch: 83 | Iteration number: [3770/4518] 83% | Training loss: 0.6869451921561669
Epoch: 83 | Iteration number: [3780/4518] 83% | Training loss: 0.6869436271449245
Epoch: 83 | Iteration number: [3790/4518] 83% | Training loss: 0.6869429724197589
Epoch: 83 | Iteration number: [3800/4518] 84% | Training loss: 0.686937567623038
Epoch: 83 | Iteration number: [3810/4518] 84% | Training loss: 0.6869379233187578
Epoch: 83 | Iteration number: [3820/4518] 84% | Training loss: 0.6869354299537799
Epoch: 83 | Iteration number: [3830/4518] 84% | Training loss: 0.6869323690784196
Epoch: 83 | Iteration number: [3840/4518] 84% | Training loss: 0.6869325379220148
Epoch: 83 | Iteration number: [3850/4518] 85% | Training loss: 0.6869304605892727
Epoch: 83 | Iteration number: [3860/4518] 85% | Training loss: 0.6869314631495451
Epoch: 83 | Iteration number: [3870/4518] 85% | Training loss: 0.6869298144674424
Epoch: 83 | Iteration number: [3880/4518] 85% | Training loss: 0.686932741458883
Epoch: 83 | Iteration number: [3890/4518] 86% | Training loss: 0.686931886112169
Epoch: 83 | Iteration number: [3900/4518] 86% | Training loss: 0.6869338174966665
Epoch: 83 | Iteration number: [3910/4518] 86% | Training loss: 0.6869347392293194
Epoch: 83 | Iteration number: [3920/4518] 86% | Training loss: 0.6869362860918045
Epoch: 83 | Iteration number: [3930/4518] 86% | Training loss: 0.6869379122293633
Epoch: 83 | Iteration number: [3940/4518] 87% | Training loss: 0.6869391596710621
Epoch: 83 | Iteration number: [3950/4518] 87% | Training loss: 0.6869387562667267
Epoch: 83 | Iteration number: [3960/4518] 87% | Training loss: 0.6869343676801883
Epoch: 83 | Iteration number: [3970/4518] 87% | Training loss: 0.6869364659341817
Epoch: 83 | Iteration number: [3980/4518] 88% | Training loss: 0.6869371391271227
Epoch: 83 | Iteration number: [3990/4518] 88% | Training loss: 0.6869366673449228
Epoch: 83 | Iteration number: [4000/4518] 88% | Training loss: 0.6869353885799646
Epoch: 83 | Iteration number: [4010/4518] 88% | Training loss: 0.6869342261567675
Epoch: 83 | Iteration number: [4020/4518] 88% | Training loss: 0.6869351012641518
Epoch: 83 | Iteration number: [4030/4518] 89% | Training loss: 0.6869331736718455
Epoch: 83 | Iteration number: [4040/4518] 89% | Training loss: 0.6869336788754652
Epoch: 83 | Iteration number: [4050/4518] 89% | Training loss: 0.6869324185230113
Epoch: 83 | Iteration number: [4060/4518] 89% | Training loss: 0.6869292051334099
Epoch: 83 | Iteration number: [4070/4518] 90% | Training loss: 0.6869267565758866
Epoch: 83 | Iteration number: [4080/4518] 90% | Training loss: 0.6869240413547731
Epoch: 83 | Iteration number: [4090/4518] 90% | Training loss: 0.6869218587875366
Epoch: 83 | Iteration number: [4100/4518] 90% | Training loss: 0.6869202259255619
Epoch: 83 | Iteration number: [4110/4518] 90% | Training loss: 0.6869175741707322
Epoch: 83 | Iteration number: [4120/4518] 91% | Training loss: 0.6869183585192393
Epoch: 83 | Iteration number: [4130/4518] 91% | Training loss: 0.686918317174796
Epoch: 83 | Iteration number: [4140/4518] 91% | Training loss: 0.686916405711197
Epoch: 83 | Iteration number: [4150/4518] 91% | Training loss: 0.686912095130208
Epoch: 83 | Iteration number: [4160/4518] 92% | Training loss: 0.686912867326576
Epoch: 83 | Iteration number: [4170/4518] 92% | Training loss: 0.6869141768637321
Epoch: 83 | Iteration number: [4180/4518] 92% | Training loss: 0.6869130742036554
Epoch: 83 | Iteration number: [4190/4518] 92% | Training loss: 0.686910716474483
Epoch: 83 | Iteration number: [4200/4518] 92% | Training loss: 0.6869128393984977
Epoch: 83 | Iteration number: [4210/4518] 93% | Training loss: 0.6869100973470194
Epoch: 83 | Iteration number: [4220/4518] 93% | Training loss: 0.6869120039504851
Epoch: 83 | Iteration number: [4230/4518] 93% | Training loss: 0.6869129662677188
Epoch: 83 | Iteration number: [4240/4518] 93% | Training loss: 0.6869157319642463
Epoch: 83 | Iteration number: [4250/4518] 94% | Training loss: 0.6869159909276401
Epoch: 83 | Iteration number: [4260/4518] 94% | Training loss: 0.6869136853816923
Epoch: 83 | Iteration number: [4270/4518] 94% | Training loss: 0.6869148007600592
Epoch: 83 | Iteration number: [4280/4518] 94% | Training loss: 0.686916110574085
Epoch: 83 | Iteration number: [4290/4518] 94% | Training loss: 0.6869180358790018
Epoch: 83 | Iteration number: [4300/4518] 95% | Training loss: 0.6869205941433131
Epoch: 83 | Iteration number: [4310/4518] 95% | Training loss: 0.6869228910404126
Epoch: 83 | Iteration number: [4320/4518] 95% | Training loss: 0.6869188162877604
Epoch: 83 | Iteration number: [4330/4518] 95% | Training loss: 0.686917596532346
Epoch: 83 | Iteration number: [4340/4518] 96% | Training loss: 0.6869158087512864
Epoch: 83 | Iteration number: [4350/4518] 96% | Training loss: 0.6869165643878367
Epoch: 83 | Iteration number: [4360/4518] 96% | Training loss: 0.6869120927852228
Epoch: 83 | Iteration number: [4370/4518] 96% | Training loss: 0.6869134278673875
Epoch: 83 | Iteration number: [4380/4518] 96% | Training loss: 0.6869115723186432
Epoch: 83 | Iteration number: [4390/4518] 97% | Training loss: 0.6869122901375582
Epoch: 83 | Iteration number: [4400/4518] 97% | Training loss: 0.6869114762002771
Epoch: 83 | Iteration number: [4410/4518] 97% | Training loss: 0.6869133753841427
Epoch: 83 | Iteration number: [4420/4518] 97% | Training loss: 0.6869136822709131
Epoch: 83 | Iteration number: [4430/4518] 98% | Training loss: 0.6869146883218606
Epoch: 83 | Iteration number: [4440/4518] 98% | Training loss: 0.6869140586069038
Epoch: 83 | Iteration number: [4450/4518] 98% | Training loss: 0.686914246618078
Epoch: 83 | Iteration number: [4460/4518] 98% | Training loss: 0.6869162419184441
Epoch: 83 | Iteration number: [4470/4518] 98% | Training loss: 0.6869143596698241
Epoch: 83 | Iteration number: [4480/4518] 99% | Training loss: 0.6869156140834093
Epoch: 83 | Iteration number: [4490/4518] 99% | Training loss: 0.6869159880088007
Epoch: 83 | Iteration number: [4500/4518] 99% | Training loss: 0.6869144107235803
Epoch: 83 | Iteration number: [4510/4518] 99% | Training loss: 0.6869145043012572

 End of epoch: 83 | Train Loss: 0.6867607173638937 | Training Time: 640 

 End of epoch: 83 | Eval Loss: 0.6897974975255071 | Evaluating Time: 17 
Epoch: 84 | Iteration number: [10/4518] 0% | Training loss: 0.7570295929908752
Epoch: 84 | Iteration number: [20/4518] 0% | Training loss: 0.7218554079532623
Epoch: 84 | Iteration number: [30/4518] 0% | Training loss: 0.7108328600724538
Epoch: 84 | Iteration number: [40/4518] 0% | Training loss: 0.705011996626854
Epoch: 84 | Iteration number: [50/4518] 1% | Training loss: 0.7013892602920532
Epoch: 84 | Iteration number: [60/4518] 1% | Training loss: 0.6988278021415074
Epoch: 84 | Iteration number: [70/4518] 1% | Training loss: 0.6969376504421234
Epoch: 84 | Iteration number: [80/4518] 1% | Training loss: 0.6957791194319725
Epoch: 84 | Iteration number: [90/4518] 1% | Training loss: 0.6946049922042423
Epoch: 84 | Iteration number: [100/4518] 2% | Training loss: 0.6938355231285095
Epoch: 84 | Iteration number: [110/4518] 2% | Training loss: 0.693118032542142
Epoch: 84 | Iteration number: [120/4518] 2% | Training loss: 0.6925451412796975
Epoch: 84 | Iteration number: [130/4518] 2% | Training loss: 0.692124995818505
Epoch: 84 | Iteration number: [140/4518] 3% | Training loss: 0.6917836542640413
Epoch: 84 | Iteration number: [150/4518] 3% | Training loss: 0.6914177866776784
Epoch: 84 | Iteration number: [160/4518] 3% | Training loss: 0.6910688176751136
Epoch: 84 | Iteration number: [170/4518] 3% | Training loss: 0.6908063713242026
Epoch: 84 | Iteration number: [180/4518] 3% | Training loss: 0.690643267499076
Epoch: 84 | Iteration number: [190/4518] 4% | Training loss: 0.6904902009587539
Epoch: 84 | Iteration number: [200/4518] 4% | Training loss: 0.6902704614400864
Epoch: 84 | Iteration number: [210/4518] 4% | Training loss: 0.6901307279155368
Epoch: 84 | Iteration number: [220/4518] 4% | Training loss: 0.689951519261707
Epoch: 84 | Iteration number: [230/4518] 5% | Training loss: 0.6898437292679497
Epoch: 84 | Iteration number: [240/4518] 5% | Training loss: 0.6896851345896721
Epoch: 84 | Iteration number: [250/4518] 5% | Training loss: 0.689610044002533
Epoch: 84 | Iteration number: [260/4518] 5% | Training loss: 0.6895133068928352
Epoch: 84 | Iteration number: [270/4518] 5% | Training loss: 0.6893914306605303
Epoch: 84 | Iteration number: [280/4518] 6% | Training loss: 0.6893230825662613
Epoch: 84 | Iteration number: [290/4518] 6% | Training loss: 0.6891933654916698
Epoch: 84 | Iteration number: [300/4518] 6% | Training loss: 0.6891230110327403
Epoch: 84 | Iteration number: [310/4518] 6% | Training loss: 0.6890614201945643
Epoch: 84 | Iteration number: [320/4518] 7% | Training loss: 0.6890039442107081
Epoch: 84 | Iteration number: [330/4518] 7% | Training loss: 0.6889400117325061
Epoch: 84 | Iteration number: [340/4518] 7% | Training loss: 0.6888868267045302
Epoch: 84 | Iteration number: [350/4518] 7% | Training loss: 0.6888107146535601
Epoch: 84 | Iteration number: [360/4518] 7% | Training loss: 0.6887313392427232
Epoch: 84 | Iteration number: [370/4518] 8% | Training loss: 0.6886755178103576
Epoch: 84 | Iteration number: [380/4518] 8% | Training loss: 0.6886089356322037
Epoch: 84 | Iteration number: [390/4518] 8% | Training loss: 0.6885612021654081
Epoch: 84 | Iteration number: [400/4518] 8% | Training loss: 0.6884979467093945
Epoch: 84 | Iteration number: [410/4518] 9% | Training loss: 0.688461448361234
Epoch: 84 | Iteration number: [420/4518] 9% | Training loss: 0.6884195217064448
Epoch: 84 | Iteration number: [430/4518] 9% | Training loss: 0.6883907593959986
Epoch: 84 | Iteration number: [440/4518] 9% | Training loss: 0.6883360108191316
Epoch: 84 | Iteration number: [450/4518] 9% | Training loss: 0.6882924841509925
Epoch: 84 | Iteration number: [460/4518] 10% | Training loss: 0.6882625548735909
Epoch: 84 | Iteration number: [470/4518] 10% | Training loss: 0.6882035263041233
Epoch: 84 | Iteration number: [480/4518] 10% | Training loss: 0.6881908545891444
Epoch: 84 | Iteration number: [490/4518] 10% | Training loss: 0.6881323657473739
Epoch: 84 | Iteration number: [500/4518] 11% | Training loss: 0.6880892913341522
Epoch: 84 | Iteration number: [510/4518] 11% | Training loss: 0.6881092326313841
Epoch: 84 | Iteration number: [520/4518] 11% | Training loss: 0.6880844628581634
Epoch: 84 | Iteration number: [530/4518] 11% | Training loss: 0.6880619064816889
Epoch: 84 | Iteration number: [540/4518] 11% | Training loss: 0.6880373512153273
Epoch: 84 | Iteration number: [550/4518] 12% | Training loss: 0.6880259733850306
Epoch: 84 | Iteration number: [560/4518] 12% | Training loss: 0.68801964659776
Epoch: 84 | Iteration number: [570/4518] 12% | Training loss: 0.687991869554185
Epoch: 84 | Iteration number: [580/4518] 12% | Training loss: 0.6879886676525248
Epoch: 84 | Iteration number: [590/4518] 13% | Training loss: 0.6879806591292559
Epoch: 84 | Iteration number: [600/4518] 13% | Training loss: 0.6879390341043472
Epoch: 84 | Iteration number: [610/4518] 13% | Training loss: 0.6879188466267507
Epoch: 84 | Iteration number: [620/4518] 13% | Training loss: 0.6879099355589959
Epoch: 84 | Iteration number: [630/4518] 13% | Training loss: 0.6878681203675648
Epoch: 84 | Iteration number: [640/4518] 14% | Training loss: 0.6878554286435247
Epoch: 84 | Iteration number: [650/4518] 14% | Training loss: 0.6878244453210097
Epoch: 84 | Iteration number: [660/4518] 14% | Training loss: 0.6878246972958247
Epoch: 84 | Iteration number: [670/4518] 14% | Training loss: 0.687819872240522
Epoch: 84 | Iteration number: [680/4518] 15% | Training loss: 0.6878117064342779
Epoch: 84 | Iteration number: [690/4518] 15% | Training loss: 0.6878127529137377
Epoch: 84 | Iteration number: [700/4518] 15% | Training loss: 0.6878031983545848
Epoch: 84 | Iteration number: [710/4518] 15% | Training loss: 0.6877931966748037
Epoch: 84 | Iteration number: [720/4518] 15% | Training loss: 0.6877767152256435
Epoch: 84 | Iteration number: [730/4518] 16% | Training loss: 0.6877627567069171
Epoch: 84 | Iteration number: [740/4518] 16% | Training loss: 0.6877325258544973
Epoch: 84 | Iteration number: [750/4518] 16% | Training loss: 0.6877308354377747
Epoch: 84 | Iteration number: [760/4518] 16% | Training loss: 0.6877290176717858
Epoch: 84 | Iteration number: [770/4518] 17% | Training loss: 0.6877242441301222
Epoch: 84 | Iteration number: [780/4518] 17% | Training loss: 0.6877157202133766
Epoch: 84 | Iteration number: [790/4518] 17% | Training loss: 0.6877015202860289
Epoch: 84 | Iteration number: [800/4518] 17% | Training loss: 0.6876909518241883
Epoch: 84 | Iteration number: [810/4518] 17% | Training loss: 0.6876899446234291
Epoch: 84 | Iteration number: [820/4518] 18% | Training loss: 0.6876825384977387
Epoch: 84 | Iteration number: [830/4518] 18% | Training loss: 0.6876719361328217
Epoch: 84 | Iteration number: [840/4518] 18% | Training loss: 0.6876598916593052
Epoch: 84 | Iteration number: [850/4518] 18% | Training loss: 0.6876482432028826
Epoch: 84 | Iteration number: [860/4518] 19% | Training loss: 0.6876394446506057
Epoch: 84 | Iteration number: [870/4518] 19% | Training loss: 0.6876066679242013
Epoch: 84 | Iteration number: [880/4518] 19% | Training loss: 0.6876060550863092
Epoch: 84 | Iteration number: [890/4518] 19% | Training loss: 0.6876120061686869
Epoch: 84 | Iteration number: [900/4518] 19% | Training loss: 0.6876100018289354
Epoch: 84 | Iteration number: [910/4518] 20% | Training loss: 0.6876049895207961
Epoch: 84 | Iteration number: [920/4518] 20% | Training loss: 0.6875803806211638
Epoch: 84 | Iteration number: [930/4518] 20% | Training loss: 0.6875612665248173
Epoch: 84 | Iteration number: [940/4518] 20% | Training loss: 0.6875542704729324
Epoch: 84 | Iteration number: [950/4518] 21% | Training loss: 0.6875406861305237
Epoch: 84 | Iteration number: [960/4518] 21% | Training loss: 0.6875299048299591
Epoch: 84 | Iteration number: [970/4518] 21% | Training loss: 0.6875204188307537
Epoch: 84 | Iteration number: [980/4518] 21% | Training loss: 0.6875197926954347
Epoch: 84 | Iteration number: [990/4518] 21% | Training loss: 0.6875209486243701
Epoch: 84 | Iteration number: [1000/4518] 22% | Training loss: 0.6875254094600678
Epoch: 84 | Iteration number: [1010/4518] 22% | Training loss: 0.6875195780012867
Epoch: 84 | Iteration number: [1020/4518] 22% | Training loss: 0.6875137483956767
Epoch: 84 | Iteration number: [1030/4518] 22% | Training loss: 0.6875228324561443
Epoch: 84 | Iteration number: [1040/4518] 23% | Training loss: 0.6875223635480954
Epoch: 84 | Iteration number: [1050/4518] 23% | Training loss: 0.6875126767158508
Epoch: 84 | Iteration number: [1060/4518] 23% | Training loss: 0.6875081878225758
Epoch: 84 | Iteration number: [1070/4518] 23% | Training loss: 0.6875020282290806
Epoch: 84 | Iteration number: [1080/4518] 23% | Training loss: 0.6874936546992373
Epoch: 84 | Iteration number: [1090/4518] 24% | Training loss: 0.6874882940305482
Epoch: 84 | Iteration number: [1100/4518] 24% | Training loss: 0.6874902770736001
Epoch: 84 | Iteration number: [1110/4518] 24% | Training loss: 0.6874716263096612
Epoch: 84 | Iteration number: [1120/4518] 24% | Training loss: 0.6874672535806894
Epoch: 84 | Iteration number: [1130/4518] 25% | Training loss: 0.6874605554922492
Epoch: 84 | Iteration number: [1140/4518] 25% | Training loss: 0.6874482320066084
Epoch: 84 | Iteration number: [1150/4518] 25% | Training loss: 0.6874430775642395
Epoch: 84 | Iteration number: [1160/4518] 25% | Training loss: 0.6874293590414113
Epoch: 84 | Iteration number: [1170/4518] 25% | Training loss: 0.6874276347649403
Epoch: 84 | Iteration number: [1180/4518] 26% | Training loss: 0.6874209452988738
Epoch: 84 | Iteration number: [1190/4518] 26% | Training loss: 0.6874173767426435
Epoch: 84 | Iteration number: [1200/4518] 26% | Training loss: 0.6874192039171855
Epoch: 84 | Iteration number: [1210/4518] 26% | Training loss: 0.6874121855113132
Epoch: 84 | Iteration number: [1220/4518] 27% | Training loss: 0.6874106169235511
Epoch: 84 | Iteration number: [1230/4518] 27% | Training loss: 0.6873919344529873
Epoch: 84 | Iteration number: [1240/4518] 27% | Training loss: 0.6873930642201055
Epoch: 84 | Iteration number: [1250/4518] 27% | Training loss: 0.6873870841026306
Epoch: 84 | Iteration number: [1260/4518] 27% | Training loss: 0.6873896241188049
Epoch: 84 | Iteration number: [1270/4518] 28% | Training loss: 0.6873860873105958
Epoch: 84 | Iteration number: [1280/4518] 28% | Training loss: 0.6873783837538212
Epoch: 84 | Iteration number: [1290/4518] 28% | Training loss: 0.6873766063719757
Epoch: 84 | Iteration number: [1300/4518] 28% | Training loss: 0.6873768151723422
Epoch: 84 | Iteration number: [1310/4518] 28% | Training loss: 0.687362796659688
Epoch: 84 | Iteration number: [1320/4518] 29% | Training loss: 0.6873626222664659
Epoch: 84 | Iteration number: [1330/4518] 29% | Training loss: 0.6873601825613724
Epoch: 84 | Iteration number: [1340/4518] 29% | Training loss: 0.6873612155665213
Epoch: 84 | Iteration number: [1350/4518] 29% | Training loss: 0.6873588526690447
Epoch: 84 | Iteration number: [1360/4518] 30% | Training loss: 0.6873539161156206
Epoch: 84 | Iteration number: [1370/4518] 30% | Training loss: 0.6873471288785448
Epoch: 84 | Iteration number: [1380/4518] 30% | Training loss: 0.6873343847799992
Epoch: 84 | Iteration number: [1390/4518] 30% | Training loss: 0.6873296460230574
Epoch: 84 | Iteration number: [1400/4518] 30% | Training loss: 0.6873308356744903
Epoch: 84 | Iteration number: [1410/4518] 31% | Training loss: 0.687325132315886
Epoch: 84 | Iteration number: [1420/4518] 31% | Training loss: 0.6873203318723491
Epoch: 84 | Iteration number: [1430/4518] 31% | Training loss: 0.6873125399326111
Epoch: 84 | Iteration number: [1440/4518] 31% | Training loss: 0.68729648122357
Epoch: 84 | Iteration number: [1450/4518] 32% | Training loss: 0.6872904334808219
Epoch: 84 | Iteration number: [1460/4518] 32% | Training loss: 0.6872819342025339
Epoch: 84 | Iteration number: [1470/4518] 32% | Training loss: 0.6872771759827931
Epoch: 84 | Iteration number: [1480/4518] 32% | Training loss: 0.6872664329973427
Epoch: 84 | Iteration number: [1490/4518] 32% | Training loss: 0.6872689665163924
Epoch: 84 | Iteration number: [1500/4518] 33% | Training loss: 0.6872732553084692
Epoch: 84 | Iteration number: [1510/4518] 33% | Training loss: 0.6872712716361544
Epoch: 84 | Iteration number: [1520/4518] 33% | Training loss: 0.6872693498275781
Epoch: 84 | Iteration number: [1530/4518] 33% | Training loss: 0.6872550500374214
Epoch: 84 | Iteration number: [1540/4518] 34% | Training loss: 0.6872475082611109
Epoch: 84 | Iteration number: [1550/4518] 34% | Training loss: 0.6872415308413967
Epoch: 84 | Iteration number: [1560/4518] 34% | Training loss: 0.6872416927264287
Epoch: 84 | Iteration number: [1570/4518] 34% | Training loss: 0.6872320391569927
Epoch: 84 | Iteration number: [1580/4518] 34% | Training loss: 0.6872359617978712
Epoch: 84 | Iteration number: [1590/4518] 35% | Training loss: 0.687227534910418
Epoch: 84 | Iteration number: [1600/4518] 35% | Training loss: 0.6872180339321494
Epoch: 84 | Iteration number: [1610/4518] 35% | Training loss: 0.6872038894558545
Epoch: 84 | Iteration number: [1620/4518] 35% | Training loss: 0.6872011461007742
Epoch: 84 | Iteration number: [1630/4518] 36% | Training loss: 0.6871966916724948
Epoch: 84 | Iteration number: [1640/4518] 36% | Training loss: 0.6871946490755896
Epoch: 84 | Iteration number: [1650/4518] 36% | Training loss: 0.687183241446813
Epoch: 84 | Iteration number: [1660/4518] 36% | Training loss: 0.6871876682861742
Epoch: 84 | Iteration number: [1670/4518] 36% | Training loss: 0.6871949931818568
Epoch: 84 | Iteration number: [1680/4518] 37% | Training loss: 0.6871954752220995
Epoch: 84 | Iteration number: [1690/4518] 37% | Training loss: 0.6871872955172725
Epoch: 84 | Iteration number: [1700/4518] 37% | Training loss: 0.6871842955491122
Epoch: 84 | Iteration number: [1710/4518] 37% | Training loss: 0.6871794328354952
Epoch: 84 | Iteration number: [1720/4518] 38% | Training loss: 0.687176246074743
Epoch: 84 | Iteration number: [1730/4518] 38% | Training loss: 0.6871720427033529
Epoch: 84 | Iteration number: [1740/4518] 38% | Training loss: 0.687175293660712
Epoch: 84 | Iteration number: [1750/4518] 38% | Training loss: 0.6871799791199821
Epoch: 84 | Iteration number: [1760/4518] 38% | Training loss: 0.6871762726794589
Epoch: 84 | Iteration number: [1770/4518] 39% | Training loss: 0.6871803925872523
Epoch: 84 | Iteration number: [1780/4518] 39% | Training loss: 0.6871734758441368
Epoch: 84 | Iteration number: [1790/4518] 39% | Training loss: 0.6871694705672771
Epoch: 84 | Iteration number: [1800/4518] 39% | Training loss: 0.6871623372369342
Epoch: 84 | Iteration number: [1810/4518] 40% | Training loss: 0.687161628284507
Epoch: 84 | Iteration number: [1820/4518] 40% | Training loss: 0.6871647299973519
Epoch: 84 | Iteration number: [1830/4518] 40% | Training loss: 0.6871667348947681
Epoch: 84 | Iteration number: [1840/4518] 40% | Training loss: 0.6871693158279295
Epoch: 84 | Iteration number: [1850/4518] 40% | Training loss: 0.6871690460797902
Epoch: 84 | Iteration number: [1860/4518] 41% | Training loss: 0.6871666836802678
Epoch: 84 | Iteration number: [1870/4518] 41% | Training loss: 0.6871596581795636
Epoch: 84 | Iteration number: [1880/4518] 41% | Training loss: 0.6871517569777813
Epoch: 84 | Iteration number: [1890/4518] 41% | Training loss: 0.6871515885231987
Epoch: 84 | Iteration number: [1900/4518] 42% | Training loss: 0.6871479412756468
Epoch: 84 | Iteration number: [1910/4518] 42% | Training loss: 0.6871489948627212
Epoch: 84 | Iteration number: [1920/4518] 42% | Training loss: 0.6871471609609823
Epoch: 84 | Iteration number: [1930/4518] 42% | Training loss: 0.687140704251324
Epoch: 84 | Iteration number: [1940/4518] 42% | Training loss: 0.6871411596376872
Epoch: 84 | Iteration number: [1950/4518] 43% | Training loss: 0.6871367044937916
Epoch: 84 | Iteration number: [1960/4518] 43% | Training loss: 0.687134783730215
Epoch: 84 | Iteration number: [1970/4518] 43% | Training loss: 0.6871324100772741
Epoch: 84 | Iteration number: [1980/4518] 43% | Training loss: 0.6871330899722649
Epoch: 84 | Iteration number: [1990/4518] 44% | Training loss: 0.6871316829817978
Epoch: 84 | Iteration number: [2000/4518] 44% | Training loss: 0.6871298550963402
Epoch: 84 | Iteration number: [2010/4518] 44% | Training loss: 0.6871259577831819
Epoch: 84 | Iteration number: [2020/4518] 44% | Training loss: 0.687119906934181
Epoch: 84 | Iteration number: [2030/4518] 44% | Training loss: 0.6871097342427728
Epoch: 84 | Iteration number: [2040/4518] 45% | Training loss: 0.6871058098825754
Epoch: 84 | Iteration number: [2050/4518] 45% | Training loss: 0.6871148822656492
Epoch: 84 | Iteration number: [2060/4518] 45% | Training loss: 0.6871120534475568
Epoch: 84 | Iteration number: [2070/4518] 45% | Training loss: 0.6871138535835892
Epoch: 84 | Iteration number: [2080/4518] 46% | Training loss: 0.6871111038785714
Epoch: 84 | Iteration number: [2090/4518] 46% | Training loss: 0.6871097641983671
Epoch: 84 | Iteration number: [2100/4518] 46% | Training loss: 0.6871027662924358
Epoch: 84 | Iteration number: [2110/4518] 46% | Training loss: 0.6871059858685986
Epoch: 84 | Iteration number: [2120/4518] 46% | Training loss: 0.6871028200916525
Epoch: 84 | Iteration number: [2130/4518] 47% | Training loss: 0.6870972332540253
Epoch: 84 | Iteration number: [2140/4518] 47% | Training loss: 0.6870922667400859
Epoch: 84 | Iteration number: [2150/4518] 47% | Training loss: 0.6870947809829269
Epoch: 84 | Iteration number: [2160/4518] 47% | Training loss: 0.6870902009308338
Epoch: 84 | Iteration number: [2170/4518] 48% | Training loss: 0.6870892842793794
Epoch: 84 | Iteration number: [2180/4518] 48% | Training loss: 0.6870911339554218
Epoch: 84 | Iteration number: [2190/4518] 48% | Training loss: 0.6870898187160492
Epoch: 84 | Iteration number: [2200/4518] 48% | Training loss: 0.6870876089551232
Epoch: 84 | Iteration number: [2210/4518] 48% | Training loss: 0.6870848961275627
Epoch: 84 | Iteration number: [2220/4518] 49% | Training loss: 0.6870887083244753
Epoch: 84 | Iteration number: [2230/4518] 49% | Training loss: 0.687090081858528
Epoch: 84 | Iteration number: [2240/4518] 49% | Training loss: 0.6870895583714758
Epoch: 84 | Iteration number: [2250/4518] 49% | Training loss: 0.687087180905872
Epoch: 84 | Iteration number: [2260/4518] 50% | Training loss: 0.6870814687119121
Epoch: 84 | Iteration number: [2270/4518] 50% | Training loss: 0.687072555582954
Epoch: 84 | Iteration number: [2280/4518] 50% | Training loss: 0.687070424697901
Epoch: 84 | Iteration number: [2290/4518] 50% | Training loss: 0.6870642395779556
Epoch: 84 | Iteration number: [2300/4518] 50% | Training loss: 0.6870590231470439
Epoch: 84 | Iteration number: [2310/4518] 51% | Training loss: 0.6870573990530782
Epoch: 84 | Iteration number: [2320/4518] 51% | Training loss: 0.6870555848910891
Epoch: 84 | Iteration number: [2330/4518] 51% | Training loss: 0.6870567292614557
Epoch: 84 | Iteration number: [2340/4518] 51% | Training loss: 0.6870550201744096
Epoch: 84 | Iteration number: [2350/4518] 52% | Training loss: 0.6870555149494334
Epoch: 84 | Iteration number: [2360/4518] 52% | Training loss: 0.6870643844038753
Epoch: 84 | Iteration number: [2370/4518] 52% | Training loss: 0.687068062618312
Epoch: 84 | Iteration number: [2380/4518] 52% | Training loss: 0.6870684587654947
Epoch: 84 | Iteration number: [2390/4518] 52% | Training loss: 0.687066457510992
Epoch: 84 | Iteration number: [2400/4518] 53% | Training loss: 0.6870650680114826
Epoch: 84 | Iteration number: [2410/4518] 53% | Training loss: 0.6870655041759934
Epoch: 84 | Iteration number: [2420/4518] 53% | Training loss: 0.6870663793865314
Epoch: 84 | Iteration number: [2430/4518] 53% | Training loss: 0.6870652814706166
Epoch: 84 | Iteration number: [2440/4518] 54% | Training loss: 0.687066924596419
Epoch: 84 | Iteration number: [2450/4518] 54% | Training loss: 0.6870668439962426
Epoch: 84 | Iteration number: [2460/4518] 54% | Training loss: 0.6870648416561809
Epoch: 84 | Iteration number: [2470/4518] 54% | Training loss: 0.6870667729541841
Epoch: 84 | Iteration number: [2480/4518] 54% | Training loss: 0.6870605887905243
Epoch: 84 | Iteration number: [2490/4518] 55% | Training loss: 0.687057087483655
Epoch: 84 | Iteration number: [2500/4518] 55% | Training loss: 0.687050084233284
Epoch: 84 | Iteration number: [2510/4518] 55% | Training loss: 0.6870476954011803
Epoch: 84 | Iteration number: [2520/4518] 55% | Training loss: 0.687050187398517
Epoch: 84 | Iteration number: [2530/4518] 55% | Training loss: 0.687054095367198
Epoch: 84 | Iteration number: [2540/4518] 56% | Training loss: 0.6870502883055079
Epoch: 84 | Iteration number: [2550/4518] 56% | Training loss: 0.6870477249575596
Epoch: 84 | Iteration number: [2560/4518] 56% | Training loss: 0.6870506434002891
Epoch: 84 | Iteration number: [2570/4518] 56% | Training loss: 0.6870529091775649
Epoch: 84 | Iteration number: [2580/4518] 57% | Training loss: 0.6870512877092805
Epoch: 84 | Iteration number: [2590/4518] 57% | Training loss: 0.6870551968863572
Epoch: 84 | Iteration number: [2600/4518] 57% | Training loss: 0.6870475072585619
Epoch: 84 | Iteration number: [2610/4518] 57% | Training loss: 0.6870451643777533
Epoch: 84 | Iteration number: [2620/4518] 57% | Training loss: 0.6870494615713149
Epoch: 84 | Iteration number: [2630/4518] 58% | Training loss: 0.6870489966053474
Epoch: 84 | Iteration number: [2640/4518] 58% | Training loss: 0.6870476164375291
Epoch: 84 | Iteration number: [2650/4518] 58% | Training loss: 0.687041018234109
Epoch: 84 | Iteration number: [2660/4518] 58% | Training loss: 0.6870393578943453
Epoch: 84 | Iteration number: [2670/4518] 59% | Training loss: 0.6870391169290864
Epoch: 84 | Iteration number: [2680/4518] 59% | Training loss: 0.6870382492889219
Epoch: 84 | Iteration number: [2690/4518] 59% | Training loss: 0.6870368509930749
Epoch: 84 | Iteration number: [2700/4518] 59% | Training loss: 0.6870366428958045
Epoch: 84 | Iteration number: [2710/4518] 59% | Training loss: 0.6870340496631566
Epoch: 84 | Iteration number: [2720/4518] 60% | Training loss: 0.6870368625968695
Epoch: 84 | Iteration number: [2730/4518] 60% | Training loss: 0.6870352594843714
Epoch: 84 | Iteration number: [2740/4518] 60% | Training loss: 0.6870350168134174
Epoch: 84 | Iteration number: [2750/4518] 60% | Training loss: 0.6870302094546231
Epoch: 84 | Iteration number: [2760/4518] 61% | Training loss: 0.6870313637498496
Epoch: 84 | Iteration number: [2770/4518] 61% | Training loss: 0.687029431959352
Epoch: 84 | Iteration number: [2780/4518] 61% | Training loss: 0.6870257815225519
Epoch: 84 | Iteration number: [2790/4518] 61% | Training loss: 0.6870236909944951
Epoch: 84 | Iteration number: [2800/4518] 61% | Training loss: 0.6870244129853589
Epoch: 84 | Iteration number: [2810/4518] 62% | Training loss: 0.6870230856527213
Epoch: 84 | Iteration number: [2820/4518] 62% | Training loss: 0.6870235228369422
Epoch: 84 | Iteration number: [2830/4518] 62% | Training loss: 0.6870278902062258
Epoch: 84 | Iteration number: [2840/4518] 62% | Training loss: 0.6870288560298127
Epoch: 84 | Iteration number: [2850/4518] 63% | Training loss: 0.6870282967048779
Epoch: 84 | Iteration number: [2860/4518] 63% | Training loss: 0.6870262348568523
Epoch: 84 | Iteration number: [2870/4518] 63% | Training loss: 0.6870292139177954
Epoch: 84 | Iteration number: [2880/4518] 63% | Training loss: 0.6870273888111115
Epoch: 84 | Iteration number: [2890/4518] 63% | Training loss: 0.6870243909449726
Epoch: 84 | Iteration number: [2900/4518] 64% | Training loss: 0.6870269088909544
Epoch: 84 | Iteration number: [2910/4518] 64% | Training loss: 0.6870209324400859
Epoch: 84 | Iteration number: [2920/4518] 64% | Training loss: 0.6870159059354704
Epoch: 84 | Iteration number: [2930/4518] 64% | Training loss: 0.6870145609761261
Epoch: 84 | Iteration number: [2940/4518] 65% | Training loss: 0.6870120559419904
Epoch: 84 | Iteration number: [2950/4518] 65% | Training loss: 0.6870107637825659
Epoch: 84 | Iteration number: [2960/4518] 65% | Training loss: 0.6870123610303208
Epoch: 84 | Iteration number: [2970/4518] 65% | Training loss: 0.6870116624165866
Epoch: 84 | Iteration number: [2980/4518] 65% | Training loss: 0.6870112474932767
Epoch: 84 | Iteration number: [2990/4518] 66% | Training loss: 0.687007435348919
Epoch: 84 | Iteration number: [3000/4518] 66% | Training loss: 0.687001146376133
Epoch: 84 | Iteration number: [3010/4518] 66% | Training loss: 0.6870049344938854
Epoch: 84 | Iteration number: [3020/4518] 66% | Training loss: 0.6869995574682753
Epoch: 84 | Iteration number: [3030/4518] 67% | Training loss: 0.6869960557312855
Epoch: 84 | Iteration number: [3040/4518] 67% | Training loss: 0.6869931188461028
Epoch: 84 | Iteration number: [3050/4518] 67% | Training loss: 0.6869913189332993
Epoch: 84 | Iteration number: [3060/4518] 67% | Training loss: 0.686985645516246
Epoch: 84 | Iteration number: [3070/4518] 67% | Training loss: 0.6869852889244253
Epoch: 84 | Iteration number: [3080/4518] 68% | Training loss: 0.6869878310661811
Epoch: 84 | Iteration number: [3090/4518] 68% | Training loss: 0.6869864065477378
Epoch: 84 | Iteration number: [3100/4518] 68% | Training loss: 0.6869832392469529
Epoch: 84 | Iteration number: [3110/4518] 68% | Training loss: 0.6869814763306805
Epoch: 84 | Iteration number: [3120/4518] 69% | Training loss: 0.6869812940366757
Epoch: 84 | Iteration number: [3130/4518] 69% | Training loss: 0.6869814299737302
Epoch: 84 | Iteration number: [3140/4518] 69% | Training loss: 0.6869844962457183
Epoch: 84 | Iteration number: [3150/4518] 69% | Training loss: 0.6869859193241785
Epoch: 84 | Iteration number: [3160/4518] 69% | Training loss: 0.6869873388092729
Epoch: 84 | Iteration number: [3170/4518] 70% | Training loss: 0.6869840579266052
Epoch: 84 | Iteration number: [3180/4518] 70% | Training loss: 0.6869820399666732
Epoch: 84 | Iteration number: [3190/4518] 70% | Training loss: 0.6869766089049253
Epoch: 84 | Iteration number: [3200/4518] 70% | Training loss: 0.6869785125739872
Epoch: 84 | Iteration number: [3210/4518] 71% | Training loss: 0.6869771252354357
Epoch: 84 | Iteration number: [3220/4518] 71% | Training loss: 0.6869701569494994
Epoch: 84 | Iteration number: [3230/4518] 71% | Training loss: 0.6869694373371431
Epoch: 84 | Iteration number: [3240/4518] 71% | Training loss: 0.6869674989286764
Epoch: 84 | Iteration number: [3250/4518] 71% | Training loss: 0.6869686596210186
Epoch: 84 | Iteration number: [3260/4518] 72% | Training loss: 0.6869675072789924
Epoch: 84 | Iteration number: [3270/4518] 72% | Training loss: 0.6869678748674714
Epoch: 84 | Iteration number: [3280/4518] 72% | Training loss: 0.68696662421997
Epoch: 84 | Iteration number: [3290/4518] 72% | Training loss: 0.6869665356030218
Epoch: 84 | Iteration number: [3300/4518] 73% | Training loss: 0.6869671130722219
Epoch: 84 | Iteration number: [3310/4518] 73% | Training loss: 0.6869676217751921
Epoch: 84 | Iteration number: [3320/4518] 73% | Training loss: 0.6869640626462109
Epoch: 84 | Iteration number: [3330/4518] 73% | Training loss: 0.6869642921575196
Epoch: 84 | Iteration number: [3340/4518] 73% | Training loss: 0.6869618418509374
Epoch: 84 | Iteration number: [3350/4518] 74% | Training loss: 0.6869630236945935
Epoch: 84 | Iteration number: [3360/4518] 74% | Training loss: 0.6869619940008436
Epoch: 84 | Iteration number: [3370/4518] 74% | Training loss: 0.6869563082559172
Epoch: 84 | Iteration number: [3380/4518] 74% | Training loss: 0.6869543166026562
Epoch: 84 | Iteration number: [3390/4518] 75% | Training loss: 0.6869544013939073
Epoch: 84 | Iteration number: [3400/4518] 75% | Training loss: 0.6869553909406942
Epoch: 84 | Iteration number: [3410/4518] 75% | Training loss: 0.6869552508826829
Epoch: 84 | Iteration number: [3420/4518] 75% | Training loss: 0.6869533938448331
Epoch: 84 | Iteration number: [3430/4518] 75% | Training loss: 0.6869514376533274
Epoch: 84 | Iteration number: [3440/4518] 76% | Training loss: 0.6869505358989849
Epoch: 84 | Iteration number: [3450/4518] 76% | Training loss: 0.686949964588967
Epoch: 84 | Iteration number: [3460/4518] 76% | Training loss: 0.6869517921023286
Epoch: 84 | Iteration number: [3470/4518] 76% | Training loss: 0.6869487495175013
Epoch: 84 | Iteration number: [3480/4518] 77% | Training loss: 0.6869459077887151
Epoch: 84 | Iteration number: [3490/4518] 77% | Training loss: 0.68694776867044
Epoch: 84 | Iteration number: [3500/4518] 77% | Training loss: 0.6869434633765902
Epoch: 84 | Iteration number: [3510/4518] 77% | Training loss: 0.6869407636827214
Epoch: 84 | Iteration number: [3520/4518] 77% | Training loss: 0.6869379743425683
Epoch: 84 | Iteration number: [3530/4518] 78% | Training loss: 0.6869404053215264
Epoch: 84 | Iteration number: [3540/4518] 78% | Training loss: 0.6869406590522346
Epoch: 84 | Iteration number: [3550/4518] 78% | Training loss: 0.6869397091697639
Epoch: 84 | Iteration number: [3560/4518] 78% | Training loss: 0.6869427337070529
Epoch: 84 | Iteration number: [3570/4518] 79% | Training loss: 0.6869432539499106
Epoch: 84 | Iteration number: [3580/4518] 79% | Training loss: 0.6869466269648941
Epoch: 84 | Iteration number: [3590/4518] 79% | Training loss: 0.686950089556261
Epoch: 84 | Iteration number: [3600/4518] 79% | Training loss: 0.6869498351381884
Epoch: 84 | Iteration number: [3610/4518] 79% | Training loss: 0.6869455667578943
Epoch: 84 | Iteration number: [3620/4518] 80% | Training loss: 0.6869430758676476
Epoch: 84 | Iteration number: [3630/4518] 80% | Training loss: 0.6869449333875304
Epoch: 84 | Iteration number: [3640/4518] 80% | Training loss: 0.6869452798759544
Epoch: 84 | Iteration number: [3650/4518] 80% | Training loss: 0.6869463199948611
Epoch: 84 | Iteration number: [3660/4518] 81% | Training loss: 0.6869480276856917
Epoch: 84 | Iteration number: [3670/4518] 81% | Training loss: 0.6869505042438611
Epoch: 84 | Iteration number: [3680/4518] 81% | Training loss: 0.6869482180670552
Epoch: 84 | Iteration number: [3690/4518] 81% | Training loss: 0.6869506763087379
Epoch: 84 | Iteration number: [3700/4518] 81% | Training loss: 0.6869517803353232
Epoch: 84 | Iteration number: [3710/4518] 82% | Training loss: 0.6869473161723093
Epoch: 84 | Iteration number: [3720/4518] 82% | Training loss: 0.6869464229992641
Epoch: 84 | Iteration number: [3730/4518] 82% | Training loss: 0.6869429600622315
Epoch: 84 | Iteration number: [3740/4518] 82% | Training loss: 0.6869423985321892
Epoch: 84 | Iteration number: [3750/4518] 83% | Training loss: 0.6869447758197784
Epoch: 84 | Iteration number: [3760/4518] 83% | Training loss: 0.6869433641750762
Epoch: 84 | Iteration number: [3770/4518] 83% | Training loss: 0.6869414992610718
Epoch: 84 | Iteration number: [3780/4518] 83% | Training loss: 0.68694350418275
Epoch: 84 | Iteration number: [3790/4518] 83% | Training loss: 0.6869426907052465
Epoch: 84 | Iteration number: [3800/4518] 84% | Training loss: 0.6869439280817383
Epoch: 84 | Iteration number: [3810/4518] 84% | Training loss: 0.6869472324691732
Epoch: 84 | Iteration number: [3820/4518] 84% | Training loss: 0.686946393510434
Epoch: 84 | Iteration number: [3830/4518] 84% | Training loss: 0.686946921840349
Epoch: 84 | Iteration number: [3840/4518] 84% | Training loss: 0.6869465390685946
Epoch: 84 | Iteration number: [3850/4518] 85% | Training loss: 0.6869432750150755
Epoch: 84 | Iteration number: [3860/4518] 85% | Training loss: 0.686940925031746
Epoch: 84 | Iteration number: [3870/4518] 85% | Training loss: 0.686941208888702
Epoch: 84 | Iteration number: [3880/4518] 85% | Training loss: 0.6869400233798421
Epoch: 84 | Iteration number: [3890/4518] 86% | Training loss: 0.6869336850845416
Epoch: 84 | Iteration number: [3900/4518] 86% | Training loss: 0.6869364723028281
Epoch: 84 | Iteration number: [3910/4518] 86% | Training loss: 0.6869383789236894
Epoch: 84 | Iteration number: [3920/4518] 86% | Training loss: 0.6869368681342017
Epoch: 84 | Iteration number: [3930/4518] 86% | Training loss: 0.6869354107301047
Epoch: 84 | Iteration number: [3940/4518] 87% | Training loss: 0.6869354682525403
Epoch: 84 | Iteration number: [3950/4518] 87% | Training loss: 0.6869372444665884
Epoch: 84 | Iteration number: [3960/4518] 87% | Training loss: 0.686936195345238
Epoch: 84 | Iteration number: [3970/4518] 87% | Training loss: 0.6869358470067569
Epoch: 84 | Iteration number: [3980/4518] 88% | Training loss: 0.6869386296475952
Epoch: 84 | Iteration number: [3990/4518] 88% | Training loss: 0.6869380734618147
Epoch: 84 | Iteration number: [4000/4518] 88% | Training loss: 0.6869351820647717
Epoch: 84 | Iteration number: [4010/4518] 88% | Training loss: 0.6869361822593242
Epoch: 84 | Iteration number: [4020/4518] 88% | Training loss: 0.686935891574295
Epoch: 84 | Iteration number: [4030/4518] 89% | Training loss: 0.6869360548095135
Epoch: 84 | Iteration number: [4040/4518] 89% | Training loss: 0.6869378379961052
Epoch: 84 | Iteration number: [4050/4518] 89% | Training loss: 0.6869375923680671
Epoch: 84 | Iteration number: [4060/4518] 89% | Training loss: 0.6869366826682255
Epoch: 84 | Iteration number: [4070/4518] 90% | Training loss: 0.6869358892522808
Epoch: 84 | Iteration number: [4080/4518] 90% | Training loss: 0.6869360695428708
Epoch: 84 | Iteration number: [4090/4518] 90% | Training loss: 0.6869365266890864
Epoch: 84 | Iteration number: [4100/4518] 90% | Training loss: 0.6869318749991858
Epoch: 84 | Iteration number: [4110/4518] 90% | Training loss: 0.6869322802463588
Epoch: 84 | Iteration number: [4120/4518] 91% | Training loss: 0.6869301955676773
Epoch: 84 | Iteration number: [4130/4518] 91% | Training loss: 0.6869265394984377
Epoch: 84 | Iteration number: [4140/4518] 91% | Training loss: 0.6869280032921529
Epoch: 84 | Iteration number: [4150/4518] 91% | Training loss: 0.6869268316964069
Epoch: 84 | Iteration number: [4160/4518] 92% | Training loss: 0.6869299904228403
Epoch: 84 | Iteration number: [4170/4518] 92% | Training loss: 0.6869285112519344
Epoch: 84 | Iteration number: [4180/4518] 92% | Training loss: 0.6869248710465773
Epoch: 84 | Iteration number: [4190/4518] 92% | Training loss: 0.6869268954653729
Epoch: 84 | Iteration number: [4200/4518] 92% | Training loss: 0.6869256316622099
Epoch: 84 | Iteration number: [4210/4518] 93% | Training loss: 0.6869262032157735
Epoch: 84 | Iteration number: [4220/4518] 93% | Training loss: 0.6869255148404018
Epoch: 84 | Iteration number: [4230/4518] 93% | Training loss: 0.6869245134769602
Epoch: 84 | Iteration number: [4240/4518] 93% | Training loss: 0.6869246401595619
Epoch: 84 | Iteration number: [4250/4518] 94% | Training loss: 0.6869240443005281
Epoch: 84 | Iteration number: [4260/4518] 94% | Training loss: 0.6869269021240199
Epoch: 84 | Iteration number: [4270/4518] 94% | Training loss: 0.6869251190638933
Epoch: 84 | Iteration number: [4280/4518] 94% | Training loss: 0.6869240913853467
Epoch: 84 | Iteration number: [4290/4518] 94% | Training loss: 0.6869235961031525
Epoch: 84 | Iteration number: [4300/4518] 95% | Training loss: 0.6869253410156383
Epoch: 84 | Iteration number: [4310/4518] 95% | Training loss: 0.6869254491721948
Epoch: 84 | Iteration number: [4320/4518] 95% | Training loss: 0.6869233257516667
Epoch: 84 | Iteration number: [4330/4518] 95% | Training loss: 0.6869247474516237
Epoch: 84 | Iteration number: [4340/4518] 96% | Training loss: 0.6869256596411428
Epoch: 84 | Iteration number: [4350/4518] 96% | Training loss: 0.686923641761144
Epoch: 84 | Iteration number: [4360/4518] 96% | Training loss: 0.6869256343863426
Epoch: 84 | Iteration number: [4370/4518] 96% | Training loss: 0.6869263686086275
Epoch: 84 | Iteration number: [4380/4518] 96% | Training loss: 0.6869220454126732
Epoch: 84 | Iteration number: [4390/4518] 97% | Training loss: 0.6869222961824413
Epoch: 84 | Iteration number: [4400/4518] 97% | Training loss: 0.6869178984381936
Epoch: 84 | Iteration number: [4410/4518] 97% | Training loss: 0.6869172288582168
Epoch: 84 | Iteration number: [4420/4518] 97% | Training loss: 0.6869146697122047
Epoch: 84 | Iteration number: [4430/4518] 98% | Training loss: 0.6869128293027728
Epoch: 84 | Iteration number: [4440/4518] 98% | Training loss: 0.6869133781339671
Epoch: 84 | Iteration number: [4450/4518] 98% | Training loss: 0.6869121916508407
Epoch: 84 | Iteration number: [4460/4518] 98% | Training loss: 0.6869129050606569
Epoch: 84 | Iteration number: [4470/4518] 98% | Training loss: 0.6869139176487122
Epoch: 84 | Iteration number: [4480/4518] 99% | Training loss: 0.6869163035947298
Epoch: 84 | Iteration number: [4490/4518] 99% | Training loss: 0.6869125135890094
Epoch: 84 | Iteration number: [4500/4518] 99% | Training loss: 0.6869081074661679
Epoch: 84 | Iteration number: [4510/4518] 99% | Training loss: 0.686910411048094

 End of epoch: 84 | Train Loss: 0.6867581484010653 | Training Time: 641 

 End of epoch: 84 | Eval Loss: 0.6897813385846664 | Evaluating Time: 17 
Epoch: 85 | Iteration number: [10/4518] 0% | Training loss: 0.7542046844959259
Epoch: 85 | Iteration number: [20/4518] 0% | Training loss: 0.7204929679632187
Epoch: 85 | Iteration number: [30/4518] 0% | Training loss: 0.7096429487069448
Epoch: 85 | Iteration number: [40/4518] 0% | Training loss: 0.703791220486164
Epoch: 85 | Iteration number: [50/4518] 1% | Training loss: 0.7002975726127625
Epoch: 85 | Iteration number: [60/4518] 1% | Training loss: 0.6982847183942795
Epoch: 85 | Iteration number: [70/4518] 1% | Training loss: 0.6968044161796569
Epoch: 85 | Iteration number: [80/4518] 1% | Training loss: 0.6955922566354275
Epoch: 85 | Iteration number: [90/4518] 1% | Training loss: 0.6945858445432451
Epoch: 85 | Iteration number: [100/4518] 2% | Training loss: 0.6938792872428894
Epoch: 85 | Iteration number: [110/4518] 2% | Training loss: 0.6932862140915611
Epoch: 85 | Iteration number: [120/4518] 2% | Training loss: 0.6928311437368393
Epoch: 85 | Iteration number: [130/4518] 2% | Training loss: 0.6924477783533243
Epoch: 85 | Iteration number: [140/4518] 3% | Training loss: 0.6920203523976463
Epoch: 85 | Iteration number: [150/4518] 3% | Training loss: 0.6916191287835439
Epoch: 85 | Iteration number: [160/4518] 3% | Training loss: 0.6912834126502275
Epoch: 85 | Iteration number: [170/4518] 3% | Training loss: 0.691019359406303
Epoch: 85 | Iteration number: [180/4518] 3% | Training loss: 0.6908782809972763
Epoch: 85 | Iteration number: [190/4518] 4% | Training loss: 0.6906120369308874
Epoch: 85 | Iteration number: [200/4518] 4% | Training loss: 0.6904335889220238
Epoch: 85 | Iteration number: [210/4518] 4% | Training loss: 0.6902685906205859
Epoch: 85 | Iteration number: [220/4518] 4% | Training loss: 0.6901519415053454
Epoch: 85 | Iteration number: [230/4518] 5% | Training loss: 0.6899475527846295
Epoch: 85 | Iteration number: [240/4518] 5% | Training loss: 0.6897789135575294
Epoch: 85 | Iteration number: [250/4518] 5% | Training loss: 0.6896495740413666
Epoch: 85 | Iteration number: [260/4518] 5% | Training loss: 0.6895134510902258
Epoch: 85 | Iteration number: [270/4518] 5% | Training loss: 0.6893980216096949
Epoch: 85 | Iteration number: [280/4518] 6% | Training loss: 0.689270322237696
Epoch: 85 | Iteration number: [290/4518] 6% | Training loss: 0.689156309284013
Epoch: 85 | Iteration number: [300/4518] 6% | Training loss: 0.689058427810669
Epoch: 85 | Iteration number: [310/4518] 6% | Training loss: 0.6889455783751703
Epoch: 85 | Iteration number: [320/4518] 7% | Training loss: 0.6888711763545871
Epoch: 85 | Iteration number: [330/4518] 7% | Training loss: 0.6887710898211508
Epoch: 85 | Iteration number: [340/4518] 7% | Training loss: 0.6887032889267978
Epoch: 85 | Iteration number: [350/4518] 7% | Training loss: 0.6886170760222844
Epoch: 85 | Iteration number: [360/4518] 7% | Training loss: 0.6885999004046123
Epoch: 85 | Iteration number: [370/4518] 8% | Training loss: 0.6885484482790972
Epoch: 85 | Iteration number: [380/4518] 8% | Training loss: 0.6884886628703067
Epoch: 85 | Iteration number: [390/4518] 8% | Training loss: 0.6884517785830375
Epoch: 85 | Iteration number: [400/4518] 8% | Training loss: 0.6884372913837433
Epoch: 85 | Iteration number: [410/4518] 9% | Training loss: 0.6883815108275995
Epoch: 85 | Iteration number: [420/4518] 9% | Training loss: 0.6883134311153776
Epoch: 85 | Iteration number: [430/4518] 9% | Training loss: 0.6882596067217893
Epoch: 85 | Iteration number: [440/4518] 9% | Training loss: 0.6882014494050633
Epoch: 85 | Iteration number: [450/4518] 9% | Training loss: 0.6881681679354774
Epoch: 85 | Iteration number: [460/4518] 10% | Training loss: 0.6881291966075482
Epoch: 85 | Iteration number: [470/4518] 10% | Training loss: 0.6881076311811488
Epoch: 85 | Iteration number: [480/4518] 10% | Training loss: 0.6880971784392993
Epoch: 85 | Iteration number: [490/4518] 10% | Training loss: 0.6880825406434584
Epoch: 85 | Iteration number: [500/4518] 11% | Training loss: 0.688057344198227
Epoch: 85 | Iteration number: [510/4518] 11% | Training loss: 0.6880145159422183
Epoch: 85 | Iteration number: [520/4518] 11% | Training loss: 0.6880228706277334
Epoch: 85 | Iteration number: [530/4518] 11% | Training loss: 0.6879795659263179
Epoch: 85 | Iteration number: [540/4518] 11% | Training loss: 0.68794099147673
Epoch: 85 | Iteration number: [550/4518] 12% | Training loss: 0.6879362321983684
Epoch: 85 | Iteration number: [560/4518] 12% | Training loss: 0.6879237301647663
Epoch: 85 | Iteration number: [570/4518] 12% | Training loss: 0.687885743588732
Epoch: 85 | Iteration number: [580/4518] 12% | Training loss: 0.6878817511015924
Epoch: 85 | Iteration number: [590/4518] 13% | Training loss: 0.6878718258970875
Epoch: 85 | Iteration number: [600/4518] 13% | Training loss: 0.6878305483857791
Epoch: 85 | Iteration number: [610/4518] 13% | Training loss: 0.6878357900947821
Epoch: 85 | Iteration number: [620/4518] 13% | Training loss: 0.6878282368183136
Epoch: 85 | Iteration number: [630/4518] 13% | Training loss: 0.6878139759813037
Epoch: 85 | Iteration number: [640/4518] 14% | Training loss: 0.6877619932405651
Epoch: 85 | Iteration number: [650/4518] 14% | Training loss: 0.6877497958219968
Epoch: 85 | Iteration number: [660/4518] 14% | Training loss: 0.6877345741698236
Epoch: 85 | Iteration number: [670/4518] 14% | Training loss: 0.6877204191328874
Epoch: 85 | Iteration number: [680/4518] 15% | Training loss: 0.6877049958004671
Epoch: 85 | Iteration number: [690/4518] 15% | Training loss: 0.6876894008422243
Epoch: 85 | Iteration number: [700/4518] 15% | Training loss: 0.6876627244268145
Epoch: 85 | Iteration number: [710/4518] 15% | Training loss: 0.6876390504165435
Epoch: 85 | Iteration number: [720/4518] 15% | Training loss: 0.6876267298228211
Epoch: 85 | Iteration number: [730/4518] 16% | Training loss: 0.6876215822076144
Epoch: 85 | Iteration number: [740/4518] 16% | Training loss: 0.6875988053308951
Epoch: 85 | Iteration number: [750/4518] 16% | Training loss: 0.6876024412314097
Epoch: 85 | Iteration number: [760/4518] 16% | Training loss: 0.6875982799812367
Epoch: 85 | Iteration number: [770/4518] 17% | Training loss: 0.6875722478736531
Epoch: 85 | Iteration number: [780/4518] 17% | Training loss: 0.6875582440541341
Epoch: 85 | Iteration number: [790/4518] 17% | Training loss: 0.6875612101222895
Epoch: 85 | Iteration number: [800/4518] 17% | Training loss: 0.6875537869334221
Epoch: 85 | Iteration number: [810/4518] 17% | Training loss: 0.6875518923188433
Epoch: 85 | Iteration number: [820/4518] 18% | Training loss: 0.6875400271357559
Epoch: 85 | Iteration number: [830/4518] 18% | Training loss: 0.687543325036405
Epoch: 85 | Iteration number: [840/4518] 18% | Training loss: 0.6875308199297814
Epoch: 85 | Iteration number: [850/4518] 18% | Training loss: 0.687514766033958
Epoch: 85 | Iteration number: [860/4518] 19% | Training loss: 0.6875175437261892
Epoch: 85 | Iteration number: [870/4518] 19% | Training loss: 0.687531799352032
Epoch: 85 | Iteration number: [880/4518] 19% | Training loss: 0.6875155511904847
Epoch: 85 | Iteration number: [890/4518] 19% | Training loss: 0.6875196136115642
Epoch: 85 | Iteration number: [900/4518] 19% | Training loss: 0.6875118786096572
Epoch: 85 | Iteration number: [910/4518] 20% | Training loss: 0.6875083924649836
Epoch: 85 | Iteration number: [920/4518] 20% | Training loss: 0.6874956778210143
Epoch: 85 | Iteration number: [930/4518] 20% | Training loss: 0.6874956446309244
Epoch: 85 | Iteration number: [940/4518] 20% | Training loss: 0.6874965288537613
Epoch: 85 | Iteration number: [950/4518] 21% | Training loss: 0.6874950015544892
Epoch: 85 | Iteration number: [960/4518] 21% | Training loss: 0.6874832738190889
Epoch: 85 | Iteration number: [970/4518] 21% | Training loss: 0.6874807492973878
Epoch: 85 | Iteration number: [980/4518] 21% | Training loss: 0.6874686638311464
Epoch: 85 | Iteration number: [990/4518] 21% | Training loss: 0.6874578739657546
Epoch: 85 | Iteration number: [1000/4518] 22% | Training loss: 0.6874525581598282
Epoch: 85 | Iteration number: [1010/4518] 22% | Training loss: 0.6874440504182683
Epoch: 85 | Iteration number: [1020/4518] 22% | Training loss: 0.687437938767321
Epoch: 85 | Iteration number: [1030/4518] 22% | Training loss: 0.6874507161020075
Epoch: 85 | Iteration number: [1040/4518] 23% | Training loss: 0.6874559092407043
Epoch: 85 | Iteration number: [1050/4518] 23% | Training loss: 0.687462363583701
Epoch: 85 | Iteration number: [1060/4518] 23% | Training loss: 0.6874680431946268
Epoch: 85 | Iteration number: [1070/4518] 23% | Training loss: 0.6874622617926553
Epoch: 85 | Iteration number: [1080/4518] 23% | Training loss: 0.6874614731581122
Epoch: 85 | Iteration number: [1090/4518] 24% | Training loss: 0.6874498550498157
Epoch: 85 | Iteration number: [1100/4518] 24% | Training loss: 0.6874373017116027
Epoch: 85 | Iteration number: [1110/4518] 24% | Training loss: 0.687438174518379
Epoch: 85 | Iteration number: [1120/4518] 24% | Training loss: 0.6874231960092272
Epoch: 85 | Iteration number: [1130/4518] 25% | Training loss: 0.687426584378808
Epoch: 85 | Iteration number: [1140/4518] 25% | Training loss: 0.6874147195565073
Epoch: 85 | Iteration number: [1150/4518] 25% | Training loss: 0.6874005331682123
Epoch: 85 | Iteration number: [1160/4518] 25% | Training loss: 0.6873908787451941
Epoch: 85 | Iteration number: [1170/4518] 25% | Training loss: 0.6873838618779794
Epoch: 85 | Iteration number: [1180/4518] 26% | Training loss: 0.6873758311999046
Epoch: 85 | Iteration number: [1190/4518] 26% | Training loss: 0.687374972595888
Epoch: 85 | Iteration number: [1200/4518] 26% | Training loss: 0.6873794158796469
Epoch: 85 | Iteration number: [1210/4518] 26% | Training loss: 0.6873735993854271
Epoch: 85 | Iteration number: [1220/4518] 27% | Training loss: 0.6873588074426182
Epoch: 85 | Iteration number: [1230/4518] 27% | Training loss: 0.6873538452435315
Epoch: 85 | Iteration number: [1240/4518] 27% | Training loss: 0.687341685929606
Epoch: 85 | Iteration number: [1250/4518] 27% | Training loss: 0.6873339015483856
Epoch: 85 | Iteration number: [1260/4518] 27% | Training loss: 0.6873203867484653
Epoch: 85 | Iteration number: [1270/4518] 28% | Training loss: 0.6873268408568826
Epoch: 85 | Iteration number: [1280/4518] 28% | Training loss: 0.6873254326637834
Epoch: 85 | Iteration number: [1290/4518] 28% | Training loss: 0.6873182602168978
Epoch: 85 | Iteration number: [1300/4518] 28% | Training loss: 0.6873213638250645
Epoch: 85 | Iteration number: [1310/4518] 28% | Training loss: 0.6873256251557183
Epoch: 85 | Iteration number: [1320/4518] 29% | Training loss: 0.6873293455351482
Epoch: 85 | Iteration number: [1330/4518] 29% | Training loss: 0.6873310329770683
Epoch: 85 | Iteration number: [1340/4518] 29% | Training loss: 0.6873180636719092
Epoch: 85 | Iteration number: [1350/4518] 29% | Training loss: 0.687310871415668
Epoch: 85 | Iteration number: [1360/4518] 30% | Training loss: 0.6873087414923836
Epoch: 85 | Iteration number: [1370/4518] 30% | Training loss: 0.6873022603727605
Epoch: 85 | Iteration number: [1380/4518] 30% | Training loss: 0.6873039538013762
Epoch: 85 | Iteration number: [1390/4518] 30% | Training loss: 0.687299100872424
Epoch: 85 | Iteration number: [1400/4518] 30% | Training loss: 0.6872993004747799
Epoch: 85 | Iteration number: [1410/4518] 31% | Training loss: 0.6872866113980611
Epoch: 85 | Iteration number: [1420/4518] 31% | Training loss: 0.687275255607887
Epoch: 85 | Iteration number: [1430/4518] 31% | Training loss: 0.6872762415792558
Epoch: 85 | Iteration number: [1440/4518] 31% | Training loss: 0.6872750139898725
Epoch: 85 | Iteration number: [1450/4518] 32% | Training loss: 0.687276986960707
Epoch: 85 | Iteration number: [1460/4518] 32% | Training loss: 0.6872795457709325
Epoch: 85 | Iteration number: [1470/4518] 32% | Training loss: 0.6872772608079067
Epoch: 85 | Iteration number: [1480/4518] 32% | Training loss: 0.6872696048907332
Epoch: 85 | Iteration number: [1490/4518] 32% | Training loss: 0.6872594014510213
Epoch: 85 | Iteration number: [1500/4518] 33% | Training loss: 0.6872564296722412
Epoch: 85 | Iteration number: [1510/4518] 33% | Training loss: 0.6872596283227402
Epoch: 85 | Iteration number: [1520/4518] 33% | Training loss: 0.687260222199716
Epoch: 85 | Iteration number: [1530/4518] 33% | Training loss: 0.687251047137516
Epoch: 85 | Iteration number: [1540/4518] 34% | Training loss: 0.6872577119570273
Epoch: 85 | Iteration number: [1550/4518] 34% | Training loss: 0.687263131295481
Epoch: 85 | Iteration number: [1560/4518] 34% | Training loss: 0.6872584226803902
Epoch: 85 | Iteration number: [1570/4518] 34% | Training loss: 0.6872530082228837
Epoch: 85 | Iteration number: [1580/4518] 34% | Training loss: 0.6872389187541189
Epoch: 85 | Iteration number: [1590/4518] 35% | Training loss: 0.687228687341858
Epoch: 85 | Iteration number: [1600/4518] 35% | Training loss: 0.6872290997579694
Epoch: 85 | Iteration number: [1610/4518] 35% | Training loss: 0.6872238477934962
Epoch: 85 | Iteration number: [1620/4518] 35% | Training loss: 0.6872249764424784
Epoch: 85 | Iteration number: [1630/4518] 36% | Training loss: 0.6872264467865411
Epoch: 85 | Iteration number: [1640/4518] 36% | Training loss: 0.6872272165810189
Epoch: 85 | Iteration number: [1650/4518] 36% | Training loss: 0.687223156004241
Epoch: 85 | Iteration number: [1660/4518] 36% | Training loss: 0.6872274249073971
Epoch: 85 | Iteration number: [1670/4518] 36% | Training loss: 0.6872299760044692
Epoch: 85 | Iteration number: [1680/4518] 37% | Training loss: 0.687228049302385
Epoch: 85 | Iteration number: [1690/4518] 37% | Training loss: 0.6872259202793505
Epoch: 85 | Iteration number: [1700/4518] 37% | Training loss: 0.6872296848717858
Epoch: 85 | Iteration number: [1710/4518] 37% | Training loss: 0.6872196381900743
Epoch: 85 | Iteration number: [1720/4518] 38% | Training loss: 0.6872118240872095
Epoch: 85 | Iteration number: [1730/4518] 38% | Training loss: 0.6872103971897522
Epoch: 85 | Iteration number: [1740/4518] 38% | Training loss: 0.6872051257511665
Epoch: 85 | Iteration number: [1750/4518] 38% | Training loss: 0.6872052305085319
Epoch: 85 | Iteration number: [1760/4518] 38% | Training loss: 0.687204029106281
Epoch: 85 | Iteration number: [1770/4518] 39% | Training loss: 0.6872029058677328
Epoch: 85 | Iteration number: [1780/4518] 39% | Training loss: 0.6872037497129333
Epoch: 85 | Iteration number: [1790/4518] 39% | Training loss: 0.687205731535757
Epoch: 85 | Iteration number: [1800/4518] 39% | Training loss: 0.6872018385264609
Epoch: 85 | Iteration number: [1810/4518] 40% | Training loss: 0.6872012260210448
Epoch: 85 | Iteration number: [1820/4518] 40% | Training loss: 0.6872080422364748
Epoch: 85 | Iteration number: [1830/4518] 40% | Training loss: 0.6872072472924092
Epoch: 85 | Iteration number: [1840/4518] 40% | Training loss: 0.6872025207332942
Epoch: 85 | Iteration number: [1850/4518] 40% | Training loss: 0.6871961305592511
Epoch: 85 | Iteration number: [1860/4518] 41% | Training loss: 0.687200126820995
Epoch: 85 | Iteration number: [1870/4518] 41% | Training loss: 0.6872028080218616
Epoch: 85 | Iteration number: [1880/4518] 41% | Training loss: 0.6872029877406486
Epoch: 85 | Iteration number: [1890/4518] 41% | Training loss: 0.6871956250970326
Epoch: 85 | Iteration number: [1900/4518] 42% | Training loss: 0.6871935775091773
Epoch: 85 | Iteration number: [1910/4518] 42% | Training loss: 0.6871953894954701
Epoch: 85 | Iteration number: [1920/4518] 42% | Training loss: 0.6871973555845519
Epoch: 85 | Iteration number: [1930/4518] 42% | Training loss: 0.6871948552872851
Epoch: 85 | Iteration number: [1940/4518] 42% | Training loss: 0.6871910596323997
Epoch: 85 | Iteration number: [1950/4518] 43% | Training loss: 0.6871837730591114
Epoch: 85 | Iteration number: [1960/4518] 43% | Training loss: 0.6871915565157424
Epoch: 85 | Iteration number: [1970/4518] 43% | Training loss: 0.6871938637670527
Epoch: 85 | Iteration number: [1980/4518] 43% | Training loss: 0.6871926778795743
Epoch: 85 | Iteration number: [1990/4518] 44% | Training loss: 0.6871919314166409
Epoch: 85 | Iteration number: [2000/4518] 44% | Training loss: 0.6871946036815644
Epoch: 85 | Iteration number: [2010/4518] 44% | Training loss: 0.6871932657203864
Epoch: 85 | Iteration number: [2020/4518] 44% | Training loss: 0.687194762696134
Epoch: 85 | Iteration number: [2030/4518] 44% | Training loss: 0.687191809721181
Epoch: 85 | Iteration number: [2040/4518] 45% | Training loss: 0.6871889982153387
Epoch: 85 | Iteration number: [2050/4518] 45% | Training loss: 0.687196628058829
Epoch: 85 | Iteration number: [2060/4518] 45% | Training loss: 0.6871924704139672
Epoch: 85 | Iteration number: [2070/4518] 45% | Training loss: 0.6871816788894543
Epoch: 85 | Iteration number: [2080/4518] 46% | Training loss: 0.6871751269755455
Epoch: 85 | Iteration number: [2090/4518] 46% | Training loss: 0.6871661660203523
Epoch: 85 | Iteration number: [2100/4518] 46% | Training loss: 0.6871588399296715
Epoch: 85 | Iteration number: [2110/4518] 46% | Training loss: 0.6871528711364168
Epoch: 85 | Iteration number: [2120/4518] 46% | Training loss: 0.6871497509614477
Epoch: 85 | Iteration number: [2130/4518] 47% | Training loss: 0.6871510082847075
Epoch: 85 | Iteration number: [2140/4518] 47% | Training loss: 0.6871463088788718
Epoch: 85 | Iteration number: [2150/4518] 47% | Training loss: 0.6871475220003793
Epoch: 85 | Iteration number: [2160/4518] 47% | Training loss: 0.6871463153373312
Epoch: 85 | Iteration number: [2170/4518] 48% | Training loss: 0.6871444937820259
Epoch: 85 | Iteration number: [2180/4518] 48% | Training loss: 0.6871453898215513
Epoch: 85 | Iteration number: [2190/4518] 48% | Training loss: 0.6871437338117051
Epoch: 85 | Iteration number: [2200/4518] 48% | Training loss: 0.6871394873478196
Epoch: 85 | Iteration number: [2210/4518] 48% | Training loss: 0.6871352602453793
Epoch: 85 | Iteration number: [2220/4518] 49% | Training loss: 0.687128243575225
Epoch: 85 | Iteration number: [2230/4518] 49% | Training loss: 0.687133664534231
Epoch: 85 | Iteration number: [2240/4518] 49% | Training loss: 0.6871309030002781
Epoch: 85 | Iteration number: [2250/4518] 49% | Training loss: 0.6871283486154345
Epoch: 85 | Iteration number: [2260/4518] 50% | Training loss: 0.6871264024909619
Epoch: 85 | Iteration number: [2270/4518] 50% | Training loss: 0.6871225993013592
Epoch: 85 | Iteration number: [2280/4518] 50% | Training loss: 0.6871245762758088
Epoch: 85 | Iteration number: [2290/4518] 50% | Training loss: 0.6871245783489344
Epoch: 85 | Iteration number: [2300/4518] 50% | Training loss: 0.6871171754598617
Epoch: 85 | Iteration number: [2310/4518] 51% | Training loss: 0.6871193185513154
Epoch: 85 | Iteration number: [2320/4518] 51% | Training loss: 0.6871098016099683
Epoch: 85 | Iteration number: [2330/4518] 51% | Training loss: 0.6871110573602849
Epoch: 85 | Iteration number: [2340/4518] 51% | Training loss: 0.6871074508652728
Epoch: 85 | Iteration number: [2350/4518] 52% | Training loss: 0.6871091639488301
Epoch: 85 | Iteration number: [2360/4518] 52% | Training loss: 0.6870995925897259
Epoch: 85 | Iteration number: [2370/4518] 52% | Training loss: 0.6871028079513759
Epoch: 85 | Iteration number: [2380/4518] 52% | Training loss: 0.6871015109935729
Epoch: 85 | Iteration number: [2390/4518] 52% | Training loss: 0.6870952624656167
Epoch: 85 | Iteration number: [2400/4518] 53% | Training loss: 0.6870971545577049
Epoch: 85 | Iteration number: [2410/4518] 53% | Training loss: 0.6870953523271806
Epoch: 85 | Iteration number: [2420/4518] 53% | Training loss: 0.6870919293608547
Epoch: 85 | Iteration number: [2430/4518] 53% | Training loss: 0.6870889176557093
Epoch: 85 | Iteration number: [2440/4518] 54% | Training loss: 0.6870870987167124
Epoch: 85 | Iteration number: [2450/4518] 54% | Training loss: 0.6870847959907688
Epoch: 85 | Iteration number: [2460/4518] 54% | Training loss: 0.6870851245352892
Epoch: 85 | Iteration number: [2470/4518] 54% | Training loss: 0.6870831188402677
Epoch: 85 | Iteration number: [2480/4518] 54% | Training loss: 0.687083174312307
Epoch: 85 | Iteration number: [2490/4518] 55% | Training loss: 0.6870814558013855
Epoch: 85 | Iteration number: [2500/4518] 55% | Training loss: 0.6870818480253219
Epoch: 85 | Iteration number: [2510/4518] 55% | Training loss: 0.6870825942531525
Epoch: 85 | Iteration number: [2520/4518] 55% | Training loss: 0.6870842742778006
Epoch: 85 | Iteration number: [2530/4518] 55% | Training loss: 0.6870826380761715
Epoch: 85 | Iteration number: [2540/4518] 56% | Training loss: 0.6870789139289556
Epoch: 85 | Iteration number: [2550/4518] 56% | Training loss: 0.6870796208288156
Epoch: 85 | Iteration number: [2560/4518] 56% | Training loss: 0.687073619524017
Epoch: 85 | Iteration number: [2570/4518] 56% | Training loss: 0.6870751328737356
Epoch: 85 | Iteration number: [2580/4518] 57% | Training loss: 0.6870771579964217
Epoch: 85 | Iteration number: [2590/4518] 57% | Training loss: 0.6870794496711157
Epoch: 85 | Iteration number: [2600/4518] 57% | Training loss: 0.6870818908627216
Epoch: 85 | Iteration number: [2610/4518] 57% | Training loss: 0.6870843250404373
Epoch: 85 | Iteration number: [2620/4518] 57% | Training loss: 0.6870824195501458
Epoch: 85 | Iteration number: [2630/4518] 58% | Training loss: 0.6870862561940241
Epoch: 85 | Iteration number: [2640/4518] 58% | Training loss: 0.6870872170861924
Epoch: 85 | Iteration number: [2650/4518] 58% | Training loss: 0.6870847345972961
Epoch: 85 | Iteration number: [2660/4518] 58% | Training loss: 0.6870855908420749
Epoch: 85 | Iteration number: [2670/4518] 59% | Training loss: 0.6870882138330838
Epoch: 85 | Iteration number: [2680/4518] 59% | Training loss: 0.6870891483862008
Epoch: 85 | Iteration number: [2690/4518] 59% | Training loss: 0.6870867544390455
Epoch: 85 | Iteration number: [2700/4518] 59% | Training loss: 0.6870872934217807
Epoch: 85 | Iteration number: [2710/4518] 59% | Training loss: 0.6870867039224758
Epoch: 85 | Iteration number: [2720/4518] 60% | Training loss: 0.6870860032298985
Epoch: 85 | Iteration number: [2730/4518] 60% | Training loss: 0.6870805850614121
Epoch: 85 | Iteration number: [2740/4518] 60% | Training loss: 0.6870777889542335
Epoch: 85 | Iteration number: [2750/4518] 60% | Training loss: 0.687074085669084
Epoch: 85 | Iteration number: [2760/4518] 61% | Training loss: 0.6870725634089415
Epoch: 85 | Iteration number: [2770/4518] 61% | Training loss: 0.687073132772308
Epoch: 85 | Iteration number: [2780/4518] 61% | Training loss: 0.6870696247696019
Epoch: 85 | Iteration number: [2790/4518] 61% | Training loss: 0.6870698135813504
Epoch: 85 | Iteration number: [2800/4518] 61% | Training loss: 0.6870652765887124
Epoch: 85 | Iteration number: [2810/4518] 62% | Training loss: 0.6870643653267219
Epoch: 85 | Iteration number: [2820/4518] 62% | Training loss: 0.687067037820816
Epoch: 85 | Iteration number: [2830/4518] 62% | Training loss: 0.6870668225279967
Epoch: 85 | Iteration number: [2840/4518] 62% | Training loss: 0.687063418328762
Epoch: 85 | Iteration number: [2850/4518] 63% | Training loss: 0.6870618344189828
Epoch: 85 | Iteration number: [2860/4518] 63% | Training loss: 0.6870623479773115
Epoch: 85 | Iteration number: [2870/4518] 63% | Training loss: 0.6870581107064822
Epoch: 85 | Iteration number: [2880/4518] 63% | Training loss: 0.687056506714887
Epoch: 85 | Iteration number: [2890/4518] 63% | Training loss: 0.6870508276467505
Epoch: 85 | Iteration number: [2900/4518] 64% | Training loss: 0.6870501712478441
Epoch: 85 | Iteration number: [2910/4518] 64% | Training loss: 0.687047022949789
Epoch: 85 | Iteration number: [2920/4518] 64% | Training loss: 0.6870501273298917
Epoch: 85 | Iteration number: [2930/4518] 64% | Training loss: 0.6870483064203946
Epoch: 85 | Iteration number: [2940/4518] 65% | Training loss: 0.6870466355563832
Epoch: 85 | Iteration number: [2950/4518] 65% | Training loss: 0.6870480867159569
Epoch: 85 | Iteration number: [2960/4518] 65% | Training loss: 0.6870444505399949
Epoch: 85 | Iteration number: [2970/4518] 65% | Training loss: 0.687044869809841
Epoch: 85 | Iteration number: [2980/4518] 65% | Training loss: 0.6870413554594821
Epoch: 85 | Iteration number: [2990/4518] 66% | Training loss: 0.6870353742985422
Epoch: 85 | Iteration number: [3000/4518] 66% | Training loss: 0.6870337827006976
Epoch: 85 | Iteration number: [3010/4518] 66% | Training loss: 0.6870301402882484
Epoch: 85 | Iteration number: [3020/4518] 66% | Training loss: 0.6870286443770327
Epoch: 85 | Iteration number: [3030/4518] 67% | Training loss: 0.687030970873219
Epoch: 85 | Iteration number: [3040/4518] 67% | Training loss: 0.6870279901513928
Epoch: 85 | Iteration number: [3050/4518] 67% | Training loss: 0.687026605019804
Epoch: 85 | Iteration number: [3060/4518] 67% | Training loss: 0.6870305683293374
Epoch: 85 | Iteration number: [3070/4518] 67% | Training loss: 0.6870307357575295
Epoch: 85 | Iteration number: [3080/4518] 68% | Training loss: 0.687031730235397
Epoch: 85 | Iteration number: [3090/4518] 68% | Training loss: 0.6870298059434181
Epoch: 85 | Iteration number: [3100/4518] 68% | Training loss: 0.6870249078542956
Epoch: 85 | Iteration number: [3110/4518] 68% | Training loss: 0.6870187736017528
Epoch: 85 | Iteration number: [3120/4518] 69% | Training loss: 0.687022915826394
Epoch: 85 | Iteration number: [3130/4518] 69% | Training loss: 0.6870214945592058
Epoch: 85 | Iteration number: [3140/4518] 69% | Training loss: 0.6870225011922751
Epoch: 85 | Iteration number: [3150/4518] 69% | Training loss: 0.687015685997312
Epoch: 85 | Iteration number: [3160/4518] 69% | Training loss: 0.6870165869970865
Epoch: 85 | Iteration number: [3170/4518] 70% | Training loss: 0.6870152816599476
Epoch: 85 | Iteration number: [3180/4518] 70% | Training loss: 0.6870170696726385
Epoch: 85 | Iteration number: [3190/4518] 70% | Training loss: 0.6870179789567068
Epoch: 85 | Iteration number: [3200/4518] 70% | Training loss: 0.6870187041349709
Epoch: 85 | Iteration number: [3210/4518] 71% | Training loss: 0.6870135024329213
Epoch: 85 | Iteration number: [3220/4518] 71% | Training loss: 0.687015678812258
Epoch: 85 | Iteration number: [3230/4518] 71% | Training loss: 0.6870100908788734
Epoch: 85 | Iteration number: [3240/4518] 71% | Training loss: 0.6870088692800498
Epoch: 85 | Iteration number: [3250/4518] 71% | Training loss: 0.6870101507627047
Epoch: 85 | Iteration number: [3260/4518] 72% | Training loss: 0.6870060663281774
Epoch: 85 | Iteration number: [3270/4518] 72% | Training loss: 0.6870031141542149
Epoch: 85 | Iteration number: [3280/4518] 72% | Training loss: 0.6870053688927394
Epoch: 85 | Iteration number: [3290/4518] 72% | Training loss: 0.6870025649983832
Epoch: 85 | Iteration number: [3300/4518] 73% | Training loss: 0.6870038521289825
Epoch: 85 | Iteration number: [3310/4518] 73% | Training loss: 0.6870039667067571
Epoch: 85 | Iteration number: [3320/4518] 73% | Training loss: 0.6870049867105771
Epoch: 85 | Iteration number: [3330/4518] 73% | Training loss: 0.6870045197439624
Epoch: 85 | Iteration number: [3340/4518] 73% | Training loss: 0.6870035006971417
Epoch: 85 | Iteration number: [3350/4518] 74% | Training loss: 0.6870026754799173
Epoch: 85 | Iteration number: [3360/4518] 74% | Training loss: 0.6870040102906171
Epoch: 85 | Iteration number: [3370/4518] 74% | Training loss: 0.6870046450228648
Epoch: 85 | Iteration number: [3380/4518] 74% | Training loss: 0.6870039186886782
Epoch: 85 | Iteration number: [3390/4518] 75% | Training loss: 0.6869970084115818
Epoch: 85 | Iteration number: [3400/4518] 75% | Training loss: 0.6869972370477284
Epoch: 85 | Iteration number: [3410/4518] 75% | Training loss: 0.6869930657823065
Epoch: 85 | Iteration number: [3420/4518] 75% | Training loss: 0.6869936314068342
Epoch: 85 | Iteration number: [3430/4518] 75% | Training loss: 0.6869907498533455
Epoch: 85 | Iteration number: [3440/4518] 76% | Training loss: 0.6869892375413762
Epoch: 85 | Iteration number: [3450/4518] 76% | Training loss: 0.686989689944447
Epoch: 85 | Iteration number: [3460/4518] 76% | Training loss: 0.6869848395014084
Epoch: 85 | Iteration number: [3470/4518] 76% | Training loss: 0.6869867042952381
Epoch: 85 | Iteration number: [3480/4518] 77% | Training loss: 0.6869904641276119
Epoch: 85 | Iteration number: [3490/4518] 77% | Training loss: 0.6869917481027565
Epoch: 85 | Iteration number: [3500/4518] 77% | Training loss: 0.6869908430406025
Epoch: 85 | Iteration number: [3510/4518] 77% | Training loss: 0.686990661193163
Epoch: 85 | Iteration number: [3520/4518] 77% | Training loss: 0.6869914698160507
Epoch: 85 | Iteration number: [3530/4518] 78% | Training loss: 0.6869846956925757
Epoch: 85 | Iteration number: [3540/4518] 78% | Training loss: 0.6869831335578261
Epoch: 85 | Iteration number: [3550/4518] 78% | Training loss: 0.6869782104794409
Epoch: 85 | Iteration number: [3560/4518] 78% | Training loss: 0.6869762813944496
Epoch: 85 | Iteration number: [3570/4518] 79% | Training loss: 0.6869743918504367
Epoch: 85 | Iteration number: [3580/4518] 79% | Training loss: 0.6869765968296115
Epoch: 85 | Iteration number: [3590/4518] 79% | Training loss: 0.6869773353872857
Epoch: 85 | Iteration number: [3600/4518] 79% | Training loss: 0.6869791923132208
Epoch: 85 | Iteration number: [3610/4518] 79% | Training loss: 0.6869788866459168
Epoch: 85 | Iteration number: [3620/4518] 80% | Training loss: 0.6869756482088764
Epoch: 85 | Iteration number: [3630/4518] 80% | Training loss: 0.6869730940699249
Epoch: 85 | Iteration number: [3640/4518] 80% | Training loss: 0.686973141019161
Epoch: 85 | Iteration number: [3650/4518] 80% | Training loss: 0.6869722126934626
Epoch: 85 | Iteration number: [3660/4518] 81% | Training loss: 0.6869717691928311
Epoch: 85 | Iteration number: [3670/4518] 81% | Training loss: 0.6869683350789124
Epoch: 85 | Iteration number: [3680/4518] 81% | Training loss: 0.6869635292369386
Epoch: 85 | Iteration number: [3690/4518] 81% | Training loss: 0.6869680541156107
Epoch: 85 | Iteration number: [3700/4518] 81% | Training loss: 0.6869684171998823
Epoch: 85 | Iteration number: [3710/4518] 82% | Training loss: 0.6869690179985488
Epoch: 85 | Iteration number: [3720/4518] 82% | Training loss: 0.6869692370776207
Epoch: 85 | Iteration number: [3730/4518] 82% | Training loss: 0.6869668505466655
Epoch: 85 | Iteration number: [3740/4518] 82% | Training loss: 0.6869663404270927
Epoch: 85 | Iteration number: [3750/4518] 83% | Training loss: 0.6869631220658621
Epoch: 85 | Iteration number: [3760/4518] 83% | Training loss: 0.6869623473032992
Epoch: 85 | Iteration number: [3770/4518] 83% | Training loss: 0.6869583965928865
Epoch: 85 | Iteration number: [3780/4518] 83% | Training loss: 0.6869548837659221
Epoch: 85 | Iteration number: [3790/4518] 83% | Training loss: 0.6869540446194621
Epoch: 85 | Iteration number: [3800/4518] 84% | Training loss: 0.6869536479523307
Epoch: 85 | Iteration number: [3810/4518] 84% | Training loss: 0.6869524932752444
Epoch: 85 | Iteration number: [3820/4518] 84% | Training loss: 0.6869522067264736
Epoch: 85 | Iteration number: [3830/4518] 84% | Training loss: 0.6869520091979373
Epoch: 85 | Iteration number: [3840/4518] 84% | Training loss: 0.6869503172890593
Epoch: 85 | Iteration number: [3850/4518] 85% | Training loss: 0.6869492323057992
Epoch: 85 | Iteration number: [3860/4518] 85% | Training loss: 0.6869500179673723
Epoch: 85 | Iteration number: [3870/4518] 85% | Training loss: 0.6869472514135277
Epoch: 85 | Iteration number: [3880/4518] 85% | Training loss: 0.6869452066949963
Epoch: 85 | Iteration number: [3890/4518] 86% | Training loss: 0.6869461412141746
Epoch: 85 | Iteration number: [3900/4518] 86% | Training loss: 0.6869425897262035
Epoch: 85 | Iteration number: [3910/4518] 86% | Training loss: 0.6869399743616733
Epoch: 85 | Iteration number: [3920/4518] 86% | Training loss: 0.6869396899427687
Epoch: 85 | Iteration number: [3930/4518] 86% | Training loss: 0.6869375283936507
Epoch: 85 | Iteration number: [3940/4518] 87% | Training loss: 0.6869382017306265
Epoch: 85 | Iteration number: [3950/4518] 87% | Training loss: 0.6869395811950104
Epoch: 85 | Iteration number: [3960/4518] 87% | Training loss: 0.6869380710853471
Epoch: 85 | Iteration number: [3970/4518] 87% | Training loss: 0.6869388572064695
Epoch: 85 | Iteration number: [3980/4518] 88% | Training loss: 0.6869396136933236
Epoch: 85 | Iteration number: [3990/4518] 88% | Training loss: 0.6869398835757023
Epoch: 85 | Iteration number: [4000/4518] 88% | Training loss: 0.6869402854591609
Epoch: 85 | Iteration number: [4010/4518] 88% | Training loss: 0.6869378446789454
Epoch: 85 | Iteration number: [4020/4518] 88% | Training loss: 0.6869381513316833
Epoch: 85 | Iteration number: [4030/4518] 89% | Training loss: 0.6869401024677617
Epoch: 85 | Iteration number: [4040/4518] 89% | Training loss: 0.6869405047285675
Epoch: 85 | Iteration number: [4050/4518] 89% | Training loss: 0.6869404399689333
Epoch: 85 | Iteration number: [4060/4518] 89% | Training loss: 0.6869403885356311
Epoch: 85 | Iteration number: [4070/4518] 90% | Training loss: 0.6869394740689299
Epoch: 85 | Iteration number: [4080/4518] 90% | Training loss: 0.686939624682361
Epoch: 85 | Iteration number: [4090/4518] 90% | Training loss: 0.6869367218979413
Epoch: 85 | Iteration number: [4100/4518] 90% | Training loss: 0.6869346421811638
Epoch: 85 | Iteration number: [4110/4518] 90% | Training loss: 0.6869342691996962
Epoch: 85 | Iteration number: [4120/4518] 91% | Training loss: 0.6869356535158111
Epoch: 85 | Iteration number: [4130/4518] 91% | Training loss: 0.6869393880806015
Epoch: 85 | Iteration number: [4140/4518] 91% | Training loss: 0.6869371322186096
Epoch: 85 | Iteration number: [4150/4518] 91% | Training loss: 0.6869387511460178
Epoch: 85 | Iteration number: [4160/4518] 92% | Training loss: 0.6869378510432748
Epoch: 85 | Iteration number: [4170/4518] 92% | Training loss: 0.6869358331465321
Epoch: 85 | Iteration number: [4180/4518] 92% | Training loss: 0.6869367755913849
Epoch: 85 | Iteration number: [4190/4518] 92% | Training loss: 0.6869340192873324
Epoch: 85 | Iteration number: [4200/4518] 92% | Training loss: 0.6869322466424533
Epoch: 85 | Iteration number: [4210/4518] 93% | Training loss: 0.6869301504024135
Epoch: 85 | Iteration number: [4220/4518] 93% | Training loss: 0.6869290971501744
Epoch: 85 | Iteration number: [4230/4518] 93% | Training loss: 0.6869286104437871
Epoch: 85 | Iteration number: [4240/4518] 93% | Training loss: 0.6869299578779149
Epoch: 85 | Iteration number: [4250/4518] 94% | Training loss: 0.6869290884522831
Epoch: 85 | Iteration number: [4260/4518] 94% | Training loss: 0.6869268618419136
Epoch: 85 | Iteration number: [4270/4518] 94% | Training loss: 0.6869299532518454
Epoch: 85 | Iteration number: [4280/4518] 94% | Training loss: 0.686928227502052
Epoch: 85 | Iteration number: [4290/4518] 94% | Training loss: 0.6869251954110908
Epoch: 85 | Iteration number: [4300/4518] 95% | Training loss: 0.6869245049842568
Epoch: 85 | Iteration number: [4310/4518] 95% | Training loss: 0.686923055955816
Epoch: 85 | Iteration number: [4320/4518] 95% | Training loss: 0.6869233226748528
Epoch: 85 | Iteration number: [4330/4518] 95% | Training loss: 0.68691968451196
Epoch: 85 | Iteration number: [4340/4518] 96% | Training loss: 0.6869169520892305
Epoch: 85 | Iteration number: [4350/4518] 96% | Training loss: 0.6869185424673147
Epoch: 85 | Iteration number: [4360/4518] 96% | Training loss: 0.6869222540510904
Epoch: 85 | Iteration number: [4370/4518] 96% | Training loss: 0.6869217655342286
Epoch: 85 | Iteration number: [4380/4518] 96% | Training loss: 0.6869239652401781
Epoch: 85 | Iteration number: [4390/4518] 97% | Training loss: 0.6869223916041823
Epoch: 85 | Iteration number: [4400/4518] 97% | Training loss: 0.6869191665270111
Epoch: 85 | Iteration number: [4410/4518] 97% | Training loss: 0.6869188325880877
Epoch: 85 | Iteration number: [4420/4518] 97% | Training loss: 0.6869175296158813
Epoch: 85 | Iteration number: [4430/4518] 98% | Training loss: 0.6869188671456503
Epoch: 85 | Iteration number: [4440/4518] 98% | Training loss: 0.6869218707353145
Epoch: 85 | Iteration number: [4450/4518] 98% | Training loss: 0.6869176645895069
Epoch: 85 | Iteration number: [4460/4518] 98% | Training loss: 0.6869155984422016
Epoch: 85 | Iteration number: [4470/4518] 98% | Training loss: 0.6869149858919567
Epoch: 85 | Iteration number: [4480/4518] 99% | Training loss: 0.6869151675009302
Epoch: 85 | Iteration number: [4490/4518] 99% | Training loss: 0.6869138662560215
Epoch: 85 | Iteration number: [4500/4518] 99% | Training loss: 0.6869132688442866
Epoch: 85 | Iteration number: [4510/4518] 99% | Training loss: 0.686914271393795

 End of epoch: 85 | Train Loss: 0.686760300725052 | Training Time: 640 

 End of epoch: 85 | Eval Loss: 0.6897823640278408 | Evaluating Time: 17 
Epoch: 86 | Iteration number: [10/4518] 0% | Training loss: 0.7558321356773376
Epoch: 86 | Iteration number: [20/4518] 0% | Training loss: 0.7214525461196899
Epoch: 86 | Iteration number: [30/4518] 0% | Training loss: 0.7098689019680023
Epoch: 86 | Iteration number: [40/4518] 0% | Training loss: 0.7040379002690316
Epoch: 86 | Iteration number: [50/4518] 1% | Training loss: 0.7004832482337952
Epoch: 86 | Iteration number: [60/4518] 1% | Training loss: 0.6983092476924261
Epoch: 86 | Iteration number: [70/4518] 1% | Training loss: 0.6965307269777571
Epoch: 86 | Iteration number: [80/4518] 1% | Training loss: 0.6953511781990528
Epoch: 86 | Iteration number: [90/4518] 1% | Training loss: 0.6944039914343092
Epoch: 86 | Iteration number: [100/4518] 2% | Training loss: 0.6936957401037216
Epoch: 86 | Iteration number: [110/4518] 2% | Training loss: 0.6931905101646076
Epoch: 86 | Iteration number: [120/4518] 2% | Training loss: 0.692679118613402
Epoch: 86 | Iteration number: [130/4518] 2% | Training loss: 0.6922362428445082
Epoch: 86 | Iteration number: [140/4518] 3% | Training loss: 0.6918558112212589
Epoch: 86 | Iteration number: [150/4518] 3% | Training loss: 0.6915116059780121
Epoch: 86 | Iteration number: [160/4518] 3% | Training loss: 0.6911873273551464
Epoch: 86 | Iteration number: [170/4518] 3% | Training loss: 0.6908772699973162
Epoch: 86 | Iteration number: [180/4518] 3% | Training loss: 0.6906487587425444
Epoch: 86 | Iteration number: [190/4518] 4% | Training loss: 0.6905106729582736
Epoch: 86 | Iteration number: [200/4518] 4% | Training loss: 0.6903744208812713
Epoch: 86 | Iteration number: [210/4518] 4% | Training loss: 0.6902076383431752
Epoch: 86 | Iteration number: [220/4518] 4% | Training loss: 0.6900491839105433
Epoch: 86 | Iteration number: [230/4518] 5% | Training loss: 0.6899477577727774
Epoch: 86 | Iteration number: [240/4518] 5% | Training loss: 0.689811871945858
Epoch: 86 | Iteration number: [250/4518] 5% | Training loss: 0.6896786839962006
Epoch: 86 | Iteration number: [260/4518] 5% | Training loss: 0.6895763073976223
Epoch: 86 | Iteration number: [270/4518] 5% | Training loss: 0.6894419870994709
Epoch: 86 | Iteration number: [280/4518] 6% | Training loss: 0.6893838554620743
Epoch: 86 | Iteration number: [290/4518] 6% | Training loss: 0.689306371170899
Epoch: 86 | Iteration number: [300/4518] 6% | Training loss: 0.689213455915451
Epoch: 86 | Iteration number: [310/4518] 6% | Training loss: 0.689083396427093
Epoch: 86 | Iteration number: [320/4518] 7% | Training loss: 0.6890106188133359
Epoch: 86 | Iteration number: [330/4518] 7% | Training loss: 0.6889417072137197
Epoch: 86 | Iteration number: [340/4518] 7% | Training loss: 0.6888689414543264
Epoch: 86 | Iteration number: [350/4518] 7% | Training loss: 0.6887885429177966
Epoch: 86 | Iteration number: [360/4518] 7% | Training loss: 0.6887430818544493
Epoch: 86 | Iteration number: [370/4518] 8% | Training loss: 0.6886752242977555
Epoch: 86 | Iteration number: [380/4518] 8% | Training loss: 0.6886123669774908
Epoch: 86 | Iteration number: [390/4518] 8% | Training loss: 0.688555051271732
Epoch: 86 | Iteration number: [400/4518] 8% | Training loss: 0.6885021349787712
Epoch: 86 | Iteration number: [410/4518] 9% | Training loss: 0.6884517790340796
Epoch: 86 | Iteration number: [420/4518] 9% | Training loss: 0.6883843725635892
Epoch: 86 | Iteration number: [430/4518] 9% | Training loss: 0.6883290425289509
Epoch: 86 | Iteration number: [440/4518] 9% | Training loss: 0.6883109564130957
Epoch: 86 | Iteration number: [450/4518] 9% | Training loss: 0.6883260121610429
Epoch: 86 | Iteration number: [460/4518] 10% | Training loss: 0.6882854604202768
Epoch: 86 | Iteration number: [470/4518] 10% | Training loss: 0.6882631582148532
Epoch: 86 | Iteration number: [480/4518] 10% | Training loss: 0.6882142861684163
Epoch: 86 | Iteration number: [490/4518] 10% | Training loss: 0.688187322202994
Epoch: 86 | Iteration number: [500/4518] 11% | Training loss: 0.6881690576076508
Epoch: 86 | Iteration number: [510/4518] 11% | Training loss: 0.6881330264549629
Epoch: 86 | Iteration number: [520/4518] 11% | Training loss: 0.6881370264750261
Epoch: 86 | Iteration number: [530/4518] 11% | Training loss: 0.6881053426355686
Epoch: 86 | Iteration number: [540/4518] 11% | Training loss: 0.6880844568764722
Epoch: 86 | Iteration number: [550/4518] 12% | Training loss: 0.6880619101090865
Epoch: 86 | Iteration number: [560/4518] 12% | Training loss: 0.688029699240412
Epoch: 86 | Iteration number: [570/4518] 12% | Training loss: 0.6880260100490169
Epoch: 86 | Iteration number: [580/4518] 12% | Training loss: 0.6880049718865033
Epoch: 86 | Iteration number: [590/4518] 13% | Training loss: 0.6880033792075464
Epoch: 86 | Iteration number: [600/4518] 13% | Training loss: 0.6879835682113965
Epoch: 86 | Iteration number: [610/4518] 13% | Training loss: 0.687976411522412
Epoch: 86 | Iteration number: [620/4518] 13% | Training loss: 0.6879766771870275
Epoch: 86 | Iteration number: [630/4518] 13% | Training loss: 0.68795751730601
Epoch: 86 | Iteration number: [640/4518] 14% | Training loss: 0.6879288163967431
Epoch: 86 | Iteration number: [650/4518] 14% | Training loss: 0.6879172624074495
Epoch: 86 | Iteration number: [660/4518] 14% | Training loss: 0.687891861706069
Epoch: 86 | Iteration number: [670/4518] 14% | Training loss: 0.6878744458084676
Epoch: 86 | Iteration number: [680/4518] 15% | Training loss: 0.6878368839621544
Epoch: 86 | Iteration number: [690/4518] 15% | Training loss: 0.6878254387689673
Epoch: 86 | Iteration number: [700/4518] 15% | Training loss: 0.6878099568401064
Epoch: 86 | Iteration number: [710/4518] 15% | Training loss: 0.6877831174454219
Epoch: 86 | Iteration number: [720/4518] 15% | Training loss: 0.6877813859946198
Epoch: 86 | Iteration number: [730/4518] 16% | Training loss: 0.6877595328304865
Epoch: 86 | Iteration number: [740/4518] 16% | Training loss: 0.6877419814870164
Epoch: 86 | Iteration number: [750/4518] 16% | Training loss: 0.6877291517257691
Epoch: 86 | Iteration number: [760/4518] 16% | Training loss: 0.6876948187225743
Epoch: 86 | Iteration number: [770/4518] 17% | Training loss: 0.6876766574847234
Epoch: 86 | Iteration number: [780/4518] 17% | Training loss: 0.687650444950813
Epoch: 86 | Iteration number: [790/4518] 17% | Training loss: 0.6876348316669464
Epoch: 86 | Iteration number: [800/4518] 17% | Training loss: 0.6876232106983662
Epoch: 86 | Iteration number: [810/4518] 17% | Training loss: 0.6876268595089147
Epoch: 86 | Iteration number: [820/4518] 18% | Training loss: 0.6876259258607539
Epoch: 86 | Iteration number: [830/4518] 18% | Training loss: 0.6876072872834034
Epoch: 86 | Iteration number: [840/4518] 18% | Training loss: 0.6876125507411502
Epoch: 86 | Iteration number: [850/4518] 18% | Training loss: 0.6875832489658804
Epoch: 86 | Iteration number: [860/4518] 19% | Training loss: 0.6875832622827486
Epoch: 86 | Iteration number: [870/4518] 19% | Training loss: 0.6875715887409517
Epoch: 86 | Iteration number: [880/4518] 19% | Training loss: 0.6875570793043483
Epoch: 86 | Iteration number: [890/4518] 19% | Training loss: 0.6875344861089514
Epoch: 86 | Iteration number: [900/4518] 19% | Training loss: 0.6875364663203557
Epoch: 86 | Iteration number: [910/4518] 20% | Training loss: 0.6875316023171603
Epoch: 86 | Iteration number: [920/4518] 20% | Training loss: 0.6875333844319634
Epoch: 86 | Iteration number: [930/4518] 20% | Training loss: 0.6875259839719342
Epoch: 86 | Iteration number: [940/4518] 20% | Training loss: 0.6875294155262887
Epoch: 86 | Iteration number: [950/4518] 21% | Training loss: 0.687514703085548
Epoch: 86 | Iteration number: [960/4518] 21% | Training loss: 0.6875144710143407
Epoch: 86 | Iteration number: [970/4518] 21% | Training loss: 0.6875190541916287
Epoch: 86 | Iteration number: [980/4518] 21% | Training loss: 0.6875115797227743
Epoch: 86 | Iteration number: [990/4518] 21% | Training loss: 0.6875125538219106
Epoch: 86 | Iteration number: [1000/4518] 22% | Training loss: 0.6875026034116745
Epoch: 86 | Iteration number: [1010/4518] 22% | Training loss: 0.687497482146367
Epoch: 86 | Iteration number: [1020/4518] 22% | Training loss: 0.6874926986063228
Epoch: 86 | Iteration number: [1030/4518] 22% | Training loss: 0.6874831854139717
Epoch: 86 | Iteration number: [1040/4518] 23% | Training loss: 0.6874775010232742
Epoch: 86 | Iteration number: [1050/4518] 23% | Training loss: 0.687466265133449
Epoch: 86 | Iteration number: [1060/4518] 23% | Training loss: 0.6874641167105369
Epoch: 86 | Iteration number: [1070/4518] 23% | Training loss: 0.6874610082011356
Epoch: 86 | Iteration number: [1080/4518] 23% | Training loss: 0.6874548903769917
Epoch: 86 | Iteration number: [1090/4518] 24% | Training loss: 0.6874507705552863
Epoch: 86 | Iteration number: [1100/4518] 24% | Training loss: 0.6874466540596702
Epoch: 86 | Iteration number: [1110/4518] 24% | Training loss: 0.687426811617774
Epoch: 86 | Iteration number: [1120/4518] 24% | Training loss: 0.6874287391879729
Epoch: 86 | Iteration number: [1130/4518] 25% | Training loss: 0.6874346432432664
Epoch: 86 | Iteration number: [1140/4518] 25% | Training loss: 0.6874208520378983
Epoch: 86 | Iteration number: [1150/4518] 25% | Training loss: 0.6874127920295882
Epoch: 86 | Iteration number: [1160/4518] 25% | Training loss: 0.6873936335074491
Epoch: 86 | Iteration number: [1170/4518] 25% | Training loss: 0.6873999591566559
Epoch: 86 | Iteration number: [1180/4518] 26% | Training loss: 0.6873900807004864
Epoch: 86 | Iteration number: [1190/4518] 26% | Training loss: 0.6873902741099606
Epoch: 86 | Iteration number: [1200/4518] 26% | Training loss: 0.6873912519216537
Epoch: 86 | Iteration number: [1210/4518] 26% | Training loss: 0.6873803992901952
Epoch: 86 | Iteration number: [1220/4518] 27% | Training loss: 0.6873778855214353
Epoch: 86 | Iteration number: [1230/4518] 27% | Training loss: 0.6873751853539691
Epoch: 86 | Iteration number: [1240/4518] 27% | Training loss: 0.6873746161980013
Epoch: 86 | Iteration number: [1250/4518] 27% | Training loss: 0.6873746143817901
Epoch: 86 | Iteration number: [1260/4518] 27% | Training loss: 0.6873728925746585
Epoch: 86 | Iteration number: [1270/4518] 28% | Training loss: 0.6873697474246888
Epoch: 86 | Iteration number: [1280/4518] 28% | Training loss: 0.6873640370555222
Epoch: 86 | Iteration number: [1290/4518] 28% | Training loss: 0.6873517319213512
Epoch: 86 | Iteration number: [1300/4518] 28% | Training loss: 0.6873509212182118
Epoch: 86 | Iteration number: [1310/4518] 28% | Training loss: 0.6873367989791258
Epoch: 86 | Iteration number: [1320/4518] 29% | Training loss: 0.6873366761388201
Epoch: 86 | Iteration number: [1330/4518] 29% | Training loss: 0.6873289989349537
Epoch: 86 | Iteration number: [1340/4518] 29% | Training loss: 0.6873201384918014
Epoch: 86 | Iteration number: [1350/4518] 29% | Training loss: 0.6873175808235451
Epoch: 86 | Iteration number: [1360/4518] 30% | Training loss: 0.687312942261205
Epoch: 86 | Iteration number: [1370/4518] 30% | Training loss: 0.6873026598108946
Epoch: 86 | Iteration number: [1380/4518] 30% | Training loss: 0.6872921916021817
Epoch: 86 | Iteration number: [1390/4518] 30% | Training loss: 0.6872915438182062
Epoch: 86 | Iteration number: [1400/4518] 30% | Training loss: 0.6872879929627691
Epoch: 86 | Iteration number: [1410/4518] 31% | Training loss: 0.687291101868271
Epoch: 86 | Iteration number: [1420/4518] 31% | Training loss: 0.687289657391293
Epoch: 86 | Iteration number: [1430/4518] 31% | Training loss: 0.6872807857039925
Epoch: 86 | Iteration number: [1440/4518] 31% | Training loss: 0.6872738417237997
Epoch: 86 | Iteration number: [1450/4518] 32% | Training loss: 0.6872675407343898
Epoch: 86 | Iteration number: [1460/4518] 32% | Training loss: 0.6872664453232125
Epoch: 86 | Iteration number: [1470/4518] 32% | Training loss: 0.6872607219786872
Epoch: 86 | Iteration number: [1480/4518] 32% | Training loss: 0.6872627310253479
Epoch: 86 | Iteration number: [1490/4518] 32% | Training loss: 0.6872572122004208
Epoch: 86 | Iteration number: [1500/4518] 33% | Training loss: 0.6872417696714401
Epoch: 86 | Iteration number: [1510/4518] 33% | Training loss: 0.6872363090515137
Epoch: 86 | Iteration number: [1520/4518] 33% | Training loss: 0.6872395724450288
Epoch: 86 | Iteration number: [1530/4518] 33% | Training loss: 0.6872422723988303
Epoch: 86 | Iteration number: [1540/4518] 34% | Training loss: 0.6872443501051371
Epoch: 86 | Iteration number: [1550/4518] 34% | Training loss: 0.6872392364471189
Epoch: 86 | Iteration number: [1560/4518] 34% | Training loss: 0.6872368747989337
Epoch: 86 | Iteration number: [1570/4518] 34% | Training loss: 0.6872354013524997
Epoch: 86 | Iteration number: [1580/4518] 34% | Training loss: 0.687228152797192
Epoch: 86 | Iteration number: [1590/4518] 35% | Training loss: 0.6872274826532639
Epoch: 86 | Iteration number: [1600/4518] 35% | Training loss: 0.6872281776368618
Epoch: 86 | Iteration number: [1610/4518] 35% | Training loss: 0.6872258031590385
Epoch: 86 | Iteration number: [1620/4518] 35% | Training loss: 0.6872186893666232
Epoch: 86 | Iteration number: [1630/4518] 36% | Training loss: 0.6872142155477605
Epoch: 86 | Iteration number: [1640/4518] 36% | Training loss: 0.6872132879204866
Epoch: 86 | Iteration number: [1650/4518] 36% | Training loss: 0.6872071090250305
Epoch: 86 | Iteration number: [1660/4518] 36% | Training loss: 0.6871992197381445
Epoch: 86 | Iteration number: [1670/4518] 36% | Training loss: 0.6871970246295015
Epoch: 86 | Iteration number: [1680/4518] 37% | Training loss: 0.6871954851207279
Epoch: 86 | Iteration number: [1690/4518] 37% | Training loss: 0.6871987059976927
Epoch: 86 | Iteration number: [1700/4518] 37% | Training loss: 0.6871971671370899
Epoch: 86 | Iteration number: [1710/4518] 37% | Training loss: 0.6871882234749042
Epoch: 86 | Iteration number: [1720/4518] 38% | Training loss: 0.687185586469118
Epoch: 86 | Iteration number: [1730/4518] 38% | Training loss: 0.6871883195259667
Epoch: 86 | Iteration number: [1740/4518] 38% | Training loss: 0.6871936148268053
Epoch: 86 | Iteration number: [1750/4518] 38% | Training loss: 0.6871890309197562
Epoch: 86 | Iteration number: [1760/4518] 38% | Training loss: 0.6871816694059155
Epoch: 86 | Iteration number: [1770/4518] 39% | Training loss: 0.6871797839127018
Epoch: 86 | Iteration number: [1780/4518] 39% | Training loss: 0.6871746176414275
Epoch: 86 | Iteration number: [1790/4518] 39% | Training loss: 0.6871705942979738
Epoch: 86 | Iteration number: [1800/4518] 39% | Training loss: 0.6871707201004028
Epoch: 86 | Iteration number: [1810/4518] 40% | Training loss: 0.687162476317
Epoch: 86 | Iteration number: [1820/4518] 40% | Training loss: 0.6871591859466427
Epoch: 86 | Iteration number: [1830/4518] 40% | Training loss: 0.687151914444126
Epoch: 86 | Iteration number: [1840/4518] 40% | Training loss: 0.6871517732091572
Epoch: 86 | Iteration number: [1850/4518] 40% | Training loss: 0.6871567039876371
Epoch: 86 | Iteration number: [1860/4518] 41% | Training loss: 0.6871555231591706
Epoch: 86 | Iteration number: [1870/4518] 41% | Training loss: 0.6871481539731357
Epoch: 86 | Iteration number: [1880/4518] 41% | Training loss: 0.6871420832073435
Epoch: 86 | Iteration number: [1890/4518] 41% | Training loss: 0.6871459381920951
Epoch: 86 | Iteration number: [1900/4518] 42% | Training loss: 0.6871429729147961
Epoch: 86 | Iteration number: [1910/4518] 42% | Training loss: 0.6871395533621624
Epoch: 86 | Iteration number: [1920/4518] 42% | Training loss: 0.6871383880575498
Epoch: 86 | Iteration number: [1930/4518] 42% | Training loss: 0.6871367527413245
Epoch: 86 | Iteration number: [1940/4518] 42% | Training loss: 0.6871307281489225
Epoch: 86 | Iteration number: [1950/4518] 43% | Training loss: 0.6871337459026239
Epoch: 86 | Iteration number: [1960/4518] 43% | Training loss: 0.6871323053630031
Epoch: 86 | Iteration number: [1970/4518] 43% | Training loss: 0.6871230650674268
Epoch: 86 | Iteration number: [1980/4518] 43% | Training loss: 0.6871248311165608
Epoch: 86 | Iteration number: [1990/4518] 44% | Training loss: 0.6871257992545564
Epoch: 86 | Iteration number: [2000/4518] 44% | Training loss: 0.6871258960068226
Epoch: 86 | Iteration number: [2010/4518] 44% | Training loss: 0.6871331324624778
Epoch: 86 | Iteration number: [2020/4518] 44% | Training loss: 0.6871314643338176
Epoch: 86 | Iteration number: [2030/4518] 44% | Training loss: 0.687127685546875
Epoch: 86 | Iteration number: [2040/4518] 45% | Training loss: 0.6871314337732746
Epoch: 86 | Iteration number: [2050/4518] 45% | Training loss: 0.6871324870644546
Epoch: 86 | Iteration number: [2060/4518] 45% | Training loss: 0.6871277277041408
Epoch: 86 | Iteration number: [2070/4518] 45% | Training loss: 0.6871325794913342
Epoch: 86 | Iteration number: [2080/4518] 46% | Training loss: 0.6871313695724194
Epoch: 86 | Iteration number: [2090/4518] 46% | Training loss: 0.6871298936850717
Epoch: 86 | Iteration number: [2100/4518] 46% | Training loss: 0.6871253669261932
Epoch: 86 | Iteration number: [2110/4518] 46% | Training loss: 0.6871228860452842
Epoch: 86 | Iteration number: [2120/4518] 46% | Training loss: 0.687124337199724
Epoch: 86 | Iteration number: [2130/4518] 47% | Training loss: 0.6871234559117348
Epoch: 86 | Iteration number: [2140/4518] 47% | Training loss: 0.687114158523417
Epoch: 86 | Iteration number: [2150/4518] 47% | Training loss: 0.6871102152591528
Epoch: 86 | Iteration number: [2160/4518] 47% | Training loss: 0.6871104611842721
Epoch: 86 | Iteration number: [2170/4518] 48% | Training loss: 0.6871067890923144
Epoch: 86 | Iteration number: [2180/4518] 48% | Training loss: 0.6871089519710716
Epoch: 86 | Iteration number: [2190/4518] 48% | Training loss: 0.6871108984838338
Epoch: 86 | Iteration number: [2200/4518] 48% | Training loss: 0.687110386626287
Epoch: 86 | Iteration number: [2210/4518] 48% | Training loss: 0.687105965371585
Epoch: 86 | Iteration number: [2220/4518] 49% | Training loss: 0.6871058063732611
Epoch: 86 | Iteration number: [2230/4518] 49% | Training loss: 0.6870995500162578
Epoch: 86 | Iteration number: [2240/4518] 49% | Training loss: 0.6870917407263603
Epoch: 86 | Iteration number: [2250/4518] 49% | Training loss: 0.6870892907778422
Epoch: 86 | Iteration number: [2260/4518] 50% | Training loss: 0.6870893032677405
Epoch: 86 | Iteration number: [2270/4518] 50% | Training loss: 0.6870804610756526
Epoch: 86 | Iteration number: [2280/4518] 50% | Training loss: 0.6870865059787767
Epoch: 86 | Iteration number: [2290/4518] 50% | Training loss: 0.6870837789695856
Epoch: 86 | Iteration number: [2300/4518] 50% | Training loss: 0.6870823734739553
Epoch: 86 | Iteration number: [2310/4518] 51% | Training loss: 0.6870785202040817
Epoch: 86 | Iteration number: [2320/4518] 51% | Training loss: 0.6870747066263495
Epoch: 86 | Iteration number: [2330/4518] 51% | Training loss: 0.6870721286202705
Epoch: 86 | Iteration number: [2340/4518] 51% | Training loss: 0.6870705884491276
Epoch: 86 | Iteration number: [2350/4518] 52% | Training loss: 0.6870636310729574
Epoch: 86 | Iteration number: [2360/4518] 52% | Training loss: 0.6870624362917269
Epoch: 86 | Iteration number: [2370/4518] 52% | Training loss: 0.6870628256083541
Epoch: 86 | Iteration number: [2380/4518] 52% | Training loss: 0.6870610532640409
Epoch: 86 | Iteration number: [2390/4518] 52% | Training loss: 0.687059479203683
Epoch: 86 | Iteration number: [2400/4518] 53% | Training loss: 0.687057276442647
Epoch: 86 | Iteration number: [2410/4518] 53% | Training loss: 0.6870544327245214
Epoch: 86 | Iteration number: [2420/4518] 53% | Training loss: 0.6870523571721778
Epoch: 86 | Iteration number: [2430/4518] 53% | Training loss: 0.687048427533711
Epoch: 86 | Iteration number: [2440/4518] 54% | Training loss: 0.6870539008838231
Epoch: 86 | Iteration number: [2450/4518] 54% | Training loss: 0.6870541949904695
Epoch: 86 | Iteration number: [2460/4518] 54% | Training loss: 0.6870531222442301
Epoch: 86 | Iteration number: [2470/4518] 54% | Training loss: 0.6870549097958847
Epoch: 86 | Iteration number: [2480/4518] 54% | Training loss: 0.6870553759076903
Epoch: 86 | Iteration number: [2490/4518] 55% | Training loss: 0.6870555185409913
Epoch: 86 | Iteration number: [2500/4518] 55% | Training loss: 0.6870492769956589
Epoch: 86 | Iteration number: [2510/4518] 55% | Training loss: 0.6870470467791614
Epoch: 86 | Iteration number: [2520/4518] 55% | Training loss: 0.6870455208988416
Epoch: 86 | Iteration number: [2530/4518] 55% | Training loss: 0.6870492563652898
Epoch: 86 | Iteration number: [2540/4518] 56% | Training loss: 0.687048004438558
Epoch: 86 | Iteration number: [2550/4518] 56% | Training loss: 0.6870463126547196
Epoch: 86 | Iteration number: [2560/4518] 56% | Training loss: 0.6870469265151768
Epoch: 86 | Iteration number: [2570/4518] 56% | Training loss: 0.6870534021102964
Epoch: 86 | Iteration number: [2580/4518] 57% | Training loss: 0.6870530930138373
Epoch: 86 | Iteration number: [2590/4518] 57% | Training loss: 0.6870538609828728
Epoch: 86 | Iteration number: [2600/4518] 57% | Training loss: 0.687054767195995
Epoch: 86 | Iteration number: [2610/4518] 57% | Training loss: 0.6870553565208026
Epoch: 86 | Iteration number: [2620/4518] 57% | Training loss: 0.6870525389227249
Epoch: 86 | Iteration number: [2630/4518] 58% | Training loss: 0.6870467739866714
Epoch: 86 | Iteration number: [2640/4518] 58% | Training loss: 0.6870371329739239
Epoch: 86 | Iteration number: [2650/4518] 58% | Training loss: 0.6870342013071168
Epoch: 86 | Iteration number: [2660/4518] 58% | Training loss: 0.6870353758335114
Epoch: 86 | Iteration number: [2670/4518] 59% | Training loss: 0.6870389065715704
Epoch: 86 | Iteration number: [2680/4518] 59% | Training loss: 0.6870373677406738
Epoch: 86 | Iteration number: [2690/4518] 59% | Training loss: 0.6870305169470692
Epoch: 86 | Iteration number: [2700/4518] 59% | Training loss: 0.6870277582274543
Epoch: 86 | Iteration number: [2710/4518] 59% | Training loss: 0.6870259864743785
Epoch: 86 | Iteration number: [2720/4518] 60% | Training loss: 0.6870234704850351
Epoch: 86 | Iteration number: [2730/4518] 60% | Training loss: 0.6870229564306937
Epoch: 86 | Iteration number: [2740/4518] 60% | Training loss: 0.6870198198261052
Epoch: 86 | Iteration number: [2750/4518] 60% | Training loss: 0.6870183254155245
Epoch: 86 | Iteration number: [2760/4518] 61% | Training loss: 0.6870180258284444
Epoch: 86 | Iteration number: [2770/4518] 61% | Training loss: 0.6870135190469694
Epoch: 86 | Iteration number: [2780/4518] 61% | Training loss: 0.6870136097180758
Epoch: 86 | Iteration number: [2790/4518] 61% | Training loss: 0.6870154582257767
Epoch: 86 | Iteration number: [2800/4518] 61% | Training loss: 0.687017213766064
Epoch: 86 | Iteration number: [2810/4518] 62% | Training loss: 0.6870136318045579
Epoch: 86 | Iteration number: [2820/4518] 62% | Training loss: 0.6870149150173714
Epoch: 86 | Iteration number: [2830/4518] 62% | Training loss: 0.6870079429537164
Epoch: 86 | Iteration number: [2840/4518] 62% | Training loss: 0.6870049395401713
Epoch: 86 | Iteration number: [2850/4518] 63% | Training loss: 0.6870026470067209
Epoch: 86 | Iteration number: [2860/4518] 63% | Training loss: 0.6869967702177021
Epoch: 86 | Iteration number: [2870/4518] 63% | Training loss: 0.6869982818900916
Epoch: 86 | Iteration number: [2880/4518] 63% | Training loss: 0.6869979485869407
Epoch: 86 | Iteration number: [2890/4518] 63% | Training loss: 0.6869962999152477
Epoch: 86 | Iteration number: [2900/4518] 64% | Training loss: 0.6869964390376518
Epoch: 86 | Iteration number: [2910/4518] 64% | Training loss: 0.6870013928700149
Epoch: 86 | Iteration number: [2920/4518] 64% | Training loss: 0.6870018513847704
Epoch: 86 | Iteration number: [2930/4518] 64% | Training loss: 0.6869982935869653
Epoch: 86 | Iteration number: [2940/4518] 65% | Training loss: 0.6869965226471829
Epoch: 86 | Iteration number: [2950/4518] 65% | Training loss: 0.6869986213667918
Epoch: 86 | Iteration number: [2960/4518] 65% | Training loss: 0.6869964084109744
Epoch: 86 | Iteration number: [2970/4518] 65% | Training loss: 0.6869977577366813
Epoch: 86 | Iteration number: [2980/4518] 65% | Training loss: 0.6869947703292706
Epoch: 86 | Iteration number: [2990/4518] 66% | Training loss: 0.6869951270894462
Epoch: 86 | Iteration number: [3000/4518] 66% | Training loss: 0.6869934819142024
Epoch: 86 | Iteration number: [3010/4518] 66% | Training loss: 0.6869899992728946
Epoch: 86 | Iteration number: [3020/4518] 66% | Training loss: 0.6869932361983305
Epoch: 86 | Iteration number: [3030/4518] 67% | Training loss: 0.6869961551313747
Epoch: 86 | Iteration number: [3040/4518] 67% | Training loss: 0.6869900349331529
Epoch: 86 | Iteration number: [3050/4518] 67% | Training loss: 0.6869919250050529
Epoch: 86 | Iteration number: [3060/4518] 67% | Training loss: 0.6869901583280439
Epoch: 86 | Iteration number: [3070/4518] 67% | Training loss: 0.6869889375829541
Epoch: 86 | Iteration number: [3080/4518] 68% | Training loss: 0.6869866351802628
Epoch: 86 | Iteration number: [3090/4518] 68% | Training loss: 0.6869845105606376
Epoch: 86 | Iteration number: [3100/4518] 68% | Training loss: 0.6869840771536673
Epoch: 86 | Iteration number: [3110/4518] 68% | Training loss: 0.6869846475469338
Epoch: 86 | Iteration number: [3120/4518] 69% | Training loss: 0.6869796885893895
Epoch: 86 | Iteration number: [3130/4518] 69% | Training loss: 0.6869757046333897
Epoch: 86 | Iteration number: [3140/4518] 69% | Training loss: 0.6869753486791235
Epoch: 86 | Iteration number: [3150/4518] 69% | Training loss: 0.686975635479367
Epoch: 86 | Iteration number: [3160/4518] 69% | Training loss: 0.6869744556425493
Epoch: 86 | Iteration number: [3170/4518] 70% | Training loss: 0.6869759573733393
Epoch: 86 | Iteration number: [3180/4518] 70% | Training loss: 0.6869724635620537
Epoch: 86 | Iteration number: [3190/4518] 70% | Training loss: 0.6869718034065629
Epoch: 86 | Iteration number: [3200/4518] 70% | Training loss: 0.686967502348125
Epoch: 86 | Iteration number: [3210/4518] 71% | Training loss: 0.6869636239106781
Epoch: 86 | Iteration number: [3220/4518] 71% | Training loss: 0.6869640553404825
Epoch: 86 | Iteration number: [3230/4518] 71% | Training loss: 0.6869634889781291
Epoch: 86 | Iteration number: [3240/4518] 71% | Training loss: 0.6869602320186886
Epoch: 86 | Iteration number: [3250/4518] 71% | Training loss: 0.6869578023690444
Epoch: 86 | Iteration number: [3260/4518] 72% | Training loss: 0.6869510515701551
Epoch: 86 | Iteration number: [3270/4518] 72% | Training loss: 0.6869504567133178
Epoch: 86 | Iteration number: [3280/4518] 72% | Training loss: 0.6869535128517849
Epoch: 86 | Iteration number: [3290/4518] 72% | Training loss: 0.6869556611069793
Epoch: 86 | Iteration number: [3300/4518] 73% | Training loss: 0.6869542843284029
Epoch: 86 | Iteration number: [3310/4518] 73% | Training loss: 0.6869552183907558
Epoch: 86 | Iteration number: [3320/4518] 73% | Training loss: 0.6869551361325276
Epoch: 86 | Iteration number: [3330/4518] 73% | Training loss: 0.6869558895135427
Epoch: 86 | Iteration number: [3340/4518] 73% | Training loss: 0.6869531854897916
Epoch: 86 | Iteration number: [3350/4518] 74% | Training loss: 0.6869502021661446
Epoch: 86 | Iteration number: [3360/4518] 74% | Training loss: 0.6869507935430322
Epoch: 86 | Iteration number: [3370/4518] 74% | Training loss: 0.686952358289713
Epoch: 86 | Iteration number: [3380/4518] 74% | Training loss: 0.686953427735165
Epoch: 86 | Iteration number: [3390/4518] 75% | Training loss: 0.6869553778199672
Epoch: 86 | Iteration number: [3400/4518] 75% | Training loss: 0.6869536319550346
Epoch: 86 | Iteration number: [3410/4518] 75% | Training loss: 0.6869515469696514
Epoch: 86 | Iteration number: [3420/4518] 75% | Training loss: 0.6869470361206267
Epoch: 86 | Iteration number: [3430/4518] 75% | Training loss: 0.6869500335381955
Epoch: 86 | Iteration number: [3440/4518] 76% | Training loss: 0.6869499058397703
Epoch: 86 | Iteration number: [3450/4518] 76% | Training loss: 0.6869503892159117
Epoch: 86 | Iteration number: [3460/4518] 76% | Training loss: 0.6869515969401839
Epoch: 86 | Iteration number: [3470/4518] 76% | Training loss: 0.6869496870624916
Epoch: 86 | Iteration number: [3480/4518] 77% | Training loss: 0.6869491341470302
Epoch: 86 | Iteration number: [3490/4518] 77% | Training loss: 0.6869477227458298
Epoch: 86 | Iteration number: [3500/4518] 77% | Training loss: 0.6869481714282717
Epoch: 86 | Iteration number: [3510/4518] 77% | Training loss: 0.6869477106974675
Epoch: 86 | Iteration number: [3520/4518] 77% | Training loss: 0.6869462132453918
Epoch: 86 | Iteration number: [3530/4518] 78% | Training loss: 0.6869465216698795
Epoch: 86 | Iteration number: [3540/4518] 78% | Training loss: 0.6869472273325516
Epoch: 86 | Iteration number: [3550/4518] 78% | Training loss: 0.686944999594084
Epoch: 86 | Iteration number: [3560/4518] 78% | Training loss: 0.6869445328799526
Epoch: 86 | Iteration number: [3570/4518] 79% | Training loss: 0.6869452848654836
Epoch: 86 | Iteration number: [3580/4518] 79% | Training loss: 0.6869485791835039
Epoch: 86 | Iteration number: [3590/4518] 79% | Training loss: 0.6869478879200714
Epoch: 86 | Iteration number: [3600/4518] 79% | Training loss: 0.6869467524356312
Epoch: 86 | Iteration number: [3610/4518] 79% | Training loss: 0.6869465087259246
Epoch: 86 | Iteration number: [3620/4518] 80% | Training loss: 0.6869436954431112
Epoch: 86 | Iteration number: [3630/4518] 80% | Training loss: 0.6869424835873701
Epoch: 86 | Iteration number: [3640/4518] 80% | Training loss: 0.6869450735030593
Epoch: 86 | Iteration number: [3650/4518] 80% | Training loss: 0.6869446647493807
Epoch: 86 | Iteration number: [3660/4518] 81% | Training loss: 0.6869458690855672
Epoch: 86 | Iteration number: [3670/4518] 81% | Training loss: 0.6869413662996214
Epoch: 86 | Iteration number: [3680/4518] 81% | Training loss: 0.6869366965702046
Epoch: 86 | Iteration number: [3690/4518] 81% | Training loss: 0.6869359761395751
Epoch: 86 | Iteration number: [3700/4518] 81% | Training loss: 0.6869369719479536
Epoch: 86 | Iteration number: [3710/4518] 82% | Training loss: 0.6869348154235079
Epoch: 86 | Iteration number: [3720/4518] 82% | Training loss: 0.6869380902218563
Epoch: 86 | Iteration number: [3730/4518] 82% | Training loss: 0.6869375382607488
Epoch: 86 | Iteration number: [3740/4518] 82% | Training loss: 0.686934768930476
Epoch: 86 | Iteration number: [3750/4518] 83% | Training loss: 0.6869323830763499
Epoch: 86 | Iteration number: [3760/4518] 83% | Training loss: 0.6869327655815064
Epoch: 86 | Iteration number: [3770/4518] 83% | Training loss: 0.6869320319249079
Epoch: 86 | Iteration number: [3780/4518] 83% | Training loss: 0.686936093196667
Epoch: 86 | Iteration number: [3790/4518] 83% | Training loss: 0.6869342189508252
Epoch: 86 | Iteration number: [3800/4518] 84% | Training loss: 0.6869343170994207
Epoch: 86 | Iteration number: [3810/4518] 84% | Training loss: 0.6869311677502209
Epoch: 86 | Iteration number: [3820/4518] 84% | Training loss: 0.6869310275734407
Epoch: 86 | Iteration number: [3830/4518] 84% | Training loss: 0.6869331438609888
Epoch: 86 | Iteration number: [3840/4518] 84% | Training loss: 0.6869340207117299
Epoch: 86 | Iteration number: [3850/4518] 85% | Training loss: 0.6869336585255412
Epoch: 86 | Iteration number: [3860/4518] 85% | Training loss: 0.6869362199244722
Epoch: 86 | Iteration number: [3870/4518] 85% | Training loss: 0.6869367786002097
Epoch: 86 | Iteration number: [3880/4518] 85% | Training loss: 0.686936697701818
Epoch: 86 | Iteration number: [3890/4518] 86% | Training loss: 0.6869363397742911
Epoch: 86 | Iteration number: [3900/4518] 86% | Training loss: 0.6869361627407563
Epoch: 86 | Iteration number: [3910/4518] 86% | Training loss: 0.6869355903866956
Epoch: 86 | Iteration number: [3920/4518] 86% | Training loss: 0.6869370678097618
Epoch: 86 | Iteration number: [3930/4518] 86% | Training loss: 0.686932405154517
Epoch: 86 | Iteration number: [3940/4518] 87% | Training loss: 0.6869326010422053
Epoch: 86 | Iteration number: [3950/4518] 87% | Training loss: 0.6869333808180652
Epoch: 86 | Iteration number: [3960/4518] 87% | Training loss: 0.6869341914099877
Epoch: 86 | Iteration number: [3970/4518] 87% | Training loss: 0.6869304338390341
Epoch: 86 | Iteration number: [3980/4518] 88% | Training loss: 0.6869293161073522
Epoch: 86 | Iteration number: [3990/4518] 88% | Training loss: 0.6869276816534219
Epoch: 86 | Iteration number: [4000/4518] 88% | Training loss: 0.6869281470477581
Epoch: 86 | Iteration number: [4010/4518] 88% | Training loss: 0.6869279184989501
Epoch: 86 | Iteration number: [4020/4518] 88% | Training loss: 0.6869235728955387
Epoch: 86 | Iteration number: [4030/4518] 89% | Training loss: 0.6869246034113409
Epoch: 86 | Iteration number: [4040/4518] 89% | Training loss: 0.6869231618571989
Epoch: 86 | Iteration number: [4050/4518] 89% | Training loss: 0.6869258204360067
Epoch: 86 | Iteration number: [4060/4518] 89% | Training loss: 0.6869245780806236
Epoch: 86 | Iteration number: [4070/4518] 90% | Training loss: 0.6869259757843299
Epoch: 86 | Iteration number: [4080/4518] 90% | Training loss: 0.6869269400542858
Epoch: 86 | Iteration number: [4090/4518] 90% | Training loss: 0.6869263879098636
Epoch: 86 | Iteration number: [4100/4518] 90% | Training loss: 0.6869291220641718
Epoch: 86 | Iteration number: [4110/4518] 90% | Training loss: 0.6869278034444563
Epoch: 86 | Iteration number: [4120/4518] 91% | Training loss: 0.6869247181322968
Epoch: 86 | Iteration number: [4130/4518] 91% | Training loss: 0.6869269373774817
Epoch: 86 | Iteration number: [4140/4518] 91% | Training loss: 0.6869269512557753
Epoch: 86 | Iteration number: [4150/4518] 91% | Training loss: 0.6869229298614594
Epoch: 86 | Iteration number: [4160/4518] 92% | Training loss: 0.6869231091812253
Epoch: 86 | Iteration number: [4170/4518] 92% | Training loss: 0.6869219113596909
Epoch: 86 | Iteration number: [4180/4518] 92% | Training loss: 0.6869218171498422
Epoch: 86 | Iteration number: [4190/4518] 92% | Training loss: 0.686922506002936
Epoch: 86 | Iteration number: [4200/4518] 92% | Training loss: 0.6869241764289992
Epoch: 86 | Iteration number: [4210/4518] 93% | Training loss: 0.6869240680669663
Epoch: 86 | Iteration number: [4220/4518] 93% | Training loss: 0.6869241515183335
Epoch: 86 | Iteration number: [4230/4518] 93% | Training loss: 0.6869213459339548
Epoch: 86 | Iteration number: [4240/4518] 93% | Training loss: 0.6869213375280488
Epoch: 86 | Iteration number: [4250/4518] 94% | Training loss: 0.6869225095300113
Epoch: 86 | Iteration number: [4260/4518] 94% | Training loss: 0.6869234269353706
Epoch: 86 | Iteration number: [4270/4518] 94% | Training loss: 0.6869216075825747
Epoch: 86 | Iteration number: [4280/4518] 94% | Training loss: 0.6869190406855021
Epoch: 86 | Iteration number: [4290/4518] 94% | Training loss: 0.6869220107029645
Epoch: 86 | Iteration number: [4300/4518] 95% | Training loss: 0.686919152487156
Epoch: 86 | Iteration number: [4310/4518] 95% | Training loss: 0.68691620718852
Epoch: 86 | Iteration number: [4320/4518] 95% | Training loss: 0.6869111411411453
Epoch: 86 | Iteration number: [4330/4518] 95% | Training loss: 0.68691287137069
Epoch: 86 | Iteration number: [4340/4518] 96% | Training loss: 0.6869120605667616
Epoch: 86 | Iteration number: [4350/4518] 96% | Training loss: 0.6869134600957235
Epoch: 86 | Iteration number: [4360/4518] 96% | Training loss: 0.6869108452846151
Epoch: 86 | Iteration number: [4370/4518] 96% | Training loss: 0.686909052831903
Epoch: 86 | Iteration number: [4380/4518] 96% | Training loss: 0.6869099806977189
Epoch: 86 | Iteration number: [4390/4518] 97% | Training loss: 0.6869102040564552
Epoch: 86 | Iteration number: [4400/4518] 97% | Training loss: 0.6869111005961895
Epoch: 86 | Iteration number: [4410/4518] 97% | Training loss: 0.6869063142475899
Epoch: 86 | Iteration number: [4420/4518] 97% | Training loss: 0.6869041339034948
Epoch: 86 | Iteration number: [4430/4518] 98% | Training loss: 0.6869029133233744
Epoch: 86 | Iteration number: [4440/4518] 98% | Training loss: 0.6869016291590424
Epoch: 86 | Iteration number: [4450/4518] 98% | Training loss: 0.6869034175524551
Epoch: 86 | Iteration number: [4460/4518] 98% | Training loss: 0.6869054922474874
Epoch: 86 | Iteration number: [4470/4518] 98% | Training loss: 0.6869053847971112
Epoch: 86 | Iteration number: [4480/4518] 99% | Training loss: 0.6869084981137088
Epoch: 86 | Iteration number: [4490/4518] 99% | Training loss: 0.686908731057012
Epoch: 86 | Iteration number: [4500/4518] 99% | Training loss: 0.6869054511653052
Epoch: 86 | Iteration number: [4510/4518] 99% | Training loss: 0.6869077506853049

 End of epoch: 86 | Train Loss: 0.686755354515796 | Training Time: 640 

 End of epoch: 86 | Eval Loss: 0.6897683496377907 | Evaluating Time: 17 
Epoch: 87 | Iteration number: [10/4518] 0% | Training loss: 0.7560214102268219
Epoch: 87 | Iteration number: [20/4518] 0% | Training loss: 0.7211484670639038
Epoch: 87 | Iteration number: [30/4518] 0% | Training loss: 0.7094128588835399
Epoch: 87 | Iteration number: [40/4518] 0% | Training loss: 0.7039405584335328
Epoch: 87 | Iteration number: [50/4518] 1% | Training loss: 0.700407794713974
Epoch: 87 | Iteration number: [60/4518] 1% | Training loss: 0.6981792916854223
Epoch: 87 | Iteration number: [70/4518] 1% | Training loss: 0.6966057130268641
Epoch: 87 | Iteration number: [80/4518] 1% | Training loss: 0.695344740152359
Epoch: 87 | Iteration number: [90/4518] 1% | Training loss: 0.6943957467873891
Epoch: 87 | Iteration number: [100/4518] 2% | Training loss: 0.6937022376060485
Epoch: 87 | Iteration number: [110/4518] 2% | Training loss: 0.6929958484389566
Epoch: 87 | Iteration number: [120/4518] 2% | Training loss: 0.6925850674510002
Epoch: 87 | Iteration number: [130/4518] 2% | Training loss: 0.6920397116587712
Epoch: 87 | Iteration number: [140/4518] 3% | Training loss: 0.691698037300791
Epoch: 87 | Iteration number: [150/4518] 3% | Training loss: 0.6914124782880148
Epoch: 87 | Iteration number: [160/4518] 3% | Training loss: 0.6911462165415287
Epoch: 87 | Iteration number: [170/4518] 3% | Training loss: 0.6908798975103042
Epoch: 87 | Iteration number: [180/4518] 3% | Training loss: 0.6905725108252632
Epoch: 87 | Iteration number: [190/4518] 4% | Training loss: 0.690388056792711
Epoch: 87 | Iteration number: [200/4518] 4% | Training loss: 0.6901904293894767
Epoch: 87 | Iteration number: [210/4518] 4% | Training loss: 0.6900556919120607
Epoch: 87 | Iteration number: [220/4518] 4% | Training loss: 0.689903995665637
Epoch: 87 | Iteration number: [230/4518] 5% | Training loss: 0.6896928362224413
Epoch: 87 | Iteration number: [240/4518] 5% | Training loss: 0.6895564762254556
Epoch: 87 | Iteration number: [250/4518] 5% | Training loss: 0.6894421110153198
Epoch: 87 | Iteration number: [260/4518] 5% | Training loss: 0.6892999144700858
Epoch: 87 | Iteration number: [270/4518] 5% | Training loss: 0.6892455032578221
Epoch: 87 | Iteration number: [280/4518] 6% | Training loss: 0.6891465461679868
Epoch: 87 | Iteration number: [290/4518] 6% | Training loss: 0.6890739584791249
Epoch: 87 | Iteration number: [300/4518] 6% | Training loss: 0.6889909078677495
Epoch: 87 | Iteration number: [310/4518] 6% | Training loss: 0.6889471634741753
Epoch: 87 | Iteration number: [320/4518] 7% | Training loss: 0.688901842571795
Epoch: 87 | Iteration number: [330/4518] 7% | Training loss: 0.6888436458327554
Epoch: 87 | Iteration number: [340/4518] 7% | Training loss: 0.6888172451187583
Epoch: 87 | Iteration number: [350/4518] 7% | Training loss: 0.6887803365503039
Epoch: 87 | Iteration number: [360/4518] 7% | Training loss: 0.6887746723161803
Epoch: 87 | Iteration number: [370/4518] 8% | Training loss: 0.6887473865135296
Epoch: 87 | Iteration number: [380/4518] 8% | Training loss: 0.6886700446668425
Epoch: 87 | Iteration number: [390/4518] 8% | Training loss: 0.6886242033579411
Epoch: 87 | Iteration number: [400/4518] 8% | Training loss: 0.6885876096785069
Epoch: 87 | Iteration number: [410/4518] 9% | Training loss: 0.688523823458974
Epoch: 87 | Iteration number: [420/4518] 9% | Training loss: 0.6884610495397023
Epoch: 87 | Iteration number: [430/4518] 9% | Training loss: 0.6884106579215028
Epoch: 87 | Iteration number: [440/4518] 9% | Training loss: 0.6883638377894055
Epoch: 87 | Iteration number: [450/4518] 9% | Training loss: 0.6883229927221934
Epoch: 87 | Iteration number: [460/4518] 10% | Training loss: 0.6882819681063942
Epoch: 87 | Iteration number: [470/4518] 10% | Training loss: 0.6882507835296874
Epoch: 87 | Iteration number: [480/4518] 10% | Training loss: 0.688211698209246
Epoch: 87 | Iteration number: [490/4518] 10% | Training loss: 0.6881882101905589
Epoch: 87 | Iteration number: [500/4518] 11% | Training loss: 0.6881671072244644
Epoch: 87 | Iteration number: [510/4518] 11% | Training loss: 0.6881249762048909
Epoch: 87 | Iteration number: [520/4518] 11% | Training loss: 0.6881053877564577
Epoch: 87 | Iteration number: [530/4518] 11% | Training loss: 0.6880516996923483
Epoch: 87 | Iteration number: [540/4518] 11% | Training loss: 0.6880326251188914
Epoch: 87 | Iteration number: [550/4518] 12% | Training loss: 0.687995935678482
Epoch: 87 | Iteration number: [560/4518] 12% | Training loss: 0.687980001951967
Epoch: 87 | Iteration number: [570/4518] 12% | Training loss: 0.6879382983634347
Epoch: 87 | Iteration number: [580/4518] 12% | Training loss: 0.6879016146577638
Epoch: 87 | Iteration number: [590/4518] 13% | Training loss: 0.6878888136249478
Epoch: 87 | Iteration number: [600/4518] 13% | Training loss: 0.6878888909022013
Epoch: 87 | Iteration number: [610/4518] 13% | Training loss: 0.687851032077289
Epoch: 87 | Iteration number: [620/4518] 13% | Training loss: 0.6878184708856767
Epoch: 87 | Iteration number: [630/4518] 13% | Training loss: 0.6878137251687428
Epoch: 87 | Iteration number: [640/4518] 14% | Training loss: 0.687810034584254
Epoch: 87 | Iteration number: [650/4518] 14% | Training loss: 0.6878029054861803
Epoch: 87 | Iteration number: [660/4518] 14% | Training loss: 0.6878140370954167
Epoch: 87 | Iteration number: [670/4518] 14% | Training loss: 0.6878162722089397
Epoch: 87 | Iteration number: [680/4518] 15% | Training loss: 0.6878309357692214
Epoch: 87 | Iteration number: [690/4518] 15% | Training loss: 0.6878181388412696
Epoch: 87 | Iteration number: [700/4518] 15% | Training loss: 0.6878017755917141
Epoch: 87 | Iteration number: [710/4518] 15% | Training loss: 0.6878007397685253
Epoch: 87 | Iteration number: [720/4518] 15% | Training loss: 0.6877866123285559
Epoch: 87 | Iteration number: [730/4518] 16% | Training loss: 0.6877697116708102
Epoch: 87 | Iteration number: [740/4518] 16% | Training loss: 0.6877394463564899
Epoch: 87 | Iteration number: [750/4518] 16% | Training loss: 0.6877344191074372
Epoch: 87 | Iteration number: [760/4518] 16% | Training loss: 0.6876909383033452
Epoch: 87 | Iteration number: [770/4518] 17% | Training loss: 0.6876880192137383
Epoch: 87 | Iteration number: [780/4518] 17% | Training loss: 0.6876579030201986
Epoch: 87 | Iteration number: [790/4518] 17% | Training loss: 0.6876450204396549
Epoch: 87 | Iteration number: [800/4518] 17% | Training loss: 0.6876322815567255
Epoch: 87 | Iteration number: [810/4518] 17% | Training loss: 0.6876266176317944
Epoch: 87 | Iteration number: [820/4518] 18% | Training loss: 0.6876208838893146
Epoch: 87 | Iteration number: [830/4518] 18% | Training loss: 0.6876219641013318
Epoch: 87 | Iteration number: [840/4518] 18% | Training loss: 0.6875999663557325
Epoch: 87 | Iteration number: [850/4518] 18% | Training loss: 0.687588839040083
Epoch: 87 | Iteration number: [860/4518] 19% | Training loss: 0.6875791720872702
Epoch: 87 | Iteration number: [870/4518] 19% | Training loss: 0.6875654385007661
Epoch: 87 | Iteration number: [880/4518] 19% | Training loss: 0.6875558104027402
Epoch: 87 | Iteration number: [890/4518] 19% | Training loss: 0.6875417141432173
Epoch: 87 | Iteration number: [900/4518] 19% | Training loss: 0.6875467713011636
Epoch: 87 | Iteration number: [910/4518] 20% | Training loss: 0.6875466185611683
Epoch: 87 | Iteration number: [920/4518] 20% | Training loss: 0.6875366701380067
Epoch: 87 | Iteration number: [930/4518] 20% | Training loss: 0.6875336422715136
Epoch: 87 | Iteration number: [940/4518] 20% | Training loss: 0.6875294773502553
Epoch: 87 | Iteration number: [950/4518] 21% | Training loss: 0.6875200114752117
Epoch: 87 | Iteration number: [960/4518] 21% | Training loss: 0.6875219920029243
Epoch: 87 | Iteration number: [970/4518] 21% | Training loss: 0.6875166223835699
Epoch: 87 | Iteration number: [980/4518] 21% | Training loss: 0.6875074955273648
Epoch: 87 | Iteration number: [990/4518] 21% | Training loss: 0.6875158604347344
Epoch: 87 | Iteration number: [1000/4518] 22% | Training loss: 0.6875078517794609
Epoch: 87 | Iteration number: [1010/4518] 22% | Training loss: 0.6875024927724706
Epoch: 87 | Iteration number: [1020/4518] 22% | Training loss: 0.6874794140165927
Epoch: 87 | Iteration number: [1030/4518] 22% | Training loss: 0.687475921228094
Epoch: 87 | Iteration number: [1040/4518] 23% | Training loss: 0.6874673970043659
Epoch: 87 | Iteration number: [1050/4518] 23% | Training loss: 0.6874511045501346
Epoch: 87 | Iteration number: [1060/4518] 23% | Training loss: 0.6874485697948708
Epoch: 87 | Iteration number: [1070/4518] 23% | Training loss: 0.6874417551767046
Epoch: 87 | Iteration number: [1080/4518] 23% | Training loss: 0.6874273916637456
Epoch: 87 | Iteration number: [1090/4518] 24% | Training loss: 0.6874184291843974
Epoch: 87 | Iteration number: [1100/4518] 24% | Training loss: 0.687426122806289
Epoch: 87 | Iteration number: [1110/4518] 24% | Training loss: 0.6874209972652229
Epoch: 87 | Iteration number: [1120/4518] 24% | Training loss: 0.6874182224805866
Epoch: 87 | Iteration number: [1130/4518] 25% | Training loss: 0.6874112103365164
Epoch: 87 | Iteration number: [1140/4518] 25% | Training loss: 0.6874159840638178
Epoch: 87 | Iteration number: [1150/4518] 25% | Training loss: 0.6873988749151645
Epoch: 87 | Iteration number: [1160/4518] 25% | Training loss: 0.6873937174677849
Epoch: 87 | Iteration number: [1170/4518] 25% | Training loss: 0.6873850098532489
Epoch: 87 | Iteration number: [1180/4518] 26% | Training loss: 0.6873797028751697
Epoch: 87 | Iteration number: [1190/4518] 26% | Training loss: 0.687367736842452
Epoch: 87 | Iteration number: [1200/4518] 26% | Training loss: 0.6873714309434096
Epoch: 87 | Iteration number: [1210/4518] 26% | Training loss: 0.6873771985207707
Epoch: 87 | Iteration number: [1220/4518] 27% | Training loss: 0.6873712419974999
Epoch: 87 | Iteration number: [1230/4518] 27% | Training loss: 0.6873598549424148
Epoch: 87 | Iteration number: [1240/4518] 27% | Training loss: 0.6873579789073236
Epoch: 87 | Iteration number: [1250/4518] 27% | Training loss: 0.6873524200439454
Epoch: 87 | Iteration number: [1260/4518] 27% | Training loss: 0.6873387737879677
Epoch: 87 | Iteration number: [1270/4518] 28% | Training loss: 0.687339270490361
Epoch: 87 | Iteration number: [1280/4518] 28% | Training loss: 0.6873394572176039
Epoch: 87 | Iteration number: [1290/4518] 28% | Training loss: 0.6873312329137048
Epoch: 87 | Iteration number: [1300/4518] 28% | Training loss: 0.6873183901034868
Epoch: 87 | Iteration number: [1310/4518] 28% | Training loss: 0.6873083176503655
Epoch: 87 | Iteration number: [1320/4518] 29% | Training loss: 0.6873030384833162
Epoch: 87 | Iteration number: [1330/4518] 29% | Training loss: 0.6872991269692442
Epoch: 87 | Iteration number: [1340/4518] 29% | Training loss: 0.6872826481043403
Epoch: 87 | Iteration number: [1350/4518] 29% | Training loss: 0.6872807453738319
Epoch: 87 | Iteration number: [1360/4518] 30% | Training loss: 0.6872658476671751
Epoch: 87 | Iteration number: [1370/4518] 30% | Training loss: 0.6872606812602412
Epoch: 87 | Iteration number: [1380/4518] 30% | Training loss: 0.6872460684050684
Epoch: 87 | Iteration number: [1390/4518] 30% | Training loss: 0.6872381498916543
Epoch: 87 | Iteration number: [1400/4518] 30% | Training loss: 0.6872276416420937
Epoch: 87 | Iteration number: [1410/4518] 31% | Training loss: 0.6872241439971518
Epoch: 87 | Iteration number: [1420/4518] 31% | Training loss: 0.6872150453463407
Epoch: 87 | Iteration number: [1430/4518] 31% | Training loss: 0.6872071343285221
Epoch: 87 | Iteration number: [1440/4518] 31% | Training loss: 0.6872023019111819
Epoch: 87 | Iteration number: [1450/4518] 32% | Training loss: 0.687195079984336
Epoch: 87 | Iteration number: [1460/4518] 32% | Training loss: 0.6871963644272661
Epoch: 87 | Iteration number: [1470/4518] 32% | Training loss: 0.6872032559242378
Epoch: 87 | Iteration number: [1480/4518] 32% | Training loss: 0.6871911713803137
Epoch: 87 | Iteration number: [1490/4518] 32% | Training loss: 0.687184846201199
Epoch: 87 | Iteration number: [1500/4518] 33% | Training loss: 0.6871780689954757
Epoch: 87 | Iteration number: [1510/4518] 33% | Training loss: 0.6871696703481358
Epoch: 87 | Iteration number: [1520/4518] 33% | Training loss: 0.6871627641743735
Epoch: 87 | Iteration number: [1530/4518] 33% | Training loss: 0.6871617814684226
Epoch: 87 | Iteration number: [1540/4518] 34% | Training loss: 0.68716481726665
Epoch: 87 | Iteration number: [1550/4518] 34% | Training loss: 0.6871637429345039
Epoch: 87 | Iteration number: [1560/4518] 34% | Training loss: 0.6871565972765287
Epoch: 87 | Iteration number: [1570/4518] 34% | Training loss: 0.6871514703058134
Epoch: 87 | Iteration number: [1580/4518] 34% | Training loss: 0.687153023556818
Epoch: 87 | Iteration number: [1590/4518] 35% | Training loss: 0.6871545025762522
Epoch: 87 | Iteration number: [1600/4518] 35% | Training loss: 0.6871549336984754
Epoch: 87 | Iteration number: [1610/4518] 35% | Training loss: 0.6871633262367722
Epoch: 87 | Iteration number: [1620/4518] 35% | Training loss: 0.6871686942047543
Epoch: 87 | Iteration number: [1630/4518] 36% | Training loss: 0.6871697679619116
Epoch: 87 | Iteration number: [1640/4518] 36% | Training loss: 0.6871705866078052
Epoch: 87 | Iteration number: [1650/4518] 36% | Training loss: 0.6871602061300567
Epoch: 87 | Iteration number: [1660/4518] 36% | Training loss: 0.687163522121418
Epoch: 87 | Iteration number: [1670/4518] 36% | Training loss: 0.6871559896511946
Epoch: 87 | Iteration number: [1680/4518] 37% | Training loss: 0.6871577210724353
Epoch: 87 | Iteration number: [1690/4518] 37% | Training loss: 0.6871526526628867
Epoch: 87 | Iteration number: [1700/4518] 37% | Training loss: 0.6871476771200404
Epoch: 87 | Iteration number: [1710/4518] 37% | Training loss: 0.6871481305325937
Epoch: 87 | Iteration number: [1720/4518] 38% | Training loss: 0.6871551490107248
Epoch: 87 | Iteration number: [1730/4518] 38% | Training loss: 0.6871531518553033
Epoch: 87 | Iteration number: [1740/4518] 38% | Training loss: 0.6871543090576413
Epoch: 87 | Iteration number: [1750/4518] 38% | Training loss: 0.6871403498649598
Epoch: 87 | Iteration number: [1760/4518] 38% | Training loss: 0.6871393150565299
Epoch: 87 | Iteration number: [1770/4518] 39% | Training loss: 0.6871378285063189
Epoch: 87 | Iteration number: [1780/4518] 39% | Training loss: 0.6871354161018736
Epoch: 87 | Iteration number: [1790/4518] 39% | Training loss: 0.6871317356991369
Epoch: 87 | Iteration number: [1800/4518] 39% | Training loss: 0.687127412226465
Epoch: 87 | Iteration number: [1810/4518] 40% | Training loss: 0.687125330834099
Epoch: 87 | Iteration number: [1820/4518] 40% | Training loss: 0.6871208898313753
Epoch: 87 | Iteration number: [1830/4518] 40% | Training loss: 0.6871133748625146
Epoch: 87 | Iteration number: [1840/4518] 40% | Training loss: 0.6871109924886538
Epoch: 87 | Iteration number: [1850/4518] 40% | Training loss: 0.6871047512582831
Epoch: 87 | Iteration number: [1860/4518] 41% | Training loss: 0.6871069846935169
Epoch: 87 | Iteration number: [1870/4518] 41% | Training loss: 0.6871085941154051
Epoch: 87 | Iteration number: [1880/4518] 41% | Training loss: 0.6871046452446187
Epoch: 87 | Iteration number: [1890/4518] 41% | Training loss: 0.68709755060534
Epoch: 87 | Iteration number: [1900/4518] 42% | Training loss: 0.6870930242538452
Epoch: 87 | Iteration number: [1910/4518] 42% | Training loss: 0.6870929409072037
Epoch: 87 | Iteration number: [1920/4518] 42% | Training loss: 0.6870965517746905
Epoch: 87 | Iteration number: [1930/4518] 42% | Training loss: 0.6870960175682226
Epoch: 87 | Iteration number: [1940/4518] 42% | Training loss: 0.6870965125634498
Epoch: 87 | Iteration number: [1950/4518] 43% | Training loss: 0.687094671298296
Epoch: 87 | Iteration number: [1960/4518] 43% | Training loss: 0.6870883825786259
Epoch: 87 | Iteration number: [1970/4518] 43% | Training loss: 0.6870871908168502
Epoch: 87 | Iteration number: [1980/4518] 43% | Training loss: 0.6870825855719923
Epoch: 87 | Iteration number: [1990/4518] 44% | Training loss: 0.6870836313944965
Epoch: 87 | Iteration number: [2000/4518] 44% | Training loss: 0.6870814687311649
Epoch: 87 | Iteration number: [2010/4518] 44% | Training loss: 0.6870789268123569
Epoch: 87 | Iteration number: [2020/4518] 44% | Training loss: 0.6870828157899403
Epoch: 87 | Iteration number: [2030/4518] 44% | Training loss: 0.6870805255297957
Epoch: 87 | Iteration number: [2040/4518] 45% | Training loss: 0.687072074793133
Epoch: 87 | Iteration number: [2050/4518] 45% | Training loss: 0.6870741651697857
Epoch: 87 | Iteration number: [2060/4518] 45% | Training loss: 0.6870695914747645
Epoch: 87 | Iteration number: [2070/4518] 45% | Training loss: 0.6870674280152804
Epoch: 87 | Iteration number: [2080/4518] 46% | Training loss: 0.6870681004455457
Epoch: 87 | Iteration number: [2090/4518] 46% | Training loss: 0.6870727663690394
Epoch: 87 | Iteration number: [2100/4518] 46% | Training loss: 0.6870708400862557
Epoch: 87 | Iteration number: [2110/4518] 46% | Training loss: 0.687067130363383
Epoch: 87 | Iteration number: [2120/4518] 46% | Training loss: 0.6870602339787303
Epoch: 87 | Iteration number: [2130/4518] 47% | Training loss: 0.687058445937197
Epoch: 87 | Iteration number: [2140/4518] 47% | Training loss: 0.6870587653645845
Epoch: 87 | Iteration number: [2150/4518] 47% | Training loss: 0.687059475516164
Epoch: 87 | Iteration number: [2160/4518] 47% | Training loss: 0.6870603842591798
Epoch: 87 | Iteration number: [2170/4518] 48% | Training loss: 0.6870596604687828
Epoch: 87 | Iteration number: [2180/4518] 48% | Training loss: 0.6870629113475117
Epoch: 87 | Iteration number: [2190/4518] 48% | Training loss: 0.6870639937381222
Epoch: 87 | Iteration number: [2200/4518] 48% | Training loss: 0.6870660722526637
Epoch: 87 | Iteration number: [2210/4518] 48% | Training loss: 0.687071898107615
Epoch: 87 | Iteration number: [2220/4518] 49% | Training loss: 0.687078716411247
Epoch: 87 | Iteration number: [2230/4518] 49% | Training loss: 0.6870708059836931
Epoch: 87 | Iteration number: [2240/4518] 49% | Training loss: 0.6870641315355897
Epoch: 87 | Iteration number: [2250/4518] 49% | Training loss: 0.6870637884140015
Epoch: 87 | Iteration number: [2260/4518] 50% | Training loss: 0.6870589967850035
Epoch: 87 | Iteration number: [2270/4518] 50% | Training loss: 0.6870589808745531
Epoch: 87 | Iteration number: [2280/4518] 50% | Training loss: 0.6870602945486705
Epoch: 87 | Iteration number: [2290/4518] 50% | Training loss: 0.6870632488134126
Epoch: 87 | Iteration number: [2300/4518] 50% | Training loss: 0.6870591824987661
Epoch: 87 | Iteration number: [2310/4518] 51% | Training loss: 0.6870595241005802
Epoch: 87 | Iteration number: [2320/4518] 51% | Training loss: 0.6870643511928362
Epoch: 87 | Iteration number: [2330/4518] 51% | Training loss: 0.6870663357650774
Epoch: 87 | Iteration number: [2340/4518] 51% | Training loss: 0.6870633619463342
Epoch: 87 | Iteration number: [2350/4518] 52% | Training loss: 0.687063010144741
Epoch: 87 | Iteration number: [2360/4518] 52% | Training loss: 0.6870652755185709
Epoch: 87 | Iteration number: [2370/4518] 52% | Training loss: 0.6870626699320878
Epoch: 87 | Iteration number: [2380/4518] 52% | Training loss: 0.6870590991082312
Epoch: 87 | Iteration number: [2390/4518] 52% | Training loss: 0.6870629981721296
Epoch: 87 | Iteration number: [2400/4518] 53% | Training loss: 0.6870614519466957
Epoch: 87 | Iteration number: [2410/4518] 53% | Training loss: 0.687060653297733
Epoch: 87 | Iteration number: [2420/4518] 53% | Training loss: 0.6870537580044802
Epoch: 87 | Iteration number: [2430/4518] 53% | Training loss: 0.6870539904376607
Epoch: 87 | Iteration number: [2440/4518] 54% | Training loss: 0.6870562011345488
Epoch: 87 | Iteration number: [2450/4518] 54% | Training loss: 0.6870500183835322
Epoch: 87 | Iteration number: [2460/4518] 54% | Training loss: 0.6870511860139971
Epoch: 87 | Iteration number: [2470/4518] 54% | Training loss: 0.6870469285650291
Epoch: 87 | Iteration number: [2480/4518] 54% | Training loss: 0.687042791492516
Epoch: 87 | Iteration number: [2490/4518] 55% | Training loss: 0.68704044340126
Epoch: 87 | Iteration number: [2500/4518] 55% | Training loss: 0.6870384925365448
Epoch: 87 | Iteration number: [2510/4518] 55% | Training loss: 0.6870335794777509
Epoch: 87 | Iteration number: [2520/4518] 55% | Training loss: 0.6870370848074792
Epoch: 87 | Iteration number: [2530/4518] 55% | Training loss: 0.6870338818772508
Epoch: 87 | Iteration number: [2540/4518] 56% | Training loss: 0.6870359852088718
Epoch: 87 | Iteration number: [2550/4518] 56% | Training loss: 0.6870362792061825
Epoch: 87 | Iteration number: [2560/4518] 56% | Training loss: 0.6870355767430738
Epoch: 87 | Iteration number: [2570/4518] 56% | Training loss: 0.6870308965328602
Epoch: 87 | Iteration number: [2580/4518] 57% | Training loss: 0.6870318547006725
Epoch: 87 | Iteration number: [2590/4518] 57% | Training loss: 0.6870264854440358
Epoch: 87 | Iteration number: [2600/4518] 57% | Training loss: 0.6870243468422156
Epoch: 87 | Iteration number: [2610/4518] 57% | Training loss: 0.6870213532356467
Epoch: 87 | Iteration number: [2620/4518] 57% | Training loss: 0.6870170135761945
Epoch: 87 | Iteration number: [2630/4518] 58% | Training loss: 0.6870146252583188
Epoch: 87 | Iteration number: [2640/4518] 58% | Training loss: 0.6870123349355929
Epoch: 87 | Iteration number: [2650/4518] 58% | Training loss: 0.6870126204445677
Epoch: 87 | Iteration number: [2660/4518] 58% | Training loss: 0.6870135492176042
Epoch: 87 | Iteration number: [2670/4518] 59% | Training loss: 0.6870073437690735
Epoch: 87 | Iteration number: [2680/4518] 59% | Training loss: 0.6870070694320237
Epoch: 87 | Iteration number: [2690/4518] 59% | Training loss: 0.6870089733689247
Epoch: 87 | Iteration number: [2700/4518] 59% | Training loss: 0.6870073767944619
Epoch: 87 | Iteration number: [2710/4518] 59% | Training loss: 0.6870080064363585
Epoch: 87 | Iteration number: [2720/4518] 60% | Training loss: 0.6870041926994043
Epoch: 87 | Iteration number: [2730/4518] 60% | Training loss: 0.687007780673303
Epoch: 87 | Iteration number: [2740/4518] 60% | Training loss: 0.687003491721014
Epoch: 87 | Iteration number: [2750/4518] 60% | Training loss: 0.6869994546933608
Epoch: 87 | Iteration number: [2760/4518] 61% | Training loss: 0.686999479022579
Epoch: 87 | Iteration number: [2770/4518] 61% | Training loss: 0.6869956009224434
Epoch: 87 | Iteration number: [2780/4518] 61% | Training loss: 0.6869928498705514
Epoch: 87 | Iteration number: [2790/4518] 61% | Training loss: 0.686992956297372
Epoch: 87 | Iteration number: [2800/4518] 61% | Training loss: 0.6869911837152073
Epoch: 87 | Iteration number: [2810/4518] 62% | Training loss: 0.6869905574678102
Epoch: 87 | Iteration number: [2820/4518] 62% | Training loss: 0.6869921167268821
Epoch: 87 | Iteration number: [2830/4518] 62% | Training loss: 0.6869930244797953
Epoch: 87 | Iteration number: [2840/4518] 62% | Training loss: 0.6869918549354648
Epoch: 87 | Iteration number: [2850/4518] 63% | Training loss: 0.6869978504850154
Epoch: 87 | Iteration number: [2860/4518] 63% | Training loss: 0.6869988300375172
Epoch: 87 | Iteration number: [2870/4518] 63% | Training loss: 0.6869993402359793
Epoch: 87 | Iteration number: [2880/4518] 63% | Training loss: 0.6869962329251899
Epoch: 87 | Iteration number: [2890/4518] 63% | Training loss: 0.6869982326525718
Epoch: 87 | Iteration number: [2900/4518] 64% | Training loss: 0.6869968419856038
Epoch: 87 | Iteration number: [2910/4518] 64% | Training loss: 0.6869911173364961
Epoch: 87 | Iteration number: [2920/4518] 64% | Training loss: 0.6869883122713598
Epoch: 87 | Iteration number: [2930/4518] 64% | Training loss: 0.6869888697671402
Epoch: 87 | Iteration number: [2940/4518] 65% | Training loss: 0.6869862591733737
Epoch: 87 | Iteration number: [2950/4518] 65% | Training loss: 0.686987575434022
Epoch: 87 | Iteration number: [2960/4518] 65% | Training loss: 0.6869872238587689
Epoch: 87 | Iteration number: [2970/4518] 65% | Training loss: 0.6869883068884262
Epoch: 87 | Iteration number: [2980/4518] 65% | Training loss: 0.6869861680789282
Epoch: 87 | Iteration number: [2990/4518] 66% | Training loss: 0.6869862051113792
Epoch: 87 | Iteration number: [3000/4518] 66% | Training loss: 0.6869876670837403
Epoch: 87 | Iteration number: [3010/4518] 66% | Training loss: 0.6869867001855097
Epoch: 87 | Iteration number: [3020/4518] 66% | Training loss: 0.6869856611979718
Epoch: 87 | Iteration number: [3030/4518] 67% | Training loss: 0.6869858798020744
Epoch: 87 | Iteration number: [3040/4518] 67% | Training loss: 0.6869793828772871
Epoch: 87 | Iteration number: [3050/4518] 67% | Training loss: 0.6869775308546473
Epoch: 87 | Iteration number: [3060/4518] 67% | Training loss: 0.6869766419229943
Epoch: 87 | Iteration number: [3070/4518] 67% | Training loss: 0.6869755973645064
Epoch: 87 | Iteration number: [3080/4518] 68% | Training loss: 0.6869763159326144
Epoch: 87 | Iteration number: [3090/4518] 68% | Training loss: 0.6869735824251638
Epoch: 87 | Iteration number: [3100/4518] 68% | Training loss: 0.6869731862891105
Epoch: 87 | Iteration number: [3110/4518] 68% | Training loss: 0.6869736147846823
Epoch: 87 | Iteration number: [3120/4518] 69% | Training loss: 0.6869763641785352
Epoch: 87 | Iteration number: [3130/4518] 69% | Training loss: 0.6869758106077822
Epoch: 87 | Iteration number: [3140/4518] 69% | Training loss: 0.6869766313938578
Epoch: 87 | Iteration number: [3150/4518] 69% | Training loss: 0.6869746926095751
Epoch: 87 | Iteration number: [3160/4518] 69% | Training loss: 0.6869743660658221
Epoch: 87 | Iteration number: [3170/4518] 70% | Training loss: 0.6869707107167891
Epoch: 87 | Iteration number: [3180/4518] 70% | Training loss: 0.6869683664362386
Epoch: 87 | Iteration number: [3190/4518] 70% | Training loss: 0.6869617626024264
Epoch: 87 | Iteration number: [3200/4518] 70% | Training loss: 0.6869629262387753
Epoch: 87 | Iteration number: [3210/4518] 71% | Training loss: 0.6869642126783032
Epoch: 87 | Iteration number: [3220/4518] 71% | Training loss: 0.6869600153487662
Epoch: 87 | Iteration number: [3230/4518] 71% | Training loss: 0.6869623651999069
Epoch: 87 | Iteration number: [3240/4518] 71% | Training loss: 0.6869597368218281
Epoch: 87 | Iteration number: [3250/4518] 71% | Training loss: 0.6869596231167133
Epoch: 87 | Iteration number: [3260/4518] 72% | Training loss: 0.6869611039849147
Epoch: 87 | Iteration number: [3270/4518] 72% | Training loss: 0.6869625458294463
Epoch: 87 | Iteration number: [3280/4518] 72% | Training loss: 0.6869677847115004
Epoch: 87 | Iteration number: [3290/4518] 72% | Training loss: 0.6869681884271396
Epoch: 87 | Iteration number: [3300/4518] 73% | Training loss: 0.6869666423400244
Epoch: 87 | Iteration number: [3310/4518] 73% | Training loss: 0.6869668535595574
Epoch: 87 | Iteration number: [3320/4518] 73% | Training loss: 0.6869666070284614
Epoch: 87 | Iteration number: [3330/4518] 73% | Training loss: 0.6869635471710571
Epoch: 87 | Iteration number: [3340/4518] 73% | Training loss: 0.6869613239686646
Epoch: 87 | Iteration number: [3350/4518] 74% | Training loss: 0.686959943059665
Epoch: 87 | Iteration number: [3360/4518] 74% | Training loss: 0.686958706538592
Epoch: 87 | Iteration number: [3370/4518] 74% | Training loss: 0.6869571298979864
Epoch: 87 | Iteration number: [3380/4518] 74% | Training loss: 0.6869518819468967
Epoch: 87 | Iteration number: [3390/4518] 75% | Training loss: 0.6869538987104872
Epoch: 87 | Iteration number: [3400/4518] 75% | Training loss: 0.686957378159551
Epoch: 87 | Iteration number: [3410/4518] 75% | Training loss: 0.6869592147488748
Epoch: 87 | Iteration number: [3420/4518] 75% | Training loss: 0.6869590613054253
Epoch: 87 | Iteration number: [3430/4518] 75% | Training loss: 0.6869564894510776
Epoch: 87 | Iteration number: [3440/4518] 76% | Training loss: 0.6869601175015749
Epoch: 87 | Iteration number: [3450/4518] 76% | Training loss: 0.6869633516194164
Epoch: 87 | Iteration number: [3460/4518] 76% | Training loss: 0.6869568402539787
Epoch: 87 | Iteration number: [3470/4518] 76% | Training loss: 0.686956476478137
Epoch: 87 | Iteration number: [3480/4518] 77% | Training loss: 0.6869563841442953
Epoch: 87 | Iteration number: [3490/4518] 77% | Training loss: 0.6869588322318386
Epoch: 87 | Iteration number: [3500/4518] 77% | Training loss: 0.6869564295836857
Epoch: 87 | Iteration number: [3510/4518] 77% | Training loss: 0.6869571543317236
Epoch: 87 | Iteration number: [3520/4518] 77% | Training loss: 0.6869574585082856
Epoch: 87 | Iteration number: [3530/4518] 78% | Training loss: 0.6869549031467006
Epoch: 87 | Iteration number: [3540/4518] 78% | Training loss: 0.6869544719066997
Epoch: 87 | Iteration number: [3550/4518] 78% | Training loss: 0.6869554147586017
Epoch: 87 | Iteration number: [3560/4518] 78% | Training loss: 0.6869543204481682
Epoch: 87 | Iteration number: [3570/4518] 79% | Training loss: 0.6869545070397086
Epoch: 87 | Iteration number: [3580/4518] 79% | Training loss: 0.6869529242955107
Epoch: 87 | Iteration number: [3590/4518] 79% | Training loss: 0.6869488529176101
Epoch: 87 | Iteration number: [3600/4518] 79% | Training loss: 0.6869505876964993
Epoch: 87 | Iteration number: [3610/4518] 79% | Training loss: 0.6869497023626048
Epoch: 87 | Iteration number: [3620/4518] 80% | Training loss: 0.6869476448271156
Epoch: 87 | Iteration number: [3630/4518] 80% | Training loss: 0.6869436523966881
Epoch: 87 | Iteration number: [3640/4518] 80% | Training loss: 0.6869422505845081
Epoch: 87 | Iteration number: [3650/4518] 80% | Training loss: 0.6869418619266928
Epoch: 87 | Iteration number: [3660/4518] 81% | Training loss: 0.6869407687682272
Epoch: 87 | Iteration number: [3670/4518] 81% | Training loss: 0.6869430507236346
Epoch: 87 | Iteration number: [3680/4518] 81% | Training loss: 0.6869452160175727
Epoch: 87 | Iteration number: [3690/4518] 81% | Training loss: 0.686944135288559
Epoch: 87 | Iteration number: [3700/4518] 81% | Training loss: 0.6869447398024636
Epoch: 87 | Iteration number: [3710/4518] 82% | Training loss: 0.6869432209154988
Epoch: 87 | Iteration number: [3720/4518] 82% | Training loss: 0.6869464461841891
Epoch: 87 | Iteration number: [3730/4518] 82% | Training loss: 0.686946199662564
Epoch: 87 | Iteration number: [3740/4518] 82% | Training loss: 0.6869473049028672
Epoch: 87 | Iteration number: [3750/4518] 83% | Training loss: 0.6869488424142202
Epoch: 87 | Iteration number: [3760/4518] 83% | Training loss: 0.6869477770747022
Epoch: 87 | Iteration number: [3770/4518] 83% | Training loss: 0.6869456114598231
Epoch: 87 | Iteration number: [3780/4518] 83% | Training loss: 0.6869449501945859
Epoch: 87 | Iteration number: [3790/4518] 83% | Training loss: 0.6869449973735458
Epoch: 87 | Iteration number: [3800/4518] 84% | Training loss: 0.6869465274246116
Epoch: 87 | Iteration number: [3810/4518] 84% | Training loss: 0.6869472412612494
Epoch: 87 | Iteration number: [3820/4518] 84% | Training loss: 0.686942511484885
Epoch: 87 | Iteration number: [3830/4518] 84% | Training loss: 0.6869395231142368
Epoch: 87 | Iteration number: [3840/4518] 84% | Training loss: 0.6869406217553963
Epoch: 87 | Iteration number: [3850/4518] 85% | Training loss: 0.6869401346398638
Epoch: 87 | Iteration number: [3860/4518] 85% | Training loss: 0.6869414214179923
Epoch: 87 | Iteration number: [3870/4518] 85% | Training loss: 0.6869402048199675
Epoch: 87 | Iteration number: [3880/4518] 85% | Training loss: 0.686938239587951
Epoch: 87 | Iteration number: [3890/4518] 86% | Training loss: 0.6869357596479528
Epoch: 87 | Iteration number: [3900/4518] 86% | Training loss: 0.6869366023785028
Epoch: 87 | Iteration number: [3910/4518] 86% | Training loss: 0.6869330969308038
Epoch: 87 | Iteration number: [3920/4518] 86% | Training loss: 0.6869344775621988
Epoch: 87 | Iteration number: [3930/4518] 86% | Training loss: 0.6869312442592689
Epoch: 87 | Iteration number: [3940/4518] 87% | Training loss: 0.6869268778465726
Epoch: 87 | Iteration number: [3950/4518] 87% | Training loss: 0.6869261066219474
Epoch: 87 | Iteration number: [3960/4518] 87% | Training loss: 0.6869264397055211
Epoch: 87 | Iteration number: [3970/4518] 87% | Training loss: 0.6869232384624049
Epoch: 87 | Iteration number: [3980/4518] 88% | Training loss: 0.6869227966022252
Epoch: 87 | Iteration number: [3990/4518] 88% | Training loss: 0.6869227111488955
Epoch: 87 | Iteration number: [4000/4518] 88% | Training loss: 0.6869206835031509
Epoch: 87 | Iteration number: [4010/4518] 88% | Training loss: 0.6869219959079476
Epoch: 87 | Iteration number: [4020/4518] 88% | Training loss: 0.6869209399270774
Epoch: 87 | Iteration number: [4030/4518] 89% | Training loss: 0.6869216765718483
Epoch: 87 | Iteration number: [4040/4518] 89% | Training loss: 0.6869217362144205
Epoch: 87 | Iteration number: [4050/4518] 89% | Training loss: 0.6869227714597443
Epoch: 87 | Iteration number: [4060/4518] 89% | Training loss: 0.6869229433131335
Epoch: 87 | Iteration number: [4070/4518] 90% | Training loss: 0.6869207277930632
Epoch: 87 | Iteration number: [4080/4518] 90% | Training loss: 0.6869219259011979
Epoch: 87 | Iteration number: [4090/4518] 90% | Training loss: 0.6869259421429016
Epoch: 87 | Iteration number: [4100/4518] 90% | Training loss: 0.6869273100975083
Epoch: 87 | Iteration number: [4110/4518] 90% | Training loss: 0.6869248147428471
Epoch: 87 | Iteration number: [4120/4518] 91% | Training loss: 0.6869216279931438
Epoch: 87 | Iteration number: [4130/4518] 91% | Training loss: 0.6869212166737702
Epoch: 87 | Iteration number: [4140/4518] 91% | Training loss: 0.6869146779251559
Epoch: 87 | Iteration number: [4150/4518] 91% | Training loss: 0.6869123741661209
Epoch: 87 | Iteration number: [4160/4518] 92% | Training loss: 0.6869145496963308
Epoch: 87 | Iteration number: [4170/4518] 92% | Training loss: 0.6869117619322358
Epoch: 87 | Iteration number: [4180/4518] 92% | Training loss: 0.6869093716144562
Epoch: 87 | Iteration number: [4190/4518] 92% | Training loss: 0.686911996850535
Epoch: 87 | Iteration number: [4200/4518] 92% | Training loss: 0.686914841064385
Epoch: 87 | Iteration number: [4210/4518] 93% | Training loss: 0.6869157788589279
Epoch: 87 | Iteration number: [4220/4518] 93% | Training loss: 0.6869199360292669
Epoch: 87 | Iteration number: [4230/4518] 93% | Training loss: 0.6869178181703491
Epoch: 87 | Iteration number: [4240/4518] 93% | Training loss: 0.6869172787891245
Epoch: 87 | Iteration number: [4250/4518] 94% | Training loss: 0.6869185101144454
Epoch: 87 | Iteration number: [4260/4518] 94% | Training loss: 0.6869182144951932
Epoch: 87 | Iteration number: [4270/4518] 94% | Training loss: 0.6869164692294681
Epoch: 87 | Iteration number: [4280/4518] 94% | Training loss: 0.6869180935844083
Epoch: 87 | Iteration number: [4290/4518] 94% | Training loss: 0.686916407060512
Epoch: 87 | Iteration number: [4300/4518] 95% | Training loss: 0.6869181394577026
Epoch: 87 | Iteration number: [4310/4518] 95% | Training loss: 0.6869196944059739
Epoch: 87 | Iteration number: [4320/4518] 95% | Training loss: 0.6869170400555487
Epoch: 87 | Iteration number: [4330/4518] 95% | Training loss: 0.6869152179215852
Epoch: 87 | Iteration number: [4340/4518] 96% | Training loss: 0.6869155774880115
Epoch: 87 | Iteration number: [4350/4518] 96% | Training loss: 0.6869144727580849
Epoch: 87 | Iteration number: [4360/4518] 96% | Training loss: 0.686912519409569
Epoch: 87 | Iteration number: [4370/4518] 96% | Training loss: 0.686912583104533
Epoch: 87 | Iteration number: [4380/4518] 96% | Training loss: 0.6869102570428152
Epoch: 87 | Iteration number: [4390/4518] 97% | Training loss: 0.6869079318567941
Epoch: 87 | Iteration number: [4400/4518] 97% | Training loss: 0.6869064510681412
Epoch: 87 | Iteration number: [4410/4518] 97% | Training loss: 0.6869059911660867
Epoch: 87 | Iteration number: [4420/4518] 97% | Training loss: 0.6869050133417095
Epoch: 87 | Iteration number: [4430/4518] 98% | Training loss: 0.6869043926756754
Epoch: 87 | Iteration number: [4440/4518] 98% | Training loss: 0.6869066941442791
Epoch: 87 | Iteration number: [4450/4518] 98% | Training loss: 0.6869070156504599
Epoch: 87 | Iteration number: [4460/4518] 98% | Training loss: 0.6869090135722952
Epoch: 87 | Iteration number: [4470/4518] 98% | Training loss: 0.6869081613334767
Epoch: 87 | Iteration number: [4480/4518] 99% | Training loss: 0.6869080747876849
Epoch: 87 | Iteration number: [4490/4518] 99% | Training loss: 0.6869075429864344
Epoch: 87 | Iteration number: [4500/4518] 99% | Training loss: 0.6869092434512244
Epoch: 87 | Iteration number: [4510/4518] 99% | Training loss: 0.6869081130313239

 End of epoch: 87 | Train Loss: 0.6867572332890279 | Training Time: 641 

 End of epoch: 87 | Eval Loss: 0.6897719964689139 | Evaluating Time: 17 
Epoch: 88 | Iteration number: [10/4518] 0% | Training loss: 0.7547863125801086
Epoch: 88 | Iteration number: [20/4518] 0% | Training loss: 0.7204420953989029
Epoch: 88 | Iteration number: [30/4518] 0% | Training loss: 0.7090611219406128
Epoch: 88 | Iteration number: [40/4518] 0% | Training loss: 0.7032476931810379
Epoch: 88 | Iteration number: [50/4518] 1% | Training loss: 0.6996630644798278
Epoch: 88 | Iteration number: [60/4518] 1% | Training loss: 0.697502808769544
Epoch: 88 | Iteration number: [70/4518] 1% | Training loss: 0.6960183365004403
Epoch: 88 | Iteration number: [80/4518] 1% | Training loss: 0.6946631446480751
Epoch: 88 | Iteration number: [90/4518] 1% | Training loss: 0.6937572962707943
Epoch: 88 | Iteration number: [100/4518] 2% | Training loss: 0.6930343800783157
Epoch: 88 | Iteration number: [110/4518] 2% | Training loss: 0.6925082455981861
Epoch: 88 | Iteration number: [120/4518] 2% | Training loss: 0.6921368623773257
Epoch: 88 | Iteration number: [130/4518] 2% | Training loss: 0.6917011843277858
Epoch: 88 | Iteration number: [140/4518] 3% | Training loss: 0.6912665320294243
Epoch: 88 | Iteration number: [150/4518] 3% | Training loss: 0.6910315092404683
Epoch: 88 | Iteration number: [160/4518] 3% | Training loss: 0.6908054068684578
Epoch: 88 | Iteration number: [170/4518] 3% | Training loss: 0.6906493207987617
Epoch: 88 | Iteration number: [180/4518] 3% | Training loss: 0.6905847662025028
Epoch: 88 | Iteration number: [190/4518] 4% | Training loss: 0.6903495747792093
Epoch: 88 | Iteration number: [200/4518] 4% | Training loss: 0.6901830792427063
Epoch: 88 | Iteration number: [210/4518] 4% | Training loss: 0.6900402787185851
Epoch: 88 | Iteration number: [220/4518] 4% | Training loss: 0.6898767612197182
Epoch: 88 | Iteration number: [230/4518] 5% | Training loss: 0.6896892392117044
Epoch: 88 | Iteration number: [240/4518] 5% | Training loss: 0.6895514138042926
Epoch: 88 | Iteration number: [250/4518] 5% | Training loss: 0.6894556438922882
Epoch: 88 | Iteration number: [260/4518] 5% | Training loss: 0.6893370781953518
Epoch: 88 | Iteration number: [270/4518] 5% | Training loss: 0.6892225000593397
Epoch: 88 | Iteration number: [280/4518] 6% | Training loss: 0.6891446473343031
Epoch: 88 | Iteration number: [290/4518] 6% | Training loss: 0.6890622587039553
Epoch: 88 | Iteration number: [300/4518] 6% | Training loss: 0.6889869320392609
Epoch: 88 | Iteration number: [310/4518] 6% | Training loss: 0.6888803920438212
Epoch: 88 | Iteration number: [320/4518] 7% | Training loss: 0.6888065950945019
Epoch: 88 | Iteration number: [330/4518] 7% | Training loss: 0.6887559448227738
Epoch: 88 | Iteration number: [340/4518] 7% | Training loss: 0.6887066821841633
Epoch: 88 | Iteration number: [350/4518] 7% | Training loss: 0.6886696795054844
Epoch: 88 | Iteration number: [360/4518] 7% | Training loss: 0.6886158014337221
Epoch: 88 | Iteration number: [370/4518] 8% | Training loss: 0.6885424862036834
Epoch: 88 | Iteration number: [380/4518] 8% | Training loss: 0.68850606883827
Epoch: 88 | Iteration number: [390/4518] 8% | Training loss: 0.6884924326187525
Epoch: 88 | Iteration number: [400/4518] 8% | Training loss: 0.6884760719537735
Epoch: 88 | Iteration number: [410/4518] 9% | Training loss: 0.6884312442163142
Epoch: 88 | Iteration number: [420/4518] 9% | Training loss: 0.6883804145313445
Epoch: 88 | Iteration number: [430/4518] 9% | Training loss: 0.6883112440275592
Epoch: 88 | Iteration number: [440/4518] 9% | Training loss: 0.6882622004909948
Epoch: 88 | Iteration number: [450/4518] 9% | Training loss: 0.6882230264610715
Epoch: 88 | Iteration number: [460/4518] 10% | Training loss: 0.6881832604822905
Epoch: 88 | Iteration number: [470/4518] 10% | Training loss: 0.688148802645663
Epoch: 88 | Iteration number: [480/4518] 10% | Training loss: 0.6881277311593295
Epoch: 88 | Iteration number: [490/4518] 10% | Training loss: 0.6881200756345477
Epoch: 88 | Iteration number: [500/4518] 11% | Training loss: 0.6881052460670471
Epoch: 88 | Iteration number: [510/4518] 11% | Training loss: 0.6880936733647889
Epoch: 88 | Iteration number: [520/4518] 11% | Training loss: 0.6880579350086359
Epoch: 88 | Iteration number: [530/4518] 11% | Training loss: 0.68803766324835
Epoch: 88 | Iteration number: [540/4518] 11% | Training loss: 0.6880235862952692
Epoch: 88 | Iteration number: [550/4518] 12% | Training loss: 0.6880271681872281
Epoch: 88 | Iteration number: [560/4518] 12% | Training loss: 0.68800271323749
Epoch: 88 | Iteration number: [570/4518] 12% | Training loss: 0.6879689173740253
Epoch: 88 | Iteration number: [580/4518] 12% | Training loss: 0.687929987804643
Epoch: 88 | Iteration number: [590/4518] 13% | Training loss: 0.6879013786881657
Epoch: 88 | Iteration number: [600/4518] 13% | Training loss: 0.6878604873021443
Epoch: 88 | Iteration number: [610/4518] 13% | Training loss: 0.6878294491377033
Epoch: 88 | Iteration number: [620/4518] 13% | Training loss: 0.6878049806241067
Epoch: 88 | Iteration number: [630/4518] 13% | Training loss: 0.6877712806065878
Epoch: 88 | Iteration number: [640/4518] 14% | Training loss: 0.687759464699775
Epoch: 88 | Iteration number: [650/4518] 14% | Training loss: 0.6877427679758805
Epoch: 88 | Iteration number: [660/4518] 14% | Training loss: 0.6877079102126035
Epoch: 88 | Iteration number: [670/4518] 14% | Training loss: 0.6876918256282807
Epoch: 88 | Iteration number: [680/4518] 15% | Training loss: 0.6876513393486248
Epoch: 88 | Iteration number: [690/4518] 15% | Training loss: 0.687628844337187
Epoch: 88 | Iteration number: [700/4518] 15% | Training loss: 0.6876110209737505
Epoch: 88 | Iteration number: [710/4518] 15% | Training loss: 0.6875999435572557
Epoch: 88 | Iteration number: [720/4518] 15% | Training loss: 0.6875732185939948
Epoch: 88 | Iteration number: [730/4518] 16% | Training loss: 0.687546259491411
Epoch: 88 | Iteration number: [740/4518] 16% | Training loss: 0.6875430927083299
Epoch: 88 | Iteration number: [750/4518] 16% | Training loss: 0.6875411434968313
Epoch: 88 | Iteration number: [760/4518] 16% | Training loss: 0.6875390323369126
Epoch: 88 | Iteration number: [770/4518] 17% | Training loss: 0.687526293156983
Epoch: 88 | Iteration number: [780/4518] 17% | Training loss: 0.6875104662699577
Epoch: 88 | Iteration number: [790/4518] 17% | Training loss: 0.6875055888031102
Epoch: 88 | Iteration number: [800/4518] 17% | Training loss: 0.6874806547164917
Epoch: 88 | Iteration number: [810/4518] 17% | Training loss: 0.6874955039701344
Epoch: 88 | Iteration number: [820/4518] 18% | Training loss: 0.6874892891907111
Epoch: 88 | Iteration number: [830/4518] 18% | Training loss: 0.6874673474983997
Epoch: 88 | Iteration number: [840/4518] 18% | Training loss: 0.6874616703107244
Epoch: 88 | Iteration number: [850/4518] 18% | Training loss: 0.6874500092338113
Epoch: 88 | Iteration number: [860/4518] 19% | Training loss: 0.6874401971351268
Epoch: 88 | Iteration number: [870/4518] 19% | Training loss: 0.687438899484174
Epoch: 88 | Iteration number: [880/4518] 19% | Training loss: 0.6874294320968064
Epoch: 88 | Iteration number: [890/4518] 19% | Training loss: 0.6874090552330017
Epoch: 88 | Iteration number: [900/4518] 19% | Training loss: 0.6873890918493271
Epoch: 88 | Iteration number: [910/4518] 20% | Training loss: 0.6873845422005915
Epoch: 88 | Iteration number: [920/4518] 20% | Training loss: 0.6873826764200045
Epoch: 88 | Iteration number: [930/4518] 20% | Training loss: 0.6873764792437195
Epoch: 88 | Iteration number: [940/4518] 20% | Training loss: 0.6873800081775544
Epoch: 88 | Iteration number: [950/4518] 21% | Training loss: 0.6873840975133996
Epoch: 88 | Iteration number: [960/4518] 21% | Training loss: 0.6873605667303005
Epoch: 88 | Iteration number: [970/4518] 21% | Training loss: 0.6873507252673513
Epoch: 88 | Iteration number: [980/4518] 21% | Training loss: 0.6873416028460678
Epoch: 88 | Iteration number: [990/4518] 21% | Training loss: 0.6873422815342142
Epoch: 88 | Iteration number: [1000/4518] 22% | Training loss: 0.6873422183990479
Epoch: 88 | Iteration number: [1010/4518] 22% | Training loss: 0.6873523630128049
Epoch: 88 | Iteration number: [1020/4518] 22% | Training loss: 0.6873530137772653
Epoch: 88 | Iteration number: [1030/4518] 22% | Training loss: 0.6873518530604908
Epoch: 88 | Iteration number: [1040/4518] 23% | Training loss: 0.6873567159932393
Epoch: 88 | Iteration number: [1050/4518] 23% | Training loss: 0.6873441024621327
Epoch: 88 | Iteration number: [1060/4518] 23% | Training loss: 0.6873423940168237
Epoch: 88 | Iteration number: [1070/4518] 23% | Training loss: 0.6873355723430064
Epoch: 88 | Iteration number: [1080/4518] 23% | Training loss: 0.6873336012164751
Epoch: 88 | Iteration number: [1090/4518] 24% | Training loss: 0.6873257122455387
Epoch: 88 | Iteration number: [1100/4518] 24% | Training loss: 0.6873212100159038
Epoch: 88 | Iteration number: [1110/4518] 24% | Training loss: 0.6873226277463071
Epoch: 88 | Iteration number: [1120/4518] 24% | Training loss: 0.6873197335749864
Epoch: 88 | Iteration number: [1130/4518] 25% | Training loss: 0.6873294816080447
Epoch: 88 | Iteration number: [1140/4518] 25% | Training loss: 0.6873224533963622
Epoch: 88 | Iteration number: [1150/4518] 25% | Training loss: 0.6873135895314424
Epoch: 88 | Iteration number: [1160/4518] 25% | Training loss: 0.6872995182357985
Epoch: 88 | Iteration number: [1170/4518] 25% | Training loss: 0.6872881084425837
Epoch: 88 | Iteration number: [1180/4518] 26% | Training loss: 0.6872880870002811
Epoch: 88 | Iteration number: [1190/4518] 26% | Training loss: 0.6873069889906074
Epoch: 88 | Iteration number: [1200/4518] 26% | Training loss: 0.6873001280426979
Epoch: 88 | Iteration number: [1210/4518] 26% | Training loss: 0.6872950287397243
Epoch: 88 | Iteration number: [1220/4518] 27% | Training loss: 0.6872844378967754
Epoch: 88 | Iteration number: [1230/4518] 27% | Training loss: 0.6872854774560385
Epoch: 88 | Iteration number: [1240/4518] 27% | Training loss: 0.687284469027673
Epoch: 88 | Iteration number: [1250/4518] 27% | Training loss: 0.6872824487686158
Epoch: 88 | Iteration number: [1260/4518] 27% | Training loss: 0.6872795863284005
Epoch: 88 | Iteration number: [1270/4518] 28% | Training loss: 0.687277422270437
Epoch: 88 | Iteration number: [1280/4518] 28% | Training loss: 0.687265447806567
Epoch: 88 | Iteration number: [1290/4518] 28% | Training loss: 0.6872629087562709
Epoch: 88 | Iteration number: [1300/4518] 28% | Training loss: 0.6872635893638317
Epoch: 88 | Iteration number: [1310/4518] 28% | Training loss: 0.6872626132637489
Epoch: 88 | Iteration number: [1320/4518] 29% | Training loss: 0.6872587638822469
Epoch: 88 | Iteration number: [1330/4518] 29% | Training loss: 0.6872538372986299
Epoch: 88 | Iteration number: [1340/4518] 29% | Training loss: 0.6872485005143864
Epoch: 88 | Iteration number: [1350/4518] 29% | Training loss: 0.6872522962534869
Epoch: 88 | Iteration number: [1360/4518] 30% | Training loss: 0.6872473006301066
Epoch: 88 | Iteration number: [1370/4518] 30% | Training loss: 0.6872490222436668
Epoch: 88 | Iteration number: [1380/4518] 30% | Training loss: 0.6872390474098317
Epoch: 88 | Iteration number: [1390/4518] 30% | Training loss: 0.6872344330060396
Epoch: 88 | Iteration number: [1400/4518] 30% | Training loss: 0.687234640802656
Epoch: 88 | Iteration number: [1410/4518] 31% | Training loss: 0.687240438723395
Epoch: 88 | Iteration number: [1420/4518] 31% | Training loss: 0.6872305221540828
Epoch: 88 | Iteration number: [1430/4518] 31% | Training loss: 0.687222537335816
Epoch: 88 | Iteration number: [1440/4518] 31% | Training loss: 0.6872193658931388
Epoch: 88 | Iteration number: [1450/4518] 32% | Training loss: 0.6872161311527778
Epoch: 88 | Iteration number: [1460/4518] 32% | Training loss: 0.6872101579626946
Epoch: 88 | Iteration number: [1470/4518] 32% | Training loss: 0.6872181265938039
Epoch: 88 | Iteration number: [1480/4518] 32% | Training loss: 0.6872206593284735
Epoch: 88 | Iteration number: [1490/4518] 32% | Training loss: 0.68721559227713
Epoch: 88 | Iteration number: [1500/4518] 33% | Training loss: 0.6872062028249105
Epoch: 88 | Iteration number: [1510/4518] 33% | Training loss: 0.6872024341924301
Epoch: 88 | Iteration number: [1520/4518] 33% | Training loss: 0.6871962880617694
Epoch: 88 | Iteration number: [1530/4518] 33% | Training loss: 0.6872038182090311
Epoch: 88 | Iteration number: [1540/4518] 34% | Training loss: 0.6872015084926184
Epoch: 88 | Iteration number: [1550/4518] 34% | Training loss: 0.6872000472391805
Epoch: 88 | Iteration number: [1560/4518] 34% | Training loss: 0.6871984290770995
Epoch: 88 | Iteration number: [1570/4518] 34% | Training loss: 0.6871968134952958
Epoch: 88 | Iteration number: [1580/4518] 34% | Training loss: 0.6872000087288361
Epoch: 88 | Iteration number: [1590/4518] 35% | Training loss: 0.6872022513698481
Epoch: 88 | Iteration number: [1600/4518] 35% | Training loss: 0.6871883786097169
Epoch: 88 | Iteration number: [1610/4518] 35% | Training loss: 0.687186302457537
Epoch: 88 | Iteration number: [1620/4518] 35% | Training loss: 0.6871865036310973
Epoch: 88 | Iteration number: [1630/4518] 36% | Training loss: 0.6871921823068631
Epoch: 88 | Iteration number: [1640/4518] 36% | Training loss: 0.6871963072113875
Epoch: 88 | Iteration number: [1650/4518] 36% | Training loss: 0.687196718490485
Epoch: 88 | Iteration number: [1660/4518] 36% | Training loss: 0.6871943814567772
Epoch: 88 | Iteration number: [1670/4518] 36% | Training loss: 0.6871927519401391
Epoch: 88 | Iteration number: [1680/4518] 37% | Training loss: 0.6871884069982029
Epoch: 88 | Iteration number: [1690/4518] 37% | Training loss: 0.6871888466840665
Epoch: 88 | Iteration number: [1700/4518] 37% | Training loss: 0.6871806912211811
Epoch: 88 | Iteration number: [1710/4518] 37% | Training loss: 0.6871743882608693
Epoch: 88 | Iteration number: [1720/4518] 38% | Training loss: 0.6871716671904852
Epoch: 88 | Iteration number: [1730/4518] 38% | Training loss: 0.6871739507755104
Epoch: 88 | Iteration number: [1740/4518] 38% | Training loss: 0.6871712722655
Epoch: 88 | Iteration number: [1750/4518] 38% | Training loss: 0.6871688652719771
Epoch: 88 | Iteration number: [1760/4518] 38% | Training loss: 0.687165833230723
Epoch: 88 | Iteration number: [1770/4518] 39% | Training loss: 0.6871603684910274
Epoch: 88 | Iteration number: [1780/4518] 39% | Training loss: 0.6871549417463582
Epoch: 88 | Iteration number: [1790/4518] 39% | Training loss: 0.6871492989569403
Epoch: 88 | Iteration number: [1800/4518] 39% | Training loss: 0.6871472503410445
Epoch: 88 | Iteration number: [1810/4518] 40% | Training loss: 0.6871473089766107
Epoch: 88 | Iteration number: [1820/4518] 40% | Training loss: 0.6871399079377835
Epoch: 88 | Iteration number: [1830/4518] 40% | Training loss: 0.6871395765106535
Epoch: 88 | Iteration number: [1840/4518] 40% | Training loss: 0.6871366239436295
Epoch: 88 | Iteration number: [1850/4518] 40% | Training loss: 0.6871303122430235
Epoch: 88 | Iteration number: [1860/4518] 41% | Training loss: 0.6871241365068702
Epoch: 88 | Iteration number: [1870/4518] 41% | Training loss: 0.6871290035426298
Epoch: 88 | Iteration number: [1880/4518] 41% | Training loss: 0.6871283659275542
Epoch: 88 | Iteration number: [1890/4518] 41% | Training loss: 0.6871184678304763
Epoch: 88 | Iteration number: [1900/4518] 42% | Training loss: 0.6871204892898861
Epoch: 88 | Iteration number: [1910/4518] 42% | Training loss: 0.6871196582055217
Epoch: 88 | Iteration number: [1920/4518] 42% | Training loss: 0.6871187116329869
Epoch: 88 | Iteration number: [1930/4518] 42% | Training loss: 0.6871174665312693
Epoch: 88 | Iteration number: [1940/4518] 42% | Training loss: 0.6871149394008302
Epoch: 88 | Iteration number: [1950/4518] 43% | Training loss: 0.6871182260452172
Epoch: 88 | Iteration number: [1960/4518] 43% | Training loss: 0.6871085432111
Epoch: 88 | Iteration number: [1970/4518] 43% | Training loss: 0.6871044294785728
Epoch: 88 | Iteration number: [1980/4518] 43% | Training loss: 0.6871025239578401
Epoch: 88 | Iteration number: [1990/4518] 44% | Training loss: 0.687103480579865
Epoch: 88 | Iteration number: [2000/4518] 44% | Training loss: 0.6871025168895721
Epoch: 88 | Iteration number: [2010/4518] 44% | Training loss: 0.6871000506095032
Epoch: 88 | Iteration number: [2020/4518] 44% | Training loss: 0.6871005169530906
Epoch: 88 | Iteration number: [2030/4518] 44% | Training loss: 0.6871010945935555
Epoch: 88 | Iteration number: [2040/4518] 45% | Training loss: 0.687099823910816
Epoch: 88 | Iteration number: [2050/4518] 45% | Training loss: 0.687096114129555
Epoch: 88 | Iteration number: [2060/4518] 45% | Training loss: 0.6870925668663191
Epoch: 88 | Iteration number: [2070/4518] 45% | Training loss: 0.687088636154138
Epoch: 88 | Iteration number: [2080/4518] 46% | Training loss: 0.6870887288107321
Epoch: 88 | Iteration number: [2090/4518] 46% | Training loss: 0.6870853890072216
Epoch: 88 | Iteration number: [2100/4518] 46% | Training loss: 0.6870871420985176
Epoch: 88 | Iteration number: [2110/4518] 46% | Training loss: 0.68708764721432
Epoch: 88 | Iteration number: [2120/4518] 46% | Training loss: 0.6870852043887354
Epoch: 88 | Iteration number: [2130/4518] 47% | Training loss: 0.6870873009934672
Epoch: 88 | Iteration number: [2140/4518] 47% | Training loss: 0.6870846196591297
Epoch: 88 | Iteration number: [2150/4518] 47% | Training loss: 0.6870799553117086
Epoch: 88 | Iteration number: [2160/4518] 47% | Training loss: 0.6870752750171556
Epoch: 88 | Iteration number: [2170/4518] 48% | Training loss: 0.6870729529088543
Epoch: 88 | Iteration number: [2180/4518] 48% | Training loss: 0.6870750686444274
Epoch: 88 | Iteration number: [2190/4518] 48% | Training loss: 0.6870712555706773
Epoch: 88 | Iteration number: [2200/4518] 48% | Training loss: 0.6870735345916315
Epoch: 88 | Iteration number: [2210/4518] 48% | Training loss: 0.6870731431704301
Epoch: 88 | Iteration number: [2220/4518] 49% | Training loss: 0.6870712758184553
Epoch: 88 | Iteration number: [2230/4518] 49% | Training loss: 0.6870681745856332
Epoch: 88 | Iteration number: [2240/4518] 49% | Training loss: 0.6870701665058732
Epoch: 88 | Iteration number: [2250/4518] 49% | Training loss: 0.6870725356207954
Epoch: 88 | Iteration number: [2260/4518] 50% | Training loss: 0.6870718036868931
Epoch: 88 | Iteration number: [2270/4518] 50% | Training loss: 0.6870690938397126
Epoch: 88 | Iteration number: [2280/4518] 50% | Training loss: 0.687071229256036
Epoch: 88 | Iteration number: [2290/4518] 50% | Training loss: 0.687067663539445
Epoch: 88 | Iteration number: [2300/4518] 50% | Training loss: 0.6870652233517688
Epoch: 88 | Iteration number: [2310/4518] 51% | Training loss: 0.6870665583001587
Epoch: 88 | Iteration number: [2320/4518] 51% | Training loss: 0.6870617293078324
Epoch: 88 | Iteration number: [2330/4518] 51% | Training loss: 0.6870605048959347
Epoch: 88 | Iteration number: [2340/4518] 51% | Training loss: 0.6870627024744311
Epoch: 88 | Iteration number: [2350/4518] 52% | Training loss: 0.6870651997911169
Epoch: 88 | Iteration number: [2360/4518] 52% | Training loss: 0.6870613048389806
Epoch: 88 | Iteration number: [2370/4518] 52% | Training loss: 0.6870594385052532
Epoch: 88 | Iteration number: [2380/4518] 52% | Training loss: 0.687055476548291
Epoch: 88 | Iteration number: [2390/4518] 52% | Training loss: 0.6870568426832494
Epoch: 88 | Iteration number: [2400/4518] 53% | Training loss: 0.6870502634346485
Epoch: 88 | Iteration number: [2410/4518] 53% | Training loss: 0.6870503628155008
Epoch: 88 | Iteration number: [2420/4518] 53% | Training loss: 0.6870471693760107
Epoch: 88 | Iteration number: [2430/4518] 53% | Training loss: 0.687047640163712
Epoch: 88 | Iteration number: [2440/4518] 54% | Training loss: 0.6870450509376214
Epoch: 88 | Iteration number: [2450/4518] 54% | Training loss: 0.6870423181202947
Epoch: 88 | Iteration number: [2460/4518] 54% | Training loss: 0.6870398718894013
Epoch: 88 | Iteration number: [2470/4518] 54% | Training loss: 0.6870404725856627
Epoch: 88 | Iteration number: [2480/4518] 54% | Training loss: 0.6870370685333206
Epoch: 88 | Iteration number: [2490/4518] 55% | Training loss: 0.6870339172671598
Epoch: 88 | Iteration number: [2500/4518] 55% | Training loss: 0.6870305340528489
Epoch: 88 | Iteration number: [2510/4518] 55% | Training loss: 0.6870317596600826
Epoch: 88 | Iteration number: [2520/4518] 55% | Training loss: 0.6870277424653372
Epoch: 88 | Iteration number: [2530/4518] 55% | Training loss: 0.6870225257553131
Epoch: 88 | Iteration number: [2540/4518] 56% | Training loss: 0.6870200883685135
Epoch: 88 | Iteration number: [2550/4518] 56% | Training loss: 0.687019932199927
Epoch: 88 | Iteration number: [2560/4518] 56% | Training loss: 0.6870151947485283
Epoch: 88 | Iteration number: [2570/4518] 56% | Training loss: 0.6870132003776758
Epoch: 88 | Iteration number: [2580/4518] 57% | Training loss: 0.6870124882736871
Epoch: 88 | Iteration number: [2590/4518] 57% | Training loss: 0.6870153586146454
Epoch: 88 | Iteration number: [2600/4518] 57% | Training loss: 0.6870070106708086
Epoch: 88 | Iteration number: [2610/4518] 57% | Training loss: 0.6870038159505617
Epoch: 88 | Iteration number: [2620/4518] 57% | Training loss: 0.6870019918634691
Epoch: 88 | Iteration number: [2630/4518] 58% | Training loss: 0.6870011357300182
Epoch: 88 | Iteration number: [2640/4518] 58% | Training loss: 0.6869977688473282
Epoch: 88 | Iteration number: [2650/4518] 58% | Training loss: 0.6869981036546096
Epoch: 88 | Iteration number: [2660/4518] 58% | Training loss: 0.6869933544693136
Epoch: 88 | Iteration number: [2670/4518] 59% | Training loss: 0.6869874399476283
Epoch: 88 | Iteration number: [2680/4518] 59% | Training loss: 0.6869776240702885
Epoch: 88 | Iteration number: [2690/4518] 59% | Training loss: 0.686975923368922
Epoch: 88 | Iteration number: [2700/4518] 59% | Training loss: 0.686976764731937
Epoch: 88 | Iteration number: [2710/4518] 59% | Training loss: 0.6869753063824784
Epoch: 88 | Iteration number: [2720/4518] 60% | Training loss: 0.686973378982614
Epoch: 88 | Iteration number: [2730/4518] 60% | Training loss: 0.6869681489336622
Epoch: 88 | Iteration number: [2740/4518] 60% | Training loss: 0.6869693491145642
Epoch: 88 | Iteration number: [2750/4518] 60% | Training loss: 0.6869691886468368
Epoch: 88 | Iteration number: [2760/4518] 61% | Training loss: 0.6869693434324817
Epoch: 88 | Iteration number: [2770/4518] 61% | Training loss: 0.6869654870420587
Epoch: 88 | Iteration number: [2780/4518] 61% | Training loss: 0.6869661956167907
Epoch: 88 | Iteration number: [2790/4518] 61% | Training loss: 0.686964794769082
Epoch: 88 | Iteration number: [2800/4518] 61% | Training loss: 0.6869646742088454
Epoch: 88 | Iteration number: [2810/4518] 62% | Training loss: 0.6869626349825876
Epoch: 88 | Iteration number: [2820/4518] 62% | Training loss: 0.6869638199290485
Epoch: 88 | Iteration number: [2830/4518] 62% | Training loss: 0.6869649497864524
Epoch: 88 | Iteration number: [2840/4518] 62% | Training loss: 0.6869672195172646
Epoch: 88 | Iteration number: [2850/4518] 63% | Training loss: 0.6869616595276615
Epoch: 88 | Iteration number: [2860/4518] 63% | Training loss: 0.686961224529293
Epoch: 88 | Iteration number: [2870/4518] 63% | Training loss: 0.686961649041558
Epoch: 88 | Iteration number: [2880/4518] 63% | Training loss: 0.686956262588501
Epoch: 88 | Iteration number: [2890/4518] 63% | Training loss: 0.6869572774761689
Epoch: 88 | Iteration number: [2900/4518] 64% | Training loss: 0.6869597480420409
Epoch: 88 | Iteration number: [2910/4518] 64% | Training loss: 0.6869631670184971
Epoch: 88 | Iteration number: [2920/4518] 64% | Training loss: 0.6869617120247997
Epoch: 88 | Iteration number: [2930/4518] 64% | Training loss: 0.6869626342029702
Epoch: 88 | Iteration number: [2940/4518] 65% | Training loss: 0.6869640899758761
Epoch: 88 | Iteration number: [2950/4518] 65% | Training loss: 0.6869638375104484
Epoch: 88 | Iteration number: [2960/4518] 65% | Training loss: 0.6869638617779757
Epoch: 88 | Iteration number: [2970/4518] 65% | Training loss: 0.6869640861095403
Epoch: 88 | Iteration number: [2980/4518] 65% | Training loss: 0.6869628518619794
Epoch: 88 | Iteration number: [2990/4518] 66% | Training loss: 0.6869641947108368
Epoch: 88 | Iteration number: [3000/4518] 66% | Training loss: 0.6869647353291511
Epoch: 88 | Iteration number: [3010/4518] 66% | Training loss: 0.6869659352936222
Epoch: 88 | Iteration number: [3020/4518] 66% | Training loss: 0.6869664533643534
Epoch: 88 | Iteration number: [3030/4518] 67% | Training loss: 0.6869681080772538
Epoch: 88 | Iteration number: [3040/4518] 67% | Training loss: 0.6869667221252855
Epoch: 88 | Iteration number: [3050/4518] 67% | Training loss: 0.6869683732556515
Epoch: 88 | Iteration number: [3060/4518] 67% | Training loss: 0.6869676748716753
Epoch: 88 | Iteration number: [3070/4518] 67% | Training loss: 0.6869665320222463
Epoch: 88 | Iteration number: [3080/4518] 68% | Training loss: 0.6869632820030311
Epoch: 88 | Iteration number: [3090/4518] 68% | Training loss: 0.686963423749004
Epoch: 88 | Iteration number: [3100/4518] 68% | Training loss: 0.6869680642312573
Epoch: 88 | Iteration number: [3110/4518] 68% | Training loss: 0.6869699086023681
Epoch: 88 | Iteration number: [3120/4518] 69% | Training loss: 0.6869665640860032
Epoch: 88 | Iteration number: [3130/4518] 69% | Training loss: 0.6869659192645893
Epoch: 88 | Iteration number: [3140/4518] 69% | Training loss: 0.6869617802132467
Epoch: 88 | Iteration number: [3150/4518] 69% | Training loss: 0.6869622874827612
Epoch: 88 | Iteration number: [3160/4518] 69% | Training loss: 0.6869593835706952
Epoch: 88 | Iteration number: [3170/4518] 70% | Training loss: 0.6869575265830248
Epoch: 88 | Iteration number: [3180/4518] 70% | Training loss: 0.6869620201347759
Epoch: 88 | Iteration number: [3190/4518] 70% | Training loss: 0.6869650565718408
Epoch: 88 | Iteration number: [3200/4518] 70% | Training loss: 0.6869686409272253
Epoch: 88 | Iteration number: [3210/4518] 71% | Training loss: 0.6869650057357419
Epoch: 88 | Iteration number: [3220/4518] 71% | Training loss: 0.6869630244392786
Epoch: 88 | Iteration number: [3230/4518] 71% | Training loss: 0.6869651109072447
Epoch: 88 | Iteration number: [3240/4518] 71% | Training loss: 0.6869651092055403
Epoch: 88 | Iteration number: [3250/4518] 71% | Training loss: 0.6869640005918649
Epoch: 88 | Iteration number: [3260/4518] 72% | Training loss: 0.6869658142511099
Epoch: 88 | Iteration number: [3270/4518] 72% | Training loss: 0.686965992235627
Epoch: 88 | Iteration number: [3280/4518] 72% | Training loss: 0.686962246113434
Epoch: 88 | Iteration number: [3290/4518] 72% | Training loss: 0.6869627651834923
Epoch: 88 | Iteration number: [3300/4518] 73% | Training loss: 0.6869606372443112
Epoch: 88 | Iteration number: [3310/4518] 73% | Training loss: 0.6869590299007036
Epoch: 88 | Iteration number: [3320/4518] 73% | Training loss: 0.686959928651172
Epoch: 88 | Iteration number: [3330/4518] 73% | Training loss: 0.6869606874189578
Epoch: 88 | Iteration number: [3340/4518] 73% | Training loss: 0.686955864254586
Epoch: 88 | Iteration number: [3350/4518] 74% | Training loss: 0.686956755011829
Epoch: 88 | Iteration number: [3360/4518] 74% | Training loss: 0.6869548749001253
Epoch: 88 | Iteration number: [3370/4518] 74% | Training loss: 0.686953527372032
Epoch: 88 | Iteration number: [3380/4518] 74% | Training loss: 0.6869547952385344
Epoch: 88 | Iteration number: [3390/4518] 75% | Training loss: 0.6869556530211176
Epoch: 88 | Iteration number: [3400/4518] 75% | Training loss: 0.6869549625936676
Epoch: 88 | Iteration number: [3410/4518] 75% | Training loss: 0.6869576980466368
Epoch: 88 | Iteration number: [3420/4518] 75% | Training loss: 0.6869583909274541
Epoch: 88 | Iteration number: [3430/4518] 75% | Training loss: 0.6869593524898107
Epoch: 88 | Iteration number: [3440/4518] 76% | Training loss: 0.6869563871691393
Epoch: 88 | Iteration number: [3450/4518] 76% | Training loss: 0.686954381224038
Epoch: 88 | Iteration number: [3460/4518] 76% | Training loss: 0.6869508338801433
Epoch: 88 | Iteration number: [3470/4518] 76% | Training loss: 0.6869460899479451
Epoch: 88 | Iteration number: [3480/4518] 77% | Training loss: 0.6869475507188118
Epoch: 88 | Iteration number: [3490/4518] 77% | Training loss: 0.6869438818498463
Epoch: 88 | Iteration number: [3500/4518] 77% | Training loss: 0.6869407302992685
Epoch: 88 | Iteration number: [3510/4518] 77% | Training loss: 0.6869389386598201
Epoch: 88 | Iteration number: [3520/4518] 77% | Training loss: 0.6869365405799313
Epoch: 88 | Iteration number: [3530/4518] 78% | Training loss: 0.6869358080304716
Epoch: 88 | Iteration number: [3540/4518] 78% | Training loss: 0.6869336472224381
Epoch: 88 | Iteration number: [3550/4518] 78% | Training loss: 0.6869333496731772
Epoch: 88 | Iteration number: [3560/4518] 78% | Training loss: 0.6869336266865891
Epoch: 88 | Iteration number: [3570/4518] 79% | Training loss: 0.686935460099987
Epoch: 88 | Iteration number: [3580/4518] 79% | Training loss: 0.6869351139947689
Epoch: 88 | Iteration number: [3590/4518] 79% | Training loss: 0.6869370586360729
Epoch: 88 | Iteration number: [3600/4518] 79% | Training loss: 0.6869339700871043
Epoch: 88 | Iteration number: [3610/4518] 79% | Training loss: 0.6869320055784611
Epoch: 88 | Iteration number: [3620/4518] 80% | Training loss: 0.6869322109946888
Epoch: 88 | Iteration number: [3630/4518] 80% | Training loss: 0.6869311859292432
Epoch: 88 | Iteration number: [3640/4518] 80% | Training loss: 0.6869326357003097
Epoch: 88 | Iteration number: [3650/4518] 80% | Training loss: 0.6869296964227337
Epoch: 88 | Iteration number: [3660/4518] 81% | Training loss: 0.6869303146509524
Epoch: 88 | Iteration number: [3670/4518] 81% | Training loss: 0.68693210260095
Epoch: 88 | Iteration number: [3680/4518] 81% | Training loss: 0.6869347596945969
Epoch: 88 | Iteration number: [3690/4518] 81% | Training loss: 0.6869319270458325
Epoch: 88 | Iteration number: [3700/4518] 81% | Training loss: 0.6869313704000937
Epoch: 88 | Iteration number: [3710/4518] 82% | Training loss: 0.6869283800658511
Epoch: 88 | Iteration number: [3720/4518] 82% | Training loss: 0.6869284502120429
Epoch: 88 | Iteration number: [3730/4518] 82% | Training loss: 0.686927276114676
Epoch: 88 | Iteration number: [3740/4518] 82% | Training loss: 0.6869266407693772
Epoch: 88 | Iteration number: [3750/4518] 83% | Training loss: 0.6869269144217173
Epoch: 88 | Iteration number: [3760/4518] 83% | Training loss: 0.6869223866215411
Epoch: 88 | Iteration number: [3770/4518] 83% | Training loss: 0.6869197864431285
Epoch: 88 | Iteration number: [3780/4518] 83% | Training loss: 0.6869192499016958
Epoch: 88 | Iteration number: [3790/4518] 83% | Training loss: 0.6869164652748914
Epoch: 88 | Iteration number: [3800/4518] 84% | Training loss: 0.6869174914297305
Epoch: 88 | Iteration number: [3810/4518] 84% | Training loss: 0.6869167272030838
Epoch: 88 | Iteration number: [3820/4518] 84% | Training loss: 0.6869166910960413
Epoch: 88 | Iteration number: [3830/4518] 84% | Training loss: 0.6869161173351128
Epoch: 88 | Iteration number: [3840/4518] 84% | Training loss: 0.6869154615172496
Epoch: 88 | Iteration number: [3850/4518] 85% | Training loss: 0.6869132901476576
Epoch: 88 | Iteration number: [3860/4518] 85% | Training loss: 0.6869126673807134
Epoch: 88 | Iteration number: [3870/4518] 85% | Training loss: 0.6869119813121874
Epoch: 88 | Iteration number: [3880/4518] 85% | Training loss: 0.6869130237661686
Epoch: 88 | Iteration number: [3890/4518] 86% | Training loss: 0.6869145601451551
Epoch: 88 | Iteration number: [3900/4518] 86% | Training loss: 0.6869139487315447
Epoch: 88 | Iteration number: [3910/4518] 86% | Training loss: 0.6869131937051368
Epoch: 88 | Iteration number: [3920/4518] 86% | Training loss: 0.6869109362667921
Epoch: 88 | Iteration number: [3930/4518] 86% | Training loss: 0.6869106171846996
Epoch: 88 | Iteration number: [3940/4518] 87% | Training loss: 0.6869115420858267
Epoch: 88 | Iteration number: [3950/4518] 87% | Training loss: 0.6869145595725579
Epoch: 88 | Iteration number: [3960/4518] 87% | Training loss: 0.6869128189002625
Epoch: 88 | Iteration number: [3970/4518] 87% | Training loss: 0.6869143021346941
Epoch: 88 | Iteration number: [3980/4518] 88% | Training loss: 0.6869154872756508
Epoch: 88 | Iteration number: [3990/4518] 88% | Training loss: 0.6869127158383678
Epoch: 88 | Iteration number: [4000/4518] 88% | Training loss: 0.6869130175560713
Epoch: 88 | Iteration number: [4010/4518] 88% | Training loss: 0.6869128664086882
Epoch: 88 | Iteration number: [4020/4518] 88% | Training loss: 0.6869137367502374
Epoch: 88 | Iteration number: [4030/4518] 89% | Training loss: 0.6869149175086625
Epoch: 88 | Iteration number: [4040/4518] 89% | Training loss: 0.6869169882323483
Epoch: 88 | Iteration number: [4050/4518] 89% | Training loss: 0.6869181747495392
Epoch: 88 | Iteration number: [4060/4518] 89% | Training loss: 0.686920088749801
Epoch: 88 | Iteration number: [4070/4518] 90% | Training loss: 0.6869193377893152
Epoch: 88 | Iteration number: [4080/4518] 90% | Training loss: 0.6869179635071287
Epoch: 88 | Iteration number: [4090/4518] 90% | Training loss: 0.6869155924739931
Epoch: 88 | Iteration number: [4100/4518] 90% | Training loss: 0.6869134046682497
Epoch: 88 | Iteration number: [4110/4518] 90% | Training loss: 0.6869137167930603
Epoch: 88 | Iteration number: [4120/4518] 91% | Training loss: 0.6869113388570767
Epoch: 88 | Iteration number: [4130/4518] 91% | Training loss: 0.6869106852402121
Epoch: 88 | Iteration number: [4140/4518] 91% | Training loss: 0.6869108340014582
Epoch: 88 | Iteration number: [4150/4518] 91% | Training loss: 0.6869111197540559
Epoch: 88 | Iteration number: [4160/4518] 92% | Training loss: 0.6869096651673317
Epoch: 88 | Iteration number: [4170/4518] 92% | Training loss: 0.6869087131618024
Epoch: 88 | Iteration number: [4180/4518] 92% | Training loss: 0.6869085914780648
Epoch: 88 | Iteration number: [4190/4518] 92% | Training loss: 0.6869070946174476
Epoch: 88 | Iteration number: [4200/4518] 92% | Training loss: 0.6869088365350451
Epoch: 88 | Iteration number: [4210/4518] 93% | Training loss: 0.6869062447066545
Epoch: 88 | Iteration number: [4220/4518] 93% | Training loss: 0.6869091182947159
Epoch: 88 | Iteration number: [4230/4518] 93% | Training loss: 0.6869062631829129
Epoch: 88 | Iteration number: [4240/4518] 93% | Training loss: 0.6869055254279443
Epoch: 88 | Iteration number: [4250/4518] 94% | Training loss: 0.6869067480564117
Epoch: 88 | Iteration number: [4260/4518] 94% | Training loss: 0.6869072818840054
Epoch: 88 | Iteration number: [4270/4518] 94% | Training loss: 0.6869079561088347
Epoch: 88 | Iteration number: [4280/4518] 94% | Training loss: 0.6869102870610273
Epoch: 88 | Iteration number: [4290/4518] 94% | Training loss: 0.6869113040415001
Epoch: 88 | Iteration number: [4300/4518] 95% | Training loss: 0.6869118113573207
Epoch: 88 | Iteration number: [4310/4518] 95% | Training loss: 0.6869112772620748
Epoch: 88 | Iteration number: [4320/4518] 95% | Training loss: 0.6869103346433905
Epoch: 88 | Iteration number: [4330/4518] 95% | Training loss: 0.686907698898888
Epoch: 88 | Iteration number: [4340/4518] 96% | Training loss: 0.6869061410015079
Epoch: 88 | Iteration number: [4350/4518] 96% | Training loss: 0.6869062060323254
Epoch: 88 | Iteration number: [4360/4518] 96% | Training loss: 0.6869048595565175
Epoch: 88 | Iteration number: [4370/4518] 96% | Training loss: 0.6869053006035785
Epoch: 88 | Iteration number: [4380/4518] 96% | Training loss: 0.686903599585028
Epoch: 88 | Iteration number: [4390/4518] 97% | Training loss: 0.6869048287765311
Epoch: 88 | Iteration number: [4400/4518] 97% | Training loss: 0.6869042133472183
Epoch: 88 | Iteration number: [4410/4518] 97% | Training loss: 0.6869047567011818
Epoch: 88 | Iteration number: [4420/4518] 97% | Training loss: 0.686905198790369
Epoch: 88 | Iteration number: [4430/4518] 98% | Training loss: 0.6869064421739858
Epoch: 88 | Iteration number: [4440/4518] 98% | Training loss: 0.6869063677954245
Epoch: 88 | Iteration number: [4450/4518] 98% | Training loss: 0.6869068098068237
Epoch: 88 | Iteration number: [4460/4518] 98% | Training loss: 0.6869082431488508
Epoch: 88 | Iteration number: [4470/4518] 98% | Training loss: 0.6869110895883317
Epoch: 88 | Iteration number: [4480/4518] 99% | Training loss: 0.6869117536715099
Epoch: 88 | Iteration number: [4490/4518] 99% | Training loss: 0.6869096830188565
Epoch: 88 | Iteration number: [4500/4518] 99% | Training loss: 0.6869103992117775
Epoch: 88 | Iteration number: [4510/4518] 99% | Training loss: 0.6869087046371596

 End of epoch: 88 | Train Loss: 0.6867550581020821 | Training Time: 641 

 End of epoch: 88 | Eval Loss: 0.689774789372269 | Evaluating Time: 17 
Epoch: 89 | Iteration number: [10/4518] 0% | Training loss: 0.7547367930412292
Epoch: 89 | Iteration number: [20/4518] 0% | Training loss: 0.7209808975458145
Epoch: 89 | Iteration number: [30/4518] 0% | Training loss: 0.7093106130758922
Epoch: 89 | Iteration number: [40/4518] 0% | Training loss: 0.7034271776676178
Epoch: 89 | Iteration number: [50/4518] 1% | Training loss: 0.7000302636623382
Epoch: 89 | Iteration number: [60/4518] 1% | Training loss: 0.6977502564589183
Epoch: 89 | Iteration number: [70/4518] 1% | Training loss: 0.6962207879338945
Epoch: 89 | Iteration number: [80/4518] 1% | Training loss: 0.694930661469698
Epoch: 89 | Iteration number: [90/4518] 1% | Training loss: 0.6942015747229259
Epoch: 89 | Iteration number: [100/4518] 2% | Training loss: 0.6934608066082001
Epoch: 89 | Iteration number: [110/4518] 2% | Training loss: 0.692934968254783
Epoch: 89 | Iteration number: [120/4518] 2% | Training loss: 0.6923527787129085
Epoch: 89 | Iteration number: [130/4518] 2% | Training loss: 0.691863869703733
Epoch: 89 | Iteration number: [140/4518] 3% | Training loss: 0.6915182279688972
Epoch: 89 | Iteration number: [150/4518] 3% | Training loss: 0.6911801298459371
Epoch: 89 | Iteration number: [160/4518] 3% | Training loss: 0.6909765545278788
Epoch: 89 | Iteration number: [170/4518] 3% | Training loss: 0.6906172433320213
Epoch: 89 | Iteration number: [180/4518] 3% | Training loss: 0.6904235465659035
Epoch: 89 | Iteration number: [190/4518] 4% | Training loss: 0.6902491833034314
Epoch: 89 | Iteration number: [200/4518] 4% | Training loss: 0.6900391292572021
Epoch: 89 | Iteration number: [210/4518] 4% | Training loss: 0.6898598622708093
Epoch: 89 | Iteration number: [220/4518] 4% | Training loss: 0.68973190323873
Epoch: 89 | Iteration number: [230/4518] 5% | Training loss: 0.6896315144455951
Epoch: 89 | Iteration number: [240/4518] 5% | Training loss: 0.6894830301403999
Epoch: 89 | Iteration number: [250/4518] 5% | Training loss: 0.6893754386901856
Epoch: 89 | Iteration number: [260/4518] 5% | Training loss: 0.6893006361447848
Epoch: 89 | Iteration number: [270/4518] 5% | Training loss: 0.6892154896700824
Epoch: 89 | Iteration number: [280/4518] 6% | Training loss: 0.6891823202371598
Epoch: 89 | Iteration number: [290/4518] 6% | Training loss: 0.6891161920695469
Epoch: 89 | Iteration number: [300/4518] 6% | Training loss: 0.6890287818511327
Epoch: 89 | Iteration number: [310/4518] 6% | Training loss: 0.6889634811109112
Epoch: 89 | Iteration number: [320/4518] 7% | Training loss: 0.6889030614867806
Epoch: 89 | Iteration number: [330/4518] 7% | Training loss: 0.6888005272908644
Epoch: 89 | Iteration number: [340/4518] 7% | Training loss: 0.6887772965080597
Epoch: 89 | Iteration number: [350/4518] 7% | Training loss: 0.6887306351321084
Epoch: 89 | Iteration number: [360/4518] 7% | Training loss: 0.6886421258250872
Epoch: 89 | Iteration number: [370/4518] 8% | Training loss: 0.6885801816308821
Epoch: 89 | Iteration number: [380/4518] 8% | Training loss: 0.6885288712225462
Epoch: 89 | Iteration number: [390/4518] 8% | Training loss: 0.6884502741006705
Epoch: 89 | Iteration number: [400/4518] 8% | Training loss: 0.6883980713784694
Epoch: 89 | Iteration number: [410/4518] 9% | Training loss: 0.6883543662908601
Epoch: 89 | Iteration number: [420/4518] 9% | Training loss: 0.6883209901196616
Epoch: 89 | Iteration number: [430/4518] 9% | Training loss: 0.6883032105689825
Epoch: 89 | Iteration number: [440/4518] 9% | Training loss: 0.6882759713313796
Epoch: 89 | Iteration number: [450/4518] 9% | Training loss: 0.6882485441366831
Epoch: 89 | Iteration number: [460/4518] 10% | Training loss: 0.6882016187128813
Epoch: 89 | Iteration number: [470/4518] 10% | Training loss: 0.6881566665274031
Epoch: 89 | Iteration number: [480/4518] 10% | Training loss: 0.6881485742827257
Epoch: 89 | Iteration number: [490/4518] 10% | Training loss: 0.688100865422463
Epoch: 89 | Iteration number: [500/4518] 11% | Training loss: 0.688064444065094
Epoch: 89 | Iteration number: [510/4518] 11% | Training loss: 0.6880400569999919
Epoch: 89 | Iteration number: [520/4518] 11% | Training loss: 0.6879972554170168
Epoch: 89 | Iteration number: [530/4518] 11% | Training loss: 0.6879749278977232
Epoch: 89 | Iteration number: [540/4518] 11% | Training loss: 0.6879526378931823
Epoch: 89 | Iteration number: [550/4518] 12% | Training loss: 0.6879489856416529
Epoch: 89 | Iteration number: [560/4518] 12% | Training loss: 0.6879113344209534
Epoch: 89 | Iteration number: [570/4518] 12% | Training loss: 0.6878878032952024
Epoch: 89 | Iteration number: [580/4518] 12% | Training loss: 0.6878635327363837
Epoch: 89 | Iteration number: [590/4518] 13% | Training loss: 0.68783445287559
Epoch: 89 | Iteration number: [600/4518] 13% | Training loss: 0.6878097859025002
Epoch: 89 | Iteration number: [610/4518] 13% | Training loss: 0.6878003098925606
Epoch: 89 | Iteration number: [620/4518] 13% | Training loss: 0.6877971889511232
Epoch: 89 | Iteration number: [630/4518] 13% | Training loss: 0.6878039705374884
Epoch: 89 | Iteration number: [640/4518] 14% | Training loss: 0.6877721030265093
Epoch: 89 | Iteration number: [650/4518] 14% | Training loss: 0.687750168121778
Epoch: 89 | Iteration number: [660/4518] 14% | Training loss: 0.6877266849532272
Epoch: 89 | Iteration number: [670/4518] 14% | Training loss: 0.6877104475427029
Epoch: 89 | Iteration number: [680/4518] 15% | Training loss: 0.6876956972129205
Epoch: 89 | Iteration number: [690/4518] 15% | Training loss: 0.6876822866391444
Epoch: 89 | Iteration number: [700/4518] 15% | Training loss: 0.6876765132801873
Epoch: 89 | Iteration number: [710/4518] 15% | Training loss: 0.6876624462470202
Epoch: 89 | Iteration number: [720/4518] 15% | Training loss: 0.6876392786701521
Epoch: 89 | Iteration number: [730/4518] 16% | Training loss: 0.687622045164239
Epoch: 89 | Iteration number: [740/4518] 16% | Training loss: 0.6876169596974914
Epoch: 89 | Iteration number: [750/4518] 16% | Training loss: 0.6875979788303376
Epoch: 89 | Iteration number: [760/4518] 16% | Training loss: 0.6875894071240174
Epoch: 89 | Iteration number: [770/4518] 17% | Training loss: 0.6875722527503967
Epoch: 89 | Iteration number: [780/4518] 17% | Training loss: 0.6875645230213802
Epoch: 89 | Iteration number: [790/4518] 17% | Training loss: 0.6875622422634801
Epoch: 89 | Iteration number: [800/4518] 17% | Training loss: 0.6875515443086624
Epoch: 89 | Iteration number: [810/4518] 17% | Training loss: 0.6875317630944429
Epoch: 89 | Iteration number: [820/4518] 18% | Training loss: 0.687519594663527
Epoch: 89 | Iteration number: [830/4518] 18% | Training loss: 0.6875140318669468
Epoch: 89 | Iteration number: [840/4518] 18% | Training loss: 0.6875061585080056
Epoch: 89 | Iteration number: [850/4518] 18% | Training loss: 0.6874937421434066
Epoch: 89 | Iteration number: [860/4518] 19% | Training loss: 0.687472748687101
Epoch: 89 | Iteration number: [870/4518] 19% | Training loss: 0.6874584629617888
Epoch: 89 | Iteration number: [880/4518] 19% | Training loss: 0.6874579825861887
Epoch: 89 | Iteration number: [890/4518] 19% | Training loss: 0.6874303620852781
Epoch: 89 | Iteration number: [900/4518] 19% | Training loss: 0.687427068816291
Epoch: 89 | Iteration number: [910/4518] 20% | Training loss: 0.6874192841760405
Epoch: 89 | Iteration number: [920/4518] 20% | Training loss: 0.6873929655422335
Epoch: 89 | Iteration number: [930/4518] 20% | Training loss: 0.687394275652465
Epoch: 89 | Iteration number: [940/4518] 20% | Training loss: 0.6873653246367232
Epoch: 89 | Iteration number: [950/4518] 21% | Training loss: 0.6873444909171055
Epoch: 89 | Iteration number: [960/4518] 21% | Training loss: 0.6873276487613718
Epoch: 89 | Iteration number: [970/4518] 21% | Training loss: 0.6873161852359772
Epoch: 89 | Iteration number: [980/4518] 21% | Training loss: 0.6873096893636548
Epoch: 89 | Iteration number: [990/4518] 21% | Training loss: 0.6873045336116445
Epoch: 89 | Iteration number: [1000/4518] 22% | Training loss: 0.687301839351654
Epoch: 89 | Iteration number: [1010/4518] 22% | Training loss: 0.6872915988511378
Epoch: 89 | Iteration number: [1020/4518] 22% | Training loss: 0.6872926557180928
Epoch: 89 | Iteration number: [1030/4518] 22% | Training loss: 0.6872691907350299
Epoch: 89 | Iteration number: [1040/4518] 23% | Training loss: 0.6872792387811038
Epoch: 89 | Iteration number: [1050/4518] 23% | Training loss: 0.6872670178753989
Epoch: 89 | Iteration number: [1060/4518] 23% | Training loss: 0.6872633570770048
Epoch: 89 | Iteration number: [1070/4518] 23% | Training loss: 0.6872501701952141
Epoch: 89 | Iteration number: [1080/4518] 23% | Training loss: 0.6872568342972685
Epoch: 89 | Iteration number: [1090/4518] 24% | Training loss: 0.6872540494170758
Epoch: 89 | Iteration number: [1100/4518] 24% | Training loss: 0.6872489905899222
Epoch: 89 | Iteration number: [1110/4518] 24% | Training loss: 0.6872494440357965
Epoch: 89 | Iteration number: [1120/4518] 24% | Training loss: 0.6872408163334642
Epoch: 89 | Iteration number: [1130/4518] 25% | Training loss: 0.6872290574871334
Epoch: 89 | Iteration number: [1140/4518] 25% | Training loss: 0.6872260996647048
Epoch: 89 | Iteration number: [1150/4518] 25% | Training loss: 0.6872054252935492
Epoch: 89 | Iteration number: [1160/4518] 25% | Training loss: 0.6872078898138013
Epoch: 89 | Iteration number: [1170/4518] 25% | Training loss: 0.6871988686231466
Epoch: 89 | Iteration number: [1180/4518] 26% | Training loss: 0.6871805028390077
Epoch: 89 | Iteration number: [1190/4518] 26% | Training loss: 0.6871846395881236
Epoch: 89 | Iteration number: [1200/4518] 26% | Training loss: 0.687185002764066
Epoch: 89 | Iteration number: [1210/4518] 26% | Training loss: 0.687185193044095
Epoch: 89 | Iteration number: [1220/4518] 27% | Training loss: 0.6871790005535375
Epoch: 89 | Iteration number: [1230/4518] 27% | Training loss: 0.6871818372389166
Epoch: 89 | Iteration number: [1240/4518] 27% | Training loss: 0.6871872860577799
Epoch: 89 | Iteration number: [1250/4518] 27% | Training loss: 0.6871791059970855
Epoch: 89 | Iteration number: [1260/4518] 27% | Training loss: 0.6871782689813584
Epoch: 89 | Iteration number: [1270/4518] 28% | Training loss: 0.6871813361100324
Epoch: 89 | Iteration number: [1280/4518] 28% | Training loss: 0.6871731251478195
Epoch: 89 | Iteration number: [1290/4518] 28% | Training loss: 0.6871775279211444
Epoch: 89 | Iteration number: [1300/4518] 28% | Training loss: 0.6871801412564058
Epoch: 89 | Iteration number: [1310/4518] 28% | Training loss: 0.6871686371228167
Epoch: 89 | Iteration number: [1320/4518] 29% | Training loss: 0.6871707365368351
Epoch: 89 | Iteration number: [1330/4518] 29% | Training loss: 0.687177747756915
Epoch: 89 | Iteration number: [1340/4518] 29% | Training loss: 0.6871801959489708
Epoch: 89 | Iteration number: [1350/4518] 29% | Training loss: 0.6871750920790213
Epoch: 89 | Iteration number: [1360/4518] 30% | Training loss: 0.6871608203386559
Epoch: 89 | Iteration number: [1370/4518] 30% | Training loss: 0.6871600534359034
Epoch: 89 | Iteration number: [1380/4518] 30% | Training loss: 0.6871469606523929
Epoch: 89 | Iteration number: [1390/4518] 30% | Training loss: 0.6871456632940032
Epoch: 89 | Iteration number: [1400/4518] 30% | Training loss: 0.6871440571546554
Epoch: 89 | Iteration number: [1410/4518] 31% | Training loss: 0.6871415210108385
Epoch: 89 | Iteration number: [1420/4518] 31% | Training loss: 0.6871426714138246
Epoch: 89 | Iteration number: [1430/4518] 31% | Training loss: 0.6871346249030187
Epoch: 89 | Iteration number: [1440/4518] 31% | Training loss: 0.6871324688610103
Epoch: 89 | Iteration number: [1450/4518] 32% | Training loss: 0.687132614481038
Epoch: 89 | Iteration number: [1460/4518] 32% | Training loss: 0.6871377831044262
Epoch: 89 | Iteration number: [1470/4518] 32% | Training loss: 0.6871321338374599
Epoch: 89 | Iteration number: [1480/4518] 32% | Training loss: 0.6871226537469272
Epoch: 89 | Iteration number: [1490/4518] 32% | Training loss: 0.6871232627222202
Epoch: 89 | Iteration number: [1500/4518] 33% | Training loss: 0.6871149777968725
Epoch: 89 | Iteration number: [1510/4518] 33% | Training loss: 0.6871068024082689
Epoch: 89 | Iteration number: [1520/4518] 33% | Training loss: 0.6871053667052796
Epoch: 89 | Iteration number: [1530/4518] 33% | Training loss: 0.6871013946392956
Epoch: 89 | Iteration number: [1540/4518] 34% | Training loss: 0.6870949424706496
Epoch: 89 | Iteration number: [1550/4518] 34% | Training loss: 0.6870907061330733
Epoch: 89 | Iteration number: [1560/4518] 34% | Training loss: 0.6870967989548659
Epoch: 89 | Iteration number: [1570/4518] 34% | Training loss: 0.6870936365643884
Epoch: 89 | Iteration number: [1580/4518] 34% | Training loss: 0.6870911322817018
Epoch: 89 | Iteration number: [1590/4518] 35% | Training loss: 0.6870934443653754
Epoch: 89 | Iteration number: [1600/4518] 35% | Training loss: 0.687090798355639
Epoch: 89 | Iteration number: [1610/4518] 35% | Training loss: 0.687094762791758
Epoch: 89 | Iteration number: [1620/4518] 35% | Training loss: 0.6870857174013868
Epoch: 89 | Iteration number: [1630/4518] 36% | Training loss: 0.6870754199159658
Epoch: 89 | Iteration number: [1640/4518] 36% | Training loss: 0.6870694739426054
Epoch: 89 | Iteration number: [1650/4518] 36% | Training loss: 0.6870657289028168
Epoch: 89 | Iteration number: [1660/4518] 36% | Training loss: 0.6870620655367173
Epoch: 89 | Iteration number: [1670/4518] 36% | Training loss: 0.6870558132668455
Epoch: 89 | Iteration number: [1680/4518] 37% | Training loss: 0.6870606914872215
Epoch: 89 | Iteration number: [1690/4518] 37% | Training loss: 0.6870646861177929
Epoch: 89 | Iteration number: [1700/4518] 37% | Training loss: 0.687056747359388
Epoch: 89 | Iteration number: [1710/4518] 37% | Training loss: 0.6870558865586219
Epoch: 89 | Iteration number: [1720/4518] 38% | Training loss: 0.6870529096486957
Epoch: 89 | Iteration number: [1730/4518] 38% | Training loss: 0.6870550175622708
Epoch: 89 | Iteration number: [1740/4518] 38% | Training loss: 0.687058670870189
Epoch: 89 | Iteration number: [1750/4518] 38% | Training loss: 0.6870635797296252
Epoch: 89 | Iteration number: [1760/4518] 38% | Training loss: 0.6870686241848902
Epoch: 89 | Iteration number: [1770/4518] 39% | Training loss: 0.687068536153621
Epoch: 89 | Iteration number: [1780/4518] 39% | Training loss: 0.6870724632498924
Epoch: 89 | Iteration number: [1790/4518] 39% | Training loss: 0.6870711220376319
Epoch: 89 | Iteration number: [1800/4518] 39% | Training loss: 0.6870744136306974
Epoch: 89 | Iteration number: [1810/4518] 40% | Training loss: 0.6870722230297426
Epoch: 89 | Iteration number: [1820/4518] 40% | Training loss: 0.687071301648905
Epoch: 89 | Iteration number: [1830/4518] 40% | Training loss: 0.6870656149960607
Epoch: 89 | Iteration number: [1840/4518] 40% | Training loss: 0.6870580180183701
Epoch: 89 | Iteration number: [1850/4518] 40% | Training loss: 0.6870459593631125
Epoch: 89 | Iteration number: [1860/4518] 41% | Training loss: 0.6870445965759215
Epoch: 89 | Iteration number: [1870/4518] 41% | Training loss: 0.6870455615979465
Epoch: 89 | Iteration number: [1880/4518] 41% | Training loss: 0.6870424947840102
Epoch: 89 | Iteration number: [1890/4518] 41% | Training loss: 0.6870420406104396
Epoch: 89 | Iteration number: [1900/4518] 42% | Training loss: 0.687036802831449
Epoch: 89 | Iteration number: [1910/4518] 42% | Training loss: 0.6870338164699015
Epoch: 89 | Iteration number: [1920/4518] 42% | Training loss: 0.6870276280368368
Epoch: 89 | Iteration number: [1930/4518] 42% | Training loss: 0.6870327272254568
Epoch: 89 | Iteration number: [1940/4518] 42% | Training loss: 0.6870350365786209
Epoch: 89 | Iteration number: [1950/4518] 43% | Training loss: 0.6870204466122848
Epoch: 89 | Iteration number: [1960/4518] 43% | Training loss: 0.6870169797113963
Epoch: 89 | Iteration number: [1970/4518] 43% | Training loss: 0.6870196311304412
Epoch: 89 | Iteration number: [1980/4518] 43% | Training loss: 0.6870169029392378
Epoch: 89 | Iteration number: [1990/4518] 44% | Training loss: 0.6870169358636866
Epoch: 89 | Iteration number: [2000/4518] 44% | Training loss: 0.6870195975005626
Epoch: 89 | Iteration number: [2010/4518] 44% | Training loss: 0.6870190268725305
Epoch: 89 | Iteration number: [2020/4518] 44% | Training loss: 0.6870160192251206
Epoch: 89 | Iteration number: [2030/4518] 44% | Training loss: 0.6870157388924378
Epoch: 89 | Iteration number: [2040/4518] 45% | Training loss: 0.6870186571397033
Epoch: 89 | Iteration number: [2050/4518] 45% | Training loss: 0.6870153900762883
Epoch: 89 | Iteration number: [2060/4518] 45% | Training loss: 0.687015577543129
Epoch: 89 | Iteration number: [2070/4518] 45% | Training loss: 0.6870176738586978
Epoch: 89 | Iteration number: [2080/4518] 46% | Training loss: 0.6870123866658945
Epoch: 89 | Iteration number: [2090/4518] 46% | Training loss: 0.6870130075507187
Epoch: 89 | Iteration number: [2100/4518] 46% | Training loss: 0.6870068869704292
Epoch: 89 | Iteration number: [2110/4518] 46% | Training loss: 0.6870063521003271
Epoch: 89 | Iteration number: [2120/4518] 46% | Training loss: 0.6870100314043602
Epoch: 89 | Iteration number: [2130/4518] 47% | Training loss: 0.6870067129112745
Epoch: 89 | Iteration number: [2140/4518] 47% | Training loss: 0.6870101839582496
Epoch: 89 | Iteration number: [2150/4518] 47% | Training loss: 0.6870096391578053
Epoch: 89 | Iteration number: [2160/4518] 47% | Training loss: 0.687003404950654
Epoch: 89 | Iteration number: [2170/4518] 48% | Training loss: 0.6870032975750585
Epoch: 89 | Iteration number: [2180/4518] 48% | Training loss: 0.6870028767563882
Epoch: 89 | Iteration number: [2190/4518] 48% | Training loss: 0.6870066141156845
Epoch: 89 | Iteration number: [2200/4518] 48% | Training loss: 0.68700721797618
Epoch: 89 | Iteration number: [2210/4518] 48% | Training loss: 0.6870055321115175
Epoch: 89 | Iteration number: [2220/4518] 49% | Training loss: 0.6870011153521839
Epoch: 89 | Iteration number: [2230/4518] 49% | Training loss: 0.6870001919066425
Epoch: 89 | Iteration number: [2240/4518] 49% | Training loss: 0.6870043914232935
Epoch: 89 | Iteration number: [2250/4518] 49% | Training loss: 0.6870055663320753
Epoch: 89 | Iteration number: [2260/4518] 50% | Training loss: 0.6870046739029674
Epoch: 89 | Iteration number: [2270/4518] 50% | Training loss: 0.6870064915276834
Epoch: 89 | Iteration number: [2280/4518] 50% | Training loss: 0.6870120245375131
Epoch: 89 | Iteration number: [2290/4518] 50% | Training loss: 0.6870128121178223
Epoch: 89 | Iteration number: [2300/4518] 50% | Training loss: 0.6870129078626632
Epoch: 89 | Iteration number: [2310/4518] 51% | Training loss: 0.687017500658572
Epoch: 89 | Iteration number: [2320/4518] 51% | Training loss: 0.6870164249220799
Epoch: 89 | Iteration number: [2330/4518] 51% | Training loss: 0.6870235195743167
Epoch: 89 | Iteration number: [2340/4518] 51% | Training loss: 0.6870197951793671
Epoch: 89 | Iteration number: [2350/4518] 52% | Training loss: 0.6870173233367027
Epoch: 89 | Iteration number: [2360/4518] 52% | Training loss: 0.6870155110450115
Epoch: 89 | Iteration number: [2370/4518] 52% | Training loss: 0.6870141930720978
Epoch: 89 | Iteration number: [2380/4518] 52% | Training loss: 0.6870032919054272
Epoch: 89 | Iteration number: [2390/4518] 52% | Training loss: 0.6870040116200388
Epoch: 89 | Iteration number: [2400/4518] 53% | Training loss: 0.6870055957635244
Epoch: 89 | Iteration number: [2410/4518] 53% | Training loss: 0.6870017172637322
Epoch: 89 | Iteration number: [2420/4518] 53% | Training loss: 0.6870059018292702
Epoch: 89 | Iteration number: [2430/4518] 53% | Training loss: 0.687003458134922
Epoch: 89 | Iteration number: [2440/4518] 54% | Training loss: 0.6870033976240236
Epoch: 89 | Iteration number: [2450/4518] 54% | Training loss: 0.6870057586504489
Epoch: 89 | Iteration number: [2460/4518] 54% | Training loss: 0.6870013980846095
Epoch: 89 | Iteration number: [2470/4518] 54% | Training loss: 0.6869985434207839
Epoch: 89 | Iteration number: [2480/4518] 54% | Training loss: 0.6869950706439634
Epoch: 89 | Iteration number: [2490/4518] 55% | Training loss: 0.6869897382805147
Epoch: 89 | Iteration number: [2500/4518] 55% | Training loss: 0.6869872714042664
Epoch: 89 | Iteration number: [2510/4518] 55% | Training loss: 0.6869838766367787
Epoch: 89 | Iteration number: [2520/4518] 55% | Training loss: 0.6869835702199785
Epoch: 89 | Iteration number: [2530/4518] 55% | Training loss: 0.6869763972966567
Epoch: 89 | Iteration number: [2540/4518] 56% | Training loss: 0.6869751463490208
Epoch: 89 | Iteration number: [2550/4518] 56% | Training loss: 0.6869756535689036
Epoch: 89 | Iteration number: [2560/4518] 56% | Training loss: 0.6869773937854916
Epoch: 89 | Iteration number: [2570/4518] 56% | Training loss: 0.6869746589938954
Epoch: 89 | Iteration number: [2580/4518] 57% | Training loss: 0.6869725845118826
Epoch: 89 | Iteration number: [2590/4518] 57% | Training loss: 0.6869684563410328
Epoch: 89 | Iteration number: [2600/4518] 57% | Training loss: 0.6869668365671084
Epoch: 89 | Iteration number: [2610/4518] 57% | Training loss: 0.6869698460074677
Epoch: 89 | Iteration number: [2620/4518] 57% | Training loss: 0.6869664598284787
Epoch: 89 | Iteration number: [2630/4518] 58% | Training loss: 0.6869641679548039
Epoch: 89 | Iteration number: [2640/4518] 58% | Training loss: 0.6869618743206516
Epoch: 89 | Iteration number: [2650/4518] 58% | Training loss: 0.686957042104793
Epoch: 89 | Iteration number: [2660/4518] 58% | Training loss: 0.6869541185915022
Epoch: 89 | Iteration number: [2670/4518] 59% | Training loss: 0.6869516038492824
Epoch: 89 | Iteration number: [2680/4518] 59% | Training loss: 0.6869550132262173
Epoch: 89 | Iteration number: [2690/4518] 59% | Training loss: 0.6869552326468287
Epoch: 89 | Iteration number: [2700/4518] 59% | Training loss: 0.6869518091502013
Epoch: 89 | Iteration number: [2710/4518] 59% | Training loss: 0.6869575648730092
Epoch: 89 | Iteration number: [2720/4518] 60% | Training loss: 0.6869557378484922
Epoch: 89 | Iteration number: [2730/4518] 60% | Training loss: 0.6869539987691593
Epoch: 89 | Iteration number: [2740/4518] 60% | Training loss: 0.686952331074833
Epoch: 89 | Iteration number: [2750/4518] 60% | Training loss: 0.6869468560869043
Epoch: 89 | Iteration number: [2760/4518] 61% | Training loss: 0.686949098304562
Epoch: 89 | Iteration number: [2770/4518] 61% | Training loss: 0.686952135859844
Epoch: 89 | Iteration number: [2780/4518] 61% | Training loss: 0.6869500006059949
Epoch: 89 | Iteration number: [2790/4518] 61% | Training loss: 0.6869471000086876
Epoch: 89 | Iteration number: [2800/4518] 61% | Training loss: 0.6869424180047853
Epoch: 89 | Iteration number: [2810/4518] 62% | Training loss: 0.6869451101352312
Epoch: 89 | Iteration number: [2820/4518] 62% | Training loss: 0.6869472148781972
Epoch: 89 | Iteration number: [2830/4518] 62% | Training loss: 0.6869461187836138
Epoch: 89 | Iteration number: [2840/4518] 62% | Training loss: 0.6869476476815385
Epoch: 89 | Iteration number: [2850/4518] 63% | Training loss: 0.6869519511858623
Epoch: 89 | Iteration number: [2860/4518] 63% | Training loss: 0.6869500697284312
Epoch: 89 | Iteration number: [2870/4518] 63% | Training loss: 0.6869502632460113
Epoch: 89 | Iteration number: [2880/4518] 63% | Training loss: 0.6869514129848944
Epoch: 89 | Iteration number: [2890/4518] 63% | Training loss: 0.6869520201608796
Epoch: 89 | Iteration number: [2900/4518] 64% | Training loss: 0.6869530285432421
Epoch: 89 | Iteration number: [2910/4518] 64% | Training loss: 0.6869524292314995
Epoch: 89 | Iteration number: [2920/4518] 64% | Training loss: 0.6869532261809258
Epoch: 89 | Iteration number: [2930/4518] 64% | Training loss: 0.68695150318813
Epoch: 89 | Iteration number: [2940/4518] 65% | Training loss: 0.6869591849190848
Epoch: 89 | Iteration number: [2950/4518] 65% | Training loss: 0.6869571920572701
Epoch: 89 | Iteration number: [2960/4518] 65% | Training loss: 0.6869569668495977
Epoch: 89 | Iteration number: [2970/4518] 65% | Training loss: 0.6869605553872657
Epoch: 89 | Iteration number: [2980/4518] 65% | Training loss: 0.6869518843473204
Epoch: 89 | Iteration number: [2990/4518] 66% | Training loss: 0.6869532369650327
Epoch: 89 | Iteration number: [3000/4518] 66% | Training loss: 0.686954794049263
Epoch: 89 | Iteration number: [3010/4518] 66% | Training loss: 0.6869580515001303
Epoch: 89 | Iteration number: [3020/4518] 66% | Training loss: 0.686958629248158
Epoch: 89 | Iteration number: [3030/4518] 67% | Training loss: 0.686957309309012
Epoch: 89 | Iteration number: [3040/4518] 67% | Training loss: 0.6869568555370758
Epoch: 89 | Iteration number: [3050/4518] 67% | Training loss: 0.6869555411573316
Epoch: 89 | Iteration number: [3060/4518] 67% | Training loss: 0.6869561468269311
Epoch: 89 | Iteration number: [3070/4518] 67% | Training loss: 0.6869551717070104
Epoch: 89 | Iteration number: [3080/4518] 68% | Training loss: 0.6869509191288576
Epoch: 89 | Iteration number: [3090/4518] 68% | Training loss: 0.6869450274408828
Epoch: 89 | Iteration number: [3100/4518] 68% | Training loss: 0.6869469174262016
Epoch: 89 | Iteration number: [3110/4518] 68% | Training loss: 0.686950799429915
Epoch: 89 | Iteration number: [3120/4518] 69% | Training loss: 0.6869514727821717
Epoch: 89 | Iteration number: [3130/4518] 69% | Training loss: 0.6869523979223574
Epoch: 89 | Iteration number: [3140/4518] 69% | Training loss: 0.686949477605759
Epoch: 89 | Iteration number: [3150/4518] 69% | Training loss: 0.6869478318804786
Epoch: 89 | Iteration number: [3160/4518] 69% | Training loss: 0.6869491266298897
Epoch: 89 | Iteration number: [3170/4518] 70% | Training loss: 0.6869462649152858
Epoch: 89 | Iteration number: [3180/4518] 70% | Training loss: 0.6869404103396074
Epoch: 89 | Iteration number: [3190/4518] 70% | Training loss: 0.6869360420771153
Epoch: 89 | Iteration number: [3200/4518] 70% | Training loss: 0.6869356787018478
Epoch: 89 | Iteration number: [3210/4518] 71% | Training loss: 0.686931398557354
Epoch: 89 | Iteration number: [3220/4518] 71% | Training loss: 0.6869311972249369
Epoch: 89 | Iteration number: [3230/4518] 71% | Training loss: 0.6869329077356002
Epoch: 89 | Iteration number: [3240/4518] 71% | Training loss: 0.6869310810242171
Epoch: 89 | Iteration number: [3250/4518] 71% | Training loss: 0.6869305718862093
Epoch: 89 | Iteration number: [3260/4518] 72% | Training loss: 0.6869342259834149
Epoch: 89 | Iteration number: [3270/4518] 72% | Training loss: 0.6869319596604105
Epoch: 89 | Iteration number: [3280/4518] 72% | Training loss: 0.6869334565248432
Epoch: 89 | Iteration number: [3290/4518] 72% | Training loss: 0.686930464919215
Epoch: 89 | Iteration number: [3300/4518] 73% | Training loss: 0.6869305582118757
Epoch: 89 | Iteration number: [3310/4518] 73% | Training loss: 0.6869266146259365
Epoch: 89 | Iteration number: [3320/4518] 73% | Training loss: 0.6869269312505263
Epoch: 89 | Iteration number: [3330/4518] 73% | Training loss: 0.6869250241879586
Epoch: 89 | Iteration number: [3340/4518] 73% | Training loss: 0.6869222503043935
Epoch: 89 | Iteration number: [3350/4518] 74% | Training loss: 0.6869207726307769
Epoch: 89 | Iteration number: [3360/4518] 74% | Training loss: 0.6869195526199682
Epoch: 89 | Iteration number: [3370/4518] 74% | Training loss: 0.686919113029712
Epoch: 89 | Iteration number: [3380/4518] 74% | Training loss: 0.6869223630287238
Epoch: 89 | Iteration number: [3390/4518] 75% | Training loss: 0.6869273935799051
Epoch: 89 | Iteration number: [3400/4518] 75% | Training loss: 0.6869281002353219
Epoch: 89 | Iteration number: [3410/4518] 75% | Training loss: 0.686927011373106
Epoch: 89 | Iteration number: [3420/4518] 75% | Training loss: 0.686925845118294
Epoch: 89 | Iteration number: [3430/4518] 75% | Training loss: 0.6869270645320937
Epoch: 89 | Iteration number: [3440/4518] 76% | Training loss: 0.6869287707258103
Epoch: 89 | Iteration number: [3450/4518] 76% | Training loss: 0.6869318471438642
Epoch: 89 | Iteration number: [3460/4518] 76% | Training loss: 0.6869325072779132
Epoch: 89 | Iteration number: [3470/4518] 76% | Training loss: 0.6869317424056853
Epoch: 89 | Iteration number: [3480/4518] 77% | Training loss: 0.6869309217080303
Epoch: 89 | Iteration number: [3490/4518] 77% | Training loss: 0.6869328012780679
Epoch: 89 | Iteration number: [3500/4518] 77% | Training loss: 0.6869312184197562
Epoch: 89 | Iteration number: [3510/4518] 77% | Training loss: 0.6869310567691456
Epoch: 89 | Iteration number: [3520/4518] 77% | Training loss: 0.6869333637708968
Epoch: 89 | Iteration number: [3530/4518] 78% | Training loss: 0.6869287775359816
Epoch: 89 | Iteration number: [3540/4518] 78% | Training loss: 0.6869279897819132
Epoch: 89 | Iteration number: [3550/4518] 78% | Training loss: 0.6869241337709024
Epoch: 89 | Iteration number: [3560/4518] 78% | Training loss: 0.6869236671020476
Epoch: 89 | Iteration number: [3570/4518] 79% | Training loss: 0.6869263615594858
Epoch: 89 | Iteration number: [3580/4518] 79% | Training loss: 0.6869216480568134
Epoch: 89 | Iteration number: [3590/4518] 79% | Training loss: 0.6869206170517754
Epoch: 89 | Iteration number: [3600/4518] 79% | Training loss: 0.6869249828656514
Epoch: 89 | Iteration number: [3610/4518] 79% | Training loss: 0.6869242154495208
Epoch: 89 | Iteration number: [3620/4518] 80% | Training loss: 0.6869230012044064
Epoch: 89 | Iteration number: [3630/4518] 80% | Training loss: 0.6869252664491164
Epoch: 89 | Iteration number: [3640/4518] 80% | Training loss: 0.686922576876132
Epoch: 89 | Iteration number: [3650/4518] 80% | Training loss: 0.6869184816863438
Epoch: 89 | Iteration number: [3660/4518] 81% | Training loss: 0.6869201419946275
Epoch: 89 | Iteration number: [3670/4518] 81% | Training loss: 0.6869220127039449
Epoch: 89 | Iteration number: [3680/4518] 81% | Training loss: 0.6869213497833065
Epoch: 89 | Iteration number: [3690/4518] 81% | Training loss: 0.6869198530347044
Epoch: 89 | Iteration number: [3700/4518] 81% | Training loss: 0.6869219964903754
Epoch: 89 | Iteration number: [3710/4518] 82% | Training loss: 0.6869223697808875
Epoch: 89 | Iteration number: [3720/4518] 82% | Training loss: 0.6869225450741347
Epoch: 89 | Iteration number: [3730/4518] 82% | Training loss: 0.6869203945107498
Epoch: 89 | Iteration number: [3740/4518] 82% | Training loss: 0.6869192467175703
Epoch: 89 | Iteration number: [3750/4518] 83% | Training loss: 0.6869158721764882
Epoch: 89 | Iteration number: [3760/4518] 83% | Training loss: 0.6869172104337113
Epoch: 89 | Iteration number: [3770/4518] 83% | Training loss: 0.68691699044774
Epoch: 89 | Iteration number: [3780/4518] 83% | Training loss: 0.6869149567431243
Epoch: 89 | Iteration number: [3790/4518] 83% | Training loss: 0.6869157733420269
Epoch: 89 | Iteration number: [3800/4518] 84% | Training loss: 0.686918463769712
Epoch: 89 | Iteration number: [3810/4518] 84% | Training loss: 0.6869188963584699
Epoch: 89 | Iteration number: [3820/4518] 84% | Training loss: 0.6869191438583804
Epoch: 89 | Iteration number: [3830/4518] 84% | Training loss: 0.6869197451570327
Epoch: 89 | Iteration number: [3840/4518] 84% | Training loss: 0.6869197514373809
Epoch: 89 | Iteration number: [3850/4518] 85% | Training loss: 0.6869184628399936
Epoch: 89 | Iteration number: [3860/4518] 85% | Training loss: 0.6869171544214604
Epoch: 89 | Iteration number: [3870/4518] 85% | Training loss: 0.6869161233575461
Epoch: 89 | Iteration number: [3880/4518] 85% | Training loss: 0.6869176364282972
Epoch: 89 | Iteration number: [3890/4518] 86% | Training loss: 0.6869139725260992
Epoch: 89 | Iteration number: [3900/4518] 86% | Training loss: 0.6869124101981139
Epoch: 89 | Iteration number: [3910/4518] 86% | Training loss: 0.6869098474607443
Epoch: 89 | Iteration number: [3920/4518] 86% | Training loss: 0.6869067001555648
Epoch: 89 | Iteration number: [3930/4518] 86% | Training loss: 0.6869068245244694
Epoch: 89 | Iteration number: [3940/4518] 87% | Training loss: 0.6869054689625193
Epoch: 89 | Iteration number: [3950/4518] 87% | Training loss: 0.6869046520885033
Epoch: 89 | Iteration number: [3960/4518] 87% | Training loss: 0.6869051579574141
Epoch: 89 | Iteration number: [3970/4518] 87% | Training loss: 0.6869030529816145
Epoch: 89 | Iteration number: [3980/4518] 88% | Training loss: 0.6869028907774681
Epoch: 89 | Iteration number: [3990/4518] 88% | Training loss: 0.686900614198288
Epoch: 89 | Iteration number: [4000/4518] 88% | Training loss: 0.6869021738469601
Epoch: 89 | Iteration number: [4010/4518] 88% | Training loss: 0.6869027832648403
Epoch: 89 | Iteration number: [4020/4518] 88% | Training loss: 0.686904317555736
Epoch: 89 | Iteration number: [4030/4518] 89% | Training loss: 0.6869053417932307
Epoch: 89 | Iteration number: [4040/4518] 89% | Training loss: 0.6869057953062624
Epoch: 89 | Iteration number: [4050/4518] 89% | Training loss: 0.6869062866104974
Epoch: 89 | Iteration number: [4060/4518] 89% | Training loss: 0.6869049745827472
Epoch: 89 | Iteration number: [4070/4518] 90% | Training loss: 0.6869058744034544
Epoch: 89 | Iteration number: [4080/4518] 90% | Training loss: 0.6869053896881786
Epoch: 89 | Iteration number: [4090/4518] 90% | Training loss: 0.6869044679592757
Epoch: 89 | Iteration number: [4100/4518] 90% | Training loss: 0.6869037665245009
Epoch: 89 | Iteration number: [4110/4518] 90% | Training loss: 0.686902086186583
Epoch: 89 | Iteration number: [4120/4518] 91% | Training loss: 0.6869043974187767
Epoch: 89 | Iteration number: [4130/4518] 91% | Training loss: 0.6869042194351446
Epoch: 89 | Iteration number: [4140/4518] 91% | Training loss: 0.6869049795727799
Epoch: 89 | Iteration number: [4150/4518] 91% | Training loss: 0.6869067478323557
Epoch: 89 | Iteration number: [4160/4518] 92% | Training loss: 0.6869072896500047
Epoch: 89 | Iteration number: [4170/4518] 92% | Training loss: 0.6869041515054177
Epoch: 89 | Iteration number: [4180/4518] 92% | Training loss: 0.6869041013803209
Epoch: 89 | Iteration number: [4190/4518] 92% | Training loss: 0.6869052107977127
Epoch: 89 | Iteration number: [4200/4518] 92% | Training loss: 0.6869061220117978
Epoch: 89 | Iteration number: [4210/4518] 93% | Training loss: 0.6869069807036755
Epoch: 89 | Iteration number: [4220/4518] 93% | Training loss: 0.6869076105090679
Epoch: 89 | Iteration number: [4230/4518] 93% | Training loss: 0.6869086025595383
Epoch: 89 | Iteration number: [4240/4518] 93% | Training loss: 0.6869100571522173
Epoch: 89 | Iteration number: [4250/4518] 94% | Training loss: 0.6869073032210855
Epoch: 89 | Iteration number: [4260/4518] 94% | Training loss: 0.6869034223853142
Epoch: 89 | Iteration number: [4270/4518] 94% | Training loss: 0.686904428365359
Epoch: 89 | Iteration number: [4280/4518] 94% | Training loss: 0.6869038567782563
Epoch: 89 | Iteration number: [4290/4518] 94% | Training loss: 0.6869030761552024
Epoch: 89 | Iteration number: [4300/4518] 95% | Training loss: 0.6869020509304002
Epoch: 89 | Iteration number: [4310/4518] 95% | Training loss: 0.6869020680402105
Epoch: 89 | Iteration number: [4320/4518] 95% | Training loss: 0.6869029102915967
Epoch: 89 | Iteration number: [4330/4518] 95% | Training loss: 0.6869049290861874
Epoch: 89 | Iteration number: [4340/4518] 96% | Training loss: 0.6869049396520386
Epoch: 89 | Iteration number: [4350/4518] 96% | Training loss: 0.6869033442831588
Epoch: 89 | Iteration number: [4360/4518] 96% | Training loss: 0.6869027472827413
Epoch: 89 | Iteration number: [4370/4518] 96% | Training loss: 0.6869013564673933
Epoch: 89 | Iteration number: [4380/4518] 96% | Training loss: 0.6868982020170177
Epoch: 89 | Iteration number: [4390/4518] 97% | Training loss: 0.686898823588204
Epoch: 89 | Iteration number: [4400/4518] 97% | Training loss: 0.6868956152281978
Epoch: 89 | Iteration number: [4410/4518] 97% | Training loss: 0.6868956677362221
Epoch: 89 | Iteration number: [4420/4518] 97% | Training loss: 0.6868955539092758
Epoch: 89 | Iteration number: [4430/4518] 98% | Training loss: 0.6868953597195799
Epoch: 89 | Iteration number: [4440/4518] 98% | Training loss: 0.6868973093124123
Epoch: 89 | Iteration number: [4450/4518] 98% | Training loss: 0.6868991314159351
Epoch: 89 | Iteration number: [4460/4518] 98% | Training loss: 0.6868970104931716
Epoch: 89 | Iteration number: [4470/4518] 98% | Training loss: 0.6868983548492926
Epoch: 89 | Iteration number: [4480/4518] 99% | Training loss: 0.6868990458415023
Epoch: 89 | Iteration number: [4490/4518] 99% | Training loss: 0.6869022711082663
Epoch: 89 | Iteration number: [4500/4518] 99% | Training loss: 0.6869025323126051
Epoch: 89 | Iteration number: [4510/4518] 99% | Training loss: 0.6869028462142479

 End of epoch: 89 | Train Loss: 0.6867531812549851 | Training Time: 641 

 End of epoch: 89 | Eval Loss: 0.6897850158263226 | Evaluating Time: 17 
Epoch: 90 | Iteration number: [10/4518] 0% | Training loss: 0.7541813611984253
Epoch: 90 | Iteration number: [20/4518] 0% | Training loss: 0.7204823076725007
Epoch: 90 | Iteration number: [30/4518] 0% | Training loss: 0.7093441108862559
Epoch: 90 | Iteration number: [40/4518] 0% | Training loss: 0.7036409214138984
Epoch: 90 | Iteration number: [50/4518] 1% | Training loss: 0.7001421236991883
Epoch: 90 | Iteration number: [60/4518] 1% | Training loss: 0.6981510122617086
Epoch: 90 | Iteration number: [70/4518] 1% | Training loss: 0.6964950340134757
Epoch: 90 | Iteration number: [80/4518] 1% | Training loss: 0.6951184011995792
Epoch: 90 | Iteration number: [90/4518] 1% | Training loss: 0.6942134625381894
Epoch: 90 | Iteration number: [100/4518] 2% | Training loss: 0.6935436880588531
Epoch: 90 | Iteration number: [110/4518] 2% | Training loss: 0.692799836397171
Epoch: 90 | Iteration number: [120/4518] 2% | Training loss: 0.6923071071505547
Epoch: 90 | Iteration number: [130/4518] 2% | Training loss: 0.6919516306657058
Epoch: 90 | Iteration number: [140/4518] 3% | Training loss: 0.6916069631065641
Epoch: 90 | Iteration number: [150/4518] 3% | Training loss: 0.6911828740437825
Epoch: 90 | Iteration number: [160/4518] 3% | Training loss: 0.6908886503428221
Epoch: 90 | Iteration number: [170/4518] 3% | Training loss: 0.6906305646195131
Epoch: 90 | Iteration number: [180/4518] 3% | Training loss: 0.6904358085658815
Epoch: 90 | Iteration number: [190/4518] 4% | Training loss: 0.6902029539409437
Epoch: 90 | Iteration number: [200/4518] 4% | Training loss: 0.6900128123164176
Epoch: 90 | Iteration number: [210/4518] 4% | Training loss: 0.6898374336106436
Epoch: 90 | Iteration number: [220/4518] 4% | Training loss: 0.6897063640030947
Epoch: 90 | Iteration number: [230/4518] 5% | Training loss: 0.6895796179771423
Epoch: 90 | Iteration number: [240/4518] 5% | Training loss: 0.6894647426903248
Epoch: 90 | Iteration number: [250/4518] 5% | Training loss: 0.6893966917991639
Epoch: 90 | Iteration number: [260/4518] 5% | Training loss: 0.6892657279968262
Epoch: 90 | Iteration number: [270/4518] 5% | Training loss: 0.6891483933837326
Epoch: 90 | Iteration number: [280/4518] 6% | Training loss: 0.6890971867101533
Epoch: 90 | Iteration number: [290/4518] 6% | Training loss: 0.6890119799252215
Epoch: 90 | Iteration number: [300/4518] 6% | Training loss: 0.6889396643638611
Epoch: 90 | Iteration number: [310/4518] 6% | Training loss: 0.6888503720683437
Epoch: 90 | Iteration number: [320/4518] 7% | Training loss: 0.6888001248240471
Epoch: 90 | Iteration number: [330/4518] 7% | Training loss: 0.6887326879934831
Epoch: 90 | Iteration number: [340/4518] 7% | Training loss: 0.688678301081938
Epoch: 90 | Iteration number: [350/4518] 7% | Training loss: 0.6886228580134256
Epoch: 90 | Iteration number: [360/4518] 7% | Training loss: 0.6885743553439776
Epoch: 90 | Iteration number: [370/4518] 8% | Training loss: 0.688555961525118
Epoch: 90 | Iteration number: [380/4518] 8% | Training loss: 0.6885329310831271
Epoch: 90 | Iteration number: [390/4518] 8% | Training loss: 0.6885147279653794
Epoch: 90 | Iteration number: [400/4518] 8% | Training loss: 0.6884221902489662
Epoch: 90 | Iteration number: [410/4518] 9% | Training loss: 0.6883767625180687
Epoch: 90 | Iteration number: [420/4518] 9% | Training loss: 0.688317434560685
Epoch: 90 | Iteration number: [430/4518] 9% | Training loss: 0.6882553143556728
Epoch: 90 | Iteration number: [440/4518] 9% | Training loss: 0.6881925199519504
Epoch: 90 | Iteration number: [450/4518] 9% | Training loss: 0.6881441994508107
Epoch: 90 | Iteration number: [460/4518] 10% | Training loss: 0.6881199090377145
Epoch: 90 | Iteration number: [470/4518] 10% | Training loss: 0.6881166124597509
Epoch: 90 | Iteration number: [480/4518] 10% | Training loss: 0.6880635865032673
Epoch: 90 | Iteration number: [490/4518] 10% | Training loss: 0.6880297428491164
Epoch: 90 | Iteration number: [500/4518] 11% | Training loss: 0.6880039039850235
Epoch: 90 | Iteration number: [510/4518] 11% | Training loss: 0.6879600153249853
Epoch: 90 | Iteration number: [520/4518] 11% | Training loss: 0.6879363358020782
Epoch: 90 | Iteration number: [530/4518] 11% | Training loss: 0.6879058379047321
Epoch: 90 | Iteration number: [540/4518] 11% | Training loss: 0.687890413734648
Epoch: 90 | Iteration number: [550/4518] 12% | Training loss: 0.687885282906619
Epoch: 90 | Iteration number: [560/4518] 12% | Training loss: 0.6878607579639979
Epoch: 90 | Iteration number: [570/4518] 12% | Training loss: 0.6878262618131805
Epoch: 90 | Iteration number: [580/4518] 12% | Training loss: 0.687782672047615
Epoch: 90 | Iteration number: [590/4518] 13% | Training loss: 0.6877578088792704
Epoch: 90 | Iteration number: [600/4518] 13% | Training loss: 0.6877331002553304
Epoch: 90 | Iteration number: [610/4518] 13% | Training loss: 0.6877322195006199
Epoch: 90 | Iteration number: [620/4518] 13% | Training loss: 0.6877227316940985
Epoch: 90 | Iteration number: [630/4518] 13% | Training loss: 0.6877106430984679
Epoch: 90 | Iteration number: [640/4518] 14% | Training loss: 0.6877060333266855
Epoch: 90 | Iteration number: [650/4518] 14% | Training loss: 0.6876915265963628
Epoch: 90 | Iteration number: [660/4518] 14% | Training loss: 0.6876830445997643
Epoch: 90 | Iteration number: [670/4518] 14% | Training loss: 0.6876717565664604
Epoch: 90 | Iteration number: [680/4518] 15% | Training loss: 0.6876761113896089
Epoch: 90 | Iteration number: [690/4518] 15% | Training loss: 0.6876449834609377
Epoch: 90 | Iteration number: [700/4518] 15% | Training loss: 0.6876363793441228
Epoch: 90 | Iteration number: [710/4518] 15% | Training loss: 0.6876226249714972
Epoch: 90 | Iteration number: [720/4518] 15% | Training loss: 0.6875947788357735
Epoch: 90 | Iteration number: [730/4518] 16% | Training loss: 0.6875770888099931
Epoch: 90 | Iteration number: [740/4518] 16% | Training loss: 0.687577395664679
Epoch: 90 | Iteration number: [750/4518] 16% | Training loss: 0.6875787580013275
Epoch: 90 | Iteration number: [760/4518] 16% | Training loss: 0.687561134052904
Epoch: 90 | Iteration number: [770/4518] 17% | Training loss: 0.6875612416824737
Epoch: 90 | Iteration number: [780/4518] 17% | Training loss: 0.6875620002165819
Epoch: 90 | Iteration number: [790/4518] 17% | Training loss: 0.6875528410265718
Epoch: 90 | Iteration number: [800/4518] 17% | Training loss: 0.6875396335870028
Epoch: 90 | Iteration number: [810/4518] 17% | Training loss: 0.6875405466850893
Epoch: 90 | Iteration number: [820/4518] 18% | Training loss: 0.6875392359931295
Epoch: 90 | Iteration number: [830/4518] 18% | Training loss: 0.6875423890280437
Epoch: 90 | Iteration number: [840/4518] 18% | Training loss: 0.6875314782063167
Epoch: 90 | Iteration number: [850/4518] 18% | Training loss: 0.6875093510571648
Epoch: 90 | Iteration number: [860/4518] 19% | Training loss: 0.6875083876210589
Epoch: 90 | Iteration number: [870/4518] 19% | Training loss: 0.6874896046073957
Epoch: 90 | Iteration number: [880/4518] 19% | Training loss: 0.6874903241341764
Epoch: 90 | Iteration number: [890/4518] 19% | Training loss: 0.6874747128299113
Epoch: 90 | Iteration number: [900/4518] 19% | Training loss: 0.6874697331587474
Epoch: 90 | Iteration number: [910/4518] 20% | Training loss: 0.6874683312007359
Epoch: 90 | Iteration number: [920/4518] 20% | Training loss: 0.6874576865978863
Epoch: 90 | Iteration number: [930/4518] 20% | Training loss: 0.6874408867410434
Epoch: 90 | Iteration number: [940/4518] 20% | Training loss: 0.6874321021298144
Epoch: 90 | Iteration number: [950/4518] 21% | Training loss: 0.687424018633993
Epoch: 90 | Iteration number: [960/4518] 21% | Training loss: 0.6874157889435689
Epoch: 90 | Iteration number: [970/4518] 21% | Training loss: 0.6874240950825288
Epoch: 90 | Iteration number: [980/4518] 21% | Training loss: 0.6874141856723902
Epoch: 90 | Iteration number: [990/4518] 21% | Training loss: 0.6873986885403142
Epoch: 90 | Iteration number: [1000/4518] 22% | Training loss: 0.6873797017335892
Epoch: 90 | Iteration number: [1010/4518] 22% | Training loss: 0.6873784445299961
Epoch: 90 | Iteration number: [1020/4518] 22% | Training loss: 0.6873664337630365
Epoch: 90 | Iteration number: [1030/4518] 22% | Training loss: 0.6873653822732203
Epoch: 90 | Iteration number: [1040/4518] 23% | Training loss: 0.6873586769287403
Epoch: 90 | Iteration number: [1050/4518] 23% | Training loss: 0.6873590222426823
Epoch: 90 | Iteration number: [1060/4518] 23% | Training loss: 0.6873477099076757
Epoch: 90 | Iteration number: [1070/4518] 23% | Training loss: 0.6873423941224535
Epoch: 90 | Iteration number: [1080/4518] 23% | Training loss: 0.6873234355339297
Epoch: 90 | Iteration number: [1090/4518] 24% | Training loss: 0.6873176421594183
Epoch: 90 | Iteration number: [1100/4518] 24% | Training loss: 0.6873155948790637
Epoch: 90 | Iteration number: [1110/4518] 24% | Training loss: 0.687313052233275
Epoch: 90 | Iteration number: [1120/4518] 24% | Training loss: 0.6872994761381831
Epoch: 90 | Iteration number: [1130/4518] 25% | Training loss: 0.6872858244760901
Epoch: 90 | Iteration number: [1140/4518] 25% | Training loss: 0.6872884334702241
Epoch: 90 | Iteration number: [1150/4518] 25% | Training loss: 0.6872809809187185
Epoch: 90 | Iteration number: [1160/4518] 25% | Training loss: 0.6872869395490351
Epoch: 90 | Iteration number: [1170/4518] 25% | Training loss: 0.6872826776443384
Epoch: 90 | Iteration number: [1180/4518] 26% | Training loss: 0.6872685182397649
Epoch: 90 | Iteration number: [1190/4518] 26% | Training loss: 0.6872671212468828
Epoch: 90 | Iteration number: [1200/4518] 26% | Training loss: 0.6872672528028488
Epoch: 90 | Iteration number: [1210/4518] 26% | Training loss: 0.6872520216240371
Epoch: 90 | Iteration number: [1220/4518] 27% | Training loss: 0.6872520451174408
Epoch: 90 | Iteration number: [1230/4518] 27% | Training loss: 0.6872567719560329
Epoch: 90 | Iteration number: [1240/4518] 27% | Training loss: 0.6872624012251054
Epoch: 90 | Iteration number: [1250/4518] 27% | Training loss: 0.6872667398452759
Epoch: 90 | Iteration number: [1260/4518] 27% | Training loss: 0.6872548579696625
Epoch: 90 | Iteration number: [1270/4518] 28% | Training loss: 0.6872572651528936
Epoch: 90 | Iteration number: [1280/4518] 28% | Training loss: 0.6872578115202487
Epoch: 90 | Iteration number: [1290/4518] 28% | Training loss: 0.6872485512448836
Epoch: 90 | Iteration number: [1300/4518] 28% | Training loss: 0.6872396882680746
Epoch: 90 | Iteration number: [1310/4518] 28% | Training loss: 0.6872418062377522
Epoch: 90 | Iteration number: [1320/4518] 29% | Training loss: 0.6872354051831997
Epoch: 90 | Iteration number: [1330/4518] 29% | Training loss: 0.6872286646437824
Epoch: 90 | Iteration number: [1340/4518] 29% | Training loss: 0.6872165229338318
Epoch: 90 | Iteration number: [1350/4518] 29% | Training loss: 0.6872139460510678
Epoch: 90 | Iteration number: [1360/4518] 30% | Training loss: 0.6872035297400811
Epoch: 90 | Iteration number: [1370/4518] 30% | Training loss: 0.6872094790865905
Epoch: 90 | Iteration number: [1380/4518] 30% | Training loss: 0.6871897336797438
Epoch: 90 | Iteration number: [1390/4518] 30% | Training loss: 0.6872031669393718
Epoch: 90 | Iteration number: [1400/4518] 30% | Training loss: 0.6872002719555582
Epoch: 90 | Iteration number: [1410/4518] 31% | Training loss: 0.6872004700467942
Epoch: 90 | Iteration number: [1420/4518] 31% | Training loss: 0.6871987429303182
Epoch: 90 | Iteration number: [1430/4518] 31% | Training loss: 0.6871954369378257
Epoch: 90 | Iteration number: [1440/4518] 31% | Training loss: 0.6871882648103766
Epoch: 90 | Iteration number: [1450/4518] 32% | Training loss: 0.6871916263267912
Epoch: 90 | Iteration number: [1460/4518] 32% | Training loss: 0.6871851250733415
Epoch: 90 | Iteration number: [1470/4518] 32% | Training loss: 0.6871843565078009
Epoch: 90 | Iteration number: [1480/4518] 32% | Training loss: 0.6871816524379962
Epoch: 90 | Iteration number: [1490/4518] 32% | Training loss: 0.6871806237521587
Epoch: 90 | Iteration number: [1500/4518] 33% | Training loss: 0.6871691613197327
Epoch: 90 | Iteration number: [1510/4518] 33% | Training loss: 0.6871781826019288
Epoch: 90 | Iteration number: [1520/4518] 33% | Training loss: 0.6871796567581202
Epoch: 90 | Iteration number: [1530/4518] 33% | Training loss: 0.6871754818882039
Epoch: 90 | Iteration number: [1540/4518] 34% | Training loss: 0.6871643056730171
Epoch: 90 | Iteration number: [1550/4518] 34% | Training loss: 0.6871584759604547
Epoch: 90 | Iteration number: [1560/4518] 34% | Training loss: 0.6871631541313269
Epoch: 90 | Iteration number: [1570/4518] 34% | Training loss: 0.6871534294003894
Epoch: 90 | Iteration number: [1580/4518] 34% | Training loss: 0.6871592842325379
Epoch: 90 | Iteration number: [1590/4518] 35% | Training loss: 0.6871514775468118
Epoch: 90 | Iteration number: [1600/4518] 35% | Training loss: 0.6871449876204133
Epoch: 90 | Iteration number: [1610/4518] 35% | Training loss: 0.687144194478574
Epoch: 90 | Iteration number: [1620/4518] 35% | Training loss: 0.6871425792758847
Epoch: 90 | Iteration number: [1630/4518] 36% | Training loss: 0.6871408971540767
Epoch: 90 | Iteration number: [1640/4518] 36% | Training loss: 0.6871329217058856
Epoch: 90 | Iteration number: [1650/4518] 36% | Training loss: 0.6871362749013034
Epoch: 90 | Iteration number: [1660/4518] 36% | Training loss: 0.687133748847318
Epoch: 90 | Iteration number: [1670/4518] 36% | Training loss: 0.6871295865424379
Epoch: 90 | Iteration number: [1680/4518] 37% | Training loss: 0.6871328647647585
Epoch: 90 | Iteration number: [1690/4518] 37% | Training loss: 0.6871229802363018
Epoch: 90 | Iteration number: [1700/4518] 37% | Training loss: 0.6871205256616368
Epoch: 90 | Iteration number: [1710/4518] 37% | Training loss: 0.6871192175045348
Epoch: 90 | Iteration number: [1720/4518] 38% | Training loss: 0.687119659538879
Epoch: 90 | Iteration number: [1730/4518] 38% | Training loss: 0.6871248622505651
Epoch: 90 | Iteration number: [1740/4518] 38% | Training loss: 0.6871155457250003
Epoch: 90 | Iteration number: [1750/4518] 38% | Training loss: 0.6871117356164115
Epoch: 90 | Iteration number: [1760/4518] 38% | Training loss: 0.6871024196120825
Epoch: 90 | Iteration number: [1770/4518] 39% | Training loss: 0.6871025740763562
Epoch: 90 | Iteration number: [1780/4518] 39% | Training loss: 0.687104699752304
Epoch: 90 | Iteration number: [1790/4518] 39% | Training loss: 0.6871059820971676
Epoch: 90 | Iteration number: [1800/4518] 39% | Training loss: 0.6871068488226997
Epoch: 90 | Iteration number: [1810/4518] 40% | Training loss: 0.6871037275751651
Epoch: 90 | Iteration number: [1820/4518] 40% | Training loss: 0.6871001950987092
Epoch: 90 | Iteration number: [1830/4518] 40% | Training loss: 0.687097451530519
Epoch: 90 | Iteration number: [1840/4518] 40% | Training loss: 0.6870995819892572
Epoch: 90 | Iteration number: [1850/4518] 40% | Training loss: 0.6871001095707352
Epoch: 90 | Iteration number: [1860/4518] 41% | Training loss: 0.6871017518543427
Epoch: 90 | Iteration number: [1870/4518] 41% | Training loss: 0.6870960932045697
Epoch: 90 | Iteration number: [1880/4518] 41% | Training loss: 0.6870947052823736
Epoch: 90 | Iteration number: [1890/4518] 41% | Training loss: 0.6870878258394817
Epoch: 90 | Iteration number: [1900/4518] 42% | Training loss: 0.6870879501418063
Epoch: 90 | Iteration number: [1910/4518] 42% | Training loss: 0.6870921759705269
Epoch: 90 | Iteration number: [1920/4518] 42% | Training loss: 0.6870907923206687
Epoch: 90 | Iteration number: [1930/4518] 42% | Training loss: 0.6870907752316233
Epoch: 90 | Iteration number: [1940/4518] 42% | Training loss: 0.6870945659494891
Epoch: 90 | Iteration number: [1950/4518] 43% | Training loss: 0.687092351088157
Epoch: 90 | Iteration number: [1960/4518] 43% | Training loss: 0.6870957852322228
Epoch: 90 | Iteration number: [1970/4518] 43% | Training loss: 0.6871009069650912
Epoch: 90 | Iteration number: [1980/4518] 43% | Training loss: 0.687101000878546
Epoch: 90 | Iteration number: [1990/4518] 44% | Training loss: 0.6870992042311472
Epoch: 90 | Iteration number: [2000/4518] 44% | Training loss: 0.68709518840909
Epoch: 90 | Iteration number: [2010/4518] 44% | Training loss: 0.6870955025971826
Epoch: 90 | Iteration number: [2020/4518] 44% | Training loss: 0.6871018485267564
Epoch: 90 | Iteration number: [2030/4518] 44% | Training loss: 0.6870993973879979
Epoch: 90 | Iteration number: [2040/4518] 45% | Training loss: 0.6871007386668055
Epoch: 90 | Iteration number: [2050/4518] 45% | Training loss: 0.687092055140472
Epoch: 90 | Iteration number: [2060/4518] 45% | Training loss: 0.6870920896240809
Epoch: 90 | Iteration number: [2070/4518] 45% | Training loss: 0.6870950400253425
Epoch: 90 | Iteration number: [2080/4518] 46% | Training loss: 0.68709920163338
Epoch: 90 | Iteration number: [2090/4518] 46% | Training loss: 0.6870929051529278
Epoch: 90 | Iteration number: [2100/4518] 46% | Training loss: 0.687097404627573
Epoch: 90 | Iteration number: [2110/4518] 46% | Training loss: 0.6870939576795316
Epoch: 90 | Iteration number: [2120/4518] 46% | Training loss: 0.687098309229005
Epoch: 90 | Iteration number: [2130/4518] 47% | Training loss: 0.6870992275750692
Epoch: 90 | Iteration number: [2140/4518] 47% | Training loss: 0.6870931897486482
Epoch: 90 | Iteration number: [2150/4518] 47% | Training loss: 0.6870903642510259
Epoch: 90 | Iteration number: [2160/4518] 47% | Training loss: 0.6870902879646531
Epoch: 90 | Iteration number: [2170/4518] 48% | Training loss: 0.687082387170484
Epoch: 90 | Iteration number: [2180/4518] 48% | Training loss: 0.687076458061507
Epoch: 90 | Iteration number: [2190/4518] 48% | Training loss: 0.6870715266765525
Epoch: 90 | Iteration number: [2200/4518] 48% | Training loss: 0.6870648968490687
Epoch: 90 | Iteration number: [2210/4518] 48% | Training loss: 0.6870617935560408
Epoch: 90 | Iteration number: [2220/4518] 49% | Training loss: 0.6870568122949686
Epoch: 90 | Iteration number: [2230/4518] 49% | Training loss: 0.6870560243792598
Epoch: 90 | Iteration number: [2240/4518] 49% | Training loss: 0.6870594874024392
Epoch: 90 | Iteration number: [2250/4518] 49% | Training loss: 0.687059907913208
Epoch: 90 | Iteration number: [2260/4518] 50% | Training loss: 0.68706075636159
Epoch: 90 | Iteration number: [2270/4518] 50% | Training loss: 0.6870638035730118
Epoch: 90 | Iteration number: [2280/4518] 50% | Training loss: 0.6870622947812081
Epoch: 90 | Iteration number: [2290/4518] 50% | Training loss: 0.6870641563396787
Epoch: 90 | Iteration number: [2300/4518] 50% | Training loss: 0.6870624720272811
Epoch: 90 | Iteration number: [2310/4518] 51% | Training loss: 0.6870643127532232
Epoch: 90 | Iteration number: [2320/4518] 51% | Training loss: 0.6870630909913573
Epoch: 90 | Iteration number: [2330/4518] 51% | Training loss: 0.6870587863635608
Epoch: 90 | Iteration number: [2340/4518] 51% | Training loss: 0.6870562780107189
Epoch: 90 | Iteration number: [2350/4518] 52% | Training loss: 0.6870529165420126
Epoch: 90 | Iteration number: [2360/4518] 52% | Training loss: 0.6870484117229106
Epoch: 90 | Iteration number: [2370/4518] 52% | Training loss: 0.6870488934879062
Epoch: 90 | Iteration number: [2380/4518] 52% | Training loss: 0.6870495135794167
Epoch: 90 | Iteration number: [2390/4518] 52% | Training loss: 0.6870466469970208
Epoch: 90 | Iteration number: [2400/4518] 53% | Training loss: 0.6870452348142863
Epoch: 90 | Iteration number: [2410/4518] 53% | Training loss: 0.687047131106072
Epoch: 90 | Iteration number: [2420/4518] 53% | Training loss: 0.6870385113580167
Epoch: 90 | Iteration number: [2430/4518] 53% | Training loss: 0.6870339575618383
Epoch: 90 | Iteration number: [2440/4518] 54% | Training loss: 0.6870333380142196
Epoch: 90 | Iteration number: [2450/4518] 54% | Training loss: 0.6870315560029477
Epoch: 90 | Iteration number: [2460/4518] 54% | Training loss: 0.687030642303994
Epoch: 90 | Iteration number: [2470/4518] 54% | Training loss: 0.6870235150159612
Epoch: 90 | Iteration number: [2480/4518] 54% | Training loss: 0.6870240976252864
Epoch: 90 | Iteration number: [2490/4518] 55% | Training loss: 0.6870195376107013
Epoch: 90 | Iteration number: [2500/4518] 55% | Training loss: 0.6870208772659302
Epoch: 90 | Iteration number: [2510/4518] 55% | Training loss: 0.6870217589980577
Epoch: 90 | Iteration number: [2520/4518] 55% | Training loss: 0.6870307511990033
Epoch: 90 | Iteration number: [2530/4518] 55% | Training loss: 0.6870288242464481
Epoch: 90 | Iteration number: [2540/4518] 56% | Training loss: 0.6870276919734759
Epoch: 90 | Iteration number: [2550/4518] 56% | Training loss: 0.6870253502855114
Epoch: 90 | Iteration number: [2560/4518] 56% | Training loss: 0.6870264371624216
Epoch: 90 | Iteration number: [2570/4518] 56% | Training loss: 0.6870240739579331
Epoch: 90 | Iteration number: [2580/4518] 57% | Training loss: 0.6870270409556323
Epoch: 90 | Iteration number: [2590/4518] 57% | Training loss: 0.6870204088540611
Epoch: 90 | Iteration number: [2600/4518] 57% | Training loss: 0.6870185041198363
Epoch: 90 | Iteration number: [2610/4518] 57% | Training loss: 0.6870139631960127
Epoch: 90 | Iteration number: [2620/4518] 57% | Training loss: 0.6870132197860543
Epoch: 90 | Iteration number: [2630/4518] 58% | Training loss: 0.6870136685924385
Epoch: 90 | Iteration number: [2640/4518] 58% | Training loss: 0.6870088641616431
Epoch: 90 | Iteration number: [2650/4518] 58% | Training loss: 0.6870110114340512
Epoch: 90 | Iteration number: [2660/4518] 58% | Training loss: 0.6870097974637397
Epoch: 90 | Iteration number: [2670/4518] 59% | Training loss: 0.68700718183196
Epoch: 90 | Iteration number: [2680/4518] 59% | Training loss: 0.6870044727823628
Epoch: 90 | Iteration number: [2690/4518] 59% | Training loss: 0.6869961141653663
Epoch: 90 | Iteration number: [2700/4518] 59% | Training loss: 0.6869956670425557
Epoch: 90 | Iteration number: [2710/4518] 59% | Training loss: 0.6869898056412095
Epoch: 90 | Iteration number: [2720/4518] 60% | Training loss: 0.6869884806301664
Epoch: 90 | Iteration number: [2730/4518] 60% | Training loss: 0.6869893767239846
Epoch: 90 | Iteration number: [2740/4518] 60% | Training loss: 0.6869871846298232
Epoch: 90 | Iteration number: [2750/4518] 60% | Training loss: 0.686987964998592
Epoch: 90 | Iteration number: [2760/4518] 61% | Training loss: 0.6869904137823892
Epoch: 90 | Iteration number: [2770/4518] 61% | Training loss: 0.6869901185646815
Epoch: 90 | Iteration number: [2780/4518] 61% | Training loss: 0.6869867484346568
Epoch: 90 | Iteration number: [2790/4518] 61% | Training loss: 0.6869875636152042
Epoch: 90 | Iteration number: [2800/4518] 61% | Training loss: 0.6869891959641661
Epoch: 90 | Iteration number: [2810/4518] 62% | Training loss: 0.6869901867523737
Epoch: 90 | Iteration number: [2820/4518] 62% | Training loss: 0.6869886373374479
Epoch: 90 | Iteration number: [2830/4518] 62% | Training loss: 0.6869905159245953
Epoch: 90 | Iteration number: [2840/4518] 62% | Training loss: 0.6869911247785663
Epoch: 90 | Iteration number: [2850/4518] 63% | Training loss: 0.6869900329907735
Epoch: 90 | Iteration number: [2860/4518] 63% | Training loss: 0.6869917998155514
Epoch: 90 | Iteration number: [2870/4518] 63% | Training loss: 0.6869867834479967
Epoch: 90 | Iteration number: [2880/4518] 63% | Training loss: 0.6869829474017024
Epoch: 90 | Iteration number: [2890/4518] 63% | Training loss: 0.6869806911912344
Epoch: 90 | Iteration number: [2900/4518] 64% | Training loss: 0.6869812772397337
Epoch: 90 | Iteration number: [2910/4518] 64% | Training loss: 0.6869785310886161
Epoch: 90 | Iteration number: [2920/4518] 64% | Training loss: 0.6869773642657554
Epoch: 90 | Iteration number: [2930/4518] 64% | Training loss: 0.6869788806389623
Epoch: 90 | Iteration number: [2940/4518] 65% | Training loss: 0.6869766513101098
Epoch: 90 | Iteration number: [2950/4518] 65% | Training loss: 0.6869752133700807
Epoch: 90 | Iteration number: [2960/4518] 65% | Training loss: 0.6869741640582278
Epoch: 90 | Iteration number: [2970/4518] 65% | Training loss: 0.6869661407639281
Epoch: 90 | Iteration number: [2980/4518] 65% | Training loss: 0.6869643339974768
Epoch: 90 | Iteration number: [2990/4518] 66% | Training loss: 0.6869583369098778
Epoch: 90 | Iteration number: [3000/4518] 66% | Training loss: 0.6869602133631706
Epoch: 90 | Iteration number: [3010/4518] 66% | Training loss: 0.6869646389619061
Epoch: 90 | Iteration number: [3020/4518] 66% | Training loss: 0.6869650393527075
Epoch: 90 | Iteration number: [3030/4518] 67% | Training loss: 0.686964362623668
Epoch: 90 | Iteration number: [3040/4518] 67% | Training loss: 0.6869669105269407
Epoch: 90 | Iteration number: [3050/4518] 67% | Training loss: 0.6869709973843371
Epoch: 90 | Iteration number: [3060/4518] 67% | Training loss: 0.6869727560118133
Epoch: 90 | Iteration number: [3070/4518] 67% | Training loss: 0.6869700038083602
Epoch: 90 | Iteration number: [3080/4518] 68% | Training loss: 0.6869713457760873
Epoch: 90 | Iteration number: [3090/4518] 68% | Training loss: 0.686968091159191
Epoch: 90 | Iteration number: [3100/4518] 68% | Training loss: 0.6869651212999898
Epoch: 90 | Iteration number: [3110/4518] 68% | Training loss: 0.6869655018834055
Epoch: 90 | Iteration number: [3120/4518] 69% | Training loss: 0.6869654597571263
Epoch: 90 | Iteration number: [3130/4518] 69% | Training loss: 0.6869629391656517
Epoch: 90 | Iteration number: [3140/4518] 69% | Training loss: 0.6869625097816917
Epoch: 90 | Iteration number: [3150/4518] 69% | Training loss: 0.686960375403601
Epoch: 90 | Iteration number: [3160/4518] 69% | Training loss: 0.6869584934998162
Epoch: 90 | Iteration number: [3170/4518] 70% | Training loss: 0.6869609154737334
Epoch: 90 | Iteration number: [3180/4518] 70% | Training loss: 0.6869637925107525
Epoch: 90 | Iteration number: [3190/4518] 70% | Training loss: 0.6869584060014229
Epoch: 90 | Iteration number: [3200/4518] 70% | Training loss: 0.6869571801275015
Epoch: 90 | Iteration number: [3210/4518] 71% | Training loss: 0.6869548980692094
Epoch: 90 | Iteration number: [3220/4518] 71% | Training loss: 0.6869535738266773
Epoch: 90 | Iteration number: [3230/4518] 71% | Training loss: 0.6869545223912218
Epoch: 90 | Iteration number: [3240/4518] 71% | Training loss: 0.6869504010235822
Epoch: 90 | Iteration number: [3250/4518] 71% | Training loss: 0.6869507749814253
Epoch: 90 | Iteration number: [3260/4518] 72% | Training loss: 0.6869507449170563
Epoch: 90 | Iteration number: [3270/4518] 72% | Training loss: 0.6869530152472516
Epoch: 90 | Iteration number: [3280/4518] 72% | Training loss: 0.6869504207881486
Epoch: 90 | Iteration number: [3290/4518] 72% | Training loss: 0.6869491915572378
Epoch: 90 | Iteration number: [3300/4518] 73% | Training loss: 0.6869495269024011
Epoch: 90 | Iteration number: [3310/4518] 73% | Training loss: 0.6869454967471408
Epoch: 90 | Iteration number: [3320/4518] 73% | Training loss: 0.6869419980839074
Epoch: 90 | Iteration number: [3330/4518] 73% | Training loss: 0.6869400076679997
Epoch: 90 | Iteration number: [3340/4518] 73% | Training loss: 0.686939795591874
Epoch: 90 | Iteration number: [3350/4518] 74% | Training loss: 0.6869383771739789
Epoch: 90 | Iteration number: [3360/4518] 74% | Training loss: 0.6869409826007628
Epoch: 90 | Iteration number: [3370/4518] 74% | Training loss: 0.6869427493665622
Epoch: 90 | Iteration number: [3380/4518] 74% | Training loss: 0.686940852036843
Epoch: 90 | Iteration number: [3390/4518] 75% | Training loss: 0.686942860334672
Epoch: 90 | Iteration number: [3400/4518] 75% | Training loss: 0.6869382852315903
Epoch: 90 | Iteration number: [3410/4518] 75% | Training loss: 0.6869385627008253
Epoch: 90 | Iteration number: [3420/4518] 75% | Training loss: 0.6869399540779884
Epoch: 90 | Iteration number: [3430/4518] 75% | Training loss: 0.6869405097586073
Epoch: 90 | Iteration number: [3440/4518] 76% | Training loss: 0.6869419166861579
Epoch: 90 | Iteration number: [3450/4518] 76% | Training loss: 0.6869395662045134
Epoch: 90 | Iteration number: [3460/4518] 76% | Training loss: 0.6869376766543857
Epoch: 90 | Iteration number: [3470/4518] 76% | Training loss: 0.6869357172109896
Epoch: 90 | Iteration number: [3480/4518] 77% | Training loss: 0.686938441553335
Epoch: 90 | Iteration number: [3490/4518] 77% | Training loss: 0.6869405370216315
Epoch: 90 | Iteration number: [3500/4518] 77% | Training loss: 0.6869380986690521
Epoch: 90 | Iteration number: [3510/4518] 77% | Training loss: 0.6869398630412555
Epoch: 90 | Iteration number: [3520/4518] 77% | Training loss: 0.6869341402399269
Epoch: 90 | Iteration number: [3530/4518] 78% | Training loss: 0.6869325054772515
Epoch: 90 | Iteration number: [3540/4518] 78% | Training loss: 0.6869316494734273
Epoch: 90 | Iteration number: [3550/4518] 78% | Training loss: 0.6869305148930617
Epoch: 90 | Iteration number: [3560/4518] 78% | Training loss: 0.6869280874561727
Epoch: 90 | Iteration number: [3570/4518] 79% | Training loss: 0.6869312488064379
Epoch: 90 | Iteration number: [3580/4518] 79% | Training loss: 0.6869291740589302
Epoch: 90 | Iteration number: [3590/4518] 79% | Training loss: 0.6869339972319377
Epoch: 90 | Iteration number: [3600/4518] 79% | Training loss: 0.6869358942243788
Epoch: 90 | Iteration number: [3610/4518] 79% | Training loss: 0.6869358477830226
Epoch: 90 | Iteration number: [3620/4518] 80% | Training loss: 0.6869344259987878
Epoch: 90 | Iteration number: [3630/4518] 80% | Training loss: 0.6869327133680506
Epoch: 90 | Iteration number: [3640/4518] 80% | Training loss: 0.686933260844959
Epoch: 90 | Iteration number: [3650/4518] 80% | Training loss: 0.6869332135703465
Epoch: 90 | Iteration number: [3660/4518] 81% | Training loss: 0.6869335149806706
Epoch: 90 | Iteration number: [3670/4518] 81% | Training loss: 0.6869306701405496
Epoch: 90 | Iteration number: [3680/4518] 81% | Training loss: 0.6869274255698142
Epoch: 90 | Iteration number: [3690/4518] 81% | Training loss: 0.6869297423821478
Epoch: 90 | Iteration number: [3700/4518] 81% | Training loss: 0.6869331145447654
Epoch: 90 | Iteration number: [3710/4518] 82% | Training loss: 0.6869352912806437
Epoch: 90 | Iteration number: [3720/4518] 82% | Training loss: 0.6869301557380666
Epoch: 90 | Iteration number: [3730/4518] 82% | Training loss: 0.6869287533510786
Epoch: 90 | Iteration number: [3740/4518] 82% | Training loss: 0.6869257973317794
Epoch: 90 | Iteration number: [3750/4518] 83% | Training loss: 0.6869264032840728
Epoch: 90 | Iteration number: [3760/4518] 83% | Training loss: 0.6869252494358001
Epoch: 90 | Iteration number: [3770/4518] 83% | Training loss: 0.6869247201583114
Epoch: 90 | Iteration number: [3780/4518] 83% | Training loss: 0.686927002605307
Epoch: 90 | Iteration number: [3790/4518] 83% | Training loss: 0.6869301848958853
Epoch: 90 | Iteration number: [3800/4518] 84% | Training loss: 0.6869273543671558
Epoch: 90 | Iteration number: [3810/4518] 84% | Training loss: 0.6869286050633808
Epoch: 90 | Iteration number: [3820/4518] 84% | Training loss: 0.686927708764975
Epoch: 90 | Iteration number: [3830/4518] 84% | Training loss: 0.6869304955472523
Epoch: 90 | Iteration number: [3840/4518] 84% | Training loss: 0.686929317486162
Epoch: 90 | Iteration number: [3850/4518] 85% | Training loss: 0.6869284036716857
Epoch: 90 | Iteration number: [3860/4518] 85% | Training loss: 0.6869245064073276
Epoch: 90 | Iteration number: [3870/4518] 85% | Training loss: 0.6869276191683087
Epoch: 90 | Iteration number: [3880/4518] 85% | Training loss: 0.6869301467673066
Epoch: 90 | Iteration number: [3890/4518] 86% | Training loss: 0.686931321522877
Epoch: 90 | Iteration number: [3900/4518] 86% | Training loss: 0.6869303830770346
Epoch: 90 | Iteration number: [3910/4518] 86% | Training loss: 0.686933208411307
Epoch: 90 | Iteration number: [3920/4518] 86% | Training loss: 0.6869298797937072
Epoch: 90 | Iteration number: [3930/4518] 86% | Training loss: 0.6869303149728071
Epoch: 90 | Iteration number: [3940/4518] 87% | Training loss: 0.6869301217612881
Epoch: 90 | Iteration number: [3950/4518] 87% | Training loss: 0.6869252629219731
Epoch: 90 | Iteration number: [3960/4518] 87% | Training loss: 0.6869253783364488
Epoch: 90 | Iteration number: [3970/4518] 87% | Training loss: 0.6869260824597453
Epoch: 90 | Iteration number: [3980/4518] 88% | Training loss: 0.6869243159965055
Epoch: 90 | Iteration number: [3990/4518] 88% | Training loss: 0.6869245345431163
Epoch: 90 | Iteration number: [4000/4518] 88% | Training loss: 0.6869223830848932
Epoch: 90 | Iteration number: [4010/4518] 88% | Training loss: 0.6869183362868064
Epoch: 90 | Iteration number: [4020/4518] 88% | Training loss: 0.6869187178748164
Epoch: 90 | Iteration number: [4030/4518] 89% | Training loss: 0.6869204090635475
Epoch: 90 | Iteration number: [4040/4518] 89% | Training loss: 0.6869152787593331
Epoch: 90 | Iteration number: [4050/4518] 89% | Training loss: 0.686915288309992
Epoch: 90 | Iteration number: [4060/4518] 89% | Training loss: 0.6869151512683906
Epoch: 90 | Iteration number: [4070/4518] 90% | Training loss: 0.6869097522640697
Epoch: 90 | Iteration number: [4080/4518] 90% | Training loss: 0.6869102530619677
Epoch: 90 | Iteration number: [4090/4518] 90% | Training loss: 0.6869084772824658
Epoch: 90 | Iteration number: [4100/4518] 90% | Training loss: 0.6869071604129745
Epoch: 90 | Iteration number: [4110/4518] 90% | Training loss: 0.6869062904023776
Epoch: 90 | Iteration number: [4120/4518] 91% | Training loss: 0.6869073321229046
Epoch: 90 | Iteration number: [4130/4518] 91% | Training loss: 0.6869056577399626
Epoch: 90 | Iteration number: [4140/4518] 91% | Training loss: 0.6869043940363299
Epoch: 90 | Iteration number: [4150/4518] 91% | Training loss: 0.6869045991495432
Epoch: 90 | Iteration number: [4160/4518] 92% | Training loss: 0.6869046890248472
Epoch: 90 | Iteration number: [4170/4518] 92% | Training loss: 0.6869038005669912
Epoch: 90 | Iteration number: [4180/4518] 92% | Training loss: 0.6869025307836715
Epoch: 90 | Iteration number: [4190/4518] 92% | Training loss: 0.6869028140223965
Epoch: 90 | Iteration number: [4200/4518] 92% | Training loss: 0.6869062386098362
Epoch: 90 | Iteration number: [4210/4518] 93% | Training loss: 0.686903943089578
Epoch: 90 | Iteration number: [4220/4518] 93% | Training loss: 0.6869042005584138
Epoch: 90 | Iteration number: [4230/4518] 93% | Training loss: 0.6869045197963715
Epoch: 90 | Iteration number: [4240/4518] 93% | Training loss: 0.6869036701630872
Epoch: 90 | Iteration number: [4250/4518] 94% | Training loss: 0.6869053170400508
Epoch: 90 | Iteration number: [4260/4518] 94% | Training loss: 0.6869053520926847
Epoch: 90 | Iteration number: [4270/4518] 94% | Training loss: 0.6869060517194958
Epoch: 90 | Iteration number: [4280/4518] 94% | Training loss: 0.6869041201667251
Epoch: 90 | Iteration number: [4290/4518] 94% | Training loss: 0.6869043665471333
Epoch: 90 | Iteration number: [4300/4518] 95% | Training loss: 0.6869068280347558
Epoch: 90 | Iteration number: [4310/4518] 95% | Training loss: 0.6869085781950408
Epoch: 90 | Iteration number: [4320/4518] 95% | Training loss: 0.6869095489796665
Epoch: 90 | Iteration number: [4330/4518] 95% | Training loss: 0.6869108848566271
Epoch: 90 | Iteration number: [4340/4518] 96% | Training loss: 0.6869107656352531
Epoch: 90 | Iteration number: [4350/4518] 96% | Training loss: 0.6869113674246031
Epoch: 90 | Iteration number: [4360/4518] 96% | Training loss: 0.686912493230006
Epoch: 90 | Iteration number: [4370/4518] 96% | Training loss: 0.6869097225044085
Epoch: 90 | Iteration number: [4380/4518] 96% | Training loss: 0.6869080891347912
Epoch: 90 | Iteration number: [4390/4518] 97% | Training loss: 0.6869063553886153
Epoch: 90 | Iteration number: [4400/4518] 97% | Training loss: 0.6869066387279467
Epoch: 90 | Iteration number: [4410/4518] 97% | Training loss: 0.6869078744836405
Epoch: 90 | Iteration number: [4420/4518] 97% | Training loss: 0.6869091094753861
Epoch: 90 | Iteration number: [4430/4518] 98% | Training loss: 0.6869066673530682
Epoch: 90 | Iteration number: [4440/4518] 98% | Training loss: 0.6869064459258372
Epoch: 90 | Iteration number: [4450/4518] 98% | Training loss: 0.6869058739201407
Epoch: 90 | Iteration number: [4460/4518] 98% | Training loss: 0.6869037367035989
Epoch: 90 | Iteration number: [4470/4518] 98% | Training loss: 0.686902587899159
Epoch: 90 | Iteration number: [4480/4518] 99% | Training loss: 0.6869035822339356
Epoch: 90 | Iteration number: [4490/4518] 99% | Training loss: 0.68690490860716
Epoch: 90 | Iteration number: [4500/4518] 99% | Training loss: 0.6869061970975664
Epoch: 90 | Iteration number: [4510/4518] 99% | Training loss: 0.6869072492794028

 End of epoch: 90 | Train Loss: 0.686754310906804 | Training Time: 642 

 End of epoch: 90 | Eval Loss: 0.6897782391431381 | Evaluating Time: 17 
Epoch: 91 | Iteration number: [10/4518] 0% | Training loss: 0.7560067772865295
Epoch: 91 | Iteration number: [20/4518] 0% | Training loss: 0.7211264967918396
Epoch: 91 | Iteration number: [30/4518] 0% | Training loss: 0.7099430362383524
Epoch: 91 | Iteration number: [40/4518] 0% | Training loss: 0.7042710036039352
Epoch: 91 | Iteration number: [50/4518] 1% | Training loss: 0.7008735084533692
Epoch: 91 | Iteration number: [60/4518] 1% | Training loss: 0.6984378784894943
Epoch: 91 | Iteration number: [70/4518] 1% | Training loss: 0.696741611616952
Epoch: 91 | Iteration number: [80/4518] 1% | Training loss: 0.6955570101737976
Epoch: 91 | Iteration number: [90/4518] 1% | Training loss: 0.6945613536569807
Epoch: 91 | Iteration number: [100/4518] 2% | Training loss: 0.693843139410019
Epoch: 91 | Iteration number: [110/4518] 2% | Training loss: 0.693093941970305
Epoch: 91 | Iteration number: [120/4518] 2% | Training loss: 0.6924472957849502
Epoch: 91 | Iteration number: [130/4518] 2% | Training loss: 0.6919468058989598
Epoch: 91 | Iteration number: [140/4518] 3% | Training loss: 0.6916260600090027
Epoch: 91 | Iteration number: [150/4518] 3% | Training loss: 0.6912934303283691
Epoch: 91 | Iteration number: [160/4518] 3% | Training loss: 0.6909850988537073
Epoch: 91 | Iteration number: [170/4518] 3% | Training loss: 0.6907571066828335
Epoch: 91 | Iteration number: [180/4518] 3% | Training loss: 0.6905326180987887
Epoch: 91 | Iteration number: [190/4518] 4% | Training loss: 0.6902690398065667
Epoch: 91 | Iteration number: [200/4518] 4% | Training loss: 0.6901251325011253
Epoch: 91 | Iteration number: [210/4518] 4% | Training loss: 0.690016047727494
Epoch: 91 | Iteration number: [220/4518] 4% | Training loss: 0.689928021214225
Epoch: 91 | Iteration number: [230/4518] 5% | Training loss: 0.6897991265939629
Epoch: 91 | Iteration number: [240/4518] 5% | Training loss: 0.6896659540633361
Epoch: 91 | Iteration number: [250/4518] 5% | Training loss: 0.6896126327514649
Epoch: 91 | Iteration number: [260/4518] 5% | Training loss: 0.6894538785402592
Epoch: 91 | Iteration number: [270/4518] 5% | Training loss: 0.6893527132493479
Epoch: 91 | Iteration number: [280/4518] 6% | Training loss: 0.6892870670982769
Epoch: 91 | Iteration number: [290/4518] 6% | Training loss: 0.689180438888484
Epoch: 91 | Iteration number: [300/4518] 6% | Training loss: 0.6891078841686249
Epoch: 91 | Iteration number: [310/4518] 6% | Training loss: 0.689037101307223
Epoch: 91 | Iteration number: [320/4518] 7% | Training loss: 0.6889369510114193
Epoch: 91 | Iteration number: [330/4518] 7% | Training loss: 0.688850176153761
Epoch: 91 | Iteration number: [340/4518] 7% | Training loss: 0.6887996480745427
Epoch: 91 | Iteration number: [350/4518] 7% | Training loss: 0.688710903269904
Epoch: 91 | Iteration number: [360/4518] 7% | Training loss: 0.6887121778395441
Epoch: 91 | Iteration number: [370/4518] 8% | Training loss: 0.6886605472178072
Epoch: 91 | Iteration number: [380/4518] 8% | Training loss: 0.6886333600470894
Epoch: 91 | Iteration number: [390/4518] 8% | Training loss: 0.6886252144972483
Epoch: 91 | Iteration number: [400/4518] 8% | Training loss: 0.6885497860610486
Epoch: 91 | Iteration number: [410/4518] 9% | Training loss: 0.6884866553108867
Epoch: 91 | Iteration number: [420/4518] 9% | Training loss: 0.6884432877813067
Epoch: 91 | Iteration number: [430/4518] 9% | Training loss: 0.6884263602800147
Epoch: 91 | Iteration number: [440/4518] 9% | Training loss: 0.6883818165822463
Epoch: 91 | Iteration number: [450/4518] 9% | Training loss: 0.6883706121974521
Epoch: 91 | Iteration number: [460/4518] 10% | Training loss: 0.6883656360532926
Epoch: 91 | Iteration number: [470/4518] 10% | Training loss: 0.6883211818147212
Epoch: 91 | Iteration number: [480/4518] 10% | Training loss: 0.6882912038515011
Epoch: 91 | Iteration number: [490/4518] 10% | Training loss: 0.6882606434578799
Epoch: 91 | Iteration number: [500/4518] 11% | Training loss: 0.6881842271089554
Epoch: 91 | Iteration number: [510/4518] 11% | Training loss: 0.6881694202329598
Epoch: 91 | Iteration number: [520/4518] 11% | Training loss: 0.6881207038576787
Epoch: 91 | Iteration number: [530/4518] 11% | Training loss: 0.6880972299935683
Epoch: 91 | Iteration number: [540/4518] 11% | Training loss: 0.6880782003755923
Epoch: 91 | Iteration number: [550/4518] 12% | Training loss: 0.6880391618338498
Epoch: 91 | Iteration number: [560/4518] 12% | Training loss: 0.6880267579640661
Epoch: 91 | Iteration number: [570/4518] 12% | Training loss: 0.6879948142327761
Epoch: 91 | Iteration number: [580/4518] 12% | Training loss: 0.6879655673586089
Epoch: 91 | Iteration number: [590/4518] 13% | Training loss: 0.6879448520935187
Epoch: 91 | Iteration number: [600/4518] 13% | Training loss: 0.6879250141978264
Epoch: 91 | Iteration number: [610/4518] 13% | Training loss: 0.6879140581263871
Epoch: 91 | Iteration number: [620/4518] 13% | Training loss: 0.6878915378162938
Epoch: 91 | Iteration number: [630/4518] 13% | Training loss: 0.6878781218377371
Epoch: 91 | Iteration number: [640/4518] 14% | Training loss: 0.6878616842441261
Epoch: 91 | Iteration number: [650/4518] 14% | Training loss: 0.6878355426054734
Epoch: 91 | Iteration number: [660/4518] 14% | Training loss: 0.6878323706713589
Epoch: 91 | Iteration number: [670/4518] 14% | Training loss: 0.687834206356931
Epoch: 91 | Iteration number: [680/4518] 15% | Training loss: 0.6878149826737011
Epoch: 91 | Iteration number: [690/4518] 15% | Training loss: 0.6878058008525683
Epoch: 91 | Iteration number: [700/4518] 15% | Training loss: 0.6877693948575428
Epoch: 91 | Iteration number: [710/4518] 15% | Training loss: 0.687748279454003
Epoch: 91 | Iteration number: [720/4518] 15% | Training loss: 0.6877436443335481
Epoch: 91 | Iteration number: [730/4518] 16% | Training loss: 0.6877160434853541
Epoch: 91 | Iteration number: [740/4518] 16% | Training loss: 0.687735600487606
Epoch: 91 | Iteration number: [750/4518] 16% | Training loss: 0.6877040285269419
Epoch: 91 | Iteration number: [760/4518] 16% | Training loss: 0.6876939793950633
Epoch: 91 | Iteration number: [770/4518] 17% | Training loss: 0.6876651910218325
Epoch: 91 | Iteration number: [780/4518] 17% | Training loss: 0.6876738833311277
Epoch: 91 | Iteration number: [790/4518] 17% | Training loss: 0.6876468869704234
Epoch: 91 | Iteration number: [800/4518] 17% | Training loss: 0.6876401382684708
Epoch: 91 | Iteration number: [810/4518] 17% | Training loss: 0.6876251709314041
Epoch: 91 | Iteration number: [820/4518] 18% | Training loss: 0.6876088308125008
Epoch: 91 | Iteration number: [830/4518] 18% | Training loss: 0.6875988661524761
Epoch: 91 | Iteration number: [840/4518] 18% | Training loss: 0.6876137304873694
Epoch: 91 | Iteration number: [850/4518] 18% | Training loss: 0.6876020283558789
Epoch: 91 | Iteration number: [860/4518] 19% | Training loss: 0.6876042093648467
Epoch: 91 | Iteration number: [870/4518] 19% | Training loss: 0.6876050413339988
Epoch: 91 | Iteration number: [880/4518] 19% | Training loss: 0.6875798685306852
Epoch: 91 | Iteration number: [890/4518] 19% | Training loss: 0.6875734347305941
Epoch: 91 | Iteration number: [900/4518] 19% | Training loss: 0.6875599347220527
Epoch: 91 | Iteration number: [910/4518] 20% | Training loss: 0.6875542015819759
Epoch: 91 | Iteration number: [920/4518] 20% | Training loss: 0.6875283896923066
Epoch: 91 | Iteration number: [930/4518] 20% | Training loss: 0.6875212639890691
Epoch: 91 | Iteration number: [940/4518] 20% | Training loss: 0.6875148769388808
Epoch: 91 | Iteration number: [950/4518] 21% | Training loss: 0.6875060286647395
Epoch: 91 | Iteration number: [960/4518] 21% | Training loss: 0.687507177516818
Epoch: 91 | Iteration number: [970/4518] 21% | Training loss: 0.6875034582983587
Epoch: 91 | Iteration number: [980/4518] 21% | Training loss: 0.6874987223318645
Epoch: 91 | Iteration number: [990/4518] 21% | Training loss: 0.6874997984279286
Epoch: 91 | Iteration number: [1000/4518] 22% | Training loss: 0.6874944968819618
Epoch: 91 | Iteration number: [1010/4518] 22% | Training loss: 0.6874953051014702
Epoch: 91 | Iteration number: [1020/4518] 22% | Training loss: 0.6874978762046964
Epoch: 91 | Iteration number: [1030/4518] 22% | Training loss: 0.6874949319270051
Epoch: 91 | Iteration number: [1040/4518] 23% | Training loss: 0.6874845700768324
Epoch: 91 | Iteration number: [1050/4518] 23% | Training loss: 0.6874668604987009
Epoch: 91 | Iteration number: [1060/4518] 23% | Training loss: 0.6874526603041955
Epoch: 91 | Iteration number: [1070/4518] 23% | Training loss: 0.6874427396560384
Epoch: 91 | Iteration number: [1080/4518] 23% | Training loss: 0.6874402132299211
Epoch: 91 | Iteration number: [1090/4518] 24% | Training loss: 0.6874398917233179
Epoch: 91 | Iteration number: [1100/4518] 24% | Training loss: 0.6874265707081014
Epoch: 91 | Iteration number: [1110/4518] 24% | Training loss: 0.6874211102455586
Epoch: 91 | Iteration number: [1120/4518] 24% | Training loss: 0.6874092321310724
Epoch: 91 | Iteration number: [1130/4518] 25% | Training loss: 0.687411427972591
Epoch: 91 | Iteration number: [1140/4518] 25% | Training loss: 0.6874133172788118
Epoch: 91 | Iteration number: [1150/4518] 25% | Training loss: 0.6874040008109549
Epoch: 91 | Iteration number: [1160/4518] 25% | Training loss: 0.68739383970869
Epoch: 91 | Iteration number: [1170/4518] 25% | Training loss: 0.6873901328469953
Epoch: 91 | Iteration number: [1180/4518] 26% | Training loss: 0.6873813011383606
Epoch: 91 | Iteration number: [1190/4518] 26% | Training loss: 0.6873765959459193
Epoch: 91 | Iteration number: [1200/4518] 26% | Training loss: 0.6873760717113813
Epoch: 91 | Iteration number: [1210/4518] 26% | Training loss: 0.6873755393442044
Epoch: 91 | Iteration number: [1220/4518] 27% | Training loss: 0.687355669306927
Epoch: 91 | Iteration number: [1230/4518] 27% | Training loss: 0.6873380156551919
Epoch: 91 | Iteration number: [1240/4518] 27% | Training loss: 0.6873334579890774
Epoch: 91 | Iteration number: [1250/4518] 27% | Training loss: 0.6873286972999573
Epoch: 91 | Iteration number: [1260/4518] 27% | Training loss: 0.6873265039353144
Epoch: 91 | Iteration number: [1270/4518] 28% | Training loss: 0.6873235391819571
Epoch: 91 | Iteration number: [1280/4518] 28% | Training loss: 0.687318723089993
Epoch: 91 | Iteration number: [1290/4518] 28% | Training loss: 0.687317109662433
Epoch: 91 | Iteration number: [1300/4518] 28% | Training loss: 0.6873190057277679
Epoch: 91 | Iteration number: [1310/4518] 28% | Training loss: 0.6873157107648049
Epoch: 91 | Iteration number: [1320/4518] 29% | Training loss: 0.687313702296127
Epoch: 91 | Iteration number: [1330/4518] 29% | Training loss: 0.6873072871588226
Epoch: 91 | Iteration number: [1340/4518] 29% | Training loss: 0.6873008782294259
Epoch: 91 | Iteration number: [1350/4518] 29% | Training loss: 0.6872948145866394
Epoch: 91 | Iteration number: [1360/4518] 30% | Training loss: 0.6872945741257247
Epoch: 91 | Iteration number: [1370/4518] 30% | Training loss: 0.6872879921519843
Epoch: 91 | Iteration number: [1380/4518] 30% | Training loss: 0.687286702748658
Epoch: 91 | Iteration number: [1390/4518] 30% | Training loss: 0.6872940431824691
Epoch: 91 | Iteration number: [1400/4518] 30% | Training loss: 0.6872861699547086
Epoch: 91 | Iteration number: [1410/4518] 31% | Training loss: 0.6872732643962752
Epoch: 91 | Iteration number: [1420/4518] 31% | Training loss: 0.6872688259457199
Epoch: 91 | Iteration number: [1430/4518] 31% | Training loss: 0.6872675808993253
Epoch: 91 | Iteration number: [1440/4518] 31% | Training loss: 0.6872589735935132
Epoch: 91 | Iteration number: [1450/4518] 32% | Training loss: 0.6872653764691846
Epoch: 91 | Iteration number: [1460/4518] 32% | Training loss: 0.6872675172270161
Epoch: 91 | Iteration number: [1470/4518] 32% | Training loss: 0.6872635900974273
Epoch: 91 | Iteration number: [1480/4518] 32% | Training loss: 0.6872625724689381
Epoch: 91 | Iteration number: [1490/4518] 32% | Training loss: 0.6872645349310549
Epoch: 91 | Iteration number: [1500/4518] 33% | Training loss: 0.6872616157929102
Epoch: 91 | Iteration number: [1510/4518] 33% | Training loss: 0.687259258102897
Epoch: 91 | Iteration number: [1520/4518] 33% | Training loss: 0.6872514241227978
Epoch: 91 | Iteration number: [1530/4518] 33% | Training loss: 0.6872510038559733
Epoch: 91 | Iteration number: [1540/4518] 34% | Training loss: 0.6872326500230022
Epoch: 91 | Iteration number: [1550/4518] 34% | Training loss: 0.6872252413918896
Epoch: 91 | Iteration number: [1560/4518] 34% | Training loss: 0.6872231614131193
Epoch: 91 | Iteration number: [1570/4518] 34% | Training loss: 0.6872226782665131
Epoch: 91 | Iteration number: [1580/4518] 34% | Training loss: 0.6872155141981342
Epoch: 91 | Iteration number: [1590/4518] 35% | Training loss: 0.6872152151551637
Epoch: 91 | Iteration number: [1600/4518] 35% | Training loss: 0.6872217959165573
Epoch: 91 | Iteration number: [1610/4518] 35% | Training loss: 0.6872193516411397
Epoch: 91 | Iteration number: [1620/4518] 35% | Training loss: 0.6872181865904067
Epoch: 91 | Iteration number: [1630/4518] 36% | Training loss: 0.6872173553595514
Epoch: 91 | Iteration number: [1640/4518] 36% | Training loss: 0.6872200812871864
Epoch: 91 | Iteration number: [1650/4518] 36% | Training loss: 0.6872178864479065
Epoch: 91 | Iteration number: [1660/4518] 36% | Training loss: 0.6872199188513928
Epoch: 91 | Iteration number: [1670/4518] 36% | Training loss: 0.6872162782503459
Epoch: 91 | Iteration number: [1680/4518] 37% | Training loss: 0.6872180185147694
Epoch: 91 | Iteration number: [1690/4518] 37% | Training loss: 0.6872146346865321
Epoch: 91 | Iteration number: [1700/4518] 37% | Training loss: 0.6872074763564503
Epoch: 91 | Iteration number: [1710/4518] 37% | Training loss: 0.6872071051806734
Epoch: 91 | Iteration number: [1720/4518] 38% | Training loss: 0.6872061804630035
Epoch: 91 | Iteration number: [1730/4518] 38% | Training loss: 0.687207711397568
Epoch: 91 | Iteration number: [1740/4518] 38% | Training loss: 0.6872050508000385
Epoch: 91 | Iteration number: [1750/4518] 38% | Training loss: 0.6871970967905862
Epoch: 91 | Iteration number: [1760/4518] 38% | Training loss: 0.6871929968622598
Epoch: 91 | Iteration number: [1770/4518] 39% | Training loss: 0.6872011295146188
Epoch: 91 | Iteration number: [1780/4518] 39% | Training loss: 0.6871993264455474
Epoch: 91 | Iteration number: [1790/4518] 39% | Training loss: 0.6871906107031434
Epoch: 91 | Iteration number: [1800/4518] 39% | Training loss: 0.6871881756848759
Epoch: 91 | Iteration number: [1810/4518] 40% | Training loss: 0.687185016488502
Epoch: 91 | Iteration number: [1820/4518] 40% | Training loss: 0.687182242169485
Epoch: 91 | Iteration number: [1830/4518] 40% | Training loss: 0.6871731944097196
Epoch: 91 | Iteration number: [1840/4518] 40% | Training loss: 0.6871662803318189
Epoch: 91 | Iteration number: [1850/4518] 40% | Training loss: 0.6871726997156401
Epoch: 91 | Iteration number: [1860/4518] 41% | Training loss: 0.687163237730662
Epoch: 91 | Iteration number: [1870/4518] 41% | Training loss: 0.6871595711950312
Epoch: 91 | Iteration number: [1880/4518] 41% | Training loss: 0.6871603385248083
Epoch: 91 | Iteration number: [1890/4518] 41% | Training loss: 0.6871504157939285
Epoch: 91 | Iteration number: [1900/4518] 42% | Training loss: 0.6871481129056529
Epoch: 91 | Iteration number: [1910/4518] 42% | Training loss: 0.6871432795886594
Epoch: 91 | Iteration number: [1920/4518] 42% | Training loss: 0.6871380365764101
Epoch: 91 | Iteration number: [1930/4518] 42% | Training loss: 0.6871322082423176
Epoch: 91 | Iteration number: [1940/4518] 42% | Training loss: 0.6871283789885413
Epoch: 91 | Iteration number: [1950/4518] 43% | Training loss: 0.6871241985528898
Epoch: 91 | Iteration number: [1960/4518] 43% | Training loss: 0.6871212325229936
Epoch: 91 | Iteration number: [1970/4518] 43% | Training loss: 0.6871195151418599
Epoch: 91 | Iteration number: [1980/4518] 43% | Training loss: 0.6871203444521836
Epoch: 91 | Iteration number: [1990/4518] 44% | Training loss: 0.6871143141284061
Epoch: 91 | Iteration number: [2000/4518] 44% | Training loss: 0.6871124567389488
Epoch: 91 | Iteration number: [2010/4518] 44% | Training loss: 0.687115798809042
Epoch: 91 | Iteration number: [2020/4518] 44% | Training loss: 0.6871127202074127
Epoch: 91 | Iteration number: [2030/4518] 44% | Training loss: 0.6871165471417563
Epoch: 91 | Iteration number: [2040/4518] 45% | Training loss: 0.6871158805255796
Epoch: 91 | Iteration number: [2050/4518] 45% | Training loss: 0.687115020344897
Epoch: 91 | Iteration number: [2060/4518] 45% | Training loss: 0.6871138922797824
Epoch: 91 | Iteration number: [2070/4518] 45% | Training loss: 0.6871089440325032
Epoch: 91 | Iteration number: [2080/4518] 46% | Training loss: 0.6871050510842066
Epoch: 91 | Iteration number: [2090/4518] 46% | Training loss: 0.6871047026517859
Epoch: 91 | Iteration number: [2100/4518] 46% | Training loss: 0.6871034475735256
Epoch: 91 | Iteration number: [2110/4518] 46% | Training loss: 0.687098207490704
Epoch: 91 | Iteration number: [2120/4518] 46% | Training loss: 0.6870964868451065
Epoch: 91 | Iteration number: [2130/4518] 47% | Training loss: 0.6870997097010904
Epoch: 91 | Iteration number: [2140/4518] 47% | Training loss: 0.6871041740212485
Epoch: 91 | Iteration number: [2150/4518] 47% | Training loss: 0.687104025192039
Epoch: 91 | Iteration number: [2160/4518] 47% | Training loss: 0.6871000781655312
Epoch: 91 | Iteration number: [2170/4518] 48% | Training loss: 0.6871005452997674
Epoch: 91 | Iteration number: [2180/4518] 48% | Training loss: 0.6871016337510643
Epoch: 91 | Iteration number: [2190/4518] 48% | Training loss: 0.6870994706132096
Epoch: 91 | Iteration number: [2200/4518] 48% | Training loss: 0.6870937927473675
Epoch: 91 | Iteration number: [2210/4518] 48% | Training loss: 0.6870929947535916
Epoch: 91 | Iteration number: [2220/4518] 49% | Training loss: 0.6870983539400874
Epoch: 91 | Iteration number: [2230/4518] 49% | Training loss: 0.6870905591500714
Epoch: 91 | Iteration number: [2240/4518] 49% | Training loss: 0.6870881980018956
Epoch: 91 | Iteration number: [2250/4518] 49% | Training loss: 0.6870864733060201
Epoch: 91 | Iteration number: [2260/4518] 50% | Training loss: 0.6870879368971934
Epoch: 91 | Iteration number: [2270/4518] 50% | Training loss: 0.6870885187833845
Epoch: 91 | Iteration number: [2280/4518] 50% | Training loss: 0.6870889744214844
Epoch: 91 | Iteration number: [2290/4518] 50% | Training loss: 0.6870904678600844
Epoch: 91 | Iteration number: [2300/4518] 50% | Training loss: 0.6870937121691911
Epoch: 91 | Iteration number: [2310/4518] 51% | Training loss: 0.6870936724272642
Epoch: 91 | Iteration number: [2320/4518] 51% | Training loss: 0.687094215714726
Epoch: 91 | Iteration number: [2330/4518] 51% | Training loss: 0.6870918093832777
Epoch: 91 | Iteration number: [2340/4518] 51% | Training loss: 0.6870847011223817
Epoch: 91 | Iteration number: [2350/4518] 52% | Training loss: 0.6870803704413961
Epoch: 91 | Iteration number: [2360/4518] 52% | Training loss: 0.6870808367001808
Epoch: 91 | Iteration number: [2370/4518] 52% | Training loss: 0.687082685825694
Epoch: 91 | Iteration number: [2380/4518] 52% | Training loss: 0.6870873108881862
Epoch: 91 | Iteration number: [2390/4518] 52% | Training loss: 0.6870837928360974
Epoch: 91 | Iteration number: [2400/4518] 53% | Training loss: 0.6870770963529745
Epoch: 91 | Iteration number: [2410/4518] 53% | Training loss: 0.687074693085247
Epoch: 91 | Iteration number: [2420/4518] 53% | Training loss: 0.6870698100771786
Epoch: 91 | Iteration number: [2430/4518] 53% | Training loss: 0.6870675014124976
Epoch: 91 | Iteration number: [2440/4518] 54% | Training loss: 0.6870613633364927
Epoch: 91 | Iteration number: [2450/4518] 54% | Training loss: 0.6870614135508635
Epoch: 91 | Iteration number: [2460/4518] 54% | Training loss: 0.6870578084777041
Epoch: 91 | Iteration number: [2470/4518] 54% | Training loss: 0.6870584467885948
Epoch: 91 | Iteration number: [2480/4518] 54% | Training loss: 0.6870568569869765
Epoch: 91 | Iteration number: [2490/4518] 55% | Training loss: 0.6870558462468496
Epoch: 91 | Iteration number: [2500/4518] 55% | Training loss: 0.6870481802940369
Epoch: 91 | Iteration number: [2510/4518] 55% | Training loss: 0.6870482374709915
Epoch: 91 | Iteration number: [2520/4518] 55% | Training loss: 0.6870520304356302
Epoch: 91 | Iteration number: [2530/4518] 55% | Training loss: 0.6870504769647545
Epoch: 91 | Iteration number: [2540/4518] 56% | Training loss: 0.6870461300836773
Epoch: 91 | Iteration number: [2550/4518] 56% | Training loss: 0.6870461265479817
Epoch: 91 | Iteration number: [2560/4518] 56% | Training loss: 0.6870489400578663
Epoch: 91 | Iteration number: [2570/4518] 56% | Training loss: 0.6870457586147442
Epoch: 91 | Iteration number: [2580/4518] 57% | Training loss: 0.6870412937661474
Epoch: 91 | Iteration number: [2590/4518] 57% | Training loss: 0.6870385928043528
Epoch: 91 | Iteration number: [2600/4518] 57% | Training loss: 0.6870400260732724
Epoch: 91 | Iteration number: [2610/4518] 57% | Training loss: 0.687040286616804
Epoch: 91 | Iteration number: [2620/4518] 57% | Training loss: 0.687040410401257
Epoch: 91 | Iteration number: [2630/4518] 58% | Training loss: 0.6870393473385858
Epoch: 91 | Iteration number: [2640/4518] 58% | Training loss: 0.6870351161469113
Epoch: 91 | Iteration number: [2650/4518] 58% | Training loss: 0.6870386377820429
Epoch: 91 | Iteration number: [2660/4518] 58% | Training loss: 0.6870401265253698
Epoch: 91 | Iteration number: [2670/4518] 59% | Training loss: 0.6870446087492539
Epoch: 91 | Iteration number: [2680/4518] 59% | Training loss: 0.6870439234731802
Epoch: 91 | Iteration number: [2690/4518] 59% | Training loss: 0.6870391007471262
Epoch: 91 | Iteration number: [2700/4518] 59% | Training loss: 0.6870403538809883
Epoch: 91 | Iteration number: [2710/4518] 59% | Training loss: 0.6870356138561925
Epoch: 91 | Iteration number: [2720/4518] 60% | Training loss: 0.6870357412187492
Epoch: 91 | Iteration number: [2730/4518] 60% | Training loss: 0.6870344649304401
Epoch: 91 | Iteration number: [2740/4518] 60% | Training loss: 0.6870342618357526
Epoch: 91 | Iteration number: [2750/4518] 60% | Training loss: 0.6870339599305934
Epoch: 91 | Iteration number: [2760/4518] 61% | Training loss: 0.6870345403750737
Epoch: 91 | Iteration number: [2770/4518] 61% | Training loss: 0.6870360950485463
Epoch: 91 | Iteration number: [2780/4518] 61% | Training loss: 0.6870369361887733
Epoch: 91 | Iteration number: [2790/4518] 61% | Training loss: 0.6870387745373565
Epoch: 91 | Iteration number: [2800/4518] 61% | Training loss: 0.6870419158467225
Epoch: 91 | Iteration number: [2810/4518] 62% | Training loss: 0.6870389162221413
Epoch: 91 | Iteration number: [2820/4518] 62% | Training loss: 0.6870366293065091
Epoch: 91 | Iteration number: [2830/4518] 62% | Training loss: 0.6870338387076509
Epoch: 91 | Iteration number: [2840/4518] 62% | Training loss: 0.687034798088208
Epoch: 91 | Iteration number: [2850/4518] 63% | Training loss: 0.6870335961015601
Epoch: 91 | Iteration number: [2860/4518] 63% | Training loss: 0.6870355986423425
Epoch: 91 | Iteration number: [2870/4518] 63% | Training loss: 0.6870365722669541
Epoch: 91 | Iteration number: [2880/4518] 63% | Training loss: 0.6870363432086176
Epoch: 91 | Iteration number: [2890/4518] 63% | Training loss: 0.687034041782564
Epoch: 91 | Iteration number: [2900/4518] 64% | Training loss: 0.6870369595700296
Epoch: 91 | Iteration number: [2910/4518] 64% | Training loss: 0.6870352142864896
Epoch: 91 | Iteration number: [2920/4518] 64% | Training loss: 0.6870350879961498
Epoch: 91 | Iteration number: [2930/4518] 64% | Training loss: 0.687034929754791
Epoch: 91 | Iteration number: [2940/4518] 65% | Training loss: 0.6870312786426674
Epoch: 91 | Iteration number: [2950/4518] 65% | Training loss: 0.6870290075924437
Epoch: 91 | Iteration number: [2960/4518] 65% | Training loss: 0.6870307507345805
Epoch: 91 | Iteration number: [2970/4518] 65% | Training loss: 0.6870307773853392
Epoch: 91 | Iteration number: [2980/4518] 65% | Training loss: 0.6870299162480655
Epoch: 91 | Iteration number: [2990/4518] 66% | Training loss: 0.6870279405228669
Epoch: 91 | Iteration number: [3000/4518] 66% | Training loss: 0.687030209183693
Epoch: 91 | Iteration number: [3010/4518] 66% | Training loss: 0.6870264671371624
Epoch: 91 | Iteration number: [3020/4518] 66% | Training loss: 0.6870271482215022
Epoch: 91 | Iteration number: [3030/4518] 67% | Training loss: 0.6870298160971589
Epoch: 91 | Iteration number: [3040/4518] 67% | Training loss: 0.6870223450425424
Epoch: 91 | Iteration number: [3050/4518] 67% | Training loss: 0.6870232543788972
Epoch: 91 | Iteration number: [3060/4518] 67% | Training loss: 0.6870207807402205
Epoch: 91 | Iteration number: [3070/4518] 67% | Training loss: 0.6870215744071364
Epoch: 91 | Iteration number: [3080/4518] 68% | Training loss: 0.6870141686363653
Epoch: 91 | Iteration number: [3090/4518] 68% | Training loss: 0.6870161111493712
Epoch: 91 | Iteration number: [3100/4518] 68% | Training loss: 0.6870170764384731
Epoch: 91 | Iteration number: [3110/4518] 68% | Training loss: 0.6870150764847108
Epoch: 91 | Iteration number: [3120/4518] 69% | Training loss: 0.6870139015981784
Epoch: 91 | Iteration number: [3130/4518] 69% | Training loss: 0.687015171439503
Epoch: 91 | Iteration number: [3140/4518] 69% | Training loss: 0.6870103425281063
Epoch: 91 | Iteration number: [3150/4518] 69% | Training loss: 0.6870082508193122
Epoch: 91 | Iteration number: [3160/4518] 69% | Training loss: 0.687006770527061
Epoch: 91 | Iteration number: [3170/4518] 70% | Training loss: 0.6870063015903208
Epoch: 91 | Iteration number: [3180/4518] 70% | Training loss: 0.6870059558055686
Epoch: 91 | Iteration number: [3190/4518] 70% | Training loss: 0.6870046419036052
Epoch: 91 | Iteration number: [3200/4518] 70% | Training loss: 0.6870063794776797
Epoch: 91 | Iteration number: [3210/4518] 71% | Training loss: 0.687000853194626
Epoch: 91 | Iteration number: [3220/4518] 71% | Training loss: 0.6869994235520037
Epoch: 91 | Iteration number: [3230/4518] 71% | Training loss: 0.6869990188270899
Epoch: 91 | Iteration number: [3240/4518] 71% | Training loss: 0.6869978677159474
Epoch: 91 | Iteration number: [3250/4518] 71% | Training loss: 0.6870022688278785
Epoch: 91 | Iteration number: [3260/4518] 72% | Training loss: 0.6870024129839762
Epoch: 91 | Iteration number: [3270/4518] 72% | Training loss: 0.6870031567706245
Epoch: 91 | Iteration number: [3280/4518] 72% | Training loss: 0.6870019362103649
Epoch: 91 | Iteration number: [3290/4518] 72% | Training loss: 0.6870016327382583
Epoch: 91 | Iteration number: [3300/4518] 73% | Training loss: 0.6869947908683257
Epoch: 91 | Iteration number: [3310/4518] 73% | Training loss: 0.68699504857337
Epoch: 91 | Iteration number: [3320/4518] 73% | Training loss: 0.6869962043072804
Epoch: 91 | Iteration number: [3330/4518] 73% | Training loss: 0.6869975222481621
Epoch: 91 | Iteration number: [3340/4518] 73% | Training loss: 0.6869945073912958
Epoch: 91 | Iteration number: [3350/4518] 74% | Training loss: 0.6869933768706535
Epoch: 91 | Iteration number: [3360/4518] 74% | Training loss: 0.686995477495449
Epoch: 91 | Iteration number: [3370/4518] 74% | Training loss: 0.6869958669743128
Epoch: 91 | Iteration number: [3380/4518] 74% | Training loss: 0.6869919625965096
Epoch: 91 | Iteration number: [3390/4518] 75% | Training loss: 0.6869918673791013
Epoch: 91 | Iteration number: [3400/4518] 75% | Training loss: 0.6869947254307129
Epoch: 91 | Iteration number: [3410/4518] 75% | Training loss: 0.6869975038113133
Epoch: 91 | Iteration number: [3420/4518] 75% | Training loss: 0.686998617962787
Epoch: 91 | Iteration number: [3430/4518] 75% | Training loss: 0.6869942247520036
Epoch: 91 | Iteration number: [3440/4518] 76% | Training loss: 0.6869939516796623
Epoch: 91 | Iteration number: [3450/4518] 76% | Training loss: 0.6869889652729034
Epoch: 91 | Iteration number: [3460/4518] 76% | Training loss: 0.6869898071006544
Epoch: 91 | Iteration number: [3470/4518] 76% | Training loss: 0.6869843867223613
Epoch: 91 | Iteration number: [3480/4518] 77% | Training loss: 0.6869819430099137
Epoch: 91 | Iteration number: [3490/4518] 77% | Training loss: 0.6869817025511176
Epoch: 91 | Iteration number: [3500/4518] 77% | Training loss: 0.686978008542742
Epoch: 91 | Iteration number: [3510/4518] 77% | Training loss: 0.6869760196942549
Epoch: 91 | Iteration number: [3520/4518] 77% | Training loss: 0.6869766226038336
Epoch: 91 | Iteration number: [3530/4518] 78% | Training loss: 0.6869759731353511
Epoch: 91 | Iteration number: [3540/4518] 78% | Training loss: 0.6869755631617908
Epoch: 91 | Iteration number: [3550/4518] 78% | Training loss: 0.6869763310862259
Epoch: 91 | Iteration number: [3560/4518] 78% | Training loss: 0.6869764515188302
Epoch: 91 | Iteration number: [3570/4518] 79% | Training loss: 0.6869734012446149
Epoch: 91 | Iteration number: [3580/4518] 79% | Training loss: 0.686973612718076
Epoch: 91 | Iteration number: [3590/4518] 79% | Training loss: 0.6869747674232738
Epoch: 91 | Iteration number: [3600/4518] 79% | Training loss: 0.6869740761485364
Epoch: 91 | Iteration number: [3610/4518] 79% | Training loss: 0.6869759632114558
Epoch: 91 | Iteration number: [3620/4518] 80% | Training loss: 0.686977581259954
Epoch: 91 | Iteration number: [3630/4518] 80% | Training loss: 0.6869718218637892
Epoch: 91 | Iteration number: [3640/4518] 80% | Training loss: 0.6869713252553573
Epoch: 91 | Iteration number: [3650/4518] 80% | Training loss: 0.6869711495262303
Epoch: 91 | Iteration number: [3660/4518] 81% | Training loss: 0.6869713787009807
Epoch: 91 | Iteration number: [3670/4518] 81% | Training loss: 0.6869680095271129
Epoch: 91 | Iteration number: [3680/4518] 81% | Training loss: 0.686966169188204
Epoch: 91 | Iteration number: [3690/4518] 81% | Training loss: 0.6869640482958094
Epoch: 91 | Iteration number: [3700/4518] 81% | Training loss: 0.6869641404216354
Epoch: 91 | Iteration number: [3710/4518] 82% | Training loss: 0.6869651025035632
Epoch: 91 | Iteration number: [3720/4518] 82% | Training loss: 0.686964646542585
Epoch: 91 | Iteration number: [3730/4518] 82% | Training loss: 0.6869661895743004
Epoch: 91 | Iteration number: [3740/4518] 82% | Training loss: 0.686964360835718
Epoch: 91 | Iteration number: [3750/4518] 83% | Training loss: 0.6869598808765411
Epoch: 91 | Iteration number: [3760/4518] 83% | Training loss: 0.6869628041665605
Epoch: 91 | Iteration number: [3770/4518] 83% | Training loss: 0.6869659161536068
Epoch: 91 | Iteration number: [3780/4518] 83% | Training loss: 0.6869659072349942
Epoch: 91 | Iteration number: [3790/4518] 83% | Training loss: 0.686964419224646
Epoch: 91 | Iteration number: [3800/4518] 84% | Training loss: 0.6869643814940202
Epoch: 91 | Iteration number: [3810/4518] 84% | Training loss: 0.6869617729205785
Epoch: 91 | Iteration number: [3820/4518] 84% | Training loss: 0.6869598328755164
Epoch: 91 | Iteration number: [3830/4518] 84% | Training loss: 0.6869603627344336
Epoch: 91 | Iteration number: [3840/4518] 84% | Training loss: 0.6869627719279379
Epoch: 91 | Iteration number: [3850/4518] 85% | Training loss: 0.6869626340463564
Epoch: 91 | Iteration number: [3860/4518] 85% | Training loss: 0.6869644073470269
Epoch: 91 | Iteration number: [3870/4518] 85% | Training loss: 0.686961701443029
Epoch: 91 | Iteration number: [3880/4518] 85% | Training loss: 0.6869642203155252
Epoch: 91 | Iteration number: [3890/4518] 86% | Training loss: 0.6869624171741211
Epoch: 91 | Iteration number: [3900/4518] 86% | Training loss: 0.6869606827619749
Epoch: 91 | Iteration number: [3910/4518] 86% | Training loss: 0.6869593605056138
Epoch: 91 | Iteration number: [3920/4518] 86% | Training loss: 0.6869577544380208
Epoch: 91 | Iteration number: [3930/4518] 86% | Training loss: 0.6869569357418225
Epoch: 91 | Iteration number: [3940/4518] 87% | Training loss: 0.6869528362291113
Epoch: 91 | Iteration number: [3950/4518] 87% | Training loss: 0.6869523770145223
Epoch: 91 | Iteration number: [3960/4518] 87% | Training loss: 0.6869519071145491
Epoch: 91 | Iteration number: [3970/4518] 87% | Training loss: 0.6869491691102909
Epoch: 91 | Iteration number: [3980/4518] 88% | Training loss: 0.6869511623628175
Epoch: 91 | Iteration number: [3990/4518] 88% | Training loss: 0.6869505427833786
Epoch: 91 | Iteration number: [4000/4518] 88% | Training loss: 0.6869505549222231
Epoch: 91 | Iteration number: [4010/4518] 88% | Training loss: 0.6869483063345836
Epoch: 91 | Iteration number: [4020/4518] 88% | Training loss: 0.6869464662389375
Epoch: 91 | Iteration number: [4030/4518] 89% | Training loss: 0.686945160935002
Epoch: 91 | Iteration number: [4040/4518] 89% | Training loss: 0.6869483943180282
Epoch: 91 | Iteration number: [4050/4518] 89% | Training loss: 0.686945678908148
Epoch: 91 | Iteration number: [4060/4518] 89% | Training loss: 0.6869433546301179
Epoch: 91 | Iteration number: [4070/4518] 90% | Training loss: 0.686943749406121
Epoch: 91 | Iteration number: [4080/4518] 90% | Training loss: 0.6869455266816943
Epoch: 91 | Iteration number: [4090/4518] 90% | Training loss: 0.6869421088462354
Epoch: 91 | Iteration number: [4100/4518] 90% | Training loss: 0.6869401427740004
Epoch: 91 | Iteration number: [4110/4518] 90% | Training loss: 0.6869392545408866
Epoch: 91 | Iteration number: [4120/4518] 91% | Training loss: 0.6869322816145073
Epoch: 91 | Iteration number: [4130/4518] 91% | Training loss: 0.6869338761086037
Epoch: 91 | Iteration number: [4140/4518] 91% | Training loss: 0.6869342875221501
Epoch: 91 | Iteration number: [4150/4518] 91% | Training loss: 0.6869333608897336
Epoch: 91 | Iteration number: [4160/4518] 92% | Training loss: 0.6869316648118771
Epoch: 91 | Iteration number: [4170/4518] 92% | Training loss: 0.686932906587061
Epoch: 91 | Iteration number: [4180/4518] 92% | Training loss: 0.6869347774526149
Epoch: 91 | Iteration number: [4190/4518] 92% | Training loss: 0.6869364129757255
Epoch: 91 | Iteration number: [4200/4518] 92% | Training loss: 0.6869369612988971
Epoch: 91 | Iteration number: [4210/4518] 93% | Training loss: 0.6869369925908975
Epoch: 91 | Iteration number: [4220/4518] 93% | Training loss: 0.6869354057509752
Epoch: 91 | Iteration number: [4230/4518] 93% | Training loss: 0.6869338468034216
Epoch: 91 | Iteration number: [4240/4518] 93% | Training loss: 0.6869287177217457
Epoch: 91 | Iteration number: [4250/4518] 94% | Training loss: 0.6869258446272681
Epoch: 91 | Iteration number: [4260/4518] 94% | Training loss: 0.6869258157244311
Epoch: 91 | Iteration number: [4270/4518] 94% | Training loss: 0.6869245470268106
Epoch: 91 | Iteration number: [4280/4518] 94% | Training loss: 0.6869243067419417
Epoch: 91 | Iteration number: [4290/4518] 94% | Training loss: 0.6869231336600297
Epoch: 91 | Iteration number: [4300/4518] 95% | Training loss: 0.6869208579978278
Epoch: 91 | Iteration number: [4310/4518] 95% | Training loss: 0.6869196753075947
Epoch: 91 | Iteration number: [4320/4518] 95% | Training loss: 0.6869188102859037
Epoch: 91 | Iteration number: [4330/4518] 95% | Training loss: 0.686913960359939
Epoch: 91 | Iteration number: [4340/4518] 96% | Training loss: 0.6869138770389117
Epoch: 91 | Iteration number: [4350/4518] 96% | Training loss: 0.6869140579508639
Epoch: 91 | Iteration number: [4360/4518] 96% | Training loss: 0.686915750883588
Epoch: 91 | Iteration number: [4370/4518] 96% | Training loss: 0.686916337528818
Epoch: 91 | Iteration number: [4380/4518] 96% | Training loss: 0.6869129091501236
Epoch: 91 | Iteration number: [4390/4518] 97% | Training loss: 0.6869120780862273
Epoch: 91 | Iteration number: [4400/4518] 97% | Training loss: 0.6869094996696169
Epoch: 91 | Iteration number: [4410/4518] 97% | Training loss: 0.6869107890561594
Epoch: 91 | Iteration number: [4420/4518] 97% | Training loss: 0.6869096632187183
Epoch: 91 | Iteration number: [4430/4518] 98% | Training loss: 0.6869106088481154
Epoch: 91 | Iteration number: [4440/4518] 98% | Training loss: 0.6869076911527832
Epoch: 91 | Iteration number: [4450/4518] 98% | Training loss: 0.6869061606787563
Epoch: 91 | Iteration number: [4460/4518] 98% | Training loss: 0.6869058693203691
Epoch: 91 | Iteration number: [4470/4518] 98% | Training loss: 0.6869058888763923
Epoch: 91 | Iteration number: [4480/4518] 99% | Training loss: 0.686906716240836
Epoch: 91 | Iteration number: [4490/4518] 99% | Training loss: 0.6869056032866837
Epoch: 91 | Iteration number: [4500/4518] 99% | Training loss: 0.6869059599240621
Epoch: 91 | Iteration number: [4510/4518] 99% | Training loss: 0.686903645299755

 End of epoch: 91 | Train Loss: 0.6867527613971233 | Training Time: 641 

 End of epoch: 91 | Eval Loss: 0.689754782890787 | Evaluating Time: 17 
Epoch: 92 | Iteration number: [10/4518] 0% | Training loss: 0.7547359347343445
Epoch: 92 | Iteration number: [20/4518] 0% | Training loss: 0.7208714038133621
Epoch: 92 | Iteration number: [30/4518] 0% | Training loss: 0.7093716124693553
Epoch: 92 | Iteration number: [40/4518] 0% | Training loss: 0.703875757753849
Epoch: 92 | Iteration number: [50/4518] 1% | Training loss: 0.7005780458450317
Epoch: 92 | Iteration number: [60/4518] 1% | Training loss: 0.6983439296483993
Epoch: 92 | Iteration number: [70/4518] 1% | Training loss: 0.696904388495854
Epoch: 92 | Iteration number: [80/4518] 1% | Training loss: 0.6955924786627292
Epoch: 92 | Iteration number: [90/4518] 1% | Training loss: 0.6946297446886699
Epoch: 92 | Iteration number: [100/4518] 2% | Training loss: 0.6939474958181381
Epoch: 92 | Iteration number: [110/4518] 2% | Training loss: 0.6932022831656716
Epoch: 92 | Iteration number: [120/4518] 2% | Training loss: 0.6927181844909985
Epoch: 92 | Iteration number: [130/4518] 2% | Training loss: 0.6922977997706486
Epoch: 92 | Iteration number: [140/4518] 3% | Training loss: 0.691954659138407
Epoch: 92 | Iteration number: [150/4518] 3% | Training loss: 0.691602813800176
Epoch: 92 | Iteration number: [160/4518] 3% | Training loss: 0.6912935242056847
Epoch: 92 | Iteration number: [170/4518] 3% | Training loss: 0.6910278453546412
Epoch: 92 | Iteration number: [180/4518] 3% | Training loss: 0.6907706469297409
Epoch: 92 | Iteration number: [190/4518] 4% | Training loss: 0.6906639287346288
Epoch: 92 | Iteration number: [200/4518] 4% | Training loss: 0.6904736849665641
Epoch: 92 | Iteration number: [210/4518] 4% | Training loss: 0.6902965341295515
Epoch: 92 | Iteration number: [220/4518] 4% | Training loss: 0.6901459401304072
Epoch: 92 | Iteration number: [230/4518] 5% | Training loss: 0.6899654632029326
Epoch: 92 | Iteration number: [240/4518] 5% | Training loss: 0.6898195058107376
Epoch: 92 | Iteration number: [250/4518] 5% | Training loss: 0.6897117984294892
Epoch: 92 | Iteration number: [260/4518] 5% | Training loss: 0.6895725662891682
Epoch: 92 | Iteration number: [270/4518] 5% | Training loss: 0.6894934466591588
Epoch: 92 | Iteration number: [280/4518] 6% | Training loss: 0.689376366351332
Epoch: 92 | Iteration number: [290/4518] 6% | Training loss: 0.6893020052334358
Epoch: 92 | Iteration number: [300/4518] 6% | Training loss: 0.6892199550072352
Epoch: 92 | Iteration number: [310/4518] 6% | Training loss: 0.6891099749072905
Epoch: 92 | Iteration number: [320/4518] 7% | Training loss: 0.6890093112364412
Epoch: 92 | Iteration number: [330/4518] 7% | Training loss: 0.6889591896172725
Epoch: 92 | Iteration number: [340/4518] 7% | Training loss: 0.6888575867694967
Epoch: 92 | Iteration number: [350/4518] 7% | Training loss: 0.6887982652868543
Epoch: 92 | Iteration number: [360/4518] 7% | Training loss: 0.6887133560246892
Epoch: 92 | Iteration number: [370/4518] 8% | Training loss: 0.6886586173160656
Epoch: 92 | Iteration number: [380/4518] 8% | Training loss: 0.6886007478362636
Epoch: 92 | Iteration number: [390/4518] 8% | Training loss: 0.6885690938203762
Epoch: 92 | Iteration number: [400/4518] 8% | Training loss: 0.6885068728029728
Epoch: 92 | Iteration number: [410/4518] 9% | Training loss: 0.6884409235744942
Epoch: 92 | Iteration number: [420/4518] 9% | Training loss: 0.6884185633489064
Epoch: 92 | Iteration number: [430/4518] 9% | Training loss: 0.6883600408254668
Epoch: 92 | Iteration number: [440/4518] 9% | Training loss: 0.6883319545875896
Epoch: 92 | Iteration number: [450/4518] 9% | Training loss: 0.6882902703020308
Epoch: 92 | Iteration number: [460/4518] 10% | Training loss: 0.6882537153751954
Epoch: 92 | Iteration number: [470/4518] 10% | Training loss: 0.6882013443936693
Epoch: 92 | Iteration number: [480/4518] 10% | Training loss: 0.6881538239618142
Epoch: 92 | Iteration number: [490/4518] 10% | Training loss: 0.6881329531572303
Epoch: 92 | Iteration number: [500/4518] 11% | Training loss: 0.6881200529336929
Epoch: 92 | Iteration number: [510/4518] 11% | Training loss: 0.6880886638865752
Epoch: 92 | Iteration number: [520/4518] 11% | Training loss: 0.6880804275090878
Epoch: 92 | Iteration number: [530/4518] 11% | Training loss: 0.6880836715113442
Epoch: 92 | Iteration number: [540/4518] 11% | Training loss: 0.6880841116110484
Epoch: 92 | Iteration number: [550/4518] 12% | Training loss: 0.6880543943968687
Epoch: 92 | Iteration number: [560/4518] 12% | Training loss: 0.6880384071597031
Epoch: 92 | Iteration number: [570/4518] 12% | Training loss: 0.6880318877989786
Epoch: 92 | Iteration number: [580/4518] 12% | Training loss: 0.6880114691010837
Epoch: 92 | Iteration number: [590/4518] 13% | Training loss: 0.6879804248526945
Epoch: 92 | Iteration number: [600/4518] 13% | Training loss: 0.6879715983072917
Epoch: 92 | Iteration number: [610/4518] 13% | Training loss: 0.6879712972484651
Epoch: 92 | Iteration number: [620/4518] 13% | Training loss: 0.6879753365632026
Epoch: 92 | Iteration number: [630/4518] 13% | Training loss: 0.6879367935279059
Epoch: 92 | Iteration number: [640/4518] 14% | Training loss: 0.6879157083109021
Epoch: 92 | Iteration number: [650/4518] 14% | Training loss: 0.6878874200124007
Epoch: 92 | Iteration number: [660/4518] 14% | Training loss: 0.6878622175166101
Epoch: 92 | Iteration number: [670/4518] 14% | Training loss: 0.6878481646971916
Epoch: 92 | Iteration number: [680/4518] 15% | Training loss: 0.6878217369318008
Epoch: 92 | Iteration number: [690/4518] 15% | Training loss: 0.6878117326377094
Epoch: 92 | Iteration number: [700/4518] 15% | Training loss: 0.6877889004775456
Epoch: 92 | Iteration number: [710/4518] 15% | Training loss: 0.6877676700202512
Epoch: 92 | Iteration number: [720/4518] 15% | Training loss: 0.6877510831587844
Epoch: 92 | Iteration number: [730/4518] 16% | Training loss: 0.68772226678182
Epoch: 92 | Iteration number: [740/4518] 16% | Training loss: 0.6877141326665879
Epoch: 92 | Iteration number: [750/4518] 16% | Training loss: 0.687697692712148
Epoch: 92 | Iteration number: [760/4518] 16% | Training loss: 0.6876835504644796
Epoch: 92 | Iteration number: [770/4518] 17% | Training loss: 0.6876728903163564
Epoch: 92 | Iteration number: [780/4518] 17% | Training loss: 0.6876649810717657
Epoch: 92 | Iteration number: [790/4518] 17% | Training loss: 0.6876468598088131
Epoch: 92 | Iteration number: [800/4518] 17% | Training loss: 0.6876369570940732
Epoch: 92 | Iteration number: [810/4518] 17% | Training loss: 0.6876165903644798
Epoch: 92 | Iteration number: [820/4518] 18% | Training loss: 0.6876019634851596
Epoch: 92 | Iteration number: [830/4518] 18% | Training loss: 0.6875920180096684
Epoch: 92 | Iteration number: [840/4518] 18% | Training loss: 0.6875654134721984
Epoch: 92 | Iteration number: [850/4518] 18% | Training loss: 0.6875430710876689
Epoch: 92 | Iteration number: [860/4518] 19% | Training loss: 0.6875355129325113
Epoch: 92 | Iteration number: [870/4518] 19% | Training loss: 0.6875273262632304
Epoch: 92 | Iteration number: [880/4518] 19% | Training loss: 0.6875226659530943
Epoch: 92 | Iteration number: [890/4518] 19% | Training loss: 0.6875106386924058
Epoch: 92 | Iteration number: [900/4518] 19% | Training loss: 0.6875096509853998
Epoch: 92 | Iteration number: [910/4518] 20% | Training loss: 0.6875081497889298
Epoch: 92 | Iteration number: [920/4518] 20% | Training loss: 0.6874879572054614
Epoch: 92 | Iteration number: [930/4518] 20% | Training loss: 0.6874816440125947
Epoch: 92 | Iteration number: [940/4518] 20% | Training loss: 0.6874686081992819
Epoch: 92 | Iteration number: [950/4518] 21% | Training loss: 0.6874762613522379
Epoch: 92 | Iteration number: [960/4518] 21% | Training loss: 0.6874681054924925
Epoch: 92 | Iteration number: [970/4518] 21% | Training loss: 0.6874557204467734
Epoch: 92 | Iteration number: [980/4518] 21% | Training loss: 0.6874427828861742
Epoch: 92 | Iteration number: [990/4518] 21% | Training loss: 0.6874320643116729
Epoch: 92 | Iteration number: [1000/4518] 22% | Training loss: 0.6874270848035813
Epoch: 92 | Iteration number: [1010/4518] 22% | Training loss: 0.6874384342443824
Epoch: 92 | Iteration number: [1020/4518] 22% | Training loss: 0.6874170378142712
Epoch: 92 | Iteration number: [1030/4518] 22% | Training loss: 0.6874173842587518
Epoch: 92 | Iteration number: [1040/4518] 23% | Training loss: 0.6874227579396505
Epoch: 92 | Iteration number: [1050/4518] 23% | Training loss: 0.6874332395054045
Epoch: 92 | Iteration number: [1060/4518] 23% | Training loss: 0.6874330251284365
Epoch: 92 | Iteration number: [1070/4518] 23% | Training loss: 0.6874144199852631
Epoch: 92 | Iteration number: [1080/4518] 23% | Training loss: 0.6874026129643123
Epoch: 92 | Iteration number: [1090/4518] 24% | Training loss: 0.6873983455360483
Epoch: 92 | Iteration number: [1100/4518] 24% | Training loss: 0.6873910524086518
Epoch: 92 | Iteration number: [1110/4518] 24% | Training loss: 0.6873794934234103
Epoch: 92 | Iteration number: [1120/4518] 24% | Training loss: 0.6873760678406272
Epoch: 92 | Iteration number: [1130/4518] 25% | Training loss: 0.6873683865091442
Epoch: 92 | Iteration number: [1140/4518] 25% | Training loss: 0.6873667273082231
Epoch: 92 | Iteration number: [1150/4518] 25% | Training loss: 0.6873664327289747
Epoch: 92 | Iteration number: [1160/4518] 25% | Training loss: 0.6873673198038134
Epoch: 92 | Iteration number: [1170/4518] 25% | Training loss: 0.6873707256256005
Epoch: 92 | Iteration number: [1180/4518] 26% | Training loss: 0.6873702897863873
Epoch: 92 | Iteration number: [1190/4518] 26% | Training loss: 0.6873645763437287
Epoch: 92 | Iteration number: [1200/4518] 26% | Training loss: 0.6873731737832228
Epoch: 92 | Iteration number: [1210/4518] 26% | Training loss: 0.6873501629868815
Epoch: 92 | Iteration number: [1220/4518] 27% | Training loss: 0.68735139076827
Epoch: 92 | Iteration number: [1230/4518] 27% | Training loss: 0.6873457565540221
Epoch: 92 | Iteration number: [1240/4518] 27% | Training loss: 0.6873352006558449
Epoch: 92 | Iteration number: [1250/4518] 27% | Training loss: 0.6873290518760681
Epoch: 92 | Iteration number: [1260/4518] 27% | Training loss: 0.6873298725438497
Epoch: 92 | Iteration number: [1270/4518] 28% | Training loss: 0.6873170700129562
Epoch: 92 | Iteration number: [1280/4518] 28% | Training loss: 0.6873042875435204
Epoch: 92 | Iteration number: [1290/4518] 28% | Training loss: 0.687309424960336
Epoch: 92 | Iteration number: [1300/4518] 28% | Training loss: 0.6873070602233593
Epoch: 92 | Iteration number: [1310/4518] 28% | Training loss: 0.687302672954006
Epoch: 92 | Iteration number: [1320/4518] 29% | Training loss: 0.6872865740096931
Epoch: 92 | Iteration number: [1330/4518] 29% | Training loss: 0.6872945988088622
Epoch: 92 | Iteration number: [1340/4518] 29% | Training loss: 0.6872943154911497
Epoch: 92 | Iteration number: [1350/4518] 29% | Training loss: 0.6872764728245911
Epoch: 92 | Iteration number: [1360/4518] 30% | Training loss: 0.6872790142017252
Epoch: 92 | Iteration number: [1370/4518] 30% | Training loss: 0.6872759167295303
Epoch: 92 | Iteration number: [1380/4518] 30% | Training loss: 0.6872717399096143
Epoch: 92 | Iteration number: [1390/4518] 30% | Training loss: 0.6872716675559394
Epoch: 92 | Iteration number: [1400/4518] 30% | Training loss: 0.6872785531623022
Epoch: 92 | Iteration number: [1410/4518] 31% | Training loss: 0.6872711348618176
Epoch: 92 | Iteration number: [1420/4518] 31% | Training loss: 0.687267172630404
Epoch: 92 | Iteration number: [1430/4518] 31% | Training loss: 0.6872685204852711
Epoch: 92 | Iteration number: [1440/4518] 31% | Training loss: 0.6872637456903855
Epoch: 92 | Iteration number: [1450/4518] 32% | Training loss: 0.6872574516411485
Epoch: 92 | Iteration number: [1460/4518] 32% | Training loss: 0.6872631147707978
Epoch: 92 | Iteration number: [1470/4518] 32% | Training loss: 0.6872567015440285
Epoch: 92 | Iteration number: [1480/4518] 32% | Training loss: 0.6872564558241818
Epoch: 92 | Iteration number: [1490/4518] 32% | Training loss: 0.6872525955606626
Epoch: 92 | Iteration number: [1500/4518] 33% | Training loss: 0.6872507054408391
Epoch: 92 | Iteration number: [1510/4518] 33% | Training loss: 0.6872511622526788
Epoch: 92 | Iteration number: [1520/4518] 33% | Training loss: 0.6872430123388767
Epoch: 92 | Iteration number: [1530/4518] 33% | Training loss: 0.6872338731694065
Epoch: 92 | Iteration number: [1540/4518] 34% | Training loss: 0.6872287931767377
Epoch: 92 | Iteration number: [1550/4518] 34% | Training loss: 0.6872292828944422
Epoch: 92 | Iteration number: [1560/4518] 34% | Training loss: 0.6872303326160479
Epoch: 92 | Iteration number: [1570/4518] 34% | Training loss: 0.6872225957311643
Epoch: 92 | Iteration number: [1580/4518] 34% | Training loss: 0.6872198533031005
Epoch: 92 | Iteration number: [1590/4518] 35% | Training loss: 0.6872097396625663
Epoch: 92 | Iteration number: [1600/4518] 35% | Training loss: 0.687210944853723
Epoch: 92 | Iteration number: [1610/4518] 35% | Training loss: 0.6872120691752582
Epoch: 92 | Iteration number: [1620/4518] 35% | Training loss: 0.6872071871786942
Epoch: 92 | Iteration number: [1630/4518] 36% | Training loss: 0.687202792335873
Epoch: 92 | Iteration number: [1640/4518] 36% | Training loss: 0.6872006781944414
Epoch: 92 | Iteration number: [1650/4518] 36% | Training loss: 0.6871921535694238
Epoch: 92 | Iteration number: [1660/4518] 36% | Training loss: 0.6871912494840392
Epoch: 92 | Iteration number: [1670/4518] 36% | Training loss: 0.6871859995547883
Epoch: 92 | Iteration number: [1680/4518] 37% | Training loss: 0.6871815290124643
Epoch: 92 | Iteration number: [1690/4518] 37% | Training loss: 0.6871776111732574
Epoch: 92 | Iteration number: [1700/4518] 37% | Training loss: 0.6871786970951977
Epoch: 92 | Iteration number: [1710/4518] 37% | Training loss: 0.687173985458954
Epoch: 92 | Iteration number: [1720/4518] 38% | Training loss: 0.6871696743507718
Epoch: 92 | Iteration number: [1730/4518] 38% | Training loss: 0.6871627311830576
Epoch: 92 | Iteration number: [1740/4518] 38% | Training loss: 0.6871514407382614
Epoch: 92 | Iteration number: [1750/4518] 38% | Training loss: 0.6871427037715911
Epoch: 92 | Iteration number: [1760/4518] 38% | Training loss: 0.6871424227952957
Epoch: 92 | Iteration number: [1770/4518] 39% | Training loss: 0.687144491025957
Epoch: 92 | Iteration number: [1780/4518] 39% | Training loss: 0.6871412010340209
Epoch: 92 | Iteration number: [1790/4518] 39% | Training loss: 0.6871399897103869
Epoch: 92 | Iteration number: [1800/4518] 39% | Training loss: 0.6871454913748635
Epoch: 92 | Iteration number: [1810/4518] 40% | Training loss: 0.6871420042949486
Epoch: 92 | Iteration number: [1820/4518] 40% | Training loss: 0.6871388354471751
Epoch: 92 | Iteration number: [1830/4518] 40% | Training loss: 0.6871385682150314
Epoch: 92 | Iteration number: [1840/4518] 40% | Training loss: 0.6871467069763204
Epoch: 92 | Iteration number: [1850/4518] 40% | Training loss: 0.6871429716896367
Epoch: 92 | Iteration number: [1860/4518] 41% | Training loss: 0.687143636070272
Epoch: 92 | Iteration number: [1870/4518] 41% | Training loss: 0.6871375560123015
Epoch: 92 | Iteration number: [1880/4518] 41% | Training loss: 0.6871347337010059
Epoch: 92 | Iteration number: [1890/4518] 41% | Training loss: 0.6871345840433918
Epoch: 92 | Iteration number: [1900/4518] 42% | Training loss: 0.6871337598248531
Epoch: 92 | Iteration number: [1910/4518] 42% | Training loss: 0.6871328187238483
Epoch: 92 | Iteration number: [1920/4518] 42% | Training loss: 0.6871258349468311
Epoch: 92 | Iteration number: [1930/4518] 42% | Training loss: 0.6871226639327608
Epoch: 92 | Iteration number: [1940/4518] 42% | Training loss: 0.6871216614221789
Epoch: 92 | Iteration number: [1950/4518] 43% | Training loss: 0.6871276771410918
Epoch: 92 | Iteration number: [1960/4518] 43% | Training loss: 0.6871207551688564
Epoch: 92 | Iteration number: [1970/4518] 43% | Training loss: 0.6871177285455811
Epoch: 92 | Iteration number: [1980/4518] 43% | Training loss: 0.6871179177604541
Epoch: 92 | Iteration number: [1990/4518] 44% | Training loss: 0.6871152159257151
Epoch: 92 | Iteration number: [2000/4518] 44% | Training loss: 0.6871128509938716
Epoch: 92 | Iteration number: [2010/4518] 44% | Training loss: 0.6871143653618162
Epoch: 92 | Iteration number: [2020/4518] 44% | Training loss: 0.6871079754121233
Epoch: 92 | Iteration number: [2030/4518] 44% | Training loss: 0.687105661219564
Epoch: 92 | Iteration number: [2040/4518] 45% | Training loss: 0.6870982870459557
Epoch: 92 | Iteration number: [2050/4518] 45% | Training loss: 0.6870917440914526
Epoch: 92 | Iteration number: [2060/4518] 45% | Training loss: 0.6870993666278505
Epoch: 92 | Iteration number: [2070/4518] 45% | Training loss: 0.6871014605685709
Epoch: 92 | Iteration number: [2080/4518] 46% | Training loss: 0.6871011471232542
Epoch: 92 | Iteration number: [2090/4518] 46% | Training loss: 0.6870997399804695
Epoch: 92 | Iteration number: [2100/4518] 46% | Training loss: 0.6870958516711281
Epoch: 92 | Iteration number: [2110/4518] 46% | Training loss: 0.6870895786590486
Epoch: 92 | Iteration number: [2120/4518] 46% | Training loss: 0.6870867113459785
Epoch: 92 | Iteration number: [2130/4518] 47% | Training loss: 0.6870946754032458
Epoch: 92 | Iteration number: [2140/4518] 47% | Training loss: 0.6870901633924413
Epoch: 92 | Iteration number: [2150/4518] 47% | Training loss: 0.6870963495553926
Epoch: 92 | Iteration number: [2160/4518] 47% | Training loss: 0.6870906703450061
Epoch: 92 | Iteration number: [2170/4518] 48% | Training loss: 0.6870880716132678
Epoch: 92 | Iteration number: [2180/4518] 48% | Training loss: 0.6870848335804196
Epoch: 92 | Iteration number: [2190/4518] 48% | Training loss: 0.6870796537018258
Epoch: 92 | Iteration number: [2200/4518] 48% | Training loss: 0.6870775770328261
Epoch: 92 | Iteration number: [2210/4518] 48% | Training loss: 0.6870765166045314
Epoch: 92 | Iteration number: [2220/4518] 49% | Training loss: 0.6870764642953873
Epoch: 92 | Iteration number: [2230/4518] 49% | Training loss: 0.6870787426762517
Epoch: 92 | Iteration number: [2240/4518] 49% | Training loss: 0.687075851219041
Epoch: 92 | Iteration number: [2250/4518] 49% | Training loss: 0.687073516395357
Epoch: 92 | Iteration number: [2260/4518] 50% | Training loss: 0.6870742051474816
Epoch: 92 | Iteration number: [2270/4518] 50% | Training loss: 0.6870686293698618
Epoch: 92 | Iteration number: [2280/4518] 50% | Training loss: 0.6870664318141184
Epoch: 92 | Iteration number: [2290/4518] 50% | Training loss: 0.6870606659541484
Epoch: 92 | Iteration number: [2300/4518] 50% | Training loss: 0.687058765033017
Epoch: 92 | Iteration number: [2310/4518] 51% | Training loss: 0.687055199848109
Epoch: 92 | Iteration number: [2320/4518] 51% | Training loss: 0.687049981540647
Epoch: 92 | Iteration number: [2330/4518] 51% | Training loss: 0.687051658978278
Epoch: 92 | Iteration number: [2340/4518] 51% | Training loss: 0.6870503425088703
Epoch: 92 | Iteration number: [2350/4518] 52% | Training loss: 0.6870423444281233
Epoch: 92 | Iteration number: [2360/4518] 52% | Training loss: 0.6870456974132586
Epoch: 92 | Iteration number: [2370/4518] 52% | Training loss: 0.6870463210822157
Epoch: 92 | Iteration number: [2380/4518] 52% | Training loss: 0.6870385563423653
Epoch: 92 | Iteration number: [2390/4518] 52% | Training loss: 0.6870372663481964
Epoch: 92 | Iteration number: [2400/4518] 53% | Training loss: 0.6870427551368873
Epoch: 92 | Iteration number: [2410/4518] 53% | Training loss: 0.6870456167771114
Epoch: 92 | Iteration number: [2420/4518] 53% | Training loss: 0.6870496559487886
Epoch: 92 | Iteration number: [2430/4518] 53% | Training loss: 0.6870479783648816
Epoch: 92 | Iteration number: [2440/4518] 54% | Training loss: 0.6870472274598528
Epoch: 92 | Iteration number: [2450/4518] 54% | Training loss: 0.6870507118409994
Epoch: 92 | Iteration number: [2460/4518] 54% | Training loss: 0.6870502784727065
Epoch: 92 | Iteration number: [2470/4518] 54% | Training loss: 0.68705035257436
Epoch: 92 | Iteration number: [2480/4518] 54% | Training loss: 0.6870485488445528
Epoch: 92 | Iteration number: [2490/4518] 55% | Training loss: 0.6870506512831492
Epoch: 92 | Iteration number: [2500/4518] 55% | Training loss: 0.6870543417453766
Epoch: 92 | Iteration number: [2510/4518] 55% | Training loss: 0.6870557114422559
Epoch: 92 | Iteration number: [2520/4518] 55% | Training loss: 0.6870570047270684
Epoch: 92 | Iteration number: [2530/4518] 55% | Training loss: 0.6870547346211233
Epoch: 92 | Iteration number: [2540/4518] 56% | Training loss: 0.6870532374447725
Epoch: 92 | Iteration number: [2550/4518] 56% | Training loss: 0.6870483106725356
Epoch: 92 | Iteration number: [2560/4518] 56% | Training loss: 0.6870520994300022
Epoch: 92 | Iteration number: [2570/4518] 56% | Training loss: 0.6870497433591909
Epoch: 92 | Iteration number: [2580/4518] 57% | Training loss: 0.6870497070310652
Epoch: 92 | Iteration number: [2590/4518] 57% | Training loss: 0.6870475062992581
Epoch: 92 | Iteration number: [2600/4518] 57% | Training loss: 0.687050031377719
Epoch: 92 | Iteration number: [2610/4518] 57% | Training loss: 0.6870502894180488
Epoch: 92 | Iteration number: [2620/4518] 57% | Training loss: 0.6870523396794123
Epoch: 92 | Iteration number: [2630/4518] 58% | Training loss: 0.6870449437161362
Epoch: 92 | Iteration number: [2640/4518] 58% | Training loss: 0.6870470037514513
Epoch: 92 | Iteration number: [2650/4518] 58% | Training loss: 0.6870433437374402
Epoch: 92 | Iteration number: [2660/4518] 58% | Training loss: 0.6870445201495536
Epoch: 92 | Iteration number: [2670/4518] 59% | Training loss: 0.6870455463504077
Epoch: 92 | Iteration number: [2680/4518] 59% | Training loss: 0.6870466200495834
Epoch: 92 | Iteration number: [2690/4518] 59% | Training loss: 0.6870388190542455
Epoch: 92 | Iteration number: [2700/4518] 59% | Training loss: 0.687035818806401
Epoch: 92 | Iteration number: [2710/4518] 59% | Training loss: 0.6870390444004227
Epoch: 92 | Iteration number: [2720/4518] 60% | Training loss: 0.6870357437387985
Epoch: 92 | Iteration number: [2730/4518] 60% | Training loss: 0.687030994520956
Epoch: 92 | Iteration number: [2740/4518] 60% | Training loss: 0.6870312069236797
Epoch: 92 | Iteration number: [2750/4518] 60% | Training loss: 0.6870288953564384
Epoch: 92 | Iteration number: [2760/4518] 61% | Training loss: 0.6870222751861034
Epoch: 92 | Iteration number: [2770/4518] 61% | Training loss: 0.6870254662062717
Epoch: 92 | Iteration number: [2780/4518] 61% | Training loss: 0.6870259591358171
Epoch: 92 | Iteration number: [2790/4518] 61% | Training loss: 0.6870224975343246
Epoch: 92 | Iteration number: [2800/4518] 61% | Training loss: 0.6870218233977046
Epoch: 92 | Iteration number: [2810/4518] 62% | Training loss: 0.6870212614748401
Epoch: 92 | Iteration number: [2820/4518] 62% | Training loss: 0.6870266292112094
Epoch: 92 | Iteration number: [2830/4518] 62% | Training loss: 0.6870231168640797
Epoch: 92 | Iteration number: [2840/4518] 62% | Training loss: 0.6870221855984607
Epoch: 92 | Iteration number: [2850/4518] 63% | Training loss: 0.6870139197926772
Epoch: 92 | Iteration number: [2860/4518] 63% | Training loss: 0.6870128879805545
Epoch: 92 | Iteration number: [2870/4518] 63% | Training loss: 0.6870137693159256
Epoch: 92 | Iteration number: [2880/4518] 63% | Training loss: 0.6870151619737347
Epoch: 92 | Iteration number: [2890/4518] 63% | Training loss: 0.6870135257813345
Epoch: 92 | Iteration number: [2900/4518] 64% | Training loss: 0.6870142378067148
Epoch: 92 | Iteration number: [2910/4518] 64% | Training loss: 0.6870108438111663
Epoch: 92 | Iteration number: [2920/4518] 64% | Training loss: 0.6870068310670656
Epoch: 92 | Iteration number: [2930/4518] 64% | Training loss: 0.6870080060926314
Epoch: 92 | Iteration number: [2940/4518] 65% | Training loss: 0.6870080447318603
Epoch: 92 | Iteration number: [2950/4518] 65% | Training loss: 0.6870063241255485
Epoch: 92 | Iteration number: [2960/4518] 65% | Training loss: 0.6870067912581804
Epoch: 92 | Iteration number: [2970/4518] 65% | Training loss: 0.6870057472275564
Epoch: 92 | Iteration number: [2980/4518] 65% | Training loss: 0.6870015144948192
Epoch: 92 | Iteration number: [2990/4518] 66% | Training loss: 0.6870018814718444
Epoch: 92 | Iteration number: [3000/4518] 66% | Training loss: 0.6870033417741458
Epoch: 92 | Iteration number: [3010/4518] 66% | Training loss: 0.6870019772916142
Epoch: 92 | Iteration number: [3020/4518] 66% | Training loss: 0.6870008395602372
Epoch: 92 | Iteration number: [3030/4518] 67% | Training loss: 0.6869980848465029
Epoch: 92 | Iteration number: [3040/4518] 67% | Training loss: 0.6869919784171017
Epoch: 92 | Iteration number: [3050/4518] 67% | Training loss: 0.6869954620814714
Epoch: 92 | Iteration number: [3060/4518] 67% | Training loss: 0.686995035702107
Epoch: 92 | Iteration number: [3070/4518] 67% | Training loss: 0.6869967717301185
Epoch: 92 | Iteration number: [3080/4518] 68% | Training loss: 0.6869994553652676
Epoch: 92 | Iteration number: [3090/4518] 68% | Training loss: 0.6869964407871456
Epoch: 92 | Iteration number: [3100/4518] 68% | Training loss: 0.686999661364863
Epoch: 92 | Iteration number: [3110/4518] 68% | Training loss: 0.6870000405901882
Epoch: 92 | Iteration number: [3120/4518] 69% | Training loss: 0.6869983453208055
Epoch: 92 | Iteration number: [3130/4518] 69% | Training loss: 0.6870000130452287
Epoch: 92 | Iteration number: [3140/4518] 69% | Training loss: 0.6869983716185685
Epoch: 92 | Iteration number: [3150/4518] 69% | Training loss: 0.6869973651568095
Epoch: 92 | Iteration number: [3160/4518] 69% | Training loss: 0.6869938601232782
Epoch: 92 | Iteration number: [3170/4518] 70% | Training loss: 0.6869916003397211
Epoch: 92 | Iteration number: [3180/4518] 70% | Training loss: 0.6869904260777827
Epoch: 92 | Iteration number: [3190/4518] 70% | Training loss: 0.6869849658311348
Epoch: 92 | Iteration number: [3200/4518] 70% | Training loss: 0.6869811833463609
Epoch: 92 | Iteration number: [3210/4518] 71% | Training loss: 0.6869810613330651
Epoch: 92 | Iteration number: [3220/4518] 71% | Training loss: 0.6869789066151802
Epoch: 92 | Iteration number: [3230/4518] 71% | Training loss: 0.6869747017190183
Epoch: 92 | Iteration number: [3240/4518] 71% | Training loss: 0.6869753273548903
Epoch: 92 | Iteration number: [3250/4518] 71% | Training loss: 0.6869735251573416
Epoch: 92 | Iteration number: [3260/4518] 72% | Training loss: 0.6869753826432433
Epoch: 92 | Iteration number: [3270/4518] 72% | Training loss: 0.6869758261453122
Epoch: 92 | Iteration number: [3280/4518] 72% | Training loss: 0.686974930436146
Epoch: 92 | Iteration number: [3290/4518] 72% | Training loss: 0.6869761011339611
Epoch: 92 | Iteration number: [3300/4518] 73% | Training loss: 0.6869789011008812
Epoch: 92 | Iteration number: [3310/4518] 73% | Training loss: 0.6869789985551574
Epoch: 92 | Iteration number: [3320/4518] 73% | Training loss: 0.6869733644896243
Epoch: 92 | Iteration number: [3330/4518] 73% | Training loss: 0.6869731260133577
Epoch: 92 | Iteration number: [3340/4518] 73% | Training loss: 0.6869705431832525
Epoch: 92 | Iteration number: [3350/4518] 74% | Training loss: 0.6869711217061797
Epoch: 92 | Iteration number: [3360/4518] 74% | Training loss: 0.6869665774738505
Epoch: 92 | Iteration number: [3370/4518] 74% | Training loss: 0.6869676069972777
Epoch: 92 | Iteration number: [3380/4518] 74% | Training loss: 0.6869704477533081
Epoch: 92 | Iteration number: [3390/4518] 75% | Training loss: 0.6869680067782556
Epoch: 92 | Iteration number: [3400/4518] 75% | Training loss: 0.6869671712728108
Epoch: 92 | Iteration number: [3410/4518] 75% | Training loss: 0.6869650466526009
Epoch: 92 | Iteration number: [3420/4518] 75% | Training loss: 0.6869635799300601
Epoch: 92 | Iteration number: [3430/4518] 75% | Training loss: 0.686961358733497
Epoch: 92 | Iteration number: [3440/4518] 76% | Training loss: 0.6869621021109958
Epoch: 92 | Iteration number: [3450/4518] 76% | Training loss: 0.6869562911987305
Epoch: 92 | Iteration number: [3460/4518] 76% | Training loss: 0.6869594612045784
Epoch: 92 | Iteration number: [3470/4518] 76% | Training loss: 0.686960432783671
Epoch: 92 | Iteration number: [3480/4518] 77% | Training loss: 0.6869599400751892
Epoch: 92 | Iteration number: [3490/4518] 77% | Training loss: 0.6869601402036781
Epoch: 92 | Iteration number: [3500/4518] 77% | Training loss: 0.6869628433840616
Epoch: 92 | Iteration number: [3510/4518] 77% | Training loss: 0.686961122812369
Epoch: 92 | Iteration number: [3520/4518] 77% | Training loss: 0.6869606813754547
Epoch: 92 | Iteration number: [3530/4518] 78% | Training loss: 0.6869633792311206
Epoch: 92 | Iteration number: [3540/4518] 78% | Training loss: 0.6869609007054129
Epoch: 92 | Iteration number: [3550/4518] 78% | Training loss: 0.6869644248485565
Epoch: 92 | Iteration number: [3560/4518] 78% | Training loss: 0.6869639981328771
Epoch: 92 | Iteration number: [3570/4518] 79% | Training loss: 0.6869651912474165
Epoch: 92 | Iteration number: [3580/4518] 79% | Training loss: 0.6869589351408975
Epoch: 92 | Iteration number: [3590/4518] 79% | Training loss: 0.6869596246889375
Epoch: 92 | Iteration number: [3600/4518] 79% | Training loss: 0.6869595674508148
Epoch: 92 | Iteration number: [3610/4518] 79% | Training loss: 0.6869581680879038
Epoch: 92 | Iteration number: [3620/4518] 80% | Training loss: 0.6869569550561642
Epoch: 92 | Iteration number: [3630/4518] 80% | Training loss: 0.6869582698036488
Epoch: 92 | Iteration number: [3640/4518] 80% | Training loss: 0.68695663274317
Epoch: 92 | Iteration number: [3650/4518] 80% | Training loss: 0.6869585205267553
Epoch: 92 | Iteration number: [3660/4518] 81% | Training loss: 0.6869604493425192
Epoch: 92 | Iteration number: [3670/4518] 81% | Training loss: 0.6869585186811494
Epoch: 92 | Iteration number: [3680/4518] 81% | Training loss: 0.6869603388821302
Epoch: 92 | Iteration number: [3690/4518] 81% | Training loss: 0.6869586664002116
Epoch: 92 | Iteration number: [3700/4518] 81% | Training loss: 0.6869599312704963
Epoch: 92 | Iteration number: [3710/4518] 82% | Training loss: 0.6869584934409416
Epoch: 92 | Iteration number: [3720/4518] 82% | Training loss: 0.6869560700430665
Epoch: 92 | Iteration number: [3730/4518] 82% | Training loss: 0.6869560412523255
Epoch: 92 | Iteration number: [3740/4518] 82% | Training loss: 0.686957826907622
Epoch: 92 | Iteration number: [3750/4518] 83% | Training loss: 0.6869564670562744
Epoch: 92 | Iteration number: [3760/4518] 83% | Training loss: 0.6869557004659734
Epoch: 92 | Iteration number: [3770/4518] 83% | Training loss: 0.6869544426547437
Epoch: 92 | Iteration number: [3780/4518] 83% | Training loss: 0.6869536627695043
Epoch: 92 | Iteration number: [3790/4518] 83% | Training loss: 0.686955375768893
Epoch: 92 | Iteration number: [3800/4518] 84% | Training loss: 0.6869565374286551
Epoch: 92 | Iteration number: [3810/4518] 84% | Training loss: 0.6869543994505575
Epoch: 92 | Iteration number: [3820/4518] 84% | Training loss: 0.6869543524780822
Epoch: 92 | Iteration number: [3830/4518] 84% | Training loss: 0.6869526305179995
Epoch: 92 | Iteration number: [3840/4518] 84% | Training loss: 0.6869525053538382
Epoch: 92 | Iteration number: [3850/4518] 85% | Training loss: 0.6869481414014643
Epoch: 92 | Iteration number: [3860/4518] 85% | Training loss: 0.6869507449896225
Epoch: 92 | Iteration number: [3870/4518] 85% | Training loss: 0.6869480251649861
Epoch: 92 | Iteration number: [3880/4518] 85% | Training loss: 0.6869492815020158
Epoch: 92 | Iteration number: [3890/4518] 86% | Training loss: 0.6869498803713634
Epoch: 92 | Iteration number: [3900/4518] 86% | Training loss: 0.6869468056391447
Epoch: 92 | Iteration number: [3910/4518] 86% | Training loss: 0.6869435180788455
Epoch: 92 | Iteration number: [3920/4518] 86% | Training loss: 0.6869452209953143
Epoch: 92 | Iteration number: [3930/4518] 86% | Training loss: 0.6869459909033836
Epoch: 92 | Iteration number: [3940/4518] 87% | Training loss: 0.6869472031968499
Epoch: 92 | Iteration number: [3950/4518] 87% | Training loss: 0.6869482027277162
Epoch: 92 | Iteration number: [3960/4518] 87% | Training loss: 0.6869471703665425
Epoch: 92 | Iteration number: [3970/4518] 87% | Training loss: 0.6869471824589545
Epoch: 92 | Iteration number: [3980/4518] 88% | Training loss: 0.6869467752063694
Epoch: 92 | Iteration number: [3990/4518] 88% | Training loss: 0.6869430523617823
Epoch: 92 | Iteration number: [4000/4518] 88% | Training loss: 0.6869389551877976
Epoch: 92 | Iteration number: [4010/4518] 88% | Training loss: 0.6869369626937067
Epoch: 92 | Iteration number: [4020/4518] 88% | Training loss: 0.6869360805892233
Epoch: 92 | Iteration number: [4030/4518] 89% | Training loss: 0.6869372775773552
Epoch: 92 | Iteration number: [4040/4518] 89% | Training loss: 0.6869389211039733
Epoch: 92 | Iteration number: [4050/4518] 89% | Training loss: 0.6869363349602546
Epoch: 92 | Iteration number: [4060/4518] 89% | Training loss: 0.686933324078621
Epoch: 92 | Iteration number: [4070/4518] 90% | Training loss: 0.6869360477684171
Epoch: 92 | Iteration number: [4080/4518] 90% | Training loss: 0.6869343668514607
Epoch: 92 | Iteration number: [4090/4518] 90% | Training loss: 0.6869333565089405
Epoch: 92 | Iteration number: [4100/4518] 90% | Training loss: 0.686932998386825
Epoch: 92 | Iteration number: [4110/4518] 90% | Training loss: 0.6869304193777469
Epoch: 92 | Iteration number: [4120/4518] 91% | Training loss: 0.6869323721065105
Epoch: 92 | Iteration number: [4130/4518] 91% | Training loss: 0.686934162874776
Epoch: 92 | Iteration number: [4140/4518] 91% | Training loss: 0.686931783421604
Epoch: 92 | Iteration number: [4150/4518] 91% | Training loss: 0.6869338213535676
Epoch: 92 | Iteration number: [4160/4518] 92% | Training loss: 0.6869324067320961
Epoch: 92 | Iteration number: [4170/4518] 92% | Training loss: 0.6869319921060146
Epoch: 92 | Iteration number: [4180/4518] 92% | Training loss: 0.6869301252673117
Epoch: 92 | Iteration number: [4190/4518] 92% | Training loss: 0.6869263832352895
Epoch: 92 | Iteration number: [4200/4518] 92% | Training loss: 0.6869271169815745
Epoch: 92 | Iteration number: [4210/4518] 93% | Training loss: 0.6869276810287014
Epoch: 92 | Iteration number: [4220/4518] 93% | Training loss: 0.6869233401748241
Epoch: 92 | Iteration number: [4230/4518] 93% | Training loss: 0.6869238646740609
Epoch: 92 | Iteration number: [4240/4518] 93% | Training loss: 0.6869246205068984
Epoch: 92 | Iteration number: [4250/4518] 94% | Training loss: 0.6869219610410578
Epoch: 92 | Iteration number: [4260/4518] 94% | Training loss: 0.686920392569242
Epoch: 92 | Iteration number: [4270/4518] 94% | Training loss: 0.6869192671440804
Epoch: 92 | Iteration number: [4280/4518] 94% | Training loss: 0.6869182075016966
Epoch: 92 | Iteration number: [4290/4518] 94% | Training loss: 0.6869155167421817
Epoch: 92 | Iteration number: [4300/4518] 95% | Training loss: 0.6869158764356791
Epoch: 92 | Iteration number: [4310/4518] 95% | Training loss: 0.6869133519047651
Epoch: 92 | Iteration number: [4320/4518] 95% | Training loss: 0.6869089987266946
Epoch: 92 | Iteration number: [4330/4518] 95% | Training loss: 0.6869084366199326
Epoch: 92 | Iteration number: [4340/4518] 96% | Training loss: 0.6869055938885509
Epoch: 92 | Iteration number: [4350/4518] 96% | Training loss: 0.6869037998544759
Epoch: 92 | Iteration number: [4360/4518] 96% | Training loss: 0.6869040139771383
Epoch: 92 | Iteration number: [4370/4518] 96% | Training loss: 0.6869055547621484
Epoch: 92 | Iteration number: [4380/4518] 96% | Training loss: 0.6869055505484751
Epoch: 92 | Iteration number: [4390/4518] 97% | Training loss: 0.686909245996649
Epoch: 92 | Iteration number: [4400/4518] 97% | Training loss: 0.686907570362091
Epoch: 92 | Iteration number: [4410/4518] 97% | Training loss: 0.6869067406438105
Epoch: 92 | Iteration number: [4420/4518] 97% | Training loss: 0.6869059673666414
Epoch: 92 | Iteration number: [4430/4518] 98% | Training loss: 0.6869054576344199
Epoch: 92 | Iteration number: [4440/4518] 98% | Training loss: 0.6869063809379801
Epoch: 92 | Iteration number: [4450/4518] 98% | Training loss: 0.6869049192814345
Epoch: 92 | Iteration number: [4460/4518] 98% | Training loss: 0.6869044205399372
Epoch: 92 | Iteration number: [4470/4518] 98% | Training loss: 0.6869020064005116
Epoch: 92 | Iteration number: [4480/4518] 99% | Training loss: 0.6869024819561413
Epoch: 92 | Iteration number: [4490/4518] 99% | Training loss: 0.6869026385065177
Epoch: 92 | Iteration number: [4500/4518] 99% | Training loss: 0.6869017332527373
Epoch: 92 | Iteration number: [4510/4518] 99% | Training loss: 0.6869042011163716

 End of epoch: 92 | Train Loss: 0.6867523135707251 | Training Time: 641 

 End of epoch: 92 | Eval Loss: 0.6897446792952868 | Evaluating Time: 17 
Epoch: 93 | Iteration number: [10/4518] 0% | Training loss: 0.7557055354118347
Epoch: 93 | Iteration number: [20/4518] 0% | Training loss: 0.721459886431694
Epoch: 93 | Iteration number: [30/4518] 0% | Training loss: 0.7100471516450246
Epoch: 93 | Iteration number: [40/4518] 0% | Training loss: 0.7038559183478356
Epoch: 93 | Iteration number: [50/4518] 1% | Training loss: 0.7003679740428924
Epoch: 93 | Iteration number: [60/4518] 1% | Training loss: 0.6978145678838094
Epoch: 93 | Iteration number: [70/4518] 1% | Training loss: 0.6961423584393093
Epoch: 93 | Iteration number: [80/4518] 1% | Training loss: 0.6948312759399414
Epoch: 93 | Iteration number: [90/4518] 1% | Training loss: 0.6938484423690372
Epoch: 93 | Iteration number: [100/4518] 2% | Training loss: 0.6931592470407486
Epoch: 93 | Iteration number: [110/4518] 2% | Training loss: 0.6925805736671794
Epoch: 93 | Iteration number: [120/4518] 2% | Training loss: 0.6920518254240354
Epoch: 93 | Iteration number: [130/4518] 2% | Training loss: 0.6915645750669333
Epoch: 93 | Iteration number: [140/4518] 3% | Training loss: 0.6913341581821442
Epoch: 93 | Iteration number: [150/4518] 3% | Training loss: 0.6909584593772888
Epoch: 93 | Iteration number: [160/4518] 3% | Training loss: 0.6907897982746363
Epoch: 93 | Iteration number: [170/4518] 3% | Training loss: 0.6905257431899801
Epoch: 93 | Iteration number: [180/4518] 3% | Training loss: 0.6903310696283976
Epoch: 93 | Iteration number: [190/4518] 4% | Training loss: 0.6901676130922217
Epoch: 93 | Iteration number: [200/4518] 4% | Training loss: 0.6899788656830788
Epoch: 93 | Iteration number: [210/4518] 4% | Training loss: 0.6898455838362376
Epoch: 93 | Iteration number: [220/4518] 4% | Training loss: 0.6896913785826077
Epoch: 93 | Iteration number: [230/4518] 5% | Training loss: 0.6895855320536572
Epoch: 93 | Iteration number: [240/4518] 5% | Training loss: 0.6894366249442101
Epoch: 93 | Iteration number: [250/4518] 5% | Training loss: 0.6893551976680755
Epoch: 93 | Iteration number: [260/4518] 5% | Training loss: 0.6892315043852879
Epoch: 93 | Iteration number: [270/4518] 5% | Training loss: 0.6891371700498793
Epoch: 93 | Iteration number: [280/4518] 6% | Training loss: 0.689053566115243
Epoch: 93 | Iteration number: [290/4518] 6% | Training loss: 0.688953613207258
Epoch: 93 | Iteration number: [300/4518] 6% | Training loss: 0.6888682448863983
Epoch: 93 | Iteration number: [310/4518] 6% | Training loss: 0.6888076545730714
Epoch: 93 | Iteration number: [320/4518] 7% | Training loss: 0.6887626668438316
Epoch: 93 | Iteration number: [330/4518] 7% | Training loss: 0.6886489768822988
Epoch: 93 | Iteration number: [340/4518] 7% | Training loss: 0.6886066161534365
Epoch: 93 | Iteration number: [350/4518] 7% | Training loss: 0.6885642344611032
Epoch: 93 | Iteration number: [360/4518] 7% | Training loss: 0.6885037107600106
Epoch: 93 | Iteration number: [370/4518] 8% | Training loss: 0.6884860818450516
Epoch: 93 | Iteration number: [380/4518] 8% | Training loss: 0.6884190847999171
Epoch: 93 | Iteration number: [390/4518] 8% | Training loss: 0.6883781211498456
Epoch: 93 | Iteration number: [400/4518] 8% | Training loss: 0.6883411340415477
Epoch: 93 | Iteration number: [410/4518] 9% | Training loss: 0.6883054228817544
Epoch: 93 | Iteration number: [420/4518] 9% | Training loss: 0.6882783569040752
Epoch: 93 | Iteration number: [430/4518] 9% | Training loss: 0.6882601136385008
Epoch: 93 | Iteration number: [440/4518] 9% | Training loss: 0.688233895464377
Epoch: 93 | Iteration number: [450/4518] 9% | Training loss: 0.6882137107849121
Epoch: 93 | Iteration number: [460/4518] 10% | Training loss: 0.6881452876588573
Epoch: 93 | Iteration number: [470/4518] 10% | Training loss: 0.6881118666618429
Epoch: 93 | Iteration number: [480/4518] 10% | Training loss: 0.6881068372478087
Epoch: 93 | Iteration number: [490/4518] 10% | Training loss: 0.6880731732261424
Epoch: 93 | Iteration number: [500/4518] 11% | Training loss: 0.688042121052742
Epoch: 93 | Iteration number: [510/4518] 11% | Training loss: 0.6880120659575742
Epoch: 93 | Iteration number: [520/4518] 11% | Training loss: 0.6879739459890586
Epoch: 93 | Iteration number: [530/4518] 11% | Training loss: 0.6879757137793415
Epoch: 93 | Iteration number: [540/4518] 11% | Training loss: 0.6879770262373819
Epoch: 93 | Iteration number: [550/4518] 12% | Training loss: 0.6879578667337244
Epoch: 93 | Iteration number: [560/4518] 12% | Training loss: 0.6879045357661587
Epoch: 93 | Iteration number: [570/4518] 12% | Training loss: 0.6878884231835081
Epoch: 93 | Iteration number: [580/4518] 12% | Training loss: 0.6878641920870748
Epoch: 93 | Iteration number: [590/4518] 13% | Training loss: 0.6878524533772873
Epoch: 93 | Iteration number: [600/4518] 13% | Training loss: 0.6878351970513662
Epoch: 93 | Iteration number: [610/4518] 13% | Training loss: 0.6878446048400441
Epoch: 93 | Iteration number: [620/4518] 13% | Training loss: 0.6878331410308038
Epoch: 93 | Iteration number: [630/4518] 13% | Training loss: 0.6878206062884558
Epoch: 93 | Iteration number: [640/4518] 14% | Training loss: 0.6878019826486707
Epoch: 93 | Iteration number: [650/4518] 14% | Training loss: 0.687775291296152
Epoch: 93 | Iteration number: [660/4518] 14% | Training loss: 0.6877759407867085
Epoch: 93 | Iteration number: [670/4518] 14% | Training loss: 0.6877578891035336
Epoch: 93 | Iteration number: [680/4518] 15% | Training loss: 0.6877330993904787
Epoch: 93 | Iteration number: [690/4518] 15% | Training loss: 0.6877123171868531
Epoch: 93 | Iteration number: [700/4518] 15% | Training loss: 0.6877004367964609
Epoch: 93 | Iteration number: [710/4518] 15% | Training loss: 0.6876939117908478
Epoch: 93 | Iteration number: [720/4518] 15% | Training loss: 0.6877005617651675
Epoch: 93 | Iteration number: [730/4518] 16% | Training loss: 0.6876973781683674
Epoch: 93 | Iteration number: [740/4518] 16% | Training loss: 0.6877017958744153
Epoch: 93 | Iteration number: [750/4518] 16% | Training loss: 0.6876893452803294
Epoch: 93 | Iteration number: [760/4518] 16% | Training loss: 0.6876790558821276
Epoch: 93 | Iteration number: [770/4518] 17% | Training loss: 0.6876669526874245
Epoch: 93 | Iteration number: [780/4518] 17% | Training loss: 0.6876609715131613
Epoch: 93 | Iteration number: [790/4518] 17% | Training loss: 0.6876516517204574
Epoch: 93 | Iteration number: [800/4518] 17% | Training loss: 0.6876274870336055
Epoch: 93 | Iteration number: [810/4518] 17% | Training loss: 0.6876287059283551
Epoch: 93 | Iteration number: [820/4518] 18% | Training loss: 0.6876251251232334
Epoch: 93 | Iteration number: [830/4518] 18% | Training loss: 0.6876190276031034
Epoch: 93 | Iteration number: [840/4518] 18% | Training loss: 0.6876030547278268
Epoch: 93 | Iteration number: [850/4518] 18% | Training loss: 0.6875894566844492
Epoch: 93 | Iteration number: [860/4518] 19% | Training loss: 0.6875759934963181
Epoch: 93 | Iteration number: [870/4518] 19% | Training loss: 0.6875585653316015
Epoch: 93 | Iteration number: [880/4518] 19% | Training loss: 0.6875489818778905
Epoch: 93 | Iteration number: [890/4518] 19% | Training loss: 0.6875213577506247
Epoch: 93 | Iteration number: [900/4518] 19% | Training loss: 0.6874978158209059
Epoch: 93 | Iteration number: [910/4518] 20% | Training loss: 0.6874855067048754
Epoch: 93 | Iteration number: [920/4518] 20% | Training loss: 0.6874885671164679
Epoch: 93 | Iteration number: [930/4518] 20% | Training loss: 0.6874717265687963
Epoch: 93 | Iteration number: [940/4518] 20% | Training loss: 0.6874766848822857
Epoch: 93 | Iteration number: [950/4518] 21% | Training loss: 0.6874767801008727
Epoch: 93 | Iteration number: [960/4518] 21% | Training loss: 0.6874669918790459
Epoch: 93 | Iteration number: [970/4518] 21% | Training loss: 0.6874482760724333
Epoch: 93 | Iteration number: [980/4518] 21% | Training loss: 0.6874396652591471
Epoch: 93 | Iteration number: [990/4518] 21% | Training loss: 0.6874294595886963
Epoch: 93 | Iteration number: [1000/4518] 22% | Training loss: 0.6874204758405685
Epoch: 93 | Iteration number: [1010/4518] 22% | Training loss: 0.6874001575578558
Epoch: 93 | Iteration number: [1020/4518] 22% | Training loss: 0.6874029307388791
Epoch: 93 | Iteration number: [1030/4518] 22% | Training loss: 0.6873864812758362
Epoch: 93 | Iteration number: [1040/4518] 23% | Training loss: 0.6873793501693469
Epoch: 93 | Iteration number: [1050/4518] 23% | Training loss: 0.6873815477462042
Epoch: 93 | Iteration number: [1060/4518] 23% | Training loss: 0.6873883136600818
Epoch: 93 | Iteration number: [1070/4518] 23% | Training loss: 0.6873868557894341
Epoch: 93 | Iteration number: [1080/4518] 23% | Training loss: 0.6873960076658814
Epoch: 93 | Iteration number: [1090/4518] 24% | Training loss: 0.6873894434456431
Epoch: 93 | Iteration number: [1100/4518] 24% | Training loss: 0.6873816627805883
Epoch: 93 | Iteration number: [1110/4518] 24% | Training loss: 0.6873807964024243
Epoch: 93 | Iteration number: [1120/4518] 24% | Training loss: 0.6873676431498357
Epoch: 93 | Iteration number: [1130/4518] 25% | Training loss: 0.6873675558419354
Epoch: 93 | Iteration number: [1140/4518] 25% | Training loss: 0.6873522252890102
Epoch: 93 | Iteration number: [1150/4518] 25% | Training loss: 0.6873576905934707
Epoch: 93 | Iteration number: [1160/4518] 25% | Training loss: 0.6873487381585713
Epoch: 93 | Iteration number: [1170/4518] 25% | Training loss: 0.687338990227789
Epoch: 93 | Iteration number: [1180/4518] 26% | Training loss: 0.68734181982986
Epoch: 93 | Iteration number: [1190/4518] 26% | Training loss: 0.6873226833443682
Epoch: 93 | Iteration number: [1200/4518] 26% | Training loss: 0.6873179396490255
Epoch: 93 | Iteration number: [1210/4518] 26% | Training loss: 0.687308402790511
Epoch: 93 | Iteration number: [1220/4518] 27% | Training loss: 0.6872988545503773
Epoch: 93 | Iteration number: [1230/4518] 27% | Training loss: 0.6873016840558711
Epoch: 93 | Iteration number: [1240/4518] 27% | Training loss: 0.6872942514477237
Epoch: 93 | Iteration number: [1250/4518] 27% | Training loss: 0.6873058335304261
Epoch: 93 | Iteration number: [1260/4518] 27% | Training loss: 0.6872976909554194
Epoch: 93 | Iteration number: [1270/4518] 28% | Training loss: 0.6872925936706423
Epoch: 93 | Iteration number: [1280/4518] 28% | Training loss: 0.6872956498060375
Epoch: 93 | Iteration number: [1290/4518] 28% | Training loss: 0.6872934233772662
Epoch: 93 | Iteration number: [1300/4518] 28% | Training loss: 0.687279613338984
Epoch: 93 | Iteration number: [1310/4518] 28% | Training loss: 0.6872771768169549
Epoch: 93 | Iteration number: [1320/4518] 29% | Training loss: 0.6872787442622763
Epoch: 93 | Iteration number: [1330/4518] 29% | Training loss: 0.6872779027859968
Epoch: 93 | Iteration number: [1340/4518] 29% | Training loss: 0.6872763818769313
Epoch: 93 | Iteration number: [1350/4518] 29% | Training loss: 0.6872765252766786
Epoch: 93 | Iteration number: [1360/4518] 30% | Training loss: 0.6872704148292541
Epoch: 93 | Iteration number: [1370/4518] 30% | Training loss: 0.6872685481161966
Epoch: 93 | Iteration number: [1380/4518] 30% | Training loss: 0.6872652427441832
Epoch: 93 | Iteration number: [1390/4518] 30% | Training loss: 0.6872502446603432
Epoch: 93 | Iteration number: [1400/4518] 30% | Training loss: 0.6872384109241622
Epoch: 93 | Iteration number: [1410/4518] 31% | Training loss: 0.6872341382588055
Epoch: 93 | Iteration number: [1420/4518] 31% | Training loss: 0.6872367879454518
Epoch: 93 | Iteration number: [1430/4518] 31% | Training loss: 0.6872230068370179
Epoch: 93 | Iteration number: [1440/4518] 31% | Training loss: 0.6872244017405642
Epoch: 93 | Iteration number: [1450/4518] 32% | Training loss: 0.6872252097623102
Epoch: 93 | Iteration number: [1460/4518] 32% | Training loss: 0.6872238630301332
Epoch: 93 | Iteration number: [1470/4518] 32% | Training loss: 0.6872197011701103
Epoch: 93 | Iteration number: [1480/4518] 32% | Training loss: 0.6872071878732862
Epoch: 93 | Iteration number: [1490/4518] 32% | Training loss: 0.6871930427199242
Epoch: 93 | Iteration number: [1500/4518] 33% | Training loss: 0.6871869316101075
Epoch: 93 | Iteration number: [1510/4518] 33% | Training loss: 0.6871857823520306
Epoch: 93 | Iteration number: [1520/4518] 33% | Training loss: 0.6871806462344371
Epoch: 93 | Iteration number: [1530/4518] 33% | Training loss: 0.6871752003828685
Epoch: 93 | Iteration number: [1540/4518] 34% | Training loss: 0.6871730412368651
Epoch: 93 | Iteration number: [1550/4518] 34% | Training loss: 0.6871767707793943
Epoch: 93 | Iteration number: [1560/4518] 34% | Training loss: 0.6871708653294123
Epoch: 93 | Iteration number: [1570/4518] 34% | Training loss: 0.6871621232503539
Epoch: 93 | Iteration number: [1580/4518] 34% | Training loss: 0.6871550715422329
Epoch: 93 | Iteration number: [1590/4518] 35% | Training loss: 0.6871550992599823
Epoch: 93 | Iteration number: [1600/4518] 35% | Training loss: 0.687145570218563
Epoch: 93 | Iteration number: [1610/4518] 35% | Training loss: 0.6871414796536013
Epoch: 93 | Iteration number: [1620/4518] 35% | Training loss: 0.6871415885142338
Epoch: 93 | Iteration number: [1630/4518] 36% | Training loss: 0.687144303541242
Epoch: 93 | Iteration number: [1640/4518] 36% | Training loss: 0.6871450428919095
Epoch: 93 | Iteration number: [1650/4518] 36% | Training loss: 0.6871350767395713
Epoch: 93 | Iteration number: [1660/4518] 36% | Training loss: 0.6871408690530133
Epoch: 93 | Iteration number: [1670/4518] 36% | Training loss: 0.6871409236670968
Epoch: 93 | Iteration number: [1680/4518] 37% | Training loss: 0.687135087734177
Epoch: 93 | Iteration number: [1690/4518] 37% | Training loss: 0.6871253346903085
Epoch: 93 | Iteration number: [1700/4518] 37% | Training loss: 0.6871168019841699
Epoch: 93 | Iteration number: [1710/4518] 37% | Training loss: 0.6871071031916212
Epoch: 93 | Iteration number: [1720/4518] 38% | Training loss: 0.6871019795190456
Epoch: 93 | Iteration number: [1730/4518] 38% | Training loss: 0.6871092143086339
Epoch: 93 | Iteration number: [1740/4518] 38% | Training loss: 0.687100332564321
Epoch: 93 | Iteration number: [1750/4518] 38% | Training loss: 0.6870990436417715
Epoch: 93 | Iteration number: [1760/4518] 38% | Training loss: 0.6870936334471811
Epoch: 93 | Iteration number: [1770/4518] 39% | Training loss: 0.6870873257265253
Epoch: 93 | Iteration number: [1780/4518] 39% | Training loss: 0.6870876361814777
Epoch: 93 | Iteration number: [1790/4518] 39% | Training loss: 0.687089561117428
Epoch: 93 | Iteration number: [1800/4518] 39% | Training loss: 0.6870848999089665
Epoch: 93 | Iteration number: [1810/4518] 40% | Training loss: 0.6870824664995815
Epoch: 93 | Iteration number: [1820/4518] 40% | Training loss: 0.6870803577559335
Epoch: 93 | Iteration number: [1830/4518] 40% | Training loss: 0.6870748227411281
Epoch: 93 | Iteration number: [1840/4518] 40% | Training loss: 0.6870718870150007
Epoch: 93 | Iteration number: [1850/4518] 40% | Training loss: 0.6870741638299581
Epoch: 93 | Iteration number: [1860/4518] 41% | Training loss: 0.6870729987018852
Epoch: 93 | Iteration number: [1870/4518] 41% | Training loss: 0.687074077352483
Epoch: 93 | Iteration number: [1880/4518] 41% | Training loss: 0.6870707054404502
Epoch: 93 | Iteration number: [1890/4518] 41% | Training loss: 0.6870724944841294
Epoch: 93 | Iteration number: [1900/4518] 42% | Training loss: 0.6870687353610992
Epoch: 93 | Iteration number: [1910/4518] 42% | Training loss: 0.6870699737708607
Epoch: 93 | Iteration number: [1920/4518] 42% | Training loss: 0.6870701417016486
Epoch: 93 | Iteration number: [1930/4518] 42% | Training loss: 0.687065493226669
Epoch: 93 | Iteration number: [1940/4518] 42% | Training loss: 0.6870652358863771
Epoch: 93 | Iteration number: [1950/4518] 43% | Training loss: 0.6870691393888914
Epoch: 93 | Iteration number: [1960/4518] 43% | Training loss: 0.6870706367249392
Epoch: 93 | Iteration number: [1970/4518] 43% | Training loss: 0.687070452682863
Epoch: 93 | Iteration number: [1980/4518] 43% | Training loss: 0.6870729020448646
Epoch: 93 | Iteration number: [1990/4518] 44% | Training loss: 0.6870747302644816
Epoch: 93 | Iteration number: [2000/4518] 44% | Training loss: 0.687067891895771
Epoch: 93 | Iteration number: [2010/4518] 44% | Training loss: 0.6870608241700414
Epoch: 93 | Iteration number: [2020/4518] 44% | Training loss: 0.6870609076011299
Epoch: 93 | Iteration number: [2030/4518] 44% | Training loss: 0.6870596794365662
Epoch: 93 | Iteration number: [2040/4518] 45% | Training loss: 0.6870585725003597
Epoch: 93 | Iteration number: [2050/4518] 45% | Training loss: 0.6870583616524207
Epoch: 93 | Iteration number: [2060/4518] 45% | Training loss: 0.687057224726214
Epoch: 93 | Iteration number: [2070/4518] 45% | Training loss: 0.6870495178849225
Epoch: 93 | Iteration number: [2080/4518] 46% | Training loss: 0.6870481430337979
Epoch: 93 | Iteration number: [2090/4518] 46% | Training loss: 0.6870446144393757
Epoch: 93 | Iteration number: [2100/4518] 46% | Training loss: 0.6870400899081003
Epoch: 93 | Iteration number: [2110/4518] 46% | Training loss: 0.6870366655254816
Epoch: 93 | Iteration number: [2120/4518] 46% | Training loss: 0.6870322162531457
Epoch: 93 | Iteration number: [2130/4518] 47% | Training loss: 0.6870349711655451
Epoch: 93 | Iteration number: [2140/4518] 47% | Training loss: 0.6870305277755328
Epoch: 93 | Iteration number: [2150/4518] 47% | Training loss: 0.6870288450496141
Epoch: 93 | Iteration number: [2160/4518] 47% | Training loss: 0.6870326126339259
Epoch: 93 | Iteration number: [2170/4518] 48% | Training loss: 0.6870352376441252
Epoch: 93 | Iteration number: [2180/4518] 48% | Training loss: 0.6870363699186832
Epoch: 93 | Iteration number: [2190/4518] 48% | Training loss: 0.6870324462243955
Epoch: 93 | Iteration number: [2200/4518] 48% | Training loss: 0.6870260729031129
Epoch: 93 | Iteration number: [2210/4518] 48% | Training loss: 0.6870195872913119
Epoch: 93 | Iteration number: [2220/4518] 49% | Training loss: 0.6870168172292881
Epoch: 93 | Iteration number: [2230/4518] 49% | Training loss: 0.6870174723088474
Epoch: 93 | Iteration number: [2240/4518] 49% | Training loss: 0.6870154395433409
Epoch: 93 | Iteration number: [2250/4518] 49% | Training loss: 0.6870147761503855
Epoch: 93 | Iteration number: [2260/4518] 50% | Training loss: 0.6870169554400233
Epoch: 93 | Iteration number: [2270/4518] 50% | Training loss: 0.6870122650909004
Epoch: 93 | Iteration number: [2280/4518] 50% | Training loss: 0.6870177939534188
Epoch: 93 | Iteration number: [2290/4518] 50% | Training loss: 0.6870207897700598
Epoch: 93 | Iteration number: [2300/4518] 50% | Training loss: 0.6870166285919107
Epoch: 93 | Iteration number: [2310/4518] 51% | Training loss: 0.6870164117513797
Epoch: 93 | Iteration number: [2320/4518] 51% | Training loss: 0.6870143613167878
Epoch: 93 | Iteration number: [2330/4518] 51% | Training loss: 0.6870124823801508
Epoch: 93 | Iteration number: [2340/4518] 51% | Training loss: 0.6870090407693488
Epoch: 93 | Iteration number: [2350/4518] 52% | Training loss: 0.6870095620510426
Epoch: 93 | Iteration number: [2360/4518] 52% | Training loss: 0.6870024429539503
Epoch: 93 | Iteration number: [2370/4518] 52% | Training loss: 0.6870058520685268
Epoch: 93 | Iteration number: [2380/4518] 52% | Training loss: 0.6870004642911318
Epoch: 93 | Iteration number: [2390/4518] 52% | Training loss: 0.6870017859476879
Epoch: 93 | Iteration number: [2400/4518] 53% | Training loss: 0.6869971344371637
Epoch: 93 | Iteration number: [2410/4518] 53% | Training loss: 0.6869989817320559
Epoch: 93 | Iteration number: [2420/4518] 53% | Training loss: 0.6869975549623001
Epoch: 93 | Iteration number: [2430/4518] 53% | Training loss: 0.6869981648254787
Epoch: 93 | Iteration number: [2440/4518] 54% | Training loss: 0.6869974179590335
Epoch: 93 | Iteration number: [2450/4518] 54% | Training loss: 0.6869948092528751
Epoch: 93 | Iteration number: [2460/4518] 54% | Training loss: 0.6869952062523462
Epoch: 93 | Iteration number: [2470/4518] 54% | Training loss: 0.6869993950673926
Epoch: 93 | Iteration number: [2480/4518] 54% | Training loss: 0.6869967224857499
Epoch: 93 | Iteration number: [2490/4518] 55% | Training loss: 0.686999560551471
Epoch: 93 | Iteration number: [2500/4518] 55% | Training loss: 0.6870009967565537
Epoch: 93 | Iteration number: [2510/4518] 55% | Training loss: 0.686993587444503
Epoch: 93 | Iteration number: [2520/4518] 55% | Training loss: 0.6869904655549262
Epoch: 93 | Iteration number: [2530/4518] 55% | Training loss: 0.6869927832260433
Epoch: 93 | Iteration number: [2540/4518] 56% | Training loss: 0.6869937293876813
Epoch: 93 | Iteration number: [2550/4518] 56% | Training loss: 0.6869987096973494
Epoch: 93 | Iteration number: [2560/4518] 56% | Training loss: 0.687001908919774
Epoch: 93 | Iteration number: [2570/4518] 56% | Training loss: 0.6870069234055768
Epoch: 93 | Iteration number: [2580/4518] 57% | Training loss: 0.6870024037684581
Epoch: 93 | Iteration number: [2590/4518] 57% | Training loss: 0.687002062774533
Epoch: 93 | Iteration number: [2600/4518] 57% | Training loss: 0.6870013048786383
Epoch: 93 | Iteration number: [2610/4518] 57% | Training loss: 0.6870007514268502
Epoch: 93 | Iteration number: [2620/4518] 57% | Training loss: 0.6870006140406805
Epoch: 93 | Iteration number: [2630/4518] 58% | Training loss: 0.6869981004937973
Epoch: 93 | Iteration number: [2640/4518] 58% | Training loss: 0.6869973332141385
Epoch: 93 | Iteration number: [2650/4518] 58% | Training loss: 0.686998812005205
Epoch: 93 | Iteration number: [2660/4518] 58% | Training loss: 0.6869966234479632
Epoch: 93 | Iteration number: [2670/4518] 59% | Training loss: 0.6869964083705502
Epoch: 93 | Iteration number: [2680/4518] 59% | Training loss: 0.6869903019559918
Epoch: 93 | Iteration number: [2690/4518] 59% | Training loss: 0.6869906389137183
Epoch: 93 | Iteration number: [2700/4518] 59% | Training loss: 0.6869929284740377
Epoch: 93 | Iteration number: [2710/4518] 59% | Training loss: 0.6869905898931722
Epoch: 93 | Iteration number: [2720/4518] 60% | Training loss: 0.6869929628117996
Epoch: 93 | Iteration number: [2730/4518] 60% | Training loss: 0.6869950774388436
Epoch: 93 | Iteration number: [2740/4518] 60% | Training loss: 0.6869965221977582
Epoch: 93 | Iteration number: [2750/4518] 60% | Training loss: 0.6869927669438449
Epoch: 93 | Iteration number: [2760/4518] 61% | Training loss: 0.6869901375278182
Epoch: 93 | Iteration number: [2770/4518] 61% | Training loss: 0.6869862516864542
Epoch: 93 | Iteration number: [2780/4518] 61% | Training loss: 0.6869884028709192
Epoch: 93 | Iteration number: [2790/4518] 61% | Training loss: 0.6869863405236206
Epoch: 93 | Iteration number: [2800/4518] 61% | Training loss: 0.6869893103412219
Epoch: 93 | Iteration number: [2810/4518] 62% | Training loss: 0.686990235517882
Epoch: 93 | Iteration number: [2820/4518] 62% | Training loss: 0.6869899152229864
Epoch: 93 | Iteration number: [2830/4518] 62% | Training loss: 0.6869954046849227
Epoch: 93 | Iteration number: [2840/4518] 62% | Training loss: 0.6869949678929759
Epoch: 93 | Iteration number: [2850/4518] 63% | Training loss: 0.6869955388077519
Epoch: 93 | Iteration number: [2860/4518] 63% | Training loss: 0.6869968899063297
Epoch: 93 | Iteration number: [2870/4518] 63% | Training loss: 0.6869983669357432
Epoch: 93 | Iteration number: [2880/4518] 63% | Training loss: 0.6869981739463078
Epoch: 93 | Iteration number: [2890/4518] 63% | Training loss: 0.6869943552569947
Epoch: 93 | Iteration number: [2900/4518] 64% | Training loss: 0.686990883966972
Epoch: 93 | Iteration number: [2910/4518] 64% | Training loss: 0.6869909402021428
Epoch: 93 | Iteration number: [2920/4518] 64% | Training loss: 0.6869899225153335
Epoch: 93 | Iteration number: [2930/4518] 64% | Training loss: 0.6869917677327635
Epoch: 93 | Iteration number: [2940/4518] 65% | Training loss: 0.6869862152402904
Epoch: 93 | Iteration number: [2950/4518] 65% | Training loss: 0.6869861584800785
Epoch: 93 | Iteration number: [2960/4518] 65% | Training loss: 0.6869834089198628
Epoch: 93 | Iteration number: [2970/4518] 65% | Training loss: 0.6869808802098939
Epoch: 93 | Iteration number: [2980/4518] 65% | Training loss: 0.6869819512703275
Epoch: 93 | Iteration number: [2990/4518] 66% | Training loss: 0.6869815909344217
Epoch: 93 | Iteration number: [3000/4518] 66% | Training loss: 0.6869774382114411
Epoch: 93 | Iteration number: [3010/4518] 66% | Training loss: 0.6869767000904907
Epoch: 93 | Iteration number: [3020/4518] 66% | Training loss: 0.6869751034785581
Epoch: 93 | Iteration number: [3030/4518] 67% | Training loss: 0.6869697332578917
Epoch: 93 | Iteration number: [3040/4518] 67% | Training loss: 0.6869699782054676
Epoch: 93 | Iteration number: [3050/4518] 67% | Training loss: 0.6869659319666566
Epoch: 93 | Iteration number: [3060/4518] 67% | Training loss: 0.6869650592017018
Epoch: 93 | Iteration number: [3070/4518] 67% | Training loss: 0.6869634853706298
Epoch: 93 | Iteration number: [3080/4518] 68% | Training loss: 0.6869651017444475
Epoch: 93 | Iteration number: [3090/4518] 68% | Training loss: 0.6869651138975397
Epoch: 93 | Iteration number: [3100/4518] 68% | Training loss: 0.6869667627926795
Epoch: 93 | Iteration number: [3110/4518] 68% | Training loss: 0.6869665108884646
Epoch: 93 | Iteration number: [3120/4518] 69% | Training loss: 0.6869670808124236
Epoch: 93 | Iteration number: [3130/4518] 69% | Training loss: 0.6869681369001492
Epoch: 93 | Iteration number: [3140/4518] 69% | Training loss: 0.6869724527855587
Epoch: 93 | Iteration number: [3150/4518] 69% | Training loss: 0.6869710574642061
Epoch: 93 | Iteration number: [3160/4518] 69% | Training loss: 0.6869704050919677
Epoch: 93 | Iteration number: [3170/4518] 70% | Training loss: 0.6869670593964189
Epoch: 93 | Iteration number: [3180/4518] 70% | Training loss: 0.6869656525130542
Epoch: 93 | Iteration number: [3190/4518] 70% | Training loss: 0.6869645692898562
Epoch: 93 | Iteration number: [3200/4518] 70% | Training loss: 0.6869642243906856
Epoch: 93 | Iteration number: [3210/4518] 71% | Training loss: 0.6869608794788705
Epoch: 93 | Iteration number: [3220/4518] 71% | Training loss: 0.6869616070149108
Epoch: 93 | Iteration number: [3230/4518] 71% | Training loss: 0.6869614535625505
Epoch: 93 | Iteration number: [3240/4518] 71% | Training loss: 0.6869624979518077
Epoch: 93 | Iteration number: [3250/4518] 71% | Training loss: 0.686957155246001
Epoch: 93 | Iteration number: [3260/4518] 72% | Training loss: 0.6869563916161017
Epoch: 93 | Iteration number: [3270/4518] 72% | Training loss: 0.6869536667059686
Epoch: 93 | Iteration number: [3280/4518] 72% | Training loss: 0.686953908404926
Epoch: 93 | Iteration number: [3290/4518] 72% | Training loss: 0.6869543766540597
Epoch: 93 | Iteration number: [3300/4518] 73% | Training loss: 0.6869560317198435
Epoch: 93 | Iteration number: [3310/4518] 73% | Training loss: 0.6869580452175659
Epoch: 93 | Iteration number: [3320/4518] 73% | Training loss: 0.6869577213224158
Epoch: 93 | Iteration number: [3330/4518] 73% | Training loss: 0.6869597774905127
Epoch: 93 | Iteration number: [3340/4518] 73% | Training loss: 0.6869573638289275
Epoch: 93 | Iteration number: [3350/4518] 74% | Training loss: 0.6869592005993004
Epoch: 93 | Iteration number: [3360/4518] 74% | Training loss: 0.6869589609759195
Epoch: 93 | Iteration number: [3370/4518] 74% | Training loss: 0.6869579787777864
Epoch: 93 | Iteration number: [3380/4518] 74% | Training loss: 0.6869567679935659
Epoch: 93 | Iteration number: [3390/4518] 75% | Training loss: 0.6869575911391098
Epoch: 93 | Iteration number: [3400/4518] 75% | Training loss: 0.686957908605828
Epoch: 93 | Iteration number: [3410/4518] 75% | Training loss: 0.6869576750962266
Epoch: 93 | Iteration number: [3420/4518] 75% | Training loss: 0.6869577409056892
Epoch: 93 | Iteration number: [3430/4518] 75% | Training loss: 0.686955979822676
Epoch: 93 | Iteration number: [3440/4518] 76% | Training loss: 0.6869576347775237
Epoch: 93 | Iteration number: [3450/4518] 76% | Training loss: 0.6869493182500204
Epoch: 93 | Iteration number: [3460/4518] 76% | Training loss: 0.6869476343165932
Epoch: 93 | Iteration number: [3470/4518] 76% | Training loss: 0.6869478724703665
Epoch: 93 | Iteration number: [3480/4518] 77% | Training loss: 0.6869456624676441
Epoch: 93 | Iteration number: [3490/4518] 77% | Training loss: 0.6869461810349735
Epoch: 93 | Iteration number: [3500/4518] 77% | Training loss: 0.6869442570550102
Epoch: 93 | Iteration number: [3510/4518] 77% | Training loss: 0.6869464732642867
Epoch: 93 | Iteration number: [3520/4518] 77% | Training loss: 0.6869438450444828
Epoch: 93 | Iteration number: [3530/4518] 78% | Training loss: 0.6869475288870652
Epoch: 93 | Iteration number: [3540/4518] 78% | Training loss: 0.6869434953577774
Epoch: 93 | Iteration number: [3550/4518] 78% | Training loss: 0.6869394817318715
Epoch: 93 | Iteration number: [3560/4518] 78% | Training loss: 0.6869378068808759
Epoch: 93 | Iteration number: [3570/4518] 79% | Training loss: 0.6869383914630954
Epoch: 93 | Iteration number: [3580/4518] 79% | Training loss: 0.6869385539153434
Epoch: 93 | Iteration number: [3590/4518] 79% | Training loss: 0.6869378457494433
Epoch: 93 | Iteration number: [3600/4518] 79% | Training loss: 0.6869374650551213
Epoch: 93 | Iteration number: [3610/4518] 79% | Training loss: 0.6869375331580143
Epoch: 93 | Iteration number: [3620/4518] 80% | Training loss: 0.686936971215912
Epoch: 93 | Iteration number: [3630/4518] 80% | Training loss: 0.6869391796017481
Epoch: 93 | Iteration number: [3640/4518] 80% | Training loss: 0.6869391309199753
Epoch: 93 | Iteration number: [3650/4518] 80% | Training loss: 0.6869388544232878
Epoch: 93 | Iteration number: [3660/4518] 81% | Training loss: 0.6869405465373576
Epoch: 93 | Iteration number: [3670/4518] 81% | Training loss: 0.6869394111373444
Epoch: 93 | Iteration number: [3680/4518] 81% | Training loss: 0.6869380596377279
Epoch: 93 | Iteration number: [3690/4518] 81% | Training loss: 0.6869376310649603
Epoch: 93 | Iteration number: [3700/4518] 81% | Training loss: 0.6869382157035776
Epoch: 93 | Iteration number: [3710/4518] 82% | Training loss: 0.6869373930593063
Epoch: 93 | Iteration number: [3720/4518] 82% | Training loss: 0.6869332926407937
Epoch: 93 | Iteration number: [3730/4518] 82% | Training loss: 0.6869332902712733
Epoch: 93 | Iteration number: [3740/4518] 82% | Training loss: 0.6869339653674293
Epoch: 93 | Iteration number: [3750/4518] 83% | Training loss: 0.6869341578006745
Epoch: 93 | Iteration number: [3760/4518] 83% | Training loss: 0.6869290037992153
Epoch: 93 | Iteration number: [3770/4518] 83% | Training loss: 0.6869275850389617
Epoch: 93 | Iteration number: [3780/4518] 83% | Training loss: 0.6869286347633947
Epoch: 93 | Iteration number: [3790/4518] 83% | Training loss: 0.6869284824834335
Epoch: 93 | Iteration number: [3800/4518] 84% | Training loss: 0.6869267277811703
Epoch: 93 | Iteration number: [3810/4518] 84% | Training loss: 0.6869262644468643
Epoch: 93 | Iteration number: [3820/4518] 84% | Training loss: 0.6869286996375827
Epoch: 93 | Iteration number: [3830/4518] 84% | Training loss: 0.686927951564988
Epoch: 93 | Iteration number: [3840/4518] 84% | Training loss: 0.6869247108077009
Epoch: 93 | Iteration number: [3850/4518] 85% | Training loss: 0.6869220102452612
Epoch: 93 | Iteration number: [3860/4518] 85% | Training loss: 0.6869196823223885
Epoch: 93 | Iteration number: [3870/4518] 85% | Training loss: 0.6869185740479511
Epoch: 93 | Iteration number: [3880/4518] 85% | Training loss: 0.686918610103966
Epoch: 93 | Iteration number: [3890/4518] 86% | Training loss: 0.6869196148335474
Epoch: 93 | Iteration number: [3900/4518] 86% | Training loss: 0.6869220445553462
Epoch: 93 | Iteration number: [3910/4518] 86% | Training loss: 0.6869218979955024
Epoch: 93 | Iteration number: [3920/4518] 86% | Training loss: 0.6869248285129362
Epoch: 93 | Iteration number: [3930/4518] 86% | Training loss: 0.6869275090651961
Epoch: 93 | Iteration number: [3940/4518] 87% | Training loss: 0.6869248949936804
Epoch: 93 | Iteration number: [3950/4518] 87% | Training loss: 0.6869245143329041
Epoch: 93 | Iteration number: [3960/4518] 87% | Training loss: 0.6869250627178134
Epoch: 93 | Iteration number: [3970/4518] 87% | Training loss: 0.6869255232871029
Epoch: 93 | Iteration number: [3980/4518] 88% | Training loss: 0.6869242792153478
Epoch: 93 | Iteration number: [3990/4518] 88% | Training loss: 0.6869245441635151
Epoch: 93 | Iteration number: [4000/4518] 88% | Training loss: 0.6869244835227728
Epoch: 93 | Iteration number: [4010/4518] 88% | Training loss: 0.6869213948523315
Epoch: 93 | Iteration number: [4020/4518] 88% | Training loss: 0.6869224810036854
Epoch: 93 | Iteration number: [4030/4518] 89% | Training loss: 0.6869199279076408
Epoch: 93 | Iteration number: [4040/4518] 89% | Training loss: 0.6869201182433874
Epoch: 93 | Iteration number: [4050/4518] 89% | Training loss: 0.6869168473173071
Epoch: 93 | Iteration number: [4060/4518] 89% | Training loss: 0.6869168270250846
Epoch: 93 | Iteration number: [4070/4518] 90% | Training loss: 0.6869177061011809
Epoch: 93 | Iteration number: [4080/4518] 90% | Training loss: 0.6869177688132314
Epoch: 93 | Iteration number: [4090/4518] 90% | Training loss: 0.6869177578859632
Epoch: 93 | Iteration number: [4100/4518] 90% | Training loss: 0.6869154266322531
Epoch: 93 | Iteration number: [4110/4518] 90% | Training loss: 0.686915855062559
Epoch: 93 | Iteration number: [4120/4518] 91% | Training loss: 0.6869152689732394
Epoch: 93 | Iteration number: [4130/4518] 91% | Training loss: 0.6869140606093926
Epoch: 93 | Iteration number: [4140/4518] 91% | Training loss: 0.686910172490682
Epoch: 93 | Iteration number: [4150/4518] 91% | Training loss: 0.6869104824583214
Epoch: 93 | Iteration number: [4160/4518] 92% | Training loss: 0.6869079359735434
Epoch: 93 | Iteration number: [4170/4518] 92% | Training loss: 0.6869081249482912
Epoch: 93 | Iteration number: [4180/4518] 92% | Training loss: 0.6869098664470837
Epoch: 93 | Iteration number: [4190/4518] 92% | Training loss: 0.6869089070538632
Epoch: 93 | Iteration number: [4200/4518] 92% | Training loss: 0.686906498840877
Epoch: 93 | Iteration number: [4210/4518] 93% | Training loss: 0.6869069643230167
Epoch: 93 | Iteration number: [4220/4518] 93% | Training loss: 0.6869067876824836
Epoch: 93 | Iteration number: [4230/4518] 93% | Training loss: 0.6869033582385269
Epoch: 93 | Iteration number: [4240/4518] 93% | Training loss: 0.6869012936387422
Epoch: 93 | Iteration number: [4250/4518] 94% | Training loss: 0.6869026803549598
Epoch: 93 | Iteration number: [4260/4518] 94% | Training loss: 0.6869064032891546
Epoch: 93 | Iteration number: [4270/4518] 94% | Training loss: 0.6869049279974551
Epoch: 93 | Iteration number: [4280/4518] 94% | Training loss: 0.686902383136972
Epoch: 93 | Iteration number: [4290/4518] 94% | Training loss: 0.6869021240369979
Epoch: 93 | Iteration number: [4300/4518] 95% | Training loss: 0.6869028233372888
Epoch: 93 | Iteration number: [4310/4518] 95% | Training loss: 0.6869023105246285
Epoch: 93 | Iteration number: [4320/4518] 95% | Training loss: 0.6869009695671223
Epoch: 93 | Iteration number: [4330/4518] 95% | Training loss: 0.6868988881760877
Epoch: 93 | Iteration number: [4340/4518] 96% | Training loss: 0.6869002315717908
Epoch: 93 | Iteration number: [4350/4518] 96% | Training loss: 0.6868994459338572
Epoch: 93 | Iteration number: [4360/4518] 96% | Training loss: 0.68689844783293
Epoch: 93 | Iteration number: [4370/4518] 96% | Training loss: 0.6868985665062745
Epoch: 93 | Iteration number: [4380/4518] 96% | Training loss: 0.6868967003065701
Epoch: 93 | Iteration number: [4390/4518] 97% | Training loss: 0.6868961965168798
Epoch: 93 | Iteration number: [4400/4518] 97% | Training loss: 0.6868992898003622
Epoch: 93 | Iteration number: [4410/4518] 97% | Training loss: 0.6868958730411097
Epoch: 93 | Iteration number: [4420/4518] 97% | Training loss: 0.6868951738420115
Epoch: 93 | Iteration number: [4430/4518] 98% | Training loss: 0.686892622197993
Epoch: 93 | Iteration number: [4440/4518] 98% | Training loss: 0.6868929055896965
Epoch: 93 | Iteration number: [4450/4518] 98% | Training loss: 0.686897060549661
Epoch: 93 | Iteration number: [4460/4518] 98% | Training loss: 0.6868970079005032
Epoch: 93 | Iteration number: [4470/4518] 98% | Training loss: 0.686895803330462
Epoch: 93 | Iteration number: [4480/4518] 99% | Training loss: 0.6868963505008391
Epoch: 93 | Iteration number: [4490/4518] 99% | Training loss: 0.686898095889187
Epoch: 93 | Iteration number: [4500/4518] 99% | Training loss: 0.6869001593192419
Epoch: 93 | Iteration number: [4510/4518] 99% | Training loss: 0.686901204311134

 End of epoch: 93 | Train Loss: 0.6867498816273391 | Training Time: 640 

 End of epoch: 93 | Eval Loss: 0.6897457169026745 | Evaluating Time: 17 
Epoch: 94 | Iteration number: [10/4518] 0% | Training loss: 0.7556279122829437
Epoch: 94 | Iteration number: [20/4518] 0% | Training loss: 0.7202954918146134
Epoch: 94 | Iteration number: [30/4518] 0% | Training loss: 0.7093588987986247
Epoch: 94 | Iteration number: [40/4518] 0% | Training loss: 0.7035721763968468
Epoch: 94 | Iteration number: [50/4518] 1% | Training loss: 0.7003359913825988
Epoch: 94 | Iteration number: [60/4518] 1% | Training loss: 0.6980003476142883
Epoch: 94 | Iteration number: [70/4518] 1% | Training loss: 0.6964578832898821
Epoch: 94 | Iteration number: [80/4518] 1% | Training loss: 0.6952626124024391
Epoch: 94 | Iteration number: [90/4518] 1% | Training loss: 0.6943683365980784
Epoch: 94 | Iteration number: [100/4518] 2% | Training loss: 0.6936391830444336
Epoch: 94 | Iteration number: [110/4518] 2% | Training loss: 0.6929935682903636
Epoch: 94 | Iteration number: [120/4518] 2% | Training loss: 0.6924962456027667
Epoch: 94 | Iteration number: [130/4518] 2% | Training loss: 0.6920532643795013
Epoch: 94 | Iteration number: [140/4518] 3% | Training loss: 0.6916720701115472
Epoch: 94 | Iteration number: [150/4518] 3% | Training loss: 0.6912257488568624
Epoch: 94 | Iteration number: [160/4518] 3% | Training loss: 0.6909287478774786
Epoch: 94 | Iteration number: [170/4518] 3% | Training loss: 0.6907022220246932
Epoch: 94 | Iteration number: [180/4518] 3% | Training loss: 0.690511898861991
Epoch: 94 | Iteration number: [190/4518] 4% | Training loss: 0.6902989221246619
Epoch: 94 | Iteration number: [200/4518] 4% | Training loss: 0.6901367828249931
Epoch: 94 | Iteration number: [210/4518] 4% | Training loss: 0.6899509472506387
Epoch: 94 | Iteration number: [220/4518] 4% | Training loss: 0.6898803469809619
Epoch: 94 | Iteration number: [230/4518] 5% | Training loss: 0.6896901674892592
Epoch: 94 | Iteration number: [240/4518] 5% | Training loss: 0.6895444368322691
Epoch: 94 | Iteration number: [250/4518] 5% | Training loss: 0.6894225780963897
Epoch: 94 | Iteration number: [260/4518] 5% | Training loss: 0.6893359924738224
Epoch: 94 | Iteration number: [270/4518] 5% | Training loss: 0.6892104402736381
Epoch: 94 | Iteration number: [280/4518] 6% | Training loss: 0.6890938648155758
Epoch: 94 | Iteration number: [290/4518] 6% | Training loss: 0.6889828507242531
Epoch: 94 | Iteration number: [300/4518] 6% | Training loss: 0.6888880058129628
Epoch: 94 | Iteration number: [310/4518] 6% | Training loss: 0.6888354126484163
Epoch: 94 | Iteration number: [320/4518] 7% | Training loss: 0.688804566860199
Epoch: 94 | Iteration number: [330/4518] 7% | Training loss: 0.6887854720606948
Epoch: 94 | Iteration number: [340/4518] 7% | Training loss: 0.6886973454671748
Epoch: 94 | Iteration number: [350/4518] 7% | Training loss: 0.6886394611426763
Epoch: 94 | Iteration number: [360/4518] 7% | Training loss: 0.6885685884290271
Epoch: 94 | Iteration number: [370/4518] 8% | Training loss: 0.6885382959971557
Epoch: 94 | Iteration number: [380/4518] 8% | Training loss: 0.6885116978695518
Epoch: 94 | Iteration number: [390/4518] 8% | Training loss: 0.6884863862624535
Epoch: 94 | Iteration number: [400/4518] 8% | Training loss: 0.688418388068676
Epoch: 94 | Iteration number: [410/4518] 9% | Training loss: 0.6883992778091896
Epoch: 94 | Iteration number: [420/4518] 9% | Training loss: 0.6883752297787439
Epoch: 94 | Iteration number: [430/4518] 9% | Training loss: 0.6882825653220332
Epoch: 94 | Iteration number: [440/4518] 9% | Training loss: 0.6882687725804069
Epoch: 94 | Iteration number: [450/4518] 9% | Training loss: 0.6882369632191129
Epoch: 94 | Iteration number: [460/4518] 10% | Training loss: 0.6882091671228409
Epoch: 94 | Iteration number: [470/4518] 10% | Training loss: 0.6881973647056742
Epoch: 94 | Iteration number: [480/4518] 10% | Training loss: 0.6881625397751728
Epoch: 94 | Iteration number: [490/4518] 10% | Training loss: 0.688123997741816
Epoch: 94 | Iteration number: [500/4518] 11% | Training loss: 0.6880788595676423
Epoch: 94 | Iteration number: [510/4518] 11% | Training loss: 0.6880482369778202
Epoch: 94 | Iteration number: [520/4518] 11% | Training loss: 0.6880178469877977
Epoch: 94 | Iteration number: [530/4518] 11% | Training loss: 0.6879879709684624
Epoch: 94 | Iteration number: [540/4518] 11% | Training loss: 0.6879922753130948
Epoch: 94 | Iteration number: [550/4518] 12% | Training loss: 0.6879773043502461
Epoch: 94 | Iteration number: [560/4518] 12% | Training loss: 0.6879449517599174
Epoch: 94 | Iteration number: [570/4518] 12% | Training loss: 0.6879402853940663
Epoch: 94 | Iteration number: [580/4518] 12% | Training loss: 0.6879239169688061
Epoch: 94 | Iteration number: [590/4518] 13% | Training loss: 0.6878947900513471
Epoch: 94 | Iteration number: [600/4518] 13% | Training loss: 0.6878758543729782
Epoch: 94 | Iteration number: [610/4518] 13% | Training loss: 0.6878666093114947
Epoch: 94 | Iteration number: [620/4518] 13% | Training loss: 0.6878437722882916
Epoch: 94 | Iteration number: [630/4518] 13% | Training loss: 0.6878373347577594
Epoch: 94 | Iteration number: [640/4518] 14% | Training loss: 0.6878207689151168
Epoch: 94 | Iteration number: [650/4518] 14% | Training loss: 0.6878081643581391
Epoch: 94 | Iteration number: [660/4518] 14% | Training loss: 0.6877903500289628
Epoch: 94 | Iteration number: [670/4518] 14% | Training loss: 0.6877506749843484
Epoch: 94 | Iteration number: [680/4518] 15% | Training loss: 0.6877496629953385
Epoch: 94 | Iteration number: [690/4518] 15% | Training loss: 0.6877436819283859
Epoch: 94 | Iteration number: [700/4518] 15% | Training loss: 0.6877410078900201
Epoch: 94 | Iteration number: [710/4518] 15% | Training loss: 0.6877380699339047
Epoch: 94 | Iteration number: [720/4518] 15% | Training loss: 0.6877203663190206
Epoch: 94 | Iteration number: [730/4518] 16% | Training loss: 0.6877127458787944
Epoch: 94 | Iteration number: [740/4518] 16% | Training loss: 0.6876973310837875
Epoch: 94 | Iteration number: [750/4518] 16% | Training loss: 0.6876988184452056
Epoch: 94 | Iteration number: [760/4518] 16% | Training loss: 0.6876914418841663
Epoch: 94 | Iteration number: [770/4518] 17% | Training loss: 0.6876833016222174
Epoch: 94 | Iteration number: [780/4518] 17% | Training loss: 0.6876841254723378
Epoch: 94 | Iteration number: [790/4518] 17% | Training loss: 0.6876638696918005
Epoch: 94 | Iteration number: [800/4518] 17% | Training loss: 0.6876613742113113
Epoch: 94 | Iteration number: [810/4518] 17% | Training loss: 0.6876537756419476
Epoch: 94 | Iteration number: [820/4518] 18% | Training loss: 0.6876319435311526
Epoch: 94 | Iteration number: [830/4518] 18% | Training loss: 0.6876375177538538
Epoch: 94 | Iteration number: [840/4518] 18% | Training loss: 0.6876238080007689
Epoch: 94 | Iteration number: [850/4518] 18% | Training loss: 0.6875946052635418
Epoch: 94 | Iteration number: [860/4518] 19% | Training loss: 0.6875747186499973
Epoch: 94 | Iteration number: [870/4518] 19% | Training loss: 0.687558800804204
Epoch: 94 | Iteration number: [880/4518] 19% | Training loss: 0.6875488371334293
Epoch: 94 | Iteration number: [890/4518] 19% | Training loss: 0.6875629195336546
Epoch: 94 | Iteration number: [900/4518] 19% | Training loss: 0.6875622132751676
Epoch: 94 | Iteration number: [910/4518] 20% | Training loss: 0.6875534748638069
Epoch: 94 | Iteration number: [920/4518] 20% | Training loss: 0.6875366517383119
Epoch: 94 | Iteration number: [930/4518] 20% | Training loss: 0.6875353727930336
Epoch: 94 | Iteration number: [940/4518] 20% | Training loss: 0.6875313668809039
Epoch: 94 | Iteration number: [950/4518] 21% | Training loss: 0.6875234047362679
Epoch: 94 | Iteration number: [960/4518] 21% | Training loss: 0.6875144151970745
Epoch: 94 | Iteration number: [970/4518] 21% | Training loss: 0.6875146218181886
Epoch: 94 | Iteration number: [980/4518] 21% | Training loss: 0.6874996884744995
Epoch: 94 | Iteration number: [990/4518] 21% | Training loss: 0.6874915581158917
Epoch: 94 | Iteration number: [1000/4518] 22% | Training loss: 0.6874884225726128
Epoch: 94 | Iteration number: [1010/4518] 22% | Training loss: 0.6874749914844437
Epoch: 94 | Iteration number: [1020/4518] 22% | Training loss: 0.687464559545704
Epoch: 94 | Iteration number: [1030/4518] 22% | Training loss: 0.6874606940931487
Epoch: 94 | Iteration number: [1040/4518] 23% | Training loss: 0.687456777290656
Epoch: 94 | Iteration number: [1050/4518] 23% | Training loss: 0.6874605852081662
Epoch: 94 | Iteration number: [1060/4518] 23% | Training loss: 0.6874628667561513
Epoch: 94 | Iteration number: [1070/4518] 23% | Training loss: 0.6874488118652985
Epoch: 94 | Iteration number: [1080/4518] 23% | Training loss: 0.6874492364901084
Epoch: 94 | Iteration number: [1090/4518] 24% | Training loss: 0.6874302568785641
Epoch: 94 | Iteration number: [1100/4518] 24% | Training loss: 0.6874343830347062
Epoch: 94 | Iteration number: [1110/4518] 24% | Training loss: 0.6874404870175027
Epoch: 94 | Iteration number: [1120/4518] 24% | Training loss: 0.6874220996562924
Epoch: 94 | Iteration number: [1130/4518] 25% | Training loss: 0.6874185779980854
Epoch: 94 | Iteration number: [1140/4518] 25% | Training loss: 0.6874164933175372
Epoch: 94 | Iteration number: [1150/4518] 25% | Training loss: 0.6874120733530625
Epoch: 94 | Iteration number: [1160/4518] 25% | Training loss: 0.6874092334303362
Epoch: 94 | Iteration number: [1170/4518] 25% | Training loss: 0.6874083995819091
Epoch: 94 | Iteration number: [1180/4518] 26% | Training loss: 0.6873912103095297
Epoch: 94 | Iteration number: [1190/4518] 26% | Training loss: 0.6873954443871474
Epoch: 94 | Iteration number: [1200/4518] 26% | Training loss: 0.6873845799763998
Epoch: 94 | Iteration number: [1210/4518] 26% | Training loss: 0.6873840373902281
Epoch: 94 | Iteration number: [1220/4518] 27% | Training loss: 0.6873834000747712
Epoch: 94 | Iteration number: [1230/4518] 27% | Training loss: 0.6873727344400514
Epoch: 94 | Iteration number: [1240/4518] 27% | Training loss: 0.6873573759390462
Epoch: 94 | Iteration number: [1250/4518] 27% | Training loss: 0.6873405663490295
Epoch: 94 | Iteration number: [1260/4518] 27% | Training loss: 0.687328421785718
Epoch: 94 | Iteration number: [1270/4518] 28% | Training loss: 0.6873208211162898
Epoch: 94 | Iteration number: [1280/4518] 28% | Training loss: 0.6873145597521215
Epoch: 94 | Iteration number: [1290/4518] 28% | Training loss: 0.6873089429482009
Epoch: 94 | Iteration number: [1300/4518] 28% | Training loss: 0.6872945803862351
Epoch: 94 | Iteration number: [1310/4518] 28% | Training loss: 0.6872817897614631
Epoch: 94 | Iteration number: [1320/4518] 29% | Training loss: 0.6872708602385087
Epoch: 94 | Iteration number: [1330/4518] 29% | Training loss: 0.6872694892094547
Epoch: 94 | Iteration number: [1340/4518] 29% | Training loss: 0.6872609537928852
Epoch: 94 | Iteration number: [1350/4518] 29% | Training loss: 0.6872591693313034
Epoch: 94 | Iteration number: [1360/4518] 30% | Training loss: 0.6872530363500118
Epoch: 94 | Iteration number: [1370/4518] 30% | Training loss: 0.6872518681696732
Epoch: 94 | Iteration number: [1380/4518] 30% | Training loss: 0.687240095069443
Epoch: 94 | Iteration number: [1390/4518] 30% | Training loss: 0.6872408845012994
Epoch: 94 | Iteration number: [1400/4518] 30% | Training loss: 0.6872389655879566
Epoch: 94 | Iteration number: [1410/4518] 31% | Training loss: 0.6872305107032154
Epoch: 94 | Iteration number: [1420/4518] 31% | Training loss: 0.687223674000149
Epoch: 94 | Iteration number: [1430/4518] 31% | Training loss: 0.6872113928511426
Epoch: 94 | Iteration number: [1440/4518] 31% | Training loss: 0.6872063203818268
Epoch: 94 | Iteration number: [1450/4518] 32% | Training loss: 0.6871954018905245
Epoch: 94 | Iteration number: [1460/4518] 32% | Training loss: 0.6871979764063064
Epoch: 94 | Iteration number: [1470/4518] 32% | Training loss: 0.6871984455050254
Epoch: 94 | Iteration number: [1480/4518] 32% | Training loss: 0.687193494390797
Epoch: 94 | Iteration number: [1490/4518] 32% | Training loss: 0.6871945828399402
Epoch: 94 | Iteration number: [1500/4518] 33% | Training loss: 0.6871942159732183
Epoch: 94 | Iteration number: [1510/4518] 33% | Training loss: 0.6871902783185441
Epoch: 94 | Iteration number: [1520/4518] 33% | Training loss: 0.6871936783586677
Epoch: 94 | Iteration number: [1530/4518] 33% | Training loss: 0.6871875055864746
Epoch: 94 | Iteration number: [1540/4518] 34% | Training loss: 0.6871785054733227
Epoch: 94 | Iteration number: [1550/4518] 34% | Training loss: 0.6871848383642012
Epoch: 94 | Iteration number: [1560/4518] 34% | Training loss: 0.6871752184553024
Epoch: 94 | Iteration number: [1570/4518] 34% | Training loss: 0.6871719219882018
Epoch: 94 | Iteration number: [1580/4518] 34% | Training loss: 0.6871763688099535
Epoch: 94 | Iteration number: [1590/4518] 35% | Training loss: 0.6871715836554954
Epoch: 94 | Iteration number: [1600/4518] 35% | Training loss: 0.6871644607186318
Epoch: 94 | Iteration number: [1610/4518] 35% | Training loss: 0.6871682837883137
Epoch: 94 | Iteration number: [1620/4518] 35% | Training loss: 0.6871574482432118
Epoch: 94 | Iteration number: [1630/4518] 36% | Training loss: 0.6871569391774254
Epoch: 94 | Iteration number: [1640/4518] 36% | Training loss: 0.6871517988966732
Epoch: 94 | Iteration number: [1650/4518] 36% | Training loss: 0.6871425914764404
Epoch: 94 | Iteration number: [1660/4518] 36% | Training loss: 0.687135143272848
Epoch: 94 | Iteration number: [1670/4518] 36% | Training loss: 0.6871371293139314
Epoch: 94 | Iteration number: [1680/4518] 37% | Training loss: 0.687132553756237
Epoch: 94 | Iteration number: [1690/4518] 37% | Training loss: 0.6871284607952163
Epoch: 94 | Iteration number: [1700/4518] 37% | Training loss: 0.6871256370754802
Epoch: 94 | Iteration number: [1710/4518] 37% | Training loss: 0.6871182025176042
Epoch: 94 | Iteration number: [1720/4518] 38% | Training loss: 0.6871095525663953
Epoch: 94 | Iteration number: [1730/4518] 38% | Training loss: 0.6871030541513696
Epoch: 94 | Iteration number: [1740/4518] 38% | Training loss: 0.6870946732745773
Epoch: 94 | Iteration number: [1750/4518] 38% | Training loss: 0.6870982761383057
Epoch: 94 | Iteration number: [1760/4518] 38% | Training loss: 0.6870941637591882
Epoch: 94 | Iteration number: [1770/4518] 39% | Training loss: 0.6870970440449687
Epoch: 94 | Iteration number: [1780/4518] 39% | Training loss: 0.6870952283398489
Epoch: 94 | Iteration number: [1790/4518] 39% | Training loss: 0.6870990579354697
Epoch: 94 | Iteration number: [1800/4518] 39% | Training loss: 0.6870931763450304
Epoch: 94 | Iteration number: [1810/4518] 40% | Training loss: 0.6870930100014196
Epoch: 94 | Iteration number: [1820/4518] 40% | Training loss: 0.6870920234984094
Epoch: 94 | Iteration number: [1830/4518] 40% | Training loss: 0.6870872982538463
Epoch: 94 | Iteration number: [1840/4518] 40% | Training loss: 0.6870777189731598
Epoch: 94 | Iteration number: [1850/4518] 40% | Training loss: 0.6870796223911079
Epoch: 94 | Iteration number: [1860/4518] 41% | Training loss: 0.6870796740055084
Epoch: 94 | Iteration number: [1870/4518] 41% | Training loss: 0.6870817185085725
Epoch: 94 | Iteration number: [1880/4518] 41% | Training loss: 0.6870785704001467
Epoch: 94 | Iteration number: [1890/4518] 41% | Training loss: 0.6870780903510947
Epoch: 94 | Iteration number: [1900/4518] 42% | Training loss: 0.6870672708122354
Epoch: 94 | Iteration number: [1910/4518] 42% | Training loss: 0.6870679355416622
Epoch: 94 | Iteration number: [1920/4518] 42% | Training loss: 0.6870639679332574
Epoch: 94 | Iteration number: [1930/4518] 42% | Training loss: 0.6870597865606219
Epoch: 94 | Iteration number: [1940/4518] 42% | Training loss: 0.6870544559562329
Epoch: 94 | Iteration number: [1950/4518] 43% | Training loss: 0.6870477551069015
Epoch: 94 | Iteration number: [1960/4518] 43% | Training loss: 0.6870412861206093
Epoch: 94 | Iteration number: [1970/4518] 43% | Training loss: 0.6870401075951339
Epoch: 94 | Iteration number: [1980/4518] 43% | Training loss: 0.6870402682309199
Epoch: 94 | Iteration number: [1990/4518] 44% | Training loss: 0.6870284566328154
Epoch: 94 | Iteration number: [2000/4518] 44% | Training loss: 0.6870247221589089
Epoch: 94 | Iteration number: [2010/4518] 44% | Training loss: 0.6870276038919515
Epoch: 94 | Iteration number: [2020/4518] 44% | Training loss: 0.6870262336317855
Epoch: 94 | Iteration number: [2030/4518] 44% | Training loss: 0.6870239301561722
Epoch: 94 | Iteration number: [2040/4518] 45% | Training loss: 0.6870225384539249
Epoch: 94 | Iteration number: [2050/4518] 45% | Training loss: 0.6870236428481776
Epoch: 94 | Iteration number: [2060/4518] 45% | Training loss: 0.6870227631434653
Epoch: 94 | Iteration number: [2070/4518] 45% | Training loss: 0.6870172425744614
Epoch: 94 | Iteration number: [2080/4518] 46% | Training loss: 0.6870176016997832
Epoch: 94 | Iteration number: [2090/4518] 46% | Training loss: 0.6870122415882549
Epoch: 94 | Iteration number: [2100/4518] 46% | Training loss: 0.6870057947578885
Epoch: 94 | Iteration number: [2110/4518] 46% | Training loss: 0.687003454354137
Epoch: 94 | Iteration number: [2120/4518] 46% | Training loss: 0.6870098448024606
Epoch: 94 | Iteration number: [2130/4518] 47% | Training loss: 0.6870022469563104
Epoch: 94 | Iteration number: [2140/4518] 47% | Training loss: 0.6870038421076035
Epoch: 94 | Iteration number: [2150/4518] 47% | Training loss: 0.687008245767549
Epoch: 94 | Iteration number: [2160/4518] 47% | Training loss: 0.6870044477835849
Epoch: 94 | Iteration number: [2170/4518] 48% | Training loss: 0.6870000776332644
Epoch: 94 | Iteration number: [2180/4518] 48% | Training loss: 0.6870005955936712
Epoch: 94 | Iteration number: [2190/4518] 48% | Training loss: 0.6869961899165149
Epoch: 94 | Iteration number: [2200/4518] 48% | Training loss: 0.6869870037111369
Epoch: 94 | Iteration number: [2210/4518] 48% | Training loss: 0.6869886639970461
Epoch: 94 | Iteration number: [2220/4518] 49% | Training loss: 0.686987449671771
Epoch: 94 | Iteration number: [2230/4518] 49% | Training loss: 0.6869967203771052
Epoch: 94 | Iteration number: [2240/4518] 49% | Training loss: 0.6869938912136214
Epoch: 94 | Iteration number: [2250/4518] 49% | Training loss: 0.6869984905719757
Epoch: 94 | Iteration number: [2260/4518] 50% | Training loss: 0.6869975668666637
Epoch: 94 | Iteration number: [2270/4518] 50% | Training loss: 0.6869970257061694
Epoch: 94 | Iteration number: [2280/4518] 50% | Training loss: 0.6869940741020336
Epoch: 94 | Iteration number: [2290/4518] 50% | Training loss: 0.6869900608947704
Epoch: 94 | Iteration number: [2300/4518] 50% | Training loss: 0.6869900357204934
Epoch: 94 | Iteration number: [2310/4518] 51% | Training loss: 0.6869921295673816
Epoch: 94 | Iteration number: [2320/4518] 51% | Training loss: 0.6869933823316262
Epoch: 94 | Iteration number: [2330/4518] 51% | Training loss: 0.6869915295823961
Epoch: 94 | Iteration number: [2340/4518] 51% | Training loss: 0.6869814471811311
Epoch: 94 | Iteration number: [2350/4518] 52% | Training loss: 0.686981891748753
Epoch: 94 | Iteration number: [2360/4518] 52% | Training loss: 0.686980998415058
Epoch: 94 | Iteration number: [2370/4518] 52% | Training loss: 0.6869769005332818
Epoch: 94 | Iteration number: [2380/4518] 52% | Training loss: 0.6869771188046752
Epoch: 94 | Iteration number: [2390/4518] 52% | Training loss: 0.6869830555746246
Epoch: 94 | Iteration number: [2400/4518] 53% | Training loss: 0.6869825286914905
Epoch: 94 | Iteration number: [2410/4518] 53% | Training loss: 0.6869805717616655
Epoch: 94 | Iteration number: [2420/4518] 53% | Training loss: 0.6869866230271079
Epoch: 94 | Iteration number: [2430/4518] 53% | Training loss: 0.6869866689782084
Epoch: 94 | Iteration number: [2440/4518] 54% | Training loss: 0.6869886421522157
Epoch: 94 | Iteration number: [2450/4518] 54% | Training loss: 0.6869939812348813
Epoch: 94 | Iteration number: [2460/4518] 54% | Training loss: 0.6869963319078694
Epoch: 94 | Iteration number: [2470/4518] 54% | Training loss: 0.6869910328011763
Epoch: 94 | Iteration number: [2480/4518] 54% | Training loss: 0.6869850545881256
Epoch: 94 | Iteration number: [2490/4518] 55% | Training loss: 0.6869806597989248
Epoch: 94 | Iteration number: [2500/4518] 55% | Training loss: 0.6869770831108093
Epoch: 94 | Iteration number: [2510/4518] 55% | Training loss: 0.6869804257653149
Epoch: 94 | Iteration number: [2520/4518] 55% | Training loss: 0.6869804804523786
Epoch: 94 | Iteration number: [2530/4518] 55% | Training loss: 0.6869787492064148
Epoch: 94 | Iteration number: [2540/4518] 56% | Training loss: 0.686977828393771
Epoch: 94 | Iteration number: [2550/4518] 56% | Training loss: 0.6869746617008659
Epoch: 94 | Iteration number: [2560/4518] 56% | Training loss: 0.6869717763969675
Epoch: 94 | Iteration number: [2570/4518] 56% | Training loss: 0.6869702629078223
Epoch: 94 | Iteration number: [2580/4518] 57% | Training loss: 0.6869742853696956
Epoch: 94 | Iteration number: [2590/4518] 57% | Training loss: 0.6869696348560362
Epoch: 94 | Iteration number: [2600/4518] 57% | Training loss: 0.6869706396643932
Epoch: 94 | Iteration number: [2610/4518] 57% | Training loss: 0.686967094625093
Epoch: 94 | Iteration number: [2620/4518] 57% | Training loss: 0.6869690095422832
Epoch: 94 | Iteration number: [2630/4518] 58% | Training loss: 0.6869724426659342
Epoch: 94 | Iteration number: [2640/4518] 58% | Training loss: 0.6869736545465209
Epoch: 94 | Iteration number: [2650/4518] 58% | Training loss: 0.6869729340526293
Epoch: 94 | Iteration number: [2660/4518] 58% | Training loss: 0.6869709135446334
Epoch: 94 | Iteration number: [2670/4518] 59% | Training loss: 0.6869723344340306
Epoch: 94 | Iteration number: [2680/4518] 59% | Training loss: 0.6869718203793711
Epoch: 94 | Iteration number: [2690/4518] 59% | Training loss: 0.6869730126458916
Epoch: 94 | Iteration number: [2700/4518] 59% | Training loss: 0.6869730995540265
Epoch: 94 | Iteration number: [2710/4518] 59% | Training loss: 0.6869708587762614
Epoch: 94 | Iteration number: [2720/4518] 60% | Training loss: 0.6869675501523649
Epoch: 94 | Iteration number: [2730/4518] 60% | Training loss: 0.6869672801031734
Epoch: 94 | Iteration number: [2740/4518] 60% | Training loss: 0.6869667056268149
Epoch: 94 | Iteration number: [2750/4518] 60% | Training loss: 0.6869621242609891
Epoch: 94 | Iteration number: [2760/4518] 61% | Training loss: 0.6869643492975097
Epoch: 94 | Iteration number: [2770/4518] 61% | Training loss: 0.6869588477732043
Epoch: 94 | Iteration number: [2780/4518] 61% | Training loss: 0.6869560004567071
Epoch: 94 | Iteration number: [2790/4518] 61% | Training loss: 0.6869565176066532
Epoch: 94 | Iteration number: [2800/4518] 61% | Training loss: 0.6869533797885691
Epoch: 94 | Iteration number: [2810/4518] 62% | Training loss: 0.6869506313495365
Epoch: 94 | Iteration number: [2820/4518] 62% | Training loss: 0.6869543172577595
Epoch: 94 | Iteration number: [2830/4518] 62% | Training loss: 0.6869482774616551
Epoch: 94 | Iteration number: [2840/4518] 62% | Training loss: 0.686945690865248
Epoch: 94 | Iteration number: [2850/4518] 63% | Training loss: 0.6869467681123499
Epoch: 94 | Iteration number: [2860/4518] 63% | Training loss: 0.6869467404130456
Epoch: 94 | Iteration number: [2870/4518] 63% | Training loss: 0.6869472970738228
Epoch: 94 | Iteration number: [2880/4518] 63% | Training loss: 0.6869497009242574
Epoch: 94 | Iteration number: [2890/4518] 63% | Training loss: 0.6869490699578321
Epoch: 94 | Iteration number: [2900/4518] 64% | Training loss: 0.6869514386818327
Epoch: 94 | Iteration number: [2910/4518] 64% | Training loss: 0.6869520117531936
Epoch: 94 | Iteration number: [2920/4518] 64% | Training loss: 0.686948029941892
Epoch: 94 | Iteration number: [2930/4518] 64% | Training loss: 0.6869470319650279
Epoch: 94 | Iteration number: [2940/4518] 65% | Training loss: 0.6869451354150058
Epoch: 94 | Iteration number: [2950/4518] 65% | Training loss: 0.6869453652834488
Epoch: 94 | Iteration number: [2960/4518] 65% | Training loss: 0.6869452359305845
Epoch: 94 | Iteration number: [2970/4518] 65% | Training loss: 0.6869415458203968
Epoch: 94 | Iteration number: [2980/4518] 65% | Training loss: 0.6869464185213883
Epoch: 94 | Iteration number: [2990/4518] 66% | Training loss: 0.6869436758019055
Epoch: 94 | Iteration number: [3000/4518] 66% | Training loss: 0.6869358755350113
Epoch: 94 | Iteration number: [3010/4518] 66% | Training loss: 0.6869312966186739
Epoch: 94 | Iteration number: [3020/4518] 66% | Training loss: 0.6869274040918476
Epoch: 94 | Iteration number: [3030/4518] 67% | Training loss: 0.686927321208979
Epoch: 94 | Iteration number: [3040/4518] 67% | Training loss: 0.6869271286812267
Epoch: 94 | Iteration number: [3050/4518] 67% | Training loss: 0.6869277200347087
Epoch: 94 | Iteration number: [3060/4518] 67% | Training loss: 0.6869240170600368
Epoch: 94 | Iteration number: [3070/4518] 67% | Training loss: 0.6869222352869736
Epoch: 94 | Iteration number: [3080/4518] 68% | Training loss: 0.6869287805317285
Epoch: 94 | Iteration number: [3090/4518] 68% | Training loss: 0.6869275670028427
Epoch: 94 | Iteration number: [3100/4518] 68% | Training loss: 0.6869249806481023
Epoch: 94 | Iteration number: [3110/4518] 68% | Training loss: 0.6869279285719158
Epoch: 94 | Iteration number: [3120/4518] 69% | Training loss: 0.6869256522793036
Epoch: 94 | Iteration number: [3130/4518] 69% | Training loss: 0.6869280437691905
Epoch: 94 | Iteration number: [3140/4518] 69% | Training loss: 0.6869269100913576
Epoch: 94 | Iteration number: [3150/4518] 69% | Training loss: 0.6869269860547687
Epoch: 94 | Iteration number: [3160/4518] 69% | Training loss: 0.6869260876050478
Epoch: 94 | Iteration number: [3170/4518] 70% | Training loss: 0.6869282158391333
Epoch: 94 | Iteration number: [3180/4518] 70% | Training loss: 0.6869269007406894
Epoch: 94 | Iteration number: [3190/4518] 70% | Training loss: 0.6869277980073493
Epoch: 94 | Iteration number: [3200/4518] 70% | Training loss: 0.686925123911351
Epoch: 94 | Iteration number: [3210/4518] 71% | Training loss: 0.6869215895639402
Epoch: 94 | Iteration number: [3220/4518] 71% | Training loss: 0.6869190623486264
Epoch: 94 | Iteration number: [3230/4518] 71% | Training loss: 0.686919597003482
Epoch: 94 | Iteration number: [3240/4518] 71% | Training loss: 0.6869179651877027
Epoch: 94 | Iteration number: [3250/4518] 71% | Training loss: 0.6869162585551922
Epoch: 94 | Iteration number: [3260/4518] 72% | Training loss: 0.6869167677646766
Epoch: 94 | Iteration number: [3270/4518] 72% | Training loss: 0.686915740853785
Epoch: 94 | Iteration number: [3280/4518] 72% | Training loss: 0.6869113902493221
Epoch: 94 | Iteration number: [3290/4518] 72% | Training loss: 0.6869111977268497
Epoch: 94 | Iteration number: [3300/4518] 73% | Training loss: 0.686907254764528
Epoch: 94 | Iteration number: [3310/4518] 73% | Training loss: 0.6869077877155604
Epoch: 94 | Iteration number: [3320/4518] 73% | Training loss: 0.6869125664952289
Epoch: 94 | Iteration number: [3330/4518] 73% | Training loss: 0.6869128678475056
Epoch: 94 | Iteration number: [3340/4518] 73% | Training loss: 0.6869146890625982
Epoch: 94 | Iteration number: [3350/4518] 74% | Training loss: 0.6869191427551099
Epoch: 94 | Iteration number: [3360/4518] 74% | Training loss: 0.6869199884434541
Epoch: 94 | Iteration number: [3370/4518] 74% | Training loss: 0.6869196683964319
Epoch: 94 | Iteration number: [3380/4518] 74% | Training loss: 0.6869171838259556
Epoch: 94 | Iteration number: [3390/4518] 75% | Training loss: 0.6869169356197031
Epoch: 94 | Iteration number: [3400/4518] 75% | Training loss: 0.6869174562482273
Epoch: 94 | Iteration number: [3410/4518] 75% | Training loss: 0.6869152315026504
Epoch: 94 | Iteration number: [3420/4518] 75% | Training loss: 0.6869166959970318
Epoch: 94 | Iteration number: [3430/4518] 75% | Training loss: 0.686917426947602
Epoch: 94 | Iteration number: [3440/4518] 76% | Training loss: 0.6869187638856644
Epoch: 94 | Iteration number: [3450/4518] 76% | Training loss: 0.6869167895593505
Epoch: 94 | Iteration number: [3460/4518] 76% | Training loss: 0.6869196355515133
Epoch: 94 | Iteration number: [3470/4518] 76% | Training loss: 0.6869161158198925
Epoch: 94 | Iteration number: [3480/4518] 77% | Training loss: 0.6869158661571042
Epoch: 94 | Iteration number: [3490/4518] 77% | Training loss: 0.6869181622577601
Epoch: 94 | Iteration number: [3500/4518] 77% | Training loss: 0.686915784733636
Epoch: 94 | Iteration number: [3510/4518] 77% | Training loss: 0.6869115466745491
Epoch: 94 | Iteration number: [3520/4518] 77% | Training loss: 0.6869118140333078
Epoch: 94 | Iteration number: [3530/4518] 78% | Training loss: 0.6869110190834607
Epoch: 94 | Iteration number: [3540/4518] 78% | Training loss: 0.6869132430708341
Epoch: 94 | Iteration number: [3550/4518] 78% | Training loss: 0.6869147325233674
Epoch: 94 | Iteration number: [3560/4518] 78% | Training loss: 0.6869174455491345
Epoch: 94 | Iteration number: [3570/4518] 79% | Training loss: 0.6869204740898281
Epoch: 94 | Iteration number: [3580/4518] 79% | Training loss: 0.686915477261197
Epoch: 94 | Iteration number: [3590/4518] 79% | Training loss: 0.6869152785509742
Epoch: 94 | Iteration number: [3600/4518] 79% | Training loss: 0.6869160286751058
Epoch: 94 | Iteration number: [3610/4518] 79% | Training loss: 0.6869189404879911
Epoch: 94 | Iteration number: [3620/4518] 80% | Training loss: 0.6869173580111719
Epoch: 94 | Iteration number: [3630/4518] 80% | Training loss: 0.6869156308082182
Epoch: 94 | Iteration number: [3640/4518] 80% | Training loss: 0.6869158156461768
Epoch: 94 | Iteration number: [3650/4518] 80% | Training loss: 0.6869133558175335
Epoch: 94 | Iteration number: [3660/4518] 81% | Training loss: 0.6869135791649584
Epoch: 94 | Iteration number: [3670/4518] 81% | Training loss: 0.6869138971336531
Epoch: 94 | Iteration number: [3680/4518] 81% | Training loss: 0.6869095625112887
Epoch: 94 | Iteration number: [3690/4518] 81% | Training loss: 0.6869109665313711
Epoch: 94 | Iteration number: [3700/4518] 81% | Training loss: 0.6869097906028903
Epoch: 94 | Iteration number: [3710/4518] 82% | Training loss: 0.6869123612774028
Epoch: 94 | Iteration number: [3720/4518] 82% | Training loss: 0.6869161773432968
Epoch: 94 | Iteration number: [3730/4518] 82% | Training loss: 0.6869168458291737
Epoch: 94 | Iteration number: [3740/4518] 82% | Training loss: 0.6869165033580148
Epoch: 94 | Iteration number: [3750/4518] 83% | Training loss: 0.6869142539183298
Epoch: 94 | Iteration number: [3760/4518] 83% | Training loss: 0.6869135037381598
Epoch: 94 | Iteration number: [3770/4518] 83% | Training loss: 0.6869158655325993
Epoch: 94 | Iteration number: [3780/4518] 83% | Training loss: 0.6869172656031513
Epoch: 94 | Iteration number: [3790/4518] 83% | Training loss: 0.686919750921959
Epoch: 94 | Iteration number: [3800/4518] 84% | Training loss: 0.6869213721469829
Epoch: 94 | Iteration number: [3810/4518] 84% | Training loss: 0.6869213154153249
Epoch: 94 | Iteration number: [3820/4518] 84% | Training loss: 0.6869241198632106
Epoch: 94 | Iteration number: [3830/4518] 84% | Training loss: 0.6869238678531299
Epoch: 94 | Iteration number: [3840/4518] 84% | Training loss: 0.6869277191037934
Epoch: 94 | Iteration number: [3850/4518] 85% | Training loss: 0.6869271974904196
Epoch: 94 | Iteration number: [3860/4518] 85% | Training loss: 0.686928736144397
Epoch: 94 | Iteration number: [3870/4518] 85% | Training loss: 0.6869306299113488
Epoch: 94 | Iteration number: [3880/4518] 85% | Training loss: 0.6869273902061059
Epoch: 94 | Iteration number: [3890/4518] 86% | Training loss: 0.6869278433083875
Epoch: 94 | Iteration number: [3900/4518] 86% | Training loss: 0.6869252247382432
Epoch: 94 | Iteration number: [3910/4518] 86% | Training loss: 0.6869289651856093
Epoch: 94 | Iteration number: [3920/4518] 86% | Training loss: 0.6869314707207437
Epoch: 94 | Iteration number: [3930/4518] 86% | Training loss: 0.6869310901516873
Epoch: 94 | Iteration number: [3940/4518] 87% | Training loss: 0.686929740367202
Epoch: 94 | Iteration number: [3950/4518] 87% | Training loss: 0.686930278026605
Epoch: 94 | Iteration number: [3960/4518] 87% | Training loss: 0.6869283049094557
Epoch: 94 | Iteration number: [3970/4518] 87% | Training loss: 0.6869264950680192
Epoch: 94 | Iteration number: [3980/4518] 88% | Training loss: 0.6869266540111609
Epoch: 94 | Iteration number: [3990/4518] 88% | Training loss: 0.6869268973668416
Epoch: 94 | Iteration number: [4000/4518] 88% | Training loss: 0.6869264645427465
Epoch: 94 | Iteration number: [4010/4518] 88% | Training loss: 0.6869279690960102
Epoch: 94 | Iteration number: [4020/4518] 88% | Training loss: 0.6869292734867305
Epoch: 94 | Iteration number: [4030/4518] 89% | Training loss: 0.6869279461226452
Epoch: 94 | Iteration number: [4040/4518] 89% | Training loss: 0.6869286284588351
Epoch: 94 | Iteration number: [4050/4518] 89% | Training loss: 0.6869291098176697
Epoch: 94 | Iteration number: [4060/4518] 89% | Training loss: 0.68692838426294
Epoch: 94 | Iteration number: [4070/4518] 90% | Training loss: 0.6869294895733311
Epoch: 94 | Iteration number: [4080/4518] 90% | Training loss: 0.6869309437771638
Epoch: 94 | Iteration number: [4090/4518] 90% | Training loss: 0.6869319524187913
Epoch: 94 | Iteration number: [4100/4518] 90% | Training loss: 0.6869326868289855
Epoch: 94 | Iteration number: [4110/4518] 90% | Training loss: 0.6869305955812589
Epoch: 94 | Iteration number: [4120/4518] 91% | Training loss: 0.6869316562720873
Epoch: 94 | Iteration number: [4130/4518] 91% | Training loss: 0.6869316375573091
Epoch: 94 | Iteration number: [4140/4518] 91% | Training loss: 0.6869280825922455
Epoch: 94 | Iteration number: [4150/4518] 91% | Training loss: 0.686927209417504
Epoch: 94 | Iteration number: [4160/4518] 92% | Training loss: 0.6869281383804404
Epoch: 94 | Iteration number: [4170/4518] 92% | Training loss: 0.6869302952604043
Epoch: 94 | Iteration number: [4180/4518] 92% | Training loss: 0.686930008439356
Epoch: 94 | Iteration number: [4190/4518] 92% | Training loss: 0.6869306852396462
Epoch: 94 | Iteration number: [4200/4518] 92% | Training loss: 0.6869300228073484
Epoch: 94 | Iteration number: [4210/4518] 93% | Training loss: 0.6869289705985515
Epoch: 94 | Iteration number: [4220/4518] 93% | Training loss: 0.686925869742276
Epoch: 94 | Iteration number: [4230/4518] 93% | Training loss: 0.6869290770509282
Epoch: 94 | Iteration number: [4240/4518] 93% | Training loss: 0.6869269129802595
Epoch: 94 | Iteration number: [4250/4518] 94% | Training loss: 0.6869264243911294
Epoch: 94 | Iteration number: [4260/4518] 94% | Training loss: 0.6869263904895021
Epoch: 94 | Iteration number: [4270/4518] 94% | Training loss: 0.686926281424261
Epoch: 94 | Iteration number: [4280/4518] 94% | Training loss: 0.6869267206604236
Epoch: 94 | Iteration number: [4290/4518] 94% | Training loss: 0.6869259923210232
Epoch: 94 | Iteration number: [4300/4518] 95% | Training loss: 0.6869243778323019
Epoch: 94 | Iteration number: [4310/4518] 95% | Training loss: 0.6869241571481709
Epoch: 94 | Iteration number: [4320/4518] 95% | Training loss: 0.6869219078371922
Epoch: 94 | Iteration number: [4330/4518] 95% | Training loss: 0.6869196611381293
Epoch: 94 | Iteration number: [4340/4518] 96% | Training loss: 0.6869191679399683
Epoch: 94 | Iteration number: [4350/4518] 96% | Training loss: 0.6869184914676623
Epoch: 94 | Iteration number: [4360/4518] 96% | Training loss: 0.686917421290087
Epoch: 94 | Iteration number: [4370/4518] 96% | Training loss: 0.6869188155953344
Epoch: 94 | Iteration number: [4380/4518] 96% | Training loss: 0.6869198126743917
Epoch: 94 | Iteration number: [4390/4518] 97% | Training loss: 0.6869153158811339
Epoch: 94 | Iteration number: [4400/4518] 97% | Training loss: 0.6869134630127387
Epoch: 94 | Iteration number: [4410/4518] 97% | Training loss: 0.6869115576046665
Epoch: 94 | Iteration number: [4420/4518] 97% | Training loss: 0.6869111506917358
Epoch: 94 | Iteration number: [4430/4518] 98% | Training loss: 0.6869108816705493
Epoch: 94 | Iteration number: [4440/4518] 98% | Training loss: 0.6869132315521842
Epoch: 94 | Iteration number: [4450/4518] 98% | Training loss: 0.6869124010975441
Epoch: 94 | Iteration number: [4460/4518] 98% | Training loss: 0.6869139175377619
Epoch: 94 | Iteration number: [4470/4518] 98% | Training loss: 0.6869128641532838
Epoch: 94 | Iteration number: [4480/4518] 99% | Training loss: 0.6869128797735486
Epoch: 94 | Iteration number: [4490/4518] 99% | Training loss: 0.6869119691556705
Epoch: 94 | Iteration number: [4500/4518] 99% | Training loss: 0.6869099913438161
Epoch: 94 | Iteration number: [4510/4518] 99% | Training loss: 0.6869053735569153

 End of epoch: 94 | Train Loss: 0.6867524036373275 | Training Time: 640 

 End of epoch: 94 | Eval Loss: 0.6897335770178814 | Evaluating Time: 17 
Epoch: 95 | Iteration number: [10/4518] 0% | Training loss: 0.7555586695671082
Epoch: 95 | Iteration number: [20/4518] 0% | Training loss: 0.7212353438138962
Epoch: 95 | Iteration number: [30/4518] 0% | Training loss: 0.7098577320575714
Epoch: 95 | Iteration number: [40/4518] 0% | Training loss: 0.7041021257638931
Epoch: 95 | Iteration number: [50/4518] 1% | Training loss: 0.7004674434661865
Epoch: 95 | Iteration number: [60/4518] 1% | Training loss: 0.6982102314631145
Epoch: 95 | Iteration number: [70/4518] 1% | Training loss: 0.6966440379619598
Epoch: 95 | Iteration number: [80/4518] 1% | Training loss: 0.695491012185812
Epoch: 95 | Iteration number: [90/4518] 1% | Training loss: 0.6945597741338941
Epoch: 95 | Iteration number: [100/4518] 2% | Training loss: 0.6938315683603287
Epoch: 95 | Iteration number: [110/4518] 2% | Training loss: 0.6930293370376933
Epoch: 95 | Iteration number: [120/4518] 2% | Training loss: 0.6923861076434453
Epoch: 95 | Iteration number: [130/4518] 2% | Training loss: 0.691967032964413
Epoch: 95 | Iteration number: [140/4518] 3% | Training loss: 0.6915696829557418
Epoch: 95 | Iteration number: [150/4518] 3% | Training loss: 0.6912146751085917
Epoch: 95 | Iteration number: [160/4518] 3% | Training loss: 0.6909428820014
Epoch: 95 | Iteration number: [170/4518] 3% | Training loss: 0.6907042766318602
Epoch: 95 | Iteration number: [180/4518] 3% | Training loss: 0.6904658055967755
Epoch: 95 | Iteration number: [190/4518] 4% | Training loss: 0.6902657540220963
Epoch: 95 | Iteration number: [200/4518] 4% | Training loss: 0.6900388792157173
Epoch: 95 | Iteration number: [210/4518] 4% | Training loss: 0.6899200731799716
Epoch: 95 | Iteration number: [220/4518] 4% | Training loss: 0.6897357173941352
Epoch: 95 | Iteration number: [230/4518] 5% | Training loss: 0.6896396701750548
Epoch: 95 | Iteration number: [240/4518] 5% | Training loss: 0.6894940383732319
Epoch: 95 | Iteration number: [250/4518] 5% | Training loss: 0.6893875257968902
Epoch: 95 | Iteration number: [260/4518] 5% | Training loss: 0.689297526387068
Epoch: 95 | Iteration number: [270/4518] 5% | Training loss: 0.6891680554107383
Epoch: 95 | Iteration number: [280/4518] 6% | Training loss: 0.6890661856957845
Epoch: 95 | Iteration number: [290/4518] 6% | Training loss: 0.6889985454493556
Epoch: 95 | Iteration number: [300/4518] 6% | Training loss: 0.6889233936866125
Epoch: 95 | Iteration number: [310/4518] 6% | Training loss: 0.6888582143091386
Epoch: 95 | Iteration number: [320/4518] 7% | Training loss: 0.6888185990974307
Epoch: 95 | Iteration number: [330/4518] 7% | Training loss: 0.6887570903156743
Epoch: 95 | Iteration number: [340/4518] 7% | Training loss: 0.6887034826418933
Epoch: 95 | Iteration number: [350/4518] 7% | Training loss: 0.6886077269486018
Epoch: 95 | Iteration number: [360/4518] 7% | Training loss: 0.6885508260793156
Epoch: 95 | Iteration number: [370/4518] 8% | Training loss: 0.6885250375077531
Epoch: 95 | Iteration number: [380/4518] 8% | Training loss: 0.6885007086553072
Epoch: 95 | Iteration number: [390/4518] 8% | Training loss: 0.6884805671679668
Epoch: 95 | Iteration number: [400/4518] 8% | Training loss: 0.6884468752145767
Epoch: 95 | Iteration number: [410/4518] 9% | Training loss: 0.6884254509355964
Epoch: 95 | Iteration number: [420/4518] 9% | Training loss: 0.6883759528398514
Epoch: 95 | Iteration number: [430/4518] 9% | Training loss: 0.6883113095926684
Epoch: 95 | Iteration number: [440/4518] 9% | Training loss: 0.688282884657383
Epoch: 95 | Iteration number: [450/4518] 9% | Training loss: 0.6882747096485562
Epoch: 95 | Iteration number: [460/4518] 10% | Training loss: 0.6882404569698417
Epoch: 95 | Iteration number: [470/4518] 10% | Training loss: 0.6882349931179209
Epoch: 95 | Iteration number: [480/4518] 10% | Training loss: 0.6881831133117279
Epoch: 95 | Iteration number: [490/4518] 10% | Training loss: 0.6881514361926487
Epoch: 95 | Iteration number: [500/4518] 11% | Training loss: 0.688115840435028
Epoch: 95 | Iteration number: [510/4518] 11% | Training loss: 0.6880668986077402
Epoch: 95 | Iteration number: [520/4518] 11% | Training loss: 0.6880396297344795
Epoch: 95 | Iteration number: [530/4518] 11% | Training loss: 0.6880091785259966
Epoch: 95 | Iteration number: [540/4518] 11% | Training loss: 0.6879893713527255
Epoch: 95 | Iteration number: [550/4518] 12% | Training loss: 0.6879880445653742
Epoch: 95 | Iteration number: [560/4518] 12% | Training loss: 0.6879524944084031
Epoch: 95 | Iteration number: [570/4518] 12% | Training loss: 0.6879134571343137
Epoch: 95 | Iteration number: [580/4518] 12% | Training loss: 0.68788598734757
Epoch: 95 | Iteration number: [590/4518] 13% | Training loss: 0.6878456545078149
Epoch: 95 | Iteration number: [600/4518] 13% | Training loss: 0.6878313412268956
Epoch: 95 | Iteration number: [610/4518] 13% | Training loss: 0.6878175487283801
Epoch: 95 | Iteration number: [620/4518] 13% | Training loss: 0.6878036988358344
Epoch: 95 | Iteration number: [630/4518] 13% | Training loss: 0.6878105371717422
Epoch: 95 | Iteration number: [640/4518] 14% | Training loss: 0.6878040076233447
Epoch: 95 | Iteration number: [650/4518] 14% | Training loss: 0.6877901832874005
Epoch: 95 | Iteration number: [660/4518] 14% | Training loss: 0.6877914022315632
Epoch: 95 | Iteration number: [670/4518] 14% | Training loss: 0.6877771579507571
Epoch: 95 | Iteration number: [680/4518] 15% | Training loss: 0.6877641312339726
Epoch: 95 | Iteration number: [690/4518] 15% | Training loss: 0.6877732785715573
Epoch: 95 | Iteration number: [700/4518] 15% | Training loss: 0.6877643114328384
Epoch: 95 | Iteration number: [710/4518] 15% | Training loss: 0.6877353890680931
Epoch: 95 | Iteration number: [720/4518] 15% | Training loss: 0.6877285550865863
Epoch: 95 | Iteration number: [730/4518] 16% | Training loss: 0.6877078025308374
Epoch: 95 | Iteration number: [740/4518] 16% | Training loss: 0.6876859677804483
Epoch: 95 | Iteration number: [750/4518] 16% | Training loss: 0.6876776775519053
Epoch: 95 | Iteration number: [760/4518] 16% | Training loss: 0.6876731940790226
Epoch: 95 | Iteration number: [770/4518] 17% | Training loss: 0.6876625236752746
Epoch: 95 | Iteration number: [780/4518] 17% | Training loss: 0.6876440399732345
Epoch: 95 | Iteration number: [790/4518] 17% | Training loss: 0.6876482366761075
Epoch: 95 | Iteration number: [800/4518] 17% | Training loss: 0.6876349657773971
Epoch: 95 | Iteration number: [810/4518] 17% | Training loss: 0.6876303759621986
Epoch: 95 | Iteration number: [820/4518] 18% | Training loss: 0.6876081280592011
Epoch: 95 | Iteration number: [830/4518] 18% | Training loss: 0.6875896387071495
Epoch: 95 | Iteration number: [840/4518] 18% | Training loss: 0.6875812338221641
Epoch: 95 | Iteration number: [850/4518] 18% | Training loss: 0.6875711726441103
Epoch: 95 | Iteration number: [860/4518] 19% | Training loss: 0.6875617614319158
Epoch: 95 | Iteration number: [870/4518] 19% | Training loss: 0.6875551341593951
Epoch: 95 | Iteration number: [880/4518] 19% | Training loss: 0.6875525668263436
Epoch: 95 | Iteration number: [890/4518] 19% | Training loss: 0.6875557565956973
Epoch: 95 | Iteration number: [900/4518] 19% | Training loss: 0.6875410276651382
Epoch: 95 | Iteration number: [910/4518] 20% | Training loss: 0.6875438705905453
Epoch: 95 | Iteration number: [920/4518] 20% | Training loss: 0.6875261564617572
Epoch: 95 | Iteration number: [930/4518] 20% | Training loss: 0.6875194532255973
Epoch: 95 | Iteration number: [940/4518] 20% | Training loss: 0.6875177725832513
Epoch: 95 | Iteration number: [950/4518] 21% | Training loss: 0.687509035813181
Epoch: 95 | Iteration number: [960/4518] 21% | Training loss: 0.6875005998338263
Epoch: 95 | Iteration number: [970/4518] 21% | Training loss: 0.6874885395630119
Epoch: 95 | Iteration number: [980/4518] 21% | Training loss: 0.6874884339011446
Epoch: 95 | Iteration number: [990/4518] 21% | Training loss: 0.6874935135094806
Epoch: 95 | Iteration number: [1000/4518] 22% | Training loss: 0.6874774003624916
Epoch: 95 | Iteration number: [1010/4518] 22% | Training loss: 0.6874751698262621
Epoch: 95 | Iteration number: [1020/4518] 22% | Training loss: 0.6874711990940805
Epoch: 95 | Iteration number: [1030/4518] 22% | Training loss: 0.6874631487050102
Epoch: 95 | Iteration number: [1040/4518] 23% | Training loss: 0.6874634235524214
Epoch: 95 | Iteration number: [1050/4518] 23% | Training loss: 0.6874658616383871
Epoch: 95 | Iteration number: [1060/4518] 23% | Training loss: 0.6874598799449093
Epoch: 95 | Iteration number: [1070/4518] 23% | Training loss: 0.6874501789841696
Epoch: 95 | Iteration number: [1080/4518] 23% | Training loss: 0.6874512899804999
Epoch: 95 | Iteration number: [1090/4518] 24% | Training loss: 0.6874438607364619
Epoch: 95 | Iteration number: [1100/4518] 24% | Training loss: 0.6874370143088427
Epoch: 95 | Iteration number: [1110/4518] 24% | Training loss: 0.687442584993603
Epoch: 95 | Iteration number: [1120/4518] 24% | Training loss: 0.6874440456607512
Epoch: 95 | Iteration number: [1130/4518] 25% | Training loss: 0.6874467045859953
Epoch: 95 | Iteration number: [1140/4518] 25% | Training loss: 0.6874285230511114
Epoch: 95 | Iteration number: [1150/4518] 25% | Training loss: 0.6874244822108228
Epoch: 95 | Iteration number: [1160/4518] 25% | Training loss: 0.6874189705170434
Epoch: 95 | Iteration number: [1170/4518] 25% | Training loss: 0.6874101427885202
Epoch: 95 | Iteration number: [1180/4518] 26% | Training loss: 0.6873941544759071
Epoch: 95 | Iteration number: [1190/4518] 26% | Training loss: 0.6873894579771186
Epoch: 95 | Iteration number: [1200/4518] 26% | Training loss: 0.6873801641662916
Epoch: 95 | Iteration number: [1210/4518] 26% | Training loss: 0.6873682226523881
Epoch: 95 | Iteration number: [1220/4518] 27% | Training loss: 0.6873659309305129
Epoch: 95 | Iteration number: [1230/4518] 27% | Training loss: 0.687366826650573
Epoch: 95 | Iteration number: [1240/4518] 27% | Training loss: 0.6873596256298403
Epoch: 95 | Iteration number: [1250/4518] 27% | Training loss: 0.6873481549263001
Epoch: 95 | Iteration number: [1260/4518] 27% | Training loss: 0.6873429819231942
Epoch: 95 | Iteration number: [1270/4518] 28% | Training loss: 0.6873481225779676
Epoch: 95 | Iteration number: [1280/4518] 28% | Training loss: 0.6873458901420235
Epoch: 95 | Iteration number: [1290/4518] 28% | Training loss: 0.6873440986917925
Epoch: 95 | Iteration number: [1300/4518] 28% | Training loss: 0.6873407193789115
Epoch: 95 | Iteration number: [1310/4518] 28% | Training loss: 0.6873323542926147
Epoch: 95 | Iteration number: [1320/4518] 29% | Training loss: 0.6873385330492799
Epoch: 95 | Iteration number: [1330/4518] 29% | Training loss: 0.6873299687876737
Epoch: 95 | Iteration number: [1340/4518] 29% | Training loss: 0.6873396168449032
Epoch: 95 | Iteration number: [1350/4518] 29% | Training loss: 0.687337128718694
Epoch: 95 | Iteration number: [1360/4518] 30% | Training loss: 0.6873321531450047
Epoch: 95 | Iteration number: [1370/4518] 30% | Training loss: 0.6873269375223313
Epoch: 95 | Iteration number: [1380/4518] 30% | Training loss: 0.6873233015986456
Epoch: 95 | Iteration number: [1390/4518] 30% | Training loss: 0.6873188668875385
Epoch: 95 | Iteration number: [1400/4518] 30% | Training loss: 0.6873080770032747
Epoch: 95 | Iteration number: [1410/4518] 31% | Training loss: 0.687305875323343
Epoch: 95 | Iteration number: [1420/4518] 31% | Training loss: 0.6873100129231601
Epoch: 95 | Iteration number: [1430/4518] 31% | Training loss: 0.6873064466289707
Epoch: 95 | Iteration number: [1440/4518] 31% | Training loss: 0.6873038723650906
Epoch: 95 | Iteration number: [1450/4518] 32% | Training loss: 0.6872961736547536
Epoch: 95 | Iteration number: [1460/4518] 32% | Training loss: 0.6872961911028379
Epoch: 95 | Iteration number: [1470/4518] 32% | Training loss: 0.6872866714892745
Epoch: 95 | Iteration number: [1480/4518] 32% | Training loss: 0.6872853352411373
Epoch: 95 | Iteration number: [1490/4518] 32% | Training loss: 0.6872924521865461
Epoch: 95 | Iteration number: [1500/4518] 33% | Training loss: 0.687286239027977
Epoch: 95 | Iteration number: [1510/4518] 33% | Training loss: 0.687287155247682
Epoch: 95 | Iteration number: [1520/4518] 33% | Training loss: 0.6872853438320913
Epoch: 95 | Iteration number: [1530/4518] 33% | Training loss: 0.6872784868954054
Epoch: 95 | Iteration number: [1540/4518] 34% | Training loss: 0.6872696417492705
Epoch: 95 | Iteration number: [1550/4518] 34% | Training loss: 0.6872615662313277
Epoch: 95 | Iteration number: [1560/4518] 34% | Training loss: 0.6872591363695951
Epoch: 95 | Iteration number: [1570/4518] 34% | Training loss: 0.6872564826421677
Epoch: 95 | Iteration number: [1580/4518] 34% | Training loss: 0.687250408341613
Epoch: 95 | Iteration number: [1590/4518] 35% | Training loss: 0.687254834587469
Epoch: 95 | Iteration number: [1600/4518] 35% | Training loss: 0.6872525380924344
Epoch: 95 | Iteration number: [1610/4518] 35% | Training loss: 0.6872535287963678
Epoch: 95 | Iteration number: [1620/4518] 35% | Training loss: 0.6872492345394912
Epoch: 95 | Iteration number: [1630/4518] 36% | Training loss: 0.6872448159141774
Epoch: 95 | Iteration number: [1640/4518] 36% | Training loss: 0.687241696402794
Epoch: 95 | Iteration number: [1650/4518] 36% | Training loss: 0.6872423786828012
Epoch: 95 | Iteration number: [1660/4518] 36% | Training loss: 0.6872422513832529
Epoch: 95 | Iteration number: [1670/4518] 36% | Training loss: 0.6872386441259327
Epoch: 95 | Iteration number: [1680/4518] 37% | Training loss: 0.6872413499014718
Epoch: 95 | Iteration number: [1690/4518] 37% | Training loss: 0.6872263319393587
Epoch: 95 | Iteration number: [1700/4518] 37% | Training loss: 0.6872266447544098
Epoch: 95 | Iteration number: [1710/4518] 37% | Training loss: 0.6872250833706549
Epoch: 95 | Iteration number: [1720/4518] 38% | Training loss: 0.6872207928882089
Epoch: 95 | Iteration number: [1730/4518] 38% | Training loss: 0.6872155928198312
Epoch: 95 | Iteration number: [1740/4518] 38% | Training loss: 0.6872135118163866
Epoch: 95 | Iteration number: [1750/4518] 38% | Training loss: 0.6872101468358721
Epoch: 95 | Iteration number: [1760/4518] 38% | Training loss: 0.6872138813138008
Epoch: 95 | Iteration number: [1770/4518] 39% | Training loss: 0.6872089134434523
Epoch: 95 | Iteration number: [1780/4518] 39% | Training loss: 0.6872058036956894
Epoch: 95 | Iteration number: [1790/4518] 39% | Training loss: 0.687199431457999
Epoch: 95 | Iteration number: [1800/4518] 39% | Training loss: 0.6871993357274268
Epoch: 95 | Iteration number: [1810/4518] 40% | Training loss: 0.6871994628761354
Epoch: 95 | Iteration number: [1820/4518] 40% | Training loss: 0.6871881144059884
Epoch: 95 | Iteration number: [1830/4518] 40% | Training loss: 0.6871896822595857
Epoch: 95 | Iteration number: [1840/4518] 40% | Training loss: 0.6871842581940734
Epoch: 95 | Iteration number: [1850/4518] 40% | Training loss: 0.6871774782361211
Epoch: 95 | Iteration number: [1860/4518] 41% | Training loss: 0.6871781182865943
Epoch: 95 | Iteration number: [1870/4518] 41% | Training loss: 0.687178513359896
Epoch: 95 | Iteration number: [1880/4518] 41% | Training loss: 0.6871785901962443
Epoch: 95 | Iteration number: [1890/4518] 41% | Training loss: 0.6871734101620931
Epoch: 95 | Iteration number: [1900/4518] 42% | Training loss: 0.6871706463474977
Epoch: 95 | Iteration number: [1910/4518] 42% | Training loss: 0.6871681669307629
Epoch: 95 | Iteration number: [1920/4518] 42% | Training loss: 0.6871631657083829
Epoch: 95 | Iteration number: [1930/4518] 42% | Training loss: 0.6871598638709963
Epoch: 95 | Iteration number: [1940/4518] 42% | Training loss: 0.6871607989687281
Epoch: 95 | Iteration number: [1950/4518] 43% | Training loss: 0.6871569522221883
Epoch: 95 | Iteration number: [1960/4518] 43% | Training loss: 0.6871627878169624
Epoch: 95 | Iteration number: [1970/4518] 43% | Training loss: 0.6871559350018573
Epoch: 95 | Iteration number: [1980/4518] 43% | Training loss: 0.6871528496344884
Epoch: 95 | Iteration number: [1990/4518] 44% | Training loss: 0.687143453102016
Epoch: 95 | Iteration number: [2000/4518] 44% | Training loss: 0.6871409568488598
Epoch: 95 | Iteration number: [2010/4518] 44% | Training loss: 0.6871458156191887
Epoch: 95 | Iteration number: [2020/4518] 44% | Training loss: 0.6871471164840283
Epoch: 95 | Iteration number: [2030/4518] 44% | Training loss: 0.6871499543413153
Epoch: 95 | Iteration number: [2040/4518] 45% | Training loss: 0.6871469183295381
Epoch: 95 | Iteration number: [2050/4518] 45% | Training loss: 0.6871442106002714
Epoch: 95 | Iteration number: [2060/4518] 45% | Training loss: 0.6871405769320368
Epoch: 95 | Iteration number: [2070/4518] 45% | Training loss: 0.6871342093184374
Epoch: 95 | Iteration number: [2080/4518] 46% | Training loss: 0.6871360864776831
Epoch: 95 | Iteration number: [2090/4518] 46% | Training loss: 0.6871329060011503
Epoch: 95 | Iteration number: [2100/4518] 46% | Training loss: 0.6871351532141368
Epoch: 95 | Iteration number: [2110/4518] 46% | Training loss: 0.6871352672011931
Epoch: 95 | Iteration number: [2120/4518] 46% | Training loss: 0.6871338050601618
Epoch: 95 | Iteration number: [2130/4518] 47% | Training loss: 0.6871306457989652
Epoch: 95 | Iteration number: [2140/4518] 47% | Training loss: 0.6871340103517068
Epoch: 95 | Iteration number: [2150/4518] 47% | Training loss: 0.6871318780266962
Epoch: 95 | Iteration number: [2160/4518] 47% | Training loss: 0.6871303277711074
Epoch: 95 | Iteration number: [2170/4518] 48% | Training loss: 0.6871274340811963
Epoch: 95 | Iteration number: [2180/4518] 48% | Training loss: 0.6871217745979992
Epoch: 95 | Iteration number: [2190/4518] 48% | Training loss: 0.6871264055439327
Epoch: 95 | Iteration number: [2200/4518] 48% | Training loss: 0.6871280655806715
Epoch: 95 | Iteration number: [2210/4518] 48% | Training loss: 0.687123515325434
Epoch: 95 | Iteration number: [2220/4518] 49% | Training loss: 0.6871194918950398
Epoch: 95 | Iteration number: [2230/4518] 49% | Training loss: 0.6871179777677818
Epoch: 95 | Iteration number: [2240/4518] 49% | Training loss: 0.6871138901316693
Epoch: 95 | Iteration number: [2250/4518] 49% | Training loss: 0.6871155192322201
Epoch: 95 | Iteration number: [2260/4518] 50% | Training loss: 0.6871180341834515
Epoch: 95 | Iteration number: [2270/4518] 50% | Training loss: 0.6871166822143588
Epoch: 95 | Iteration number: [2280/4518] 50% | Training loss: 0.6871072336769941
Epoch: 95 | Iteration number: [2290/4518] 50% | Training loss: 0.6871056890643841
Epoch: 95 | Iteration number: [2300/4518] 50% | Training loss: 0.6871050873528356
Epoch: 95 | Iteration number: [2310/4518] 51% | Training loss: 0.6871037457154426
Epoch: 95 | Iteration number: [2320/4518] 51% | Training loss: 0.6871016066649864
Epoch: 95 | Iteration number: [2330/4518] 51% | Training loss: 0.6871006772241879
Epoch: 95 | Iteration number: [2340/4518] 51% | Training loss: 0.6870986594094171
Epoch: 95 | Iteration number: [2350/4518] 52% | Training loss: 0.6870959892932405
Epoch: 95 | Iteration number: [2360/4518] 52% | Training loss: 0.6870967473771612
Epoch: 95 | Iteration number: [2370/4518] 52% | Training loss: 0.6870905012772556
Epoch: 95 | Iteration number: [2380/4518] 52% | Training loss: 0.6870915472257038
Epoch: 95 | Iteration number: [2390/4518] 52% | Training loss: 0.6870866163255779
Epoch: 95 | Iteration number: [2400/4518] 53% | Training loss: 0.6870865417520206
Epoch: 95 | Iteration number: [2410/4518] 53% | Training loss: 0.6870852152094307
Epoch: 95 | Iteration number: [2420/4518] 53% | Training loss: 0.6870855377232733
Epoch: 95 | Iteration number: [2430/4518] 53% | Training loss: 0.687083830853058
Epoch: 95 | Iteration number: [2440/4518] 54% | Training loss: 0.6870881290953668
Epoch: 95 | Iteration number: [2450/4518] 54% | Training loss: 0.6870900889075532
Epoch: 95 | Iteration number: [2460/4518] 54% | Training loss: 0.6870875988791628
Epoch: 95 | Iteration number: [2470/4518] 54% | Training loss: 0.6870857727913722
Epoch: 95 | Iteration number: [2480/4518] 54% | Training loss: 0.6870851916891914
Epoch: 95 | Iteration number: [2490/4518] 55% | Training loss: 0.687083989022726
Epoch: 95 | Iteration number: [2500/4518] 55% | Training loss: 0.6870790776729584
Epoch: 95 | Iteration number: [2510/4518] 55% | Training loss: 0.6870790668455253
Epoch: 95 | Iteration number: [2520/4518] 55% | Training loss: 0.6870770658292468
Epoch: 95 | Iteration number: [2530/4518] 55% | Training loss: 0.6870745287111154
Epoch: 95 | Iteration number: [2540/4518] 56% | Training loss: 0.6870757330590346
Epoch: 95 | Iteration number: [2550/4518] 56% | Training loss: 0.6870713939152512
Epoch: 95 | Iteration number: [2560/4518] 56% | Training loss: 0.6870651620673016
Epoch: 95 | Iteration number: [2570/4518] 56% | Training loss: 0.6870616277832001
Epoch: 95 | Iteration number: [2580/4518] 57% | Training loss: 0.687061652240827
Epoch: 95 | Iteration number: [2590/4518] 57% | Training loss: 0.6870652489450447
Epoch: 95 | Iteration number: [2600/4518] 57% | Training loss: 0.6870597096360647
Epoch: 95 | Iteration number: [2610/4518] 57% | Training loss: 0.6870563477848681
Epoch: 95 | Iteration number: [2620/4518] 57% | Training loss: 0.6870546038596684
Epoch: 95 | Iteration number: [2630/4518] 58% | Training loss: 0.6870505012260191
Epoch: 95 | Iteration number: [2640/4518] 58% | Training loss: 0.6870448454988726
Epoch: 95 | Iteration number: [2650/4518] 58% | Training loss: 0.6870396408045067
Epoch: 95 | Iteration number: [2660/4518] 58% | Training loss: 0.6870361869720588
Epoch: 95 | Iteration number: [2670/4518] 59% | Training loss: 0.6870278604468156
Epoch: 95 | Iteration number: [2680/4518] 59% | Training loss: 0.6870233151450086
Epoch: 95 | Iteration number: [2690/4518] 59% | Training loss: 0.6870192542838341
Epoch: 95 | Iteration number: [2700/4518] 59% | Training loss: 0.6870140350306475
Epoch: 95 | Iteration number: [2710/4518] 59% | Training loss: 0.6870140345334127
Epoch: 95 | Iteration number: [2720/4518] 60% | Training loss: 0.6870146320804077
Epoch: 95 | Iteration number: [2730/4518] 60% | Training loss: 0.6870082327297755
Epoch: 95 | Iteration number: [2740/4518] 60% | Training loss: 0.687007907968368
Epoch: 95 | Iteration number: [2750/4518] 60% | Training loss: 0.6870066745931452
Epoch: 95 | Iteration number: [2760/4518] 61% | Training loss: 0.6870080034154049
Epoch: 95 | Iteration number: [2770/4518] 61% | Training loss: 0.6870048989672953
Epoch: 95 | Iteration number: [2780/4518] 61% | Training loss: 0.6870074776865596
Epoch: 95 | Iteration number: [2790/4518] 61% | Training loss: 0.6870064297670959
Epoch: 95 | Iteration number: [2800/4518] 61% | Training loss: 0.6870073547746454
Epoch: 95 | Iteration number: [2810/4518] 62% | Training loss: 0.6870012504138132
Epoch: 95 | Iteration number: [2820/4518] 62% | Training loss: 0.6869951999779289
Epoch: 95 | Iteration number: [2830/4518] 62% | Training loss: 0.6869952866340273
Epoch: 95 | Iteration number: [2840/4518] 62% | Training loss: 0.6869936432007333
Epoch: 95 | Iteration number: [2850/4518] 63% | Training loss: 0.6869974342563696
Epoch: 95 | Iteration number: [2860/4518] 63% | Training loss: 0.6869969183540011
Epoch: 95 | Iteration number: [2870/4518] 63% | Training loss: 0.6869949442792022
Epoch: 95 | Iteration number: [2880/4518] 63% | Training loss: 0.6869936507402195
Epoch: 95 | Iteration number: [2890/4518] 63% | Training loss: 0.6869900765922243
Epoch: 95 | Iteration number: [2900/4518] 64% | Training loss: 0.686984341658395
Epoch: 95 | Iteration number: [2910/4518] 64% | Training loss: 0.6869850014493227
Epoch: 95 | Iteration number: [2920/4518] 64% | Training loss: 0.6869857500677239
Epoch: 95 | Iteration number: [2930/4518] 64% | Training loss: 0.68698859216817
Epoch: 95 | Iteration number: [2940/4518] 65% | Training loss: 0.6869830051855165
Epoch: 95 | Iteration number: [2950/4518] 65% | Training loss: 0.6869800157062078
Epoch: 95 | Iteration number: [2960/4518] 65% | Training loss: 0.686979806101
Epoch: 95 | Iteration number: [2970/4518] 65% | Training loss: 0.6869811574015955
Epoch: 95 | Iteration number: [2980/4518] 65% | Training loss: 0.6869780116633281
Epoch: 95 | Iteration number: [2990/4518] 66% | Training loss: 0.6869781504307304
Epoch: 95 | Iteration number: [3000/4518] 66% | Training loss: 0.6869779134392738
Epoch: 95 | Iteration number: [3010/4518] 66% | Training loss: 0.6869789334230645
Epoch: 95 | Iteration number: [3020/4518] 66% | Training loss: 0.6869781672559827
Epoch: 95 | Iteration number: [3030/4518] 67% | Training loss: 0.6869798340616446
Epoch: 95 | Iteration number: [3040/4518] 67% | Training loss: 0.6869749567422427
Epoch: 95 | Iteration number: [3050/4518] 67% | Training loss: 0.6869765033291989
Epoch: 95 | Iteration number: [3060/4518] 67% | Training loss: 0.6869745664542017
Epoch: 95 | Iteration number: [3070/4518] 67% | Training loss: 0.6869742552504089
Epoch: 95 | Iteration number: [3080/4518] 68% | Training loss: 0.6869782898720209
Epoch: 95 | Iteration number: [3090/4518] 68% | Training loss: 0.6869746178099253
Epoch: 95 | Iteration number: [3100/4518] 68% | Training loss: 0.6869728564446972
Epoch: 95 | Iteration number: [3110/4518] 68% | Training loss: 0.6869749841391082
Epoch: 95 | Iteration number: [3120/4518] 69% | Training loss: 0.6869729032692237
Epoch: 95 | Iteration number: [3130/4518] 69% | Training loss: 0.686975135723242
Epoch: 95 | Iteration number: [3140/4518] 69% | Training loss: 0.6869746883204029
Epoch: 95 | Iteration number: [3150/4518] 69% | Training loss: 0.6869734722470481
Epoch: 95 | Iteration number: [3160/4518] 69% | Training loss: 0.6869754523038865
Epoch: 95 | Iteration number: [3170/4518] 70% | Training loss: 0.6869763655429383
Epoch: 95 | Iteration number: [3180/4518] 70% | Training loss: 0.6869751628464873
Epoch: 95 | Iteration number: [3190/4518] 70% | Training loss: 0.686972830848634
Epoch: 95 | Iteration number: [3200/4518] 70% | Training loss: 0.6869699565321207
Epoch: 95 | Iteration number: [3210/4518] 71% | Training loss: 0.6869688852925167
Epoch: 95 | Iteration number: [3220/4518] 71% | Training loss: 0.6869666225976826
Epoch: 95 | Iteration number: [3230/4518] 71% | Training loss: 0.6869672688721873
Epoch: 95 | Iteration number: [3240/4518] 71% | Training loss: 0.6869644676645597
Epoch: 95 | Iteration number: [3250/4518] 71% | Training loss: 0.6869695580005646
Epoch: 95 | Iteration number: [3260/4518] 72% | Training loss: 0.686966777615752
Epoch: 95 | Iteration number: [3270/4518] 72% | Training loss: 0.686968280817026
Epoch: 95 | Iteration number: [3280/4518] 72% | Training loss: 0.6869714294083235
Epoch: 95 | Iteration number: [3290/4518] 72% | Training loss: 0.6869735367935842
Epoch: 95 | Iteration number: [3300/4518] 73% | Training loss: 0.6869718710039601
Epoch: 95 | Iteration number: [3310/4518] 73% | Training loss: 0.6869698041515407
Epoch: 95 | Iteration number: [3320/4518] 73% | Training loss: 0.6869684798171721
Epoch: 95 | Iteration number: [3330/4518] 73% | Training loss: 0.6869640955337891
Epoch: 95 | Iteration number: [3340/4518] 73% | Training loss: 0.6869633403723825
Epoch: 95 | Iteration number: [3350/4518] 74% | Training loss: 0.6869612161081229
Epoch: 95 | Iteration number: [3360/4518] 74% | Training loss: 0.6869651481331814
Epoch: 95 | Iteration number: [3370/4518] 74% | Training loss: 0.6869609929510677
Epoch: 95 | Iteration number: [3380/4518] 74% | Training loss: 0.6869636541287575
Epoch: 95 | Iteration number: [3390/4518] 75% | Training loss: 0.6869644184555628
Epoch: 95 | Iteration number: [3400/4518] 75% | Training loss: 0.6869662061333657
Epoch: 95 | Iteration number: [3410/4518] 75% | Training loss: 0.6869685395721816
Epoch: 95 | Iteration number: [3420/4518] 75% | Training loss: 0.686966523388673
Epoch: 95 | Iteration number: [3430/4518] 75% | Training loss: 0.6869677098951257
Epoch: 95 | Iteration number: [3440/4518] 76% | Training loss: 0.6869665568131347
Epoch: 95 | Iteration number: [3450/4518] 76% | Training loss: 0.6869650613916093
Epoch: 95 | Iteration number: [3460/4518] 76% | Training loss: 0.6869601848842092
Epoch: 95 | Iteration number: [3470/4518] 76% | Training loss: 0.6869592931497337
Epoch: 95 | Iteration number: [3480/4518] 77% | Training loss: 0.6869606084179605
Epoch: 95 | Iteration number: [3490/4518] 77% | Training loss: 0.68696245725312
Epoch: 95 | Iteration number: [3500/4518] 77% | Training loss: 0.686962475504194
Epoch: 95 | Iteration number: [3510/4518] 77% | Training loss: 0.6869567867527661
Epoch: 95 | Iteration number: [3520/4518] 77% | Training loss: 0.6869590874761343
Epoch: 95 | Iteration number: [3530/4518] 78% | Training loss: 0.686958669518614
Epoch: 95 | Iteration number: [3540/4518] 78% | Training loss: 0.6869581079584057
Epoch: 95 | Iteration number: [3550/4518] 78% | Training loss: 0.6869594407081604
Epoch: 95 | Iteration number: [3560/4518] 78% | Training loss: 0.6869553956422912
Epoch: 95 | Iteration number: [3570/4518] 79% | Training loss: 0.686960977933654
Epoch: 95 | Iteration number: [3580/4518] 79% | Training loss: 0.6869599327694771
Epoch: 95 | Iteration number: [3590/4518] 79% | Training loss: 0.6869606940859208
Epoch: 95 | Iteration number: [3600/4518] 79% | Training loss: 0.6869595007267263
Epoch: 95 | Iteration number: [3610/4518] 79% | Training loss: 0.6869567353144247
Epoch: 95 | Iteration number: [3620/4518] 80% | Training loss: 0.6869571247482826
Epoch: 95 | Iteration number: [3630/4518] 80% | Training loss: 0.6869511820068044
Epoch: 95 | Iteration number: [3640/4518] 80% | Training loss: 0.6869512755464722
Epoch: 95 | Iteration number: [3650/4518] 80% | Training loss: 0.6869488060147795
Epoch: 95 | Iteration number: [3660/4518] 81% | Training loss: 0.6869483943031134
Epoch: 95 | Iteration number: [3670/4518] 81% | Training loss: 0.6869490259187423
Epoch: 95 | Iteration number: [3680/4518] 81% | Training loss: 0.686951089763771
Epoch: 95 | Iteration number: [3690/4518] 81% | Training loss: 0.6869485878847479
Epoch: 95 | Iteration number: [3700/4518] 81% | Training loss: 0.6869527821283082
Epoch: 95 | Iteration number: [3710/4518] 82% | Training loss: 0.6869511106907518
Epoch: 95 | Iteration number: [3720/4518] 82% | Training loss: 0.6869491589005275
Epoch: 95 | Iteration number: [3730/4518] 82% | Training loss: 0.6869490932363608
Epoch: 95 | Iteration number: [3740/4518] 82% | Training loss: 0.686942988968788
Epoch: 95 | Iteration number: [3750/4518] 83% | Training loss: 0.6869413998285929
Epoch: 95 | Iteration number: [3760/4518] 83% | Training loss: 0.6869400934811603
Epoch: 95 | Iteration number: [3770/4518] 83% | Training loss: 0.6869409792777398
Epoch: 95 | Iteration number: [3780/4518] 83% | Training loss: 0.6869387854501684
Epoch: 95 | Iteration number: [3790/4518] 83% | Training loss: 0.6869378666607245
Epoch: 95 | Iteration number: [3800/4518] 84% | Training loss: 0.6869366144506555
Epoch: 95 | Iteration number: [3810/4518] 84% | Training loss: 0.6869339347824337
Epoch: 95 | Iteration number: [3820/4518] 84% | Training loss: 0.6869323050476493
Epoch: 95 | Iteration number: [3830/4518] 84% | Training loss: 0.6869301705229687
Epoch: 95 | Iteration number: [3840/4518] 84% | Training loss: 0.6869297652505338
Epoch: 95 | Iteration number: [3850/4518] 85% | Training loss: 0.6869296712070316
Epoch: 95 | Iteration number: [3860/4518] 85% | Training loss: 0.6869299567116357
Epoch: 95 | Iteration number: [3870/4518] 85% | Training loss: 0.686928621173213
Epoch: 95 | Iteration number: [3880/4518] 85% | Training loss: 0.6869267229259629
Epoch: 95 | Iteration number: [3890/4518] 86% | Training loss: 0.6869253408020137
Epoch: 95 | Iteration number: [3900/4518] 86% | Training loss: 0.6869259109558203
Epoch: 95 | Iteration number: [3910/4518] 86% | Training loss: 0.6869275603757795
Epoch: 95 | Iteration number: [3920/4518] 86% | Training loss: 0.6869254207428621
Epoch: 95 | Iteration number: [3930/4518] 86% | Training loss: 0.6869224679379062
Epoch: 95 | Iteration number: [3940/4518] 87% | Training loss: 0.6869210824294744
Epoch: 95 | Iteration number: [3950/4518] 87% | Training loss: 0.6869243737866607
Epoch: 95 | Iteration number: [3960/4518] 87% | Training loss: 0.6869198087489966
Epoch: 95 | Iteration number: [3970/4518] 87% | Training loss: 0.6869205075937794
Epoch: 95 | Iteration number: [3980/4518] 88% | Training loss: 0.6869190185064047
Epoch: 95 | Iteration number: [3990/4518] 88% | Training loss: 0.686921430067311
Epoch: 95 | Iteration number: [4000/4518] 88% | Training loss: 0.6869190911054611
Epoch: 95 | Iteration number: [4010/4518] 88% | Training loss: 0.6869173611340083
Epoch: 95 | Iteration number: [4020/4518] 88% | Training loss: 0.6869207228594159
Epoch: 95 | Iteration number: [4030/4518] 89% | Training loss: 0.6869170039670344
Epoch: 95 | Iteration number: [4040/4518] 89% | Training loss: 0.6869203058947431
Epoch: 95 | Iteration number: [4050/4518] 89% | Training loss: 0.6869185115967268
Epoch: 95 | Iteration number: [4060/4518] 89% | Training loss: 0.6869170814018531
Epoch: 95 | Iteration number: [4070/4518] 90% | Training loss: 0.6869147591274553
Epoch: 95 | Iteration number: [4080/4518] 90% | Training loss: 0.6869129252053944
Epoch: 95 | Iteration number: [4090/4518] 90% | Training loss: 0.6869160017495051
Epoch: 95 | Iteration number: [4100/4518] 90% | Training loss: 0.6869162540319489
Epoch: 95 | Iteration number: [4110/4518] 90% | Training loss: 0.6869164036428261
Epoch: 95 | Iteration number: [4120/4518] 91% | Training loss: 0.6869149710512855
Epoch: 95 | Iteration number: [4130/4518] 91% | Training loss: 0.6869124208610803
Epoch: 95 | Iteration number: [4140/4518] 91% | Training loss: 0.686911654918666
Epoch: 95 | Iteration number: [4150/4518] 91% | Training loss: 0.6869119918777282
Epoch: 95 | Iteration number: [4160/4518] 92% | Training loss: 0.6869125511353978
Epoch: 95 | Iteration number: [4170/4518] 92% | Training loss: 0.6869128955925683
Epoch: 95 | Iteration number: [4180/4518] 92% | Training loss: 0.6869157689610167
Epoch: 95 | Iteration number: [4190/4518] 92% | Training loss: 0.6869154560110734
Epoch: 95 | Iteration number: [4200/4518] 92% | Training loss: 0.6869146935712723
Epoch: 95 | Iteration number: [4210/4518] 93% | Training loss: 0.6869149997653418
Epoch: 95 | Iteration number: [4220/4518] 93% | Training loss: 0.6869169059522909
Epoch: 95 | Iteration number: [4230/4518] 93% | Training loss: 0.6869133892493327
Epoch: 95 | Iteration number: [4240/4518] 93% | Training loss: 0.6869115689593666
Epoch: 95 | Iteration number: [4250/4518] 94% | Training loss: 0.6869112964377684
Epoch: 95 | Iteration number: [4260/4518] 94% | Training loss: 0.6869109317310539
Epoch: 95 | Iteration number: [4270/4518] 94% | Training loss: 0.6869130720578536
Epoch: 95 | Iteration number: [4280/4518] 94% | Training loss: 0.6869154694620694
Epoch: 95 | Iteration number: [4290/4518] 94% | Training loss: 0.6869174789437603
Epoch: 95 | Iteration number: [4300/4518] 95% | Training loss: 0.6869163565164389
Epoch: 95 | Iteration number: [4310/4518] 95% | Training loss: 0.6869123954922307
Epoch: 95 | Iteration number: [4320/4518] 95% | Training loss: 0.6869138185624724
Epoch: 95 | Iteration number: [4330/4518] 95% | Training loss: 0.686914093513687
Epoch: 95 | Iteration number: [4340/4518] 96% | Training loss: 0.6869131687736731
Epoch: 95 | Iteration number: [4350/4518] 96% | Training loss: 0.6869127754507394
Epoch: 95 | Iteration number: [4360/4518] 96% | Training loss: 0.6869128503383847
Epoch: 95 | Iteration number: [4370/4518] 96% | Training loss: 0.6869152818855486
Epoch: 95 | Iteration number: [4380/4518] 96% | Training loss: 0.6869168200993647
Epoch: 95 | Iteration number: [4390/4518] 97% | Training loss: 0.686915835201876
Epoch: 95 | Iteration number: [4400/4518] 97% | Training loss: 0.6869158779897473
Epoch: 95 | Iteration number: [4410/4518] 97% | Training loss: 0.6869154369614833
Epoch: 95 | Iteration number: [4420/4518] 97% | Training loss: 0.6869141724584329
Epoch: 95 | Iteration number: [4430/4518] 98% | Training loss: 0.6869120186392395
Epoch: 95 | Iteration number: [4440/4518] 98% | Training loss: 0.6869125125778688
Epoch: 95 | Iteration number: [4450/4518] 98% | Training loss: 0.686912889226099
Epoch: 95 | Iteration number: [4460/4518] 98% | Training loss: 0.6869117175116133
Epoch: 95 | Iteration number: [4470/4518] 98% | Training loss: 0.6869115316761153
Epoch: 95 | Iteration number: [4480/4518] 99% | Training loss: 0.6869097234681248
Epoch: 95 | Iteration number: [4490/4518] 99% | Training loss: 0.6869105901378301
Epoch: 95 | Iteration number: [4500/4518] 99% | Training loss: 0.6869051467577616
Epoch: 95 | Iteration number: [4510/4518] 99% | Training loss: 0.6869050826571733

 End of epoch: 95 | Train Loss: 0.6867538614577031 | Training Time: 639 

 End of epoch: 95 | Eval Loss: 0.6898493499171977 | Evaluating Time: 17 
Epoch: 96 | Iteration number: [10/4518] 0% | Training loss: 0.7552365243434906
Epoch: 96 | Iteration number: [20/4518] 0% | Training loss: 0.7207230597734451
Epoch: 96 | Iteration number: [30/4518] 0% | Training loss: 0.7093766212463379
Epoch: 96 | Iteration number: [40/4518] 0% | Training loss: 0.7038267031311989
Epoch: 96 | Iteration number: [50/4518] 1% | Training loss: 0.7005322325229645
Epoch: 96 | Iteration number: [60/4518] 1% | Training loss: 0.6983939558267593
Epoch: 96 | Iteration number: [70/4518] 1% | Training loss: 0.6966605791023799
Epoch: 96 | Iteration number: [80/4518] 1% | Training loss: 0.6953436769545078
Epoch: 96 | Iteration number: [90/4518] 1% | Training loss: 0.6941660589641995
Epoch: 96 | Iteration number: [100/4518] 2% | Training loss: 0.6934546840190887
Epoch: 96 | Iteration number: [110/4518] 2% | Training loss: 0.6929333231665872
Epoch: 96 | Iteration number: [120/4518] 2% | Training loss: 0.6924378131826718
Epoch: 96 | Iteration number: [130/4518] 2% | Training loss: 0.6920291355023017
Epoch: 96 | Iteration number: [140/4518] 3% | Training loss: 0.6917328766414097
Epoch: 96 | Iteration number: [150/4518] 3% | Training loss: 0.6913072522481283
Epoch: 96 | Iteration number: [160/4518] 3% | Training loss: 0.6910862755030394
Epoch: 96 | Iteration number: [170/4518] 3% | Training loss: 0.6908286350614884
Epoch: 96 | Iteration number: [180/4518] 3% | Training loss: 0.6905975580215454
Epoch: 96 | Iteration number: [190/4518] 4% | Training loss: 0.6904060526898033
Epoch: 96 | Iteration number: [200/4518] 4% | Training loss: 0.6901452809572219
Epoch: 96 | Iteration number: [210/4518] 4% | Training loss: 0.6899757728690192
Epoch: 96 | Iteration number: [220/4518] 4% | Training loss: 0.6898633471944116
Epoch: 96 | Iteration number: [230/4518] 5% | Training loss: 0.6897663487040478
Epoch: 96 | Iteration number: [240/4518] 5% | Training loss: 0.689562538266182
Epoch: 96 | Iteration number: [250/4518] 5% | Training loss: 0.6894265127182007
Epoch: 96 | Iteration number: [260/4518] 5% | Training loss: 0.6893197836784216
Epoch: 96 | Iteration number: [270/4518] 5% | Training loss: 0.689254018553981
Epoch: 96 | Iteration number: [280/4518] 6% | Training loss: 0.6891696212547166
Epoch: 96 | Iteration number: [290/4518] 6% | Training loss: 0.6890705205243209
Epoch: 96 | Iteration number: [300/4518] 6% | Training loss: 0.6889868684609731
Epoch: 96 | Iteration number: [310/4518] 6% | Training loss: 0.6889200643185647
Epoch: 96 | Iteration number: [320/4518] 7% | Training loss: 0.6888101287186146
Epoch: 96 | Iteration number: [330/4518] 7% | Training loss: 0.6887651176163645
Epoch: 96 | Iteration number: [340/4518] 7% | Training loss: 0.6887299083611544
Epoch: 96 | Iteration number: [350/4518] 7% | Training loss: 0.688689945425306
Epoch: 96 | Iteration number: [360/4518] 7% | Training loss: 0.6886620975202984
Epoch: 96 | Iteration number: [370/4518] 8% | Training loss: 0.6886338224282136
Epoch: 96 | Iteration number: [380/4518] 8% | Training loss: 0.6886017655071459
Epoch: 96 | Iteration number: [390/4518] 8% | Training loss: 0.6885673897388654
Epoch: 96 | Iteration number: [400/4518] 8% | Training loss: 0.6885517683625221
Epoch: 96 | Iteration number: [410/4518] 9% | Training loss: 0.688509969595002
Epoch: 96 | Iteration number: [420/4518] 9% | Training loss: 0.6884663911092849
Epoch: 96 | Iteration number: [430/4518] 9% | Training loss: 0.6884508128776107
Epoch: 96 | Iteration number: [440/4518] 9% | Training loss: 0.688398002223535
Epoch: 96 | Iteration number: [450/4518] 9% | Training loss: 0.6883682820532057
Epoch: 96 | Iteration number: [460/4518] 10% | Training loss: 0.6883174387009248
Epoch: 96 | Iteration number: [470/4518] 10% | Training loss: 0.6882429119120252
Epoch: 96 | Iteration number: [480/4518] 10% | Training loss: 0.6881906331827243
Epoch: 96 | Iteration number: [490/4518] 10% | Training loss: 0.6881474436545859
Epoch: 96 | Iteration number: [500/4518] 11% | Training loss: 0.6881332265138627
Epoch: 96 | Iteration number: [510/4518] 11% | Training loss: 0.6881170317238452
Epoch: 96 | Iteration number: [520/4518] 11% | Training loss: 0.6881111650512769
Epoch: 96 | Iteration number: [530/4518] 11% | Training loss: 0.6880703820372528
Epoch: 96 | Iteration number: [540/4518] 11% | Training loss: 0.6880643408607554
Epoch: 96 | Iteration number: [550/4518] 12% | Training loss: 0.6880303434892134
Epoch: 96 | Iteration number: [560/4518] 12% | Training loss: 0.688000513613224
Epoch: 96 | Iteration number: [570/4518] 12% | Training loss: 0.6879616453982236
Epoch: 96 | Iteration number: [580/4518] 12% | Training loss: 0.6879464737300215
Epoch: 96 | Iteration number: [590/4518] 13% | Training loss: 0.6879504558393511
Epoch: 96 | Iteration number: [600/4518] 13% | Training loss: 0.6879233020544052
Epoch: 96 | Iteration number: [610/4518] 13% | Training loss: 0.6879167701377243
Epoch: 96 | Iteration number: [620/4518] 13% | Training loss: 0.6879042988823306
Epoch: 96 | Iteration number: [630/4518] 13% | Training loss: 0.6879035613839588
Epoch: 96 | Iteration number: [640/4518] 14% | Training loss: 0.6878550630062819
Epoch: 96 | Iteration number: [650/4518] 14% | Training loss: 0.6878197754346408
Epoch: 96 | Iteration number: [660/4518] 14% | Training loss: 0.6878029467481556
Epoch: 96 | Iteration number: [670/4518] 14% | Training loss: 0.6877825060887123
Epoch: 96 | Iteration number: [680/4518] 15% | Training loss: 0.6877595894476947
Epoch: 96 | Iteration number: [690/4518] 15% | Training loss: 0.6877595015194105
Epoch: 96 | Iteration number: [700/4518] 15% | Training loss: 0.6877368179389408
Epoch: 96 | Iteration number: [710/4518] 15% | Training loss: 0.6877149422403792
Epoch: 96 | Iteration number: [720/4518] 15% | Training loss: 0.6877115978135003
Epoch: 96 | Iteration number: [730/4518] 16% | Training loss: 0.6877055880141585
Epoch: 96 | Iteration number: [740/4518] 16% | Training loss: 0.6876741921579516
Epoch: 96 | Iteration number: [750/4518] 16% | Training loss: 0.6876625556151073
Epoch: 96 | Iteration number: [760/4518] 16% | Training loss: 0.6876545882538745
Epoch: 96 | Iteration number: [770/4518] 17% | Training loss: 0.6876397704149222
Epoch: 96 | Iteration number: [780/4518] 17% | Training loss: 0.6876201270482479
Epoch: 96 | Iteration number: [790/4518] 17% | Training loss: 0.6876076010963584
Epoch: 96 | Iteration number: [800/4518] 17% | Training loss: 0.6876158726960421
Epoch: 96 | Iteration number: [810/4518] 17% | Training loss: 0.6875883597650646
Epoch: 96 | Iteration number: [820/4518] 18% | Training loss: 0.6875794859194174
Epoch: 96 | Iteration number: [830/4518] 18% | Training loss: 0.6875554665025458
Epoch: 96 | Iteration number: [840/4518] 18% | Training loss: 0.6875401170480819
Epoch: 96 | Iteration number: [850/4518] 18% | Training loss: 0.6875369292147019
Epoch: 96 | Iteration number: [860/4518] 19% | Training loss: 0.6875272563030553
Epoch: 96 | Iteration number: [870/4518] 19% | Training loss: 0.6875122714316708
Epoch: 96 | Iteration number: [880/4518] 19% | Training loss: 0.6875033062290061
Epoch: 96 | Iteration number: [890/4518] 19% | Training loss: 0.6875081703234255
Epoch: 96 | Iteration number: [900/4518] 19% | Training loss: 0.6875027651256985
Epoch: 96 | Iteration number: [910/4518] 20% | Training loss: 0.687493942137603
Epoch: 96 | Iteration number: [920/4518] 20% | Training loss: 0.6874743554903113
Epoch: 96 | Iteration number: [930/4518] 20% | Training loss: 0.6874706679133958
Epoch: 96 | Iteration number: [940/4518] 20% | Training loss: 0.6874570930257756
Epoch: 96 | Iteration number: [950/4518] 21% | Training loss: 0.687437341966127
Epoch: 96 | Iteration number: [960/4518] 21% | Training loss: 0.6874307161817949
Epoch: 96 | Iteration number: [970/4518] 21% | Training loss: 0.6874392395781488
Epoch: 96 | Iteration number: [980/4518] 21% | Training loss: 0.687417821981469
Epoch: 96 | Iteration number: [990/4518] 21% | Training loss: 0.6874150517612997
Epoch: 96 | Iteration number: [1000/4518] 22% | Training loss: 0.6874166897535324
Epoch: 96 | Iteration number: [1010/4518] 22% | Training loss: 0.6874178387150907
Epoch: 96 | Iteration number: [1020/4518] 22% | Training loss: 0.6874229876434101
Epoch: 96 | Iteration number: [1030/4518] 22% | Training loss: 0.6874229519112596
Epoch: 96 | Iteration number: [1040/4518] 23% | Training loss: 0.68742224121323
Epoch: 96 | Iteration number: [1050/4518] 23% | Training loss: 0.6874207710652124
Epoch: 96 | Iteration number: [1060/4518] 23% | Training loss: 0.6874060778685336
Epoch: 96 | Iteration number: [1070/4518] 23% | Training loss: 0.6874057722982959
Epoch: 96 | Iteration number: [1080/4518] 23% | Training loss: 0.6874006546757839
Epoch: 96 | Iteration number: [1090/4518] 24% | Training loss: 0.6873904016586618
Epoch: 96 | Iteration number: [1100/4518] 24% | Training loss: 0.6873864646933295
Epoch: 96 | Iteration number: [1110/4518] 24% | Training loss: 0.6873812431150729
Epoch: 96 | Iteration number: [1120/4518] 24% | Training loss: 0.6873825971569334
Epoch: 96 | Iteration number: [1130/4518] 25% | Training loss: 0.6873706523823527
Epoch: 96 | Iteration number: [1140/4518] 25% | Training loss: 0.6873634968410458
Epoch: 96 | Iteration number: [1150/4518] 25% | Training loss: 0.6873683908193008
Epoch: 96 | Iteration number: [1160/4518] 25% | Training loss: 0.6873799894904268
Epoch: 96 | Iteration number: [1170/4518] 25% | Training loss: 0.6873848531490717
Epoch: 96 | Iteration number: [1180/4518] 26% | Training loss: 0.6873744654453406
Epoch: 96 | Iteration number: [1190/4518] 26% | Training loss: 0.6873656419144959
Epoch: 96 | Iteration number: [1200/4518] 26% | Training loss: 0.6873644195993741
Epoch: 96 | Iteration number: [1210/4518] 26% | Training loss: 0.6873479530338413
Epoch: 96 | Iteration number: [1220/4518] 27% | Training loss: 0.6873391406457933
Epoch: 96 | Iteration number: [1230/4518] 27% | Training loss: 0.6873328731796606
Epoch: 96 | Iteration number: [1240/4518] 27% | Training loss: 0.6873289334197198
Epoch: 96 | Iteration number: [1250/4518] 27% | Training loss: 0.6873280181884766
Epoch: 96 | Iteration number: [1260/4518] 27% | Training loss: 0.6873220731341649
Epoch: 96 | Iteration number: [1270/4518] 28% | Training loss: 0.6873111439971473
Epoch: 96 | Iteration number: [1280/4518] 28% | Training loss: 0.6873089380096644
Epoch: 96 | Iteration number: [1290/4518] 28% | Training loss: 0.6873101519983869
Epoch: 96 | Iteration number: [1300/4518] 28% | Training loss: 0.687310185432434
Epoch: 96 | Iteration number: [1310/4518] 28% | Training loss: 0.6873077415327989
Epoch: 96 | Iteration number: [1320/4518] 29% | Training loss: 0.6873048251325434
Epoch: 96 | Iteration number: [1330/4518] 29% | Training loss: 0.6873083046056274
Epoch: 96 | Iteration number: [1340/4518] 29% | Training loss: 0.6873048642233236
Epoch: 96 | Iteration number: [1350/4518] 29% | Training loss: 0.6873000665947243
Epoch: 96 | Iteration number: [1360/4518] 30% | Training loss: 0.6872929916224059
Epoch: 96 | Iteration number: [1370/4518] 30% | Training loss: 0.6872940653867095
Epoch: 96 | Iteration number: [1380/4518] 30% | Training loss: 0.6872919933519501
Epoch: 96 | Iteration number: [1390/4518] 30% | Training loss: 0.6872878431845054
Epoch: 96 | Iteration number: [1400/4518] 30% | Training loss: 0.6872851011582783
Epoch: 96 | Iteration number: [1410/4518] 31% | Training loss: 0.6872827753107599
Epoch: 96 | Iteration number: [1420/4518] 31% | Training loss: 0.6872772668029221
Epoch: 96 | Iteration number: [1430/4518] 31% | Training loss: 0.6872692015204396
Epoch: 96 | Iteration number: [1440/4518] 31% | Training loss: 0.6872629783219761
Epoch: 96 | Iteration number: [1450/4518] 32% | Training loss: 0.6872557884660261
Epoch: 96 | Iteration number: [1460/4518] 32% | Training loss: 0.687253164346904
Epoch: 96 | Iteration number: [1470/4518] 32% | Training loss: 0.6872515499186354
Epoch: 96 | Iteration number: [1480/4518] 32% | Training loss: 0.6872504312041644
Epoch: 96 | Iteration number: [1490/4518] 32% | Training loss: 0.6872427665547236
Epoch: 96 | Iteration number: [1500/4518] 33% | Training loss: 0.6872326773405075
Epoch: 96 | Iteration number: [1510/4518] 33% | Training loss: 0.6872236576301373
Epoch: 96 | Iteration number: [1520/4518] 33% | Training loss: 0.6872228429505699
Epoch: 96 | Iteration number: [1530/4518] 33% | Training loss: 0.6872268176546283
Epoch: 96 | Iteration number: [1540/4518] 34% | Training loss: 0.6872184474359859
Epoch: 96 | Iteration number: [1550/4518] 34% | Training loss: 0.6872112046518634
Epoch: 96 | Iteration number: [1560/4518] 34% | Training loss: 0.6872088119387627
Epoch: 96 | Iteration number: [1570/4518] 34% | Training loss: 0.6872088135807377
Epoch: 96 | Iteration number: [1580/4518] 34% | Training loss: 0.6871990741053714
Epoch: 96 | Iteration number: [1590/4518] 35% | Training loss: 0.6872024345697847
Epoch: 96 | Iteration number: [1600/4518] 35% | Training loss: 0.6871957505494356
Epoch: 96 | Iteration number: [1610/4518] 35% | Training loss: 0.6871890345715588
Epoch: 96 | Iteration number: [1620/4518] 35% | Training loss: 0.6871815078420404
Epoch: 96 | Iteration number: [1630/4518] 36% | Training loss: 0.6871789009658837
Epoch: 96 | Iteration number: [1640/4518] 36% | Training loss: 0.6871774474658617
Epoch: 96 | Iteration number: [1650/4518] 36% | Training loss: 0.6871693508191542
Epoch: 96 | Iteration number: [1660/4518] 36% | Training loss: 0.687175089479929
Epoch: 96 | Iteration number: [1670/4518] 36% | Training loss: 0.6871727530470865
Epoch: 96 | Iteration number: [1680/4518] 37% | Training loss: 0.6871716622085798
Epoch: 96 | Iteration number: [1690/4518] 37% | Training loss: 0.6871615820029784
Epoch: 96 | Iteration number: [1700/4518] 37% | Training loss: 0.687159560603254
Epoch: 96 | Iteration number: [1710/4518] 37% | Training loss: 0.687168867720498
Epoch: 96 | Iteration number: [1720/4518] 38% | Training loss: 0.687171396127967
Epoch: 96 | Iteration number: [1730/4518] 38% | Training loss: 0.687175368745892
Epoch: 96 | Iteration number: [1740/4518] 38% | Training loss: 0.6871719462775636
Epoch: 96 | Iteration number: [1750/4518] 38% | Training loss: 0.687164383820125
Epoch: 96 | Iteration number: [1760/4518] 38% | Training loss: 0.687161851877516
Epoch: 96 | Iteration number: [1770/4518] 39% | Training loss: 0.6871595568576101
Epoch: 96 | Iteration number: [1780/4518] 39% | Training loss: 0.6871552538001136
Epoch: 96 | Iteration number: [1790/4518] 39% | Training loss: 0.6871513046698863
Epoch: 96 | Iteration number: [1800/4518] 39% | Training loss: 0.6871429333753056
Epoch: 96 | Iteration number: [1810/4518] 40% | Training loss: 0.6871391254893983
Epoch: 96 | Iteration number: [1820/4518] 40% | Training loss: 0.6871368149807165
Epoch: 96 | Iteration number: [1830/4518] 40% | Training loss: 0.687128797092073
Epoch: 96 | Iteration number: [1840/4518] 40% | Training loss: 0.6871344467867976
Epoch: 96 | Iteration number: [1850/4518] 40% | Training loss: 0.6871297235102267
Epoch: 96 | Iteration number: [1860/4518] 41% | Training loss: 0.68712206434819
Epoch: 96 | Iteration number: [1870/4518] 41% | Training loss: 0.6871256103490125
Epoch: 96 | Iteration number: [1880/4518] 41% | Training loss: 0.6871290057263476
Epoch: 96 | Iteration number: [1890/4518] 41% | Training loss: 0.6871246624875952
Epoch: 96 | Iteration number: [1900/4518] 42% | Training loss: 0.687125461572095
Epoch: 96 | Iteration number: [1910/4518] 42% | Training loss: 0.6871247408277701
Epoch: 96 | Iteration number: [1920/4518] 42% | Training loss: 0.6871231737546623
Epoch: 96 | Iteration number: [1930/4518] 42% | Training loss: 0.6871244277669976
Epoch: 96 | Iteration number: [1940/4518] 42% | Training loss: 0.6871206696807723
Epoch: 96 | Iteration number: [1950/4518] 43% | Training loss: 0.6871210577549078
Epoch: 96 | Iteration number: [1960/4518] 43% | Training loss: 0.6871148779075973
Epoch: 96 | Iteration number: [1970/4518] 43% | Training loss: 0.6871098933183603
Epoch: 96 | Iteration number: [1980/4518] 43% | Training loss: 0.6871104979755902
Epoch: 96 | Iteration number: [1990/4518] 44% | Training loss: 0.6871085995106242
Epoch: 96 | Iteration number: [2000/4518] 44% | Training loss: 0.6871071937978268
Epoch: 96 | Iteration number: [2010/4518] 44% | Training loss: 0.6871065786228844
Epoch: 96 | Iteration number: [2020/4518] 44% | Training loss: 0.6871026993387996
Epoch: 96 | Iteration number: [2030/4518] 44% | Training loss: 0.6871019521957548
Epoch: 96 | Iteration number: [2040/4518] 45% | Training loss: 0.6870968769286193
Epoch: 96 | Iteration number: [2050/4518] 45% | Training loss: 0.6870992036272839
Epoch: 96 | Iteration number: [2060/4518] 45% | Training loss: 0.6870935647522362
Epoch: 96 | Iteration number: [2070/4518] 45% | Training loss: 0.6870947733017557
Epoch: 96 | Iteration number: [2080/4518] 46% | Training loss: 0.6870976278701654
Epoch: 96 | Iteration number: [2090/4518] 46% | Training loss: 0.6870884788378574
Epoch: 96 | Iteration number: [2100/4518] 46% | Training loss: 0.6870884084133875
Epoch: 96 | Iteration number: [2110/4518] 46% | Training loss: 0.6870928657845863
Epoch: 96 | Iteration number: [2120/4518] 46% | Training loss: 0.6870991552213452
Epoch: 96 | Iteration number: [2130/4518] 47% | Training loss: 0.6870982993376646
Epoch: 96 | Iteration number: [2140/4518] 47% | Training loss: 0.6870989460811436
Epoch: 96 | Iteration number: [2150/4518] 47% | Training loss: 0.687094663520192
Epoch: 96 | Iteration number: [2160/4518] 47% | Training loss: 0.6870911692855535
Epoch: 96 | Iteration number: [2170/4518] 48% | Training loss: 0.6870902650092604
Epoch: 96 | Iteration number: [2180/4518] 48% | Training loss: 0.6870964202858986
Epoch: 96 | Iteration number: [2190/4518] 48% | Training loss: 0.6871006142875375
Epoch: 96 | Iteration number: [2200/4518] 48% | Training loss: 0.687090762338855
Epoch: 96 | Iteration number: [2210/4518] 48% | Training loss: 0.6870844787062563
Epoch: 96 | Iteration number: [2220/4518] 49% | Training loss: 0.6870889516564103
Epoch: 96 | Iteration number: [2230/4518] 49% | Training loss: 0.6870876250512932
Epoch: 96 | Iteration number: [2240/4518] 49% | Training loss: 0.687083637341857
Epoch: 96 | Iteration number: [2250/4518] 49% | Training loss: 0.6870812119113074
Epoch: 96 | Iteration number: [2260/4518] 50% | Training loss: 0.6870795527390674
Epoch: 96 | Iteration number: [2270/4518] 50% | Training loss: 0.6870777723547645
Epoch: 96 | Iteration number: [2280/4518] 50% | Training loss: 0.6870829213868108
Epoch: 96 | Iteration number: [2290/4518] 50% | Training loss: 0.6870853553172283
Epoch: 96 | Iteration number: [2300/4518] 50% | Training loss: 0.6870838028451671
Epoch: 96 | Iteration number: [2310/4518] 51% | Training loss: 0.6870869127186862
Epoch: 96 | Iteration number: [2320/4518] 51% | Training loss: 0.6870841276285977
Epoch: 96 | Iteration number: [2330/4518] 51% | Training loss: 0.6870785884846945
Epoch: 96 | Iteration number: [2340/4518] 51% | Training loss: 0.6870739039957013
Epoch: 96 | Iteration number: [2350/4518] 52% | Training loss: 0.6870741834285411
Epoch: 96 | Iteration number: [2360/4518] 52% | Training loss: 0.6870674582861238
Epoch: 96 | Iteration number: [2370/4518] 52% | Training loss: 0.6870653165543633
Epoch: 96 | Iteration number: [2380/4518] 52% | Training loss: 0.6870659189063961
Epoch: 96 | Iteration number: [2390/4518] 52% | Training loss: 0.6870634838626973
Epoch: 96 | Iteration number: [2400/4518] 53% | Training loss: 0.6870600978036722
Epoch: 96 | Iteration number: [2410/4518] 53% | Training loss: 0.68705993218046
Epoch: 96 | Iteration number: [2420/4518] 53% | Training loss: 0.687057198916585
Epoch: 96 | Iteration number: [2430/4518] 53% | Training loss: 0.687056770123572
Epoch: 96 | Iteration number: [2440/4518] 54% | Training loss: 0.6870545465193811
Epoch: 96 | Iteration number: [2450/4518] 54% | Training loss: 0.6870522952566341
Epoch: 96 | Iteration number: [2460/4518] 54% | Training loss: 0.6870543766554779
Epoch: 96 | Iteration number: [2470/4518] 54% | Training loss: 0.6870590363436865
Epoch: 96 | Iteration number: [2480/4518] 54% | Training loss: 0.6870588427109103
Epoch: 96 | Iteration number: [2490/4518] 55% | Training loss: 0.6870541777476729
Epoch: 96 | Iteration number: [2500/4518] 55% | Training loss: 0.6870529145479203
Epoch: 96 | Iteration number: [2510/4518] 55% | Training loss: 0.6870540346044943
Epoch: 96 | Iteration number: [2520/4518] 55% | Training loss: 0.6870508716219947
Epoch: 96 | Iteration number: [2530/4518] 55% | Training loss: 0.6870485632315926
Epoch: 96 | Iteration number: [2540/4518] 56% | Training loss: 0.6870495272199
Epoch: 96 | Iteration number: [2550/4518] 56% | Training loss: 0.6870510168636547
Epoch: 96 | Iteration number: [2560/4518] 56% | Training loss: 0.6870440980885177
Epoch: 96 | Iteration number: [2570/4518] 56% | Training loss: 0.6870466832057047
Epoch: 96 | Iteration number: [2580/4518] 57% | Training loss: 0.6870460457349008
Epoch: 96 | Iteration number: [2590/4518] 57% | Training loss: 0.6870441287871033
Epoch: 96 | Iteration number: [2600/4518] 57% | Training loss: 0.6870392434413617
Epoch: 96 | Iteration number: [2610/4518] 57% | Training loss: 0.687042085672247
Epoch: 96 | Iteration number: [2620/4518] 57% | Training loss: 0.687041242978045
Epoch: 96 | Iteration number: [2630/4518] 58% | Training loss: 0.6870355106578581
Epoch: 96 | Iteration number: [2640/4518] 58% | Training loss: 0.6870378802445802
Epoch: 96 | Iteration number: [2650/4518] 58% | Training loss: 0.6870346982749004
Epoch: 96 | Iteration number: [2660/4518] 58% | Training loss: 0.6870343634732684
Epoch: 96 | Iteration number: [2670/4518] 59% | Training loss: 0.6870290879899643
Epoch: 96 | Iteration number: [2680/4518] 59% | Training loss: 0.6870251371789334
Epoch: 96 | Iteration number: [2690/4518] 59% | Training loss: 0.6870243090900789
Epoch: 96 | Iteration number: [2700/4518] 59% | Training loss: 0.6870234553681479
Epoch: 96 | Iteration number: [2710/4518] 59% | Training loss: 0.6870202765693524
Epoch: 96 | Iteration number: [2720/4518] 60% | Training loss: 0.6870205030940911
Epoch: 96 | Iteration number: [2730/4518] 60% | Training loss: 0.6870194861303756
Epoch: 96 | Iteration number: [2740/4518] 60% | Training loss: 0.6870207682360698
Epoch: 96 | Iteration number: [2750/4518] 60% | Training loss: 0.6870177953893488
Epoch: 96 | Iteration number: [2760/4518] 61% | Training loss: 0.6870157083091528
Epoch: 96 | Iteration number: [2770/4518] 61% | Training loss: 0.6870106020128683
Epoch: 96 | Iteration number: [2780/4518] 61% | Training loss: 0.6870089782870931
Epoch: 96 | Iteration number: [2790/4518] 61% | Training loss: 0.6870055802834076
Epoch: 96 | Iteration number: [2800/4518] 61% | Training loss: 0.6870036195218563
Epoch: 96 | Iteration number: [2810/4518] 62% | Training loss: 0.6870022127424695
Epoch: 96 | Iteration number: [2820/4518] 62% | Training loss: 0.6869966060768627
Epoch: 96 | Iteration number: [2830/4518] 62% | Training loss: 0.6869999224853178
Epoch: 96 | Iteration number: [2840/4518] 62% | Training loss: 0.6869976483810116
Epoch: 96 | Iteration number: [2850/4518] 63% | Training loss: 0.6869988173560092
Epoch: 96 | Iteration number: [2860/4518] 63% | Training loss: 0.6870003154644599
Epoch: 96 | Iteration number: [2870/4518] 63% | Training loss: 0.6870042254492796
Epoch: 96 | Iteration number: [2880/4518] 63% | Training loss: 0.6869983223784301
Epoch: 96 | Iteration number: [2890/4518] 63% | Training loss: 0.6869980758861687
Epoch: 96 | Iteration number: [2900/4518] 64% | Training loss: 0.686997219837945
Epoch: 96 | Iteration number: [2910/4518] 64% | Training loss: 0.6869987322292787
Epoch: 96 | Iteration number: [2920/4518] 64% | Training loss: 0.6869986916853957
Epoch: 96 | Iteration number: [2930/4518] 64% | Training loss: 0.6869972844172664
Epoch: 96 | Iteration number: [2940/4518] 65% | Training loss: 0.6869943290746131
Epoch: 96 | Iteration number: [2950/4518] 65% | Training loss: 0.6869923165693121
Epoch: 96 | Iteration number: [2960/4518] 65% | Training loss: 0.6869910039611765
Epoch: 96 | Iteration number: [2970/4518] 65% | Training loss: 0.6869876438319081
Epoch: 96 | Iteration number: [2980/4518] 65% | Training loss: 0.6869858158514803
Epoch: 96 | Iteration number: [2990/4518] 66% | Training loss: 0.6869783591067911
Epoch: 96 | Iteration number: [3000/4518] 66% | Training loss: 0.686974236190319
Epoch: 96 | Iteration number: [3010/4518] 66% | Training loss: 0.6869709170141886
Epoch: 96 | Iteration number: [3020/4518] 66% | Training loss: 0.6869688681419323
Epoch: 96 | Iteration number: [3030/4518] 67% | Training loss: 0.6869697151797833
Epoch: 96 | Iteration number: [3040/4518] 67% | Training loss: 0.6869652620859836
Epoch: 96 | Iteration number: [3050/4518] 67% | Training loss: 0.686964370579016
Epoch: 96 | Iteration number: [3060/4518] 67% | Training loss: 0.6869639579961503
Epoch: 96 | Iteration number: [3070/4518] 67% | Training loss: 0.6869655228593062
Epoch: 96 | Iteration number: [3080/4518] 68% | Training loss: 0.6869600212032144
Epoch: 96 | Iteration number: [3090/4518] 68% | Training loss: 0.6869586422412527
Epoch: 96 | Iteration number: [3100/4518] 68% | Training loss: 0.6869583757077494
Epoch: 96 | Iteration number: [3110/4518] 68% | Training loss: 0.6869600234116006
Epoch: 96 | Iteration number: [3120/4518] 69% | Training loss: 0.6869581702810067
Epoch: 96 | Iteration number: [3130/4518] 69% | Training loss: 0.6869576150616898
Epoch: 96 | Iteration number: [3140/4518] 69% | Training loss: 0.6869572208185865
Epoch: 96 | Iteration number: [3150/4518] 69% | Training loss: 0.6869561190643008
Epoch: 96 | Iteration number: [3160/4518] 69% | Training loss: 0.6869541887618318
Epoch: 96 | Iteration number: [3170/4518] 70% | Training loss: 0.6869550957288652
Epoch: 96 | Iteration number: [3180/4518] 70% | Training loss: 0.6869512733423485
Epoch: 96 | Iteration number: [3190/4518] 70% | Training loss: 0.6869511446795867
Epoch: 96 | Iteration number: [3200/4518] 70% | Training loss: 0.6869498990289867
Epoch: 96 | Iteration number: [3210/4518] 71% | Training loss: 0.6869496185274511
Epoch: 96 | Iteration number: [3220/4518] 71% | Training loss: 0.6869496879740531
Epoch: 96 | Iteration number: [3230/4518] 71% | Training loss: 0.686947576420226
Epoch: 96 | Iteration number: [3240/4518] 71% | Training loss: 0.6869500747249451
Epoch: 96 | Iteration number: [3250/4518] 71% | Training loss: 0.6869496394304129
Epoch: 96 | Iteration number: [3260/4518] 72% | Training loss: 0.686948778749975
Epoch: 96 | Iteration number: [3270/4518] 72% | Training loss: 0.6869495016719224
Epoch: 96 | Iteration number: [3280/4518] 72% | Training loss: 0.6869485888539291
Epoch: 96 | Iteration number: [3290/4518] 72% | Training loss: 0.6869443636353617
Epoch: 96 | Iteration number: [3300/4518] 73% | Training loss: 0.686944880882899
Epoch: 96 | Iteration number: [3310/4518] 73% | Training loss: 0.6869424723246307
Epoch: 96 | Iteration number: [3320/4518] 73% | Training loss: 0.6869407532624452
Epoch: 96 | Iteration number: [3330/4518] 73% | Training loss: 0.6869387524442988
Epoch: 96 | Iteration number: [3340/4518] 73% | Training loss: 0.6869363982877331
Epoch: 96 | Iteration number: [3350/4518] 74% | Training loss: 0.6869364374253287
Epoch: 96 | Iteration number: [3360/4518] 74% | Training loss: 0.6869376438891603
Epoch: 96 | Iteration number: [3370/4518] 74% | Training loss: 0.6869430117508071
Epoch: 96 | Iteration number: [3380/4518] 74% | Training loss: 0.6869447342919175
Epoch: 96 | Iteration number: [3390/4518] 75% | Training loss: 0.6869413390272134
Epoch: 96 | Iteration number: [3400/4518] 75% | Training loss: 0.6869374771679149
Epoch: 96 | Iteration number: [3410/4518] 75% | Training loss: 0.686937905301796
Epoch: 96 | Iteration number: [3420/4518] 75% | Training loss: 0.6869393599137925
Epoch: 96 | Iteration number: [3430/4518] 75% | Training loss: 0.6869387841606974
Epoch: 96 | Iteration number: [3440/4518] 76% | Training loss: 0.6869374049957409
Epoch: 96 | Iteration number: [3450/4518] 76% | Training loss: 0.6869388135101484
Epoch: 96 | Iteration number: [3460/4518] 76% | Training loss: 0.6869392528354777
Epoch: 96 | Iteration number: [3470/4518] 76% | Training loss: 0.6869417338618627
Epoch: 96 | Iteration number: [3480/4518] 77% | Training loss: 0.6869435264803897
Epoch: 96 | Iteration number: [3490/4518] 77% | Training loss: 0.6869456781869632
Epoch: 96 | Iteration number: [3500/4518] 77% | Training loss: 0.6869429375614439
Epoch: 96 | Iteration number: [3510/4518] 77% | Training loss: 0.6869431704877109
Epoch: 96 | Iteration number: [3520/4518] 77% | Training loss: 0.6869441463866017
Epoch: 96 | Iteration number: [3530/4518] 78% | Training loss: 0.6869430311847341
Epoch: 96 | Iteration number: [3540/4518] 78% | Training loss: 0.6869420798316513
Epoch: 96 | Iteration number: [3550/4518] 78% | Training loss: 0.6869442636698064
Epoch: 96 | Iteration number: [3560/4518] 78% | Training loss: 0.6869455361801586
Epoch: 96 | Iteration number: [3570/4518] 79% | Training loss: 0.686941898770693
Epoch: 96 | Iteration number: [3580/4518] 79% | Training loss: 0.6869396774129495
Epoch: 96 | Iteration number: [3590/4518] 79% | Training loss: 0.68694054471085
Epoch: 96 | Iteration number: [3600/4518] 79% | Training loss: 0.6869432278474172
Epoch: 96 | Iteration number: [3610/4518] 79% | Training loss: 0.6869426088154811
Epoch: 96 | Iteration number: [3620/4518] 80% | Training loss: 0.6869409216537001
Epoch: 96 | Iteration number: [3630/4518] 80% | Training loss: 0.6869445549390861
Epoch: 96 | Iteration number: [3640/4518] 80% | Training loss: 0.6869389731641654
Epoch: 96 | Iteration number: [3650/4518] 80% | Training loss: 0.6869365384317424
Epoch: 96 | Iteration number: [3660/4518] 81% | Training loss: 0.686932752953201
Epoch: 96 | Iteration number: [3670/4518] 81% | Training loss: 0.6869311081778451
Epoch: 96 | Iteration number: [3680/4518] 81% | Training loss: 0.6869320079522289
Epoch: 96 | Iteration number: [3690/4518] 81% | Training loss: 0.6869335572086376
Epoch: 96 | Iteration number: [3700/4518] 81% | Training loss: 0.6869317445400599
Epoch: 96 | Iteration number: [3710/4518] 82% | Training loss: 0.6869305640378731
Epoch: 96 | Iteration number: [3720/4518] 82% | Training loss: 0.6869331269494949
Epoch: 96 | Iteration number: [3730/4518] 82% | Training loss: 0.6869355143075334
Epoch: 96 | Iteration number: [3740/4518] 82% | Training loss: 0.6869315681929257
Epoch: 96 | Iteration number: [3750/4518] 83% | Training loss: 0.6869328882535298
Epoch: 96 | Iteration number: [3760/4518] 83% | Training loss: 0.6869318231306177
Epoch: 96 | Iteration number: [3770/4518] 83% | Training loss: 0.6869321308812665
Epoch: 96 | Iteration number: [3780/4518] 83% | Training loss: 0.6869310103238575
Epoch: 96 | Iteration number: [3790/4518] 83% | Training loss: 0.6869340947246804
Epoch: 96 | Iteration number: [3800/4518] 84% | Training loss: 0.6869341262704448
Epoch: 96 | Iteration number: [3810/4518] 84% | Training loss: 0.686933249813991
Epoch: 96 | Iteration number: [3820/4518] 84% | Training loss: 0.6869335682916392
Epoch: 96 | Iteration number: [3830/4518] 84% | Training loss: 0.6869332883438927
Epoch: 96 | Iteration number: [3840/4518] 84% | Training loss: 0.6869299146812409
Epoch: 96 | Iteration number: [3850/4518] 85% | Training loss: 0.6869295139746232
Epoch: 96 | Iteration number: [3860/4518] 85% | Training loss: 0.6869269722638353
Epoch: 96 | Iteration number: [3870/4518] 85% | Training loss: 0.6869290303044233
Epoch: 96 | Iteration number: [3880/4518] 85% | Training loss: 0.6869278934659417
Epoch: 96 | Iteration number: [3890/4518] 86% | Training loss: 0.6869276793879531
Epoch: 96 | Iteration number: [3900/4518] 86% | Training loss: 0.6869303169464454
Epoch: 96 | Iteration number: [3910/4518] 86% | Training loss: 0.6869278309137925
Epoch: 96 | Iteration number: [3920/4518] 86% | Training loss: 0.6869266170020006
Epoch: 96 | Iteration number: [3930/4518] 86% | Training loss: 0.6869255135987551
Epoch: 96 | Iteration number: [3940/4518] 87% | Training loss: 0.6869231374433198
Epoch: 96 | Iteration number: [3950/4518] 87% | Training loss: 0.6869205559507201
Epoch: 96 | Iteration number: [3960/4518] 87% | Training loss: 0.6869188316542693
Epoch: 96 | Iteration number: [3970/4518] 87% | Training loss: 0.6869191347051328
Epoch: 96 | Iteration number: [3980/4518] 88% | Training loss: 0.6869179255399273
Epoch: 96 | Iteration number: [3990/4518] 88% | Training loss: 0.6869146449673444
Epoch: 96 | Iteration number: [4000/4518] 88% | Training loss: 0.6869142587035895
Epoch: 96 | Iteration number: [4010/4518] 88% | Training loss: 0.6869137563758955
Epoch: 96 | Iteration number: [4020/4518] 88% | Training loss: 0.6869095592949521
Epoch: 96 | Iteration number: [4030/4518] 89% | Training loss: 0.6869093424629041
Epoch: 96 | Iteration number: [4040/4518] 89% | Training loss: 0.6869048145737978
Epoch: 96 | Iteration number: [4050/4518] 89% | Training loss: 0.6869046343255926
Epoch: 96 | Iteration number: [4060/4518] 89% | Training loss: 0.6869040201303407
Epoch: 96 | Iteration number: [4070/4518] 90% | Training loss: 0.6869004518892021
Epoch: 96 | Iteration number: [4080/4518] 90% | Training loss: 0.686900823884735
Epoch: 96 | Iteration number: [4090/4518] 90% | Training loss: 0.6868976492607798
Epoch: 96 | Iteration number: [4100/4518] 90% | Training loss: 0.6868978135469483
Epoch: 96 | Iteration number: [4110/4518] 90% | Training loss: 0.6868935215212133
Epoch: 96 | Iteration number: [4120/4518] 91% | Training loss: 0.6868977877844884
Epoch: 96 | Iteration number: [4130/4518] 91% | Training loss: 0.6868973178378607
Epoch: 96 | Iteration number: [4140/4518] 91% | Training loss: 0.6868998778471048
Epoch: 96 | Iteration number: [4150/4518] 91% | Training loss: 0.686896083685289
Epoch: 96 | Iteration number: [4160/4518] 92% | Training loss: 0.686898491015801
Epoch: 96 | Iteration number: [4170/4518] 92% | Training loss: 0.6868979082118979
Epoch: 96 | Iteration number: [4180/4518] 92% | Training loss: 0.6868944516307429
Epoch: 96 | Iteration number: [4190/4518] 92% | Training loss: 0.6868961603374072
Epoch: 96 | Iteration number: [4200/4518] 92% | Training loss: 0.6868942711041087
Epoch: 96 | Iteration number: [4210/4518] 93% | Training loss: 0.6868904350772324
Epoch: 96 | Iteration number: [4220/4518] 93% | Training loss: 0.6868896439459652
Epoch: 96 | Iteration number: [4230/4518] 93% | Training loss: 0.6868878828859216
Epoch: 96 | Iteration number: [4240/4518] 93% | Training loss: 0.6868870649697646
Epoch: 96 | Iteration number: [4250/4518] 94% | Training loss: 0.6868860261440277
Epoch: 96 | Iteration number: [4260/4518] 94% | Training loss: 0.6868882527373766
Epoch: 96 | Iteration number: [4270/4518] 94% | Training loss: 0.6868913825976486
Epoch: 96 | Iteration number: [4280/4518] 94% | Training loss: 0.6868904062659941
Epoch: 96 | Iteration number: [4290/4518] 94% | Training loss: 0.6868886835091598
Epoch: 96 | Iteration number: [4300/4518] 95% | Training loss: 0.6868902799833653
Epoch: 96 | Iteration number: [4310/4518] 95% | Training loss: 0.6868908183204049
Epoch: 96 | Iteration number: [4320/4518] 95% | Training loss: 0.6868914247662933
Epoch: 96 | Iteration number: [4330/4518] 95% | Training loss: 0.6868900563369997
Epoch: 96 | Iteration number: [4340/4518] 96% | Training loss: 0.6868888143982206
Epoch: 96 | Iteration number: [4350/4518] 96% | Training loss: 0.6868893980294809
Epoch: 96 | Iteration number: [4360/4518] 96% | Training loss: 0.6868906861324923
Epoch: 96 | Iteration number: [4370/4518] 96% | Training loss: 0.686892892307766
Epoch: 96 | Iteration number: [4380/4518] 96% | Training loss: 0.686895907279019
Epoch: 96 | Iteration number: [4390/4518] 97% | Training loss: 0.686896550655365
Epoch: 96 | Iteration number: [4400/4518] 97% | Training loss: 0.6868975386971777
Epoch: 96 | Iteration number: [4410/4518] 97% | Training loss: 0.6868975864246049
Epoch: 96 | Iteration number: [4420/4518] 97% | Training loss: 0.6868979353305981
Epoch: 96 | Iteration number: [4430/4518] 98% | Training loss: 0.6868996340318942
Epoch: 96 | Iteration number: [4440/4518] 98% | Training loss: 0.6869003617414483
Epoch: 96 | Iteration number: [4450/4518] 98% | Training loss: 0.6869038854824023
Epoch: 96 | Iteration number: [4460/4518] 98% | Training loss: 0.6868999862483799
Epoch: 96 | Iteration number: [4470/4518] 98% | Training loss: 0.6869003342968772
Epoch: 96 | Iteration number: [4480/4518] 99% | Training loss: 0.6868988813167172
Epoch: 96 | Iteration number: [4490/4518] 99% | Training loss: 0.6868979657545918
Epoch: 96 | Iteration number: [4500/4518] 99% | Training loss: 0.6868990741173426
Epoch: 96 | Iteration number: [4510/4518] 99% | Training loss: 0.6868993062534248

 End of epoch: 96 | Train Loss: 0.6867480355720174 | Training Time: 641 

 End of epoch: 96 | Eval Loss: 0.6897393440713688 | Evaluating Time: 17 
Epoch: 97 | Iteration number: [10/4518] 0% | Training loss: 0.7552031219005585
Epoch: 97 | Iteration number: [20/4518] 0% | Training loss: 0.721212187409401
Epoch: 97 | Iteration number: [30/4518] 0% | Training loss: 0.7097868760426839
Epoch: 97 | Iteration number: [40/4518] 0% | Training loss: 0.7040533110499382
Epoch: 97 | Iteration number: [50/4518] 1% | Training loss: 0.7008420407772065
Epoch: 97 | Iteration number: [60/4518] 1% | Training loss: 0.6985944251219431
Epoch: 97 | Iteration number: [70/4518] 1% | Training loss: 0.6967869341373444
Epoch: 97 | Iteration number: [80/4518] 1% | Training loss: 0.6955823212862015
Epoch: 97 | Iteration number: [90/4518] 1% | Training loss: 0.6943963170051575
Epoch: 97 | Iteration number: [100/4518] 2% | Training loss: 0.6934940087795257
Epoch: 97 | Iteration number: [110/4518] 2% | Training loss: 0.6927895112471147
Epoch: 97 | Iteration number: [120/4518] 2% | Training loss: 0.6922065198421479
Epoch: 97 | Iteration number: [130/4518] 2% | Training loss: 0.6917967406603006
Epoch: 97 | Iteration number: [140/4518] 3% | Training loss: 0.6914634776966913
Epoch: 97 | Iteration number: [150/4518] 3% | Training loss: 0.6911838404337565
Epoch: 97 | Iteration number: [160/4518] 3% | Training loss: 0.690898597612977
Epoch: 97 | Iteration number: [170/4518] 3% | Training loss: 0.6906912460046656
Epoch: 97 | Iteration number: [180/4518] 3% | Training loss: 0.6905116455422508
Epoch: 97 | Iteration number: [190/4518] 4% | Training loss: 0.6903118898994044
Epoch: 97 | Iteration number: [200/4518] 4% | Training loss: 0.690178197324276
Epoch: 97 | Iteration number: [210/4518] 4% | Training loss: 0.6899211880706605
Epoch: 97 | Iteration number: [220/4518] 4% | Training loss: 0.6897887053814802
Epoch: 97 | Iteration number: [230/4518] 5% | Training loss: 0.689655376776405
Epoch: 97 | Iteration number: [240/4518] 5% | Training loss: 0.689513948559761
Epoch: 97 | Iteration number: [250/4518] 5% | Training loss: 0.6893647274971009
Epoch: 97 | Iteration number: [260/4518] 5% | Training loss: 0.689286429148454
Epoch: 97 | Iteration number: [270/4518] 5% | Training loss: 0.6892245619385331
Epoch: 97 | Iteration number: [280/4518] 6% | Training loss: 0.6891311351742063
Epoch: 97 | Iteration number: [290/4518] 6% | Training loss: 0.6890699943591808
Epoch: 97 | Iteration number: [300/4518] 6% | Training loss: 0.6890241092443466
Epoch: 97 | Iteration number: [310/4518] 6% | Training loss: 0.6889142290238411
Epoch: 97 | Iteration number: [320/4518] 7% | Training loss: 0.6888316368684173
Epoch: 97 | Iteration number: [330/4518] 7% | Training loss: 0.6887344605994947
Epoch: 97 | Iteration number: [340/4518] 7% | Training loss: 0.688676297138719
Epoch: 97 | Iteration number: [350/4518] 7% | Training loss: 0.6886245461872645
Epoch: 97 | Iteration number: [360/4518] 7% | Training loss: 0.6885433105958833
Epoch: 97 | Iteration number: [370/4518] 8% | Training loss: 0.6884880705459698
Epoch: 97 | Iteration number: [380/4518] 8% | Training loss: 0.688447042358549
Epoch: 97 | Iteration number: [390/4518] 8% | Training loss: 0.68841247573877
Epoch: 97 | Iteration number: [400/4518] 8% | Training loss: 0.6883754286170006
Epoch: 97 | Iteration number: [410/4518] 9% | Training loss: 0.6883534809438193
Epoch: 97 | Iteration number: [420/4518] 9% | Training loss: 0.6883326283523015
Epoch: 97 | Iteration number: [430/4518] 9% | Training loss: 0.6883013073788132
Epoch: 97 | Iteration number: [440/4518] 9% | Training loss: 0.6883006538857114
Epoch: 97 | Iteration number: [450/4518] 9% | Training loss: 0.6882622149255541
Epoch: 97 | Iteration number: [460/4518] 10% | Training loss: 0.6882528150859086
Epoch: 97 | Iteration number: [470/4518] 10% | Training loss: 0.6882248343305385
Epoch: 97 | Iteration number: [480/4518] 10% | Training loss: 0.6881811125824849
Epoch: 97 | Iteration number: [490/4518] 10% | Training loss: 0.6881422850550437
Epoch: 97 | Iteration number: [500/4518] 11% | Training loss: 0.6880867357254028
Epoch: 97 | Iteration number: [510/4518] 11% | Training loss: 0.6880478580792745
Epoch: 97 | Iteration number: [520/4518] 11% | Training loss: 0.6880310711952357
Epoch: 97 | Iteration number: [530/4518] 11% | Training loss: 0.6879934132099151
Epoch: 97 | Iteration number: [540/4518] 11% | Training loss: 0.6879726350307465
Epoch: 97 | Iteration number: [550/4518] 12% | Training loss: 0.6879490396109494
Epoch: 97 | Iteration number: [560/4518] 12% | Training loss: 0.6879336695585933
Epoch: 97 | Iteration number: [570/4518] 12% | Training loss: 0.6879205753928737
Epoch: 97 | Iteration number: [580/4518] 12% | Training loss: 0.6878907229365974
Epoch: 97 | Iteration number: [590/4518] 13% | Training loss: 0.6878856790267815
Epoch: 97 | Iteration number: [600/4518] 13% | Training loss: 0.6878558478752772
Epoch: 97 | Iteration number: [610/4518] 13% | Training loss: 0.687855140107577
Epoch: 97 | Iteration number: [620/4518] 13% | Training loss: 0.687847726960336
Epoch: 97 | Iteration number: [630/4518] 13% | Training loss: 0.6878454173368121
Epoch: 97 | Iteration number: [640/4518] 14% | Training loss: 0.6878326825797558
Epoch: 97 | Iteration number: [650/4518] 14% | Training loss: 0.6878256760193752
Epoch: 97 | Iteration number: [660/4518] 14% | Training loss: 0.6878059596726389
Epoch: 97 | Iteration number: [670/4518] 14% | Training loss: 0.6877854546504234
Epoch: 97 | Iteration number: [680/4518] 15% | Training loss: 0.6878002073834925
Epoch: 97 | Iteration number: [690/4518] 15% | Training loss: 0.6877664426962534
Epoch: 97 | Iteration number: [700/4518] 15% | Training loss: 0.6877384861877986
Epoch: 97 | Iteration number: [710/4518] 15% | Training loss: 0.6877228634458192
Epoch: 97 | Iteration number: [720/4518] 15% | Training loss: 0.6877236204014884
Epoch: 97 | Iteration number: [730/4518] 16% | Training loss: 0.6877107259345381
Epoch: 97 | Iteration number: [740/4518] 16% | Training loss: 0.6876784403581877
Epoch: 97 | Iteration number: [750/4518] 16% | Training loss: 0.6876450990835825
Epoch: 97 | Iteration number: [760/4518] 16% | Training loss: 0.6876381188631058
Epoch: 97 | Iteration number: [770/4518] 17% | Training loss: 0.6876203068665095
Epoch: 97 | Iteration number: [780/4518] 17% | Training loss: 0.687611616956882
Epoch: 97 | Iteration number: [790/4518] 17% | Training loss: 0.6875934213022642
Epoch: 97 | Iteration number: [800/4518] 17% | Training loss: 0.6875807922333479
Epoch: 97 | Iteration number: [810/4518] 17% | Training loss: 0.6875713648619475
Epoch: 97 | Iteration number: [820/4518] 18% | Training loss: 0.6875609130394168
Epoch: 97 | Iteration number: [830/4518] 18% | Training loss: 0.6875495191798152
Epoch: 97 | Iteration number: [840/4518] 18% | Training loss: 0.6875501525543984
Epoch: 97 | Iteration number: [850/4518] 18% | Training loss: 0.6875423827592064
Epoch: 97 | Iteration number: [860/4518] 19% | Training loss: 0.6875206261873246
Epoch: 97 | Iteration number: [870/4518] 19% | Training loss: 0.6875005215748974
Epoch: 97 | Iteration number: [880/4518] 19% | Training loss: 0.6875027912584218
Epoch: 97 | Iteration number: [890/4518] 19% | Training loss: 0.6875115054377009
Epoch: 97 | Iteration number: [900/4518] 19% | Training loss: 0.6875146257215076
Epoch: 97 | Iteration number: [910/4518] 20% | Training loss: 0.6875148350720878
Epoch: 97 | Iteration number: [920/4518] 20% | Training loss: 0.6875077234662097
Epoch: 97 | Iteration number: [930/4518] 20% | Training loss: 0.6875030454768929
Epoch: 97 | Iteration number: [940/4518] 20% | Training loss: 0.6875043385206385
Epoch: 97 | Iteration number: [950/4518] 21% | Training loss: 0.6874937686794682
Epoch: 97 | Iteration number: [960/4518] 21% | Training loss: 0.6874768333509564
Epoch: 97 | Iteration number: [970/4518] 21% | Training loss: 0.6874673547204008
Epoch: 97 | Iteration number: [980/4518] 21% | Training loss: 0.6874767689680567
Epoch: 97 | Iteration number: [990/4518] 21% | Training loss: 0.6874760282762122
Epoch: 97 | Iteration number: [1000/4518] 22% | Training loss: 0.6874578346014023
Epoch: 97 | Iteration number: [1010/4518] 22% | Training loss: 0.6874432539585793
Epoch: 97 | Iteration number: [1020/4518] 22% | Training loss: 0.6874360948216681
Epoch: 97 | Iteration number: [1030/4518] 22% | Training loss: 0.6874153830472706
Epoch: 97 | Iteration number: [1040/4518] 23% | Training loss: 0.6874126803989594
Epoch: 97 | Iteration number: [1050/4518] 23% | Training loss: 0.6874077665238153
Epoch: 97 | Iteration number: [1060/4518] 23% | Training loss: 0.6873966237846411
Epoch: 97 | Iteration number: [1070/4518] 23% | Training loss: 0.6873921208849577
Epoch: 97 | Iteration number: [1080/4518] 23% | Training loss: 0.6873771913073681
Epoch: 97 | Iteration number: [1090/4518] 24% | Training loss: 0.6873713873941963
Epoch: 97 | Iteration number: [1100/4518] 24% | Training loss: 0.6873655687678945
Epoch: 97 | Iteration number: [1110/4518] 24% | Training loss: 0.6873571632144687
Epoch: 97 | Iteration number: [1120/4518] 24% | Training loss: 0.6873557255204235
Epoch: 97 | Iteration number: [1130/4518] 25% | Training loss: 0.6873472881528129
Epoch: 97 | Iteration number: [1140/4518] 25% | Training loss: 0.6873476758337858
Epoch: 97 | Iteration number: [1150/4518] 25% | Training loss: 0.6873429883044699
Epoch: 97 | Iteration number: [1160/4518] 25% | Training loss: 0.6873458305823392
Epoch: 97 | Iteration number: [1170/4518] 25% | Training loss: 0.6873552961736663
Epoch: 97 | Iteration number: [1180/4518] 26% | Training loss: 0.6873527816291582
Epoch: 97 | Iteration number: [1190/4518] 26% | Training loss: 0.6873490968672167
Epoch: 97 | Iteration number: [1200/4518] 26% | Training loss: 0.6873448709646861
Epoch: 97 | Iteration number: [1210/4518] 26% | Training loss: 0.6873465590733142
Epoch: 97 | Iteration number: [1220/4518] 27% | Training loss: 0.6873324660981288
Epoch: 97 | Iteration number: [1230/4518] 27% | Training loss: 0.6873274265750637
Epoch: 97 | Iteration number: [1240/4518] 27% | Training loss: 0.6873229690617131
Epoch: 97 | Iteration number: [1250/4518] 27% | Training loss: 0.6873114915370941
Epoch: 97 | Iteration number: [1260/4518] 27% | Training loss: 0.6873034611107811
Epoch: 97 | Iteration number: [1270/4518] 28% | Training loss: 0.6872991177510089
Epoch: 97 | Iteration number: [1280/4518] 28% | Training loss: 0.6872945651877671
Epoch: 97 | Iteration number: [1290/4518] 28% | Training loss: 0.6872866178667822
Epoch: 97 | Iteration number: [1300/4518] 28% | Training loss: 0.6872833694861485
Epoch: 97 | Iteration number: [1310/4518] 28% | Training loss: 0.6872859908424261
Epoch: 97 | Iteration number: [1320/4518] 29% | Training loss: 0.6872869739478285
Epoch: 97 | Iteration number: [1330/4518] 29% | Training loss: 0.6872860233138378
Epoch: 97 | Iteration number: [1340/4518] 29% | Training loss: 0.6872933740936108
Epoch: 97 | Iteration number: [1350/4518] 29% | Training loss: 0.6872982352309757
Epoch: 97 | Iteration number: [1360/4518] 30% | Training loss: 0.6872987007831826
Epoch: 97 | Iteration number: [1370/4518] 30% | Training loss: 0.6873006839386738
Epoch: 97 | Iteration number: [1380/4518] 30% | Training loss: 0.6872976125150487
Epoch: 97 | Iteration number: [1390/4518] 30% | Training loss: 0.6872842142050215
Epoch: 97 | Iteration number: [1400/4518] 30% | Training loss: 0.6872847961953709
Epoch: 97 | Iteration number: [1410/4518] 31% | Training loss: 0.6872739904738487
Epoch: 97 | Iteration number: [1420/4518] 31% | Training loss: 0.6872648937601439
Epoch: 97 | Iteration number: [1430/4518] 31% | Training loss: 0.6872625420143554
Epoch: 97 | Iteration number: [1440/4518] 31% | Training loss: 0.6872562933299277
Epoch: 97 | Iteration number: [1450/4518] 32% | Training loss: 0.6872616901890984
Epoch: 97 | Iteration number: [1460/4518] 32% | Training loss: 0.6872533427934124
Epoch: 97 | Iteration number: [1470/4518] 32% | Training loss: 0.6872482721902886
Epoch: 97 | Iteration number: [1480/4518] 32% | Training loss: 0.6872492863519771
Epoch: 97 | Iteration number: [1490/4518] 32% | Training loss: 0.6872441673838853
Epoch: 97 | Iteration number: [1500/4518] 33% | Training loss: 0.687237324754397
Epoch: 97 | Iteration number: [1510/4518] 33% | Training loss: 0.6872282095697542
Epoch: 97 | Iteration number: [1520/4518] 33% | Training loss: 0.687232907783044
Epoch: 97 | Iteration number: [1530/4518] 33% | Training loss: 0.6872381431604523
Epoch: 97 | Iteration number: [1540/4518] 34% | Training loss: 0.6872429339142588
Epoch: 97 | Iteration number: [1550/4518] 34% | Training loss: 0.6872372766079441
Epoch: 97 | Iteration number: [1560/4518] 34% | Training loss: 0.6872335447714879
Epoch: 97 | Iteration number: [1570/4518] 34% | Training loss: 0.6872269740150233
Epoch: 97 | Iteration number: [1580/4518] 34% | Training loss: 0.6872268159555484
Epoch: 97 | Iteration number: [1590/4518] 35% | Training loss: 0.6872317234675089
Epoch: 97 | Iteration number: [1600/4518] 35% | Training loss: 0.6872239890322089
Epoch: 97 | Iteration number: [1610/4518] 35% | Training loss: 0.6872243202250937
Epoch: 97 | Iteration number: [1620/4518] 35% | Training loss: 0.6872202184833126
Epoch: 97 | Iteration number: [1630/4518] 36% | Training loss: 0.6872125256280958
Epoch: 97 | Iteration number: [1640/4518] 36% | Training loss: 0.6872138991951943
Epoch: 97 | Iteration number: [1650/4518] 36% | Training loss: 0.687217775222027
Epoch: 97 | Iteration number: [1660/4518] 36% | Training loss: 0.6872235679841904
Epoch: 97 | Iteration number: [1670/4518] 36% | Training loss: 0.6872240163608939
Epoch: 97 | Iteration number: [1680/4518] 37% | Training loss: 0.6872163686723937
Epoch: 97 | Iteration number: [1690/4518] 37% | Training loss: 0.6872133278282436
Epoch: 97 | Iteration number: [1700/4518] 37% | Training loss: 0.6872120086235158
Epoch: 97 | Iteration number: [1710/4518] 37% | Training loss: 0.6872125983586785
Epoch: 97 | Iteration number: [1720/4518] 38% | Training loss: 0.6872093130336251
Epoch: 97 | Iteration number: [1730/4518] 38% | Training loss: 0.6872096111319658
Epoch: 97 | Iteration number: [1740/4518] 38% | Training loss: 0.6872050058567661
Epoch: 97 | Iteration number: [1750/4518] 38% | Training loss: 0.6872058852400098
Epoch: 97 | Iteration number: [1760/4518] 38% | Training loss: 0.6872045694427057
Epoch: 97 | Iteration number: [1770/4518] 39% | Training loss: 0.6871932564818927
Epoch: 97 | Iteration number: [1780/4518] 39% | Training loss: 0.6871824028786648
Epoch: 97 | Iteration number: [1790/4518] 39% | Training loss: 0.6871744020025158
Epoch: 97 | Iteration number: [1800/4518] 39% | Training loss: 0.6871625817815463
Epoch: 97 | Iteration number: [1810/4518] 40% | Training loss: 0.68715537486814
Epoch: 97 | Iteration number: [1820/4518] 40% | Training loss: 0.6871603219718724
Epoch: 97 | Iteration number: [1830/4518] 40% | Training loss: 0.6871541710824914
Epoch: 97 | Iteration number: [1840/4518] 40% | Training loss: 0.6871523067031218
Epoch: 97 | Iteration number: [1850/4518] 40% | Training loss: 0.6871421900633219
Epoch: 97 | Iteration number: [1860/4518] 41% | Training loss: 0.6871406945490068
Epoch: 97 | Iteration number: [1870/4518] 41% | Training loss: 0.6871320516986643
Epoch: 97 | Iteration number: [1880/4518] 41% | Training loss: 0.6871266528012905
Epoch: 97 | Iteration number: [1890/4518] 41% | Training loss: 0.6871275834305577
Epoch: 97 | Iteration number: [1900/4518] 42% | Training loss: 0.6871307761104484
Epoch: 97 | Iteration number: [1910/4518] 42% | Training loss: 0.687128717331362
Epoch: 97 | Iteration number: [1920/4518] 42% | Training loss: 0.6871292786672711
Epoch: 97 | Iteration number: [1930/4518] 42% | Training loss: 0.6871220091772821
Epoch: 97 | Iteration number: [1940/4518] 42% | Training loss: 0.6871231586355524
Epoch: 97 | Iteration number: [1950/4518] 43% | Training loss: 0.6871171632791176
Epoch: 97 | Iteration number: [1960/4518] 43% | Training loss: 0.6871094809502971
Epoch: 97 | Iteration number: [1970/4518] 43% | Training loss: 0.6871033973197647
Epoch: 97 | Iteration number: [1980/4518] 43% | Training loss: 0.6871015722703452
Epoch: 97 | Iteration number: [1990/4518] 44% | Training loss: 0.6870980219625349
Epoch: 97 | Iteration number: [2000/4518] 44% | Training loss: 0.6870899000167847
Epoch: 97 | Iteration number: [2010/4518] 44% | Training loss: 0.6870926539696272
Epoch: 97 | Iteration number: [2020/4518] 44% | Training loss: 0.6870934658121355
Epoch: 97 | Iteration number: [2030/4518] 44% | Training loss: 0.6870934977907265
Epoch: 97 | Iteration number: [2040/4518] 45% | Training loss: 0.6870915463157728
Epoch: 97 | Iteration number: [2050/4518] 45% | Training loss: 0.6870942603669515
Epoch: 97 | Iteration number: [2060/4518] 45% | Training loss: 0.687094275031275
Epoch: 97 | Iteration number: [2070/4518] 45% | Training loss: 0.6870894576616333
Epoch: 97 | Iteration number: [2080/4518] 46% | Training loss: 0.6870867156638549
Epoch: 97 | Iteration number: [2090/4518] 46% | Training loss: 0.6870864536773645
Epoch: 97 | Iteration number: [2100/4518] 46% | Training loss: 0.6870828913507008
Epoch: 97 | Iteration number: [2110/4518] 46% | Training loss: 0.6870787293990076
Epoch: 97 | Iteration number: [2120/4518] 46% | Training loss: 0.6870789888894783
Epoch: 97 | Iteration number: [2130/4518] 47% | Training loss: 0.6870736141160061
Epoch: 97 | Iteration number: [2140/4518] 47% | Training loss: 0.687075806471789
Epoch: 97 | Iteration number: [2150/4518] 47% | Training loss: 0.6870730229865673
Epoch: 97 | Iteration number: [2160/4518] 47% | Training loss: 0.6870741566022237
Epoch: 97 | Iteration number: [2170/4518] 48% | Training loss: 0.6870811780202224
Epoch: 97 | Iteration number: [2180/4518] 48% | Training loss: 0.6870675508308848
Epoch: 97 | Iteration number: [2190/4518] 48% | Training loss: 0.6870705682665246
Epoch: 97 | Iteration number: [2200/4518] 48% | Training loss: 0.6870685422149572
Epoch: 97 | Iteration number: [2210/4518] 48% | Training loss: 0.6870720472540791
Epoch: 97 | Iteration number: [2220/4518] 49% | Training loss: 0.6870674233984303
Epoch: 97 | Iteration number: [2230/4518] 49% | Training loss: 0.6870721654239791
Epoch: 97 | Iteration number: [2240/4518] 49% | Training loss: 0.687067744668041
Epoch: 97 | Iteration number: [2250/4518] 49% | Training loss: 0.687067032761044
Epoch: 97 | Iteration number: [2260/4518] 50% | Training loss: 0.6870660802431866
Epoch: 97 | Iteration number: [2270/4518] 50% | Training loss: 0.687069674289174
Epoch: 97 | Iteration number: [2280/4518] 50% | Training loss: 0.6870759018680506
Epoch: 97 | Iteration number: [2290/4518] 50% | Training loss: 0.6870718872963602
Epoch: 97 | Iteration number: [2300/4518] 50% | Training loss: 0.6870676259113395
Epoch: 97 | Iteration number: [2310/4518] 51% | Training loss: 0.6870605939910526
Epoch: 97 | Iteration number: [2320/4518] 51% | Training loss: 0.6870598584670445
Epoch: 97 | Iteration number: [2330/4518] 51% | Training loss: 0.6870585345914947
Epoch: 97 | Iteration number: [2340/4518] 51% | Training loss: 0.6870586668578987
Epoch: 97 | Iteration number: [2350/4518] 52% | Training loss: 0.6870520459844711
Epoch: 97 | Iteration number: [2360/4518] 52% | Training loss: 0.6870502666144048
Epoch: 97 | Iteration number: [2370/4518] 52% | Training loss: 0.6870534920742744
Epoch: 97 | Iteration number: [2380/4518] 52% | Training loss: 0.6870472501556413
Epoch: 97 | Iteration number: [2390/4518] 52% | Training loss: 0.6870405882971057
Epoch: 97 | Iteration number: [2400/4518] 53% | Training loss: 0.6870391899098952
Epoch: 97 | Iteration number: [2410/4518] 53% | Training loss: 0.6870347026720086
Epoch: 97 | Iteration number: [2420/4518] 53% | Training loss: 0.6870354295762118
Epoch: 97 | Iteration number: [2430/4518] 53% | Training loss: 0.6870326380670807
Epoch: 97 | Iteration number: [2440/4518] 54% | Training loss: 0.6870309660424951
Epoch: 97 | Iteration number: [2450/4518] 54% | Training loss: 0.6870298569543021
Epoch: 97 | Iteration number: [2460/4518] 54% | Training loss: 0.6870300364445865
Epoch: 97 | Iteration number: [2470/4518] 54% | Training loss: 0.6870314754455196
Epoch: 97 | Iteration number: [2480/4518] 54% | Training loss: 0.6870273912625928
Epoch: 97 | Iteration number: [2490/4518] 55% | Training loss: 0.6870285796113761
Epoch: 97 | Iteration number: [2500/4518] 55% | Training loss: 0.6870316042423248
Epoch: 97 | Iteration number: [2510/4518] 55% | Training loss: 0.6870267393342052
Epoch: 97 | Iteration number: [2520/4518] 55% | Training loss: 0.6870292678711907
Epoch: 97 | Iteration number: [2530/4518] 55% | Training loss: 0.6870257848807474
Epoch: 97 | Iteration number: [2540/4518] 56% | Training loss: 0.687025313959347
Epoch: 97 | Iteration number: [2550/4518] 56% | Training loss: 0.6870259648210862
Epoch: 97 | Iteration number: [2560/4518] 56% | Training loss: 0.6870220784330741
Epoch: 97 | Iteration number: [2570/4518] 56% | Training loss: 0.6870184460038805
Epoch: 97 | Iteration number: [2580/4518] 57% | Training loss: 0.687018514464992
Epoch: 97 | Iteration number: [2590/4518] 57% | Training loss: 0.6870116732065282
Epoch: 97 | Iteration number: [2600/4518] 57% | Training loss: 0.6870117140962527
Epoch: 97 | Iteration number: [2610/4518] 57% | Training loss: 0.6870172670517845
Epoch: 97 | Iteration number: [2620/4518] 57% | Training loss: 0.6870169892793393
Epoch: 97 | Iteration number: [2630/4518] 58% | Training loss: 0.6870155604619944
Epoch: 97 | Iteration number: [2640/4518] 58% | Training loss: 0.6870119864516187
Epoch: 97 | Iteration number: [2650/4518] 58% | Training loss: 0.6870055304833178
Epoch: 97 | Iteration number: [2660/4518] 58% | Training loss: 0.6869994706005083
Epoch: 97 | Iteration number: [2670/4518] 59% | Training loss: 0.686996868420183
Epoch: 97 | Iteration number: [2680/4518] 59% | Training loss: 0.6870014756028332
Epoch: 97 | Iteration number: [2690/4518] 59% | Training loss: 0.6869982215773217
Epoch: 97 | Iteration number: [2700/4518] 59% | Training loss: 0.6869924799601237
Epoch: 97 | Iteration number: [2710/4518] 59% | Training loss: 0.6869910553372655
Epoch: 97 | Iteration number: [2720/4518] 60% | Training loss: 0.6869894084904123
Epoch: 97 | Iteration number: [2730/4518] 60% | Training loss: 0.6869921298472436
Epoch: 97 | Iteration number: [2740/4518] 60% | Training loss: 0.6869950788081998
Epoch: 97 | Iteration number: [2750/4518] 60% | Training loss: 0.6869981206763874
Epoch: 97 | Iteration number: [2760/4518] 61% | Training loss: 0.6869948933953824
Epoch: 97 | Iteration number: [2770/4518] 61% | Training loss: 0.6869954084661463
Epoch: 97 | Iteration number: [2780/4518] 61% | Training loss: 0.6870000961873172
Epoch: 97 | Iteration number: [2790/4518] 61% | Training loss: 0.6870023476607483
Epoch: 97 | Iteration number: [2800/4518] 61% | Training loss: 0.6870022439956665
Epoch: 97 | Iteration number: [2810/4518] 62% | Training loss: 0.687002495599387
Epoch: 97 | Iteration number: [2820/4518] 62% | Training loss: 0.6870064928599283
Epoch: 97 | Iteration number: [2830/4518] 62% | Training loss: 0.6870058833078445
Epoch: 97 | Iteration number: [2840/4518] 62% | Training loss: 0.6870041626649843
Epoch: 97 | Iteration number: [2850/4518] 63% | Training loss: 0.6870028062870628
Epoch: 97 | Iteration number: [2860/4518] 63% | Training loss: 0.6870022671414422
Epoch: 97 | Iteration number: [2870/4518] 63% | Training loss: 0.6869962823307888
Epoch: 97 | Iteration number: [2880/4518] 63% | Training loss: 0.6869960273512535
Epoch: 97 | Iteration number: [2890/4518] 63% | Training loss: 0.6869944076843327
Epoch: 97 | Iteration number: [2900/4518] 64% | Training loss: 0.686990690847923
Epoch: 97 | Iteration number: [2910/4518] 64% | Training loss: 0.6869923657363223
Epoch: 97 | Iteration number: [2920/4518] 64% | Training loss: 0.6869896796468186
Epoch: 97 | Iteration number: [2930/4518] 64% | Training loss: 0.6869895522301515
Epoch: 97 | Iteration number: [2940/4518] 65% | Training loss: 0.6869905581685151
Epoch: 97 | Iteration number: [2950/4518] 65% | Training loss: 0.6869860591928838
Epoch: 97 | Iteration number: [2960/4518] 65% | Training loss: 0.6869838372275636
Epoch: 97 | Iteration number: [2970/4518] 65% | Training loss: 0.686982605694119
Epoch: 97 | Iteration number: [2980/4518] 65% | Training loss: 0.6869816027031649
Epoch: 97 | Iteration number: [2990/4518] 66% | Training loss: 0.6869777723698313
Epoch: 97 | Iteration number: [3000/4518] 66% | Training loss: 0.6869776269594828
Epoch: 97 | Iteration number: [3010/4518] 66% | Training loss: 0.6869759974685619
Epoch: 97 | Iteration number: [3020/4518] 66% | Training loss: 0.6869746385425921
Epoch: 97 | Iteration number: [3030/4518] 67% | Training loss: 0.6869738530994642
Epoch: 97 | Iteration number: [3040/4518] 67% | Training loss: 0.6869725643412063
Epoch: 97 | Iteration number: [3050/4518] 67% | Training loss: 0.6869743709876889
Epoch: 97 | Iteration number: [3060/4518] 67% | Training loss: 0.6869728365365196
Epoch: 97 | Iteration number: [3070/4518] 67% | Training loss: 0.6869727639693779
Epoch: 97 | Iteration number: [3080/4518] 68% | Training loss: 0.6869706263983405
Epoch: 97 | Iteration number: [3090/4518] 68% | Training loss: 0.686967265297294
Epoch: 97 | Iteration number: [3100/4518] 68% | Training loss: 0.6869686209001848
Epoch: 97 | Iteration number: [3110/4518] 68% | Training loss: 0.6869689796898526
Epoch: 97 | Iteration number: [3120/4518] 69% | Training loss: 0.6869671246180168
Epoch: 97 | Iteration number: [3130/4518] 69% | Training loss: 0.6869698910286632
Epoch: 97 | Iteration number: [3140/4518] 69% | Training loss: 0.6869697041572279
Epoch: 97 | Iteration number: [3150/4518] 69% | Training loss: 0.686968011307338
Epoch: 97 | Iteration number: [3160/4518] 69% | Training loss: 0.6869686320801325
Epoch: 97 | Iteration number: [3170/4518] 70% | Training loss: 0.6869635746494077
Epoch: 97 | Iteration number: [3180/4518] 70% | Training loss: 0.6869652365176183
Epoch: 97 | Iteration number: [3190/4518] 70% | Training loss: 0.6869627327380883
Epoch: 97 | Iteration number: [3200/4518] 70% | Training loss: 0.6869602901116013
Epoch: 97 | Iteration number: [3210/4518] 71% | Training loss: 0.6869549432090509
Epoch: 97 | Iteration number: [3220/4518] 71% | Training loss: 0.6869557201121905
Epoch: 97 | Iteration number: [3230/4518] 71% | Training loss: 0.6869565423059021
Epoch: 97 | Iteration number: [3240/4518] 71% | Training loss: 0.6869542370607824
Epoch: 97 | Iteration number: [3250/4518] 71% | Training loss: 0.6869488944273728
Epoch: 97 | Iteration number: [3260/4518] 72% | Training loss: 0.6869494519716391
Epoch: 97 | Iteration number: [3270/4518] 72% | Training loss: 0.6869482139928625
Epoch: 97 | Iteration number: [3280/4518] 72% | Training loss: 0.6869515751920096
Epoch: 97 | Iteration number: [3290/4518] 72% | Training loss: 0.6869541576024609
Epoch: 97 | Iteration number: [3300/4518] 73% | Training loss: 0.6869501614570618
Epoch: 97 | Iteration number: [3310/4518] 73% | Training loss: 0.6869445534631204
Epoch: 97 | Iteration number: [3320/4518] 73% | Training loss: 0.6869420037571207
Epoch: 97 | Iteration number: [3330/4518] 73% | Training loss: 0.6869409768252044
Epoch: 97 | Iteration number: [3340/4518] 73% | Training loss: 0.6869397835103338
Epoch: 97 | Iteration number: [3350/4518] 74% | Training loss: 0.6869396026810604
Epoch: 97 | Iteration number: [3360/4518] 74% | Training loss: 0.6869397728748264
Epoch: 97 | Iteration number: [3370/4518] 74% | Training loss: 0.6869411110877991
Epoch: 97 | Iteration number: [3380/4518] 74% | Training loss: 0.6869416634711993
Epoch: 97 | Iteration number: [3390/4518] 75% | Training loss: 0.6869390413472786
Epoch: 97 | Iteration number: [3400/4518] 75% | Training loss: 0.6869412397286471
Epoch: 97 | Iteration number: [3410/4518] 75% | Training loss: 0.6869381132538368
Epoch: 97 | Iteration number: [3420/4518] 75% | Training loss: 0.686935904691791
Epoch: 97 | Iteration number: [3430/4518] 75% | Training loss: 0.6869383240406437
Epoch: 97 | Iteration number: [3440/4518] 76% | Training loss: 0.6869393849095633
Epoch: 97 | Iteration number: [3450/4518] 76% | Training loss: 0.6869366037154543
Epoch: 97 | Iteration number: [3460/4518] 76% | Training loss: 0.6869354054245645
Epoch: 97 | Iteration number: [3470/4518] 76% | Training loss: 0.6869331224507489
Epoch: 97 | Iteration number: [3480/4518] 77% | Training loss: 0.6869352270303102
Epoch: 97 | Iteration number: [3490/4518] 77% | Training loss: 0.6869335428349951
Epoch: 97 | Iteration number: [3500/4518] 77% | Training loss: 0.6869331062521253
Epoch: 97 | Iteration number: [3510/4518] 77% | Training loss: 0.6869337313365392
Epoch: 97 | Iteration number: [3520/4518] 77% | Training loss: 0.6869295024567029
Epoch: 97 | Iteration number: [3530/4518] 78% | Training loss: 0.6869263099543433
Epoch: 97 | Iteration number: [3540/4518] 78% | Training loss: 0.6869264107639507
Epoch: 97 | Iteration number: [3550/4518] 78% | Training loss: 0.6869295593886309
Epoch: 97 | Iteration number: [3560/4518] 78% | Training loss: 0.6869313340675964
Epoch: 97 | Iteration number: [3570/4518] 79% | Training loss: 0.6869259549289191
Epoch: 97 | Iteration number: [3580/4518] 79% | Training loss: 0.6869255261214752
Epoch: 97 | Iteration number: [3590/4518] 79% | Training loss: 0.6869260516505388
Epoch: 97 | Iteration number: [3600/4518] 79% | Training loss: 0.6869291064639886
Epoch: 97 | Iteration number: [3610/4518] 79% | Training loss: 0.6869305537513088
Epoch: 97 | Iteration number: [3620/4518] 80% | Training loss: 0.6869325312296989
Epoch: 97 | Iteration number: [3630/4518] 80% | Training loss: 0.6869306954963148
Epoch: 97 | Iteration number: [3640/4518] 80% | Training loss: 0.6869301617964283
Epoch: 97 | Iteration number: [3650/4518] 80% | Training loss: 0.6869316404812956
Epoch: 97 | Iteration number: [3660/4518] 81% | Training loss: 0.6869331686548849
Epoch: 97 | Iteration number: [3670/4518] 81% | Training loss: 0.6869321957758402
Epoch: 97 | Iteration number: [3680/4518] 81% | Training loss: 0.6869298031148703
Epoch: 97 | Iteration number: [3690/4518] 81% | Training loss: 0.6869305914010458
Epoch: 97 | Iteration number: [3700/4518] 81% | Training loss: 0.6869297716424272
Epoch: 97 | Iteration number: [3710/4518] 82% | Training loss: 0.6869280440306085
Epoch: 97 | Iteration number: [3720/4518] 82% | Training loss: 0.6869301959872246
Epoch: 97 | Iteration number: [3730/4518] 82% | Training loss: 0.686926726889035
Epoch: 97 | Iteration number: [3740/4518] 82% | Training loss: 0.6869233935752654
Epoch: 97 | Iteration number: [3750/4518] 83% | Training loss: 0.6869213375250498
Epoch: 97 | Iteration number: [3760/4518] 83% | Training loss: 0.6869228885845935
Epoch: 97 | Iteration number: [3770/4518] 83% | Training loss: 0.6869179752524399
Epoch: 97 | Iteration number: [3780/4518] 83% | Training loss: 0.6869162274258477
Epoch: 97 | Iteration number: [3790/4518] 83% | Training loss: 0.6869129206700186
Epoch: 97 | Iteration number: [3800/4518] 84% | Training loss: 0.6869150005359399
Epoch: 97 | Iteration number: [3810/4518] 84% | Training loss: 0.686916925525415
Epoch: 97 | Iteration number: [3820/4518] 84% | Training loss: 0.6869143437964754
Epoch: 97 | Iteration number: [3830/4518] 84% | Training loss: 0.6869129353030232
Epoch: 97 | Iteration number: [3840/4518] 84% | Training loss: 0.6869135922907541
Epoch: 97 | Iteration number: [3850/4518] 85% | Training loss: 0.6869157588791538
Epoch: 97 | Iteration number: [3860/4518] 85% | Training loss: 0.686916377677201
Epoch: 97 | Iteration number: [3870/4518] 85% | Training loss: 0.6869168369036929
Epoch: 97 | Iteration number: [3880/4518] 85% | Training loss: 0.6869177378637275
Epoch: 97 | Iteration number: [3890/4518] 86% | Training loss: 0.6869196501060133
Epoch: 97 | Iteration number: [3900/4518] 86% | Training loss: 0.6869197764763465
Epoch: 97 | Iteration number: [3910/4518] 86% | Training loss: 0.686913536104095
Epoch: 97 | Iteration number: [3920/4518] 86% | Training loss: 0.686913395353726
Epoch: 97 | Iteration number: [3930/4518] 86% | Training loss: 0.6869149779848773
Epoch: 97 | Iteration number: [3940/4518] 87% | Training loss: 0.6869132058269481
Epoch: 97 | Iteration number: [3950/4518] 87% | Training loss: 0.6869128327430049
Epoch: 97 | Iteration number: [3960/4518] 87% | Training loss: 0.6869108090798061
Epoch: 97 | Iteration number: [3970/4518] 87% | Training loss: 0.6869133556519708
Epoch: 97 | Iteration number: [3980/4518] 88% | Training loss: 0.6869128013226256
Epoch: 97 | Iteration number: [3990/4518] 88% | Training loss: 0.6869140423031379
Epoch: 97 | Iteration number: [4000/4518] 88% | Training loss: 0.6869133584201336
Epoch: 97 | Iteration number: [4010/4518] 88% | Training loss: 0.6869141762987931
Epoch: 97 | Iteration number: [4020/4518] 88% | Training loss: 0.6869157109687577
Epoch: 97 | Iteration number: [4030/4518] 89% | Training loss: 0.6869158243866771
Epoch: 97 | Iteration number: [4040/4518] 89% | Training loss: 0.6869153898393754
Epoch: 97 | Iteration number: [4050/4518] 89% | Training loss: 0.6869129530588786
Epoch: 97 | Iteration number: [4060/4518] 89% | Training loss: 0.6869143185944393
Epoch: 97 | Iteration number: [4070/4518] 90% | Training loss: 0.6869116611064798
Epoch: 97 | Iteration number: [4080/4518] 90% | Training loss: 0.6869147854838885
Epoch: 97 | Iteration number: [4090/4518] 90% | Training loss: 0.6869151589631451
Epoch: 97 | Iteration number: [4100/4518] 90% | Training loss: 0.6869151566086746
Epoch: 97 | Iteration number: [4110/4518] 90% | Training loss: 0.6869126764382179
Epoch: 97 | Iteration number: [4120/4518] 91% | Training loss: 0.6869123519334979
Epoch: 97 | Iteration number: [4130/4518] 91% | Training loss: 0.686909853575016
Epoch: 97 | Iteration number: [4140/4518] 91% | Training loss: 0.6869093679143611
Epoch: 97 | Iteration number: [4150/4518] 91% | Training loss: 0.6869115717152515
Epoch: 97 | Iteration number: [4160/4518] 92% | Training loss: 0.6869099510690341
Epoch: 97 | Iteration number: [4170/4518] 92% | Training loss: 0.6869078553694901
Epoch: 97 | Iteration number: [4180/4518] 92% | Training loss: 0.6869055502009734
Epoch: 97 | Iteration number: [4190/4518] 92% | Training loss: 0.6869052214525765
Epoch: 97 | Iteration number: [4200/4518] 92% | Training loss: 0.6869057686272122
Epoch: 97 | Iteration number: [4210/4518] 93% | Training loss: 0.6869078494307548
Epoch: 97 | Iteration number: [4220/4518] 93% | Training loss: 0.6869060714945409
Epoch: 97 | Iteration number: [4230/4518] 93% | Training loss: 0.6869055180684894
Epoch: 97 | Iteration number: [4240/4518] 93% | Training loss: 0.6869078938972275
Epoch: 97 | Iteration number: [4250/4518] 94% | Training loss: 0.6869093168483061
Epoch: 97 | Iteration number: [4260/4518] 94% | Training loss: 0.6869085927944228
Epoch: 97 | Iteration number: [4270/4518] 94% | Training loss: 0.6869058455600113
Epoch: 97 | Iteration number: [4280/4518] 94% | Training loss: 0.686906994280414
Epoch: 97 | Iteration number: [4290/4518] 94% | Training loss: 0.6869081784656276
Epoch: 97 | Iteration number: [4300/4518] 95% | Training loss: 0.686908769177836
Epoch: 97 | Iteration number: [4310/4518] 95% | Training loss: 0.6869103302673508
Epoch: 97 | Iteration number: [4320/4518] 95% | Training loss: 0.686908903731792
Epoch: 97 | Iteration number: [4330/4518] 95% | Training loss: 0.6869105405124726
Epoch: 97 | Iteration number: [4340/4518] 96% | Training loss: 0.6869113567100692
Epoch: 97 | Iteration number: [4350/4518] 96% | Training loss: 0.6869076442855528
Epoch: 97 | Iteration number: [4360/4518] 96% | Training loss: 0.6869101882117604
Epoch: 97 | Iteration number: [4370/4518] 96% | Training loss: 0.6869086407414836
Epoch: 97 | Iteration number: [4380/4518] 96% | Training loss: 0.6869054304138166
Epoch: 97 | Iteration number: [4390/4518] 97% | Training loss: 0.6869034468448787
Epoch: 97 | Iteration number: [4400/4518] 97% | Training loss: 0.6869041547043757
Epoch: 97 | Iteration number: [4410/4518] 97% | Training loss: 0.686904317938011
Epoch: 97 | Iteration number: [4420/4518] 97% | Training loss: 0.6869032709576965
Epoch: 97 | Iteration number: [4430/4518] 98% | Training loss: 0.6869041403179513
Epoch: 97 | Iteration number: [4440/4518] 98% | Training loss: 0.6869030593349053
Epoch: 97 | Iteration number: [4450/4518] 98% | Training loss: 0.6869050980283973
Epoch: 97 | Iteration number: [4460/4518] 98% | Training loss: 0.6869023198905012
Epoch: 97 | Iteration number: [4470/4518] 98% | Training loss: 0.6869030057850567
Epoch: 97 | Iteration number: [4480/4518] 99% | Training loss: 0.6869030423063253
Epoch: 97 | Iteration number: [4490/4518] 99% | Training loss: 0.6869031464867709
Epoch: 97 | Iteration number: [4500/4518] 99% | Training loss: 0.6869026052951813
Epoch: 97 | Iteration number: [4510/4518] 99% | Training loss: 0.6869006252738166

 End of epoch: 97 | Train Loss: 0.6867488948657166 | Training Time: 640 

 End of epoch: 97 | Eval Loss: 0.6897373077820759 | Evaluating Time: 17 
Epoch: 98 | Iteration number: [10/4518] 0% | Training loss: 0.7574264883995057
Epoch: 98 | Iteration number: [20/4518] 0% | Training loss: 0.722799563407898
Epoch: 98 | Iteration number: [30/4518] 0% | Training loss: 0.7108567635218302
Epoch: 98 | Iteration number: [40/4518] 0% | Training loss: 0.7047228306531906
Epoch: 98 | Iteration number: [50/4518] 1% | Training loss: 0.7008692705631256
Epoch: 98 | Iteration number: [60/4518] 1% | Training loss: 0.698404868443807
Epoch: 98 | Iteration number: [70/4518] 1% | Training loss: 0.6966105410030909
Epoch: 98 | Iteration number: [80/4518] 1% | Training loss: 0.6953036844730377
Epoch: 98 | Iteration number: [90/4518] 1% | Training loss: 0.6944327387544844
Epoch: 98 | Iteration number: [100/4518] 2% | Training loss: 0.6936778980493545
Epoch: 98 | Iteration number: [110/4518] 2% | Training loss: 0.6930525069886988
Epoch: 98 | Iteration number: [120/4518] 2% | Training loss: 0.6926020140449206
Epoch: 98 | Iteration number: [130/4518] 2% | Training loss: 0.6921444283081934
Epoch: 98 | Iteration number: [140/4518] 3% | Training loss: 0.6916598447731563
Epoch: 98 | Iteration number: [150/4518] 3% | Training loss: 0.6913838211695353
Epoch: 98 | Iteration number: [160/4518] 3% | Training loss: 0.6911165852099657
Epoch: 98 | Iteration number: [170/4518] 3% | Training loss: 0.6908123054925133
Epoch: 98 | Iteration number: [180/4518] 3% | Training loss: 0.6906199269824558
Epoch: 98 | Iteration number: [190/4518] 4% | Training loss: 0.6904117794413316
Epoch: 98 | Iteration number: [200/4518] 4% | Training loss: 0.690257485806942
Epoch: 98 | Iteration number: [210/4518] 4% | Training loss: 0.6900867839654287
Epoch: 98 | Iteration number: [220/4518] 4% | Training loss: 0.6899513919245113
Epoch: 98 | Iteration number: [230/4518] 5% | Training loss: 0.6898219976736152
Epoch: 98 | Iteration number: [240/4518] 5% | Training loss: 0.6896191487709681
Epoch: 98 | Iteration number: [250/4518] 5% | Training loss: 0.6894991357326508
Epoch: 98 | Iteration number: [260/4518] 5% | Training loss: 0.6894061464529772
Epoch: 98 | Iteration number: [270/4518] 5% | Training loss: 0.6893086031631187
Epoch: 98 | Iteration number: [280/4518] 6% | Training loss: 0.6892139370952334
Epoch: 98 | Iteration number: [290/4518] 6% | Training loss: 0.6891212342114285
Epoch: 98 | Iteration number: [300/4518] 6% | Training loss: 0.6890537915627162
Epoch: 98 | Iteration number: [310/4518] 6% | Training loss: 0.6889710368648652
Epoch: 98 | Iteration number: [320/4518] 7% | Training loss: 0.68891889359802
Epoch: 98 | Iteration number: [330/4518] 7% | Training loss: 0.6888478304400588
Epoch: 98 | Iteration number: [340/4518] 7% | Training loss: 0.688824844009736
Epoch: 98 | Iteration number: [350/4518] 7% | Training loss: 0.6887808568137033
Epoch: 98 | Iteration number: [360/4518] 7% | Training loss: 0.6887231328421168
Epoch: 98 | Iteration number: [370/4518] 8% | Training loss: 0.6886927746437691
Epoch: 98 | Iteration number: [380/4518] 8% | Training loss: 0.6886145954069338
Epoch: 98 | Iteration number: [390/4518] 8% | Training loss: 0.6885553045150561
Epoch: 98 | Iteration number: [400/4518] 8% | Training loss: 0.688491667509079
Epoch: 98 | Iteration number: [410/4518] 9% | Training loss: 0.6884711806367083
Epoch: 98 | Iteration number: [420/4518] 9% | Training loss: 0.6884426097075145
Epoch: 98 | Iteration number: [430/4518] 9% | Training loss: 0.6884186721125315
Epoch: 98 | Iteration number: [440/4518] 9% | Training loss: 0.6883880838751792
Epoch: 98 | Iteration number: [450/4518] 9% | Training loss: 0.688362477487988
Epoch: 98 | Iteration number: [460/4518] 10% | Training loss: 0.6883379953063052
Epoch: 98 | Iteration number: [470/4518] 10% | Training loss: 0.688315564647634
Epoch: 98 | Iteration number: [480/4518] 10% | Training loss: 0.6882730575899283
Epoch: 98 | Iteration number: [490/4518] 10% | Training loss: 0.6882620355304406
Epoch: 98 | Iteration number: [500/4518] 11% | Training loss: 0.6882240872383117
Epoch: 98 | Iteration number: [510/4518] 11% | Training loss: 0.6882003431226693
Epoch: 98 | Iteration number: [520/4518] 11% | Training loss: 0.6881932666668525
Epoch: 98 | Iteration number: [530/4518] 11% | Training loss: 0.6881643329026564
Epoch: 98 | Iteration number: [540/4518] 11% | Training loss: 0.6881603757540385
Epoch: 98 | Iteration number: [550/4518] 12% | Training loss: 0.6881387626041066
Epoch: 98 | Iteration number: [560/4518] 12% | Training loss: 0.6881246581673622
Epoch: 98 | Iteration number: [570/4518] 12% | Training loss: 0.6881004331404703
Epoch: 98 | Iteration number: [580/4518] 12% | Training loss: 0.688079197036809
Epoch: 98 | Iteration number: [590/4518] 13% | Training loss: 0.6880613800832781
Epoch: 98 | Iteration number: [600/4518] 13% | Training loss: 0.6880351575215657
Epoch: 98 | Iteration number: [610/4518] 13% | Training loss: 0.6880109519254965
Epoch: 98 | Iteration number: [620/4518] 13% | Training loss: 0.6880063202111951
Epoch: 98 | Iteration number: [630/4518] 13% | Training loss: 0.687984493800572
Epoch: 98 | Iteration number: [640/4518] 14% | Training loss: 0.6879651298746466
Epoch: 98 | Iteration number: [650/4518] 14% | Training loss: 0.6879528436293969
Epoch: 98 | Iteration number: [660/4518] 14% | Training loss: 0.6879425236673066
Epoch: 98 | Iteration number: [670/4518] 14% | Training loss: 0.6879177270540551
Epoch: 98 | Iteration number: [680/4518] 15% | Training loss: 0.6879145916770486
Epoch: 98 | Iteration number: [690/4518] 15% | Training loss: 0.6879027488438979
Epoch: 98 | Iteration number: [700/4518] 15% | Training loss: 0.6878967829261508
Epoch: 98 | Iteration number: [710/4518] 15% | Training loss: 0.6878796816711694
Epoch: 98 | Iteration number: [720/4518] 15% | Training loss: 0.6878378843267758
Epoch: 98 | Iteration number: [730/4518] 16% | Training loss: 0.6878496231281594
Epoch: 98 | Iteration number: [740/4518] 16% | Training loss: 0.6878240605463852
Epoch: 98 | Iteration number: [750/4518] 16% | Training loss: 0.6878120709260305
Epoch: 98 | Iteration number: [760/4518] 16% | Training loss: 0.6877977037900372
Epoch: 98 | Iteration number: [770/4518] 17% | Training loss: 0.6877941291827661
Epoch: 98 | Iteration number: [780/4518] 17% | Training loss: 0.6877717219102077
Epoch: 98 | Iteration number: [790/4518] 17% | Training loss: 0.687759848561468
Epoch: 98 | Iteration number: [800/4518] 17% | Training loss: 0.6877423258870841
Epoch: 98 | Iteration number: [810/4518] 17% | Training loss: 0.6877272359382959
Epoch: 98 | Iteration number: [820/4518] 18% | Training loss: 0.6877113358276646
Epoch: 98 | Iteration number: [830/4518] 18% | Training loss: 0.6876921703298408
Epoch: 98 | Iteration number: [840/4518] 18% | Training loss: 0.6876742477218311
Epoch: 98 | Iteration number: [850/4518] 18% | Training loss: 0.6876661858137916
Epoch: 98 | Iteration number: [860/4518] 19% | Training loss: 0.6876314629649007
Epoch: 98 | Iteration number: [870/4518] 19% | Training loss: 0.6876139620939891
Epoch: 98 | Iteration number: [880/4518] 19% | Training loss: 0.6876168528741057
Epoch: 98 | Iteration number: [890/4518] 19% | Training loss: 0.6876271755507822
Epoch: 98 | Iteration number: [900/4518] 19% | Training loss: 0.6876175955269072
Epoch: 98 | Iteration number: [910/4518] 20% | Training loss: 0.6875968992710113
Epoch: 98 | Iteration number: [920/4518] 20% | Training loss: 0.6875903312926707
Epoch: 98 | Iteration number: [930/4518] 20% | Training loss: 0.6875820821331393
Epoch: 98 | Iteration number: [940/4518] 20% | Training loss: 0.6875810843832949
Epoch: 98 | Iteration number: [950/4518] 21% | Training loss: 0.6875630059995149
Epoch: 98 | Iteration number: [960/4518] 21% | Training loss: 0.6875490413357814
Epoch: 98 | Iteration number: [970/4518] 21% | Training loss: 0.6875302533513492
Epoch: 98 | Iteration number: [980/4518] 21% | Training loss: 0.6875167215357021
Epoch: 98 | Iteration number: [990/4518] 21% | Training loss: 0.6875021556411126
Epoch: 98 | Iteration number: [1000/4518] 22% | Training loss: 0.6874942061901093
Epoch: 98 | Iteration number: [1010/4518] 22% | Training loss: 0.6874740832512921
Epoch: 98 | Iteration number: [1020/4518] 22% | Training loss: 0.6874629941641116
Epoch: 98 | Iteration number: [1030/4518] 22% | Training loss: 0.6874586605331273
Epoch: 98 | Iteration number: [1040/4518] 23% | Training loss: 0.6874475901516585
Epoch: 98 | Iteration number: [1050/4518] 23% | Training loss: 0.6874312267417
Epoch: 98 | Iteration number: [1060/4518] 23% | Training loss: 0.6874161659546618
Epoch: 98 | Iteration number: [1070/4518] 23% | Training loss: 0.6874116153360528
Epoch: 98 | Iteration number: [1080/4518] 23% | Training loss: 0.6874042082164022
Epoch: 98 | Iteration number: [1090/4518] 24% | Training loss: 0.6873832444532202
Epoch: 98 | Iteration number: [1100/4518] 24% | Training loss: 0.6873818509687077
Epoch: 98 | Iteration number: [1110/4518] 24% | Training loss: 0.6873635758687784
Epoch: 98 | Iteration number: [1120/4518] 24% | Training loss: 0.687354300809758
Epoch: 98 | Iteration number: [1130/4518] 25% | Training loss: 0.6873410586234743
Epoch: 98 | Iteration number: [1140/4518] 25% | Training loss: 0.6873443515154354
Epoch: 98 | Iteration number: [1150/4518] 25% | Training loss: 0.687344301265219
Epoch: 98 | Iteration number: [1160/4518] 25% | Training loss: 0.6873263705393363
Epoch: 98 | Iteration number: [1170/4518] 25% | Training loss: 0.6873274573912987
Epoch: 98 | Iteration number: [1180/4518] 26% | Training loss: 0.6873238244299161
Epoch: 98 | Iteration number: [1190/4518] 26% | Training loss: 0.687318491134323
Epoch: 98 | Iteration number: [1200/4518] 26% | Training loss: 0.6873113725086053
Epoch: 98 | Iteration number: [1210/4518] 26% | Training loss: 0.6873034392014022
Epoch: 98 | Iteration number: [1220/4518] 27% | Training loss: 0.6873010568442892
Epoch: 98 | Iteration number: [1230/4518] 27% | Training loss: 0.6872873745313505
Epoch: 98 | Iteration number: [1240/4518] 27% | Training loss: 0.6872916299008553
Epoch: 98 | Iteration number: [1250/4518] 27% | Training loss: 0.6872834583759307
Epoch: 98 | Iteration number: [1260/4518] 27% | Training loss: 0.6872746723511862
Epoch: 98 | Iteration number: [1270/4518] 28% | Training loss: 0.6872758551376073
Epoch: 98 | Iteration number: [1280/4518] 28% | Training loss: 0.6872811669949442
Epoch: 98 | Iteration number: [1290/4518] 28% | Training loss: 0.6872752757497537
Epoch: 98 | Iteration number: [1300/4518] 28% | Training loss: 0.6872725563324414
Epoch: 98 | Iteration number: [1310/4518] 28% | Training loss: 0.6872683550565297
Epoch: 98 | Iteration number: [1320/4518] 29% | Training loss: 0.6872801367983673
Epoch: 98 | Iteration number: [1330/4518] 29% | Training loss: 0.6872822274839071
Epoch: 98 | Iteration number: [1340/4518] 29% | Training loss: 0.6872852437086959
Epoch: 98 | Iteration number: [1350/4518] 29% | Training loss: 0.6872742542514094
Epoch: 98 | Iteration number: [1360/4518] 30% | Training loss: 0.6872649871689431
Epoch: 98 | Iteration number: [1370/4518] 30% | Training loss: 0.6872525239512868
Epoch: 98 | Iteration number: [1380/4518] 30% | Training loss: 0.6872367128945779
Epoch: 98 | Iteration number: [1390/4518] 30% | Training loss: 0.6872305430096688
Epoch: 98 | Iteration number: [1400/4518] 30% | Training loss: 0.6872282422440392
Epoch: 98 | Iteration number: [1410/4518] 31% | Training loss: 0.6872202063283176
Epoch: 98 | Iteration number: [1420/4518] 31% | Training loss: 0.6872134979342072
Epoch: 98 | Iteration number: [1430/4518] 31% | Training loss: 0.6872154688918507
Epoch: 98 | Iteration number: [1440/4518] 31% | Training loss: 0.6872073964940177
Epoch: 98 | Iteration number: [1450/4518] 32% | Training loss: 0.6871993611598837
Epoch: 98 | Iteration number: [1460/4518] 32% | Training loss: 0.6871986079297654
Epoch: 98 | Iteration number: [1470/4518] 32% | Training loss: 0.6872014090722921
Epoch: 98 | Iteration number: [1480/4518] 32% | Training loss: 0.6871961856613288
Epoch: 98 | Iteration number: [1490/4518] 32% | Training loss: 0.6871911266106087
Epoch: 98 | Iteration number: [1500/4518] 33% | Training loss: 0.6871915998061499
Epoch: 98 | Iteration number: [1510/4518] 33% | Training loss: 0.6871941070288222
Epoch: 98 | Iteration number: [1520/4518] 33% | Training loss: 0.687191460987455
Epoch: 98 | Iteration number: [1530/4518] 33% | Training loss: 0.6871888473532558
Epoch: 98 | Iteration number: [1540/4518] 34% | Training loss: 0.6871844617190299
Epoch: 98 | Iteration number: [1550/4518] 34% | Training loss: 0.6871705608983194
Epoch: 98 | Iteration number: [1560/4518] 34% | Training loss: 0.6871717624557324
Epoch: 98 | Iteration number: [1570/4518] 34% | Training loss: 0.6871809874370599
Epoch: 98 | Iteration number: [1580/4518] 34% | Training loss: 0.6871686332965199
Epoch: 98 | Iteration number: [1590/4518] 35% | Training loss: 0.6871660530942041
Epoch: 98 | Iteration number: [1600/4518] 35% | Training loss: 0.687163345515728
Epoch: 98 | Iteration number: [1610/4518] 35% | Training loss: 0.6871520387830201
Epoch: 98 | Iteration number: [1620/4518] 35% | Training loss: 0.6871422786403585
Epoch: 98 | Iteration number: [1630/4518] 36% | Training loss: 0.6871367661133866
Epoch: 98 | Iteration number: [1640/4518] 36% | Training loss: 0.6871382507245715
Epoch: 98 | Iteration number: [1650/4518] 36% | Training loss: 0.6871378647558617
Epoch: 98 | Iteration number: [1660/4518] 36% | Training loss: 0.6871363003569914
Epoch: 98 | Iteration number: [1670/4518] 36% | Training loss: 0.6871352456286995
Epoch: 98 | Iteration number: [1680/4518] 37% | Training loss: 0.6871353328582787
Epoch: 98 | Iteration number: [1690/4518] 37% | Training loss: 0.6871312256395464
Epoch: 98 | Iteration number: [1700/4518] 37% | Training loss: 0.6871271856041515
Epoch: 98 | Iteration number: [1710/4518] 37% | Training loss: 0.6871204701780576
Epoch: 98 | Iteration number: [1720/4518] 38% | Training loss: 0.6871234159830004
Epoch: 98 | Iteration number: [1730/4518] 38% | Training loss: 0.6871218014314685
Epoch: 98 | Iteration number: [1740/4518] 38% | Training loss: 0.6871134367482415
Epoch: 98 | Iteration number: [1750/4518] 38% | Training loss: 0.6871071032796587
Epoch: 98 | Iteration number: [1760/4518] 38% | Training loss: 0.6871007167818871
Epoch: 98 | Iteration number: [1770/4518] 39% | Training loss: 0.6870961603135038
Epoch: 98 | Iteration number: [1780/4518] 39% | Training loss: 0.6870887921767288
Epoch: 98 | Iteration number: [1790/4518] 39% | Training loss: 0.6870831598449686
Epoch: 98 | Iteration number: [1800/4518] 39% | Training loss: 0.6870811950829294
Epoch: 98 | Iteration number: [1810/4518] 40% | Training loss: 0.6870777373485144
Epoch: 98 | Iteration number: [1820/4518] 40% | Training loss: 0.6870761564799718
Epoch: 98 | Iteration number: [1830/4518] 40% | Training loss: 0.6870697454350894
Epoch: 98 | Iteration number: [1840/4518] 40% | Training loss: 0.6870739239065543
Epoch: 98 | Iteration number: [1850/4518] 40% | Training loss: 0.687076512993993
Epoch: 98 | Iteration number: [1860/4518] 41% | Training loss: 0.6870813215932539
Epoch: 98 | Iteration number: [1870/4518] 41% | Training loss: 0.6870823134394253
Epoch: 98 | Iteration number: [1880/4518] 41% | Training loss: 0.6870840971457197
Epoch: 98 | Iteration number: [1890/4518] 41% | Training loss: 0.6870853426910583
Epoch: 98 | Iteration number: [1900/4518] 42% | Training loss: 0.6870795127592588
Epoch: 98 | Iteration number: [1910/4518] 42% | Training loss: 0.68707646921043
Epoch: 98 | Iteration number: [1920/4518] 42% | Training loss: 0.6870716897149881
Epoch: 98 | Iteration number: [1930/4518] 42% | Training loss: 0.6870726584770519
Epoch: 98 | Iteration number: [1940/4518] 42% | Training loss: 0.6870663134093137
Epoch: 98 | Iteration number: [1950/4518] 43% | Training loss: 0.6870703860429617
Epoch: 98 | Iteration number: [1960/4518] 43% | Training loss: 0.6870640173554421
Epoch: 98 | Iteration number: [1970/4518] 43% | Training loss: 0.6870605421550383
Epoch: 98 | Iteration number: [1980/4518] 43% | Training loss: 0.6870500109713487
Epoch: 98 | Iteration number: [1990/4518] 44% | Training loss: 0.6870512124282032
Epoch: 98 | Iteration number: [2000/4518] 44% | Training loss: 0.6870393154919148
Epoch: 98 | Iteration number: [2010/4518] 44% | Training loss: 0.6870367505657139
Epoch: 98 | Iteration number: [2020/4518] 44% | Training loss: 0.6870370160825182
Epoch: 98 | Iteration number: [2030/4518] 44% | Training loss: 0.6870337118362558
Epoch: 98 | Iteration number: [2040/4518] 45% | Training loss: 0.6870293555598633
Epoch: 98 | Iteration number: [2050/4518] 45% | Training loss: 0.6870197750010142
Epoch: 98 | Iteration number: [2060/4518] 45% | Training loss: 0.6870216389593569
Epoch: 98 | Iteration number: [2070/4518] 45% | Training loss: 0.6870208132670121
Epoch: 98 | Iteration number: [2080/4518] 46% | Training loss: 0.6870261702399988
Epoch: 98 | Iteration number: [2090/4518] 46% | Training loss: 0.6870288200070414
Epoch: 98 | Iteration number: [2100/4518] 46% | Training loss: 0.6870294872635887
Epoch: 98 | Iteration number: [2110/4518] 46% | Training loss: 0.6870206326952478
Epoch: 98 | Iteration number: [2120/4518] 46% | Training loss: 0.6870194010577112
Epoch: 98 | Iteration number: [2130/4518] 47% | Training loss: 0.6870183673822824
Epoch: 98 | Iteration number: [2140/4518] 47% | Training loss: 0.6870207525302316
Epoch: 98 | Iteration number: [2150/4518] 47% | Training loss: 0.6870143389147382
Epoch: 98 | Iteration number: [2160/4518] 47% | Training loss: 0.6870152792168989
Epoch: 98 | Iteration number: [2170/4518] 48% | Training loss: 0.6870097368268923
Epoch: 98 | Iteration number: [2180/4518] 48% | Training loss: 0.687008086038292
Epoch: 98 | Iteration number: [2190/4518] 48% | Training loss: 0.6870093191051048
Epoch: 98 | Iteration number: [2200/4518] 48% | Training loss: 0.6870053593949839
Epoch: 98 | Iteration number: [2210/4518] 48% | Training loss: 0.6870021055996148
Epoch: 98 | Iteration number: [2220/4518] 49% | Training loss: 0.6869998551972277
Epoch: 98 | Iteration number: [2230/4518] 49% | Training loss: 0.6870004147424826
Epoch: 98 | Iteration number: [2240/4518] 49% | Training loss: 0.6870017019499626
Epoch: 98 | Iteration number: [2250/4518] 49% | Training loss: 0.687009886900584
Epoch: 98 | Iteration number: [2260/4518] 50% | Training loss: 0.6870081765198075
Epoch: 98 | Iteration number: [2270/4518] 50% | Training loss: 0.6870081235133604
Epoch: 98 | Iteration number: [2280/4518] 50% | Training loss: 0.6870057907282261
Epoch: 98 | Iteration number: [2290/4518] 50% | Training loss: 0.687004916142168
Epoch: 98 | Iteration number: [2300/4518] 50% | Training loss: 0.6869975395047146
Epoch: 98 | Iteration number: [2310/4518] 51% | Training loss: 0.6869983538662716
Epoch: 98 | Iteration number: [2320/4518] 51% | Training loss: 0.6869993031538766
Epoch: 98 | Iteration number: [2330/4518] 51% | Training loss: 0.6869959853493605
Epoch: 98 | Iteration number: [2340/4518] 51% | Training loss: 0.6869913016119574
Epoch: 98 | Iteration number: [2350/4518] 52% | Training loss: 0.6869936971207883
Epoch: 98 | Iteration number: [2360/4518] 52% | Training loss: 0.6869934051723804
Epoch: 98 | Iteration number: [2370/4518] 52% | Training loss: 0.6869928648703209
Epoch: 98 | Iteration number: [2380/4518] 52% | Training loss: 0.6869899480783639
Epoch: 98 | Iteration number: [2390/4518] 52% | Training loss: 0.6869888349806414
Epoch: 98 | Iteration number: [2400/4518] 53% | Training loss: 0.6869880253573258
Epoch: 98 | Iteration number: [2410/4518] 53% | Training loss: 0.686986906696652
Epoch: 98 | Iteration number: [2420/4518] 53% | Training loss: 0.6869836813901081
Epoch: 98 | Iteration number: [2430/4518] 53% | Training loss: 0.6869815988795748
Epoch: 98 | Iteration number: [2440/4518] 54% | Training loss: 0.6869755938649178
Epoch: 98 | Iteration number: [2450/4518] 54% | Training loss: 0.686977831903769
Epoch: 98 | Iteration number: [2460/4518] 54% | Training loss: 0.6869769295298956
Epoch: 98 | Iteration number: [2470/4518] 54% | Training loss: 0.6869741939581357
Epoch: 98 | Iteration number: [2480/4518] 54% | Training loss: 0.6869709755384152
Epoch: 98 | Iteration number: [2490/4518] 55% | Training loss: 0.686971048226797
Epoch: 98 | Iteration number: [2500/4518] 55% | Training loss: 0.6869716254472733
Epoch: 98 | Iteration number: [2510/4518] 55% | Training loss: 0.6869710224558158
Epoch: 98 | Iteration number: [2520/4518] 55% | Training loss: 0.6869676452544
Epoch: 98 | Iteration number: [2530/4518] 55% | Training loss: 0.6869616670570826
Epoch: 98 | Iteration number: [2540/4518] 56% | Training loss: 0.6869604305019529
Epoch: 98 | Iteration number: [2550/4518] 56% | Training loss: 0.6869609664701948
Epoch: 98 | Iteration number: [2560/4518] 56% | Training loss: 0.6869622247992083
Epoch: 98 | Iteration number: [2570/4518] 56% | Training loss: 0.6869640374461965
Epoch: 98 | Iteration number: [2580/4518] 57% | Training loss: 0.6869633033294086
Epoch: 98 | Iteration number: [2590/4518] 57% | Training loss: 0.686965890441622
Epoch: 98 | Iteration number: [2600/4518] 57% | Training loss: 0.6869640725621811
Epoch: 98 | Iteration number: [2610/4518] 57% | Training loss: 0.686965095425931
Epoch: 98 | Iteration number: [2620/4518] 57% | Training loss: 0.6869671100651035
Epoch: 98 | Iteration number: [2630/4518] 58% | Training loss: 0.6869673745033859
Epoch: 98 | Iteration number: [2640/4518] 58% | Training loss: 0.6869659863186605
Epoch: 98 | Iteration number: [2650/4518] 58% | Training loss: 0.6869644058200548
Epoch: 98 | Iteration number: [2660/4518] 58% | Training loss: 0.6869637969293092
Epoch: 98 | Iteration number: [2670/4518] 59% | Training loss: 0.6869641418537397
Epoch: 98 | Iteration number: [2680/4518] 59% | Training loss: 0.6869654518677227
Epoch: 98 | Iteration number: [2690/4518] 59% | Training loss: 0.6869672965382998
Epoch: 98 | Iteration number: [2700/4518] 59% | Training loss: 0.6869671586045513
Epoch: 98 | Iteration number: [2710/4518] 59% | Training loss: 0.6869673192501068
Epoch: 98 | Iteration number: [2720/4518] 60% | Training loss: 0.6869650602778967
Epoch: 98 | Iteration number: [2730/4518] 60% | Training loss: 0.6869629851846031
Epoch: 98 | Iteration number: [2740/4518] 60% | Training loss: 0.6869625309305469
Epoch: 98 | Iteration number: [2750/4518] 60% | Training loss: 0.6869597716981715
Epoch: 98 | Iteration number: [2760/4518] 61% | Training loss: 0.6869606648450313
Epoch: 98 | Iteration number: [2770/4518] 61% | Training loss: 0.6869590819312347
Epoch: 98 | Iteration number: [2780/4518] 61% | Training loss: 0.6869629954905818
Epoch: 98 | Iteration number: [2790/4518] 61% | Training loss: 0.6869657767075364
Epoch: 98 | Iteration number: [2800/4518] 61% | Training loss: 0.6869689588461604
Epoch: 98 | Iteration number: [2810/4518] 62% | Training loss: 0.6869647509050539
Epoch: 98 | Iteration number: [2820/4518] 62% | Training loss: 0.686966007165875
Epoch: 98 | Iteration number: [2830/4518] 62% | Training loss: 0.6869635516889525
Epoch: 98 | Iteration number: [2840/4518] 62% | Training loss: 0.6869629539234537
Epoch: 98 | Iteration number: [2850/4518] 63% | Training loss: 0.6869612107987989
Epoch: 98 | Iteration number: [2860/4518] 63% | Training loss: 0.6869579400007542
Epoch: 98 | Iteration number: [2870/4518] 63% | Training loss: 0.6869583064878444
Epoch: 98 | Iteration number: [2880/4518] 63% | Training loss: 0.686957750386662
Epoch: 98 | Iteration number: [2890/4518] 63% | Training loss: 0.6869573616032781
Epoch: 98 | Iteration number: [2900/4518] 64% | Training loss: 0.6869512903484805
Epoch: 98 | Iteration number: [2910/4518] 64% | Training loss: 0.6869512119858535
Epoch: 98 | Iteration number: [2920/4518] 64% | Training loss: 0.6869500368425291
Epoch: 98 | Iteration number: [2930/4518] 64% | Training loss: 0.6869503934839073
Epoch: 98 | Iteration number: [2940/4518] 65% | Training loss: 0.6869488135689781
Epoch: 98 | Iteration number: [2950/4518] 65% | Training loss: 0.6869478087506051
Epoch: 98 | Iteration number: [2960/4518] 65% | Training loss: 0.6869495510249525
Epoch: 98 | Iteration number: [2970/4518] 65% | Training loss: 0.6869477607987143
Epoch: 98 | Iteration number: [2980/4518] 65% | Training loss: 0.6869467827297697
Epoch: 98 | Iteration number: [2990/4518] 66% | Training loss: 0.6869424559400233
Epoch: 98 | Iteration number: [3000/4518] 66% | Training loss: 0.6869375538229943
Epoch: 98 | Iteration number: [3010/4518] 66% | Training loss: 0.686934327821795
Epoch: 98 | Iteration number: [3020/4518] 66% | Training loss: 0.6869293051247565
Epoch: 98 | Iteration number: [3030/4518] 67% | Training loss: 0.6869310060546736
Epoch: 98 | Iteration number: [3040/4518] 67% | Training loss: 0.6869284971568145
Epoch: 98 | Iteration number: [3050/4518] 67% | Training loss: 0.6869287627055997
Epoch: 98 | Iteration number: [3060/4518] 67% | Training loss: 0.6869300099954107
Epoch: 98 | Iteration number: [3070/4518] 67% | Training loss: 0.6869290393998646
Epoch: 98 | Iteration number: [3080/4518] 68% | Training loss: 0.6869290763681585
Epoch: 98 | Iteration number: [3090/4518] 68% | Training loss: 0.6869290920522992
Epoch: 98 | Iteration number: [3100/4518] 68% | Training loss: 0.6869240942501252
Epoch: 98 | Iteration number: [3110/4518] 68% | Training loss: 0.6869247482520591
Epoch: 98 | Iteration number: [3120/4518] 69% | Training loss: 0.6869248248827763
Epoch: 98 | Iteration number: [3130/4518] 69% | Training loss: 0.6869272988825179
Epoch: 98 | Iteration number: [3140/4518] 69% | Training loss: 0.6869269148749151
Epoch: 98 | Iteration number: [3150/4518] 69% | Training loss: 0.6869288053020598
Epoch: 98 | Iteration number: [3160/4518] 69% | Training loss: 0.6869275129105471
Epoch: 98 | Iteration number: [3170/4518] 70% | Training loss: 0.6869202572088512
Epoch: 98 | Iteration number: [3180/4518] 70% | Training loss: 0.6869215017407195
Epoch: 98 | Iteration number: [3190/4518] 70% | Training loss: 0.6869171828311813
Epoch: 98 | Iteration number: [3200/4518] 70% | Training loss: 0.6869161398150027
Epoch: 98 | Iteration number: [3210/4518] 71% | Training loss: 0.6869198241709178
Epoch: 98 | Iteration number: [3220/4518] 71% | Training loss: 0.6869236105347272
Epoch: 98 | Iteration number: [3230/4518] 71% | Training loss: 0.6869252110413353
Epoch: 98 | Iteration number: [3240/4518] 71% | Training loss: 0.6869248163368967
Epoch: 98 | Iteration number: [3250/4518] 71% | Training loss: 0.6869218909006852
Epoch: 98 | Iteration number: [3260/4518] 72% | Training loss: 0.6869176570257526
Epoch: 98 | Iteration number: [3270/4518] 72% | Training loss: 0.6869204924376369
Epoch: 98 | Iteration number: [3280/4518] 72% | Training loss: 0.6869229051398068
Epoch: 98 | Iteration number: [3290/4518] 72% | Training loss: 0.6869257175270185
Epoch: 98 | Iteration number: [3300/4518] 73% | Training loss: 0.6869243094054135
Epoch: 98 | Iteration number: [3310/4518] 73% | Training loss: 0.6869262234682043
Epoch: 98 | Iteration number: [3320/4518] 73% | Training loss: 0.6869241144822305
Epoch: 98 | Iteration number: [3330/4518] 73% | Training loss: 0.6869235255338766
Epoch: 98 | Iteration number: [3340/4518] 73% | Training loss: 0.686923108325747
Epoch: 98 | Iteration number: [3350/4518] 74% | Training loss: 0.6869250059483656
Epoch: 98 | Iteration number: [3360/4518] 74% | Training loss: 0.6869244177426611
Epoch: 98 | Iteration number: [3370/4518] 74% | Training loss: 0.6869257874587877
Epoch: 98 | Iteration number: [3380/4518] 74% | Training loss: 0.6869215504304897
Epoch: 98 | Iteration number: [3390/4518] 75% | Training loss: 0.6869232559098607
Epoch: 98 | Iteration number: [3400/4518] 75% | Training loss: 0.6869223760681994
Epoch: 98 | Iteration number: [3410/4518] 75% | Training loss: 0.6869239454220467
Epoch: 98 | Iteration number: [3420/4518] 75% | Training loss: 0.6869214371805302
Epoch: 98 | Iteration number: [3430/4518] 75% | Training loss: 0.6869211953165927
Epoch: 98 | Iteration number: [3440/4518] 76% | Training loss: 0.6869232818311037
Epoch: 98 | Iteration number: [3450/4518] 76% | Training loss: 0.686921241145203
Epoch: 98 | Iteration number: [3460/4518] 76% | Training loss: 0.6869199805866087
Epoch: 98 | Iteration number: [3470/4518] 76% | Training loss: 0.686918230462143
Epoch: 98 | Iteration number: [3480/4518] 77% | Training loss: 0.6869204029954713
Epoch: 98 | Iteration number: [3490/4518] 77% | Training loss: 0.6869214499918984
Epoch: 98 | Iteration number: [3500/4518] 77% | Training loss: 0.6869163386992045
Epoch: 98 | Iteration number: [3510/4518] 77% | Training loss: 0.6869153871325686
Epoch: 98 | Iteration number: [3520/4518] 77% | Training loss: 0.6869144681333141
Epoch: 98 | Iteration number: [3530/4518] 78% | Training loss: 0.6869180691140907
Epoch: 98 | Iteration number: [3540/4518] 78% | Training loss: 0.6869189460062037
Epoch: 98 | Iteration number: [3550/4518] 78% | Training loss: 0.68692081031665
Epoch: 98 | Iteration number: [3560/4518] 78% | Training loss: 0.6869214138623034
Epoch: 98 | Iteration number: [3570/4518] 79% | Training loss: 0.6869241044133985
Epoch: 98 | Iteration number: [3580/4518] 79% | Training loss: 0.6869256057386292
Epoch: 98 | Iteration number: [3590/4518] 79% | Training loss: 0.6869269134108402
Epoch: 98 | Iteration number: [3600/4518] 79% | Training loss: 0.686921527998315
Epoch: 98 | Iteration number: [3610/4518] 79% | Training loss: 0.686923165218982
Epoch: 98 | Iteration number: [3620/4518] 80% | Training loss: 0.6869239224584063
Epoch: 98 | Iteration number: [3630/4518] 80% | Training loss: 0.6869248171811589
Epoch: 98 | Iteration number: [3640/4518] 80% | Training loss: 0.6869239444261069
Epoch: 98 | Iteration number: [3650/4518] 80% | Training loss: 0.6869237849320451
Epoch: 98 | Iteration number: [3660/4518] 81% | Training loss: 0.686924348323723
Epoch: 98 | Iteration number: [3670/4518] 81% | Training loss: 0.6869252369092012
Epoch: 98 | Iteration number: [3680/4518] 81% | Training loss: 0.6869216855615378
Epoch: 98 | Iteration number: [3690/4518] 81% | Training loss: 0.6869243789817583
Epoch: 98 | Iteration number: [3700/4518] 81% | Training loss: 0.6869270745322511
Epoch: 98 | Iteration number: [3710/4518] 82% | Training loss: 0.6869277418302397
Epoch: 98 | Iteration number: [3720/4518] 82% | Training loss: 0.6869247661322676
Epoch: 98 | Iteration number: [3730/4518] 82% | Training loss: 0.6869224772536403
Epoch: 98 | Iteration number: [3740/4518] 82% | Training loss: 0.6869240451145937
Epoch: 98 | Iteration number: [3750/4518] 83% | Training loss: 0.6869226068337758
Epoch: 98 | Iteration number: [3760/4518] 83% | Training loss: 0.6869206201522908
Epoch: 98 | Iteration number: [3770/4518] 83% | Training loss: 0.6869215513097828
Epoch: 98 | Iteration number: [3780/4518] 83% | Training loss: 0.6869209957185877
Epoch: 98 | Iteration number: [3790/4518] 83% | Training loss: 0.6869206755016599
Epoch: 98 | Iteration number: [3800/4518] 84% | Training loss: 0.6869196015439536
Epoch: 98 | Iteration number: [3810/4518] 84% | Training loss: 0.6869206016927254
Epoch: 98 | Iteration number: [3820/4518] 84% | Training loss: 0.6869189327924039
Epoch: 98 | Iteration number: [3830/4518] 84% | Training loss: 0.6869193031644697
Epoch: 98 | Iteration number: [3840/4518] 84% | Training loss: 0.6869194641554107
Epoch: 98 | Iteration number: [3850/4518] 85% | Training loss: 0.6869196638813266
Epoch: 98 | Iteration number: [3860/4518] 85% | Training loss: 0.6869163290206632
Epoch: 98 | Iteration number: [3870/4518] 85% | Training loss: 0.686917077170478
Epoch: 98 | Iteration number: [3880/4518] 85% | Training loss: 0.6869153592543503
Epoch: 98 | Iteration number: [3890/4518] 86% | Training loss: 0.6869174707977814
Epoch: 98 | Iteration number: [3900/4518] 86% | Training loss: 0.6869133617939093
Epoch: 98 | Iteration number: [3910/4518] 86% | Training loss: 0.6869111839767612
Epoch: 98 | Iteration number: [3920/4518] 86% | Training loss: 0.6869075153099031
Epoch: 98 | Iteration number: [3930/4518] 86% | Training loss: 0.686907605557648
Epoch: 98 | Iteration number: [3940/4518] 87% | Training loss: 0.6869073085978552
Epoch: 98 | Iteration number: [3950/4518] 87% | Training loss: 0.6869110058832772
Epoch: 98 | Iteration number: [3960/4518] 87% | Training loss: 0.6869136223588327
Epoch: 98 | Iteration number: [3970/4518] 87% | Training loss: 0.6869101723585681
Epoch: 98 | Iteration number: [3980/4518] 88% | Training loss: 0.6869108922817
Epoch: 98 | Iteration number: [3990/4518] 88% | Training loss: 0.6869087798404215
Epoch: 98 | Iteration number: [4000/4518] 88% | Training loss: 0.6869085908830166
Epoch: 98 | Iteration number: [4010/4518] 88% | Training loss: 0.6869080614865272
Epoch: 98 | Iteration number: [4020/4518] 88% | Training loss: 0.6869089796916762
Epoch: 98 | Iteration number: [4030/4518] 89% | Training loss: 0.6869111353794931
Epoch: 98 | Iteration number: [4040/4518] 89% | Training loss: 0.6869117613476101
Epoch: 98 | Iteration number: [4050/4518] 89% | Training loss: 0.6869102603270684
Epoch: 98 | Iteration number: [4060/4518] 89% | Training loss: 0.6869142438684191
Epoch: 98 | Iteration number: [4070/4518] 90% | Training loss: 0.6869129177539882
Epoch: 98 | Iteration number: [4080/4518] 90% | Training loss: 0.6869146602556986
Epoch: 98 | Iteration number: [4090/4518] 90% | Training loss: 0.6869126881830266
Epoch: 98 | Iteration number: [4100/4518] 90% | Training loss: 0.6869103319179721
Epoch: 98 | Iteration number: [4110/4518] 90% | Training loss: 0.6869119024334743
Epoch: 98 | Iteration number: [4120/4518] 91% | Training loss: 0.6869110088325241
Epoch: 98 | Iteration number: [4130/4518] 91% | Training loss: 0.6869126064725418
Epoch: 98 | Iteration number: [4140/4518] 91% | Training loss: 0.6869154077365203
Epoch: 98 | Iteration number: [4150/4518] 91% | Training loss: 0.6869167676316686
Epoch: 98 | Iteration number: [4160/4518] 92% | Training loss: 0.6869165472113169
Epoch: 98 | Iteration number: [4170/4518] 92% | Training loss: 0.6869184143394589
Epoch: 98 | Iteration number: [4180/4518] 92% | Training loss: 0.6869208081202074
Epoch: 98 | Iteration number: [4190/4518] 92% | Training loss: 0.6869199287777584
Epoch: 98 | Iteration number: [4200/4518] 92% | Training loss: 0.686915379067262
Epoch: 98 | Iteration number: [4210/4518] 93% | Training loss: 0.6869159704432635
Epoch: 98 | Iteration number: [4220/4518] 93% | Training loss: 0.6869149188153552
Epoch: 98 | Iteration number: [4230/4518] 93% | Training loss: 0.6869149989692878
Epoch: 98 | Iteration number: [4240/4518] 93% | Training loss: 0.6869123842637493
Epoch: 98 | Iteration number: [4250/4518] 94% | Training loss: 0.686909841930165
Epoch: 98 | Iteration number: [4260/4518] 94% | Training loss: 0.6869093542227722
Epoch: 98 | Iteration number: [4270/4518] 94% | Training loss: 0.686911601205062
Epoch: 98 | Iteration number: [4280/4518] 94% | Training loss: 0.6869084018970204
Epoch: 98 | Iteration number: [4290/4518] 94% | Training loss: 0.6869081963331272
Epoch: 98 | Iteration number: [4300/4518] 95% | Training loss: 0.6869074985592865
Epoch: 98 | Iteration number: [4310/4518] 95% | Training loss: 0.6869048079869033
Epoch: 98 | Iteration number: [4320/4518] 95% | Training loss: 0.6869053400225109
Epoch: 98 | Iteration number: [4330/4518] 95% | Training loss: 0.6869070791482375
Epoch: 98 | Iteration number: [4340/4518] 96% | Training loss: 0.6869074732339877
Epoch: 98 | Iteration number: [4350/4518] 96% | Training loss: 0.6869067294707244
Epoch: 98 | Iteration number: [4360/4518] 96% | Training loss: 0.6869061090257189
Epoch: 98 | Iteration number: [4370/4518] 96% | Training loss: 0.6869077223116528
Epoch: 98 | Iteration number: [4380/4518] 96% | Training loss: 0.686908458955756
Epoch: 98 | Iteration number: [4390/4518] 97% | Training loss: 0.6869072895250994
Epoch: 98 | Iteration number: [4400/4518] 97% | Training loss: 0.6869084633209489
Epoch: 98 | Iteration number: [4410/4518] 97% | Training loss: 0.6869073527199882
Epoch: 98 | Iteration number: [4420/4518] 97% | Training loss: 0.6869081042336123
Epoch: 98 | Iteration number: [4430/4518] 98% | Training loss: 0.6869074119805751
Epoch: 98 | Iteration number: [4440/4518] 98% | Training loss: 0.6869052745200492
Epoch: 98 | Iteration number: [4450/4518] 98% | Training loss: 0.6869033279043905
Epoch: 98 | Iteration number: [4460/4518] 98% | Training loss: 0.6869035785641906
Epoch: 98 | Iteration number: [4470/4518] 98% | Training loss: 0.6869029539943542
Epoch: 98 | Iteration number: [4480/4518] 99% | Training loss: 0.6869034372802292
Epoch: 98 | Iteration number: [4490/4518] 99% | Training loss: 0.6869025017477091
Epoch: 98 | Iteration number: [4500/4518] 99% | Training loss: 0.6869023417234421
Epoch: 98 | Iteration number: [4510/4518] 99% | Training loss: 0.6869011020581104

 End of epoch: 98 | Train Loss: 0.6867477824831495 | Training Time: 640 

 End of epoch: 98 | Eval Loss: 0.6897307184277749 | Evaluating Time: 16 
Epoch: 99 | Iteration number: [10/4518] 0% | Training loss: 0.7551980197429657
Epoch: 99 | Iteration number: [20/4518] 0% | Training loss: 0.7208533167839051
Epoch: 99 | Iteration number: [30/4518] 0% | Training loss: 0.7098187108834585
Epoch: 99 | Iteration number: [40/4518] 0% | Training loss: 0.7038650989532471
Epoch: 99 | Iteration number: [50/4518] 1% | Training loss: 0.700528861284256
Epoch: 99 | Iteration number: [60/4518] 1% | Training loss: 0.6981413195530574
Epoch: 99 | Iteration number: [70/4518] 1% | Training loss: 0.6965412608214787
Epoch: 99 | Iteration number: [80/4518] 1% | Training loss: 0.6952967263758183
Epoch: 99 | Iteration number: [90/4518] 1% | Training loss: 0.6943734731939104
Epoch: 99 | Iteration number: [100/4518] 2% | Training loss: 0.693656650185585
Epoch: 99 | Iteration number: [110/4518] 2% | Training loss: 0.6929440547119488
Epoch: 99 | Iteration number: [120/4518] 2% | Training loss: 0.6924353341261545
Epoch: 99 | Iteration number: [130/4518] 2% | Training loss: 0.6920598227244157
Epoch: 99 | Iteration number: [140/4518] 3% | Training loss: 0.6916830275739942
Epoch: 99 | Iteration number: [150/4518] 3% | Training loss: 0.6914451853434245
Epoch: 99 | Iteration number: [160/4518] 3% | Training loss: 0.691227813065052
Epoch: 99 | Iteration number: [170/4518] 3% | Training loss: 0.6910078255569234
Epoch: 99 | Iteration number: [180/4518] 3% | Training loss: 0.6907994714048173
Epoch: 99 | Iteration number: [190/4518] 4% | Training loss: 0.6906048815501363
Epoch: 99 | Iteration number: [200/4518] 4% | Training loss: 0.6903697523474693
Epoch: 99 | Iteration number: [210/4518] 4% | Training loss: 0.6902396358194806
Epoch: 99 | Iteration number: [220/4518] 4% | Training loss: 0.6900799892165445
Epoch: 99 | Iteration number: [230/4518] 5% | Training loss: 0.6898888961128566
Epoch: 99 | Iteration number: [240/4518] 5% | Training loss: 0.6897171144684155
Epoch: 99 | Iteration number: [250/4518] 5% | Training loss: 0.6896428780555726
Epoch: 99 | Iteration number: [260/4518] 5% | Training loss: 0.6895717123380074
Epoch: 99 | Iteration number: [270/4518] 5% | Training loss: 0.6894889937506782
Epoch: 99 | Iteration number: [280/4518] 6% | Training loss: 0.6894015980618341
Epoch: 99 | Iteration number: [290/4518] 6% | Training loss: 0.6892731239055765
Epoch: 99 | Iteration number: [300/4518] 6% | Training loss: 0.68921437839667
Epoch: 99 | Iteration number: [310/4518] 6% | Training loss: 0.6891516937363532
Epoch: 99 | Iteration number: [320/4518] 7% | Training loss: 0.6890310434624553
Epoch: 99 | Iteration number: [330/4518] 7% | Training loss: 0.6889758937286609
Epoch: 99 | Iteration number: [340/4518] 7% | Training loss: 0.6889181698069853
Epoch: 99 | Iteration number: [350/4518] 7% | Training loss: 0.6888847955635615
Epoch: 99 | Iteration number: [360/4518] 7% | Training loss: 0.6888419662912687
Epoch: 99 | Iteration number: [370/4518] 8% | Training loss: 0.6887779193955499
Epoch: 99 | Iteration number: [380/4518] 8% | Training loss: 0.6887172438596424
Epoch: 99 | Iteration number: [390/4518] 8% | Training loss: 0.6886928723408625
Epoch: 99 | Iteration number: [400/4518] 8% | Training loss: 0.6886415012180805
Epoch: 99 | Iteration number: [410/4518] 9% | Training loss: 0.6886151662686976
Epoch: 99 | Iteration number: [420/4518] 9% | Training loss: 0.6885850053457987
Epoch: 99 | Iteration number: [430/4518] 9% | Training loss: 0.6885474214720172
Epoch: 99 | Iteration number: [440/4518] 9% | Training loss: 0.6885132599960674
Epoch: 99 | Iteration number: [450/4518] 9% | Training loss: 0.6884908743699392
Epoch: 99 | Iteration number: [460/4518] 10% | Training loss: 0.6884871007307716
Epoch: 99 | Iteration number: [470/4518] 10% | Training loss: 0.6884433274573468
Epoch: 99 | Iteration number: [480/4518] 10% | Training loss: 0.6884205972154935
Epoch: 99 | Iteration number: [490/4518] 10% | Training loss: 0.6883833644341449
Epoch: 99 | Iteration number: [500/4518] 11% | Training loss: 0.6883699868917466
Epoch: 99 | Iteration number: [510/4518] 11% | Training loss: 0.6883613776926901
Epoch: 99 | Iteration number: [520/4518] 11% | Training loss: 0.6883142450681099
Epoch: 99 | Iteration number: [530/4518] 11% | Training loss: 0.6883032048648259
Epoch: 99 | Iteration number: [540/4518] 11% | Training loss: 0.6882357358932495
Epoch: 99 | Iteration number: [550/4518] 12% | Training loss: 0.6882028689167716
Epoch: 99 | Iteration number: [560/4518] 12% | Training loss: 0.6881676141704832
Epoch: 99 | Iteration number: [570/4518] 12% | Training loss: 0.6881439525830119
Epoch: 99 | Iteration number: [580/4518] 12% | Training loss: 0.688132760853603
Epoch: 99 | Iteration number: [590/4518] 13% | Training loss: 0.6881159321736481
Epoch: 99 | Iteration number: [600/4518] 13% | Training loss: 0.6880970656871795
Epoch: 99 | Iteration number: [610/4518] 13% | Training loss: 0.6880566884259709
Epoch: 99 | Iteration number: [620/4518] 13% | Training loss: 0.6880477605327483
Epoch: 99 | Iteration number: [630/4518] 13% | Training loss: 0.6880410607845064
Epoch: 99 | Iteration number: [640/4518] 14% | Training loss: 0.6880172199569643
Epoch: 99 | Iteration number: [650/4518] 14% | Training loss: 0.6880088505378136
Epoch: 99 | Iteration number: [660/4518] 14% | Training loss: 0.68800151321021
Epoch: 99 | Iteration number: [670/4518] 14% | Training loss: 0.6879602149351319
Epoch: 99 | Iteration number: [680/4518] 15% | Training loss: 0.6879373796722468
Epoch: 99 | Iteration number: [690/4518] 15% | Training loss: 0.6879113611103832
Epoch: 99 | Iteration number: [700/4518] 15% | Training loss: 0.6878709409918103
Epoch: 99 | Iteration number: [710/4518] 15% | Training loss: 0.6878641011849256
Epoch: 99 | Iteration number: [720/4518] 15% | Training loss: 0.687835327287515
Epoch: 99 | Iteration number: [730/4518] 16% | Training loss: 0.6878321368400365
Epoch: 99 | Iteration number: [740/4518] 16% | Training loss: 0.6878152580680074
Epoch: 99 | Iteration number: [750/4518] 16% | Training loss: 0.6877952882448832
Epoch: 99 | Iteration number: [760/4518] 16% | Training loss: 0.6877691663409534
Epoch: 99 | Iteration number: [770/4518] 17% | Training loss: 0.6877472755196806
Epoch: 99 | Iteration number: [780/4518] 17% | Training loss: 0.6877436925967534
Epoch: 99 | Iteration number: [790/4518] 17% | Training loss: 0.6877359474007088
Epoch: 99 | Iteration number: [800/4518] 17% | Training loss: 0.6877128733694553
Epoch: 99 | Iteration number: [810/4518] 17% | Training loss: 0.687690270020638
Epoch: 99 | Iteration number: [820/4518] 18% | Training loss: 0.6876619467648064
Epoch: 99 | Iteration number: [830/4518] 18% | Training loss: 0.687655162524028
Epoch: 99 | Iteration number: [840/4518] 18% | Training loss: 0.6876269866313253
Epoch: 99 | Iteration number: [850/4518] 18% | Training loss: 0.6876198085616617
Epoch: 99 | Iteration number: [860/4518] 19% | Training loss: 0.6876101326803828
Epoch: 99 | Iteration number: [870/4518] 19% | Training loss: 0.6875930634723313
Epoch: 99 | Iteration number: [880/4518] 19% | Training loss: 0.6875616939907724
Epoch: 99 | Iteration number: [890/4518] 19% | Training loss: 0.6875508628534467
Epoch: 99 | Iteration number: [900/4518] 19% | Training loss: 0.687558823691474
Epoch: 99 | Iteration number: [910/4518] 20% | Training loss: 0.6875580806653578
Epoch: 99 | Iteration number: [920/4518] 20% | Training loss: 0.6875481053538944
Epoch: 99 | Iteration number: [930/4518] 20% | Training loss: 0.6875465706471474
Epoch: 99 | Iteration number: [940/4518] 20% | Training loss: 0.6875344830624601
Epoch: 99 | Iteration number: [950/4518] 21% | Training loss: 0.6875015803387291
Epoch: 99 | Iteration number: [960/4518] 21% | Training loss: 0.6874891275539994
Epoch: 99 | Iteration number: [970/4518] 21% | Training loss: 0.687484828713014
Epoch: 99 | Iteration number: [980/4518] 21% | Training loss: 0.6874783961748591
Epoch: 99 | Iteration number: [990/4518] 21% | Training loss: 0.6874625861644745
Epoch: 99 | Iteration number: [1000/4518] 22% | Training loss: 0.6874618779420852
Epoch: 99 | Iteration number: [1010/4518] 22% | Training loss: 0.6874497420126849
Epoch: 99 | Iteration number: [1020/4518] 22% | Training loss: 0.6874456728205961
Epoch: 99 | Iteration number: [1030/4518] 22% | Training loss: 0.6874506494952637
Epoch: 99 | Iteration number: [1040/4518] 23% | Training loss: 0.6874492079592668
Epoch: 99 | Iteration number: [1050/4518] 23% | Training loss: 0.6874474337555113
Epoch: 99 | Iteration number: [1060/4518] 23% | Training loss: 0.6874517773682216
Epoch: 99 | Iteration number: [1070/4518] 23% | Training loss: 0.6874383796041257
Epoch: 99 | Iteration number: [1080/4518] 23% | Training loss: 0.6874232934580908
Epoch: 99 | Iteration number: [1090/4518] 24% | Training loss: 0.6874191698678043
Epoch: 99 | Iteration number: [1100/4518] 24% | Training loss: 0.6874110807072032
Epoch: 99 | Iteration number: [1110/4518] 24% | Training loss: 0.6874181094470325
Epoch: 99 | Iteration number: [1120/4518] 24% | Training loss: 0.6874076908720391
Epoch: 99 | Iteration number: [1130/4518] 25% | Training loss: 0.6873983820455264
Epoch: 99 | Iteration number: [1140/4518] 25% | Training loss: 0.6873854943011937
Epoch: 99 | Iteration number: [1150/4518] 25% | Training loss: 0.6873677503544351
Epoch: 99 | Iteration number: [1160/4518] 25% | Training loss: 0.6873757999518822
Epoch: 99 | Iteration number: [1170/4518] 25% | Training loss: 0.6873613652510521
Epoch: 99 | Iteration number: [1180/4518] 26% | Training loss: 0.6873567555415429
Epoch: 99 | Iteration number: [1190/4518] 26% | Training loss: 0.6873507417550608
Epoch: 99 | Iteration number: [1200/4518] 26% | Training loss: 0.6873496339718501
Epoch: 99 | Iteration number: [1210/4518] 26% | Training loss: 0.6873375963573614
Epoch: 99 | Iteration number: [1220/4518] 27% | Training loss: 0.6873303829157938
Epoch: 99 | Iteration number: [1230/4518] 27% | Training loss: 0.6873362362869386
Epoch: 99 | Iteration number: [1240/4518] 27% | Training loss: 0.6873355681857755
Epoch: 99 | Iteration number: [1250/4518] 27% | Training loss: 0.6873351879119873
Epoch: 99 | Iteration number: [1260/4518] 27% | Training loss: 0.6873286471953468
Epoch: 99 | Iteration number: [1270/4518] 28% | Training loss: 0.6873188215916551
Epoch: 99 | Iteration number: [1280/4518] 28% | Training loss: 0.6873110806103796
Epoch: 99 | Iteration number: [1290/4518] 28% | Training loss: 0.6873105698777724
Epoch: 99 | Iteration number: [1300/4518] 28% | Training loss: 0.6873093341864073
Epoch: 99 | Iteration number: [1310/4518] 28% | Training loss: 0.6873142221046769
Epoch: 99 | Iteration number: [1320/4518] 29% | Training loss: 0.6873182712179242
Epoch: 99 | Iteration number: [1330/4518] 29% | Training loss: 0.6873096725546328
Epoch: 99 | Iteration number: [1340/4518] 29% | Training loss: 0.6873052687342487
Epoch: 99 | Iteration number: [1350/4518] 29% | Training loss: 0.6872942322271841
Epoch: 99 | Iteration number: [1360/4518] 30% | Training loss: 0.6872877411982592
Epoch: 99 | Iteration number: [1370/4518] 30% | Training loss: 0.6872816066237262
Epoch: 99 | Iteration number: [1380/4518] 30% | Training loss: 0.687270737817322
Epoch: 99 | Iteration number: [1390/4518] 30% | Training loss: 0.6872779242855181
Epoch: 99 | Iteration number: [1400/4518] 30% | Training loss: 0.6872835207411221
Epoch: 99 | Iteration number: [1410/4518] 31% | Training loss: 0.6872816333111297
Epoch: 99 | Iteration number: [1420/4518] 31% | Training loss: 0.687267021897813
Epoch: 99 | Iteration number: [1430/4518] 31% | Training loss: 0.6872627544653166
Epoch: 99 | Iteration number: [1440/4518] 31% | Training loss: 0.6872604445450836
Epoch: 99 | Iteration number: [1450/4518] 32% | Training loss: 0.6872596750999319
Epoch: 99 | Iteration number: [1460/4518] 32% | Training loss: 0.6872543120629167
Epoch: 99 | Iteration number: [1470/4518] 32% | Training loss: 0.6872498291690333
Epoch: 99 | Iteration number: [1480/4518] 32% | Training loss: 0.687254843558814
Epoch: 99 | Iteration number: [1490/4518] 32% | Training loss: 0.6872580496256784
Epoch: 99 | Iteration number: [1500/4518] 33% | Training loss: 0.6872593510945638
Epoch: 99 | Iteration number: [1510/4518] 33% | Training loss: 0.6872560477809401
Epoch: 99 | Iteration number: [1520/4518] 33% | Training loss: 0.6872587700423441
Epoch: 99 | Iteration number: [1530/4518] 33% | Training loss: 0.6872667823741638
Epoch: 99 | Iteration number: [1540/4518] 34% | Training loss: 0.6872678878245415
Epoch: 99 | Iteration number: [1550/4518] 34% | Training loss: 0.6872591257864429
Epoch: 99 | Iteration number: [1560/4518] 34% | Training loss: 0.6872578573532594
Epoch: 99 | Iteration number: [1570/4518] 34% | Training loss: 0.6872441671076853
Epoch: 99 | Iteration number: [1580/4518] 34% | Training loss: 0.6872399942029881
Epoch: 99 | Iteration number: [1590/4518] 35% | Training loss: 0.6872394567015786
Epoch: 99 | Iteration number: [1600/4518] 35% | Training loss: 0.6872361933067441
Epoch: 99 | Iteration number: [1610/4518] 35% | Training loss: 0.6872404158485602
Epoch: 99 | Iteration number: [1620/4518] 35% | Training loss: 0.6872463900733877
Epoch: 99 | Iteration number: [1630/4518] 36% | Training loss: 0.6872316123152071
Epoch: 99 | Iteration number: [1640/4518] 36% | Training loss: 0.6872253021815928
Epoch: 99 | Iteration number: [1650/4518] 36% | Training loss: 0.6872229374538769
Epoch: 99 | Iteration number: [1660/4518] 36% | Training loss: 0.6872192421232362
Epoch: 99 | Iteration number: [1670/4518] 36% | Training loss: 0.6872171539389444
Epoch: 99 | Iteration number: [1680/4518] 37% | Training loss: 0.6872201900397028
Epoch: 99 | Iteration number: [1690/4518] 37% | Training loss: 0.6872200476347342
Epoch: 99 | Iteration number: [1700/4518] 37% | Training loss: 0.6872120033993441
Epoch: 99 | Iteration number: [1710/4518] 37% | Training loss: 0.687204671045493
Epoch: 99 | Iteration number: [1720/4518] 38% | Training loss: 0.6872016704013181
Epoch: 99 | Iteration number: [1730/4518] 38% | Training loss: 0.6872021192760137
Epoch: 99 | Iteration number: [1740/4518] 38% | Training loss: 0.6872019378618263
Epoch: 99 | Iteration number: [1750/4518] 38% | Training loss: 0.6872001700401306
Epoch: 99 | Iteration number: [1760/4518] 38% | Training loss: 0.687201645530083
Epoch: 99 | Iteration number: [1770/4518] 39% | Training loss: 0.6871990886111717
Epoch: 99 | Iteration number: [1780/4518] 39% | Training loss: 0.6871927840656109
Epoch: 99 | Iteration number: [1790/4518] 39% | Training loss: 0.6871846397495802
Epoch: 99 | Iteration number: [1800/4518] 39% | Training loss: 0.6871927287181219
Epoch: 99 | Iteration number: [1810/4518] 40% | Training loss: 0.6871861764739231
Epoch: 99 | Iteration number: [1820/4518] 40% | Training loss: 0.6871808366461114
Epoch: 99 | Iteration number: [1830/4518] 40% | Training loss: 0.6871690347546436
Epoch: 99 | Iteration number: [1840/4518] 40% | Training loss: 0.6871609415697015
Epoch: 99 | Iteration number: [1850/4518] 40% | Training loss: 0.6871560099962596
Epoch: 99 | Iteration number: [1860/4518] 41% | Training loss: 0.6871570572737724
Epoch: 99 | Iteration number: [1870/4518] 41% | Training loss: 0.687154236834317
Epoch: 99 | Iteration number: [1880/4518] 41% | Training loss: 0.6871592185598738
Epoch: 99 | Iteration number: [1890/4518] 41% | Training loss: 0.6871507540897087
Epoch: 99 | Iteration number: [1900/4518] 42% | Training loss: 0.6871440274464456
Epoch: 99 | Iteration number: [1910/4518] 42% | Training loss: 0.6871423335911716
Epoch: 99 | Iteration number: [1920/4518] 42% | Training loss: 0.6871350622735918
Epoch: 99 | Iteration number: [1930/4518] 42% | Training loss: 0.687127857504731
Epoch: 99 | Iteration number: [1940/4518] 42% | Training loss: 0.6871224642107168
Epoch: 99 | Iteration number: [1950/4518] 43% | Training loss: 0.6871280994782081
Epoch: 99 | Iteration number: [1960/4518] 43% | Training loss: 0.6871308469954802
Epoch: 99 | Iteration number: [1970/4518] 43% | Training loss: 0.6871293601650877
Epoch: 99 | Iteration number: [1980/4518] 43% | Training loss: 0.6871208851987666
Epoch: 99 | Iteration number: [1990/4518] 44% | Training loss: 0.6871194730152437
Epoch: 99 | Iteration number: [2000/4518] 44% | Training loss: 0.6871142783761024
Epoch: 99 | Iteration number: [2010/4518] 44% | Training loss: 0.6871144119483321
Epoch: 99 | Iteration number: [2020/4518] 44% | Training loss: 0.6871215598122908
Epoch: 99 | Iteration number: [2030/4518] 44% | Training loss: 0.68711484127444
Epoch: 99 | Iteration number: [2040/4518] 45% | Training loss: 0.6871143794527241
Epoch: 99 | Iteration number: [2050/4518] 45% | Training loss: 0.6871121150400581
Epoch: 99 | Iteration number: [2060/4518] 45% | Training loss: 0.6871130740179598
Epoch: 99 | Iteration number: [2070/4518] 45% | Training loss: 0.687120524149586
Epoch: 99 | Iteration number: [2080/4518] 46% | Training loss: 0.6871171850424547
Epoch: 99 | Iteration number: [2090/4518] 46% | Training loss: 0.6871148045268355
Epoch: 99 | Iteration number: [2100/4518] 46% | Training loss: 0.6871149481478191
Epoch: 99 | Iteration number: [2110/4518] 46% | Training loss: 0.687107564685469
Epoch: 99 | Iteration number: [2120/4518] 46% | Training loss: 0.6871123715954007
Epoch: 99 | Iteration number: [2130/4518] 47% | Training loss: 0.6871079163372237
Epoch: 99 | Iteration number: [2140/4518] 47% | Training loss: 0.687110587815258
Epoch: 99 | Iteration number: [2150/4518] 47% | Training loss: 0.6871099051209383
Epoch: 99 | Iteration number: [2160/4518] 47% | Training loss: 0.6871118596030606
Epoch: 99 | Iteration number: [2170/4518] 48% | Training loss: 0.6871053048267892
Epoch: 99 | Iteration number: [2180/4518] 48% | Training loss: 0.6871053885976109
Epoch: 99 | Iteration number: [2190/4518] 48% | Training loss: 0.6871007766353485
Epoch: 99 | Iteration number: [2200/4518] 48% | Training loss: 0.6870969973910939
Epoch: 99 | Iteration number: [2210/4518] 48% | Training loss: 0.6870997715859392
Epoch: 99 | Iteration number: [2220/4518] 49% | Training loss: 0.6870954376620215
Epoch: 99 | Iteration number: [2230/4518] 49% | Training loss: 0.687093829092958
Epoch: 99 | Iteration number: [2240/4518] 49% | Training loss: 0.6870914733569536
Epoch: 99 | Iteration number: [2250/4518] 49% | Training loss: 0.6870938299232059
Epoch: 99 | Iteration number: [2260/4518] 50% | Training loss: 0.687101787144104
Epoch: 99 | Iteration number: [2270/4518] 50% | Training loss: 0.6870959328922406
Epoch: 99 | Iteration number: [2280/4518] 50% | Training loss: 0.6870957718868005
Epoch: 99 | Iteration number: [2290/4518] 50% | Training loss: 0.6871004311018115
Epoch: 99 | Iteration number: [2300/4518] 50% | Training loss: 0.687101203928823
Epoch: 99 | Iteration number: [2310/4518] 51% | Training loss: 0.6871002667136007
Epoch: 99 | Iteration number: [2320/4518] 51% | Training loss: 0.687094062207074
Epoch: 99 | Iteration number: [2330/4518] 51% | Training loss: 0.6870920545553445
Epoch: 99 | Iteration number: [2340/4518] 51% | Training loss: 0.6870960937351243
Epoch: 99 | Iteration number: [2350/4518] 52% | Training loss: 0.687095097582391
Epoch: 99 | Iteration number: [2360/4518] 52% | Training loss: 0.6870903573803983
Epoch: 99 | Iteration number: [2370/4518] 52% | Training loss: 0.6870844492680915
Epoch: 99 | Iteration number: [2380/4518] 52% | Training loss: 0.6870886129491469
Epoch: 99 | Iteration number: [2390/4518] 52% | Training loss: 0.6870905845484474
Epoch: 99 | Iteration number: [2400/4518] 53% | Training loss: 0.6870909131566684
Epoch: 99 | Iteration number: [2410/4518] 53% | Training loss: 0.6870898571251833
Epoch: 99 | Iteration number: [2420/4518] 53% | Training loss: 0.6870805207362845
Epoch: 99 | Iteration number: [2430/4518] 53% | Training loss: 0.6870788811901469
Epoch: 99 | Iteration number: [2440/4518] 54% | Training loss: 0.6870761991768587
Epoch: 99 | Iteration number: [2450/4518] 54% | Training loss: 0.6870720531259265
Epoch: 99 | Iteration number: [2460/4518] 54% | Training loss: 0.6870695049442896
Epoch: 99 | Iteration number: [2470/4518] 54% | Training loss: 0.6870704932975383
Epoch: 99 | Iteration number: [2480/4518] 54% | Training loss: 0.6870696018299749
Epoch: 99 | Iteration number: [2490/4518] 55% | Training loss: 0.6870726972938063
Epoch: 99 | Iteration number: [2500/4518] 55% | Training loss: 0.6870703514575959
Epoch: 99 | Iteration number: [2510/4518] 55% | Training loss: 0.6870690151277291
Epoch: 99 | Iteration number: [2520/4518] 55% | Training loss: 0.6870688943872376
Epoch: 99 | Iteration number: [2530/4518] 55% | Training loss: 0.6870674730525187
Epoch: 99 | Iteration number: [2540/4518] 56% | Training loss: 0.6870684160726277
Epoch: 99 | Iteration number: [2550/4518] 56% | Training loss: 0.687065981205772
Epoch: 99 | Iteration number: [2560/4518] 56% | Training loss: 0.6870625870302319
Epoch: 99 | Iteration number: [2570/4518] 56% | Training loss: 0.6870594693760927
Epoch: 99 | Iteration number: [2580/4518] 57% | Training loss: 0.6870504450428393
Epoch: 99 | Iteration number: [2590/4518] 57% | Training loss: 0.6870521210105263
Epoch: 99 | Iteration number: [2600/4518] 57% | Training loss: 0.6870567631262999
Epoch: 99 | Iteration number: [2610/4518] 57% | Training loss: 0.6870566637808335
Epoch: 99 | Iteration number: [2620/4518] 57% | Training loss: 0.6870559791572222
Epoch: 99 | Iteration number: [2630/4518] 58% | Training loss: 0.687049775749105
Epoch: 99 | Iteration number: [2640/4518] 58% | Training loss: 0.6870451008054344
Epoch: 99 | Iteration number: [2650/4518] 58% | Training loss: 0.68704185497086
Epoch: 99 | Iteration number: [2660/4518] 58% | Training loss: 0.6870402048853107
Epoch: 99 | Iteration number: [2670/4518] 59% | Training loss: 0.6870402631018492
Epoch: 99 | Iteration number: [2680/4518] 59% | Training loss: 0.6870346433413562
Epoch: 99 | Iteration number: [2690/4518] 59% | Training loss: 0.6870359952343441
Epoch: 99 | Iteration number: [2700/4518] 59% | Training loss: 0.6870400101829458
Epoch: 99 | Iteration number: [2710/4518] 59% | Training loss: 0.6870435142209169
Epoch: 99 | Iteration number: [2720/4518] 60% | Training loss: 0.6870440685354612
Epoch: 99 | Iteration number: [2730/4518] 60% | Training loss: 0.6870477858698848
Epoch: 99 | Iteration number: [2740/4518] 60% | Training loss: 0.6870444073294201
Epoch: 99 | Iteration number: [2750/4518] 60% | Training loss: 0.6870481402657249
Epoch: 99 | Iteration number: [2760/4518] 61% | Training loss: 0.6870466063204019
Epoch: 99 | Iteration number: [2770/4518] 61% | Training loss: 0.6870453855621256
Epoch: 99 | Iteration number: [2780/4518] 61% | Training loss: 0.6870486829563868
Epoch: 99 | Iteration number: [2790/4518] 61% | Training loss: 0.6870474413945257
Epoch: 99 | Iteration number: [2800/4518] 61% | Training loss: 0.687047328289066
Epoch: 99 | Iteration number: [2810/4518] 62% | Training loss: 0.6870440561788362
Epoch: 99 | Iteration number: [2820/4518] 62% | Training loss: 0.6870509858883864
Epoch: 99 | Iteration number: [2830/4518] 62% | Training loss: 0.687049605673699
Epoch: 99 | Iteration number: [2840/4518] 62% | Training loss: 0.6870469348111623
Epoch: 99 | Iteration number: [2850/4518] 63% | Training loss: 0.6870441175552837
Epoch: 99 | Iteration number: [2860/4518] 63% | Training loss: 0.6870468710685943
Epoch: 99 | Iteration number: [2870/4518] 63% | Training loss: 0.6870450097509377
Epoch: 99 | Iteration number: [2880/4518] 63% | Training loss: 0.6870420273393393
Epoch: 99 | Iteration number: [2890/4518] 63% | Training loss: 0.6870448812068952
Epoch: 99 | Iteration number: [2900/4518] 64% | Training loss: 0.6870449918714063
Epoch: 99 | Iteration number: [2910/4518] 64% | Training loss: 0.6870419772220231
Epoch: 99 | Iteration number: [2920/4518] 64% | Training loss: 0.6870416132962867
Epoch: 99 | Iteration number: [2930/4518] 64% | Training loss: 0.6870415339087463
Epoch: 99 | Iteration number: [2940/4518] 65% | Training loss: 0.6870428069108198
Epoch: 99 | Iteration number: [2950/4518] 65% | Training loss: 0.6870349855140104
Epoch: 99 | Iteration number: [2960/4518] 65% | Training loss: 0.6870332652249852
Epoch: 99 | Iteration number: [2970/4518] 65% | Training loss: 0.6870281277682243
Epoch: 99 | Iteration number: [2980/4518] 65% | Training loss: 0.6870306815477025
Epoch: 99 | Iteration number: [2990/4518] 66% | Training loss: 0.6870327115656939
Epoch: 99 | Iteration number: [3000/4518] 66% | Training loss: 0.687030181268851
Epoch: 99 | Iteration number: [3010/4518] 66% | Training loss: 0.6870288429664219
Epoch: 99 | Iteration number: [3020/4518] 66% | Training loss: 0.6870285073652962
Epoch: 99 | Iteration number: [3030/4518] 67% | Training loss: 0.6870263664832603
Epoch: 99 | Iteration number: [3040/4518] 67% | Training loss: 0.6870240738909495
Epoch: 99 | Iteration number: [3050/4518] 67% | Training loss: 0.6870228357784084
Epoch: 99 | Iteration number: [3060/4518] 67% | Training loss: 0.6870235106719086
Epoch: 99 | Iteration number: [3070/4518] 67% | Training loss: 0.6870229106966758
Epoch: 99 | Iteration number: [3080/4518] 68% | Training loss: 0.6870241118522433
Epoch: 99 | Iteration number: [3090/4518] 68% | Training loss: 0.6870197262578798
Epoch: 99 | Iteration number: [3100/4518] 68% | Training loss: 0.6870178952524739
Epoch: 99 | Iteration number: [3110/4518] 68% | Training loss: 0.6870164730349537
Epoch: 99 | Iteration number: [3120/4518] 69% | Training loss: 0.6870190007373308
Epoch: 99 | Iteration number: [3130/4518] 69% | Training loss: 0.6870210211497907
Epoch: 99 | Iteration number: [3140/4518] 69% | Training loss: 0.6870214620213599
Epoch: 99 | Iteration number: [3150/4518] 69% | Training loss: 0.6870215266848367
Epoch: 99 | Iteration number: [3160/4518] 69% | Training loss: 0.6870165999554381
Epoch: 99 | Iteration number: [3170/4518] 70% | Training loss: 0.6870127632978963
Epoch: 99 | Iteration number: [3180/4518] 70% | Training loss: 0.6870091588429685
Epoch: 99 | Iteration number: [3190/4518] 70% | Training loss: 0.6870084208941385
Epoch: 99 | Iteration number: [3200/4518] 70% | Training loss: 0.6870052737183869
Epoch: 99 | Iteration number: [3210/4518] 71% | Training loss: 0.6870024080402755
Epoch: 99 | Iteration number: [3220/4518] 71% | Training loss: 0.6869988306338742
Epoch: 99 | Iteration number: [3230/4518] 71% | Training loss: 0.6869992613792419
Epoch: 99 | Iteration number: [3240/4518] 71% | Training loss: 0.6869953593538132
Epoch: 99 | Iteration number: [3250/4518] 71% | Training loss: 0.6869945282752697
Epoch: 99 | Iteration number: [3260/4518] 72% | Training loss: 0.6869934060456563
Epoch: 99 | Iteration number: [3270/4518] 72% | Training loss: 0.6869975733283098
Epoch: 99 | Iteration number: [3280/4518] 72% | Training loss: 0.6869984772692367
Epoch: 99 | Iteration number: [3290/4518] 72% | Training loss: 0.6869979743537207
Epoch: 99 | Iteration number: [3300/4518] 73% | Training loss: 0.6869964008439671
Epoch: 99 | Iteration number: [3310/4518] 73% | Training loss: 0.6869967597849059
Epoch: 99 | Iteration number: [3320/4518] 73% | Training loss: 0.686999122457332
Epoch: 99 | Iteration number: [3330/4518] 73% | Training loss: 0.6869969673700876
Epoch: 99 | Iteration number: [3340/4518] 73% | Training loss: 0.6869950954071776
Epoch: 99 | Iteration number: [3350/4518] 74% | Training loss: 0.6869938159878575
Epoch: 99 | Iteration number: [3360/4518] 74% | Training loss: 0.6869952445761078
Epoch: 99 | Iteration number: [3370/4518] 74% | Training loss: 0.6869937750988969
Epoch: 99 | Iteration number: [3380/4518] 74% | Training loss: 0.6869976208583843
Epoch: 99 | Iteration number: [3390/4518] 75% | Training loss: 0.6869976599132065
Epoch: 99 | Iteration number: [3400/4518] 75% | Training loss: 0.6869948058093296
Epoch: 99 | Iteration number: [3410/4518] 75% | Training loss: 0.6869916042274744
Epoch: 99 | Iteration number: [3420/4518] 75% | Training loss: 0.6869903646540223
Epoch: 99 | Iteration number: [3430/4518] 75% | Training loss: 0.6869889996315925
Epoch: 99 | Iteration number: [3440/4518] 76% | Training loss: 0.6869859065773876
Epoch: 99 | Iteration number: [3450/4518] 76% | Training loss: 0.6869805183099664
Epoch: 99 | Iteration number: [3460/4518] 76% | Training loss: 0.6869801192097581
Epoch: 99 | Iteration number: [3470/4518] 76% | Training loss: 0.6869774390194533
Epoch: 99 | Iteration number: [3480/4518] 77% | Training loss: 0.6869787223551466
Epoch: 99 | Iteration number: [3490/4518] 77% | Training loss: 0.6869752543020385
Epoch: 99 | Iteration number: [3500/4518] 77% | Training loss: 0.6869792269468308
Epoch: 99 | Iteration number: [3510/4518] 77% | Training loss: 0.6869779174653893
Epoch: 99 | Iteration number: [3520/4518] 77% | Training loss: 0.6869763577018272
Epoch: 99 | Iteration number: [3530/4518] 78% | Training loss: 0.686973793665343
Epoch: 99 | Iteration number: [3540/4518] 78% | Training loss: 0.6869706272068671
Epoch: 99 | Iteration number: [3550/4518] 78% | Training loss: 0.6869673417487615
Epoch: 99 | Iteration number: [3560/4518] 78% | Training loss: 0.6869684525587586
Epoch: 99 | Iteration number: [3570/4518] 79% | Training loss: 0.6869695499163716
Epoch: 99 | Iteration number: [3580/4518] 79% | Training loss: 0.6869676036042208
Epoch: 99 | Iteration number: [3590/4518] 79% | Training loss: 0.6869678239802464
Epoch: 99 | Iteration number: [3600/4518] 79% | Training loss: 0.6869644303454293
Epoch: 99 | Iteration number: [3610/4518] 79% | Training loss: 0.6869625710384337
Epoch: 99 | Iteration number: [3620/4518] 80% | Training loss: 0.6869638962475635
Epoch: 99 | Iteration number: [3630/4518] 80% | Training loss: 0.6869624008817121
Epoch: 99 | Iteration number: [3640/4518] 80% | Training loss: 0.6869612486316607
Epoch: 99 | Iteration number: [3650/4518] 80% | Training loss: 0.6869629571372515
Epoch: 99 | Iteration number: [3660/4518] 81% | Training loss: 0.6869623250648623
Epoch: 99 | Iteration number: [3670/4518] 81% | Training loss: 0.6869646067677792
Epoch: 99 | Iteration number: [3680/4518] 81% | Training loss: 0.686961858978738
Epoch: 99 | Iteration number: [3690/4518] 81% | Training loss: 0.686966363685887
Epoch: 99 | Iteration number: [3700/4518] 81% | Training loss: 0.6869679886908144
Epoch: 99 | Iteration number: [3710/4518] 82% | Training loss: 0.6869716402334023
Epoch: 99 | Iteration number: [3720/4518] 82% | Training loss: 0.6869725792959173
Epoch: 99 | Iteration number: [3730/4518] 82% | Training loss: 0.6869719567311673
Epoch: 99 | Iteration number: [3740/4518] 82% | Training loss: 0.6869729676826752
Epoch: 99 | Iteration number: [3750/4518] 83% | Training loss: 0.6869747006416321
Epoch: 99 | Iteration number: [3760/4518] 83% | Training loss: 0.6869759848935807
Epoch: 99 | Iteration number: [3770/4518] 83% | Training loss: 0.6869748660676992
Epoch: 99 | Iteration number: [3780/4518] 83% | Training loss: 0.6869740341863935
Epoch: 99 | Iteration number: [3790/4518] 83% | Training loss: 0.6869718189289827
Epoch: 99 | Iteration number: [3800/4518] 84% | Training loss: 0.6869714594985309
Epoch: 99 | Iteration number: [3810/4518] 84% | Training loss: 0.6869678993394056
Epoch: 99 | Iteration number: [3820/4518] 84% | Training loss: 0.686965635777768
Epoch: 99 | Iteration number: [3830/4518] 84% | Training loss: 0.6869675112455383
Epoch: 99 | Iteration number: [3840/4518] 84% | Training loss: 0.686963449170192
Epoch: 99 | Iteration number: [3850/4518] 85% | Training loss: 0.6869589399826991
Epoch: 99 | Iteration number: [3860/4518] 85% | Training loss: 0.6869558753899342
Epoch: 99 | Iteration number: [3870/4518] 85% | Training loss: 0.6869558111179707
Epoch: 99 | Iteration number: [3880/4518] 85% | Training loss: 0.6869541053765827
Epoch: 99 | Iteration number: [3890/4518] 86% | Training loss: 0.6869539121276003
Epoch: 99 | Iteration number: [3900/4518] 86% | Training loss: 0.6869509923916597
Epoch: 99 | Iteration number: [3910/4518] 86% | Training loss: 0.6869483767567998
Epoch: 99 | Iteration number: [3920/4518] 86% | Training loss: 0.686946492170801
Epoch: 99 | Iteration number: [3930/4518] 86% | Training loss: 0.6869452433125056
Epoch: 99 | Iteration number: [3940/4518] 87% | Training loss: 0.6869476436207137
Epoch: 99 | Iteration number: [3950/4518] 87% | Training loss: 0.6869455034521562
Epoch: 99 | Iteration number: [3960/4518] 87% | Training loss: 0.6869413081744704
Epoch: 99 | Iteration number: [3970/4518] 87% | Training loss: 0.6869389038542356
Epoch: 99 | Iteration number: [3980/4518] 88% | Training loss: 0.6869355804207337
Epoch: 99 | Iteration number: [3990/4518] 88% | Training loss: 0.6869356637311759
Epoch: 99 | Iteration number: [4000/4518] 88% | Training loss: 0.6869316869080067
Epoch: 99 | Iteration number: [4010/4518] 88% | Training loss: 0.686930675265795
Epoch: 99 | Iteration number: [4020/4518] 88% | Training loss: 0.6869263979036416
Epoch: 99 | Iteration number: [4030/4518] 89% | Training loss: 0.6869242041045915
Epoch: 99 | Iteration number: [4040/4518] 89% | Training loss: 0.6869270830018686
Epoch: 99 | Iteration number: [4050/4518] 89% | Training loss: 0.6869272904042845
Epoch: 99 | Iteration number: [4060/4518] 89% | Training loss: 0.6869271868849035
Epoch: 99 | Iteration number: [4070/4518] 90% | Training loss: 0.6869287407368934
Epoch: 99 | Iteration number: [4080/4518] 90% | Training loss: 0.6869288781548247
Epoch: 99 | Iteration number: [4090/4518] 90% | Training loss: 0.6869308767225457
Epoch: 99 | Iteration number: [4100/4518] 90% | Training loss: 0.6869312842153922
Epoch: 99 | Iteration number: [4110/4518] 90% | Training loss: 0.6869293947869554
Epoch: 99 | Iteration number: [4120/4518] 91% | Training loss: 0.6869241337463694
Epoch: 99 | Iteration number: [4130/4518] 91% | Training loss: 0.6869233858354444
Epoch: 99 | Iteration number: [4140/4518] 91% | Training loss: 0.6869229493941662
Epoch: 99 | Iteration number: [4150/4518] 91% | Training loss: 0.6869227848570031
Epoch: 99 | Iteration number: [4160/4518] 92% | Training loss: 0.6869207210982076
Epoch: 99 | Iteration number: [4170/4518] 92% | Training loss: 0.6869171472190381
Epoch: 99 | Iteration number: [4180/4518] 92% | Training loss: 0.6869176998092797
Epoch: 99 | Iteration number: [4190/4518] 92% | Training loss: 0.6869146972254523
Epoch: 99 | Iteration number: [4200/4518] 92% | Training loss: 0.6869155387225605
Epoch: 99 | Iteration number: [4210/4518] 93% | Training loss: 0.6869182187417907
Epoch: 99 | Iteration number: [4220/4518] 93% | Training loss: 0.6869148201428319
Epoch: 99 | Iteration number: [4230/4518] 93% | Training loss: 0.6869166192151694
Epoch: 99 | Iteration number: [4240/4518] 93% | Training loss: 0.6869139623810661
Epoch: 99 | Iteration number: [4250/4518] 94% | Training loss: 0.6869134145624497
Epoch: 99 | Iteration number: [4260/4518] 94% | Training loss: 0.686913065759229
Epoch: 99 | Iteration number: [4270/4518] 94% | Training loss: 0.6869117859934197
Epoch: 99 | Iteration number: [4280/4518] 94% | Training loss: 0.6869113921005036
Epoch: 99 | Iteration number: [4290/4518] 94% | Training loss: 0.6869127548380054
Epoch: 99 | Iteration number: [4300/4518] 95% | Training loss: 0.6869135498168857
Epoch: 99 | Iteration number: [4310/4518] 95% | Training loss: 0.6869169366055464
Epoch: 99 | Iteration number: [4320/4518] 95% | Training loss: 0.6869193317575587
Epoch: 99 | Iteration number: [4330/4518] 95% | Training loss: 0.6869170513632116
Epoch: 99 | Iteration number: [4340/4518] 96% | Training loss: 0.6869184201763522
Epoch: 99 | Iteration number: [4350/4518] 96% | Training loss: 0.686920499815338
Epoch: 99 | Iteration number: [4360/4518] 96% | Training loss: 0.686916418223206
Epoch: 99 | Iteration number: [4370/4518] 96% | Training loss: 0.6869148673809365
Epoch: 99 | Iteration number: [4380/4518] 96% | Training loss: 0.6869125912722932
Epoch: 99 | Iteration number: [4390/4518] 97% | Training loss: 0.6869149415531028
Epoch: 99 | Iteration number: [4400/4518] 97% | Training loss: 0.6869107300720432
Epoch: 99 | Iteration number: [4410/4518] 97% | Training loss: 0.6869107915836127
Epoch: 99 | Iteration number: [4420/4518] 97% | Training loss: 0.6869108148020318
Epoch: 99 | Iteration number: [4430/4518] 98% | Training loss: 0.6869123676425986
Epoch: 99 | Iteration number: [4440/4518] 98% | Training loss: 0.686910641596124
Epoch: 99 | Iteration number: [4450/4518] 98% | Training loss: 0.6869077238340057
Epoch: 99 | Iteration number: [4460/4518] 98% | Training loss: 0.6869054571529141
Epoch: 99 | Iteration number: [4470/4518] 98% | Training loss: 0.6869056765131769
Epoch: 99 | Iteration number: [4480/4518] 99% | Training loss: 0.6869066516336586
Epoch: 99 | Iteration number: [4490/4518] 99% | Training loss: 0.6869044156674553
Epoch: 99 | Iteration number: [4500/4518] 99% | Training loss: 0.6869033186038335
Epoch: 99 | Iteration number: [4510/4518] 99% | Training loss: 0.6869020588514282

 End of epoch: 99 | Train Loss: 0.6867472939176757 | Training Time: 641 

 End of epoch: 99 | Eval Loss: 0.6897440151292451 | Evaluating Time: 17 
Epoch: 100 | Iteration number: [10/4518] 0% | Training loss: 0.7555239856243133
Epoch: 100 | Iteration number: [20/4518] 0% | Training loss: 0.721801221370697
Epoch: 100 | Iteration number: [30/4518] 0% | Training loss: 0.709979259967804
Epoch: 100 | Iteration number: [40/4518] 0% | Training loss: 0.704257769882679
Epoch: 100 | Iteration number: [50/4518] 1% | Training loss: 0.7004104697704315
Epoch: 100 | Iteration number: [60/4518] 1% | Training loss: 0.6981458216905594
Epoch: 100 | Iteration number: [70/4518] 1% | Training loss: 0.6965721317699978
Epoch: 100 | Iteration number: [80/4518] 1% | Training loss: 0.6953572802245617
Epoch: 100 | Iteration number: [90/4518] 1% | Training loss: 0.6944134838051266
Epoch: 100 | Iteration number: [100/4518] 2% | Training loss: 0.6935908311605453
Epoch: 100 | Iteration number: [110/4518] 2% | Training loss: 0.6928958329287442
Epoch: 100 | Iteration number: [120/4518] 2% | Training loss: 0.6923658569653829
Epoch: 100 | Iteration number: [130/4518] 2% | Training loss: 0.6920069978787349
Epoch: 100 | Iteration number: [140/4518] 3% | Training loss: 0.6916451739413397
Epoch: 100 | Iteration number: [150/4518] 3% | Training loss: 0.6913032432397207
Epoch: 100 | Iteration number: [160/4518] 3% | Training loss: 0.6909975290298462
Epoch: 100 | Iteration number: [170/4518] 3% | Training loss: 0.6906506384120268
Epoch: 100 | Iteration number: [180/4518] 3% | Training loss: 0.6904777867926492
Epoch: 100 | Iteration number: [190/4518] 4% | Training loss: 0.6902755649466263
Epoch: 100 | Iteration number: [200/4518] 4% | Training loss: 0.6900063228607177
Epoch: 100 | Iteration number: [210/4518] 4% | Training loss: 0.6898919071469988
Epoch: 100 | Iteration number: [220/4518] 4% | Training loss: 0.6897818595170975
Epoch: 100 | Iteration number: [230/4518] 5% | Training loss: 0.689688341513924
Epoch: 100 | Iteration number: [240/4518] 5% | Training loss: 0.6895734158655008
Epoch: 100 | Iteration number: [250/4518] 5% | Training loss: 0.6894447810649872
Epoch: 100 | Iteration number: [260/4518] 5% | Training loss: 0.689377856025329
Epoch: 100 | Iteration number: [270/4518] 5% | Training loss: 0.6893000022128776
Epoch: 100 | Iteration number: [280/4518] 6% | Training loss: 0.6892314625637872
Epoch: 100 | Iteration number: [290/4518] 6% | Training loss: 0.6891601155544149
Epoch: 100 | Iteration number: [300/4518] 6% | Training loss: 0.6890783214569092
Epoch: 100 | Iteration number: [310/4518] 6% | Training loss: 0.6890271992452683
Epoch: 100 | Iteration number: [320/4518] 7% | Training loss: 0.6889536216855049
Epoch: 100 | Iteration number: [330/4518] 7% | Training loss: 0.6889074838522709
Epoch: 100 | Iteration number: [340/4518] 7% | Training loss: 0.688898110039094
Epoch: 100 | Iteration number: [350/4518] 7% | Training loss: 0.6888352799415588
Epoch: 100 | Iteration number: [360/4518] 7% | Training loss: 0.6887909033232265
Epoch: 100 | Iteration number: [370/4518] 8% | Training loss: 0.6887511205028843
Epoch: 100 | Iteration number: [380/4518] 8% | Training loss: 0.6887044657217829
Epoch: 100 | Iteration number: [390/4518] 8% | Training loss: 0.6886427720387777
Epoch: 100 | Iteration number: [400/4518] 8% | Training loss: 0.6885641743242741
Epoch: 100 | Iteration number: [410/4518] 9% | Training loss: 0.6884889801827873
Epoch: 100 | Iteration number: [420/4518] 9% | Training loss: 0.6884423583745957
Epoch: 100 | Iteration number: [430/4518] 9% | Training loss: 0.6883900739425837
Epoch: 100 | Iteration number: [440/4518] 9% | Training loss: 0.6883472269231623
Epoch: 100 | Iteration number: [450/4518] 9% | Training loss: 0.6883265374766456
Epoch: 100 | Iteration number: [460/4518] 10% | Training loss: 0.688268634547358
Epoch: 100 | Iteration number: [470/4518] 10% | Training loss: 0.6882405875845158
Epoch: 100 | Iteration number: [480/4518] 10% | Training loss: 0.6882067985832692
Epoch: 100 | Iteration number: [490/4518] 10% | Training loss: 0.6881631700360045
Epoch: 100 | Iteration number: [500/4518] 11% | Training loss: 0.6881630402803421
Epoch: 100 | Iteration number: [510/4518] 11% | Training loss: 0.6881299502709333
Epoch: 100 | Iteration number: [520/4518] 11% | Training loss: 0.6881072400854185
Epoch: 100 | Iteration number: [530/4518] 11% | Training loss: 0.6880701319226679
Epoch: 100 | Iteration number: [540/4518] 11% | Training loss: 0.6880257040262222
Epoch: 100 | Iteration number: [550/4518] 12% | Training loss: 0.687990079684691
Epoch: 100 | Iteration number: [560/4518] 12% | Training loss: 0.6879691644438676
Epoch: 100 | Iteration number: [570/4518] 12% | Training loss: 0.6879406216897462
Epoch: 100 | Iteration number: [580/4518] 12% | Training loss: 0.6879283955384945
Epoch: 100 | Iteration number: [590/4518] 13% | Training loss: 0.6879193777755156
Epoch: 100 | Iteration number: [600/4518] 13% | Training loss: 0.6878967382510504
Epoch: 100 | Iteration number: [610/4518] 13% | Training loss: 0.6878914570222135
Epoch: 100 | Iteration number: [620/4518] 13% | Training loss: 0.6878592245040401
Epoch: 100 | Iteration number: [630/4518] 13% | Training loss: 0.6878404503776914
Epoch: 100 | Iteration number: [640/4518] 14% | Training loss: 0.687833912204951
Epoch: 100 | Iteration number: [650/4518] 14% | Training loss: 0.6878174325136038
Epoch: 100 | Iteration number: [660/4518] 14% | Training loss: 0.6877885389508623
Epoch: 100 | Iteration number: [670/4518] 14% | Training loss: 0.6877557928882428
Epoch: 100 | Iteration number: [680/4518] 15% | Training loss: 0.6877485628513729
Epoch: 100 | Iteration number: [690/4518] 15% | Training loss: 0.6877536388411039
Epoch: 100 | Iteration number: [700/4518] 15% | Training loss: 0.687713177374431
Epoch: 100 | Iteration number: [710/4518] 15% | Training loss: 0.6877050654988893
Epoch: 100 | Iteration number: [720/4518] 15% | Training loss: 0.6876988041732046
Epoch: 100 | Iteration number: [730/4518] 16% | Training loss: 0.6876971960884251
Epoch: 100 | Iteration number: [740/4518] 16% | Training loss: 0.6877020631287549
Epoch: 100 | Iteration number: [750/4518] 16% | Training loss: 0.6876895742416382
Epoch: 100 | Iteration number: [760/4518] 16% | Training loss: 0.6876836609683539
Epoch: 100 | Iteration number: [770/4518] 17% | Training loss: 0.6876749946699514
Epoch: 100 | Iteration number: [780/4518] 17% | Training loss: 0.6876734452369886
Epoch: 100 | Iteration number: [790/4518] 17% | Training loss: 0.6876550500151477
Epoch: 100 | Iteration number: [800/4518] 17% | Training loss: 0.6876495667546988
Epoch: 100 | Iteration number: [810/4518] 17% | Training loss: 0.6876414179066082
Epoch: 100 | Iteration number: [820/4518] 18% | Training loss: 0.6876243038148415
Epoch: 100 | Iteration number: [830/4518] 18% | Training loss: 0.6876171609723424
Epoch: 100 | Iteration number: [840/4518] 18% | Training loss: 0.6876100711169697
Epoch: 100 | Iteration number: [850/4518] 18% | Training loss: 0.6876076615557951
Epoch: 100 | Iteration number: [860/4518] 19% | Training loss: 0.6876027564669764
Epoch: 100 | Iteration number: [870/4518] 19% | Training loss: 0.6875901778539022
Epoch: 100 | Iteration number: [880/4518] 19% | Training loss: 0.6875850127501921
Epoch: 100 | Iteration number: [890/4518] 19% | Training loss: 0.6875824437382516
Epoch: 100 | Iteration number: [900/4518] 19% | Training loss: 0.6875798784361945
Epoch: 100 | Iteration number: [910/4518] 20% | Training loss: 0.6875749110520541
Epoch: 100 | Iteration number: [920/4518] 20% | Training loss: 0.6875681478044261
Epoch: 100 | Iteration number: [930/4518] 20% | Training loss: 0.6875419083461967
Epoch: 100 | Iteration number: [940/4518] 20% | Training loss: 0.6875531127478214
Epoch: 100 | Iteration number: [950/4518] 21% | Training loss: 0.6875412573312458
Epoch: 100 | Iteration number: [960/4518] 21% | Training loss: 0.6875426658118765
Epoch: 100 | Iteration number: [970/4518] 21% | Training loss: 0.6875233312857519
Epoch: 100 | Iteration number: [980/4518] 21% | Training loss: 0.6875083521312597
Epoch: 100 | Iteration number: [990/4518] 21% | Training loss: 0.687519493970004
Epoch: 100 | Iteration number: [1000/4518] 22% | Training loss: 0.6875216293334961
Epoch: 100 | Iteration number: [1010/4518] 22% | Training loss: 0.6875175123757655
Epoch: 100 | Iteration number: [1020/4518] 22% | Training loss: 0.687504604341937
Epoch: 100 | Iteration number: [1030/4518] 22% | Training loss: 0.6875067221886904
Epoch: 100 | Iteration number: [1040/4518] 23% | Training loss: 0.6875043601370775
Epoch: 100 | Iteration number: [1050/4518] 23% | Training loss: 0.6874864934171949
Epoch: 100 | Iteration number: [1060/4518] 23% | Training loss: 0.6874759078025818
Epoch: 100 | Iteration number: [1070/4518] 23% | Training loss: 0.6874676076608284
Epoch: 100 | Iteration number: [1080/4518] 23% | Training loss: 0.6874610526694191
Epoch: 100 | Iteration number: [1090/4518] 24% | Training loss: 0.6874494608389128
Epoch: 100 | Iteration number: [1100/4518] 24% | Training loss: 0.6874474759535356
Epoch: 100 | Iteration number: [1110/4518] 24% | Training loss: 0.6874431640178233
Epoch: 100 | Iteration number: [1120/4518] 24% | Training loss: 0.6874380560857909
Epoch: 100 | Iteration number: [1130/4518] 25% | Training loss: 0.6874277286824927
Epoch: 100 | Iteration number: [1140/4518] 25% | Training loss: 0.6874264191117203
Epoch: 100 | Iteration number: [1150/4518] 25% | Training loss: 0.6874087141389432
Epoch: 100 | Iteration number: [1160/4518] 25% | Training loss: 0.6873989500876131
Epoch: 100 | Iteration number: [1170/4518] 25% | Training loss: 0.6873964072802128
Epoch: 100 | Iteration number: [1180/4518] 26% | Training loss: 0.6873977711645224
Epoch: 100 | Iteration number: [1190/4518] 26% | Training loss: 0.6873897285020651
Epoch: 100 | Iteration number: [1200/4518] 26% | Training loss: 0.6873850603401661
Epoch: 100 | Iteration number: [1210/4518] 26% | Training loss: 0.6873750619159257
Epoch: 100 | Iteration number: [1220/4518] 27% | Training loss: 0.6873760314749889
Epoch: 100 | Iteration number: [1230/4518] 27% | Training loss: 0.6873779919573931
Epoch: 100 | Iteration number: [1240/4518] 27% | Training loss: 0.6873549964639448
Epoch: 100 | Iteration number: [1250/4518] 27% | Training loss: 0.6873435719490051
Epoch: 100 | Iteration number: [1260/4518] 27% | Training loss: 0.6873337531373614
Epoch: 100 | Iteration number: [1270/4518] 28% | Training loss: 0.6873196337636062
Epoch: 100 | Iteration number: [1280/4518] 28% | Training loss: 0.6873122525867075
Epoch: 100 | Iteration number: [1290/4518] 28% | Training loss: 0.6873115414334822
Epoch: 100 | Iteration number: [1300/4518] 28% | Training loss: 0.6873032543292412
Epoch: 100 | Iteration number: [1310/4518] 28% | Training loss: 0.6873064147152064
Epoch: 100 | Iteration number: [1320/4518] 29% | Training loss: 0.6873097915089492
Epoch: 100 | Iteration number: [1330/4518] 29% | Training loss: 0.6873000308086997
Epoch: 100 | Iteration number: [1340/4518] 29% | Training loss: 0.6872938745502216
Epoch: 100 | Iteration number: [1350/4518] 29% | Training loss: 0.6872942658706948
Epoch: 100 | Iteration number: [1360/4518] 30% | Training loss: 0.6872956615598763
Epoch: 100 | Iteration number: [1370/4518] 30% | Training loss: 0.6872971021345932
Epoch: 100 | Iteration number: [1380/4518] 30% | Training loss: 0.6872938503389773
Epoch: 100 | Iteration number: [1390/4518] 30% | Training loss: 0.6872904362438395
Epoch: 100 | Iteration number: [1400/4518] 30% | Training loss: 0.6872775443962642
Epoch: 100 | Iteration number: [1410/4518] 31% | Training loss: 0.6872776310071878
Epoch: 100 | Iteration number: [1420/4518] 31% | Training loss: 0.6872640851098047
Epoch: 100 | Iteration number: [1430/4518] 31% | Training loss: 0.6872556816031049
Epoch: 100 | Iteration number: [1440/4518] 31% | Training loss: 0.6872534610331058
Epoch: 100 | Iteration number: [1450/4518] 32% | Training loss: 0.6872536483304253
Epoch: 100 | Iteration number: [1460/4518] 32% | Training loss: 0.6872509174967465
Epoch: 100 | Iteration number: [1470/4518] 32% | Training loss: 0.6872455802904506
Epoch: 100 | Iteration number: [1480/4518] 32% | Training loss: 0.6872452373842936
Epoch: 100 | Iteration number: [1490/4518] 32% | Training loss: 0.6872412193941589
Epoch: 100 | Iteration number: [1500/4518] 33% | Training loss: 0.6872348410685857
Epoch: 100 | Iteration number: [1510/4518] 33% | Training loss: 0.6872348520534718
Epoch: 100 | Iteration number: [1520/4518] 33% | Training loss: 0.6872362051355211
Epoch: 100 | Iteration number: [1530/4518] 33% | Training loss: 0.6872362023085551
Epoch: 100 | Iteration number: [1540/4518] 34% | Training loss: 0.6872278194148819
Epoch: 100 | Iteration number: [1550/4518] 34% | Training loss: 0.6872253001889875
Epoch: 100 | Iteration number: [1560/4518] 34% | Training loss: 0.6872285274358896
Epoch: 100 | Iteration number: [1570/4518] 34% | Training loss: 0.6872310204111087
Epoch: 100 | Iteration number: [1580/4518] 34% | Training loss: 0.6872273723913145
Epoch: 100 | Iteration number: [1590/4518] 35% | Training loss: 0.6872296581853111
Epoch: 100 | Iteration number: [1600/4518] 35% | Training loss: 0.6872272934764624
Epoch: 100 | Iteration number: [1610/4518] 35% | Training loss: 0.6872311433649951
Epoch: 100 | Iteration number: [1620/4518] 35% | Training loss: 0.6872311311003603
Epoch: 100 | Iteration number: [1630/4518] 36% | Training loss: 0.6872326948525715
Epoch: 100 | Iteration number: [1640/4518] 36% | Training loss: 0.6872333050137613
Epoch: 100 | Iteration number: [1650/4518] 36% | Training loss: 0.6872269109523658
Epoch: 100 | Iteration number: [1660/4518] 36% | Training loss: 0.6872280441134809
Epoch: 100 | Iteration number: [1670/4518] 36% | Training loss: 0.6872245016212235
Epoch: 100 | Iteration number: [1680/4518] 37% | Training loss: 0.6872222874136198
Epoch: 100 | Iteration number: [1690/4518] 37% | Training loss: 0.6872164624329855
Epoch: 100 | Iteration number: [1700/4518] 37% | Training loss: 0.6872165646973778
Epoch: 100 | Iteration number: [1710/4518] 37% | Training loss: 0.6872109420815407
Epoch: 100 | Iteration number: [1720/4518] 38% | Training loss: 0.6872065273481746
Epoch: 100 | Iteration number: [1730/4518] 38% | Training loss: 0.687194223038723
Epoch: 100 | Iteration number: [1740/4518] 38% | Training loss: 0.6871876483676077
Epoch: 100 | Iteration number: [1750/4518] 38% | Training loss: 0.6871887016636985
Epoch: 100 | Iteration number: [1760/4518] 38% | Training loss: 0.6871926409277049
Epoch: 100 | Iteration number: [1770/4518] 39% | Training loss: 0.6871816336771863
Epoch: 100 | Iteration number: [1780/4518] 39% | Training loss: 0.6871814604555623
Epoch: 100 | Iteration number: [1790/4518] 39% | Training loss: 0.6871727464585331
Epoch: 100 | Iteration number: [1800/4518] 39% | Training loss: 0.6871730471981896
Epoch: 100 | Iteration number: [1810/4518] 40% | Training loss: 0.6871654537501256
Epoch: 100 | Iteration number: [1820/4518] 40% | Training loss: 0.6871725631939186
Epoch: 100 | Iteration number: [1830/4518] 40% | Training loss: 0.6871691880981778
Epoch: 100 | Iteration number: [1840/4518] 40% | Training loss: 0.6871668272692224
Epoch: 100 | Iteration number: [1850/4518] 40% | Training loss: 0.6871660475150959
Epoch: 100 | Iteration number: [1860/4518] 41% | Training loss: 0.6871671771490445
Epoch: 100 | Iteration number: [1870/4518] 41% | Training loss: 0.6871636099356381
Epoch: 100 | Iteration number: [1880/4518] 41% | Training loss: 0.6871609593642519
Epoch: 100 | Iteration number: [1890/4518] 41% | Training loss: 0.6871565400923371
Epoch: 100 | Iteration number: [1900/4518] 42% | Training loss: 0.687152641196
Epoch: 100 | Iteration number: [1910/4518] 42% | Training loss: 0.6871538605053388
Epoch: 100 | Iteration number: [1920/4518] 42% | Training loss: 0.6871505671180784
Epoch: 100 | Iteration number: [1930/4518] 42% | Training loss: 0.6871494542749434
Epoch: 100 | Iteration number: [1940/4518] 42% | Training loss: 0.6871441746495434
Epoch: 100 | Iteration number: [1950/4518] 43% | Training loss: 0.687140999971292
Epoch: 100 | Iteration number: [1960/4518] 43% | Training loss: 0.6871305748820304
Epoch: 100 | Iteration number: [1970/4518] 43% | Training loss: 0.6871234487458534
Epoch: 100 | Iteration number: [1980/4518] 43% | Training loss: 0.6871207151750122
Epoch: 100 | Iteration number: [1990/4518] 44% | Training loss: 0.687119830912681
Epoch: 100 | Iteration number: [2000/4518] 44% | Training loss: 0.6871236473619938
Epoch: 100 | Iteration number: [2010/4518] 44% | Training loss: 0.6871250689622774
Epoch: 100 | Iteration number: [2020/4518] 44% | Training loss: 0.6871262433800367
Epoch: 100 | Iteration number: [2030/4518] 44% | Training loss: 0.6871286472076266
Epoch: 100 | Iteration number: [2040/4518] 45% | Training loss: 0.6871345660265754
Epoch: 100 | Iteration number: [2050/4518] 45% | Training loss: 0.6871298542546063
Epoch: 100 | Iteration number: [2060/4518] 45% | Training loss: 0.6871281201110303
Epoch: 100 | Iteration number: [2070/4518] 45% | Training loss: 0.6871277539338466
Epoch: 100 | Iteration number: [2080/4518] 46% | Training loss: 0.6871334636727204
Epoch: 100 | Iteration number: [2090/4518] 46% | Training loss: 0.6871286064528963
Epoch: 100 | Iteration number: [2100/4518] 46% | Training loss: 0.6871269351243973
Epoch: 100 | Iteration number: [2110/4518] 46% | Training loss: 0.6871230105088221
Epoch: 100 | Iteration number: [2120/4518] 46% | Training loss: 0.6871234994733109
Epoch: 100 | Iteration number: [2130/4518] 47% | Training loss: 0.6871246107867066
Epoch: 100 | Iteration number: [2140/4518] 47% | Training loss: 0.6871290146468956
Epoch: 100 | Iteration number: [2150/4518] 47% | Training loss: 0.6871325063982675
Epoch: 100 | Iteration number: [2160/4518] 47% | Training loss: 0.6871349681582716
Epoch: 100 | Iteration number: [2170/4518] 48% | Training loss: 0.6871318904760246
Epoch: 100 | Iteration number: [2180/4518] 48% | Training loss: 0.6871253127898646
Epoch: 100 | Iteration number: [2190/4518] 48% | Training loss: 0.6871251794301212
Epoch: 100 | Iteration number: [2200/4518] 48% | Training loss: 0.6871273848956282
Epoch: 100 | Iteration number: [2210/4518] 48% | Training loss: 0.6871206203467166
Epoch: 100 | Iteration number: [2220/4518] 49% | Training loss: 0.6871199553345775
Epoch: 100 | Iteration number: [2230/4518] 49% | Training loss: 0.6871156359734557
Epoch: 100 | Iteration number: [2240/4518] 49% | Training loss: 0.6871090124228171
Epoch: 100 | Iteration number: [2250/4518] 49% | Training loss: 0.6871116766399807
Epoch: 100 | Iteration number: [2260/4518] 50% | Training loss: 0.687110694820902
Epoch: 100 | Iteration number: [2270/4518] 50% | Training loss: 0.6871076649768763
Epoch: 100 | Iteration number: [2280/4518] 50% | Training loss: 0.6871098437330179
Epoch: 100 | Iteration number: [2290/4518] 50% | Training loss: 0.6871077138263586
Epoch: 100 | Iteration number: [2300/4518] 50% | Training loss: 0.6871119231244792
Epoch: 100 | Iteration number: [2310/4518] 51% | Training loss: 0.6871112519012386
Epoch: 100 | Iteration number: [2320/4518] 51% | Training loss: 0.6871081536186152
Epoch: 100 | Iteration number: [2330/4518] 51% | Training loss: 0.6871065569537904
Epoch: 100 | Iteration number: [2340/4518] 51% | Training loss: 0.6871013486487234
Epoch: 100 | Iteration number: [2350/4518] 52% | Training loss: 0.6871035650435915
Epoch: 100 | Iteration number: [2360/4518] 52% | Training loss: 0.6871054766541821
Epoch: 100 | Iteration number: [2370/4518] 52% | Training loss: 0.6870999016590762
Epoch: 100 | Iteration number: [2380/4518] 52% | Training loss: 0.6870917206551849
Epoch: 100 | Iteration number: [2390/4518] 52% | Training loss: 0.6870933216486017
Epoch: 100 | Iteration number: [2400/4518] 53% | Training loss: 0.6870958800862232
Epoch: 100 | Iteration number: [2410/4518] 53% | Training loss: 0.6870888687268333
Epoch: 100 | Iteration number: [2420/4518] 53% | Training loss: 0.6870848315560129
Epoch: 100 | Iteration number: [2430/4518] 53% | Training loss: 0.6870802671575742
Epoch: 100 | Iteration number: [2440/4518] 54% | Training loss: 0.6870794271836516
Epoch: 100 | Iteration number: [2450/4518] 54% | Training loss: 0.6870790347517753
Epoch: 100 | Iteration number: [2460/4518] 54% | Training loss: 0.6870759075976969
Epoch: 100 | Iteration number: [2470/4518] 54% | Training loss: 0.6870733957782931
Epoch: 100 | Iteration number: [2480/4518] 54% | Training loss: 0.687067745481768
Epoch: 100 | Iteration number: [2490/4518] 55% | Training loss: 0.6870657611084751
Epoch: 100 | Iteration number: [2500/4518] 55% | Training loss: 0.6870681924581528
Epoch: 100 | Iteration number: [2510/4518] 55% | Training loss: 0.6870653422230268
Epoch: 100 | Iteration number: [2520/4518] 55% | Training loss: 0.6870619166701559
Epoch: 100 | Iteration number: [2530/4518] 55% | Training loss: 0.6870593875764387
Epoch: 100 | Iteration number: [2540/4518] 56% | Training loss: 0.6870543830038056
Epoch: 100 | Iteration number: [2550/4518] 56% | Training loss: 0.6870572523042268
Epoch: 100 | Iteration number: [2560/4518] 56% | Training loss: 0.6870578524423763
Epoch: 100 | Iteration number: [2570/4518] 56% | Training loss: 0.6870513050008841
Epoch: 100 | Iteration number: [2580/4518] 57% | Training loss: 0.6870453614135121
Epoch: 100 | Iteration number: [2590/4518] 57% | Training loss: 0.687045123448243
Epoch: 100 | Iteration number: [2600/4518] 57% | Training loss: 0.6870393392672905
Epoch: 100 | Iteration number: [2610/4518] 57% | Training loss: 0.6870378138461789
Epoch: 100 | Iteration number: [2620/4518] 57% | Training loss: 0.6870318762901175
Epoch: 100 | Iteration number: [2630/4518] 58% | Training loss: 0.6870345410738607
Epoch: 100 | Iteration number: [2640/4518] 58% | Training loss: 0.687031499002919
Epoch: 100 | Iteration number: [2650/4518] 58% | Training loss: 0.6870321544836152
Epoch: 100 | Iteration number: [2660/4518] 58% | Training loss: 0.687028861269915
Epoch: 100 | Iteration number: [2670/4518] 59% | Training loss: 0.6870266987366622
Epoch: 100 | Iteration number: [2680/4518] 59% | Training loss: 0.6870189791517471
Epoch: 100 | Iteration number: [2690/4518] 59% | Training loss: 0.6870169944257984
Epoch: 100 | Iteration number: [2700/4518] 59% | Training loss: 0.6870197815806778
Epoch: 100 | Iteration number: [2710/4518] 59% | Training loss: 0.6870152460692993
Epoch: 100 | Iteration number: [2720/4518] 60% | Training loss: 0.6870144672910957
Epoch: 100 | Iteration number: [2730/4518] 60% | Training loss: 0.6870128280732222
Epoch: 100 | Iteration number: [2740/4518] 60% | Training loss: 0.6870127865215288
Epoch: 100 | Iteration number: [2750/4518] 60% | Training loss: 0.6870128343105316
Epoch: 100 | Iteration number: [2760/4518] 61% | Training loss: 0.6870083787518999
Epoch: 100 | Iteration number: [2770/4518] 61% | Training loss: 0.6870117246459108
Epoch: 100 | Iteration number: [2780/4518] 61% | Training loss: 0.6870056568933048
Epoch: 100 | Iteration number: [2790/4518] 61% | Training loss: 0.6870049571905512
Epoch: 100 | Iteration number: [2800/4518] 61% | Training loss: 0.6870019082086427
Epoch: 100 | Iteration number: [2810/4518] 62% | Training loss: 0.6870053746734226
Epoch: 100 | Iteration number: [2820/4518] 62% | Training loss: 0.6870033675897206
Epoch: 100 | Iteration number: [2830/4518] 62% | Training loss: 0.6869992684138537
Epoch: 100 | Iteration number: [2840/4518] 62% | Training loss: 0.686996262929809
Epoch: 100 | Iteration number: [2850/4518] 63% | Training loss: 0.6869965068708387
Epoch: 100 | Iteration number: [2860/4518] 63% | Training loss: 0.6869937391964706
Epoch: 100 | Iteration number: [2870/4518] 63% | Training loss: 0.6869933585464332
Epoch: 100 | Iteration number: [2880/4518] 63% | Training loss: 0.6869956041582757
Epoch: 100 | Iteration number: [2890/4518] 63% | Training loss: 0.686999355839198
Epoch: 100 | Iteration number: [2900/4518] 64% | Training loss: 0.6869955986121605
Epoch: 100 | Iteration number: [2910/4518] 64% | Training loss: 0.6869892274186373
Epoch: 100 | Iteration number: [2920/4518] 64% | Training loss: 0.6869876713785407
Epoch: 100 | Iteration number: [2930/4518] 64% | Training loss: 0.6869893701816988
Epoch: 100 | Iteration number: [2940/4518] 65% | Training loss: 0.6869926772150052
Epoch: 100 | Iteration number: [2950/4518] 65% | Training loss: 0.6869904776953034
Epoch: 100 | Iteration number: [2960/4518] 65% | Training loss: 0.6869919503661426
Epoch: 100 | Iteration number: [2970/4518] 65% | Training loss: 0.6869936941247998
Epoch: 100 | Iteration number: [2980/4518] 65% | Training loss: 0.6869885622654985
Epoch: 100 | Iteration number: [2990/4518] 66% | Training loss: 0.6869845906826963
Epoch: 100 | Iteration number: [3000/4518] 66% | Training loss: 0.6869817396799723
Epoch: 100 | Iteration number: [3010/4518] 66% | Training loss: 0.6869805127085246
Epoch: 100 | Iteration number: [3020/4518] 66% | Training loss: 0.6869733191681224
Epoch: 100 | Iteration number: [3030/4518] 67% | Training loss: 0.6869722225485069
Epoch: 100 | Iteration number: [3040/4518] 67% | Training loss: 0.6869698722111551
Epoch: 100 | Iteration number: [3050/4518] 67% | Training loss: 0.6869703561165293
Epoch: 100 | Iteration number: [3060/4518] 67% | Training loss: 0.6869719010942122
Epoch: 100 | Iteration number: [3070/4518] 67% | Training loss: 0.6869720287936518
Epoch: 100 | Iteration number: [3080/4518] 68% | Training loss: 0.6869704644594874
Epoch: 100 | Iteration number: [3090/4518] 68% | Training loss: 0.6869725611989166
Epoch: 100 | Iteration number: [3100/4518] 68% | Training loss: 0.6869665247009646
Epoch: 100 | Iteration number: [3110/4518] 68% | Training loss: 0.6869659999175853
Epoch: 100 | Iteration number: [3120/4518] 69% | Training loss: 0.6869635516825395
Epoch: 100 | Iteration number: [3130/4518] 69% | Training loss: 0.6869629759567614
Epoch: 100 | Iteration number: [3140/4518] 69% | Training loss: 0.6869649581089141
Epoch: 100 | Iteration number: [3150/4518] 69% | Training loss: 0.6869657210508983
Epoch: 100 | Iteration number: [3160/4518] 69% | Training loss: 0.6869633726681335
Epoch: 100 | Iteration number: [3170/4518] 70% | Training loss: 0.6869604966053827
Epoch: 100 | Iteration number: [3180/4518] 70% | Training loss: 0.6869599953574954
Epoch: 100 | Iteration number: [3190/4518] 70% | Training loss: 0.6869625159939254
Epoch: 100 | Iteration number: [3200/4518] 70% | Training loss: 0.6869663692638278
Epoch: 100 | Iteration number: [3210/4518] 71% | Training loss: 0.6869666980991482
Epoch: 100 | Iteration number: [3220/4518] 71% | Training loss: 0.6869669865747416
Epoch: 100 | Iteration number: [3230/4518] 71% | Training loss: 0.6869660941439886
Epoch: 100 | Iteration number: [3240/4518] 71% | Training loss: 0.6869639360978279
Epoch: 100 | Iteration number: [3250/4518] 71% | Training loss: 0.6869577414806073
Epoch: 100 | Iteration number: [3260/4518] 72% | Training loss: 0.6869616036400473
Epoch: 100 | Iteration number: [3270/4518] 72% | Training loss: 0.6869658382478475
Epoch: 100 | Iteration number: [3280/4518] 72% | Training loss: 0.6869644275162278
Epoch: 100 | Iteration number: [3290/4518] 72% | Training loss: 0.6869675224131726
Epoch: 100 | Iteration number: [3300/4518] 73% | Training loss: 0.6869691241509986
Epoch: 100 | Iteration number: [3310/4518] 73% | Training loss: 0.6869631194095958
Epoch: 100 | Iteration number: [3320/4518] 73% | Training loss: 0.6869637823068951
Epoch: 100 | Iteration number: [3330/4518] 73% | Training loss: 0.6869667508222678
Epoch: 100 | Iteration number: [3340/4518] 73% | Training loss: 0.6869636741940847
Epoch: 100 | Iteration number: [3350/4518] 74% | Training loss: 0.6869626456054289
Epoch: 100 | Iteration number: [3360/4518] 74% | Training loss: 0.686961118504405
Epoch: 100 | Iteration number: [3370/4518] 74% | Training loss: 0.6869592131068516
Epoch: 100 | Iteration number: [3380/4518] 74% | Training loss: 0.6869586047159849
Epoch: 100 | Iteration number: [3390/4518] 75% | Training loss: 0.6869581341215995
Epoch: 100 | Iteration number: [3400/4518] 75% | Training loss: 0.6869581025488236
Epoch: 100 | Iteration number: [3410/4518] 75% | Training loss: 0.686957943789071
Epoch: 100 | Iteration number: [3420/4518] 75% | Training loss: 0.6869541130742134
Epoch: 100 | Iteration number: [3430/4518] 75% | Training loss: 0.6869512218080526
Epoch: 100 | Iteration number: [3440/4518] 76% | Training loss: 0.6869542008395805
Epoch: 100 | Iteration number: [3450/4518] 76% | Training loss: 0.6869494938159334
Epoch: 100 | Iteration number: [3460/4518] 76% | Training loss: 0.6869468619196402
Epoch: 100 | Iteration number: [3470/4518] 76% | Training loss: 0.68694655914128
Epoch: 100 | Iteration number: [3480/4518] 77% | Training loss: 0.6869480147786524
Epoch: 100 | Iteration number: [3490/4518] 77% | Training loss: 0.6869456842157424
Epoch: 100 | Iteration number: [3500/4518] 77% | Training loss: 0.6869479067155293
Epoch: 100 | Iteration number: [3510/4518] 77% | Training loss: 0.6869456673279787
Epoch: 100 | Iteration number: [3520/4518] 77% | Training loss: 0.6869453942403198
Epoch: 100 | Iteration number: [3530/4518] 78% | Training loss: 0.6869439817184092
Epoch: 100 | Iteration number: [3540/4518] 78% | Training loss: 0.6869449607901654
Epoch: 100 | Iteration number: [3550/4518] 78% | Training loss: 0.686948759270386
Epoch: 100 | Iteration number: [3560/4518] 78% | Training loss: 0.6869443691513512
Epoch: 100 | Iteration number: [3570/4518] 79% | Training loss: 0.6869458706606002
Epoch: 100 | Iteration number: [3580/4518] 79% | Training loss: 0.6869467556476593
Epoch: 100 | Iteration number: [3590/4518] 79% | Training loss: 0.6869474114315756
Epoch: 100 | Iteration number: [3600/4518] 79% | Training loss: 0.686950993306107
Epoch: 100 | Iteration number: [3610/4518] 79% | Training loss: 0.686945904209343
Epoch: 100 | Iteration number: [3620/4518] 80% | Training loss: 0.6869448672671344
Epoch: 100 | Iteration number: [3630/4518] 80% | Training loss: 0.6869445450542387
Epoch: 100 | Iteration number: [3640/4518] 80% | Training loss: 0.6869415883998294
Epoch: 100 | Iteration number: [3650/4518] 80% | Training loss: 0.6869382942702672
Epoch: 100 | Iteration number: [3660/4518] 81% | Training loss: 0.686935740986157
Epoch: 100 | Iteration number: [3670/4518] 81% | Training loss: 0.6869356154258635
Epoch: 100 | Iteration number: [3680/4518] 81% | Training loss: 0.6869385031416364
Epoch: 100 | Iteration number: [3690/4518] 81% | Training loss: 0.6869397571254875
Epoch: 100 | Iteration number: [3700/4518] 81% | Training loss: 0.686937197575698
Epoch: 100 | Iteration number: [3710/4518] 82% | Training loss: 0.6869358619589689
Epoch: 100 | Iteration number: [3720/4518] 82% | Training loss: 0.6869345829051028
Epoch: 100 | Iteration number: [3730/4518] 82% | Training loss: 0.6869319062769892
Epoch: 100 | Iteration number: [3740/4518] 82% | Training loss: 0.6869328095154329
Epoch: 100 | Iteration number: [3750/4518] 83% | Training loss: 0.686930589278539
Epoch: 100 | Iteration number: [3760/4518] 83% | Training loss: 0.6869268982492863
Epoch: 100 | Iteration number: [3770/4518] 83% | Training loss: 0.6869273073951508
Epoch: 100 | Iteration number: [3780/4518] 83% | Training loss: 0.6869257643740013
Epoch: 100 | Iteration number: [3790/4518] 83% | Training loss: 0.6869263901716801
Epoch: 100 | Iteration number: [3800/4518] 84% | Training loss: 0.6869261917158177
Epoch: 100 | Iteration number: [3810/4518] 84% | Training loss: 0.6869268550491082
Epoch: 100 | Iteration number: [3820/4518] 84% | Training loss: 0.6869253729338421
Epoch: 100 | Iteration number: [3830/4518] 84% | Training loss: 0.6869247077494938
Epoch: 100 | Iteration number: [3840/4518] 84% | Training loss: 0.686923912462468
Epoch: 100 | Iteration number: [3850/4518] 85% | Training loss: 0.6869244081478614
Epoch: 100 | Iteration number: [3860/4518] 85% | Training loss: 0.6869212469443139
Epoch: 100 | Iteration number: [3870/4518] 85% | Training loss: 0.686922194606574
Epoch: 100 | Iteration number: [3880/4518] 85% | Training loss: 0.6869188093647515
Epoch: 100 | Iteration number: [3890/4518] 86% | Training loss: 0.6869198391860433
Epoch: 100 | Iteration number: [3900/4518] 86% | Training loss: 0.6869183171406771
Epoch: 100 | Iteration number: [3910/4518] 86% | Training loss: 0.6869158029861158
Epoch: 100 | Iteration number: [3920/4518] 86% | Training loss: 0.6869144286428179
Epoch: 100 | Iteration number: [3930/4518] 86% | Training loss: 0.6869123716997433
Epoch: 100 | Iteration number: [3940/4518] 87% | Training loss: 0.6869122496111139
Epoch: 100 | Iteration number: [3950/4518] 87% | Training loss: 0.6869137226478963
Epoch: 100 | Iteration number: [3960/4518] 87% | Training loss: 0.6869127331358014
Epoch: 100 | Iteration number: [3970/4518] 87% | Training loss: 0.6869140694363591
Epoch: 100 | Iteration number: [3980/4518] 88% | Training loss: 0.6869127597641106
Epoch: 100 | Iteration number: [3990/4518] 88% | Training loss: 0.6869114916575583
Epoch: 100 | Iteration number: [4000/4518] 88% | Training loss: 0.6869111742377281
Epoch: 100 | Iteration number: [4010/4518] 88% | Training loss: 0.6869146456890868
Epoch: 100 | Iteration number: [4020/4518] 88% | Training loss: 0.6869133961437947
Epoch: 100 | Iteration number: [4030/4518] 89% | Training loss: 0.6869172017716296
Epoch: 100 | Iteration number: [4040/4518] 89% | Training loss: 0.6869169819768113
Epoch: 100 | Iteration number: [4050/4518] 89% | Training loss: 0.686917885777391
Epoch: 100 | Iteration number: [4060/4518] 89% | Training loss: 0.6869161482368197
Epoch: 100 | Iteration number: [4070/4518] 90% | Training loss: 0.6869167178942471
Epoch: 100 | Iteration number: [4080/4518] 90% | Training loss: 0.6869162630801108
Epoch: 100 | Iteration number: [4090/4518] 90% | Training loss: 0.6869153431837599
Epoch: 100 | Iteration number: [4100/4518] 90% | Training loss: 0.6869155188013868
Epoch: 100 | Iteration number: [4110/4518] 90% | Training loss: 0.686913567056331
Epoch: 100 | Iteration number: [4120/4518] 91% | Training loss: 0.6869139270875061
Epoch: 100 | Iteration number: [4130/4518] 91% | Training loss: 0.6869158483590687
Epoch: 100 | Iteration number: [4140/4518] 91% | Training loss: 0.6869142649830251
Epoch: 100 | Iteration number: [4150/4518] 91% | Training loss: 0.6869163590597819
Epoch: 100 | Iteration number: [4160/4518] 92% | Training loss: 0.6869162623985455
Epoch: 100 | Iteration number: [4170/4518] 92% | Training loss: 0.6869168712652559
Epoch: 100 | Iteration number: [4180/4518] 92% | Training loss: 0.6869144210832541
Epoch: 100 | Iteration number: [4190/4518] 92% | Training loss: 0.6869143870963687
Epoch: 100 | Iteration number: [4200/4518] 92% | Training loss: 0.6869127009312311
Epoch: 100 | Iteration number: [4210/4518] 93% | Training loss: 0.6869100330985923
Epoch: 100 | Iteration number: [4220/4518] 93% | Training loss: 0.6869088224890108
Epoch: 100 | Iteration number: [4230/4518] 93% | Training loss: 0.6869078422832714
Epoch: 100 | Iteration number: [4240/4518] 93% | Training loss: 0.6869053752073702
Epoch: 100 | Iteration number: [4250/4518] 94% | Training loss: 0.686904295724981
Epoch: 100 | Iteration number: [4260/4518] 94% | Training loss: 0.6869051101621888
Epoch: 100 | Iteration number: [4270/4518] 94% | Training loss: 0.6869053451741328
Epoch: 100 | Iteration number: [4280/4518] 94% | Training loss: 0.6869048160788055
Epoch: 100 | Iteration number: [4290/4518] 94% | Training loss: 0.6869046628753066
Epoch: 100 | Iteration number: [4300/4518] 95% | Training loss: 0.6869014645870342
Epoch: 100 | Iteration number: [4310/4518] 95% | Training loss: 0.6869006284151719
Epoch: 100 | Iteration number: [4320/4518] 95% | Training loss: 0.6869012064817879
Epoch: 100 | Iteration number: [4330/4518] 95% | Training loss: 0.6869026141271305
Epoch: 100 | Iteration number: [4340/4518] 96% | Training loss: 0.6869028402363649
Epoch: 100 | Iteration number: [4350/4518] 96% | Training loss: 0.6869020109889151
Epoch: 100 | Iteration number: [4360/4518] 96% | Training loss: 0.686899869075609
Epoch: 100 | Iteration number: [4370/4518] 96% | Training loss: 0.6868993668588949
Epoch: 100 | Iteration number: [4380/4518] 96% | Training loss: 0.6868984009713343
Epoch: 100 | Iteration number: [4390/4518] 97% | Training loss: 0.6869006672046722
Epoch: 100 | Iteration number: [4400/4518] 97% | Training loss: 0.6869022899866104
Epoch: 100 | Iteration number: [4410/4518] 97% | Training loss: 0.6869043816649725
Epoch: 100 | Iteration number: [4420/4518] 97% | Training loss: 0.686904468417707
Epoch: 100 | Iteration number: [4430/4518] 98% | Training loss: 0.6869023243810468
Epoch: 100 | Iteration number: [4440/4518] 98% | Training loss: 0.6869041802244144
Epoch: 100 | Iteration number: [4450/4518] 98% | Training loss: 0.6869039874398306
Epoch: 100 | Iteration number: [4460/4518] 98% | Training loss: 0.6869014678648234
Epoch: 100 | Iteration number: [4470/4518] 98% | Training loss: 0.6869011604012526
Epoch: 100 | Iteration number: [4480/4518] 99% | Training loss: 0.6868992578637387
Epoch: 100 | Iteration number: [4490/4518] 99% | Training loss: 0.6868979803039661
Epoch: 100 | Iteration number: [4500/4518] 99% | Training loss: 0.6868955832322439
Epoch: 100 | Iteration number: [4510/4518] 99% | Training loss: 0.6868951297387844

 End of epoch: 100 | Train Loss: 0.6867426025914956 | Training Time: 641 

 End of epoch: 100 | Eval Loss: 0.689742700177796 | Evaluating Time: 17 

 End of Test | Dice Loss: 0.9541148388385773 | Binary Cross Entropy With Logits Loss: 0.6898004066944122 
