Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7642403066158294
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7293411999940872
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7176139712333679
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7117257818579674
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7082444512844086
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7058819661537806
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7042133407933372
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7028465807437897
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7018338117334578
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7010082137584687
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7003322612155568
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.6997548282146454
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6992765431220714
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6988596950258528
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6984934333960215
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6981680251657962
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.697855873668895
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6975605289141337
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.6973304833236493
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.697093959748745
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6968846988110315
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6967053351077166
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6965295161889947
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6963820780316988
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6962119603157043
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6960621288189521
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.695929518673155
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6957813565220151
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6956509851176164
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6955359478791555
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6954125633162836
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6953056132420897
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6952114887309797
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6951187398503809
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6950221451691219
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6949371134241422
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6948553262530146
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6947598852609334
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6946774930526048
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6946070298552514
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6945245345918144
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6944503630910601
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6943895176399586
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6943324541503733
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6942713121573131
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6942114652498909
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6941515824896224
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6940839756280184
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6940240276103117
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6939729058742523
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6939116356419582
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6938528830042252
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6937871278456922
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.6937406848978114
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6936964971368963
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6936511990215097

 End of epoch: 1 | Train Loss: 0.6924023601861127 | Training Time: 90 

 End of epoch: 1 | Eval Loss: 0.693605397428785 | Evaluating Time: 5 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7598311483860016
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7254505097866059
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7139148672421773
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7079897910356522
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7044783151149749
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7021368314822515
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7005531106676374
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.699324406683445
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.698393589258194
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.6976030123233795
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6969882488250733
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6964864358305931
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6960522555387937
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6956603603703635
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.695341770251592
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6950500167906284
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6947714360321269
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6945386019017962
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6943232953548432
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6941155284643173
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6939522592794327
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6937911916862834
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6936185585415882
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6934908760090669
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6933618991374969
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.693254747069799
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6931433397310751
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6930656118052346
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6929566732768355
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6928625432650248
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6927855714674919
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6927161643281579
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6926375203060381
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6925591093652389
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6924866231850215
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6924272985921965
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6923687886547398
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6923061091648904
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6922443515215164
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6921874187886715
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6921348231594737
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6920827845732371
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6920351639736531
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.691986169191924
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.69194603867001
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6919173060551934
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6918724668786881
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6918382893006007
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6917967155271647
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6917507090568542
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6917187953696532
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6916875439194533
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6916536826007771
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6916234152184593
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.691597093668851
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.691564423271588

 End of epoch: 2 | Train Loss: 0.6903307515962989 | Training Time: 90 

 End of epoch: 2 | Eval Loss: 0.6919840489115033 | Evaluating Time: 5 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7591248273849487
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7245383352041245
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7127867460250854
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7069829389452934
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.703513091802597
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7011692742506663
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6995013560567583
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6982096835970879
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6972693973117404
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6965345537662506
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6959002581509677
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6954002464811008
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6949795402013339
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6945939647299902
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6942659600575765
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6939676638692618
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6937249863848967
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6934755351808336
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6932871363664929
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6931027096509933
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6929364354837508
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6927818994630467
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6926348274168761
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6924999443193277
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6923676810264587
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6922475019326577
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6921418847861114
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6920410311647824
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6919461227696517
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.6918609907229741
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.6917952666359563
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6917280489578843
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6916484870693901
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6915733801967957
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6915153963225228
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6914586794045237
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6913952754961478
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6913177667479766
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6912654291360806
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6912108261883259
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6911605118251428
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6911225974559784
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6910749131856962
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6910327648574656
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.690984554555681
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.6909500115591547
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.690909739758106
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6908840299894412
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6908473552489768
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6908064824342728
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.690773703771479
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6907373034037076
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6907042944206382
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6906664056910409
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6906447718360207
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6906104865883078

 End of epoch: 3 | Train Loss: 0.6893796465038198 | Training Time: 91 

 End of epoch: 3 | Eval Loss: 0.6918794853346688 | Evaluating Time: 5 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7579752802848816
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.723771134018898
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7122591873009999
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7063680678606034
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7029266357421875
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7006171266237895
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6989859078611647
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6976854182779789
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6967125051551395
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6959392315149308
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6952965465458957
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6947756956020991
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6943340668311486
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6939505798476083
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6936243462562561
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6933222014456988
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6930518963757684
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6928207334544924
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6925921879316631
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6924145713448524
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6922689298788707
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6921007018197667
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.691939145585765
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6918239613374074
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6916940877437592
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6915903073090773
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6914787747241833
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6913883805274963
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6912939421061812
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6912078253428141
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.691130748871834
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6910526636987925
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6909895978190682
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.69093077323016
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6908554511410849
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6908014862073792
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6907470622578182
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6906918320216631
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6906302774563814
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6905860061943531
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6905251942029813
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6904822778134119
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6904377281665802
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6903910309076309
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6903400835725996
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6902954019930052
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6902560131346925
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6902305168410142
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6902078694226791
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6901816384792328
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6901452741202186
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6901160854559678
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6900821530594016
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.690053121580018
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.690027009898966
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6899991024817739

 End of epoch: 4 | Train Loss: 0.6887661614249238 | Training Time: 91 

 End of epoch: 4 | Eval Loss: 0.6917511395045689 | Evaluating Time: 5 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.757551085948944
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7229592472314834
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7114901940027872
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7057582482695579
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7022663521766662
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.6999214837948481
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.6982861765793391
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6970479540526867
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6960805647903019
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6953229331970214
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6946730781685222
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6941208725174268
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.693710324397454
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6933167325598854
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.692962506612142
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6926848597824573
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.692442506201127
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6922317687008116
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6920359460931075
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6918463099002838
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6916852789265769
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6915281114253131
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6914078049037767
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6912906828025976
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6911748526096344
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6910826084705499
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6909756170378791
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6908792465925216
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6907984287574374
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6907291009028753
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6906567365892472
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6905709750950336
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6905013631690632
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6904324117828818
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6903711329187666
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6903199490573672
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6902729649801512
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6902243603216974
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6901699692775042
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6901312673091888
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6900889103005572
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.690057610755875
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6900173648845318
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6899823130531745
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.689936951663759
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6898945892634599
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.6898497934037067
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6898273747414351
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6897983316256076
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6897653557062149
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6897366355447209
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6897124894536458
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6896849042964431
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6896491103702121
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6896256335215135
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.689602307336671

 End of epoch: 5 | Train Loss: 0.6883735375066774 | Training Time: 91 

 End of epoch: 5 | Eval Loss: 0.6916612642151969 | Evaluating Time: 5 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7567251324653625
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7223787426948547
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7108967383702596
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.705201230943203
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7018660736083985
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6996781945228576
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6980828966413225
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6968116149306297
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6958400030930837
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6950754350423813
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6944357606497678
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6939295252164205
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6934879665191357
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6930822666202273
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6927609717845917
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6925196677446366
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6922502510687885
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6920559571848975
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6918731444760373
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6916721138358116
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6914953192075094
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6913221947171472
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6911932756071505
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6910578158994516
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6909327824115753
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6908115240243765
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6907143003410763
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6906135705964905
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.690534645318985
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6904493979612987
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6903676671366538
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6902881348505616
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6902291798230373
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6901728158487993
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6901150890759059
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6900590833690431
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6900015420204885
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.689937501047787
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6898842091743763
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.689824547469616
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.689772864085872
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6897313931158611
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6896843215753866
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6896436290307478
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6896029367711809
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6895717585864274
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6895429494533133
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6895155306905508
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6894858579246366
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6894487618207932
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6894290672797783
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6893957721499296
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.689372037041862
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6893505737737373
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.68933251099153
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.689310492255858

 End of epoch: 6 | Train Loss: 0.6880803981713489 | Training Time: 90 

 End of epoch: 6 | Eval Loss: 0.6905692730631147 | Evaluating Time: 5 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7570863723754883
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7223475098609924
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7109497427940369
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7052630573511124
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7018292009830475
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6994732260704041
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6978107324668339
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6965544126927853
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6955889893902673
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6947974622249603
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6941886061971838
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6936570132772127
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6932113225643451
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6928304140056882
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6924860421816508
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6922002512961626
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6919334769248963
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916996945937475
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6915054867142125
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912941786646843
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6911254973638625
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6909743821079081
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6908434854901355
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6907272977133592
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6906274807453155
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.6905101154859249
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6904057908941198
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6903092767511095
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6902370572090148
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6901564321915309
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.690072218448885
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6900044839829207
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6899425414475527
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6898745510508032
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6898233888830457
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6897685564226574
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6897029298382836
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.689659468908059
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6896072402978555
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6895521053671837
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6895096271503263
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6894632204657509
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6894241351027821
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6893864356658675
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.689348021613227
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6893153317596601
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6892860680184466
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6892451527218024
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.689213241971269
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6891882034540177
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6891729580421074
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6891477530965439
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6891149231847727
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6890874226888021
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6890623867511749
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6890364997088909

 End of epoch: 7 | Train Loss: 0.687808220681891 | Training Time: 90 

 End of epoch: 7 | Eval Loss: 0.6903915745871407 | Evaluating Time: 5 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7562972605228424
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7218798190355301
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7105359057585399
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7048224538564682
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7013913023471833
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6990808208783468
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6974469951220921
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6962384931743145
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6952865713172489
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6945741456747055
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6939676062627272
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6935164213180542
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6930571070084205
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6927040453468051
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6923587310314179
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6920615699142217
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6917736674056334
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6915289660294851
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.691315105714296
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6911555835604668
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6910108268260956
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6908508173444055
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6907244757465695
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6905958548188209
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6904737119674682
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6903551218601374
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.690275968224914
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6901785197002547
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6900834558338954
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6900087571144105
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6899301986540517
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6898575935512781
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6897852729667316
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6897347097887713
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6896739099706922
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6896128740575579
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6895570690567429
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.689499295698969
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6894612836532104
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6894208306074142
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6893768162262149
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6893312589043663
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6892898067485455
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6892478203231638
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6892081348101298
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6891766233288723
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6891467525603924
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6891069896519184
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890801795891353
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.6890423691272736
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.689017273164263
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6889915961485643
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6889687860911747
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6889413388790908
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6889189493656158
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6888908626777785

 End of epoch: 8 | Train Loss: 0.6876623192719654 | Training Time: 91 

 End of epoch: 8 | Eval Loss: 0.6908050520079476 | Evaluating Time: 5 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7564828574657441
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.722201806306839
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.710674500465393
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7047920912504196
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7013503086566925
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6990313857793808
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6973927804401943
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6961311034858226
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6952050666014353
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6944364607334137
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6937866779890928
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6932647575934728
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6928576414401715
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6924614271947316
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6921336662769317
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6918318007141352
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6915711504571578
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6913436992300881
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6911524747547351
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6909826618432998
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6908243993918101
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6906915794719349
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6905580191508583
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6904392383992672
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6903079626560211
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6902017820339936
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6901169474478122
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6900084340146609
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6899342789732177
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.689853460987409
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6897762196679269
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6896974705159664
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6896370615019943
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6895867128582561
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6895198367323194
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6894617132014699
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6894041101674776
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893475706640043
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6893040496569414
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6892473568022252
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6892077528848881
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891640343836376
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6891334471314452
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6891049194065008
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6890722794002957
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.689025242432304
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889885746418162
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6889610259483258
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6889159050523018
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6888901427984238
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888705067774828
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6888359075555435
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6888064419323543
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6887724918347818
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887404804879969
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6887188009917736

 End of epoch: 9 | Train Loss: 0.6874898391487324 | Training Time: 91 

 End of epoch: 9 | Eval Loss: 0.6908270035471235 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7563571751117706
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7220684111118316
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7104832609494527
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.70474853515625
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7012788677215576
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6989652276039123
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6972643426486425
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6960299707949161
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6950218141078949
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6942366623878479
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6935962481932206
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6930981248617172
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6926403013559488
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.692261049577168
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6919594478607177
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6916742328554392
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.691431499228758
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6912006911304261
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6910043722704837
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6908187454938889
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6906626840432485
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6905248216607354
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6903888026009435
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6902680523693562
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6901390450000763
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6900223782429329
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6899288709516879
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6898456765072686
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6897591268194133
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6896673883994421
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6895840058403631
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6895076563581825
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6894273053516041
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6893632205093608
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893137787069593
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6892658124367396
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.689214093459619
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6891691832165969
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891282324607556
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6890896989405155
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890533335325194
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890180756648382
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6889857336532238
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889509672468359
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.68892239385181
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888829886913299
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888458751617594
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888262769828241
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887942252110462
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887632987499237
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.68873616994596
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6887140658039314
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886934489574073
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6886796435824147
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6886569661443884
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6886298743741853

 End of epoch: 10 | Train Loss: 0.6874024358470883 | Training Time: 90 

 End of epoch: 10 | Eval Loss: 0.6907225591795785 | Evaluating Time: 5 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7560016512870789
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7214100182056427
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7101207733154297
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7044581279158593
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7010255300998688
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6988503177960713
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6972206005028316
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6959372088313103
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6950258784823947
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6942651516199112
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6935780362649397
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6930247445901235
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6925899290121519
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6922479212284088
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6918779782454173
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6915775939822197
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6913270277135513
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911032746235529
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6909046863254747
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.690702046751976
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6905410709835235
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6904010406949304
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6902779840904734
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.690166079501311
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6900592973232269
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6899696425749705
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6898588204825365
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6897782344903265
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896990706180705
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896247047185898
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895503620947561
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6894733965396881
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6893880542480584
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.689315720165477
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892584754739489
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891955557796691
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891382747405285
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890897142259698
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6890383387223268
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6889987716078758
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.688956654944071
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889163223050889
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888768384622973
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888399344953624
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888035599390666
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.688774457703466
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887503932131097
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887277528643608
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6887044165815626
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.688676301240921
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6886579661977057
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.688628124159116
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6886061039735686
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885917784991088
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885726247050545
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6885480035628592

 End of epoch: 11 | Train Loss: 0.6873171335827988 | Training Time: 89 

 End of epoch: 11 | Eval Loss: 0.690696120262146 | Evaluating Time: 5 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7561533689498902
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7217887252569198
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7102669974168142
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7045101642608642
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7010432839393616
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6988166977961858
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6971584183829171
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6958932280540466
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6949125488599142
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6941152864694595
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6934824488379738
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6929619312286377
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6925156524548164
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6921808557850974
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6918315962950389
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6915436305105687
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6912782451685737
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910478707816866
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6908533268853237
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906608501076699
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6904910462243217
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903317527337508
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6902043765005859
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6900782103339831
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6899624383449554
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.689851584801307
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6897331789687827
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896450917635645
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6895599334404386
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6894720443089803
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894073799733192
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.689338349364698
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6892702371785135
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892022141638924
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6891570167882102
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.68910584135188
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6890621343174497
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890114415633051
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6889674227971297
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889263890683651
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888776050835121
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6888302236795425
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6887916322364364
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6887458291920748
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887004208564759
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6886662969122762
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6886333483330747
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6886040467768908
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6885781481557963
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6885577424764633
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6885319253977608
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885005510770358
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6884781608041727
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6884639395607842
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884390211105347
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884220930082458

 End of epoch: 12 | Train Loss: 0.6871944084631658 | Training Time: 92 

 End of epoch: 12 | Eval Loss: 0.6907317212649754 | Evaluating Time: 5 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7561660528182983
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7217922359704971
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7102161884307862
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7044377595186233
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7009610283374786
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6986173679431279
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6970221315111432
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6957452982664108
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6948506010903253
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6941207057237625
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6934910459951921
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6929538572827975
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6924681906516735
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6920984838690076
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917371718088786
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6914467006921768
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6911776220097261
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909268077876832
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907322714203282
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905649164319039
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6903785279818944
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6902269791473042
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6900903546291849
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6899637492994467
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6898546240329743
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6897584949548428
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6896590288038607
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6895666454519545
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6894944452006241
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894167536497116
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6893471902416598
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6892683636397123
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6891933491735748
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6891296732075074
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6890772151947021
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890277814533975
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.688985211462588
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6889393608821066
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6888987654294723
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6888503021001816
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888056249153324
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6887617258798509
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887311139772104
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887005139480937
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.688671510749393
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886343470086222
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886078785074518
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6885810900479555
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.688555487686274
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885294843912124
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6885060519564385
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884825568932753
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884588160604801
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.688431469378648
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6884034462408586
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883781429912362

 End of epoch: 13 | Train Loss: 0.6871500819130282 | Training Time: 90 

 End of epoch: 13 | Eval Loss: 0.690475344657898 | Evaluating Time: 5 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7556049525737762
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7213595360517502
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7099697748819987
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7042385593056679
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.70083740234375
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6986070036888122
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6970532826014928
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.69580612257123
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6948504759205713
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6940691882371902
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6934254830533808
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.692899818221728
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6924772588106302
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6920806518622807
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.691753515402476
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.691479018703103
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6912456673734328
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6910273810227712
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6908587656523052
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6906761875748635
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6904897786322094
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6903342103416269
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6901974372241808
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6900581161181132
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.689932321548462
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6898219193403538
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6897253082858191
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6896436810493469
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6895608778657585
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.689490576783816
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6894301729817545
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.689352486282587
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6892755103833748
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6892021145890741
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6891394691807883
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890752827127774
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6890245693760949
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889659417302985
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6889280196947929
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888679255545139
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6888221339481633
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.6887805920271647
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6887276133825613
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886898338794708
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886566122372945
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6886200601639955
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885879345396732
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885582018643618
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885372789538636
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.688512077331543
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884838055161869
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884514723832791
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884163315566081
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883923093477885
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883726453781128
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883492124932152

 End of epoch: 14 | Train Loss: 0.6871279314555953 | Training Time: 90 

 End of epoch: 14 | Eval Loss: 0.6901899661336627 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7559020578861236
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7215838193893432
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7099419871966044
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7042449027299881
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.700851526260376
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.698585644364357
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6970399107251849
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6958105958998203
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6948573847611745
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6940758854150773
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6934809798544104
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6929644927382469
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6925100115629342
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6920895572219576
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.691741871436437
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6914576914161443
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6912015676498413
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6909535649749968
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6907315589879689
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.690556917488575
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903820318835122
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902158626101234
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900681941405586
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6899459230403105
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.689842439174652
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897498740599706
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896460524311772
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895423041922706
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894711619821088
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6893837511539459
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893171518079696
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892408153042198
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891590710842248
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6890966823872398
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.689033989395414
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6889887299802568
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6889447779268831
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.688892147101854
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6888522116037515
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888101822137833
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887707338100526
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887315171105521
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886985516825388
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886616803028367
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886336025926801
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.6886115550994873
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885759746774714
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885436547299226
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.68850503454403
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884755572080612
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884363766978768
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6884134116081091
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883838478124367
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883622488489858
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883386413617567
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883201940783432

 End of epoch: 15 | Train Loss: 0.6870949928739429 | Training Time: 92 

 End of epoch: 15 | Eval Loss: 0.690243090902056 | Evaluating Time: 5 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7555489420890809
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7212876170873642
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7099668920040131
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7041729867458344
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7007651829719543
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.698524139324824
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6968936358179365
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6956254407763481
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6946704473760393
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6939296579360962
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6932916581630707
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6927810604373614
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6923544361041143
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.692021649650165
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6916868424415589
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6913987290114164
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6911564017043395
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6909111122290293
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6907306580167067
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6905507805943489
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6903946107342129
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.690232022783973
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6900874420352604
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6899521564443906
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6898119161128998
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6897220419003414
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6896329987932135
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6895498467343194
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6894546997958216
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6893834962447485
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6893130240901824
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6892431993037462
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.689177068977645
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891228263869005
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6890675953456333
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6890031789739927
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6889495841554694
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888938183847226
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888462292842376
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887926730513573
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6887499410931657
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6887031306823095
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886631761872491
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886297714981165
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6886001388231914
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885558342156203
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885316843682147
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884992372244596
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884663032025707
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884388216733932
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.688411906303144
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883907990959974
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883684872456317
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883439625854846
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883208664980802
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882995624627386

 End of epoch: 16 | Train Loss: 0.6870681289023003 | Training Time: 90 

 End of epoch: 16 | Eval Loss: 0.690406322479248 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7555579125881196
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.72153060734272
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7099848985671997
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7042921558022499
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.700804488658905
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6983944594860076
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6968082087380546
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6955689504742623
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6945805430412293
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6938355338573455
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932219933379781
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927010546127955
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6922528496155372
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6918836810759136
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6915677626927693
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6912891194224358
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6910329531220829
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6907912383476893
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6905822738220817
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6903756645321846
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6902134483768827
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6900800014084035
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6899513604848281
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6898363346854846
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6897354445457459
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896376281976699
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895476294888391
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6894467211195401
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6893684339934382
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.689293079773585
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892079555219219
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.689154758863151
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.689089525829662
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890368137289496
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6889847828660692
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889208897948265
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.688873492865949
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888225066034417
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887647754106766
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887186916172504
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886783349804761
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886419954754057
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886002841383911
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885712503032251
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885273847315047
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885002938301666
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6884705169403806
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884416582683722
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6884061722122893
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6883781810998917
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.688358540277855
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883333711669996
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883149946635624
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6883024564495793
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6882850987260992
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6882626001323973

 End of epoch: 17 | Train Loss: 0.6870361896742762 | Training Time: 88 

 End of epoch: 17 | Eval Loss: 0.6901057958602905 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7563137531280517
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.721560874581337
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7101289212703705
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.704345840215683
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7009098172187805
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6985853721698125
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6968791084630149
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6955936066806316
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.694661283493042
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6939355462789536
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932932539419694
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6927214587728182
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.692317958520009
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.691942800794329
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6916118756930033
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6913083389401435
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6910557561060962
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908321029610104
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6906393985999258
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904549953341484
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902914850484757
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.690160579031164
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6900227430074112
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.689912403623263
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6898078379631043
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896935919156442
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6896090600225661
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6895176153097834
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6894351063103511
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.689365040063858
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892967902844952
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6892248056828976
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891463978724046
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890880809110753
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6890282298837389
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889838015039762
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6889282920876065
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888698344167911
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6888121320651128
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887665775418281
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6887272927819229
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886868194455192
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.688645915236584
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6886145490137013
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885791366630131
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885403031888215
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.688501582373964
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884771589189768
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884464800357819
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6884141355752945
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883811396711013
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883462923077437
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6883219310697519
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6882916748523712
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882714048298922
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882558123341629

 End of epoch: 18 | Train Loss: 0.6870289929145206 | Training Time: 90 

 End of epoch: 18 | Eval Loss: 0.6904503192220416 | Evaluating Time: 6 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.755971223115921
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.721305912733078
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7099420110384623
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7041365548968315
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.700682954788208
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6983785967032115
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6967717170715332
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6954418875277042
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6945086783832974
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.693719916343689
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6931461491368034
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6926314507921537
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6922352291070498
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6918756199734551
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6915650721391042
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6912870302796363
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910336778444403
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6908052696122063
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6905832745526966
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6904051876068116
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6902251101675487
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6900769214738499
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899393441884414
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6898089990019798
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897014164924622
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6895985243412165
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.689518478402385
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6894239446946553
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6893288043038598
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892621262868246
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6891855012985968
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891023064032197
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890360349958593
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889837606864817
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.688925553389958
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888670328590605
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888107517281095
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887677070341612
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887081873722566
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.6886722154915332
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886348328939298
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886091626825787
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.688569487111513
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885319245132533
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885046982765197
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884741886802341
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884454656154552
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884191593776147
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6883905714871932
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883622410297394
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883306846899144
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6882989230064246
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882730355802572
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882514203036273
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882208879427476
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882101247353213

 End of epoch: 19 | Train Loss: 0.6869838227212957 | Training Time: 89 

 End of epoch: 19 | Eval Loss: 0.6904591832842145 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7556720852851868
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7215739667415619
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7100501279036204
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7042694717645646
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7008369410037995
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6984599699576696
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6968072388853346
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6955182053148746
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6945724666118622
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6938036805391312
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932186050848528
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6926906277736028
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922227080051716
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6918602790151324
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6915240315596263
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6912513386458159
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910158637691947
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.690779549545712
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6905701022399099
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6903963908553123
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902244167668479
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6900729661638086
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6899711455987847
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898534812033177
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897420670986175
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896415962622716
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895356445400803
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.689432675072125
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893690339450178
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6893041332562765
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6892147335313982
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.689147406257689
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890862224680004
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890269773847917
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889816243307931
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889296034971873
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888748694110561
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6888364357383627
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887905331758353
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6887494492530822
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.68870171177678
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886586870465959
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6886177618836248
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885814933614297
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885409222708808
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.688511351917101
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.6884795645450024
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884510487318038
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6884186666838977
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883895382881164
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883492105147417
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883258355351595
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6883003182006332
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882740499796691
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.688245022947138
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882201464048454

 End of epoch: 20 | Train Loss: 0.6869919363376313 | Training Time: 90 

 End of epoch: 20 | Eval Loss: 0.6905129126140049 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7558464884757996
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7213395863771439
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7098695357640584
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7040959134697914
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7007039606571197
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6983655790487925
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.696809527703694
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6955948911607266
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.694640702009201
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938820099830627
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.693262840942903
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6927504559357961
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922880654151623
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6918898535626276
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915818492571513
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6913096386939287
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910924059503218
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6908393979072571
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6906310200691224
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6904318231344223
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6902880830424173
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6901286745613272
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899887372618136
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898774753014246
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.689748393535614
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6896446480200841
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895419798515461
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6894335291215352
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893402235261326
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.689271909793218
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6892076517305067
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891353158280253
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890685533032272
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6890103469876682
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889625409671238
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6889220974511571
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888737683360641
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6888169011003092
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887613368340028
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.688708598613739
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886600715358083
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6886377388522739
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885888295118199
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885516634041613
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6885142856174045
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884802655033443
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884487292868026
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6884134595592817
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.688381427526474
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883507788181304
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883214370877135
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6883021471592096
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882924474635215
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882668330713555
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.688233887499029
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6882105249379362

 End of epoch: 21 | Train Loss: 0.6869851821291764 | Training Time: 87 

 End of epoch: 21 | Eval Loss: 0.6903827871595111 | Evaluating Time: 5 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7559725165367126
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7214337110519409
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7099093794822693
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7042362242937088
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7008324754238129
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6984611948331197
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6967805113111224
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6955926552414894
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6946463704109191
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.6938898408412933
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6932959962974895
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6927438537279765
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.6922823154009305
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6918856007712227
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915789564450582
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912955917418003
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6910301008645225
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907865703105927
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.69059092214233
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903966832160949
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902394422463008
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6900925248861313
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899560910204182
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6898187351723511
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896929452419281
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6895889419775743
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895105960192504
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894215324095317
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6893558755003173
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892501590649287
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891828267805038
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891054790467024
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890414532386895
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889731393140905
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889153679779597
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888486428393258
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6887969690400201
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887533583139118
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887069851924211
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886587058007717
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.688627379987298
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885906825462977
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885510674742765
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.688519145954739
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884860101011064
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884468282046525
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884126097597975
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883886235455672
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.688353123956797
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.688332190155983
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.688307220211216
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882815261299794
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882606686286207
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882309289994063
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6882032843069597
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881859716560159

 End of epoch: 22 | Train Loss: 0.686956225137795 | Training Time: 87 

 End of epoch: 22 | Eval Loss: 0.690621520791735 | Evaluating Time: 5 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7559997498989105
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7214051127433777
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7097944994767507
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7040762528777122
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7006341850757599
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6983424951632817
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6967333648885999
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6955132983624935
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6945706347624461
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6937481236457824
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6931346367705952
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6926132674018542
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6921841868987451
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6918239542416164
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6915285098552704
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912238221615553
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6909614061608034
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907354772090912
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6905073294514104
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.690307697057724
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6901493989285968
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6899906123226339
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6898694875447646
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6897380697230499
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6896526980400085
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895369499921798
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6894539526215306
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6893651523760387
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6892905929992938
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892000263929368
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891165318027619
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6890721585601568
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890130301316579
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6889495183439815
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889024085657938
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888449572854571
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.68879426443899
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887461740719645
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6886990022964966
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886545430123806
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886030768475881
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885675064155033
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885316685188648
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6884967018257487
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884548789925046
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884271759053935
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6883933725509238
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6883570215354363
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883344096796853
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883044859170914
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6882749756177267
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882566549457036
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882365143524026
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.688212697815012
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6881919296221299
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881800055503845

 End of epoch: 23 | Train Loss: 0.6869509002803701 | Training Time: 89 

 End of epoch: 23 | Eval Loss: 0.690096880708422 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7559776902198792
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7217112451791763
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7100668291250865
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7041297614574432
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7007731854915619
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6984339743852616
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6967532788004194
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6955655172467232
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6946225318643782
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6938675975799561
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6932113495740023
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6927096496025721
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922977938101842
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6919106807027544
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915744010607402
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912750795483589
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6910037324709051
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6907818347215653
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905632150800605
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903827983140945
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902414327576047
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.690103249929168
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899519337260205
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6898207885523637
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6897146351337433
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6896080512266892
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6895001203925522
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.6894186315791947
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893436764848644
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892549212773641
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891733644470092
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6891071882098914
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890432717222156
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889720783514135
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6888998581681933
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888556190662913
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888067537062877
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.688748141966368
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6886990712239192
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6886533313989639
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886107754416582
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885718605348042
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885378754416177
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6884999645027248
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.688454990916782
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884277041839517
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6883955805859667
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883666070799033
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883407091607853
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883130617141724
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882984765604431
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882661881355139
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882375133487414
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882244455593604
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.688197745626623
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881719501955169

 End of epoch: 24 | Train Loss: 0.6869466217218247 | Training Time: 89 

 End of epoch: 24 | Eval Loss: 0.690399306161063 | Evaluating Time: 6 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7560340881347656
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.721480992436409
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7098875184853871
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7041093915700912
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7006791162490845
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6983758121728897
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6967780487877983
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6956103712320327
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946126328574287
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938621479272843
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932374564084139
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6926918322841327
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922250555111812
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918132858616965
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.691475787560145
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6911946512758732
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.690950541636523
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6907257070144017
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6905304889929922
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6903507682681084
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6902002147265843
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900479804385792
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899229456549105
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6897973681489626
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6896636497974395
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6895599248317572
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6894781359919795
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6893953410642487
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.689295952073459
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6892124150196711
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6891428070683633
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6890774719417095
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.689012472557299
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6889619248754838
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6888963603973388
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888508141040802
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6888073698894398
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887578352501518
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887121773683108
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886737595498562
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886351108551025
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885951832646415
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885566607464192
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6885199782523241
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6884834236568875
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884384096964545
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6884054653188015
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883752646545569
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883529891773146
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6883154194355011
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882945555097917
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882744731811377
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882482439841864
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882193155862667
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881912712617354
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881756905998503

 End of epoch: 25 | Train Loss: 0.6869489457754963 | Training Time: 91 

 End of epoch: 25 | Eval Loss: 0.6900963698114667 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7556551694869995
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7214972674846649
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7100278119246165
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7043704822659492
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7007624864578247
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6984345078468323
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6967533009392874
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.6955659002065658
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6945938964684805
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.693835723400116
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6932004668495871
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6927029093106588
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6922618059011606
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6918467428003039
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6914793217182159
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6911887045949697
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.690962178216261
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907482792933782
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.690542746531336
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6903486281633378
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6901951315857116
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6900406382300637
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6898931088654892
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897899717092514
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896714618206025
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895545388643558
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894874424846084
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893910972135407
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6893068408143932
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892273271083832
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6891671223025169
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.689110741019249
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890503957416072
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889851545586305
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6889245283603668
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.688863898979293
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.688817430670197
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887617586474669
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.688713205472017
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886745730042457
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6886215369875838
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885832678704035
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885413526102554
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6885013476014137
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884775959120857
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884476672048154
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6884051429464462
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883723379423221
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883368191670398
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6883078520298004
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882733075057759
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882594350438852
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882322475595294
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881991888637896
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881727942553434
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881554978234428

 End of epoch: 26 | Train Loss: 0.6869256659946611 | Training Time: 90 

 End of epoch: 26 | Eval Loss: 0.6904140199933734 | Evaluating Time: 5 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7554356634616852
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7211483657360077
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7097716490427654
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.7041502371430397
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7007094383239746
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6984103818734487
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967545262404851
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6955851823091507
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6946050392256843
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6938363832235336
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931887832554904
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6926722675561905
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6922444261037386
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6919021214757647
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6915586205323537
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912709433585406
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6910223070312949
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907829526397917
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6905918846004888
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.690406222641468
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.690248795066561
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.690089036659761
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6899521356043609
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6898048574725787
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.689680844783783
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895822112376874
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894783560876493
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893891489931515
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.689297642790038
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892160924275716
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891266632464624
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.689049450494349
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889915262207841
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889298293520423
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888800288949694
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888151006566153
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887683839411349
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887179470375965
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886750192214282
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886296467483044
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6885731582234546
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885354818332763
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6884981852631237
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884587006135421
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884320965078142
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6883899324614069
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883498616675113
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883239779621363
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883040791871596
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882754576206207
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882466545291975
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882265478372573
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882101125312301
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881797951680643
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881552124023438
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881328751998288

 End of epoch: 27 | Train Loss: 0.6869038549144711 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.6905100771359035 | Evaluating Time: 6 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7554075241088867
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7208971947431564
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7096087992191314
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7038197726011276
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7004392874240876
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6982017576694488
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6966256013938359
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6954152606427669
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6944772269990709
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937090694904328
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931068301200867
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6926139901081722
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6921938602740948
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6918502458504268
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6915106161435445
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912046775221825
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909433610299054
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.690724942750401
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6905149469250127
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903409233689308
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901689444269453
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900198061357845
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6898786516293235
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897461009522279
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896335391998291
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895443969047986
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894426981608073
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893499480826514
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892773395982282
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6891992499430974
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891095845930038
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890373609960079
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6889673137303555
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889137557324241
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888638756956373
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888031302226915
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887683878073821
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887188436169374
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886743449247801
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886395211517811
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885973449160413
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885573624145417
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.688525397971619
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884912856600501
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.688448714017868
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6884054323901301
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883712760945584
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883377195646365
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883027783461979
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882742673158646
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882441395638036
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882231738704901
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882024039637368
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6881870420994582
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881575285304676
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.688142875369106

 End of epoch: 28 | Train Loss: 0.6869142425798737 | Training Time: 88 

 End of epoch: 28 | Eval Loss: 0.6899083171572004 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7556194067001343
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7210900813341141
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7096517443656921
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7040157005190849
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7006425988674164
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6984896192948024
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6968046043600354
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6955130770802498
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6945681677924262
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6938204979896545
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6931859888813713
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6926714137196541
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6921770884440496
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6918090309415544
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.691483686765035
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911888338625432
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6909345900311189
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907105442550447
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905198178793255
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6903158804774284
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6901414496558053
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6899866591800343
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898690500985021
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6897491271297137
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6896228210926056
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6895300177427438
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6894306884871588
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6893467153821673
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892539388146893
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6891746705770493
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.689100045158017
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890189381316304
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6889532380031816
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6888999574324663
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888476155485426
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888063215547138
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887445122809024
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887018956636127
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886619415038672
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.688617492467165
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885928587215703
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885497466439292
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885019249694292
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884612904353575
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884270261393654
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6883846575799195
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883476201524126
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883246336132288
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883020512911738
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882849956750869
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882598145335328
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882318007258269
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882040284714609
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881685843070348
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881404688141562
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881220177880355

 End of epoch: 29 | Train Loss: 0.6868970479585428 | Training Time: 90 

 End of epoch: 29 | Eval Loss: 0.6899256706237793 | Evaluating Time: 5 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7557141780853271
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7211907774209976
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.709786723057429
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7039757281541824
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7004599606990815
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6980781068404516
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6965124470846994
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6953040085732937
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.694407688246833
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6936049044132233
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.692993572625247
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.692469896376133
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6920858140175159
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6917114789996829
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6913872985045115
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6911303643137217
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6908806653583751
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6906711783674028
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6904623373558647
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6902890974283218
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901322606064024
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6899843094023791
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898540051087089
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897393758098285
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896309900283814
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895280799040427
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894284027594108
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893497688429696
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892652593809983
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891891431808471
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891022826394727
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890418693423271
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6889742303978313
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6889076494118747
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.688854375226157
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6887939850489299
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887320666699797
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6886909560153359
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886487644452315
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.688594024181366
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885578100274249
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885277901376997
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6884880315425784
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.688446709242734
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884065923425886
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883812238340793
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883531296506841
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883319538086653
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6883051337028037
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882820935249329
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.688246533683702
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882225443537419
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6881906910887304
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881741736774092
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881520861929113
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881262125713484

 End of epoch: 30 | Train Loss: 0.6869011822000014 | Training Time: 88 

 End of epoch: 30 | Eval Loss: 0.6906137721879142 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7558320522308349
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7213896870613098
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7098443865776062
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7041215181350708
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7007841813564301
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6984747131665547
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6968471680368696
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6956068359315395
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6945933103561401
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6938419395685196
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6931998615915125
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6926724682251613
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6922528702479143
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6918789425066539
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6915259444713593
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6912021014839411
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6909348337089314
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.690719156132804
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6905124962329865
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6903393226861954
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901874193123408
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6900545811111277
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.68990714420443
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6897703511019547
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6896475670337677
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895157612287082
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894172189412293
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6893299717988287
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6892458393655975
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6891691499948501
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6890927462808547
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890225587412715
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6889651798840725
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889037449570263
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888456683499472
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6887978883253203
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887349866531991
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6886899896358188
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886339505513509
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6885918501019478
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885515583724511
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885157776730401
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884746595870617
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884359665892341
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.688394926653968
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883684251619422
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883321784912272
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.688310514887174
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6882794711054588
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882527741193771
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.688232348128861
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882059167210872
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.688179142745036
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.688150582269386
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881297435543754
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881140877093588

 End of epoch: 31 | Train Loss: 0.6868889110278239 | Training Time: 90 

 End of epoch: 31 | Eval Loss: 0.6899545022419521 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.755293196439743
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7210514575242997
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7096531291802725
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7038001477718353
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.700489901304245
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6982109208901723
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6965777584484645
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6953574165701866
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6944239689244165
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6936845505237579
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6930601932785728
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6925714616974195
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921436186020191
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6917823842593602
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6914710096518198
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.691162246465683
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6908829338410322
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6906668636533949
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.690468945001301
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6902782332897186
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901379690283821
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6899867298928174
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898554641267528
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897326916456222
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896049909591675
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895132844264691
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894335351608417
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.689327587400164
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892508973335397
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891577756404876
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6890823196980261
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890296487137675
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889621575673421
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6888938232379801
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888443926402501
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6887991140286128
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887467390782124
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.688699828323565
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886630278367263
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6886156402528286
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885665134685796
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885307703699385
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6884902072507282
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884512610056184
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884162498844995
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883775105942851
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883374145690431
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883034913490216
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6882691620563974
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882431894540787
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882175646576227
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6881950135414417
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881747615787218
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881512524905028
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.688125991712917
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881052987916129

 End of epoch: 32 | Train Loss: 0.6868771008685627 | Training Time: 88 

 End of epoch: 32 | Eval Loss: 0.6902333157403129 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7547713577747345
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.720811077952385
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7096522569656372
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7038440495729447
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.7004244923591614
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.698153692483902
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.696553008045469
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953469581902028
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6943969077534146
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6935948938131332
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6930032768032768
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925127719839413
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6920858970055214
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917523588453021
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.691412080526352
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911024402827024
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908509762848125
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906283918354247
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904235777102019
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902537924051285
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6900957155795324
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.689979996193539
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898489006187605
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6897166137893994
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6896143016815186
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6895226831619556
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6894289096196492
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6893422088452748
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892559692777437
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.689190401037534
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6891222092413133
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.689051434956491
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889866276220842
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6889175613136852
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888543553011758
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887853198581272
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887298538878157
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.68868663577657
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886498173077901
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.688607577830553
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885669062777263
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885286281506221
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884803771972656
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884324004704302
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6883912301063537
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883555084466935
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883229447172043
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6882955656697353
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882759585672495
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882453491687774
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882115144355624
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6881906487620794
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881631522808435
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881345807402223
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881186889518391
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6880952769092151

 End of epoch: 33 | Train Loss: 0.6868697321520443 | Training Time: 90 

 End of epoch: 33 | Eval Loss: 0.6901159031050546 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7551752626895905
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.721123605966568
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7096118887265523
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7039914160966874
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7005125510692597
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6982150445381801
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6965842919690268
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6953597903251648
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6943697684341007
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6936452317237854
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6930220766500993
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6925123065710068
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6920872216041272
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917162043707711
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914066811402638
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911513600498438
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6908790974056019
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.690633769830068
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904349744319915
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902624770998955
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901122763043358
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899731709198518
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898138149924901
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6896833340326946
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6895875897407532
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.68950302532086
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6894181854195065
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893458513276918
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892643268766074
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891994645198186
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6891139526521006
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890555599704384
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889947773832263
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6889382998732959
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.688880317551749
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6888317404521836
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887764017324189
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6887235120723122
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886658949729724
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6886278957128524
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.688584747837811
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885331748496919
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884863584540611
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884574983607639
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884210079246097
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.688395895646966
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.688363751832475
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883279679963986
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882909125211287
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882568117380142
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882262513918035
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6882001994894101
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881770462360022
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881498114930259
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.6881273912299763
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6881066148834569

 End of epoch: 34 | Train Loss: 0.6868795841141084 | Training Time: 89 

 End of epoch: 34 | Eval Loss: 0.6902881179537091 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7555541396141052
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7213662445545197
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7098964095115662
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7041693702340126
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7006853902339936
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6983891755342484
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.696724557025092
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6955275431275367
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6945661452081469
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6937845307588577
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6931798978285356
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926594868302345
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921998803432171
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6918165049382619
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914834229151408
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6911911692470312
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909510296933791
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907356785403358
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905518478468845
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903666326403618
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901834527651469
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900015264749527
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898831789908202
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897854790091514
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896787664890289
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895782152047524
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894776459093447
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.689373873599938
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892762313629018
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6892071497440339
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6891186958359133
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.6890587931498885
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6890024987134067
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6889374482281068
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888828189032419
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6888181009226375
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887692177617872
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6887189593754317
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.688681062673911
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6886361506581307
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885860732415827
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885373024713426
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.688490724979445
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884589265693318
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6884234175417159
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883819616359214
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.688356942192037
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883262626826763
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882930306755767
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882609275579452
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882330807985044
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6882071720866056
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881878198317761
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.688158314316361
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.688137197711251
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881147832742759

 End of epoch: 35 | Train Loss: 0.686883063653929 | Training Time: 88 

 End of epoch: 35 | Eval Loss: 0.6899908355304173 | Evaluating Time: 5 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7558918297290802
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7213870465755463
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7099168757597606
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7042473316192627
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7007408797740936
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.698386358221372
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6967413672379085
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6955028474330902
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6945368263456556
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6937435448169709
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6931536977941339
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6926027079423268
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921293639219724
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.691735896042415
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6913926470279693
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6911222789436579
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6908650762894575
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6906230078803168
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6904207596653387
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6902249032258987
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6900823414325714
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6899499310688539
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.68979887832766
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6896740270157655
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.689554235458374
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6894622197517982
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6893659035364786
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6892695914421763
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6891855235757499
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6890989271799723
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6890387688913653
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6889808930456638
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889181850534497
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6888521071742563
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888048430851528
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887437618441052
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6887112074607128
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886661338178734
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886102864375481
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885711526870728
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885344104069036
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6884962212471735
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884584090044332
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6884326214140112
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6883954087893168
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883562772170357
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883227264627497
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882980018854141
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882697784170813
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882456057071685
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6882199437010522
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881869535033519
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881649748334345
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881374901091611
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881146112355319
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.688094026701791

 End of epoch: 36 | Train Loss: 0.6868719890054348 | Training Time: 87 

 End of epoch: 36 | Eval Loss: 0.6905188305037362 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7556963086128234
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7212944567203522
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7097165207068126
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7039687588810921
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.700507583618164
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6981955726941427
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6965614761625017
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.695328164845705
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.694367073641883
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.693625156879425
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930269046263261
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6925327370564143
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6920914402374855
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6916908085346222
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6913625625769297
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6910684131085872
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6908235697185292
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6906057433949576
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.690401238830466
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.690221793949604
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6900561806701478
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6898966789245605
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6897567401761594
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6896192622681458
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6895054762363434
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6893932489248422
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6893092449064608
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6892326578497887
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6891498504013851
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6890810793638229
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6889993950243919
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6889469524845481
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6888919790585836
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6888197178349775
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6887592543874468
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6887039351794455
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6886566961133802
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6886118805722187
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6885661592850318
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6885240983963012
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6884733470474801
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6884397540773665
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884201504463373
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6883909597992897
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.6883629386954837
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883390247821808
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883030470381392
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6882750233014424
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.688241523382615
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882127064466477
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6881794564864214
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6881659303720181
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881588333057908
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881385445594788
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881137802384116
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880842163094453

 End of epoch: 37 | Train Loss: 0.6868568153507941 | Training Time: 88 

 End of epoch: 37 | Eval Loss: 0.6900540249688285 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7553770184516907
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7213957816362381
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7098781128724416
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7039916723966598
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7006783306598663
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.698482092221578
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6968183304582324
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6955636128783226
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6945872644583384
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.693800088763237
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6931866028092124
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.692668546239535
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6922290774492117
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.69188326554639
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.691577129761378
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.691289234533906
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.691034895882887
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6908324423763487
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.690621919380991
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6904441064596176
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6902753546124413
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6901177753101696
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6899929101052491
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6898541204631329
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6897443528175354
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6896433433661094
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6895385417673323
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6894384520394462
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6893583036702254
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6892681344350179
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6892001152038574
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6891116017475725
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6890350204525572
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6889682233333587
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6889146140643528
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6888478277458085
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6887991760228132
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6887473586358522
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6886830806732178
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6886287802457809
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885893737397543
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6885523642812457
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.6885028639505076
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6884614424272018
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6884312204519908
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.688403171689614
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883699285223129
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6883400987833739
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6883187988582923
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882844574451447
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6882524400365119
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.688208481325553
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881799502192804
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881547392518432
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881231560490348
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880828249667372

 End of epoch: 38 | Train Loss: 0.6868592652599369 | Training Time: 89 

 End of epoch: 38 | Eval Loss: 0.6903013842446464 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7557511568069458
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7212954521179199
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7099668363730113
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7042282700538636
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7006621408462524
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983712305625279
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6967183223792485
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6954768665134907
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6945112930403815
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6937573474645614
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6931369786912744
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6926304007569949
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6921923774939317
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6918095712150846
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6915089356899261
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6912238322198391
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6909637174185584
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6907369335492451
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6905343943520597
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6903477802872657
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.690169624487559
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899965735999021
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.689843204487925
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6897029558817546
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6895916841030121
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894924684212758
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893865980483868
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6892867335251399
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892175649774486
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891440252463022
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890653204533361
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6889934262260795
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889180347774968
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888643780175377
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888123653616224
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887661976946725
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887053908528509
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886610700895912
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886146968755966
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885662776231766
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.6885260246148923
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6884873969214304
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884494146635366
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884185976602815
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883860741721259
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883637749630472
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883319628999588
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.6883050020784139
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882671845202544
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882365713119507
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6882143650569168
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881941281832181
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881608949517304
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881323854128519
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881114629181948
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.688082972488233

 End of epoch: 39 | Train Loss: 0.6868600533071872 | Training Time: 90 

 End of epoch: 39 | Eval Loss: 0.6900204505239215 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.755746704339981
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7213940918445587
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7098998367786408
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7040716469287872
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.70065354347229
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6983912905057271
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.696733546257019
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6954909175634384
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6945155739784241
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6937333762645721
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6931159837679429
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6925780341029167
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6921662486516512
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917788841894694
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914599096775055
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911529406905175
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908936889732585
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6906642850902346
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904743229088031
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902959197759628
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6901310310477302
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899795719168403
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.68984444167303
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897071726620198
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6896016750335693
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6894825245325382
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6893863282821796
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6892876842192242
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6891937284634031
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891061468919119
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890374149045636
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.688969656638801
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889117602146033
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888482307686525
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6887932021277291
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887344295779864
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6886900905016307
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886406973788612
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6885996280572353
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6885492247343064
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885001607057525
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884645943130766
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884244763573935
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6883904845877127
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883550204171075
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883164893025937
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6882881510764994
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882596772164107
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882303788953897
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882010365724563
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6881705382291008
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881441572537789
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881231478925022
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881025437955504
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.688081238378178
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880686429994447

 End of epoch: 40 | Train Loss: 0.6868422240282582 | Training Time: 91 

 End of epoch: 40 | Eval Loss: 0.6899699313299996 | Evaluating Time: 5 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7552435576915741
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.721153301000595
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7098397771517436
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041015610098839
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7006218290328979
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6983624835809071
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6967938227312905
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6955633334815502
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6945950196848976
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6938016575574875
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6931716415015134
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.692628908654054
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921681601267594
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917827806302479
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914678617318472
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6912083197385073
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909807969542111
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6907257742351955
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6905195847937935
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6903522744774818
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.690182128690538
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6900272239338268
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898908112360084
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897390084962051
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6896323726177216
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6895371448535186
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894423239760928
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893574999911445
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892729132339872
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6891753025849661
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6891013310801598
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890288427472114
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889555322401452
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6888852527912925
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888337182998657
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887913273440467
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887321306241525
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886870128543754
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886570157148899
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6886090430617332
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885689344347977
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885116013742628
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884820124437643
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884321268309247
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6884000364939372
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.688366204370623
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883350752769632
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6883024332424005
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882733342598896
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882451223134994
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882294333448598
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6882006869866297
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.688176662741967
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881466012310099
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881098492579026
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880904372249331

 End of epoch: 41 | Train Loss: 0.6868672600889628 | Training Time: 89 

 End of epoch: 41 | Eval Loss: 0.6904154249600002 | Evaluating Time: 5 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7556754767894744
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7212803512811661
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7098444819450378
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7041057109832763
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7006784224510193
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6984062135219574
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6968080699443817
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6955920986831188
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6946318553553688
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6938663768768311
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931962262500416
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.692652786274751
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6922090892608349
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6918362370559148
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6915052545070648
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.691215704753995
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6909603024230284
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6907271795802646
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6905223771145469
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6903485590219498
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901933204560052
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6900116251273589
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6899080600427545
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897859667738279
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6896665804386138
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6895594463898586
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.689459894100825
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6893617621489934
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892606648905524
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891794772942861
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6891083684659773
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6890145486220718
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889585196971894
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888942408211091
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888259133270809
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887702334258291
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.688713214687399
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886625214626915
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6886184548720335
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885738441348076
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.6885166848578104
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.688477311247871
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884450747523196
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884123772382736
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883849701616499
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883547510789788
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883241323714561
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.688289412856102
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882538746814338
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882242922782897
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6882003619390376
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881777780560346
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881489867309354
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881213205832022
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880922437797893
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880741432309151

 End of epoch: 42 | Train Loss: 0.6868425030623917 | Training Time: 90 

 End of epoch: 42 | Eval Loss: 0.6904872570719037 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7558127164840698
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7211088061332702
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7095497747262319
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7038840055465698
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7004211080074311
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6981356312831243
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6964971576418195
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6952981404960156
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6943531162208981
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6935867500305176
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6929652880538594
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6924589375654856
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6920431458033048
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6916658942188535
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6913120706876119
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6910059146583081
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6907691341989181
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6905559615956413
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6903365586933337
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6901715677976609
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6900114896751586
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6898632721467451
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6896902763325236
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6895767328639825
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6894747586250305
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6893684465151567
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6892664622377467
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6891877685274397
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6891259960059462
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6890497281153997
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6889696811476061
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.688902298361063
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6888419669685941
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6887914349051083
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6887503841945103
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6886978038483196
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6886553094193743
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886074478688993
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6885520880038921
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885137386620045
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6884853931461893
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884523644333794
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884152200332908
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.688378895683722
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883423512511783
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883065747178119
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6882776824717826
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.688245880479614
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882248933217964
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.688198755979538
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6881718249881968
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881499115091104
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881145462674915
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6880980021423764
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6880758448080583
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880603938230446

 End of epoch: 43 | Train Loss: 0.6868341744473551 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.690284720488957 | Evaluating Time: 5 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.7554976940155029
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7212632775306702
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7098237752914429
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7040437743067741
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.700605456829071
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6982718626658122
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6966020728860582
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6954330742359162
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944753792550828
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6937228137254715
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.693103642355312
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6925641417503356
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6921542901259202
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917816200426646
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6914500240484873
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6911940615624189
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6909376582678627
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6907494028409322
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6905339871582232
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6903385409712791
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6901603468826839
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6900260109793056
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6898714265097743
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6897364551822345
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6896155688762665
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894998930967771
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6893902021425742
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6893035469310624
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6892066865131773
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6891338654359181
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.689054572966791
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6889825861901044
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889170399217894
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888633102178574
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.688808992930821
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887607998318143
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6886977977043873
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886467665433884
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.688610686858495
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.688558273166418
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885144046167048
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.688479467233022
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884512966455415
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884074062108994
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883646417988671
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883347462052885
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6883017685819179
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882679525762796
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882397173618784
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882105557918549
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881896918895198
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881635613166369
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881391688337866
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881063848733902
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.6880817958441647
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880553336015769

 End of epoch: 44 | Train Loss: 0.6868283545021462 | Training Time: 89 

 End of epoch: 44 | Eval Loss: 0.6902452707290649 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7555659532546997
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7211732655763626
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7095815141995748
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7039603412151336
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7005130696296692
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6982711056868235
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6966516315937042
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6954544179141522
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6944906665219202
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6937544292211533
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6931600673632188
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6926071102420489
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921398937702179
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917601640735354
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6914518984158834
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6911609772592783
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6909163864219889
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906869282325109
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904907433610213
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.6903164890408516
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6901474427609217
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6900049914013255
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6898856831633526
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6897701141734918
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.689648752450943
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.68954547391488
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6894435741283276
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6893482817070825
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6892702373965033
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891975096861521
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6891223063392024
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6890494264662266
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.688970416242426
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6889168860281215
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6888710442611149
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6888167127966881
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6887567840717934
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6887074428169351
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6886499472153492
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.6886054341495037
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885644863291485
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6885133977447238
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884688510451206
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6884319664402442
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883935799863603
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883552521467209
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883276697168959
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882860497881969
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882506779261998
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882229679822922
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881948533011418
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881701806416878
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881425889033191
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881196337717551
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880942239544608
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880718559026718

 End of epoch: 45 | Train Loss: 0.6868418690377632 | Training Time: 89 

 End of epoch: 45 | Eval Loss: 0.6904489994049072 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7551318228244781
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7209787994623185
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7095571080843608
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7038443356752395
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.70041494846344
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.698138639330864
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6965316414833069
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6953025408089161
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6943314830462138
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6936061358451844
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6930185843597759
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925043165683746
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6920374810695649
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6916560270956584
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.691325557231903
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6910534303635358
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6908068895339966
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.690590516726176
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6903807279310729
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902073794603347
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6900669029780797
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899245676669208
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.689771654813186
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6896530856688817
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6895431077480316
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894492286902207
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893465090681006
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892537906765938
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891751375691644
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.689095675945282
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890079257949706
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889455227181316
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6888845474431009
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.688833979122779
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887848082610539
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887333628204134
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886888476642402
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886431141903526
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6885994209693028
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885474686324596
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6884996675863498
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884639146782103
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884240348671757
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.688392549617724
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883533616860708
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883188946091611
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882916056095285
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882577578226725
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882219731807708
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6881960085630416
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881714158198413
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881518174822514
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881204400422438
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6880978167057037
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.688076624545184
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880505559699875

 End of epoch: 46 | Train Loss: 0.6868275137074226 | Training Time: 89 

 End of epoch: 46 | Eval Loss: 0.689902024609702 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.755454933643341
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.72127725481987
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7096973121166229
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7039268985390663
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7003890883922577
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6981804678837459
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6964784988335201
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6952847667038441
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6943967991405063
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6936257982254028
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6929542178457434
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6924835309386254
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6919887579404391
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6916325590440205
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.691315831343333
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6910452730953693
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.690779706660439
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6905687246057722
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6903755191125368
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902190363407135
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900595920426505
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899066686630249
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6897654455641041
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896552642186483
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895316245555878
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894152813232862
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893313131950519
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892419044460569
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891576836849082
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6890846453110377
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.689005434128546
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889353191480041
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6888628506299221
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6887831903555814
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.688736207144601
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6886775356200007
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6886288265924196
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6885729231332478
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.688530496450571
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6884865659475327
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6884501570608558
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884029103176934
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6883684137532877
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883475710045207
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883084415064917
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6882882619681565
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882624011090461
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882388707250356
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882178566893753
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6881966735124588
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.688167556477528
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881411005671207
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881203270183419
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6880925489796532
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880678099935705
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880498649818557

 End of epoch: 47 | Train Loss: 0.6868218453584519 | Training Time: 88 

 End of epoch: 47 | Eval Loss: 0.6904079573495048 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7552556812763214
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7209500879049301
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7096758047739665
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7039219692349434
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7004727530479431
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6981817652781804
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6965776128428323
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6953902184963227
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6944229125976562
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6936311537027359
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6929857617074793
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6924767578641574
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.692048595043329
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6916665826525007
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6913505121072133
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6910602416843176
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6907878507586086
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.690603306889534
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6903941279963444
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902032843232155
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6900348521414257
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6898874832825227
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6897431124811587
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6896265258391698
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895106995105743
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894041806459427
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893153144253625
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892072896872248
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891212705908151
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6890462225675583
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6889715012042753
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889183524996042
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6888528296441743
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6887953262118732
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6887544681344714
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887026937471495
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886551132073273
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886050679181751
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6885555267333985
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885055732727051
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6884653606065889
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884204258521398
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6883818318677503
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883507892489433
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883112347126007
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.68828337231408
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6882548282755182
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882305787255366
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.688208305957366
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881701565980911
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881499498498206
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881306373156034
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881048363334727
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6880815561170931
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880685950409282
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880454510450363

 End of epoch: 48 | Train Loss: 0.6868202794969609 | Training Time: 86 

 End of epoch: 48 | Eval Loss: 0.690405820097242 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7556982398033142
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7214657247066498
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7098303894201915
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7040761768817901
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7006695830821991
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6983615100383759
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6967095170702253
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6955151155591011
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6945298386944665
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6938134092092514
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6931637135418979
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6926309024294217
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6922100713619819
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6918113078389849
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914803167184194
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6911568563431502
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6909054054933436
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906762848297755
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904437338051043
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902701956033707
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6901249193009876
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.689975856109099
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6898373839647873
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6897000146408876
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895822505950928
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894968699950438
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893964008048729
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6893036378281457
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892163188293062
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891496384143829
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890739985050693
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6890021380037069
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889265596866607
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888605769942788
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888079524040223
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887528098291821
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.688690726821487
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886494120484904
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6885909583324041
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885361680388451
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6884947033917032
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884524918737865
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884049800939338
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883840468796817
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883561898602379
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.688329581203668
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882986742131254
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.688272749632597
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882454425704723
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882140166759491
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881938600072673
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881653888867452
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881573615209111
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.688127820690473
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880938712033359
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880859112100942

 End of epoch: 49 | Train Loss: 0.6868578204011495 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.6897386738232204 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7555939316749573
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7210207581520081
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7096089601516724
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7038065001368523
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7004562985897064
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6981470674276352
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6965743167059762
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6952813439071178
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6942924367056953
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6935241842269897
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6928748461333188
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6923418005307516
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6918766416036166
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6915033808776311
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6912056835492452
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6909130610525608
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6906765317215638
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6904823972119225
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6902832115951337
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6901332178711891
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.689981841757184
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6898268415169282
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6897039574125539
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6895920957128207
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6894992642402649
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6893900660368112
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893155051602258
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892247344766345
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891337651630928
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6890680291255316
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6889982733034319
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889302337542176
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6888817935278921
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888166567858528
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887655440398625
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887192426456346
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886584591221165
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886047066826569
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6885607876838782
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885152374207973
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6884672381528993
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884341193096978
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6883946458960688
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883625920523296
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883355071809557
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883094532334286
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882738124816976
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.688239752377073
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882151782512664
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.688186230301857
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881590187549591
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881344594634496
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881155188353556
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880944444073571
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.688073578639464
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.68805577733687

 End of epoch: 50 | Train Loss: 0.6868312240701862 | Training Time: 87 

 End of epoch: 50 | Eval Loss: 0.6903512477874756 | Evaluating Time: 6 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7559192776679993
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7212497383356095
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7098401923974355
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7040743365883827
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7005525493621826
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6982202758391698
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6966899820736476
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6955212756991387
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6945588674810198
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6937503552436829
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930671762336384
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6925532728433609
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6920981838152959
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6917411225182669
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6914187387625377
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6911391537636519
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6908833005849053
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6906648824612299
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6904460517983687
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6902406898140907
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900940645308722
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6899571559645913
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6898193452669227
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6897103240092596
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.689588406085968
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.689473179441232
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893806208063055
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892848276666232
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891941646049763
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6891128130753835
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890393720519158
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889748847112059
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6889063248128602
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888448443482904
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887815817764827
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887414332893159
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886881148492968
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886239613357343
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885777890682221
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885374610126018
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6884925358179139
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884531022537322
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884042213129443
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883685541423884
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883376808961232
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883054700882538
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882782838446029
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882457269976536
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882194430244212
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6881857358217239
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881532665561227
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881203229610736
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881062043163012
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880878816048305
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880649742213163
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880457468330861

 End of epoch: 51 | Train Loss: 0.6868221564630491 | Training Time: 88 

 End of epoch: 51 | Eval Loss: 0.6895942091941833 | Evaluating Time: 6 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7555165350437164
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7209795743227005
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7095002174377442
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7037669017910957
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7004398441314698
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.698168953259786
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6965541320187705
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6953575521707535
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.694430810213089
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.69363663315773
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930106824094598
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6924815411369006
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.692079143340771
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6917163529566356
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6914117785294851
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911428745836019
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6908869739841013
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906436701615651
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904384318150972
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902294048666954
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.690059582960038
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899171875281768
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6897866324238155
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.689668191721042
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895533111095429
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.689447409602312
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893318774523558
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.689243293447154
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891397568686255
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.689058072368304
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.688997152351564
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.688916333205998
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6888453021193995
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.688789777545368
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887310528755188
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.688674642642339
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.688619010190706
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6885742476111965
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885211869692192
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6884759432077407
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6884349539512541
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6883899453140441
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6883581076943597
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883224227211692
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6882941344049242
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.688259148079416
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882352782056687
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882141277194023
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6881884616248461
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881595791578293
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881299886049009
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881124279820002
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6880929033711272
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880738877587849
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880563036961989
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880328334867954

 End of epoch: 52 | Train Loss: 0.6868124757192832 | Training Time: 89 

 End of epoch: 52 | Eval Loss: 0.6898141503334045 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7558100283145904
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7212971925735474
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7098390996456146
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7041544258594513
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7007016921043396
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6983883420626322
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6967718464987619
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.695506752282381
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6945121705532074
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6937524336576462
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6931663458997553
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6926511074105899
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6921771044914539
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6917910835572652
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6915104627609253
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.691212658956647
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6909207536893732
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906994760036469
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6904812106960698
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902816310524941
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901069408371335
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899662291461771
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.689825212178023
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896835481127103
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6895693054199219
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894744052336766
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893866095277998
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892903562102999
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6892204471703234
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891351854801178
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890603488491428
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.689004610106349
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6889443048925111
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888853690203498
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6888248658180237
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887765912546052
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6887126466712437
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886589955342444
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885985278166258
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.688541933298111
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6885127157699771
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884719702459517
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884295439997384
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.688398781012405
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883503217167325
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883020219595536
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882713877140207
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882491495460272
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882215654363437
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.688205409526825
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.688178213671142
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881573003072005
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881270397384212
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6881035523282157
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880778671394695
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.68805019355246

 End of epoch: 53 | Train Loss: 0.6868210042472435 | Training Time: 88 

 End of epoch: 53 | Eval Loss: 0.6902337670326233 | Evaluating Time: 5 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7555183649063111
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7212236195802688
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7096305390199026
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7039467841386795
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7004402196407318
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6981148550907771
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6964178749493191
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6952102668583393
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6942363778750101
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6934512656927109
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6927995318716222
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.6922971730430921
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6919171337897961
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6915283390453884
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.691226878563563
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6909323420375586
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6906653116731083
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6904491202698814
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6902764608985499
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6901089549064636
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6899549963928404
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6898042193867944
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6896903338639633
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.689591720700264
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6894710454940796
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6893597827507899
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6892768844410225
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6891957106334823
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891159316589093
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6890453465779622
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6889595050965586
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889003500342369
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888300352024309
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6887643750976113
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887072105067117
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6886565418707
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886093862958856
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6885679935154162
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885325557146317
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6884957027435302
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884424059856229
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884070670320874
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6883611963238827
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883235201239586
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6882976943916744
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6882689084695733
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882337164371571
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882072161883116
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6881796119164447
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.688161003947258
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.688132925711426
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.688113160431385
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6880985857180829
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6880787432193756
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880567554994063
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880346355693681

 End of epoch: 54 | Train Loss: 0.6868060072966381 | Training Time: 89 

 End of epoch: 54 | Eval Loss: 0.689155672277723 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7556054055690765
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7210891246795654
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7095969398816426
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7039282843470573
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7005125904083251
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6982499768336614
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6966305843421391
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.695450322329998
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.694499076075024
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6936813807487487
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6930965407328172
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6925973504781723
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6921646145673899
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6917785231556212
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6914602971076965
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6911298874765635
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908870223690482
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6906683852275213
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6904756254271457
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.69029676258564
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6901214886279333
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6899582868272608
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6898124412350033
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896745949983597
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6895503034591675
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6894483529604398
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893492647895106
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892565801739693
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.689161086493525
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6890689780314764
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6889869957200943
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.688928659632802
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888551390532291
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6887954724185607
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887402365888868
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6886904474761751
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886486114682377
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886044190118187
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885601176665379
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885056829452515
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884671618298787
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884239799919583
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6883898635243261
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883535576137629
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883186508549585
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882933144984038
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882670341654027
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882350698113442
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6882049637181419
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881674218177796
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881480052190668
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.688120014507037
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881039995067525
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.688076678580708
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880518176338889
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880288528544563

 End of epoch: 55 | Train Loss: 0.6868035711018385 | Training Time: 90 

 End of epoch: 55 | Eval Loss: 0.6903702446392604 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7549476325511932
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7207857131958008
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.709455543756485
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7038006618618965
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7003932070732116
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6981058488289515
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6964693069458008
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6952457010746003
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6943116188049316
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.693546193242073
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.692926427451047
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6924374148249626
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6919931333798629
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.691642924291747
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6913010255495707
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910303562879563
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6907592647215899
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6905113385783301
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6903022932378869
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6901365575194359
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6899982202620734
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6898553290150382
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6897260785102844
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6895780071616173
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6894631474018097
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6893486387454546
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.689272223799317
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6891942569187709
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891122857044483
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890415130058924
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6889709518801781
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889230223372579
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6888548901586822
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6887864140903248
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.688730696439743
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6886714589264658
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.68862352822278
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6885750234127045
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885390086051745
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885033392906189
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6884615582663839
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.688426481684049
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6883890560893126
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883499863472852
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883186150921715
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882918563873871
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.6882644710388589
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.688235113521417
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882064964090074
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.688189679980278
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881666264113258
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.688142025585358
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881163261971384
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880923153073699
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880680082061074
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880406909755298

 End of epoch: 56 | Train Loss: 0.6868192492333134 | Training Time: 88 

 End of epoch: 56 | Eval Loss: 0.6901202116693769 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7557332217693329
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7213981568813324
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7097243527571361
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7039827078580856
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7005721294879913
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6983220438162486
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6966836035251618
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954402022063733
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6944861888885498
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.693761630654335
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6931395194747231
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925809855262438
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921627287681286
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917543977499008
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.691436019341151
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911638684570789
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6909094284562504
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906799011760287
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904680578332199
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902710393071174
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.690111308722269
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899518611756238
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6898151638715163
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896861950556438
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895684037208557
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894632612283413
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893738159426936
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892881323184286
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6891952652355721
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6891310187180837
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890612763743247
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889927975833416
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6889332137324593
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888731928432689
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6888000130653381
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887493476271629
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6887006817637263
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886553380050158
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6886136698417175
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885814906656742
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6885376428685537
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884809327977044
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6884416390297025
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6884192157875407
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883737288581
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6883366657340009
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6883008018453071
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882707762221495
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882353708452108
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6882066074609756
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.6881883345398249
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881636585180576
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.68813425549921
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6881089817594599
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880797518383373
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880510074751718

 End of epoch: 57 | Train Loss: 0.6868221061419597 | Training Time: 90 

 End of epoch: 57 | Eval Loss: 0.6892043948173523 | Evaluating Time: 5 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7554415047168732
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7212133556604385
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7097028096516927
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.704038679599762
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7005955076217651
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6983346422513326
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6967008020196642
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6954785965383052
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6944593568642934
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6936875200271606
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.693045131184838
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6925045748551687
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.692048166348384
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6916701938424792
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6913376347223917
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.691051360219717
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6907968181021074
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6905778441164229
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6903872402090775
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6902116477489472
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6900323112805684
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6898744593967091
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.6897562464942103
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6896374640365441
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6895319790840149
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6894403459934088
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6893482727033121
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892485586660249
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6891699760124601
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.689098060131073
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890357511658822
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889601791277528
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6888940467978969
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888260506531771
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887703468118395
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887078290184339
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886516437337206
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886143645173625
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885647657590035
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885174152255058
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884731138624796
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884234417052496
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883884087551472
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.688356941532005
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883266984091865
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882901034925295
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882529366523662
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882174786180257
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6881798721089655
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881659662723542
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.688141892938053
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.688122056883115
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6880970888542679
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.68806671069728
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880501071973281
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880246631801128

 End of epoch: 58 | Train Loss: 0.6867983891900662 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.6902160899979728 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7550701081752778
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7207129180431366
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7093824466069539
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7037837713956833
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7003701341152191
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6981486082077026
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6965320757457188
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6953186713159084
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6943771249718136
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.6935977780818939
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6929595811800523
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6924476981163025
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6919843449042393
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6916105896234512
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6913244342803955
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6910503178834915
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6908007400877335
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6905826886494955
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6903891958688435
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902219635248185
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6900360828354245
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899101493033496
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897880359836247
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896666216353575
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6895602288246154
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6894371186311429
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893426294679995
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892535731196403
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891641988836485
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890737390518189
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6889973246282147
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889338172972203
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6888695646416058
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.688805203928667
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887419131823949
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6886834977401628
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886399915089478
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6885868897563533
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885407761121407
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885009014606476
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884525953269587
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.6884022216002147
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6883663730565892
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883323799480091
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883113543192546
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.688284193692
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882583605482223
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882247172296048
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6881927951258056
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881675934791565
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881445582006492
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881155804945872
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6880921982369332
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880752521532553
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880507296865637
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880240614925112

 End of epoch: 59 | Train Loss: 0.6867969392675214 | Training Time: 88 

 End of epoch: 59 | Eval Loss: 0.6898281914847237 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.755462396144867
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7212503165006637
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7097218195597331
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7040624797344208
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7006758034229279
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6983782480160395
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6967383427279336
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6955126330256463
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6944840868314107
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.693697206377983
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6930733539841392
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6925333912173907
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6921258522914007
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917761227914265
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6914034752051036
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911367684602737
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6909004309598137
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.690666765305731
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904588002907602
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902715295553208
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901274391583034
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6899681497703899
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6898303832696832
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896999592582385
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6895703520774842
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894686547609475
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893625131359806
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892538360186986
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6891548181402272
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6890743553638459
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6889982263888083
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889387657865882
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6888624016082648
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.688809225839727
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887485917976924
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6886910147137112
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886328320245485
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6885761968399349
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885331282248863
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6884919901192188
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884532611544539
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884071863832928
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6883771608042163
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.688347034833648
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883149888780382
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882863980272542
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882455615287132
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882156927138567
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6881737205446983
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881535273790359
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881327899063334
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6880977506820972
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6880769703748091
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880482235440502
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.688029613494873
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.688016645184585

 End of epoch: 60 | Train Loss: 0.6867941570492972 | Training Time: 89 

 End of epoch: 60 | Eval Loss: 0.6899419597217015 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7556059539318085
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7211083084344864
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7095850308736166
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.70404604524374
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.700658746957779
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6982883473237356
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6965608724525997
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6952887572348118
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6943922771347893
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6936209160089493
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6930151142857292
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6925016601880392
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6921043272201831
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.6917244430099215
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6914120185375213
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6911442551761866
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6908814707223107
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.690634153286616
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904384104829085
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902391365170479
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6900906273296901
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6899366628039967
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6897842764854432
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6896680779755116
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6895585775375366
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894502238585398
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893530973681697
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6892481077994619
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891521466189418
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890769557158152
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890098812118653
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889404801651835
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888645900018288
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888043680611778
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887418493202755
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6886813039580981
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886450192412814
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.688610269991975
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885567334982065
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6885094174742699
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884642928111844
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884344836076101
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883897845135178
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883560904047706
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883195625411139
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882856600958368
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882434749856908
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882184127966563
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881931952067784
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881600453853607
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881307128597708
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881139716276756
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.688089829908227
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880652560128107
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.688050804680044
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880231594400746

 End of epoch: 61 | Train Loss: 0.6867964495599798 | Training Time: 91 

 End of epoch: 61 | Eval Loss: 0.6897298778806414 | Evaluating Time: 5 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7557743430137634
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7212409406900406
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.70963094830513
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.703889413177967
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7005028402805329
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6981688429911931
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6965431128229413
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953654393553734
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944254318873088
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936800730228424
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6930353164672851
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925080617268881
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6920409138386067
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6916712995086397
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913422580560048
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.691063829138875
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.690793938145918
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.6905985259347491
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.690409474310122
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6902254319190979
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6900811853862944
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899271263317628
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6897948205471038
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896656257410844
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6895461554527282
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894361236920723
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6893390787972344
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892244356019156
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891211931047768
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890454341967901
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6889838851267291
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889156261458993
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888525841814099
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6887847448096556
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887224755968366
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6886883437633514
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886284928064088
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6885671076021697
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885234146546095
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6884797441959382
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884354525949897
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6883897324403127
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883503352486811
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883192911744118
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6882815109358893
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882607835790385
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882320392639079
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882116009791692
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881798452260542
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881568408012391
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881225677097544
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881002768874168
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880798636742358
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880647816039898
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880414552038366
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880212333585535

 End of epoch: 62 | Train Loss: 0.6867938780151637 | Training Time: 91 

 End of epoch: 62 | Eval Loss: 0.6896344338144574 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.755706250667572
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.7213005274534225
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7097349663575491
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7039991647005082
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7005684387683868
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.698297522465388
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.696706599848611
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.69540174305439
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6944637689325545
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6936373054981232
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6930025079033592
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.692481204867363
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920373843266414
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.691669481566974
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6913387250900268
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910591702908278
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6907842779860777
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905515508519279
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903544068336487
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6901807099580765
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900182672909327
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6898459103974429
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6897100746631623
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.689588782687982
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.689455826997757
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6893458290741994
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6892709270671562
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6891761068786894
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891028149374601
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6890170753002167
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6889398157596588
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6888696897774935
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888043885881251
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6887391221873901
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6886909091472626
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6886435909403695
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6885958138349894
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885466065845991
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885026195110419
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6884705711901188
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884427955964717
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884158096143178
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883942128613938
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883460745215416
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883176497618357
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882953050343886
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882631707698741
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882319069157045
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6882132365995524
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881832193136215
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881539783057045
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881253498104902
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6881010747180795
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880759432359979
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880459594726562
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880305857530662

 End of epoch: 63 | Train Loss: 0.6868033738262885 | Training Time: 89 

 End of epoch: 63 | Eval Loss: 0.690331254686628 | Evaluating Time: 5 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7551387190818787
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.720985832810402
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7097421367963155
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7039701744914055
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7005413210391999
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6981899907191594
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6965442844799586
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6953395135700703
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6943695028622945
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6936370950937271
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6930167187343944
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6925169597069423
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6920856448320242
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6916897939784187
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.691333620150884
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6910554707050324
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6908334700500264
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6905995647112528
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6903849002562071
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6902262768149376
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.690059897445497
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6899043616923419
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6897753337155218
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896449215710163
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6895340945720673
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6894161710372337
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6893201997986547
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.689225648343563
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891347007504824
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6890530033906301
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6889832052492326
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889306008815765
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888695234602148
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888162534026538
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887619081565312
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6887079021996922
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886549986697532
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6886053314334468
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885568773135161
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6885131694376468
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884626842126613
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884194070384616
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6883737363094508
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883364643562924
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883102329572042
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882710551438125
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882431949706788
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882084882507722
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6881747537729691
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881456422805786
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881303954358194
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881010831548617
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880706329390688
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880512685687453
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.6880337429046631
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880134613386222

 End of epoch: 64 | Train Loss: 0.6867920637130738 | Training Time: 91 

 End of epoch: 64 | Eval Loss: 0.6895594256264823 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7553685188293457
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7209612965583801
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7095592578252157
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7037760123610497
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7003654420375824
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6981256306171417
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6965643857206617
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953789047896862
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.694502036439048
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6937542980909348
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6931473406878385
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6926029796401659
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6921808219872988
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.691767110994884
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6914466385046641
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6911585539579391
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6909105893443612
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6906785001357396
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904566187607615
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902713215351105
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900973564102536
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.689943042397499
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6898179652898208
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896979518234729
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895558259487152
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6894454277478732
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893385743653333
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6892344036272594
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6891464734899586
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6890706803401311
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6889957900970213
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6889155156910419
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888335710222071
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6887710665955263
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6887302390166692
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6886716966827711
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886229866259806
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6885888901196028
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885383304877158
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6884896677732467
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6884428886378684
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884067998045966
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6883695024390554
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883374132893302
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883022089799246
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6882678683685219
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882346471573444
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882068696121375
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6881750052072564
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881566383838653
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.6881226638952891
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6880969210312917
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6880710552323539
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880495560389978
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880253900181164
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880085096827575

 End of epoch: 65 | Train Loss: 0.6867834546924693 | Training Time: 90 

 End of epoch: 65 | Eval Loss: 0.6894924896103996 | Evaluating Time: 5 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7553889691829682
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7213600277900696
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7097808102766673
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7039945468306541
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7005554747581482
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6982233047485351
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6965475235666547
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6952952533960343
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6943897008895874
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6936092710494995
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6929469325325706
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6924322709441185
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920159170260796
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6916744428021567
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6913693153858185
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6911010079085826
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6908381367430968
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6906162275208367
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6904195769837028
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6902228021621704
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.6900557489622207
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6899315305731514
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6898069433543993
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896732725203037
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6895375046730041
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894351560335893
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6893411106533475
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6892380865556853
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891602396965026
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890593737363815
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6889874775563517
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889115525409579
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888387360356071
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6887856779729619
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887183111054557
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6886687240666813
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886171725956169
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6885722405032108
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6885201237140558
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6884752908349037
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884402014860292
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.688398779290063
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6883720895578694
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883364460685036
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6882977521419525
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882681437160658
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882389417354097
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882117199401061
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.688189100975893
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881664263010026
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881359900913987
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881161535015473
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6881049735366174
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880737336697402
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880440553751859
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880157620779106

 End of epoch: 66 | Train Loss: 0.686789590278558 | Training Time: 91 

 End of epoch: 66 | Eval Loss: 0.689771022115435 | Evaluating Time: 5 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7555494546890259
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7211186558008194
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7096595486005147
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7038479432463646
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7004039514064789
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6980877657731374
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6964608779975346
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6952679231762886
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6943223145272996
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6935433310270309
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.6928643730553714
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6923687597115834
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6919508539713346
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6915829518011638
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6912503306070964
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6909919694066048
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6907693221288569
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6905381527211931
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6903647460435566
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.690175847709179
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6900307042258126
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.68988597528501
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6897707293862881
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.689644405245781
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895241529941559
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894192934036255
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893305242061615
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892512862171446
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891665886188375
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6891023357709248
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890189834179417
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889571513980627
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6888908816106392
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888264538610682
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887738725117275
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6887230005529191
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886594020031594
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.688612224710615
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885626426109901
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885134619474411
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884698441842707
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884331395228703
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6884036906929903
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883645052259618
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883248550362057
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882932374010915
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882567900292417
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882223625977834
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.688188033566183
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881576372385025
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881324901300319
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881042564144502
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880838566231278
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880660094596721
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.688043383251537
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880115677203451

 End of epoch: 67 | Train Loss: 0.6867826758232792 | Training Time: 90 

 End of epoch: 67 | Eval Loss: 0.6897086756569999 | Evaluating Time: 5 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7552059352397918
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7208360344171524
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.709593536456426
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7038862988352775
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7005115568637847
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6982034017642339
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6965916156768799
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6953664369881153
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944132480356429
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.693687435388565
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930495197122747
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925340513388316
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6920703544066502
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6917224236897059
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913860070705414
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910818923264742
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6907950811526354
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.690587153368526
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6903762318586049
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902118363976478
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900499281429109
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.689911575479941
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897777124591495
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896784255901972
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895475885868072
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894587963819504
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893793947166866
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892937308975629
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891923859201629
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6891301256418229
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.6890512274157616
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889792026951909
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6889144229166435
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888562116552802
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887821769714355
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6887212625808186
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.688672462991766
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6886021651719746
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885587171102181
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.688523739874363
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884847030407045
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884350014584405
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883968601393146
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883641867475077
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883268172211118
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882920244465703
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882615921345163
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882324484487374
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.688205178294863
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881663942337036
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.688141354041941
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881093183389076
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880873452942327
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880627405864221
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880436795408076
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880138498331819

 End of epoch: 68 | Train Loss: 0.6867910064427198 | Training Time: 91 

 End of epoch: 68 | Eval Loss: 0.690054110118321 | Evaluating Time: 5 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.755940842628479
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7213899433612824
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7098198533058167
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7039683729410171
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7005562818050385
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6982328742742538
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6965900489262172
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6953482694923878
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6943795104821523
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6936600458621979
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6930833426388827
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6925535216927529
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6921396177548629
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917565264872142
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914321347077688
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.691156255453825
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6909074769300573
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.690676377216975
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6904709044255708
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902644571661949
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900951291833605
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6899455306204882
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6898016693799393
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896744767824808
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895523467063904
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.689442972953503
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.689343762618524
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892674903784479
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891841395147915
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6891205014785131
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890426051232122
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889755595475435
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6889190977269953
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6888498870765462
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887798079422542
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.68872030377388
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886762921874587
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6886121934966037
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885667392840752
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6885208988189697
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884696831063526
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884184953712281
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883866229722666
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883431353352286
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883164914449056
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882729640473491
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882331881117314
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882030283411343
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881790827731697
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881536583900452
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881249199895297
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881060460439095
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880841409260372
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880613339168055
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880402075160633
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880225354007312

 End of epoch: 69 | Train Loss: 0.686791507121736 | Training Time: 91 

 End of epoch: 69 | Eval Loss: 0.6897849355425153 | Evaluating Time: 5 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7559002459049224
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.721261203289032
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7094811022281646
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7038081660866737
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.700416773557663
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6981975764036179
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6966087290218899
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6953906491398811
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6944454722934299
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6936847686767578
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6930334026163275
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6925109689434369
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6920916204269115
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6917040207556315
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.691359437306722
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6910635709762574
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6908346211209017
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6906053059630923
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6904166325142509
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6902297222614289
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6900554046744392
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.689939054033973
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897975846477177
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6896724181870619
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895472354888916
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.689438991363232
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.689337388895176
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892451328890664
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.6891682848848145
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890805373589198
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6890121842584302
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889348812401295
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888712594003389
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6888129427152522
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887486668995448
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6886805247929361
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886335711221437
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6885771299663342
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885358677460597
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.688500779569149
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884556654022961
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6884100481158211
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883755782315898
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.688344705240293
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6883029672834609
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882669990477355
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882311200841944
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882008910179138
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881757843251131
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881538661718368
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.688126371421066
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.688094063790945
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880721979546097
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880536146737911
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880302001129497
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880100017147405

 End of epoch: 70 | Train Loss: 0.6867842635222241 | Training Time: 91 

 End of epoch: 70 | Eval Loss: 0.6903033767427716 | Evaluating Time: 5 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7560118913650513
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7213888376951217
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7099083542823792
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7041166543960571
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7006279587745666
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982345332702001
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6966115985597883
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953143931925296
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6943607568740845
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6935903644561767
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6929672718048095
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6924811934431394
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.692069642818891
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6916849178927286
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6913713161150614
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6910784371197224
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.690815812699935
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6905843847327762
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6903842144890835
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6901891675591468
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.690045671519779
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6899088818918575
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6897683262825012
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6896396810809772
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.689509997844696
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894053479799858
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893124160943208
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892255749021258
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891289949417114
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6890323136250178
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6889593076321386
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6888951597735286
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6888384921984239
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6887753272757811
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887109134878431
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6886512925227483
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.6885994234600583
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.688551136537602
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885114258680588
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6884652364253998
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884345300313903
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.68839863439401
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883618619552878
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883240959861062
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6882946425014072
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882618142210919
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882364313653175
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6881997047613064
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881837622243531
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881590247154236
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881415817083097
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881092697381973
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880861966115124
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880574457071446
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.688031535690481
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880073212087154

 End of epoch: 71 | Train Loss: 0.6867795694190844 | Training Time: 91 

 End of epoch: 71 | Eval Loss: 0.6891664011137826 | Evaluating Time: 5 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7556338250637055
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7213738441467286
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7098779122034709
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7040858283638954
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7006755244731903
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6982847859462102
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6966567925044469
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6953913003206253
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6944714393880632
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.693690824508667
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6930647990920327
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6925341755151748
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6920991439085741
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6917326011828013
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6913827570279439
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910641971975565
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6908083999858183
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905927581919564
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.6903879529551455
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6902013805508613
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900444652353014
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898872451348739
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897635814936265
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.689640707274278
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895398418903351
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894316622844109
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.6893116496227406
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892258759055819
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891564523351603
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890763050317764
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6890023269960958
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889340447261929
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888702849547068
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888170358012704
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887631874425071
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886980656120513
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886472693971686
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6886009911173269
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885587356029412
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.68850968003273
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884735213547218
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884269715774627
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883943895960963
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.688354818252
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883338379859925
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882937932791917
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882530213670528
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882279592255751
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6882039328010715
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881767921447753
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881417696382485
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881099217213117
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.688084947163204
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880676902002758
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880415337735957
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880145560417856

 End of epoch: 72 | Train Loss: 0.6867945076090045 | Training Time: 91 

 End of epoch: 72 | Eval Loss: 0.6896297335624695 | Evaluating Time: 5 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.754813838005066
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7206236004829407
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7093617459138234
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7036838665604591
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7002303063869476
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6979254484176636
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.696396860906056
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.695214182138443
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6943070338832007
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.693524689078331
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6929086148738861
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6924018422762553
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6919288461024945
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6915916212967463
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6912724339962005
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6909865971654654
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6907335782752317
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905258725086848
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6903249621391296
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6901568025350571
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6899943618547348
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6898264662785963
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6896924692651499
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6895843920608361
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6894678068161011
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6893734434476265
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6892683960773327
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6891855546406337
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.689107132163541
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890255087614059
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6889533398612853
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6888818629086018
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888170124906482
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6887546090518727
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6886995674882617
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.688651352127393
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6885984515821612
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885492036217138
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885142607566638
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6884658227860928
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.68841396657432
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6883844869477408
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.688355236413867
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883206494829871
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6882961270544264
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882581736730493
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882325059555946
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6882078631470601
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881694320513277
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881442593336106
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881134056577496
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6880937461669628
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880673289299011
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880413169110263
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880215721780604
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.6880002028175762

 End of epoch: 73 | Train Loss: 0.6867770781559227 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.6896385039602008 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7556284248828888
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7211927354335785
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7096604307492574
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7038825199007988
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7004402256011963
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6981472541888555
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6965058522565024
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6952891997992993
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6943781958685981
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6936554104089737
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6930227967825803
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6924908344944318
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6920356094837189
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.6916786968708039
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6913536389668783
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6910664964467287
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.690830052950803
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6905879553821351
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6903972017137627
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6902185347676277
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6900164774485997
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6898865567012267
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6897655756577201
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.689642566939195
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895238602161408
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894211679697037
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.6893148861549518
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892334067395756
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891353089233925
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6890696048736572
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.688987720589484
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889165680855512
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888395307642041
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6887757844784681
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6887028062343598
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886528939008713
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886103604290936
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885550202507722
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885159723269634
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884642472863197
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884188055992126
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6883791642529624
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883500517800797
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883178399367766
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6882948248916202
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882548456606657
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882171994828163
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6881977081298828
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881712024309197
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881539226770401
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881296227960025
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6881007722937144
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880813832552928
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880536398401966
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880369018424641
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880115586732115

 End of epoch: 74 | Train Loss: 0.6867808315606244 | Training Time: 88 

 End of epoch: 74 | Eval Loss: 0.6900069117546082 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.755449652671814
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7211272180080414
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7097660144170125
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7039606839418411
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7005526566505432
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6982186535994211
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6965732336044311
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6953169442713261
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6943834741910299
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.693624820113182
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.6929690919139169
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6924332285920779
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6919995908553783
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6916348912886211
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6913331584135691
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6910403817892075
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6907757962451262
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6905738469627168
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6903850395428507
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6901937434077263
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900298129944574
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6899068932641637
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897648129774177
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896449786921343
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.689518878698349
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894112752034114
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893287003040314
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892493552395276
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.689149123430252
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890828408797582
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6889960579333767
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889287592843175
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888506139769699
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887922928613774
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887330220426832
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886817811263932
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886243446453197
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885667062119434
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885208791647202
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884857243299485
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884434659306596
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.688397199341229
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.688351776572161
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883251079104163
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6883004878626929
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882732609043951
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882291128026679
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6881980277597904
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881664789452845
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881443688869476
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881171897345898
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880940672296744
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880668688495204
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880409133655053
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.688015793020075
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880018141652856

 End of epoch: 75 | Train Loss: 0.686773171045084 | Training Time: 90 

 End of epoch: 75 | Eval Loss: 0.6896175231252398 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.755571985244751
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7212614297866822
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7099113206068675
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7040617555379868
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7006537616252899
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6983158399661382
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6966956751687187
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6954261757433414
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6944809661971199
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6937098902463913
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930795935067263
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6925270448128382
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6920761177173027
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6916805565357208
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913578375180562
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6910531893372536
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908166061429416
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6905885560644998
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6903855552798823
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6901906022429466
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900139456703549
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6898636853153055
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6897393579068392
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.689612603187561
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6894910209178925
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6893955226127918
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.689293423626158
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892149067350797
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891175122096621
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6890420279900233
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6889705657958984
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889023711904884
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.688834607781786
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6887689876205781
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887076006616865
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886588368150923
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886048750297443
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6885527998209
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885133556830577
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.6884730604290962
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884442973427656
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884137745414461
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.688379009379897
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883400284431197
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6883044796519809
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.688276607186898
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882394684121964
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.688208560521404
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.688180947303772
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881469434499741
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.688114322868048
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6880926839434184
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880739137811481
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880378458234999
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880151962150227
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6879919858915465

 End of epoch: 76 | Train Loss: 0.6867681734329831 | Training Time: 91 

 End of epoch: 76 | Eval Loss: 0.6900618757520404 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7556149303913117
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7209534198045731
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7094894786675771
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7037104845046998
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7003079342842102
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6980350385109584
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6964144698211125
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6952223874628544
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6942583633793725
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6935076296329499
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6928688244386153
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.692386357486248
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6919939724298624
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6916243433952332
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6913203756014507
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910293098539114
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6907681910430684
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905425253841612
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6903407551740345
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6901733812689781
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.690010256426675
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6898765431209044
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897588939770408
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.689648249745369
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895293800830841
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894173207191321
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893183677284805
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892340574945722
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891478824204412
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890545904636383
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889697990109843
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6888996694236994
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.688852919773622
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6887969756827635
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887362784998757
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6886885787049929
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886425129465155
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6885906642989108
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885507487333737
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6885072410106658
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884734355821842
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884382415385474
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6884009698102641
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883659240874377
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.688314940267139
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.688281238467797
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882435077048362
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.688221455241243
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881872739110674
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881623394489288
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.6881297962338316
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6881084452454861
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.688085845843801
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880566333179121
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880254578590393
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6880037373730115

 End of epoch: 77 | Train Loss: 0.6867781430219126 | Training Time: 91 

 End of epoch: 77 | Eval Loss: 0.6899551578930446 | Evaluating Time: 5 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.755627965927124
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7212635815143585
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.709803295135498
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7041527733206749
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7006364572048187
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6983429610729217
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6966505408287048
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.695409395545721
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.694432172510359
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6937453812360763
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6930889633568851
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6925856962800025
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6921610043599056
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6917608542101724
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6914406577746074
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6911561869084835
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6909062771236195
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6906694034735362
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904670536518097
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6902784317731857
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6901003000282105
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.689937130429528
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.689792214528374
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896562380095322
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895371661186218
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6894255232352476
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893182533758658
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892214098146984
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891305734371317
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890404556194941
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889661335176037
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6888945046812296
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888266751260469
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6887761987307492
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887227041380746
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886615393890275
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886065745675886
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6885596212587859
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885110757289788
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6884633059799671
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884294677071455
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6883916805187861
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883574828158977
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883218288421631
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6882962229516771
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882599587025849
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882248042745793
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882006338487069
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881773022972808
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881507103443145
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881214002768199
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6880986836094123
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880776909162414
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880491716994179
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880261344259435
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6879998791430678

 End of epoch: 78 | Train Loss: 0.686775024591294 | Training Time: 90 

 End of epoch: 78 | Eval Loss: 0.6896303636687142 | Evaluating Time: 6 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.7553422272205352
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7210770428180695
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7098393301169078
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7040285557508469
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7006119608879089
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6983133107423782
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6966744269643511
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6954234585165977
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6944609423478444
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6937189644575119
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930709026076577
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925814857085546
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6921176126370063
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6917480992419379
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6914174242814382
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6911338590085506
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6908955812454224
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.690682672129737
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6904740760200903
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6903047981858254
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6901427544298626
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6899816187945279
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6898299823636594
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6897156784931818
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6895774321556092
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6894623472140385
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893523244946091
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892481390919004
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891678865613609
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890908070405324
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890117649109133
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889502754434943
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.688882234060403
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888354343526504
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887542634350913
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.688707881172498
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886537365011267
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6886136180476139
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885553543384259
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6885088078677655
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.688466329109378
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6884227708691643
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883782044399617
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883434454148466
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6883058994346195
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882710279329963
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882402957753933
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882111681004365
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881775065344207
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881498430967331
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881203694670808
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6880914392379615
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880653854810966
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880379558713348
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880196039243178
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6879943858299936

 End of epoch: 79 | Train Loss: 0.6867712597931381 | Training Time: 89 

 End of epoch: 79 | Eval Loss: 0.6894160679408482 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7556188941001892
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7214201837778091
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7098227918148041
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7038941577076911
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7004854595661163
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6982405364513398
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6965552287442344
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.695255360007286
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6943363547325134
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.693613560795784
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6929943046786569
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6924961452682813
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6920684415560502
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6917170452220099
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6913648188114166
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6910679340362549
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908073674230014
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.6906035979588826
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.690415986274418
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6902349108457565
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900351319994246
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6898717752911828
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897407956745314
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896025493741036
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6894888265132904
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6893907393400486
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6893087239177139
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6892198877675193
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891337530366306
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890504600604376
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889700560800491
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6888811016455293
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888244973890709
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6887751985998715
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887279030254909
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6886790388160282
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886238259238165
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6885803100309874
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688538366709
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884851330518722
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884378280581498
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6883884192932219
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883547120316084
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883306816220284
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882932715945773
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882490529962207
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.688229243806068
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882099329183499
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881805074458219
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881468360424041
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881243629782807
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880962273249259
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.688072820429532
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.688049551182323
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880174422264099
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879891267844609

 End of epoch: 80 | Train Loss: 0.6867678961922637 | Training Time: 89 

 End of epoch: 80 | Eval Loss: 0.6898485507283892 | Evaluating Time: 5 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7551885366439819
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7210404604673386
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7095882177352906
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7038737878203392
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.700423287153244
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.698234365383784
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6965465767042978
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6953247264027596
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6943429787953694
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6935599851608276
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6929676142605868
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6924681926767031
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6920523336300484
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.691656563111714
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913302075862885
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6910710271447897
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6908178318949306
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6906119260523055
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6904127237043882
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6902348998188973
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6900824944178263
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6899385219270533
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.689792802800303
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6896760406593482
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895500271320343
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894448821361249
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893279861520838
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892293561782156
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891406782742204
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890596908330917
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6889943624696424
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.688928035274148
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888645255204403
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6888054849470363
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887566719736372
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6887051221397188
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.688658056065843
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.68861369835703
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885621796815823
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6885077847540378
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884586811065674
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884143623567763
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883949436420618
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883570501750166
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6883187589380476
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882839303949605
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882481029693116
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6882144699494044
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.688181527901669
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881526848077774
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881244075064565
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6880975531843992
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880779547511406
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880552089876599
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880345702171325
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6880103117653302

 End of epoch: 81 | Train Loss: 0.6867877958095179 | Training Time: 87 

 End of epoch: 81 | Eval Loss: 0.6900779604911804 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7556040704250335
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7212422758340835
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7097979565461476
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7039079308509827
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.700543532371521
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.698302627603213
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.696673777273723
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6954077482223511
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6944325559669071
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6936888253688812
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6930739744143053
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925404757261276
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6920786587091593
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6916627705097198
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6913451723257701
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6910992283374071
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908551556222579
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906208359532886
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904138919554259
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902018886804581
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6900501387459891
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.689910872686993
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6897718629111415
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6896418573955695
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6895238077640533
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6894344598054886
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6893205558812177
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892393808279719
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6891712801209812
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6891003354390463
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890090936614621
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889512294903397
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888807294946728
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888144803397795
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6887446701526642
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6886937838461664
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886515888007911
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6886069487584264
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885599513848623
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6885138437151909
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884671180713468
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884251043910072
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883903051531592
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883569182320075
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.688308291832606
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882789464100547
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882533039184326
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882135053475698
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881820849009923
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881601175069809
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881318724622913
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880909069226339
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.688068937693002
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880389676049904
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880170978199351
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6879958068685872

 End of epoch: 82 | Train Loss: 0.6867746592622943 | Training Time: 89 

 End of epoch: 82 | Eval Loss: 0.6895842722484044 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7552115797996521
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7211694240570068
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7095395565032959
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7038266852498054
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004783749580383
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6980926722288132
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6965373754501343
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6952854670584202
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6943585945500268
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6936347037553787
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6930156734856692
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6924911345044772
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6920692494282356
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6916940821068628
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6913702321052552
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6910935945808887
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.690807580947876
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905819353130128
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.690399538215838
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6902293974161148
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900701318468366
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6899290092966773
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897883241591246
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896586579581102
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895296630859375
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894340703120598
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.6893212172720168
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892351161156381
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.689143410427817
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890642293294271
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889978993323541
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889245143160224
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888507382436232
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.688799053605865
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.688740416765213
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.688684211505784
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886364074977669
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885805473515861
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.688528692875153
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6884907709062099
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884613413636277
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884262434073857
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883917976257413
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.688357813520865
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883257451322343
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6883061167986496
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882648532694958
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6882380058368047
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6882016562685674
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881800309419632
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881498459507437
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.688119427401286
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880895409943922
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880540665653017
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880190180648457
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6879939277257238

 End of epoch: 83 | Train Loss: 0.6867669088650594 | Training Time: 89 

 End of epoch: 83 | Eval Loss: 0.6896740623882839 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7556166529655457
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7210541516542435
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7095176557699839
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7038039118051529
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7003838658332825
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6981344660123189
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6965010362012046
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6952977441251278
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6943553725878397
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.69359304189682
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6929606155915694
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6924814696113268
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920213075784537
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6916499116591045
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913282144069671
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6910435047000647
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6908068881315343
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6905818657742606
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6903879491906417
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6902164950966835
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6900555244513921
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899126277728515
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6897934239843617
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6896619481345018
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6895401923656463
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894391144697483
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6893486777941386
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.689250873029232
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6891685596827803
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890802552302678
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.688997055638221
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6889385893940926
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888745179682066
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6888157511458678
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887472632953099
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6887020587921142
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6886517864626807
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6886042651377227
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885746156558012
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.688532537817955
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884923583123742
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6884438511871156
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6884034036203872
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883665357123722
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6883272449175517
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882948671994003
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882598813543929
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882257246722777
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881966854844774
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881563041210175
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881295069759967
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6881057506570449
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880765505556791
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880510327992616
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.688027688481591
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6880017775510039

 End of epoch: 84 | Train Loss: 0.6867711746587163 | Training Time: 91 

 End of epoch: 84 | Eval Loss: 0.6896306276321411 | Evaluating Time: 5 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7554255306720734
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.7212736368179321
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7097462733586629
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7039327770471573
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.700527333021164
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.698226218422254
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6965032747813633
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6953024663031101
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6943853225972917
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6936326116323471
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6930137926881964
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6924808179338773
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6920349299907684
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6916626870632172
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913623543580373
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.691059210523963
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6907913712894216
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.690569179587894
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903452070135819
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6901733151078224
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900108297665913
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898531312292272
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6897141145623249
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6895781603952249
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6894820704460144
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893749743700027
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892728032889189
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6892055334789412
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6891290448862931
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6890657035509745
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889957158796249
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6889219833537936
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.688861242388234
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887979854555691
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887392476626805
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886908036139276
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6886403531641574
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.688573335503277
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885259233988248
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884897278249263
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884619273790499
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6884331006379355
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.688388676144356
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.688348824056712
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6883150071567959
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882782029068988
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882416290171602
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6882078353315592
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881713402514555
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881389948129654
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6881093977713117
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880843258821048
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.688062048520682
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880349725484848
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880112746628848
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.687987389096192

 End of epoch: 85 | Train Loss: 0.6867593463543242 | Training Time: 90 

 End of epoch: 85 | Eval Loss: 0.6901721273149762 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7555105090141296
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7211210459470749
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7096475780010223
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7039328411221504
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7004527735710144
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6981556177139282
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.696530647788729
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6952949002385139
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6943415959676107
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6935685956478119
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929280438206412
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6924097677071889
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6919729296977704
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916024765798023
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6912927961349488
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6909997425973415
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6907744975651011
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905423700809479
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903584618317453
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6901692959666252
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900096941561926
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898628256537698
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897375907586969
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.689618198076884
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6895059690475464
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6894094198942184
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893053697215186
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.689213333598205
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891327551726637
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.6890504785378774
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.688991444149325
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6889249296858907
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888668463085637
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6888084329226438
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887500851494925
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886987696091335
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886467395602046
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885950232806959
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885403017203013
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884999498724937
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884625472673556
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6884203084877559
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883706683336303
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883337163112381
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882864174577925
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882569741943608
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882257504666105
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6881858136504888
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881521363647617
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881230832338333
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881036761929007
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880780408015618
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880585204880193
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880403640093626
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880123828757893
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879862621426582

 End of epoch: 86 | Train Loss: 0.6867581496196511 | Training Time: 88 

 End of epoch: 86 | Eval Loss: 0.6900974001203265 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7557930171489715
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.721151602268219
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7096902132034302
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040624141693115
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7006509959697723
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6983184158802033
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6966734979833875
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.695391871035099
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6944056789080302
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6936649405956268
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6930224418640136
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6924726878603299
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920623352894416
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6916665068694523
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913652805487315
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6910789866000414
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6908523857593536
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.690617103377978
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.690420834327999
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6902344444394112
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900424747239976
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6898938271132382
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897570410500402
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896346511940161
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895176086425782
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894157668718925
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893180509408315
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892368337937764
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891494993505807
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890640972057979
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889984023186468
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.688941509462893
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888904551664988
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6888301193714141
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887628102302551
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6887050378653738
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886376617728053
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885908015464481
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.688538411183235
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884970983862877
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884563510010883
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6884174696036748
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883855715740559
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883442709391767
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6883083890544044
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882700445859329
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882365156995489
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6882046962777774
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881747886842611
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881433103084564
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881138480177112
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880876099834076
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880597233772278
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880360661833375
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880043874003671
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879857946719442

 End of epoch: 87 | Train Loss: 0.686756400513438 | Training Time: 90 

 End of epoch: 87 | Eval Loss: 0.6893535000937325 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7555250585079193
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7210504561662674
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7096423586209615
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7038143575191498
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7003822553157807
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6980698317289352
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6964835550103868
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.69526307284832
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6942789852619171
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6935643601417542
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6929625110192732
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6924313535292943
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920384934315315
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.691642735685621
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913026376565298
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910305682569742
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6908021155525657
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905676434437434
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6903863351596029
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6902093243598938
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900331329731714
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6898644991896369
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897137636723726
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6895759319265683
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6894553179740905
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6893658956656089
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6892608406367126
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6891797338213239
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6890897880340444
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.68901194135348
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889556413696658
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6888985281810165
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.688806679573926
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6887502363499474
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.688688439301082
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886339012119506
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6885822721429773
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885295687537444
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6884885020745106
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6884440815448761
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884118216793712
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6883706581024897
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883510238902514
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883102788166566
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882738445864783
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882453242073888
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882160208326705
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6881855300317208
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6881506534255281
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881216077804565
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6880947795568728
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.688075873026481
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880464502100675
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880240204157653
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880062504248186
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879853686051709

 End of epoch: 88 | Train Loss: 0.6867579815662013 | Training Time: 88 

 End of epoch: 88 | Eval Loss: 0.6898803966385978 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7550872802734375
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7211064130067826
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7096893668174744
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7038929417729378
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7003636193275452
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6980833192666371
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6964656932013376
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6952434360980988
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.6942671557267507
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6935699373483658
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6929692327976227
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6924425954620044
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6920092353454003
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6916555396148136
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913407444953918
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910461444407702
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6907568777308745
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.690535803967052
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903284797542973
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6901253440976143
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6899707314513979
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6898055797273462
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6896868145984152
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6895538814365864
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6894337003231048
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.689337668969081
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6892423543665144
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.689147785944598
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6890735987959237
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6890184930960337
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.688936476361367
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6888713592663407
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888233152302828
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6887537111254299
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6886901295185089
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6886260832349459
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6885778420680279
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6885340638850864
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6884988012986305
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6884500721096992
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884021628193739
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6883573781876337
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883220028045566
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6882698519663377
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6882353868749407
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6881992588872495
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6881709557898501
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6881542896231015
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881317193410834
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881065618991852
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6880847538218778
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880634244817954
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880442229082
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880262186129887
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880068100582469
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879898847213813

 End of epoch: 89 | Train Loss: 0.6867641434205317 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6900617906025478 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.755275547504425
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7210438102483749
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7095818122227987
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7036997139453888
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7003063142299653
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6980783730745316
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6964786376271929
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6952793709933758
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6942916108502282
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6935621517896652
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929439680142836
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6924508839845658
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.692010693366711
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.691619331070355
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6912772826353709
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910531714558601
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.6908277634312124
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905967351463106
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903769364482478
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6901829445362091
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6900254218351274
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6898823193528435
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6897347719773003
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6896060648063819
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6895200641155242
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6894079737938368
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.689319853870957
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.689222143803324
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6891257707414956
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890342011054357
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.688958788687183
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6888902626931668
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888309359550476
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.688786136578111
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6887352739061628
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6886722422308392
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886192776061393
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885661321251015
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6885168587550139
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884702634811402
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884282064147111
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6884054677827017
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883633433386337
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883285680955107
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882899718814426
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882607782664506
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882359026594365
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6882036509613196
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881838068670156
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881628623008728
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6881358650385164
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6881080662974944
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880846010064179
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.688056551527094
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880304211919958
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879962597574506

 End of epoch: 90 | Train Loss: 0.6867649345271355 | Training Time: 90 

 End of epoch: 90 | Eval Loss: 0.6896320411137172 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7559821665287018
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7214067161083222
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7099980513254801
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7040644630789756
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7006262183189392
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6983366231123607
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.696621915272304
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6954762384295463
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6944992767439948
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6937737035751342
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6931138981472362
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6926017522811889
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6921694031128517
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6917969818626132
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6914853501319885
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6912048894912004
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6909208248643314
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6906958318418926
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6904709179150431
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6902722352743149
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6901004013561067
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6899403959512711
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897890648116236
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896519976357619
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.689549200296402
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894451152819854
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893479371512378
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892552150147302
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.689173463295246
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890930553277334
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6890163258198769
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6889310050755739
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888674152619911
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887928913621342
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887416372980391
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886879507038328
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6886424929709047
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885984060011412
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885447289699164
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6885109797120095
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884611658933686
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6884231631244931
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.688388393091601
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883414259011095
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882920365863376
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882643754067628
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.688233745098114
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881935617576043
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.688160208536654
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881338398456573
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881147953809477
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.688084906568894
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880574488414908
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880319170377872
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880032994530417
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879831342824868

 End of epoch: 91 | Train Loss: 0.6867606495333984 | Training Time: 92 

 End of epoch: 91 | Eval Loss: 0.6895266090120588 | Evaluating Time: 5 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7551756918430328
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7209422379732132
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.709577868382136
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7037971988320351
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7004478096961975
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6981673608223598
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.696574308191027
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.695363012701273
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6944458696577284
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.693646582365036
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930174632505937
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6925149028499921
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6920804738998413
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.69170515196664
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913573972384135
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6910960916429758
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908316528095918
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6905868987242381
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6903692970150396
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.6901809003949165
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6900174719946724
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6898722851818259
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897393428761026
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896125875413418
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6894868078231812
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6893776911955614
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6892676666930869
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891843118837901
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.689107923672117
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890231037139892
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889427525381888
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888794539496302
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888138845111385
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.688751128841849
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6886940607002803
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886449643307262
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6885959169349155
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.688541377688709
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6885028686278906
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884586089849472
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884147404170617
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.688372738588424
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.688341703109963
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6883161161433566
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882841845353445
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.68824904859066
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882191330828565
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.68819283892711
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881679223508251
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.688133557677269
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881050165961771
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880884723021434
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880707758777547
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880415349094956
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880157695033333
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879882248384612

 End of epoch: 92 | Train Loss: 0.6867549378260047 | Training Time: 91 

 End of epoch: 92 | Eval Loss: 0.6904577272278922 | Evaluating Time: 6 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7550451099872589
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.721081456542015
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.709657096862793
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7039612844586373
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7005567669868469
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6982656796773274
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6966497208390917
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6954272568225861
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6944529639350043
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6936525005102158
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6930341725999659
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6925162573655447
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6920761580650623
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6917331597634724
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6913819189866384
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6910952303558588
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6908575029934154
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6906383368704054
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6904440616306505
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6902733242511749
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6901207685470581
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6899679801680825
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6898290649704312
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6897141754627227
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6895991661548615
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6895037238414471
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6894122710934392
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.689326773583889
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6892447233200073
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6891742698351542
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6890977724905937
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.689017491787672
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6889443952025789
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.6888797390110353
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887985164778573
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6887418669131067
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6886829838559434
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6886233522703773
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885812938213348
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6885313926637173
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884876890880306
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6884513379562469
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6884185517943182
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883809105916456
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6883373810185327
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882999624895013
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882746943768034
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6882414532204469
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6882113667166962
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881883422136307
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881498614947001
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6881162990744297
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880846869270757
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.688059757594709
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880322127992456
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6880022881286485

 End of epoch: 93 | Train Loss: 0.6867776202944528 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.6900836569922311 | Evaluating Time: 5 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7555022716522217
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7213221102952957
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7098109106222789
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7039798483252525
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7005524885654449
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6983016431331635
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6967049726418086
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6954948991537094
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6945704228348202
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6937863528728485
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.693133317340504
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6925717934966087
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6921090900897979
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.691739468063627
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6914126853148143
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6911076053977012
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6908564984798431
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6906554347938961
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6904695909274252
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6902832141518593
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6900878034886859
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6899211357940327
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.689778925543246
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6896655057867368
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6895528428554535
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6894426393967409
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6893482676258793
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6892534866929054
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891563131891448
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890551104148229
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889798129758528
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6889110144227744
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888495622259198
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887630380251828
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6887056914397648
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886399037308163
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6885940608140585
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885560100015841
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885018961551862
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884605023264885
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884303068242422
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883969501370475
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883682031964147
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883393123745918
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6883082740836673
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882612120846043
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882342935876643
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6882099973658721
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881765269503302
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881387642621994
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881130001124214
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880884661124302
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880514702706967
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880325609887088
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880050222440199
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879820264875889

 End of epoch: 94 | Train Loss: 0.6867540773037261 | Training Time: 89 

 End of epoch: 94 | Eval Loss: 0.6896012425422668 | Evaluating Time: 6 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.75557382106781
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7209166914224625
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7095124284426372
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7039128184318543
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7005399906635285
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6982318103313446
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6966467891420637
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6954178236424923
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6944180289904277
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6936205130815506
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929383077404716
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.692431045571963
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6920164387959701
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916432035820824
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913155086835225
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.690991972386837
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6907634671996622
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905476308531231
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6903268287056371
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6901506525278092
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6899921536445618
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.6898390683260831
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6897071001322373
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6895757965743542
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6894576752185821
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.689346321271016
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6892393717059383
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6891573312027114
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6890689551830291
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6889937577644983
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889253231786913
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888537796214222
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6887829115896514
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.688721071621951
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6886627851213728
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886013681689899
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6885498178971781
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885032001294588
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6884684058336111
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884328965842724
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6883956864112761
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883396967535927
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.688291862953541
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6882662939754399
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882420276270972
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882154815870782
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.688191421108043
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6881695862859487
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.688144253589669
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.688115963101387
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6880982761289559
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880797540912261
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880532272581784
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.688023677137163
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6879988104646856
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879806367414338

 End of epoch: 95 | Train Loss: 0.686749044667303 | Training Time: 88 

 End of epoch: 95 | Eval Loss: 0.689849887575422 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7550900995731353
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7209960013628006
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7096762835979462
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7039854288101196
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7005768036842346
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6982334136962891
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6966142875807626
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6953376993536949
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6943535599443648
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6936068224906922
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6929967717690901
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6925066684683164
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6920589194847987
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6916504472494125
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.691310144662857
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910206638276577
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907661381889793
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.690533235669136
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6903375857754758
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901676443219185
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6900173053854988
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898576817729256
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.6897305359011111
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6896311623354753
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6895054450035095
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6893974421116021
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6893128247172744
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6892104317034994
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6891495862911488
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890621624390284
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6889857847844401
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6889188533648849
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.688850831082373
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6887856076745426
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887251719406673
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886547803878784
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886147392762674
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885567423544432
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.688504948371496
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884434548020363
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884037767968527
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883549071493603
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883212214292482
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.688292231072079
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882571154170566
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882264461206353
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6881946913739468
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881608286251625
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881357157716945
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881184695959092
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880959107595331
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880740147370559
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880437838581374
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880193048053318
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880009228532965
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879832348653249

 End of epoch: 96 | Train Loss: 0.6867479856035351 | Training Time: 89 

 End of epoch: 96 | Eval Loss: 0.6892301780836922 | Evaluating Time: 6 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7552567899227143
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7212203592061996
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7095985233783721
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7038960948586463
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7004716622829438
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.698160645365715
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6964902068887439
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6952497474849224
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6943444159295824
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6936240440607071
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929982868107882
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924749736984571
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6920382307125972
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.691675745163645
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6913507378101349
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910667087882757
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6908402975867777
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6905844430128734
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903895390661139
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6902221849560738
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6900454614843641
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6899055136875673
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.689741896805556
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6896270823975404
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.689502947807312
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6893990654211778
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6893085517265178
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.689214280460562
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.689124667850034
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890559055407842
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889787766241258
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6889184147119523
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888536512851715
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.688779992741697
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.688707263810294
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.688647388584084
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886034303420299
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885648766630574
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.688515461408175
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884701170027256
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884320815888847
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6884001839728583
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883691577024238
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883453450419686
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.688306331369612
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882671562225923
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882384491727708
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6882065073897441
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881648080689566
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881325985193253
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881148804636562
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880839629815175
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880679100189568
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880455530352063
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6880227877876975
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879976600408554

 End of epoch: 97 | Train Loss: 0.6867686553338987 | Training Time: 89 

 End of epoch: 97 | Eval Loss: 0.6901637996946063 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7550295352935791
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7207771599292755
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7093991080919901
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7037880018353462
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7004884850978851
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6981979648272196
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6964974003178733
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6953006841242313
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943361269103157
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6936132818460464
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6929794961755926
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6924373616774877
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6919793349045974
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6915992838995797
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.6912866655985515
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6909944839775563
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6907166579190422
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6904905603991615
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6903086822283896
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6901199707388878
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6899579235485622
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6898085290735418
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6896882992723714
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6895674655834834
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6894540221691131
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6893441220888725
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6892487932134558
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6891498729586601
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6890542126935104
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6889588993787765
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6888917584573069
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6888235067948699
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6887579954031742
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887063303414513
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6886747455596924
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886235824889607
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6885745986087902
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885259021269647
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6884782259280865
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884452828764915
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.688404657055692
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883622616529464
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883344141549842
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6883101166649298
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882715789477031
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882363920626433
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882063642461249
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881761220594247
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881493437046907
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881182355880737
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6880899526324926
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880590589000628
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880379515998768
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880188479467675
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6879968466541984
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879775933921337

 End of epoch: 98 | Train Loss: 0.6867497484240912 | Training Time: 90 

 End of epoch: 98 | Eval Loss: 0.6901132975305829 | Evaluating Time: 6 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7551017165184021
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7210064351558685
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7095337510108948
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7038898542523384
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7004914093017578
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.698169062534968
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.696527521099363
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6953055866062641
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6943127400345273
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.693576203584671
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930181633342396
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6924956540266672
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.692054576598681
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6916636547871998
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913203879197438
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910612676292658
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908340180621427
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6906151824527317
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.690411377894251
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.6902093595266342
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6900479711237408
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.689914679798213
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897733499174533
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6896363809704781
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6895136203765869
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893795240383882
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892827603552076
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.689185528244291
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.689113311315405
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890425292650858
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889786372261663
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6889013113453984
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888337310516472
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.688758154651698
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6886980055059706
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886390111512608
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6885853775449702
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885433713072224
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6884859807980366
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884536112844944
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884092566443653
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6883628339994521
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883318819278894
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6882961175658486
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882616682847341
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882297146579494
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.688200973323051
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881718158721923
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881458062298443
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881153693199158
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6880922816547693
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880632569010441
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880471988668981
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880204871848777
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6879999725385145
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879740557500295

 End of epoch: 99 | Train Loss: 0.686747331112887 | Training Time: 92 

 End of epoch: 99 | Eval Loss: 0.6898923005376544 | Evaluating Time: 5 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7555564939975739
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7210316002368927
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7096110244592031
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7038351505994797
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7004691779613494
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6981541891892751
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6965007143361228
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.695262897014618
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6943659755918715
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6935946208238601
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929861545562744
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6924778550863266
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920396635165581
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916756008352553
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913532988230388
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910738293081522
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6908196536933675
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6906018141243193
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903938911463084
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.690201610326767
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.690028965473175
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6898834884166718
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897572916486989
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6896340342859427
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6895203266143799
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.689415129331442
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6893139867870895
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6892345928720065
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6891393334701144
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890705398718516
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.688997995468878
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6889138925820589
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888477273059613
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6888065019074608
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6887571408067431
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6887110710144043
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6886535699303086
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.688597876617783
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6885551348710671
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.688512042015791
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884753688079555
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6884320760057085
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883761884168137
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883314629847354
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882939110861884
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882610923570135
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882296604044894
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881963882595301
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881611248668359
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881260645389556
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6880962894243352
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880734256826915
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880416295438443
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880187963997876
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6879927812923085
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879723878843443

 End of epoch: 100 | Train Loss: 0.6867473119128067 | Training Time: 89 

 End of epoch: 100 | Eval Loss: 0.6900606410843986 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9606406092643738 | Binary Cross Entropy With Logits Loss: 0.6892593417848859 
