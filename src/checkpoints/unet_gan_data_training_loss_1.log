Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7647403240203857
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7296474784612655
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.71783274213473
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7119836717844009
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7084154641628265
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7059788346290589
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7043033003807068
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7030167423188687
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7019840445783403
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7011906290054322
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7005125603892587
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.6998907878994942
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.6994068847252772
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6990204530102866
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.6986455674966177
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6982947506010533
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6979908662683824
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6977173258860906
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.6974598210108908
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6972352540493012
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.6970304421016148
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6968377140435306
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6966667201208032
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6964959467450778
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6963433427810669
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6962021609911552
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6960589821691866
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6959526477115495
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6958347863164441
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6957275170087814
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.695630552499525
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6955289656296373
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6954247940670361
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.69532071667559
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.695231455564499
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.695134967731105
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6950510461588164
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6949650477421911
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6948892183792896
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6948130613565445
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6947408001597335
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6946735008841469
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6946034457794455
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.6945331061428244
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6944696874088712
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6944016275198563
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.694335278805266
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6942763365805149
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.694218725695902
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6941550425291061
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6940905075447232
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6940419231469814
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6939814459602788
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.693929143194799
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.693867914243178
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6938192768820695

 End of epoch: 1 | Train Loss: 0.6925700123331188 | Training Time: 100 

 End of epoch: 1 | Eval Loss: 0.692736063684736 | Evaluating Time: 5 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.760215026140213
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7256724536418915
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7140964051087697
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.7083642661571503
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.704783684015274
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.702493088444074
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7008166406835828
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.6995762884616852
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.6985989941491021
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.697778627872467
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6971532111818141
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6965997457504273
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6961434676096989
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6957555200372424
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6954189554850261
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6951251994818449
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6948382237378289
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6945960859457652
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6943610426626707
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.6941574466228485
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6939887356190454
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6938171909614043
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6936690760695416
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6935589075088501
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6934276821613312
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6932900027586864
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.6931770530011919
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6930788817150252
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6929851153801228
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6928773719072342
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6927798405770332
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.6926931204274297
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6926082036711952
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6925322683418498
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6924542466231755
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6923922891418139
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6923121036709966
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6922544410354212
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6922000953784355
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6921442200243473
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6920869699338588
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6920449263992764
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6919881282850754
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6919368394396522
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6918885739644368
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6918481121892515
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6918064440818543
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6917645054558913
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6917251374040331
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.69168436896801
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6916528839691013
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6916078715370252
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6915634120410343
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6915259146028094
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6915011998740109
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6914735717432839

 End of epoch: 2 | Train Loss: 0.6902383933025124 | Training Time: 87 

 End of epoch: 2 | Eval Loss: 0.6916607362883431 | Evaluating Time: 5 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.758251017332077
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.723890870809555
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7122008919715881
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7065411314368248
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7032746911048889
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7009922941525777
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.6993601202964783
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6981170736253262
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6971682680977715
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6963954424858093
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6957730547948318
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6952589025100072
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6948337651216067
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6944568450961794
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6941342214743297
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.693851612880826
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6936084333588095
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6933461020390193
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6931550182794269
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6929746463894844
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6927946300733657
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6926352617415514
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6925036699875541
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6923564277589321
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6922293739318848
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.692111305319346
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6919952355049275
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6918843616332326
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6917949341494462
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.6917005695899328
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.691642035976533
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6915787171572447
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6914965374903246
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.691422751545906
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6913596088545663
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6913015806012683
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6912403312889306
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.6911832177325299
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6911256649555304
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.691068374812603
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6910276523450526
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6909814523799079
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6909370962963548
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.69089682942087
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.6908555461300744
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.690815265411916
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.6907660843210017
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6907270922015111
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6906897688398556
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.6906523344516754
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6906249103592891
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.690596613746423
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6905674783688671
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6905437527983277
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6905185734141956
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6904914685658046

 End of epoch: 3 | Train Loss: 0.6892554353823704 | Training Time: 89 

 End of epoch: 3 | Eval Loss: 0.6906631333487374 | Evaluating Time: 6 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7580491721630096
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7232569634914399
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.7118972778320313
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7062828063964843
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7028496468067169
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.7004471292098363
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6987804336207254
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6975032329559326
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.696582841873169
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.695816992521286
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6951969748193567
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.6946691185235977
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.6942136558202597
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.6938153914042882
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6934585670630137
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6931780103594065
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6929040421457852
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6926802251074049
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6924719408938759
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6922978511452675
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6921196531681787
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6919816019860181
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6918357152005901
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6917155424753825
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6916110033988953
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6914990739180491
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6913903190029992
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6912913443786758
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.6912056164494876
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6911255423227946
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6910590433305309
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6909772569313646
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6909086225610791
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6908380424275118
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6907714089325496
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6907198280096054
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6906757369234755
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6906072792253997
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.690567321349413
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.6905101689696312
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6904537110793881
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.6904056397222337
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.690364294966986
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.690319123999639
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6902747282716963
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.690241096071575
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6902017452615372
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6901638844360908
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.69012651589452
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.690083735704422
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6900502693419363
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6900241823150561
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6899975398801408
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6899806013813725
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6899531571431593
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6899240825857434

 End of epoch: 4 | Train Loss: 0.6886875886832718 | Training Time: 87 

 End of epoch: 4 | Eval Loss: 0.6908247981752668 | Evaluating Time: 6 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.7570937037467956
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7226996272802353
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7112990578015645
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7055283650755882
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7019867992401123
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.6997724205255509
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.698117310660226
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.696913442760706
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6959373414516449
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6952095514535904
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6945107758045197
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6940197497606277
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6935670297879439
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6931792540209634
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6928390455245972
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6925608493387699
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6923352059196023
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6921342627869712
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6919312317120402
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.6917432823777199
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6915727243536994
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6914300211451271
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6913049804127734
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6911716302235921
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6910560157299042
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6909509732173039
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6908472189196834
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6907551222613879
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6906672017327671
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6905872734387716
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6905039348909932
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6904327077791095
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6903731310006344
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6903023285024307
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6902406091349466
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6901763008700477
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6901228762961723
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6900838008052425
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6900396276742984
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6899888421595096
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.689944841803574
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6899068172488894
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6898597422034242
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6898244275288148
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6897875899738736
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6897407783114392
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.689709212678544
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6896785621841749
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6896410408068676
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6896071766614914
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6895802158935397
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6895517881099994
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6895232051048639
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6894891578842093
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6894730321927504
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.689450371584722

 End of epoch: 5 | Train Loss: 0.6882192845893117 | Training Time: 88 

 End of epoch: 5 | Eval Loss: 0.6908106122698102 | Evaluating Time: 6 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.756911301612854
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7224329501390457
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7110174636046092
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7053182303905488
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7018275058269501
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.699479674299558
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6977901484285082
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6966229103505611
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6956579724947611
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.6949048548936844
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.6943272888660431
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6937994529803594
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.693342819580665
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6929814811263766
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6926324538389842
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6923434719443321
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.6920718936359181
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.6918123516771528
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.691619000309392
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6914772430062294
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6912825575896672
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6911453658884222
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6910129720750062
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6908797527352969
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.690774482011795
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6906868214790638
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6905860759593823
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.6904911664979798
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.6903950816598432
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6903106532494228
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6902331198415449
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6901682583615184
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6901081692088734
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6900200849070268
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6899551217896598
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6898947834968567
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6898397682486354
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6898056552598351
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6897727082937192
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6897348816692829
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6896971455434474
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6896569863671348
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6896200566790824
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6895769797942856
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.689545409017139
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6895033255867337
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6894722431264025
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.689430923635761
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6894025777067457
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6893799333572388
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.6893534676701415
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.6893170895484778
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6892919253628209
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.689257025277173
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6892273195223375
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6892043820449284

 End of epoch: 6 | Train Loss: 0.6879735904457295 | Training Time: 88 

 End of epoch: 6 | Eval Loss: 0.6906091059957232 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7563679993152619
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7222846210002899
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7107614517211914
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7049622997641564
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7015294313430787
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6992396036783854
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6975870677403041
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6963274359703064
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6953609135415819
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.694582713842392
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6939802045171911
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6934737573067348
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6930867566512181
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6926941995109831
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6923809381326039
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.6920907124876976
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6918534538325142
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6916411578655243
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.6913997785041207
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6912334561347961
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6910366098086039
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6908829691735181
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6907484907171001
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6906155419846376
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6904878334999085
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.69036857348222
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6902566009097629
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.6901546207921846
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6900676762235576
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6899866861104965
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6899184088553152
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.6898533023893834
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6897940142588181
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.6897292473736931
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6896742045879364
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.689606652657191
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6895585662609822
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6895135333663539
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6894718000522027
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6894298723340034
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6893859662660738
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6893487217880431
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6893199181833932
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.689287778870626
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6892486931218041
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6892163066760354
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6891805010907194
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.6891557343304158
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6891308938970371
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6891029999256134
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.6890670889732884
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6890363960311963
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6890087956527494
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6889933548591755
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.6889721647175876
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6889539931501661

 End of epoch: 7 | Train Loss: 0.6877249315776656 | Training Time: 88 

 End of epoch: 7 | Eval Loss: 0.6901959436280387 | Evaluating Time: 6 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7566760897636413
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7220341861248016
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7104606846968333
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7047601833939552
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7012859725952149
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6989679525295893
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.6973466651780265
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6960927024483681
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.695143257247077
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.6943673503398895
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6937538808042353
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6932759985327721
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.6928058431698726
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6923967054912022
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6920774781703949
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6918138716369867
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.6915714207817526
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6913428061538273
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6911706215456912
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6909821650385857
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6908288731461479
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.6906987393444235
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6905459139658057
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.6904423020780086
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.690323352098465
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6902210758282588
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6901176896360185
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6900128832885197
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.689929893510095
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.6898546721537908
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6897880484980922
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6897297075018287
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6896607113607002
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.689598244954558
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6895258522033691
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6894705719417996
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6894190369425593
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6893658368211043
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6893205317167136
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6892621043324471
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6892315806412115
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6891988276016144
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6891635675762975
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6891191379590468
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6890857893890805
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.68905207151952
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6890168135470532
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6889819213499625
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.688950359334751
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.688923951268196
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6888915572680679
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.688865221463717
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6888377133405433
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6888100340410516
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6887854461236433
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6887659710432802

 End of epoch: 8 | Train Loss: 0.6875389868179254 | Training Time: 88 

 End of epoch: 8 | Eval Loss: 0.690473735332489 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7561474561691284
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7217829763889313
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7104177335898082
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7046668514609337
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7012222468852997
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6988585462172826
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6972382051604135
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.6960107818245888
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6950353622436524
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.694236730337143
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6936510893431577
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6930775706966718
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.6926708115981175
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6922802954912186
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.691933449904124
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6916523385792971
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6914153442663304
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6911967164940305
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.6910039779387023
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6908067479729653
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6906291127204895
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6904849236661738
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.690356166207272
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6902304194867611
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6901117844581603
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6900229903367849
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6899417643193846
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.6898461842111179
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.689778195989543
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.6897060749928157
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6896357107547022
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6895691737532615
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6895156867576367
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.6894516366369584
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6893885854312352
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6893488440248702
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.6892959652720271
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6892491607289565
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6892084477803646
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6891514831781387
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6891119461234023
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.689073124669847
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6890198175297227
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6889749705791474
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6889451889197031
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6889154756846635
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6888790787534511
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6888457330564658
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6888165813319537
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6887919828891754
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6887696975586461
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6887394913114034
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.688721465277222
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.688699961260513
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6886698628555644
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6886427817600114

 End of epoch: 9 | Train Loss: 0.6874146655597518 | Training Time: 89 

 End of epoch: 9 | Eval Loss: 0.6902152555329459 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7559642374515534
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7217380911111831
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7102865000565847
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7045137196779251
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7010338926315307
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6987148582935333
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.6971225040299552
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.6959257110953331
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6949398259321848
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6942263287305832
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.693630573424426
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6931086748838424
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6926802048316368
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6922876353774752
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6919650689760843
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6916595082730055
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6914146914201624
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6912014441357719
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6909772910569844
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6907801973819733
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6906288146972657
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6904709935188293
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6903378706911336
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6902172021567822
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.69010511136055
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.689996143258535
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.6898953587920578
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.689799430327756
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.689721589663933
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.6896508838733038
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6895767581078314
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.689510246925056
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6894341224973852
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6893631123444613
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893005653790065
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6892504885792732
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.6891937938896385
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6891450859998401
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891083721931164
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6890490421652794
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890101945981747
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6889711418322154
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6889330833457237
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6888990350744941
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6888709368970659
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888361127480217
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6887944132723707
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6887646015733481
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887302443689229
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.688703526377678
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6886782086363026
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6886542698511711
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.6886187499424197
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6885875226170929
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6885699392448772
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6885488820927483

 End of epoch: 10 | Train Loss: 0.6873236674123105 | Training Time: 90 

 End of epoch: 10 | Eval Loss: 0.6901685680661883 | Evaluating Time: 5 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7564164459705353
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.721923115849495
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7103395144144694
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7044554978609086
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7010650551319122
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6986969292163849
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.6970536495958056
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6957926258444787
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6948329634136624
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6940698444843292
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6934489152648232
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6929452270269394
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6924915863917425
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.6920887683119092
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6917844955126444
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6914869733154774
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.691251707427642
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6910353584422005
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6908518016338349
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6906718194484711
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6904968290101914
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6903478728099303
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6902249149654223
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6901047132909298
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6899831681251526
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6898707944613237
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6897814468101219
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.6897009591971125
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896080177405784
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6895289893945058
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6894615980886644
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6893965858966112
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6893331771547144
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.689271402183701
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892114814690181
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891375235385365
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6890861693266276
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890360680065657
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6889859806268643
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.688940201997757
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6888999616227499
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6888771863210769
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888493551764377
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888132421807809
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6887805782424079
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6887403201797734
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887147729701184
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6886688490708669
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6886393062922419
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886176661252975
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.6885885048146342
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6885590008818187
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6885377827680336
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885240857247953
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6884997342933308
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.6884694517723151

 End of epoch: 11 | Train Loss: 0.6872403337892178 | Training Time: 91 

 End of epoch: 11 | Eval Loss: 0.6896407093320575 | Evaluating Time: 5 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7560175001621247
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7215413361787796
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7100426574548085
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7042591273784637
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7008241784572601
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6986209223667781
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6969943531921932
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6956981539726257
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.6947170250945621
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6939479088783265
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6933757554401051
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6928977653384208
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.6924593246900118
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6920972236565182
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6917712966601054
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6914760351181031
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.6912342488765717
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910118599732716
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6908092467408431
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906319802999497
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6904636709463029
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903282612562179
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6901945593564407
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6900672607123852
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.6899468164443969
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6898325076470009
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6897462877962325
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6896555977208274
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6895648580172966
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6894879007339477
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894106145828001
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893485030159354
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6892807384332021
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892241490237853
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6891651964187622
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.689114673435688
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6890611759714178
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.6890150118815271
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6889587761499942
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889099045097828
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.6888771205413632
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6888334650368918
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.6887950524341229
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.6887532620267435
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887293377187517
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.68869601526986
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.68866101439963
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.6886286007861296
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6885989274297442
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6885636336803437
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6885424305410947
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885290798086386
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.688493697148449
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6884695490201315
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884430633891713
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.6884226532919067

 End of epoch: 12 | Train Loss: 0.6872000352471276 | Training Time: 90 

 End of epoch: 12 | Eval Loss: 0.690176682812827 | Evaluating Time: 5 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7556327819824219
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7212965518236161
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.7100188473860423
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7042831212282181
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7008105087280273
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.6985686997572581
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6969660980360849
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6957585997879505
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6947277863820394
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6939557921886444
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.6933107863772999
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.692828435699145
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6923674872288337
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6919752866029739
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6916552233695984
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6913677651435137
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6911542766234454
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909226142697864
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907165502247058
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905670109391212
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904143114884694
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6902688771486283
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901408716388371
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6899943977594376
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6898924553394318
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6897999426493278
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897223282743383
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.689617064169475
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895486136962627
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.6894630620876948
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6893977768959537
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6893158508464694
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6892343846234408
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6891742862322752
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6891091116837093
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6890573117468092
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6889998928920643
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.688952017614716
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6889228611420363
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6888650064170361
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888149857521058
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6887789155755725
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6887454053690267
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887061148881912
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6886748315228356
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.6886488165544427
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.688615760777859
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.6885863912602266
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885508133440602
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885239557027817
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6884991559327818
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6884803101420403
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.6884471766228946
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884188739237962
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6883917338197881
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6883620882672923

 End of epoch: 13 | Train Loss: 0.6871367331099721 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6896732023784092 | Evaluating Time: 4 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7558479368686676
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.721467399597168
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.7100509683291117
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7043266072869301
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.700918459892273
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6986846725145975
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6970054856368474
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.6957631051540375
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.6947731382317013
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6939849895238877
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6933992445468903
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928746710220973
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.692470246553421
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6921198219060898
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6918079221248626
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6915124800056219
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6912681348183576
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6910327967670229
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6908459522222218
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6906615918874741
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6904806443623134
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902977634559978
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.6901439174361851
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6899946935474872
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6898917109966278
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897680942828839
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896790246168772
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895787381700107
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894897662360092
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6894088502724965
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893198492065553
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892475483939051
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6891893390453223
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891384698012296
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890832524640219
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.6890385573108991
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889745829878626
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889257308683897
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888733226519365
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888366423547267
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887994742975002
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.688769102522305
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6887289079122765
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6887021139264107
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.6886679477161831
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6886398402245149
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6886059792751962
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885751329362393
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885489679112726
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6885200883150101
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884967382047691
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884725456054394
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884394078884485
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6884128662171187
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883873564546759
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.688361559169633

 End of epoch: 14 | Train Loss: 0.6871256091953379 | Training Time: 90 

 End of epoch: 14 | Eval Loss: 0.6903399910245623 | Evaluating Time: 5 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7561621904373169
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7212945729494095
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7100560188293457
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7043799430131912
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7009941422939301
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.6986422051986059
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6969877243041992
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6956814579665661
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.6947269519170125
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6939482843875885
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6933137888258154
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.6927867636084557
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923560665203975
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919873471770968
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916739471753438
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6914003871381282
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6911426919348099
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6909243583679199
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.690727258355994
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.690547451376915
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.6903752738521213
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6902288090098988
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900993212409642
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.689991903056701
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.689853176832199
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6897463152041802
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6896561662356059
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895580634474754
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894854210574052
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6893999232848486
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6893170812437611
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892367672175169
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891687839320212
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6890886492588941
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890176156588963
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6889522206452158
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.6888867737473668
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6888476225890612
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.6887848306924869
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6887333701550961
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6886858759856805
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6886560712541853
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886254138724749
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886018169197169
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6885637060801189
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.688544056467388
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885060192422664
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6884800336013238
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.688448207354059
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884189827442169
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884022322355532
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6883884577797009
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883639561680128
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883483291776092
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883289262381467
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883079775742122

 End of epoch: 15 | Train Loss: 0.6870796942077907 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.6898831469672067 | Evaluating Time: 5 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7559424340724945
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7214701473712921
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.71006254752477
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7043254375457764
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7009288311004639
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6986426264047623
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.6970007462160928
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6957284368574619
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6947670559088389
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.694032222032547
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6934064361182126
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6928507536649704
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.69238105737246
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6920027175119945
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6916643353303273
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.6913743034005165
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6911158449509565
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6908758209811316
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.69068712811721
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6905059084296227
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6903484225273132
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.6901691788976843
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.690032714864482
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6899021563430627
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6898028275966644
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6897042196530562
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.689592327232714
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.689494574708598
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6894112794563688
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6893304040034612
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6892610365344632
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6891976414248348
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.689156685814713
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891083964530159
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6890369251796178
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.68897548880842
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6889188945293426
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6888720219072543
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888143362143101
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6887526328861714
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.688708510486091
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.6886778336195719
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6886367610720701
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.688594735075127
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6885631859302521
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885398157264875
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885076683886507
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6884837837268909
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.6884450253175229
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884250319004059
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884021858374277
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883755648365387
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883522652230173
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883347541093826
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6883115450902418
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882951171270438

 End of epoch: 16 | Train Loss: 0.6870681400847646 | Training Time: 90 

 End of epoch: 16 | Eval Loss: 0.6903891137668065 | Evaluating Time: 5 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7558957636356354
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7216937392950058
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7102992157141368
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7046218186616897
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7009651958942413
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6987156420946121
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6970521501132421
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6957729838788509
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6947931905587514
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6939953446388245
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6933334648609162
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927925884723664
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923392887298877
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.69195294209889
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916102763017019
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.691309018433094
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.6910622007706586
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908594869905048
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.690658670350125
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904887786507606
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6903280014083499
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901732845739885
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6900213202704554
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6899057837824026
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6898041744232177
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.6896886974573135
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895954571388386
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6895112659249987
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894427605744066
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893464108308156
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892623099588578
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891975935548544
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.689124979575475
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.6890725176124012
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6890176260471343
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889680688579877
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6889281632126989
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.6888808477866022
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6888359305186149
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887885634601116
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6887495468302471
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886984065884636
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.6886645184006802
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6886316055601294
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885936644342211
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885528672000636
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6885175155832413
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.688493249192834
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6884527515391914
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6884236702919007
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883895385499094
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883644884595504
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883398738672148
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6883128587846403
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.68828733086586
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.688274599718196

 End of epoch: 17 | Train Loss: 0.6870479418113168 | Training Time: 88 

 End of epoch: 17 | Eval Loss: 0.6893659319196429 | Evaluating Time: 5 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.755594003200531
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7212516814470291
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7097836256027221
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7041095718741417
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7007791864871978
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6984492560227712
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6967882897172656
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.695553581416607
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.694668216837777
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6938314986228943
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.6932361933318052
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6926818440357844
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922415673732758
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6918582205261503
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915477172533671
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6912808272987604
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6910425378995784
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6908002588484022
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.690585111003173
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.6904058960080147
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902395132042113
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901104493574662
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6900014685547871
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.689864993840456
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897492415904999
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896429027502353
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895477456075174
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894711651972362
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893934893197027
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.689318468372027
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892414358354384
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891685055568815
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6891014456748963
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890452263986363
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889790647370475
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889295140902202
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888599086452175
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.6888104184677727
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887551810496892
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887052102386951
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6886566980582912
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886211328563236
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6885795797026435
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885469924319875
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885136328803169
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6884736856688624
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884395918947586
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884227217485507
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6883885153702327
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883618459701538
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883331294153251
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.688305113521906
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6882750803569577
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6882627154941912
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.6882391019300981
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882194284881864

 End of epoch: 18 | Train Loss: 0.6869951423290557 | Training Time: 89 

 End of epoch: 18 | Eval Loss: 0.6893929157938276 | Evaluating Time: 5 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7556959569454194
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7212247371673584
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.709803984562556
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7041005983948707
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7007253348827363
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6983201305071512
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6966904640197754
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6954628378152847
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6944766210185157
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6937437325716018
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6931622299281034
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6926307618618012
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6921843767166138
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.6918452590703964
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6914968931674957
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6911926493048668
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6909323832568001
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6907205531994501
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.690512570581938
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6903407824039459
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6901852471487863
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6900610140778801
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899190524350042
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6897866894801458
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.689670717716217
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6895619610181222
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.6894629858158253
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.6893653133085795
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.6892797472148106
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892106155554454
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6891444944566296
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.689085022173822
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890292640888329
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889847704592873
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6889397176674434
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888761656151877
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888175030012389
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887676657814729
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887157221635183
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.688673140257597
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886355022104775
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886003583669662
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885798353095387
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885438392108137
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885147443082598
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884909314953762
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.688464629650116
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884436886757612
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6884239421815288
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883941043615341
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883734277650422
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883300842000888
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882973762053364
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882719644793758
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.688247652053833
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882229134440422

 End of epoch: 19 | Train Loss: 0.6869977140848615 | Training Time: 90 

 End of epoch: 19 | Eval Loss: 0.6894553814615522 | Evaluating Time: 5 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.7560991168022155
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.72145274579525
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7100607713063558
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7042700484395027
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7007224607467651
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.6984913965066274
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6968524856226784
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6955984137952328
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6946093612247043
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6938926833868027
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.6932631779800762
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927515089511871
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922906898535215
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6919137993029185
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6915692102909088
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6912902720272541
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910225703435786
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6907846457428403
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6905818929797725
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6904023140668869
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.6902525214921861
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6900967486880042
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.6899552588877471
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898369461297988
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.689740654706955
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896359019554579
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895428655324158
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6894419853176389
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893466041005891
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892555610338846
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.6891744019523743
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891103504225612
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890464681567567
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6889922375188154
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889368508543287
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6888789769675997
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888241289435206
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6887682262219881
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887053660857372
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.6886616046726703
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886251452492504
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6885904813096637
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6885498886884645
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.688513485680927
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6884756265746222
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.6884477500034415
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.68841702215215
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6883773420006036
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883492923512751
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883296827077866
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.688304809144899
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6882741092489316
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882488408178653
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.688219287108492
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882037186622619
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.688186088843005

 End of epoch: 20 | Train Loss: 0.6869622568113614 | Training Time: 90 

 End of epoch: 20 | Eval Loss: 0.6897504755428859 | Evaluating Time: 5 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7558660745620728
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7214084386825561
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7099957784016927
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7041567847132683
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7006417500972748
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6983496258656184
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.6966931581497192
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6955124326050282
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6946079989274343
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6938461011648178
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.6932379484176636
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6927096595366796
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6922128617763519
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6918566516467504
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915461635589599
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6912460878491402
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910109737340142
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6907878544595506
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6906147181987763
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6904358917474747
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6902756415662311
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.6901280923323198
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6899908739587535
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898751648763816
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6897674181461334
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.689663655941303
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895558255690115
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.6894688774432455
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.689392290649743
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.6893095894654592
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6892304547371403
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891523208469152
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.689071450992064
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.6889920672949623
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.6889422304289682
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888858935899205
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888251726691788
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887801190740184
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887411079345606
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6887042057514191
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.688648396730423
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.6885987735929944
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885594768579616
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.6885100245475769
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6884707379341125
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884353175111438
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884050078848575
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6883785249044497
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883550624458157
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883283770084381
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883037101988699
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882743203869233
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882514309208349
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882219876404162
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882033816250888
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.6881895077015673

 End of epoch: 21 | Train Loss: 0.6869630765070958 | Training Time: 89 

 End of epoch: 21 | Eval Loss: 0.6896181787763324 | Evaluating Time: 5 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.7556451737880707
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7210832893848419
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7098066806793213
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7042240291833878
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.700800439119339
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.698552867770195
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6969424903392791
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6956967324018478
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6947149680720435
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.693932077884674
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.693272249807011
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6927164360880852
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.692310303908128
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6919322162866592
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915730877717337
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912707630544901
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6910115848569309
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907762908273273
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6905709050203624
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6903770619630814
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902116522902534
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6900639861822129
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899208294308704
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.689784137159586
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6896716225147247
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6895589337899135
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6894606762462192
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.689382771721908
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.6892916003177906
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6891995577017466
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6891229189211322
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.689052970893681
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6889845329703707
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6889160073855344
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6888733443192073
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6888245221641328
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6887727502230051
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887224860881505
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6886683017779619
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886248567700386
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6885790095096681
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885352299326942
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6884960066440493
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.688466890156269
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884323836697472
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884087333212728
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6883880742052768
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883689213544131
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883462495949804
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883215684890747
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6882978842538946
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882707623335031
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882410714086497
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882112962228281
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.688190264376727
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6881759232708387

 End of epoch: 22 | Train Loss: 0.6869486438489594 | Training Time: 89 

 End of epoch: 22 | Eval Loss: 0.6897583774157933 | Evaluating Time: 5 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7557319521903991
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7214877218008041
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.7099404394626617
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7040661036968231
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7006402385234832
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.698302561044693
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6966989764145443
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6954079069197178
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6944388780328963
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6936999493837357
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.6930581363764676
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6925563668211301
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.6920999600337102
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6917475083044597
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6914285822709402
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6911317400634289
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6908699642209446
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6906469182835685
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6904810582336627
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903279316425324
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.690182348943892
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.6900486374443228
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.6899259857509448
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.689812712619702
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6897088606357574
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6896074015360613
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6895020065484223
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6894252670662744
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.689346373697807
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892709203561147
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891910104982315
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6891228662803769
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890694255178625
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.6890074170687619
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889478586401259
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888868214355575
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6888357681197089
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887798091298656
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6887351616834982
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886921004951
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886457899721657
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6886146756864729
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885662354702173
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.688529814102433
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884980920950572
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884648722151051
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884406097391819
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.6884068309019009
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883765536911634
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883508749008179
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6883270249647253
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882935584737704
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882748310296041
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882551811359546
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6882238831303337
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6882019235619476

 End of epoch: 23 | Train Loss: 0.6869736041642923 | Training Time: 89 

 End of epoch: 23 | Eval Loss: 0.690197331564767 | Evaluating Time: 5 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.755318146944046
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7211176723241806
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7097176253795624
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7039692044258118
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.700563782453537
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.698217049241066
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6965308776923589
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6953603692352772
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6943600436051687
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.693573003411293
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.692997338555076
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6925008709232012
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.692101188806387
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6917478365557534
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6914303807417551
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6911559324711561
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6909147437881021
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6906881418493059
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6904960823686499
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6903228133916854
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.690181576354163
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6900223512541164
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899147147717684
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6898071524997552
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.6896844000816346
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6895611260945981
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6894624805008923
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.689376818708011
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6892936959348875
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892200098435084
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891575307615342
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6890915423631668
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890372110135627
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889814438188777
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6889284019810813
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888656778468026
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888192924293312
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.6887777565341247
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887319988165146
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.6886871126294136
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886435380796107
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6886120255504335
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.6885778014049974
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6885468436913057
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6885157529513041
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884770222332166
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.688433605939784
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6884042193492254
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.68837589913485
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883535268306732
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6883221629787893
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882944094446989
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.688267412613023
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882387968125167
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6882081730799241
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881858113620962

 End of epoch: 24 | Train Loss: 0.686961003214912 | Training Time: 90 

 End of epoch: 24 | Eval Loss: 0.6899683049746922 | Evaluating Time: 5 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7554007112979889
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7211654871702194
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7097300012906392
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7040342316031456
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7006146550178528
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6983221550782521
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6966962882450649
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6955393835902214
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946106692155202
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938520562648773
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.6932150450619784
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6927171960473061
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6923197457423577
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6919491818972996
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.691652045249939
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6913469448685646
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6910779300857993
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.690850156876776
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.6906368622654363
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6904966852068901
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6903246842679523
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6901524392041293
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6900127600068632
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6898745800058047
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6897582659721374
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6896444937357535
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6895349635018243
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6894442051649093
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6893702124727183
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6893103470404943
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6892418809475437
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6891774332150817
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6891189808195287
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.6890523587956148
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6889891302585602
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6889239567849371
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.6888719483001812
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6888221993258125
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6887654212804941
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6887191739678383
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6886726030489293
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6886201471090316
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885792895805004
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6885392424735156
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.6885006329748365
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884653522916462
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.6884314083038492
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883904449641705
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883645985807691
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6883353404998779
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6883129720594369
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882883805495043
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882547138996844
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6882313879551711
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.688203294060447
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881697637694223

 End of epoch: 25 | Train Loss: 0.6869416346592185 | Training Time: 90 

 End of epoch: 25 | Eval Loss: 0.6901038033621651 | Evaluating Time: 5 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7555442333221436
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7211133986711502
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7098818163077036
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7040878996253014
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7005821800231934
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6982951104640961
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6966990777424403
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.695503968000412
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6945847113927205
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6938072657585144
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.6931886678392237
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.6926417787869771
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6922301998505226
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6918605046612876
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6915319188435872
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.6912609878927469
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.691023304532556
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6908001588450537
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905927818072469
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6904228961467743
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6902698233014062
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.690140324831009
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6900212111680404
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6898849678536256
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6897611565589905
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6896399722649501
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6895358741283417
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6894543930888176
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6893779138038898
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6892803458372752
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6892095000513139
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6891341716051101
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6890600043715853
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889927225954392
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6889368283748627
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.6888855401012632
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6888294621093853
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6887796119639747
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.6887395774706816
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6886896656453609
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6886500591185035
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885983181851251
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6885563923869022
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6885174893520095
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884788624445597
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6884422735027645
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6884082189265718
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6883800234645605
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6883501262080912
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6883230226039887
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882884961717269
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882646349760202
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882363199063067
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6882051632360175
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.6881792356751182
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881620954189982

 End of epoch: 26 | Train Loss: 0.6869317461959029 | Training Time: 90 

 End of epoch: 26 | Eval Loss: 0.6896118351391384 | Evaluating Time: 5 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7556705176830292
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.721449026465416
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.7098175962766011
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.704094460606575
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7006928026676178
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.6984436591466268
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6967200228146144
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.695542249828577
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6945857326189677
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6938062316179275
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6931128258054907
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.6925852740804355
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6921507523610042
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.6917484027998788
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6914344171682993
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6911554452031851
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6908809788086835
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6906696849399143
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.690479783949099
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6902967727184296
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6901097686517806
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6899754410440272
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.6898304483164912
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6897082994381587
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.689603571653366
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895052841076484
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894012316509529
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893299958535604
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.6892533324915787
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.689187815785408
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891116374923337
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890524491667748
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6889942376902609
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889357147847905
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888885109765189
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888272672891617
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887772389360376
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.688727153445545
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886886994043986
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886492209136486
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6886128065062732
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885649671157201
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885264337062835
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884901061654091
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884539829360115
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884273320436478
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883966340663585
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883680431793133
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883440096767581
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6883133709430694
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882789677264644
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.6882541303451245
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.6882188561952339
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.6881853153308233
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881556819785725
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881285388554845

 End of epoch: 27 | Train Loss: 0.6869080156351612 | Training Time: 90 

 End of epoch: 27 | Eval Loss: 0.689648415361132 | Evaluating Time: 5 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7559132635593414
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7214606493711472
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.7099743982156118
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7041164621710777
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7006023764610291
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6983345379432042
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6967212992055075
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.695470429211855
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.6945080008771685
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937495315074921
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931567603891546
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.6926234210530917
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6921618168170636
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.6917641431093215
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6914660668373108
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6911829847842454
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909366972306196
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6906992607646518
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6904958461460314
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903082609176636
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901515642801921
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900140439922159
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6898828975532366
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897381616135438
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896196181774139
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895162976705111
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894303441047669
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893313063042504
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892589028539329
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6891844546794892
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891025508603742
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890279142186045
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.68897631854722
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889099450672374
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.6888585105964116
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888017629583677
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887616255798855
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887073883884831
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886637961253141
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.688619859367609
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.688573981203684
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.6885370078540983
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884897872459057
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884520452130924
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884124369091458
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6883746345405993
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883386072960306
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.688309171795845
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6882828206432109
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882634398937225
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882467264053869
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882323208909769
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6881988031684227
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.688173320779094
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.6881528815356168
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881334562386785

 End of epoch: 28 | Train Loss: 0.6869112718421801 | Training Time: 91 

 End of epoch: 28 | Eval Loss: 0.689838171005249 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.755761981010437
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7214317888021469
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.709935853878657
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7041148483753205
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7006858348846435
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6984398136536281
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6967223925249917
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6955078467726707
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6945831576983134
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6938606578111649
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6932434277100996
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6927184467514356
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6922692120075226
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6919024663312094
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6915474045276642
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6912636533379555
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6910354870207169
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6907985607782999
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6905877069423073
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6904152259230614
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6902370126474471
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6901013536886735
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6899610944416212
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6898407496511936
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6897371270656586
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6896271382386868
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6895206771515033
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6894076483590262
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6893196675284156
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6892447060346604
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6891671584498498
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890840174630284
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.689006715109854
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6889572536244112
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888928299290793
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6888222734133402
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887616196194211
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6887113869190216
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886732385708736
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6886398640275001
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885962003614844
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885516923098337
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6885184185449467
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884824747389013
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6884452329741584
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6884095269700755
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.688377157551177
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883495466162761
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6883221808744937
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882923399209976
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882620736664417
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882352812932088
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882095953203597
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.688181961024249
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881630252708089
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881369259740625

 End of epoch: 29 | Train Loss: 0.6869091925367845 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.6894544788769313 | Evaluating Time: 6 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7554361343383789
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7211988478899002
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7098762174447377
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.7040665984153748
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7006541168689728
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6984305689732234
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6967878792967115
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6956059947609902
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6946461253696018
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6938688266277313
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6932179017500444
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6927092745900154
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6922755365188306
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6918804943561554
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6915349666277567
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6912510082125664
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6909706666189082
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6907422102159924
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6905413103731055
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6903611901402473
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901955292338416
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6900343526493419
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.6898886633955914
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897630475461483
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896648912429809
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895598333615524
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894672983222537
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.689372370498521
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892937242984771
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6892144874731699
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891497269753487
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.689094627276063
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.6890127301216126
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.688946054612889
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888847536700112
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.688826598558161
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887744518550667
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6887275411894447
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.6886858860651652
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6886388985812664
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885947717399132
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885658119406018
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6885152701721635
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884693004868248
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.6884365804990132
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6884087522392688
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883747638540065
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883487685273091
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.6883235475238488
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882934365272522
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882684043809479
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882408644144352
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.688214010225152
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881917084808703
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881709303639152
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.6881424004478114

 End of epoch: 30 | Train Loss: 0.6869199248541773 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6900475365774972 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7554002285003663
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7210861444473267
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7098147730032603
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7041506707668305
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7006755411624909
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6983097900946935
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6966570360319955
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.695457749813795
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6945307870705922
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6937604171037673
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.6931505560874939
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6926561812559764
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6922260357783391
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6918853934322085
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6915576259295145
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6912789274007082
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6910592745332157
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6908354924784766
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6906328427164178
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6904848417639733
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6903017506712958
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6901595297184857
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6900072105552839
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.6898803862432639
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.689754558801651
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6896426673118885
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6895560489760505
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6894560473305839
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.6893684677008924
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6892938143014908
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.689222780735262
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6891483644023537
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6890756778644793
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6890114868388456
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6889559495449066
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6888956619633568
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6888258692380544
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887663122854735
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6887217683669848
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6886725676059723
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6886207446819399
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885923382781801
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6885543672151344
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6885094979947264
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884760046005249
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6884337689565576
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883985695686746
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883539249499638
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6883151060464431
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882761181592941
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882512777459387
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.6882208928465843
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.688198167535494
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881695649138203
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.688138423724608
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881158536033971

 End of epoch: 31 | Train Loss: 0.6868913499654922 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.6896753055708749 | Evaluating Time: 5 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7555253148078919
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7213091492652893
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7098614037036896
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7041706070303917
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7006154835224152
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6983181864023209
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6966548536505018
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6954307109117508
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6945040961106618
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937451875209808
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931101463057778
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926028549671173
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921411945269658
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6917859413794109
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.691443817615509
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911663915961981
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6909336780800539
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907080130444633
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905071145609806
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6903350976109505
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901721517244975
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6900318944996053
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898875145808511
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897646484275659
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896531648635864
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895491545016948
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894427756468455
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893545459423747
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892643092007472
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891910618543625
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6891152322292328
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890550058335065
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889948792529829
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6889374501564923
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888748604910714
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6888322282168601
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887759347219725
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6887288156308626
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.68868202597667
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.688626826107502
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885790041307124
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.6885382351421174
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6885044402854387
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884705836122686
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6884288744131724
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.6883929158034532
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.6883628696837324
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6883382711559534
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6883067724656086
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882748893499374
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882502258992662
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6882162842613
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881931908850399
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.688165330334946
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881391129710458
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881155418498176

 End of epoch: 32 | Train Loss: 0.6868914570428629 | Training Time: 88 

 End of epoch: 32 | Eval Loss: 0.6898758241108486 | Evaluating Time: 5 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7559028506278992
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7212137550115585
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.709669154882431
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7039491593837738
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.700461174249649
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.6982196946938832
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6965735648359571
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953822188079357
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6944136010275946
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6936943900585174
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.6931156537749551
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925799518823623
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.6921436318984399
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6917761687721525
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6914424669742584
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6911319304257632
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908793179427877
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6906623380051718
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904393487855007
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902571937441826
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6900993117264339
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6899519299918955
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6898233421470807
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6897019098202387
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.6895957934856415
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6895007254985662
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6893879897064633
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6892948612570763
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6892117037855345
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891249682505926
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890487743962196
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6889815226197242
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6889231185118357
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888670020243701
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6888239276409149
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.688788536687692
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887437931589178
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6886941171006152
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886456868587396
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885998265445232
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885604012303236
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885212312142054
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884847252867943
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884530675682154
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6884150735537211
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883786284405252
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.688355088614403
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883207619190216
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.688303344347039
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882860660552979
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882594032614839
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882257110797442
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881955630374404
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881737456277565
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881595897674561
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881270856729576

 End of epoch: 33 | Train Loss: 0.6869005715952511 | Training Time: 87 

 End of epoch: 33 | Eval Loss: 0.6895673700741359 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7551211595535279
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7210839658975601
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7096207857131958
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.703888151049614
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7004560494422912
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6982158571481705
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.6966595198426928
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.695449560880661
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6945220576392279
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937537604570388
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.693131743777882
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6925879190365474
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921227372609652
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917716660669871
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914492837587992
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911828428506851
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6909234902437995
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906795124212901
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.6904793886761916
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902765014767647
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901346870831081
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899914979934693
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.68984712595525
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6897074669599533
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6895785689353943
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6894907057285309
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6893993490272098
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6893033219235284
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.6892401514382198
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6891442553202312
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.689064916487663
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6890058329328894
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6889357429562193
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888750844142016
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6888238598619189
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887772048513094
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6887313944262428
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886885597517616
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886367310316135
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885956022143364
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885568881907114
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6885197402465911
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884816528752793
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884378549727527
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6884129436810812
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883880476588788
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.6883522655101533
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6883188425252835
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882889652738766
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.6882551494836807
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882245913440106
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6881988805073959
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.6881784717991667
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881534139315287
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.688129636591131
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880996208105769

 End of epoch: 34 | Train Loss: 0.6868720130582826 | Training Time: 90 

 End of epoch: 34 | Eval Loss: 0.6892958198274884 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7556459426879882
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7211818695068359
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7098715901374817
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7041324228048325
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7006450462341308
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6983120689789454
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6965908970151629
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6953516222536564
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6944154779116313
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6936563068628311
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6930612222714858
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6925276497999827
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6921140689116257
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6917583452803748
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914100495974222
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6911319274455309
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6908507452291601
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6906416366497675
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6904534684984307
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6902915239334106
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901397909436907
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900047746571627
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898551295632901
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897457900146643
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.689617048740387
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895144811043372
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894055883089701
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893226491553442
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892314847173362
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891611389319102
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.6890846460096298
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.68902931753546
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.6889742515303872
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6889237237327239
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888752365112305
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6888202605975999
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887690093066241
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6887257386195033
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886818462457412
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6886329312622547
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6886034981506627
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6885466700508481
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6885041067766589
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.6884581754153425
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.688421550989151
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883834517520407
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883477829872293
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6883127178996802
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882767053282991
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.6882499125003815
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882219972563725
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6882059646340517
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881806944901089
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.688158823163421
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881406031955373
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6881165949361665

 End of epoch: 35 | Train Loss: 0.6868891849982 | Training Time: 90 

 End of epoch: 35 | Eval Loss: 0.6899572355406625 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7549957156181335
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7211837559938431
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7097392797470092
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7041079744696617
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7006232297420502
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6983011990785599
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6967173048428127
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6954611361026763
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.6944868253337012
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6937358498573303
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6931519448757172
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6926466301083565
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921999747936542
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6918037440095629
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6914723678429922
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6911839731037617
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.690932764375911
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6907332718372345
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.6905334406777432
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6903220957517624
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6901577779224941
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6900189288637855
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6898807051389114
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6897631491223971
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6896489844322204
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6895266817166255
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894317278155574
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893630193812507
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6892737164579589
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6892005310455958
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6891322572385111
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6890458213165402
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889681326620507
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.6888986801399904
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6888387501239777
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887819561693403
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.688728784870457
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886689818219135
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6886122552248147
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885630805790425
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6885216285542743
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.6884785000767026
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6884335400060165
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6883956187150695
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6883694615628985
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6883392804342767
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6883089127692771
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882776775707801
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.688252305984497
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.6882177610397339
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.688188660846037
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881729333446576
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881467399732122
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881253126594755
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881092490933158
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880917598094259

 End of epoch: 36 | Train Loss: 0.6868661523920245 | Training Time: 89 

 End of epoch: 36 | Eval Loss: 0.6899925810950143 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7559174120426178
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7216542512178421
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.709926329056422
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7041736125946045
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.70067990899086
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6983045359452565
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.6966701345784324
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6954398855566979
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6944293532106611
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6936557620763779
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6930965981700203
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6926131159067154
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6921970463716067
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6918256704296385
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6914773984750112
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6912101466208697
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6909694419187657
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.690727620323499
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6905449945675699
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6903465569019318
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.6901909606797355
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6900372797792608
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6898911577204
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6897869529823463
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6896552515029907
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6895598778357872
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6894593909934715
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6893776580691338
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.689283685232031
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6892116214831671
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6891329286559935
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6890677586197853
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6889880306792981
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6889317356488284
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6888691013199942
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6888064526849322
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6887445979827159
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6887027655777178
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6886646475547399
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.6886200277507305
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6885708785638577
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.68852381223724
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884829709696215
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6884541751308875
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.688418613937166
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883852753950201
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6883489171241192
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.6883241432408492
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6883035013870317
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882729046344757
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6882372373459386
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.6882163694271675
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881829632903045
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881473989398391
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.688122030063109
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880938345832485

 End of epoch: 37 | Train Loss: 0.6868727283140199 | Training Time: 89 

 End of epoch: 37 | Eval Loss: 0.6893964069230216 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7555125057697296
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7209158509969711
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7094667096932729
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7036965787410736
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.700360426902771
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.698125422000885
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6964722684451512
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6952874690294266
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.6942872504393259
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6935412096977234
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6929138075221669
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6924419124921163
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6920166891354781
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.691679556454931
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6913558761278789
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6910756174474955
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908271309207468
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6906014134486517
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6903993339915024
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6902123865485191
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.6900744568733942
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6899126570333134
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6897898090922314
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896707298854987
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895370359420776
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.689428650874358
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893414501790647
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.6892501100897789
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.689166568271045
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6890711442629496
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890044100822941
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6889358313754201
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6888801119544289
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888192339855082
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6887658022131239
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887116259998746
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6886764405546961
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886444211006164
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.6886026113461226
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885685688257217
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885172236256483
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6884701762880597
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.68842773894931
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.6883962417190725
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6883662156263988
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883357527463333
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883077716573756
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6882714466502269
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.6882356220362138
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882169595956802
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6881990677001429
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.688175707596999
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.6881506703934579
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881298183291047
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.6881061215834184
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6880805702081748

 End of epoch: 38 | Train Loss: 0.6868573853399901 | Training Time: 88 

 End of epoch: 38 | Eval Loss: 0.689626829964774 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7553556263446808
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7211015850305558
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7097525298595428
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7041102007031441
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7005996143817902
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6983954012393951
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6966619959899357
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6954292401671409
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6944392184416454
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6936416667699814
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.693018604408611
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6925147344668706
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6921071268044985
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917364367416927
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6914127810796102
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6911180999130011
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6908661674050723
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6906558861335118
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904743665143063
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.6902799773216247
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6901318010829743
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899813931096684
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898604895757592
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.689731348802646
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6896078779697418
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6895117846819071
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6894080157633181
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6893189809152058
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6892344686491736
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891506359974543
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890782669667275
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6889970218762755
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6889498049562628
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888944638126037
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6888406159196581
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887835007574823
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6887213107701894
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886775672435761
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6886396541045262
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885953189432621
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.68855985708353
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6885370409204846
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.6884998973025832
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884625884619626
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6884213180012173
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883794820826986
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.688338275158659
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.68829840409259
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882698050567082
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882417882680893
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.688209486358306
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881831001776916
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881590901680712
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881319462149231
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881064603545449
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880744792521

 End of epoch: 39 | Train Loss: 0.6868530686977691 | Training Time: 89 

 End of epoch: 39 | Eval Loss: 0.6897233809743609 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7556187033653259
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7212171077728271
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7096611320972442
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.7038586974143982
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7004985415935516
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6981767326593399
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6965585112571716
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.6953309342265129
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6943098551697201
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.693530426621437
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6929481397975575
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6924073820312818
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6919648019167093
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6915909073182515
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6913026372591654
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6910362169146538
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.69080530369983
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.6905897004736794
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904327220038364
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902650427818299
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6900976754370189
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899580356749622
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898329833279485
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6897199022273223
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.6895926465988159
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6894833301122372
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6894082663235841
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6893182341541563
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.6892386251482471
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891634939114253
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890770942934098
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.689014059305191
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.6889729752685084
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6889145614469753
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.688860775913511
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6888114624553257
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6887585248496081
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886991536930988
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6886636053904509
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.6886205533146859
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885776218844624
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6885412463120052
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884923697904098
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884594403884627
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6884250439537896
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883863112200861
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6883589535317522
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6883209879199664
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.6882869247271091
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882508113384247
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6882233037668116
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881904510351328
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.688168201356564
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.6881305510247195
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6881091558933258
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880847461521625

 End of epoch: 40 | Train Loss: 0.6868641283659809 | Training Time: 90 

 End of epoch: 40 | Eval Loss: 0.6896911774362836 | Evaluating Time: 6 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.755040067434311
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7209692478179932
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.7097251097361247
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7038380280137062
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7004255747795105
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6981931567192078
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.6965560700212207
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6953799791634083
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.694417401154836
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6937229663133622
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.693128417296843
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6925927822788557
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921280755446507
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917501858302525
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914417203267416
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6911568008363247
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909086556995616
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6906849026679993
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904751090626967
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6903225022554398
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901766056106204
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6900231093168259
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898926835993062
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897738613188267
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6896572451591492
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6895488791740858
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.68945424468429
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893729278019496
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892744668598833
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6892053532600403
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6891268845527403
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890571147203446
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889992495377858
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6889399151591694
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888916260855539
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6888405265079605
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887903604958509
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6887356356570595
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886799046626457
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.6886259223520755
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885671840935219
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6885292960064752
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884878484315651
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6884383021430536
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6883947328726451
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.688368117550145
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883371346808494
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6883111429711183
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882846213116938
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882379977703095
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882110842302733
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881796871240322
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881514811290885
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881362171084793
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6881141895597631
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880877891821521

 End of epoch: 41 | Train Loss: 0.6868630495746578 | Training Time: 87 

 End of epoch: 41 | Eval Loss: 0.6899870123182025 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7552091717720032
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7211505502462388
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7097319463888804
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7039487421512604
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7005486702919006
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6982903530200323
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6966291674545833
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6954159036278724
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6944654517703586
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6936957615613938
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.693069155107845
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6925510187943776
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6921173503765693
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6917537110192435
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6914240276813507
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6911425698548556
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6908869487397811
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6906819462776184
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6905166378146723
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.6903439274430275
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901897935640244
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6900342540307478
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898825471815856
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897694985071818
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6896725988388062
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6895600798038336
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6894409040609996
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.689352975998606
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6892682823641547
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891884183883668
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.689100178210966
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.689027625694871
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889583513592229
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.6888901535202475
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6888325985840389
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887753200199869
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6887312687732078
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886704000987505
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.688624699604817
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885783384740353
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.688527657636782
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884828763348716
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884411899156349
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.6884084851904348
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.688383382293913
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883512293514998
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.6883189402996226
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882968670378129
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882686659997823
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.6882414690256119
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.688205130778107
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881802334235265
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.688151711675356
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881296741741675
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6881071443991228
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.6880814493766853

 End of epoch: 42 | Train Loss: 0.6868541567726473 | Training Time: 88 

 End of epoch: 42 | Eval Loss: 0.6898849861962455 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.7550884842872619
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.720991337299347
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7095756073792775
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7039341881871224
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.700532602071762
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6982466508944829
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.69657820888928
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6953935630619525
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6944075372483995
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6937049317359925
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.693095044114373
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6925610800584158
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.692146475498493
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6918087393045426
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914974280198415
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6912148352712393
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6909806812510771
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.6907319247722625
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6905182678448526
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6903545725345611
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.6901785052957989
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6900200415741313
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6898839906505917
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897604711353779
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.6896319515705108
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6895211582000439
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6894157557575791
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6893218510917255
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.6892396404825408
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891639663775762
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890877187252045
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6890336228534579
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.688958694898721
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.6888927556136075
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6888436787469047
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887855816218588
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.688747894119572
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886826394419922
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6886318191503867
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885861207544803
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885343926708872
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6885007971809024
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884608042794604
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884269019419497
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6884003693527646
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883674436289331
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6883321385434333
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.6882905532916387
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882706570382021
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.688252386212349
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6882170622255288
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881825605264077
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.688156658411026
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.6881253123283386
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6881029357693412
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.6880731553903647

 End of epoch: 43 | Train Loss: 0.6868436498979552 | Training Time: 87 

 End of epoch: 43 | Eval Loss: 0.6896180084773472 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.755537497997284
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.721402183175087
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7099688728650411
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7043123573064805
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7008181190490723
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6984870463609696
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.696759739943913
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.695570332556963
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.694573230875863
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6938433146476746
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6931681101972407
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6926602547367414
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6922049637024219
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6918313907725471
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.6914785289764405
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6912105146795511
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6909292126403136
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6906892084413104
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6904965460300445
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6903517135977745
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6901785694417499
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6900255853479559
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6899017538713372
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6897719090183576
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6896600391864777
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6895631148264958
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6894744261547371
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6893719562462398
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.6892869007998499
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6892156094312668
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6891381555987942
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6890628332272172
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889877113428983
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6889358490705491
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6888767606871469
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6888193857338694
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6887689198996569
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6887196299276854
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6886650333037743
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6886148703098297
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885718523002252
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6885334100042071
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884949592656867
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6884593591094017
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6884251100487179
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883823484182358
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6883552969770229
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.68831138809522
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882788802896227
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882412900924683
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6882132695001715
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881832761260179
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881470038081116
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6881155257975614
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.688093886158683
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880675274346556

 End of epoch: 44 | Train Loss: 0.6868429360136522 | Training Time: 86 

 End of epoch: 44 | Eval Loss: 0.6898566399301801 | Evaluating Time: 6 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7554804563522339
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7214100569486618
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.709875100851059
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7040331646800041
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7006308341026306
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6983832230170568
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6966724302087511
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6954175353050231
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6944876101281908
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6937107491493225
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6930735604329543
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6925633450349172
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6921484447442569
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6917847786630903
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6914762663841247
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6911608640104532
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6909237114822163
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6907223747836219
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6905314059633958
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.690367442369461
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6901797456400734
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6900318641554225
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6898717411186384
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6897666876514753
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6896400649547577
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6895260219390575
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6894190295978829
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6893228283950261
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.689227799506023
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891406307617823
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.6890618072402093
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889911130070686
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6889108074433876
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888490285943536
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.688799158334732
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887451902031898
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886965994899338
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886637984137786
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6886265001235864
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.6885899741947651
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885509018490954
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6885107346943447
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.6884586435417797
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6884215969930996
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883818589316474
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.6883578976859217
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6883257769523783
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882979717105627
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882641674304495
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882427901029586
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6882194644095851
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.688183872974836
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881519264770004
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881268075218907
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6881132695891641
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880903149289744

 End of epoch: 45 | Train Loss: 0.6868607232000975 | Training Time: 89 

 End of epoch: 45 | Eval Loss: 0.6896866815430778 | Evaluating Time: 6 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7552036166191101
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7209637999534607
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7095035791397095
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7039364323019981
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7004923117160797
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6981886367003123
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6966085936341967
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6953908413648605
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.694413568576177
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6936737167835235
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6930656292221763
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6925417229533195
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6921159524184007
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6917741456202098
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6914328455924987
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6911339141428471
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6908727375900044
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.6906449082824919
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.690451969598469
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6902713641524315
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.6901181331702642
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6899661370299079
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898397204668626
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6897335164248943
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6896095588207245
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6894769877195358
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6893731064266628
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892634351338659
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891893758856017
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.689114938378334
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890383893443692
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889649132266641
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889003139553648
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888302313930849
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887731829711369
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887324589822027
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6886799759155995
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886327465898112
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6885930146926489
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.6885495880246162
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6885059916391605
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.6884703701450712
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884439078874366
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.6884052981029857
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883616958724128
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883110324973646
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6882756360033725
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882472614447276
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882272231335542
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882057378292084
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.6881823123670092
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881583684912095
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881404522454964
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881160297879466
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880964303016662
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880686366132327

 End of epoch: 46 | Train Loss: 0.686844285294018 | Training Time: 88 

 End of epoch: 46 | Eval Loss: 0.6894347071647644 | Evaluating Time: 6 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.755400937795639
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7211050391197205
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7096797009309133
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7039471685886383
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7005487787723541
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6981934408346812
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6965616737093244
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.695284228026867
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.6942975613805983
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6935643297433853
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6929219468073411
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6923860723773638
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.692035993704429
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6916848923478808
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6913376454512278
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6910776618868113
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908425061141743
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.690621155500412
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6904266200567547
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902601116895676
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.690098945583616
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899493957107717
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6898181091184201
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896925926208496
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895716683864593
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894495679781987
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893481261200375
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892522056187902
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891702674586198
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.6890943268934886
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890241109555767
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889549905434251
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6888930494135076
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888212528298883
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6887582547324045
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887083810236719
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6886520952791781
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886015575183065
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6885524615263328
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885137468576431
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6884645453313502
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884357147273563
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6883926111598347
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.688365305418318
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883399001757304
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883202914310538
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882830859498775
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.68825775111715
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882312728434193
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6882076812982559
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.6881798047645419
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881546851534109
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881337015133984
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881121889308647
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880896212837913
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880649464470999

 End of epoch: 47 | Train Loss: 0.6868341195899829 | Training Time: 87 

 End of epoch: 47 | Eval Loss: 0.6901558126722064 | Evaluating Time: 6 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7558852076530457
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7213385105133057
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.709991725285848
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7043503373861313
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7008716452121735
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6984296907981237
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6967680198805672
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6955703891813755
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6945804986688826
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6938042265176773
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6930963489142331
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6925697738925616
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6921092395599072
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.6917227915355137
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6913871363798777
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6910949211567641
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908324967412388
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6905931214491526
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6903918790189844
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902367597818375
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6900821529683613
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899254197424108
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.689773857852687
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.689665290961663
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895531408786774
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894460689563018
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893497297057399
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892545063580785
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891855428958761
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6891020681460699
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6890143238729046
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.688949360512197
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6888766491051876
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.688822882140384
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.688758031129837
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887079036898083
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886638253121763
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886203947820162
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.6885756368820484
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885334865748882
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6884837476218619
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884496194975717
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884113033150517
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883749196475203
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883382283316718
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.6883064663928488
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6882758006136468
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882503402729829
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.6882162313072049
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881851885318756
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881731256550434
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881560410444553
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881186935136903
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6880979587634405
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.688077586889267
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880527890154293

 End of epoch: 48 | Train Loss: 0.6868315191395515 | Training Time: 88 

 End of epoch: 48 | Eval Loss: 0.6898524676050458 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.755267882347107
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7210579127073288
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7096217652161916
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7040084823966026
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7005794954299926
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6981686949729919
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6965507873467036
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6953119888901711
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.6943631509939829
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.6936130124330521
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6929587532173503
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6924205924073855
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6919867235880631
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.6916004036154065
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6913181225458781
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.6910511262714862
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6908087888184715
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906070040331946
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904075999008982
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902247735857964
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.690066553297497
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.689907995950092
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6897815243057582
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6896740689873695
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6895389900207519
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6894330176023337
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6893452774595331
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6892551737172263
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6891644206540338
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891011716922124
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.689028093699486
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6889458030462265
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6888746895573356
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888208064962836
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6887697121075221
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887252026134068
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6886593976536313
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886051007007298
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6885557987751105
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885109081864357
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.688474585661074
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.6884316218750818
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.6884009718894959
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883697164329615
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883427001370324
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883220717958782
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6882948243871648
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.6882625160117944
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882344723964224
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6882134844064712
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881843111094307
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881620940107566
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881367467484384
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881044196861762
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.688077220808376
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880515124116625

 End of epoch: 49 | Train Loss: 0.6868238505009001 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.6899726816586086 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7555304229259491
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7210738450288773
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.7097746392091115
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7041189715266227
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7007161164283753
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6983478287855784
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6966721492154258
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.695467185229063
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.694483615954717
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6937023293972016
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6931007049300454
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6925693631172181
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6921159354540017
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6917339908225196
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6914087076981862
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911344017833472
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908769295496099
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906638357374403
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.6904618473429429
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.690293454527855
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6901294007187798
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899692050435327
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.689811433657356
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6896893406907717
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895819213390351
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894857904085746
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893955617039292
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.68930522863354
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6892276770082013
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.689134946068128
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890639162832691
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889969978481532
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.688921416347677
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888706403620103
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6888016843795777
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.6887341752648354
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886834202585994
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886270248576214
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.6885839506601676
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.6885378853976727
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6884893439164976
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884496341149012
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884187392024107
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883903355761007
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883524356948005
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6883170162853988
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882831886727759
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882501494139432
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882196331510738
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6881893699169159
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.688160136049869
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881401319916431
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881217152442572
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880972550974952
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880704689025879
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880501184080329

 End of epoch: 50 | Train Loss: 0.6868223067933479 | Training Time: 97 

 End of epoch: 50 | Eval Loss: 0.6894827995981488 | Evaluating Time: 8 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7551991283893585
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7207986295223237
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7094003776709239
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7037564381957054
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7004419827461242
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6982393095890681
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6965675243309566
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6953317441046238
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6944362084070842
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6936432290077209
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6930551545186476
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6924919957915942
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.692046666603822
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6916658537728446
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6913413365681966
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6910486366599798
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6908394192948061
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6906309912602107
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6904200497426485
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6902358591556549
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.6900700750805083
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.689951702952385
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6898224439309991
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6896948394676049
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.6895714249610901
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.689483814056103
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893748157554203
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892791088138308
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6892010692892403
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6891403027375539
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890671662745937
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889988670125604
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.688940944816127
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888823754647199
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.688825010572161
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.6887606489989493
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6887059010363914
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886684408313349
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6886142084231743
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885626810789108
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6885143474834722
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.6884731810717356
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884331219418104
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6884015056219968
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.688362129661772
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883322508438774
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6883023103500935
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.688275329520305
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882482432589239
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.6882157764434814
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881839014735877
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.688156830232877
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881206257163354
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6881016224622727
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880725350163199
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.6880525922136648

 End of epoch: 51 | Train Loss: 0.6868228437626256 | Training Time: 96 

 End of epoch: 51 | Eval Loss: 0.6896941917283195 | Evaluating Time: 5 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7551407158374787
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.720932611823082
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7095336616039276
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7038609966635704
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7003826463222503
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6981134861707687
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6965251215866634
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6953210711479187
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.6943982614411248
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6936866664886474
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.6930703146891161
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925580342610677
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6920656392207513
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.691734772494861
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6913931318124136
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.691108587384224
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6908503718235913
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906246072716183
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.6904202677701649
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902196106314659
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.690061218397958
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899114546450702
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6897443659927533
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.689638530711333
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6895292377471924
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.6894359130125779
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893397598354905
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892593692455973
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891751815532816
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6890965942541758
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890295226727763
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889767294749618
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6889259685169566
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.6888678440276315
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6888163481439863
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.688754186199771
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6887017646351377
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886470449598212
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6886055428248186
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885601735115051
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6885270610088255
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884856876872835
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884524084800898
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6884225126017224
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883893790509966
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883635786564454
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.688331266159707
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6883037481456995
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882713882290588
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6882395275831222
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6882059633731842
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881735637784004
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881435041157704
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6881151793179688
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880942697958513
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880731425115041

 End of epoch: 52 | Train Loss: 0.6868484554037584 | Training Time: 88 

 End of epoch: 52 | Eval Loss: 0.689910922731672 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7555923640727997
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7211818844079971
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7097227851549784
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7039355903863906
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7005939674377442
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6982625464598338
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6967082594122206
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.695512780547142
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6945580237441593
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6937791347503662
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.6930992272767154
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6925793533523877
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.6921463682101323
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.691794958284923
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6914557520548502
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6911461595445871
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908827017335331
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6906438830826017
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.690451582168278
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902727797627449
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6901066374211084
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899613217874007
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6898149788379669
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896663397550583
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6895673217773437
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894643513055948
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6893724788118292
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.689286328639303
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6891960255030928
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6891159149010976
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6890337357597967
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889772383496165
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.688922010046063
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.688857896363034
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.6888038752760206
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887443564004369
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6886897351290728
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6886268949822376
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885848276126079
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885355520248413
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884837729174916
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884528912249066
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884199954742609
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.6883806691928344
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883369455072614
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883049640966499
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6882687075341002
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.68824464045465
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882149489558473
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6881806015968323
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6881617861635545
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.68813159179229
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.6881115541143238
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6880912823809517
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6880654532259161
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.688040048203298

 End of epoch: 53 | Train Loss: 0.6868202796024558 | Training Time: 88 

 End of epoch: 53 | Eval Loss: 0.6895378742899213 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7555782973766327
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.721007326245308
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7096247295538585
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7039021223783493
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7005460214614868
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6982884883880616
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6966408848762512
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6954205580055713
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.694464013311598
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6937339186668396
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6930783710696481
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.692525393764178
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6921149235505324
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6917649571384702
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6914333625634511
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911520227789879
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6909122547682593
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6907094005081389
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.6905255493364836
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6903304859995842
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6901533064388093
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6899866602637551
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6898356165574945
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6896895974874496
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6895705654621124
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894722241621751
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893736110793219
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892774552106857
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.6891891991269999
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.689107224146525
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890233837789105
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889571230858564
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.6888916505105568
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888273311011931
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6887590907301222
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.688709355559614
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6886573393602629
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886107476134049
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.6885596405237149
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885036198794842
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6884577746798353
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884098446085339
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.688370173753694
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.68833873082291
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6882973674933116
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6882598581521407
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882297775846846
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882089654604594
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6881872055481891
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881657793521881
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881423313243716
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881207341184983
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881044459792803
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6880808498020525
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.688061447577043
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.688043326990945

 End of epoch: 54 | Train Loss: 0.6868104677284713 | Training Time: 88 

 End of epoch: 54 | Eval Loss: 0.6896977509771075 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.7558912992477417
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7215756356716156
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7099117199579875
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7041815936565399
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.7007490670681
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6983797391255696
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6967189175742013
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6954659581184387
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6944864994949764
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6937170898914338
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6930526121096178
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6925174583991368
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6920493529393122
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6916886308363506
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913774299621582
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6910717900842428
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6907754638615776
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6905370308293237
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6903420338505193
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.690162436068058
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.6899916231632233
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6898688990961421
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.6897453994854637
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896127350628376
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.689538732290268
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.6894378132545032
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893232239617242
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892185973269599
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891372138056262
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6890671567122142
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6890123786464815
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889516403898597
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888906437339205
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888324755079606
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887829405920846
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6887218582961294
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886609531737663
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6886148513931977
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885781219372382
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885390008985997
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884929120540619
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884533672105698
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6884176204370898
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883724811402234
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.6883290546470219
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882973919744076
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.6882556169591052
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882262866944074
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.6882032764201261
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881677091121674
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.6881473157920089
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.6881172905747707
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881024602449165
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880827832001227
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.688065595518459
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880409738847187

 End of epoch: 55 | Train Loss: 0.6868184007374586 | Training Time: 88 

 End of epoch: 55 | Eval Loss: 0.6894226329667228 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7551205039024353
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7211261093616486
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7097325265407562
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7039672955870628
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7005816066265106
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.6982661644617717
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6965715680803571
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6953361488878727
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6944083737002479
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6936477202177048
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6929992399432442
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.6924972290794055
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6920402274681972
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6916704139539174
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6913634932041168
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6910855527967215
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.690837882196202
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6906269523832533
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6904568628260964
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6902619475126266
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.690108745438712
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6899642608382485
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.689846979794295
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6897251240909099
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895980331897735
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6894942111693896
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6893893400828044
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6893185296228954
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.689231697444258
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.689158056974411
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6890783088822519
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6890076486393809
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.6889538416356752
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.688889298193595
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.688828968490873
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.688755018512408
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886986674489202
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6886559436195775
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6886117713573652
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6885540020465851
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.688505720219961
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.6884633321137655
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884234016717866
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883922576904297
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883581744299995
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6883211567350056
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.688284022884166
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882621344178915
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6882256849687927
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6882036621570587
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.688181381482704
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881487567837422
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881169346143614
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880965769290924
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880685578693043
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880424580403737

 End of epoch: 56 | Train Loss: 0.6868144848705393 | Training Time: 88 

 End of epoch: 56 | Eval Loss: 0.6893745575632367 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7554519355297089
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7211483687162399
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.7097653528054555
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7040699765086174
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7007287156581878
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6984130263328552
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6967629866940634
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.6954817466437817
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6945011046197679
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6937290519475937
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6930740871212699
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925647268692653
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6921394737867209
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.6917853968484061
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6914597054322561
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.691183565184474
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.690938968518201
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6907111790445116
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6905273158299295
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6903420996665954
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6901817137286776
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6900265363129703
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6898826485094817
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6897616498172283
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6896523730754852
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6895245412221321
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6894190947214762
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6893282660416195
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.689244454482506
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.6891730171442032
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6891037302632486
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6890354784205556
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6889594833056132
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888776444336947
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6888233980110713
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887578482429186
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6887042844617689
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886484894313311
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6886060273035979
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.6885619144141674
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6885166192927011
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.688478701029505
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6884436779244002
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883967326446013
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883708386951023
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6883388768071713
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.688308145010725
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.688274264211456
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882486861579272
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6882141513824462
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.688188358966042
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881595200070968
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6881371621815664
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6881046280816749
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.6880693067203868
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880557700991631

 End of epoch: 57 | Train Loss: 0.6868304069063305 | Training Time: 89 

 End of epoch: 57 | Eval Loss: 0.6896173868860517 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7561618626117707
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7215916246175766
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7100012938181559
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7042847231030465
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7009247672557831
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6986264725526173
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6969528700624193
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.695736126601696
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6947744601302677
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6940191799402237
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6933790591630069
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6928010414044062
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6923436627938198
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6919245238815035
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6915882639090221
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6912403896450996
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6909724719384137
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6907598475615183
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.6905409561960321
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6903665271401406
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6901789543174562
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6900241927667098
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.689883256736009
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6897633001208305
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6896378126144409
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6895325057781659
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.6894151458033809
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6892998829483986
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6892306979360252
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6891424675782521
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890512049198151
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.6889811657369137
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6889267874486519
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888634534443125
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887997538702828
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887450789411863
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886976863886859
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.6886509049879878
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6886048983304929
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885602015256882
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6885184807021444
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884841957262584
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6884338347024695
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883891039273956
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883564327822791
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6883296485828316
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6883061757747163
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882733583450318
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6882502614235392
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6882178024053573
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881890596127977
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881591710906763
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.688133192849609
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6881068347780793
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880798245560039
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880558059683868

 End of epoch: 58 | Train Loss: 0.6868270123954368 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.6891070944922311 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7554935932159423
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.7210294634103775
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7096414407094319
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7038709998130799
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7003981053829194
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6981548259655634
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.696534594467708
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.6953337423503398
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6943641132778592
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.693576180934906
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6929516396739266
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.692434894045194
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6919836732057425
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6915827372244426
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6912576548258463
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6909952227026224
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6907425806802862
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6905322866307364
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6903361402059857
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6901574462652207
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6899945009322394
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6898671388626099
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897440868875254
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896303835014502
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.689521231174469
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.689416882624993
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6893147135222399
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.689229887511049
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891510579092749
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890692045291265
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6890057558013547
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889456303790211
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6888824797037876
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888336832032484
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887628104005541
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887083917856216
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886713833422274
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6886258876637409
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.68858402967453
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885421139001846
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.68850404547482
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.688467133470944
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6884293529876443
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883879088542678
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883611581060621
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883094800555187
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882746407326231
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882473883529504
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882299252918789
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881982469558716
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881809730155796
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.688146185531066
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881023239414646
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880746845845823
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880607454343276
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880367975149836

 End of epoch: 59 | Train Loss: 0.6868071975961195 | Training Time: 91 

 End of epoch: 59 | Eval Loss: 0.689582748072488 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7555123150348664
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7212378442287445
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7097895979881287
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.704147607088089
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7006603682041168
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6983745117982229
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6967209143298013
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.6955251716077328
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6945571555031671
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6937871968746185
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6931703188202598
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6926551555593808
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6922169795403114
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6918205840247018
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6914795804023742
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6911930348724127
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6909350181327146
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906891690360175
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904864235928184
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6903224694728851
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6901577816123055
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.6900046581571753
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6898607951143514
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6897385309139887
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.6896141130924225
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6895021397333879
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6894101701400898
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6893043943813869
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.6892108185537931
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.6891256076097488
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890565128095688
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889910200610757
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6889168495481665
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888503335854587
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.6887803062370845
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887170551551713
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886596264065923
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886209895736293
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885806586497869
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.6885294304788112
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884857212624899
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884390581221808
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6883870313333911
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.6883599229834296
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883326741059621
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6882921091888262
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882593654571696
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882306636621555
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.688193673260358
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6881668539047241
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881374978551678
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881130514236596
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6880874737253729
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880611196712211
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.688040987144817
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880277166409152

 End of epoch: 60 | Train Loss: 0.6868015447549061 | Training Time: 92 

 End of epoch: 60 | Eval Loss: 0.6895712443760463 | Evaluating Time: 5 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7557055473327636
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7215946763753891
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7100753525892893
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7043858081102371
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7008744096755981
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6985567768414815
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.696884412424905
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6957048170268536
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6947121017509037
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6939422589540482
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6932650587775491
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6927424550056458
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6922742788608257
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.691900326524462
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.6915483434995016
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.691238147392869
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.690979440422619
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6907266557216645
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.690509873942325
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6903239214420318
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.6901447171256656
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6899866849184036
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.689831803155982
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6897058730324109
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6896083576679229
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894863837040388
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893875607737788
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.689296336046287
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6892136528574188
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6891390891869863
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6890561920981253
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.689007705822587
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6889390398155559
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.688866062374676
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887997622149331
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6887376041875946
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886955923325306
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6886426224520332
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885915291615021
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.688540323972702
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884801634928075
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884434343803496
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883982748486275
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.6883648711172017
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.6883245064152612
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.688295225734296
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882716734358605
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882487952709198
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6882126358090614
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881814960241318
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881560370033862
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881227319057172
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880961726296623
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880738117076732
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880457521568645
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880295372435025

 End of epoch: 61 | Train Loss: 0.6867995577575886 | Training Time: 90 

 End of epoch: 61 | Eval Loss: 0.6896496755736214 | Evaluating Time: 6 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7552631795406342
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7212125808000565
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.7097774585088094
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7040704697370529
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7006757974624633
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6983919342358907
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6967384389468602
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6955133035779
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6945809503396352
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6937446743249893
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6931329992684451
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925584554672242
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.692129006752601
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6917425032172885
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6914529955387115
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6911748889833689
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6908835663514978
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.69065520034896
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6904766465488233
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6903018075227737
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6901569746789478
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6899947599931197
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6898461339266404
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6897180711229642
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.689594310760498
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6894905523611949
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.689385242373855
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892924193825041
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6892028097448678
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6891113744179408
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.689041151923518
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889832546934486
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6889127109989975
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888485628015855
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887823786054339
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.6887289037307104
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886707312351948
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6886160507013923
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885630693191137
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6885175949335098
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884707365094161
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884324273892811
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6884005850137667
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.688363943723115
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6883354275756413
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6883082200651583
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882728423209901
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882433788230021
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6882123619926219
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881772720813751
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.68814970944442
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.688120636000083
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.6880925789194287
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880758389278695
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880491304397583
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880260572901794

 End of epoch: 62 | Train Loss: 0.6868017273666585 | Training Time: 88 

 End of epoch: 62 | Eval Loss: 0.689747188772474 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.754995858669281
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.720867645740509
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.7095165709654491
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7038307785987854
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.700370934009552
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6980704079071681
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6964603313377925
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6952466070652008
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.6943225887086656
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.6936052823066712
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6930130785161799
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6925194889307023
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.69206503033638
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6917026434625898
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.6913709525267283
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910655364394188
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6908115271259757
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905950605869293
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903817876389152
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6902009853720665
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.6900614159447807
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.6899292981082743
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6898087330486463
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6897024986644585
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6895845682621002
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6894953035391294
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.689404797995532
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6893206453749112
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6892505740297252
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6891560371716817
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6890595459168957
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6889875760301948
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6889297413103508
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6888615983373979
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6888075361933027
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6887435212731361
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.688696621398668
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6886409767364201
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885910005141527
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6885408954322338
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884988760075919
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.688452207048734
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6884132345055425
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883700464259495
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883313780360751
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6883008848065916
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882633242201298
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882351417094469
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6882121049627966
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.688181369304657
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881594351693696
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881336097533887
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6881194435200602
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880905098385282
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880659579146992
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880444293575627

 End of epoch: 63 | Train Loss: 0.6868167660932625 | Training Time: 88 

 End of epoch: 63 | Eval Loss: 0.689363820212228 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7553944945335388
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7213956236839294
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7096709529558818
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7039700612425804
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7005158793926239
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.698224080602328
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6966062358447483
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6954372622072696
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6945745534367032
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6938385307788849
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6931794247844002
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6926731422543526
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6922101419705611
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.691815539768764
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6914638539155324
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.691167925670743
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.690912828725927
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.690722217824724
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6905015760346462
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6903106635808944
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6901407170863378
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6900298980149355
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6898975009503572
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6897568675378959
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6896208655834198
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.6895175149807563
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6894002804049739
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6893094309738704
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6892214750421458
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.6891424312194189
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890663456532263
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889880079776048
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.688927644852436
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888561946504256
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887964250360217
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6887447726395395
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.688691623790844
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6886355762418948
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.68858488263228
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.688544370085001
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6885077864658542
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884653410741262
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6884215127590091
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883769150484692
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883423381381565
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.688307345043058
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.6882750531460377
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.6882414814084769
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6882079707116496
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.688181623339653
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881472547849019
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881349029449316
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6881037408450864
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880777621710742
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.688051484823227
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880238990698542

 End of epoch: 64 | Train Loss: 0.686798054454601 | Training Time: 88 

 End of epoch: 64 | Eval Loss: 0.6889369232313973 | Evaluating Time: 5 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.755219554901123
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7208107739686966
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.709537164370219
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7038692608475685
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7004978001117707
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6982799977064132
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966520164694104
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6954660028219223
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.6945361561245389
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6937623053789139
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.693098153851249
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6926443904638291
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6921869080800277
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.691832913671221
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6915003323554992
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.691190742701292
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6909126828698551
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6906664537058936
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904713392257691
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902862691879272
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6901032728808266
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6899601681665941
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6898176931816599
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6897079378366471
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895932593345642
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.6895091680380014
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.689409346933718
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.6893195724913053
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6892378356950036
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6891731057564418
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.689083412578029
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.6890062211081386
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6889362145553936
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6888692077468423
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.6888035067490169
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6887498981422848
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6887034383980004
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6886462158278415
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6886031612371787
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6885632838308812
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6885155696694444
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884799575521833
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6884344166101412
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883924374526197
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.6883462733692594
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.6883075588423273
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.6882645929113348
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.6882265186558167
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.688201162644795
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881626732349396
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.6881426060900969
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881143365915005
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6880844811223588
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880674765065864
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880485809933056
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.6880248337984085

 End of epoch: 65 | Train Loss: 0.6868021007132741 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6887082287243435 | Evaluating Time: 5 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7552546739578248
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7207153052091598
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7092992464701334
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.7036059543490409
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.7002061080932617
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6979697823524476
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6964004261153085
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.695199953764677
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6942690749963124
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6935070121288299
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6928570303049955
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6923634787400563
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6919053875482999
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6915650823286601
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6912652683258057
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6909630302339792
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6907209929297952
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6904917667309444
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6903149080903906
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6901449584960937
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.689983080966132
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6898608990690925
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897438769755156
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896415092051029
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.689528046131134
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894346509988492
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.6893466251867789
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6892634951642581
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891724183641631
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890990591049194
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6890387490872414
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889675322920084
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6889074899933555
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6888612843611661
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.688796557358333
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6887426084942287
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886962874515636
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6886501273042277
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.6886100706381676
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6885581623017788
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6885070430069435
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.688472913702329
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.6884287062079407
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883894671093334
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.6883472402890524
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6883117005876873
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882782956387135
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882523423681657
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6882230741637093
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881944260597229
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881642695735483
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.6881392422776956
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6881117815116666
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.6880925670818047
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880716181885113
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.6880499861070088

 End of epoch: 66 | Train Loss: 0.6868199771484442 | Training Time: 88 

 End of epoch: 66 | Eval Loss: 0.6892209819384983 | Evaluating Time: 6 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7559275269508362
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7211476355791092
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7098068277041117
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7040033802390099
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7005834090709686
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6982662290334701
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6965988269874028
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6953796245157718
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6944194561905331
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6936562722921371
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.693087348612872
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925843591491382
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6921961009502411
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6918418237141201
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6915164490540823
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.6911959990859031
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.690945120418773
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6907337043020461
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6905256196072227
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.690321152806282
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6901384123734066
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899952327663248
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6898616018502609
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6897279322147369
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6896380846500396
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6895060112843147
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6894050752675092
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6893053755164147
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891967888536125
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.6891249150037766
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890485371312788
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889859564602375
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6889159932281032
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888540588757571
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.688775063753128
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6887297522690561
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886752255865045
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6886373341083527
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885905724305373
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.6885295033454895
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884862478186444
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.688434455934025
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6884037037228429
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883553323420611
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883323546250661
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6883014019416727
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882754107739063
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882426229616007
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882003787828952
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881720869541168
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.6881492937312407
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881186321377755
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880919950188331
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880712705629843
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880524658073078
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880260387701648

 End of epoch: 67 | Train Loss: 0.686800310358537 | Training Time: 89 

 End of epoch: 67 | Eval Loss: 0.689689746924809 | Evaluating Time: 6 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7549753546714782
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7209055483341217
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7094553808371226
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7038152635097503
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7003777754306794
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.698178909222285
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6965916872024536
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6953400053083897
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944063425064086
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6936379635334015
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930180251598358
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925178517897924
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.692081841138693
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6916967877319881
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913415797551473
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910659328103066
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.6908301030888276
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6906124075253804
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6904226406624443
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6902500051259994
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900746839387076
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6899308180267161
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6898086104703987
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896827106674512
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895535440444946
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894441045247591
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893484978764145
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892588017242295
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891841280049291
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.6891114840904872
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.68904126498007
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6889529019594193
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888952565915657
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6888341705588733
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887724041938782
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6887164548039436
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.688672015151462
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6886164577383744
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885734518369039
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6885198700428009
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884696964810534
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884302904208501
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.688380730429361
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883453882553361
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883051203356849
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882695074962533
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882536195694132
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882284421473741
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881940453636403
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881670104265213
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881398801710091
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.6881111808694326
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6880802816939804
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880573050843345
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880283200740814
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880120566913059

 End of epoch: 68 | Train Loss: 0.6867874497860934 | Training Time: 88 

 End of epoch: 68 | Eval Loss: 0.6896136658532279 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7555795192718506
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7211537957191467
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7095595260461172
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7037990123033524
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7004173684120178
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6982166608174641
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6966637781688145
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954624526202678
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6945318400859832
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.6937845212221145
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6931667951020327
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6926142483949661
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6921461013647227
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.6917760453053883
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6914749217033386
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6911710452288389
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.6909025690134833
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906593640645345
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6904424758333909
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902658492326736
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6900948896294549
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.68994872786782
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.689800062386886
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896715506911277
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895420560836792
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894546350607506
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.689348163207372
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892534319843565
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891727260474501
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890898044904074
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6890045973562425
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889510467648506
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888910345958941
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.6888110227444593
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887626819951194
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.688702889614635
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886513263792605
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885932933343084
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885439070371481
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6884892727434635
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884399714993268
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884029622588839
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883642712304758
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883270174264908
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6882987798584832
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882594085257986
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.6882292588974567
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882002141326666
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881790436044031
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881475484371186
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.6881263734078875
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881026494961519
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880681725043171
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880500844231359
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880327884717421
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.6880117456827844

 End of epoch: 69 | Train Loss: 0.6867856341125691 | Training Time: 88 

 End of epoch: 69 | Eval Loss: 0.6894626872880119 | Evaluating Time: 5 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7561259984970092
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7212956339120865
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7098471502463023
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7040797129273415
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.7005713272094727
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6982374300559362
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6965829278741564
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6953488655388356
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6943861073917813
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6935966378450393
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6929604812101884
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6924204135934512
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.691969026510532
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6916015067270824
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6913039592901865
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6910415481775999
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6908072646926431
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.6905841287639406
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.690392520866896
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6902068993449211
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6900546411673228
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6899018461054022
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897562223932018
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6896625849107901
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6895423173904419
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6894349155517725
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.6893295782583732
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6892307426248278
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.68914794038082
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890520224968593
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889788077723595
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6889130877330899
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888583306110266
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.6887967284987955
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887480354309082
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6886902713113361
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886288931240907
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6885746761372215
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885270722401448
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6884749642014504
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884357714071506
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6883838381086077
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883415014244789
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.6883100496097044
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.6882870933744643
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882547473130018
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882226062581894
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6881937025735776
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881712277324832
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.688155319571495
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.68812315604266
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6881015621698819
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.6880730479393365
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880521128575007
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880333151600577
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880103005894593

 End of epoch: 70 | Train Loss: 0.6867847500649173 | Training Time: 88 

 End of epoch: 70 | Eval Loss: 0.689771831035614 | Evaluating Time: 6 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7559352040290832
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7212966024875641
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7098252713680268
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7041198134422302
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7006385147571563
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982158432404201
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6965399324893952
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6952885307371617
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6943727175394694
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6935842090845108
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6929559620943937
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6924060304959615
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6919511538285475
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6915699946028846
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6912577025095622
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.690988176688552
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6907232691259945
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6905010912153456
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.690313467540239
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6901223349571228
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.689961515437989
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6898326700383967
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6897054231685141
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6895991081992785
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6894794926643372
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6893792232641807
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6892789803169391
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6891847103834152
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891036420032896
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6890287603934606
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6889643609523773
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6888956498354674
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.6888299790295688
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6887786577729618
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887193374974387
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6886558994650841
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.688607768432514
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.6885620903027685
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885154658403152
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6884801523387432
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.688430763453972
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6883990008206594
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883647239485452
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883225052194162
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6882932212617662
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882642673409504
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882363034055589
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882143417994181
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.6881820278508323
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.6881554399728775
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.68813303510348
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.6881021208488024
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880757159781906
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880520596548363
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880319227955558
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880092313247067

 End of epoch: 71 | Train Loss: 0.686786413298244 | Training Time: 89 

 End of epoch: 71 | Eval Loss: 0.6891138468469892 | Evaluating Time: 6 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7551444709300995
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7207983791828155
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7094538191954295
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7038240388035775
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.7003806912899018
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6981328507264455
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.6965067216328212
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6952447488903999
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6942597647507985
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6935650837421418
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6929805262522264
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6924737264712651
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6920377011482532
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6916206768580846
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6912890064716339
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6910516433417797
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.6908196982215432
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.6905827800432841
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.690382909147363
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6901982820034027
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6900410592556
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6898973960768092
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6897745642973029
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.6896737647553285
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.689562920331955
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.689460094846212
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.689371285394386
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892743996211461
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891769347519711
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890834164619446
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6890159135864627
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889617130160332
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6889037923379377
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.6888488366323359
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887926464421409
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6887483555409644
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886936513153282
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6886367529630661
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885959956890497
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885546869039536
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6885016514033806
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884690385489237
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6884375361509101
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883797298778187
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883408086829715
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6883255515409552
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882987141609191
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882674703995387
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6882370643469752
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6882055535316467
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881673996355019
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6881416214200167
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6881084858246569
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880903525484933
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880663440444252
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880424333470209

 End of epoch: 72 | Train Loss: 0.6868176851652364 | Training Time: 88 

 End of epoch: 72 | Eval Loss: 0.6895638704299927 | Evaluating Time: 6 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7558402717113495
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7213733226060868
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7098702291647593
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7040727481245994
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7007012224197388
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6984183549880981
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.6967390520232064
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6955127522349358
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6945095717906952
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6937199038267136
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6931001733649861
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6925814415017764
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6921388795742622
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.691729234797614
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6914041781425476
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6911437556147575
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6909093849799213
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.690682954258389
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6904658618726228
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.690285139977932
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6901099874859764
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.6899285617199811
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6897881365340689
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896774585048357
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6895532660484314
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894544658752588
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893552559393423
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6892458079116685
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891722948386751
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890985645850499
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6890119762189927
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889403371140361
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.688867641398401
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6888097670148401
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.688743942294802
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6886852170030276
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886345715136142
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.6885988246453436
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885561185005383
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6885144881904125
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884765565395355
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6884412050247193
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6884044518304425
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883610481565648
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6883275641335381
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882822774026705
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882423920834319
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.688209838916858
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.688182364434612
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.688160465836525
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.6881455150305056
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6881077844362993
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880863091855679
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880663957860734
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.688040322823958
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.688019021494048

 End of epoch: 73 | Train Loss: 0.6867885302653355 | Training Time: 87 

 End of epoch: 73 | Eval Loss: 0.6897420457431248 | Evaluating Time: 5 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7554017543792725
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7210569500923156
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.70969544450442
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7040029332041741
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7004556751251221
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6982044100761413
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.696636575460434
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.695392070710659
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.6944294571876526
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6936212730407715
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6929552235386588
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6924315964182218
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.69201325911742
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.691630847964968
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6912983123461406
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6910171937197447
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6907674835008734
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6905340015888214
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.6903470268374995
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6901500487327575
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6899831913766407
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6898556395010514
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.689742805905964
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.6896168947219848
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6895010538101196
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6894073731624163
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.689325890717683
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6892283258693559
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6891502696892311
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.68908451517423
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6889925825980402
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889170575886965
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6888567315809655
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6887973510167178
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.68874191062791
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6886793721053336
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886205036897917
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6885731623360986
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.6885236782905383
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6884799921512603
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.6884315657906416
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6883900635299228
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883503127929776
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883159736340696
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6882670884662204
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882313487322435
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882074551379427
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.6881772357970476
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6881513498267349
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881177654266357
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.688089412801406
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.6880772333878737
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880669665786455
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880443148039005
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880231961337003
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.6880066619387695

 End of epoch: 74 | Train Loss: 0.6867791038698855 | Training Time: 88 

 End of epoch: 74 | Eval Loss: 0.6895329441343035 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.755404943227768
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.721144038438797
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7094814320405324
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7038688257336616
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.7004380130767822
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6981733371814092
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6964869431086949
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.695310065150261
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.6943543712298076
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6936331021785737
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.69302173148502
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6924923131863276
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6920423631484692
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6916625640222005
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6913439885775248
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6910610370337963
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908056809621699
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6905936304065916
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6903682733836927
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6901971757411957
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.6900370226019905
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6898654249581424
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897598655327507
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896355715890725
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895172183513641
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.6894100219011307
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893178036919346
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.6892393665654318
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.6891587454697181
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.6890886328617731
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6890094795534688
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.6889275407418609
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888521440101393
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6887889816480525
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887311293397631
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6886996131804254
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886398782601227
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6885814273043682
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885299506859902
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884944313764572
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884356622288866
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884027720916839
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.688368159809778
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883302960883487
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6882883388466305
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882588634024496
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.688225956419681
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6881911392013232
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881652231119118
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881547185182572
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.688129483718498
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.688113922224595
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880817402083919
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.688064628287598
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880484108491377
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880231402814388

 End of epoch: 75 | Train Loss: 0.6867946243919103 | Training Time: 89 

 End of epoch: 75 | Eval Loss: 0.6891542843409947 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.755759310722351
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7214213222265243
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.710002326965332
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7042556956410408
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.700776926279068
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.698392567038536
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.69673011302948
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.695504193007946
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6945620079835256
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6937698268890381
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930979707024314
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6925902997454008
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6921702531667856
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6917835942336491
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6914359041055044
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6911458354443312
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908828142811271
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6906491945187251
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6904529537025251
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6902394884824753
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900842144375756
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6899207058277997
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.6898086071014404
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896808542311191
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.689562046289444
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894544131480731
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893597271707322
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.689267693885735
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891755932363971
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6891084525982539
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6890204066230404
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.6889661738649011
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888982444098501
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888207591631833
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887691986560821
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6887330705920856
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886814139984749
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6886388770843807
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885816673437755
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.688529941290617
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884779784737564
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6884283006191254
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6883815589339234
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883386630903591
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.688300371699863
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882631729478421
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882257114065454
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6881953213363886
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6881753285320438
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881437246799469
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881219729488971
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6881070954295305
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880829197055889
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880601368568562
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880449353564869
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880266697279045

 End of epoch: 76 | Train Loss: 0.6867992627937182 | Training Time: 88 

 End of epoch: 76 | Eval Loss: 0.6887752839497158 | Evaluating Time: 6 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7558916926383972
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.7213052064180374
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7097649614016215
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7040218517184258
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7004765117168427
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6982108523448308
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6966040177004678
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6953838482499123
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6944233000278472
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.6936639899015427
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6930273207751187
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6925039614240328
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6920520695356223
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6917091378143856
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.691399222612381
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910782661288977
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6908020482343786
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6905834446350734
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6903841442183445
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6901835703849792
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.690033279146467
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.6898913220925764
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897654650004014
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896358934541543
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895374429225921
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894280646856015
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893358870788857
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892381553139005
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891569147849905
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890918590625127
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6890125370794727
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889725059270859
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888959368069967
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.688836691309424
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887786677905492
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6887133715881242
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886625094993695
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6886103172051279
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885620653629303
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.68852224111557
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.688479943100999
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884262715067182
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883842063504596
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.688350719619881
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6883141035503811
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882793074068816
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882476324730731
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.688217007368803
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881914925818541
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881624765396118
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.688139932529599
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6881143216903393
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880758688134967
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.688047566678789
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880245921828531
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6879961217088358

 End of epoch: 77 | Train Loss: 0.6867781632769424 | Training Time: 88 

 End of epoch: 77 | Eval Loss: 0.6895536524908883 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7550559043884277
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7207038074731826
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7094021558761596
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7036620140075683
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7002867221832275
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.697931119799614
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6963387489318847
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6951893359422684
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6942345360914867
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6935091662406921
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6929187861355868
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6924163326621056
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.6920091761992528
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.6916214334113258
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6913026336828868
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6910200856626034
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.6907560678089366
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6905533717738257
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6903575203920665
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.6901653692126274
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900122296242487
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6898616080934351
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6897364815940028
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896333796282609
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895221564769745
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.689424074613131
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.689329136521728
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892094133155686
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.6891372549122777
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890706769625345
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.688998677269105
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889232225716114
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888530274232229
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.6887932793182485
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.688733389718192
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6886877588099903
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.688643663155066
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6886039718201286
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885668545197218
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6885192602872848
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884729024840565
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884292027779988
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883899618026822
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.6883569751273502
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6883346096674601
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882904688949171
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882721349279931
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882421009242534
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6882007764310253
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881725322008133
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.688145379225413
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6881154160086925
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880887584866218
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880634992210953
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880327431722121
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6880057743617467

 End of epoch: 78 | Train Loss: 0.6867834447759442 | Training Time: 88 

 End of epoch: 78 | Eval Loss: 0.6894221305847168 | Evaluating Time: 5 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.755235755443573
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.7209958583116531
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7096052805582682
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.703864136338234
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7004535794258118
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.6981902013222376
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6964705867426736
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6952316500246525
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6943129307693905
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6935484820604324
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6929727061228319
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6924135088920593
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6919596176881057
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6915688459362302
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6912330790360769
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.690971278399229
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6907422062228707
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6904999431636598
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6903146188510092
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6901537787914276
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6900050776345389
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6898599074645476
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6897221674089846
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6896107745667298
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.68950017786026
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6894000459175843
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.68930781505726
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892353500638689
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6891617265240899
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6890782958269119
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890067263956993
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889390809461474
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6888647532824314
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888024850803263
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.688737369946071
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6886804592278268
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886224453513686
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6885705337712639
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.6885169739906605
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.6884806995093823
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884452933218421
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.688401812456903
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883604116218035
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883142272179777
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6882856659094493
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882590976746186
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882242438641001
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882059541841348
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881799873040647
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.6881602452993393
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881307163659264
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6881000381249648
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880746193651883
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.6880510127102887
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880238444154912
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880032791623047

 End of epoch: 79 | Train Loss: 0.6867806954721434 | Training Time: 87 

 End of epoch: 79 | Eval Loss: 0.6895913992609296 | Evaluating Time: 5 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7555409073829651
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7213614672422409
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7097446163495381
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.7041543737053871
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7006222128868103
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6983017136653265
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.696690685408456
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954390496015549
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6944567799568176
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.693663918375969
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6930408266457644
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6925129468242327
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6920761181758001
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6916957893541881
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6913570666313171
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6910911370068789
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908339216428645
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.690600840581788
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.6904105860936014
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.6902113348245621
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900518718219939
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.6899211040951989
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897841272146805
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896572296818098
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895271282196045
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894139780448033
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6893293314509922
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6892376925264087
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.6891655504703522
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890846536556879
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6890114599658597
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889358840882778
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888656041838906
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6888211818302379
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887660009520394
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6886970493528578
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886390167313653
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.6885852004352369
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688536437963828
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.688498448729515
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884504995694974
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.688412696265039
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883697953335074
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883306258104064
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882947821087307
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882647522117781
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882393962525307
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882082659751176
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881713256543996
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881422415971756
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881159456337199
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880890119534272
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880616298261678
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880454224568826
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880261128598993
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.687999836994069

 End of epoch: 80 | Train Loss: 0.6867762528689562 | Training Time: 88 

 End of epoch: 80 | Eval Loss: 0.6894310372216361 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7550864815711975
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7210784971714019
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7098153432210287
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7040366873145103
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7006129956245423
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6983295241991679
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6967125330652509
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6955119788646698
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6945334871610006
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.6937635439634323
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6931159154935317
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6925812621911367
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.6921327852285826
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6917526266404561
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6914622851212819
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6911660872399807
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6909081564230077
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.69064139591323
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6904189263519488
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6902440977096558
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6900893875530788
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.689935427904129
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6898057346758635
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6896622454126676
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895560858249664
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.6894438436398139
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893623526449557
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6892667804445539
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891822541582173
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6891006300846736
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.6890143894380139
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6889447208493948
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.688881826581377
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6888200453099083
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887578342642103
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886960408753819
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6886473307738433
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885916962435371
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885512857865065
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6885063533484935
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884710407838589
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884268661340077
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883885322615158
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883457880128514
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6883156491650475
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882861520933068
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882467226779208
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6882156935830911
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881883045848535
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881581697463989
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.688131865566852
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6881037873717455
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880721994166105
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880515615145365
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880234033411199
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6880035503634385

 End of epoch: 81 | Train Loss: 0.6867768513417877 | Training Time: 88 

 End of epoch: 81 | Eval Loss: 0.6896801505770002 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7557331144809722
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7213509976863861
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7097394029299419
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.703961455821991
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7005125284194946
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6982194284598032
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6966261616774968
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6954377546906472
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6944279273351034
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6936666280031204
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.6930314259095626
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.6925656576951345
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6921336513299209
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.691774559020996
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6914511060714722
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6911633267998696
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6909004088710337
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906701091263029
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904637079489858
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.690283269584179
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6901113853568123
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899722305211153
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.6898498752842779
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6897192458311717
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.6896150128841401
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6895047052548482
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.6893961937339218
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892992349607604
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.6892190043268532
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6891330901781718
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6890427550961894
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6889633810147643
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6889113655596069
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6888402193784714
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.6887742693083627
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.688709263337983
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886585287145666
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.6885952394259603
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885421381546901
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6884913578629493
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.6884515432322897
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6884116125958306
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883771167245022
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.6883534290573814
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6883158620198567
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882797287858051
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882464635879435
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6882129353781541
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.6881848109011748
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881558821201325
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881296431317049
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6881005939382773
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.688075158393608
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880497673043499
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880271039225838
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.6880009985395841

 End of epoch: 82 | Train Loss: 0.6867720652470547 | Training Time: 89 

 End of epoch: 82 | Eval Loss: 0.6896260465894427 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7553498923778534
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.7209134608507156
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7095624645551045
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7038535416126251
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7003672003746033
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.697980460524559
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.696364345720836
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.695181281119585
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6942409349812402
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.693486338853836
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6928134809840809
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.692346363266309
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6919068941703209
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6915723000253949
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.691275536219279
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6909921728074551
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6907575607299805
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905653867456648
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6903495979936499
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.690187578201294
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900271645614079
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898814217610792
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897783232771832
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896615979572137
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895514962673187
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894670461232846
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.689348476462894
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892528352992875
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891518173546627
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890622103214263
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889713196985183
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.688899764046073
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888402050191705
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6887799766133813
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.688714280298778
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886397173007329
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6885987394564861
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885467813203209
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6884963384041419
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6884560745954513
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884184585838783
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6883737308638437
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883383569329284
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883059028874744
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6882683131429884
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.688239354154338
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882090152578151
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.6881856894741456
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881618794129819
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881364173889161
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.6881104163095063
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880929233936163
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880682521271255
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.688043929250152
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880171046473763
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.6880000547638961

 End of epoch: 83 | Train Loss: 0.6867729108945458 | Training Time: 88 

 End of epoch: 83 | Eval Loss: 0.6893630879265922 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7554408967494964
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.721107828617096
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7097276786963145
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7039537444710732
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7004665112495423
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6981979270776113
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.6965524349893842
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6953733645379543
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6943995939360724
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6936818051338196
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6930685287172144
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6925321405132612
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6921006743724529
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.691737853203501
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6914190745353699
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6911346919834613
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.6908782001803903
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6906373749176661
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6904370163616381
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6902758237719536
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6900934960160937
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899419372731989
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6897724475549615
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6896303561826547
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.689511688709259
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894065652902309
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.689283651334268
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6891826750976698
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6890985544385582
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6890232851107915
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.688948005437851
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6888956623151898
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888318972154097
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887709649170146
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887236401012966
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886749996079339
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.688620326808981
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885690132254049
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885268928148808
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884730546176434
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884393920258778
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.688400802158174
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883575402026952
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.6883283632722768
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6883039118183983
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882694533337718
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882433320613618
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882134980211655
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.6881838315603684
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881503521203994
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881314575672149
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880994060864816
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880729814745346
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880422238950377
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880179204724052
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.688003653713635

 End of epoch: 84 | Train Loss: 0.6867764164916182 | Training Time: 87 

 End of epoch: 84 | Eval Loss: 0.6902952364512852 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7556140899658204
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.721245190501213
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7097729424635569
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7041019961237908
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7006948387622833
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.698336797952652
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6966473775250571
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.6954731777310371
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6944921963744694
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6937355017662048
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6930927813053132
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.692605825761954
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6921181325729077
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6917216437203544
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6913599236806234
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.6910028006881476
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.6907205935786752
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.69052744143539
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6903334579969708
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.6901595729589463
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6900026602404458
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6898520125584169
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.6897335780703503
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6895746516684691
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6894582202434539
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893478437111928
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892680205680706
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6891699539763587
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6890748455606658
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6889934619267781
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.6889096306216332
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6888510635122657
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888044155005253
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887627138810999
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6887044538770403
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886582303378317
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6885977933535705
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885450436880715
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6884990618779109
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884655313193798
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884353580998211
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6883941895904995
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883653866690259
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883494207804853
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6883167499966092
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882773006739824
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882520996509714
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6882180608808994
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.6881794365084901
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881525266170502
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6881163954734802
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880979338517555
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880783595004172
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880512870020337
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.688029057004235
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6880091320191111

 End of epoch: 85 | Train Loss: 0.6867836046007882 | Training Time: 88 

 End of epoch: 85 | Eval Loss: 0.6891003761972699 | Evaluating Time: 5 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7552401065826416
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7211341023445129
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7098027169704437
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7040116101503372
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.7005738604068756
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6982444683710735
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6966501312596457
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6954690150916576
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6945000602139367
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6937235951423645
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.693061436848207
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6925611471136411
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920805674332838
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6917144111224584
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6913914088408152
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6910748321563005
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.690875332846361
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6906629926628537
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6904567774973418
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6902835726737976
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6901245664982568
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6899748669429259
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6898281229578931
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6896958604454995
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6895959537029266
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6894879361757865
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.6893814788924323
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6892589322158269
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6891754764935066
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.68909839173158
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6890063876105893
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6889260407537222
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888680049867341
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6888050875243019
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.688743553672518
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886800489491887
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6886189125679635
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885769944441946
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.6885270513021029
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884861399233341
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884516221720998
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6884039390654791
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883617391419965
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6883159828456965
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882857281631893
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882628290549568
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882385368042804
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.688209040959676
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881826259651963
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.6881567016839981
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881217722799263
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880958306101652
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.688070218293172
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880478986987362
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880121914906935
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879899336823395

 End of epoch: 86 | Train Loss: 0.6867643806786664 | Training Time: 89 

 End of epoch: 86 | Eval Loss: 0.6892591970307487 | Evaluating Time: 6 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.755598646402359
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7212744235992432
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7098296284675598
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.7040290400385857
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7006090152263641
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6982190569241842
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6966365924903325
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6954436518251896
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6944730268584357
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.693717365860939
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.693066141280261
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6925660043954849
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6921179968577165
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.69171005657741
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913610903422037
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6910497728735209
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6907686563099131
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6905727532174852
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.690392866260127
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6902022662758828
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900575135435377
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.6899242384867235
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897867083549499
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896522618830204
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895458528995514
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894476328904812
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.6893544420048042
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892372591154916
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891511261463166
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890700793266297
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889892301251811
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.688935623690486
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888589692838264
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6887938846560085
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887256343024117
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886661301056544
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886057605614533
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.6885507235401556
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885009328524272
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884529440104962
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884159202982739
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6883780276491529
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.688341114964596
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883078228343616
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882763248019749
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.6882511776426564
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882284399042738
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6882042693595092
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881694374035816
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881481677293777
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881230588052787
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880952882078978
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880675806189483
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880446225404739
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880233231457797
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879942739648478

 End of epoch: 87 | Train Loss: 0.6867681211074896 | Training Time: 90 

 End of epoch: 87 | Eval Loss: 0.689450911113194 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7553083896636963
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.7208116233348847
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7093817671140035
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.7037826403975487
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7003741586208343
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6981323649485905
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6964769303798676
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.695308443158865
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6943833569685618
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6936345452070236
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6930028752847152
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6924594566226006
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920398244490991
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.6917104065418244
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913528605302175
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910737175494432
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6908129709608415
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905873954296112
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6903783760572735
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6901931071281433
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900237812882378
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.6898840641433542
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897489983102549
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896448753774166
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895385837554932
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6894246674500979
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6893361160048732
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892521630440439
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891886803610572
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.68910868704319
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6890227048627792
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889584079384804
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888931167848182
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6888382939731373
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887732711860112
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6887140800555547
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.688663452541506
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6886121542830216
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885592167194073
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6885229834914207
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884815676910121
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6884401226327532
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6884090045163798
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.6883727727965875
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6883316416210599
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882842394320862
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882557891784831
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6882290260245403
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.68818866209108
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881745989322663
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881496604751138
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6881136795649162
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880876353326834
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880567477809059
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880354135686702
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6880058412040982

 End of epoch: 88 | Train Loss: 0.6867767383567 | Training Time: 88 

 End of epoch: 88 | Eval Loss: 0.6890676702771869 | Evaluating Time: 5 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7557384014129639
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7212245732545852
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.709819088379542
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7040521994233131
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7006633114814759
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6983403970797857
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6967287242412568
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.695412491261959
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.694448999563853
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6936931538581849
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.693048929084431
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6925553108255068
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6921055280245267
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6917012627635684
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.6913807785511017
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.6910478260368109
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908073972253238
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6905760953823725
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6903797943341105
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6902235892415046
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900710656529381
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6899146329272877
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6897844019143478
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6896724089980125
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895608894824982
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.6894482885415737
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893372456232707
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892404051763671
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.6891658632919706
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6891019628445307
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6890092999704422
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889610776677728
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.6888944481358383
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.6888415026314119
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887757916109902
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6887271978788906
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886721296890362
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6886139469711404
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885628880598607
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6885187216103077
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.6884728472407271
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884150151695524
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883802386217339
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883431429212744
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.6883033907413483
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.688267620102219
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882335038895303
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882044403503339
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881847539726569
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.688148958683014
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881257330670076
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880916096843206
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880629118883385
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880370156632529
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.6880150579322468
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.687989181386573

 End of epoch: 89 | Train Loss: 0.6867647838803519 | Training Time: 89 

 End of epoch: 89 | Eval Loss: 0.6892933334623065 | Evaluating Time: 6 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7553712606430054
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.721022117137909
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.7094653050104777
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.703707629442215
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.700268874168396
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6980475713809331
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6964301909719195
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6951904438436032
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6942952924304538
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.6934951293468475
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6928910380060023
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.692387277384599
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6919914126396179
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916207641363143
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6913042585055034
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910447258502245
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.690810681441251
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.690583210852411
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903867592937067
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6902035126090049
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6900389529409863
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6898705897006121
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6897370600182077
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.6896037392318248
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894935889244079
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6894019035192637
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6893010671491976
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6892124559198107
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.689128970688787
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6890559802452724
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.688983864553513
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6889232119545341
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6888645999359362
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.688810135511791
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.688752669436591
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.688689032693704
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6886358679951848
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6885872848724064
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.688537793740248
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6884908311069011
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6884498229840906
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6884083029769715
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6883785694144493
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6883432086218487
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6883153545856476
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6882749526397042
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.6882409606842285
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6882145757476489
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881925177817442
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6881733099222184
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6881490168618221
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6881267502903938
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880901251199111
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880646450652017
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6880408525466919
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6880193581538541

 End of epoch: 90 | Train Loss: 0.6867887062309063 | Training Time: 89 

 End of epoch: 90 | Eval Loss: 0.6891836268561227 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.7558111727237702
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7214144259691239
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7097567578156789
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7039123311638832
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7005043613910675
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6982140521208445
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965915943895068
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6953885585069657
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.694440468814638
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.6936724531650543
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6930387594483115
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6925150911013286
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920736079032604
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916644752025605
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913507390022278
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910804159939289
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6908262035425972
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6906165589888891
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6904457528340189
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6902341079711914
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900794721785046
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6899397430094806
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6898036609525265
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896777239938577
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6895626301765442
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894575497278801
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893692568496421
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892568879893848
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891697801392654
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.6890768178304036
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6890104228450405
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.688949479535222
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.6888903166308548
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6888137673630433
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887515778200967
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886932320064969
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6886350196761054
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.688586014979764
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885379652182261
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884969085454941
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884541512989416
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.688419261716661
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883732912152313
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883310229940848
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6883032491472032
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882638504971629
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882299894982196
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881945139418045
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881669217226457
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881431913375855
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6881097308560914
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880784529906053
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880557994797545
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880259099933836
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880104819211093
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.6879902203168188

 End of epoch: 91 | Train Loss: 0.6867705028668969 | Training Time: 92 

 End of epoch: 91 | Eval Loss: 0.6888803924833026 | Evaluating Time: 5 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7556679904460907
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7212654829025269
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7098393499851227
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7042128711938858
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7007013249397278
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6984506080547969
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6967441073485783
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6954595051705837
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6944866769843632
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6937350809574128
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6930760676210577
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6925483182072639
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6921250595496251
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6917278221675328
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6913912034034729
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.6911390956491232
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6908850203542148
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6906700048181745
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.6904647234239076
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.690285993218422
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6900942305723826
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.6899456346576864
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6897923391798269
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6896570454041163
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6895362527370453
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6894189559496366
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.6893343585508841
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6892341311488833
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6891423642635346
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6890588833888371
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889880474536649
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6889128090813756
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6888563127228708
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887921350843766
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6887270828655788
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.688668437467681
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6886148008140358
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.68857255829008
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6885226977177156
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.68847306355834
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6884293964723261
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6884003687472571
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883632389611976
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6883180620995435
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882823068565792
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.688244672961857
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6882223797605392
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881923190007607
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881634605174162
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.688142482161522
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6881152634527169
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880943643359038
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880763967082185
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880410662403813
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880158997665752
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879897720047405

 End of epoch: 92 | Train Loss: 0.6867614130003262 | Training Time: 91 

 End of epoch: 92 | Eval Loss: 0.689561494759151 | Evaluating Time: 5 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.755644291639328
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7212073147296906
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7094771862030029
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.703837288916111
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7004684209823608
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.698102577527364
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6965343807424818
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6953276537358761
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.6943103618092007
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6935175061225891
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6929232976653359
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6924222484230995
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6919867350504949
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6916095405817032
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.691290272474289
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6910079341381788
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.6907399444019093
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.6904998689889907
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6903161964918437
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6901446318626404
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6899998267491658
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6898397307504307
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6897056797276373
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6895911186933518
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.6894714329242706
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6893750582750027
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6892811753131726
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6891991340688297
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6891136360579524
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6890432608127594
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6889916737233439
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6889274846762419
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.688859060677615
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.688796602101887
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6887422095026289
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886884762181176
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6886341355942391
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885801649407337
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6885289343503805
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884829264879226
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6884358336285847
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6884051574128015
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883565571419028
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.6883202272382649
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882950121826595
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882605140623839
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882225034084726
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6882066834717989
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881702716253242
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881485636234284
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.688119355136273
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880869177671579
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880561515970051
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880353525832847
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.688009649515152
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.687989606069667

 End of epoch: 93 | Train Loss: 0.6867584953265907 | Training Time: 89 

 End of epoch: 93 | Eval Loss: 0.6891723786081586 | Evaluating Time: 5 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.75523641705513
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7207698851823807
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7093783577283224
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7037464275956153
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7003617441654205
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6981215556462605
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6964594858033316
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6952310532331467
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6942948228783078
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6935292690992355
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.692877202684229
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6923687289158503
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.6919225330536182
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6915198790175574
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6912061870098114
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6909394521266222
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6906986359287711
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6904775679111481
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6902824756346251
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901008906960487
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6899434021541051
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6897886612198569
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6896714143131091
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895564161241055
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.6894570162296295
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.6893340752674983
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6892306080570927
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6891361474990845
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6890543115550074
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6889838310082753
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889078990105659
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.6888452097773552
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888031816843784
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887538198162527
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6886993977001735
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886460782753097
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6886004444715139
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885571884481531
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6885039375378535
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884642516076565
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6884266161337131
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883942765848977
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883575767971749
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6883177824995734
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.688287298017078
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882552660029867
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6882349155050643
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.688209476818641
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.6881744651161894
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881466292142868
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6881192056571737
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880899699834677
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880570530891419
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880340174392418
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6880057941783558
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879782575581755

 End of epoch: 94 | Train Loss: 0.6867575230851638 | Training Time: 89 

 End of epoch: 94 | Eval Loss: 0.6891752907208034 | Evaluating Time: 5 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7556572437286377
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.721385446190834
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7098231494426728
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7040986403822899
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7005949974060058
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6982611248890559
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.6965888840811593
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6953375719487667
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6943581117524041
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6936517697572708
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6930400593714281
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6925177628795306
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6920656589361337
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916878713028771
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6913665874799093
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910638406872749
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.6908278198803173
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905963311592738
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6903897536428352
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902079728245735
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900543908278147
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.689904440262101
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.689757121645886
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.6896366737782955
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895218353271484
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6893993026935137
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6892982750027268
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.6892055043152401
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6891270577907562
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6890521490573883
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6889618744773249
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6888902306556701
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6888370190605972
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6887618988752365
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6886967962128775
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6886452890104717
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6885920382834769
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6885467512042899
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885067496544276
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6884686067700386
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884372836206017
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.6883960590476081
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883569042349971
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883206195451996
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.6882846109072367
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882500251998072
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.688210429409717
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.68818190805614
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.688164819381675
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881409050226212
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.688112258794261
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6880869910120964
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880579307394208
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880332347419527
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.688006680878726
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6879921430987971

 End of epoch: 95 | Train Loss: 0.6867614357872347 | Training Time: 89 

 End of epoch: 95 | Eval Loss: 0.6896143470491681 | Evaluating Time: 6 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7553060710430145
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.7212068498134613
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.709576294819514
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7039732307195663
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7005284440517425
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6982907692591349
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6966203246797834
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6953872866928578
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6943571170171102
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6936368083953858
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6929890925234015
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6924848755200704
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6920589442436512
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6916889935731888
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6913415018717448
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910381056368351
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6907663029782912
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6905387461185455
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6903455608769467
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6901815748214721
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6900162495317913
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6898610369725661
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.689744229161221
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6896154438455899
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6894942348003388
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.68937729207369
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6892998540842975
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6891985195023673
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6891264539340447
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.689054615298907
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.688960535295548
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6888809084892273
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888219896591071
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.68876253313878
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887152699061803
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6886556274361081
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886075942902952
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6885534510800713
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6885032586562327
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6884653222560883
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884233176708221
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6883991017228082
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883620540763057
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.6883255781097846
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6882780146598816
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882435902305272
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882170684794162
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.6881845682859421
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881524238051201
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881248196363449
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6880953003378475
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.6880710267103636
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880433976650238
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.688029901848899
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880042682994496
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879823549517563

 End of epoch: 96 | Train Loss: 0.6867576859693612 | Training Time: 90 

 End of epoch: 96 | Eval Loss: 0.6896261657987323 | Evaluating Time: 6 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7554896593093872
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7211831867694855
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7097192347049713
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7037852093577385
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.700417332649231
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6981005311012268
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6964902630874089
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6953023716807365
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6943358712726169
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.6935728162527084
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6929523056203669
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6924474621812503
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.6920146272732661
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6916409007140568
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6912966565291087
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6910095851868391
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.6907751405940337
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.690526369214058
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6903262110132921
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.6901488974690437
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.689984233038766
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.689843815294179
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6897108585938163
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6895749948918819
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6894715003967286
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.689374712568063
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6892752784269828
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.6891776393566813
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891018764726047
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890244807799657
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.6889418059779752
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6888646990060806
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6887905362880591
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6887319785707137
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6886765471526555
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6886126322878732
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6885625488049275
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885078954069238
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6884737195112767
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6884356439113617
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6883916713842532
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6883472485201699
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883178184198778
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6882779775695367
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.68824170033137
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882170192573381
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6881905591234247
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881601327409347
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881363439316652
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881070652008057
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6880912703626296
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880698914711292
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880432742946553
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.688020513344694
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6880048815770583
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879885319088187

 End of epoch: 97 | Train Loss: 0.6867584816122477 | Training Time: 91 

 End of epoch: 97 | Eval Loss: 0.6895238416535514 | Evaluating Time: 5 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7558347940444946
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7216109216213227
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7100863416989645
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7043317809700966
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7008364367485046
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6984144290288289
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6967613543782916
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6954563841223717
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6944490088356866
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6937127178907394
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6930724160237746
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6925744185845057
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920945043747242
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6917177149227687
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.691382954120636
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6910688038915396
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6908276992685655
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6906238036023246
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6904282613804466
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.6902381959557533
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900798408758073
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.6899256364865737
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6897924120011537
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896692186594009
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6895499753952027
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6894389989284369
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6893501955050009
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892407896263258
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891492360624774
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890730303525925
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6890061530374711
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.6889220854267478
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888523795387962
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887728010906893
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887236392498016
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.6886655444900195
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6886096147266594
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885674726021918
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6885225049960307
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884710557758809
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884207995926461
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6883893562214715
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883599889832873
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.6883275962688706
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882910276783837
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.68824822721274
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882205890848282
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881829189757506
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881632657683625
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881345530748367
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6881082022891325
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880892117436116
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880592033548175
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880385288485774
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6880077217925679
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6879809060267039

 End of epoch: 98 | Train Loss: 0.6867580439137146 | Training Time: 88 

 End of epoch: 98 | Eval Loss: 0.6897146616663251 | Evaluating Time: 6 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7552509486675263
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7207064807415009
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7094651480515798
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.703718937933445
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.7002435886859893
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6980294932921728
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6964011039052691
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6951934687793255
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6942757129669189
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6935817217826843
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6929742986505681
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6924883152047793
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6920341762212606
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6916421519858497
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913108313083649
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910067513585091
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6907656967639924
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.690565855966674
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903687834739685
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.690203495323658
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6900505613713037
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898769980127161
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897237230902132
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6895859745641549
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6894597430229187
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893524032372694
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892498305550327
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.689162358215877
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6890833194913535
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890023972590764
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889256138955393
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6888577330857515
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888033507448255
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887442949940177
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6886758017539978
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886189267039299
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6885658330208546
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885244029132943
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6884790000243065
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884299956262112
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6883859270956458
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6883474753016517
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883152952027876
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6882859958843751
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882518221272362
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882297421279161
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6881995387533878
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881674585243066
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881374093951012
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881104209423066
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6880911696190928
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880713042158347
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880388154173797
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880223162748196
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6880016618425195
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879862065826143

 End of epoch: 99 | Train Loss: 0.6867586706591918 | Training Time: 86 

 End of epoch: 99 | Eval Loss: 0.6886633634567261 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7557450532913208
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7213551819324493
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7098597844441732
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7040630176663398
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.700691123008728
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6983861049016317
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.6966494287763323
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6954569593071938
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6944465352429284
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6936359941959381
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929821263660084
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6924788425366084
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920329231482286
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916721888950893
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913550051053365
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910316582769156
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6907751346335692
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6904966202047136
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6902928496661939
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901054933667183
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.6899384731338137
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6897996154698458
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6896678719831549
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6895645583669344
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6894468269348144
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6893421975465921
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6892604969165943
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6891656049660274
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6890904991791166
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890019442637761
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.6889288604259491
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.6888553684577345
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.6888045885346152
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.6887460543828852
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6886934900283813
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886370698610942
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6885869752716374
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885415764231431
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6884928837800637
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884505379199982
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884149673508435
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883817187377385
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883453457854515
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883095678958026
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882775543795692
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882419986569364
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882140678294162
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881741584589084
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.68815144653223
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881217719316483
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6880947132905324
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880700543522835
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880482447597216
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880144708686404
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6879920251802965
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879744893738202

 End of epoch: 100 | Train Loss: 0.686752852823882 | Training Time: 90 

 End of epoch: 100 | Eval Loss: 0.6896951028278896 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9662361145019531 | Binary Cross Entropy With Logits Loss: 0.6896399855613708 
