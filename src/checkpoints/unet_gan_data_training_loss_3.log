Epoch: 1 | Iteration number: [10/565] 1% | Training loss: 0.7658655047416687
Epoch: 1 | Iteration number: [20/565] 3% | Training loss: 0.7310217529535293
Epoch: 1 | Iteration number: [30/565] 5% | Training loss: 0.7191408773263296
Epoch: 1 | Iteration number: [40/565] 7% | Training loss: 0.7131874680519104
Epoch: 1 | Iteration number: [50/565] 8% | Training loss: 0.7095822501182556
Epoch: 1 | Iteration number: [60/565] 10% | Training loss: 0.7071786562601725
Epoch: 1 | Iteration number: [70/565] 12% | Training loss: 0.7053811473505838
Epoch: 1 | Iteration number: [80/565] 14% | Training loss: 0.7040339209139347
Epoch: 1 | Iteration number: [90/565] 15% | Training loss: 0.7030124763647715
Epoch: 1 | Iteration number: [100/565] 17% | Training loss: 0.7021626526117325
Epoch: 1 | Iteration number: [110/565] 19% | Training loss: 0.7014655487103896
Epoch: 1 | Iteration number: [120/565] 21% | Training loss: 0.700848576426506
Epoch: 1 | Iteration number: [130/565] 23% | Training loss: 0.7003256779450636
Epoch: 1 | Iteration number: [140/565] 24% | Training loss: 0.6998879428420748
Epoch: 1 | Iteration number: [150/565] 26% | Training loss: 0.699495708545049
Epoch: 1 | Iteration number: [160/565] 28% | Training loss: 0.6991314604878426
Epoch: 1 | Iteration number: [170/565] 30% | Training loss: 0.6988258698407341
Epoch: 1 | Iteration number: [180/565] 31% | Training loss: 0.6985527551836438
Epoch: 1 | Iteration number: [190/565] 33% | Training loss: 0.698289113923123
Epoch: 1 | Iteration number: [200/565] 35% | Training loss: 0.6980492076277733
Epoch: 1 | Iteration number: [210/565] 37% | Training loss: 0.697846953357969
Epoch: 1 | Iteration number: [220/565] 38% | Training loss: 0.6976559086279436
Epoch: 1 | Iteration number: [230/565] 40% | Training loss: 0.6974732953569164
Epoch: 1 | Iteration number: [240/565] 42% | Training loss: 0.6972979945441087
Epoch: 1 | Iteration number: [250/565] 44% | Training loss: 0.6971522312164307
Epoch: 1 | Iteration number: [260/565] 46% | Training loss: 0.6969930087144558
Epoch: 1 | Iteration number: [270/565] 47% | Training loss: 0.6968532551217962
Epoch: 1 | Iteration number: [280/565] 49% | Training loss: 0.6967100379722458
Epoch: 1 | Iteration number: [290/565] 51% | Training loss: 0.6965765229586898
Epoch: 1 | Iteration number: [300/565] 53% | Training loss: 0.6964484878381093
Epoch: 1 | Iteration number: [310/565] 54% | Training loss: 0.6963232997925051
Epoch: 1 | Iteration number: [320/565] 56% | Training loss: 0.6962127992883325
Epoch: 1 | Iteration number: [330/565] 58% | Training loss: 0.6961108774849862
Epoch: 1 | Iteration number: [340/565] 60% | Training loss: 0.6960083610871259
Epoch: 1 | Iteration number: [350/565] 61% | Training loss: 0.6959167371477399
Epoch: 1 | Iteration number: [360/565] 63% | Training loss: 0.6958289566967223
Epoch: 1 | Iteration number: [370/565] 65% | Training loss: 0.6957365522513519
Epoch: 1 | Iteration number: [380/565] 67% | Training loss: 0.6956539883425361
Epoch: 1 | Iteration number: [390/565] 69% | Training loss: 0.6955752731897892
Epoch: 1 | Iteration number: [400/565] 70% | Training loss: 0.6954963751137256
Epoch: 1 | Iteration number: [410/565] 72% | Training loss: 0.6954091477684858
Epoch: 1 | Iteration number: [420/565] 74% | Training loss: 0.6953333789394015
Epoch: 1 | Iteration number: [430/565] 76% | Training loss: 0.6952532191609228
Epoch: 1 | Iteration number: [440/565] 77% | Training loss: 0.695187039131468
Epoch: 1 | Iteration number: [450/565] 79% | Training loss: 0.6951280072000292
Epoch: 1 | Iteration number: [460/565] 81% | Training loss: 0.6950539259806924
Epoch: 1 | Iteration number: [470/565] 83% | Training loss: 0.6949996842982921
Epoch: 1 | Iteration number: [480/565] 84% | Training loss: 0.6949393435070912
Epoch: 1 | Iteration number: [490/565] 86% | Training loss: 0.6948768014810524
Epoch: 1 | Iteration number: [500/565] 88% | Training loss: 0.6948183288574219
Epoch: 1 | Iteration number: [510/565] 90% | Training loss: 0.6947624273159925
Epoch: 1 | Iteration number: [520/565] 92% | Training loss: 0.6947031391354708
Epoch: 1 | Iteration number: [530/565] 93% | Training loss: 0.6946448047206087
Epoch: 1 | Iteration number: [540/565] 95% | Training loss: 0.69459620029838
Epoch: 1 | Iteration number: [550/565] 97% | Training loss: 0.6945366389101202
Epoch: 1 | Iteration number: [560/565] 99% | Training loss: 0.6944819798426969

 End of epoch: 1 | Train Loss: 0.6932340166210074 | Training Time: 88 

 End of epoch: 1 | Eval Loss: 0.6940684573990958 | Evaluating Time: 5 
Epoch: 2 | Iteration number: [10/565] 1% | Training loss: 0.7608225166797637
Epoch: 2 | Iteration number: [20/565] 3% | Training loss: 0.7262434303760529
Epoch: 2 | Iteration number: [30/565] 5% | Training loss: 0.7146395583947499
Epoch: 2 | Iteration number: [40/565] 7% | Training loss: 0.708921630680561
Epoch: 2 | Iteration number: [50/565] 8% | Training loss: 0.7054050672054291
Epoch: 2 | Iteration number: [60/565] 10% | Training loss: 0.7031042069196701
Epoch: 2 | Iteration number: [70/565] 12% | Training loss: 0.7015005826950074
Epoch: 2 | Iteration number: [80/565] 14% | Training loss: 0.7002212181687355
Epoch: 2 | Iteration number: [90/565] 15% | Training loss: 0.699245791302787
Epoch: 2 | Iteration number: [100/565] 17% | Training loss: 0.6984795361757279
Epoch: 2 | Iteration number: [110/565] 19% | Training loss: 0.6978292058814656
Epoch: 2 | Iteration number: [120/565] 21% | Training loss: 0.6973334337274234
Epoch: 2 | Iteration number: [130/565] 23% | Training loss: 0.6968739312428694
Epoch: 2 | Iteration number: [140/565] 24% | Training loss: 0.6964637334857668
Epoch: 2 | Iteration number: [150/565] 26% | Training loss: 0.6961076426506042
Epoch: 2 | Iteration number: [160/565] 28% | Training loss: 0.6958327803760767
Epoch: 2 | Iteration number: [170/565] 30% | Training loss: 0.6955483289325939
Epoch: 2 | Iteration number: [180/565] 31% | Training loss: 0.6953119532929526
Epoch: 2 | Iteration number: [190/565] 33% | Training loss: 0.6951060718611667
Epoch: 2 | Iteration number: [200/565] 35% | Training loss: 0.694892005622387
Epoch: 2 | Iteration number: [210/565] 37% | Training loss: 0.6947132133302234
Epoch: 2 | Iteration number: [220/565] 38% | Training loss: 0.6945607675747438
Epoch: 2 | Iteration number: [230/565] 40% | Training loss: 0.6944351794927016
Epoch: 2 | Iteration number: [240/565] 42% | Training loss: 0.6943141800661882
Epoch: 2 | Iteration number: [250/565] 44% | Training loss: 0.6941858005523681
Epoch: 2 | Iteration number: [260/565] 46% | Training loss: 0.6940853953361511
Epoch: 2 | Iteration number: [270/565] 47% | Training loss: 0.693970591492123
Epoch: 2 | Iteration number: [280/565] 49% | Training loss: 0.6938639962247439
Epoch: 2 | Iteration number: [290/565] 51% | Training loss: 0.6937631417965067
Epoch: 2 | Iteration number: [300/565] 53% | Training loss: 0.6936782292524973
Epoch: 2 | Iteration number: [310/565] 54% | Training loss: 0.6935937616132921
Epoch: 2 | Iteration number: [320/565] 56% | Training loss: 0.693511862680316
Epoch: 2 | Iteration number: [330/565] 58% | Training loss: 0.6934289341623133
Epoch: 2 | Iteration number: [340/565] 60% | Training loss: 0.6933519084663952
Epoch: 2 | Iteration number: [350/565] 61% | Training loss: 0.6932753453935896
Epoch: 2 | Iteration number: [360/565] 63% | Training loss: 0.6931848578982883
Epoch: 2 | Iteration number: [370/565] 65% | Training loss: 0.6931211647149679
Epoch: 2 | Iteration number: [380/565] 67% | Training loss: 0.6930576068790335
Epoch: 2 | Iteration number: [390/565] 69% | Training loss: 0.6929907407516088
Epoch: 2 | Iteration number: [400/565] 70% | Training loss: 0.6929221953451633
Epoch: 2 | Iteration number: [410/565] 72% | Training loss: 0.6928684830665588
Epoch: 2 | Iteration number: [420/565] 74% | Training loss: 0.6928198417027791
Epoch: 2 | Iteration number: [430/565] 76% | Training loss: 0.6927715648052304
Epoch: 2 | Iteration number: [440/565] 77% | Training loss: 0.6927189554680477
Epoch: 2 | Iteration number: [450/565] 79% | Training loss: 0.6926698860857222
Epoch: 2 | Iteration number: [460/565] 81% | Training loss: 0.6926246819288834
Epoch: 2 | Iteration number: [470/565] 83% | Training loss: 0.6925800655750518
Epoch: 2 | Iteration number: [480/565] 84% | Training loss: 0.6925461476047834
Epoch: 2 | Iteration number: [490/565] 86% | Training loss: 0.6925050593152338
Epoch: 2 | Iteration number: [500/565] 88% | Training loss: 0.6924657521247863
Epoch: 2 | Iteration number: [510/565] 90% | Training loss: 0.6924244410851422
Epoch: 2 | Iteration number: [520/565] 92% | Training loss: 0.6923893883824348
Epoch: 2 | Iteration number: [530/565] 93% | Training loss: 0.6923490989882991
Epoch: 2 | Iteration number: [540/565] 95% | Training loss: 0.6923109252143789
Epoch: 2 | Iteration number: [550/565] 97% | Training loss: 0.6922727645527232
Epoch: 2 | Iteration number: [560/565] 99% | Training loss: 0.6922381916216441

 End of epoch: 2 | Train Loss: 0.6909978338047467 | Training Time: 89 

 End of epoch: 2 | Eval Loss: 0.6932067275047302 | Evaluating Time: 6 
Epoch: 3 | Iteration number: [10/565] 1% | Training loss: 0.7592086374759675
Epoch: 3 | Iteration number: [20/565] 3% | Training loss: 0.7247698158025742
Epoch: 3 | Iteration number: [30/565] 5% | Training loss: 0.7133582055568695
Epoch: 3 | Iteration number: [40/565] 7% | Training loss: 0.7076374843716622
Epoch: 3 | Iteration number: [50/565] 8% | Training loss: 0.7041444456577302
Epoch: 3 | Iteration number: [60/565] 10% | Training loss: 0.7018258333206177
Epoch: 3 | Iteration number: [70/565] 12% | Training loss: 0.7001773170062474
Epoch: 3 | Iteration number: [80/565] 14% | Training loss: 0.6989054717123508
Epoch: 3 | Iteration number: [90/565] 15% | Training loss: 0.6979508777459462
Epoch: 3 | Iteration number: [100/565] 17% | Training loss: 0.6971527868509293
Epoch: 3 | Iteration number: [110/565] 19% | Training loss: 0.6965299552137202
Epoch: 3 | Iteration number: [120/565] 21% | Training loss: 0.6959882934888204
Epoch: 3 | Iteration number: [130/565] 23% | Training loss: 0.6955424721424396
Epoch: 3 | Iteration number: [140/565] 24% | Training loss: 0.6951287627220154
Epoch: 3 | Iteration number: [150/565] 26% | Training loss: 0.6947753127415975
Epoch: 3 | Iteration number: [160/565] 28% | Training loss: 0.6944909196346998
Epoch: 3 | Iteration number: [170/565] 30% | Training loss: 0.6942051249391893
Epoch: 3 | Iteration number: [180/565] 31% | Training loss: 0.6939918037917879
Epoch: 3 | Iteration number: [190/565] 33% | Training loss: 0.6937951360878192
Epoch: 3 | Iteration number: [200/565] 35% | Training loss: 0.6936256626248359
Epoch: 3 | Iteration number: [210/565] 37% | Training loss: 0.6934401832875752
Epoch: 3 | Iteration number: [220/565] 38% | Training loss: 0.6932887128808282
Epoch: 3 | Iteration number: [230/565] 40% | Training loss: 0.6931542572767838
Epoch: 3 | Iteration number: [240/565] 42% | Training loss: 0.6930168350537618
Epoch: 3 | Iteration number: [250/565] 44% | Training loss: 0.6929031777381897
Epoch: 3 | Iteration number: [260/565] 46% | Training loss: 0.6927772567822383
Epoch: 3 | Iteration number: [270/565] 47% | Training loss: 0.6926651018637198
Epoch: 3 | Iteration number: [280/565] 49% | Training loss: 0.6925601203526769
Epoch: 3 | Iteration number: [290/565] 51% | Training loss: 0.6924533365101649
Epoch: 3 | Iteration number: [300/565] 53% | Training loss: 0.692364452679952
Epoch: 3 | Iteration number: [310/565] 54% | Training loss: 0.692283506547251
Epoch: 3 | Iteration number: [320/565] 56% | Training loss: 0.6922077585011721
Epoch: 3 | Iteration number: [330/565] 58% | Training loss: 0.6921283983823024
Epoch: 3 | Iteration number: [340/565] 60% | Training loss: 0.6920501922859865
Epoch: 3 | Iteration number: [350/565] 61% | Training loss: 0.6919780436583928
Epoch: 3 | Iteration number: [360/565] 63% | Training loss: 0.6919145312574174
Epoch: 3 | Iteration number: [370/565] 65% | Training loss: 0.6918528767856391
Epoch: 3 | Iteration number: [380/565] 67% | Training loss: 0.691794280158846
Epoch: 3 | Iteration number: [390/565] 69% | Training loss: 0.6917307745187711
Epoch: 3 | Iteration number: [400/565] 70% | Training loss: 0.6916701205074787
Epoch: 3 | Iteration number: [410/565] 72% | Training loss: 0.6916190596615396
Epoch: 3 | Iteration number: [420/565] 74% | Training loss: 0.6915714676891055
Epoch: 3 | Iteration number: [430/565] 76% | Training loss: 0.6915231345697891
Epoch: 3 | Iteration number: [440/565] 77% | Training loss: 0.6914785023440014
Epoch: 3 | Iteration number: [450/565] 79% | Training loss: 0.691434356768926
Epoch: 3 | Iteration number: [460/565] 81% | Training loss: 0.691393829299056
Epoch: 3 | Iteration number: [470/565] 83% | Training loss: 0.691351349303063
Epoch: 3 | Iteration number: [480/565] 84% | Training loss: 0.6913186355183522
Epoch: 3 | Iteration number: [490/565] 86% | Training loss: 0.6912803997798842
Epoch: 3 | Iteration number: [500/565] 88% | Training loss: 0.691241025686264
Epoch: 3 | Iteration number: [510/565] 90% | Training loss: 0.6912038152124368
Epoch: 3 | Iteration number: [520/565] 92% | Training loss: 0.6911664170714525
Epoch: 3 | Iteration number: [530/565] 93% | Training loss: 0.6911373637757211
Epoch: 3 | Iteration number: [540/565] 95% | Training loss: 0.6911111842702936
Epoch: 3 | Iteration number: [550/565] 97% | Training loss: 0.6910760477456179
Epoch: 3 | Iteration number: [560/565] 99% | Training loss: 0.6910494015685149

 End of epoch: 3 | Train Loss: 0.6898147797162554 | Training Time: 91 

 End of epoch: 3 | Eval Loss: 0.692232004233769 | Evaluating Time: 5 
Epoch: 4 | Iteration number: [10/565] 1% | Training loss: 0.7582645237445831
Epoch: 4 | Iteration number: [20/565] 3% | Training loss: 0.7239849954843521
Epoch: 4 | Iteration number: [30/565] 5% | Training loss: 0.71243457198143
Epoch: 4 | Iteration number: [40/565] 7% | Training loss: 0.7067424312233925
Epoch: 4 | Iteration number: [50/565] 8% | Training loss: 0.7031861352920532
Epoch: 4 | Iteration number: [60/565] 10% | Training loss: 0.700870747367541
Epoch: 4 | Iteration number: [70/565] 12% | Training loss: 0.6991609522274562
Epoch: 4 | Iteration number: [80/565] 14% | Training loss: 0.6980083659291267
Epoch: 4 | Iteration number: [90/565] 15% | Training loss: 0.6970268567403157
Epoch: 4 | Iteration number: [100/565] 17% | Training loss: 0.6962555980682373
Epoch: 4 | Iteration number: [110/565] 19% | Training loss: 0.6956458519805562
Epoch: 4 | Iteration number: [120/565] 21% | Training loss: 0.695106939971447
Epoch: 4 | Iteration number: [130/565] 23% | Training loss: 0.694674186523144
Epoch: 4 | Iteration number: [140/565] 24% | Training loss: 0.694309885587011
Epoch: 4 | Iteration number: [150/565] 26% | Training loss: 0.6939647658665975
Epoch: 4 | Iteration number: [160/565] 28% | Training loss: 0.6936554864048958
Epoch: 4 | Iteration number: [170/565] 30% | Training loss: 0.6933755576610565
Epoch: 4 | Iteration number: [180/565] 31% | Training loss: 0.6931493245893054
Epoch: 4 | Iteration number: [190/565] 33% | Training loss: 0.6929135316296627
Epoch: 4 | Iteration number: [200/565] 35% | Training loss: 0.6927189573645591
Epoch: 4 | Iteration number: [210/565] 37% | Training loss: 0.6925337450844901
Epoch: 4 | Iteration number: [220/565] 38% | Training loss: 0.6923550635576248
Epoch: 4 | Iteration number: [230/565] 40% | Training loss: 0.6922101803447889
Epoch: 4 | Iteration number: [240/565] 42% | Training loss: 0.6920776610573133
Epoch: 4 | Iteration number: [250/565] 44% | Training loss: 0.6919575860500335
Epoch: 4 | Iteration number: [260/565] 46% | Training loss: 0.6918441254359026
Epoch: 4 | Iteration number: [270/565] 47% | Training loss: 0.6917271684717249
Epoch: 4 | Iteration number: [280/565] 49% | Training loss: 0.6916474702102797
Epoch: 4 | Iteration number: [290/565] 51% | Training loss: 0.69156968819684
Epoch: 4 | Iteration number: [300/565] 53% | Training loss: 0.6914885709683101
Epoch: 4 | Iteration number: [310/565] 54% | Training loss: 0.6914123915856885
Epoch: 4 | Iteration number: [320/565] 56% | Training loss: 0.6913395497947932
Epoch: 4 | Iteration number: [330/565] 58% | Training loss: 0.6912660418134747
Epoch: 4 | Iteration number: [340/565] 60% | Training loss: 0.6912037889747059
Epoch: 4 | Iteration number: [350/565] 61% | Training loss: 0.6911420404911042
Epoch: 4 | Iteration number: [360/565] 63% | Training loss: 0.6910796236660746
Epoch: 4 | Iteration number: [370/565] 65% | Training loss: 0.6910234022784878
Epoch: 4 | Iteration number: [380/565] 67% | Training loss: 0.6909685861123236
Epoch: 4 | Iteration number: [390/565] 69% | Training loss: 0.6909099543705964
Epoch: 4 | Iteration number: [400/565] 70% | Training loss: 0.690861649364233
Epoch: 4 | Iteration number: [410/565] 72% | Training loss: 0.6908133184037557
Epoch: 4 | Iteration number: [420/565] 74% | Training loss: 0.690768633428074
Epoch: 4 | Iteration number: [430/565] 76% | Training loss: 0.6907228286876235
Epoch: 4 | Iteration number: [440/565] 77% | Training loss: 0.6906763904473998
Epoch: 4 | Iteration number: [450/565] 79% | Training loss: 0.6906233718660143
Epoch: 4 | Iteration number: [460/565] 81% | Training loss: 0.6905812431936679
Epoch: 4 | Iteration number: [470/565] 83% | Training loss: 0.6905428800177067
Epoch: 4 | Iteration number: [480/565] 84% | Training loss: 0.6905024825284879
Epoch: 4 | Iteration number: [490/565] 86% | Training loss: 0.6904719749275519
Epoch: 4 | Iteration number: [500/565] 88% | Training loss: 0.6904443681240082
Epoch: 4 | Iteration number: [510/565] 90% | Training loss: 0.6904066644462885
Epoch: 4 | Iteration number: [520/565] 92% | Training loss: 0.6903768490140255
Epoch: 4 | Iteration number: [530/565] 93% | Training loss: 0.6903413321612016
Epoch: 4 | Iteration number: [540/565] 95% | Training loss: 0.6903121032096722
Epoch: 4 | Iteration number: [550/565] 97% | Training loss: 0.6902896669777957
Epoch: 4 | Iteration number: [560/565] 99% | Training loss: 0.6902568571269512

 End of epoch: 4 | Train Loss: 0.6890222025128593 | Training Time: 90 

 End of epoch: 4 | Eval Loss: 0.6917343395096915 | Evaluating Time: 5 
Epoch: 5 | Iteration number: [10/565] 1% | Training loss: 0.758177661895752
Epoch: 5 | Iteration number: [20/565] 3% | Training loss: 0.7233896523714065
Epoch: 5 | Iteration number: [30/565] 5% | Training loss: 0.7118511041005452
Epoch: 5 | Iteration number: [40/565] 7% | Training loss: 0.7059821769595146
Epoch: 5 | Iteration number: [50/565] 8% | Training loss: 0.7025673341751099
Epoch: 5 | Iteration number: [60/565] 10% | Training loss: 0.7002498656511307
Epoch: 5 | Iteration number: [70/565] 12% | Training loss: 0.698603298834392
Epoch: 5 | Iteration number: [80/565] 14% | Training loss: 0.6973536908626556
Epoch: 5 | Iteration number: [90/565] 15% | Training loss: 0.6964146885606978
Epoch: 5 | Iteration number: [100/565] 17% | Training loss: 0.6956405431032181
Epoch: 5 | Iteration number: [110/565] 19% | Training loss: 0.6950163543224335
Epoch: 5 | Iteration number: [120/565] 21% | Training loss: 0.6945029919346174
Epoch: 5 | Iteration number: [130/565] 23% | Training loss: 0.6940216307456677
Epoch: 5 | Iteration number: [140/565] 24% | Training loss: 0.6936327755451203
Epoch: 5 | Iteration number: [150/565] 26% | Training loss: 0.6933088950316111
Epoch: 5 | Iteration number: [160/565] 28% | Training loss: 0.6930347930639982
Epoch: 5 | Iteration number: [170/565] 30% | Training loss: 0.6927808733547435
Epoch: 5 | Iteration number: [180/565] 31% | Training loss: 0.6925486491786109
Epoch: 5 | Iteration number: [190/565] 33% | Training loss: 0.6923332085734919
Epoch: 5 | Iteration number: [200/565] 35% | Training loss: 0.692154156267643
Epoch: 5 | Iteration number: [210/565] 37% | Training loss: 0.6920048966294243
Epoch: 5 | Iteration number: [220/565] 38% | Training loss: 0.6918639678846706
Epoch: 5 | Iteration number: [230/565] 40% | Training loss: 0.6917168205199035
Epoch: 5 | Iteration number: [240/565] 42% | Training loss: 0.6915979837377866
Epoch: 5 | Iteration number: [250/565] 44% | Training loss: 0.6914810087680817
Epoch: 5 | Iteration number: [260/565] 46% | Training loss: 0.6913520223819293
Epoch: 5 | Iteration number: [270/565] 47% | Training loss: 0.6912517911858029
Epoch: 5 | Iteration number: [280/565] 49% | Training loss: 0.6911577573844365
Epoch: 5 | Iteration number: [290/565] 51% | Training loss: 0.6910671852785966
Epoch: 5 | Iteration number: [300/565] 53% | Training loss: 0.6909957601626714
Epoch: 5 | Iteration number: [310/565] 54% | Training loss: 0.6909079549774046
Epoch: 5 | Iteration number: [320/565] 56% | Training loss: 0.6908446628600359
Epoch: 5 | Iteration number: [330/565] 58% | Training loss: 0.6907693315636028
Epoch: 5 | Iteration number: [340/565] 60% | Training loss: 0.6906851300421883
Epoch: 5 | Iteration number: [350/565] 61% | Training loss: 0.6906138329846518
Epoch: 5 | Iteration number: [360/565] 63% | Training loss: 0.6905521311693721
Epoch: 5 | Iteration number: [370/565] 65% | Training loss: 0.6904850716526444
Epoch: 5 | Iteration number: [380/565] 67% | Training loss: 0.6904215956989087
Epoch: 5 | Iteration number: [390/565] 69% | Training loss: 0.6903658782824492
Epoch: 5 | Iteration number: [400/565] 70% | Training loss: 0.6903145115077496
Epoch: 5 | Iteration number: [410/565] 72% | Training loss: 0.6902581383542317
Epoch: 5 | Iteration number: [420/565] 74% | Training loss: 0.6901981596435819
Epoch: 5 | Iteration number: [430/565] 76% | Training loss: 0.6901551195355349
Epoch: 5 | Iteration number: [440/565] 77% | Training loss: 0.6901178817857395
Epoch: 5 | Iteration number: [450/565] 79% | Training loss: 0.6900805644194286
Epoch: 5 | Iteration number: [460/565] 81% | Training loss: 0.6900430724672649
Epoch: 5 | Iteration number: [470/565] 83% | Training loss: 0.690012458791124
Epoch: 5 | Iteration number: [480/565] 84% | Training loss: 0.6899790609876315
Epoch: 5 | Iteration number: [490/565] 86% | Training loss: 0.6899510839763953
Epoch: 5 | Iteration number: [500/565] 88% | Training loss: 0.6899190742969513
Epoch: 5 | Iteration number: [510/565] 90% | Training loss: 0.6898921991095823
Epoch: 5 | Iteration number: [520/565] 92% | Training loss: 0.6898599084753256
Epoch: 5 | Iteration number: [530/565] 93% | Training loss: 0.6898241866309688
Epoch: 5 | Iteration number: [540/565] 95% | Training loss: 0.6897958412214562
Epoch: 5 | Iteration number: [550/565] 97% | Training loss: 0.6897662473808636
Epoch: 5 | Iteration number: [560/565] 99% | Training loss: 0.6897359562771661

 End of epoch: 5 | Train Loss: 0.6885075014249413 | Training Time: 89 

 End of epoch: 5 | Eval Loss: 0.6915575265884399 | Evaluating Time: 5 
Epoch: 6 | Iteration number: [10/565] 1% | Training loss: 0.7569429516792298
Epoch: 6 | Iteration number: [20/565] 3% | Training loss: 0.7226910680532456
Epoch: 6 | Iteration number: [30/565] 5% | Training loss: 0.7111544946829478
Epoch: 6 | Iteration number: [40/565] 7% | Training loss: 0.7054911226034164
Epoch: 6 | Iteration number: [50/565] 8% | Training loss: 0.7020793414115906
Epoch: 6 | Iteration number: [60/565] 10% | Training loss: 0.6997828880945841
Epoch: 6 | Iteration number: [70/565] 12% | Training loss: 0.6981208920478821
Epoch: 6 | Iteration number: [80/565] 14% | Training loss: 0.6969102993607521
Epoch: 6 | Iteration number: [90/565] 15% | Training loss: 0.6958995242913564
Epoch: 6 | Iteration number: [100/565] 17% | Training loss: 0.695168519616127
Epoch: 6 | Iteration number: [110/565] 19% | Training loss: 0.694518812678077
Epoch: 6 | Iteration number: [120/565] 21% | Training loss: 0.6939969524741173
Epoch: 6 | Iteration number: [130/565] 23% | Training loss: 0.6935498613577623
Epoch: 6 | Iteration number: [140/565] 24% | Training loss: 0.6931520359856742
Epoch: 6 | Iteration number: [150/565] 26% | Training loss: 0.6928203268845876
Epoch: 6 | Iteration number: [160/565] 28% | Training loss: 0.6925296865403652
Epoch: 6 | Iteration number: [170/565] 30% | Training loss: 0.692270769441829
Epoch: 6 | Iteration number: [180/565] 31% | Training loss: 0.692051343454255
Epoch: 6 | Iteration number: [190/565] 33% | Training loss: 0.6918556285531897
Epoch: 6 | Iteration number: [200/565] 35% | Training loss: 0.6916642355918884
Epoch: 6 | Iteration number: [210/565] 37% | Training loss: 0.6915000100930532
Epoch: 6 | Iteration number: [220/565] 38% | Training loss: 0.6913382383910093
Epoch: 6 | Iteration number: [230/565] 40% | Training loss: 0.6911836111027262
Epoch: 6 | Iteration number: [240/565] 42% | Training loss: 0.6910471126437188
Epoch: 6 | Iteration number: [250/565] 44% | Training loss: 0.6909543044567108
Epoch: 6 | Iteration number: [260/565] 46% | Training loss: 0.6908487567534813
Epoch: 6 | Iteration number: [270/565] 47% | Training loss: 0.6907515927597329
Epoch: 6 | Iteration number: [280/565] 49% | Training loss: 0.690660873906953
Epoch: 6 | Iteration number: [290/565] 51% | Training loss: 0.690586780679637
Epoch: 6 | Iteration number: [300/565] 53% | Training loss: 0.6905001093943913
Epoch: 6 | Iteration number: [310/565] 54% | Training loss: 0.6904083719176631
Epoch: 6 | Iteration number: [320/565] 56% | Training loss: 0.6903435746207833
Epoch: 6 | Iteration number: [330/565] 58% | Training loss: 0.6902678592638536
Epoch: 6 | Iteration number: [340/565] 60% | Training loss: 0.6902164082316792
Epoch: 6 | Iteration number: [350/565] 61% | Training loss: 0.6901585798604147
Epoch: 6 | Iteration number: [360/565] 63% | Training loss: 0.6900995112127728
Epoch: 6 | Iteration number: [370/565] 65% | Training loss: 0.6900411871639458
Epoch: 6 | Iteration number: [380/565] 67% | Training loss: 0.6899822324514389
Epoch: 6 | Iteration number: [390/565] 69% | Training loss: 0.6899282596050165
Epoch: 6 | Iteration number: [400/565] 70% | Training loss: 0.6898795069754123
Epoch: 6 | Iteration number: [410/565] 72% | Training loss: 0.6898318975436978
Epoch: 6 | Iteration number: [420/565] 74% | Training loss: 0.6897919992605845
Epoch: 6 | Iteration number: [430/565] 76% | Training loss: 0.6897516981113788
Epoch: 6 | Iteration number: [440/565] 77% | Training loss: 0.6897140324115754
Epoch: 6 | Iteration number: [450/565] 79% | Training loss: 0.6896737060281966
Epoch: 6 | Iteration number: [460/565] 81% | Training loss: 0.6896450027175571
Epoch: 6 | Iteration number: [470/565] 83% | Training loss: 0.6896137596444881
Epoch: 6 | Iteration number: [480/565] 84% | Training loss: 0.6895742669701577
Epoch: 6 | Iteration number: [490/565] 86% | Training loss: 0.6895496162833
Epoch: 6 | Iteration number: [500/565] 88% | Training loss: 0.6895218303203583
Epoch: 6 | Iteration number: [510/565] 90% | Training loss: 0.689485961783166
Epoch: 6 | Iteration number: [520/565] 92% | Training loss: 0.689463418492904
Epoch: 6 | Iteration number: [530/565] 93% | Training loss: 0.6894373096385092
Epoch: 6 | Iteration number: [540/565] 95% | Training loss: 0.6894140760103862
Epoch: 6 | Iteration number: [550/565] 97% | Training loss: 0.6893918845870278
Epoch: 6 | Iteration number: [560/565] 99% | Training loss: 0.6893668429127762

 End of epoch: 6 | Train Loss: 0.6881323674083811 | Training Time: 90 

 End of epoch: 6 | Eval Loss: 0.6910782030650547 | Evaluating Time: 6 
Epoch: 7 | Iteration number: [10/565] 1% | Training loss: 0.7566095411777496
Epoch: 7 | Iteration number: [20/565] 3% | Training loss: 0.7222979366779327
Epoch: 7 | Iteration number: [30/565] 5% | Training loss: 0.7107844710350036
Epoch: 7 | Iteration number: [40/565] 7% | Training loss: 0.7051669776439666
Epoch: 7 | Iteration number: [50/565] 8% | Training loss: 0.7017422580718994
Epoch: 7 | Iteration number: [60/565] 10% | Training loss: 0.6994592428207398
Epoch: 7 | Iteration number: [70/565] 12% | Training loss: 0.6977618319647653
Epoch: 7 | Iteration number: [80/565] 14% | Training loss: 0.6965814709663392
Epoch: 7 | Iteration number: [90/565] 15% | Training loss: 0.6955966823630862
Epoch: 7 | Iteration number: [100/565] 17% | Training loss: 0.6947821593284607
Epoch: 7 | Iteration number: [110/565] 19% | Training loss: 0.6942090820182454
Epoch: 7 | Iteration number: [120/565] 21% | Training loss: 0.6936889285842578
Epoch: 7 | Iteration number: [130/565] 23% | Training loss: 0.6932690368248866
Epoch: 7 | Iteration number: [140/565] 24% | Training loss: 0.6929019753422055
Epoch: 7 | Iteration number: [150/565] 26% | Training loss: 0.6925895102818806
Epoch: 7 | Iteration number: [160/565] 28% | Training loss: 0.692280200496316
Epoch: 7 | Iteration number: [170/565] 30% | Training loss: 0.6919999115607318
Epoch: 7 | Iteration number: [180/565] 31% | Training loss: 0.6917679356204138
Epoch: 7 | Iteration number: [190/565] 33% | Training loss: 0.691564637108853
Epoch: 7 | Iteration number: [200/565] 35% | Training loss: 0.6913986113667488
Epoch: 7 | Iteration number: [210/565] 37% | Training loss: 0.6912320443562099
Epoch: 7 | Iteration number: [220/565] 38% | Training loss: 0.6910742534832521
Epoch: 7 | Iteration number: [230/565] 40% | Training loss: 0.6909578704315683
Epoch: 7 | Iteration number: [240/565] 42% | Training loss: 0.6908207299808661
Epoch: 7 | Iteration number: [250/565] 44% | Training loss: 0.6906956512928009
Epoch: 7 | Iteration number: [260/565] 46% | Training loss: 0.690590644799746
Epoch: 7 | Iteration number: [270/565] 47% | Training loss: 0.6904941790633732
Epoch: 7 | Iteration number: [280/565] 49% | Training loss: 0.690393732062408
Epoch: 7 | Iteration number: [290/565] 51% | Training loss: 0.6903169695673318
Epoch: 7 | Iteration number: [300/565] 53% | Training loss: 0.6902288275957108
Epoch: 7 | Iteration number: [310/565] 54% | Training loss: 0.6901624273869299
Epoch: 7 | Iteration number: [320/565] 56% | Training loss: 0.690081138536334
Epoch: 7 | Iteration number: [330/565] 58% | Training loss: 0.6900156608133605
Epoch: 7 | Iteration number: [340/565] 60% | Training loss: 0.689942700196715
Epoch: 7 | Iteration number: [350/565] 61% | Training loss: 0.6898911912100656
Epoch: 7 | Iteration number: [360/565] 63% | Training loss: 0.6898294400837687
Epoch: 7 | Iteration number: [370/565] 65% | Training loss: 0.6897814391432582
Epoch: 7 | Iteration number: [380/565] 67% | Training loss: 0.6897239184693287
Epoch: 7 | Iteration number: [390/565] 69% | Training loss: 0.6896706966253427
Epoch: 7 | Iteration number: [400/565] 70% | Training loss: 0.6896162025630475
Epoch: 7 | Iteration number: [410/565] 72% | Training loss: 0.6895687334421204
Epoch: 7 | Iteration number: [420/565] 74% | Training loss: 0.6895269930362702
Epoch: 7 | Iteration number: [430/565] 76% | Training loss: 0.6894899620566257
Epoch: 7 | Iteration number: [440/565] 77% | Training loss: 0.6894603601910851
Epoch: 7 | Iteration number: [450/565] 79% | Training loss: 0.6894226062297821
Epoch: 7 | Iteration number: [460/565] 81% | Training loss: 0.6893931653188623
Epoch: 7 | Iteration number: [470/565] 83% | Training loss: 0.6893542263102024
Epoch: 7 | Iteration number: [480/565] 84% | Training loss: 0.689329723144571
Epoch: 7 | Iteration number: [490/565] 86% | Training loss: 0.6892935948712485
Epoch: 7 | Iteration number: [500/565] 88% | Training loss: 0.6892682015895844
Epoch: 7 | Iteration number: [510/565] 90% | Training loss: 0.689233604482576
Epoch: 7 | Iteration number: [520/565] 92% | Training loss: 0.6892012212138909
Epoch: 7 | Iteration number: [530/565] 93% | Training loss: 0.6891719574073576
Epoch: 7 | Iteration number: [540/565] 95% | Training loss: 0.6891465621965903
Epoch: 7 | Iteration number: [550/565] 97% | Training loss: 0.689125101999803
Epoch: 7 | Iteration number: [560/565] 99% | Training loss: 0.6890982122293541

 End of epoch: 7 | Train Loss: 0.6878685472285853 | Training Time: 89 

 End of epoch: 7 | Eval Loss: 0.6906965630395072 | Evaluating Time: 6 
Epoch: 8 | Iteration number: [10/565] 1% | Training loss: 0.7568119049072266
Epoch: 8 | Iteration number: [20/565] 3% | Training loss: 0.7224370419979096
Epoch: 8 | Iteration number: [30/565] 5% | Training loss: 0.7108724315961202
Epoch: 8 | Iteration number: [40/565] 7% | Training loss: 0.7050549477338791
Epoch: 8 | Iteration number: [50/565] 8% | Training loss: 0.7015819597244263
Epoch: 8 | Iteration number: [60/565] 10% | Training loss: 0.6992854177951813
Epoch: 8 | Iteration number: [70/565] 12% | Training loss: 0.697696430342538
Epoch: 8 | Iteration number: [80/565] 14% | Training loss: 0.6964663289487362
Epoch: 8 | Iteration number: [90/565] 15% | Training loss: 0.6955070012145572
Epoch: 8 | Iteration number: [100/565] 17% | Training loss: 0.694695930480957
Epoch: 8 | Iteration number: [110/565] 19% | Training loss: 0.6940670831636949
Epoch: 8 | Iteration number: [120/565] 21% | Training loss: 0.6935661057631175
Epoch: 8 | Iteration number: [130/565] 23% | Training loss: 0.693124453838055
Epoch: 8 | Iteration number: [140/565] 24% | Training loss: 0.6927174325500216
Epoch: 8 | Iteration number: [150/565] 26% | Training loss: 0.6923945152759552
Epoch: 8 | Iteration number: [160/565] 28% | Training loss: 0.6920848716050386
Epoch: 8 | Iteration number: [170/565] 30% | Training loss: 0.691838758132037
Epoch: 8 | Iteration number: [180/565] 31% | Training loss: 0.6916243132617739
Epoch: 8 | Iteration number: [190/565] 33% | Training loss: 0.6914161926821658
Epoch: 8 | Iteration number: [200/565] 35% | Training loss: 0.6912205079197884
Epoch: 8 | Iteration number: [210/565] 37% | Training loss: 0.6910485605398814
Epoch: 8 | Iteration number: [220/565] 38% | Training loss: 0.690891572562131
Epoch: 8 | Iteration number: [230/565] 40% | Training loss: 0.6907502982927405
Epoch: 8 | Iteration number: [240/565] 42% | Training loss: 0.690610583126545
Epoch: 8 | Iteration number: [250/565] 44% | Training loss: 0.6904900586605072
Epoch: 8 | Iteration number: [260/565] 46% | Training loss: 0.6903888287452551
Epoch: 8 | Iteration number: [270/565] 47% | Training loss: 0.6903116416048121
Epoch: 8 | Iteration number: [280/565] 49% | Training loss: 0.6902200377413205
Epoch: 8 | Iteration number: [290/565] 51% | Training loss: 0.6901293727858313
Epoch: 8 | Iteration number: [300/565] 53% | Training loss: 0.690045251250267
Epoch: 8 | Iteration number: [310/565] 54% | Training loss: 0.6899785368673264
Epoch: 8 | Iteration number: [320/565] 56% | Training loss: 0.6899079406633973
Epoch: 8 | Iteration number: [330/565] 58% | Training loss: 0.6898460749423865
Epoch: 8 | Iteration number: [340/565] 60% | Training loss: 0.6897860218496884
Epoch: 8 | Iteration number: [350/565] 61% | Training loss: 0.6897276883465903
Epoch: 8 | Iteration number: [360/565] 63% | Training loss: 0.6896686987744437
Epoch: 8 | Iteration number: [370/565] 65% | Training loss: 0.6896176968071912
Epoch: 8 | Iteration number: [380/565] 67% | Training loss: 0.6895629115794835
Epoch: 8 | Iteration number: [390/565] 69% | Training loss: 0.6895031248911833
Epoch: 8 | Iteration number: [400/565] 70% | Training loss: 0.6894472296535968
Epoch: 8 | Iteration number: [410/565] 72% | Training loss: 0.6894035026794527
Epoch: 8 | Iteration number: [420/565] 74% | Training loss: 0.6893569540409815
Epoch: 8 | Iteration number: [430/565] 76% | Training loss: 0.6893105176992195
Epoch: 8 | Iteration number: [440/565] 77% | Training loss: 0.6892769106409766
Epoch: 8 | Iteration number: [450/565] 79% | Training loss: 0.6892316495047676
Epoch: 8 | Iteration number: [460/565] 81% | Training loss: 0.6891965295957483
Epoch: 8 | Iteration number: [470/565] 83% | Training loss: 0.6891574821573623
Epoch: 8 | Iteration number: [480/565] 84% | Training loss: 0.6891270402818919
Epoch: 8 | Iteration number: [490/565] 86% | Training loss: 0.6890910582883017
Epoch: 8 | Iteration number: [500/565] 88% | Training loss: 0.689067748427391
Epoch: 8 | Iteration number: [510/565] 90% | Training loss: 0.6890399153326072
Epoch: 8 | Iteration number: [520/565] 92% | Training loss: 0.6890183972624632
Epoch: 8 | Iteration number: [530/565] 93% | Training loss: 0.6889827817116143
Epoch: 8 | Iteration number: [540/565] 95% | Training loss: 0.6889541409633778
Epoch: 8 | Iteration number: [550/565] 97% | Training loss: 0.6889319949800318
Epoch: 8 | Iteration number: [560/565] 99% | Training loss: 0.6889037779399327

 End of epoch: 8 | Train Loss: 0.6876761532462804 | Training Time: 87 

 End of epoch: 8 | Eval Loss: 0.6906115072114127 | Evaluating Time: 6 
Epoch: 9 | Iteration number: [10/565] 1% | Training loss: 0.7561149299144745
Epoch: 9 | Iteration number: [20/565] 3% | Training loss: 0.7219305723905564
Epoch: 9 | Iteration number: [30/565] 5% | Training loss: 0.7105233271916708
Epoch: 9 | Iteration number: [40/565] 7% | Training loss: 0.7048358276486397
Epoch: 9 | Iteration number: [50/565] 8% | Training loss: 0.7013480079174041
Epoch: 9 | Iteration number: [60/565] 10% | Training loss: 0.6990662942330043
Epoch: 9 | Iteration number: [70/565] 12% | Training loss: 0.6974338182381221
Epoch: 9 | Iteration number: [80/565] 14% | Training loss: 0.69622196033597
Epoch: 9 | Iteration number: [90/565] 15% | Training loss: 0.6952731702062819
Epoch: 9 | Iteration number: [100/565] 17% | Training loss: 0.6945258998870849
Epoch: 9 | Iteration number: [110/565] 19% | Training loss: 0.6939043738625267
Epoch: 9 | Iteration number: [120/565] 21% | Training loss: 0.6933557331562042
Epoch: 9 | Iteration number: [130/565] 23% | Training loss: 0.692896181344986
Epoch: 9 | Iteration number: [140/565] 24% | Training loss: 0.6925202889101846
Epoch: 9 | Iteration number: [150/565] 26% | Training loss: 0.6921882077058157
Epoch: 9 | Iteration number: [160/565] 28% | Training loss: 0.6919063992798329
Epoch: 9 | Iteration number: [170/565] 30% | Training loss: 0.6916504775776583
Epoch: 9 | Iteration number: [180/565] 31% | Training loss: 0.6914298478100035
Epoch: 9 | Iteration number: [190/565] 33% | Training loss: 0.691248472427067
Epoch: 9 | Iteration number: [200/565] 35% | Training loss: 0.6910618552565575
Epoch: 9 | Iteration number: [210/565] 37% | Training loss: 0.6909041748160407
Epoch: 9 | Iteration number: [220/565] 38% | Training loss: 0.6907616490667516
Epoch: 9 | Iteration number: [230/565] 40% | Training loss: 0.6906179746855861
Epoch: 9 | Iteration number: [240/565] 42% | Training loss: 0.6904951771100362
Epoch: 9 | Iteration number: [250/565] 44% | Training loss: 0.6903708622455597
Epoch: 9 | Iteration number: [260/565] 46% | Training loss: 0.6902468011929439
Epoch: 9 | Iteration number: [270/565] 47% | Training loss: 0.6901484111944834
Epoch: 9 | Iteration number: [280/565] 49% | Training loss: 0.690045901281493
Epoch: 9 | Iteration number: [290/565] 51% | Training loss: 0.6899723242069112
Epoch: 9 | Iteration number: [300/565] 53% | Training loss: 0.689913693467776
Epoch: 9 | Iteration number: [310/565] 54% | Training loss: 0.6898484431928203
Epoch: 9 | Iteration number: [320/565] 56% | Training loss: 0.6897693092003465
Epoch: 9 | Iteration number: [330/565] 58% | Training loss: 0.6896845266674504
Epoch: 9 | Iteration number: [340/565] 60% | Training loss: 0.689614166582332
Epoch: 9 | Iteration number: [350/565] 61% | Training loss: 0.6895424469879695
Epoch: 9 | Iteration number: [360/565] 63% | Training loss: 0.6894902502497037
Epoch: 9 | Iteration number: [370/565] 65% | Training loss: 0.689432141587541
Epoch: 9 | Iteration number: [380/565] 67% | Training loss: 0.6893768373288607
Epoch: 9 | Iteration number: [390/565] 69% | Training loss: 0.6893103821155352
Epoch: 9 | Iteration number: [400/565] 70% | Training loss: 0.6892672702670097
Epoch: 9 | Iteration number: [410/565] 72% | Training loss: 0.6892146123618614
Epoch: 9 | Iteration number: [420/565] 74% | Training loss: 0.6891813075258618
Epoch: 9 | Iteration number: [430/565] 76% | Training loss: 0.6891387565191402
Epoch: 9 | Iteration number: [440/565] 77% | Training loss: 0.6891087387095798
Epoch: 9 | Iteration number: [450/565] 79% | Training loss: 0.6890652820799086
Epoch: 9 | Iteration number: [460/565] 81% | Training loss: 0.6890250404243884
Epoch: 9 | Iteration number: [470/565] 83% | Training loss: 0.6889886645560569
Epoch: 9 | Iteration number: [480/565] 84% | Training loss: 0.6889588213215272
Epoch: 9 | Iteration number: [490/565] 86% | Training loss: 0.6889343762884335
Epoch: 9 | Iteration number: [500/565] 88% | Training loss: 0.6889130969047547
Epoch: 9 | Iteration number: [510/565] 90% | Training loss: 0.6888746041877597
Epoch: 9 | Iteration number: [520/565] 92% | Training loss: 0.6888493683475715
Epoch: 9 | Iteration number: [530/565] 93% | Training loss: 0.6888300831587809
Epoch: 9 | Iteration number: [540/565] 95% | Training loss: 0.6887990122592008
Epoch: 9 | Iteration number: [550/565] 97% | Training loss: 0.6887765218994835
Epoch: 9 | Iteration number: [560/565] 99% | Training loss: 0.6887545615434647

 End of epoch: 9 | Train Loss: 0.6875292360255149 | Training Time: 89 

 End of epoch: 9 | Eval Loss: 0.6908235975674221 | Evaluating Time: 6 
Epoch: 10 | Iteration number: [10/565] 1% | Training loss: 0.7557330071926117
Epoch: 10 | Iteration number: [20/565] 3% | Training loss: 0.7215425878763199
Epoch: 10 | Iteration number: [30/565] 5% | Training loss: 0.7100553870201111
Epoch: 10 | Iteration number: [40/565] 7% | Training loss: 0.7044296562671661
Epoch: 10 | Iteration number: [50/565] 8% | Training loss: 0.7010425090789795
Epoch: 10 | Iteration number: [60/565] 10% | Training loss: 0.6987847646077474
Epoch: 10 | Iteration number: [70/565] 12% | Training loss: 0.69718000463077
Epoch: 10 | Iteration number: [80/565] 14% | Training loss: 0.69595031067729
Epoch: 10 | Iteration number: [90/565] 15% | Training loss: 0.6950167563226488
Epoch: 10 | Iteration number: [100/565] 17% | Training loss: 0.6942607176303863
Epoch: 10 | Iteration number: [110/565] 19% | Training loss: 0.6936147418889133
Epoch: 10 | Iteration number: [120/565] 21% | Training loss: 0.6930892010529836
Epoch: 10 | Iteration number: [130/565] 23% | Training loss: 0.6926483612794142
Epoch: 10 | Iteration number: [140/565] 24% | Training loss: 0.6922854866300311
Epoch: 10 | Iteration number: [150/565] 26% | Training loss: 0.6919570183753967
Epoch: 10 | Iteration number: [160/565] 28% | Training loss: 0.6916804019361734
Epoch: 10 | Iteration number: [170/565] 30% | Training loss: 0.6913938224315643
Epoch: 10 | Iteration number: [180/565] 31% | Training loss: 0.6911974708239238
Epoch: 10 | Iteration number: [190/565] 33% | Training loss: 0.6909986420681602
Epoch: 10 | Iteration number: [200/565] 35% | Training loss: 0.6908307373523712
Epoch: 10 | Iteration number: [210/565] 37% | Training loss: 0.6906498599620092
Epoch: 10 | Iteration number: [220/565] 38% | Training loss: 0.6905087928880345
Epoch: 10 | Iteration number: [230/565] 40% | Training loss: 0.6903507388156394
Epoch: 10 | Iteration number: [240/565] 42% | Training loss: 0.6902489667137464
Epoch: 10 | Iteration number: [250/565] 44% | Training loss: 0.6901364123821259
Epoch: 10 | Iteration number: [260/565] 46% | Training loss: 0.6900313927577092
Epoch: 10 | Iteration number: [270/565] 47% | Training loss: 0.68993103923621
Epoch: 10 | Iteration number: [280/565] 49% | Training loss: 0.6898303749305862
Epoch: 10 | Iteration number: [290/565] 51% | Training loss: 0.6897370973537709
Epoch: 10 | Iteration number: [300/565] 53% | Training loss: 0.689662663936615
Epoch: 10 | Iteration number: [310/565] 54% | Training loss: 0.6896050084021783
Epoch: 10 | Iteration number: [320/565] 56% | Training loss: 0.6895351463928818
Epoch: 10 | Iteration number: [330/565] 58% | Training loss: 0.6894651557459975
Epoch: 10 | Iteration number: [340/565] 60% | Training loss: 0.6894084800692165
Epoch: 10 | Iteration number: [350/565] 61% | Training loss: 0.6893610056809016
Epoch: 10 | Iteration number: [360/565] 63% | Training loss: 0.6893110086520513
Epoch: 10 | Iteration number: [370/565] 65% | Training loss: 0.6892583884097434
Epoch: 10 | Iteration number: [380/565] 67% | Training loss: 0.6892015708120246
Epoch: 10 | Iteration number: [390/565] 69% | Training loss: 0.6891514472472362
Epoch: 10 | Iteration number: [400/565] 70% | Training loss: 0.6891104313731193
Epoch: 10 | Iteration number: [410/565] 72% | Training loss: 0.6890786796081357
Epoch: 10 | Iteration number: [420/565] 74% | Training loss: 0.6890482026906241
Epoch: 10 | Iteration number: [430/565] 76% | Training loss: 0.6890021006728327
Epoch: 10 | Iteration number: [440/565] 77% | Training loss: 0.6889643044634299
Epoch: 10 | Iteration number: [450/565] 79% | Training loss: 0.6889266628689236
Epoch: 10 | Iteration number: [460/565] 81% | Training loss: 0.6888789347980333
Epoch: 10 | Iteration number: [470/565] 83% | Training loss: 0.6888363722791063
Epoch: 10 | Iteration number: [480/565] 84% | Training loss: 0.6888057416925828
Epoch: 10 | Iteration number: [490/565] 86% | Training loss: 0.6887765946436901
Epoch: 10 | Iteration number: [500/565] 88% | Training loss: 0.6887511833906174
Epoch: 10 | Iteration number: [510/565] 90% | Training loss: 0.6887204873795603
Epoch: 10 | Iteration number: [520/565] 92% | Training loss: 0.6887005404784129
Epoch: 10 | Iteration number: [530/565] 93% | Training loss: 0.688673050336118
Epoch: 10 | Iteration number: [540/565] 95% | Training loss: 0.6886442177825504
Epoch: 10 | Iteration number: [550/565] 97% | Training loss: 0.6886215027895841
Epoch: 10 | Iteration number: [560/565] 99% | Training loss: 0.6886002170188087

 End of epoch: 10 | Train Loss: 0.6873688839178169 | Training Time: 89 

 End of epoch: 10 | Eval Loss: 0.6901253717286246 | Evaluating Time: 6 
Epoch: 11 | Iteration number: [10/565] 1% | Training loss: 0.7561282098293305
Epoch: 11 | Iteration number: [20/565] 3% | Training loss: 0.7218431651592254
Epoch: 11 | Iteration number: [30/565] 5% | Training loss: 0.7103159050146739
Epoch: 11 | Iteration number: [40/565] 7% | Training loss: 0.7045620933175087
Epoch: 11 | Iteration number: [50/565] 8% | Training loss: 0.7011307454109192
Epoch: 11 | Iteration number: [60/565] 10% | Training loss: 0.6988474627335867
Epoch: 11 | Iteration number: [70/565] 12% | Training loss: 0.697188424212592
Epoch: 11 | Iteration number: [80/565] 14% | Training loss: 0.6959832966327667
Epoch: 11 | Iteration number: [90/565] 15% | Training loss: 0.6949721766842736
Epoch: 11 | Iteration number: [100/565] 17% | Training loss: 0.6942037862539291
Epoch: 11 | Iteration number: [110/565] 19% | Training loss: 0.6935554022138769
Epoch: 11 | Iteration number: [120/565] 21% | Training loss: 0.6930067032575608
Epoch: 11 | Iteration number: [130/565] 23% | Training loss: 0.6925764386470501
Epoch: 11 | Iteration number: [140/565] 24% | Training loss: 0.692206181372915
Epoch: 11 | Iteration number: [150/565] 26% | Training loss: 0.6918885632356008
Epoch: 11 | Iteration number: [160/565] 28% | Training loss: 0.6916011612862348
Epoch: 11 | Iteration number: [170/565] 30% | Training loss: 0.6913346188909867
Epoch: 11 | Iteration number: [180/565] 31% | Training loss: 0.6911285552713606
Epoch: 11 | Iteration number: [190/565] 33% | Training loss: 0.6909388228466636
Epoch: 11 | Iteration number: [200/565] 35% | Training loss: 0.6907618030905723
Epoch: 11 | Iteration number: [210/565] 37% | Training loss: 0.6905789977028256
Epoch: 11 | Iteration number: [220/565] 38% | Training loss: 0.6904326682740992
Epoch: 11 | Iteration number: [230/565] 40% | Training loss: 0.6902831779873889
Epoch: 11 | Iteration number: [240/565] 42% | Training loss: 0.6901634720464548
Epoch: 11 | Iteration number: [250/565] 44% | Training loss: 0.6900361080169678
Epoch: 11 | Iteration number: [260/565] 46% | Training loss: 0.6899230950153791
Epoch: 11 | Iteration number: [270/565] 47% | Training loss: 0.6898274666733212
Epoch: 11 | Iteration number: [280/565] 49% | Training loss: 0.689740558394364
Epoch: 11 | Iteration number: [290/565] 51% | Training loss: 0.6896804634867043
Epoch: 11 | Iteration number: [300/565] 53% | Training loss: 0.6896006737152736
Epoch: 11 | Iteration number: [310/565] 54% | Training loss: 0.6895325558800851
Epoch: 11 | Iteration number: [320/565] 56% | Training loss: 0.6894674738869071
Epoch: 11 | Iteration number: [330/565] 58% | Training loss: 0.6894076033072039
Epoch: 11 | Iteration number: [340/565] 60% | Training loss: 0.6893302421359455
Epoch: 11 | Iteration number: [350/565] 61% | Training loss: 0.6892579099110194
Epoch: 11 | Iteration number: [360/565] 63% | Training loss: 0.6891951872242822
Epoch: 11 | Iteration number: [370/565] 65% | Training loss: 0.6891329406081019
Epoch: 11 | Iteration number: [380/565] 67% | Training loss: 0.6890914852681913
Epoch: 11 | Iteration number: [390/565] 69% | Training loss: 0.6890397441692842
Epoch: 11 | Iteration number: [400/565] 70% | Training loss: 0.6889911207556725
Epoch: 11 | Iteration number: [410/565] 72% | Training loss: 0.6889590395659935
Epoch: 11 | Iteration number: [420/565] 74% | Training loss: 0.6889293401014237
Epoch: 11 | Iteration number: [430/565] 76% | Training loss: 0.6888964999553769
Epoch: 11 | Iteration number: [440/565] 77% | Training loss: 0.6888656721873717
Epoch: 11 | Iteration number: [450/565] 79% | Training loss: 0.6888171521822611
Epoch: 11 | Iteration number: [460/565] 81% | Training loss: 0.6887868316277214
Epoch: 11 | Iteration number: [470/565] 83% | Training loss: 0.6887535178914983
Epoch: 11 | Iteration number: [480/565] 84% | Training loss: 0.6887229433904092
Epoch: 11 | Iteration number: [490/565] 86% | Training loss: 0.6886912710812627
Epoch: 11 | Iteration number: [500/565] 88% | Training loss: 0.6886621090173721
Epoch: 11 | Iteration number: [510/565] 90% | Training loss: 0.688635967058294
Epoch: 11 | Iteration number: [520/565] 92% | Training loss: 0.6886009607177515
Epoch: 11 | Iteration number: [530/565] 93% | Training loss: 0.6885790709054695
Epoch: 11 | Iteration number: [540/565] 95% | Training loss: 0.6885627934226284
Epoch: 11 | Iteration number: [550/565] 97% | Training loss: 0.6885349561951377
Epoch: 11 | Iteration number: [560/565] 99% | Training loss: 0.688518634970699

 End of epoch: 11 | Train Loss: 0.6872873601660264 | Training Time: 87 

 End of epoch: 11 | Eval Loss: 0.6896101066044399 | Evaluating Time: 5 
Epoch: 12 | Iteration number: [10/565] 1% | Training loss: 0.7564574718475342
Epoch: 12 | Iteration number: [20/565] 3% | Training loss: 0.7217831373214721
Epoch: 12 | Iteration number: [30/565] 5% | Training loss: 0.7104914168516795
Epoch: 12 | Iteration number: [40/565] 7% | Training loss: 0.7048739284276963
Epoch: 12 | Iteration number: [50/565] 8% | Training loss: 0.7013270473480224
Epoch: 12 | Iteration number: [60/565] 10% | Training loss: 0.6989390035470326
Epoch: 12 | Iteration number: [70/565] 12% | Training loss: 0.6972775936126709
Epoch: 12 | Iteration number: [80/565] 14% | Training loss: 0.6959996223449707
Epoch: 12 | Iteration number: [90/565] 15% | Training loss: 0.694969982571072
Epoch: 12 | Iteration number: [100/565] 17% | Training loss: 0.6941965019702911
Epoch: 12 | Iteration number: [110/565] 19% | Training loss: 0.6935068049214103
Epoch: 12 | Iteration number: [120/565] 21% | Training loss: 0.6930109883348147
Epoch: 12 | Iteration number: [130/565] 23% | Training loss: 0.692528885602951
Epoch: 12 | Iteration number: [140/565] 24% | Training loss: 0.6921668993575233
Epoch: 12 | Iteration number: [150/565] 26% | Training loss: 0.6918301701545715
Epoch: 12 | Iteration number: [160/565] 28% | Training loss: 0.6915233511477709
Epoch: 12 | Iteration number: [170/565] 30% | Training loss: 0.691301770771251
Epoch: 12 | Iteration number: [180/565] 31% | Training loss: 0.6910767138004303
Epoch: 12 | Iteration number: [190/565] 33% | Training loss: 0.6908574716040963
Epoch: 12 | Iteration number: [200/565] 35% | Training loss: 0.6906856933236122
Epoch: 12 | Iteration number: [210/565] 37% | Training loss: 0.6905367910861969
Epoch: 12 | Iteration number: [220/565] 38% | Training loss: 0.6903708709911867
Epoch: 12 | Iteration number: [230/565] 40% | Training loss: 0.6902260611886564
Epoch: 12 | Iteration number: [240/565] 42% | Training loss: 0.6901355281472206
Epoch: 12 | Iteration number: [250/565] 44% | Training loss: 0.690023325920105
Epoch: 12 | Iteration number: [260/565] 46% | Training loss: 0.6899133521776933
Epoch: 12 | Iteration number: [270/565] 47% | Training loss: 0.6898047111652515
Epoch: 12 | Iteration number: [280/565] 49% | Training loss: 0.6897121825388499
Epoch: 12 | Iteration number: [290/565] 51% | Training loss: 0.6896232023321349
Epoch: 12 | Iteration number: [300/565] 53% | Training loss: 0.6895406730969746
Epoch: 12 | Iteration number: [310/565] 54% | Training loss: 0.6894615007985023
Epoch: 12 | Iteration number: [320/565] 56% | Training loss: 0.6893871542066335
Epoch: 12 | Iteration number: [330/565] 58% | Training loss: 0.6893281071475058
Epoch: 12 | Iteration number: [340/565] 60% | Training loss: 0.6892561970388188
Epoch: 12 | Iteration number: [350/565] 61% | Training loss: 0.6892088660172053
Epoch: 12 | Iteration number: [360/565] 63% | Training loss: 0.689161387251483
Epoch: 12 | Iteration number: [370/565] 65% | Training loss: 0.6891205273769997
Epoch: 12 | Iteration number: [380/565] 67% | Training loss: 0.689074979800927
Epoch: 12 | Iteration number: [390/565] 69% | Training loss: 0.6890242509352855
Epoch: 12 | Iteration number: [400/565] 70% | Training loss: 0.6889687083661556
Epoch: 12 | Iteration number: [410/565] 72% | Training loss: 0.688917813068483
Epoch: 12 | Iteration number: [420/565] 74% | Training loss: 0.6888822857822691
Epoch: 12 | Iteration number: [430/565] 76% | Training loss: 0.68884237408638
Epoch: 12 | Iteration number: [440/565] 77% | Training loss: 0.688812732425603
Epoch: 12 | Iteration number: [450/565] 79% | Training loss: 0.6887792094548544
Epoch: 12 | Iteration number: [460/565] 81% | Training loss: 0.6887411492026371
Epoch: 12 | Iteration number: [470/565] 83% | Training loss: 0.6886969644972618
Epoch: 12 | Iteration number: [480/565] 84% | Training loss: 0.688664622232318
Epoch: 12 | Iteration number: [490/565] 86% | Training loss: 0.6886383382641539
Epoch: 12 | Iteration number: [500/565] 88% | Training loss: 0.6886175835132599
Epoch: 12 | Iteration number: [510/565] 90% | Training loss: 0.6885939045279634
Epoch: 12 | Iteration number: [520/565] 92% | Training loss: 0.6885647902121911
Epoch: 12 | Iteration number: [530/565] 93% | Training loss: 0.6885417785284654
Epoch: 12 | Iteration number: [540/565] 95% | Training loss: 0.6885094673545272
Epoch: 12 | Iteration number: [550/565] 97% | Training loss: 0.6884884268587286
Epoch: 12 | Iteration number: [560/565] 99% | Training loss: 0.688466009071895

 End of epoch: 12 | Train Loss: 0.6872335046793507 | Training Time: 89 

 End of epoch: 12 | Eval Loss: 0.6899781141962323 | Evaluating Time: 6 
Epoch: 13 | Iteration number: [10/565] 1% | Training loss: 0.7556324601173401
Epoch: 13 | Iteration number: [20/565] 3% | Training loss: 0.7212907820940018
Epoch: 13 | Iteration number: [30/565] 5% | Training loss: 0.709824800491333
Epoch: 13 | Iteration number: [40/565] 7% | Training loss: 0.7042309388518333
Epoch: 13 | Iteration number: [50/565] 8% | Training loss: 0.7008122360706329
Epoch: 13 | Iteration number: [60/565] 10% | Training loss: 0.698580680290858
Epoch: 13 | Iteration number: [70/565] 12% | Training loss: 0.6969773147787367
Epoch: 13 | Iteration number: [80/565] 14% | Training loss: 0.6956577256321907
Epoch: 13 | Iteration number: [90/565] 15% | Training loss: 0.6946192562580109
Epoch: 13 | Iteration number: [100/565] 17% | Training loss: 0.6938556867837906
Epoch: 13 | Iteration number: [110/565] 19% | Training loss: 0.693285590952093
Epoch: 13 | Iteration number: [120/565] 21% | Training loss: 0.6927807052930196
Epoch: 13 | Iteration number: [130/565] 23% | Training loss: 0.6923994591602912
Epoch: 13 | Iteration number: [140/565] 24% | Training loss: 0.6920367343085153
Epoch: 13 | Iteration number: [150/565] 26% | Training loss: 0.6917087304592132
Epoch: 13 | Iteration number: [160/565] 28% | Training loss: 0.6913799982517957
Epoch: 13 | Iteration number: [170/565] 30% | Training loss: 0.6911361322683447
Epoch: 13 | Iteration number: [180/565] 31% | Training loss: 0.6909157365560532
Epoch: 13 | Iteration number: [190/565] 33% | Training loss: 0.6907072575468766
Epoch: 13 | Iteration number: [200/565] 35% | Training loss: 0.6905394133925438
Epoch: 13 | Iteration number: [210/565] 37% | Training loss: 0.6904093225797018
Epoch: 13 | Iteration number: [220/565] 38% | Training loss: 0.6902808327566493
Epoch: 13 | Iteration number: [230/565] 40% | Training loss: 0.6901584029197693
Epoch: 13 | Iteration number: [240/565] 42% | Training loss: 0.6900506019592285
Epoch: 13 | Iteration number: [250/565] 44% | Training loss: 0.6899518978595733
Epoch: 13 | Iteration number: [260/565] 46% | Training loss: 0.6898546911202944
Epoch: 13 | Iteration number: [270/565] 47% | Training loss: 0.6897640892752894
Epoch: 13 | Iteration number: [280/565] 49% | Training loss: 0.6896704162870134
Epoch: 13 | Iteration number: [290/565] 51% | Training loss: 0.6895867569693204
Epoch: 13 | Iteration number: [300/565] 53% | Training loss: 0.689514550169309
Epoch: 13 | Iteration number: [310/565] 54% | Training loss: 0.6894453214060876
Epoch: 13 | Iteration number: [320/565] 56% | Training loss: 0.6893675195053219
Epoch: 13 | Iteration number: [330/565] 58% | Training loss: 0.6893118036515785
Epoch: 13 | Iteration number: [340/565] 60% | Training loss: 0.6892454361214357
Epoch: 13 | Iteration number: [350/565] 61% | Training loss: 0.6891994323049273
Epoch: 13 | Iteration number: [360/565] 63% | Training loss: 0.6891346404949824
Epoch: 13 | Iteration number: [370/565] 65% | Training loss: 0.6890820757762806
Epoch: 13 | Iteration number: [380/565] 67% | Training loss: 0.6890285846434141
Epoch: 13 | Iteration number: [390/565] 69% | Training loss: 0.6889839612520658
Epoch: 13 | Iteration number: [400/565] 70% | Training loss: 0.6889507375657559
Epoch: 13 | Iteration number: [410/565] 72% | Training loss: 0.6888933633885732
Epoch: 13 | Iteration number: [420/565] 74% | Training loss: 0.6888404805035818
Epoch: 13 | Iteration number: [430/565] 76% | Training loss: 0.6888048022292381
Epoch: 13 | Iteration number: [440/565] 77% | Training loss: 0.6887597227638418
Epoch: 13 | Iteration number: [450/565] 79% | Training loss: 0.6887250697612762
Epoch: 13 | Iteration number: [460/565] 81% | Training loss: 0.688697774513908
Epoch: 13 | Iteration number: [470/565] 83% | Training loss: 0.6886726735754216
Epoch: 13 | Iteration number: [480/565] 84% | Training loss: 0.688638660311699
Epoch: 13 | Iteration number: [490/565] 86% | Training loss: 0.6885995929338494
Epoch: 13 | Iteration number: [500/565] 88% | Training loss: 0.6885765138864517
Epoch: 13 | Iteration number: [510/565] 90% | Training loss: 0.6885420100361693
Epoch: 13 | Iteration number: [520/565] 92% | Training loss: 0.6885207560199957
Epoch: 13 | Iteration number: [530/565] 93% | Training loss: 0.688492006963154
Epoch: 13 | Iteration number: [540/565] 95% | Training loss: 0.6884720152174985
Epoch: 13 | Iteration number: [550/565] 97% | Training loss: 0.6884396376393058
Epoch: 13 | Iteration number: [560/565] 99% | Training loss: 0.6884162788944584

 End of epoch: 13 | Train Loss: 0.687189819116508 | Training Time: 89 

 End of epoch: 13 | Eval Loss: 0.6900419167109898 | Evaluating Time: 6 
Epoch: 14 | Iteration number: [10/565] 1% | Training loss: 0.7560823202133179
Epoch: 14 | Iteration number: [20/565] 3% | Training loss: 0.7216268122196198
Epoch: 14 | Iteration number: [30/565] 5% | Training loss: 0.710112702846527
Epoch: 14 | Iteration number: [40/565] 7% | Training loss: 0.7043286636471748
Epoch: 14 | Iteration number: [50/565] 8% | Training loss: 0.7008478224277497
Epoch: 14 | Iteration number: [60/565] 10% | Training loss: 0.6985704918702443
Epoch: 14 | Iteration number: [70/565] 12% | Training loss: 0.6969407439231873
Epoch: 14 | Iteration number: [80/565] 14% | Training loss: 0.69575185328722
Epoch: 14 | Iteration number: [90/565] 15% | Training loss: 0.69480126897494
Epoch: 14 | Iteration number: [100/565] 17% | Training loss: 0.6940137404203415
Epoch: 14 | Iteration number: [110/565] 19% | Training loss: 0.6933594134720888
Epoch: 14 | Iteration number: [120/565] 21% | Training loss: 0.6928188343842824
Epoch: 14 | Iteration number: [130/565] 23% | Training loss: 0.6923856657284957
Epoch: 14 | Iteration number: [140/565] 24% | Training loss: 0.6919902141605104
Epoch: 14 | Iteration number: [150/565] 26% | Training loss: 0.6916727435588836
Epoch: 14 | Iteration number: [160/565] 28% | Training loss: 0.6914028204977513
Epoch: 14 | Iteration number: [170/565] 30% | Training loss: 0.6911691546440124
Epoch: 14 | Iteration number: [180/565] 31% | Training loss: 0.6909420301516851
Epoch: 14 | Iteration number: [190/565] 33% | Training loss: 0.6907632950105165
Epoch: 14 | Iteration number: [200/565] 35% | Training loss: 0.6905690449476242
Epoch: 14 | Iteration number: [210/565] 37% | Training loss: 0.6903968535718463
Epoch: 14 | Iteration number: [220/565] 38% | Training loss: 0.6902527714317496
Epoch: 14 | Iteration number: [230/565] 40% | Training loss: 0.690121883413066
Epoch: 14 | Iteration number: [240/565] 42% | Training loss: 0.6900216122468312
Epoch: 14 | Iteration number: [250/565] 44% | Training loss: 0.6899051456451416
Epoch: 14 | Iteration number: [260/565] 46% | Training loss: 0.6897924345273238
Epoch: 14 | Iteration number: [270/565] 47% | Training loss: 0.6896832801677563
Epoch: 14 | Iteration number: [280/565] 49% | Training loss: 0.6895686890397753
Epoch: 14 | Iteration number: [290/565] 51% | Training loss: 0.6894752619595363
Epoch: 14 | Iteration number: [300/565] 53% | Training loss: 0.6894019591808319
Epoch: 14 | Iteration number: [310/565] 54% | Training loss: 0.6893482021747097
Epoch: 14 | Iteration number: [320/565] 56% | Training loss: 0.6892796363681555
Epoch: 14 | Iteration number: [330/565] 58% | Training loss: 0.6892038307406686
Epoch: 14 | Iteration number: [340/565] 60% | Training loss: 0.6891407789552912
Epoch: 14 | Iteration number: [350/565] 61% | Training loss: 0.6890719926357269
Epoch: 14 | Iteration number: [360/565] 63% | Training loss: 0.689029991461171
Epoch: 14 | Iteration number: [370/565] 65% | Training loss: 0.6889790236949921
Epoch: 14 | Iteration number: [380/565] 67% | Training loss: 0.6889254060230757
Epoch: 14 | Iteration number: [390/565] 69% | Training loss: 0.6888750045727461
Epoch: 14 | Iteration number: [400/565] 70% | Training loss: 0.6888316245377064
Epoch: 14 | Iteration number: [410/565] 72% | Training loss: 0.6887916232027659
Epoch: 14 | Iteration number: [420/565] 74% | Training loss: 0.688752364118894
Epoch: 14 | Iteration number: [430/565] 76% | Training loss: 0.6887267280456632
Epoch: 14 | Iteration number: [440/565] 77% | Training loss: 0.6886889636516571
Epoch: 14 | Iteration number: [450/565] 79% | Training loss: 0.688653228547838
Epoch: 14 | Iteration number: [460/565] 81% | Training loss: 0.6886148222114729
Epoch: 14 | Iteration number: [470/565] 83% | Training loss: 0.6885873376054966
Epoch: 14 | Iteration number: [480/565] 84% | Training loss: 0.6885609553505977
Epoch: 14 | Iteration number: [490/565] 86% | Training loss: 0.6885222636923498
Epoch: 14 | Iteration number: [500/565] 88% | Training loss: 0.6884919818639755
Epoch: 14 | Iteration number: [510/565] 90% | Training loss: 0.6884660921844782
Epoch: 14 | Iteration number: [520/565] 92% | Training loss: 0.6884434937284543
Epoch: 14 | Iteration number: [530/565] 93% | Training loss: 0.6884172652127608
Epoch: 14 | Iteration number: [540/565] 95% | Training loss: 0.6883887314134174
Epoch: 14 | Iteration number: [550/565] 97% | Training loss: 0.6883685493469238
Epoch: 14 | Iteration number: [560/565] 99% | Training loss: 0.6883418354604925

 End of epoch: 14 | Train Loss: 0.68711635602259 | Training Time: 90 

 End of epoch: 14 | Eval Loss: 0.6901236942836216 | Evaluating Time: 6 
Epoch: 15 | Iteration number: [10/565] 1% | Training loss: 0.7560331165790558
Epoch: 15 | Iteration number: [20/565] 3% | Training loss: 0.7217481404542923
Epoch: 15 | Iteration number: [30/565] 5% | Training loss: 0.7101905246575674
Epoch: 15 | Iteration number: [40/565] 7% | Training loss: 0.7044184401631355
Epoch: 15 | Iteration number: [50/565] 8% | Training loss: 0.7009313714504242
Epoch: 15 | Iteration number: [60/565] 10% | Training loss: 0.698566484451294
Epoch: 15 | Iteration number: [70/565] 12% | Training loss: 0.6969388399805342
Epoch: 15 | Iteration number: [80/565] 14% | Training loss: 0.6956909090280533
Epoch: 15 | Iteration number: [90/565] 15% | Training loss: 0.694749841425154
Epoch: 15 | Iteration number: [100/565] 17% | Training loss: 0.6939612859487534
Epoch: 15 | Iteration number: [110/565] 19% | Training loss: 0.6933225810527801
Epoch: 15 | Iteration number: [120/565] 21% | Training loss: 0.692793574432532
Epoch: 15 | Iteration number: [130/565] 23% | Training loss: 0.6923706063857445
Epoch: 15 | Iteration number: [140/565] 24% | Training loss: 0.6919903044189726
Epoch: 15 | Iteration number: [150/565] 26% | Training loss: 0.6916593476136526
Epoch: 15 | Iteration number: [160/565] 28% | Training loss: 0.6913599349558354
Epoch: 15 | Iteration number: [170/565] 30% | Training loss: 0.6911195134415345
Epoch: 15 | Iteration number: [180/565] 31% | Training loss: 0.6908872455358506
Epoch: 15 | Iteration number: [190/565] 33% | Training loss: 0.6906614005565643
Epoch: 15 | Iteration number: [200/565] 35% | Training loss: 0.6904723411798477
Epoch: 15 | Iteration number: [210/565] 37% | Training loss: 0.690314792735236
Epoch: 15 | Iteration number: [220/565] 38% | Training loss: 0.6901656391945752
Epoch: 15 | Iteration number: [230/565] 40% | Training loss: 0.6900361786717953
Epoch: 15 | Iteration number: [240/565] 42% | Training loss: 0.6899040594696999
Epoch: 15 | Iteration number: [250/565] 44% | Training loss: 0.6897926692962646
Epoch: 15 | Iteration number: [260/565] 46% | Training loss: 0.6896858781576156
Epoch: 15 | Iteration number: [270/565] 47% | Training loss: 0.6895931897339997
Epoch: 15 | Iteration number: [280/565] 49% | Training loss: 0.6895133633698736
Epoch: 15 | Iteration number: [290/565] 51% | Training loss: 0.6894176727738873
Epoch: 15 | Iteration number: [300/565] 53% | Training loss: 0.6893384442726771
Epoch: 15 | Iteration number: [310/565] 54% | Training loss: 0.6892823294285805
Epoch: 15 | Iteration number: [320/565] 56% | Training loss: 0.6892140181735158
Epoch: 15 | Iteration number: [330/565] 58% | Training loss: 0.6891554778272455
Epoch: 15 | Iteration number: [340/565] 60% | Training loss: 0.6890969004701165
Epoch: 15 | Iteration number: [350/565] 61% | Training loss: 0.6890399188654763
Epoch: 15 | Iteration number: [360/565] 63% | Training loss: 0.6889888394210074
Epoch: 15 | Iteration number: [370/565] 65% | Training loss: 0.688944812400921
Epoch: 15 | Iteration number: [380/565] 67% | Training loss: 0.6889095927539625
Epoch: 15 | Iteration number: [390/565] 69% | Training loss: 0.688862394522398
Epoch: 15 | Iteration number: [400/565] 70% | Training loss: 0.6888281278312206
Epoch: 15 | Iteration number: [410/565] 72% | Training loss: 0.6887791072450034
Epoch: 15 | Iteration number: [420/565] 74% | Training loss: 0.6887438315720785
Epoch: 15 | Iteration number: [430/565] 76% | Training loss: 0.6886953040610913
Epoch: 15 | Iteration number: [440/565] 77% | Training loss: 0.6886540182612159
Epoch: 15 | Iteration number: [450/565] 79% | Training loss: 0.6886102694935269
Epoch: 15 | Iteration number: [460/565] 81% | Training loss: 0.688573666240858
Epoch: 15 | Iteration number: [470/565] 83% | Training loss: 0.6885499692977743
Epoch: 15 | Iteration number: [480/565] 84% | Training loss: 0.6885199669748545
Epoch: 15 | Iteration number: [490/565] 86% | Training loss: 0.6884833341958572
Epoch: 15 | Iteration number: [500/565] 88% | Training loss: 0.6884532980918884
Epoch: 15 | Iteration number: [510/565] 90% | Training loss: 0.6884231317277049
Epoch: 15 | Iteration number: [520/565] 92% | Training loss: 0.6883957913288703
Epoch: 15 | Iteration number: [530/565] 93% | Training loss: 0.6883664209887667
Epoch: 15 | Iteration number: [540/565] 95% | Training loss: 0.6883505745066537
Epoch: 15 | Iteration number: [550/565] 97% | Training loss: 0.6883301636305722
Epoch: 15 | Iteration number: [560/565] 99% | Training loss: 0.6883075453341008

 End of epoch: 15 | Train Loss: 0.6870818879752032 | Training Time: 89 

 End of epoch: 15 | Eval Loss: 0.6903730034828186 | Evaluating Time: 6 
Epoch: 16 | Iteration number: [10/565] 1% | Training loss: 0.7553547084331512
Epoch: 16 | Iteration number: [20/565] 3% | Training loss: 0.7214483171701431
Epoch: 16 | Iteration number: [30/565] 5% | Training loss: 0.7100515266259512
Epoch: 16 | Iteration number: [40/565] 7% | Training loss: 0.7042687952518463
Epoch: 16 | Iteration number: [50/565] 8% | Training loss: 0.7008533465862274
Epoch: 16 | Iteration number: [60/565] 10% | Training loss: 0.6986142009496689
Epoch: 16 | Iteration number: [70/565] 12% | Training loss: 0.697014513186046
Epoch: 16 | Iteration number: [80/565] 14% | Training loss: 0.6957337863743305
Epoch: 16 | Iteration number: [90/565] 15% | Training loss: 0.6947963760958777
Epoch: 16 | Iteration number: [100/565] 17% | Training loss: 0.6940229207277298
Epoch: 16 | Iteration number: [110/565] 19% | Training loss: 0.6934291536157782
Epoch: 16 | Iteration number: [120/565] 21% | Training loss: 0.6929158826669057
Epoch: 16 | Iteration number: [130/565] 23% | Training loss: 0.6924145597677964
Epoch: 16 | Iteration number: [140/565] 24% | Training loss: 0.6920672450746809
Epoch: 16 | Iteration number: [150/565] 26% | Training loss: 0.6917238835493723
Epoch: 16 | Iteration number: [160/565] 28% | Training loss: 0.691447677463293
Epoch: 16 | Iteration number: [170/565] 30% | Training loss: 0.6912035637042102
Epoch: 16 | Iteration number: [180/565] 31% | Training loss: 0.6909915023379856
Epoch: 16 | Iteration number: [190/565] 33% | Training loss: 0.6907990904230821
Epoch: 16 | Iteration number: [200/565] 35% | Training loss: 0.6906084835529327
Epoch: 16 | Iteration number: [210/565] 37% | Training loss: 0.6904394998436882
Epoch: 16 | Iteration number: [220/565] 38% | Training loss: 0.690295659141107
Epoch: 16 | Iteration number: [230/565] 40% | Training loss: 0.6901615225750467
Epoch: 16 | Iteration number: [240/565] 42% | Training loss: 0.6900162438551585
Epoch: 16 | Iteration number: [250/565] 44% | Training loss: 0.6898894875049592
Epoch: 16 | Iteration number: [260/565] 46% | Training loss: 0.6897751500973335
Epoch: 16 | Iteration number: [270/565] 47% | Training loss: 0.6896705753273434
Epoch: 16 | Iteration number: [280/565] 49% | Training loss: 0.6895716656531606
Epoch: 16 | Iteration number: [290/565] 51% | Training loss: 0.6894989685765628
Epoch: 16 | Iteration number: [300/565] 53% | Training loss: 0.6894140857458114
Epoch: 16 | Iteration number: [310/565] 54% | Training loss: 0.6893418800446295
Epoch: 16 | Iteration number: [320/565] 56% | Training loss: 0.6892795102670789
Epoch: 16 | Iteration number: [330/565] 58% | Training loss: 0.6892168668183414
Epoch: 16 | Iteration number: [340/565] 60% | Training loss: 0.6891590253395192
Epoch: 16 | Iteration number: [350/565] 61% | Training loss: 0.6891021808556148
Epoch: 16 | Iteration number: [360/565] 63% | Training loss: 0.6890376400616434
Epoch: 16 | Iteration number: [370/565] 65% | Training loss: 0.6889716776641639
Epoch: 16 | Iteration number: [380/565] 67% | Training loss: 0.6889107177132054
Epoch: 16 | Iteration number: [390/565] 69% | Training loss: 0.6888679810059376
Epoch: 16 | Iteration number: [400/565] 70% | Training loss: 0.6888288339972496
Epoch: 16 | Iteration number: [410/565] 72% | Training loss: 0.6887755090143622
Epoch: 16 | Iteration number: [420/565] 74% | Training loss: 0.688739424092429
Epoch: 16 | Iteration number: [430/565] 76% | Training loss: 0.6887076359848644
Epoch: 16 | Iteration number: [440/565] 77% | Training loss: 0.6886625120585615
Epoch: 16 | Iteration number: [450/565] 79% | Training loss: 0.6886193282074399
Epoch: 16 | Iteration number: [460/565] 81% | Training loss: 0.6885732057301894
Epoch: 16 | Iteration number: [470/565] 83% | Training loss: 0.6885304128870051
Epoch: 16 | Iteration number: [480/565] 84% | Training loss: 0.6885015030701955
Epoch: 16 | Iteration number: [490/565] 86% | Training loss: 0.688469924367204
Epoch: 16 | Iteration number: [500/565] 88% | Training loss: 0.6884340544939042
Epoch: 16 | Iteration number: [510/565] 90% | Training loss: 0.6884118586194281
Epoch: 16 | Iteration number: [520/565] 92% | Training loss: 0.6883869988413958
Epoch: 16 | Iteration number: [530/565] 93% | Training loss: 0.6883541813436544
Epoch: 16 | Iteration number: [540/565] 95% | Training loss: 0.6883198823089953
Epoch: 16 | Iteration number: [550/565] 97% | Training loss: 0.6882974969257007
Epoch: 16 | Iteration number: [560/565] 99% | Training loss: 0.6882786863616535

 End of epoch: 16 | Train Loss: 0.6870562291778295 | Training Time: 90 

 End of epoch: 16 | Eval Loss: 0.6905926551137652 | Evaluating Time: 6 
Epoch: 17 | Iteration number: [10/565] 1% | Training loss: 0.7561079561710358
Epoch: 17 | Iteration number: [20/565] 3% | Training loss: 0.7215140998363495
Epoch: 17 | Iteration number: [30/565] 5% | Training loss: 0.7098500589529674
Epoch: 17 | Iteration number: [40/565] 7% | Training loss: 0.7040650710463524
Epoch: 17 | Iteration number: [50/565] 8% | Training loss: 0.7007267558574677
Epoch: 17 | Iteration number: [60/565] 10% | Training loss: 0.6984506229559581
Epoch: 17 | Iteration number: [70/565] 12% | Training loss: 0.6968252982412065
Epoch: 17 | Iteration number: [80/565] 14% | Training loss: 0.6955868482589722
Epoch: 17 | Iteration number: [90/565] 15% | Training loss: 0.6946247431966993
Epoch: 17 | Iteration number: [100/565] 17% | Training loss: 0.6938663327693939
Epoch: 17 | Iteration number: [110/565] 19% | Training loss: 0.6932510305534709
Epoch: 17 | Iteration number: [120/565] 21% | Training loss: 0.6927683487534523
Epoch: 17 | Iteration number: [130/565] 23% | Training loss: 0.6923556745052337
Epoch: 17 | Iteration number: [140/565] 24% | Training loss: 0.6919744904552187
Epoch: 17 | Iteration number: [150/565] 26% | Training loss: 0.6916237107912699
Epoch: 17 | Iteration number: [160/565] 28% | Training loss: 0.6913328748196363
Epoch: 17 | Iteration number: [170/565] 30% | Training loss: 0.691057160321404
Epoch: 17 | Iteration number: [180/565] 31% | Training loss: 0.6908529973692364
Epoch: 17 | Iteration number: [190/565] 33% | Training loss: 0.6906789701235921
Epoch: 17 | Iteration number: [200/565] 35% | Training loss: 0.6904740458726883
Epoch: 17 | Iteration number: [210/565] 37% | Training loss: 0.6903222583589099
Epoch: 17 | Iteration number: [220/565] 38% | Training loss: 0.6901746481657028
Epoch: 17 | Iteration number: [230/565] 40% | Training loss: 0.6900624544724174
Epoch: 17 | Iteration number: [240/565] 42% | Training loss: 0.6899282959600289
Epoch: 17 | Iteration number: [250/565] 44% | Training loss: 0.6898085622787475
Epoch: 17 | Iteration number: [260/565] 46% | Training loss: 0.689685732126236
Epoch: 17 | Iteration number: [270/565] 47% | Training loss: 0.6895868628113359
Epoch: 17 | Iteration number: [280/565] 49% | Training loss: 0.6894902565649578
Epoch: 17 | Iteration number: [290/565] 51% | Training loss: 0.6894053726360716
Epoch: 17 | Iteration number: [300/565] 53% | Training loss: 0.6893228119611741
Epoch: 17 | Iteration number: [310/565] 54% | Training loss: 0.6892412014545933
Epoch: 17 | Iteration number: [320/565] 56% | Training loss: 0.6891789097338915
Epoch: 17 | Iteration number: [330/565] 58% | Training loss: 0.6890991234418118
Epoch: 17 | Iteration number: [340/565] 60% | Training loss: 0.68902086966178
Epoch: 17 | Iteration number: [350/565] 61% | Training loss: 0.6889630365371704
Epoch: 17 | Iteration number: [360/565] 63% | Training loss: 0.6889075623618232
Epoch: 17 | Iteration number: [370/565] 65% | Training loss: 0.6888672303509068
Epoch: 17 | Iteration number: [380/565] 67% | Training loss: 0.688820932727111
Epoch: 17 | Iteration number: [390/565] 69% | Training loss: 0.6887782637889569
Epoch: 17 | Iteration number: [400/565] 70% | Training loss: 0.6887256035208702
Epoch: 17 | Iteration number: [410/565] 72% | Training loss: 0.6886902210189075
Epoch: 17 | Iteration number: [420/565] 74% | Training loss: 0.6886444568634034
Epoch: 17 | Iteration number: [430/565] 76% | Training loss: 0.688609127388444
Epoch: 17 | Iteration number: [440/565] 77% | Training loss: 0.6885848946192048
Epoch: 17 | Iteration number: [450/565] 79% | Training loss: 0.6885523153675928
Epoch: 17 | Iteration number: [460/565] 81% | Training loss: 0.6885187570167625
Epoch: 17 | Iteration number: [470/565] 83% | Training loss: 0.6884862387433965
Epoch: 17 | Iteration number: [480/565] 84% | Training loss: 0.6884566580255826
Epoch: 17 | Iteration number: [490/565] 86% | Training loss: 0.6884236279799014
Epoch: 17 | Iteration number: [500/565] 88% | Training loss: 0.6883987140655518
Epoch: 17 | Iteration number: [510/565] 90% | Training loss: 0.6883639288883583
Epoch: 17 | Iteration number: [520/565] 92% | Training loss: 0.6883315617075333
Epoch: 17 | Iteration number: [530/565] 93% | Training loss: 0.6883042521071884
Epoch: 17 | Iteration number: [540/565] 95% | Training loss: 0.6882868306504355
Epoch: 17 | Iteration number: [550/565] 97% | Training loss: 0.6882663305239244
Epoch: 17 | Iteration number: [560/565] 99% | Training loss: 0.6882436539445604

 End of epoch: 17 | Train Loss: 0.6870156679533225 | Training Time: 88 

 End of epoch: 17 | Eval Loss: 0.6902992810521807 | Evaluating Time: 6 
Epoch: 18 | Iteration number: [10/565] 1% | Training loss: 0.7556310176849366
Epoch: 18 | Iteration number: [20/565] 3% | Training loss: 0.7214361935853958
Epoch: 18 | Iteration number: [30/565] 5% | Training loss: 0.7098373055458069
Epoch: 18 | Iteration number: [40/565] 7% | Training loss: 0.7041452556848526
Epoch: 18 | Iteration number: [50/565] 8% | Training loss: 0.7007846474647522
Epoch: 18 | Iteration number: [60/565] 10% | Training loss: 0.6984198212623596
Epoch: 18 | Iteration number: [70/565] 12% | Training loss: 0.6967802907739367
Epoch: 18 | Iteration number: [80/565] 14% | Training loss: 0.6955302260816097
Epoch: 18 | Iteration number: [90/565] 15% | Training loss: 0.6946204715304904
Epoch: 18 | Iteration number: [100/565] 17% | Training loss: 0.6938394588232041
Epoch: 18 | Iteration number: [110/565] 19% | Training loss: 0.693245699188926
Epoch: 18 | Iteration number: [120/565] 21% | Training loss: 0.6926611115535101
Epoch: 18 | Iteration number: [130/565] 23% | Training loss: 0.6922160176130442
Epoch: 18 | Iteration number: [140/565] 24% | Training loss: 0.6918618500232696
Epoch: 18 | Iteration number: [150/565] 26% | Training loss: 0.6915371326605478
Epoch: 18 | Iteration number: [160/565] 28% | Training loss: 0.6912490244954824
Epoch: 18 | Iteration number: [170/565] 30% | Training loss: 0.6909979883362265
Epoch: 18 | Iteration number: [180/565] 31% | Training loss: 0.6907788114415274
Epoch: 18 | Iteration number: [190/565] 33% | Training loss: 0.6905835211277008
Epoch: 18 | Iteration number: [200/565] 35% | Training loss: 0.69041209846735
Epoch: 18 | Iteration number: [210/565] 37% | Training loss: 0.6902344803015391
Epoch: 18 | Iteration number: [220/565] 38% | Training loss: 0.6901109332388098
Epoch: 18 | Iteration number: [230/565] 40% | Training loss: 0.6899843057860499
Epoch: 18 | Iteration number: [240/565] 42% | Training loss: 0.6898586784799894
Epoch: 18 | Iteration number: [250/565] 44% | Training loss: 0.6897524642944336
Epoch: 18 | Iteration number: [260/565] 46% | Training loss: 0.6896521306954897
Epoch: 18 | Iteration number: [270/565] 47% | Training loss: 0.6895456530429699
Epoch: 18 | Iteration number: [280/565] 49% | Training loss: 0.6894539750048092
Epoch: 18 | Iteration number: [290/565] 51% | Training loss: 0.6893707912543724
Epoch: 18 | Iteration number: [300/565] 53% | Training loss: 0.6892837299903234
Epoch: 18 | Iteration number: [310/565] 54% | Training loss: 0.6892121807221443
Epoch: 18 | Iteration number: [320/565] 56% | Training loss: 0.6891311114653945
Epoch: 18 | Iteration number: [330/565] 58% | Training loss: 0.6890687973210305
Epoch: 18 | Iteration number: [340/565] 60% | Training loss: 0.6890105307102203
Epoch: 18 | Iteration number: [350/565] 61% | Training loss: 0.6889621235643114
Epoch: 18 | Iteration number: [360/565] 63% | Training loss: 0.6889085787865851
Epoch: 18 | Iteration number: [370/565] 65% | Training loss: 0.6888643601456204
Epoch: 18 | Iteration number: [380/565] 67% | Training loss: 0.688816603861357
Epoch: 18 | Iteration number: [390/565] 69% | Training loss: 0.6887680985988714
Epoch: 18 | Iteration number: [400/565] 70% | Training loss: 0.6887426595389843
Epoch: 18 | Iteration number: [410/565] 72% | Training loss: 0.6887037130390725
Epoch: 18 | Iteration number: [420/565] 74% | Training loss: 0.6886678772313254
Epoch: 18 | Iteration number: [430/565] 76% | Training loss: 0.6886232109956963
Epoch: 18 | Iteration number: [440/565] 77% | Training loss: 0.6885896758599714
Epoch: 18 | Iteration number: [450/565] 79% | Training loss: 0.6885527718067169
Epoch: 18 | Iteration number: [460/565] 81% | Training loss: 0.6885165346705395
Epoch: 18 | Iteration number: [470/565] 83% | Training loss: 0.6884948792609763
Epoch: 18 | Iteration number: [480/565] 84% | Training loss: 0.6884612480799357
Epoch: 18 | Iteration number: [490/565] 86% | Training loss: 0.6884290669645582
Epoch: 18 | Iteration number: [500/565] 88% | Training loss: 0.6883994204998016
Epoch: 18 | Iteration number: [510/565] 90% | Training loss: 0.6883779121380226
Epoch: 18 | Iteration number: [520/565] 92% | Training loss: 0.6883530342808136
Epoch: 18 | Iteration number: [530/565] 93% | Training loss: 0.6883273819707475
Epoch: 18 | Iteration number: [540/565] 95% | Training loss: 0.6883009830006847
Epoch: 18 | Iteration number: [550/565] 97% | Training loss: 0.68827103452249
Epoch: 18 | Iteration number: [560/565] 99% | Training loss: 0.6882419544671263

 End of epoch: 18 | Train Loss: 0.6870132151958162 | Training Time: 90 

 End of epoch: 18 | Eval Loss: 0.6902021510260445 | Evaluating Time: 5 
Epoch: 19 | Iteration number: [10/565] 1% | Training loss: 0.7558174550533294
Epoch: 19 | Iteration number: [20/565] 3% | Training loss: 0.7214659363031387
Epoch: 19 | Iteration number: [30/565] 5% | Training loss: 0.7099212785561879
Epoch: 19 | Iteration number: [40/565] 7% | Training loss: 0.7042401686310769
Epoch: 19 | Iteration number: [50/565] 8% | Training loss: 0.7007962191104888
Epoch: 19 | Iteration number: [60/565] 10% | Training loss: 0.6985743701457977
Epoch: 19 | Iteration number: [70/565] 12% | Training loss: 0.6969522271837507
Epoch: 19 | Iteration number: [80/565] 14% | Training loss: 0.6956899806857109
Epoch: 19 | Iteration number: [90/565] 15% | Training loss: 0.6946900063090854
Epoch: 19 | Iteration number: [100/565] 17% | Training loss: 0.6939376974105835
Epoch: 19 | Iteration number: [110/565] 19% | Training loss: 0.6932903268120506
Epoch: 19 | Iteration number: [120/565] 21% | Training loss: 0.6927364408969879
Epoch: 19 | Iteration number: [130/565] 23% | Training loss: 0.6923075593434848
Epoch: 19 | Iteration number: [140/565] 24% | Training loss: 0.691927192892347
Epoch: 19 | Iteration number: [150/565] 26% | Training loss: 0.6915882404645284
Epoch: 19 | Iteration number: [160/565] 28% | Training loss: 0.6913090024143458
Epoch: 19 | Iteration number: [170/565] 30% | Training loss: 0.6910288298831266
Epoch: 19 | Iteration number: [180/565] 31% | Training loss: 0.6908045285277896
Epoch: 19 | Iteration number: [190/565] 33% | Training loss: 0.6905964186317042
Epoch: 19 | Iteration number: [200/565] 35% | Training loss: 0.6904097616672515
Epoch: 19 | Iteration number: [210/565] 37% | Training loss: 0.6902567207813263
Epoch: 19 | Iteration number: [220/565] 38% | Training loss: 0.6901205390691757
Epoch: 19 | Iteration number: [230/565] 40% | Training loss: 0.6899886268636455
Epoch: 19 | Iteration number: [240/565] 42% | Training loss: 0.6898456615706284
Epoch: 19 | Iteration number: [250/565] 44% | Training loss: 0.6897411873340606
Epoch: 19 | Iteration number: [260/565] 46% | Training loss: 0.6896484661560792
Epoch: 19 | Iteration number: [270/565] 47% | Training loss: 0.689542971054713
Epoch: 19 | Iteration number: [280/565] 49% | Training loss: 0.689443564414978
Epoch: 19 | Iteration number: [290/565] 51% | Training loss: 0.689355324465653
Epoch: 19 | Iteration number: [300/565] 53% | Training loss: 0.6892719888687133
Epoch: 19 | Iteration number: [310/565] 54% | Training loss: 0.6892033302014874
Epoch: 19 | Iteration number: [320/565] 56% | Training loss: 0.6891270507127046
Epoch: 19 | Iteration number: [330/565] 58% | Training loss: 0.6890480960860397
Epoch: 19 | Iteration number: [340/565] 60% | Training loss: 0.6889832824468612
Epoch: 19 | Iteration number: [350/565] 61% | Training loss: 0.6889275533812387
Epoch: 19 | Iteration number: [360/565] 63% | Training loss: 0.6888719023929701
Epoch: 19 | Iteration number: [370/565] 65% | Training loss: 0.6888257667825028
Epoch: 19 | Iteration number: [380/565] 67% | Training loss: 0.6887915419904809
Epoch: 19 | Iteration number: [390/565] 69% | Training loss: 0.6887520317847912
Epoch: 19 | Iteration number: [400/565] 70% | Training loss: 0.688698785752058
Epoch: 19 | Iteration number: [410/565] 72% | Training loss: 0.6886531640843647
Epoch: 19 | Iteration number: [420/565] 74% | Training loss: 0.6886201852843875
Epoch: 19 | Iteration number: [430/565] 76% | Training loss: 0.6885894129442615
Epoch: 19 | Iteration number: [440/565] 77% | Training loss: 0.6885577616366473
Epoch: 19 | Iteration number: [450/565] 79% | Training loss: 0.6885258583227793
Epoch: 19 | Iteration number: [460/565] 81% | Training loss: 0.6884931183379629
Epoch: 19 | Iteration number: [470/565] 83% | Training loss: 0.6884642982736547
Epoch: 19 | Iteration number: [480/565] 84% | Training loss: 0.6884207103401423
Epoch: 19 | Iteration number: [490/565] 86% | Training loss: 0.6883941647957782
Epoch: 19 | Iteration number: [500/565] 88% | Training loss: 0.6883643454313279
Epoch: 19 | Iteration number: [510/565] 90% | Training loss: 0.6883492926756541
Epoch: 19 | Iteration number: [520/565] 92% | Training loss: 0.6883265860951864
Epoch: 19 | Iteration number: [530/565] 93% | Training loss: 0.6882967199919359
Epoch: 19 | Iteration number: [540/565] 95% | Training loss: 0.6882751646969053
Epoch: 19 | Iteration number: [550/565] 97% | Training loss: 0.6882528026537462
Epoch: 19 | Iteration number: [560/565] 99% | Training loss: 0.6882326598678317

 End of epoch: 19 | Train Loss: 0.6870002853131927 | Training Time: 89 

 End of epoch: 19 | Eval Loss: 0.6904464364051819 | Evaluating Time: 6 
Epoch: 20 | Iteration number: [10/565] 1% | Training loss: 0.755092591047287
Epoch: 20 | Iteration number: [20/565] 3% | Training loss: 0.7210369080305099
Epoch: 20 | Iteration number: [30/565] 5% | Training loss: 0.7096651931603749
Epoch: 20 | Iteration number: [40/565] 7% | Training loss: 0.7040248855948448
Epoch: 20 | Iteration number: [50/565] 8% | Training loss: 0.7006456708908081
Epoch: 20 | Iteration number: [60/565] 10% | Training loss: 0.698418844739596
Epoch: 20 | Iteration number: [70/565] 12% | Training loss: 0.6967565315110343
Epoch: 20 | Iteration number: [80/565] 14% | Training loss: 0.6954815454781056
Epoch: 20 | Iteration number: [90/565] 15% | Training loss: 0.6945604940255483
Epoch: 20 | Iteration number: [100/565] 17% | Training loss: 0.6938369381427765
Epoch: 20 | Iteration number: [110/565] 19% | Training loss: 0.693229760906913
Epoch: 20 | Iteration number: [120/565] 21% | Training loss: 0.6927214011549949
Epoch: 20 | Iteration number: [130/565] 23% | Training loss: 0.6922795401169703
Epoch: 20 | Iteration number: [140/565] 24% | Training loss: 0.6918961699519839
Epoch: 20 | Iteration number: [150/565] 26% | Training loss: 0.6915627384185791
Epoch: 20 | Iteration number: [160/565] 28% | Training loss: 0.6912638582289219
Epoch: 20 | Iteration number: [170/565] 30% | Training loss: 0.6910096010741066
Epoch: 20 | Iteration number: [180/565] 31% | Training loss: 0.6907911509275436
Epoch: 20 | Iteration number: [190/565] 33% | Training loss: 0.6906205092605792
Epoch: 20 | Iteration number: [200/565] 35% | Training loss: 0.6904553556442261
Epoch: 20 | Iteration number: [210/565] 37% | Training loss: 0.690309693983623
Epoch: 20 | Iteration number: [220/565] 38% | Training loss: 0.6901488911021839
Epoch: 20 | Iteration number: [230/565] 40% | Training loss: 0.690006259990775
Epoch: 20 | Iteration number: [240/565] 42% | Training loss: 0.6898691758513451
Epoch: 20 | Iteration number: [250/565] 44% | Training loss: 0.6897568643093109
Epoch: 20 | Iteration number: [260/565] 46% | Training loss: 0.6896503748802039
Epoch: 20 | Iteration number: [270/565] 47% | Training loss: 0.6895566834343805
Epoch: 20 | Iteration number: [280/565] 49% | Training loss: 0.6894619767154966
Epoch: 20 | Iteration number: [290/565] 51% | Training loss: 0.6893551894303026
Epoch: 20 | Iteration number: [300/565] 53% | Training loss: 0.6892925427357356
Epoch: 20 | Iteration number: [310/565] 54% | Training loss: 0.689212675440696
Epoch: 20 | Iteration number: [320/565] 56% | Training loss: 0.6891448711976409
Epoch: 20 | Iteration number: [330/565] 58% | Training loss: 0.6890750852498141
Epoch: 20 | Iteration number: [340/565] 60% | Training loss: 0.6890211250852136
Epoch: 20 | Iteration number: [350/565] 61% | Training loss: 0.6889704528876713
Epoch: 20 | Iteration number: [360/565] 63% | Training loss: 0.6889156677656704
Epoch: 20 | Iteration number: [370/565] 65% | Training loss: 0.6888535841091259
Epoch: 20 | Iteration number: [380/565] 67% | Training loss: 0.6888123251889882
Epoch: 20 | Iteration number: [390/565] 69% | Training loss: 0.6887756263598418
Epoch: 20 | Iteration number: [400/565] 70% | Training loss: 0.688736270815134
Epoch: 20 | Iteration number: [410/565] 72% | Training loss: 0.6886911831251005
Epoch: 20 | Iteration number: [420/565] 74% | Training loss: 0.6886437237262726
Epoch: 20 | Iteration number: [430/565] 76% | Training loss: 0.6886030651802241
Epoch: 20 | Iteration number: [440/565] 77% | Training loss: 0.6885564991018989
Epoch: 20 | Iteration number: [450/565] 79% | Training loss: 0.6885115245978037
Epoch: 20 | Iteration number: [460/565] 81% | Training loss: 0.688479432463646
Epoch: 20 | Iteration number: [470/565] 83% | Training loss: 0.688456525193884
Epoch: 20 | Iteration number: [480/565] 84% | Training loss: 0.6884237168977658
Epoch: 20 | Iteration number: [490/565] 86% | Training loss: 0.6883954404568186
Epoch: 20 | Iteration number: [500/565] 88% | Training loss: 0.6883730552196503
Epoch: 20 | Iteration number: [510/565] 90% | Training loss: 0.6883440401039872
Epoch: 20 | Iteration number: [520/565] 92% | Training loss: 0.6883135575514573
Epoch: 20 | Iteration number: [530/565] 93% | Training loss: 0.6882866957277621
Epoch: 20 | Iteration number: [540/565] 95% | Training loss: 0.6882643082627544
Epoch: 20 | Iteration number: [550/565] 97% | Training loss: 0.6882410018010573
Epoch: 20 | Iteration number: [560/565] 99% | Training loss: 0.6882140216018472

 End of epoch: 20 | Train Loss: 0.6869874968992925 | Training Time: 89 

 End of epoch: 20 | Eval Loss: 0.6905609454427447 | Evaluating Time: 6 
Epoch: 21 | Iteration number: [10/565] 1% | Training loss: 0.7556703925132752
Epoch: 21 | Iteration number: [20/565] 3% | Training loss: 0.7214549392461777
Epoch: 21 | Iteration number: [30/565] 5% | Training loss: 0.7100614607334137
Epoch: 21 | Iteration number: [40/565] 7% | Training loss: 0.7043884143233299
Epoch: 21 | Iteration number: [50/565] 8% | Training loss: 0.7008659660816192
Epoch: 21 | Iteration number: [60/565] 10% | Training loss: 0.6985266854365667
Epoch: 21 | Iteration number: [70/565] 12% | Training loss: 0.69693791781153
Epoch: 21 | Iteration number: [80/565] 14% | Training loss: 0.6956266805529594
Epoch: 21 | Iteration number: [90/565] 15% | Training loss: 0.6947149647606744
Epoch: 21 | Iteration number: [100/565] 17% | Training loss: 0.6939504832029343
Epoch: 21 | Iteration number: [110/565] 19% | Training loss: 0.693273149837147
Epoch: 21 | Iteration number: [120/565] 21% | Training loss: 0.6927475392818451
Epoch: 21 | Iteration number: [130/565] 23% | Training loss: 0.6923088270884293
Epoch: 21 | Iteration number: [140/565] 24% | Training loss: 0.6919035549674716
Epoch: 21 | Iteration number: [150/565] 26% | Training loss: 0.6915942045052846
Epoch: 21 | Iteration number: [160/565] 28% | Training loss: 0.6913245487958193
Epoch: 21 | Iteration number: [170/565] 30% | Training loss: 0.6910777151584625
Epoch: 21 | Iteration number: [180/565] 31% | Training loss: 0.6908576783206728
Epoch: 21 | Iteration number: [190/565] 33% | Training loss: 0.6906405935161992
Epoch: 21 | Iteration number: [200/565] 35% | Training loss: 0.6904837867617607
Epoch: 21 | Iteration number: [210/565] 37% | Training loss: 0.6903089946224577
Epoch: 21 | Iteration number: [220/565] 38% | Training loss: 0.690145994587378
Epoch: 21 | Iteration number: [230/565] 40% | Training loss: 0.6900146474008975
Epoch: 21 | Iteration number: [240/565] 42% | Training loss: 0.6898853537937005
Epoch: 21 | Iteration number: [250/565] 44% | Training loss: 0.6897680909633637
Epoch: 21 | Iteration number: [260/565] 46% | Training loss: 0.6896740654340157
Epoch: 21 | Iteration number: [270/565] 47% | Training loss: 0.6895740456051297
Epoch: 21 | Iteration number: [280/565] 49% | Training loss: 0.689467140180724
Epoch: 21 | Iteration number: [290/565] 51% | Training loss: 0.6893975878583973
Epoch: 21 | Iteration number: [300/565] 53% | Training loss: 0.689321615298589
Epoch: 21 | Iteration number: [310/565] 54% | Training loss: 0.6892362388872331
Epoch: 21 | Iteration number: [320/565] 56% | Training loss: 0.6891543375328183
Epoch: 21 | Iteration number: [330/565] 58% | Training loss: 0.6890769416635687
Epoch: 21 | Iteration number: [340/565] 60% | Training loss: 0.689004861607271
Epoch: 21 | Iteration number: [350/565] 61% | Training loss: 0.68894767505782
Epoch: 21 | Iteration number: [360/565] 63% | Training loss: 0.6888838388853603
Epoch: 21 | Iteration number: [370/565] 65% | Training loss: 0.6888313394946021
Epoch: 21 | Iteration number: [380/565] 67% | Training loss: 0.6887794165234816
Epoch: 21 | Iteration number: [390/565] 69% | Training loss: 0.6887360031788166
Epoch: 21 | Iteration number: [400/565] 70% | Training loss: 0.6886992567777633
Epoch: 21 | Iteration number: [410/565] 72% | Training loss: 0.6886561965070119
Epoch: 21 | Iteration number: [420/565] 74% | Training loss: 0.68861340710095
Epoch: 21 | Iteration number: [430/565] 76% | Training loss: 0.6885754662890767
Epoch: 21 | Iteration number: [440/565] 77% | Training loss: 0.688540920208801
Epoch: 21 | Iteration number: [450/565] 79% | Training loss: 0.6885182633664872
Epoch: 21 | Iteration number: [460/565] 81% | Training loss: 0.6884876541469408
Epoch: 21 | Iteration number: [470/565] 83% | Training loss: 0.6884439659879563
Epoch: 21 | Iteration number: [480/565] 84% | Training loss: 0.6884209470202526
Epoch: 21 | Iteration number: [490/565] 86% | Training loss: 0.6883862278899368
Epoch: 21 | Iteration number: [500/565] 88% | Training loss: 0.6883556370735169
Epoch: 21 | Iteration number: [510/565] 90% | Training loss: 0.6883193879735237
Epoch: 21 | Iteration number: [520/565] 92% | Training loss: 0.6882893492396062
Epoch: 21 | Iteration number: [530/565] 93% | Training loss: 0.6882559226368958
Epoch: 21 | Iteration number: [540/565] 95% | Training loss: 0.6882327723282354
Epoch: 21 | Iteration number: [550/565] 97% | Training loss: 0.6882049852067774
Epoch: 21 | Iteration number: [560/565] 99% | Training loss: 0.688185064388173

 End of epoch: 21 | Train Loss: 0.6869546312146482 | Training Time: 88 

 End of epoch: 21 | Eval Loss: 0.690563270023891 | Evaluating Time: 5 
Epoch: 22 | Iteration number: [10/565] 1% | Training loss: 0.755977189540863
Epoch: 22 | Iteration number: [20/565] 3% | Training loss: 0.7214796751737594
Epoch: 22 | Iteration number: [30/565] 5% | Training loss: 0.7099637587865194
Epoch: 22 | Iteration number: [40/565] 7% | Training loss: 0.7041559115052223
Epoch: 22 | Iteration number: [50/565] 8% | Training loss: 0.7007580780982972
Epoch: 22 | Iteration number: [60/565] 10% | Training loss: 0.6985483129819234
Epoch: 22 | Iteration number: [70/565] 12% | Training loss: 0.6968708421502795
Epoch: 22 | Iteration number: [80/565] 14% | Training loss: 0.6956293299794197
Epoch: 22 | Iteration number: [90/565] 15% | Training loss: 0.6946842895613776
Epoch: 22 | Iteration number: [100/565] 17% | Training loss: 0.69392214179039
Epoch: 22 | Iteration number: [110/565] 19% | Training loss: 0.6932774662971497
Epoch: 22 | Iteration number: [120/565] 21% | Training loss: 0.6927687287330627
Epoch: 22 | Iteration number: [130/565] 23% | Training loss: 0.692316277210529
Epoch: 22 | Iteration number: [140/565] 24% | Training loss: 0.6919413345200675
Epoch: 22 | Iteration number: [150/565] 26% | Training loss: 0.6915898183981578
Epoch: 22 | Iteration number: [160/565] 28% | Training loss: 0.6912845332175493
Epoch: 22 | Iteration number: [170/565] 30% | Training loss: 0.6910248055177577
Epoch: 22 | Iteration number: [180/565] 31% | Training loss: 0.6907834844456778
Epoch: 22 | Iteration number: [190/565] 33% | Training loss: 0.6906114192385423
Epoch: 22 | Iteration number: [200/565] 35% | Training loss: 0.6904300281405449
Epoch: 22 | Iteration number: [210/565] 37% | Training loss: 0.6902768308208103
Epoch: 22 | Iteration number: [220/565] 38% | Training loss: 0.6900949088009921
Epoch: 22 | Iteration number: [230/565] 40% | Training loss: 0.6899610998837844
Epoch: 22 | Iteration number: [240/565] 42% | Training loss: 0.6898424488802751
Epoch: 22 | Iteration number: [250/565] 44% | Training loss: 0.6897120037078858
Epoch: 22 | Iteration number: [260/565] 46% | Training loss: 0.6896186331143745
Epoch: 22 | Iteration number: [270/565] 47% | Training loss: 0.6895205469043166
Epoch: 22 | Iteration number: [280/565] 49% | Training loss: 0.6894321807793209
Epoch: 22 | Iteration number: [290/565] 51% | Training loss: 0.689352136028224
Epoch: 22 | Iteration number: [300/565] 53% | Training loss: 0.6892896922429402
Epoch: 22 | Iteration number: [310/565] 54% | Training loss: 0.6892179839072688
Epoch: 22 | Iteration number: [320/565] 56% | Training loss: 0.6891497772186994
Epoch: 22 | Iteration number: [330/565] 58% | Training loss: 0.6890653975082166
Epoch: 22 | Iteration number: [340/565] 60% | Training loss: 0.6890029565376394
Epoch: 22 | Iteration number: [350/565] 61% | Training loss: 0.6889447273526873
Epoch: 22 | Iteration number: [360/565] 63% | Training loss: 0.6889008361432287
Epoch: 22 | Iteration number: [370/565] 65% | Training loss: 0.6888376566203864
Epoch: 22 | Iteration number: [380/565] 67% | Training loss: 0.6887819712099276
Epoch: 22 | Iteration number: [390/565] 69% | Training loss: 0.6887326462146564
Epoch: 22 | Iteration number: [400/565] 70% | Training loss: 0.6886865659058095
Epoch: 22 | Iteration number: [410/565] 72% | Training loss: 0.6886299171098849
Epoch: 22 | Iteration number: [420/565] 74% | Training loss: 0.6885885721161252
Epoch: 22 | Iteration number: [430/565] 76% | Training loss: 0.6885446183903273
Epoch: 22 | Iteration number: [440/565] 77% | Training loss: 0.6885115218433466
Epoch: 22 | Iteration number: [450/565] 79% | Training loss: 0.6884909604655371
Epoch: 22 | Iteration number: [460/565] 81% | Training loss: 0.6884562966616258
Epoch: 22 | Iteration number: [470/565] 83% | Training loss: 0.6884250709351073
Epoch: 22 | Iteration number: [480/565] 84% | Training loss: 0.6883958672483762
Epoch: 22 | Iteration number: [490/565] 86% | Training loss: 0.6883628389056848
Epoch: 22 | Iteration number: [500/565] 88% | Training loss: 0.6883386882543564
Epoch: 22 | Iteration number: [510/565] 90% | Training loss: 0.6883116674189474
Epoch: 22 | Iteration number: [520/565] 92% | Training loss: 0.6882939893465776
Epoch: 22 | Iteration number: [530/565] 93% | Training loss: 0.6882716120414014
Epoch: 22 | Iteration number: [540/565] 95% | Training loss: 0.6882484473564007
Epoch: 22 | Iteration number: [550/565] 97% | Training loss: 0.6882298549738797
Epoch: 22 | Iteration number: [560/565] 99% | Training loss: 0.6882010746215071

 End of epoch: 22 | Train Loss: 0.6869717875413135 | Training Time: 88 

 End of epoch: 22 | Eval Loss: 0.6897897635187421 | Evaluating Time: 6 
Epoch: 23 | Iteration number: [10/565] 1% | Training loss: 0.7553579986095429
Epoch: 23 | Iteration number: [20/565] 3% | Training loss: 0.7211193174123764
Epoch: 23 | Iteration number: [30/565] 5% | Training loss: 0.709792027870814
Epoch: 23 | Iteration number: [40/565] 7% | Training loss: 0.7041529446840287
Epoch: 23 | Iteration number: [50/565] 8% | Training loss: 0.7007077002525329
Epoch: 23 | Iteration number: [60/565] 10% | Training loss: 0.6985128959019978
Epoch: 23 | Iteration number: [70/565] 12% | Training loss: 0.6968318981783731
Epoch: 23 | Iteration number: [80/565] 14% | Training loss: 0.6956150472164154
Epoch: 23 | Iteration number: [90/565] 15% | Training loss: 0.6946396562788222
Epoch: 23 | Iteration number: [100/565] 17% | Training loss: 0.6939033806324005
Epoch: 23 | Iteration number: [110/565] 19% | Training loss: 0.693255889415741
Epoch: 23 | Iteration number: [120/565] 21% | Training loss: 0.6927565743525823
Epoch: 23 | Iteration number: [130/565] 23% | Training loss: 0.692302134862313
Epoch: 23 | Iteration number: [140/565] 24% | Training loss: 0.6918891595942633
Epoch: 23 | Iteration number: [150/565] 26% | Training loss: 0.6915396336714427
Epoch: 23 | Iteration number: [160/565] 28% | Training loss: 0.6912235412746668
Epoch: 23 | Iteration number: [170/565] 30% | Training loss: 0.6909783833167132
Epoch: 23 | Iteration number: [180/565] 31% | Training loss: 0.6907772203286489
Epoch: 23 | Iteration number: [190/565] 33% | Training loss: 0.6905733287334442
Epoch: 23 | Iteration number: [200/565] 35% | Training loss: 0.6903814753890037
Epoch: 23 | Iteration number: [210/565] 37% | Training loss: 0.6902289546671367
Epoch: 23 | Iteration number: [220/565] 38% | Training loss: 0.690097363428636
Epoch: 23 | Iteration number: [230/565] 40% | Training loss: 0.689960069241731
Epoch: 23 | Iteration number: [240/565] 42% | Training loss: 0.6898283079266548
Epoch: 23 | Iteration number: [250/565] 44% | Training loss: 0.6897133212089539
Epoch: 23 | Iteration number: [260/565] 46% | Training loss: 0.6895986375900415
Epoch: 23 | Iteration number: [270/565] 47% | Training loss: 0.6894978066285451
Epoch: 23 | Iteration number: [280/565] 49% | Training loss: 0.6894168615341186
Epoch: 23 | Iteration number: [290/565] 51% | Training loss: 0.6893421629379536
Epoch: 23 | Iteration number: [300/565] 53% | Training loss: 0.6892515369256338
Epoch: 23 | Iteration number: [310/565] 54% | Training loss: 0.6891949263311201
Epoch: 23 | Iteration number: [320/565] 56% | Training loss: 0.6891301671043039
Epoch: 23 | Iteration number: [330/565] 58% | Training loss: 0.6890561177875056
Epoch: 23 | Iteration number: [340/565] 60% | Training loss: 0.688999187595704
Epoch: 23 | Iteration number: [350/565] 61% | Training loss: 0.6889351378168379
Epoch: 23 | Iteration number: [360/565] 63% | Training loss: 0.6888735241360134
Epoch: 23 | Iteration number: [370/565] 65% | Training loss: 0.6888154456744323
Epoch: 23 | Iteration number: [380/565] 67% | Training loss: 0.6887712324920453
Epoch: 23 | Iteration number: [390/565] 69% | Training loss: 0.6887196108316764
Epoch: 23 | Iteration number: [400/565] 70% | Training loss: 0.6886790859699249
Epoch: 23 | Iteration number: [410/565] 72% | Training loss: 0.6886399343246367
Epoch: 23 | Iteration number: [420/565] 74% | Training loss: 0.6885929195653825
Epoch: 23 | Iteration number: [430/565] 76% | Training loss: 0.6885450529497723
Epoch: 23 | Iteration number: [440/565] 77% | Training loss: 0.6885082387111404
Epoch: 23 | Iteration number: [450/565] 79% | Training loss: 0.6884798177083333
Epoch: 23 | Iteration number: [460/565] 81% | Training loss: 0.6884475108074105
Epoch: 23 | Iteration number: [470/565] 83% | Training loss: 0.6884060363820259
Epoch: 23 | Iteration number: [480/565] 84% | Training loss: 0.68837707079947
Epoch: 23 | Iteration number: [490/565] 86% | Training loss: 0.6883554580260296
Epoch: 23 | Iteration number: [500/565] 88% | Training loss: 0.6883171834945678
Epoch: 23 | Iteration number: [510/565] 90% | Training loss: 0.6882890502611796
Epoch: 23 | Iteration number: [520/565] 92% | Training loss: 0.6882681761796657
Epoch: 23 | Iteration number: [530/565] 93% | Training loss: 0.6882583719379497
Epoch: 23 | Iteration number: [540/565] 95% | Training loss: 0.6882409545006576
Epoch: 23 | Iteration number: [550/565] 97% | Training loss: 0.6882154485312375
Epoch: 23 | Iteration number: [560/565] 99% | Training loss: 0.6881884972964014

 End of epoch: 23 | Train Loss: 0.6869631146962664 | Training Time: 87 

 End of epoch: 23 | Eval Loss: 0.690554107938494 | Evaluating Time: 6 
Epoch: 24 | Iteration number: [10/565] 1% | Training loss: 0.7556030929088593
Epoch: 24 | Iteration number: [20/565] 3% | Training loss: 0.7215881407260895
Epoch: 24 | Iteration number: [30/565] 5% | Training loss: 0.7099602321783701
Epoch: 24 | Iteration number: [40/565] 7% | Training loss: 0.7042655363678932
Epoch: 24 | Iteration number: [50/565] 8% | Training loss: 0.7007890236377716
Epoch: 24 | Iteration number: [60/565] 10% | Training loss: 0.6984936694304148
Epoch: 24 | Iteration number: [70/565] 12% | Training loss: 0.6968896789210183
Epoch: 24 | Iteration number: [80/565] 14% | Training loss: 0.6956134095788002
Epoch: 24 | Iteration number: [90/565] 15% | Training loss: 0.6946483393510182
Epoch: 24 | Iteration number: [100/565] 17% | Training loss: 0.6938647723197937
Epoch: 24 | Iteration number: [110/565] 19% | Training loss: 0.6932524968277324
Epoch: 24 | Iteration number: [120/565] 21% | Training loss: 0.6927320251862208
Epoch: 24 | Iteration number: [130/565] 23% | Training loss: 0.6922821691403023
Epoch: 24 | Iteration number: [140/565] 24% | Training loss: 0.6918992472546441
Epoch: 24 | Iteration number: [150/565] 26% | Training loss: 0.6915659817059835
Epoch: 24 | Iteration number: [160/565] 28% | Training loss: 0.6912733260542154
Epoch: 24 | Iteration number: [170/565] 30% | Training loss: 0.6910286128520966
Epoch: 24 | Iteration number: [180/565] 31% | Training loss: 0.6907992949088414
Epoch: 24 | Iteration number: [190/565] 33% | Training loss: 0.6905998694269281
Epoch: 24 | Iteration number: [200/565] 35% | Training loss: 0.6904310321807862
Epoch: 24 | Iteration number: [210/565] 37% | Training loss: 0.6902752566905249
Epoch: 24 | Iteration number: [220/565] 38% | Training loss: 0.6901374949650331
Epoch: 24 | Iteration number: [230/565] 40% | Training loss: 0.6899964306665504
Epoch: 24 | Iteration number: [240/565] 42% | Training loss: 0.6898850508034229
Epoch: 24 | Iteration number: [250/565] 44% | Training loss: 0.689757114648819
Epoch: 24 | Iteration number: [260/565] 46% | Training loss: 0.6896497265650676
Epoch: 24 | Iteration number: [270/565] 47% | Training loss: 0.6895466583746451
Epoch: 24 | Iteration number: [280/565] 49% | Training loss: 0.689454219170979
Epoch: 24 | Iteration number: [290/565] 51% | Training loss: 0.6893624833945571
Epoch: 24 | Iteration number: [300/565] 53% | Training loss: 0.6892725449800491
Epoch: 24 | Iteration number: [310/565] 54% | Training loss: 0.6891875324710723
Epoch: 24 | Iteration number: [320/565] 56% | Training loss: 0.6891284801065922
Epoch: 24 | Iteration number: [330/565] 58% | Training loss: 0.6890492692138209
Epoch: 24 | Iteration number: [340/565] 60% | Training loss: 0.6889786795658224
Epoch: 24 | Iteration number: [350/565] 61% | Training loss: 0.6889305693762643
Epoch: 24 | Iteration number: [360/565] 63% | Training loss: 0.6888616273800532
Epoch: 24 | Iteration number: [370/565] 65% | Training loss: 0.6888070119393839
Epoch: 24 | Iteration number: [380/565] 67% | Training loss: 0.688754265559347
Epoch: 24 | Iteration number: [390/565] 69% | Training loss: 0.6887125877233652
Epoch: 24 | Iteration number: [400/565] 70% | Training loss: 0.688662691116333
Epoch: 24 | Iteration number: [410/565] 72% | Training loss: 0.6886220155692682
Epoch: 24 | Iteration number: [420/565] 74% | Training loss: 0.6885928659212022
Epoch: 24 | Iteration number: [430/565] 76% | Training loss: 0.688543360593707
Epoch: 24 | Iteration number: [440/565] 77% | Training loss: 0.6885094695470549
Epoch: 24 | Iteration number: [450/565] 79% | Training loss: 0.6884653064939711
Epoch: 24 | Iteration number: [460/565] 81% | Training loss: 0.6884231807097144
Epoch: 24 | Iteration number: [470/565] 83% | Training loss: 0.6883875283789127
Epoch: 24 | Iteration number: [480/565] 84% | Training loss: 0.6883606066306432
Epoch: 24 | Iteration number: [490/565] 86% | Training loss: 0.6883397604737963
Epoch: 24 | Iteration number: [500/565] 88% | Training loss: 0.6883090896606445
Epoch: 24 | Iteration number: [510/565] 90% | Training loss: 0.6882860274875865
Epoch: 24 | Iteration number: [520/565] 92% | Training loss: 0.6882556906113257
Epoch: 24 | Iteration number: [530/565] 93% | Training loss: 0.6882336090195854
Epoch: 24 | Iteration number: [540/565] 95% | Training loss: 0.6882082211750525
Epoch: 24 | Iteration number: [550/565] 97% | Training loss: 0.6881916500221599
Epoch: 24 | Iteration number: [560/565] 99% | Training loss: 0.6881704261260373

 End of epoch: 24 | Train Loss: 0.686948319241009 | Training Time: 90 

 End of epoch: 24 | Eval Loss: 0.6898547496114459 | Evaluating Time: 5 
Epoch: 25 | Iteration number: [10/565] 1% | Training loss: 0.7556738138198853
Epoch: 25 | Iteration number: [20/565] 3% | Training loss: 0.7214061856269837
Epoch: 25 | Iteration number: [30/565] 5% | Training loss: 0.7098896861076355
Epoch: 25 | Iteration number: [40/565] 7% | Training loss: 0.7041197150945664
Epoch: 25 | Iteration number: [50/565] 8% | Training loss: 0.7006196391582489
Epoch: 25 | Iteration number: [60/565] 10% | Training loss: 0.6983790834744771
Epoch: 25 | Iteration number: [70/565] 12% | Training loss: 0.6968253323010036
Epoch: 25 | Iteration number: [80/565] 14% | Training loss: 0.6955981031060219
Epoch: 25 | Iteration number: [90/565] 15% | Training loss: 0.6946749289830526
Epoch: 25 | Iteration number: [100/565] 17% | Training loss: 0.6938844162225724
Epoch: 25 | Iteration number: [110/565] 19% | Training loss: 0.693224614316767
Epoch: 25 | Iteration number: [120/565] 21% | Training loss: 0.6927002420028051
Epoch: 25 | Iteration number: [130/565] 23% | Training loss: 0.6922315244491284
Epoch: 25 | Iteration number: [140/565] 24% | Training loss: 0.6918402731418609
Epoch: 25 | Iteration number: [150/565] 26% | Training loss: 0.6915244992574056
Epoch: 25 | Iteration number: [160/565] 28% | Training loss: 0.6912071112543344
Epoch: 25 | Iteration number: [170/565] 30% | Training loss: 0.6909104403327493
Epoch: 25 | Iteration number: [180/565] 31% | Training loss: 0.6906986577643288
Epoch: 25 | Iteration number: [190/565] 33% | Training loss: 0.690510731935501
Epoch: 25 | Iteration number: [200/565] 35% | Training loss: 0.6903313639760017
Epoch: 25 | Iteration number: [210/565] 37% | Training loss: 0.6901741541567303
Epoch: 25 | Iteration number: [220/565] 38% | Training loss: 0.6900496192953803
Epoch: 25 | Iteration number: [230/565] 40% | Training loss: 0.6899159760578819
Epoch: 25 | Iteration number: [240/565] 42% | Training loss: 0.6897882076601187
Epoch: 25 | Iteration number: [250/565] 44% | Training loss: 0.6896679255962371
Epoch: 25 | Iteration number: [260/565] 46% | Training loss: 0.6895549492194102
Epoch: 25 | Iteration number: [270/565] 47% | Training loss: 0.6894616261676506
Epoch: 25 | Iteration number: [280/565] 49% | Training loss: 0.6893737771681376
Epoch: 25 | Iteration number: [290/565] 51% | Training loss: 0.6892651173575172
Epoch: 25 | Iteration number: [300/565] 53% | Training loss: 0.6891968041658402
Epoch: 25 | Iteration number: [310/565] 54% | Training loss: 0.6891300955126363
Epoch: 25 | Iteration number: [320/565] 56% | Training loss: 0.6890641886740922
Epoch: 25 | Iteration number: [330/565] 58% | Training loss: 0.6889897783597311
Epoch: 25 | Iteration number: [340/565] 60% | Training loss: 0.688939758609323
Epoch: 25 | Iteration number: [350/565] 61% | Training loss: 0.6888873103686741
Epoch: 25 | Iteration number: [360/565] 63% | Training loss: 0.6888347667124536
Epoch: 25 | Iteration number: [370/565] 65% | Training loss: 0.688782586761423
Epoch: 25 | Iteration number: [380/565] 67% | Training loss: 0.6887354138650392
Epoch: 25 | Iteration number: [390/565] 69% | Training loss: 0.6886866658161848
Epoch: 25 | Iteration number: [400/565] 70% | Training loss: 0.6886382502317429
Epoch: 25 | Iteration number: [410/565] 72% | Training loss: 0.6885969364061588
Epoch: 25 | Iteration number: [420/565] 74% | Training loss: 0.6885558219183059
Epoch: 25 | Iteration number: [430/565] 76% | Training loss: 0.6885213997474936
Epoch: 25 | Iteration number: [440/565] 77% | Training loss: 0.6884897181933577
Epoch: 25 | Iteration number: [450/565] 79% | Training loss: 0.688460140493181
Epoch: 25 | Iteration number: [460/565] 81% | Training loss: 0.6884130419596382
Epoch: 25 | Iteration number: [470/565] 83% | Training loss: 0.688378954948263
Epoch: 25 | Iteration number: [480/565] 84% | Training loss: 0.6883452357103427
Epoch: 25 | Iteration number: [490/565] 86% | Training loss: 0.6883197902416697
Epoch: 25 | Iteration number: [500/565] 88% | Training loss: 0.6882911108732224
Epoch: 25 | Iteration number: [510/565] 90% | Training loss: 0.6882656617491854
Epoch: 25 | Iteration number: [520/565] 92% | Training loss: 0.6882335488612835
Epoch: 25 | Iteration number: [530/565] 93% | Training loss: 0.6882078366459541
Epoch: 25 | Iteration number: [540/565] 95% | Training loss: 0.6881839998342373
Epoch: 25 | Iteration number: [550/565] 97% | Training loss: 0.6881668772480705
Epoch: 25 | Iteration number: [560/565] 99% | Training loss: 0.6881467213588102

 End of epoch: 25 | Train Loss: 0.6869141129265844 | Training Time: 90 

 End of epoch: 25 | Eval Loss: 0.6894304156303406 | Evaluating Time: 6 
Epoch: 26 | Iteration number: [10/565] 1% | Training loss: 0.7552706599235535
Epoch: 26 | Iteration number: [20/565] 3% | Training loss: 0.7212404787540436
Epoch: 26 | Iteration number: [30/565] 5% | Training loss: 0.7099204758803049
Epoch: 26 | Iteration number: [40/565] 7% | Training loss: 0.7042379230260849
Epoch: 26 | Iteration number: [50/565] 8% | Training loss: 0.7007427072525024
Epoch: 26 | Iteration number: [60/565] 10% | Training loss: 0.6984286566575368
Epoch: 26 | Iteration number: [70/565] 12% | Training loss: 0.6968046920640129
Epoch: 26 | Iteration number: [80/565] 14% | Training loss: 0.695576498657465
Epoch: 26 | Iteration number: [90/565] 15% | Training loss: 0.6946334620316823
Epoch: 26 | Iteration number: [100/565] 17% | Training loss: 0.6938287210464478
Epoch: 26 | Iteration number: [110/565] 19% | Training loss: 0.693190980499441
Epoch: 26 | Iteration number: [120/565] 21% | Training loss: 0.692689356704553
Epoch: 26 | Iteration number: [130/565] 23% | Training loss: 0.6922229936489692
Epoch: 26 | Iteration number: [140/565] 24% | Training loss: 0.6918411855186735
Epoch: 26 | Iteration number: [150/565] 26% | Training loss: 0.6915424338976542
Epoch: 26 | Iteration number: [160/565] 28% | Training loss: 0.691246472671628
Epoch: 26 | Iteration number: [170/565] 30% | Training loss: 0.6909824294202468
Epoch: 26 | Iteration number: [180/565] 31% | Training loss: 0.6907403018739489
Epoch: 26 | Iteration number: [190/565] 33% | Training loss: 0.6905150281755548
Epoch: 26 | Iteration number: [200/565] 35% | Training loss: 0.6903002578020095
Epoch: 26 | Iteration number: [210/565] 37% | Training loss: 0.6901393376645588
Epoch: 26 | Iteration number: [220/565] 38% | Training loss: 0.6899893430146304
Epoch: 26 | Iteration number: [230/565] 40% | Training loss: 0.6898436986881754
Epoch: 26 | Iteration number: [240/565] 42% | Training loss: 0.6897222566107909
Epoch: 26 | Iteration number: [250/565] 44% | Training loss: 0.6896265869140625
Epoch: 26 | Iteration number: [260/565] 46% | Training loss: 0.6895461701429807
Epoch: 26 | Iteration number: [270/565] 47% | Training loss: 0.6894494423159847
Epoch: 26 | Iteration number: [280/565] 49% | Training loss: 0.6893643813473838
Epoch: 26 | Iteration number: [290/565] 51% | Training loss: 0.6892655820682131
Epoch: 26 | Iteration number: [300/565] 53% | Training loss: 0.6891811229785283
Epoch: 26 | Iteration number: [310/565] 54% | Training loss: 0.6890995865867984
Epoch: 26 | Iteration number: [320/565] 56% | Training loss: 0.6890196111053228
Epoch: 26 | Iteration number: [330/565] 58% | Training loss: 0.6889594466397256
Epoch: 26 | Iteration number: [340/565] 60% | Training loss: 0.6889013860155554
Epoch: 26 | Iteration number: [350/565] 61% | Training loss: 0.6888455028193338
Epoch: 26 | Iteration number: [360/565] 63% | Training loss: 0.688793363670508
Epoch: 26 | Iteration number: [370/565] 65% | Training loss: 0.6887389845139271
Epoch: 26 | Iteration number: [380/565] 67% | Training loss: 0.6886894414299413
Epoch: 26 | Iteration number: [390/565] 69% | Training loss: 0.68864496136323
Epoch: 26 | Iteration number: [400/565] 70% | Training loss: 0.6885980260372162
Epoch: 26 | Iteration number: [410/565] 72% | Training loss: 0.6885666576827445
Epoch: 26 | Iteration number: [420/565] 74% | Training loss: 0.6885145791939327
Epoch: 26 | Iteration number: [430/565] 76% | Training loss: 0.6884750637897226
Epoch: 26 | Iteration number: [440/565] 77% | Training loss: 0.6884426920251413
Epoch: 26 | Iteration number: [450/565] 79% | Training loss: 0.6884080665641361
Epoch: 26 | Iteration number: [460/565] 81% | Training loss: 0.6883707030959751
Epoch: 26 | Iteration number: [470/565] 83% | Training loss: 0.6883268461582509
Epoch: 26 | Iteration number: [480/565] 84% | Training loss: 0.6882998408128818
Epoch: 26 | Iteration number: [490/565] 86% | Training loss: 0.6882680131464588
Epoch: 26 | Iteration number: [500/565] 88% | Training loss: 0.6882519258260726
Epoch: 26 | Iteration number: [510/565] 90% | Training loss: 0.6882393524927252
Epoch: 26 | Iteration number: [520/565] 92% | Training loss: 0.6882212312175677
Epoch: 26 | Iteration number: [530/565] 93% | Training loss: 0.6882003500776471
Epoch: 26 | Iteration number: [540/565] 95% | Training loss: 0.6881850211708634
Epoch: 26 | Iteration number: [550/565] 97% | Training loss: 0.688165450963107
Epoch: 26 | Iteration number: [560/565] 99% | Training loss: 0.6881393834948539

 End of epoch: 26 | Train Loss: 0.6869168603314763 | Training Time: 90 

 End of epoch: 26 | Eval Loss: 0.6904867376599994 | Evaluating Time: 6 
Epoch: 27 | Iteration number: [10/565] 1% | Training loss: 0.7555774331092835
Epoch: 27 | Iteration number: [20/565] 3% | Training loss: 0.7210188031196594
Epoch: 27 | Iteration number: [30/565] 5% | Training loss: 0.709673285484314
Epoch: 27 | Iteration number: [40/565] 7% | Training loss: 0.704010334610939
Epoch: 27 | Iteration number: [50/565] 8% | Training loss: 0.7004852950572967
Epoch: 27 | Iteration number: [60/565] 10% | Training loss: 0.698225216070811
Epoch: 27 | Iteration number: [70/565] 12% | Training loss: 0.6966090781348092
Epoch: 27 | Iteration number: [80/565] 14% | Training loss: 0.6953400664031506
Epoch: 27 | Iteration number: [90/565] 15% | Training loss: 0.6944648232724931
Epoch: 27 | Iteration number: [100/565] 17% | Training loss: 0.6937264311313629
Epoch: 27 | Iteration number: [110/565] 19% | Training loss: 0.6930900904265317
Epoch: 27 | Iteration number: [120/565] 21% | Training loss: 0.692588654657205
Epoch: 27 | Iteration number: [130/565] 23% | Training loss: 0.6921569416156181
Epoch: 27 | Iteration number: [140/565] 24% | Training loss: 0.691785432611193
Epoch: 27 | Iteration number: [150/565] 26% | Training loss: 0.6914717809359232
Epoch: 27 | Iteration number: [160/565] 28% | Training loss: 0.6912230599671603
Epoch: 27 | Iteration number: [170/565] 30% | Training loss: 0.6909765657256631
Epoch: 27 | Iteration number: [180/565] 31% | Training loss: 0.6907392687267727
Epoch: 27 | Iteration number: [190/565] 33% | Training loss: 0.6905613864723005
Epoch: 27 | Iteration number: [200/565] 35% | Training loss: 0.6904065775871276
Epoch: 27 | Iteration number: [210/565] 37% | Training loss: 0.6902351078532991
Epoch: 27 | Iteration number: [220/565] 38% | Training loss: 0.6901005379178308
Epoch: 27 | Iteration number: [230/565] 40% | Training loss: 0.68999157651611
Epoch: 27 | Iteration number: [240/565] 42% | Training loss: 0.6898471916715304
Epoch: 27 | Iteration number: [250/565] 44% | Training loss: 0.6897116239070893
Epoch: 27 | Iteration number: [260/565] 46% | Training loss: 0.6895958687250431
Epoch: 27 | Iteration number: [270/565] 47% | Training loss: 0.6894913386415552
Epoch: 27 | Iteration number: [280/565] 49% | Training loss: 0.6893923868026052
Epoch: 27 | Iteration number: [290/565] 51% | Training loss: 0.6892958651328909
Epoch: 27 | Iteration number: [300/565] 53% | Training loss: 0.6892322643597921
Epoch: 27 | Iteration number: [310/565] 54% | Training loss: 0.6891533003699395
Epoch: 27 | Iteration number: [320/565] 56% | Training loss: 0.6890742411836982
Epoch: 27 | Iteration number: [330/565] 58% | Training loss: 0.6890114681287245
Epoch: 27 | Iteration number: [340/565] 60% | Training loss: 0.6889440587338279
Epoch: 27 | Iteration number: [350/565] 61% | Training loss: 0.6888767559187753
Epoch: 27 | Iteration number: [360/565] 63% | Training loss: 0.6888365086581972
Epoch: 27 | Iteration number: [370/565] 65% | Training loss: 0.6887872315741874
Epoch: 27 | Iteration number: [380/565] 67% | Training loss: 0.6887349919268959
Epoch: 27 | Iteration number: [390/565] 69% | Training loss: 0.6886839703107491
Epoch: 27 | Iteration number: [400/565] 70% | Training loss: 0.6886461773514747
Epoch: 27 | Iteration number: [410/565] 72% | Training loss: 0.6886035823240513
Epoch: 27 | Iteration number: [420/565] 74% | Training loss: 0.6885613379024323
Epoch: 27 | Iteration number: [430/565] 76% | Training loss: 0.6885208445926045
Epoch: 27 | Iteration number: [440/565] 77% | Training loss: 0.6884795738892122
Epoch: 27 | Iteration number: [450/565] 79% | Training loss: 0.6884536147117615
Epoch: 27 | Iteration number: [460/565] 81% | Training loss: 0.6884135209995768
Epoch: 27 | Iteration number: [470/565] 83% | Training loss: 0.6883790394093128
Epoch: 27 | Iteration number: [480/565] 84% | Training loss: 0.6883444391191006
Epoch: 27 | Iteration number: [490/565] 86% | Training loss: 0.6883159302935309
Epoch: 27 | Iteration number: [500/565] 88% | Training loss: 0.6882879079580307
Epoch: 27 | Iteration number: [510/565] 90% | Training loss: 0.6882600374081556
Epoch: 27 | Iteration number: [520/565] 92% | Training loss: 0.688236282651241
Epoch: 27 | Iteration number: [530/565] 93% | Training loss: 0.688199896744962
Epoch: 27 | Iteration number: [540/565] 95% | Training loss: 0.688180970924872
Epoch: 27 | Iteration number: [550/565] 97% | Training loss: 0.6881621612202038
Epoch: 27 | Iteration number: [560/565] 99% | Training loss: 0.6881406291254929

 End of epoch: 27 | Train Loss: 0.6869135108669248 | Training Time: 89 

 End of epoch: 27 | Eval Loss: 0.690082882131849 | Evaluating Time: 5 
Epoch: 28 | Iteration number: [10/565] 1% | Training loss: 0.7554915428161622
Epoch: 28 | Iteration number: [20/565] 3% | Training loss: 0.7209326982498169
Epoch: 28 | Iteration number: [30/565] 5% | Training loss: 0.709669425090154
Epoch: 28 | Iteration number: [40/565] 7% | Training loss: 0.7039646416902542
Epoch: 28 | Iteration number: [50/565] 8% | Training loss: 0.7005734694004059
Epoch: 28 | Iteration number: [60/565] 10% | Training loss: 0.6983581771453221
Epoch: 28 | Iteration number: [70/565] 12% | Training loss: 0.6967379808425903
Epoch: 28 | Iteration number: [80/565] 14% | Training loss: 0.6955148011446
Epoch: 28 | Iteration number: [90/565] 15% | Training loss: 0.694537224372228
Epoch: 28 | Iteration number: [100/565] 17% | Training loss: 0.6937889170646667
Epoch: 28 | Iteration number: [110/565] 19% | Training loss: 0.6931657964533026
Epoch: 28 | Iteration number: [120/565] 21% | Training loss: 0.692636276781559
Epoch: 28 | Iteration number: [130/565] 23% | Training loss: 0.6922058976613559
Epoch: 28 | Iteration number: [140/565] 24% | Training loss: 0.691837472149304
Epoch: 28 | Iteration number: [150/565] 26% | Training loss: 0.6915159678459167
Epoch: 28 | Iteration number: [160/565] 28% | Training loss: 0.6912153579294682
Epoch: 28 | Iteration number: [170/565] 30% | Training loss: 0.6909919451264774
Epoch: 28 | Iteration number: [180/565] 31% | Training loss: 0.6907476070854399
Epoch: 28 | Iteration number: [190/565] 33% | Training loss: 0.6905198178793255
Epoch: 28 | Iteration number: [200/565] 35% | Training loss: 0.6903375598788262
Epoch: 28 | Iteration number: [210/565] 37% | Training loss: 0.6901863909903027
Epoch: 28 | Iteration number: [220/565] 38% | Training loss: 0.6900468162514947
Epoch: 28 | Iteration number: [230/565] 40% | Training loss: 0.6899034976959229
Epoch: 28 | Iteration number: [240/565] 42% | Training loss: 0.6897524642447631
Epoch: 28 | Iteration number: [250/565] 44% | Training loss: 0.6896358141899109
Epoch: 28 | Iteration number: [260/565] 46% | Training loss: 0.6895405329190768
Epoch: 28 | Iteration number: [270/565] 47% | Training loss: 0.6894462106404481
Epoch: 28 | Iteration number: [280/565] 49% | Training loss: 0.6893447999443326
Epoch: 28 | Iteration number: [290/565] 51% | Training loss: 0.6892751782104887
Epoch: 28 | Iteration number: [300/565] 53% | Training loss: 0.6891871257623037
Epoch: 28 | Iteration number: [310/565] 54% | Training loss: 0.6891117028651699
Epoch: 28 | Iteration number: [320/565] 56% | Training loss: 0.6890487210825086
Epoch: 28 | Iteration number: [330/565] 58% | Training loss: 0.6889707182392929
Epoch: 28 | Iteration number: [340/565] 60% | Training loss: 0.6889219617142397
Epoch: 28 | Iteration number: [350/565] 61% | Training loss: 0.688856223310743
Epoch: 28 | Iteration number: [360/565] 63% | Training loss: 0.6888071184357007
Epoch: 28 | Iteration number: [370/565] 65% | Training loss: 0.6887667478741826
Epoch: 28 | Iteration number: [380/565] 67% | Training loss: 0.6887011689575095
Epoch: 28 | Iteration number: [390/565] 69% | Training loss: 0.6886556607026321
Epoch: 28 | Iteration number: [400/565] 70% | Training loss: 0.6886195100843906
Epoch: 28 | Iteration number: [410/565] 72% | Training loss: 0.6885764059497089
Epoch: 28 | Iteration number: [420/565] 74% | Training loss: 0.688529150400843
Epoch: 28 | Iteration number: [430/565] 76% | Training loss: 0.6884993508804677
Epoch: 28 | Iteration number: [440/565] 77% | Training loss: 0.6884673251347109
Epoch: 28 | Iteration number: [450/565] 79% | Training loss: 0.6884457541836633
Epoch: 28 | Iteration number: [460/565] 81% | Training loss: 0.6884124473385189
Epoch: 28 | Iteration number: [470/565] 83% | Training loss: 0.6883735590792717
Epoch: 28 | Iteration number: [480/565] 84% | Training loss: 0.6883424391349157
Epoch: 28 | Iteration number: [490/565] 86% | Training loss: 0.6883128534774391
Epoch: 28 | Iteration number: [500/565] 88% | Training loss: 0.6882830210924149
Epoch: 28 | Iteration number: [510/565] 90% | Training loss: 0.6882616789901957
Epoch: 28 | Iteration number: [520/565] 92% | Training loss: 0.6882327343408878
Epoch: 28 | Iteration number: [530/565] 93% | Training loss: 0.6882100052428696
Epoch: 28 | Iteration number: [540/565] 95% | Training loss: 0.6881877479729829
Epoch: 28 | Iteration number: [550/565] 97% | Training loss: 0.688153858835047
Epoch: 28 | Iteration number: [560/565] 99% | Training loss: 0.6881291151046753

 End of epoch: 28 | Train Loss: 0.6869043428285987 | Training Time: 88 

 End of epoch: 28 | Eval Loss: 0.689895008291517 | Evaluating Time: 6 
Epoch: 29 | Iteration number: [10/565] 1% | Training loss: 0.7557596087455749
Epoch: 29 | Iteration number: [20/565] 3% | Training loss: 0.7212872773408889
Epoch: 29 | Iteration number: [30/565] 5% | Training loss: 0.7097231388092041
Epoch: 29 | Iteration number: [40/565] 7% | Training loss: 0.7040084809064865
Epoch: 29 | Iteration number: [50/565] 8% | Training loss: 0.7004676485061645
Epoch: 29 | Iteration number: [60/565] 10% | Training loss: 0.6981881320476532
Epoch: 29 | Iteration number: [70/565] 12% | Training loss: 0.6965486586093903
Epoch: 29 | Iteration number: [80/565] 14% | Training loss: 0.6953046225011349
Epoch: 29 | Iteration number: [90/565] 15% | Training loss: 0.6943870054350959
Epoch: 29 | Iteration number: [100/565] 17% | Training loss: 0.6935869961977005
Epoch: 29 | Iteration number: [110/565] 19% | Training loss: 0.6929749369621276
Epoch: 29 | Iteration number: [120/565] 21% | Training loss: 0.6924810866514842
Epoch: 29 | Iteration number: [130/565] 23% | Training loss: 0.6920724845849551
Epoch: 29 | Iteration number: [140/565] 24% | Training loss: 0.6917060217687062
Epoch: 29 | Iteration number: [150/565] 26% | Training loss: 0.6913655583063761
Epoch: 29 | Iteration number: [160/565] 28% | Training loss: 0.6911155544221401
Epoch: 29 | Iteration number: [170/565] 30% | Training loss: 0.6908611834049225
Epoch: 29 | Iteration number: [180/565] 31% | Training loss: 0.6906559652752347
Epoch: 29 | Iteration number: [190/565] 33% | Training loss: 0.6904610028392391
Epoch: 29 | Iteration number: [200/565] 35% | Training loss: 0.6902659115195274
Epoch: 29 | Iteration number: [210/565] 37% | Training loss: 0.6901282475108192
Epoch: 29 | Iteration number: [220/565] 38% | Training loss: 0.6899859761649912
Epoch: 29 | Iteration number: [230/565] 40% | Training loss: 0.6898463612017425
Epoch: 29 | Iteration number: [240/565] 42% | Training loss: 0.6897213108837604
Epoch: 29 | Iteration number: [250/565] 44% | Training loss: 0.6895896847248077
Epoch: 29 | Iteration number: [260/565] 46% | Training loss: 0.6894855139347223
Epoch: 29 | Iteration number: [270/565] 47% | Training loss: 0.6893794300379577
Epoch: 29 | Iteration number: [280/565] 49% | Training loss: 0.6892971954175404
Epoch: 29 | Iteration number: [290/565] 51% | Training loss: 0.6892201816213542
Epoch: 29 | Iteration number: [300/565] 53% | Training loss: 0.6891486783822377
Epoch: 29 | Iteration number: [310/565] 54% | Training loss: 0.6890759754565454
Epoch: 29 | Iteration number: [320/565] 56% | Training loss: 0.6890043217688799
Epoch: 29 | Iteration number: [330/565] 58% | Training loss: 0.6889394373604746
Epoch: 29 | Iteration number: [340/565] 60% | Training loss: 0.6888699948787689
Epoch: 29 | Iteration number: [350/565] 61% | Training loss: 0.6888155898026057
Epoch: 29 | Iteration number: [360/565] 63% | Training loss: 0.6887636489338345
Epoch: 29 | Iteration number: [370/565] 65% | Training loss: 0.6887117877199843
Epoch: 29 | Iteration number: [380/565] 67% | Training loss: 0.6886768123036937
Epoch: 29 | Iteration number: [390/565] 69% | Training loss: 0.6886260619530311
Epoch: 29 | Iteration number: [400/565] 70% | Training loss: 0.6885813239216805
Epoch: 29 | Iteration number: [410/565] 72% | Training loss: 0.6885470247850185
Epoch: 29 | Iteration number: [420/565] 74% | Training loss: 0.6885072516543524
Epoch: 29 | Iteration number: [430/565] 76% | Training loss: 0.6884618524895157
Epoch: 29 | Iteration number: [440/565] 77% | Training loss: 0.6884299885142934
Epoch: 29 | Iteration number: [450/565] 79% | Training loss: 0.6883992587195502
Epoch: 29 | Iteration number: [460/565] 81% | Training loss: 0.6883685601794202
Epoch: 29 | Iteration number: [470/565] 83% | Training loss: 0.6883393001049123
Epoch: 29 | Iteration number: [480/565] 84% | Training loss: 0.6883144721388816
Epoch: 29 | Iteration number: [490/565] 86% | Training loss: 0.6882942996462997
Epoch: 29 | Iteration number: [500/565] 88% | Training loss: 0.6882673332691193
Epoch: 29 | Iteration number: [510/565] 90% | Training loss: 0.6882495157858904
Epoch: 29 | Iteration number: [520/565] 92% | Training loss: 0.6882291892400154
Epoch: 29 | Iteration number: [530/565] 93% | Training loss: 0.6882027128957352
Epoch: 29 | Iteration number: [540/565] 95% | Training loss: 0.6881733255253898
Epoch: 29 | Iteration number: [550/565] 97% | Training loss: 0.6881507858363065
Epoch: 29 | Iteration number: [560/565] 99% | Training loss: 0.6881254861397402

 End of epoch: 29 | Train Loss: 0.6869045142578868 | Training Time: 89 

 End of epoch: 29 | Eval Loss: 0.6899764963558742 | Evaluating Time: 5 
Epoch: 30 | Iteration number: [10/565] 1% | Training loss: 0.7556385636329651
Epoch: 30 | Iteration number: [20/565] 3% | Training loss: 0.7211742103099823
Epoch: 30 | Iteration number: [30/565] 5% | Training loss: 0.7097362081209818
Epoch: 30 | Iteration number: [40/565] 7% | Training loss: 0.704057639837265
Epoch: 30 | Iteration number: [50/565] 8% | Training loss: 0.7006833744049072
Epoch: 30 | Iteration number: [60/565] 10% | Training loss: 0.6983573456605275
Epoch: 30 | Iteration number: [70/565] 12% | Training loss: 0.6967329953398024
Epoch: 30 | Iteration number: [80/565] 14% | Training loss: 0.6954696498811245
Epoch: 30 | Iteration number: [90/565] 15% | Training loss: 0.6944711499743992
Epoch: 30 | Iteration number: [100/565] 17% | Training loss: 0.6937564915418625
Epoch: 30 | Iteration number: [110/565] 19% | Training loss: 0.6930920254100453
Epoch: 30 | Iteration number: [120/565] 21% | Training loss: 0.6925918544332187
Epoch: 30 | Iteration number: [130/565] 23% | Training loss: 0.6921447171614721
Epoch: 30 | Iteration number: [140/565] 24% | Training loss: 0.6917983697993415
Epoch: 30 | Iteration number: [150/565] 26% | Training loss: 0.6914749511082967
Epoch: 30 | Iteration number: [160/565] 28% | Training loss: 0.6912064000964164
Epoch: 30 | Iteration number: [170/565] 30% | Training loss: 0.6909643120625439
Epoch: 30 | Iteration number: [180/565] 31% | Training loss: 0.6907753086752362
Epoch: 30 | Iteration number: [190/565] 33% | Training loss: 0.6905658389392652
Epoch: 30 | Iteration number: [200/565] 35% | Training loss: 0.6903805536031723
Epoch: 30 | Iteration number: [210/565] 37% | Training loss: 0.6901903379531134
Epoch: 30 | Iteration number: [220/565] 38% | Training loss: 0.6900284710255536
Epoch: 30 | Iteration number: [230/565] 40% | Training loss: 0.689903083573217
Epoch: 30 | Iteration number: [240/565] 42% | Training loss: 0.6897680600484212
Epoch: 30 | Iteration number: [250/565] 44% | Training loss: 0.6896612896919251
Epoch: 30 | Iteration number: [260/565] 46% | Training loss: 0.6895537784466377
Epoch: 30 | Iteration number: [270/565] 47% | Training loss: 0.6894645858694006
Epoch: 30 | Iteration number: [280/565] 49% | Training loss: 0.6893656126090458
Epoch: 30 | Iteration number: [290/565] 51% | Training loss: 0.6892719040656912
Epoch: 30 | Iteration number: [300/565] 53% | Training loss: 0.6891889349619548
Epoch: 30 | Iteration number: [310/565] 54% | Training loss: 0.6891074617062846
Epoch: 30 | Iteration number: [320/565] 56% | Training loss: 0.6890280792489648
Epoch: 30 | Iteration number: [330/565] 58% | Training loss: 0.688990960337899
Epoch: 30 | Iteration number: [340/565] 60% | Training loss: 0.6889326719676747
Epoch: 30 | Iteration number: [350/565] 61% | Training loss: 0.6888679221698216
Epoch: 30 | Iteration number: [360/565] 63% | Training loss: 0.6888170518808895
Epoch: 30 | Iteration number: [370/565] 65% | Training loss: 0.6887671372374973
Epoch: 30 | Iteration number: [380/565] 67% | Training loss: 0.6887143751508311
Epoch: 30 | Iteration number: [390/565] 69% | Training loss: 0.688672539515373
Epoch: 30 | Iteration number: [400/565] 70% | Training loss: 0.6886263564229012
Epoch: 30 | Iteration number: [410/565] 72% | Training loss: 0.6885874880523216
Epoch: 30 | Iteration number: [420/565] 74% | Training loss: 0.6885383869920458
Epoch: 30 | Iteration number: [430/565] 76% | Training loss: 0.6885035635426987
Epoch: 30 | Iteration number: [440/565] 77% | Training loss: 0.6884721639481458
Epoch: 30 | Iteration number: [450/565] 79% | Training loss: 0.688436307642195
Epoch: 30 | Iteration number: [460/565] 81% | Training loss: 0.6883975341268208
Epoch: 30 | Iteration number: [470/565] 83% | Training loss: 0.6883705648970097
Epoch: 30 | Iteration number: [480/565] 84% | Training loss: 0.6883453616251548
Epoch: 30 | Iteration number: [490/565] 86% | Training loss: 0.688313567395113
Epoch: 30 | Iteration number: [500/565] 88% | Training loss: 0.6882907054424285
Epoch: 30 | Iteration number: [510/565] 90% | Training loss: 0.6882592607946957
Epoch: 30 | Iteration number: [520/565] 92% | Training loss: 0.6882307929488328
Epoch: 30 | Iteration number: [530/565] 93% | Training loss: 0.6882007822675525
Epoch: 30 | Iteration number: [540/565] 95% | Training loss: 0.6881768566590768
Epoch: 30 | Iteration number: [550/565] 97% | Training loss: 0.6881473556431857
Epoch: 30 | Iteration number: [560/565] 99% | Training loss: 0.688116054981947

 End of epoch: 30 | Train Loss: 0.686889171178362 | Training Time: 89 

 End of epoch: 30 | Eval Loss: 0.6902546797479902 | Evaluating Time: 6 
Epoch: 31 | Iteration number: [10/565] 1% | Training loss: 0.7554408609867096
Epoch: 31 | Iteration number: [20/565] 3% | Training loss: 0.7212539881467819
Epoch: 31 | Iteration number: [30/565] 5% | Training loss: 0.7095735649267833
Epoch: 31 | Iteration number: [40/565] 7% | Training loss: 0.7039936527609825
Epoch: 31 | Iteration number: [50/565] 8% | Training loss: 0.7005247557163239
Epoch: 31 | Iteration number: [60/565] 10% | Training loss: 0.6982747008403142
Epoch: 31 | Iteration number: [70/565] 12% | Training loss: 0.6966407103197915
Epoch: 31 | Iteration number: [80/565] 14% | Training loss: 0.6954061597585678
Epoch: 31 | Iteration number: [90/565] 15% | Training loss: 0.6944456093841129
Epoch: 31 | Iteration number: [100/565] 17% | Training loss: 0.6937417542934418
Epoch: 31 | Iteration number: [110/565] 19% | Training loss: 0.693143936178901
Epoch: 31 | Iteration number: [120/565] 21% | Training loss: 0.6925764774282773
Epoch: 31 | Iteration number: [130/565] 23% | Training loss: 0.6921451770342313
Epoch: 31 | Iteration number: [140/565] 24% | Training loss: 0.6917626751320702
Epoch: 31 | Iteration number: [150/565] 26% | Training loss: 0.6914551266034444
Epoch: 31 | Iteration number: [160/565] 28% | Training loss: 0.6911475002765656
Epoch: 31 | Iteration number: [170/565] 30% | Training loss: 0.6908770929364597
Epoch: 31 | Iteration number: [180/565] 31% | Training loss: 0.6906718350119061
Epoch: 31 | Iteration number: [190/565] 33% | Training loss: 0.6904751266303816
Epoch: 31 | Iteration number: [200/565] 35% | Training loss: 0.6903038841485977
Epoch: 31 | Iteration number: [210/565] 37% | Training loss: 0.6901465049811772
Epoch: 31 | Iteration number: [220/565] 38% | Training loss: 0.6899978122927926
Epoch: 31 | Iteration number: [230/565] 40% | Training loss: 0.6898476471071658
Epoch: 31 | Iteration number: [240/565] 42% | Training loss: 0.689735675851504
Epoch: 31 | Iteration number: [250/565] 44% | Training loss: 0.6896299192905426
Epoch: 31 | Iteration number: [260/565] 46% | Training loss: 0.6895205325805224
Epoch: 31 | Iteration number: [270/565] 47% | Training loss: 0.6894354820251465
Epoch: 31 | Iteration number: [280/565] 49% | Training loss: 0.6893556697028024
Epoch: 31 | Iteration number: [290/565] 51% | Training loss: 0.689281544192084
Epoch: 31 | Iteration number: [300/565] 53% | Training loss: 0.6892186574141185
Epoch: 31 | Iteration number: [310/565] 54% | Training loss: 0.6891572277392111
Epoch: 31 | Iteration number: [320/565] 56% | Training loss: 0.6890766398981214
Epoch: 31 | Iteration number: [330/565] 58% | Training loss: 0.6890079814376253
Epoch: 31 | Iteration number: [340/565] 60% | Training loss: 0.6889424632577336
Epoch: 31 | Iteration number: [350/565] 61% | Training loss: 0.6888710452829089
Epoch: 31 | Iteration number: [360/565] 63% | Training loss: 0.6888155458701981
Epoch: 31 | Iteration number: [370/565] 65% | Training loss: 0.6887661507000794
Epoch: 31 | Iteration number: [380/565] 67% | Training loss: 0.6887144436961726
Epoch: 31 | Iteration number: [390/565] 69% | Training loss: 0.6886666609690739
Epoch: 31 | Iteration number: [400/565] 70% | Training loss: 0.6886158294975757
Epoch: 31 | Iteration number: [410/565] 72% | Training loss: 0.6885691556988693
Epoch: 31 | Iteration number: [420/565] 74% | Training loss: 0.6885412671736308
Epoch: 31 | Iteration number: [430/565] 76% | Training loss: 0.6884986903778342
Epoch: 31 | Iteration number: [440/565] 77% | Training loss: 0.6884578580206091
Epoch: 31 | Iteration number: [450/565] 79% | Training loss: 0.6884298010667165
Epoch: 31 | Iteration number: [460/565] 81% | Training loss: 0.6883983761072159
Epoch: 31 | Iteration number: [470/565] 83% | Training loss: 0.6883703886194432
Epoch: 31 | Iteration number: [480/565] 84% | Training loss: 0.6883367504924536
Epoch: 31 | Iteration number: [490/565] 86% | Training loss: 0.6883088620341554
Epoch: 31 | Iteration number: [500/565] 88% | Training loss: 0.6882836731672287
Epoch: 31 | Iteration number: [510/565] 90% | Training loss: 0.6882500092188517
Epoch: 31 | Iteration number: [520/565] 92% | Training loss: 0.688223442206016
Epoch: 31 | Iteration number: [530/565] 93% | Training loss: 0.6881972240951826
Epoch: 31 | Iteration number: [540/565] 95% | Training loss: 0.6881780530567523
Epoch: 31 | Iteration number: [550/565] 97% | Training loss: 0.6881487141955983
Epoch: 31 | Iteration number: [560/565] 99% | Training loss: 0.6881353801914624

 End of epoch: 31 | Train Loss: 0.6869108820383527 | Training Time: 89 

 End of epoch: 31 | Eval Loss: 0.6899750402995518 | Evaluating Time: 6 
Epoch: 32 | Iteration number: [10/565] 1% | Training loss: 0.7554481208324433
Epoch: 32 | Iteration number: [20/565] 3% | Training loss: 0.7212919741868973
Epoch: 32 | Iteration number: [30/565] 5% | Training loss: 0.7098433117071787
Epoch: 32 | Iteration number: [40/565] 7% | Training loss: 0.7039382293820381
Epoch: 32 | Iteration number: [50/565] 8% | Training loss: 0.7005279362201691
Epoch: 32 | Iteration number: [60/565] 10% | Training loss: 0.6982909301916759
Epoch: 32 | Iteration number: [70/565] 12% | Training loss: 0.6967545620032719
Epoch: 32 | Iteration number: [80/565] 14% | Training loss: 0.6955908954143524
Epoch: 32 | Iteration number: [90/565] 15% | Training loss: 0.6945884413189358
Epoch: 32 | Iteration number: [100/565] 17% | Training loss: 0.6937895554304123
Epoch: 32 | Iteration number: [110/565] 19% | Training loss: 0.6931393043561416
Epoch: 32 | Iteration number: [120/565] 21% | Training loss: 0.6926044836640358
Epoch: 32 | Iteration number: [130/565] 23% | Training loss: 0.6921960757328913
Epoch: 32 | Iteration number: [140/565] 24% | Training loss: 0.6918493462460381
Epoch: 32 | Iteration number: [150/565] 26% | Training loss: 0.6915038839975993
Epoch: 32 | Iteration number: [160/565] 28% | Training loss: 0.6911956079304218
Epoch: 32 | Iteration number: [170/565] 30% | Training loss: 0.6909439353381887
Epoch: 32 | Iteration number: [180/565] 31% | Training loss: 0.6907000829776128
Epoch: 32 | Iteration number: [190/565] 33% | Training loss: 0.6905008645434129
Epoch: 32 | Iteration number: [200/565] 35% | Training loss: 0.6902968034148216
Epoch: 32 | Iteration number: [210/565] 37% | Training loss: 0.6901157001654307
Epoch: 32 | Iteration number: [220/565] 38% | Training loss: 0.6899605509909716
Epoch: 32 | Iteration number: [230/565] 40% | Training loss: 0.6898318881573884
Epoch: 32 | Iteration number: [240/565] 42% | Training loss: 0.6897218095759551
Epoch: 32 | Iteration number: [250/565] 44% | Training loss: 0.6896161582469941
Epoch: 32 | Iteration number: [260/565] 46% | Training loss: 0.6895038937146847
Epoch: 32 | Iteration number: [270/565] 47% | Training loss: 0.6894157537707576
Epoch: 32 | Iteration number: [280/565] 49% | Training loss: 0.6893495436225618
Epoch: 32 | Iteration number: [290/565] 51% | Training loss: 0.6892649837608995
Epoch: 32 | Iteration number: [300/565] 53% | Training loss: 0.6891766935586929
Epoch: 32 | Iteration number: [310/565] 54% | Training loss: 0.6890903255631847
Epoch: 32 | Iteration number: [320/565] 56% | Training loss: 0.6890229122713208
Epoch: 32 | Iteration number: [330/565] 58% | Training loss: 0.6889553965944233
Epoch: 32 | Iteration number: [340/565] 60% | Training loss: 0.6888887202038484
Epoch: 32 | Iteration number: [350/565] 61% | Training loss: 0.6888252692563194
Epoch: 32 | Iteration number: [360/565] 63% | Training loss: 0.6887720753749211
Epoch: 32 | Iteration number: [370/565] 65% | Training loss: 0.6887239507726721
Epoch: 32 | Iteration number: [380/565] 67% | Training loss: 0.6886691356960096
Epoch: 32 | Iteration number: [390/565] 69% | Training loss: 0.6886190788868146
Epoch: 32 | Iteration number: [400/565] 70% | Training loss: 0.6885775601863862
Epoch: 32 | Iteration number: [410/565] 72% | Training loss: 0.6885257677334111
Epoch: 32 | Iteration number: [420/565] 74% | Training loss: 0.688491581593241
Epoch: 32 | Iteration number: [430/565] 76% | Training loss: 0.6884438897288123
Epoch: 32 | Iteration number: [440/565] 77% | Training loss: 0.6884061057459224
Epoch: 32 | Iteration number: [450/565] 79% | Training loss: 0.6883779117796156
Epoch: 32 | Iteration number: [460/565] 81% | Training loss: 0.688342113468958
Epoch: 32 | Iteration number: [470/565] 83% | Training loss: 0.688314539194107
Epoch: 32 | Iteration number: [480/565] 84% | Training loss: 0.6882931763927141
Epoch: 32 | Iteration number: [490/565] 86% | Training loss: 0.6882727404030002
Epoch: 32 | Iteration number: [500/565] 88% | Training loss: 0.6882476561069488
Epoch: 32 | Iteration number: [510/565] 90% | Training loss: 0.6882190299969093
Epoch: 32 | Iteration number: [520/565] 92% | Training loss: 0.6881858542561531
Epoch: 32 | Iteration number: [530/565] 93% | Training loss: 0.6881705894785107
Epoch: 32 | Iteration number: [540/565] 95% | Training loss: 0.6881542605382425
Epoch: 32 | Iteration number: [550/565] 97% | Training loss: 0.6881425342776558
Epoch: 32 | Iteration number: [560/565] 99% | Training loss: 0.6881196771349226

 End of epoch: 32 | Train Loss: 0.6868900525886401 | Training Time: 88 

 End of epoch: 32 | Eval Loss: 0.6902548755918231 | Evaluating Time: 6 
Epoch: 33 | Iteration number: [10/565] 1% | Training loss: 0.7555470645427704
Epoch: 33 | Iteration number: [20/565] 3% | Training loss: 0.7212684869766235
Epoch: 33 | Iteration number: [30/565] 5% | Training loss: 0.7099133332570394
Epoch: 33 | Iteration number: [40/565] 7% | Training loss: 0.7040091142058372
Epoch: 33 | Iteration number: [50/565] 8% | Training loss: 0.7005504453182221
Epoch: 33 | Iteration number: [60/565] 10% | Training loss: 0.6981889814138412
Epoch: 33 | Iteration number: [70/565] 12% | Training loss: 0.6966045950140272
Epoch: 33 | Iteration number: [80/565] 14% | Training loss: 0.6953952081501484
Epoch: 33 | Iteration number: [90/565] 15% | Training loss: 0.6944099386533101
Epoch: 33 | Iteration number: [100/565] 17% | Training loss: 0.6936589962244034
Epoch: 33 | Iteration number: [110/565] 19% | Training loss: 0.693022576787255
Epoch: 33 | Iteration number: [120/565] 21% | Training loss: 0.6925030852357547
Epoch: 33 | Iteration number: [130/565] 23% | Training loss: 0.692085260611314
Epoch: 33 | Iteration number: [140/565] 24% | Training loss: 0.6916979363986424
Epoch: 33 | Iteration number: [150/565] 26% | Training loss: 0.6913309097290039
Epoch: 33 | Iteration number: [160/565] 28% | Training loss: 0.6910402055829763
Epoch: 33 | Iteration number: [170/565] 30% | Training loss: 0.6908079431337468
Epoch: 33 | Iteration number: [180/565] 31% | Training loss: 0.6905965735514958
Epoch: 33 | Iteration number: [190/565] 33% | Training loss: 0.6904111466909709
Epoch: 33 | Iteration number: [200/565] 35% | Training loss: 0.6902273344993591
Epoch: 33 | Iteration number: [210/565] 37% | Training loss: 0.6900713094643184
Epoch: 33 | Iteration number: [220/565] 38% | Training loss: 0.6899203194813295
Epoch: 33 | Iteration number: [230/565] 40% | Training loss: 0.6897840546525043
Epoch: 33 | Iteration number: [240/565] 42% | Training loss: 0.6896686250964801
Epoch: 33 | Iteration number: [250/565] 44% | Training loss: 0.689570867061615
Epoch: 33 | Iteration number: [260/565] 46% | Training loss: 0.6894742014316412
Epoch: 33 | Iteration number: [270/565] 47% | Training loss: 0.6893796889870255
Epoch: 33 | Iteration number: [280/565] 49% | Training loss: 0.6892599638019289
Epoch: 33 | Iteration number: [290/565] 51% | Training loss: 0.6891690661167277
Epoch: 33 | Iteration number: [300/565] 53% | Training loss: 0.6891082666317622
Epoch: 33 | Iteration number: [310/565] 54% | Training loss: 0.6890398719618397
Epoch: 33 | Iteration number: [320/565] 56% | Training loss: 0.6889597032219171
Epoch: 33 | Iteration number: [330/565] 58% | Training loss: 0.6888992622043147
Epoch: 33 | Iteration number: [340/565] 60% | Training loss: 0.6888481895713245
Epoch: 33 | Iteration number: [350/565] 61% | Training loss: 0.6887929139818464
Epoch: 33 | Iteration number: [360/565] 63% | Training loss: 0.6887547183367941
Epoch: 33 | Iteration number: [370/565] 65% | Training loss: 0.6887104994541889
Epoch: 33 | Iteration number: [380/565] 67% | Training loss: 0.6886519664212277
Epoch: 33 | Iteration number: [390/565] 69% | Training loss: 0.6886172309899942
Epoch: 33 | Iteration number: [400/565] 70% | Training loss: 0.6885733033716679
Epoch: 33 | Iteration number: [410/565] 72% | Training loss: 0.6885345991064863
Epoch: 33 | Iteration number: [420/565] 74% | Training loss: 0.6885043770074845
Epoch: 33 | Iteration number: [430/565] 76% | Training loss: 0.6884688696195913
Epoch: 33 | Iteration number: [440/565] 77% | Training loss: 0.6884376345710321
Epoch: 33 | Iteration number: [450/565] 79% | Training loss: 0.6884004247188568
Epoch: 33 | Iteration number: [460/565] 81% | Training loss: 0.6883590529794278
Epoch: 33 | Iteration number: [470/565] 83% | Training loss: 0.6883298772446653
Epoch: 33 | Iteration number: [480/565] 84% | Training loss: 0.6883043246964614
Epoch: 33 | Iteration number: [490/565] 86% | Training loss: 0.6882839669986647
Epoch: 33 | Iteration number: [500/565] 88% | Training loss: 0.6882553371191025
Epoch: 33 | Iteration number: [510/565] 90% | Training loss: 0.6882344986878189
Epoch: 33 | Iteration number: [520/565] 92% | Training loss: 0.6882089073841389
Epoch: 33 | Iteration number: [530/565] 93% | Training loss: 0.6881749248729562
Epoch: 33 | Iteration number: [540/565] 95% | Training loss: 0.6881505515840318
Epoch: 33 | Iteration number: [550/565] 97% | Training loss: 0.6881255580078471
Epoch: 33 | Iteration number: [560/565] 99% | Training loss: 0.6881040860499654

 End of epoch: 33 | Train Loss: 0.6868789865907314 | Training Time: 90 

 End of epoch: 33 | Eval Loss: 0.6902227827480861 | Evaluating Time: 6 
Epoch: 34 | Iteration number: [10/565] 1% | Training loss: 0.7556862950325012
Epoch: 34 | Iteration number: [20/565] 3% | Training loss: 0.7211865365505219
Epoch: 34 | Iteration number: [30/565] 5% | Training loss: 0.7096600393454234
Epoch: 34 | Iteration number: [40/565] 7% | Training loss: 0.7040422111749649
Epoch: 34 | Iteration number: [50/565] 8% | Training loss: 0.7006128466129303
Epoch: 34 | Iteration number: [60/565] 10% | Training loss: 0.6983331640561422
Epoch: 34 | Iteration number: [70/565] 12% | Training loss: 0.696693002326148
Epoch: 34 | Iteration number: [80/565] 14% | Training loss: 0.6954791717231273
Epoch: 34 | Iteration number: [90/565] 15% | Training loss: 0.6945335659715864
Epoch: 34 | Iteration number: [100/565] 17% | Training loss: 0.6937722188234329
Epoch: 34 | Iteration number: [110/565] 19% | Training loss: 0.6931285695596174
Epoch: 34 | Iteration number: [120/565] 21% | Training loss: 0.6925917247931163
Epoch: 34 | Iteration number: [130/565] 23% | Training loss: 0.6921507546534905
Epoch: 34 | Iteration number: [140/565] 24% | Training loss: 0.6917637322630201
Epoch: 34 | Iteration number: [150/565] 26% | Training loss: 0.6914257983366648
Epoch: 34 | Iteration number: [160/565] 28% | Training loss: 0.6911292482167483
Epoch: 34 | Iteration number: [170/565] 30% | Training loss: 0.6908663598930135
Epoch: 34 | Iteration number: [180/565] 31% | Training loss: 0.6906378904978434
Epoch: 34 | Iteration number: [190/565] 33% | Training loss: 0.690448817767595
Epoch: 34 | Iteration number: [200/565] 35% | Training loss: 0.6902625423669815
Epoch: 34 | Iteration number: [210/565] 37% | Training loss: 0.6901037162258512
Epoch: 34 | Iteration number: [220/565] 38% | Training loss: 0.6899505057118156
Epoch: 34 | Iteration number: [230/565] 40% | Training loss: 0.6898188824238984
Epoch: 34 | Iteration number: [240/565] 42% | Training loss: 0.6896880092720191
Epoch: 34 | Iteration number: [250/565] 44% | Training loss: 0.6895613970756531
Epoch: 34 | Iteration number: [260/565] 46% | Training loss: 0.6894513820226376
Epoch: 34 | Iteration number: [270/565] 47% | Training loss: 0.6893536338099727
Epoch: 34 | Iteration number: [280/565] 49% | Training loss: 0.6892603931682451
Epoch: 34 | Iteration number: [290/565] 51% | Training loss: 0.689180332833323
Epoch: 34 | Iteration number: [300/565] 53% | Training loss: 0.6890970917542776
Epoch: 34 | Iteration number: [310/565] 54% | Training loss: 0.6890056975426212
Epoch: 34 | Iteration number: [320/565] 56% | Training loss: 0.6889475725591183
Epoch: 34 | Iteration number: [330/565] 58% | Training loss: 0.6888867437839508
Epoch: 34 | Iteration number: [340/565] 60% | Training loss: 0.6888272118919035
Epoch: 34 | Iteration number: [350/565] 61% | Training loss: 0.6887727390016828
Epoch: 34 | Iteration number: [360/565] 63% | Training loss: 0.6887212440371513
Epoch: 34 | Iteration number: [370/565] 65% | Training loss: 0.6886734901247797
Epoch: 34 | Iteration number: [380/565] 67% | Training loss: 0.6886352131241247
Epoch: 34 | Iteration number: [390/565] 69% | Training loss: 0.6886040719655844
Epoch: 34 | Iteration number: [400/565] 70% | Training loss: 0.6885736264288426
Epoch: 34 | Iteration number: [410/565] 72% | Training loss: 0.6885322546086661
Epoch: 34 | Iteration number: [420/565] 74% | Training loss: 0.6884911592517581
Epoch: 34 | Iteration number: [430/565] 76% | Training loss: 0.6884595126606697
Epoch: 34 | Iteration number: [440/565] 77% | Training loss: 0.6884245401079004
Epoch: 34 | Iteration number: [450/565] 79% | Training loss: 0.6883873131540087
Epoch: 34 | Iteration number: [460/565] 81% | Training loss: 0.6883506794338641
Epoch: 34 | Iteration number: [470/565] 83% | Training loss: 0.688311531442277
Epoch: 34 | Iteration number: [480/565] 84% | Training loss: 0.6882911423842112
Epoch: 34 | Iteration number: [490/565] 86% | Training loss: 0.6882603307159579
Epoch: 34 | Iteration number: [500/565] 88% | Training loss: 0.688236496090889
Epoch: 34 | Iteration number: [510/565] 90% | Training loss: 0.6882089381124459
Epoch: 34 | Iteration number: [520/565] 92% | Training loss: 0.6881809565883417
Epoch: 34 | Iteration number: [530/565] 93% | Training loss: 0.688155756131658
Epoch: 34 | Iteration number: [540/565] 95% | Training loss: 0.6881317846201084
Epoch: 34 | Iteration number: [550/565] 97% | Training loss: 0.688113276199861
Epoch: 34 | Iteration number: [560/565] 99% | Training loss: 0.6880934682275568

 End of epoch: 34 | Train Loss: 0.6868615542892861 | Training Time: 89 

 End of epoch: 34 | Eval Loss: 0.6903621213776725 | Evaluating Time: 6 
Epoch: 35 | Iteration number: [10/565] 1% | Training loss: 0.7557101488113404
Epoch: 35 | Iteration number: [20/565] 3% | Training loss: 0.7213542580604553
Epoch: 35 | Iteration number: [30/565] 5% | Training loss: 0.7099771479765574
Epoch: 35 | Iteration number: [40/565] 7% | Training loss: 0.7042312026023865
Epoch: 35 | Iteration number: [50/565] 8% | Training loss: 0.7008507215976715
Epoch: 35 | Iteration number: [60/565] 10% | Training loss: 0.6986230542262395
Epoch: 35 | Iteration number: [70/565] 12% | Training loss: 0.6968881947653635
Epoch: 35 | Iteration number: [80/565] 14% | Training loss: 0.6955956071615219
Epoch: 35 | Iteration number: [90/565] 15% | Training loss: 0.6946123149659899
Epoch: 35 | Iteration number: [100/565] 17% | Training loss: 0.6938240092992782
Epoch: 35 | Iteration number: [110/565] 19% | Training loss: 0.6932326604019512
Epoch: 35 | Iteration number: [120/565] 21% | Training loss: 0.6926884382963181
Epoch: 35 | Iteration number: [130/565] 23% | Training loss: 0.6922637833998754
Epoch: 35 | Iteration number: [140/565] 24% | Training loss: 0.6918506767068591
Epoch: 35 | Iteration number: [150/565] 26% | Training loss: 0.6914959176381429
Epoch: 35 | Iteration number: [160/565] 28% | Training loss: 0.6912186302244663
Epoch: 35 | Iteration number: [170/565] 30% | Training loss: 0.6909800631158493
Epoch: 35 | Iteration number: [180/565] 31% | Training loss: 0.6907379557689031
Epoch: 35 | Iteration number: [190/565] 33% | Training loss: 0.6905280869258078
Epoch: 35 | Iteration number: [200/565] 35% | Training loss: 0.6903487661480904
Epoch: 35 | Iteration number: [210/565] 37% | Training loss: 0.6901767299288795
Epoch: 35 | Iteration number: [220/565] 38% | Training loss: 0.6900092739950526
Epoch: 35 | Iteration number: [230/565] 40% | Training loss: 0.6898774240327918
Epoch: 35 | Iteration number: [240/565] 42% | Training loss: 0.6897431530058384
Epoch: 35 | Iteration number: [250/565] 44% | Training loss: 0.6896427624225616
Epoch: 35 | Iteration number: [260/565] 46% | Training loss: 0.6895326843628516
Epoch: 35 | Iteration number: [270/565] 47% | Training loss: 0.6894282382947428
Epoch: 35 | Iteration number: [280/565] 49% | Training loss: 0.6893394676702363
Epoch: 35 | Iteration number: [290/565] 51% | Training loss: 0.6892335394333149
Epoch: 35 | Iteration number: [300/565] 53% | Training loss: 0.6891538113355636
Epoch: 35 | Iteration number: [310/565] 54% | Training loss: 0.689087632202333
Epoch: 35 | Iteration number: [320/565] 56% | Training loss: 0.689015474356711
Epoch: 35 | Iteration number: [330/565] 58% | Training loss: 0.688951373280901
Epoch: 35 | Iteration number: [340/565] 60% | Training loss: 0.6888908452847424
Epoch: 35 | Iteration number: [350/565] 61% | Training loss: 0.6888346758910587
Epoch: 35 | Iteration number: [360/565] 63% | Training loss: 0.6887806096010738
Epoch: 35 | Iteration number: [370/565] 65% | Training loss: 0.6887279339738794
Epoch: 35 | Iteration number: [380/565] 67% | Training loss: 0.6886660790757129
Epoch: 35 | Iteration number: [390/565] 69% | Training loss: 0.6886204384840452
Epoch: 35 | Iteration number: [400/565] 70% | Training loss: 0.6885770240426063
Epoch: 35 | Iteration number: [410/565] 72% | Training loss: 0.6885253422143983
Epoch: 35 | Iteration number: [420/565] 74% | Training loss: 0.6884831876981826
Epoch: 35 | Iteration number: [430/565] 76% | Training loss: 0.6884457243043323
Epoch: 35 | Iteration number: [440/565] 77% | Training loss: 0.688412544131279
Epoch: 35 | Iteration number: [450/565] 79% | Training loss: 0.6883715919653575
Epoch: 35 | Iteration number: [460/565] 81% | Training loss: 0.6883462103812591
Epoch: 35 | Iteration number: [470/565] 83% | Training loss: 0.6883048564829725
Epoch: 35 | Iteration number: [480/565] 84% | Training loss: 0.6882718591640393
Epoch: 35 | Iteration number: [490/565] 86% | Training loss: 0.6882518757362754
Epoch: 35 | Iteration number: [500/565] 88% | Training loss: 0.68822669506073
Epoch: 35 | Iteration number: [510/565] 90% | Training loss: 0.6882012394129061
Epoch: 35 | Iteration number: [520/565] 92% | Training loss: 0.6881798415229871
Epoch: 35 | Iteration number: [530/565] 93% | Training loss: 0.6881516528579424
Epoch: 35 | Iteration number: [540/565] 95% | Training loss: 0.6881271358993318
Epoch: 35 | Iteration number: [550/565] 97% | Training loss: 0.6881129510836168
Epoch: 35 | Iteration number: [560/565] 99% | Training loss: 0.6880905571792807

 End of epoch: 35 | Train Loss: 0.6868632813470553 | Training Time: 89 

 End of epoch: 35 | Eval Loss: 0.6903508220400129 | Evaluating Time: 6 
Epoch: 36 | Iteration number: [10/565] 1% | Training loss: 0.7550787448883056
Epoch: 36 | Iteration number: [20/565] 3% | Training loss: 0.7209423124790192
Epoch: 36 | Iteration number: [30/565] 5% | Training loss: 0.7095381995042165
Epoch: 36 | Iteration number: [40/565] 7% | Training loss: 0.7038761794567108
Epoch: 36 | Iteration number: [50/565] 8% | Training loss: 0.7004351615905762
Epoch: 36 | Iteration number: [60/565] 10% | Training loss: 0.6981989522775014
Epoch: 36 | Iteration number: [70/565] 12% | Training loss: 0.6965762828077589
Epoch: 36 | Iteration number: [80/565] 14% | Training loss: 0.6953575618565082
Epoch: 36 | Iteration number: [90/565] 15% | Training loss: 0.694450976451238
Epoch: 36 | Iteration number: [100/565] 17% | Training loss: 0.6936953872442245
Epoch: 36 | Iteration number: [110/565] 19% | Training loss: 0.6930583146485415
Epoch: 36 | Iteration number: [120/565] 21% | Training loss: 0.6925627554456393
Epoch: 36 | Iteration number: [130/565] 23% | Training loss: 0.6921082702966836
Epoch: 36 | Iteration number: [140/565] 24% | Training loss: 0.6917417143072401
Epoch: 36 | Iteration number: [150/565] 26% | Training loss: 0.6914608466625214
Epoch: 36 | Iteration number: [160/565] 28% | Training loss: 0.6911947604268789
Epoch: 36 | Iteration number: [170/565] 30% | Training loss: 0.6909357070922851
Epoch: 36 | Iteration number: [180/565] 31% | Training loss: 0.6907143420643277
Epoch: 36 | Iteration number: [190/565] 33% | Training loss: 0.690504996713839
Epoch: 36 | Iteration number: [200/565] 35% | Training loss: 0.6903379422426223
Epoch: 36 | Iteration number: [210/565] 37% | Training loss: 0.6901685504686265
Epoch: 36 | Iteration number: [220/565] 38% | Training loss: 0.6900078190998598
Epoch: 36 | Iteration number: [230/565] 40% | Training loss: 0.6898852648942367
Epoch: 36 | Iteration number: [240/565] 42% | Training loss: 0.6897559347252051
Epoch: 36 | Iteration number: [250/565] 44% | Training loss: 0.6896262838840485
Epoch: 36 | Iteration number: [260/565] 46% | Training loss: 0.6895053877280308
Epoch: 36 | Iteration number: [270/565] 47% | Training loss: 0.6894063583126775
Epoch: 36 | Iteration number: [280/565] 49% | Training loss: 0.6893261432647705
Epoch: 36 | Iteration number: [290/565] 51% | Training loss: 0.6892448082052428
Epoch: 36 | Iteration number: [300/565] 53% | Training loss: 0.6891448201735815
Epoch: 36 | Iteration number: [310/565] 54% | Training loss: 0.6890530188237467
Epoch: 36 | Iteration number: [320/565] 56% | Training loss: 0.6889800665900111
Epoch: 36 | Iteration number: [330/565] 58% | Training loss: 0.6889151139692826
Epoch: 36 | Iteration number: [340/565] 60% | Training loss: 0.688853135880302
Epoch: 36 | Iteration number: [350/565] 61% | Training loss: 0.6887871355669839
Epoch: 36 | Iteration number: [360/565] 63% | Training loss: 0.6887236590186755
Epoch: 36 | Iteration number: [370/565] 65% | Training loss: 0.6886674987303244
Epoch: 36 | Iteration number: [380/565] 67% | Training loss: 0.6886167353705356
Epoch: 36 | Iteration number: [390/565] 69% | Training loss: 0.6885765447066381
Epoch: 36 | Iteration number: [400/565] 70% | Training loss: 0.6885297948122024
Epoch: 36 | Iteration number: [410/565] 72% | Training loss: 0.6884774163001921
Epoch: 36 | Iteration number: [420/565] 74% | Training loss: 0.688435641356877
Epoch: 36 | Iteration number: [430/565] 76% | Training loss: 0.6883964391641839
Epoch: 36 | Iteration number: [440/565] 77% | Training loss: 0.6883701228282668
Epoch: 36 | Iteration number: [450/565] 79% | Training loss: 0.6883347780174679
Epoch: 36 | Iteration number: [460/565] 81% | Training loss: 0.6882982084284658
Epoch: 36 | Iteration number: [470/565] 83% | Training loss: 0.6882732808589935
Epoch: 36 | Iteration number: [480/565] 84% | Training loss: 0.6882355968157451
Epoch: 36 | Iteration number: [490/565] 86% | Training loss: 0.6882163681546036
Epoch: 36 | Iteration number: [500/565] 88% | Training loss: 0.688199813246727
Epoch: 36 | Iteration number: [510/565] 90% | Training loss: 0.6881762785070082
Epoch: 36 | Iteration number: [520/565] 92% | Training loss: 0.6881522231377089
Epoch: 36 | Iteration number: [530/565] 93% | Training loss: 0.6881433016849015
Epoch: 36 | Iteration number: [540/565] 95% | Training loss: 0.6881210253194526
Epoch: 36 | Iteration number: [550/565] 97% | Training loss: 0.6881040135296909
Epoch: 36 | Iteration number: [560/565] 99% | Training loss: 0.6880899410162653

 End of epoch: 36 | Train Loss: 0.6868610070869986 | Training Time: 88 

 End of epoch: 36 | Eval Loss: 0.6894935284342084 | Evaluating Time: 6 
Epoch: 37 | Iteration number: [10/565] 1% | Training loss: 0.7558368742465973
Epoch: 37 | Iteration number: [20/565] 3% | Training loss: 0.7211818367242813
Epoch: 37 | Iteration number: [30/565] 5% | Training loss: 0.7096295515696208
Epoch: 37 | Iteration number: [40/565] 7% | Training loss: 0.7039261162281036
Epoch: 37 | Iteration number: [50/565] 8% | Training loss: 0.7005760860443115
Epoch: 37 | Iteration number: [60/565] 10% | Training loss: 0.6982012689113617
Epoch: 37 | Iteration number: [70/565] 12% | Training loss: 0.696599212714604
Epoch: 37 | Iteration number: [80/565] 14% | Training loss: 0.6953231863677501
Epoch: 37 | Iteration number: [90/565] 15% | Training loss: 0.6943481034702725
Epoch: 37 | Iteration number: [100/565] 17% | Training loss: 0.6935689038038254
Epoch: 37 | Iteration number: [110/565] 19% | Training loss: 0.6929694294929505
Epoch: 37 | Iteration number: [120/565] 21% | Training loss: 0.6924770976106326
Epoch: 37 | Iteration number: [130/565] 23% | Training loss: 0.6920601115776942
Epoch: 37 | Iteration number: [140/565] 24% | Training loss: 0.6916756698063442
Epoch: 37 | Iteration number: [150/565] 26% | Training loss: 0.6913406872749328
Epoch: 37 | Iteration number: [160/565] 28% | Training loss: 0.6910456001758576
Epoch: 37 | Iteration number: [170/565] 30% | Training loss: 0.6907864304149852
Epoch: 37 | Iteration number: [180/565] 31% | Training loss: 0.6905842039320204
Epoch: 37 | Iteration number: [190/565] 33% | Training loss: 0.6904062500125483
Epoch: 37 | Iteration number: [200/565] 35% | Training loss: 0.6902023839950562
Epoch: 37 | Iteration number: [210/565] 37% | Training loss: 0.690036560240246
Epoch: 37 | Iteration number: [220/565] 38% | Training loss: 0.6898928040807898
Epoch: 37 | Iteration number: [230/565] 40% | Training loss: 0.6897649464399919
Epoch: 37 | Iteration number: [240/565] 42% | Training loss: 0.6896638691425323
Epoch: 37 | Iteration number: [250/565] 44% | Training loss: 0.6895437669754029
Epoch: 37 | Iteration number: [260/565] 46% | Training loss: 0.6894420165282029
Epoch: 37 | Iteration number: [270/565] 47% | Training loss: 0.6893244504928588
Epoch: 37 | Iteration number: [280/565] 49% | Training loss: 0.6892371916345188
Epoch: 37 | Iteration number: [290/565] 51% | Training loss: 0.6891524814326188
Epoch: 37 | Iteration number: [300/565] 53% | Training loss: 0.6890660629669825
Epoch: 37 | Iteration number: [310/565] 54% | Training loss: 0.6889930523210956
Epoch: 37 | Iteration number: [320/565] 56% | Training loss: 0.6889319328591228
Epoch: 37 | Iteration number: [330/565] 58% | Training loss: 0.6888720105994831
Epoch: 37 | Iteration number: [340/565] 60% | Training loss: 0.6888096507857827
Epoch: 37 | Iteration number: [350/565] 61% | Training loss: 0.6887545759337289
Epoch: 37 | Iteration number: [360/565] 63% | Training loss: 0.6887009036209848
Epoch: 37 | Iteration number: [370/565] 65% | Training loss: 0.6886404327444128
Epoch: 37 | Iteration number: [380/565] 67% | Training loss: 0.6885992426621287
Epoch: 37 | Iteration number: [390/565] 69% | Training loss: 0.6885481785505246
Epoch: 37 | Iteration number: [400/565] 70% | Training loss: 0.688525334149599
Epoch: 37 | Iteration number: [410/565] 72% | Training loss: 0.6884814573497307
Epoch: 37 | Iteration number: [420/565] 74% | Training loss: 0.6884450117746989
Epoch: 37 | Iteration number: [430/565] 76% | Training loss: 0.6884181322053421
Epoch: 37 | Iteration number: [440/565] 77% | Training loss: 0.6883834088390524
Epoch: 37 | Iteration number: [450/565] 79% | Training loss: 0.68834243244595
Epoch: 37 | Iteration number: [460/565] 81% | Training loss: 0.6883172746585763
Epoch: 37 | Iteration number: [470/565] 83% | Training loss: 0.6882882852503593
Epoch: 37 | Iteration number: [480/565] 84% | Training loss: 0.688259127860268
Epoch: 37 | Iteration number: [490/565] 86% | Training loss: 0.6882316355802575
Epoch: 37 | Iteration number: [500/565] 88% | Training loss: 0.6882106637954712
Epoch: 37 | Iteration number: [510/565] 90% | Training loss: 0.6881918791462394
Epoch: 37 | Iteration number: [520/565] 92% | Training loss: 0.688164753982654
Epoch: 37 | Iteration number: [530/565] 93% | Training loss: 0.6881448191291881
Epoch: 37 | Iteration number: [540/565] 95% | Training loss: 0.6881263567341699
Epoch: 37 | Iteration number: [550/565] 97% | Training loss: 0.6881024613163688
Epoch: 37 | Iteration number: [560/565] 99% | Training loss: 0.6880845478602818

 End of epoch: 37 | Train Loss: 0.6868600767270654 | Training Time: 88 

 End of epoch: 37 | Eval Loss: 0.6902739490781512 | Evaluating Time: 6 
Epoch: 38 | Iteration number: [10/565] 1% | Training loss: 0.7554287075996399
Epoch: 38 | Iteration number: [20/565] 3% | Training loss: 0.7211156487464905
Epoch: 38 | Iteration number: [30/565] 5% | Training loss: 0.7095376074314117
Epoch: 38 | Iteration number: [40/565] 7% | Training loss: 0.7037982419133186
Epoch: 38 | Iteration number: [50/565] 8% | Training loss: 0.7003818440437317
Epoch: 38 | Iteration number: [60/565] 10% | Training loss: 0.6981441368659337
Epoch: 38 | Iteration number: [70/565] 12% | Training loss: 0.6965921793665205
Epoch: 38 | Iteration number: [80/565] 14% | Training loss: 0.6954401068389415
Epoch: 38 | Iteration number: [90/565] 15% | Training loss: 0.69449985159768
Epoch: 38 | Iteration number: [100/565] 17% | Training loss: 0.6937299180030823
Epoch: 38 | Iteration number: [110/565] 19% | Training loss: 0.6931205120953646
Epoch: 38 | Iteration number: [120/565] 21% | Training loss: 0.6925633197029432
Epoch: 38 | Iteration number: [130/565] 23% | Training loss: 0.6921081964786236
Epoch: 38 | Iteration number: [140/565] 24% | Training loss: 0.6917748698166438
Epoch: 38 | Iteration number: [150/565] 26% | Training loss: 0.6914505489667256
Epoch: 38 | Iteration number: [160/565] 28% | Training loss: 0.6911421295255422
Epoch: 38 | Iteration number: [170/565] 30% | Training loss: 0.6908660737907185
Epoch: 38 | Iteration number: [180/565] 31% | Training loss: 0.6906276716126336
Epoch: 38 | Iteration number: [190/565] 33% | Training loss: 0.6904210002798783
Epoch: 38 | Iteration number: [200/565] 35% | Training loss: 0.6902505794167518
Epoch: 38 | Iteration number: [210/565] 37% | Training loss: 0.690076185124261
Epoch: 38 | Iteration number: [220/565] 38% | Training loss: 0.6899347001856023
Epoch: 38 | Iteration number: [230/565] 40% | Training loss: 0.6897953012715216
Epoch: 38 | Iteration number: [240/565] 42% | Training loss: 0.6896751637260119
Epoch: 38 | Iteration number: [250/565] 44% | Training loss: 0.6895623679161071
Epoch: 38 | Iteration number: [260/565] 46% | Training loss: 0.6894595545071822
Epoch: 38 | Iteration number: [270/565] 47% | Training loss: 0.6893686945791597
Epoch: 38 | Iteration number: [280/565] 49% | Training loss: 0.689295535002436
Epoch: 38 | Iteration number: [290/565] 51% | Training loss: 0.6892307614458019
Epoch: 38 | Iteration number: [300/565] 53% | Training loss: 0.6891517009337743
Epoch: 38 | Iteration number: [310/565] 54% | Training loss: 0.6890806701875503
Epoch: 38 | Iteration number: [320/565] 56% | Training loss: 0.6890160579234361
Epoch: 38 | Iteration number: [330/565] 58% | Training loss: 0.6889485409765532
Epoch: 38 | Iteration number: [340/565] 60% | Training loss: 0.6888812789145637
Epoch: 38 | Iteration number: [350/565] 61% | Training loss: 0.6888291130747114
Epoch: 38 | Iteration number: [360/565] 63% | Training loss: 0.6887788421577877
Epoch: 38 | Iteration number: [370/565] 65% | Training loss: 0.6887323924013087
Epoch: 38 | Iteration number: [380/565] 67% | Training loss: 0.6886948993331508
Epoch: 38 | Iteration number: [390/565] 69% | Training loss: 0.688642137325727
Epoch: 38 | Iteration number: [400/565] 70% | Training loss: 0.6885956139862537
Epoch: 38 | Iteration number: [410/565] 72% | Training loss: 0.6885608771952187
Epoch: 38 | Iteration number: [420/565] 74% | Training loss: 0.6885255758251463
Epoch: 38 | Iteration number: [430/565] 76% | Training loss: 0.688495823533036
Epoch: 38 | Iteration number: [440/565] 77% | Training loss: 0.688463413038037
Epoch: 38 | Iteration number: [450/565] 79% | Training loss: 0.6884212179978688
Epoch: 38 | Iteration number: [460/565] 81% | Training loss: 0.6883897396533386
Epoch: 38 | Iteration number: [470/565] 83% | Training loss: 0.6883564372011955
Epoch: 38 | Iteration number: [480/565] 84% | Training loss: 0.6883287897954384
Epoch: 38 | Iteration number: [490/565] 86% | Training loss: 0.688297332792866
Epoch: 38 | Iteration number: [500/565] 88% | Training loss: 0.6882692165374756
Epoch: 38 | Iteration number: [510/565] 90% | Training loss: 0.6882340003462398
Epoch: 38 | Iteration number: [520/565] 92% | Training loss: 0.6882131458475039
Epoch: 38 | Iteration number: [530/565] 93% | Training loss: 0.688191271390555
Epoch: 38 | Iteration number: [540/565] 95% | Training loss: 0.6881694598330392
Epoch: 38 | Iteration number: [550/565] 97% | Training loss: 0.688145121010867
Epoch: 38 | Iteration number: [560/565] 99% | Training loss: 0.6881315966801984

 End of epoch: 38 | Train Loss: 0.6869006833143994 | Training Time: 87 

 End of epoch: 38 | Eval Loss: 0.6897081051553998 | Evaluating Time: 6 
Epoch: 39 | Iteration number: [10/565] 1% | Training loss: 0.7551337599754333
Epoch: 39 | Iteration number: [20/565] 3% | Training loss: 0.7208822965621948
Epoch: 39 | Iteration number: [30/565] 5% | Training loss: 0.7096090773741405
Epoch: 39 | Iteration number: [40/565] 7% | Training loss: 0.7039176747202873
Epoch: 39 | Iteration number: [50/565] 8% | Training loss: 0.7003988492488861
Epoch: 39 | Iteration number: [60/565] 10% | Training loss: 0.6980698198080063
Epoch: 39 | Iteration number: [70/565] 12% | Training loss: 0.6965581067970821
Epoch: 39 | Iteration number: [80/565] 14% | Training loss: 0.6953410223126412
Epoch: 39 | Iteration number: [90/565] 15% | Training loss: 0.6943972918722364
Epoch: 39 | Iteration number: [100/565] 17% | Training loss: 0.6936256486177445
Epoch: 39 | Iteration number: [110/565] 19% | Training loss: 0.6930256686427376
Epoch: 39 | Iteration number: [120/565] 21% | Training loss: 0.6925330241521199
Epoch: 39 | Iteration number: [130/565] 23% | Training loss: 0.6920907905468574
Epoch: 39 | Iteration number: [140/565] 24% | Training loss: 0.6917277365922928
Epoch: 39 | Iteration number: [150/565] 26% | Training loss: 0.6913984131813049
Epoch: 39 | Iteration number: [160/565] 28% | Training loss: 0.6911174021661282
Epoch: 39 | Iteration number: [170/565] 30% | Training loss: 0.6908552786883186
Epoch: 39 | Iteration number: [180/565] 31% | Training loss: 0.6906408187415864
Epoch: 39 | Iteration number: [190/565] 33% | Training loss: 0.6904346519394925
Epoch: 39 | Iteration number: [200/565] 35% | Training loss: 0.690238823890686
Epoch: 39 | Iteration number: [210/565] 37% | Training loss: 0.6900639942714146
Epoch: 39 | Iteration number: [220/565] 38% | Training loss: 0.6899204202673652
Epoch: 39 | Iteration number: [230/565] 40% | Training loss: 0.6898110483003699
Epoch: 39 | Iteration number: [240/565] 42% | Training loss: 0.6896884066363176
Epoch: 39 | Iteration number: [250/565] 44% | Training loss: 0.6895761585235596
Epoch: 39 | Iteration number: [260/565] 46% | Training loss: 0.6894686669111252
Epoch: 39 | Iteration number: [270/565] 47% | Training loss: 0.6893594704292438
Epoch: 39 | Iteration number: [280/565] 49% | Training loss: 0.6892686345747538
Epoch: 39 | Iteration number: [290/565] 51% | Training loss: 0.6891857087612152
Epoch: 39 | Iteration number: [300/565] 53% | Training loss: 0.6891185873746872
Epoch: 39 | Iteration number: [310/565] 54% | Training loss: 0.6890467222659818
Epoch: 39 | Iteration number: [320/565] 56% | Training loss: 0.6889694491401315
Epoch: 39 | Iteration number: [330/565] 58% | Training loss: 0.6888961158015511
Epoch: 39 | Iteration number: [340/565] 60% | Training loss: 0.6888241497909322
Epoch: 39 | Iteration number: [350/565] 61% | Training loss: 0.6887670493125916
Epoch: 39 | Iteration number: [360/565] 63% | Training loss: 0.6887088373303414
Epoch: 39 | Iteration number: [370/565] 65% | Training loss: 0.6886617961767557
Epoch: 39 | Iteration number: [380/565] 67% | Training loss: 0.6886221885681152
Epoch: 39 | Iteration number: [390/565] 69% | Training loss: 0.6885813908699231
Epoch: 39 | Iteration number: [400/565] 70% | Training loss: 0.6885539224743843
Epoch: 39 | Iteration number: [410/565] 72% | Training loss: 0.688517391536294
Epoch: 39 | Iteration number: [420/565] 74% | Training loss: 0.6884821490162895
Epoch: 39 | Iteration number: [430/565] 76% | Training loss: 0.688434010189633
Epoch: 39 | Iteration number: [440/565] 77% | Training loss: 0.6884078014980662
Epoch: 39 | Iteration number: [450/565] 79% | Training loss: 0.6883743601375156
Epoch: 39 | Iteration number: [460/565] 81% | Training loss: 0.6883452478958213
Epoch: 39 | Iteration number: [470/565] 83% | Training loss: 0.6883082803259505
Epoch: 39 | Iteration number: [480/565] 84% | Training loss: 0.688283405204614
Epoch: 39 | Iteration number: [490/565] 86% | Training loss: 0.6882484743789751
Epoch: 39 | Iteration number: [500/565] 88% | Training loss: 0.6882190997600556
Epoch: 39 | Iteration number: [510/565] 90% | Training loss: 0.6881958581653296
Epoch: 39 | Iteration number: [520/565] 92% | Training loss: 0.6881740417618017
Epoch: 39 | Iteration number: [530/565] 93% | Training loss: 0.6881522554271626
Epoch: 39 | Iteration number: [540/565] 95% | Training loss: 0.6881293625743301
Epoch: 39 | Iteration number: [550/565] 97% | Training loss: 0.6881054775281386
Epoch: 39 | Iteration number: [560/565] 99% | Training loss: 0.6880892937736852

 End of epoch: 39 | Train Loss: 0.6868590731536393 | Training Time: 87 

 End of epoch: 39 | Eval Loss: 0.6902838008744376 | Evaluating Time: 6 
Epoch: 40 | Iteration number: [10/565] 1% | Training loss: 0.7560279667377472
Epoch: 40 | Iteration number: [20/565] 3% | Training loss: 0.7213916569948197
Epoch: 40 | Iteration number: [30/565] 5% | Training loss: 0.7099009891351064
Epoch: 40 | Iteration number: [40/565] 7% | Training loss: 0.704156544804573
Epoch: 40 | Iteration number: [50/565] 8% | Training loss: 0.7008076870441436
Epoch: 40 | Iteration number: [60/565] 10% | Training loss: 0.6985192527373631
Epoch: 40 | Iteration number: [70/565] 12% | Training loss: 0.6968104932989393
Epoch: 40 | Iteration number: [80/565] 14% | Training loss: 0.69554837718606
Epoch: 40 | Iteration number: [90/565] 15% | Training loss: 0.6945609483453963
Epoch: 40 | Iteration number: [100/565] 17% | Training loss: 0.6938029801845551
Epoch: 40 | Iteration number: [110/565] 19% | Training loss: 0.6931784738193859
Epoch: 40 | Iteration number: [120/565] 21% | Training loss: 0.6926179846127828
Epoch: 40 | Iteration number: [130/565] 23% | Training loss: 0.6921354298408214
Epoch: 40 | Iteration number: [140/565] 24% | Training loss: 0.6917677044868469
Epoch: 40 | Iteration number: [150/565] 26% | Training loss: 0.6914085598786672
Epoch: 40 | Iteration number: [160/565] 28% | Training loss: 0.6911340333521366
Epoch: 40 | Iteration number: [170/565] 30% | Training loss: 0.6908645934918347
Epoch: 40 | Iteration number: [180/565] 31% | Training loss: 0.690623665187094
Epoch: 40 | Iteration number: [190/565] 33% | Training loss: 0.6904355899283761
Epoch: 40 | Iteration number: [200/565] 35% | Training loss: 0.6902420037984848
Epoch: 40 | Iteration number: [210/565] 37% | Training loss: 0.6900748794987088
Epoch: 40 | Iteration number: [220/565] 38% | Training loss: 0.6899249502203681
Epoch: 40 | Iteration number: [230/565] 40% | Training loss: 0.6898142894972925
Epoch: 40 | Iteration number: [240/565] 42% | Training loss: 0.6896787829697132
Epoch: 40 | Iteration number: [250/565] 44% | Training loss: 0.689568806886673
Epoch: 40 | Iteration number: [260/565] 46% | Training loss: 0.6894566079744926
Epoch: 40 | Iteration number: [270/565] 47% | Training loss: 0.6893552069310789
Epoch: 40 | Iteration number: [280/565] 49% | Training loss: 0.6892741296972548
Epoch: 40 | Iteration number: [290/565] 51% | Training loss: 0.689183402472529
Epoch: 40 | Iteration number: [300/565] 53% | Training loss: 0.6891026818752288
Epoch: 40 | Iteration number: [310/565] 54% | Training loss: 0.6890294401876388
Epoch: 40 | Iteration number: [320/565] 56% | Training loss: 0.6889539370313287
Epoch: 40 | Iteration number: [330/565] 58% | Training loss: 0.688895150386926
Epoch: 40 | Iteration number: [340/565] 60% | Training loss: 0.6888410669915817
Epoch: 40 | Iteration number: [350/565] 61% | Training loss: 0.6887893281664167
Epoch: 40 | Iteration number: [360/565] 63% | Training loss: 0.6887492401732339
Epoch: 40 | Iteration number: [370/565] 65% | Training loss: 0.6886981334235217
Epoch: 40 | Iteration number: [380/565] 67% | Training loss: 0.6886480889822307
Epoch: 40 | Iteration number: [390/565] 69% | Training loss: 0.6886001791709508
Epoch: 40 | Iteration number: [400/565] 70% | Training loss: 0.688552752584219
Epoch: 40 | Iteration number: [410/565] 72% | Training loss: 0.6885184273487184
Epoch: 40 | Iteration number: [420/565] 74% | Training loss: 0.6884744749182746
Epoch: 40 | Iteration number: [430/565] 76% | Training loss: 0.6884331942990769
Epoch: 40 | Iteration number: [440/565] 77% | Training loss: 0.6884043978019194
Epoch: 40 | Iteration number: [450/565] 79% | Training loss: 0.6883763062953949
Epoch: 40 | Iteration number: [460/565] 81% | Training loss: 0.6883443454037542
Epoch: 40 | Iteration number: [470/565] 83% | Training loss: 0.6882973611354828
Epoch: 40 | Iteration number: [480/565] 84% | Training loss: 0.6882706136753162
Epoch: 40 | Iteration number: [490/565] 86% | Training loss: 0.688246059782651
Epoch: 40 | Iteration number: [500/565] 88% | Training loss: 0.6882155799865722
Epoch: 40 | Iteration number: [510/565] 90% | Training loss: 0.6881904194168016
Epoch: 40 | Iteration number: [520/565] 92% | Training loss: 0.6881631877559882
Epoch: 40 | Iteration number: [530/565] 93% | Training loss: 0.6881289726158358
Epoch: 40 | Iteration number: [540/565] 95% | Training loss: 0.688102403724635
Epoch: 40 | Iteration number: [550/565] 97% | Training loss: 0.6880834457007321
Epoch: 40 | Iteration number: [560/565] 99% | Training loss: 0.6880720463182245

 End of epoch: 40 | Train Loss: 0.6868405842148098 | Training Time: 88 

 End of epoch: 40 | Eval Loss: 0.6901023813656398 | Evaluating Time: 5 
Epoch: 41 | Iteration number: [10/565] 1% | Training loss: 0.7564499199390411
Epoch: 41 | Iteration number: [20/565] 3% | Training loss: 0.7216720640659332
Epoch: 41 | Iteration number: [30/565] 5% | Training loss: 0.709901879231135
Epoch: 41 | Iteration number: [40/565] 7% | Training loss: 0.7041855961084366
Epoch: 41 | Iteration number: [50/565] 8% | Training loss: 0.7006515920162201
Epoch: 41 | Iteration number: [60/565] 10% | Training loss: 0.6983158151308696
Epoch: 41 | Iteration number: [70/565] 12% | Training loss: 0.696664730991636
Epoch: 41 | Iteration number: [80/565] 14% | Training loss: 0.6954006381332875
Epoch: 41 | Iteration number: [90/565] 15% | Training loss: 0.6944190985626645
Epoch: 41 | Iteration number: [100/565] 17% | Training loss: 0.6936658757925034
Epoch: 41 | Iteration number: [110/565] 19% | Training loss: 0.6930657381361182
Epoch: 41 | Iteration number: [120/565] 21% | Training loss: 0.6925597275296848
Epoch: 41 | Iteration number: [130/565] 23% | Training loss: 0.6921520755841182
Epoch: 41 | Iteration number: [140/565] 24% | Training loss: 0.6917763671704701
Epoch: 41 | Iteration number: [150/565] 26% | Training loss: 0.6914562467734019
Epoch: 41 | Iteration number: [160/565] 28% | Training loss: 0.6911807358264923
Epoch: 41 | Iteration number: [170/565] 30% | Training loss: 0.6909326932009529
Epoch: 41 | Iteration number: [180/565] 31% | Training loss: 0.6907171669933531
Epoch: 41 | Iteration number: [190/565] 33% | Training loss: 0.6904896334597939
Epoch: 41 | Iteration number: [200/565] 35% | Training loss: 0.6903062751889228
Epoch: 41 | Iteration number: [210/565] 37% | Training loss: 0.6901441469078973
Epoch: 41 | Iteration number: [220/565] 38% | Training loss: 0.6900031311945481
Epoch: 41 | Iteration number: [230/565] 40% | Training loss: 0.6898628346298052
Epoch: 41 | Iteration number: [240/565] 42% | Training loss: 0.6897468249003093
Epoch: 41 | Iteration number: [250/565] 44% | Training loss: 0.6896391901969909
Epoch: 41 | Iteration number: [260/565] 46% | Training loss: 0.6895061270548747
Epoch: 41 | Iteration number: [270/565] 47% | Training loss: 0.6894099871317546
Epoch: 41 | Iteration number: [280/565] 49% | Training loss: 0.6893106328589576
Epoch: 41 | Iteration number: [290/565] 51% | Training loss: 0.6892179193167851
Epoch: 41 | Iteration number: [300/565] 53% | Training loss: 0.6891280899445216
Epoch: 41 | Iteration number: [310/565] 54% | Training loss: 0.6890593830616244
Epoch: 41 | Iteration number: [320/565] 56% | Training loss: 0.6890048811212182
Epoch: 41 | Iteration number: [330/565] 58% | Training loss: 0.6889307157559829
Epoch: 41 | Iteration number: [340/565] 60% | Training loss: 0.6888641297817231
Epoch: 41 | Iteration number: [350/565] 61% | Training loss: 0.6888110596793039
Epoch: 41 | Iteration number: [360/565] 63% | Training loss: 0.6887581686178843
Epoch: 41 | Iteration number: [370/565] 65% | Training loss: 0.6887030073114344
Epoch: 41 | Iteration number: [380/565] 67% | Training loss: 0.6886474187436856
Epoch: 41 | Iteration number: [390/565] 69% | Training loss: 0.6886023614651118
Epoch: 41 | Iteration number: [400/565] 70% | Training loss: 0.688554475158453
Epoch: 41 | Iteration number: [410/565] 72% | Training loss: 0.6885058965624833
Epoch: 41 | Iteration number: [420/565] 74% | Training loss: 0.6884604915266945
Epoch: 41 | Iteration number: [430/565] 76% | Training loss: 0.6884252674357836
Epoch: 41 | Iteration number: [440/565] 77% | Training loss: 0.6883828761902723
Epoch: 41 | Iteration number: [450/565] 79% | Training loss: 0.6883605643113454
Epoch: 41 | Iteration number: [460/565] 81% | Training loss: 0.688330781718959
Epoch: 41 | Iteration number: [470/565] 83% | Training loss: 0.6883033474709125
Epoch: 41 | Iteration number: [480/565] 84% | Training loss: 0.6882772882779439
Epoch: 41 | Iteration number: [490/565] 86% | Training loss: 0.6882471661178433
Epoch: 41 | Iteration number: [500/565] 88% | Training loss: 0.6882200050354004
Epoch: 41 | Iteration number: [510/565] 90% | Training loss: 0.6882000559685277
Epoch: 41 | Iteration number: [520/565] 92% | Training loss: 0.6881781947154265
Epoch: 41 | Iteration number: [530/565] 93% | Training loss: 0.6881532818641303
Epoch: 41 | Iteration number: [540/565] 95% | Training loss: 0.6881202320257823
Epoch: 41 | Iteration number: [550/565] 97% | Training loss: 0.6880932176113128
Epoch: 41 | Iteration number: [560/565] 99% | Training loss: 0.6880676780428205

 End of epoch: 41 | Train Loss: 0.6868444604156292 | Training Time: 89 

 End of epoch: 41 | Eval Loss: 0.6894093241010394 | Evaluating Time: 6 
Epoch: 42 | Iteration number: [10/565] 1% | Training loss: 0.7554597616195678
Epoch: 42 | Iteration number: [20/565] 3% | Training loss: 0.7211643993854523
Epoch: 42 | Iteration number: [30/565] 5% | Training loss: 0.7098010202248891
Epoch: 42 | Iteration number: [40/565] 7% | Training loss: 0.7040479198098183
Epoch: 42 | Iteration number: [50/565] 8% | Training loss: 0.7006462168693542
Epoch: 42 | Iteration number: [60/565] 10% | Training loss: 0.6984285424153011
Epoch: 42 | Iteration number: [70/565] 12% | Training loss: 0.6968592660767692
Epoch: 42 | Iteration number: [80/565] 14% | Training loss: 0.6955747395753861
Epoch: 42 | Iteration number: [90/565] 15% | Training loss: 0.6946246001455519
Epoch: 42 | Iteration number: [100/565] 17% | Training loss: 0.6938425761461258
Epoch: 42 | Iteration number: [110/565] 19% | Training loss: 0.6931847648187117
Epoch: 42 | Iteration number: [120/565] 21% | Training loss: 0.6926568100849787
Epoch: 42 | Iteration number: [130/565] 23% | Training loss: 0.6922277693565075
Epoch: 42 | Iteration number: [140/565] 24% | Training loss: 0.6918789386749268
Epoch: 42 | Iteration number: [150/565] 26% | Training loss: 0.6915460824966431
Epoch: 42 | Iteration number: [160/565] 28% | Training loss: 0.6912271019071341
Epoch: 42 | Iteration number: [170/565] 30% | Training loss: 0.6909447442082798
Epoch: 42 | Iteration number: [180/565] 31% | Training loss: 0.6907217025756835
Epoch: 42 | Iteration number: [190/565] 33% | Training loss: 0.6905143530745256
Epoch: 42 | Iteration number: [200/565] 35% | Training loss: 0.690339959859848
Epoch: 42 | Iteration number: [210/565] 37% | Training loss: 0.6901451431569599
Epoch: 42 | Iteration number: [220/565] 38% | Training loss: 0.6899927293712442
Epoch: 42 | Iteration number: [230/565] 40% | Training loss: 0.6898423555104629
Epoch: 42 | Iteration number: [240/565] 42% | Training loss: 0.6897028379142285
Epoch: 42 | Iteration number: [250/565] 44% | Training loss: 0.6895813107490539
Epoch: 42 | Iteration number: [260/565] 46% | Training loss: 0.6894851707495175
Epoch: 42 | Iteration number: [270/565] 47% | Training loss: 0.6893736079887107
Epoch: 42 | Iteration number: [280/565] 49% | Training loss: 0.6892864465713501
Epoch: 42 | Iteration number: [290/565] 51% | Training loss: 0.6891987975301413
Epoch: 42 | Iteration number: [300/565] 53% | Training loss: 0.6891160082817077
Epoch: 42 | Iteration number: [310/565] 54% | Training loss: 0.6890489989711392
Epoch: 42 | Iteration number: [320/565] 56% | Training loss: 0.6889805629849434
Epoch: 42 | Iteration number: [330/565] 58% | Training loss: 0.6889207455244931
Epoch: 42 | Iteration number: [340/565] 60% | Training loss: 0.688861018243958
Epoch: 42 | Iteration number: [350/565] 61% | Training loss: 0.6887949047769819
Epoch: 42 | Iteration number: [360/565] 63% | Training loss: 0.6887371288405524
Epoch: 42 | Iteration number: [370/565] 65% | Training loss: 0.6886897878066913
Epoch: 42 | Iteration number: [380/565] 67% | Training loss: 0.6886395226967962
Epoch: 42 | Iteration number: [390/565] 69% | Training loss: 0.6885922586306548
Epoch: 42 | Iteration number: [400/565] 70% | Training loss: 0.6885514409840107
Epoch: 42 | Iteration number: [410/565] 72% | Training loss: 0.68850321013753
Epoch: 42 | Iteration number: [420/565] 74% | Training loss: 0.6884672047126861
Epoch: 42 | Iteration number: [430/565] 76% | Training loss: 0.6884339132974314
Epoch: 42 | Iteration number: [440/565] 77% | Training loss: 0.688408557257869
Epoch: 42 | Iteration number: [450/565] 79% | Training loss: 0.6883691226111518
Epoch: 42 | Iteration number: [460/565] 81% | Training loss: 0.6883365953746049
Epoch: 42 | Iteration number: [470/565] 83% | Training loss: 0.688311068555142
Epoch: 42 | Iteration number: [480/565] 84% | Training loss: 0.6882842021683852
Epoch: 42 | Iteration number: [490/565] 86% | Training loss: 0.6882597784606778
Epoch: 42 | Iteration number: [500/565] 88% | Training loss: 0.688235203385353
Epoch: 42 | Iteration number: [510/565] 90% | Training loss: 0.6882092377718757
Epoch: 42 | Iteration number: [520/565] 92% | Training loss: 0.6881755591585086
Epoch: 42 | Iteration number: [530/565] 93% | Training loss: 0.6881462912514524
Epoch: 42 | Iteration number: [540/565] 95% | Training loss: 0.6881119565831291
Epoch: 42 | Iteration number: [550/565] 97% | Training loss: 0.6880840242992748
Epoch: 42 | Iteration number: [560/565] 99% | Training loss: 0.688061464790787

 End of epoch: 42 | Train Loss: 0.686834911962526 | Training Time: 89 

 End of epoch: 42 | Eval Loss: 0.6901387316840035 | Evaluating Time: 6 
Epoch: 43 | Iteration number: [10/565] 1% | Training loss: 0.755615520477295
Epoch: 43 | Iteration number: [20/565] 3% | Training loss: 0.7211034387350083
Epoch: 43 | Iteration number: [30/565] 5% | Training loss: 0.7096631725629171
Epoch: 43 | Iteration number: [40/565] 7% | Training loss: 0.7041219487786293
Epoch: 43 | Iteration number: [50/565] 8% | Training loss: 0.7006682109832764
Epoch: 43 | Iteration number: [60/565] 10% | Training loss: 0.6983614007631938
Epoch: 43 | Iteration number: [70/565] 12% | Training loss: 0.6967635290963309
Epoch: 43 | Iteration number: [80/565] 14% | Training loss: 0.6955247655510902
Epoch: 43 | Iteration number: [90/565] 15% | Training loss: 0.6946260816521115
Epoch: 43 | Iteration number: [100/565] 17% | Training loss: 0.6938440960645675
Epoch: 43 | Iteration number: [110/565] 19% | Training loss: 0.6931808590888977
Epoch: 43 | Iteration number: [120/565] 21% | Training loss: 0.6926141237219174
Epoch: 43 | Iteration number: [130/565] 23% | Training loss: 0.6921601295471191
Epoch: 43 | Iteration number: [140/565] 24% | Training loss: 0.6917978652885982
Epoch: 43 | Iteration number: [150/565] 26% | Training loss: 0.6914599533875784
Epoch: 43 | Iteration number: [160/565] 28% | Training loss: 0.6912001844495534
Epoch: 43 | Iteration number: [170/565] 30% | Training loss: 0.6909151466453777
Epoch: 43 | Iteration number: [180/565] 31% | Training loss: 0.690688775645362
Epoch: 43 | Iteration number: [190/565] 33% | Training loss: 0.6904823227932578
Epoch: 43 | Iteration number: [200/565] 35% | Training loss: 0.6902882868051529
Epoch: 43 | Iteration number: [210/565] 37% | Training loss: 0.690123443660282
Epoch: 43 | Iteration number: [220/565] 38% | Training loss: 0.6899575534191998
Epoch: 43 | Iteration number: [230/565] 40% | Training loss: 0.6898437396339748
Epoch: 43 | Iteration number: [240/565] 42% | Training loss: 0.6897476096947988
Epoch: 43 | Iteration number: [250/565] 44% | Training loss: 0.689625898361206
Epoch: 43 | Iteration number: [260/565] 46% | Training loss: 0.6895199349293342
Epoch: 43 | Iteration number: [270/565] 47% | Training loss: 0.6894149508741166
Epoch: 43 | Iteration number: [280/565] 49% | Training loss: 0.6893175684979984
Epoch: 43 | Iteration number: [290/565] 51% | Training loss: 0.689245218860692
Epoch: 43 | Iteration number: [300/565] 53% | Training loss: 0.6891568098465601
Epoch: 43 | Iteration number: [310/565] 54% | Training loss: 0.6890638364899543
Epoch: 43 | Iteration number: [320/565] 56% | Training loss: 0.6889886174350976
Epoch: 43 | Iteration number: [330/565] 58% | Training loss: 0.6889156128420975
Epoch: 43 | Iteration number: [340/565] 60% | Training loss: 0.688856489167494
Epoch: 43 | Iteration number: [350/565] 61% | Training loss: 0.6887901014941079
Epoch: 43 | Iteration number: [360/565] 63% | Training loss: 0.6887394335534838
Epoch: 43 | Iteration number: [370/565] 65% | Training loss: 0.6886984332187756
Epoch: 43 | Iteration number: [380/565] 67% | Training loss: 0.6886512246571089
Epoch: 43 | Iteration number: [390/565] 69% | Training loss: 0.6886100397660182
Epoch: 43 | Iteration number: [400/565] 70% | Training loss: 0.6885635775327682
Epoch: 43 | Iteration number: [410/565] 72% | Training loss: 0.6885188621718709
Epoch: 43 | Iteration number: [420/565] 74% | Training loss: 0.6884808043638865
Epoch: 43 | Iteration number: [430/565] 76% | Training loss: 0.6884429974611416
Epoch: 43 | Iteration number: [440/565] 77% | Training loss: 0.6884049714966254
Epoch: 43 | Iteration number: [450/565] 79% | Training loss: 0.6883783778879378
Epoch: 43 | Iteration number: [460/565] 81% | Training loss: 0.6883401041445525
Epoch: 43 | Iteration number: [470/565] 83% | Training loss: 0.6883117353662531
Epoch: 43 | Iteration number: [480/565] 84% | Training loss: 0.688286070773999
Epoch: 43 | Iteration number: [490/565] 86% | Training loss: 0.6882616971220289
Epoch: 43 | Iteration number: [500/565] 88% | Training loss: 0.688231789112091
Epoch: 43 | Iteration number: [510/565] 90% | Training loss: 0.6882037935303706
Epoch: 43 | Iteration number: [520/565] 92% | Training loss: 0.6881750701711729
Epoch: 43 | Iteration number: [530/565] 93% | Training loss: 0.6881541286999324
Epoch: 43 | Iteration number: [540/565] 95% | Training loss: 0.688129037839395
Epoch: 43 | Iteration number: [550/565] 97% | Training loss: 0.6881062055717815
Epoch: 43 | Iteration number: [560/565] 99% | Training loss: 0.688081135068621

 End of epoch: 43 | Train Loss: 0.6868510047946356 | Training Time: 89 

 End of epoch: 43 | Eval Loss: 0.6899991376059396 | Evaluating Time: 6 
Epoch: 44 | Iteration number: [10/565] 1% | Training loss: 0.75580113530159
Epoch: 44 | Iteration number: [20/565] 3% | Training loss: 0.7214109510183334
Epoch: 44 | Iteration number: [30/565] 5% | Training loss: 0.7099327484766642
Epoch: 44 | Iteration number: [40/565] 7% | Training loss: 0.7041198536753654
Epoch: 44 | Iteration number: [50/565] 8% | Training loss: 0.7006571245193481
Epoch: 44 | Iteration number: [60/565] 10% | Training loss: 0.6983608116706213
Epoch: 44 | Iteration number: [70/565] 12% | Training loss: 0.6966945946216583
Epoch: 44 | Iteration number: [80/565] 14% | Training loss: 0.6954548865556717
Epoch: 44 | Iteration number: [90/565] 15% | Training loss: 0.6944426324632432
Epoch: 44 | Iteration number: [100/565] 17% | Training loss: 0.6937004262208939
Epoch: 44 | Iteration number: [110/565] 19% | Training loss: 0.6930739998817443
Epoch: 44 | Iteration number: [120/565] 21% | Training loss: 0.6925707976023356
Epoch: 44 | Iteration number: [130/565] 23% | Training loss: 0.6921100754004258
Epoch: 44 | Iteration number: [140/565] 24% | Training loss: 0.6917131577219282
Epoch: 44 | Iteration number: [150/565] 26% | Training loss: 0.691401111682256
Epoch: 44 | Iteration number: [160/565] 28% | Training loss: 0.6911060184240341
Epoch: 44 | Iteration number: [170/565] 30% | Training loss: 0.6908514261245727
Epoch: 44 | Iteration number: [180/565] 31% | Training loss: 0.6906212780210707
Epoch: 44 | Iteration number: [190/565] 33% | Training loss: 0.6904305006328382
Epoch: 44 | Iteration number: [200/565] 35% | Training loss: 0.6902495563030243
Epoch: 44 | Iteration number: [210/565] 37% | Training loss: 0.6900988533383324
Epoch: 44 | Iteration number: [220/565] 38% | Training loss: 0.6899765280160037
Epoch: 44 | Iteration number: [230/565] 40% | Training loss: 0.6898501997408659
Epoch: 44 | Iteration number: [240/565] 42% | Training loss: 0.6897096934417883
Epoch: 44 | Iteration number: [250/565] 44% | Training loss: 0.6895877439975738
Epoch: 44 | Iteration number: [260/565] 46% | Training loss: 0.6894783228635788
Epoch: 44 | Iteration number: [270/565] 47% | Training loss: 0.6894022579546328
Epoch: 44 | Iteration number: [280/565] 49% | Training loss: 0.6893115365079471
Epoch: 44 | Iteration number: [290/565] 51% | Training loss: 0.689228816690116
Epoch: 44 | Iteration number: [300/565] 53% | Training loss: 0.6891469192504883
Epoch: 44 | Iteration number: [310/565] 54% | Training loss: 0.6890839553648426
Epoch: 44 | Iteration number: [320/565] 56% | Training loss: 0.6890217149630189
Epoch: 44 | Iteration number: [330/565] 58% | Training loss: 0.6889552726890101
Epoch: 44 | Iteration number: [340/565] 60% | Training loss: 0.6888882945565616
Epoch: 44 | Iteration number: [350/565] 61% | Training loss: 0.6888214346340724
Epoch: 44 | Iteration number: [360/565] 63% | Training loss: 0.6887673404481676
Epoch: 44 | Iteration number: [370/565] 65% | Training loss: 0.6887185352879601
Epoch: 44 | Iteration number: [380/565] 67% | Training loss: 0.6886712714245445
Epoch: 44 | Iteration number: [390/565] 69% | Training loss: 0.6886076317383693
Epoch: 44 | Iteration number: [400/565] 70% | Training loss: 0.6885559937357902
Epoch: 44 | Iteration number: [410/565] 72% | Training loss: 0.6885205007180935
Epoch: 44 | Iteration number: [420/565] 74% | Training loss: 0.6884746395406269
Epoch: 44 | Iteration number: [430/565] 76% | Training loss: 0.6884347339009129
Epoch: 44 | Iteration number: [440/565] 77% | Training loss: 0.6883993702855977
Epoch: 44 | Iteration number: [450/565] 79% | Training loss: 0.6883684390121037
Epoch: 44 | Iteration number: [460/565] 81% | Training loss: 0.6883342380109041
Epoch: 44 | Iteration number: [470/565] 83% | Training loss: 0.6882942406421012
Epoch: 44 | Iteration number: [480/565] 84% | Training loss: 0.6882607930650314
Epoch: 44 | Iteration number: [490/565] 86% | Training loss: 0.6882280533411065
Epoch: 44 | Iteration number: [500/565] 88% | Training loss: 0.6882018374204636
Epoch: 44 | Iteration number: [510/565] 90% | Training loss: 0.6881719800771452
Epoch: 44 | Iteration number: [520/565] 92% | Training loss: 0.6881351004426296
Epoch: 44 | Iteration number: [530/565] 93% | Training loss: 0.6881143592438608
Epoch: 44 | Iteration number: [540/565] 95% | Training loss: 0.6880968243987472
Epoch: 44 | Iteration number: [550/565] 97% | Training loss: 0.688074844642119
Epoch: 44 | Iteration number: [560/565] 99% | Training loss: 0.6880536268864359

 End of epoch: 44 | Train Loss: 0.6868320737264852 | Training Time: 89 

 End of epoch: 44 | Eval Loss: 0.6896517957959857 | Evaluating Time: 5 
Epoch: 45 | Iteration number: [10/565] 1% | Training loss: 0.7552422702312469
Epoch: 45 | Iteration number: [20/565] 3% | Training loss: 0.7210133910179138
Epoch: 45 | Iteration number: [30/565] 5% | Training loss: 0.7094325045744578
Epoch: 45 | Iteration number: [40/565] 7% | Training loss: 0.7037856817245484
Epoch: 45 | Iteration number: [50/565] 8% | Training loss: 0.7004061341285706
Epoch: 45 | Iteration number: [60/565] 10% | Training loss: 0.6981396188338598
Epoch: 45 | Iteration number: [70/565] 12% | Training loss: 0.6965270459651947
Epoch: 45 | Iteration number: [80/565] 14% | Training loss: 0.6952881693840027
Epoch: 45 | Iteration number: [90/565] 15% | Training loss: 0.6943796124723223
Epoch: 45 | Iteration number: [100/565] 17% | Training loss: 0.6936480331420899
Epoch: 45 | Iteration number: [110/565] 19% | Training loss: 0.6930291690609672
Epoch: 45 | Iteration number: [120/565] 21% | Training loss: 0.6924964398145675
Epoch: 45 | Iteration number: [130/565] 23% | Training loss: 0.6920552354592543
Epoch: 45 | Iteration number: [140/565] 24% | Training loss: 0.6916692410196577
Epoch: 45 | Iteration number: [150/565] 26% | Training loss: 0.6913345110416412
Epoch: 45 | Iteration number: [160/565] 28% | Training loss: 0.6910634394735098
Epoch: 45 | Iteration number: [170/565] 30% | Training loss: 0.6908248557763941
Epoch: 45 | Iteration number: [180/565] 31% | Training loss: 0.6906003481811948
Epoch: 45 | Iteration number: [190/565] 33% | Training loss: 0.6904172031502974
Epoch: 45 | Iteration number: [200/565] 35% | Training loss: 0.690231466293335
Epoch: 45 | Iteration number: [210/565] 37% | Training loss: 0.6900623622394744
Epoch: 45 | Iteration number: [220/565] 38% | Training loss: 0.6899230892008001
Epoch: 45 | Iteration number: [230/565] 40% | Training loss: 0.6897824803124304
Epoch: 45 | Iteration number: [240/565] 42% | Training loss: 0.6896711232761542
Epoch: 45 | Iteration number: [250/565] 44% | Training loss: 0.6895602724552155
Epoch: 45 | Iteration number: [260/565] 46% | Training loss: 0.6894425050570414
Epoch: 45 | Iteration number: [270/565] 47% | Training loss: 0.6893415958793075
Epoch: 45 | Iteration number: [280/565] 49% | Training loss: 0.6892644888588361
Epoch: 45 | Iteration number: [290/565] 51% | Training loss: 0.6891839923529789
Epoch: 45 | Iteration number: [300/565] 53% | Training loss: 0.6891023260354996
Epoch: 45 | Iteration number: [310/565] 54% | Training loss: 0.689036952295611
Epoch: 45 | Iteration number: [320/565] 56% | Training loss: 0.6889740381389856
Epoch: 45 | Iteration number: [330/565] 58% | Training loss: 0.6889192698579846
Epoch: 45 | Iteration number: [340/565] 60% | Training loss: 0.6888512083712746
Epoch: 45 | Iteration number: [350/565] 61% | Training loss: 0.6887996305738177
Epoch: 45 | Iteration number: [360/565] 63% | Training loss: 0.6887425690889358
Epoch: 45 | Iteration number: [370/565] 65% | Training loss: 0.6886894862394075
Epoch: 45 | Iteration number: [380/565] 67% | Training loss: 0.6886386129416917
Epoch: 45 | Iteration number: [390/565] 69% | Training loss: 0.6885950462940412
Epoch: 45 | Iteration number: [400/565] 70% | Training loss: 0.688543246537447
Epoch: 45 | Iteration number: [410/565] 72% | Training loss: 0.6885050860846915
Epoch: 45 | Iteration number: [420/565] 74% | Training loss: 0.6884592791398366
Epoch: 45 | Iteration number: [430/565] 76% | Training loss: 0.688429206332495
Epoch: 45 | Iteration number: [440/565] 77% | Training loss: 0.6883951635523275
Epoch: 45 | Iteration number: [450/565] 79% | Training loss: 0.6883532302909428
Epoch: 45 | Iteration number: [460/565] 81% | Training loss: 0.68831336705581
Epoch: 45 | Iteration number: [470/565] 83% | Training loss: 0.6882807923124191
Epoch: 45 | Iteration number: [480/565] 84% | Training loss: 0.6882466185837984
Epoch: 45 | Iteration number: [490/565] 86% | Training loss: 0.6882231237936993
Epoch: 45 | Iteration number: [500/565] 88% | Training loss: 0.6882025763988495
Epoch: 45 | Iteration number: [510/565] 90% | Training loss: 0.6881662642254549
Epoch: 45 | Iteration number: [520/565] 92% | Training loss: 0.6881513852339525
Epoch: 45 | Iteration number: [530/565] 93% | Training loss: 0.6881298836672081
Epoch: 45 | Iteration number: [540/565] 95% | Training loss: 0.6881098164452447
Epoch: 45 | Iteration number: [550/565] 97% | Training loss: 0.6880811175433073
Epoch: 45 | Iteration number: [560/565] 99% | Training loss: 0.6880680498267923

 End of epoch: 45 | Train Loss: 0.6868373326495686 | Training Time: 88 

 End of epoch: 45 | Eval Loss: 0.6897642357008797 | Evaluating Time: 5 
Epoch: 46 | Iteration number: [10/565] 1% | Training loss: 0.7555727779865264
Epoch: 46 | Iteration number: [20/565] 3% | Training loss: 0.7213590949773788
Epoch: 46 | Iteration number: [30/565] 5% | Training loss: 0.7099697669347127
Epoch: 46 | Iteration number: [40/565] 7% | Training loss: 0.7042075917124748
Epoch: 46 | Iteration number: [50/565] 8% | Training loss: 0.7008417534828186
Epoch: 46 | Iteration number: [60/565] 10% | Training loss: 0.6984979073206584
Epoch: 46 | Iteration number: [70/565] 12% | Training loss: 0.6969208742891039
Epoch: 46 | Iteration number: [80/565] 14% | Training loss: 0.6957101449370384
Epoch: 46 | Iteration number: [90/565] 15% | Training loss: 0.6947369747691684
Epoch: 46 | Iteration number: [100/565] 17% | Training loss: 0.6939967429637909
Epoch: 46 | Iteration number: [110/565] 19% | Training loss: 0.6933371728116816
Epoch: 46 | Iteration number: [120/565] 21% | Training loss: 0.6927980571985245
Epoch: 46 | Iteration number: [130/565] 23% | Training loss: 0.6923426518073449
Epoch: 46 | Iteration number: [140/565] 24% | Training loss: 0.6919646569660731
Epoch: 46 | Iteration number: [150/565] 26% | Training loss: 0.6916246700286866
Epoch: 46 | Iteration number: [160/565] 28% | Training loss: 0.6913222316652536
Epoch: 46 | Iteration number: [170/565] 30% | Training loss: 0.6910279827959397
Epoch: 46 | Iteration number: [180/565] 31% | Training loss: 0.690764030151897
Epoch: 46 | Iteration number: [190/565] 33% | Training loss: 0.6905479255475496
Epoch: 46 | Iteration number: [200/565] 35% | Training loss: 0.6903381186723709
Epoch: 46 | Iteration number: [210/565] 37% | Training loss: 0.690175961028962
Epoch: 46 | Iteration number: [220/565] 38% | Training loss: 0.6900135205550627
Epoch: 46 | Iteration number: [230/565] 40% | Training loss: 0.6898676613102789
Epoch: 46 | Iteration number: [240/565] 42% | Training loss: 0.6897372235854466
Epoch: 46 | Iteration number: [250/565] 44% | Training loss: 0.6896182291507721
Epoch: 46 | Iteration number: [260/565] 46% | Training loss: 0.6895048421162825
Epoch: 46 | Iteration number: [270/565] 47% | Training loss: 0.6894052258244268
Epoch: 46 | Iteration number: [280/565] 49% | Training loss: 0.6892959245613643
Epoch: 46 | Iteration number: [290/565] 51% | Training loss: 0.6891999534491835
Epoch: 46 | Iteration number: [300/565] 53% | Training loss: 0.6891272701819737
Epoch: 46 | Iteration number: [310/565] 54% | Training loss: 0.6890615005646983
Epoch: 46 | Iteration number: [320/565] 56% | Training loss: 0.6889806929975748
Epoch: 46 | Iteration number: [330/565] 58% | Training loss: 0.6889161489226602
Epoch: 46 | Iteration number: [340/565] 60% | Training loss: 0.6888543563730577
Epoch: 46 | Iteration number: [350/565] 61% | Training loss: 0.6887891336849757
Epoch: 46 | Iteration number: [360/565] 63% | Training loss: 0.6887432080176141
Epoch: 46 | Iteration number: [370/565] 65% | Training loss: 0.6887035978806986
Epoch: 46 | Iteration number: [380/565] 67% | Training loss: 0.6886549681425095
Epoch: 46 | Iteration number: [390/565] 69% | Training loss: 0.6886003310863789
Epoch: 46 | Iteration number: [400/565] 70% | Training loss: 0.688561714142561
Epoch: 46 | Iteration number: [410/565] 72% | Training loss: 0.6885279280383413
Epoch: 46 | Iteration number: [420/565] 74% | Training loss: 0.688506783757891
Epoch: 46 | Iteration number: [430/565] 76% | Training loss: 0.6884697122629299
Epoch: 46 | Iteration number: [440/565] 77% | Training loss: 0.688425985114141
Epoch: 46 | Iteration number: [450/565] 79% | Training loss: 0.6883874290519291
Epoch: 46 | Iteration number: [460/565] 81% | Training loss: 0.6883494570203449
Epoch: 46 | Iteration number: [470/565] 83% | Training loss: 0.6883189764428645
Epoch: 46 | Iteration number: [480/565] 84% | Training loss: 0.6882849438736837
Epoch: 46 | Iteration number: [490/565] 86% | Training loss: 0.6882522812911442
Epoch: 46 | Iteration number: [500/565] 88% | Training loss: 0.6882228440046311
Epoch: 46 | Iteration number: [510/565] 90% | Training loss: 0.68818993732041
Epoch: 46 | Iteration number: [520/565] 92% | Training loss: 0.6881769614724013
Epoch: 46 | Iteration number: [530/565] 93% | Training loss: 0.6881400625660734
Epoch: 46 | Iteration number: [540/565] 95% | Training loss: 0.6881180531448788
Epoch: 46 | Iteration number: [550/565] 97% | Training loss: 0.6880959663607857
Epoch: 46 | Iteration number: [560/565] 99% | Training loss: 0.6880656965076923

 End of epoch: 46 | Train Loss: 0.6868405095243876 | Training Time: 88 

 End of epoch: 46 | Eval Loss: 0.6902850270271301 | Evaluating Time: 5 
Epoch: 47 | Iteration number: [10/565] 1% | Training loss: 0.7558095574378967
Epoch: 47 | Iteration number: [20/565] 3% | Training loss: 0.7212418287992477
Epoch: 47 | Iteration number: [30/565] 5% | Training loss: 0.7098516066869099
Epoch: 47 | Iteration number: [40/565] 7% | Training loss: 0.7040980815887451
Epoch: 47 | Iteration number: [50/565] 8% | Training loss: 0.7006613326072693
Epoch: 47 | Iteration number: [60/565] 10% | Training loss: 0.6982629726330439
Epoch: 47 | Iteration number: [70/565] 12% | Training loss: 0.6967153140476772
Epoch: 47 | Iteration number: [80/565] 14% | Training loss: 0.6954128317534923
Epoch: 47 | Iteration number: [90/565] 15% | Training loss: 0.694450095627043
Epoch: 47 | Iteration number: [100/565] 17% | Training loss: 0.6936824768781662
Epoch: 47 | Iteration number: [110/565] 19% | Training loss: 0.6930690017613498
Epoch: 47 | Iteration number: [120/565] 21% | Training loss: 0.6925684149066608
Epoch: 47 | Iteration number: [130/565] 23% | Training loss: 0.6921570255206182
Epoch: 47 | Iteration number: [140/565] 24% | Training loss: 0.6917416432074138
Epoch: 47 | Iteration number: [150/565] 26% | Training loss: 0.6914222415288289
Epoch: 47 | Iteration number: [160/565] 28% | Training loss: 0.6911003056913614
Epoch: 47 | Iteration number: [170/565] 30% | Training loss: 0.6908307100043577
Epoch: 47 | Iteration number: [180/565] 31% | Training loss: 0.6906008544895385
Epoch: 47 | Iteration number: [190/565] 33% | Training loss: 0.6903917450653879
Epoch: 47 | Iteration number: [200/565] 35% | Training loss: 0.6902216988801956
Epoch: 47 | Iteration number: [210/565] 37% | Training loss: 0.6900755638167971
Epoch: 47 | Iteration number: [220/565] 38% | Training loss: 0.6899279857223685
Epoch: 47 | Iteration number: [230/565] 40% | Training loss: 0.6897833894128385
Epoch: 47 | Iteration number: [240/565] 42% | Training loss: 0.6896596319973469
Epoch: 47 | Iteration number: [250/565] 44% | Training loss: 0.6895583956241608
Epoch: 47 | Iteration number: [260/565] 46% | Training loss: 0.6894413044819465
Epoch: 47 | Iteration number: [270/565] 47% | Training loss: 0.6893523083792792
Epoch: 47 | Iteration number: [280/565] 49% | Training loss: 0.6892701189432825
Epoch: 47 | Iteration number: [290/565] 51% | Training loss: 0.6891935046376854
Epoch: 47 | Iteration number: [300/565] 53% | Training loss: 0.689108724196752
Epoch: 47 | Iteration number: [310/565] 54% | Training loss: 0.6890444653649483
Epoch: 47 | Iteration number: [320/565] 56% | Training loss: 0.6889736754819751
Epoch: 47 | Iteration number: [330/565] 58% | Training loss: 0.6889279239105456
Epoch: 47 | Iteration number: [340/565] 60% | Training loss: 0.6888724206125035
Epoch: 47 | Iteration number: [350/565] 61% | Training loss: 0.6888087398665292
Epoch: 47 | Iteration number: [360/565] 63% | Training loss: 0.6887511173884074
Epoch: 47 | Iteration number: [370/565] 65% | Training loss: 0.6886868103130444
Epoch: 47 | Iteration number: [380/565] 67% | Training loss: 0.6886298490198035
Epoch: 47 | Iteration number: [390/565] 69% | Training loss: 0.6885827165383559
Epoch: 47 | Iteration number: [400/565] 70% | Training loss: 0.6885432982444764
Epoch: 47 | Iteration number: [410/565] 72% | Training loss: 0.6885017262726295
Epoch: 47 | Iteration number: [420/565] 74% | Training loss: 0.6884630169187274
Epoch: 47 | Iteration number: [430/565] 76% | Training loss: 0.6884241461753845
Epoch: 47 | Iteration number: [440/565] 77% | Training loss: 0.6883900080214848
Epoch: 47 | Iteration number: [450/565] 79% | Training loss: 0.6883571416801877
Epoch: 47 | Iteration number: [460/565] 81% | Training loss: 0.6883328880952753
Epoch: 47 | Iteration number: [470/565] 83% | Training loss: 0.6882992090062893
Epoch: 47 | Iteration number: [480/565] 84% | Training loss: 0.6882639568299055
Epoch: 47 | Iteration number: [490/565] 86% | Training loss: 0.6882443650644653
Epoch: 47 | Iteration number: [500/565] 88% | Training loss: 0.6882207332849503
Epoch: 47 | Iteration number: [510/565] 90% | Training loss: 0.688188551453983
Epoch: 47 | Iteration number: [520/565] 92% | Training loss: 0.6881577506661415
Epoch: 47 | Iteration number: [530/565] 93% | Training loss: 0.6881371809626525
Epoch: 47 | Iteration number: [540/565] 95% | Training loss: 0.6881135771671931
Epoch: 47 | Iteration number: [550/565] 97% | Training loss: 0.6880858697674491
Epoch: 47 | Iteration number: [560/565] 99% | Training loss: 0.6880613415368966

 End of epoch: 47 | Train Loss: 0.6868377185500829 | Training Time: 89 

 End of epoch: 47 | Eval Loss: 0.6902750815664019 | Evaluating Time: 5 
Epoch: 48 | Iteration number: [10/565] 1% | Training loss: 0.7556836545467377
Epoch: 48 | Iteration number: [20/565] 3% | Training loss: 0.7211984187364578
Epoch: 48 | Iteration number: [30/565] 5% | Training loss: 0.7098510483900706
Epoch: 48 | Iteration number: [40/565] 7% | Training loss: 0.7040694251656532
Epoch: 48 | Iteration number: [50/565] 8% | Training loss: 0.7005817568302155
Epoch: 48 | Iteration number: [60/565] 10% | Training loss: 0.6982911576827368
Epoch: 48 | Iteration number: [70/565] 12% | Training loss: 0.6966970596994673
Epoch: 48 | Iteration number: [80/565] 14% | Training loss: 0.6954698614776135
Epoch: 48 | Iteration number: [90/565] 15% | Training loss: 0.6944971402486165
Epoch: 48 | Iteration number: [100/565] 17% | Training loss: 0.6937216573953628
Epoch: 48 | Iteration number: [110/565] 19% | Training loss: 0.6931079403920607
Epoch: 48 | Iteration number: [120/565] 21% | Training loss: 0.6925739258527756
Epoch: 48 | Iteration number: [130/565] 23% | Training loss: 0.6921323629525992
Epoch: 48 | Iteration number: [140/565] 24% | Training loss: 0.691764024751527
Epoch: 48 | Iteration number: [150/565] 26% | Training loss: 0.6914442137877146
Epoch: 48 | Iteration number: [160/565] 28% | Training loss: 0.6911681812256575
Epoch: 48 | Iteration number: [170/565] 30% | Training loss: 0.6908939898014068
Epoch: 48 | Iteration number: [180/565] 31% | Training loss: 0.6906716896428002
Epoch: 48 | Iteration number: [190/565] 33% | Training loss: 0.6904528426496606
Epoch: 48 | Iteration number: [200/565] 35% | Training loss: 0.6902791941165924
Epoch: 48 | Iteration number: [210/565] 37% | Training loss: 0.6901150206724803
Epoch: 48 | Iteration number: [220/565] 38% | Training loss: 0.6899467782540755
Epoch: 48 | Iteration number: [230/565] 40% | Training loss: 0.6897844223872475
Epoch: 48 | Iteration number: [240/565] 42% | Training loss: 0.6896598517894745
Epoch: 48 | Iteration number: [250/565] 44% | Training loss: 0.6895583100318908
Epoch: 48 | Iteration number: [260/565] 46% | Training loss: 0.6894537889040433
Epoch: 48 | Iteration number: [270/565] 47% | Training loss: 0.6893591172165341
Epoch: 48 | Iteration number: [280/565] 49% | Training loss: 0.6892655012863023
Epoch: 48 | Iteration number: [290/565] 51% | Training loss: 0.6891790398235978
Epoch: 48 | Iteration number: [300/565] 53% | Training loss: 0.6890970118840536
Epoch: 48 | Iteration number: [310/565] 54% | Training loss: 0.6890268660360767
Epoch: 48 | Iteration number: [320/565] 56% | Training loss: 0.6889545645564794
Epoch: 48 | Iteration number: [330/565] 58% | Training loss: 0.6888978038773392
Epoch: 48 | Iteration number: [340/565] 60% | Training loss: 0.6888338872615029
Epoch: 48 | Iteration number: [350/565] 61% | Training loss: 0.6887826097011566
Epoch: 48 | Iteration number: [360/565] 63% | Training loss: 0.6887166236837705
Epoch: 48 | Iteration number: [370/565] 65% | Training loss: 0.6886596634581282
Epoch: 48 | Iteration number: [380/565] 67% | Training loss: 0.6886039652322468
Epoch: 48 | Iteration number: [390/565] 69% | Training loss: 0.688562162564351
Epoch: 48 | Iteration number: [400/565] 70% | Training loss: 0.6885197937488556
Epoch: 48 | Iteration number: [410/565] 72% | Training loss: 0.6884884044891451
Epoch: 48 | Iteration number: [420/565] 74% | Training loss: 0.6884472242423466
Epoch: 48 | Iteration number: [430/565] 76% | Training loss: 0.6884058956490007
Epoch: 48 | Iteration number: [440/565] 77% | Training loss: 0.6883714320984754
Epoch: 48 | Iteration number: [450/565] 79% | Training loss: 0.6883313080999587
Epoch: 48 | Iteration number: [460/565] 81% | Training loss: 0.688286812538686
Epoch: 48 | Iteration number: [470/565] 83% | Training loss: 0.6882593063597984
Epoch: 48 | Iteration number: [480/565] 84% | Training loss: 0.6882387106617291
Epoch: 48 | Iteration number: [490/565] 86% | Training loss: 0.688211347132313
Epoch: 48 | Iteration number: [500/565] 88% | Training loss: 0.6881826387643815
Epoch: 48 | Iteration number: [510/565] 90% | Training loss: 0.6881636805394117
Epoch: 48 | Iteration number: [520/565] 92% | Training loss: 0.6881404131650924
Epoch: 48 | Iteration number: [530/565] 93% | Training loss: 0.6881182406308516
Epoch: 48 | Iteration number: [540/565] 95% | Training loss: 0.6880955859466835
Epoch: 48 | Iteration number: [550/565] 97% | Training loss: 0.6880771217562935
Epoch: 48 | Iteration number: [560/565] 99% | Training loss: 0.6880475861685617

 End of epoch: 48 | Train Loss: 0.6868193314138767 | Training Time: 90 

 End of epoch: 48 | Eval Loss: 0.6900745374815804 | Evaluating Time: 6 
Epoch: 49 | Iteration number: [10/565] 1% | Training loss: 0.7549054503440857
Epoch: 49 | Iteration number: [20/565] 3% | Training loss: 0.7205536842346192
Epoch: 49 | Iteration number: [30/565] 5% | Training loss: 0.7091570218404134
Epoch: 49 | Iteration number: [40/565] 7% | Training loss: 0.7036422967910767
Epoch: 49 | Iteration number: [50/565] 8% | Training loss: 0.7002683746814727
Epoch: 49 | Iteration number: [60/565] 10% | Training loss: 0.6980295230944952
Epoch: 49 | Iteration number: [70/565] 12% | Training loss: 0.6964628202574593
Epoch: 49 | Iteration number: [80/565] 14% | Training loss: 0.6952623553574085
Epoch: 49 | Iteration number: [90/565] 15% | Training loss: 0.694352329439587
Epoch: 49 | Iteration number: [100/565] 17% | Training loss: 0.693635727763176
Epoch: 49 | Iteration number: [110/565] 19% | Training loss: 0.6930265681310134
Epoch: 49 | Iteration number: [120/565] 21% | Training loss: 0.6924979383746783
Epoch: 49 | Iteration number: [130/565] 23% | Training loss: 0.6920959674395047
Epoch: 49 | Iteration number: [140/565] 24% | Training loss: 0.691721082159451
Epoch: 49 | Iteration number: [150/565] 26% | Training loss: 0.6914115039507548
Epoch: 49 | Iteration number: [160/565] 28% | Training loss: 0.69113246537745
Epoch: 49 | Iteration number: [170/565] 30% | Training loss: 0.6908785374725566
Epoch: 49 | Iteration number: [180/565] 31% | Training loss: 0.6906650781631469
Epoch: 49 | Iteration number: [190/565] 33% | Training loss: 0.6904509613388463
Epoch: 49 | Iteration number: [200/565] 35% | Training loss: 0.6902723208069801
Epoch: 49 | Iteration number: [210/565] 37% | Training loss: 0.6901194288617089
Epoch: 49 | Iteration number: [220/565] 38% | Training loss: 0.6899759008125825
Epoch: 49 | Iteration number: [230/565] 40% | Training loss: 0.6898544166399085
Epoch: 49 | Iteration number: [240/565] 42% | Training loss: 0.6897271121541659
Epoch: 49 | Iteration number: [250/565] 44% | Training loss: 0.6896166467666626
Epoch: 49 | Iteration number: [260/565] 46% | Training loss: 0.6895053542577303
Epoch: 49 | Iteration number: [270/565] 47% | Training loss: 0.6894039332866668
Epoch: 49 | Iteration number: [280/565] 49% | Training loss: 0.6893203794956207
Epoch: 49 | Iteration number: [290/565] 51% | Training loss: 0.6892339120651113
Epoch: 49 | Iteration number: [300/565] 53% | Training loss: 0.6891607507069906
Epoch: 49 | Iteration number: [310/565] 54% | Training loss: 0.6890735566616059
Epoch: 49 | Iteration number: [320/565] 56% | Training loss: 0.6890095956623554
Epoch: 49 | Iteration number: [330/565] 58% | Training loss: 0.6889373268141891
Epoch: 49 | Iteration number: [340/565] 60% | Training loss: 0.6888732517466826
Epoch: 49 | Iteration number: [350/565] 61% | Training loss: 0.6888053108964648
Epoch: 49 | Iteration number: [360/565] 63% | Training loss: 0.6887483722633786
Epoch: 49 | Iteration number: [370/565] 65% | Training loss: 0.6887015349156148
Epoch: 49 | Iteration number: [380/565] 67% | Training loss: 0.6886492746440988
Epoch: 49 | Iteration number: [390/565] 69% | Training loss: 0.6886018024041103
Epoch: 49 | Iteration number: [400/565] 70% | Training loss: 0.6885603731870651
Epoch: 49 | Iteration number: [410/565] 72% | Training loss: 0.6885182507154418
Epoch: 49 | Iteration number: [420/565] 74% | Training loss: 0.688481239052046
Epoch: 49 | Iteration number: [430/565] 76% | Training loss: 0.688429297818694
Epoch: 49 | Iteration number: [440/565] 77% | Training loss: 0.6883985740217295
Epoch: 49 | Iteration number: [450/565] 79% | Training loss: 0.6883691342671713
Epoch: 49 | Iteration number: [460/565] 81% | Training loss: 0.6883374852978665
Epoch: 49 | Iteration number: [470/565] 83% | Training loss: 0.6883063289713353
Epoch: 49 | Iteration number: [480/565] 84% | Training loss: 0.688265456383427
Epoch: 49 | Iteration number: [490/565] 86% | Training loss: 0.6882269909187239
Epoch: 49 | Iteration number: [500/565] 88% | Training loss: 0.6881909983158112
Epoch: 49 | Iteration number: [510/565] 90% | Training loss: 0.6881612905100281
Epoch: 49 | Iteration number: [520/565] 92% | Training loss: 0.6881467051230944
Epoch: 49 | Iteration number: [530/565] 93% | Training loss: 0.6881263640691649
Epoch: 49 | Iteration number: [540/565] 95% | Training loss: 0.6881021944461045
Epoch: 49 | Iteration number: [550/565] 97% | Training loss: 0.6880819281664762
Epoch: 49 | Iteration number: [560/565] 99% | Training loss: 0.6880603865853377

 End of epoch: 49 | Train Loss: 0.686837404702617 | Training Time: 88 

 End of epoch: 49 | Eval Loss: 0.6901860748018537 | Evaluating Time: 6 
Epoch: 50 | Iteration number: [10/565] 1% | Training loss: 0.7557309746742249
Epoch: 50 | Iteration number: [20/565] 3% | Training loss: 0.7212395519018173
Epoch: 50 | Iteration number: [30/565] 5% | Training loss: 0.709751562277476
Epoch: 50 | Iteration number: [40/565] 7% | Training loss: 0.7041253373026848
Epoch: 50 | Iteration number: [50/565] 8% | Training loss: 0.7007170820236206
Epoch: 50 | Iteration number: [60/565] 10% | Training loss: 0.6983643968900045
Epoch: 50 | Iteration number: [70/565] 12% | Training loss: 0.6967360513550894
Epoch: 50 | Iteration number: [80/565] 14% | Training loss: 0.6953670337796212
Epoch: 50 | Iteration number: [90/565] 15% | Training loss: 0.6944138010342916
Epoch: 50 | Iteration number: [100/565] 17% | Training loss: 0.6936246657371521
Epoch: 50 | Iteration number: [110/565] 19% | Training loss: 0.6930140495300293
Epoch: 50 | Iteration number: [120/565] 21% | Training loss: 0.6925151040156682
Epoch: 50 | Iteration number: [130/565] 23% | Training loss: 0.6920785679267003
Epoch: 50 | Iteration number: [140/565] 24% | Training loss: 0.6916856982878277
Epoch: 50 | Iteration number: [150/565] 26% | Training loss: 0.6913841950893402
Epoch: 50 | Iteration number: [160/565] 28% | Training loss: 0.6911244187504053
Epoch: 50 | Iteration number: [170/565] 30% | Training loss: 0.6908481864368214
Epoch: 50 | Iteration number: [180/565] 31% | Training loss: 0.6906318949328528
Epoch: 50 | Iteration number: [190/565] 33% | Training loss: 0.690465803209104
Epoch: 50 | Iteration number: [200/565] 35% | Training loss: 0.6903001266717911
Epoch: 50 | Iteration number: [210/565] 37% | Training loss: 0.6901473584629241
Epoch: 50 | Iteration number: [220/565] 38% | Training loss: 0.6899885356426239
Epoch: 50 | Iteration number: [230/565] 40% | Training loss: 0.6898375570774078
Epoch: 50 | Iteration number: [240/565] 42% | Training loss: 0.6897143696745237
Epoch: 50 | Iteration number: [250/565] 44% | Training loss: 0.6895966284275055
Epoch: 50 | Iteration number: [260/565] 46% | Training loss: 0.6894710517846621
Epoch: 50 | Iteration number: [270/565] 47% | Training loss: 0.6893583847416772
Epoch: 50 | Iteration number: [280/565] 49% | Training loss: 0.6892588902797018
Epoch: 50 | Iteration number: [290/565] 51% | Training loss: 0.6891742722741488
Epoch: 50 | Iteration number: [300/565] 53% | Training loss: 0.6890813150008519
Epoch: 50 | Iteration number: [310/565] 54% | Training loss: 0.6890042033887679
Epoch: 50 | Iteration number: [320/565] 56% | Training loss: 0.6889369823038578
Epoch: 50 | Iteration number: [330/565] 58% | Training loss: 0.6888729151451226
Epoch: 50 | Iteration number: [340/565] 60% | Training loss: 0.6888259400339688
Epoch: 50 | Iteration number: [350/565] 61% | Training loss: 0.6887723793302264
Epoch: 50 | Iteration number: [360/565] 63% | Training loss: 0.688724140326182
Epoch: 50 | Iteration number: [370/565] 65% | Training loss: 0.6886769264130979
Epoch: 50 | Iteration number: [380/565] 67% | Training loss: 0.6886226476807343
Epoch: 50 | Iteration number: [390/565] 69% | Training loss: 0.688577464604989
Epoch: 50 | Iteration number: [400/565] 70% | Training loss: 0.688527581691742
Epoch: 50 | Iteration number: [410/565] 72% | Training loss: 0.6884848754580428
Epoch: 50 | Iteration number: [420/565] 74% | Training loss: 0.6884479773896081
Epoch: 50 | Iteration number: [430/565] 76% | Training loss: 0.6884031194587087
Epoch: 50 | Iteration number: [440/565] 77% | Training loss: 0.6883738979697227
Epoch: 50 | Iteration number: [450/565] 79% | Training loss: 0.6883358906375038
Epoch: 50 | Iteration number: [460/565] 81% | Training loss: 0.6882985340512318
Epoch: 50 | Iteration number: [470/565] 83% | Training loss: 0.6882763731986918
Epoch: 50 | Iteration number: [480/565] 84% | Training loss: 0.6882448226213456
Epoch: 50 | Iteration number: [490/565] 86% | Training loss: 0.6882261762813646
Epoch: 50 | Iteration number: [500/565] 88% | Training loss: 0.6882024163007736
Epoch: 50 | Iteration number: [510/565] 90% | Training loss: 0.6881765080433265
Epoch: 50 | Iteration number: [520/565] 92% | Training loss: 0.6881552355793806
Epoch: 50 | Iteration number: [530/565] 93% | Training loss: 0.6881230514004545
Epoch: 50 | Iteration number: [540/565] 95% | Training loss: 0.6880999226261069
Epoch: 50 | Iteration number: [550/565] 97% | Training loss: 0.6880800342559814
Epoch: 50 | Iteration number: [560/565] 99% | Training loss: 0.6880605241017682

 End of epoch: 50 | Train Loss: 0.6868318299276639 | Training Time: 90 

 End of epoch: 50 | Eval Loss: 0.690190315246582 | Evaluating Time: 5 
Epoch: 51 | Iteration number: [10/565] 1% | Training loss: 0.7556065559387207
Epoch: 51 | Iteration number: [20/565] 3% | Training loss: 0.7212642848491668
Epoch: 51 | Iteration number: [30/565] 5% | Training loss: 0.7095952073733012
Epoch: 51 | Iteration number: [40/565] 7% | Training loss: 0.7039917081594467
Epoch: 51 | Iteration number: [50/565] 8% | Training loss: 0.7005795466899872
Epoch: 51 | Iteration number: [60/565] 10% | Training loss: 0.6982226053873698
Epoch: 51 | Iteration number: [70/565] 12% | Training loss: 0.6966251381805965
Epoch: 51 | Iteration number: [80/565] 14% | Training loss: 0.6954533472657204
Epoch: 51 | Iteration number: [90/565] 15% | Training loss: 0.6944799131817287
Epoch: 51 | Iteration number: [100/565] 17% | Training loss: 0.6938077825307846
Epoch: 51 | Iteration number: [110/565] 19% | Training loss: 0.6931648010557349
Epoch: 51 | Iteration number: [120/565] 21% | Training loss: 0.6926218673586846
Epoch: 51 | Iteration number: [130/565] 23% | Training loss: 0.6921947139960068
Epoch: 51 | Iteration number: [140/565] 24% | Training loss: 0.6917979657649994
Epoch: 51 | Iteration number: [150/565] 26% | Training loss: 0.6915038021405538
Epoch: 51 | Iteration number: [160/565] 28% | Training loss: 0.6912331070750952
Epoch: 51 | Iteration number: [170/565] 30% | Training loss: 0.6909777655321009
Epoch: 51 | Iteration number: [180/565] 31% | Training loss: 0.6907316817177667
Epoch: 51 | Iteration number: [190/565] 33% | Training loss: 0.6905339077899331
Epoch: 51 | Iteration number: [200/565] 35% | Training loss: 0.6903563034534455
Epoch: 51 | Iteration number: [210/565] 37% | Training loss: 0.690160178854352
Epoch: 51 | Iteration number: [220/565] 38% | Training loss: 0.6900111583146182
Epoch: 51 | Iteration number: [230/565] 40% | Training loss: 0.6898723576379859
Epoch: 51 | Iteration number: [240/565] 42% | Training loss: 0.6897352958718935
Epoch: 51 | Iteration number: [250/565] 44% | Training loss: 0.689601850271225
Epoch: 51 | Iteration number: [260/565] 46% | Training loss: 0.6894861959494077
Epoch: 51 | Iteration number: [270/565] 47% | Training loss: 0.6893802607500995
Epoch: 51 | Iteration number: [280/565] 49% | Training loss: 0.6892820486000606
Epoch: 51 | Iteration number: [290/565] 51% | Training loss: 0.6891911247680927
Epoch: 51 | Iteration number: [300/565] 53% | Training loss: 0.6891118174791336
Epoch: 51 | Iteration number: [310/565] 54% | Training loss: 0.6890260740633933
Epoch: 51 | Iteration number: [320/565] 56% | Training loss: 0.6889677952975035
Epoch: 51 | Iteration number: [330/565] 58% | Training loss: 0.6888926515073487
Epoch: 51 | Iteration number: [340/565] 60% | Training loss: 0.6888265260878731
Epoch: 51 | Iteration number: [350/565] 61% | Training loss: 0.6887730646133423
Epoch: 51 | Iteration number: [360/565] 63% | Training loss: 0.688711606297228
Epoch: 51 | Iteration number: [370/565] 65% | Training loss: 0.6886608798761625
Epoch: 51 | Iteration number: [380/565] 67% | Training loss: 0.6886105277036366
Epoch: 51 | Iteration number: [390/565] 69% | Training loss: 0.6885727119751466
Epoch: 51 | Iteration number: [400/565] 70% | Training loss: 0.6885368052124977
Epoch: 51 | Iteration number: [410/565] 72% | Training loss: 0.6885041533446894
Epoch: 51 | Iteration number: [420/565] 74% | Training loss: 0.688457488162177
Epoch: 51 | Iteration number: [430/565] 76% | Training loss: 0.6884337172951809
Epoch: 51 | Iteration number: [440/565] 77% | Training loss: 0.6883905959400264
Epoch: 51 | Iteration number: [450/565] 79% | Training loss: 0.6883585715293884
Epoch: 51 | Iteration number: [460/565] 81% | Training loss: 0.6883269873650177
Epoch: 51 | Iteration number: [470/565] 83% | Training loss: 0.6882927922492331
Epoch: 51 | Iteration number: [480/565] 84% | Training loss: 0.6882463935762644
Epoch: 51 | Iteration number: [490/565] 86% | Training loss: 0.6882162615960958
Epoch: 51 | Iteration number: [500/565] 88% | Training loss: 0.688182389497757
Epoch: 51 | Iteration number: [510/565] 90% | Training loss: 0.6881589766810922
Epoch: 51 | Iteration number: [520/565] 92% | Training loss: 0.6881340351242285
Epoch: 51 | Iteration number: [530/565] 93% | Training loss: 0.6881115585003259
Epoch: 51 | Iteration number: [540/565] 95% | Training loss: 0.6880887665130474
Epoch: 51 | Iteration number: [550/565] 97% | Training loss: 0.6880686477097598
Epoch: 51 | Iteration number: [560/565] 99% | Training loss: 0.68804152192814

 End of epoch: 51 | Train Loss: 0.6868134486991747 | Training Time: 89 

 End of epoch: 51 | Eval Loss: 0.6902322939464024 | Evaluating Time: 5 
Epoch: 52 | Iteration number: [10/565] 1% | Training loss: 0.7555962145328522
Epoch: 52 | Iteration number: [20/565] 3% | Training loss: 0.7213505357503891
Epoch: 52 | Iteration number: [30/565] 5% | Training loss: 0.7100076476732889
Epoch: 52 | Iteration number: [40/565] 7% | Training loss: 0.7042025446891784
Epoch: 52 | Iteration number: [50/565] 8% | Training loss: 0.7006592953205109
Epoch: 52 | Iteration number: [60/565] 10% | Training loss: 0.6983691791693369
Epoch: 52 | Iteration number: [70/565] 12% | Training loss: 0.6967189167227064
Epoch: 52 | Iteration number: [80/565] 14% | Training loss: 0.6954530738294125
Epoch: 52 | Iteration number: [90/565] 15% | Training loss: 0.694408529996872
Epoch: 52 | Iteration number: [100/565] 17% | Training loss: 0.6937119174003601
Epoch: 52 | Iteration number: [110/565] 19% | Training loss: 0.693091484633359
Epoch: 52 | Iteration number: [120/565] 21% | Training loss: 0.6925760135054588
Epoch: 52 | Iteration number: [130/565] 23% | Training loss: 0.6921496212482452
Epoch: 52 | Iteration number: [140/565] 24% | Training loss: 0.6917775026389531
Epoch: 52 | Iteration number: [150/565] 26% | Training loss: 0.6914378607273102
Epoch: 52 | Iteration number: [160/565] 28% | Training loss: 0.6911760561168194
Epoch: 52 | Iteration number: [170/565] 30% | Training loss: 0.6908967554569244
Epoch: 52 | Iteration number: [180/565] 31% | Training loss: 0.6906608018610213
Epoch: 52 | Iteration number: [190/565] 33% | Training loss: 0.690476678860815
Epoch: 52 | Iteration number: [200/565] 35% | Training loss: 0.6902965182065963
Epoch: 52 | Iteration number: [210/565] 37% | Training loss: 0.6901136801356361
Epoch: 52 | Iteration number: [220/565] 38% | Training loss: 0.6899691237644716
Epoch: 52 | Iteration number: [230/565] 40% | Training loss: 0.6898561029330544
Epoch: 52 | Iteration number: [240/565] 42% | Training loss: 0.6897327214479446
Epoch: 52 | Iteration number: [250/565] 44% | Training loss: 0.6896196913719177
Epoch: 52 | Iteration number: [260/565] 46% | Training loss: 0.689508181810379
Epoch: 52 | Iteration number: [270/565] 47% | Training loss: 0.6893990704306849
Epoch: 52 | Iteration number: [280/565] 49% | Training loss: 0.6892887760485922
Epoch: 52 | Iteration number: [290/565] 51% | Training loss: 0.6891981568829767
Epoch: 52 | Iteration number: [300/565] 53% | Training loss: 0.6891269048055013
Epoch: 52 | Iteration number: [310/565] 54% | Training loss: 0.6890498245916059
Epoch: 52 | Iteration number: [320/565] 56% | Training loss: 0.6889819048345089
Epoch: 52 | Iteration number: [330/565] 58% | Training loss: 0.6889231430761742
Epoch: 52 | Iteration number: [340/565] 60% | Training loss: 0.688860870108885
Epoch: 52 | Iteration number: [350/565] 61% | Training loss: 0.6887904449871608
Epoch: 52 | Iteration number: [360/565] 63% | Training loss: 0.6887335868345367
Epoch: 52 | Iteration number: [370/565] 65% | Training loss: 0.6886806410712165
Epoch: 52 | Iteration number: [380/565] 67% | Training loss: 0.6886356488654488
Epoch: 52 | Iteration number: [390/565] 69% | Training loss: 0.6885855914690555
Epoch: 52 | Iteration number: [400/565] 70% | Training loss: 0.6885423722863198
Epoch: 52 | Iteration number: [410/565] 72% | Training loss: 0.6885151104229252
Epoch: 52 | Iteration number: [420/565] 74% | Training loss: 0.6884762058655421
Epoch: 52 | Iteration number: [430/565] 76% | Training loss: 0.6884321858716566
Epoch: 52 | Iteration number: [440/565] 77% | Training loss: 0.6883961422876879
Epoch: 52 | Iteration number: [450/565] 79% | Training loss: 0.6883500556151072
Epoch: 52 | Iteration number: [460/565] 81% | Training loss: 0.6883135260447212
Epoch: 52 | Iteration number: [470/565] 83% | Training loss: 0.6882790549004332
Epoch: 52 | Iteration number: [480/565] 84% | Training loss: 0.6882423332581917
Epoch: 52 | Iteration number: [490/565] 86% | Training loss: 0.6882138617184698
Epoch: 52 | Iteration number: [500/565] 88% | Training loss: 0.6881878544092178
Epoch: 52 | Iteration number: [510/565] 90% | Training loss: 0.6881662684328416
Epoch: 52 | Iteration number: [520/565] 92% | Training loss: 0.6881362638794459
Epoch: 52 | Iteration number: [530/565] 93% | Training loss: 0.6881158700529134
Epoch: 52 | Iteration number: [540/565] 95% | Training loss: 0.6880835231807497
Epoch: 52 | Iteration number: [550/565] 97% | Training loss: 0.6880615130337802
Epoch: 52 | Iteration number: [560/565] 99% | Training loss: 0.6880380182393959

 End of epoch: 52 | Train Loss: 0.6868149956770703 | Training Time: 90 

 End of epoch: 52 | Eval Loss: 0.6899000746863229 | Evaluating Time: 6 
Epoch: 53 | Iteration number: [10/565] 1% | Training loss: 0.7551460981369018
Epoch: 53 | Iteration number: [20/565] 3% | Training loss: 0.7206383883953095
Epoch: 53 | Iteration number: [30/565] 5% | Training loss: 0.7093357384204865
Epoch: 53 | Iteration number: [40/565] 7% | Training loss: 0.7035922318696975
Epoch: 53 | Iteration number: [50/565] 8% | Training loss: 0.7002512180805206
Epoch: 53 | Iteration number: [60/565] 10% | Training loss: 0.6981089462836584
Epoch: 53 | Iteration number: [70/565] 12% | Training loss: 0.6964784264564514
Epoch: 53 | Iteration number: [80/565] 14% | Training loss: 0.6951909922063351
Epoch: 53 | Iteration number: [90/565] 15% | Training loss: 0.6942447119288975
Epoch: 53 | Iteration number: [100/565] 17% | Training loss: 0.6934766262769699
Epoch: 53 | Iteration number: [110/565] 19% | Training loss: 0.692912296815352
Epoch: 53 | Iteration number: [120/565] 21% | Training loss: 0.6924257462223371
Epoch: 53 | Iteration number: [130/565] 23% | Training loss: 0.691977738417112
Epoch: 53 | Iteration number: [140/565] 24% | Training loss: 0.6916285859686988
Epoch: 53 | Iteration number: [150/565] 26% | Training loss: 0.6913407659530639
Epoch: 53 | Iteration number: [160/565] 28% | Training loss: 0.6910733141005039
Epoch: 53 | Iteration number: [170/565] 30% | Training loss: 0.6908025310320013
Epoch: 53 | Iteration number: [180/565] 31% | Training loss: 0.6905804316202799
Epoch: 53 | Iteration number: [190/565] 33% | Training loss: 0.6903838819579075
Epoch: 53 | Iteration number: [200/565] 35% | Training loss: 0.6902047434449196
Epoch: 53 | Iteration number: [210/565] 37% | Training loss: 0.6900626472064427
Epoch: 53 | Iteration number: [220/565] 38% | Training loss: 0.6899193403395739
Epoch: 53 | Iteration number: [230/565] 40% | Training loss: 0.6897882111694502
Epoch: 53 | Iteration number: [240/565] 42% | Training loss: 0.6896623641252517
Epoch: 53 | Iteration number: [250/565] 44% | Training loss: 0.6895298428535461
Epoch: 53 | Iteration number: [260/565] 46% | Training loss: 0.6894064245315699
Epoch: 53 | Iteration number: [270/565] 47% | Training loss: 0.6892990624463117
Epoch: 53 | Iteration number: [280/565] 49% | Training loss: 0.6892309923257146
Epoch: 53 | Iteration number: [290/565] 51% | Training loss: 0.6891559598774746
Epoch: 53 | Iteration number: [300/565] 53% | Training loss: 0.6890786161025365
Epoch: 53 | Iteration number: [310/565] 54% | Training loss: 0.6889988768485285
Epoch: 53 | Iteration number: [320/565] 56% | Training loss: 0.6889365289360285
Epoch: 53 | Iteration number: [330/565] 58% | Training loss: 0.6888706041104866
Epoch: 53 | Iteration number: [340/565] 60% | Training loss: 0.6888194492634605
Epoch: 53 | Iteration number: [350/565] 61% | Training loss: 0.688756674698421
Epoch: 53 | Iteration number: [360/565] 63% | Training loss: 0.6887032426065869
Epoch: 53 | Iteration number: [370/565] 65% | Training loss: 0.6886499944570902
Epoch: 53 | Iteration number: [380/565] 67% | Training loss: 0.6885994685323615
Epoch: 53 | Iteration number: [390/565] 69% | Training loss: 0.6885619139059996
Epoch: 53 | Iteration number: [400/565] 70% | Training loss: 0.6885213249921799
Epoch: 53 | Iteration number: [410/565] 72% | Training loss: 0.6884779070935598
Epoch: 53 | Iteration number: [420/565] 74% | Training loss: 0.6884330792086465
Epoch: 53 | Iteration number: [430/565] 76% | Training loss: 0.6884009559487188
Epoch: 53 | Iteration number: [440/565] 77% | Training loss: 0.688393231278116
Epoch: 53 | Iteration number: [450/565] 79% | Training loss: 0.6883655381202698
Epoch: 53 | Iteration number: [460/565] 81% | Training loss: 0.6883367743181146
Epoch: 53 | Iteration number: [470/565] 83% | Training loss: 0.6883126535314195
Epoch: 53 | Iteration number: [480/565] 84% | Training loss: 0.6882911209017039
Epoch: 53 | Iteration number: [490/565] 86% | Training loss: 0.6882620850387885
Epoch: 53 | Iteration number: [500/565] 88% | Training loss: 0.6882262089252472
Epoch: 53 | Iteration number: [510/565] 90% | Training loss: 0.6882036965267331
Epoch: 53 | Iteration number: [520/565] 92% | Training loss: 0.6881785456950847
Epoch: 53 | Iteration number: [530/565] 93% | Training loss: 0.688154843055977
Epoch: 53 | Iteration number: [540/565] 95% | Training loss: 0.6881327688694
Epoch: 53 | Iteration number: [550/565] 97% | Training loss: 0.6881080443208868
Epoch: 53 | Iteration number: [560/565] 99% | Training loss: 0.6880822770297528

 End of epoch: 53 | Train Loss: 0.6868546886781676 | Training Time: 89 

 End of epoch: 53 | Eval Loss: 0.6901867645127433 | Evaluating Time: 6 
Epoch: 54 | Iteration number: [10/565] 1% | Training loss: 0.7558542966842652
Epoch: 54 | Iteration number: [20/565] 3% | Training loss: 0.7214084327220917
Epoch: 54 | Iteration number: [30/565] 5% | Training loss: 0.7098180015881856
Epoch: 54 | Iteration number: [40/565] 7% | Training loss: 0.7039656892418862
Epoch: 54 | Iteration number: [50/565] 8% | Training loss: 0.7005470633506775
Epoch: 54 | Iteration number: [60/565] 10% | Training loss: 0.6982751786708832
Epoch: 54 | Iteration number: [70/565] 12% | Training loss: 0.6965959770338875
Epoch: 54 | Iteration number: [80/565] 14% | Training loss: 0.6954254537820816
Epoch: 54 | Iteration number: [90/565] 15% | Training loss: 0.6945127778583102
Epoch: 54 | Iteration number: [100/565] 17% | Training loss: 0.6937488329410553
Epoch: 54 | Iteration number: [110/565] 19% | Training loss: 0.6930937046354467
Epoch: 54 | Iteration number: [120/565] 21% | Training loss: 0.692549034456412
Epoch: 54 | Iteration number: [130/565] 23% | Training loss: 0.6921093752750984
Epoch: 54 | Iteration number: [140/565] 24% | Training loss: 0.6917150838034494
Epoch: 54 | Iteration number: [150/565] 26% | Training loss: 0.6913818025588989
Epoch: 54 | Iteration number: [160/565] 28% | Training loss: 0.6911051604896784
Epoch: 54 | Iteration number: [170/565] 30% | Training loss: 0.6908650605117573
Epoch: 54 | Iteration number: [180/565] 31% | Training loss: 0.6906556540065342
Epoch: 54 | Iteration number: [190/565] 33% | Training loss: 0.690474881310212
Epoch: 54 | Iteration number: [200/565] 35% | Training loss: 0.6903152483701706
Epoch: 54 | Iteration number: [210/565] 37% | Training loss: 0.6901501627195449
Epoch: 54 | Iteration number: [220/565] 38% | Training loss: 0.6899709609421817
Epoch: 54 | Iteration number: [230/565] 40% | Training loss: 0.6898385949756788
Epoch: 54 | Iteration number: [240/565] 42% | Training loss: 0.6897118794421355
Epoch: 54 | Iteration number: [250/565] 44% | Training loss: 0.6896084175109863
Epoch: 54 | Iteration number: [260/565] 46% | Training loss: 0.6894873314178906
Epoch: 54 | Iteration number: [270/565] 47% | Training loss: 0.6893977787759569
Epoch: 54 | Iteration number: [280/565] 49% | Training loss: 0.6892979679363115
Epoch: 54 | Iteration number: [290/565] 51% | Training loss: 0.689197093042834
Epoch: 54 | Iteration number: [300/565] 53% | Training loss: 0.6891193699836731
Epoch: 54 | Iteration number: [310/565] 54% | Training loss: 0.6890494567732657
Epoch: 54 | Iteration number: [320/565] 56% | Training loss: 0.6889825358986854
Epoch: 54 | Iteration number: [330/565] 58% | Training loss: 0.688923784458276
Epoch: 54 | Iteration number: [340/565] 60% | Training loss: 0.6888618302695891
Epoch: 54 | Iteration number: [350/565] 61% | Training loss: 0.6888074062551771
Epoch: 54 | Iteration number: [360/565] 63% | Training loss: 0.6887637338704533
Epoch: 54 | Iteration number: [370/565] 65% | Training loss: 0.6887056350708007
Epoch: 54 | Iteration number: [380/565] 67% | Training loss: 0.6886604202421088
Epoch: 54 | Iteration number: [390/565] 69% | Training loss: 0.688616925630814
Epoch: 54 | Iteration number: [400/565] 70% | Training loss: 0.6885642196238041
Epoch: 54 | Iteration number: [410/565] 72% | Training loss: 0.6885051097811722
Epoch: 54 | Iteration number: [420/565] 74% | Training loss: 0.6884580731391907
Epoch: 54 | Iteration number: [430/565] 76% | Training loss: 0.6884238593800124
Epoch: 54 | Iteration number: [440/565] 77% | Training loss: 0.6883927349339832
Epoch: 54 | Iteration number: [450/565] 79% | Training loss: 0.6883468519316779
Epoch: 54 | Iteration number: [460/565] 81% | Training loss: 0.6883104065190191
Epoch: 54 | Iteration number: [470/565] 83% | Training loss: 0.6882740104452093
Epoch: 54 | Iteration number: [480/565] 84% | Training loss: 0.6882408985247215
Epoch: 54 | Iteration number: [490/565] 86% | Training loss: 0.6882156648197952
Epoch: 54 | Iteration number: [500/565] 88% | Training loss: 0.6881846883296967
Epoch: 54 | Iteration number: [510/565] 90% | Training loss: 0.6881660440388848
Epoch: 54 | Iteration number: [520/565] 92% | Training loss: 0.6881424310115668
Epoch: 54 | Iteration number: [530/565] 93% | Training loss: 0.6881268854411143
Epoch: 54 | Iteration number: [540/565] 95% | Training loss: 0.6881056929076159
Epoch: 54 | Iteration number: [550/565] 97% | Training loss: 0.6880835948207161
Epoch: 54 | Iteration number: [560/565] 99% | Training loss: 0.6880594548370157

 End of epoch: 54 | Train Loss: 0.6868299453659396 | Training Time: 90 

 End of epoch: 54 | Eval Loss: 0.6900181429726737 | Evaluating Time: 6 
Epoch: 55 | Iteration number: [10/565] 1% | Training loss: 0.755623334646225
Epoch: 55 | Iteration number: [20/565] 3% | Training loss: 0.7211863458156585
Epoch: 55 | Iteration number: [30/565] 5% | Training loss: 0.7098441104094187
Epoch: 55 | Iteration number: [40/565] 7% | Training loss: 0.7040930256247521
Epoch: 55 | Iteration number: [50/565] 8% | Training loss: 0.700611276626587
Epoch: 55 | Iteration number: [60/565] 10% | Training loss: 0.6983613590399425
Epoch: 55 | Iteration number: [70/565] 12% | Training loss: 0.6967073730060033
Epoch: 55 | Iteration number: [80/565] 14% | Training loss: 0.6954828672111034
Epoch: 55 | Iteration number: [90/565] 15% | Training loss: 0.6945221934053633
Epoch: 55 | Iteration number: [100/565] 17% | Training loss: 0.6937699264287949
Epoch: 55 | Iteration number: [110/565] 19% | Training loss: 0.6931241739879955
Epoch: 55 | Iteration number: [120/565] 21% | Training loss: 0.6926013792554537
Epoch: 55 | Iteration number: [130/565] 23% | Training loss: 0.6921326971971071
Epoch: 55 | Iteration number: [140/565] 24% | Training loss: 0.6917211702891759
Epoch: 55 | Iteration number: [150/565] 26% | Training loss: 0.6913941633701325
Epoch: 55 | Iteration number: [160/565] 28% | Training loss: 0.6910939551889896
Epoch: 55 | Iteration number: [170/565] 30% | Training loss: 0.6908433486433591
Epoch: 55 | Iteration number: [180/565] 31% | Training loss: 0.6906252645783955
Epoch: 55 | Iteration number: [190/565] 33% | Training loss: 0.6904478217426099
Epoch: 55 | Iteration number: [200/565] 35% | Training loss: 0.6902686604857444
Epoch: 55 | Iteration number: [210/565] 37% | Training loss: 0.690091495003019
Epoch: 55 | Iteration number: [220/565] 38% | Training loss: 0.6899355771866712
Epoch: 55 | Iteration number: [230/565] 40% | Training loss: 0.689776880585629
Epoch: 55 | Iteration number: [240/565] 42% | Training loss: 0.6896462050577005
Epoch: 55 | Iteration number: [250/565] 44% | Training loss: 0.6895290071964264
Epoch: 55 | Iteration number: [260/565] 46% | Training loss: 0.689424920311341
Epoch: 55 | Iteration number: [270/565] 47% | Training loss: 0.6893229268215321
Epoch: 55 | Iteration number: [280/565] 49% | Training loss: 0.6892282009124756
Epoch: 55 | Iteration number: [290/565] 51% | Training loss: 0.6891506647241527
Epoch: 55 | Iteration number: [300/565] 53% | Training loss: 0.6890663462877273
Epoch: 55 | Iteration number: [310/565] 54% | Training loss: 0.6889933268870077
Epoch: 55 | Iteration number: [320/565] 56% | Training loss: 0.6889347551390529
Epoch: 55 | Iteration number: [330/565] 58% | Training loss: 0.6888647489475481
Epoch: 55 | Iteration number: [340/565] 60% | Training loss: 0.6888011511634378
Epoch: 55 | Iteration number: [350/565] 61% | Training loss: 0.6887474891117641
Epoch: 55 | Iteration number: [360/565] 63% | Training loss: 0.6886934689349599
Epoch: 55 | Iteration number: [370/565] 65% | Training loss: 0.6886427607085254
Epoch: 55 | Iteration number: [380/565] 67% | Training loss: 0.6885922593505759
Epoch: 55 | Iteration number: [390/565] 69% | Training loss: 0.6885427947227771
Epoch: 55 | Iteration number: [400/565] 70% | Training loss: 0.6885043819248676
Epoch: 55 | Iteration number: [410/565] 72% | Training loss: 0.6884727595782861
Epoch: 55 | Iteration number: [420/565] 74% | Training loss: 0.6884416622774941
Epoch: 55 | Iteration number: [430/565] 76% | Training loss: 0.6883948278981585
Epoch: 55 | Iteration number: [440/565] 77% | Training loss: 0.6883632493290034
Epoch: 55 | Iteration number: [450/565] 79% | Training loss: 0.688326840268241
Epoch: 55 | Iteration number: [460/565] 81% | Training loss: 0.6882978230714798
Epoch: 55 | Iteration number: [470/565] 83% | Training loss: 0.688277075518953
Epoch: 55 | Iteration number: [480/565] 84% | Training loss: 0.6882472009708483
Epoch: 55 | Iteration number: [490/565] 86% | Training loss: 0.688220808335713
Epoch: 55 | Iteration number: [500/565] 88% | Training loss: 0.6881971856355668
Epoch: 55 | Iteration number: [510/565] 90% | Training loss: 0.688170759935005
Epoch: 55 | Iteration number: [520/565] 92% | Training loss: 0.688150566128584
Epoch: 55 | Iteration number: [530/565] 93% | Training loss: 0.6881232644027134
Epoch: 55 | Iteration number: [540/565] 95% | Training loss: 0.6880966182108279
Epoch: 55 | Iteration number: [550/565] 97% | Training loss: 0.6880679906498303
Epoch: 55 | Iteration number: [560/565] 99% | Training loss: 0.6880407381270613

 End of epoch: 55 | Train Loss: 0.6868120319020432 | Training Time: 88 

 End of epoch: 55 | Eval Loss: 0.6896973507744926 | Evaluating Time: 6 
Epoch: 56 | Iteration number: [10/565] 1% | Training loss: 0.7556226372718811
Epoch: 56 | Iteration number: [20/565] 3% | Training loss: 0.7211299151182174
Epoch: 56 | Iteration number: [30/565] 5% | Training loss: 0.7096689065297445
Epoch: 56 | Iteration number: [40/565] 7% | Training loss: 0.7038847029209137
Epoch: 56 | Iteration number: [50/565] 8% | Training loss: 0.7005000615119934
Epoch: 56 | Iteration number: [60/565] 10% | Training loss: 0.698216050863266
Epoch: 56 | Iteration number: [70/565] 12% | Training loss: 0.6965979823044368
Epoch: 56 | Iteration number: [80/565] 14% | Training loss: 0.6953810572624206
Epoch: 56 | Iteration number: [90/565] 15% | Training loss: 0.6944556030962202
Epoch: 56 | Iteration number: [100/565] 17% | Training loss: 0.6936736780405045
Epoch: 56 | Iteration number: [110/565] 19% | Training loss: 0.6930724723772569
Epoch: 56 | Iteration number: [120/565] 21% | Training loss: 0.692536457379659
Epoch: 56 | Iteration number: [130/565] 23% | Training loss: 0.6920801419478196
Epoch: 56 | Iteration number: [140/565] 24% | Training loss: 0.6917240249259131
Epoch: 56 | Iteration number: [150/565] 26% | Training loss: 0.6913951953252157
Epoch: 56 | Iteration number: [160/565] 28% | Training loss: 0.6911109335720539
Epoch: 56 | Iteration number: [170/565] 30% | Training loss: 0.6908846946323619
Epoch: 56 | Iteration number: [180/565] 31% | Training loss: 0.6906659424304962
Epoch: 56 | Iteration number: [190/565] 33% | Training loss: 0.6904444590995186
Epoch: 56 | Iteration number: [200/565] 35% | Training loss: 0.6902436950802803
Epoch: 56 | Iteration number: [210/565] 37% | Training loss: 0.6900854178837368
Epoch: 56 | Iteration number: [220/565] 38% | Training loss: 0.6899319239638069
Epoch: 56 | Iteration number: [230/565] 40% | Training loss: 0.6898002865521804
Epoch: 56 | Iteration number: [240/565] 42% | Training loss: 0.6896727085113525
Epoch: 56 | Iteration number: [250/565] 44% | Training loss: 0.6895574679374695
Epoch: 56 | Iteration number: [260/565] 46% | Training loss: 0.6894688892822999
Epoch: 56 | Iteration number: [270/565] 47% | Training loss: 0.6893711496282506
Epoch: 56 | Iteration number: [280/565] 49% | Training loss: 0.6892746261187962
Epoch: 56 | Iteration number: [290/565] 51% | Training loss: 0.6891706916792639
Epoch: 56 | Iteration number: [300/565] 53% | Training loss: 0.6890763986110687
Epoch: 56 | Iteration number: [310/565] 54% | Training loss: 0.6889994107907819
Epoch: 56 | Iteration number: [320/565] 56% | Training loss: 0.6889289857819676
Epoch: 56 | Iteration number: [330/565] 58% | Training loss: 0.688852931875171
Epoch: 56 | Iteration number: [340/565] 60% | Training loss: 0.6887910527341506
Epoch: 56 | Iteration number: [350/565] 61% | Training loss: 0.6887389026369367
Epoch: 56 | Iteration number: [360/565] 63% | Training loss: 0.6886748428146044
Epoch: 56 | Iteration number: [370/565] 65% | Training loss: 0.6886255072580801
Epoch: 56 | Iteration number: [380/565] 67% | Training loss: 0.6885874464323646
Epoch: 56 | Iteration number: [390/565] 69% | Training loss: 0.6885455438723931
Epoch: 56 | Iteration number: [400/565] 70% | Training loss: 0.6884999230504036
Epoch: 56 | Iteration number: [410/565] 72% | Training loss: 0.6884661908556775
Epoch: 56 | Iteration number: [420/565] 74% | Training loss: 0.688446581363678
Epoch: 56 | Iteration number: [430/565] 76% | Training loss: 0.6884106458619583
Epoch: 56 | Iteration number: [440/565] 77% | Training loss: 0.6883670350367372
Epoch: 56 | Iteration number: [450/565] 79% | Training loss: 0.6883329623275333
Epoch: 56 | Iteration number: [460/565] 81% | Training loss: 0.6882907302483269
Epoch: 56 | Iteration number: [470/565] 83% | Training loss: 0.688254110483413
Epoch: 56 | Iteration number: [480/565] 84% | Training loss: 0.6882171085725228
Epoch: 56 | Iteration number: [490/565] 86% | Training loss: 0.6881899102609985
Epoch: 56 | Iteration number: [500/565] 88% | Training loss: 0.6881650141477584
Epoch: 56 | Iteration number: [510/565] 90% | Training loss: 0.6881394497319764
Epoch: 56 | Iteration number: [520/565] 92% | Training loss: 0.6881154453525177
Epoch: 56 | Iteration number: [530/565] 93% | Training loss: 0.6881016231932731
Epoch: 56 | Iteration number: [540/565] 95% | Training loss: 0.6880815828288043
Epoch: 56 | Iteration number: [550/565] 97% | Training loss: 0.6880551961335268
Epoch: 56 | Iteration number: [560/565] 99% | Training loss: 0.6880283440862384

 End of epoch: 56 | Train Loss: 0.6868020423745687 | Training Time: 89 

 End of epoch: 56 | Eval Loss: 0.6897893037114825 | Evaluating Time: 6 
Epoch: 57 | Iteration number: [10/565] 1% | Training loss: 0.7551980078220367
Epoch: 57 | Iteration number: [20/565] 3% | Training loss: 0.7210691630840301
Epoch: 57 | Iteration number: [30/565] 5% | Training loss: 0.709567109743754
Epoch: 57 | Iteration number: [40/565] 7% | Training loss: 0.7038626462221146
Epoch: 57 | Iteration number: [50/565] 8% | Training loss: 0.7003676605224609
Epoch: 57 | Iteration number: [60/565] 10% | Training loss: 0.6982101142406464
Epoch: 57 | Iteration number: [70/565] 12% | Training loss: 0.6966592184134892
Epoch: 57 | Iteration number: [80/565] 14% | Training loss: 0.695433384180069
Epoch: 57 | Iteration number: [90/565] 15% | Training loss: 0.6945044451289707
Epoch: 57 | Iteration number: [100/565] 17% | Training loss: 0.6937325721979142
Epoch: 57 | Iteration number: [110/565] 19% | Training loss: 0.6931025916879827
Epoch: 57 | Iteration number: [120/565] 21% | Training loss: 0.6925577183564504
Epoch: 57 | Iteration number: [130/565] 23% | Training loss: 0.6920932471752167
Epoch: 57 | Iteration number: [140/565] 24% | Training loss: 0.691719406417438
Epoch: 57 | Iteration number: [150/565] 26% | Training loss: 0.6913925965627035
Epoch: 57 | Iteration number: [160/565] 28% | Training loss: 0.6911315213888883
Epoch: 57 | Iteration number: [170/565] 30% | Training loss: 0.6908810906550463
Epoch: 57 | Iteration number: [180/565] 31% | Training loss: 0.6906529506047566
Epoch: 57 | Iteration number: [190/565] 33% | Training loss: 0.6904503643512726
Epoch: 57 | Iteration number: [200/565] 35% | Training loss: 0.6902445638179779
Epoch: 57 | Iteration number: [210/565] 37% | Training loss: 0.6900743036043077
Epoch: 57 | Iteration number: [220/565] 38% | Training loss: 0.6899071108211171
Epoch: 57 | Iteration number: [230/565] 40% | Training loss: 0.6897796750068664
Epoch: 57 | Iteration number: [240/565] 42% | Training loss: 0.6896734689672788
Epoch: 57 | Iteration number: [250/565] 44% | Training loss: 0.6895446715354919
Epoch: 57 | Iteration number: [260/565] 46% | Training loss: 0.6894559452166924
Epoch: 57 | Iteration number: [270/565] 47% | Training loss: 0.6893539298463751
Epoch: 57 | Iteration number: [280/565] 49% | Training loss: 0.6892730874674661
Epoch: 57 | Iteration number: [290/565] 51% | Training loss: 0.6891768989891841
Epoch: 57 | Iteration number: [300/565] 53% | Training loss: 0.689093227982521
Epoch: 57 | Iteration number: [310/565] 54% | Training loss: 0.6890208792301916
Epoch: 57 | Iteration number: [320/565] 56% | Training loss: 0.6889569863677025
Epoch: 57 | Iteration number: [330/565] 58% | Training loss: 0.6888886307225083
Epoch: 57 | Iteration number: [340/565] 60% | Training loss: 0.6888260574901806
Epoch: 57 | Iteration number: [350/565] 61% | Training loss: 0.6887610348633357
Epoch: 57 | Iteration number: [360/565] 63% | Training loss: 0.6887116177214516
Epoch: 57 | Iteration number: [370/565] 65% | Training loss: 0.6886602429119316
Epoch: 57 | Iteration number: [380/565] 67% | Training loss: 0.6886179103663094
Epoch: 57 | Iteration number: [390/565] 69% | Training loss: 0.6885545606796558
Epoch: 57 | Iteration number: [400/565] 70% | Training loss: 0.688508536964655
Epoch: 57 | Iteration number: [410/565] 72% | Training loss: 0.6884706363445375
Epoch: 57 | Iteration number: [420/565] 74% | Training loss: 0.6884309738874436
Epoch: 57 | Iteration number: [430/565] 76% | Training loss: 0.6883940581665483
Epoch: 57 | Iteration number: [440/565] 77% | Training loss: 0.6883611857891083
Epoch: 57 | Iteration number: [450/565] 79% | Training loss: 0.6883286011219024
Epoch: 57 | Iteration number: [460/565] 81% | Training loss: 0.6882947694996129
Epoch: 57 | Iteration number: [470/565] 83% | Training loss: 0.6882564955569328
Epoch: 57 | Iteration number: [480/565] 84% | Training loss: 0.6882338713854551
Epoch: 57 | Iteration number: [490/565] 86% | Training loss: 0.6882103163368848
Epoch: 57 | Iteration number: [500/565] 88% | Training loss: 0.6881793351173401
Epoch: 57 | Iteration number: [510/565] 90% | Training loss: 0.688144646322026
Epoch: 57 | Iteration number: [520/565] 92% | Training loss: 0.6881184982565733
Epoch: 57 | Iteration number: [530/565] 93% | Training loss: 0.6880947460543435
Epoch: 57 | Iteration number: [540/565] 95% | Training loss: 0.6880625934512526
Epoch: 57 | Iteration number: [550/565] 97% | Training loss: 0.688041916327043
Epoch: 57 | Iteration number: [560/565] 99% | Training loss: 0.6880254114312785

 End of epoch: 57 | Train Loss: 0.6867996539689798 | Training Time: 88 

 End of epoch: 57 | Eval Loss: 0.6902034963880267 | Evaluating Time: 6 
Epoch: 58 | Iteration number: [10/565] 1% | Training loss: 0.7553749322891236
Epoch: 58 | Iteration number: [20/565] 3% | Training loss: 0.7211930096149445
Epoch: 58 | Iteration number: [30/565] 5% | Training loss: 0.7097397983074188
Epoch: 58 | Iteration number: [40/565] 7% | Training loss: 0.7040025442838669
Epoch: 58 | Iteration number: [50/565] 8% | Training loss: 0.7006229817867279
Epoch: 58 | Iteration number: [60/565] 10% | Training loss: 0.6983732004960378
Epoch: 58 | Iteration number: [70/565] 12% | Training loss: 0.6967548762048994
Epoch: 58 | Iteration number: [80/565] 14% | Training loss: 0.6955156490206719
Epoch: 58 | Iteration number: [90/565] 15% | Training loss: 0.6945500493049621
Epoch: 58 | Iteration number: [100/565] 17% | Training loss: 0.6938113832473755
Epoch: 58 | Iteration number: [110/565] 19% | Training loss: 0.6931723193688826
Epoch: 58 | Iteration number: [120/565] 21% | Training loss: 0.6926580781737963
Epoch: 58 | Iteration number: [130/565] 23% | Training loss: 0.6922157622300662
Epoch: 58 | Iteration number: [140/565] 24% | Training loss: 0.6918418909822192
Epoch: 58 | Iteration number: [150/565] 26% | Training loss: 0.6915091772874197
Epoch: 58 | Iteration number: [160/565] 28% | Training loss: 0.6912347722798586
Epoch: 58 | Iteration number: [170/565] 30% | Training loss: 0.6909710929674261
Epoch: 58 | Iteration number: [180/565] 31% | Training loss: 0.6907143738534716
Epoch: 58 | Iteration number: [190/565] 33% | Training loss: 0.690490588388945
Epoch: 58 | Iteration number: [200/565] 35% | Training loss: 0.6903101986646653
Epoch: 58 | Iteration number: [210/565] 37% | Training loss: 0.6901371754351117
Epoch: 58 | Iteration number: [220/565] 38% | Training loss: 0.6899986464868892
Epoch: 58 | Iteration number: [230/565] 40% | Training loss: 0.689864373466243
Epoch: 58 | Iteration number: [240/565] 42% | Training loss: 0.6897334059079488
Epoch: 58 | Iteration number: [250/565] 44% | Training loss: 0.6896099467277527
Epoch: 58 | Iteration number: [260/565] 46% | Training loss: 0.6895070399229343
Epoch: 58 | Iteration number: [270/565] 47% | Training loss: 0.689392352324945
Epoch: 58 | Iteration number: [280/565] 49% | Training loss: 0.6893040397337504
Epoch: 58 | Iteration number: [290/565] 51% | Training loss: 0.6892169099429558
Epoch: 58 | Iteration number: [300/565] 53% | Training loss: 0.6891475355625153
Epoch: 58 | Iteration number: [310/565] 54% | Training loss: 0.6890634088746963
Epoch: 58 | Iteration number: [320/565] 56% | Training loss: 0.688996791653335
Epoch: 58 | Iteration number: [330/565] 58% | Training loss: 0.6889101082628424
Epoch: 58 | Iteration number: [340/565] 60% | Training loss: 0.6888397527091643
Epoch: 58 | Iteration number: [350/565] 61% | Training loss: 0.6887896568434579
Epoch: 58 | Iteration number: [360/565] 63% | Training loss: 0.6887385994195938
Epoch: 58 | Iteration number: [370/565] 65% | Training loss: 0.6886690930740254
Epoch: 58 | Iteration number: [380/565] 67% | Training loss: 0.688613213990864
Epoch: 58 | Iteration number: [390/565] 69% | Training loss: 0.6885556135422144
Epoch: 58 | Iteration number: [400/565] 70% | Training loss: 0.6885015672445297
Epoch: 58 | Iteration number: [410/565] 72% | Training loss: 0.6884686676467338
Epoch: 58 | Iteration number: [420/565] 74% | Training loss: 0.6884185016155243
Epoch: 58 | Iteration number: [430/565] 76% | Training loss: 0.6883871183838955
Epoch: 58 | Iteration number: [440/565] 77% | Training loss: 0.6883420843969692
Epoch: 58 | Iteration number: [450/565] 79% | Training loss: 0.6883150989479488
Epoch: 58 | Iteration number: [460/565] 81% | Training loss: 0.6882904812045719
Epoch: 58 | Iteration number: [470/565] 83% | Training loss: 0.6882615703217527
Epoch: 58 | Iteration number: [480/565] 84% | Training loss: 0.6882322680205106
Epoch: 58 | Iteration number: [490/565] 86% | Training loss: 0.6882069815178307
Epoch: 58 | Iteration number: [500/565] 88% | Training loss: 0.6881876834630967
Epoch: 58 | Iteration number: [510/565] 90% | Training loss: 0.6881489259355208
Epoch: 58 | Iteration number: [520/565] 92% | Training loss: 0.6881299163286503
Epoch: 58 | Iteration number: [530/565] 93% | Training loss: 0.6881035678791549
Epoch: 58 | Iteration number: [540/565] 95% | Training loss: 0.6880817061221158
Epoch: 58 | Iteration number: [550/565] 97% | Training loss: 0.6880636274814605
Epoch: 58 | Iteration number: [560/565] 99% | Training loss: 0.6880486022148814

 End of epoch: 58 | Train Loss: 0.6868177621765474 | Training Time: 89 

 End of epoch: 58 | Eval Loss: 0.6891940576689584 | Evaluating Time: 6 
Epoch: 59 | Iteration number: [10/565] 1% | Training loss: 0.7551022291183471
Epoch: 59 | Iteration number: [20/565] 3% | Training loss: 0.720977982878685
Epoch: 59 | Iteration number: [30/565] 5% | Training loss: 0.7095936059951782
Epoch: 59 | Iteration number: [40/565] 7% | Training loss: 0.7038703367114068
Epoch: 59 | Iteration number: [50/565] 8% | Training loss: 0.7004739916324616
Epoch: 59 | Iteration number: [60/565] 10% | Training loss: 0.6982476224501928
Epoch: 59 | Iteration number: [70/565] 12% | Training loss: 0.6966720002038138
Epoch: 59 | Iteration number: [80/565] 14% | Training loss: 0.695438240468502
Epoch: 59 | Iteration number: [90/565] 15% | Training loss: 0.6944874929057228
Epoch: 59 | Iteration number: [100/565] 17% | Training loss: 0.693746742606163
Epoch: 59 | Iteration number: [110/565] 19% | Training loss: 0.6930897523056377
Epoch: 59 | Iteration number: [120/565] 21% | Training loss: 0.6925759295622508
Epoch: 59 | Iteration number: [130/565] 23% | Training loss: 0.6921180211580716
Epoch: 59 | Iteration number: [140/565] 24% | Training loss: 0.6917240815503257
Epoch: 59 | Iteration number: [150/565] 26% | Training loss: 0.6914055097103119
Epoch: 59 | Iteration number: [160/565] 28% | Training loss: 0.6911348327994347
Epoch: 59 | Iteration number: [170/565] 30% | Training loss: 0.6908814707223107
Epoch: 59 | Iteration number: [180/565] 31% | Training loss: 0.6906300018231074
Epoch: 59 | Iteration number: [190/565] 33% | Training loss: 0.6904182713282736
Epoch: 59 | Iteration number: [200/565] 35% | Training loss: 0.6902152484655381
Epoch: 59 | Iteration number: [210/565] 37% | Training loss: 0.6900474338304429
Epoch: 59 | Iteration number: [220/565] 38% | Training loss: 0.6899032950401306
Epoch: 59 | Iteration number: [230/565] 40% | Training loss: 0.6897609244222226
Epoch: 59 | Iteration number: [240/565] 42% | Training loss: 0.6896257154643536
Epoch: 59 | Iteration number: [250/565] 44% | Training loss: 0.6894987127780914
Epoch: 59 | Iteration number: [260/565] 46% | Training loss: 0.6893885853198859
Epoch: 59 | Iteration number: [270/565] 47% | Training loss: 0.6892866064001013
Epoch: 59 | Iteration number: [280/565] 49% | Training loss: 0.6892028274280685
Epoch: 59 | Iteration number: [290/565] 51% | Training loss: 0.6891183984690699
Epoch: 59 | Iteration number: [300/565] 53% | Training loss: 0.6890411567687988
Epoch: 59 | Iteration number: [310/565] 54% | Training loss: 0.6889762457339994
Epoch: 59 | Iteration number: [320/565] 56% | Training loss: 0.6889219608157873
Epoch: 59 | Iteration number: [330/565] 58% | Training loss: 0.6888609660394264
Epoch: 59 | Iteration number: [340/565] 60% | Training loss: 0.6888000360306572
Epoch: 59 | Iteration number: [350/565] 61% | Training loss: 0.6887621900013515
Epoch: 59 | Iteration number: [360/565] 63% | Training loss: 0.6887094934781393
Epoch: 59 | Iteration number: [370/565] 65% | Training loss: 0.6886549701561799
Epoch: 59 | Iteration number: [380/565] 67% | Training loss: 0.6885946098126863
Epoch: 59 | Iteration number: [390/565] 69% | Training loss: 0.6885580628346174
Epoch: 59 | Iteration number: [400/565] 70% | Training loss: 0.6885142254829407
Epoch: 59 | Iteration number: [410/565] 72% | Training loss: 0.6884773721055286
Epoch: 59 | Iteration number: [420/565] 74% | Training loss: 0.688433619198345
Epoch: 59 | Iteration number: [430/565] 76% | Training loss: 0.6883989049944766
Epoch: 59 | Iteration number: [440/565] 77% | Training loss: 0.6883594466881319
Epoch: 59 | Iteration number: [450/565] 79% | Training loss: 0.6883253480328454
Epoch: 59 | Iteration number: [460/565] 81% | Training loss: 0.6883010448321052
Epoch: 59 | Iteration number: [470/565] 83% | Training loss: 0.6882716909367987
Epoch: 59 | Iteration number: [480/565] 84% | Training loss: 0.6882432150344054
Epoch: 59 | Iteration number: [490/565] 86% | Training loss: 0.6882069339557569
Epoch: 59 | Iteration number: [500/565] 88% | Training loss: 0.6881768149137497
Epoch: 59 | Iteration number: [510/565] 90% | Training loss: 0.6881447467149473
Epoch: 59 | Iteration number: [520/565] 92% | Training loss: 0.6881264579983858
Epoch: 59 | Iteration number: [530/565] 93% | Training loss: 0.6881026777456392
Epoch: 59 | Iteration number: [540/565] 95% | Training loss: 0.6880790541569392
Epoch: 59 | Iteration number: [550/565] 97% | Training loss: 0.6880482050505552
Epoch: 59 | Iteration number: [560/565] 99% | Training loss: 0.6880296692252159

 End of epoch: 59 | Train Loss: 0.6868022130653921 | Training Time: 90 

 End of epoch: 59 | Eval Loss: 0.6899323889187404 | Evaluating Time: 6 
Epoch: 60 | Iteration number: [10/565] 1% | Training loss: 0.7557576119899749
Epoch: 60 | Iteration number: [20/565] 3% | Training loss: 0.7211569964885711
Epoch: 60 | Iteration number: [30/565] 5% | Training loss: 0.7098425924777985
Epoch: 60 | Iteration number: [40/565] 7% | Training loss: 0.7039075493812561
Epoch: 60 | Iteration number: [50/565] 8% | Training loss: 0.7004389607906342
Epoch: 60 | Iteration number: [60/565] 10% | Training loss: 0.6981229384740194
Epoch: 60 | Iteration number: [70/565] 12% | Training loss: 0.6964850868497576
Epoch: 60 | Iteration number: [80/565] 14% | Training loss: 0.695290657132864
Epoch: 60 | Iteration number: [90/565] 15% | Training loss: 0.6943829993406931
Epoch: 60 | Iteration number: [100/565] 17% | Training loss: 0.6936513042449951
Epoch: 60 | Iteration number: [110/565] 19% | Training loss: 0.6930575414137407
Epoch: 60 | Iteration number: [120/565] 21% | Training loss: 0.6925618315736453
Epoch: 60 | Iteration number: [130/565] 23% | Training loss: 0.6921010659291194
Epoch: 60 | Iteration number: [140/565] 24% | Training loss: 0.6917051179068429
Epoch: 60 | Iteration number: [150/565] 26% | Training loss: 0.6913842304547628
Epoch: 60 | Iteration number: [160/565] 28% | Training loss: 0.6910909321159124
Epoch: 60 | Iteration number: [170/565] 30% | Training loss: 0.6908368748777053
Epoch: 60 | Iteration number: [180/565] 31% | Training loss: 0.6906097044547399
Epoch: 60 | Iteration number: [190/565] 33% | Training loss: 0.6904165158146306
Epoch: 60 | Iteration number: [200/565] 35% | Training loss: 0.6902284240722656
Epoch: 60 | Iteration number: [210/565] 37% | Training loss: 0.6900758868172056
Epoch: 60 | Iteration number: [220/565] 38% | Training loss: 0.689924598552964
Epoch: 60 | Iteration number: [230/565] 40% | Training loss: 0.6897888116214587
Epoch: 60 | Iteration number: [240/565] 42% | Training loss: 0.6896727375686169
Epoch: 60 | Iteration number: [250/565] 44% | Training loss: 0.68956662774086
Epoch: 60 | Iteration number: [260/565] 46% | Training loss: 0.6894597477637805
Epoch: 60 | Iteration number: [270/565] 47% | Training loss: 0.6893687095907
Epoch: 60 | Iteration number: [280/565] 49% | Training loss: 0.6892821622746331
Epoch: 60 | Iteration number: [290/565] 51% | Training loss: 0.689195795305844
Epoch: 60 | Iteration number: [300/565] 53% | Training loss: 0.689101034005483
Epoch: 60 | Iteration number: [310/565] 54% | Training loss: 0.6890363306768479
Epoch: 60 | Iteration number: [320/565] 56% | Training loss: 0.6889760067686439
Epoch: 60 | Iteration number: [330/565] 58% | Training loss: 0.6889023999373118
Epoch: 60 | Iteration number: [340/565] 60% | Training loss: 0.6888163999599569
Epoch: 60 | Iteration number: [350/565] 61% | Training loss: 0.688759652035577
Epoch: 60 | Iteration number: [360/565] 63% | Training loss: 0.6887038297123379
Epoch: 60 | Iteration number: [370/565] 65% | Training loss: 0.6886509859884108
Epoch: 60 | Iteration number: [380/565] 67% | Training loss: 0.6886078178882599
Epoch: 60 | Iteration number: [390/565] 69% | Training loss: 0.6885582165840345
Epoch: 60 | Iteration number: [400/565] 70% | Training loss: 0.688528162240982
Epoch: 60 | Iteration number: [410/565] 72% | Training loss: 0.6884849340450473
Epoch: 60 | Iteration number: [420/565] 74% | Training loss: 0.6884486317634583
Epoch: 60 | Iteration number: [430/565] 76% | Training loss: 0.6884129902651144
Epoch: 60 | Iteration number: [440/565] 77% | Training loss: 0.68837214383212
Epoch: 60 | Iteration number: [450/565] 79% | Training loss: 0.6883394952615102
Epoch: 60 | Iteration number: [460/565] 81% | Training loss: 0.6883069112249043
Epoch: 60 | Iteration number: [470/565] 83% | Training loss: 0.6882848901951567
Epoch: 60 | Iteration number: [480/565] 84% | Training loss: 0.6882615243395169
Epoch: 60 | Iteration number: [490/565] 86% | Training loss: 0.6882338374244924
Epoch: 60 | Iteration number: [500/565] 88% | Training loss: 0.6882069144248962
Epoch: 60 | Iteration number: [510/565] 90% | Training loss: 0.6881709677331588
Epoch: 60 | Iteration number: [520/565] 92% | Training loss: 0.6881419917711845
Epoch: 60 | Iteration number: [530/565] 93% | Training loss: 0.6881139161451808
Epoch: 60 | Iteration number: [540/565] 95% | Training loss: 0.6880920393599405
Epoch: 60 | Iteration number: [550/565] 97% | Training loss: 0.6880702999505129
Epoch: 60 | Iteration number: [560/565] 99% | Training loss: 0.6880417073411601

 End of epoch: 60 | Train Loss: 0.6868162290184898 | Training Time: 89 

 End of epoch: 60 | Eval Loss: 0.6902209179741996 | Evaluating Time: 6 
Epoch: 61 | Iteration number: [10/565] 1% | Training loss: 0.7554348886013031
Epoch: 61 | Iteration number: [20/565] 3% | Training loss: 0.7211251765489578
Epoch: 61 | Iteration number: [30/565] 5% | Training loss: 0.7097536981105804
Epoch: 61 | Iteration number: [40/565] 7% | Training loss: 0.7040061190724373
Epoch: 61 | Iteration number: [50/565] 8% | Training loss: 0.7005152845382691
Epoch: 61 | Iteration number: [60/565] 10% | Training loss: 0.6982054422299068
Epoch: 61 | Iteration number: [70/565] 12% | Training loss: 0.6965303352900913
Epoch: 61 | Iteration number: [80/565] 14% | Training loss: 0.6953166723251343
Epoch: 61 | Iteration number: [90/565] 15% | Training loss: 0.6944597562154134
Epoch: 61 | Iteration number: [100/565] 17% | Training loss: 0.6936793303489686
Epoch: 61 | Iteration number: [110/565] 19% | Training loss: 0.6930894515731117
Epoch: 61 | Iteration number: [120/565] 21% | Training loss: 0.6925925721724828
Epoch: 61 | Iteration number: [130/565] 23% | Training loss: 0.6921186965245467
Epoch: 61 | Iteration number: [140/565] 24% | Training loss: 0.691736798627036
Epoch: 61 | Iteration number: [150/565] 26% | Training loss: 0.691378120581309
Epoch: 61 | Iteration number: [160/565] 28% | Training loss: 0.6910882513970137
Epoch: 61 | Iteration number: [170/565] 30% | Training loss: 0.6908311563379624
Epoch: 61 | Iteration number: [180/565] 31% | Training loss: 0.6906136708127127
Epoch: 61 | Iteration number: [190/565] 33% | Training loss: 0.6904055196987955
Epoch: 61 | Iteration number: [200/565] 35% | Training loss: 0.6902249637246132
Epoch: 61 | Iteration number: [210/565] 37% | Training loss: 0.690042544830413
Epoch: 61 | Iteration number: [220/565] 38% | Training loss: 0.6898948834701017
Epoch: 61 | Iteration number: [230/565] 40% | Training loss: 0.6897458452245463
Epoch: 61 | Iteration number: [240/565] 42% | Training loss: 0.6896492498616378
Epoch: 61 | Iteration number: [250/565] 44% | Training loss: 0.6895243139266968
Epoch: 61 | Iteration number: [260/565] 46% | Training loss: 0.6894165444832582
Epoch: 61 | Iteration number: [270/565] 47% | Training loss: 0.6893197081707142
Epoch: 61 | Iteration number: [280/565] 49% | Training loss: 0.6892303873385702
Epoch: 61 | Iteration number: [290/565] 51% | Training loss: 0.6891319079645749
Epoch: 61 | Iteration number: [300/565] 53% | Training loss: 0.6890497062603632
Epoch: 61 | Iteration number: [310/565] 54% | Training loss: 0.6889858217008652
Epoch: 61 | Iteration number: [320/565] 56% | Training loss: 0.6889206422492862
Epoch: 61 | Iteration number: [330/565] 58% | Training loss: 0.6888577192118673
Epoch: 61 | Iteration number: [340/565] 60% | Training loss: 0.6888025459121255
Epoch: 61 | Iteration number: [350/565] 61% | Training loss: 0.6887508007458278
Epoch: 61 | Iteration number: [360/565] 63% | Training loss: 0.6886949357059267
Epoch: 61 | Iteration number: [370/565] 65% | Training loss: 0.6886338050301011
Epoch: 61 | Iteration number: [380/565] 67% | Training loss: 0.6885823155704297
Epoch: 61 | Iteration number: [390/565] 69% | Training loss: 0.6885277405763284
Epoch: 61 | Iteration number: [400/565] 70% | Training loss: 0.6884882743656635
Epoch: 61 | Iteration number: [410/565] 72% | Training loss: 0.6884489156850955
Epoch: 61 | Iteration number: [420/565] 74% | Training loss: 0.6884128228539512
Epoch: 61 | Iteration number: [430/565] 76% | Training loss: 0.6883718863476155
Epoch: 61 | Iteration number: [440/565] 77% | Training loss: 0.688334345953031
Epoch: 61 | Iteration number: [450/565] 79% | Training loss: 0.688293480210834
Epoch: 61 | Iteration number: [460/565] 81% | Training loss: 0.6882778224737748
Epoch: 61 | Iteration number: [470/565] 83% | Training loss: 0.6882452742850527
Epoch: 61 | Iteration number: [480/565] 84% | Training loss: 0.6882221372177203
Epoch: 61 | Iteration number: [490/565] 86% | Training loss: 0.6881938000114597
Epoch: 61 | Iteration number: [500/565] 88% | Training loss: 0.6881644656658172
Epoch: 61 | Iteration number: [510/565] 90% | Training loss: 0.6881413735595404
Epoch: 61 | Iteration number: [520/565] 92% | Training loss: 0.6881102786614345
Epoch: 61 | Iteration number: [530/565] 93% | Training loss: 0.6880837249306013
Epoch: 61 | Iteration number: [540/565] 95% | Training loss: 0.6880689442157746
Epoch: 61 | Iteration number: [550/565] 97% | Training loss: 0.6880487569895658
Epoch: 61 | Iteration number: [560/565] 99% | Training loss: 0.6880274397986276

 End of epoch: 61 | Train Loss: 0.6867961696818866 | Training Time: 87 

 End of epoch: 61 | Eval Loss: 0.6897206647055489 | Evaluating Time: 5 
Epoch: 62 | Iteration number: [10/565] 1% | Training loss: 0.7552224159240722
Epoch: 62 | Iteration number: [20/565] 3% | Training loss: 0.7210574358701706
Epoch: 62 | Iteration number: [30/565] 5% | Training loss: 0.709578812122345
Epoch: 62 | Iteration number: [40/565] 7% | Training loss: 0.7038489907979966
Epoch: 62 | Iteration number: [50/565] 8% | Training loss: 0.7004510867595672
Epoch: 62 | Iteration number: [60/565] 10% | Training loss: 0.6982489536205928
Epoch: 62 | Iteration number: [70/565] 12% | Training loss: 0.6966131048543113
Epoch: 62 | Iteration number: [80/565] 14% | Training loss: 0.6953734427690506
Epoch: 62 | Iteration number: [90/565] 15% | Training loss: 0.6944595588578119
Epoch: 62 | Iteration number: [100/565] 17% | Training loss: 0.6936894625425338
Epoch: 62 | Iteration number: [110/565] 19% | Training loss: 0.6930580355904319
Epoch: 62 | Iteration number: [120/565] 21% | Training loss: 0.6925218800703684
Epoch: 62 | Iteration number: [130/565] 23% | Training loss: 0.6920937451032492
Epoch: 62 | Iteration number: [140/565] 24% | Training loss: 0.6917214291436332
Epoch: 62 | Iteration number: [150/565] 26% | Training loss: 0.6913715708255768
Epoch: 62 | Iteration number: [160/565] 28% | Training loss: 0.6910748422145844
Epoch: 62 | Iteration number: [170/565] 30% | Training loss: 0.6908262424609241
Epoch: 62 | Iteration number: [180/565] 31% | Training loss: 0.690579573975669
Epoch: 62 | Iteration number: [190/565] 33% | Training loss: 0.6903697490692139
Epoch: 62 | Iteration number: [200/565] 35% | Training loss: 0.6902016171813011
Epoch: 62 | Iteration number: [210/565] 37% | Training loss: 0.6900373561041696
Epoch: 62 | Iteration number: [220/565] 38% | Training loss: 0.6898920300331983
Epoch: 62 | Iteration number: [230/565] 40% | Training loss: 0.6897404507450435
Epoch: 62 | Iteration number: [240/565] 42% | Training loss: 0.6896148497859637
Epoch: 62 | Iteration number: [250/565] 44% | Training loss: 0.6894924552440643
Epoch: 62 | Iteration number: [260/565] 46% | Training loss: 0.6893892260698172
Epoch: 62 | Iteration number: [270/565] 47% | Training loss: 0.6892973932955
Epoch: 62 | Iteration number: [280/565] 49% | Training loss: 0.6892041214874812
Epoch: 62 | Iteration number: [290/565] 51% | Training loss: 0.6891273640353104
Epoch: 62 | Iteration number: [300/565] 53% | Training loss: 0.6890610955158869
Epoch: 62 | Iteration number: [310/565] 54% | Training loss: 0.6889877667350154
Epoch: 62 | Iteration number: [320/565] 56% | Training loss: 0.6889268573373556
Epoch: 62 | Iteration number: [330/565] 58% | Training loss: 0.6888722510048837
Epoch: 62 | Iteration number: [340/565] 60% | Training loss: 0.6888047849430757
Epoch: 62 | Iteration number: [350/565] 61% | Training loss: 0.6887455526420049
Epoch: 62 | Iteration number: [360/565] 63% | Training loss: 0.688683439625634
Epoch: 62 | Iteration number: [370/565] 65% | Training loss: 0.6886367883231189
Epoch: 62 | Iteration number: [380/565] 67% | Training loss: 0.6885921053196254
Epoch: 62 | Iteration number: [390/565] 69% | Training loss: 0.6885407041280698
Epoch: 62 | Iteration number: [400/565] 70% | Training loss: 0.6884999398887157
Epoch: 62 | Iteration number: [410/565] 72% | Training loss: 0.6884568525523674
Epoch: 62 | Iteration number: [420/565] 74% | Training loss: 0.6884184967903864
Epoch: 62 | Iteration number: [430/565] 76% | Training loss: 0.6883777549100477
Epoch: 62 | Iteration number: [440/565] 77% | Training loss: 0.6883340698751537
Epoch: 62 | Iteration number: [450/565] 79% | Training loss: 0.6882986268732283
Epoch: 62 | Iteration number: [460/565] 81% | Training loss: 0.6882604451283164
Epoch: 62 | Iteration number: [470/565] 83% | Training loss: 0.6882322670297419
Epoch: 62 | Iteration number: [480/565] 84% | Training loss: 0.6882052546987931
Epoch: 62 | Iteration number: [490/565] 86% | Training loss: 0.6881852963749243
Epoch: 62 | Iteration number: [500/565] 88% | Training loss: 0.6881581147909165
Epoch: 62 | Iteration number: [510/565] 90% | Training loss: 0.6881255216458264
Epoch: 62 | Iteration number: [520/565] 92% | Training loss: 0.6881032016414862
Epoch: 62 | Iteration number: [530/565] 93% | Training loss: 0.688097020702542
Epoch: 62 | Iteration number: [540/565] 95% | Training loss: 0.6880676205511447
Epoch: 62 | Iteration number: [550/565] 97% | Training loss: 0.6880407943508842
Epoch: 62 | Iteration number: [560/565] 99% | Training loss: 0.6880197786859104

 End of epoch: 62 | Train Loss: 0.6867932899863319 | Training Time: 90 

 End of epoch: 62 | Eval Loss: 0.6895844851221357 | Evaluating Time: 6 
Epoch: 63 | Iteration number: [10/565] 1% | Training loss: 0.755322802066803
Epoch: 63 | Iteration number: [20/565] 3% | Training loss: 0.720733779668808
Epoch: 63 | Iteration number: [30/565] 5% | Training loss: 0.70937606493632
Epoch: 63 | Iteration number: [40/565] 7% | Training loss: 0.7037520304322242
Epoch: 63 | Iteration number: [50/565] 8% | Training loss: 0.7004111850261688
Epoch: 63 | Iteration number: [60/565] 10% | Training loss: 0.6981427212556203
Epoch: 63 | Iteration number: [70/565] 12% | Training loss: 0.6964802759034293
Epoch: 63 | Iteration number: [80/565] 14% | Training loss: 0.6952294908463955
Epoch: 63 | Iteration number: [90/565] 15% | Training loss: 0.694308771027459
Epoch: 63 | Iteration number: [100/565] 17% | Training loss: 0.693563614487648
Epoch: 63 | Iteration number: [110/565] 19% | Training loss: 0.6929465597326105
Epoch: 63 | Iteration number: [120/565] 21% | Training loss: 0.6924486140410105
Epoch: 63 | Iteration number: [130/565] 23% | Training loss: 0.6920059314140907
Epoch: 63 | Iteration number: [140/565] 24% | Training loss: 0.6916320937020438
Epoch: 63 | Iteration number: [150/565] 26% | Training loss: 0.691313302119573
Epoch: 63 | Iteration number: [160/565] 28% | Training loss: 0.6910282909870148
Epoch: 63 | Iteration number: [170/565] 30% | Training loss: 0.6907865355996524
Epoch: 63 | Iteration number: [180/565] 31% | Training loss: 0.6905348810884687
Epoch: 63 | Iteration number: [190/565] 33% | Training loss: 0.6903400951310208
Epoch: 63 | Iteration number: [200/565] 35% | Training loss: 0.6901520383358002
Epoch: 63 | Iteration number: [210/565] 37% | Training loss: 0.689962558235441
Epoch: 63 | Iteration number: [220/565] 38% | Training loss: 0.689809449152513
Epoch: 63 | Iteration number: [230/565] 40% | Training loss: 0.6896816207014996
Epoch: 63 | Iteration number: [240/565] 42% | Training loss: 0.6895566888153553
Epoch: 63 | Iteration number: [250/565] 44% | Training loss: 0.6894454817771911
Epoch: 63 | Iteration number: [260/565] 46% | Training loss: 0.6893605168049152
Epoch: 63 | Iteration number: [270/565] 47% | Training loss: 0.6892798430389828
Epoch: 63 | Iteration number: [280/565] 49% | Training loss: 0.6891828028219087
Epoch: 63 | Iteration number: [290/565] 51% | Training loss: 0.6891015784493808
Epoch: 63 | Iteration number: [300/565] 53% | Training loss: 0.6890240242083867
Epoch: 63 | Iteration number: [310/565] 54% | Training loss: 0.6889441176768272
Epoch: 63 | Iteration number: [320/565] 56% | Training loss: 0.6888816667720675
Epoch: 63 | Iteration number: [330/565] 58% | Training loss: 0.6888274521538705
Epoch: 63 | Iteration number: [340/565] 60% | Training loss: 0.6887836514150395
Epoch: 63 | Iteration number: [350/565] 61% | Training loss: 0.6887287860257285
Epoch: 63 | Iteration number: [360/565] 63% | Training loss: 0.6886889989177386
Epoch: 63 | Iteration number: [370/565] 65% | Training loss: 0.6886309812197814
Epoch: 63 | Iteration number: [380/565] 67% | Training loss: 0.6885812392360285
Epoch: 63 | Iteration number: [390/565] 69% | Training loss: 0.6885334007250957
Epoch: 63 | Iteration number: [400/565] 70% | Training loss: 0.6884925839304924
Epoch: 63 | Iteration number: [410/565] 72% | Training loss: 0.6884614598460314
Epoch: 63 | Iteration number: [420/565] 74% | Training loss: 0.6884213839258466
Epoch: 63 | Iteration number: [430/565] 76% | Training loss: 0.6883871785430021
Epoch: 63 | Iteration number: [440/565] 77% | Training loss: 0.6883472168987448
Epoch: 63 | Iteration number: [450/565] 79% | Training loss: 0.6883131775591108
Epoch: 63 | Iteration number: [460/565] 81% | Training loss: 0.6882810135250507
Epoch: 63 | Iteration number: [470/565] 83% | Training loss: 0.6882454775749369
Epoch: 63 | Iteration number: [480/565] 84% | Training loss: 0.6882105826089779
Epoch: 63 | Iteration number: [490/565] 86% | Training loss: 0.6881798930314122
Epoch: 63 | Iteration number: [500/565] 88% | Training loss: 0.6881512067317963
Epoch: 63 | Iteration number: [510/565] 90% | Training loss: 0.6881304377434301
Epoch: 63 | Iteration number: [520/565] 92% | Training loss: 0.6881055808984317
Epoch: 63 | Iteration number: [530/565] 93% | Training loss: 0.6880800192086202
Epoch: 63 | Iteration number: [540/565] 95% | Training loss: 0.6880568664383006
Epoch: 63 | Iteration number: [550/565] 97% | Training loss: 0.6880377565730702
Epoch: 63 | Iteration number: [560/565] 99% | Training loss: 0.6880234108439514

 End of epoch: 63 | Train Loss: 0.6867993710315333 | Training Time: 88 

 End of epoch: 63 | Eval Loss: 0.6895281076431274 | Evaluating Time: 6 
Epoch: 64 | Iteration number: [10/565] 1% | Training loss: 0.7558798491954803
Epoch: 64 | Iteration number: [20/565] 3% | Training loss: 0.7214622378349305
Epoch: 64 | Iteration number: [30/565] 5% | Training loss: 0.7097755332787832
Epoch: 64 | Iteration number: [40/565] 7% | Training loss: 0.7040128737688065
Epoch: 64 | Iteration number: [50/565] 8% | Training loss: 0.7005991351604461
Epoch: 64 | Iteration number: [60/565] 10% | Training loss: 0.6983763615290324
Epoch: 64 | Iteration number: [70/565] 12% | Training loss: 0.6967523378985269
Epoch: 64 | Iteration number: [80/565] 14% | Training loss: 0.6955641657114029
Epoch: 64 | Iteration number: [90/565] 15% | Training loss: 0.6945341103606754
Epoch: 64 | Iteration number: [100/565] 17% | Training loss: 0.6937450593709946
Epoch: 64 | Iteration number: [110/565] 19% | Training loss: 0.6931123511357741
Epoch: 64 | Iteration number: [120/565] 21% | Training loss: 0.6926060269276301
Epoch: 64 | Iteration number: [130/565] 23% | Training loss: 0.6921649864086739
Epoch: 64 | Iteration number: [140/565] 24% | Training loss: 0.6917630587305341
Epoch: 64 | Iteration number: [150/565] 26% | Training loss: 0.6914394736289978
Epoch: 64 | Iteration number: [160/565] 28% | Training loss: 0.6911545746028424
Epoch: 64 | Iteration number: [170/565] 30% | Training loss: 0.6909028368837693
Epoch: 64 | Iteration number: [180/565] 31% | Training loss: 0.6906741566128201
Epoch: 64 | Iteration number: [190/565] 33% | Training loss: 0.6904740001025953
Epoch: 64 | Iteration number: [200/565] 35% | Training loss: 0.6902778002619744
Epoch: 64 | Iteration number: [210/565] 37% | Training loss: 0.6901158068861281
Epoch: 64 | Iteration number: [220/565] 38% | Training loss: 0.6899381450631402
Epoch: 64 | Iteration number: [230/565] 40% | Training loss: 0.6898139209850974
Epoch: 64 | Iteration number: [240/565] 42% | Training loss: 0.6896733870108922
Epoch: 64 | Iteration number: [250/565] 44% | Training loss: 0.6895615499019623
Epoch: 64 | Iteration number: [260/565] 46% | Training loss: 0.689452913403511
Epoch: 64 | Iteration number: [270/565] 47% | Training loss: 0.6893592052989536
Epoch: 64 | Iteration number: [280/565] 49% | Training loss: 0.6892613374761173
Epoch: 64 | Iteration number: [290/565] 51% | Training loss: 0.6891740729068888
Epoch: 64 | Iteration number: [300/565] 53% | Training loss: 0.689098661939303
Epoch: 64 | Iteration number: [310/565] 54% | Training loss: 0.6890287926120143
Epoch: 64 | Iteration number: [320/565] 56% | Training loss: 0.6889533752575516
Epoch: 64 | Iteration number: [330/565] 58% | Training loss: 0.6888698370167703
Epoch: 64 | Iteration number: [340/565] 60% | Training loss: 0.6888156273785759
Epoch: 64 | Iteration number: [350/565] 61% | Training loss: 0.6887493000711713
Epoch: 64 | Iteration number: [360/565] 63% | Training loss: 0.6886970778306325
Epoch: 64 | Iteration number: [370/565] 65% | Training loss: 0.6886488453761951
Epoch: 64 | Iteration number: [380/565] 67% | Training loss: 0.6886033037775441
Epoch: 64 | Iteration number: [390/565] 69% | Training loss: 0.6885601624464377
Epoch: 64 | Iteration number: [400/565] 70% | Training loss: 0.6885286046564579
Epoch: 64 | Iteration number: [410/565] 72% | Training loss: 0.6884868155165417
Epoch: 64 | Iteration number: [420/565] 74% | Training loss: 0.6884384942906243
Epoch: 64 | Iteration number: [430/565] 76% | Training loss: 0.6884042095306308
Epoch: 64 | Iteration number: [440/565] 77% | Training loss: 0.6883640495213595
Epoch: 64 | Iteration number: [450/565] 79% | Training loss: 0.6883316671848297
Epoch: 64 | Iteration number: [460/565] 81% | Training loss: 0.6882991576972215
Epoch: 64 | Iteration number: [470/565] 83% | Training loss: 0.688268094240351
Epoch: 64 | Iteration number: [480/565] 84% | Training loss: 0.688244191557169
Epoch: 64 | Iteration number: [490/565] 86% | Training loss: 0.6882051611433224
Epoch: 64 | Iteration number: [500/565] 88% | Training loss: 0.6881731944084167
Epoch: 64 | Iteration number: [510/565] 90% | Training loss: 0.6881430391003104
Epoch: 64 | Iteration number: [520/565] 92% | Training loss: 0.6881098728913527
Epoch: 64 | Iteration number: [530/565] 93% | Training loss: 0.6880845044019087
Epoch: 64 | Iteration number: [540/565] 95% | Training loss: 0.6880602717399598
Epoch: 64 | Iteration number: [550/565] 97% | Training loss: 0.688043505711989
Epoch: 64 | Iteration number: [560/565] 99% | Training loss: 0.6880187121885163

 End of epoch: 64 | Train Loss: 0.6867951153653913 | Training Time: 89 

 End of epoch: 64 | Eval Loss: 0.6897480743271964 | Evaluating Time: 6 
Epoch: 65 | Iteration number: [10/565] 1% | Training loss: 0.7548297226428986
Epoch: 65 | Iteration number: [20/565] 3% | Training loss: 0.7207989126443863
Epoch: 65 | Iteration number: [30/565] 5% | Training loss: 0.7093352337678274
Epoch: 65 | Iteration number: [40/565] 7% | Training loss: 0.7038127839565277
Epoch: 65 | Iteration number: [50/565] 8% | Training loss: 0.7005231904983521
Epoch: 65 | Iteration number: [60/565] 10% | Training loss: 0.6981916507085164
Epoch: 65 | Iteration number: [70/565] 12% | Training loss: 0.6966130682400294
Epoch: 65 | Iteration number: [80/565] 14% | Training loss: 0.6953591786324977
Epoch: 65 | Iteration number: [90/565] 15% | Training loss: 0.694373811615838
Epoch: 65 | Iteration number: [100/565] 17% | Training loss: 0.6936228853464127
Epoch: 65 | Iteration number: [110/565] 19% | Training loss: 0.6929851656610315
Epoch: 65 | Iteration number: [120/565] 21% | Training loss: 0.6924518167972564
Epoch: 65 | Iteration number: [130/565] 23% | Training loss: 0.6920224143908574
Epoch: 65 | Iteration number: [140/565] 24% | Training loss: 0.691638685975756
Epoch: 65 | Iteration number: [150/565] 26% | Training loss: 0.6913537287712097
Epoch: 65 | Iteration number: [160/565] 28% | Training loss: 0.6910708460956811
Epoch: 65 | Iteration number: [170/565] 30% | Training loss: 0.6908050915774178
Epoch: 65 | Iteration number: [180/565] 31% | Training loss: 0.6905806048048867
Epoch: 65 | Iteration number: [190/565] 33% | Training loss: 0.6904006126679872
Epoch: 65 | Iteration number: [200/565] 35% | Training loss: 0.6902453681826591
Epoch: 65 | Iteration number: [210/565] 37% | Training loss: 0.6900651784170242
Epoch: 65 | Iteration number: [220/565] 38% | Training loss: 0.6899274026805704
Epoch: 65 | Iteration number: [230/565] 40% | Training loss: 0.6897954510605854
Epoch: 65 | Iteration number: [240/565] 42% | Training loss: 0.6896979076166948
Epoch: 65 | Iteration number: [250/565] 44% | Training loss: 0.6895837411880493
Epoch: 65 | Iteration number: [260/565] 46% | Training loss: 0.68949250464256
Epoch: 65 | Iteration number: [270/565] 47% | Training loss: 0.6893881501974883
Epoch: 65 | Iteration number: [280/565] 49% | Training loss: 0.689306344304766
Epoch: 65 | Iteration number: [290/565] 51% | Training loss: 0.6892079412937164
Epoch: 65 | Iteration number: [300/565] 53% | Training loss: 0.6891309980551402
Epoch: 65 | Iteration number: [310/565] 54% | Training loss: 0.6890464032849958
Epoch: 65 | Iteration number: [320/565] 56% | Training loss: 0.68897665143013
Epoch: 65 | Iteration number: [330/565] 58% | Training loss: 0.6888976528789058
Epoch: 65 | Iteration number: [340/565] 60% | Training loss: 0.6888347625732422
Epoch: 65 | Iteration number: [350/565] 61% | Training loss: 0.688780814920153
Epoch: 65 | Iteration number: [360/565] 63% | Training loss: 0.6887343300713433
Epoch: 65 | Iteration number: [370/565] 65% | Training loss: 0.6886934294893935
Epoch: 65 | Iteration number: [380/565] 67% | Training loss: 0.6886416041537335
Epoch: 65 | Iteration number: [390/565] 69% | Training loss: 0.6885916920808646
Epoch: 65 | Iteration number: [400/565] 70% | Training loss: 0.6885515463352203
Epoch: 65 | Iteration number: [410/565] 72% | Training loss: 0.6885028186367779
Epoch: 65 | Iteration number: [420/565] 74% | Training loss: 0.6884554723898569
Epoch: 65 | Iteration number: [430/565] 76% | Training loss: 0.6884206655413605
Epoch: 65 | Iteration number: [440/565] 77% | Training loss: 0.6883823230862618
Epoch: 65 | Iteration number: [450/565] 79% | Training loss: 0.688356910943985
Epoch: 65 | Iteration number: [460/565] 81% | Training loss: 0.688317920461945
Epoch: 65 | Iteration number: [470/565] 83% | Training loss: 0.688283349985772
Epoch: 65 | Iteration number: [480/565] 84% | Training loss: 0.688244953006506
Epoch: 65 | Iteration number: [490/565] 86% | Training loss: 0.6882124787690688
Epoch: 65 | Iteration number: [500/565] 88% | Training loss: 0.6881889100074768
Epoch: 65 | Iteration number: [510/565] 90% | Training loss: 0.688154050766253
Epoch: 65 | Iteration number: [520/565] 92% | Training loss: 0.6881268610174839
Epoch: 65 | Iteration number: [530/565] 93% | Training loss: 0.6881001823353318
Epoch: 65 | Iteration number: [540/565] 95% | Training loss: 0.6880693408074202
Epoch: 65 | Iteration number: [550/565] 97% | Training loss: 0.6880439606579867
Epoch: 65 | Iteration number: [560/565] 99% | Training loss: 0.688025095739535

 End of epoch: 65 | Train Loss: 0.6867961900424113 | Training Time: 89 

 End of epoch: 65 | Eval Loss: 0.6900666781834194 | Evaluating Time: 5 
Epoch: 66 | Iteration number: [10/565] 1% | Training loss: 0.7555653214454651
Epoch: 66 | Iteration number: [20/565] 3% | Training loss: 0.7212640136480332
Epoch: 66 | Iteration number: [30/565] 5% | Training loss: 0.7097384552160899
Epoch: 66 | Iteration number: [40/565] 7% | Training loss: 0.704022441804409
Epoch: 66 | Iteration number: [50/565] 8% | Training loss: 0.700599000453949
Epoch: 66 | Iteration number: [60/565] 10% | Training loss: 0.6983061134815216
Epoch: 66 | Iteration number: [70/565] 12% | Training loss: 0.6966641357966832
Epoch: 66 | Iteration number: [80/565] 14% | Training loss: 0.6954466663300991
Epoch: 66 | Iteration number: [90/565] 15% | Training loss: 0.6944538129700555
Epoch: 66 | Iteration number: [100/565] 17% | Training loss: 0.6937216526269913
Epoch: 66 | Iteration number: [110/565] 19% | Training loss: 0.6930841137062419
Epoch: 66 | Iteration number: [120/565] 21% | Training loss: 0.6925704961021741
Epoch: 66 | Iteration number: [130/565] 23% | Training loss: 0.6920797393872188
Epoch: 66 | Iteration number: [140/565] 24% | Training loss: 0.6917275224413191
Epoch: 66 | Iteration number: [150/565] 26% | Training loss: 0.6913964955012003
Epoch: 66 | Iteration number: [160/565] 28% | Training loss: 0.6911015007644892
Epoch: 66 | Iteration number: [170/565] 30% | Training loss: 0.6908466328592862
Epoch: 66 | Iteration number: [180/565] 31% | Training loss: 0.6906429843770133
Epoch: 66 | Iteration number: [190/565] 33% | Training loss: 0.6904386002766458
Epoch: 66 | Iteration number: [200/565] 35% | Training loss: 0.6902508959174156
Epoch: 66 | Iteration number: [210/565] 37% | Training loss: 0.690079436983381
Epoch: 66 | Iteration number: [220/565] 38% | Training loss: 0.6899053037166596
Epoch: 66 | Iteration number: [230/565] 40% | Training loss: 0.6897714998411095
Epoch: 66 | Iteration number: [240/565] 42% | Training loss: 0.6896686971187591
Epoch: 66 | Iteration number: [250/565] 44% | Training loss: 0.6895549740791321
Epoch: 66 | Iteration number: [260/565] 46% | Training loss: 0.6894317081341377
Epoch: 66 | Iteration number: [270/565] 47% | Training loss: 0.689316882248278
Epoch: 66 | Iteration number: [280/565] 49% | Training loss: 0.6892357238701412
Epoch: 66 | Iteration number: [290/565] 51% | Training loss: 0.6891552331118748
Epoch: 66 | Iteration number: [300/565] 53% | Training loss: 0.6890784494082133
Epoch: 66 | Iteration number: [310/565] 54% | Training loss: 0.6890152154430267
Epoch: 66 | Iteration number: [320/565] 56% | Training loss: 0.6889551669359207
Epoch: 66 | Iteration number: [330/565] 58% | Training loss: 0.6888721234870679
Epoch: 66 | Iteration number: [340/565] 60% | Training loss: 0.6888229396413355
Epoch: 66 | Iteration number: [350/565] 61% | Training loss: 0.6887645166260855
Epoch: 66 | Iteration number: [360/565] 63% | Training loss: 0.6887137931254175
Epoch: 66 | Iteration number: [370/565] 65% | Training loss: 0.6886485847266944
Epoch: 66 | Iteration number: [380/565] 67% | Training loss: 0.6886106001703363
Epoch: 66 | Iteration number: [390/565] 69% | Training loss: 0.688555487149801
Epoch: 66 | Iteration number: [400/565] 70% | Training loss: 0.6885197950899601
Epoch: 66 | Iteration number: [410/565] 72% | Training loss: 0.6884780263028494
Epoch: 66 | Iteration number: [420/565] 74% | Training loss: 0.6884385563078381
Epoch: 66 | Iteration number: [430/565] 76% | Training loss: 0.688398927727411
Epoch: 66 | Iteration number: [440/565] 77% | Training loss: 0.6883613958954811
Epoch: 66 | Iteration number: [450/565] 79% | Training loss: 0.688321532673306
Epoch: 66 | Iteration number: [460/565] 81% | Training loss: 0.6882921628330065
Epoch: 66 | Iteration number: [470/565] 83% | Training loss: 0.6882597641741975
Epoch: 66 | Iteration number: [480/565] 84% | Training loss: 0.6882417025665443
Epoch: 66 | Iteration number: [490/565] 86% | Training loss: 0.6882186011392243
Epoch: 66 | Iteration number: [500/565] 88% | Training loss: 0.6881916607618332
Epoch: 66 | Iteration number: [510/565] 90% | Training loss: 0.6881617729570352
Epoch: 66 | Iteration number: [520/565] 92% | Training loss: 0.688132386138806
Epoch: 66 | Iteration number: [530/565] 93% | Training loss: 0.6881083067857994
Epoch: 66 | Iteration number: [540/565] 95% | Training loss: 0.688075202593097
Epoch: 66 | Iteration number: [550/565] 97% | Training loss: 0.6880456257950176
Epoch: 66 | Iteration number: [560/565] 99% | Training loss: 0.688025318299021

 End of epoch: 66 | Train Loss: 0.6867956456884874 | Training Time: 89 

 End of epoch: 66 | Eval Loss: 0.6899785143988473 | Evaluating Time: 5 
Epoch: 67 | Iteration number: [10/565] 1% | Training loss: 0.7558703482151031
Epoch: 67 | Iteration number: [20/565] 3% | Training loss: 0.7212256163358688
Epoch: 67 | Iteration number: [30/565] 5% | Training loss: 0.7098729729652404
Epoch: 67 | Iteration number: [40/565] 7% | Training loss: 0.7042089015245437
Epoch: 67 | Iteration number: [50/565] 8% | Training loss: 0.7007090187072754
Epoch: 67 | Iteration number: [60/565] 10% | Training loss: 0.6984306395053863
Epoch: 67 | Iteration number: [70/565] 12% | Training loss: 0.6967663620199476
Epoch: 67 | Iteration number: [80/565] 14% | Training loss: 0.6955114245414734
Epoch: 67 | Iteration number: [90/565] 15% | Training loss: 0.6945406443542904
Epoch: 67 | Iteration number: [100/565] 17% | Training loss: 0.6937079191207886
Epoch: 67 | Iteration number: [110/565] 19% | Training loss: 0.693054916641929
Epoch: 67 | Iteration number: [120/565] 21% | Training loss: 0.6925515199700991
Epoch: 67 | Iteration number: [130/565] 23% | Training loss: 0.6921504951440371
Epoch: 67 | Iteration number: [140/565] 24% | Training loss: 0.6917957889182227
Epoch: 67 | Iteration number: [150/565] 26% | Training loss: 0.6914614148934682
Epoch: 67 | Iteration number: [160/565] 28% | Training loss: 0.691174104064703
Epoch: 67 | Iteration number: [170/565] 30% | Training loss: 0.6909127589534311
Epoch: 67 | Iteration number: [180/565] 31% | Training loss: 0.6906889872418509
Epoch: 67 | Iteration number: [190/565] 33% | Training loss: 0.6904900086553474
Epoch: 67 | Iteration number: [200/565] 35% | Training loss: 0.6903137910366058
Epoch: 67 | Iteration number: [210/565] 37% | Training loss: 0.6901336664245242
Epoch: 67 | Iteration number: [220/565] 38% | Training loss: 0.6899903516877781
Epoch: 67 | Iteration number: [230/565] 40% | Training loss: 0.6898517377998518
Epoch: 67 | Iteration number: [240/565] 42% | Training loss: 0.6897265846530597
Epoch: 67 | Iteration number: [250/565] 44% | Training loss: 0.6895857765674591
Epoch: 67 | Iteration number: [260/565] 46% | Training loss: 0.6894621502894621
Epoch: 67 | Iteration number: [270/565] 47% | Training loss: 0.6893598322515134
Epoch: 67 | Iteration number: [280/565] 49% | Training loss: 0.6892710451568876
Epoch: 67 | Iteration number: [290/565] 51% | Training loss: 0.6891908711400525
Epoch: 67 | Iteration number: [300/565] 53% | Training loss: 0.689109388589859
Epoch: 67 | Iteration number: [310/565] 54% | Training loss: 0.6890348232561542
Epoch: 67 | Iteration number: [320/565] 56% | Training loss: 0.6889659870415926
Epoch: 67 | Iteration number: [330/565] 58% | Training loss: 0.6888924873236454
Epoch: 67 | Iteration number: [340/565] 60% | Training loss: 0.6888316855711095
Epoch: 67 | Iteration number: [350/565] 61% | Training loss: 0.6887849371773856
Epoch: 67 | Iteration number: [360/565] 63% | Training loss: 0.6887181856566005
Epoch: 67 | Iteration number: [370/565] 65% | Training loss: 0.6886690624662348
Epoch: 67 | Iteration number: [380/565] 67% | Training loss: 0.6886089053593184
Epoch: 67 | Iteration number: [390/565] 69% | Training loss: 0.6885641486216814
Epoch: 67 | Iteration number: [400/565] 70% | Training loss: 0.688519638478756
Epoch: 67 | Iteration number: [410/565] 72% | Training loss: 0.6884710506695073
Epoch: 67 | Iteration number: [420/565] 74% | Training loss: 0.6884362508853277
Epoch: 67 | Iteration number: [430/565] 76% | Training loss: 0.6883963166281234
Epoch: 67 | Iteration number: [440/565] 77% | Training loss: 0.6883583404801109
Epoch: 67 | Iteration number: [450/565] 79% | Training loss: 0.6883196873135037
Epoch: 67 | Iteration number: [460/565] 81% | Training loss: 0.6882954781470092
Epoch: 67 | Iteration number: [470/565] 83% | Training loss: 0.6882702789408095
Epoch: 67 | Iteration number: [480/565] 84% | Training loss: 0.6882337945202986
Epoch: 67 | Iteration number: [490/565] 86% | Training loss: 0.6882068110972035
Epoch: 67 | Iteration number: [500/565] 88% | Training loss: 0.6881798573732376
Epoch: 67 | Iteration number: [510/565] 90% | Training loss: 0.688150607955222
Epoch: 67 | Iteration number: [520/565] 92% | Training loss: 0.6881171173774279
Epoch: 67 | Iteration number: [530/565] 93% | Training loss: 0.6880936374079506
Epoch: 67 | Iteration number: [540/565] 95% | Training loss: 0.6880774996898792
Epoch: 67 | Iteration number: [550/565] 97% | Training loss: 0.6880513889139349
Epoch: 67 | Iteration number: [560/565] 99% | Training loss: 0.6880271574216229

 End of epoch: 67 | Train Loss: 0.6867977363873372 | Training Time: 89 

 End of epoch: 67 | Eval Loss: 0.6898476225989205 | Evaluating Time: 5 
Epoch: 68 | Iteration number: [10/565] 1% | Training loss: 0.7552546501159668
Epoch: 68 | Iteration number: [20/565] 3% | Training loss: 0.7212738633155823
Epoch: 68 | Iteration number: [30/565] 5% | Training loss: 0.7098960320154826
Epoch: 68 | Iteration number: [40/565] 7% | Training loss: 0.7041749686002732
Epoch: 68 | Iteration number: [50/565] 8% | Training loss: 0.7007324624061585
Epoch: 68 | Iteration number: [60/565] 10% | Training loss: 0.6984309047460556
Epoch: 68 | Iteration number: [70/565] 12% | Training loss: 0.6967247894832066
Epoch: 68 | Iteration number: [80/565] 14% | Training loss: 0.6954428620636464
Epoch: 68 | Iteration number: [90/565] 15% | Training loss: 0.6944955660237206
Epoch: 68 | Iteration number: [100/565] 17% | Training loss: 0.6937189602851868
Epoch: 68 | Iteration number: [110/565] 19% | Training loss: 0.6930597554553639
Epoch: 68 | Iteration number: [120/565] 21% | Training loss: 0.6925017868479093
Epoch: 68 | Iteration number: [130/565] 23% | Training loss: 0.6920647052618173
Epoch: 68 | Iteration number: [140/565] 24% | Training loss: 0.6916997419936316
Epoch: 68 | Iteration number: [150/565] 26% | Training loss: 0.6913941895961762
Epoch: 68 | Iteration number: [160/565] 28% | Training loss: 0.6910705517977476
Epoch: 68 | Iteration number: [170/565] 30% | Training loss: 0.690815742226208
Epoch: 68 | Iteration number: [180/565] 31% | Training loss: 0.6905789458089404
Epoch: 68 | Iteration number: [190/565] 33% | Training loss: 0.6903784397401308
Epoch: 68 | Iteration number: [200/565] 35% | Training loss: 0.6901993235945701
Epoch: 68 | Iteration number: [210/565] 37% | Training loss: 0.6900366729214078
Epoch: 68 | Iteration number: [220/565] 38% | Training loss: 0.6898983817208897
Epoch: 68 | Iteration number: [230/565] 40% | Training loss: 0.6897648298222085
Epoch: 68 | Iteration number: [240/565] 42% | Training loss: 0.6896246053278446
Epoch: 68 | Iteration number: [250/565] 44% | Training loss: 0.6895111770629883
Epoch: 68 | Iteration number: [260/565] 46% | Training loss: 0.6894057443508735
Epoch: 68 | Iteration number: [270/565] 47% | Training loss: 0.6893165886402131
Epoch: 68 | Iteration number: [280/565] 49% | Training loss: 0.6892355505909239
Epoch: 68 | Iteration number: [290/565] 51% | Training loss: 0.6891316892771885
Epoch: 68 | Iteration number: [300/565] 53% | Training loss: 0.68906329870224
Epoch: 68 | Iteration number: [310/565] 54% | Training loss: 0.688979507261707
Epoch: 68 | Iteration number: [320/565] 56% | Training loss: 0.6888989424332976
Epoch: 68 | Iteration number: [330/565] 58% | Training loss: 0.6888246184045618
Epoch: 68 | Iteration number: [340/565] 60% | Training loss: 0.6887744521393495
Epoch: 68 | Iteration number: [350/565] 61% | Training loss: 0.6887280561242785
Epoch: 68 | Iteration number: [360/565] 63% | Training loss: 0.6886751408378283
Epoch: 68 | Iteration number: [370/565] 65% | Training loss: 0.688625598598171
Epoch: 68 | Iteration number: [380/565] 67% | Training loss: 0.6885770700479809
Epoch: 68 | Iteration number: [390/565] 69% | Training loss: 0.6885301288885948
Epoch: 68 | Iteration number: [400/565] 70% | Training loss: 0.6884816226363182
Epoch: 68 | Iteration number: [410/565] 72% | Training loss: 0.6884462400180538
Epoch: 68 | Iteration number: [420/565] 74% | Training loss: 0.6884095319679805
Epoch: 68 | Iteration number: [430/565] 76% | Training loss: 0.6883779503578363
Epoch: 68 | Iteration number: [440/565] 77% | Training loss: 0.6883344926617362
Epoch: 68 | Iteration number: [450/565] 79% | Training loss: 0.6883049473497602
Epoch: 68 | Iteration number: [460/565] 81% | Training loss: 0.6882706928512324
Epoch: 68 | Iteration number: [470/565] 83% | Training loss: 0.6882401487928755
Epoch: 68 | Iteration number: [480/565] 84% | Training loss: 0.6882223586241404
Epoch: 68 | Iteration number: [490/565] 86% | Training loss: 0.6881974124178595
Epoch: 68 | Iteration number: [500/565] 88% | Training loss: 0.6881719460487365
Epoch: 68 | Iteration number: [510/565] 90% | Training loss: 0.6881481558668847
Epoch: 68 | Iteration number: [520/565] 92% | Training loss: 0.688125182229739
Epoch: 68 | Iteration number: [530/565] 93% | Training loss: 0.6881033273238056
Epoch: 68 | Iteration number: [540/565] 95% | Training loss: 0.6880642176778228
Epoch: 68 | Iteration number: [550/565] 97% | Training loss: 0.6880420450730758
Epoch: 68 | Iteration number: [560/565] 99% | Training loss: 0.6880184309823173

 End of epoch: 68 | Train Loss: 0.6867892517452746 | Training Time: 89 

 End of epoch: 68 | Eval Loss: 0.6892721482685634 | Evaluating Time: 6 
Epoch: 69 | Iteration number: [10/565] 1% | Training loss: 0.7555370569229126
Epoch: 69 | Iteration number: [20/565] 3% | Training loss: 0.7212122559547425
Epoch: 69 | Iteration number: [30/565] 5% | Training loss: 0.7097473740577698
Epoch: 69 | Iteration number: [40/565] 7% | Training loss: 0.7040612384676933
Epoch: 69 | Iteration number: [50/565] 8% | Training loss: 0.7006592047214508
Epoch: 69 | Iteration number: [60/565] 10% | Training loss: 0.6983236382404964
Epoch: 69 | Iteration number: [70/565] 12% | Training loss: 0.6966526670115335
Epoch: 69 | Iteration number: [80/565] 14% | Training loss: 0.6954629048705101
Epoch: 69 | Iteration number: [90/565] 15% | Training loss: 0.6944870909055074
Epoch: 69 | Iteration number: [100/565] 17% | Training loss: 0.693730348944664
Epoch: 69 | Iteration number: [110/565] 19% | Training loss: 0.6930865688757463
Epoch: 69 | Iteration number: [120/565] 21% | Training loss: 0.6925750732421875
Epoch: 69 | Iteration number: [130/565] 23% | Training loss: 0.6921336733377896
Epoch: 69 | Iteration number: [140/565] 24% | Training loss: 0.691729097706931
Epoch: 69 | Iteration number: [150/565] 26% | Training loss: 0.6913670146465302
Epoch: 69 | Iteration number: [160/565] 28% | Training loss: 0.6910824000835418
Epoch: 69 | Iteration number: [170/565] 30% | Training loss: 0.690828797045876
Epoch: 69 | Iteration number: [180/565] 31% | Training loss: 0.6906048827701144
Epoch: 69 | Iteration number: [190/565] 33% | Training loss: 0.6904097381391023
Epoch: 69 | Iteration number: [200/565] 35% | Training loss: 0.6902426564693451
Epoch: 69 | Iteration number: [210/565] 37% | Training loss: 0.6901008728004637
Epoch: 69 | Iteration number: [220/565] 38% | Training loss: 0.6899123703891581
Epoch: 69 | Iteration number: [230/565] 40% | Training loss: 0.6897784632185231
Epoch: 69 | Iteration number: [240/565] 42% | Training loss: 0.6896494212249915
Epoch: 69 | Iteration number: [250/565] 44% | Training loss: 0.6895193297863007
Epoch: 69 | Iteration number: [260/565] 46% | Training loss: 0.6894085845121971
Epoch: 69 | Iteration number: [270/565] 47% | Training loss: 0.6893057653197536
Epoch: 69 | Iteration number: [280/565] 49% | Training loss: 0.6892125761934689
Epoch: 69 | Iteration number: [290/565] 51% | Training loss: 0.6891370485568868
Epoch: 69 | Iteration number: [300/565] 53% | Training loss: 0.6890589016675949
Epoch: 69 | Iteration number: [310/565] 54% | Training loss: 0.6889920671139994
Epoch: 69 | Iteration number: [320/565] 56% | Training loss: 0.6889148132875562
Epoch: 69 | Iteration number: [330/565] 58% | Training loss: 0.6888443224357836
Epoch: 69 | Iteration number: [340/565] 60% | Training loss: 0.688784390337327
Epoch: 69 | Iteration number: [350/565] 61% | Training loss: 0.6887169025625501
Epoch: 69 | Iteration number: [360/565] 63% | Training loss: 0.6886652221282323
Epoch: 69 | Iteration number: [370/565] 65% | Training loss: 0.6886145934865281
Epoch: 69 | Iteration number: [380/565] 67% | Training loss: 0.6885768382172835
Epoch: 69 | Iteration number: [390/565] 69% | Training loss: 0.6885394322566497
Epoch: 69 | Iteration number: [400/565] 70% | Training loss: 0.6884978394210338
Epoch: 69 | Iteration number: [410/565] 72% | Training loss: 0.6884597519548928
Epoch: 69 | Iteration number: [420/565] 74% | Training loss: 0.6884199839262736
Epoch: 69 | Iteration number: [430/565] 76% | Training loss: 0.6883811940980512
Epoch: 69 | Iteration number: [440/565] 77% | Training loss: 0.6883580175313082
Epoch: 69 | Iteration number: [450/565] 79% | Training loss: 0.6883250811364916
Epoch: 69 | Iteration number: [460/565] 81% | Training loss: 0.6882944248292757
Epoch: 69 | Iteration number: [470/565] 83% | Training loss: 0.68826141978832
Epoch: 69 | Iteration number: [480/565] 84% | Training loss: 0.6882324742774169
Epoch: 69 | Iteration number: [490/565] 86% | Training loss: 0.6881985176582726
Epoch: 69 | Iteration number: [500/565] 88% | Training loss: 0.6881728162765502
Epoch: 69 | Iteration number: [510/565] 90% | Training loss: 0.688138981777079
Epoch: 69 | Iteration number: [520/565] 92% | Training loss: 0.6881191999866412
Epoch: 69 | Iteration number: [530/565] 93% | Training loss: 0.6880989759598138
Epoch: 69 | Iteration number: [540/565] 95% | Training loss: 0.6880744451725924
Epoch: 69 | Iteration number: [550/565] 97% | Training loss: 0.6880553505637429
Epoch: 69 | Iteration number: [560/565] 99% | Training loss: 0.688029192175184

 End of epoch: 69 | Train Loss: 0.6868012291140261 | Training Time: 89 

 End of epoch: 69 | Eval Loss: 0.6899205616542271 | Evaluating Time: 6 
Epoch: 70 | Iteration number: [10/565] 1% | Training loss: 0.7552802801132202
Epoch: 70 | Iteration number: [20/565] 3% | Training loss: 0.7209972679615021
Epoch: 70 | Iteration number: [30/565] 5% | Training loss: 0.7094903469085694
Epoch: 70 | Iteration number: [40/565] 7% | Training loss: 0.7037866979837417
Epoch: 70 | Iteration number: [50/565] 8% | Training loss: 0.700407350063324
Epoch: 70 | Iteration number: [60/565] 10% | Training loss: 0.6981179684400558
Epoch: 70 | Iteration number: [70/565] 12% | Training loss: 0.6964587926864624
Epoch: 70 | Iteration number: [80/565] 14% | Training loss: 0.6952360302209855
Epoch: 70 | Iteration number: [90/565] 15% | Training loss: 0.6942277073860168
Epoch: 70 | Iteration number: [100/565] 17% | Training loss: 0.6934968858957291
Epoch: 70 | Iteration number: [110/565] 19% | Training loss: 0.6928753511472182
Epoch: 70 | Iteration number: [120/565] 21% | Training loss: 0.6924001197020213
Epoch: 70 | Iteration number: [130/565] 23% | Training loss: 0.6919437243388249
Epoch: 70 | Iteration number: [140/565] 24% | Training loss: 0.6915898484843118
Epoch: 70 | Iteration number: [150/565] 26% | Training loss: 0.6912560757001242
Epoch: 70 | Iteration number: [160/565] 28% | Training loss: 0.6909950327128171
Epoch: 70 | Iteration number: [170/565] 30% | Training loss: 0.6907377057215747
Epoch: 70 | Iteration number: [180/565] 31% | Training loss: 0.690512380666203
Epoch: 70 | Iteration number: [190/565] 33% | Training loss: 0.6903122832900599
Epoch: 70 | Iteration number: [200/565] 35% | Training loss: 0.6901453900337219
Epoch: 70 | Iteration number: [210/565] 37% | Training loss: 0.6899881408328101
Epoch: 70 | Iteration number: [220/565] 38% | Training loss: 0.6898536898873069
Epoch: 70 | Iteration number: [230/565] 40% | Training loss: 0.6897220917370008
Epoch: 70 | Iteration number: [240/565] 42% | Training loss: 0.6895897676547368
Epoch: 70 | Iteration number: [250/565] 44% | Training loss: 0.6894675924777984
Epoch: 70 | Iteration number: [260/565] 46% | Training loss: 0.6893566512144529
Epoch: 70 | Iteration number: [270/565] 47% | Training loss: 0.689263023491259
Epoch: 70 | Iteration number: [280/565] 49% | Training loss: 0.6891724614160402
Epoch: 70 | Iteration number: [290/565] 51% | Training loss: 0.689090953818683
Epoch: 70 | Iteration number: [300/565] 53% | Training loss: 0.6890170631806055
Epoch: 70 | Iteration number: [310/565] 54% | Training loss: 0.6889492582890295
Epoch: 70 | Iteration number: [320/565] 56% | Training loss: 0.6888770898804069
Epoch: 70 | Iteration number: [330/565] 58% | Training loss: 0.6888270562345331
Epoch: 70 | Iteration number: [340/565] 60% | Training loss: 0.688776040427825
Epoch: 70 | Iteration number: [350/565] 61% | Training loss: 0.6887122849055699
Epoch: 70 | Iteration number: [360/565] 63% | Training loss: 0.6886559683415625
Epoch: 70 | Iteration number: [370/565] 65% | Training loss: 0.6886110420162613
Epoch: 70 | Iteration number: [380/565] 67% | Training loss: 0.6885566234588623
Epoch: 70 | Iteration number: [390/565] 69% | Training loss: 0.6885120203861823
Epoch: 70 | Iteration number: [400/565] 70% | Training loss: 0.6884662130475044
Epoch: 70 | Iteration number: [410/565] 72% | Training loss: 0.6884203755274052
Epoch: 70 | Iteration number: [420/565] 74% | Training loss: 0.6883775398844765
Epoch: 70 | Iteration number: [430/565] 76% | Training loss: 0.6883502914461979
Epoch: 70 | Iteration number: [440/565] 77% | Training loss: 0.688308039036664
Epoch: 70 | Iteration number: [450/565] 79% | Training loss: 0.688286837471856
Epoch: 70 | Iteration number: [460/565] 81% | Training loss: 0.6882533651331196
Epoch: 70 | Iteration number: [470/565] 83% | Training loss: 0.6882365735287362
Epoch: 70 | Iteration number: [480/565] 84% | Training loss: 0.6882026986529429
Epoch: 70 | Iteration number: [490/565] 86% | Training loss: 0.6881721317768097
Epoch: 70 | Iteration number: [500/565] 88% | Training loss: 0.6881435041427613
Epoch: 70 | Iteration number: [510/565] 90% | Training loss: 0.6881148040294647
Epoch: 70 | Iteration number: [520/565] 92% | Training loss: 0.6880954377926313
Epoch: 70 | Iteration number: [530/565] 93% | Training loss: 0.688070198612393
Epoch: 70 | Iteration number: [540/565] 95% | Training loss: 0.6880465624509035
Epoch: 70 | Iteration number: [550/565] 97% | Training loss: 0.6880321434411135
Epoch: 70 | Iteration number: [560/565] 99% | Training loss: 0.6880093886383942

 End of epoch: 70 | Train Loss: 0.6867786932835537 | Training Time: 88 

 End of epoch: 70 | Eval Loss: 0.6898406744003296 | Evaluating Time: 5 
Epoch: 71 | Iteration number: [10/565] 1% | Training loss: 0.7556278526782989
Epoch: 71 | Iteration number: [20/565] 3% | Training loss: 0.7211585700511932
Epoch: 71 | Iteration number: [30/565] 5% | Training loss: 0.7095882773399353
Epoch: 71 | Iteration number: [40/565] 7% | Training loss: 0.7039757072925568
Epoch: 71 | Iteration number: [50/565] 8% | Training loss: 0.7005112504959107
Epoch: 71 | Iteration number: [60/565] 10% | Training loss: 0.6982691993316015
Epoch: 71 | Iteration number: [70/565] 12% | Training loss: 0.6965856381825039
Epoch: 71 | Iteration number: [80/565] 14% | Training loss: 0.6953545801341534
Epoch: 71 | Iteration number: [90/565] 15% | Training loss: 0.6943797138002183
Epoch: 71 | Iteration number: [100/565] 17% | Training loss: 0.6936612832546234
Epoch: 71 | Iteration number: [110/565] 19% | Training loss: 0.6930314156142148
Epoch: 71 | Iteration number: [120/565] 21% | Training loss: 0.6925023739536603
Epoch: 71 | Iteration number: [130/565] 23% | Training loss: 0.6920729339122772
Epoch: 71 | Iteration number: [140/565] 24% | Training loss: 0.6917230244193758
Epoch: 71 | Iteration number: [150/565] 26% | Training loss: 0.6913893206914266
Epoch: 71 | Iteration number: [160/565] 28% | Training loss: 0.6911050118505955
Epoch: 71 | Iteration number: [170/565] 30% | Training loss: 0.6908399445169112
Epoch: 71 | Iteration number: [180/565] 31% | Training loss: 0.6906256768438551
Epoch: 71 | Iteration number: [190/565] 33% | Training loss: 0.6903970997584493
Epoch: 71 | Iteration number: [200/565] 35% | Training loss: 0.6902169236540794
Epoch: 71 | Iteration number: [210/565] 37% | Training loss: 0.6900526611577897
Epoch: 71 | Iteration number: [220/565] 38% | Training loss: 0.6898956054990942
Epoch: 71 | Iteration number: [230/565] 40% | Training loss: 0.6897478077722632
Epoch: 71 | Iteration number: [240/565] 42% | Training loss: 0.6896438670655092
Epoch: 71 | Iteration number: [250/565] 44% | Training loss: 0.6895455086231231
Epoch: 71 | Iteration number: [260/565] 46% | Training loss: 0.6894265335339766
Epoch: 71 | Iteration number: [270/565] 47% | Training loss: 0.6893318639861212
Epoch: 71 | Iteration number: [280/565] 49% | Training loss: 0.6892336487770081
Epoch: 71 | Iteration number: [290/565] 51% | Training loss: 0.6891497632552838
Epoch: 71 | Iteration number: [300/565] 53% | Training loss: 0.6890636575222016
Epoch: 71 | Iteration number: [310/565] 54% | Training loss: 0.6889744452891812
Epoch: 71 | Iteration number: [320/565] 56% | Training loss: 0.6889123542234301
Epoch: 71 | Iteration number: [330/565] 58% | Training loss: 0.688856114582582
Epoch: 71 | Iteration number: [340/565] 60% | Training loss: 0.6888071172377642
Epoch: 71 | Iteration number: [350/565] 61% | Training loss: 0.6887525168487004
Epoch: 71 | Iteration number: [360/565] 63% | Training loss: 0.6887024404274092
Epoch: 71 | Iteration number: [370/565] 65% | Training loss: 0.688653021406483
Epoch: 71 | Iteration number: [380/565] 67% | Training loss: 0.688607372735676
Epoch: 71 | Iteration number: [390/565] 69% | Training loss: 0.6885546889060583
Epoch: 71 | Iteration number: [400/565] 70% | Training loss: 0.6885216362774372
Epoch: 71 | Iteration number: [410/565] 72% | Training loss: 0.6884808197254088
Epoch: 71 | Iteration number: [420/565] 74% | Training loss: 0.6884384003423509
Epoch: 71 | Iteration number: [430/565] 76% | Training loss: 0.6883987401807031
Epoch: 71 | Iteration number: [440/565] 77% | Training loss: 0.6883492156863212
Epoch: 71 | Iteration number: [450/565] 79% | Training loss: 0.6883211467001173
Epoch: 71 | Iteration number: [460/565] 81% | Training loss: 0.6882981801810472
Epoch: 71 | Iteration number: [470/565] 83% | Training loss: 0.6882680813048748
Epoch: 71 | Iteration number: [480/565] 84% | Training loss: 0.6882284309715032
Epoch: 71 | Iteration number: [490/565] 86% | Training loss: 0.688188912308946
Epoch: 71 | Iteration number: [500/565] 88% | Training loss: 0.688163400888443
Epoch: 71 | Iteration number: [510/565] 90% | Training loss: 0.6881359044243308
Epoch: 71 | Iteration number: [520/565] 92% | Training loss: 0.688099274956263
Epoch: 71 | Iteration number: [530/565] 93% | Training loss: 0.6880787819061639
Epoch: 71 | Iteration number: [540/565] 95% | Training loss: 0.6880522102117539
Epoch: 71 | Iteration number: [550/565] 97% | Training loss: 0.6880297709595073
Epoch: 71 | Iteration number: [560/565] 99% | Training loss: 0.6880024753510952

 End of epoch: 71 | Train Loss: 0.6867743310675157 | Training Time: 89 

 End of epoch: 71 | Eval Loss: 0.6899951951844352 | Evaluating Time: 5 
Epoch: 72 | Iteration number: [10/565] 1% | Training loss: 0.7555685222148896
Epoch: 72 | Iteration number: [20/565] 3% | Training loss: 0.7210469424724579
Epoch: 72 | Iteration number: [30/565] 5% | Training loss: 0.7096795916557312
Epoch: 72 | Iteration number: [40/565] 7% | Training loss: 0.7039455085992813
Epoch: 72 | Iteration number: [50/565] 8% | Training loss: 0.700514520406723
Epoch: 72 | Iteration number: [60/565] 10% | Training loss: 0.6982157359520594
Epoch: 72 | Iteration number: [70/565] 12% | Training loss: 0.69658454145704
Epoch: 72 | Iteration number: [80/565] 14% | Training loss: 0.6953915320336819
Epoch: 72 | Iteration number: [90/565] 15% | Training loss: 0.6944950766033596
Epoch: 72 | Iteration number: [100/565] 17% | Training loss: 0.6937662148475647
Epoch: 72 | Iteration number: [110/565] 19% | Training loss: 0.6931651402603496
Epoch: 72 | Iteration number: [120/565] 21% | Training loss: 0.6926361203193665
Epoch: 72 | Iteration number: [130/565] 23% | Training loss: 0.6921954187063071
Epoch: 72 | Iteration number: [140/565] 24% | Training loss: 0.6918078741856983
Epoch: 72 | Iteration number: [150/565] 26% | Training loss: 0.6914903752009074
Epoch: 72 | Iteration number: [160/565] 28% | Training loss: 0.6911786664277315
Epoch: 72 | Iteration number: [170/565] 30% | Training loss: 0.690913914231693
Epoch: 72 | Iteration number: [180/565] 31% | Training loss: 0.690653200281991
Epoch: 72 | Iteration number: [190/565] 33% | Training loss: 0.690466571795313
Epoch: 72 | Iteration number: [200/565] 35% | Training loss: 0.6902702260017395
Epoch: 72 | Iteration number: [210/565] 37% | Training loss: 0.6901014211631956
Epoch: 72 | Iteration number: [220/565] 38% | Training loss: 0.6899572299285368
Epoch: 72 | Iteration number: [230/565] 40% | Training loss: 0.6898136696089869
Epoch: 72 | Iteration number: [240/565] 42% | Training loss: 0.689702337483565
Epoch: 72 | Iteration number: [250/565] 44% | Training loss: 0.6895567896366119
Epoch: 72 | Iteration number: [260/565] 46% | Training loss: 0.6894635707139969
Epoch: 72 | Iteration number: [270/565] 47% | Training loss: 0.689364986066465
Epoch: 72 | Iteration number: [280/565] 49% | Training loss: 0.6892820573278836
Epoch: 72 | Iteration number: [290/565] 51% | Training loss: 0.6891712786822484
Epoch: 72 | Iteration number: [300/565] 53% | Training loss: 0.6890965962409973
Epoch: 72 | Iteration number: [310/565] 54% | Training loss: 0.6890225937289577
Epoch: 72 | Iteration number: [320/565] 56% | Training loss: 0.6889433316886425
Epoch: 72 | Iteration number: [330/565] 58% | Training loss: 0.6888660277381088
Epoch: 72 | Iteration number: [340/565] 60% | Training loss: 0.688808411359787
Epoch: 72 | Iteration number: [350/565] 61% | Training loss: 0.6887425184249878
Epoch: 72 | Iteration number: [360/565] 63% | Training loss: 0.6886994224455621
Epoch: 72 | Iteration number: [370/565] 65% | Training loss: 0.6886293430586119
Epoch: 72 | Iteration number: [380/565] 67% | Training loss: 0.6885813498183301
Epoch: 72 | Iteration number: [390/565] 69% | Training loss: 0.6885523054844294
Epoch: 72 | Iteration number: [400/565] 70% | Training loss: 0.6885038863122463
Epoch: 72 | Iteration number: [410/565] 72% | Training loss: 0.6884679555892944
Epoch: 72 | Iteration number: [420/565] 74% | Training loss: 0.6884303253321421
Epoch: 72 | Iteration number: [430/565] 76% | Training loss: 0.6883881225142368
Epoch: 72 | Iteration number: [440/565] 77% | Training loss: 0.6883519696918401
Epoch: 72 | Iteration number: [450/565] 79% | Training loss: 0.6883131392796834
Epoch: 72 | Iteration number: [460/565] 81% | Training loss: 0.6882826268672944
Epoch: 72 | Iteration number: [470/565] 83% | Training loss: 0.6882425393195862
Epoch: 72 | Iteration number: [480/565] 84% | Training loss: 0.6882152795791626
Epoch: 72 | Iteration number: [490/565] 86% | Training loss: 0.6881788821852937
Epoch: 72 | Iteration number: [500/565] 88% | Training loss: 0.6881485226154327
Epoch: 72 | Iteration number: [510/565] 90% | Training loss: 0.6881154262552074
Epoch: 72 | Iteration number: [520/565] 92% | Training loss: 0.6880904688284948
Epoch: 72 | Iteration number: [530/565] 93% | Training loss: 0.6880710248677235
Epoch: 72 | Iteration number: [540/565] 95% | Training loss: 0.6880404725118919
Epoch: 72 | Iteration number: [550/565] 97% | Training loss: 0.6880173627896743
Epoch: 72 | Iteration number: [560/565] 99% | Training loss: 0.6880032573427473

 End of epoch: 72 | Train Loss: 0.6867748626565511 | Training Time: 90 

 End of epoch: 72 | Eval Loss: 0.6899561030524117 | Evaluating Time: 5 
Epoch: 73 | Iteration number: [10/565] 1% | Training loss: 0.7551579892635345
Epoch: 73 | Iteration number: [20/565] 3% | Training loss: 0.7209222912788391
Epoch: 73 | Iteration number: [30/565] 5% | Training loss: 0.7094756941000621
Epoch: 73 | Iteration number: [40/565] 7% | Training loss: 0.7039939001202583
Epoch: 73 | Iteration number: [50/565] 8% | Training loss: 0.7004578638076783
Epoch: 73 | Iteration number: [60/565] 10% | Training loss: 0.6980766028165817
Epoch: 73 | Iteration number: [70/565] 12% | Training loss: 0.696418218101774
Epoch: 73 | Iteration number: [80/565] 14% | Training loss: 0.6952132180333137
Epoch: 73 | Iteration number: [90/565] 15% | Training loss: 0.6943101598156823
Epoch: 73 | Iteration number: [100/565] 17% | Training loss: 0.6935481804609299
Epoch: 73 | Iteration number: [110/565] 19% | Training loss: 0.6929335241967981
Epoch: 73 | Iteration number: [120/565] 21% | Training loss: 0.6924345428744952
Epoch: 73 | Iteration number: [130/565] 23% | Training loss: 0.6920013134296124
Epoch: 73 | Iteration number: [140/565] 24% | Training loss: 0.6916170980249132
Epoch: 73 | Iteration number: [150/565] 26% | Training loss: 0.6913041150569916
Epoch: 73 | Iteration number: [160/565] 28% | Training loss: 0.6910222105681896
Epoch: 73 | Iteration number: [170/565] 30% | Training loss: 0.6907716551247765
Epoch: 73 | Iteration number: [180/565] 31% | Training loss: 0.6905523200829824
Epoch: 73 | Iteration number: [190/565] 33% | Training loss: 0.6903572452695746
Epoch: 73 | Iteration number: [200/565] 35% | Training loss: 0.6901616495847702
Epoch: 73 | Iteration number: [210/565] 37% | Training loss: 0.6900082761333102
Epoch: 73 | Iteration number: [220/565] 38% | Training loss: 0.689872003143484
Epoch: 73 | Iteration number: [230/565] 40% | Training loss: 0.6897491659807122
Epoch: 73 | Iteration number: [240/565] 42% | Training loss: 0.6896219837168852
Epoch: 73 | Iteration number: [250/565] 44% | Training loss: 0.6895177397727966
Epoch: 73 | Iteration number: [260/565] 46% | Training loss: 0.6894163863017009
Epoch: 73 | Iteration number: [270/565] 47% | Training loss: 0.6893203713275768
Epoch: 73 | Iteration number: [280/565] 49% | Training loss: 0.6892331593802997
Epoch: 73 | Iteration number: [290/565] 51% | Training loss: 0.6891413146051867
Epoch: 73 | Iteration number: [300/565] 53% | Training loss: 0.6890628719329834
Epoch: 73 | Iteration number: [310/565] 54% | Training loss: 0.6889799156496602
Epoch: 73 | Iteration number: [320/565] 56% | Training loss: 0.6889230627566576
Epoch: 73 | Iteration number: [330/565] 58% | Training loss: 0.6888505030762065
Epoch: 73 | Iteration number: [340/565] 60% | Training loss: 0.6887792697724174
Epoch: 73 | Iteration number: [350/565] 61% | Training loss: 0.6887180398191725
Epoch: 73 | Iteration number: [360/565] 63% | Training loss: 0.6886633929279116
Epoch: 73 | Iteration number: [370/565] 65% | Training loss: 0.6886123971359149
Epoch: 73 | Iteration number: [380/565] 67% | Training loss: 0.68854957348422
Epoch: 73 | Iteration number: [390/565] 69% | Training loss: 0.6885016852464432
Epoch: 73 | Iteration number: [400/565] 70% | Training loss: 0.6884535059332848
Epoch: 73 | Iteration number: [410/565] 72% | Training loss: 0.6884217596635586
Epoch: 73 | Iteration number: [420/565] 74% | Training loss: 0.6883772813138508
Epoch: 73 | Iteration number: [430/565] 76% | Training loss: 0.6883420479852099
Epoch: 73 | Iteration number: [440/565] 77% | Training loss: 0.6883050432259387
Epoch: 73 | Iteration number: [450/565] 79% | Training loss: 0.6882709295219845
Epoch: 73 | Iteration number: [460/565] 81% | Training loss: 0.6882420420646668
Epoch: 73 | Iteration number: [470/565] 83% | Training loss: 0.6882112846729603
Epoch: 73 | Iteration number: [480/565] 84% | Training loss: 0.6881895573188861
Epoch: 73 | Iteration number: [490/565] 86% | Training loss: 0.6881625888298969
Epoch: 73 | Iteration number: [500/565] 88% | Training loss: 0.6881398638486862
Epoch: 73 | Iteration number: [510/565] 90% | Training loss: 0.688119212435741
Epoch: 73 | Iteration number: [520/565] 92% | Training loss: 0.6880938062301049
Epoch: 73 | Iteration number: [530/565] 93% | Training loss: 0.6880708974487376
Epoch: 73 | Iteration number: [540/565] 95% | Training loss: 0.6880458534867675
Epoch: 73 | Iteration number: [550/565] 97% | Training loss: 0.6880330900712447
Epoch: 73 | Iteration number: [560/565] 99% | Training loss: 0.688013215043715

 End of epoch: 73 | Train Loss: 0.6867818930507761 | Training Time: 89 

 End of epoch: 73 | Eval Loss: 0.6899316821779523 | Evaluating Time: 6 
Epoch: 74 | Iteration number: [10/565] 1% | Training loss: 0.7559653580188751
Epoch: 74 | Iteration number: [20/565] 3% | Training loss: 0.7213669329881668
Epoch: 74 | Iteration number: [30/565] 5% | Training loss: 0.7099838793277741
Epoch: 74 | Iteration number: [40/565] 7% | Training loss: 0.7042127221822738
Epoch: 74 | Iteration number: [50/565] 8% | Training loss: 0.7006497776508331
Epoch: 74 | Iteration number: [60/565] 10% | Training loss: 0.6983458658059438
Epoch: 74 | Iteration number: [70/565] 12% | Training loss: 0.6967443074498858
Epoch: 74 | Iteration number: [80/565] 14% | Training loss: 0.6954861752688885
Epoch: 74 | Iteration number: [90/565] 15% | Training loss: 0.694564069641961
Epoch: 74 | Iteration number: [100/565] 17% | Training loss: 0.6937811380624771
Epoch: 74 | Iteration number: [110/565] 19% | Training loss: 0.6931648097255013
Epoch: 74 | Iteration number: [120/565] 21% | Training loss: 0.6926485404372216
Epoch: 74 | Iteration number: [130/565] 23% | Training loss: 0.6922151505947113
Epoch: 74 | Iteration number: [140/565] 24% | Training loss: 0.691834871683802
Epoch: 74 | Iteration number: [150/565] 26% | Training loss: 0.6914870377381642
Epoch: 74 | Iteration number: [160/565] 28% | Training loss: 0.6912230774760246
Epoch: 74 | Iteration number: [170/565] 30% | Training loss: 0.6909518105142257
Epoch: 74 | Iteration number: [180/565] 31% | Training loss: 0.6907083057694965
Epoch: 74 | Iteration number: [190/565] 33% | Training loss: 0.690505585231279
Epoch: 74 | Iteration number: [200/565] 35% | Training loss: 0.6903460788726806
Epoch: 74 | Iteration number: [210/565] 37% | Training loss: 0.6901587982972462
Epoch: 74 | Iteration number: [220/565] 38% | Training loss: 0.6899893611669541
Epoch: 74 | Iteration number: [230/565] 40% | Training loss: 0.6898704026056373
Epoch: 74 | Iteration number: [240/565] 42% | Training loss: 0.689728832244873
Epoch: 74 | Iteration number: [250/565] 44% | Training loss: 0.6896258964538574
Epoch: 74 | Iteration number: [260/565] 46% | Training loss: 0.6895039264972394
Epoch: 74 | Iteration number: [270/565] 47% | Training loss: 0.689417158012037
Epoch: 74 | Iteration number: [280/565] 49% | Training loss: 0.6893259080392974
Epoch: 74 | Iteration number: [290/565] 51% | Training loss: 0.6892246042859965
Epoch: 74 | Iteration number: [300/565] 53% | Training loss: 0.6891354022423426
Epoch: 74 | Iteration number: [310/565] 54% | Training loss: 0.6890531089998061
Epoch: 74 | Iteration number: [320/565] 56% | Training loss: 0.6889851612970233
Epoch: 74 | Iteration number: [330/565] 58% | Training loss: 0.6889201155214598
Epoch: 74 | Iteration number: [340/565] 60% | Training loss: 0.6888674522147459
Epoch: 74 | Iteration number: [350/565] 61% | Training loss: 0.6888052240439824
Epoch: 74 | Iteration number: [360/565] 63% | Training loss: 0.6887515568070941
Epoch: 74 | Iteration number: [370/565] 65% | Training loss: 0.6886911157015208
Epoch: 74 | Iteration number: [380/565] 67% | Training loss: 0.6886222196252723
Epoch: 74 | Iteration number: [390/565] 69% | Training loss: 0.688574826106047
Epoch: 74 | Iteration number: [400/565] 70% | Training loss: 0.6885198758542538
Epoch: 74 | Iteration number: [410/565] 72% | Training loss: 0.688479625015724
Epoch: 74 | Iteration number: [420/565] 74% | Training loss: 0.6884420037269592
Epoch: 74 | Iteration number: [430/565] 76% | Training loss: 0.6883975544641184
Epoch: 74 | Iteration number: [440/565] 77% | Training loss: 0.6883602235804904
Epoch: 74 | Iteration number: [450/565] 79% | Training loss: 0.6883224134975009
Epoch: 74 | Iteration number: [460/565] 81% | Training loss: 0.6882924503606299
Epoch: 74 | Iteration number: [470/565] 83% | Training loss: 0.6882588197576239
Epoch: 74 | Iteration number: [480/565] 84% | Training loss: 0.688236532608668
Epoch: 74 | Iteration number: [490/565] 86% | Training loss: 0.6882060272353036
Epoch: 74 | Iteration number: [500/565] 88% | Training loss: 0.6881774446964264
Epoch: 74 | Iteration number: [510/565] 90% | Training loss: 0.6881551127807767
Epoch: 74 | Iteration number: [520/565] 92% | Training loss: 0.688122688119228
Epoch: 74 | Iteration number: [530/565] 93% | Training loss: 0.6880950534118796
Epoch: 74 | Iteration number: [540/565] 95% | Training loss: 0.6880612462759018
Epoch: 74 | Iteration number: [550/565] 97% | Training loss: 0.6880408134243705
Epoch: 74 | Iteration number: [560/565] 99% | Training loss: 0.688031911530665

 End of epoch: 74 | Train Loss: 0.686810497900026 | Training Time: 89 

 End of epoch: 74 | Eval Loss: 0.6897943701062884 | Evaluating Time: 6 
Epoch: 75 | Iteration number: [10/565] 1% | Training loss: 0.7554647624492645
Epoch: 75 | Iteration number: [20/565] 3% | Training loss: 0.7210613459348678
Epoch: 75 | Iteration number: [30/565] 5% | Training loss: 0.7096133867899577
Epoch: 75 | Iteration number: [40/565] 7% | Training loss: 0.7039754405617714
Epoch: 75 | Iteration number: [50/565] 8% | Training loss: 0.70051806807518
Epoch: 75 | Iteration number: [60/565] 10% | Training loss: 0.6982725024223327
Epoch: 75 | Iteration number: [70/565] 12% | Training loss: 0.6966502785682678
Epoch: 75 | Iteration number: [80/565] 14% | Training loss: 0.6954173803329468
Epoch: 75 | Iteration number: [90/565] 15% | Training loss: 0.694476083252165
Epoch: 75 | Iteration number: [100/565] 17% | Training loss: 0.6937401521205903
Epoch: 75 | Iteration number: [110/565] 19% | Training loss: 0.693079776655544
Epoch: 75 | Iteration number: [120/565] 21% | Training loss: 0.6925352483987808
Epoch: 75 | Iteration number: [130/565] 23% | Training loss: 0.6921050543968494
Epoch: 75 | Iteration number: [140/565] 24% | Training loss: 0.6917058114494596
Epoch: 75 | Iteration number: [150/565] 26% | Training loss: 0.6913849421342214
Epoch: 75 | Iteration number: [160/565] 28% | Training loss: 0.6910991623997689
Epoch: 75 | Iteration number: [170/565] 30% | Training loss: 0.6908695596105913
Epoch: 75 | Iteration number: [180/565] 31% | Training loss: 0.6906582474708557
Epoch: 75 | Iteration number: [190/565] 33% | Training loss: 0.6904489078019794
Epoch: 75 | Iteration number: [200/565] 35% | Training loss: 0.6902677538990974
Epoch: 75 | Iteration number: [210/565] 37% | Training loss: 0.690089803366434
Epoch: 75 | Iteration number: [220/565] 38% | Training loss: 0.6899359231645411
Epoch: 75 | Iteration number: [230/565] 40% | Training loss: 0.6897873932900636
Epoch: 75 | Iteration number: [240/565] 42% | Training loss: 0.6896662068863709
Epoch: 75 | Iteration number: [250/565] 44% | Training loss: 0.6895497391223907
Epoch: 75 | Iteration number: [260/565] 46% | Training loss: 0.689437261911539
Epoch: 75 | Iteration number: [270/565] 47% | Training loss: 0.6893437045591849
Epoch: 75 | Iteration number: [280/565] 49% | Training loss: 0.689257947249072
Epoch: 75 | Iteration number: [290/565] 51% | Training loss: 0.68917085672247
Epoch: 75 | Iteration number: [300/565] 53% | Training loss: 0.689082969625791
Epoch: 75 | Iteration number: [310/565] 54% | Training loss: 0.6890057807968509
Epoch: 75 | Iteration number: [320/565] 56% | Training loss: 0.688939101062715
Epoch: 75 | Iteration number: [330/565] 58% | Training loss: 0.6888608959588137
Epoch: 75 | Iteration number: [340/565] 60% | Training loss: 0.6888044359052883
Epoch: 75 | Iteration number: [350/565] 61% | Training loss: 0.6887535980769566
Epoch: 75 | Iteration number: [360/565] 63% | Training loss: 0.6887010071012709
Epoch: 75 | Iteration number: [370/565] 65% | Training loss: 0.6886489275339488
Epoch: 75 | Iteration number: [380/565] 67% | Training loss: 0.6886007216415907
Epoch: 75 | Iteration number: [390/565] 69% | Training loss: 0.6885478845009437
Epoch: 75 | Iteration number: [400/565] 70% | Training loss: 0.6884881690144539
Epoch: 75 | Iteration number: [410/565] 72% | Training loss: 0.6884451571034222
Epoch: 75 | Iteration number: [420/565] 74% | Training loss: 0.6884038374537513
Epoch: 75 | Iteration number: [430/565] 76% | Training loss: 0.6883571943571402
Epoch: 75 | Iteration number: [440/565] 77% | Training loss: 0.6883241760459813
Epoch: 75 | Iteration number: [450/565] 79% | Training loss: 0.6882884926266141
Epoch: 75 | Iteration number: [460/565] 81% | Training loss: 0.6882664806169012
Epoch: 75 | Iteration number: [470/565] 83% | Training loss: 0.6882293767117439
Epoch: 75 | Iteration number: [480/565] 84% | Training loss: 0.6882059302181005
Epoch: 75 | Iteration number: [490/565] 86% | Training loss: 0.6881783215367064
Epoch: 75 | Iteration number: [500/565] 88% | Training loss: 0.6881416082382202
Epoch: 75 | Iteration number: [510/565] 90% | Training loss: 0.6881094899832033
Epoch: 75 | Iteration number: [520/565] 92% | Training loss: 0.6880878706391041
Epoch: 75 | Iteration number: [530/565] 93% | Training loss: 0.6880613683529619
Epoch: 75 | Iteration number: [540/565] 95% | Training loss: 0.6880419063347357
Epoch: 75 | Iteration number: [550/565] 97% | Training loss: 0.6880190005085685
Epoch: 75 | Iteration number: [560/565] 99% | Training loss: 0.6880023380475385

 End of epoch: 75 | Train Loss: 0.6867797731298261 | Training Time: 88 

 End of epoch: 75 | Eval Loss: 0.6896656325885228 | Evaluating Time: 6 
Epoch: 76 | Iteration number: [10/565] 1% | Training loss: 0.7552899241447448
Epoch: 76 | Iteration number: [20/565] 3% | Training loss: 0.7212503910064697
Epoch: 76 | Iteration number: [30/565] 5% | Training loss: 0.7095708429813385
Epoch: 76 | Iteration number: [40/565] 7% | Training loss: 0.7038830533623696
Epoch: 76 | Iteration number: [50/565] 8% | Training loss: 0.7004191195964813
Epoch: 76 | Iteration number: [60/565] 10% | Training loss: 0.6981337676445644
Epoch: 76 | Iteration number: [70/565] 12% | Training loss: 0.6965085029602051
Epoch: 76 | Iteration number: [80/565] 14% | Training loss: 0.6953280866146088
Epoch: 76 | Iteration number: [90/565] 15% | Training loss: 0.6943961944844987
Epoch: 76 | Iteration number: [100/565] 17% | Training loss: 0.6936784297227859
Epoch: 76 | Iteration number: [110/565] 19% | Training loss: 0.6930658660151742
Epoch: 76 | Iteration number: [120/565] 21% | Training loss: 0.6925369809071223
Epoch: 76 | Iteration number: [130/565] 23% | Training loss: 0.6920965928297776
Epoch: 76 | Iteration number: [140/565] 24% | Training loss: 0.6917356899806432
Epoch: 76 | Iteration number: [150/565] 26% | Training loss: 0.6913882271448771
Epoch: 76 | Iteration number: [160/565] 28% | Training loss: 0.6911051325500012
Epoch: 76 | Iteration number: [170/565] 30% | Training loss: 0.6908320469014785
Epoch: 76 | Iteration number: [180/565] 31% | Training loss: 0.6906082000997331
Epoch: 76 | Iteration number: [190/565] 33% | Training loss: 0.6903941716018476
Epoch: 76 | Iteration number: [200/565] 35% | Training loss: 0.6901849782466889
Epoch: 76 | Iteration number: [210/565] 37% | Training loss: 0.6900453700905754
Epoch: 76 | Iteration number: [220/565] 38% | Training loss: 0.6898883686824279
Epoch: 76 | Iteration number: [230/565] 40% | Training loss: 0.689764935814816
Epoch: 76 | Iteration number: [240/565] 42% | Training loss: 0.6896403670310974
Epoch: 76 | Iteration number: [250/565] 44% | Training loss: 0.6895269999504089
Epoch: 76 | Iteration number: [260/565] 46% | Training loss: 0.6894294931338384
Epoch: 76 | Iteration number: [270/565] 47% | Training loss: 0.6893228758264471
Epoch: 76 | Iteration number: [280/565] 49% | Training loss: 0.6892454215458461
Epoch: 76 | Iteration number: [290/565] 51% | Training loss: 0.6891761714014514
Epoch: 76 | Iteration number: [300/565] 53% | Training loss: 0.6891000878810882
Epoch: 76 | Iteration number: [310/565] 54% | Training loss: 0.6890213093449993
Epoch: 76 | Iteration number: [320/565] 56% | Training loss: 0.688960537314415
Epoch: 76 | Iteration number: [330/565] 58% | Training loss: 0.6888918943477399
Epoch: 76 | Iteration number: [340/565] 60% | Training loss: 0.6888325631618499
Epoch: 76 | Iteration number: [350/565] 61% | Training loss: 0.6887728100163596
Epoch: 76 | Iteration number: [360/565] 63% | Training loss: 0.6886977318260404
Epoch: 76 | Iteration number: [370/565] 65% | Training loss: 0.6886259837730511
Epoch: 76 | Iteration number: [380/565] 67% | Training loss: 0.6885814520873521
Epoch: 76 | Iteration number: [390/565] 69% | Training loss: 0.6885213897778437
Epoch: 76 | Iteration number: [400/565] 70% | Training loss: 0.688472933024168
Epoch: 76 | Iteration number: [410/565] 72% | Training loss: 0.6884300838156444
Epoch: 76 | Iteration number: [420/565] 74% | Training loss: 0.6883872490553629
Epoch: 76 | Iteration number: [430/565] 76% | Training loss: 0.6883557372314986
Epoch: 76 | Iteration number: [440/565] 77% | Training loss: 0.6883226222612641
Epoch: 76 | Iteration number: [450/565] 79% | Training loss: 0.6882911041047838
Epoch: 76 | Iteration number: [460/565] 81% | Training loss: 0.6882493999989137
Epoch: 76 | Iteration number: [470/565] 83% | Training loss: 0.6882197574098059
Epoch: 76 | Iteration number: [480/565] 84% | Training loss: 0.6881905393054087
Epoch: 76 | Iteration number: [490/565] 86% | Training loss: 0.6881660836083549
Epoch: 76 | Iteration number: [500/565] 88% | Training loss: 0.6881428112983704
Epoch: 76 | Iteration number: [510/565] 90% | Training loss: 0.6881232064144284
Epoch: 76 | Iteration number: [520/565] 92% | Training loss: 0.6880928182831177
Epoch: 76 | Iteration number: [530/565] 93% | Training loss: 0.6880656806927807
Epoch: 76 | Iteration number: [540/565] 95% | Training loss: 0.6880437454691639
Epoch: 76 | Iteration number: [550/565] 97% | Training loss: 0.6880281382257288
Epoch: 76 | Iteration number: [560/565] 99% | Training loss: 0.6880046794457095

 End of epoch: 76 | Train Loss: 0.68677459881369 | Training Time: 90 

 End of epoch: 76 | Eval Loss: 0.6891642127718244 | Evaluating Time: 5 
Epoch: 77 | Iteration number: [10/565] 1% | Training loss: 0.7550798177719116
Epoch: 77 | Iteration number: [20/565] 3% | Training loss: 0.720857810974121
Epoch: 77 | Iteration number: [30/565] 5% | Training loss: 0.7093757232030232
Epoch: 77 | Iteration number: [40/565] 7% | Training loss: 0.7038062199950218
Epoch: 77 | Iteration number: [50/565] 8% | Training loss: 0.7005074286460876
Epoch: 77 | Iteration number: [60/565] 10% | Training loss: 0.6982616325219472
Epoch: 77 | Iteration number: [70/565] 12% | Training loss: 0.6965916275978088
Epoch: 77 | Iteration number: [80/565] 14% | Training loss: 0.6954292312264443
Epoch: 77 | Iteration number: [90/565] 15% | Training loss: 0.6944916632440356
Epoch: 77 | Iteration number: [100/565] 17% | Training loss: 0.693715597987175
Epoch: 77 | Iteration number: [110/565] 19% | Training loss: 0.6930861933664842
Epoch: 77 | Iteration number: [120/565] 21% | Training loss: 0.6925428663690885
Epoch: 77 | Iteration number: [130/565] 23% | Training loss: 0.6920745326922491
Epoch: 77 | Iteration number: [140/565] 24% | Training loss: 0.6917108016354697
Epoch: 77 | Iteration number: [150/565] 26% | Training loss: 0.6914017832279206
Epoch: 77 | Iteration number: [160/565] 28% | Training loss: 0.6910963457077741
Epoch: 77 | Iteration number: [170/565] 30% | Training loss: 0.6908255605136647
Epoch: 77 | Iteration number: [180/565] 31% | Training loss: 0.6906232777569029
Epoch: 77 | Iteration number: [190/565] 33% | Training loss: 0.6904526710510254
Epoch: 77 | Iteration number: [200/565] 35% | Training loss: 0.6902540472149848
Epoch: 77 | Iteration number: [210/565] 37% | Training loss: 0.6900628393604642
Epoch: 77 | Iteration number: [220/565] 38% | Training loss: 0.689904417774894
Epoch: 77 | Iteration number: [230/565] 40% | Training loss: 0.6897798359394074
Epoch: 77 | Iteration number: [240/565] 42% | Training loss: 0.6896615393459797
Epoch: 77 | Iteration number: [250/565] 44% | Training loss: 0.6895376777648926
Epoch: 77 | Iteration number: [260/565] 46% | Training loss: 0.6894274466312849
Epoch: 77 | Iteration number: [270/565] 47% | Training loss: 0.6893217832953842
Epoch: 77 | Iteration number: [280/565] 49% | Training loss: 0.6892447399241584
Epoch: 77 | Iteration number: [290/565] 51% | Training loss: 0.6891542927972202
Epoch: 77 | Iteration number: [300/565] 53% | Training loss: 0.6890628451108932
Epoch: 77 | Iteration number: [310/565] 54% | Training loss: 0.6889916802606275
Epoch: 77 | Iteration number: [320/565] 56% | Training loss: 0.6889140782877803
Epoch: 77 | Iteration number: [330/565] 58% | Training loss: 0.6888449242620757
Epoch: 77 | Iteration number: [340/565] 60% | Training loss: 0.6887832848464741
Epoch: 77 | Iteration number: [350/565] 61% | Training loss: 0.6887361281258719
Epoch: 77 | Iteration number: [360/565] 63% | Training loss: 0.6886849199732145
Epoch: 77 | Iteration number: [370/565] 65% | Training loss: 0.6886379435255721
Epoch: 77 | Iteration number: [380/565] 67% | Training loss: 0.6885888982760279
Epoch: 77 | Iteration number: [390/565] 69% | Training loss: 0.6885425092318119
Epoch: 77 | Iteration number: [400/565] 70% | Training loss: 0.6884899586439133
Epoch: 77 | Iteration number: [410/565] 72% | Training loss: 0.6884415782079464
Epoch: 77 | Iteration number: [420/565] 74% | Training loss: 0.6884105642636617
Epoch: 77 | Iteration number: [430/565] 76% | Training loss: 0.6883623536242995
Epoch: 77 | Iteration number: [440/565] 77% | Training loss: 0.6883281959728761
Epoch: 77 | Iteration number: [450/565] 79% | Training loss: 0.6882968615161048
Epoch: 77 | Iteration number: [460/565] 81% | Training loss: 0.6882616619700971
Epoch: 77 | Iteration number: [470/565] 83% | Training loss: 0.6882235624688737
Epoch: 77 | Iteration number: [480/565] 84% | Training loss: 0.6882015701383353
Epoch: 77 | Iteration number: [490/565] 86% | Training loss: 0.6881716854718267
Epoch: 77 | Iteration number: [500/565] 88% | Training loss: 0.6881431214809418
Epoch: 77 | Iteration number: [510/565] 90% | Training loss: 0.688110099586786
Epoch: 77 | Iteration number: [520/565] 92% | Training loss: 0.6880763814999507
Epoch: 77 | Iteration number: [530/565] 93% | Training loss: 0.6880601288012739
Epoch: 77 | Iteration number: [540/565] 95% | Training loss: 0.6880411665748667
Epoch: 77 | Iteration number: [550/565] 97% | Training loss: 0.6880192096666856
Epoch: 77 | Iteration number: [560/565] 99% | Training loss: 0.6880008433546339

 End of epoch: 77 | Train Loss: 0.6867711664301104 | Training Time: 90 

 End of epoch: 77 | Eval Loss: 0.6900076781000409 | Evaluating Time: 6 
Epoch: 78 | Iteration number: [10/565] 1% | Training loss: 0.7549354791641235
Epoch: 78 | Iteration number: [20/565] 3% | Training loss: 0.7208077311515808
Epoch: 78 | Iteration number: [30/565] 5% | Training loss: 0.7095263957977295
Epoch: 78 | Iteration number: [40/565] 7% | Training loss: 0.7038431689143181
Epoch: 78 | Iteration number: [50/565] 8% | Training loss: 0.7004574155807495
Epoch: 78 | Iteration number: [60/565] 10% | Training loss: 0.6982716391483943
Epoch: 78 | Iteration number: [70/565] 12% | Training loss: 0.6966364400727408
Epoch: 78 | Iteration number: [80/565] 14% | Training loss: 0.6953788049519062
Epoch: 78 | Iteration number: [90/565] 15% | Training loss: 0.6944336440828112
Epoch: 78 | Iteration number: [100/565] 17% | Training loss: 0.6936406743526459
Epoch: 78 | Iteration number: [110/565] 19% | Training loss: 0.6930498773401433
Epoch: 78 | Iteration number: [120/565] 21% | Training loss: 0.6925337553024292
Epoch: 78 | Iteration number: [130/565] 23% | Training loss: 0.692136889237624
Epoch: 78 | Iteration number: [140/565] 24% | Training loss: 0.691778695157596
Epoch: 78 | Iteration number: [150/565] 26% | Training loss: 0.6914284388224284
Epoch: 78 | Iteration number: [160/565] 28% | Training loss: 0.6911657806485891
Epoch: 78 | Iteration number: [170/565] 30% | Training loss: 0.690881515601102
Epoch: 78 | Iteration number: [180/565] 31% | Training loss: 0.6906483040915595
Epoch: 78 | Iteration number: [190/565] 33% | Training loss: 0.6904135857757769
Epoch: 78 | Iteration number: [200/565] 35% | Training loss: 0.69022196829319
Epoch: 78 | Iteration number: [210/565] 37% | Training loss: 0.6900555690129598
Epoch: 78 | Iteration number: [220/565] 38% | Training loss: 0.6899131149053573
Epoch: 78 | Iteration number: [230/565] 40% | Training loss: 0.6897723993529444
Epoch: 78 | Iteration number: [240/565] 42% | Training loss: 0.6896352800230185
Epoch: 78 | Iteration number: [250/565] 44% | Training loss: 0.6895263569355011
Epoch: 78 | Iteration number: [260/565] 46% | Training loss: 0.6894214678269166
Epoch: 78 | Iteration number: [270/565] 47% | Training loss: 0.6893249123184769
Epoch: 78 | Iteration number: [280/565] 49% | Training loss: 0.6892192738396781
Epoch: 78 | Iteration number: [290/565] 51% | Training loss: 0.689131523000783
Epoch: 78 | Iteration number: [300/565] 53% | Training loss: 0.6890609528621038
Epoch: 78 | Iteration number: [310/565] 54% | Training loss: 0.6889899051958515
Epoch: 78 | Iteration number: [320/565] 56% | Training loss: 0.6889379797503352
Epoch: 78 | Iteration number: [330/565] 58% | Training loss: 0.6888679005882957
Epoch: 78 | Iteration number: [340/565] 60% | Training loss: 0.688813016519827
Epoch: 78 | Iteration number: [350/565] 61% | Training loss: 0.6887654306207385
Epoch: 78 | Iteration number: [360/565] 63% | Training loss: 0.6887219881018003
Epoch: 78 | Iteration number: [370/565] 65% | Training loss: 0.6886677044468957
Epoch: 78 | Iteration number: [380/565] 67% | Training loss: 0.6886109863456927
Epoch: 78 | Iteration number: [390/565] 69% | Training loss: 0.6885605541559366
Epoch: 78 | Iteration number: [400/565] 70% | Training loss: 0.6885170765221119
Epoch: 78 | Iteration number: [410/565] 72% | Training loss: 0.6884787110293784
Epoch: 78 | Iteration number: [420/565] 74% | Training loss: 0.6884385320402328
Epoch: 78 | Iteration number: [430/565] 76% | Training loss: 0.6883911253407944
Epoch: 78 | Iteration number: [440/565] 77% | Training loss: 0.688349293849685
Epoch: 78 | Iteration number: [450/565] 79% | Training loss: 0.6883195518122779
Epoch: 78 | Iteration number: [460/565] 81% | Training loss: 0.6882841313662736
Epoch: 78 | Iteration number: [470/565] 83% | Training loss: 0.6882537571673698
Epoch: 78 | Iteration number: [480/565] 84% | Training loss: 0.6882186077535153
Epoch: 78 | Iteration number: [490/565] 86% | Training loss: 0.6881832746826873
Epoch: 78 | Iteration number: [500/565] 88% | Training loss: 0.6881568139791489
Epoch: 78 | Iteration number: [510/565] 90% | Training loss: 0.6881337099215563
Epoch: 78 | Iteration number: [520/565] 92% | Training loss: 0.6881076637368936
Epoch: 78 | Iteration number: [530/565] 93% | Training loss: 0.6880801190745156
Epoch: 78 | Iteration number: [540/565] 95% | Training loss: 0.6880502995517519
Epoch: 78 | Iteration number: [550/565] 97% | Training loss: 0.6880185516314073
Epoch: 78 | Iteration number: [560/565] 99% | Training loss: 0.6879928610154561

 End of epoch: 78 | Train Loss: 0.6867714310114362 | Training Time: 88 

 End of epoch: 78 | Eval Loss: 0.6898073894636971 | Evaluating Time: 5 
Epoch: 79 | Iteration number: [10/565] 1% | Training loss: 0.755546897649765
Epoch: 79 | Iteration number: [20/565] 3% | Training loss: 0.721248260140419
Epoch: 79 | Iteration number: [30/565] 5% | Training loss: 0.7096721847852071
Epoch: 79 | Iteration number: [40/565] 7% | Training loss: 0.7040038198232651
Epoch: 79 | Iteration number: [50/565] 8% | Training loss: 0.7005190169811248
Epoch: 79 | Iteration number: [60/565] 10% | Training loss: 0.698250025510788
Epoch: 79 | Iteration number: [70/565] 12% | Training loss: 0.6966056253228868
Epoch: 79 | Iteration number: [80/565] 14% | Training loss: 0.6953577913343907
Epoch: 79 | Iteration number: [90/565] 15% | Training loss: 0.6944420609209273
Epoch: 79 | Iteration number: [100/565] 17% | Training loss: 0.6937203234434128
Epoch: 79 | Iteration number: [110/565] 19% | Training loss: 0.6930741467259147
Epoch: 79 | Iteration number: [120/565] 21% | Training loss: 0.6925875176986058
Epoch: 79 | Iteration number: [130/565] 23% | Training loss: 0.6921498014376714
Epoch: 79 | Iteration number: [140/565] 24% | Training loss: 0.6917912683316639
Epoch: 79 | Iteration number: [150/565] 26% | Training loss: 0.6914667960007985
Epoch: 79 | Iteration number: [160/565] 28% | Training loss: 0.6911816392093897
Epoch: 79 | Iteration number: [170/565] 30% | Training loss: 0.6909352709265316
Epoch: 79 | Iteration number: [180/565] 31% | Training loss: 0.6907243192195892
Epoch: 79 | Iteration number: [190/565] 33% | Training loss: 0.6905137931045733
Epoch: 79 | Iteration number: [200/565] 35% | Training loss: 0.6903117987513542
Epoch: 79 | Iteration number: [210/565] 37% | Training loss: 0.6901445672625587
Epoch: 79 | Iteration number: [220/565] 38% | Training loss: 0.6900135205550627
Epoch: 79 | Iteration number: [230/565] 40% | Training loss: 0.6898740641448808
Epoch: 79 | Iteration number: [240/565] 42% | Training loss: 0.6897459618747235
Epoch: 79 | Iteration number: [250/565] 44% | Training loss: 0.6896384546756744
Epoch: 79 | Iteration number: [260/565] 46% | Training loss: 0.6895190486541161
Epoch: 79 | Iteration number: [270/565] 47% | Training loss: 0.6893955990120216
Epoch: 79 | Iteration number: [280/565] 49% | Training loss: 0.6892979174852372
Epoch: 79 | Iteration number: [290/565] 51% | Training loss: 0.6892147935669998
Epoch: 79 | Iteration number: [300/565] 53% | Training loss: 0.6891276639699936
Epoch: 79 | Iteration number: [310/565] 54% | Training loss: 0.6890475003950057
Epoch: 79 | Iteration number: [320/565] 56% | Training loss: 0.6889695506542921
Epoch: 79 | Iteration number: [330/565] 58% | Training loss: 0.6889048079649608
Epoch: 79 | Iteration number: [340/565] 60% | Training loss: 0.6888473980567035
Epoch: 79 | Iteration number: [350/565] 61% | Training loss: 0.6887822079658509
Epoch: 79 | Iteration number: [360/565] 63% | Training loss: 0.6887228300174077
Epoch: 79 | Iteration number: [370/565] 65% | Training loss: 0.6886736608840324
Epoch: 79 | Iteration number: [380/565] 67% | Training loss: 0.6886224163206001
Epoch: 79 | Iteration number: [390/565] 69% | Training loss: 0.688575533261666
Epoch: 79 | Iteration number: [400/565] 70% | Training loss: 0.688512315005064
Epoch: 79 | Iteration number: [410/565] 72% | Training loss: 0.6884731859695621
Epoch: 79 | Iteration number: [420/565] 74% | Training loss: 0.6884181874138968
Epoch: 79 | Iteration number: [430/565] 76% | Training loss: 0.6883794808110525
Epoch: 79 | Iteration number: [440/565] 77% | Training loss: 0.6883359923958778
Epoch: 79 | Iteration number: [450/565] 79% | Training loss: 0.6883029793368446
Epoch: 79 | Iteration number: [460/565] 81% | Training loss: 0.6882755337849907
Epoch: 79 | Iteration number: [470/565] 83% | Training loss: 0.6882389738204632
Epoch: 79 | Iteration number: [480/565] 84% | Training loss: 0.6882115438580513
Epoch: 79 | Iteration number: [490/565] 86% | Training loss: 0.6881887613510599
Epoch: 79 | Iteration number: [500/565] 88% | Training loss: 0.688157208442688
Epoch: 79 | Iteration number: [510/565] 90% | Training loss: 0.6881300168878892
Epoch: 79 | Iteration number: [520/565] 92% | Training loss: 0.6881038689842591
Epoch: 79 | Iteration number: [530/565] 93% | Training loss: 0.6880812440278395
Epoch: 79 | Iteration number: [540/565] 95% | Training loss: 0.688061703686361
Epoch: 79 | Iteration number: [550/565] 97% | Training loss: 0.6880266430161216
Epoch: 79 | Iteration number: [560/565] 99% | Training loss: 0.6880025082400867

 End of epoch: 79 | Train Loss: 0.686769922961176 | Training Time: 88 

 End of epoch: 79 | Eval Loss: 0.6899045194898333 | Evaluating Time: 6 
Epoch: 80 | Iteration number: [10/565] 1% | Training loss: 0.7559281408786773
Epoch: 80 | Iteration number: [20/565] 3% | Training loss: 0.7214326322078705
Epoch: 80 | Iteration number: [30/565] 5% | Training loss: 0.7097761293252309
Epoch: 80 | Iteration number: [40/565] 7% | Training loss: 0.704075326025486
Epoch: 80 | Iteration number: [50/565] 8% | Training loss: 0.7006867825984955
Epoch: 80 | Iteration number: [60/565] 10% | Training loss: 0.6983374138673146
Epoch: 80 | Iteration number: [70/565] 12% | Training loss: 0.6966917778764452
Epoch: 80 | Iteration number: [80/565] 14% | Training loss: 0.6954577691853047
Epoch: 80 | Iteration number: [90/565] 15% | Training loss: 0.6944691439469656
Epoch: 80 | Iteration number: [100/565] 17% | Training loss: 0.6937425512075425
Epoch: 80 | Iteration number: [110/565] 19% | Training loss: 0.6930924388495359
Epoch: 80 | Iteration number: [120/565] 21% | Training loss: 0.6925639629364013
Epoch: 80 | Iteration number: [130/565] 23% | Training loss: 0.6921194704679342
Epoch: 80 | Iteration number: [140/565] 24% | Training loss: 0.6917140334844589
Epoch: 80 | Iteration number: [150/565] 26% | Training loss: 0.6914176595211029
Epoch: 80 | Iteration number: [160/565] 28% | Training loss: 0.6911061152815818
Epoch: 80 | Iteration number: [170/565] 30% | Training loss: 0.6908662308664882
Epoch: 80 | Iteration number: [180/565] 31% | Training loss: 0.690635523531172
Epoch: 80 | Iteration number: [190/565] 33% | Training loss: 0.690432674006412
Epoch: 80 | Iteration number: [200/565] 35% | Training loss: 0.690236110985279
Epoch: 80 | Iteration number: [210/565] 37% | Training loss: 0.6900723111061823
Epoch: 80 | Iteration number: [220/565] 38% | Training loss: 0.689920755408027
Epoch: 80 | Iteration number: [230/565] 40% | Training loss: 0.6897722042125204
Epoch: 80 | Iteration number: [240/565] 42% | Training loss: 0.6896568454802037
Epoch: 80 | Iteration number: [250/565] 44% | Training loss: 0.6895615525245666
Epoch: 80 | Iteration number: [260/565] 46% | Training loss: 0.6894540174649312
Epoch: 80 | Iteration number: [270/565] 47% | Training loss: 0.6893364678930354
Epoch: 80 | Iteration number: [280/565] 49% | Training loss: 0.6892361647316387
Epoch: 80 | Iteration number: [290/565] 51% | Training loss: 0.689154099801491
Epoch: 80 | Iteration number: [300/565] 53% | Training loss: 0.6890653810898463
Epoch: 80 | Iteration number: [310/565] 54% | Training loss: 0.6889993344583819
Epoch: 80 | Iteration number: [320/565] 56% | Training loss: 0.6889309341087937
Epoch: 80 | Iteration number: [330/565] 58% | Training loss: 0.6888764724586949
Epoch: 80 | Iteration number: [340/565] 60% | Training loss: 0.6888213594170177
Epoch: 80 | Iteration number: [350/565] 61% | Training loss: 0.6887586769035884
Epoch: 80 | Iteration number: [360/565] 63% | Training loss: 0.6886928071578343
Epoch: 80 | Iteration number: [370/565] 65% | Training loss: 0.6886402903376398
Epoch: 80 | Iteration number: [380/565] 67% | Training loss: 0.688590953381438
Epoch: 80 | Iteration number: [390/565] 69% | Training loss: 0.688543243591602
Epoch: 80 | Iteration number: [400/565] 70% | Training loss: 0.6884980870783329
Epoch: 80 | Iteration number: [410/565] 72% | Training loss: 0.6884403252020115
Epoch: 80 | Iteration number: [420/565] 74% | Training loss: 0.6884050365005221
Epoch: 80 | Iteration number: [430/565] 76% | Training loss: 0.6883657785349114
Epoch: 80 | Iteration number: [440/565] 77% | Training loss: 0.6883217747915875
Epoch: 80 | Iteration number: [450/565] 79% | Training loss: 0.6882888241608938
Epoch: 80 | Iteration number: [460/565] 81% | Training loss: 0.6882649715827859
Epoch: 80 | Iteration number: [470/565] 83% | Training loss: 0.6882334903199622
Epoch: 80 | Iteration number: [480/565] 84% | Training loss: 0.6882029800365369
Epoch: 80 | Iteration number: [490/565] 86% | Training loss: 0.6881708264350891
Epoch: 80 | Iteration number: [500/565] 88% | Training loss: 0.6881471871137619
Epoch: 80 | Iteration number: [510/565] 90% | Training loss: 0.6881203420021955
Epoch: 80 | Iteration number: [520/565] 92% | Training loss: 0.6880884275986598
Epoch: 80 | Iteration number: [530/565] 93% | Training loss: 0.6880595311803638
Epoch: 80 | Iteration number: [540/565] 95% | Training loss: 0.6880366575938685
Epoch: 80 | Iteration number: [550/565] 97% | Training loss: 0.6880163550376892
Epoch: 80 | Iteration number: [560/565] 99% | Training loss: 0.6879924493176597

 End of epoch: 80 | Train Loss: 0.6867767250643367 | Training Time: 88 

 End of epoch: 80 | Eval Loss: 0.6894367252077375 | Evaluating Time: 6 
Epoch: 81 | Iteration number: [10/565] 1% | Training loss: 0.7554568529129029
Epoch: 81 | Iteration number: [20/565] 3% | Training loss: 0.7211487263441085
Epoch: 81 | Iteration number: [30/565] 5% | Training loss: 0.7097028195858002
Epoch: 81 | Iteration number: [40/565] 7% | Training loss: 0.7039424300193786
Epoch: 81 | Iteration number: [50/565] 8% | Training loss: 0.7005670070648193
Epoch: 81 | Iteration number: [60/565] 10% | Training loss: 0.6981876611709594
Epoch: 81 | Iteration number: [70/565] 12% | Training loss: 0.6966090210846492
Epoch: 81 | Iteration number: [80/565] 14% | Training loss: 0.6954109854996204
Epoch: 81 | Iteration number: [90/565] 15% | Training loss: 0.6944862504800161
Epoch: 81 | Iteration number: [100/565] 17% | Training loss: 0.693726058602333
Epoch: 81 | Iteration number: [110/565] 19% | Training loss: 0.6930588630112735
Epoch: 81 | Iteration number: [120/565] 21% | Training loss: 0.6925175189971924
Epoch: 81 | Iteration number: [130/565] 23% | Training loss: 0.692074580834462
Epoch: 81 | Iteration number: [140/565] 24% | Training loss: 0.6916884375470025
Epoch: 81 | Iteration number: [150/565] 26% | Training loss: 0.6913583914438883
Epoch: 81 | Iteration number: [160/565] 28% | Training loss: 0.6910655066370964
Epoch: 81 | Iteration number: [170/565] 30% | Training loss: 0.6908144035760094
Epoch: 81 | Iteration number: [180/565] 31% | Training loss: 0.6905582848522398
Epoch: 81 | Iteration number: [190/565] 33% | Training loss: 0.6903550129187734
Epoch: 81 | Iteration number: [200/565] 35% | Training loss: 0.6901764678955078
Epoch: 81 | Iteration number: [210/565] 37% | Training loss: 0.6900262602737972
Epoch: 81 | Iteration number: [220/565] 38% | Training loss: 0.6898725141178478
Epoch: 81 | Iteration number: [230/565] 40% | Training loss: 0.6897565243036851
Epoch: 81 | Iteration number: [240/565] 42% | Training loss: 0.6896471994618575
Epoch: 81 | Iteration number: [250/565] 44% | Training loss: 0.6895183546543121
Epoch: 81 | Iteration number: [260/565] 46% | Training loss: 0.689409938454628
Epoch: 81 | Iteration number: [270/565] 47% | Training loss: 0.6893093956841363
Epoch: 81 | Iteration number: [280/565] 49% | Training loss: 0.6891995451280049
Epoch: 81 | Iteration number: [290/565] 51% | Training loss: 0.6891188452983724
Epoch: 81 | Iteration number: [300/565] 53% | Training loss: 0.6890390950441361
Epoch: 81 | Iteration number: [310/565] 54% | Training loss: 0.68896348860956
Epoch: 81 | Iteration number: [320/565] 56% | Training loss: 0.6888917477801442
Epoch: 81 | Iteration number: [330/565] 58% | Training loss: 0.6888321459293365
Epoch: 81 | Iteration number: [340/565] 60% | Training loss: 0.6887798891347997
Epoch: 81 | Iteration number: [350/565] 61% | Training loss: 0.6887223953860147
Epoch: 81 | Iteration number: [360/565] 63% | Training loss: 0.6886561317576303
Epoch: 81 | Iteration number: [370/565] 65% | Training loss: 0.6886108923602748
Epoch: 81 | Iteration number: [380/565] 67% | Training loss: 0.6885657837516383
Epoch: 81 | Iteration number: [390/565] 69% | Training loss: 0.6885172073657696
Epoch: 81 | Iteration number: [400/565] 70% | Training loss: 0.6884741422533989
Epoch: 81 | Iteration number: [410/565] 72% | Training loss: 0.6884430486981462
Epoch: 81 | Iteration number: [420/565] 74% | Training loss: 0.6884071018014636
Epoch: 81 | Iteration number: [430/565] 76% | Training loss: 0.6883671003718709
Epoch: 81 | Iteration number: [440/565] 77% | Training loss: 0.6883266123858365
Epoch: 81 | Iteration number: [450/565] 79% | Training loss: 0.6882867838276757
Epoch: 81 | Iteration number: [460/565] 81% | Training loss: 0.6882493748613026
Epoch: 81 | Iteration number: [470/565] 83% | Training loss: 0.6882299656563616
Epoch: 81 | Iteration number: [480/565] 84% | Training loss: 0.6882041431963444
Epoch: 81 | Iteration number: [490/565] 86% | Training loss: 0.6881686213065167
Epoch: 81 | Iteration number: [500/565] 88% | Training loss: 0.6881410388946533
Epoch: 81 | Iteration number: [510/565] 90% | Training loss: 0.6881203615197948
Epoch: 81 | Iteration number: [520/565] 92% | Training loss: 0.6881022258446767
Epoch: 81 | Iteration number: [530/565] 93% | Training loss: 0.6880824823424502
Epoch: 81 | Iteration number: [540/565] 95% | Training loss: 0.6880600034086792
Epoch: 81 | Iteration number: [550/565] 97% | Training loss: 0.6880325409499082
Epoch: 81 | Iteration number: [560/565] 99% | Training loss: 0.6880071893334389

 End of epoch: 81 | Train Loss: 0.686781707907145 | Training Time: 90 

 End of epoch: 81 | Eval Loss: 0.689739099570683 | Evaluating Time: 6 
Epoch: 82 | Iteration number: [10/565] 1% | Training loss: 0.7553180694580078
Epoch: 82 | Iteration number: [20/565] 3% | Training loss: 0.7212443739175797
Epoch: 82 | Iteration number: [30/565] 5% | Training loss: 0.7098035355408986
Epoch: 82 | Iteration number: [40/565] 7% | Training loss: 0.7040211349725723
Epoch: 82 | Iteration number: [50/565] 8% | Training loss: 0.7005889940261841
Epoch: 82 | Iteration number: [60/565] 10% | Training loss: 0.6982872674862544
Epoch: 82 | Iteration number: [70/565] 12% | Training loss: 0.6965881168842316
Epoch: 82 | Iteration number: [80/565] 14% | Training loss: 0.6953309684991836
Epoch: 82 | Iteration number: [90/565] 15% | Training loss: 0.6943879240088993
Epoch: 82 | Iteration number: [100/565] 17% | Training loss: 0.6936286115646362
Epoch: 82 | Iteration number: [110/565] 19% | Training loss: 0.692993085492741
Epoch: 82 | Iteration number: [120/565] 21% | Training loss: 0.692529774705569
Epoch: 82 | Iteration number: [130/565] 23% | Training loss: 0.6921238683737241
Epoch: 82 | Iteration number: [140/565] 24% | Training loss: 0.6917305448225566
Epoch: 82 | Iteration number: [150/565] 26% | Training loss: 0.6914242752393087
Epoch: 82 | Iteration number: [160/565] 28% | Training loss: 0.6911078944802285
Epoch: 82 | Iteration number: [170/565] 30% | Training loss: 0.6908667750218336
Epoch: 82 | Iteration number: [180/565] 31% | Training loss: 0.6906470676263173
Epoch: 82 | Iteration number: [190/565] 33% | Training loss: 0.6904371085919832
Epoch: 82 | Iteration number: [200/565] 35% | Training loss: 0.6902496924996376
Epoch: 82 | Iteration number: [210/565] 37% | Training loss: 0.6900935513632638
Epoch: 82 | Iteration number: [220/565] 38% | Training loss: 0.6899065253409472
Epoch: 82 | Iteration number: [230/565] 40% | Training loss: 0.689760831127996
Epoch: 82 | Iteration number: [240/565] 42% | Training loss: 0.6896577306091786
Epoch: 82 | Iteration number: [250/565] 44% | Training loss: 0.68953466629982
Epoch: 82 | Iteration number: [260/565] 46% | Training loss: 0.6894086406781124
Epoch: 82 | Iteration number: [270/565] 47% | Training loss: 0.689310434129503
Epoch: 82 | Iteration number: [280/565] 49% | Training loss: 0.6892006239720754
Epoch: 82 | Iteration number: [290/565] 51% | Training loss: 0.689106907310157
Epoch: 82 | Iteration number: [300/565] 53% | Training loss: 0.6890139708916346
Epoch: 82 | Iteration number: [310/565] 54% | Training loss: 0.6889486184043269
Epoch: 82 | Iteration number: [320/565] 56% | Training loss: 0.6888754999265074
Epoch: 82 | Iteration number: [330/565] 58% | Training loss: 0.6888125363624458
Epoch: 82 | Iteration number: [340/565] 60% | Training loss: 0.6887712848537109
Epoch: 82 | Iteration number: [350/565] 61% | Training loss: 0.688716515983854
Epoch: 82 | Iteration number: [360/565] 63% | Training loss: 0.6886546595229043
Epoch: 82 | Iteration number: [370/565] 65% | Training loss: 0.6886164048233547
Epoch: 82 | Iteration number: [380/565] 67% | Training loss: 0.68856968926756
Epoch: 82 | Iteration number: [390/565] 69% | Training loss: 0.6885129632093967
Epoch: 82 | Iteration number: [400/565] 70% | Training loss: 0.6884684666991234
Epoch: 82 | Iteration number: [410/565] 72% | Training loss: 0.688423037819746
Epoch: 82 | Iteration number: [420/565] 74% | Training loss: 0.6883775979280472
Epoch: 82 | Iteration number: [430/565] 76% | Training loss: 0.6883335620857949
Epoch: 82 | Iteration number: [440/565] 77% | Training loss: 0.688295851783319
Epoch: 82 | Iteration number: [450/565] 79% | Training loss: 0.6882634193367428
Epoch: 82 | Iteration number: [460/565] 81% | Training loss: 0.6882342820582182
Epoch: 82 | Iteration number: [470/565] 83% | Training loss: 0.6882115598688734
Epoch: 82 | Iteration number: [480/565] 84% | Training loss: 0.6881858743727207
Epoch: 82 | Iteration number: [490/565] 86% | Training loss: 0.68816133105025
Epoch: 82 | Iteration number: [500/565] 88% | Training loss: 0.6881352082490921
Epoch: 82 | Iteration number: [510/565] 90% | Training loss: 0.6881147354256874
Epoch: 82 | Iteration number: [520/565] 92% | Training loss: 0.6880949433033283
Epoch: 82 | Iteration number: [530/565] 93% | Training loss: 0.6880678812287888
Epoch: 82 | Iteration number: [540/565] 95% | Training loss: 0.6880460012842108
Epoch: 82 | Iteration number: [550/565] 97% | Training loss: 0.6880239104140888
Epoch: 82 | Iteration number: [560/565] 99% | Training loss: 0.688001683886562

 End of epoch: 82 | Train Loss: 0.6867749486349325 | Training Time: 90 

 End of epoch: 82 | Eval Loss: 0.6900163803781781 | Evaluating Time: 6 
Epoch: 83 | Iteration number: [10/565] 1% | Training loss: 0.7555538713932037
Epoch: 83 | Iteration number: [20/565] 3% | Training loss: 0.721070072054863
Epoch: 83 | Iteration number: [30/565] 5% | Training loss: 0.7096914112567901
Epoch: 83 | Iteration number: [40/565] 7% | Training loss: 0.7039323091506958
Epoch: 83 | Iteration number: [50/565] 8% | Training loss: 0.7004955351352692
Epoch: 83 | Iteration number: [60/565] 10% | Training loss: 0.6981381197770437
Epoch: 83 | Iteration number: [70/565] 12% | Training loss: 0.6964064981256213
Epoch: 83 | Iteration number: [80/565] 14% | Training loss: 0.6951562106609345
Epoch: 83 | Iteration number: [90/565] 15% | Training loss: 0.6942734671963586
Epoch: 83 | Iteration number: [100/565] 17% | Training loss: 0.6934908348321914
Epoch: 83 | Iteration number: [110/565] 19% | Training loss: 0.6928984349424189
Epoch: 83 | Iteration number: [120/565] 21% | Training loss: 0.6923743203282356
Epoch: 83 | Iteration number: [130/565] 23% | Training loss: 0.6919667459451235
Epoch: 83 | Iteration number: [140/565] 24% | Training loss: 0.6916200399398804
Epoch: 83 | Iteration number: [150/565] 26% | Training loss: 0.6913117094834645
Epoch: 83 | Iteration number: [160/565] 28% | Training loss: 0.6910701766610146
Epoch: 83 | Iteration number: [170/565] 30% | Training loss: 0.6908091629252714
Epoch: 83 | Iteration number: [180/565] 31% | Training loss: 0.6905831032329135
Epoch: 83 | Iteration number: [190/565] 33% | Training loss: 0.6903579551922647
Epoch: 83 | Iteration number: [200/565] 35% | Training loss: 0.6901893454790116
Epoch: 83 | Iteration number: [210/565] 37% | Training loss: 0.6900470231260573
Epoch: 83 | Iteration number: [220/565] 38% | Training loss: 0.6898877176371487
Epoch: 83 | Iteration number: [230/565] 40% | Training loss: 0.6897521078586578
Epoch: 83 | Iteration number: [240/565] 42% | Training loss: 0.6896330508093039
Epoch: 83 | Iteration number: [250/565] 44% | Training loss: 0.6895286266803742
Epoch: 83 | Iteration number: [260/565] 46% | Training loss: 0.6894154337736277
Epoch: 83 | Iteration number: [270/565] 47% | Training loss: 0.689317046933704
Epoch: 83 | Iteration number: [280/565] 49% | Training loss: 0.6892423063516617
Epoch: 83 | Iteration number: [290/565] 51% | Training loss: 0.6891533436446354
Epoch: 83 | Iteration number: [300/565] 53% | Training loss: 0.6890648855765661
Epoch: 83 | Iteration number: [310/565] 54% | Training loss: 0.6889953376785402
Epoch: 83 | Iteration number: [320/565] 56% | Training loss: 0.6889287812635303
Epoch: 83 | Iteration number: [330/565] 58% | Training loss: 0.6888512506629482
Epoch: 83 | Iteration number: [340/565] 60% | Training loss: 0.6888085377566955
Epoch: 83 | Iteration number: [350/565] 61% | Training loss: 0.6887401820932115
Epoch: 83 | Iteration number: [360/565] 63% | Training loss: 0.6886746101909214
Epoch: 83 | Iteration number: [370/565] 65% | Training loss: 0.6886310192378792
Epoch: 83 | Iteration number: [380/565] 67% | Training loss: 0.6885870808049253
Epoch: 83 | Iteration number: [390/565] 69% | Training loss: 0.6885408595586434
Epoch: 83 | Iteration number: [400/565] 70% | Training loss: 0.6885021826624871
Epoch: 83 | Iteration number: [410/565] 72% | Training loss: 0.6884543250246746
Epoch: 83 | Iteration number: [420/565] 74% | Training loss: 0.6884109030167261
Epoch: 83 | Iteration number: [430/565] 76% | Training loss: 0.6883719983489014
Epoch: 83 | Iteration number: [440/565] 77% | Training loss: 0.6883386951955882
Epoch: 83 | Iteration number: [450/565] 79% | Training loss: 0.6883007831043667
Epoch: 83 | Iteration number: [460/565] 81% | Training loss: 0.6882782600496127
Epoch: 83 | Iteration number: [470/565] 83% | Training loss: 0.6882386719926875
Epoch: 83 | Iteration number: [480/565] 84% | Training loss: 0.688212317849199
Epoch: 83 | Iteration number: [490/565] 86% | Training loss: 0.6881775044665045
Epoch: 83 | Iteration number: [500/565] 88% | Training loss: 0.6881451196670533
Epoch: 83 | Iteration number: [510/565] 90% | Training loss: 0.688120328912548
Epoch: 83 | Iteration number: [520/565] 92% | Training loss: 0.6880965291307523
Epoch: 83 | Iteration number: [530/565] 93% | Training loss: 0.6880771342313514
Epoch: 83 | Iteration number: [540/565] 95% | Training loss: 0.6880549310534089
Epoch: 83 | Iteration number: [550/565] 97% | Training loss: 0.6880320008234544
Epoch: 83 | Iteration number: [560/565] 99% | Training loss: 0.688003492887531

 End of epoch: 83 | Train Loss: 0.6867690428168373 | Training Time: 91 

 End of epoch: 83 | Eval Loss: 0.6893844604492188 | Evaluating Time: 6 
Epoch: 84 | Iteration number: [10/565] 1% | Training loss: 0.7552954375743866
Epoch: 84 | Iteration number: [20/565] 3% | Training loss: 0.7209412008523941
Epoch: 84 | Iteration number: [30/565] 5% | Training loss: 0.7094957709312439
Epoch: 84 | Iteration number: [40/565] 7% | Training loss: 0.7038898497819901
Epoch: 84 | Iteration number: [50/565] 8% | Training loss: 0.7005511283874511
Epoch: 84 | Iteration number: [60/565] 10% | Training loss: 0.6982592473427455
Epoch: 84 | Iteration number: [70/565] 12% | Training loss: 0.69663867354393
Epoch: 84 | Iteration number: [80/565] 14% | Training loss: 0.6954414121806621
Epoch: 84 | Iteration number: [90/565] 15% | Training loss: 0.6944472226831648
Epoch: 84 | Iteration number: [100/565] 17% | Training loss: 0.6937043917179108
Epoch: 84 | Iteration number: [110/565] 19% | Training loss: 0.6930531599304893
Epoch: 84 | Iteration number: [120/565] 21% | Training loss: 0.6925157849987348
Epoch: 84 | Iteration number: [130/565] 23% | Training loss: 0.6920824353511517
Epoch: 84 | Iteration number: [140/565] 24% | Training loss: 0.6917012108223779
Epoch: 84 | Iteration number: [150/565] 26% | Training loss: 0.6913615067799886
Epoch: 84 | Iteration number: [160/565] 28% | Training loss: 0.6910977583378554
Epoch: 84 | Iteration number: [170/565] 30% | Training loss: 0.690864698676502
Epoch: 84 | Iteration number: [180/565] 31% | Training loss: 0.6906372222635481
Epoch: 84 | Iteration number: [190/565] 33% | Training loss: 0.6904375164132369
Epoch: 84 | Iteration number: [200/565] 35% | Training loss: 0.6902514839172363
Epoch: 84 | Iteration number: [210/565] 37% | Training loss: 0.6900831199827648
Epoch: 84 | Iteration number: [220/565] 38% | Training loss: 0.6899379443038594
Epoch: 84 | Iteration number: [230/565] 40% | Training loss: 0.6898138810759006
Epoch: 84 | Iteration number: [240/565] 42% | Training loss: 0.6896784243484338
Epoch: 84 | Iteration number: [250/565] 44% | Training loss: 0.6895888028144836
Epoch: 84 | Iteration number: [260/565] 46% | Training loss: 0.6894841457788761
Epoch: 84 | Iteration number: [270/565] 47% | Training loss: 0.6893808991820723
Epoch: 84 | Iteration number: [280/565] 49% | Training loss: 0.6892808635319982
Epoch: 84 | Iteration number: [290/565] 51% | Training loss: 0.6891870106088704
Epoch: 84 | Iteration number: [300/565] 53% | Training loss: 0.6891016135613124
Epoch: 84 | Iteration number: [310/565] 54% | Training loss: 0.6890122081002882
Epoch: 84 | Iteration number: [320/565] 56% | Training loss: 0.6889323186129331
Epoch: 84 | Iteration number: [330/565] 58% | Training loss: 0.6888520173954241
Epoch: 84 | Iteration number: [340/565] 60% | Training loss: 0.6887837483602411
Epoch: 84 | Iteration number: [350/565] 61% | Training loss: 0.6887283987658365
Epoch: 84 | Iteration number: [360/565] 63% | Training loss: 0.6886653419997957
Epoch: 84 | Iteration number: [370/565] 65% | Training loss: 0.6886150527644802
Epoch: 84 | Iteration number: [380/565] 67% | Training loss: 0.6885693034059123
Epoch: 84 | Iteration number: [390/565] 69% | Training loss: 0.6885298359088409
Epoch: 84 | Iteration number: [400/565] 70% | Training loss: 0.6884961877763272
Epoch: 84 | Iteration number: [410/565] 72% | Training loss: 0.6884463377115203
Epoch: 84 | Iteration number: [420/565] 74% | Training loss: 0.6884001260712034
Epoch: 84 | Iteration number: [430/565] 76% | Training loss: 0.6883637015209642
Epoch: 84 | Iteration number: [440/565] 77% | Training loss: 0.688330007547682
Epoch: 84 | Iteration number: [450/565] 79% | Training loss: 0.6882989553610483
Epoch: 84 | Iteration number: [460/565] 81% | Training loss: 0.6882703848507093
Epoch: 84 | Iteration number: [470/565] 83% | Training loss: 0.6882407864357563
Epoch: 84 | Iteration number: [480/565] 84% | Training loss: 0.6882113243142763
Epoch: 84 | Iteration number: [490/565] 86% | Training loss: 0.688178061709112
Epoch: 84 | Iteration number: [500/565] 88% | Training loss: 0.6881511054039001
Epoch: 84 | Iteration number: [510/565] 90% | Training loss: 0.6881142090348636
Epoch: 84 | Iteration number: [520/565] 92% | Training loss: 0.6880938072617238
Epoch: 84 | Iteration number: [530/565] 93% | Training loss: 0.6880596705202786
Epoch: 84 | Iteration number: [540/565] 95% | Training loss: 0.6880412208813208
Epoch: 84 | Iteration number: [550/565] 97% | Training loss: 0.6880207962339575
Epoch: 84 | Iteration number: [560/565] 99% | Training loss: 0.6879962254847799

 End of epoch: 84 | Train Loss: 0.6867684878079238 | Training Time: 89 

 End of epoch: 84 | Eval Loss: 0.6890988264765058 | Evaluating Time: 6 
Epoch: 85 | Iteration number: [10/565] 1% | Training loss: 0.7541759073734283
Epoch: 85 | Iteration number: [20/565] 3% | Training loss: 0.720208129286766
Epoch: 85 | Iteration number: [30/565] 5% | Training loss: 0.7091851731141409
Epoch: 85 | Iteration number: [40/565] 7% | Training loss: 0.7035671606659889
Epoch: 85 | Iteration number: [50/565] 8% | Training loss: 0.7002626788616181
Epoch: 85 | Iteration number: [60/565] 10% | Training loss: 0.6980078111092249
Epoch: 85 | Iteration number: [70/565] 12% | Training loss: 0.6963216645377023
Epoch: 85 | Iteration number: [80/565] 14% | Training loss: 0.695118536055088
Epoch: 85 | Iteration number: [90/565] 15% | Training loss: 0.6942101127571529
Epoch: 85 | Iteration number: [100/565] 17% | Training loss: 0.6934112703800202
Epoch: 85 | Iteration number: [110/565] 19% | Training loss: 0.6927659040147608
Epoch: 85 | Iteration number: [120/565] 21% | Training loss: 0.6922479713956515
Epoch: 85 | Iteration number: [130/565] 23% | Training loss: 0.6918223701990568
Epoch: 85 | Iteration number: [140/565] 24% | Training loss: 0.6914622034345355
Epoch: 85 | Iteration number: [150/565] 26% | Training loss: 0.6911225120226542
Epoch: 85 | Iteration number: [160/565] 28% | Training loss: 0.690873047709465
Epoch: 85 | Iteration number: [170/565] 30% | Training loss: 0.690652730885674
Epoch: 85 | Iteration number: [180/565] 31% | Training loss: 0.6904251479440265
Epoch: 85 | Iteration number: [190/565] 33% | Training loss: 0.6902248238262377
Epoch: 85 | Iteration number: [200/565] 35% | Training loss: 0.690058453977108
Epoch: 85 | Iteration number: [210/565] 37% | Training loss: 0.6899050891399383
Epoch: 85 | Iteration number: [220/565] 38% | Training loss: 0.6897595053369349
Epoch: 85 | Iteration number: [230/565] 40% | Training loss: 0.689631756492283
Epoch: 85 | Iteration number: [240/565] 42% | Training loss: 0.6895197863380115
Epoch: 85 | Iteration number: [250/565] 44% | Training loss: 0.6894094350337983
Epoch: 85 | Iteration number: [260/565] 46% | Training loss: 0.6893203157645006
Epoch: 85 | Iteration number: [270/565] 47% | Training loss: 0.6892209167833682
Epoch: 85 | Iteration number: [280/565] 49% | Training loss: 0.6891362711787223
Epoch: 85 | Iteration number: [290/565] 51% | Training loss: 0.6890603077822718
Epoch: 85 | Iteration number: [300/565] 53% | Training loss: 0.6889922020832697
Epoch: 85 | Iteration number: [310/565] 54% | Training loss: 0.68892608457996
Epoch: 85 | Iteration number: [320/565] 56% | Training loss: 0.6888639811426401
Epoch: 85 | Iteration number: [330/565] 58% | Training loss: 0.6888052541198153
Epoch: 85 | Iteration number: [340/565] 60% | Training loss: 0.6887432436732684
Epoch: 85 | Iteration number: [350/565] 61% | Training loss: 0.6886868938377926
Epoch: 85 | Iteration number: [360/565] 63% | Training loss: 0.6886374349395434
Epoch: 85 | Iteration number: [370/565] 65% | Training loss: 0.6885937681069245
Epoch: 85 | Iteration number: [380/565] 67% | Training loss: 0.6885584923781847
Epoch: 85 | Iteration number: [390/565] 69% | Training loss: 0.6885127315154442
Epoch: 85 | Iteration number: [400/565] 70% | Training loss: 0.6884718126058579
Epoch: 85 | Iteration number: [410/565] 72% | Training loss: 0.6884245112174895
Epoch: 85 | Iteration number: [420/565] 74% | Training loss: 0.6883799121493385
Epoch: 85 | Iteration number: [430/565] 76% | Training loss: 0.6883468145547911
Epoch: 85 | Iteration number: [440/565] 77% | Training loss: 0.6883110655979676
Epoch: 85 | Iteration number: [450/565] 79% | Training loss: 0.6882741785049439
Epoch: 85 | Iteration number: [460/565] 81% | Training loss: 0.6882465950820758
Epoch: 85 | Iteration number: [470/565] 83% | Training loss: 0.6882084245377399
Epoch: 85 | Iteration number: [480/565] 84% | Training loss: 0.6881812521566947
Epoch: 85 | Iteration number: [490/565] 86% | Training loss: 0.68815489350533
Epoch: 85 | Iteration number: [500/565] 88% | Training loss: 0.6881217283010482
Epoch: 85 | Iteration number: [510/565] 90% | Training loss: 0.6880872719428118
Epoch: 85 | Iteration number: [520/565] 92% | Training loss: 0.6880711333109782
Epoch: 85 | Iteration number: [530/565] 93% | Training loss: 0.6880491497381678
Epoch: 85 | Iteration number: [540/565] 95% | Training loss: 0.6880202039524361
Epoch: 85 | Iteration number: [550/565] 97% | Training loss: 0.6880048351938074
Epoch: 85 | Iteration number: [560/565] 99% | Training loss: 0.6879847345607621

 End of epoch: 85 | Train Loss: 0.6867669875642894 | Training Time: 90 

 End of epoch: 85 | Eval Loss: 0.6898939779826573 | Evaluating Time: 6 
Epoch: 86 | Iteration number: [10/565] 1% | Training loss: 0.7554085612297058
Epoch: 86 | Iteration number: [20/565] 3% | Training loss: 0.7212800472974777
Epoch: 86 | Iteration number: [30/565] 5% | Training loss: 0.7098379035790762
Epoch: 86 | Iteration number: [40/565] 7% | Training loss: 0.7040270254015922
Epoch: 86 | Iteration number: [50/565] 8% | Training loss: 0.700555579662323
Epoch: 86 | Iteration number: [60/565] 10% | Training loss: 0.6983087241649628
Epoch: 86 | Iteration number: [70/565] 12% | Training loss: 0.6966632987771716
Epoch: 86 | Iteration number: [80/565] 14% | Training loss: 0.6954239025712013
Epoch: 86 | Iteration number: [90/565] 15% | Training loss: 0.6944049338499705
Epoch: 86 | Iteration number: [100/565] 17% | Training loss: 0.6936115926504135
Epoch: 86 | Iteration number: [110/565] 19% | Training loss: 0.6929810215126384
Epoch: 86 | Iteration number: [120/565] 21% | Training loss: 0.6924506222208341
Epoch: 86 | Iteration number: [130/565] 23% | Training loss: 0.6920167116018442
Epoch: 86 | Iteration number: [140/565] 24% | Training loss: 0.6916285276412963
Epoch: 86 | Iteration number: [150/565] 26% | Training loss: 0.6912704348564148
Epoch: 86 | Iteration number: [160/565] 28% | Training loss: 0.6909997411072254
Epoch: 86 | Iteration number: [170/565] 30% | Training loss: 0.6907493983998018
Epoch: 86 | Iteration number: [180/565] 31% | Training loss: 0.6905242721239726
Epoch: 86 | Iteration number: [190/565] 33% | Training loss: 0.6903252504373851
Epoch: 86 | Iteration number: [200/565] 35% | Training loss: 0.6901634496450424
Epoch: 86 | Iteration number: [210/565] 37% | Training loss: 0.6900031328201294
Epoch: 86 | Iteration number: [220/565] 38% | Training loss: 0.6898517906665802
Epoch: 86 | Iteration number: [230/565] 40% | Training loss: 0.6897164015666298
Epoch: 86 | Iteration number: [240/565] 42% | Training loss: 0.6895900937418143
Epoch: 86 | Iteration number: [250/565] 44% | Training loss: 0.6894660594463349
Epoch: 86 | Iteration number: [260/565] 46% | Training loss: 0.6893535657570913
Epoch: 86 | Iteration number: [270/565] 47% | Training loss: 0.689257801020587
Epoch: 86 | Iteration number: [280/565] 49% | Training loss: 0.6891686771597181
Epoch: 86 | Iteration number: [290/565] 51% | Training loss: 0.6890923364409085
Epoch: 86 | Iteration number: [300/565] 53% | Training loss: 0.689002307454745
Epoch: 86 | Iteration number: [310/565] 54% | Training loss: 0.6889320988808909
Epoch: 86 | Iteration number: [320/565] 56% | Training loss: 0.6888663917779922
Epoch: 86 | Iteration number: [330/565] 58% | Training loss: 0.6888190793268608
Epoch: 86 | Iteration number: [340/565] 60% | Training loss: 0.6887680513017318
Epoch: 86 | Iteration number: [350/565] 61% | Training loss: 0.6887055671215058
Epoch: 86 | Iteration number: [360/565] 63% | Training loss: 0.6886383559968736
Epoch: 86 | Iteration number: [370/565] 65% | Training loss: 0.6885966014217686
Epoch: 86 | Iteration number: [380/565] 67% | Training loss: 0.6885465570186314
Epoch: 86 | Iteration number: [390/565] 69% | Training loss: 0.688505350626432
Epoch: 86 | Iteration number: [400/565] 70% | Training loss: 0.6884472846984864
Epoch: 86 | Iteration number: [410/565] 72% | Training loss: 0.6884061314710757
Epoch: 86 | Iteration number: [420/565] 74% | Training loss: 0.6883663681291399
Epoch: 86 | Iteration number: [430/565] 76% | Training loss: 0.6883367862812309
Epoch: 86 | Iteration number: [440/565] 77% | Training loss: 0.6882997350259261
Epoch: 86 | Iteration number: [450/565] 79% | Training loss: 0.6882683800326453
Epoch: 86 | Iteration number: [460/565] 81% | Training loss: 0.6882296731938486
Epoch: 86 | Iteration number: [470/565] 83% | Training loss: 0.6882026080121385
Epoch: 86 | Iteration number: [480/565] 84% | Training loss: 0.6881784666329622
Epoch: 86 | Iteration number: [490/565] 86% | Training loss: 0.6881545387968725
Epoch: 86 | Iteration number: [500/565] 88% | Training loss: 0.688124482870102
Epoch: 86 | Iteration number: [510/565] 90% | Training loss: 0.6881071517280504
Epoch: 86 | Iteration number: [520/565] 92% | Training loss: 0.6880843121271867
Epoch: 86 | Iteration number: [530/565] 93% | Training loss: 0.6880574267990184
Epoch: 86 | Iteration number: [540/565] 95% | Training loss: 0.6880338571689747
Epoch: 86 | Iteration number: [550/565] 97% | Training loss: 0.6880071319233287
Epoch: 86 | Iteration number: [560/565] 99% | Training loss: 0.6879921853542328

 End of epoch: 86 | Train Loss: 0.6867645699366004 | Training Time: 90 

 End of epoch: 86 | Eval Loss: 0.6897449748856681 | Evaluating Time: 5 
Epoch: 87 | Iteration number: [10/565] 1% | Training loss: 0.7552992105484009
Epoch: 87 | Iteration number: [20/565] 3% | Training loss: 0.7208731681108475
Epoch: 87 | Iteration number: [30/565] 5% | Training loss: 0.7096199909845988
Epoch: 87 | Iteration number: [40/565] 7% | Training loss: 0.703854750096798
Epoch: 87 | Iteration number: [50/565] 8% | Training loss: 0.7004498422145844
Epoch: 87 | Iteration number: [60/565] 10% | Training loss: 0.6980925410985946
Epoch: 87 | Iteration number: [70/565] 12% | Training loss: 0.6965280013425009
Epoch: 87 | Iteration number: [80/565] 14% | Training loss: 0.6952868424355984
Epoch: 87 | Iteration number: [90/565] 15% | Training loss: 0.6943683677249485
Epoch: 87 | Iteration number: [100/565] 17% | Training loss: 0.6936084306240082
Epoch: 87 | Iteration number: [110/565] 19% | Training loss: 0.6929740873250094
Epoch: 87 | Iteration number: [120/565] 21% | Training loss: 0.6924528564016025
Epoch: 87 | Iteration number: [130/565] 23% | Training loss: 0.6920338754470532
Epoch: 87 | Iteration number: [140/565] 24% | Training loss: 0.6917036946330751
Epoch: 87 | Iteration number: [150/565] 26% | Training loss: 0.6913604931036631
Epoch: 87 | Iteration number: [160/565] 28% | Training loss: 0.6910733308643102
Epoch: 87 | Iteration number: [170/565] 30% | Training loss: 0.6908151412711424
Epoch: 87 | Iteration number: [180/565] 31% | Training loss: 0.6905792663494746
Epoch: 87 | Iteration number: [190/565] 33% | Training loss: 0.6903883924609736
Epoch: 87 | Iteration number: [200/565] 35% | Training loss: 0.6902345883846283
Epoch: 87 | Iteration number: [210/565] 37% | Training loss: 0.6900716242336091
Epoch: 87 | Iteration number: [220/565] 38% | Training loss: 0.689917608553713
Epoch: 87 | Iteration number: [230/565] 40% | Training loss: 0.6897782577120739
Epoch: 87 | Iteration number: [240/565] 42% | Training loss: 0.6896542047460874
Epoch: 87 | Iteration number: [250/565] 44% | Training loss: 0.6895470297336579
Epoch: 87 | Iteration number: [260/565] 46% | Training loss: 0.6894437929758659
Epoch: 87 | Iteration number: [270/565] 47% | Training loss: 0.689355053945824
Epoch: 87 | Iteration number: [280/565] 49% | Training loss: 0.6892625944955009
Epoch: 87 | Iteration number: [290/565] 51% | Training loss: 0.6891574943887776
Epoch: 87 | Iteration number: [300/565] 53% | Training loss: 0.6890642746289571
Epoch: 87 | Iteration number: [310/565] 54% | Training loss: 0.6889880443772962
Epoch: 87 | Iteration number: [320/565] 56% | Training loss: 0.6889160733669997
Epoch: 87 | Iteration number: [330/565] 58% | Training loss: 0.6888596377589485
Epoch: 87 | Iteration number: [340/565] 60% | Training loss: 0.6887914615518906
Epoch: 87 | Iteration number: [350/565] 61% | Training loss: 0.6887362582342965
Epoch: 87 | Iteration number: [360/565] 63% | Training loss: 0.6886914687024223
Epoch: 87 | Iteration number: [370/565] 65% | Training loss: 0.6886349006279094
Epoch: 87 | Iteration number: [380/565] 67% | Training loss: 0.688579722297819
Epoch: 87 | Iteration number: [390/565] 69% | Training loss: 0.6885249032424047
Epoch: 87 | Iteration number: [400/565] 70% | Training loss: 0.6884843020141125
Epoch: 87 | Iteration number: [410/565] 72% | Training loss: 0.6884474763056126
Epoch: 87 | Iteration number: [420/565] 74% | Training loss: 0.6884019241446541
Epoch: 87 | Iteration number: [430/565] 76% | Training loss: 0.6883562010388041
Epoch: 87 | Iteration number: [440/565] 77% | Training loss: 0.6883239141919396
Epoch: 87 | Iteration number: [450/565] 79% | Training loss: 0.6882767796516418
Epoch: 87 | Iteration number: [460/565] 81% | Training loss: 0.68825298651405
Epoch: 87 | Iteration number: [470/565] 83% | Training loss: 0.6882137549684403
Epoch: 87 | Iteration number: [480/565] 84% | Training loss: 0.6881914008408785
Epoch: 87 | Iteration number: [490/565] 86% | Training loss: 0.6881587854453496
Epoch: 87 | Iteration number: [500/565] 88% | Training loss: 0.6881379115581513
Epoch: 87 | Iteration number: [510/565] 90% | Training loss: 0.6881153740134893
Epoch: 87 | Iteration number: [520/565] 92% | Training loss: 0.6880827155250769
Epoch: 87 | Iteration number: [530/565] 93% | Training loss: 0.6880519635272476
Epoch: 87 | Iteration number: [540/565] 95% | Training loss: 0.6880304039628418
Epoch: 87 | Iteration number: [550/565] 97% | Training loss: 0.6880108004266565
Epoch: 87 | Iteration number: [560/565] 99% | Training loss: 0.6879929615982942

 End of epoch: 87 | Train Loss: 0.6867706655401045 | Training Time: 88 

 End of epoch: 87 | Eval Loss: 0.6897912791797093 | Evaluating Time: 6 
Epoch: 88 | Iteration number: [10/565] 1% | Training loss: 0.7558097183704376
Epoch: 88 | Iteration number: [20/565] 3% | Training loss: 0.721090766787529
Epoch: 88 | Iteration number: [30/565] 5% | Training loss: 0.7095744033654531
Epoch: 88 | Iteration number: [40/565] 7% | Training loss: 0.703897950053215
Epoch: 88 | Iteration number: [50/565] 8% | Training loss: 0.7005038404464722
Epoch: 88 | Iteration number: [60/565] 10% | Training loss: 0.6981546690066656
Epoch: 88 | Iteration number: [70/565] 12% | Training loss: 0.6964842089584895
Epoch: 88 | Iteration number: [80/565] 14% | Training loss: 0.6952515251934528
Epoch: 88 | Iteration number: [90/565] 15% | Training loss: 0.6943359865082634
Epoch: 88 | Iteration number: [100/565] 17% | Training loss: 0.6936306655406952
Epoch: 88 | Iteration number: [110/565] 19% | Training loss: 0.6930171007459814
Epoch: 88 | Iteration number: [120/565] 21% | Training loss: 0.6924908364812533
Epoch: 88 | Iteration number: [130/565] 23% | Training loss: 0.6920731737063481
Epoch: 88 | Iteration number: [140/565] 24% | Training loss: 0.69168994980199
Epoch: 88 | Iteration number: [150/565] 26% | Training loss: 0.6913312200705211
Epoch: 88 | Iteration number: [160/565] 28% | Training loss: 0.6910621523857117
Epoch: 88 | Iteration number: [170/565] 30% | Training loss: 0.6908171197947334
Epoch: 88 | Iteration number: [180/565] 31% | Training loss: 0.6905806796418296
Epoch: 88 | Iteration number: [190/565] 33% | Training loss: 0.6903695081409655
Epoch: 88 | Iteration number: [200/565] 35% | Training loss: 0.6901930207014084
Epoch: 88 | Iteration number: [210/565] 37% | Training loss: 0.6900117624373663
Epoch: 88 | Iteration number: [220/565] 38% | Training loss: 0.689845778725364
Epoch: 88 | Iteration number: [230/565] 40% | Training loss: 0.6897395556387694
Epoch: 88 | Iteration number: [240/565] 42% | Training loss: 0.6896150295933088
Epoch: 88 | Iteration number: [250/565] 44% | Training loss: 0.6895054695606232
Epoch: 88 | Iteration number: [260/565] 46% | Training loss: 0.6894126463394898
Epoch: 88 | Iteration number: [270/565] 47% | Training loss: 0.6893269059834657
Epoch: 88 | Iteration number: [280/565] 49% | Training loss: 0.6892292284539767
Epoch: 88 | Iteration number: [290/565] 51% | Training loss: 0.6891321303515598
Epoch: 88 | Iteration number: [300/565] 53% | Training loss: 0.6890573489665985
Epoch: 88 | Iteration number: [310/565] 54% | Training loss: 0.6889871114684689
Epoch: 88 | Iteration number: [320/565] 56% | Training loss: 0.6889188215136528
Epoch: 88 | Iteration number: [330/565] 58% | Training loss: 0.6888532201449077
Epoch: 88 | Iteration number: [340/565] 60% | Training loss: 0.6888048301724826
Epoch: 88 | Iteration number: [350/565] 61% | Training loss: 0.6887423499992915
Epoch: 88 | Iteration number: [360/565] 63% | Training loss: 0.6886834707525041
Epoch: 88 | Iteration number: [370/565] 65% | Training loss: 0.6886318783502321
Epoch: 88 | Iteration number: [380/565] 67% | Training loss: 0.6885847052461223
Epoch: 88 | Iteration number: [390/565] 69% | Training loss: 0.6885326559727009
Epoch: 88 | Iteration number: [400/565] 70% | Training loss: 0.6884907904267311
Epoch: 88 | Iteration number: [410/565] 72% | Training loss: 0.6884447064341568
Epoch: 88 | Iteration number: [420/565] 74% | Training loss: 0.6884086238486427
Epoch: 88 | Iteration number: [430/565] 76% | Training loss: 0.6883677812509759
Epoch: 88 | Iteration number: [440/565] 77% | Training loss: 0.68832271004265
Epoch: 88 | Iteration number: [450/565] 79% | Training loss: 0.6882999736732907
Epoch: 88 | Iteration number: [460/565] 81% | Training loss: 0.6882801344861155
Epoch: 88 | Iteration number: [470/565] 83% | Training loss: 0.6882553704241489
Epoch: 88 | Iteration number: [480/565] 84% | Training loss: 0.6882258584101995
Epoch: 88 | Iteration number: [490/565] 86% | Training loss: 0.6882026790356149
Epoch: 88 | Iteration number: [500/565] 88% | Training loss: 0.6881768178939819
Epoch: 88 | Iteration number: [510/565] 90% | Training loss: 0.6881419331419701
Epoch: 88 | Iteration number: [520/565] 92% | Training loss: 0.6881142336588639
Epoch: 88 | Iteration number: [530/565] 93% | Training loss: 0.6880675920900309
Epoch: 88 | Iteration number: [540/565] 95% | Training loss: 0.6880327766692197
Epoch: 88 | Iteration number: [550/565] 97% | Training loss: 0.6880109268968756
Epoch: 88 | Iteration number: [560/565] 99% | Training loss: 0.6879925889628274

 End of epoch: 88 | Train Loss: 0.6867666934443786 | Training Time: 89 

 End of epoch: 88 | Eval Loss: 0.68980872631073 | Evaluating Time: 6 
Epoch: 89 | Iteration number: [10/565] 1% | Training loss: 0.7556997179985047
Epoch: 89 | Iteration number: [20/565] 3% | Training loss: 0.7212049692869187
Epoch: 89 | Iteration number: [30/565] 5% | Training loss: 0.7097809930642446
Epoch: 89 | Iteration number: [40/565] 7% | Training loss: 0.7040285259485245
Epoch: 89 | Iteration number: [50/565] 8% | Training loss: 0.7005791282653808
Epoch: 89 | Iteration number: [60/565] 10% | Training loss: 0.6982849528392155
Epoch: 89 | Iteration number: [70/565] 12% | Training loss: 0.6966343743460519
Epoch: 89 | Iteration number: [80/565] 14% | Training loss: 0.6954468712210655
Epoch: 89 | Iteration number: [90/565] 15% | Training loss: 0.694514948129654
Epoch: 89 | Iteration number: [100/565] 17% | Training loss: 0.6937359470129013
Epoch: 89 | Iteration number: [110/565] 19% | Training loss: 0.6931107038801366
Epoch: 89 | Iteration number: [120/565] 21% | Training loss: 0.6926087513566017
Epoch: 89 | Iteration number: [130/565] 23% | Training loss: 0.6921884133265569
Epoch: 89 | Iteration number: [140/565] 24% | Training loss: 0.6918183671576636
Epoch: 89 | Iteration number: [150/565] 26% | Training loss: 0.691430634657542
Epoch: 89 | Iteration number: [160/565] 28% | Training loss: 0.691145971044898
Epoch: 89 | Iteration number: [170/565] 30% | Training loss: 0.6908641482100767
Epoch: 89 | Iteration number: [180/565] 31% | Training loss: 0.6906366060177486
Epoch: 89 | Iteration number: [190/565] 33% | Training loss: 0.6904182104687941
Epoch: 89 | Iteration number: [200/565] 35% | Training loss: 0.6902409845590591
Epoch: 89 | Iteration number: [210/565] 37% | Training loss: 0.6900989895775205
Epoch: 89 | Iteration number: [220/565] 38% | Training loss: 0.6899470952424136
Epoch: 89 | Iteration number: [230/565] 40% | Training loss: 0.6898200594860574
Epoch: 89 | Iteration number: [240/565] 42% | Training loss: 0.6897043503820897
Epoch: 89 | Iteration number: [250/565] 44% | Training loss: 0.6895920510292053
Epoch: 89 | Iteration number: [260/565] 46% | Training loss: 0.689490126646482
Epoch: 89 | Iteration number: [270/565] 47% | Training loss: 0.6893828091798005
Epoch: 89 | Iteration number: [280/565] 49% | Training loss: 0.6892987002219473
Epoch: 89 | Iteration number: [290/565] 51% | Training loss: 0.689182191676107
Epoch: 89 | Iteration number: [300/565] 53% | Training loss: 0.6891179718573888
Epoch: 89 | Iteration number: [310/565] 54% | Training loss: 0.6890345954125927
Epoch: 89 | Iteration number: [320/565] 56% | Training loss: 0.6889720387756825
Epoch: 89 | Iteration number: [330/565] 58% | Training loss: 0.688900139837554
Epoch: 89 | Iteration number: [340/565] 60% | Training loss: 0.68884377812638
Epoch: 89 | Iteration number: [350/565] 61% | Training loss: 0.6887845504283905
Epoch: 89 | Iteration number: [360/565] 63% | Training loss: 0.6887135878205299
Epoch: 89 | Iteration number: [370/565] 65% | Training loss: 0.6886626897631465
Epoch: 89 | Iteration number: [380/565] 67% | Training loss: 0.6886086796459399
Epoch: 89 | Iteration number: [390/565] 69% | Training loss: 0.6885521080249395
Epoch: 89 | Iteration number: [400/565] 70% | Training loss: 0.6885084247589112
Epoch: 89 | Iteration number: [410/565] 72% | Training loss: 0.688467341516076
Epoch: 89 | Iteration number: [420/565] 74% | Training loss: 0.6884238159372693
Epoch: 89 | Iteration number: [430/565] 76% | Training loss: 0.6883980617966763
Epoch: 89 | Iteration number: [440/565] 77% | Training loss: 0.6883580740202557
Epoch: 89 | Iteration number: [450/565] 79% | Training loss: 0.688312447865804
Epoch: 89 | Iteration number: [460/565] 81% | Training loss: 0.6882826259602671
Epoch: 89 | Iteration number: [470/565] 83% | Training loss: 0.6882513168010306
Epoch: 89 | Iteration number: [480/565] 84% | Training loss: 0.6882135483125845
Epoch: 89 | Iteration number: [490/565] 86% | Training loss: 0.6881852646263278
Epoch: 89 | Iteration number: [500/565] 88% | Training loss: 0.6881546404361725
Epoch: 89 | Iteration number: [510/565] 90% | Training loss: 0.6881196496533413
Epoch: 89 | Iteration number: [520/565] 92% | Training loss: 0.6880991612489407
Epoch: 89 | Iteration number: [530/565] 93% | Training loss: 0.6880743889313824
Epoch: 89 | Iteration number: [540/565] 95% | Training loss: 0.6880444463756349
Epoch: 89 | Iteration number: [550/565] 97% | Training loss: 0.688021832596172
Epoch: 89 | Iteration number: [560/565] 99% | Training loss: 0.6879986459655422

 End of epoch: 89 | Train Loss: 0.6867669722675223 | Training Time: 88 

 End of epoch: 89 | Eval Loss: 0.6900750483785357 | Evaluating Time: 5 
Epoch: 90 | Iteration number: [10/565] 1% | Training loss: 0.7549511730670929
Epoch: 90 | Iteration number: [20/565] 3% | Training loss: 0.7206644028425216
Epoch: 90 | Iteration number: [30/565] 5% | Training loss: 0.709528120358785
Epoch: 90 | Iteration number: [40/565] 7% | Training loss: 0.7038968235254288
Epoch: 90 | Iteration number: [50/565] 8% | Training loss: 0.7003883457183838
Epoch: 90 | Iteration number: [60/565] 10% | Training loss: 0.6982288102308909
Epoch: 90 | Iteration number: [70/565] 12% | Training loss: 0.6965594206537519
Epoch: 90 | Iteration number: [80/565] 14% | Training loss: 0.6952749125659465
Epoch: 90 | Iteration number: [90/565] 15% | Training loss: 0.6942976805898878
Epoch: 90 | Iteration number: [100/565] 17% | Training loss: 0.693559719324112
Epoch: 90 | Iteration number: [110/565] 19% | Training loss: 0.6929488182067871
Epoch: 90 | Iteration number: [120/565] 21% | Training loss: 0.6924260516961416
Epoch: 90 | Iteration number: [130/565] 23% | Training loss: 0.6919772253586696
Epoch: 90 | Iteration number: [140/565] 24% | Training loss: 0.6916218910898481
Epoch: 90 | Iteration number: [150/565] 26% | Training loss: 0.6912837159633637
Epoch: 90 | Iteration number: [160/565] 28% | Training loss: 0.6910334046930074
Epoch: 90 | Iteration number: [170/565] 30% | Training loss: 0.690759825706482
Epoch: 90 | Iteration number: [180/565] 31% | Training loss: 0.6905350635449091
Epoch: 90 | Iteration number: [190/565] 33% | Training loss: 0.6903365646537981
Epoch: 90 | Iteration number: [200/565] 35% | Training loss: 0.6901419061422348
Epoch: 90 | Iteration number: [210/565] 37% | Training loss: 0.6899811389900389
Epoch: 90 | Iteration number: [220/565] 38% | Training loss: 0.6898281655528329
Epoch: 90 | Iteration number: [230/565] 40% | Training loss: 0.6896868366262187
Epoch: 90 | Iteration number: [240/565] 42% | Training loss: 0.68956187342604
Epoch: 90 | Iteration number: [250/565] 44% | Training loss: 0.6894516875743866
Epoch: 90 | Iteration number: [260/565] 46% | Training loss: 0.6893395444521537
Epoch: 90 | Iteration number: [270/565] 47% | Training loss: 0.6892609609497918
Epoch: 90 | Iteration number: [280/565] 49% | Training loss: 0.6891335131866592
Epoch: 90 | Iteration number: [290/565] 51% | Training loss: 0.6890518772191014
Epoch: 90 | Iteration number: [300/565] 53% | Training loss: 0.6889722953240077
Epoch: 90 | Iteration number: [310/565] 54% | Training loss: 0.6888965443257362
Epoch: 90 | Iteration number: [320/565] 56% | Training loss: 0.6888363538309932
Epoch: 90 | Iteration number: [330/565] 58% | Training loss: 0.6887642808032758
Epoch: 90 | Iteration number: [340/565] 60% | Training loss: 0.6886985596488504
Epoch: 90 | Iteration number: [350/565] 61% | Training loss: 0.6886341907296862
Epoch: 90 | Iteration number: [360/565] 63% | Training loss: 0.6885748134719001
Epoch: 90 | Iteration number: [370/565] 65% | Training loss: 0.6885265395448015
Epoch: 90 | Iteration number: [380/565] 67% | Training loss: 0.6884720924653505
Epoch: 90 | Iteration number: [390/565] 69% | Training loss: 0.6884334033880478
Epoch: 90 | Iteration number: [400/565] 70% | Training loss: 0.6883873490989209
Epoch: 90 | Iteration number: [410/565] 72% | Training loss: 0.6883527187312521
Epoch: 90 | Iteration number: [420/565] 74% | Training loss: 0.6883144663912909
Epoch: 90 | Iteration number: [430/565] 76% | Training loss: 0.6882885449154432
Epoch: 90 | Iteration number: [440/565] 77% | Training loss: 0.6882573706182566
Epoch: 90 | Iteration number: [450/565] 79% | Training loss: 0.6882272137535943
Epoch: 90 | Iteration number: [460/565] 81% | Training loss: 0.6881998776093773
Epoch: 90 | Iteration number: [470/565] 83% | Training loss: 0.688160076800813
Epoch: 90 | Iteration number: [480/565] 84% | Training loss: 0.6881322727849086
Epoch: 90 | Iteration number: [490/565] 86% | Training loss: 0.6881172146115985
Epoch: 90 | Iteration number: [500/565] 88% | Training loss: 0.6880974706411361
Epoch: 90 | Iteration number: [510/565] 90% | Training loss: 0.6880768240666857
Epoch: 90 | Iteration number: [520/565] 92% | Training loss: 0.6880600317166402
Epoch: 90 | Iteration number: [530/565] 93% | Training loss: 0.6880277684274709
Epoch: 90 | Iteration number: [540/565] 95% | Training loss: 0.6880102699553525
Epoch: 90 | Iteration number: [550/565] 97% | Training loss: 0.6879907756501978
Epoch: 90 | Iteration number: [560/565] 99% | Training loss: 0.6879779426114899

 End of epoch: 90 | Train Loss: 0.6867576818550583 | Training Time: 88 

 End of epoch: 90 | Eval Loss: 0.6898406914302281 | Evaluating Time: 6 
Epoch: 91 | Iteration number: [10/565] 1% | Training loss: 0.755322527885437
Epoch: 91 | Iteration number: [20/565] 3% | Training loss: 0.7210660755634308
Epoch: 91 | Iteration number: [30/565] 5% | Training loss: 0.7096248249212901
Epoch: 91 | Iteration number: [40/565] 7% | Training loss: 0.7039137110114098
Epoch: 91 | Iteration number: [50/565] 8% | Training loss: 0.7005031490325928
Epoch: 91 | Iteration number: [60/565] 10% | Training loss: 0.6982227265834808
Epoch: 91 | Iteration number: [70/565] 12% | Training loss: 0.6965640604496002
Epoch: 91 | Iteration number: [80/565] 14% | Training loss: 0.6953676953911782
Epoch: 91 | Iteration number: [90/565] 15% | Training loss: 0.6944378627671136
Epoch: 91 | Iteration number: [100/565] 17% | Training loss: 0.693645886182785
Epoch: 91 | Iteration number: [110/565] 19% | Training loss: 0.6930394638668407
Epoch: 91 | Iteration number: [120/565] 21% | Training loss: 0.6925205916166306
Epoch: 91 | Iteration number: [130/565] 23% | Training loss: 0.6920522900728079
Epoch: 91 | Iteration number: [140/565] 24% | Training loss: 0.6916995780808585
Epoch: 91 | Iteration number: [150/565] 26% | Training loss: 0.6913535018761953
Epoch: 91 | Iteration number: [160/565] 28% | Training loss: 0.6910877849906683
Epoch: 91 | Iteration number: [170/565] 30% | Training loss: 0.6908201470094568
Epoch: 91 | Iteration number: [180/565] 31% | Training loss: 0.6905780689583885
Epoch: 91 | Iteration number: [190/565] 33% | Training loss: 0.6903910414168709
Epoch: 91 | Iteration number: [200/565] 35% | Training loss: 0.6901940843462944
Epoch: 91 | Iteration number: [210/565] 37% | Training loss: 0.6900363235246567
Epoch: 91 | Iteration number: [220/565] 38% | Training loss: 0.6898863976651972
Epoch: 91 | Iteration number: [230/565] 40% | Training loss: 0.6897761318994605
Epoch: 91 | Iteration number: [240/565] 42% | Training loss: 0.6896542514363925
Epoch: 91 | Iteration number: [250/565] 44% | Training loss: 0.6895406100749969
Epoch: 91 | Iteration number: [260/565] 46% | Training loss: 0.6894439690388166
Epoch: 91 | Iteration number: [270/565] 47% | Training loss: 0.6893520405998936
Epoch: 91 | Iteration number: [280/565] 49% | Training loss: 0.6892523361103875
Epoch: 91 | Iteration number: [290/565] 51% | Training loss: 0.6891364829293612
Epoch: 91 | Iteration number: [300/565] 53% | Training loss: 0.689067067305247
Epoch: 91 | Iteration number: [310/565] 54% | Training loss: 0.6890003335091376
Epoch: 91 | Iteration number: [320/565] 56% | Training loss: 0.6889105681329966
Epoch: 91 | Iteration number: [330/565] 58% | Training loss: 0.688843942230398
Epoch: 91 | Iteration number: [340/565] 60% | Training loss: 0.6887895606896457
Epoch: 91 | Iteration number: [350/565] 61% | Training loss: 0.6887337149892534
Epoch: 91 | Iteration number: [360/565] 63% | Training loss: 0.6886598002579477
Epoch: 91 | Iteration number: [370/565] 65% | Training loss: 0.6886129906048646
Epoch: 91 | Iteration number: [380/565] 67% | Training loss: 0.6885627031326294
Epoch: 91 | Iteration number: [390/565] 69% | Training loss: 0.6885128846535316
Epoch: 91 | Iteration number: [400/565] 70% | Training loss: 0.6884702880680561
Epoch: 91 | Iteration number: [410/565] 72% | Training loss: 0.6884200399968682
Epoch: 91 | Iteration number: [420/565] 74% | Training loss: 0.6883818414949235
Epoch: 91 | Iteration number: [430/565] 76% | Training loss: 0.6883526229581167
Epoch: 91 | Iteration number: [440/565] 77% | Training loss: 0.6883083274418658
Epoch: 91 | Iteration number: [450/565] 79% | Training loss: 0.6882762430773841
Epoch: 91 | Iteration number: [460/565] 81% | Training loss: 0.6882483018481214
Epoch: 91 | Iteration number: [470/565] 83% | Training loss: 0.6882147334991617
Epoch: 91 | Iteration number: [480/565] 84% | Training loss: 0.6881800405681133
Epoch: 91 | Iteration number: [490/565] 86% | Training loss: 0.6881620685664975
Epoch: 91 | Iteration number: [500/565] 88% | Training loss: 0.6881330851316452
Epoch: 91 | Iteration number: [510/565] 90% | Training loss: 0.6880949729797887
Epoch: 91 | Iteration number: [520/565] 92% | Training loss: 0.6880732057186273
Epoch: 91 | Iteration number: [530/565] 93% | Training loss: 0.6880454241104845
Epoch: 91 | Iteration number: [540/565] 95% | Training loss: 0.6880235377285215
Epoch: 91 | Iteration number: [550/565] 97% | Training loss: 0.6880024593526667
Epoch: 91 | Iteration number: [560/565] 99% | Training loss: 0.687987408041954

 End of epoch: 91 | Train Loss: 0.6867572812907463 | Training Time: 91 

 End of epoch: 91 | Eval Loss: 0.6886545164244515 | Evaluating Time: 6 
Epoch: 92 | Iteration number: [10/565] 1% | Training loss: 0.7552297532558441
Epoch: 92 | Iteration number: [20/565] 3% | Training loss: 0.7208715885877609
Epoch: 92 | Iteration number: [30/565] 5% | Training loss: 0.7094932953516643
Epoch: 92 | Iteration number: [40/565] 7% | Training loss: 0.7037645608186722
Epoch: 92 | Iteration number: [50/565] 8% | Training loss: 0.7004278218746185
Epoch: 92 | Iteration number: [60/565] 10% | Training loss: 0.6980526387691498
Epoch: 92 | Iteration number: [70/565] 12% | Training loss: 0.6964254353727614
Epoch: 92 | Iteration number: [80/565] 14% | Training loss: 0.6951884917914868
Epoch: 92 | Iteration number: [90/565] 15% | Training loss: 0.6941990494728089
Epoch: 92 | Iteration number: [100/565] 17% | Training loss: 0.6934370249509811
Epoch: 92 | Iteration number: [110/565] 19% | Training loss: 0.6928144119002603
Epoch: 92 | Iteration number: [120/565] 21% | Training loss: 0.6922948534289995
Epoch: 92 | Iteration number: [130/565] 23% | Training loss: 0.6918647458920112
Epoch: 92 | Iteration number: [140/565] 24% | Training loss: 0.6915067323616573
Epoch: 92 | Iteration number: [150/565] 26% | Training loss: 0.6911679832140605
Epoch: 92 | Iteration number: [160/565] 28% | Training loss: 0.690853961929679
Epoch: 92 | Iteration number: [170/565] 30% | Training loss: 0.6906085782191332
Epoch: 92 | Iteration number: [180/565] 31% | Training loss: 0.6903879791498184
Epoch: 92 | Iteration number: [190/565] 33% | Training loss: 0.690214969609913
Epoch: 92 | Iteration number: [200/565] 35% | Training loss: 0.690053918659687
Epoch: 92 | Iteration number: [210/565] 37% | Training loss: 0.6899069161642165
Epoch: 92 | Iteration number: [220/565] 38% | Training loss: 0.689784340154041
Epoch: 92 | Iteration number: [230/565] 40% | Training loss: 0.6896557357000268
Epoch: 92 | Iteration number: [240/565] 42% | Training loss: 0.6895054390033086
Epoch: 92 | Iteration number: [250/565] 44% | Training loss: 0.6894073054790497
Epoch: 92 | Iteration number: [260/565] 46% | Training loss: 0.6892967687203334
Epoch: 92 | Iteration number: [270/565] 47% | Training loss: 0.689211274738665
Epoch: 92 | Iteration number: [280/565] 49% | Training loss: 0.6891173098768507
Epoch: 92 | Iteration number: [290/565] 51% | Training loss: 0.6890442375479073
Epoch: 92 | Iteration number: [300/565] 53% | Training loss: 0.6889800681670507
Epoch: 92 | Iteration number: [310/565] 54% | Training loss: 0.6889249617053617
Epoch: 92 | Iteration number: [320/565] 56% | Training loss: 0.6888567361980676
Epoch: 92 | Iteration number: [330/565] 58% | Training loss: 0.6887989139918125
Epoch: 92 | Iteration number: [340/565] 60% | Training loss: 0.6887334618498298
Epoch: 92 | Iteration number: [350/565] 61% | Training loss: 0.6886798550401415
Epoch: 92 | Iteration number: [360/565] 63% | Training loss: 0.6886157282524639
Epoch: 92 | Iteration number: [370/565] 65% | Training loss: 0.6885586641930245
Epoch: 92 | Iteration number: [380/565] 67% | Training loss: 0.6885145515203476
Epoch: 92 | Iteration number: [390/565] 69% | Training loss: 0.6884806668147062
Epoch: 92 | Iteration number: [400/565] 70% | Training loss: 0.6884360717236996
Epoch: 92 | Iteration number: [410/565] 72% | Training loss: 0.6883921572347966
Epoch: 92 | Iteration number: [420/565] 74% | Training loss: 0.6883471388192404
Epoch: 92 | Iteration number: [430/565] 76% | Training loss: 0.6883156427117281
Epoch: 92 | Iteration number: [440/565] 77% | Training loss: 0.6882720465009863
Epoch: 92 | Iteration number: [450/565] 79% | Training loss: 0.6882429220941332
Epoch: 92 | Iteration number: [460/565] 81% | Training loss: 0.6882199775913488
Epoch: 92 | Iteration number: [470/565] 83% | Training loss: 0.6881942916423717
Epoch: 92 | Iteration number: [480/565] 84% | Training loss: 0.6881680611521006
Epoch: 92 | Iteration number: [490/565] 86% | Training loss: 0.6881437551002113
Epoch: 92 | Iteration number: [500/565] 88% | Training loss: 0.6881117360591888
Epoch: 92 | Iteration number: [510/565] 90% | Training loss: 0.6880839192399791
Epoch: 92 | Iteration number: [520/565] 92% | Training loss: 0.6880619334486815
Epoch: 92 | Iteration number: [530/565] 93% | Training loss: 0.6880320157644884
Epoch: 92 | Iteration number: [540/565] 95% | Training loss: 0.6880192914494762
Epoch: 92 | Iteration number: [550/565] 97% | Training loss: 0.6880038037083366
Epoch: 92 | Iteration number: [560/565] 99% | Training loss: 0.6879842921027115

 End of epoch: 92 | Train Loss: 0.6867551435411504 | Training Time: 89 

 End of epoch: 92 | Eval Loss: 0.6897380607468742 | Evaluating Time: 5 
Epoch: 93 | Iteration number: [10/565] 1% | Training loss: 0.7557310819625854
Epoch: 93 | Iteration number: [20/565] 3% | Training loss: 0.7213284194469451
Epoch: 93 | Iteration number: [30/565] 5% | Training loss: 0.7097748299439748
Epoch: 93 | Iteration number: [40/565] 7% | Training loss: 0.7039901435375213
Epoch: 93 | Iteration number: [50/565] 8% | Training loss: 0.7004907989501953
Epoch: 93 | Iteration number: [60/565] 10% | Training loss: 0.6981425295273463
Epoch: 93 | Iteration number: [70/565] 12% | Training loss: 0.6964834102562496
Epoch: 93 | Iteration number: [80/565] 14% | Training loss: 0.6952459707856178
Epoch: 93 | Iteration number: [90/565] 15% | Training loss: 0.694286757045322
Epoch: 93 | Iteration number: [100/565] 17% | Training loss: 0.6935500556230545
Epoch: 93 | Iteration number: [110/565] 19% | Training loss: 0.6929325959899209
Epoch: 93 | Iteration number: [120/565] 21% | Training loss: 0.6923913141091664
Epoch: 93 | Iteration number: [130/565] 23% | Training loss: 0.6919617166885963
Epoch: 93 | Iteration number: [140/565] 24% | Training loss: 0.6915621429681778
Epoch: 93 | Iteration number: [150/565] 26% | Training loss: 0.6912417383988698
Epoch: 93 | Iteration number: [160/565] 28% | Training loss: 0.6909652460366488
Epoch: 93 | Iteration number: [170/565] 30% | Training loss: 0.690731320661657
Epoch: 93 | Iteration number: [180/565] 31% | Training loss: 0.690484901269277
Epoch: 93 | Iteration number: [190/565] 33% | Training loss: 0.6902833289221714
Epoch: 93 | Iteration number: [200/565] 35% | Training loss: 0.6901059660315514
Epoch: 93 | Iteration number: [210/565] 37% | Training loss: 0.6899253813993363
Epoch: 93 | Iteration number: [220/565] 38% | Training loss: 0.6897782244465568
Epoch: 93 | Iteration number: [230/565] 40% | Training loss: 0.6896502595880757
Epoch: 93 | Iteration number: [240/565] 42% | Training loss: 0.6895139008760452
Epoch: 93 | Iteration number: [250/565] 44% | Training loss: 0.689407032251358
Epoch: 93 | Iteration number: [260/565] 46% | Training loss: 0.6893020533598386
Epoch: 93 | Iteration number: [270/565] 47% | Training loss: 0.6891964735808196
Epoch: 93 | Iteration number: [280/565] 49% | Training loss: 0.6891124863709722
Epoch: 93 | Iteration number: [290/565] 51% | Training loss: 0.6890311643995087
Epoch: 93 | Iteration number: [300/565] 53% | Training loss: 0.6889519633849462
Epoch: 93 | Iteration number: [310/565] 54% | Training loss: 0.6888790651675194
Epoch: 93 | Iteration number: [320/565] 56% | Training loss: 0.6888127729296685
Epoch: 93 | Iteration number: [330/565] 58% | Training loss: 0.6887597638549227
Epoch: 93 | Iteration number: [340/565] 60% | Training loss: 0.68871330250712
Epoch: 93 | Iteration number: [350/565] 61% | Training loss: 0.6886669271332877
Epoch: 93 | Iteration number: [360/565] 63% | Training loss: 0.6886228506763776
Epoch: 93 | Iteration number: [370/565] 65% | Training loss: 0.6885813840337702
Epoch: 93 | Iteration number: [380/565] 67% | Training loss: 0.6885216152981708
Epoch: 93 | Iteration number: [390/565] 69% | Training loss: 0.6884847877881466
Epoch: 93 | Iteration number: [400/565] 70% | Training loss: 0.6884423942863941
Epoch: 93 | Iteration number: [410/565] 72% | Training loss: 0.6883909860762154
Epoch: 93 | Iteration number: [420/565] 74% | Training loss: 0.6883692710172562
Epoch: 93 | Iteration number: [430/565] 76% | Training loss: 0.6883275356403616
Epoch: 93 | Iteration number: [440/565] 77% | Training loss: 0.688301506638527
Epoch: 93 | Iteration number: [450/565] 79% | Training loss: 0.6882712996006012
Epoch: 93 | Iteration number: [460/565] 81% | Training loss: 0.6882422053295633
Epoch: 93 | Iteration number: [470/565] 83% | Training loss: 0.6882112456128953
Epoch: 93 | Iteration number: [480/565] 84% | Training loss: 0.6881883824865024
Epoch: 93 | Iteration number: [490/565] 86% | Training loss: 0.6881589186434843
Epoch: 93 | Iteration number: [500/565] 88% | Training loss: 0.6881399292945862
Epoch: 93 | Iteration number: [510/565] 90% | Training loss: 0.6881114348477009
Epoch: 93 | Iteration number: [520/565] 92% | Training loss: 0.6880735172675206
Epoch: 93 | Iteration number: [530/565] 93% | Training loss: 0.6880512613170552
Epoch: 93 | Iteration number: [540/565] 95% | Training loss: 0.6880277276039124
Epoch: 93 | Iteration number: [550/565] 97% | Training loss: 0.6880025446414948
Epoch: 93 | Iteration number: [560/565] 99% | Training loss: 0.6879785942179816

 End of epoch: 93 | Train Loss: 0.6867528939669111 | Training Time: 87 

 End of epoch: 93 | Eval Loss: 0.6900076355252948 | Evaluating Time: 6 
Epoch: 94 | Iteration number: [10/565] 1% | Training loss: 0.7548142015933991
Epoch: 94 | Iteration number: [20/565] 3% | Training loss: 0.7209262728691102
Epoch: 94 | Iteration number: [30/565] 5% | Training loss: 0.7095420062541962
Epoch: 94 | Iteration number: [40/565] 7% | Training loss: 0.7037767201662064
Epoch: 94 | Iteration number: [50/565] 8% | Training loss: 0.7003379499912262
Epoch: 94 | Iteration number: [60/565] 10% | Training loss: 0.6981572210788727
Epoch: 94 | Iteration number: [70/565] 12% | Training loss: 0.6965116901057107
Epoch: 94 | Iteration number: [80/565] 14% | Training loss: 0.6953022748231887
Epoch: 94 | Iteration number: [90/565] 15% | Training loss: 0.6943117393387689
Epoch: 94 | Iteration number: [100/565] 17% | Training loss: 0.6935753673315048
Epoch: 94 | Iteration number: [110/565] 19% | Training loss: 0.6929465223442425
Epoch: 94 | Iteration number: [120/565] 21% | Training loss: 0.6924280320604642
Epoch: 94 | Iteration number: [130/565] 23% | Training loss: 0.691999161701936
Epoch: 94 | Iteration number: [140/565] 24% | Training loss: 0.6915896981954575
Epoch: 94 | Iteration number: [150/565] 26% | Training loss: 0.6912877523899078
Epoch: 94 | Iteration number: [160/565] 28% | Training loss: 0.6910093627870083
Epoch: 94 | Iteration number: [170/565] 30% | Training loss: 0.6907488850986256
Epoch: 94 | Iteration number: [180/565] 31% | Training loss: 0.6905088222689099
Epoch: 94 | Iteration number: [190/565] 33% | Training loss: 0.6903110159070869
Epoch: 94 | Iteration number: [200/565] 35% | Training loss: 0.6901442682743073
Epoch: 94 | Iteration number: [210/565] 37% | Training loss: 0.6899911514350346
Epoch: 94 | Iteration number: [220/565] 38% | Training loss: 0.6898282728411934
Epoch: 94 | Iteration number: [230/565] 40% | Training loss: 0.6896967553574106
Epoch: 94 | Iteration number: [240/565] 42% | Training loss: 0.6895646167298158
Epoch: 94 | Iteration number: [250/565] 44% | Training loss: 0.689441291809082
Epoch: 94 | Iteration number: [260/565] 46% | Training loss: 0.689324595607244
Epoch: 94 | Iteration number: [270/565] 47% | Training loss: 0.6892392648590936
Epoch: 94 | Iteration number: [280/565] 49% | Training loss: 0.6891685060092381
Epoch: 94 | Iteration number: [290/565] 51% | Training loss: 0.6891064929551092
Epoch: 94 | Iteration number: [300/565] 53% | Training loss: 0.6890247869491577
Epoch: 94 | Iteration number: [310/565] 54% | Training loss: 0.6889454407076682
Epoch: 94 | Iteration number: [320/565] 56% | Training loss: 0.688882669992745
Epoch: 94 | Iteration number: [330/565] 58% | Training loss: 0.6888117923881069
Epoch: 94 | Iteration number: [340/565] 60% | Training loss: 0.6887454981313033
Epoch: 94 | Iteration number: [350/565] 61% | Training loss: 0.6886832545484816
Epoch: 94 | Iteration number: [360/565] 63% | Training loss: 0.6886340732375781
Epoch: 94 | Iteration number: [370/565] 65% | Training loss: 0.6885714632433814
Epoch: 94 | Iteration number: [380/565] 67% | Training loss: 0.6885271050428089
Epoch: 94 | Iteration number: [390/565] 69% | Training loss: 0.6884745744558481
Epoch: 94 | Iteration number: [400/565] 70% | Training loss: 0.6884351244568825
Epoch: 94 | Iteration number: [410/565] 72% | Training loss: 0.6883892296290979
Epoch: 94 | Iteration number: [420/565] 74% | Training loss: 0.6883551274027143
Epoch: 94 | Iteration number: [430/565] 76% | Training loss: 0.6883193214272344
Epoch: 94 | Iteration number: [440/565] 77% | Training loss: 0.6882914927872744
Epoch: 94 | Iteration number: [450/565] 79% | Training loss: 0.6882620092233022
Epoch: 94 | Iteration number: [460/565] 81% | Training loss: 0.6882230005834413
Epoch: 94 | Iteration number: [470/565] 83% | Training loss: 0.6881923600714257
Epoch: 94 | Iteration number: [480/565] 84% | Training loss: 0.6881625744203727
Epoch: 94 | Iteration number: [490/565] 86% | Training loss: 0.688134935802343
Epoch: 94 | Iteration number: [500/565] 88% | Training loss: 0.6881068571805954
Epoch: 94 | Iteration number: [510/565] 90% | Training loss: 0.6880833111557306
Epoch: 94 | Iteration number: [520/565] 92% | Training loss: 0.6880582687946466
Epoch: 94 | Iteration number: [530/565] 93% | Training loss: 0.6880350381698248
Epoch: 94 | Iteration number: [540/565] 95% | Training loss: 0.6880115154716704
Epoch: 94 | Iteration number: [550/565] 97% | Training loss: 0.6879879455132918
Epoch: 94 | Iteration number: [560/565] 99% | Training loss: 0.6879740734185491

 End of epoch: 94 | Train Loss: 0.686751356061581 | Training Time: 89 

 End of epoch: 94 | Eval Loss: 0.6894564202853611 | Evaluating Time: 6 
Epoch: 95 | Iteration number: [10/565] 1% | Training loss: 0.7559897840023041
Epoch: 95 | Iteration number: [20/565] 3% | Training loss: 0.7211962759494781
Epoch: 95 | Iteration number: [30/565] 5% | Training loss: 0.7097617506980896
Epoch: 95 | Iteration number: [40/565] 7% | Training loss: 0.7040111616253852
Epoch: 95 | Iteration number: [50/565] 8% | Training loss: 0.7005253911018372
Epoch: 95 | Iteration number: [60/565] 10% | Training loss: 0.6981886277596155
Epoch: 95 | Iteration number: [70/565] 12% | Training loss: 0.696458592585155
Epoch: 95 | Iteration number: [80/565] 14% | Training loss: 0.6953119523823261
Epoch: 95 | Iteration number: [90/565] 15% | Training loss: 0.6942996713850234
Epoch: 95 | Iteration number: [100/565] 17% | Training loss: 0.6935748487710953
Epoch: 95 | Iteration number: [110/565] 19% | Training loss: 0.6929359609430487
Epoch: 95 | Iteration number: [120/565] 21% | Training loss: 0.6924088900287946
Epoch: 95 | Iteration number: [130/565] 23% | Training loss: 0.6919644149450156
Epoch: 95 | Iteration number: [140/565] 24% | Training loss: 0.6916119839463916
Epoch: 95 | Iteration number: [150/565] 26% | Training loss: 0.6912991623083751
Epoch: 95 | Iteration number: [160/565] 28% | Training loss: 0.6910084679722786
Epoch: 95 | Iteration number: [170/565] 30% | Training loss: 0.690765243768692
Epoch: 95 | Iteration number: [180/565] 31% | Training loss: 0.6905877507395215
Epoch: 95 | Iteration number: [190/565] 33% | Training loss: 0.6903751272904245
Epoch: 95 | Iteration number: [200/565] 35% | Training loss: 0.6902203941345215
Epoch: 95 | Iteration number: [210/565] 37% | Training loss: 0.6900769327368055
Epoch: 95 | Iteration number: [220/565] 38% | Training loss: 0.689941664446484
Epoch: 95 | Iteration number: [230/565] 40% | Training loss: 0.6898014923800593
Epoch: 95 | Iteration number: [240/565] 42% | Training loss: 0.689699791620175
Epoch: 95 | Iteration number: [250/565] 44% | Training loss: 0.6895885684490204
Epoch: 95 | Iteration number: [260/565] 46% | Training loss: 0.6895015906829101
Epoch: 95 | Iteration number: [270/565] 47% | Training loss: 0.6893991653566007
Epoch: 95 | Iteration number: [280/565] 49% | Training loss: 0.689323587502752
Epoch: 95 | Iteration number: [290/565] 51% | Training loss: 0.6892388512348306
Epoch: 95 | Iteration number: [300/565] 53% | Training loss: 0.6891567800442377
Epoch: 95 | Iteration number: [310/565] 54% | Training loss: 0.6890543614664385
Epoch: 95 | Iteration number: [320/565] 56% | Training loss: 0.6889784507453441
Epoch: 95 | Iteration number: [330/565] 58% | Training loss: 0.6889229501738693
Epoch: 95 | Iteration number: [340/565] 60% | Training loss: 0.6888530603226494
Epoch: 95 | Iteration number: [350/565] 61% | Training loss: 0.6887772866657802
Epoch: 95 | Iteration number: [360/565] 63% | Training loss: 0.6887229611476262
Epoch: 95 | Iteration number: [370/565] 65% | Training loss: 0.6886689091050947
Epoch: 95 | Iteration number: [380/565] 67% | Training loss: 0.6886134088039398
Epoch: 95 | Iteration number: [390/565] 69% | Training loss: 0.6885638987406706
Epoch: 95 | Iteration number: [400/565] 70% | Training loss: 0.6885298602283001
Epoch: 95 | Iteration number: [410/565] 72% | Training loss: 0.6884813138624517
Epoch: 95 | Iteration number: [420/565] 74% | Training loss: 0.688425584634145
Epoch: 95 | Iteration number: [430/565] 76% | Training loss: 0.6883899655452994
Epoch: 95 | Iteration number: [440/565] 77% | Training loss: 0.6883525534109636
Epoch: 95 | Iteration number: [450/565] 79% | Training loss: 0.688321307765113
Epoch: 95 | Iteration number: [460/565] 81% | Training loss: 0.6882807190003603
Epoch: 95 | Iteration number: [470/565] 83% | Training loss: 0.688247119239036
Epoch: 95 | Iteration number: [480/565] 84% | Training loss: 0.6882176016767819
Epoch: 95 | Iteration number: [490/565] 86% | Training loss: 0.6881848559087637
Epoch: 95 | Iteration number: [500/565] 88% | Training loss: 0.6881658169031143
Epoch: 95 | Iteration number: [510/565] 90% | Training loss: 0.6881422136344162
Epoch: 95 | Iteration number: [520/565] 92% | Training loss: 0.6881045349515401
Epoch: 95 | Iteration number: [530/565] 93% | Training loss: 0.6880703348033833
Epoch: 95 | Iteration number: [540/565] 95% | Training loss: 0.6880485550121025
Epoch: 95 | Iteration number: [550/565] 97% | Training loss: 0.6880218099464069
Epoch: 95 | Iteration number: [560/565] 99% | Training loss: 0.6880015145455088

 End of epoch: 95 | Train Loss: 0.6867743241048492 | Training Time: 89 

 End of epoch: 95 | Eval Loss: 0.6900623611041478 | Evaluating Time: 5 
Epoch: 96 | Iteration number: [10/565] 1% | Training loss: 0.7554364264011383
Epoch: 96 | Iteration number: [20/565] 3% | Training loss: 0.721272760629654
Epoch: 96 | Iteration number: [30/565] 5% | Training loss: 0.7098017116387685
Epoch: 96 | Iteration number: [40/565] 7% | Training loss: 0.7039303049445153
Epoch: 96 | Iteration number: [50/565] 8% | Training loss: 0.7004837834835053
Epoch: 96 | Iteration number: [60/565] 10% | Training loss: 0.6982770919799804
Epoch: 96 | Iteration number: [70/565] 12% | Training loss: 0.6967070920126779
Epoch: 96 | Iteration number: [80/565] 14% | Training loss: 0.6954268693923951
Epoch: 96 | Iteration number: [90/565] 15% | Training loss: 0.6944508545928532
Epoch: 96 | Iteration number: [100/565] 17% | Training loss: 0.6936837702989578
Epoch: 96 | Iteration number: [110/565] 19% | Training loss: 0.6930601298809052
Epoch: 96 | Iteration number: [120/565] 21% | Training loss: 0.6925291702151298
Epoch: 96 | Iteration number: [130/565] 23% | Training loss: 0.6920727885686434
Epoch: 96 | Iteration number: [140/565] 24% | Training loss: 0.6916946457965033
Epoch: 96 | Iteration number: [150/565] 26% | Training loss: 0.6913661670684814
Epoch: 96 | Iteration number: [160/565] 28% | Training loss: 0.6910872045904398
Epoch: 96 | Iteration number: [170/565] 30% | Training loss: 0.6908508952926187
Epoch: 96 | Iteration number: [180/565] 31% | Training loss: 0.6906402409076691
Epoch: 96 | Iteration number: [190/565] 33% | Training loss: 0.6904508361690923
Epoch: 96 | Iteration number: [200/565] 35% | Training loss: 0.6902812495827675
Epoch: 96 | Iteration number: [210/565] 37% | Training loss: 0.6901078789007096
Epoch: 96 | Iteration number: [220/565] 38% | Training loss: 0.6899454940449108
Epoch: 96 | Iteration number: [230/565] 40% | Training loss: 0.689806756765946
Epoch: 96 | Iteration number: [240/565] 42% | Training loss: 0.6896792158484459
Epoch: 96 | Iteration number: [250/565] 44% | Training loss: 0.6895619311332702
Epoch: 96 | Iteration number: [260/565] 46% | Training loss: 0.6894533794659835
Epoch: 96 | Iteration number: [270/565] 47% | Training loss: 0.6893569571000558
Epoch: 96 | Iteration number: [280/565] 49% | Training loss: 0.6892578801938466
Epoch: 96 | Iteration number: [290/565] 51% | Training loss: 0.6891789154759769
Epoch: 96 | Iteration number: [300/565] 53% | Training loss: 0.6890978389978408
Epoch: 96 | Iteration number: [310/565] 54% | Training loss: 0.6890069373192326
Epoch: 96 | Iteration number: [320/565] 56% | Training loss: 0.6889477971941232
Epoch: 96 | Iteration number: [330/565] 58% | Training loss: 0.6888916665857489
Epoch: 96 | Iteration number: [340/565] 60% | Training loss: 0.6888253916712368
Epoch: 96 | Iteration number: [350/565] 61% | Training loss: 0.6887523659637996
Epoch: 96 | Iteration number: [360/565] 63% | Training loss: 0.6887024621168772
Epoch: 96 | Iteration number: [370/565] 65% | Training loss: 0.6886645321910446
Epoch: 96 | Iteration number: [380/565] 67% | Training loss: 0.6886181516082663
Epoch: 96 | Iteration number: [390/565] 69% | Training loss: 0.6885587476767027
Epoch: 96 | Iteration number: [400/565] 70% | Training loss: 0.6885168737173081
Epoch: 96 | Iteration number: [410/565] 72% | Training loss: 0.6884637238048925
Epoch: 96 | Iteration number: [420/565] 74% | Training loss: 0.6884259067830585
Epoch: 96 | Iteration number: [430/565] 76% | Training loss: 0.6883866181207258
Epoch: 96 | Iteration number: [440/565] 77% | Training loss: 0.688342321054502
Epoch: 96 | Iteration number: [450/565] 79% | Training loss: 0.6883121530214945
Epoch: 96 | Iteration number: [460/565] 81% | Training loss: 0.6882732793040898
Epoch: 96 | Iteration number: [470/565] 83% | Training loss: 0.6882426266974592
Epoch: 96 | Iteration number: [480/565] 84% | Training loss: 0.688211548452576
Epoch: 96 | Iteration number: [490/565] 86% | Training loss: 0.6881701784474509
Epoch: 96 | Iteration number: [500/565] 88% | Training loss: 0.6881385928392411
Epoch: 96 | Iteration number: [510/565] 90% | Training loss: 0.6881116921995201
Epoch: 96 | Iteration number: [520/565] 92% | Training loss: 0.688082455098629
Epoch: 96 | Iteration number: [530/565] 93% | Training loss: 0.6880610381657223
Epoch: 96 | Iteration number: [540/565] 95% | Training loss: 0.6880450413182929
Epoch: 96 | Iteration number: [550/565] 97% | Training loss: 0.6880127503655173
Epoch: 96 | Iteration number: [560/565] 99% | Training loss: 0.6879830220980304

 End of epoch: 96 | Train Loss: 0.6867537704189267 | Training Time: 88 

 End of epoch: 96 | Eval Loss: 0.689692599432809 | Evaluating Time: 6 
Epoch: 97 | Iteration number: [10/565] 1% | Training loss: 0.7550057768821716
Epoch: 97 | Iteration number: [20/565] 3% | Training loss: 0.7206041663885117
Epoch: 97 | Iteration number: [30/565] 5% | Training loss: 0.7093756596247355
Epoch: 97 | Iteration number: [40/565] 7% | Training loss: 0.7036850363016128
Epoch: 97 | Iteration number: [50/565] 8% | Training loss: 0.7002246367931366
Epoch: 97 | Iteration number: [60/565] 10% | Training loss: 0.6979946613311767
Epoch: 97 | Iteration number: [70/565] 12% | Training loss: 0.6963727678571429
Epoch: 97 | Iteration number: [80/565] 14% | Training loss: 0.6951348550617695
Epoch: 97 | Iteration number: [90/565] 15% | Training loss: 0.6942457483874427
Epoch: 97 | Iteration number: [100/565] 17% | Training loss: 0.693479192852974
Epoch: 97 | Iteration number: [110/565] 19% | Training loss: 0.6928594556721774
Epoch: 97 | Iteration number: [120/565] 21% | Training loss: 0.6923663611213366
Epoch: 97 | Iteration number: [130/565] 23% | Training loss: 0.69193146778987
Epoch: 97 | Iteration number: [140/565] 24% | Training loss: 0.6915478203977857
Epoch: 97 | Iteration number: [150/565] 26% | Training loss: 0.6912057836850484
Epoch: 97 | Iteration number: [160/565] 28% | Training loss: 0.6909139007329941
Epoch: 97 | Iteration number: [170/565] 30% | Training loss: 0.690678300927667
Epoch: 97 | Iteration number: [180/565] 31% | Training loss: 0.6904914985100429
Epoch: 97 | Iteration number: [190/565] 33% | Training loss: 0.6902899927214572
Epoch: 97 | Iteration number: [200/565] 35% | Training loss: 0.690139362514019
Epoch: 97 | Iteration number: [210/565] 37% | Training loss: 0.6899814506371816
Epoch: 97 | Iteration number: [220/565] 38% | Training loss: 0.6898405592549931
Epoch: 97 | Iteration number: [230/565] 40% | Training loss: 0.6896882816501285
Epoch: 97 | Iteration number: [240/565] 42% | Training loss: 0.6895642501612504
Epoch: 97 | Iteration number: [250/565] 44% | Training loss: 0.6894676401615143
Epoch: 97 | Iteration number: [260/565] 46% | Training loss: 0.6893860344703381
Epoch: 97 | Iteration number: [270/565] 47% | Training loss: 0.6892969464814221
Epoch: 97 | Iteration number: [280/565] 49% | Training loss: 0.689226505798953
Epoch: 97 | Iteration number: [290/565] 51% | Training loss: 0.6891525920095115
Epoch: 97 | Iteration number: [300/565] 53% | Training loss: 0.6890833137432734
Epoch: 97 | Iteration number: [310/565] 54% | Training loss: 0.689006725434334
Epoch: 97 | Iteration number: [320/565] 56% | Training loss: 0.6889467583969235
Epoch: 97 | Iteration number: [330/565] 58% | Training loss: 0.6888834516207377
Epoch: 97 | Iteration number: [340/565] 60% | Training loss: 0.6888080186703626
Epoch: 97 | Iteration number: [350/565] 61% | Training loss: 0.6887519528184618
Epoch: 97 | Iteration number: [360/565] 63% | Training loss: 0.6887002329031626
Epoch: 97 | Iteration number: [370/565] 65% | Training loss: 0.6886391182203551
Epoch: 97 | Iteration number: [380/565] 67% | Training loss: 0.6885821138557635
Epoch: 97 | Iteration number: [390/565] 69% | Training loss: 0.6885356065554497
Epoch: 97 | Iteration number: [400/565] 70% | Training loss: 0.6885057185590268
Epoch: 97 | Iteration number: [410/565] 72% | Training loss: 0.6884574957010222
Epoch: 97 | Iteration number: [420/565] 74% | Training loss: 0.6884206219798042
Epoch: 97 | Iteration number: [430/565] 76% | Training loss: 0.6883837595928547
Epoch: 97 | Iteration number: [440/565] 77% | Training loss: 0.6883432980288159
Epoch: 97 | Iteration number: [450/565] 79% | Training loss: 0.6882999454604255
Epoch: 97 | Iteration number: [460/565] 81% | Training loss: 0.6882572639247645
Epoch: 97 | Iteration number: [470/565] 83% | Training loss: 0.6882213312260648
Epoch: 97 | Iteration number: [480/565] 84% | Training loss: 0.6881895318627358
Epoch: 97 | Iteration number: [490/565] 86% | Training loss: 0.6881668525082725
Epoch: 97 | Iteration number: [500/565] 88% | Training loss: 0.6881277565956115
Epoch: 97 | Iteration number: [510/565] 90% | Training loss: 0.6881037059952231
Epoch: 97 | Iteration number: [520/565] 92% | Training loss: 0.6880771882258929
Epoch: 97 | Iteration number: [530/565] 93% | Training loss: 0.6880431387784346
Epoch: 97 | Iteration number: [540/565] 95% | Training loss: 0.6880176333365617
Epoch: 97 | Iteration number: [550/565] 97% | Training loss: 0.6879936933517456
Epoch: 97 | Iteration number: [560/565] 99% | Training loss: 0.6879718448434557

 End of epoch: 97 | Train Loss: 0.6867479386582839 | Training Time: 89 

 End of epoch: 97 | Eval Loss: 0.6895765236445835 | Evaluating Time: 6 
Epoch: 98 | Iteration number: [10/565] 1% | Training loss: 0.7552907168865204
Epoch: 98 | Iteration number: [20/565] 3% | Training loss: 0.7209960907697678
Epoch: 98 | Iteration number: [30/565] 5% | Training loss: 0.7094750324885051
Epoch: 98 | Iteration number: [40/565] 7% | Training loss: 0.7038262590765954
Epoch: 98 | Iteration number: [50/565] 8% | Training loss: 0.7005413568019867
Epoch: 98 | Iteration number: [60/565] 10% | Training loss: 0.6982332855463028
Epoch: 98 | Iteration number: [70/565] 12% | Training loss: 0.6966410543237413
Epoch: 98 | Iteration number: [80/565] 14% | Training loss: 0.6953644827008247
Epoch: 98 | Iteration number: [90/565] 15% | Training loss: 0.6943641801675161
Epoch: 98 | Iteration number: [100/565] 17% | Training loss: 0.6935545092821122
Epoch: 98 | Iteration number: [110/565] 19% | Training loss: 0.6929451872001995
Epoch: 98 | Iteration number: [120/565] 21% | Training loss: 0.6924493074417114
Epoch: 98 | Iteration number: [130/565] 23% | Training loss: 0.6920466432204613
Epoch: 98 | Iteration number: [140/565] 24% | Training loss: 0.6916960243667875
Epoch: 98 | Iteration number: [150/565] 26% | Training loss: 0.691396118402481
Epoch: 98 | Iteration number: [160/565] 28% | Training loss: 0.6911146957427263
Epoch: 98 | Iteration number: [170/565] 30% | Training loss: 0.6908227177227244
Epoch: 98 | Iteration number: [180/565] 31% | Training loss: 0.6905723296933703
Epoch: 98 | Iteration number: [190/565] 33% | Training loss: 0.6903842577808782
Epoch: 98 | Iteration number: [200/565] 35% | Training loss: 0.690195060968399
Epoch: 98 | Iteration number: [210/565] 37% | Training loss: 0.6900027263732184
Epoch: 98 | Iteration number: [220/565] 38% | Training loss: 0.689886179024523
Epoch: 98 | Iteration number: [230/565] 40% | Training loss: 0.6897559552089028
Epoch: 98 | Iteration number: [240/565] 42% | Training loss: 0.6896280450125535
Epoch: 98 | Iteration number: [250/565] 44% | Training loss: 0.6895159387588501
Epoch: 98 | Iteration number: [260/565] 46% | Training loss: 0.6894183342273419
Epoch: 98 | Iteration number: [270/565] 47% | Training loss: 0.6893189659825077
Epoch: 98 | Iteration number: [280/565] 49% | Training loss: 0.6892161533236504
Epoch: 98 | Iteration number: [290/565] 51% | Training loss: 0.6891435684828923
Epoch: 98 | Iteration number: [300/565] 53% | Training loss: 0.6890773518880209
Epoch: 98 | Iteration number: [310/565] 54% | Training loss: 0.6889929029249375
Epoch: 98 | Iteration number: [320/565] 56% | Training loss: 0.688905737362802
Epoch: 98 | Iteration number: [330/565] 58% | Training loss: 0.6888394635735136
Epoch: 98 | Iteration number: [340/565] 60% | Training loss: 0.6887677823795991
Epoch: 98 | Iteration number: [350/565] 61% | Training loss: 0.6887187332766397
Epoch: 98 | Iteration number: [360/565] 63% | Training loss: 0.688663661148813
Epoch: 98 | Iteration number: [370/565] 65% | Training loss: 0.6886276981315097
Epoch: 98 | Iteration number: [380/565] 67% | Training loss: 0.6885785551447617
Epoch: 98 | Iteration number: [390/565] 69% | Training loss: 0.6885263302387336
Epoch: 98 | Iteration number: [400/565] 70% | Training loss: 0.6884759047627449
Epoch: 98 | Iteration number: [410/565] 72% | Training loss: 0.6884397633192015
Epoch: 98 | Iteration number: [420/565] 74% | Training loss: 0.6884017585288911
Epoch: 98 | Iteration number: [430/565] 76% | Training loss: 0.6883505803208019
Epoch: 98 | Iteration number: [440/565] 77% | Training loss: 0.688323244994337
Epoch: 98 | Iteration number: [450/565] 79% | Training loss: 0.6882824603716532
Epoch: 98 | Iteration number: [460/565] 81% | Training loss: 0.6882550484460334
Epoch: 98 | Iteration number: [470/565] 83% | Training loss: 0.6882280933096053
Epoch: 98 | Iteration number: [480/565] 84% | Training loss: 0.6881997841099898
Epoch: 98 | Iteration number: [490/565] 86% | Training loss: 0.6881686969679229
Epoch: 98 | Iteration number: [500/565] 88% | Training loss: 0.6881411479711532
Epoch: 98 | Iteration number: [510/565] 90% | Training loss: 0.6881180080713011
Epoch: 98 | Iteration number: [520/565] 92% | Training loss: 0.6880961370009643
Epoch: 98 | Iteration number: [530/565] 93% | Training loss: 0.6880733302179373
Epoch: 98 | Iteration number: [540/565] 95% | Training loss: 0.6880536197512238
Epoch: 98 | Iteration number: [550/565] 97% | Training loss: 0.6880296248739416
Epoch: 98 | Iteration number: [560/565] 99% | Training loss: 0.6880009104098592

 End of epoch: 98 | Train Loss: 0.6867728469646083 | Training Time: 88 

 End of epoch: 98 | Eval Loss: 0.6901169504438128 | Evaluating Time: 6 
Epoch: 99 | Iteration number: [10/565] 1% | Training loss: 0.7554984629154206
Epoch: 99 | Iteration number: [20/565] 3% | Training loss: 0.7212090730667114
Epoch: 99 | Iteration number: [30/565] 5% | Training loss: 0.7097459256649017
Epoch: 99 | Iteration number: [40/565] 7% | Training loss: 0.7038774609565734
Epoch: 99 | Iteration number: [50/565] 8% | Training loss: 0.700476405620575
Epoch: 99 | Iteration number: [60/565] 10% | Training loss: 0.6982917696237564
Epoch: 99 | Iteration number: [70/565] 12% | Training loss: 0.6966101101466587
Epoch: 99 | Iteration number: [80/565] 14% | Training loss: 0.6954078555107117
Epoch: 99 | Iteration number: [90/565] 15% | Training loss: 0.6944366375605265
Epoch: 99 | Iteration number: [100/565] 17% | Training loss: 0.6936195576190949
Epoch: 99 | Iteration number: [110/565] 19% | Training loss: 0.6930313489653848
Epoch: 99 | Iteration number: [120/565] 21% | Training loss: 0.6925178612271945
Epoch: 99 | Iteration number: [130/565] 23% | Training loss: 0.6921025711756487
Epoch: 99 | Iteration number: [140/565] 24% | Training loss: 0.6917295971087047
Epoch: 99 | Iteration number: [150/565] 26% | Training loss: 0.6913769404093425
Epoch: 99 | Iteration number: [160/565] 28% | Training loss: 0.6910992745310068
Epoch: 99 | Iteration number: [170/565] 30% | Training loss: 0.6908535992397982
Epoch: 99 | Iteration number: [180/565] 31% | Training loss: 0.6906106935607063
Epoch: 99 | Iteration number: [190/565] 33% | Training loss: 0.6903998487874081
Epoch: 99 | Iteration number: [200/565] 35% | Training loss: 0.690208269059658
Epoch: 99 | Iteration number: [210/565] 37% | Training loss: 0.6900397910958245
Epoch: 99 | Iteration number: [220/565] 38% | Training loss: 0.6898914074355905
Epoch: 99 | Iteration number: [230/565] 40% | Training loss: 0.6897483206313589
Epoch: 99 | Iteration number: [240/565] 42% | Training loss: 0.6896292251845201
Epoch: 99 | Iteration number: [250/565] 44% | Training loss: 0.6895055890083313
Epoch: 99 | Iteration number: [260/565] 46% | Training loss: 0.6893829526809546
Epoch: 99 | Iteration number: [270/565] 47% | Training loss: 0.6892882563449718
Epoch: 99 | Iteration number: [280/565] 49% | Training loss: 0.6892084864633424
Epoch: 99 | Iteration number: [290/565] 51% | Training loss: 0.6891365378067411
Epoch: 99 | Iteration number: [300/565] 53% | Training loss: 0.6890450155735016
Epoch: 99 | Iteration number: [310/565] 54% | Training loss: 0.6889784851381856
Epoch: 99 | Iteration number: [320/565] 56% | Training loss: 0.6889077441766858
Epoch: 99 | Iteration number: [330/565] 58% | Training loss: 0.6888501432808962
Epoch: 99 | Iteration number: [340/565] 60% | Training loss: 0.6887869782307569
Epoch: 99 | Iteration number: [350/565] 61% | Training loss: 0.6887248589311328
Epoch: 99 | Iteration number: [360/565] 63% | Training loss: 0.6886679955654674
Epoch: 99 | Iteration number: [370/565] 65% | Training loss: 0.6886176682807303
Epoch: 99 | Iteration number: [380/565] 67% | Training loss: 0.6885813730327707
Epoch: 99 | Iteration number: [390/565] 69% | Training loss: 0.6885323941707611
Epoch: 99 | Iteration number: [400/565] 70% | Training loss: 0.6884966024756431
Epoch: 99 | Iteration number: [410/565] 72% | Training loss: 0.6884521155822568
Epoch: 99 | Iteration number: [420/565] 74% | Training loss: 0.6883987545967102
Epoch: 99 | Iteration number: [430/565] 76% | Training loss: 0.6883587799793066
Epoch: 99 | Iteration number: [440/565] 77% | Training loss: 0.6883225732228972
Epoch: 99 | Iteration number: [450/565] 79% | Training loss: 0.6882820891009437
Epoch: 99 | Iteration number: [460/565] 81% | Training loss: 0.6882508987965791
Epoch: 99 | Iteration number: [470/565] 83% | Training loss: 0.6882239817304814
Epoch: 99 | Iteration number: [480/565] 84% | Training loss: 0.6881837405264377
Epoch: 99 | Iteration number: [490/565] 86% | Training loss: 0.6881588035700272
Epoch: 99 | Iteration number: [500/565] 88% | Training loss: 0.6881252834796906
Epoch: 99 | Iteration number: [510/565] 90% | Training loss: 0.6880983899621402
Epoch: 99 | Iteration number: [520/565] 92% | Training loss: 0.6880680824701603
Epoch: 99 | Iteration number: [530/565] 93% | Training loss: 0.6880459823698367
Epoch: 99 | Iteration number: [540/565] 95% | Training loss: 0.6880254805088043
Epoch: 99 | Iteration number: [550/565] 97% | Training loss: 0.6880024321512742
Epoch: 99 | Iteration number: [560/565] 99% | Training loss: 0.6879832335880824

 End of epoch: 99 | Train Loss: 0.6867565670899586 | Training Time: 89 

 End of epoch: 99 | Eval Loss: 0.689672725541251 | Evaluating Time: 6 
Epoch: 100 | Iteration number: [10/565] 1% | Training loss: 0.7547467529773713
Epoch: 100 | Iteration number: [20/565] 3% | Training loss: 0.7207989662885665
Epoch: 100 | Iteration number: [30/565] 5% | Training loss: 0.7093620280424754
Epoch: 100 | Iteration number: [40/565] 7% | Training loss: 0.7037547856569291
Epoch: 100 | Iteration number: [50/565] 8% | Training loss: 0.7004230356216431
Epoch: 100 | Iteration number: [60/565] 10% | Training loss: 0.6982097884019216
Epoch: 100 | Iteration number: [70/565] 12% | Training loss: 0.696581209557397
Epoch: 100 | Iteration number: [80/565] 14% | Training loss: 0.6953441105782986
Epoch: 100 | Iteration number: [90/565] 15% | Training loss: 0.6943459735976325
Epoch: 100 | Iteration number: [100/565] 17% | Training loss: 0.6935517048835754
Epoch: 100 | Iteration number: [110/565] 19% | Training loss: 0.6929439669305628
Epoch: 100 | Iteration number: [120/565] 21% | Training loss: 0.6924434577425321
Epoch: 100 | Iteration number: [130/565] 23% | Training loss: 0.6920354833969703
Epoch: 100 | Iteration number: [140/565] 24% | Training loss: 0.6916638825620923
Epoch: 100 | Iteration number: [150/565] 26% | Training loss: 0.6913269726435344
Epoch: 100 | Iteration number: [160/565] 28% | Training loss: 0.6910737317055464
Epoch: 100 | Iteration number: [170/565] 30% | Training loss: 0.6908246408490574
Epoch: 100 | Iteration number: [180/565] 31% | Training loss: 0.6905853586064444
Epoch: 100 | Iteration number: [190/565] 33% | Training loss: 0.6903559295754683
Epoch: 100 | Iteration number: [200/565] 35% | Training loss: 0.6901783394813538
Epoch: 100 | Iteration number: [210/565] 37% | Training loss: 0.689999535821733
Epoch: 100 | Iteration number: [220/565] 38% | Training loss: 0.6898295313119889
Epoch: 100 | Iteration number: [230/565] 40% | Training loss: 0.6897098429824995
Epoch: 100 | Iteration number: [240/565] 42% | Training loss: 0.6895779266953468
Epoch: 100 | Iteration number: [250/565] 44% | Training loss: 0.6894667205810547
Epoch: 100 | Iteration number: [260/565] 46% | Training loss: 0.6893671794579579
Epoch: 100 | Iteration number: [270/565] 47% | Training loss: 0.6892660646526901
Epoch: 100 | Iteration number: [280/565] 49% | Training loss: 0.6891749839697565
Epoch: 100 | Iteration number: [290/565] 51% | Training loss: 0.6890942857183259
Epoch: 100 | Iteration number: [300/565] 53% | Training loss: 0.6890104935566584
Epoch: 100 | Iteration number: [310/565] 54% | Training loss: 0.688935153330526
Epoch: 100 | Iteration number: [320/565] 56% | Training loss: 0.688874770142138
Epoch: 100 | Iteration number: [330/565] 58% | Training loss: 0.688808905175238
Epoch: 100 | Iteration number: [340/565] 60% | Training loss: 0.688758001608007
Epoch: 100 | Iteration number: [350/565] 61% | Training loss: 0.6886984733172825
Epoch: 100 | Iteration number: [360/565] 63% | Training loss: 0.6886408781011899
Epoch: 100 | Iteration number: [370/565] 65% | Training loss: 0.6885916898379455
Epoch: 100 | Iteration number: [380/565] 67% | Training loss: 0.6885356365065826
Epoch: 100 | Iteration number: [390/565] 69% | Training loss: 0.6884839936708793
Epoch: 100 | Iteration number: [400/565] 70% | Training loss: 0.6884533737599849
Epoch: 100 | Iteration number: [410/565] 72% | Training loss: 0.6884085848564054
Epoch: 100 | Iteration number: [420/565] 74% | Training loss: 0.6883659929037094
Epoch: 100 | Iteration number: [430/565] 76% | Training loss: 0.6883320704449055
Epoch: 100 | Iteration number: [440/565] 77% | Training loss: 0.6883004895665429
Epoch: 100 | Iteration number: [450/565] 79% | Training loss: 0.6882634450329674
Epoch: 100 | Iteration number: [460/565] 81% | Training loss: 0.6882345910953439
Epoch: 100 | Iteration number: [470/565] 83% | Training loss: 0.6882085177492588
Epoch: 100 | Iteration number: [480/565] 84% | Training loss: 0.6881784029304981
Epoch: 100 | Iteration number: [490/565] 86% | Training loss: 0.6881499526452045
Epoch: 100 | Iteration number: [500/565] 88% | Training loss: 0.6881185501813889
Epoch: 100 | Iteration number: [510/565] 90% | Training loss: 0.6880861809440687
Epoch: 100 | Iteration number: [520/565] 92% | Training loss: 0.6880654965455716
Epoch: 100 | Iteration number: [530/565] 93% | Training loss: 0.6880357738935723
Epoch: 100 | Iteration number: [540/565] 95% | Training loss: 0.6880092217966363
Epoch: 100 | Iteration number: [550/565] 97% | Training loss: 0.6879863804036921
Epoch: 100 | Iteration number: [560/565] 99% | Training loss: 0.6879663088491985

 End of epoch: 100 | Train Loss: 0.6867464033903273 | Training Time: 87 

 End of epoch: 100 | Eval Loss: 0.6897769144603184 | Evaluating Time: 6 

 End of Test | Dice Loss: 0.9540248513221741 | Binary Cross Entropy With Logits Loss: 0.6895017538751874 
